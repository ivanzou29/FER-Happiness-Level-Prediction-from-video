Epoch: 1| Step: 0
Training loss: 4.527660342346715
Validation loss: 4.543091553383748

Epoch: 6| Step: 1
Training loss: 5.577027113978711
Validation loss: 4.519577672352338

Epoch: 6| Step: 2
Training loss: 3.7519949375028965
Validation loss: 4.4962758088999495

Epoch: 6| Step: 3
Training loss: 4.782144300809996
Validation loss: 4.46945956627818

Epoch: 6| Step: 4
Training loss: 5.033423292017183
Validation loss: 4.443035434190945

Epoch: 6| Step: 5
Training loss: 3.714172495174877
Validation loss: 4.41632637776317

Epoch: 6| Step: 6
Training loss: 4.312433656928551
Validation loss: 4.387163184443408

Epoch: 6| Step: 7
Training loss: 5.362979310851669
Validation loss: 4.35965369642856

Epoch: 6| Step: 8
Training loss: 4.951861391829994
Validation loss: 4.3329745779940225

Epoch: 6| Step: 9
Training loss: 3.704371761541365
Validation loss: 4.302695069989943

Epoch: 6| Step: 10
Training loss: 3.561869247547009
Validation loss: 4.273246542356226

Epoch: 6| Step: 11
Training loss: 4.173678690440264
Validation loss: 4.245335094404415

Epoch: 6| Step: 12
Training loss: 4.320334132659448
Validation loss: 4.217092588774035

Epoch: 6| Step: 13
Training loss: 4.599708896216329
Validation loss: 4.187189441760838

Epoch: 2| Step: 0
Training loss: 4.8028968017216735
Validation loss: 4.156690951788553

Epoch: 6| Step: 1
Training loss: 4.877553222303306
Validation loss: 4.125369161405457

Epoch: 6| Step: 2
Training loss: 4.509751668043583
Validation loss: 4.0910398330732285

Epoch: 6| Step: 3
Training loss: 4.024368445089979
Validation loss: 4.057234613933987

Epoch: 6| Step: 4
Training loss: 3.9757641663561905
Validation loss: 4.025041318566835

Epoch: 6| Step: 5
Training loss: 4.3577258637940375
Validation loss: 3.994382768548916

Epoch: 6| Step: 6
Training loss: 3.283425037116766
Validation loss: 3.9576619967641893

Epoch: 6| Step: 7
Training loss: 2.9145091842006674
Validation loss: 3.9182121731160877

Epoch: 6| Step: 8
Training loss: 3.86703879330563
Validation loss: 3.8840801950642403

Epoch: 6| Step: 9
Training loss: 3.903675176787159
Validation loss: 3.8449039536192533

Epoch: 6| Step: 10
Training loss: 3.464939258037527
Validation loss: 3.807454319239684

Epoch: 6| Step: 11
Training loss: 4.638790500127932
Validation loss: 3.7665483706530085

Epoch: 6| Step: 12
Training loss: 4.438758349312761
Validation loss: 3.7268873135810408

Epoch: 6| Step: 13
Training loss: 3.236659325991739
Validation loss: 3.6806818542563264

Epoch: 3| Step: 0
Training loss: 3.7315383416334567
Validation loss: 3.638489431113118

Epoch: 6| Step: 1
Training loss: 4.191424224900297
Validation loss: 3.5931483110578633

Epoch: 6| Step: 2
Training loss: 3.2721523047164585
Validation loss: 3.5406487666401665

Epoch: 6| Step: 3
Training loss: 3.449994493563031
Validation loss: 3.4912866032010204

Epoch: 6| Step: 4
Training loss: 3.175930643732068
Validation loss: 3.446187272320193

Epoch: 6| Step: 5
Training loss: 3.7082777269173315
Validation loss: 3.393729878758777

Epoch: 6| Step: 6
Training loss: 4.084969692234522
Validation loss: 3.3389740583065737

Epoch: 6| Step: 7
Training loss: 2.9894997898528564
Validation loss: 3.2847436864329485

Epoch: 6| Step: 8
Training loss: 3.541796169531266
Validation loss: 3.223810939264614

Epoch: 6| Step: 9
Training loss: 3.008943260968789
Validation loss: 3.1647398549377415

Epoch: 6| Step: 10
Training loss: 3.068211115430706
Validation loss: 3.1069706577822234

Epoch: 6| Step: 11
Training loss: 3.287222812120943
Validation loss: 3.045860786853504

Epoch: 6| Step: 12
Training loss: 3.3373975930951008
Validation loss: 2.987418282427373

Epoch: 6| Step: 13
Training loss: 2.831641608432889
Validation loss: 2.9283183378365054

Epoch: 4| Step: 0
Training loss: 3.1887005807597855
Validation loss: 2.8679255368059855

Epoch: 6| Step: 1
Training loss: 2.839246600516574
Validation loss: 2.7999889152171202

Epoch: 6| Step: 2
Training loss: 2.3205425520885123
Validation loss: 2.759158878351908

Epoch: 6| Step: 3
Training loss: 2.1947148823051745
Validation loss: 2.706435864227813

Epoch: 6| Step: 4
Training loss: 2.59721795306702
Validation loss: 2.6690059077594235

Epoch: 6| Step: 5
Training loss: 2.800533438004987
Validation loss: 2.6203802722893093

Epoch: 6| Step: 6
Training loss: 2.3169614695776812
Validation loss: 2.5884525480734486

Epoch: 6| Step: 7
Training loss: 2.632444452205082
Validation loss: 2.5559012653148447

Epoch: 6| Step: 8
Training loss: 2.6430364128199573
Validation loss: 2.534103480609948

Epoch: 6| Step: 9
Training loss: 2.6278062987801616
Validation loss: 2.52077982717009

Epoch: 6| Step: 10
Training loss: 2.1341387638927802
Validation loss: 2.507629784001427

Epoch: 6| Step: 11
Training loss: 2.535482941019651
Validation loss: 2.5028948871377685

Epoch: 6| Step: 12
Training loss: 2.834577249967825
Validation loss: 2.484881279499709

Epoch: 6| Step: 13
Training loss: 3.1978816590686585
Validation loss: 2.5077283138036828

Epoch: 5| Step: 0
Training loss: 1.575486952572388
Validation loss: 2.522707822825201

Epoch: 6| Step: 1
Training loss: 2.5079033855951254
Validation loss: 2.54775365639163

Epoch: 6| Step: 2
Training loss: 2.3708935422129525
Validation loss: 2.553575979718431

Epoch: 6| Step: 3
Training loss: 2.8320565058141094
Validation loss: 2.573592330206234

Epoch: 6| Step: 4
Training loss: 3.169565647343854
Validation loss: 2.567422078382413

Epoch: 6| Step: 5
Training loss: 2.683070235849768
Validation loss: 2.570007677178104

Epoch: 6| Step: 6
Training loss: 2.20344768352479
Validation loss: 2.5872841024704187

Epoch: 6| Step: 7
Training loss: 2.67244558209362
Validation loss: 2.583665139413867

Epoch: 6| Step: 8
Training loss: 2.435822912509938
Validation loss: 2.575541965152357

Epoch: 6| Step: 9
Training loss: 2.3126721704673576
Validation loss: 2.5695490374770524

Epoch: 6| Step: 10
Training loss: 3.1849914852489634
Validation loss: 2.5528610186402947

Epoch: 6| Step: 11
Training loss: 2.7445187997033376
Validation loss: 2.5339768717512463

Epoch: 6| Step: 12
Training loss: 2.18144139103277
Validation loss: 2.5376238302574485

Epoch: 6| Step: 13
Training loss: 2.949712487127155
Validation loss: 2.5186261426638543

Epoch: 6| Step: 0
Training loss: 3.586951683754856
Validation loss: 2.512388259781594

Epoch: 6| Step: 1
Training loss: 2.334558800913328
Validation loss: 2.493095734702534

Epoch: 6| Step: 2
Training loss: 2.4890944081935484
Validation loss: 2.4859127667641476

Epoch: 6| Step: 3
Training loss: 2.109316111555017
Validation loss: 2.4954420979286174

Epoch: 6| Step: 4
Training loss: 1.8503646516980214
Validation loss: 2.4736314952519027

Epoch: 6| Step: 5
Training loss: 3.0287523499659588
Validation loss: 2.486398860207881

Epoch: 6| Step: 6
Training loss: 3.209872252397124
Validation loss: 2.4827230067255774

Epoch: 6| Step: 7
Training loss: 1.802446303077036
Validation loss: 2.4934596817707098

Epoch: 6| Step: 8
Training loss: 2.7631137459557467
Validation loss: 2.492482015493205

Epoch: 6| Step: 9
Training loss: 2.817295140533649
Validation loss: 2.4814967550835143

Epoch: 6| Step: 10
Training loss: 2.292360605309599
Validation loss: 2.480647836062504

Epoch: 6| Step: 11
Training loss: 2.352752080499542
Validation loss: 2.494163566848285

Epoch: 6| Step: 12
Training loss: 2.7185156710258784
Validation loss: 2.4760628084834955

Epoch: 6| Step: 13
Training loss: 1.4348216605934445
Validation loss: 2.482615105456506

Epoch: 7| Step: 0
Training loss: 2.69274054286048
Validation loss: 2.4877246371871906

Epoch: 6| Step: 1
Training loss: 2.731748529324363
Validation loss: 2.4881755141664517

Epoch: 6| Step: 2
Training loss: 2.2224354827064117
Validation loss: 2.479980020109315

Epoch: 6| Step: 3
Training loss: 2.179578771579728
Validation loss: 2.4856260816331788

Epoch: 6| Step: 4
Training loss: 2.8275424083224316
Validation loss: 2.4785871282493592

Epoch: 6| Step: 5
Training loss: 2.612400334113489
Validation loss: 2.4783378198613404

Epoch: 6| Step: 6
Training loss: 2.753666773995988
Validation loss: 2.480901188839142

Epoch: 6| Step: 7
Training loss: 2.0582446502649385
Validation loss: 2.483012827623089

Epoch: 6| Step: 8
Training loss: 2.5222597001307308
Validation loss: 2.484455835078967

Epoch: 6| Step: 9
Training loss: 2.7423993759682035
Validation loss: 2.4802063810705848

Epoch: 6| Step: 10
Training loss: 2.8104325218875132
Validation loss: 2.4714878369041777

Epoch: 6| Step: 11
Training loss: 2.468871970724851
Validation loss: 2.476028657610758

Epoch: 6| Step: 12
Training loss: 2.6265691880793978
Validation loss: 2.472551838788135

Epoch: 6| Step: 13
Training loss: 1.924143932776001
Validation loss: 2.4703836629044877

Epoch: 8| Step: 0
Training loss: 1.9998999809051121
Validation loss: 2.4811375314636708

Epoch: 6| Step: 1
Training loss: 2.717208074280125
Validation loss: 2.480299768173686

Epoch: 6| Step: 2
Training loss: 2.651138503748597
Validation loss: 2.476380607271161

Epoch: 6| Step: 3
Training loss: 2.5272615823256737
Validation loss: 2.4742856796265276

Epoch: 6| Step: 4
Training loss: 2.5935291058341408
Validation loss: 2.481382455020927

Epoch: 6| Step: 5
Training loss: 2.850055453112348
Validation loss: 2.475657589569579

Epoch: 6| Step: 6
Training loss: 2.55200427704934
Validation loss: 2.4739690813868433

Epoch: 6| Step: 7
Training loss: 2.203964830855287
Validation loss: 2.4689371866976115

Epoch: 6| Step: 8
Training loss: 2.8070571792046235
Validation loss: 2.477844051102955

Epoch: 6| Step: 9
Training loss: 3.0124944536466707
Validation loss: 2.4703007426938197

Epoch: 6| Step: 10
Training loss: 2.6094175780700035
Validation loss: 2.475269898876882

Epoch: 6| Step: 11
Training loss: 2.700173944592216
Validation loss: 2.4717158035217994

Epoch: 6| Step: 12
Training loss: 2.0207627929750718
Validation loss: 2.4724000594174838

Epoch: 6| Step: 13
Training loss: 1.7884000526252455
Validation loss: 2.4742351551112294

Epoch: 9| Step: 0
Training loss: 2.908369050630949
Validation loss: 2.4624833191953748

Epoch: 6| Step: 1
Training loss: 2.361565589796758
Validation loss: 2.471306117360809

Epoch: 6| Step: 2
Training loss: 2.5143097466088165
Validation loss: 2.4588038484552657

Epoch: 6| Step: 3
Training loss: 3.2335466439059495
Validation loss: 2.4723874910764474

Epoch: 6| Step: 4
Training loss: 2.0355217252212405
Validation loss: 2.479312537146683

Epoch: 6| Step: 5
Training loss: 2.3594107719892703
Validation loss: 2.463775709673861

Epoch: 6| Step: 6
Training loss: 2.4681590857896727
Validation loss: 2.4846033435224513

Epoch: 6| Step: 7
Training loss: 2.3583117988421
Validation loss: 2.472453064326777

Epoch: 6| Step: 8
Training loss: 2.5976769009106304
Validation loss: 2.46938610332197

Epoch: 6| Step: 9
Training loss: 2.5909559528548125
Validation loss: 2.4715868830606533

Epoch: 6| Step: 10
Training loss: 2.6037830121039454
Validation loss: 2.4596293368381357

Epoch: 6| Step: 11
Training loss: 2.340322913524775
Validation loss: 2.4638434635874376

Epoch: 6| Step: 12
Training loss: 2.0951804214028873
Validation loss: 2.454761089125985

Epoch: 6| Step: 13
Training loss: 2.6382113830695624
Validation loss: 2.453616293530489

Epoch: 10| Step: 0
Training loss: 2.4749329798708275
Validation loss: 2.464421207344035

Epoch: 6| Step: 1
Training loss: 2.5218727764134017
Validation loss: 2.467399050481172

Epoch: 6| Step: 2
Training loss: 2.5888174563782456
Validation loss: 2.4601653648765662

Epoch: 6| Step: 3
Training loss: 1.898605715987304
Validation loss: 2.4651591909717885

Epoch: 6| Step: 4
Training loss: 2.2336536656949986
Validation loss: 2.4551765869272018

Epoch: 6| Step: 5
Training loss: 2.785679665025481
Validation loss: 2.4712416874834675

Epoch: 6| Step: 6
Training loss: 2.5208968372595546
Validation loss: 2.4745921129579544

Epoch: 6| Step: 7
Training loss: 2.0002484167317056
Validation loss: 2.4686633710510413

Epoch: 6| Step: 8
Training loss: 1.7809698319533322
Validation loss: 2.45689618134116

Epoch: 6| Step: 9
Training loss: 2.584421226152624
Validation loss: 2.4660390544092365

Epoch: 6| Step: 10
Training loss: 2.8117920726342844
Validation loss: 2.471158924704613

Epoch: 6| Step: 11
Training loss: 2.3055016065768568
Validation loss: 2.475564284170382

Epoch: 6| Step: 12
Training loss: 2.755483968080008
Validation loss: 2.4605764780193127

Epoch: 6| Step: 13
Training loss: 3.375972042682106
Validation loss: 2.475695950824362

Epoch: 11| Step: 0
Training loss: 2.426826878261406
Validation loss: 2.4748017543168914

Epoch: 6| Step: 1
Training loss: 3.0564423420611484
Validation loss: 2.46550485941152

Epoch: 6| Step: 2
Training loss: 1.88302066649422
Validation loss: 2.465395398684593

Epoch: 6| Step: 3
Training loss: 2.310681736574303
Validation loss: 2.458433881955547

Epoch: 6| Step: 4
Training loss: 2.5205443245490846
Validation loss: 2.459405702870275

Epoch: 6| Step: 5
Training loss: 2.8525168298196415
Validation loss: 2.455921870761658

Epoch: 6| Step: 6
Training loss: 2.077570332095221
Validation loss: 2.462791325914127

Epoch: 6| Step: 7
Training loss: 2.5920541573800615
Validation loss: 2.4505109688820093

Epoch: 6| Step: 8
Training loss: 2.8640861680904557
Validation loss: 2.453797865672977

Epoch: 6| Step: 9
Training loss: 2.2238428471498564
Validation loss: 2.4588470461036014

Epoch: 6| Step: 10
Training loss: 2.509561184523539
Validation loss: 2.458474564671127

Epoch: 6| Step: 11
Training loss: 2.2649864612368398
Validation loss: 2.447561024472328

Epoch: 6| Step: 12
Training loss: 2.1009356049406125
Validation loss: 2.455143561713914

Epoch: 6| Step: 13
Training loss: 3.050836267109551
Validation loss: 2.4577147680835756

Epoch: 12| Step: 0
Training loss: 2.1075044603402393
Validation loss: 2.447543003430535

Epoch: 6| Step: 1
Training loss: 2.0305425732509694
Validation loss: 2.4499484673095333

Epoch: 6| Step: 2
Training loss: 2.3572046263556956
Validation loss: 2.4662950598829316

Epoch: 6| Step: 3
Training loss: 2.3349648176070854
Validation loss: 2.461110798218848

Epoch: 6| Step: 4
Training loss: 2.458487899145355
Validation loss: 2.461945988126413

Epoch: 6| Step: 5
Training loss: 2.4064382504233484
Validation loss: 2.470060893786933

Epoch: 6| Step: 6
Training loss: 2.5915917298828095
Validation loss: 2.4588643540393083

Epoch: 6| Step: 7
Training loss: 2.751271907402006
Validation loss: 2.473629712146654

Epoch: 6| Step: 8
Training loss: 2.567118692433694
Validation loss: 2.4745812177373376

Epoch: 6| Step: 9
Training loss: 3.290367900372207
Validation loss: 2.4593979717702186

Epoch: 6| Step: 10
Training loss: 2.1267383421455843
Validation loss: 2.4522134338539847

Epoch: 6| Step: 11
Training loss: 2.9750867173835704
Validation loss: 2.452820275042828

Epoch: 6| Step: 12
Training loss: 2.1406420407695923
Validation loss: 2.4602195055652993

Epoch: 6| Step: 13
Training loss: 2.7155626401775876
Validation loss: 2.4511660957014993

Epoch: 13| Step: 0
Training loss: 2.1322948680034313
Validation loss: 2.4571846417293965

Epoch: 6| Step: 1
Training loss: 2.409453897136855
Validation loss: 2.4548178741973548

Epoch: 6| Step: 2
Training loss: 3.182096201652657
Validation loss: 2.4379004940091344

Epoch: 6| Step: 3
Training loss: 2.487160231039018
Validation loss: 2.431135614902882

Epoch: 6| Step: 4
Training loss: 2.575905971961224
Validation loss: 2.4470409423111343

Epoch: 6| Step: 5
Training loss: 2.6266016842054114
Validation loss: 2.4378312774249298

Epoch: 6| Step: 6
Training loss: 2.4742732975219366
Validation loss: 2.4569842602431753

Epoch: 6| Step: 7
Training loss: 2.139721087881161
Validation loss: 2.4611071089168335

Epoch: 6| Step: 8
Training loss: 2.251315685883453
Validation loss: 2.4397572718984675

Epoch: 6| Step: 9
Training loss: 2.5457738824657095
Validation loss: 2.4509513279556674

Epoch: 6| Step: 10
Training loss: 2.516434628061037
Validation loss: 2.4488194741997726

Epoch: 6| Step: 11
Training loss: 2.970942601088894
Validation loss: 2.446559064207102

Epoch: 6| Step: 12
Training loss: 2.4710383372526543
Validation loss: 2.448011223339811

Epoch: 6| Step: 13
Training loss: 2.003344005211425
Validation loss: 2.450542856591095

Epoch: 14| Step: 0
Training loss: 2.442969031070099
Validation loss: 2.4467201446991114

Epoch: 6| Step: 1
Training loss: 2.3274052678711343
Validation loss: 2.4441875921273386

Epoch: 6| Step: 2
Training loss: 2.0808914242255128
Validation loss: 2.4470706424636286

Epoch: 6| Step: 3
Training loss: 2.4348348082920643
Validation loss: 2.4383323748002828

Epoch: 6| Step: 4
Training loss: 2.40170671654195
Validation loss: 2.4372753952747948

Epoch: 6| Step: 5
Training loss: 2.3924298423437853
Validation loss: 2.442901674168561

Epoch: 6| Step: 6
Training loss: 2.876460492233277
Validation loss: 2.4475579722691774

Epoch: 6| Step: 7
Training loss: 2.6918794301822255
Validation loss: 2.4424859917042783

Epoch: 6| Step: 8
Training loss: 3.01164591858273
Validation loss: 2.449680623497703

Epoch: 6| Step: 9
Training loss: 2.326870471459141
Validation loss: 2.4579835227965496

Epoch: 6| Step: 10
Training loss: 2.699956282508981
Validation loss: 2.4508037072805475

Epoch: 6| Step: 11
Training loss: 2.0600542537248367
Validation loss: 2.4658427282139144

Epoch: 6| Step: 12
Training loss: 2.41947985931105
Validation loss: 2.452244999649229

Epoch: 6| Step: 13
Training loss: 2.4847906952486634
Validation loss: 2.4542072524863574

Epoch: 15| Step: 0
Training loss: 2.7418586555517273
Validation loss: 2.454639857991533

Epoch: 6| Step: 1
Training loss: 2.229152097089934
Validation loss: 2.4613036352603226

Epoch: 6| Step: 2
Training loss: 2.1606936898539115
Validation loss: 2.458750694751884

Epoch: 6| Step: 3
Training loss: 2.7775150895416996
Validation loss: 2.4530500493677594

Epoch: 6| Step: 4
Training loss: 1.7885526905227374
Validation loss: 2.4502332128738464

Epoch: 6| Step: 5
Training loss: 2.3072348789319346
Validation loss: 2.445972438887795

Epoch: 6| Step: 6
Training loss: 2.562726266687246
Validation loss: 2.438152323757729

Epoch: 6| Step: 7
Training loss: 2.6200680495299125
Validation loss: 2.4458269709472393

Epoch: 6| Step: 8
Training loss: 2.735911607864882
Validation loss: 2.4401880749932188

Epoch: 6| Step: 9
Training loss: 2.6030596300139663
Validation loss: 2.4512158231607564

Epoch: 6| Step: 10
Training loss: 2.787573494391368
Validation loss: 2.449684143466388

Epoch: 6| Step: 11
Training loss: 2.405168562789246
Validation loss: 2.4549467040995365

Epoch: 6| Step: 12
Training loss: 2.645495465750766
Validation loss: 2.4469562892151027

Epoch: 6| Step: 13
Training loss: 2.2674168308402916
Validation loss: 2.4531146816676492

Epoch: 16| Step: 0
Training loss: 2.0920463577079436
Validation loss: 2.458791210615928

Epoch: 6| Step: 1
Training loss: 2.4070421376488182
Validation loss: 2.4351154955889673

Epoch: 6| Step: 2
Training loss: 2.5003364336613063
Validation loss: 2.442448711357851

Epoch: 6| Step: 3
Training loss: 2.382987694475207
Validation loss: 2.447657215626763

Epoch: 6| Step: 4
Training loss: 2.889211938189945
Validation loss: 2.4384024327052822

Epoch: 6| Step: 5
Training loss: 2.1607281167624657
Validation loss: 2.436540838776998

Epoch: 6| Step: 6
Training loss: 2.561095620487981
Validation loss: 2.4379255298311477

Epoch: 6| Step: 7
Training loss: 2.4971103180152325
Validation loss: 2.4347558020378233

Epoch: 6| Step: 8
Training loss: 2.488964424188644
Validation loss: 2.435173342525156

Epoch: 6| Step: 9
Training loss: 2.073350972696481
Validation loss: 2.4405350170732545

Epoch: 6| Step: 10
Training loss: 2.848811413721039
Validation loss: 2.4371527236953208

Epoch: 6| Step: 11
Training loss: 2.3059512019755175
Validation loss: 2.4356576608333245

Epoch: 6| Step: 12
Training loss: 2.9336002517404647
Validation loss: 2.4356607687352185

Epoch: 6| Step: 13
Training loss: 2.223103939082112
Validation loss: 2.4379107952378636

Epoch: 17| Step: 0
Training loss: 2.8159497614627345
Validation loss: 2.4259059216685923

Epoch: 6| Step: 1
Training loss: 2.2697080454683634
Validation loss: 2.438792334416761

Epoch: 6| Step: 2
Training loss: 2.056031458409912
Validation loss: 2.4391876964055688

Epoch: 6| Step: 3
Training loss: 2.408505658207021
Validation loss: 2.4273648132909855

Epoch: 6| Step: 4
Training loss: 2.754525016367776
Validation loss: 2.433388266095773

Epoch: 6| Step: 5
Training loss: 2.45644702849139
Validation loss: 2.4459498573199987

Epoch: 6| Step: 6
Training loss: 3.1233815389012
Validation loss: 2.4352173264902794

Epoch: 6| Step: 7
Training loss: 2.572187394999656
Validation loss: 2.4284795311629424

Epoch: 6| Step: 8
Training loss: 2.41476222887664
Validation loss: 2.4268723479374414

Epoch: 6| Step: 9
Training loss: 2.261399531526113
Validation loss: 2.4391401429640815

Epoch: 6| Step: 10
Training loss: 1.8554489616543484
Validation loss: 2.4307447220592224

Epoch: 6| Step: 11
Training loss: 2.499922369705352
Validation loss: 2.429353697192449

Epoch: 6| Step: 12
Training loss: 2.163734493806086
Validation loss: 2.434335047696404

Epoch: 6| Step: 13
Training loss: 2.6322768937181813
Validation loss: 2.435216763539707

Epoch: 18| Step: 0
Training loss: 2.5460904088895306
Validation loss: 2.435238547184342

Epoch: 6| Step: 1
Training loss: 2.0864792023972183
Validation loss: 2.446885047135202

Epoch: 6| Step: 2
Training loss: 2.830507234063782
Validation loss: 2.436730679124776

Epoch: 6| Step: 3
Training loss: 2.5652753175802734
Validation loss: 2.4285203884275

Epoch: 6| Step: 4
Training loss: 1.9876252836651003
Validation loss: 2.448283786164136

Epoch: 6| Step: 5
Training loss: 2.2648703535082717
Validation loss: 2.439049668311921

Epoch: 6| Step: 6
Training loss: 2.398191955124837
Validation loss: 2.4327486304635793

Epoch: 6| Step: 7
Training loss: 2.891074975534214
Validation loss: 2.4295578213641438

Epoch: 6| Step: 8
Training loss: 2.690170203571166
Validation loss: 2.4421588358271813

Epoch: 6| Step: 9
Training loss: 2.117002359438497
Validation loss: 2.44075826361665

Epoch: 6| Step: 10
Training loss: 1.7849738029887041
Validation loss: 2.439580371918959

Epoch: 6| Step: 11
Training loss: 2.427608274958196
Validation loss: 2.453026965990813

Epoch: 6| Step: 12
Training loss: 2.48757584422667
Validation loss: 2.453099422766948

Epoch: 6| Step: 13
Training loss: 3.1215383048346217
Validation loss: 2.459735395110364

Epoch: 19| Step: 0
Training loss: 2.046706680482427
Validation loss: 2.4444171537937356

Epoch: 6| Step: 1
Training loss: 2.1426991904036927
Validation loss: 2.4437532176120973

Epoch: 6| Step: 2
Training loss: 2.49482649511397
Validation loss: 2.4501494323156865

Epoch: 6| Step: 3
Training loss: 2.2448848224142286
Validation loss: 2.441694351490678

Epoch: 6| Step: 4
Training loss: 1.9441318222806228
Validation loss: 2.4446299679993015

Epoch: 6| Step: 5
Training loss: 2.9393934275499474
Validation loss: 2.434638348733136

Epoch: 6| Step: 6
Training loss: 2.991492606565612
Validation loss: 2.4265956197633036

Epoch: 6| Step: 7
Training loss: 2.4507576763465186
Validation loss: 2.423535128704618

Epoch: 6| Step: 8
Training loss: 2.852791132199748
Validation loss: 2.429490534249285

Epoch: 6| Step: 9
Training loss: 2.6343743194180984
Validation loss: 2.4243770513667644

Epoch: 6| Step: 10
Training loss: 2.2758206071734115
Validation loss: 2.4276153870831862

Epoch: 6| Step: 11
Training loss: 2.8649892253573266
Validation loss: 2.435642202837169

Epoch: 6| Step: 12
Training loss: 1.9946179691981358
Validation loss: 2.4384507827302504

Epoch: 6| Step: 13
Training loss: 2.15854809795956
Validation loss: 2.413356673705619

Epoch: 20| Step: 0
Training loss: 2.2237968535094907
Validation loss: 2.4268291214739

Epoch: 6| Step: 1
Training loss: 2.3542358815868734
Validation loss: 2.41940926989644

Epoch: 6| Step: 2
Training loss: 2.752673410190124
Validation loss: 2.4256126521313175

Epoch: 6| Step: 3
Training loss: 2.153518051790987
Validation loss: 2.4273167826702844

Epoch: 6| Step: 4
Training loss: 2.6326255845185655
Validation loss: 2.440192764828776

Epoch: 6| Step: 5
Training loss: 2.2122270577390277
Validation loss: 2.432661405529265

Epoch: 6| Step: 6
Training loss: 2.2427375995895713
Validation loss: 2.45034695912804

Epoch: 6| Step: 7
Training loss: 3.525391842321466
Validation loss: 2.4358226514963364

Epoch: 6| Step: 8
Training loss: 2.609140899573207
Validation loss: 2.45801954098635

Epoch: 6| Step: 9
Training loss: 2.5057880156563
Validation loss: 2.4409219653142706

Epoch: 6| Step: 10
Training loss: 2.5387190835968245
Validation loss: 2.4440477246766754

Epoch: 6| Step: 11
Training loss: 2.1954721413123894
Validation loss: 2.432614818946015

Epoch: 6| Step: 12
Training loss: 2.3215749883065517
Validation loss: 2.4257753610667456

Epoch: 6| Step: 13
Training loss: 2.056221972799172
Validation loss: 2.427286529766952

Epoch: 21| Step: 0
Training loss: 2.016729717477514
Validation loss: 2.423585029602594

Epoch: 6| Step: 1
Training loss: 1.9471998748851351
Validation loss: 2.4307721855869304

Epoch: 6| Step: 2
Training loss: 2.9170114767524264
Validation loss: 2.4195945257663

Epoch: 6| Step: 3
Training loss: 3.129731525448584
Validation loss: 2.4206044299512977

Epoch: 6| Step: 4
Training loss: 2.3586982615446326
Validation loss: 2.426077398220211

Epoch: 6| Step: 5
Training loss: 2.645603520382551
Validation loss: 2.4233509119577734

Epoch: 6| Step: 6
Training loss: 1.8907492730778477
Validation loss: 2.420528406667968

Epoch: 6| Step: 7
Training loss: 2.716327596540015
Validation loss: 2.4249669836359518

Epoch: 6| Step: 8
Training loss: 2.581672955237114
Validation loss: 2.424849670705764

Epoch: 6| Step: 9
Training loss: 2.6771277833407505
Validation loss: 2.420831369299647

Epoch: 6| Step: 10
Training loss: 2.6428827869982747
Validation loss: 2.4217303325145476

Epoch: 6| Step: 11
Training loss: 1.682656294887959
Validation loss: 2.420223944866141

Epoch: 6| Step: 12
Training loss: 2.296154921405719
Validation loss: 2.4308405079396262

Epoch: 6| Step: 13
Training loss: 2.371895216301567
Validation loss: 2.415366091389284

Epoch: 22| Step: 0
Training loss: 2.3420008935576444
Validation loss: 2.4330071507181725

Epoch: 6| Step: 1
Training loss: 2.529110322059653
Validation loss: 2.4173613130907325

Epoch: 6| Step: 2
Training loss: 2.8860704987203594
Validation loss: 2.4147367801132593

Epoch: 6| Step: 3
Training loss: 2.6732927988868562
Validation loss: 2.425050560925555

Epoch: 6| Step: 4
Training loss: 2.488043613554477
Validation loss: 2.412976741957448

Epoch: 6| Step: 5
Training loss: 2.106959563589225
Validation loss: 2.4310695564888176

Epoch: 6| Step: 6
Training loss: 2.505988768093454
Validation loss: 2.427668886945866

Epoch: 6| Step: 7
Training loss: 2.0678538568312
Validation loss: 2.4243426477421246

Epoch: 6| Step: 8
Training loss: 2.0544662066326516
Validation loss: 2.4257668921168074

Epoch: 6| Step: 9
Training loss: 2.9155871618826894
Validation loss: 2.4131554604239467

Epoch: 6| Step: 10
Training loss: 2.2149748586773517
Validation loss: 2.428097808960576

Epoch: 6| Step: 11
Training loss: 2.684784781782966
Validation loss: 2.437542132478103

Epoch: 6| Step: 12
Training loss: 2.523147991567977
Validation loss: 2.43894876316333

Epoch: 6| Step: 13
Training loss: 2.051455780995685
Validation loss: 2.426406427601594

Epoch: 23| Step: 0
Training loss: 2.5585686835306
Validation loss: 2.4342550049810954

Epoch: 6| Step: 1
Training loss: 2.38909174799558
Validation loss: 2.431541013911566

Epoch: 6| Step: 2
Training loss: 2.946086913277668
Validation loss: 2.4357502191410294

Epoch: 6| Step: 3
Training loss: 2.7669140241726136
Validation loss: 2.4154515472687215

Epoch: 6| Step: 4
Training loss: 2.168603862489031
Validation loss: 2.4260101292286804

Epoch: 6| Step: 5
Training loss: 2.3294141643600206
Validation loss: 2.4128066235375916

Epoch: 6| Step: 6
Training loss: 2.38393208200881
Validation loss: 2.419018560149369

Epoch: 6| Step: 7
Training loss: 2.7350851826068823
Validation loss: 2.4294681102488727

Epoch: 6| Step: 8
Training loss: 2.360686184163689
Validation loss: 2.417181656215371

Epoch: 6| Step: 9
Training loss: 2.2829010097047755
Validation loss: 2.429236645178605

Epoch: 6| Step: 10
Training loss: 1.9020005059427096
Validation loss: 2.424597065671413

Epoch: 6| Step: 11
Training loss: 2.4205514552228777
Validation loss: 2.428212248463267

Epoch: 6| Step: 12
Training loss: 2.4365311677920958
Validation loss: 2.4139540729225573

Epoch: 6| Step: 13
Training loss: 2.567062038669104
Validation loss: 2.4129300223430867

Epoch: 24| Step: 0
Training loss: 1.8559213829079377
Validation loss: 2.4257123100898657

Epoch: 6| Step: 1
Training loss: 2.5692755279920862
Validation loss: 2.4193166694911667

Epoch: 6| Step: 2
Training loss: 2.379846045860078
Validation loss: 2.413019319090988

Epoch: 6| Step: 3
Training loss: 2.4377809020333143
Validation loss: 2.42569418406407

Epoch: 6| Step: 4
Training loss: 2.1884588047653604
Validation loss: 2.4237172493075305

Epoch: 6| Step: 5
Training loss: 2.023558859702183
Validation loss: 2.409394335968102

Epoch: 6| Step: 6
Training loss: 3.161972448201216
Validation loss: 2.414326049508594

Epoch: 6| Step: 7
Training loss: 2.8443351395122654
Validation loss: 2.417853940704172

Epoch: 6| Step: 8
Training loss: 2.0679902493894464
Validation loss: 2.4214562987309973

Epoch: 6| Step: 9
Training loss: 2.957547867065946
Validation loss: 2.414420651695419

Epoch: 6| Step: 10
Training loss: 2.3147281531606834
Validation loss: 2.42238151421939

Epoch: 6| Step: 11
Training loss: 1.7854394333351193
Validation loss: 2.411267585433187

Epoch: 6| Step: 12
Training loss: 2.6744399224175153
Validation loss: 2.4227039190181014

Epoch: 6| Step: 13
Training loss: 2.3553776509902145
Validation loss: 2.4234266827307254

Epoch: 25| Step: 0
Training loss: 2.5593287686188595
Validation loss: 2.4201659458447335

Epoch: 6| Step: 1
Training loss: 1.949186764380133
Validation loss: 2.4326193600336965

Epoch: 6| Step: 2
Training loss: 1.9961489317072894
Validation loss: 2.4351073202129703

Epoch: 6| Step: 3
Training loss: 1.8991008588574323
Validation loss: 2.432327259356036

Epoch: 6| Step: 4
Training loss: 2.6741259278780074
Validation loss: 2.4634120468869396

Epoch: 6| Step: 5
Training loss: 2.8265852978379
Validation loss: 2.4522927688787575

Epoch: 6| Step: 6
Training loss: 1.8377051751424218
Validation loss: 2.4769771000246714

Epoch: 6| Step: 7
Training loss: 2.5053034795403866
Validation loss: 2.471963215832031

Epoch: 6| Step: 8
Training loss: 2.9296113271347397
Validation loss: 2.479146097135294

Epoch: 6| Step: 9
Training loss: 2.5038891105838905
Validation loss: 2.4779624953029558

Epoch: 6| Step: 10
Training loss: 2.8898512345934098
Validation loss: 2.4489119325885578

Epoch: 6| Step: 11
Training loss: 2.733459493780397
Validation loss: 2.4449015100348834

Epoch: 6| Step: 12
Training loss: 2.1937864164715237
Validation loss: 2.4308321792378353

Epoch: 6| Step: 13
Training loss: 2.4314666808393115
Validation loss: 2.4253131212042747

Epoch: 26| Step: 0
Training loss: 2.3710139102471435
Validation loss: 2.4136611621324877

Epoch: 6| Step: 1
Training loss: 1.8416070931351887
Validation loss: 2.4189602940341475

Epoch: 6| Step: 2
Training loss: 2.275923480727002
Validation loss: 2.4076701675650836

Epoch: 6| Step: 3
Training loss: 2.122097276778757
Validation loss: 2.4245323123426816

Epoch: 6| Step: 4
Training loss: 2.4508888111582388
Validation loss: 2.410589821106898

Epoch: 6| Step: 5
Training loss: 2.8574545826477333
Validation loss: 2.4162050880643164

Epoch: 6| Step: 6
Training loss: 2.2392196951482113
Validation loss: 2.4178349586821968

Epoch: 6| Step: 7
Training loss: 2.391656191954675
Validation loss: 2.408986925470478

Epoch: 6| Step: 8
Training loss: 2.848020428262804
Validation loss: 2.411720069429321

Epoch: 6| Step: 9
Training loss: 2.5566230930691853
Validation loss: 2.413146379085153

Epoch: 6| Step: 10
Training loss: 2.439019927509226
Validation loss: 2.427990908788496

Epoch: 6| Step: 11
Training loss: 2.5674773467642242
Validation loss: 2.430399963000617

Epoch: 6| Step: 12
Training loss: 2.2600955178322315
Validation loss: 2.416132931031725

Epoch: 6| Step: 13
Training loss: 2.770081458701494
Validation loss: 2.4198954213615385

Epoch: 27| Step: 0
Training loss: 2.7566062299137535
Validation loss: 2.420283395499048

Epoch: 6| Step: 1
Training loss: 2.7013426621204757
Validation loss: 2.414071882408699

Epoch: 6| Step: 2
Training loss: 1.796692946789725
Validation loss: 2.4248518256179903

Epoch: 6| Step: 3
Training loss: 2.53119348533554
Validation loss: 2.418574029926827

Epoch: 6| Step: 4
Training loss: 2.8540688565240964
Validation loss: 2.4143230046654343

Epoch: 6| Step: 5
Training loss: 1.5636000766132498
Validation loss: 2.418974486980909

Epoch: 6| Step: 6
Training loss: 2.148781155931242
Validation loss: 2.4197859911962243

Epoch: 6| Step: 7
Training loss: 2.5323574328045537
Validation loss: 2.4216314131771406

Epoch: 6| Step: 8
Training loss: 2.3236339698949586
Validation loss: 2.433538674047177

Epoch: 6| Step: 9
Training loss: 2.198337520665752
Validation loss: 2.4406734251720494

Epoch: 6| Step: 10
Training loss: 3.084594588883764
Validation loss: 2.436877195558344

Epoch: 6| Step: 11
Training loss: 2.202847077716185
Validation loss: 2.427334069874327

Epoch: 6| Step: 12
Training loss: 2.784182855931422
Validation loss: 2.4275496912072962

Epoch: 6| Step: 13
Training loss: 2.2193125696621356
Validation loss: 2.4278492571736985

Epoch: 28| Step: 0
Training loss: 2.2109854864837195
Validation loss: 2.4192390371367725

Epoch: 6| Step: 1
Training loss: 3.0584719890654464
Validation loss: 2.4208076668285314

Epoch: 6| Step: 2
Training loss: 3.1250357053624267
Validation loss: 2.4114238058190334

Epoch: 6| Step: 3
Training loss: 2.126995383999671
Validation loss: 2.4156473547792268

Epoch: 6| Step: 4
Training loss: 2.6248214297637418
Validation loss: 2.4134453701740703

Epoch: 6| Step: 5
Training loss: 1.8639036534585742
Validation loss: 2.4134761423286197

Epoch: 6| Step: 6
Training loss: 2.4957192010103517
Validation loss: 2.4088625081235784

Epoch: 6| Step: 7
Training loss: 1.9256482803834278
Validation loss: 2.4162769304811675

Epoch: 6| Step: 8
Training loss: 2.042769996792625
Validation loss: 2.4213072408679084

Epoch: 6| Step: 9
Training loss: 2.359813220019781
Validation loss: 2.4026069310870675

Epoch: 6| Step: 10
Training loss: 2.4887449589998702
Validation loss: 2.4234457357313

Epoch: 6| Step: 11
Training loss: 2.4751629168903055
Validation loss: 2.412001436729699

Epoch: 6| Step: 12
Training loss: 2.086952448319178
Validation loss: 2.402508572349114

Epoch: 6| Step: 13
Training loss: 2.7724869079555914
Validation loss: 2.4097219412806847

Epoch: 29| Step: 0
Training loss: 2.1992495383890596
Validation loss: 2.418096486601603

Epoch: 6| Step: 1
Training loss: 2.6007269356608878
Validation loss: 2.408826695191044

Epoch: 6| Step: 2
Training loss: 2.687448900313618
Validation loss: 2.4176995492688227

Epoch: 6| Step: 3
Training loss: 2.197407655999844
Validation loss: 2.414661213889022

Epoch: 6| Step: 4
Training loss: 1.8919813476957659
Validation loss: 2.4287865737776393

Epoch: 6| Step: 5
Training loss: 2.297246993686138
Validation loss: 2.443483369335502

Epoch: 6| Step: 6
Training loss: 2.95559572879319
Validation loss: 2.458415213261191

Epoch: 6| Step: 7
Training loss: 1.6451690234509815
Validation loss: 2.4554784949563735

Epoch: 6| Step: 8
Training loss: 2.6492536969412415
Validation loss: 2.4642339517357783

Epoch: 6| Step: 9
Training loss: 2.41758180150492
Validation loss: 2.471076898862098

Epoch: 6| Step: 10
Training loss: 2.8903999859634344
Validation loss: 2.490368696591852

Epoch: 6| Step: 11
Training loss: 1.7902869153371186
Validation loss: 2.4857939820388464

Epoch: 6| Step: 12
Training loss: 2.341317911298587
Validation loss: 2.4663991881881566

Epoch: 6| Step: 13
Training loss: 3.0694007199156883
Validation loss: 2.4514421250707743

Epoch: 30| Step: 0
Training loss: 2.133373033134299
Validation loss: 2.433533938730664

Epoch: 6| Step: 1
Training loss: 2.2250605285640943
Validation loss: 2.4159008297982476

Epoch: 6| Step: 2
Training loss: 1.8169287145526292
Validation loss: 2.429996156048449

Epoch: 6| Step: 3
Training loss: 2.7421772405100993
Validation loss: 2.4153566482016022

Epoch: 6| Step: 4
Training loss: 2.722472437779489
Validation loss: 2.418496069775019

Epoch: 6| Step: 5
Training loss: 2.622616821392673
Validation loss: 2.420442038300378

Epoch: 6| Step: 6
Training loss: 2.4398727605819097
Validation loss: 2.4104123219082996

Epoch: 6| Step: 7
Training loss: 3.1502722607375477
Validation loss: 2.415185052140933

Epoch: 6| Step: 8
Training loss: 2.40562232612269
Validation loss: 2.4168005171791997

Epoch: 6| Step: 9
Training loss: 2.0992115584244253
Validation loss: 2.407466481847943

Epoch: 6| Step: 10
Training loss: 2.272325801068943
Validation loss: 2.4165452290859233

Epoch: 6| Step: 11
Training loss: 2.614091915642316
Validation loss: 2.4241094966409653

Epoch: 6| Step: 12
Training loss: 2.3051986903284694
Validation loss: 2.42176757902416

Epoch: 6| Step: 13
Training loss: 2.1271165517018398
Validation loss: 2.4201756329683506

Epoch: 31| Step: 0
Training loss: 2.2142454816090127
Validation loss: 2.411962721429549

Epoch: 6| Step: 1
Training loss: 2.2339291427836354
Validation loss: 2.410230143942947

Epoch: 6| Step: 2
Training loss: 2.5797916458336485
Validation loss: 2.398854711240632

Epoch: 6| Step: 3
Training loss: 2.207764090340037
Validation loss: 2.41062852548848

Epoch: 6| Step: 4
Training loss: 3.5294419782878688
Validation loss: 2.4099690484661878

Epoch: 6| Step: 5
Training loss: 2.2523891691827824
Validation loss: 2.410641811431902

Epoch: 6| Step: 6
Training loss: 2.240683659380229
Validation loss: 2.412826254465007

Epoch: 6| Step: 7
Training loss: 2.4980718806777187
Validation loss: 2.4165149071058196

Epoch: 6| Step: 8
Training loss: 2.5328469595897665
Validation loss: 2.4190050573854642

Epoch: 6| Step: 9
Training loss: 2.1217698623160834
Validation loss: 2.4167449105410648

Epoch: 6| Step: 10
Training loss: 1.6970540607318279
Validation loss: 2.42598834461684

Epoch: 6| Step: 11
Training loss: 2.493046244890495
Validation loss: 2.4189579121078384

Epoch: 6| Step: 12
Training loss: 2.313268997587655
Validation loss: 2.414487626420124

Epoch: 6| Step: 13
Training loss: 2.416743299211956
Validation loss: 2.4219922109153655

Epoch: 32| Step: 0
Training loss: 3.0295219608309867
Validation loss: 2.4304805332291815

Epoch: 6| Step: 1
Training loss: 2.6811652821492817
Validation loss: 2.436474755666598

Epoch: 6| Step: 2
Training loss: 1.8290296745124701
Validation loss: 2.440330736409093

Epoch: 6| Step: 3
Training loss: 2.043393851229835
Validation loss: 2.442173544790366

Epoch: 6| Step: 4
Training loss: 1.9643129272557573
Validation loss: 2.43777113816605

Epoch: 6| Step: 5
Training loss: 2.3463889968663505
Validation loss: 2.4391974871840505

Epoch: 6| Step: 6
Training loss: 2.9395963614914296
Validation loss: 2.441581878448497

Epoch: 6| Step: 7
Training loss: 1.7537592293135527
Validation loss: 2.435406804996187

Epoch: 6| Step: 8
Training loss: 2.6632642696753535
Validation loss: 2.4293266347315767

Epoch: 6| Step: 9
Training loss: 2.0014117741767268
Validation loss: 2.4518696433929423

Epoch: 6| Step: 10
Training loss: 2.245306736269079
Validation loss: 2.4337433941971405

Epoch: 6| Step: 11
Training loss: 2.728883908210638
Validation loss: 2.4594951136597962

Epoch: 6| Step: 12
Training loss: 2.159865071709509
Validation loss: 2.4495457578466557

Epoch: 6| Step: 13
Training loss: 2.747996467393717
Validation loss: 2.436023966241754

Epoch: 33| Step: 0
Training loss: 2.187809404562504
Validation loss: 2.441069247574067

Epoch: 6| Step: 1
Training loss: 2.2130785169570455
Validation loss: 2.4154226099054896

Epoch: 6| Step: 2
Training loss: 2.2861313524530793
Validation loss: 2.416778016539613

Epoch: 6| Step: 3
Training loss: 2.3044686940955934
Validation loss: 2.408746613172002

Epoch: 6| Step: 4
Training loss: 2.2286611203600013
Validation loss: 2.4113884923281055

Epoch: 6| Step: 5
Training loss: 2.599312482312734
Validation loss: 2.414305805344125

Epoch: 6| Step: 6
Training loss: 2.831097973916664
Validation loss: 2.4079053725134902

Epoch: 6| Step: 7
Training loss: 2.33672541467857
Validation loss: 2.394297784954139

Epoch: 6| Step: 8
Training loss: 2.0616128342841455
Validation loss: 2.404393888035238

Epoch: 6| Step: 9
Training loss: 2.4779096242820517
Validation loss: 2.4037660270443593

Epoch: 6| Step: 10
Training loss: 2.7589814299635633
Validation loss: 2.403633759627735

Epoch: 6| Step: 11
Training loss: 2.6376483098135366
Validation loss: 2.3920307057375676

Epoch: 6| Step: 12
Training loss: 2.519125641103775
Validation loss: 2.42098743213079

Epoch: 6| Step: 13
Training loss: 2.069621881420774
Validation loss: 2.4173610172078717

Epoch: 34| Step: 0
Training loss: 2.620485874870908
Validation loss: 2.4101023861200215

Epoch: 6| Step: 1
Training loss: 1.937599794832592
Validation loss: 2.401749328017575

Epoch: 6| Step: 2
Training loss: 2.601526300218539
Validation loss: 2.412631057974357

Epoch: 6| Step: 3
Training loss: 2.693483832501102
Validation loss: 2.4225578247926953

Epoch: 6| Step: 4
Training loss: 2.1829616880667837
Validation loss: 2.433568841062769

Epoch: 6| Step: 5
Training loss: 2.0482842639025307
Validation loss: 2.4360094322038686

Epoch: 6| Step: 6
Training loss: 1.7022539063441207
Validation loss: 2.43492872790524

Epoch: 6| Step: 7
Training loss: 2.3563955327833623
Validation loss: 2.443526646747904

Epoch: 6| Step: 8
Training loss: 2.201426723996115
Validation loss: 2.455451024560228

Epoch: 6| Step: 9
Training loss: 2.895487227213925
Validation loss: 2.4502198983463255

Epoch: 6| Step: 10
Training loss: 2.6824065446172525
Validation loss: 2.447362103784191

Epoch: 6| Step: 11
Training loss: 2.4750818104179344
Validation loss: 2.4344431464826655

Epoch: 6| Step: 12
Training loss: 2.2997409301472804
Validation loss: 2.426641265710873

Epoch: 6| Step: 13
Training loss: 2.6231573085872077
Validation loss: 2.4237123308538395

Epoch: 35| Step: 0
Training loss: 2.8826097039738725
Validation loss: 2.4242169285827933

Epoch: 6| Step: 1
Training loss: 2.096389245792166
Validation loss: 2.4103456213615946

Epoch: 6| Step: 2
Training loss: 2.3689698411689246
Validation loss: 2.408435341105754

Epoch: 6| Step: 3
Training loss: 3.102018769572058
Validation loss: 2.4082193613858585

Epoch: 6| Step: 4
Training loss: 2.2627207063543215
Validation loss: 2.409431006295618

Epoch: 6| Step: 5
Training loss: 2.1201783623428887
Validation loss: 2.411031324069458

Epoch: 6| Step: 6
Training loss: 2.5757828679772463
Validation loss: 2.398467189012773

Epoch: 6| Step: 7
Training loss: 2.494820378934029
Validation loss: 2.401038400864328

Epoch: 6| Step: 8
Training loss: 2.2120677633546517
Validation loss: 2.404800606047029

Epoch: 6| Step: 9
Training loss: 2.2131472486763575
Validation loss: 2.414240973499535

Epoch: 6| Step: 10
Training loss: 2.1202196318740265
Validation loss: 2.4102492518027328

Epoch: 6| Step: 11
Training loss: 2.0933274938821844
Validation loss: 2.4165136820503625

Epoch: 6| Step: 12
Training loss: 3.058506132505417
Validation loss: 2.4005752297979064

Epoch: 6| Step: 13
Training loss: 1.8243558452315485
Validation loss: 2.3967065187447143

Epoch: 36| Step: 0
Training loss: 1.5900446884305028
Validation loss: 2.4180922222504093

Epoch: 6| Step: 1
Training loss: 3.1667118236601333
Validation loss: 2.4152935637994726

Epoch: 6| Step: 2
Training loss: 2.469146213848039
Validation loss: 2.425157754558146

Epoch: 6| Step: 3
Training loss: 3.0232630637462403
Validation loss: 2.4168670889079884

Epoch: 6| Step: 4
Training loss: 2.3123022458862437
Validation loss: 2.428493873008312

Epoch: 6| Step: 5
Training loss: 2.707025260973714
Validation loss: 2.4157125436597107

Epoch: 6| Step: 6
Training loss: 2.4726238519796953
Validation loss: 2.4319337558372265

Epoch: 6| Step: 7
Training loss: 1.8964890264892107
Validation loss: 2.4183995485037

Epoch: 6| Step: 8
Training loss: 2.309354859962448
Validation loss: 2.4205209453900287

Epoch: 6| Step: 9
Training loss: 1.8896650288959933
Validation loss: 2.4039721255429254

Epoch: 6| Step: 10
Training loss: 2.2205592555914317
Validation loss: 2.4212526321593764

Epoch: 6| Step: 11
Training loss: 2.536866444387433
Validation loss: 2.419821214981295

Epoch: 6| Step: 12
Training loss: 2.39288920968699
Validation loss: 2.4236725729867423

Epoch: 6| Step: 13
Training loss: 1.8369837600164594
Validation loss: 2.4193201761514285

Epoch: 37| Step: 0
Training loss: 2.730729119325519
Validation loss: 2.4395207400046597

Epoch: 6| Step: 1
Training loss: 2.6133250416734426
Validation loss: 2.4304389323154156

Epoch: 6| Step: 2
Training loss: 2.4604039173834904
Validation loss: 2.4385120540506344

Epoch: 6| Step: 3
Training loss: 2.1008772743327633
Validation loss: 2.4482714267440886

Epoch: 6| Step: 4
Training loss: 3.1899152095132997
Validation loss: 2.4376052768502015

Epoch: 6| Step: 5
Training loss: 2.228906087410724
Validation loss: 2.4346728435276446

Epoch: 6| Step: 6
Training loss: 2.5519645715185564
Validation loss: 2.4411997634034175

Epoch: 6| Step: 7
Training loss: 1.9769405561317814
Validation loss: 2.419615054134205

Epoch: 6| Step: 8
Training loss: 2.1927937349797086
Validation loss: 2.4303172400367297

Epoch: 6| Step: 9
Training loss: 2.377766453586284
Validation loss: 2.421398526154141

Epoch: 6| Step: 10
Training loss: 2.0974293733511717
Validation loss: 2.419586642826743

Epoch: 6| Step: 11
Training loss: 1.6677466787408974
Validation loss: 2.4151710343593757

Epoch: 6| Step: 12
Training loss: 2.4678383604687077
Validation loss: 2.4136535561520773

Epoch: 6| Step: 13
Training loss: 2.37605091735921
Validation loss: 2.4080792694541544

Epoch: 38| Step: 0
Training loss: 2.6762192416394606
Validation loss: 2.4117354418481036

Epoch: 6| Step: 1
Training loss: 2.22619261764606
Validation loss: 2.4081589528962466

Epoch: 6| Step: 2
Training loss: 2.3365026702506415
Validation loss: 2.406973395662943

Epoch: 6| Step: 3
Training loss: 2.119566309491645
Validation loss: 2.4042307650672727

Epoch: 6| Step: 4
Training loss: 2.3859422485064488
Validation loss: 2.4013180577093927

Epoch: 6| Step: 5
Training loss: 1.1450367615141495
Validation loss: 2.4068146905877277

Epoch: 6| Step: 6
Training loss: 1.7231805743033706
Validation loss: 2.408150438493979

Epoch: 6| Step: 7
Training loss: 2.941880227208483
Validation loss: 2.4100187438615825

Epoch: 6| Step: 8
Training loss: 2.0525453954176616
Validation loss: 2.4081045328064676

Epoch: 6| Step: 9
Training loss: 2.3010320089634595
Validation loss: 2.4063415344795342

Epoch: 6| Step: 10
Training loss: 2.6863729198338238
Validation loss: 2.3987303315867576

Epoch: 6| Step: 11
Training loss: 2.949273074830792
Validation loss: 2.404072093811423

Epoch: 6| Step: 12
Training loss: 2.607164005858163
Validation loss: 2.4212079431849185

Epoch: 6| Step: 13
Training loss: 2.487465813176618
Validation loss: 2.3987658397078038

Epoch: 39| Step: 0
Training loss: 2.39482416100765
Validation loss: 2.4024033949976307

Epoch: 6| Step: 1
Training loss: 2.5673852269744257
Validation loss: 2.4095030094615293

Epoch: 6| Step: 2
Training loss: 2.2238779046005006
Validation loss: 2.4205579560576593

Epoch: 6| Step: 3
Training loss: 2.4471391674106506
Validation loss: 2.4173445627762122

Epoch: 6| Step: 4
Training loss: 2.3622682528388603
Validation loss: 2.4248811010989293

Epoch: 6| Step: 5
Training loss: 1.9038375222218669
Validation loss: 2.426570139535381

Epoch: 6| Step: 6
Training loss: 1.654261709152504
Validation loss: 2.419213454788038

Epoch: 6| Step: 7
Training loss: 2.231852995444352
Validation loss: 2.434763717467015

Epoch: 6| Step: 8
Training loss: 1.8819546466596213
Validation loss: 2.4381141215008943

Epoch: 6| Step: 9
Training loss: 2.665472021330665
Validation loss: 2.451910378301925

Epoch: 6| Step: 10
Training loss: 2.3493604520249374
Validation loss: 2.4604778042098157

Epoch: 6| Step: 11
Training loss: 2.418760105476659
Validation loss: 2.462992945095278

Epoch: 6| Step: 12
Training loss: 3.2397701949579227
Validation loss: 2.4653125605271096

Epoch: 6| Step: 13
Training loss: 2.5904210800698624
Validation loss: 2.4488241718451196

Epoch: 40| Step: 0
Training loss: 2.0438834890464954
Validation loss: 2.4440261821343343

Epoch: 6| Step: 1
Training loss: 2.242709853305706
Validation loss: 2.435705110966535

Epoch: 6| Step: 2
Training loss: 1.696353715664838
Validation loss: 2.4291800800125465

Epoch: 6| Step: 3
Training loss: 2.4459948090555126
Validation loss: 2.423691804399356

Epoch: 6| Step: 4
Training loss: 2.451319424873064
Validation loss: 2.4111775728471567

Epoch: 6| Step: 5
Training loss: 2.4048055301326023
Validation loss: 2.4132164683507153

Epoch: 6| Step: 6
Training loss: 2.853685732972929
Validation loss: 2.41287643447383

Epoch: 6| Step: 7
Training loss: 1.9309276966167759
Validation loss: 2.4202387543015

Epoch: 6| Step: 8
Training loss: 2.8563005772626413
Validation loss: 2.4186080637973078

Epoch: 6| Step: 9
Training loss: 2.489356462896633
Validation loss: 2.4119512385167794

Epoch: 6| Step: 10
Training loss: 2.465257806353796
Validation loss: 2.422013883812883

Epoch: 6| Step: 11
Training loss: 2.6284472219223645
Validation loss: 2.4108069400373315

Epoch: 6| Step: 12
Training loss: 2.341804510745214
Validation loss: 2.410144717262576

Epoch: 6| Step: 13
Training loss: 1.8746754047444285
Validation loss: 2.4136469050153653

Epoch: 41| Step: 0
Training loss: 1.7776794787224848
Validation loss: 2.4040387715171487

Epoch: 6| Step: 1
Training loss: 1.87810754752024
Validation loss: 2.4032697014799553

Epoch: 6| Step: 2
Training loss: 2.573765253111674
Validation loss: 2.401741196241246

Epoch: 6| Step: 3
Training loss: 1.9533080968864858
Validation loss: 2.4052713476500553

Epoch: 6| Step: 4
Training loss: 2.96141801221415
Validation loss: 2.407574499647233

Epoch: 6| Step: 5
Training loss: 2.1412361553432677
Validation loss: 2.4031370595059776

Epoch: 6| Step: 6
Training loss: 2.825738817001309
Validation loss: 2.4147902526491505

Epoch: 6| Step: 7
Training loss: 2.2747626883009
Validation loss: 2.4074879719086124

Epoch: 6| Step: 8
Training loss: 2.2804068483456925
Validation loss: 2.4013505738335086

Epoch: 6| Step: 9
Training loss: 1.9861909261937003
Validation loss: 2.401533615676559

Epoch: 6| Step: 10
Training loss: 2.3759350190958126
Validation loss: 2.415836600000656

Epoch: 6| Step: 11
Training loss: 2.2481780622899876
Validation loss: 2.4173710607669547

Epoch: 6| Step: 12
Training loss: 2.3003259800983806
Validation loss: 2.44204775914232

Epoch: 6| Step: 13
Training loss: 3.1712044443986622
Validation loss: 2.43156552281764

Epoch: 42| Step: 0
Training loss: 2.082372927229088
Validation loss: 2.4369423057103923

Epoch: 6| Step: 1
Training loss: 2.6165344334455547
Validation loss: 2.4295081331010016

Epoch: 6| Step: 2
Training loss: 2.5250014427860785
Validation loss: 2.4439724956667166

Epoch: 6| Step: 3
Training loss: 2.5191265875374516
Validation loss: 2.457918622441367

Epoch: 6| Step: 4
Training loss: 2.0212337320082403
Validation loss: 2.450164490646926

Epoch: 6| Step: 5
Training loss: 1.6773183038040218
Validation loss: 2.451254202180795

Epoch: 6| Step: 6
Training loss: 2.423747464789038
Validation loss: 2.4594100975495463

Epoch: 6| Step: 7
Training loss: 1.6861589542634967
Validation loss: 2.448206918160852

Epoch: 6| Step: 8
Training loss: 2.994960525838457
Validation loss: 2.431697949981087

Epoch: 6| Step: 9
Training loss: 2.3737353923362203
Validation loss: 2.4315832251294

Epoch: 6| Step: 10
Training loss: 2.4885576654566353
Validation loss: 2.426973583266806

Epoch: 6| Step: 11
Training loss: 2.321590598184489
Validation loss: 2.415037960099029

Epoch: 6| Step: 12
Training loss: 2.5016954395012765
Validation loss: 2.405413577207027

Epoch: 6| Step: 13
Training loss: 2.44501471610604
Validation loss: 2.3974025701085213

Epoch: 43| Step: 0
Training loss: 2.9101867264553514
Validation loss: 2.406423521184443

Epoch: 6| Step: 1
Training loss: 2.395410472759901
Validation loss: 2.408978257290824

Epoch: 6| Step: 2
Training loss: 1.9791231719474611
Validation loss: 2.409612246986395

Epoch: 6| Step: 3
Training loss: 2.5086309220545733
Validation loss: 2.411141019724539

Epoch: 6| Step: 4
Training loss: 1.9556133440840109
Validation loss: 2.4259664451519805

Epoch: 6| Step: 5
Training loss: 2.4461081675881595
Validation loss: 2.4218775923520233

Epoch: 6| Step: 6
Training loss: 2.842642432194815
Validation loss: 2.4302924201459217

Epoch: 6| Step: 7
Training loss: 2.4387240148711435
Validation loss: 2.428626643549591

Epoch: 6| Step: 8
Training loss: 1.909224643812129
Validation loss: 2.4271016481769974

Epoch: 6| Step: 9
Training loss: 2.464500923315995
Validation loss: 2.4109478046875243

Epoch: 6| Step: 10
Training loss: 2.304194717742346
Validation loss: 2.4179075990338457

Epoch: 6| Step: 11
Training loss: 2.276236053708971
Validation loss: 2.405504994843596

Epoch: 6| Step: 12
Training loss: 1.740162172542912
Validation loss: 2.410606816165286

Epoch: 6| Step: 13
Training loss: 2.941173285875279
Validation loss: 2.397604251884829

Epoch: 44| Step: 0
Training loss: 2.3923451337448443
Validation loss: 2.4230140058579988

Epoch: 6| Step: 1
Training loss: 2.2385738374632957
Validation loss: 2.441893034153127

Epoch: 6| Step: 2
Training loss: 2.0560078023176174
Validation loss: 2.4365231602527815

Epoch: 6| Step: 3
Training loss: 2.423219467576805
Validation loss: 2.450647021837368

Epoch: 6| Step: 4
Training loss: 2.8526368508037394
Validation loss: 2.4830308312842133

Epoch: 6| Step: 5
Training loss: 2.304353748013505
Validation loss: 2.4783029467531232

Epoch: 6| Step: 6
Training loss: 2.08206846622607
Validation loss: 2.4797415641110194

Epoch: 6| Step: 7
Training loss: 2.747887753866435
Validation loss: 2.4897191051878984

Epoch: 6| Step: 8
Training loss: 2.0950595688829394
Validation loss: 2.496338133372798

Epoch: 6| Step: 9
Training loss: 2.1832234677731908
Validation loss: 2.4932181081904465

Epoch: 6| Step: 10
Training loss: 2.5447637314160363
Validation loss: 2.4854642291659523

Epoch: 6| Step: 11
Training loss: 2.256168704272234
Validation loss: 2.4840753402566857

Epoch: 6| Step: 12
Training loss: 2.653095301808994
Validation loss: 2.4605034823905614

Epoch: 6| Step: 13
Training loss: 2.0545465109140344
Validation loss: 2.4466188494022703

Epoch: 45| Step: 0
Training loss: 2.1089131167491426
Validation loss: 2.4473132641076014

Epoch: 6| Step: 1
Training loss: 2.31977832951942
Validation loss: 2.425981645399886

Epoch: 6| Step: 2
Training loss: 2.6650406728077765
Validation loss: 2.424157303951258

Epoch: 6| Step: 3
Training loss: 2.1772943300155405
Validation loss: 2.4166625505171173

Epoch: 6| Step: 4
Training loss: 2.737540020933199
Validation loss: 2.4102801142209573

Epoch: 6| Step: 5
Training loss: 1.8624733506926765
Validation loss: 2.4148473770244356

Epoch: 6| Step: 6
Training loss: 2.889464769266452
Validation loss: 2.3986768323544365

Epoch: 6| Step: 7
Training loss: 2.3579316429538446
Validation loss: 2.411525524897815

Epoch: 6| Step: 8
Training loss: 1.8347173653993214
Validation loss: 2.405253579722044

Epoch: 6| Step: 9
Training loss: 2.448128440840881
Validation loss: 2.393116137160312

Epoch: 6| Step: 10
Training loss: 2.3914996772269816
Validation loss: 2.4123950783902575

Epoch: 6| Step: 11
Training loss: 1.8772390983326976
Validation loss: 2.400216022014816

Epoch: 6| Step: 12
Training loss: 2.626965468140147
Validation loss: 2.415819765096483

Epoch: 6| Step: 13
Training loss: 2.3063617379430226
Validation loss: 2.4092696757700502

Epoch: 46| Step: 0
Training loss: 2.0925437527073667
Validation loss: 2.4110729219876386

Epoch: 6| Step: 1
Training loss: 2.091898426828541
Validation loss: 2.4041963706558844

Epoch: 6| Step: 2
Training loss: 2.9871222348969617
Validation loss: 2.415647922290319

Epoch: 6| Step: 3
Training loss: 2.734039286031918
Validation loss: 2.406303149210204

Epoch: 6| Step: 4
Training loss: 1.5550315897882132
Validation loss: 2.4084472367521434

Epoch: 6| Step: 5
Training loss: 1.8625891977751237
Validation loss: 2.4168111631888625

Epoch: 6| Step: 6
Training loss: 1.8982576512675258
Validation loss: 2.416061002099089

Epoch: 6| Step: 7
Training loss: 2.473764565893837
Validation loss: 2.4418485601936912

Epoch: 6| Step: 8
Training loss: 2.6623826981615033
Validation loss: 2.4190185847893804

Epoch: 6| Step: 9
Training loss: 2.3168924217093925
Validation loss: 2.4225262658394957

Epoch: 6| Step: 10
Training loss: 2.3606216471847468
Validation loss: 2.425325835186841

Epoch: 6| Step: 11
Training loss: 2.428370667822727
Validation loss: 2.429276459199141

Epoch: 6| Step: 12
Training loss: 2.1138410972487325
Validation loss: 2.4210468886350593

Epoch: 6| Step: 13
Training loss: 2.629760512700062
Validation loss: 2.4219864686314425

Epoch: 47| Step: 0
Training loss: 2.6679374726502103
Validation loss: 2.4154294124379074

Epoch: 6| Step: 1
Training loss: 2.562083978144681
Validation loss: 2.4104948872431096

Epoch: 6| Step: 2
Training loss: 2.3709986257561186
Validation loss: 2.420478590505153

Epoch: 6| Step: 3
Training loss: 2.782867132953942
Validation loss: 2.4193481717650185

Epoch: 6| Step: 4
Training loss: 2.474313382554419
Validation loss: 2.4122771623044006

Epoch: 6| Step: 5
Training loss: 2.4867116627785433
Validation loss: 2.413317947215707

Epoch: 6| Step: 6
Training loss: 1.9685793605908022
Validation loss: 2.405247813997067

Epoch: 6| Step: 7
Training loss: 2.3351806639348767
Validation loss: 2.401533764593008

Epoch: 6| Step: 8
Training loss: 1.7520061302034264
Validation loss: 2.4085192693280426

Epoch: 6| Step: 9
Training loss: 1.8917189656672864
Validation loss: 2.4091839923673284

Epoch: 6| Step: 10
Training loss: 2.148267260655798
Validation loss: 2.408374162567648

Epoch: 6| Step: 11
Training loss: 1.929209908755342
Validation loss: 2.407754865117888

Epoch: 6| Step: 12
Training loss: 2.281252299268426
Validation loss: 2.4091909856986207

Epoch: 6| Step: 13
Training loss: 2.7806908549053415
Validation loss: 2.4135619697051607

Epoch: 48| Step: 0
Training loss: 1.8045316026076048
Validation loss: 2.413617880162185

Epoch: 6| Step: 1
Training loss: 2.5752087369589893
Validation loss: 2.422374509757055

Epoch: 6| Step: 2
Training loss: 2.0838910182931945
Validation loss: 2.4454175217636136

Epoch: 6| Step: 3
Training loss: 1.7699413371736739
Validation loss: 2.456440072636519

Epoch: 6| Step: 4
Training loss: 2.8249230568459045
Validation loss: 2.466345086485734

Epoch: 6| Step: 5
Training loss: 2.512392893923297
Validation loss: 2.4822127171323713

Epoch: 6| Step: 6
Training loss: 2.0161490535357247
Validation loss: 2.4841530978670328

Epoch: 6| Step: 7
Training loss: 3.142134118824133
Validation loss: 2.502365963674786

Epoch: 6| Step: 8
Training loss: 2.812709546230303
Validation loss: 2.50360630914958

Epoch: 6| Step: 9
Training loss: 2.245943333108805
Validation loss: 2.500704610393661

Epoch: 6| Step: 10
Training loss: 1.2935262440487896
Validation loss: 2.489770049644303

Epoch: 6| Step: 11
Training loss: 2.004226748173285
Validation loss: 2.4794511605096603

Epoch: 6| Step: 12
Training loss: 2.869190316909284
Validation loss: 2.4634033605182792

Epoch: 6| Step: 13
Training loss: 2.0734781498434987
Validation loss: 2.4497150119151945

Epoch: 49| Step: 0
Training loss: 1.8983448147224191
Validation loss: 2.428624361093132

Epoch: 6| Step: 1
Training loss: 2.9537039698865613
Validation loss: 2.4162399693580343

Epoch: 6| Step: 2
Training loss: 2.0845950946962786
Validation loss: 2.408579512050969

Epoch: 6| Step: 3
Training loss: 2.610242870621033
Validation loss: 2.4042936687102063

Epoch: 6| Step: 4
Training loss: 2.4408380198105397
Validation loss: 2.409597759776427

Epoch: 6| Step: 5
Training loss: 2.537504968497387
Validation loss: 2.3986964215445252

Epoch: 6| Step: 6
Training loss: 2.4104822763686733
Validation loss: 2.393818071292226

Epoch: 6| Step: 7
Training loss: 1.8674524350728512
Validation loss: 2.401401787904576

Epoch: 6| Step: 8
Training loss: 2.565019253069209
Validation loss: 2.404533517132339

Epoch: 6| Step: 9
Training loss: 1.8497363392356005
Validation loss: 2.399476661843666

Epoch: 6| Step: 10
Training loss: 2.2165999404883814
Validation loss: 2.406928326004374

Epoch: 6| Step: 11
Training loss: 2.1383563640699137
Validation loss: 2.4021395712823077

Epoch: 6| Step: 12
Training loss: 2.7123346164052284
Validation loss: 2.409199496423469

Epoch: 6| Step: 13
Training loss: 1.8777146079870208
Validation loss: 2.4156840617800786

Epoch: 50| Step: 0
Training loss: 2.8743972146406938
Validation loss: 2.4142557373400058

Epoch: 6| Step: 1
Training loss: 2.7897532913895535
Validation loss: 2.4033419140368473

Epoch: 6| Step: 2
Training loss: 2.0967551912057223
Validation loss: 2.4236507919570562

Epoch: 6| Step: 3
Training loss: 1.955539827963893
Validation loss: 2.4060798683957616

Epoch: 6| Step: 4
Training loss: 1.8603759123242405
Validation loss: 2.404014060489753

Epoch: 6| Step: 5
Training loss: 1.8777613333760153
Validation loss: 2.4126384530667813

Epoch: 6| Step: 6
Training loss: 2.2587158085695145
Validation loss: 2.411842065741001

Epoch: 6| Step: 7
Training loss: 1.7533109542496648
Validation loss: 2.4181973334397253

Epoch: 6| Step: 8
Training loss: 2.230787264500586
Validation loss: 2.4176366657075365

Epoch: 6| Step: 9
Training loss: 2.2965900477938446
Validation loss: 2.423978699938876

Epoch: 6| Step: 10
Training loss: 2.1126167535965683
Validation loss: 2.4370925269298875

Epoch: 6| Step: 11
Training loss: 1.9862257969547792
Validation loss: 2.457645992322562

Epoch: 6| Step: 12
Training loss: 3.178896193958351
Validation loss: 2.4643026927892264

Epoch: 6| Step: 13
Training loss: 2.622366174241622
Validation loss: 2.481541327118085

Epoch: 51| Step: 0
Training loss: 2.276432542095939
Validation loss: 2.454036025136001

Epoch: 6| Step: 1
Training loss: 2.0666842931590526
Validation loss: 2.453632666667823

Epoch: 6| Step: 2
Training loss: 1.3759566793636393
Validation loss: 2.426039808400088

Epoch: 6| Step: 3
Training loss: 2.7651212416654753
Validation loss: 2.4163991242879344

Epoch: 6| Step: 4
Training loss: 2.156541003064952
Validation loss: 2.414051644343028

Epoch: 6| Step: 5
Training loss: 2.8643665208551607
Validation loss: 2.393714387925916

Epoch: 6| Step: 6
Training loss: 2.259817955314567
Validation loss: 2.4165769812505493

Epoch: 6| Step: 7
Training loss: 2.121746489688131
Validation loss: 2.395695538635533

Epoch: 6| Step: 8
Training loss: 2.0093176280325284
Validation loss: 2.415860951601213

Epoch: 6| Step: 9
Training loss: 2.9512355350719943
Validation loss: 2.408178737214729

Epoch: 6| Step: 10
Training loss: 1.8834549057243108
Validation loss: 2.4021190672634756

Epoch: 6| Step: 11
Training loss: 2.2874948386879317
Validation loss: 2.397732841367992

Epoch: 6| Step: 12
Training loss: 2.168314258433873
Validation loss: 2.412489855124007

Epoch: 6| Step: 13
Training loss: 2.8114745919905966
Validation loss: 2.438983107388033

Epoch: 52| Step: 0
Training loss: 2.5124396777147253
Validation loss: 2.4411951568896755

Epoch: 6| Step: 1
Training loss: 2.1225383188048506
Validation loss: 2.4287357490109676

Epoch: 6| Step: 2
Training loss: 2.261060549769267
Validation loss: 2.4124378552116483

Epoch: 6| Step: 3
Training loss: 2.3199768851213927
Validation loss: 2.420536565618839

Epoch: 6| Step: 4
Training loss: 2.891735956276145
Validation loss: 2.4224619082489647

Epoch: 6| Step: 5
Training loss: 1.9598681205056043
Validation loss: 2.4291851673326854

Epoch: 6| Step: 6
Training loss: 2.8730657954212147
Validation loss: 2.4302413979602986

Epoch: 6| Step: 7
Training loss: 2.8155320671909627
Validation loss: 2.4316332468434125

Epoch: 6| Step: 8
Training loss: 1.7241463304183517
Validation loss: 2.4210023928213817

Epoch: 6| Step: 9
Training loss: 2.286329701714923
Validation loss: 2.4131087113359024

Epoch: 6| Step: 10
Training loss: 2.25954004215181
Validation loss: 2.4098359342844606

Epoch: 6| Step: 11
Training loss: 1.9498551730635922
Validation loss: 2.4119179591781372

Epoch: 6| Step: 12
Training loss: 1.835687173862642
Validation loss: 2.411675978218386

Epoch: 6| Step: 13
Training loss: 1.9702987029086407
Validation loss: 2.412872943151563

Epoch: 53| Step: 0
Training loss: 2.2447158434837715
Validation loss: 2.404941318560053

Epoch: 6| Step: 1
Training loss: 1.9419299518826107
Validation loss: 2.4225012841104805

Epoch: 6| Step: 2
Training loss: 1.3611278851874646
Validation loss: 2.4446209385642397

Epoch: 6| Step: 3
Training loss: 2.1790499284546563
Validation loss: 2.4641171375345894

Epoch: 6| Step: 4
Training loss: 2.330698216976918
Validation loss: 2.4655527343603016

Epoch: 6| Step: 5
Training loss: 2.9797304771456536
Validation loss: 2.4671423139857382

Epoch: 6| Step: 6
Training loss: 2.0776481368113098
Validation loss: 2.4707662501457093

Epoch: 6| Step: 7
Training loss: 2.1937280550562814
Validation loss: 2.490258023018843

Epoch: 6| Step: 8
Training loss: 2.3109756807032302
Validation loss: 2.494817113779744

Epoch: 6| Step: 9
Training loss: 2.0330506779724162
Validation loss: 2.4770912464380133

Epoch: 6| Step: 10
Training loss: 3.1218395273142656
Validation loss: 2.488256098022777

Epoch: 6| Step: 11
Training loss: 2.378230257248894
Validation loss: 2.466789271770085

Epoch: 6| Step: 12
Training loss: 2.4862201484433912
Validation loss: 2.4542277665835903

Epoch: 6| Step: 13
Training loss: 2.1149706055242103
Validation loss: 2.4265625903933397

Epoch: 54| Step: 0
Training loss: 2.292318482612379
Validation loss: 2.3964006222259235

Epoch: 6| Step: 1
Training loss: 2.1798377856876465
Validation loss: 2.4099125092270692

Epoch: 6| Step: 2
Training loss: 2.6159329724138782
Validation loss: 2.4202090942936785

Epoch: 6| Step: 3
Training loss: 2.331378481190601
Validation loss: 2.398799525139457

Epoch: 6| Step: 4
Training loss: 2.2054459271008486
Validation loss: 2.396049727466759

Epoch: 6| Step: 5
Training loss: 2.115286674099529
Validation loss: 2.40879213545377

Epoch: 6| Step: 6
Training loss: 2.0147374291118334
Validation loss: 2.419210580349926

Epoch: 6| Step: 7
Training loss: 1.8666100027929926
Validation loss: 2.402323752219231

Epoch: 6| Step: 8
Training loss: 2.637091445014313
Validation loss: 2.4071938946450113

Epoch: 6| Step: 9
Training loss: 2.249660466324889
Validation loss: 2.410997652962722

Epoch: 6| Step: 10
Training loss: 2.1044007602312504
Validation loss: 2.424966082384899

Epoch: 6| Step: 11
Training loss: 2.4348643798972525
Validation loss: 2.430067206475088

Epoch: 6| Step: 12
Training loss: 2.6164268185298845
Validation loss: 2.436513301647359

Epoch: 6| Step: 13
Training loss: 2.3079062533851027
Validation loss: 2.424427344686534

Epoch: 55| Step: 0
Training loss: 2.460850499144185
Validation loss: 2.428936579578215

Epoch: 6| Step: 1
Training loss: 1.806027662063263
Validation loss: 2.4129696607910156

Epoch: 6| Step: 2
Training loss: 1.9969376722837606
Validation loss: 2.4251132112799216

Epoch: 6| Step: 3
Training loss: 2.222343221655113
Validation loss: 2.4120413869730566

Epoch: 6| Step: 4
Training loss: 2.9048138423240015
Validation loss: 2.420514206416259

Epoch: 6| Step: 5
Training loss: 2.6324987932077453
Validation loss: 2.413959834313798

Epoch: 6| Step: 6
Training loss: 1.763524046117183
Validation loss: 2.4203149262349015

Epoch: 6| Step: 7
Training loss: 3.1763825357612028
Validation loss: 2.429475781210306

Epoch: 6| Step: 8
Training loss: 1.8589232721484847
Validation loss: 2.4153314113481192

Epoch: 6| Step: 9
Training loss: 1.5362916586607445
Validation loss: 2.4185106926293183

Epoch: 6| Step: 10
Training loss: 2.177604418242637
Validation loss: 2.407915290488436

Epoch: 6| Step: 11
Training loss: 2.090969687929465
Validation loss: 2.414096375261666

Epoch: 6| Step: 12
Training loss: 2.3038683453866793
Validation loss: 2.41165795265562

Epoch: 6| Step: 13
Training loss: 2.266092396898621
Validation loss: 2.417809525826084

Epoch: 56| Step: 0
Training loss: 2.2005329440233186
Validation loss: 2.421617375279349

Epoch: 6| Step: 1
Training loss: 2.0753282356326226
Validation loss: 2.413813276707704

Epoch: 6| Step: 2
Training loss: 2.845193349908624
Validation loss: 2.4202454201596817

Epoch: 6| Step: 3
Training loss: 2.1237719858343884
Validation loss: 2.4009705296457717

Epoch: 6| Step: 4
Training loss: 2.0329042007909535
Validation loss: 2.4310700795366316

Epoch: 6| Step: 5
Training loss: 1.9813502530025433
Validation loss: 2.4011533025798313

Epoch: 6| Step: 6
Training loss: 2.692927801065998
Validation loss: 2.415237807299652

Epoch: 6| Step: 7
Training loss: 1.8445363065269795
Validation loss: 2.412640157722956

Epoch: 6| Step: 8
Training loss: 2.507247338235279
Validation loss: 2.414585307934809

Epoch: 6| Step: 9
Training loss: 2.162358463484552
Validation loss: 2.406202563524216

Epoch: 6| Step: 10
Training loss: 2.019771480475825
Validation loss: 2.4240575164931224

Epoch: 6| Step: 11
Training loss: 2.0153228769909175
Validation loss: 2.4386838825595634

Epoch: 6| Step: 12
Training loss: 2.3109649512135197
Validation loss: 2.4685823327280234

Epoch: 6| Step: 13
Training loss: 2.781046999262935
Validation loss: 2.4883366313622046

Epoch: 57| Step: 0
Training loss: 2.4886981129853627
Validation loss: 2.523536908501546

Epoch: 6| Step: 1
Training loss: 1.9893872495628258
Validation loss: 2.491523861593648

Epoch: 6| Step: 2
Training loss: 2.2159634136663917
Validation loss: 2.4836131913203277

Epoch: 6| Step: 3
Training loss: 1.5817886731704822
Validation loss: 2.476401001872145

Epoch: 6| Step: 4
Training loss: 2.086335447834579
Validation loss: 2.4546971395988435

Epoch: 6| Step: 5
Training loss: 2.1434465732985855
Validation loss: 2.47269700404968

Epoch: 6| Step: 6
Training loss: 2.486504559725783
Validation loss: 2.470452570618661

Epoch: 6| Step: 7
Training loss: 2.061026538143111
Validation loss: 2.4752838331650353

Epoch: 6| Step: 8
Training loss: 2.254981883413955
Validation loss: 2.4382001898191534

Epoch: 6| Step: 9
Training loss: 2.350238718934786
Validation loss: 2.439503245962498

Epoch: 6| Step: 10
Training loss: 2.1612890215517626
Validation loss: 2.429767930313563

Epoch: 6| Step: 11
Training loss: 3.0838081063067846
Validation loss: 2.4308588734844427

Epoch: 6| Step: 12
Training loss: 2.1087024888236012
Validation loss: 2.4255474180589003

Epoch: 6| Step: 13
Training loss: 2.376586885847573
Validation loss: 2.4254426090163963

Epoch: 58| Step: 0
Training loss: 2.3948451671843793
Validation loss: 2.4145788733040994

Epoch: 6| Step: 1
Training loss: 2.056905267539701
Validation loss: 2.4108226479290127

Epoch: 6| Step: 2
Training loss: 2.538040847641999
Validation loss: 2.4206436964948495

Epoch: 6| Step: 3
Training loss: 2.3401136545146994
Validation loss: 2.4041728430084106

Epoch: 6| Step: 4
Training loss: 2.5920867182918985
Validation loss: 2.4069061705734396

Epoch: 6| Step: 5
Training loss: 2.345247934407007
Validation loss: 2.420162801625936

Epoch: 6| Step: 6
Training loss: 2.3681143277638332
Validation loss: 2.403831653844677

Epoch: 6| Step: 7
Training loss: 3.053601005876239
Validation loss: 2.414427564027218

Epoch: 6| Step: 8
Training loss: 1.7525879253146937
Validation loss: 2.397593296849144

Epoch: 6| Step: 9
Training loss: 1.6834573712618068
Validation loss: 2.4146347602148936

Epoch: 6| Step: 10
Training loss: 1.845542359793289
Validation loss: 2.428377867713356

Epoch: 6| Step: 11
Training loss: 1.5304287635054417
Validation loss: 2.4232862155178085

Epoch: 6| Step: 12
Training loss: 2.3278456142659936
Validation loss: 2.4264038728414974

Epoch: 6| Step: 13
Training loss: 2.243033644887742
Validation loss: 2.4355806798559487

Epoch: 59| Step: 0
Training loss: 2.078121328709163
Validation loss: 2.451646314606083

Epoch: 6| Step: 1
Training loss: 2.100727808943964
Validation loss: 2.4654291166199966

Epoch: 6| Step: 2
Training loss: 2.522540804152048
Validation loss: 2.4674123125686456

Epoch: 6| Step: 3
Training loss: 2.0899670716023446
Validation loss: 2.470440675971921

Epoch: 6| Step: 4
Training loss: 2.439234581008256
Validation loss: 2.4934807334855735

Epoch: 6| Step: 5
Training loss: 2.543727966513096
Validation loss: 2.471817878870141

Epoch: 6| Step: 6
Training loss: 2.1693617735657083
Validation loss: 2.4849142772848527

Epoch: 6| Step: 7
Training loss: 2.381920319173349
Validation loss: 2.4783496525562168

Epoch: 6| Step: 8
Training loss: 2.924740615168399
Validation loss: 2.4801506419216452

Epoch: 6| Step: 9
Training loss: 1.5609329758159458
Validation loss: 2.4544078040272255

Epoch: 6| Step: 10
Training loss: 2.1709570831737834
Validation loss: 2.451271596149122

Epoch: 6| Step: 11
Training loss: 2.412999286276834
Validation loss: 2.4510858893035885

Epoch: 6| Step: 12
Training loss: 1.6392200085187238
Validation loss: 2.4381810891405475

Epoch: 6| Step: 13
Training loss: 1.7031982826075533
Validation loss: 2.4121173976914068

Epoch: 60| Step: 0
Training loss: 2.2503440381978677
Validation loss: 2.410941764150373

Epoch: 6| Step: 1
Training loss: 2.20142748210891
Validation loss: 2.417760524709624

Epoch: 6| Step: 2
Training loss: 2.1034572525921855
Validation loss: 2.4088354051563856

Epoch: 6| Step: 3
Training loss: 2.0298722509768057
Validation loss: 2.41150451571992

Epoch: 6| Step: 4
Training loss: 2.266602614376641
Validation loss: 2.4008015383603714

Epoch: 6| Step: 5
Training loss: 2.285817629317149
Validation loss: 2.4047402934425683

Epoch: 6| Step: 6
Training loss: 2.0462153878893723
Validation loss: 2.4121680207529956

Epoch: 6| Step: 7
Training loss: 1.9131313005086295
Validation loss: 2.4122984694932326

Epoch: 6| Step: 8
Training loss: 1.8853839709852462
Validation loss: 2.411557260767711

Epoch: 6| Step: 9
Training loss: 2.44337342621859
Validation loss: 2.4312021536805726

Epoch: 6| Step: 10
Training loss: 2.0764332245254327
Validation loss: 2.4366518484970516

Epoch: 6| Step: 11
Training loss: 2.864948281824951
Validation loss: 2.4425922249621355

Epoch: 6| Step: 12
Training loss: 2.3693072707775524
Validation loss: 2.4347158899301675

Epoch: 6| Step: 13
Training loss: 2.4020712100867527
Validation loss: 2.4446065775488615

Epoch: 61| Step: 0
Training loss: 2.2014030057639653
Validation loss: 2.412249825902097

Epoch: 6| Step: 1
Training loss: 1.9610262542943524
Validation loss: 2.423604007578158

Epoch: 6| Step: 2
Training loss: 1.8509742027558294
Validation loss: 2.4240866622320567

Epoch: 6| Step: 3
Training loss: 1.9933481463176417
Validation loss: 2.4332864158061294

Epoch: 6| Step: 4
Training loss: 2.2526162090236874
Validation loss: 2.4341909819732237

Epoch: 6| Step: 5
Training loss: 2.183313996712279
Validation loss: 2.4461262804238193

Epoch: 6| Step: 6
Training loss: 2.0765507981176587
Validation loss: 2.444453274344863

Epoch: 6| Step: 7
Training loss: 2.292323891001999
Validation loss: 2.459644353287259

Epoch: 6| Step: 8
Training loss: 2.61194707686596
Validation loss: 2.4650622964690005

Epoch: 6| Step: 9
Training loss: 1.3901552842899934
Validation loss: 2.46500037935472

Epoch: 6| Step: 10
Training loss: 2.299665455744271
Validation loss: 2.5018954085503085

Epoch: 6| Step: 11
Training loss: 2.5916141770455674
Validation loss: 2.4864105107077092

Epoch: 6| Step: 12
Training loss: 2.9543982289052533
Validation loss: 2.468749814898649

Epoch: 6| Step: 13
Training loss: 1.9637062010564061
Validation loss: 2.456870433111223

Epoch: 62| Step: 0
Training loss: 2.04082661168757
Validation loss: 2.4330811509222343

Epoch: 6| Step: 1
Training loss: 2.6657631555422423
Validation loss: 2.418164320818554

Epoch: 6| Step: 2
Training loss: 2.5384103729853624
Validation loss: 2.4207261344649593

Epoch: 6| Step: 3
Training loss: 2.122714665029971
Validation loss: 2.421612477174294

Epoch: 6| Step: 4
Training loss: 2.7035440991041337
Validation loss: 2.4254548390192774

Epoch: 6| Step: 5
Training loss: 1.9038849840005716
Validation loss: 2.429042587470211

Epoch: 6| Step: 6
Training loss: 1.9315103423305575
Validation loss: 2.426651410047898

Epoch: 6| Step: 7
Training loss: 2.4955314755129576
Validation loss: 2.4256614372899845

Epoch: 6| Step: 8
Training loss: 2.203845183707331
Validation loss: 2.4299719706306777

Epoch: 6| Step: 9
Training loss: 2.1050013658605207
Validation loss: 2.415015829704431

Epoch: 6| Step: 10
Training loss: 1.837764464050423
Validation loss: 2.420272124454235

Epoch: 6| Step: 11
Training loss: 2.324747080018269
Validation loss: 2.406161005265249

Epoch: 6| Step: 12
Training loss: 1.8687769935725163
Validation loss: 2.4096845745427906

Epoch: 6| Step: 13
Training loss: 2.1456469359194688
Validation loss: 2.4292688693951137

Epoch: 63| Step: 0
Training loss: 2.5794498622966198
Validation loss: 2.4381756131504817

Epoch: 6| Step: 1
Training loss: 1.3954451101750562
Validation loss: 2.4874463080357567

Epoch: 6| Step: 2
Training loss: 2.1357022226341966
Validation loss: 2.5567127098138505

Epoch: 6| Step: 3
Training loss: 1.6093699631102916
Validation loss: 2.5784905839133785

Epoch: 6| Step: 4
Training loss: 2.4166463215289435
Validation loss: 2.603610816125385

Epoch: 6| Step: 5
Training loss: 2.5016502655664112
Validation loss: 2.6103467064748216

Epoch: 6| Step: 6
Training loss: 1.864943556557873
Validation loss: 2.565839498755529

Epoch: 6| Step: 7
Training loss: 2.5612692319595696
Validation loss: 2.542085946525711

Epoch: 6| Step: 8
Training loss: 1.987926938727289
Validation loss: 2.5190390645791974

Epoch: 6| Step: 9
Training loss: 2.63572292031097
Validation loss: 2.4786784602293856

Epoch: 6| Step: 10
Training loss: 2.0545658902343464
Validation loss: 2.435203424020671

Epoch: 6| Step: 11
Training loss: 2.6897978606729014
Validation loss: 2.401985609035807

Epoch: 6| Step: 12
Training loss: 1.468029251191793
Validation loss: 2.4084744678268795

Epoch: 6| Step: 13
Training loss: 2.6543336126102295
Validation loss: 2.41273511422826

Epoch: 64| Step: 0
Training loss: 2.500270924193307
Validation loss: 2.414056788235093

Epoch: 6| Step: 1
Training loss: 2.2779092233872436
Validation loss: 2.417825196441438

Epoch: 6| Step: 2
Training loss: 2.380994860179341
Validation loss: 2.425042138602021

Epoch: 6| Step: 3
Training loss: 2.1120827708642116
Validation loss: 2.418097004239097

Epoch: 6| Step: 4
Training loss: 2.1502513649843795
Validation loss: 2.413018849766788

Epoch: 6| Step: 5
Training loss: 2.1527256566236086
Validation loss: 2.4065491461481385

Epoch: 6| Step: 6
Training loss: 1.4651002379616866
Validation loss: 2.4012692744235937

Epoch: 6| Step: 7
Training loss: 2.8671914913970857
Validation loss: 2.394727440617575

Epoch: 6| Step: 8
Training loss: 1.7740961271817954
Validation loss: 2.401959206008927

Epoch: 6| Step: 9
Training loss: 1.9673449028374717
Validation loss: 2.4133254389958676

Epoch: 6| Step: 10
Training loss: 1.889628376225875
Validation loss: 2.428074177423281

Epoch: 6| Step: 11
Training loss: 2.6007502207075275
Validation loss: 2.47186877430334

Epoch: 6| Step: 12
Training loss: 2.181029532147347
Validation loss: 2.4762855639688808

Epoch: 6| Step: 13
Training loss: 2.01944636566803
Validation loss: 2.456021763079723

Epoch: 65| Step: 0
Training loss: 2.2221434526258315
Validation loss: 2.4707302891138885

Epoch: 6| Step: 1
Training loss: 2.2140112763955915
Validation loss: 2.474201717785838

Epoch: 6| Step: 2
Training loss: 2.841461937950994
Validation loss: 2.525025284517805

Epoch: 6| Step: 3
Training loss: 2.008489709783608
Validation loss: 2.5306089397940505

Epoch: 6| Step: 4
Training loss: 2.051596982481655
Validation loss: 2.4869543317317064

Epoch: 6| Step: 5
Training loss: 2.024966571673232
Validation loss: 2.492864694140179

Epoch: 6| Step: 6
Training loss: 2.7796467649960626
Validation loss: 2.463165824453088

Epoch: 6| Step: 7
Training loss: 1.8082210412150452
Validation loss: 2.398427725077207

Epoch: 6| Step: 8
Training loss: 2.121397892343433
Validation loss: 2.417871032613771

Epoch: 6| Step: 9
Training loss: 1.857080919679142
Validation loss: 2.3939509142297415

Epoch: 6| Step: 10
Training loss: 2.356939005603508
Validation loss: 2.411867627424782

Epoch: 6| Step: 11
Training loss: 1.881874578976972
Validation loss: 2.4108914779453605

Epoch: 6| Step: 12
Training loss: 2.4856723301107535
Validation loss: 2.408127634268299

Epoch: 6| Step: 13
Training loss: 2.0374700532362366
Validation loss: 2.416811076870054

Epoch: 66| Step: 0
Training loss: 2.2334740162660163
Validation loss: 2.394344436634987

Epoch: 6| Step: 1
Training loss: 1.9300271171680854
Validation loss: 2.3974675340943703

Epoch: 6| Step: 2
Training loss: 1.9274099399688365
Validation loss: 2.412992295748904

Epoch: 6| Step: 3
Training loss: 2.2396506602495077
Validation loss: 2.4149414980655917

Epoch: 6| Step: 4
Training loss: 2.7286370809470144
Validation loss: 2.448073708116464

Epoch: 6| Step: 5
Training loss: 2.9271517346264875
Validation loss: 2.452674832517187

Epoch: 6| Step: 6
Training loss: 2.2697816799224806
Validation loss: 2.4635100466827433

Epoch: 6| Step: 7
Training loss: 2.026043248768428
Validation loss: 2.4676048101435897

Epoch: 6| Step: 8
Training loss: 2.3672094564395305
Validation loss: 2.466735524964846

Epoch: 6| Step: 9
Training loss: 2.0881572442532423
Validation loss: 2.4624527237641494

Epoch: 6| Step: 10
Training loss: 2.175416542593409
Validation loss: 2.4327204950469725

Epoch: 6| Step: 11
Training loss: 1.8200513791597677
Validation loss: 2.419850091534047

Epoch: 6| Step: 12
Training loss: 2.1252445753383027
Validation loss: 2.4172899138625557

Epoch: 6| Step: 13
Training loss: 1.3343093051864112
Validation loss: 2.417373616854299

Epoch: 67| Step: 0
Training loss: 2.10773421156993
Validation loss: 2.4142736118354042

Epoch: 6| Step: 1
Training loss: 1.7038154252519302
Validation loss: 2.412982538617757

Epoch: 6| Step: 2
Training loss: 2.08311288303041
Validation loss: 2.4330355196344873

Epoch: 6| Step: 3
Training loss: 2.5120116637013803
Validation loss: 2.4533070944163824

Epoch: 6| Step: 4
Training loss: 2.3830026019198627
Validation loss: 2.4364295222772667

Epoch: 6| Step: 5
Training loss: 2.1129466019259295
Validation loss: 2.4433882742356112

Epoch: 6| Step: 6
Training loss: 1.8437291160305926
Validation loss: 2.4405169441506613

Epoch: 6| Step: 7
Training loss: 2.0871583030772944
Validation loss: 2.441306703699708

Epoch: 6| Step: 8
Training loss: 2.09534097832792
Validation loss: 2.4332075715770745

Epoch: 6| Step: 9
Training loss: 2.8074909958053866
Validation loss: 2.4599526266250664

Epoch: 6| Step: 10
Training loss: 1.979582398235807
Validation loss: 2.41568593700512

Epoch: 6| Step: 11
Training loss: 2.14716026487637
Validation loss: 2.430374637107153

Epoch: 6| Step: 12
Training loss: 2.054595132934545
Validation loss: 2.4214210330895627

Epoch: 6| Step: 13
Training loss: 1.993033016518967
Validation loss: 2.391393766440196

Epoch: 68| Step: 0
Training loss: 1.7667626960614535
Validation loss: 2.3990604283390673

Epoch: 6| Step: 1
Training loss: 1.9663135044442963
Validation loss: 2.4010723026552587

Epoch: 6| Step: 2
Training loss: 2.0737428280808112
Validation loss: 2.41601055106697

Epoch: 6| Step: 3
Training loss: 1.6652208335302612
Validation loss: 2.406279328402841

Epoch: 6| Step: 4
Training loss: 1.869256250199341
Validation loss: 2.425147980831829

Epoch: 6| Step: 5
Training loss: 2.2283803913832063
Validation loss: 2.4347921638382726

Epoch: 6| Step: 6
Training loss: 2.289428369231721
Validation loss: 2.4461584933239418

Epoch: 6| Step: 7
Training loss: 2.1928421185077736
Validation loss: 2.43796952118988

Epoch: 6| Step: 8
Training loss: 1.9231948662316452
Validation loss: 2.4415572869947333

Epoch: 6| Step: 9
Training loss: 2.2050411467919164
Validation loss: 2.4333422568127125

Epoch: 6| Step: 10
Training loss: 2.033560744320731
Validation loss: 2.4679911771139493

Epoch: 6| Step: 11
Training loss: 2.0628505755630555
Validation loss: 2.451676242605664

Epoch: 6| Step: 12
Training loss: 2.1822641108433913
Validation loss: 2.460848020511267

Epoch: 6| Step: 13
Training loss: 2.7795849219914133
Validation loss: 2.4746196117354984

Epoch: 69| Step: 0
Training loss: 2.0507888067197086
Validation loss: 2.45154734619592

Epoch: 6| Step: 1
Training loss: 2.38644652367185
Validation loss: 2.4385087379427812

Epoch: 6| Step: 2
Training loss: 2.1377492926601667
Validation loss: 2.3912667470672266

Epoch: 6| Step: 3
Training loss: 1.5164375093629332
Validation loss: 2.4067439113207207

Epoch: 6| Step: 4
Training loss: 1.9144031455087864
Validation loss: 2.4383451838627996

Epoch: 6| Step: 5
Training loss: 1.9298527449925673
Validation loss: 2.3982731434592726

Epoch: 6| Step: 6
Training loss: 2.031266315101245
Validation loss: 2.4229906855325574

Epoch: 6| Step: 7
Training loss: 2.0124279364721134
Validation loss: 2.4177909296782887

Epoch: 6| Step: 8
Training loss: 2.1012337012626126
Validation loss: 2.419095279714786

Epoch: 6| Step: 9
Training loss: 2.466956344125449
Validation loss: 2.418685363181878

Epoch: 6| Step: 10
Training loss: 2.4755114903438566
Validation loss: 2.441263944420329

Epoch: 6| Step: 11
Training loss: 2.1411521986379047
Validation loss: 2.433727728113672

Epoch: 6| Step: 12
Training loss: 2.2881217820229054
Validation loss: 2.4686876924917214

Epoch: 6| Step: 13
Training loss: 1.6814069596661219
Validation loss: 2.4517059271249413

Epoch: 70| Step: 0
Training loss: 1.9628745918188477
Validation loss: 2.4601834872803354

Epoch: 6| Step: 1
Training loss: 1.5504933433500536
Validation loss: 2.457264002220722

Epoch: 6| Step: 2
Training loss: 2.1391418219405183
Validation loss: 2.446886865969517

Epoch: 6| Step: 3
Training loss: 1.8661125632267772
Validation loss: 2.429322210166387

Epoch: 6| Step: 4
Training loss: 2.586289949398957
Validation loss: 2.460913780138457

Epoch: 6| Step: 5
Training loss: 2.0078333990887027
Validation loss: 2.422756617063275

Epoch: 6| Step: 6
Training loss: 1.9127185073391932
Validation loss: 2.4288235075738416

Epoch: 6| Step: 7
Training loss: 1.9168357221710512
Validation loss: 2.431073234166377

Epoch: 6| Step: 8
Training loss: 2.4192922294883266
Validation loss: 2.440207738045513

Epoch: 6| Step: 9
Training loss: 2.106446104796733
Validation loss: 2.416686310085396

Epoch: 6| Step: 10
Training loss: 1.7200255082700755
Validation loss: 2.420711524993536

Epoch: 6| Step: 11
Training loss: 1.8683200737139254
Validation loss: 2.4088855198374826

Epoch: 6| Step: 12
Training loss: 2.353978433651203
Validation loss: 2.4286501551805153

Epoch: 6| Step: 13
Training loss: 2.1521264051304394
Validation loss: 2.4360217804323936

Epoch: 71| Step: 0
Training loss: 1.9211096751703696
Validation loss: 2.423469527176615

Epoch: 6| Step: 1
Training loss: 1.7246838183120936
Validation loss: 2.4116321992640968

Epoch: 6| Step: 2
Training loss: 1.7194756796565336
Validation loss: 2.4496019987314526

Epoch: 6| Step: 3
Training loss: 2.029064234890439
Validation loss: 2.466414896470869

Epoch: 6| Step: 4
Training loss: 2.075450581726171
Validation loss: 2.4976681960870932

Epoch: 6| Step: 5
Training loss: 2.701868195058604
Validation loss: 2.484873611669592

Epoch: 6| Step: 6
Training loss: 2.3270916789789453
Validation loss: 2.5019938068323406

Epoch: 6| Step: 7
Training loss: 2.3431334638302808
Validation loss: 2.4834377512218273

Epoch: 6| Step: 8
Training loss: 1.6573949491141944
Validation loss: 2.5060323574730363

Epoch: 6| Step: 9
Training loss: 2.37467562819469
Validation loss: 2.4468931344417086

Epoch: 6| Step: 10
Training loss: 1.71484472322545
Validation loss: 2.444479706057139

Epoch: 6| Step: 11
Training loss: 1.877330920635555
Validation loss: 2.44927277573862

Epoch: 6| Step: 12
Training loss: 1.452741264620284
Validation loss: 2.472313606582961

Epoch: 6| Step: 13
Training loss: 2.3967677961544087
Validation loss: 2.4019110478609416

Epoch: 72| Step: 0
Training loss: 1.620095113152058
Validation loss: 2.404388541677716

Epoch: 6| Step: 1
Training loss: 1.8792449582433062
Validation loss: 2.4025470099743984

Epoch: 6| Step: 2
Training loss: 2.316939963085255
Validation loss: 2.433016313081368

Epoch: 6| Step: 3
Training loss: 2.061981251532405
Validation loss: 2.422108005266996

Epoch: 6| Step: 4
Training loss: 2.1460976916187753
Validation loss: 2.4152832483682167

Epoch: 6| Step: 5
Training loss: 1.8398070767062211
Validation loss: 2.4242925493565375

Epoch: 6| Step: 6
Training loss: 1.8051961867211248
Validation loss: 2.4104921754985535

Epoch: 6| Step: 7
Training loss: 2.111013948424286
Validation loss: 2.3824458022489376

Epoch: 6| Step: 8
Training loss: 2.413412160833006
Validation loss: 2.410493502522866

Epoch: 6| Step: 9
Training loss: 1.7536164110111918
Validation loss: 2.437217989526768

Epoch: 6| Step: 10
Training loss: 2.145973373830954
Validation loss: 2.447346330039086

Epoch: 6| Step: 11
Training loss: 2.3365651183797977
Validation loss: 2.483155052988314

Epoch: 6| Step: 12
Training loss: 1.7726227489414372
Validation loss: 2.4631214684066873

Epoch: 6| Step: 13
Training loss: 2.1581252416306222
Validation loss: 2.4760253195302577

Epoch: 73| Step: 0
Training loss: 2.1688626482727655
Validation loss: 2.4941691270283566

Epoch: 6| Step: 1
Training loss: 2.1488880031934086
Validation loss: 2.495564037902848

Epoch: 6| Step: 2
Training loss: 1.7269525562036074
Validation loss: 2.546482602024373

Epoch: 6| Step: 3
Training loss: 1.2267657069119398
Validation loss: 2.5388081584600393

Epoch: 6| Step: 4
Training loss: 2.3968922362024903
Validation loss: 2.534506919867448

Epoch: 6| Step: 5
Training loss: 1.6124627574789416
Validation loss: 2.4887750875146435

Epoch: 6| Step: 6
Training loss: 2.4429901112353587
Validation loss: 2.4532697274507798

Epoch: 6| Step: 7
Training loss: 1.9786047355264345
Validation loss: 2.414011340540533

Epoch: 6| Step: 8
Training loss: 2.5360304349462917
Validation loss: 2.4217086570794093

Epoch: 6| Step: 9
Training loss: 1.8212101241690186
Validation loss: 2.401653829611312

Epoch: 6| Step: 10
Training loss: 1.9292519884898818
Validation loss: 2.401806861823507

Epoch: 6| Step: 11
Training loss: 2.249186686704318
Validation loss: 2.3912959601263974

Epoch: 6| Step: 12
Training loss: 1.7247131938509954
Validation loss: 2.412299013083528

Epoch: 6| Step: 13
Training loss: 2.1024653540987415
Validation loss: 2.438956632399841

Epoch: 74| Step: 0
Training loss: 2.4067548742358875
Validation loss: 2.4326416243085465

Epoch: 6| Step: 1
Training loss: 1.4051256983585352
Validation loss: 2.426032106100342

Epoch: 6| Step: 2
Training loss: 1.9590768687660969
Validation loss: 2.4382377551370507

Epoch: 6| Step: 3
Training loss: 1.7410505887415715
Validation loss: 2.4414143798692765

Epoch: 6| Step: 4
Training loss: 1.868713266273189
Validation loss: 2.4605875725193243

Epoch: 6| Step: 5
Training loss: 2.0077728386312557
Validation loss: 2.496508162457817

Epoch: 6| Step: 6
Training loss: 2.0715015379734023
Validation loss: 2.511699053507652

Epoch: 6| Step: 7
Training loss: 2.0795313156716073
Validation loss: 2.488222401959593

Epoch: 6| Step: 8
Training loss: 2.0673018535606627
Validation loss: 2.47132423846363

Epoch: 6| Step: 9
Training loss: 2.126883849810209
Validation loss: 2.432353634967258

Epoch: 6| Step: 10
Training loss: 1.2254755342765817
Validation loss: 2.4134935286694432

Epoch: 6| Step: 11
Training loss: 2.6707365945881145
Validation loss: 2.4228590740029503

Epoch: 6| Step: 12
Training loss: 2.260046991686803
Validation loss: 2.4170008022784186

Epoch: 6| Step: 13
Training loss: 1.9329742980684994
Validation loss: 2.4254445668039906

Epoch: 75| Step: 0
Training loss: 1.9342318628256339
Validation loss: 2.380830325960479

Epoch: 6| Step: 1
Training loss: 2.0215950018793416
Validation loss: 2.410371446199057

Epoch: 6| Step: 2
Training loss: 1.787801573062678
Validation loss: 2.4056967805305476

Epoch: 6| Step: 3
Training loss: 2.091495267778333
Validation loss: 2.442556060621406

Epoch: 6| Step: 4
Training loss: 2.0712252925856434
Validation loss: 2.468493130354002

Epoch: 6| Step: 5
Training loss: 2.0503965180411003
Validation loss: 2.4974404106630095

Epoch: 6| Step: 6
Training loss: 2.1441077420435213
Validation loss: 2.49335150406926

Epoch: 6| Step: 7
Training loss: 2.06004534217784
Validation loss: 2.4763984104353085

Epoch: 6| Step: 8
Training loss: 2.03286385614263
Validation loss: 2.4562298671165856

Epoch: 6| Step: 9
Training loss: 1.4807152052292811
Validation loss: 2.4556032204448988

Epoch: 6| Step: 10
Training loss: 1.595689528371158
Validation loss: 2.4240034205482863

Epoch: 6| Step: 11
Training loss: 1.7871072404358836
Validation loss: 2.4577059888223585

Epoch: 6| Step: 12
Training loss: 2.5991263682462216
Validation loss: 2.444304383364176

Epoch: 6| Step: 13
Training loss: 2.0158899414053773
Validation loss: 2.406845101753843

Epoch: 76| Step: 0
Training loss: 1.8979806232528524
Validation loss: 2.4429018286962996

Epoch: 6| Step: 1
Training loss: 2.283770905865138
Validation loss: 2.415338502042194

Epoch: 6| Step: 2
Training loss: 1.3639528210778482
Validation loss: 2.405479274692454

Epoch: 6| Step: 3
Training loss: 1.5599547445628763
Validation loss: 2.42025584578776

Epoch: 6| Step: 4
Training loss: 2.667848464242604
Validation loss: 2.4301696168181226

Epoch: 6| Step: 5
Training loss: 1.6591047479995333
Validation loss: 2.4479256704178387

Epoch: 6| Step: 6
Training loss: 1.8498826917623346
Validation loss: 2.449005393470276

Epoch: 6| Step: 7
Training loss: 1.9495363148792169
Validation loss: 2.417923885292831

Epoch: 6| Step: 8
Training loss: 1.8366522513699097
Validation loss: 2.4068294999820927

Epoch: 6| Step: 9
Training loss: 1.7237804662987228
Validation loss: 2.4284400640616575

Epoch: 6| Step: 10
Training loss: 1.838596188292447
Validation loss: 2.447595467022254

Epoch: 6| Step: 11
Training loss: 2.297119335231718
Validation loss: 2.4331739460552098

Epoch: 6| Step: 12
Training loss: 1.846359475311553
Validation loss: 2.4370385409712

Epoch: 6| Step: 13
Training loss: 2.01149142564221
Validation loss: 2.5408594981224994

Epoch: 77| Step: 0
Training loss: 1.9980673989354003
Validation loss: 2.6121515817428334

Epoch: 6| Step: 1
Training loss: 1.5677757459913162
Validation loss: 2.6518459836157704

Epoch: 6| Step: 2
Training loss: 1.3292378867908392
Validation loss: 2.7418460832654583

Epoch: 6| Step: 3
Training loss: 2.170611336377012
Validation loss: 2.766369864809768

Epoch: 6| Step: 4
Training loss: 2.0532934296846688
Validation loss: 2.7429752069822992

Epoch: 6| Step: 5
Training loss: 2.7104942113254746
Validation loss: 2.6677803505487874

Epoch: 6| Step: 6
Training loss: 1.2412859926258721
Validation loss: 2.538643200805279

Epoch: 6| Step: 7
Training loss: 1.6541113090700936
Validation loss: 2.4583861350730616

Epoch: 6| Step: 8
Training loss: 2.2276409548978013
Validation loss: 2.4292370214028884

Epoch: 6| Step: 9
Training loss: 1.858370084641506
Validation loss: 2.43210480739395

Epoch: 6| Step: 10
Training loss: 2.2594048715729866
Validation loss: 2.4159956170304437

Epoch: 6| Step: 11
Training loss: 1.6429080155593347
Validation loss: 2.420019214017901

Epoch: 6| Step: 12
Training loss: 1.8363401580137155
Validation loss: 2.454755577278166

Epoch: 6| Step: 13
Training loss: 1.769743378242211
Validation loss: 2.500924344841505

Epoch: 78| Step: 0
Training loss: 2.0849014738300258
Validation loss: 2.483282700818259

Epoch: 6| Step: 1
Training loss: 1.7251361461484143
Validation loss: 2.491376818721029

Epoch: 6| Step: 2
Training loss: 2.0362716810408155
Validation loss: 2.4492460874971624

Epoch: 6| Step: 3
Training loss: 1.9200445622994848
Validation loss: 2.40618805578518

Epoch: 6| Step: 4
Training loss: 2.9606002575301678
Validation loss: 2.3972008879404614

Epoch: 6| Step: 5
Training loss: 1.3120699132429048
Validation loss: 2.406932354242633

Epoch: 6| Step: 6
Training loss: 1.6376653951734041
Validation loss: 2.413804288385657

Epoch: 6| Step: 7
Training loss: 1.9947504050931748
Validation loss: 2.472196563368477

Epoch: 6| Step: 8
Training loss: 1.6016348473560185
Validation loss: 2.487218321374288

Epoch: 6| Step: 9
Training loss: 2.0902411822737688
Validation loss: 2.51449185078306

Epoch: 6| Step: 10
Training loss: 2.2553531755857565
Validation loss: 2.5214043488079376

Epoch: 6| Step: 11
Training loss: 1.9110709966409596
Validation loss: 2.5291844327031368

Epoch: 6| Step: 12
Training loss: 1.7420778796002576
Validation loss: 2.442572272008149

Epoch: 6| Step: 13
Training loss: 1.3944505940682088
Validation loss: 2.4894595388069174

Epoch: 79| Step: 0
Training loss: 1.5539519904046797
Validation loss: 2.4713459289434927

Epoch: 6| Step: 1
Training loss: 1.7575797371933866
Validation loss: 2.4890731916658955

Epoch: 6| Step: 2
Training loss: 1.6396029240537704
Validation loss: 2.445529688410878

Epoch: 6| Step: 3
Training loss: 1.5904744464844582
Validation loss: 2.4577556082124414

Epoch: 6| Step: 4
Training loss: 2.160802154826079
Validation loss: 2.429430949086429

Epoch: 6| Step: 5
Training loss: 2.8967464480224807
Validation loss: 2.4521246974398

Epoch: 6| Step: 6
Training loss: 1.4172409333541134
Validation loss: 2.4393460219943655

Epoch: 6| Step: 7
Training loss: 1.514529589399543
Validation loss: 2.4285265406833223

Epoch: 6| Step: 8
Training loss: 2.402133839438274
Validation loss: 2.4301681288494645

Epoch: 6| Step: 9
Training loss: 1.6772518507679581
Validation loss: 2.443379061320011

Epoch: 6| Step: 10
Training loss: 1.2581805525907164
Validation loss: 2.4179937128227706

Epoch: 6| Step: 11
Training loss: 2.3128039186109968
Validation loss: 2.4180148463870155

Epoch: 6| Step: 12
Training loss: 2.2117148606492867
Validation loss: 2.4227227398801072

Epoch: 6| Step: 13
Training loss: 1.4248289507551115
Validation loss: 2.4401451576939786

Epoch: 80| Step: 0
Training loss: 1.792385430285764
Validation loss: 2.4476941974814084

Epoch: 6| Step: 1
Training loss: 2.236701660943712
Validation loss: 2.5133315031043284

Epoch: 6| Step: 2
Training loss: 2.766116599664272
Validation loss: 2.6613917830794485

Epoch: 6| Step: 3
Training loss: 1.5785754476840066
Validation loss: 2.697604862198364

Epoch: 6| Step: 4
Training loss: 2.163836746284038
Validation loss: 2.7230764581969193

Epoch: 6| Step: 5
Training loss: 1.5841907221001004
Validation loss: 2.7326413644286376

Epoch: 6| Step: 6
Training loss: 1.7006418867580115
Validation loss: 2.561252755665821

Epoch: 6| Step: 7
Training loss: 2.124229291389576
Validation loss: 2.503518037263634

Epoch: 6| Step: 8
Training loss: 1.4645146114601164
Validation loss: 2.455652785234228

Epoch: 6| Step: 9
Training loss: 1.8884684976864587
Validation loss: 2.3915618025046266

Epoch: 6| Step: 10
Training loss: 1.7118171277105345
Validation loss: 2.3991204696594215

Epoch: 6| Step: 11
Training loss: 1.8356389878454096
Validation loss: 2.410069946854232

Epoch: 6| Step: 12
Training loss: 1.7626194311489138
Validation loss: 2.4471207860255104

Epoch: 6| Step: 13
Training loss: 1.7199042865825072
Validation loss: 2.4404280266788567

Epoch: 81| Step: 0
Training loss: 1.6757798272684812
Validation loss: 2.4799505858984627

Epoch: 6| Step: 1
Training loss: 2.4411474472202257
Validation loss: 2.466995356113788

Epoch: 6| Step: 2
Training loss: 1.7264538208601885
Validation loss: 2.466304662491505

Epoch: 6| Step: 3
Training loss: 1.6065187014249023
Validation loss: 2.420093685246708

Epoch: 6| Step: 4
Training loss: 1.9645623371489613
Validation loss: 2.4018166560825214

Epoch: 6| Step: 5
Training loss: 2.4584803348706696
Validation loss: 2.3646881707655445

Epoch: 6| Step: 6
Training loss: 1.9064697389119405
Validation loss: 2.461477416216514

Epoch: 6| Step: 7
Training loss: 1.7223891139776548
Validation loss: 2.5028684531451075

Epoch: 6| Step: 8
Training loss: 1.6810242058113505
Validation loss: 2.5535579287883197

Epoch: 6| Step: 9
Training loss: 1.673562170063201
Validation loss: 2.624014442351767

Epoch: 6| Step: 10
Training loss: 2.014418603210356
Validation loss: 2.674180937535085

Epoch: 6| Step: 11
Training loss: 2.001262743002108
Validation loss: 2.6526147837825538

Epoch: 6| Step: 12
Training loss: 1.9977470463843214
Validation loss: 2.551397664869463

Epoch: 6| Step: 13
Training loss: 1.6078824279229236
Validation loss: 2.5058352319828407

Epoch: 82| Step: 0
Training loss: 1.822044040172801
Validation loss: 2.4394528969529685

Epoch: 6| Step: 1
Training loss: 1.6428068639039233
Validation loss: 2.410796407616125

Epoch: 6| Step: 2
Training loss: 1.862646158615205
Validation loss: 2.4315148255925596

Epoch: 6| Step: 3
Training loss: 1.8913928907916082
Validation loss: 2.4423397954736688

Epoch: 6| Step: 4
Training loss: 1.7740353152255337
Validation loss: 2.4470647154526923

Epoch: 6| Step: 5
Training loss: 2.586227631211745
Validation loss: 2.4268048308107546

Epoch: 6| Step: 6
Training loss: 1.7044806028802713
Validation loss: 2.4162431104587796

Epoch: 6| Step: 7
Training loss: 1.7915723761062248
Validation loss: 2.4183219031395278

Epoch: 6| Step: 8
Training loss: 1.7977737169543409
Validation loss: 2.40390522977179

Epoch: 6| Step: 9
Training loss: 1.5771624963092434
Validation loss: 2.3853328112615344

Epoch: 6| Step: 10
Training loss: 2.0028635029898783
Validation loss: 2.4416196195824065

Epoch: 6| Step: 11
Training loss: 2.1590596566379614
Validation loss: 2.4977487918628243

Epoch: 6| Step: 12
Training loss: 1.8661847474532625
Validation loss: 2.5146546950771658

Epoch: 6| Step: 13
Training loss: 1.5399927726179679
Validation loss: 2.488316973355427

Epoch: 83| Step: 0
Training loss: 1.462811089710386
Validation loss: 2.5256775950873003

Epoch: 6| Step: 1
Training loss: 1.776575614189655
Validation loss: 2.5264792518843344

Epoch: 6| Step: 2
Training loss: 2.0526535352183846
Validation loss: 2.4744827571311045

Epoch: 6| Step: 3
Training loss: 1.5573712672002
Validation loss: 2.464615010702611

Epoch: 6| Step: 4
Training loss: 1.5296614055336637
Validation loss: 2.441084760733866

Epoch: 6| Step: 5
Training loss: 2.21503599701644
Validation loss: 2.4216443926221576

Epoch: 6| Step: 6
Training loss: 1.7535618909144137
Validation loss: 2.4020297540499427

Epoch: 6| Step: 7
Training loss: 1.8554805072612695
Validation loss: 2.413262556717234

Epoch: 6| Step: 8
Training loss: 1.6204766627169922
Validation loss: 2.3977076841795375

Epoch: 6| Step: 9
Training loss: 1.5915282227521221
Validation loss: 2.395710317245428

Epoch: 6| Step: 10
Training loss: 1.678888104084661
Validation loss: 2.403117994307354

Epoch: 6| Step: 11
Training loss: 2.000691056071192
Validation loss: 2.4004432914549403

Epoch: 6| Step: 12
Training loss: 2.0936336200310492
Validation loss: 2.400467617123455

Epoch: 6| Step: 13
Training loss: 1.8474703608549912
Validation loss: 2.423133588698106

Epoch: 84| Step: 0
Training loss: 2.114416131485806
Validation loss: 2.44050160648434

Epoch: 6| Step: 1
Training loss: 1.9178741493901965
Validation loss: 2.474394939779396

Epoch: 6| Step: 2
Training loss: 1.9768463654664925
Validation loss: 2.4813484454223462

Epoch: 6| Step: 3
Training loss: 1.6518747372001008
Validation loss: 2.4454234771408356

Epoch: 6| Step: 4
Training loss: 1.834386356974965
Validation loss: 2.4341511340648587

Epoch: 6| Step: 5
Training loss: 1.5978464325842432
Validation loss: 2.4336365542415668

Epoch: 6| Step: 6
Training loss: 1.477710902980304
Validation loss: 2.4252960162050514

Epoch: 6| Step: 7
Training loss: 1.426119077191562
Validation loss: 2.4411838440363547

Epoch: 6| Step: 8
Training loss: 2.0953592976486575
Validation loss: 2.435726188741919

Epoch: 6| Step: 9
Training loss: 1.8542530454024546
Validation loss: 2.4240681060428506

Epoch: 6| Step: 10
Training loss: 2.3036203791084375
Validation loss: 2.4394260198320676

Epoch: 6| Step: 11
Training loss: 1.4717948681183735
Validation loss: 2.413993143116173

Epoch: 6| Step: 12
Training loss: 1.1699230977403878
Validation loss: 2.4534471142427066

Epoch: 6| Step: 13
Training loss: 1.0905730292499354
Validation loss: 2.4223642654893687

Epoch: 85| Step: 0
Training loss: 1.345881656491738
Validation loss: 2.479600993880764

Epoch: 6| Step: 1
Training loss: 1.3134658983216017
Validation loss: 2.4550186105503142

Epoch: 6| Step: 2
Training loss: 1.8479780437106446
Validation loss: 2.4328113112449805

Epoch: 6| Step: 3
Training loss: 1.7547050305354464
Validation loss: 2.5023315524668326

Epoch: 6| Step: 4
Training loss: 1.4913571429073607
Validation loss: 2.4548721409150756

Epoch: 6| Step: 5
Training loss: 2.243230809575077
Validation loss: 2.459851658155427

Epoch: 6| Step: 6
Training loss: 1.4248639225820747
Validation loss: 2.4527893484708394

Epoch: 6| Step: 7
Training loss: 1.648867004268723
Validation loss: 2.4617222256375135

Epoch: 6| Step: 8
Training loss: 1.4832737099883742
Validation loss: 2.472410964249852

Epoch: 6| Step: 9
Training loss: 2.058769783151951
Validation loss: 2.482836840962191

Epoch: 6| Step: 10
Training loss: 1.6268335415235855
Validation loss: 2.4922364169335562

Epoch: 6| Step: 11
Training loss: 1.5244501123069656
Validation loss: 2.4311435176017233

Epoch: 6| Step: 12
Training loss: 2.149311567581251
Validation loss: 2.4900208465183558

Epoch: 6| Step: 13
Training loss: 1.7270366311133993
Validation loss: 2.431140657269018

Epoch: 86| Step: 0
Training loss: 1.5855715475068237
Validation loss: 2.4745914305026546

Epoch: 6| Step: 1
Training loss: 2.4053303335866105
Validation loss: 2.4343055023079985

Epoch: 6| Step: 2
Training loss: 1.1524782263960107
Validation loss: 2.4047000979696054

Epoch: 6| Step: 3
Training loss: 1.5200686252311069
Validation loss: 2.44410329542998

Epoch: 6| Step: 4
Training loss: 1.4418407912013869
Validation loss: 2.455677073719391

Epoch: 6| Step: 5
Training loss: 1.5824847289639716
Validation loss: 2.440475717848002

Epoch: 6| Step: 6
Training loss: 1.5966840178171402
Validation loss: 2.4441673026575597

Epoch: 6| Step: 7
Training loss: 1.8342953094380856
Validation loss: 2.499075551773492

Epoch: 6| Step: 8
Training loss: 1.8938924125277292
Validation loss: 2.4391629504857644

Epoch: 6| Step: 9
Training loss: 2.0049825830250105
Validation loss: 2.511964966851636

Epoch: 6| Step: 10
Training loss: 1.6054717943297245
Validation loss: 2.4676280148017877

Epoch: 6| Step: 11
Training loss: 1.716395412544551
Validation loss: 2.4200359458197838

Epoch: 6| Step: 12
Training loss: 1.8224340690126013
Validation loss: 2.44101896342249

Epoch: 6| Step: 13
Training loss: 1.4833691853394584
Validation loss: 2.4172931029141713

Epoch: 87| Step: 0
Training loss: 1.4202950890945871
Validation loss: 2.4363663637423336

Epoch: 6| Step: 1
Training loss: 1.3024141069525754
Validation loss: 2.463977595035448

Epoch: 6| Step: 2
Training loss: 1.5815249539486116
Validation loss: 2.4431135306516474

Epoch: 6| Step: 3
Training loss: 1.3835884115675086
Validation loss: 2.5495583454081054

Epoch: 6| Step: 4
Training loss: 1.4386394794347646
Validation loss: 2.4912137448125433

Epoch: 6| Step: 5
Training loss: 2.1292659350680485
Validation loss: 2.500307159627907

Epoch: 6| Step: 6
Training loss: 2.0717604845715463
Validation loss: 2.4905239759607225

Epoch: 6| Step: 7
Training loss: 1.6904391371684895
Validation loss: 2.4697982317127853

Epoch: 6| Step: 8
Training loss: 1.4951073006490543
Validation loss: 2.454087637474587

Epoch: 6| Step: 9
Training loss: 1.4796086935872321
Validation loss: 2.46959923571474

Epoch: 6| Step: 10
Training loss: 2.0039527694329324
Validation loss: 2.428891132185399

Epoch: 6| Step: 11
Training loss: 2.111657384276468
Validation loss: 2.459728610102681

Epoch: 6| Step: 12
Training loss: 2.3523204507120483
Validation loss: 2.4128876083179778

Epoch: 6| Step: 13
Training loss: 1.281075488975921
Validation loss: 2.436378824329224

Epoch: 88| Step: 0
Training loss: 2.0175703257200412
Validation loss: 2.4614854959374033

Epoch: 6| Step: 1
Training loss: 1.5541926991154882
Validation loss: 2.5392391749805374

Epoch: 6| Step: 2
Training loss: 1.6319177539707992
Validation loss: 2.566230276298011

Epoch: 6| Step: 3
Training loss: 1.1238521442094007
Validation loss: 2.5377850884454554

Epoch: 6| Step: 4
Training loss: 1.993213523987438
Validation loss: 2.58261248057721

Epoch: 6| Step: 5
Training loss: 1.1619885293653758
Validation loss: 2.49534442063475

Epoch: 6| Step: 6
Training loss: 1.7356098349942055
Validation loss: 2.4740183585397304

Epoch: 6| Step: 7
Training loss: 1.964921710854712
Validation loss: 2.4370800373822306

Epoch: 6| Step: 8
Training loss: 2.275143117909336
Validation loss: 2.4227596513073535

Epoch: 6| Step: 9
Training loss: 1.6642291205003115
Validation loss: 2.44733312158039

Epoch: 6| Step: 10
Training loss: 1.2823143701637785
Validation loss: 2.4459392650307565

Epoch: 6| Step: 11
Training loss: 1.5907535433588127
Validation loss: 2.467965544637861

Epoch: 6| Step: 12
Training loss: 2.144003103012003
Validation loss: 2.454002903610912

Epoch: 6| Step: 13
Training loss: 1.1733388277669343
Validation loss: 2.45492507105455

Epoch: 89| Step: 0
Training loss: 1.67291341601571
Validation loss: 2.464127651684503

Epoch: 6| Step: 1
Training loss: 1.4138104967686849
Validation loss: 2.5111591354445886

Epoch: 6| Step: 2
Training loss: 1.2507018026535208
Validation loss: 2.5636112780822433

Epoch: 6| Step: 3
Training loss: 2.321696270190053
Validation loss: 2.5868903610585696

Epoch: 6| Step: 4
Training loss: 1.6412945788823465
Validation loss: 2.6268441670450957

Epoch: 6| Step: 5
Training loss: 0.987704926968821
Validation loss: 2.5958627346041303

Epoch: 6| Step: 6
Training loss: 1.6442617888791438
Validation loss: 2.5837573554591464

Epoch: 6| Step: 7
Training loss: 1.6091895876252458
Validation loss: 2.541632532192796

Epoch: 6| Step: 8
Training loss: 1.6103548196790891
Validation loss: 2.4849630495595276

Epoch: 6| Step: 9
Training loss: 1.3314436346364986
Validation loss: 2.477504867820949

Epoch: 6| Step: 10
Training loss: 1.8227597922989613
Validation loss: 2.4818293326742715

Epoch: 6| Step: 11
Training loss: 1.8946708706404891
Validation loss: 2.4694994179302157

Epoch: 6| Step: 12
Training loss: 1.5781709267760238
Validation loss: 2.485066307700401

Epoch: 6| Step: 13
Training loss: 1.6351987932542278
Validation loss: 2.453839629251762

Epoch: 90| Step: 0
Training loss: 2.4225601703741546
Validation loss: 2.4598200122768845

Epoch: 6| Step: 1
Training loss: 1.4421651026349434
Validation loss: 2.4685434987423056

Epoch: 6| Step: 2
Training loss: 2.222499097688747
Validation loss: 2.4501348523246653

Epoch: 6| Step: 3
Training loss: 1.0326807327589018
Validation loss: 2.452731835998397

Epoch: 6| Step: 4
Training loss: 1.7146001482015831
Validation loss: 2.482246894982272

Epoch: 6| Step: 5
Training loss: 1.3387572662840188
Validation loss: 2.4777956037730693

Epoch: 6| Step: 6
Training loss: 1.2687871072538648
Validation loss: 2.4745844052165724

Epoch: 6| Step: 7
Training loss: 1.850360592933998
Validation loss: 2.4548096915948987

Epoch: 6| Step: 8
Training loss: 1.5855015498466218
Validation loss: 2.500034681715409

Epoch: 6| Step: 9
Training loss: 1.389236271118843
Validation loss: 2.468739891836341

Epoch: 6| Step: 10
Training loss: 1.7530072123351415
Validation loss: 2.492098472862602

Epoch: 6| Step: 11
Training loss: 1.2978074731506684
Validation loss: 2.4322844729157174

Epoch: 6| Step: 12
Training loss: 1.2811015903769432
Validation loss: 2.4805055470378

Epoch: 6| Step: 13
Training loss: 1.2857882444363222
Validation loss: 2.446954592225918

Epoch: 91| Step: 0
Training loss: 1.4850082652828482
Validation loss: 2.4985105050979226

Epoch: 6| Step: 1
Training loss: 2.643138704803361
Validation loss: 2.497368277728211

Epoch: 6| Step: 2
Training loss: 1.6153950363388965
Validation loss: 2.4529770889560045

Epoch: 6| Step: 3
Training loss: 1.5053189862859706
Validation loss: 2.4845381309324908

Epoch: 6| Step: 4
Training loss: 1.553460331720055
Validation loss: 2.449908486428252

Epoch: 6| Step: 5
Training loss: 1.0987708246646692
Validation loss: 2.4454515801508783

Epoch: 6| Step: 6
Training loss: 1.3624765376599437
Validation loss: 2.45251240947823

Epoch: 6| Step: 7
Training loss: 1.5269838967763885
Validation loss: 2.495040607708027

Epoch: 6| Step: 8
Training loss: 1.4028242982677135
Validation loss: 2.4869615697321388

Epoch: 6| Step: 9
Training loss: 1.5518229562710635
Validation loss: 2.4999106391194794

Epoch: 6| Step: 10
Training loss: 1.7012673142089552
Validation loss: 2.4703454282666395

Epoch: 6| Step: 11
Training loss: 1.212272547988314
Validation loss: 2.48158217543971

Epoch: 6| Step: 12
Training loss: 1.4226626216404286
Validation loss: 2.4154642555804835

Epoch: 6| Step: 13
Training loss: 1.3316709864661311
Validation loss: 2.451031368529581

Epoch: 92| Step: 0
Training loss: 1.082004588105069
Validation loss: 2.4575212451977597

Epoch: 6| Step: 1
Training loss: 1.7273864161114636
Validation loss: 2.496745407057997

Epoch: 6| Step: 2
Training loss: 1.4464171441112874
Validation loss: 2.4868622810631003

Epoch: 6| Step: 3
Training loss: 1.484924214802242
Validation loss: 2.502166175159066

Epoch: 6| Step: 4
Training loss: 1.2797433321630631
Validation loss: 2.5385832818499257

Epoch: 6| Step: 5
Training loss: 2.4239297333721206
Validation loss: 2.440728836683636

Epoch: 6| Step: 6
Training loss: 1.6854001862137102
Validation loss: 2.498721129425721

Epoch: 6| Step: 7
Training loss: 1.1411895922313589
Validation loss: 2.478692591777154

Epoch: 6| Step: 8
Training loss: 1.6882684159044807
Validation loss: 2.4502784833479536

Epoch: 6| Step: 9
Training loss: 1.3895557450392093
Validation loss: 2.504577626059103

Epoch: 6| Step: 10
Training loss: 1.2135190948002526
Validation loss: 2.457447479685455

Epoch: 6| Step: 11
Training loss: 1.622816232390127
Validation loss: 2.476623213512172

Epoch: 6| Step: 12
Training loss: 1.5210959412451714
Validation loss: 2.5035382742831147

Epoch: 6| Step: 13
Training loss: 1.3305234009678564
Validation loss: 2.4668708280752463

Epoch: 93| Step: 0
Training loss: 1.7319998071110994
Validation loss: 2.461130164945492

Epoch: 6| Step: 1
Training loss: 1.5827300612284803
Validation loss: 2.4715170503460757

Epoch: 6| Step: 2
Training loss: 0.972395283569987
Validation loss: 2.4256827170098862

Epoch: 6| Step: 3
Training loss: 1.5618070973400517
Validation loss: 2.4521385525881843

Epoch: 6| Step: 4
Training loss: 1.6257489752510335
Validation loss: 2.427083442480606

Epoch: 6| Step: 5
Training loss: 2.3090059845038535
Validation loss: 2.5036907133033566

Epoch: 6| Step: 6
Training loss: 1.1567125168616568
Validation loss: 2.530131709159762

Epoch: 6| Step: 7
Training loss: 1.267467617396228
Validation loss: 2.5839797692943844

Epoch: 6| Step: 8
Training loss: 1.568530157726536
Validation loss: 2.664123549372477

Epoch: 6| Step: 9
Training loss: 1.403851986421743
Validation loss: 2.600040345612519

Epoch: 6| Step: 10
Training loss: 1.6704600398363145
Validation loss: 2.5821857723565933

Epoch: 6| Step: 11
Training loss: 1.2560321220372335
Validation loss: 2.463275714952336

Epoch: 6| Step: 12
Training loss: 1.3337335979164586
Validation loss: 2.462169229977322

Epoch: 6| Step: 13
Training loss: 1.5866282795555333
Validation loss: 2.458964320740594

Epoch: 94| Step: 0
Training loss: 1.9051197641126905
Validation loss: 2.4647311564269874

Epoch: 6| Step: 1
Training loss: 1.8691383290052512
Validation loss: 2.478867397891535

Epoch: 6| Step: 2
Training loss: 2.1254934972045754
Validation loss: 2.5067530817581236

Epoch: 6| Step: 3
Training loss: 1.183499171944487
Validation loss: 2.466860824968198

Epoch: 6| Step: 4
Training loss: 1.4147088696934715
Validation loss: 2.5269081333833485

Epoch: 6| Step: 5
Training loss: 1.1530328791348083
Validation loss: 2.495539500708648

Epoch: 6| Step: 6
Training loss: 0.8889319070863914
Validation loss: 2.5506542538335695

Epoch: 6| Step: 7
Training loss: 1.850122141027938
Validation loss: 2.615398140704379

Epoch: 6| Step: 8
Training loss: 1.5540000891028811
Validation loss: 2.5974033395125726

Epoch: 6| Step: 9
Training loss: 1.6457195564570681
Validation loss: 2.4904996443935024

Epoch: 6| Step: 10
Training loss: 1.3278288567178167
Validation loss: 2.4881914682524586

Epoch: 6| Step: 11
Training loss: 0.8905043938607095
Validation loss: 2.4821090601194595

Epoch: 6| Step: 12
Training loss: 1.2678001926380449
Validation loss: 2.4619926814340563

Epoch: 6| Step: 13
Training loss: 1.544092083299955
Validation loss: 2.4418811061637307

Epoch: 95| Step: 0
Training loss: 1.039440344467065
Validation loss: 2.491943251739766

Epoch: 6| Step: 1
Training loss: 1.5107118077050072
Validation loss: 2.444817506133227

Epoch: 6| Step: 2
Training loss: 1.391862297394116
Validation loss: 2.5234723949873805

Epoch: 6| Step: 3
Training loss: 1.3697473593775344
Validation loss: 2.5376447661372743

Epoch: 6| Step: 4
Training loss: 2.6668760594968655
Validation loss: 2.625995734747594

Epoch: 6| Step: 5
Training loss: 1.3387275695346417
Validation loss: 2.5772143518504453

Epoch: 6| Step: 6
Training loss: 1.2576837888459205
Validation loss: 2.494293439221945

Epoch: 6| Step: 7
Training loss: 1.2348219146979744
Validation loss: 2.473989688607666

Epoch: 6| Step: 8
Training loss: 1.2187479459305106
Validation loss: 2.4618413809277038

Epoch: 6| Step: 9
Training loss: 1.5123929829214493
Validation loss: 2.4808615946630894

Epoch: 6| Step: 10
Training loss: 1.7170216974077224
Validation loss: 2.397869651746709

Epoch: 6| Step: 11
Training loss: 1.4932247371583491
Validation loss: 2.4346574037604776

Epoch: 6| Step: 12
Training loss: 1.667153509878586
Validation loss: 2.459338424520513

Epoch: 6| Step: 13
Training loss: 0.9041068946547639
Validation loss: 2.5345014011456697

Epoch: 96| Step: 0
Training loss: 1.8621120023138718
Validation loss: 2.4975981777878946

Epoch: 6| Step: 1
Training loss: 1.4189011211825562
Validation loss: 2.5813866992434287

Epoch: 6| Step: 2
Training loss: 1.2729709449263118
Validation loss: 2.52289045484573

Epoch: 6| Step: 3
Training loss: 0.9125806746681139
Validation loss: 2.5484146425869865

Epoch: 6| Step: 4
Training loss: 0.9297132728915133
Validation loss: 2.4523373937023143

Epoch: 6| Step: 5
Training loss: 1.691779326773095
Validation loss: 2.492966341874057

Epoch: 6| Step: 6
Training loss: 0.830138260402154
Validation loss: 2.458603558532395

Epoch: 6| Step: 7
Training loss: 2.0812975537248666
Validation loss: 2.425366663659563

Epoch: 6| Step: 8
Training loss: 1.464095349182492
Validation loss: 2.4462467964059122

Epoch: 6| Step: 9
Training loss: 1.3295353749774186
Validation loss: 2.5073788783954063

Epoch: 6| Step: 10
Training loss: 1.2938401895682357
Validation loss: 2.4674471705023744

Epoch: 6| Step: 11
Training loss: 1.221181254018676
Validation loss: 2.5126885281711027

Epoch: 6| Step: 12
Training loss: 0.7465624310831555
Validation loss: 2.5271974311936316

Epoch: 6| Step: 13
Training loss: 2.162651510939702
Validation loss: 2.5334838146974823

Epoch: 97| Step: 0
Training loss: 0.9719930325678331
Validation loss: 2.566550248362714

Epoch: 6| Step: 1
Training loss: 1.1484521358880846
Validation loss: 2.5672341167406736

Epoch: 6| Step: 2
Training loss: 1.1981433930276197
Validation loss: 2.52099588096037

Epoch: 6| Step: 3
Training loss: 1.0183298332749406
Validation loss: 2.5441430696537863

Epoch: 6| Step: 4
Training loss: 2.2091524176591943
Validation loss: 2.5862382788782026

Epoch: 6| Step: 5
Training loss: 1.3432645142504307
Validation loss: 2.5346851195199305

Epoch: 6| Step: 6
Training loss: 1.3900515627731111
Validation loss: 2.539116961555337

Epoch: 6| Step: 7
Training loss: 1.2676820403825333
Validation loss: 2.4909440050481666

Epoch: 6| Step: 8
Training loss: 1.2839559497942143
Validation loss: 2.417814226199612

Epoch: 6| Step: 9
Training loss: 1.322117942327413
Validation loss: 2.48454389657809

Epoch: 6| Step: 10
Training loss: 1.7569721841276658
Validation loss: 2.507641209093296

Epoch: 6| Step: 11
Training loss: 1.5594424277120686
Validation loss: 2.515955877559548

Epoch: 6| Step: 12
Training loss: 1.5105853896339692
Validation loss: 2.434799964907835

Epoch: 6| Step: 13
Training loss: 1.6157858851474862
Validation loss: 2.485641636436676

Epoch: 98| Step: 0
Training loss: 1.4480527726931338
Validation loss: 2.502420382279571

Epoch: 6| Step: 1
Training loss: 1.0998064477737424
Validation loss: 2.587531060724986

Epoch: 6| Step: 2
Training loss: 1.7046308946870528
Validation loss: 2.6764002916926453

Epoch: 6| Step: 3
Training loss: 1.2515208052834894
Validation loss: 2.5927455902998835

Epoch: 6| Step: 4
Training loss: 1.4441589701000406
Validation loss: 2.6178817966811745

Epoch: 6| Step: 5
Training loss: 1.1085106612206008
Validation loss: 2.5569098136357553

Epoch: 6| Step: 6
Training loss: 1.1709911828299575
Validation loss: 2.4924706325120947

Epoch: 6| Step: 7
Training loss: 1.3285682836032449
Validation loss: 2.4544478573244626

Epoch: 6| Step: 8
Training loss: 2.201983433396943
Validation loss: 2.5040561355426787

Epoch: 6| Step: 9
Training loss: 1.4086055947650475
Validation loss: 2.489083265148902

Epoch: 6| Step: 10
Training loss: 1.1575621299465007
Validation loss: 2.491300211679711

Epoch: 6| Step: 11
Training loss: 1.3785340668678885
Validation loss: 2.470213580981076

Epoch: 6| Step: 12
Training loss: 1.4920632675143997
Validation loss: 2.4523011462223616

Epoch: 6| Step: 13
Training loss: 1.2940063001547124
Validation loss: 2.4415970221689007

Epoch: 99| Step: 0
Training loss: 1.0741437851150932
Validation loss: 2.477797993286225

Epoch: 6| Step: 1
Training loss: 1.3456989171996305
Validation loss: 2.5074143851317365

Epoch: 6| Step: 2
Training loss: 0.8755576876921224
Validation loss: 2.536473038543958

Epoch: 6| Step: 3
Training loss: 1.134335250788602
Validation loss: 2.597091743491934

Epoch: 6| Step: 4
Training loss: 1.7784573262875276
Validation loss: 2.556356679964551

Epoch: 6| Step: 5
Training loss: 1.5362263994755319
Validation loss: 2.5054170808379936

Epoch: 6| Step: 6
Training loss: 1.301436891940448
Validation loss: 2.521528153515917

Epoch: 6| Step: 7
Training loss: 1.120112824036564
Validation loss: 2.468815009955248

Epoch: 6| Step: 8
Training loss: 1.087649087442522
Validation loss: 2.4477141492684003

Epoch: 6| Step: 9
Training loss: 1.1455393442950805
Validation loss: 2.5044040512406793

Epoch: 6| Step: 10
Training loss: 1.352010443221056
Validation loss: 2.47304356310224

Epoch: 6| Step: 11
Training loss: 1.0322017323837718
Validation loss: 2.481975172075948

Epoch: 6| Step: 12
Training loss: 1.0115799385196311
Validation loss: 2.5071695836616636

Epoch: 6| Step: 13
Training loss: 1.9907314589462295
Validation loss: 2.460821247887143

Epoch: 100| Step: 0
Training loss: 1.1774893485233424
Validation loss: 2.496159775029369

Epoch: 6| Step: 1
Training loss: 0.9929869127150643
Validation loss: 2.4987959505416684

Epoch: 6| Step: 2
Training loss: 1.5461297600144195
Validation loss: 2.541086620577343

Epoch: 6| Step: 3
Training loss: 1.0740233087478896
Validation loss: 2.6232533244648133

Epoch: 6| Step: 4
Training loss: 1.9071703705759888
Validation loss: 2.607324567448274

Epoch: 6| Step: 5
Training loss: 1.2167319193198727
Validation loss: 2.6395043698256795

Epoch: 6| Step: 6
Training loss: 1.2738448819506203
Validation loss: 2.580396941992653

Epoch: 6| Step: 7
Training loss: 1.1858002393496139
Validation loss: 2.5824650387091577

Epoch: 6| Step: 8
Training loss: 1.0195568563819213
Validation loss: 2.5424366446534354

Epoch: 6| Step: 9
Training loss: 1.2644645174236264
Validation loss: 2.5137200814035903

Epoch: 6| Step: 10
Training loss: 1.5991341393790388
Validation loss: 2.4849600752777263

Epoch: 6| Step: 11
Training loss: 1.7024253317973916
Validation loss: 2.488014146970043

Epoch: 6| Step: 12
Training loss: 1.0657741363963573
Validation loss: 2.5552129953567104

Epoch: 6| Step: 13
Training loss: 1.1389233162698083
Validation loss: 2.5291499543200824

Epoch: 101| Step: 0
Training loss: 0.8610211644999546
Validation loss: 2.498529629641895

Epoch: 6| Step: 1
Training loss: 1.551861365231899
Validation loss: 2.5150071169156547

Epoch: 6| Step: 2
Training loss: 1.0146406244999662
Validation loss: 2.5280121082174882

Epoch: 6| Step: 3
Training loss: 1.2214303497868773
Validation loss: 2.5291098349992693

Epoch: 6| Step: 4
Training loss: 1.1361465324739426
Validation loss: 2.6195131511538925

Epoch: 6| Step: 5
Training loss: 1.3815999722613854
Validation loss: 2.620288177419811

Epoch: 6| Step: 6
Training loss: 1.2400683674884754
Validation loss: 2.4814951537740386

Epoch: 6| Step: 7
Training loss: 1.9686085483658804
Validation loss: 2.486308554996606

Epoch: 6| Step: 8
Training loss: 1.0979868977986151
Validation loss: 2.5087570519024305

Epoch: 6| Step: 9
Training loss: 1.2467779116966524
Validation loss: 2.5599163645751775

Epoch: 6| Step: 10
Training loss: 1.638889957506654
Validation loss: 2.4803749126797077

Epoch: 6| Step: 11
Training loss: 0.9745162888834615
Validation loss: 2.546462901345207

Epoch: 6| Step: 12
Training loss: 1.2909882927798868
Validation loss: 2.4688451563527734

Epoch: 6| Step: 13
Training loss: 1.3452252119325938
Validation loss: 2.494859863071216

Epoch: 102| Step: 0
Training loss: 1.3345832429938038
Validation loss: 2.518847910553278

Epoch: 6| Step: 1
Training loss: 1.9807935218945447
Validation loss: 2.494352940559258

Epoch: 6| Step: 2
Training loss: 1.2967987957362255
Validation loss: 2.4751005781654025

Epoch: 6| Step: 3
Training loss: 0.8869688378787504
Validation loss: 2.5032752993223473

Epoch: 6| Step: 4
Training loss: 1.0883312599976338
Validation loss: 2.531093027404535

Epoch: 6| Step: 5
Training loss: 1.4771661079718732
Validation loss: 2.59117812451253

Epoch: 6| Step: 6
Training loss: 1.0624297623699566
Validation loss: 2.59176826604995

Epoch: 6| Step: 7
Training loss: 1.2572071206090536
Validation loss: 2.635768223610716

Epoch: 6| Step: 8
Training loss: 1.2026178851803833
Validation loss: 2.564802050670328

Epoch: 6| Step: 9
Training loss: 1.0880233163228545
Validation loss: 2.5013607375049216

Epoch: 6| Step: 10
Training loss: 1.0390837244146325
Validation loss: 2.545505428476514

Epoch: 6| Step: 11
Training loss: 1.2660077305176571
Validation loss: 2.5010401945945246

Epoch: 6| Step: 12
Training loss: 1.3986732241616535
Validation loss: 2.4929207706646106

Epoch: 6| Step: 13
Training loss: 1.1916221548094696
Validation loss: 2.5174358476674583

Epoch: 103| Step: 0
Training loss: 1.1130673922539895
Validation loss: 2.459772760781619

Epoch: 6| Step: 1
Training loss: 1.1042014902249564
Validation loss: 2.577634452620831

Epoch: 6| Step: 2
Training loss: 0.5778775072020697
Validation loss: 2.577152130290059

Epoch: 6| Step: 3
Training loss: 1.6466626198650678
Validation loss: 2.50085394897743

Epoch: 6| Step: 4
Training loss: 1.048714288824199
Validation loss: 2.5771560235181075

Epoch: 6| Step: 5
Training loss: 2.052637157805837
Validation loss: 2.6335041484680586

Epoch: 6| Step: 6
Training loss: 1.3876831999108512
Validation loss: 2.604137822309332

Epoch: 6| Step: 7
Training loss: 1.6630385566274366
Validation loss: 2.6222664057067835

Epoch: 6| Step: 8
Training loss: 0.9037136232011773
Validation loss: 2.576638195683294

Epoch: 6| Step: 9
Training loss: 1.2284977703889357
Validation loss: 2.5034156989284537

Epoch: 6| Step: 10
Training loss: 1.1668124902508523
Validation loss: 2.5238179175005104

Epoch: 6| Step: 11
Training loss: 0.8595335380663823
Validation loss: 2.516315452329562

Epoch: 6| Step: 12
Training loss: 1.2192005400646446
Validation loss: 2.544073830626843

Epoch: 6| Step: 13
Training loss: 0.7723706140771798
Validation loss: 2.5261700364886712

Epoch: 104| Step: 0
Training loss: 0.9426011539180208
Validation loss: 2.4665168609321224

Epoch: 6| Step: 1
Training loss: 1.0838554786822059
Validation loss: 2.6154657042689378

Epoch: 6| Step: 2
Training loss: 1.0544539581564603
Validation loss: 2.6525919689949378

Epoch: 6| Step: 3
Training loss: 1.4973571064681837
Validation loss: 2.6185027200731947

Epoch: 6| Step: 4
Training loss: 1.0265702501349916
Validation loss: 2.5916638468351896

Epoch: 6| Step: 5
Training loss: 1.3456985628579463
Validation loss: 2.564253827166341

Epoch: 6| Step: 6
Training loss: 0.840597763471149
Validation loss: 2.45886447524291

Epoch: 6| Step: 7
Training loss: 1.356851625386132
Validation loss: 2.5151953320396423

Epoch: 6| Step: 8
Training loss: 1.317322002163956
Validation loss: 2.568778387007213

Epoch: 6| Step: 9
Training loss: 1.4858526003036443
Validation loss: 2.5648467320387973

Epoch: 6| Step: 10
Training loss: 1.120080789308904
Validation loss: 2.466568864567451

Epoch: 6| Step: 11
Training loss: 1.3782665292463825
Validation loss: 2.5497833060151334

Epoch: 6| Step: 12
Training loss: 1.3462310774101116
Validation loss: 2.5342749742492425

Epoch: 6| Step: 13
Training loss: 1.8163432448750223
Validation loss: 2.6244587567330613

Epoch: 105| Step: 0
Training loss: 1.8820637207270516
Validation loss: 2.6746622906288082

Epoch: 6| Step: 1
Training loss: 1.3317773302874814
Validation loss: 2.6166810565803886

Epoch: 6| Step: 2
Training loss: 1.3169195153706201
Validation loss: 2.584047193237

Epoch: 6| Step: 3
Training loss: 1.04565848653178
Validation loss: 2.5330229935122626

Epoch: 6| Step: 4
Training loss: 0.7258790606238484
Validation loss: 2.5160954037566743

Epoch: 6| Step: 5
Training loss: 0.9540098179385976
Validation loss: 2.4808666721069095

Epoch: 6| Step: 6
Training loss: 0.7583652328936183
Validation loss: 2.4618383504646713

Epoch: 6| Step: 7
Training loss: 1.1674515207260405
Validation loss: 2.4620130176824975

Epoch: 6| Step: 8
Training loss: 1.5552518960720143
Validation loss: 2.4596581256895833

Epoch: 6| Step: 9
Training loss: 1.1549570225898196
Validation loss: 2.500273705440447

Epoch: 6| Step: 10
Training loss: 1.4293901311409611
Validation loss: 2.5758194141223716

Epoch: 6| Step: 11
Training loss: 1.4486021802136622
Validation loss: 2.635330053019426

Epoch: 6| Step: 12
Training loss: 1.3483739738485205
Validation loss: 2.707629601431476

Epoch: 6| Step: 13
Training loss: 1.2813890893385025
Validation loss: 2.664762723748304

Epoch: 106| Step: 0
Training loss: 1.1046063729244118
Validation loss: 2.6374638613715438

Epoch: 6| Step: 1
Training loss: 1.382311757259598
Validation loss: 2.588410930031258

Epoch: 6| Step: 2
Training loss: 0.7882458076789018
Validation loss: 2.561147363833213

Epoch: 6| Step: 3
Training loss: 1.1067888983953837
Validation loss: 2.5406859699861597

Epoch: 6| Step: 4
Training loss: 2.106976650324105
Validation loss: 2.540147082182863

Epoch: 6| Step: 5
Training loss: 1.5009654434973652
Validation loss: 2.5805214273171333

Epoch: 6| Step: 6
Training loss: 1.0477536058812134
Validation loss: 2.5633816946731613

Epoch: 6| Step: 7
Training loss: 1.0905151486750406
Validation loss: 2.5571812115736097

Epoch: 6| Step: 8
Training loss: 1.0631074851699682
Validation loss: 2.643171839100207

Epoch: 6| Step: 9
Training loss: 1.5264699636503687
Validation loss: 2.7099841784147936

Epoch: 6| Step: 10
Training loss: 1.290390348000799
Validation loss: 2.7175428553351444

Epoch: 6| Step: 11
Training loss: 1.0133589480220304
Validation loss: 2.6411601620927816

Epoch: 6| Step: 12
Training loss: 1.1540679962911529
Validation loss: 2.5899643599023072

Epoch: 6| Step: 13
Training loss: 1.2910216269303092
Validation loss: 2.5212657074256963

Epoch: 107| Step: 0
Training loss: 1.1720077439465695
Validation loss: 2.5755479513552895

Epoch: 6| Step: 1
Training loss: 1.159156085628115
Validation loss: 2.5667369983581967

Epoch: 6| Step: 2
Training loss: 1.472261492287414
Validation loss: 2.5261450100763003

Epoch: 6| Step: 3
Training loss: 1.2668933399982596
Validation loss: 2.5661798974427983

Epoch: 6| Step: 4
Training loss: 1.3134139375753693
Validation loss: 2.563516787258812

Epoch: 6| Step: 5
Training loss: 1.2707566670706876
Validation loss: 2.5781626072462283

Epoch: 6| Step: 6
Training loss: 0.8360044506036665
Validation loss: 2.553884304135548

Epoch: 6| Step: 7
Training loss: 1.162030077881483
Validation loss: 2.5083286550442314

Epoch: 6| Step: 8
Training loss: 0.8133201494542418
Validation loss: 2.5317508531661095

Epoch: 6| Step: 9
Training loss: 1.196255280932466
Validation loss: 2.548237629156362

Epoch: 6| Step: 10
Training loss: 2.066463592252883
Validation loss: 2.544695852201074

Epoch: 6| Step: 11
Training loss: 0.683872732727331
Validation loss: 2.537970870666739

Epoch: 6| Step: 12
Training loss: 1.0713340728957403
Validation loss: 2.488297969935608

Epoch: 6| Step: 13
Training loss: 0.971864400971442
Validation loss: 2.4872154935758513

Epoch: 108| Step: 0
Training loss: 1.0490422944778406
Validation loss: 2.5573573184990184

Epoch: 6| Step: 1
Training loss: 1.263392044521573
Validation loss: 2.4754890658695023

Epoch: 6| Step: 2
Training loss: 1.8456973121188227
Validation loss: 2.5275208432287415

Epoch: 6| Step: 3
Training loss: 1.2764760841433311
Validation loss: 2.615394334789415

Epoch: 6| Step: 4
Training loss: 1.1729988812394916
Validation loss: 2.614480268617811

Epoch: 6| Step: 5
Training loss: 1.1999025166175254
Validation loss: 2.57450797926451

Epoch: 6| Step: 6
Training loss: 1.3482364013936758
Validation loss: 2.5602471287475375

Epoch: 6| Step: 7
Training loss: 1.152115207573803
Validation loss: 2.465988965199809

Epoch: 6| Step: 8
Training loss: 1.220662792302443
Validation loss: 2.528063459869406

Epoch: 6| Step: 9
Training loss: 1.0263238057442523
Validation loss: 2.49749251023736

Epoch: 6| Step: 10
Training loss: 1.1471453293521088
Validation loss: 2.5670578128054067

Epoch: 6| Step: 11
Training loss: 1.2894956843469236
Validation loss: 2.5754059758561296

Epoch: 6| Step: 12
Training loss: 1.1900336691957838
Validation loss: 2.5293618212281865

Epoch: 6| Step: 13
Training loss: 1.3540426001813142
Validation loss: 2.5239158704468028

Epoch: 109| Step: 0
Training loss: 1.3163935267345774
Validation loss: 2.626105726571137

Epoch: 6| Step: 1
Training loss: 1.4139181242524401
Validation loss: 2.6863627873962983

Epoch: 6| Step: 2
Training loss: 1.293635078522876
Validation loss: 2.7490747874982233

Epoch: 6| Step: 3
Training loss: 1.9554233303426622
Validation loss: 2.6466668660774766

Epoch: 6| Step: 4
Training loss: 1.00273140764559
Validation loss: 2.627943538126977

Epoch: 6| Step: 5
Training loss: 1.0129764942706945
Validation loss: 2.5170673318788013

Epoch: 6| Step: 6
Training loss: 0.9939143854607979
Validation loss: 2.4914092759179503

Epoch: 6| Step: 7
Training loss: 1.0115881876118948
Validation loss: 2.4474461908240945

Epoch: 6| Step: 8
Training loss: 1.0702901127833755
Validation loss: 2.4337606112616688

Epoch: 6| Step: 9
Training loss: 0.7607140199198984
Validation loss: 2.496613449892759

Epoch: 6| Step: 10
Training loss: 1.4085268873276182
Validation loss: 2.5596949879170374

Epoch: 6| Step: 11
Training loss: 0.8333991183699908
Validation loss: 2.536342082926942

Epoch: 6| Step: 12
Training loss: 1.2280329740179083
Validation loss: 2.5050994521581056

Epoch: 6| Step: 13
Training loss: 0.8032696649309222
Validation loss: 2.567528326961032

Epoch: 110| Step: 0
Training loss: 0.9098024785859834
Validation loss: 2.5680010140665575

Epoch: 6| Step: 1
Training loss: 1.147394550107474
Validation loss: 2.582586754827754

Epoch: 6| Step: 2
Training loss: 1.1151249125352014
Validation loss: 2.5125775725376127

Epoch: 6| Step: 3
Training loss: 0.5419404701096089
Validation loss: 2.5279931988524043

Epoch: 6| Step: 4
Training loss: 0.8762310768293521
Validation loss: 2.457216644974588

Epoch: 6| Step: 5
Training loss: 1.1483784355493363
Validation loss: 2.4753396497978555

Epoch: 6| Step: 6
Training loss: 1.0265311156516699
Validation loss: 2.477214578970025

Epoch: 6| Step: 7
Training loss: 1.1445712971109432
Validation loss: 2.488993703909554

Epoch: 6| Step: 8
Training loss: 1.9831702712957282
Validation loss: 2.5435658118745734

Epoch: 6| Step: 9
Training loss: 0.9814959308988821
Validation loss: 2.5803845608873566

Epoch: 6| Step: 10
Training loss: 1.3812123323715788
Validation loss: 2.6507255400689074

Epoch: 6| Step: 11
Training loss: 1.112085282252693
Validation loss: 2.5873716282597656

Epoch: 6| Step: 12
Training loss: 1.3244180444956544
Validation loss: 2.63286046438173

Epoch: 6| Step: 13
Training loss: 1.025284592732062
Validation loss: 2.575708863916321

Epoch: 111| Step: 0
Training loss: 2.022127294350102
Validation loss: 2.4920134129803637

Epoch: 6| Step: 1
Training loss: 1.19405188812596
Validation loss: 2.5497538516352183

Epoch: 6| Step: 2
Training loss: 1.0966021271723436
Validation loss: 2.4860172561840437

Epoch: 6| Step: 3
Training loss: 1.0426819939324197
Validation loss: 2.554094702706155

Epoch: 6| Step: 4
Training loss: 1.2758165848668983
Validation loss: 2.5132421261034077

Epoch: 6| Step: 5
Training loss: 1.2980223945837068
Validation loss: 2.49315718517757

Epoch: 6| Step: 6
Training loss: 0.977887285005431
Validation loss: 2.550280176615478

Epoch: 6| Step: 7
Training loss: 0.856237092582149
Validation loss: 2.5817760162475927

Epoch: 6| Step: 8
Training loss: 0.8372811899876754
Validation loss: 2.582130972686595

Epoch: 6| Step: 9
Training loss: 0.9581125184681333
Validation loss: 2.5419800570366218

Epoch: 6| Step: 10
Training loss: 1.1271949125236025
Validation loss: 2.5503647188146656

Epoch: 6| Step: 11
Training loss: 1.1419656269291858
Validation loss: 2.528302175555763

Epoch: 6| Step: 12
Training loss: 0.8070812361267707
Validation loss: 2.5382819125134595

Epoch: 6| Step: 13
Training loss: 0.9581558159876067
Validation loss: 2.4975773994282227

Epoch: 112| Step: 0
Training loss: 1.224034857555904
Validation loss: 2.5609587632220334

Epoch: 6| Step: 1
Training loss: 1.0683879395175895
Validation loss: 2.525734642221

Epoch: 6| Step: 2
Training loss: 0.7704515327815157
Validation loss: 2.5760536118500506

Epoch: 6| Step: 3
Training loss: 1.4033728943426125
Validation loss: 2.596760630317412

Epoch: 6| Step: 4
Training loss: 1.0216980340528583
Validation loss: 2.591640518481786

Epoch: 6| Step: 5
Training loss: 1.1743506666487493
Validation loss: 2.682377776211235

Epoch: 6| Step: 6
Training loss: 0.5224866628998032
Validation loss: 2.5596820836488616

Epoch: 6| Step: 7
Training loss: 0.6895131633434264
Validation loss: 2.4969562439319026

Epoch: 6| Step: 8
Training loss: 1.0700556314570013
Validation loss: 2.5117880582763963

Epoch: 6| Step: 9
Training loss: 0.8310006434510422
Validation loss: 2.5194725246633407

Epoch: 6| Step: 10
Training loss: 1.8816400573488867
Validation loss: 2.5027267367819634

Epoch: 6| Step: 11
Training loss: 1.3515165464494092
Validation loss: 2.493421036032887

Epoch: 6| Step: 12
Training loss: 1.0218543117657146
Validation loss: 2.590241475968783

Epoch: 6| Step: 13
Training loss: 1.0625286098443047
Validation loss: 2.651826316463945

Epoch: 113| Step: 0
Training loss: 1.1636187840618517
Validation loss: 2.6084193842123105

Epoch: 6| Step: 1
Training loss: 2.0653578869759945
Validation loss: 2.611498153579724

Epoch: 6| Step: 2
Training loss: 0.9764853790348847
Validation loss: 2.6400597322815726

Epoch: 6| Step: 3
Training loss: 1.058277998000786
Validation loss: 2.5564287416974785

Epoch: 6| Step: 4
Training loss: 0.7919233224000264
Validation loss: 2.4820741119222007

Epoch: 6| Step: 5
Training loss: 0.8108634973765412
Validation loss: 2.5025186090733356

Epoch: 6| Step: 6
Training loss: 0.9741376144040815
Validation loss: 2.509675859758301

Epoch: 6| Step: 7
Training loss: 1.6719451604364408
Validation loss: 2.505914859449834

Epoch: 6| Step: 8
Training loss: 1.578775781585567
Validation loss: 2.501566888605605

Epoch: 6| Step: 9
Training loss: 0.734622913476416
Validation loss: 2.490925819293971

Epoch: 6| Step: 10
Training loss: 0.7700030821577536
Validation loss: 2.6711749968696874

Epoch: 6| Step: 11
Training loss: 0.7855949884113032
Validation loss: 2.732309116875473

Epoch: 6| Step: 12
Training loss: 1.1283046082785002
Validation loss: 2.7633097956229764

Epoch: 6| Step: 13
Training loss: 1.4472376193941843
Validation loss: 2.7865726459383064

Epoch: 114| Step: 0
Training loss: 0.7610205947655744
Validation loss: 2.5901986133613257

Epoch: 6| Step: 1
Training loss: 0.8932312760545978
Validation loss: 2.494265942274359

Epoch: 6| Step: 2
Training loss: 1.5085581778743218
Validation loss: 2.4736552056103296

Epoch: 6| Step: 3
Training loss: 0.9970458622698464
Validation loss: 2.50462444477507

Epoch: 6| Step: 4
Training loss: 1.15515951334945
Validation loss: 2.5387268470548605

Epoch: 6| Step: 5
Training loss: 0.7504041695352878
Validation loss: 2.449188946102014

Epoch: 6| Step: 6
Training loss: 1.4237986536730438
Validation loss: 2.4445387943680106

Epoch: 6| Step: 7
Training loss: 1.0513774215820928
Validation loss: 2.487582106009977

Epoch: 6| Step: 8
Training loss: 1.0170311217220787
Validation loss: 2.4969821676173356

Epoch: 6| Step: 9
Training loss: 0.8689441930412546
Validation loss: 2.6361215324807747

Epoch: 6| Step: 10
Training loss: 1.8797908611846195
Validation loss: 2.665785276268576

Epoch: 6| Step: 11
Training loss: 0.8367460387095977
Validation loss: 2.6963705299022895

Epoch: 6| Step: 12
Training loss: 1.387041296183946
Validation loss: 2.70882717667502

Epoch: 6| Step: 13
Training loss: 1.2439970834949319
Validation loss: 2.6846708443344474

Epoch: 115| Step: 0
Training loss: 0.9948532458248047
Validation loss: 2.554701164434599

Epoch: 6| Step: 1
Training loss: 0.7183743199945447
Validation loss: 2.496512619158818

Epoch: 6| Step: 2
Training loss: 0.9624248562003399
Validation loss: 2.4583165981779147

Epoch: 6| Step: 3
Training loss: 1.021653462231817
Validation loss: 2.481950276396487

Epoch: 6| Step: 4
Training loss: 2.0050546430338287
Validation loss: 2.409243484516233

Epoch: 6| Step: 5
Training loss: 1.1872392167296293
Validation loss: 2.4610424362496155

Epoch: 6| Step: 6
Training loss: 0.8063747161689699
Validation loss: 2.5164464395261312

Epoch: 6| Step: 7
Training loss: 0.9170865303883915
Validation loss: 2.5373888652248606

Epoch: 6| Step: 8
Training loss: 1.0646572652229298
Validation loss: 2.5262205919167573

Epoch: 6| Step: 9
Training loss: 1.1370036498978275
Validation loss: 2.6224742878931346

Epoch: 6| Step: 10
Training loss: 1.2344133395264745
Validation loss: 2.6776871699080034

Epoch: 6| Step: 11
Training loss: 1.0545048308246017
Validation loss: 2.6423229649770517

Epoch: 6| Step: 12
Training loss: 1.3941737125368416
Validation loss: 2.468029367721443

Epoch: 6| Step: 13
Training loss: 1.2653536093513973
Validation loss: 2.4553069921218693

Epoch: 116| Step: 0
Training loss: 1.1029433665534323
Validation loss: 2.458285813491941

Epoch: 6| Step: 1
Training loss: 1.9049948640689052
Validation loss: 2.5421475804935714

Epoch: 6| Step: 2
Training loss: 1.2017714577924234
Validation loss: 2.508240327557697

Epoch: 6| Step: 3
Training loss: 1.213831832751425
Validation loss: 2.5128096944762226

Epoch: 6| Step: 4
Training loss: 1.3164100533721947
Validation loss: 2.518679641990432

Epoch: 6| Step: 5
Training loss: 1.0802237497012552
Validation loss: 2.4530277759375405

Epoch: 6| Step: 6
Training loss: 0.8309915700179623
Validation loss: 2.53639431558668

Epoch: 6| Step: 7
Training loss: 1.1340025865838157
Validation loss: 2.7129042908644956

Epoch: 6| Step: 8
Training loss: 1.2354389868398428
Validation loss: 2.7540801442031735

Epoch: 6| Step: 9
Training loss: 1.3630453523212043
Validation loss: 2.8594863397430177

Epoch: 6| Step: 10
Training loss: 1.1592615447350794
Validation loss: 2.7995505295758307

Epoch: 6| Step: 11
Training loss: 1.01782083088057
Validation loss: 2.7275617602867936

Epoch: 6| Step: 12
Training loss: 0.8654037550904468
Validation loss: 2.5370227151880544

Epoch: 6| Step: 13
Training loss: 0.7603188194830718
Validation loss: 2.530053723384319

Epoch: 117| Step: 0
Training loss: 0.96371665946397
Validation loss: 2.43065858592296

Epoch: 6| Step: 1
Training loss: 1.3195927932507776
Validation loss: 2.5169668784879136

Epoch: 6| Step: 2
Training loss: 1.1770689240420442
Validation loss: 2.508919919982795

Epoch: 6| Step: 3
Training loss: 1.056091899438448
Validation loss: 2.4093555045586372

Epoch: 6| Step: 4
Training loss: 0.9780625685977564
Validation loss: 2.425426184836474

Epoch: 6| Step: 5
Training loss: 0.7919903812787665
Validation loss: 2.4572219815034764

Epoch: 6| Step: 6
Training loss: 0.6857234151514887
Validation loss: 2.484040291749666

Epoch: 6| Step: 7
Training loss: 0.8598904537692696
Validation loss: 2.5363539113529194

Epoch: 6| Step: 8
Training loss: 1.466361193200973
Validation loss: 2.5738567508756223

Epoch: 6| Step: 9
Training loss: 1.5941215530821282
Validation loss: 2.6760309181774615

Epoch: 6| Step: 10
Training loss: 1.2793479385085644
Validation loss: 2.601105123796633

Epoch: 6| Step: 11
Training loss: 1.7982111731264319
Validation loss: 2.560335935763746

Epoch: 6| Step: 12
Training loss: 0.6222416089458856
Validation loss: 2.506700548499322

Epoch: 6| Step: 13
Training loss: 1.3594044210823681
Validation loss: 2.5587868032835406

Epoch: 118| Step: 0
Training loss: 0.9844567401190839
Validation loss: 2.5220210191066075

Epoch: 6| Step: 1
Training loss: 1.052436177726643
Validation loss: 2.5057312914571646

Epoch: 6| Step: 2
Training loss: 0.9635760052035102
Validation loss: 2.522353404952023

Epoch: 6| Step: 3
Training loss: 0.5748871526692332
Validation loss: 2.5420687831613775

Epoch: 6| Step: 4
Training loss: 1.0461851665503392
Validation loss: 2.547548349375274

Epoch: 6| Step: 5
Training loss: 1.7756221271989805
Validation loss: 2.6337800554426307

Epoch: 6| Step: 6
Training loss: 0.7245870828412706
Validation loss: 2.6393462325755146

Epoch: 6| Step: 7
Training loss: 0.8785365704744514
Validation loss: 2.561102478286783

Epoch: 6| Step: 8
Training loss: 0.995609390078947
Validation loss: 2.5484479793642634

Epoch: 6| Step: 9
Training loss: 1.1719005327622112
Validation loss: 2.5034925860033677

Epoch: 6| Step: 10
Training loss: 1.2158645315440255
Validation loss: 2.529948099908251

Epoch: 6| Step: 11
Training loss: 1.3359540079446537
Validation loss: 2.4519918217810424

Epoch: 6| Step: 12
Training loss: 1.007903693752899
Validation loss: 2.4287944104971753

Epoch: 6| Step: 13
Training loss: 1.1176947662487635
Validation loss: 2.503592992777439

Epoch: 119| Step: 0
Training loss: 0.895432663554682
Validation loss: 2.4591803519336657

Epoch: 6| Step: 1
Training loss: 0.5874343571615865
Validation loss: 2.466921173209968

Epoch: 6| Step: 2
Training loss: 0.5607023654830017
Validation loss: 2.5710690823560443

Epoch: 6| Step: 3
Training loss: 1.2941836731369114
Validation loss: 2.6155657170184847

Epoch: 6| Step: 4
Training loss: 1.0612897712255571
Validation loss: 2.582060382349719

Epoch: 6| Step: 5
Training loss: 2.0021063918083555
Validation loss: 2.5679581980328408

Epoch: 6| Step: 6
Training loss: 1.099935317305181
Validation loss: 2.5578494476899793

Epoch: 6| Step: 7
Training loss: 0.9830935175002432
Validation loss: 2.487955116925066

Epoch: 6| Step: 8
Training loss: 0.9232656044569683
Validation loss: 2.4875116360774

Epoch: 6| Step: 9
Training loss: 0.8926296761815892
Validation loss: 2.513336783726328

Epoch: 6| Step: 10
Training loss: 0.7176708745016557
Validation loss: 2.4709189982839432

Epoch: 6| Step: 11
Training loss: 1.2329295423135538
Validation loss: 2.47534383960648

Epoch: 6| Step: 12
Training loss: 0.5124862971451092
Validation loss: 2.3983346293668797

Epoch: 6| Step: 13
Training loss: 0.8223821054625087
Validation loss: 2.457231676167972

Epoch: 120| Step: 0
Training loss: 0.9696988104684022
Validation loss: 2.415318924437182

Epoch: 6| Step: 1
Training loss: 0.6690952773352679
Validation loss: 2.4293251217111154

Epoch: 6| Step: 2
Training loss: 1.1146726780433485
Validation loss: 2.4477094332585687

Epoch: 6| Step: 3
Training loss: 0.9927629619243082
Validation loss: 2.5372172218445916

Epoch: 6| Step: 4
Training loss: 0.4562382461392503
Validation loss: 2.5951079065750213

Epoch: 6| Step: 5
Training loss: 1.0268271420100277
Validation loss: 2.5888705489209833

Epoch: 6| Step: 6
Training loss: 1.0972729757028115
Validation loss: 2.5571854149110154

Epoch: 6| Step: 7
Training loss: 0.9492892015473675
Validation loss: 2.57751927822142

Epoch: 6| Step: 8
Training loss: 0.8827258717392146
Validation loss: 2.5413048491881414

Epoch: 6| Step: 9
Training loss: 0.7452137335827876
Validation loss: 2.470417505775533

Epoch: 6| Step: 10
Training loss: 1.9167505812588725
Validation loss: 2.4920333288453036

Epoch: 6| Step: 11
Training loss: 1.0192022852523193
Validation loss: 2.473592925274089

Epoch: 6| Step: 12
Training loss: 0.6200883032612372
Validation loss: 2.5804863798544213

Epoch: 6| Step: 13
Training loss: 0.7832359630521359
Validation loss: 2.5916381419371195

Epoch: 121| Step: 0
Training loss: 1.0417052770452582
Validation loss: 2.5304902588810636

Epoch: 6| Step: 1
Training loss: 0.8178084893250358
Validation loss: 2.533232701231123

Epoch: 6| Step: 2
Training loss: 1.1797840508366697
Validation loss: 2.515441358667411

Epoch: 6| Step: 3
Training loss: 0.8328344918330071
Validation loss: 2.4789234704590584

Epoch: 6| Step: 4
Training loss: 1.0085089591010872
Validation loss: 2.5426174063692546

Epoch: 6| Step: 5
Training loss: 0.8805891413322188
Validation loss: 2.558474332628886

Epoch: 6| Step: 6
Training loss: 0.8965830696647571
Validation loss: 2.5685618892453945

Epoch: 6| Step: 7
Training loss: 0.8087410907755798
Validation loss: 2.5401045944675515

Epoch: 6| Step: 8
Training loss: 0.816114966890722
Validation loss: 2.481483888532674

Epoch: 6| Step: 9
Training loss: 0.862175798990035
Validation loss: 2.547729114939848

Epoch: 6| Step: 10
Training loss: 0.8346040732716946
Validation loss: 2.5075260842545912

Epoch: 6| Step: 11
Training loss: 0.7921694029296558
Validation loss: 2.4859336985669502

Epoch: 6| Step: 12
Training loss: 1.7168325652664629
Validation loss: 2.5897644245624756

Epoch: 6| Step: 13
Training loss: 0.8713170607822139
Validation loss: 2.584057919086888

Epoch: 122| Step: 0
Training loss: 1.04954694555875
Validation loss: 2.507295319496815

Epoch: 6| Step: 1
Training loss: 0.8110705786496175
Validation loss: 2.569629025631141

Epoch: 6| Step: 2
Training loss: 1.044566327506796
Validation loss: 2.621348020497244

Epoch: 6| Step: 3
Training loss: 0.7681318232184378
Validation loss: 2.559370913907905

Epoch: 6| Step: 4
Training loss: 1.1816412303071797
Validation loss: 2.503514045393024

Epoch: 6| Step: 5
Training loss: 0.5551807735490414
Validation loss: 2.5174526738728606

Epoch: 6| Step: 6
Training loss: 0.5479392459215432
Validation loss: 2.4993937552033696

Epoch: 6| Step: 7
Training loss: 1.7415857344931975
Validation loss: 2.5084602889907752

Epoch: 6| Step: 8
Training loss: 0.9202790103641445
Validation loss: 2.510353108679161

Epoch: 6| Step: 9
Training loss: 0.6101379509012235
Validation loss: 2.5873003515598496

Epoch: 6| Step: 10
Training loss: 0.8869823114530164
Validation loss: 2.528682112638147

Epoch: 6| Step: 11
Training loss: 0.7205546156297781
Validation loss: 2.4882634759624462

Epoch: 6| Step: 12
Training loss: 0.558260891850395
Validation loss: 2.592743651559625

Epoch: 6| Step: 13
Training loss: 1.272700184063161
Validation loss: 2.512245688528701

Epoch: 123| Step: 0
Training loss: 1.7800498399293336
Validation loss: 2.519017429842231

Epoch: 6| Step: 1
Training loss: 0.7712093200960325
Validation loss: 2.5408544389101095

Epoch: 6| Step: 2
Training loss: 0.8551925492001365
Validation loss: 2.4882906879144255

Epoch: 6| Step: 3
Training loss: 1.0664654390446493
Validation loss: 2.568766874179038

Epoch: 6| Step: 4
Training loss: 0.7964476393103855
Validation loss: 2.5081951447586524

Epoch: 6| Step: 5
Training loss: 0.8184925417108785
Validation loss: 2.5321618152897423

Epoch: 6| Step: 6
Training loss: 0.8015888514658128
Validation loss: 2.501856464282699

Epoch: 6| Step: 7
Training loss: 0.5649970051171253
Validation loss: 2.521337393079939

Epoch: 6| Step: 8
Training loss: 0.733597567124841
Validation loss: 2.570344060918563

Epoch: 6| Step: 9
Training loss: 0.8080304528767366
Validation loss: 2.4901405466392057

Epoch: 6| Step: 10
Training loss: 0.6782322794353064
Validation loss: 2.5274630974837295

Epoch: 6| Step: 11
Training loss: 0.8247177638275331
Validation loss: 2.5715223593612846

Epoch: 6| Step: 12
Training loss: 0.7431718422360943
Validation loss: 2.5834059602516333

Epoch: 6| Step: 13
Training loss: 1.2798749476679707
Validation loss: 2.541777207102234

Epoch: 124| Step: 0
Training loss: 1.0499009199170946
Validation loss: 2.5812837458414384

Epoch: 6| Step: 1
Training loss: 1.8019609869143134
Validation loss: 2.56663751358551

Epoch: 6| Step: 2
Training loss: 0.7820605079139563
Validation loss: 2.6147749983813204

Epoch: 6| Step: 3
Training loss: 0.6434583345794562
Validation loss: 2.563191064831046

Epoch: 6| Step: 4
Training loss: 1.2436374862616144
Validation loss: 2.586544968168972

Epoch: 6| Step: 5
Training loss: 1.040318182084347
Validation loss: 2.544241684766512

Epoch: 6| Step: 6
Training loss: 0.7984372700730085
Validation loss: 2.59680680461998

Epoch: 6| Step: 7
Training loss: 0.9242277349710853
Validation loss: 2.6024589483301233

Epoch: 6| Step: 8
Training loss: 0.7033475311783752
Validation loss: 2.5661003592407834

Epoch: 6| Step: 9
Training loss: 0.7683664403996852
Validation loss: 2.5286119002407195

Epoch: 6| Step: 10
Training loss: 0.6827844897707561
Validation loss: 2.4984386177688718

Epoch: 6| Step: 11
Training loss: 1.0289213881830857
Validation loss: 2.5329741190875654

Epoch: 6| Step: 12
Training loss: 0.6978557237425786
Validation loss: 2.446150728478096

Epoch: 6| Step: 13
Training loss: 0.8350214707589368
Validation loss: 2.5115189776910154

Epoch: 125| Step: 0
Training loss: 0.6928918471128271
Validation loss: 2.5777250499877504

Epoch: 6| Step: 1
Training loss: 1.019673421600637
Validation loss: 2.5900910395132284

Epoch: 6| Step: 2
Training loss: 0.8847197463917353
Validation loss: 2.578192869892144

Epoch: 6| Step: 3
Training loss: 0.7456882833019987
Validation loss: 2.4611982621192117

Epoch: 6| Step: 4
Training loss: 0.7624347940298895
Validation loss: 2.5163776622286482

Epoch: 6| Step: 5
Training loss: 0.8487317342576466
Validation loss: 2.499631361803313

Epoch: 6| Step: 6
Training loss: 0.9175118790670873
Validation loss: 2.514319466118179

Epoch: 6| Step: 7
Training loss: 0.7001352111474967
Validation loss: 2.4636229863902543

Epoch: 6| Step: 8
Training loss: 0.7522134701754815
Validation loss: 2.546127451458736

Epoch: 6| Step: 9
Training loss: 0.9851514690625002
Validation loss: 2.5671583957612767

Epoch: 6| Step: 10
Training loss: 1.1138538694914952
Validation loss: 2.5055276002426305

Epoch: 6| Step: 11
Training loss: 0.8810094802749054
Validation loss: 2.497424977079134

Epoch: 6| Step: 12
Training loss: 1.7655550512450895
Validation loss: 2.5839727953639113

Epoch: 6| Step: 13
Training loss: 0.8883510136112269
Validation loss: 2.564932986258409

Epoch: 126| Step: 0
Training loss: 1.2101905241632307
Validation loss: 2.5636635751477033

Epoch: 6| Step: 1
Training loss: 0.7066060890205871
Validation loss: 2.5170540235741345

Epoch: 6| Step: 2
Training loss: 0.6543010199116613
Validation loss: 2.516758112688101

Epoch: 6| Step: 3
Training loss: 1.1342486518715642
Validation loss: 2.596051822507077

Epoch: 6| Step: 4
Training loss: 0.6120913923454481
Validation loss: 2.5870054484942706

Epoch: 6| Step: 5
Training loss: 0.6089517884408999
Validation loss: 2.478911872935137

Epoch: 6| Step: 6
Training loss: 0.5946935384567075
Validation loss: 2.5334368391809776

Epoch: 6| Step: 7
Training loss: 1.0411016775782929
Validation loss: 2.6500614405053264

Epoch: 6| Step: 8
Training loss: 1.07609023322778
Validation loss: 2.587148407838388

Epoch: 6| Step: 9
Training loss: 0.6133179380291823
Validation loss: 2.611328132608471

Epoch: 6| Step: 10
Training loss: 0.6738740103758046
Validation loss: 2.549693102850129

Epoch: 6| Step: 11
Training loss: 1.022777082212885
Validation loss: 2.562154777656925

Epoch: 6| Step: 12
Training loss: 1.7732460489996782
Validation loss: 2.5161049426470115

Epoch: 6| Step: 13
Training loss: 0.8239985890607884
Validation loss: 2.575487286407387

Epoch: 127| Step: 0
Training loss: 0.6495147397583761
Validation loss: 2.5686971425405978

Epoch: 6| Step: 1
Training loss: 0.705726241120941
Validation loss: 2.482535106798701

Epoch: 6| Step: 2
Training loss: 0.7419422748403351
Validation loss: 2.4826622023002827

Epoch: 6| Step: 3
Training loss: 0.4643061438194872
Validation loss: 2.5056986867514706

Epoch: 6| Step: 4
Training loss: 0.9698531422591238
Validation loss: 2.5283572460829964

Epoch: 6| Step: 5
Training loss: 1.6368597511609548
Validation loss: 2.5622143004646856

Epoch: 6| Step: 6
Training loss: 0.8973116911445868
Validation loss: 2.5409229993736795

Epoch: 6| Step: 7
Training loss: 0.5654200946738616
Validation loss: 2.5205901530434796

Epoch: 6| Step: 8
Training loss: 0.8674889461571625
Validation loss: 2.5622413318616566

Epoch: 6| Step: 9
Training loss: 1.0795978492360636
Validation loss: 2.5666941302758173

Epoch: 6| Step: 10
Training loss: 0.591670409938451
Validation loss: 2.521313571635965

Epoch: 6| Step: 11
Training loss: 1.1974725093353975
Validation loss: 2.5497068174278494

Epoch: 6| Step: 12
Training loss: 0.7306601125798533
Validation loss: 2.5423927416537597

Epoch: 6| Step: 13
Training loss: 0.8517311699087144
Validation loss: 2.540228551484183

Epoch: 128| Step: 0
Training loss: 0.7847256214964693
Validation loss: 2.5605752275586315

Epoch: 6| Step: 1
Training loss: 0.8173257131013877
Validation loss: 2.5770215842503017

Epoch: 6| Step: 2
Training loss: 0.539617943359496
Validation loss: 2.6490196930957457

Epoch: 6| Step: 3
Training loss: 0.721313714133724
Validation loss: 2.4920751532381202

Epoch: 6| Step: 4
Training loss: 1.033168972438851
Validation loss: 2.6058185729546164

Epoch: 6| Step: 5
Training loss: 1.1154248931680202
Validation loss: 2.529930131698872

Epoch: 6| Step: 6
Training loss: 0.7583499850726043
Validation loss: 2.532660715213473

Epoch: 6| Step: 7
Training loss: 1.6309442372428702
Validation loss: 2.5215106453525555

Epoch: 6| Step: 8
Training loss: 1.0407889228449778
Validation loss: 2.612118411449031

Epoch: 6| Step: 9
Training loss: 0.6912561458431705
Validation loss: 2.513000208847456

Epoch: 6| Step: 10
Training loss: 0.4650509636904972
Validation loss: 2.5513137565320565

Epoch: 6| Step: 11
Training loss: 0.42861120502058575
Validation loss: 2.5898291662696438

Epoch: 6| Step: 12
Training loss: 0.9559479479485333
Validation loss: 2.561108684423717

Epoch: 6| Step: 13
Training loss: 0.9843141143376726
Validation loss: 2.606580276968302

Epoch: 129| Step: 0
Training loss: 1.158273627208377
Validation loss: 2.5688883073610675

Epoch: 6| Step: 1
Training loss: 0.9657978791967012
Validation loss: 2.601103030881191

Epoch: 6| Step: 2
Training loss: 1.04591450825801
Validation loss: 2.566760049912913

Epoch: 6| Step: 3
Training loss: 0.8625890796381404
Validation loss: 2.5732633586208067

Epoch: 6| Step: 4
Training loss: 1.7215864877904412
Validation loss: 2.519082830381978

Epoch: 6| Step: 5
Training loss: 0.8056644694009389
Validation loss: 2.5701108039788085

Epoch: 6| Step: 6
Training loss: 0.7526912880776622
Validation loss: 2.534295663403221

Epoch: 6| Step: 7
Training loss: 0.6027693347100328
Validation loss: 2.6062950185276983

Epoch: 6| Step: 8
Training loss: 0.7028375249862361
Validation loss: 2.611122292523984

Epoch: 6| Step: 9
Training loss: 0.815618436063465
Validation loss: 2.5744553854217793

Epoch: 6| Step: 10
Training loss: 0.5661301564769102
Validation loss: 2.589427141577218

Epoch: 6| Step: 11
Training loss: 0.7675253192316336
Validation loss: 2.635943459393078

Epoch: 6| Step: 12
Training loss: 0.8158575523010543
Validation loss: 2.580900790259121

Epoch: 6| Step: 13
Training loss: 0.6126223870054139
Validation loss: 2.622172149442335

Epoch: 130| Step: 0
Training loss: 0.6412494453814452
Validation loss: 2.636708547313401

Epoch: 6| Step: 1
Training loss: 1.0010665927500113
Validation loss: 2.605042673909744

Epoch: 6| Step: 2
Training loss: 0.8697595342917807
Validation loss: 2.5573078680723

Epoch: 6| Step: 3
Training loss: 0.545961598135754
Validation loss: 2.625180979953683

Epoch: 6| Step: 4
Training loss: 1.6327105038558567
Validation loss: 2.599033023370017

Epoch: 6| Step: 5
Training loss: 0.9020518701952938
Validation loss: 2.5726170899559473

Epoch: 6| Step: 6
Training loss: 1.0446237299172958
Validation loss: 2.5887119741208884

Epoch: 6| Step: 7
Training loss: 0.8127455707055043
Validation loss: 2.570402976688217

Epoch: 6| Step: 8
Training loss: 0.8129192884341974
Validation loss: 2.62098225158859

Epoch: 6| Step: 9
Training loss: 0.9120431095859922
Validation loss: 2.5979589759136683

Epoch: 6| Step: 10
Training loss: 0.8940307016327997
Validation loss: 2.6267009098786787

Epoch: 6| Step: 11
Training loss: 0.5358657866785548
Validation loss: 2.563267569605704

Epoch: 6| Step: 12
Training loss: 0.47957990974355424
Validation loss: 2.573564684623462

Epoch: 6| Step: 13
Training loss: 0.6847515437696143
Validation loss: 2.575531280979814

Epoch: 131| Step: 0
Training loss: 0.6298412693725279
Validation loss: 2.5228456525523466

Epoch: 6| Step: 1
Training loss: 1.921822896111542
Validation loss: 2.4990210285301866

Epoch: 6| Step: 2
Training loss: 0.6507000344695731
Validation loss: 2.5217994751113166

Epoch: 6| Step: 3
Training loss: 0.7911238231363884
Validation loss: 2.522400988591185

Epoch: 6| Step: 4
Training loss: 0.9294220361049709
Validation loss: 2.4971086312403403

Epoch: 6| Step: 5
Training loss: 0.5167612791597532
Validation loss: 2.625955324570608

Epoch: 6| Step: 6
Training loss: 0.7431325417048499
Validation loss: 2.651276993315105

Epoch: 6| Step: 7
Training loss: 0.8362533115384118
Validation loss: 2.6837247902583847

Epoch: 6| Step: 8
Training loss: 1.0852711780786688
Validation loss: 2.6250239931251342

Epoch: 6| Step: 9
Training loss: 0.7861626471313671
Validation loss: 2.529825021399851

Epoch: 6| Step: 10
Training loss: 0.6832745488010706
Validation loss: 2.4945402927953593

Epoch: 6| Step: 11
Training loss: 0.712848358991604
Validation loss: 2.5169862180112004

Epoch: 6| Step: 12
Training loss: 0.8892009794865617
Validation loss: 2.4851501183352736

Epoch: 6| Step: 13
Training loss: 0.9320701392758617
Validation loss: 2.5062879481815803

Epoch: 132| Step: 0
Training loss: 0.7155635940659344
Validation loss: 2.4890979841743803

Epoch: 6| Step: 1
Training loss: 1.0128761063905953
Validation loss: 2.5173697887285704

Epoch: 6| Step: 2
Training loss: 0.6248812085747695
Validation loss: 2.5351346744350063

Epoch: 6| Step: 3
Training loss: 0.6668462859016637
Validation loss: 2.6488946090715775

Epoch: 6| Step: 4
Training loss: 1.5960071512219827
Validation loss: 2.6472708834267134

Epoch: 6| Step: 5
Training loss: 1.3268221579697086
Validation loss: 2.6461983876938033

Epoch: 6| Step: 6
Training loss: 0.819975538528588
Validation loss: 2.7154146980004175

Epoch: 6| Step: 7
Training loss: 0.7501532080250366
Validation loss: 2.636511825165568

Epoch: 6| Step: 8
Training loss: 0.6847306960185315
Validation loss: 2.5992182192062816

Epoch: 6| Step: 9
Training loss: 0.7633132287533207
Validation loss: 2.5510376377367256

Epoch: 6| Step: 10
Training loss: 0.5231682383762913
Validation loss: 2.5482225967940253

Epoch: 6| Step: 11
Training loss: 0.6643872981400074
Validation loss: 2.5153374596455844

Epoch: 6| Step: 12
Training loss: 0.8322098231428253
Validation loss: 2.528483877027384

Epoch: 6| Step: 13
Training loss: 0.566686600329841
Validation loss: 2.6063733529859907

Epoch: 133| Step: 0
Training loss: 1.0696947863032806
Validation loss: 2.5560916926230357

Epoch: 6| Step: 1
Training loss: 0.646107728154226
Validation loss: 2.587498020165219

Epoch: 6| Step: 2
Training loss: 0.565751664326538
Validation loss: 2.6353709979617457

Epoch: 6| Step: 3
Training loss: 0.870942209516425
Validation loss: 2.572830512783294

Epoch: 6| Step: 4
Training loss: 0.7815601496182578
Validation loss: 2.5682548627391157

Epoch: 6| Step: 5
Training loss: 0.8499743149186471
Validation loss: 2.50369203854333

Epoch: 6| Step: 6
Training loss: 1.5586594493661887
Validation loss: 2.5629612112187323

Epoch: 6| Step: 7
Training loss: 0.43676848222224235
Validation loss: 2.4966026109831674

Epoch: 6| Step: 8
Training loss: 0.6984691757768166
Validation loss: 2.537255075219416

Epoch: 6| Step: 9
Training loss: 0.9722995640251628
Validation loss: 2.525454499473678

Epoch: 6| Step: 10
Training loss: 0.8224894384384358
Validation loss: 2.522744255779399

Epoch: 6| Step: 11
Training loss: 0.6472407408162887
Validation loss: 2.5491897501861094

Epoch: 6| Step: 12
Training loss: 0.953065182419096
Validation loss: 2.548053726123919

Epoch: 6| Step: 13
Training loss: 0.7050464232020003
Validation loss: 2.474394321505928

Epoch: 134| Step: 0
Training loss: 0.49333360231667134
Validation loss: 2.605058308862207

Epoch: 6| Step: 1
Training loss: 0.8538667144418072
Validation loss: 2.513302325096224

Epoch: 6| Step: 2
Training loss: 0.5128780947430795
Validation loss: 2.470721612391204

Epoch: 6| Step: 3
Training loss: 1.5602431210557404
Validation loss: 2.4918470160070147

Epoch: 6| Step: 4
Training loss: 0.8191307638481604
Validation loss: 2.5767174008923606

Epoch: 6| Step: 5
Training loss: 0.8676855358290319
Validation loss: 2.577756651178838

Epoch: 6| Step: 6
Training loss: 0.5427403690110926
Validation loss: 2.536009109686285

Epoch: 6| Step: 7
Training loss: 1.012342106316915
Validation loss: 2.5344563651047287

Epoch: 6| Step: 8
Training loss: 0.5646492640391277
Validation loss: 2.553401845165562

Epoch: 6| Step: 9
Training loss: 0.650856767465352
Validation loss: 2.467698553368407

Epoch: 6| Step: 10
Training loss: 0.8577949911251924
Validation loss: 2.5720562802619304

Epoch: 6| Step: 11
Training loss: 1.1417065548483674
Validation loss: 2.5534848056548056

Epoch: 6| Step: 12
Training loss: 0.5523250128820147
Validation loss: 2.5078982678222435

Epoch: 6| Step: 13
Training loss: 0.7726570970243279
Validation loss: 2.5549393820368165

Epoch: 135| Step: 0
Training loss: 0.6901841866986177
Validation loss: 2.569887955223288

Epoch: 6| Step: 1
Training loss: 1.0507969057412943
Validation loss: 2.562720289298334

Epoch: 6| Step: 2
Training loss: 0.8935998790548784
Validation loss: 2.586665194214405

Epoch: 6| Step: 3
Training loss: 0.5106168341479819
Validation loss: 2.655001881892704

Epoch: 6| Step: 4
Training loss: 1.064880733169614
Validation loss: 2.6025417649933202

Epoch: 6| Step: 5
Training loss: 0.6709177161588252
Validation loss: 2.663859347505712

Epoch: 6| Step: 6
Training loss: 0.7997013532982238
Validation loss: 2.6352628630336947

Epoch: 6| Step: 7
Training loss: 0.3825814464597067
Validation loss: 2.544844865548679

Epoch: 6| Step: 8
Training loss: 0.833916618935998
Validation loss: 2.4809651516393134

Epoch: 6| Step: 9
Training loss: 1.622815277432203
Validation loss: 2.525069599640204

Epoch: 6| Step: 10
Training loss: 0.6289423819641221
Validation loss: 2.4918245232589027

Epoch: 6| Step: 11
Training loss: 0.6449111050330923
Validation loss: 2.5399028463381166

Epoch: 6| Step: 12
Training loss: 0.8633034819765283
Validation loss: 2.5237958513880923

Epoch: 6| Step: 13
Training loss: 0.645393950192066
Validation loss: 2.529047631903851

Epoch: 136| Step: 0
Training loss: 0.932325930827075
Validation loss: 2.5766178233891024

Epoch: 6| Step: 1
Training loss: 0.7835127677412747
Validation loss: 2.637138095993706

Epoch: 6| Step: 2
Training loss: 1.7258585189438005
Validation loss: 2.572189403303512

Epoch: 6| Step: 3
Training loss: 0.7454050290553474
Validation loss: 2.618110304264785

Epoch: 6| Step: 4
Training loss: 0.7993539884071066
Validation loss: 2.571087883558432

Epoch: 6| Step: 5
Training loss: 0.5701850330617622
Validation loss: 2.5418085986255363

Epoch: 6| Step: 6
Training loss: 0.8045917935538185
Validation loss: 2.551962033457739

Epoch: 6| Step: 7
Training loss: 0.8221407544060746
Validation loss: 2.59142922747851

Epoch: 6| Step: 8
Training loss: 0.706599952282163
Validation loss: 2.5991420846526583

Epoch: 6| Step: 9
Training loss: 0.554185048733013
Validation loss: 2.6344391036313564

Epoch: 6| Step: 10
Training loss: 0.7268804039266356
Validation loss: 2.5939562918501013

Epoch: 6| Step: 11
Training loss: 0.48294445259339436
Validation loss: 2.638494666808315

Epoch: 6| Step: 12
Training loss: 0.43856436820934985
Validation loss: 2.6012906074684508

Epoch: 6| Step: 13
Training loss: 1.0290491142526033
Validation loss: 2.58863385737996

Epoch: 137| Step: 0
Training loss: 0.5699843939100393
Validation loss: 2.6316146314025297

Epoch: 6| Step: 1
Training loss: 0.6273284929256334
Validation loss: 2.6086757507261917

Epoch: 6| Step: 2
Training loss: 0.511079578302309
Validation loss: 2.5360222401761887

Epoch: 6| Step: 3
Training loss: 0.5096111136521864
Validation loss: 2.571307019862681

Epoch: 6| Step: 4
Training loss: 0.7826950441974855
Validation loss: 2.591892711148699

Epoch: 6| Step: 5
Training loss: 0.7477525575288624
Validation loss: 2.5223693476584828

Epoch: 6| Step: 6
Training loss: 0.6945737707726581
Validation loss: 2.5406057822363604

Epoch: 6| Step: 7
Training loss: 0.9085067405597589
Validation loss: 2.5899230730079057

Epoch: 6| Step: 8
Training loss: 0.7389703995657243
Validation loss: 2.6095616622220694

Epoch: 6| Step: 9
Training loss: 1.642413735526725
Validation loss: 2.589259730523435

Epoch: 6| Step: 10
Training loss: 0.6734122278202295
Validation loss: 2.578065759768114

Epoch: 6| Step: 11
Training loss: 0.821579236672302
Validation loss: 2.562768829014554

Epoch: 6| Step: 12
Training loss: 0.7025103955840266
Validation loss: 2.5486816286199496

Epoch: 6| Step: 13
Training loss: 0.8682213540155724
Validation loss: 2.6522741144746287

Epoch: 138| Step: 0
Training loss: 0.9836641197089747
Validation loss: 2.5214018903025885

Epoch: 6| Step: 1
Training loss: 0.704308742564963
Validation loss: 2.5589292815835596

Epoch: 6| Step: 2
Training loss: 0.7721782412990892
Validation loss: 2.5453261363938693

Epoch: 6| Step: 3
Training loss: 0.6195678199855982
Validation loss: 2.5598270074563487

Epoch: 6| Step: 4
Training loss: 0.529465426813898
Validation loss: 2.5560729132561884

Epoch: 6| Step: 5
Training loss: 0.7483119644294389
Validation loss: 2.553413672374351

Epoch: 6| Step: 6
Training loss: 0.5533612743422105
Validation loss: 2.522517600551029

Epoch: 6| Step: 7
Training loss: 0.4147414093794962
Validation loss: 2.564946518650911

Epoch: 6| Step: 8
Training loss: 0.9934130631255534
Validation loss: 2.6346704811316006

Epoch: 6| Step: 9
Training loss: 0.5745027838723351
Validation loss: 2.5611449434781512

Epoch: 6| Step: 10
Training loss: 1.7437960464796736
Validation loss: 2.5577246512410126

Epoch: 6| Step: 11
Training loss: 0.7195496464633875
Validation loss: 2.631160002412953

Epoch: 6| Step: 12
Training loss: 0.37735442310347633
Validation loss: 2.618163713424111

Epoch: 6| Step: 13
Training loss: 0.5984548830142129
Validation loss: 2.5943372896499133

Epoch: 139| Step: 0
Training loss: 0.7534249701579456
Validation loss: 2.5623271852851848

Epoch: 6| Step: 1
Training loss: 0.6536154315661765
Validation loss: 2.5305761688412725

Epoch: 6| Step: 2
Training loss: 0.5593370680494889
Validation loss: 2.555467787792678

Epoch: 6| Step: 3
Training loss: 0.7189548034787656
Validation loss: 2.6061735634454433

Epoch: 6| Step: 4
Training loss: 0.6216291123604536
Validation loss: 2.5170175950849014

Epoch: 6| Step: 5
Training loss: 0.981275067343307
Validation loss: 2.627530543364254

Epoch: 6| Step: 6
Training loss: 0.7974966279918212
Validation loss: 2.5107848080836117

Epoch: 6| Step: 7
Training loss: 0.5199197162953079
Validation loss: 2.566169871104186

Epoch: 6| Step: 8
Training loss: 0.7832392353666008
Validation loss: 2.5971054831758345

Epoch: 6| Step: 9
Training loss: 0.8683575134669234
Validation loss: 2.491312644733597

Epoch: 6| Step: 10
Training loss: 1.0196115747138246
Validation loss: 2.571325147090412

Epoch: 6| Step: 11
Training loss: 1.489436144548172
Validation loss: 2.5611720482212044

Epoch: 6| Step: 12
Training loss: 0.47881779374976946
Validation loss: 2.5060226375351973

Epoch: 6| Step: 13
Training loss: 0.34541521098348227
Validation loss: 2.5964706583523043

Epoch: 140| Step: 0
Training loss: 0.6141854684799414
Validation loss: 2.539187791129481

Epoch: 6| Step: 1
Training loss: 0.887879473192004
Validation loss: 2.569052251032738

Epoch: 6| Step: 2
Training loss: 0.42919112925885833
Validation loss: 2.551635240933955

Epoch: 6| Step: 3
Training loss: 0.6000770956417235
Validation loss: 2.558438952085124

Epoch: 6| Step: 4
Training loss: 0.6329056706539594
Validation loss: 2.6488583210736

Epoch: 6| Step: 5
Training loss: 0.515028579715176
Validation loss: 2.610545407951765

Epoch: 6| Step: 6
Training loss: 0.7556229253571635
Validation loss: 2.518134001255556

Epoch: 6| Step: 7
Training loss: 0.4342133845724976
Validation loss: 2.571617544953134

Epoch: 6| Step: 8
Training loss: 0.7838451769409405
Validation loss: 2.5475351613082413

Epoch: 6| Step: 9
Training loss: 0.8585189023078129
Validation loss: 2.518349319531816

Epoch: 6| Step: 10
Training loss: 0.6981899428662519
Validation loss: 2.6076104828130675

Epoch: 6| Step: 11
Training loss: 1.5901993487405097
Validation loss: 2.530725354112411

Epoch: 6| Step: 12
Training loss: 0.9285222292012452
Validation loss: 2.6762821369121346

Epoch: 6| Step: 13
Training loss: 0.776779583498058
Validation loss: 2.643356370292359

Epoch: 141| Step: 0
Training loss: 0.6762855941021628
Validation loss: 2.5987632438709967

Epoch: 6| Step: 1
Training loss: 0.8800684725608393
Validation loss: 2.6198066321691917

Epoch: 6| Step: 2
Training loss: 0.9370995938043851
Validation loss: 2.5151041411774213

Epoch: 6| Step: 3
Training loss: 0.4201629301641686
Validation loss: 2.620963156375076

Epoch: 6| Step: 4
Training loss: 0.842108684241881
Validation loss: 2.53511129612734

Epoch: 6| Step: 5
Training loss: 0.6729454783323369
Validation loss: 2.492061958618886

Epoch: 6| Step: 6
Training loss: 0.4957791028966616
Validation loss: 2.6202754161184267

Epoch: 6| Step: 7
Training loss: 0.6708379548863345
Validation loss: 2.478490742667982

Epoch: 6| Step: 8
Training loss: 0.8446664424957162
Validation loss: 2.510818090568771

Epoch: 6| Step: 9
Training loss: 0.6439150089518876
Validation loss: 2.6524853450862875

Epoch: 6| Step: 10
Training loss: 0.8203963463938584
Validation loss: 2.674989160771261

Epoch: 6| Step: 11
Training loss: 0.37725898706817784
Validation loss: 2.660055284642661

Epoch: 6| Step: 12
Training loss: 1.643204396137237
Validation loss: 2.650462408927947

Epoch: 6| Step: 13
Training loss: 0.5139313829167671
Validation loss: 2.591721488356459

Epoch: 142| Step: 0
Training loss: 0.40460664979879085
Validation loss: 2.577132509873061

Epoch: 6| Step: 1
Training loss: 0.47339309446365174
Validation loss: 2.499466775613192

Epoch: 6| Step: 2
Training loss: 1.5705109276353417
Validation loss: 2.548712062020144

Epoch: 6| Step: 3
Training loss: 0.6747991227667172
Validation loss: 2.454914881686737

Epoch: 6| Step: 4
Training loss: 0.575171167355864
Validation loss: 2.5021871695040465

Epoch: 6| Step: 5
Training loss: 0.6013443786716134
Validation loss: 2.550220305145121

Epoch: 6| Step: 6
Training loss: 0.5172037750172753
Validation loss: 2.4754585027656173

Epoch: 6| Step: 7
Training loss: 0.5255781498462816
Validation loss: 2.5617607027174425

Epoch: 6| Step: 8
Training loss: 0.4053533819929204
Validation loss: 2.5202017273970965

Epoch: 6| Step: 9
Training loss: 1.2157342229184578
Validation loss: 2.5824361032642074

Epoch: 6| Step: 10
Training loss: 0.9239561222111602
Validation loss: 2.552810819571366

Epoch: 6| Step: 11
Training loss: 0.6202458285768425
Validation loss: 2.6047305348606864

Epoch: 6| Step: 12
Training loss: 0.6039753863201535
Validation loss: 2.5578415480828314

Epoch: 6| Step: 13
Training loss: 0.6069048923080278
Validation loss: 2.6223471648704613

Epoch: 143| Step: 0
Training loss: 0.49628997286218035
Validation loss: 2.5601382032481435

Epoch: 6| Step: 1
Training loss: 0.3991110102026325
Validation loss: 2.674114649421169

Epoch: 6| Step: 2
Training loss: 0.49868140097843644
Validation loss: 2.6257202885913586

Epoch: 6| Step: 3
Training loss: 0.9031857611996015
Validation loss: 2.6116524996329646

Epoch: 6| Step: 4
Training loss: 0.5304535898730598
Validation loss: 2.6310482132013897

Epoch: 6| Step: 5
Training loss: 0.630870240298026
Validation loss: 2.650403923464204

Epoch: 6| Step: 6
Training loss: 0.5048362666206785
Validation loss: 2.6119445742709035

Epoch: 6| Step: 7
Training loss: 0.7309549926647841
Validation loss: 2.5471201039580613

Epoch: 6| Step: 8
Training loss: 0.642271507875659
Validation loss: 2.4943194702359976

Epoch: 6| Step: 9
Training loss: 0.45534304655786634
Validation loss: 2.539624626339263

Epoch: 6| Step: 10
Training loss: 1.5095800604044662
Validation loss: 2.5833043025036564

Epoch: 6| Step: 11
Training loss: 0.935539611915635
Validation loss: 2.639252473367559

Epoch: 6| Step: 12
Training loss: 0.9091835554554873
Validation loss: 2.5116231612412028

Epoch: 6| Step: 13
Training loss: 0.7253704752303521
Validation loss: 2.6066304771499826

Epoch: 144| Step: 0
Training loss: 0.7487809685239736
Validation loss: 2.6075378163595473

Epoch: 6| Step: 1
Training loss: 0.8221241881447882
Validation loss: 2.541048996295967

Epoch: 6| Step: 2
Training loss: 1.5739642143350026
Validation loss: 2.6037342831556507

Epoch: 6| Step: 3
Training loss: 0.6949276877251823
Validation loss: 2.5809579870338735

Epoch: 6| Step: 4
Training loss: 0.7317231774791855
Validation loss: 2.5545786952064415

Epoch: 6| Step: 5
Training loss: 0.8586592034060976
Validation loss: 2.5262399942991745

Epoch: 6| Step: 6
Training loss: 0.6482638390796517
Validation loss: 2.5313763214113405

Epoch: 6| Step: 7
Training loss: 0.9439543749080032
Validation loss: 2.6029346959777264

Epoch: 6| Step: 8
Training loss: 0.6187450938560104
Validation loss: 2.5743941622116067

Epoch: 6| Step: 9
Training loss: 0.7776286307640898
Validation loss: 2.613587928343281

Epoch: 6| Step: 10
Training loss: 0.7121649406043783
Validation loss: 2.5454895057898996

Epoch: 6| Step: 11
Training loss: 0.4731891717313138
Validation loss: 2.5444520998325526

Epoch: 6| Step: 12
Training loss: 0.4958156947864051
Validation loss: 2.4848509038795683

Epoch: 6| Step: 13
Training loss: 0.5559350075539892
Validation loss: 2.5281129243402773

Epoch: 145| Step: 0
Training loss: 0.8045740140127932
Validation loss: 2.481550758640522

Epoch: 6| Step: 1
Training loss: 0.6170691847569041
Validation loss: 2.5187099015015515

Epoch: 6| Step: 2
Training loss: 0.9602094543962534
Validation loss: 2.563129518299202

Epoch: 6| Step: 3
Training loss: 0.8444465305347219
Validation loss: 2.6114864524866293

Epoch: 6| Step: 4
Training loss: 0.4305667551012847
Validation loss: 2.580296359192467

Epoch: 6| Step: 5
Training loss: 0.5072138852667676
Validation loss: 2.5455853838342937

Epoch: 6| Step: 6
Training loss: 0.556586654455941
Validation loss: 2.6146463687993315

Epoch: 6| Step: 7
Training loss: 0.6860632622551156
Validation loss: 2.5132101326966616

Epoch: 6| Step: 8
Training loss: 0.8632212829475346
Validation loss: 2.5369682869899473

Epoch: 6| Step: 9
Training loss: 0.8247620297167764
Validation loss: 2.551107450991932

Epoch: 6| Step: 10
Training loss: 0.9290992735184386
Validation loss: 2.5627073188591387

Epoch: 6| Step: 11
Training loss: 1.6224086346639157
Validation loss: 2.5989192788980864

Epoch: 6| Step: 12
Training loss: 0.583813135053434
Validation loss: 2.626943247420827

Epoch: 6| Step: 13
Training loss: 0.7322958876016518
Validation loss: 2.6586508129840323

Epoch: 146| Step: 0
Training loss: 0.7978304950075787
Validation loss: 2.6682490159253947

Epoch: 6| Step: 1
Training loss: 0.591940506731029
Validation loss: 2.592994848114066

Epoch: 6| Step: 2
Training loss: 0.6968395309659241
Validation loss: 2.542359497404161

Epoch: 6| Step: 3
Training loss: 0.8451137118601976
Validation loss: 2.5475289377023347

Epoch: 6| Step: 4
Training loss: 0.4918141841493587
Validation loss: 2.5297134193881696

Epoch: 6| Step: 5
Training loss: 0.8805655858591401
Validation loss: 2.482780464658689

Epoch: 6| Step: 6
Training loss: 1.6999093592546035
Validation loss: 2.502371457990899

Epoch: 6| Step: 7
Training loss: 0.5473165092256075
Validation loss: 2.5343780890719163

Epoch: 6| Step: 8
Training loss: 0.9157597361304038
Validation loss: 2.584010025323842

Epoch: 6| Step: 9
Training loss: 0.6148025692789899
Validation loss: 2.5977773996655085

Epoch: 6| Step: 10
Training loss: 0.5718496327428296
Validation loss: 2.5718913538595554

Epoch: 6| Step: 11
Training loss: 0.6109163890420497
Validation loss: 2.5889296723793023

Epoch: 6| Step: 12
Training loss: 0.5120460104422697
Validation loss: 2.480743088657468

Epoch: 6| Step: 13
Training loss: 0.7059373560242931
Validation loss: 2.525981710974337

Epoch: 147| Step: 0
Training loss: 0.7941673503231003
Validation loss: 2.520319063887983

Epoch: 6| Step: 1
Training loss: 0.7104399061084232
Validation loss: 2.554797925516555

Epoch: 6| Step: 2
Training loss: 0.6702041031483901
Validation loss: 2.5089092926205234

Epoch: 6| Step: 3
Training loss: 0.9801428203736053
Validation loss: 2.5931329567714303

Epoch: 6| Step: 4
Training loss: 0.4757789361205312
Validation loss: 2.5307143158655854

Epoch: 6| Step: 5
Training loss: 0.48644148030246154
Validation loss: 2.551937664831241

Epoch: 6| Step: 6
Training loss: 0.7207174739081207
Validation loss: 2.578235777969908

Epoch: 6| Step: 7
Training loss: 0.68711139793597
Validation loss: 2.631982372506081

Epoch: 6| Step: 8
Training loss: 0.6280547354194782
Validation loss: 2.603687308379774

Epoch: 6| Step: 9
Training loss: 0.5545022144600186
Validation loss: 2.5479692943894694

Epoch: 6| Step: 10
Training loss: 1.561594967996002
Validation loss: 2.5217203255907337

Epoch: 6| Step: 11
Training loss: 1.0793944914912799
Validation loss: 2.5199305018423823

Epoch: 6| Step: 12
Training loss: 0.6234000947673164
Validation loss: 2.5099814949265378

Epoch: 6| Step: 13
Training loss: 0.381478046784264
Validation loss: 2.548420115586422

Epoch: 148| Step: 0
Training loss: 0.6660336131242479
Validation loss: 2.5461441426783376

Epoch: 6| Step: 1
Training loss: 0.7327947455819582
Validation loss: 2.604467501748014

Epoch: 6| Step: 2
Training loss: 0.7055625836225925
Validation loss: 2.5433872111035436

Epoch: 6| Step: 3
Training loss: 0.6820385053146054
Validation loss: 2.514177478526378

Epoch: 6| Step: 4
Training loss: 0.770577585907292
Validation loss: 2.505920028844445

Epoch: 6| Step: 5
Training loss: 0.921950224054093
Validation loss: 2.5260145887254124

Epoch: 6| Step: 6
Training loss: 0.5690602179643353
Validation loss: 2.5107767287452267

Epoch: 6| Step: 7
Training loss: 0.5248557846356724
Validation loss: 2.5355731012068095

Epoch: 6| Step: 8
Training loss: 0.48212352592830404
Validation loss: 2.57196297261424

Epoch: 6| Step: 9
Training loss: 1.475833369678143
Validation loss: 2.5237298723249224

Epoch: 6| Step: 10
Training loss: 0.6157269156276148
Validation loss: 2.532037071025952

Epoch: 6| Step: 11
Training loss: 0.5696153691130377
Validation loss: 2.5697267400185755

Epoch: 6| Step: 12
Training loss: 0.5993069560198029
Validation loss: 2.528585774382536

Epoch: 6| Step: 13
Training loss: 0.5409135687794254
Validation loss: 2.5195693533132997

Epoch: 149| Step: 0
Training loss: 0.680454720003216
Validation loss: 2.461843802067259

Epoch: 6| Step: 1
Training loss: 0.42825825281202495
Validation loss: 2.5453245284059935

Epoch: 6| Step: 2
Training loss: 0.3784144444455342
Validation loss: 2.532929008827401

Epoch: 6| Step: 3
Training loss: 0.4819542784730388
Validation loss: 2.63554542337546

Epoch: 6| Step: 4
Training loss: 0.9683486045370774
Validation loss: 2.57940466362525

Epoch: 6| Step: 5
Training loss: 0.5821925202264324
Validation loss: 2.630500797340491

Epoch: 6| Step: 6
Training loss: 1.5408368411865796
Validation loss: 2.577346776779539

Epoch: 6| Step: 7
Training loss: 0.5788072220792652
Validation loss: 2.6223379290999396

Epoch: 6| Step: 8
Training loss: 0.46210720871121735
Validation loss: 2.601401200893052

Epoch: 6| Step: 9
Training loss: 0.48877105560217465
Validation loss: 2.5711583424107416

Epoch: 6| Step: 10
Training loss: 0.740254746612203
Validation loss: 2.551992583445432

Epoch: 6| Step: 11
Training loss: 0.6819465628325826
Validation loss: 2.506993794916785

Epoch: 6| Step: 12
Training loss: 0.8191699836355936
Validation loss: 2.541706488771585

Epoch: 6| Step: 13
Training loss: 0.6473178388937653
Validation loss: 2.5491773655959853

Epoch: 150| Step: 0
Training loss: 0.6567952071125936
Validation loss: 2.528002865752475

Epoch: 6| Step: 1
Training loss: 0.6276725373019751
Validation loss: 2.478296116376528

Epoch: 6| Step: 2
Training loss: 0.9601731400521281
Validation loss: 2.554241005301627

Epoch: 6| Step: 3
Training loss: 0.443182569699884
Validation loss: 2.5682803839271893

Epoch: 6| Step: 4
Training loss: 1.4968409651866945
Validation loss: 2.52517567895273

Epoch: 6| Step: 5
Training loss: 0.5473883263254372
Validation loss: 2.528578207655002

Epoch: 6| Step: 6
Training loss: 0.9706384034714365
Validation loss: 2.5400692552851982

Epoch: 6| Step: 7
Training loss: 0.481853304497033
Validation loss: 2.5605010710653606

Epoch: 6| Step: 8
Training loss: 0.5582920940551367
Validation loss: 2.5094531942166265

Epoch: 6| Step: 9
Training loss: 0.4181021896264367
Validation loss: 2.60911261025445

Epoch: 6| Step: 10
Training loss: 0.5449963317100193
Validation loss: 2.5451159497161604

Epoch: 6| Step: 11
Training loss: 0.6172212519048157
Validation loss: 2.5834301550984446

Epoch: 6| Step: 12
Training loss: 0.5681904545040941
Validation loss: 2.6071423479566183

Epoch: 6| Step: 13
Training loss: 0.5506935049735553
Validation loss: 2.531440774769171

Epoch: 151| Step: 0
Training loss: 0.9702306322829904
Validation loss: 2.5709875238838698

Epoch: 6| Step: 1
Training loss: 0.5454819784797722
Validation loss: 2.5717229557943564

Epoch: 6| Step: 2
Training loss: 0.5061767054116976
Validation loss: 2.5164048307095648

Epoch: 6| Step: 3
Training loss: 0.7541160884427377
Validation loss: 2.530836974304548

Epoch: 6| Step: 4
Training loss: 1.543917825202029
Validation loss: 2.4856654960051845

Epoch: 6| Step: 5
Training loss: 0.6511183324814097
Validation loss: 2.529029248781561

Epoch: 6| Step: 6
Training loss: 0.3822326550512255
Validation loss: 2.5922948746443057

Epoch: 6| Step: 7
Training loss: 0.47803685117468603
Validation loss: 2.604933867295403

Epoch: 6| Step: 8
Training loss: 0.803329247356117
Validation loss: 2.620559804760315

Epoch: 6| Step: 9
Training loss: 0.4332190948377089
Validation loss: 2.623348943000636

Epoch: 6| Step: 10
Training loss: 0.8114719122034949
Validation loss: 2.6201178851312124

Epoch: 6| Step: 11
Training loss: 0.3840885886324351
Validation loss: 2.551555599741376

Epoch: 6| Step: 12
Training loss: 0.3293533154647792
Validation loss: 2.519248706046683

Epoch: 6| Step: 13
Training loss: 0.5899022054443157
Validation loss: 2.55359980363861

Epoch: 152| Step: 0
Training loss: 0.8495668247134995
Validation loss: 2.5426260956109745

Epoch: 6| Step: 1
Training loss: 0.6979382687162448
Validation loss: 2.4833197441838686

Epoch: 6| Step: 2
Training loss: 0.5620982006624445
Validation loss: 2.5679742444579903

Epoch: 6| Step: 3
Training loss: 0.4518081010337057
Validation loss: 2.5629699245131503

Epoch: 6| Step: 4
Training loss: 0.6783856387635281
Validation loss: 2.5404646850656025

Epoch: 6| Step: 5
Training loss: 0.562831357208991
Validation loss: 2.6218355420628936

Epoch: 6| Step: 6
Training loss: 0.3738612926601534
Validation loss: 2.594505935265175

Epoch: 6| Step: 7
Training loss: 0.488174091024564
Validation loss: 2.5874593507334955

Epoch: 6| Step: 8
Training loss: 0.49693142012795555
Validation loss: 2.561136371368912

Epoch: 6| Step: 9
Training loss: 0.4338096905732618
Validation loss: 2.585209662434305

Epoch: 6| Step: 10
Training loss: 1.5479389731578477
Validation loss: 2.5075472397314598

Epoch: 6| Step: 11
Training loss: 0.5007267081661458
Validation loss: 2.53201400937719

Epoch: 6| Step: 12
Training loss: 0.6131742590618833
Validation loss: 2.4852772000223085

Epoch: 6| Step: 13
Training loss: 0.5113976322780157
Validation loss: 2.529642450199723

Epoch: 153| Step: 0
Training loss: 1.4436053942637974
Validation loss: 2.616423052079538

Epoch: 6| Step: 1
Training loss: 0.31210337741708644
Validation loss: 2.59771295547737

Epoch: 6| Step: 2
Training loss: 0.5997720802062108
Validation loss: 2.524595154514602

Epoch: 6| Step: 3
Training loss: 0.5102109754106372
Validation loss: 2.556432394470658

Epoch: 6| Step: 4
Training loss: 0.9646395880414311
Validation loss: 2.564766974321129

Epoch: 6| Step: 5
Training loss: 0.4784783952204385
Validation loss: 2.5510699745020933

Epoch: 6| Step: 6
Training loss: 0.6409151769179395
Validation loss: 2.584927964009214

Epoch: 6| Step: 7
Training loss: 0.5970704941878762
Validation loss: 2.527928649733938

Epoch: 6| Step: 8
Training loss: 0.5366571360486185
Validation loss: 2.5561441979434836

Epoch: 6| Step: 9
Training loss: 0.4092388975143981
Validation loss: 2.542463909769491

Epoch: 6| Step: 10
Training loss: 0.45471935291734
Validation loss: 2.6483978898678804

Epoch: 6| Step: 11
Training loss: 0.7178162853920038
Validation loss: 2.640285688340815

Epoch: 6| Step: 12
Training loss: 0.9888140783753652
Validation loss: 2.6859182390014684

Epoch: 6| Step: 13
Training loss: 0.6287102008683724
Validation loss: 2.6350041671010604

Epoch: 154| Step: 0
Training loss: 0.4431448093769701
Validation loss: 2.5889618888771833

Epoch: 6| Step: 1
Training loss: 1.502178914295767
Validation loss: 2.550846396953535

Epoch: 6| Step: 2
Training loss: 0.6846510639533149
Validation loss: 2.5852659646211986

Epoch: 6| Step: 3
Training loss: 0.6247531641864369
Validation loss: 2.5454608993404526

Epoch: 6| Step: 4
Training loss: 0.41744655895270166
Validation loss: 2.542914644399188

Epoch: 6| Step: 5
Training loss: 0.4957098789822124
Validation loss: 2.5079138191647665

Epoch: 6| Step: 6
Training loss: 0.7241836489964095
Validation loss: 2.5522579107454337

Epoch: 6| Step: 7
Training loss: 0.3996687172897287
Validation loss: 2.5897152323645956

Epoch: 6| Step: 8
Training loss: 0.473923458311408
Validation loss: 2.593293835462564

Epoch: 6| Step: 9
Training loss: 0.9067987556401866
Validation loss: 2.6407591053995536

Epoch: 6| Step: 10
Training loss: 0.9462463873185769
Validation loss: 2.6020830949020173

Epoch: 6| Step: 11
Training loss: 0.5215301207862143
Validation loss: 2.545186557702124

Epoch: 6| Step: 12
Training loss: 0.6163715812110198
Validation loss: 2.504299805371253

Epoch: 6| Step: 13
Training loss: 0.639037304780295
Validation loss: 2.482204712884056

Epoch: 155| Step: 0
Training loss: 0.49788033187907405
Validation loss: 2.4942738998520624

Epoch: 6| Step: 1
Training loss: 0.5084716333843592
Validation loss: 2.463369405152845

Epoch: 6| Step: 2
Training loss: 0.7186169708541266
Validation loss: 2.486716568482777

Epoch: 6| Step: 3
Training loss: 0.4864486177387766
Validation loss: 2.534286624168773

Epoch: 6| Step: 4
Training loss: 0.4288504684112115
Validation loss: 2.495394390357307

Epoch: 6| Step: 5
Training loss: 0.7428753927564538
Validation loss: 2.56626745397371

Epoch: 6| Step: 6
Training loss: 0.8951858723886719
Validation loss: 2.5915083562902805

Epoch: 6| Step: 7
Training loss: 0.5667235439403834
Validation loss: 2.4997618402846116

Epoch: 6| Step: 8
Training loss: 0.9659190807233925
Validation loss: 2.492300479444661

Epoch: 6| Step: 9
Training loss: 0.47257008042932314
Validation loss: 2.5064991713762894

Epoch: 6| Step: 10
Training loss: 0.30679367279409864
Validation loss: 2.539485594882155

Epoch: 6| Step: 11
Training loss: 0.4178411342421147
Validation loss: 2.5415758731655465

Epoch: 6| Step: 12
Training loss: 1.4346597226859967
Validation loss: 2.5762847189281284

Epoch: 6| Step: 13
Training loss: 0.36128257258126695
Validation loss: 2.5015405756005307

Epoch: 156| Step: 0
Training loss: 1.4448081296364659
Validation loss: 2.5408591149676636

Epoch: 6| Step: 1
Training loss: 0.655470566866406
Validation loss: 2.5671361681650393

Epoch: 6| Step: 2
Training loss: 0.7074015790870477
Validation loss: 2.5958683295261054

Epoch: 6| Step: 3
Training loss: 0.5031988516206934
Validation loss: 2.537929591253131

Epoch: 6| Step: 4
Training loss: 0.5493981872716854
Validation loss: 2.4876418796888813

Epoch: 6| Step: 5
Training loss: 0.4036007107360752
Validation loss: 2.5394930508728746

Epoch: 6| Step: 6
Training loss: 0.5689830700713885
Validation loss: 2.5325402162301627

Epoch: 6| Step: 7
Training loss: 0.5460607734295729
Validation loss: 2.5347169751210243

Epoch: 6| Step: 8
Training loss: 0.41883820273825706
Validation loss: 2.561439092956072

Epoch: 6| Step: 9
Training loss: 0.5249907379241642
Validation loss: 2.475490478440811

Epoch: 6| Step: 10
Training loss: 0.48905328370206674
Validation loss: 2.5902593479631513

Epoch: 6| Step: 11
Training loss: 0.7665304940684304
Validation loss: 2.611543230447693

Epoch: 6| Step: 12
Training loss: 0.5170602186612163
Validation loss: 2.656624053348473

Epoch: 6| Step: 13
Training loss: 1.0593094887071437
Validation loss: 2.5883605607126308

Epoch: 157| Step: 0
Training loss: 0.42116097672673014
Validation loss: 2.5482214428538326

Epoch: 6| Step: 1
Training loss: 0.5863216158348639
Validation loss: 2.5286152631887195

Epoch: 6| Step: 2
Training loss: 0.5784761805613278
Validation loss: 2.4985197294284673

Epoch: 6| Step: 3
Training loss: 0.5752198711132954
Validation loss: 2.537685251598917

Epoch: 6| Step: 4
Training loss: 0.5249541217194873
Validation loss: 2.509913735775423

Epoch: 6| Step: 5
Training loss: 0.6770061351098071
Validation loss: 2.618554285060362

Epoch: 6| Step: 6
Training loss: 0.6031590368124373
Validation loss: 2.5915543175128133

Epoch: 6| Step: 7
Training loss: 0.6657365454754934
Validation loss: 2.6279959158205206

Epoch: 6| Step: 8
Training loss: 0.600104037841437
Validation loss: 2.600070972574346

Epoch: 6| Step: 9
Training loss: 0.7096320102621558
Validation loss: 2.5773752760040662

Epoch: 6| Step: 10
Training loss: 0.3650274659626793
Validation loss: 2.598223034970848

Epoch: 6| Step: 11
Training loss: 0.6293883992940359
Validation loss: 2.546266416766117

Epoch: 6| Step: 12
Training loss: 1.6281533090542868
Validation loss: 2.563503673591757

Epoch: 6| Step: 13
Training loss: 0.4587115511776018
Validation loss: 2.5195903288151826

Epoch: 158| Step: 0
Training loss: 0.6200202685934715
Validation loss: 2.6512998044307334

Epoch: 6| Step: 1
Training loss: 1.5321054210147895
Validation loss: 2.5595362356693263

Epoch: 6| Step: 2
Training loss: 0.5028048758583699
Validation loss: 2.559952702606896

Epoch: 6| Step: 3
Training loss: 0.4153994801689315
Validation loss: 2.5903441500462665

Epoch: 6| Step: 4
Training loss: 0.5107368191788857
Validation loss: 2.5399863103062126

Epoch: 6| Step: 5
Training loss: 0.5556015220805247
Validation loss: 2.524466683622054

Epoch: 6| Step: 6
Training loss: 0.3088243081947199
Validation loss: 2.536943053837774

Epoch: 6| Step: 7
Training loss: 0.6009018726073384
Validation loss: 2.5004265898096714

Epoch: 6| Step: 8
Training loss: 0.6283157609342496
Validation loss: 2.5159460459181697

Epoch: 6| Step: 9
Training loss: 0.8546781675397601
Validation loss: 2.474326487135723

Epoch: 6| Step: 10
Training loss: 0.5766100752722649
Validation loss: 2.5692523211457905

Epoch: 6| Step: 11
Training loss: 0.38260514618647556
Validation loss: 2.5622069338555344

Epoch: 6| Step: 12
Training loss: 0.63507905704497
Validation loss: 2.516992375052735

Epoch: 6| Step: 13
Training loss: 0.6153503793009945
Validation loss: 2.5158841649223374

Epoch: 159| Step: 0
Training loss: 0.4808140576078414
Validation loss: 2.48005690472188

Epoch: 6| Step: 1
Training loss: 0.5867027117979097
Validation loss: 2.585365708551075

Epoch: 6| Step: 2
Training loss: 0.40865242793842554
Validation loss: 2.4734393301543554

Epoch: 6| Step: 3
Training loss: 0.5470197486049712
Validation loss: 2.501834593602327

Epoch: 6| Step: 4
Training loss: 0.848316410198178
Validation loss: 2.5400329456795903

Epoch: 6| Step: 5
Training loss: 0.503974495931226
Validation loss: 2.563444800770496

Epoch: 6| Step: 6
Training loss: 1.3967074982919336
Validation loss: 2.5568604633418803

Epoch: 6| Step: 7
Training loss: 0.7646711207273691
Validation loss: 2.5783495256161677

Epoch: 6| Step: 8
Training loss: 0.7469456387876728
Validation loss: 2.530278156668236

Epoch: 6| Step: 9
Training loss: 0.5456045106709052
Validation loss: 2.494016560112804

Epoch: 6| Step: 10
Training loss: 0.34520208828897797
Validation loss: 2.4413760577560186

Epoch: 6| Step: 11
Training loss: 0.4709404627979539
Validation loss: 2.50454818741119

Epoch: 6| Step: 12
Training loss: 0.3478876693809058
Validation loss: 2.4816263456337593

Epoch: 6| Step: 13
Training loss: 0.5744507509076415
Validation loss: 2.593231946079603

Epoch: 160| Step: 0
Training loss: 0.3346887711715422
Validation loss: 2.4909324076571004

Epoch: 6| Step: 1
Training loss: 0.4871477474464397
Validation loss: 2.5476333955599264

Epoch: 6| Step: 2
Training loss: 0.47282661961502126
Validation loss: 2.5273642050275487

Epoch: 6| Step: 3
Training loss: 0.6161878917030044
Validation loss: 2.6283021622984237

Epoch: 6| Step: 4
Training loss: 0.3033184078473621
Validation loss: 2.61049938532587

Epoch: 6| Step: 5
Training loss: 0.5878058844543397
Validation loss: 2.60265093879641

Epoch: 6| Step: 6
Training loss: 0.4574361458497866
Validation loss: 2.5311890269027564

Epoch: 6| Step: 7
Training loss: 0.4692647968148131
Validation loss: 2.6160066436329354

Epoch: 6| Step: 8
Training loss: 0.5021267008222017
Validation loss: 2.5864722475949433

Epoch: 6| Step: 9
Training loss: 1.5962449534791232
Validation loss: 2.638597917967424

Epoch: 6| Step: 10
Training loss: 0.809280214687819
Validation loss: 2.594438484460963

Epoch: 6| Step: 11
Training loss: 0.6613451392772892
Validation loss: 2.5862612027097263

Epoch: 6| Step: 12
Training loss: 0.5909881605585768
Validation loss: 2.5636749365208655

Epoch: 6| Step: 13
Training loss: 0.5304240369422039
Validation loss: 2.5489797417963196

Epoch: 161| Step: 0
Training loss: 0.826446343320458
Validation loss: 2.5143363526885967

Epoch: 6| Step: 1
Training loss: 0.33829978469218214
Validation loss: 2.467930444458576

Epoch: 6| Step: 2
Training loss: 0.7440931650481221
Validation loss: 2.5858858147533597

Epoch: 6| Step: 3
Training loss: 1.4074786434958695
Validation loss: 2.52327756896524

Epoch: 6| Step: 4
Training loss: 0.338337442959567
Validation loss: 2.5228376275892703

Epoch: 6| Step: 5
Training loss: 0.5470312167889243
Validation loss: 2.4877897343038957

Epoch: 6| Step: 6
Training loss: 0.3527179274837975
Validation loss: 2.4528540038402347

Epoch: 6| Step: 7
Training loss: 0.47511829358842234
Validation loss: 2.574922533937875

Epoch: 6| Step: 8
Training loss: 0.538804116728461
Validation loss: 2.451837894490515

Epoch: 6| Step: 9
Training loss: 0.7628964441002306
Validation loss: 2.479734248950744

Epoch: 6| Step: 10
Training loss: 0.3646975156819207
Validation loss: 2.5523212763093968

Epoch: 6| Step: 11
Training loss: 0.6364293523164086
Validation loss: 2.4807339263705903

Epoch: 6| Step: 12
Training loss: 0.5312225110290979
Validation loss: 2.5676240629923655

Epoch: 6| Step: 13
Training loss: 0.6778481907327346
Validation loss: 2.5761728467498406

Epoch: 162| Step: 0
Training loss: 0.4664646386894124
Validation loss: 2.6030677969250795

Epoch: 6| Step: 1
Training loss: 0.40992741331848886
Validation loss: 2.558290148089944

Epoch: 6| Step: 2
Training loss: 0.5716220504748043
Validation loss: 2.5003724694939975

Epoch: 6| Step: 3
Training loss: 0.6893258774341562
Validation loss: 2.4958002099931607

Epoch: 6| Step: 4
Training loss: 0.518575549379525
Validation loss: 2.5322471350066986

Epoch: 6| Step: 5
Training loss: 0.4728242874945314
Validation loss: 2.5844957264290285

Epoch: 6| Step: 6
Training loss: 0.5357819957177287
Validation loss: 2.609905029191353

Epoch: 6| Step: 7
Training loss: 1.374825076333954
Validation loss: 2.6020280576097754

Epoch: 6| Step: 8
Training loss: 0.5711215825219704
Validation loss: 2.6049255384369796

Epoch: 6| Step: 9
Training loss: 0.48373287461399095
Validation loss: 2.6503700549780556

Epoch: 6| Step: 10
Training loss: 0.40533637971318853
Validation loss: 2.580098038740216

Epoch: 6| Step: 11
Training loss: 0.6224678242652253
Validation loss: 2.550478766880371

Epoch: 6| Step: 12
Training loss: 0.9375010172520523
Validation loss: 2.5373749509544825

Epoch: 6| Step: 13
Training loss: 0.5198704752173673
Validation loss: 2.5027772180041743

Epoch: 163| Step: 0
Training loss: 0.6548049093135828
Validation loss: 2.4783020248137193

Epoch: 6| Step: 1
Training loss: 0.7961361395544234
Validation loss: 2.4987537456647857

Epoch: 6| Step: 2
Training loss: 1.400888436977426
Validation loss: 2.5134194856730336

Epoch: 6| Step: 3
Training loss: 0.5157486738371891
Validation loss: 2.5797906600439626

Epoch: 6| Step: 4
Training loss: 0.5390474621430575
Validation loss: 2.5978485418675503

Epoch: 6| Step: 5
Training loss: 0.49370646345162356
Validation loss: 2.5424415053518903

Epoch: 6| Step: 6
Training loss: 0.416858160202102
Validation loss: 2.610455766970065

Epoch: 6| Step: 7
Training loss: 0.3144910090591058
Validation loss: 2.5547429816611302

Epoch: 6| Step: 8
Training loss: 0.6682037475540221
Validation loss: 2.502666656529029

Epoch: 6| Step: 9
Training loss: 0.6167520846241581
Validation loss: 2.474373348293667

Epoch: 6| Step: 10
Training loss: 0.5745081788452795
Validation loss: 2.4674444327753413

Epoch: 6| Step: 11
Training loss: 0.5051446527152184
Validation loss: 2.435766304530309

Epoch: 6| Step: 12
Training loss: 0.377691109831466
Validation loss: 2.542403158721038

Epoch: 6| Step: 13
Training loss: 0.6447886328761926
Validation loss: 2.505593463905095

Epoch: 164| Step: 0
Training loss: 0.6960026177241985
Validation loss: 2.5587925724500176

Epoch: 6| Step: 1
Training loss: 0.38269255179709666
Validation loss: 2.5977202366952814

Epoch: 6| Step: 2
Training loss: 0.384489357226821
Validation loss: 2.5084258504980164

Epoch: 6| Step: 3
Training loss: 0.4857838353983637
Validation loss: 2.5310791334715357

Epoch: 6| Step: 4
Training loss: 0.5003787930449887
Validation loss: 2.5890648285681306

Epoch: 6| Step: 5
Training loss: 0.7606702582029072
Validation loss: 2.4327706975495813

Epoch: 6| Step: 6
Training loss: 0.5336490764391547
Validation loss: 2.617231180765965

Epoch: 6| Step: 7
Training loss: 0.6146184835780933
Validation loss: 2.5585925269669967

Epoch: 6| Step: 8
Training loss: 0.33629612299671946
Validation loss: 2.595714667614871

Epoch: 6| Step: 9
Training loss: 0.5699740411469011
Validation loss: 2.5371060468041544

Epoch: 6| Step: 10
Training loss: 0.47131052043455063
Validation loss: 2.5770349529374443

Epoch: 6| Step: 11
Training loss: 1.3088813579551721
Validation loss: 2.506105549138392

Epoch: 6| Step: 12
Training loss: 0.4189244156185217
Validation loss: 2.5634865606203836

Epoch: 6| Step: 13
Training loss: 0.7303442211387093
Validation loss: 2.5323150654607094

Epoch: 165| Step: 0
Training loss: 0.31507157585437295
Validation loss: 2.51307196425106

Epoch: 6| Step: 1
Training loss: 0.5852505535333322
Validation loss: 2.5605544558872846

Epoch: 6| Step: 2
Training loss: 0.3083501167927461
Validation loss: 2.5660525871313515

Epoch: 6| Step: 3
Training loss: 0.3299556595280942
Validation loss: 2.5925343740324753

Epoch: 6| Step: 4
Training loss: 0.597244320196942
Validation loss: 2.537882322251142

Epoch: 6| Step: 5
Training loss: 0.3811512928742239
Validation loss: 2.5383690146202853

Epoch: 6| Step: 6
Training loss: 0.6558310215758604
Validation loss: 2.5253455051562153

Epoch: 6| Step: 7
Training loss: 0.5925146603279553
Validation loss: 2.539562187909996

Epoch: 6| Step: 8
Training loss: 0.3408821727500226
Validation loss: 2.5348985224570364

Epoch: 6| Step: 9
Training loss: 0.5154859470945767
Validation loss: 2.567546867777341

Epoch: 6| Step: 10
Training loss: 1.3680837255031477
Validation loss: 2.611209795374356

Epoch: 6| Step: 11
Training loss: 0.7463515470413977
Validation loss: 2.512388987326591

Epoch: 6| Step: 12
Training loss: 0.5446373801882874
Validation loss: 2.57651637591056

Epoch: 6| Step: 13
Training loss: 0.5133311951373928
Validation loss: 2.5746033322871043

Epoch: 166| Step: 0
Training loss: 0.47058784687766003
Validation loss: 2.5470139947263877

Epoch: 6| Step: 1
Training loss: 0.480423514244838
Validation loss: 2.554661936345264

Epoch: 6| Step: 2
Training loss: 0.36462110142132453
Validation loss: 2.5595055350837295

Epoch: 6| Step: 3
Training loss: 1.2809156121056526
Validation loss: 2.450133068337604

Epoch: 6| Step: 4
Training loss: 0.4690793787532644
Validation loss: 2.514875185721529

Epoch: 6| Step: 5
Training loss: 0.49391799555578764
Validation loss: 2.515222236820054

Epoch: 6| Step: 6
Training loss: 0.748888264660366
Validation loss: 2.4766652981415054

Epoch: 6| Step: 7
Training loss: 0.5115458363759271
Validation loss: 2.5490832750394277

Epoch: 6| Step: 8
Training loss: 0.8862054826561256
Validation loss: 2.517461086933388

Epoch: 6| Step: 9
Training loss: 0.4194688171589009
Validation loss: 2.5514591829181135

Epoch: 6| Step: 10
Training loss: 0.6386217803440853
Validation loss: 2.5774721725520635

Epoch: 6| Step: 11
Training loss: 0.37295085609957623
Validation loss: 2.5955032221904504

Epoch: 6| Step: 12
Training loss: 0.5276747618351683
Validation loss: 2.591901373175971

Epoch: 6| Step: 13
Training loss: 0.29971938519514446
Validation loss: 2.5476338400854823

Epoch: 167| Step: 0
Training loss: 0.4392242853066254
Validation loss: 2.585885515103459

Epoch: 6| Step: 1
Training loss: 0.37651443649568567
Validation loss: 2.538417057260445

Epoch: 6| Step: 2
Training loss: 0.5402852992220976
Validation loss: 2.513657948006574

Epoch: 6| Step: 3
Training loss: 1.2510854299970646
Validation loss: 2.5335472420262337

Epoch: 6| Step: 4
Training loss: 0.5019896082106482
Validation loss: 2.560540807170259

Epoch: 6| Step: 5
Training loss: 0.31127193666620073
Validation loss: 2.581660580251311

Epoch: 6| Step: 6
Training loss: 0.6880631524546446
Validation loss: 2.6854444523555907

Epoch: 6| Step: 7
Training loss: 0.6165538383915682
Validation loss: 2.6760538598111108

Epoch: 6| Step: 8
Training loss: 0.5773571689063177
Validation loss: 2.5881475894436234

Epoch: 6| Step: 9
Training loss: 0.8617724874830945
Validation loss: 2.5715121297909342

Epoch: 6| Step: 10
Training loss: 0.6277144376084667
Validation loss: 2.5027790200355864

Epoch: 6| Step: 11
Training loss: 0.6580311581689966
Validation loss: 2.504735356105909

Epoch: 6| Step: 12
Training loss: 0.8610904910753242
Validation loss: 2.5590928073892236

Epoch: 6| Step: 13
Training loss: 0.6094008464711579
Validation loss: 2.548206394802128

Epoch: 168| Step: 0
Training loss: 0.29368998442007144
Validation loss: 2.5570307337590146

Epoch: 6| Step: 1
Training loss: 1.3690626527620295
Validation loss: 2.614468550473888

Epoch: 6| Step: 2
Training loss: 0.6666690160789418
Validation loss: 2.6902526538756497

Epoch: 6| Step: 3
Training loss: 0.7147835878163765
Validation loss: 2.7195563746497835

Epoch: 6| Step: 4
Training loss: 0.6453681367623363
Validation loss: 2.5835436355964347

Epoch: 6| Step: 5
Training loss: 0.2921391503216796
Validation loss: 2.5540508756377323

Epoch: 6| Step: 6
Training loss: 0.5662035085948032
Validation loss: 2.4790435781830293

Epoch: 6| Step: 7
Training loss: 0.8076503244080439
Validation loss: 2.5294238595003655

Epoch: 6| Step: 8
Training loss: 0.914307325131169
Validation loss: 2.5243254792973486

Epoch: 6| Step: 9
Training loss: 0.5094307570569888
Validation loss: 2.5541627521910133

Epoch: 6| Step: 10
Training loss: 0.5633670164887953
Validation loss: 2.5524766476192173

Epoch: 6| Step: 11
Training loss: 0.7076442863883269
Validation loss: 2.5716060950545567

Epoch: 6| Step: 12
Training loss: 0.7275387757575987
Validation loss: 2.662692190227358

Epoch: 6| Step: 13
Training loss: 0.8432831709032161
Validation loss: 2.598787815613357

Epoch: 169| Step: 0
Training loss: 0.5403258957093081
Validation loss: 2.5196595309619445

Epoch: 6| Step: 1
Training loss: 0.7692730465605108
Validation loss: 2.565117855648687

Epoch: 6| Step: 2
Training loss: 0.45928344722506953
Validation loss: 2.5245100483947787

Epoch: 6| Step: 3
Training loss: 0.5560736730327087
Validation loss: 2.637317210909791

Epoch: 6| Step: 4
Training loss: 0.43947596172759407
Validation loss: 2.5294982280143126

Epoch: 6| Step: 5
Training loss: 0.6145352705788337
Validation loss: 2.512012652361749

Epoch: 6| Step: 6
Training loss: 1.390734936086923
Validation loss: 2.4940717025948405

Epoch: 6| Step: 7
Training loss: 0.4701069582312404
Validation loss: 2.584173055782578

Epoch: 6| Step: 8
Training loss: 0.37244762602904863
Validation loss: 2.5495482848750246

Epoch: 6| Step: 9
Training loss: 0.7807001849481504
Validation loss: 2.605001572604202

Epoch: 6| Step: 10
Training loss: 0.43821780039587765
Validation loss: 2.5542957188258044

Epoch: 6| Step: 11
Training loss: 0.6583651787463696
Validation loss: 2.578698805329973

Epoch: 6| Step: 12
Training loss: 0.41565459440030805
Validation loss: 2.495214395937456

Epoch: 6| Step: 13
Training loss: 0.27412902037789955
Validation loss: 2.5211908517789063

Epoch: 170| Step: 0
Training loss: 0.3823778838279297
Validation loss: 2.513918058625418

Epoch: 6| Step: 1
Training loss: 0.4587496218043127
Validation loss: 2.4900790935297406

Epoch: 6| Step: 2
Training loss: 0.40569065173988655
Validation loss: 2.5277685705536594

Epoch: 6| Step: 3
Training loss: 0.5118681711339904
Validation loss: 2.5147306222664274

Epoch: 6| Step: 4
Training loss: 0.5604515925116353
Validation loss: 2.54856005509804

Epoch: 6| Step: 5
Training loss: 0.7046547038361501
Validation loss: 2.549347330853342

Epoch: 6| Step: 6
Training loss: 0.523498133094031
Validation loss: 2.5312908467580213

Epoch: 6| Step: 7
Training loss: 0.3982771943680149
Validation loss: 2.493648734462644

Epoch: 6| Step: 8
Training loss: 1.3543259698137307
Validation loss: 2.4910556052428587

Epoch: 6| Step: 9
Training loss: 0.44885853132367226
Validation loss: 2.4993005091880125

Epoch: 6| Step: 10
Training loss: 0.4195281733678887
Validation loss: 2.5597343639675256

Epoch: 6| Step: 11
Training loss: 0.4997220757064666
Validation loss: 2.532813621425047

Epoch: 6| Step: 12
Training loss: 0.5302770906045035
Validation loss: 2.562257111676137

Epoch: 6| Step: 13
Training loss: 0.7585919491150338
Validation loss: 2.5496991341564637

Epoch: 171| Step: 0
Training loss: 0.7970804435835795
Validation loss: 2.5377915864729483

Epoch: 6| Step: 1
Training loss: 0.4229450254688247
Validation loss: 2.54982354420011

Epoch: 6| Step: 2
Training loss: 0.5810183730117505
Validation loss: 2.5997845566571316

Epoch: 6| Step: 3
Training loss: 0.42406102123297834
Validation loss: 2.511275470351935

Epoch: 6| Step: 4
Training loss: 0.5043058068085048
Validation loss: 2.555542696756916

Epoch: 6| Step: 5
Training loss: 0.41241507017140455
Validation loss: 2.5348953873055446

Epoch: 6| Step: 6
Training loss: 0.38918020084312405
Validation loss: 2.5569367379339414

Epoch: 6| Step: 7
Training loss: 0.4717563385216688
Validation loss: 2.553200571909773

Epoch: 6| Step: 8
Training loss: 1.3355644106655118
Validation loss: 2.59556289496901

Epoch: 6| Step: 9
Training loss: 0.4774193486911687
Validation loss: 2.584522609346859

Epoch: 6| Step: 10
Training loss: 0.32504979449061605
Validation loss: 2.5808802052684925

Epoch: 6| Step: 11
Training loss: 0.6314474854459935
Validation loss: 2.5842145421787523

Epoch: 6| Step: 12
Training loss: 0.5517261597322958
Validation loss: 2.584627309381308

Epoch: 6| Step: 13
Training loss: 0.49796635593955574
Validation loss: 2.5227584948887047

Epoch: 172| Step: 0
Training loss: 0.8098718981052727
Validation loss: 2.508467377812277

Epoch: 6| Step: 1
Training loss: 0.5392056703487254
Validation loss: 2.5050507308863565

Epoch: 6| Step: 2
Training loss: 0.445777850694662
Validation loss: 2.4681712248752774

Epoch: 6| Step: 3
Training loss: 0.41909513484403754
Validation loss: 2.4572057454826064

Epoch: 6| Step: 4
Training loss: 0.5293823116927995
Validation loss: 2.490778023212154

Epoch: 6| Step: 5
Training loss: 0.6425242531870754
Validation loss: 2.5087495204036188

Epoch: 6| Step: 6
Training loss: 0.5981554925653804
Validation loss: 2.4906838085039387

Epoch: 6| Step: 7
Training loss: 0.6219256845263694
Validation loss: 2.4786547658595945

Epoch: 6| Step: 8
Training loss: 0.38340761676046936
Validation loss: 2.5233832196990735

Epoch: 6| Step: 9
Training loss: 0.37676722631959364
Validation loss: 2.4568482994453746

Epoch: 6| Step: 10
Training loss: 0.4871601509605116
Validation loss: 2.473997839896663

Epoch: 6| Step: 11
Training loss: 0.41931568127032465
Validation loss: 2.5208281735033764

Epoch: 6| Step: 12
Training loss: 1.3512100024659972
Validation loss: 2.478521781414734

Epoch: 6| Step: 13
Training loss: 0.6420003502271416
Validation loss: 2.425002533626216

Epoch: 173| Step: 0
Training loss: 0.4147556010127338
Validation loss: 2.4930422282829374

Epoch: 6| Step: 1
Training loss: 0.494517638635361
Validation loss: 2.589475763797129

Epoch: 6| Step: 2
Training loss: 0.5617782677964236
Validation loss: 2.593103703634888

Epoch: 6| Step: 3
Training loss: 0.46933671472606525
Validation loss: 2.564538586740302

Epoch: 6| Step: 4
Training loss: 0.502863048101367
Validation loss: 2.4917087234554005

Epoch: 6| Step: 5
Training loss: 0.373611781420258
Validation loss: 2.579107679104392

Epoch: 6| Step: 6
Training loss: 0.3437630260773801
Validation loss: 2.5419743513218456

Epoch: 6| Step: 7
Training loss: 0.6001489802016817
Validation loss: 2.462847401468827

Epoch: 6| Step: 8
Training loss: 0.5903305672121786
Validation loss: 2.5229382882319187

Epoch: 6| Step: 9
Training loss: 0.6549132674792744
Validation loss: 2.5068091567059985

Epoch: 6| Step: 10
Training loss: 1.2268304714336544
Validation loss: 2.64498041828361

Epoch: 6| Step: 11
Training loss: 0.840497600729001
Validation loss: 2.59948173761798

Epoch: 6| Step: 12
Training loss: 0.5779492652415807
Validation loss: 2.55592313198484

Epoch: 6| Step: 13
Training loss: 0.48990934927441154
Validation loss: 2.5967320990082077

Epoch: 174| Step: 0
Training loss: 0.4080641477998243
Validation loss: 2.587504884773595

Epoch: 6| Step: 1
Training loss: 0.38910949453849814
Validation loss: 2.585807343710004

Epoch: 6| Step: 2
Training loss: 0.5178557604973294
Validation loss: 2.523828875697987

Epoch: 6| Step: 3
Training loss: 0.5686989258271227
Validation loss: 2.536362387052046

Epoch: 6| Step: 4
Training loss: 0.4752711011826508
Validation loss: 2.522014228352608

Epoch: 6| Step: 5
Training loss: 0.3303726056431098
Validation loss: 2.5109613838001503

Epoch: 6| Step: 6
Training loss: 0.5460066031364125
Validation loss: 2.4716902498632227

Epoch: 6| Step: 7
Training loss: 0.5075654529306667
Validation loss: 2.437608398570324

Epoch: 6| Step: 8
Training loss: 1.2823921788124084
Validation loss: 2.579586485639653

Epoch: 6| Step: 9
Training loss: 0.6210149559087457
Validation loss: 2.567303861030688

Epoch: 6| Step: 10
Training loss: 0.46538838768780355
Validation loss: 2.565910086240073

Epoch: 6| Step: 11
Training loss: 0.8092010723568895
Validation loss: 2.615783876784194

Epoch: 6| Step: 12
Training loss: 0.35510948386798896
Validation loss: 2.6437399585193493

Epoch: 6| Step: 13
Training loss: 0.5093747683097453
Validation loss: 2.553819063522157

Epoch: 175| Step: 0
Training loss: 0.5496489336408585
Validation loss: 2.611075815904659

Epoch: 6| Step: 1
Training loss: 0.4854745996747114
Validation loss: 2.500636377401672

Epoch: 6| Step: 2
Training loss: 0.45322657137336464
Validation loss: 2.4785427676198393

Epoch: 6| Step: 3
Training loss: 0.6938859256550122
Validation loss: 2.457412035232173

Epoch: 6| Step: 4
Training loss: 0.33062900192853006
Validation loss: 2.4992903019960546

Epoch: 6| Step: 5
Training loss: 0.6182580186452669
Validation loss: 2.482005334738245

Epoch: 6| Step: 6
Training loss: 1.2274163062626284
Validation loss: 2.5357824805061604

Epoch: 6| Step: 7
Training loss: 0.4612478407625764
Validation loss: 2.523887247765697

Epoch: 6| Step: 8
Training loss: 0.46086692269729845
Validation loss: 2.540808788250651

Epoch: 6| Step: 9
Training loss: 0.36568637153504835
Validation loss: 2.486350603543914

Epoch: 6| Step: 10
Training loss: 0.49624879171478997
Validation loss: 2.531433648248683

Epoch: 6| Step: 11
Training loss: 0.3198308812968962
Validation loss: 2.4463365906789303

Epoch: 6| Step: 12
Training loss: 0.5473526911940397
Validation loss: 2.5185676407724364

Epoch: 6| Step: 13
Training loss: 0.6569767061833309
Validation loss: 2.539471152260736

Epoch: 176| Step: 0
Training loss: 0.5274788012470981
Validation loss: 2.5397405569984493

Epoch: 6| Step: 1
Training loss: 0.391830244383298
Validation loss: 2.4750214604690006

Epoch: 6| Step: 2
Training loss: 0.8149459043347815
Validation loss: 2.482098518078804

Epoch: 6| Step: 3
Training loss: 0.5809877244847506
Validation loss: 2.5760576918417573

Epoch: 6| Step: 4
Training loss: 0.40482745162446726
Validation loss: 2.5745980538534248

Epoch: 6| Step: 5
Training loss: 0.4468663861704982
Validation loss: 2.507309162970052

Epoch: 6| Step: 6
Training loss: 0.42254183308187737
Validation loss: 2.5295238574676753

Epoch: 6| Step: 7
Training loss: 0.43964946175603803
Validation loss: 2.5582743282741323

Epoch: 6| Step: 8
Training loss: 1.1796288886257285
Validation loss: 2.478317361030682

Epoch: 6| Step: 9
Training loss: 0.33428369460897467
Validation loss: 2.5654072745430425

Epoch: 6| Step: 10
Training loss: 0.47883347834281614
Validation loss: 2.5682294263951118

Epoch: 6| Step: 11
Training loss: 0.5306545454680477
Validation loss: 2.593949834946382

Epoch: 6| Step: 12
Training loss: 0.4844039016222756
Validation loss: 2.530745350017306

Epoch: 6| Step: 13
Training loss: 0.4504718220976818
Validation loss: 2.556981712146616

Epoch: 177| Step: 0
Training loss: 0.4401901845745881
Validation loss: 2.535807666443914

Epoch: 6| Step: 1
Training loss: 0.31538388418686325
Validation loss: 2.475968065934602

Epoch: 6| Step: 2
Training loss: 0.383236669536258
Validation loss: 2.5043784106499265

Epoch: 6| Step: 3
Training loss: 0.8260096397460872
Validation loss: 2.4734498689381983

Epoch: 6| Step: 4
Training loss: 0.4248339938874096
Validation loss: 2.5609110193316806

Epoch: 6| Step: 5
Training loss: 1.2649197438379778
Validation loss: 2.449367326025376

Epoch: 6| Step: 6
Training loss: 0.3997733964401355
Validation loss: 2.5131540898914184

Epoch: 6| Step: 7
Training loss: 0.4930740878677306
Validation loss: 2.527591274586773

Epoch: 6| Step: 8
Training loss: 0.5023624517539915
Validation loss: 2.534668352840725

Epoch: 6| Step: 9
Training loss: 0.6300942472699887
Validation loss: 2.5670518996804237

Epoch: 6| Step: 10
Training loss: 0.5492568598367926
Validation loss: 2.552813854891945

Epoch: 6| Step: 11
Training loss: 0.465338147534486
Validation loss: 2.5051581099479554

Epoch: 6| Step: 12
Training loss: 0.5597596705267083
Validation loss: 2.5106170041462885

Epoch: 6| Step: 13
Training loss: 0.5504509226120875
Validation loss: 2.4962040534046745

Epoch: 178| Step: 0
Training loss: 0.30723559008004336
Validation loss: 2.4842893957588523

Epoch: 6| Step: 1
Training loss: 0.5230289971826809
Validation loss: 2.4897653494553684

Epoch: 6| Step: 2
Training loss: 0.3773297617276251
Validation loss: 2.5060210836101553

Epoch: 6| Step: 3
Training loss: 0.49196395641589846
Validation loss: 2.5007440572394284

Epoch: 6| Step: 4
Training loss: 0.5138121438785604
Validation loss: 2.5155313762673592

Epoch: 6| Step: 5
Training loss: 0.34274989642302367
Validation loss: 2.525676084720968

Epoch: 6| Step: 6
Training loss: 0.7425372454103115
Validation loss: 2.504868765253111

Epoch: 6| Step: 7
Training loss: 0.4182073856666203
Validation loss: 2.5997601318973866

Epoch: 6| Step: 8
Training loss: 0.639994986037641
Validation loss: 2.521069812454145

Epoch: 6| Step: 9
Training loss: 0.4106608964741214
Validation loss: 2.573402464457716

Epoch: 6| Step: 10
Training loss: 0.40471377048134544
Validation loss: 2.5372025392188973

Epoch: 6| Step: 11
Training loss: 0.43780782633103665
Validation loss: 2.4858259766261264

Epoch: 6| Step: 12
Training loss: 1.2489451248874641
Validation loss: 2.5567087466006875

Epoch: 6| Step: 13
Training loss: 0.4778555073166374
Validation loss: 2.493079222268983

Epoch: 179| Step: 0
Training loss: 0.4579350427921138
Validation loss: 2.6047065073596314

Epoch: 6| Step: 1
Training loss: 0.35613385532465386
Validation loss: 2.4696432179780174

Epoch: 6| Step: 2
Training loss: 0.3903895240571211
Validation loss: 2.5305633084424657

Epoch: 6| Step: 3
Training loss: 0.49869402559387543
Validation loss: 2.5177973495696104

Epoch: 6| Step: 4
Training loss: 0.7837174170625079
Validation loss: 2.5000044027925505

Epoch: 6| Step: 5
Training loss: 1.2752539194866075
Validation loss: 2.514609817158933

Epoch: 6| Step: 6
Training loss: 0.4061418169202461
Validation loss: 2.506566674067664

Epoch: 6| Step: 7
Training loss: 0.3620800957061272
Validation loss: 2.531537381094533

Epoch: 6| Step: 8
Training loss: 0.4292452356799493
Validation loss: 2.565438129095084

Epoch: 6| Step: 9
Training loss: 0.4000908077995576
Validation loss: 2.5319082558057393

Epoch: 6| Step: 10
Training loss: 0.327497518107787
Validation loss: 2.513790227617769

Epoch: 6| Step: 11
Training loss: 0.3000424712635199
Validation loss: 2.5002194785097576

Epoch: 6| Step: 12
Training loss: 0.4543679717201157
Validation loss: 2.592998288468986

Epoch: 6| Step: 13
Training loss: 0.6592206928073548
Validation loss: 2.5793670282717507

Epoch: 180| Step: 0
Training loss: 0.6662278270789282
Validation loss: 2.62490417668876

Epoch: 6| Step: 1
Training loss: 1.2806554670977708
Validation loss: 2.503172927251567

Epoch: 6| Step: 2
Training loss: 0.38791863377799984
Validation loss: 2.628184778332729

Epoch: 6| Step: 3
Training loss: 0.39552789331015303
Validation loss: 2.5580701918407707

Epoch: 6| Step: 4
Training loss: 0.28542426330081744
Validation loss: 2.637197161941317

Epoch: 6| Step: 5
Training loss: 0.33555073985670636
Validation loss: 2.554518107826623

Epoch: 6| Step: 6
Training loss: 0.3439958733433118
Validation loss: 2.574826266776505

Epoch: 6| Step: 7
Training loss: 0.5592399274254057
Validation loss: 2.5188824431855688

Epoch: 6| Step: 8
Training loss: 0.3739743910222425
Validation loss: 2.538674568471846

Epoch: 6| Step: 9
Training loss: 0.48779058599033276
Validation loss: 2.5084541902121114

Epoch: 6| Step: 10
Training loss: 0.6656360159665344
Validation loss: 2.485714229561294

Epoch: 6| Step: 11
Training loss: 0.3744483108258793
Validation loss: 2.5385556228581736

Epoch: 6| Step: 12
Training loss: 0.4228087617211256
Validation loss: 2.5386985791882606

Epoch: 6| Step: 13
Training loss: 0.3945304190749681
Validation loss: 2.541073907197948

Epoch: 181| Step: 0
Training loss: 0.33729848629586096
Validation loss: 2.5959952797334935

Epoch: 6| Step: 1
Training loss: 0.47775691081407934
Validation loss: 2.612265670342383

Epoch: 6| Step: 2
Training loss: 0.48283884044509245
Validation loss: 2.6069799841714913

Epoch: 6| Step: 3
Training loss: 1.1620486972899853
Validation loss: 2.509116557657798

Epoch: 6| Step: 4
Training loss: 0.2764824401149647
Validation loss: 2.5319835243643243

Epoch: 6| Step: 5
Training loss: 0.3570684551328004
Validation loss: 2.5162125053461084

Epoch: 6| Step: 6
Training loss: 0.47609603440600834
Validation loss: 2.4365913213473696

Epoch: 6| Step: 7
Training loss: 0.7424403914212172
Validation loss: 2.475805814811168

Epoch: 6| Step: 8
Training loss: 0.5168997295326533
Validation loss: 2.5444727062361387

Epoch: 6| Step: 9
Training loss: 0.41038608469358684
Validation loss: 2.5333822633593956

Epoch: 6| Step: 10
Training loss: 0.45195256845609777
Validation loss: 2.527691675182253

Epoch: 6| Step: 11
Training loss: 0.44864769173154495
Validation loss: 2.546153920139513

Epoch: 6| Step: 12
Training loss: 0.33658412313112845
Validation loss: 2.5606616644561755

Epoch: 6| Step: 13
Training loss: 0.3380977238496391
Validation loss: 2.5504992544829577

Epoch: 182| Step: 0
Training loss: 0.4851331622393692
Validation loss: 2.5404828759512044

Epoch: 6| Step: 1
Training loss: 1.3151275129102968
Validation loss: 2.5900426666447176

Epoch: 6| Step: 2
Training loss: 0.38098207111301136
Validation loss: 2.4855512637464776

Epoch: 6| Step: 3
Training loss: 0.5080101215525666
Validation loss: 2.5223118935785385

Epoch: 6| Step: 4
Training loss: 0.41268490201833385
Validation loss: 2.5757984491324986

Epoch: 6| Step: 5
Training loss: 0.3376636514554179
Validation loss: 2.5123623843486267

Epoch: 6| Step: 6
Training loss: 0.34905197419678063
Validation loss: 2.506661710590509

Epoch: 6| Step: 7
Training loss: 0.3468552051085441
Validation loss: 2.5369906692593927

Epoch: 6| Step: 8
Training loss: 0.3626707957192824
Validation loss: 2.54019624878082

Epoch: 6| Step: 9
Training loss: 0.4839555246838462
Validation loss: 2.600349135676972

Epoch: 6| Step: 10
Training loss: 0.41541070791630524
Validation loss: 2.574363615661131

Epoch: 6| Step: 11
Training loss: 0.539500708004166
Validation loss: 2.5010046529725343

Epoch: 6| Step: 12
Training loss: 0.22648676889081437
Validation loss: 2.5419124864825404

Epoch: 6| Step: 13
Training loss: 0.5827387151979713
Validation loss: 2.5018464978198933

Epoch: 183| Step: 0
Training loss: 0.33682503007625203
Validation loss: 2.5632748556556306

Epoch: 6| Step: 1
Training loss: 0.32079538140477143
Validation loss: 2.5326534587637544

Epoch: 6| Step: 2
Training loss: 0.7540605219195743
Validation loss: 2.545915450183296

Epoch: 6| Step: 3
Training loss: 0.49855903770045096
Validation loss: 2.5242828748250483

Epoch: 6| Step: 4
Training loss: 0.4974474122897559
Validation loss: 2.604613110739198

Epoch: 6| Step: 5
Training loss: 0.4545858774309212
Validation loss: 2.5640836644698797

Epoch: 6| Step: 6
Training loss: 0.3927954077207466
Validation loss: 2.5906578230609556

Epoch: 6| Step: 7
Training loss: 0.3652155254212196
Validation loss: 2.6009940670996357

Epoch: 6| Step: 8
Training loss: 0.38951665040714833
Validation loss: 2.6596752521715605

Epoch: 6| Step: 9
Training loss: 1.1969448736526485
Validation loss: 2.53634952465833

Epoch: 6| Step: 10
Training loss: 0.3632731693148451
Validation loss: 2.530778252240152

Epoch: 6| Step: 11
Training loss: 0.6609946350220428
Validation loss: 2.509297170101102

Epoch: 6| Step: 12
Training loss: 0.5138076776766136
Validation loss: 2.474256209794644

Epoch: 6| Step: 13
Training loss: 0.6420873141510889
Validation loss: 2.5317515045183643

Epoch: 184| Step: 0
Training loss: 0.705810546875
Validation loss: 2.4983880329781747

Epoch: 6| Step: 1
Training loss: 0.26654372094339557
Validation loss: 2.6120809355839527

Epoch: 6| Step: 2
Training loss: 0.48900157439284614
Validation loss: 2.539511272189344

Epoch: 6| Step: 3
Training loss: 1.161427222321323
Validation loss: 2.55730626761832

Epoch: 6| Step: 4
Training loss: 0.4514746372580754
Validation loss: 2.5094062439021343

Epoch: 6| Step: 5
Training loss: 0.40427140602569916
Validation loss: 2.5669056151578116

Epoch: 6| Step: 6
Training loss: 0.5018255168040415
Validation loss: 2.551239696857557

Epoch: 6| Step: 7
Training loss: 0.47736417848418355
Validation loss: 2.56650348326239

Epoch: 6| Step: 8
Training loss: 0.39265401306000913
Validation loss: 2.475461047029998

Epoch: 6| Step: 9
Training loss: 0.42485628362801103
Validation loss: 2.5551897618743347

Epoch: 6| Step: 10
Training loss: 0.34829413368351414
Validation loss: 2.54437011764509

Epoch: 6| Step: 11
Training loss: 0.28551065290872424
Validation loss: 2.6211175818006547

Epoch: 6| Step: 12
Training loss: 0.4039150960163839
Validation loss: 2.5323735635921176

Epoch: 6| Step: 13
Training loss: 0.4988914509294822
Validation loss: 2.5775757638061796

Epoch: 185| Step: 0
Training loss: 0.6307767453716715
Validation loss: 2.5159841403532077

Epoch: 6| Step: 1
Training loss: 1.1715224180693784
Validation loss: 2.5464752601257157

Epoch: 6| Step: 2
Training loss: 0.31792617062869616
Validation loss: 2.5559807089160698

Epoch: 6| Step: 3
Training loss: 0.3091608944240074
Validation loss: 2.5514024461988116

Epoch: 6| Step: 4
Training loss: 0.45177417862368746
Validation loss: 2.5399830797462886

Epoch: 6| Step: 5
Training loss: 0.3590623698221872
Validation loss: 2.5421710269568547

Epoch: 6| Step: 6
Training loss: 0.4462445860889614
Validation loss: 2.517453313140173

Epoch: 6| Step: 7
Training loss: 0.49004589880336524
Validation loss: 2.5686245277371307

Epoch: 6| Step: 8
Training loss: 0.4408141190242093
Validation loss: 2.5221561686394525

Epoch: 6| Step: 9
Training loss: 0.313350283658009
Validation loss: 2.5280133578338893

Epoch: 6| Step: 10
Training loss: 0.4423306331219121
Validation loss: 2.524024556532718

Epoch: 6| Step: 11
Training loss: 0.443428874345242
Validation loss: 2.4914534553050305

Epoch: 6| Step: 12
Training loss: 0.4710202553578909
Validation loss: 2.489707150964891

Epoch: 6| Step: 13
Training loss: 0.3780539453755425
Validation loss: 2.6114837136016096

Epoch: 186| Step: 0
Training loss: 0.3682966322472227
Validation loss: 2.5657414814522874

Epoch: 6| Step: 1
Training loss: 0.27729303944078565
Validation loss: 2.5414205390285343

Epoch: 6| Step: 2
Training loss: 0.5965555814298892
Validation loss: 2.5666133539641

Epoch: 6| Step: 3
Training loss: 0.7071625814122822
Validation loss: 2.466391656232499

Epoch: 6| Step: 4
Training loss: 0.3779844495738471
Validation loss: 2.5281843765509957

Epoch: 6| Step: 5
Training loss: 0.5091986883471692
Validation loss: 2.5262378629543583

Epoch: 6| Step: 6
Training loss: 0.4317792781959574
Validation loss: 2.6112388837159846

Epoch: 6| Step: 7
Training loss: 0.6292046733349195
Validation loss: 2.5551848943241526

Epoch: 6| Step: 8
Training loss: 0.4950958488124671
Validation loss: 2.5356089967005286

Epoch: 6| Step: 9
Training loss: 0.3229327608015113
Validation loss: 2.5652627395696714

Epoch: 6| Step: 10
Training loss: 0.39978310620418134
Validation loss: 2.4854103186356555

Epoch: 6| Step: 11
Training loss: 0.4591879535224724
Validation loss: 2.5516027478144627

Epoch: 6| Step: 12
Training loss: 1.1588583728271045
Validation loss: 2.4945825769225665

Epoch: 6| Step: 13
Training loss: 0.2760353792422182
Validation loss: 2.6289728164747506

Epoch: 187| Step: 0
Training loss: 0.4261718323425216
Validation loss: 2.601096797955155

Epoch: 6| Step: 1
Training loss: 0.36023844775989844
Validation loss: 2.593434088591689

Epoch: 6| Step: 2
Training loss: 0.41952034138681615
Validation loss: 2.5083760690903363

Epoch: 6| Step: 3
Training loss: 0.5417592140755583
Validation loss: 2.5054290949148803

Epoch: 6| Step: 4
Training loss: 0.3432041298972913
Validation loss: 2.5970286287539666

Epoch: 6| Step: 5
Training loss: 0.698554080049246
Validation loss: 2.5367961608961527

Epoch: 6| Step: 6
Training loss: 0.5336932769491316
Validation loss: 2.579286394642473

Epoch: 6| Step: 7
Training loss: 1.1364664013952388
Validation loss: 2.535375804044195

Epoch: 6| Step: 8
Training loss: 0.37485083951363773
Validation loss: 2.47457313260157

Epoch: 6| Step: 9
Training loss: 0.4318687043510906
Validation loss: 2.5013430008064286

Epoch: 6| Step: 10
Training loss: 0.38328849627008876
Validation loss: 2.5499031615724976

Epoch: 6| Step: 11
Training loss: 0.5121434611390849
Validation loss: 2.5168795093527243

Epoch: 6| Step: 12
Training loss: 0.5631994825635099
Validation loss: 2.5669669860130626

Epoch: 6| Step: 13
Training loss: 0.3718069150450402
Validation loss: 2.4590905580427966

Epoch: 188| Step: 0
Training loss: 0.4995439207673301
Validation loss: 2.466270022033066

Epoch: 6| Step: 1
Training loss: 0.405782577400842
Validation loss: 2.5327150398657827

Epoch: 6| Step: 2
Training loss: 0.4488531532314519
Validation loss: 2.448641557432671

Epoch: 6| Step: 3
Training loss: 0.44801027037032554
Validation loss: 2.4997118465933927

Epoch: 6| Step: 4
Training loss: 0.36054499533711937
Validation loss: 2.5076211319554726

Epoch: 6| Step: 5
Training loss: 0.3619147616203131
Validation loss: 2.5079126862887664

Epoch: 6| Step: 6
Training loss: 1.1652551468197605
Validation loss: 2.5629965138316773

Epoch: 6| Step: 7
Training loss: 0.5184909472470727
Validation loss: 2.6252515157669722

Epoch: 6| Step: 8
Training loss: 0.6788018913525368
Validation loss: 2.539380973992287

Epoch: 6| Step: 9
Training loss: 0.4486360668550933
Validation loss: 2.4621525585517743

Epoch: 6| Step: 10
Training loss: 0.35840870689210547
Validation loss: 2.5275896081532023

Epoch: 6| Step: 11
Training loss: 0.3660355618481083
Validation loss: 2.507564401683817

Epoch: 6| Step: 12
Training loss: 0.4640091046527322
Validation loss: 2.483557920626476

Epoch: 6| Step: 13
Training loss: 0.5045807043406604
Validation loss: 2.498408399026348

Epoch: 189| Step: 0
Training loss: 0.36528014849887425
Validation loss: 2.5309614872654334

Epoch: 6| Step: 1
Training loss: 0.39705755585736136
Validation loss: 2.55816066658363

Epoch: 6| Step: 2
Training loss: 0.3443502690388556
Validation loss: 2.5519500749531736

Epoch: 6| Step: 3
Training loss: 0.47393707255651435
Validation loss: 2.5452667962848254

Epoch: 6| Step: 4
Training loss: 0.40202170510790664
Validation loss: 2.6093304186760684

Epoch: 6| Step: 5
Training loss: 0.6609820105172202
Validation loss: 2.599324704468089

Epoch: 6| Step: 6
Training loss: 0.34184622272113596
Validation loss: 2.531662754267603

Epoch: 6| Step: 7
Training loss: 0.29930074877959145
Validation loss: 2.5217725380807154

Epoch: 6| Step: 8
Training loss: 0.35754263250201757
Validation loss: 2.551802916918332

Epoch: 6| Step: 9
Training loss: 0.4860971814006569
Validation loss: 2.5649178193592936

Epoch: 6| Step: 10
Training loss: 1.1495084375417766
Validation loss: 2.4301857881989566

Epoch: 6| Step: 11
Training loss: 0.36328567994400823
Validation loss: 2.488713057821971

Epoch: 6| Step: 12
Training loss: 0.4588043021979411
Validation loss: 2.568076864933197

Epoch: 6| Step: 13
Training loss: 0.4349146475310465
Validation loss: 2.441459586005941

Epoch: 190| Step: 0
Training loss: 0.35293102929135195
Validation loss: 2.5121268993334502

Epoch: 6| Step: 1
Training loss: 0.45445313328911346
Validation loss: 2.5164711202561922

Epoch: 6| Step: 2
Training loss: 0.40678813944727266
Validation loss: 2.600970807152324

Epoch: 6| Step: 3
Training loss: 0.5370524705740338
Validation loss: 2.5319711419299553

Epoch: 6| Step: 4
Training loss: 0.3933554777011036
Validation loss: 2.494719380159053

Epoch: 6| Step: 5
Training loss: 0.4097919481111978
Validation loss: 2.4979288184151685

Epoch: 6| Step: 6
Training loss: 0.34445337379880914
Validation loss: 2.5801276087437484

Epoch: 6| Step: 7
Training loss: 0.48970437751707946
Validation loss: 2.51477054435281

Epoch: 6| Step: 8
Training loss: 0.3489234311408763
Validation loss: 2.4954569307209433

Epoch: 6| Step: 9
Training loss: 0.31602647147408314
Validation loss: 2.498382187947355

Epoch: 6| Step: 10
Training loss: 0.2183786544068234
Validation loss: 2.5466950865935627

Epoch: 6| Step: 11
Training loss: 0.7485905755536462
Validation loss: 2.5398448188816256

Epoch: 6| Step: 12
Training loss: 1.1601940110351727
Validation loss: 2.590150457280877

Epoch: 6| Step: 13
Training loss: 0.3649248657888014
Validation loss: 2.5751073882786715

Epoch: 191| Step: 0
Training loss: 0.41708916065871976
Validation loss: 2.5863197251624093

Epoch: 6| Step: 1
Training loss: 0.5024746215636684
Validation loss: 2.6043149422712673

Epoch: 6| Step: 2
Training loss: 0.4764467630397893
Validation loss: 2.5809756615816584

Epoch: 6| Step: 3
Training loss: 0.2951455184092219
Validation loss: 2.440992298890764

Epoch: 6| Step: 4
Training loss: 0.7949554661207345
Validation loss: 2.485706252574207

Epoch: 6| Step: 5
Training loss: 0.45425263219752016
Validation loss: 2.5221931215905076

Epoch: 6| Step: 6
Training loss: 0.41086693001862534
Validation loss: 2.546273798281245

Epoch: 6| Step: 7
Training loss: 0.37505451441932536
Validation loss: 2.597579717823301

Epoch: 6| Step: 8
Training loss: 0.46853475397092637
Validation loss: 2.5438979053534228

Epoch: 6| Step: 9
Training loss: 0.5415326068726233
Validation loss: 2.598491119608392

Epoch: 6| Step: 10
Training loss: 1.2108901476061742
Validation loss: 2.615092852264789

Epoch: 6| Step: 11
Training loss: 0.333570033711154
Validation loss: 2.560295141102192

Epoch: 6| Step: 12
Training loss: 0.48823771473399763
Validation loss: 2.519113021954105

Epoch: 6| Step: 13
Training loss: 0.41240020180502096
Validation loss: 2.523489306915063

Epoch: 192| Step: 0
Training loss: 0.3731354613251353
Validation loss: 2.563456938168932

Epoch: 6| Step: 1
Training loss: 0.6800595942146731
Validation loss: 2.5235409080646787

Epoch: 6| Step: 2
Training loss: 0.35136631684039027
Validation loss: 2.571353720781549

Epoch: 6| Step: 3
Training loss: 0.4295926769706882
Validation loss: 2.504417157035313

Epoch: 6| Step: 4
Training loss: 0.4690280725296646
Validation loss: 2.5169726093172455

Epoch: 6| Step: 5
Training loss: 0.3696244515436546
Validation loss: 2.563939690307607

Epoch: 6| Step: 6
Training loss: 0.3949804675729387
Validation loss: 2.5314613379647235

Epoch: 6| Step: 7
Training loss: 0.5402884985125155
Validation loss: 2.6282522853368584

Epoch: 6| Step: 8
Training loss: 0.38764914903206615
Validation loss: 2.588179431850477

Epoch: 6| Step: 9
Training loss: 1.1071562271805107
Validation loss: 2.5403469964296383

Epoch: 6| Step: 10
Training loss: 0.3196354432665697
Validation loss: 2.578812324533843

Epoch: 6| Step: 11
Training loss: 0.5421377725360966
Validation loss: 2.4750660929219794

Epoch: 6| Step: 12
Training loss: 0.3396431670786312
Validation loss: 2.5106286293125737

Epoch: 6| Step: 13
Training loss: 0.36755985291618704
Validation loss: 2.5400267506239564

Epoch: 193| Step: 0
Training loss: 0.4498270311657323
Validation loss: 2.470626536352039

Epoch: 6| Step: 1
Training loss: 0.3663182215898702
Validation loss: 2.4637167601566405

Epoch: 6| Step: 2
Training loss: 0.47095207500622316
Validation loss: 2.559766955670999

Epoch: 6| Step: 3
Training loss: 0.3424049526961876
Validation loss: 2.530637203811133

Epoch: 6| Step: 4
Training loss: 0.7165769400724172
Validation loss: 2.502137653058705

Epoch: 6| Step: 5
Training loss: 0.4499019237770553
Validation loss: 2.478036467937841

Epoch: 6| Step: 6
Training loss: 0.32278009444048467
Validation loss: 2.551612628943468

Epoch: 6| Step: 7
Training loss: 0.20102711441231247
Validation loss: 2.57770989669382

Epoch: 6| Step: 8
Training loss: 0.32535255914710187
Validation loss: 2.527814213055823

Epoch: 6| Step: 9
Training loss: 0.37692003648443406
Validation loss: 2.5603371308039518

Epoch: 6| Step: 10
Training loss: 0.27272595058467475
Validation loss: 2.5787871618238976

Epoch: 6| Step: 11
Training loss: 0.3096313777346815
Validation loss: 2.5473567296434343

Epoch: 6| Step: 12
Training loss: 1.1265873307072214
Validation loss: 2.558938583160743

Epoch: 6| Step: 13
Training loss: 0.31493252290720825
Validation loss: 2.5823555962416314

Epoch: 194| Step: 0
Training loss: 0.5065771188103246
Validation loss: 2.6216554452042007

Epoch: 6| Step: 1
Training loss: 0.3421821820268262
Validation loss: 2.594467714889672

Epoch: 6| Step: 2
Training loss: 0.44961361323794186
Validation loss: 2.5050096624724834

Epoch: 6| Step: 3
Training loss: 0.3232815306539225
Validation loss: 2.566015112115092

Epoch: 6| Step: 4
Training loss: 0.3765967468264033
Validation loss: 2.501661289098332

Epoch: 6| Step: 5
Training loss: 1.1044799911945424
Validation loss: 2.502641950805687

Epoch: 6| Step: 6
Training loss: 0.3381860577071931
Validation loss: 2.61082836800436

Epoch: 6| Step: 7
Training loss: 0.36343364185440397
Validation loss: 2.5081897107276396

Epoch: 6| Step: 8
Training loss: 0.4158195785867173
Validation loss: 2.5991647265069178

Epoch: 6| Step: 9
Training loss: 0.4229453073240131
Validation loss: 2.5701414551874286

Epoch: 6| Step: 10
Training loss: 0.6274102941733182
Validation loss: 2.5909877760841846

Epoch: 6| Step: 11
Training loss: 0.6202087334770506
Validation loss: 2.578092709734064

Epoch: 6| Step: 12
Training loss: 0.3107458952389431
Validation loss: 2.514983575209874

Epoch: 6| Step: 13
Training loss: 0.31603904891936435
Validation loss: 2.552774512187745

Epoch: 195| Step: 0
Training loss: 0.6777960669502742
Validation loss: 2.5462603929345318

Epoch: 6| Step: 1
Training loss: 0.2994645267170067
Validation loss: 2.5144757475088886

Epoch: 6| Step: 2
Training loss: 0.2963089817419989
Validation loss: 2.5443915758535507

Epoch: 6| Step: 3
Training loss: 0.435363080713927
Validation loss: 2.5414256518381975

Epoch: 6| Step: 4
Training loss: 0.5023593075539742
Validation loss: 2.5439977639246454

Epoch: 6| Step: 5
Training loss: 0.3355202856397891
Validation loss: 2.58195856389296

Epoch: 6| Step: 6
Training loss: 0.5471008924158677
Validation loss: 2.525200510404469

Epoch: 6| Step: 7
Training loss: 0.46619695954928997
Validation loss: 2.541549380259303

Epoch: 6| Step: 8
Training loss: 0.4026899977468457
Validation loss: 2.5040465586881777

Epoch: 6| Step: 9
Training loss: 0.3355590551650337
Validation loss: 2.495532932470045

Epoch: 6| Step: 10
Training loss: 0.37520569881775984
Validation loss: 2.5021264886959167

Epoch: 6| Step: 11
Training loss: 1.1083726249747676
Validation loss: 2.5861569299018194

Epoch: 6| Step: 12
Training loss: 0.38008963243053984
Validation loss: 2.5251734286886998

Epoch: 6| Step: 13
Training loss: 0.46670323793413143
Validation loss: 2.600690708969777

Epoch: 196| Step: 0
Training loss: 0.41585928258154914
Validation loss: 2.6139086021151132

Epoch: 6| Step: 1
Training loss: 0.4955354988804647
Validation loss: 2.559893872301367

Epoch: 6| Step: 2
Training loss: 0.38080015455676597
Validation loss: 2.6370664918260993

Epoch: 6| Step: 3
Training loss: 0.4316171493015158
Validation loss: 2.651927347882529

Epoch: 6| Step: 4
Training loss: 0.2542666298595529
Validation loss: 2.533794536980158

Epoch: 6| Step: 5
Training loss: 0.33063628051277366
Validation loss: 2.54337009557934

Epoch: 6| Step: 6
Training loss: 0.613211536697274
Validation loss: 2.5253417287421462

Epoch: 6| Step: 7
Training loss: 0.3351950980838045
Validation loss: 2.5168712285464063

Epoch: 6| Step: 8
Training loss: 0.39829543329772377
Validation loss: 2.484351615875683

Epoch: 6| Step: 9
Training loss: 0.3329164038351945
Validation loss: 2.501706772566857

Epoch: 6| Step: 10
Training loss: 1.0131488251752754
Validation loss: 2.5539199889412423

Epoch: 6| Step: 11
Training loss: 0.5165001061080277
Validation loss: 2.633358801545549

Epoch: 6| Step: 12
Training loss: 0.49915215013673914
Validation loss: 2.5499332687273135

Epoch: 6| Step: 13
Training loss: 0.46134159995481583
Validation loss: 2.5794712905651607

Epoch: 197| Step: 0
Training loss: 0.42850129513005103
Validation loss: 2.5133667597415617

Epoch: 6| Step: 1
Training loss: 0.47971654176554795
Validation loss: 2.4744658234068617

Epoch: 6| Step: 2
Training loss: 0.7237290126676251
Validation loss: 2.492720169334724

Epoch: 6| Step: 3
Training loss: 0.43073820483662784
Validation loss: 2.5491015680993554

Epoch: 6| Step: 4
Training loss: 0.32498011757481876
Validation loss: 2.5159854828082664

Epoch: 6| Step: 5
Training loss: 0.4026166120269503
Validation loss: 2.597105223071135

Epoch: 6| Step: 6
Training loss: 0.5045840709511836
Validation loss: 2.630819621041826

Epoch: 6| Step: 7
Training loss: 0.3848756158532038
Validation loss: 2.5702423812747854

Epoch: 6| Step: 8
Training loss: 0.386411487005511
Validation loss: 2.6052380659401537

Epoch: 6| Step: 9
Training loss: 0.35840109842336454
Validation loss: 2.5103316127778124

Epoch: 6| Step: 10
Training loss: 0.3734591936649649
Validation loss: 2.53495709421188

Epoch: 6| Step: 11
Training loss: 1.1152598149325863
Validation loss: 2.5143857790363255

Epoch: 6| Step: 12
Training loss: 0.43098871705428204
Validation loss: 2.538788656481683

Epoch: 6| Step: 13
Training loss: 0.24628806390038047
Validation loss: 2.5670529832383773

Epoch: 198| Step: 0
Training loss: 0.36543248153588875
Validation loss: 2.6042148178735256

Epoch: 6| Step: 1
Training loss: 0.5353327828933353
Validation loss: 2.5662305859851644

Epoch: 6| Step: 2
Training loss: 0.34430449369798627
Validation loss: 2.571838281615791

Epoch: 6| Step: 3
Training loss: 0.44799515310075283
Validation loss: 2.5061625899041373

Epoch: 6| Step: 4
Training loss: 0.46197360987656166
Validation loss: 2.4937311412381824

Epoch: 6| Step: 5
Training loss: 0.3835176085441988
Validation loss: 2.4180978875091688

Epoch: 6| Step: 6
Training loss: 0.48917354688024534
Validation loss: 2.465826138026844

Epoch: 6| Step: 7
Training loss: 0.34948346731815305
Validation loss: 2.4516240284226907

Epoch: 6| Step: 8
Training loss: 1.0852646424088481
Validation loss: 2.562337218906154

Epoch: 6| Step: 9
Training loss: 0.3907010004496501
Validation loss: 2.4994705116316607

Epoch: 6| Step: 10
Training loss: 0.37913254734555046
Validation loss: 2.476184017811377

Epoch: 6| Step: 11
Training loss: 0.44692930545157405
Validation loss: 2.4891604352970327

Epoch: 6| Step: 12
Training loss: 0.28841590734398576
Validation loss: 2.440608227322524

Epoch: 6| Step: 13
Training loss: 0.6754582244949515
Validation loss: 2.4866650501157332

Epoch: 199| Step: 0
Training loss: 0.27574789261553045
Validation loss: 2.486510001195619

Epoch: 6| Step: 1
Training loss: 0.47163926419309343
Validation loss: 2.490261804766211

Epoch: 6| Step: 2
Training loss: 0.2746614311876275
Validation loss: 2.5007887390780925

Epoch: 6| Step: 3
Training loss: 0.42116525782455305
Validation loss: 2.5151731981789176

Epoch: 6| Step: 4
Training loss: 0.4585490170810719
Validation loss: 2.537280759438457

Epoch: 6| Step: 5
Training loss: 0.56017096804725
Validation loss: 2.4936500411368154

Epoch: 6| Step: 6
Training loss: 0.4068418556401926
Validation loss: 2.5002749609738566

Epoch: 6| Step: 7
Training loss: 0.3813014667979995
Validation loss: 2.5198319445436184

Epoch: 6| Step: 8
Training loss: 0.48242629199766573
Validation loss: 2.5289305118453274

Epoch: 6| Step: 9
Training loss: 0.5169312086989695
Validation loss: 2.513542411056853

Epoch: 6| Step: 10
Training loss: 0.7116906504941121
Validation loss: 2.5167485131182006

Epoch: 6| Step: 11
Training loss: 0.40432158684879366
Validation loss: 2.556379079008082

Epoch: 6| Step: 12
Training loss: 1.095847108461854
Validation loss: 2.5045220167893514

Epoch: 6| Step: 13
Training loss: 0.432644035935677
Validation loss: 2.5603632275493644

Epoch: 200| Step: 0
Training loss: 0.32992571635881396
Validation loss: 2.5307905777062203

Epoch: 6| Step: 1
Training loss: 1.0871824085788526
Validation loss: 2.584887680439515

Epoch: 6| Step: 2
Training loss: 0.3141950175894357
Validation loss: 2.6379394041688355

Epoch: 6| Step: 3
Training loss: 0.4054996272919114
Validation loss: 2.6059598445609113

Epoch: 6| Step: 4
Training loss: 0.30672475547566247
Validation loss: 2.5649348220822987

Epoch: 6| Step: 5
Training loss: 0.4623121356887898
Validation loss: 2.4919685259597446

Epoch: 6| Step: 6
Training loss: 0.44707393286469455
Validation loss: 2.5559880079645763

Epoch: 6| Step: 7
Training loss: 0.35158353318768343
Validation loss: 2.485978966284596

Epoch: 6| Step: 8
Training loss: 0.7480354009400694
Validation loss: 2.591434057617649

Epoch: 6| Step: 9
Training loss: 0.4349111185033656
Validation loss: 2.6213146406579577

Epoch: 6| Step: 10
Training loss: 0.34621445507805004
Validation loss: 2.576203672623981

Epoch: 6| Step: 11
Training loss: 0.4471578676441228
Validation loss: 2.530862566649622

Epoch: 6| Step: 12
Training loss: 0.518426911727089
Validation loss: 2.500422108301074

Epoch: 6| Step: 13
Training loss: 0.3621550505471205
Validation loss: 2.5944894249897152

Epoch: 201| Step: 0
Training loss: 0.33813733261731505
Validation loss: 2.5886403045179773

Epoch: 6| Step: 1
Training loss: 0.4622364814188578
Validation loss: 2.5603733154260544

Epoch: 6| Step: 2
Training loss: 0.3888879683271745
Validation loss: 2.5607676659392755

Epoch: 6| Step: 3
Training loss: 0.5363191096804656
Validation loss: 2.539788479821116

Epoch: 6| Step: 4
Training loss: 0.41726963006293566
Validation loss: 2.5562263232738083

Epoch: 6| Step: 5
Training loss: 0.4072442359656913
Validation loss: 2.5989951753521403

Epoch: 6| Step: 6
Training loss: 0.3835915792679598
Validation loss: 2.5437989488745627

Epoch: 6| Step: 7
Training loss: 0.32208827369440973
Validation loss: 2.545496155865245

Epoch: 6| Step: 8
Training loss: 1.205645064626491
Validation loss: 2.5911218434410164

Epoch: 6| Step: 9
Training loss: 0.3889446930450812
Validation loss: 2.5281191014369186

Epoch: 6| Step: 10
Training loss: 0.43267766732120916
Validation loss: 2.609748448128508

Epoch: 6| Step: 11
Training loss: 0.2759201694113725
Validation loss: 2.5919506388637368

Epoch: 6| Step: 12
Training loss: 0.5960935720140984
Validation loss: 2.6518927496439626

Epoch: 6| Step: 13
Training loss: 0.8553180300527191
Validation loss: 2.537595659717261

Epoch: 202| Step: 0
Training loss: 0.41121750636564613
Validation loss: 2.4575903437847972

Epoch: 6| Step: 1
Training loss: 0.6332633214032052
Validation loss: 2.5217577025005093

Epoch: 6| Step: 2
Training loss: 0.5191820735186301
Validation loss: 2.507009106192822

Epoch: 6| Step: 3
Training loss: 0.4425151365999489
Validation loss: 2.4687560198102867

Epoch: 6| Step: 4
Training loss: 0.3766055901593652
Validation loss: 2.5182708347559064

Epoch: 6| Step: 5
Training loss: 0.34405564678133504
Validation loss: 2.5072943131280065

Epoch: 6| Step: 6
Training loss: 0.6736518961126959
Validation loss: 2.607283883128256

Epoch: 6| Step: 7
Training loss: 0.37027312443632754
Validation loss: 2.5760800121357

Epoch: 6| Step: 8
Training loss: 0.573337761419222
Validation loss: 2.657610107466271

Epoch: 6| Step: 9
Training loss: 0.3314353757053229
Validation loss: 2.583189427048984

Epoch: 6| Step: 10
Training loss: 0.33693661821575827
Validation loss: 2.5422436236513106

Epoch: 6| Step: 11
Training loss: 0.37005642918131704
Validation loss: 2.5508532277847364

Epoch: 6| Step: 12
Training loss: 1.0514027058913962
Validation loss: 2.555300406720155

Epoch: 6| Step: 13
Training loss: 0.5845773805445258
Validation loss: 2.5369896942486196

Epoch: 203| Step: 0
Training loss: 0.5925422733050647
Validation loss: 2.474531168957654

Epoch: 6| Step: 1
Training loss: 0.7511536150144684
Validation loss: 2.495896555991931

Epoch: 6| Step: 2
Training loss: 0.5182089649908286
Validation loss: 2.5270931349582857

Epoch: 6| Step: 3
Training loss: 0.49673069591863056
Validation loss: 2.6113607955711124

Epoch: 6| Step: 4
Training loss: 0.5081511615338647
Validation loss: 2.581904405795635

Epoch: 6| Step: 5
Training loss: 0.4090649573687245
Validation loss: 2.610349895620902

Epoch: 6| Step: 6
Training loss: 0.5426314424555445
Validation loss: 2.5305612828059267

Epoch: 6| Step: 7
Training loss: 0.5414718742287078
Validation loss: 2.4972067885039215

Epoch: 6| Step: 8
Training loss: 0.3890321489927838
Validation loss: 2.4982723942560985

Epoch: 6| Step: 9
Training loss: 0.3237928442608185
Validation loss: 2.5681079504530677

Epoch: 6| Step: 10
Training loss: 0.3368479235318272
Validation loss: 2.5150125994155

Epoch: 6| Step: 11
Training loss: 0.5702521148485221
Validation loss: 2.4708815438604668

Epoch: 6| Step: 12
Training loss: 0.29714941843772824
Validation loss: 2.509011137644056

Epoch: 6| Step: 13
Training loss: 0.9890504339123947
Validation loss: 2.574023164565377

Epoch: 204| Step: 0
Training loss: 1.0028870154703122
Validation loss: 2.5987759961296963

Epoch: 6| Step: 1
Training loss: 0.7413718309040478
Validation loss: 2.582062975466872

Epoch: 6| Step: 2
Training loss: 0.6181413305842705
Validation loss: 2.547637926597487

Epoch: 6| Step: 3
Training loss: 0.26968531420939146
Validation loss: 2.47849568869266

Epoch: 6| Step: 4
Training loss: 0.43462061215880043
Validation loss: 2.5189489041555446

Epoch: 6| Step: 5
Training loss: 0.5384013226134335
Validation loss: 2.5018185359222525

Epoch: 6| Step: 6
Training loss: 0.3205756292943691
Validation loss: 2.3949575205535147

Epoch: 6| Step: 7
Training loss: 0.3836077001952364
Validation loss: 2.5014791086765493

Epoch: 6| Step: 8
Training loss: 0.6454377706273556
Validation loss: 2.4826705491923056

Epoch: 6| Step: 9
Training loss: 0.5064832456176913
Validation loss: 2.4697661662518215

Epoch: 6| Step: 10
Training loss: 0.41854766611964445
Validation loss: 2.5464480925759303

Epoch: 6| Step: 11
Training loss: 0.47704706415077247
Validation loss: 2.536539970718673

Epoch: 6| Step: 12
Training loss: 0.466924290844605
Validation loss: 2.5324454290818723

Epoch: 6| Step: 13
Training loss: 0.3040261059236766
Validation loss: 2.5373263874388194

Epoch: 205| Step: 0
Training loss: 0.3075643463769261
Validation loss: 2.5278466818457845

Epoch: 6| Step: 1
Training loss: 0.27320265903274993
Validation loss: 2.5771162275118242

Epoch: 6| Step: 2
Training loss: 0.3327082072078408
Validation loss: 2.5380417557095427

Epoch: 6| Step: 3
Training loss: 0.4510234572131783
Validation loss: 2.524163613110275

Epoch: 6| Step: 4
Training loss: 0.3584282054544131
Validation loss: 2.560289817649677

Epoch: 6| Step: 5
Training loss: 0.476228628304813
Validation loss: 2.551234923010882

Epoch: 6| Step: 6
Training loss: 0.4026577659285301
Validation loss: 2.566649326249373

Epoch: 6| Step: 7
Training loss: 0.38694796849309143
Validation loss: 2.496205143838306

Epoch: 6| Step: 8
Training loss: 0.4438518024582451
Validation loss: 2.599675935026413

Epoch: 6| Step: 9
Training loss: 0.46534330308357447
Validation loss: 2.5499885811269563

Epoch: 6| Step: 10
Training loss: 0.4528675828000444
Validation loss: 2.5178457216070127

Epoch: 6| Step: 11
Training loss: 0.6107310587787375
Validation loss: 2.508859964281801

Epoch: 6| Step: 12
Training loss: 0.9314392000054994
Validation loss: 2.5250399986095355

Epoch: 6| Step: 13
Training loss: 0.47806911266539714
Validation loss: 2.518505579634956

Epoch: 206| Step: 0
Training loss: 0.4192740477760569
Validation loss: 2.556735416575541

Epoch: 6| Step: 1
Training loss: 0.464147703781045
Validation loss: 2.5607240384264442

Epoch: 6| Step: 2
Training loss: 0.3073026229500048
Validation loss: 2.5160427260048523

Epoch: 6| Step: 3
Training loss: 0.3129072634955706
Validation loss: 2.480316926409845

Epoch: 6| Step: 4
Training loss: 1.0987647490222134
Validation loss: 2.48721789800354

Epoch: 6| Step: 5
Training loss: 0.6526524161860237
Validation loss: 2.5012355771110433

Epoch: 6| Step: 6
Training loss: 0.38341867371146937
Validation loss: 2.5095144737440886

Epoch: 6| Step: 7
Training loss: 0.5080655567829473
Validation loss: 2.5070476692718437

Epoch: 6| Step: 8
Training loss: 0.34166688899676523
Validation loss: 2.5523236271882612

Epoch: 6| Step: 9
Training loss: 0.5934154672334229
Validation loss: 2.62788813518106

Epoch: 6| Step: 10
Training loss: 0.35310500096766406
Validation loss: 2.6236280761712347

Epoch: 6| Step: 11
Training loss: 0.30459979824715716
Validation loss: 2.4611658222507633

Epoch: 6| Step: 12
Training loss: 0.3648128831373526
Validation loss: 2.5606510345821385

Epoch: 6| Step: 13
Training loss: 0.43808863414082405
Validation loss: 2.4955276380590723

Epoch: 207| Step: 0
Training loss: 0.4653304621378811
Validation loss: 2.59646233295397

Epoch: 6| Step: 1
Training loss: 0.6886204346017113
Validation loss: 2.4933209925828934

Epoch: 6| Step: 2
Training loss: 0.23922125089348475
Validation loss: 2.536373682717946

Epoch: 6| Step: 3
Training loss: 0.9924118809533504
Validation loss: 2.6344616382089105

Epoch: 6| Step: 4
Training loss: 0.3309593626082615
Validation loss: 2.6378657655369775

Epoch: 6| Step: 5
Training loss: 0.4969264273750281
Validation loss: 2.67421089369578

Epoch: 6| Step: 6
Training loss: 0.31980191218503484
Validation loss: 2.60344551528126

Epoch: 6| Step: 7
Training loss: 0.4881310498965341
Validation loss: 2.5802915852041597

Epoch: 6| Step: 8
Training loss: 0.31636612249162865
Validation loss: 2.590394143316549

Epoch: 6| Step: 9
Training loss: 0.5067412300781269
Validation loss: 2.492703231974216

Epoch: 6| Step: 10
Training loss: 0.5293128655189498
Validation loss: 2.515903212680441

Epoch: 6| Step: 11
Training loss: 0.46032635535204985
Validation loss: 2.480177502291648

Epoch: 6| Step: 12
Training loss: 0.4274092880289433
Validation loss: 2.461267495610593

Epoch: 6| Step: 13
Training loss: 0.4142595577967603
Validation loss: 2.472405154238298

Epoch: 208| Step: 0
Training loss: 0.4395545164338162
Validation loss: 2.567574121605678

Epoch: 6| Step: 1
Training loss: 0.507649674353922
Validation loss: 2.514472792333538

Epoch: 6| Step: 2
Training loss: 0.3104925527984894
Validation loss: 2.576216852751317

Epoch: 6| Step: 3
Training loss: 0.35131758530076185
Validation loss: 2.553276769079585

Epoch: 6| Step: 4
Training loss: 1.1018275489911111
Validation loss: 2.5156204823834467

Epoch: 6| Step: 5
Training loss: 0.3116529548254322
Validation loss: 2.539821491752132

Epoch: 6| Step: 6
Training loss: 0.3376793062775286
Validation loss: 2.5500222323576693

Epoch: 6| Step: 7
Training loss: 0.45782047173651946
Validation loss: 2.5468191285041057

Epoch: 6| Step: 8
Training loss: 0.4802211961106139
Validation loss: 2.593583327610532

Epoch: 6| Step: 9
Training loss: 0.42518309477958066
Validation loss: 2.555859047265226

Epoch: 6| Step: 10
Training loss: 0.29293571285893377
Validation loss: 2.5382283332140667

Epoch: 6| Step: 11
Training loss: 0.43372063026155333
Validation loss: 2.55042718101677

Epoch: 6| Step: 12
Training loss: 0.32183159007698864
Validation loss: 2.523136022488709

Epoch: 6| Step: 13
Training loss: 0.3059058284439018
Validation loss: 2.5553976116115815

Epoch: 209| Step: 0
Training loss: 0.15972416440040926
Validation loss: 2.54959319460074

Epoch: 6| Step: 1
Training loss: 0.3487385394493234
Validation loss: 2.507012347543095

Epoch: 6| Step: 2
Training loss: 0.2872393826264654
Validation loss: 2.523666324220264

Epoch: 6| Step: 3
Training loss: 0.44010050243530163
Validation loss: 2.5381932105672966

Epoch: 6| Step: 4
Training loss: 1.065125811045248
Validation loss: 2.564044548931122

Epoch: 6| Step: 5
Training loss: 0.38309390565729157
Validation loss: 2.6117244658396674

Epoch: 6| Step: 6
Training loss: 0.3851448939508289
Validation loss: 2.52799585528879

Epoch: 6| Step: 7
Training loss: 0.34311527476399384
Validation loss: 2.5426870444934315

Epoch: 6| Step: 8
Training loss: 0.300604409089624
Validation loss: 2.5331394223821397

Epoch: 6| Step: 9
Training loss: 0.2846263246517995
Validation loss: 2.518565266273767

Epoch: 6| Step: 10
Training loss: 0.2782961650880242
Validation loss: 2.517593750709121

Epoch: 6| Step: 11
Training loss: 0.4215441395385812
Validation loss: 2.492473876826433

Epoch: 6| Step: 12
Training loss: 0.31753790953862454
Validation loss: 2.5842162336040504

Epoch: 6| Step: 13
Training loss: 0.302966170631985
Validation loss: 2.5371803702507854

Epoch: 210| Step: 0
Training loss: 0.2967041301892073
Validation loss: 2.531056235789546

Epoch: 6| Step: 1
Training loss: 0.3993342909862475
Validation loss: 2.616288139720181

Epoch: 6| Step: 2
Training loss: 0.5320258925920206
Validation loss: 2.547153278274293

Epoch: 6| Step: 3
Training loss: 0.32576822671085076
Validation loss: 2.5287587029003586

Epoch: 6| Step: 4
Training loss: 0.36721681924195015
Validation loss: 2.486273322209387

Epoch: 6| Step: 5
Training loss: 0.3229171870852963
Validation loss: 2.4824415316680124

Epoch: 6| Step: 6
Training loss: 0.25815992354626227
Validation loss: 2.4971815911696797

Epoch: 6| Step: 7
Training loss: 0.37209934712060266
Validation loss: 2.4859947506498044

Epoch: 6| Step: 8
Training loss: 0.29907890468157183
Validation loss: 2.540193268777078

Epoch: 6| Step: 9
Training loss: 0.3824483735642303
Validation loss: 2.517545736857706

Epoch: 6| Step: 10
Training loss: 0.43925817615973994
Validation loss: 2.534099246826638

Epoch: 6| Step: 11
Training loss: 0.43296393626857266
Validation loss: 2.5498646076885185

Epoch: 6| Step: 12
Training loss: 0.46640572859385115
Validation loss: 2.506470183342715

Epoch: 6| Step: 13
Training loss: 1.0865431818590146
Validation loss: 2.5949683640841825

Epoch: 211| Step: 0
Training loss: 0.3929262657786383
Validation loss: 2.505062572233284

Epoch: 6| Step: 1
Training loss: 0.4833794792387995
Validation loss: 2.5305954357633356

Epoch: 6| Step: 2
Training loss: 0.97842409844177
Validation loss: 2.552901838705854

Epoch: 6| Step: 3
Training loss: 0.42829652538426544
Validation loss: 2.4915047151716276

Epoch: 6| Step: 4
Training loss: 0.24721375172875798
Validation loss: 2.5223099952242505

Epoch: 6| Step: 5
Training loss: 0.3296971238345218
Validation loss: 2.5325701375414202

Epoch: 6| Step: 6
Training loss: 0.46933022192793816
Validation loss: 2.5122178898296466

Epoch: 6| Step: 7
Training loss: 0.6381052519295342
Validation loss: 2.5457561430230276

Epoch: 6| Step: 8
Training loss: 0.3878100247115847
Validation loss: 2.5440375937957036

Epoch: 6| Step: 9
Training loss: 0.3236898911765858
Validation loss: 2.589642516421734

Epoch: 6| Step: 10
Training loss: 0.6078372283455464
Validation loss: 2.6480822629693437

Epoch: 6| Step: 11
Training loss: 0.5355041932085207
Validation loss: 2.5815699824663554

Epoch: 6| Step: 12
Training loss: 0.3474123881721584
Validation loss: 2.4727698365809627

Epoch: 6| Step: 13
Training loss: 0.40349791082623676
Validation loss: 2.557557386796711

Epoch: 212| Step: 0
Training loss: 0.38637440696406694
Validation loss: 2.522639082346845

Epoch: 6| Step: 1
Training loss: 0.3654382310171369
Validation loss: 2.4730274309538673

Epoch: 6| Step: 2
Training loss: 0.4298797524121016
Validation loss: 2.4914684155119797

Epoch: 6| Step: 3
Training loss: 0.9044111933448697
Validation loss: 2.477888624696405

Epoch: 6| Step: 4
Training loss: 0.3488036306224535
Validation loss: 2.587383231079056

Epoch: 6| Step: 5
Training loss: 0.5275440542076001
Validation loss: 2.621729614931292

Epoch: 6| Step: 6
Training loss: 0.36277629254342003
Validation loss: 2.5898966297180706

Epoch: 6| Step: 7
Training loss: 0.4098974046915351
Validation loss: 2.532407417513036

Epoch: 6| Step: 8
Training loss: 0.3494756965161718
Validation loss: 2.5014024774254198

Epoch: 6| Step: 9
Training loss: 0.36441783100395486
Validation loss: 2.46273950874

Epoch: 6| Step: 10
Training loss: 0.5299683144382765
Validation loss: 2.559522884258893

Epoch: 6| Step: 11
Training loss: 0.39522523557641587
Validation loss: 2.502850441354747

Epoch: 6| Step: 12
Training loss: 0.39927383610151684
Validation loss: 2.504657182452485

Epoch: 6| Step: 13
Training loss: 0.616898915871731
Validation loss: 2.581183328452549

Epoch: 213| Step: 0
Training loss: 0.32869840655861793
Validation loss: 2.523085562746072

Epoch: 6| Step: 1
Training loss: 0.38371612010967643
Validation loss: 2.5940212123280983

Epoch: 6| Step: 2
Training loss: 0.2766848514413748
Validation loss: 2.5066421011809976

Epoch: 6| Step: 3
Training loss: 0.5463327716993635
Validation loss: 2.5145984948393068

Epoch: 6| Step: 4
Training loss: 0.37915978355587865
Validation loss: 2.5441636551323654

Epoch: 6| Step: 5
Training loss: 1.0200607269572743
Validation loss: 2.488222497778429

Epoch: 6| Step: 6
Training loss: 0.28634832032555146
Validation loss: 2.540476541220785

Epoch: 6| Step: 7
Training loss: 0.41403604818819223
Validation loss: 2.4987764702330435

Epoch: 6| Step: 8
Training loss: 0.32713158407498344
Validation loss: 2.579237618854447

Epoch: 6| Step: 9
Training loss: 0.23688489572443056
Validation loss: 2.487055326297601

Epoch: 6| Step: 10
Training loss: 0.3183250759815523
Validation loss: 2.4986490414152858

Epoch: 6| Step: 11
Training loss: 0.5268255442693492
Validation loss: 2.53075277680315

Epoch: 6| Step: 12
Training loss: 0.2954443919622948
Validation loss: 2.5093127365273715

Epoch: 6| Step: 13
Training loss: 0.4858087424286674
Validation loss: 2.4464061513608653

Epoch: 214| Step: 0
Training loss: 0.3911413213653333
Validation loss: 2.4834686561384736

Epoch: 6| Step: 1
Training loss: 0.9709564738020428
Validation loss: 2.47668033163101

Epoch: 6| Step: 2
Training loss: 0.5159186480732679
Validation loss: 2.48988722432196

Epoch: 6| Step: 3
Training loss: 0.5110692568874993
Validation loss: 2.5181990460261483

Epoch: 6| Step: 4
Training loss: 0.22741201234567177
Validation loss: 2.5081622631461804

Epoch: 6| Step: 5
Training loss: 0.2591569121529531
Validation loss: 2.5837896364490964

Epoch: 6| Step: 6
Training loss: 0.3563697212227011
Validation loss: 2.567015398989593

Epoch: 6| Step: 7
Training loss: 0.3066133620661877
Validation loss: 2.5830935910457686

Epoch: 6| Step: 8
Training loss: 0.3498840957555037
Validation loss: 2.5057361440667805

Epoch: 6| Step: 9
Training loss: 0.30727098147497567
Validation loss: 2.5604359136923165

Epoch: 6| Step: 10
Training loss: 0.5892004332202865
Validation loss: 2.5747642267179023

Epoch: 6| Step: 11
Training loss: 0.27048957845881016
Validation loss: 2.5645419258185678

Epoch: 6| Step: 12
Training loss: 0.37682838550211745
Validation loss: 2.577986757829905

Epoch: 6| Step: 13
Training loss: 0.3922788703534492
Validation loss: 2.5358250092983945

Epoch: 215| Step: 0
Training loss: 0.3809143809186885
Validation loss: 2.5634283617120213

Epoch: 6| Step: 1
Training loss: 0.4609109741595777
Validation loss: 2.498659950963172

Epoch: 6| Step: 2
Training loss: 0.6021624954171368
Validation loss: 2.524162763019749

Epoch: 6| Step: 3
Training loss: 0.40268422507352103
Validation loss: 2.497800033896487

Epoch: 6| Step: 4
Training loss: 0.42911501808235536
Validation loss: 2.509645800074072

Epoch: 6| Step: 5
Training loss: 0.36452141190524906
Validation loss: 2.560668026841423

Epoch: 6| Step: 6
Training loss: 0.34589534738755384
Validation loss: 2.516474357314156

Epoch: 6| Step: 7
Training loss: 0.35497977612203535
Validation loss: 2.536030716983797

Epoch: 6| Step: 8
Training loss: 0.39422554031432777
Validation loss: 2.477796742400431

Epoch: 6| Step: 9
Training loss: 0.24412596086331537
Validation loss: 2.5176243073711375

Epoch: 6| Step: 10
Training loss: 0.3579755777934183
Validation loss: 2.479571603247178

Epoch: 6| Step: 11
Training loss: 0.37282251931322324
Validation loss: 2.542834620691114

Epoch: 6| Step: 12
Training loss: 0.2892726829977017
Validation loss: 2.5211518667020396

Epoch: 6| Step: 13
Training loss: 0.9220347508524177
Validation loss: 2.5547697810339125

Epoch: 216| Step: 0
Training loss: 0.5769651480153576
Validation loss: 2.5830861762982957

Epoch: 6| Step: 1
Training loss: 0.35106670599739337
Validation loss: 2.5050297208838854

Epoch: 6| Step: 2
Training loss: 0.28507845614354727
Validation loss: 2.538784227038756

Epoch: 6| Step: 3
Training loss: 0.4287566071604569
Validation loss: 2.5088198055939186

Epoch: 6| Step: 4
Training loss: 0.41700680280529207
Validation loss: 2.4943568594730197

Epoch: 6| Step: 5
Training loss: 0.9941978213301527
Validation loss: 2.5457685676698505

Epoch: 6| Step: 6
Training loss: 0.36235175636726996
Validation loss: 2.4365218392508954

Epoch: 6| Step: 7
Training loss: 0.6156618843066706
Validation loss: 2.508296773227972

Epoch: 6| Step: 8
Training loss: 0.4397155995123593
Validation loss: 2.4742717397171003

Epoch: 6| Step: 9
Training loss: 0.3216067427736113
Validation loss: 2.465646539488466

Epoch: 6| Step: 10
Training loss: 0.41900773016916176
Validation loss: 2.5470928574824003

Epoch: 6| Step: 11
Training loss: 0.35583617535706147
Validation loss: 2.5230478117730866

Epoch: 6| Step: 12
Training loss: 0.4003074745738287
Validation loss: 2.4646254501764133

Epoch: 6| Step: 13
Training loss: 0.4198292297362376
Validation loss: 2.4552390673762052

Epoch: 217| Step: 0
Training loss: 0.4003262723985053
Validation loss: 2.479758541929963

Epoch: 6| Step: 1
Training loss: 0.4738043720175687
Validation loss: 2.5042545197405377

Epoch: 6| Step: 2
Training loss: 0.3483360801516988
Validation loss: 2.5034343574354048

Epoch: 6| Step: 3
Training loss: 0.2671948493259072
Validation loss: 2.4476238292012487

Epoch: 6| Step: 4
Training loss: 0.30900763268596093
Validation loss: 2.5112334752112733

Epoch: 6| Step: 5
Training loss: 0.28962006793311196
Validation loss: 2.5123459590042767

Epoch: 6| Step: 6
Training loss: 0.5581793414976086
Validation loss: 2.516141984468513

Epoch: 6| Step: 7
Training loss: 0.38529610251676405
Validation loss: 2.543906402778453

Epoch: 6| Step: 8
Training loss: 0.4077112803046466
Validation loss: 2.5299662407594146

Epoch: 6| Step: 9
Training loss: 0.3035260708065702
Validation loss: 2.519230850803615

Epoch: 6| Step: 10
Training loss: 0.8941395997474428
Validation loss: 2.575170075870705

Epoch: 6| Step: 11
Training loss: 0.25510141345234044
Validation loss: 2.531065498503816

Epoch: 6| Step: 12
Training loss: 0.209802585591988
Validation loss: 2.5454102264995555

Epoch: 6| Step: 13
Training loss: 0.36363344655302815
Validation loss: 2.5476802496865147

Epoch: 218| Step: 0
Training loss: 0.35852753187812003
Validation loss: 2.5242484475563898

Epoch: 6| Step: 1
Training loss: 0.47455687683865505
Validation loss: 2.5396865469091074

Epoch: 6| Step: 2
Training loss: 0.33356721937826866
Validation loss: 2.499654444018807

Epoch: 6| Step: 3
Training loss: 0.478496379854545
Validation loss: 2.546814705226646

Epoch: 6| Step: 4
Training loss: 0.39119187230977515
Validation loss: 2.5195742896689284

Epoch: 6| Step: 5
Training loss: 0.369319065299678
Validation loss: 2.491135856666396

Epoch: 6| Step: 6
Training loss: 0.3114204595283953
Validation loss: 2.5226182975918805

Epoch: 6| Step: 7
Training loss: 0.8399189050448245
Validation loss: 2.633066348130334

Epoch: 6| Step: 8
Training loss: 0.3715594531705144
Validation loss: 2.587254061352032

Epoch: 6| Step: 9
Training loss: 0.41092023994546667
Validation loss: 2.616881615522787

Epoch: 6| Step: 10
Training loss: 0.3184792579584537
Validation loss: 2.5309493588842775

Epoch: 6| Step: 11
Training loss: 0.33838700894429385
Validation loss: 2.546559273276191

Epoch: 6| Step: 12
Training loss: 0.5333560263256346
Validation loss: 2.4773520124769415

Epoch: 6| Step: 13
Training loss: 0.4653393643773088
Validation loss: 2.4650949067060677

Epoch: 219| Step: 0
Training loss: 0.30890943580570734
Validation loss: 2.4678220091229943

Epoch: 6| Step: 1
Training loss: 0.4798498431917892
Validation loss: 2.4881911488523407

Epoch: 6| Step: 2
Training loss: 0.37881543359091024
Validation loss: 2.510243632788945

Epoch: 6| Step: 3
Training loss: 0.3781510131337143
Validation loss: 2.484716236023657

Epoch: 6| Step: 4
Training loss: 0.3077332050798059
Validation loss: 2.577092883113682

Epoch: 6| Step: 5
Training loss: 0.3293285096744485
Validation loss: 2.609212660926777

Epoch: 6| Step: 6
Training loss: 0.590797865259915
Validation loss: 2.5934312310491427

Epoch: 6| Step: 7
Training loss: 0.36247592796771516
Validation loss: 2.528075044104599

Epoch: 6| Step: 8
Training loss: 0.2954642506402597
Validation loss: 2.575438376952715

Epoch: 6| Step: 9
Training loss: 0.4271966349721028
Validation loss: 2.5285577231606093

Epoch: 6| Step: 10
Training loss: 0.49146641785927025
Validation loss: 2.515540253848606

Epoch: 6| Step: 11
Training loss: 0.9087952027235381
Validation loss: 2.5508952794429978

Epoch: 6| Step: 12
Training loss: 0.29104615377782317
Validation loss: 2.525971485749203

Epoch: 6| Step: 13
Training loss: 0.3280828993899966
Validation loss: 2.499570571257229

Epoch: 220| Step: 0
Training loss: 0.404015005142274
Validation loss: 2.542935982066747

Epoch: 6| Step: 1
Training loss: 0.3219247112959266
Validation loss: 2.500973988583457

Epoch: 6| Step: 2
Training loss: 0.595726037757351
Validation loss: 2.510943208508747

Epoch: 6| Step: 3
Training loss: 0.4843127764451098
Validation loss: 2.514320714637797

Epoch: 6| Step: 4
Training loss: 0.48766354971876275
Validation loss: 2.518697154056303

Epoch: 6| Step: 5
Training loss: 0.39366284722879846
Validation loss: 2.5250445308472558

Epoch: 6| Step: 6
Training loss: 0.8110393820324702
Validation loss: 2.5189811165084044

Epoch: 6| Step: 7
Training loss: 0.41311163856148514
Validation loss: 2.5516682241805904

Epoch: 6| Step: 8
Training loss: 0.2844747735104144
Validation loss: 2.5431404426926467

Epoch: 6| Step: 9
Training loss: 0.4062470656068902
Validation loss: 2.5786006064941094

Epoch: 6| Step: 10
Training loss: 0.4276670289693434
Validation loss: 2.522248672098327

Epoch: 6| Step: 11
Training loss: 0.3807497698231513
Validation loss: 2.5294055498064645

Epoch: 6| Step: 12
Training loss: 0.2791326747074933
Validation loss: 2.6043701143267004

Epoch: 6| Step: 13
Training loss: 0.41630143211552756
Validation loss: 2.5357144862353365

Epoch: 221| Step: 0
Training loss: 0.3700817362935488
Validation loss: 2.537844834441324

Epoch: 6| Step: 1
Training loss: 0.33986808426651016
Validation loss: 2.4735860015700877

Epoch: 6| Step: 2
Training loss: 0.28684250761869146
Validation loss: 2.509014091333537

Epoch: 6| Step: 3
Training loss: 0.40331759694365205
Validation loss: 2.5608912124159082

Epoch: 6| Step: 4
Training loss: 0.40229978598973715
Validation loss: 2.5800999176776065

Epoch: 6| Step: 5
Training loss: 0.8466361803538491
Validation loss: 2.5040314514629545

Epoch: 6| Step: 6
Training loss: 0.32262259855119324
Validation loss: 2.5569468704102536

Epoch: 6| Step: 7
Training loss: 0.33414785388461127
Validation loss: 2.5201538578375047

Epoch: 6| Step: 8
Training loss: 0.33418031711396434
Validation loss: 2.5708572598853006

Epoch: 6| Step: 9
Training loss: 0.40466593975827214
Validation loss: 2.561078320755566

Epoch: 6| Step: 10
Training loss: 0.38335434849119765
Validation loss: 2.5795608067338933

Epoch: 6| Step: 11
Training loss: 0.29678033273038396
Validation loss: 2.529187826312151

Epoch: 6| Step: 12
Training loss: 0.35211221315041186
Validation loss: 2.5360218641249173

Epoch: 6| Step: 13
Training loss: 0.5904465430980386
Validation loss: 2.5556857834911955

Epoch: 222| Step: 0
Training loss: 0.34137361750258177
Validation loss: 2.5701158597140554

Epoch: 6| Step: 1
Training loss: 0.44338017889611236
Validation loss: 2.5346429792120406

Epoch: 6| Step: 2
Training loss: 0.30788443930122394
Validation loss: 2.4995031180919702

Epoch: 6| Step: 3
Training loss: 0.39994183951979084
Validation loss: 2.5187426769695995

Epoch: 6| Step: 4
Training loss: 0.38479164926266934
Validation loss: 2.4950434505269636

Epoch: 6| Step: 5
Training loss: 0.6337983728791787
Validation loss: 2.4827255915608823

Epoch: 6| Step: 6
Training loss: 0.32007762392138456
Validation loss: 2.480828430850928

Epoch: 6| Step: 7
Training loss: 0.5912502773518143
Validation loss: 2.6248324961428326

Epoch: 6| Step: 8
Training loss: 0.44028929103006936
Validation loss: 2.6254776111433498

Epoch: 6| Step: 9
Training loss: 0.3824524840904252
Validation loss: 2.6102616408444463

Epoch: 6| Step: 10
Training loss: 0.3411184062075867
Validation loss: 2.6636985164722935

Epoch: 6| Step: 11
Training loss: 0.8441419750592947
Validation loss: 2.5859118611120215

Epoch: 6| Step: 12
Training loss: 0.2206881273288286
Validation loss: 2.5969254079884867

Epoch: 6| Step: 13
Training loss: 0.30436841444532287
Validation loss: 2.56871668042975

Epoch: 223| Step: 0
Training loss: 0.3333658659477167
Validation loss: 2.5619899893512246

Epoch: 6| Step: 1
Training loss: 0.3161189812071789
Validation loss: 2.594110624682419

Epoch: 6| Step: 2
Training loss: 0.3173237907109532
Validation loss: 2.5201078321960337

Epoch: 6| Step: 3
Training loss: 0.3192962831846856
Validation loss: 2.5813525101794

Epoch: 6| Step: 4
Training loss: 0.4671462758481006
Validation loss: 2.5534691583705356

Epoch: 6| Step: 5
Training loss: 0.2830399799691633
Validation loss: 2.5229715836394213

Epoch: 6| Step: 6
Training loss: 0.3195393582273646
Validation loss: 2.577863938186081

Epoch: 6| Step: 7
Training loss: 0.37188838405726515
Validation loss: 2.5350222794646604

Epoch: 6| Step: 8
Training loss: 0.6235630205421229
Validation loss: 2.585045006469052

Epoch: 6| Step: 9
Training loss: 0.4416048059087099
Validation loss: 2.616016122006153

Epoch: 6| Step: 10
Training loss: 0.9365926166079669
Validation loss: 2.5624330403333104

Epoch: 6| Step: 11
Training loss: 0.26545506539192176
Validation loss: 2.5059742909873677

Epoch: 6| Step: 12
Training loss: 0.30914471127824683
Validation loss: 2.5133798662308267

Epoch: 6| Step: 13
Training loss: 0.39938979319962686
Validation loss: 2.4922622701336663

Epoch: 224| Step: 0
Training loss: 0.3820806046259851
Validation loss: 2.535534666372184

Epoch: 6| Step: 1
Training loss: 0.3200915900673987
Validation loss: 2.5517017676117093

Epoch: 6| Step: 2
Training loss: 0.8215093328627255
Validation loss: 2.566937798468054

Epoch: 6| Step: 3
Training loss: 0.3093354209474571
Validation loss: 2.5910485381960333

Epoch: 6| Step: 4
Training loss: 0.2674931439965006
Validation loss: 2.635209860747849

Epoch: 6| Step: 5
Training loss: 0.6382455598711847
Validation loss: 2.6385176336130414

Epoch: 6| Step: 6
Training loss: 0.47698246321240517
Validation loss: 2.646719135978243

Epoch: 6| Step: 7
Training loss: 0.3523126228945418
Validation loss: 2.567991548024437

Epoch: 6| Step: 8
Training loss: 0.3441604742762347
Validation loss: 2.6242435061593166

Epoch: 6| Step: 9
Training loss: 0.31108392306201327
Validation loss: 2.5602683297237343

Epoch: 6| Step: 10
Training loss: 0.6677092332481791
Validation loss: 2.5554076646660455

Epoch: 6| Step: 11
Training loss: 0.31303804094279797
Validation loss: 2.5416370113914906

Epoch: 6| Step: 12
Training loss: 0.4804513819587008
Validation loss: 2.598666628952411

Epoch: 6| Step: 13
Training loss: 0.5193430624276204
Validation loss: 2.6056851016480684

Epoch: 225| Step: 0
Training loss: 0.4407336080903333
Validation loss: 2.650491208908949

Epoch: 6| Step: 1
Training loss: 0.5177554420616203
Validation loss: 2.6629079515146117

Epoch: 6| Step: 2
Training loss: 0.3805610270679204
Validation loss: 2.6175343905147734

Epoch: 6| Step: 3
Training loss: 0.2917280118439445
Validation loss: 2.5286109573572997

Epoch: 6| Step: 4
Training loss: 0.3635081331295541
Validation loss: 2.5335587070836105

Epoch: 6| Step: 5
Training loss: 0.28623230281829204
Validation loss: 2.543786522417995

Epoch: 6| Step: 6
Training loss: 0.3005775157995466
Validation loss: 2.468298166510899

Epoch: 6| Step: 7
Training loss: 0.32054899370728435
Validation loss: 2.496506093272505

Epoch: 6| Step: 8
Training loss: 0.681607286572517
Validation loss: 2.4928096923327727

Epoch: 6| Step: 9
Training loss: 0.8481206368971544
Validation loss: 2.5537844898336535

Epoch: 6| Step: 10
Training loss: 0.46738245478232593
Validation loss: 2.5677272236240722

Epoch: 6| Step: 11
Training loss: 0.4445615426252598
Validation loss: 2.515922686731803

Epoch: 6| Step: 12
Training loss: 0.4182412872205005
Validation loss: 2.613350358399903

Epoch: 6| Step: 13
Training loss: 0.3023611167237373
Validation loss: 2.5085269627233755

Epoch: 226| Step: 0
Training loss: 0.3593977216089001
Validation loss: 2.475671730335598

Epoch: 6| Step: 1
Training loss: 0.4240124209469509
Validation loss: 2.520600502569208

Epoch: 6| Step: 2
Training loss: 0.37312699501104896
Validation loss: 2.5654068873098606

Epoch: 6| Step: 3
Training loss: 0.3232284496880088
Validation loss: 2.512520582516504

Epoch: 6| Step: 4
Training loss: 0.4660968879136264
Validation loss: 2.562085218897773

Epoch: 6| Step: 5
Training loss: 0.4046760292342256
Validation loss: 2.597059765549726

Epoch: 6| Step: 6
Training loss: 0.3958028752337223
Validation loss: 2.5019448583199813

Epoch: 6| Step: 7
Training loss: 0.4159164668725819
Validation loss: 2.5869891975525294

Epoch: 6| Step: 8
Training loss: 0.3695585317400257
Validation loss: 2.615492162517827

Epoch: 6| Step: 9
Training loss: 0.4193783991316324
Validation loss: 2.575716384751281

Epoch: 6| Step: 10
Training loss: 0.4144321447126248
Validation loss: 2.545334004591741

Epoch: 6| Step: 11
Training loss: 0.41035837914943324
Validation loss: 2.60893550377156

Epoch: 6| Step: 12
Training loss: 0.8128841299066074
Validation loss: 2.6264477325182756

Epoch: 6| Step: 13
Training loss: 0.6395468128807588
Validation loss: 2.5641432897225114

Epoch: 227| Step: 0
Training loss: 0.4672316118931787
Validation loss: 2.5978488018978263

Epoch: 6| Step: 1
Training loss: 0.38325084190873393
Validation loss: 2.616546347356508

Epoch: 6| Step: 2
Training loss: 0.2837102361788847
Validation loss: 2.5913671785571197

Epoch: 6| Step: 3
Training loss: 0.3059012860538301
Validation loss: 2.569941253287538

Epoch: 6| Step: 4
Training loss: 0.23587522379546674
Validation loss: 2.518691506033946

Epoch: 6| Step: 5
Training loss: 0.3374763330355978
Validation loss: 2.535731441879824

Epoch: 6| Step: 6
Training loss: 0.5212920902374371
Validation loss: 2.4974106333071644

Epoch: 6| Step: 7
Training loss: 0.5094115097909799
Validation loss: 2.4843552786566154

Epoch: 6| Step: 8
Training loss: 0.32380782363996063
Validation loss: 2.510568643193344

Epoch: 6| Step: 9
Training loss: 0.8675093869627613
Validation loss: 2.546001151797585

Epoch: 6| Step: 10
Training loss: 0.4141686321489503
Validation loss: 2.5263267330021884

Epoch: 6| Step: 11
Training loss: 0.39171682359596827
Validation loss: 2.5486372173426295

Epoch: 6| Step: 12
Training loss: 0.2901508873529718
Validation loss: 2.438427984843319

Epoch: 6| Step: 13
Training loss: 0.48279177426787234
Validation loss: 2.4408190130341363

Epoch: 228| Step: 0
Training loss: 0.4449055301118924
Validation loss: 2.4714557491497886

Epoch: 6| Step: 1
Training loss: 0.5933710947191501
Validation loss: 2.4559015164350417

Epoch: 6| Step: 2
Training loss: 0.3514652753542714
Validation loss: 2.497073137094996

Epoch: 6| Step: 3
Training loss: 0.25078022918018056
Validation loss: 2.5394919633792643

Epoch: 6| Step: 4
Training loss: 0.38215717354429785
Validation loss: 2.601692372117096

Epoch: 6| Step: 5
Training loss: 0.38191159954839504
Validation loss: 2.637744694548464

Epoch: 6| Step: 6
Training loss: 0.5912964470747407
Validation loss: 2.573076240646484

Epoch: 6| Step: 7
Training loss: 0.3539287618925548
Validation loss: 2.569994047741856

Epoch: 6| Step: 8
Training loss: 0.3301396848618352
Validation loss: 2.5341159545489123

Epoch: 6| Step: 9
Training loss: 0.5563391421180318
Validation loss: 2.482573049660766

Epoch: 6| Step: 10
Training loss: 0.38467564958901934
Validation loss: 2.534507162879068

Epoch: 6| Step: 11
Training loss: 0.5240263402448256
Validation loss: 2.50871034990956

Epoch: 6| Step: 12
Training loss: 0.8684668168606487
Validation loss: 2.537055136610111

Epoch: 6| Step: 13
Training loss: 0.5258602610110077
Validation loss: 2.490750846411609

Epoch: 229| Step: 0
Training loss: 0.3487344054184449
Validation loss: 2.528499380336789

Epoch: 6| Step: 1
Training loss: 0.40724623012846883
Validation loss: 2.564064734421337

Epoch: 6| Step: 2
Training loss: 0.8798623881790326
Validation loss: 2.673583311841918

Epoch: 6| Step: 3
Training loss: 0.3898132281691867
Validation loss: 2.6373175499170256

Epoch: 6| Step: 4
Training loss: 0.39375595360750804
Validation loss: 2.611471616825079

Epoch: 6| Step: 5
Training loss: 0.45058488849836914
Validation loss: 2.5060075184378725

Epoch: 6| Step: 6
Training loss: 0.5344080184194336
Validation loss: 2.5384345740477112

Epoch: 6| Step: 7
Training loss: 0.5699450733256002
Validation loss: 2.473472576973025

Epoch: 6| Step: 8
Training loss: 0.3468022626787893
Validation loss: 2.525088530898939

Epoch: 6| Step: 9
Training loss: 0.2848193778546312
Validation loss: 2.5145749493079648

Epoch: 6| Step: 10
Training loss: 0.3860080044551419
Validation loss: 2.601006510513138

Epoch: 6| Step: 11
Training loss: 0.3412880079531022
Validation loss: 2.62416667426618

Epoch: 6| Step: 12
Training loss: 0.4021577497740829
Validation loss: 2.6224927735933683

Epoch: 6| Step: 13
Training loss: 0.46045811827585575
Validation loss: 2.638956374147617

Epoch: 230| Step: 0
Training loss: 0.8561931312777393
Validation loss: 2.608674722538023

Epoch: 6| Step: 1
Training loss: 0.2823401357887035
Validation loss: 2.55265749227204

Epoch: 6| Step: 2
Training loss: 0.4155923185191194
Validation loss: 2.543338121815478

Epoch: 6| Step: 3
Training loss: 0.3500900054904367
Validation loss: 2.5244012336724717

Epoch: 6| Step: 4
Training loss: 0.45375004770998534
Validation loss: 2.542198802920526

Epoch: 6| Step: 5
Training loss: 0.3369203428705856
Validation loss: 2.473337442218147

Epoch: 6| Step: 6
Training loss: 0.33602579198559046
Validation loss: 2.613297097956829

Epoch: 6| Step: 7
Training loss: 0.392381856261133
Validation loss: 2.590600687057839

Epoch: 6| Step: 8
Training loss: 0.24909853831263956
Validation loss: 2.4611471742791657

Epoch: 6| Step: 9
Training loss: 0.32044047613605203
Validation loss: 2.5266021631037576

Epoch: 6| Step: 10
Training loss: 0.5393164216342278
Validation loss: 2.537826096200381

Epoch: 6| Step: 11
Training loss: 0.3471355074314572
Validation loss: 2.4728151805677876

Epoch: 6| Step: 12
Training loss: 0.36695407996440205
Validation loss: 2.529142059340534

Epoch: 6| Step: 13
Training loss: 0.31776632759379336
Validation loss: 2.551734734426114

Epoch: 231| Step: 0
Training loss: 0.488313185601148
Validation loss: 2.4911985836921535

Epoch: 6| Step: 1
Training loss: 0.44791882721431614
Validation loss: 2.5984438130142804

Epoch: 6| Step: 2
Training loss: 0.4393469109923812
Validation loss: 2.591325898679048

Epoch: 6| Step: 3
Training loss: 0.42466795025109516
Validation loss: 2.5880938065138417

Epoch: 6| Step: 4
Training loss: 0.3682117785386543
Validation loss: 2.527275112031739

Epoch: 6| Step: 5
Training loss: 0.32199288589011216
Validation loss: 2.495498474809021

Epoch: 6| Step: 6
Training loss: 0.2935666024130755
Validation loss: 2.57636421262629

Epoch: 6| Step: 7
Training loss: 0.301768873684812
Validation loss: 2.459065770020894

Epoch: 6| Step: 8
Training loss: 0.8595556589449457
Validation loss: 2.4990788352145903

Epoch: 6| Step: 9
Training loss: 0.26659278715454127
Validation loss: 2.563322121463789

Epoch: 6| Step: 10
Training loss: 0.4484603450684776
Validation loss: 2.5732565563942003

Epoch: 6| Step: 11
Training loss: 0.3208261302762813
Validation loss: 2.504710091726769

Epoch: 6| Step: 12
Training loss: 0.29213676573156844
Validation loss: 2.553301015986344

Epoch: 6| Step: 13
Training loss: 0.32946085348420157
Validation loss: 2.4656782233968846

Epoch: 232| Step: 0
Training loss: 0.3389429892591917
Validation loss: 2.5323126803150915

Epoch: 6| Step: 1
Training loss: 0.3762334961297314
Validation loss: 2.5234627579723083

Epoch: 6| Step: 2
Training loss: 0.29628142194257095
Validation loss: 2.591870871979758

Epoch: 6| Step: 3
Training loss: 0.3060745310725501
Validation loss: 2.5900513425301517

Epoch: 6| Step: 4
Training loss: 0.2492141741150173
Validation loss: 2.5192335401393984

Epoch: 6| Step: 5
Training loss: 0.33011373068277383
Validation loss: 2.523231072736872

Epoch: 6| Step: 6
Training loss: 0.4209059252150371
Validation loss: 2.4842307010865983

Epoch: 6| Step: 7
Training loss: 0.20385179340564527
Validation loss: 2.4502790266209984

Epoch: 6| Step: 8
Training loss: 0.3873076530646952
Validation loss: 2.4873901080932783

Epoch: 6| Step: 9
Training loss: 0.4007331127682774
Validation loss: 2.4559103506865503

Epoch: 6| Step: 10
Training loss: 0.2468610035272577
Validation loss: 2.535368845312855

Epoch: 6| Step: 11
Training loss: 0.4891323149456064
Validation loss: 2.5105522140272845

Epoch: 6| Step: 12
Training loss: 0.8279926266226748
Validation loss: 2.5048780216917312

Epoch: 6| Step: 13
Training loss: 0.23982726080809166
Validation loss: 2.5201034566416567

Epoch: 233| Step: 0
Training loss: 0.2867998024196955
Validation loss: 2.529527093530972

Epoch: 6| Step: 1
Training loss: 0.26804561569109286
Validation loss: 2.487881822531057

Epoch: 6| Step: 2
Training loss: 0.45695406922301374
Validation loss: 2.515114529076771

Epoch: 6| Step: 3
Training loss: 0.4899698584881193
Validation loss: 2.524060112484213

Epoch: 6| Step: 4
Training loss: 0.7861275808977708
Validation loss: 2.482611152001955

Epoch: 6| Step: 5
Training loss: 0.2540315465616848
Validation loss: 2.540377404542156

Epoch: 6| Step: 6
Training loss: 0.28791463899289466
Validation loss: 2.5345804729337877

Epoch: 6| Step: 7
Training loss: 0.37542581224609595
Validation loss: 2.5789578566404523

Epoch: 6| Step: 8
Training loss: 0.46863573589018864
Validation loss: 2.5270628500347025

Epoch: 6| Step: 9
Training loss: 0.3655089707767471
Validation loss: 2.588182609928406

Epoch: 6| Step: 10
Training loss: 0.30268196144448106
Validation loss: 2.5083765522559225

Epoch: 6| Step: 11
Training loss: 0.3895567210010703
Validation loss: 2.4853804371173864

Epoch: 6| Step: 12
Training loss: 0.4107248270861846
Validation loss: 2.4852573739161694

Epoch: 6| Step: 13
Training loss: 0.31480127810118175
Validation loss: 2.4839310959234457

Epoch: 234| Step: 0
Training loss: 0.2973967785438887
Validation loss: 2.491002756888815

Epoch: 6| Step: 1
Training loss: 0.30021005121507716
Validation loss: 2.557213330800947

Epoch: 6| Step: 2
Training loss: 0.35218982887005795
Validation loss: 2.5148236516753975

Epoch: 6| Step: 3
Training loss: 0.4423389876259878
Validation loss: 2.533155563876635

Epoch: 6| Step: 4
Training loss: 0.7640938142003647
Validation loss: 2.562628859094526

Epoch: 6| Step: 5
Training loss: 0.35738635277503433
Validation loss: 2.534876215769818

Epoch: 6| Step: 6
Training loss: 0.2779867348259087
Validation loss: 2.5563611566801305

Epoch: 6| Step: 7
Training loss: 0.35480229288847265
Validation loss: 2.5204785993268244

Epoch: 6| Step: 8
Training loss: 0.45652044720101637
Validation loss: 2.5127527492544717

Epoch: 6| Step: 9
Training loss: 0.24926439483134336
Validation loss: 2.546720660005106

Epoch: 6| Step: 10
Training loss: 0.4535932095031987
Validation loss: 2.504802065533729

Epoch: 6| Step: 11
Training loss: 0.33984143705786757
Validation loss: 2.503856608850419

Epoch: 6| Step: 12
Training loss: 0.4882336097364819
Validation loss: 2.521733514723752

Epoch: 6| Step: 13
Training loss: 0.5527461289952211
Validation loss: 2.541655592555534

Epoch: 235| Step: 0
Training loss: 0.3773396541144125
Validation loss: 2.5465357735916947

Epoch: 6| Step: 1
Training loss: 0.2687003139653375
Validation loss: 2.4914532001194845

Epoch: 6| Step: 2
Training loss: 0.22952081217706125
Validation loss: 2.5823313759390567

Epoch: 6| Step: 3
Training loss: 0.25167079750569776
Validation loss: 2.530064049903897

Epoch: 6| Step: 4
Training loss: 0.7569915414637447
Validation loss: 2.588557365467098

Epoch: 6| Step: 5
Training loss: 0.4802962823238245
Validation loss: 2.544603376153974

Epoch: 6| Step: 6
Training loss: 0.29073566052737987
Validation loss: 2.575609933965987

Epoch: 6| Step: 7
Training loss: 0.42310061619762646
Validation loss: 2.514627499786417

Epoch: 6| Step: 8
Training loss: 0.22290674139963648
Validation loss: 2.556224893137308

Epoch: 6| Step: 9
Training loss: 0.38537245788997854
Validation loss: 2.531290603437625

Epoch: 6| Step: 10
Training loss: 0.44791834483460685
Validation loss: 2.4862422603654846

Epoch: 6| Step: 11
Training loss: 0.2641691534234178
Validation loss: 2.5430599963903298

Epoch: 6| Step: 12
Training loss: 0.33981825195771054
Validation loss: 2.5814672518755097

Epoch: 6| Step: 13
Training loss: 0.4295263855326692
Validation loss: 2.5760739423306114

Epoch: 236| Step: 0
Training loss: 0.3634202342634961
Validation loss: 2.5614630454135

Epoch: 6| Step: 1
Training loss: 0.3548139262799854
Validation loss: 2.5821610580186776

Epoch: 6| Step: 2
Training loss: 0.4202997680777782
Validation loss: 2.537557553044226

Epoch: 6| Step: 3
Training loss: 0.4377254348051616
Validation loss: 2.492469102023275

Epoch: 6| Step: 4
Training loss: 0.29827865247759433
Validation loss: 2.5410247575819103

Epoch: 6| Step: 5
Training loss: 0.43857160527961087
Validation loss: 2.5116878683625137

Epoch: 6| Step: 6
Training loss: 0.31485480958809897
Validation loss: 2.532188100408704

Epoch: 6| Step: 7
Training loss: 0.49554833895632283
Validation loss: 2.559707438048552

Epoch: 6| Step: 8
Training loss: 0.3260223479940946
Validation loss: 2.5964609173275166

Epoch: 6| Step: 9
Training loss: 0.3849328544201353
Validation loss: 2.469969709702271

Epoch: 6| Step: 10
Training loss: 0.31006826550875544
Validation loss: 2.5279193991042748

Epoch: 6| Step: 11
Training loss: 0.5168037523661196
Validation loss: 2.5229804665404925

Epoch: 6| Step: 12
Training loss: 0.6823847733856561
Validation loss: 2.4779877998692124

Epoch: 6| Step: 13
Training loss: 0.2179912452984996
Validation loss: 2.524233964980251

Epoch: 237| Step: 0
Training loss: 0.27242286990448705
Validation loss: 2.532225581731777

Epoch: 6| Step: 1
Training loss: 0.27270066574474944
Validation loss: 2.5487602137145347

Epoch: 6| Step: 2
Training loss: 0.4662662347058573
Validation loss: 2.585114185693867

Epoch: 6| Step: 3
Training loss: 0.46150009929267416
Validation loss: 2.58062131613372

Epoch: 6| Step: 4
Training loss: 0.2656576192686151
Validation loss: 2.555227862186401

Epoch: 6| Step: 5
Training loss: 0.782028306465821
Validation loss: 2.497603157568171

Epoch: 6| Step: 6
Training loss: 0.3188899013696681
Validation loss: 2.539848221714601

Epoch: 6| Step: 7
Training loss: 0.3418231300079379
Validation loss: 2.582025686653365

Epoch: 6| Step: 8
Training loss: 0.3971148209364456
Validation loss: 2.5365370569147188

Epoch: 6| Step: 9
Training loss: 0.20916909227509914
Validation loss: 2.498097474652255

Epoch: 6| Step: 10
Training loss: 0.29080517731397215
Validation loss: 2.586069247759101

Epoch: 6| Step: 11
Training loss: 0.46346001673895154
Validation loss: 2.592746801053934

Epoch: 6| Step: 12
Training loss: 0.2803936610744379
Validation loss: 2.5713247762021227

Epoch: 6| Step: 13
Training loss: 0.23121647849567376
Validation loss: 2.5561157651444004

Epoch: 238| Step: 0
Training loss: 0.3490198588814881
Validation loss: 2.6034825507255026

Epoch: 6| Step: 1
Training loss: 0.3348536639363562
Validation loss: 2.61894686193404

Epoch: 6| Step: 2
Training loss: 0.36192171981130333
Validation loss: 2.5440549000708264

Epoch: 6| Step: 3
Training loss: 0.3909392046872181
Validation loss: 2.4976579026769716

Epoch: 6| Step: 4
Training loss: 0.2657416031660154
Validation loss: 2.597866835698774

Epoch: 6| Step: 5
Training loss: 0.35480252388010247
Validation loss: 2.6102025286459525

Epoch: 6| Step: 6
Training loss: 0.34591640208209773
Validation loss: 2.5761686281189062

Epoch: 6| Step: 7
Training loss: 0.5034419145633264
Validation loss: 2.627975363294867

Epoch: 6| Step: 8
Training loss: 0.33642381022502943
Validation loss: 2.6213114875903134

Epoch: 6| Step: 9
Training loss: 0.7405935337126375
Validation loss: 2.600767149600056

Epoch: 6| Step: 10
Training loss: 0.4672545420026377
Validation loss: 2.528880701966192

Epoch: 6| Step: 11
Training loss: 0.21829025457510043
Validation loss: 2.5446193980806355

Epoch: 6| Step: 12
Training loss: 0.30765693044514575
Validation loss: 2.5618774619288023

Epoch: 6| Step: 13
Training loss: 0.3741838195999534
Validation loss: 2.583105851484005

Epoch: 239| Step: 0
Training loss: 0.3545928265764728
Validation loss: 2.5091547874525064

Epoch: 6| Step: 1
Training loss: 0.24932359295836917
Validation loss: 2.554529999865993

Epoch: 6| Step: 2
Training loss: 0.2056990714131965
Validation loss: 2.548273166930048

Epoch: 6| Step: 3
Training loss: 0.2365548252412841
Validation loss: 2.5050926551891166

Epoch: 6| Step: 4
Training loss: 0.38598119357106325
Validation loss: 2.5656298774799877

Epoch: 6| Step: 5
Training loss: 0.42334206128447105
Validation loss: 2.5719794420965183

Epoch: 6| Step: 6
Training loss: 0.4415281684417506
Validation loss: 2.6036208356397608

Epoch: 6| Step: 7
Training loss: 0.4011988600111879
Validation loss: 2.5820425074683477

Epoch: 6| Step: 8
Training loss: 0.269482124385127
Validation loss: 2.549073002185538

Epoch: 6| Step: 9
Training loss: 0.22412750966315292
Validation loss: 2.5350444437930113

Epoch: 6| Step: 10
Training loss: 0.3313947972931585
Validation loss: 2.5837955189586093

Epoch: 6| Step: 11
Training loss: 0.8058030257168467
Validation loss: 2.4850105256510764

Epoch: 6| Step: 12
Training loss: 0.503406247021936
Validation loss: 2.5136544543899877

Epoch: 6| Step: 13
Training loss: 0.22252992760911267
Validation loss: 2.5458361607445865

Epoch: 240| Step: 0
Training loss: 0.3877330924971194
Validation loss: 2.543085254787674

Epoch: 6| Step: 1
Training loss: 0.3818117997523218
Validation loss: 2.5794761507982837

Epoch: 6| Step: 2
Training loss: 0.8381350500882492
Validation loss: 2.5378799266804

Epoch: 6| Step: 3
Training loss: 0.25313034346321095
Validation loss: 2.596635370257712

Epoch: 6| Step: 4
Training loss: 0.40256581150488013
Validation loss: 2.604264117642781

Epoch: 6| Step: 5
Training loss: 0.4384903937454368
Validation loss: 2.532471978000207

Epoch: 6| Step: 6
Training loss: 0.4149971256386363
Validation loss: 2.4815965706699696

Epoch: 6| Step: 7
Training loss: 0.36049029153219
Validation loss: 2.5232077967417244

Epoch: 6| Step: 8
Training loss: 0.37664950699175764
Validation loss: 2.500366501964201

Epoch: 6| Step: 9
Training loss: 0.5346372552001775
Validation loss: 2.4945044196191577

Epoch: 6| Step: 10
Training loss: 0.31366149106064667
Validation loss: 2.4999562100707933

Epoch: 6| Step: 11
Training loss: 0.28004712261743875
Validation loss: 2.4922056924919276

Epoch: 6| Step: 12
Training loss: 0.39693592459958105
Validation loss: 2.5759275299796247

Epoch: 6| Step: 13
Training loss: 0.5662072193751347
Validation loss: 2.618378189021597

Epoch: 241| Step: 0
Training loss: 0.4845892217130198
Validation loss: 2.5204173656514577

Epoch: 6| Step: 1
Training loss: 0.46635777079325824
Validation loss: 2.5082652831008496

Epoch: 6| Step: 2
Training loss: 0.2583674036652421
Validation loss: 2.4917135316105146

Epoch: 6| Step: 3
Training loss: 0.4197294104662769
Validation loss: 2.5613950192286263

Epoch: 6| Step: 4
Training loss: 0.35967805772148354
Validation loss: 2.5172127240758395

Epoch: 6| Step: 5
Training loss: 0.402044314466111
Validation loss: 2.5322374372326024

Epoch: 6| Step: 6
Training loss: 0.7225560711681157
Validation loss: 2.585917054985797

Epoch: 6| Step: 7
Training loss: 0.23074491571247505
Validation loss: 2.5673022048966283

Epoch: 6| Step: 8
Training loss: 0.44762422936444285
Validation loss: 2.653414188615515

Epoch: 6| Step: 9
Training loss: 0.47965876216728864
Validation loss: 2.648130866110172

Epoch: 6| Step: 10
Training loss: 0.2588884846423117
Validation loss: 2.6121622606471244

Epoch: 6| Step: 11
Training loss: 0.3677674036245143
Validation loss: 2.5568460955524994

Epoch: 6| Step: 12
Training loss: 0.44961782227111596
Validation loss: 2.6089271876881437

Epoch: 6| Step: 13
Training loss: 0.32539533357545025
Validation loss: 2.525282843488459

Epoch: 242| Step: 0
Training loss: 0.7809928852421504
Validation loss: 2.61873244808509

Epoch: 6| Step: 1
Training loss: 0.5285915729005404
Validation loss: 2.64376260921276

Epoch: 6| Step: 2
Training loss: 0.5074393148266453
Validation loss: 2.606435662112731

Epoch: 6| Step: 3
Training loss: 0.4232832398901178
Validation loss: 2.612341703824091

Epoch: 6| Step: 4
Training loss: 0.3453865325761217
Validation loss: 2.5166996621080475

Epoch: 6| Step: 5
Training loss: 0.22388262725927843
Validation loss: 2.4708398431839083

Epoch: 6| Step: 6
Training loss: 0.5873102510706976
Validation loss: 2.459553760460854

Epoch: 6| Step: 7
Training loss: 0.3963395779799227
Validation loss: 2.493788114493881

Epoch: 6| Step: 8
Training loss: 0.38093331426209415
Validation loss: 2.5538347164423243

Epoch: 6| Step: 9
Training loss: 0.3557499831528703
Validation loss: 2.5048821620927924

Epoch: 6| Step: 10
Training loss: 0.4517877182089478
Validation loss: 2.5794312837975064

Epoch: 6| Step: 11
Training loss: 0.47804215031293507
Validation loss: 2.6174165843702206

Epoch: 6| Step: 12
Training loss: 0.3436045880969756
Validation loss: 2.557403769175795

Epoch: 6| Step: 13
Training loss: 0.21925969008690638
Validation loss: 2.4653026316886852

Epoch: 243| Step: 0
Training loss: 0.40004076675455796
Validation loss: 2.5142095544520586

Epoch: 6| Step: 1
Training loss: 0.4015554835675052
Validation loss: 2.416834411609103

Epoch: 6| Step: 2
Training loss: 0.7091853589897753
Validation loss: 2.5013921834964106

Epoch: 6| Step: 3
Training loss: 0.2785325696587156
Validation loss: 2.5072651599538935

Epoch: 6| Step: 4
Training loss: 0.3473615361583546
Validation loss: 2.5071386222159266

Epoch: 6| Step: 5
Training loss: 0.41376961840191323
Validation loss: 2.6076574097737697

Epoch: 6| Step: 6
Training loss: 0.495199027436084
Validation loss: 2.5931363279864934

Epoch: 6| Step: 7
Training loss: 0.4327873429241291
Validation loss: 2.589024125902383

Epoch: 6| Step: 8
Training loss: 0.19366587804609398
Validation loss: 2.5469627131236603

Epoch: 6| Step: 9
Training loss: 0.38718551826123837
Validation loss: 2.511862727458986

Epoch: 6| Step: 10
Training loss: 0.2619651943649431
Validation loss: 2.4947642336128855

Epoch: 6| Step: 11
Training loss: 0.3336563507234272
Validation loss: 2.56017292394826

Epoch: 6| Step: 12
Training loss: 0.28542004754971495
Validation loss: 2.5236350534306764

Epoch: 6| Step: 13
Training loss: 0.3934872477184619
Validation loss: 2.5458255938356653

Epoch: 244| Step: 0
Training loss: 0.3293661644237314
Validation loss: 2.526999055526873

Epoch: 6| Step: 1
Training loss: 0.28297653341305035
Validation loss: 2.5902395430246634

Epoch: 6| Step: 2
Training loss: 0.39427781226945274
Validation loss: 2.5417464561654066

Epoch: 6| Step: 3
Training loss: 0.2677410771176967
Validation loss: 2.5833821266447514

Epoch: 6| Step: 4
Training loss: 0.25848952898625366
Validation loss: 2.5282308052596987

Epoch: 6| Step: 5
Training loss: 0.2549915154999685
Validation loss: 2.547012629622564

Epoch: 6| Step: 6
Training loss: 0.7714064932999161
Validation loss: 2.539743678345967

Epoch: 6| Step: 7
Training loss: 0.36571336640195595
Validation loss: 2.5567439179600995

Epoch: 6| Step: 8
Training loss: 0.2858719140800715
Validation loss: 2.4761490582030063

Epoch: 6| Step: 9
Training loss: 0.34109269764519873
Validation loss: 2.513768650455547

Epoch: 6| Step: 10
Training loss: 0.4953356680280224
Validation loss: 2.5506198709329317

Epoch: 6| Step: 11
Training loss: 0.41034857464246827
Validation loss: 2.531501317989743

Epoch: 6| Step: 12
Training loss: 0.34543464494025383
Validation loss: 2.602395337724462

Epoch: 6| Step: 13
Training loss: 0.5302511249154409
Validation loss: 2.5443988534872313

Epoch: 245| Step: 0
Training loss: 0.4318874913243376
Validation loss: 2.565736455815758

Epoch: 6| Step: 1
Training loss: 0.3338222444758679
Validation loss: 2.534085557545525

Epoch: 6| Step: 2
Training loss: 0.22059089203828786
Validation loss: 2.5654326614229053

Epoch: 6| Step: 3
Training loss: 0.404993719064022
Validation loss: 2.4751817562655445

Epoch: 6| Step: 4
Training loss: 0.23214506446920796
Validation loss: 2.4890749397613536

Epoch: 6| Step: 5
Training loss: 0.39681010654392757
Validation loss: 2.5338901518526975

Epoch: 6| Step: 6
Training loss: 0.23154426423108204
Validation loss: 2.504022287109121

Epoch: 6| Step: 7
Training loss: 0.4637262712561881
Validation loss: 2.477602350280964

Epoch: 6| Step: 8
Training loss: 0.7324975139979337
Validation loss: 2.4993563936200265

Epoch: 6| Step: 9
Training loss: 0.4218342019593032
Validation loss: 2.4829777801216957

Epoch: 6| Step: 10
Training loss: 0.28880577027719523
Validation loss: 2.486189293712413

Epoch: 6| Step: 11
Training loss: 0.35393556132417997
Validation loss: 2.508407149913231

Epoch: 6| Step: 12
Training loss: 0.4469371572361697
Validation loss: 2.5611155033993334

Epoch: 6| Step: 13
Training loss: 0.329449432981961
Validation loss: 2.4804540278280705

Epoch: 246| Step: 0
Training loss: 0.30766276672808
Validation loss: 2.4810073788369276

Epoch: 6| Step: 1
Training loss: 0.445898507010028
Validation loss: 2.49360762964937

Epoch: 6| Step: 2
Training loss: 0.4974474272673803
Validation loss: 2.459555020624703

Epoch: 6| Step: 3
Training loss: 0.2723291823692572
Validation loss: 2.503134979151956

Epoch: 6| Step: 4
Training loss: 0.2771278131726766
Validation loss: 2.496492006849994

Epoch: 6| Step: 5
Training loss: 0.293658804433912
Validation loss: 2.5156283092279565

Epoch: 6| Step: 6
Training loss: 0.4529225785198019
Validation loss: 2.5921507964813335

Epoch: 6| Step: 7
Training loss: 0.45797882313682114
Validation loss: 2.592008779909232

Epoch: 6| Step: 8
Training loss: 0.3116432605248488
Validation loss: 2.590479753975828

Epoch: 6| Step: 9
Training loss: 0.6734120729252987
Validation loss: 2.5730637007694477

Epoch: 6| Step: 10
Training loss: 0.32004994587485847
Validation loss: 2.54455399800276

Epoch: 6| Step: 11
Training loss: 0.3363003766955575
Validation loss: 2.5173192134015996

Epoch: 6| Step: 12
Training loss: 0.36266685131771864
Validation loss: 2.6310612469625534

Epoch: 6| Step: 13
Training loss: 0.23772907377782848
Validation loss: 2.5791651621512695

Epoch: 247| Step: 0
Training loss: 0.2963885538210927
Validation loss: 2.524801037443614

Epoch: 6| Step: 1
Training loss: 0.4365739387810374
Validation loss: 2.6310629611314367

Epoch: 6| Step: 2
Training loss: 0.6984901041450822
Validation loss: 2.5959250740588726

Epoch: 6| Step: 3
Training loss: 0.346952744526473
Validation loss: 2.614444794853646

Epoch: 6| Step: 4
Training loss: 0.42352125599334794
Validation loss: 2.619516442910552

Epoch: 6| Step: 5
Training loss: 0.28773980764521545
Validation loss: 2.585368667226648

Epoch: 6| Step: 6
Training loss: 0.5586796941198021
Validation loss: 2.5088876893191103

Epoch: 6| Step: 7
Training loss: 0.3788067008529538
Validation loss: 2.489209068502521

Epoch: 6| Step: 8
Training loss: 0.5095739771695463
Validation loss: 2.490136764707684

Epoch: 6| Step: 9
Training loss: 0.34391441531369155
Validation loss: 2.44962683385395

Epoch: 6| Step: 10
Training loss: 0.25161013063441573
Validation loss: 2.505428325698482

Epoch: 6| Step: 11
Training loss: 0.3219523670212604
Validation loss: 2.5550704575694634

Epoch: 6| Step: 12
Training loss: 0.32785329468523017
Validation loss: 2.54695803267041

Epoch: 6| Step: 13
Training loss: 0.31013036182662534
Validation loss: 2.5709717281028

Epoch: 248| Step: 0
Training loss: 0.35147785651307023
Validation loss: 2.532319121772276

Epoch: 6| Step: 1
Training loss: 0.32633709863001037
Validation loss: 2.5005232660723653

Epoch: 6| Step: 2
Training loss: 0.3566853799136976
Validation loss: 2.5201409836720075

Epoch: 6| Step: 3
Training loss: 0.40708891740142755
Validation loss: 2.470410532959557

Epoch: 6| Step: 4
Training loss: 0.3737240182974314
Validation loss: 2.5633953980206456

Epoch: 6| Step: 5
Training loss: 0.2603493062956821
Validation loss: 2.474200312508906

Epoch: 6| Step: 6
Training loss: 0.24727478914318402
Validation loss: 2.5895337992866807

Epoch: 6| Step: 7
Training loss: 0.4188318343408317
Validation loss: 2.585815810983118

Epoch: 6| Step: 8
Training loss: 0.3411286606967885
Validation loss: 2.6445015511659973

Epoch: 6| Step: 9
Training loss: 0.3457142887360371
Validation loss: 2.600520004332431

Epoch: 6| Step: 10
Training loss: 0.6433249310906692
Validation loss: 2.5779071600231944

Epoch: 6| Step: 11
Training loss: 0.3310367162997322
Validation loss: 2.5715914156228297

Epoch: 6| Step: 12
Training loss: 0.4074164297850033
Validation loss: 2.5784162876993584

Epoch: 6| Step: 13
Training loss: 0.44142361834628985
Validation loss: 2.6155898042815267

Epoch: 249| Step: 0
Training loss: 0.2574649404296471
Validation loss: 2.5353241459795974

Epoch: 6| Step: 1
Training loss: 0.2620959765993624
Validation loss: 2.609412849745664

Epoch: 6| Step: 2
Training loss: 0.5849930335714156
Validation loss: 2.6456377803194306

Epoch: 6| Step: 3
Training loss: 0.6265158153084316
Validation loss: 2.582523085573159

Epoch: 6| Step: 4
Training loss: 0.47600455532478786
Validation loss: 2.5263034383415413

Epoch: 6| Step: 5
Training loss: 0.5538365727814993
Validation loss: 2.5550537702298493

Epoch: 6| Step: 6
Training loss: 0.4338150318930874
Validation loss: 2.530921522263479

Epoch: 6| Step: 7
Training loss: 0.7359511323544976
Validation loss: 2.5180015789862287

Epoch: 6| Step: 8
Training loss: 0.33819267796105773
Validation loss: 2.5425752725026967

Epoch: 6| Step: 9
Training loss: 0.30650486947838496
Validation loss: 2.5636270417142955

Epoch: 6| Step: 10
Training loss: 0.3525163637921745
Validation loss: 2.5407352825532907

Epoch: 6| Step: 11
Training loss: 0.42951670633493755
Validation loss: 2.600395292102472

Epoch: 6| Step: 12
Training loss: 0.36156416735186353
Validation loss: 2.5931633665051295

Epoch: 6| Step: 13
Training loss: 0.3140239511621618
Validation loss: 2.562343422052478

Epoch: 250| Step: 0
Training loss: 0.49627210759997686
Validation loss: 2.503056676140912

Epoch: 6| Step: 1
Training loss: 0.36389422231790663
Validation loss: 2.477286536820126

Epoch: 6| Step: 2
Training loss: 0.6227013757069616
Validation loss: 2.552970752702438

Epoch: 6| Step: 3
Training loss: 0.3695128446354447
Validation loss: 2.494997813734117

Epoch: 6| Step: 4
Training loss: 0.4118414636252219
Validation loss: 2.556797684288707

Epoch: 6| Step: 5
Training loss: 0.24624438444018226
Validation loss: 2.6047237156495795

Epoch: 6| Step: 6
Training loss: 0.6449528557899088
Validation loss: 2.566230229844935

Epoch: 6| Step: 7
Training loss: 0.333868129198222
Validation loss: 2.55899467142039

Epoch: 6| Step: 8
Training loss: 0.3637568734034134
Validation loss: 2.5269527063994968

Epoch: 6| Step: 9
Training loss: 0.3376945853018667
Validation loss: 2.5292804575108665

Epoch: 6| Step: 10
Training loss: 0.3321714554013386
Validation loss: 2.5895133596486795

Epoch: 6| Step: 11
Training loss: 0.4686126507759742
Validation loss: 2.526934386662659

Epoch: 6| Step: 12
Training loss: 0.3346898842307258
Validation loss: 2.528989166826843

Epoch: 6| Step: 13
Training loss: 0.29665492081874306
Validation loss: 2.5604192613216585

Epoch: 251| Step: 0
Training loss: 0.4167826213026115
Validation loss: 2.5539526159465895

Epoch: 6| Step: 1
Training loss: 0.3568593585967513
Validation loss: 2.5222413620617026

Epoch: 6| Step: 2
Training loss: 0.4022337013034197
Validation loss: 2.541896971185614

Epoch: 6| Step: 3
Training loss: 0.2757428939557378
Validation loss: 2.5643385827428014

Epoch: 6| Step: 4
Training loss: 0.33193329880946254
Validation loss: 2.568307374686476

Epoch: 6| Step: 5
Training loss: 0.44638633085412177
Validation loss: 2.6089475818455043

Epoch: 6| Step: 6
Training loss: 0.7451837392461113
Validation loss: 2.615949423301063

Epoch: 6| Step: 7
Training loss: 0.38334805142439915
Validation loss: 2.611018829935746

Epoch: 6| Step: 8
Training loss: 0.39144827870234017
Validation loss: 2.562869580296852

Epoch: 6| Step: 9
Training loss: 0.2643341788662844
Validation loss: 2.5667863213115054

Epoch: 6| Step: 10
Training loss: 0.29908824644404935
Validation loss: 2.512956313390432

Epoch: 6| Step: 11
Training loss: 0.3415090493438624
Validation loss: 2.5774150448848228

Epoch: 6| Step: 12
Training loss: 0.2379190631524181
Validation loss: 2.531259662311464

Epoch: 6| Step: 13
Training loss: 0.542204641681321
Validation loss: 2.51521847680345

Epoch: 252| Step: 0
Training loss: 0.2493207316279299
Validation loss: 2.524814312782924

Epoch: 6| Step: 1
Training loss: 0.45000258352279787
Validation loss: 2.566198951249375

Epoch: 6| Step: 2
Training loss: 0.28276296150119606
Validation loss: 2.5062243224847727

Epoch: 6| Step: 3
Training loss: 0.6976369942702175
Validation loss: 2.5432842349974916

Epoch: 6| Step: 4
Training loss: 0.23958291523661968
Validation loss: 2.5403546454181307

Epoch: 6| Step: 5
Training loss: 0.24381723729801813
Validation loss: 2.4965915014499065

Epoch: 6| Step: 6
Training loss: 0.3613926597906388
Validation loss: 2.5203984150725205

Epoch: 6| Step: 7
Training loss: 0.27604740364782837
Validation loss: 2.543723405078826

Epoch: 6| Step: 8
Training loss: 0.15762742398097576
Validation loss: 2.542433835290525

Epoch: 6| Step: 9
Training loss: 0.40164809594944256
Validation loss: 2.494846292958198

Epoch: 6| Step: 10
Training loss: 0.37914956529359223
Validation loss: 2.5107011013954854

Epoch: 6| Step: 11
Training loss: 0.40004911046743935
Validation loss: 2.509937958298866

Epoch: 6| Step: 12
Training loss: 0.3783548413197438
Validation loss: 2.5117112590229187

Epoch: 6| Step: 13
Training loss: 0.2618910947965823
Validation loss: 2.5435280367950344

Epoch: 253| Step: 0
Training loss: 0.3559561102793727
Validation loss: 2.49483649758427

Epoch: 6| Step: 1
Training loss: 0.31459634492925
Validation loss: 2.5299922188600243

Epoch: 6| Step: 2
Training loss: 0.24214602699809198
Validation loss: 2.494639251980223

Epoch: 6| Step: 3
Training loss: 0.7787605677418826
Validation loss: 2.4580767842496187

Epoch: 6| Step: 4
Training loss: 0.39889294642114703
Validation loss: 2.476095979956386

Epoch: 6| Step: 5
Training loss: 0.29730231501046533
Validation loss: 2.523128982753727

Epoch: 6| Step: 6
Training loss: 0.3017116869391622
Validation loss: 2.5345155350071114

Epoch: 6| Step: 7
Training loss: 0.3072189659930422
Validation loss: 2.53756729312358

Epoch: 6| Step: 8
Training loss: 0.38629670666261756
Validation loss: 2.5196757666962686

Epoch: 6| Step: 9
Training loss: 0.462410432287608
Validation loss: 2.5967809134468807

Epoch: 6| Step: 10
Training loss: 0.27758228091675347
Validation loss: 2.5372700668477592

Epoch: 6| Step: 11
Training loss: 0.4821988103582136
Validation loss: 2.6096242149870656

Epoch: 6| Step: 12
Training loss: 0.2552066952140291
Validation loss: 2.5583925745646154

Epoch: 6| Step: 13
Training loss: 0.31993383028936795
Validation loss: 2.5899787510917087

Epoch: 254| Step: 0
Training loss: 0.265997653303694
Validation loss: 2.593312529167468

Epoch: 6| Step: 1
Training loss: 0.25837418030755066
Validation loss: 2.5074159857359914

Epoch: 6| Step: 2
Training loss: 0.31459951843326717
Validation loss: 2.6062276898716767

Epoch: 6| Step: 3
Training loss: 0.5182931531448366
Validation loss: 2.547447623880257

Epoch: 6| Step: 4
Training loss: 0.38510123008837654
Validation loss: 2.5700056207845257

Epoch: 6| Step: 5
Training loss: 0.3963431308762256
Validation loss: 2.583513335653066

Epoch: 6| Step: 6
Training loss: 0.42730278292994417
Validation loss: 2.5775187309341807

Epoch: 6| Step: 7
Training loss: 0.28022753774971015
Validation loss: 2.5960380389801982

Epoch: 6| Step: 8
Training loss: 0.3439787082175024
Validation loss: 2.518441970706993

Epoch: 6| Step: 9
Training loss: 0.28175782345806544
Validation loss: 2.5090572955736814

Epoch: 6| Step: 10
Training loss: 0.3252123464527758
Validation loss: 2.50304530949922

Epoch: 6| Step: 11
Training loss: 0.4355479526934099
Validation loss: 2.510116857351571

Epoch: 6| Step: 12
Training loss: 0.3865977782031184
Validation loss: 2.4833404338231655

Epoch: 6| Step: 13
Training loss: 0.6683047158003681
Validation loss: 2.5167922950697825

Epoch: 255| Step: 0
Training loss: 0.384663873376131
Validation loss: 2.5124155979308798

Epoch: 6| Step: 1
Training loss: 0.2920226524561076
Validation loss: 2.5465638920465814

Epoch: 6| Step: 2
Training loss: 0.4638735640238125
Validation loss: 2.566324667212101

Epoch: 6| Step: 3
Training loss: 0.38359051098980773
Validation loss: 2.508034162539151

Epoch: 6| Step: 4
Training loss: 0.23605232854962016
Validation loss: 2.534714270859415

Epoch: 6| Step: 5
Training loss: 0.23369197662067112
Validation loss: 2.538170885868796

Epoch: 6| Step: 6
Training loss: 0.20014611546858632
Validation loss: 2.5132036343567217

Epoch: 6| Step: 7
Training loss: 0.38614301499205317
Validation loss: 2.5807442509081717

Epoch: 6| Step: 8
Training loss: 0.41339902083143
Validation loss: 2.5278750553440137

Epoch: 6| Step: 9
Training loss: 0.2377514891116523
Validation loss: 2.501541870210031

Epoch: 6| Step: 10
Training loss: 0.6512570952982628
Validation loss: 2.545344792101275

Epoch: 6| Step: 11
Training loss: 0.3558357565921636
Validation loss: 2.546818239168514

Epoch: 6| Step: 12
Training loss: 0.2873471631277306
Validation loss: 2.5436352053272

Epoch: 6| Step: 13
Training loss: 0.46759678127002524
Validation loss: 2.525014252827016

Epoch: 256| Step: 0
Training loss: 0.40581905910068156
Validation loss: 2.5533006113543593

Epoch: 6| Step: 1
Training loss: 0.4095971975020651
Validation loss: 2.5776986125961203

Epoch: 6| Step: 2
Training loss: 0.30962547027465936
Validation loss: 2.5554166291893754

Epoch: 6| Step: 3
Training loss: 0.3211221232257547
Validation loss: 2.506874360583996

Epoch: 6| Step: 4
Training loss: 0.35093454864157697
Validation loss: 2.5320076299183785

Epoch: 6| Step: 5
Training loss: 0.6269785795659553
Validation loss: 2.505800797057032

Epoch: 6| Step: 6
Training loss: 0.37191897540978863
Validation loss: 2.523938348785223

Epoch: 6| Step: 7
Training loss: 0.3493379786194065
Validation loss: 2.507162364377426

Epoch: 6| Step: 8
Training loss: 0.25663134182146824
Validation loss: 2.5383644670375087

Epoch: 6| Step: 9
Training loss: 0.39758520034967865
Validation loss: 2.51461931427816

Epoch: 6| Step: 10
Training loss: 0.3987233501605171
Validation loss: 2.4686318059385077

Epoch: 6| Step: 11
Training loss: 0.42454236580087296
Validation loss: 2.546897794469386

Epoch: 6| Step: 12
Training loss: 0.2878863402918648
Validation loss: 2.585734410296705

Epoch: 6| Step: 13
Training loss: 0.2373922131666736
Validation loss: 2.4827076417047538

Epoch: 257| Step: 0
Training loss: 0.4291615475037573
Validation loss: 2.5103553326555015

Epoch: 6| Step: 1
Training loss: 0.23701271493872925
Validation loss: 2.5799413813725818

Epoch: 6| Step: 2
Training loss: 0.23106509174774423
Validation loss: 2.5284478332336042

Epoch: 6| Step: 3
Training loss: 0.32074206321452803
Validation loss: 2.5491720734840593

Epoch: 6| Step: 4
Training loss: 0.6490018066695566
Validation loss: 2.5089738004919813

Epoch: 6| Step: 5
Training loss: 0.3228851374748953
Validation loss: 2.5256777052181434

Epoch: 6| Step: 6
Training loss: 0.18968225171780162
Validation loss: 2.5517101222556517

Epoch: 6| Step: 7
Training loss: 0.3536197656491512
Validation loss: 2.526016743854916

Epoch: 6| Step: 8
Training loss: 0.28387055510127984
Validation loss: 2.604470309039388

Epoch: 6| Step: 9
Training loss: 0.2954301181070311
Validation loss: 2.544679643369865

Epoch: 6| Step: 10
Training loss: 0.31894637911840723
Validation loss: 2.6060441128697462

Epoch: 6| Step: 11
Training loss: 0.3358743519537196
Validation loss: 2.5735309243398117

Epoch: 6| Step: 12
Training loss: 0.23163989293720944
Validation loss: 2.495588367861092

Epoch: 6| Step: 13
Training loss: 0.4641888115832114
Validation loss: 2.5587038904609614

Epoch: 258| Step: 0
Training loss: 0.28359627893334394
Validation loss: 2.588740279153194

Epoch: 6| Step: 1
Training loss: 0.31521538933703735
Validation loss: 2.5709177867881237

Epoch: 6| Step: 2
Training loss: 0.34895575816594476
Validation loss: 2.5693086095652102

Epoch: 6| Step: 3
Training loss: 0.31268735276241066
Validation loss: 2.548436807382483

Epoch: 6| Step: 4
Training loss: 0.23565854830418503
Validation loss: 2.5247794835579187

Epoch: 6| Step: 5
Training loss: 0.277435327911124
Validation loss: 2.6010117964632893

Epoch: 6| Step: 6
Training loss: 0.30656682480960806
Validation loss: 2.5208120870614383

Epoch: 6| Step: 7
Training loss: 0.3515042362676844
Validation loss: 2.5239331966150256

Epoch: 6| Step: 8
Training loss: 0.641584840321467
Validation loss: 2.5421759975792892

Epoch: 6| Step: 9
Training loss: 0.21647711533454483
Validation loss: 2.529859514143159

Epoch: 6| Step: 10
Training loss: 0.3966853567269561
Validation loss: 2.576030612607676

Epoch: 6| Step: 11
Training loss: 0.3836567580302138
Validation loss: 2.557272471390191

Epoch: 6| Step: 12
Training loss: 0.2751772845544852
Validation loss: 2.5993273720853507

Epoch: 6| Step: 13
Training loss: 0.27837171916372977
Validation loss: 2.527614903238885

Epoch: 259| Step: 0
Training loss: 0.4124406865854258
Validation loss: 2.5249047437646728

Epoch: 6| Step: 1
Training loss: 0.28486751936413607
Validation loss: 2.5214060193294356

Epoch: 6| Step: 2
Training loss: 0.3939533911781167
Validation loss: 2.5241095688227495

Epoch: 6| Step: 3
Training loss: 0.25292024631627463
Validation loss: 2.603795968692436

Epoch: 6| Step: 4
Training loss: 0.3238891856901213
Validation loss: 2.6177189073957514

Epoch: 6| Step: 5
Training loss: 0.40986650314319
Validation loss: 2.5708185719994177

Epoch: 6| Step: 6
Training loss: 0.29407845456890436
Validation loss: 2.617897552277977

Epoch: 6| Step: 7
Training loss: 0.2775295065322611
Validation loss: 2.5845042979359105

Epoch: 6| Step: 8
Training loss: 0.2946452934403863
Validation loss: 2.525405942747979

Epoch: 6| Step: 9
Training loss: 0.25549844225130536
Validation loss: 2.528609142305727

Epoch: 6| Step: 10
Training loss: 0.29615857866528367
Validation loss: 2.5848245674827672

Epoch: 6| Step: 11
Training loss: 0.4157936148541308
Validation loss: 2.537360300562577

Epoch: 6| Step: 12
Training loss: 0.4194715169653226
Validation loss: 2.495158737244761

Epoch: 6| Step: 13
Training loss: 0.7894922351539873
Validation loss: 2.5547543827055

Epoch: 260| Step: 0
Training loss: 0.3784247416228578
Validation loss: 2.598378498373247

Epoch: 6| Step: 1
Training loss: 0.39392742367905675
Validation loss: 2.639850630821314

Epoch: 6| Step: 2
Training loss: 0.4080047855657525
Validation loss: 2.6291412203162396

Epoch: 6| Step: 3
Training loss: 0.3485691215401939
Validation loss: 2.6491763979347183

Epoch: 6| Step: 4
Training loss: 0.30781911852542043
Validation loss: 2.5755483524921017

Epoch: 6| Step: 5
Training loss: 0.3330659675718289
Validation loss: 2.527866834136023

Epoch: 6| Step: 6
Training loss: 0.3011265296295447
Validation loss: 2.5224625915687326

Epoch: 6| Step: 7
Training loss: 0.7054290954665094
Validation loss: 2.513848342767575

Epoch: 6| Step: 8
Training loss: 0.2923787979941016
Validation loss: 2.4748103444809466

Epoch: 6| Step: 9
Training loss: 0.40337196000936365
Validation loss: 2.5112204366373923

Epoch: 6| Step: 10
Training loss: 0.2754753063761033
Validation loss: 2.5485288246954054

Epoch: 6| Step: 11
Training loss: 0.6274205304543348
Validation loss: 2.5878111322057915

Epoch: 6| Step: 12
Training loss: 0.303022063366354
Validation loss: 2.5699919836065246

Epoch: 6| Step: 13
Training loss: 0.31935320232978304
Validation loss: 2.5618046693314045

Epoch: 261| Step: 0
Training loss: 0.2898141650501075
Validation loss: 2.5884454940849917

Epoch: 6| Step: 1
Training loss: 0.5589290759486085
Validation loss: 2.4144716955076726

Epoch: 6| Step: 2
Training loss: 0.2571570271299355
Validation loss: 2.524933905727905

Epoch: 6| Step: 3
Training loss: 0.31509250298763763
Validation loss: 2.612927863875117

Epoch: 6| Step: 4
Training loss: 0.33548586449499657
Validation loss: 2.539849528088349

Epoch: 6| Step: 5
Training loss: 0.2909670283557824
Validation loss: 2.5206241100488476

Epoch: 6| Step: 6
Training loss: 0.3423807987343234
Validation loss: 2.6056444069797

Epoch: 6| Step: 7
Training loss: 0.32048127914777635
Validation loss: 2.5512771007662827

Epoch: 6| Step: 8
Training loss: 0.5886095789883972
Validation loss: 2.57270801846196

Epoch: 6| Step: 9
Training loss: 0.4145433405016309
Validation loss: 2.5146293802372535

Epoch: 6| Step: 10
Training loss: 0.2346902951761085
Validation loss: 2.546126819390766

Epoch: 6| Step: 11
Training loss: 0.32373797147638383
Validation loss: 2.5200171660035404

Epoch: 6| Step: 12
Training loss: 0.37501452338387203
Validation loss: 2.528939585936909

Epoch: 6| Step: 13
Training loss: 0.43527113735094813
Validation loss: 2.603599567972674

Epoch: 262| Step: 0
Training loss: 0.6443418282259522
Validation loss: 2.5761698852253736

Epoch: 6| Step: 1
Training loss: 0.529831113448067
Validation loss: 2.6813498957830784

Epoch: 6| Step: 2
Training loss: 0.34696626235907085
Validation loss: 2.600251700982527

Epoch: 6| Step: 3
Training loss: 0.33188035565525154
Validation loss: 2.5225950868275686

Epoch: 6| Step: 4
Training loss: 0.3226699604511287
Validation loss: 2.5465425613714414

Epoch: 6| Step: 5
Training loss: 0.3052315256704884
Validation loss: 2.5646211792306826

Epoch: 6| Step: 6
Training loss: 0.31184965649913554
Validation loss: 2.5139707255756805

Epoch: 6| Step: 7
Training loss: 0.2809515667789341
Validation loss: 2.596687078734427

Epoch: 6| Step: 8
Training loss: 0.36361908329739395
Validation loss: 2.5726258863905973

Epoch: 6| Step: 9
Training loss: 0.29071641427727346
Validation loss: 2.5603477464612983

Epoch: 6| Step: 10
Training loss: 0.3093629497531743
Validation loss: 2.5150825120903852

Epoch: 6| Step: 11
Training loss: 0.2568155868068105
Validation loss: 2.5134980468400934

Epoch: 6| Step: 12
Training loss: 0.5376253181568331
Validation loss: 2.6115545623075604

Epoch: 6| Step: 13
Training loss: 0.26785055617907944
Validation loss: 2.6308975953269

Epoch: 263| Step: 0
Training loss: 0.22936907773596962
Validation loss: 2.54955818955197

Epoch: 6| Step: 1
Training loss: 0.212003785577525
Validation loss: 2.553327877181609

Epoch: 6| Step: 2
Training loss: 0.32740810963360245
Validation loss: 2.5581453119660322

Epoch: 6| Step: 3
Training loss: 0.5924371208353094
Validation loss: 2.487629548090781

Epoch: 6| Step: 4
Training loss: 0.4472251274065204
Validation loss: 2.554928425074372

Epoch: 6| Step: 5
Training loss: 0.3316688354858976
Validation loss: 2.522350451129238

Epoch: 6| Step: 6
Training loss: 0.3251738670082441
Validation loss: 2.532343891023205

Epoch: 6| Step: 7
Training loss: 0.2279689640569695
Validation loss: 2.54386156448291

Epoch: 6| Step: 8
Training loss: 0.29022050570263647
Validation loss: 2.5313549412453202

Epoch: 6| Step: 9
Training loss: 0.27217988589353015
Validation loss: 2.521287961165621

Epoch: 6| Step: 10
Training loss: 0.4808204108286233
Validation loss: 2.5107799335789407

Epoch: 6| Step: 11
Training loss: 0.35248501857413206
Validation loss: 2.480749327642889

Epoch: 6| Step: 12
Training loss: 0.3355392490714987
Validation loss: 2.498859137256732

Epoch: 6| Step: 13
Training loss: 0.2776222710971263
Validation loss: 2.5055711183489913

Epoch: 264| Step: 0
Training loss: 0.3143417682488532
Validation loss: 2.5210565725634617

Epoch: 6| Step: 1
Training loss: 0.3824968204179143
Validation loss: 2.5175878792419164

Epoch: 6| Step: 2
Training loss: 0.3068814152282057
Validation loss: 2.5116280657513284

Epoch: 6| Step: 3
Training loss: 0.5852296495431443
Validation loss: 2.5752029814236477

Epoch: 6| Step: 4
Training loss: 0.2810313381439685
Validation loss: 2.5455402160781597

Epoch: 6| Step: 5
Training loss: 0.34039304999012365
Validation loss: 2.5950982905879107

Epoch: 6| Step: 6
Training loss: 0.3320968114414394
Validation loss: 2.6201530091060565

Epoch: 6| Step: 7
Training loss: 0.3974609375
Validation loss: 2.622605124452425

Epoch: 6| Step: 8
Training loss: 0.2741180941611607
Validation loss: 2.560224592817537

Epoch: 6| Step: 9
Training loss: 0.38816543632602796
Validation loss: 2.5425901819700156

Epoch: 6| Step: 10
Training loss: 0.28984258399584895
Validation loss: 2.5374721300069747

Epoch: 6| Step: 11
Training loss: 0.33716380496554105
Validation loss: 2.503332253780547

Epoch: 6| Step: 12
Training loss: 0.372858868902525
Validation loss: 2.57178619713506

Epoch: 6| Step: 13
Training loss: 0.30172197196974615
Validation loss: 2.525222611450016

Epoch: 265| Step: 0
Training loss: 0.34585921217520554
Validation loss: 2.609673762778084

Epoch: 6| Step: 1
Training loss: 0.43399101822212427
Validation loss: 2.6859583314062294

Epoch: 6| Step: 2
Training loss: 0.43688260520678696
Validation loss: 2.6068353686250267

Epoch: 6| Step: 3
Training loss: 0.35086755943902925
Validation loss: 2.632601570109297

Epoch: 6| Step: 4
Training loss: 0.3696054226912539
Validation loss: 2.503250123387973

Epoch: 6| Step: 5
Training loss: 0.32371555483887565
Validation loss: 2.5190877913521894

Epoch: 6| Step: 6
Training loss: 0.35154707133028557
Validation loss: 2.4842991367489224

Epoch: 6| Step: 7
Training loss: 0.2886594075361351
Validation loss: 2.4795317073886265

Epoch: 6| Step: 8
Training loss: 0.36427452314975384
Validation loss: 2.52643457614561

Epoch: 6| Step: 9
Training loss: 0.6473835802542677
Validation loss: 2.5587577631363154

Epoch: 6| Step: 10
Training loss: 0.17891991492312043
Validation loss: 2.505590831294931

Epoch: 6| Step: 11
Training loss: 0.3915447850341503
Validation loss: 2.533911910514831

Epoch: 6| Step: 12
Training loss: 0.4766289867861662
Validation loss: 2.588907969376738

Epoch: 6| Step: 13
Training loss: 0.34453178500871356
Validation loss: 2.5665480730806345

Epoch: 266| Step: 0
Training loss: 0.30687785842636406
Validation loss: 2.4739489317598222

Epoch: 6| Step: 1
Training loss: 0.2919553905763578
Validation loss: 2.474197895430716

Epoch: 6| Step: 2
Training loss: 0.4198018456953238
Validation loss: 2.4922926829751946

Epoch: 6| Step: 3
Training loss: 0.4252706843777853
Validation loss: 2.45854991562238

Epoch: 6| Step: 4
Training loss: 0.43867527254713234
Validation loss: 2.4355829476359583

Epoch: 6| Step: 5
Training loss: 0.29428962489980753
Validation loss: 2.5197916847492885

Epoch: 6| Step: 6
Training loss: 0.40264855107684216
Validation loss: 2.544807468593742

Epoch: 6| Step: 7
Training loss: 0.5406929458522054
Validation loss: 2.62128127555277

Epoch: 6| Step: 8
Training loss: 0.3824448279563835
Validation loss: 2.6275724113569416

Epoch: 6| Step: 9
Training loss: 0.6439327813810253
Validation loss: 2.52578659867266

Epoch: 6| Step: 10
Training loss: 0.36211511634135096
Validation loss: 2.5040659583263953

Epoch: 6| Step: 11
Training loss: 0.27544709566790276
Validation loss: 2.5297809309471004

Epoch: 6| Step: 12
Training loss: 0.45152552892215586
Validation loss: 2.5110286953247476

Epoch: 6| Step: 13
Training loss: 0.36232471667756183
Validation loss: 2.502151898268624

Epoch: 267| Step: 0
Training loss: 0.36856077964449774
Validation loss: 2.5503216378562015

Epoch: 6| Step: 1
Training loss: 0.29555757485567724
Validation loss: 2.522830933537736

Epoch: 6| Step: 2
Training loss: 0.363102345867926
Validation loss: 2.5580593026569236

Epoch: 6| Step: 3
Training loss: 0.49796275008063867
Validation loss: 2.5994145076482953

Epoch: 6| Step: 4
Training loss: 0.3013486217384663
Validation loss: 2.548771501206921

Epoch: 6| Step: 5
Training loss: 0.2991419745967983
Validation loss: 2.497874894533917

Epoch: 6| Step: 6
Training loss: 0.2642957441647993
Validation loss: 2.519502956024513

Epoch: 6| Step: 7
Training loss: 0.3019396039889068
Validation loss: 2.517399661474179

Epoch: 6| Step: 8
Training loss: 0.5809910074168395
Validation loss: 2.5302216909680766

Epoch: 6| Step: 9
Training loss: 0.4408419893180531
Validation loss: 2.5564290292564076

Epoch: 6| Step: 10
Training loss: 0.3178666754677757
Validation loss: 2.521072523470804

Epoch: 6| Step: 11
Training loss: 0.29605872467948524
Validation loss: 2.5772683618147805

Epoch: 6| Step: 12
Training loss: 0.45837730680831373
Validation loss: 2.6018662299262587

Epoch: 6| Step: 13
Training loss: 0.1826446125020465
Validation loss: 2.5670964799728138

Epoch: 268| Step: 0
Training loss: 0.6052926822740576
Validation loss: 2.6087370223932127

Epoch: 6| Step: 1
Training loss: 0.3207024898360139
Validation loss: 2.54142161006138

Epoch: 6| Step: 2
Training loss: 0.36701393083331346
Validation loss: 2.534251305775392

Epoch: 6| Step: 3
Training loss: 0.317679527675749
Validation loss: 2.520700038717081

Epoch: 6| Step: 4
Training loss: 0.23510515602105342
Validation loss: 2.5021683667101193

Epoch: 6| Step: 5
Training loss: 0.1998411348572942
Validation loss: 2.5037363265488337

Epoch: 6| Step: 6
Training loss: 0.35195709971428535
Validation loss: 2.51543195153568

Epoch: 6| Step: 7
Training loss: 0.31404156733732275
Validation loss: 2.5188423890743388

Epoch: 6| Step: 8
Training loss: 0.3111276773434883
Validation loss: 2.504347851038603

Epoch: 6| Step: 9
Training loss: 0.31297944959537866
Validation loss: 2.531808297082113

Epoch: 6| Step: 10
Training loss: 0.3534697402766206
Validation loss: 2.547639915260309

Epoch: 6| Step: 11
Training loss: 0.3677992898258989
Validation loss: 2.499462363924618

Epoch: 6| Step: 12
Training loss: 0.43220479697522635
Validation loss: 2.5301747726742114

Epoch: 6| Step: 13
Training loss: 0.3804974523601886
Validation loss: 2.49823924684216

Epoch: 269| Step: 0
Training loss: 0.26296523737247185
Validation loss: 2.505785993778624

Epoch: 6| Step: 1
Training loss: 0.3130229389206602
Validation loss: 2.5691917086071774

Epoch: 6| Step: 2
Training loss: 0.2546343560735429
Validation loss: 2.5602251360413235

Epoch: 6| Step: 3
Training loss: 0.29266697918419743
Validation loss: 2.5442268318320136

Epoch: 6| Step: 4
Training loss: 0.39902034838615497
Validation loss: 2.5567203409246377

Epoch: 6| Step: 5
Training loss: 0.4359291691137881
Validation loss: 2.5432328938124797

Epoch: 6| Step: 6
Training loss: 0.5885640086656678
Validation loss: 2.54355290779552

Epoch: 6| Step: 7
Training loss: 0.33293757439052696
Validation loss: 2.561185763391163

Epoch: 6| Step: 8
Training loss: 0.2740847420447955
Validation loss: 2.5485269380737026

Epoch: 6| Step: 9
Training loss: 0.2739665771133655
Validation loss: 2.567712893427165

Epoch: 6| Step: 10
Training loss: 0.3507566965936201
Validation loss: 2.5847628980790067

Epoch: 6| Step: 11
Training loss: 0.3522870438951277
Validation loss: 2.6244399972031514

Epoch: 6| Step: 12
Training loss: 0.2649937168537075
Validation loss: 2.512148269148967

Epoch: 6| Step: 13
Training loss: 0.34236349822783996
Validation loss: 2.532059700898336

Epoch: 270| Step: 0
Training loss: 0.3768516759787845
Validation loss: 2.4991211300023686

Epoch: 6| Step: 1
Training loss: 0.3757034300487388
Validation loss: 2.5305155171203317

Epoch: 6| Step: 2
Training loss: 0.3265678263873254
Validation loss: 2.547173777024474

Epoch: 6| Step: 3
Training loss: 0.4439084186655395
Validation loss: 2.510061307477536

Epoch: 6| Step: 4
Training loss: 0.24840029371911496
Validation loss: 2.5870296250372182

Epoch: 6| Step: 5
Training loss: 0.377304229878228
Validation loss: 2.562945280697278

Epoch: 6| Step: 6
Training loss: 0.43195800850243565
Validation loss: 2.5776041911267717

Epoch: 6| Step: 7
Training loss: 0.3045945392526796
Validation loss: 2.5793286991115547

Epoch: 6| Step: 8
Training loss: 0.4007161747560302
Validation loss: 2.54196906766222

Epoch: 6| Step: 9
Training loss: 0.34695964845753446
Validation loss: 2.522142249107789

Epoch: 6| Step: 10
Training loss: 0.7109737177416167
Validation loss: 2.4814663700599953

Epoch: 6| Step: 11
Training loss: 0.24820932190255132
Validation loss: 2.492922364634929

Epoch: 6| Step: 12
Training loss: 0.19533379438665105
Validation loss: 2.504174672863476

Epoch: 6| Step: 13
Training loss: 0.36042503703693274
Validation loss: 2.5527368500280896

Epoch: 271| Step: 0
Training loss: 0.39269858263020785
Validation loss: 2.586101038929462

Epoch: 6| Step: 1
Training loss: 0.5127799409320393
Validation loss: 2.5611623280930473

Epoch: 6| Step: 2
Training loss: 0.33755011848678734
Validation loss: 2.5442346409566503

Epoch: 6| Step: 3
Training loss: 0.32710544816150344
Validation loss: 2.4992913990327037

Epoch: 6| Step: 4
Training loss: 0.3688501900809844
Validation loss: 2.545477540293677

Epoch: 6| Step: 5
Training loss: 0.29488126209865645
Validation loss: 2.562171271413466

Epoch: 6| Step: 6
Training loss: 0.5462556056121292
Validation loss: 2.5219884831934203

Epoch: 6| Step: 7
Training loss: 0.3013542711477739
Validation loss: 2.5041634144394287

Epoch: 6| Step: 8
Training loss: 0.3179233232707877
Validation loss: 2.5417697343617687

Epoch: 6| Step: 9
Training loss: 0.3257829780441303
Validation loss: 2.5604894705825747

Epoch: 6| Step: 10
Training loss: 0.3264577264035606
Validation loss: 2.5964764891760517

Epoch: 6| Step: 11
Training loss: 0.44835538411362524
Validation loss: 2.6023349016280215

Epoch: 6| Step: 12
Training loss: 0.3672411859102529
Validation loss: 2.5538233035124915

Epoch: 6| Step: 13
Training loss: 0.3190406694145471
Validation loss: 2.587412372278601

Epoch: 272| Step: 0
Training loss: 0.3517293745933267
Validation loss: 2.5465989070469264

Epoch: 6| Step: 1
Training loss: 0.36296625735034177
Validation loss: 2.5335263193390936

Epoch: 6| Step: 2
Training loss: 0.3409662671981646
Validation loss: 2.5034050799457725

Epoch: 6| Step: 3
Training loss: 0.43203737830563266
Validation loss: 2.569540307831334

Epoch: 6| Step: 4
Training loss: 0.37443941654331836
Validation loss: 2.5626176636516433

Epoch: 6| Step: 5
Training loss: 0.3642335121701281
Validation loss: 2.608402520217852

Epoch: 6| Step: 6
Training loss: 0.29220328466852563
Validation loss: 2.6094119284447546

Epoch: 6| Step: 7
Training loss: 0.26614306921870395
Validation loss: 2.606039523279011

Epoch: 6| Step: 8
Training loss: 0.42526209967755757
Validation loss: 2.611104913347974

Epoch: 6| Step: 9
Training loss: 0.4070063482710323
Validation loss: 2.598520572058543

Epoch: 6| Step: 10
Training loss: 0.1854210477125666
Validation loss: 2.541954498461036

Epoch: 6| Step: 11
Training loss: 0.43541742975755227
Validation loss: 2.5087026361170577

Epoch: 6| Step: 12
Training loss: 0.6527920855539093
Validation loss: 2.462360039556317

Epoch: 6| Step: 13
Training loss: 0.24099958480803155
Validation loss: 2.5112708025017376

Epoch: 273| Step: 0
Training loss: 0.33734647119863687
Validation loss: 2.551270115318414

Epoch: 6| Step: 1
Training loss: 0.4717802805287025
Validation loss: 2.56529511388091

Epoch: 6| Step: 2
Training loss: 0.25307457504048364
Validation loss: 2.5710099113779763

Epoch: 6| Step: 3
Training loss: 0.4967425601720788
Validation loss: 2.6444332643703556

Epoch: 6| Step: 4
Training loss: 0.5444916698459644
Validation loss: 2.5492485859097496

Epoch: 6| Step: 5
Training loss: 0.36712522181477275
Validation loss: 2.5131236211808843

Epoch: 6| Step: 6
Training loss: 0.3698933107975284
Validation loss: 2.509910680237888

Epoch: 6| Step: 7
Training loss: 0.3270752326707334
Validation loss: 2.5665330628099143

Epoch: 6| Step: 8
Training loss: 0.3701644303660633
Validation loss: 2.492387139785669

Epoch: 6| Step: 9
Training loss: 0.2868054136845995
Validation loss: 2.493774897069466

Epoch: 6| Step: 10
Training loss: 0.27129604476171565
Validation loss: 2.500244891570077

Epoch: 6| Step: 11
Training loss: 0.39895316021838084
Validation loss: 2.543842046573498

Epoch: 6| Step: 12
Training loss: 0.3302428945972532
Validation loss: 2.580200508135584

Epoch: 6| Step: 13
Training loss: 0.41930788085776827
Validation loss: 2.6025017311610785

Epoch: 274| Step: 0
Training loss: 0.30319444706368737
Validation loss: 2.635591860490393

Epoch: 6| Step: 1
Training loss: 0.2577347927315603
Validation loss: 2.6113225708100916

Epoch: 6| Step: 2
Training loss: 0.2715541146260074
Validation loss: 2.5725343139554564

Epoch: 6| Step: 3
Training loss: 0.35938034882918685
Validation loss: 2.536425256741923

Epoch: 6| Step: 4
Training loss: 0.43155857531885083
Validation loss: 2.537507497528976

Epoch: 6| Step: 5
Training loss: 0.422627643033112
Validation loss: 2.539408045021772

Epoch: 6| Step: 6
Training loss: 0.28070753818676986
Validation loss: 2.5289425084945387

Epoch: 6| Step: 7
Training loss: 0.412144483182693
Validation loss: 2.572259013235776

Epoch: 6| Step: 8
Training loss: 0.35092544055983627
Validation loss: 2.5701687742667882

Epoch: 6| Step: 9
Training loss: 0.415779010662025
Validation loss: 2.587704357425379

Epoch: 6| Step: 10
Training loss: 0.3717566341867679
Validation loss: 2.6168990246654147

Epoch: 6| Step: 11
Training loss: 0.5304394878243679
Validation loss: 2.5360977783446894

Epoch: 6| Step: 12
Training loss: 0.47226380378618094
Validation loss: 2.5876128502284375

Epoch: 6| Step: 13
Training loss: 0.3228844452235911
Validation loss: 2.524652257585904

Epoch: 275| Step: 0
Training loss: 0.5003900794473692
Validation loss: 2.51164794474026

Epoch: 6| Step: 1
Training loss: 0.3538382517518766
Validation loss: 2.5475780554216554

Epoch: 6| Step: 2
Training loss: 0.2708579871376203
Validation loss: 2.5516196757457434

Epoch: 6| Step: 3
Training loss: 0.23575947657841426
Validation loss: 2.5935174922065176

Epoch: 6| Step: 4
Training loss: 0.34149077741755895
Validation loss: 2.600275250072446

Epoch: 6| Step: 5
Training loss: 0.5419130559667329
Validation loss: 2.5481668795987393

Epoch: 6| Step: 6
Training loss: 0.2527141904951474
Validation loss: 2.5625586154095417

Epoch: 6| Step: 7
Training loss: 0.2828252310021306
Validation loss: 2.6103959665495076

Epoch: 6| Step: 8
Training loss: 0.3247877780644004
Validation loss: 2.601373690454236

Epoch: 6| Step: 9
Training loss: 0.41938761946541814
Validation loss: 2.6334551320297326

Epoch: 6| Step: 10
Training loss: 0.2560086142657135
Validation loss: 2.51908876146128

Epoch: 6| Step: 11
Training loss: 0.3845071456899987
Validation loss: 2.5639096701337643

Epoch: 6| Step: 12
Training loss: 0.2888692519170258
Validation loss: 2.533818374386222

Epoch: 6| Step: 13
Training loss: 0.28727014413058816
Validation loss: 2.557155836011013

Epoch: 276| Step: 0
Training loss: 0.3422800191583569
Validation loss: 2.574226622504322

Epoch: 6| Step: 1
Training loss: 0.27054500668415127
Validation loss: 2.593032607483445

Epoch: 6| Step: 2
Training loss: 0.5446330299652249
Validation loss: 2.5680989451296288

Epoch: 6| Step: 3
Training loss: 0.27437107930608146
Validation loss: 2.577772389969

Epoch: 6| Step: 4
Training loss: 0.2936435937925751
Validation loss: 2.597751587000217

Epoch: 6| Step: 5
Training loss: 0.38853781990553793
Validation loss: 2.5563433430362514

Epoch: 6| Step: 6
Training loss: 0.49242339460648954
Validation loss: 2.569546091514895

Epoch: 6| Step: 7
Training loss: 0.45542517923122383
Validation loss: 2.529276215654245

Epoch: 6| Step: 8
Training loss: 0.2977204581466239
Validation loss: 2.498355077958946

Epoch: 6| Step: 9
Training loss: 0.2873311775489716
Validation loss: 2.5351717987132325

Epoch: 6| Step: 10
Training loss: 0.30638634410355464
Validation loss: 2.4724877949443314

Epoch: 6| Step: 11
Training loss: 0.20339088277924253
Validation loss: 2.4918975980352873

Epoch: 6| Step: 12
Training loss: 0.2909757087521902
Validation loss: 2.5478149427026904

Epoch: 6| Step: 13
Training loss: 0.33574586769736653
Validation loss: 2.552660753491675

Epoch: 277| Step: 0
Training loss: 0.37316928472930877
Validation loss: 2.5523094129009

Epoch: 6| Step: 1
Training loss: 0.20201117236570534
Validation loss: 2.5390567407787246

Epoch: 6| Step: 2
Training loss: 0.30335549655884164
Validation loss: 2.5993284727633084

Epoch: 6| Step: 3
Training loss: 0.26390729213980874
Validation loss: 2.5454518217014424

Epoch: 6| Step: 4
Training loss: 0.2405679371908894
Validation loss: 2.531096033821808

Epoch: 6| Step: 5
Training loss: 0.6059776628472346
Validation loss: 2.5479247147398443

Epoch: 6| Step: 6
Training loss: 0.31999462916665217
Validation loss: 2.5276230152202133

Epoch: 6| Step: 7
Training loss: 0.35449248174649894
Validation loss: 2.5084031658231507

Epoch: 6| Step: 8
Training loss: 0.2471310537105215
Validation loss: 2.552656044569387

Epoch: 6| Step: 9
Training loss: 0.4309532595844791
Validation loss: 2.5157861322328294

Epoch: 6| Step: 10
Training loss: 0.36938280910621757
Validation loss: 2.5403932654193677

Epoch: 6| Step: 11
Training loss: 0.23104904954727584
Validation loss: 2.535740131211918

Epoch: 6| Step: 12
Training loss: 0.5257742803375237
Validation loss: 2.527420042793789

Epoch: 6| Step: 13
Training loss: 0.29929574518630253
Validation loss: 2.5128832975447075

Epoch: 278| Step: 0
Training loss: 0.576113319654328
Validation loss: 2.56154163396308

Epoch: 6| Step: 1
Training loss: 0.3691928362379193
Validation loss: 2.5419678483545933

Epoch: 6| Step: 2
Training loss: 0.3029421431774105
Validation loss: 2.481277910551203

Epoch: 6| Step: 3
Training loss: 0.4421165288038666
Validation loss: 2.5239366445161844

Epoch: 6| Step: 4
Training loss: 0.16990711981189574
Validation loss: 2.5492756300907202

Epoch: 6| Step: 5
Training loss: 0.23432341643754467
Validation loss: 2.519577223089737

Epoch: 6| Step: 6
Training loss: 0.3015054184251196
Validation loss: 2.6294606773394267

Epoch: 6| Step: 7
Training loss: 0.30011159490210276
Validation loss: 2.589186326516951

Epoch: 6| Step: 8
Training loss: 0.3948392892999932
Validation loss: 2.6302423355372304

Epoch: 6| Step: 9
Training loss: 0.37356204266493837
Validation loss: 2.633311691275726

Epoch: 6| Step: 10
Training loss: 0.30314876128989177
Validation loss: 2.5707929909960314

Epoch: 6| Step: 11
Training loss: 0.4380471010379334
Validation loss: 2.534160204783711

Epoch: 6| Step: 12
Training loss: 0.3262661552083265
Validation loss: 2.542868632246751

Epoch: 6| Step: 13
Training loss: 0.5041566566650552
Validation loss: 2.4965707147119085

Epoch: 279| Step: 0
Training loss: 0.27920689500554846
Validation loss: 2.5235362943948343

Epoch: 6| Step: 1
Training loss: 0.2615793483188954
Validation loss: 2.56497352125395

Epoch: 6| Step: 2
Training loss: 0.3741451095404691
Validation loss: 2.5019978805378518

Epoch: 6| Step: 3
Training loss: 0.31287504578855624
Validation loss: 2.5823361615441685

Epoch: 6| Step: 4
Training loss: 0.33795566704586044
Validation loss: 2.5735480477221975

Epoch: 6| Step: 5
Training loss: 0.4800829229898834
Validation loss: 2.5060026029277456

Epoch: 6| Step: 6
Training loss: 0.28019838291827487
Validation loss: 2.493520677072198

Epoch: 6| Step: 7
Training loss: 0.3869992212033876
Validation loss: 2.4587189538957923

Epoch: 6| Step: 8
Training loss: 0.6533113031379103
Validation loss: 2.4987343445402437

Epoch: 6| Step: 9
Training loss: 0.4098442707647461
Validation loss: 2.4942836416768888

Epoch: 6| Step: 10
Training loss: 0.3190532214453006
Validation loss: 2.517076551351097

Epoch: 6| Step: 11
Training loss: 0.3069357696854172
Validation loss: 2.5642334572076604

Epoch: 6| Step: 12
Training loss: 0.3828285758866442
Validation loss: 2.5765849436161647

Epoch: 6| Step: 13
Training loss: 0.32715525833534903
Validation loss: 2.591902737634265

Epoch: 280| Step: 0
Training loss: 0.34961444701879063
Validation loss: 2.5643821100230477

Epoch: 6| Step: 1
Training loss: 0.37637256723388623
Validation loss: 2.532849909015682

Epoch: 6| Step: 2
Training loss: 0.31433937432102765
Validation loss: 2.5467539565453596

Epoch: 6| Step: 3
Training loss: 0.3823020607092256
Validation loss: 2.5280612043167596

Epoch: 6| Step: 4
Training loss: 0.33211013754373725
Validation loss: 2.5904677201810933

Epoch: 6| Step: 5
Training loss: 0.621993846175978
Validation loss: 2.512497547331921

Epoch: 6| Step: 6
Training loss: 0.3800024712005371
Validation loss: 2.5831243727885007

Epoch: 6| Step: 7
Training loss: 0.2630386944488132
Validation loss: 2.575559175448287

Epoch: 6| Step: 8
Training loss: 0.35526059941714616
Validation loss: 2.6207343441130067

Epoch: 6| Step: 9
Training loss: 0.38986773522235363
Validation loss: 2.64023825768433

Epoch: 6| Step: 10
Training loss: 0.294049697540535
Validation loss: 2.601343063554631

Epoch: 6| Step: 11
Training loss: 0.4291469989208118
Validation loss: 2.6235500145709207

Epoch: 6| Step: 12
Training loss: 0.3318790648008512
Validation loss: 2.5938655107507294

Epoch: 6| Step: 13
Training loss: 0.3259988885711376
Validation loss: 2.5443756696224935

Epoch: 281| Step: 0
Training loss: 0.3339478991483382
Validation loss: 2.504592634797349

Epoch: 6| Step: 1
Training loss: 0.4516982933645583
Validation loss: 2.544175103585175

Epoch: 6| Step: 2
Training loss: 0.3096167111448111
Validation loss: 2.6167918195579323

Epoch: 6| Step: 3
Training loss: 0.29293408506668406
Validation loss: 2.6170960595397914

Epoch: 6| Step: 4
Training loss: 0.5051230001317956
Validation loss: 2.5930994589145313

Epoch: 6| Step: 5
Training loss: 0.32673836813816143
Validation loss: 2.586447044180974

Epoch: 6| Step: 6
Training loss: 0.28489613100044464
Validation loss: 2.572162360588066

Epoch: 6| Step: 7
Training loss: 0.24138889620728135
Validation loss: 2.494949572084773

Epoch: 6| Step: 8
Training loss: 0.5125843327615431
Validation loss: 2.4972273471762243

Epoch: 6| Step: 9
Training loss: 0.3119302084989117
Validation loss: 2.5348420264325164

Epoch: 6| Step: 10
Training loss: 0.38608827155567166
Validation loss: 2.5016201412145036

Epoch: 6| Step: 11
Training loss: 0.5368306216904045
Validation loss: 2.5382889180504455

Epoch: 6| Step: 12
Training loss: 0.41188650749003375
Validation loss: 2.522167961187662

Epoch: 6| Step: 13
Training loss: 0.20590109320983044
Validation loss: 2.529420858950428

Epoch: 282| Step: 0
Training loss: 0.4080491574139772
Validation loss: 2.5331744190198417

Epoch: 6| Step: 1
Training loss: 0.38433717215876984
Validation loss: 2.5345562507486443

Epoch: 6| Step: 2
Training loss: 0.18359858932610257
Validation loss: 2.549024497855647

Epoch: 6| Step: 3
Training loss: 0.35648504584435536
Validation loss: 2.5086929106857254

Epoch: 6| Step: 4
Training loss: 0.3759212502751399
Validation loss: 2.56601463205968

Epoch: 6| Step: 5
Training loss: 0.3793738125086492
Validation loss: 2.4876135584535195

Epoch: 6| Step: 6
Training loss: 0.5941026042181912
Validation loss: 2.5139044333223826

Epoch: 6| Step: 7
Training loss: 0.37120887576741646
Validation loss: 2.553772679902113

Epoch: 6| Step: 8
Training loss: 0.4332892405409041
Validation loss: 2.536257558992796

Epoch: 6| Step: 9
Training loss: 0.41638421578287754
Validation loss: 2.549469778623561

Epoch: 6| Step: 10
Training loss: 0.34202125813548295
Validation loss: 2.5745245868108677

Epoch: 6| Step: 11
Training loss: 0.27180960954053346
Validation loss: 2.5919978186780677

Epoch: 6| Step: 12
Training loss: 0.27596642110431757
Validation loss: 2.583427094224432

Epoch: 6| Step: 13
Training loss: 0.28752450061144763
Validation loss: 2.667412800017562

Epoch: 283| Step: 0
Training loss: 0.39915741600488114
Validation loss: 2.6319230234509625

Epoch: 6| Step: 1
Training loss: 0.2679304045442207
Validation loss: 2.5831575385135728

Epoch: 6| Step: 2
Training loss: 0.3590480104648667
Validation loss: 2.632704373185367

Epoch: 6| Step: 3
Training loss: 0.25632036336293523
Validation loss: 2.610657717410183

Epoch: 6| Step: 4
Training loss: 0.3100800514305518
Validation loss: 2.536288791658771

Epoch: 6| Step: 5
Training loss: 0.28306123533364363
Validation loss: 2.5682880348189747

Epoch: 6| Step: 6
Training loss: 0.44656280202568416
Validation loss: 2.559780072957757

Epoch: 6| Step: 7
Training loss: 0.3398554460113291
Validation loss: 2.4939598390383853

Epoch: 6| Step: 8
Training loss: 0.5838600460122851
Validation loss: 2.542961101061465

Epoch: 6| Step: 9
Training loss: 0.20586166561524413
Validation loss: 2.5551644909458187

Epoch: 6| Step: 10
Training loss: 0.5809299110626914
Validation loss: 2.59990433859294

Epoch: 6| Step: 11
Training loss: 0.4716219501422025
Validation loss: 2.5033315077299663

Epoch: 6| Step: 12
Training loss: 0.3599932162983497
Validation loss: 2.573789561744044

Epoch: 6| Step: 13
Training loss: 0.4057547778696177
Validation loss: 2.489669915347019

Epoch: 284| Step: 0
Training loss: 0.33772021058995916
Validation loss: 2.539800073159518

Epoch: 6| Step: 1
Training loss: 0.42986602542446206
Validation loss: 2.5316032508540314

Epoch: 6| Step: 2
Training loss: 0.3451103473151703
Validation loss: 2.5636059305154286

Epoch: 6| Step: 3
Training loss: 0.37479967488668664
Validation loss: 2.533854004617172

Epoch: 6| Step: 4
Training loss: 0.33001094337582615
Validation loss: 2.6140865497353065

Epoch: 6| Step: 5
Training loss: 0.3835490206493972
Validation loss: 2.5800717026704936

Epoch: 6| Step: 6
Training loss: 0.5033051209827236
Validation loss: 2.6180609616719313

Epoch: 6| Step: 7
Training loss: 0.34249704852189894
Validation loss: 2.578556618058594

Epoch: 6| Step: 8
Training loss: 0.3327066396424513
Validation loss: 2.5532976855519456

Epoch: 6| Step: 9
Training loss: 0.30434430184937566
Validation loss: 2.5124384440762357

Epoch: 6| Step: 10
Training loss: 0.38551949942041175
Validation loss: 2.4812298425581116

Epoch: 6| Step: 11
Training loss: 0.3083484495598734
Validation loss: 2.5141275818285718

Epoch: 6| Step: 12
Training loss: 0.4143075757530328
Validation loss: 2.534415208753917

Epoch: 6| Step: 13
Training loss: 0.2576659392876699
Validation loss: 2.511244108561214

Epoch: 285| Step: 0
Training loss: 0.5080403037059072
Validation loss: 2.551956350060864

Epoch: 6| Step: 1
Training loss: 0.3307467578605051
Validation loss: 2.569797127950736

Epoch: 6| Step: 2
Training loss: 0.46441852129466593
Validation loss: 2.592059124325254

Epoch: 6| Step: 3
Training loss: 0.23919323419476085
Validation loss: 2.5609991594129737

Epoch: 6| Step: 4
Training loss: 0.49826528210801463
Validation loss: 2.513201112490346

Epoch: 6| Step: 5
Training loss: 0.3440058363042362
Validation loss: 2.4769592368501656

Epoch: 6| Step: 6
Training loss: 0.3335034102926082
Validation loss: 2.520840358461622

Epoch: 6| Step: 7
Training loss: 0.2950153455339458
Validation loss: 2.5914787014775347

Epoch: 6| Step: 8
Training loss: 0.27193852044319344
Validation loss: 2.525821217359252

Epoch: 6| Step: 9
Training loss: 0.33774905463848054
Validation loss: 2.5422619737416987

Epoch: 6| Step: 10
Training loss: 0.31638958969523295
Validation loss: 2.5082436861343838

Epoch: 6| Step: 11
Training loss: 0.29600496546263066
Validation loss: 2.5398696633687803

Epoch: 6| Step: 12
Training loss: 0.3450931836487768
Validation loss: 2.500679774054327

Epoch: 6| Step: 13
Training loss: 0.1818736232954533
Validation loss: 2.5150686245069354

Epoch: 286| Step: 0
Training loss: 0.21939558744961626
Validation loss: 2.4803798949979887

Epoch: 6| Step: 1
Training loss: 0.35820438630226237
Validation loss: 2.502080242611397

Epoch: 6| Step: 2
Training loss: 0.30816028427765263
Validation loss: 2.4784141301305573

Epoch: 6| Step: 3
Training loss: 0.1728290284549367
Validation loss: 2.551681040501822

Epoch: 6| Step: 4
Training loss: 0.42528857153317534
Validation loss: 2.5891552561825795

Epoch: 6| Step: 5
Training loss: 0.33932170013810803
Validation loss: 2.571583318721473

Epoch: 6| Step: 6
Training loss: 0.2850907394198372
Validation loss: 2.538914853229197

Epoch: 6| Step: 7
Training loss: 0.31366412769598095
Validation loss: 2.5339308776430207

Epoch: 6| Step: 8
Training loss: 0.338905046530346
Validation loss: 2.5874952098169386

Epoch: 6| Step: 9
Training loss: 0.332098707190636
Validation loss: 2.6153704356439182

Epoch: 6| Step: 10
Training loss: 0.4854542337732951
Validation loss: 2.5901425411271735

Epoch: 6| Step: 11
Training loss: 0.37865297957038513
Validation loss: 2.664843954583776

Epoch: 6| Step: 12
Training loss: 0.3077229999029105
Validation loss: 2.62517890623264

Epoch: 6| Step: 13
Training loss: 0.3036047206983461
Validation loss: 2.5834838197827885

Epoch: 287| Step: 0
Training loss: 0.3847184128042873
Validation loss: 2.5353664630400803

Epoch: 6| Step: 1
Training loss: 0.3337370419576305
Validation loss: 2.581734536840377

Epoch: 6| Step: 2
Training loss: 0.2781406960719519
Validation loss: 2.6470233588917984

Epoch: 6| Step: 3
Training loss: 0.3670891569211826
Validation loss: 2.6035435630480284

Epoch: 6| Step: 4
Training loss: 0.27341367072768324
Validation loss: 2.638063004292525

Epoch: 6| Step: 5
Training loss: 0.3452957468586207
Validation loss: 2.590298435809474

Epoch: 6| Step: 6
Training loss: 0.2830931877638488
Validation loss: 2.552889674472415

Epoch: 6| Step: 7
Training loss: 0.40827067058183847
Validation loss: 2.6340146513289806

Epoch: 6| Step: 8
Training loss: 0.46903993858551546
Validation loss: 2.5761865591807305

Epoch: 6| Step: 9
Training loss: 0.15286526303462433
Validation loss: 2.635025271777693

Epoch: 6| Step: 10
Training loss: 0.40355863757365457
Validation loss: 2.604337035646162

Epoch: 6| Step: 11
Training loss: 0.3127490362637351
Validation loss: 2.5623363969881394

Epoch: 6| Step: 12
Training loss: 0.2171820663897655
Validation loss: 2.60189435367807

Epoch: 6| Step: 13
Training loss: 0.4051725147011744
Validation loss: 2.575077367132656

Epoch: 288| Step: 0
Training loss: 0.41034151162099225
Validation loss: 2.516865394863825

Epoch: 6| Step: 1
Training loss: 0.3545368261054286
Validation loss: 2.562948776893193

Epoch: 6| Step: 2
Training loss: 0.32528357696946913
Validation loss: 2.5752815209970965

Epoch: 6| Step: 3
Training loss: 0.4023301205595025
Validation loss: 2.5598166535331206

Epoch: 6| Step: 4
Training loss: 0.35151850107158167
Validation loss: 2.5740250016247823

Epoch: 6| Step: 5
Training loss: 0.3265725490173806
Validation loss: 2.570336315659221

Epoch: 6| Step: 6
Training loss: 0.36117094590589277
Validation loss: 2.601149678053228

Epoch: 6| Step: 7
Training loss: 0.32238482958246856
Validation loss: 2.5963345332090473

Epoch: 6| Step: 8
Training loss: 0.26840344418378126
Validation loss: 2.544654307104625

Epoch: 6| Step: 9
Training loss: 0.3360476424168154
Validation loss: 2.513210029924993

Epoch: 6| Step: 10
Training loss: 0.5402040695108468
Validation loss: 2.5546981780191635

Epoch: 6| Step: 11
Training loss: 0.37909774267364316
Validation loss: 2.5228971802399687

Epoch: 6| Step: 12
Training loss: 0.2849126585339743
Validation loss: 2.5685341817838725

Epoch: 6| Step: 13
Training loss: 0.3331354964787296
Validation loss: 2.559012963505007

Epoch: 289| Step: 0
Training loss: 0.3616257550059934
Validation loss: 2.550908598123346

Epoch: 6| Step: 1
Training loss: 0.35723672042094756
Validation loss: 2.592899167639681

Epoch: 6| Step: 2
Training loss: 0.3181242747570232
Validation loss: 2.584977539378119

Epoch: 6| Step: 3
Training loss: 0.25907059236962715
Validation loss: 2.6459286414774894

Epoch: 6| Step: 4
Training loss: 0.3923168926397234
Validation loss: 2.5892337408628037

Epoch: 6| Step: 5
Training loss: 0.3400517627287841
Validation loss: 2.602046138801998

Epoch: 6| Step: 6
Training loss: 0.31942190243939633
Validation loss: 2.5865230070322762

Epoch: 6| Step: 7
Training loss: 0.349103551037074
Validation loss: 2.5819253212057167

Epoch: 6| Step: 8
Training loss: 0.48464867336119566
Validation loss: 2.520690186169451

Epoch: 6| Step: 9
Training loss: 0.23793494746535215
Validation loss: 2.5156579104338066

Epoch: 6| Step: 10
Training loss: 0.2800720102448719
Validation loss: 2.5452933519742613

Epoch: 6| Step: 11
Training loss: 0.464886831643306
Validation loss: 2.5523677174423973

Epoch: 6| Step: 12
Training loss: 0.2589268731310542
Validation loss: 2.5803189354175236

Epoch: 6| Step: 13
Training loss: 0.3452298000608352
Validation loss: 2.5667173215483166

Epoch: 290| Step: 0
Training loss: 0.2222787769361858
Validation loss: 2.5593053396058156

Epoch: 6| Step: 1
Training loss: 0.2758215650533543
Validation loss: 2.5867854607560403

Epoch: 6| Step: 2
Training loss: 0.390088991532949
Validation loss: 2.5138313185584638

Epoch: 6| Step: 3
Training loss: 0.2565707734385133
Validation loss: 2.5252891101185884

Epoch: 6| Step: 4
Training loss: 0.2850325198400881
Validation loss: 2.534371746921921

Epoch: 6| Step: 5
Training loss: 0.3158438830052216
Validation loss: 2.5580756752496105

Epoch: 6| Step: 6
Training loss: 0.38834539915885646
Validation loss: 2.6038005622377742

Epoch: 6| Step: 7
Training loss: 0.3924623005371481
Validation loss: 2.610199894978351

Epoch: 6| Step: 8
Training loss: 0.23751667742147517
Validation loss: 2.4960064143909455

Epoch: 6| Step: 9
Training loss: 0.2926908319248181
Validation loss: 2.5594637879064654

Epoch: 6| Step: 10
Training loss: 0.5091994784730067
Validation loss: 2.520473538618596

Epoch: 6| Step: 11
Training loss: 0.35492106574249876
Validation loss: 2.508517533622284

Epoch: 6| Step: 12
Training loss: 0.17014433012476934
Validation loss: 2.572647016245928

Epoch: 6| Step: 13
Training loss: 0.24884830375067982
Validation loss: 2.510989038159644

Epoch: 291| Step: 0
Training loss: 0.21436060419209174
Validation loss: 2.6024990362604696

Epoch: 6| Step: 1
Training loss: 0.2510702648467265
Validation loss: 2.59184608134877

Epoch: 6| Step: 2
Training loss: 0.3189917760060955
Validation loss: 2.550741385225791

Epoch: 6| Step: 3
Training loss: 0.35067705335814764
Validation loss: 2.5567111012163073

Epoch: 6| Step: 4
Training loss: 0.5287908408442304
Validation loss: 2.5104527028980974

Epoch: 6| Step: 5
Training loss: 0.2996827912184449
Validation loss: 2.5728913021510507

Epoch: 6| Step: 6
Training loss: 0.2580799680504185
Validation loss: 2.5295492039012157

Epoch: 6| Step: 7
Training loss: 0.21345637331580294
Validation loss: 2.5327547569211406

Epoch: 6| Step: 8
Training loss: 0.2349511535332486
Validation loss: 2.5163516935924397

Epoch: 6| Step: 9
Training loss: 0.3303157019121641
Validation loss: 2.485590975059092

Epoch: 6| Step: 10
Training loss: 0.2962359653037657
Validation loss: 2.519860975982044

Epoch: 6| Step: 11
Training loss: 0.329447578526414
Validation loss: 2.5437279899451

Epoch: 6| Step: 12
Training loss: 0.27090348044434187
Validation loss: 2.4935234419447014

Epoch: 6| Step: 13
Training loss: 0.44107571607230084
Validation loss: 2.5600718958017548

Epoch: 292| Step: 0
Training loss: 0.30688538471605586
Validation loss: 2.560724077220579

Epoch: 6| Step: 1
Training loss: 0.26370973668413417
Validation loss: 2.5884865051982766

Epoch: 6| Step: 2
Training loss: 0.28662981478211025
Validation loss: 2.525880636739049

Epoch: 6| Step: 3
Training loss: 0.34379460305498827
Validation loss: 2.5494458070052497

Epoch: 6| Step: 4
Training loss: 0.41229972240037105
Validation loss: 2.516839044448452

Epoch: 6| Step: 5
Training loss: 0.3908790906393807
Validation loss: 2.528341529730644

Epoch: 6| Step: 6
Training loss: 0.32874502910728587
Validation loss: 2.5359178132965545

Epoch: 6| Step: 7
Training loss: 0.23372495628009288
Validation loss: 2.5678225034720294

Epoch: 6| Step: 8
Training loss: 0.35138446750527186
Validation loss: 2.5929450352476877

Epoch: 6| Step: 9
Training loss: 0.37618951092632696
Validation loss: 2.5508892821197837

Epoch: 6| Step: 10
Training loss: 0.46294544394336234
Validation loss: 2.564928733648655

Epoch: 6| Step: 11
Training loss: 0.38540938301764727
Validation loss: 2.579649749855496

Epoch: 6| Step: 12
Training loss: 0.3227612816318513
Validation loss: 2.571980315007036

Epoch: 6| Step: 13
Training loss: 0.26138299785018765
Validation loss: 2.497130797917596

Epoch: 293| Step: 0
Training loss: 0.2798027845225048
Validation loss: 2.535800062503067

Epoch: 6| Step: 1
Training loss: 0.29721312341226397
Validation loss: 2.5699623897536577

Epoch: 6| Step: 2
Training loss: 0.4723342555357214
Validation loss: 2.6268989793758664

Epoch: 6| Step: 3
Training loss: 0.417057291349073
Validation loss: 2.598009786234517

Epoch: 6| Step: 4
Training loss: 0.29129621560643587
Validation loss: 2.6214532733516633

Epoch: 6| Step: 5
Training loss: 0.21887852094923838
Validation loss: 2.6275359801161837

Epoch: 6| Step: 6
Training loss: 0.29652602615603424
Validation loss: 2.601282832146092

Epoch: 6| Step: 7
Training loss: 0.21512369643741272
Validation loss: 2.565649190921086

Epoch: 6| Step: 8
Training loss: 0.23351246749667784
Validation loss: 2.563049699392997

Epoch: 6| Step: 9
Training loss: 0.2894739624842306
Validation loss: 2.575693220509261

Epoch: 6| Step: 10
Training loss: 0.20957695203006513
Validation loss: 2.596053131211266

Epoch: 6| Step: 11
Training loss: 0.4350821235022279
Validation loss: 2.5672907434909824

Epoch: 6| Step: 12
Training loss: 0.38411145828613796
Validation loss: 2.6503828138078442

Epoch: 6| Step: 13
Training loss: 0.3119704886403968
Validation loss: 2.634296983534295

Epoch: 294| Step: 0
Training loss: 0.1838085865510812
Validation loss: 2.5930051844896025

Epoch: 6| Step: 1
Training loss: 0.27354878477106576
Validation loss: 2.5693470108758274

Epoch: 6| Step: 2
Training loss: 0.3463425407274973
Validation loss: 2.5525463592474043

Epoch: 6| Step: 3
Training loss: 0.3657536614470082
Validation loss: 2.5528239414697906

Epoch: 6| Step: 4
Training loss: 0.35353174752411404
Validation loss: 2.558381826539668

Epoch: 6| Step: 5
Training loss: 0.27118442623948674
Validation loss: 2.5325969675723488

Epoch: 6| Step: 6
Training loss: 0.3550600909698796
Validation loss: 2.52446612483337

Epoch: 6| Step: 7
Training loss: 0.28910422668342783
Validation loss: 2.577305156707509

Epoch: 6| Step: 8
Training loss: 0.3366353084262128
Validation loss: 2.5179674761456563

Epoch: 6| Step: 9
Training loss: 0.21285284214541714
Validation loss: 2.5400382333666385

Epoch: 6| Step: 10
Training loss: 0.2844167290976324
Validation loss: 2.532460555095463

Epoch: 6| Step: 11
Training loss: 0.5297807121969426
Validation loss: 2.505793106023461

Epoch: 6| Step: 12
Training loss: 0.27225490696743637
Validation loss: 2.570807551332491

Epoch: 6| Step: 13
Training loss: 0.23055908889501472
Validation loss: 2.583102482561354

Epoch: 295| Step: 0
Training loss: 0.35339689632015203
Validation loss: 2.5360788195883486

Epoch: 6| Step: 1
Training loss: 0.31100125929065403
Validation loss: 2.5638241486821207

Epoch: 6| Step: 2
Training loss: 0.350304939909866
Validation loss: 2.4946329521603845

Epoch: 6| Step: 3
Training loss: 0.24152455810405368
Validation loss: 2.5154919480546427

Epoch: 6| Step: 4
Training loss: 0.19529630593875352
Validation loss: 2.512099170500966

Epoch: 6| Step: 5
Training loss: 0.3564836037330887
Validation loss: 2.4996898140801

Epoch: 6| Step: 6
Training loss: 0.25837350265131803
Validation loss: 2.50346049180959

Epoch: 6| Step: 7
Training loss: 0.4500212425940115
Validation loss: 2.4760709449236393

Epoch: 6| Step: 8
Training loss: 0.4518003668824134
Validation loss: 2.5114834736077714

Epoch: 6| Step: 9
Training loss: 0.2709730808693726
Validation loss: 2.5320569310253735

Epoch: 6| Step: 10
Training loss: 0.3720386121166428
Validation loss: 2.548692097937711

Epoch: 6| Step: 11
Training loss: 0.33949809199079345
Validation loss: 2.6295527229669218

Epoch: 6| Step: 12
Training loss: 0.2667145542022582
Validation loss: 2.549880830311383

Epoch: 6| Step: 13
Training loss: 0.24409527929713606
Validation loss: 2.586422201563071

Epoch: 296| Step: 0
Training loss: 0.30481140356158004
Validation loss: 2.526578894573581

Epoch: 6| Step: 1
Training loss: 0.31469674476598186
Validation loss: 2.617314744579528

Epoch: 6| Step: 2
Training loss: 0.34256253179819024
Validation loss: 2.542856787244773

Epoch: 6| Step: 3
Training loss: 0.2816343991971067
Validation loss: 2.513304167012469

Epoch: 6| Step: 4
Training loss: 0.2976475501603834
Validation loss: 2.5064073628960437

Epoch: 6| Step: 5
Training loss: 0.3354913721154857
Validation loss: 2.4932959791010063

Epoch: 6| Step: 6
Training loss: 0.3375447217133343
Validation loss: 2.532233255252215

Epoch: 6| Step: 7
Training loss: 0.24080262007000788
Validation loss: 2.5797092232732024

Epoch: 6| Step: 8
Training loss: 0.27600323061589943
Validation loss: 2.59142885946754

Epoch: 6| Step: 9
Training loss: 0.26549343048290563
Validation loss: 2.6174544772343387

Epoch: 6| Step: 10
Training loss: 0.2542387032957751
Validation loss: 2.611510326312739

Epoch: 6| Step: 11
Training loss: 0.4965390887302219
Validation loss: 2.654926209534863

Epoch: 6| Step: 12
Training loss: 0.4045388423697848
Validation loss: 2.668577646948115

Epoch: 6| Step: 13
Training loss: 0.4996069167660506
Validation loss: 2.594279468835748

Epoch: 297| Step: 0
Training loss: 0.37263082101620326
Validation loss: 2.570402427885783

Epoch: 6| Step: 1
Training loss: 0.2933743022265139
Validation loss: 2.5561953108952435

Epoch: 6| Step: 2
Training loss: 0.3258138050307132
Validation loss: 2.4852045781428065

Epoch: 6| Step: 3
Training loss: 0.37698638848313193
Validation loss: 2.515049973314314

Epoch: 6| Step: 4
Training loss: 0.3277553565273588
Validation loss: 2.4991886332268267

Epoch: 6| Step: 5
Training loss: 0.2520501888701237
Validation loss: 2.5522623168048266

Epoch: 6| Step: 6
Training loss: 0.3001862871430274
Validation loss: 2.6108626124540977

Epoch: 6| Step: 7
Training loss: 0.3871245326395635
Validation loss: 2.610490381631434

Epoch: 6| Step: 8
Training loss: 0.2957318784574407
Validation loss: 2.543899053444676

Epoch: 6| Step: 9
Training loss: 0.3159159641113828
Validation loss: 2.52702608622854

Epoch: 6| Step: 10
Training loss: 0.426223455256967
Validation loss: 2.4456792034430785

Epoch: 6| Step: 11
Training loss: 0.47917641926944
Validation loss: 2.517012109058722

Epoch: 6| Step: 12
Training loss: 0.3394005395612435
Validation loss: 2.48072390708283

Epoch: 6| Step: 13
Training loss: 0.4079314792750414
Validation loss: 2.513155987256089

Epoch: 298| Step: 0
Training loss: 0.387857091093775
Validation loss: 2.5394410462506123

Epoch: 6| Step: 1
Training loss: 0.3224361430940214
Validation loss: 2.5861021145059646

Epoch: 6| Step: 2
Training loss: 0.37023736618066877
Validation loss: 2.604920840094839

Epoch: 6| Step: 3
Training loss: 0.23595104399704964
Validation loss: 2.60039123501531

Epoch: 6| Step: 4
Training loss: 0.5391642709390909
Validation loss: 2.5879592444961133

Epoch: 6| Step: 5
Training loss: 0.37189281164516713
Validation loss: 2.5697340232178534

Epoch: 6| Step: 6
Training loss: 0.3526379137592039
Validation loss: 2.524222756668637

Epoch: 6| Step: 7
Training loss: 0.26190529054066125
Validation loss: 2.522288648486383

Epoch: 6| Step: 8
Training loss: 0.29622048456300093
Validation loss: 2.5603321178393497

Epoch: 6| Step: 9
Training loss: 0.26034637297189395
Validation loss: 2.528743869021682

Epoch: 6| Step: 10
Training loss: 0.2458368201466499
Validation loss: 2.5712970057894937

Epoch: 6| Step: 11
Training loss: 0.33760294492163667
Validation loss: 2.567019090876953

Epoch: 6| Step: 12
Training loss: 0.2516047116517679
Validation loss: 2.5479803514566393

Epoch: 6| Step: 13
Training loss: 0.33536475171750796
Validation loss: 2.6147101904704164

Epoch: 299| Step: 0
Training loss: 0.4976695707206201
Validation loss: 2.6613223992338426

Epoch: 6| Step: 1
Training loss: 0.3487111706122389
Validation loss: 2.5692397239395173

Epoch: 6| Step: 2
Training loss: 0.3102776421967175
Validation loss: 2.6192878152677697

Epoch: 6| Step: 3
Training loss: 0.34525017240576616
Validation loss: 2.507024837401294

Epoch: 6| Step: 4
Training loss: 0.4388520262356864
Validation loss: 2.5611466811691965

Epoch: 6| Step: 5
Training loss: 0.3297142867645907
Validation loss: 2.4963427973095116

Epoch: 6| Step: 6
Training loss: 0.4773670971244486
Validation loss: 2.5212350924518776

Epoch: 6| Step: 7
Training loss: 0.2446405556469081
Validation loss: 2.5283759955635587

Epoch: 6| Step: 8
Training loss: 0.3032470054494335
Validation loss: 2.567270273803973

Epoch: 6| Step: 9
Training loss: 0.3378555301676304
Validation loss: 2.5393011284224234

Epoch: 6| Step: 10
Training loss: 0.311712500621898
Validation loss: 2.577604144878674

Epoch: 6| Step: 11
Training loss: 0.2758992415503806
Validation loss: 2.4704068575457527

Epoch: 6| Step: 12
Training loss: 0.564903528366374
Validation loss: 2.4997954602809753

Epoch: 6| Step: 13
Training loss: 0.35224949153216384
Validation loss: 2.4478986347156604

Epoch: 300| Step: 0
Training loss: 0.4099356103264092
Validation loss: 2.500382362371538

Epoch: 6| Step: 1
Training loss: 0.2958011782099773
Validation loss: 2.4898723503698887

Epoch: 6| Step: 2
Training loss: 0.31115977666744477
Validation loss: 2.5294003734253843

Epoch: 6| Step: 3
Training loss: 0.30362089238974893
Validation loss: 2.5132750282135485

Epoch: 6| Step: 4
Training loss: 0.32752267868201224
Validation loss: 2.546050743792497

Epoch: 6| Step: 5
Training loss: 0.4664030129274018
Validation loss: 2.554908276272021

Epoch: 6| Step: 6
Training loss: 0.26401905232826167
Validation loss: 2.5627535562753248

Epoch: 6| Step: 7
Training loss: 0.2753092192325548
Validation loss: 2.5447844836372706

Epoch: 6| Step: 8
Training loss: 0.36727072401631355
Validation loss: 2.5717026063686745

Epoch: 6| Step: 9
Training loss: 0.3709707558241622
Validation loss: 2.579050356553886

Epoch: 6| Step: 10
Training loss: 0.2348253850044125
Validation loss: 2.5326293201322136

Epoch: 6| Step: 11
Training loss: 0.22910147339281722
Validation loss: 2.5122423036679944

Epoch: 6| Step: 12
Training loss: 0.3766068760853436
Validation loss: 2.515346906624691

Epoch: 6| Step: 13
Training loss: 0.2579794834244585
Validation loss: 2.5623770428442874

Epoch: 301| Step: 0
Training loss: 0.29713378468944884
Validation loss: 2.5369843727976766

Epoch: 6| Step: 1
Training loss: 0.2412851196381918
Validation loss: 2.4975453883244896

Epoch: 6| Step: 2
Training loss: 0.23929103698483775
Validation loss: 2.5687597235923314

Epoch: 6| Step: 3
Training loss: 0.35135566136961793
Validation loss: 2.523299458510249

Epoch: 6| Step: 4
Training loss: 0.23835317901840378
Validation loss: 2.5954756300993496

Epoch: 6| Step: 5
Training loss: 0.2671221865192101
Validation loss: 2.4810264581191794

Epoch: 6| Step: 6
Training loss: 0.34768824483684363
Validation loss: 2.592505229097376

Epoch: 6| Step: 7
Training loss: 0.20454278737072829
Validation loss: 2.5346298729317813

Epoch: 6| Step: 8
Training loss: 0.3055377004324281
Validation loss: 2.5360182211253415

Epoch: 6| Step: 9
Training loss: 0.31818467009647233
Validation loss: 2.531738595156281

Epoch: 6| Step: 10
Training loss: 0.4570857936557612
Validation loss: 2.566103502722795

Epoch: 6| Step: 11
Training loss: 0.2898150519792789
Validation loss: 2.532766100054292

Epoch: 6| Step: 12
Training loss: 0.38465362700286165
Validation loss: 2.5539681669166705

Epoch: 6| Step: 13
Training loss: 0.20483978590632282
Validation loss: 2.52655789845334

Epoch: 302| Step: 0
Training loss: 0.24344319481364873
Validation loss: 2.5175075634562103

Epoch: 6| Step: 1
Training loss: 0.2220875017933178
Validation loss: 2.526219349278351

Epoch: 6| Step: 2
Training loss: 0.30982979570400343
Validation loss: 2.4692437768620663

Epoch: 6| Step: 3
Training loss: 0.3477111301610576
Validation loss: 2.566897457034784

Epoch: 6| Step: 4
Training loss: 0.27481172467231474
Validation loss: 2.523864237602699

Epoch: 6| Step: 5
Training loss: 0.34319787768011184
Validation loss: 2.519760176635462

Epoch: 6| Step: 6
Training loss: 0.2943968868623246
Validation loss: 2.578764610711412

Epoch: 6| Step: 7
Training loss: 0.44751011525341805
Validation loss: 2.5784949297364133

Epoch: 6| Step: 8
Training loss: 0.30653072015524224
Validation loss: 2.6199432137088934

Epoch: 6| Step: 9
Training loss: 0.42818517749286245
Validation loss: 2.586241920277884

Epoch: 6| Step: 10
Training loss: 0.2057531781408854
Validation loss: 2.579915875423654

Epoch: 6| Step: 11
Training loss: 0.35982363105878745
Validation loss: 2.5267175668137245

Epoch: 6| Step: 12
Training loss: 0.457191031801528
Validation loss: 2.536355070692365

Epoch: 6| Step: 13
Training loss: 0.2821912512419009
Validation loss: 2.565069933564431

Epoch: 303| Step: 0
Training loss: 0.3114911603798498
Validation loss: 2.5447098513638196

Epoch: 6| Step: 1
Training loss: 0.39721171370561503
Validation loss: 2.6482427444793153

Epoch: 6| Step: 2
Training loss: 0.30104473265348264
Validation loss: 2.6273557295362147

Epoch: 6| Step: 3
Training loss: 0.16557842355477867
Validation loss: 2.5032380274202475

Epoch: 6| Step: 4
Training loss: 0.2366399441844961
Validation loss: 2.5678874192580574

Epoch: 6| Step: 5
Training loss: 0.29591504292744014
Validation loss: 2.5583447750179475

Epoch: 6| Step: 6
Training loss: 0.40329350712626827
Validation loss: 2.5095379875841144

Epoch: 6| Step: 7
Training loss: 0.24716984398837744
Validation loss: 2.5354226887823934

Epoch: 6| Step: 8
Training loss: 0.31416131927398283
Validation loss: 2.5713059535511875

Epoch: 6| Step: 9
Training loss: 0.540487920327935
Validation loss: 2.5208176436343206

Epoch: 6| Step: 10
Training loss: 0.3932057198951028
Validation loss: 2.5499349361421655

Epoch: 6| Step: 11
Training loss: 0.2996835743564462
Validation loss: 2.539002606590268

Epoch: 6| Step: 12
Training loss: 0.5236039537547184
Validation loss: 2.6304611437069823

Epoch: 6| Step: 13
Training loss: 0.3590425529284586
Validation loss: 2.556977100539057

Epoch: 304| Step: 0
Training loss: 0.3257470934043605
Validation loss: 2.588198715200524

Epoch: 6| Step: 1
Training loss: 0.2901368024653234
Validation loss: 2.571363742360585

Epoch: 6| Step: 2
Training loss: 0.3686938331953752
Validation loss: 2.6092379490234547

Epoch: 6| Step: 3
Training loss: 0.4248734867902869
Validation loss: 2.568935253334658

Epoch: 6| Step: 4
Training loss: 0.42943135342885624
Validation loss: 2.581343704998182

Epoch: 6| Step: 5
Training loss: 0.20872365428373324
Validation loss: 2.579862675610001

Epoch: 6| Step: 6
Training loss: 0.36054036639818293
Validation loss: 2.597670904514976

Epoch: 6| Step: 7
Training loss: 0.4072548835840946
Validation loss: 2.5699697573251674

Epoch: 6| Step: 8
Training loss: 0.358198895112234
Validation loss: 2.6315833674151126

Epoch: 6| Step: 9
Training loss: 0.36837645053221973
Validation loss: 2.6451916004004286

Epoch: 6| Step: 10
Training loss: 0.3785719822676483
Validation loss: 2.603897024817978

Epoch: 6| Step: 11
Training loss: 0.22704265949120636
Validation loss: 2.547539708118484

Epoch: 6| Step: 12
Training loss: 0.48693974653275884
Validation loss: 2.5321234934513077

Epoch: 6| Step: 13
Training loss: 0.14332035947410582
Validation loss: 2.5225313683617694

Epoch: 305| Step: 0
Training loss: 0.29921505380444163
Validation loss: 2.5151024901689345

Epoch: 6| Step: 1
Training loss: 0.25974579068519105
Validation loss: 2.4854470025444466

Epoch: 6| Step: 2
Training loss: 0.2582279672372981
Validation loss: 2.4814361207790046

Epoch: 6| Step: 3
Training loss: 0.33457383901649324
Validation loss: 2.5851725727179677

Epoch: 6| Step: 4
Training loss: 0.29771074812390036
Validation loss: 2.5160992256342967

Epoch: 6| Step: 5
Training loss: 0.4213723614524358
Validation loss: 2.5793825800736325

Epoch: 6| Step: 6
Training loss: 0.28495971229713396
Validation loss: 2.5141820777603656

Epoch: 6| Step: 7
Training loss: 0.3175662874875475
Validation loss: 2.5194420929345998

Epoch: 6| Step: 8
Training loss: 0.28413563809700465
Validation loss: 2.5708428698527213

Epoch: 6| Step: 9
Training loss: 0.28841975640041106
Validation loss: 2.5487971629165886

Epoch: 6| Step: 10
Training loss: 0.22708634949060563
Validation loss: 2.5483463928290533

Epoch: 6| Step: 11
Training loss: 0.34893981922437306
Validation loss: 2.5335370787035365

Epoch: 6| Step: 12
Training loss: 0.28320144126654656
Validation loss: 2.563052420268733

Epoch: 6| Step: 13
Training loss: 0.20548580156941626
Validation loss: 2.5235846036662952

Epoch: 306| Step: 0
Training loss: 0.34519138283439116
Validation loss: 2.5172999237926126

Epoch: 6| Step: 1
Training loss: 0.34435796077619096
Validation loss: 2.539975406172225

Epoch: 6| Step: 2
Training loss: 0.33857516587628017
Validation loss: 2.5368063268257997

Epoch: 6| Step: 3
Training loss: 0.3398167500787039
Validation loss: 2.5875057908391113

Epoch: 6| Step: 4
Training loss: 0.3570774482537356
Validation loss: 2.6110586342599778

Epoch: 6| Step: 5
Training loss: 0.3178228760697467
Validation loss: 2.5877993393638485

Epoch: 6| Step: 6
Training loss: 0.32059261820309193
Validation loss: 2.6116206543339633

Epoch: 6| Step: 7
Training loss: 0.3263423953635967
Validation loss: 2.5786967789814255

Epoch: 6| Step: 8
Training loss: 0.1740987471330832
Validation loss: 2.591911476282712

Epoch: 6| Step: 9
Training loss: 0.19091580284821819
Validation loss: 2.541892859811463

Epoch: 6| Step: 10
Training loss: 0.3132661725456677
Validation loss: 2.5221287391323433

Epoch: 6| Step: 11
Training loss: 0.31344366643740645
Validation loss: 2.560000091840822

Epoch: 6| Step: 12
Training loss: 0.432338581833247
Validation loss: 2.5392999626037382

Epoch: 6| Step: 13
Training loss: 0.425877061615509
Validation loss: 2.5829057621642355

Epoch: 307| Step: 0
Training loss: 0.32400928763040754
Validation loss: 2.575332045827918

Epoch: 6| Step: 1
Training loss: 0.2818675942727422
Validation loss: 2.5866807866284627

Epoch: 6| Step: 2
Training loss: 0.4297642032479806
Validation loss: 2.5483626407096494

Epoch: 6| Step: 3
Training loss: 0.2798160049980701
Validation loss: 2.5304406524414196

Epoch: 6| Step: 4
Training loss: 0.293732068346448
Validation loss: 2.564516320942519

Epoch: 6| Step: 5
Training loss: 0.2709662618627335
Validation loss: 2.472643763313283

Epoch: 6| Step: 6
Training loss: 0.33786144020300773
Validation loss: 2.5491599382168513

Epoch: 6| Step: 7
Training loss: 0.33180316496029966
Validation loss: 2.5661539140474314

Epoch: 6| Step: 8
Training loss: 0.1832084061241685
Validation loss: 2.410657635785097

Epoch: 6| Step: 9
Training loss: 0.378372228996028
Validation loss: 2.5332395481852856

Epoch: 6| Step: 10
Training loss: 0.2370956819153162
Validation loss: 2.504792404278342

Epoch: 6| Step: 11
Training loss: 0.2929430123785757
Validation loss: 2.4826494898417844

Epoch: 6| Step: 12
Training loss: 0.3247017307852742
Validation loss: 2.525407004838

Epoch: 6| Step: 13
Training loss: 0.21031356298282886
Validation loss: 2.496015313656813

Epoch: 308| Step: 0
Training loss: 0.2438846390514001
Validation loss: 2.5490008494192518

Epoch: 6| Step: 1
Training loss: 0.25658639599082256
Validation loss: 2.541684046409679

Epoch: 6| Step: 2
Training loss: 0.2770932100204071
Validation loss: 2.5572038675581807

Epoch: 6| Step: 3
Training loss: 0.2760351903023723
Validation loss: 2.4798131682151654

Epoch: 6| Step: 4
Training loss: 0.34390099417012265
Validation loss: 2.4920839708722125

Epoch: 6| Step: 5
Training loss: 0.2892908534639681
Validation loss: 2.520325725195143

Epoch: 6| Step: 6
Training loss: 0.27138719260115024
Validation loss: 2.4981796631007236

Epoch: 6| Step: 7
Training loss: 0.2762188058174009
Validation loss: 2.5085573684618736

Epoch: 6| Step: 8
Training loss: 0.40063558388951326
Validation loss: 2.5638086342457465

Epoch: 6| Step: 9
Training loss: 0.43168130743330146
Validation loss: 2.586075870311591

Epoch: 6| Step: 10
Training loss: 0.4093706873309855
Validation loss: 2.5819580791068466

Epoch: 6| Step: 11
Training loss: 0.4381024606269901
Validation loss: 2.5798935498103144

Epoch: 6| Step: 12
Training loss: 0.4403434381384392
Validation loss: 2.5949866629069755

Epoch: 6| Step: 13
Training loss: 0.26026159278726535
Validation loss: 2.5733860272446294

Epoch: 309| Step: 0
Training loss: 0.38463729809727265
Validation loss: 2.5105872406263474

Epoch: 6| Step: 1
Training loss: 0.3099977929282838
Validation loss: 2.5005904771931995

Epoch: 6| Step: 2
Training loss: 0.40595777712036063
Validation loss: 2.475359467048507

Epoch: 6| Step: 3
Training loss: 0.23247421701071536
Validation loss: 2.450221349811731

Epoch: 6| Step: 4
Training loss: 0.26158417615322294
Validation loss: 2.548616434126956

Epoch: 6| Step: 5
Training loss: 0.32657161362264864
Validation loss: 2.5956419666549277

Epoch: 6| Step: 6
Training loss: 0.2478290712990157
Validation loss: 2.5912706022398924

Epoch: 6| Step: 7
Training loss: 0.37181531122568096
Validation loss: 2.6525415151105496

Epoch: 6| Step: 8
Training loss: 0.4407192386466794
Validation loss: 2.597706454372703

Epoch: 6| Step: 9
Training loss: 0.2529150174279359
Validation loss: 2.577410851412866

Epoch: 6| Step: 10
Training loss: 0.43948960894559813
Validation loss: 2.5533412609857074

Epoch: 6| Step: 11
Training loss: 0.3473317743039577
Validation loss: 2.5235167846192033

Epoch: 6| Step: 12
Training loss: 0.42035062326312694
Validation loss: 2.4808336925623795

Epoch: 6| Step: 13
Training loss: 0.13397435075723943
Validation loss: 2.5276788394089387

Epoch: 310| Step: 0
Training loss: 0.2947505933546932
Validation loss: 2.574939378006288

Epoch: 6| Step: 1
Training loss: 0.2772237759993395
Validation loss: 2.574423419570829

Epoch: 6| Step: 2
Training loss: 0.31933398931533147
Validation loss: 2.543359416871248

Epoch: 6| Step: 3
Training loss: 0.28287126236257154
Validation loss: 2.565793115619266

Epoch: 6| Step: 4
Training loss: 0.25179711768233026
Validation loss: 2.5821475312042996

Epoch: 6| Step: 5
Training loss: 0.2320926562527851
Validation loss: 2.5598370974461893

Epoch: 6| Step: 6
Training loss: 0.2568989955526088
Validation loss: 2.469991267287947

Epoch: 6| Step: 7
Training loss: 0.42450638744235036
Validation loss: 2.4475319715651516

Epoch: 6| Step: 8
Training loss: 0.4306089058845833
Validation loss: 2.499875852363335

Epoch: 6| Step: 9
Training loss: 0.2885872439367256
Validation loss: 2.5444558947341163

Epoch: 6| Step: 10
Training loss: 0.5109979634570991
Validation loss: 2.5278517670917444

Epoch: 6| Step: 11
Training loss: 0.3130964309542572
Validation loss: 2.576699180517149

Epoch: 6| Step: 12
Training loss: 0.27040651814226924
Validation loss: 2.5510723576867917

Epoch: 6| Step: 13
Training loss: 0.23082054089108664
Validation loss: 2.5663063033725524

Epoch: 311| Step: 0
Training loss: 0.42990555865551144
Validation loss: 2.5560963174873237

Epoch: 6| Step: 1
Training loss: 0.3896448044380479
Validation loss: 2.540227174912468

Epoch: 6| Step: 2
Training loss: 0.2272102534248383
Validation loss: 2.4688179554016645

Epoch: 6| Step: 3
Training loss: 0.30674362882357076
Validation loss: 2.5124663194135435

Epoch: 6| Step: 4
Training loss: 0.35497425603873917
Validation loss: 2.508902909846285

Epoch: 6| Step: 5
Training loss: 0.25162009474326463
Validation loss: 2.5588166040331544

Epoch: 6| Step: 6
Training loss: 0.27138019181920664
Validation loss: 2.533788052225957

Epoch: 6| Step: 7
Training loss: 0.2758317890272867
Validation loss: 2.5066703183911825

Epoch: 6| Step: 8
Training loss: 0.30106715448625154
Validation loss: 2.5542331489842733

Epoch: 6| Step: 9
Training loss: 0.2300412690932446
Validation loss: 2.5259164104016234

Epoch: 6| Step: 10
Training loss: 0.4226591628392057
Validation loss: 2.584559739139584

Epoch: 6| Step: 11
Training loss: 0.18005974193752697
Validation loss: 2.547548848508345

Epoch: 6| Step: 12
Training loss: 0.31706424864774235
Validation loss: 2.500776392860387

Epoch: 6| Step: 13
Training loss: 0.356060206736163
Validation loss: 2.523892293756974

Epoch: 312| Step: 0
Training loss: 0.26768307820296827
Validation loss: 2.4827140518109387

Epoch: 6| Step: 1
Training loss: 0.2270456457069999
Validation loss: 2.49009157257523

Epoch: 6| Step: 2
Training loss: 0.3071839930585455
Validation loss: 2.5356430581628047

Epoch: 6| Step: 3
Training loss: 0.26070378052809406
Validation loss: 2.584910316485639

Epoch: 6| Step: 4
Training loss: 0.22881809822169533
Validation loss: 2.5635173762871997

Epoch: 6| Step: 5
Training loss: 0.30264615650115545
Validation loss: 2.5181353662346435

Epoch: 6| Step: 6
Training loss: 0.44111127196321565
Validation loss: 2.5302645095320226

Epoch: 6| Step: 7
Training loss: 0.17781974502847678
Validation loss: 2.5624134933012197

Epoch: 6| Step: 8
Training loss: 0.2858643688423553
Validation loss: 2.5577349126502127

Epoch: 6| Step: 9
Training loss: 0.19199747134570108
Validation loss: 2.547096164828512

Epoch: 6| Step: 10
Training loss: 0.4814506205484755
Validation loss: 2.5358725281902963

Epoch: 6| Step: 11
Training loss: 0.22731235982215636
Validation loss: 2.5498351620397184

Epoch: 6| Step: 12
Training loss: 0.4096127314832942
Validation loss: 2.540611006169179

Epoch: 6| Step: 13
Training loss: 0.27165883448393924
Validation loss: 2.6392138169556283

Epoch: 313| Step: 0
Training loss: 0.3903947914791321
Validation loss: 2.6289884149144505

Epoch: 6| Step: 1
Training loss: 0.31312277250582643
Validation loss: 2.5919571544050464

Epoch: 6| Step: 2
Training loss: 0.26558180065049913
Validation loss: 2.587940112906345

Epoch: 6| Step: 3
Training loss: 0.4727870035199008
Validation loss: 2.6055623370839

Epoch: 6| Step: 4
Training loss: 0.5255630380439703
Validation loss: 2.54867946926909

Epoch: 6| Step: 5
Training loss: 0.3103686727100864
Validation loss: 2.5753586232346444

Epoch: 6| Step: 6
Training loss: 0.33363424318929363
Validation loss: 2.484552676966905

Epoch: 6| Step: 7
Training loss: 0.2989984911797643
Validation loss: 2.549175385926536

Epoch: 6| Step: 8
Training loss: 0.2774723319058642
Validation loss: 2.5853339160235205

Epoch: 6| Step: 9
Training loss: 0.36527778245146686
Validation loss: 2.518875596643747

Epoch: 6| Step: 10
Training loss: 0.31140440577120265
Validation loss: 2.5349538337295847

Epoch: 6| Step: 11
Training loss: 0.41371536098359685
Validation loss: 2.5663150827287646

Epoch: 6| Step: 12
Training loss: 0.3481405720746454
Validation loss: 2.5770329792486657

Epoch: 6| Step: 13
Training loss: 0.2909469651506943
Validation loss: 2.567121896584663

Epoch: 314| Step: 0
Training loss: 0.412065548848914
Validation loss: 2.621830540591921

Epoch: 6| Step: 1
Training loss: 0.31203853390462816
Validation loss: 2.558747179706599

Epoch: 6| Step: 2
Training loss: 0.3130526781412979
Validation loss: 2.5600424278612746

Epoch: 6| Step: 3
Training loss: 0.2731774455899339
Validation loss: 2.5298191547594184

Epoch: 6| Step: 4
Training loss: 0.2746887325697533
Validation loss: 2.559804848146769

Epoch: 6| Step: 5
Training loss: 0.47373058450414735
Validation loss: 2.6010284486637705

Epoch: 6| Step: 6
Training loss: 0.3854022109267675
Validation loss: 2.63306808363082

Epoch: 6| Step: 7
Training loss: 0.4186484078395122
Validation loss: 2.614614559964848

Epoch: 6| Step: 8
Training loss: 0.35372665597839553
Validation loss: 2.629637240108806

Epoch: 6| Step: 9
Training loss: 0.2908055103805743
Validation loss: 2.66711896299157

Epoch: 6| Step: 10
Training loss: 0.26721266689342615
Validation loss: 2.605783865735329

Epoch: 6| Step: 11
Training loss: 0.2639892081399368
Validation loss: 2.5691290298098948

Epoch: 6| Step: 12
Training loss: 0.2211369664311313
Validation loss: 2.5586232268598623

Epoch: 6| Step: 13
Training loss: 0.4086653725047153
Validation loss: 2.503291561952413

Epoch: 315| Step: 0
Training loss: 0.25115605626342635
Validation loss: 2.4693563899616082

Epoch: 6| Step: 1
Training loss: 0.3740977121413713
Validation loss: 2.5551459924677085

Epoch: 6| Step: 2
Training loss: 0.26852895440010816
Validation loss: 2.5091143088282046

Epoch: 6| Step: 3
Training loss: 0.2659326762917319
Validation loss: 2.5643276969333346

Epoch: 6| Step: 4
Training loss: 0.30884042369421916
Validation loss: 2.5635866481818805

Epoch: 6| Step: 5
Training loss: 0.46151099654391115
Validation loss: 2.56100329442019

Epoch: 6| Step: 6
Training loss: 0.3453495135255698
Validation loss: 2.571168078840814

Epoch: 6| Step: 7
Training loss: 0.2642631682468549
Validation loss: 2.5009996243562638

Epoch: 6| Step: 8
Training loss: 0.3523185547576887
Validation loss: 2.506844940981754

Epoch: 6| Step: 9
Training loss: 0.38035199529962677
Validation loss: 2.5409091279145697

Epoch: 6| Step: 10
Training loss: 0.30273564246127693
Validation loss: 2.5691886462363263

Epoch: 6| Step: 11
Training loss: 0.3737332884455625
Validation loss: 2.5591590237500776

Epoch: 6| Step: 12
Training loss: 0.32418376090366535
Validation loss: 2.5563738562090936

Epoch: 6| Step: 13
Training loss: 0.24001501504549755
Validation loss: 2.5804533953839774

Epoch: 316| Step: 0
Training loss: 0.37299636179272094
Validation loss: 2.566269188196163

Epoch: 6| Step: 1
Training loss: 0.20467616151752926
Validation loss: 2.5236590025444516

Epoch: 6| Step: 2
Training loss: 0.1962878668449767
Validation loss: 2.552690617975085

Epoch: 6| Step: 3
Training loss: 0.26644525382266804
Validation loss: 2.5784908767172885

Epoch: 6| Step: 4
Training loss: 0.24811216681513434
Validation loss: 2.4582469623285297

Epoch: 6| Step: 5
Training loss: 0.2967324039919441
Validation loss: 2.5608349562156825

Epoch: 6| Step: 6
Training loss: 0.3904322530138341
Validation loss: 2.51415359714522

Epoch: 6| Step: 7
Training loss: 0.21707688540463968
Validation loss: 2.518309619858399

Epoch: 6| Step: 8
Training loss: 0.31255999227691367
Validation loss: 2.5629007444805505

Epoch: 6| Step: 9
Training loss: 0.4139859110696993
Validation loss: 2.5809854533521976

Epoch: 6| Step: 10
Training loss: 0.28760921021133107
Validation loss: 2.542300134940797

Epoch: 6| Step: 11
Training loss: 0.2966219425823505
Validation loss: 2.52030954094729

Epoch: 6| Step: 12
Training loss: 0.27623009398534154
Validation loss: 2.567980952360096

Epoch: 6| Step: 13
Training loss: 0.30944795326354857
Validation loss: 2.533610126678867

Epoch: 317| Step: 0
Training loss: 0.26639660792646985
Validation loss: 2.50926089029336

Epoch: 6| Step: 1
Training loss: 0.14807388039229577
Validation loss: 2.5239721623471008

Epoch: 6| Step: 2
Training loss: 0.28945008918518994
Validation loss: 2.5382813332838374

Epoch: 6| Step: 3
Training loss: 0.24157967742012532
Validation loss: 2.6009883762614674

Epoch: 6| Step: 4
Training loss: 0.22731290063935478
Validation loss: 2.5843706560694186

Epoch: 6| Step: 5
Training loss: 0.3858638137095574
Validation loss: 2.546833701081673

Epoch: 6| Step: 6
Training loss: 0.3095507931497179
Validation loss: 2.5173878860511296

Epoch: 6| Step: 7
Training loss: 0.230352598760149
Validation loss: 2.503954557130379

Epoch: 6| Step: 8
Training loss: 0.2718727983188272
Validation loss: 2.4956546530556913

Epoch: 6| Step: 9
Training loss: 0.45180566042030346
Validation loss: 2.550834822664155

Epoch: 6| Step: 10
Training loss: 0.4139656817406814
Validation loss: 2.4651878668876517

Epoch: 6| Step: 11
Training loss: 0.3612934817640777
Validation loss: 2.481071835390331

Epoch: 6| Step: 12
Training loss: 0.35562356784310944
Validation loss: 2.561316100385097

Epoch: 6| Step: 13
Training loss: 0.34579328665143383
Validation loss: 2.5771056038324165

Epoch: 318| Step: 0
Training loss: 0.27805185588460135
Validation loss: 2.581761448509444

Epoch: 6| Step: 1
Training loss: 0.2898542541081168
Validation loss: 2.5702811396733134

Epoch: 6| Step: 2
Training loss: 0.3794931212456446
Validation loss: 2.56204112526601

Epoch: 6| Step: 3
Training loss: 0.38119929867666924
Validation loss: 2.5670671313673936

Epoch: 6| Step: 4
Training loss: 0.35377278116422795
Validation loss: 2.567098616092387

Epoch: 6| Step: 5
Training loss: 0.2862601533904778
Validation loss: 2.537728468783733

Epoch: 6| Step: 6
Training loss: 0.39771792939593675
Validation loss: 2.6016204567869585

Epoch: 6| Step: 7
Training loss: 0.43880151546754703
Validation loss: 2.5488359200271926

Epoch: 6| Step: 8
Training loss: 0.24448440761228285
Validation loss: 2.650383548450698

Epoch: 6| Step: 9
Training loss: 0.4116829206884644
Validation loss: 2.6141954466095174

Epoch: 6| Step: 10
Training loss: 0.18146031156535347
Validation loss: 2.591206985339887

Epoch: 6| Step: 11
Training loss: 0.36215601747225395
Validation loss: 2.5348086988308967

Epoch: 6| Step: 12
Training loss: 0.20162260615742264
Validation loss: 2.529048936000613

Epoch: 6| Step: 13
Training loss: 0.29172576436138714
Validation loss: 2.550527952429789

Epoch: 319| Step: 0
Training loss: 0.2600804335863274
Validation loss: 2.5548345929806175

Epoch: 6| Step: 1
Training loss: 0.2921744450799303
Validation loss: 2.5650502207290726

Epoch: 6| Step: 2
Training loss: 0.25702592038365585
Validation loss: 2.577618620492756

Epoch: 6| Step: 3
Training loss: 0.19517146740691335
Validation loss: 2.5559015607065856

Epoch: 6| Step: 4
Training loss: 0.37728825431571134
Validation loss: 2.5063606250476216

Epoch: 6| Step: 5
Training loss: 0.2776089864077446
Validation loss: 2.5349178819316016

Epoch: 6| Step: 6
Training loss: 0.27537109089283257
Validation loss: 2.5543479343788342

Epoch: 6| Step: 7
Training loss: 0.41610872543265354
Validation loss: 2.579529212240553

Epoch: 6| Step: 8
Training loss: 0.2814425365726721
Validation loss: 2.5226557793355426

Epoch: 6| Step: 9
Training loss: 0.4689730431469562
Validation loss: 2.575671853374704

Epoch: 6| Step: 10
Training loss: 0.26006133951534655
Validation loss: 2.500551456983503

Epoch: 6| Step: 11
Training loss: 0.49677686141965355
Validation loss: 2.5171973012192312

Epoch: 6| Step: 12
Training loss: 0.219016066594375
Validation loss: 2.503466237684608

Epoch: 6| Step: 13
Training loss: 0.2715245772859054
Validation loss: 2.496082574523838

Epoch: 320| Step: 0
Training loss: 0.3463785072129826
Validation loss: 2.554915904995887

Epoch: 6| Step: 1
Training loss: 0.276282024404465
Validation loss: 2.5265190905583212

Epoch: 6| Step: 2
Training loss: 0.26628523004747373
Validation loss: 2.5131041965921708

Epoch: 6| Step: 3
Training loss: 0.18317843191478192
Validation loss: 2.532968777434633

Epoch: 6| Step: 4
Training loss: 0.5218327819285632
Validation loss: 2.594395093859177

Epoch: 6| Step: 5
Training loss: 0.438635000987279
Validation loss: 2.5517140387289023

Epoch: 6| Step: 6
Training loss: 0.31947106818270704
Validation loss: 2.4929248432567497

Epoch: 6| Step: 7
Training loss: 0.5421398064911459
Validation loss: 2.5689499170082315

Epoch: 6| Step: 8
Training loss: 0.3449330994452669
Validation loss: 2.5708721289858016

Epoch: 6| Step: 9
Training loss: 0.4663695610095263
Validation loss: 2.528702478268706

Epoch: 6| Step: 10
Training loss: 0.21616742110549647
Validation loss: 2.543374727953032

Epoch: 6| Step: 11
Training loss: 0.2353068740648396
Validation loss: 2.5743284380576994

Epoch: 6| Step: 12
Training loss: 0.29701021528336974
Validation loss: 2.571562149221511

Epoch: 6| Step: 13
Training loss: 0.3156019750071567
Validation loss: 2.6099070845979124

Epoch: 321| Step: 0
Training loss: 0.3284694589297462
Validation loss: 2.6408100326688224

Epoch: 6| Step: 1
Training loss: 0.3743757177546631
Validation loss: 2.5656329595865923

Epoch: 6| Step: 2
Training loss: 0.38408298254683315
Validation loss: 2.5936206953917003

Epoch: 6| Step: 3
Training loss: 0.3498327511297479
Validation loss: 2.582138128564617

Epoch: 6| Step: 4
Training loss: 0.30174408421568333
Validation loss: 2.50145601152753

Epoch: 6| Step: 5
Training loss: 0.2976913146143592
Validation loss: 2.541409351789863

Epoch: 6| Step: 6
Training loss: 0.31129693673210834
Validation loss: 2.5299194276743253

Epoch: 6| Step: 7
Training loss: 0.2948834728981958
Validation loss: 2.514634705539974

Epoch: 6| Step: 8
Training loss: 0.18179671441215764
Validation loss: 2.489478764805247

Epoch: 6| Step: 9
Training loss: 0.23601800101030324
Validation loss: 2.503863385369699

Epoch: 6| Step: 10
Training loss: 0.3898779783340002
Validation loss: 2.524719841525621

Epoch: 6| Step: 11
Training loss: 0.28805209462149683
Validation loss: 2.497525786889452

Epoch: 6| Step: 12
Training loss: 0.27143107378136017
Validation loss: 2.4899187274420753

Epoch: 6| Step: 13
Training loss: 0.3035170620131872
Validation loss: 2.5555950423198492

Epoch: 322| Step: 0
Training loss: 0.287637186491029
Validation loss: 2.5171248267351576

Epoch: 6| Step: 1
Training loss: 0.30110943217433117
Validation loss: 2.6135075142854984

Epoch: 6| Step: 2
Training loss: 0.2946741946180831
Validation loss: 2.5810773571614685

Epoch: 6| Step: 3
Training loss: 0.3441498230171497
Validation loss: 2.562470133537602

Epoch: 6| Step: 4
Training loss: 0.30021806728713857
Validation loss: 2.5105557436163437

Epoch: 6| Step: 5
Training loss: 0.35822605904113736
Validation loss: 2.4831808487162657

Epoch: 6| Step: 6
Training loss: 0.378389261448915
Validation loss: 2.498033624434454

Epoch: 6| Step: 7
Training loss: 0.23277209046433867
Validation loss: 2.5393565472260926

Epoch: 6| Step: 8
Training loss: 0.20086906383030187
Validation loss: 2.5148142738348986

Epoch: 6| Step: 9
Training loss: 0.19660559795807636
Validation loss: 2.565681808158711

Epoch: 6| Step: 10
Training loss: 0.3310554414363592
Validation loss: 2.582673093553259

Epoch: 6| Step: 11
Training loss: 0.3999684969596262
Validation loss: 2.5706856562046942

Epoch: 6| Step: 12
Training loss: 0.3983384177483324
Validation loss: 2.593569262844953

Epoch: 6| Step: 13
Training loss: 0.31028751122854575
Validation loss: 2.5466934326606068

Epoch: 323| Step: 0
Training loss: 0.20453521982570372
Validation loss: 2.5306718032489672

Epoch: 6| Step: 1
Training loss: 0.4028534484718524
Validation loss: 2.5090795467341

Epoch: 6| Step: 2
Training loss: 0.3736587220305034
Validation loss: 2.522494806310161

Epoch: 6| Step: 3
Training loss: 0.3897243416264001
Validation loss: 2.5132899059604705

Epoch: 6| Step: 4
Training loss: 0.30840616923153447
Validation loss: 2.52208050438469

Epoch: 6| Step: 5
Training loss: 0.35126508212035923
Validation loss: 2.610366587197805

Epoch: 6| Step: 6
Training loss: 0.31680736312720326
Validation loss: 2.5821823714561334

Epoch: 6| Step: 7
Training loss: 0.3067729445785816
Validation loss: 2.6126491388464794

Epoch: 6| Step: 8
Training loss: 0.3541192439062897
Validation loss: 2.5923989388887745

Epoch: 6| Step: 9
Training loss: 0.2894148869553566
Validation loss: 2.569381406085232

Epoch: 6| Step: 10
Training loss: 0.30713079843105023
Validation loss: 2.497093482041185

Epoch: 6| Step: 11
Training loss: 0.2278796336335377
Validation loss: 2.534601355563905

Epoch: 6| Step: 12
Training loss: 0.34836897496959585
Validation loss: 2.5416160849452383

Epoch: 6| Step: 13
Training loss: 0.3222754274669212
Validation loss: 2.5326594757348855

Epoch: 324| Step: 0
Training loss: 0.29252807535430003
Validation loss: 2.5497191137308355

Epoch: 6| Step: 1
Training loss: 0.3245735754660971
Validation loss: 2.5697413837124996

Epoch: 6| Step: 2
Training loss: 0.31035725784597507
Validation loss: 2.584314934041345

Epoch: 6| Step: 3
Training loss: 0.3036908452787327
Validation loss: 2.5722945512686586

Epoch: 6| Step: 4
Training loss: 0.2865589860889974
Validation loss: 2.5124906992067984

Epoch: 6| Step: 5
Training loss: 0.32500802910496923
Validation loss: 2.5682106584201674

Epoch: 6| Step: 6
Training loss: 0.1488732980271333
Validation loss: 2.5038483960653495

Epoch: 6| Step: 7
Training loss: 0.3752323463983957
Validation loss: 2.557187318453409

Epoch: 6| Step: 8
Training loss: 0.2552988741634332
Validation loss: 2.495532399048696

Epoch: 6| Step: 9
Training loss: 0.20642776522953937
Validation loss: 2.5245777148406545

Epoch: 6| Step: 10
Training loss: 0.23520629008216304
Validation loss: 2.5188196089018193

Epoch: 6| Step: 11
Training loss: 0.1557618443120851
Validation loss: 2.546635099630623

Epoch: 6| Step: 12
Training loss: 0.3412185681193503
Validation loss: 2.6013439036988317

Epoch: 6| Step: 13
Training loss: 0.3474767092748569
Validation loss: 2.5657260947651577

Epoch: 325| Step: 0
Training loss: 0.25799302803089535
Validation loss: 2.5467190919051994

Epoch: 6| Step: 1
Training loss: 0.3926488897967336
Validation loss: 2.520391580531762

Epoch: 6| Step: 2
Training loss: 0.36375277691859365
Validation loss: 2.523759882345339

Epoch: 6| Step: 3
Training loss: 0.23585003974941307
Validation loss: 2.4891389239995556

Epoch: 6| Step: 4
Training loss: 0.20559851606312188
Validation loss: 2.514175487102866

Epoch: 6| Step: 5
Training loss: 0.24280596029589402
Validation loss: 2.52682368702336

Epoch: 6| Step: 6
Training loss: 0.2213481659169339
Validation loss: 2.544432625495562

Epoch: 6| Step: 7
Training loss: 0.30993234061400604
Validation loss: 2.4929555508654584

Epoch: 6| Step: 8
Training loss: 0.20347370880229088
Validation loss: 2.53005236483526

Epoch: 6| Step: 9
Training loss: 0.27410863529347534
Validation loss: 2.571778255356501

Epoch: 6| Step: 10
Training loss: 0.25106067954807215
Validation loss: 2.534094417168892

Epoch: 6| Step: 11
Training loss: 0.18840250724685256
Validation loss: 2.503513283524351

Epoch: 6| Step: 12
Training loss: 0.2866827721331704
Validation loss: 2.5268503814990053

Epoch: 6| Step: 13
Training loss: 0.3304590138112631
Validation loss: 2.48216190572593

Epoch: 326| Step: 0
Training loss: 0.3053946480787348
Validation loss: 2.5510170609977716

Epoch: 6| Step: 1
Training loss: 0.19729166519973362
Validation loss: 2.47193764061856

Epoch: 6| Step: 2
Training loss: 0.24545714372165195
Validation loss: 2.5226350025941264

Epoch: 6| Step: 3
Training loss: 0.30363143174625423
Validation loss: 2.467385329339324

Epoch: 6| Step: 4
Training loss: 0.28367340240865757
Validation loss: 2.5117602307823286

Epoch: 6| Step: 5
Training loss: 0.20787430002079763
Validation loss: 2.562411376537111

Epoch: 6| Step: 6
Training loss: 0.3141584970835379
Validation loss: 2.5505974368919837

Epoch: 6| Step: 7
Training loss: 0.31054344415269003
Validation loss: 2.5044574021854453

Epoch: 6| Step: 8
Training loss: 0.30714023490353526
Validation loss: 2.6059975990519537

Epoch: 6| Step: 9
Training loss: 0.22907304025263647
Validation loss: 2.544351876463858

Epoch: 6| Step: 10
Training loss: 0.20648049927161724
Validation loss: 2.5051761448008985

Epoch: 6| Step: 11
Training loss: 0.26200645916380516
Validation loss: 2.5436158965782076

Epoch: 6| Step: 12
Training loss: 0.4530416938234184
Validation loss: 2.473206935345051

Epoch: 6| Step: 13
Training loss: 0.2926477708418137
Validation loss: 2.5081070898262423

Epoch: 327| Step: 0
Training loss: 0.28057600430496893
Validation loss: 2.554490092482997

Epoch: 6| Step: 1
Training loss: 0.3480986555565293
Validation loss: 2.554459494585647

Epoch: 6| Step: 2
Training loss: 0.27679396926857763
Validation loss: 2.524706006953974

Epoch: 6| Step: 3
Training loss: 0.38635830505793134
Validation loss: 2.562137849539685

Epoch: 6| Step: 4
Training loss: 0.23825767275372758
Validation loss: 2.5225045730453592

Epoch: 6| Step: 5
Training loss: 0.22750090414171495
Validation loss: 2.5501975014191163

Epoch: 6| Step: 6
Training loss: 0.25324178462339947
Validation loss: 2.4857558325710247

Epoch: 6| Step: 7
Training loss: 0.3225676652797438
Validation loss: 2.5402836684899164

Epoch: 6| Step: 8
Training loss: 0.17515071526663675
Validation loss: 2.4826523188395964

Epoch: 6| Step: 9
Training loss: 0.22805874953370733
Validation loss: 2.5339962931517817

Epoch: 6| Step: 10
Training loss: 0.235436443993327
Validation loss: 2.5611290404473004

Epoch: 6| Step: 11
Training loss: 0.4069614050277863
Validation loss: 2.570195204078807

Epoch: 6| Step: 12
Training loss: 0.3418397604059752
Validation loss: 2.538389232088464

Epoch: 6| Step: 13
Training loss: 0.3338265073787493
Validation loss: 2.511249077105127

Epoch: 328| Step: 0
Training loss: 0.1667224311422216
Validation loss: 2.542990649744791

Epoch: 6| Step: 1
Training loss: 0.436178783927094
Validation loss: 2.5559519400458646

Epoch: 6| Step: 2
Training loss: 0.29590468195504693
Validation loss: 2.501549081887502

Epoch: 6| Step: 3
Training loss: 0.19204720400595143
Validation loss: 2.5323410194658265

Epoch: 6| Step: 4
Training loss: 0.3202324511360177
Validation loss: 2.53550039188144

Epoch: 6| Step: 5
Training loss: 0.30617585160383143
Validation loss: 2.514848782851433

Epoch: 6| Step: 6
Training loss: 0.3827054788894539
Validation loss: 2.5541023883126406

Epoch: 6| Step: 7
Training loss: 0.29591555907818234
Validation loss: 2.5336437680332575

Epoch: 6| Step: 8
Training loss: 0.35125872945628717
Validation loss: 2.6161823525076904

Epoch: 6| Step: 9
Training loss: 0.36934256706561547
Validation loss: 2.5736278498279614

Epoch: 6| Step: 10
Training loss: 0.4067645482331961
Validation loss: 2.55034189300869

Epoch: 6| Step: 11
Training loss: 0.20741627536550047
Validation loss: 2.53973921927691

Epoch: 6| Step: 12
Training loss: 0.284169842526559
Validation loss: 2.4731208481302698

Epoch: 6| Step: 13
Training loss: 0.3981459055491596
Validation loss: 2.4950796663233934

Epoch: 329| Step: 0
Training loss: 0.45003630836027503
Validation loss: 2.5027029842962154

Epoch: 6| Step: 1
Training loss: 0.35268074844647285
Validation loss: 2.486346927720557

Epoch: 6| Step: 2
Training loss: 0.366069613844331
Validation loss: 2.4874953980778693

Epoch: 6| Step: 3
Training loss: 0.29285554606097064
Validation loss: 2.559632511249171

Epoch: 6| Step: 4
Training loss: 0.39549358954581526
Validation loss: 2.5772173969756027

Epoch: 6| Step: 5
Training loss: 0.21765271933622862
Validation loss: 2.5531298976245784

Epoch: 6| Step: 6
Training loss: 0.32343864809283984
Validation loss: 2.5478912931370874

Epoch: 6| Step: 7
Training loss: 0.20506040405730044
Validation loss: 2.5058615871071805

Epoch: 6| Step: 8
Training loss: 0.20420106716404895
Validation loss: 2.5305723845304615

Epoch: 6| Step: 9
Training loss: 0.29058375732490127
Validation loss: 2.4912303812645678

Epoch: 6| Step: 10
Training loss: 0.23294598125946822
Validation loss: 2.5305495215198737

Epoch: 6| Step: 11
Training loss: 0.34536799118753064
Validation loss: 2.5461220593676828

Epoch: 6| Step: 12
Training loss: 0.18354413193971367
Validation loss: 2.563947788100191

Epoch: 6| Step: 13
Training loss: 0.36504403932953683
Validation loss: 2.5805636422471205

Epoch: 330| Step: 0
Training loss: 0.3358685844172103
Validation loss: 2.5915504574148027

Epoch: 6| Step: 1
Training loss: 0.3513017429136187
Validation loss: 2.5172409332937504

Epoch: 6| Step: 2
Training loss: 0.41529348316958226
Validation loss: 2.5387239670651334

Epoch: 6| Step: 3
Training loss: 0.2661755690165758
Validation loss: 2.5928257900395666

Epoch: 6| Step: 4
Training loss: 0.24634080172464198
Validation loss: 2.529528130327075

Epoch: 6| Step: 5
Training loss: 0.39829023294955357
Validation loss: 2.555636572820567

Epoch: 6| Step: 6
Training loss: 0.2524046290039666
Validation loss: 2.5449070728776166

Epoch: 6| Step: 7
Training loss: 0.3604028763457286
Validation loss: 2.5929808261303173

Epoch: 6| Step: 8
Training loss: 0.36173769446047804
Validation loss: 2.5431979730898595

Epoch: 6| Step: 9
Training loss: 0.300437867476459
Validation loss: 2.566086887131404

Epoch: 6| Step: 10
Training loss: 0.3063131272201172
Validation loss: 2.5099337391637198

Epoch: 6| Step: 11
Training loss: 0.19194627991062663
Validation loss: 2.5390240397352555

Epoch: 6| Step: 12
Training loss: 0.44285507762005477
Validation loss: 2.4657428631091842

Epoch: 6| Step: 13
Training loss: 0.2685147342439582
Validation loss: 2.5113716815148535

Epoch: 331| Step: 0
Training loss: 0.3675825955872075
Validation loss: 2.515979654968759

Epoch: 6| Step: 1
Training loss: 0.20898697753426593
Validation loss: 2.5122532649059974

Epoch: 6| Step: 2
Training loss: 0.378490495192038
Validation loss: 2.5298781425420995

Epoch: 6| Step: 3
Training loss: 0.305134164642855
Validation loss: 2.5302446433160974

Epoch: 6| Step: 4
Training loss: 0.254785716537614
Validation loss: 2.5387846418102415

Epoch: 6| Step: 5
Training loss: 0.4166509585598533
Validation loss: 2.543007642816741

Epoch: 6| Step: 6
Training loss: 0.4045505372919973
Validation loss: 2.4944834561921123

Epoch: 6| Step: 7
Training loss: 0.2279478992551114
Validation loss: 2.5584056367711456

Epoch: 6| Step: 8
Training loss: 0.275858461415764
Validation loss: 2.572496083796924

Epoch: 6| Step: 9
Training loss: 0.32425182817233433
Validation loss: 2.57490532710282

Epoch: 6| Step: 10
Training loss: 0.3152263446527168
Validation loss: 2.575545768244234

Epoch: 6| Step: 11
Training loss: 0.2569178171508433
Validation loss: 2.583803892860814

Epoch: 6| Step: 12
Training loss: 0.2196549023228569
Validation loss: 2.556379840665376

Epoch: 6| Step: 13
Training loss: 0.3430994879509194
Validation loss: 2.5331092568062115

Epoch: 332| Step: 0
Training loss: 0.2983376710503562
Validation loss: 2.4324736162919636

Epoch: 6| Step: 1
Training loss: 0.26360910869506027
Validation loss: 2.542541389866118

Epoch: 6| Step: 2
Training loss: 0.2361000868188625
Validation loss: 2.5459636859851162

Epoch: 6| Step: 3
Training loss: 0.30290725447860967
Validation loss: 2.4988302196139887

Epoch: 6| Step: 4
Training loss: 0.18428299758235162
Validation loss: 2.5552507065500607

Epoch: 6| Step: 5
Training loss: 0.3273330167772416
Validation loss: 2.529771632114376

Epoch: 6| Step: 6
Training loss: 0.38887356073204526
Validation loss: 2.6121263142470013

Epoch: 6| Step: 7
Training loss: 0.47857539523774495
Validation loss: 2.585425088906127

Epoch: 6| Step: 8
Training loss: 0.2983534539797136
Validation loss: 2.5200837704949195

Epoch: 6| Step: 9
Training loss: 0.315566183974215
Validation loss: 2.5512933299827005

Epoch: 6| Step: 10
Training loss: 0.3403010196868647
Validation loss: 2.513889432758345

Epoch: 6| Step: 11
Training loss: 0.34799274490319
Validation loss: 2.493352651529731

Epoch: 6| Step: 12
Training loss: 0.3589646650513453
Validation loss: 2.4986812133124747

Epoch: 6| Step: 13
Training loss: 0.2893990413368141
Validation loss: 2.4997172036758615

Epoch: 333| Step: 0
Training loss: 0.21864107519487955
Validation loss: 2.5173283924885057

Epoch: 6| Step: 1
Training loss: 0.29281291631874606
Validation loss: 2.5221613283784197

Epoch: 6| Step: 2
Training loss: 0.41218488462484565
Validation loss: 2.5638875538593022

Epoch: 6| Step: 3
Training loss: 0.35503809905784484
Validation loss: 2.6168686553924325

Epoch: 6| Step: 4
Training loss: 0.327994184302898
Validation loss: 2.564701204873373

Epoch: 6| Step: 5
Training loss: 0.2598150105964173
Validation loss: 2.478889775774972

Epoch: 6| Step: 6
Training loss: 0.25776608367155807
Validation loss: 2.4864570722082675

Epoch: 6| Step: 7
Training loss: 0.36449302054291516
Validation loss: 2.518854236575701

Epoch: 6| Step: 8
Training loss: 0.28819973524565917
Validation loss: 2.4763236828207447

Epoch: 6| Step: 9
Training loss: 0.3337831616089339
Validation loss: 2.417151481953521

Epoch: 6| Step: 10
Training loss: 0.24790770463746326
Validation loss: 2.5535061405840813

Epoch: 6| Step: 11
Training loss: 0.40498803441891845
Validation loss: 2.5661395053825506

Epoch: 6| Step: 12
Training loss: 0.30887118073421316
Validation loss: 2.591013495102522

Epoch: 6| Step: 13
Training loss: 0.3162941910849805
Validation loss: 2.6328893210714583

Epoch: 334| Step: 0
Training loss: 0.2654717788837834
Validation loss: 2.5096665893489147

Epoch: 6| Step: 1
Training loss: 0.33127811510502586
Validation loss: 2.545128518002903

Epoch: 6| Step: 2
Training loss: 0.3717546099843199
Validation loss: 2.5152794144471398

Epoch: 6| Step: 3
Training loss: 0.4129978924794493
Validation loss: 2.546125547451043

Epoch: 6| Step: 4
Training loss: 0.1928566456465392
Validation loss: 2.5906907082857513

Epoch: 6| Step: 5
Training loss: 0.3320273118627035
Validation loss: 2.566975987567648

Epoch: 6| Step: 6
Training loss: 0.31418249675135546
Validation loss: 2.622111866087171

Epoch: 6| Step: 7
Training loss: 0.4221849009718334
Validation loss: 2.6034893045051266

Epoch: 6| Step: 8
Training loss: 0.37863950090041154
Validation loss: 2.5963809905711956

Epoch: 6| Step: 9
Training loss: 0.20951716521484526
Validation loss: 2.5399363730563813

Epoch: 6| Step: 10
Training loss: 0.2884652307928188
Validation loss: 2.5085764322521666

Epoch: 6| Step: 11
Training loss: 0.3752630820919821
Validation loss: 2.5110152046794556

Epoch: 6| Step: 12
Training loss: 0.38239456250672244
Validation loss: 2.493264096309377

Epoch: 6| Step: 13
Training loss: 0.3668896501920607
Validation loss: 2.420310747881904

Epoch: 335| Step: 0
Training loss: 0.34987014762918045
Validation loss: 2.5034971413773497

Epoch: 6| Step: 1
Training loss: 0.25960489908056955
Validation loss: 2.5454562083203798

Epoch: 6| Step: 2
Training loss: 0.27386512016677217
Validation loss: 2.5493798760993065

Epoch: 6| Step: 3
Training loss: 0.36563926326611756
Validation loss: 2.6492811751559717

Epoch: 6| Step: 4
Training loss: 0.3901567704606318
Validation loss: 2.6341540034624424

Epoch: 6| Step: 5
Training loss: 0.29349836163169135
Validation loss: 2.571687116284091

Epoch: 6| Step: 6
Training loss: 0.32358997915622895
Validation loss: 2.552899838576762

Epoch: 6| Step: 7
Training loss: 0.27142233105303243
Validation loss: 2.559357274405146

Epoch: 6| Step: 8
Training loss: 0.2869289246326546
Validation loss: 2.507601728128481

Epoch: 6| Step: 9
Training loss: 0.43347406883515943
Validation loss: 2.4991974774371837

Epoch: 6| Step: 10
Training loss: 0.3070555631217782
Validation loss: 2.5508658690580845

Epoch: 6| Step: 11
Training loss: 0.26705025723010517
Validation loss: 2.583840387070913

Epoch: 6| Step: 12
Training loss: 0.33719436484729765
Validation loss: 2.6008559786433967

Epoch: 6| Step: 13
Training loss: 0.3384977189907038
Validation loss: 2.5956345877534237

Epoch: 336| Step: 0
Training loss: 0.329874799957446
Validation loss: 2.598572319480196

Epoch: 6| Step: 1
Training loss: 0.308609201551455
Validation loss: 2.6221492061668514

Epoch: 6| Step: 2
Training loss: 0.20326050493441136
Validation loss: 2.537383572016759

Epoch: 6| Step: 3
Training loss: 0.24544263413054596
Validation loss: 2.582531555920968

Epoch: 6| Step: 4
Training loss: 0.42632505704122947
Validation loss: 2.534418093639908

Epoch: 6| Step: 5
Training loss: 0.31256906223101893
Validation loss: 2.506525931702523

Epoch: 6| Step: 6
Training loss: 0.29114741982907516
Validation loss: 2.5556908910847214

Epoch: 6| Step: 7
Training loss: 0.3301439953148624
Validation loss: 2.630813518937315

Epoch: 6| Step: 8
Training loss: 0.3108731121700748
Validation loss: 2.610238257966395

Epoch: 6| Step: 9
Training loss: 0.4519690205013339
Validation loss: 2.618889159614953

Epoch: 6| Step: 10
Training loss: 0.31822022515496057
Validation loss: 2.6209793255347273

Epoch: 6| Step: 11
Training loss: 0.2051321049447153
Validation loss: 2.513635642524903

Epoch: 6| Step: 12
Training loss: 0.36320466085344316
Validation loss: 2.5107846181680227

Epoch: 6| Step: 13
Training loss: 0.41569707431988745
Validation loss: 2.524767057922821

Epoch: 337| Step: 0
Training loss: 0.25112311096012574
Validation loss: 2.5095325485437363

Epoch: 6| Step: 1
Training loss: 0.29275879012120143
Validation loss: 2.487308681421427

Epoch: 6| Step: 2
Training loss: 0.24566469938195945
Validation loss: 2.5238822647410104

Epoch: 6| Step: 3
Training loss: 0.24684413161624358
Validation loss: 2.5470814377448865

Epoch: 6| Step: 4
Training loss: 0.372466469670115
Validation loss: 2.464794128208663

Epoch: 6| Step: 5
Training loss: 0.22831247543054967
Validation loss: 2.554915609490188

Epoch: 6| Step: 6
Training loss: 0.26679728383693396
Validation loss: 2.502210918945954

Epoch: 6| Step: 7
Training loss: 0.25608966742677525
Validation loss: 2.5039313241196113

Epoch: 6| Step: 8
Training loss: 0.3179913482321296
Validation loss: 2.4775060386596954

Epoch: 6| Step: 9
Training loss: 0.39414163746245356
Validation loss: 2.485855852788736

Epoch: 6| Step: 10
Training loss: 0.31573292237383394
Validation loss: 2.6029440082278135

Epoch: 6| Step: 11
Training loss: 0.26369399931593135
Validation loss: 2.607734270943337

Epoch: 6| Step: 12
Training loss: 0.3863480071996749
Validation loss: 2.5860666279279703

Epoch: 6| Step: 13
Training loss: 0.439158429835249
Validation loss: 2.5614378363766686

Epoch: 338| Step: 0
Training loss: 0.3162544734171034
Validation loss: 2.516645899638541

Epoch: 6| Step: 1
Training loss: 0.4252434054552417
Validation loss: 2.497405645187457

Epoch: 6| Step: 2
Training loss: 0.48465247051632965
Validation loss: 2.509371691709929

Epoch: 6| Step: 3
Training loss: 0.3867796262355801
Validation loss: 2.5511835549209407

Epoch: 6| Step: 4
Training loss: 0.32820178450483417
Validation loss: 2.4957520156969903

Epoch: 6| Step: 5
Training loss: 0.2869951708716328
Validation loss: 2.576419551377859

Epoch: 6| Step: 6
Training loss: 0.3480988802947458
Validation loss: 2.596459532308456

Epoch: 6| Step: 7
Training loss: 0.4499556758032179
Validation loss: 2.6301862256219457

Epoch: 6| Step: 8
Training loss: 0.363878210845745
Validation loss: 2.572479540388567

Epoch: 6| Step: 9
Training loss: 0.3530404918116397
Validation loss: 2.554397169875188

Epoch: 6| Step: 10
Training loss: 0.24902151518435048
Validation loss: 2.4732119963702393

Epoch: 6| Step: 11
Training loss: 0.29091222577478565
Validation loss: 2.534227629240541

Epoch: 6| Step: 12
Training loss: 0.4490208397151739
Validation loss: 2.5204812006214925

Epoch: 6| Step: 13
Training loss: 0.38990790349547505
Validation loss: 2.4581425533513386

Epoch: 339| Step: 0
Training loss: 0.3194286433518263
Validation loss: 2.5252958999338064

Epoch: 6| Step: 1
Training loss: 0.22277117992088646
Validation loss: 2.601859502478177

Epoch: 6| Step: 2
Training loss: 0.36517615032692563
Validation loss: 2.599429702568425

Epoch: 6| Step: 3
Training loss: 0.3155680491744727
Validation loss: 2.615125019958009

Epoch: 6| Step: 4
Training loss: 0.2561904715965713
Validation loss: 2.6410543480215805

Epoch: 6| Step: 5
Training loss: 0.28670390036065063
Validation loss: 2.5707853089169173

Epoch: 6| Step: 6
Training loss: 0.35514586319778474
Validation loss: 2.516292262384888

Epoch: 6| Step: 7
Training loss: 0.4032830320405366
Validation loss: 2.5225152218941926

Epoch: 6| Step: 8
Training loss: 0.4259143586284986
Validation loss: 2.4756153272982186

Epoch: 6| Step: 9
Training loss: 0.3016246761204877
Validation loss: 2.4961245380188313

Epoch: 6| Step: 10
Training loss: 0.21666392984098373
Validation loss: 2.562765332573149

Epoch: 6| Step: 11
Training loss: 0.19016109990099936
Validation loss: 2.5626874405451905

Epoch: 6| Step: 12
Training loss: 0.42148331720680804
Validation loss: 2.655629957048879

Epoch: 6| Step: 13
Training loss: 0.49403426944442874
Validation loss: 2.617322980875648

Epoch: 340| Step: 0
Training loss: 0.3043821467553404
Validation loss: 2.5061061833722507

Epoch: 6| Step: 1
Training loss: 0.3715501287853586
Validation loss: 2.542977461480114

Epoch: 6| Step: 2
Training loss: 0.41192923129474257
Validation loss: 2.5060303040798475

Epoch: 6| Step: 3
Training loss: 0.27965817057945086
Validation loss: 2.494641744824894

Epoch: 6| Step: 4
Training loss: 0.3949182896965426
Validation loss: 2.5210689376777986

Epoch: 6| Step: 5
Training loss: 0.2720241806014427
Validation loss: 2.486002518918313

Epoch: 6| Step: 6
Training loss: 0.35138102191961
Validation loss: 2.58253240218489

Epoch: 6| Step: 7
Training loss: 0.5693735728575725
Validation loss: 2.557463324872088

Epoch: 6| Step: 8
Training loss: 0.2628385869254839
Validation loss: 2.6046394275057545

Epoch: 6| Step: 9
Training loss: 0.27007272482657607
Validation loss: 2.5841083953382498

Epoch: 6| Step: 10
Training loss: 0.41236366995758494
Validation loss: 2.5248124163101533

Epoch: 6| Step: 11
Training loss: 0.1719260790091688
Validation loss: 2.506805923018705

Epoch: 6| Step: 12
Training loss: 0.2892559538272175
Validation loss: 2.5238480209403185

Epoch: 6| Step: 13
Training loss: 0.17687658671486262
Validation loss: 2.4766841581770027

Epoch: 341| Step: 0
Training loss: 0.35558824312354564
Validation loss: 2.5088618807323972

Epoch: 6| Step: 1
Training loss: 0.19817435696732022
Validation loss: 2.5006229737062324

Epoch: 6| Step: 2
Training loss: 0.4798712853618076
Validation loss: 2.5002860382476304

Epoch: 6| Step: 3
Training loss: 0.31976629999473044
Validation loss: 2.4906662191301074

Epoch: 6| Step: 4
Training loss: 0.22149243617651848
Validation loss: 2.529821235965413

Epoch: 6| Step: 5
Training loss: 0.3244659905899105
Validation loss: 2.550255308896306

Epoch: 6| Step: 6
Training loss: 0.16228755672312514
Validation loss: 2.4934996017905515

Epoch: 6| Step: 7
Training loss: 0.2761517281312621
Validation loss: 2.5210191931396815

Epoch: 6| Step: 8
Training loss: 0.3148149339916174
Validation loss: 2.5209842405521425

Epoch: 6| Step: 9
Training loss: 0.34706500494252385
Validation loss: 2.5535621925540117

Epoch: 6| Step: 10
Training loss: 0.3821322956904889
Validation loss: 2.51668163088798

Epoch: 6| Step: 11
Training loss: 0.2528820213855386
Validation loss: 2.564490266459783

Epoch: 6| Step: 12
Training loss: 0.272063235090206
Validation loss: 2.5755090870732418

Epoch: 6| Step: 13
Training loss: 0.27637470895621624
Validation loss: 2.55166076483398

Epoch: 342| Step: 0
Training loss: 0.512605786454385
Validation loss: 2.5530248553068127

Epoch: 6| Step: 1
Training loss: 0.25721277940068205
Validation loss: 2.523988488416421

Epoch: 6| Step: 2
Training loss: 0.21830254158046797
Validation loss: 2.6237612026460684

Epoch: 6| Step: 3
Training loss: 0.3181003265517992
Validation loss: 2.584239344513359

Epoch: 6| Step: 4
Training loss: 0.3370160155905335
Validation loss: 2.5732978018554316

Epoch: 6| Step: 5
Training loss: 0.28988440400727516
Validation loss: 2.5701945315482067

Epoch: 6| Step: 6
Training loss: 0.26812865710487616
Validation loss: 2.5246555313722348

Epoch: 6| Step: 7
Training loss: 0.18602917879368744
Validation loss: 2.543880285602251

Epoch: 6| Step: 8
Training loss: 0.22208839081223622
Validation loss: 2.5431100988681976

Epoch: 6| Step: 9
Training loss: 0.1916733940557519
Validation loss: 2.5701219513206843

Epoch: 6| Step: 10
Training loss: 0.20431011441513472
Validation loss: 2.5804790038119627

Epoch: 6| Step: 11
Training loss: 0.29005141825961334
Validation loss: 2.544722335772491

Epoch: 6| Step: 12
Training loss: 0.36854840765021546
Validation loss: 2.510966218389687

Epoch: 6| Step: 13
Training loss: 0.29850474793285914
Validation loss: 2.545276772264142

Epoch: 343| Step: 0
Training loss: 0.14668012255770474
Validation loss: 2.5283142616275205

Epoch: 6| Step: 1
Training loss: 0.24849726120113053
Validation loss: 2.484139013378561

Epoch: 6| Step: 2
Training loss: 0.21936194791303187
Validation loss: 2.529444698300028

Epoch: 6| Step: 3
Training loss: 0.22812118069835163
Validation loss: 2.5825801079417383

Epoch: 6| Step: 4
Training loss: 0.37624096181539124
Validation loss: 2.5066539587889154

Epoch: 6| Step: 5
Training loss: 0.3232235975192441
Validation loss: 2.58804348476173

Epoch: 6| Step: 6
Training loss: 0.272353899860176
Validation loss: 2.5636440452480684

Epoch: 6| Step: 7
Training loss: 0.23347885151137202
Validation loss: 2.539575839846547

Epoch: 6| Step: 8
Training loss: 0.24535687950238733
Validation loss: 2.553571140214343

Epoch: 6| Step: 9
Training loss: 0.24681658778086207
Validation loss: 2.5137064392195345

Epoch: 6| Step: 10
Training loss: 0.3097503812293415
Validation loss: 2.4927770541121355

Epoch: 6| Step: 11
Training loss: 0.3489179647164305
Validation loss: 2.5210669438170643

Epoch: 6| Step: 12
Training loss: 0.36940009469184426
Validation loss: 2.5617910815644374

Epoch: 6| Step: 13
Training loss: 0.29027989211572336
Validation loss: 2.552355449467936

Epoch: 344| Step: 0
Training loss: 0.3790547188182709
Validation loss: 2.549425934393963

Epoch: 6| Step: 1
Training loss: 0.2018365527232786
Validation loss: 2.5924936721930534

Epoch: 6| Step: 2
Training loss: 0.19685377430406573
Validation loss: 2.5294644215591315

Epoch: 6| Step: 3
Training loss: 0.2622113218613543
Validation loss: 2.4741810561194564

Epoch: 6| Step: 4
Training loss: 0.23165171308820617
Validation loss: 2.481617562897237

Epoch: 6| Step: 5
Training loss: 0.3186776962739895
Validation loss: 2.526093462121335

Epoch: 6| Step: 6
Training loss: 0.36507910217507034
Validation loss: 2.5252167655888593

Epoch: 6| Step: 7
Training loss: 0.3041966470331075
Validation loss: 2.528850029905863

Epoch: 6| Step: 8
Training loss: 0.3442378916636758
Validation loss: 2.5272102851354683

Epoch: 6| Step: 9
Training loss: 0.2682738066381101
Validation loss: 2.5540954806026

Epoch: 6| Step: 10
Training loss: 0.31376067029430826
Validation loss: 2.572806558041889

Epoch: 6| Step: 11
Training loss: 0.2547541618868222
Validation loss: 2.5485731910866565

Epoch: 6| Step: 12
Training loss: 0.27390957000687527
Validation loss: 2.5718956104069197

Epoch: 6| Step: 13
Training loss: 0.278363783269082
Validation loss: 2.6121949816333223

Epoch: 345| Step: 0
Training loss: 0.2815433799907368
Validation loss: 2.589447804405864

Epoch: 6| Step: 1
Training loss: 0.32468807767462354
Validation loss: 2.612716613805889

Epoch: 6| Step: 2
Training loss: 0.3302937542550329
Validation loss: 2.5677120577544668

Epoch: 6| Step: 3
Training loss: 0.21535466739070702
Validation loss: 2.606102297810982

Epoch: 6| Step: 4
Training loss: 0.22702946716679742
Validation loss: 2.601917964260772

Epoch: 6| Step: 5
Training loss: 0.2175738613320437
Validation loss: 2.5783506506609752

Epoch: 6| Step: 6
Training loss: 0.25444411016136415
Validation loss: 2.619272887256358

Epoch: 6| Step: 7
Training loss: 0.2922751035277526
Validation loss: 2.530984668404414

Epoch: 6| Step: 8
Training loss: 0.25488778178899263
Validation loss: 2.5749578886076216

Epoch: 6| Step: 9
Training loss: 0.3318928598458262
Validation loss: 2.6206195552061864

Epoch: 6| Step: 10
Training loss: 0.28708004963901895
Validation loss: 2.5107278169358933

Epoch: 6| Step: 11
Training loss: 0.3703932726366527
Validation loss: 2.5327746505152735

Epoch: 6| Step: 12
Training loss: 0.24623380944234086
Validation loss: 2.54623027356284

Epoch: 6| Step: 13
Training loss: 0.4009320204160405
Validation loss: 2.531297361456713

Epoch: 346| Step: 0
Training loss: 0.17818030285224093
Validation loss: 2.565832545210232

Epoch: 6| Step: 1
Training loss: 0.31776016104454
Validation loss: 2.6113003539323207

Epoch: 6| Step: 2
Training loss: 0.2435971887577011
Validation loss: 2.601654371867514

Epoch: 6| Step: 3
Training loss: 0.419404549531223
Validation loss: 2.573788403827735

Epoch: 6| Step: 4
Training loss: 0.21222466238889018
Validation loss: 2.543984783937826

Epoch: 6| Step: 5
Training loss: 0.5243556098399277
Validation loss: 2.5087379023689973

Epoch: 6| Step: 6
Training loss: 0.3447243363521981
Validation loss: 2.4835519446940117

Epoch: 6| Step: 7
Training loss: 0.4002017436295043
Validation loss: 2.524077909950822

Epoch: 6| Step: 8
Training loss: 0.3270401277170963
Validation loss: 2.5022320796596595

Epoch: 6| Step: 9
Training loss: 0.2503908648318661
Validation loss: 2.5848198940957428

Epoch: 6| Step: 10
Training loss: 0.36264125275244224
Validation loss: 2.6473627000699467

Epoch: 6| Step: 11
Training loss: 0.4115924395342757
Validation loss: 2.6101676665879165

Epoch: 6| Step: 12
Training loss: 0.33032805105754987
Validation loss: 2.623312657596715

Epoch: 6| Step: 13
Training loss: 0.40170010684066315
Validation loss: 2.6204211551261656

Epoch: 347| Step: 0
Training loss: 0.18993843488158763
Validation loss: 2.485420251083241

Epoch: 6| Step: 1
Training loss: 0.3269319643672479
Validation loss: 2.544944624507594

Epoch: 6| Step: 2
Training loss: 0.3977641418323886
Validation loss: 2.5073429987277454

Epoch: 6| Step: 3
Training loss: 0.26793122487587173
Validation loss: 2.476095418275735

Epoch: 6| Step: 4
Training loss: 0.3742462371096778
Validation loss: 2.5145642115243323

Epoch: 6| Step: 5
Training loss: 0.2338478995901543
Validation loss: 2.4828780600724776

Epoch: 6| Step: 6
Training loss: 0.3108036970621336
Validation loss: 2.549996676474007

Epoch: 6| Step: 7
Training loss: 0.5192577818286048
Validation loss: 2.5452941793957597

Epoch: 6| Step: 8
Training loss: 0.3919545815623065
Validation loss: 2.5588102370444137

Epoch: 6| Step: 9
Training loss: 0.2751130402758977
Validation loss: 2.4176881593462163

Epoch: 6| Step: 10
Training loss: 0.34798254281206087
Validation loss: 2.4369595572447746

Epoch: 6| Step: 11
Training loss: 0.3621351148557546
Validation loss: 2.5069502698056305

Epoch: 6| Step: 12
Training loss: 0.4200614697171713
Validation loss: 2.470072548955264

Epoch: 6| Step: 13
Training loss: 0.3487160847693042
Validation loss: 2.4542461352173315

Epoch: 348| Step: 0
Training loss: 0.24112747076468377
Validation loss: 2.536640510570437

Epoch: 6| Step: 1
Training loss: 0.37301148251713395
Validation loss: 2.524528432944723

Epoch: 6| Step: 2
Training loss: 0.3962401779654246
Validation loss: 2.5337214394308285

Epoch: 6| Step: 3
Training loss: 0.2890959282181581
Validation loss: 2.575602505388269

Epoch: 6| Step: 4
Training loss: 0.25545232002550994
Validation loss: 2.4851462568561646

Epoch: 6| Step: 5
Training loss: 0.2384829995975998
Validation loss: 2.5139644662960277

Epoch: 6| Step: 6
Training loss: 0.24545888906446298
Validation loss: 2.5468111244725993

Epoch: 6| Step: 7
Training loss: 0.2818749160935643
Validation loss: 2.4572577116915064

Epoch: 6| Step: 8
Training loss: 0.3207349782311686
Validation loss: 2.523609568867702

Epoch: 6| Step: 9
Training loss: 0.29436507305488485
Validation loss: 2.5440804844026794

Epoch: 6| Step: 10
Training loss: 0.28317552629362813
Validation loss: 2.5143622789243665

Epoch: 6| Step: 11
Training loss: 0.3558246382038821
Validation loss: 2.5346276702548227

Epoch: 6| Step: 12
Training loss: 0.27093425423197015
Validation loss: 2.6142765538965644

Epoch: 6| Step: 13
Training loss: 0.33571892658318836
Validation loss: 2.564835158957375

Epoch: 349| Step: 0
Training loss: 0.33464515859868377
Validation loss: 2.604078906805761

Epoch: 6| Step: 1
Training loss: 0.2429173071639078
Validation loss: 2.5244521157245345

Epoch: 6| Step: 2
Training loss: 0.2751426933453894
Validation loss: 2.5170124721629823

Epoch: 6| Step: 3
Training loss: 0.20405747882104158
Validation loss: 2.5137949145006826

Epoch: 6| Step: 4
Training loss: 0.3309961227783435
Validation loss: 2.5428959161706755

Epoch: 6| Step: 5
Training loss: 0.29855104453422093
Validation loss: 2.5113509696458984

Epoch: 6| Step: 6
Training loss: 0.32127324677008934
Validation loss: 2.5456242210636124

Epoch: 6| Step: 7
Training loss: 0.2805728708459196
Validation loss: 2.5351412184416096

Epoch: 6| Step: 8
Training loss: 0.23341018455663143
Validation loss: 2.5493618032518044

Epoch: 6| Step: 9
Training loss: 0.29699511356861574
Validation loss: 2.523012359677569

Epoch: 6| Step: 10
Training loss: 0.3528695499122256
Validation loss: 2.525694500115506

Epoch: 6| Step: 11
Training loss: 0.2794943291604062
Validation loss: 2.5615558745831506

Epoch: 6| Step: 12
Training loss: 0.3144828829693678
Validation loss: 2.5505832285639904

Epoch: 6| Step: 13
Training loss: 0.2589989728539031
Validation loss: 2.5215701347913426

Epoch: 350| Step: 0
Training loss: 0.4047215760366296
Validation loss: 2.5270919399214504

Epoch: 6| Step: 1
Training loss: 0.3294388941078744
Validation loss: 2.5580505804027616

Epoch: 6| Step: 2
Training loss: 0.3600095040338379
Validation loss: 2.5324768578243018

Epoch: 6| Step: 3
Training loss: 0.1843517159452728
Validation loss: 2.5391018438958954

Epoch: 6| Step: 4
Training loss: 0.20389394832641547
Validation loss: 2.5345352736789333

Epoch: 6| Step: 5
Training loss: 0.3303475493617765
Validation loss: 2.5456830689515915

Epoch: 6| Step: 6
Training loss: 0.26794970252847505
Validation loss: 2.624014321204779

Epoch: 6| Step: 7
Training loss: 0.3740070827484103
Validation loss: 2.5879191309480527

Epoch: 6| Step: 8
Training loss: 0.2792379810688908
Validation loss: 2.6277850378347067

Epoch: 6| Step: 9
Training loss: 0.19985342838929465
Validation loss: 2.565667729829232

Epoch: 6| Step: 10
Training loss: 0.20594294623320863
Validation loss: 2.5536944591216675

Epoch: 6| Step: 11
Training loss: 0.4511157079306764
Validation loss: 2.503168720525518

Epoch: 6| Step: 12
Training loss: 0.4401696700006067
Validation loss: 2.4605195190052367

Epoch: 6| Step: 13
Training loss: 0.5052136456973855
Validation loss: 2.5209696919365694

Epoch: 351| Step: 0
Training loss: 0.3687378234792549
Validation loss: 2.542797420763755

Epoch: 6| Step: 1
Training loss: 0.24239182313312987
Validation loss: 2.547010437654322

Epoch: 6| Step: 2
Training loss: 0.370704044706693
Validation loss: 2.6035606187699063

Epoch: 6| Step: 3
Training loss: 0.28476888657364774
Validation loss: 2.576515111261875

Epoch: 6| Step: 4
Training loss: 0.27931097301834845
Validation loss: 2.555762777242881

Epoch: 6| Step: 5
Training loss: 0.22244766570868807
Validation loss: 2.4921488106174934

Epoch: 6| Step: 6
Training loss: 0.29128982120275454
Validation loss: 2.445264293776431

Epoch: 6| Step: 7
Training loss: 0.35730743660708014
Validation loss: 2.5010020473084937

Epoch: 6| Step: 8
Training loss: 0.23110819057666335
Validation loss: 2.486129581008678

Epoch: 6| Step: 9
Training loss: 0.2964616709021112
Validation loss: 2.5040864765532125

Epoch: 6| Step: 10
Training loss: 0.21684311038663864
Validation loss: 2.535036841481572

Epoch: 6| Step: 11
Training loss: 0.23980508610725984
Validation loss: 2.5511688903719487

Epoch: 6| Step: 12
Training loss: 0.5445360301176013
Validation loss: 2.603440364008355

Epoch: 6| Step: 13
Training loss: 0.3971029633149452
Validation loss: 2.5890774060535633

Epoch: 352| Step: 0
Training loss: 0.25504858830301896
Validation loss: 2.4967717308106376

Epoch: 6| Step: 1
Training loss: 0.23210812075599294
Validation loss: 2.514012208715741

Epoch: 6| Step: 2
Training loss: 0.3664401545017734
Validation loss: 2.537725305811835

Epoch: 6| Step: 3
Training loss: 0.4774508872663999
Validation loss: 2.5376743062603064

Epoch: 6| Step: 4
Training loss: 0.4019809309199159
Validation loss: 2.4990722524276077

Epoch: 6| Step: 5
Training loss: 0.444100990640643
Validation loss: 2.6253757964694855

Epoch: 6| Step: 6
Training loss: 0.363031896516563
Validation loss: 2.6030571875682824

Epoch: 6| Step: 7
Training loss: 0.5250159420136103
Validation loss: 2.597523162415432

Epoch: 6| Step: 8
Training loss: 0.2651042602229125
Validation loss: 2.5797228860998582

Epoch: 6| Step: 9
Training loss: 0.37176994154033904
Validation loss: 2.591490546576585

Epoch: 6| Step: 10
Training loss: 0.3736006535969557
Validation loss: 2.533981356641778

Epoch: 6| Step: 11
Training loss: 0.2835457143744575
Validation loss: 2.50232030956998

Epoch: 6| Step: 12
Training loss: 0.4543988475024776
Validation loss: 2.5328599339004314

Epoch: 6| Step: 13
Training loss: 0.38568300203585226
Validation loss: 2.4974153668405767

Epoch: 353| Step: 0
Training loss: 0.30202299644532543
Validation loss: 2.547941846455389

Epoch: 6| Step: 1
Training loss: 0.26497424576327444
Validation loss: 2.5357481310125247

Epoch: 6| Step: 2
Training loss: 0.23667958820074617
Validation loss: 2.5379645061811673

Epoch: 6| Step: 3
Training loss: 0.2599230124583694
Validation loss: 2.6060038888726114

Epoch: 6| Step: 4
Training loss: 0.3525600796930733
Validation loss: 2.5070681313963643

Epoch: 6| Step: 5
Training loss: 0.29941073202432095
Validation loss: 2.516727506036925

Epoch: 6| Step: 6
Training loss: 0.23875427197334279
Validation loss: 2.4939423126028193

Epoch: 6| Step: 7
Training loss: 0.3784964596961983
Validation loss: 2.5229000310456993

Epoch: 6| Step: 8
Training loss: 0.373802139511129
Validation loss: 2.521965313901058

Epoch: 6| Step: 9
Training loss: 0.48174434451578
Validation loss: 2.4917081015043103

Epoch: 6| Step: 10
Training loss: 0.32827839217832605
Validation loss: 2.514393111911304

Epoch: 6| Step: 11
Training loss: 0.288745500108409
Validation loss: 2.5507075721182955

Epoch: 6| Step: 12
Training loss: 0.25852799112503944
Validation loss: 2.616884644858589

Epoch: 6| Step: 13
Training loss: 0.3257258214840802
Validation loss: 2.621770658603046

Epoch: 354| Step: 0
Training loss: 0.3668242341746893
Validation loss: 2.5910418823451487

Epoch: 6| Step: 1
Training loss: 0.23931327488390963
Validation loss: 2.562637426211343

Epoch: 6| Step: 2
Training loss: 0.29100784188942
Validation loss: 2.5480133664196276

Epoch: 6| Step: 3
Training loss: 0.31886310160265846
Validation loss: 2.4997792543864565

Epoch: 6| Step: 4
Training loss: 0.28821962778271487
Validation loss: 2.4780628781832346

Epoch: 6| Step: 5
Training loss: 0.2030593325766216
Validation loss: 2.468440772862238

Epoch: 6| Step: 6
Training loss: 0.34255974784459614
Validation loss: 2.4711218598453715

Epoch: 6| Step: 7
Training loss: 0.41583692267530886
Validation loss: 2.4850181290971354

Epoch: 6| Step: 8
Training loss: 0.20212825729703846
Validation loss: 2.5563265396510717

Epoch: 6| Step: 9
Training loss: 0.25603215738976365
Validation loss: 2.559065416652483

Epoch: 6| Step: 10
Training loss: 0.359443657992284
Validation loss: 2.544234828375347

Epoch: 6| Step: 11
Training loss: 0.21083288777597062
Validation loss: 2.5761023707988016

Epoch: 6| Step: 12
Training loss: 0.2505449227285853
Validation loss: 2.5460970495919946

Epoch: 6| Step: 13
Training loss: 0.43598824961056554
Validation loss: 2.5711117538552823

Epoch: 355| Step: 0
Training loss: 0.21373847676609534
Validation loss: 2.576376755718121

Epoch: 6| Step: 1
Training loss: 0.355067980865845
Validation loss: 2.5676289843407685

Epoch: 6| Step: 2
Training loss: 0.21566145215616525
Validation loss: 2.5539026250431336

Epoch: 6| Step: 3
Training loss: 0.2361051595317991
Validation loss: 2.5628157707980828

Epoch: 6| Step: 4
Training loss: 0.23758555301894682
Validation loss: 2.493442335087841

Epoch: 6| Step: 5
Training loss: 0.27045693590442477
Validation loss: 2.479097026092603

Epoch: 6| Step: 6
Training loss: 0.2983140325540865
Validation loss: 2.489688732730584

Epoch: 6| Step: 7
Training loss: 0.26770642956503315
Validation loss: 2.498343260488537

Epoch: 6| Step: 8
Training loss: 0.2223013508917809
Validation loss: 2.5424911433352912

Epoch: 6| Step: 9
Training loss: 0.1846808249014418
Validation loss: 2.527610045470161

Epoch: 6| Step: 10
Training loss: 0.342908316481995
Validation loss: 2.578243168136071

Epoch: 6| Step: 11
Training loss: 0.4236480576483615
Validation loss: 2.53934896564838

Epoch: 6| Step: 12
Training loss: 0.40193303450042184
Validation loss: 2.5446419629037256

Epoch: 6| Step: 13
Training loss: 0.37304022418579486
Validation loss: 2.536407318751066

Epoch: 356| Step: 0
Training loss: 0.26723304828768807
Validation loss: 2.528869797085723

Epoch: 6| Step: 1
Training loss: 0.26198187454421845
Validation loss: 2.4830437538316112

Epoch: 6| Step: 2
Training loss: 0.5301319586925191
Validation loss: 2.472134021252451

Epoch: 6| Step: 3
Training loss: 0.3814687304674495
Validation loss: 2.517293562293408

Epoch: 6| Step: 4
Training loss: 0.4281813667948346
Validation loss: 2.5169049910147914

Epoch: 6| Step: 5
Training loss: 0.20179706018183147
Validation loss: 2.5172645643874154

Epoch: 6| Step: 6
Training loss: 0.3424296815414447
Validation loss: 2.6011999066582923

Epoch: 6| Step: 7
Training loss: 0.4456652532430037
Validation loss: 2.6374243952926704

Epoch: 6| Step: 8
Training loss: 0.32512083145733994
Validation loss: 2.6147644821171028

Epoch: 6| Step: 9
Training loss: 0.384455037506624
Validation loss: 2.582117468798241

Epoch: 6| Step: 10
Training loss: 0.31681823987684765
Validation loss: 2.53550478788112

Epoch: 6| Step: 11
Training loss: 0.4369569882693225
Validation loss: 2.5054202132266283

Epoch: 6| Step: 12
Training loss: 0.3024910718215052
Validation loss: 2.536566602105093

Epoch: 6| Step: 13
Training loss: 0.46588220724923357
Validation loss: 2.515476972754222

Epoch: 357| Step: 0
Training loss: 0.36336280563595175
Validation loss: 2.4589737580595115

Epoch: 6| Step: 1
Training loss: 0.3678220176923821
Validation loss: 2.5419199744357903

Epoch: 6| Step: 2
Training loss: 0.21947615023638653
Validation loss: 2.594374792077088

Epoch: 6| Step: 3
Training loss: 0.4642493671295832
Validation loss: 2.5784372005817695

Epoch: 6| Step: 4
Training loss: 0.34535102370433374
Validation loss: 2.59639005084606

Epoch: 6| Step: 5
Training loss: 0.24707198613621478
Validation loss: 2.5293970429409094

Epoch: 6| Step: 6
Training loss: 0.2682066031412978
Validation loss: 2.5370083838477044

Epoch: 6| Step: 7
Training loss: 0.2620739021686564
Validation loss: 2.5333001582165253

Epoch: 6| Step: 8
Training loss: 0.24038300142296593
Validation loss: 2.474002136378084

Epoch: 6| Step: 9
Training loss: 0.43817141647540686
Validation loss: 2.503488744880188

Epoch: 6| Step: 10
Training loss: 0.3369956981882433
Validation loss: 2.4633546614422612

Epoch: 6| Step: 11
Training loss: 0.26485830340163874
Validation loss: 2.520076170355474

Epoch: 6| Step: 12
Training loss: 0.21317161599803172
Validation loss: 2.550261977706946

Epoch: 6| Step: 13
Training loss: 0.3895811629957376
Validation loss: 2.5901590714400258

Epoch: 358| Step: 0
Training loss: 0.35635077908193785
Validation loss: 2.578342050990939

Epoch: 6| Step: 1
Training loss: 0.4407947152564777
Validation loss: 2.5645085503350176

Epoch: 6| Step: 2
Training loss: 0.19880002091093932
Validation loss: 2.5890270343531587

Epoch: 6| Step: 3
Training loss: 0.406286678125665
Validation loss: 2.4926563965843553

Epoch: 6| Step: 4
Training loss: 0.16406885770559
Validation loss: 2.540639471722154

Epoch: 6| Step: 5
Training loss: 0.2359697761942743
Validation loss: 2.537203455417226

Epoch: 6| Step: 6
Training loss: 0.22748755006993457
Validation loss: 2.5231350775589805

Epoch: 6| Step: 7
Training loss: 0.3897394059768036
Validation loss: 2.537429331279311

Epoch: 6| Step: 8
Training loss: 0.2369973897040753
Validation loss: 2.556685324662558

Epoch: 6| Step: 9
Training loss: 0.3226116634532904
Validation loss: 2.588304425631017

Epoch: 6| Step: 10
Training loss: 0.21108710317361487
Validation loss: 2.5757709583574

Epoch: 6| Step: 11
Training loss: 0.24408960190709642
Validation loss: 2.588483450303383

Epoch: 6| Step: 12
Training loss: 0.36624761779192694
Validation loss: 2.591826296200718

Epoch: 6| Step: 13
Training loss: 0.27020585596972946
Validation loss: 2.5132664351283105

Epoch: 359| Step: 0
Training loss: 0.2795682802189079
Validation loss: 2.492818483458099

Epoch: 6| Step: 1
Training loss: 0.2661584798243127
Validation loss: 2.491378955964691

Epoch: 6| Step: 2
Training loss: 0.2743911462086674
Validation loss: 2.508787288543878

Epoch: 6| Step: 3
Training loss: 0.3972908799687588
Validation loss: 2.532080219834559

Epoch: 6| Step: 4
Training loss: 0.23650838739470623
Validation loss: 2.518219599003781

Epoch: 6| Step: 5
Training loss: 0.26768300861898847
Validation loss: 2.5625688962280897

Epoch: 6| Step: 6
Training loss: 0.2282992912124412
Validation loss: 2.600536499241107

Epoch: 6| Step: 7
Training loss: 0.4745336401524043
Validation loss: 2.6758110842932656

Epoch: 6| Step: 8
Training loss: 0.28793173073382755
Validation loss: 2.5844098022282522

Epoch: 6| Step: 9
Training loss: 0.23487197320600794
Validation loss: 2.549682910377538

Epoch: 6| Step: 10
Training loss: 0.17065454791354814
Validation loss: 2.4795616914418677

Epoch: 6| Step: 11
Training loss: 0.4262101174599177
Validation loss: 2.4850327362831184

Epoch: 6| Step: 12
Training loss: 0.3099126276973839
Validation loss: 2.503563756822807

Epoch: 6| Step: 13
Training loss: 0.32498717878801114
Validation loss: 2.5382756505645925

Epoch: 360| Step: 0
Training loss: 0.2229516763171552
Validation loss: 2.5769830043283104

Epoch: 6| Step: 1
Training loss: 0.25533799199433066
Validation loss: 2.5192392421526915

Epoch: 6| Step: 2
Training loss: 0.3088657894274148
Validation loss: 2.5804934248022198

Epoch: 6| Step: 3
Training loss: 0.4122857895879296
Validation loss: 2.616277037200007

Epoch: 6| Step: 4
Training loss: 0.2433314379336293
Validation loss: 2.6303294138217095

Epoch: 6| Step: 5
Training loss: 0.2103917160600829
Validation loss: 2.5812272952161117

Epoch: 6| Step: 6
Training loss: 0.2491478179271308
Validation loss: 2.5426197505920682

Epoch: 6| Step: 7
Training loss: 0.28160644831806314
Validation loss: 2.5905499154849223

Epoch: 6| Step: 8
Training loss: 0.3809589940391891
Validation loss: 2.5447711016750105

Epoch: 6| Step: 9
Training loss: 0.43469426819655715
Validation loss: 2.5664769612426515

Epoch: 6| Step: 10
Training loss: 0.2760174698691065
Validation loss: 2.545892163068841

Epoch: 6| Step: 11
Training loss: 0.30095599411795554
Validation loss: 2.574394193082116

Epoch: 6| Step: 12
Training loss: 0.4091151329957931
Validation loss: 2.635298991434632

Epoch: 6| Step: 13
Training loss: 0.29398463546980635
Validation loss: 2.5876809549865514

Epoch: 361| Step: 0
Training loss: 0.3496144043970906
Validation loss: 2.5333891726496884

Epoch: 6| Step: 1
Training loss: 0.2262119837430257
Validation loss: 2.548370140895975

Epoch: 6| Step: 2
Training loss: 0.21719620844994203
Validation loss: 2.51301500916012

Epoch: 6| Step: 3
Training loss: 0.22671186522132944
Validation loss: 2.5260035141623187

Epoch: 6| Step: 4
Training loss: 0.3277792016746463
Validation loss: 2.477425842946011

Epoch: 6| Step: 5
Training loss: 0.3586633726860073
Validation loss: 2.527339434140985

Epoch: 6| Step: 6
Training loss: 0.29033740590725027
Validation loss: 2.459513135986757

Epoch: 6| Step: 7
Training loss: 0.2167848377494549
Validation loss: 2.5082648038743796

Epoch: 6| Step: 8
Training loss: 0.38075935811135053
Validation loss: 2.5761350716330407

Epoch: 6| Step: 9
Training loss: 0.3597058141902888
Validation loss: 2.5039772186299225

Epoch: 6| Step: 10
Training loss: 0.20832030235703947
Validation loss: 2.531519808733981

Epoch: 6| Step: 11
Training loss: 0.2903333513144551
Validation loss: 2.578967055164675

Epoch: 6| Step: 12
Training loss: 0.23128033645216486
Validation loss: 2.4549816176353647

Epoch: 6| Step: 13
Training loss: 0.18645116394438715
Validation loss: 2.553101026592905

Epoch: 362| Step: 0
Training loss: 0.20286497565751016
Validation loss: 2.488313859359601

Epoch: 6| Step: 1
Training loss: 0.21760692131930923
Validation loss: 2.5009013220131666

Epoch: 6| Step: 2
Training loss: 0.26381312225131043
Validation loss: 2.4862867872822716

Epoch: 6| Step: 3
Training loss: 0.2321378912368377
Validation loss: 2.5060360995597715

Epoch: 6| Step: 4
Training loss: 0.2604713605030231
Validation loss: 2.5416819514664453

Epoch: 6| Step: 5
Training loss: 0.20737198914037402
Validation loss: 2.5101523728493587

Epoch: 6| Step: 6
Training loss: 0.18534034477994438
Validation loss: 2.56435260638653

Epoch: 6| Step: 7
Training loss: 0.3531411859296809
Validation loss: 2.526327425075249

Epoch: 6| Step: 8
Training loss: 0.4225676642921724
Validation loss: 2.5714771604236355

Epoch: 6| Step: 9
Training loss: 0.21228990757793334
Validation loss: 2.527665563393564

Epoch: 6| Step: 10
Training loss: 0.22252149854426734
Validation loss: 2.5384038530607422

Epoch: 6| Step: 11
Training loss: 0.3118076522750044
Validation loss: 2.4891734776777787

Epoch: 6| Step: 12
Training loss: 0.21856639172779274
Validation loss: 2.528710806758641

Epoch: 6| Step: 13
Training loss: 0.23888045934579863
Validation loss: 2.493422789048396

Epoch: 363| Step: 0
Training loss: 0.3696578302997036
Validation loss: 2.5515981303785704

Epoch: 6| Step: 1
Training loss: 0.21612665175539786
Validation loss: 2.5158833515198378

Epoch: 6| Step: 2
Training loss: 0.29320500067037997
Validation loss: 2.55629929026344

Epoch: 6| Step: 3
Training loss: 0.3167110435026269
Validation loss: 2.579071271998463

Epoch: 6| Step: 4
Training loss: 0.21986267959988184
Validation loss: 2.5350848061987095

Epoch: 6| Step: 5
Training loss: 0.28677368001683134
Validation loss: 2.5007431276834544

Epoch: 6| Step: 6
Training loss: 0.275646172313661
Validation loss: 2.5470348378207612

Epoch: 6| Step: 7
Training loss: 0.2890971008418326
Validation loss: 2.507904962120581

Epoch: 6| Step: 8
Training loss: 0.20966227381114144
Validation loss: 2.4516587137404056

Epoch: 6| Step: 9
Training loss: 0.3934671574414102
Validation loss: 2.4974301640468295

Epoch: 6| Step: 10
Training loss: 0.3291905223475202
Validation loss: 2.5340542977243015

Epoch: 6| Step: 11
Training loss: 0.3018304064690562
Validation loss: 2.5118589386842163

Epoch: 6| Step: 12
Training loss: 0.3492211685267596
Validation loss: 2.574786789718155

Epoch: 6| Step: 13
Training loss: 0.31775767563343843
Validation loss: 2.551389799796809

Epoch: 364| Step: 0
Training loss: 0.28166679123211724
Validation loss: 2.5678516886983087

Epoch: 6| Step: 1
Training loss: 0.3284916418803495
Validation loss: 2.5938024860265156

Epoch: 6| Step: 2
Training loss: 0.25717104962325016
Validation loss: 2.538617906037377

Epoch: 6| Step: 3
Training loss: 0.27671508997732003
Validation loss: 2.4890124944759253

Epoch: 6| Step: 4
Training loss: 0.2764029597662883
Validation loss: 2.4895014782674085

Epoch: 6| Step: 5
Training loss: 0.262063539479744
Validation loss: 2.4807581695157634

Epoch: 6| Step: 6
Training loss: 0.21519592204745927
Validation loss: 2.4987492054970923

Epoch: 6| Step: 7
Training loss: 0.31035665768377385
Validation loss: 2.5109158780667062

Epoch: 6| Step: 8
Training loss: 0.2701365405339926
Validation loss: 2.541767819273071

Epoch: 6| Step: 9
Training loss: 0.34435548342807026
Validation loss: 2.5845813710337837

Epoch: 6| Step: 10
Training loss: 0.37764433504626266
Validation loss: 2.582811977219495

Epoch: 6| Step: 11
Training loss: 0.3349535526985235
Validation loss: 2.5543003858336126

Epoch: 6| Step: 12
Training loss: 0.2049443308037099
Validation loss: 2.533500793113105

Epoch: 6| Step: 13
Training loss: 0.2461643344834427
Validation loss: 2.554577201927574

Epoch: 365| Step: 0
Training loss: 0.33267040442961
Validation loss: 2.501088787452139

Epoch: 6| Step: 1
Training loss: 0.39739796657497983
Validation loss: 2.435874396896033

Epoch: 6| Step: 2
Training loss: 0.185983625669267
Validation loss: 2.5277152321545096

Epoch: 6| Step: 3
Training loss: 0.18466715820070062
Validation loss: 2.540285569054991

Epoch: 6| Step: 4
Training loss: 0.28421127825411197
Validation loss: 2.5257967302528623

Epoch: 6| Step: 5
Training loss: 0.23663940106966727
Validation loss: 2.566342287703579

Epoch: 6| Step: 6
Training loss: 0.23254535504411933
Validation loss: 2.5827939383041145

Epoch: 6| Step: 7
Training loss: 0.514691895707612
Validation loss: 2.5491905997246995

Epoch: 6| Step: 8
Training loss: 0.2766633889615034
Validation loss: 2.5250947153941024

Epoch: 6| Step: 9
Training loss: 0.26457477966259046
Validation loss: 2.5136001841476845

Epoch: 6| Step: 10
Training loss: 0.41799309918077987
Validation loss: 2.4930451291668225

Epoch: 6| Step: 11
Training loss: 0.3683017099011429
Validation loss: 2.4703989758959644

Epoch: 6| Step: 12
Training loss: 0.2912186803882138
Validation loss: 2.4539363677467834

Epoch: 6| Step: 13
Training loss: 0.23836908128768844
Validation loss: 2.4972934058820258

Epoch: 366| Step: 0
Training loss: 0.15810881264197624
Validation loss: 2.4959615394788166

Epoch: 6| Step: 1
Training loss: 0.3287461169633606
Validation loss: 2.5411403194387736

Epoch: 6| Step: 2
Training loss: 0.2174050675316539
Validation loss: 2.5329304521171623

Epoch: 6| Step: 3
Training loss: 0.26525673863285115
Validation loss: 2.560931322619048

Epoch: 6| Step: 4
Training loss: 0.3133732515551829
Validation loss: 2.5833765508256663

Epoch: 6| Step: 5
Training loss: 0.3437881665282596
Validation loss: 2.5256884350858284

Epoch: 6| Step: 6
Training loss: 0.25341720433937576
Validation loss: 2.5026177370548326

Epoch: 6| Step: 7
Training loss: 0.2803562055386398
Validation loss: 2.520384793270522

Epoch: 6| Step: 8
Training loss: 0.33168862560477286
Validation loss: 2.483329809002861

Epoch: 6| Step: 9
Training loss: 0.3624995239846623
Validation loss: 2.4341977565425004

Epoch: 6| Step: 10
Training loss: 0.24489353813016382
Validation loss: 2.467943277013207

Epoch: 6| Step: 11
Training loss: 0.25284078501093377
Validation loss: 2.4778895467896214

Epoch: 6| Step: 12
Training loss: 0.2687890296141032
Validation loss: 2.5185020375205975

Epoch: 6| Step: 13
Training loss: 0.2592779615721732
Validation loss: 2.5154144799264735

Epoch: 367| Step: 0
Training loss: 0.18447021515070694
Validation loss: 2.509457580423739

Epoch: 6| Step: 1
Training loss: 0.27115325494536335
Validation loss: 2.513905745274728

Epoch: 6| Step: 2
Training loss: 0.3190189386384317
Validation loss: 2.4947547086926174

Epoch: 6| Step: 3
Training loss: 0.3229464419798956
Validation loss: 2.542519212748336

Epoch: 6| Step: 4
Training loss: 0.28912535834547926
Validation loss: 2.555236259729797

Epoch: 6| Step: 5
Training loss: 0.3156076879757952
Validation loss: 2.546059038944553

Epoch: 6| Step: 6
Training loss: 0.3382972519682055
Validation loss: 2.4958457763905137

Epoch: 6| Step: 7
Training loss: 0.36992461093748846
Validation loss: 2.569757473123709

Epoch: 6| Step: 8
Training loss: 0.38122826342294425
Validation loss: 2.600573560833532

Epoch: 6| Step: 9
Training loss: 0.21845421207332943
Validation loss: 2.547006022509716

Epoch: 6| Step: 10
Training loss: 0.23630749793712547
Validation loss: 2.5426880134125858

Epoch: 6| Step: 11
Training loss: 0.22259277978375303
Validation loss: 2.500488710319603

Epoch: 6| Step: 12
Training loss: 0.31449161317692564
Validation loss: 2.4989693265489987

Epoch: 6| Step: 13
Training loss: 0.2822905207302206
Validation loss: 2.540748936006403

Epoch: 368| Step: 0
Training loss: 0.292013352561566
Validation loss: 2.47588078274792

Epoch: 6| Step: 1
Training loss: 0.2570174848354835
Validation loss: 2.538149335929746

Epoch: 6| Step: 2
Training loss: 0.19921127941111674
Validation loss: 2.5544295963370014

Epoch: 6| Step: 3
Training loss: 0.25834966820683924
Validation loss: 2.5898498028760693

Epoch: 6| Step: 4
Training loss: 0.30447436483022344
Validation loss: 2.562316244406412

Epoch: 6| Step: 5
Training loss: 0.24187483909512866
Validation loss: 2.5343705866752106

Epoch: 6| Step: 6
Training loss: 0.21444142558107845
Validation loss: 2.508950701067939

Epoch: 6| Step: 7
Training loss: 0.24066042917930178
Validation loss: 2.543612131667517

Epoch: 6| Step: 8
Training loss: 0.23680075367589332
Validation loss: 2.475087862991903

Epoch: 6| Step: 9
Training loss: 0.3175541928553743
Validation loss: 2.497707189749047

Epoch: 6| Step: 10
Training loss: 0.3547200923178793
Validation loss: 2.4901225784239176

Epoch: 6| Step: 11
Training loss: 0.30169044903186504
Validation loss: 2.504950453927517

Epoch: 6| Step: 12
Training loss: 0.3425182359776116
Validation loss: 2.522886548753726

Epoch: 6| Step: 13
Training loss: 0.25725133106083814
Validation loss: 2.5939836205362656

Epoch: 369| Step: 0
Training loss: 0.3264324495091746
Validation loss: 2.5659232495535176

Epoch: 6| Step: 1
Training loss: 0.350633038940343
Validation loss: 2.618611296726163

Epoch: 6| Step: 2
Training loss: 0.3743553979292141
Validation loss: 2.5739901358660697

Epoch: 6| Step: 3
Training loss: 0.2860565865180275
Validation loss: 2.517650965230493

Epoch: 6| Step: 4
Training loss: 0.43307660166842765
Validation loss: 2.5174872098595933

Epoch: 6| Step: 5
Training loss: 0.41007607902645826
Validation loss: 2.524839265825166

Epoch: 6| Step: 6
Training loss: 0.27406845864894225
Validation loss: 2.520212054867291

Epoch: 6| Step: 7
Training loss: 0.3090810911336043
Validation loss: 2.603118934944845

Epoch: 6| Step: 8
Training loss: 0.33712560674282493
Validation loss: 2.6057980933112708

Epoch: 6| Step: 9
Training loss: 0.3111919684486719
Validation loss: 2.63529648085851

Epoch: 6| Step: 10
Training loss: 0.3396327690208898
Validation loss: 2.657084195660954

Epoch: 6| Step: 11
Training loss: 0.26921513582129447
Validation loss: 2.5383460261536226

Epoch: 6| Step: 12
Training loss: 0.24906655480591336
Validation loss: 2.6000229458529973

Epoch: 6| Step: 13
Training loss: 0.3379721570736049
Validation loss: 2.5458184139316096

Epoch: 370| Step: 0
Training loss: 0.27212306577164175
Validation loss: 2.539501907278317

Epoch: 6| Step: 1
Training loss: 0.13767567623078683
Validation loss: 2.534124116282156

Epoch: 6| Step: 2
Training loss: 0.368635043313012
Validation loss: 2.5542308932055184

Epoch: 6| Step: 3
Training loss: 0.27231193214359045
Validation loss: 2.5225221845787393

Epoch: 6| Step: 4
Training loss: 0.24611241406101098
Validation loss: 2.5200250816863083

Epoch: 6| Step: 5
Training loss: 0.19409872558510463
Validation loss: 2.529768121481985

Epoch: 6| Step: 6
Training loss: 0.2540604050046685
Validation loss: 2.5345142494012314

Epoch: 6| Step: 7
Training loss: 0.2458104137401956
Validation loss: 2.5035253622899667

Epoch: 6| Step: 8
Training loss: 0.28948149085212843
Validation loss: 2.4918455489215163

Epoch: 6| Step: 9
Training loss: 0.31879680514296305
Validation loss: 2.4515260640620307

Epoch: 6| Step: 10
Training loss: 0.330658847612244
Validation loss: 2.5285748918025717

Epoch: 6| Step: 11
Training loss: 0.2309343113117726
Validation loss: 2.47934827753784

Epoch: 6| Step: 12
Training loss: 0.17506633655024004
Validation loss: 2.4866617582731236

Epoch: 6| Step: 13
Training loss: 0.25053287875005403
Validation loss: 2.6005422521883528

Epoch: 371| Step: 0
Training loss: 0.13423708919205107
Validation loss: 2.5710799164401332

Epoch: 6| Step: 1
Training loss: 0.2911195889326746
Validation loss: 2.5650316851036425

Epoch: 6| Step: 2
Training loss: 0.40825119830608
Validation loss: 2.504214342735092

Epoch: 6| Step: 3
Training loss: 0.17873185457482926
Validation loss: 2.5646173831797894

Epoch: 6| Step: 4
Training loss: 0.3654387814946391
Validation loss: 2.5102569138808732

Epoch: 6| Step: 5
Training loss: 0.32659982258096326
Validation loss: 2.4968306240296854

Epoch: 6| Step: 6
Training loss: 0.2753097063587487
Validation loss: 2.5340054902346174

Epoch: 6| Step: 7
Training loss: 0.3056521916141
Validation loss: 2.50795844456541

Epoch: 6| Step: 8
Training loss: 0.2904951318145817
Validation loss: 2.513511164501622

Epoch: 6| Step: 9
Training loss: 0.3160085887149176
Validation loss: 2.5893733928975293

Epoch: 6| Step: 10
Training loss: 0.3230201903903389
Validation loss: 2.6412602550225066

Epoch: 6| Step: 11
Training loss: 0.324073368247086
Validation loss: 2.6179807912560435

Epoch: 6| Step: 12
Training loss: 0.28783869074341883
Validation loss: 2.580973921844956

Epoch: 6| Step: 13
Training loss: 0.19883845064522657
Validation loss: 2.5476622505667126

Epoch: 372| Step: 0
Training loss: 0.21750604781424254
Validation loss: 2.5500832226206382

Epoch: 6| Step: 1
Training loss: 0.46826964243369296
Validation loss: 2.4450336008811964

Epoch: 6| Step: 2
Training loss: 0.328893205017035
Validation loss: 2.4981964678956534

Epoch: 6| Step: 3
Training loss: 0.4919545515505296
Validation loss: 2.479287526579997

Epoch: 6| Step: 4
Training loss: 0.2933271885674414
Validation loss: 2.5057160754520265

Epoch: 6| Step: 5
Training loss: 0.2999926297951403
Validation loss: 2.576646739352978

Epoch: 6| Step: 6
Training loss: 0.2827052244878951
Validation loss: 2.5765728063706894

Epoch: 6| Step: 7
Training loss: 0.3467492799352638
Validation loss: 2.5138790635068564

Epoch: 6| Step: 8
Training loss: 0.17060032046869048
Validation loss: 2.5151621232761348

Epoch: 6| Step: 9
Training loss: 0.3338621484731696
Validation loss: 2.514719845643681

Epoch: 6| Step: 10
Training loss: 0.25797649427373587
Validation loss: 2.50328314095511

Epoch: 6| Step: 11
Training loss: 0.36496028713497863
Validation loss: 2.4955218898287264

Epoch: 6| Step: 12
Training loss: 0.3072014678969368
Validation loss: 2.4914507439572686

Epoch: 6| Step: 13
Training loss: 0.2548812047681125
Validation loss: 2.506937311983632

Epoch: 373| Step: 0
Training loss: 0.25471254120336984
Validation loss: 2.5328911535533662

Epoch: 6| Step: 1
Training loss: 0.3060587324643207
Validation loss: 2.5399758911490493

Epoch: 6| Step: 2
Training loss: 0.3132720945927826
Validation loss: 2.550373233644918

Epoch: 6| Step: 3
Training loss: 0.18330682491527223
Validation loss: 2.562189579591521

Epoch: 6| Step: 4
Training loss: 0.24766654044351746
Validation loss: 2.5106478119062996

Epoch: 6| Step: 5
Training loss: 0.324385129222855
Validation loss: 2.530785490514761

Epoch: 6| Step: 6
Training loss: 0.37075493051616276
Validation loss: 2.508859164440416

Epoch: 6| Step: 7
Training loss: 0.2805004994478046
Validation loss: 2.502489185900574

Epoch: 6| Step: 8
Training loss: 0.2688022374240961
Validation loss: 2.4929768459276676

Epoch: 6| Step: 9
Training loss: 0.19319756798748644
Validation loss: 2.5076630053620454

Epoch: 6| Step: 10
Training loss: 0.207102907123681
Validation loss: 2.4744730979370217

Epoch: 6| Step: 11
Training loss: 0.17521679639126894
Validation loss: 2.502189210170395

Epoch: 6| Step: 12
Training loss: 0.19565113275462281
Validation loss: 2.4505700901336227

Epoch: 6| Step: 13
Training loss: 0.2931981523734005
Validation loss: 2.5451808279507526

Epoch: 374| Step: 0
Training loss: 0.29894284309016284
Validation loss: 2.551508863500108

Epoch: 6| Step: 1
Training loss: 0.23868315056670936
Validation loss: 2.5639862619518983

Epoch: 6| Step: 2
Training loss: 0.2622646644945144
Validation loss: 2.5325078625320034

Epoch: 6| Step: 3
Training loss: 0.3142896784243674
Validation loss: 2.538259619905098

Epoch: 6| Step: 4
Training loss: 0.2218390072924031
Validation loss: 2.563649989483271

Epoch: 6| Step: 5
Training loss: 0.30836919267796953
Validation loss: 2.4905120973990784

Epoch: 6| Step: 6
Training loss: 0.2220999896669321
Validation loss: 2.593561464374524

Epoch: 6| Step: 7
Training loss: 0.30754684370564306
Validation loss: 2.5060550318959947

Epoch: 6| Step: 8
Training loss: 0.3428583936476883
Validation loss: 2.59978926428157

Epoch: 6| Step: 9
Training loss: 0.25515618407791135
Validation loss: 2.4971055202515844

Epoch: 6| Step: 10
Training loss: 0.2613128389640531
Validation loss: 2.5084899272598613

Epoch: 6| Step: 11
Training loss: 0.33377900976195857
Validation loss: 2.499301916250924

Epoch: 6| Step: 12
Training loss: 0.3377897961068575
Validation loss: 2.5085016018854334

Epoch: 6| Step: 13
Training loss: 0.2546933518656017
Validation loss: 2.542273970002615

Epoch: 375| Step: 0
Training loss: 0.2939176831614957
Validation loss: 2.4828246375416025

Epoch: 6| Step: 1
Training loss: 0.23307433829415655
Validation loss: 2.503515902446942

Epoch: 6| Step: 2
Training loss: 0.21578856705089802
Validation loss: 2.5459956189722455

Epoch: 6| Step: 3
Training loss: 0.23465925304468957
Validation loss: 2.5015112680037417

Epoch: 6| Step: 4
Training loss: 0.28714811621627095
Validation loss: 2.5500533198099005

Epoch: 6| Step: 5
Training loss: 0.3430564994043982
Validation loss: 2.5443887959793976

Epoch: 6| Step: 6
Training loss: 0.23534961557176587
Validation loss: 2.5730006220990154

Epoch: 6| Step: 7
Training loss: 0.3485447855287514
Validation loss: 2.4819034622367635

Epoch: 6| Step: 8
Training loss: 0.21541677697404538
Validation loss: 2.502124765599925

Epoch: 6| Step: 9
Training loss: 0.32965344980865724
Validation loss: 2.5465099330508387

Epoch: 6| Step: 10
Training loss: 0.3352917963979521
Validation loss: 2.5300604925600862

Epoch: 6| Step: 11
Training loss: 0.21761953791874472
Validation loss: 2.480152324208055

Epoch: 6| Step: 12
Training loss: 0.25974997853360715
Validation loss: 2.544745883433517

Epoch: 6| Step: 13
Training loss: 0.2773141442199205
Validation loss: 2.547535644845908

Epoch: 376| Step: 0
Training loss: 0.344583303277792
Validation loss: 2.5502152800846485

Epoch: 6| Step: 1
Training loss: 0.21247218945784577
Validation loss: 2.5178535967708147

Epoch: 6| Step: 2
Training loss: 0.28401945125766165
Validation loss: 2.525975969122242

Epoch: 6| Step: 3
Training loss: 0.29372960790912206
Validation loss: 2.5447402307655334

Epoch: 6| Step: 4
Training loss: 0.267190108927878
Validation loss: 2.5909344815394713

Epoch: 6| Step: 5
Training loss: 0.2949665364181272
Validation loss: 2.5586882440332412

Epoch: 6| Step: 6
Training loss: 0.2627892733866595
Validation loss: 2.4971390566651976

Epoch: 6| Step: 7
Training loss: 0.293223461052701
Validation loss: 2.582444781623664

Epoch: 6| Step: 8
Training loss: 0.22929352623022958
Validation loss: 2.5476836342554967

Epoch: 6| Step: 9
Training loss: 0.17731143598200294
Validation loss: 2.529951162658483

Epoch: 6| Step: 10
Training loss: 0.22001263116208775
Validation loss: 2.5439666180929645

Epoch: 6| Step: 11
Training loss: 0.25207108685930063
Validation loss: 2.527881468810842

Epoch: 6| Step: 12
Training loss: 0.3231713254765578
Validation loss: 2.542326330869594

Epoch: 6| Step: 13
Training loss: 0.2731418100766368
Validation loss: 2.540907040151766

Epoch: 377| Step: 0
Training loss: 0.27692744750742165
Validation loss: 2.553506436252892

Epoch: 6| Step: 1
Training loss: 0.23182224210733698
Validation loss: 2.5599566763202133

Epoch: 6| Step: 2
Training loss: 0.20037801825593604
Validation loss: 2.525346488596452

Epoch: 6| Step: 3
Training loss: 0.2173530558246912
Validation loss: 2.5769968974842703

Epoch: 6| Step: 4
Training loss: 0.23535771183828524
Validation loss: 2.548876866913518

Epoch: 6| Step: 5
Training loss: 0.35947802352318203
Validation loss: 2.533549453484568

Epoch: 6| Step: 6
Training loss: 0.24961549276815514
Validation loss: 2.603503399624921

Epoch: 6| Step: 7
Training loss: 0.3350390685131406
Validation loss: 2.531098270970725

Epoch: 6| Step: 8
Training loss: 0.25339790220690694
Validation loss: 2.538308071637788

Epoch: 6| Step: 9
Training loss: 0.2350235865809036
Validation loss: 2.5410697632167487

Epoch: 6| Step: 10
Training loss: 0.2340059553839418
Validation loss: 2.5380264515967563

Epoch: 6| Step: 11
Training loss: 0.21365305662537512
Validation loss: 2.550065115801612

Epoch: 6| Step: 12
Training loss: 0.34940998422578595
Validation loss: 2.564187943828262

Epoch: 6| Step: 13
Training loss: 0.1545579849737526
Validation loss: 2.5315568369066033

Epoch: 378| Step: 0
Training loss: 0.3750482567890962
Validation loss: 2.556086881200719

Epoch: 6| Step: 1
Training loss: 0.42044818630845754
Validation loss: 2.529533251465228

Epoch: 6| Step: 2
Training loss: 0.19353762993197485
Validation loss: 2.4712547601150052

Epoch: 6| Step: 3
Training loss: 0.20168434533712845
Validation loss: 2.4917787318294993

Epoch: 6| Step: 4
Training loss: 0.31631159838397394
Validation loss: 2.5355311167036345

Epoch: 6| Step: 5
Training loss: 0.19430163095050362
Validation loss: 2.483751782635998

Epoch: 6| Step: 6
Training loss: 0.30816502305368415
Validation loss: 2.482517123552255

Epoch: 6| Step: 7
Training loss: 0.21613475280916666
Validation loss: 2.487280548102378

Epoch: 6| Step: 8
Training loss: 0.3204766527426255
Validation loss: 2.509341984678524

Epoch: 6| Step: 9
Training loss: 0.28962948326193816
Validation loss: 2.5287359649173173

Epoch: 6| Step: 10
Training loss: 0.29430375154186467
Validation loss: 2.5595534216265134

Epoch: 6| Step: 11
Training loss: 0.2358420788518853
Validation loss: 2.528148226322823

Epoch: 6| Step: 12
Training loss: 0.2500581226733269
Validation loss: 2.5174923633837167

Epoch: 6| Step: 13
Training loss: 0.3048767455802954
Validation loss: 2.563466486835358

Epoch: 379| Step: 0
Training loss: 0.2102237919043601
Validation loss: 2.5382837049934786

Epoch: 6| Step: 1
Training loss: 0.30338208219908724
Validation loss: 2.5204356854600367

Epoch: 6| Step: 2
Training loss: 0.40481909596951865
Validation loss: 2.477518260258509

Epoch: 6| Step: 3
Training loss: 0.20741799956183748
Validation loss: 2.5213526881722603

Epoch: 6| Step: 4
Training loss: 0.39996128789016633
Validation loss: 2.531616702420701

Epoch: 6| Step: 5
Training loss: 0.22736411675269444
Validation loss: 2.537139399044707

Epoch: 6| Step: 6
Training loss: 0.23522415511406977
Validation loss: 2.5893898283723913

Epoch: 6| Step: 7
Training loss: 0.22214405643764085
Validation loss: 2.5566313383760906

Epoch: 6| Step: 8
Training loss: 0.3393730762771403
Validation loss: 2.6159376889530543

Epoch: 6| Step: 9
Training loss: 0.2904778446376359
Validation loss: 2.585167046873407

Epoch: 6| Step: 10
Training loss: 0.25270067252623263
Validation loss: 2.5576960573468615

Epoch: 6| Step: 11
Training loss: 0.29363572809766997
Validation loss: 2.5349167846374008

Epoch: 6| Step: 12
Training loss: 0.2942975364092308
Validation loss: 2.5690325532872387

Epoch: 6| Step: 13
Training loss: 0.26462653375612694
Validation loss: 2.564920817114085

Epoch: 380| Step: 0
Training loss: 0.22031400355373845
Validation loss: 2.572241417827162

Epoch: 6| Step: 1
Training loss: 0.19213690750882453
Validation loss: 2.5878752241336156

Epoch: 6| Step: 2
Training loss: 0.31212508838806613
Validation loss: 2.5911487266230444

Epoch: 6| Step: 3
Training loss: 0.23644188436496297
Validation loss: 2.4913138808580775

Epoch: 6| Step: 4
Training loss: 0.29050103076417094
Validation loss: 2.541026032074892

Epoch: 6| Step: 5
Training loss: 0.17448309934273945
Validation loss: 2.5095029780087788

Epoch: 6| Step: 6
Training loss: 0.20938781763100173
Validation loss: 2.5344624013133155

Epoch: 6| Step: 7
Training loss: 0.28859709311770726
Validation loss: 2.4873030979174877

Epoch: 6| Step: 8
Training loss: 0.29655306074517873
Validation loss: 2.4744283664643327

Epoch: 6| Step: 9
Training loss: 0.27652351891324733
Validation loss: 2.4784899610829525

Epoch: 6| Step: 10
Training loss: 0.3561894164521629
Validation loss: 2.4933174943760856

Epoch: 6| Step: 11
Training loss: 0.135553407099423
Validation loss: 2.5495739465590472

Epoch: 6| Step: 12
Training loss: 0.31523088266548793
Validation loss: 2.5658357122504603

Epoch: 6| Step: 13
Training loss: 0.2510974162604979
Validation loss: 2.5316832999645063

Epoch: 381| Step: 0
Training loss: 0.23558675324038336
Validation loss: 2.540638236136091

Epoch: 6| Step: 1
Training loss: 0.37357221432035076
Validation loss: 2.4944933246358327

Epoch: 6| Step: 2
Training loss: 0.23484436561722058
Validation loss: 2.5418026111288516

Epoch: 6| Step: 3
Training loss: 0.349031514232835
Validation loss: 2.526983126304335

Epoch: 6| Step: 4
Training loss: 0.3450167247961481
Validation loss: 2.472846949386502

Epoch: 6| Step: 5
Training loss: 0.2960146811000326
Validation loss: 2.4894153399961687

Epoch: 6| Step: 6
Training loss: 0.3956534788539188
Validation loss: 2.4884839576703324

Epoch: 6| Step: 7
Training loss: 0.37780024162328174
Validation loss: 2.5479941844195118

Epoch: 6| Step: 8
Training loss: 0.35387539339599516
Validation loss: 2.590337454034832

Epoch: 6| Step: 9
Training loss: 0.24377332141766975
Validation loss: 2.549755799686725

Epoch: 6| Step: 10
Training loss: 0.3364902539754885
Validation loss: 2.5931472077870286

Epoch: 6| Step: 11
Training loss: 0.3195311390100114
Validation loss: 2.579552411355326

Epoch: 6| Step: 12
Training loss: 0.24542863216898794
Validation loss: 2.549681546702656

Epoch: 6| Step: 13
Training loss: 0.2463325900669159
Validation loss: 2.50562069381302

Epoch: 382| Step: 0
Training loss: 0.23860346786204398
Validation loss: 2.4569155327697785

Epoch: 6| Step: 1
Training loss: 0.3813486331238488
Validation loss: 2.5110571559967476

Epoch: 6| Step: 2
Training loss: 0.45810530871321614
Validation loss: 2.494506219662051

Epoch: 6| Step: 3
Training loss: 0.18828646308361677
Validation loss: 2.492522556977025

Epoch: 6| Step: 4
Training loss: 0.24159239903482946
Validation loss: 2.559442514282848

Epoch: 6| Step: 5
Training loss: 0.2904758568028228
Validation loss: 2.589303690592686

Epoch: 6| Step: 6
Training loss: 0.2891622577398914
Validation loss: 2.587184985422589

Epoch: 6| Step: 7
Training loss: 0.28862614817946464
Validation loss: 2.6009849235589533

Epoch: 6| Step: 8
Training loss: 0.28186320637561946
Validation loss: 2.5355172627620592

Epoch: 6| Step: 9
Training loss: 0.2605205694184815
Validation loss: 2.5340622714850873

Epoch: 6| Step: 10
Training loss: 0.22003829882783998
Validation loss: 2.562179824551474

Epoch: 6| Step: 11
Training loss: 0.42972346068671424
Validation loss: 2.5132374381896105

Epoch: 6| Step: 12
Training loss: 0.40039488627329395
Validation loss: 2.539250317009323

Epoch: 6| Step: 13
Training loss: 0.344844981486477
Validation loss: 2.5394202347148065

Epoch: 383| Step: 0
Training loss: 0.21218520718039424
Validation loss: 2.538152146121057

Epoch: 6| Step: 1
Training loss: 0.35115811084425025
Validation loss: 2.6211344549483453

Epoch: 6| Step: 2
Training loss: 0.306364652036355
Validation loss: 2.5791475368236085

Epoch: 6| Step: 3
Training loss: 0.4280326534832258
Validation loss: 2.615178072235239

Epoch: 6| Step: 4
Training loss: 0.21544370112833425
Validation loss: 2.544438919142823

Epoch: 6| Step: 5
Training loss: 0.3031985508279591
Validation loss: 2.5125829812639062

Epoch: 6| Step: 6
Training loss: 0.4423019301555865
Validation loss: 2.504668668698765

Epoch: 6| Step: 7
Training loss: 0.383029389734101
Validation loss: 2.4418356637330634

Epoch: 6| Step: 8
Training loss: 0.28040058295805625
Validation loss: 2.4332140385984227

Epoch: 6| Step: 9
Training loss: 0.22074288879293932
Validation loss: 2.552691147235649

Epoch: 6| Step: 10
Training loss: 0.23886437277956296
Validation loss: 2.515871640074116

Epoch: 6| Step: 11
Training loss: 0.2820977837867997
Validation loss: 2.525685886353058

Epoch: 6| Step: 12
Training loss: 0.3212798096968008
Validation loss: 2.549658792705582

Epoch: 6| Step: 13
Training loss: 0.24432329591878746
Validation loss: 2.5424202338665287

Epoch: 384| Step: 0
Training loss: 0.26688096493167784
Validation loss: 2.5032434960113203

Epoch: 6| Step: 1
Training loss: 0.242057288451842
Validation loss: 2.4727272798883297

Epoch: 6| Step: 2
Training loss: 0.2894176415072681
Validation loss: 2.5017750796064826

Epoch: 6| Step: 3
Training loss: 0.36106471177279315
Validation loss: 2.4515901854527904

Epoch: 6| Step: 4
Training loss: 0.29094887294318267
Validation loss: 2.4602955702510063

Epoch: 6| Step: 5
Training loss: 0.3167354613582793
Validation loss: 2.5062931088793405

Epoch: 6| Step: 6
Training loss: 0.2944011891817547
Validation loss: 2.469510343616607

Epoch: 6| Step: 7
Training loss: 0.3920281766707916
Validation loss: 2.558120054701092

Epoch: 6| Step: 8
Training loss: 0.38896049633081936
Validation loss: 2.5869864634521096

Epoch: 6| Step: 9
Training loss: 0.3587464350347136
Validation loss: 2.587152831273077

Epoch: 6| Step: 10
Training loss: 0.3815709436030687
Validation loss: 2.5548841068313246

Epoch: 6| Step: 11
Training loss: 0.2561544071395088
Validation loss: 2.5239904012517687

Epoch: 6| Step: 12
Training loss: 0.3078272632021221
Validation loss: 2.4792959249015922

Epoch: 6| Step: 13
Training loss: 0.30623023397535337
Validation loss: 2.4944876218111323

Epoch: 385| Step: 0
Training loss: 0.4676797729245371
Validation loss: 2.469326813025788

Epoch: 6| Step: 1
Training loss: 0.2382051471437955
Validation loss: 2.4687681237694283

Epoch: 6| Step: 2
Training loss: 0.23654017904994348
Validation loss: 2.511076477737022

Epoch: 6| Step: 3
Training loss: 0.3170627682295766
Validation loss: 2.5380570049332083

Epoch: 6| Step: 4
Training loss: 0.26374102498101726
Validation loss: 2.548074693268205

Epoch: 6| Step: 5
Training loss: 0.31701374603501314
Validation loss: 2.560594656716928

Epoch: 6| Step: 6
Training loss: 0.27659577261138135
Validation loss: 2.5296556372989145

Epoch: 6| Step: 7
Training loss: 0.22080791989933812
Validation loss: 2.5315818843767297

Epoch: 6| Step: 8
Training loss: 0.31392135437570057
Validation loss: 2.544603102874623

Epoch: 6| Step: 9
Training loss: 0.1550883743781097
Validation loss: 2.5527056395925545

Epoch: 6| Step: 10
Training loss: 0.2845760609315186
Validation loss: 2.507739920670083

Epoch: 6| Step: 11
Training loss: 0.3691641986727113
Validation loss: 2.4916342157995865

Epoch: 6| Step: 12
Training loss: 0.23284387345106605
Validation loss: 2.520487948209694

Epoch: 6| Step: 13
Training loss: 0.3467939054358129
Validation loss: 2.5130312087614035

Epoch: 386| Step: 0
Training loss: 0.21254723528793815
Validation loss: 2.508769738981797

Epoch: 6| Step: 1
Training loss: 0.2819163852007667
Validation loss: 2.5605205395835733

Epoch: 6| Step: 2
Training loss: 0.2582118092056181
Validation loss: 2.584944074186865

Epoch: 6| Step: 3
Training loss: 0.32359080804641477
Validation loss: 2.51958305837904

Epoch: 6| Step: 4
Training loss: 0.25549669258754015
Validation loss: 2.553660770699087

Epoch: 6| Step: 5
Training loss: 0.2938766526038248
Validation loss: 2.4877893429755638

Epoch: 6| Step: 6
Training loss: 0.301475887015993
Validation loss: 2.513777882026009

Epoch: 6| Step: 7
Training loss: 0.25610674482406187
Validation loss: 2.469166949831427

Epoch: 6| Step: 8
Training loss: 0.21179606409033727
Validation loss: 2.491565192164644

Epoch: 6| Step: 9
Training loss: 0.332208922476832
Validation loss: 2.5024935049200736

Epoch: 6| Step: 10
Training loss: 0.31278339887039597
Validation loss: 2.5032733309734247

Epoch: 6| Step: 11
Training loss: 0.15362414244652223
Validation loss: 2.5853181387309045

Epoch: 6| Step: 12
Training loss: 0.27973334346969486
Validation loss: 2.5416719066586704

Epoch: 6| Step: 13
Training loss: 0.29281764902251206
Validation loss: 2.6085021411233025

Epoch: 387| Step: 0
Training loss: 0.24780324550632324
Validation loss: 2.551061571032401

Epoch: 6| Step: 1
Training loss: 0.31055543995688084
Validation loss: 2.5242306276791875

Epoch: 6| Step: 2
Training loss: 0.21107819068541137
Validation loss: 2.5130034029394026

Epoch: 6| Step: 3
Training loss: 0.2541632452067442
Validation loss: 2.493074743491607

Epoch: 6| Step: 4
Training loss: 0.2735818754241176
Validation loss: 2.5012935947404578

Epoch: 6| Step: 5
Training loss: 0.27797093464002004
Validation loss: 2.538051055554998

Epoch: 6| Step: 6
Training loss: 0.22028950950029835
Validation loss: 2.5690246416649667

Epoch: 6| Step: 7
Training loss: 0.34686386159248606
Validation loss: 2.532757165183948

Epoch: 6| Step: 8
Training loss: 0.21574365972085324
Validation loss: 2.489588962266589

Epoch: 6| Step: 9
Training loss: 0.4549384332493474
Validation loss: 2.503609150178092

Epoch: 6| Step: 10
Training loss: 0.18820171377841344
Validation loss: 2.489211894036214

Epoch: 6| Step: 11
Training loss: 0.2292210458407788
Validation loss: 2.5301593974189354

Epoch: 6| Step: 12
Training loss: 0.2819683649431889
Validation loss: 2.4743742636672845

Epoch: 6| Step: 13
Training loss: 0.18867804080847467
Validation loss: 2.5028985227821874

Epoch: 388| Step: 0
Training loss: 0.2560439135905773
Validation loss: 2.5320574567522027

Epoch: 6| Step: 1
Training loss: 0.2613409646476627
Validation loss: 2.5170120143358625

Epoch: 6| Step: 2
Training loss: 0.18815949804888646
Validation loss: 2.535560932197836

Epoch: 6| Step: 3
Training loss: 0.26552027152415947
Validation loss: 2.522568402454581

Epoch: 6| Step: 4
Training loss: 0.32081745632734443
Validation loss: 2.525210361090173

Epoch: 6| Step: 5
Training loss: 0.32382736942216916
Validation loss: 2.5387138088144128

Epoch: 6| Step: 6
Training loss: 0.25636773893618736
Validation loss: 2.5455158796367723

Epoch: 6| Step: 7
Training loss: 0.1471004880671116
Validation loss: 2.4700496648770915

Epoch: 6| Step: 8
Training loss: 0.3337398995074788
Validation loss: 2.4890209717368332

Epoch: 6| Step: 9
Training loss: 0.4055957294006978
Validation loss: 2.4925086473208466

Epoch: 6| Step: 10
Training loss: 0.24405180269015947
Validation loss: 2.524777421803825

Epoch: 6| Step: 11
Training loss: 0.3001235483993195
Validation loss: 2.5199511510791988

Epoch: 6| Step: 12
Training loss: 0.1952771154775764
Validation loss: 2.536182996987556

Epoch: 6| Step: 13
Training loss: 0.3399425560269614
Validation loss: 2.5317090250137797

Epoch: 389| Step: 0
Training loss: 0.23379717169826134
Validation loss: 2.5480458195397744

Epoch: 6| Step: 1
Training loss: 0.2901252721212443
Validation loss: 2.592862762617476

Epoch: 6| Step: 2
Training loss: 0.34813891348780424
Validation loss: 2.539797256968821

Epoch: 6| Step: 3
Training loss: 0.25831485702727774
Validation loss: 2.555698284249963

Epoch: 6| Step: 4
Training loss: 0.30257216999508457
Validation loss: 2.516030494122059

Epoch: 6| Step: 5
Training loss: 0.34515835786851895
Validation loss: 2.502217612579433

Epoch: 6| Step: 6
Training loss: 0.3870942190765966
Validation loss: 2.5011412240999613

Epoch: 6| Step: 7
Training loss: 0.3400302572496182
Validation loss: 2.553680960465288

Epoch: 6| Step: 8
Training loss: 0.31164254330197433
Validation loss: 2.585769140750073

Epoch: 6| Step: 9
Training loss: 0.25417305060222833
Validation loss: 2.592840824341068

Epoch: 6| Step: 10
Training loss: 0.38481242481012246
Validation loss: 2.582375184668345

Epoch: 6| Step: 11
Training loss: 0.2684663662028125
Validation loss: 2.5667290099940896

Epoch: 6| Step: 12
Training loss: 0.24365753443507718
Validation loss: 2.562788226037437

Epoch: 6| Step: 13
Training loss: 0.2132907659203354
Validation loss: 2.5095452554537303

Epoch: 390| Step: 0
Training loss: 0.3626195356988904
Validation loss: 2.4812080302880775

Epoch: 6| Step: 1
Training loss: 0.3610580672324962
Validation loss: 2.4808654387855493

Epoch: 6| Step: 2
Training loss: 0.20043796627036833
Validation loss: 2.504697169909707

Epoch: 6| Step: 3
Training loss: 0.2546250951408167
Validation loss: 2.5584371271316035

Epoch: 6| Step: 4
Training loss: 0.23091411393445693
Validation loss: 2.478572699508666

Epoch: 6| Step: 5
Training loss: 0.22696045750445137
Validation loss: 2.5449247792037824

Epoch: 6| Step: 6
Training loss: 0.1718510806172347
Validation loss: 2.51719935339598

Epoch: 6| Step: 7
Training loss: 0.23114978255419083
Validation loss: 2.541123610989202

Epoch: 6| Step: 8
Training loss: 0.3520648546091036
Validation loss: 2.547574155986643

Epoch: 6| Step: 9
Training loss: 0.22921239963724224
Validation loss: 2.5013255896482325

Epoch: 6| Step: 10
Training loss: 0.30865079618067337
Validation loss: 2.5165283129305918

Epoch: 6| Step: 11
Training loss: 0.27336160423937583
Validation loss: 2.4786322335542583

Epoch: 6| Step: 12
Training loss: 0.2798416054120042
Validation loss: 2.5139220102656163

Epoch: 6| Step: 13
Training loss: 0.2633502694284101
Validation loss: 2.507748184092399

Epoch: 391| Step: 0
Training loss: 0.24422733293022966
Validation loss: 2.4855907992052413

Epoch: 6| Step: 1
Training loss: 0.19739435735534855
Validation loss: 2.4950333374028464

Epoch: 6| Step: 2
Training loss: 0.2733155387275073
Validation loss: 2.502718996608327

Epoch: 6| Step: 3
Training loss: 0.22683837143065358
Validation loss: 2.5008528446816416

Epoch: 6| Step: 4
Training loss: 0.184664626472039
Validation loss: 2.514989041961196

Epoch: 6| Step: 5
Training loss: 0.2695794960738416
Validation loss: 2.559469765137986

Epoch: 6| Step: 6
Training loss: 0.24495383058730927
Validation loss: 2.5276136848673474

Epoch: 6| Step: 7
Training loss: 0.1882298094571877
Validation loss: 2.4807790967577907

Epoch: 6| Step: 8
Training loss: 0.11377269101973606
Validation loss: 2.537746444410546

Epoch: 6| Step: 9
Training loss: 0.3031978627755497
Validation loss: 2.534732510852109

Epoch: 6| Step: 10
Training loss: 0.35285512857568224
Validation loss: 2.505313781189802

Epoch: 6| Step: 11
Training loss: 0.31062730911133457
Validation loss: 2.566435466814881

Epoch: 6| Step: 12
Training loss: 0.27027005375027036
Validation loss: 2.5724080055279916

Epoch: 6| Step: 13
Training loss: 0.25456141527873416
Validation loss: 2.5227453977463283

Epoch: 392| Step: 0
Training loss: 0.2119324847533277
Validation loss: 2.547656495188748

Epoch: 6| Step: 1
Training loss: 0.2127730718714229
Validation loss: 2.5175339305501634

Epoch: 6| Step: 2
Training loss: 0.22678650272841652
Validation loss: 2.489034318175721

Epoch: 6| Step: 3
Training loss: 0.32049143840614003
Validation loss: 2.496835724701167

Epoch: 6| Step: 4
Training loss: 0.2597162587001938
Validation loss: 2.4690529198849553

Epoch: 6| Step: 5
Training loss: 0.22192038689726587
Validation loss: 2.491766085815457

Epoch: 6| Step: 6
Training loss: 0.21465626251980385
Validation loss: 2.5652756196376516

Epoch: 6| Step: 7
Training loss: 0.2602912346441589
Validation loss: 2.573091181861071

Epoch: 6| Step: 8
Training loss: 0.3008997423682753
Validation loss: 2.5425383891680515

Epoch: 6| Step: 9
Training loss: 0.19332095448419542
Validation loss: 2.551862330826076

Epoch: 6| Step: 10
Training loss: 0.20137751355783928
Validation loss: 2.5176530170374543

Epoch: 6| Step: 11
Training loss: 0.1405550994926378
Validation loss: 2.494969353025752

Epoch: 6| Step: 12
Training loss: 0.4292739091445315
Validation loss: 2.473127355387256

Epoch: 6| Step: 13
Training loss: 0.270147227880717
Validation loss: 2.483573184388707

Epoch: 393| Step: 0
Training loss: 0.32504180630145973
Validation loss: 2.4874357406904055

Epoch: 6| Step: 1
Training loss: 0.16973294245029255
Validation loss: 2.455226912904944

Epoch: 6| Step: 2
Training loss: 0.2228244012701122
Validation loss: 2.5037666634995297

Epoch: 6| Step: 3
Training loss: 0.24204611496808798
Validation loss: 2.5362245555094556

Epoch: 6| Step: 4
Training loss: 0.28059955723721464
Validation loss: 2.5593853296266302

Epoch: 6| Step: 5
Training loss: 0.32125879858265505
Validation loss: 2.5487466655395705

Epoch: 6| Step: 6
Training loss: 0.23582177260766557
Validation loss: 2.530775787139735

Epoch: 6| Step: 7
Training loss: 0.27001686853679074
Validation loss: 2.505640271569193

Epoch: 6| Step: 8
Training loss: 0.37789262299071574
Validation loss: 2.5222082539473645

Epoch: 6| Step: 9
Training loss: 0.3098866143444817
Validation loss: 2.4783723718133475

Epoch: 6| Step: 10
Training loss: 0.20634358840305184
Validation loss: 2.4448084611374092

Epoch: 6| Step: 11
Training loss: 0.22018625281026996
Validation loss: 2.492331274463449

Epoch: 6| Step: 12
Training loss: 0.3430309035132737
Validation loss: 2.4932366437914752

Epoch: 6| Step: 13
Training loss: 0.2226920182794586
Validation loss: 2.533471376857525

Epoch: 394| Step: 0
Training loss: 0.1946467592862529
Validation loss: 2.502629343806608

Epoch: 6| Step: 1
Training loss: 0.266777748885679
Validation loss: 2.5249215595411942

Epoch: 6| Step: 2
Training loss: 0.22744031736343373
Validation loss: 2.5494023832007224

Epoch: 6| Step: 3
Training loss: 0.2311928091983907
Validation loss: 2.5285826235465114

Epoch: 6| Step: 4
Training loss: 0.2898611300005437
Validation loss: 2.5081418495553325

Epoch: 6| Step: 5
Training loss: 0.2647961137629771
Validation loss: 2.4900147265135386

Epoch: 6| Step: 6
Training loss: 0.3156945973325211
Validation loss: 2.537928025550038

Epoch: 6| Step: 7
Training loss: 0.31290135835485017
Validation loss: 2.4886074760574064

Epoch: 6| Step: 8
Training loss: 0.22680381551405882
Validation loss: 2.518553488411728

Epoch: 6| Step: 9
Training loss: 0.24727025442023237
Validation loss: 2.5223184472221956

Epoch: 6| Step: 10
Training loss: 0.2731480837915875
Validation loss: 2.5346865774867937

Epoch: 6| Step: 11
Training loss: 0.29191386725767454
Validation loss: 2.5955966212895696

Epoch: 6| Step: 12
Training loss: 0.2881596616388518
Validation loss: 2.5774935324705215

Epoch: 6| Step: 13
Training loss: 0.304054556504685
Validation loss: 2.58107105278324

Epoch: 395| Step: 0
Training loss: 0.2407149493548716
Validation loss: 2.482784313812534

Epoch: 6| Step: 1
Training loss: 0.25865960391889947
Validation loss: 2.539793251714451

Epoch: 6| Step: 2
Training loss: 0.23814876187531472
Validation loss: 2.542296336821317

Epoch: 6| Step: 3
Training loss: 0.19277470751559508
Validation loss: 2.545619280588837

Epoch: 6| Step: 4
Training loss: 0.33110976534639475
Validation loss: 2.5533968574906964

Epoch: 6| Step: 5
Training loss: 0.2249363468121527
Validation loss: 2.577385320421673

Epoch: 6| Step: 6
Training loss: 0.2784096557703463
Validation loss: 2.5892726830528834

Epoch: 6| Step: 7
Training loss: 0.18898406411532143
Validation loss: 2.5478166271001457

Epoch: 6| Step: 8
Training loss: 0.25256840298670746
Validation loss: 2.5098154342597105

Epoch: 6| Step: 9
Training loss: 0.31681250170303016
Validation loss: 2.5668168651510843

Epoch: 6| Step: 10
Training loss: 0.13154559483275077
Validation loss: 2.545778143659661

Epoch: 6| Step: 11
Training loss: 0.27559686608006795
Validation loss: 2.5375662752713777

Epoch: 6| Step: 12
Training loss: 0.17618000049841526
Validation loss: 2.556729293074451

Epoch: 6| Step: 13
Training loss: 0.19980685996387565
Validation loss: 2.5472464261372023

Epoch: 396| Step: 0
Training loss: 0.3513891216427246
Validation loss: 2.497239909841971

Epoch: 6| Step: 1
Training loss: 0.20699198368463453
Validation loss: 2.5118991595192646

Epoch: 6| Step: 2
Training loss: 0.20236715748431086
Validation loss: 2.5402578973128356

Epoch: 6| Step: 3
Training loss: 0.24241316956438577
Validation loss: 2.5894283155188003

Epoch: 6| Step: 4
Training loss: 0.33066571996265554
Validation loss: 2.6035697227403665

Epoch: 6| Step: 5
Training loss: 0.33764410121515254
Validation loss: 2.6271328662515505

Epoch: 6| Step: 6
Training loss: 0.29888077814315367
Validation loss: 2.5434362291400925

Epoch: 6| Step: 7
Training loss: 0.26163488439286153
Validation loss: 2.5916261671853564

Epoch: 6| Step: 8
Training loss: 0.23367676838527793
Validation loss: 2.5488594764544934

Epoch: 6| Step: 9
Training loss: 0.28243646438925385
Validation loss: 2.4684727670033912

Epoch: 6| Step: 10
Training loss: 0.26677765113750856
Validation loss: 2.5044234798427025

Epoch: 6| Step: 11
Training loss: 0.21068930152353704
Validation loss: 2.5169499779909974

Epoch: 6| Step: 12
Training loss: 0.26101391809722335
Validation loss: 2.5412846314609405

Epoch: 6| Step: 13
Training loss: 0.23485974410282295
Validation loss: 2.536911030397809

Epoch: 397| Step: 0
Training loss: 0.27149400762580317
Validation loss: 2.5199216554967157

Epoch: 6| Step: 1
Training loss: 0.27508957281887886
Validation loss: 2.540283723238724

Epoch: 6| Step: 2
Training loss: 0.2543279813384182
Validation loss: 2.4588777429610866

Epoch: 6| Step: 3
Training loss: 0.34503218635436866
Validation loss: 2.556973413578084

Epoch: 6| Step: 4
Training loss: 0.20835709237678116
Validation loss: 2.5049002941133804

Epoch: 6| Step: 5
Training loss: 0.3275044454207359
Validation loss: 2.5201497898290603

Epoch: 6| Step: 6
Training loss: 0.2396408751397445
Validation loss: 2.5354766251415533

Epoch: 6| Step: 7
Training loss: 0.3048991666289489
Validation loss: 2.51590265988684

Epoch: 6| Step: 8
Training loss: 0.20592596001484065
Validation loss: 2.532801070472867

Epoch: 6| Step: 9
Training loss: 0.20911945006398927
Validation loss: 2.502765461106595

Epoch: 6| Step: 10
Training loss: 0.25976239826234726
Validation loss: 2.5477048461983363

Epoch: 6| Step: 11
Training loss: 0.20609817226833566
Validation loss: 2.504842510729535

Epoch: 6| Step: 12
Training loss: 0.187748932498254
Validation loss: 2.492657209595565

Epoch: 6| Step: 13
Training loss: 0.2485172587547577
Validation loss: 2.4957235476675788

Epoch: 398| Step: 0
Training loss: 0.27338865388821465
Validation loss: 2.458229262094175

Epoch: 6| Step: 1
Training loss: 0.22064351652536243
Validation loss: 2.5143540135335183

Epoch: 6| Step: 2
Training loss: 0.2512488910071727
Validation loss: 2.5302467398766817

Epoch: 6| Step: 3
Training loss: 0.265487803762738
Validation loss: 2.515710769991887

Epoch: 6| Step: 4
Training loss: 0.20342850019175204
Validation loss: 2.486455737782341

Epoch: 6| Step: 5
Training loss: 0.252835554479257
Validation loss: 2.5432336555007504

Epoch: 6| Step: 6
Training loss: 0.24412327514035184
Validation loss: 2.577546025780073

Epoch: 6| Step: 7
Training loss: 0.2726968816961503
Validation loss: 2.5598753847150806

Epoch: 6| Step: 8
Training loss: 0.20870116464936958
Validation loss: 2.55125098116761

Epoch: 6| Step: 9
Training loss: 0.30688593097183275
Validation loss: 2.537547531058599

Epoch: 6| Step: 10
Training loss: 0.26528724064906184
Validation loss: 2.5365597484661895

Epoch: 6| Step: 11
Training loss: 0.31036738840879663
Validation loss: 2.5642412906342744

Epoch: 6| Step: 12
Training loss: 0.3140145317377873
Validation loss: 2.6242950719084646

Epoch: 6| Step: 13
Training loss: 0.19516534984132436
Validation loss: 2.527086507213976

Epoch: 399| Step: 0
Training loss: 0.23561776804007406
Validation loss: 2.556122511938904

Epoch: 6| Step: 1
Training loss: 0.10511763283767407
Validation loss: 2.482071806572603

Epoch: 6| Step: 2
Training loss: 0.23219894488790682
Validation loss: 2.550549491257566

Epoch: 6| Step: 3
Training loss: 0.13068989553951454
Validation loss: 2.540784398670426

Epoch: 6| Step: 4
Training loss: 0.40925211481656
Validation loss: 2.491315595481342

Epoch: 6| Step: 5
Training loss: 0.28703499174300867
Validation loss: 2.5253651817556517

Epoch: 6| Step: 6
Training loss: 0.3297624037385782
Validation loss: 2.657180682927302

Epoch: 6| Step: 7
Training loss: 0.24726091353280316
Validation loss: 2.614225162933493

Epoch: 6| Step: 8
Training loss: 0.2788353955535953
Validation loss: 2.6374423016207693

Epoch: 6| Step: 9
Training loss: 0.3587637139068404
Validation loss: 2.5698559480216305

Epoch: 6| Step: 10
Training loss: 0.20369425199647603
Validation loss: 2.543122973944006

Epoch: 6| Step: 11
Training loss: 0.18624914682756138
Validation loss: 2.5084487725833036

Epoch: 6| Step: 12
Training loss: 0.26889222174432
Validation loss: 2.493734933653073

Epoch: 6| Step: 13
Training loss: 0.45494100444967406
Validation loss: 2.4367295539227514

Epoch: 400| Step: 0
Training loss: 0.23677986098998874
Validation loss: 2.4463844915216963

Epoch: 6| Step: 1
Training loss: 0.2874180956978544
Validation loss: 2.5169845287689667

Epoch: 6| Step: 2
Training loss: 0.37461034080532024
Validation loss: 2.5165097909837075

Epoch: 6| Step: 3
Training loss: 0.2452103563123715
Validation loss: 2.555030589732417

Epoch: 6| Step: 4
Training loss: 0.28630753218015986
Validation loss: 2.5672520715104157

Epoch: 6| Step: 5
Training loss: 0.20878083129872804
Validation loss: 2.566531088786346

Epoch: 6| Step: 6
Training loss: 0.22569303736288843
Validation loss: 2.524648259783378

Epoch: 6| Step: 7
Training loss: 0.3579055348679514
Validation loss: 2.5157338942184992

Epoch: 6| Step: 8
Training loss: 0.28484226603076973
Validation loss: 2.488099040132609

Epoch: 6| Step: 9
Training loss: 0.2770561284976875
Validation loss: 2.5561399307119608

Epoch: 6| Step: 10
Training loss: 0.18651269212698438
Validation loss: 2.5281083661676838

Epoch: 6| Step: 11
Training loss: 0.3006640366887174
Validation loss: 2.5627429273254267

Epoch: 6| Step: 12
Training loss: 0.19631008016691348
Validation loss: 2.554393615306366

Epoch: 6| Step: 13
Training loss: 0.17597485053513623
Validation loss: 2.5509261381740624

Epoch: 401| Step: 0
Training loss: 0.2130409549888016
Validation loss: 2.5451983840555163

Epoch: 6| Step: 1
Training loss: 0.261227588102911
Validation loss: 2.5338078906599306

Epoch: 6| Step: 2
Training loss: 0.24232260719415877
Validation loss: 2.5522917188827545

Epoch: 6| Step: 3
Training loss: 0.267914720432298
Validation loss: 2.5325863061993545

Epoch: 6| Step: 4
Training loss: 0.17544432245000566
Validation loss: 2.492260476442039

Epoch: 6| Step: 5
Training loss: 0.3400288877767107
Validation loss: 2.5152361077570617

Epoch: 6| Step: 6
Training loss: 0.305353927495786
Validation loss: 2.540498814375897

Epoch: 6| Step: 7
Training loss: 0.2204234621614536
Validation loss: 2.561439201549325

Epoch: 6| Step: 8
Training loss: 0.2691748100462199
Validation loss: 2.5530116877474467

Epoch: 6| Step: 9
Training loss: 0.3563999512954961
Validation loss: 2.562486260850252

Epoch: 6| Step: 10
Training loss: 0.24346808306309273
Validation loss: 2.580925070175402

Epoch: 6| Step: 11
Training loss: 0.1458565865154596
Validation loss: 2.4970840455713077

Epoch: 6| Step: 12
Training loss: 0.20635340042170977
Validation loss: 2.5636102085697727

Epoch: 6| Step: 13
Training loss: 0.15871130598449368
Validation loss: 2.51115911170868

Epoch: 402| Step: 0
Training loss: 0.31122442023555524
Validation loss: 2.4944380719991543

Epoch: 6| Step: 1
Training loss: 0.3859031438014413
Validation loss: 2.4989216545140773

Epoch: 6| Step: 2
Training loss: 0.24529156048814918
Validation loss: 2.5015597405181156

Epoch: 6| Step: 3
Training loss: 0.21991414857778877
Validation loss: 2.497585831708349

Epoch: 6| Step: 4
Training loss: 0.2627441474306297
Validation loss: 2.5958620457620136

Epoch: 6| Step: 5
Training loss: 0.2608112429495529
Validation loss: 2.567115271572449

Epoch: 6| Step: 6
Training loss: 0.320707275605379
Validation loss: 2.5041420478901255

Epoch: 6| Step: 7
Training loss: 0.21483700481576795
Validation loss: 2.5463441478843998

Epoch: 6| Step: 8
Training loss: 0.2601387671017592
Validation loss: 2.5100883385259127

Epoch: 6| Step: 9
Training loss: 0.2007695220609413
Validation loss: 2.467285913200169

Epoch: 6| Step: 10
Training loss: 0.35325444304958326
Validation loss: 2.4526724995342155

Epoch: 6| Step: 11
Training loss: 0.2914188331157677
Validation loss: 2.473456126319859

Epoch: 6| Step: 12
Training loss: 0.23442000116022563
Validation loss: 2.4906061111940088

Epoch: 6| Step: 13
Training loss: 0.17203922986883
Validation loss: 2.492040384667998

Epoch: 403| Step: 0
Training loss: 0.26321000513384535
Validation loss: 2.507447545956742

Epoch: 6| Step: 1
Training loss: 0.1970701854694059
Validation loss: 2.553559967304922

Epoch: 6| Step: 2
Training loss: 0.23174705633435855
Validation loss: 2.522194933381902

Epoch: 6| Step: 3
Training loss: 0.3106827228841137
Validation loss: 2.521138926707008

Epoch: 6| Step: 4
Training loss: 0.29468640659974893
Validation loss: 2.5623093665940693

Epoch: 6| Step: 5
Training loss: 0.19345392940062223
Validation loss: 2.5092985161336374

Epoch: 6| Step: 6
Training loss: 0.31635104981211004
Validation loss: 2.5267059606283055

Epoch: 6| Step: 7
Training loss: 0.2423683229798602
Validation loss: 2.4728265254735216

Epoch: 6| Step: 8
Training loss: 0.23317910906198835
Validation loss: 2.501326550760034

Epoch: 6| Step: 9
Training loss: 0.25342508353828136
Validation loss: 2.5203413575190203

Epoch: 6| Step: 10
Training loss: 0.30616032591518083
Validation loss: 2.522736844795244

Epoch: 6| Step: 11
Training loss: 0.30075360455972955
Validation loss: 2.5420707605494224

Epoch: 6| Step: 12
Training loss: 0.26742341796982627
Validation loss: 2.5062483190592695

Epoch: 6| Step: 13
Training loss: 0.1539949952754449
Validation loss: 2.4997736351527924

Epoch: 404| Step: 0
Training loss: 0.23401506919970583
Validation loss: 2.474772306687076

Epoch: 6| Step: 1
Training loss: 0.36917299804826675
Validation loss: 2.4735745557292095

Epoch: 6| Step: 2
Training loss: 0.1639626914650463
Validation loss: 2.4584348275090218

Epoch: 6| Step: 3
Training loss: 0.2764993762592158
Validation loss: 2.570089761499887

Epoch: 6| Step: 4
Training loss: 0.25479609742656817
Validation loss: 2.5397554361694685

Epoch: 6| Step: 5
Training loss: 0.2745024514983447
Validation loss: 2.5593255236590067

Epoch: 6| Step: 6
Training loss: 0.20467623432111534
Validation loss: 2.5177753332774695

Epoch: 6| Step: 7
Training loss: 0.1880218376826745
Validation loss: 2.5422466559581762

Epoch: 6| Step: 8
Training loss: 0.24128829240791852
Validation loss: 2.546732518241799

Epoch: 6| Step: 9
Training loss: 0.2896563384199692
Validation loss: 2.5185612035881277

Epoch: 6| Step: 10
Training loss: 0.3166728133098622
Validation loss: 2.5449719876644465

Epoch: 6| Step: 11
Training loss: 0.2810825405674203
Validation loss: 2.4840340530315768

Epoch: 6| Step: 12
Training loss: 0.2502237451196968
Validation loss: 2.506177628788997

Epoch: 6| Step: 13
Training loss: 0.21085615708961683
Validation loss: 2.500860225181645

Epoch: 405| Step: 0
Training loss: 0.1904671167611876
Validation loss: 2.4924298749552447

Epoch: 6| Step: 1
Training loss: 0.1938470412852336
Validation loss: 2.4935306847806156

Epoch: 6| Step: 2
Training loss: 0.20986145679076673
Validation loss: 2.555002253407619

Epoch: 6| Step: 3
Training loss: 0.22844695012992924
Validation loss: 2.5251084612852117

Epoch: 6| Step: 4
Training loss: 0.2686884876205562
Validation loss: 2.5261749914057776

Epoch: 6| Step: 5
Training loss: 0.28001914633701647
Validation loss: 2.5211574461678334

Epoch: 6| Step: 6
Training loss: 0.2773268385553244
Validation loss: 2.560420650316641

Epoch: 6| Step: 7
Training loss: 0.29483321417182023
Validation loss: 2.5150483143705333

Epoch: 6| Step: 8
Training loss: 0.3523144415869072
Validation loss: 2.509944346356781

Epoch: 6| Step: 9
Training loss: 0.3237958240850015
Validation loss: 2.4768757105622647

Epoch: 6| Step: 10
Training loss: 0.2695301719312254
Validation loss: 2.4956956763879568

Epoch: 6| Step: 11
Training loss: 0.18586758453145868
Validation loss: 2.4443593224120472

Epoch: 6| Step: 12
Training loss: 0.373518421072469
Validation loss: 2.482654047447705

Epoch: 6| Step: 13
Training loss: 0.22507936812974122
Validation loss: 2.553533318629322

Epoch: 406| Step: 0
Training loss: 0.29660144550186035
Validation loss: 2.5428376913602357

Epoch: 6| Step: 1
Training loss: 0.34276382997965044
Validation loss: 2.533237854095257

Epoch: 6| Step: 2
Training loss: 0.24782585449602484
Validation loss: 2.551314504126643

Epoch: 6| Step: 3
Training loss: 0.35821212374533684
Validation loss: 2.533916034838373

Epoch: 6| Step: 4
Training loss: 0.2032099509495181
Validation loss: 2.5030243699780677

Epoch: 6| Step: 5
Training loss: 0.23643314770800122
Validation loss: 2.5359417717678894

Epoch: 6| Step: 6
Training loss: 0.2883279721201731
Validation loss: 2.511927815976991

Epoch: 6| Step: 7
Training loss: 0.2006433451218378
Validation loss: 2.4708398391633692

Epoch: 6| Step: 8
Training loss: 0.31171572738749953
Validation loss: 2.524159677503583

Epoch: 6| Step: 9
Training loss: 0.2380176399289413
Validation loss: 2.5081399721620343

Epoch: 6| Step: 10
Training loss: 0.20437032170730363
Validation loss: 2.4779324277542583

Epoch: 6| Step: 11
Training loss: 0.24157636969056756
Validation loss: 2.51940190577132

Epoch: 6| Step: 12
Training loss: 0.19865494776357903
Validation loss: 2.524098312730287

Epoch: 6| Step: 13
Training loss: 0.2519886376245156
Validation loss: 2.5133963480578876

Epoch: 407| Step: 0
Training loss: 0.277030929591063
Validation loss: 2.4905861679617347

Epoch: 6| Step: 1
Training loss: 0.22113044690334316
Validation loss: 2.531245196302589

Epoch: 6| Step: 2
Training loss: 0.16044075050226497
Validation loss: 2.519745289781969

Epoch: 6| Step: 3
Training loss: 0.20999448641282867
Validation loss: 2.53166645846974

Epoch: 6| Step: 4
Training loss: 0.35459822652957435
Validation loss: 2.5590094619318657

Epoch: 6| Step: 5
Training loss: 0.21621512638986115
Validation loss: 2.529417999784349

Epoch: 6| Step: 6
Training loss: 0.36745846672602145
Validation loss: 2.5209371897423503

Epoch: 6| Step: 7
Training loss: 0.25105791962642554
Validation loss: 2.5428538259856572

Epoch: 6| Step: 8
Training loss: 0.25100136422835206
Validation loss: 2.5454493005629377

Epoch: 6| Step: 9
Training loss: 0.32278834633879677
Validation loss: 2.566057557949834

Epoch: 6| Step: 10
Training loss: 0.19438241757409913
Validation loss: 2.473859778331787

Epoch: 6| Step: 11
Training loss: 0.2486374575172792
Validation loss: 2.5141392144700183

Epoch: 6| Step: 12
Training loss: 0.2857211670408763
Validation loss: 2.4993921176648235

Epoch: 6| Step: 13
Training loss: 0.25840856542367624
Validation loss: 2.563709655821227

Epoch: 408| Step: 0
Training loss: 0.2096517548601601
Validation loss: 2.505878078740745

Epoch: 6| Step: 1
Training loss: 0.32532265034431473
Validation loss: 2.5223516405356285

Epoch: 6| Step: 2
Training loss: 0.20035894266162366
Validation loss: 2.5521710646724363

Epoch: 6| Step: 3
Training loss: 0.2627059905991147
Validation loss: 2.5114863769239744

Epoch: 6| Step: 4
Training loss: 0.16490343830197654
Validation loss: 2.554441885461789

Epoch: 6| Step: 5
Training loss: 0.2458019191395819
Validation loss: 2.5376139103169066

Epoch: 6| Step: 6
Training loss: 0.2761998832776971
Validation loss: 2.550766310519078

Epoch: 6| Step: 7
Training loss: 0.1522628801841208
Validation loss: 2.516228739633961

Epoch: 6| Step: 8
Training loss: 0.28993313071857907
Validation loss: 2.49952921408226

Epoch: 6| Step: 9
Training loss: 0.27746407491098907
Validation loss: 2.5384872489129577

Epoch: 6| Step: 10
Training loss: 0.26194858423080897
Validation loss: 2.514729105325256

Epoch: 6| Step: 11
Training loss: 0.28400790866061804
Validation loss: 2.4746171870380547

Epoch: 6| Step: 12
Training loss: 0.38226218469359197
Validation loss: 2.5284007798689205

Epoch: 6| Step: 13
Training loss: 0.22602388880443555
Validation loss: 2.499769184265677

Epoch: 409| Step: 0
Training loss: 0.2228502382177244
Validation loss: 2.533783951218058

Epoch: 6| Step: 1
Training loss: 0.29588859214392604
Validation loss: 2.569483923966733

Epoch: 6| Step: 2
Training loss: 0.2582750361687998
Validation loss: 2.5262715317005

Epoch: 6| Step: 3
Training loss: 0.21521621842139607
Validation loss: 2.4979235370362276

Epoch: 6| Step: 4
Training loss: 0.26021345156931625
Validation loss: 2.5146359697051355

Epoch: 6| Step: 5
Training loss: 0.1636517127644391
Validation loss: 2.5343684543285203

Epoch: 6| Step: 6
Training loss: 0.22341158389800783
Validation loss: 2.5026278433471987

Epoch: 6| Step: 7
Training loss: 0.3261155748032488
Validation loss: 2.5516333098902515

Epoch: 6| Step: 8
Training loss: 0.2081139701062721
Validation loss: 2.581085455070373

Epoch: 6| Step: 9
Training loss: 0.25436858119879796
Validation loss: 2.570209180307095

Epoch: 6| Step: 10
Training loss: 0.149568590028239
Validation loss: 2.5374285561036034

Epoch: 6| Step: 11
Training loss: 0.19119848925834618
Validation loss: 2.521086567120899

Epoch: 6| Step: 12
Training loss: 0.2107159280900589
Validation loss: 2.5341208547281244

Epoch: 6| Step: 13
Training loss: 0.2576506135322881
Validation loss: 2.5134044031657026

Epoch: 410| Step: 0
Training loss: 0.29325793934259464
Validation loss: 2.5127114825340606

Epoch: 6| Step: 1
Training loss: 0.222447766189566
Validation loss: 2.512913176185673

Epoch: 6| Step: 2
Training loss: 0.24869400374178688
Validation loss: 2.4924320910100874

Epoch: 6| Step: 3
Training loss: 0.2541199151931605
Validation loss: 2.5798053236266685

Epoch: 6| Step: 4
Training loss: 0.23331105020820134
Validation loss: 2.4612096646092123

Epoch: 6| Step: 5
Training loss: 0.2941783602194146
Validation loss: 2.4849837974746736

Epoch: 6| Step: 6
Training loss: 0.19128814284181667
Validation loss: 2.448209791016044

Epoch: 6| Step: 7
Training loss: 0.23104653428720026
Validation loss: 2.484743047039041

Epoch: 6| Step: 8
Training loss: 0.24495056081701033
Validation loss: 2.5138754042257325

Epoch: 6| Step: 9
Training loss: 0.30568748603747453
Validation loss: 2.4704113452493974

Epoch: 6| Step: 10
Training loss: 0.29467802513885694
Validation loss: 2.479096909885323

Epoch: 6| Step: 11
Training loss: 0.35139732719277694
Validation loss: 2.5278365742013373

Epoch: 6| Step: 12
Training loss: 0.24269777808478848
Validation loss: 2.4753777270316903

Epoch: 6| Step: 13
Training loss: 0.28683665031709227
Validation loss: 2.533652589992824

Epoch: 411| Step: 0
Training loss: 0.32028961099860115
Validation loss: 2.510951599860112

Epoch: 6| Step: 1
Training loss: 0.34014950075756345
Validation loss: 2.4901697965738063

Epoch: 6| Step: 2
Training loss: 0.228590716552424
Validation loss: 2.5529457633247525

Epoch: 6| Step: 3
Training loss: 0.26180815237282506
Validation loss: 2.5283563974024648

Epoch: 6| Step: 4
Training loss: 0.2591588383490971
Validation loss: 2.5434996582489955

Epoch: 6| Step: 5
Training loss: 0.26140802356599424
Validation loss: 2.5546609330813124

Epoch: 6| Step: 6
Training loss: 0.20016851478420147
Validation loss: 2.4795732458626625

Epoch: 6| Step: 7
Training loss: 0.3186586997228023
Validation loss: 2.5392274695380843

Epoch: 6| Step: 8
Training loss: 0.31361295875978895
Validation loss: 2.536562223611061

Epoch: 6| Step: 9
Training loss: 0.27275707872664795
Validation loss: 2.5019796480732945

Epoch: 6| Step: 10
Training loss: 0.18980257506136133
Validation loss: 2.5438162099108688

Epoch: 6| Step: 11
Training loss: 0.2477975102517565
Validation loss: 2.57502304116221

Epoch: 6| Step: 12
Training loss: 0.3005569042439285
Validation loss: 2.508927522241153

Epoch: 6| Step: 13
Training loss: 0.22374059753268616
Validation loss: 2.558028724151726

Epoch: 412| Step: 0
Training loss: 0.19174300950449283
Validation loss: 2.5431372552018447

Epoch: 6| Step: 1
Training loss: 0.316533075040214
Validation loss: 2.55938531410086

Epoch: 6| Step: 2
Training loss: 0.19741336087102146
Validation loss: 2.56672357603453

Epoch: 6| Step: 3
Training loss: 0.25547083990892905
Validation loss: 2.605369615551411

Epoch: 6| Step: 4
Training loss: 0.24460779887069004
Validation loss: 2.5444721674577226

Epoch: 6| Step: 5
Training loss: 0.26967843501303723
Validation loss: 2.5652040465349124

Epoch: 6| Step: 6
Training loss: 0.35036586984475987
Validation loss: 2.5532077310543793

Epoch: 6| Step: 7
Training loss: 0.31354707299236356
Validation loss: 2.5019837773887517

Epoch: 6| Step: 8
Training loss: 0.23094364312948307
Validation loss: 2.553616127019285

Epoch: 6| Step: 9
Training loss: 0.3275006120981801
Validation loss: 2.5648679569654043

Epoch: 6| Step: 10
Training loss: 0.17631968579866947
Validation loss: 2.5503456791462713

Epoch: 6| Step: 11
Training loss: 0.14945203012004563
Validation loss: 2.537239406152

Epoch: 6| Step: 12
Training loss: 0.2118829273608819
Validation loss: 2.496982828039201

Epoch: 6| Step: 13
Training loss: 0.2943843211988295
Validation loss: 2.461625131279459

Epoch: 413| Step: 0
Training loss: 0.29834900887204663
Validation loss: 2.4617921344323683

Epoch: 6| Step: 1
Training loss: 0.25066883800131345
Validation loss: 2.5083284094963876

Epoch: 6| Step: 2
Training loss: 0.3264243467946838
Validation loss: 2.526196903033796

Epoch: 6| Step: 3
Training loss: 0.29534594886307564
Validation loss: 2.4611896688449373

Epoch: 6| Step: 4
Training loss: 0.19104063381309677
Validation loss: 2.482821260584457

Epoch: 6| Step: 5
Training loss: 0.20897865287576387
Validation loss: 2.4849336024137645

Epoch: 6| Step: 6
Training loss: 0.25308389271038023
Validation loss: 2.520562438491139

Epoch: 6| Step: 7
Training loss: 0.30202366250538265
Validation loss: 2.4934606698188344

Epoch: 6| Step: 8
Training loss: 0.20642327161222201
Validation loss: 2.507994711526084

Epoch: 6| Step: 9
Training loss: 0.15938131749964843
Validation loss: 2.5464206126399582

Epoch: 6| Step: 10
Training loss: 0.26339577241443435
Validation loss: 2.5159560907754415

Epoch: 6| Step: 11
Training loss: 0.21107549921647906
Validation loss: 2.5152495994606734

Epoch: 6| Step: 12
Training loss: 0.23300146716192122
Validation loss: 2.4984685578204133

Epoch: 6| Step: 13
Training loss: 0.24164747204408424
Validation loss: 2.5656345238704374

Epoch: 414| Step: 0
Training loss: 0.2076501054048443
Validation loss: 2.515000291423642

Epoch: 6| Step: 1
Training loss: 0.3283008036357294
Validation loss: 2.515699405241139

Epoch: 6| Step: 2
Training loss: 0.17861281238992846
Validation loss: 2.5322888679651077

Epoch: 6| Step: 3
Training loss: 0.23350819197789838
Validation loss: 2.510006033420277

Epoch: 6| Step: 4
Training loss: 0.2159137351019131
Validation loss: 2.5532491291925776

Epoch: 6| Step: 5
Training loss: 0.25977762811219957
Validation loss: 2.555029524404267

Epoch: 6| Step: 6
Training loss: 0.3369401672864831
Validation loss: 2.552253333417726

Epoch: 6| Step: 7
Training loss: 0.176002860776859
Validation loss: 2.5146288350646766

Epoch: 6| Step: 8
Training loss: 0.19623780411589128
Validation loss: 2.4685671050493347

Epoch: 6| Step: 9
Training loss: 0.2904655967939344
Validation loss: 2.4606822451662738

Epoch: 6| Step: 10
Training loss: 0.3694509584327457
Validation loss: 2.427663059880206

Epoch: 6| Step: 11
Training loss: 0.22170128065973074
Validation loss: 2.5429681874639356

Epoch: 6| Step: 12
Training loss: 0.2684888863145949
Validation loss: 2.5006600541747996

Epoch: 6| Step: 13
Training loss: 0.31178673167828175
Validation loss: 2.5364414869893963

Epoch: 415| Step: 0
Training loss: 0.2536480985118654
Validation loss: 2.5533360319729215

Epoch: 6| Step: 1
Training loss: 0.14500549197073023
Validation loss: 2.5296359940724913

Epoch: 6| Step: 2
Training loss: 0.28469143177001527
Validation loss: 2.553324935847817

Epoch: 6| Step: 3
Training loss: 0.2476025303481783
Validation loss: 2.5285459761278886

Epoch: 6| Step: 4
Training loss: 0.253814475272805
Validation loss: 2.5048560742790964

Epoch: 6| Step: 5
Training loss: 0.16605552866957562
Validation loss: 2.5056376310788036

Epoch: 6| Step: 6
Training loss: 0.31688326917012416
Validation loss: 2.4688168126332535

Epoch: 6| Step: 7
Training loss: 0.3534370039878218
Validation loss: 2.5223684575792067

Epoch: 6| Step: 8
Training loss: 0.20477848869824322
Validation loss: 2.478757693646999

Epoch: 6| Step: 9
Training loss: 0.17586989287008417
Validation loss: 2.5281471968196247

Epoch: 6| Step: 10
Training loss: 0.33061562739393824
Validation loss: 2.5190716937964126

Epoch: 6| Step: 11
Training loss: 0.3424825711236084
Validation loss: 2.4983535590274553

Epoch: 6| Step: 12
Training loss: 0.20182372472457732
Validation loss: 2.4831792004860795

Epoch: 6| Step: 13
Training loss: 0.22196050326186148
Validation loss: 2.5143791494035788

Epoch: 416| Step: 0
Training loss: 0.3815619029259911
Validation loss: 2.5035228148021993

Epoch: 6| Step: 1
Training loss: 0.3480127414187758
Validation loss: 2.4769118149914178

Epoch: 6| Step: 2
Training loss: 0.2510234032051201
Validation loss: 2.480255934829771

Epoch: 6| Step: 3
Training loss: 0.24627482095513803
Validation loss: 2.5255040858468614

Epoch: 6| Step: 4
Training loss: 0.29395564115000267
Validation loss: 2.5057980536601367

Epoch: 6| Step: 5
Training loss: 0.2676541436241095
Validation loss: 2.486155969213869

Epoch: 6| Step: 6
Training loss: 0.22116218357015033
Validation loss: 2.564912668170397

Epoch: 6| Step: 7
Training loss: 0.19144893676278762
Validation loss: 2.5129293052858572

Epoch: 6| Step: 8
Training loss: 0.1934848147318502
Validation loss: 2.498963999665613

Epoch: 6| Step: 9
Training loss: 0.2344534265909667
Validation loss: 2.5269770171928427

Epoch: 6| Step: 10
Training loss: 0.23904361089244125
Validation loss: 2.4899639227116195

Epoch: 6| Step: 11
Training loss: 0.19805259282512683
Validation loss: 2.5278612223209493

Epoch: 6| Step: 12
Training loss: 0.25321952679602155
Validation loss: 2.523059639527095

Epoch: 6| Step: 13
Training loss: 0.21565563081089442
Validation loss: 2.4866586741642007

Epoch: 417| Step: 0
Training loss: 0.23686908254051253
Validation loss: 2.576037530912439

Epoch: 6| Step: 1
Training loss: 0.1749563890850907
Validation loss: 2.5184381997192333

Epoch: 6| Step: 2
Training loss: 0.31630914870022375
Validation loss: 2.5257774975213207

Epoch: 6| Step: 3
Training loss: 0.26032655428421775
Validation loss: 2.485080538838296

Epoch: 6| Step: 4
Training loss: 0.14999381887098226
Validation loss: 2.46794418672126

Epoch: 6| Step: 5
Training loss: 0.18039938638193165
Validation loss: 2.5210587870976386

Epoch: 6| Step: 6
Training loss: 0.33217822916940837
Validation loss: 2.5621042798916327

Epoch: 6| Step: 7
Training loss: 0.16699516003734868
Validation loss: 2.523300820695083

Epoch: 6| Step: 8
Training loss: 0.20955885600748195
Validation loss: 2.4969724681483734

Epoch: 6| Step: 9
Training loss: 0.22380542340418802
Validation loss: 2.505933895772104

Epoch: 6| Step: 10
Training loss: 0.23154794051336225
Validation loss: 2.515525578968746

Epoch: 6| Step: 11
Training loss: 0.16862325897972272
Validation loss: 2.532898625033843

Epoch: 6| Step: 12
Training loss: 0.294216069327291
Validation loss: 2.4911376750944587

Epoch: 6| Step: 13
Training loss: 0.2802453242965954
Validation loss: 2.545444047532583

Epoch: 418| Step: 0
Training loss: 0.28714527502538206
Validation loss: 2.566592886615702

Epoch: 6| Step: 1
Training loss: 0.3000178868206665
Validation loss: 2.555032074970192

Epoch: 6| Step: 2
Training loss: 0.25369048120551885
Validation loss: 2.511608851091597

Epoch: 6| Step: 3
Training loss: 0.356334658652542
Validation loss: 2.5286221462178777

Epoch: 6| Step: 4
Training loss: 0.3325639154554275
Validation loss: 2.489787892725591

Epoch: 6| Step: 5
Training loss: 0.35167749431552914
Validation loss: 2.5888774559367036

Epoch: 6| Step: 6
Training loss: 0.18572451470312043
Validation loss: 2.521963730408838

Epoch: 6| Step: 7
Training loss: 0.2860219695182857
Validation loss: 2.5218461316680854

Epoch: 6| Step: 8
Training loss: 0.22392086151747614
Validation loss: 2.540168466563059

Epoch: 6| Step: 9
Training loss: 0.18169569390765336
Validation loss: 2.5481679322018804

Epoch: 6| Step: 10
Training loss: 0.31577770769113417
Validation loss: 2.5390576484829452

Epoch: 6| Step: 11
Training loss: 0.40931204246207675
Validation loss: 2.558607028606407

Epoch: 6| Step: 12
Training loss: 0.20692561711648744
Validation loss: 2.5091992482561927

Epoch: 6| Step: 13
Training loss: 0.3133786009789701
Validation loss: 2.4681881051888497

Epoch: 419| Step: 0
Training loss: 0.3210196945664037
Validation loss: 2.440850587807522

Epoch: 6| Step: 1
Training loss: 0.35640128922009867
Validation loss: 2.4807609165767346

Epoch: 6| Step: 2
Training loss: 0.16143770560400286
Validation loss: 2.4846859783298605

Epoch: 6| Step: 3
Training loss: 0.268832392593562
Validation loss: 2.4888563384849145

Epoch: 6| Step: 4
Training loss: 0.2540644079749053
Validation loss: 2.516497916654486

Epoch: 6| Step: 5
Training loss: 0.2427685136364773
Validation loss: 2.5067118747883765

Epoch: 6| Step: 6
Training loss: 0.3166448847072154
Validation loss: 2.527525701168907

Epoch: 6| Step: 7
Training loss: 0.20184915843709758
Validation loss: 2.4930211091089562

Epoch: 6| Step: 8
Training loss: 0.20457332790236366
Validation loss: 2.4631696881261673

Epoch: 6| Step: 9
Training loss: 0.2906310721757747
Validation loss: 2.4704756922326054

Epoch: 6| Step: 10
Training loss: 0.170319464742359
Validation loss: 2.4707240328701983

Epoch: 6| Step: 11
Training loss: 0.21214226771517516
Validation loss: 2.4853808927772643

Epoch: 6| Step: 12
Training loss: 0.30345339143196387
Validation loss: 2.486363948335206

Epoch: 6| Step: 13
Training loss: 0.27886093904243975
Validation loss: 2.514366767194056

Epoch: 420| Step: 0
Training loss: 0.23301822226614258
Validation loss: 2.501461960572892

Epoch: 6| Step: 1
Training loss: 0.24670845039230463
Validation loss: 2.5505103862710263

Epoch: 6| Step: 2
Training loss: 0.36008797285932365
Validation loss: 2.4756943618134755

Epoch: 6| Step: 3
Training loss: 0.17412363072984516
Validation loss: 2.488793799900886

Epoch: 6| Step: 4
Training loss: 0.27775264202409883
Validation loss: 2.531227865240074

Epoch: 6| Step: 5
Training loss: 0.3977906267995573
Validation loss: 2.433300239411975

Epoch: 6| Step: 6
Training loss: 0.2782935949518533
Validation loss: 2.5069752342280034

Epoch: 6| Step: 7
Training loss: 0.23713986830732964
Validation loss: 2.4672333770860932

Epoch: 6| Step: 8
Training loss: 0.20428108460651745
Validation loss: 2.4746727778485016

Epoch: 6| Step: 9
Training loss: 0.33623145793289544
Validation loss: 2.4900670692240623

Epoch: 6| Step: 10
Training loss: 0.22079072749697679
Validation loss: 2.457908720318454

Epoch: 6| Step: 11
Training loss: 0.24657695500653626
Validation loss: 2.5238235383060217

Epoch: 6| Step: 12
Training loss: 0.27230713033996357
Validation loss: 2.552929832566085

Epoch: 6| Step: 13
Training loss: 0.3090785600367875
Validation loss: 2.5691542020460925

Epoch: 421| Step: 0
Training loss: 0.20022975346251007
Validation loss: 2.560069668450182

Epoch: 6| Step: 1
Training loss: 0.26789010787384415
Validation loss: 2.5724795481119385

Epoch: 6| Step: 2
Training loss: 0.2742086435830294
Validation loss: 2.49129320161107

Epoch: 6| Step: 3
Training loss: 0.17273190230450577
Validation loss: 2.493518342465651

Epoch: 6| Step: 4
Training loss: 0.3359602321651682
Validation loss: 2.5018248732385695

Epoch: 6| Step: 5
Training loss: 0.2828508224656742
Validation loss: 2.4470007028198064

Epoch: 6| Step: 6
Training loss: 0.25176140047983586
Validation loss: 2.4842647791950045

Epoch: 6| Step: 7
Training loss: 0.22100614321755643
Validation loss: 2.454381244477599

Epoch: 6| Step: 8
Training loss: 0.19801879849325696
Validation loss: 2.49561132028424

Epoch: 6| Step: 9
Training loss: 0.25789077610865446
Validation loss: 2.502375650177738

Epoch: 6| Step: 10
Training loss: 0.20415939533818436
Validation loss: 2.5479999936177182

Epoch: 6| Step: 11
Training loss: 0.4455681451853765
Validation loss: 2.523397124511712

Epoch: 6| Step: 12
Training loss: 0.266810422695792
Validation loss: 2.5140302432756685

Epoch: 6| Step: 13
Training loss: 0.23653327297737115
Validation loss: 2.444430272345449

Epoch: 422| Step: 0
Training loss: 0.14724986652277547
Validation loss: 2.5124030162508735

Epoch: 6| Step: 1
Training loss: 0.21243342029753914
Validation loss: 2.4371605824265856

Epoch: 6| Step: 2
Training loss: 0.2309386909412859
Validation loss: 2.5052567845428957

Epoch: 6| Step: 3
Training loss: 0.30530365973083656
Validation loss: 2.4922449151164963

Epoch: 6| Step: 4
Training loss: 0.24058875640788427
Validation loss: 2.5181291646474016

Epoch: 6| Step: 5
Training loss: 0.24758178180992518
Validation loss: 2.5255791833930967

Epoch: 6| Step: 6
Training loss: 0.27481598115771866
Validation loss: 2.485011085316669

Epoch: 6| Step: 7
Training loss: 0.16166944443226938
Validation loss: 2.535207856627268

Epoch: 6| Step: 8
Training loss: 0.25776527434636975
Validation loss: 2.55671316830282

Epoch: 6| Step: 9
Training loss: 0.5146253026869196
Validation loss: 2.486787564284976

Epoch: 6| Step: 10
Training loss: 0.30164701779578224
Validation loss: 2.5130598206864136

Epoch: 6| Step: 11
Training loss: 0.2683362870369721
Validation loss: 2.5626933017177507

Epoch: 6| Step: 12
Training loss: 0.23583181932275632
Validation loss: 2.4494531206004386

Epoch: 6| Step: 13
Training loss: 0.24444950400987034
Validation loss: 2.4566122485189155

Epoch: 423| Step: 0
Training loss: 0.2467926108223457
Validation loss: 2.519568375503689

Epoch: 6| Step: 1
Training loss: 0.23194882794592048
Validation loss: 2.4777912497213603

Epoch: 6| Step: 2
Training loss: 0.20954310515203234
Validation loss: 2.5185567701256413

Epoch: 6| Step: 3
Training loss: 0.23786501409916094
Validation loss: 2.5487048044979206

Epoch: 6| Step: 4
Training loss: 0.24336675445977576
Validation loss: 2.55250432700632

Epoch: 6| Step: 5
Training loss: 0.2252739735017012
Validation loss: 2.5204453340492314

Epoch: 6| Step: 6
Training loss: 0.2558351170346169
Validation loss: 2.528334858109533

Epoch: 6| Step: 7
Training loss: 0.21055619780047738
Validation loss: 2.4991115262863035

Epoch: 6| Step: 8
Training loss: 0.3565953605146798
Validation loss: 2.458781982689651

Epoch: 6| Step: 9
Training loss: 0.28966643418358345
Validation loss: 2.54580311754675

Epoch: 6| Step: 10
Training loss: 0.2785442321552679
Validation loss: 2.4753647564377133

Epoch: 6| Step: 11
Training loss: 0.20083784871611543
Validation loss: 2.426772418320399

Epoch: 6| Step: 12
Training loss: 0.26220708807974824
Validation loss: 2.470606077999755

Epoch: 6| Step: 13
Training loss: 0.2391279140435439
Validation loss: 2.494440246444923

Epoch: 424| Step: 0
Training loss: 0.2768703772888743
Validation loss: 2.5285792448401776

Epoch: 6| Step: 1
Training loss: 0.23718666940978403
Validation loss: 2.520926857361499

Epoch: 6| Step: 2
Training loss: 0.2835883316068873
Validation loss: 2.538822589201518

Epoch: 6| Step: 3
Training loss: 0.22913296769643599
Validation loss: 2.504748309454852

Epoch: 6| Step: 4
Training loss: 0.1917041484492346
Validation loss: 2.4936723102651386

Epoch: 6| Step: 5
Training loss: 0.2390739824616645
Validation loss: 2.463744952878745

Epoch: 6| Step: 6
Training loss: 0.2531107398125335
Validation loss: 2.466449696002406

Epoch: 6| Step: 7
Training loss: 0.23615361698657034
Validation loss: 2.510339566915929

Epoch: 6| Step: 8
Training loss: 0.3190573313982836
Validation loss: 2.461202423529649

Epoch: 6| Step: 9
Training loss: 0.26719776323472283
Validation loss: 2.498366314842287

Epoch: 6| Step: 10
Training loss: 0.2840571975213112
Validation loss: 2.4895643023371368

Epoch: 6| Step: 11
Training loss: 0.36009302142816974
Validation loss: 2.5118965493371213

Epoch: 6| Step: 12
Training loss: 0.18165756474742165
Validation loss: 2.522356319387114

Epoch: 6| Step: 13
Training loss: 0.22767324134186803
Validation loss: 2.530597791122718

Epoch: 425| Step: 0
Training loss: 0.31793083414746737
Validation loss: 2.5590634368684833

Epoch: 6| Step: 1
Training loss: 0.28479037916389627
Validation loss: 2.581316735095394

Epoch: 6| Step: 2
Training loss: 0.2266018274309319
Validation loss: 2.5519085155998376

Epoch: 6| Step: 3
Training loss: 0.3268034411196369
Validation loss: 2.4998293579991984

Epoch: 6| Step: 4
Training loss: 0.22351848395131524
Validation loss: 2.497747089610197

Epoch: 6| Step: 5
Training loss: 0.2013241275069268
Validation loss: 2.48541356417219

Epoch: 6| Step: 6
Training loss: 0.1970104039514121
Validation loss: 2.5176068194095462

Epoch: 6| Step: 7
Training loss: 0.19586689467843962
Validation loss: 2.5413212984499944

Epoch: 6| Step: 8
Training loss: 0.254328288937482
Validation loss: 2.5508796630070028

Epoch: 6| Step: 9
Training loss: 0.3017200211745617
Validation loss: 2.5397254586969007

Epoch: 6| Step: 10
Training loss: 0.2924928869499252
Validation loss: 2.4953504718334982

Epoch: 6| Step: 11
Training loss: 0.21336968792659167
Validation loss: 2.5329012410273104

Epoch: 6| Step: 12
Training loss: 0.2634388494400451
Validation loss: 2.5353038805594057

Epoch: 6| Step: 13
Training loss: 0.3283998155979006
Validation loss: 2.512716203057388

Epoch: 426| Step: 0
Training loss: 0.276742484907307
Validation loss: 2.583027165225627

Epoch: 6| Step: 1
Training loss: 0.15301594013114272
Validation loss: 2.5186659714507837

Epoch: 6| Step: 2
Training loss: 0.2682704878277509
Validation loss: 2.5396726999891683

Epoch: 6| Step: 3
Training loss: 0.19960403584545444
Validation loss: 2.5523444191385245

Epoch: 6| Step: 4
Training loss: 0.29345304514991155
Validation loss: 2.5592884004044767

Epoch: 6| Step: 5
Training loss: 0.38297992081460597
Validation loss: 2.5425932060494203

Epoch: 6| Step: 6
Training loss: 0.244899911823545
Validation loss: 2.5591847909152876

Epoch: 6| Step: 7
Training loss: 0.25255418394388246
Validation loss: 2.541965284680239

Epoch: 6| Step: 8
Training loss: 0.3082615476674389
Validation loss: 2.538283086627152

Epoch: 6| Step: 9
Training loss: 0.38955710351671113
Validation loss: 2.5519382487467372

Epoch: 6| Step: 10
Training loss: 0.3008747946196086
Validation loss: 2.5295323796157536

Epoch: 6| Step: 11
Training loss: 0.3017634172135121
Validation loss: 2.506250015537836

Epoch: 6| Step: 12
Training loss: 0.29001636608985387
Validation loss: 2.53414026718497

Epoch: 6| Step: 13
Training loss: 0.2566434479765753
Validation loss: 2.4871641413152594

Epoch: 427| Step: 0
Training loss: 0.24691286460611234
Validation loss: 2.4699284440974374

Epoch: 6| Step: 1
Training loss: 0.27852628347753233
Validation loss: 2.5096883759441453

Epoch: 6| Step: 2
Training loss: 0.3111271744556696
Validation loss: 2.5384217064999484

Epoch: 6| Step: 3
Training loss: 0.2614062564528351
Validation loss: 2.515747122633707

Epoch: 6| Step: 4
Training loss: 0.3423761853514058
Validation loss: 2.5615259195486133

Epoch: 6| Step: 5
Training loss: 0.20792850361468548
Validation loss: 2.5354254157971456

Epoch: 6| Step: 6
Training loss: 0.16556434442861528
Validation loss: 2.560072951270813

Epoch: 6| Step: 7
Training loss: 0.2228477056438681
Validation loss: 2.5262966590988007

Epoch: 6| Step: 8
Training loss: 0.247610444125878
Validation loss: 2.53266006409505

Epoch: 6| Step: 9
Training loss: 0.250133538343963
Validation loss: 2.460885119006855

Epoch: 6| Step: 10
Training loss: 0.2822120425175187
Validation loss: 2.5247810180684604

Epoch: 6| Step: 11
Training loss: 0.34944801229603983
Validation loss: 2.4286269626024737

Epoch: 6| Step: 12
Training loss: 0.17501024595136913
Validation loss: 2.4591233928996212

Epoch: 6| Step: 13
Training loss: 0.1701460598117795
Validation loss: 2.5114888609575168

Epoch: 428| Step: 0
Training loss: 0.23809530476018562
Validation loss: 2.5789644974543653

Epoch: 6| Step: 1
Training loss: 0.43485691178114116
Validation loss: 2.5247839297012837

Epoch: 6| Step: 2
Training loss: 0.17913540735644193
Validation loss: 2.495463268269311

Epoch: 6| Step: 3
Training loss: 0.2233446421772874
Validation loss: 2.5106269832746015

Epoch: 6| Step: 4
Training loss: 0.17430042011891003
Validation loss: 2.4913959182775436

Epoch: 6| Step: 5
Training loss: 0.3492736376441138
Validation loss: 2.541889725470428

Epoch: 6| Step: 6
Training loss: 0.3832521249783126
Validation loss: 2.49376184688549

Epoch: 6| Step: 7
Training loss: 0.21593256659054616
Validation loss: 2.4951095192748483

Epoch: 6| Step: 8
Training loss: 0.3063356620330284
Validation loss: 2.517440977620047

Epoch: 6| Step: 9
Training loss: 0.22446979663938912
Validation loss: 2.5534802071838976

Epoch: 6| Step: 10
Training loss: 0.2863726473303288
Validation loss: 2.554561771328165

Epoch: 6| Step: 11
Training loss: 0.19086204743983412
Validation loss: 2.5481989721034815

Epoch: 6| Step: 12
Training loss: 0.27633511791920345
Validation loss: 2.5294123521363603

Epoch: 6| Step: 13
Training loss: 0.3145412890125055
Validation loss: 2.473620925113725

Epoch: 429| Step: 0
Training loss: 0.30107417024654726
Validation loss: 2.493989888622198

Epoch: 6| Step: 1
Training loss: 0.2994816558845012
Validation loss: 2.544644383339994

Epoch: 6| Step: 2
Training loss: 0.258889866035984
Validation loss: 2.513336736295641

Epoch: 6| Step: 3
Training loss: 0.23363399988130062
Validation loss: 2.5387294766078448

Epoch: 6| Step: 4
Training loss: 0.201834873132426
Validation loss: 2.57433336974279

Epoch: 6| Step: 5
Training loss: 0.20389955736189874
Validation loss: 2.5400648906508754

Epoch: 6| Step: 6
Training loss: 0.3293551817619405
Validation loss: 2.514101771713168

Epoch: 6| Step: 7
Training loss: 0.2956642508307729
Validation loss: 2.552487459429037

Epoch: 6| Step: 8
Training loss: 0.1164458489109751
Validation loss: 2.5736868988596924

Epoch: 6| Step: 9
Training loss: 0.20147020015724218
Validation loss: 2.5470103362464926

Epoch: 6| Step: 10
Training loss: 0.25587854968722323
Validation loss: 2.5954916901175857

Epoch: 6| Step: 11
Training loss: 0.14305216226853587
Validation loss: 2.504206535754025

Epoch: 6| Step: 12
Training loss: 0.30410576574303194
Validation loss: 2.4763857982024526

Epoch: 6| Step: 13
Training loss: 0.2592338195016761
Validation loss: 2.4514425870389083

Epoch: 430| Step: 0
Training loss: 0.1891174488766293
Validation loss: 2.4416132724726194

Epoch: 6| Step: 1
Training loss: 0.21255390416189318
Validation loss: 2.5352302701123617

Epoch: 6| Step: 2
Training loss: 0.1895370101053425
Validation loss: 2.476746063970645

Epoch: 6| Step: 3
Training loss: 0.25404785315791434
Validation loss: 2.5357895164535997

Epoch: 6| Step: 4
Training loss: 0.18424819408460807
Validation loss: 2.523987606779888

Epoch: 6| Step: 5
Training loss: 0.2311607414109403
Validation loss: 2.5360990239770245

Epoch: 6| Step: 6
Training loss: 0.4178464835476004
Validation loss: 2.543800807761023

Epoch: 6| Step: 7
Training loss: 0.16123116121657505
Validation loss: 2.464046407746618

Epoch: 6| Step: 8
Training loss: 0.2986528468475485
Validation loss: 2.501708805683212

Epoch: 6| Step: 9
Training loss: 0.24366730393711475
Validation loss: 2.462575788993708

Epoch: 6| Step: 10
Training loss: 0.3659289685956133
Validation loss: 2.4767176181417683

Epoch: 6| Step: 11
Training loss: 0.16964363469038865
Validation loss: 2.5000261782229254

Epoch: 6| Step: 12
Training loss: 0.1968522035933723
Validation loss: 2.4837990499055036

Epoch: 6| Step: 13
Training loss: 0.26126245320677755
Validation loss: 2.561205048285315

Epoch: 431| Step: 0
Training loss: 0.20199322846483223
Validation loss: 2.502174147313835

Epoch: 6| Step: 1
Training loss: 0.3451135856470686
Validation loss: 2.5543675509099115

Epoch: 6| Step: 2
Training loss: 0.26506399769664596
Validation loss: 2.5588339656439043

Epoch: 6| Step: 3
Training loss: 0.28173367977516706
Validation loss: 2.5476589283582545

Epoch: 6| Step: 4
Training loss: 0.27981028019610593
Validation loss: 2.507640139478721

Epoch: 6| Step: 5
Training loss: 0.19679151346763524
Validation loss: 2.4995386810646942

Epoch: 6| Step: 6
Training loss: 0.2538677773305178
Validation loss: 2.5129895433971647

Epoch: 6| Step: 7
Training loss: 0.1554911185232011
Validation loss: 2.549419388088091

Epoch: 6| Step: 8
Training loss: 0.20158541866975363
Validation loss: 2.542853029023512

Epoch: 6| Step: 9
Training loss: 0.3164505633182367
Validation loss: 2.493618585156237

Epoch: 6| Step: 10
Training loss: 0.22628150154229387
Validation loss: 2.5185644537371634

Epoch: 6| Step: 11
Training loss: 0.1712427322383904
Validation loss: 2.5393113234449

Epoch: 6| Step: 12
Training loss: 0.35411575129045597
Validation loss: 2.536968412293615

Epoch: 6| Step: 13
Training loss: 0.321747959398736
Validation loss: 2.527306329920846

Epoch: 432| Step: 0
Training loss: 0.2872337279612071
Validation loss: 2.4793721736285717

Epoch: 6| Step: 1
Training loss: 0.3487574998158561
Validation loss: 2.460599910448944

Epoch: 6| Step: 2
Training loss: 0.275689537749092
Validation loss: 2.515159642870397

Epoch: 6| Step: 3
Training loss: 0.23154358849669768
Validation loss: 2.5046407700381823

Epoch: 6| Step: 4
Training loss: 0.1814966451509551
Validation loss: 2.50659761879899

Epoch: 6| Step: 5
Training loss: 0.2632265781269777
Validation loss: 2.5484908892981535

Epoch: 6| Step: 6
Training loss: 0.3176605535235389
Validation loss: 2.5502890812567096

Epoch: 6| Step: 7
Training loss: 0.32044487055617754
Validation loss: 2.568872343987766

Epoch: 6| Step: 8
Training loss: 0.3132260352395653
Validation loss: 2.5085091182879347

Epoch: 6| Step: 9
Training loss: 0.2236804161879313
Validation loss: 2.464411315224714

Epoch: 6| Step: 10
Training loss: 0.22005365397477775
Validation loss: 2.495298192176892

Epoch: 6| Step: 11
Training loss: 0.3636285290971371
Validation loss: 2.4698185197798814

Epoch: 6| Step: 12
Training loss: 0.16672906725706263
Validation loss: 2.5227516273637187

Epoch: 6| Step: 13
Training loss: 0.2220696703415899
Validation loss: 2.5350117223419684

Epoch: 433| Step: 0
Training loss: 0.18776918003690887
Validation loss: 2.5176710018430573

Epoch: 6| Step: 1
Training loss: 0.2417350203075405
Validation loss: 2.5618561501828188

Epoch: 6| Step: 2
Training loss: 0.2674164387949726
Validation loss: 2.5830317572461547

Epoch: 6| Step: 3
Training loss: 0.2941928974124102
Validation loss: 2.5612262878760075

Epoch: 6| Step: 4
Training loss: 0.2730414383201007
Validation loss: 2.563311053064726

Epoch: 6| Step: 5
Training loss: 0.27788217423925105
Validation loss: 2.546392757887733

Epoch: 6| Step: 6
Training loss: 0.3820083307049389
Validation loss: 2.4893716432173822

Epoch: 6| Step: 7
Training loss: 0.260392200592246
Validation loss: 2.554416762694209

Epoch: 6| Step: 8
Training loss: 0.304966395453749
Validation loss: 2.545972574508319

Epoch: 6| Step: 9
Training loss: 0.25743414830774003
Validation loss: 2.53703726572292

Epoch: 6| Step: 10
Training loss: 0.2692661363695002
Validation loss: 2.6193410790541605

Epoch: 6| Step: 11
Training loss: 0.26825822592545484
Validation loss: 2.550792232565728

Epoch: 6| Step: 12
Training loss: 0.25421707495083035
Validation loss: 2.5064205691925747

Epoch: 6| Step: 13
Training loss: 0.21028351068153117
Validation loss: 2.544114081019125

Epoch: 434| Step: 0
Training loss: 0.3102249300077828
Validation loss: 2.48391773806171

Epoch: 6| Step: 1
Training loss: 0.2902786857696236
Validation loss: 2.498985203774357

Epoch: 6| Step: 2
Training loss: 0.3129163352890055
Validation loss: 2.4757862338586416

Epoch: 6| Step: 3
Training loss: 0.25176653495457935
Validation loss: 2.489515995301398

Epoch: 6| Step: 4
Training loss: 0.3481481051696269
Validation loss: 2.526615114436813

Epoch: 6| Step: 5
Training loss: 0.21615072995503143
Validation loss: 2.520138657958428

Epoch: 6| Step: 6
Training loss: 0.3049611305655446
Validation loss: 2.522369891158063

Epoch: 6| Step: 7
Training loss: 0.29453020424492754
Validation loss: 2.5842076688300133

Epoch: 6| Step: 8
Training loss: 0.2269211183522357
Validation loss: 2.565355152431232

Epoch: 6| Step: 9
Training loss: 0.23123796244813777
Validation loss: 2.542066626009029

Epoch: 6| Step: 10
Training loss: 0.1954620932856636
Validation loss: 2.545738621982718

Epoch: 6| Step: 11
Training loss: 0.18600567761851583
Validation loss: 2.5293556000361685

Epoch: 6| Step: 12
Training loss: 0.29949324892631407
Validation loss: 2.52038588112547

Epoch: 6| Step: 13
Training loss: 0.2413328148585905
Validation loss: 2.4997619833493836

Epoch: 435| Step: 0
Training loss: 0.3878996956524364
Validation loss: 2.450537513624791

Epoch: 6| Step: 1
Training loss: 0.38328204261022913
Validation loss: 2.494452528443674

Epoch: 6| Step: 2
Training loss: 0.288493860096775
Validation loss: 2.5828758778135747

Epoch: 6| Step: 3
Training loss: 0.19480484792069003
Validation loss: 2.4873390829411273

Epoch: 6| Step: 4
Training loss: 0.2683986973723085
Validation loss: 2.5410577690896825

Epoch: 6| Step: 5
Training loss: 0.2525857479551011
Validation loss: 2.5181573399291026

Epoch: 6| Step: 6
Training loss: 0.24455905914615758
Validation loss: 2.6052902137633165

Epoch: 6| Step: 7
Training loss: 0.2246947499433262
Validation loss: 2.607268924489486

Epoch: 6| Step: 8
Training loss: 0.2584368053735995
Validation loss: 2.566794146947205

Epoch: 6| Step: 9
Training loss: 0.17352542882134547
Validation loss: 2.555111537820438

Epoch: 6| Step: 10
Training loss: 0.2897504404408594
Validation loss: 2.4877345484149997

Epoch: 6| Step: 11
Training loss: 0.31876574365219
Validation loss: 2.482104849712237

Epoch: 6| Step: 12
Training loss: 0.1810637100424213
Validation loss: 2.570530906295059

Epoch: 6| Step: 13
Training loss: 0.17141760306024534
Validation loss: 2.605670179580963

Epoch: 436| Step: 0
Training loss: 0.30810747584249937
Validation loss: 2.5519792392807052

Epoch: 6| Step: 1
Training loss: 0.1150796870341212
Validation loss: 2.5852685852636967

Epoch: 6| Step: 2
Training loss: 0.19077741712801813
Validation loss: 2.578122426041368

Epoch: 6| Step: 3
Training loss: 0.2731423010682216
Validation loss: 2.5205379081780745

Epoch: 6| Step: 4
Training loss: 0.21874335823875246
Validation loss: 2.5173318415434642

Epoch: 6| Step: 5
Training loss: 0.29564948357618115
Validation loss: 2.526921767195866

Epoch: 6| Step: 6
Training loss: 0.32703029719914256
Validation loss: 2.5529192794538225

Epoch: 6| Step: 7
Training loss: 0.2194719152937933
Validation loss: 2.5029310210808973

Epoch: 6| Step: 8
Training loss: 0.19212101778893276
Validation loss: 2.550652212994681

Epoch: 6| Step: 9
Training loss: 0.3098118558734218
Validation loss: 2.554176209407568

Epoch: 6| Step: 10
Training loss: 0.20944537360800067
Validation loss: 2.605764529526882

Epoch: 6| Step: 11
Training loss: 0.27861138900397725
Validation loss: 2.6281103749875627

Epoch: 6| Step: 12
Training loss: 0.32164352945680036
Validation loss: 2.6412990244046592

Epoch: 6| Step: 13
Training loss: 0.2825786941349625
Validation loss: 2.5974145609535753

Epoch: 437| Step: 0
Training loss: 0.20892555977848037
Validation loss: 2.557216096733927

Epoch: 6| Step: 1
Training loss: 0.336602240848732
Validation loss: 2.5349731379182385

Epoch: 6| Step: 2
Training loss: 0.2267552082395219
Validation loss: 2.51709300107909

Epoch: 6| Step: 3
Training loss: 0.23533445114042723
Validation loss: 2.483621399021471

Epoch: 6| Step: 4
Training loss: 0.31634171145584133
Validation loss: 2.466261949930759

Epoch: 6| Step: 5
Training loss: 0.26963016519387306
Validation loss: 2.5288844102433603

Epoch: 6| Step: 6
Training loss: 0.2942324911586678
Validation loss: 2.5447392313975117

Epoch: 6| Step: 7
Training loss: 0.3355057625680741
Validation loss: 2.5400436774826316

Epoch: 6| Step: 8
Training loss: 0.3217988766772127
Validation loss: 2.46763909370112

Epoch: 6| Step: 9
Training loss: 0.24276852898150753
Validation loss: 2.4703387689128733

Epoch: 6| Step: 10
Training loss: 0.2049420950101932
Validation loss: 2.4473927904494235

Epoch: 6| Step: 11
Training loss: 0.45303148093845597
Validation loss: 2.500458850077804

Epoch: 6| Step: 12
Training loss: 0.27155890230839996
Validation loss: 2.521349898656931

Epoch: 6| Step: 13
Training loss: 0.23619955679854335
Validation loss: 2.4923252318778086

Epoch: 438| Step: 0
Training loss: 0.29244661214825707
Validation loss: 2.529858940838655

Epoch: 6| Step: 1
Training loss: 0.27402967634868297
Validation loss: 2.5688063238671766

Epoch: 6| Step: 2
Training loss: 0.29676754161115587
Validation loss: 2.6356338793434864

Epoch: 6| Step: 3
Training loss: 0.3575270034355131
Validation loss: 2.607758506732502

Epoch: 6| Step: 4
Training loss: 0.3454315174627615
Validation loss: 2.5484072828655115

Epoch: 6| Step: 5
Training loss: 0.2543312623759189
Validation loss: 2.546366361912777

Epoch: 6| Step: 6
Training loss: 0.2316940194615543
Validation loss: 2.496946385222144

Epoch: 6| Step: 7
Training loss: 0.4343718686436916
Validation loss: 2.5246506679092797

Epoch: 6| Step: 8
Training loss: 0.23343915065503507
Validation loss: 2.5163304384314045

Epoch: 6| Step: 9
Training loss: 0.294522374876968
Validation loss: 2.5626178962444444

Epoch: 6| Step: 10
Training loss: 0.27142062913910564
Validation loss: 2.57025848300992

Epoch: 6| Step: 11
Training loss: 0.2666733753334022
Validation loss: 2.5545877793007445

Epoch: 6| Step: 12
Training loss: 0.26873829893765894
Validation loss: 2.5432387685714937

Epoch: 6| Step: 13
Training loss: 0.2920829733879458
Validation loss: 2.523929087466397

Epoch: 439| Step: 0
Training loss: 0.23298880410821265
Validation loss: 2.5193299284549684

Epoch: 6| Step: 1
Training loss: 0.24096144000653025
Validation loss: 2.5377447533291284

Epoch: 6| Step: 2
Training loss: 0.28861237610923296
Validation loss: 2.5399828372585738

Epoch: 6| Step: 3
Training loss: 0.32796799218470535
Validation loss: 2.537955754008892

Epoch: 6| Step: 4
Training loss: 0.29617791149817113
Validation loss: 2.5202651578930904

Epoch: 6| Step: 5
Training loss: 0.2553757617881194
Validation loss: 2.581589338274469

Epoch: 6| Step: 6
Training loss: 0.19683432877979568
Validation loss: 2.5216891488533077

Epoch: 6| Step: 7
Training loss: 0.28844104152997396
Validation loss: 2.589592612217437

Epoch: 6| Step: 8
Training loss: 0.4265781783970953
Validation loss: 2.5677292276787123

Epoch: 6| Step: 9
Training loss: 0.2686168806713742
Validation loss: 2.583715346506455

Epoch: 6| Step: 10
Training loss: 0.33199494107252725
Validation loss: 2.553866706605024

Epoch: 6| Step: 11
Training loss: 0.34748723711617036
Validation loss: 2.587937978635154

Epoch: 6| Step: 12
Training loss: 0.20500270728324002
Validation loss: 2.520754022112498

Epoch: 6| Step: 13
Training loss: 0.4268420766921507
Validation loss: 2.4955457823170306

Epoch: 440| Step: 0
Training loss: 0.2598893867462719
Validation loss: 2.5218485818619185

Epoch: 6| Step: 1
Training loss: 0.22920891343471964
Validation loss: 2.539443002213255

Epoch: 6| Step: 2
Training loss: 0.23215182026390407
Validation loss: 2.554559204737569

Epoch: 6| Step: 3
Training loss: 0.3025463627918921
Validation loss: 2.532907759428064

Epoch: 6| Step: 4
Training loss: 0.2744489898717607
Validation loss: 2.5610766993845204

Epoch: 6| Step: 5
Training loss: 0.19307541466835992
Validation loss: 2.531990005893278

Epoch: 6| Step: 6
Training loss: 0.2570976403478639
Validation loss: 2.5337874170798522

Epoch: 6| Step: 7
Training loss: 0.2505175924719373
Validation loss: 2.504789651844905

Epoch: 6| Step: 8
Training loss: 0.19270659566216117
Validation loss: 2.4876799762735593

Epoch: 6| Step: 9
Training loss: 0.30763110174771996
Validation loss: 2.505561015998809

Epoch: 6| Step: 10
Training loss: 0.1785630933059433
Validation loss: 2.4935176412864655

Epoch: 6| Step: 11
Training loss: 0.28690204789965507
Validation loss: 2.507064644446593

Epoch: 6| Step: 12
Training loss: 0.294957922949256
Validation loss: 2.465135560090025

Epoch: 6| Step: 13
Training loss: 0.29431634596010725
Validation loss: 2.515367988425883

Epoch: 441| Step: 0
Training loss: 0.30345498734909315
Validation loss: 2.4688124829847564

Epoch: 6| Step: 1
Training loss: 0.3017977345548432
Validation loss: 2.488713999854605

Epoch: 6| Step: 2
Training loss: 0.3711532545066001
Validation loss: 2.5037583155183656

Epoch: 6| Step: 3
Training loss: 0.2478739593823549
Validation loss: 2.5026888216105356

Epoch: 6| Step: 4
Training loss: 0.26613415277508373
Validation loss: 2.565750866744072

Epoch: 6| Step: 5
Training loss: 0.3066087937082475
Validation loss: 2.5383780236629683

Epoch: 6| Step: 6
Training loss: 0.2596053869748719
Validation loss: 2.518509800187876

Epoch: 6| Step: 7
Training loss: 0.20214027351442604
Validation loss: 2.500607670999893

Epoch: 6| Step: 8
Training loss: 0.23495413436617024
Validation loss: 2.5083420888509265

Epoch: 6| Step: 9
Training loss: 0.19131566843190081
Validation loss: 2.5464301783753385

Epoch: 6| Step: 10
Training loss: 0.2561947611840447
Validation loss: 2.5030916091907947

Epoch: 6| Step: 11
Training loss: 0.16610146154730127
Validation loss: 2.546232989002672

Epoch: 6| Step: 12
Training loss: 0.17042909205470613
Validation loss: 2.56983037289861

Epoch: 6| Step: 13
Training loss: 0.3364888036687559
Validation loss: 2.548277143262663

Epoch: 442| Step: 0
Training loss: 0.2316219283691315
Validation loss: 2.5060924046055346

Epoch: 6| Step: 1
Training loss: 0.30033350725165386
Validation loss: 2.507422300981425

Epoch: 6| Step: 2
Training loss: 0.2213303758888498
Validation loss: 2.495671673879708

Epoch: 6| Step: 3
Training loss: 0.37121917211291994
Validation loss: 2.5463073815640707

Epoch: 6| Step: 4
Training loss: 0.2820365028209191
Validation loss: 2.4929626678357537

Epoch: 6| Step: 5
Training loss: 0.23684103926131514
Validation loss: 2.5070213979414757

Epoch: 6| Step: 6
Training loss: 0.17348227223734425
Validation loss: 2.5024676224490583

Epoch: 6| Step: 7
Training loss: 0.15522460649507752
Validation loss: 2.463430629322059

Epoch: 6| Step: 8
Training loss: 0.20035433152416685
Validation loss: 2.5000273067254617

Epoch: 6| Step: 9
Training loss: 0.29922452826436063
Validation loss: 2.515517807092423

Epoch: 6| Step: 10
Training loss: 0.3120575753244934
Validation loss: 2.495105665246247

Epoch: 6| Step: 11
Training loss: 0.35202851668175894
Validation loss: 2.5173918085674725

Epoch: 6| Step: 12
Training loss: 0.205169820721639
Validation loss: 2.493703550449515

Epoch: 6| Step: 13
Training loss: 0.3252356907975765
Validation loss: 2.510083241038622

Epoch: 443| Step: 0
Training loss: 0.23603024901788058
Validation loss: 2.491597431607346

Epoch: 6| Step: 1
Training loss: 0.20873090042750675
Validation loss: 2.462784670336251

Epoch: 6| Step: 2
Training loss: 0.27758131463977265
Validation loss: 2.5379645061811673

Epoch: 6| Step: 3
Training loss: 0.17565644389998453
Validation loss: 2.4956884477961663

Epoch: 6| Step: 4
Training loss: 0.19769384154846806
Validation loss: 2.470865092038578

Epoch: 6| Step: 5
Training loss: 0.23980626673845634
Validation loss: 2.4503576702048755

Epoch: 6| Step: 6
Training loss: 0.2081111955503639
Validation loss: 2.54234408642919

Epoch: 6| Step: 7
Training loss: 0.2139880043772118
Validation loss: 2.5019224563533506

Epoch: 6| Step: 8
Training loss: 0.24747282720724303
Validation loss: 2.5570674857542097

Epoch: 6| Step: 9
Training loss: 0.22059773148287207
Validation loss: 2.527992994511028

Epoch: 6| Step: 10
Training loss: 0.19991576984082982
Validation loss: 2.532749579540576

Epoch: 6| Step: 11
Training loss: 0.3362383382575983
Validation loss: 2.4917960741466687

Epoch: 6| Step: 12
Training loss: 0.27444742889096474
Validation loss: 2.466839739381022

Epoch: 6| Step: 13
Training loss: 0.23545463172895786
Validation loss: 2.510379463859304

Epoch: 444| Step: 0
Training loss: 0.25548269484604813
Validation loss: 2.5088534309164916

Epoch: 6| Step: 1
Training loss: 0.3308289582594192
Validation loss: 2.525973231905964

Epoch: 6| Step: 2
Training loss: 0.219224355888334
Validation loss: 2.5022093705940223

Epoch: 6| Step: 3
Training loss: 0.29351228520694306
Validation loss: 2.5445013316035996

Epoch: 6| Step: 4
Training loss: 0.23057478550602453
Validation loss: 2.5291919661947597

Epoch: 6| Step: 5
Training loss: 0.1993186830935408
Validation loss: 2.5396581254376467

Epoch: 6| Step: 6
Training loss: 0.27892612311675696
Validation loss: 2.537226023548541

Epoch: 6| Step: 7
Training loss: 0.2381295987934178
Validation loss: 2.58036416427278

Epoch: 6| Step: 8
Training loss: 0.2544575208706459
Validation loss: 2.5507776280796572

Epoch: 6| Step: 9
Training loss: 0.21874146785445356
Validation loss: 2.4805050824725927

Epoch: 6| Step: 10
Training loss: 0.2826766810247676
Validation loss: 2.4306571146016527

Epoch: 6| Step: 11
Training loss: 0.26413209099735785
Validation loss: 2.5099616423179842

Epoch: 6| Step: 12
Training loss: 0.22278749211909601
Validation loss: 2.4688364247191754

Epoch: 6| Step: 13
Training loss: 0.26193995166469525
Validation loss: 2.4695711580966133

Epoch: 445| Step: 0
Training loss: 0.17379485572733172
Validation loss: 2.4680791176686334

Epoch: 6| Step: 1
Training loss: 0.21062527614088664
Validation loss: 2.5288585071851473

Epoch: 6| Step: 2
Training loss: 0.3337832732170108
Validation loss: 2.526352457544978

Epoch: 6| Step: 3
Training loss: 0.3097329660062326
Validation loss: 2.5533567145234066

Epoch: 6| Step: 4
Training loss: 0.23495188288947935
Validation loss: 2.4718651090955355

Epoch: 6| Step: 5
Training loss: 0.29075102329730085
Validation loss: 2.522153781764268

Epoch: 6| Step: 6
Training loss: 0.24229793953066708
Validation loss: 2.5059101181858923

Epoch: 6| Step: 7
Training loss: 0.32878398570922285
Validation loss: 2.5063360508632053

Epoch: 6| Step: 8
Training loss: 0.2868907511299321
Validation loss: 2.4779286271901304

Epoch: 6| Step: 9
Training loss: 0.2683612057152817
Validation loss: 2.4746570015539047

Epoch: 6| Step: 10
Training loss: 0.2675393765648608
Validation loss: 2.529709547393271

Epoch: 6| Step: 11
Training loss: 0.33174305918848773
Validation loss: 2.5322146206402674

Epoch: 6| Step: 12
Training loss: 0.1703606891702099
Validation loss: 2.537413498855757

Epoch: 6| Step: 13
Training loss: 0.29555209194321325
Validation loss: 2.531448325091677

Epoch: 446| Step: 0
Training loss: 0.25426932565090254
Validation loss: 2.4816783688997117

Epoch: 6| Step: 1
Training loss: 0.22810029327168022
Validation loss: 2.5313277683948705

Epoch: 6| Step: 2
Training loss: 0.3128465280879133
Validation loss: 2.5007482442094906

Epoch: 6| Step: 3
Training loss: 0.19339881841459847
Validation loss: 2.556343591744176

Epoch: 6| Step: 4
Training loss: 0.30091894391646445
Validation loss: 2.5778266965355168

Epoch: 6| Step: 5
Training loss: 0.21596768038571346
Validation loss: 2.5815131763720696

Epoch: 6| Step: 6
Training loss: 0.23248087510800367
Validation loss: 2.5926542610322216

Epoch: 6| Step: 7
Training loss: 0.3381609414225303
Validation loss: 2.5217324116925703

Epoch: 6| Step: 8
Training loss: 0.30095526380389437
Validation loss: 2.5560155405030804

Epoch: 6| Step: 9
Training loss: 0.1634131934287877
Validation loss: 2.5327663118550503

Epoch: 6| Step: 10
Training loss: 0.26321476059985593
Validation loss: 2.551684466482013

Epoch: 6| Step: 11
Training loss: 0.2278568520823843
Validation loss: 2.4883200554089973

Epoch: 6| Step: 12
Training loss: 0.2268467386235149
Validation loss: 2.525758720885076

Epoch: 6| Step: 13
Training loss: 0.260616314969703
Validation loss: 2.5214643292919297

Epoch: 447| Step: 0
Training loss: 0.20299300159760467
Validation loss: 2.5215387276943115

Epoch: 6| Step: 1
Training loss: 0.19766541373077975
Validation loss: 2.5475756923647506

Epoch: 6| Step: 2
Training loss: 0.28418594038858147
Validation loss: 2.5366663889899415

Epoch: 6| Step: 3
Training loss: 0.3042835100443985
Validation loss: 2.5524338513955893

Epoch: 6| Step: 4
Training loss: 0.31970082006364203
Validation loss: 2.5610978236742135

Epoch: 6| Step: 5
Training loss: 0.14420503453990846
Validation loss: 2.537467721755713

Epoch: 6| Step: 6
Training loss: 0.22564548680768404
Validation loss: 2.521264895759373

Epoch: 6| Step: 7
Training loss: 0.27296017810745704
Validation loss: 2.501195971203932

Epoch: 6| Step: 8
Training loss: 0.27810391496178327
Validation loss: 2.5125812416163686

Epoch: 6| Step: 9
Training loss: 0.25728537394798856
Validation loss: 2.537005055519373

Epoch: 6| Step: 10
Training loss: 0.16931757403881992
Validation loss: 2.51157648881079

Epoch: 6| Step: 11
Training loss: 0.2954851922191393
Validation loss: 2.5834343541810134

Epoch: 6| Step: 12
Training loss: 0.3464617191721955
Validation loss: 2.5573790251086153

Epoch: 6| Step: 13
Training loss: 0.2965403477602493
Validation loss: 2.5810213330995895

Epoch: 448| Step: 0
Training loss: 0.21186812294008306
Validation loss: 2.4948779644040266

Epoch: 6| Step: 1
Training loss: 0.2734922899121853
Validation loss: 2.4718342278964416

Epoch: 6| Step: 2
Training loss: 0.2720505279336079
Validation loss: 2.4416229884262832

Epoch: 6| Step: 3
Training loss: 0.2468975201729035
Validation loss: 2.5191443646506184

Epoch: 6| Step: 4
Training loss: 0.20799658301760846
Validation loss: 2.548636554714588

Epoch: 6| Step: 5
Training loss: 0.2287301825058307
Validation loss: 2.524528613956321

Epoch: 6| Step: 6
Training loss: 0.1875667552528858
Validation loss: 2.5352929562865847

Epoch: 6| Step: 7
Training loss: 0.27413857366577676
Validation loss: 2.515989067949441

Epoch: 6| Step: 8
Training loss: 0.30068215062884446
Validation loss: 2.5396445443524653

Epoch: 6| Step: 9
Training loss: 0.2248920652001114
Validation loss: 2.486022091330827

Epoch: 6| Step: 10
Training loss: 0.20731268054194119
Validation loss: 2.466266751304177

Epoch: 6| Step: 11
Training loss: 0.30991443076014846
Validation loss: 2.436881272127804

Epoch: 6| Step: 12
Training loss: 0.2494356744972324
Validation loss: 2.457548967328282

Epoch: 6| Step: 13
Training loss: 0.22964834216823635
Validation loss: 2.431051707414703

Epoch: 449| Step: 0
Training loss: 0.28426040079988896
Validation loss: 2.523156543125363

Epoch: 6| Step: 1
Training loss: 0.23919117057830672
Validation loss: 2.5142977986726547

Epoch: 6| Step: 2
Training loss: 0.16753640088924254
Validation loss: 2.5043123404922274

Epoch: 6| Step: 3
Training loss: 0.1653903912257442
Validation loss: 2.55817765208511

Epoch: 6| Step: 4
Training loss: 0.25198106832576495
Validation loss: 2.542109440451305

Epoch: 6| Step: 5
Training loss: 0.2030463616664455
Validation loss: 2.5258377674566868

Epoch: 6| Step: 6
Training loss: 0.1791036075321368
Validation loss: 2.488533274744339

Epoch: 6| Step: 7
Training loss: 0.18002208367287167
Validation loss: 2.5028130440503595

Epoch: 6| Step: 8
Training loss: 0.2507084850856894
Validation loss: 2.475634403995796

Epoch: 6| Step: 9
Training loss: 0.24913385972377078
Validation loss: 2.4662001112725505

Epoch: 6| Step: 10
Training loss: 0.3464430202675401
Validation loss: 2.4635177487481834

Epoch: 6| Step: 11
Training loss: 0.17896465364367187
Validation loss: 2.5220969608639727

Epoch: 6| Step: 12
Training loss: 0.3465219918079942
Validation loss: 2.5156938847495245

Epoch: 6| Step: 13
Training loss: 0.18497886047211914
Validation loss: 2.497483480995186

Epoch: 450| Step: 0
Training loss: 0.28928568961338497
Validation loss: 2.561349191676461

Epoch: 6| Step: 1
Training loss: 0.2201401442138655
Validation loss: 2.533826497872055

Epoch: 6| Step: 2
Training loss: 0.3473235906876179
Validation loss: 2.519932890823453

Epoch: 6| Step: 3
Training loss: 0.26381074992206927
Validation loss: 2.4925667086608185

Epoch: 6| Step: 4
Training loss: 0.16322504038870847
Validation loss: 2.4201989640001487

Epoch: 6| Step: 5
Training loss: 0.272131525891004
Validation loss: 2.451529289622001

Epoch: 6| Step: 6
Training loss: 0.371630030174869
Validation loss: 2.5236730003104464

Epoch: 6| Step: 7
Training loss: 0.24096361214215425
Validation loss: 2.533040610350191

Epoch: 6| Step: 8
Training loss: 0.3489157546337979
Validation loss: 2.4999444160640105

Epoch: 6| Step: 9
Training loss: 0.3221243693257125
Validation loss: 2.531614756107426

Epoch: 6| Step: 10
Training loss: 0.3539082996570105
Validation loss: 2.5716904460807193

Epoch: 6| Step: 11
Training loss: 0.1904589312669271
Validation loss: 2.5497283865690243

Epoch: 6| Step: 12
Training loss: 0.2693465885659404
Validation loss: 2.4982193724979975

Epoch: 6| Step: 13
Training loss: 0.29884285983988507
Validation loss: 2.5039229449480804

Testing loss: 2.622037259125262
