Epoch: 1| Step: 0
Training loss: 4.343475113548104
Validation loss: 5.061940291747021

Epoch: 6| Step: 1
Training loss: 5.031407134641024
Validation loss: 5.030584666486617

Epoch: 6| Step: 2
Training loss: 5.6744852916538004
Validation loss: 4.995019975787121

Epoch: 6| Step: 3
Training loss: 5.009999766092809
Validation loss: 4.96437500732555

Epoch: 6| Step: 4
Training loss: 5.040308031024237
Validation loss: 4.9295859671493165

Epoch: 6| Step: 5
Training loss: 5.325072009535484
Validation loss: 4.895609078107254

Epoch: 6| Step: 6
Training loss: 4.2303564844002715
Validation loss: 4.862370196573666

Epoch: 6| Step: 7
Training loss: 4.55726134662533
Validation loss: 4.8324139586615535

Epoch: 6| Step: 8
Training loss: 4.593973374936875
Validation loss: 4.800459227846621

Epoch: 6| Step: 9
Training loss: 5.402518335087991
Validation loss: 4.7696078640853035

Epoch: 6| Step: 10
Training loss: 3.486904440723226
Validation loss: 4.734152172791415

Epoch: 6| Step: 11
Training loss: 5.662597466781546
Validation loss: 4.70453775506052

Epoch: 6| Step: 12
Training loss: 5.140983592225541
Validation loss: 4.671755820022582

Epoch: 6| Step: 13
Training loss: 5.444588086229383
Validation loss: 4.637359874764187

Epoch: 2| Step: 0
Training loss: 4.414276820018201
Validation loss: 4.602886050622529

Epoch: 6| Step: 1
Training loss: 4.834770887719827
Validation loss: 4.56925561753737

Epoch: 6| Step: 2
Training loss: 4.16478707198585
Validation loss: 4.529323405080774

Epoch: 6| Step: 3
Training loss: 5.0077437516610015
Validation loss: 4.4845170586710585

Epoch: 6| Step: 4
Training loss: 4.791112563672275
Validation loss: 4.446287167858243

Epoch: 6| Step: 5
Training loss: 4.9377928055485825
Validation loss: 4.407773847837571

Epoch: 6| Step: 6
Training loss: 4.362156353288716
Validation loss: 4.359284649531348

Epoch: 6| Step: 7
Training loss: 4.416407355607504
Validation loss: 4.3164971481579535

Epoch: 6| Step: 8
Training loss: 3.9266107546372124
Validation loss: 4.261491181439627

Epoch: 6| Step: 9
Training loss: 4.176111934404043
Validation loss: 4.212726540893147

Epoch: 6| Step: 10
Training loss: 4.543059855734151
Validation loss: 4.1585992278338235

Epoch: 6| Step: 11
Training loss: 3.763812883523858
Validation loss: 4.106143507599909

Epoch: 6| Step: 12
Training loss: 3.7067506963366825
Validation loss: 4.049024504459515

Epoch: 6| Step: 13
Training loss: 4.735726846498691
Validation loss: 3.990883611167346

Epoch: 3| Step: 0
Training loss: 3.7774265599764645
Validation loss: 3.9255171805620335

Epoch: 6| Step: 1
Training loss: 3.6709348083626514
Validation loss: 3.8632426785509715

Epoch: 6| Step: 2
Training loss: 3.683421708394595
Validation loss: 3.8009638074345897

Epoch: 6| Step: 3
Training loss: 4.60834121749415
Validation loss: 3.724779215505843

Epoch: 6| Step: 4
Training loss: 3.654997521437445
Validation loss: 3.650952841004269

Epoch: 6| Step: 5
Training loss: 3.558534255299867
Validation loss: 3.5629041342138845

Epoch: 6| Step: 6
Training loss: 3.939390909198227
Validation loss: 3.5075809711038306

Epoch: 6| Step: 7
Training loss: 3.591145243193993
Validation loss: 3.4217472255778505

Epoch: 6| Step: 8
Training loss: 3.333486187927002
Validation loss: 3.337152693033187

Epoch: 6| Step: 9
Training loss: 3.4610160319285725
Validation loss: 3.261491949606097

Epoch: 6| Step: 10
Training loss: 2.7417474377299205
Validation loss: 3.1852380543230234

Epoch: 6| Step: 11
Training loss: 3.409868750409542
Validation loss: 3.088945955230377

Epoch: 6| Step: 12
Training loss: 2.826144879363121
Validation loss: 3.017794683395335

Epoch: 6| Step: 13
Training loss: 2.660076033717358
Validation loss: 2.9354397738765337

Epoch: 4| Step: 0
Training loss: 2.751978509270125
Validation loss: 2.8648211756138364

Epoch: 6| Step: 1
Training loss: 3.0921306032379143
Validation loss: 2.7975530104490938

Epoch: 6| Step: 2
Training loss: 2.721598919291789
Validation loss: 2.7356037539798144

Epoch: 6| Step: 3
Training loss: 1.8183369537839618
Validation loss: 2.7069466978137355

Epoch: 6| Step: 4
Training loss: 2.530675563858251
Validation loss: 2.669965734821526

Epoch: 6| Step: 5
Training loss: 2.6246406672537383
Validation loss: 2.6292082644727097

Epoch: 6| Step: 6
Training loss: 2.4113052572244076
Validation loss: 2.6226619420024373

Epoch: 6| Step: 7
Training loss: 3.21191896163924
Validation loss: 2.6249271715748574

Epoch: 6| Step: 8
Training loss: 2.7821394965975075
Validation loss: 2.627374664859795

Epoch: 6| Step: 9
Training loss: 2.907381063244311
Validation loss: 2.649816748442913

Epoch: 6| Step: 10
Training loss: 2.6113855531094075
Validation loss: 2.6622062174776446

Epoch: 6| Step: 11
Training loss: 3.019433655339859
Validation loss: 2.702810427198535

Epoch: 6| Step: 12
Training loss: 2.9408889052113834
Validation loss: 2.699638617431748

Epoch: 6| Step: 13
Training loss: 2.387388943790497
Validation loss: 2.720283528888882

Epoch: 5| Step: 0
Training loss: 2.8781392746363235
Validation loss: 2.7009752137149534

Epoch: 6| Step: 1
Training loss: 2.5600606891769746
Validation loss: 2.694724050960618

Epoch: 6| Step: 2
Training loss: 2.624617321639955
Validation loss: 2.704494372017312

Epoch: 6| Step: 3
Training loss: 2.9896116000621342
Validation loss: 2.669283496857664

Epoch: 6| Step: 4
Training loss: 2.1742435411416747
Validation loss: 2.6441337403143783

Epoch: 6| Step: 5
Training loss: 4.038794503092229
Validation loss: 2.6564495684882226

Epoch: 6| Step: 6
Training loss: 1.9089673170526187
Validation loss: 2.6306257816820167

Epoch: 6| Step: 7
Training loss: 2.4309539928531456
Validation loss: 2.633592861601254

Epoch: 6| Step: 8
Training loss: 2.030562768735771
Validation loss: 2.6041708348558763

Epoch: 6| Step: 9
Training loss: 2.2989851412631044
Validation loss: 2.597586578735068

Epoch: 6| Step: 10
Training loss: 2.100886012678709
Validation loss: 2.5988042985810225

Epoch: 6| Step: 11
Training loss: 3.0240443209674988
Validation loss: 2.5974594538818976

Epoch: 6| Step: 12
Training loss: 2.7236509325936775
Validation loss: 2.592654920073534

Epoch: 6| Step: 13
Training loss: 2.665955528168808
Validation loss: 2.6085532868567776

Epoch: 6| Step: 0
Training loss: 2.6111162965691483
Validation loss: 2.5988817961793864

Epoch: 6| Step: 1
Training loss: 2.6195276530554263
Validation loss: 2.6057025855965126

Epoch: 6| Step: 2
Training loss: 2.190533306036673
Validation loss: 2.5793524084140937

Epoch: 6| Step: 3
Training loss: 2.8719089310958834
Validation loss: 2.6038680070643356

Epoch: 6| Step: 4
Training loss: 2.4716803627209174
Validation loss: 2.58961003218923

Epoch: 6| Step: 5
Training loss: 2.6109848082095715
Validation loss: 2.5802435291298957

Epoch: 6| Step: 6
Training loss: 2.7747660289108618
Validation loss: 2.5888360749625585

Epoch: 6| Step: 7
Training loss: 3.1968389097024272
Validation loss: 2.5695796799225246

Epoch: 6| Step: 8
Training loss: 2.430159838721692
Validation loss: 2.5843487456470737

Epoch: 6| Step: 9
Training loss: 2.4799190843364136
Validation loss: 2.5778482770277225

Epoch: 6| Step: 10
Training loss: 2.6062874258450783
Validation loss: 2.578216705232556

Epoch: 6| Step: 11
Training loss: 2.0274881594461496
Validation loss: 2.5794978638356882

Epoch: 6| Step: 12
Training loss: 3.0184464770012878
Validation loss: 2.591808940952313

Epoch: 6| Step: 13
Training loss: 2.3691547138647446
Validation loss: 2.5943278852396823

Epoch: 7| Step: 0
Training loss: 2.4423990169019625
Validation loss: 2.577716725707096

Epoch: 6| Step: 1
Training loss: 2.6174682466608514
Validation loss: 2.591897126486572

Epoch: 6| Step: 2
Training loss: 2.7776922551870946
Validation loss: 2.5826650852444044

Epoch: 6| Step: 3
Training loss: 3.1754162192677007
Validation loss: 2.584171318198451

Epoch: 6| Step: 4
Training loss: 1.9857208013672683
Validation loss: 2.5763091811617

Epoch: 6| Step: 5
Training loss: 2.8726953308252368
Validation loss: 2.585265149992784

Epoch: 6| Step: 6
Training loss: 2.8699621760304965
Validation loss: 2.57933683332178

Epoch: 6| Step: 7
Training loss: 1.898680997075603
Validation loss: 2.5830514405381373

Epoch: 6| Step: 8
Training loss: 2.738159873547019
Validation loss: 2.57802088363491

Epoch: 6| Step: 9
Training loss: 3.045803253261866
Validation loss: 2.573620508168465

Epoch: 6| Step: 10
Training loss: 2.038426442529331
Validation loss: 2.584855651440674

Epoch: 6| Step: 11
Training loss: 2.7332588751661113
Validation loss: 2.566155485756117

Epoch: 6| Step: 12
Training loss: 2.34435884832698
Validation loss: 2.574652219020457

Epoch: 6| Step: 13
Training loss: 2.4403420532172206
Validation loss: 2.578130964792461

Epoch: 8| Step: 0
Training loss: 2.8070971835021554
Validation loss: 2.582371430103172

Epoch: 6| Step: 1
Training loss: 2.539037052907337
Validation loss: 2.5826462836993245

Epoch: 6| Step: 2
Training loss: 2.353041073137083
Validation loss: 2.5715688091340834

Epoch: 6| Step: 3
Training loss: 3.040791076327515
Validation loss: 2.5653074438939263

Epoch: 6| Step: 4
Training loss: 2.2692729126648783
Validation loss: 2.577765977309976

Epoch: 6| Step: 5
Training loss: 2.493072926476427
Validation loss: 2.577118370745177

Epoch: 6| Step: 6
Training loss: 2.806728120102362
Validation loss: 2.5646331406277714

Epoch: 6| Step: 7
Training loss: 2.4207587838526186
Validation loss: 2.566415578669408

Epoch: 6| Step: 8
Training loss: 2.117893903501027
Validation loss: 2.5679499504098313

Epoch: 6| Step: 9
Training loss: 2.8125905340246313
Validation loss: 2.585279736413657

Epoch: 6| Step: 10
Training loss: 2.2078498335028547
Validation loss: 2.561498523803818

Epoch: 6| Step: 11
Training loss: 2.6916715493960033
Validation loss: 2.5746327493245422

Epoch: 6| Step: 12
Training loss: 2.905085340549648
Validation loss: 2.576174620577969

Epoch: 6| Step: 13
Training loss: 2.4441769434282232
Validation loss: 2.5678266352288857

Epoch: 9| Step: 0
Training loss: 2.4364654106003645
Validation loss: 2.5618899634964185

Epoch: 6| Step: 1
Training loss: 3.010418127426972
Validation loss: 2.5654539434580848

Epoch: 6| Step: 2
Training loss: 2.9876974894477097
Validation loss: 2.564685153463536

Epoch: 6| Step: 3
Training loss: 3.026461407455557
Validation loss: 2.5724575750265113

Epoch: 6| Step: 4
Training loss: 2.7042510933963313
Validation loss: 2.5638895647898297

Epoch: 6| Step: 5
Training loss: 2.290945586998231
Validation loss: 2.553127998838994

Epoch: 6| Step: 6
Training loss: 2.832919277529031
Validation loss: 2.566688936207094

Epoch: 6| Step: 7
Training loss: 2.399895737290627
Validation loss: 2.572575431980721

Epoch: 6| Step: 8
Training loss: 2.997741802984106
Validation loss: 2.577336832426327

Epoch: 6| Step: 9
Training loss: 2.0040629364684173
Validation loss: 2.561505147830125

Epoch: 6| Step: 10
Training loss: 2.4091860210952416
Validation loss: 2.559096836784093

Epoch: 6| Step: 11
Training loss: 2.325502493096481
Validation loss: 2.562726034104281

Epoch: 6| Step: 12
Training loss: 1.9938419428465737
Validation loss: 2.543603063052707

Epoch: 6| Step: 13
Training loss: 2.2545138751542293
Validation loss: 2.559908479107615

Epoch: 10| Step: 0
Training loss: 2.5481244164457535
Validation loss: 2.554719401713522

Epoch: 6| Step: 1
Training loss: 2.4896685746628644
Validation loss: 2.556622984271367

Epoch: 6| Step: 2
Training loss: 2.5471935424059096
Validation loss: 2.5645877582957075

Epoch: 6| Step: 3
Training loss: 2.4858087205409003
Validation loss: 2.554490699148329

Epoch: 6| Step: 4
Training loss: 2.5158660962689305
Validation loss: 2.5539424793703422

Epoch: 6| Step: 5
Training loss: 2.752337416057678
Validation loss: 2.548905700048726

Epoch: 6| Step: 6
Training loss: 2.3881777535357185
Validation loss: 2.552459522988713

Epoch: 6| Step: 7
Training loss: 2.4967876777132183
Validation loss: 2.564051336852667

Epoch: 6| Step: 8
Training loss: 2.828620150725842
Validation loss: 2.551537596812118

Epoch: 6| Step: 9
Training loss: 2.1004815139955904
Validation loss: 2.5529307820327487

Epoch: 6| Step: 10
Training loss: 2.07590635796301
Validation loss: 2.557820769746959

Epoch: 6| Step: 11
Training loss: 2.935474752731793
Validation loss: 2.5715169973408134

Epoch: 6| Step: 12
Training loss: 2.822090074827856
Validation loss: 2.552973227501367

Epoch: 6| Step: 13
Training loss: 2.57628626132046
Validation loss: 2.5630920160480164

Epoch: 11| Step: 0
Training loss: 3.1014542644842433
Validation loss: 2.557387089292443

Epoch: 6| Step: 1
Training loss: 3.062132521399634
Validation loss: 2.5475986911323703

Epoch: 6| Step: 2
Training loss: 2.5504671753425883
Validation loss: 2.548860107844817

Epoch: 6| Step: 3
Training loss: 2.3951052900197856
Validation loss: 2.544130106027174

Epoch: 6| Step: 4
Training loss: 2.287838657512552
Validation loss: 2.5387735759968333

Epoch: 6| Step: 5
Training loss: 2.6249133504462723
Validation loss: 2.554445556631902

Epoch: 6| Step: 6
Training loss: 1.8494735071698498
Validation loss: 2.54846073391862

Epoch: 6| Step: 7
Training loss: 2.1371611254030047
Validation loss: 2.545171421450844

Epoch: 6| Step: 8
Training loss: 2.53829559481798
Validation loss: 2.5423479313667827

Epoch: 6| Step: 9
Training loss: 2.698653916967126
Validation loss: 2.546191788914549

Epoch: 6| Step: 10
Training loss: 2.292185244984938
Validation loss: 2.538554769760541

Epoch: 6| Step: 11
Training loss: 2.387128079989819
Validation loss: 2.5355381220050046

Epoch: 6| Step: 12
Training loss: 2.5317685573316266
Validation loss: 2.5428655850549435

Epoch: 6| Step: 13
Training loss: 2.948441601352639
Validation loss: 2.534439514599611

Epoch: 12| Step: 0
Training loss: 2.6170495751320284
Validation loss: 2.5478078619826907

Epoch: 6| Step: 1
Training loss: 2.341994174666616
Validation loss: 2.525794834517732

Epoch: 6| Step: 2
Training loss: 2.62784240872577
Validation loss: 2.5403701310298428

Epoch: 6| Step: 3
Training loss: 1.8079442615019286
Validation loss: 2.543566717969674

Epoch: 6| Step: 4
Training loss: 1.9161895766315264
Validation loss: 2.5372721458573886

Epoch: 6| Step: 5
Training loss: 3.0096127361699394
Validation loss: 2.5364513096852486

Epoch: 6| Step: 6
Training loss: 2.583385487511959
Validation loss: 2.5509134426787163

Epoch: 6| Step: 7
Training loss: 2.1277110813379227
Validation loss: 2.5462621095719276

Epoch: 6| Step: 8
Training loss: 2.5349194338183034
Validation loss: 2.533541768266452

Epoch: 6| Step: 9
Training loss: 2.831880047148966
Validation loss: 2.5447152932930783

Epoch: 6| Step: 10
Training loss: 3.004238948578533
Validation loss: 2.5415624899437956

Epoch: 6| Step: 11
Training loss: 2.888031326884866
Validation loss: 2.5408155913300186

Epoch: 6| Step: 12
Training loss: 2.4705175518561977
Validation loss: 2.5273681041992555

Epoch: 6| Step: 13
Training loss: 2.4880305812219636
Validation loss: 2.537316356709721

Epoch: 13| Step: 0
Training loss: 2.702121614544319
Validation loss: 2.5372188428012605

Epoch: 6| Step: 1
Training loss: 2.5439130726124075
Validation loss: 2.5297656711048115

Epoch: 6| Step: 2
Training loss: 2.970681616149123
Validation loss: 2.5260971351642225

Epoch: 6| Step: 3
Training loss: 2.5133682458849136
Validation loss: 2.528461254440315

Epoch: 6| Step: 4
Training loss: 2.1580269167673585
Validation loss: 2.516078544785065

Epoch: 6| Step: 5
Training loss: 2.3506192061158364
Validation loss: 2.5211379337448405

Epoch: 6| Step: 6
Training loss: 2.7172473832869874
Validation loss: 2.5268615073901275

Epoch: 6| Step: 7
Training loss: 2.8857737479767396
Validation loss: 2.5288324310147594

Epoch: 6| Step: 8
Training loss: 1.9807446530265238
Validation loss: 2.5129109386601667

Epoch: 6| Step: 9
Training loss: 2.2971712297681495
Validation loss: 2.5152786916877057

Epoch: 6| Step: 10
Training loss: 2.592195343686332
Validation loss: 2.535279257777532

Epoch: 6| Step: 11
Training loss: 2.4060617348479267
Validation loss: 2.518841505636585

Epoch: 6| Step: 12
Training loss: 2.7461324718887146
Validation loss: 2.5174772500326927

Epoch: 6| Step: 13
Training loss: 2.513244450293515
Validation loss: 2.5051880252091676

Epoch: 14| Step: 0
Training loss: 1.799914103683742
Validation loss: 2.513919844767557

Epoch: 6| Step: 1
Training loss: 2.3493526378723217
Validation loss: 2.518904717980892

Epoch: 6| Step: 2
Training loss: 2.247802827183968
Validation loss: 2.5216502345126073

Epoch: 6| Step: 3
Training loss: 2.8632749216548414
Validation loss: 2.5349302813230623

Epoch: 6| Step: 4
Training loss: 2.478221830806917
Validation loss: 2.5220681048410936

Epoch: 6| Step: 5
Training loss: 3.0934545202468144
Validation loss: 2.538567018336666

Epoch: 6| Step: 6
Training loss: 2.680613810862098
Validation loss: 2.5137182081764453

Epoch: 6| Step: 7
Training loss: 3.704464312088669
Validation loss: 2.5495634964480187

Epoch: 6| Step: 8
Training loss: 2.3156500316919444
Validation loss: 2.5460006679684866

Epoch: 6| Step: 9
Training loss: 2.6261174684444044
Validation loss: 2.5551848476702723

Epoch: 6| Step: 10
Training loss: 2.993450804474835
Validation loss: 2.5359480159758503

Epoch: 6| Step: 11
Training loss: 1.8679483690988734
Validation loss: 2.520627515182924

Epoch: 6| Step: 12
Training loss: 1.5955880729445646
Validation loss: 2.5177136550697665

Epoch: 6| Step: 13
Training loss: 2.0755520143803174
Validation loss: 2.511487239216151

Epoch: 15| Step: 0
Training loss: 2.7092996096214286
Validation loss: 2.5254631454939607

Epoch: 6| Step: 1
Training loss: 2.5651426877196943
Validation loss: 2.521037547979754

Epoch: 6| Step: 2
Training loss: 2.9241184047203386
Validation loss: 2.51875316029643

Epoch: 6| Step: 3
Training loss: 2.459735588967452
Validation loss: 2.515080079003945

Epoch: 6| Step: 4
Training loss: 2.9948157975703538
Validation loss: 2.5153616694332035

Epoch: 6| Step: 5
Training loss: 3.11724302773029
Validation loss: 2.5096362762169973

Epoch: 6| Step: 6
Training loss: 1.7667114830930368
Validation loss: 2.520222303459998

Epoch: 6| Step: 7
Training loss: 2.508274499281352
Validation loss: 2.5227077440677044

Epoch: 6| Step: 8
Training loss: 2.9689838518093503
Validation loss: 2.5145995851974976

Epoch: 6| Step: 9
Training loss: 2.0525434207389024
Validation loss: 2.495702960685597

Epoch: 6| Step: 10
Training loss: 2.241295401118122
Validation loss: 2.508256906525809

Epoch: 6| Step: 11
Training loss: 2.078433479990016
Validation loss: 2.487791866642911

Epoch: 6| Step: 12
Training loss: 2.3722949434023652
Validation loss: 2.509274089489705

Epoch: 6| Step: 13
Training loss: 2.0729185580399925
Validation loss: 2.5108131053458767

Epoch: 16| Step: 0
Training loss: 3.1313101574264333
Validation loss: 2.49223467902766

Epoch: 6| Step: 1
Training loss: 2.3468913071392197
Validation loss: 2.5072769591456527

Epoch: 6| Step: 2
Training loss: 2.5253326574577764
Validation loss: 2.49947481996943

Epoch: 6| Step: 3
Training loss: 2.496944372099062
Validation loss: 2.506506115137678

Epoch: 6| Step: 4
Training loss: 2.679492020219444
Validation loss: 2.493228842280579

Epoch: 6| Step: 5
Training loss: 2.7291769265329027
Validation loss: 2.511429029874172

Epoch: 6| Step: 6
Training loss: 2.885894533838167
Validation loss: 2.495739198755257

Epoch: 6| Step: 7
Training loss: 2.523385534548623
Validation loss: 2.5122118634423685

Epoch: 6| Step: 8
Training loss: 2.235428995013719
Validation loss: 2.4943046864376024

Epoch: 6| Step: 9
Training loss: 2.063986502669803
Validation loss: 2.513741255886779

Epoch: 6| Step: 10
Training loss: 2.5837863606928955
Validation loss: 2.5139115937286607

Epoch: 6| Step: 11
Training loss: 2.1642559529676832
Validation loss: 2.5328529682570187

Epoch: 6| Step: 12
Training loss: 2.0233953169619654
Validation loss: 2.520342082768203

Epoch: 6| Step: 13
Training loss: 2.466356493375804
Validation loss: 2.5256563240115733

Epoch: 17| Step: 0
Training loss: 3.068716629375187
Validation loss: 2.5160018449088217

Epoch: 6| Step: 1
Training loss: 2.8483735111350033
Validation loss: 2.4994312275155552

Epoch: 6| Step: 2
Training loss: 2.549942696619373
Validation loss: 2.508941206248148

Epoch: 6| Step: 3
Training loss: 2.3880062345490467
Validation loss: 2.497957269265944

Epoch: 6| Step: 4
Training loss: 2.0689183561387035
Validation loss: 2.4848438356377893

Epoch: 6| Step: 5
Training loss: 2.923691618337711
Validation loss: 2.495959656903894

Epoch: 6| Step: 6
Training loss: 2.816344960216437
Validation loss: 2.503760942120003

Epoch: 6| Step: 7
Training loss: 1.737821848308606
Validation loss: 2.502716908742006

Epoch: 6| Step: 8
Training loss: 2.486499190157972
Validation loss: 2.4805053067454623

Epoch: 6| Step: 9
Training loss: 2.1953047891393163
Validation loss: 2.502416380718363

Epoch: 6| Step: 10
Training loss: 2.6363571258093823
Validation loss: 2.4920743559821434

Epoch: 6| Step: 11
Training loss: 2.9216328076846776
Validation loss: 2.5014486089573373

Epoch: 6| Step: 12
Training loss: 1.8830933420765803
Validation loss: 2.4936525987104985

Epoch: 6| Step: 13
Training loss: 2.1964438567477034
Validation loss: 2.4775608830135742

Epoch: 18| Step: 0
Training loss: 2.5618505818007615
Validation loss: 2.485250003041218

Epoch: 6| Step: 1
Training loss: 2.6295101838104173
Validation loss: 2.493149574676986

Epoch: 6| Step: 2
Training loss: 1.9556112105705417
Validation loss: 2.4849106473100697

Epoch: 6| Step: 3
Training loss: 2.2482534623528205
Validation loss: 2.497159361292693

Epoch: 6| Step: 4
Training loss: 2.6158948752252984
Validation loss: 2.479748735030322

Epoch: 6| Step: 5
Training loss: 2.890724304143077
Validation loss: 2.502171924006294

Epoch: 6| Step: 6
Training loss: 2.764122161307607
Validation loss: 2.4877915631640617

Epoch: 6| Step: 7
Training loss: 2.259738615331238
Validation loss: 2.4837924426208455

Epoch: 6| Step: 8
Training loss: 2.2610753120860547
Validation loss: 2.4967906458629847

Epoch: 6| Step: 9
Training loss: 2.5286312921317435
Validation loss: 2.489219899697593

Epoch: 6| Step: 10
Training loss: 1.999956011288404
Validation loss: 2.507788732303162

Epoch: 6| Step: 11
Training loss: 2.914872371437978
Validation loss: 2.4997201286062514

Epoch: 6| Step: 12
Training loss: 2.107469955899906
Validation loss: 2.4967324042313437

Epoch: 6| Step: 13
Training loss: 2.7588102356764934
Validation loss: 2.517864683507767

Epoch: 19| Step: 0
Training loss: 2.35764780044432
Validation loss: 2.501358823250189

Epoch: 6| Step: 1
Training loss: 2.9103325502386346
Validation loss: 2.485689659080179

Epoch: 6| Step: 2
Training loss: 2.0636866074916584
Validation loss: 2.4919138153219405

Epoch: 6| Step: 3
Training loss: 2.036281750398111
Validation loss: 2.47909886937977

Epoch: 6| Step: 4
Training loss: 2.9124440462033987
Validation loss: 2.48671950870478

Epoch: 6| Step: 5
Training loss: 2.0946954898263557
Validation loss: 2.4926992785784443

Epoch: 6| Step: 6
Training loss: 2.6614557752702717
Validation loss: 2.48768283549055

Epoch: 6| Step: 7
Training loss: 2.420521807254992
Validation loss: 2.4841704534301083

Epoch: 6| Step: 8
Training loss: 3.3105177796472187
Validation loss: 2.498113556251022

Epoch: 6| Step: 9
Training loss: 1.8523927267832547
Validation loss: 2.4932555298812282

Epoch: 6| Step: 10
Training loss: 3.0118938548520444
Validation loss: 2.4924672765952764

Epoch: 6| Step: 11
Training loss: 2.50292521047322
Validation loss: 2.4744896943843884

Epoch: 6| Step: 12
Training loss: 2.0925707556498834
Validation loss: 2.4797242656851424

Epoch: 6| Step: 13
Training loss: 2.0257877560123787
Validation loss: 2.462989266679232

Epoch: 20| Step: 0
Training loss: 2.272073972612671
Validation loss: 2.4921740428916

Epoch: 6| Step: 1
Training loss: 2.6802433427248173
Validation loss: 2.494397211182238

Epoch: 6| Step: 2
Training loss: 2.3177857689655212
Validation loss: 2.5018437739111983

Epoch: 6| Step: 3
Training loss: 2.2003262104592767
Validation loss: 2.5003903481597978

Epoch: 6| Step: 4
Training loss: 2.7188501449205815
Validation loss: 2.5013485609135335

Epoch: 6| Step: 5
Training loss: 2.7048635900374807
Validation loss: 2.5111619995759775

Epoch: 6| Step: 6
Training loss: 2.611723339956565
Validation loss: 2.535844643758053

Epoch: 6| Step: 7
Training loss: 3.0512166707720167
Validation loss: 2.497043912328056

Epoch: 6| Step: 8
Training loss: 1.9981383361466813
Validation loss: 2.508818950304283

Epoch: 6| Step: 9
Training loss: 2.376886522022921
Validation loss: 2.4946789221616337

Epoch: 6| Step: 10
Training loss: 2.646491401916409
Validation loss: 2.506296073699361

Epoch: 6| Step: 11
Training loss: 2.0695865149947457
Validation loss: 2.485623268009817

Epoch: 6| Step: 12
Training loss: 2.2472716850094288
Validation loss: 2.4617795119337536

Epoch: 6| Step: 13
Training loss: 2.869549602031313
Validation loss: 2.463542306481911

Epoch: 21| Step: 0
Training loss: 2.0026916035057525
Validation loss: 2.4970650611317975

Epoch: 6| Step: 1
Training loss: 2.0435918437646414
Validation loss: 2.4737426877985937

Epoch: 6| Step: 2
Training loss: 2.938310551921994
Validation loss: 2.4688439331211707

Epoch: 6| Step: 3
Training loss: 3.1177462504883366
Validation loss: 2.4526615717476283

Epoch: 6| Step: 4
Training loss: 2.821262949726637
Validation loss: 2.4741825015583956

Epoch: 6| Step: 5
Training loss: 2.9106903610115498
Validation loss: 2.470153506215514

Epoch: 6| Step: 6
Training loss: 2.211702356038566
Validation loss: 2.4640975443287796

Epoch: 6| Step: 7
Training loss: 2.4539579690257773
Validation loss: 2.4756206562685015

Epoch: 6| Step: 8
Training loss: 1.5388019941580304
Validation loss: 2.4753370171175435

Epoch: 6| Step: 9
Training loss: 2.115081866147642
Validation loss: 2.473585447351644

Epoch: 6| Step: 10
Training loss: 2.847656584897957
Validation loss: 2.478891346707625

Epoch: 6| Step: 11
Training loss: 2.4474990380258976
Validation loss: 2.478643591913785

Epoch: 6| Step: 12
Training loss: 2.0186824822723852
Validation loss: 2.4657856007767185

Epoch: 6| Step: 13
Training loss: 2.6479158591072376
Validation loss: 2.490961536627615

Epoch: 22| Step: 0
Training loss: 1.8431028103066718
Validation loss: 2.480911543765167

Epoch: 6| Step: 1
Training loss: 2.0947258795890495
Validation loss: 2.491058269165825

Epoch: 6| Step: 2
Training loss: 2.679064085931107
Validation loss: 2.4834984166576954

Epoch: 6| Step: 3
Training loss: 1.540045255020841
Validation loss: 2.467072959465332

Epoch: 6| Step: 4
Training loss: 2.93125625316872
Validation loss: 2.4966680097979546

Epoch: 6| Step: 5
Training loss: 2.3146214419940834
Validation loss: 2.466879912987562

Epoch: 6| Step: 6
Training loss: 2.0369142638241224
Validation loss: 2.4831916822020106

Epoch: 6| Step: 7
Training loss: 2.4546103870267495
Validation loss: 2.4713047345560244

Epoch: 6| Step: 8
Training loss: 2.8124526973561212
Validation loss: 2.469286960843362

Epoch: 6| Step: 9
Training loss: 2.6583402599694903
Validation loss: 2.480111981063333

Epoch: 6| Step: 10
Training loss: 2.2382558984302734
Validation loss: 2.4666715314748404

Epoch: 6| Step: 11
Training loss: 3.4712398631380927
Validation loss: 2.483690323441503

Epoch: 6| Step: 12
Training loss: 2.0046705309178656
Validation loss: 2.481536074913481

Epoch: 6| Step: 13
Training loss: 2.669631908775221
Validation loss: 2.4767552570536098

Epoch: 23| Step: 0
Training loss: 2.134359951161717
Validation loss: 2.498285508358667

Epoch: 6| Step: 1
Training loss: 2.3247250302056055
Validation loss: 2.4788434488440685

Epoch: 6| Step: 2
Training loss: 2.732955476958614
Validation loss: 2.456290428016575

Epoch: 6| Step: 3
Training loss: 2.6472640687246423
Validation loss: 2.4752092003310433

Epoch: 6| Step: 4
Training loss: 1.9634484252917155
Validation loss: 2.4547850626872014

Epoch: 6| Step: 5
Training loss: 1.9970343775419162
Validation loss: 2.446674995156993

Epoch: 6| Step: 6
Training loss: 2.821746630616186
Validation loss: 2.4787630238770384

Epoch: 6| Step: 7
Training loss: 2.9492019349686207
Validation loss: 2.4767841677134226

Epoch: 6| Step: 8
Training loss: 2.8539534069126153
Validation loss: 2.4700576602522264

Epoch: 6| Step: 9
Training loss: 2.018519843713842
Validation loss: 2.4923184319585068

Epoch: 6| Step: 10
Training loss: 2.43940425729176
Validation loss: 2.480445072731893

Epoch: 6| Step: 11
Training loss: 2.199505477291432
Validation loss: 2.484760518421862

Epoch: 6| Step: 12
Training loss: 2.360480447453454
Validation loss: 2.4630941961802013

Epoch: 6| Step: 13
Training loss: 2.6090566475195245
Validation loss: 2.4628985306776534

Epoch: 24| Step: 0
Training loss: 1.935831520560318
Validation loss: 2.4463328628527456

Epoch: 6| Step: 1
Training loss: 2.557429064590093
Validation loss: 2.4679444926407066

Epoch: 6| Step: 2
Training loss: 2.8570637351388415
Validation loss: 2.4550980167802035

Epoch: 6| Step: 3
Training loss: 2.619684104657854
Validation loss: 2.45720129834662

Epoch: 6| Step: 4
Training loss: 2.5010261337092388
Validation loss: 2.4531966034953876

Epoch: 6| Step: 5
Training loss: 2.9536268019843654
Validation loss: 2.468888524349978

Epoch: 6| Step: 6
Training loss: 2.4579195439430213
Validation loss: 2.4376082111042154

Epoch: 6| Step: 7
Training loss: 2.3254592277907578
Validation loss: 2.456665189691701

Epoch: 6| Step: 8
Training loss: 2.2076620365174713
Validation loss: 2.4750614691656607

Epoch: 6| Step: 9
Training loss: 2.381484765522452
Validation loss: 2.4670280696548725

Epoch: 6| Step: 10
Training loss: 2.6921688599475315
Validation loss: 2.4570132822452213

Epoch: 6| Step: 11
Training loss: 1.7941133589679528
Validation loss: 2.446088348905793

Epoch: 6| Step: 12
Training loss: 2.756311456596326
Validation loss: 2.4707779904407987

Epoch: 6| Step: 13
Training loss: 2.0260193602078465
Validation loss: 2.456915387210082

Epoch: 25| Step: 0
Training loss: 3.0082141954777795
Validation loss: 2.4434291098828274

Epoch: 6| Step: 1
Training loss: 2.2862398105433903
Validation loss: 2.4503939221092033

Epoch: 6| Step: 2
Training loss: 2.282579948805029
Validation loss: 2.454256659273437

Epoch: 6| Step: 3
Training loss: 2.407035600311003
Validation loss: 2.458398427478603

Epoch: 6| Step: 4
Training loss: 2.5290546080281033
Validation loss: 2.4564606489687653

Epoch: 6| Step: 5
Training loss: 2.201792104104301
Validation loss: 2.446801022011751

Epoch: 6| Step: 6
Training loss: 1.7741270363273967
Validation loss: 2.4612365863848487

Epoch: 6| Step: 7
Training loss: 1.993251022991213
Validation loss: 2.4606995482678706

Epoch: 6| Step: 8
Training loss: 2.553409174929043
Validation loss: 2.4610233836855344

Epoch: 6| Step: 9
Training loss: 2.7159677936627635
Validation loss: 2.4774807612509058

Epoch: 6| Step: 10
Training loss: 2.993715219952671
Validation loss: 2.4553095653597805

Epoch: 6| Step: 11
Training loss: 2.7104607858275296
Validation loss: 2.461778688725074

Epoch: 6| Step: 12
Training loss: 2.465531581177415
Validation loss: 2.4910761030198536

Epoch: 6| Step: 13
Training loss: 1.6276827454989862
Validation loss: 2.4765575581369923

Epoch: 26| Step: 0
Training loss: 2.0706602560231904
Validation loss: 2.4811297639786365

Epoch: 6| Step: 1
Training loss: 2.615306029929956
Validation loss: 2.4866827077407865

Epoch: 6| Step: 2
Training loss: 2.0785805339173713
Validation loss: 2.474246156245814

Epoch: 6| Step: 3
Training loss: 2.674905408095909
Validation loss: 2.461516749113559

Epoch: 6| Step: 4
Training loss: 1.7701708582941114
Validation loss: 2.476968854264572

Epoch: 6| Step: 5
Training loss: 2.9052762276772315
Validation loss: 2.4735847324899902

Epoch: 6| Step: 6
Training loss: 2.604920016358655
Validation loss: 2.48286947381453

Epoch: 6| Step: 7
Training loss: 2.508120889211176
Validation loss: 2.478212843593166

Epoch: 6| Step: 8
Training loss: 1.684652327600424
Validation loss: 2.455062052841808

Epoch: 6| Step: 9
Training loss: 2.42728248619557
Validation loss: 2.4350615147543224

Epoch: 6| Step: 10
Training loss: 2.488368154113063
Validation loss: 2.4593655202732183

Epoch: 6| Step: 11
Training loss: 1.7431732262976918
Validation loss: 2.449963729615871

Epoch: 6| Step: 12
Training loss: 2.8368641413959677
Validation loss: 2.4547702755115135

Epoch: 6| Step: 13
Training loss: 3.0531379691622575
Validation loss: 2.473472496647836

Epoch: 27| Step: 0
Training loss: 2.427799975858456
Validation loss: 2.4578458388860955

Epoch: 6| Step: 1
Training loss: 2.1756298074118505
Validation loss: 2.450717797844736

Epoch: 6| Step: 2
Training loss: 1.8039536077958296
Validation loss: 2.434746597258937

Epoch: 6| Step: 3
Training loss: 2.3574952980876485
Validation loss: 2.488203557516772

Epoch: 6| Step: 4
Training loss: 2.0690730001220317
Validation loss: 2.475299838235625

Epoch: 6| Step: 5
Training loss: 3.0251841465410663
Validation loss: 2.488370405722844

Epoch: 6| Step: 6
Training loss: 2.5948463788435268
Validation loss: 2.4792491728146038

Epoch: 6| Step: 7
Training loss: 1.5950614171176738
Validation loss: 2.4935811290751833

Epoch: 6| Step: 8
Training loss: 2.699352123095549
Validation loss: 2.490021676348359

Epoch: 6| Step: 9
Training loss: 2.4580152812324454
Validation loss: 2.4807722892166115

Epoch: 6| Step: 10
Training loss: 2.6552184850878553
Validation loss: 2.495728053535028

Epoch: 6| Step: 11
Training loss: 2.218878728866345
Validation loss: 2.468931247801989

Epoch: 6| Step: 12
Training loss: 2.988379862037138
Validation loss: 2.4755890594803827

Epoch: 6| Step: 13
Training loss: 2.346993401965508
Validation loss: 2.4578670258808417

Epoch: 28| Step: 0
Training loss: 2.022127412254931
Validation loss: 2.462887188442413

Epoch: 6| Step: 1
Training loss: 2.478606622947821
Validation loss: 2.4480927640733676

Epoch: 6| Step: 2
Training loss: 2.279092055453005
Validation loss: 2.4503187744205595

Epoch: 6| Step: 3
Training loss: 2.697981687569877
Validation loss: 2.461721273275874

Epoch: 6| Step: 4
Training loss: 2.1929196386542436
Validation loss: 2.4510562864408785

Epoch: 6| Step: 5
Training loss: 2.4523513448694216
Validation loss: 2.455855775214327

Epoch: 6| Step: 6
Training loss: 2.7182661480984884
Validation loss: 2.466096627141628

Epoch: 6| Step: 7
Training loss: 2.6915649898760687
Validation loss: 2.4636113652268734

Epoch: 6| Step: 8
Training loss: 1.9746789212530262
Validation loss: 2.452373632544882

Epoch: 6| Step: 9
Training loss: 2.42284762633195
Validation loss: 2.461923327107634

Epoch: 6| Step: 10
Training loss: 2.3972829220442873
Validation loss: 2.4604620983980015

Epoch: 6| Step: 11
Training loss: 3.062850309305356
Validation loss: 2.4673258862812935

Epoch: 6| Step: 12
Training loss: 2.075368788705
Validation loss: 2.442585050702298

Epoch: 6| Step: 13
Training loss: 2.379451495043941
Validation loss: 2.4357570220011824

Epoch: 29| Step: 0
Training loss: 2.614560759144227
Validation loss: 2.474597701055444

Epoch: 6| Step: 1
Training loss: 2.1087301893496497
Validation loss: 2.480114832983126

Epoch: 6| Step: 2
Training loss: 2.239841097406707
Validation loss: 2.499489366516257

Epoch: 6| Step: 3
Training loss: 2.3866826880394996
Validation loss: 2.4821672046325847

Epoch: 6| Step: 4
Training loss: 2.298201197568837
Validation loss: 2.5052498055962285

Epoch: 6| Step: 5
Training loss: 2.126062688454133
Validation loss: 2.504125195718926

Epoch: 6| Step: 6
Training loss: 2.2032873215634643
Validation loss: 2.5657024996006674

Epoch: 6| Step: 7
Training loss: 3.66994812099782
Validation loss: 2.5939389968097024

Epoch: 6| Step: 8
Training loss: 2.2237883837144246
Validation loss: 2.5525514964738476

Epoch: 6| Step: 9
Training loss: 2.4961157187389067
Validation loss: 2.519775016091507

Epoch: 6| Step: 10
Training loss: 2.9174465953185234
Validation loss: 2.4837976980532934

Epoch: 6| Step: 11
Training loss: 2.0616168819122636
Validation loss: 2.468511465274589

Epoch: 6| Step: 12
Training loss: 1.7493069502558374
Validation loss: 2.457811418724267

Epoch: 6| Step: 13
Training loss: 2.4240474678528487
Validation loss: 2.44795294119289

Epoch: 30| Step: 0
Training loss: 2.013485031265535
Validation loss: 2.4612632576227127

Epoch: 6| Step: 1
Training loss: 2.8658316002171556
Validation loss: 2.4260887978937005

Epoch: 6| Step: 2
Training loss: 2.5346146814766795
Validation loss: 2.432688022533202

Epoch: 6| Step: 3
Training loss: 2.432585530360302
Validation loss: 2.454784900813839

Epoch: 6| Step: 4
Training loss: 2.5010909561157826
Validation loss: 2.456764404814667

Epoch: 6| Step: 5
Training loss: 2.390073425888865
Validation loss: 2.4368032290976425

Epoch: 6| Step: 6
Training loss: 2.431136603763192
Validation loss: 2.4427949175641706

Epoch: 6| Step: 7
Training loss: 1.861084865112977
Validation loss: 2.4508500859365614

Epoch: 6| Step: 8
Training loss: 2.7339505111356472
Validation loss: 2.4624221440899094

Epoch: 6| Step: 9
Training loss: 2.06985664387273
Validation loss: 2.4379619421498466

Epoch: 6| Step: 10
Training loss: 2.8850841307645356
Validation loss: 2.441744556638482

Epoch: 6| Step: 11
Training loss: 2.1548899908818395
Validation loss: 2.429760718187931

Epoch: 6| Step: 12
Training loss: 2.269171733908915
Validation loss: 2.4558302264220337

Epoch: 6| Step: 13
Training loss: 2.317502050470887
Validation loss: 2.476142663197144

Epoch: 31| Step: 0
Training loss: 2.724575247602127
Validation loss: 2.4552524922515606

Epoch: 6| Step: 1
Training loss: 2.9424975474435704
Validation loss: 2.494893819885049

Epoch: 6| Step: 2
Training loss: 2.850574729926152
Validation loss: 2.4697740901437975

Epoch: 6| Step: 3
Training loss: 2.7158204002887887
Validation loss: 2.478827594896207

Epoch: 6| Step: 4
Training loss: 2.33410807644863
Validation loss: 2.4844665030656676

Epoch: 6| Step: 5
Training loss: 2.2058514978083408
Validation loss: 2.4627820726391576

Epoch: 6| Step: 6
Training loss: 2.342088644576711
Validation loss: 2.498489980840274

Epoch: 6| Step: 7
Training loss: 2.3128026815741296
Validation loss: 2.4900349376326236

Epoch: 6| Step: 8
Training loss: 3.077119614669836
Validation loss: 2.4609895488744957

Epoch: 6| Step: 9
Training loss: 2.299625022009416
Validation loss: 2.4788336062634984

Epoch: 6| Step: 10
Training loss: 1.5144168718557895
Validation loss: 2.4716827581460166

Epoch: 6| Step: 11
Training loss: 2.133942133740127
Validation loss: 2.4421199233585558

Epoch: 6| Step: 12
Training loss: 1.873670360865353
Validation loss: 2.4448632507073107

Epoch: 6| Step: 13
Training loss: 1.8263033406472557
Validation loss: 2.454046129095734

Epoch: 32| Step: 0
Training loss: 2.504668073763269
Validation loss: 2.4349411142528155

Epoch: 6| Step: 1
Training loss: 2.6931481558653467
Validation loss: 2.442384227949035

Epoch: 6| Step: 2
Training loss: 2.1998477666376406
Validation loss: 2.4429941125424834

Epoch: 6| Step: 3
Training loss: 2.7899235269874314
Validation loss: 2.444892026523302

Epoch: 6| Step: 4
Training loss: 2.3572808881696683
Validation loss: 2.4443264599224053

Epoch: 6| Step: 5
Training loss: 2.612875959731886
Validation loss: 2.4638705581801243

Epoch: 6| Step: 6
Training loss: 2.7235501763414085
Validation loss: 2.424514783904256

Epoch: 6| Step: 7
Training loss: 2.5264683523666496
Validation loss: 2.459805659226356

Epoch: 6| Step: 8
Training loss: 2.1221425535261695
Validation loss: 2.436567258472631

Epoch: 6| Step: 9
Training loss: 2.0106430585084034
Validation loss: 2.453463893410399

Epoch: 6| Step: 10
Training loss: 2.2171711206671243
Validation loss: 2.4502201578262377

Epoch: 6| Step: 11
Training loss: 2.242139968634102
Validation loss: 2.4371302397578165

Epoch: 6| Step: 12
Training loss: 2.1065120907501487
Validation loss: 2.4212589259681425

Epoch: 6| Step: 13
Training loss: 2.425550465194262
Validation loss: 2.4709758944712807

Epoch: 33| Step: 0
Training loss: 2.7125344094058406
Validation loss: 2.4694151968047016

Epoch: 6| Step: 1
Training loss: 2.6164750225406515
Validation loss: 2.5046651070161534

Epoch: 6| Step: 2
Training loss: 1.89415512283954
Validation loss: 2.5075239370033287

Epoch: 6| Step: 3
Training loss: 2.486145348434496
Validation loss: 2.475259624697127

Epoch: 6| Step: 4
Training loss: 2.149546389078982
Validation loss: 2.509940428033222

Epoch: 6| Step: 5
Training loss: 1.9959223425441786
Validation loss: 2.4861475700911195

Epoch: 6| Step: 6
Training loss: 2.8982632731180886
Validation loss: 2.5047126221423173

Epoch: 6| Step: 7
Training loss: 2.142241153281646
Validation loss: 2.5099662651084826

Epoch: 6| Step: 8
Training loss: 2.3191552149985313
Validation loss: 2.5016348420706263

Epoch: 6| Step: 9
Training loss: 2.0523984508971735
Validation loss: 2.5018090060930596

Epoch: 6| Step: 10
Training loss: 2.3878412931473827
Validation loss: 2.489736374070923

Epoch: 6| Step: 11
Training loss: 2.1213067441329314
Validation loss: 2.4783953634254012

Epoch: 6| Step: 12
Training loss: 3.064700834475363
Validation loss: 2.472360264809107

Epoch: 6| Step: 13
Training loss: 2.1964030424931673
Validation loss: 2.454927774183949

Epoch: 34| Step: 0
Training loss: 2.3399696889365047
Validation loss: 2.4464929106164135

Epoch: 6| Step: 1
Training loss: 1.9021221556641308
Validation loss: 2.4455794004925013

Epoch: 6| Step: 2
Training loss: 2.370769346565941
Validation loss: 2.448092999431363

Epoch: 6| Step: 3
Training loss: 2.9203346802678953
Validation loss: 2.4613872621671966

Epoch: 6| Step: 4
Training loss: 2.447657621488604
Validation loss: 2.47597263182704

Epoch: 6| Step: 5
Training loss: 1.945114432060128
Validation loss: 2.4434646270712355

Epoch: 6| Step: 6
Training loss: 2.195518402543737
Validation loss: 2.4695060875928245

Epoch: 6| Step: 7
Training loss: 2.317502770612556
Validation loss: 2.4539663568774617

Epoch: 6| Step: 8
Training loss: 2.3818494507803933
Validation loss: 2.4073347643817433

Epoch: 6| Step: 9
Training loss: 2.6467901186973783
Validation loss: 2.4419455133598085

Epoch: 6| Step: 10
Training loss: 2.017733986106738
Validation loss: 2.4303518779125426

Epoch: 6| Step: 11
Training loss: 2.3176820789236006
Validation loss: 2.4323919358643664

Epoch: 6| Step: 12
Training loss: 2.7463682642506813
Validation loss: 2.4563897634253484

Epoch: 6| Step: 13
Training loss: 2.348051878841782
Validation loss: 2.462401294827797

Epoch: 35| Step: 0
Training loss: 2.8242918561704218
Validation loss: 2.463492634280599

Epoch: 6| Step: 1
Training loss: 2.611533545643627
Validation loss: 2.460965337040807

Epoch: 6| Step: 2
Training loss: 2.9513864395031706
Validation loss: 2.4657471820323096

Epoch: 6| Step: 3
Training loss: 2.9761454773180436
Validation loss: 2.4335740253430846

Epoch: 6| Step: 4
Training loss: 3.060306619977215
Validation loss: 2.4363292588686

Epoch: 6| Step: 5
Training loss: 2.012172610741305
Validation loss: 2.449611991208139

Epoch: 6| Step: 6
Training loss: 2.0656194505025445
Validation loss: 2.4587976426701528

Epoch: 6| Step: 7
Training loss: 1.9101414592146875
Validation loss: 2.4650863955241555

Epoch: 6| Step: 8
Training loss: 1.7967616833325155
Validation loss: 2.4594301966443646

Epoch: 6| Step: 9
Training loss: 1.7836448231025337
Validation loss: 2.4306109310078767

Epoch: 6| Step: 10
Training loss: 2.074715937278631
Validation loss: 2.451009109179242

Epoch: 6| Step: 11
Training loss: 2.1284018942778813
Validation loss: 2.474210936382721

Epoch: 6| Step: 12
Training loss: 2.1061086726103966
Validation loss: 2.4671210858467845

Epoch: 6| Step: 13
Training loss: 2.4498985113805127
Validation loss: 2.455469003746739

Epoch: 36| Step: 0
Training loss: 2.5379212617015767
Validation loss: 2.4762758235493156

Epoch: 6| Step: 1
Training loss: 2.660396436247434
Validation loss: 2.459528443955462

Epoch: 6| Step: 2
Training loss: 3.0050170590746386
Validation loss: 2.4621535349549304

Epoch: 6| Step: 3
Training loss: 2.1589296800929914
Validation loss: 2.4596730854198645

Epoch: 6| Step: 4
Training loss: 2.355305376602623
Validation loss: 2.457122332042586

Epoch: 6| Step: 5
Training loss: 2.2315595267884616
Validation loss: 2.430588926055951

Epoch: 6| Step: 6
Training loss: 1.922104240329686
Validation loss: 2.457409633981332

Epoch: 6| Step: 7
Training loss: 2.027784237205401
Validation loss: 2.440999323183638

Epoch: 6| Step: 8
Training loss: 2.421089094070729
Validation loss: 2.4588213506242136

Epoch: 6| Step: 9
Training loss: 2.350429730995828
Validation loss: 2.476396075732926

Epoch: 6| Step: 10
Training loss: 2.087829417659904
Validation loss: 2.4627525942323465

Epoch: 6| Step: 11
Training loss: 2.4386899928810495
Validation loss: 2.456095199301406

Epoch: 6| Step: 12
Training loss: 2.3455490328498634
Validation loss: 2.4608867498745672

Epoch: 6| Step: 13
Training loss: 2.39305320538404
Validation loss: 2.4674815689784784

Epoch: 37| Step: 0
Training loss: 2.485722398353204
Validation loss: 2.451543375057768

Epoch: 6| Step: 1
Training loss: 1.8070293606271197
Validation loss: 2.4675945443074156

Epoch: 6| Step: 2
Training loss: 2.11365374598063
Validation loss: 2.4742873177213265

Epoch: 6| Step: 3
Training loss: 2.8855192714768783
Validation loss: 2.4765595958544275

Epoch: 6| Step: 4
Training loss: 2.8153781998630594
Validation loss: 2.4708702302293184

Epoch: 6| Step: 5
Training loss: 2.5455278449527774
Validation loss: 2.4622629784182517

Epoch: 6| Step: 6
Training loss: 2.2440267323144343
Validation loss: 2.4531482606339816

Epoch: 6| Step: 7
Training loss: 2.49058935888963
Validation loss: 2.4517946705919034

Epoch: 6| Step: 8
Training loss: 2.041423264092057
Validation loss: 2.4357624789580035

Epoch: 6| Step: 9
Training loss: 2.6650809301859706
Validation loss: 2.467211537710112

Epoch: 6| Step: 10
Training loss: 1.7278287223155098
Validation loss: 2.4437270138205025

Epoch: 6| Step: 11
Training loss: 2.288096774275447
Validation loss: 2.415435145633544

Epoch: 6| Step: 12
Training loss: 1.9858891274888604
Validation loss: 2.4542696442773955

Epoch: 6| Step: 13
Training loss: 2.483736447977417
Validation loss: 2.4467855369741796

Epoch: 38| Step: 0
Training loss: 2.6616343062441508
Validation loss: 2.4426857812378597

Epoch: 6| Step: 1
Training loss: 2.025346363728043
Validation loss: 2.440201997916188

Epoch: 6| Step: 2
Training loss: 2.0031513182626575
Validation loss: 2.4435257645386956

Epoch: 6| Step: 3
Training loss: 2.7223719882206647
Validation loss: 2.4421746186713764

Epoch: 6| Step: 4
Training loss: 2.8119920059893566
Validation loss: 2.4404227266979435

Epoch: 6| Step: 5
Training loss: 2.6768474153303803
Validation loss: 2.4551603131028075

Epoch: 6| Step: 6
Training loss: 1.7704892964980845
Validation loss: 2.445777401996756

Epoch: 6| Step: 7
Training loss: 2.3494003342431857
Validation loss: 2.448719563940076

Epoch: 6| Step: 8
Training loss: 2.412060941758183
Validation loss: 2.4369714196420276

Epoch: 6| Step: 9
Training loss: 2.191522659772958
Validation loss: 2.4461021976331168

Epoch: 6| Step: 10
Training loss: 2.231412617717264
Validation loss: 2.4593990138948407

Epoch: 6| Step: 11
Training loss: 2.023166122796373
Validation loss: 2.465187979720838

Epoch: 6| Step: 12
Training loss: 2.2902546665230306
Validation loss: 2.457106006417006

Epoch: 6| Step: 13
Training loss: 2.195499507228976
Validation loss: 2.4520269799596894

Epoch: 39| Step: 0
Training loss: 2.12761045444887
Validation loss: 2.4714839138840303

Epoch: 6| Step: 1
Training loss: 2.4443236475295307
Validation loss: 2.4644934419913738

Epoch: 6| Step: 2
Training loss: 2.2853914058359135
Validation loss: 2.445244671385639

Epoch: 6| Step: 3
Training loss: 2.4300336683162214
Validation loss: 2.4186815845233784

Epoch: 6| Step: 4
Training loss: 2.6724759145566677
Validation loss: 2.4617210230791113

Epoch: 6| Step: 5
Training loss: 2.1746700606624674
Validation loss: 2.430949113560387

Epoch: 6| Step: 6
Training loss: 2.7111101342896053
Validation loss: 2.435865636796897

Epoch: 6| Step: 7
Training loss: 2.0763056542403198
Validation loss: 2.4629803126172094

Epoch: 6| Step: 8
Training loss: 2.2146748473337663
Validation loss: 2.390930521937435

Epoch: 6| Step: 9
Training loss: 2.4148407209482885
Validation loss: 2.464741418067444

Epoch: 6| Step: 10
Training loss: 1.4311426813794432
Validation loss: 2.460424072960784

Epoch: 6| Step: 11
Training loss: 2.2153522102928496
Validation loss: 2.4217703683872855

Epoch: 6| Step: 12
Training loss: 2.5481319017389326
Validation loss: 2.489246159363253

Epoch: 6| Step: 13
Training loss: 2.877245647944527
Validation loss: 2.4595135479702757

Epoch: 40| Step: 0
Training loss: 1.8324143389447465
Validation loss: 2.461012258857453

Epoch: 6| Step: 1
Training loss: 2.012724571255975
Validation loss: 2.467731458867704

Epoch: 6| Step: 2
Training loss: 2.129248691280295
Validation loss: 2.48861253769753

Epoch: 6| Step: 3
Training loss: 1.9673213922264683
Validation loss: 2.4744047277504677

Epoch: 6| Step: 4
Training loss: 2.148082911967271
Validation loss: 2.481783332806573

Epoch: 6| Step: 5
Training loss: 2.443451682221699
Validation loss: 2.5056004736126467

Epoch: 6| Step: 6
Training loss: 2.6332909576611914
Validation loss: 2.521077078602695

Epoch: 6| Step: 7
Training loss: 2.747577120086487
Validation loss: 2.53784673291843

Epoch: 6| Step: 8
Training loss: 2.8718758899575265
Validation loss: 2.5485274837908674

Epoch: 6| Step: 9
Training loss: 2.1273622285766725
Validation loss: 2.490095577984501

Epoch: 6| Step: 10
Training loss: 2.588758790845326
Validation loss: 2.488864201598781

Epoch: 6| Step: 11
Training loss: 2.3723949400268167
Validation loss: 2.456127993309393

Epoch: 6| Step: 12
Training loss: 2.157567271469028
Validation loss: 2.4697663834552905

Epoch: 6| Step: 13
Training loss: 2.5814104820038057
Validation loss: 2.423601761380597

Epoch: 41| Step: 0
Training loss: 1.6840392760138787
Validation loss: 2.430273249141076

Epoch: 6| Step: 1
Training loss: 2.501429530558496
Validation loss: 2.4111315105481586

Epoch: 6| Step: 2
Training loss: 2.7043925053396025
Validation loss: 2.4417010564194133

Epoch: 6| Step: 3
Training loss: 2.569957024478428
Validation loss: 2.428456238778373

Epoch: 6| Step: 4
Training loss: 2.422138224417846
Validation loss: 2.421531570859952

Epoch: 6| Step: 5
Training loss: 1.9394722406495966
Validation loss: 2.430520367746106

Epoch: 6| Step: 6
Training loss: 2.799595793431241
Validation loss: 2.438787788529805

Epoch: 6| Step: 7
Training loss: 2.234892031730762
Validation loss: 2.45110221449716

Epoch: 6| Step: 8
Training loss: 2.6620176639558366
Validation loss: 2.486520844147731

Epoch: 6| Step: 9
Training loss: 2.207091528145319
Validation loss: 2.471629535754552

Epoch: 6| Step: 10
Training loss: 2.327533416344268
Validation loss: 2.4428885474081254

Epoch: 6| Step: 11
Training loss: 1.98847166097704
Validation loss: 2.434596998402807

Epoch: 6| Step: 12
Training loss: 2.0956837847866914
Validation loss: 2.418533201794041

Epoch: 6| Step: 13
Training loss: 2.3582083741995787
Validation loss: 2.4205420979300407

Epoch: 42| Step: 0
Training loss: 2.613101513986761
Validation loss: 2.443477710081269

Epoch: 6| Step: 1
Training loss: 2.2569356621465415
Validation loss: 2.4472328258933693

Epoch: 6| Step: 2
Training loss: 2.5823112947662588
Validation loss: 2.4446751065472188

Epoch: 6| Step: 3
Training loss: 2.579327389624557
Validation loss: 2.44427647037589

Epoch: 6| Step: 4
Training loss: 2.173900839522563
Validation loss: 2.459562508892721

Epoch: 6| Step: 5
Training loss: 1.8673791507700606
Validation loss: 2.4032221483056984

Epoch: 6| Step: 6
Training loss: 2.4551783429724168
Validation loss: 2.4702338978091025

Epoch: 6| Step: 7
Training loss: 2.618604043248032
Validation loss: 2.4622164193443443

Epoch: 6| Step: 8
Training loss: 2.057347421655155
Validation loss: 2.441303692507364

Epoch: 6| Step: 9
Training loss: 2.450574387151986
Validation loss: 2.4518873814343056

Epoch: 6| Step: 10
Training loss: 1.934871551922653
Validation loss: 2.477186940568752

Epoch: 6| Step: 11
Training loss: 1.6405976792740071
Validation loss: 2.485998778643913

Epoch: 6| Step: 12
Training loss: 2.5658965511861855
Validation loss: 2.4871535288352056

Epoch: 6| Step: 13
Training loss: 2.3906066494904366
Validation loss: 2.482760482572872

Epoch: 43| Step: 0
Training loss: 2.4999208437785967
Validation loss: 2.468886504443475

Epoch: 6| Step: 1
Training loss: 2.3438063551167456
Validation loss: 2.492401002290863

Epoch: 6| Step: 2
Training loss: 2.6190324799401488
Validation loss: 2.431771418106446

Epoch: 6| Step: 3
Training loss: 2.365083571524053
Validation loss: 2.4372607219659894

Epoch: 6| Step: 4
Training loss: 2.104409937125293
Validation loss: 2.408710938740572

Epoch: 6| Step: 5
Training loss: 1.743128227485303
Validation loss: 2.454358788846285

Epoch: 6| Step: 6
Training loss: 2.3270603280109943
Validation loss: 2.4346082684164165

Epoch: 6| Step: 7
Training loss: 2.001110722152688
Validation loss: 2.455670358406082

Epoch: 6| Step: 8
Training loss: 3.0734648307201806
Validation loss: 2.450813354372707

Epoch: 6| Step: 9
Training loss: 2.259284677982071
Validation loss: 2.4499140172908778

Epoch: 6| Step: 10
Training loss: 1.6957481281641926
Validation loss: 2.491916366704529

Epoch: 6| Step: 11
Training loss: 2.0347628222318237
Validation loss: 2.501764310709773

Epoch: 6| Step: 12
Training loss: 2.6905945992164564
Validation loss: 2.5234652380899987

Epoch: 6| Step: 13
Training loss: 2.650116874708638
Validation loss: 2.520676605354671

Epoch: 44| Step: 0
Training loss: 2.003833315825217
Validation loss: 2.4983716430000222

Epoch: 6| Step: 1
Training loss: 2.271997369254295
Validation loss: 2.468215618967061

Epoch: 6| Step: 2
Training loss: 2.442282752817178
Validation loss: 2.4269523312383017

Epoch: 6| Step: 3
Training loss: 2.093852254164096
Validation loss: 2.4598605428362883

Epoch: 6| Step: 4
Training loss: 2.4980120384286626
Validation loss: 2.5017520646071856

Epoch: 6| Step: 5
Training loss: 2.0696511417854575
Validation loss: 2.4287154858869586

Epoch: 6| Step: 6
Training loss: 2.7508209043644016
Validation loss: 2.438464202258818

Epoch: 6| Step: 7
Training loss: 3.0438911107622175
Validation loss: 2.467831895621683

Epoch: 6| Step: 8
Training loss: 2.260809892007254
Validation loss: 2.433444537491479

Epoch: 6| Step: 9
Training loss: 2.1137209732706532
Validation loss: 2.45324435419542

Epoch: 6| Step: 10
Training loss: 1.8034260622440836
Validation loss: 2.4481112842436925

Epoch: 6| Step: 11
Training loss: 1.9911860323663189
Validation loss: 2.437538969918453

Epoch: 6| Step: 12
Training loss: 2.2622188878216973
Validation loss: 2.435978748950228

Epoch: 6| Step: 13
Training loss: 2.3198245784604277
Validation loss: 2.461412769422726

Epoch: 45| Step: 0
Training loss: 2.193562634935741
Validation loss: 2.4606333549705837

Epoch: 6| Step: 1
Training loss: 2.791716608388379
Validation loss: 2.4327529916282007

Epoch: 6| Step: 2
Training loss: 1.3989017504480492
Validation loss: 2.411687215292631

Epoch: 6| Step: 3
Training loss: 2.250784843042082
Validation loss: 2.4459774425451055

Epoch: 6| Step: 4
Training loss: 1.9837566223226293
Validation loss: 2.464724175585103

Epoch: 6| Step: 5
Training loss: 2.333726225426916
Validation loss: 2.4569692841414645

Epoch: 6| Step: 6
Training loss: 2.5642483027317664
Validation loss: 2.464403728821054

Epoch: 6| Step: 7
Training loss: 2.706061912149775
Validation loss: 2.4867366625937355

Epoch: 6| Step: 8
Training loss: 2.482875827488226
Validation loss: 2.455525885724451

Epoch: 6| Step: 9
Training loss: 2.55215403141008
Validation loss: 2.4902195509924376

Epoch: 6| Step: 10
Training loss: 1.8970366281845235
Validation loss: 2.456868880445515

Epoch: 6| Step: 11
Training loss: 2.369412324048421
Validation loss: 2.468682477325417

Epoch: 6| Step: 12
Training loss: 2.125667018547984
Validation loss: 2.4310561778681854

Epoch: 6| Step: 13
Training loss: 2.4039503726375058
Validation loss: 2.441775199986369

Epoch: 46| Step: 0
Training loss: 2.423347468520772
Validation loss: 2.4328011190923657

Epoch: 6| Step: 1
Training loss: 2.646491401916409
Validation loss: 2.441301430041483

Epoch: 6| Step: 2
Training loss: 2.2251154966059814
Validation loss: 2.4435323587399096

Epoch: 6| Step: 3
Training loss: 2.4578978158120472
Validation loss: 2.452338001333197

Epoch: 6| Step: 4
Training loss: 1.882020902625016
Validation loss: 2.436194877411934

Epoch: 6| Step: 5
Training loss: 2.6523299968289877
Validation loss: 2.4228483233621745

Epoch: 6| Step: 6
Training loss: 2.086251224542605
Validation loss: 2.4438961586980543

Epoch: 6| Step: 7
Training loss: 2.4500420508376592
Validation loss: 2.423279254664984

Epoch: 6| Step: 8
Training loss: 1.9065984813907024
Validation loss: 2.4627779744033895

Epoch: 6| Step: 9
Training loss: 2.405460872308928
Validation loss: 2.445939573702411

Epoch: 6| Step: 10
Training loss: 2.0359157089741835
Validation loss: 2.4568967069774654

Epoch: 6| Step: 11
Training loss: 2.8789393760814663
Validation loss: 2.4756498048909306

Epoch: 6| Step: 12
Training loss: 1.7868939712867609
Validation loss: 2.4537364740269347

Epoch: 6| Step: 13
Training loss: 2.0730864744427757
Validation loss: 2.444975467160953

Epoch: 47| Step: 0
Training loss: 2.5625171195598107
Validation loss: 2.476018763719639

Epoch: 6| Step: 1
Training loss: 1.7780949943705868
Validation loss: 2.4519378154382636

Epoch: 6| Step: 2
Training loss: 1.524859034167231
Validation loss: 2.5074762453657273

Epoch: 6| Step: 3
Training loss: 2.5471395343471235
Validation loss: 2.4348632538327717

Epoch: 6| Step: 4
Training loss: 2.4556914104473155
Validation loss: 2.4583457418441115

Epoch: 6| Step: 5
Training loss: 2.799771306371461
Validation loss: 2.4278056389233007

Epoch: 6| Step: 6
Training loss: 2.674076355807637
Validation loss: 2.4424293591928126

Epoch: 6| Step: 7
Training loss: 2.3850583358444
Validation loss: 2.4268390685408145

Epoch: 6| Step: 8
Training loss: 2.3904937508650392
Validation loss: 2.4243138738736145

Epoch: 6| Step: 9
Training loss: 2.3524812950177103
Validation loss: 2.4164206993508857

Epoch: 6| Step: 10
Training loss: 1.9145823492878518
Validation loss: 2.416838382232775

Epoch: 6| Step: 11
Training loss: 2.5564824602527745
Validation loss: 2.4182637927728345

Epoch: 6| Step: 12
Training loss: 2.070449651817612
Validation loss: 2.434152611436481

Epoch: 6| Step: 13
Training loss: 1.3284587665112826
Validation loss: 2.4505195387952723

Epoch: 48| Step: 0
Training loss: 1.9510780288992842
Validation loss: 2.4399934388682216

Epoch: 6| Step: 1
Training loss: 1.9675011079583933
Validation loss: 2.476425905201207

Epoch: 6| Step: 2
Training loss: 2.884771079727832
Validation loss: 2.4863775247888946

Epoch: 6| Step: 3
Training loss: 2.1594419212294946
Validation loss: 2.501880725107878

Epoch: 6| Step: 4
Training loss: 2.867425311046255
Validation loss: 2.5628094214973

Epoch: 6| Step: 5
Training loss: 2.380107807955395
Validation loss: 2.5091707190011387

Epoch: 6| Step: 6
Training loss: 2.3269099194542093
Validation loss: 2.506396154135992

Epoch: 6| Step: 7
Training loss: 2.397898262366474
Validation loss: 2.5238205704592938

Epoch: 6| Step: 8
Training loss: 2.146744938760142
Validation loss: 2.4849081526987744

Epoch: 6| Step: 9
Training loss: 2.529761265132193
Validation loss: 2.44989080704755

Epoch: 6| Step: 10
Training loss: 1.7189846918956782
Validation loss: 2.4561891472212993

Epoch: 6| Step: 11
Training loss: 2.1913579435685127
Validation loss: 2.426865503798683

Epoch: 6| Step: 12
Training loss: 2.18536228903827
Validation loss: 2.4206412669780324

Epoch: 6| Step: 13
Training loss: 1.9763658146759673
Validation loss: 2.4341369643113797

Epoch: 49| Step: 0
Training loss: 2.758646290553444
Validation loss: 2.4245237243251028

Epoch: 6| Step: 1
Training loss: 1.7559295742102476
Validation loss: 2.4001488891088703

Epoch: 6| Step: 2
Training loss: 2.160254809043678
Validation loss: 2.423554918669467

Epoch: 6| Step: 3
Training loss: 2.53063957483377
Validation loss: 2.4444486089391586

Epoch: 6| Step: 4
Training loss: 1.8772668486999997
Validation loss: 2.462003010978066

Epoch: 6| Step: 5
Training loss: 2.2965482103041026
Validation loss: 2.463351685266783

Epoch: 6| Step: 6
Training loss: 2.0656607712780604
Validation loss: 2.4724474392386937

Epoch: 6| Step: 7
Training loss: 1.895313974302871
Validation loss: 2.4829801886530327

Epoch: 6| Step: 8
Training loss: 2.0363942662248458
Validation loss: 2.4764922219301964

Epoch: 6| Step: 9
Training loss: 2.301381782434307
Validation loss: 2.4847865373610696

Epoch: 6| Step: 10
Training loss: 2.814091634731928
Validation loss: 2.4982959502843767

Epoch: 6| Step: 11
Training loss: 2.3176200478415843
Validation loss: 2.4788354176859837

Epoch: 6| Step: 12
Training loss: 2.437098543412378
Validation loss: 2.458891099489351

Epoch: 6| Step: 13
Training loss: 2.4766972742803537
Validation loss: 2.5139610205243152

Epoch: 50| Step: 0
Training loss: 2.4678227095521366
Validation loss: 2.464207159459394

Epoch: 6| Step: 1
Training loss: 2.4232892245021804
Validation loss: 2.442985215318132

Epoch: 6| Step: 2
Training loss: 2.180634105047808
Validation loss: 2.429901391659397

Epoch: 6| Step: 3
Training loss: 1.820195599514666
Validation loss: 2.4410744159252453

Epoch: 6| Step: 4
Training loss: 2.141873628979331
Validation loss: 2.4089430729035906

Epoch: 6| Step: 5
Training loss: 1.9549755637356359
Validation loss: 2.434066310208133

Epoch: 6| Step: 6
Training loss: 2.413547300404337
Validation loss: 2.4698721029654385

Epoch: 6| Step: 7
Training loss: 1.9301071637302074
Validation loss: 2.4700765466090298

Epoch: 6| Step: 8
Training loss: 2.499991989122907
Validation loss: 2.4624115096973136

Epoch: 6| Step: 9
Training loss: 2.1215327530417727
Validation loss: 2.4505486860053827

Epoch: 6| Step: 10
Training loss: 2.3181478247980576
Validation loss: 2.4054523400968044

Epoch: 6| Step: 11
Training loss: 1.7710014113900383
Validation loss: 2.4496901614656497

Epoch: 6| Step: 12
Training loss: 2.3318279950944185
Validation loss: 2.493423251206825

Epoch: 6| Step: 13
Training loss: 2.9419307975591393
Validation loss: 2.4208134365303704

Epoch: 51| Step: 0
Training loss: 1.9846608714445257
Validation loss: 2.5065359191918257

Epoch: 6| Step: 1
Training loss: 1.723924926557066
Validation loss: 2.494900142936769

Epoch: 6| Step: 2
Training loss: 2.0060131753201684
Validation loss: 2.49916426676853

Epoch: 6| Step: 3
Training loss: 1.7486866382302393
Validation loss: 2.5722329213181014

Epoch: 6| Step: 4
Training loss: 2.8879174000982157
Validation loss: 2.5884891072290235

Epoch: 6| Step: 5
Training loss: 2.736755032833814
Validation loss: 2.5839610157605426

Epoch: 6| Step: 6
Training loss: 2.4389207074178394
Validation loss: 2.5459004977576054

Epoch: 6| Step: 7
Training loss: 2.846502460177813
Validation loss: 2.4957069093233004

Epoch: 6| Step: 8
Training loss: 2.013425469700777
Validation loss: 2.4683509777819914

Epoch: 6| Step: 9
Training loss: 2.7100777705671053
Validation loss: 2.4520540673760083

Epoch: 6| Step: 10
Training loss: 1.6599902260733885
Validation loss: 2.4432947611225297

Epoch: 6| Step: 11
Training loss: 2.06227041180438
Validation loss: 2.4294243902130908

Epoch: 6| Step: 12
Training loss: 2.3034496021690307
Validation loss: 2.437451158343965

Epoch: 6| Step: 13
Training loss: 2.472326078864674
Validation loss: 2.4140287147964323

Epoch: 52| Step: 0
Training loss: 2.503556296996867
Validation loss: 2.472260928178411

Epoch: 6| Step: 1
Training loss: 2.4436867278900873
Validation loss: 2.4391346039623443

Epoch: 6| Step: 2
Training loss: 2.3454481966229808
Validation loss: 2.447509932038388

Epoch: 6| Step: 3
Training loss: 2.181700948975757
Validation loss: 2.4564060533695478

Epoch: 6| Step: 4
Training loss: 1.5048964374180422
Validation loss: 2.405171544875929

Epoch: 6| Step: 5
Training loss: 1.7604332270398229
Validation loss: 2.4224836097506626

Epoch: 6| Step: 6
Training loss: 1.8444511244294155
Validation loss: 2.4392823280912577

Epoch: 6| Step: 7
Training loss: 2.228819656695614
Validation loss: 2.4663091173802694

Epoch: 6| Step: 8
Training loss: 2.6629939019666606
Validation loss: 2.4632404188907175

Epoch: 6| Step: 9
Training loss: 2.714009503960045
Validation loss: 2.438418174679132

Epoch: 6| Step: 10
Training loss: 2.5010547320368746
Validation loss: 2.501110815585504

Epoch: 6| Step: 11
Training loss: 1.9778338177322141
Validation loss: 2.491881077662292

Epoch: 6| Step: 12
Training loss: 1.9288388135021262
Validation loss: 2.5011540292467336

Epoch: 6| Step: 13
Training loss: 2.259026013194579
Validation loss: 2.4860204369924075

Epoch: 53| Step: 0
Training loss: 2.687950096586751
Validation loss: 2.49875248936702

Epoch: 6| Step: 1
Training loss: 2.1708301253731346
Validation loss: 2.4874512122911367

Epoch: 6| Step: 2
Training loss: 2.6322849548842004
Validation loss: 2.4998926775466384

Epoch: 6| Step: 3
Training loss: 1.7971320590371256
Validation loss: 2.4973998296796522

Epoch: 6| Step: 4
Training loss: 1.7457367875649294
Validation loss: 2.4389966461786283

Epoch: 6| Step: 5
Training loss: 1.8369029002684514
Validation loss: 2.4362206647426943

Epoch: 6| Step: 6
Training loss: 2.4603603110021983
Validation loss: 2.443717168016692

Epoch: 6| Step: 7
Training loss: 2.695970537879315
Validation loss: 2.4366353612559557

Epoch: 6| Step: 8
Training loss: 2.3074894828184744
Validation loss: 2.4302771896328843

Epoch: 6| Step: 9
Training loss: 2.308818051048345
Validation loss: 2.4609755417239936

Epoch: 6| Step: 10
Training loss: 2.05650452311116
Validation loss: 2.446516932713908

Epoch: 6| Step: 11
Training loss: 2.833559662998034
Validation loss: 2.4534931595025884

Epoch: 6| Step: 12
Training loss: 1.9631612866292842
Validation loss: 2.456842525412794

Epoch: 6| Step: 13
Training loss: 1.7912952200698091
Validation loss: 2.416378091705009

Epoch: 54| Step: 0
Training loss: 1.7337165476150838
Validation loss: 2.399583341935556

Epoch: 6| Step: 1
Training loss: 2.146869767139615
Validation loss: 2.4463981274158115

Epoch: 6| Step: 2
Training loss: 2.0019959980165343
Validation loss: 2.4547710848830397

Epoch: 6| Step: 3
Training loss: 2.2280270762279315
Validation loss: 2.513772871057893

Epoch: 6| Step: 4
Training loss: 2.5303853759975006
Validation loss: 2.557424760658272

Epoch: 6| Step: 5
Training loss: 2.55624332940087
Validation loss: 2.5885121876645405

Epoch: 6| Step: 6
Training loss: 2.436972732247385
Validation loss: 2.6140456590339896

Epoch: 6| Step: 7
Training loss: 2.1632413442339993
Validation loss: 2.568456062459915

Epoch: 6| Step: 8
Training loss: 2.9450800067804423
Validation loss: 2.544980785969349

Epoch: 6| Step: 9
Training loss: 2.593808184970728
Validation loss: 2.5378559395336553

Epoch: 6| Step: 10
Training loss: 1.696137890972748
Validation loss: 2.445588678236009

Epoch: 6| Step: 11
Training loss: 2.2242049736343974
Validation loss: 2.4518447337477296

Epoch: 6| Step: 12
Training loss: 2.0754523048590814
Validation loss: 2.416682922922465

Epoch: 6| Step: 13
Training loss: 2.0894759095084146
Validation loss: 2.456856984729329

Epoch: 55| Step: 0
Training loss: 2.4110718012924353
Validation loss: 2.4401752756044774

Epoch: 6| Step: 1
Training loss: 1.8770741752149895
Validation loss: 2.440617165774749

Epoch: 6| Step: 2
Training loss: 2.5111894064581075
Validation loss: 2.4477522990999363

Epoch: 6| Step: 3
Training loss: 2.131456999360886
Validation loss: 2.446677837329002

Epoch: 6| Step: 4
Training loss: 2.206742259322182
Validation loss: 2.46721917990312

Epoch: 6| Step: 5
Training loss: 2.4225689293785497
Validation loss: 2.4378068518877787

Epoch: 6| Step: 6
Training loss: 1.9221103182996837
Validation loss: 2.463530257496347

Epoch: 6| Step: 7
Training loss: 1.9122460913561465
Validation loss: 2.4408031644440356

Epoch: 6| Step: 8
Training loss: 2.5184735584245552
Validation loss: 2.470859342720153

Epoch: 6| Step: 9
Training loss: 1.7706731686434425
Validation loss: 2.4373141160822285

Epoch: 6| Step: 10
Training loss: 2.561366318927999
Validation loss: 2.433809975967737

Epoch: 6| Step: 11
Training loss: 2.388270995592559
Validation loss: 2.46598851401363

Epoch: 6| Step: 12
Training loss: 1.8602364732281014
Validation loss: 2.5081329299442707

Epoch: 6| Step: 13
Training loss: 2.5179696855060993
Validation loss: 2.5186066264072196

Epoch: 56| Step: 0
Training loss: 2.3438788823613397
Validation loss: 2.5805694705171414

Epoch: 6| Step: 1
Training loss: 2.4990595002160547
Validation loss: 2.5279052440820555

Epoch: 6| Step: 2
Training loss: 2.2659061652044903
Validation loss: 2.567511093786751

Epoch: 6| Step: 3
Training loss: 2.5733398418970106
Validation loss: 2.490925691674174

Epoch: 6| Step: 4
Training loss: 1.9459089107934175
Validation loss: 2.450010051187671

Epoch: 6| Step: 5
Training loss: 2.9456557015725773
Validation loss: 2.445597915323958

Epoch: 6| Step: 6
Training loss: 2.1555276296495522
Validation loss: 2.450473397120466

Epoch: 6| Step: 7
Training loss: 2.29613072799391
Validation loss: 2.431906370785623

Epoch: 6| Step: 8
Training loss: 1.8109589964649784
Validation loss: 2.4473962325275553

Epoch: 6| Step: 9
Training loss: 2.2457017108609545
Validation loss: 2.457870720046271

Epoch: 6| Step: 10
Training loss: 1.6187717951776497
Validation loss: 2.4525689306757066

Epoch: 6| Step: 11
Training loss: 2.03875858775189
Validation loss: 2.431891534363959

Epoch: 6| Step: 12
Training loss: 2.5840434257236065
Validation loss: 2.418635279048384

Epoch: 6| Step: 13
Training loss: 1.7771591593704754
Validation loss: 2.434282902292324

Epoch: 57| Step: 0
Training loss: 2.104967726507623
Validation loss: 2.3976325756406958

Epoch: 6| Step: 1
Training loss: 2.1516899874502147
Validation loss: 2.4353468261398574

Epoch: 6| Step: 2
Training loss: 2.3150229223447107
Validation loss: 2.455104231916888

Epoch: 6| Step: 3
Training loss: 1.5637344061960579
Validation loss: 2.4966866789432967

Epoch: 6| Step: 4
Training loss: 2.940062358999327
Validation loss: 2.477599078473831

Epoch: 6| Step: 5
Training loss: 1.6510485178647858
Validation loss: 2.50540789776216

Epoch: 6| Step: 6
Training loss: 3.0340047687047953
Validation loss: 2.4946689827736823

Epoch: 6| Step: 7
Training loss: 2.2706896768562506
Validation loss: 2.4858133482846356

Epoch: 6| Step: 8
Training loss: 2.1659058800181996
Validation loss: 2.441562047437776

Epoch: 6| Step: 9
Training loss: 2.2342435357959736
Validation loss: 2.446641489760384

Epoch: 6| Step: 10
Training loss: 1.9212869504354877
Validation loss: 2.3792060116144014

Epoch: 6| Step: 11
Training loss: 1.8132654744077938
Validation loss: 2.4532233378468096

Epoch: 6| Step: 12
Training loss: 2.293365600140855
Validation loss: 2.44904048094465

Epoch: 6| Step: 13
Training loss: 2.163662098774515
Validation loss: 2.4315535727651088

Epoch: 58| Step: 0
Training loss: 1.9421500732547567
Validation loss: 2.4553629715755356

Epoch: 6| Step: 1
Training loss: 1.9390738463089046
Validation loss: 2.4466318911836384

Epoch: 6| Step: 2
Training loss: 2.5175250915670975
Validation loss: 2.4477436789134033

Epoch: 6| Step: 3
Training loss: 2.013647721272453
Validation loss: 2.4487425581030506

Epoch: 6| Step: 4
Training loss: 2.047002773810419
Validation loss: 2.4830206292256034

Epoch: 6| Step: 5
Training loss: 2.094106615356413
Validation loss: 2.4700992856553716

Epoch: 6| Step: 6
Training loss: 2.986942963961397
Validation loss: 2.477229689329489

Epoch: 6| Step: 7
Training loss: 2.247116572481237
Validation loss: 2.4428867906616003

Epoch: 6| Step: 8
Training loss: 2.1024646737014625
Validation loss: 2.4852637054962874

Epoch: 6| Step: 9
Training loss: 2.077858585116815
Validation loss: 2.4605234433572605

Epoch: 6| Step: 10
Training loss: 1.9479652303533992
Validation loss: 2.451933618046276

Epoch: 6| Step: 11
Training loss: 1.8436206836933124
Validation loss: 2.4429635007497104

Epoch: 6| Step: 12
Training loss: 2.013561286442569
Validation loss: 2.440265065319703

Epoch: 6| Step: 13
Training loss: 2.699003219280323
Validation loss: 2.4265188753227256

Epoch: 59| Step: 0
Training loss: 2.2565389559100892
Validation loss: 2.4462671823341604

Epoch: 6| Step: 1
Training loss: 2.070564456219221
Validation loss: 2.4382659491169223

Epoch: 6| Step: 2
Training loss: 2.07232936290115
Validation loss: 2.44890254573866

Epoch: 6| Step: 3
Training loss: 1.918861197067057
Validation loss: 2.4670148699301597

Epoch: 6| Step: 4
Training loss: 1.8863350614324217
Validation loss: 2.4352174162360107

Epoch: 6| Step: 5
Training loss: 2.2819211834695645
Validation loss: 2.4507024996987754

Epoch: 6| Step: 6
Training loss: 1.5409965175512574
Validation loss: 2.4203339626870255

Epoch: 6| Step: 7
Training loss: 1.8202878107189338
Validation loss: 2.4147580491434155

Epoch: 6| Step: 8
Training loss: 1.9977113622911038
Validation loss: 2.427049568388909

Epoch: 6| Step: 9
Training loss: 2.2563879673586107
Validation loss: 2.444766908988103

Epoch: 6| Step: 10
Training loss: 2.6620334270164103
Validation loss: 2.4391756900229034

Epoch: 6| Step: 11
Training loss: 2.4490162645565463
Validation loss: 2.4391692143713555

Epoch: 6| Step: 12
Training loss: 2.256667113912173
Validation loss: 2.4347405096821517

Epoch: 6| Step: 13
Training loss: 2.537383759941496
Validation loss: 2.4434753276614143

Epoch: 60| Step: 0
Training loss: 2.221739353594399
Validation loss: 2.4266113318913134

Epoch: 6| Step: 1
Training loss: 1.8158399786206805
Validation loss: 2.48686106669372

Epoch: 6| Step: 2
Training loss: 2.3915895996791456
Validation loss: 2.503852561974186

Epoch: 6| Step: 3
Training loss: 1.3738588018954025
Validation loss: 2.540742242226416

Epoch: 6| Step: 4
Training loss: 1.5789182576624676
Validation loss: 2.5577475199118926

Epoch: 6| Step: 5
Training loss: 1.8813780072533957
Validation loss: 2.578969350938636

Epoch: 6| Step: 6
Training loss: 2.025525050912123
Validation loss: 2.560651779450662

Epoch: 6| Step: 7
Training loss: 1.8213092219896356
Validation loss: 2.5273360459113485

Epoch: 6| Step: 8
Training loss: 1.9545098849925133
Validation loss: 2.5557487220137807

Epoch: 6| Step: 9
Training loss: 2.6545051678240594
Validation loss: 2.523911202358423

Epoch: 6| Step: 10
Training loss: 1.9688658301778263
Validation loss: 2.514513168894161

Epoch: 6| Step: 11
Training loss: 2.1879899702382737
Validation loss: 2.466680149952234

Epoch: 6| Step: 12
Training loss: 2.89764459257437
Validation loss: 2.4246530986039514

Epoch: 6| Step: 13
Training loss: 2.6788675816621783
Validation loss: 2.4162709197118755

Epoch: 61| Step: 0
Training loss: 1.9273264413712812
Validation loss: 2.4313215380867947

Epoch: 6| Step: 1
Training loss: 1.8489319991981024
Validation loss: 2.4847923424099014

Epoch: 6| Step: 2
Training loss: 2.6013083577243497
Validation loss: 2.504142174836371

Epoch: 6| Step: 3
Training loss: 2.318819638257902
Validation loss: 2.529233576744748

Epoch: 6| Step: 4
Training loss: 2.3481815404230244
Validation loss: 2.5243209064150394

Epoch: 6| Step: 5
Training loss: 1.6543844981221727
Validation loss: 2.5027822589257878

Epoch: 6| Step: 6
Training loss: 2.781002076489422
Validation loss: 2.4844120270790846

Epoch: 6| Step: 7
Training loss: 2.3002602678734587
Validation loss: 2.449261808447845

Epoch: 6| Step: 8
Training loss: 2.0758802867690465
Validation loss: 2.4188985603176945

Epoch: 6| Step: 9
Training loss: 2.2410885979000685
Validation loss: 2.434530601376515

Epoch: 6| Step: 10
Training loss: 2.5269734555032657
Validation loss: 2.44954158879975

Epoch: 6| Step: 11
Training loss: 1.1418142520340475
Validation loss: 2.5243663515246757

Epoch: 6| Step: 12
Training loss: 2.4458537614826024
Validation loss: 2.5628721385650146

Epoch: 6| Step: 13
Training loss: 1.8877668608926779
Validation loss: 2.6517454810650816

Epoch: 62| Step: 0
Training loss: 2.087162643858045
Validation loss: 2.668117893233656

Epoch: 6| Step: 1
Training loss: 2.422230454478531
Validation loss: 2.6673783951903136

Epoch: 6| Step: 2
Training loss: 2.372712087366719
Validation loss: 2.6376672767035214

Epoch: 6| Step: 3
Training loss: 2.3978266730325295
Validation loss: 2.59540930683609

Epoch: 6| Step: 4
Training loss: 2.0348312499166132
Validation loss: 2.5062064220162825

Epoch: 6| Step: 5
Training loss: 1.9633017949138607
Validation loss: 2.4279066716722677

Epoch: 6| Step: 6
Training loss: 1.738023374481523
Validation loss: 2.4303829428521038

Epoch: 6| Step: 7
Training loss: 2.6448655248252564
Validation loss: 2.4460315479974346

Epoch: 6| Step: 8
Training loss: 2.1808033483142295
Validation loss: 2.433630243459448

Epoch: 6| Step: 9
Training loss: 2.276692894504806
Validation loss: 2.425545435780615

Epoch: 6| Step: 10
Training loss: 2.0852256446059068
Validation loss: 2.4273770090539415

Epoch: 6| Step: 11
Training loss: 1.7406009583379507
Validation loss: 2.439584134495639

Epoch: 6| Step: 12
Training loss: 2.2434688721400238
Validation loss: 2.440799810748706

Epoch: 6| Step: 13
Training loss: 2.220865235329162
Validation loss: 2.4211997618786403

Epoch: 63| Step: 0
Training loss: 2.301831975364418
Validation loss: 2.4379470773835528

Epoch: 6| Step: 1
Training loss: 1.8684502964120704
Validation loss: 2.4132790719126707

Epoch: 6| Step: 2
Training loss: 2.354414721448307
Validation loss: 2.404159760974859

Epoch: 6| Step: 3
Training loss: 2.3906414555001976
Validation loss: 2.3977028780990124

Epoch: 6| Step: 4
Training loss: 1.8803721714932966
Validation loss: 2.4639998178647127

Epoch: 6| Step: 5
Training loss: 1.8669541983316604
Validation loss: 2.4560740212904952

Epoch: 6| Step: 6
Training loss: 1.9828136038269866
Validation loss: 2.44786546261309

Epoch: 6| Step: 7
Training loss: 1.8324172014003233
Validation loss: 2.4150354509009127

Epoch: 6| Step: 8
Training loss: 1.8791667416636697
Validation loss: 2.435790448728625

Epoch: 6| Step: 9
Training loss: 1.7207978966168505
Validation loss: 2.4487826878363688

Epoch: 6| Step: 10
Training loss: 2.6587822904719824
Validation loss: 2.4375143295258135

Epoch: 6| Step: 11
Training loss: 2.1784435810928495
Validation loss: 2.4433311259514316

Epoch: 6| Step: 12
Training loss: 2.4696761699707683
Validation loss: 2.4694328892721993

Epoch: 6| Step: 13
Training loss: 2.1082453210526126
Validation loss: 2.4439753084636773

Epoch: 64| Step: 0
Training loss: 1.8056702683354011
Validation loss: 2.4937960417280816

Epoch: 6| Step: 1
Training loss: 2.100354496235618
Validation loss: 2.498399110665735

Epoch: 6| Step: 2
Training loss: 2.3581477124747927
Validation loss: 2.462573191076272

Epoch: 6| Step: 3
Training loss: 2.2589490729101143
Validation loss: 2.4338209394171475

Epoch: 6| Step: 4
Training loss: 1.5220079806465718
Validation loss: 2.451566910035685

Epoch: 6| Step: 5
Training loss: 2.2009515525134193
Validation loss: 2.4522175173370315

Epoch: 6| Step: 6
Training loss: 1.7394725360725332
Validation loss: 2.4771983055551834

Epoch: 6| Step: 7
Training loss: 1.8468905065824675
Validation loss: 2.4357238884672494

Epoch: 6| Step: 8
Training loss: 2.4337900734665063
Validation loss: 2.4764626820822584

Epoch: 6| Step: 9
Training loss: 2.2027043150616166
Validation loss: 2.5063906844965524

Epoch: 6| Step: 10
Training loss: 2.491843459917848
Validation loss: 2.476431392885665

Epoch: 6| Step: 11
Training loss: 1.906682575110557
Validation loss: 2.4455688634679142

Epoch: 6| Step: 12
Training loss: 1.9504679191824115
Validation loss: 2.497376655024989

Epoch: 6| Step: 13
Training loss: 2.236638556510797
Validation loss: 2.474363150687486

Epoch: 65| Step: 0
Training loss: 2.3188901709785728
Validation loss: 2.4421137809406552

Epoch: 6| Step: 1
Training loss: 2.106862811582623
Validation loss: 2.4786397283139157

Epoch: 6| Step: 2
Training loss: 2.363485431520526
Validation loss: 2.4364632578051575

Epoch: 6| Step: 3
Training loss: 2.1946239545558597
Validation loss: 2.434988504913999

Epoch: 6| Step: 4
Training loss: 2.0041622719614085
Validation loss: 2.4793189560306743

Epoch: 6| Step: 5
Training loss: 1.7088928546922886
Validation loss: 2.4640945851767477

Epoch: 6| Step: 6
Training loss: 2.638151014353828
Validation loss: 2.418867200037622

Epoch: 6| Step: 7
Training loss: 1.5936089247553222
Validation loss: 2.4347360296728917

Epoch: 6| Step: 8
Training loss: 2.1921477941613636
Validation loss: 2.444898787693849

Epoch: 6| Step: 9
Training loss: 2.0303882825112023
Validation loss: 2.4742577033694992

Epoch: 6| Step: 10
Training loss: 2.137956835911441
Validation loss: 2.481182286117663

Epoch: 6| Step: 11
Training loss: 1.8430949195018962
Validation loss: 2.4665734236938617

Epoch: 6| Step: 12
Training loss: 2.334877819973478
Validation loss: 2.4736960556473586

Epoch: 6| Step: 13
Training loss: 1.5950889199084015
Validation loss: 2.4427799032716475

Epoch: 66| Step: 0
Training loss: 2.157910578305979
Validation loss: 2.492380674841703

Epoch: 6| Step: 1
Training loss: 2.4199968500353277
Validation loss: 2.483064701818204

Epoch: 6| Step: 2
Training loss: 1.8344195644807664
Validation loss: 2.4565246739063586

Epoch: 6| Step: 3
Training loss: 2.366960873472625
Validation loss: 2.4485643111779036

Epoch: 6| Step: 4
Training loss: 2.5860423271391224
Validation loss: 2.423238317230775

Epoch: 6| Step: 5
Training loss: 2.218915154126484
Validation loss: 2.461015601155064

Epoch: 6| Step: 6
Training loss: 1.3824984953666901
Validation loss: 2.446173324435896

Epoch: 6| Step: 7
Training loss: 2.4844456308749114
Validation loss: 2.4582141319298025

Epoch: 6| Step: 8
Training loss: 1.271939197766521
Validation loss: 2.4712607577444636

Epoch: 6| Step: 9
Training loss: 1.7318440433793048
Validation loss: 2.483934535361245

Epoch: 6| Step: 10
Training loss: 2.2737388804343666
Validation loss: 2.5220400756608408

Epoch: 6| Step: 11
Training loss: 2.3705615682887995
Validation loss: 2.517460321393396

Epoch: 6| Step: 12
Training loss: 1.5116325570702043
Validation loss: 2.4965022413998947

Epoch: 6| Step: 13
Training loss: 2.0395818173250584
Validation loss: 2.485800663930215

Epoch: 67| Step: 0
Training loss: 1.8904779550416702
Validation loss: 2.4873975525019945

Epoch: 6| Step: 1
Training loss: 2.5420250144946266
Validation loss: 2.487547242692033

Epoch: 6| Step: 2
Training loss: 1.8976803121223031
Validation loss: 2.475532341551856

Epoch: 6| Step: 3
Training loss: 1.8039521539860335
Validation loss: 2.417058121009891

Epoch: 6| Step: 4
Training loss: 1.7021237151057114
Validation loss: 2.4724391301565967

Epoch: 6| Step: 5
Training loss: 1.9872006100856379
Validation loss: 2.4295360685629435

Epoch: 6| Step: 6
Training loss: 1.9662192897253565
Validation loss: 2.4278140352928195

Epoch: 6| Step: 7
Training loss: 1.6337577602491118
Validation loss: 2.4917528337444854

Epoch: 6| Step: 8
Training loss: 2.295085599212989
Validation loss: 2.47996907645604

Epoch: 6| Step: 9
Training loss: 1.534763664541451
Validation loss: 2.4883331820399994

Epoch: 6| Step: 10
Training loss: 2.471675057408741
Validation loss: 2.4622075028181314

Epoch: 6| Step: 11
Training loss: 2.1845148699379413
Validation loss: 2.474053653419993

Epoch: 6| Step: 12
Training loss: 2.553486859791419
Validation loss: 2.472723431149153

Epoch: 6| Step: 13
Training loss: 2.2715183822959477
Validation loss: 2.4344882780398622

Epoch: 68| Step: 0
Training loss: 2.0160940644708107
Validation loss: 2.447026928390663

Epoch: 6| Step: 1
Training loss: 1.9820128070482963
Validation loss: 2.441450813395372

Epoch: 6| Step: 2
Training loss: 2.631382585025761
Validation loss: 2.4534819843342643

Epoch: 6| Step: 3
Training loss: 1.682693984481479
Validation loss: 2.433535310340533

Epoch: 6| Step: 4
Training loss: 2.390355712085097
Validation loss: 2.4039400581211567

Epoch: 6| Step: 5
Training loss: 1.594129255460367
Validation loss: 2.4192857909518657

Epoch: 6| Step: 6
Training loss: 1.7019984868106772
Validation loss: 2.4359948980792674

Epoch: 6| Step: 7
Training loss: 1.7422444287223484
Validation loss: 2.436915107391126

Epoch: 6| Step: 8
Training loss: 2.6518385213536213
Validation loss: 2.449037033064816

Epoch: 6| Step: 9
Training loss: 1.8572401084169219
Validation loss: 2.508522931301879

Epoch: 6| Step: 10
Training loss: 1.9720501563481676
Validation loss: 2.498116212647582

Epoch: 6| Step: 11
Training loss: 1.7134306001080752
Validation loss: 2.4928738596617634

Epoch: 6| Step: 12
Training loss: 1.8224960786544413
Validation loss: 2.4868827095433135

Epoch: 6| Step: 13
Training loss: 2.586735812505075
Validation loss: 2.4997965253042045

Epoch: 69| Step: 0
Training loss: 2.26669381022563
Validation loss: 2.4825074956191076

Epoch: 6| Step: 1
Training loss: 2.1100239073497256
Validation loss: 2.420230446580628

Epoch: 6| Step: 2
Training loss: 2.7617108076485866
Validation loss: 2.4590789639371886

Epoch: 6| Step: 3
Training loss: 2.1231811817855952
Validation loss: 2.4564309167603144

Epoch: 6| Step: 4
Training loss: 2.058417238489311
Validation loss: 2.469642944448894

Epoch: 6| Step: 5
Training loss: 2.1311539569592197
Validation loss: 2.5238816192299836

Epoch: 6| Step: 6
Training loss: 2.4425186918669892
Validation loss: 2.516278942085098

Epoch: 6| Step: 7
Training loss: 1.9080090145841808
Validation loss: 2.4767835660799338

Epoch: 6| Step: 8
Training loss: 2.2371151001691953
Validation loss: 2.4569390567207483

Epoch: 6| Step: 9
Training loss: 1.927163701486532
Validation loss: 2.4761844671398303

Epoch: 6| Step: 10
Training loss: 1.5052527802800744
Validation loss: 2.455638650552168

Epoch: 6| Step: 11
Training loss: 1.8781550247915262
Validation loss: 2.5430890829794217

Epoch: 6| Step: 12
Training loss: 1.6417903575999298
Validation loss: 2.5730110928483763

Epoch: 6| Step: 13
Training loss: 1.288400098362812
Validation loss: 2.580078125

Epoch: 70| Step: 0
Training loss: 1.608664939309268
Validation loss: 2.6218939979419633

Epoch: 6| Step: 1
Training loss: 2.033893098023048
Validation loss: 2.7288053482087875

Epoch: 6| Step: 2
Training loss: 2.9835945427057733
Validation loss: 2.7109489037588106

Epoch: 6| Step: 3
Training loss: 2.00220701515067
Validation loss: 2.6246574874732276

Epoch: 6| Step: 4
Training loss: 2.2851754473018415
Validation loss: 2.4881068736986545

Epoch: 6| Step: 5
Training loss: 1.5924247767050446
Validation loss: 2.4748131061722156

Epoch: 6| Step: 6
Training loss: 2.5804681475942095
Validation loss: 2.4737432580450887

Epoch: 6| Step: 7
Training loss: 1.6572820938508426
Validation loss: 2.41974969948744

Epoch: 6| Step: 8
Training loss: 2.3996044389269393
Validation loss: 2.5228158127912494

Epoch: 6| Step: 9
Training loss: 2.164112297063569
Validation loss: 2.5068660150260893

Epoch: 6| Step: 10
Training loss: 2.1444516471166444
Validation loss: 2.4988413350961336

Epoch: 6| Step: 11
Training loss: 1.7141392679332113
Validation loss: 2.487914149633883

Epoch: 6| Step: 12
Training loss: 2.1954471641860165
Validation loss: 2.441708428564951

Epoch: 6| Step: 13
Training loss: 2.39677605256874
Validation loss: 2.4605455681877664

Epoch: 71| Step: 0
Training loss: 2.3823620980252302
Validation loss: 2.4782148238295036

Epoch: 6| Step: 1
Training loss: 2.0196666561457666
Validation loss: 2.5061192326982695

Epoch: 6| Step: 2
Training loss: 1.7590142105422015
Validation loss: 2.5084878679579905

Epoch: 6| Step: 3
Training loss: 2.2226553918605547
Validation loss: 2.5079493024833863

Epoch: 6| Step: 4
Training loss: 1.9933505384580863
Validation loss: 2.5071379010719888

Epoch: 6| Step: 5
Training loss: 2.2583838139296177
Validation loss: 2.4893089499695162

Epoch: 6| Step: 6
Training loss: 1.8726191982125684
Validation loss: 2.4717457457393563

Epoch: 6| Step: 7
Training loss: 1.7511191195715257
Validation loss: 2.513150405837592

Epoch: 6| Step: 8
Training loss: 2.2316008732702555
Validation loss: 2.5286801326375388

Epoch: 6| Step: 9
Training loss: 1.5461185802221886
Validation loss: 2.5116840555930278

Epoch: 6| Step: 10
Training loss: 1.6938915010585531
Validation loss: 2.551671401014697

Epoch: 6| Step: 11
Training loss: 1.8091035787557859
Validation loss: 2.48161065357583

Epoch: 6| Step: 12
Training loss: 1.6633428889186779
Validation loss: 2.5152728859076654

Epoch: 6| Step: 13
Training loss: 2.6121975372300508
Validation loss: 2.4637370983026607

Epoch: 72| Step: 0
Training loss: 2.3924732917084124
Validation loss: 2.4520657271080193

Epoch: 6| Step: 1
Training loss: 1.5446742422378832
Validation loss: 2.4244899783659952

Epoch: 6| Step: 2
Training loss: 2.0096733287085637
Validation loss: 2.480435348646299

Epoch: 6| Step: 3
Training loss: 1.892005794504176
Validation loss: 2.5556329500070514

Epoch: 6| Step: 4
Training loss: 2.199692669989884
Validation loss: 2.5551911303851758

Epoch: 6| Step: 5
Training loss: 2.008058050555166
Validation loss: 2.5924486779455003

Epoch: 6| Step: 6
Training loss: 1.84081746311119
Validation loss: 2.516814296278654

Epoch: 6| Step: 7
Training loss: 2.2209667898114356
Validation loss: 2.4785414609972833

Epoch: 6| Step: 8
Training loss: 2.9709419590876522
Validation loss: 2.4843401316629037

Epoch: 6| Step: 9
Training loss: 2.0669323083933997
Validation loss: 2.497939627708637

Epoch: 6| Step: 10
Training loss: 2.280757380558789
Validation loss: 2.527169065811148

Epoch: 6| Step: 11
Training loss: 2.1249579257165716
Validation loss: 2.58167229339236

Epoch: 6| Step: 12
Training loss: 1.8533244702701281
Validation loss: 2.653502880035691

Epoch: 6| Step: 13
Training loss: 1.454692528344139
Validation loss: 2.6636138045938433

Epoch: 73| Step: 0
Training loss: 1.8276739623718268
Validation loss: 2.6758268626239876

Epoch: 6| Step: 1
Training loss: 2.7187023816378093
Validation loss: 2.6611471025275724

Epoch: 6| Step: 2
Training loss: 1.0896499078565989
Validation loss: 2.605619381387432

Epoch: 6| Step: 3
Training loss: 2.5972250214786596
Validation loss: 2.5574587723984727

Epoch: 6| Step: 4
Training loss: 1.5234161375455346
Validation loss: 2.5268736003526207

Epoch: 6| Step: 5
Training loss: 1.7639209998037282
Validation loss: 2.467241268848449

Epoch: 6| Step: 6
Training loss: 2.0330938333678357
Validation loss: 2.445923116575142

Epoch: 6| Step: 7
Training loss: 1.8473311091799351
Validation loss: 2.4439202225791785

Epoch: 6| Step: 8
Training loss: 1.9021098719650387
Validation loss: 2.419590649990894

Epoch: 6| Step: 9
Training loss: 2.2861753620292795
Validation loss: 2.42511711919269

Epoch: 6| Step: 10
Training loss: 2.051032815671635
Validation loss: 2.4403819140169407

Epoch: 6| Step: 11
Training loss: 2.0758454863831757
Validation loss: 2.4369318699403304

Epoch: 6| Step: 12
Training loss: 2.141136832200152
Validation loss: 2.445851657567004

Epoch: 6| Step: 13
Training loss: 1.1574443113306951
Validation loss: 2.4480065728309173

Epoch: 74| Step: 0
Training loss: 1.6867604224466923
Validation loss: 2.4416638047740773

Epoch: 6| Step: 1
Training loss: 2.2322648761641073
Validation loss: 2.455450021217409

Epoch: 6| Step: 2
Training loss: 2.6385511572589713
Validation loss: 2.433379856300665

Epoch: 6| Step: 3
Training loss: 2.1866418517650814
Validation loss: 2.432176858178706

Epoch: 6| Step: 4
Training loss: 1.9706406975679591
Validation loss: 2.4556664910245423

Epoch: 6| Step: 5
Training loss: 1.6914261250726763
Validation loss: 2.491253222310148

Epoch: 6| Step: 6
Training loss: 1.555666361374243
Validation loss: 2.4567138515385487

Epoch: 6| Step: 7
Training loss: 1.9476297816663504
Validation loss: 2.5173132307972765

Epoch: 6| Step: 8
Training loss: 1.5405965992010129
Validation loss: 2.5317725125006216

Epoch: 6| Step: 9
Training loss: 2.759452785894658
Validation loss: 2.5752670785362124

Epoch: 6| Step: 10
Training loss: 2.164896119336799
Validation loss: 2.5136938481925357

Epoch: 6| Step: 11
Training loss: 2.026039012393994
Validation loss: 2.467781907210353

Epoch: 6| Step: 12
Training loss: 1.8758480697226982
Validation loss: 2.428719232573415

Epoch: 6| Step: 13
Training loss: 1.7451846083568017
Validation loss: 2.4362535305529334

Epoch: 75| Step: 0
Training loss: 2.0216466571334437
Validation loss: 2.451624595709872

Epoch: 6| Step: 1
Training loss: 1.4729728864257847
Validation loss: 2.496488139038718

Epoch: 6| Step: 2
Training loss: 1.6393785373825553
Validation loss: 2.436649043553919

Epoch: 6| Step: 3
Training loss: 1.699605121751889
Validation loss: 2.4682656790893054

Epoch: 6| Step: 4
Training loss: 1.9240625848564115
Validation loss: 2.447206261542246

Epoch: 6| Step: 5
Training loss: 1.864102356605315
Validation loss: 2.4475293008559014

Epoch: 6| Step: 6
Training loss: 2.266096500136503
Validation loss: 2.4412876924338525

Epoch: 6| Step: 7
Training loss: 2.4562671728722894
Validation loss: 2.4414523595906177

Epoch: 6| Step: 8
Training loss: 1.817567909157904
Validation loss: 2.484430964257428

Epoch: 6| Step: 9
Training loss: 1.5204595167345984
Validation loss: 2.527825051751761

Epoch: 6| Step: 10
Training loss: 2.2666869732938206
Validation loss: 2.5702418478982514

Epoch: 6| Step: 11
Training loss: 1.9503588810817993
Validation loss: 2.603094762815032

Epoch: 6| Step: 12
Training loss: 2.2147188773771145
Validation loss: 2.6637594548473356

Epoch: 6| Step: 13
Training loss: 2.3655897735028923
Validation loss: 2.666878979893544

Epoch: 76| Step: 0
Training loss: 2.458293160148006
Validation loss: 2.584249938866434

Epoch: 6| Step: 1
Training loss: 1.9987590039058185
Validation loss: 2.537280454048356

Epoch: 6| Step: 2
Training loss: 1.846722421297923
Validation loss: 2.442888628738952

Epoch: 6| Step: 3
Training loss: 1.421245980772913
Validation loss: 2.4489887297861515

Epoch: 6| Step: 4
Training loss: 1.4117676887410573
Validation loss: 2.443571663387616

Epoch: 6| Step: 5
Training loss: 2.8771583085139714
Validation loss: 2.453393650125473

Epoch: 6| Step: 6
Training loss: 1.725226666582228
Validation loss: 2.438453544861474

Epoch: 6| Step: 7
Training loss: 2.268957383947186
Validation loss: 2.430295575785103

Epoch: 6| Step: 8
Training loss: 1.7338282092660813
Validation loss: 2.4334545799862046

Epoch: 6| Step: 9
Training loss: 1.686410693634012
Validation loss: 2.4241762938384235

Epoch: 6| Step: 10
Training loss: 1.9908659497230963
Validation loss: 2.4451455576240337

Epoch: 6| Step: 11
Training loss: 1.6058337314184883
Validation loss: 2.4625427258523773

Epoch: 6| Step: 12
Training loss: 1.8796617412625503
Validation loss: 2.4012140693471817

Epoch: 6| Step: 13
Training loss: 1.4921472354269811
Validation loss: 2.442348418463263

Epoch: 77| Step: 0
Training loss: 2.2736958884521172
Validation loss: 2.4242331478680152

Epoch: 6| Step: 1
Training loss: 1.5466407058992504
Validation loss: 2.484350448263159

Epoch: 6| Step: 2
Training loss: 1.5337043866103444
Validation loss: 2.4398138524272817

Epoch: 6| Step: 3
Training loss: 2.5200166456490214
Validation loss: 2.439078643048122

Epoch: 6| Step: 4
Training loss: 2.2346429197366744
Validation loss: 2.4457727716108435

Epoch: 6| Step: 5
Training loss: 1.9236195407626113
Validation loss: 2.4567988477323692

Epoch: 6| Step: 6
Training loss: 2.1001427828976604
Validation loss: 2.4319986878954123

Epoch: 6| Step: 7
Training loss: 1.8386379429263546
Validation loss: 2.4708429309557784

Epoch: 6| Step: 8
Training loss: 2.133609385312653
Validation loss: 2.477973191244302

Epoch: 6| Step: 9
Training loss: 1.6614423729140906
Validation loss: 2.408426901925706

Epoch: 6| Step: 10
Training loss: 1.3197689856326853
Validation loss: 2.434604889866038

Epoch: 6| Step: 11
Training loss: 1.7140617933941256
Validation loss: 2.439220685144581

Epoch: 6| Step: 12
Training loss: 2.164652719814405
Validation loss: 2.4905864711000603

Epoch: 6| Step: 13
Training loss: 1.3765703250866108
Validation loss: 2.4798787694443756

Epoch: 78| Step: 0
Training loss: 2.5004859452030925
Validation loss: 2.47506553100761

Epoch: 6| Step: 1
Training loss: 1.6114882141117854
Validation loss: 2.49454750878491

Epoch: 6| Step: 2
Training loss: 2.1395649756585327
Validation loss: 2.444434108736363

Epoch: 6| Step: 3
Training loss: 1.6219547788663837
Validation loss: 2.473651045069296

Epoch: 6| Step: 4
Training loss: 2.4208209297357035
Validation loss: 2.4684624564839424

Epoch: 6| Step: 5
Training loss: 1.7490445662371894
Validation loss: 2.48603164970903

Epoch: 6| Step: 6
Training loss: 1.5774912553112603
Validation loss: 2.5041021229766858

Epoch: 6| Step: 7
Training loss: 1.4685116838322254
Validation loss: 2.546949841856526

Epoch: 6| Step: 8
Training loss: 1.5153712423986467
Validation loss: 2.53996670786248

Epoch: 6| Step: 9
Training loss: 2.3212814619800897
Validation loss: 2.5611977563472372

Epoch: 6| Step: 10
Training loss: 1.5450094514082418
Validation loss: 2.5045688524104177

Epoch: 6| Step: 11
Training loss: 1.6663338646813801
Validation loss: 2.4156047581675444

Epoch: 6| Step: 12
Training loss: 1.8864567102783005
Validation loss: 2.4799252853367704

Epoch: 6| Step: 13
Training loss: 2.268969152705734
Validation loss: 2.481819405869292

Epoch: 79| Step: 0
Training loss: 1.9942764400371151
Validation loss: 2.454644965392741

Epoch: 6| Step: 1
Training loss: 2.369983595457322
Validation loss: 2.4669332056336346

Epoch: 6| Step: 2
Training loss: 1.8488915086589088
Validation loss: 2.4539304411257516

Epoch: 6| Step: 3
Training loss: 1.6421725286060829
Validation loss: 2.4685605213832686

Epoch: 6| Step: 4
Training loss: 1.7578385414737683
Validation loss: 2.4458253462843533

Epoch: 6| Step: 5
Training loss: 1.823820213550722
Validation loss: 2.483893597743734

Epoch: 6| Step: 6
Training loss: 1.8370617609912545
Validation loss: 2.436982254729679

Epoch: 6| Step: 7
Training loss: 1.299523097374237
Validation loss: 2.4942658148254604

Epoch: 6| Step: 8
Training loss: 2.407658251575205
Validation loss: 2.5278661582037745

Epoch: 6| Step: 9
Training loss: 1.7731469542334535
Validation loss: 2.503472777172726

Epoch: 6| Step: 10
Training loss: 1.4151199349301868
Validation loss: 2.50000913936216

Epoch: 6| Step: 11
Training loss: 1.7410267611073202
Validation loss: 2.4782553261300384

Epoch: 6| Step: 12
Training loss: 1.9788501151730296
Validation loss: 2.4720662695264006

Epoch: 6| Step: 13
Training loss: 2.309858927526892
Validation loss: 2.4587101297357163

Epoch: 80| Step: 0
Training loss: 2.188058618335658
Validation loss: 2.4481292037142177

Epoch: 6| Step: 1
Training loss: 1.4252539927010648
Validation loss: 2.428572354864163

Epoch: 6| Step: 2
Training loss: 2.0310394177952786
Validation loss: 2.420377173810522

Epoch: 6| Step: 3
Training loss: 1.2072349302418148
Validation loss: 2.415542691939439

Epoch: 6| Step: 4
Training loss: 1.6164386876918329
Validation loss: 2.477802627972958

Epoch: 6| Step: 5
Training loss: 2.3587985313448474
Validation loss: 2.458466822561389

Epoch: 6| Step: 6
Training loss: 1.73252673944533
Validation loss: 2.4401120267488356

Epoch: 6| Step: 7
Training loss: 1.9547791457246981
Validation loss: 2.4833033347611426

Epoch: 6| Step: 8
Training loss: 1.7884908370843606
Validation loss: 2.440162581996792

Epoch: 6| Step: 9
Training loss: 1.1611950266527564
Validation loss: 2.4695848349132277

Epoch: 6| Step: 10
Training loss: 1.7927917526079247
Validation loss: 2.476306954245103

Epoch: 6| Step: 11
Training loss: 2.146577341914462
Validation loss: 2.5178291821046503

Epoch: 6| Step: 12
Training loss: 2.213302910588005
Validation loss: 2.542750117234584

Epoch: 6| Step: 13
Training loss: 1.782881541674681
Validation loss: 2.605270187536433

Epoch: 81| Step: 0
Training loss: 1.8717513869901918
Validation loss: 2.4929878759332893

Epoch: 6| Step: 1
Training loss: 1.497513140077846
Validation loss: 2.502413522456439

Epoch: 6| Step: 2
Training loss: 1.771121356952557
Validation loss: 2.500895609967386

Epoch: 6| Step: 3
Training loss: 2.209309440190452
Validation loss: 2.5118884023875325

Epoch: 6| Step: 4
Training loss: 1.4038474434162322
Validation loss: 2.5030724163143954

Epoch: 6| Step: 5
Training loss: 1.8195471730565347
Validation loss: 2.5154167547179074

Epoch: 6| Step: 6
Training loss: 1.612982549101147
Validation loss: 2.5093967270534043

Epoch: 6| Step: 7
Training loss: 2.560176633463256
Validation loss: 2.4754397216795123

Epoch: 6| Step: 8
Training loss: 1.707740618841232
Validation loss: 2.4141971916803273

Epoch: 6| Step: 9
Training loss: 1.4057988608761214
Validation loss: 2.5056856669523078

Epoch: 6| Step: 10
Training loss: 1.8294178882155112
Validation loss: 2.4537659311967652

Epoch: 6| Step: 11
Training loss: 1.7940683753550808
Validation loss: 2.4795960901242373

Epoch: 6| Step: 12
Training loss: 1.9401565305739283
Validation loss: 2.442591785722343

Epoch: 6| Step: 13
Training loss: 1.362344283208733
Validation loss: 2.4593480381342046

Epoch: 82| Step: 0
Training loss: 1.2644335000745748
Validation loss: 2.3976947740310677

Epoch: 6| Step: 1
Training loss: 1.6486712827827399
Validation loss: 2.4835173848025414

Epoch: 6| Step: 2
Training loss: 1.7525881293717014
Validation loss: 2.4624220472671188

Epoch: 6| Step: 3
Training loss: 0.8411367000560327
Validation loss: 2.540664848024526

Epoch: 6| Step: 4
Training loss: 1.4365699081113712
Validation loss: 2.4738763146440568

Epoch: 6| Step: 5
Training loss: 1.5046319176854834
Validation loss: 2.524449660187338

Epoch: 6| Step: 6
Training loss: 1.815916984047024
Validation loss: 2.5655996602487887

Epoch: 6| Step: 7
Training loss: 2.304124666443989
Validation loss: 2.5791213759316403

Epoch: 6| Step: 8
Training loss: 2.404228550353057
Validation loss: 2.554220889969517

Epoch: 6| Step: 9
Training loss: 1.9537391612508253
Validation loss: 2.496139151847294

Epoch: 6| Step: 10
Training loss: 2.1486488931867456
Validation loss: 2.5878352398013966

Epoch: 6| Step: 11
Training loss: 1.830148734213496
Validation loss: 2.493092578859788

Epoch: 6| Step: 12
Training loss: 1.7357213061671206
Validation loss: 2.5020542923393085

Epoch: 6| Step: 13
Training loss: 1.808309709889795
Validation loss: 2.4775830722178416

Epoch: 83| Step: 0
Training loss: 1.2788448554363907
Validation loss: 2.506620684423479

Epoch: 6| Step: 1
Training loss: 1.6431345320432733
Validation loss: 2.461972764659671

Epoch: 6| Step: 2
Training loss: 1.9978288548344747
Validation loss: 2.4717406334830567

Epoch: 6| Step: 3
Training loss: 1.6073777481270388
Validation loss: 2.4538399045424786

Epoch: 6| Step: 4
Training loss: 1.930721299476398
Validation loss: 2.471346330915007

Epoch: 6| Step: 5
Training loss: 1.6669997677130672
Validation loss: 2.442695427855756

Epoch: 6| Step: 6
Training loss: 1.7995046198839397
Validation loss: 2.479192883222003

Epoch: 6| Step: 7
Training loss: 1.9532044661568309
Validation loss: 2.5497082044662616

Epoch: 6| Step: 8
Training loss: 1.7511869220142493
Validation loss: 2.5507316097708372

Epoch: 6| Step: 9
Training loss: 2.08605419504019
Validation loss: 2.569885945120906

Epoch: 6| Step: 10
Training loss: 2.209031540479283
Validation loss: 2.503208787319836

Epoch: 6| Step: 11
Training loss: 1.6284218486413673
Validation loss: 2.5274915774790223

Epoch: 6| Step: 12
Training loss: 1.7044871771126728
Validation loss: 2.523203946260395

Epoch: 6| Step: 13
Training loss: 1.5871092127603443
Validation loss: 2.538585535880116

Epoch: 84| Step: 0
Training loss: 1.5701232340611198
Validation loss: 2.4770288439490558

Epoch: 6| Step: 1
Training loss: 2.233135599900719
Validation loss: 2.4678855943975218

Epoch: 6| Step: 2
Training loss: 1.4673009989005363
Validation loss: 2.487189404187762

Epoch: 6| Step: 3
Training loss: 1.8665050073286202
Validation loss: 2.47951327767304

Epoch: 6| Step: 4
Training loss: 1.4196200253277795
Validation loss: 2.457826616036923

Epoch: 6| Step: 5
Training loss: 2.1448976519871525
Validation loss: 2.4620405197703406

Epoch: 6| Step: 6
Training loss: 1.8802550108408795
Validation loss: 2.475228946384733

Epoch: 6| Step: 7
Training loss: 1.4251130510961372
Validation loss: 2.5444306733685584

Epoch: 6| Step: 8
Training loss: 1.8584498820799233
Validation loss: 2.633067827078646

Epoch: 6| Step: 9
Training loss: 2.093077366521279
Validation loss: 2.7143964440124315

Epoch: 6| Step: 10
Training loss: 2.005857235499711
Validation loss: 2.706582036253423

Epoch: 6| Step: 11
Training loss: 2.078263127605231
Validation loss: 2.524424577367689

Epoch: 6| Step: 12
Training loss: 1.5650325849754414
Validation loss: 2.5095518741053517

Epoch: 6| Step: 13
Training loss: 1.4193780794366433
Validation loss: 2.476567730662441

Epoch: 85| Step: 0
Training loss: 1.5478113596415426
Validation loss: 2.4696088254756474

Epoch: 6| Step: 1
Training loss: 1.4858160151771926
Validation loss: 2.492866447546915

Epoch: 6| Step: 2
Training loss: 2.04227822415278
Validation loss: 2.578601970285424

Epoch: 6| Step: 3
Training loss: 1.979954940687775
Validation loss: 2.5386891564961145

Epoch: 6| Step: 4
Training loss: 1.5040983795699019
Validation loss: 2.4665978060166225

Epoch: 6| Step: 5
Training loss: 1.9214531039992961
Validation loss: 2.4912153558256995

Epoch: 6| Step: 6
Training loss: 1.6341439253362535
Validation loss: 2.44412821894139

Epoch: 6| Step: 7
Training loss: 1.595362053679718
Validation loss: 2.437832638467015

Epoch: 6| Step: 8
Training loss: 1.2092506719354321
Validation loss: 2.405052522877532

Epoch: 6| Step: 9
Training loss: 1.8403375371990798
Validation loss: 2.509406307242105

Epoch: 6| Step: 10
Training loss: 2.0485425373676733
Validation loss: 2.514608458167225

Epoch: 6| Step: 11
Training loss: 1.6859212483921155
Validation loss: 2.5728064885403805

Epoch: 6| Step: 12
Training loss: 2.147002361578813
Validation loss: 2.596054325116267

Epoch: 6| Step: 13
Training loss: 2.1191320744355147
Validation loss: 2.5327211978936344

Epoch: 86| Step: 0
Training loss: 1.5659716376589943
Validation loss: 2.5375333514472542

Epoch: 6| Step: 1
Training loss: 1.6092004773963486
Validation loss: 2.539497299134817

Epoch: 6| Step: 2
Training loss: 1.5535881718076274
Validation loss: 2.482289548598995

Epoch: 6| Step: 3
Training loss: 1.4829856393624234
Validation loss: 2.52306902609401

Epoch: 6| Step: 4
Training loss: 1.9017048414958355
Validation loss: 2.511784562058999

Epoch: 6| Step: 5
Training loss: 2.265752433613078
Validation loss: 2.543356370267449

Epoch: 6| Step: 6
Training loss: 1.873064058958909
Validation loss: 2.4429053340334312

Epoch: 6| Step: 7
Training loss: 1.532748053981757
Validation loss: 2.4892323990137286

Epoch: 6| Step: 8
Training loss: 1.7310116435099565
Validation loss: 2.4188023754563885

Epoch: 6| Step: 9
Training loss: 1.4978001676131736
Validation loss: 2.432462426235523

Epoch: 6| Step: 10
Training loss: 1.9403249388836858
Validation loss: 2.4553528892182994

Epoch: 6| Step: 11
Training loss: 2.0433155589655607
Validation loss: 2.4498330075579746

Epoch: 6| Step: 12
Training loss: 1.5942445623440584
Validation loss: 2.395864326166016

Epoch: 6| Step: 13
Training loss: 1.383406172217365
Validation loss: 2.4773981587829015

Epoch: 87| Step: 0
Training loss: 1.7317245438969382
Validation loss: 2.467009788138119

Epoch: 6| Step: 1
Training loss: 1.6422743000352884
Validation loss: 2.505293328528011

Epoch: 6| Step: 2
Training loss: 1.5871454158280163
Validation loss: 2.529232634093086

Epoch: 6| Step: 3
Training loss: 1.8828985424088174
Validation loss: 2.578427923111758

Epoch: 6| Step: 4
Training loss: 1.5390600214129788
Validation loss: 2.607950320372317

Epoch: 6| Step: 5
Training loss: 1.6533511722791843
Validation loss: 2.4982961252439178

Epoch: 6| Step: 6
Training loss: 1.5840889817396913
Validation loss: 2.5021523588147483

Epoch: 6| Step: 7
Training loss: 1.203429047449106
Validation loss: 2.5542091520633208

Epoch: 6| Step: 8
Training loss: 1.2725362572441605
Validation loss: 2.5058120719110013

Epoch: 6| Step: 9
Training loss: 1.729166681986736
Validation loss: 2.475911276442248

Epoch: 6| Step: 10
Training loss: 1.7366582601689127
Validation loss: 2.44434312287739

Epoch: 6| Step: 11
Training loss: 1.673409515346329
Validation loss: 2.4243704624302382

Epoch: 6| Step: 12
Training loss: 1.4456366922884527
Validation loss: 2.487197416359026

Epoch: 6| Step: 13
Training loss: 2.4380693993270697
Validation loss: 2.4167079976811663

Epoch: 88| Step: 0
Training loss: 1.83399224000327
Validation loss: 2.4600657377272697

Epoch: 6| Step: 1
Training loss: 1.5885488874761178
Validation loss: 2.4211682836961743

Epoch: 6| Step: 2
Training loss: 1.1483893870960478
Validation loss: 2.4878734691649473

Epoch: 6| Step: 3
Training loss: 1.528143865862822
Validation loss: 2.4853125028907215

Epoch: 6| Step: 4
Training loss: 1.6060762393047694
Validation loss: 2.5193725062788306

Epoch: 6| Step: 5
Training loss: 1.7508000860941506
Validation loss: 2.4536445699186613

Epoch: 6| Step: 6
Training loss: 1.8708177972274513
Validation loss: 2.4760735848476845

Epoch: 6| Step: 7
Training loss: 1.3293845991569129
Validation loss: 2.5075119646572315

Epoch: 6| Step: 8
Training loss: 1.583793280536258
Validation loss: 2.4864871085880007

Epoch: 6| Step: 9
Training loss: 1.2991915775102405
Validation loss: 2.5065350631228736

Epoch: 6| Step: 10
Training loss: 1.8152716918288099
Validation loss: 2.4666112496190875

Epoch: 6| Step: 11
Training loss: 1.5627714302816147
Validation loss: 2.5996375078818525

Epoch: 6| Step: 12
Training loss: 2.405798931697298
Validation loss: 2.6197495555084322

Epoch: 6| Step: 13
Training loss: 1.540092781789388
Validation loss: 2.6537391913216792

Epoch: 89| Step: 0
Training loss: 1.556138631367064
Validation loss: 2.6046161314598244

Epoch: 6| Step: 1
Training loss: 2.311739719266113
Validation loss: 2.5731246699426484

Epoch: 6| Step: 2
Training loss: 1.9542805419580949
Validation loss: 2.6096785896023382

Epoch: 6| Step: 3
Training loss: 1.3432102893786269
Validation loss: 2.534773426903173

Epoch: 6| Step: 4
Training loss: 1.3815234366716325
Validation loss: 2.482850108613044

Epoch: 6| Step: 5
Training loss: 1.2581487170739802
Validation loss: 2.515333992058231

Epoch: 6| Step: 6
Training loss: 1.6051833741436132
Validation loss: 2.47875292448409

Epoch: 6| Step: 7
Training loss: 1.4641400490724
Validation loss: 2.433063969879267

Epoch: 6| Step: 8
Training loss: 1.5494172754402273
Validation loss: 2.441869584939936

Epoch: 6| Step: 9
Training loss: 1.9735716857957324
Validation loss: 2.4186838763626075

Epoch: 6| Step: 10
Training loss: 1.6872003077250346
Validation loss: 2.4220144498322105

Epoch: 6| Step: 11
Training loss: 1.3460706145367924
Validation loss: 2.4956451394949664

Epoch: 6| Step: 12
Training loss: 1.9366336854609307
Validation loss: 2.437819321411797

Epoch: 6| Step: 13
Training loss: 1.2104695554242866
Validation loss: 2.4987238805925074

Epoch: 90| Step: 0
Training loss: 1.2122111851541049
Validation loss: 2.494785553055973

Epoch: 6| Step: 1
Training loss: 1.3969397169307798
Validation loss: 2.5129968882525144

Epoch: 6| Step: 2
Training loss: 1.4687722387050601
Validation loss: 2.5382168970768926

Epoch: 6| Step: 3
Training loss: 1.3431992400159838
Validation loss: 2.4944027230507877

Epoch: 6| Step: 4
Training loss: 1.3683459360484755
Validation loss: 2.6073838210930593

Epoch: 6| Step: 5
Training loss: 1.8630653112269293
Validation loss: 2.5058738844846156

Epoch: 6| Step: 6
Training loss: 2.034486393142165
Validation loss: 2.5444682086041213

Epoch: 6| Step: 7
Training loss: 1.7288216012951174
Validation loss: 2.517231019849728

Epoch: 6| Step: 8
Training loss: 1.4301884508336904
Validation loss: 2.4927826173848393

Epoch: 6| Step: 9
Training loss: 1.6347900534642483
Validation loss: 2.4743735249447423

Epoch: 6| Step: 10
Training loss: 2.1248981227014982
Validation loss: 2.565680545913401

Epoch: 6| Step: 11
Training loss: 2.4850744066669597
Validation loss: 2.4790304183919774

Epoch: 6| Step: 12
Training loss: 1.142706239478744
Validation loss: 2.5119029877815016

Epoch: 6| Step: 13
Training loss: 1.438134758164756
Validation loss: 2.633453592942554

Epoch: 91| Step: 0
Training loss: 1.598810874609175
Validation loss: 2.6492626738893534

Epoch: 6| Step: 1
Training loss: 2.039826231829758
Validation loss: 2.677671959036196

Epoch: 6| Step: 2
Training loss: 1.3151069364109396
Validation loss: 2.647984333709404

Epoch: 6| Step: 3
Training loss: 1.6392931664039538
Validation loss: 2.6616430996078617

Epoch: 6| Step: 4
Training loss: 1.9263563554775047
Validation loss: 2.5890767537754673

Epoch: 6| Step: 5
Training loss: 1.2656786871931944
Validation loss: 2.491992492380768

Epoch: 6| Step: 6
Training loss: 1.3635168882974062
Validation loss: 2.5038868173845956

Epoch: 6| Step: 7
Training loss: 2.3383721259722385
Validation loss: 2.4937022995748768

Epoch: 6| Step: 8
Training loss: 1.3415947418994716
Validation loss: 2.4240074040181274

Epoch: 6| Step: 9
Training loss: 1.6646309181767591
Validation loss: 2.5531110964722967

Epoch: 6| Step: 10
Training loss: 1.4407007822224864
Validation loss: 2.511986638600558

Epoch: 6| Step: 11
Training loss: 1.8529443533787353
Validation loss: 2.5235750773023287

Epoch: 6| Step: 12
Training loss: 1.2211476729599149
Validation loss: 2.4965505803787766

Epoch: 6| Step: 13
Training loss: 1.2980248742387244
Validation loss: 2.496151043428888

Epoch: 92| Step: 0
Training loss: 1.1465561696436901
Validation loss: 2.513267755319029

Epoch: 6| Step: 1
Training loss: 1.9259387216930857
Validation loss: 2.4679888103072756

Epoch: 6| Step: 2
Training loss: 1.8404547776167033
Validation loss: 2.5727721313981697

Epoch: 6| Step: 3
Training loss: 1.9340205790737497
Validation loss: 2.4575844502289064

Epoch: 6| Step: 4
Training loss: 1.2514713211278918
Validation loss: 2.489427064170326

Epoch: 6| Step: 5
Training loss: 1.553335934597233
Validation loss: 2.48468341952279

Epoch: 6| Step: 6
Training loss: 1.8032281432906294
Validation loss: 2.487912464609997

Epoch: 6| Step: 7
Training loss: 1.4306758945223186
Validation loss: 2.496745701490864

Epoch: 6| Step: 8
Training loss: 1.090805996192144
Validation loss: 2.506289200702136

Epoch: 6| Step: 9
Training loss: 1.3895100613806655
Validation loss: 2.4937606040072637

Epoch: 6| Step: 10
Training loss: 1.9365912736715991
Validation loss: 2.5118983290070585

Epoch: 6| Step: 11
Training loss: 1.2580013725685673
Validation loss: 2.488847094305066

Epoch: 6| Step: 12
Training loss: 0.9290111229090035
Validation loss: 2.4966498020741676

Epoch: 6| Step: 13
Training loss: 2.0147625164623495
Validation loss: 2.534554494827195

Epoch: 93| Step: 0
Training loss: 1.6163790981248738
Validation loss: 2.521901926167131

Epoch: 6| Step: 1
Training loss: 1.1567256567714161
Validation loss: 2.625260688310737

Epoch: 6| Step: 2
Training loss: 1.041631748885788
Validation loss: 2.6821644626318317

Epoch: 6| Step: 3
Training loss: 2.3124375206007466
Validation loss: 2.711651593498379

Epoch: 6| Step: 4
Training loss: 1.4317773438832155
Validation loss: 2.7316392346235

Epoch: 6| Step: 5
Training loss: 1.7037199888433903
Validation loss: 2.6022618053631605

Epoch: 6| Step: 6
Training loss: 1.588508889115497
Validation loss: 2.5607432259338414

Epoch: 6| Step: 7
Training loss: 1.4618632601445574
Validation loss: 2.4902351169959065

Epoch: 6| Step: 8
Training loss: 1.5252061016704044
Validation loss: 2.521959673197866

Epoch: 6| Step: 9
Training loss: 1.8626989578382596
Validation loss: 2.507012989472603

Epoch: 6| Step: 10
Training loss: 1.549559142883059
Validation loss: 2.5291746289181845

Epoch: 6| Step: 11
Training loss: 1.6289000293786722
Validation loss: 2.515592618303412

Epoch: 6| Step: 12
Training loss: 1.5028414833603998
Validation loss: 2.4984850187317527

Epoch: 6| Step: 13
Training loss: 1.2716787632074806
Validation loss: 2.5116475729500287

Epoch: 94| Step: 0
Training loss: 2.102860400940758
Validation loss: 2.513774206790118

Epoch: 6| Step: 1
Training loss: 1.2690903117972656
Validation loss: 2.5112810875838902

Epoch: 6| Step: 2
Training loss: 1.1522900585015514
Validation loss: 2.5632141947828675

Epoch: 6| Step: 3
Training loss: 0.8507725262435475
Validation loss: 2.587259943663924

Epoch: 6| Step: 4
Training loss: 1.9513334068052441
Validation loss: 2.5404225624203343

Epoch: 6| Step: 5
Training loss: 1.8391140343147236
Validation loss: 2.6099661425882816

Epoch: 6| Step: 6
Training loss: 1.7060064037108897
Validation loss: 2.6068190583840876

Epoch: 6| Step: 7
Training loss: 1.7792198256592127
Validation loss: 2.4842741843826954

Epoch: 6| Step: 8
Training loss: 1.293874095180469
Validation loss: 2.472318299768515

Epoch: 6| Step: 9
Training loss: 1.3645909529999822
Validation loss: 2.507186082540574

Epoch: 6| Step: 10
Training loss: 1.6724430438323696
Validation loss: 2.4832497053551674

Epoch: 6| Step: 11
Training loss: 1.4527593993626486
Validation loss: 2.591905972470721

Epoch: 6| Step: 12
Training loss: 1.9011727553507247
Validation loss: 2.522711792199836

Epoch: 6| Step: 13
Training loss: 1.4206833929034661
Validation loss: 2.496845687293104

Epoch: 95| Step: 0
Training loss: 1.6464465081508937
Validation loss: 2.458174818930623

Epoch: 6| Step: 1
Training loss: 1.1092946198047804
Validation loss: 2.4935856547494057

Epoch: 6| Step: 2
Training loss: 1.4635247153751925
Validation loss: 2.583265893322488

Epoch: 6| Step: 3
Training loss: 1.6002274321800443
Validation loss: 2.7310180111615554

Epoch: 6| Step: 4
Training loss: 1.9157341955529386
Validation loss: 2.704709685535996

Epoch: 6| Step: 5
Training loss: 1.5665335662927555
Validation loss: 2.6547791691026688

Epoch: 6| Step: 6
Training loss: 1.267056115203187
Validation loss: 2.5625922488843904

Epoch: 6| Step: 7
Training loss: 1.5201359896310052
Validation loss: 2.5578455017732344

Epoch: 6| Step: 8
Training loss: 1.1083532651863388
Validation loss: 2.4961508205617484

Epoch: 6| Step: 9
Training loss: 2.0619169624917446
Validation loss: 2.4648355764988046

Epoch: 6| Step: 10
Training loss: 1.3333146968174887
Validation loss: 2.497639415796795

Epoch: 6| Step: 11
Training loss: 1.5064781491036658
Validation loss: 2.49275044906327

Epoch: 6| Step: 12
Training loss: 1.5918624021932548
Validation loss: 2.5030727496906753

Epoch: 6| Step: 13
Training loss: 1.6007070350105834
Validation loss: 2.510777179796145

Epoch: 96| Step: 0
Training loss: 1.617679097373412
Validation loss: 2.5093869726418765

Epoch: 6| Step: 1
Training loss: 1.0033241098134171
Validation loss: 2.5028077253478

Epoch: 6| Step: 2
Training loss: 1.4791937095784795
Validation loss: 2.5248766201707884

Epoch: 6| Step: 3
Training loss: 1.4227633373632094
Validation loss: 2.5515256051711086

Epoch: 6| Step: 4
Training loss: 1.9312155538406681
Validation loss: 2.6650638283296035

Epoch: 6| Step: 5
Training loss: 1.6579229434919485
Validation loss: 2.562546706355499

Epoch: 6| Step: 6
Training loss: 1.2360199217193901
Validation loss: 2.671796526137571

Epoch: 6| Step: 7
Training loss: 1.2638915635990071
Validation loss: 2.5877725902966

Epoch: 6| Step: 8
Training loss: 1.264290565315158
Validation loss: 2.5425060376671063

Epoch: 6| Step: 9
Training loss: 1.1690951118315493
Validation loss: 2.5224771788326907

Epoch: 6| Step: 10
Training loss: 1.815413008639427
Validation loss: 2.5032640924118335

Epoch: 6| Step: 11
Training loss: 1.211901078319849
Validation loss: 2.513095081135125

Epoch: 6| Step: 12
Training loss: 1.891669497158717
Validation loss: 2.485391181075432

Epoch: 6| Step: 13
Training loss: 1.707494746991814
Validation loss: 2.5188601524177052

Epoch: 97| Step: 0
Training loss: 1.4722211685816675
Validation loss: 2.4935446046713166

Epoch: 6| Step: 1
Training loss: 1.2454238095189816
Validation loss: 2.5066841415377827

Epoch: 6| Step: 2
Training loss: 1.291238554897344
Validation loss: 2.512840574187003

Epoch: 6| Step: 3
Training loss: 1.6987974148744334
Validation loss: 2.516128339623074

Epoch: 6| Step: 4
Training loss: 1.4219036728200165
Validation loss: 2.557800177667011

Epoch: 6| Step: 5
Training loss: 1.3928043133634356
Validation loss: 2.6133426341634145

Epoch: 6| Step: 6
Training loss: 1.3071879108892492
Validation loss: 2.659894006978853

Epoch: 6| Step: 7
Training loss: 1.6441861694437279
Validation loss: 2.6559255214794626

Epoch: 6| Step: 8
Training loss: 1.4976619937251296
Validation loss: 2.566786599969566

Epoch: 6| Step: 9
Training loss: 1.5633039313657886
Validation loss: 2.5305184143035584

Epoch: 6| Step: 10
Training loss: 1.3312324522769265
Validation loss: 2.5018301304988206

Epoch: 6| Step: 11
Training loss: 1.7128909729769102
Validation loss: 2.5433381843103997

Epoch: 6| Step: 12
Training loss: 1.337634965735962
Validation loss: 2.5546205377697957

Epoch: 6| Step: 13
Training loss: 2.2132966627775317
Validation loss: 2.5383518730867447

Epoch: 98| Step: 0
Training loss: 1.7618812773647845
Validation loss: 2.4343671799396605

Epoch: 6| Step: 1
Training loss: 1.2170954991487548
Validation loss: 2.5112886826944414

Epoch: 6| Step: 2
Training loss: 1.5283436343817607
Validation loss: 2.5825451499633303

Epoch: 6| Step: 3
Training loss: 2.207252693882347
Validation loss: 2.713085338762817

Epoch: 6| Step: 4
Training loss: 1.5536741088108408
Validation loss: 2.7184631079361363

Epoch: 6| Step: 5
Training loss: 1.8236243118785826
Validation loss: 2.7637863225345827

Epoch: 6| Step: 6
Training loss: 1.1856256549935953
Validation loss: 2.639548870565221

Epoch: 6| Step: 7
Training loss: 1.4107199517010385
Validation loss: 2.575806393942707

Epoch: 6| Step: 8
Training loss: 0.988649533372415
Validation loss: 2.526206498159238

Epoch: 6| Step: 9
Training loss: 1.4913737689678126
Validation loss: 2.506610665566613

Epoch: 6| Step: 10
Training loss: 1.1974523501383032
Validation loss: 2.490442954908553

Epoch: 6| Step: 11
Training loss: 1.3702440373054867
Validation loss: 2.5564199128454317

Epoch: 6| Step: 12
Training loss: 1.4933487931938556
Validation loss: 2.5823832477324804

Epoch: 6| Step: 13
Training loss: 1.4891964959200963
Validation loss: 2.541097817055598

Epoch: 99| Step: 0
Training loss: 1.7062468308639438
Validation loss: 2.529799669876095

Epoch: 6| Step: 1
Training loss: 1.3134593182534384
Validation loss: 2.544045325404283

Epoch: 6| Step: 2
Training loss: 1.5105670021044018
Validation loss: 2.6007229936835388

Epoch: 6| Step: 3
Training loss: 1.680135126129212
Validation loss: 2.6513026670470214

Epoch: 6| Step: 4
Training loss: 1.5276293085185932
Validation loss: 2.639455999260196

Epoch: 6| Step: 5
Training loss: 1.3782347430002806
Validation loss: 2.6221743164652445

Epoch: 6| Step: 6
Training loss: 1.235190544641579
Validation loss: 2.616458438274208

Epoch: 6| Step: 7
Training loss: 1.2590422690085294
Validation loss: 2.524779239610003

Epoch: 6| Step: 8
Training loss: 1.061672449400607
Validation loss: 2.495232701722576

Epoch: 6| Step: 9
Training loss: 1.5631016907904467
Validation loss: 2.5541689051814847

Epoch: 6| Step: 10
Training loss: 2.126980363655647
Validation loss: 2.5854570724276766

Epoch: 6| Step: 11
Training loss: 1.572033598465564
Validation loss: 2.505023867556229

Epoch: 6| Step: 12
Training loss: 1.120727160127254
Validation loss: 2.4925232743783905

Epoch: 6| Step: 13
Training loss: 1.4273864906731124
Validation loss: 2.50661922598478

Epoch: 100| Step: 0
Training loss: 1.1804994731871201
Validation loss: 2.4897941010664644

Epoch: 6| Step: 1
Training loss: 1.4945066315397562
Validation loss: 2.6315414726366417

Epoch: 6| Step: 2
Training loss: 2.2290658898316438
Validation loss: 2.617289526929231

Epoch: 6| Step: 3
Training loss: 1.5429400091271004
Validation loss: 2.7184414889510315

Epoch: 6| Step: 4
Training loss: 1.5438077166806634
Validation loss: 2.676951577077452

Epoch: 6| Step: 5
Training loss: 1.6630769058493018
Validation loss: 2.5292705441237215

Epoch: 6| Step: 6
Training loss: 1.4408186048053118
Validation loss: 2.5114159606709148

Epoch: 6| Step: 7
Training loss: 1.3469626148164602
Validation loss: 2.5775025820541893

Epoch: 6| Step: 8
Training loss: 1.7099823397566605
Validation loss: 2.5464698765733975

Epoch: 6| Step: 9
Training loss: 1.1537809558323637
Validation loss: 2.5238006456472593

Epoch: 6| Step: 10
Training loss: 1.229113022662785
Validation loss: 2.5148252554643316

Epoch: 6| Step: 11
Training loss: 1.1301459135524003
Validation loss: 2.5543128000328745

Epoch: 6| Step: 12
Training loss: 1.4011469332301898
Validation loss: 2.5014370761541165

Epoch: 6| Step: 13
Training loss: 1.3407766580942029
Validation loss: 2.557828661650669

Epoch: 101| Step: 0
Training loss: 1.4932873252752255
Validation loss: 2.618043476777302

Epoch: 6| Step: 1
Training loss: 1.304766943791411
Validation loss: 2.645696971913753

Epoch: 6| Step: 2
Training loss: 2.0271696923715887
Validation loss: 2.638084739721878

Epoch: 6| Step: 3
Training loss: 1.2423433410006717
Validation loss: 2.5773499373798887

Epoch: 6| Step: 4
Training loss: 1.5307200546313604
Validation loss: 2.6176699824673073

Epoch: 6| Step: 5
Training loss: 1.149595338694892
Validation loss: 2.579130435210484

Epoch: 6| Step: 6
Training loss: 0.8660051688465099
Validation loss: 2.5045430548494396

Epoch: 6| Step: 7
Training loss: 1.003727522202871
Validation loss: 2.5343235178405363

Epoch: 6| Step: 8
Training loss: 1.2097926480776668
Validation loss: 2.5582620886244274

Epoch: 6| Step: 9
Training loss: 1.4530911185303663
Validation loss: 2.4749717537395193

Epoch: 6| Step: 10
Training loss: 1.2490915812260504
Validation loss: 2.538474467727365

Epoch: 6| Step: 11
Training loss: 1.665166068057539
Validation loss: 2.600452067737246

Epoch: 6| Step: 12
Training loss: 1.6358372902623943
Validation loss: 2.5920451739303223

Epoch: 6| Step: 13
Training loss: 1.2806640773934344
Validation loss: 2.5329874770925067

Epoch: 102| Step: 0
Training loss: 1.701551497943153
Validation loss: 2.5805498529851856

Epoch: 6| Step: 1
Training loss: 2.047314545706169
Validation loss: 2.593675236984126

Epoch: 6| Step: 2
Training loss: 0.6311406786839784
Validation loss: 2.5434803094138587

Epoch: 6| Step: 3
Training loss: 1.1835848867758076
Validation loss: 2.5398953680830103

Epoch: 6| Step: 4
Training loss: 1.312905022026648
Validation loss: 2.555625704364613

Epoch: 6| Step: 5
Training loss: 1.3411649634715985
Validation loss: 2.505511463143374

Epoch: 6| Step: 6
Training loss: 1.5187411963439221
Validation loss: 2.508204064148467

Epoch: 6| Step: 7
Training loss: 1.482694055551844
Validation loss: 2.55921870163097

Epoch: 6| Step: 8
Training loss: 1.2133142097157306
Validation loss: 2.5067263872644965

Epoch: 6| Step: 9
Training loss: 1.29638441987202
Validation loss: 2.5987083044678183

Epoch: 6| Step: 10
Training loss: 1.4003366542402367
Validation loss: 2.542415404386208

Epoch: 6| Step: 11
Training loss: 1.013721971982808
Validation loss: 2.5356290167780715

Epoch: 6| Step: 12
Training loss: 1.3096171007325026
Validation loss: 2.5593410186933725

Epoch: 6| Step: 13
Training loss: 1.0867190395988335
Validation loss: 2.5973938850093123

Epoch: 103| Step: 0
Training loss: 1.1460115929861028
Validation loss: 2.615055350647219

Epoch: 6| Step: 1
Training loss: 1.2171802682135333
Validation loss: 2.5247243113823954

Epoch: 6| Step: 2
Training loss: 2.2597723773667484
Validation loss: 2.535253913773304

Epoch: 6| Step: 3
Training loss: 1.353521702079837
Validation loss: 2.5970851031286717

Epoch: 6| Step: 4
Training loss: 1.5250736156268179
Validation loss: 2.5081381739823256

Epoch: 6| Step: 5
Training loss: 0.933419502628844
Validation loss: 2.498102572737058

Epoch: 6| Step: 6
Training loss: 0.9831895199100754
Validation loss: 2.6242111625383777

Epoch: 6| Step: 7
Training loss: 1.2272289919365487
Validation loss: 2.585884838970223

Epoch: 6| Step: 8
Training loss: 1.1787354625561925
Validation loss: 2.6008863515521368

Epoch: 6| Step: 9
Training loss: 1.4217369934850113
Validation loss: 2.576799811204534

Epoch: 6| Step: 10
Training loss: 1.115800543472587
Validation loss: 2.5917750580211263

Epoch: 6| Step: 11
Training loss: 0.9708440973779334
Validation loss: 2.6014908942066226

Epoch: 6| Step: 12
Training loss: 1.1626594844240472
Validation loss: 2.592855751277926

Epoch: 6| Step: 13
Training loss: 1.3759675089942351
Validation loss: 2.5471822791213157

Epoch: 104| Step: 0
Training loss: 1.1268057635930768
Validation loss: 2.5236729845649717

Epoch: 6| Step: 1
Training loss: 1.4808723483351287
Validation loss: 2.565383777127741

Epoch: 6| Step: 2
Training loss: 1.3737657382608524
Validation loss: 2.525067325676469

Epoch: 6| Step: 3
Training loss: 1.3086654871165913
Validation loss: 2.56223034409069

Epoch: 6| Step: 4
Training loss: 1.5208016309525736
Validation loss: 2.5618300298680623

Epoch: 6| Step: 5
Training loss: 1.1833159873031336
Validation loss: 2.5472700986611816

Epoch: 6| Step: 6
Training loss: 1.3214446862169749
Validation loss: 2.590868992928683

Epoch: 6| Step: 7
Training loss: 1.2783701095032447
Validation loss: 2.6390287551845506

Epoch: 6| Step: 8
Training loss: 2.023970957068948
Validation loss: 2.6057964006455356

Epoch: 6| Step: 9
Training loss: 1.0988432415662517
Validation loss: 2.6781682637480313

Epoch: 6| Step: 10
Training loss: 1.2284753062025806
Validation loss: 2.604148335710223

Epoch: 6| Step: 11
Training loss: 1.2790218610945776
Validation loss: 2.6757455345424725

Epoch: 6| Step: 12
Training loss: 1.228602856569914
Validation loss: 2.6803061287437924

Epoch: 6| Step: 13
Training loss: 0.6520050448708102
Validation loss: 2.5901209556781573

Epoch: 105| Step: 0
Training loss: 1.2346111989081754
Validation loss: 2.483653221606292

Epoch: 6| Step: 1
Training loss: 1.195414819265015
Validation loss: 2.561857375535463

Epoch: 6| Step: 2
Training loss: 1.443891992233351
Validation loss: 2.5534923141385732

Epoch: 6| Step: 3
Training loss: 1.427458312433022
Validation loss: 2.5630341415095943

Epoch: 6| Step: 4
Training loss: 1.535503784910386
Validation loss: 2.5853904383638193

Epoch: 6| Step: 5
Training loss: 1.8498758609464787
Validation loss: 2.5732965587877334

Epoch: 6| Step: 6
Training loss: 1.1375687819425284
Validation loss: 2.6293300534568678

Epoch: 6| Step: 7
Training loss: 1.1833838349074297
Validation loss: 2.651367786985813

Epoch: 6| Step: 8
Training loss: 1.7233391271133476
Validation loss: 2.728428126766043

Epoch: 6| Step: 9
Training loss: 1.362893429220545
Validation loss: 2.6367479562907907

Epoch: 6| Step: 10
Training loss: 0.8829673361239558
Validation loss: 2.552853889654365

Epoch: 6| Step: 11
Training loss: 1.1903392579027288
Validation loss: 2.5569111423740045

Epoch: 6| Step: 12
Training loss: 1.2419465029155345
Validation loss: 2.5091063903981015

Epoch: 6| Step: 13
Training loss: 1.154262587397904
Validation loss: 2.5670730289780157

Epoch: 106| Step: 0
Training loss: 1.1869108846903424
Validation loss: 2.595481585637247

Epoch: 6| Step: 1
Training loss: 1.5465332578529514
Validation loss: 2.575422824477227

Epoch: 6| Step: 2
Training loss: 1.1701413873682915
Validation loss: 2.5809605658626293

Epoch: 6| Step: 3
Training loss: 0.8221209981042856
Validation loss: 2.5382538940859196

Epoch: 6| Step: 4
Training loss: 1.0552082047959777
Validation loss: 2.5259130910549605

Epoch: 6| Step: 5
Training loss: 1.2933279039983412
Validation loss: 2.6177511187172646

Epoch: 6| Step: 6
Training loss: 1.1172564825355185
Validation loss: 2.6039341835517438

Epoch: 6| Step: 7
Training loss: 1.2097790499007897
Validation loss: 2.637479620518828

Epoch: 6| Step: 8
Training loss: 1.7482522683976474
Validation loss: 2.696152663934407

Epoch: 6| Step: 9
Training loss: 1.3568442453547658
Validation loss: 2.657602751101058

Epoch: 6| Step: 10
Training loss: 1.8972820643340507
Validation loss: 2.656991010041702

Epoch: 6| Step: 11
Training loss: 1.6647403393138724
Validation loss: 2.556250651016712

Epoch: 6| Step: 12
Training loss: 1.1129369370587674
Validation loss: 2.5545501360968106

Epoch: 6| Step: 13
Training loss: 1.1208540497369708
Validation loss: 2.5271953714121644

Epoch: 107| Step: 0
Training loss: 1.1165182603366965
Validation loss: 2.582130095513086

Epoch: 6| Step: 1
Training loss: 1.5931640744720792
Validation loss: 2.6288178548552072

Epoch: 6| Step: 2
Training loss: 1.4504402544616222
Validation loss: 2.6186846498090737

Epoch: 6| Step: 3
Training loss: 0.9880704391057261
Validation loss: 2.5758476448545964

Epoch: 6| Step: 4
Training loss: 1.1205887670664418
Validation loss: 2.5532427327571736

Epoch: 6| Step: 5
Training loss: 1.7753692726387196
Validation loss: 2.603834845701445

Epoch: 6| Step: 6
Training loss: 0.772169441558487
Validation loss: 2.599968804881437

Epoch: 6| Step: 7
Training loss: 1.293338411622712
Validation loss: 2.6204362434007336

Epoch: 6| Step: 8
Training loss: 1.1050325213691161
Validation loss: 2.6447529627064044

Epoch: 6| Step: 9
Training loss: 1.0394515836375269
Validation loss: 2.7329895724085893

Epoch: 6| Step: 10
Training loss: 0.6028104693278217
Validation loss: 2.6838836587363466

Epoch: 6| Step: 11
Training loss: 1.1384908489718961
Validation loss: 2.6930134721492895

Epoch: 6| Step: 12
Training loss: 1.6015685290711594
Validation loss: 2.5634654172624782

Epoch: 6| Step: 13
Training loss: 1.5750517427936825
Validation loss: 2.584371963001021

Epoch: 108| Step: 0
Training loss: 1.2514845615460408
Validation loss: 2.6009254019136305

Epoch: 6| Step: 1
Training loss: 1.2216421193201974
Validation loss: 2.571148150028967

Epoch: 6| Step: 2
Training loss: 1.2262949074582277
Validation loss: 2.550109213939913

Epoch: 6| Step: 3
Training loss: 1.4799354417999968
Validation loss: 2.539376146555842

Epoch: 6| Step: 4
Training loss: 1.1967658389039266
Validation loss: 2.5891234794929865

Epoch: 6| Step: 5
Training loss: 0.9590772906194887
Validation loss: 2.5702809155039614

Epoch: 6| Step: 6
Training loss: 2.0307755136170376
Validation loss: 2.603432549317111

Epoch: 6| Step: 7
Training loss: 1.0858507739228074
Validation loss: 2.6536114471773247

Epoch: 6| Step: 8
Training loss: 1.2337238187630473
Validation loss: 2.6239623486310326

Epoch: 6| Step: 9
Training loss: 1.5489883628590322
Validation loss: 2.6573266184945767

Epoch: 6| Step: 10
Training loss: 1.357658486361686
Validation loss: 2.65391927451463

Epoch: 6| Step: 11
Training loss: 0.8028394347261194
Validation loss: 2.5769587797895364

Epoch: 6| Step: 12
Training loss: 1.056820838212658
Validation loss: 2.64913382139561

Epoch: 6| Step: 13
Training loss: 1.0361929830181396
Validation loss: 2.621330436257048

Epoch: 109| Step: 0
Training loss: 0.916123764064318
Validation loss: 2.6091937308632307

Epoch: 6| Step: 1
Training loss: 1.4847069620066466
Validation loss: 2.6146938609638593

Epoch: 6| Step: 2
Training loss: 0.6039550564130838
Validation loss: 2.564910809092164

Epoch: 6| Step: 3
Training loss: 0.919833622483516
Validation loss: 2.544595536928931

Epoch: 6| Step: 4
Training loss: 1.2005197631213314
Validation loss: 2.5642275220732436

Epoch: 6| Step: 5
Training loss: 0.814804001567436
Validation loss: 2.5342065553704765

Epoch: 6| Step: 6
Training loss: 1.9698239379477143
Validation loss: 2.5392544483109423

Epoch: 6| Step: 7
Training loss: 1.0249851551376554
Validation loss: 2.548367287397334

Epoch: 6| Step: 8
Training loss: 1.4837148704323022
Validation loss: 2.6534745619997966

Epoch: 6| Step: 9
Training loss: 1.4375908864356004
Validation loss: 2.6002417066904147

Epoch: 6| Step: 10
Training loss: 0.9535281470014524
Validation loss: 2.6139068690956413

Epoch: 6| Step: 11
Training loss: 1.0617311725352865
Validation loss: 2.6618956015665076

Epoch: 6| Step: 12
Training loss: 1.291417554193166
Validation loss: 2.6276625496635555

Epoch: 6| Step: 13
Training loss: 1.0388981968898476
Validation loss: 2.6432207580332436

Epoch: 110| Step: 0
Training loss: 1.253357954561251
Validation loss: 2.6164032097828516

Epoch: 6| Step: 1
Training loss: 1.2402455727379582
Validation loss: 2.5789805216216997

Epoch: 6| Step: 2
Training loss: 0.8744122029502648
Validation loss: 2.613484707806268

Epoch: 6| Step: 3
Training loss: 1.239054152856253
Validation loss: 2.5422527049306556

Epoch: 6| Step: 4
Training loss: 0.9865096727739019
Validation loss: 2.62248575813395

Epoch: 6| Step: 5
Training loss: 1.35908439423869
Validation loss: 2.555847806621111

Epoch: 6| Step: 6
Training loss: 1.0661694050568304
Validation loss: 2.6131865632029045

Epoch: 6| Step: 7
Training loss: 0.9512622328183474
Validation loss: 2.64254298331274

Epoch: 6| Step: 8
Training loss: 1.1301255554731178
Validation loss: 2.549424048436138

Epoch: 6| Step: 9
Training loss: 0.9412557077931349
Validation loss: 2.60841618508895

Epoch: 6| Step: 10
Training loss: 0.9950858308682876
Validation loss: 2.6478922159750313

Epoch: 6| Step: 11
Training loss: 1.2018893448424395
Validation loss: 2.647196716309362

Epoch: 6| Step: 12
Training loss: 1.4451665856190488
Validation loss: 2.6252589930575376

Epoch: 6| Step: 13
Training loss: 1.9029042634280646
Validation loss: 2.5379313604964637

Epoch: 111| Step: 0
Training loss: 1.6289350840991879
Validation loss: 2.651237155823843

Epoch: 6| Step: 1
Training loss: 1.0492037024310132
Validation loss: 2.589221263891414

Epoch: 6| Step: 2
Training loss: 1.76860382500502
Validation loss: 2.6366772834437087

Epoch: 6| Step: 3
Training loss: 0.8691109984416862
Validation loss: 2.5304851553827676

Epoch: 6| Step: 4
Training loss: 0.9657016291659611
Validation loss: 2.6335342429171384

Epoch: 6| Step: 5
Training loss: 0.9038588449614189
Validation loss: 2.620486102327361

Epoch: 6| Step: 6
Training loss: 1.239761478648631
Validation loss: 2.683168247033426

Epoch: 6| Step: 7
Training loss: 0.8911496674934336
Validation loss: 2.6715989295557145

Epoch: 6| Step: 8
Training loss: 1.1630711270277385
Validation loss: 2.6176255044661123

Epoch: 6| Step: 9
Training loss: 1.1980977736967962
Validation loss: 2.683842735826335

Epoch: 6| Step: 10
Training loss: 1.1317973356600832
Validation loss: 2.703708394624491

Epoch: 6| Step: 11
Training loss: 0.9184510607527898
Validation loss: 2.6176849044396993

Epoch: 6| Step: 12
Training loss: 0.9824497833231524
Validation loss: 2.6085994580634737

Epoch: 6| Step: 13
Training loss: 0.8052588721268885
Validation loss: 2.605658086315191

Epoch: 112| Step: 0
Training loss: 0.9667157379937066
Validation loss: 2.658491393226446

Epoch: 6| Step: 1
Training loss: 1.326058159561055
Validation loss: 2.6487903041152516

Epoch: 6| Step: 2
Training loss: 1.7889893362752045
Validation loss: 2.593237247877113

Epoch: 6| Step: 3
Training loss: 0.9235673016043018
Validation loss: 2.5679708556841745

Epoch: 6| Step: 4
Training loss: 0.8333706529525963
Validation loss: 2.604470949833734

Epoch: 6| Step: 5
Training loss: 1.4470990660420238
Validation loss: 2.554798897619424

Epoch: 6| Step: 6
Training loss: 1.0191230980041115
Validation loss: 2.5685788446411575

Epoch: 6| Step: 7
Training loss: 0.9589770718857769
Validation loss: 2.658504666115616

Epoch: 6| Step: 8
Training loss: 1.5126981495091214
Validation loss: 2.6655335154604316

Epoch: 6| Step: 9
Training loss: 1.1437639913067987
Validation loss: 2.6988088146525055

Epoch: 6| Step: 10
Training loss: 1.010870854393421
Validation loss: 2.685151338059453

Epoch: 6| Step: 11
Training loss: 1.0016004748591616
Validation loss: 2.694249556289235

Epoch: 6| Step: 12
Training loss: 0.956861519846282
Validation loss: 2.6785687631260764

Epoch: 6| Step: 13
Training loss: 1.084274885409658
Validation loss: 2.6331730415554717

Epoch: 113| Step: 0
Training loss: 1.8887934364560264
Validation loss: 2.6649693262936553

Epoch: 6| Step: 1
Training loss: 0.8373029733315058
Validation loss: 2.642759630314108

Epoch: 6| Step: 2
Training loss: 0.9260699630779511
Validation loss: 2.5636887932980157

Epoch: 6| Step: 3
Training loss: 1.0916492451061468
Validation loss: 2.680144690835227

Epoch: 6| Step: 4
Training loss: 1.1384878124310138
Validation loss: 2.5978755695811238

Epoch: 6| Step: 5
Training loss: 0.9022081942112388
Validation loss: 2.62833525685603

Epoch: 6| Step: 6
Training loss: 1.3685753453969725
Validation loss: 2.636698208952589

Epoch: 6| Step: 7
Training loss: 1.4449647227274296
Validation loss: 2.6874432520826312

Epoch: 6| Step: 8
Training loss: 1.0214066484977757
Validation loss: 2.6535896292821826

Epoch: 6| Step: 9
Training loss: 0.9505929301192623
Validation loss: 2.6890339724445917

Epoch: 6| Step: 10
Training loss: 0.836502098436568
Validation loss: 2.726230123786468

Epoch: 6| Step: 11
Training loss: 1.1772717125413938
Validation loss: 2.674777887457774

Epoch: 6| Step: 12
Training loss: 1.3088415110601508
Validation loss: 2.666981668543503

Epoch: 6| Step: 13
Training loss: 0.9363233812042495
Validation loss: 2.6633971904010987

Epoch: 114| Step: 0
Training loss: 0.706288237085193
Validation loss: 2.617168172129153

Epoch: 6| Step: 1
Training loss: 1.3121782998518576
Validation loss: 2.637009517508324

Epoch: 6| Step: 2
Training loss: 0.9688766765833436
Validation loss: 2.6698143878574703

Epoch: 6| Step: 3
Training loss: 1.287748834951974
Validation loss: 2.6290771972941904

Epoch: 6| Step: 4
Training loss: 0.9865649250666502
Validation loss: 2.6589015741010686

Epoch: 6| Step: 5
Training loss: 0.7713325834034357
Validation loss: 2.575852658476873

Epoch: 6| Step: 6
Training loss: 0.9947405430837252
Validation loss: 2.630191014802526

Epoch: 6| Step: 7
Training loss: 1.0789689893111014
Validation loss: 2.6077511544970937

Epoch: 6| Step: 8
Training loss: 1.459975144945503
Validation loss: 2.618886322260657

Epoch: 6| Step: 9
Training loss: 0.9623034003968997
Validation loss: 2.599716891256243

Epoch: 6| Step: 10
Training loss: 0.754166987895019
Validation loss: 2.703700730122809

Epoch: 6| Step: 11
Training loss: 1.1093923540504167
Validation loss: 2.6333541388434183

Epoch: 6| Step: 12
Training loss: 1.7376202987630351
Validation loss: 2.6829153922095195

Epoch: 6| Step: 13
Training loss: 1.3553004091588559
Validation loss: 2.6896481910723735

Epoch: 115| Step: 0
Training loss: 1.3678386336599977
Validation loss: 2.7189700158203163

Epoch: 6| Step: 1
Training loss: 0.896602049440913
Validation loss: 2.6812313514896813

Epoch: 6| Step: 2
Training loss: 0.8711517383108162
Validation loss: 2.659409562456718

Epoch: 6| Step: 3
Training loss: 1.171924946038499
Validation loss: 2.58009534354075

Epoch: 6| Step: 4
Training loss: 0.9178235527622545
Validation loss: 2.5875802714110114

Epoch: 6| Step: 5
Training loss: 1.058003222177571
Validation loss: 2.5886238719595047

Epoch: 6| Step: 6
Training loss: 0.7893863806428943
Validation loss: 2.630057964496028

Epoch: 6| Step: 7
Training loss: 1.2136147713096068
Validation loss: 2.658190149578759

Epoch: 6| Step: 8
Training loss: 1.9736691735347338
Validation loss: 2.593598112385365

Epoch: 6| Step: 9
Training loss: 0.6890935203161243
Validation loss: 2.6641328714721264

Epoch: 6| Step: 10
Training loss: 0.8020809883644867
Validation loss: 2.7233081185034655

Epoch: 6| Step: 11
Training loss: 0.8346247124345074
Validation loss: 2.651084499849986

Epoch: 6| Step: 12
Training loss: 1.573587522959346
Validation loss: 2.701415283828179

Epoch: 6| Step: 13
Training loss: 0.9314804099332178
Validation loss: 2.711437007093785

Epoch: 116| Step: 0
Training loss: 0.9425161949203169
Validation loss: 2.6833581723866247

Epoch: 6| Step: 1
Training loss: 0.88368796091697
Validation loss: 2.6531537878528804

Epoch: 6| Step: 2
Training loss: 0.8975877143054775
Validation loss: 2.6584777465945026

Epoch: 6| Step: 3
Training loss: 0.6504944039792402
Validation loss: 2.6917566552093923

Epoch: 6| Step: 4
Training loss: 0.9446153197883492
Validation loss: 2.6179390354911978

Epoch: 6| Step: 5
Training loss: 1.3290906649219159
Validation loss: 2.6069365203263684

Epoch: 6| Step: 6
Training loss: 1.0604404796532174
Validation loss: 2.6913638469159094

Epoch: 6| Step: 7
Training loss: 0.7692102450145271
Validation loss: 2.7086295968408605

Epoch: 6| Step: 8
Training loss: 1.0631722399281525
Validation loss: 2.7475252575996216

Epoch: 6| Step: 9
Training loss: 1.2196404554211369
Validation loss: 2.677493399200234

Epoch: 6| Step: 10
Training loss: 1.0325626919535351
Validation loss: 2.7330619638534603

Epoch: 6| Step: 11
Training loss: 1.0136234220416505
Validation loss: 2.652578966126027

Epoch: 6| Step: 12
Training loss: 1.5967980950456926
Validation loss: 2.7056317181825813

Epoch: 6| Step: 13
Training loss: 1.1235269863688726
Validation loss: 2.7587129673548554

Epoch: 117| Step: 0
Training loss: 0.8278133597680909
Validation loss: 2.7768299970715735

Epoch: 6| Step: 1
Training loss: 0.9922078047950027
Validation loss: 2.714331269778239

Epoch: 6| Step: 2
Training loss: 0.6827775278453957
Validation loss: 2.700982326900753

Epoch: 6| Step: 3
Training loss: 1.119482603966174
Validation loss: 2.73234964111191

Epoch: 6| Step: 4
Training loss: 1.8428805612742674
Validation loss: 2.8014966121201255

Epoch: 6| Step: 5
Training loss: 0.8855529381098954
Validation loss: 2.6561308590966193

Epoch: 6| Step: 6
Training loss: 1.088372389242069
Validation loss: 2.65815583466585

Epoch: 6| Step: 7
Training loss: 1.0240803803322618
Validation loss: 2.678345606533844

Epoch: 6| Step: 8
Training loss: 1.1390855930745127
Validation loss: 2.670624676516985

Epoch: 6| Step: 9
Training loss: 0.8981569598516894
Validation loss: 2.5394051658046046

Epoch: 6| Step: 10
Training loss: 1.2812290189932527
Validation loss: 2.559503679840588

Epoch: 6| Step: 11
Training loss: 1.0320362792661393
Validation loss: 2.6187144669312428

Epoch: 6| Step: 12
Training loss: 0.910438919377381
Validation loss: 2.6224184966536495

Epoch: 6| Step: 13
Training loss: 0.8397073324435996
Validation loss: 2.6761138709278467

Epoch: 118| Step: 0
Training loss: 0.9864505502997327
Validation loss: 2.6274986182879765

Epoch: 6| Step: 1
Training loss: 0.7069261588717293
Validation loss: 2.620129198863635

Epoch: 6| Step: 2
Training loss: 0.5503832955342793
Validation loss: 2.6397387580505756

Epoch: 6| Step: 3
Training loss: 0.9447072195707387
Validation loss: 2.62435523697747

Epoch: 6| Step: 4
Training loss: 0.7772164935512196
Validation loss: 2.6510530232983793

Epoch: 6| Step: 5
Training loss: 0.6460632842882919
Validation loss: 2.6936791377471816

Epoch: 6| Step: 6
Training loss: 0.8304464084207428
Validation loss: 2.691128683703095

Epoch: 6| Step: 7
Training loss: 0.8856517404895272
Validation loss: 2.7453353652190065

Epoch: 6| Step: 8
Training loss: 0.7683504601539817
Validation loss: 2.661576767965654

Epoch: 6| Step: 9
Training loss: 2.0398719321049663
Validation loss: 2.7030461764741065

Epoch: 6| Step: 10
Training loss: 1.1643033898488773
Validation loss: 2.6547301637942033

Epoch: 6| Step: 11
Training loss: 1.3012494685073925
Validation loss: 2.699566816383544

Epoch: 6| Step: 12
Training loss: 0.8317047338112724
Validation loss: 2.7331496917472275

Epoch: 6| Step: 13
Training loss: 0.9332892268408517
Validation loss: 2.707678911421472

Epoch: 119| Step: 0
Training loss: 0.8954811217013038
Validation loss: 2.595941269060825

Epoch: 6| Step: 1
Training loss: 1.5353331330487388
Validation loss: 2.617788111155023

Epoch: 6| Step: 2
Training loss: 0.90981040572486
Validation loss: 2.652264406106429

Epoch: 6| Step: 3
Training loss: 0.8329665966503422
Validation loss: 2.6737411518316114

Epoch: 6| Step: 4
Training loss: 0.6564913033579796
Validation loss: 2.636448945735002

Epoch: 6| Step: 5
Training loss: 1.1291432379418724
Validation loss: 2.7073612718390705

Epoch: 6| Step: 6
Training loss: 0.8380162071604538
Validation loss: 2.762921723731398

Epoch: 6| Step: 7
Training loss: 1.862761418986592
Validation loss: 2.701847884587508

Epoch: 6| Step: 8
Training loss: 0.80479871111012
Validation loss: 2.7567860221240172

Epoch: 6| Step: 9
Training loss: 1.0946013815478168
Validation loss: 2.7043671005177146

Epoch: 6| Step: 10
Training loss: 1.2135591737633142
Validation loss: 2.67499825189361

Epoch: 6| Step: 11
Training loss: 0.7137371732825253
Validation loss: 2.6751336792197433

Epoch: 6| Step: 12
Training loss: 0.790344933522704
Validation loss: 2.633792027127723

Epoch: 6| Step: 13
Training loss: 0.9928194871752053
Validation loss: 2.684556591211183

Epoch: 120| Step: 0
Training loss: 1.156861117963385
Validation loss: 2.66397861262873

Epoch: 6| Step: 1
Training loss: 0.9411561562514382
Validation loss: 2.751484138084894

Epoch: 6| Step: 2
Training loss: 1.1826589688796376
Validation loss: 2.683691149799129

Epoch: 6| Step: 3
Training loss: 0.8380851608695933
Validation loss: 2.7166895750363165

Epoch: 6| Step: 4
Training loss: 1.2191891001481951
Validation loss: 2.6741861828592826

Epoch: 6| Step: 5
Training loss: 1.0069825059267075
Validation loss: 2.775101870594359

Epoch: 6| Step: 6
Training loss: 0.8694002256703353
Validation loss: 2.7003095514138424

Epoch: 6| Step: 7
Training loss: 0.8263767069676486
Validation loss: 2.7587574464679903

Epoch: 6| Step: 8
Training loss: 0.8257827744339051
Validation loss: 2.717654559265171

Epoch: 6| Step: 9
Training loss: 0.9283736425708048
Validation loss: 2.673328331584326

Epoch: 6| Step: 10
Training loss: 0.9427091833851953
Validation loss: 2.6627416981580887

Epoch: 6| Step: 11
Training loss: 1.0767741932237924
Validation loss: 2.660877878652711

Epoch: 6| Step: 12
Training loss: 1.4185528353511332
Validation loss: 2.731206165837809

Epoch: 6| Step: 13
Training loss: 1.736905974791063
Validation loss: 2.7590665478535707

Epoch: 121| Step: 0
Training loss: 1.8169933395767537
Validation loss: 2.697128156123245

Epoch: 6| Step: 1
Training loss: 1.3040481188502422
Validation loss: 2.761652685343732

Epoch: 6| Step: 2
Training loss: 0.8237393689084609
Validation loss: 2.750734375663811

Epoch: 6| Step: 3
Training loss: 1.2832269535726348
Validation loss: 2.774294911410448

Epoch: 6| Step: 4
Training loss: 1.288661038855315
Validation loss: 2.7152854358882723

Epoch: 6| Step: 5
Training loss: 0.8571365333505504
Validation loss: 2.726989231764009

Epoch: 6| Step: 6
Training loss: 1.1824598766883052
Validation loss: 2.5737009333237393

Epoch: 6| Step: 7
Training loss: 0.7503042398718602
Validation loss: 2.6031476328561585

Epoch: 6| Step: 8
Training loss: 0.9162173831853648
Validation loss: 2.666496321085203

Epoch: 6| Step: 9
Training loss: 1.0828121961452835
Validation loss: 2.64164638892573

Epoch: 6| Step: 10
Training loss: 1.1700532103934322
Validation loss: 2.6913136178857533

Epoch: 6| Step: 11
Training loss: 0.8748459680402749
Validation loss: 2.6535602489642516

Epoch: 6| Step: 12
Training loss: 0.6886247624182036
Validation loss: 2.7357452156531457

Epoch: 6| Step: 13
Training loss: 0.855882344357722
Validation loss: 2.7690787580160854

Epoch: 122| Step: 0
Training loss: 0.754122648658166
Validation loss: 2.928351420601958

Epoch: 6| Step: 1
Training loss: 0.9756064656248661
Validation loss: 2.8118326737654438

Epoch: 6| Step: 2
Training loss: 0.9070683763316705
Validation loss: 2.6452508620659207

Epoch: 6| Step: 3
Training loss: 0.6890249246399255
Validation loss: 2.680827855547367

Epoch: 6| Step: 4
Training loss: 1.1637806903303785
Validation loss: 2.6798648756987706

Epoch: 6| Step: 5
Training loss: 0.4189265320309779
Validation loss: 2.6681890810928244

Epoch: 6| Step: 6
Training loss: 0.6719303330103183
Validation loss: 2.6629612679810903

Epoch: 6| Step: 7
Training loss: 0.5293519952092376
Validation loss: 2.6733528942794087

Epoch: 6| Step: 8
Training loss: 0.8388576662458062
Validation loss: 2.647390723250102

Epoch: 6| Step: 9
Training loss: 1.291074211880394
Validation loss: 2.706974691338679

Epoch: 6| Step: 10
Training loss: 1.19325687948498
Validation loss: 2.643860108688116

Epoch: 6| Step: 11
Training loss: 1.2085257848309727
Validation loss: 2.6263533085883553

Epoch: 6| Step: 12
Training loss: 0.9454260513581858
Validation loss: 2.6521462248491825

Epoch: 6| Step: 13
Training loss: 1.7211799783530195
Validation loss: 2.702780846827839

Epoch: 123| Step: 0
Training loss: 0.9752716688551936
Validation loss: 2.752181358430173

Epoch: 6| Step: 1
Training loss: 1.0793873128094833
Validation loss: 2.6303060884848137

Epoch: 6| Step: 2
Training loss: 1.1377639422366066
Validation loss: 2.6409224694391202

Epoch: 6| Step: 3
Training loss: 0.9149664623075944
Validation loss: 2.6633520437529494

Epoch: 6| Step: 4
Training loss: 1.2345979706463743
Validation loss: 2.660012844886456

Epoch: 6| Step: 5
Training loss: 0.8171965866604818
Validation loss: 2.6415437382958005

Epoch: 6| Step: 6
Training loss: 0.5841946940788703
Validation loss: 2.64641700274119

Epoch: 6| Step: 7
Training loss: 0.6156089974274442
Validation loss: 2.6615450422541476

Epoch: 6| Step: 8
Training loss: 0.712290513881105
Validation loss: 2.702626353229332

Epoch: 6| Step: 9
Training loss: 0.9668285017909356
Validation loss: 2.6958551275285223

Epoch: 6| Step: 10
Training loss: 0.8475452121839058
Validation loss: 2.675802129585127

Epoch: 6| Step: 11
Training loss: 0.9939660179423735
Validation loss: 2.6640162011800417

Epoch: 6| Step: 12
Training loss: 0.9315200503715592
Validation loss: 2.730754977365053

Epoch: 6| Step: 13
Training loss: 1.7835244498238612
Validation loss: 2.671350840413197

Epoch: 124| Step: 0
Training loss: 0.9161806913550028
Validation loss: 2.6827882819322157

Epoch: 6| Step: 1
Training loss: 0.9507124964508976
Validation loss: 2.7019936283214334

Epoch: 6| Step: 2
Training loss: 0.9761870616206264
Validation loss: 2.7249880000092284

Epoch: 6| Step: 3
Training loss: 0.7546991714617552
Validation loss: 2.6860486332875935

Epoch: 6| Step: 4
Training loss: 0.813008736018017
Validation loss: 2.670679163140656

Epoch: 6| Step: 5
Training loss: 1.8483532484109348
Validation loss: 2.7317858835877917

Epoch: 6| Step: 6
Training loss: 1.1171716542220598
Validation loss: 2.6137508014207653

Epoch: 6| Step: 7
Training loss: 0.7316232625242322
Validation loss: 2.7002593121983325

Epoch: 6| Step: 8
Training loss: 0.8308008256736403
Validation loss: 2.637643308196312

Epoch: 6| Step: 9
Training loss: 0.8015440866240431
Validation loss: 2.663367440845184

Epoch: 6| Step: 10
Training loss: 0.7807650014344295
Validation loss: 2.655879020964247

Epoch: 6| Step: 11
Training loss: 1.13042097537753
Validation loss: 2.678056507874298

Epoch: 6| Step: 12
Training loss: 0.9835880100606942
Validation loss: 2.710189444957286

Epoch: 6| Step: 13
Training loss: 0.738946604765127
Validation loss: 2.611597998746297

Epoch: 125| Step: 0
Training loss: 1.185220437772865
Validation loss: 2.6922482971305044

Epoch: 6| Step: 1
Training loss: 0.7024235511397452
Validation loss: 2.672527018030742

Epoch: 6| Step: 2
Training loss: 0.5961792590804146
Validation loss: 2.7811005798664046

Epoch: 6| Step: 3
Training loss: 1.1511653241093138
Validation loss: 2.7195343698456114

Epoch: 6| Step: 4
Training loss: 0.8018610675222805
Validation loss: 2.5992696164130775

Epoch: 6| Step: 5
Training loss: 0.6865091552985184
Validation loss: 2.6783338710861124

Epoch: 6| Step: 6
Training loss: 1.7709182793681693
Validation loss: 2.696743453535392

Epoch: 6| Step: 7
Training loss: 0.9463479542392739
Validation loss: 2.633329587845211

Epoch: 6| Step: 8
Training loss: 0.9396361491942611
Validation loss: 2.6536468465926033

Epoch: 6| Step: 9
Training loss: 1.0171915736900594
Validation loss: 2.7816449145713587

Epoch: 6| Step: 10
Training loss: 0.8867381761750436
Validation loss: 2.70621343445541

Epoch: 6| Step: 11
Training loss: 1.0268915145576933
Validation loss: 2.734036684451039

Epoch: 6| Step: 12
Training loss: 0.9810181556444822
Validation loss: 2.757969117873004

Epoch: 6| Step: 13
Training loss: 0.9533758302422151
Validation loss: 2.7468650751147967

Epoch: 126| Step: 0
Training loss: 0.9235176064589659
Validation loss: 2.794003666136477

Epoch: 6| Step: 1
Training loss: 0.7145460999541288
Validation loss: 2.717972414036732

Epoch: 6| Step: 2
Training loss: 1.2533748843698134
Validation loss: 2.76021513773061

Epoch: 6| Step: 3
Training loss: 0.9934890800398138
Validation loss: 2.6906029582551483

Epoch: 6| Step: 4
Training loss: 0.9049554984600708
Validation loss: 2.736666709034122

Epoch: 6| Step: 5
Training loss: 0.7339594050571119
Validation loss: 2.729650561310773

Epoch: 6| Step: 6
Training loss: 0.5972625333158362
Validation loss: 2.6476031464201806

Epoch: 6| Step: 7
Training loss: 0.7294049191651335
Validation loss: 2.725492440504742

Epoch: 6| Step: 8
Training loss: 0.7822708707873764
Validation loss: 2.7156634367171346

Epoch: 6| Step: 9
Training loss: 1.1601200804546996
Validation loss: 2.6534461687846655

Epoch: 6| Step: 10
Training loss: 1.7130741382105976
Validation loss: 2.7132191579245553

Epoch: 6| Step: 11
Training loss: 0.8813421782854345
Validation loss: 2.760381652801903

Epoch: 6| Step: 12
Training loss: 0.9702037240453307
Validation loss: 2.6666357267094845

Epoch: 6| Step: 13
Training loss: 0.9873548244042992
Validation loss: 2.651154661237459

Epoch: 127| Step: 0
Training loss: 0.7074738271205787
Validation loss: 2.6424740819944192

Epoch: 6| Step: 1
Training loss: 0.7602804837147548
Validation loss: 2.6973847020645016

Epoch: 6| Step: 2
Training loss: 1.2135360892280909
Validation loss: 2.7266088880729993

Epoch: 6| Step: 3
Training loss: 0.9715996330676715
Validation loss: 2.693593060021882

Epoch: 6| Step: 4
Training loss: 0.9132208250237784
Validation loss: 2.6570746843271924

Epoch: 6| Step: 5
Training loss: 0.9533378801092903
Validation loss: 2.701562404099377

Epoch: 6| Step: 6
Training loss: 1.085797197897544
Validation loss: 2.7034440780216853

Epoch: 6| Step: 7
Training loss: 0.9598487641000042
Validation loss: 2.7092284019552464

Epoch: 6| Step: 8
Training loss: 0.8219221036343706
Validation loss: 2.6114455438966933

Epoch: 6| Step: 9
Training loss: 0.7600184316658792
Validation loss: 2.611849587986198

Epoch: 6| Step: 10
Training loss: 0.6854457943726571
Validation loss: 2.6448757110700036

Epoch: 6| Step: 11
Training loss: 1.707602608252093
Validation loss: 2.687213808538594

Epoch: 6| Step: 12
Training loss: 0.9166445982328439
Validation loss: 2.6701069981379644

Epoch: 6| Step: 13
Training loss: 0.7618749213903198
Validation loss: 2.7965964706084896

Epoch: 128| Step: 0
Training loss: 0.6331578242613409
Validation loss: 2.6841231725754007

Epoch: 6| Step: 1
Training loss: 1.0629580015496716
Validation loss: 2.726244116323058

Epoch: 6| Step: 2
Training loss: 1.001186203751742
Validation loss: 2.634732988257681

Epoch: 6| Step: 3
Training loss: 0.7474924527938694
Validation loss: 2.6832392725442045

Epoch: 6| Step: 4
Training loss: 0.8674375500036187
Validation loss: 2.6059688029155303

Epoch: 6| Step: 5
Training loss: 0.969216572785073
Validation loss: 2.7079632188307885

Epoch: 6| Step: 6
Training loss: 0.5179706164940624
Validation loss: 2.6936397282097153

Epoch: 6| Step: 7
Training loss: 0.6763173441045823
Validation loss: 2.6521729988788545

Epoch: 6| Step: 8
Training loss: 0.658079594189653
Validation loss: 2.7815618875912365

Epoch: 6| Step: 9
Training loss: 1.7222732498785767
Validation loss: 2.745715126499444

Epoch: 6| Step: 10
Training loss: 0.6702548831461591
Validation loss: 2.711406656174109

Epoch: 6| Step: 11
Training loss: 0.9762117289955552
Validation loss: 2.730834237933676

Epoch: 6| Step: 12
Training loss: 0.5876834542373457
Validation loss: 2.6769575591667336

Epoch: 6| Step: 13
Training loss: 0.89390922141819
Validation loss: 2.7655284742619326

Epoch: 129| Step: 0
Training loss: 0.9289590883105788
Validation loss: 2.670479616456982

Epoch: 6| Step: 1
Training loss: 0.658888779486157
Validation loss: 2.7732530702689546

Epoch: 6| Step: 2
Training loss: 0.8137585356187039
Validation loss: 2.6728198516826662

Epoch: 6| Step: 3
Training loss: 0.9583290797982289
Validation loss: 2.6785362595565427

Epoch: 6| Step: 4
Training loss: 0.48989747161991454
Validation loss: 2.750723671339878

Epoch: 6| Step: 5
Training loss: 0.9255325369594916
Validation loss: 2.6366294111022235

Epoch: 6| Step: 6
Training loss: 1.172839314748576
Validation loss: 2.613115169491753

Epoch: 6| Step: 7
Training loss: 0.6694702316486448
Validation loss: 2.6952406426770263

Epoch: 6| Step: 8
Training loss: 1.7048391412828796
Validation loss: 2.690950116029131

Epoch: 6| Step: 9
Training loss: 0.8514020576170812
Validation loss: 2.659000879636908

Epoch: 6| Step: 10
Training loss: 0.7392453151034538
Validation loss: 2.667406692243433

Epoch: 6| Step: 11
Training loss: 0.7690630035212735
Validation loss: 2.7031392150387537

Epoch: 6| Step: 12
Training loss: 0.9927038816423595
Validation loss: 2.6901177808793153

Epoch: 6| Step: 13
Training loss: 0.7535078349880018
Validation loss: 2.8017697684723335

Epoch: 130| Step: 0
Training loss: 0.8067035050164332
Validation loss: 2.7006186771355587

Epoch: 6| Step: 1
Training loss: 0.6855184869784529
Validation loss: 2.6486923560266455

Epoch: 6| Step: 2
Training loss: 0.6665782174404783
Validation loss: 2.7275231899624126

Epoch: 6| Step: 3
Training loss: 0.9881965691394771
Validation loss: 2.741597053161958

Epoch: 6| Step: 4
Training loss: 1.147935718763665
Validation loss: 2.716568023747407

Epoch: 6| Step: 5
Training loss: 0.6519892523134238
Validation loss: 2.69341320254227

Epoch: 6| Step: 6
Training loss: 0.916593422275425
Validation loss: 2.6371777547044566

Epoch: 6| Step: 7
Training loss: 0.5788757501513704
Validation loss: 2.7133856720605767

Epoch: 6| Step: 8
Training loss: 0.9855451138571759
Validation loss: 2.6896995518339293

Epoch: 6| Step: 9
Training loss: 1.1091347017752753
Validation loss: 2.760978588754876

Epoch: 6| Step: 10
Training loss: 0.8497633520448235
Validation loss: 2.6892102809908076

Epoch: 6| Step: 11
Training loss: 0.5145736147726014
Validation loss: 2.685182962441042

Epoch: 6| Step: 12
Training loss: 0.6683917797444361
Validation loss: 2.7553632628947953

Epoch: 6| Step: 13
Training loss: 1.612749506254746
Validation loss: 2.722167238882563

Epoch: 131| Step: 0
Training loss: 0.6569231304970309
Validation loss: 2.721786878336733

Epoch: 6| Step: 1
Training loss: 0.817336068588563
Validation loss: 2.7707536848471053

Epoch: 6| Step: 2
Training loss: 0.7775660058120276
Validation loss: 2.729909756860846

Epoch: 6| Step: 3
Training loss: 0.7649750188725472
Validation loss: 2.823501249549625

Epoch: 6| Step: 4
Training loss: 1.7405867813818183
Validation loss: 2.7089135110979323

Epoch: 6| Step: 5
Training loss: 1.0456281040143298
Validation loss: 2.7669153454101516

Epoch: 6| Step: 6
Training loss: 0.762213951924959
Validation loss: 2.7426276655222876

Epoch: 6| Step: 7
Training loss: 0.7858312182298541
Validation loss: 2.7892101686852224

Epoch: 6| Step: 8
Training loss: 0.6760855634531788
Validation loss: 2.765245515754489

Epoch: 6| Step: 9
Training loss: 0.5449545792367391
Validation loss: 2.8139469380702367

Epoch: 6| Step: 10
Training loss: 1.2015673474832882
Validation loss: 2.7408021215013085

Epoch: 6| Step: 11
Training loss: 0.8692080353730165
Validation loss: 2.779196720637559

Epoch: 6| Step: 12
Training loss: 0.6224092670943477
Validation loss: 2.7317833525907473

Epoch: 6| Step: 13
Training loss: 0.8555259511278916
Validation loss: 2.7636819828059784

Epoch: 132| Step: 0
Training loss: 1.6656415727374172
Validation loss: 2.764136493929516

Epoch: 6| Step: 1
Training loss: 0.4885982704990412
Validation loss: 2.7188271259461567

Epoch: 6| Step: 2
Training loss: 1.0499986762083882
Validation loss: 2.7761585337436956

Epoch: 6| Step: 3
Training loss: 0.8021113072921293
Validation loss: 2.820513167775851

Epoch: 6| Step: 4
Training loss: 0.6349112475690866
Validation loss: 2.6971591244314572

Epoch: 6| Step: 5
Training loss: 0.6252787206963621
Validation loss: 2.651639400064658

Epoch: 6| Step: 6
Training loss: 0.9550551585301034
Validation loss: 2.620321297370156

Epoch: 6| Step: 7
Training loss: 1.2275005568213666
Validation loss: 2.6703092586586203

Epoch: 6| Step: 8
Training loss: 0.6157599006055122
Validation loss: 2.7212504876690793

Epoch: 6| Step: 9
Training loss: 0.7438570218061942
Validation loss: 2.663565938990912

Epoch: 6| Step: 10
Training loss: 1.044783025054843
Validation loss: 2.6684032289340127

Epoch: 6| Step: 11
Training loss: 0.9204177329968316
Validation loss: 2.799036863413412

Epoch: 6| Step: 12
Training loss: 1.0157786326483955
Validation loss: 2.7415378159581776

Epoch: 6| Step: 13
Training loss: 0.5780092329670494
Validation loss: 2.7438894788182715

Epoch: 133| Step: 0
Training loss: 0.6782723965404249
Validation loss: 2.691965149390769

Epoch: 6| Step: 1
Training loss: 0.9785235741572234
Validation loss: 2.7719887831599976

Epoch: 6| Step: 2
Training loss: 1.085475741125447
Validation loss: 2.7189725587448503

Epoch: 6| Step: 3
Training loss: 1.0441207524216307
Validation loss: 2.664616710780881

Epoch: 6| Step: 4
Training loss: 1.4339353066167286
Validation loss: 2.6295520731732593

Epoch: 6| Step: 5
Training loss: 0.7309264926481163
Validation loss: 2.7907109593690045

Epoch: 6| Step: 6
Training loss: 0.7575119838459099
Validation loss: 2.8159771088352494

Epoch: 6| Step: 7
Training loss: 0.9186495589802788
Validation loss: 2.8313432511108867

Epoch: 6| Step: 8
Training loss: 0.995874059049196
Validation loss: 2.800215248508248

Epoch: 6| Step: 9
Training loss: 0.9150378899989153
Validation loss: 2.749456380807629

Epoch: 6| Step: 10
Training loss: 0.8804537903023404
Validation loss: 2.6863810701317488

Epoch: 6| Step: 11
Training loss: 0.6393811548333921
Validation loss: 2.74265335342775

Epoch: 6| Step: 12
Training loss: 0.9632251460187865
Validation loss: 2.7201405619317285

Epoch: 6| Step: 13
Training loss: 1.6527433881556703
Validation loss: 2.7030371061820166

Epoch: 134| Step: 0
Training loss: 0.6903537778657477
Validation loss: 2.664076968216226

Epoch: 6| Step: 1
Training loss: 0.7387458106630567
Validation loss: 2.692244946705806

Epoch: 6| Step: 2
Training loss: 0.7672525739555154
Validation loss: 2.808624281560333

Epoch: 6| Step: 3
Training loss: 0.7460758546610412
Validation loss: 2.6580043459603915

Epoch: 6| Step: 4
Training loss: 0.6831800898599472
Validation loss: 2.8315893911542775

Epoch: 6| Step: 5
Training loss: 0.7090653302340892
Validation loss: 2.79838268482645

Epoch: 6| Step: 6
Training loss: 0.8686528926888373
Validation loss: 2.7137628173525434

Epoch: 6| Step: 7
Training loss: 0.7268348921569796
Validation loss: 2.6758559613343755

Epoch: 6| Step: 8
Training loss: 0.8226227698256029
Validation loss: 2.7224766048527282

Epoch: 6| Step: 9
Training loss: 0.7648264554711254
Validation loss: 2.642767952705232

Epoch: 6| Step: 10
Training loss: 1.5528291877253695
Validation loss: 2.7169830748436055

Epoch: 6| Step: 11
Training loss: 0.3041957775429544
Validation loss: 2.754279275074291

Epoch: 6| Step: 12
Training loss: 1.2271887765775276
Validation loss: 2.654949513139131

Epoch: 6| Step: 13
Training loss: 0.95189067775066
Validation loss: 2.719639022578028

Epoch: 135| Step: 0
Training loss: 0.7014249594596528
Validation loss: 2.6572884418423617

Epoch: 6| Step: 1
Training loss: 0.8502626910722036
Validation loss: 2.718716749082953

Epoch: 6| Step: 2
Training loss: 0.5528588036983604
Validation loss: 2.713681842797912

Epoch: 6| Step: 3
Training loss: 0.6194008602205954
Validation loss: 2.7644228001555065

Epoch: 6| Step: 4
Training loss: 0.697117274127494
Validation loss: 2.665960357428514

Epoch: 6| Step: 5
Training loss: 0.7067934342333583
Validation loss: 2.771679990288723

Epoch: 6| Step: 6
Training loss: 0.8376250301805681
Validation loss: 2.717747923822294

Epoch: 6| Step: 7
Training loss: 0.8047782328293613
Validation loss: 2.7821981835427074

Epoch: 6| Step: 8
Training loss: 0.5794240172801531
Validation loss: 2.7809831727008154

Epoch: 6| Step: 9
Training loss: 1.083266781939085
Validation loss: 2.7080834248979615

Epoch: 6| Step: 10
Training loss: 0.8730059449844427
Validation loss: 2.7311306116240655

Epoch: 6| Step: 11
Training loss: 0.5700570671057703
Validation loss: 2.7898302348363333

Epoch: 6| Step: 12
Training loss: 1.5034750580363245
Validation loss: 2.7398974790907666

Epoch: 6| Step: 13
Training loss: 1.0113982646691142
Validation loss: 2.6376847746307956

Epoch: 136| Step: 0
Training loss: 0.5715287186790108
Validation loss: 2.7287432194065038

Epoch: 6| Step: 1
Training loss: 0.6883366219355033
Validation loss: 2.691657657627898

Epoch: 6| Step: 2
Training loss: 0.5160760929275897
Validation loss: 2.7066962625227506

Epoch: 6| Step: 3
Training loss: 1.2036632968500112
Validation loss: 2.75101634953636

Epoch: 6| Step: 4
Training loss: 0.595443268678425
Validation loss: 2.732120507294618

Epoch: 6| Step: 5
Training loss: 0.8231280735337929
Validation loss: 2.6893946304922807

Epoch: 6| Step: 6
Training loss: 0.8540127002924149
Validation loss: 2.8045730779998066

Epoch: 6| Step: 7
Training loss: 0.8064792647158738
Validation loss: 2.7790951900260326

Epoch: 6| Step: 8
Training loss: 0.7791453431691455
Validation loss: 2.655445784951792

Epoch: 6| Step: 9
Training loss: 0.6888196590803689
Validation loss: 2.6923474796205795

Epoch: 6| Step: 10
Training loss: 0.7397310664598875
Validation loss: 2.698024840868098

Epoch: 6| Step: 11
Training loss: 1.6014297802525441
Validation loss: 2.6799201975513247

Epoch: 6| Step: 12
Training loss: 1.033248352330055
Validation loss: 2.672674762089681

Epoch: 6| Step: 13
Training loss: 0.7397113653409602
Validation loss: 2.6622976533654445

Epoch: 137| Step: 0
Training loss: 0.8145693323309393
Validation loss: 2.676485541625973

Epoch: 6| Step: 1
Training loss: 0.8380290097220452
Validation loss: 2.6222198841476074

Epoch: 6| Step: 2
Training loss: 0.6861087420221458
Validation loss: 2.71521879025317

Epoch: 6| Step: 3
Training loss: 0.7058128269809245
Validation loss: 2.7087718510798946

Epoch: 6| Step: 4
Training loss: 0.5376721017901398
Validation loss: 2.7605492374087444

Epoch: 6| Step: 5
Training loss: 0.6193010381118597
Validation loss: 2.7169660656789185

Epoch: 6| Step: 6
Training loss: 0.9409968328757099
Validation loss: 2.775109223344149

Epoch: 6| Step: 7
Training loss: 0.6450515727561026
Validation loss: 2.820521550342859

Epoch: 6| Step: 8
Training loss: 0.6487620587045924
Validation loss: 2.7538262971134295

Epoch: 6| Step: 9
Training loss: 0.4931558740521468
Validation loss: 2.76049564656446

Epoch: 6| Step: 10
Training loss: 0.6547183600825083
Validation loss: 2.6627031514446395

Epoch: 6| Step: 11
Training loss: 1.2027967921852034
Validation loss: 2.756658498143829

Epoch: 6| Step: 12
Training loss: 1.6005729037039866
Validation loss: 2.7609154352595624

Epoch: 6| Step: 13
Training loss: 0.8602131657562059
Validation loss: 2.7931554629642927

Epoch: 138| Step: 0
Training loss: 0.7752819994116692
Validation loss: 2.716850304003931

Epoch: 6| Step: 1
Training loss: 0.727123618080173
Validation loss: 2.7045470449735833

Epoch: 6| Step: 2
Training loss: 0.5348502349237484
Validation loss: 2.7477885660116637

Epoch: 6| Step: 3
Training loss: 1.0837114970089547
Validation loss: 2.714530593777427

Epoch: 6| Step: 4
Training loss: 0.8261925444486121
Validation loss: 2.6679939131064425

Epoch: 6| Step: 5
Training loss: 0.8101544268890144
Validation loss: 2.7132601649926595

Epoch: 6| Step: 6
Training loss: 0.6955308892680651
Validation loss: 2.7249014384559147

Epoch: 6| Step: 7
Training loss: 0.8130333690340777
Validation loss: 2.743029328447552

Epoch: 6| Step: 8
Training loss: 1.5641285610824553
Validation loss: 2.7644840049195833

Epoch: 6| Step: 9
Training loss: 0.6858299953183241
Validation loss: 2.866900035504064

Epoch: 6| Step: 10
Training loss: 0.908153015723228
Validation loss: 2.818982473797291

Epoch: 6| Step: 11
Training loss: 0.6445710603383572
Validation loss: 2.806892569535147

Epoch: 6| Step: 12
Training loss: 0.9132511417852741
Validation loss: 2.7222473187706204

Epoch: 6| Step: 13
Training loss: 0.7323880607428737
Validation loss: 2.7392966455255814

Epoch: 139| Step: 0
Training loss: 0.6143903483184054
Validation loss: 2.7250442139657918

Epoch: 6| Step: 1
Training loss: 0.6488108192262596
Validation loss: 2.680197071378442

Epoch: 6| Step: 2
Training loss: 0.981072046459348
Validation loss: 2.7163956339228865

Epoch: 6| Step: 3
Training loss: 1.686411753956262
Validation loss: 2.7796377802621612

Epoch: 6| Step: 4
Training loss: 0.7769304643321164
Validation loss: 2.7328576373761515

Epoch: 6| Step: 5
Training loss: 0.6022878212697705
Validation loss: 2.7642658291835254

Epoch: 6| Step: 6
Training loss: 1.230430771983355
Validation loss: 2.8119196681589678

Epoch: 6| Step: 7
Training loss: 0.5500453605153126
Validation loss: 2.7894077176423155

Epoch: 6| Step: 8
Training loss: 0.7258653885573071
Validation loss: 2.850988816336028

Epoch: 6| Step: 9
Training loss: 0.49019926636958855
Validation loss: 2.8440383653141

Epoch: 6| Step: 10
Training loss: 0.6354825944520324
Validation loss: 2.7729403627808047

Epoch: 6| Step: 11
Training loss: 0.37394725531672396
Validation loss: 2.7055928131982983

Epoch: 6| Step: 12
Training loss: 0.7053555394580407
Validation loss: 2.7604525197897667

Epoch: 6| Step: 13
Training loss: 0.6768885454564313
Validation loss: 2.749954887944894

Epoch: 140| Step: 0
Training loss: 0.7216731214418189
Validation loss: 2.7199401735056137

Epoch: 6| Step: 1
Training loss: 0.6948234895875258
Validation loss: 2.8246671075398173

Epoch: 6| Step: 2
Training loss: 0.4253132724404591
Validation loss: 2.7914128449094564

Epoch: 6| Step: 3
Training loss: 1.0434040775527236
Validation loss: 2.784402239630935

Epoch: 6| Step: 4
Training loss: 0.8752615401534989
Validation loss: 2.754312601613998

Epoch: 6| Step: 5
Training loss: 0.6124765741967764
Validation loss: 2.808326931350912

Epoch: 6| Step: 6
Training loss: 0.6382363610609013
Validation loss: 2.804204405086184

Epoch: 6| Step: 7
Training loss: 0.6368951845573695
Validation loss: 2.7341245845388062

Epoch: 6| Step: 8
Training loss: 0.8027852731425931
Validation loss: 2.7006392469841796

Epoch: 6| Step: 9
Training loss: 0.6753987900354574
Validation loss: 2.688518442090323

Epoch: 6| Step: 10
Training loss: 0.5971984356448335
Validation loss: 2.6973071103193935

Epoch: 6| Step: 11
Training loss: 0.5074194927908501
Validation loss: 2.8243385525202025

Epoch: 6| Step: 12
Training loss: 1.552377182284209
Validation loss: 2.775080764442922

Epoch: 6| Step: 13
Training loss: 1.1861859128018737
Validation loss: 2.839992639975346

Epoch: 141| Step: 0
Training loss: 1.586436150993348
Validation loss: 2.95023635251491

Epoch: 6| Step: 1
Training loss: 1.066864809368608
Validation loss: 2.865066630890731

Epoch: 6| Step: 2
Training loss: 0.6529173927165143
Validation loss: 2.7464110768556034

Epoch: 6| Step: 3
Training loss: 0.6104229206333349
Validation loss: 2.668466114844253

Epoch: 6| Step: 4
Training loss: 1.0990829698415139
Validation loss: 2.732658254211995

Epoch: 6| Step: 5
Training loss: 0.8869833194428626
Validation loss: 2.646619399639175

Epoch: 6| Step: 6
Training loss: 0.9479001466478334
Validation loss: 2.6560244520581366

Epoch: 6| Step: 7
Training loss: 1.0016482597686711
Validation loss: 2.6667334851198543

Epoch: 6| Step: 8
Training loss: 0.7549496876455806
Validation loss: 2.7189148454640066

Epoch: 6| Step: 9
Training loss: 0.7104558046435507
Validation loss: 2.8342913849766758

Epoch: 6| Step: 10
Training loss: 0.9460854010997164
Validation loss: 2.834227131130636

Epoch: 6| Step: 11
Training loss: 1.0847656733533817
Validation loss: 2.9764969652492472

Epoch: 6| Step: 12
Training loss: 0.86949184907687
Validation loss: 2.8943911101084354

Epoch: 6| Step: 13
Training loss: 0.7216094399668942
Validation loss: 2.8073600001089623

Epoch: 142| Step: 0
Training loss: 0.5194647610216383
Validation loss: 2.856302093654067

Epoch: 6| Step: 1
Training loss: 0.6755273595615764
Validation loss: 2.684658159650623

Epoch: 6| Step: 2
Training loss: 0.7340695983881297
Validation loss: 2.662053384469619

Epoch: 6| Step: 3
Training loss: 0.7751764342762247
Validation loss: 2.6919299586424863

Epoch: 6| Step: 4
Training loss: 0.8403115322664987
Validation loss: 2.6385299828942474

Epoch: 6| Step: 5
Training loss: 1.1902634439652588
Validation loss: 2.703324635801737

Epoch: 6| Step: 6
Training loss: 1.5137848842642823
Validation loss: 2.752278280079564

Epoch: 6| Step: 7
Training loss: 1.1368408137587411
Validation loss: 2.8083701011522284

Epoch: 6| Step: 8
Training loss: 0.6972503660439741
Validation loss: 2.854763001193621

Epoch: 6| Step: 9
Training loss: 0.7996957259893599
Validation loss: 2.8129623598178983

Epoch: 6| Step: 10
Training loss: 0.8022487684450239
Validation loss: 2.7989626575053728

Epoch: 6| Step: 11
Training loss: 0.8342473064535736
Validation loss: 2.7099943398373134

Epoch: 6| Step: 12
Training loss: 0.5795966311075831
Validation loss: 2.7192528942845966

Epoch: 6| Step: 13
Training loss: 0.8420748860047018
Validation loss: 2.6718948913785603

Epoch: 143| Step: 0
Training loss: 0.9692991607533298
Validation loss: 2.7431614406016824

Epoch: 6| Step: 1
Training loss: 1.0478680583583322
Validation loss: 2.6644449863701953

Epoch: 6| Step: 2
Training loss: 0.6262727890512856
Validation loss: 2.7166282442414307

Epoch: 6| Step: 3
Training loss: 0.8345637932970718
Validation loss: 2.6865644083211904

Epoch: 6| Step: 4
Training loss: 0.6171406595346136
Validation loss: 2.7812783171965956

Epoch: 6| Step: 5
Training loss: 1.5733417500793414
Validation loss: 2.804463426286762

Epoch: 6| Step: 6
Training loss: 0.906040759430799
Validation loss: 2.8437257004143315

Epoch: 6| Step: 7
Training loss: 0.8711809875871028
Validation loss: 2.8662781343051127

Epoch: 6| Step: 8
Training loss: 0.793011856786593
Validation loss: 2.7898922352960565

Epoch: 6| Step: 9
Training loss: 0.7308964012957189
Validation loss: 2.708826259847506

Epoch: 6| Step: 10
Training loss: 0.649043202450818
Validation loss: 2.6359178772629157

Epoch: 6| Step: 11
Training loss: 0.9025040521292977
Validation loss: 2.7229355787823426

Epoch: 6| Step: 12
Training loss: 0.808213185855716
Validation loss: 2.6258091512051003

Epoch: 6| Step: 13
Training loss: 0.859883487427175
Validation loss: 2.6836416951893507

Epoch: 144| Step: 0
Training loss: 0.8712606227451559
Validation loss: 2.6636219573994944

Epoch: 6| Step: 1
Training loss: 0.5075067333188176
Validation loss: 2.732478154157057

Epoch: 6| Step: 2
Training loss: 1.5004761258100632
Validation loss: 2.7882054541024597

Epoch: 6| Step: 3
Training loss: 0.8626389681773191
Validation loss: 2.742021561082228

Epoch: 6| Step: 4
Training loss: 0.9174094586302458
Validation loss: 2.8482878673072785

Epoch: 6| Step: 5
Training loss: 0.9557932417315139
Validation loss: 2.754257114866232

Epoch: 6| Step: 6
Training loss: 0.5994060059643335
Validation loss: 2.697596267076046

Epoch: 6| Step: 7
Training loss: 0.9785957227501558
Validation loss: 2.686863934852832

Epoch: 6| Step: 8
Training loss: 0.7380891580301944
Validation loss: 2.7012169264840336

Epoch: 6| Step: 9
Training loss: 0.8112240088579772
Validation loss: 2.7785363692673872

Epoch: 6| Step: 10
Training loss: 0.6572022341438322
Validation loss: 2.6903479663509375

Epoch: 6| Step: 11
Training loss: 0.36918272555421794
Validation loss: 2.752880913793025

Epoch: 6| Step: 12
Training loss: 0.8081783019835961
Validation loss: 2.7805969385943454

Epoch: 6| Step: 13
Training loss: 0.6821102502957291
Validation loss: 2.750135071645115

Epoch: 145| Step: 0
Training loss: 0.5203266508452054
Validation loss: 2.7338703670786

Epoch: 6| Step: 1
Training loss: 0.4237800254424331
Validation loss: 2.753034362571124

Epoch: 6| Step: 2
Training loss: 0.3370841329590249
Validation loss: 2.700110744924864

Epoch: 6| Step: 3
Training loss: 0.45854787970803396
Validation loss: 2.6666041953001374

Epoch: 6| Step: 4
Training loss: 0.6795434031712162
Validation loss: 2.761548041967417

Epoch: 6| Step: 5
Training loss: 0.6130748814621638
Validation loss: 2.7555766493449685

Epoch: 6| Step: 6
Training loss: 0.6163186101654089
Validation loss: 2.685658922112144

Epoch: 6| Step: 7
Training loss: 0.3827466713494611
Validation loss: 2.7213509348191534

Epoch: 6| Step: 8
Training loss: 1.516489470614169
Validation loss: 2.8051510766880687

Epoch: 6| Step: 9
Training loss: 0.5486557442044132
Validation loss: 2.737954113366072

Epoch: 6| Step: 10
Training loss: 0.9275533077827315
Validation loss: 2.716171284035481

Epoch: 6| Step: 11
Training loss: 0.9762735168125358
Validation loss: 2.7104944605491306

Epoch: 6| Step: 12
Training loss: 0.8647114226048132
Validation loss: 2.77636586360428

Epoch: 6| Step: 13
Training loss: 0.7576548618863277
Validation loss: 2.7327424616387606

Epoch: 146| Step: 0
Training loss: 0.80543771974453
Validation loss: 2.7591310686330357

Epoch: 6| Step: 1
Training loss: 0.5513721029378037
Validation loss: 2.6869887080019774

Epoch: 6| Step: 2
Training loss: 0.9132466383902696
Validation loss: 2.7706627231550867

Epoch: 6| Step: 3
Training loss: 0.7630885791757248
Validation loss: 2.789898865403801

Epoch: 6| Step: 4
Training loss: 0.8261443870787338
Validation loss: 2.7059728361572204

Epoch: 6| Step: 5
Training loss: 0.7188009161122322
Validation loss: 2.7992370831997078

Epoch: 6| Step: 6
Training loss: 0.4211914034197122
Validation loss: 2.7193843788377436

Epoch: 6| Step: 7
Training loss: 0.5559052009484701
Validation loss: 2.746978819718354

Epoch: 6| Step: 8
Training loss: 1.4926901564874526
Validation loss: 2.8336626357028303

Epoch: 6| Step: 9
Training loss: 0.6742626171494482
Validation loss: 2.7521030591844475

Epoch: 6| Step: 10
Training loss: 0.5840495656858595
Validation loss: 2.6401652701501224

Epoch: 6| Step: 11
Training loss: 0.9674746208903651
Validation loss: 2.7668823573667614

Epoch: 6| Step: 12
Training loss: 0.5948486703880106
Validation loss: 2.7816693850580747

Epoch: 6| Step: 13
Training loss: 0.6368095239630955
Validation loss: 2.7230828934715534

Epoch: 147| Step: 0
Training loss: 0.5353026363891523
Validation loss: 2.7296347083300363

Epoch: 6| Step: 1
Training loss: 0.8330681657114087
Validation loss: 2.7644792327790775

Epoch: 6| Step: 2
Training loss: 1.5096991402223283
Validation loss: 2.688701523693048

Epoch: 6| Step: 3
Training loss: 0.6313015359671024
Validation loss: 2.784491104234151

Epoch: 6| Step: 4
Training loss: 0.636964551602556
Validation loss: 2.763168522767332

Epoch: 6| Step: 5
Training loss: 1.0443962700422544
Validation loss: 2.8217189026076017

Epoch: 6| Step: 6
Training loss: 0.632311469579183
Validation loss: 2.8110019508933153

Epoch: 6| Step: 7
Training loss: 0.7988105529494002
Validation loss: 2.7252595077977286

Epoch: 6| Step: 8
Training loss: 0.4930504394170298
Validation loss: 2.7507347656991192

Epoch: 6| Step: 9
Training loss: 0.3337675472711519
Validation loss: 2.679114589115807

Epoch: 6| Step: 10
Training loss: 0.6204643179034652
Validation loss: 2.8113758524983496

Epoch: 6| Step: 11
Training loss: 0.4483002269792801
Validation loss: 2.7676332011067375

Epoch: 6| Step: 12
Training loss: 0.6259121913811714
Validation loss: 2.711853165859158

Epoch: 6| Step: 13
Training loss: 0.5253228920312047
Validation loss: 2.819660255762462

Epoch: 148| Step: 0
Training loss: 1.090241171727851
Validation loss: 2.7224882886790587

Epoch: 6| Step: 1
Training loss: 0.5294737573087546
Validation loss: 2.7381495118932424

Epoch: 6| Step: 2
Training loss: 0.4652915848949724
Validation loss: 2.8473254911308334

Epoch: 6| Step: 3
Training loss: 0.5876494765354079
Validation loss: 2.7634543397298255

Epoch: 6| Step: 4
Training loss: 0.60802128400378
Validation loss: 2.7546966789151823

Epoch: 6| Step: 5
Training loss: 0.6879504635382115
Validation loss: 2.757830928636454

Epoch: 6| Step: 6
Training loss: 0.8335079288368704
Validation loss: 2.776482414102439

Epoch: 6| Step: 7
Training loss: 0.635915378120179
Validation loss: 2.733550479644934

Epoch: 6| Step: 8
Training loss: 0.48521048262685046
Validation loss: 2.7696328586148313

Epoch: 6| Step: 9
Training loss: 0.8739493056245166
Validation loss: 2.738653225740708

Epoch: 6| Step: 10
Training loss: 0.712664257323234
Validation loss: 2.7029624257968465

Epoch: 6| Step: 11
Training loss: 1.442008040184854
Validation loss: 2.7880714001919604

Epoch: 6| Step: 12
Training loss: 0.6392340096512767
Validation loss: 2.782238859482192

Epoch: 6| Step: 13
Training loss: 0.6166685312689695
Validation loss: 2.764874329496208

Epoch: 149| Step: 0
Training loss: 1.3730376285333885
Validation loss: 2.792891153177967

Epoch: 6| Step: 1
Training loss: 0.706505363850301
Validation loss: 2.819761368572664

Epoch: 6| Step: 2
Training loss: 0.741242419392258
Validation loss: 2.717655356141692

Epoch: 6| Step: 3
Training loss: 0.551984352259752
Validation loss: 2.7197876334967064

Epoch: 6| Step: 4
Training loss: 0.5983696463341219
Validation loss: 2.7578550773121973

Epoch: 6| Step: 5
Training loss: 0.7124693161230022
Validation loss: 2.7106944624749607

Epoch: 6| Step: 6
Training loss: 0.8274382136578323
Validation loss: 2.7052736360886174

Epoch: 6| Step: 7
Training loss: 1.0740712012481515
Validation loss: 2.756188033972331

Epoch: 6| Step: 8
Training loss: 0.5071524218112091
Validation loss: 2.83652299033749

Epoch: 6| Step: 9
Training loss: 0.9169153540844357
Validation loss: 2.8272337097414666

Epoch: 6| Step: 10
Training loss: 0.6433621061970052
Validation loss: 2.824477159735175

Epoch: 6| Step: 11
Training loss: 0.5378501084525735
Validation loss: 2.863402040994662

Epoch: 6| Step: 12
Training loss: 0.7241318355285746
Validation loss: 2.8492185391299705

Epoch: 6| Step: 13
Training loss: 0.6448642679568503
Validation loss: 2.7886679376496986

Epoch: 150| Step: 0
Training loss: 0.5768816439410289
Validation loss: 2.7973924864926105

Epoch: 6| Step: 1
Training loss: 0.605795446056857
Validation loss: 2.771367936917708

Epoch: 6| Step: 2
Training loss: 0.4879114505424938
Validation loss: 2.727474479124658

Epoch: 6| Step: 3
Training loss: 0.3669373898201428
Validation loss: 2.8058209267517498

Epoch: 6| Step: 4
Training loss: 0.8590568647203282
Validation loss: 2.7615655247736948

Epoch: 6| Step: 5
Training loss: 0.8577729985604152
Validation loss: 2.730964481028265

Epoch: 6| Step: 6
Training loss: 0.635874275982495
Validation loss: 2.7319126049936595

Epoch: 6| Step: 7
Training loss: 1.0883763870750904
Validation loss: 2.8685520053928126

Epoch: 6| Step: 8
Training loss: 0.5178070138054742
Validation loss: 2.8086522944701615

Epoch: 6| Step: 9
Training loss: 0.5863326711052731
Validation loss: 2.893945357537302

Epoch: 6| Step: 10
Training loss: 0.5649703668739708
Validation loss: 2.819814594026684

Epoch: 6| Step: 11
Training loss: 1.4715145957603983
Validation loss: 2.7864459218732174

Epoch: 6| Step: 12
Training loss: 0.6488678894167775
Validation loss: 2.7110949643710405

Epoch: 6| Step: 13
Training loss: 0.6703721693463929
Validation loss: 2.7873146713983656

Epoch: 151| Step: 0
Training loss: 0.6707775334633571
Validation loss: 2.76466140196058

Epoch: 6| Step: 1
Training loss: 1.4727277257760205
Validation loss: 2.7045040692076463

Epoch: 6| Step: 2
Training loss: 0.5282763112019816
Validation loss: 2.739107813499312

Epoch: 6| Step: 3
Training loss: 0.7034053667372989
Validation loss: 2.7771992706190183

Epoch: 6| Step: 4
Training loss: 0.7204780537309224
Validation loss: 2.7129260418573238

Epoch: 6| Step: 5
Training loss: 0.5535074226670817
Validation loss: 2.767314646187349

Epoch: 6| Step: 6
Training loss: 0.47583684236309337
Validation loss: 2.7859421486636586

Epoch: 6| Step: 7
Training loss: 0.5465563799611965
Validation loss: 2.866107193186516

Epoch: 6| Step: 8
Training loss: 0.7367504740060784
Validation loss: 2.84392725912569

Epoch: 6| Step: 9
Training loss: 0.5717787771101136
Validation loss: 2.8382175552161075

Epoch: 6| Step: 10
Training loss: 0.3574084295026428
Validation loss: 2.8630200275995765

Epoch: 6| Step: 11
Training loss: 0.4495545169031897
Validation loss: 2.7332582354890085

Epoch: 6| Step: 12
Training loss: 1.13162811451463
Validation loss: 2.751438689312065

Epoch: 6| Step: 13
Training loss: 0.648541109011523
Validation loss: 2.6953083572724426

Epoch: 152| Step: 0
Training loss: 0.7779739355805881
Validation loss: 2.7881347081895362

Epoch: 6| Step: 1
Training loss: 0.4811746327723304
Validation loss: 2.727486003137019

Epoch: 6| Step: 2
Training loss: 0.6045857543511249
Validation loss: 2.771130858965925

Epoch: 6| Step: 3
Training loss: 0.6095252707627427
Validation loss: 2.8121420102637416

Epoch: 6| Step: 4
Training loss: 0.8840658355142959
Validation loss: 2.8641595607917667

Epoch: 6| Step: 5
Training loss: 0.5868073428300454
Validation loss: 2.8652789756668438

Epoch: 6| Step: 6
Training loss: 0.6742561197367373
Validation loss: 2.8165878822850257

Epoch: 6| Step: 7
Training loss: 0.6558962277117389
Validation loss: 2.8868532885015608

Epoch: 6| Step: 8
Training loss: 0.6129203268893154
Validation loss: 2.793422180217984

Epoch: 6| Step: 9
Training loss: 0.447825917950023
Validation loss: 2.7554818337929055

Epoch: 6| Step: 10
Training loss: 1.4352096888228958
Validation loss: 2.7431833283058036

Epoch: 6| Step: 11
Training loss: 0.6144902164155294
Validation loss: 2.7808025300176853

Epoch: 6| Step: 12
Training loss: 0.5223771357842951
Validation loss: 2.7517173924228944

Epoch: 6| Step: 13
Training loss: 0.6384270575029275
Validation loss: 2.821546430810646

Epoch: 153| Step: 0
Training loss: 1.0656400170484677
Validation loss: 2.8102893053006306

Epoch: 6| Step: 1
Training loss: 0.7656861884131037
Validation loss: 2.8286986779043843

Epoch: 6| Step: 2
Training loss: 0.45253379663952464
Validation loss: 2.8107864811469527

Epoch: 6| Step: 3
Training loss: 0.6602056134971319
Validation loss: 2.902363328281529

Epoch: 6| Step: 4
Training loss: 0.774921150195643
Validation loss: 2.756242977257372

Epoch: 6| Step: 5
Training loss: 0.5406433366962345
Validation loss: 2.7971051084171954

Epoch: 6| Step: 6
Training loss: 0.3601848764689725
Validation loss: 2.7732704792862743

Epoch: 6| Step: 7
Training loss: 0.7218406404847486
Validation loss: 2.7462354816092938

Epoch: 6| Step: 8
Training loss: 1.3608680505912376
Validation loss: 2.685249480455774

Epoch: 6| Step: 9
Training loss: 0.49985081712091817
Validation loss: 2.7828575945967864

Epoch: 6| Step: 10
Training loss: 0.38504817676699526
Validation loss: 2.7328538787192644

Epoch: 6| Step: 11
Training loss: 0.6532633347462363
Validation loss: 2.8003615202712493

Epoch: 6| Step: 12
Training loss: 0.6252244546301772
Validation loss: 2.8093074622149623

Epoch: 6| Step: 13
Training loss: 0.5342211384704519
Validation loss: 2.792469156038569

Epoch: 154| Step: 0
Training loss: 0.44888364483341375
Validation loss: 2.879506311289486

Epoch: 6| Step: 1
Training loss: 0.41758466167704317
Validation loss: 2.839273233663314

Epoch: 6| Step: 2
Training loss: 0.49111902730799933
Validation loss: 2.723662108050288

Epoch: 6| Step: 3
Training loss: 0.670114895342223
Validation loss: 2.779164664760099

Epoch: 6| Step: 4
Training loss: 0.45456247216576917
Validation loss: 2.7869685243705047

Epoch: 6| Step: 5
Training loss: 0.31847840406750305
Validation loss: 2.78527790390631

Epoch: 6| Step: 6
Training loss: 0.6041948268071645
Validation loss: 2.707043301407345

Epoch: 6| Step: 7
Training loss: 0.9815663429143735
Validation loss: 2.781922991191613

Epoch: 6| Step: 8
Training loss: 0.681690247049355
Validation loss: 2.7642146679453115

Epoch: 6| Step: 9
Training loss: 1.445598677062805
Validation loss: 2.786887081827554

Epoch: 6| Step: 10
Training loss: 0.56425211142
Validation loss: 2.8080132901066492

Epoch: 6| Step: 11
Training loss: 0.5815403039008002
Validation loss: 2.8355579945483362

Epoch: 6| Step: 12
Training loss: 0.5970260189399285
Validation loss: 2.846840014558531

Epoch: 6| Step: 13
Training loss: 0.4974634680442115
Validation loss: 2.8017861918956353

Epoch: 155| Step: 0
Training loss: 0.4745913843583367
Validation loss: 2.8320964516335936

Epoch: 6| Step: 1
Training loss: 0.5671734054117272
Validation loss: 2.7480437805837976

Epoch: 6| Step: 2
Training loss: 0.48822668152112836
Validation loss: 2.8356416406073834

Epoch: 6| Step: 3
Training loss: 0.5948774274827421
Validation loss: 2.8030582041527285

Epoch: 6| Step: 4
Training loss: 0.4625328870627978
Validation loss: 2.804746182676987

Epoch: 6| Step: 5
Training loss: 0.5095529807006479
Validation loss: 2.8002796442168822

Epoch: 6| Step: 6
Training loss: 0.5843744920534588
Validation loss: 2.7801439893605795

Epoch: 6| Step: 7
Training loss: 1.5631315862188189
Validation loss: 2.7936289898340085

Epoch: 6| Step: 8
Training loss: 0.6680470024807376
Validation loss: 2.7587333489027728

Epoch: 6| Step: 9
Training loss: 0.4872069786440297
Validation loss: 2.761300508086997

Epoch: 6| Step: 10
Training loss: 0.6186717812390792
Validation loss: 2.7560847041821463

Epoch: 6| Step: 11
Training loss: 0.657146386616866
Validation loss: 2.72255287357267

Epoch: 6| Step: 12
Training loss: 0.631857398492632
Validation loss: 2.747952103307987

Epoch: 6| Step: 13
Training loss: 0.9866839682881368
Validation loss: 2.737969744019844

Epoch: 156| Step: 0
Training loss: 0.8084147527006377
Validation loss: 2.7958009529417964

Epoch: 6| Step: 1
Training loss: 0.5199435612879728
Validation loss: 2.7938945809658193

Epoch: 6| Step: 2
Training loss: 0.9026357995573054
Validation loss: 2.8347734456530254

Epoch: 6| Step: 3
Training loss: 0.4862919529710901
Validation loss: 2.818554873877645

Epoch: 6| Step: 4
Training loss: 0.40886300881253934
Validation loss: 2.721311889514732

Epoch: 6| Step: 5
Training loss: 0.46617870818702023
Validation loss: 2.8221391308518244

Epoch: 6| Step: 6
Training loss: 0.48147304369931454
Validation loss: 2.809266626561231

Epoch: 6| Step: 7
Training loss: 0.711549307022792
Validation loss: 2.8049145308249503

Epoch: 6| Step: 8
Training loss: 1.4441940516483678
Validation loss: 2.8004726947555936

Epoch: 6| Step: 9
Training loss: 0.7358891319368129
Validation loss: 2.7901014855771726

Epoch: 6| Step: 10
Training loss: 0.5804993099008117
Validation loss: 2.8310171411907814

Epoch: 6| Step: 11
Training loss: 0.6628396836839013
Validation loss: 2.7847533289016786

Epoch: 6| Step: 12
Training loss: 0.37068197594017305
Validation loss: 2.7610076463614877

Epoch: 6| Step: 13
Training loss: 0.6143276253768155
Validation loss: 2.7715166917583063

Epoch: 157| Step: 0
Training loss: 0.9280028908289903
Validation loss: 2.705436321096871

Epoch: 6| Step: 1
Training loss: 0.7080775154266539
Validation loss: 2.743683293834412

Epoch: 6| Step: 2
Training loss: 0.542940070403417
Validation loss: 2.7531089620595766

Epoch: 6| Step: 3
Training loss: 0.4602718072166471
Validation loss: 2.680277145061835

Epoch: 6| Step: 4
Training loss: 0.5229675688671842
Validation loss: 2.7984907004991517

Epoch: 6| Step: 5
Training loss: 1.3375931680618922
Validation loss: 2.798622011952801

Epoch: 6| Step: 6
Training loss: 0.5643816840028426
Validation loss: 2.8475171802193375

Epoch: 6| Step: 7
Training loss: 0.4352142706223016
Validation loss: 2.9004621263589474

Epoch: 6| Step: 8
Training loss: 0.4565037185197863
Validation loss: 2.7628730976518323

Epoch: 6| Step: 9
Training loss: 0.5162706667478788
Validation loss: 2.7648825645686497

Epoch: 6| Step: 10
Training loss: 0.6750176586384421
Validation loss: 2.809115499775272

Epoch: 6| Step: 11
Training loss: 0.597648096963959
Validation loss: 2.8076903013577947

Epoch: 6| Step: 12
Training loss: 0.7636886946052782
Validation loss: 2.7951788420944736

Epoch: 6| Step: 13
Training loss: 0.5785469886371077
Validation loss: 2.757728611405965

Epoch: 158| Step: 0
Training loss: 0.8492936874216137
Validation loss: 2.799299031457722

Epoch: 6| Step: 1
Training loss: 0.45626476603612287
Validation loss: 2.830241884592664

Epoch: 6| Step: 2
Training loss: 1.377863979057084
Validation loss: 2.7786969243041693

Epoch: 6| Step: 3
Training loss: 0.4994143393899555
Validation loss: 2.8153996390455913

Epoch: 6| Step: 4
Training loss: 0.4577496091589934
Validation loss: 2.7471220678577164

Epoch: 6| Step: 5
Training loss: 0.5426973721305804
Validation loss: 2.7853841166756874

Epoch: 6| Step: 6
Training loss: 0.6136389982764202
Validation loss: 2.721738845917735

Epoch: 6| Step: 7
Training loss: 0.47981892813773797
Validation loss: 2.8219178791808623

Epoch: 6| Step: 8
Training loss: 0.48263316604673184
Validation loss: 2.829362110434125

Epoch: 6| Step: 9
Training loss: 0.2263506029980504
Validation loss: 2.8166420988181433

Epoch: 6| Step: 10
Training loss: 0.5371372839872621
Validation loss: 2.753744711320335

Epoch: 6| Step: 11
Training loss: 0.48787953445864607
Validation loss: 2.7366714570734967

Epoch: 6| Step: 12
Training loss: 0.7131164193201327
Validation loss: 2.8149183119625794

Epoch: 6| Step: 13
Training loss: 0.6128679085308981
Validation loss: 2.7827648652112376

Epoch: 159| Step: 0
Training loss: 0.7358269642877908
Validation loss: 2.779483105337254

Epoch: 6| Step: 1
Training loss: 0.6368382347658423
Validation loss: 2.7602518908186666

Epoch: 6| Step: 2
Training loss: 0.2699750342791804
Validation loss: 2.7745594316438265

Epoch: 6| Step: 3
Training loss: 0.5700621381987896
Validation loss: 2.8073214008594363

Epoch: 6| Step: 4
Training loss: 0.6038410580918625
Validation loss: 2.820180620401724

Epoch: 6| Step: 5
Training loss: 0.928230811358672
Validation loss: 2.8037926708369545

Epoch: 6| Step: 6
Training loss: 0.2749460703898665
Validation loss: 2.7785900125852194

Epoch: 6| Step: 7
Training loss: 0.6420949957463221
Validation loss: 2.81687526175012

Epoch: 6| Step: 8
Training loss: 0.37152598455873737
Validation loss: 2.8136969385915718

Epoch: 6| Step: 9
Training loss: 1.576270345001455
Validation loss: 2.7810998511771214

Epoch: 6| Step: 10
Training loss: 0.5240002354373839
Validation loss: 2.7917595795689407

Epoch: 6| Step: 11
Training loss: 0.4310368245981989
Validation loss: 2.7588949123545046

Epoch: 6| Step: 12
Training loss: 0.5194267798914747
Validation loss: 2.7772198741987957

Epoch: 6| Step: 13
Training loss: 0.6482525297410523
Validation loss: 2.8419274438879767

Epoch: 160| Step: 0
Training loss: 0.5405109406474674
Validation loss: 2.80767072809004

Epoch: 6| Step: 1
Training loss: 0.48384403537070936
Validation loss: 2.8233117018377274

Epoch: 6| Step: 2
Training loss: 0.55836599548608
Validation loss: 2.770991612457371

Epoch: 6| Step: 3
Training loss: 0.6955297323627628
Validation loss: 2.797251201880648

Epoch: 6| Step: 4
Training loss: 0.5253852645430392
Validation loss: 2.8523696802110488

Epoch: 6| Step: 5
Training loss: 0.49372955231638294
Validation loss: 2.7753662709638056

Epoch: 6| Step: 6
Training loss: 0.5410702123542869
Validation loss: 2.7675493302122702

Epoch: 6| Step: 7
Training loss: 0.5294001855004666
Validation loss: 2.7355540612708453

Epoch: 6| Step: 8
Training loss: 1.3001107443809254
Validation loss: 2.7647733364820324

Epoch: 6| Step: 9
Training loss: 0.4908941623977859
Validation loss: 2.772231435240185

Epoch: 6| Step: 10
Training loss: 0.524378485866959
Validation loss: 2.715811240976549

Epoch: 6| Step: 11
Training loss: 0.5058207846985558
Validation loss: 2.7883304949660674

Epoch: 6| Step: 12
Training loss: 0.8631433920589177
Validation loss: 2.8561811971690116

Epoch: 6| Step: 13
Training loss: 0.5002296635556156
Validation loss: 2.8533517458431557

Epoch: 161| Step: 0
Training loss: 0.5981296085909574
Validation loss: 2.736310132421551

Epoch: 6| Step: 1
Training loss: 0.7143253885899262
Validation loss: 2.7938331529046474

Epoch: 6| Step: 2
Training loss: 0.6452404628567616
Validation loss: 2.7676585277076433

Epoch: 6| Step: 3
Training loss: 0.42917390820341084
Validation loss: 2.8199132353148344

Epoch: 6| Step: 4
Training loss: 1.3901516826803721
Validation loss: 2.735814367835309

Epoch: 6| Step: 5
Training loss: 0.4689709301695341
Validation loss: 2.7802894162164504

Epoch: 6| Step: 6
Training loss: 0.4989657434007503
Validation loss: 2.8871109850416246

Epoch: 6| Step: 7
Training loss: 0.5511119742391007
Validation loss: 2.7988763535739514

Epoch: 6| Step: 8
Training loss: 0.5037215729826089
Validation loss: 2.872215235345222

Epoch: 6| Step: 9
Training loss: 0.5812071015309389
Validation loss: 2.8895007034805213

Epoch: 6| Step: 10
Training loss: 0.975723638735068
Validation loss: 2.827763908475461

Epoch: 6| Step: 11
Training loss: 0.6670345890536165
Validation loss: 2.767986230725934

Epoch: 6| Step: 12
Training loss: 0.6549140183237937
Validation loss: 2.7899486654838936

Epoch: 6| Step: 13
Training loss: 0.40254232450641475
Validation loss: 2.854048779876944

Epoch: 162| Step: 0
Training loss: 0.6580634039576363
Validation loss: 2.8445929790456406

Epoch: 6| Step: 1
Training loss: 1.251142932987046
Validation loss: 2.801949272115886

Epoch: 6| Step: 2
Training loss: 0.5819667037913966
Validation loss: 2.7921121773204547

Epoch: 6| Step: 3
Training loss: 0.4729832235490333
Validation loss: 2.796395990707029

Epoch: 6| Step: 4
Training loss: 0.5792570886305795
Validation loss: 2.725756215383

Epoch: 6| Step: 5
Training loss: 0.5461412684732285
Validation loss: 2.7490123868260534

Epoch: 6| Step: 6
Training loss: 0.24215613438939115
Validation loss: 2.752939647103082

Epoch: 6| Step: 7
Training loss: 0.6367579255017086
Validation loss: 2.8399814325719657

Epoch: 6| Step: 8
Training loss: 0.4677806686447703
Validation loss: 2.7704924801624196

Epoch: 6| Step: 9
Training loss: 0.6701848928992618
Validation loss: 2.8212355831680993

Epoch: 6| Step: 10
Training loss: 0.27391699574571354
Validation loss: 2.8415320973308287

Epoch: 6| Step: 11
Training loss: 0.9609260868542245
Validation loss: 2.794520162863098

Epoch: 6| Step: 12
Training loss: 0.6672659852366697
Validation loss: 2.8283605740894493

Epoch: 6| Step: 13
Training loss: 0.5508515874441776
Validation loss: 2.8159287145295044

Epoch: 163| Step: 0
Training loss: 0.7969466532487539
Validation loss: 2.8561129419566234

Epoch: 6| Step: 1
Training loss: 0.4076372632437067
Validation loss: 2.7794951070870666

Epoch: 6| Step: 2
Training loss: 0.39499708566918446
Validation loss: 2.725596988390875

Epoch: 6| Step: 3
Training loss: 0.419905338405316
Validation loss: 2.770514037204043

Epoch: 6| Step: 4
Training loss: 0.45414618816344665
Validation loss: 2.7505694580017854

Epoch: 6| Step: 5
Training loss: 0.4052724079900327
Validation loss: 2.8063375848753873

Epoch: 6| Step: 6
Training loss: 0.9172058831473325
Validation loss: 2.8180153351026496

Epoch: 6| Step: 7
Training loss: 0.6458201381401851
Validation loss: 2.8726389630167306

Epoch: 6| Step: 8
Training loss: 0.628383466578173
Validation loss: 2.8326985031338543

Epoch: 6| Step: 9
Training loss: 0.49562168940416174
Validation loss: 2.8171696080327107

Epoch: 6| Step: 10
Training loss: 0.5996540065395202
Validation loss: 2.8139213114269417

Epoch: 6| Step: 11
Training loss: 0.4553236401411894
Validation loss: 2.7857811125633445

Epoch: 6| Step: 12
Training loss: 0.5880583463674777
Validation loss: 2.7925585323245308

Epoch: 6| Step: 13
Training loss: 1.4050983375535682
Validation loss: 2.8295845564890745

Epoch: 164| Step: 0
Training loss: 0.677444791902218
Validation loss: 2.711327296659329

Epoch: 6| Step: 1
Training loss: 0.5936950607982968
Validation loss: 2.7882091737714165

Epoch: 6| Step: 2
Training loss: 0.7621088838404603
Validation loss: 2.8402613105907992

Epoch: 6| Step: 3
Training loss: 0.5178338624625956
Validation loss: 2.9748907192044722

Epoch: 6| Step: 4
Training loss: 0.5775198991658167
Validation loss: 2.823695977290751

Epoch: 6| Step: 5
Training loss: 1.2942592484731568
Validation loss: 2.8593620202720116

Epoch: 6| Step: 6
Training loss: 0.554463569679263
Validation loss: 2.80637842775133

Epoch: 6| Step: 7
Training loss: 0.5380513202588293
Validation loss: 2.804294859765046

Epoch: 6| Step: 8
Training loss: 0.6377260162766532
Validation loss: 2.7888620484425406

Epoch: 6| Step: 9
Training loss: 0.4829992013573214
Validation loss: 2.7095022662234785

Epoch: 6| Step: 10
Training loss: 0.5189798627155059
Validation loss: 2.7702745481280777

Epoch: 6| Step: 11
Training loss: 0.45422451856773355
Validation loss: 2.797905389380055

Epoch: 6| Step: 12
Training loss: 0.43937229684728024
Validation loss: 2.7964358420098567

Epoch: 6| Step: 13
Training loss: 0.43598355012449325
Validation loss: 2.7846027410998073

Epoch: 165| Step: 0
Training loss: 0.5417643300068128
Validation loss: 2.8197078743585053

Epoch: 6| Step: 1
Training loss: 0.6298532405091885
Validation loss: 2.7850261584730784

Epoch: 6| Step: 2
Training loss: 0.44146785474983347
Validation loss: 2.789664922028677

Epoch: 6| Step: 3
Training loss: 0.3822956293751296
Validation loss: 2.7890699370469387

Epoch: 6| Step: 4
Training loss: 0.6589095855042285
Validation loss: 2.826060150757205

Epoch: 6| Step: 5
Training loss: 0.4538471124308185
Validation loss: 2.834873697022868

Epoch: 6| Step: 6
Training loss: 0.8918082090736145
Validation loss: 2.805179039289521

Epoch: 6| Step: 7
Training loss: 0.5798172797758236
Validation loss: 2.8422125793043995

Epoch: 6| Step: 8
Training loss: 0.5253022413823594
Validation loss: 2.8831297192499434

Epoch: 6| Step: 9
Training loss: 0.5664225608844892
Validation loss: 2.7813775394071456

Epoch: 6| Step: 10
Training loss: 0.659408552211067
Validation loss: 2.745251109826906

Epoch: 6| Step: 11
Training loss: 1.3531892721580265
Validation loss: 2.697806534059632

Epoch: 6| Step: 12
Training loss: 0.49662575018226235
Validation loss: 2.7804856410866248

Epoch: 6| Step: 13
Training loss: 0.39718836030184107
Validation loss: 2.9061479311284786

Epoch: 166| Step: 0
Training loss: 0.547893067010028
Validation loss: 2.7867369087696336

Epoch: 6| Step: 1
Training loss: 0.3977159249247427
Validation loss: 2.867922502458465

Epoch: 6| Step: 2
Training loss: 1.282383766038009
Validation loss: 2.894339654221077

Epoch: 6| Step: 3
Training loss: 0.9353950711811084
Validation loss: 2.842343775678764

Epoch: 6| Step: 4
Training loss: 0.42690943069451504
Validation loss: 2.8790863270644693

Epoch: 6| Step: 5
Training loss: 0.5419525131963406
Validation loss: 2.847145540605619

Epoch: 6| Step: 6
Training loss: 0.4080645129667866
Validation loss: 2.8075729587775355

Epoch: 6| Step: 7
Training loss: 0.5402176132415271
Validation loss: 2.784919789367415

Epoch: 6| Step: 8
Training loss: 0.5518208155487755
Validation loss: 2.7779647554940707

Epoch: 6| Step: 9
Training loss: 0.6057669612762827
Validation loss: 2.81405108031378

Epoch: 6| Step: 10
Training loss: 0.636085241903191
Validation loss: 2.7729493477202163

Epoch: 6| Step: 11
Training loss: 0.3991010787347119
Validation loss: 2.7835725095247037

Epoch: 6| Step: 12
Training loss: 0.577087812257134
Validation loss: 2.7545628263231126

Epoch: 6| Step: 13
Training loss: 0.3956595424138192
Validation loss: 2.842368995781285

Epoch: 167| Step: 0
Training loss: 0.49480685829800075
Validation loss: 2.837168038621471

Epoch: 6| Step: 1
Training loss: 0.670701865726593
Validation loss: 2.799574857747126

Epoch: 6| Step: 2
Training loss: 0.52320711560128
Validation loss: 2.7810466134788467

Epoch: 6| Step: 3
Training loss: 0.4714235514651174
Validation loss: 2.836930394522337

Epoch: 6| Step: 4
Training loss: 0.6004140716521363
Validation loss: 2.7600290614132272

Epoch: 6| Step: 5
Training loss: 0.5040488226229836
Validation loss: 2.7589708944617226

Epoch: 6| Step: 6
Training loss: 0.6416324973813763
Validation loss: 2.700529068456372

Epoch: 6| Step: 7
Training loss: 0.46377509558193813
Validation loss: 2.8347017031926973

Epoch: 6| Step: 8
Training loss: 0.5946969962952974
Validation loss: 2.7879898188335326

Epoch: 6| Step: 9
Training loss: 0.472906456289547
Validation loss: 2.9078852930511427

Epoch: 6| Step: 10
Training loss: 0.4862279367467166
Validation loss: 2.877255909186821

Epoch: 6| Step: 11
Training loss: 0.7361643480047471
Validation loss: 2.8782230361881105

Epoch: 6| Step: 12
Training loss: 0.6324423661190399
Validation loss: 2.851470318702148

Epoch: 6| Step: 13
Training loss: 1.4833151798351867
Validation loss: 2.823544820643357

Epoch: 168| Step: 0
Training loss: 0.5698578210907665
Validation loss: 2.8241979687050596

Epoch: 6| Step: 1
Training loss: 0.453051725579674
Validation loss: 2.8908245808203223

Epoch: 6| Step: 2
Training loss: 0.5318851320711437
Validation loss: 2.832749451519356

Epoch: 6| Step: 3
Training loss: 0.466353089771074
Validation loss: 2.8169571350550417

Epoch: 6| Step: 4
Training loss: 1.3062004408492613
Validation loss: 2.75958823002638

Epoch: 6| Step: 5
Training loss: 0.4631154765695617
Validation loss: 2.819908852896563

Epoch: 6| Step: 6
Training loss: 0.43386787478378014
Validation loss: 2.8171180957743944

Epoch: 6| Step: 7
Training loss: 0.4075155353510209
Validation loss: 2.755269911041278

Epoch: 6| Step: 8
Training loss: 0.4281098968737695
Validation loss: 2.8577186776248573

Epoch: 6| Step: 9
Training loss: 0.5583192377541167
Validation loss: 2.8651627295650117

Epoch: 6| Step: 10
Training loss: 0.4991255803094094
Validation loss: 2.7626011296284076

Epoch: 6| Step: 11
Training loss: 0.41375993074214257
Validation loss: 2.843877265513783

Epoch: 6| Step: 12
Training loss: 0.4530138339778705
Validation loss: 2.855802628688162

Epoch: 6| Step: 13
Training loss: 0.9331185955280068
Validation loss: 2.7883912675892364

Epoch: 169| Step: 0
Training loss: 0.6795032075984494
Validation loss: 2.8139319553910185

Epoch: 6| Step: 1
Training loss: 0.39735523664797473
Validation loss: 2.783883094934667

Epoch: 6| Step: 2
Training loss: 0.6026644336717445
Validation loss: 2.7862887654746027

Epoch: 6| Step: 3
Training loss: 0.5321033300118861
Validation loss: 2.789759159790867

Epoch: 6| Step: 4
Training loss: 0.5183960120470837
Validation loss: 2.8282254448857147

Epoch: 6| Step: 5
Training loss: 0.5871501073457597
Validation loss: 2.8400492080043094

Epoch: 6| Step: 6
Training loss: 0.44677637652516544
Validation loss: 2.8180965689660873

Epoch: 6| Step: 7
Training loss: 0.37786811504470613
Validation loss: 2.7895374481400688

Epoch: 6| Step: 8
Training loss: 0.35543152331255345
Validation loss: 2.8014146557654027

Epoch: 6| Step: 9
Training loss: 0.5885160294296797
Validation loss: 2.8812735980674895

Epoch: 6| Step: 10
Training loss: 0.31749749092552415
Validation loss: 2.9188400799222007

Epoch: 6| Step: 11
Training loss: 1.296324279775775
Validation loss: 2.8649203200519526

Epoch: 6| Step: 12
Training loss: 0.5178178627873731
Validation loss: 2.9294406769942074

Epoch: 6| Step: 13
Training loss: 0.8394112116315993
Validation loss: 2.8115312674014654

Epoch: 170| Step: 0
Training loss: 0.4418747533935118
Validation loss: 2.780260645885316

Epoch: 6| Step: 1
Training loss: 0.45721158113504873
Validation loss: 2.814313840541122

Epoch: 6| Step: 2
Training loss: 0.5061350185602054
Validation loss: 2.8740287190513114

Epoch: 6| Step: 3
Training loss: 0.5421685559044112
Validation loss: 2.8128242588323658

Epoch: 6| Step: 4
Training loss: 0.32942884115521615
Validation loss: 2.8803391429773515

Epoch: 6| Step: 5
Training loss: 0.4614475144208058
Validation loss: 2.8195320944689235

Epoch: 6| Step: 6
Training loss: 0.578489910123465
Validation loss: 2.7870420801120144

Epoch: 6| Step: 7
Training loss: 0.5854489133196138
Validation loss: 2.748059563515983

Epoch: 6| Step: 8
Training loss: 1.3071744139269605
Validation loss: 2.8203634748845134

Epoch: 6| Step: 9
Training loss: 0.49159550259552787
Validation loss: 2.8439063423972297

Epoch: 6| Step: 10
Training loss: 0.9230923777441922
Validation loss: 2.8653836236353656

Epoch: 6| Step: 11
Training loss: 0.6331042335471138
Validation loss: 2.931877165656482

Epoch: 6| Step: 12
Training loss: 0.5497451668700775
Validation loss: 2.8772123918768258

Epoch: 6| Step: 13
Training loss: 0.5119720880194352
Validation loss: 2.868831783228734

Epoch: 171| Step: 0
Training loss: 0.5299094621232863
Validation loss: 2.8693682617294503

Epoch: 6| Step: 1
Training loss: 0.8244024858382651
Validation loss: 2.8169952073061535

Epoch: 6| Step: 2
Training loss: 0.4507487901871325
Validation loss: 2.8780401575628356

Epoch: 6| Step: 3
Training loss: 0.3760224351517874
Validation loss: 2.82066268367151

Epoch: 6| Step: 4
Training loss: 0.4718448831408319
Validation loss: 2.750780616131079

Epoch: 6| Step: 5
Training loss: 0.31528184809813764
Validation loss: 2.8186248492125645

Epoch: 6| Step: 6
Training loss: 0.48630008846496303
Validation loss: 2.8632620151180745

Epoch: 6| Step: 7
Training loss: 0.43721201478232274
Validation loss: 2.8434306933097284

Epoch: 6| Step: 8
Training loss: 1.2061297559348871
Validation loss: 2.8289351593790673

Epoch: 6| Step: 9
Training loss: 0.6657134906170855
Validation loss: 2.8620830698680066

Epoch: 6| Step: 10
Training loss: 0.43984633761740755
Validation loss: 2.8731305084054

Epoch: 6| Step: 11
Training loss: 0.6812011482501811
Validation loss: 2.8384444520501124

Epoch: 6| Step: 12
Training loss: 0.4116877708868511
Validation loss: 2.8679263958444263

Epoch: 6| Step: 13
Training loss: 0.49446773633435326
Validation loss: 2.872341931351201

Epoch: 172| Step: 0
Training loss: 0.7100994494460883
Validation loss: 2.9211449484543857

Epoch: 6| Step: 1
Training loss: 1.2426222034588266
Validation loss: 2.82239992730749

Epoch: 6| Step: 2
Training loss: 0.886910976462507
Validation loss: 2.890002319352606

Epoch: 6| Step: 3
Training loss: 0.5520643075027857
Validation loss: 2.8546437099183457

Epoch: 6| Step: 4
Training loss: 0.3872179219853779
Validation loss: 2.853246183074579

Epoch: 6| Step: 5
Training loss: 0.6192609026352982
Validation loss: 2.9064707381668002

Epoch: 6| Step: 6
Training loss: 0.5785065242610447
Validation loss: 2.804346161227819

Epoch: 6| Step: 7
Training loss: 0.48120163637368185
Validation loss: 2.8113379444316378

Epoch: 6| Step: 8
Training loss: 0.5573930440181928
Validation loss: 2.79580626856007

Epoch: 6| Step: 9
Training loss: 0.7860971004359333
Validation loss: 2.835625497348364

Epoch: 6| Step: 10
Training loss: 0.6148736774378397
Validation loss: 2.7512382551673658

Epoch: 6| Step: 11
Training loss: 0.5643828457173992
Validation loss: 2.82456591711674

Epoch: 6| Step: 12
Training loss: 0.6163637966142754
Validation loss: 2.839643174844881

Epoch: 6| Step: 13
Training loss: 0.4463114325929022
Validation loss: 2.8480136474378828

Epoch: 173| Step: 0
Training loss: 0.814010097112993
Validation loss: 2.76410483843068

Epoch: 6| Step: 1
Training loss: 0.5429779985038133
Validation loss: 2.905231721295391

Epoch: 6| Step: 2
Training loss: 0.42223627021944965
Validation loss: 2.8212805695371257

Epoch: 6| Step: 3
Training loss: 0.5197393244481388
Validation loss: 2.8166803164029113

Epoch: 6| Step: 4
Training loss: 0.6934024421318803
Validation loss: 2.8479728505290685

Epoch: 6| Step: 5
Training loss: 0.4413608595204294
Validation loss: 2.8103835301652595

Epoch: 6| Step: 6
Training loss: 0.5520291631741764
Validation loss: 2.7964001328817285

Epoch: 6| Step: 7
Training loss: 0.43464138864201296
Validation loss: 2.766393048379635

Epoch: 6| Step: 8
Training loss: 0.5322987918663038
Validation loss: 2.79907561949551

Epoch: 6| Step: 9
Training loss: 0.6539894862277726
Validation loss: 2.852000233396509

Epoch: 6| Step: 10
Training loss: 0.4795642806355313
Validation loss: 2.9013728301478006

Epoch: 6| Step: 11
Training loss: 0.3799218596564919
Validation loss: 2.850976335034587

Epoch: 6| Step: 12
Training loss: 1.31815920970327
Validation loss: 2.8679556861302107

Epoch: 6| Step: 13
Training loss: 0.5752623540023387
Validation loss: 2.802281132822589

Epoch: 174| Step: 0
Training loss: 0.4642838544205733
Validation loss: 2.8274039513744844

Epoch: 6| Step: 1
Training loss: 0.5261211209361502
Validation loss: 2.746862955830063

Epoch: 6| Step: 2
Training loss: 0.8897987682571511
Validation loss: 2.8822864993349735

Epoch: 6| Step: 3
Training loss: 0.5025556339951975
Validation loss: 2.8074285206084237

Epoch: 6| Step: 4
Training loss: 0.4938893188017104
Validation loss: 2.8347274959236253

Epoch: 6| Step: 5
Training loss: 0.7312685418019751
Validation loss: 2.8688760994295257

Epoch: 6| Step: 6
Training loss: 0.47812713111452365
Validation loss: 2.845911650652833

Epoch: 6| Step: 7
Training loss: 0.5008350492195192
Validation loss: 2.9346451244667033

Epoch: 6| Step: 8
Training loss: 1.286729863760965
Validation loss: 2.9710426713362974

Epoch: 6| Step: 9
Training loss: 0.5826446322129106
Validation loss: 2.9092458576805464

Epoch: 6| Step: 10
Training loss: 0.3615626424658914
Validation loss: 2.9287329038326426

Epoch: 6| Step: 11
Training loss: 0.29149222550240206
Validation loss: 2.8731115607494404

Epoch: 6| Step: 12
Training loss: 0.530928318018379
Validation loss: 2.846891533377549

Epoch: 6| Step: 13
Training loss: 0.5761305454754505
Validation loss: 2.8913326325175666

Epoch: 175| Step: 0
Training loss: 0.4550539918975724
Validation loss: 2.7875861669203292

Epoch: 6| Step: 1
Training loss: 0.6884389447696191
Validation loss: 2.7874707008042257

Epoch: 6| Step: 2
Training loss: 0.38347933552658275
Validation loss: 2.8183074897048925

Epoch: 6| Step: 3
Training loss: 0.9651197895748822
Validation loss: 2.8172549425326006

Epoch: 6| Step: 4
Training loss: 0.5392645305255149
Validation loss: 2.899211715022229

Epoch: 6| Step: 5
Training loss: 0.47606335749830014
Validation loss: 2.941295890206929

Epoch: 6| Step: 6
Training loss: 0.7034725178120343
Validation loss: 2.9457973954644823

Epoch: 6| Step: 7
Training loss: 0.6139725597413092
Validation loss: 2.9407820391773405

Epoch: 6| Step: 8
Training loss: 0.4607091273291499
Validation loss: 2.8746056631798393

Epoch: 6| Step: 9
Training loss: 0.5617727240468081
Validation loss: 2.8108277753753708

Epoch: 6| Step: 10
Training loss: 0.515050683814453
Validation loss: 2.82478177766588

Epoch: 6| Step: 11
Training loss: 0.501740525639468
Validation loss: 2.8062791053944824

Epoch: 6| Step: 12
Training loss: 0.5878200552017286
Validation loss: 2.774199288924021

Epoch: 6| Step: 13
Training loss: 1.3673752574060807
Validation loss: 2.793036769936764

Epoch: 176| Step: 0
Training loss: 0.4830228020377888
Validation loss: 2.8458934153911604

Epoch: 6| Step: 1
Training loss: 0.6031185436397339
Validation loss: 2.8553783230220526

Epoch: 6| Step: 2
Training loss: 0.5508024603905782
Validation loss: 2.931832805571983

Epoch: 6| Step: 3
Training loss: 0.882080686280236
Validation loss: 2.965293183436838

Epoch: 6| Step: 4
Training loss: 0.9080365428125048
Validation loss: 2.8994726781336797

Epoch: 6| Step: 5
Training loss: 0.6128480195018372
Validation loss: 2.857731303289827

Epoch: 6| Step: 6
Training loss: 0.31571459820390696
Validation loss: 2.828083916184814

Epoch: 6| Step: 7
Training loss: 1.2352474364775428
Validation loss: 2.7753647103510257

Epoch: 6| Step: 8
Training loss: 0.5349879034849563
Validation loss: 2.859285808346455

Epoch: 6| Step: 9
Training loss: 0.5750149766381344
Validation loss: 2.806954660281186

Epoch: 6| Step: 10
Training loss: 0.6757163749822095
Validation loss: 2.731357428025994

Epoch: 6| Step: 11
Training loss: 0.6120514414429159
Validation loss: 2.8717812889176577

Epoch: 6| Step: 12
Training loss: 0.5482722280634629
Validation loss: 2.7890748665728693

Epoch: 6| Step: 13
Training loss: 0.573121898189292
Validation loss: 2.9310846820295646

Epoch: 177| Step: 0
Training loss: 0.5948882486078848
Validation loss: 2.8404876664595675

Epoch: 6| Step: 1
Training loss: 0.47469212944781863
Validation loss: 2.9220151952609097

Epoch: 6| Step: 2
Training loss: 0.552822631691339
Validation loss: 2.8492140344291865

Epoch: 6| Step: 3
Training loss: 0.4300813430541006
Validation loss: 2.809188716088595

Epoch: 6| Step: 4
Training loss: 0.4548989790602469
Validation loss: 2.8559258508700336

Epoch: 6| Step: 5
Training loss: 1.4456910333589008
Validation loss: 2.758039996423999

Epoch: 6| Step: 6
Training loss: 0.6354007536557957
Validation loss: 2.736324189587381

Epoch: 6| Step: 7
Training loss: 0.465974234495952
Validation loss: 2.829643516261885

Epoch: 6| Step: 8
Training loss: 0.47214374657626085
Validation loss: 2.844712873382929

Epoch: 6| Step: 9
Training loss: 0.43933595578829665
Validation loss: 2.8701173397936826

Epoch: 6| Step: 10
Training loss: 0.5707883547955002
Validation loss: 2.840918364307411

Epoch: 6| Step: 11
Training loss: 0.5874164227632033
Validation loss: 2.823049708723419

Epoch: 6| Step: 12
Training loss: 0.5789123020035957
Validation loss: 2.884645088034719

Epoch: 6| Step: 13
Training loss: 0.42834559625606355
Validation loss: 2.8000053348944567

Epoch: 178| Step: 0
Training loss: 0.30032019763095974
Validation loss: 2.827122898897856

Epoch: 6| Step: 1
Training loss: 0.2921074477094156
Validation loss: 2.806513596511365

Epoch: 6| Step: 2
Training loss: 0.9172813601452344
Validation loss: 2.717566477381544

Epoch: 6| Step: 3
Training loss: 0.516906878815597
Validation loss: 2.7545390671328747

Epoch: 6| Step: 4
Training loss: 0.5019898753683998
Validation loss: 2.805682559228462

Epoch: 6| Step: 5
Training loss: 0.4507553357587643
Validation loss: 2.8836178089847952

Epoch: 6| Step: 6
Training loss: 0.4979717721599012
Validation loss: 2.8930824624862113

Epoch: 6| Step: 7
Training loss: 0.5446901820122788
Validation loss: 2.850671540164558

Epoch: 6| Step: 8
Training loss: 0.5866626575542504
Validation loss: 2.839908954163895

Epoch: 6| Step: 9
Training loss: 0.514948314184179
Validation loss: 2.89668260557518

Epoch: 6| Step: 10
Training loss: 0.3312886179599539
Validation loss: 2.8337862456855443

Epoch: 6| Step: 11
Training loss: 0.5097429993968652
Validation loss: 2.817119887152965

Epoch: 6| Step: 12
Training loss: 0.5043271694642906
Validation loss: 2.7828645770201264

Epoch: 6| Step: 13
Training loss: 1.2164124789412307
Validation loss: 2.838881268732636

Epoch: 179| Step: 0
Training loss: 0.4623783028787055
Validation loss: 2.7933734307184213

Epoch: 6| Step: 1
Training loss: 0.3989964099306634
Validation loss: 2.753839283663299

Epoch: 6| Step: 2
Training loss: 0.506623092971552
Validation loss: 2.8259916883005785

Epoch: 6| Step: 3
Training loss: 0.43101955628447514
Validation loss: 2.7827834855883355

Epoch: 6| Step: 4
Training loss: 0.5337554251062349
Validation loss: 2.829753722875165

Epoch: 6| Step: 5
Training loss: 0.30674434535636963
Validation loss: 2.7666284353609796

Epoch: 6| Step: 6
Training loss: 0.4518795985598595
Validation loss: 2.889222225699912

Epoch: 6| Step: 7
Training loss: 0.4856549241752537
Validation loss: 2.8322636230546974

Epoch: 6| Step: 8
Training loss: 0.8027694954347718
Validation loss: 2.8556435840692442

Epoch: 6| Step: 9
Training loss: 0.48146368150314284
Validation loss: 2.8613801189815264

Epoch: 6| Step: 10
Training loss: 0.4992093003263671
Validation loss: 2.8732099627261585

Epoch: 6| Step: 11
Training loss: 0.5813275890452966
Validation loss: 2.876090312925384

Epoch: 6| Step: 12
Training loss: 1.1411965388366219
Validation loss: 2.8284193556664445

Epoch: 6| Step: 13
Training loss: 0.4312147222823311
Validation loss: 2.820520028803135

Epoch: 180| Step: 0
Training loss: 0.4972686371933052
Validation loss: 2.7908847529892333

Epoch: 6| Step: 1
Training loss: 0.41161807094201647
Validation loss: 2.8866695112503638

Epoch: 6| Step: 2
Training loss: 1.1876440462786022
Validation loss: 2.7635194913911696

Epoch: 6| Step: 3
Training loss: 0.5886279833352082
Validation loss: 2.764703758815432

Epoch: 6| Step: 4
Training loss: 0.8577965198133174
Validation loss: 2.7715973816464214

Epoch: 6| Step: 5
Training loss: 0.3679307962593879
Validation loss: 2.8673012110641762

Epoch: 6| Step: 6
Training loss: 0.43131558016384897
Validation loss: 2.851363236942181

Epoch: 6| Step: 7
Training loss: 0.34136180981268704
Validation loss: 2.8293589434411435

Epoch: 6| Step: 8
Training loss: 0.7154378038133963
Validation loss: 2.8139924081068695

Epoch: 6| Step: 9
Training loss: 0.7238126832372026
Validation loss: 2.872756137655329

Epoch: 6| Step: 10
Training loss: 0.5484808641119274
Validation loss: 2.84008950311814

Epoch: 6| Step: 11
Training loss: 0.5488034443040287
Validation loss: 2.7926637709772515

Epoch: 6| Step: 12
Training loss: 0.5049645009169251
Validation loss: 2.7195923475916124

Epoch: 6| Step: 13
Training loss: 0.447156601324176
Validation loss: 2.7870452880619894

Epoch: 181| Step: 0
Training loss: 0.43827776236004945
Validation loss: 2.822634768516463

Epoch: 6| Step: 1
Training loss: 0.3674550400693898
Validation loss: 2.878203845937414

Epoch: 6| Step: 2
Training loss: 0.7451657820588062
Validation loss: 2.849608663829482

Epoch: 6| Step: 3
Training loss: 0.4731466098420867
Validation loss: 2.811586768623038

Epoch: 6| Step: 4
Training loss: 0.40911912128433564
Validation loss: 2.8831881973547904

Epoch: 6| Step: 5
Training loss: 0.38544705846745064
Validation loss: 2.9117471259416194

Epoch: 6| Step: 6
Training loss: 0.6126157709596789
Validation loss: 2.8672611736426137

Epoch: 6| Step: 7
Training loss: 0.3748081034176185
Validation loss: 2.8185181338403784

Epoch: 6| Step: 8
Training loss: 0.49039652601006484
Validation loss: 2.7881839340812067

Epoch: 6| Step: 9
Training loss: 1.2102045117304379
Validation loss: 2.828440330727894

Epoch: 6| Step: 10
Training loss: 0.4505811184219059
Validation loss: 2.8877211410370167

Epoch: 6| Step: 11
Training loss: 0.5672679791482428
Validation loss: 2.839312658099264

Epoch: 6| Step: 12
Training loss: 0.3720528706144435
Validation loss: 2.7410622486086815

Epoch: 6| Step: 13
Training loss: 0.3953617909577035
Validation loss: 2.8760003892551667

Epoch: 182| Step: 0
Training loss: 0.3513763040629004
Validation loss: 2.9234145217446446

Epoch: 6| Step: 1
Training loss: 0.7530886312860298
Validation loss: 2.8312447975228787

Epoch: 6| Step: 2
Training loss: 0.3535713868395738
Validation loss: 2.870021510857706

Epoch: 6| Step: 3
Training loss: 0.45095255091049624
Validation loss: 2.8050621724619136

Epoch: 6| Step: 4
Training loss: 0.44539598050567014
Validation loss: 2.889170636494428

Epoch: 6| Step: 5
Training loss: 0.45396984199838475
Validation loss: 2.838645419869823

Epoch: 6| Step: 6
Training loss: 0.3943898164653126
Validation loss: 2.8537029019519977

Epoch: 6| Step: 7
Training loss: 0.6109482434979376
Validation loss: 2.838773390151336

Epoch: 6| Step: 8
Training loss: 0.516237992708166
Validation loss: 2.853506197468848

Epoch: 6| Step: 9
Training loss: 0.5744319182743067
Validation loss: 2.856295304666006

Epoch: 6| Step: 10
Training loss: 0.4736644459021819
Validation loss: 2.838332944889755

Epoch: 6| Step: 11
Training loss: 1.1845818854739187
Validation loss: 2.8343393465860856

Epoch: 6| Step: 12
Training loss: 0.42315786073503636
Validation loss: 2.8494096267201634

Epoch: 6| Step: 13
Training loss: 0.5442668300158978
Validation loss: 2.843820731712146

Epoch: 183| Step: 0
Training loss: 0.4398798587267313
Validation loss: 2.787704022956809

Epoch: 6| Step: 1
Training loss: 0.4747082956466363
Validation loss: 2.8158187359238362

Epoch: 6| Step: 2
Training loss: 0.33830703038040694
Validation loss: 2.832073048250276

Epoch: 6| Step: 3
Training loss: 0.5914192127737181
Validation loss: 2.843630596071483

Epoch: 6| Step: 4
Training loss: 0.42774771752297536
Validation loss: 2.912063472052568

Epoch: 6| Step: 5
Training loss: 0.3592902373820357
Validation loss: 2.8074583996085196

Epoch: 6| Step: 6
Training loss: 1.0990729370142254
Validation loss: 2.8196848895728026

Epoch: 6| Step: 7
Training loss: 0.34975801004177004
Validation loss: 2.893023511351307

Epoch: 6| Step: 8
Training loss: 0.4980016351236363
Validation loss: 2.7688477376215963

Epoch: 6| Step: 9
Training loss: 0.6092043906801915
Validation loss: 2.7870486670986363

Epoch: 6| Step: 10
Training loss: 0.7741030132116293
Validation loss: 2.8181417675961944

Epoch: 6| Step: 11
Training loss: 0.5502362903289195
Validation loss: 2.8248451561815893

Epoch: 6| Step: 12
Training loss: 0.5781447432987253
Validation loss: 2.879534669609426

Epoch: 6| Step: 13
Training loss: 0.6930211921468112
Validation loss: 2.9027395616010274

Epoch: 184| Step: 0
Training loss: 0.7957865443297923
Validation loss: 2.8354112681595094

Epoch: 6| Step: 1
Training loss: 0.5552886069872727
Validation loss: 2.876636564540027

Epoch: 6| Step: 2
Training loss: 0.4084793689285182
Validation loss: 2.81338333104288

Epoch: 6| Step: 3
Training loss: 0.466438698718133
Validation loss: 2.8140180376329242

Epoch: 6| Step: 4
Training loss: 0.6915589072456929
Validation loss: 2.8564019511265455

Epoch: 6| Step: 5
Training loss: 0.6115849841959676
Validation loss: 2.839589313511045

Epoch: 6| Step: 6
Training loss: 1.2572322952592567
Validation loss: 2.8487928901535793

Epoch: 6| Step: 7
Training loss: 0.5560798363312925
Validation loss: 2.798237388863932

Epoch: 6| Step: 8
Training loss: 0.40459821592485373
Validation loss: 2.8343828632283516

Epoch: 6| Step: 9
Training loss: 0.7356942684000615
Validation loss: 2.8993920247983636

Epoch: 6| Step: 10
Training loss: 0.46968528899321516
Validation loss: 2.806266956235638

Epoch: 6| Step: 11
Training loss: 0.3949054793851204
Validation loss: 2.913804057288205

Epoch: 6| Step: 12
Training loss: 0.2972374134486951
Validation loss: 2.8425386664523837

Epoch: 6| Step: 13
Training loss: 0.42201421348084034
Validation loss: 2.8462202361143163

Epoch: 185| Step: 0
Training loss: 0.49757605345155986
Validation loss: 2.7848498446508736

Epoch: 6| Step: 1
Training loss: 0.45406224890726266
Validation loss: 2.8537012727832374

Epoch: 6| Step: 2
Training loss: 0.7366883385895329
Validation loss: 2.8703466295356606

Epoch: 6| Step: 3
Training loss: 0.4016486153496935
Validation loss: 2.8521221221411315

Epoch: 6| Step: 4
Training loss: 0.4437142854744416
Validation loss: 2.8670288929046106

Epoch: 6| Step: 5
Training loss: 0.6183014486511526
Validation loss: 2.879941742868541

Epoch: 6| Step: 6
Training loss: 0.552024034398438
Validation loss: 2.891380706154794

Epoch: 6| Step: 7
Training loss: 0.5346625898256115
Validation loss: 2.875526138205881

Epoch: 6| Step: 8
Training loss: 0.5568101056067046
Validation loss: 2.8836619461829938

Epoch: 6| Step: 9
Training loss: 0.4509507500227864
Validation loss: 2.791871423946038

Epoch: 6| Step: 10
Training loss: 0.5704168981863276
Validation loss: 2.797654581375711

Epoch: 6| Step: 11
Training loss: 0.5896471719137524
Validation loss: 2.7580387213609616

Epoch: 6| Step: 12
Training loss: 0.4786104380817568
Validation loss: 2.7489522469643397

Epoch: 6| Step: 13
Training loss: 1.188103121135161
Validation loss: 2.866630257515756

Epoch: 186| Step: 0
Training loss: 0.7154375538769733
Validation loss: 2.8920424414167805

Epoch: 6| Step: 1
Training loss: 0.5889348992281487
Validation loss: 2.893100235495779

Epoch: 6| Step: 2
Training loss: 0.34566579498639705
Validation loss: 2.929667073496499

Epoch: 6| Step: 3
Training loss: 0.3479074899049507
Validation loss: 2.8960430952070038

Epoch: 6| Step: 4
Training loss: 0.36605337186468445
Validation loss: 2.7838594325378305

Epoch: 6| Step: 5
Training loss: 0.4241926322189257
Validation loss: 2.788714503813706

Epoch: 6| Step: 6
Training loss: 0.7733138785162275
Validation loss: 2.872118210482314

Epoch: 6| Step: 7
Training loss: 0.3937696149269773
Validation loss: 2.7944355134292507

Epoch: 6| Step: 8
Training loss: 1.1535676308239962
Validation loss: 2.8540190127157588

Epoch: 6| Step: 9
Training loss: 0.4220007073353539
Validation loss: 2.8128283273707693

Epoch: 6| Step: 10
Training loss: 0.538776681288016
Validation loss: 2.769285764158323

Epoch: 6| Step: 11
Training loss: 0.4279372548453207
Validation loss: 2.888946265686041

Epoch: 6| Step: 12
Training loss: 0.34374814683241267
Validation loss: 2.8644932796310436

Epoch: 6| Step: 13
Training loss: 0.27962677152479215
Validation loss: 2.8389976391882694

Epoch: 187| Step: 0
Training loss: 0.3641470569434575
Validation loss: 2.842625308242597

Epoch: 6| Step: 1
Training loss: 0.35637651589538516
Validation loss: 2.794477120375489

Epoch: 6| Step: 2
Training loss: 0.35481814696491903
Validation loss: 2.758252275395735

Epoch: 6| Step: 3
Training loss: 0.5460728893743431
Validation loss: 2.7930726643329233

Epoch: 6| Step: 4
Training loss: 1.1754033694934436
Validation loss: 2.8983159618138608

Epoch: 6| Step: 5
Training loss: 0.45019332653608873
Validation loss: 2.7974009241372557

Epoch: 6| Step: 6
Training loss: 0.32097895999833376
Validation loss: 2.759877866067525

Epoch: 6| Step: 7
Training loss: 0.7153846903612399
Validation loss: 2.828412541899012

Epoch: 6| Step: 8
Training loss: 0.5816509873573241
Validation loss: 2.8284093527692344

Epoch: 6| Step: 9
Training loss: 0.3789221376843891
Validation loss: 2.858473769501683

Epoch: 6| Step: 10
Training loss: 0.399293764834083
Validation loss: 2.8967940888804296

Epoch: 6| Step: 11
Training loss: 0.394744720871833
Validation loss: 2.8928140273180634

Epoch: 6| Step: 12
Training loss: 0.3681611888176351
Validation loss: 2.7956757203050993

Epoch: 6| Step: 13
Training loss: 0.41698591598332924
Validation loss: 2.821449297241923

Epoch: 188| Step: 0
Training loss: 0.3214851175441023
Validation loss: 2.86616795955498

Epoch: 6| Step: 1
Training loss: 0.33501353837882786
Validation loss: 2.8792911929533926

Epoch: 6| Step: 2
Training loss: 0.7550696848611238
Validation loss: 2.8085826083029937

Epoch: 6| Step: 3
Training loss: 0.5762064260694474
Validation loss: 2.8201444933331308

Epoch: 6| Step: 4
Training loss: 0.4307068611036948
Validation loss: 2.827527849019204

Epoch: 6| Step: 5
Training loss: 1.0417697601165345
Validation loss: 2.861917001583064

Epoch: 6| Step: 6
Training loss: 0.672752871424665
Validation loss: 2.9100341907821634

Epoch: 6| Step: 7
Training loss: 0.5493036565360664
Validation loss: 2.8840986103565633

Epoch: 6| Step: 8
Training loss: 0.40490209273176475
Validation loss: 2.7908469652594943

Epoch: 6| Step: 9
Training loss: 0.395664758507456
Validation loss: 2.9086381131324863

Epoch: 6| Step: 10
Training loss: 0.45570801458771687
Validation loss: 2.813600847473248

Epoch: 6| Step: 11
Training loss: 0.3999466085563669
Validation loss: 2.78605612350551

Epoch: 6| Step: 12
Training loss: 0.689805154379558
Validation loss: 2.798337230948513

Epoch: 6| Step: 13
Training loss: 0.5905890650640847
Validation loss: 2.8479689438176727

Epoch: 189| Step: 0
Training loss: 0.37504708471341225
Validation loss: 2.9051068973625314

Epoch: 6| Step: 1
Training loss: 0.5337326159538565
Validation loss: 2.986610680322197

Epoch: 6| Step: 2
Training loss: 0.4581191328227253
Validation loss: 2.944857709800989

Epoch: 6| Step: 3
Training loss: 0.5425483667989077
Validation loss: 3.009953701934788

Epoch: 6| Step: 4
Training loss: 0.5672142842171473
Validation loss: 2.972496573144356

Epoch: 6| Step: 5
Training loss: 0.5313898351299402
Validation loss: 2.8773565585710745

Epoch: 6| Step: 6
Training loss: 0.4668027486391709
Validation loss: 2.8551147491991213

Epoch: 6| Step: 7
Training loss: 0.5278195812863786
Validation loss: 2.7940031825871

Epoch: 6| Step: 8
Training loss: 0.4992925586373599
Validation loss: 2.822929344758753

Epoch: 6| Step: 9
Training loss: 0.5601228712024855
Validation loss: 2.8508244086152534

Epoch: 6| Step: 10
Training loss: 0.5336995311792182
Validation loss: 2.824331602283843

Epoch: 6| Step: 11
Training loss: 0.7542165009137293
Validation loss: 2.8278778979853967

Epoch: 6| Step: 12
Training loss: 1.1940087083022926
Validation loss: 2.895972740239115

Epoch: 6| Step: 13
Training loss: 0.7185236532980775
Validation loss: 2.8788994107969597

Epoch: 190| Step: 0
Training loss: 0.3544295704922752
Validation loss: 2.9670955799737335

Epoch: 6| Step: 1
Training loss: 0.31009468409236024
Validation loss: 2.8617108919002985

Epoch: 6| Step: 2
Training loss: 0.6010532452962739
Validation loss: 2.84607019197409

Epoch: 6| Step: 3
Training loss: 0.5520514053133357
Validation loss: 2.814889119156987

Epoch: 6| Step: 4
Training loss: 1.1207467848157067
Validation loss: 2.8698074885011238

Epoch: 6| Step: 5
Training loss: 0.8414643022351187
Validation loss: 2.898847196264622

Epoch: 6| Step: 6
Training loss: 0.5476844791205847
Validation loss: 2.8804141218859445

Epoch: 6| Step: 7
Training loss: 0.4850358761466705
Validation loss: 2.8859723562501496

Epoch: 6| Step: 8
Training loss: 0.4379625089583815
Validation loss: 2.9332567911204115

Epoch: 6| Step: 9
Training loss: 0.5383648158346394
Validation loss: 2.9458692515196514

Epoch: 6| Step: 10
Training loss: 0.38860918622558543
Validation loss: 2.9111557987009036

Epoch: 6| Step: 11
Training loss: 0.3395033040946329
Validation loss: 2.8854438192877976

Epoch: 6| Step: 12
Training loss: 0.4680869658467692
Validation loss: 2.879952808563045

Epoch: 6| Step: 13
Training loss: 0.3780900678971639
Validation loss: 2.8710567411429233

Epoch: 191| Step: 0
Training loss: 0.47933617129975714
Validation loss: 2.900627165973504

Epoch: 6| Step: 1
Training loss: 0.41318198816595614
Validation loss: 2.906188950529789

Epoch: 6| Step: 2
Training loss: 0.7669261075301296
Validation loss: 2.823353755844037

Epoch: 6| Step: 3
Training loss: 0.37966697072231004
Validation loss: 2.846075022773098

Epoch: 6| Step: 4
Training loss: 0.4258378717413304
Validation loss: 2.8767365173163566

Epoch: 6| Step: 5
Training loss: 0.42791399385062645
Validation loss: 2.926171772880928

Epoch: 6| Step: 6
Training loss: 0.5872346126461622
Validation loss: 2.897629644978532

Epoch: 6| Step: 7
Training loss: 0.4249357876233277
Validation loss: 2.841112073120228

Epoch: 6| Step: 8
Training loss: 0.4144041343446828
Validation loss: 2.8422902730906525

Epoch: 6| Step: 9
Training loss: 0.3934131112087855
Validation loss: 2.858879115840837

Epoch: 6| Step: 10
Training loss: 0.45479807607014
Validation loss: 2.869867650368659

Epoch: 6| Step: 11
Training loss: 0.5180302210906487
Validation loss: 2.8734161188084837

Epoch: 6| Step: 12
Training loss: 1.0950275044927882
Validation loss: 2.7971733971225574

Epoch: 6| Step: 13
Training loss: 0.48028156076630085
Validation loss: 2.7788292854953935

Epoch: 192| Step: 0
Training loss: 0.5538429762153577
Validation loss: 2.8187203038491746

Epoch: 6| Step: 1
Training loss: 0.4850300389750254
Validation loss: 2.8979602431077165

Epoch: 6| Step: 2
Training loss: 0.4920196549765619
Validation loss: 2.846693548623522

Epoch: 6| Step: 3
Training loss: 0.4500566546221173
Validation loss: 2.8214059895490693

Epoch: 6| Step: 4
Training loss: 0.4027785572048114
Validation loss: 2.831105454932624

Epoch: 6| Step: 5
Training loss: 1.161668299469058
Validation loss: 2.8143812175232785

Epoch: 6| Step: 6
Training loss: 0.41883028669889916
Validation loss: 2.8660490043338975

Epoch: 6| Step: 7
Training loss: 0.8967313405529115
Validation loss: 2.876817087555633

Epoch: 6| Step: 8
Training loss: 0.4872130497025279
Validation loss: 2.873360954455786

Epoch: 6| Step: 9
Training loss: 0.3735442515743166
Validation loss: 2.8892920092590977

Epoch: 6| Step: 10
Training loss: 0.6442720296525346
Validation loss: 2.9046462634933357

Epoch: 6| Step: 11
Training loss: 0.5620644260485055
Validation loss: 2.862069796977565

Epoch: 6| Step: 12
Training loss: 0.5585983382883565
Validation loss: 2.8260976785596736

Epoch: 6| Step: 13
Training loss: 0.37511009348634744
Validation loss: 2.7790785753128424

Epoch: 193| Step: 0
Training loss: 0.6330978550792218
Validation loss: 2.7563663974211554

Epoch: 6| Step: 1
Training loss: 0.45274401136910614
Validation loss: 2.8497343430320883

Epoch: 6| Step: 2
Training loss: 0.47682457893563795
Validation loss: 2.8045743814961304

Epoch: 6| Step: 3
Training loss: 0.47666187500990603
Validation loss: 2.8618461061923934

Epoch: 6| Step: 4
Training loss: 0.5075820987047382
Validation loss: 2.8908648967000334

Epoch: 6| Step: 5
Training loss: 0.5237546500862197
Validation loss: 2.9013569978363645

Epoch: 6| Step: 6
Training loss: 1.0004728510622292
Validation loss: 2.925947889973451

Epoch: 6| Step: 7
Training loss: 0.37846466760746345
Validation loss: 2.904749903590822

Epoch: 6| Step: 8
Training loss: 0.8071620262813934
Validation loss: 2.8838035306687093

Epoch: 6| Step: 9
Training loss: 0.3858500269552817
Validation loss: 2.8752816518400137

Epoch: 6| Step: 10
Training loss: 0.2792793615225476
Validation loss: 2.91264114965605

Epoch: 6| Step: 11
Training loss: 0.3307106571074214
Validation loss: 2.86180195188883

Epoch: 6| Step: 12
Training loss: 0.3703230232642859
Validation loss: 2.892713805868769

Epoch: 6| Step: 13
Training loss: 0.3371052738439722
Validation loss: 2.8984695391670705

Epoch: 194| Step: 0
Training loss: 0.3385638657652018
Validation loss: 2.92867012500045

Epoch: 6| Step: 1
Training loss: 0.6394156694948431
Validation loss: 2.859045499567008

Epoch: 6| Step: 2
Training loss: 0.6806913613929747
Validation loss: 2.9297974019099686

Epoch: 6| Step: 3
Training loss: 0.45579944795275473
Validation loss: 2.8856972421415286

Epoch: 6| Step: 4
Training loss: 0.44623380022537207
Validation loss: 2.867520859522446

Epoch: 6| Step: 5
Training loss: 0.3652138321755057
Validation loss: 2.9109129329456254

Epoch: 6| Step: 6
Training loss: 0.5125415971203572
Validation loss: 2.8816586522538254

Epoch: 6| Step: 7
Training loss: 0.42684843030933406
Validation loss: 2.8746352724565045

Epoch: 6| Step: 8
Training loss: 0.4468607506781025
Validation loss: 2.7712687578084094

Epoch: 6| Step: 9
Training loss: 0.40300466826316883
Validation loss: 2.8774635568272515

Epoch: 6| Step: 10
Training loss: 0.44929125656783264
Validation loss: 2.898688703894815

Epoch: 6| Step: 11
Training loss: 1.0695125068264983
Validation loss: 2.79378001561778

Epoch: 6| Step: 12
Training loss: 0.4006356954709083
Validation loss: 2.917870808855251

Epoch: 6| Step: 13
Training loss: 0.4472761860895766
Validation loss: 2.919185658737141

Epoch: 195| Step: 0
Training loss: 0.4302796704935637
Validation loss: 2.8798951892192295

Epoch: 6| Step: 1
Training loss: 1.1655515836856718
Validation loss: 2.8649638021555774

Epoch: 6| Step: 2
Training loss: 0.4446429020224509
Validation loss: 2.8308085430752845

Epoch: 6| Step: 3
Training loss: 0.43043792392692665
Validation loss: 2.8234099253954774

Epoch: 6| Step: 4
Training loss: 0.3797597808482388
Validation loss: 2.7645265226029596

Epoch: 6| Step: 5
Training loss: 0.4206904984105071
Validation loss: 2.916985137900284

Epoch: 6| Step: 6
Training loss: 0.3620361402211776
Validation loss: 2.886488214010263

Epoch: 6| Step: 7
Training loss: 0.49968897563437314
Validation loss: 2.88304226863351

Epoch: 6| Step: 8
Training loss: 0.42156872404691437
Validation loss: 2.8884826419346843

Epoch: 6| Step: 9
Training loss: 0.7154690035244521
Validation loss: 2.885905370170269

Epoch: 6| Step: 10
Training loss: 0.4822730170640801
Validation loss: 2.9360784919400102

Epoch: 6| Step: 11
Training loss: 0.5100433937479592
Validation loss: 2.952211605417922

Epoch: 6| Step: 12
Training loss: 0.4151699263761084
Validation loss: 2.932575060812528

Epoch: 6| Step: 13
Training loss: 0.4086700397407221
Validation loss: 2.8225100929478497

Epoch: 196| Step: 0
Training loss: 0.3227654482441247
Validation loss: 2.8501946081676777

Epoch: 6| Step: 1
Training loss: 0.4383931239884524
Validation loss: 2.7623869336264884

Epoch: 6| Step: 2
Training loss: 0.692442639863872
Validation loss: 2.7547461272845792

Epoch: 6| Step: 3
Training loss: 0.42267321201775926
Validation loss: 2.8719461088401914

Epoch: 6| Step: 4
Training loss: 0.7323660053560918
Validation loss: 2.8582506036232

Epoch: 6| Step: 5
Training loss: 0.40031960950817147
Validation loss: 2.8274744385008814

Epoch: 6| Step: 6
Training loss: 0.4525547879334665
Validation loss: 2.848541080435083

Epoch: 6| Step: 7
Training loss: 0.4922313367910127
Validation loss: 2.8928309778065193

Epoch: 6| Step: 8
Training loss: 0.5105081171386147
Validation loss: 2.9213074049548395

Epoch: 6| Step: 9
Training loss: 0.4036980215810811
Validation loss: 2.938955798486143

Epoch: 6| Step: 10
Training loss: 0.29616427676215684
Validation loss: 2.865674429508439

Epoch: 6| Step: 11
Training loss: 0.3850452355958787
Validation loss: 2.8657517610702197

Epoch: 6| Step: 12
Training loss: 1.1351072023826114
Validation loss: 2.8285560490174966

Epoch: 6| Step: 13
Training loss: 0.524230868203736
Validation loss: 2.8469235105879376

Epoch: 197| Step: 0
Training loss: 0.5474216726092311
Validation loss: 2.7786026402804422

Epoch: 6| Step: 1
Training loss: 0.4073550709920685
Validation loss: 2.8447972699313517

Epoch: 6| Step: 2
Training loss: 0.4464589803420716
Validation loss: 2.8976762702519747

Epoch: 6| Step: 3
Training loss: 0.3987918101188145
Validation loss: 2.904963122980228

Epoch: 6| Step: 4
Training loss: 0.3616489944593811
Validation loss: 2.934052737479099

Epoch: 6| Step: 5
Training loss: 1.032189374847511
Validation loss: 2.9056937119424107

Epoch: 6| Step: 6
Training loss: 0.5000703285347322
Validation loss: 2.9214189822947514

Epoch: 6| Step: 7
Training loss: 0.44474917468658604
Validation loss: 2.8849550881022084

Epoch: 6| Step: 8
Training loss: 0.7099414597139
Validation loss: 2.8456852793870353

Epoch: 6| Step: 9
Training loss: 0.5501404951288769
Validation loss: 2.8139242027763904

Epoch: 6| Step: 10
Training loss: 0.3918112481201151
Validation loss: 2.8391118074907062

Epoch: 6| Step: 11
Training loss: 0.35866154464106786
Validation loss: 2.8389183191174494

Epoch: 6| Step: 12
Training loss: 0.3972872792871696
Validation loss: 2.8080563373719514

Epoch: 6| Step: 13
Training loss: 0.4480307585287901
Validation loss: 2.7974183249233757

Epoch: 198| Step: 0
Training loss: 0.3834654824726447
Validation loss: 2.83819943152697

Epoch: 6| Step: 1
Training loss: 0.2745394708643358
Validation loss: 2.8985245272585893

Epoch: 6| Step: 2
Training loss: 0.32604534870217683
Validation loss: 2.8490002133338237

Epoch: 6| Step: 3
Training loss: 0.3472027660587928
Validation loss: 2.9163978361942906

Epoch: 6| Step: 4
Training loss: 0.37225329287618053
Validation loss: 2.8569594222175705

Epoch: 6| Step: 5
Training loss: 0.6648443219802135
Validation loss: 2.8668402410417735

Epoch: 6| Step: 6
Training loss: 0.4986041672304847
Validation loss: 2.864729351599244

Epoch: 6| Step: 7
Training loss: 0.43786248449309034
Validation loss: 2.851022399197971

Epoch: 6| Step: 8
Training loss: 1.0901339564997086
Validation loss: 2.8246672622839695

Epoch: 6| Step: 9
Training loss: 0.7768919892421394
Validation loss: 2.781531930414125

Epoch: 6| Step: 10
Training loss: 0.47195600231236345
Validation loss: 2.7606915079203036

Epoch: 6| Step: 11
Training loss: 0.39865422431973585
Validation loss: 2.84153646038434

Epoch: 6| Step: 12
Training loss: 0.4212697597249956
Validation loss: 2.8601960495575653

Epoch: 6| Step: 13
Training loss: 0.498521959688716
Validation loss: 2.860697456094009

Epoch: 199| Step: 0
Training loss: 0.3230851590074881
Validation loss: 2.8808114292443845

Epoch: 6| Step: 1
Training loss: 0.389779472785592
Validation loss: 2.8499112717720294

Epoch: 6| Step: 2
Training loss: 0.30160682876192735
Validation loss: 2.843489135403037

Epoch: 6| Step: 3
Training loss: 0.47060252337336517
Validation loss: 2.851067960871315

Epoch: 6| Step: 4
Training loss: 0.4103340490163475
Validation loss: 2.8701424127616533

Epoch: 6| Step: 5
Training loss: 0.5376741803523818
Validation loss: 2.825764255614958

Epoch: 6| Step: 6
Training loss: 0.7032208271423971
Validation loss: 2.8506850333967737

Epoch: 6| Step: 7
Training loss: 0.4674386118296593
Validation loss: 2.8333136660697353

Epoch: 6| Step: 8
Training loss: 1.0882680570373715
Validation loss: 2.8905091820961273

Epoch: 6| Step: 9
Training loss: 0.42535480527108516
Validation loss: 2.8574587823270803

Epoch: 6| Step: 10
Training loss: 0.3860981518051819
Validation loss: 2.901727418418764

Epoch: 6| Step: 11
Training loss: 0.41020456665283256
Validation loss: 2.8830163568303284

Epoch: 6| Step: 12
Training loss: 0.5407963663064471
Validation loss: 2.860394072159792

Epoch: 6| Step: 13
Training loss: 0.41478482706181097
Validation loss: 2.845953733728057

Epoch: 200| Step: 0
Training loss: 0.38812007744288957
Validation loss: 2.838169813151658

Epoch: 6| Step: 1
Training loss: 0.27470230765677045
Validation loss: 2.807928764414186

Epoch: 6| Step: 2
Training loss: 0.35722166196737326
Validation loss: 2.894281936870422

Epoch: 6| Step: 3
Training loss: 0.3681673408989685
Validation loss: 2.877689416695658

Epoch: 6| Step: 4
Training loss: 0.4225726187670441
Validation loss: 2.9398558213006987

Epoch: 6| Step: 5
Training loss: 0.6900845842762016
Validation loss: 2.8700056509744303

Epoch: 6| Step: 6
Training loss: 0.4461762266860269
Validation loss: 2.892672485488428

Epoch: 6| Step: 7
Training loss: 0.43621395328326756
Validation loss: 2.9911888188993063

Epoch: 6| Step: 8
Training loss: 0.4093188320094767
Validation loss: 2.8951274963001845

Epoch: 6| Step: 9
Training loss: 0.4806488753937875
Validation loss: 2.90716639464912

Epoch: 6| Step: 10
Training loss: 0.442215456264194
Validation loss: 2.8750750766847624

Epoch: 6| Step: 11
Training loss: 0.447581317215714
Validation loss: 2.8406895248644117

Epoch: 6| Step: 12
Training loss: 1.1294440865931767
Validation loss: 2.8922989268574613

Epoch: 6| Step: 13
Training loss: 0.397868367038271
Validation loss: 2.871020811369789

Epoch: 201| Step: 0
Training loss: 0.56929892784472
Validation loss: 2.830765139934046

Epoch: 6| Step: 1
Training loss: 0.28934602750991567
Validation loss: 2.8822041931959377

Epoch: 6| Step: 2
Training loss: 0.4216263356101412
Validation loss: 2.82460912008895

Epoch: 6| Step: 3
Training loss: 0.5444786976832381
Validation loss: 2.870124663725802

Epoch: 6| Step: 4
Training loss: 0.4867743164967539
Validation loss: 2.932282054246197

Epoch: 6| Step: 5
Training loss: 0.6473031750816102
Validation loss: 2.853342610222302

Epoch: 6| Step: 6
Training loss: 0.4382912768952641
Validation loss: 2.8704800804141177

Epoch: 6| Step: 7
Training loss: 0.5602793836194987
Validation loss: 2.8904695761196355

Epoch: 6| Step: 8
Training loss: 0.4978891758798161
Validation loss: 2.9491276000633966

Epoch: 6| Step: 9
Training loss: 0.2769287792744822
Validation loss: 2.887927279434734

Epoch: 6| Step: 10
Training loss: 0.35622194162935666
Validation loss: 2.815673619964397

Epoch: 6| Step: 11
Training loss: 0.38277427326776453
Validation loss: 2.8725274967419145

Epoch: 6| Step: 12
Training loss: 1.0067802287987366
Validation loss: 2.9034089589114687

Epoch: 6| Step: 13
Training loss: 0.35966233501014905
Validation loss: 2.9273977868717784

Epoch: 202| Step: 0
Training loss: 0.3849156276102213
Validation loss: 2.940398558256861

Epoch: 6| Step: 1
Training loss: 0.5098925611516316
Validation loss: 2.860879026544943

Epoch: 6| Step: 2
Training loss: 0.4202228798032497
Validation loss: 2.891562899084451

Epoch: 6| Step: 3
Training loss: 0.31268014483862433
Validation loss: 2.8811978691940197

Epoch: 6| Step: 4
Training loss: 0.7817130051957802
Validation loss: 2.8958694858261143

Epoch: 6| Step: 5
Training loss: 1.0311698304427808
Validation loss: 2.917487387762019

Epoch: 6| Step: 6
Training loss: 0.5173528792930403
Validation loss: 2.9235918301640984

Epoch: 6| Step: 7
Training loss: 0.42561466562997974
Validation loss: 2.9109707573632195

Epoch: 6| Step: 8
Training loss: 0.4602663682350876
Validation loss: 2.8892817632567436

Epoch: 6| Step: 9
Training loss: 0.29492490653191517
Validation loss: 2.9117011626947242

Epoch: 6| Step: 10
Training loss: 0.272734091503703
Validation loss: 2.8344797638665193

Epoch: 6| Step: 11
Training loss: 0.37124169061012147
Validation loss: 2.8320567794175293

Epoch: 6| Step: 12
Training loss: 0.3972009094099658
Validation loss: 2.9243108622265446

Epoch: 6| Step: 13
Training loss: 0.5241425733178966
Validation loss: 2.866909425921169

Epoch: 203| Step: 0
Training loss: 0.3987002534837302
Validation loss: 2.8652864714508226

Epoch: 6| Step: 1
Training loss: 0.3942520362206357
Validation loss: 2.8430426559772646

Epoch: 6| Step: 2
Training loss: 0.377675880550086
Validation loss: 2.897218487295115

Epoch: 6| Step: 3
Training loss: 0.35027258850655013
Validation loss: 2.8438340688163204

Epoch: 6| Step: 4
Training loss: 0.5025048100065734
Validation loss: 2.8250099857120077

Epoch: 6| Step: 5
Training loss: 0.6493683533608314
Validation loss: 2.7814079839862704

Epoch: 6| Step: 6
Training loss: 0.40916725085165634
Validation loss: 2.944194942575765

Epoch: 6| Step: 7
Training loss: 0.9777779606405964
Validation loss: 2.8920955182381087

Epoch: 6| Step: 8
Training loss: 0.3497810794567823
Validation loss: 2.866916016520267

Epoch: 6| Step: 9
Training loss: 0.2860846104560508
Validation loss: 2.8337094580879056

Epoch: 6| Step: 10
Training loss: 0.31208599800344
Validation loss: 2.912599989193848

Epoch: 6| Step: 11
Training loss: 0.40730321514931433
Validation loss: 2.9205110463723347

Epoch: 6| Step: 12
Training loss: 0.37536388861705394
Validation loss: 2.8613583160647678

Epoch: 6| Step: 13
Training loss: 0.5385619341088198
Validation loss: 2.8472400111648075

Epoch: 204| Step: 0
Training loss: 0.713526152467644
Validation loss: 2.880333983363384

Epoch: 6| Step: 1
Training loss: 0.43167965052322066
Validation loss: 2.8637120858208993

Epoch: 6| Step: 2
Training loss: 0.31914802878860404
Validation loss: 2.936804885324966

Epoch: 6| Step: 3
Training loss: 0.5166244069116097
Validation loss: 2.899349086432145

Epoch: 6| Step: 4
Training loss: 0.5113161556279682
Validation loss: 2.887058539173761

Epoch: 6| Step: 5
Training loss: 0.40315298530375065
Validation loss: 2.9369478315474593

Epoch: 6| Step: 6
Training loss: 0.4241709223810435
Validation loss: 2.8272875815823415

Epoch: 6| Step: 7
Training loss: 0.4050614135591063
Validation loss: 2.8144143406536055

Epoch: 6| Step: 8
Training loss: 0.31496898914762955
Validation loss: 2.7743335118249206

Epoch: 6| Step: 9
Training loss: 0.9464606256532098
Validation loss: 2.8362170765561503

Epoch: 6| Step: 10
Training loss: 0.30020289116788135
Validation loss: 2.8526444146311496

Epoch: 6| Step: 11
Training loss: 0.3459001076914842
Validation loss: 2.809738385748045

Epoch: 6| Step: 12
Training loss: 0.36756252859757976
Validation loss: 2.850013681568523

Epoch: 6| Step: 13
Training loss: 0.49349478028579674
Validation loss: 2.8434808345189264

Epoch: 205| Step: 0
Training loss: 0.2891394538515538
Validation loss: 2.877224324330716

Epoch: 6| Step: 1
Training loss: 0.41290896256795184
Validation loss: 2.8459123906724706

Epoch: 6| Step: 2
Training loss: 0.37017032775259273
Validation loss: 2.930889605264948

Epoch: 6| Step: 3
Training loss: 0.47676272954284415
Validation loss: 2.826217035874346

Epoch: 6| Step: 4
Training loss: 0.47609891387272324
Validation loss: 2.8685706991927695

Epoch: 6| Step: 5
Training loss: 0.29539903351832913
Validation loss: 2.9451736498414895

Epoch: 6| Step: 6
Training loss: 0.4726408175636693
Validation loss: 2.788603544540248

Epoch: 6| Step: 7
Training loss: 1.0373140122417035
Validation loss: 2.817722360478505

Epoch: 6| Step: 8
Training loss: 0.3680173546181904
Validation loss: 2.820426227111738

Epoch: 6| Step: 9
Training loss: 0.7648706807430558
Validation loss: 2.8226158479174157

Epoch: 6| Step: 10
Training loss: 0.38058880707493814
Validation loss: 2.8727092739063753

Epoch: 6| Step: 11
Training loss: 0.3458528140720837
Validation loss: 2.8848817561317444

Epoch: 6| Step: 12
Training loss: 0.30138921601536034
Validation loss: 2.8730587556006837

Epoch: 6| Step: 13
Training loss: 0.33693052611000196
Validation loss: 2.8071713867087422

Epoch: 206| Step: 0
Training loss: 0.5797692192448395
Validation loss: 2.8400207072608987

Epoch: 6| Step: 1
Training loss: 0.42519516811272023
Validation loss: 2.860467642940897

Epoch: 6| Step: 2
Training loss: 0.2791872409574265
Validation loss: 2.866980203034843

Epoch: 6| Step: 3
Training loss: 0.3567058081666548
Validation loss: 2.868331944097537

Epoch: 6| Step: 4
Training loss: 0.5314487197806005
Validation loss: 2.8268161646502996

Epoch: 6| Step: 5
Training loss: 0.9730278745286965
Validation loss: 2.8434052310751396

Epoch: 6| Step: 6
Training loss: 0.4326599995459923
Validation loss: 2.843480163739354

Epoch: 6| Step: 7
Training loss: 0.4005020730825769
Validation loss: 2.878885780651627

Epoch: 6| Step: 8
Training loss: 0.42208270858361924
Validation loss: 2.961948353071783

Epoch: 6| Step: 9
Training loss: 0.5363932881843531
Validation loss: 2.909412358935666

Epoch: 6| Step: 10
Training loss: 0.6116013084109465
Validation loss: 2.913013995743617

Epoch: 6| Step: 11
Training loss: 0.35258476193599264
Validation loss: 2.8871810467201953

Epoch: 6| Step: 12
Training loss: 0.35771259095745034
Validation loss: 2.82011181794544

Epoch: 6| Step: 13
Training loss: 0.34658448967339855
Validation loss: 2.8536061945542928

Epoch: 207| Step: 0
Training loss: 0.4644654922827956
Validation loss: 2.8384400282462194

Epoch: 6| Step: 1
Training loss: 0.40575488804324955
Validation loss: 2.9162584200749913

Epoch: 6| Step: 2
Training loss: 0.509585059915
Validation loss: 2.931475284597802

Epoch: 6| Step: 3
Training loss: 0.37496956065933007
Validation loss: 2.9146096105438537

Epoch: 6| Step: 4
Training loss: 0.4438989691454439
Validation loss: 2.8556648322750697

Epoch: 6| Step: 5
Training loss: 0.42609614355843933
Validation loss: 2.863976047762905

Epoch: 6| Step: 6
Training loss: 0.4227881262859608
Validation loss: 2.8951225826464757

Epoch: 6| Step: 7
Training loss: 0.9547994320147407
Validation loss: 2.888322865429939

Epoch: 6| Step: 8
Training loss: 0.5115542839103581
Validation loss: 2.8498338589567305

Epoch: 6| Step: 9
Training loss: 0.2680960049990702
Validation loss: 2.871114240300767

Epoch: 6| Step: 10
Training loss: 0.3805869864600384
Validation loss: 2.834766577070901

Epoch: 6| Step: 11
Training loss: 0.34886625365607565
Validation loss: 2.8178108652654528

Epoch: 6| Step: 12
Training loss: 0.6861583015448404
Validation loss: 2.869783063392182

Epoch: 6| Step: 13
Training loss: 0.3964092014249483
Validation loss: 2.8032980818314295

Epoch: 208| Step: 0
Training loss: 0.4857629763116173
Validation loss: 2.846864845880293

Epoch: 6| Step: 1
Training loss: 0.3103794030197145
Validation loss: 2.870597592342096

Epoch: 6| Step: 2
Training loss: 0.42128521701293875
Validation loss: 2.877033702984857

Epoch: 6| Step: 3
Training loss: 0.3755735541100974
Validation loss: 2.8524250554930606

Epoch: 6| Step: 4
Training loss: 0.268481463073025
Validation loss: 2.851910114438602

Epoch: 6| Step: 5
Training loss: 0.30008743819900596
Validation loss: 2.8958054731021385

Epoch: 6| Step: 6
Training loss: 0.9029779558691081
Validation loss: 2.837525230665247

Epoch: 6| Step: 7
Training loss: 0.6152564635171728
Validation loss: 2.8038584015891943

Epoch: 6| Step: 8
Training loss: 0.46665021755258806
Validation loss: 2.932792611749926

Epoch: 6| Step: 9
Training loss: 0.35250118823561366
Validation loss: 2.8609585849964874

Epoch: 6| Step: 10
Training loss: 0.3432236022189437
Validation loss: 2.872790856173524

Epoch: 6| Step: 11
Training loss: 0.29577703471940897
Validation loss: 2.787030759583486

Epoch: 6| Step: 12
Training loss: 0.6728466460071874
Validation loss: 2.859946619371505

Epoch: 6| Step: 13
Training loss: 0.26902665713618473
Validation loss: 2.8335564235671997

Epoch: 209| Step: 0
Training loss: 0.48765028813319483
Validation loss: 2.819480470344711

Epoch: 6| Step: 1
Training loss: 0.25960817082481974
Validation loss: 2.8339298031839437

Epoch: 6| Step: 2
Training loss: 0.2982244939745581
Validation loss: 2.8943240236963472

Epoch: 6| Step: 3
Training loss: 0.5290935731202246
Validation loss: 2.896833512366801

Epoch: 6| Step: 4
Training loss: 0.3689778286855776
Validation loss: 2.89574440927072

Epoch: 6| Step: 5
Training loss: 0.3970127062049379
Validation loss: 2.8901181025721043

Epoch: 6| Step: 6
Training loss: 0.3188639194143939
Validation loss: 2.9188532716396156

Epoch: 6| Step: 7
Training loss: 0.6677281576616759
Validation loss: 2.898346329700652

Epoch: 6| Step: 8
Training loss: 0.5030958475232331
Validation loss: 2.938376329799455

Epoch: 6| Step: 9
Training loss: 0.40609389753878394
Validation loss: 2.872299183487311

Epoch: 6| Step: 10
Training loss: 1.0261849369514493
Validation loss: 2.8512010597846404

Epoch: 6| Step: 11
Training loss: 0.404206528451228
Validation loss: 2.893888483654272

Epoch: 6| Step: 12
Training loss: 0.3396667918619787
Validation loss: 2.9195399482181674

Epoch: 6| Step: 13
Training loss: 0.3095365680389861
Validation loss: 2.861885261325639

Epoch: 210| Step: 0
Training loss: 0.41318646012756566
Validation loss: 2.898757766070593

Epoch: 6| Step: 1
Training loss: 0.4174891777691756
Validation loss: 2.8678814137516535

Epoch: 6| Step: 2
Training loss: 0.3859920223812564
Validation loss: 2.8895748533432966

Epoch: 6| Step: 3
Training loss: 0.5009469363727242
Validation loss: 2.8536913445808576

Epoch: 6| Step: 4
Training loss: 0.4864738123580038
Validation loss: 2.821803775647496

Epoch: 6| Step: 5
Training loss: 0.6060393321347592
Validation loss: 2.8128124487361643

Epoch: 6| Step: 6
Training loss: 0.3198735322862697
Validation loss: 2.8757476111029074

Epoch: 6| Step: 7
Training loss: 0.3862904189852956
Validation loss: 2.8080813842936334

Epoch: 6| Step: 8
Training loss: 0.3996275538749813
Validation loss: 2.8938014542884662

Epoch: 6| Step: 9
Training loss: 0.42876122946533296
Validation loss: 2.9561525867803105

Epoch: 6| Step: 10
Training loss: 0.5326999064308459
Validation loss: 2.9200051048094835

Epoch: 6| Step: 11
Training loss: 0.882208220684119
Validation loss: 2.8973080335762673

Epoch: 6| Step: 12
Training loss: 0.31143395265736556
Validation loss: 2.908476192241178

Epoch: 6| Step: 13
Training loss: 0.39828293738264015
Validation loss: 2.933707230392568

Epoch: 211| Step: 0
Training loss: 0.39941510711011013
Validation loss: 2.90424677128555

Epoch: 6| Step: 1
Training loss: 0.3171033597320668
Validation loss: 2.9116640831452387

Epoch: 6| Step: 2
Training loss: 0.40744375022029994
Validation loss: 2.885261026492984

Epoch: 6| Step: 3
Training loss: 0.9497893074699723
Validation loss: 2.913836472977973

Epoch: 6| Step: 4
Training loss: 0.4324151077361256
Validation loss: 2.8866937797130587

Epoch: 6| Step: 5
Training loss: 0.6127604563321675
Validation loss: 2.9469858369179507

Epoch: 6| Step: 6
Training loss: 0.37155873129098815
Validation loss: 2.8806807192131774

Epoch: 6| Step: 7
Training loss: 0.3292546581208178
Validation loss: 2.93922110113908

Epoch: 6| Step: 8
Training loss: 0.44314033710425593
Validation loss: 2.885511325610143

Epoch: 6| Step: 9
Training loss: 0.4472441355777631
Validation loss: 2.9633532410014807

Epoch: 6| Step: 10
Training loss: 0.439663188319128
Validation loss: 2.900069306082562

Epoch: 6| Step: 11
Training loss: 0.4234498265010106
Validation loss: 2.908903189268515

Epoch: 6| Step: 12
Training loss: 0.4530262017240806
Validation loss: 2.8689660317187453

Epoch: 6| Step: 13
Training loss: 0.3550094319823309
Validation loss: 2.871927872850088

Epoch: 212| Step: 0
Training loss: 0.5084518222866589
Validation loss: 2.865949316610829

Epoch: 6| Step: 1
Training loss: 0.44862048904838026
Validation loss: 2.8631803140027627

Epoch: 6| Step: 2
Training loss: 0.406847807390114
Validation loss: 2.8468339567439664

Epoch: 6| Step: 3
Training loss: 0.9039467448904064
Validation loss: 2.8790909230435666

Epoch: 6| Step: 4
Training loss: 0.4634431527140917
Validation loss: 2.930739679222219

Epoch: 6| Step: 5
Training loss: 0.41693852814170346
Validation loss: 2.9211073358272035

Epoch: 6| Step: 6
Training loss: 0.39356941593146116
Validation loss: 2.931375707168974

Epoch: 6| Step: 7
Training loss: 0.3410109612494475
Validation loss: 2.9433960147662117

Epoch: 6| Step: 8
Training loss: 0.29948387004089055
Validation loss: 2.835632602075245

Epoch: 6| Step: 9
Training loss: 0.42538787448578824
Validation loss: 2.875360770325982

Epoch: 6| Step: 10
Training loss: 0.5027497793829769
Validation loss: 2.8471890289935597

Epoch: 6| Step: 11
Training loss: 0.7179408286957225
Validation loss: 2.8474123780141043

Epoch: 6| Step: 12
Training loss: 0.37485994266646544
Validation loss: 2.886097525865607

Epoch: 6| Step: 13
Training loss: 0.4965887228665875
Validation loss: 2.9257592207618743

Epoch: 213| Step: 0
Training loss: 0.2831442278423369
Validation loss: 2.9220379734657196

Epoch: 6| Step: 1
Training loss: 0.32515563951954685
Validation loss: 2.9139209266342214

Epoch: 6| Step: 2
Training loss: 0.6010365602176093
Validation loss: 2.9134779711186707

Epoch: 6| Step: 3
Training loss: 0.342826828235538
Validation loss: 2.9006322209940216

Epoch: 6| Step: 4
Training loss: 0.3280911201061357
Validation loss: 2.8727831517417663

Epoch: 6| Step: 5
Training loss: 0.28506494392831117
Validation loss: 2.7987217977220813

Epoch: 6| Step: 6
Training loss: 0.271020053113675
Validation loss: 2.8664076920085755

Epoch: 6| Step: 7
Training loss: 0.5847796380473316
Validation loss: 2.7862875532537754

Epoch: 6| Step: 8
Training loss: 0.5245176529109191
Validation loss: 2.9177586464094496

Epoch: 6| Step: 9
Training loss: 0.33325586561204906
Validation loss: 2.823058351196311

Epoch: 6| Step: 10
Training loss: 0.5067005307347808
Validation loss: 2.9429454516636375

Epoch: 6| Step: 11
Training loss: 0.4825586904892431
Validation loss: 2.960313930961472

Epoch: 6| Step: 12
Training loss: 0.5066674159958384
Validation loss: 2.866777298884682

Epoch: 6| Step: 13
Training loss: 0.9937782751415328
Validation loss: 2.8629288536778046

Epoch: 214| Step: 0
Training loss: 0.3537296890520643
Validation loss: 2.8464149731524735

Epoch: 6| Step: 1
Training loss: 1.0585257870862546
Validation loss: 2.9096541481481495

Epoch: 6| Step: 2
Training loss: 0.40835958886236734
Validation loss: 2.8161298146164726

Epoch: 6| Step: 3
Training loss: 0.43417215001834797
Validation loss: 2.8769963285608147

Epoch: 6| Step: 4
Training loss: 0.24018439106315118
Validation loss: 2.878666309173206

Epoch: 6| Step: 5
Training loss: 0.24395395390374564
Validation loss: 2.843202747884452

Epoch: 6| Step: 6
Training loss: 0.3905513503262158
Validation loss: 2.83543102831617

Epoch: 6| Step: 7
Training loss: 0.3621661391718874
Validation loss: 2.865153146193476

Epoch: 6| Step: 8
Training loss: 0.4225718077181944
Validation loss: 2.877965310105713

Epoch: 6| Step: 9
Training loss: 0.3093496553077214
Validation loss: 2.831904925455775

Epoch: 6| Step: 10
Training loss: 0.33767572084675995
Validation loss: 2.956936712530143

Epoch: 6| Step: 11
Training loss: 0.49600915863441347
Validation loss: 2.9111072053308793

Epoch: 6| Step: 12
Training loss: 0.42652383845701985
Validation loss: 2.855099578942438

Epoch: 6| Step: 13
Training loss: 0.45550844206037394
Validation loss: 2.8350947365246157

Epoch: 215| Step: 0
Training loss: 0.466525809141377
Validation loss: 2.914687197954379

Epoch: 6| Step: 1
Training loss: 0.38919538197301506
Validation loss: 2.9188859035265478

Epoch: 6| Step: 2
Training loss: 0.5253529304681163
Validation loss: 2.8568825063841197

Epoch: 6| Step: 3
Training loss: 0.5046484161454902
Validation loss: 2.9077421206826526

Epoch: 6| Step: 4
Training loss: 0.3034662935677833
Validation loss: 2.947710688284034

Epoch: 6| Step: 5
Training loss: 0.3001971828623317
Validation loss: 2.8929263739624695

Epoch: 6| Step: 6
Training loss: 0.6859712075399758
Validation loss: 2.896520030067374

Epoch: 6| Step: 7
Training loss: 0.36403049606649923
Validation loss: 2.914663462506505

Epoch: 6| Step: 8
Training loss: 0.2905568596728785
Validation loss: 2.8974385420847995

Epoch: 6| Step: 9
Training loss: 0.8878180793498273
Validation loss: 2.8992122906717683

Epoch: 6| Step: 10
Training loss: 0.3431649973926608
Validation loss: 2.9452328253778663

Epoch: 6| Step: 11
Training loss: 0.34789849531761696
Validation loss: 2.9330913453820218

Epoch: 6| Step: 12
Training loss: 0.31169263735129304
Validation loss: 2.9109215329671314

Epoch: 6| Step: 13
Training loss: 0.3473180776316043
Validation loss: 2.98155451938089

Epoch: 216| Step: 0
Training loss: 0.4172013984108125
Validation loss: 2.942609212550707

Epoch: 6| Step: 1
Training loss: 0.30943278437723304
Validation loss: 2.9901429736891547

Epoch: 6| Step: 2
Training loss: 0.31368678759402596
Validation loss: 2.8403942583776463

Epoch: 6| Step: 3
Training loss: 0.4380960831506893
Validation loss: 2.863637321783018

Epoch: 6| Step: 4
Training loss: 0.9240984208753056
Validation loss: 2.875415923951296

Epoch: 6| Step: 5
Training loss: 0.3762370210607844
Validation loss: 2.900613932463438

Epoch: 6| Step: 6
Training loss: 0.37652324218618294
Validation loss: 2.935119191662537

Epoch: 6| Step: 7
Training loss: 0.43079656175943276
Validation loss: 2.956739121473586

Epoch: 6| Step: 8
Training loss: 0.4666506646029674
Validation loss: 2.9412705996821864

Epoch: 6| Step: 9
Training loss: 0.5927460866836731
Validation loss: 2.983365072759935

Epoch: 6| Step: 10
Training loss: 0.38613118705349503
Validation loss: 2.853358486130034

Epoch: 6| Step: 11
Training loss: 0.2964321648384839
Validation loss: 2.915572674258917

Epoch: 6| Step: 12
Training loss: 0.6523322829649195
Validation loss: 2.887492831883196

Epoch: 6| Step: 13
Training loss: 0.7078434615279229
Validation loss: 2.8933926503814886

Epoch: 217| Step: 0
Training loss: 0.39715922758502176
Validation loss: 2.8911882556260164

Epoch: 6| Step: 1
Training loss: 0.4118789824320743
Validation loss: 2.9317007785075444

Epoch: 6| Step: 2
Training loss: 0.704482061716806
Validation loss: 2.986726137644879

Epoch: 6| Step: 3
Training loss: 0.29323090586081585
Validation loss: 2.898041786401565

Epoch: 6| Step: 4
Training loss: 0.43175945113594244
Validation loss: 2.92742137834852

Epoch: 6| Step: 5
Training loss: 0.39301947082450517
Validation loss: 2.9250668857676048

Epoch: 6| Step: 6
Training loss: 0.33497532849774375
Validation loss: 2.908719329759719

Epoch: 6| Step: 7
Training loss: 0.4636910194359046
Validation loss: 2.855905509001802

Epoch: 6| Step: 8
Training loss: 0.2321213694926888
Validation loss: 2.8693111915171317

Epoch: 6| Step: 9
Training loss: 0.44156687691821445
Validation loss: 2.797612680797038

Epoch: 6| Step: 10
Training loss: 0.4668148787470171
Validation loss: 2.8560161352930624

Epoch: 6| Step: 11
Training loss: 0.43285149973529863
Validation loss: 2.89104871651477

Epoch: 6| Step: 12
Training loss: 0.9209995315418026
Validation loss: 2.8907223659304018

Epoch: 6| Step: 13
Training loss: 0.33530459555546416
Validation loss: 2.911241886143442

Epoch: 218| Step: 0
Training loss: 0.4465737467818429
Validation loss: 2.922723344394549

Epoch: 6| Step: 1
Training loss: 0.38010819522977063
Validation loss: 2.950227247526421

Epoch: 6| Step: 2
Training loss: 0.34907997796229495
Validation loss: 2.9127116408830775

Epoch: 6| Step: 3
Training loss: 0.326372427587259
Validation loss: 2.902345584613807

Epoch: 6| Step: 4
Training loss: 0.3678758742930956
Validation loss: 2.9010495517333625

Epoch: 6| Step: 5
Training loss: 0.49363382457554844
Validation loss: 2.885407862093239

Epoch: 6| Step: 6
Training loss: 0.4395681273133946
Validation loss: 2.878883613625107

Epoch: 6| Step: 7
Training loss: 1.0797621970277191
Validation loss: 2.8710767680593654

Epoch: 6| Step: 8
Training loss: 0.3565730244974769
Validation loss: 2.8900198706875444

Epoch: 6| Step: 9
Training loss: 0.43674579393319113
Validation loss: 2.867906624039634

Epoch: 6| Step: 10
Training loss: 0.3577209847037958
Validation loss: 2.9042423519377403

Epoch: 6| Step: 11
Training loss: 0.37887364670006163
Validation loss: 2.878545744575247

Epoch: 6| Step: 12
Training loss: 0.33557586278258134
Validation loss: 2.924698103298462

Epoch: 6| Step: 13
Training loss: 0.3057444408875184
Validation loss: 2.90588871614193

Epoch: 219| Step: 0
Training loss: 0.5319068438346968
Validation loss: 2.8554855603629097

Epoch: 6| Step: 1
Training loss: 0.29988734444735077
Validation loss: 2.8023506424663753

Epoch: 6| Step: 2
Training loss: 0.2772189652088729
Validation loss: 2.9107979359309684

Epoch: 6| Step: 3
Training loss: 0.33992144913187533
Validation loss: 2.8532260170776533

Epoch: 6| Step: 4
Training loss: 0.31779720543412315
Validation loss: 2.877610983631926

Epoch: 6| Step: 5
Training loss: 0.5960332237302575
Validation loss: 2.874420190477899

Epoch: 6| Step: 6
Training loss: 0.3470480667567133
Validation loss: 2.8593471365927745

Epoch: 6| Step: 7
Training loss: 0.3605553689040877
Validation loss: 2.847834982231935

Epoch: 6| Step: 8
Training loss: 0.4292741347755802
Validation loss: 2.7951612709892095

Epoch: 6| Step: 9
Training loss: 0.3293429884293233
Validation loss: 2.8678244732942155

Epoch: 6| Step: 10
Training loss: 0.48642395791165993
Validation loss: 2.8411618636413616

Epoch: 6| Step: 11
Training loss: 0.30375818210146743
Validation loss: 2.9112391835797014

Epoch: 6| Step: 12
Training loss: 0.45838801823571884
Validation loss: 2.9423194470753335

Epoch: 6| Step: 13
Training loss: 0.9627415230159171
Validation loss: 2.8536597913268533

Epoch: 220| Step: 0
Training loss: 0.29174291374766453
Validation loss: 2.8973411275574774

Epoch: 6| Step: 1
Training loss: 0.44276268756270476
Validation loss: 2.863896267886871

Epoch: 6| Step: 2
Training loss: 1.0624424974925515
Validation loss: 2.924397649446987

Epoch: 6| Step: 3
Training loss: 0.5382840991117819
Validation loss: 2.9103259419031438

Epoch: 6| Step: 4
Training loss: 0.29043550722798356
Validation loss: 2.9061438428297532

Epoch: 6| Step: 5
Training loss: 0.38595625333744776
Validation loss: 2.868883301872876

Epoch: 6| Step: 6
Training loss: 0.4005632354091513
Validation loss: 2.940142572431992

Epoch: 6| Step: 7
Training loss: 0.5153498059724765
Validation loss: 2.9040030130023933

Epoch: 6| Step: 8
Training loss: 0.433066846981245
Validation loss: 2.8764512642331743

Epoch: 6| Step: 9
Training loss: 0.27978048270751016
Validation loss: 2.85946952510718

Epoch: 6| Step: 10
Training loss: 0.39297467221600046
Validation loss: 2.909359775589425

Epoch: 6| Step: 11
Training loss: 0.3277211883401831
Validation loss: 2.9109250821749497

Epoch: 6| Step: 12
Training loss: 0.3574920543708004
Validation loss: 2.975222802567841

Epoch: 6| Step: 13
Training loss: 0.33839582700932314
Validation loss: 2.9106174180397133

Epoch: 221| Step: 0
Training loss: 0.3448351183918536
Validation loss: 2.900012428980534

Epoch: 6| Step: 1
Training loss: 0.41133855532964264
Validation loss: 2.8849596058636253

Epoch: 6| Step: 2
Training loss: 0.45481445794773795
Validation loss: 2.9281950137175965

Epoch: 6| Step: 3
Training loss: 0.844123792855614
Validation loss: 2.8190294554363344

Epoch: 6| Step: 4
Training loss: 0.45939857785706867
Validation loss: 2.8632923939597754

Epoch: 6| Step: 5
Training loss: 0.29890327505973313
Validation loss: 2.8775696673274265

Epoch: 6| Step: 6
Training loss: 0.36183201476907756
Validation loss: 2.960435313077257

Epoch: 6| Step: 7
Training loss: 0.3935428551345793
Validation loss: 2.9788208251677992

Epoch: 6| Step: 8
Training loss: 0.29034432168012714
Validation loss: 2.8378262286089906

Epoch: 6| Step: 9
Training loss: 0.37851643911614674
Validation loss: 2.898359957443482

Epoch: 6| Step: 10
Training loss: 0.407515571916892
Validation loss: 2.8932044128036583

Epoch: 6| Step: 11
Training loss: 0.6879484924549969
Validation loss: 2.8241201606028805

Epoch: 6| Step: 12
Training loss: 0.348839364719755
Validation loss: 2.806923303635144

Epoch: 6| Step: 13
Training loss: 0.4051500983015777
Validation loss: 2.85352403594685

Epoch: 222| Step: 0
Training loss: 0.3566812439900119
Validation loss: 2.8512483676346596

Epoch: 6| Step: 1
Training loss: 0.3921679731272411
Validation loss: 2.9105597913898578

Epoch: 6| Step: 2
Training loss: 0.46135950974986234
Validation loss: 2.8973299088362032

Epoch: 6| Step: 3
Training loss: 0.3278901417683005
Validation loss: 2.9545234450385243

Epoch: 6| Step: 4
Training loss: 0.2970861136041976
Validation loss: 2.9221827027106713

Epoch: 6| Step: 5
Training loss: 0.9704562819341304
Validation loss: 2.8660270566947585

Epoch: 6| Step: 6
Training loss: 0.3439630368467779
Validation loss: 2.8965403610789853

Epoch: 6| Step: 7
Training loss: 0.44666403078729616
Validation loss: 2.9344866697860423

Epoch: 6| Step: 8
Training loss: 0.4072340637540724
Validation loss: 2.923925295811758

Epoch: 6| Step: 9
Training loss: 0.4212177065857536
Validation loss: 2.7863568629152757

Epoch: 6| Step: 10
Training loss: 0.3787371857996521
Validation loss: 2.8875369373727806

Epoch: 6| Step: 11
Training loss: 0.5003438601651856
Validation loss: 2.930081150311209

Epoch: 6| Step: 12
Training loss: 0.44103726856787934
Validation loss: 2.8950710711323038

Epoch: 6| Step: 13
Training loss: 0.36376230117474145
Validation loss: 2.9011704138375505

Epoch: 223| Step: 0
Training loss: 0.25831115067261334
Validation loss: 2.8743412672942945

Epoch: 6| Step: 1
Training loss: 0.45503847006720666
Validation loss: 2.863701165508737

Epoch: 6| Step: 2
Training loss: 0.6709286878670738
Validation loss: 2.8244299591990925

Epoch: 6| Step: 3
Training loss: 0.8329977949463601
Validation loss: 2.9068003307751265

Epoch: 6| Step: 4
Training loss: 0.6065181375167439
Validation loss: 2.9514092266404273

Epoch: 6| Step: 5
Training loss: 0.34058229721194233
Validation loss: 2.940442349919632

Epoch: 6| Step: 6
Training loss: 0.33505794799706884
Validation loss: 2.9120824937541316

Epoch: 6| Step: 7
Training loss: 0.2832075973683767
Validation loss: 2.7902395861539313

Epoch: 6| Step: 8
Training loss: 0.28200480054428445
Validation loss: 2.877036637947707

Epoch: 6| Step: 9
Training loss: 0.32859065302442814
Validation loss: 2.836359502326958

Epoch: 6| Step: 10
Training loss: 0.43781987485589596
Validation loss: 2.949261366513113

Epoch: 6| Step: 11
Training loss: 0.5139098685796266
Validation loss: 2.8791562872854604

Epoch: 6| Step: 12
Training loss: 0.2642198449354083
Validation loss: 2.8200535113756433

Epoch: 6| Step: 13
Training loss: 0.3939987592701813
Validation loss: 2.8943632543000555

Epoch: 224| Step: 0
Training loss: 0.37062432564067765
Validation loss: 2.933440399564033

Epoch: 6| Step: 1
Training loss: 0.6352038470049661
Validation loss: 2.924933629492025

Epoch: 6| Step: 2
Training loss: 0.4759841912072667
Validation loss: 2.982338961431547

Epoch: 6| Step: 3
Training loss: 0.5224163285935505
Validation loss: 2.9376162648019783

Epoch: 6| Step: 4
Training loss: 0.3421061832882789
Validation loss: 2.866734662099741

Epoch: 6| Step: 5
Training loss: 0.4772229698953309
Validation loss: 2.847499778575626

Epoch: 6| Step: 6
Training loss: 0.448559534434869
Validation loss: 2.916774725047623

Epoch: 6| Step: 7
Training loss: 0.4541357540261165
Validation loss: 2.856524869240219

Epoch: 6| Step: 8
Training loss: 0.8529803170843469
Validation loss: 2.8691087430598303

Epoch: 6| Step: 9
Training loss: 0.45726273046138227
Validation loss: 2.8785548830351293

Epoch: 6| Step: 10
Training loss: 0.2950979300981251
Validation loss: 2.8874214635079567

Epoch: 6| Step: 11
Training loss: 0.2840690528525077
Validation loss: 3.013220808711874

Epoch: 6| Step: 12
Training loss: 0.4844405837420422
Validation loss: 2.9433849040820474

Epoch: 6| Step: 13
Training loss: 0.49472474264660316
Validation loss: 2.9045942368496767

Epoch: 225| Step: 0
Training loss: 0.25822730362376406
Validation loss: 2.860737397859301

Epoch: 6| Step: 1
Training loss: 0.4569127834054635
Validation loss: 2.8546218973106097

Epoch: 6| Step: 2
Training loss: 0.4477330726094724
Validation loss: 2.8373217186397275

Epoch: 6| Step: 3
Training loss: 0.9418630797423533
Validation loss: 2.7854933924772656

Epoch: 6| Step: 4
Training loss: 0.3050561044636491
Validation loss: 2.892735070249364

Epoch: 6| Step: 5
Training loss: 0.5937625482136726
Validation loss: 2.8822549144596983

Epoch: 6| Step: 6
Training loss: 0.39559033321824916
Validation loss: 2.8824764010987205

Epoch: 6| Step: 7
Training loss: 0.3094813462707812
Validation loss: 2.859219836974143

Epoch: 6| Step: 8
Training loss: 0.33873196413090273
Validation loss: 2.909867568066824

Epoch: 6| Step: 9
Training loss: 0.42690342703761963
Validation loss: 2.851487403473023

Epoch: 6| Step: 10
Training loss: 0.3875290828989074
Validation loss: 2.86605154154224

Epoch: 6| Step: 11
Training loss: 0.3189469047174931
Validation loss: 2.766221968021391

Epoch: 6| Step: 12
Training loss: 0.4175035615300839
Validation loss: 2.879024487659264

Epoch: 6| Step: 13
Training loss: 0.4299328190420747
Validation loss: 2.8336137371061247

Epoch: 226| Step: 0
Training loss: 0.41816159728248736
Validation loss: 2.865551085716582

Epoch: 6| Step: 1
Training loss: 0.2780595327327462
Validation loss: 2.8749853976887825

Epoch: 6| Step: 2
Training loss: 0.3781611795692818
Validation loss: 2.939197868002736

Epoch: 6| Step: 3
Training loss: 0.39707631989910386
Validation loss: 2.8635449324934177

Epoch: 6| Step: 4
Training loss: 0.7967856862000449
Validation loss: 2.9151114041091652

Epoch: 6| Step: 5
Training loss: 0.38952500914812427
Validation loss: 2.9298106121051153

Epoch: 6| Step: 6
Training loss: 0.4099656161567902
Validation loss: 2.930257404421425

Epoch: 6| Step: 7
Training loss: 0.45645884998570285
Validation loss: 2.9406588053474634

Epoch: 6| Step: 8
Training loss: 0.3835946869693042
Validation loss: 2.9271399378252787

Epoch: 6| Step: 9
Training loss: 0.4594340292963364
Validation loss: 2.910728162854453

Epoch: 6| Step: 10
Training loss: 0.33063464678877047
Validation loss: 2.802979468994581

Epoch: 6| Step: 11
Training loss: 0.3561304033873049
Validation loss: 2.9282403245360746

Epoch: 6| Step: 12
Training loss: 0.32082321576270567
Validation loss: 2.9231637570672833

Epoch: 6| Step: 13
Training loss: 0.5303541371460808
Validation loss: 2.9976674654739806

Epoch: 227| Step: 0
Training loss: 0.4266055815463473
Validation loss: 2.93669590867978

Epoch: 6| Step: 1
Training loss: 0.2789018144441837
Validation loss: 2.9243086473318827

Epoch: 6| Step: 2
Training loss: 0.7905890550848322
Validation loss: 2.907915847966963

Epoch: 6| Step: 3
Training loss: 0.3526471994512198
Validation loss: 2.846144258670692

Epoch: 6| Step: 4
Training loss: 0.3462088059974468
Validation loss: 2.9372570938430327

Epoch: 6| Step: 5
Training loss: 0.241144395059096
Validation loss: 2.9998980213422533

Epoch: 6| Step: 6
Training loss: 0.3914816237493614
Validation loss: 2.9447454687506243

Epoch: 6| Step: 7
Training loss: 0.5242991969864753
Validation loss: 2.9102789321744527

Epoch: 6| Step: 8
Training loss: 0.5626388484400595
Validation loss: 2.928974359818821

Epoch: 6| Step: 9
Training loss: 0.4650777500278596
Validation loss: 2.9372033855486084

Epoch: 6| Step: 10
Training loss: 0.55396613374373
Validation loss: 2.833917828652059

Epoch: 6| Step: 11
Training loss: 0.3469369283158436
Validation loss: 2.9393269829704893

Epoch: 6| Step: 12
Training loss: 0.3680141963552828
Validation loss: 2.9268265381886898

Epoch: 6| Step: 13
Training loss: 0.4896892693395729
Validation loss: 2.9054036429156302

Epoch: 228| Step: 0
Training loss: 0.3693424056851976
Validation loss: 2.8835186873010628

Epoch: 6| Step: 1
Training loss: 0.23162767010594437
Validation loss: 2.9292323865251078

Epoch: 6| Step: 2
Training loss: 0.24999856948443264
Validation loss: 2.8731332606457634

Epoch: 6| Step: 3
Training loss: 0.9288422725324222
Validation loss: 2.893362381572491

Epoch: 6| Step: 4
Training loss: 0.5056155290883677
Validation loss: 2.9264437065990987

Epoch: 6| Step: 5
Training loss: 0.44162064805897644
Validation loss: 2.9034719554802972

Epoch: 6| Step: 6
Training loss: 0.22382676155780193
Validation loss: 2.907861611404035

Epoch: 6| Step: 7
Training loss: 0.37051740361469954
Validation loss: 2.9161521503216323

Epoch: 6| Step: 8
Training loss: 0.33989523355164347
Validation loss: 2.909543758514516

Epoch: 6| Step: 9
Training loss: 0.3740021423173939
Validation loss: 2.86596510881924

Epoch: 6| Step: 10
Training loss: 0.5577989272061137
Validation loss: 2.817223644112886

Epoch: 6| Step: 11
Training loss: 0.39621413468706274
Validation loss: 2.879586196858984

Epoch: 6| Step: 12
Training loss: 0.4487329592962543
Validation loss: 2.8496685409765816

Epoch: 6| Step: 13
Training loss: 0.2263588977049541
Validation loss: 2.8955654779688538

Epoch: 229| Step: 0
Training loss: 0.4256914201521502
Validation loss: 2.8861561641250533

Epoch: 6| Step: 1
Training loss: 0.3259061541895973
Validation loss: 2.8774317394857842

Epoch: 6| Step: 2
Training loss: 0.2989338083320402
Validation loss: 2.8827498927981057

Epoch: 6| Step: 3
Training loss: 0.3168802360989896
Validation loss: 2.9525734388029123

Epoch: 6| Step: 4
Training loss: 0.43150166825163183
Validation loss: 2.8944648463928857

Epoch: 6| Step: 5
Training loss: 0.3144303070698433
Validation loss: 2.896599487568982

Epoch: 6| Step: 6
Training loss: 0.3599751271490115
Validation loss: 2.8565495607312363

Epoch: 6| Step: 7
Training loss: 0.3671716321397888
Validation loss: 2.8426755195718987

Epoch: 6| Step: 8
Training loss: 0.3830550067932413
Validation loss: 2.8858232498617

Epoch: 6| Step: 9
Training loss: 0.7928390020948755
Validation loss: 2.8203611642684443

Epoch: 6| Step: 10
Training loss: 0.5685369207711338
Validation loss: 2.879606081659715

Epoch: 6| Step: 11
Training loss: 0.23787197547308797
Validation loss: 2.9139001850539143

Epoch: 6| Step: 12
Training loss: 0.4738827075638342
Validation loss: 2.9332133324598284

Epoch: 6| Step: 13
Training loss: 0.35618636248879326
Validation loss: 2.920459343171202

Epoch: 230| Step: 0
Training loss: 0.3735856165493157
Validation loss: 2.937025248263033

Epoch: 6| Step: 1
Training loss: 0.3200505511394893
Validation loss: 2.8455400736571033

Epoch: 6| Step: 2
Training loss: 0.8834114406049559
Validation loss: 2.8380995146500347

Epoch: 6| Step: 3
Training loss: 0.6183766124681956
Validation loss: 2.8586268740438827

Epoch: 6| Step: 4
Training loss: 0.3578870279247532
Validation loss: 2.87633549728545

Epoch: 6| Step: 5
Training loss: 0.3689012104289629
Validation loss: 2.855468680420478

Epoch: 6| Step: 6
Training loss: 0.2922558949229236
Validation loss: 2.89217858707285

Epoch: 6| Step: 7
Training loss: 0.27125281468702167
Validation loss: 2.8362093848566152

Epoch: 6| Step: 8
Training loss: 0.3191141880996537
Validation loss: 2.925640026397027

Epoch: 6| Step: 9
Training loss: 0.3817117981935453
Validation loss: 2.869532264759837

Epoch: 6| Step: 10
Training loss: 0.39955649599373466
Validation loss: 2.8683092935394443

Epoch: 6| Step: 11
Training loss: 0.3313353482542681
Validation loss: 2.8492145225550023

Epoch: 6| Step: 12
Training loss: 0.2838523526381644
Validation loss: 2.845965867053881

Epoch: 6| Step: 13
Training loss: 0.29330601670443834
Validation loss: 2.779017992251275

Epoch: 231| Step: 0
Training loss: 0.38239939451139787
Validation loss: 2.884478576056893

Epoch: 6| Step: 1
Training loss: 0.4179210457361627
Validation loss: 2.834039338356856

Epoch: 6| Step: 2
Training loss: 0.4471347734035278
Validation loss: 2.8324994281208196

Epoch: 6| Step: 3
Training loss: 0.6872276286802801
Validation loss: 2.8839920580508136

Epoch: 6| Step: 4
Training loss: 0.3115999133910572
Validation loss: 2.952625171808495

Epoch: 6| Step: 5
Training loss: 0.33951857784127765
Validation loss: 2.894757109704926

Epoch: 6| Step: 6
Training loss: 0.770756902428083
Validation loss: 2.9633603076829926

Epoch: 6| Step: 7
Training loss: 0.5282327011713318
Validation loss: 2.9237747680171657

Epoch: 6| Step: 8
Training loss: 0.2655880004694966
Validation loss: 2.9018378999929144

Epoch: 6| Step: 9
Training loss: 0.33571852711053457
Validation loss: 2.8343375380513764

Epoch: 6| Step: 10
Training loss: 0.43061125900867975
Validation loss: 2.9075978547847052

Epoch: 6| Step: 11
Training loss: 0.4890443103807987
Validation loss: 2.9316391611317965

Epoch: 6| Step: 12
Training loss: 0.3783969208801252
Validation loss: 2.895602681330373

Epoch: 6| Step: 13
Training loss: 0.27196478019007797
Validation loss: 2.9221944787296317

Epoch: 232| Step: 0
Training loss: 0.6844102179815177
Validation loss: 2.964382103859126

Epoch: 6| Step: 1
Training loss: 0.6155777230481121
Validation loss: 2.9269592467011156

Epoch: 6| Step: 2
Training loss: 0.6682484359123515
Validation loss: 2.902391983528205

Epoch: 6| Step: 3
Training loss: 0.9086605109815349
Validation loss: 2.92629795239949

Epoch: 6| Step: 4
Training loss: 0.4865452844591364
Validation loss: 2.8700824504842926

Epoch: 6| Step: 5
Training loss: 0.5818905244225238
Validation loss: 2.8461726562105776

Epoch: 6| Step: 6
Training loss: 0.5028015566074187
Validation loss: 2.8696237273789125

Epoch: 6| Step: 7
Training loss: 0.30164075636545923
Validation loss: 2.8996402818828804

Epoch: 6| Step: 8
Training loss: 0.39806460714478775
Validation loss: 2.918340302710832

Epoch: 6| Step: 9
Training loss: 0.673243526128728
Validation loss: 2.912552702376436

Epoch: 6| Step: 10
Training loss: 0.46927475167295796
Validation loss: 2.9652556751826102

Epoch: 6| Step: 11
Training loss: 0.4468264026493264
Validation loss: 2.9350564546587337

Epoch: 6| Step: 12
Training loss: 0.43340501887725397
Validation loss: 2.8565772845003163

Epoch: 6| Step: 13
Training loss: 0.5681999481082988
Validation loss: 2.9103401211334767

Epoch: 233| Step: 0
Training loss: 0.782126621524495
Validation loss: 2.8257223921694483

Epoch: 6| Step: 1
Training loss: 0.3378999631616674
Validation loss: 2.793552108344196

Epoch: 6| Step: 2
Training loss: 0.428961035698482
Validation loss: 2.8863080205271814

Epoch: 6| Step: 3
Training loss: 0.3466945913630404
Validation loss: 2.8646233203293368

Epoch: 6| Step: 4
Training loss: 0.4104636175955072
Validation loss: 2.95192998426345

Epoch: 6| Step: 5
Training loss: 0.3533075046695654
Validation loss: 2.911312015430357

Epoch: 6| Step: 6
Training loss: 0.5294278253818109
Validation loss: 2.933865198951772

Epoch: 6| Step: 7
Training loss: 0.48521627156222946
Validation loss: 2.9773163996327523

Epoch: 6| Step: 8
Training loss: 0.7962958905636282
Validation loss: 2.8790494761560064

Epoch: 6| Step: 9
Training loss: 0.33864905292564984
Validation loss: 2.8480943465785926

Epoch: 6| Step: 10
Training loss: 0.343126967829219
Validation loss: 2.8537987149336326

Epoch: 6| Step: 11
Training loss: 0.43360440352814994
Validation loss: 2.85652422934522

Epoch: 6| Step: 12
Training loss: 0.3449697204273479
Validation loss: 2.822368052382779

Epoch: 6| Step: 13
Training loss: 0.5060525179322884
Validation loss: 2.881083051543491

Epoch: 234| Step: 0
Training loss: 0.4359603253750209
Validation loss: 2.8689759209128667

Epoch: 6| Step: 1
Training loss: 0.407797543481628
Validation loss: 2.910705419009247

Epoch: 6| Step: 2
Training loss: 0.43068793613410095
Validation loss: 2.9684500827208717

Epoch: 6| Step: 3
Training loss: 0.5034333605036694
Validation loss: 2.9591915649796077

Epoch: 6| Step: 4
Training loss: 0.4042000032552335
Validation loss: 2.9216786554906244

Epoch: 6| Step: 5
Training loss: 0.3626774517996456
Validation loss: 2.9028478828940614

Epoch: 6| Step: 6
Training loss: 0.29159332386394937
Validation loss: 2.8709192893379183

Epoch: 6| Step: 7
Training loss: 0.5325374430266162
Validation loss: 2.9225130931385825

Epoch: 6| Step: 8
Training loss: 0.788099853695286
Validation loss: 2.8234941846642294

Epoch: 6| Step: 9
Training loss: 0.3417368263902168
Validation loss: 2.8889631976042223

Epoch: 6| Step: 10
Training loss: 0.2962699798494079
Validation loss: 2.866188866326151

Epoch: 6| Step: 11
Training loss: 0.2917879596047842
Validation loss: 2.857605405672876

Epoch: 6| Step: 12
Training loss: 0.27914475252957827
Validation loss: 2.8410211961764062

Epoch: 6| Step: 13
Training loss: 0.3518953760762291
Validation loss: 2.9125559630904516

Epoch: 235| Step: 0
Training loss: 0.4059994365025824
Validation loss: 2.857438715591572

Epoch: 6| Step: 1
Training loss: 0.48031703755724126
Validation loss: 2.905839268910157

Epoch: 6| Step: 2
Training loss: 0.38358041075842364
Validation loss: 2.929436485557356

Epoch: 6| Step: 3
Training loss: 0.4335551889129497
Validation loss: 2.8974540118083376

Epoch: 6| Step: 4
Training loss: 0.830507198961671
Validation loss: 2.831246523823404

Epoch: 6| Step: 5
Training loss: 0.30168689277102584
Validation loss: 2.9042265079048715

Epoch: 6| Step: 6
Training loss: 0.5547566437944442
Validation loss: 2.9512698554674826

Epoch: 6| Step: 7
Training loss: 0.5634190151506255
Validation loss: 2.796476111924035

Epoch: 6| Step: 8
Training loss: 0.585257224320672
Validation loss: 2.981514523524688

Epoch: 6| Step: 9
Training loss: 0.7099536753706771
Validation loss: 2.987249511262398

Epoch: 6| Step: 10
Training loss: 0.4303441665289502
Validation loss: 2.8895492201489583

Epoch: 6| Step: 11
Training loss: 0.3146258051835049
Validation loss: 2.9346288352542937

Epoch: 6| Step: 12
Training loss: 0.40508652018986135
Validation loss: 2.8322333743873243

Epoch: 6| Step: 13
Training loss: 0.381493475823218
Validation loss: 2.9038150253382895

Epoch: 236| Step: 0
Training loss: 0.3175058097195176
Validation loss: 2.804198085123327

Epoch: 6| Step: 1
Training loss: 0.45943824566243646
Validation loss: 2.8192403768551264

Epoch: 6| Step: 2
Training loss: 0.45911181689413605
Validation loss: 2.7967183017700163

Epoch: 6| Step: 3
Training loss: 0.2954693443336743
Validation loss: 2.895032872687044

Epoch: 6| Step: 4
Training loss: 0.7338826172410131
Validation loss: 2.941832087317062

Epoch: 6| Step: 5
Training loss: 0.2627320671604056
Validation loss: 2.9618216128185466

Epoch: 6| Step: 6
Training loss: 0.5262679535528373
Validation loss: 2.9826578522803335

Epoch: 6| Step: 7
Training loss: 0.5339852769086431
Validation loss: 2.989399393694485

Epoch: 6| Step: 8
Training loss: 0.31483038786369716
Validation loss: 2.933913753984999

Epoch: 6| Step: 9
Training loss: 0.48913750911171694
Validation loss: 2.8974723545694236

Epoch: 6| Step: 10
Training loss: 0.5211229822289485
Validation loss: 2.9123053276916298

Epoch: 6| Step: 11
Training loss: 0.5208716632726073
Validation loss: 2.8387357499618684

Epoch: 6| Step: 12
Training loss: 0.6098657246060443
Validation loss: 2.870069200742586

Epoch: 6| Step: 13
Training loss: 0.4169853799518879
Validation loss: 2.8926702875793238

Epoch: 237| Step: 0
Training loss: 0.3717985988319675
Validation loss: 2.9496370873580573

Epoch: 6| Step: 1
Training loss: 0.41207921790114493
Validation loss: 3.014279501858428

Epoch: 6| Step: 2
Training loss: 0.5564623630920005
Validation loss: 2.9754973313756543

Epoch: 6| Step: 3
Training loss: 0.5232280482951637
Validation loss: 2.895840573930722

Epoch: 6| Step: 4
Training loss: 0.7599005493547613
Validation loss: 2.906659593055879

Epoch: 6| Step: 5
Training loss: 0.3638759380604988
Validation loss: 2.8721878838797408

Epoch: 6| Step: 6
Training loss: 0.5049067183540383
Validation loss: 2.8478143732712264

Epoch: 6| Step: 7
Training loss: 0.36620825194327794
Validation loss: 2.7664654562833273

Epoch: 6| Step: 8
Training loss: 0.5994618883689288
Validation loss: 2.8453740942298786

Epoch: 6| Step: 9
Training loss: 0.385909785306471
Validation loss: 2.821308696216802

Epoch: 6| Step: 10
Training loss: 0.48556489304910205
Validation loss: 2.870637652441738

Epoch: 6| Step: 11
Training loss: 0.4952447941230631
Validation loss: 2.8669477565224573

Epoch: 6| Step: 12
Training loss: 0.2646957721115675
Validation loss: 2.9016538940782532

Epoch: 6| Step: 13
Training loss: 0.29509334758249167
Validation loss: 2.8794620137929137

Epoch: 238| Step: 0
Training loss: 0.31169684435902584
Validation loss: 2.8716251357299134

Epoch: 6| Step: 1
Training loss: 0.3652324574466081
Validation loss: 2.8593360050509418

Epoch: 6| Step: 2
Training loss: 0.3746368517459936
Validation loss: 2.826176528909257

Epoch: 6| Step: 3
Training loss: 0.3647855152647757
Validation loss: 2.83747025080699

Epoch: 6| Step: 4
Training loss: 0.2700084663317634
Validation loss: 2.8600689822327507

Epoch: 6| Step: 5
Training loss: 0.28584144521459476
Validation loss: 2.8432010288433625

Epoch: 6| Step: 6
Training loss: 0.41598383464146965
Validation loss: 2.85410966375375

Epoch: 6| Step: 7
Training loss: 0.5935946060419499
Validation loss: 2.9524339678101827

Epoch: 6| Step: 8
Training loss: 0.5029612707202344
Validation loss: 2.877013234125398

Epoch: 6| Step: 9
Training loss: 0.7819616890837636
Validation loss: 2.9236249664131364

Epoch: 6| Step: 10
Training loss: 0.317334121490416
Validation loss: 2.904079378659779

Epoch: 6| Step: 11
Training loss: 0.40835927869475597
Validation loss: 2.873151461324711

Epoch: 6| Step: 12
Training loss: 0.42318074933933897
Validation loss: 2.8894026087594966

Epoch: 6| Step: 13
Training loss: 0.4487872165665543
Validation loss: 2.8857878894919895

Epoch: 239| Step: 0
Training loss: 0.31691416252000176
Validation loss: 2.8681090395858737

Epoch: 6| Step: 1
Training loss: 0.8526840174122313
Validation loss: 2.849821993081779

Epoch: 6| Step: 2
Training loss: 0.5085282490121972
Validation loss: 2.861908851340579

Epoch: 6| Step: 3
Training loss: 0.37909157143840183
Validation loss: 2.85867121639204

Epoch: 6| Step: 4
Training loss: 0.3943447200860857
Validation loss: 2.931554025094841

Epoch: 6| Step: 5
Training loss: 0.42731211124997814
Validation loss: 2.9147783070141933

Epoch: 6| Step: 6
Training loss: 0.27349780643828314
Validation loss: 2.8835657336633513

Epoch: 6| Step: 7
Training loss: 0.3838150170943616
Validation loss: 2.924171354558765

Epoch: 6| Step: 8
Training loss: 0.28146681111149613
Validation loss: 2.8561567390068867

Epoch: 6| Step: 9
Training loss: 0.3166861532305758
Validation loss: 2.8614846873496074

Epoch: 6| Step: 10
Training loss: 0.44796867586154543
Validation loss: 2.897536831024579

Epoch: 6| Step: 11
Training loss: 0.4124291973327521
Validation loss: 2.9110613821318414

Epoch: 6| Step: 12
Training loss: 0.4834924471599571
Validation loss: 2.9332855916111775

Epoch: 6| Step: 13
Training loss: 0.36887119693792836
Validation loss: 2.9811603215429567

Epoch: 240| Step: 0
Training loss: 0.3845629860415984
Validation loss: 2.982482163428419

Epoch: 6| Step: 1
Training loss: 0.5143553389619164
Validation loss: 2.986173410776119

Epoch: 6| Step: 2
Training loss: 0.39335057192880013
Validation loss: 3.0089764015144604

Epoch: 6| Step: 3
Training loss: 0.34842673657133644
Validation loss: 2.9728747841857226

Epoch: 6| Step: 4
Training loss: 0.2547873833567381
Validation loss: 2.8846633607184087

Epoch: 6| Step: 5
Training loss: 0.21228666114958106
Validation loss: 2.90937030599279

Epoch: 6| Step: 6
Training loss: 0.7842794048523066
Validation loss: 2.910003589833286

Epoch: 6| Step: 7
Training loss: 0.38815551272375154
Validation loss: 2.94600628170251

Epoch: 6| Step: 8
Training loss: 0.29663033191021776
Validation loss: 2.905807406724887

Epoch: 6| Step: 9
Training loss: 0.38099053887512296
Validation loss: 2.8925557742048436

Epoch: 6| Step: 10
Training loss: 0.35106910415340614
Validation loss: 2.931523011703433

Epoch: 6| Step: 11
Training loss: 0.6849752798283911
Validation loss: 2.9545683386389947

Epoch: 6| Step: 12
Training loss: 0.3944703423347722
Validation loss: 2.953658444296904

Epoch: 6| Step: 13
Training loss: 0.5164372375701825
Validation loss: 2.9438910794046502

Epoch: 241| Step: 0
Training loss: 0.7700139579498686
Validation loss: 2.9147100606929786

Epoch: 6| Step: 1
Training loss: 0.4646518856271806
Validation loss: 2.908976298164297

Epoch: 6| Step: 2
Training loss: 0.5461948524937933
Validation loss: 2.8801033778092204

Epoch: 6| Step: 3
Training loss: 0.3477920738384794
Validation loss: 2.899097857519922

Epoch: 6| Step: 4
Training loss: 0.4121832035699736
Validation loss: 2.9317708521278387

Epoch: 6| Step: 5
Training loss: 0.38033079979406814
Validation loss: 2.9119949983564326

Epoch: 6| Step: 6
Training loss: 0.401906266368109
Validation loss: 2.903719672160868

Epoch: 6| Step: 7
Training loss: 0.31726938421581535
Validation loss: 2.8654890582150268

Epoch: 6| Step: 8
Training loss: 0.533382623103513
Validation loss: 2.8935463791812817

Epoch: 6| Step: 9
Training loss: 0.4057844869420644
Validation loss: 2.9555720126459506

Epoch: 6| Step: 10
Training loss: 0.3050512685445193
Validation loss: 2.908950173419524

Epoch: 6| Step: 11
Training loss: 0.27405815529940813
Validation loss: 2.9362509215900072

Epoch: 6| Step: 12
Training loss: 0.2730020871082634
Validation loss: 2.9188859375604483

Epoch: 6| Step: 13
Training loss: 0.3886218014766764
Validation loss: 2.9348527599966068

Epoch: 242| Step: 0
Training loss: 0.30706801060957933
Validation loss: 2.8799452336720215

Epoch: 6| Step: 1
Training loss: 0.6857015755800925
Validation loss: 2.927771481751105

Epoch: 6| Step: 2
Training loss: 0.26056865389504796
Validation loss: 2.922820483959187

Epoch: 6| Step: 3
Training loss: 0.2874368629373855
Validation loss: 2.935133190198134

Epoch: 6| Step: 4
Training loss: 0.31753041283183925
Validation loss: 2.953899167696468

Epoch: 6| Step: 5
Training loss: 0.31828310702366924
Validation loss: 2.93819990004051

Epoch: 6| Step: 6
Training loss: 0.3295083178250352
Validation loss: 2.986361296964125

Epoch: 6| Step: 7
Training loss: 0.4902792982210544
Validation loss: 2.9446070169356737

Epoch: 6| Step: 8
Training loss: 0.4923665916739851
Validation loss: 2.9123291096466946

Epoch: 6| Step: 9
Training loss: 0.29974096161464425
Validation loss: 2.833104956529553

Epoch: 6| Step: 10
Training loss: 0.29938318400654723
Validation loss: 2.848382411583816

Epoch: 6| Step: 11
Training loss: 0.42333642942818284
Validation loss: 2.896696652680454

Epoch: 6| Step: 12
Training loss: 0.5316038075520979
Validation loss: 2.94847040176565

Epoch: 6| Step: 13
Training loss: 0.3176385172234934
Validation loss: 2.8923801351783816

Epoch: 243| Step: 0
Training loss: 0.3398847007194831
Validation loss: 2.909670372326229

Epoch: 6| Step: 1
Training loss: 0.3778882854169213
Validation loss: 2.933948507247586

Epoch: 6| Step: 2
Training loss: 0.31573391347698393
Validation loss: 2.9728110127341894

Epoch: 6| Step: 3
Training loss: 0.2922729367277392
Validation loss: 2.957665883020923

Epoch: 6| Step: 4
Training loss: 0.3928849838194712
Validation loss: 2.995206314351213

Epoch: 6| Step: 5
Training loss: 0.3676193619561328
Validation loss: 2.9124153534208808

Epoch: 6| Step: 6
Training loss: 0.4586588252879545
Validation loss: 2.820082763444866

Epoch: 6| Step: 7
Training loss: 0.5233466226060779
Validation loss: 2.9119884347310454

Epoch: 6| Step: 8
Training loss: 0.4101639156533474
Validation loss: 2.867148833053088

Epoch: 6| Step: 9
Training loss: 0.6933264711121414
Validation loss: 2.865945309618735

Epoch: 6| Step: 10
Training loss: 0.31236347554117977
Validation loss: 2.86275084172466

Epoch: 6| Step: 11
Training loss: 0.47700779856898556
Validation loss: 2.8566948675709574

Epoch: 6| Step: 12
Training loss: 0.36171439891200335
Validation loss: 2.890602015498429

Epoch: 6| Step: 13
Training loss: 0.4369114595624716
Validation loss: 2.852842125687449

Epoch: 244| Step: 0
Training loss: 0.25581075483016247
Validation loss: 2.8887123997484925

Epoch: 6| Step: 1
Training loss: 0.3527834248789582
Validation loss: 2.8909857310063156

Epoch: 6| Step: 2
Training loss: 0.44340600596147045
Validation loss: 2.939056106065592

Epoch: 6| Step: 3
Training loss: 0.3923211086702745
Validation loss: 2.876259251568198

Epoch: 6| Step: 4
Training loss: 0.283698549689538
Validation loss: 2.9819384443102983

Epoch: 6| Step: 5
Training loss: 0.5136245299592679
Validation loss: 2.943566989811804

Epoch: 6| Step: 6
Training loss: 0.3143872375647048
Validation loss: 2.9342480373033113

Epoch: 6| Step: 7
Training loss: 0.5238476754564692
Validation loss: 2.8874231011745985

Epoch: 6| Step: 8
Training loss: 0.21471706469999668
Validation loss: 2.8746008665036067

Epoch: 6| Step: 9
Training loss: 0.817975812442462
Validation loss: 2.8501268648610742

Epoch: 6| Step: 10
Training loss: 0.3715226355263159
Validation loss: 2.930871288613109

Epoch: 6| Step: 11
Training loss: 0.3784123771008249
Validation loss: 2.8853488505596094

Epoch: 6| Step: 12
Training loss: 0.33431789409673873
Validation loss: 2.915374651345296

Epoch: 6| Step: 13
Training loss: 0.3696482362316317
Validation loss: 2.9871172996360342

Epoch: 245| Step: 0
Training loss: 0.3532500138576367
Validation loss: 3.015893775939995

Epoch: 6| Step: 1
Training loss: 0.4643394876612188
Validation loss: 2.9316586928686585

Epoch: 6| Step: 2
Training loss: 0.33337327474470235
Validation loss: 2.971339478429965

Epoch: 6| Step: 3
Training loss: 0.29228728829220263
Validation loss: 2.9817566361845875

Epoch: 6| Step: 4
Training loss: 0.3294656816368791
Validation loss: 2.8761400920012106

Epoch: 6| Step: 5
Training loss: 0.31340678499058033
Validation loss: 2.9283441337410885

Epoch: 6| Step: 6
Training loss: 0.41010621991885793
Validation loss: 2.8637252817206926

Epoch: 6| Step: 7
Training loss: 0.6260971215092832
Validation loss: 2.942325470360667

Epoch: 6| Step: 8
Training loss: 0.787794737685603
Validation loss: 2.9187711117271586

Epoch: 6| Step: 9
Training loss: 0.3665116766439557
Validation loss: 2.8919600831676235

Epoch: 6| Step: 10
Training loss: 0.32912109950905866
Validation loss: 2.9582853626785512

Epoch: 6| Step: 11
Training loss: 0.2780567192527953
Validation loss: 2.9665061501857646

Epoch: 6| Step: 12
Training loss: 0.38784222257634715
Validation loss: 2.943585632443699

Epoch: 6| Step: 13
Training loss: 0.3525753795061285
Validation loss: 2.938623443478916

Epoch: 246| Step: 0
Training loss: 0.37240037270649207
Validation loss: 2.891670821422337

Epoch: 6| Step: 1
Training loss: 0.38160001681230815
Validation loss: 2.9627499095382506

Epoch: 6| Step: 2
Training loss: 0.29009246334574246
Validation loss: 2.8606696611301476

Epoch: 6| Step: 3
Training loss: 0.4531290448764609
Validation loss: 2.970674152220444

Epoch: 6| Step: 4
Training loss: 0.28003912777925877
Validation loss: 2.8947311243125506

Epoch: 6| Step: 5
Training loss: 0.2835769291032325
Validation loss: 2.953178445645256

Epoch: 6| Step: 6
Training loss: 0.3188032087158589
Validation loss: 2.8790342939966007

Epoch: 6| Step: 7
Training loss: 0.18853209473003202
Validation loss: 2.9301086529971085

Epoch: 6| Step: 8
Training loss: 0.37088699604404013
Validation loss: 2.872851605654913

Epoch: 6| Step: 9
Training loss: 0.39851991885574867
Validation loss: 2.903803626364614

Epoch: 6| Step: 10
Training loss: 0.807773930054948
Validation loss: 2.803544005311059

Epoch: 6| Step: 11
Training loss: 0.37991328962989096
Validation loss: 2.9357560845277657

Epoch: 6| Step: 12
Training loss: 0.344159619156832
Validation loss: 2.8579295383832193

Epoch: 6| Step: 13
Training loss: 0.4956294913647643
Validation loss: 2.956021605601522

Epoch: 247| Step: 0
Training loss: 0.38914078074316016
Validation loss: 2.896326933217522

Epoch: 6| Step: 1
Training loss: 0.32922211654817457
Validation loss: 2.9705993380067848

Epoch: 6| Step: 2
Training loss: 0.3840990052593433
Validation loss: 2.892795304742522

Epoch: 6| Step: 3
Training loss: 0.39395236991041666
Validation loss: 2.8864912976727872

Epoch: 6| Step: 4
Training loss: 0.3143101242652262
Validation loss: 2.868842261554602

Epoch: 6| Step: 5
Training loss: 0.33632353847092245
Validation loss: 2.888141190429074

Epoch: 6| Step: 6
Training loss: 0.743042583788089
Validation loss: 2.8699555993494648

Epoch: 6| Step: 7
Training loss: 0.2506236998602803
Validation loss: 2.933129034640414

Epoch: 6| Step: 8
Training loss: 0.480193609838059
Validation loss: 2.9141136621751467

Epoch: 6| Step: 9
Training loss: 0.30071441105916674
Validation loss: 2.852198476721846

Epoch: 6| Step: 10
Training loss: 0.49686699027077325
Validation loss: 2.855875079411331

Epoch: 6| Step: 11
Training loss: 0.34456390779686125
Validation loss: 2.856796143986779

Epoch: 6| Step: 12
Training loss: 0.460026001428609
Validation loss: 2.873165499003654

Epoch: 6| Step: 13
Training loss: 0.34312001935196357
Validation loss: 2.9057606384210377

Epoch: 248| Step: 0
Training loss: 0.38640817057883864
Validation loss: 2.954030659983315

Epoch: 6| Step: 1
Training loss: 0.7478696448829198
Validation loss: 2.96464836136857

Epoch: 6| Step: 2
Training loss: 0.3208825342529464
Validation loss: 2.862756310638747

Epoch: 6| Step: 3
Training loss: 0.3592553976313145
Validation loss: 2.907538685452448

Epoch: 6| Step: 4
Training loss: 0.3850558778849407
Validation loss: 2.935971329003336

Epoch: 6| Step: 5
Training loss: 0.29511162672477953
Validation loss: 2.9419815156141156

Epoch: 6| Step: 6
Training loss: 0.26397820092099517
Validation loss: 2.9072862097264003

Epoch: 6| Step: 7
Training loss: 0.4898800424275894
Validation loss: 2.9087399306899644

Epoch: 6| Step: 8
Training loss: 0.32699817224087996
Validation loss: 2.897390747248709

Epoch: 6| Step: 9
Training loss: 0.33718421167249796
Validation loss: 2.913994496006285

Epoch: 6| Step: 10
Training loss: 0.4990913210568431
Validation loss: 2.922747517424898

Epoch: 6| Step: 11
Training loss: 0.3475892720371728
Validation loss: 2.886488984926203

Epoch: 6| Step: 12
Training loss: 0.3685382995034742
Validation loss: 2.922033975393664

Epoch: 6| Step: 13
Training loss: 0.3709035285491827
Validation loss: 2.9249922227891956

Epoch: 249| Step: 0
Training loss: 0.42523308561214745
Validation loss: 2.8535607151835496

Epoch: 6| Step: 1
Training loss: 0.39482906167803383
Validation loss: 2.8194104105414772

Epoch: 6| Step: 2
Training loss: 0.6566906312581213
Validation loss: 2.9179534707441754

Epoch: 6| Step: 3
Training loss: 0.36598064047782547
Validation loss: 2.875525564724047

Epoch: 6| Step: 4
Training loss: 0.3342609041513912
Validation loss: 2.9513662843524235

Epoch: 6| Step: 5
Training loss: 0.31974383792800304
Validation loss: 2.930711965520038

Epoch: 6| Step: 6
Training loss: 0.20157372051619726
Validation loss: 2.9436492135949486

Epoch: 6| Step: 7
Training loss: 0.4535998782835567
Validation loss: 2.996376697321412

Epoch: 6| Step: 8
Training loss: 0.432037102381989
Validation loss: 2.965949695366347

Epoch: 6| Step: 9
Training loss: 0.4390388740346229
Validation loss: 3.011062900298808

Epoch: 6| Step: 10
Training loss: 0.30348254628640237
Validation loss: 2.877417253088325

Epoch: 6| Step: 11
Training loss: 0.4319935732204496
Validation loss: 2.9245227370012814

Epoch: 6| Step: 12
Training loss: 0.2390385537838889
Validation loss: 2.8993905789109644

Epoch: 6| Step: 13
Training loss: 0.712655099082909
Validation loss: 2.8836841729958205

Epoch: 250| Step: 0
Training loss: 0.3270771689147927
Validation loss: 2.8961843419662276

Epoch: 6| Step: 1
Training loss: 0.2823610612283681
Validation loss: 2.8158784354997777

Epoch: 6| Step: 2
Training loss: 0.2917360183598434
Validation loss: 2.9570675187971096

Epoch: 6| Step: 3
Training loss: 0.3747456800836582
Validation loss: 2.9253985261175823

Epoch: 6| Step: 4
Training loss: 0.6894971493073553
Validation loss: 2.9144511709363075

Epoch: 6| Step: 5
Training loss: 0.34051701295113196
Validation loss: 2.902887881217354

Epoch: 6| Step: 6
Training loss: 0.2654478941252773
Validation loss: 2.887592285024653

Epoch: 6| Step: 7
Training loss: 0.2984295599315589
Validation loss: 2.8743996200618604

Epoch: 6| Step: 8
Training loss: 0.3724767112492403
Validation loss: 2.883600390934848

Epoch: 6| Step: 9
Training loss: 0.34936463724507844
Validation loss: 2.886258031328101

Epoch: 6| Step: 10
Training loss: 0.3684864201314467
Validation loss: 2.9122446371177513

Epoch: 6| Step: 11
Training loss: 0.4846873506832323
Validation loss: 2.878804039833726

Epoch: 6| Step: 12
Training loss: 0.3476742193314361
Validation loss: 2.881805133644177

Epoch: 6| Step: 13
Training loss: 0.298159230904131
Validation loss: 2.9144187348146775

Testing loss: 2.568778484050139
