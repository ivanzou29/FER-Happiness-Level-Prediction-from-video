Epoch: 1| Step: 0
Training loss: 8.78071999901898
Validation loss: 8.03144561093961

Epoch: 6| Step: 1
Training loss: 6.924955281137342
Validation loss: 7.995298911704302

Epoch: 6| Step: 2
Training loss: 7.228238561969315
Validation loss: 7.967072792820987

Epoch: 6| Step: 3
Training loss: 8.949091723509222
Validation loss: 7.937062769584552

Epoch: 6| Step: 4
Training loss: 8.382319653644743
Validation loss: 7.9061258379166945

Epoch: 6| Step: 5
Training loss: 8.559941932980392
Validation loss: 7.877337194705672

Epoch: 6| Step: 6
Training loss: 7.660301911303135
Validation loss: 7.851109510927205

Epoch: 6| Step: 7
Training loss: 7.63931631414478
Validation loss: 7.82060704040213

Epoch: 6| Step: 8
Training loss: 7.320098320139143
Validation loss: 7.791330938875094

Epoch: 6| Step: 9
Training loss: 8.83489870800249
Validation loss: 7.763987685204103

Epoch: 6| Step: 10
Training loss: 7.616637349924419
Validation loss: 7.72852060200381

Epoch: 6| Step: 11
Training loss: 7.952796434611607
Validation loss: 7.702244830190374

Epoch: 6| Step: 12
Training loss: 7.128785315755062
Validation loss: 7.670916733779634

Epoch: 6| Step: 13
Training loss: 7.72989063693874
Validation loss: 7.6345898717059635

Epoch: 2| Step: 0
Training loss: 8.959807613214712
Validation loss: 7.605496754437185

Epoch: 6| Step: 1
Training loss: 7.99116839253385
Validation loss: 7.572031115387888

Epoch: 6| Step: 2
Training loss: 6.115343539428068
Validation loss: 7.536261024519761

Epoch: 6| Step: 3
Training loss: 7.711727020750807
Validation loss: 7.501766547799736

Epoch: 6| Step: 4
Training loss: 7.698355848476699
Validation loss: 7.4659511796697355

Epoch: 6| Step: 5
Training loss: 7.366352248350424
Validation loss: 7.425241278464717

Epoch: 6| Step: 6
Training loss: 6.634759013004507
Validation loss: 7.388779348582841

Epoch: 6| Step: 7
Training loss: 7.742677736591834
Validation loss: 7.345015699466333

Epoch: 6| Step: 8
Training loss: 7.067439419703
Validation loss: 7.298807828917682

Epoch: 6| Step: 9
Training loss: 7.871614243026371
Validation loss: 7.255729559810581

Epoch: 6| Step: 10
Training loss: 7.503738743006116
Validation loss: 7.204496902595409

Epoch: 6| Step: 11
Training loss: 7.354527393459919
Validation loss: 7.158494711120077

Epoch: 6| Step: 12
Training loss: 6.101424329221403
Validation loss: 7.104078842321266

Epoch: 6| Step: 13
Training loss: 7.719130533699315
Validation loss: 7.050543642839649

Epoch: 3| Step: 0
Training loss: 6.988351666952379
Validation loss: 6.989010085709522

Epoch: 6| Step: 1
Training loss: 8.457064628975699
Validation loss: 6.934351301045297

Epoch: 6| Step: 2
Training loss: 6.2514231778089435
Validation loss: 6.875657160013099

Epoch: 6| Step: 3
Training loss: 6.772944132118385
Validation loss: 6.809071836102607

Epoch: 6| Step: 4
Training loss: 6.35942088867427
Validation loss: 6.74854738593957

Epoch: 6| Step: 5
Training loss: 7.223645420535333
Validation loss: 6.6811360058339275

Epoch: 6| Step: 6
Training loss: 7.772345047292978
Validation loss: 6.612214616988266

Epoch: 6| Step: 7
Training loss: 5.708161437330667
Validation loss: 6.541404751274387

Epoch: 6| Step: 8
Training loss: 7.192493594806193
Validation loss: 6.463621677474182

Epoch: 6| Step: 9
Training loss: 5.809155229881818
Validation loss: 6.387993629129124

Epoch: 6| Step: 10
Training loss: 5.697335259473317
Validation loss: 6.3059659573190325

Epoch: 6| Step: 11
Training loss: 6.233146833325907
Validation loss: 6.2232888940424225

Epoch: 6| Step: 12
Training loss: 6.2761075809125115
Validation loss: 6.131513026224713

Epoch: 6| Step: 13
Training loss: 5.6380059668599705
Validation loss: 6.03787034125042

Epoch: 4| Step: 0
Training loss: 6.306276785242608
Validation loss: 5.948454806362181

Epoch: 6| Step: 1
Training loss: 6.688470502648189
Validation loss: 5.859761380489763

Epoch: 6| Step: 2
Training loss: 5.605030130378531
Validation loss: 5.744472362213538

Epoch: 6| Step: 3
Training loss: 6.158829666529845
Validation loss: 5.647734553000558

Epoch: 6| Step: 4
Training loss: 5.185217665515068
Validation loss: 5.528421803225498

Epoch: 6| Step: 5
Training loss: 4.174870133807191
Validation loss: 5.42357550932395

Epoch: 6| Step: 6
Training loss: 4.770516908416354
Validation loss: 5.31352974878423

Epoch: 6| Step: 7
Training loss: 5.745400952988025
Validation loss: 5.191645516994906

Epoch: 6| Step: 8
Training loss: 5.131194859904233
Validation loss: 5.0717382087053355

Epoch: 6| Step: 9
Training loss: 4.280908501363455
Validation loss: 4.946374153492341

Epoch: 6| Step: 10
Training loss: 4.9673056752515965
Validation loss: 4.82136465632411

Epoch: 6| Step: 11
Training loss: 4.717796785189847
Validation loss: 4.681298998995168

Epoch: 6| Step: 12
Training loss: 4.1847807752281065
Validation loss: 4.546723388381452

Epoch: 6| Step: 13
Training loss: 5.254118983843696
Validation loss: 4.410880755461401

Epoch: 5| Step: 0
Training loss: 4.549747149809236
Validation loss: 4.270327852930841

Epoch: 6| Step: 1
Training loss: 4.778346757252339
Validation loss: 4.110992422767634

Epoch: 6| Step: 2
Training loss: 3.478587180359622
Validation loss: 3.963398767502775

Epoch: 6| Step: 3
Training loss: 3.5997197201023106
Validation loss: 3.7981814424866607

Epoch: 6| Step: 4
Training loss: 3.2053842903927574
Validation loss: 3.6697343362528985

Epoch: 6| Step: 5
Training loss: 3.5051547646739376
Validation loss: 3.5480563735260793

Epoch: 6| Step: 6
Training loss: 3.2221797706467643
Validation loss: 3.4093848568930887

Epoch: 6| Step: 7
Training loss: 3.4351662776853584
Validation loss: 3.3007949377374297

Epoch: 6| Step: 8
Training loss: 3.3639729106506353
Validation loss: 3.1793240551134923

Epoch: 6| Step: 9
Training loss: 3.035419074698815
Validation loss: 3.084105321965861

Epoch: 6| Step: 10
Training loss: 3.5776610760844285
Validation loss: 2.978864792332633

Epoch: 6| Step: 11
Training loss: 2.934622146224839
Validation loss: 2.9473487837216132

Epoch: 6| Step: 12
Training loss: 3.3260901592832184
Validation loss: 2.9160899454956715

Epoch: 6| Step: 13
Training loss: 3.4885938617533547
Validation loss: 2.9039809690750387

Epoch: 6| Step: 0
Training loss: 2.930208612508226
Validation loss: 2.8846869159860855

Epoch: 6| Step: 1
Training loss: 3.078260544634235
Validation loss: 2.900001631659564

Epoch: 6| Step: 2
Training loss: 2.885807786638067
Validation loss: 2.8913273482168025

Epoch: 6| Step: 3
Training loss: 3.6083702901896095
Validation loss: 2.9313253749545334

Epoch: 6| Step: 4
Training loss: 2.4042066344889745
Validation loss: 2.934342764073744

Epoch: 6| Step: 5
Training loss: 2.7517233563811807
Validation loss: 2.940303911711528

Epoch: 6| Step: 6
Training loss: 2.58562456064126
Validation loss: 2.962204916056015

Epoch: 6| Step: 7
Training loss: 3.1609920721392126
Validation loss: 3.0020101753196267

Epoch: 6| Step: 8
Training loss: 3.7044506677861206
Validation loss: 2.9390334462351024

Epoch: 6| Step: 9
Training loss: 3.996650485487743
Validation loss: 2.9474694594639064

Epoch: 6| Step: 10
Training loss: 3.5281911108886397
Validation loss: 2.8864199458340956

Epoch: 6| Step: 11
Training loss: 2.833491507958227
Validation loss: 2.888249632724503

Epoch: 6| Step: 12
Training loss: 2.7226390865447176
Validation loss: 2.8768283931767185

Epoch: 6| Step: 13
Training loss: 2.48813991654272
Validation loss: 2.8302890233029343

Epoch: 7| Step: 0
Training loss: 3.411903798767406
Validation loss: 2.869598303694375

Epoch: 6| Step: 1
Training loss: 3.6159725249689836
Validation loss: 2.8665015208188556

Epoch: 6| Step: 2
Training loss: 2.6522793881412245
Validation loss: 2.8107095600166234

Epoch: 6| Step: 3
Training loss: 3.0889883677917176
Validation loss: 2.788441222847917

Epoch: 6| Step: 4
Training loss: 2.5064712693100937
Validation loss: 2.7968454199564023

Epoch: 6| Step: 5
Training loss: 3.000479977676163
Validation loss: 2.796684429133512

Epoch: 6| Step: 6
Training loss: 2.3018135384509097
Validation loss: 2.8391781061373282

Epoch: 6| Step: 7
Training loss: 2.9639588896439695
Validation loss: 2.819127687242444

Epoch: 6| Step: 8
Training loss: 3.462568669378433
Validation loss: 2.8162746248778574

Epoch: 6| Step: 9
Training loss: 3.3696322671176726
Validation loss: 2.813431451346013

Epoch: 6| Step: 10
Training loss: 2.6294944071241466
Validation loss: 2.7740340616563994

Epoch: 6| Step: 11
Training loss: 3.13401562046231
Validation loss: 2.8033923644980683

Epoch: 6| Step: 12
Training loss: 2.3745434974836006
Validation loss: 2.800000382037364

Epoch: 6| Step: 13
Training loss: 2.1398055464198746
Validation loss: 2.8264601076501568

Epoch: 8| Step: 0
Training loss: 1.883183866100509
Validation loss: 2.7929782680536026

Epoch: 6| Step: 1
Training loss: 2.359422190617415
Validation loss: 2.8101094435469434

Epoch: 6| Step: 2
Training loss: 3.2181692247580282
Validation loss: 2.822418060937929

Epoch: 6| Step: 3
Training loss: 2.777208971490205
Validation loss: 2.8065109630021494

Epoch: 6| Step: 4
Training loss: 3.51377650513859
Validation loss: 2.7935142855729875

Epoch: 6| Step: 5
Training loss: 3.8480645752165623
Validation loss: 2.8017670454083885

Epoch: 6| Step: 6
Training loss: 2.784118630265923
Validation loss: 2.7608240702625584

Epoch: 6| Step: 7
Training loss: 3.488761296406044
Validation loss: 2.7875691894246626

Epoch: 6| Step: 8
Training loss: 2.936917511022864
Validation loss: 2.772016306203026

Epoch: 6| Step: 9
Training loss: 2.783167317477991
Validation loss: 2.746219492855562

Epoch: 6| Step: 10
Training loss: 2.146099135840302
Validation loss: 2.7423868278954173

Epoch: 6| Step: 11
Training loss: 2.8804607775096476
Validation loss: 2.740222527570574

Epoch: 6| Step: 12
Training loss: 2.392625756860052
Validation loss: 2.730716401212866

Epoch: 6| Step: 13
Training loss: 2.6843006696612886
Validation loss: 2.7496229404541697

Epoch: 9| Step: 0
Training loss: 3.49435569139692
Validation loss: 2.772896770364835

Epoch: 6| Step: 1
Training loss: 2.0643191551256677
Validation loss: 2.7264998901523865

Epoch: 6| Step: 2
Training loss: 2.474849650122296
Validation loss: 2.748335594729975

Epoch: 6| Step: 3
Training loss: 3.3813103915478178
Validation loss: 2.7267035854967827

Epoch: 6| Step: 4
Training loss: 2.4680923358516784
Validation loss: 2.745410962728238

Epoch: 6| Step: 5
Training loss: 2.6485496654783294
Validation loss: 2.734813814828839

Epoch: 6| Step: 6
Training loss: 2.849655056875528
Validation loss: 2.737073790816743

Epoch: 6| Step: 7
Training loss: 2.9900868664119047
Validation loss: 2.7210904567047645

Epoch: 6| Step: 8
Training loss: 3.1218827531048152
Validation loss: 2.680287285679812

Epoch: 6| Step: 9
Training loss: 2.1460439214486886
Validation loss: 2.7106483297917747

Epoch: 6| Step: 10
Training loss: 3.762010034234447
Validation loss: 2.7398592492078433

Epoch: 6| Step: 11
Training loss: 3.0638636453033805
Validation loss: 2.732160212594932

Epoch: 6| Step: 12
Training loss: 2.773940435665282
Validation loss: 2.7022314781532724

Epoch: 6| Step: 13
Training loss: 2.154964782710307
Validation loss: 2.7230597935375016

Epoch: 10| Step: 0
Training loss: 2.6067098381129314
Validation loss: 2.655526904249075

Epoch: 6| Step: 1
Training loss: 2.4782005692994313
Validation loss: 2.6703739523024668

Epoch: 6| Step: 2
Training loss: 2.792127447864733
Validation loss: 2.6980884354945656

Epoch: 6| Step: 3
Training loss: 2.3841346949602866
Validation loss: 2.7313926199798497

Epoch: 6| Step: 4
Training loss: 3.1256935875805842
Validation loss: 2.7457259227099113

Epoch: 6| Step: 5
Training loss: 2.970518529048573
Validation loss: 2.7179011777391335

Epoch: 6| Step: 6
Training loss: 2.4316726866297453
Validation loss: 2.712338425472312

Epoch: 6| Step: 7
Training loss: 2.6615240358926
Validation loss: 2.7731333247912313

Epoch: 6| Step: 8
Training loss: 2.911707522260852
Validation loss: 2.7070552646880026

Epoch: 6| Step: 9
Training loss: 2.4965807420267305
Validation loss: 2.6984720922571035

Epoch: 6| Step: 10
Training loss: 3.158002612295876
Validation loss: 2.686455545846756

Epoch: 6| Step: 11
Training loss: 3.315638081401651
Validation loss: 2.65179539566022

Epoch: 6| Step: 12
Training loss: 2.355039339162186
Validation loss: 2.691826406016209

Epoch: 6| Step: 13
Training loss: 3.3355286680466905
Validation loss: 2.6954235109328915

Epoch: 11| Step: 0
Training loss: 2.270411624306619
Validation loss: 2.6664859789986313

Epoch: 6| Step: 1
Training loss: 2.853033653042078
Validation loss: 2.6861158621319854

Epoch: 6| Step: 2
Training loss: 2.323798543947294
Validation loss: 2.6894189947396367

Epoch: 6| Step: 3
Training loss: 2.4130256673093533
Validation loss: 2.6418902133094204

Epoch: 6| Step: 4
Training loss: 3.5277756334700454
Validation loss: 2.686996050463226

Epoch: 6| Step: 5
Training loss: 2.259231385537935
Validation loss: 2.7018407736804786

Epoch: 6| Step: 6
Training loss: 2.046729395688948
Validation loss: 2.701149176122729

Epoch: 6| Step: 7
Training loss: 2.966737727767881
Validation loss: 2.661414417917306

Epoch: 6| Step: 8
Training loss: 2.7301334289809103
Validation loss: 2.663451765201925

Epoch: 6| Step: 9
Training loss: 2.6035023465000373
Validation loss: 2.6482272294405567

Epoch: 6| Step: 10
Training loss: 2.6729610979565273
Validation loss: 2.6338968883145193

Epoch: 6| Step: 11
Training loss: 3.0296727432434585
Validation loss: 2.6572178143375154

Epoch: 6| Step: 12
Training loss: 2.8798614532206397
Validation loss: 2.646628963560638

Epoch: 6| Step: 13
Training loss: 3.7937285018889955
Validation loss: 2.6189201275440537

Epoch: 12| Step: 0
Training loss: 1.9668329987527946
Validation loss: 2.622549532970136

Epoch: 6| Step: 1
Training loss: 2.1734194307104073
Validation loss: 2.6626240117857845

Epoch: 6| Step: 2
Training loss: 2.8528571547332158
Validation loss: 2.6675245623662835

Epoch: 6| Step: 3
Training loss: 2.935117363995806
Validation loss: 2.666536541585218

Epoch: 6| Step: 4
Training loss: 2.7159875449961057
Validation loss: 2.6179566728675163

Epoch: 6| Step: 5
Training loss: 2.7857732958709236
Validation loss: 2.6446718885701794

Epoch: 6| Step: 6
Training loss: 2.8407699564761795
Validation loss: 2.6360864554608723

Epoch: 6| Step: 7
Training loss: 2.188937341677695
Validation loss: 2.673823874678948

Epoch: 6| Step: 8
Training loss: 3.1476053127277432
Validation loss: 2.6834319323635274

Epoch: 6| Step: 9
Training loss: 2.2804576595150414
Validation loss: 2.658498926495999

Epoch: 6| Step: 10
Training loss: 2.8885739859914246
Validation loss: 2.631224004959886

Epoch: 6| Step: 11
Training loss: 3.4924968949388098
Validation loss: 2.640043160707059

Epoch: 6| Step: 12
Training loss: 2.889830774018752
Validation loss: 2.6452448082735254

Epoch: 6| Step: 13
Training loss: 2.799564198230183
Validation loss: 2.6559209133566397

Epoch: 13| Step: 0
Training loss: 1.3343607202699412
Validation loss: 2.6243605213230725

Epoch: 6| Step: 1
Training loss: 2.7052707865168224
Validation loss: 2.6593480910819896

Epoch: 6| Step: 2
Training loss: 2.9600369737223255
Validation loss: 2.6297626432493315

Epoch: 6| Step: 3
Training loss: 3.2498374311428906
Validation loss: 2.6271244565168765

Epoch: 6| Step: 4
Training loss: 2.5007393697314213
Validation loss: 2.6558877136899994

Epoch: 6| Step: 5
Training loss: 3.116286986644504
Validation loss: 2.592764303283502

Epoch: 6| Step: 6
Training loss: 2.2684142733933905
Validation loss: 2.6137907845787325

Epoch: 6| Step: 7
Training loss: 2.454440693433889
Validation loss: 2.620499689023667

Epoch: 6| Step: 8
Training loss: 2.68303167017765
Validation loss: 2.63120008347282

Epoch: 6| Step: 9
Training loss: 2.9517349120108487
Validation loss: 2.6416955617373303

Epoch: 6| Step: 10
Training loss: 3.0344826676255097
Validation loss: 2.5802861413067135

Epoch: 6| Step: 11
Training loss: 2.5658112508284647
Validation loss: 2.6172891321898475

Epoch: 6| Step: 12
Training loss: 2.9495417740109637
Validation loss: 2.639928616825424

Epoch: 6| Step: 13
Training loss: 2.532765629385877
Validation loss: 2.6450876376603145

Epoch: 14| Step: 0
Training loss: 2.9888029951999533
Validation loss: 2.6310659741392337

Epoch: 6| Step: 1
Training loss: 3.3362896842783116
Validation loss: 2.626224519829032

Epoch: 6| Step: 2
Training loss: 2.175704215036903
Validation loss: 2.6386219832199966

Epoch: 6| Step: 3
Training loss: 2.7169307892386922
Validation loss: 2.665217547265955

Epoch: 6| Step: 4
Training loss: 2.467176104682954
Validation loss: 2.6196678592455727

Epoch: 6| Step: 5
Training loss: 2.4550731722615615
Validation loss: 2.598556186750962

Epoch: 6| Step: 6
Training loss: 3.256994789744805
Validation loss: 2.5910608376727247

Epoch: 6| Step: 7
Training loss: 1.7524050126610737
Validation loss: 2.64500299074981

Epoch: 6| Step: 8
Training loss: 3.0977646182179197
Validation loss: 2.6282487021419167

Epoch: 6| Step: 9
Training loss: 2.2053291711748755
Validation loss: 2.584587028812774

Epoch: 6| Step: 10
Training loss: 2.166570539053783
Validation loss: 2.5965630164493874

Epoch: 6| Step: 11
Training loss: 3.1469814066620976
Validation loss: 2.6103910040500975

Epoch: 6| Step: 12
Training loss: 2.33426486448744
Validation loss: 2.652319389759497

Epoch: 6| Step: 13
Training loss: 3.351259017755768
Validation loss: 2.6438954883701573

Epoch: 15| Step: 0
Training loss: 3.3399888035021212
Validation loss: 2.6505482682282246

Epoch: 6| Step: 1
Training loss: 2.31776941340396
Validation loss: 2.6190125132763455

Epoch: 6| Step: 2
Training loss: 2.312721035677928
Validation loss: 2.654165519662207

Epoch: 6| Step: 3
Training loss: 3.0574283255210157
Validation loss: 2.654674990577555

Epoch: 6| Step: 4
Training loss: 2.405682781791158
Validation loss: 2.633065367194771

Epoch: 6| Step: 5
Training loss: 3.047592000472303
Validation loss: 2.6623565715788

Epoch: 6| Step: 6
Training loss: 1.8625336432778654
Validation loss: 2.6478624948102056

Epoch: 6| Step: 7
Training loss: 2.7796589447321662
Validation loss: 2.6728664588722184

Epoch: 6| Step: 8
Training loss: 2.4652824676421305
Validation loss: 2.6528528368207924

Epoch: 6| Step: 9
Training loss: 3.7225204715204283
Validation loss: 2.6785004324813873

Epoch: 6| Step: 10
Training loss: 2.7786055433551495
Validation loss: 2.638981956937745

Epoch: 6| Step: 11
Training loss: 3.216197659258966
Validation loss: 2.635320689347218

Epoch: 6| Step: 12
Training loss: 2.0914312019897405
Validation loss: 2.617390563071309

Epoch: 6| Step: 13
Training loss: 2.0365214098229454
Validation loss: 2.6243595825575823

Epoch: 16| Step: 0
Training loss: 2.6638017006577734
Validation loss: 2.682645820026977

Epoch: 6| Step: 1
Training loss: 2.611922887548886
Validation loss: 2.639823521076242

Epoch: 6| Step: 2
Training loss: 2.5230512293854668
Validation loss: 2.631133097621284

Epoch: 6| Step: 3
Training loss: 3.3720563130953973
Validation loss: 2.657631339137853

Epoch: 6| Step: 4
Training loss: 2.41038633265376
Validation loss: 2.600723971538942

Epoch: 6| Step: 5
Training loss: 1.9068448748814288
Validation loss: 2.553091174570457

Epoch: 6| Step: 6
Training loss: 2.9220616898078946
Validation loss: 2.6283120196519847

Epoch: 6| Step: 7
Training loss: 2.1687357877326106
Validation loss: 2.6041918079434185

Epoch: 6| Step: 8
Training loss: 2.5386435764682496
Validation loss: 2.6525745768943665

Epoch: 6| Step: 9
Training loss: 2.33362191550106
Validation loss: 2.6128596263660064

Epoch: 6| Step: 10
Training loss: 2.7031287044433614
Validation loss: 2.5868729266127426

Epoch: 6| Step: 11
Training loss: 3.8327652192338943
Validation loss: 2.60899319777425

Epoch: 6| Step: 12
Training loss: 2.386490581488271
Validation loss: 2.620865184143629

Epoch: 6| Step: 13
Training loss: 2.8443193808850853
Validation loss: 2.6149041914909192

Epoch: 17| Step: 0
Training loss: 2.5410116842182164
Validation loss: 2.6571651527816647

Epoch: 6| Step: 1
Training loss: 2.035106812094466
Validation loss: 2.619701297988664

Epoch: 6| Step: 2
Training loss: 2.7449730095986906
Validation loss: 2.603961941619171

Epoch: 6| Step: 3
Training loss: 3.2498506364979143
Validation loss: 2.594073401822149

Epoch: 6| Step: 4
Training loss: 2.8343471134584615
Validation loss: 2.59035252578878

Epoch: 6| Step: 5
Training loss: 2.1893151517981195
Validation loss: 2.6256313813514955

Epoch: 6| Step: 6
Training loss: 3.4634682248391155
Validation loss: 2.6006344809676776

Epoch: 6| Step: 7
Training loss: 2.6665272874964883
Validation loss: 2.5667878229684744

Epoch: 6| Step: 8
Training loss: 2.9660667741581017
Validation loss: 2.6288049006658465

Epoch: 6| Step: 9
Training loss: 2.549822453320433
Validation loss: 2.65173485667243

Epoch: 6| Step: 10
Training loss: 2.8843943486747774
Validation loss: 2.5800384356718538

Epoch: 6| Step: 11
Training loss: 2.0665748109195556
Validation loss: 2.5682854974175515

Epoch: 6| Step: 12
Training loss: 2.5147818342955284
Validation loss: 2.6165884214798636

Epoch: 6| Step: 13
Training loss: 2.6135275686184585
Validation loss: 2.607454823108387

Epoch: 18| Step: 0
Training loss: 2.785949850777096
Validation loss: 2.5819789094376278

Epoch: 6| Step: 1
Training loss: 2.5897409179893556
Validation loss: 2.582410391145037

Epoch: 6| Step: 2
Training loss: 3.565267324603617
Validation loss: 2.632082633285667

Epoch: 6| Step: 3
Training loss: 2.7936343380328483
Validation loss: 2.6456157314499555

Epoch: 6| Step: 4
Training loss: 2.6148804474265157
Validation loss: 2.634621079167604

Epoch: 6| Step: 5
Training loss: 3.0065701383615195
Validation loss: 2.6323303022569675

Epoch: 6| Step: 6
Training loss: 2.578766714052074
Validation loss: 2.652722533440237

Epoch: 6| Step: 7
Training loss: 2.171105996530097
Validation loss: 2.691820560303695

Epoch: 6| Step: 8
Training loss: 2.732068816819303
Validation loss: 2.6339286604073844

Epoch: 6| Step: 9
Training loss: 2.5037390404631346
Validation loss: 2.644746547182397

Epoch: 6| Step: 10
Training loss: 2.2309629624326113
Validation loss: 2.6292473551423825

Epoch: 6| Step: 11
Training loss: 2.3645460039012627
Validation loss: 2.6009969774429336

Epoch: 6| Step: 12
Training loss: 2.980969308238949
Validation loss: 2.6249540718541473

Epoch: 6| Step: 13
Training loss: 2.457969207521134
Validation loss: 2.62087766208569

Epoch: 19| Step: 0
Training loss: 2.9205508572134664
Validation loss: 2.5876712115859366

Epoch: 6| Step: 1
Training loss: 2.4078369852315022
Validation loss: 2.6103971158386696

Epoch: 6| Step: 2
Training loss: 2.9007779360504906
Validation loss: 2.641699006357004

Epoch: 6| Step: 3
Training loss: 2.6728505812989156
Validation loss: 2.5869633079633068

Epoch: 6| Step: 4
Training loss: 2.485933306946446
Validation loss: 2.6384666997473087

Epoch: 6| Step: 5
Training loss: 3.1257483539981226
Validation loss: 2.5638881892980208

Epoch: 6| Step: 6
Training loss: 1.8124116021008272
Validation loss: 2.5522333736819127

Epoch: 6| Step: 7
Training loss: 2.702027202681039
Validation loss: 2.591547494296938

Epoch: 6| Step: 8
Training loss: 2.1465925583378023
Validation loss: 2.605864548633952

Epoch: 6| Step: 9
Training loss: 3.0210822342681998
Validation loss: 2.638721645364915

Epoch: 6| Step: 10
Training loss: 3.044239958820573
Validation loss: 2.568576740693021

Epoch: 6| Step: 11
Training loss: 2.5091946319707525
Validation loss: 2.6208470281011684

Epoch: 6| Step: 12
Training loss: 2.1584114630070275
Validation loss: 2.5944822572307418

Epoch: 6| Step: 13
Training loss: 3.1359135602598927
Validation loss: 2.600099612430798

Epoch: 20| Step: 0
Training loss: 3.387138859828708
Validation loss: 2.5910158722201295

Epoch: 6| Step: 1
Training loss: 2.477216664269276
Validation loss: 2.6241605112636166

Epoch: 6| Step: 2
Training loss: 2.398330536982762
Validation loss: 2.624029252528912

Epoch: 6| Step: 3
Training loss: 2.372091821704148
Validation loss: 2.626566071576911

Epoch: 6| Step: 4
Training loss: 2.6643622892516383
Validation loss: 2.6922778308700535

Epoch: 6| Step: 5
Training loss: 2.9109382142062494
Validation loss: 2.659110806315865

Epoch: 6| Step: 6
Training loss: 3.012370671072291
Validation loss: 2.656033750221

Epoch: 6| Step: 7
Training loss: 2.023858575199776
Validation loss: 2.615492154921469

Epoch: 6| Step: 8
Training loss: 2.3010835044261304
Validation loss: 2.7161732590273053

Epoch: 6| Step: 9
Training loss: 2.439261460238535
Validation loss: 2.634382042322969

Epoch: 6| Step: 10
Training loss: 1.80732685974624
Validation loss: 2.605525681971265

Epoch: 6| Step: 11
Training loss: 2.763840956621074
Validation loss: 2.591015235766274

Epoch: 6| Step: 12
Training loss: 2.8058681712543105
Validation loss: 2.65293144415679

Epoch: 6| Step: 13
Training loss: 3.2634132597827654
Validation loss: 2.6116587986570963

Epoch: 21| Step: 0
Training loss: 2.9447801346626723
Validation loss: 2.63397572947013

Epoch: 6| Step: 1
Training loss: 2.688450312598875
Validation loss: 2.594471635739524

Epoch: 6| Step: 2
Training loss: 2.7724903477327896
Validation loss: 2.5766702882742094

Epoch: 6| Step: 3
Training loss: 2.457846598743319
Validation loss: 2.6226153213993655

Epoch: 6| Step: 4
Training loss: 2.9668990940669016
Validation loss: 2.602275013843767

Epoch: 6| Step: 5
Training loss: 2.8205615327314377
Validation loss: 2.6128353922686314

Epoch: 6| Step: 6
Training loss: 2.6029481605646536
Validation loss: 2.616788053632947

Epoch: 6| Step: 7
Training loss: 2.467909851047633
Validation loss: 2.6274982402056395

Epoch: 6| Step: 8
Training loss: 2.35563322540005
Validation loss: 2.604755317279575

Epoch: 6| Step: 9
Training loss: 2.3048658398954576
Validation loss: 2.6253807609155984

Epoch: 6| Step: 10
Training loss: 2.8368913711979773
Validation loss: 2.5893514941148625

Epoch: 6| Step: 11
Training loss: 2.9500512975338333
Validation loss: 2.6402133492877393

Epoch: 6| Step: 12
Training loss: 2.0422976031462445
Validation loss: 2.5603200199478175

Epoch: 6| Step: 13
Training loss: 2.413198767154277
Validation loss: 2.6090023513253087

Epoch: 22| Step: 0
Training loss: 2.2953093506003963
Validation loss: 2.6077563277301796

Epoch: 6| Step: 1
Training loss: 2.6404243709031836
Validation loss: 2.65660996335477

Epoch: 6| Step: 2
Training loss: 2.4036532174958243
Validation loss: 2.6111727021327917

Epoch: 6| Step: 3
Training loss: 3.126334553901729
Validation loss: 2.6596181720227

Epoch: 6| Step: 4
Training loss: 2.6442380486234756
Validation loss: 2.7060899955899234

Epoch: 6| Step: 5
Training loss: 3.299127469165187
Validation loss: 2.6961114187738473

Epoch: 6| Step: 6
Training loss: 3.014324006423039
Validation loss: 2.7053563164292025

Epoch: 6| Step: 7
Training loss: 2.7534269308048196
Validation loss: 2.643923217654064

Epoch: 6| Step: 8
Training loss: 2.0512614532653073
Validation loss: 2.604456791293346

Epoch: 6| Step: 9
Training loss: 2.416962693159688
Validation loss: 2.6110965356915976

Epoch: 6| Step: 10
Training loss: 3.146322065035026
Validation loss: 2.5628170654643214

Epoch: 6| Step: 11
Training loss: 2.7102591685560604
Validation loss: 2.5664453914759973

Epoch: 6| Step: 12
Training loss: 2.762300033581599
Validation loss: 2.576004666871134

Epoch: 6| Step: 13
Training loss: 2.7159188975218425
Validation loss: 2.6192531499887117

Epoch: 23| Step: 0
Training loss: 2.4935771452002324
Validation loss: 2.6011316288209403

Epoch: 6| Step: 1
Training loss: 2.2801797524919647
Validation loss: 2.6122424270958695

Epoch: 6| Step: 2
Training loss: 3.2305714822691636
Validation loss: 2.5716257499098276

Epoch: 6| Step: 3
Training loss: 2.6342217270687067
Validation loss: 2.6324113187376836

Epoch: 6| Step: 4
Training loss: 2.8778801464920742
Validation loss: 2.5870273748157873

Epoch: 6| Step: 5
Training loss: 3.013712380236544
Validation loss: 2.5949507848425184

Epoch: 6| Step: 6
Training loss: 2.81881073676942
Validation loss: 2.6010248814353005

Epoch: 6| Step: 7
Training loss: 3.124078080563063
Validation loss: 2.6250312894137093

Epoch: 6| Step: 8
Training loss: 2.4241981439086566
Validation loss: 2.5910758515433177

Epoch: 6| Step: 9
Training loss: 2.248969265827453
Validation loss: 2.599957586822829

Epoch: 6| Step: 10
Training loss: 2.4796341100087815
Validation loss: 2.598208620623613

Epoch: 6| Step: 11
Training loss: 2.073462741816023
Validation loss: 2.6612961203952303

Epoch: 6| Step: 12
Training loss: 2.3380207481279456
Validation loss: 2.6022783274058394

Epoch: 6| Step: 13
Training loss: 2.6645014336958495
Validation loss: 2.6632884552062643

Epoch: 24| Step: 0
Training loss: 2.9503629170261556
Validation loss: 2.579357815768363

Epoch: 6| Step: 1
Training loss: 1.4945185962386596
Validation loss: 2.5846385632294817

Epoch: 6| Step: 2
Training loss: 2.6405942113763055
Validation loss: 2.5804962658740864

Epoch: 6| Step: 3
Training loss: 2.24671399384559
Validation loss: 2.6158535570730246

Epoch: 6| Step: 4
Training loss: 1.6605916248969024
Validation loss: 2.6120410327424306

Epoch: 6| Step: 5
Training loss: 2.6746199043682855
Validation loss: 2.6613649226230147

Epoch: 6| Step: 6
Training loss: 2.353880288138858
Validation loss: 2.616301186260284

Epoch: 6| Step: 7
Training loss: 3.0334950421445117
Validation loss: 2.6057340762325754

Epoch: 6| Step: 8
Training loss: 3.171402017440486
Validation loss: 2.5771683276219473

Epoch: 6| Step: 9
Training loss: 2.1551922401305514
Validation loss: 2.5685615798393227

Epoch: 6| Step: 10
Training loss: 2.490727585961721
Validation loss: 2.593295367738528

Epoch: 6| Step: 11
Training loss: 2.5159582071396263
Validation loss: 2.589523502762478

Epoch: 6| Step: 12
Training loss: 3.505097899981133
Validation loss: 2.5541035240379535

Epoch: 6| Step: 13
Training loss: 2.6962467951572067
Validation loss: 2.6597871902494683

Epoch: 25| Step: 0
Training loss: 2.092771159004826
Validation loss: 2.57030647068418

Epoch: 6| Step: 1
Training loss: 2.542303370371434
Validation loss: 2.5712878107342423

Epoch: 6| Step: 2
Training loss: 3.0835141481186605
Validation loss: 2.622216580630913

Epoch: 6| Step: 3
Training loss: 2.7674719898491493
Validation loss: 2.5942146773592496

Epoch: 6| Step: 4
Training loss: 2.4597599179106413
Validation loss: 2.6153633706925885

Epoch: 6| Step: 5
Training loss: 1.6506012370238157
Validation loss: 2.635931489941752

Epoch: 6| Step: 6
Training loss: 2.340945078580742
Validation loss: 2.6232436223021787

Epoch: 6| Step: 7
Training loss: 3.484064883813736
Validation loss: 2.646829422607505

Epoch: 6| Step: 8
Training loss: 2.3238675918087575
Validation loss: 2.6324978875335594

Epoch: 6| Step: 9
Training loss: 2.9581583714572415
Validation loss: 2.588020476916166

Epoch: 6| Step: 10
Training loss: 2.8272928098931556
Validation loss: 2.6315701927909454

Epoch: 6| Step: 11
Training loss: 2.7587057509544435
Validation loss: 2.6123903710879746

Epoch: 6| Step: 12
Training loss: 2.355021926227069
Validation loss: 2.5820623906691655

Epoch: 6| Step: 13
Training loss: 2.3791870552788295
Validation loss: 2.5723820387001894

Epoch: 26| Step: 0
Training loss: 3.922538427647284
Validation loss: 2.563292791651993

Epoch: 6| Step: 1
Training loss: 2.4800509844430643
Validation loss: 2.6055493282762447

Epoch: 6| Step: 2
Training loss: 1.9304110139791075
Validation loss: 2.599026854280079

Epoch: 6| Step: 3
Training loss: 2.4956969421854662
Validation loss: 2.544971933016495

Epoch: 6| Step: 4
Training loss: 2.976160217494642
Validation loss: 2.615538727778115

Epoch: 6| Step: 5
Training loss: 2.3856968166863664
Validation loss: 2.6373943602994023

Epoch: 6| Step: 6
Training loss: 2.915065071334976
Validation loss: 2.6132760116760334

Epoch: 6| Step: 7
Training loss: 2.0874901183117185
Validation loss: 2.667989273699808

Epoch: 6| Step: 8
Training loss: 2.1947850581357655
Validation loss: 2.6118720892538305

Epoch: 6| Step: 9
Training loss: 2.270436721837328
Validation loss: 2.626245763146749

Epoch: 6| Step: 10
Training loss: 2.8288158605631497
Validation loss: 2.6413466090190125

Epoch: 6| Step: 11
Training loss: 2.8159123383120623
Validation loss: 2.6161357227585484

Epoch: 6| Step: 12
Training loss: 1.9726615074767502
Validation loss: 2.605925192592884

Epoch: 6| Step: 13
Training loss: 2.3418391258112545
Validation loss: 2.6196662058786373

Epoch: 27| Step: 0
Training loss: 2.4310159761821057
Validation loss: 2.622379114778949

Epoch: 6| Step: 1
Training loss: 2.4647847454184633
Validation loss: 2.597948513942176

Epoch: 6| Step: 2
Training loss: 2.693127528800494
Validation loss: 2.6588175762073627

Epoch: 6| Step: 3
Training loss: 2.6974865976872153
Validation loss: 2.5998062682111764

Epoch: 6| Step: 4
Training loss: 2.1653970397486457
Validation loss: 2.6188691918584532

Epoch: 6| Step: 5
Training loss: 2.0829373046845605
Validation loss: 2.5724984857488638

Epoch: 6| Step: 6
Training loss: 2.586452098710382
Validation loss: 2.557335153327801

Epoch: 6| Step: 7
Training loss: 2.3760759024778517
Validation loss: 2.612520465436048

Epoch: 6| Step: 8
Training loss: 3.4562764006394495
Validation loss: 2.622467454211945

Epoch: 6| Step: 9
Training loss: 2.8835995641260643
Validation loss: 2.650444867922041

Epoch: 6| Step: 10
Training loss: 2.563791275324529
Validation loss: 2.629990065680381

Epoch: 6| Step: 11
Training loss: 2.684285303822169
Validation loss: 2.5563537265715084

Epoch: 6| Step: 12
Training loss: 2.4109409730284246
Validation loss: 2.5529329222227033

Epoch: 6| Step: 13
Training loss: 2.0382422189422464
Validation loss: 2.626787598794389

Epoch: 28| Step: 0
Training loss: 2.1442824255835573
Validation loss: 2.6452307177551906

Epoch: 6| Step: 1
Training loss: 2.7653688646233037
Validation loss: 2.6709861541050217

Epoch: 6| Step: 2
Training loss: 3.1915544641226066
Validation loss: 2.6665858216746527

Epoch: 6| Step: 3
Training loss: 2.4179551427701735
Validation loss: 2.642943152877766

Epoch: 6| Step: 4
Training loss: 2.259583408984812
Validation loss: 2.670797878234372

Epoch: 6| Step: 5
Training loss: 3.094353665112856
Validation loss: 2.6504762767350623

Epoch: 6| Step: 6
Training loss: 2.441877884132043
Validation loss: 2.640863253587559

Epoch: 6| Step: 7
Training loss: 2.3918316357790683
Validation loss: 2.6335763549531976

Epoch: 6| Step: 8
Training loss: 2.639101028838699
Validation loss: 2.5713523454191574

Epoch: 6| Step: 9
Training loss: 2.846752049359021
Validation loss: 2.631015771995217

Epoch: 6| Step: 10
Training loss: 2.7293601125246063
Validation loss: 2.5466364337298284

Epoch: 6| Step: 11
Training loss: 2.4160391113323874
Validation loss: 2.6314252751220635

Epoch: 6| Step: 12
Training loss: 2.3864862856371967
Validation loss: 2.607687421556738

Epoch: 6| Step: 13
Training loss: 2.1839479217188935
Validation loss: 2.638795026704925

Epoch: 29| Step: 0
Training loss: 2.883251291184602
Validation loss: 2.546372838041925

Epoch: 6| Step: 1
Training loss: 3.047405490176458
Validation loss: 2.6418959514099094

Epoch: 6| Step: 2
Training loss: 2.39479807725214
Validation loss: 2.617779322272757

Epoch: 6| Step: 3
Training loss: 2.4001140885256795
Validation loss: 2.608018198770867

Epoch: 6| Step: 4
Training loss: 2.0746115906979554
Validation loss: 2.673384598773965

Epoch: 6| Step: 5
Training loss: 2.308902519735749
Validation loss: 2.6057927408239707

Epoch: 6| Step: 6
Training loss: 2.518000458539295
Validation loss: 2.5942547931237807

Epoch: 6| Step: 7
Training loss: 2.688426190842136
Validation loss: 2.665584752031276

Epoch: 6| Step: 8
Training loss: 3.043414062510027
Validation loss: 2.5907312467267456

Epoch: 6| Step: 9
Training loss: 2.2786523321149885
Validation loss: 2.5752989644810196

Epoch: 6| Step: 10
Training loss: 2.7810376546999738
Validation loss: 2.612289491413161

Epoch: 6| Step: 11
Training loss: 2.679510794727287
Validation loss: 2.5839782853173707

Epoch: 6| Step: 12
Training loss: 2.1649382984628276
Validation loss: 2.597956658682387

Epoch: 6| Step: 13
Training loss: 2.5956053934291394
Validation loss: 2.5949934770799805

Epoch: 30| Step: 0
Training loss: 2.066730668502292
Validation loss: 2.5825129380445198

Epoch: 6| Step: 1
Training loss: 1.930859537990902
Validation loss: 2.5905430742845237

Epoch: 6| Step: 2
Training loss: 1.9398675420118632
Validation loss: 2.583719675851654

Epoch: 6| Step: 3
Training loss: 2.8660417393096083
Validation loss: 2.658125809687983

Epoch: 6| Step: 4
Training loss: 2.0554872994073454
Validation loss: 2.6457886329138907

Epoch: 6| Step: 5
Training loss: 2.4098527367896767
Validation loss: 2.602023231864934

Epoch: 6| Step: 6
Training loss: 2.6796859874665464
Validation loss: 2.58268770230631

Epoch: 6| Step: 7
Training loss: 2.6819245812538597
Validation loss: 2.6402154036749597

Epoch: 6| Step: 8
Training loss: 3.0977932489605666
Validation loss: 2.6807112670522204

Epoch: 6| Step: 9
Training loss: 2.7445388667877513
Validation loss: 2.605939602378128

Epoch: 6| Step: 10
Training loss: 2.549513590927392
Validation loss: 2.6065682641486116

Epoch: 6| Step: 11
Training loss: 2.651700960229662
Validation loss: 2.642507525372865

Epoch: 6| Step: 12
Training loss: 2.2726550246806165
Validation loss: 2.653668424430923

Epoch: 6| Step: 13
Training loss: 3.4102767800685627
Validation loss: 2.6166783535042346

Epoch: 31| Step: 0
Training loss: 3.1933299585323245
Validation loss: 2.6503778212295894

Epoch: 6| Step: 1
Training loss: 1.9602897151606193
Validation loss: 2.6684682740547316

Epoch: 6| Step: 2
Training loss: 2.8725236925919257
Validation loss: 2.6437444225399744

Epoch: 6| Step: 3
Training loss: 2.1204288908934084
Validation loss: 2.6537923476053242

Epoch: 6| Step: 4
Training loss: 2.2613803432469584
Validation loss: 2.6601019959745207

Epoch: 6| Step: 5
Training loss: 3.2538375206108046
Validation loss: 2.685920901984177

Epoch: 6| Step: 6
Training loss: 2.841818688168001
Validation loss: 2.6095231217851484

Epoch: 6| Step: 7
Training loss: 2.1824558411770316
Validation loss: 2.6305449216905887

Epoch: 6| Step: 8
Training loss: 2.029896211648743
Validation loss: 2.5857061645663295

Epoch: 6| Step: 9
Training loss: 2.327199662413561
Validation loss: 2.659760866363059

Epoch: 6| Step: 10
Training loss: 2.885351040274017
Validation loss: 2.5986083004576814

Epoch: 6| Step: 11
Training loss: 2.213311851389556
Validation loss: 2.62119054639266

Epoch: 6| Step: 12
Training loss: 3.310439998735741
Validation loss: 2.5981270346757075

Epoch: 6| Step: 13
Training loss: 2.0199249297063417
Validation loss: 2.6111558939653383

Epoch: 32| Step: 0
Training loss: 2.4307425315025792
Validation loss: 2.6303135816207717

Epoch: 6| Step: 1
Training loss: 2.460659919706093
Validation loss: 2.5911248338829242

Epoch: 6| Step: 2
Training loss: 2.4158847683969458
Validation loss: 2.601628047816147

Epoch: 6| Step: 3
Training loss: 1.635686362153727
Validation loss: 2.579523389322415

Epoch: 6| Step: 4
Training loss: 2.8715670448538755
Validation loss: 2.5749218086296604

Epoch: 6| Step: 5
Training loss: 2.62765005857368
Validation loss: 2.6073336735164907

Epoch: 6| Step: 6
Training loss: 2.996316237562951
Validation loss: 2.61202992738264

Epoch: 6| Step: 7
Training loss: 3.062913516406295
Validation loss: 2.620759960738468

Epoch: 6| Step: 8
Training loss: 2.898765524838662
Validation loss: 2.619324603957092

Epoch: 6| Step: 9
Training loss: 2.6894777694381946
Validation loss: 2.5717478708741894

Epoch: 6| Step: 10
Training loss: 2.354233754870319
Validation loss: 2.567244920574065

Epoch: 6| Step: 11
Training loss: 2.2495303193588754
Validation loss: 2.6125210282058964

Epoch: 6| Step: 12
Training loss: 2.037258358533665
Validation loss: 2.5912884671364256

Epoch: 6| Step: 13
Training loss: 2.5740505505083355
Validation loss: 2.6502134507063406

Epoch: 33| Step: 0
Training loss: 2.6825899026244846
Validation loss: 2.5491450359985146

Epoch: 6| Step: 1
Training loss: 1.6664327298334916
Validation loss: 2.6541537821011327

Epoch: 6| Step: 2
Training loss: 2.7162044490781425
Validation loss: 2.619277142658525

Epoch: 6| Step: 3
Training loss: 2.4393112104687575
Validation loss: 2.5764036655145084

Epoch: 6| Step: 4
Training loss: 2.291260376952003
Validation loss: 2.588838469428647

Epoch: 6| Step: 5
Training loss: 2.385684424507953
Validation loss: 2.6130911810711344

Epoch: 6| Step: 6
Training loss: 2.9858525797587125
Validation loss: 2.638351816324286

Epoch: 6| Step: 7
Training loss: 2.1718408595633334
Validation loss: 2.592449858182713

Epoch: 6| Step: 8
Training loss: 2.9082642824853084
Validation loss: 2.590089873542881

Epoch: 6| Step: 9
Training loss: 2.9336009019137186
Validation loss: 2.6064278564021035

Epoch: 6| Step: 10
Training loss: 2.123259224050005
Validation loss: 2.6068015133287354

Epoch: 6| Step: 11
Training loss: 2.696400121648831
Validation loss: 2.583524563592306

Epoch: 6| Step: 12
Training loss: 2.4340235053614623
Validation loss: 2.64710894695107

Epoch: 6| Step: 13
Training loss: 2.7075687992164177
Validation loss: 2.571726339624015

Epoch: 34| Step: 0
Training loss: 2.5962231346948035
Validation loss: 2.5962437663939393

Epoch: 6| Step: 1
Training loss: 2.1945369341495895
Validation loss: 2.6476735351334457

Epoch: 6| Step: 2
Training loss: 2.8789105564121455
Validation loss: 2.6284195561398

Epoch: 6| Step: 3
Training loss: 3.101489779679209
Validation loss: 2.611723659463981

Epoch: 6| Step: 4
Training loss: 2.2862637957724528
Validation loss: 2.5797790461808643

Epoch: 6| Step: 5
Training loss: 1.732179300040034
Validation loss: 2.600400678620844

Epoch: 6| Step: 6
Training loss: 2.3872181671126285
Validation loss: 2.580234519960109

Epoch: 6| Step: 7
Training loss: 2.4401873910581138
Validation loss: 2.5780118050434444

Epoch: 6| Step: 8
Training loss: 3.3082550487977054
Validation loss: 2.631152390869149

Epoch: 6| Step: 9
Training loss: 2.200585166096097
Validation loss: 2.560214985497814

Epoch: 6| Step: 10
Training loss: 2.77254744741087
Validation loss: 2.608570088944429

Epoch: 6| Step: 11
Training loss: 2.7560594730742505
Validation loss: 2.6777878711197163

Epoch: 6| Step: 12
Training loss: 2.367674925322721
Validation loss: 2.679487867861872

Epoch: 6| Step: 13
Training loss: 2.2755152066551863
Validation loss: 2.604238727844126

Epoch: 35| Step: 0
Training loss: 2.3395518023663873
Validation loss: 2.627821057343852

Epoch: 6| Step: 1
Training loss: 2.550169049063707
Validation loss: 2.597997825556064

Epoch: 6| Step: 2
Training loss: 2.4389343931876644
Validation loss: 2.6454962843630523

Epoch: 6| Step: 3
Training loss: 2.8342116808286577
Validation loss: 2.6455755759012205

Epoch: 6| Step: 4
Training loss: 2.2110845833640194
Validation loss: 2.5424806562980056

Epoch: 6| Step: 5
Training loss: 2.9412314881059562
Validation loss: 2.604386867114412

Epoch: 6| Step: 6
Training loss: 1.961937880952978
Validation loss: 2.6685285227681166

Epoch: 6| Step: 7
Training loss: 2.781895423322248
Validation loss: 2.6006923285626944

Epoch: 6| Step: 8
Training loss: 2.528601874229016
Validation loss: 2.6369964528721166

Epoch: 6| Step: 9
Training loss: 2.3593781325969996
Validation loss: 2.659281911389954

Epoch: 6| Step: 10
Training loss: 2.353568909861013
Validation loss: 2.663158050668639

Epoch: 6| Step: 11
Training loss: 2.7770813121821685
Validation loss: 2.6415312827604223

Epoch: 6| Step: 12
Training loss: 2.7166317108651343
Validation loss: 2.6858980890134005

Epoch: 6| Step: 13
Training loss: 2.6027790696086504
Validation loss: 2.587539883243246

Epoch: 36| Step: 0
Training loss: 2.2009117967956304
Validation loss: 2.640804307255877

Epoch: 6| Step: 1
Training loss: 2.150838058724645
Validation loss: 2.596344902203151

Epoch: 6| Step: 2
Training loss: 2.1773595923650535
Validation loss: 2.631017644775913

Epoch: 6| Step: 3
Training loss: 3.1147218671287993
Validation loss: 2.5897178868645017

Epoch: 6| Step: 4
Training loss: 2.110566657392135
Validation loss: 2.588243537687197

Epoch: 6| Step: 5
Training loss: 2.5426995622753705
Validation loss: 2.625575305323456

Epoch: 6| Step: 6
Training loss: 1.6080469373903057
Validation loss: 2.615996785480768

Epoch: 6| Step: 7
Training loss: 2.63399454177372
Validation loss: 2.680087090329775

Epoch: 6| Step: 8
Training loss: 2.715070492723263
Validation loss: 2.5897283974298992

Epoch: 6| Step: 9
Training loss: 2.009135126061199
Validation loss: 2.616180560239531

Epoch: 6| Step: 10
Training loss: 2.87991493390869
Validation loss: 2.604956397791787

Epoch: 6| Step: 11
Training loss: 3.0705525932882853
Validation loss: 2.6158383360303774

Epoch: 6| Step: 12
Training loss: 2.6058092252297054
Validation loss: 2.6024364420189654

Epoch: 6| Step: 13
Training loss: 2.4865949776707295
Validation loss: 2.5878500343834205

Epoch: 37| Step: 0
Training loss: 2.6900473653601082
Validation loss: 2.641332798586924

Epoch: 6| Step: 1
Training loss: 1.9667251104086991
Validation loss: 2.6544660224754284

Epoch: 6| Step: 2
Training loss: 2.3822033713296324
Validation loss: 2.6300504932947324

Epoch: 6| Step: 3
Training loss: 2.644356974010838
Validation loss: 2.6258209549363825

Epoch: 6| Step: 4
Training loss: 2.302257537004302
Validation loss: 2.626304105733617

Epoch: 6| Step: 5
Training loss: 1.9493940805844894
Validation loss: 2.707922586447385

Epoch: 6| Step: 6
Training loss: 1.8763225976977156
Validation loss: 2.673149325521957

Epoch: 6| Step: 7
Training loss: 2.8017070096855843
Validation loss: 2.6364662633500546

Epoch: 6| Step: 8
Training loss: 3.3741247667038308
Validation loss: 2.649838679879567

Epoch: 6| Step: 9
Training loss: 2.8967135255781815
Validation loss: 2.593954300398711

Epoch: 6| Step: 10
Training loss: 2.246280244465509
Validation loss: 2.5925577096699026

Epoch: 6| Step: 11
Training loss: 2.249465031074142
Validation loss: 2.609092788511342

Epoch: 6| Step: 12
Training loss: 2.4581633902393047
Validation loss: 2.573769545157452

Epoch: 6| Step: 13
Training loss: 2.479375547270045
Validation loss: 2.6752111119897397

Epoch: 38| Step: 0
Training loss: 2.171530167902598
Validation loss: 2.6523917956488106

Epoch: 6| Step: 1
Training loss: 2.6618272459749432
Validation loss: 2.6643527964425116

Epoch: 6| Step: 2
Training loss: 2.0126370306336003
Validation loss: 2.62253347197907

Epoch: 6| Step: 3
Training loss: 2.032454852251442
Validation loss: 2.636620609670491

Epoch: 6| Step: 4
Training loss: 2.7171424410101817
Validation loss: 2.604854475106867

Epoch: 6| Step: 5
Training loss: 1.9736709855289083
Validation loss: 2.6080659030484177

Epoch: 6| Step: 6
Training loss: 2.311880492662524
Validation loss: 2.614745911385381

Epoch: 6| Step: 7
Training loss: 1.9954412480027963
Validation loss: 2.618775943758087

Epoch: 6| Step: 8
Training loss: 2.79622723627694
Validation loss: 2.6152960475860403

Epoch: 6| Step: 9
Training loss: 2.977418471084158
Validation loss: 2.591918758467245

Epoch: 6| Step: 10
Training loss: 2.83887004294447
Validation loss: 2.621620227679692

Epoch: 6| Step: 11
Training loss: 2.592971960826057
Validation loss: 2.602434510498118

Epoch: 6| Step: 12
Training loss: 2.025522343648156
Validation loss: 2.5675561381352883

Epoch: 6| Step: 13
Training loss: 2.712850198245402
Validation loss: 2.624100001015198

Epoch: 39| Step: 0
Training loss: 3.3012817725631827
Validation loss: 2.653899555349455

Epoch: 6| Step: 1
Training loss: 2.0580289525552513
Validation loss: 2.646161154215226

Epoch: 6| Step: 2
Training loss: 3.039559840912703
Validation loss: 2.6173437726636424

Epoch: 6| Step: 3
Training loss: 2.410147544808023
Validation loss: 2.622270769901912

Epoch: 6| Step: 4
Training loss: 2.113159176161698
Validation loss: 2.633848460028266

Epoch: 6| Step: 5
Training loss: 2.464744311955183
Validation loss: 2.5955225544684826

Epoch: 6| Step: 6
Training loss: 1.9216832010970013
Validation loss: 2.6117143176595854

Epoch: 6| Step: 7
Training loss: 2.0734572224947456
Validation loss: 2.619701669612125

Epoch: 6| Step: 8
Training loss: 2.193577634120585
Validation loss: 2.5930392965351783

Epoch: 6| Step: 9
Training loss: 2.713632876180607
Validation loss: 2.6186012283468187

Epoch: 6| Step: 10
Training loss: 2.0235166791940613
Validation loss: 2.612979462840829

Epoch: 6| Step: 11
Training loss: 1.8174730675130386
Validation loss: 2.5775553835059464

Epoch: 6| Step: 12
Training loss: 2.056198898654417
Validation loss: 2.6108121359782746

Epoch: 6| Step: 13
Training loss: 3.2005414266314354
Validation loss: 2.587781926397406

Epoch: 40| Step: 0
Training loss: 2.3373362968362206
Validation loss: 2.6333320625720598

Epoch: 6| Step: 1
Training loss: 1.9512487325719203
Validation loss: 2.6234124999438913

Epoch: 6| Step: 2
Training loss: 2.506449962068566
Validation loss: 2.6976189884838644

Epoch: 6| Step: 3
Training loss: 3.209353462302975
Validation loss: 2.6568200341216803

Epoch: 6| Step: 4
Training loss: 2.0296957084836302
Validation loss: 2.6758491303310157

Epoch: 6| Step: 5
Training loss: 2.383537107261625
Validation loss: 2.6397584324672634

Epoch: 6| Step: 6
Training loss: 2.2528139108607648
Validation loss: 2.675661478819411

Epoch: 6| Step: 7
Training loss: 2.85880911808911
Validation loss: 2.650699950692664

Epoch: 6| Step: 8
Training loss: 1.789088886183013
Validation loss: 2.614691611754407

Epoch: 6| Step: 9
Training loss: 2.309255437375612
Validation loss: 2.643418393933189

Epoch: 6| Step: 10
Training loss: 3.105379076928577
Validation loss: 2.6293402923307476

Epoch: 6| Step: 11
Training loss: 2.0448601976655585
Validation loss: 2.5767585446935386

Epoch: 6| Step: 12
Training loss: 2.1685499907068833
Validation loss: 2.672619022636806

Epoch: 6| Step: 13
Training loss: 2.735168516278104
Validation loss: 2.6426786904983723

Epoch: 41| Step: 0
Training loss: 2.4344932400117365
Validation loss: 2.6512240563825458

Epoch: 6| Step: 1
Training loss: 2.153440220407205
Validation loss: 2.600713024121138

Epoch: 6| Step: 2
Training loss: 1.8869364674056057
Validation loss: 2.7064013902050768

Epoch: 6| Step: 3
Training loss: 2.5025980800802077
Validation loss: 2.715142352105626

Epoch: 6| Step: 4
Training loss: 2.46674564939637
Validation loss: 2.6799691870564444

Epoch: 6| Step: 5
Training loss: 2.3453264148357826
Validation loss: 2.6888550587654865

Epoch: 6| Step: 6
Training loss: 3.171490124432835
Validation loss: 2.6169583652076907

Epoch: 6| Step: 7
Training loss: 2.416377170805873
Validation loss: 2.611490697752733

Epoch: 6| Step: 8
Training loss: 2.1463837396080434
Validation loss: 2.6228398108540443

Epoch: 6| Step: 9
Training loss: 2.328550056723862
Validation loss: 2.632287823083384

Epoch: 6| Step: 10
Training loss: 2.5428939316110526
Validation loss: 2.6558087823972083

Epoch: 6| Step: 11
Training loss: 2.1824773619920803
Validation loss: 2.7208846762594887

Epoch: 6| Step: 12
Training loss: 1.7922548023680474
Validation loss: 2.7141548288907242

Epoch: 6| Step: 13
Training loss: 3.462455881436758
Validation loss: 2.7500931695125073

Epoch: 42| Step: 0
Training loss: 2.1062457574184714
Validation loss: 2.7679259360534956

Epoch: 6| Step: 1
Training loss: 2.8876244720449256
Validation loss: 2.7779836297583915

Epoch: 6| Step: 2
Training loss: 2.0759289833593577
Validation loss: 2.7394926300311737

Epoch: 6| Step: 3
Training loss: 2.14957622521232
Validation loss: 2.6395730024184276

Epoch: 6| Step: 4
Training loss: 2.6376555410505866
Validation loss: 2.6413144372198034

Epoch: 6| Step: 5
Training loss: 2.144365370263781
Validation loss: 2.5658778900394346

Epoch: 6| Step: 6
Training loss: 2.4464418770882728
Validation loss: 2.556570418841054

Epoch: 6| Step: 7
Training loss: 2.7313411775991088
Validation loss: 2.583783346378356

Epoch: 6| Step: 8
Training loss: 2.7950018891957678
Validation loss: 2.6003708807197734

Epoch: 6| Step: 9
Training loss: 2.4678232892174834
Validation loss: 2.555643958368695

Epoch: 6| Step: 10
Training loss: 2.762428634895502
Validation loss: 2.6257185633678035

Epoch: 6| Step: 11
Training loss: 2.304668258328045
Validation loss: 2.58595807546553

Epoch: 6| Step: 12
Training loss: 2.131600059779004
Validation loss: 2.6415045061690985

Epoch: 6| Step: 13
Training loss: 2.1477160542953366
Validation loss: 2.6586917350589023

Epoch: 43| Step: 0
Training loss: 2.368233729645362
Validation loss: 2.5805071912676514

Epoch: 6| Step: 1
Training loss: 2.62983258777004
Validation loss: 2.569576517496791

Epoch: 6| Step: 2
Training loss: 2.170496001975651
Validation loss: 2.585904400662649

Epoch: 6| Step: 3
Training loss: 2.2676714895184884
Validation loss: 2.6761419716747854

Epoch: 6| Step: 4
Training loss: 2.7548303663365625
Validation loss: 2.7112205277009593

Epoch: 6| Step: 5
Training loss: 1.696128402770646
Validation loss: 2.681049605011566

Epoch: 6| Step: 6
Training loss: 2.2062081481595004
Validation loss: 2.573777318682573

Epoch: 6| Step: 7
Training loss: 1.7913137872043847
Validation loss: 2.626090065614645

Epoch: 6| Step: 8
Training loss: 2.671850907066539
Validation loss: 2.6128424108270143

Epoch: 6| Step: 9
Training loss: 2.713511451557851
Validation loss: 2.655887137666884

Epoch: 6| Step: 10
Training loss: 2.017338460626198
Validation loss: 2.68051988669093

Epoch: 6| Step: 11
Training loss: 3.3757925162715554
Validation loss: 2.684105140938618

Epoch: 6| Step: 12
Training loss: 2.53217863779731
Validation loss: 2.6620647140268145

Epoch: 6| Step: 13
Training loss: 2.213672900330074
Validation loss: 2.641258449682346

Epoch: 44| Step: 0
Training loss: 2.904822214172025
Validation loss: 2.6280918456415683

Epoch: 6| Step: 1
Training loss: 2.268927751624067
Validation loss: 2.5813693199874135

Epoch: 6| Step: 2
Training loss: 2.3779389116864214
Validation loss: 2.6197367384949546

Epoch: 6| Step: 3
Training loss: 2.610751582705471
Validation loss: 2.6470727845885507

Epoch: 6| Step: 4
Training loss: 2.7720886388976664
Validation loss: 2.677969111887634

Epoch: 6| Step: 5
Training loss: 2.173617425597271
Validation loss: 2.664868125777948

Epoch: 6| Step: 6
Training loss: 3.012017657021774
Validation loss: 2.653019447758158

Epoch: 6| Step: 7
Training loss: 2.0625203449517397
Validation loss: 2.6124365201109665

Epoch: 6| Step: 8
Training loss: 2.1489198455347185
Validation loss: 2.600342366100881

Epoch: 6| Step: 9
Training loss: 2.4563408444133126
Validation loss: 2.656804778562669

Epoch: 6| Step: 10
Training loss: 2.6860436330334565
Validation loss: 2.6295068441174863

Epoch: 6| Step: 11
Training loss: 1.867344422709341
Validation loss: 2.6436223581702425

Epoch: 6| Step: 12
Training loss: 2.367736954074799
Validation loss: 2.6761055779958087

Epoch: 6| Step: 13
Training loss: 1.6735408006657382
Validation loss: 2.624456606737244

Epoch: 45| Step: 0
Training loss: 1.9013083771641208
Validation loss: 2.6570826403508434

Epoch: 6| Step: 1
Training loss: 2.247824146628254
Validation loss: 2.579016036368472

Epoch: 6| Step: 2
Training loss: 2.8492643109489615
Validation loss: 2.6328386480917665

Epoch: 6| Step: 3
Training loss: 2.9302501087395365
Validation loss: 2.5597294662500953

Epoch: 6| Step: 4
Training loss: 2.3144423086179216
Validation loss: 2.6136339802033786

Epoch: 6| Step: 5
Training loss: 1.9767422198587181
Validation loss: 2.590851186488559

Epoch: 6| Step: 6
Training loss: 2.251212429175806
Validation loss: 2.599304869233822

Epoch: 6| Step: 7
Training loss: 1.9227886974312811
Validation loss: 2.6359826160030377

Epoch: 6| Step: 8
Training loss: 2.809514813874432
Validation loss: 2.578502111115873

Epoch: 6| Step: 9
Training loss: 1.970198204603685
Validation loss: 2.6685643497070526

Epoch: 6| Step: 10
Training loss: 2.115092011202073
Validation loss: 2.6010556266592353

Epoch: 6| Step: 11
Training loss: 2.3875271540989975
Validation loss: 2.6802656552801913

Epoch: 6| Step: 12
Training loss: 3.2042484453246183
Validation loss: 2.640497735020902

Epoch: 6| Step: 13
Training loss: 2.218454045718844
Validation loss: 2.608656915777895

Epoch: 46| Step: 0
Training loss: 2.5961397491246236
Validation loss: 2.6163094713110557

Epoch: 6| Step: 1
Training loss: 2.810916115561246
Validation loss: 2.656434864268307

Epoch: 6| Step: 2
Training loss: 2.677729566974622
Validation loss: 2.686783125729994

Epoch: 6| Step: 3
Training loss: 1.5696635257470528
Validation loss: 2.6311582958584196

Epoch: 6| Step: 4
Training loss: 2.759922679149772
Validation loss: 2.6057019298552517

Epoch: 6| Step: 5
Training loss: 2.2684616746361868
Validation loss: 2.6143671126204504

Epoch: 6| Step: 6
Training loss: 2.051653460355018
Validation loss: 2.5806272905542356

Epoch: 6| Step: 7
Training loss: 2.5364989500037964
Validation loss: 2.5912307853127405

Epoch: 6| Step: 8
Training loss: 1.921918977063701
Validation loss: 2.614904107912191

Epoch: 6| Step: 9
Training loss: 1.7408151738431112
Validation loss: 2.623903196774472

Epoch: 6| Step: 10
Training loss: 1.6012788847105532
Validation loss: 2.605595819595508

Epoch: 6| Step: 11
Training loss: 2.9775198450716345
Validation loss: 2.570441902714079

Epoch: 6| Step: 12
Training loss: 2.3365081804468226
Validation loss: 2.693798417602538

Epoch: 6| Step: 13
Training loss: 2.521645585867268
Validation loss: 2.6056801073019598

Epoch: 47| Step: 0
Training loss: 2.190252479735565
Validation loss: 2.660285681415319

Epoch: 6| Step: 1
Training loss: 2.8494452154030783
Validation loss: 2.71763763472242

Epoch: 6| Step: 2
Training loss: 2.6347690635981085
Validation loss: 2.6867648235458867

Epoch: 6| Step: 3
Training loss: 1.6001583736239082
Validation loss: 2.6080528153120817

Epoch: 6| Step: 4
Training loss: 2.260116826810353
Validation loss: 2.6474594665921

Epoch: 6| Step: 5
Training loss: 2.523418698078416
Validation loss: 2.627065315356218

Epoch: 6| Step: 6
Training loss: 2.424238663547662
Validation loss: 2.6019126266995314

Epoch: 6| Step: 7
Training loss: 2.25275824282646
Validation loss: 2.5642599094543166

Epoch: 6| Step: 8
Training loss: 2.1703085979649046
Validation loss: 2.6205205086794314

Epoch: 6| Step: 9
Training loss: 2.0992979874472555
Validation loss: 2.677758934377672

Epoch: 6| Step: 10
Training loss: 2.471939537469373
Validation loss: 2.613990181946552

Epoch: 6| Step: 11
Training loss: 2.651316470509402
Validation loss: 2.6467124399635846

Epoch: 6| Step: 12
Training loss: 2.3586048612430806
Validation loss: 2.6531681058786987

Epoch: 6| Step: 13
Training loss: 2.215415060107204
Validation loss: 2.5240901579354404

Epoch: 48| Step: 0
Training loss: 2.260935909795301
Validation loss: 2.635018040862506

Epoch: 6| Step: 1
Training loss: 3.014414806352281
Validation loss: 2.6491064991517734

Epoch: 6| Step: 2
Training loss: 2.067871958474583
Validation loss: 2.5795725987286566

Epoch: 6| Step: 3
Training loss: 2.4303303447714257
Validation loss: 2.6369684849903914

Epoch: 6| Step: 4
Training loss: 2.1100153198409197
Validation loss: 2.7062115109285756

Epoch: 6| Step: 5
Training loss: 2.122180526827547
Validation loss: 2.617787564696882

Epoch: 6| Step: 6
Training loss: 1.6771359958633663
Validation loss: 2.7073250776702174

Epoch: 6| Step: 7
Training loss: 2.1295754037240577
Validation loss: 2.622199668984849

Epoch: 6| Step: 8
Training loss: 2.962416468219274
Validation loss: 2.6780944774999726

Epoch: 6| Step: 9
Training loss: 1.5233863235094103
Validation loss: 2.6421806673743244

Epoch: 6| Step: 10
Training loss: 2.0372994353451856
Validation loss: 2.6079272672168874

Epoch: 6| Step: 11
Training loss: 2.3412746327535654
Validation loss: 2.6689181856260316

Epoch: 6| Step: 12
Training loss: 2.6792760594303675
Validation loss: 2.6528505300916847

Epoch: 6| Step: 13
Training loss: 2.705900145860012
Validation loss: 2.7110987458659292

Epoch: 49| Step: 0
Training loss: 2.264832246138644
Validation loss: 2.592462013061968

Epoch: 6| Step: 1
Training loss: 3.259157484043743
Validation loss: 2.644630584278652

Epoch: 6| Step: 2
Training loss: 2.575006714599151
Validation loss: 2.6484761568172117

Epoch: 6| Step: 3
Training loss: 2.040129517576354
Validation loss: 2.6463846147979493

Epoch: 6| Step: 4
Training loss: 1.8105554343867931
Validation loss: 2.6235339899969876

Epoch: 6| Step: 5
Training loss: 2.8252910092784025
Validation loss: 2.6920732724485363

Epoch: 6| Step: 6
Training loss: 1.8986828806341987
Validation loss: 2.6375169539547

Epoch: 6| Step: 7
Training loss: 1.6345418870377586
Validation loss: 2.587509415098006

Epoch: 6| Step: 8
Training loss: 2.578233196415735
Validation loss: 2.606711575917204

Epoch: 6| Step: 9
Training loss: 2.345957009379319
Validation loss: 2.7016849099574234

Epoch: 6| Step: 10
Training loss: 2.225209678456874
Validation loss: 2.678175845529649

Epoch: 6| Step: 11
Training loss: 2.4670158766230617
Validation loss: 2.626198116748059

Epoch: 6| Step: 12
Training loss: 2.5049037523491227
Validation loss: 2.6834342942485807

Epoch: 6| Step: 13
Training loss: 1.6022152942667003
Validation loss: 2.6797422916901623

Epoch: 50| Step: 0
Training loss: 2.0013954539577026
Validation loss: 2.62985179234533

Epoch: 6| Step: 1
Training loss: 2.5545243610707082
Validation loss: 2.721896167180838

Epoch: 6| Step: 2
Training loss: 2.6055496409154086
Validation loss: 2.7465332460945135

Epoch: 6| Step: 3
Training loss: 1.9036459098708054
Validation loss: 2.6432601601172574

Epoch: 6| Step: 4
Training loss: 2.700063747077326
Validation loss: 2.6583374124055217

Epoch: 6| Step: 5
Training loss: 2.648500874979207
Validation loss: 2.698885877356383

Epoch: 6| Step: 6
Training loss: 2.13674340939981
Validation loss: 2.7175699062532934

Epoch: 6| Step: 7
Training loss: 1.992344509744189
Validation loss: 2.666590083532555

Epoch: 6| Step: 8
Training loss: 1.8837966562832946
Validation loss: 2.6222666860459247

Epoch: 6| Step: 9
Training loss: 2.742426935159794
Validation loss: 2.6810772612681038

Epoch: 6| Step: 10
Training loss: 2.610035612806072
Validation loss: 2.622712682821954

Epoch: 6| Step: 11
Training loss: 2.379412918129373
Validation loss: 2.5940546599864263

Epoch: 6| Step: 12
Training loss: 2.411895272949931
Validation loss: 2.6926650308832443

Epoch: 6| Step: 13
Training loss: 1.8075740567939886
Validation loss: 2.646671347682026

Epoch: 51| Step: 0
Training loss: 2.555257471179481
Validation loss: 2.6591091251712653

Epoch: 6| Step: 1
Training loss: 2.220243354381078
Validation loss: 2.6659188091132773

Epoch: 6| Step: 2
Training loss: 2.779082064124884
Validation loss: 2.6796702837599513

Epoch: 6| Step: 3
Training loss: 2.5236051049094237
Validation loss: 2.646910520733347

Epoch: 6| Step: 4
Training loss: 1.8286671934851373
Validation loss: 2.6485979824899886

Epoch: 6| Step: 5
Training loss: 1.9714342014556168
Validation loss: 2.6397257671350016

Epoch: 6| Step: 6
Training loss: 1.6090952806065626
Validation loss: 2.640017527994094

Epoch: 6| Step: 7
Training loss: 2.536870861515298
Validation loss: 2.7007261594862833

Epoch: 6| Step: 8
Training loss: 2.5151521226444187
Validation loss: 2.73510802843098

Epoch: 6| Step: 9
Training loss: 1.5656017035237724
Validation loss: 2.6923401960307736

Epoch: 6| Step: 10
Training loss: 2.234726884783184
Validation loss: 2.591494333930166

Epoch: 6| Step: 11
Training loss: 1.5725814596888703
Validation loss: 2.7335649870967087

Epoch: 6| Step: 12
Training loss: 3.045133905081668
Validation loss: 2.6496334770134102

Epoch: 6| Step: 13
Training loss: 2.5538931728715557
Validation loss: 2.6194534740739592

Epoch: 52| Step: 0
Training loss: 2.0083769364853667
Validation loss: 2.7350358001067554

Epoch: 6| Step: 1
Training loss: 2.401422091209737
Validation loss: 2.6175210692739723

Epoch: 6| Step: 2
Training loss: 2.6833876262724385
Validation loss: 2.675662377308858

Epoch: 6| Step: 3
Training loss: 2.302403860663384
Validation loss: 2.64210122883316

Epoch: 6| Step: 4
Training loss: 2.711649952254533
Validation loss: 2.63389402186754

Epoch: 6| Step: 5
Training loss: 2.376082926359476
Validation loss: 2.681644848113822

Epoch: 6| Step: 6
Training loss: 2.199929808450573
Validation loss: 2.5565986134433816

Epoch: 6| Step: 7
Training loss: 2.4428619683488115
Validation loss: 2.6478588180965956

Epoch: 6| Step: 8
Training loss: 1.8197444962791565
Validation loss: 2.711942649455281

Epoch: 6| Step: 9
Training loss: 2.541904584244907
Validation loss: 2.667590880176123

Epoch: 6| Step: 10
Training loss: 1.872616715505257
Validation loss: 2.6577873867193276

Epoch: 6| Step: 11
Training loss: 2.1126611050000608
Validation loss: 2.692148830544214

Epoch: 6| Step: 12
Training loss: 1.9028561507123851
Validation loss: 2.5956789986259623

Epoch: 6| Step: 13
Training loss: 2.7834811744334274
Validation loss: 2.6141594825656456

Epoch: 53| Step: 0
Training loss: 2.3835057985376493
Validation loss: 2.6111175596775302

Epoch: 6| Step: 1
Training loss: 1.7468285433301949
Validation loss: 2.603696755291996

Epoch: 6| Step: 2
Training loss: 2.2686970896370426
Validation loss: 2.5997744994309095

Epoch: 6| Step: 3
Training loss: 1.8659781525897838
Validation loss: 2.679325134866888

Epoch: 6| Step: 4
Training loss: 1.746446953536618
Validation loss: 2.667222268120599

Epoch: 6| Step: 5
Training loss: 3.0327382317892444
Validation loss: 2.6246384114285255

Epoch: 6| Step: 6
Training loss: 2.9061266144843145
Validation loss: 2.612749898174482

Epoch: 6| Step: 7
Training loss: 1.8223173046245627
Validation loss: 2.611817851588877

Epoch: 6| Step: 8
Training loss: 2.597078508649735
Validation loss: 2.6610863133838882

Epoch: 6| Step: 9
Training loss: 1.720770116881031
Validation loss: 2.6446922474870784

Epoch: 6| Step: 10
Training loss: 1.7311623864434829
Validation loss: 2.611282732466082

Epoch: 6| Step: 11
Training loss: 2.640808821380128
Validation loss: 2.670925023552744

Epoch: 6| Step: 12
Training loss: 2.6118092404001763
Validation loss: 2.6472454257716262

Epoch: 6| Step: 13
Training loss: 2.424130675240023
Validation loss: 2.6437450387846537

Epoch: 54| Step: 0
Training loss: 2.469005716335003
Validation loss: 2.638330474686495

Epoch: 6| Step: 1
Training loss: 2.388174958214427
Validation loss: 2.645005860180964

Epoch: 6| Step: 2
Training loss: 2.152166397347979
Validation loss: 2.689557330426651

Epoch: 6| Step: 3
Training loss: 2.3642370387743896
Validation loss: 2.682580178061869

Epoch: 6| Step: 4
Training loss: 2.20168024402083
Validation loss: 2.610709711316462

Epoch: 6| Step: 5
Training loss: 2.401179929601547
Validation loss: 2.6526999592532174

Epoch: 6| Step: 6
Training loss: 2.497077759875969
Validation loss: 2.6581738479949055

Epoch: 6| Step: 7
Training loss: 2.8226650918906024
Validation loss: 2.707858943962808

Epoch: 6| Step: 8
Training loss: 1.780479398313101
Validation loss: 2.64302493404126

Epoch: 6| Step: 9
Training loss: 1.7733177783231266
Validation loss: 2.6665663600971032

Epoch: 6| Step: 10
Training loss: 1.943118961357974
Validation loss: 2.6648723531049283

Epoch: 6| Step: 11
Training loss: 2.09852556511097
Validation loss: 2.6008225038647863

Epoch: 6| Step: 12
Training loss: 2.498726138773386
Validation loss: 2.646266246031618

Epoch: 6| Step: 13
Training loss: 2.132456990889421
Validation loss: 2.6309133862542264

Epoch: 55| Step: 0
Training loss: 2.695192373059001
Validation loss: 2.639926584793171

Epoch: 6| Step: 1
Training loss: 2.007037298862345
Validation loss: 2.7172128051375033

Epoch: 6| Step: 2
Training loss: 2.0835497044419475
Validation loss: 2.650818473748686

Epoch: 6| Step: 3
Training loss: 2.2188060914592294
Validation loss: 2.640856324546486

Epoch: 6| Step: 4
Training loss: 2.1028390857264814
Validation loss: 2.6535334589820447

Epoch: 6| Step: 5
Training loss: 2.6023648144646203
Validation loss: 2.6684119553174788

Epoch: 6| Step: 6
Training loss: 2.0992215530268896
Validation loss: 2.6780134927866976

Epoch: 6| Step: 7
Training loss: 3.025303149205429
Validation loss: 2.69711130903745

Epoch: 6| Step: 8
Training loss: 2.118954754953498
Validation loss: 2.58932632639939

Epoch: 6| Step: 9
Training loss: 2.0853007627042817
Validation loss: 2.7336998678249578

Epoch: 6| Step: 10
Training loss: 1.426455320111162
Validation loss: 2.6453757653854977

Epoch: 6| Step: 11
Training loss: 2.0314896662245294
Validation loss: 2.67473065990056

Epoch: 6| Step: 12
Training loss: 2.3161609642015524
Validation loss: 2.668880978779113

Epoch: 6| Step: 13
Training loss: 1.908868211084788
Validation loss: 2.7589853186553763

Epoch: 56| Step: 0
Training loss: 1.6703689779755273
Validation loss: 2.7643293517521927

Epoch: 6| Step: 1
Training loss: 1.8606537340717737
Validation loss: 2.680632725748456

Epoch: 6| Step: 2
Training loss: 2.696892582028254
Validation loss: 2.7751513419823746

Epoch: 6| Step: 3
Training loss: 2.024617797198139
Validation loss: 2.714052592749733

Epoch: 6| Step: 4
Training loss: 1.9462793850502633
Validation loss: 2.6668598929573997

Epoch: 6| Step: 5
Training loss: 2.219078469476153
Validation loss: 2.64145856412667

Epoch: 6| Step: 6
Training loss: 2.3389371156691423
Validation loss: 2.6469673720105744

Epoch: 6| Step: 7
Training loss: 1.8496641575918928
Validation loss: 2.693296347386182

Epoch: 6| Step: 8
Training loss: 2.5379812902267456
Validation loss: 2.7783050089740358

Epoch: 6| Step: 9
Training loss: 2.2367460035341904
Validation loss: 2.7460318459361073

Epoch: 6| Step: 10
Training loss: 3.8405788335050732
Validation loss: 2.7573412527696792

Epoch: 6| Step: 11
Training loss: 2.6203052682156933
Validation loss: 2.741769409187047

Epoch: 6| Step: 12
Training loss: 2.2098942644190265
Validation loss: 2.6496748232914102

Epoch: 6| Step: 13
Training loss: 2.1211135329418145
Validation loss: 2.637071856178755

Epoch: 57| Step: 0
Training loss: 2.119144675255346
Validation loss: 2.737189873092859

Epoch: 6| Step: 1
Training loss: 2.7268087281369313
Validation loss: 2.782883239566661

Epoch: 6| Step: 2
Training loss: 2.4314786435757645
Validation loss: 2.832501841065004

Epoch: 6| Step: 3
Training loss: 2.5055840118701966
Validation loss: 2.8509804188165058

Epoch: 6| Step: 4
Training loss: 2.4521284083585635
Validation loss: 2.781481701061257

Epoch: 6| Step: 5
Training loss: 2.180185787438544
Validation loss: 2.8055927653934867

Epoch: 6| Step: 6
Training loss: 2.348361348981588
Validation loss: 2.7295384966675673

Epoch: 6| Step: 7
Training loss: 2.3580290131858783
Validation loss: 2.6742720977249657

Epoch: 6| Step: 8
Training loss: 2.377984430517203
Validation loss: 2.6726533377002535

Epoch: 6| Step: 9
Training loss: 2.075021247295385
Validation loss: 2.6312961154499908

Epoch: 6| Step: 10
Training loss: 2.6442137940402115
Validation loss: 2.5992024573964074

Epoch: 6| Step: 11
Training loss: 2.3342197187832685
Validation loss: 2.6572465111935712

Epoch: 6| Step: 12
Training loss: 1.9792012931070135
Validation loss: 2.70930738295057

Epoch: 6| Step: 13
Training loss: 1.5405285044815358
Validation loss: 2.6970561261756676

Epoch: 58| Step: 0
Training loss: 2.5243404886824425
Validation loss: 2.6367445052031098

Epoch: 6| Step: 1
Training loss: 2.167544321665201
Validation loss: 2.619939300644479

Epoch: 6| Step: 2
Training loss: 2.145857604053111
Validation loss: 2.6286204817121135

Epoch: 6| Step: 3
Training loss: 2.8861493076819347
Validation loss: 2.692303098859816

Epoch: 6| Step: 4
Training loss: 1.9260585500150138
Validation loss: 2.5751549461189702

Epoch: 6| Step: 5
Training loss: 1.7189888528104031
Validation loss: 2.656679148694546

Epoch: 6| Step: 6
Training loss: 2.099181347177662
Validation loss: 2.6289426471369097

Epoch: 6| Step: 7
Training loss: 2.3306817474371986
Validation loss: 2.679348433890609

Epoch: 6| Step: 8
Training loss: 2.4034408421307805
Validation loss: 2.616810072069174

Epoch: 6| Step: 9
Training loss: 2.896159384688376
Validation loss: 2.655119299989095

Epoch: 6| Step: 10
Training loss: 1.5998639287308474
Validation loss: 2.6667914560047903

Epoch: 6| Step: 11
Training loss: 2.2737577547063808
Validation loss: 2.6519528954476272

Epoch: 6| Step: 12
Training loss: 1.5401656171992382
Validation loss: 2.6770410843618837

Epoch: 6| Step: 13
Training loss: 1.7689509840363977
Validation loss: 2.6572583098631397

Epoch: 59| Step: 0
Training loss: 1.4892919917952832
Validation loss: 2.6916867106806457

Epoch: 6| Step: 1
Training loss: 1.7773931810820194
Validation loss: 2.671478941119326

Epoch: 6| Step: 2
Training loss: 2.7794101930572883
Validation loss: 2.735911851142175

Epoch: 6| Step: 3
Training loss: 2.4017239895433953
Validation loss: 2.7513503747262407

Epoch: 6| Step: 4
Training loss: 2.0443868875464055
Validation loss: 2.764346673222199

Epoch: 6| Step: 5
Training loss: 2.7942751943382986
Validation loss: 2.7744845281002166

Epoch: 6| Step: 6
Training loss: 2.6356491066778016
Validation loss: 2.8494201416045604

Epoch: 6| Step: 7
Training loss: 2.4769710360247785
Validation loss: 2.6993829554854

Epoch: 6| Step: 8
Training loss: 1.6129232752999736
Validation loss: 2.6734842581332185

Epoch: 6| Step: 9
Training loss: 1.5726754548842121
Validation loss: 2.666276684696218

Epoch: 6| Step: 10
Training loss: 2.770394044247206
Validation loss: 2.554052135851479

Epoch: 6| Step: 11
Training loss: 2.1883671812803676
Validation loss: 2.685538293073409

Epoch: 6| Step: 12
Training loss: 1.9855367308662766
Validation loss: 2.7026425263647704

Epoch: 6| Step: 13
Training loss: 1.8742283822846089
Validation loss: 2.7489000345812964

Epoch: 60| Step: 0
Training loss: 2.6744589998301453
Validation loss: 2.737522791124573

Epoch: 6| Step: 1
Training loss: 1.0706060522109717
Validation loss: 2.7643835438737097

Epoch: 6| Step: 2
Training loss: 2.2793226069000596
Validation loss: 2.7123543062943556

Epoch: 6| Step: 3
Training loss: 2.2572380839984034
Validation loss: 2.7437501604663797

Epoch: 6| Step: 4
Training loss: 2.718952916783239
Validation loss: 2.658978306446909

Epoch: 6| Step: 5
Training loss: 2.0754058946463845
Validation loss: 2.6172546529932283

Epoch: 6| Step: 6
Training loss: 1.9162994392322934
Validation loss: 2.68561144571995

Epoch: 6| Step: 7
Training loss: 2.264552316274842
Validation loss: 2.6738786527746536

Epoch: 6| Step: 8
Training loss: 2.4862949462019337
Validation loss: 2.850783582236724

Epoch: 6| Step: 9
Training loss: 2.943187483316461
Validation loss: 2.7921368549338497

Epoch: 6| Step: 10
Training loss: 2.515868749715672
Validation loss: 2.756797286674923

Epoch: 6| Step: 11
Training loss: 2.104679334776176
Validation loss: 2.774886434253142

Epoch: 6| Step: 12
Training loss: 2.293400010684745
Validation loss: 2.7500471053279476

Epoch: 6| Step: 13
Training loss: 1.683001137364185
Validation loss: 2.7097431963716017

Epoch: 61| Step: 0
Training loss: 1.7780616735568886
Validation loss: 2.663337541759096

Epoch: 6| Step: 1
Training loss: 2.413858250739485
Validation loss: 2.6608284779150013

Epoch: 6| Step: 2
Training loss: 2.4650201749459626
Validation loss: 2.6533870751802575

Epoch: 6| Step: 3
Training loss: 1.5741749797633178
Validation loss: 2.707375948979707

Epoch: 6| Step: 4
Training loss: 2.091249367576453
Validation loss: 2.7121348965946845

Epoch: 6| Step: 5
Training loss: 2.5063780487911065
Validation loss: 2.69857768696166

Epoch: 6| Step: 6
Training loss: 1.598263501553467
Validation loss: 2.734458769468785

Epoch: 6| Step: 7
Training loss: 2.444062617372296
Validation loss: 2.6744416013541503

Epoch: 6| Step: 8
Training loss: 1.7168245107186255
Validation loss: 2.6572521189327887

Epoch: 6| Step: 9
Training loss: 2.610813589483083
Validation loss: 2.6973297236747302

Epoch: 6| Step: 10
Training loss: 1.9426603200534331
Validation loss: 2.7333704238406473

Epoch: 6| Step: 11
Training loss: 2.5025418710778453
Validation loss: 2.64364109431239

Epoch: 6| Step: 12
Training loss: 1.7159146590719532
Validation loss: 2.7029818017327933

Epoch: 6| Step: 13
Training loss: 2.6116466570462755
Validation loss: 2.6730958108985865

Epoch: 62| Step: 0
Training loss: 1.888265729784364
Validation loss: 2.746203496773948

Epoch: 6| Step: 1
Training loss: 2.3116762910884114
Validation loss: 2.7558458140017272

Epoch: 6| Step: 2
Training loss: 1.8384019908494187
Validation loss: 2.6238598542450453

Epoch: 6| Step: 3
Training loss: 1.5083002280014768
Validation loss: 2.7222732719729628

Epoch: 6| Step: 4
Training loss: 2.2640718595470575
Validation loss: 2.6762344607680553

Epoch: 6| Step: 5
Training loss: 2.2720231838252345
Validation loss: 2.7078917559078435

Epoch: 6| Step: 6
Training loss: 1.8274326154442078
Validation loss: 2.681231366309898

Epoch: 6| Step: 7
Training loss: 2.87172744919856
Validation loss: 2.6792718622449314

Epoch: 6| Step: 8
Training loss: 2.8586151280715377
Validation loss: 2.6813717693667254

Epoch: 6| Step: 9
Training loss: 2.1342973954710374
Validation loss: 2.691465143704523

Epoch: 6| Step: 10
Training loss: 2.2088621933771817
Validation loss: 2.7141188278019137

Epoch: 6| Step: 11
Training loss: 2.255469561828742
Validation loss: 2.6006614338899507

Epoch: 6| Step: 12
Training loss: 1.6592181259112428
Validation loss: 2.628741247356341

Epoch: 6| Step: 13
Training loss: 2.5749867151899135
Validation loss: 2.695443457034291

Epoch: 63| Step: 0
Training loss: 1.3106416989173582
Validation loss: 2.696348173770848

Epoch: 6| Step: 1
Training loss: 2.2088945743241157
Validation loss: 2.6787123467449434

Epoch: 6| Step: 2
Training loss: 2.1222777039275256
Validation loss: 2.6865496322739593

Epoch: 6| Step: 3
Training loss: 2.0389600706133666
Validation loss: 2.6824418603024736

Epoch: 6| Step: 4
Training loss: 2.5149926759222634
Validation loss: 2.689279056143511

Epoch: 6| Step: 5
Training loss: 2.5075403939337595
Validation loss: 2.725990330104978

Epoch: 6| Step: 6
Training loss: 1.7954438854511252
Validation loss: 2.6819825571456835

Epoch: 6| Step: 7
Training loss: 2.8204158013781537
Validation loss: 2.6223882519114565

Epoch: 6| Step: 8
Training loss: 1.9978171595938714
Validation loss: 2.689458975858287

Epoch: 6| Step: 9
Training loss: 2.0090889639631215
Validation loss: 2.6841992949482743

Epoch: 6| Step: 10
Training loss: 1.7246661927485887
Validation loss: 2.698934647752978

Epoch: 6| Step: 11
Training loss: 1.870281449317523
Validation loss: 2.6926333763172074

Epoch: 6| Step: 12
Training loss: 2.179520576675713
Validation loss: 2.7387077082902005

Epoch: 6| Step: 13
Training loss: 2.5341177813368305
Validation loss: 2.6864680593392687

Epoch: 64| Step: 0
Training loss: 2.730326418243557
Validation loss: 2.6688047917121756

Epoch: 6| Step: 1
Training loss: 2.0988013979518008
Validation loss: 2.7363327138872715

Epoch: 6| Step: 2
Training loss: 2.4642747321979974
Validation loss: 2.722167530829561

Epoch: 6| Step: 3
Training loss: 2.2836263115956523
Validation loss: 2.623345428844456

Epoch: 6| Step: 4
Training loss: 1.5100091143200394
Validation loss: 2.7087742275439037

Epoch: 6| Step: 5
Training loss: 2.7249500130084545
Validation loss: 2.7308390252158112

Epoch: 6| Step: 6
Training loss: 1.557303446679443
Validation loss: 2.587029141201376

Epoch: 6| Step: 7
Training loss: 2.1267625567463613
Validation loss: 2.664137793527583

Epoch: 6| Step: 8
Training loss: 2.387761813682813
Validation loss: 2.714439541298773

Epoch: 6| Step: 9
Training loss: 1.6625635981047222
Validation loss: 2.69084197737541

Epoch: 6| Step: 10
Training loss: 1.206154316482123
Validation loss: 2.726147041621285

Epoch: 6| Step: 11
Training loss: 1.6276494948115228
Validation loss: 2.695119524695636

Epoch: 6| Step: 12
Training loss: 2.0675038990136207
Validation loss: 2.7013760680543015

Epoch: 6| Step: 13
Training loss: 1.6264172755774808
Validation loss: 2.710115834067938

Epoch: 65| Step: 0
Training loss: 2.107846872149845
Validation loss: 2.685628253975337

Epoch: 6| Step: 1
Training loss: 2.110809290653997
Validation loss: 2.7567319761432945

Epoch: 6| Step: 2
Training loss: 2.3433876266086413
Validation loss: 2.716741119331871

Epoch: 6| Step: 3
Training loss: 2.3700305748428008
Validation loss: 2.6331984089034486

Epoch: 6| Step: 4
Training loss: 2.2067989801036307
Validation loss: 2.7117696578715726

Epoch: 6| Step: 5
Training loss: 2.5046560798335307
Validation loss: 2.720673374032531

Epoch: 6| Step: 6
Training loss: 2.7284900224449764
Validation loss: 2.716634021945146

Epoch: 6| Step: 7
Training loss: 1.5878201289557687
Validation loss: 2.774775108182788

Epoch: 6| Step: 8
Training loss: 2.2641093478940437
Validation loss: 2.5698330634011612

Epoch: 6| Step: 9
Training loss: 2.2117148606492867
Validation loss: 2.6768857286802183

Epoch: 6| Step: 10
Training loss: 2.1200345311861386
Validation loss: 2.7015276766713776

Epoch: 6| Step: 11
Training loss: 1.7777024127297285
Validation loss: 2.7027263457643103

Epoch: 6| Step: 12
Training loss: 1.6787551776411322
Validation loss: 2.7388796367923165

Epoch: 6| Step: 13
Training loss: 1.937892197322073
Validation loss: 2.690732475730526

Epoch: 66| Step: 0
Training loss: 2.2844046114608343
Validation loss: 2.8056469111367

Epoch: 6| Step: 1
Training loss: 2.1221765947124918
Validation loss: 2.8415820063474513

Epoch: 6| Step: 2
Training loss: 2.647795562816031
Validation loss: 2.7063804603829205

Epoch: 6| Step: 3
Training loss: 1.6806539904277655
Validation loss: 2.630534453365014

Epoch: 6| Step: 4
Training loss: 2.146293430322189
Validation loss: 2.6804233500854275

Epoch: 6| Step: 5
Training loss: 1.6558702141401844
Validation loss: 2.7438785015998706

Epoch: 6| Step: 6
Training loss: 3.098550790013134
Validation loss: 2.654371457505862

Epoch: 6| Step: 7
Training loss: 1.4413017917402509
Validation loss: 2.6743689009467704

Epoch: 6| Step: 8
Training loss: 1.7373219789927847
Validation loss: 2.7086357290225718

Epoch: 6| Step: 9
Training loss: 1.9318610548678032
Validation loss: 2.753303003636723

Epoch: 6| Step: 10
Training loss: 1.2003205546749667
Validation loss: 2.704364881808809

Epoch: 6| Step: 11
Training loss: 1.9337426947053147
Validation loss: 2.771881913753863

Epoch: 6| Step: 12
Training loss: 2.547214040832064
Validation loss: 2.689648737704368

Epoch: 6| Step: 13
Training loss: 2.1184124658042065
Validation loss: 2.712086121821488

Epoch: 67| Step: 0
Training loss: 2.2245195620176768
Validation loss: 2.809689777916281

Epoch: 6| Step: 1
Training loss: 1.9531162719531545
Validation loss: 2.685582223370584

Epoch: 6| Step: 2
Training loss: 2.131788294317029
Validation loss: 2.639130223822318

Epoch: 6| Step: 3
Training loss: 3.0895588546952744
Validation loss: 2.7768332168191066

Epoch: 6| Step: 4
Training loss: 2.1658086789665236
Validation loss: 2.699009446946268

Epoch: 6| Step: 5
Training loss: 2.3168104053977587
Validation loss: 2.6738749226686376

Epoch: 6| Step: 6
Training loss: 1.3467154937255101
Validation loss: 2.7166529932048538

Epoch: 6| Step: 7
Training loss: 1.4277990824886548
Validation loss: 2.71141887865196

Epoch: 6| Step: 8
Training loss: 2.309020440289942
Validation loss: 2.7446990000496068

Epoch: 6| Step: 9
Training loss: 1.9403160918207603
Validation loss: 2.6758851711020313

Epoch: 6| Step: 10
Training loss: 1.9723981934009418
Validation loss: 2.708175571443992

Epoch: 6| Step: 11
Training loss: 1.4474884973572983
Validation loss: 2.623213387073399

Epoch: 6| Step: 12
Training loss: 2.441145298554009
Validation loss: 2.6898617384404466

Epoch: 6| Step: 13
Training loss: 2.184217551564183
Validation loss: 2.6445640437967954

Epoch: 68| Step: 0
Training loss: 2.043790167084261
Validation loss: 2.662780871075676

Epoch: 6| Step: 1
Training loss: 2.4356416318275165
Validation loss: 2.7448022879600718

Epoch: 6| Step: 2
Training loss: 1.9837387146175058
Validation loss: 2.6015903444680686

Epoch: 6| Step: 3
Training loss: 2.2605004595389233
Validation loss: 2.5874834923209944

Epoch: 6| Step: 4
Training loss: 2.0346859555127996
Validation loss: 2.667576259713492

Epoch: 6| Step: 5
Training loss: 1.9023061509695545
Validation loss: 2.7156178932696884

Epoch: 6| Step: 6
Training loss: 2.7836101676034932
Validation loss: 2.7788304437709894

Epoch: 6| Step: 7
Training loss: 1.7713608872210342
Validation loss: 2.7252372865869376

Epoch: 6| Step: 8
Training loss: 1.8846296350308653
Validation loss: 2.7574632547788718

Epoch: 6| Step: 9
Training loss: 2.107755477281
Validation loss: 2.692551146493443

Epoch: 6| Step: 10
Training loss: 1.6479241896247432
Validation loss: 2.5996221383935283

Epoch: 6| Step: 11
Training loss: 2.2554803439015103
Validation loss: 2.699338638874523

Epoch: 6| Step: 12
Training loss: 2.0455816711070094
Validation loss: 2.7582329419662925

Epoch: 6| Step: 13
Training loss: 1.3928642674497944
Validation loss: 2.780987144936145

Epoch: 69| Step: 0
Training loss: 2.3589301289895364
Validation loss: 2.7511003922522583

Epoch: 6| Step: 1
Training loss: 1.2104634002925805
Validation loss: 2.7283862480814536

Epoch: 6| Step: 2
Training loss: 1.8520449882917576
Validation loss: 2.7536983474640966

Epoch: 6| Step: 3
Training loss: 2.8584636632569174
Validation loss: 2.6950232161664336

Epoch: 6| Step: 4
Training loss: 2.1749945541839826
Validation loss: 2.694950540167779

Epoch: 6| Step: 5
Training loss: 2.4889520672128866
Validation loss: 2.7570733366676397

Epoch: 6| Step: 6
Training loss: 2.0801560651477797
Validation loss: 2.6541232252732914

Epoch: 6| Step: 7
Training loss: 2.479222839317476
Validation loss: 2.7101929564715093

Epoch: 6| Step: 8
Training loss: 1.4068345444436825
Validation loss: 2.7032295603733045

Epoch: 6| Step: 9
Training loss: 2.3456932658449654
Validation loss: 2.7890883586122914

Epoch: 6| Step: 10
Training loss: 2.2371171250766095
Validation loss: 2.7779185169382217

Epoch: 6| Step: 11
Training loss: 1.5907318858749446
Validation loss: 2.704295983379341

Epoch: 6| Step: 12
Training loss: 1.994648270063597
Validation loss: 2.738743023430397

Epoch: 6| Step: 13
Training loss: 2.094613879180706
Validation loss: 2.74647723324373

Epoch: 70| Step: 0
Training loss: 2.0928830301886814
Validation loss: 2.755043404635908

Epoch: 6| Step: 1
Training loss: 2.1131772281902195
Validation loss: 2.7859216809068794

Epoch: 6| Step: 2
Training loss: 2.2399762777366634
Validation loss: 2.787463366406038

Epoch: 6| Step: 3
Training loss: 1.8942206373915678
Validation loss: 2.7162192539863037

Epoch: 6| Step: 4
Training loss: 2.452602646727924
Validation loss: 2.7671967115487637

Epoch: 6| Step: 5
Training loss: 1.8195043906640824
Validation loss: 2.6407428542101887

Epoch: 6| Step: 6
Training loss: 1.6567641126090042
Validation loss: 2.7370715260310283

Epoch: 6| Step: 7
Training loss: 1.9207734463417676
Validation loss: 2.7324724099551263

Epoch: 6| Step: 8
Training loss: 2.5410891851381705
Validation loss: 2.7794517675877666

Epoch: 6| Step: 9
Training loss: 2.6734723229874264
Validation loss: 2.670421599154759

Epoch: 6| Step: 10
Training loss: 1.85458160072348
Validation loss: 2.726377639406142

Epoch: 6| Step: 11
Training loss: 2.212895581070686
Validation loss: 2.837954305838769

Epoch: 6| Step: 12
Training loss: 1.2442806051367425
Validation loss: 2.7757761519936666

Epoch: 6| Step: 13
Training loss: 2.2164541912306084
Validation loss: 2.760164462870114

Epoch: 71| Step: 0
Training loss: 2.155671747043078
Validation loss: 2.6727267092022196

Epoch: 6| Step: 1
Training loss: 2.2484406259818543
Validation loss: 2.7262331409332434

Epoch: 6| Step: 2
Training loss: 2.388967300823579
Validation loss: 2.7048552897603817

Epoch: 6| Step: 3
Training loss: 2.2320269004130484
Validation loss: 2.7422987579352163

Epoch: 6| Step: 4
Training loss: 2.6093262993385244
Validation loss: 2.6960776012507774

Epoch: 6| Step: 5
Training loss: 1.419941688199971
Validation loss: 2.8123834939067094

Epoch: 6| Step: 6
Training loss: 2.0164499886286853
Validation loss: 2.67747904800495

Epoch: 6| Step: 7
Training loss: 1.630941532829519
Validation loss: 2.743531805992052

Epoch: 6| Step: 8
Training loss: 1.436827958620001
Validation loss: 2.696182980235764

Epoch: 6| Step: 9
Training loss: 1.56281689291407
Validation loss: 2.7745393238930123

Epoch: 6| Step: 10
Training loss: 1.631336475871782
Validation loss: 2.7026930888430263

Epoch: 6| Step: 11
Training loss: 2.5378492068081155
Validation loss: 2.728932222580739

Epoch: 6| Step: 12
Training loss: 2.292759016540654
Validation loss: 2.7620423670057646

Epoch: 6| Step: 13
Training loss: 1.6160721918117826
Validation loss: 2.7385070388440673

Epoch: 72| Step: 0
Training loss: 1.7914402914826348
Validation loss: 2.674597648712641

Epoch: 6| Step: 1
Training loss: 2.1269799152855384
Validation loss: 2.701628754161703

Epoch: 6| Step: 2
Training loss: 2.042751672710686
Validation loss: 2.7216798772995463

Epoch: 6| Step: 3
Training loss: 2.2760433194105723
Validation loss: 2.7425113787396174

Epoch: 6| Step: 4
Training loss: 2.2394800088394304
Validation loss: 2.7888335375297792

Epoch: 6| Step: 5
Training loss: 1.9464984021340728
Validation loss: 2.7165936947794873

Epoch: 6| Step: 6
Training loss: 1.475077533300554
Validation loss: 2.6951647879257608

Epoch: 6| Step: 7
Training loss: 2.288617295856188
Validation loss: 2.6735047543551613

Epoch: 6| Step: 8
Training loss: 1.9609545216828457
Validation loss: 2.7429044244608836

Epoch: 6| Step: 9
Training loss: 1.419867891022666
Validation loss: 2.682754881530213

Epoch: 6| Step: 10
Training loss: 2.3090146579863666
Validation loss: 2.793899032634368

Epoch: 6| Step: 11
Training loss: 2.142970227481946
Validation loss: 2.708861201758266

Epoch: 6| Step: 12
Training loss: 1.9603865255970394
Validation loss: 2.7860467101674997

Epoch: 6| Step: 13
Training loss: 2.083975108160922
Validation loss: 2.7281059844179816

Epoch: 73| Step: 0
Training loss: 1.356901703110095
Validation loss: 2.7597641851516355

Epoch: 6| Step: 1
Training loss: 1.5510721774545058
Validation loss: 2.7573723086007296

Epoch: 6| Step: 2
Training loss: 2.706754243667868
Validation loss: 2.7571814141870545

Epoch: 6| Step: 3
Training loss: 2.031190959365816
Validation loss: 2.761108820287657

Epoch: 6| Step: 4
Training loss: 1.207921955631744
Validation loss: 2.6762671110748575

Epoch: 6| Step: 5
Training loss: 1.66760206993928
Validation loss: 2.713945872440567

Epoch: 6| Step: 6
Training loss: 2.4058932745927173
Validation loss: 2.6998079266929222

Epoch: 6| Step: 7
Training loss: 1.9861215429617463
Validation loss: 2.731564106981664

Epoch: 6| Step: 8
Training loss: 2.239434549283569
Validation loss: 2.68846868460051

Epoch: 6| Step: 9
Training loss: 2.4347293463650677
Validation loss: 2.7430430035096034

Epoch: 6| Step: 10
Training loss: 1.1834076083517813
Validation loss: 2.7412151413194374

Epoch: 6| Step: 11
Training loss: 2.3443224398589813
Validation loss: 2.665439835110237

Epoch: 6| Step: 12
Training loss: 2.222273701495365
Validation loss: 2.779892522303164

Epoch: 6| Step: 13
Training loss: 1.6706786822175916
Validation loss: 2.666698028459508

Epoch: 74| Step: 0
Training loss: 2.0252227566493253
Validation loss: 2.6998763215030728

Epoch: 6| Step: 1
Training loss: 2.5585434304450714
Validation loss: 2.649207619295218

Epoch: 6| Step: 2
Training loss: 1.6589881287943904
Validation loss: 2.7326844866086986

Epoch: 6| Step: 3
Training loss: 1.6310467823646895
Validation loss: 2.806225977216386

Epoch: 6| Step: 4
Training loss: 2.1730445621799777
Validation loss: 2.654469959490712

Epoch: 6| Step: 5
Training loss: 1.7179553882726322
Validation loss: 2.7759102056030973

Epoch: 6| Step: 6
Training loss: 1.9245443027676525
Validation loss: 2.6781229209817643

Epoch: 6| Step: 7
Training loss: 2.2268284689008326
Validation loss: 2.734428361644499

Epoch: 6| Step: 8
Training loss: 1.647070005623341
Validation loss: 2.7243260463030756

Epoch: 6| Step: 9
Training loss: 1.9571603210891229
Validation loss: 2.7008850872193757

Epoch: 6| Step: 10
Training loss: 1.3774182555353576
Validation loss: 2.7239161695398453

Epoch: 6| Step: 11
Training loss: 2.1309567157389724
Validation loss: 2.7279528158238042

Epoch: 6| Step: 12
Training loss: 2.2276243655918444
Validation loss: 2.775151427894293

Epoch: 6| Step: 13
Training loss: 1.865753900365677
Validation loss: 2.730197571043488

Epoch: 75| Step: 0
Training loss: 1.6471349985074404
Validation loss: 2.7473702861929947

Epoch: 6| Step: 1
Training loss: 1.319324507476742
Validation loss: 2.817307432544723

Epoch: 6| Step: 2
Training loss: 2.023747365194659
Validation loss: 2.774385761177956

Epoch: 6| Step: 3
Training loss: 2.0885820519656315
Validation loss: 2.7040200341138974

Epoch: 6| Step: 4
Training loss: 2.085644190593952
Validation loss: 2.7143924182459167

Epoch: 6| Step: 5
Training loss: 2.163321137396355
Validation loss: 2.8251565912333456

Epoch: 6| Step: 6
Training loss: 1.75693106698567
Validation loss: 2.742365803224447

Epoch: 6| Step: 7
Training loss: 2.372311526048705
Validation loss: 2.832813668746132

Epoch: 6| Step: 8
Training loss: 1.306069287663038
Validation loss: 2.703904908554742

Epoch: 6| Step: 9
Training loss: 2.545689031712082
Validation loss: 2.742339793846069

Epoch: 6| Step: 10
Training loss: 1.8463769076461911
Validation loss: 2.715408303087587

Epoch: 6| Step: 11
Training loss: 1.9189761249116564
Validation loss: 2.682114120582463

Epoch: 6| Step: 12
Training loss: 2.5167466974059605
Validation loss: 2.7183902692494155

Epoch: 6| Step: 13
Training loss: 1.7386122484852353
Validation loss: 2.8080000022080323

Epoch: 76| Step: 0
Training loss: 1.6012092014567723
Validation loss: 2.654764171239328

Epoch: 6| Step: 1
Training loss: 2.6272320113637515
Validation loss: 2.84710029997465

Epoch: 6| Step: 2
Training loss: 2.308440072613464
Validation loss: 2.741686667472755

Epoch: 6| Step: 3
Training loss: 1.691734793031944
Validation loss: 2.6994552251092796

Epoch: 6| Step: 4
Training loss: 2.3170564456233236
Validation loss: 2.748563174377535

Epoch: 6| Step: 5
Training loss: 1.7136432034015872
Validation loss: 2.714092694138184

Epoch: 6| Step: 6
Training loss: 1.7269578023768228
Validation loss: 2.778486128665296

Epoch: 6| Step: 7
Training loss: 1.9105136903553337
Validation loss: 2.7404136318124057

Epoch: 6| Step: 8
Training loss: 1.6044795569249513
Validation loss: 2.7548385016154597

Epoch: 6| Step: 9
Training loss: 2.3941123309698735
Validation loss: 2.667780573972887

Epoch: 6| Step: 10
Training loss: 1.6535883695775673
Validation loss: 2.777681039609185

Epoch: 6| Step: 11
Training loss: 1.7316982473970002
Validation loss: 2.723073437552561

Epoch: 6| Step: 12
Training loss: 1.7630572932730812
Validation loss: 2.6793691522030065

Epoch: 6| Step: 13
Training loss: 1.9641081568737995
Validation loss: 2.661634022586773

Epoch: 77| Step: 0
Training loss: 2.1325696869853124
Validation loss: 2.7255350707503765

Epoch: 6| Step: 1
Training loss: 1.9038958161404318
Validation loss: 2.783307553836271

Epoch: 6| Step: 2
Training loss: 2.264670966966956
Validation loss: 2.722288116859914

Epoch: 6| Step: 3
Training loss: 1.8178184352054534
Validation loss: 2.684988903920163

Epoch: 6| Step: 4
Training loss: 2.1482546086927248
Validation loss: 2.7863526202437647

Epoch: 6| Step: 5
Training loss: 1.708663195265807
Validation loss: 2.731104975384734

Epoch: 6| Step: 6
Training loss: 1.813541573472069
Validation loss: 2.706003497660675

Epoch: 6| Step: 7
Training loss: 1.9984218808563667
Validation loss: 2.7183084969835094

Epoch: 6| Step: 8
Training loss: 1.259654242744428
Validation loss: 2.7200625382741843

Epoch: 6| Step: 9
Training loss: 1.3653510702792193
Validation loss: 2.7566980229923423

Epoch: 6| Step: 10
Training loss: 1.7579459584753798
Validation loss: 2.7334829492055204

Epoch: 6| Step: 11
Training loss: 2.3588375464659865
Validation loss: 2.7390055802664355

Epoch: 6| Step: 12
Training loss: 1.6791170792873824
Validation loss: 2.7039437937378055

Epoch: 6| Step: 13
Training loss: 2.386433436045878
Validation loss: 2.7495118488195893

Epoch: 78| Step: 0
Training loss: 1.6300042200326412
Validation loss: 2.7319505679069414

Epoch: 6| Step: 1
Training loss: 1.9218901967013828
Validation loss: 2.7645750333598653

Epoch: 6| Step: 2
Training loss: 1.764194685626829
Validation loss: 2.736251724705008

Epoch: 6| Step: 3
Training loss: 1.9406468462367057
Validation loss: 2.7567257275264496

Epoch: 6| Step: 4
Training loss: 1.843826809592477
Validation loss: 2.7572918365290153

Epoch: 6| Step: 5
Training loss: 2.356856966640095
Validation loss: 2.714092833225576

Epoch: 6| Step: 6
Training loss: 2.2025476876161263
Validation loss: 2.7172059099284085

Epoch: 6| Step: 7
Training loss: 2.25975444134819
Validation loss: 2.7262036689507303

Epoch: 6| Step: 8
Training loss: 2.5537060826913702
Validation loss: 2.743407815669144

Epoch: 6| Step: 9
Training loss: 1.4727028755881564
Validation loss: 2.755218698137158

Epoch: 6| Step: 10
Training loss: 1.5117836477459872
Validation loss: 2.775075065468131

Epoch: 6| Step: 11
Training loss: 1.9730717891735576
Validation loss: 2.7612167830258763

Epoch: 6| Step: 12
Training loss: 1.7125153255473
Validation loss: 2.6629572689100844

Epoch: 6| Step: 13
Training loss: 1.6710023117551673
Validation loss: 2.7617661014797825

Epoch: 79| Step: 0
Training loss: 2.5310769669530755
Validation loss: 2.6893632624916193

Epoch: 6| Step: 1
Training loss: 2.2159923555607235
Validation loss: 2.75557627441537

Epoch: 6| Step: 2
Training loss: 1.8183608828496367
Validation loss: 2.799738180317298

Epoch: 6| Step: 3
Training loss: 2.106837915610745
Validation loss: 2.7891575701811884

Epoch: 6| Step: 4
Training loss: 1.4915189993169669
Validation loss: 2.7481088493496655

Epoch: 6| Step: 5
Training loss: 1.630420740039448
Validation loss: 2.738598110932382

Epoch: 6| Step: 6
Training loss: 1.5102650358010137
Validation loss: 2.844853393227698

Epoch: 6| Step: 7
Training loss: 1.7843088354881285
Validation loss: 2.7514483510301324

Epoch: 6| Step: 8
Training loss: 1.1350319003356968
Validation loss: 2.7504546049803507

Epoch: 6| Step: 9
Training loss: 2.1652240596706522
Validation loss: 2.6577256685067234

Epoch: 6| Step: 10
Training loss: 1.3542926534097834
Validation loss: 2.7435596072701256

Epoch: 6| Step: 11
Training loss: 2.4321181720771707
Validation loss: 2.842889998071084

Epoch: 6| Step: 12
Training loss: 2.365123591832946
Validation loss: 2.7868908032561452

Epoch: 6| Step: 13
Training loss: 1.7579393807289685
Validation loss: 2.795735444933926

Epoch: 80| Step: 0
Training loss: 2.629650809745482
Validation loss: 2.8543632235450116

Epoch: 6| Step: 1
Training loss: 2.3938261054866383
Validation loss: 2.794691828535583

Epoch: 6| Step: 2
Training loss: 2.028966118564927
Validation loss: 2.785497443873654

Epoch: 6| Step: 3
Training loss: 1.4786134231453436
Validation loss: 2.7464279036615884

Epoch: 6| Step: 4
Training loss: 1.9897780264883933
Validation loss: 2.7908582703083886

Epoch: 6| Step: 5
Training loss: 1.513582406630097
Validation loss: 2.8541468505913996

Epoch: 6| Step: 6
Training loss: 1.7199482988748855
Validation loss: 2.7931844988102594

Epoch: 6| Step: 7
Training loss: 1.610320767026646
Validation loss: 2.8346297065888795

Epoch: 6| Step: 8
Training loss: 2.1360642234419593
Validation loss: 2.7889813465667705

Epoch: 6| Step: 9
Training loss: 1.576654939238233
Validation loss: 2.751569379588157

Epoch: 6| Step: 10
Training loss: 1.7353710716580637
Validation loss: 2.6914445923250407

Epoch: 6| Step: 11
Training loss: 1.947979244376178
Validation loss: 2.6958198401591495

Epoch: 6| Step: 12
Training loss: 1.5255592633954251
Validation loss: 2.672002175857035

Epoch: 6| Step: 13
Training loss: 2.539759519712201
Validation loss: 2.765025934255244

Epoch: 81| Step: 0
Training loss: 2.5489968664210663
Validation loss: 2.8310399918636997

Epoch: 6| Step: 1
Training loss: 2.689868327041547
Validation loss: 2.793983058325581

Epoch: 6| Step: 2
Training loss: 1.7603566387107132
Validation loss: 2.7846006862113573

Epoch: 6| Step: 3
Training loss: 1.8418443821335249
Validation loss: 2.7405482624696793

Epoch: 6| Step: 4
Training loss: 1.444680400470351
Validation loss: 2.7205511243742255

Epoch: 6| Step: 5
Training loss: 2.22786570106239
Validation loss: 2.7575084745634832

Epoch: 6| Step: 6
Training loss: 1.7142519266341076
Validation loss: 2.849553401154127

Epoch: 6| Step: 7
Training loss: 2.0383390699894868
Validation loss: 2.714748258306353

Epoch: 6| Step: 8
Training loss: 1.2077290021255072
Validation loss: 2.6277766755522696

Epoch: 6| Step: 9
Training loss: 1.9785872631905048
Validation loss: 2.737788962872716

Epoch: 6| Step: 10
Training loss: 1.3449310612648715
Validation loss: 2.747807235409047

Epoch: 6| Step: 11
Training loss: 1.7949706227653355
Validation loss: 2.7080918913595085

Epoch: 6| Step: 12
Training loss: 1.8866129148507298
Validation loss: 2.7475759052485773

Epoch: 6| Step: 13
Training loss: 1.7987904829462729
Validation loss: 2.732728211557265

Epoch: 82| Step: 0
Training loss: 2.054714884412333
Validation loss: 2.643903927421493

Epoch: 6| Step: 1
Training loss: 1.6872642493698307
Validation loss: 2.7239342148091743

Epoch: 6| Step: 2
Training loss: 1.463485535691245
Validation loss: 2.837210433457751

Epoch: 6| Step: 3
Training loss: 2.131565050571841
Validation loss: 2.7642892316483954

Epoch: 6| Step: 4
Training loss: 1.691460095400863
Validation loss: 2.7603732171627775

Epoch: 6| Step: 5
Training loss: 1.9467425011970116
Validation loss: 2.7671786324839833

Epoch: 6| Step: 6
Training loss: 1.5719248526765388
Validation loss: 2.684950291808666

Epoch: 6| Step: 7
Training loss: 2.2148932665044687
Validation loss: 2.7439087902166164

Epoch: 6| Step: 8
Training loss: 1.1539118038965868
Validation loss: 2.760845530082213

Epoch: 6| Step: 9
Training loss: 1.581119830537226
Validation loss: 2.778611592609449

Epoch: 6| Step: 10
Training loss: 1.6115938464613684
Validation loss: 2.7407047070200297

Epoch: 6| Step: 11
Training loss: 1.673660893137342
Validation loss: 2.6827562886508827

Epoch: 6| Step: 12
Training loss: 2.271964208643359
Validation loss: 2.7695132005226224

Epoch: 6| Step: 13
Training loss: 2.284663429263897
Validation loss: 2.659793494796533

Epoch: 83| Step: 0
Training loss: 2.1343297906111727
Validation loss: 2.687992331778662

Epoch: 6| Step: 1
Training loss: 1.8787771961835096
Validation loss: 2.7593047199681204

Epoch: 6| Step: 2
Training loss: 2.502027452423467
Validation loss: 2.845425667520657

Epoch: 6| Step: 3
Training loss: 2.0202807690222544
Validation loss: 2.832007242736786

Epoch: 6| Step: 4
Training loss: 1.5200922305584936
Validation loss: 2.915173179995911

Epoch: 6| Step: 5
Training loss: 1.5264698074608616
Validation loss: 2.7269740627497563

Epoch: 6| Step: 6
Training loss: 1.6172783130450068
Validation loss: 2.7340354781305742

Epoch: 6| Step: 7
Training loss: 1.3311162138143933
Validation loss: 2.6686622087033376

Epoch: 6| Step: 8
Training loss: 1.6948733837807295
Validation loss: 2.7898517848881643

Epoch: 6| Step: 9
Training loss: 1.5440302420703211
Validation loss: 2.7363915773014793

Epoch: 6| Step: 10
Training loss: 1.6131615398041876
Validation loss: 2.7940043345722425

Epoch: 6| Step: 11
Training loss: 1.8016092709560256
Validation loss: 2.845399385229325

Epoch: 6| Step: 12
Training loss: 2.192876801773216
Validation loss: 2.9416386553445597

Epoch: 6| Step: 13
Training loss: 2.0727651211600313
Validation loss: 2.8004716873231583

Epoch: 84| Step: 0
Training loss: 1.7156077010597577
Validation loss: 2.7751320690081434

Epoch: 6| Step: 1
Training loss: 1.5930063345209053
Validation loss: 2.819921020783873

Epoch: 6| Step: 2
Training loss: 1.72247188905054
Validation loss: 2.7405228013253136

Epoch: 6| Step: 3
Training loss: 2.2260131158159577
Validation loss: 2.7111498248440404

Epoch: 6| Step: 4
Training loss: 1.8938367691557203
Validation loss: 2.7552803957961185

Epoch: 6| Step: 5
Training loss: 1.5993166179369174
Validation loss: 2.763814818658652

Epoch: 6| Step: 6
Training loss: 1.615750987823907
Validation loss: 2.7840585993376465

Epoch: 6| Step: 7
Training loss: 2.297438571843444
Validation loss: 2.700340865835695

Epoch: 6| Step: 8
Training loss: 1.3528426618026885
Validation loss: 2.7307366861378943

Epoch: 6| Step: 9
Training loss: 1.7634095327406287
Validation loss: 2.7250923193595833

Epoch: 6| Step: 10
Training loss: 1.6601227162284184
Validation loss: 2.847474338771994

Epoch: 6| Step: 11
Training loss: 1.762397990419798
Validation loss: 2.779408992133136

Epoch: 6| Step: 12
Training loss: 2.0940033488934544
Validation loss: 2.7810092636104082

Epoch: 6| Step: 13
Training loss: 2.3318044785443885
Validation loss: 2.7803412820970492

Epoch: 85| Step: 0
Training loss: 0.9603606562855938
Validation loss: 2.8240839432252667

Epoch: 6| Step: 1
Training loss: 1.965397781314764
Validation loss: 2.667774347880973

Epoch: 6| Step: 2
Training loss: 1.7205428049870555
Validation loss: 2.731544919244161

Epoch: 6| Step: 3
Training loss: 1.5668456110653644
Validation loss: 2.7385496406153718

Epoch: 6| Step: 4
Training loss: 1.5782538635216286
Validation loss: 2.7003565081951924

Epoch: 6| Step: 5
Training loss: 2.4705765160247926
Validation loss: 2.7773008848478047

Epoch: 6| Step: 6
Training loss: 1.4671878217507883
Validation loss: 2.833846141652151

Epoch: 6| Step: 7
Training loss: 1.4016141986136452
Validation loss: 2.7259373717909505

Epoch: 6| Step: 8
Training loss: 2.1134664909137624
Validation loss: 2.830924992717414

Epoch: 6| Step: 9
Training loss: 1.5411478234893061
Validation loss: 2.8678129035534017

Epoch: 6| Step: 10
Training loss: 2.060092561364455
Validation loss: 2.7179177570667346

Epoch: 6| Step: 11
Training loss: 2.154718712241075
Validation loss: 2.724951792065992

Epoch: 6| Step: 12
Training loss: 1.8069934067513491
Validation loss: 2.8198240496482634

Epoch: 6| Step: 13
Training loss: 1.741376063486122
Validation loss: 2.8238555407322297

Epoch: 86| Step: 0
Training loss: 2.2751196442048442
Validation loss: 2.80299487880439

Epoch: 6| Step: 1
Training loss: 1.850402017678704
Validation loss: 2.743587545858628

Epoch: 6| Step: 2
Training loss: 1.3989399268482023
Validation loss: 2.832182276414846

Epoch: 6| Step: 3
Training loss: 1.4650000730390824
Validation loss: 2.7449945064830183

Epoch: 6| Step: 4
Training loss: 1.8175883066796878
Validation loss: 2.7856578045371947

Epoch: 6| Step: 5
Training loss: 1.656037658898991
Validation loss: 2.796646392970055

Epoch: 6| Step: 6
Training loss: 2.0227361811362803
Validation loss: 2.7195891331320112

Epoch: 6| Step: 7
Training loss: 1.290918112807551
Validation loss: 2.7802312178019495

Epoch: 6| Step: 8
Training loss: 1.4720370258152795
Validation loss: 2.730282640276774

Epoch: 6| Step: 9
Training loss: 1.5050367985785875
Validation loss: 2.829112187976699

Epoch: 6| Step: 10
Training loss: 1.8612831646671837
Validation loss: 2.732477237994014

Epoch: 6| Step: 11
Training loss: 1.5420406592435012
Validation loss: 2.8427915809512765

Epoch: 6| Step: 12
Training loss: 2.1702697090560856
Validation loss: 2.6978098186607884

Epoch: 6| Step: 13
Training loss: 2.1085476983699634
Validation loss: 2.7306955631702805

Epoch: 87| Step: 0
Training loss: 2.1494140625
Validation loss: 2.7150254296270457

Epoch: 6| Step: 1
Training loss: 1.4552357428264697
Validation loss: 2.730191429073238

Epoch: 6| Step: 2
Training loss: 1.1216827865470096
Validation loss: 2.7275797377322744

Epoch: 6| Step: 3
Training loss: 0.9965320296128527
Validation loss: 2.846894297026673

Epoch: 6| Step: 4
Training loss: 2.3059927654764945
Validation loss: 2.727356052871764

Epoch: 6| Step: 5
Training loss: 1.7954569653054668
Validation loss: 2.815318694337759

Epoch: 6| Step: 6
Training loss: 2.159552436306813
Validation loss: 2.801250565639599

Epoch: 6| Step: 7
Training loss: 1.3670847826927444
Validation loss: 2.7881772785178267

Epoch: 6| Step: 8
Training loss: 1.7404205530933146
Validation loss: 2.7211794467062913

Epoch: 6| Step: 9
Training loss: 1.4210851802221502
Validation loss: 2.821058518076956

Epoch: 6| Step: 10
Training loss: 1.5702274735998145
Validation loss: 2.7538591962541545

Epoch: 6| Step: 11
Training loss: 1.639009534127305
Validation loss: 2.8561474732320624

Epoch: 6| Step: 12
Training loss: 2.5252707232387923
Validation loss: 2.7288953389028743

Epoch: 6| Step: 13
Training loss: 1.268178741685026
Validation loss: 2.699355140843214

Epoch: 88| Step: 0
Training loss: 1.4381228217249773
Validation loss: 2.779523249164371

Epoch: 6| Step: 1
Training loss: 1.2636843272425504
Validation loss: 2.8024354923751864

Epoch: 6| Step: 2
Training loss: 1.4852664880509974
Validation loss: 2.7620425540317046

Epoch: 6| Step: 3
Training loss: 1.8517928483181576
Validation loss: 2.8492546601573805

Epoch: 6| Step: 4
Training loss: 1.8570646790932768
Validation loss: 2.769349458554149

Epoch: 6| Step: 5
Training loss: 1.5905837977380988
Validation loss: 2.754552014258004

Epoch: 6| Step: 6
Training loss: 2.0821418661252133
Validation loss: 2.792697265519594

Epoch: 6| Step: 7
Training loss: 1.3664739872242795
Validation loss: 2.8270372156941765

Epoch: 6| Step: 8
Training loss: 2.0124314906620184
Validation loss: 2.8121523324340396

Epoch: 6| Step: 9
Training loss: 1.7230759020850803
Validation loss: 2.7619856975626154

Epoch: 6| Step: 10
Training loss: 1.7999541064875586
Validation loss: 2.7591528152522153

Epoch: 6| Step: 11
Training loss: 1.9555991409362292
Validation loss: 2.842060551421802

Epoch: 6| Step: 12
Training loss: 1.6244712115948423
Validation loss: 2.7830474417349755

Epoch: 6| Step: 13
Training loss: 2.310009517402364
Validation loss: 2.869842028075004

Epoch: 89| Step: 0
Training loss: 1.2646480604487855
Validation loss: 2.859243101541662

Epoch: 6| Step: 1
Training loss: 1.3847348057770203
Validation loss: 2.840939414931784

Epoch: 6| Step: 2
Training loss: 1.6913977924514298
Validation loss: 2.7935354800434005

Epoch: 6| Step: 3
Training loss: 2.541091436945544
Validation loss: 2.7779855178929727

Epoch: 6| Step: 4
Training loss: 1.4681426070689325
Validation loss: 2.7086974314946177

Epoch: 6| Step: 5
Training loss: 2.460335987995974
Validation loss: 2.7388114180149934

Epoch: 6| Step: 6
Training loss: 1.6090868349322527
Validation loss: 2.9249005895822506

Epoch: 6| Step: 7
Training loss: 1.7374037681660803
Validation loss: 2.8168664098675933

Epoch: 6| Step: 8
Training loss: 1.6933257243718882
Validation loss: 2.737739542056618

Epoch: 6| Step: 9
Training loss: 1.6909506803163508
Validation loss: 2.8345930066818164

Epoch: 6| Step: 10
Training loss: 1.2652714553397748
Validation loss: 2.840017349275241

Epoch: 6| Step: 11
Training loss: 1.5135991823522847
Validation loss: 2.86755907802148

Epoch: 6| Step: 12
Training loss: 1.3145775473941401
Validation loss: 2.804822417319709

Epoch: 6| Step: 13
Training loss: 2.226981782753908
Validation loss: 2.7092855735725037

Epoch: 90| Step: 0
Training loss: 1.7833376245654993
Validation loss: 2.8047024470562354

Epoch: 6| Step: 1
Training loss: 1.5048855058075348
Validation loss: 2.8032304668112826

Epoch: 6| Step: 2
Training loss: 1.2100005432001582
Validation loss: 2.8831496829785883

Epoch: 6| Step: 3
Training loss: 2.782122443016006
Validation loss: 2.785531866239752

Epoch: 6| Step: 4
Training loss: 1.468165991719582
Validation loss: 2.7563181458552752

Epoch: 6| Step: 5
Training loss: 1.3430978390098367
Validation loss: 2.8195728801001563

Epoch: 6| Step: 6
Training loss: 1.7553858304101513
Validation loss: 2.751525614670129

Epoch: 6| Step: 7
Training loss: 1.5775044798145073
Validation loss: 2.8038584724494586

Epoch: 6| Step: 8
Training loss: 1.5060996174433363
Validation loss: 2.8323175956396893

Epoch: 6| Step: 9
Training loss: 1.6621191291209088
Validation loss: 2.7913862391203987

Epoch: 6| Step: 10
Training loss: 1.7397952226740938
Validation loss: 2.8764462357895195

Epoch: 6| Step: 11
Training loss: 2.217634753548583
Validation loss: 2.9303369777053474

Epoch: 6| Step: 12
Training loss: 1.3058590682722868
Validation loss: 2.8117034066571183

Epoch: 6| Step: 13
Training loss: 1.6570752085421883
Validation loss: 2.8670970961396516

Epoch: 91| Step: 0
Training loss: 1.925558328783685
Validation loss: 2.799868766229682

Epoch: 6| Step: 1
Training loss: 1.8555476442931071
Validation loss: 2.8750327702741667

Epoch: 6| Step: 2
Training loss: 1.39252984389919
Validation loss: 2.8009760109236086

Epoch: 6| Step: 3
Training loss: 1.4844606876737765
Validation loss: 2.804235969261457

Epoch: 6| Step: 4
Training loss: 1.6208523122400362
Validation loss: 2.8236376321496444

Epoch: 6| Step: 5
Training loss: 1.5468896422030336
Validation loss: 2.7945527109046004

Epoch: 6| Step: 6
Training loss: 1.7320106130014923
Validation loss: 2.8597592788707162

Epoch: 6| Step: 7
Training loss: 1.9669589418160927
Validation loss: 2.884237238885693

Epoch: 6| Step: 8
Training loss: 1.3100716060258077
Validation loss: 2.6826809844402186

Epoch: 6| Step: 9
Training loss: 2.434922640783802
Validation loss: 2.7739699877843775

Epoch: 6| Step: 10
Training loss: 1.4408452459357306
Validation loss: 2.734385499479935

Epoch: 6| Step: 11
Training loss: 1.1493281329889946
Validation loss: 2.7365665191264252

Epoch: 6| Step: 12
Training loss: 1.9029449828749967
Validation loss: 2.7815365304403525

Epoch: 6| Step: 13
Training loss: 1.4895112969468542
Validation loss: 2.6976424241082233

Epoch: 92| Step: 0
Training loss: 2.206772402547555
Validation loss: 2.7061251123286683

Epoch: 6| Step: 1
Training loss: 1.1288168056653674
Validation loss: 2.8163603815513696

Epoch: 6| Step: 2
Training loss: 1.3272053844593314
Validation loss: 2.858664377428972

Epoch: 6| Step: 3
Training loss: 1.6288219402641706
Validation loss: 2.7577284240874587

Epoch: 6| Step: 4
Training loss: 1.233184336778055
Validation loss: 2.76387106241668

Epoch: 6| Step: 5
Training loss: 1.6911409447492318
Validation loss: 2.848594256377599

Epoch: 6| Step: 6
Training loss: 2.4459948090555126
Validation loss: 2.771816886972185

Epoch: 6| Step: 7
Training loss: 1.587493358808428
Validation loss: 2.762277103367173

Epoch: 6| Step: 8
Training loss: 1.6582476247111677
Validation loss: 2.763434726348892

Epoch: 6| Step: 9
Training loss: 1.3796799950055336
Validation loss: 2.7295701308657323

Epoch: 6| Step: 10
Training loss: 1.6630366212227055
Validation loss: 2.815594927097597

Epoch: 6| Step: 11
Training loss: 1.741959150599631
Validation loss: 2.8754392785878093

Epoch: 6| Step: 12
Training loss: 1.9665522948915166
Validation loss: 2.844737674382817

Epoch: 6| Step: 13
Training loss: 1.324807725307036
Validation loss: 2.9097577327806112

Epoch: 93| Step: 0
Training loss: 1.9944434463772391
Validation loss: 2.855082418362257

Epoch: 6| Step: 1
Training loss: 1.1369147377556081
Validation loss: 2.859310851220032

Epoch: 6| Step: 2
Training loss: 1.4647721336660025
Validation loss: 2.639584451046421

Epoch: 6| Step: 3
Training loss: 1.2832834807947495
Validation loss: 2.7678052996982205

Epoch: 6| Step: 4
Training loss: 1.5200628218718901
Validation loss: 2.726774671983483

Epoch: 6| Step: 5
Training loss: 2.190756852865901
Validation loss: 2.7558155412294747

Epoch: 6| Step: 6
Training loss: 1.6963592672891115
Validation loss: 2.799914975805463

Epoch: 6| Step: 7
Training loss: 1.699473394847269
Validation loss: 2.799751124220591

Epoch: 6| Step: 8
Training loss: 1.3935975012721797
Validation loss: 2.803366262202449

Epoch: 6| Step: 9
Training loss: 1.7707710554354061
Validation loss: 2.8550768790775347

Epoch: 6| Step: 10
Training loss: 1.5147320191215994
Validation loss: 2.8045725537674184

Epoch: 6| Step: 11
Training loss: 2.228736966748087
Validation loss: 2.829627872416657

Epoch: 6| Step: 12
Training loss: 1.4980268215941035
Validation loss: 2.762658520001044

Epoch: 6| Step: 13
Training loss: 1.7302986560865037
Validation loss: 2.788354080230938

Epoch: 94| Step: 0
Training loss: 1.3515889600688444
Validation loss: 2.758930862068381

Epoch: 6| Step: 1
Training loss: 1.6453947939674347
Validation loss: 2.689366852912498

Epoch: 6| Step: 2
Training loss: 1.361180389137704
Validation loss: 2.7799960106196697

Epoch: 6| Step: 3
Training loss: 1.838298626650202
Validation loss: 2.8007907415040316

Epoch: 6| Step: 4
Training loss: 0.9840387950960363
Validation loss: 2.803288974452583

Epoch: 6| Step: 5
Training loss: 1.912474615888495
Validation loss: 2.8201522147579725

Epoch: 6| Step: 6
Training loss: 2.331421636649912
Validation loss: 2.714398200708676

Epoch: 6| Step: 7
Training loss: 2.352245143013285
Validation loss: 2.8453589977282596

Epoch: 6| Step: 8
Training loss: 1.4158704801689206
Validation loss: 2.844415356277043

Epoch: 6| Step: 9
Training loss: 1.4546997397591108
Validation loss: 2.781003033820725

Epoch: 6| Step: 10
Training loss: 1.3871763522049745
Validation loss: 2.7725608192287923

Epoch: 6| Step: 11
Training loss: 1.345581049150427
Validation loss: 2.7165208791062283

Epoch: 6| Step: 12
Training loss: 1.8217369040338731
Validation loss: 2.8599770473235

Epoch: 6| Step: 13
Training loss: 1.5685635216508949
Validation loss: 2.8255751831640374

Epoch: 95| Step: 0
Training loss: 1.6280096500120098
Validation loss: 2.7869152419395906

Epoch: 6| Step: 1
Training loss: 1.3455363974522936
Validation loss: 2.8853275042000215

Epoch: 6| Step: 2
Training loss: 1.5685957449041472
Validation loss: 2.794186256932377

Epoch: 6| Step: 3
Training loss: 1.2715473774713615
Validation loss: 2.78362422858265

Epoch: 6| Step: 4
Training loss: 1.7268777274718752
Validation loss: 2.850051270408573

Epoch: 6| Step: 5
Training loss: 1.5294500398485398
Validation loss: 2.892911141007659

Epoch: 6| Step: 6
Training loss: 1.9492523251625196
Validation loss: 2.832911198154368

Epoch: 6| Step: 7
Training loss: 1.1842109908833625
Validation loss: 2.839056480455919

Epoch: 6| Step: 8
Training loss: 1.2786766820269397
Validation loss: 2.694840895816647

Epoch: 6| Step: 9
Training loss: 1.6361313086606732
Validation loss: 2.7857980581643007

Epoch: 6| Step: 10
Training loss: 2.0846714935580297
Validation loss: 2.7952575268785242

Epoch: 6| Step: 11
Training loss: 1.6002786095756516
Validation loss: 2.8123181531539463

Epoch: 6| Step: 12
Training loss: 1.65633766374171
Validation loss: 2.904182341180769

Epoch: 6| Step: 13
Training loss: 1.809612868622305
Validation loss: 2.884147259230753

Epoch: 96| Step: 0
Training loss: 1.5340076449625233
Validation loss: 2.8122918369824337

Epoch: 6| Step: 1
Training loss: 2.040344303097667
Validation loss: 2.786131614473542

Epoch: 6| Step: 2
Training loss: 1.3420458344735093
Validation loss: 2.76989725023337

Epoch: 6| Step: 3
Training loss: 1.3682722747288816
Validation loss: 2.7505742831684032

Epoch: 6| Step: 4
Training loss: 1.9701297103470221
Validation loss: 2.717793585094577

Epoch: 6| Step: 5
Training loss: 1.0868842299926604
Validation loss: 2.8671546123395895

Epoch: 6| Step: 6
Training loss: 1.6392001549707194
Validation loss: 2.838165780940522

Epoch: 6| Step: 7
Training loss: 1.4554391297926603
Validation loss: 2.86699680730196

Epoch: 6| Step: 8
Training loss: 1.8998690258860584
Validation loss: 2.8687948075218603

Epoch: 6| Step: 9
Training loss: 1.7993110397859253
Validation loss: 2.865966897395743

Epoch: 6| Step: 10
Training loss: 1.6082372995803431
Validation loss: 2.793842426224795

Epoch: 6| Step: 11
Training loss: 2.258469852201535
Validation loss: 2.8006931860365216

Epoch: 6| Step: 12
Training loss: 1.3571488579280382
Validation loss: 2.8460777453296195

Epoch: 6| Step: 13
Training loss: 1.4140546598269792
Validation loss: 2.801872817478355

Epoch: 97| Step: 0
Training loss: 1.47809146254319
Validation loss: 2.859599954063126

Epoch: 6| Step: 1
Training loss: 1.530019849885318
Validation loss: 2.8738531091794974

Epoch: 6| Step: 2
Training loss: 1.3194412426602962
Validation loss: 2.8101160188845355

Epoch: 6| Step: 3
Training loss: 1.7977561448784882
Validation loss: 2.7728877565943737

Epoch: 6| Step: 4
Training loss: 1.7114130343453615
Validation loss: 2.9225105097711976

Epoch: 6| Step: 5
Training loss: 1.5253055954213988
Validation loss: 2.83821437710363

Epoch: 6| Step: 6
Training loss: 1.9037808545643615
Validation loss: 2.737385950369088

Epoch: 6| Step: 7
Training loss: 1.7839854468235299
Validation loss: 2.818809101531148

Epoch: 6| Step: 8
Training loss: 1.8137864118794973
Validation loss: 2.865240809964939

Epoch: 6| Step: 9
Training loss: 1.5456531978368881
Validation loss: 2.837771177567567

Epoch: 6| Step: 10
Training loss: 0.9696628207706028
Validation loss: 2.8909895383526134

Epoch: 6| Step: 11
Training loss: 1.449154752156243
Validation loss: 2.740768007254025

Epoch: 6| Step: 12
Training loss: 0.9790723058536428
Validation loss: 2.7716699833333016

Epoch: 6| Step: 13
Training loss: 2.187905846140813
Validation loss: 2.845334795676478

Epoch: 98| Step: 0
Training loss: 1.5753528684087454
Validation loss: 2.75825240505315

Epoch: 6| Step: 1
Training loss: 0.9604312834934132
Validation loss: 2.805453069365632

Epoch: 6| Step: 2
Training loss: 1.27094338154235
Validation loss: 2.8062490580783046

Epoch: 6| Step: 3
Training loss: 1.5637908181306965
Validation loss: 2.8489551486056217

Epoch: 6| Step: 4
Training loss: 1.9468067971616632
Validation loss: 2.872869434664612

Epoch: 6| Step: 5
Training loss: 1.4077247092661804
Validation loss: 2.9006705648871973

Epoch: 6| Step: 6
Training loss: 1.9804466592433214
Validation loss: 2.8648456707675676

Epoch: 6| Step: 7
Training loss: 1.546247644075713
Validation loss: 2.8271582480849498

Epoch: 6| Step: 8
Training loss: 1.6888797205890849
Validation loss: 2.8978616805702453

Epoch: 6| Step: 9
Training loss: 1.927384210416223
Validation loss: 2.8758765418595327

Epoch: 6| Step: 10
Training loss: 2.001457994220867
Validation loss: 2.9359100042750477

Epoch: 6| Step: 11
Training loss: 1.718283017615401
Validation loss: 2.9234563318893456

Epoch: 6| Step: 12
Training loss: 1.4931156806766743
Validation loss: 2.9061670188952453

Epoch: 6| Step: 13
Training loss: 0.9133303717985194
Validation loss: 2.9487258061279853

Epoch: 99| Step: 0
Training loss: 1.2512949911254636
Validation loss: 2.8584624677427937

Epoch: 6| Step: 1
Training loss: 1.1434965175880878
Validation loss: 2.9538369775408206

Epoch: 6| Step: 2
Training loss: 1.6978684947039413
Validation loss: 2.919701582169579

Epoch: 6| Step: 3
Training loss: 1.9842723910017734
Validation loss: 2.9576257656483302

Epoch: 6| Step: 4
Training loss: 2.1575576576493947
Validation loss: 2.9725676233862615

Epoch: 6| Step: 5
Training loss: 1.0369833314672448
Validation loss: 2.7991158230399913

Epoch: 6| Step: 6
Training loss: 1.5381366249088493
Validation loss: 2.8416236780966466

Epoch: 6| Step: 7
Training loss: 1.2987558445142695
Validation loss: 2.8707266021362337

Epoch: 6| Step: 8
Training loss: 2.237561707737925
Validation loss: 2.8938123708639965

Epoch: 6| Step: 9
Training loss: 1.5911450508311378
Validation loss: 2.9765303535761385

Epoch: 6| Step: 10
Training loss: 1.5470354401585924
Validation loss: 2.863751048933326

Epoch: 6| Step: 11
Training loss: 2.222640159830271
Validation loss: 2.917161631592917

Epoch: 6| Step: 12
Training loss: 1.4905157661000838
Validation loss: 2.94615595686222

Epoch: 6| Step: 13
Training loss: 1.0814005531940347
Validation loss: 2.8208567621637686

Epoch: 100| Step: 0
Training loss: 1.900878718111826
Validation loss: 2.80602578879569

Epoch: 6| Step: 1
Training loss: 1.5808679895753053
Validation loss: 2.849656360666782

Epoch: 6| Step: 2
Training loss: 1.1735333216893218
Validation loss: 2.8864083267298333

Epoch: 6| Step: 3
Training loss: 1.879492400612453
Validation loss: 2.8040169965489192

Epoch: 6| Step: 4
Training loss: 1.9034543408588436
Validation loss: 2.766008885639415

Epoch: 6| Step: 5
Training loss: 1.694299914062296
Validation loss: 2.8459457402256447

Epoch: 6| Step: 6
Training loss: 1.3848764135809897
Validation loss: 2.8470682898574844

Epoch: 6| Step: 7
Training loss: 1.8455773043258512
Validation loss: 2.794714862470996

Epoch: 6| Step: 8
Training loss: 1.3020999856519804
Validation loss: 2.7687560495464063

Epoch: 6| Step: 9
Training loss: 1.7206651594669482
Validation loss: 2.861581517305941

Epoch: 6| Step: 10
Training loss: 1.2128428574153567
Validation loss: 2.818823409833868

Epoch: 6| Step: 11
Training loss: 1.2799936973893447
Validation loss: 2.926138502514678

Epoch: 6| Step: 12
Training loss: 1.0938661786093042
Validation loss: 2.747473141033036

Epoch: 6| Step: 13
Training loss: 1.6497792934424693
Validation loss: 2.7667395003816324

Epoch: 101| Step: 0
Training loss: 1.1036200819961242
Validation loss: 2.669319566731517

Epoch: 6| Step: 1
Training loss: 1.5442714937754394
Validation loss: 2.853894315844852

Epoch: 6| Step: 2
Training loss: 1.751627029468948
Validation loss: 2.8109754315612983

Epoch: 6| Step: 3
Training loss: 1.7587033875232185
Validation loss: 2.8295400883378963

Epoch: 6| Step: 4
Training loss: 1.3900538353820384
Validation loss: 2.862540974663845

Epoch: 6| Step: 5
Training loss: 1.5247931293192656
Validation loss: 2.795991242938501

Epoch: 6| Step: 6
Training loss: 1.7991999967643768
Validation loss: 2.786727084215209

Epoch: 6| Step: 7
Training loss: 1.160377250198275
Validation loss: 2.8819753918396867

Epoch: 6| Step: 8
Training loss: 2.2113708502747946
Validation loss: 2.808632444947246

Epoch: 6| Step: 9
Training loss: 1.0647405673753674
Validation loss: 2.8425502132520033

Epoch: 6| Step: 10
Training loss: 1.7353867337811741
Validation loss: 2.8361452865492645

Epoch: 6| Step: 11
Training loss: 1.7516247155525413
Validation loss: 2.826026580597801

Epoch: 6| Step: 12
Training loss: 2.074974597637538
Validation loss: 2.9347749339365263

Epoch: 6| Step: 13
Training loss: 1.483242847954542
Validation loss: 2.834594730943244

Epoch: 102| Step: 0
Training loss: 1.8114434813259308
Validation loss: 2.9134003651441507

Epoch: 6| Step: 1
Training loss: 1.1629070717773289
Validation loss: 2.841187436888671

Epoch: 6| Step: 2
Training loss: 1.686728053665829
Validation loss: 2.805538179534719

Epoch: 6| Step: 3
Training loss: 2.140448792716313
Validation loss: 2.884195053091688

Epoch: 6| Step: 4
Training loss: 1.3368584654054385
Validation loss: 2.932645547132446

Epoch: 6| Step: 5
Training loss: 1.349393747331113
Validation loss: 2.8266192760708444

Epoch: 6| Step: 6
Training loss: 1.3203917710924669
Validation loss: 2.7691147333679

Epoch: 6| Step: 7
Training loss: 1.3617486509453351
Validation loss: 2.9261351618774136

Epoch: 6| Step: 8
Training loss: 1.1554532269924
Validation loss: 2.858831343533944

Epoch: 6| Step: 9
Training loss: 1.5792906582483766
Validation loss: 2.8553124005348045

Epoch: 6| Step: 10
Training loss: 1.8988916301329288
Validation loss: 2.808345721827801

Epoch: 6| Step: 11
Training loss: 1.214812348870701
Validation loss: 2.87352056723764

Epoch: 6| Step: 12
Training loss: 1.339246655757475
Validation loss: 2.8441898718385685

Epoch: 6| Step: 13
Training loss: 1.8258528323621666
Validation loss: 2.8602422708765296

Epoch: 103| Step: 0
Training loss: 1.545217994446126
Validation loss: 2.881797246480429

Epoch: 6| Step: 1
Training loss: 1.0641103210010348
Validation loss: 2.8797354468060616

Epoch: 6| Step: 2
Training loss: 1.719169565488979
Validation loss: 2.817863648106824

Epoch: 6| Step: 3
Training loss: 1.6990484042667837
Validation loss: 2.879370739481508

Epoch: 6| Step: 4
Training loss: 1.254426937196974
Validation loss: 2.8604640866928857

Epoch: 6| Step: 5
Training loss: 1.5384483080074978
Validation loss: 2.7789003112060304

Epoch: 6| Step: 6
Training loss: 1.4013493234379673
Validation loss: 2.9259579804185236

Epoch: 6| Step: 7
Training loss: 1.4422054401244846
Validation loss: 2.7673281007268637

Epoch: 6| Step: 8
Training loss: 1.193259676750391
Validation loss: 2.810804930029898

Epoch: 6| Step: 9
Training loss: 2.3463704020072207
Validation loss: 2.846761499257674

Epoch: 6| Step: 10
Training loss: 1.6545551193061734
Validation loss: 2.8842521594482724

Epoch: 6| Step: 11
Training loss: 1.7946772528024877
Validation loss: 2.8936090549009514

Epoch: 6| Step: 12
Training loss: 1.0987261787583733
Validation loss: 2.816609721388759

Epoch: 6| Step: 13
Training loss: 1.4400756814725155
Validation loss: 2.841301265466075

Epoch: 104| Step: 0
Training loss: 1.1726386061935168
Validation loss: 2.868374806499016

Epoch: 6| Step: 1
Training loss: 1.5733375070538091
Validation loss: 2.9107328180853727

Epoch: 6| Step: 2
Training loss: 1.9005581036090666
Validation loss: 2.7712246802513585

Epoch: 6| Step: 3
Training loss: 1.6561657866175268
Validation loss: 2.930628700809931

Epoch: 6| Step: 4
Training loss: 1.0951313015848265
Validation loss: 2.8958193735202435

Epoch: 6| Step: 5
Training loss: 1.4386021908184814
Validation loss: 2.806875071758099

Epoch: 6| Step: 6
Training loss: 1.5072750260234848
Validation loss: 2.715275484513932

Epoch: 6| Step: 7
Training loss: 1.4115675101572387
Validation loss: 2.8571528153586554

Epoch: 6| Step: 8
Training loss: 1.5825153881608447
Validation loss: 2.815647666803221

Epoch: 6| Step: 9
Training loss: 2.1185038510814937
Validation loss: 2.7998284315724153

Epoch: 6| Step: 10
Training loss: 1.4018527050515905
Validation loss: 2.836316618436116

Epoch: 6| Step: 11
Training loss: 0.9931215410310347
Validation loss: 2.910814754391481

Epoch: 6| Step: 12
Training loss: 1.4308109559560829
Validation loss: 2.8521043933195824

Epoch: 6| Step: 13
Training loss: 1.2518491419132285
Validation loss: 2.893260558490544

Epoch: 105| Step: 0
Training loss: 1.6324683013689316
Validation loss: 2.8433865395256444

Epoch: 6| Step: 1
Training loss: 1.4116224449254169
Validation loss: 2.7968245418266364

Epoch: 6| Step: 2
Training loss: 0.7736172322758376
Validation loss: 2.8341967071343945

Epoch: 6| Step: 3
Training loss: 1.1162864946506086
Validation loss: 2.8355750770986394

Epoch: 6| Step: 4
Training loss: 1.6230672933714905
Validation loss: 2.850827126636084

Epoch: 6| Step: 5
Training loss: 1.0726027106518825
Validation loss: 2.8301134091940456

Epoch: 6| Step: 6
Training loss: 1.3446383977174494
Validation loss: 2.8299491998630906

Epoch: 6| Step: 7
Training loss: 1.1940068113493767
Validation loss: 2.792601917425354

Epoch: 6| Step: 8
Training loss: 1.355929953085317
Validation loss: 2.8315522308382315

Epoch: 6| Step: 9
Training loss: 2.137405201555378
Validation loss: 2.858275029965955

Epoch: 6| Step: 10
Training loss: 1.5730248555076687
Validation loss: 2.838920838582047

Epoch: 6| Step: 11
Training loss: 1.56008709566589
Validation loss: 2.8727692781796934

Epoch: 6| Step: 12
Training loss: 2.0160671015425957
Validation loss: 2.853805857961238

Epoch: 6| Step: 13
Training loss: 1.213985962093707
Validation loss: 2.882720132535137

Epoch: 106| Step: 0
Training loss: 1.804370274261745
Validation loss: 3.0225946925758955

Epoch: 6| Step: 1
Training loss: 1.1074065891939975
Validation loss: 2.935636578659474

Epoch: 6| Step: 2
Training loss: 1.9541722046123624
Validation loss: 2.877214283947468

Epoch: 6| Step: 3
Training loss: 1.1795474341905947
Validation loss: 2.91648965480083

Epoch: 6| Step: 4
Training loss: 2.068154876945085
Validation loss: 2.8877046834556905

Epoch: 6| Step: 5
Training loss: 1.0981158723055593
Validation loss: 2.9387528743970526

Epoch: 6| Step: 6
Training loss: 1.1644649961852431
Validation loss: 2.7394141131646306

Epoch: 6| Step: 7
Training loss: 1.4441597955580265
Validation loss: 2.970516790046664

Epoch: 6| Step: 8
Training loss: 1.4506382326823428
Validation loss: 2.8930625741667657

Epoch: 6| Step: 9
Training loss: 1.599423948539938
Validation loss: 2.7811133247539743

Epoch: 6| Step: 10
Training loss: 1.7824566418268568
Validation loss: 2.8237483968247514

Epoch: 6| Step: 11
Training loss: 1.6064223082034503
Validation loss: 2.8412580505829887

Epoch: 6| Step: 12
Training loss: 0.6617490525046131
Validation loss: 2.8652077751424474

Epoch: 6| Step: 13
Training loss: 1.5942289343380287
Validation loss: 2.9278956108662553

Epoch: 107| Step: 0
Training loss: 2.234942810897173
Validation loss: 2.8927702358070935

Epoch: 6| Step: 1
Training loss: 1.6547143402660411
Validation loss: 2.935846255516988

Epoch: 6| Step: 2
Training loss: 1.5813954523911031
Validation loss: 2.952993575036069

Epoch: 6| Step: 3
Training loss: 1.14126025760382
Validation loss: 2.949953882751339

Epoch: 6| Step: 4
Training loss: 1.4442520787859843
Validation loss: 2.8718553151537702

Epoch: 6| Step: 5
Training loss: 1.4689197036424086
Validation loss: 2.7809261462077752

Epoch: 6| Step: 6
Training loss: 1.19570856451413
Validation loss: 2.7890316118227165

Epoch: 6| Step: 7
Training loss: 1.125344912319892
Validation loss: 2.8924265840489642

Epoch: 6| Step: 8
Training loss: 1.5222789565107793
Validation loss: 2.7880284576815355

Epoch: 6| Step: 9
Training loss: 1.2877935926627224
Validation loss: 2.784008030197467

Epoch: 6| Step: 10
Training loss: 1.0547986007383148
Validation loss: 2.986357371700788

Epoch: 6| Step: 11
Training loss: 1.286844460716469
Validation loss: 2.776042034060876

Epoch: 6| Step: 12
Training loss: 1.548669640994052
Validation loss: 2.7744597077992714

Epoch: 6| Step: 13
Training loss: 1.0569335757039404
Validation loss: 2.9721449998427962

Epoch: 108| Step: 0
Training loss: 1.124694199856122
Validation loss: 2.8517194870189524

Epoch: 6| Step: 1
Training loss: 1.8951762251831654
Validation loss: 2.8231807505448874

Epoch: 6| Step: 2
Training loss: 1.520675502930929
Validation loss: 2.8353887470187185

Epoch: 6| Step: 3
Training loss: 1.6886231252360697
Validation loss: 2.7971823610455973

Epoch: 6| Step: 4
Training loss: 1.1173662162765818
Validation loss: 2.8047448084226376

Epoch: 6| Step: 5
Training loss: 1.1438443462877919
Validation loss: 2.906702245711802

Epoch: 6| Step: 6
Training loss: 1.5109665845184168
Validation loss: 2.948947461179048

Epoch: 6| Step: 7
Training loss: 1.1998130990549651
Validation loss: 2.8873226650768773

Epoch: 6| Step: 8
Training loss: 1.754181770144913
Validation loss: 2.7635029555819646

Epoch: 6| Step: 9
Training loss: 1.6387800469688236
Validation loss: 2.8336404372187745

Epoch: 6| Step: 10
Training loss: 1.2849363005468453
Validation loss: 2.8742458971612583

Epoch: 6| Step: 11
Training loss: 1.6667877232774375
Validation loss: 2.910412026585726

Epoch: 6| Step: 12
Training loss: 1.0620460662549125
Validation loss: 2.8155682252162118

Epoch: 6| Step: 13
Training loss: 1.4581354370266888
Validation loss: 2.914546636568994

Epoch: 109| Step: 0
Training loss: 1.3649079419627388
Validation loss: 2.904028874379835

Epoch: 6| Step: 1
Training loss: 0.8895711184756674
Validation loss: 2.9129294475860155

Epoch: 6| Step: 2
Training loss: 1.315326644157986
Validation loss: 2.8280914332749525

Epoch: 6| Step: 3
Training loss: 1.3986102801946254
Validation loss: 2.791649353391186

Epoch: 6| Step: 4
Training loss: 2.2415869569846887
Validation loss: 2.7828723447670187

Epoch: 6| Step: 5
Training loss: 1.7402704751051852
Validation loss: 2.8548102013008245

Epoch: 6| Step: 6
Training loss: 0.8132349871432071
Validation loss: 2.8616548909289583

Epoch: 6| Step: 7
Training loss: 1.564130618872832
Validation loss: 2.7348529652248454

Epoch: 6| Step: 8
Training loss: 1.2840773857184105
Validation loss: 2.9482512042731237

Epoch: 6| Step: 9
Training loss: 1.287294412142745
Validation loss: 2.845955032233753

Epoch: 6| Step: 10
Training loss: 1.5152351428563728
Validation loss: 2.88557896806018

Epoch: 6| Step: 11
Training loss: 1.6429688196549557
Validation loss: 2.789461208877207

Epoch: 6| Step: 12
Training loss: 0.9758165791379304
Validation loss: 2.8449426741989643

Epoch: 6| Step: 13
Training loss: 1.3691302637859109
Validation loss: 2.858972510688349

Epoch: 110| Step: 0
Training loss: 1.3924305370818841
Validation loss: 2.8855840494424148

Epoch: 6| Step: 1
Training loss: 1.633258156441187
Validation loss: 2.8212017936233176

Epoch: 6| Step: 2
Training loss: 1.5003839637153613
Validation loss: 2.9489026032821783

Epoch: 6| Step: 3
Training loss: 1.9587279253642673
Validation loss: 2.892768175336985

Epoch: 6| Step: 4
Training loss: 1.292555036940951
Validation loss: 2.9064463477308777

Epoch: 6| Step: 5
Training loss: 0.8363348827418661
Validation loss: 2.775178919571558

Epoch: 6| Step: 6
Training loss: 1.293928084348752
Validation loss: 2.898838779745332

Epoch: 6| Step: 7
Training loss: 0.9125378600849443
Validation loss: 2.8717340356588883

Epoch: 6| Step: 8
Training loss: 1.438802046509709
Validation loss: 2.8402783228825235

Epoch: 6| Step: 9
Training loss: 1.5190834621230098
Validation loss: 2.7454558310294237

Epoch: 6| Step: 10
Training loss: 1.1749870685109296
Validation loss: 2.7091921740617657

Epoch: 6| Step: 11
Training loss: 1.3734713206287865
Validation loss: 2.847035797859703

Epoch: 6| Step: 12
Training loss: 1.5915928622139184
Validation loss: 2.8286614515172728

Epoch: 6| Step: 13
Training loss: 1.1564596346957394
Validation loss: 2.949206408207482

Epoch: 111| Step: 0
Training loss: 1.671970899451869
Validation loss: 2.9383206810537286

Epoch: 6| Step: 1
Training loss: 1.1840188046908082
Validation loss: 2.8531032632457256

Epoch: 6| Step: 2
Training loss: 1.4364304917670825
Validation loss: 2.858756771549444

Epoch: 6| Step: 3
Training loss: 1.44367195017507
Validation loss: 2.7433495735515896

Epoch: 6| Step: 4
Training loss: 2.2401264567102506
Validation loss: 2.9188298151183845

Epoch: 6| Step: 5
Training loss: 1.4825950792775149
Validation loss: 2.850831503341104

Epoch: 6| Step: 6
Training loss: 1.1982755151169469
Validation loss: 2.8050467598429436

Epoch: 6| Step: 7
Training loss: 0.9904726482891753
Validation loss: 2.8008896413460627

Epoch: 6| Step: 8
Training loss: 1.1490287556282832
Validation loss: 2.9418693809436705

Epoch: 6| Step: 9
Training loss: 1.5192633149914898
Validation loss: 2.896842949781512

Epoch: 6| Step: 10
Training loss: 1.6984174571043487
Validation loss: 2.908161122890038

Epoch: 6| Step: 11
Training loss: 0.8286875847145277
Validation loss: 2.9114143673074198

Epoch: 6| Step: 12
Training loss: 1.2800642900414825
Validation loss: 2.9139511728029444

Epoch: 6| Step: 13
Training loss: 1.167711312491263
Validation loss: 2.8698357626590125

Epoch: 112| Step: 0
Training loss: 1.252795050887981
Validation loss: 2.8504746125540543

Epoch: 6| Step: 1
Training loss: 1.2920795621614964
Validation loss: 2.785095799143633

Epoch: 6| Step: 2
Training loss: 1.4933928569499753
Validation loss: 2.765586895868773

Epoch: 6| Step: 3
Training loss: 1.4228832317276046
Validation loss: 2.860564674017502

Epoch: 6| Step: 4
Training loss: 1.555720843699511
Validation loss: 2.872649420539125

Epoch: 6| Step: 5
Training loss: 1.4485413646802838
Validation loss: 2.7949487599115677

Epoch: 6| Step: 6
Training loss: 1.5458820122854113
Validation loss: 2.8703521808836396

Epoch: 6| Step: 7
Training loss: 1.1280269168050119
Validation loss: 2.7975246449266473

Epoch: 6| Step: 8
Training loss: 1.0452752487319177
Validation loss: 2.8697106037818174

Epoch: 6| Step: 9
Training loss: 1.4389593760500126
Validation loss: 2.9266987929250026

Epoch: 6| Step: 10
Training loss: 1.3059197733950074
Validation loss: 2.7827127303484547

Epoch: 6| Step: 11
Training loss: 1.3007192511002519
Validation loss: 2.8933241331009856

Epoch: 6| Step: 12
Training loss: 1.9325904169681376
Validation loss: 2.9327413689549178

Epoch: 6| Step: 13
Training loss: 1.6544039532844783
Validation loss: 2.7908972325095207

Epoch: 113| Step: 0
Training loss: 1.5517489011111332
Validation loss: 2.9620115803035643

Epoch: 6| Step: 1
Training loss: 1.6523762151897061
Validation loss: 2.910692866132616

Epoch: 6| Step: 2
Training loss: 1.185320963066255
Validation loss: 2.873482898203486

Epoch: 6| Step: 3
Training loss: 1.3479011202607947
Validation loss: 2.9528030542954715

Epoch: 6| Step: 4
Training loss: 1.356318886057842
Validation loss: 2.901035607889219

Epoch: 6| Step: 5
Training loss: 1.5453880947279963
Validation loss: 2.913180602178069

Epoch: 6| Step: 6
Training loss: 1.97817095421419
Validation loss: 2.8737406252873625

Epoch: 6| Step: 7
Training loss: 1.0849958220194875
Validation loss: 2.884792099617923

Epoch: 6| Step: 8
Training loss: 0.9651035777524389
Validation loss: 2.909204082337646

Epoch: 6| Step: 9
Training loss: 1.2663300045907202
Validation loss: 2.9389607470195944

Epoch: 6| Step: 10
Training loss: 1.2874601635742084
Validation loss: 2.9390460876298627

Epoch: 6| Step: 11
Training loss: 1.6821654029286355
Validation loss: 2.85548613091157

Epoch: 6| Step: 12
Training loss: 1.362760602894056
Validation loss: 2.895092771138488

Epoch: 6| Step: 13
Training loss: 1.2347822362596415
Validation loss: 2.9686586867895612

Epoch: 114| Step: 0
Training loss: 1.2808839693817329
Validation loss: 2.831130859360852

Epoch: 6| Step: 1
Training loss: 1.0498032680768021
Validation loss: 2.951776065238655

Epoch: 6| Step: 2
Training loss: 1.3460043693176817
Validation loss: 2.744958272916752

Epoch: 6| Step: 3
Training loss: 1.1019790619316643
Validation loss: 2.8647362731796475

Epoch: 6| Step: 4
Training loss: 2.3191934577946993
Validation loss: 2.841767426957603

Epoch: 6| Step: 5
Training loss: 1.3421100989373702
Validation loss: 2.7831136767196094

Epoch: 6| Step: 6
Training loss: 1.1383235653857977
Validation loss: 2.820696817773229

Epoch: 6| Step: 7
Training loss: 1.0035099776284688
Validation loss: 2.7244757069166052

Epoch: 6| Step: 8
Training loss: 1.2550879878473737
Validation loss: 2.7899770937882846

Epoch: 6| Step: 9
Training loss: 1.2324621130515216
Validation loss: 2.8001879884419587

Epoch: 6| Step: 10
Training loss: 1.3697820839589012
Validation loss: 2.8664122805909287

Epoch: 6| Step: 11
Training loss: 1.483121483208256
Validation loss: 2.875969695604953

Epoch: 6| Step: 12
Training loss: 1.6540684277680333
Validation loss: 2.7776565625975818

Epoch: 6| Step: 13
Training loss: 1.2142045771314458
Validation loss: 2.797803515098822

Epoch: 115| Step: 0
Training loss: 1.2001765399454876
Validation loss: 2.820015269051015

Epoch: 6| Step: 1
Training loss: 1.5261874688013093
Validation loss: 2.8394137568134

Epoch: 6| Step: 2
Training loss: 1.2252184069813463
Validation loss: 2.8119188767990972

Epoch: 6| Step: 3
Training loss: 1.5282558829769837
Validation loss: 2.942083084163341

Epoch: 6| Step: 4
Training loss: 0.945167593450422
Validation loss: 2.8103924307450954

Epoch: 6| Step: 5
Training loss: 1.262170197117286
Validation loss: 2.814925003114249

Epoch: 6| Step: 6
Training loss: 1.2659940299334786
Validation loss: 2.8907205651784538

Epoch: 6| Step: 7
Training loss: 1.2725936808698861
Validation loss: 2.898028047470237

Epoch: 6| Step: 8
Training loss: 1.40827677159839
Validation loss: 2.8357699005792716

Epoch: 6| Step: 9
Training loss: 1.1169060839493887
Validation loss: 2.9069965593194955

Epoch: 6| Step: 10
Training loss: 1.359891157703502
Validation loss: 2.88699149571254

Epoch: 6| Step: 11
Training loss: 1.1240430576656972
Validation loss: 2.7713744321150395

Epoch: 6| Step: 12
Training loss: 2.0706312402043383
Validation loss: 2.795587609223891

Epoch: 6| Step: 13
Training loss: 1.2879787628958228
Validation loss: 2.8267908479595567

Epoch: 116| Step: 0
Training loss: 1.633731200293182
Validation loss: 2.927048331127198

Epoch: 6| Step: 1
Training loss: 2.115628164449604
Validation loss: 2.87856483591689

Epoch: 6| Step: 2
Training loss: 0.969315763590631
Validation loss: 2.938446298318519

Epoch: 6| Step: 3
Training loss: 1.034849070910149
Validation loss: 2.8823408449143546

Epoch: 6| Step: 4
Training loss: 0.8642578814662755
Validation loss: 2.8507311022672193

Epoch: 6| Step: 5
Training loss: 1.5622474466303902
Validation loss: 2.8473535559119276

Epoch: 6| Step: 6
Training loss: 0.9687770409040243
Validation loss: 2.7836684238475646

Epoch: 6| Step: 7
Training loss: 0.9435247114470002
Validation loss: 2.8859750549373326

Epoch: 6| Step: 8
Training loss: 1.2360033328804585
Validation loss: 2.8636223631906947

Epoch: 6| Step: 9
Training loss: 1.2295466767735945
Validation loss: 2.83628212592406

Epoch: 6| Step: 10
Training loss: 1.5634388201302158
Validation loss: 2.8664249164829183

Epoch: 6| Step: 11
Training loss: 1.2902088039172916
Validation loss: 2.840501501842089

Epoch: 6| Step: 12
Training loss: 1.3831257869340716
Validation loss: 2.7622912010121317

Epoch: 6| Step: 13
Training loss: 1.520298859553683
Validation loss: 2.7965896148282208

Epoch: 117| Step: 0
Training loss: 1.495949282531046
Validation loss: 2.757175303502846

Epoch: 6| Step: 1
Training loss: 1.1808116684897936
Validation loss: 2.936879099163608

Epoch: 6| Step: 2
Training loss: 0.9507245651060755
Validation loss: 2.914400723680792

Epoch: 6| Step: 3
Training loss: 1.4941691875844278
Validation loss: 2.8761308077093806

Epoch: 6| Step: 4
Training loss: 0.8385544927970613
Validation loss: 2.7890172504134574

Epoch: 6| Step: 5
Training loss: 1.8009174816707603
Validation loss: 2.8373094993311194

Epoch: 6| Step: 6
Training loss: 0.9923439803593962
Validation loss: 2.9504983311350887

Epoch: 6| Step: 7
Training loss: 0.6584485103155527
Validation loss: 2.9152076932267166

Epoch: 6| Step: 8
Training loss: 1.4464720327585785
Validation loss: 2.922022293920499

Epoch: 6| Step: 9
Training loss: 1.1364500377059716
Validation loss: 2.9288392869334596

Epoch: 6| Step: 10
Training loss: 1.5624100468491744
Validation loss: 2.8703917183532237

Epoch: 6| Step: 11
Training loss: 1.3859573638077427
Validation loss: 2.9584296483940715

Epoch: 6| Step: 12
Training loss: 1.21928594493776
Validation loss: 2.8297283552321426

Epoch: 6| Step: 13
Training loss: 2.0134091284465665
Validation loss: 2.8902128733428785

Epoch: 118| Step: 0
Training loss: 1.1626436944567367
Validation loss: 2.8887325931312393

Epoch: 6| Step: 1
Training loss: 1.112196330083408
Validation loss: 2.8379038989602674

Epoch: 6| Step: 2
Training loss: 1.5213268036837342
Validation loss: 2.8159256029849624

Epoch: 6| Step: 3
Training loss: 1.2426243619641857
Validation loss: 2.8449012745475373

Epoch: 6| Step: 4
Training loss: 1.3339938921609855
Validation loss: 2.8344116730089217

Epoch: 6| Step: 5
Training loss: 1.416722530310722
Validation loss: 2.82311383693116

Epoch: 6| Step: 6
Training loss: 1.53520346221931
Validation loss: 2.7987172685361545

Epoch: 6| Step: 7
Training loss: 0.8129956127672425
Validation loss: 2.907236321547905

Epoch: 6| Step: 8
Training loss: 1.2703854078928556
Validation loss: 2.847613173421939

Epoch: 6| Step: 9
Training loss: 1.2469458461893432
Validation loss: 2.840871646749937

Epoch: 6| Step: 10
Training loss: 2.0216425294790104
Validation loss: 2.7842328082025403

Epoch: 6| Step: 11
Training loss: 1.7710653564438705
Validation loss: 2.9341109184408602

Epoch: 6| Step: 12
Training loss: 0.752021608082798
Validation loss: 2.8086471587909423

Epoch: 6| Step: 13
Training loss: 1.1435396240701685
Validation loss: 2.672149763052368

Epoch: 119| Step: 0
Training loss: 1.5331626935353706
Validation loss: 2.937651501800145

Epoch: 6| Step: 1
Training loss: 1.537030422795647
Validation loss: 2.925065663135927

Epoch: 6| Step: 2
Training loss: 0.9331338300242457
Validation loss: 2.884388342179354

Epoch: 6| Step: 3
Training loss: 0.8822465618603789
Validation loss: 2.8610321690389635

Epoch: 6| Step: 4
Training loss: 0.9736911828882127
Validation loss: 2.914921242842504

Epoch: 6| Step: 5
Training loss: 0.7548801673753989
Validation loss: 2.835206525210915

Epoch: 6| Step: 6
Training loss: 1.5963871399138048
Validation loss: 2.8805855520687933

Epoch: 6| Step: 7
Training loss: 1.0350010593611598
Validation loss: 2.896225543642627

Epoch: 6| Step: 8
Training loss: 1.4767605280412888
Validation loss: 2.8702224758859605

Epoch: 6| Step: 9
Training loss: 2.0828331410443366
Validation loss: 2.847798522269714

Epoch: 6| Step: 10
Training loss: 1.1851437934517595
Validation loss: 2.8088250062799798

Epoch: 6| Step: 11
Training loss: 0.8145133163201944
Validation loss: 2.920713741304794

Epoch: 6| Step: 12
Training loss: 0.8819942902490477
Validation loss: 2.8757683929595355

Epoch: 6| Step: 13
Training loss: 1.5800257651727136
Validation loss: 2.8194689136272237

Epoch: 120| Step: 0
Training loss: 0.825638186098964
Validation loss: 2.86843540015225

Epoch: 6| Step: 1
Training loss: 1.1965706879123186
Validation loss: 2.9405747142117735

Epoch: 6| Step: 2
Training loss: 1.1840123610302333
Validation loss: 2.8159134248886812

Epoch: 6| Step: 3
Training loss: 1.101543345183361
Validation loss: 2.8117769230192153

Epoch: 6| Step: 4
Training loss: 1.2814955127234153
Validation loss: 2.8112906929079973

Epoch: 6| Step: 5
Training loss: 1.4178737471940785
Validation loss: 2.87395788738657

Epoch: 6| Step: 6
Training loss: 1.1583789093784775
Validation loss: 2.895797390794794

Epoch: 6| Step: 7
Training loss: 1.7845198083164568
Validation loss: 2.900669496361134

Epoch: 6| Step: 8
Training loss: 1.256557999996314
Validation loss: 2.9256786808901456

Epoch: 6| Step: 9
Training loss: 1.4159525679656058
Validation loss: 2.980046886954237

Epoch: 6| Step: 10
Training loss: 1.8444159646625011
Validation loss: 2.84939540227899

Epoch: 6| Step: 11
Training loss: 0.9126492195400671
Validation loss: 2.8140977065478525

Epoch: 6| Step: 12
Training loss: 1.3496999089173378
Validation loss: 2.9253837746670586

Epoch: 6| Step: 13
Training loss: 0.8602867145325284
Validation loss: 3.0182231456486988

Epoch: 121| Step: 0
Training loss: 1.340332164660171
Validation loss: 3.0159018460288403

Epoch: 6| Step: 1
Training loss: 1.8710899910461003
Validation loss: 2.8805179027187986

Epoch: 6| Step: 2
Training loss: 1.517098330107822
Validation loss: 2.885863635610637

Epoch: 6| Step: 3
Training loss: 1.4597175931186677
Validation loss: 2.9672897495344914

Epoch: 6| Step: 4
Training loss: 1.5311304162488903
Validation loss: 2.9015391737617087

Epoch: 6| Step: 5
Training loss: 1.1712105456763386
Validation loss: 2.8887069937303838

Epoch: 6| Step: 6
Training loss: 1.6939663794557915
Validation loss: 2.982890493852981

Epoch: 6| Step: 7
Training loss: 1.4721258609753338
Validation loss: 2.8930976945389673

Epoch: 6| Step: 8
Training loss: 1.66090997079193
Validation loss: 2.8766552127095877

Epoch: 6| Step: 9
Training loss: 1.1977713731751005
Validation loss: 2.8706126530118254

Epoch: 6| Step: 10
Training loss: 1.1494417017074352
Validation loss: 2.8447518732245953

Epoch: 6| Step: 11
Training loss: 0.7945537792751353
Validation loss: 2.8878376349134234

Epoch: 6| Step: 12
Training loss: 1.0253394704501948
Validation loss: 2.830311135755768

Epoch: 6| Step: 13
Training loss: 1.1513403192932936
Validation loss: 2.807437041322056

Epoch: 122| Step: 0
Training loss: 1.1949874336188469
Validation loss: 3.005674479190922

Epoch: 6| Step: 1
Training loss: 1.5054465592653745
Validation loss: 2.920039669795101

Epoch: 6| Step: 2
Training loss: 1.6349111695029572
Validation loss: 2.8882817849036733

Epoch: 6| Step: 3
Training loss: 1.2780804857183048
Validation loss: 2.8617348027176113

Epoch: 6| Step: 4
Training loss: 1.0389462169315264
Validation loss: 2.8822850104005693

Epoch: 6| Step: 5
Training loss: 1.6777544120329255
Validation loss: 2.853311777285974

Epoch: 6| Step: 6
Training loss: 1.3816556240019369
Validation loss: 2.9351441019697138

Epoch: 6| Step: 7
Training loss: 1.0213257646413028
Validation loss: 2.82609427590948

Epoch: 6| Step: 8
Training loss: 1.7062230761293664
Validation loss: 2.9363472076603845

Epoch: 6| Step: 9
Training loss: 1.1585730851144591
Validation loss: 2.7883743876254483

Epoch: 6| Step: 10
Training loss: 1.3089409666454013
Validation loss: 2.798430807480867

Epoch: 6| Step: 11
Training loss: 0.9073000776482794
Validation loss: 2.863000610531817

Epoch: 6| Step: 12
Training loss: 1.201054860439878
Validation loss: 2.8768864814064545

Epoch: 6| Step: 13
Training loss: 1.342439367178904
Validation loss: 2.9055868233026945

Epoch: 123| Step: 0
Training loss: 0.7604527443117878
Validation loss: 2.8532808743835876

Epoch: 6| Step: 1
Training loss: 0.8354735468449748
Validation loss: 2.7756253491551557

Epoch: 6| Step: 2
Training loss: 1.5131449120529818
Validation loss: 2.889513465313535

Epoch: 6| Step: 3
Training loss: 1.327777951842172
Validation loss: 2.889830966524834

Epoch: 6| Step: 4
Training loss: 1.4631575581522407
Validation loss: 2.9003454134207667

Epoch: 6| Step: 5
Training loss: 1.1738425458634765
Validation loss: 2.853284049640901

Epoch: 6| Step: 6
Training loss: 0.8821398442659836
Validation loss: 2.8929154265720354

Epoch: 6| Step: 7
Training loss: 1.0851328221779504
Validation loss: 2.868091284893927

Epoch: 6| Step: 8
Training loss: 1.2713497342547215
Validation loss: 2.835967583054508

Epoch: 6| Step: 9
Training loss: 0.6063824312348046
Validation loss: 2.88994019790779

Epoch: 6| Step: 10
Training loss: 1.5571710886464616
Validation loss: 2.8639045026604117

Epoch: 6| Step: 11
Training loss: 1.9182850874007724
Validation loss: 2.835585363014483

Epoch: 6| Step: 12
Training loss: 0.9726071019758404
Validation loss: 2.705377099951107

Epoch: 6| Step: 13
Training loss: 1.4901674188093539
Validation loss: 2.897197530130621

Epoch: 124| Step: 0
Training loss: 0.8039206396952242
Validation loss: 2.891874603431949

Epoch: 6| Step: 1
Training loss: 1.4139666024247255
Validation loss: 2.871354999031229

Epoch: 6| Step: 2
Training loss: 0.9296733310164701
Validation loss: 2.818898784491606

Epoch: 6| Step: 3
Training loss: 1.0499253314580366
Validation loss: 2.90362248204625

Epoch: 6| Step: 4
Training loss: 1.5368732043143722
Validation loss: 2.863746081443491

Epoch: 6| Step: 5
Training loss: 1.2277663816284659
Validation loss: 2.7993074349654923

Epoch: 6| Step: 6
Training loss: 1.0377426943667727
Validation loss: 2.877275589125163

Epoch: 6| Step: 7
Training loss: 0.8156221996273915
Validation loss: 2.7876863192112973

Epoch: 6| Step: 8
Training loss: 1.1386243440578212
Validation loss: 2.9720260613814675

Epoch: 6| Step: 9
Training loss: 1.5420643920614716
Validation loss: 2.9621537796281348

Epoch: 6| Step: 10
Training loss: 0.7714699659329839
Validation loss: 2.8361716686072485

Epoch: 6| Step: 11
Training loss: 1.3081888511883655
Validation loss: 2.864239444320436

Epoch: 6| Step: 12
Training loss: 2.081325733536688
Validation loss: 2.8105006422915197

Epoch: 6| Step: 13
Training loss: 1.2027609633566723
Validation loss: 2.855612066301832

Epoch: 125| Step: 0
Training loss: 1.606560477444901
Validation loss: 2.829414635654436

Epoch: 6| Step: 1
Training loss: 1.3039975654895266
Validation loss: 2.753288398134308

Epoch: 6| Step: 2
Training loss: 0.5457747699779875
Validation loss: 2.9199978651622476

Epoch: 6| Step: 3
Training loss: 1.0265352381972186
Validation loss: 2.8867462941508775

Epoch: 6| Step: 4
Training loss: 1.409853662377574
Validation loss: 2.865221671449201

Epoch: 6| Step: 5
Training loss: 1.3741743469871877
Validation loss: 2.932669035421156

Epoch: 6| Step: 6
Training loss: 1.200808536812682
Validation loss: 2.9125659089278084

Epoch: 6| Step: 7
Training loss: 1.5472858538385108
Validation loss: 2.811361393217768

Epoch: 6| Step: 8
Training loss: 1.0274282790535494
Validation loss: 2.8535142324567384

Epoch: 6| Step: 9
Training loss: 1.3548631002095555
Validation loss: 2.874654058015923

Epoch: 6| Step: 10
Training loss: 1.1972502914367817
Validation loss: 2.8411003876060485

Epoch: 6| Step: 11
Training loss: 1.1152837578684562
Validation loss: 2.8623483898098097

Epoch: 6| Step: 12
Training loss: 1.7468209000673858
Validation loss: 2.8898173810641516

Epoch: 6| Step: 13
Training loss: 0.9982715809106484
Validation loss: 2.935025667818075

Epoch: 126| Step: 0
Training loss: 0.9962975387048151
Validation loss: 2.932631319926369

Epoch: 6| Step: 1
Training loss: 1.1404786211959295
Validation loss: 2.920515019317288

Epoch: 6| Step: 2
Training loss: 0.970462546671921
Validation loss: 2.8166185529162155

Epoch: 6| Step: 3
Training loss: 1.3025445756954286
Validation loss: 2.822873433099924

Epoch: 6| Step: 4
Training loss: 0.6174460485186901
Validation loss: 2.7876117541344843

Epoch: 6| Step: 5
Training loss: 1.1890437481838987
Validation loss: 2.905549036626106

Epoch: 6| Step: 6
Training loss: 0.9383337763711302
Validation loss: 2.8656305560575013

Epoch: 6| Step: 7
Training loss: 1.2718420975761857
Validation loss: 2.769513021175079

Epoch: 6| Step: 8
Training loss: 1.3892657462753872
Validation loss: 2.762682842227843

Epoch: 6| Step: 9
Training loss: 1.1429511089097788
Validation loss: 2.8492910038641064

Epoch: 6| Step: 10
Training loss: 1.3985639120751892
Validation loss: 2.864778135207296

Epoch: 6| Step: 11
Training loss: 2.1175372408459854
Validation loss: 2.857933069977267

Epoch: 6| Step: 12
Training loss: 1.2474280600741772
Validation loss: 2.8763758504700876

Epoch: 6| Step: 13
Training loss: 1.1715203320720695
Validation loss: 2.8351270289950556

Epoch: 127| Step: 0
Training loss: 1.865838493259389
Validation loss: 2.8864059450830175

Epoch: 6| Step: 1
Training loss: 1.0051037366667617
Validation loss: 2.9056070088178068

Epoch: 6| Step: 2
Training loss: 1.4604144460504314
Validation loss: 2.9308602253541793

Epoch: 6| Step: 3
Training loss: 1.1295186002262827
Validation loss: 2.9559246026628285

Epoch: 6| Step: 4
Training loss: 1.0313381966531903
Validation loss: 2.775450685921898

Epoch: 6| Step: 5
Training loss: 0.862613886072977
Validation loss: 2.790647111771636

Epoch: 6| Step: 6
Training loss: 1.229423442248826
Validation loss: 2.893533937257729

Epoch: 6| Step: 7
Training loss: 1.0193413451607374
Validation loss: 2.846129878294146

Epoch: 6| Step: 8
Training loss: 1.0060231492126357
Validation loss: 2.8733895670336427

Epoch: 6| Step: 9
Training loss: 0.8122145811690697
Validation loss: 2.8765219930586823

Epoch: 6| Step: 10
Training loss: 1.5186807561717044
Validation loss: 2.910108035923488

Epoch: 6| Step: 11
Training loss: 0.8822097070691352
Validation loss: 2.861109959397398

Epoch: 6| Step: 12
Training loss: 1.2013069387034991
Validation loss: 2.866417763313384

Epoch: 6| Step: 13
Training loss: 1.4062815768617305
Validation loss: 2.843796446703885

Epoch: 128| Step: 0
Training loss: 1.079421162636981
Validation loss: 2.8163679863688897

Epoch: 6| Step: 1
Training loss: 1.2759497265553432
Validation loss: 2.8127682805146397

Epoch: 6| Step: 2
Training loss: 1.21330119139329
Validation loss: 2.8252646029735495

Epoch: 6| Step: 3
Training loss: 0.9842057763828408
Validation loss: 2.8787964343137022

Epoch: 6| Step: 4
Training loss: 1.3431964000044765
Validation loss: 2.7905535162996893

Epoch: 6| Step: 5
Training loss: 0.951006113135007
Validation loss: 2.8739483471694967

Epoch: 6| Step: 6
Training loss: 1.1382204603772983
Validation loss: 2.868195539316269

Epoch: 6| Step: 7
Training loss: 0.6244864976933571
Validation loss: 2.827824747013593

Epoch: 6| Step: 8
Training loss: 1.7966349565801647
Validation loss: 2.8872248954785857

Epoch: 6| Step: 9
Training loss: 1.1747143743210824
Validation loss: 2.8480833803358383

Epoch: 6| Step: 10
Training loss: 0.8711005240549038
Validation loss: 2.8986542681499348

Epoch: 6| Step: 11
Training loss: 1.202435134676779
Validation loss: 2.8142160478604046

Epoch: 6| Step: 12
Training loss: 1.3509641877573155
Validation loss: 2.8289301518235805

Epoch: 6| Step: 13
Training loss: 1.041396309418107
Validation loss: 2.8269388651544194

Epoch: 129| Step: 0
Training loss: 1.2869421426265917
Validation loss: 2.8353115963907256

Epoch: 6| Step: 1
Training loss: 1.1275780067610297
Validation loss: 2.962043186705736

Epoch: 6| Step: 2
Training loss: 1.9041065610029018
Validation loss: 2.853386414979648

Epoch: 6| Step: 3
Training loss: 1.4232062511008752
Validation loss: 2.787750320143087

Epoch: 6| Step: 4
Training loss: 0.7227825157586234
Validation loss: 2.7946897241912785

Epoch: 6| Step: 5
Training loss: 1.1711545637041085
Validation loss: 2.8920163491922657

Epoch: 6| Step: 6
Training loss: 1.1138382438525927
Validation loss: 2.811810684503

Epoch: 6| Step: 7
Training loss: 0.7898274481323967
Validation loss: 2.8883280245304204

Epoch: 6| Step: 8
Training loss: 1.02341303905346
Validation loss: 2.9629775025973504

Epoch: 6| Step: 9
Training loss: 0.9250223775682809
Validation loss: 2.8534776640274577

Epoch: 6| Step: 10
Training loss: 1.0535472781666984
Validation loss: 2.86309314229579

Epoch: 6| Step: 11
Training loss: 1.029396472144136
Validation loss: 2.882287726326636

Epoch: 6| Step: 12
Training loss: 1.1185853122990277
Validation loss: 2.8617534924508017

Epoch: 6| Step: 13
Training loss: 1.0599915682259378
Validation loss: 2.9481912401920467

Epoch: 130| Step: 0
Training loss: 1.2758681614011298
Validation loss: 2.851804832717222

Epoch: 6| Step: 1
Training loss: 0.9382394417652262
Validation loss: 2.794410329976625

Epoch: 6| Step: 2
Training loss: 0.9875451162148257
Validation loss: 2.8660058575836755

Epoch: 6| Step: 3
Training loss: 1.6036172479169624
Validation loss: 2.810719852103852

Epoch: 6| Step: 4
Training loss: 1.219802402065781
Validation loss: 2.8059891962580696

Epoch: 6| Step: 5
Training loss: 0.9627921961371025
Validation loss: 2.8502733495473183

Epoch: 6| Step: 6
Training loss: 1.0083442290692104
Validation loss: 2.864779799688792

Epoch: 6| Step: 7
Training loss: 0.991674756302949
Validation loss: 2.9370858326579885

Epoch: 6| Step: 8
Training loss: 0.7840078885401682
Validation loss: 2.821310752537917

Epoch: 6| Step: 9
Training loss: 0.7675147964716296
Validation loss: 2.9013318385270535

Epoch: 6| Step: 10
Training loss: 1.2145088936365052
Validation loss: 3.0020113666140484

Epoch: 6| Step: 11
Training loss: 2.020522208367638
Validation loss: 2.996218616149887

Epoch: 6| Step: 12
Training loss: 0.8249725582876335
Validation loss: 2.8700836965383596

Epoch: 6| Step: 13
Training loss: 0.9683267837955115
Validation loss: 2.7449983570855974

Epoch: 131| Step: 0
Training loss: 1.0016448083821
Validation loss: 2.8881269366096807

Epoch: 6| Step: 1
Training loss: 1.124481664563235
Validation loss: 2.899502115699578

Epoch: 6| Step: 2
Training loss: 1.175511326016893
Validation loss: 2.8849342209111764

Epoch: 6| Step: 3
Training loss: 1.1551977988961826
Validation loss: 2.833134733046324

Epoch: 6| Step: 4
Training loss: 1.165955099455083
Validation loss: 2.9229663979687794

Epoch: 6| Step: 5
Training loss: 0.9710338497331469
Validation loss: 2.8527620205128827

Epoch: 6| Step: 6
Training loss: 0.8972759533538052
Validation loss: 2.8863498725644865

Epoch: 6| Step: 7
Training loss: 0.9614517572631996
Validation loss: 2.9528317179696892

Epoch: 6| Step: 8
Training loss: 0.7330449823417896
Validation loss: 2.8996963988801148

Epoch: 6| Step: 9
Training loss: 1.1605557867970795
Validation loss: 2.9422817877573215

Epoch: 6| Step: 10
Training loss: 1.8903592135660585
Validation loss: 2.876867296052615

Epoch: 6| Step: 11
Training loss: 1.038021225585455
Validation loss: 2.961226731854786

Epoch: 6| Step: 12
Training loss: 1.2564656409420756
Validation loss: 2.831657093807278

Epoch: 6| Step: 13
Training loss: 0.8447896415664227
Validation loss: 2.8801503281963674

Epoch: 132| Step: 0
Training loss: 1.429199468979522
Validation loss: 2.926071852006275

Epoch: 6| Step: 1
Training loss: 1.0573602225090313
Validation loss: 2.838789319541985

Epoch: 6| Step: 2
Training loss: 0.8922111040456928
Validation loss: 3.0129644618892173

Epoch: 6| Step: 3
Training loss: 1.2217009105714263
Validation loss: 2.9053670574245376

Epoch: 6| Step: 4
Training loss: 1.2319257556788408
Validation loss: 2.9020299318269833

Epoch: 6| Step: 5
Training loss: 1.6022072587451306
Validation loss: 2.8986444802082936

Epoch: 6| Step: 6
Training loss: 0.9665382116295765
Validation loss: 2.967632109998884

Epoch: 6| Step: 7
Training loss: 0.9095657463196665
Validation loss: 2.8482411101872254

Epoch: 6| Step: 8
Training loss: 1.1647831267169635
Validation loss: 2.79691274890963

Epoch: 6| Step: 9
Training loss: 1.6685238345612639
Validation loss: 2.9640675744613354

Epoch: 6| Step: 10
Training loss: 1.150112824503148
Validation loss: 2.913278169051492

Epoch: 6| Step: 11
Training loss: 1.1305831018279262
Validation loss: 2.9434099469378756

Epoch: 6| Step: 12
Training loss: 0.8827198958988243
Validation loss: 2.898282159171086

Epoch: 6| Step: 13
Training loss: 1.1658044365025406
Validation loss: 2.893571413927145

Epoch: 133| Step: 0
Training loss: 0.8845794683998786
Validation loss: 2.942491105875657

Epoch: 6| Step: 1
Training loss: 0.9507882913345982
Validation loss: 2.8600906004704774

Epoch: 6| Step: 2
Training loss: 0.6194789214962537
Validation loss: 2.8253211494355317

Epoch: 6| Step: 3
Training loss: 1.728608520080585
Validation loss: 2.8057881270429137

Epoch: 6| Step: 4
Training loss: 1.2766791898513261
Validation loss: 2.8427593755467075

Epoch: 6| Step: 5
Training loss: 1.5264206069706887
Validation loss: 2.9107445585173837

Epoch: 6| Step: 6
Training loss: 0.9882396342445351
Validation loss: 2.8441217200498774

Epoch: 6| Step: 7
Training loss: 1.0181017679710014
Validation loss: 2.851769844773346

Epoch: 6| Step: 8
Training loss: 1.6007974425539924
Validation loss: 2.887708027269522

Epoch: 6| Step: 9
Training loss: 1.0467354411007164
Validation loss: 2.836224137770145

Epoch: 6| Step: 10
Training loss: 0.9255250342851024
Validation loss: 2.8572621417122366

Epoch: 6| Step: 11
Training loss: 1.2162864925010535
Validation loss: 2.8537943288551904

Epoch: 6| Step: 12
Training loss: 1.0054289554288125
Validation loss: 2.777166304573433

Epoch: 6| Step: 13
Training loss: 1.2650357982410216
Validation loss: 2.7977090511898224

Epoch: 134| Step: 0
Training loss: 1.3934181536785635
Validation loss: 2.86558088561935

Epoch: 6| Step: 1
Training loss: 1.3101070933938526
Validation loss: 2.8673053824629253

Epoch: 6| Step: 2
Training loss: 1.1064433731641212
Validation loss: 2.9074081109642944

Epoch: 6| Step: 3
Training loss: 0.8577324862936684
Validation loss: 2.8537527373572718

Epoch: 6| Step: 4
Training loss: 1.2092874421353672
Validation loss: 2.9414356596659785

Epoch: 6| Step: 5
Training loss: 1.4636537321181315
Validation loss: 2.8709983619535566

Epoch: 6| Step: 6
Training loss: 1.1127939328854424
Validation loss: 2.8973609042195143

Epoch: 6| Step: 7
Training loss: 0.9024943436632932
Validation loss: 2.8633442551297605

Epoch: 6| Step: 8
Training loss: 0.9528768873119717
Validation loss: 2.8516726259191225

Epoch: 6| Step: 9
Training loss: 1.710791734033915
Validation loss: 2.8907416861412174

Epoch: 6| Step: 10
Training loss: 1.12041599109573
Validation loss: 2.936780949778137

Epoch: 6| Step: 11
Training loss: 1.4493493692188837
Validation loss: 2.9058377783693654

Epoch: 6| Step: 12
Training loss: 1.1085574401543852
Validation loss: 2.999004496865814

Epoch: 6| Step: 13
Training loss: 0.878247026537806
Validation loss: 2.8340315285774986

Epoch: 135| Step: 0
Training loss: 1.076183118259525
Validation loss: 2.9438809694392125

Epoch: 6| Step: 1
Training loss: 2.148332295009381
Validation loss: 2.9364286863506823

Epoch: 6| Step: 2
Training loss: 1.2455419197455313
Validation loss: 2.9745744956550024

Epoch: 6| Step: 3
Training loss: 1.2348101368031124
Validation loss: 3.0013152524227533

Epoch: 6| Step: 4
Training loss: 1.1675914550510393
Validation loss: 2.7954365958083707

Epoch: 6| Step: 5
Training loss: 0.9918966392651679
Validation loss: 2.829883850463955

Epoch: 6| Step: 6
Training loss: 1.3261295362408074
Validation loss: 2.866752182623879

Epoch: 6| Step: 7
Training loss: 1.2104023889344082
Validation loss: 2.9727623845793802

Epoch: 6| Step: 8
Training loss: 0.9199648642568544
Validation loss: 3.0294397985706967

Epoch: 6| Step: 9
Training loss: 1.0734699760754944
Validation loss: 2.948965220890785

Epoch: 6| Step: 10
Training loss: 1.1004473946809465
Validation loss: 2.8017436297857596

Epoch: 6| Step: 11
Training loss: 1.0937640597938405
Validation loss: 2.938149847020113

Epoch: 6| Step: 12
Training loss: 0.7694846589366793
Validation loss: 2.8480672238859954

Epoch: 6| Step: 13
Training loss: 1.2279978814961057
Validation loss: 2.841210527438152

Epoch: 136| Step: 0
Training loss: 0.7977852204287632
Validation loss: 2.7674356772538413

Epoch: 6| Step: 1
Training loss: 0.676192230323714
Validation loss: 2.799277213448997

Epoch: 6| Step: 2
Training loss: 1.017265286379278
Validation loss: 2.8198746247073108

Epoch: 6| Step: 3
Training loss: 1.085919167343288
Validation loss: 2.824923352239785

Epoch: 6| Step: 4
Training loss: 1.2503232537960551
Validation loss: 2.8527785194934183

Epoch: 6| Step: 5
Training loss: 1.7929606385556578
Validation loss: 2.911700152805263

Epoch: 6| Step: 6
Training loss: 0.7348614157212616
Validation loss: 2.9345250452562794

Epoch: 6| Step: 7
Training loss: 1.0215479172733217
Validation loss: 2.977929122796986

Epoch: 6| Step: 8
Training loss: 1.41005843819256
Validation loss: 2.8599183169173363

Epoch: 6| Step: 9
Training loss: 1.1586135214355229
Validation loss: 2.8823563267373866

Epoch: 6| Step: 10
Training loss: 0.8914375613946124
Validation loss: 2.9457206004872645

Epoch: 6| Step: 11
Training loss: 0.7615147244037397
Validation loss: 2.8381568064500344

Epoch: 6| Step: 12
Training loss: 1.3390337216501942
Validation loss: 2.7766085410321435

Epoch: 6| Step: 13
Training loss: 1.2033157197468047
Validation loss: 2.864786096968369

Epoch: 137| Step: 0
Training loss: 1.0043831965094812
Validation loss: 2.8149320471575767

Epoch: 6| Step: 1
Training loss: 1.3479707654958055
Validation loss: 2.865264968691402

Epoch: 6| Step: 2
Training loss: 1.0123762549616162
Validation loss: 2.8705823931669836

Epoch: 6| Step: 3
Training loss: 0.8514407359570462
Validation loss: 2.8410613656126253

Epoch: 6| Step: 4
Training loss: 0.5677643377928453
Validation loss: 2.8953770522751108

Epoch: 6| Step: 5
Training loss: 0.9341681720359667
Validation loss: 2.7826553822992155

Epoch: 6| Step: 6
Training loss: 1.2542698888450665
Validation loss: 2.887632081835245

Epoch: 6| Step: 7
Training loss: 0.9944311890230733
Validation loss: 2.814733339082337

Epoch: 6| Step: 8
Training loss: 0.7842025658487433
Validation loss: 2.890023919922815

Epoch: 6| Step: 9
Training loss: 1.1118124390917914
Validation loss: 2.841968299615549

Epoch: 6| Step: 10
Training loss: 1.0827371105905739
Validation loss: 2.8724147119302312

Epoch: 6| Step: 11
Training loss: 1.2498642847773267
Validation loss: 2.977824440059903

Epoch: 6| Step: 12
Training loss: 1.225935125569872
Validation loss: 2.9461650474578276

Epoch: 6| Step: 13
Training loss: 1.8452333205611045
Validation loss: 2.949081532231412

Epoch: 138| Step: 0
Training loss: 1.1318263529913968
Validation loss: 2.947101889297083

Epoch: 6| Step: 1
Training loss: 1.0991476115921768
Validation loss: 2.832155562555403

Epoch: 6| Step: 2
Training loss: 0.7893592729610135
Validation loss: 2.927085650206675

Epoch: 6| Step: 3
Training loss: 0.949750084379212
Validation loss: 2.875687268251846

Epoch: 6| Step: 4
Training loss: 0.8714180244415037
Validation loss: 2.904175746215755

Epoch: 6| Step: 5
Training loss: 2.0026625553212503
Validation loss: 2.8891687247466384

Epoch: 6| Step: 6
Training loss: 1.425086283162963
Validation loss: 2.7954316917156277

Epoch: 6| Step: 7
Training loss: 1.1805652106893814
Validation loss: 2.900499335412717

Epoch: 6| Step: 8
Training loss: 1.089772157129205
Validation loss: 2.941824685266127

Epoch: 6| Step: 9
Training loss: 0.9367362408122546
Validation loss: 2.904829395885171

Epoch: 6| Step: 10
Training loss: 0.6268606622792481
Validation loss: 2.850409608261662

Epoch: 6| Step: 11
Training loss: 0.919456672074938
Validation loss: 2.915459673774535

Epoch: 6| Step: 12
Training loss: 0.6937365298638845
Validation loss: 2.9325187870691067

Epoch: 6| Step: 13
Training loss: 1.3031317292183775
Validation loss: 2.9569677550177103

Epoch: 139| Step: 0
Training loss: 1.0172891334587044
Validation loss: 2.9390414096441284

Epoch: 6| Step: 1
Training loss: 1.1758929734996006
Validation loss: 2.759185823700292

Epoch: 6| Step: 2
Training loss: 1.3542412468351113
Validation loss: 2.872120188920211

Epoch: 6| Step: 3
Training loss: 0.5957098788519545
Validation loss: 2.9091489273123425

Epoch: 6| Step: 4
Training loss: 1.2222913008492595
Validation loss: 2.836396193386951

Epoch: 6| Step: 5
Training loss: 0.6814563141336811
Validation loss: 2.9437592016941534

Epoch: 6| Step: 6
Training loss: 0.6978415453512444
Validation loss: 2.9319925624328933

Epoch: 6| Step: 7
Training loss: 0.9028317341615757
Validation loss: 2.934377417463526

Epoch: 6| Step: 8
Training loss: 0.6920590309463325
Validation loss: 2.9003101067974493

Epoch: 6| Step: 9
Training loss: 2.0610042118730965
Validation loss: 2.8930133884470437

Epoch: 6| Step: 10
Training loss: 0.9357284974856622
Validation loss: 2.8360102340296582

Epoch: 6| Step: 11
Training loss: 0.8151734823343537
Validation loss: 2.8222140649575853

Epoch: 6| Step: 12
Training loss: 1.0173755524658772
Validation loss: 2.901863150768584

Epoch: 6| Step: 13
Training loss: 0.9653070858562431
Validation loss: 2.865106393859105

Epoch: 140| Step: 0
Training loss: 1.5457127375830428
Validation loss: 2.9381088545706673

Epoch: 6| Step: 1
Training loss: 1.550480811085527
Validation loss: 2.839270238671366

Epoch: 6| Step: 2
Training loss: 0.966842650283518
Validation loss: 2.823283271398258

Epoch: 6| Step: 3
Training loss: 1.0972380469317136
Validation loss: 2.90293761142362

Epoch: 6| Step: 4
Training loss: 0.7258866971615398
Validation loss: 2.98380022355869

Epoch: 6| Step: 5
Training loss: 0.8756990365225534
Validation loss: 2.933480251671661

Epoch: 6| Step: 6
Training loss: 0.7512795341893863
Validation loss: 2.9500509877297514

Epoch: 6| Step: 7
Training loss: 0.7814890686461661
Validation loss: 2.9345753361325206

Epoch: 6| Step: 8
Training loss: 1.9853427959948484
Validation loss: 2.8470528534133663

Epoch: 6| Step: 9
Training loss: 0.884810490765385
Validation loss: 2.9672603550692043

Epoch: 6| Step: 10
Training loss: 0.8290809296286101
Validation loss: 2.956965457078501

Epoch: 6| Step: 11
Training loss: 1.1789513116090304
Validation loss: 2.9225516802175244

Epoch: 6| Step: 12
Training loss: 0.7751051523798488
Validation loss: 2.8929519222909126

Epoch: 6| Step: 13
Training loss: 1.1137925964669728
Validation loss: 2.892221521980858

Epoch: 141| Step: 0
Training loss: 0.7419934470820448
Validation loss: 2.9136861876912574

Epoch: 6| Step: 1
Training loss: 0.6595465649324841
Validation loss: 2.78021105102391

Epoch: 6| Step: 2
Training loss: 0.9813366578342094
Validation loss: 2.9227568983558307

Epoch: 6| Step: 3
Training loss: 0.8227942572866643
Validation loss: 2.931564313118557

Epoch: 6| Step: 4
Training loss: 0.9907668147579358
Validation loss: 2.9315789385868314

Epoch: 6| Step: 5
Training loss: 1.0933083868863622
Validation loss: 2.983273061395668

Epoch: 6| Step: 6
Training loss: 0.808207322815456
Validation loss: 2.853921021149054

Epoch: 6| Step: 7
Training loss: 1.9680556632094024
Validation loss: 2.831643769514236

Epoch: 6| Step: 8
Training loss: 1.2610055425311868
Validation loss: 2.9051632780673513

Epoch: 6| Step: 9
Training loss: 0.8212250492944946
Validation loss: 2.840336759888047

Epoch: 6| Step: 10
Training loss: 0.8817439406218935
Validation loss: 2.8762528965159144

Epoch: 6| Step: 11
Training loss: 1.1363324954360943
Validation loss: 2.89387907779816

Epoch: 6| Step: 12
Training loss: 1.035037858058702
Validation loss: 2.852985706250753

Epoch: 6| Step: 13
Training loss: 1.1521377120656113
Validation loss: 2.807931269230204

Epoch: 142| Step: 0
Training loss: 1.0041711361312065
Validation loss: 2.923164382374563

Epoch: 6| Step: 1
Training loss: 0.8440798362016487
Validation loss: 2.8140889518323458

Epoch: 6| Step: 2
Training loss: 1.2299260471566185
Validation loss: 2.9512339462797987

Epoch: 6| Step: 3
Training loss: 1.9876816000835111
Validation loss: 2.7587847414236073

Epoch: 6| Step: 4
Training loss: 1.0347933150979056
Validation loss: 2.8498655242871704

Epoch: 6| Step: 5
Training loss: 0.8833081702181104
Validation loss: 2.9143269191361427

Epoch: 6| Step: 6
Training loss: 1.0931417136116903
Validation loss: 2.908060678819716

Epoch: 6| Step: 7
Training loss: 0.8501348164174933
Validation loss: 2.9556650342439523

Epoch: 6| Step: 8
Training loss: 0.8317183860019802
Validation loss: 2.948135264528882

Epoch: 6| Step: 9
Training loss: 0.8167813548178386
Validation loss: 2.8810184620181065

Epoch: 6| Step: 10
Training loss: 1.0835997852908203
Validation loss: 2.8784143380446072

Epoch: 6| Step: 11
Training loss: 1.0792816702247687
Validation loss: 2.9453140784949974

Epoch: 6| Step: 12
Training loss: 1.0543159112840625
Validation loss: 2.818000007429951

Epoch: 6| Step: 13
Training loss: 1.3545355758923545
Validation loss: 2.985459362043286

Epoch: 143| Step: 0
Training loss: 1.8928994613605583
Validation loss: 2.941258859508923

Epoch: 6| Step: 1
Training loss: 1.2827683268107535
Validation loss: 2.863888803151727

Epoch: 6| Step: 2
Training loss: 0.9544898095363769
Validation loss: 2.9126006849837562

Epoch: 6| Step: 3
Training loss: 1.011891118393075
Validation loss: 2.795925568841937

Epoch: 6| Step: 4
Training loss: 0.8202720995445717
Validation loss: 2.8499357974757045

Epoch: 6| Step: 5
Training loss: 0.847211202348287
Validation loss: 2.868920781988127

Epoch: 6| Step: 6
Training loss: 1.0956602581158996
Validation loss: 2.9092832480500843

Epoch: 6| Step: 7
Training loss: 0.9629790166864328
Validation loss: 2.8802690735264798

Epoch: 6| Step: 8
Training loss: 0.8677096470292044
Validation loss: 2.8910009466165536

Epoch: 6| Step: 9
Training loss: 0.7851666502002813
Validation loss: 2.97928435531099

Epoch: 6| Step: 10
Training loss: 0.9857089979412973
Validation loss: 2.845386453470835

Epoch: 6| Step: 11
Training loss: 1.0036387402544982
Validation loss: 2.9308245135201627

Epoch: 6| Step: 12
Training loss: 0.9434600207738774
Validation loss: 2.754257057157124

Epoch: 6| Step: 13
Training loss: 0.8879056540751586
Validation loss: 2.7683108662522873

Epoch: 144| Step: 0
Training loss: 1.891993256103239
Validation loss: 2.843579255731642

Epoch: 6| Step: 1
Training loss: 1.0567928634661043
Validation loss: 2.8250875161267532

Epoch: 6| Step: 2
Training loss: 1.0658369955358353
Validation loss: 2.9059837109931177

Epoch: 6| Step: 3
Training loss: 1.1108677988412394
Validation loss: 2.8464149173118027

Epoch: 6| Step: 4
Training loss: 0.6924353661654501
Validation loss: 2.8465367730081206

Epoch: 6| Step: 5
Training loss: 1.0940708779627417
Validation loss: 2.910470891750926

Epoch: 6| Step: 6
Training loss: 0.8665208058002795
Validation loss: 2.8286145877160154

Epoch: 6| Step: 7
Training loss: 1.0320036475094942
Validation loss: 2.919068237860982

Epoch: 6| Step: 8
Training loss: 1.2370744474423152
Validation loss: 2.8559826041946477

Epoch: 6| Step: 9
Training loss: 0.903544663071071
Validation loss: 2.937054133564785

Epoch: 6| Step: 10
Training loss: 0.4436717676322795
Validation loss: 2.84799689063874

Epoch: 6| Step: 11
Training loss: 0.8423814978302944
Validation loss: 2.8884901531664204

Epoch: 6| Step: 12
Training loss: 0.9734478528986169
Validation loss: 2.8324359473101284

Epoch: 6| Step: 13
Training loss: 0.6356070473010192
Validation loss: 2.9342591419578623

Epoch: 145| Step: 0
Training loss: 1.1028451148442449
Validation loss: 2.868166362314295

Epoch: 6| Step: 1
Training loss: 1.1677750646947027
Validation loss: 2.7924593658814953

Epoch: 6| Step: 2
Training loss: 0.9272897397697436
Validation loss: 2.8901997433838176

Epoch: 6| Step: 3
Training loss: 0.9164842330129961
Validation loss: 2.8684165461600144

Epoch: 6| Step: 4
Training loss: 0.9036057139934952
Validation loss: 2.9100058019608626

Epoch: 6| Step: 5
Training loss: 0.9343765041887813
Validation loss: 2.911029645355839

Epoch: 6| Step: 6
Training loss: 1.1833568877351859
Validation loss: 2.840780265545942

Epoch: 6| Step: 7
Training loss: 1.0235872231957983
Validation loss: 2.8121627322825664

Epoch: 6| Step: 8
Training loss: 0.4867511885412485
Validation loss: 2.909255712394442

Epoch: 6| Step: 9
Training loss: 1.0894441589883779
Validation loss: 2.9046898075591865

Epoch: 6| Step: 10
Training loss: 1.6350039874620257
Validation loss: 2.8273026972770947

Epoch: 6| Step: 11
Training loss: 1.2964924627306393
Validation loss: 2.815863258479017

Epoch: 6| Step: 12
Training loss: 0.8868452813705116
Validation loss: 2.861231064262299

Epoch: 6| Step: 13
Training loss: 1.0728069113483867
Validation loss: 2.9164678278765606

Epoch: 146| Step: 0
Training loss: 0.9691778284240853
Validation loss: 2.934624664768083

Epoch: 6| Step: 1
Training loss: 1.311397952668589
Validation loss: 2.920709020351793

Epoch: 6| Step: 2
Training loss: 1.7730093956024404
Validation loss: 2.9004604412542716

Epoch: 6| Step: 3
Training loss: 0.9151311968460852
Validation loss: 2.8725555850461784

Epoch: 6| Step: 4
Training loss: 1.0169883380697624
Validation loss: 2.7741368231443433

Epoch: 6| Step: 5
Training loss: 1.0563592730096143
Validation loss: 2.7933534583988084

Epoch: 6| Step: 6
Training loss: 0.9556590616706189
Validation loss: 2.8852428884312538

Epoch: 6| Step: 7
Training loss: 0.9894916525416859
Validation loss: 2.874202265151691

Epoch: 6| Step: 8
Training loss: 0.9099348724031742
Validation loss: 2.9050251283505384

Epoch: 6| Step: 9
Training loss: 0.7976321942534481
Validation loss: 2.8100934788460523

Epoch: 6| Step: 10
Training loss: 1.037346534409243
Validation loss: 2.8326277321737128

Epoch: 6| Step: 11
Training loss: 0.6899135878260351
Validation loss: 2.8531013412581

Epoch: 6| Step: 12
Training loss: 1.0605628361914716
Validation loss: 2.8377215025903135

Epoch: 6| Step: 13
Training loss: 0.8458759228236398
Validation loss: 2.74824209091486

Epoch: 147| Step: 0
Training loss: 1.1812980722808029
Validation loss: 2.8623947984889835

Epoch: 6| Step: 1
Training loss: 1.1934099202291792
Validation loss: 2.976053970430759

Epoch: 6| Step: 2
Training loss: 0.8480145800119847
Validation loss: 2.8436058203509167

Epoch: 6| Step: 3
Training loss: 0.7768059408439003
Validation loss: 2.8579710830006846

Epoch: 6| Step: 4
Training loss: 0.6843114954081969
Validation loss: 2.8971855907881707

Epoch: 6| Step: 5
Training loss: 1.0874564436159178
Validation loss: 2.9159455406997403

Epoch: 6| Step: 6
Training loss: 0.8712884659669976
Validation loss: 2.953267654122048

Epoch: 6| Step: 7
Training loss: 0.9185721828669053
Validation loss: 2.9055035907611795

Epoch: 6| Step: 8
Training loss: 0.9080824905181089
Validation loss: 2.9347664579744617

Epoch: 6| Step: 9
Training loss: 0.7930965978227925
Validation loss: 2.8332151266759236

Epoch: 6| Step: 10
Training loss: 1.7103890014467884
Validation loss: 2.8786370450451586

Epoch: 6| Step: 11
Training loss: 1.1939082654924258
Validation loss: 2.843703720219227

Epoch: 6| Step: 12
Training loss: 1.137438254724157
Validation loss: 2.918220206187976

Epoch: 6| Step: 13
Training loss: 1.1027042072641042
Validation loss: 2.8265322842308804

Epoch: 148| Step: 0
Training loss: 1.128401488345144
Validation loss: 2.9869813306557296

Epoch: 6| Step: 1
Training loss: 1.1074611650120683
Validation loss: 2.8472548743962762

Epoch: 6| Step: 2
Training loss: 1.0937930507361733
Validation loss: 2.904593990599871

Epoch: 6| Step: 3
Training loss: 0.5679551617493687
Validation loss: 2.875667964352068

Epoch: 6| Step: 4
Training loss: 1.1508001819304163
Validation loss: 2.8046126501779978

Epoch: 6| Step: 5
Training loss: 0.7714335750803571
Validation loss: 2.873238300210823

Epoch: 6| Step: 6
Training loss: 1.100375191685596
Validation loss: 2.8978842235497875

Epoch: 6| Step: 7
Training loss: 0.6463932998905441
Validation loss: 2.9029170651355956

Epoch: 6| Step: 8
Training loss: 0.4597381084443402
Validation loss: 2.9159554204668465

Epoch: 6| Step: 9
Training loss: 0.8668163295658229
Validation loss: 2.9485956135807387

Epoch: 6| Step: 10
Training loss: 0.9763334387120062
Validation loss: 2.971753284463549

Epoch: 6| Step: 11
Training loss: 1.5977093750718192
Validation loss: 2.838846499439081

Epoch: 6| Step: 12
Training loss: 0.633466876740937
Validation loss: 2.9562092709037495

Epoch: 6| Step: 13
Training loss: 1.1927386728395335
Validation loss: 2.9107140332956565

Epoch: 149| Step: 0
Training loss: 1.2444344597275885
Validation loss: 2.8678323850302223

Epoch: 6| Step: 1
Training loss: 0.8665776213115214
Validation loss: 2.794104470132359

Epoch: 6| Step: 2
Training loss: 0.8245206162585852
Validation loss: 2.9623447989198315

Epoch: 6| Step: 3
Training loss: 0.663716933150548
Validation loss: 2.8544437570951784

Epoch: 6| Step: 4
Training loss: 1.0226065487364515
Validation loss: 2.9469751577660293

Epoch: 6| Step: 5
Training loss: 1.1970921650574136
Validation loss: 2.9339250495176827

Epoch: 6| Step: 6
Training loss: 0.7802953991526621
Validation loss: 2.8352682061233807

Epoch: 6| Step: 7
Training loss: 0.8484861468846019
Validation loss: 2.8411727796769157

Epoch: 6| Step: 8
Training loss: 1.5585651442883222
Validation loss: 2.8205356808994217

Epoch: 6| Step: 9
Training loss: 0.905622725605659
Validation loss: 2.9322097839161363

Epoch: 6| Step: 10
Training loss: 1.0686758852240008
Validation loss: 2.8889096024475722

Epoch: 6| Step: 11
Training loss: 0.8999010852922902
Validation loss: 2.8791438383825056

Epoch: 6| Step: 12
Training loss: 0.8270822473770302
Validation loss: 2.8324227880159816

Epoch: 6| Step: 13
Training loss: 0.7686736464380665
Validation loss: 2.911448829558027

Epoch: 150| Step: 0
Training loss: 0.6716847704899994
Validation loss: 2.8837280335876017

Epoch: 6| Step: 1
Training loss: 0.9614790344213944
Validation loss: 2.9030761068584336

Epoch: 6| Step: 2
Training loss: 0.8994854330269058
Validation loss: 2.836280332638201

Epoch: 6| Step: 3
Training loss: 1.0675239713956752
Validation loss: 3.0116823608997194

Epoch: 6| Step: 4
Training loss: 0.6506578509330887
Validation loss: 2.850533426011746

Epoch: 6| Step: 5
Training loss: 0.9827122647792665
Validation loss: 2.874674737194719

Epoch: 6| Step: 6
Training loss: 0.9620091734982127
Validation loss: 2.967433061795494

Epoch: 6| Step: 7
Training loss: 1.2621777529244511
Validation loss: 3.0077552690882325

Epoch: 6| Step: 8
Training loss: 1.3875504269758334
Validation loss: 2.8596742539419853

Epoch: 6| Step: 9
Training loss: 0.7669875418510432
Validation loss: 2.9305191961828134

Epoch: 6| Step: 10
Training loss: 1.7150517991364906
Validation loss: 2.913484981468697

Epoch: 6| Step: 11
Training loss: 0.8526938036896947
Validation loss: 2.8431001416725032

Epoch: 6| Step: 12
Training loss: 1.372742012657892
Validation loss: 2.8391936833654716

Epoch: 6| Step: 13
Training loss: 1.1038830170882938
Validation loss: 2.8259140139549483

Epoch: 151| Step: 0
Training loss: 0.7609901269029141
Validation loss: 2.824420153206349

Epoch: 6| Step: 1
Training loss: 0.8211762739790812
Validation loss: 2.8798271648989178

Epoch: 6| Step: 2
Training loss: 0.7073672850181874
Validation loss: 2.9599489895403175

Epoch: 6| Step: 3
Training loss: 0.9068119017130846
Validation loss: 2.8340599493408614

Epoch: 6| Step: 4
Training loss: 0.8124926640106019
Validation loss: 2.8505847944410037

Epoch: 6| Step: 5
Training loss: 1.3483543909658098
Validation loss: 2.8964541933764116

Epoch: 6| Step: 6
Training loss: 0.5855074512323548
Validation loss: 2.8395020193173512

Epoch: 6| Step: 7
Training loss: 1.212149425832081
Validation loss: 2.9096593103964423

Epoch: 6| Step: 8
Training loss: 1.0517586059000605
Validation loss: 2.8710069431321514

Epoch: 6| Step: 9
Training loss: 1.0012763937377602
Validation loss: 2.7757351809299644

Epoch: 6| Step: 10
Training loss: 0.5285903325253709
Validation loss: 2.865872766841486

Epoch: 6| Step: 11
Training loss: 1.6797784825013857
Validation loss: 2.942926885990477

Epoch: 6| Step: 12
Training loss: 1.1257957187546108
Validation loss: 2.9400356252073205

Epoch: 6| Step: 13
Training loss: 1.185113265101049
Validation loss: 2.8685804512267947

Epoch: 152| Step: 0
Training loss: 0.945111403080014
Validation loss: 2.8542721907513813

Epoch: 6| Step: 1
Training loss: 0.7764027329470976
Validation loss: 2.8282479528181823

Epoch: 6| Step: 2
Training loss: 1.1220348276182999
Validation loss: 2.9472207145395437

Epoch: 6| Step: 3
Training loss: 0.8500031358997616
Validation loss: 2.864171644740532

Epoch: 6| Step: 4
Training loss: 0.7861080947686307
Validation loss: 2.7790777888996874

Epoch: 6| Step: 5
Training loss: 1.6571622531441663
Validation loss: 2.8086314262936756

Epoch: 6| Step: 6
Training loss: 0.8829997041427445
Validation loss: 2.8448657826663286

Epoch: 6| Step: 7
Training loss: 0.6701580109665393
Validation loss: 2.8799010947030825

Epoch: 6| Step: 8
Training loss: 0.7711173814362272
Validation loss: 2.9753120979923424

Epoch: 6| Step: 9
Training loss: 1.2181530982388467
Validation loss: 2.898144977131351

Epoch: 6| Step: 10
Training loss: 1.297840999563157
Validation loss: 2.899550670584711

Epoch: 6| Step: 11
Training loss: 0.6213398571770206
Validation loss: 2.908809300654104

Epoch: 6| Step: 12
Training loss: 0.8157457664209203
Validation loss: 2.8449279944319867

Epoch: 6| Step: 13
Training loss: 1.1224352954320533
Validation loss: 2.944491122633536

Epoch: 153| Step: 0
Training loss: 0.6846035284018855
Validation loss: 2.8831609362034367

Epoch: 6| Step: 1
Training loss: 0.6486001098071043
Validation loss: 2.8584167945584276

Epoch: 6| Step: 2
Training loss: 1.5669657404841997
Validation loss: 2.9350385160155548

Epoch: 6| Step: 3
Training loss: 1.3520649323389322
Validation loss: 2.819385323324819

Epoch: 6| Step: 4
Training loss: 0.6791402652695204
Validation loss: 2.990806812166309

Epoch: 6| Step: 5
Training loss: 0.7549725043740598
Validation loss: 2.952711005685506

Epoch: 6| Step: 6
Training loss: 0.7388480296665056
Validation loss: 2.8511077239514546

Epoch: 6| Step: 7
Training loss: 0.9651079935710618
Validation loss: 2.9367832973375707

Epoch: 6| Step: 8
Training loss: 0.9178949204643978
Validation loss: 2.884654420686346

Epoch: 6| Step: 9
Training loss: 0.8213377222621476
Validation loss: 2.8574454810035936

Epoch: 6| Step: 10
Training loss: 0.7240126792946087
Validation loss: 3.022898268605319

Epoch: 6| Step: 11
Training loss: 1.1267624930160414
Validation loss: 2.9705172983704045

Epoch: 6| Step: 12
Training loss: 0.7911410762065402
Validation loss: 2.9543233791334123

Epoch: 6| Step: 13
Training loss: 0.9261611931424982
Validation loss: 3.0125694145552284

Epoch: 154| Step: 0
Training loss: 0.7395783992835571
Validation loss: 2.819120005297467

Epoch: 6| Step: 1
Training loss: 0.7065885643789218
Validation loss: 2.869502561283691

Epoch: 6| Step: 2
Training loss: 1.0069371051447782
Validation loss: 2.856333701189314

Epoch: 6| Step: 3
Training loss: 0.7401759142173073
Validation loss: 2.8901600712969544

Epoch: 6| Step: 4
Training loss: 0.9580523590401275
Validation loss: 2.8921020583122883

Epoch: 6| Step: 5
Training loss: 0.7781965858591442
Validation loss: 2.8409918240146776

Epoch: 6| Step: 6
Training loss: 0.7542012877622994
Validation loss: 2.8841937580248924

Epoch: 6| Step: 7
Training loss: 0.9127355219357001
Validation loss: 2.9211971700296036

Epoch: 6| Step: 8
Training loss: 1.1630071682204777
Validation loss: 2.947862029271348

Epoch: 6| Step: 9
Training loss: 1.1231253157048957
Validation loss: 2.841916509777753

Epoch: 6| Step: 10
Training loss: 0.7995942040268184
Validation loss: 2.8665915137427564

Epoch: 6| Step: 11
Training loss: 1.049896662032052
Validation loss: 2.8108187842838404

Epoch: 6| Step: 12
Training loss: 0.9168191407291031
Validation loss: 2.9262223295337244

Epoch: 6| Step: 13
Training loss: 1.681516423440403
Validation loss: 2.8832426637568167

Epoch: 155| Step: 0
Training loss: 0.8633628564988255
Validation loss: 2.8434200933896068

Epoch: 6| Step: 1
Training loss: 1.2015717127810164
Validation loss: 2.952505325885376

Epoch: 6| Step: 2
Training loss: 1.1714890416667065
Validation loss: 2.9399021147956743

Epoch: 6| Step: 3
Training loss: 0.7315366965480637
Validation loss: 2.8047821255645133

Epoch: 6| Step: 4
Training loss: 0.8243165523120836
Validation loss: 2.81912953372518

Epoch: 6| Step: 5
Training loss: 1.0694138589974398
Validation loss: 3.004137484179026

Epoch: 6| Step: 6
Training loss: 0.7272162009076454
Validation loss: 2.8713101744445964

Epoch: 6| Step: 7
Training loss: 0.8185415133538171
Validation loss: 2.804644861490485

Epoch: 6| Step: 8
Training loss: 0.7034782793722152
Validation loss: 2.857675335573003

Epoch: 6| Step: 9
Training loss: 1.1544122267143666
Validation loss: 2.9675677170561965

Epoch: 6| Step: 10
Training loss: 0.9233894839123624
Validation loss: 2.961971159570285

Epoch: 6| Step: 11
Training loss: 0.7259413412241273
Validation loss: 2.957651359681293

Epoch: 6| Step: 12
Training loss: 1.5081489464336426
Validation loss: 2.83195593021249

Epoch: 6| Step: 13
Training loss: 0.5906247406408962
Validation loss: 2.9381617348587175

Epoch: 156| Step: 0
Training loss: 1.0559474624656042
Validation loss: 2.884354879158241

Epoch: 6| Step: 1
Training loss: 1.5502923535923976
Validation loss: 2.892213539570995

Epoch: 6| Step: 2
Training loss: 0.6042879958385077
Validation loss: 2.8871977412569336

Epoch: 6| Step: 3
Training loss: 0.6198325157060981
Validation loss: 2.9551344532292947

Epoch: 6| Step: 4
Training loss: 0.6650588470966665
Validation loss: 2.864980695503001

Epoch: 6| Step: 5
Training loss: 0.8006433135535604
Validation loss: 2.9159920775171146

Epoch: 6| Step: 6
Training loss: 0.860517609211598
Validation loss: 2.868288291394266

Epoch: 6| Step: 7
Training loss: 0.7878115718825494
Validation loss: 2.882298686509889

Epoch: 6| Step: 8
Training loss: 1.0726620023146698
Validation loss: 2.932220449085317

Epoch: 6| Step: 9
Training loss: 1.1767232676140604
Validation loss: 2.870211788010293

Epoch: 6| Step: 10
Training loss: 0.9301560767782528
Validation loss: 2.9689982795628973

Epoch: 6| Step: 11
Training loss: 1.0206391026491417
Validation loss: 3.0239209454772547

Epoch: 6| Step: 12
Training loss: 1.1198089893982464
Validation loss: 2.908897684170772

Epoch: 6| Step: 13
Training loss: 1.0732953906214144
Validation loss: 2.9686321569778897

Epoch: 157| Step: 0
Training loss: 0.6773060701266914
Validation loss: 2.924430667863428

Epoch: 6| Step: 1
Training loss: 0.8064334778900115
Validation loss: 2.87899556532555

Epoch: 6| Step: 2
Training loss: 0.8551813975532325
Validation loss: 2.9207357949927997

Epoch: 6| Step: 3
Training loss: 0.6485553312674672
Validation loss: 2.908899569292264

Epoch: 6| Step: 4
Training loss: 1.6327886260263096
Validation loss: 2.951856835362108

Epoch: 6| Step: 5
Training loss: 0.8439268350730355
Validation loss: 2.832871516307848

Epoch: 6| Step: 6
Training loss: 1.0634805978745752
Validation loss: 2.8194313821557877

Epoch: 6| Step: 7
Training loss: 0.9211633812855146
Validation loss: 2.9730686965988258

Epoch: 6| Step: 8
Training loss: 0.9368582118224417
Validation loss: 2.9826823389167108

Epoch: 6| Step: 9
Training loss: 0.9426268266600213
Validation loss: 2.990941012968366

Epoch: 6| Step: 10
Training loss: 0.8257293598252943
Validation loss: 2.933136451861947

Epoch: 6| Step: 11
Training loss: 1.1453952587667005
Validation loss: 2.9453995453158877

Epoch: 6| Step: 12
Training loss: 0.6991179622703103
Validation loss: 2.8535757822200987

Epoch: 6| Step: 13
Training loss: 1.0745556112448136
Validation loss: 2.844993668690516

Epoch: 158| Step: 0
Training loss: 2.0744565550842187
Validation loss: 2.908414847935845

Epoch: 6| Step: 1
Training loss: 0.7764632255605466
Validation loss: 2.8420372720350797

Epoch: 6| Step: 2
Training loss: 0.6317276309075768
Validation loss: 2.867077866068445

Epoch: 6| Step: 3
Training loss: 0.5950495401963884
Validation loss: 2.881595771767633

Epoch: 6| Step: 4
Training loss: 0.9615435046283812
Validation loss: 3.0555431601725687

Epoch: 6| Step: 5
Training loss: 0.729530261985386
Validation loss: 2.9145009765187075

Epoch: 6| Step: 6
Training loss: 0.8715041010875582
Validation loss: 2.9118786521507167

Epoch: 6| Step: 7
Training loss: 0.9001374126543145
Validation loss: 2.8363858823924586

Epoch: 6| Step: 8
Training loss: 0.6903234073576751
Validation loss: 2.8641888895986405

Epoch: 6| Step: 9
Training loss: 0.622705108755047
Validation loss: 2.918103835840115

Epoch: 6| Step: 10
Training loss: 0.6448323326865555
Validation loss: 2.9038581713484297

Epoch: 6| Step: 11
Training loss: 0.9962929021674962
Validation loss: 2.931439864917131

Epoch: 6| Step: 12
Training loss: 1.1642095485718367
Validation loss: 2.900938245663706

Epoch: 6| Step: 13
Training loss: 0.9164149343301883
Validation loss: 2.8715347885503424

Epoch: 159| Step: 0
Training loss: 0.8836411494620676
Validation loss: 2.8280637955760732

Epoch: 6| Step: 1
Training loss: 0.6283729851308907
Validation loss: 2.9515936377817993

Epoch: 6| Step: 2
Training loss: 0.9291573944541491
Validation loss: 2.925377268248574

Epoch: 6| Step: 3
Training loss: 0.7883456533718037
Validation loss: 2.7996362307941345

Epoch: 6| Step: 4
Training loss: 0.7646977395329688
Validation loss: 2.9778462042308775

Epoch: 6| Step: 5
Training loss: 1.5831045018859626
Validation loss: 2.929869704620577

Epoch: 6| Step: 6
Training loss: 0.8213616337957841
Validation loss: 2.794084367932802

Epoch: 6| Step: 7
Training loss: 0.8313627826215686
Validation loss: 2.8707641412362936

Epoch: 6| Step: 8
Training loss: 0.7081257899415474
Validation loss: 2.9155069270729057

Epoch: 6| Step: 9
Training loss: 0.6578044646218606
Validation loss: 2.912274436784193

Epoch: 6| Step: 10
Training loss: 0.8647990972471863
Validation loss: 2.9966136575776265

Epoch: 6| Step: 11
Training loss: 0.8862373625011664
Validation loss: 2.9126013944164333

Epoch: 6| Step: 12
Training loss: 0.6300570934401601
Validation loss: 2.9773836646853264

Epoch: 6| Step: 13
Training loss: 1.365625153635396
Validation loss: 2.8705933495932054

Epoch: 160| Step: 0
Training loss: 0.9274628894507254
Validation loss: 2.8584424775604584

Epoch: 6| Step: 1
Training loss: 0.7380736528410478
Validation loss: 2.879161518016873

Epoch: 6| Step: 2
Training loss: 0.6326989201471536
Validation loss: 2.7411459079408766

Epoch: 6| Step: 3
Training loss: 0.6841142689026883
Validation loss: 2.7983588574873512

Epoch: 6| Step: 4
Training loss: 0.8115214544058577
Validation loss: 2.919980147002502

Epoch: 6| Step: 5
Training loss: 0.9892879379821936
Validation loss: 2.9874957612671302

Epoch: 6| Step: 6
Training loss: 0.8561737778422586
Validation loss: 2.9538169467317026

Epoch: 6| Step: 7
Training loss: 0.5102175758971201
Validation loss: 2.8834859859063604

Epoch: 6| Step: 8
Training loss: 0.5754004535237031
Validation loss: 3.067723717297428

Epoch: 6| Step: 9
Training loss: 1.0363310283644662
Validation loss: 2.9570539600435866

Epoch: 6| Step: 10
Training loss: 1.6359145344139652
Validation loss: 2.9166429495982507

Epoch: 6| Step: 11
Training loss: 1.402579710084118
Validation loss: 2.957443000349519

Epoch: 6| Step: 12
Training loss: 0.6945506218696322
Validation loss: 2.899369986929222

Epoch: 6| Step: 13
Training loss: 1.0658122214243866
Validation loss: 2.897488914382964

Epoch: 161| Step: 0
Training loss: 0.4856120279904251
Validation loss: 2.986201474697812

Epoch: 6| Step: 1
Training loss: 0.828966253267892
Validation loss: 2.935311374621448

Epoch: 6| Step: 2
Training loss: 0.5947800284971257
Validation loss: 2.8820663630627625

Epoch: 6| Step: 3
Training loss: 1.6928041949393247
Validation loss: 2.9648700456621695

Epoch: 6| Step: 4
Training loss: 1.0124039262943405
Validation loss: 2.9354920660280004

Epoch: 6| Step: 5
Training loss: 1.0213530767896337
Validation loss: 2.8654840382690723

Epoch: 6| Step: 6
Training loss: 0.9143900488177642
Validation loss: 2.9328247498202415

Epoch: 6| Step: 7
Training loss: 0.9001068859738385
Validation loss: 2.9225538148648775

Epoch: 6| Step: 8
Training loss: 1.0176495839982285
Validation loss: 2.8818622597819754

Epoch: 6| Step: 9
Training loss: 0.7054914916503465
Validation loss: 2.905942264794602

Epoch: 6| Step: 10
Training loss: 0.6992910550203141
Validation loss: 2.867186848625643

Epoch: 6| Step: 11
Training loss: 0.8194557075121567
Validation loss: 2.8057350178930127

Epoch: 6| Step: 12
Training loss: 0.9191121873132446
Validation loss: 2.964783840051615

Epoch: 6| Step: 13
Training loss: 0.5173838988739509
Validation loss: 2.8890502489296823

Epoch: 162| Step: 0
Training loss: 0.616330142816332
Validation loss: 2.9863449971080227

Epoch: 6| Step: 1
Training loss: 1.0186718354926199
Validation loss: 2.951872087205684

Epoch: 6| Step: 2
Training loss: 0.7500531654587623
Validation loss: 2.971545191828189

Epoch: 6| Step: 3
Training loss: 0.7767930883925123
Validation loss: 2.9435955004363987

Epoch: 6| Step: 4
Training loss: 0.944286988182066
Validation loss: 2.8549333828059114

Epoch: 6| Step: 5
Training loss: 0.9568316504527832
Validation loss: 2.8832695658105987

Epoch: 6| Step: 6
Training loss: 0.686779316389253
Validation loss: 2.8413499618379636

Epoch: 6| Step: 7
Training loss: 1.4453510176191424
Validation loss: 2.93761938948185

Epoch: 6| Step: 8
Training loss: 0.5274056292362564
Validation loss: 2.920688435819131

Epoch: 6| Step: 9
Training loss: 0.7720331485603735
Validation loss: 2.84124177140805

Epoch: 6| Step: 10
Training loss: 0.5794538227440721
Validation loss: 2.971273761611994

Epoch: 6| Step: 11
Training loss: 1.096431279434261
Validation loss: 2.9081677634721936

Epoch: 6| Step: 12
Training loss: 0.9965866963465652
Validation loss: 2.9119666013592678

Epoch: 6| Step: 13
Training loss: 1.0304680952253713
Validation loss: 2.9598947935266438

Epoch: 163| Step: 0
Training loss: 0.7881187233610646
Validation loss: 2.8997056077195187

Epoch: 6| Step: 1
Training loss: 0.6658724186215099
Validation loss: 2.9333018476429213

Epoch: 6| Step: 2
Training loss: 0.8107487806228092
Validation loss: 2.8270415027272042

Epoch: 6| Step: 3
Training loss: 0.9672719693620937
Validation loss: 2.8869192477926986

Epoch: 6| Step: 4
Training loss: 0.8322141920816271
Validation loss: 2.897609863293935

Epoch: 6| Step: 5
Training loss: 0.7453135460420381
Validation loss: 2.8760509090604365

Epoch: 6| Step: 6
Training loss: 1.0577759909703774
Validation loss: 2.9456009997555586

Epoch: 6| Step: 7
Training loss: 0.6397891756102614
Validation loss: 3.0051583473812973

Epoch: 6| Step: 8
Training loss: 0.7833445889766779
Validation loss: 2.9412540229221884

Epoch: 6| Step: 9
Training loss: 1.4730863474329698
Validation loss: 2.8677272167385457

Epoch: 6| Step: 10
Training loss: 0.8451851542617369
Validation loss: 2.8400252825099668

Epoch: 6| Step: 11
Training loss: 0.6807200163907529
Validation loss: 2.887712733371319

Epoch: 6| Step: 12
Training loss: 0.6808453924479945
Validation loss: 2.9397709840447934

Epoch: 6| Step: 13
Training loss: 0.9040627887196612
Validation loss: 2.9006810309421858

Epoch: 164| Step: 0
Training loss: 0.8865429203962674
Validation loss: 2.910117798962981

Epoch: 6| Step: 1
Training loss: 1.0924907519824203
Validation loss: 2.9265522503338155

Epoch: 6| Step: 2
Training loss: 0.8368012787396123
Validation loss: 2.917327715121525

Epoch: 6| Step: 3
Training loss: 0.683144819804516
Validation loss: 2.951230391690773

Epoch: 6| Step: 4
Training loss: 0.7954545169681693
Validation loss: 2.911447451075835

Epoch: 6| Step: 5
Training loss: 0.6738847570532001
Validation loss: 2.9454141560490426

Epoch: 6| Step: 6
Training loss: 0.6611663043555897
Validation loss: 2.895799929382722

Epoch: 6| Step: 7
Training loss: 0.3756839158225606
Validation loss: 2.866575503193494

Epoch: 6| Step: 8
Training loss: 0.9289424379067754
Validation loss: 2.980254545967947

Epoch: 6| Step: 9
Training loss: 1.5955934521865665
Validation loss: 2.9861187326102367

Epoch: 6| Step: 10
Training loss: 0.7687620782291009
Validation loss: 2.9452731722660674

Epoch: 6| Step: 11
Training loss: 0.7720017641818193
Validation loss: 2.9398769068953783

Epoch: 6| Step: 12
Training loss: 0.9577553014805181
Validation loss: 2.837126329439529

Epoch: 6| Step: 13
Training loss: 1.024721461341442
Validation loss: 2.960292467433227

Epoch: 165| Step: 0
Training loss: 0.5196615643661673
Validation loss: 2.937706500431278

Epoch: 6| Step: 1
Training loss: 0.5914256628118328
Validation loss: 2.8841928762769546

Epoch: 6| Step: 2
Training loss: 1.1857403718258674
Validation loss: 2.8768550720563333

Epoch: 6| Step: 3
Training loss: 0.5546325602657738
Validation loss: 2.880908354434446

Epoch: 6| Step: 4
Training loss: 0.7972539860699621
Validation loss: 2.9625256522526047

Epoch: 6| Step: 5
Training loss: 0.5323163158086941
Validation loss: 2.909485031653207

Epoch: 6| Step: 6
Training loss: 1.0120076242091853
Validation loss: 2.9338623817871046

Epoch: 6| Step: 7
Training loss: 0.8499542939295363
Validation loss: 2.9947706448466787

Epoch: 6| Step: 8
Training loss: 0.7578305507751729
Validation loss: 2.913322934416566

Epoch: 6| Step: 9
Training loss: 1.5331734235279937
Validation loss: 2.913489877792659

Epoch: 6| Step: 10
Training loss: 0.4378246567350083
Validation loss: 2.9311419593838486

Epoch: 6| Step: 11
Training loss: 1.1497106955309557
Validation loss: 2.857710431978748

Epoch: 6| Step: 12
Training loss: 0.7335851764279517
Validation loss: 2.921141765343032

Epoch: 6| Step: 13
Training loss: 0.7444748816111767
Validation loss: 2.9551734345860434

Epoch: 166| Step: 0
Training loss: 0.8164934905680974
Validation loss: 2.906453716835955

Epoch: 6| Step: 1
Training loss: 0.719546250177648
Validation loss: 2.9605183971589133

Epoch: 6| Step: 2
Training loss: 0.9582078823962108
Validation loss: 2.9323416051231566

Epoch: 6| Step: 3
Training loss: 0.7611685306194089
Validation loss: 2.931731627371513

Epoch: 6| Step: 4
Training loss: 0.923152846146883
Validation loss: 2.894400212268635

Epoch: 6| Step: 5
Training loss: 0.8088383327751206
Validation loss: 2.984412720659884

Epoch: 6| Step: 6
Training loss: 1.178946003076159
Validation loss: 3.0821235878202122

Epoch: 6| Step: 7
Training loss: 0.9487544364473657
Validation loss: 2.893345942345259

Epoch: 6| Step: 8
Training loss: 1.0326009051729588
Validation loss: 3.023530273591266

Epoch: 6| Step: 9
Training loss: 0.6030189420910166
Validation loss: 2.924269329275346

Epoch: 6| Step: 10
Training loss: 1.462622420575135
Validation loss: 2.846289943146186

Epoch: 6| Step: 11
Training loss: 0.9499951550711514
Validation loss: 2.88572244137174

Epoch: 6| Step: 12
Training loss: 0.6884971669678311
Validation loss: 2.9321988341213965

Epoch: 6| Step: 13
Training loss: 0.6739357682646017
Validation loss: 2.8174787534777477

Epoch: 167| Step: 0
Training loss: 0.8825656579531617
Validation loss: 2.856176244338531

Epoch: 6| Step: 1
Training loss: 0.7824326909156123
Validation loss: 2.9119778592120333

Epoch: 6| Step: 2
Training loss: 0.7460118593342019
Validation loss: 2.9777737720266444

Epoch: 6| Step: 3
Training loss: 0.7800127532112018
Validation loss: 2.931795194525432

Epoch: 6| Step: 4
Training loss: 0.8902706980775048
Validation loss: 2.8902595082755114

Epoch: 6| Step: 5
Training loss: 0.698760580484336
Validation loss: 2.9043737665125477

Epoch: 6| Step: 6
Training loss: 0.6865987722810347
Validation loss: 2.8910252062088944

Epoch: 6| Step: 7
Training loss: 0.7930327892283268
Validation loss: 2.956299180958486

Epoch: 6| Step: 8
Training loss: 1.5566490489009048
Validation loss: 2.9027329222900904

Epoch: 6| Step: 9
Training loss: 0.8080612862024862
Validation loss: 3.007620127417382

Epoch: 6| Step: 10
Training loss: 0.8224890036268182
Validation loss: 2.816902698882573

Epoch: 6| Step: 11
Training loss: 0.7004084774705776
Validation loss: 2.857593335674029

Epoch: 6| Step: 12
Training loss: 1.0976423486664213
Validation loss: 2.8937499055251346

Epoch: 6| Step: 13
Training loss: 0.746028238186485
Validation loss: 2.9010114731007834

Epoch: 168| Step: 0
Training loss: 0.8978735439156493
Validation loss: 2.968551281083904

Epoch: 6| Step: 1
Training loss: 0.6905846320735
Validation loss: 2.875494776182029

Epoch: 6| Step: 2
Training loss: 0.8631724983863422
Validation loss: 2.8995209868311242

Epoch: 6| Step: 3
Training loss: 0.7981788589598844
Validation loss: 2.9319195327732492

Epoch: 6| Step: 4
Training loss: 0.7939399071541089
Validation loss: 2.913674827335865

Epoch: 6| Step: 5
Training loss: 0.5275102423175243
Validation loss: 2.9354208899946586

Epoch: 6| Step: 6
Training loss: 0.7031346214483852
Validation loss: 2.835219160026535

Epoch: 6| Step: 7
Training loss: 1.5374938406471996
Validation loss: 2.9841642455135844

Epoch: 6| Step: 8
Training loss: 1.0814948008813987
Validation loss: 2.990149153133064

Epoch: 6| Step: 9
Training loss: 0.9752781471233151
Validation loss: 2.978370871439853

Epoch: 6| Step: 10
Training loss: 1.1767734637347396
Validation loss: 2.9399287551888986

Epoch: 6| Step: 11
Training loss: 0.5765429061827068
Validation loss: 2.824547375228188

Epoch: 6| Step: 12
Training loss: 1.0357588255752785
Validation loss: 2.8220069001084394

Epoch: 6| Step: 13
Training loss: 0.6450850448431286
Validation loss: 2.905035756537267

Epoch: 169| Step: 0
Training loss: 1.1777386261972402
Validation loss: 2.8814898371087274

Epoch: 6| Step: 1
Training loss: 0.7229364625124092
Validation loss: 2.8631953304179505

Epoch: 6| Step: 2
Training loss: 1.5398531204627528
Validation loss: 2.954005155645377

Epoch: 6| Step: 3
Training loss: 0.769316977475257
Validation loss: 2.9112474550547542

Epoch: 6| Step: 4
Training loss: 0.8822357521819953
Validation loss: 2.9228281924469774

Epoch: 6| Step: 5
Training loss: 0.8653560923089851
Validation loss: 2.8439237101391797

Epoch: 6| Step: 6
Training loss: 0.7587345059492391
Validation loss: 3.010951055243161

Epoch: 6| Step: 7
Training loss: 0.7099952322168511
Validation loss: 2.812597922986964

Epoch: 6| Step: 8
Training loss: 0.9511126552687595
Validation loss: 2.9740361316523813

Epoch: 6| Step: 9
Training loss: 0.8430278301306104
Validation loss: 2.854137912429054

Epoch: 6| Step: 10
Training loss: 0.7671093079290798
Validation loss: 2.9598688161407782

Epoch: 6| Step: 11
Training loss: 0.7582010669080895
Validation loss: 2.8867718421138564

Epoch: 6| Step: 12
Training loss: 0.7781249295276779
Validation loss: 2.9962660944250046

Epoch: 6| Step: 13
Training loss: 0.8189008282644089
Validation loss: 2.9544172201360444

Epoch: 170| Step: 0
Training loss: 0.8446984082419805
Validation loss: 2.8991789576339455

Epoch: 6| Step: 1
Training loss: 0.7097673112747408
Validation loss: 2.89717819125141

Epoch: 6| Step: 2
Training loss: 1.5462245922421947
Validation loss: 2.840294761472215

Epoch: 6| Step: 3
Training loss: 0.7785878409709389
Validation loss: 2.940892904674001

Epoch: 6| Step: 4
Training loss: 0.8016317177792475
Validation loss: 2.8829782191942463

Epoch: 6| Step: 5
Training loss: 1.1238160791371392
Validation loss: 2.8792694980643128

Epoch: 6| Step: 6
Training loss: 0.8635401272884647
Validation loss: 3.006419730467423

Epoch: 6| Step: 7
Training loss: 0.6770297078146539
Validation loss: 2.906630733804509

Epoch: 6| Step: 8
Training loss: 0.8217827110545904
Validation loss: 2.9134044841775233

Epoch: 6| Step: 9
Training loss: 0.9958977001462018
Validation loss: 2.9040278891887237

Epoch: 6| Step: 10
Training loss: 0.8330915259170565
Validation loss: 2.9272078807755655

Epoch: 6| Step: 11
Training loss: 0.6556919086305543
Validation loss: 2.9895137995875514

Epoch: 6| Step: 12
Training loss: 0.7137965051228224
Validation loss: 2.9778073862329273

Epoch: 6| Step: 13
Training loss: 0.5382517924227993
Validation loss: 2.9645750973645826

Epoch: 171| Step: 0
Training loss: 0.8459931684538337
Validation loss: 3.0121787347081317

Epoch: 6| Step: 1
Training loss: 0.7584697193772799
Validation loss: 2.8842631397206473

Epoch: 6| Step: 2
Training loss: 1.015352300566531
Validation loss: 2.8777990951223127

Epoch: 6| Step: 3
Training loss: 0.7339246464698279
Validation loss: 2.906139029841943

Epoch: 6| Step: 4
Training loss: 0.7446887783306898
Validation loss: 2.899091908901043

Epoch: 6| Step: 5
Training loss: 0.645875626891703
Validation loss: 3.0902622098685377

Epoch: 6| Step: 6
Training loss: 1.1337154604393722
Validation loss: 2.929650254754569

Epoch: 6| Step: 7
Training loss: 1.5614574005687423
Validation loss: 2.9496748615765642

Epoch: 6| Step: 8
Training loss: 0.8477465322204779
Validation loss: 2.972749726157913

Epoch: 6| Step: 9
Training loss: 0.8903206422325681
Validation loss: 2.9019854167367622

Epoch: 6| Step: 10
Training loss: 0.8404647305660723
Validation loss: 2.8784038048315637

Epoch: 6| Step: 11
Training loss: 0.5004339123479734
Validation loss: 2.819929285335179

Epoch: 6| Step: 12
Training loss: 0.611096103500793
Validation loss: 2.88465997205004

Epoch: 6| Step: 13
Training loss: 0.7093357445026351
Validation loss: 2.905391333829866

Epoch: 172| Step: 0
Training loss: 0.9182441460651066
Validation loss: 2.9086766793595062

Epoch: 6| Step: 1
Training loss: 0.999065558626029
Validation loss: 2.933865876154414

Epoch: 6| Step: 2
Training loss: 0.8299021455807133
Validation loss: 2.7684886065563212

Epoch: 6| Step: 3
Training loss: 0.9157296325997154
Validation loss: 2.893932107203293

Epoch: 6| Step: 4
Training loss: 1.4918004677432843
Validation loss: 2.981386829064598

Epoch: 6| Step: 5
Training loss: 0.9061661385506649
Validation loss: 2.9630591475142523

Epoch: 6| Step: 6
Training loss: 0.802299585956275
Validation loss: 2.8583729139725684

Epoch: 6| Step: 7
Training loss: 0.827517808682217
Validation loss: 2.9180089495850416

Epoch: 6| Step: 8
Training loss: 0.652980699067005
Validation loss: 2.891581650252805

Epoch: 6| Step: 9
Training loss: 0.8350388518448849
Validation loss: 2.969730496364749

Epoch: 6| Step: 10
Training loss: 0.9584962492139616
Validation loss: 2.894647977725892

Epoch: 6| Step: 11
Training loss: 0.560176208438473
Validation loss: 2.9305497049410865

Epoch: 6| Step: 12
Training loss: 0.6025358969730461
Validation loss: 2.924219452265673

Epoch: 6| Step: 13
Training loss: 0.6783140270624043
Validation loss: 2.9476175639504394

Epoch: 173| Step: 0
Training loss: 0.9202431929548229
Validation loss: 2.977323726792589

Epoch: 6| Step: 1
Training loss: 0.7634372594694804
Validation loss: 2.921037564141567

Epoch: 6| Step: 2
Training loss: 0.9938568429671305
Validation loss: 2.877529358502778

Epoch: 6| Step: 3
Training loss: 0.6069562298580776
Validation loss: 2.8671296518364597

Epoch: 6| Step: 4
Training loss: 1.5662234382782236
Validation loss: 2.839367854188916

Epoch: 6| Step: 5
Training loss: 1.0445728895722564
Validation loss: 2.9374464449498388

Epoch: 6| Step: 6
Training loss: 0.7250412633268615
Validation loss: 2.998527112307203

Epoch: 6| Step: 7
Training loss: 1.1798814525700603
Validation loss: 2.8833158858181136

Epoch: 6| Step: 8
Training loss: 0.46085242116634995
Validation loss: 2.9155695804672783

Epoch: 6| Step: 9
Training loss: 0.7859312948357375
Validation loss: 2.841611819889284

Epoch: 6| Step: 10
Training loss: 0.9021710647550035
Validation loss: 2.9681487562126248

Epoch: 6| Step: 11
Training loss: 0.7865653607297881
Validation loss: 2.914667866053368

Epoch: 6| Step: 12
Training loss: 0.7681331811629077
Validation loss: 2.869622204179755

Epoch: 6| Step: 13
Training loss: 1.020901048451499
Validation loss: 2.9683203269149496

Epoch: 174| Step: 0
Training loss: 0.8133278810469476
Validation loss: 2.864883370147612

Epoch: 6| Step: 1
Training loss: 0.9613438499184521
Validation loss: 2.9168915162382794

Epoch: 6| Step: 2
Training loss: 0.9019689400774513
Validation loss: 2.9516252076525555

Epoch: 6| Step: 3
Training loss: 0.8100704033596094
Validation loss: 2.8761911827018567

Epoch: 6| Step: 4
Training loss: 0.9152202284367214
Validation loss: 2.8722671982617225

Epoch: 6| Step: 5
Training loss: 1.4779095030916518
Validation loss: 2.8776719075280455

Epoch: 6| Step: 6
Training loss: 0.8650513190552941
Validation loss: 2.9997595982127128

Epoch: 6| Step: 7
Training loss: 1.0653670281185028
Validation loss: 2.93925421665957

Epoch: 6| Step: 8
Training loss: 0.9091347131145999
Validation loss: 2.9594798664659114

Epoch: 6| Step: 9
Training loss: 1.0825106113257332
Validation loss: 2.9019812404167316

Epoch: 6| Step: 10
Training loss: 0.7317137690294563
Validation loss: 2.8853427496484385

Epoch: 6| Step: 11
Training loss: 0.9192938148860617
Validation loss: 2.9259259434747853

Epoch: 6| Step: 12
Training loss: 0.8084058312877249
Validation loss: 2.903826451635542

Epoch: 6| Step: 13
Training loss: 0.7990882282195342
Validation loss: 2.884628578465602

Epoch: 175| Step: 0
Training loss: 0.5915908202955734
Validation loss: 2.903707561207427

Epoch: 6| Step: 1
Training loss: 0.821306988206388
Validation loss: 2.9133603201983083

Epoch: 6| Step: 2
Training loss: 0.5447385746290355
Validation loss: 2.9108121060364502

Epoch: 6| Step: 3
Training loss: 0.5157853657426233
Validation loss: 2.9164191050143553

Epoch: 6| Step: 4
Training loss: 1.1663414070312934
Validation loss: 2.9875394278548804

Epoch: 6| Step: 5
Training loss: 0.7184139793100005
Validation loss: 2.868573829820942

Epoch: 6| Step: 6
Training loss: 1.625655922190457
Validation loss: 2.991303262625598

Epoch: 6| Step: 7
Training loss: 0.5479370431290039
Validation loss: 2.898507747158761

Epoch: 6| Step: 8
Training loss: 0.498286141161928
Validation loss: 3.0330571034874274

Epoch: 6| Step: 9
Training loss: 0.7582860037597455
Validation loss: 2.877006065846664

Epoch: 6| Step: 10
Training loss: 1.1093489415506592
Validation loss: 2.893613517953664

Epoch: 6| Step: 11
Training loss: 0.8276638690467448
Validation loss: 2.9297829031775344

Epoch: 6| Step: 12
Training loss: 1.0292006851216247
Validation loss: 2.9359476573498373

Epoch: 6| Step: 13
Training loss: 0.852250932068006
Validation loss: 2.915376000710683

Epoch: 176| Step: 0
Training loss: 0.5630429085054152
Validation loss: 2.938599671489216

Epoch: 6| Step: 1
Training loss: 0.8889163173642546
Validation loss: 2.972164278762906

Epoch: 6| Step: 2
Training loss: 0.8069230663541248
Validation loss: 2.8649059853764975

Epoch: 6| Step: 3
Training loss: 1.5059421778770694
Validation loss: 2.891679162613164

Epoch: 6| Step: 4
Training loss: 0.9037538549992611
Validation loss: 2.9535550539374764

Epoch: 6| Step: 5
Training loss: 0.7848796072440564
Validation loss: 3.0252585565920813

Epoch: 6| Step: 6
Training loss: 0.8529733991242913
Validation loss: 2.8466972058271356

Epoch: 6| Step: 7
Training loss: 0.8640178799964633
Validation loss: 2.8951734207162674

Epoch: 6| Step: 8
Training loss: 0.9702214172171313
Validation loss: 2.948552340569025

Epoch: 6| Step: 9
Training loss: 0.4197491845184911
Validation loss: 3.031513635241362

Epoch: 6| Step: 10
Training loss: 0.730656033746883
Validation loss: 2.994753475222116

Epoch: 6| Step: 11
Training loss: 0.5497033955854829
Validation loss: 2.96758807014398

Epoch: 6| Step: 12
Training loss: 0.8650262379939164
Validation loss: 2.953845573662381

Epoch: 6| Step: 13
Training loss: 0.47661838829142755
Validation loss: 2.912885044497198

Epoch: 177| Step: 0
Training loss: 1.4487567998218014
Validation loss: 3.0375344587132305

Epoch: 6| Step: 1
Training loss: 0.6994923530485111
Validation loss: 2.99758864555119

Epoch: 6| Step: 2
Training loss: 0.5160824451600069
Validation loss: 2.9476781463281596

Epoch: 6| Step: 3
Training loss: 0.931702905648452
Validation loss: 2.841770531181589

Epoch: 6| Step: 4
Training loss: 0.9054371049039738
Validation loss: 2.9161448193508774

Epoch: 6| Step: 5
Training loss: 0.852965852194785
Validation loss: 2.911355104930905

Epoch: 6| Step: 6
Training loss: 0.6874520545193522
Validation loss: 3.024879578224294

Epoch: 6| Step: 7
Training loss: 1.018221133981746
Validation loss: 2.932100270576413

Epoch: 6| Step: 8
Training loss: 0.709851703872135
Validation loss: 2.9624905367457335

Epoch: 6| Step: 9
Training loss: 0.5332863431833186
Validation loss: 2.914686884391422

Epoch: 6| Step: 10
Training loss: 0.5294380984932844
Validation loss: 2.8688888422016103

Epoch: 6| Step: 11
Training loss: 0.5885515521634325
Validation loss: 2.967371342758877

Epoch: 6| Step: 12
Training loss: 0.8003252917797572
Validation loss: 2.904963547023214

Epoch: 6| Step: 13
Training loss: 0.8330778962288882
Validation loss: 2.9446986441576963

Epoch: 178| Step: 0
Training loss: 0.6013893770074467
Validation loss: 3.0008192135952636

Epoch: 6| Step: 1
Training loss: 0.9166163120021906
Validation loss: 2.839880605928093

Epoch: 6| Step: 2
Training loss: 0.5938678674656973
Validation loss: 2.8451312417105066

Epoch: 6| Step: 3
Training loss: 0.5200884133149765
Validation loss: 2.950408426126121

Epoch: 6| Step: 4
Training loss: 0.6148230009928223
Validation loss: 2.8855994174708157

Epoch: 6| Step: 5
Training loss: 0.9913856089361868
Validation loss: 2.9102462583955346

Epoch: 6| Step: 6
Training loss: 0.9678169494763119
Validation loss: 2.8619892697536335

Epoch: 6| Step: 7
Training loss: 0.6416102253461147
Validation loss: 2.881021882554588

Epoch: 6| Step: 8
Training loss: 1.5164695038689537
Validation loss: 2.915558704468854

Epoch: 6| Step: 9
Training loss: 0.6572178560901777
Validation loss: 2.8583588314494657

Epoch: 6| Step: 10
Training loss: 0.6620309608860389
Validation loss: 2.9794885532619966

Epoch: 6| Step: 11
Training loss: 0.729627155038704
Validation loss: 2.9456527338058534

Epoch: 6| Step: 12
Training loss: 1.1364533419314433
Validation loss: 2.9087706268982445

Epoch: 6| Step: 13
Training loss: 0.7326235074020097
Validation loss: 2.9694976935882185

Epoch: 179| Step: 0
Training loss: 0.535290081804044
Validation loss: 2.759068578552885

Epoch: 6| Step: 1
Training loss: 0.7378624025665675
Validation loss: 3.0127087923033793

Epoch: 6| Step: 2
Training loss: 0.8278125677400348
Validation loss: 2.9130018961496815

Epoch: 6| Step: 3
Training loss: 0.8590568647203282
Validation loss: 2.8790255849217514

Epoch: 6| Step: 4
Training loss: 0.6064140569768691
Validation loss: 2.897666191028483

Epoch: 6| Step: 5
Training loss: 0.8471006339189582
Validation loss: 2.928303288989743

Epoch: 6| Step: 6
Training loss: 0.8952376395945901
Validation loss: 2.9143174292604455

Epoch: 6| Step: 7
Training loss: 0.4778543379375679
Validation loss: 3.047984333725631

Epoch: 6| Step: 8
Training loss: 0.4892377411461954
Validation loss: 2.9087387285176725

Epoch: 6| Step: 9
Training loss: 0.7842113825757315
Validation loss: 2.988285332305048

Epoch: 6| Step: 10
Training loss: 0.867450021408919
Validation loss: 3.0109111199430068

Epoch: 6| Step: 11
Training loss: 1.8484127762109213
Validation loss: 2.973885962323318

Epoch: 6| Step: 12
Training loss: 0.9185457729237145
Validation loss: 2.811059625335899

Epoch: 6| Step: 13
Training loss: 0.678095388864676
Validation loss: 2.898513669558028

Epoch: 180| Step: 0
Training loss: 0.9525552516341357
Validation loss: 2.849545829121938

Epoch: 6| Step: 1
Training loss: 0.659144308765585
Validation loss: 2.8279737288060978

Epoch: 6| Step: 2
Training loss: 0.9451164483676266
Validation loss: 2.9390153966627808

Epoch: 6| Step: 3
Training loss: 0.5912400197241267
Validation loss: 2.9101433056025034

Epoch: 6| Step: 4
Training loss: 0.6154105766716506
Validation loss: 2.9039474307863897

Epoch: 6| Step: 5
Training loss: 1.544865468535106
Validation loss: 2.8842170415838413

Epoch: 6| Step: 6
Training loss: 0.8062044308226709
Validation loss: 2.8894816500139453

Epoch: 6| Step: 7
Training loss: 0.4591111677637421
Validation loss: 2.831994348044422

Epoch: 6| Step: 8
Training loss: 1.0131670626475189
Validation loss: 2.9217119834426186

Epoch: 6| Step: 9
Training loss: 0.5820969154131355
Validation loss: 2.910197909268201

Epoch: 6| Step: 10
Training loss: 0.27939538618888304
Validation loss: 2.945294070671025

Epoch: 6| Step: 11
Training loss: 0.4806968333680246
Validation loss: 2.848572774085912

Epoch: 6| Step: 12
Training loss: 0.8300454166924394
Validation loss: 2.895705272852672

Epoch: 6| Step: 13
Training loss: 0.8423904839601307
Validation loss: 2.9483059647409204

Epoch: 181| Step: 0
Training loss: 0.9059744119904419
Validation loss: 2.9169124953804815

Epoch: 6| Step: 1
Training loss: 0.7595515403085569
Validation loss: 2.95866886886674

Epoch: 6| Step: 2
Training loss: 0.5587811989149271
Validation loss: 2.8935447587130323

Epoch: 6| Step: 3
Training loss: 0.6443028825720568
Validation loss: 2.8730169727352104

Epoch: 6| Step: 4
Training loss: 0.5783782610449897
Validation loss: 2.954161662181351

Epoch: 6| Step: 5
Training loss: 0.7375761833282537
Validation loss: 2.904967513873951

Epoch: 6| Step: 6
Training loss: 0.2964806949753987
Validation loss: 2.9244441876424205

Epoch: 6| Step: 7
Training loss: 1.5065037082356805
Validation loss: 2.9552878746396236

Epoch: 6| Step: 8
Training loss: 0.6642314471581644
Validation loss: 2.9469457224790188

Epoch: 6| Step: 9
Training loss: 0.7432118624780394
Validation loss: 2.836144992324186

Epoch: 6| Step: 10
Training loss: 0.9791974644518262
Validation loss: 2.955120307401104

Epoch: 6| Step: 11
Training loss: 0.6951887470657041
Validation loss: 2.9594450102127774

Epoch: 6| Step: 12
Training loss: 1.0207867254918774
Validation loss: 2.9447136092166217

Epoch: 6| Step: 13
Training loss: 0.5679480778475324
Validation loss: 2.886567658568475

Epoch: 182| Step: 0
Training loss: 0.5899511327953635
Validation loss: 2.8895821967165105

Epoch: 6| Step: 1
Training loss: 0.7290688221997029
Validation loss: 3.0150906842175713

Epoch: 6| Step: 2
Training loss: 0.5183362195291332
Validation loss: 2.987272816297104

Epoch: 6| Step: 3
Training loss: 0.6704571423384772
Validation loss: 2.981512644332643

Epoch: 6| Step: 4
Training loss: 0.9135356591149293
Validation loss: 2.893019665475976

Epoch: 6| Step: 5
Training loss: 1.4635808357979545
Validation loss: 2.9148911703262588

Epoch: 6| Step: 6
Training loss: 0.766559225480511
Validation loss: 2.9995097448520625

Epoch: 6| Step: 7
Training loss: 0.7473331562482141
Validation loss: 3.011812451888589

Epoch: 6| Step: 8
Training loss: 0.8582677470460526
Validation loss: 2.9672673990541574

Epoch: 6| Step: 9
Training loss: 1.0058417161298812
Validation loss: 2.901794984124996

Epoch: 6| Step: 10
Training loss: 0.6224272705395857
Validation loss: 2.948385347418231

Epoch: 6| Step: 11
Training loss: 0.6556343869609158
Validation loss: 2.9476256120149253

Epoch: 6| Step: 12
Training loss: 0.7691284132220986
Validation loss: 2.8536261211414615

Epoch: 6| Step: 13
Training loss: 1.1010173233117655
Validation loss: 2.7600308034624548

Epoch: 183| Step: 0
Training loss: 0.7925048749154032
Validation loss: 2.965505084771202

Epoch: 6| Step: 1
Training loss: 0.9861251168905569
Validation loss: 2.8726668911562947

Epoch: 6| Step: 2
Training loss: 0.8987061472077126
Validation loss: 2.877744028596413

Epoch: 6| Step: 3
Training loss: 0.9923742524055446
Validation loss: 2.8732989710842634

Epoch: 6| Step: 4
Training loss: 0.839014042710646
Validation loss: 2.9104891115172897

Epoch: 6| Step: 5
Training loss: 0.5035069088296118
Validation loss: 2.7976455266427958

Epoch: 6| Step: 6
Training loss: 0.5217560478375384
Validation loss: 2.887999061844093

Epoch: 6| Step: 7
Training loss: 0.4851320718339753
Validation loss: 2.839023924757783

Epoch: 6| Step: 8
Training loss: 0.6566848449522655
Validation loss: 2.8674162202639413

Epoch: 6| Step: 9
Training loss: 0.5246761526638148
Validation loss: 2.8458623621192207

Epoch: 6| Step: 10
Training loss: 0.6058052850480766
Validation loss: 2.874738598425489

Epoch: 6| Step: 11
Training loss: 0.6525228106139908
Validation loss: 2.9292380433228833

Epoch: 6| Step: 12
Training loss: 1.4724807432304745
Validation loss: 2.9014235039202307

Epoch: 6| Step: 13
Training loss: 0.734638856602327
Validation loss: 2.9375549338324283

Epoch: 184| Step: 0
Training loss: 0.4913342967519972
Validation loss: 2.870916202790465

Epoch: 6| Step: 1
Training loss: 0.9400862307259699
Validation loss: 2.953513804411919

Epoch: 6| Step: 2
Training loss: 0.9266271790546118
Validation loss: 2.958621418496776

Epoch: 6| Step: 3
Training loss: 0.46374796088045434
Validation loss: 2.826253507112275

Epoch: 6| Step: 4
Training loss: 0.7520798613520092
Validation loss: 2.8205371742542047

Epoch: 6| Step: 5
Training loss: 0.4292451141781428
Validation loss: 2.864416351075371

Epoch: 6| Step: 6
Training loss: 0.9116496330415733
Validation loss: 2.903263074796328

Epoch: 6| Step: 7
Training loss: 0.7368573379017662
Validation loss: 2.9699933978477246

Epoch: 6| Step: 8
Training loss: 1.5969100739272093
Validation loss: 2.87725314707944

Epoch: 6| Step: 9
Training loss: 0.4835577499966921
Validation loss: 2.9695553674331547

Epoch: 6| Step: 10
Training loss: 0.646398417586984
Validation loss: 2.860623085555295

Epoch: 6| Step: 11
Training loss: 0.7849940042206007
Validation loss: 2.935070263954645

Epoch: 6| Step: 12
Training loss: 0.8756287563659997
Validation loss: 2.8873603875122833

Epoch: 6| Step: 13
Training loss: 0.8223194820498763
Validation loss: 2.9751935666154146

Epoch: 185| Step: 0
Training loss: 0.7032842032017346
Validation loss: 2.9157890679799903

Epoch: 6| Step: 1
Training loss: 0.5516282191041073
Validation loss: 2.8948317426277828

Epoch: 6| Step: 2
Training loss: 0.8529158870418273
Validation loss: 2.899813919016718

Epoch: 6| Step: 3
Training loss: 1.018292664924433
Validation loss: 2.9394689278584414

Epoch: 6| Step: 4
Training loss: 1.4695033312614092
Validation loss: 3.0024308912575233

Epoch: 6| Step: 5
Training loss: 0.52068398877614
Validation loss: 3.020364795172221

Epoch: 6| Step: 6
Training loss: 0.7130109293556125
Validation loss: 2.9866449002199382

Epoch: 6| Step: 7
Training loss: 0.7724576195260995
Validation loss: 2.9457258748945385

Epoch: 6| Step: 8
Training loss: 0.7324574372876893
Validation loss: 2.9427235065620407

Epoch: 6| Step: 9
Training loss: 0.5819561801092259
Validation loss: 2.912551297130358

Epoch: 6| Step: 10
Training loss: 0.7559032969564761
Validation loss: 2.955913834817717

Epoch: 6| Step: 11
Training loss: 0.7744725555226682
Validation loss: 2.9498923098848895

Epoch: 6| Step: 12
Training loss: 0.8641691173149634
Validation loss: 2.878875718457364

Epoch: 6| Step: 13
Training loss: 0.6278702394812693
Validation loss: 2.9235691184327592

Epoch: 186| Step: 0
Training loss: 1.4470716338705754
Validation loss: 2.9485509929097553

Epoch: 6| Step: 1
Training loss: 0.9320249264703234
Validation loss: 2.928091049947462

Epoch: 6| Step: 2
Training loss: 0.933647952242113
Validation loss: 3.0236796200822122

Epoch: 6| Step: 3
Training loss: 0.7227348491092735
Validation loss: 2.949399168714844

Epoch: 6| Step: 4
Training loss: 0.7493484766627447
Validation loss: 2.9377166316457592

Epoch: 6| Step: 5
Training loss: 0.7926242625051549
Validation loss: 2.927965273414069

Epoch: 6| Step: 6
Training loss: 0.6076511060909467
Validation loss: 2.8862754195723888

Epoch: 6| Step: 7
Training loss: 0.8643266381052113
Validation loss: 2.8363466484355633

Epoch: 6| Step: 8
Training loss: 0.9801273739521714
Validation loss: 2.8516379150451323

Epoch: 6| Step: 9
Training loss: 0.614158246290161
Validation loss: 2.8759828905296114

Epoch: 6| Step: 10
Training loss: 0.6272401479492417
Validation loss: 3.0028208874683804

Epoch: 6| Step: 11
Training loss: 0.7026312047809617
Validation loss: 2.956022922969856

Epoch: 6| Step: 12
Training loss: 0.9408668143873041
Validation loss: 2.945635331840804

Epoch: 6| Step: 13
Training loss: 0.6784349937164247
Validation loss: 3.0166384323302227

Epoch: 187| Step: 0
Training loss: 0.8889245313379524
Validation loss: 2.874813875448509

Epoch: 6| Step: 1
Training loss: 0.9210745358909935
Validation loss: 2.889265204539887

Epoch: 6| Step: 2
Training loss: 0.9335219543176061
Validation loss: 2.9085383959583475

Epoch: 6| Step: 3
Training loss: 0.8557694834063395
Validation loss: 2.899748198221351

Epoch: 6| Step: 4
Training loss: 0.4819026423045219
Validation loss: 2.872286068481146

Epoch: 6| Step: 5
Training loss: 0.684225128694652
Validation loss: 2.9761073714869664

Epoch: 6| Step: 6
Training loss: 0.6597041099694402
Validation loss: 2.90012497632622

Epoch: 6| Step: 7
Training loss: 1.4600681431427232
Validation loss: 2.8757666104790505

Epoch: 6| Step: 8
Training loss: 0.5503707871337565
Validation loss: 2.9762301388777055

Epoch: 6| Step: 9
Training loss: 0.456729577425896
Validation loss: 2.9866222023066658

Epoch: 6| Step: 10
Training loss: 0.668212087823778
Validation loss: 2.9387608115233843

Epoch: 6| Step: 11
Training loss: 0.5324995548174792
Validation loss: 2.9577043339235924

Epoch: 6| Step: 12
Training loss: 0.61638935003091
Validation loss: 2.8832056316769163

Epoch: 6| Step: 13
Training loss: 0.6045039211237523
Validation loss: 2.9763679073668388

Epoch: 188| Step: 0
Training loss: 0.6143628684055916
Validation loss: 2.9389888831948667

Epoch: 6| Step: 1
Training loss: 0.690158040564928
Validation loss: 2.9395478192154774

Epoch: 6| Step: 2
Training loss: 0.7909471647048137
Validation loss: 2.8881329628469268

Epoch: 6| Step: 3
Training loss: 0.6685140068566899
Validation loss: 2.9393061908484763

Epoch: 6| Step: 4
Training loss: 0.502414951054313
Validation loss: 2.9663772202495333

Epoch: 6| Step: 5
Training loss: 0.6567896032310843
Validation loss: 2.888392705110869

Epoch: 6| Step: 6
Training loss: 0.8552510232682339
Validation loss: 2.9127635634633666

Epoch: 6| Step: 7
Training loss: 0.9607655441134508
Validation loss: 2.968900750331477

Epoch: 6| Step: 8
Training loss: 0.6739988249024241
Validation loss: 2.932080213241431

Epoch: 6| Step: 9
Training loss: 0.4501258151018665
Validation loss: 2.86690162945157

Epoch: 6| Step: 10
Training loss: 0.5908688359787404
Validation loss: 2.885120450088763

Epoch: 6| Step: 11
Training loss: 0.6411160238749172
Validation loss: 2.9190390656773473

Epoch: 6| Step: 12
Training loss: 1.477363248199141
Validation loss: 2.8274240766788306

Epoch: 6| Step: 13
Training loss: 0.8206302209181066
Validation loss: 2.891074192096625

Epoch: 189| Step: 0
Training loss: 0.6391687822451968
Validation loss: 2.8555984432827684

Epoch: 6| Step: 1
Training loss: 0.6765871039094935
Validation loss: 2.8737240738132708

Epoch: 6| Step: 2
Training loss: 0.5642667680546616
Validation loss: 2.9809512993051634

Epoch: 6| Step: 3
Training loss: 0.6641681138369478
Validation loss: 2.9092108161509804

Epoch: 6| Step: 4
Training loss: 0.7340982605597982
Validation loss: 2.94816615708023

Epoch: 6| Step: 5
Training loss: 0.5704830385005297
Validation loss: 2.811324389558888

Epoch: 6| Step: 6
Training loss: 0.5339614171169662
Validation loss: 2.8758093897057573

Epoch: 6| Step: 7
Training loss: 0.5006306962011836
Validation loss: 2.8528255783239813

Epoch: 6| Step: 8
Training loss: 0.972540423379312
Validation loss: 2.912249371792089

Epoch: 6| Step: 9
Training loss: 0.8679886287744222
Validation loss: 2.900699332748636

Epoch: 6| Step: 10
Training loss: 0.7093438952512343
Validation loss: 2.897890586013498

Epoch: 6| Step: 11
Training loss: 0.6535521410985439
Validation loss: 2.9729210046007197

Epoch: 6| Step: 12
Training loss: 1.4247592555353064
Validation loss: 2.8762976026291467

Epoch: 6| Step: 13
Training loss: 0.5397879101018759
Validation loss: 2.9360599099126627

Epoch: 190| Step: 0
Training loss: 0.4601341294054223
Validation loss: 2.9469370792628604

Epoch: 6| Step: 1
Training loss: 0.7635960065614358
Validation loss: 2.8858846957352187

Epoch: 6| Step: 2
Training loss: 0.660477328798646
Validation loss: 2.9068903337247955

Epoch: 6| Step: 3
Training loss: 0.5482605955854314
Validation loss: 2.8626521773887403

Epoch: 6| Step: 4
Training loss: 0.6532888818316499
Validation loss: 2.8902134370361208

Epoch: 6| Step: 5
Training loss: 0.5244925385190801
Validation loss: 3.005044880900517

Epoch: 6| Step: 6
Training loss: 0.8990863281635252
Validation loss: 2.912668366811577

Epoch: 6| Step: 7
Training loss: 0.6817228163869596
Validation loss: 2.8217540800956735

Epoch: 6| Step: 8
Training loss: 0.6595701968277956
Validation loss: 2.964391996455718

Epoch: 6| Step: 9
Training loss: 0.7551859929079922
Validation loss: 2.9695106201204635

Epoch: 6| Step: 10
Training loss: 1.5336400278175828
Validation loss: 2.9146043207277774

Epoch: 6| Step: 11
Training loss: 0.641716980096918
Validation loss: 2.9166208717747386

Epoch: 6| Step: 12
Training loss: 0.4874969898033128
Validation loss: 2.97587967430516

Epoch: 6| Step: 13
Training loss: 0.6831879201323621
Validation loss: 2.9042361128470313

Epoch: 191| Step: 0
Training loss: 0.7558436823356864
Validation loss: 2.992984582561563

Epoch: 6| Step: 1
Training loss: 0.7654789376578579
Validation loss: 2.8577755761059787

Epoch: 6| Step: 2
Training loss: 0.5837722444074008
Validation loss: 2.870834553408721

Epoch: 6| Step: 3
Training loss: 0.6971540602218256
Validation loss: 2.9665282920826916

Epoch: 6| Step: 4
Training loss: 1.596452553368709
Validation loss: 2.948543203427109

Epoch: 6| Step: 5
Training loss: 0.7346050632556765
Validation loss: 2.974395056267697

Epoch: 6| Step: 6
Training loss: 0.5948397022988372
Validation loss: 2.9130899614934425

Epoch: 6| Step: 7
Training loss: 0.46587429093761645
Validation loss: 2.9299102291637285

Epoch: 6| Step: 8
Training loss: 0.5881885268048676
Validation loss: 2.913662334985164

Epoch: 6| Step: 9
Training loss: 0.6245951771986326
Validation loss: 2.951590595209251

Epoch: 6| Step: 10
Training loss: 0.7508596817951093
Validation loss: 2.8889397047130014

Epoch: 6| Step: 11
Training loss: 1.0215648962198733
Validation loss: 2.9134462674865644

Epoch: 6| Step: 12
Training loss: 0.6225103621405561
Validation loss: 2.9421536533315202

Epoch: 6| Step: 13
Training loss: 0.8079227114079633
Validation loss: 2.835596475685445

Epoch: 192| Step: 0
Training loss: 0.6458908075989945
Validation loss: 2.859068279109719

Epoch: 6| Step: 1
Training loss: 0.4656169775457332
Validation loss: 2.9995201574802275

Epoch: 6| Step: 2
Training loss: 0.4175081835018971
Validation loss: 2.9729827420849766

Epoch: 6| Step: 3
Training loss: 0.5466058886380057
Validation loss: 2.910005446928155

Epoch: 6| Step: 4
Training loss: 0.7747421435572959
Validation loss: 2.8348080966952076

Epoch: 6| Step: 5
Training loss: 0.7828902382997678
Validation loss: 2.9428157055376114

Epoch: 6| Step: 6
Training loss: 0.8005264248939132
Validation loss: 2.9683733784885398

Epoch: 6| Step: 7
Training loss: 0.6250253195402373
Validation loss: 2.864203276420129

Epoch: 6| Step: 8
Training loss: 0.8752810844168724
Validation loss: 2.879920177059944

Epoch: 6| Step: 9
Training loss: 0.5516077968595475
Validation loss: 3.0293030795130758

Epoch: 6| Step: 10
Training loss: 0.5769810571023752
Validation loss: 2.9182900860811927

Epoch: 6| Step: 11
Training loss: 1.6960364698861394
Validation loss: 2.8611697069564768

Epoch: 6| Step: 12
Training loss: 0.6802660354356119
Validation loss: 2.911291432700742

Epoch: 6| Step: 13
Training loss: 0.7120565473303854
Validation loss: 2.903830981089434

Epoch: 193| Step: 0
Training loss: 0.7481320882921947
Validation loss: 2.9487141360648437

Epoch: 6| Step: 1
Training loss: 1.460763359910991
Validation loss: 2.8907408545019315

Epoch: 6| Step: 2
Training loss: 0.5175454183357082
Validation loss: 2.935074988885092

Epoch: 6| Step: 3
Training loss: 0.7924988956624228
Validation loss: 2.9295008756748357

Epoch: 6| Step: 4
Training loss: 0.5643879149892989
Validation loss: 2.970550553255578

Epoch: 6| Step: 5
Training loss: 0.5965142403091493
Validation loss: 2.909689464298711

Epoch: 6| Step: 6
Training loss: 0.6856632405607941
Validation loss: 2.9487464105493406

Epoch: 6| Step: 7
Training loss: 0.8667426128001131
Validation loss: 2.929119424633426

Epoch: 6| Step: 8
Training loss: 0.8052316695989786
Validation loss: 2.8911947427766926

Epoch: 6| Step: 9
Training loss: 0.7888987909585066
Validation loss: 2.9080650240437835

Epoch: 6| Step: 10
Training loss: 0.6840932928188964
Validation loss: 2.8636199070878265

Epoch: 6| Step: 11
Training loss: 0.9992532624226507
Validation loss: 2.8848391940843605

Epoch: 6| Step: 12
Training loss: 0.49777294928556637
Validation loss: 2.899293771340387

Epoch: 6| Step: 13
Training loss: 0.7686024206284685
Validation loss: 2.9562500661321716

Epoch: 194| Step: 0
Training loss: 0.5610528450112093
Validation loss: 2.9254403079070608

Epoch: 6| Step: 1
Training loss: 0.6893323841220634
Validation loss: 2.9667609260529115

Epoch: 6| Step: 2
Training loss: 0.476405821512592
Validation loss: 2.838614763257808

Epoch: 6| Step: 3
Training loss: 1.5035773375867203
Validation loss: 2.851166315295869

Epoch: 6| Step: 4
Training loss: 0.6708059011106523
Validation loss: 2.8797570277965954

Epoch: 6| Step: 5
Training loss: 0.7663778768375615
Validation loss: 2.8808841475806366

Epoch: 6| Step: 6
Training loss: 0.523731945973962
Validation loss: 2.92000397531683

Epoch: 6| Step: 7
Training loss: 1.0222926834834216
Validation loss: 2.9651098454430684

Epoch: 6| Step: 8
Training loss: 0.6067609717968885
Validation loss: 2.918025808189281

Epoch: 6| Step: 9
Training loss: 0.6758539458407229
Validation loss: 2.8449771734482883

Epoch: 6| Step: 10
Training loss: 0.46209090801367825
Validation loss: 3.003903657261424

Epoch: 6| Step: 11
Training loss: 0.550432026851156
Validation loss: 2.948852583699158

Epoch: 6| Step: 12
Training loss: 0.5688019697318866
Validation loss: 2.9334656627746187

Epoch: 6| Step: 13
Training loss: 0.5088189934476789
Validation loss: 2.9840671853239673

Epoch: 195| Step: 0
Training loss: 1.0928366526028288
Validation loss: 2.9182759795189224

Epoch: 6| Step: 1
Training loss: 0.7320675412426787
Validation loss: 2.927587409187265

Epoch: 6| Step: 2
Training loss: 0.7476716058921964
Validation loss: 3.017413977445314

Epoch: 6| Step: 3
Training loss: 0.5341650422091885
Validation loss: 2.8240362577100964

Epoch: 6| Step: 4
Training loss: 0.7154159757032781
Validation loss: 2.9811835408883676

Epoch: 6| Step: 5
Training loss: 1.379409611712366
Validation loss: 2.9938982927497917

Epoch: 6| Step: 6
Training loss: 0.6675931532648705
Validation loss: 2.958170205754218

Epoch: 6| Step: 7
Training loss: 0.6379300630318532
Validation loss: 2.9502330795710994

Epoch: 6| Step: 8
Training loss: 0.5663459482649716
Validation loss: 2.9742878443504117

Epoch: 6| Step: 9
Training loss: 0.6974921619836276
Validation loss: 3.007948967286007

Epoch: 6| Step: 10
Training loss: 0.6245898808532053
Validation loss: 2.9596394803038444

Epoch: 6| Step: 11
Training loss: 0.7902562393429713
Validation loss: 2.8692650331964944

Epoch: 6| Step: 12
Training loss: 0.45692178442300935
Validation loss: 3.0102769803877085

Epoch: 6| Step: 13
Training loss: 0.6198668447682292
Validation loss: 2.880160648073072

Epoch: 196| Step: 0
Training loss: 0.645886562573926
Validation loss: 2.8960564250682963

Epoch: 6| Step: 1
Training loss: 0.8341310894671103
Validation loss: 2.914249213051988

Epoch: 6| Step: 2
Training loss: 0.37181418907409
Validation loss: 2.926250384500601

Epoch: 6| Step: 3
Training loss: 0.6611324518785944
Validation loss: 2.9157811773461075

Epoch: 6| Step: 4
Training loss: 0.5891445639033079
Validation loss: 2.8785716552085208

Epoch: 6| Step: 5
Training loss: 0.8029474128876726
Validation loss: 2.842446779654825

Epoch: 6| Step: 6
Training loss: 0.5769080163139199
Validation loss: 2.9703398345914933

Epoch: 6| Step: 7
Training loss: 0.7098912935585254
Validation loss: 2.9052641505672647

Epoch: 6| Step: 8
Training loss: 0.5683888168836821
Validation loss: 2.8696316203070515

Epoch: 6| Step: 9
Training loss: 1.469057335048247
Validation loss: 2.9273606482354793

Epoch: 6| Step: 10
Training loss: 0.5288402657081024
Validation loss: 2.801361080715248

Epoch: 6| Step: 11
Training loss: 0.9095388127287622
Validation loss: 3.000781129762382

Epoch: 6| Step: 12
Training loss: 0.6772888654144223
Validation loss: 2.914970195218756

Epoch: 6| Step: 13
Training loss: 0.7882284534266778
Validation loss: 2.8696931844014792

Epoch: 197| Step: 0
Training loss: 0.7144991351496786
Validation loss: 2.906412721679377

Epoch: 6| Step: 1
Training loss: 1.4140141937266488
Validation loss: 2.935759739064816

Epoch: 6| Step: 2
Training loss: 0.6363995928173812
Validation loss: 2.895258157998648

Epoch: 6| Step: 3
Training loss: 0.5432460269036604
Validation loss: 2.8520227905564846

Epoch: 6| Step: 4
Training loss: 0.9726694864498452
Validation loss: 2.869357736854524

Epoch: 6| Step: 5
Training loss: 0.7092429706196908
Validation loss: 2.8999453013293035

Epoch: 6| Step: 6
Training loss: 0.44542602296690237
Validation loss: 2.838409929397451

Epoch: 6| Step: 7
Training loss: 0.7116818566082246
Validation loss: 2.9008645232453567

Epoch: 6| Step: 8
Training loss: 0.719769998013557
Validation loss: 2.95047786689218

Epoch: 6| Step: 9
Training loss: 0.5017827854497675
Validation loss: 2.9954196481605413

Epoch: 6| Step: 10
Training loss: 0.5631842425193642
Validation loss: 2.952896512996567

Epoch: 6| Step: 11
Training loss: 0.8919305434705161
Validation loss: 2.9042473733014496

Epoch: 6| Step: 12
Training loss: 0.6525496426329476
Validation loss: 2.9023321261885546

Epoch: 6| Step: 13
Training loss: 0.555961810690664
Validation loss: 2.8616962426074886

Epoch: 198| Step: 0
Training loss: 0.5019419628045138
Validation loss: 2.9738324679291996

Epoch: 6| Step: 1
Training loss: 0.817669124432662
Validation loss: 2.955024175830106

Epoch: 6| Step: 2
Training loss: 0.6001738832758998
Validation loss: 2.88707614281364

Epoch: 6| Step: 3
Training loss: 0.690618551232795
Validation loss: 2.9851757526467795

Epoch: 6| Step: 4
Training loss: 0.6265901840068157
Validation loss: 3.019802448156523

Epoch: 6| Step: 5
Training loss: 0.7590183613658318
Validation loss: 2.9580224684239584

Epoch: 6| Step: 6
Training loss: 0.5288415054970642
Validation loss: 2.8526628714002285

Epoch: 6| Step: 7
Training loss: 0.6109396824712381
Validation loss: 2.8173495409150737

Epoch: 6| Step: 8
Training loss: 0.5226843810672066
Validation loss: 3.0111507237993207

Epoch: 6| Step: 9
Training loss: 1.448903010848197
Validation loss: 2.898709403528672

Epoch: 6| Step: 10
Training loss: 0.9843570768147568
Validation loss: 3.0789139409466473

Epoch: 6| Step: 11
Training loss: 0.4669593145334589
Validation loss: 2.9325771746137757

Epoch: 6| Step: 12
Training loss: 0.5989219626841904
Validation loss: 2.851498969776927

Epoch: 6| Step: 13
Training loss: 0.8373085258579213
Validation loss: 2.848685233482003

Epoch: 199| Step: 0
Training loss: 0.6217137966452418
Validation loss: 2.937780245135309

Epoch: 6| Step: 1
Training loss: 0.750612168023726
Validation loss: 2.8495138952841623

Epoch: 6| Step: 2
Training loss: 0.9347716047938206
Validation loss: 2.9268691277551975

Epoch: 6| Step: 3
Training loss: 0.685235020492923
Validation loss: 2.9181956960862534

Epoch: 6| Step: 4
Training loss: 0.5317516763084112
Validation loss: 2.892641549764117

Epoch: 6| Step: 5
Training loss: 0.6768822933941803
Validation loss: 2.8948920707590795

Epoch: 6| Step: 6
Training loss: 0.5366234818354222
Validation loss: 2.956670123431204

Epoch: 6| Step: 7
Training loss: 0.4763911517669989
Validation loss: 3.00991704066068

Epoch: 6| Step: 8
Training loss: 0.7439890228994751
Validation loss: 2.9891000461164494

Epoch: 6| Step: 9
Training loss: 0.48691785055768805
Validation loss: 2.9724392103647745

Epoch: 6| Step: 10
Training loss: 0.595906307402299
Validation loss: 2.9176325197912463

Epoch: 6| Step: 11
Training loss: 1.4089434789904618
Validation loss: 2.888307855834533

Epoch: 6| Step: 12
Training loss: 1.0898392653287545
Validation loss: 2.8943178936519667

Epoch: 6| Step: 13
Training loss: 0.681907667082079
Validation loss: 2.9344153745755994

Epoch: 200| Step: 0
Training loss: 0.6111220478634954
Validation loss: 2.931996174226514

Epoch: 6| Step: 1
Training loss: 0.5705593306576375
Validation loss: 2.889782262077335

Epoch: 6| Step: 2
Training loss: 0.6029560741981248
Validation loss: 2.9470756103797

Epoch: 6| Step: 3
Training loss: 0.774972567534234
Validation loss: 2.9689405681280343

Epoch: 6| Step: 4
Training loss: 0.6645003726404206
Validation loss: 3.0184402304252367

Epoch: 6| Step: 5
Training loss: 0.608271651428671
Validation loss: 2.8808500921239917

Epoch: 6| Step: 6
Training loss: 1.0284190768988546
Validation loss: 2.913589643715977

Epoch: 6| Step: 7
Training loss: 0.5830849447936391
Validation loss: 2.8242950780885905

Epoch: 6| Step: 8
Training loss: 0.37887826796569324
Validation loss: 2.9233042031608925

Epoch: 6| Step: 9
Training loss: 1.3979714325563277
Validation loss: 2.8752955132796556

Epoch: 6| Step: 10
Training loss: 0.5922464608102396
Validation loss: 2.91454849076912

Epoch: 6| Step: 11
Training loss: 0.45658973821478405
Validation loss: 3.017912897759566

Epoch: 6| Step: 12
Training loss: 0.6561607345541899
Validation loss: 2.910172867354157

Epoch: 6| Step: 13
Training loss: 0.5472471061149052
Validation loss: 2.849477930939693

Epoch: 201| Step: 0
Training loss: 0.5895217370206769
Validation loss: 2.909695200059964

Epoch: 6| Step: 1
Training loss: 0.7991897025847294
Validation loss: 2.921261116042593

Epoch: 6| Step: 2
Training loss: 0.9828449043790393
Validation loss: 2.991976605213384

Epoch: 6| Step: 3
Training loss: 0.36237809499186713
Validation loss: 2.8574540681170575

Epoch: 6| Step: 4
Training loss: 0.4889951750998989
Validation loss: 2.932065095612122

Epoch: 6| Step: 5
Training loss: 0.6263684074406628
Validation loss: 2.9553278220627495

Epoch: 6| Step: 6
Training loss: 0.6742658216326626
Validation loss: 2.8692289701934595

Epoch: 6| Step: 7
Training loss: 0.6852956023353051
Validation loss: 2.9741767807526047

Epoch: 6| Step: 8
Training loss: 0.6847535675780391
Validation loss: 2.8871969705302405

Epoch: 6| Step: 9
Training loss: 1.4617046443191324
Validation loss: 2.818337112377603

Epoch: 6| Step: 10
Training loss: 0.38270676378742646
Validation loss: 2.8775887513359133

Epoch: 6| Step: 11
Training loss: 0.627169800391247
Validation loss: 3.0004728527412188

Epoch: 6| Step: 12
Training loss: 0.6894955716561456
Validation loss: 2.956772134868064

Epoch: 6| Step: 13
Training loss: 0.6720591891453849
Validation loss: 2.858646501525468

Epoch: 202| Step: 0
Training loss: 0.5386190387133014
Validation loss: 2.9523709930780786

Epoch: 6| Step: 1
Training loss: 0.6662151004389436
Validation loss: 2.9233562502366923

Epoch: 6| Step: 2
Training loss: 0.6976746286532359
Validation loss: 2.8990358213229444

Epoch: 6| Step: 3
Training loss: 0.5779312427702227
Validation loss: 2.996885683254788

Epoch: 6| Step: 4
Training loss: 0.6747436495832273
Validation loss: 2.9289827982756758

Epoch: 6| Step: 5
Training loss: 0.5323582477571641
Validation loss: 2.9014520177998198

Epoch: 6| Step: 6
Training loss: 0.6460970729756266
Validation loss: 2.929434491570729

Epoch: 6| Step: 7
Training loss: 0.5137195637544096
Validation loss: 2.9465414058663737

Epoch: 6| Step: 8
Training loss: 0.43440236478823996
Validation loss: 2.933859727148693

Epoch: 6| Step: 9
Training loss: 0.945303672560153
Validation loss: 2.8792991421848058

Epoch: 6| Step: 10
Training loss: 0.6513449280465589
Validation loss: 3.035920402464314

Epoch: 6| Step: 11
Training loss: 0.46404826595170245
Validation loss: 2.8172903168038066

Epoch: 6| Step: 12
Training loss: 0.6199953695478112
Validation loss: 2.984971457855576

Epoch: 6| Step: 13
Training loss: 1.4430986925240927
Validation loss: 2.8793586227164316

Epoch: 203| Step: 0
Training loss: 1.003945791452857
Validation loss: 2.960518075028043

Epoch: 6| Step: 1
Training loss: 0.606505754932545
Validation loss: 2.922981025674238

Epoch: 6| Step: 2
Training loss: 1.417755531274684
Validation loss: 2.9007674292493624

Epoch: 6| Step: 3
Training loss: 0.4725950217194269
Validation loss: 2.9095674947560393

Epoch: 6| Step: 4
Training loss: 0.4771095325600261
Validation loss: 2.9177844811966414

Epoch: 6| Step: 5
Training loss: 0.6251441312538701
Validation loss: 2.805675746894722

Epoch: 6| Step: 6
Training loss: 0.5449711220203652
Validation loss: 2.883931949708544

Epoch: 6| Step: 7
Training loss: 0.5309559344795522
Validation loss: 2.8495874401884183

Epoch: 6| Step: 8
Training loss: 0.354893648846062
Validation loss: 2.924611026081896

Epoch: 6| Step: 9
Training loss: 0.8552498036473285
Validation loss: 2.87298529978416

Epoch: 6| Step: 10
Training loss: 0.43426609320679316
Validation loss: 2.906085949714721

Epoch: 6| Step: 11
Training loss: 0.748852447926637
Validation loss: 2.9245124377936595

Epoch: 6| Step: 12
Training loss: 0.6546626648482762
Validation loss: 2.8138669400887912

Epoch: 6| Step: 13
Training loss: 0.605280496187463
Validation loss: 2.8971937995199997

Epoch: 204| Step: 0
Training loss: 1.3295703876709515
Validation loss: 2.879647272152932

Epoch: 6| Step: 1
Training loss: 0.4971744750478899
Validation loss: 2.858222979499703

Epoch: 6| Step: 2
Training loss: 0.8065148872117737
Validation loss: 2.9107232482330856

Epoch: 6| Step: 3
Training loss: 0.5502678663186095
Validation loss: 2.9005956438175433

Epoch: 6| Step: 4
Training loss: 0.5171396377406061
Validation loss: 2.8824864782946467

Epoch: 6| Step: 5
Training loss: 0.7217629762731043
Validation loss: 2.864040716393308

Epoch: 6| Step: 6
Training loss: 0.8492350839063508
Validation loss: 2.8149458810991823

Epoch: 6| Step: 7
Training loss: 0.49890862504660805
Validation loss: 2.9413484970441437

Epoch: 6| Step: 8
Training loss: 0.40870165156895744
Validation loss: 2.953448834568202

Epoch: 6| Step: 9
Training loss: 0.5104571799983295
Validation loss: 2.9099164962148727

Epoch: 6| Step: 10
Training loss: 0.4958359957337693
Validation loss: 2.8367032785290536

Epoch: 6| Step: 11
Training loss: 0.6465971465159613
Validation loss: 2.865665804628967

Epoch: 6| Step: 12
Training loss: 0.4541587547464688
Validation loss: 2.9245699933226947

Epoch: 6| Step: 13
Training loss: 0.5836899694661529
Validation loss: 2.8305193493712992

Epoch: 205| Step: 0
Training loss: 0.40909377040488537
Validation loss: 2.898636275584689

Epoch: 6| Step: 1
Training loss: 0.7917028008964963
Validation loss: 2.9695620982056408

Epoch: 6| Step: 2
Training loss: 0.5461973624106732
Validation loss: 2.9085702692122877

Epoch: 6| Step: 3
Training loss: 0.5349158979427109
Validation loss: 2.882011447010166

Epoch: 6| Step: 4
Training loss: 0.45127322557229504
Validation loss: 2.9172285129175224

Epoch: 6| Step: 5
Training loss: 0.4262887747179946
Validation loss: 2.799743672967781

Epoch: 6| Step: 6
Training loss: 1.603217632748
Validation loss: 2.815612370684628

Epoch: 6| Step: 7
Training loss: 0.808025436817737
Validation loss: 2.8335934173665125

Epoch: 6| Step: 8
Training loss: 0.4907254195254134
Validation loss: 2.912145029792522

Epoch: 6| Step: 9
Training loss: 0.5969613716784995
Validation loss: 2.943407800415725

Epoch: 6| Step: 10
Training loss: 0.7969372294942094
Validation loss: 2.9369093794947188

Epoch: 6| Step: 11
Training loss: 0.5664660455118645
Validation loss: 2.8244728617756345

Epoch: 6| Step: 12
Training loss: 0.5625072319837424
Validation loss: 2.870478433081136

Epoch: 6| Step: 13
Training loss: 0.6927123368417641
Validation loss: 2.81971806313981

Epoch: 206| Step: 0
Training loss: 0.6884217152493709
Validation loss: 2.9299620368329533

Epoch: 6| Step: 1
Training loss: 0.5422822743014148
Validation loss: 2.8870768654001613

Epoch: 6| Step: 2
Training loss: 0.6333492263464577
Validation loss: 2.9319291283115927

Epoch: 6| Step: 3
Training loss: 0.6957433201671032
Validation loss: 2.86834037393847

Epoch: 6| Step: 4
Training loss: 0.7589287942196815
Validation loss: 2.958309137666285

Epoch: 6| Step: 5
Training loss: 0.7036978613204733
Validation loss: 2.8746375947398155

Epoch: 6| Step: 6
Training loss: 0.7934723180618761
Validation loss: 2.8002634815724448

Epoch: 6| Step: 7
Training loss: 0.6760425393246356
Validation loss: 2.879834008797755

Epoch: 6| Step: 8
Training loss: 0.8732233402519395
Validation loss: 2.85736612372898

Epoch: 6| Step: 9
Training loss: 0.5700808799397923
Validation loss: 2.833895505970423

Epoch: 6| Step: 10
Training loss: 0.5675419438192032
Validation loss: 2.9672619218885963

Epoch: 6| Step: 11
Training loss: 1.3731973275333915
Validation loss: 2.867865777580954

Epoch: 6| Step: 12
Training loss: 0.6182587417003036
Validation loss: 2.9282546544962544

Epoch: 6| Step: 13
Training loss: 0.5773543814995262
Validation loss: 2.9189927952463943

Epoch: 207| Step: 0
Training loss: 0.8591826830597323
Validation loss: 2.8591901305979697

Epoch: 6| Step: 1
Training loss: 0.6230484534934208
Validation loss: 2.9245574388138014

Epoch: 6| Step: 2
Training loss: 0.7411373539160537
Validation loss: 2.8222540796873137

Epoch: 6| Step: 3
Training loss: 0.6525363751938127
Validation loss: 2.904530348005604

Epoch: 6| Step: 4
Training loss: 0.4986448400819713
Validation loss: 2.955667050867073

Epoch: 6| Step: 5
Training loss: 0.43686964400123063
Validation loss: 2.837375623018864

Epoch: 6| Step: 6
Training loss: 0.3730571405885689
Validation loss: 2.9245082392936026

Epoch: 6| Step: 7
Training loss: 0.6291188182909865
Validation loss: 2.9129676841735663

Epoch: 6| Step: 8
Training loss: 0.669433215340828
Validation loss: 2.9044405729124843

Epoch: 6| Step: 9
Training loss: 0.5709501907950969
Validation loss: 2.953913171399057

Epoch: 6| Step: 10
Training loss: 0.6177210372810669
Validation loss: 2.9520057292923987

Epoch: 6| Step: 11
Training loss: 0.5551478664925811
Validation loss: 2.8508496930781897

Epoch: 6| Step: 12
Training loss: 0.5053674964961044
Validation loss: 2.8203691668818758

Epoch: 6| Step: 13
Training loss: 1.554740253109397
Validation loss: 2.953194632541843

Epoch: 208| Step: 0
Training loss: 0.7083516305542397
Validation loss: 2.9334877221883437

Epoch: 6| Step: 1
Training loss: 0.6678376989470249
Validation loss: 2.8513244529545996

Epoch: 6| Step: 2
Training loss: 0.6334511160081082
Validation loss: 2.8475801992356065

Epoch: 6| Step: 3
Training loss: 0.5600124296869534
Validation loss: 2.9531562171106875

Epoch: 6| Step: 4
Training loss: 0.48528029841621384
Validation loss: 2.8165437521064187

Epoch: 6| Step: 5
Training loss: 0.5370409557807324
Validation loss: 2.9645415408811466

Epoch: 6| Step: 6
Training loss: 1.3583162064827996
Validation loss: 2.819737397766046

Epoch: 6| Step: 7
Training loss: 0.5121958015890963
Validation loss: 2.788576014215409

Epoch: 6| Step: 8
Training loss: 0.6052945286294122
Validation loss: 2.8649021017558987

Epoch: 6| Step: 9
Training loss: 0.8109195449987616
Validation loss: 2.800297878519381

Epoch: 6| Step: 10
Training loss: 0.7919094733944144
Validation loss: 2.885048582283922

Epoch: 6| Step: 11
Training loss: 1.0144768313699497
Validation loss: 2.993039945152113

Epoch: 6| Step: 12
Training loss: 0.452279354117052
Validation loss: 2.81395020007559

Epoch: 6| Step: 13
Training loss: 0.4678165678715102
Validation loss: 2.890450219721275

Epoch: 209| Step: 0
Training loss: 0.4777155357008655
Validation loss: 2.885302755997062

Epoch: 6| Step: 1
Training loss: 0.6474641135297526
Validation loss: 2.9135095311996344

Epoch: 6| Step: 2
Training loss: 0.5675095697259875
Validation loss: 2.8608387325675575

Epoch: 6| Step: 3
Training loss: 0.6582582037545258
Validation loss: 2.8511582597542557

Epoch: 6| Step: 4
Training loss: 0.7047451004204427
Validation loss: 2.8393138336863935

Epoch: 6| Step: 5
Training loss: 0.6203106675973727
Validation loss: 2.9308431694148442

Epoch: 6| Step: 6
Training loss: 0.6665056501093258
Validation loss: 2.8773176830256197

Epoch: 6| Step: 7
Training loss: 1.2872452845039761
Validation loss: 2.9224266578645444

Epoch: 6| Step: 8
Training loss: 0.6048780697915936
Validation loss: 2.8723620184772383

Epoch: 6| Step: 9
Training loss: 0.6740351483309543
Validation loss: 2.889710290196774

Epoch: 6| Step: 10
Training loss: 0.6522162307091831
Validation loss: 2.9122653222665695

Epoch: 6| Step: 11
Training loss: 0.6759839057247963
Validation loss: 2.9001337796080224

Epoch: 6| Step: 12
Training loss: 0.8892368407177981
Validation loss: 2.86756790506433

Epoch: 6| Step: 13
Training loss: 0.717480533548448
Validation loss: 2.893893550445844

Epoch: 210| Step: 0
Training loss: 0.5951428389396531
Validation loss: 2.913664626162666

Epoch: 6| Step: 1
Training loss: 0.6233830755661874
Validation loss: 2.8932928609947233

Epoch: 6| Step: 2
Training loss: 0.4606388061762883
Validation loss: 2.820480778429896

Epoch: 6| Step: 3
Training loss: 0.6497702632737128
Validation loss: 2.8572380682998495

Epoch: 6| Step: 4
Training loss: 1.292842939542688
Validation loss: 2.86875220072211

Epoch: 6| Step: 5
Training loss: 0.56000354233541
Validation loss: 3.0398912778871066

Epoch: 6| Step: 6
Training loss: 0.4361382135175536
Validation loss: 2.8988163264358806

Epoch: 6| Step: 7
Training loss: 0.4768236101590969
Validation loss: 2.8929681027822296

Epoch: 6| Step: 8
Training loss: 0.9909386171486824
Validation loss: 2.9637211285486327

Epoch: 6| Step: 9
Training loss: 0.6880185599124685
Validation loss: 2.874894706898811

Epoch: 6| Step: 10
Training loss: 0.5075211202520614
Validation loss: 2.957544078224345

Epoch: 6| Step: 11
Training loss: 0.692135313318571
Validation loss: 2.91212532624128

Epoch: 6| Step: 12
Training loss: 0.5931515438302523
Validation loss: 3.007705118483626

Epoch: 6| Step: 13
Training loss: 0.5767817227800379
Validation loss: 2.9064760838011394

Epoch: 211| Step: 0
Training loss: 0.40935146759187613
Validation loss: 2.8706495430133394

Epoch: 6| Step: 1
Training loss: 0.44876671313665956
Validation loss: 2.8997122265547763

Epoch: 6| Step: 2
Training loss: 0.6349054035928969
Validation loss: 2.856544441611481

Epoch: 6| Step: 3
Training loss: 0.654990918445965
Validation loss: 2.941849403721135

Epoch: 6| Step: 4
Training loss: 0.44921345914959143
Validation loss: 2.90031684755966

Epoch: 6| Step: 5
Training loss: 0.40540205052261363
Validation loss: 2.8506303352295435

Epoch: 6| Step: 6
Training loss: 0.5455888610792102
Validation loss: 2.903686076114884

Epoch: 6| Step: 7
Training loss: 0.6460850337961604
Validation loss: 2.8952256166501726

Epoch: 6| Step: 8
Training loss: 0.6031917703066503
Validation loss: 2.876731254549492

Epoch: 6| Step: 9
Training loss: 0.746014975338676
Validation loss: 2.904722297600928

Epoch: 6| Step: 10
Training loss: 1.4875008847530522
Validation loss: 2.959721029340946

Epoch: 6| Step: 11
Training loss: 0.5569677629713032
Validation loss: 2.8686259972194383

Epoch: 6| Step: 12
Training loss: 0.5361005707376093
Validation loss: 2.9119757168118907

Epoch: 6| Step: 13
Training loss: 0.557005404692681
Validation loss: 2.9166247410258648

Epoch: 212| Step: 0
Training loss: 0.3903985702380984
Validation loss: 2.9059529033011575

Epoch: 6| Step: 1
Training loss: 0.5447424042738068
Validation loss: 2.9594406598657734

Epoch: 6| Step: 2
Training loss: 0.5266392275547376
Validation loss: 2.924917585075874

Epoch: 6| Step: 3
Training loss: 1.3280890516016122
Validation loss: 2.877699124019495

Epoch: 6| Step: 4
Training loss: 0.40965114554416504
Validation loss: 2.9839953568868163

Epoch: 6| Step: 5
Training loss: 0.5412147513578377
Validation loss: 2.8797329630499706

Epoch: 6| Step: 6
Training loss: 0.6753904502608082
Validation loss: 2.908455753391416

Epoch: 6| Step: 7
Training loss: 0.9198689050670795
Validation loss: 2.8645880589301695

Epoch: 6| Step: 8
Training loss: 0.8304324482172487
Validation loss: 2.765370186599087

Epoch: 6| Step: 9
Training loss: 0.795200795720986
Validation loss: 2.9124799834124313

Epoch: 6| Step: 10
Training loss: 0.4681470171610825
Validation loss: 2.82713240035301

Epoch: 6| Step: 11
Training loss: 0.4332385799390867
Validation loss: 2.881273005042703

Epoch: 6| Step: 12
Training loss: 0.5310979793926739
Validation loss: 2.8507536276526864

Epoch: 6| Step: 13
Training loss: 0.5622160512768143
Validation loss: 2.9381235962300214

Epoch: 213| Step: 0
Training loss: 0.5394631431141049
Validation loss: 2.8690038847100867

Epoch: 6| Step: 1
Training loss: 0.5256040912329595
Validation loss: 2.8561169488303015

Epoch: 6| Step: 2
Training loss: 0.6813879555824849
Validation loss: 2.934536284272171

Epoch: 6| Step: 3
Training loss: 1.253791019457067
Validation loss: 2.9500494117693514

Epoch: 6| Step: 4
Training loss: 0.6473369220702261
Validation loss: 2.9559549836373225

Epoch: 6| Step: 5
Training loss: 0.671848851072103
Validation loss: 2.982591705383276

Epoch: 6| Step: 6
Training loss: 0.7066054352812295
Validation loss: 3.0006229230749994

Epoch: 6| Step: 7
Training loss: 0.35157116773304703
Validation loss: 2.9009606277588755

Epoch: 6| Step: 8
Training loss: 0.7833190223387604
Validation loss: 2.9393769077968335

Epoch: 6| Step: 9
Training loss: 0.6330187190739653
Validation loss: 2.9545770536747007

Epoch: 6| Step: 10
Training loss: 0.6114825215231762
Validation loss: 2.999136283835796

Epoch: 6| Step: 11
Training loss: 0.5181307739193781
Validation loss: 2.8744842439857665

Epoch: 6| Step: 12
Training loss: 0.5805032886687971
Validation loss: 2.90700867023975

Epoch: 6| Step: 13
Training loss: 0.46592423341465644
Validation loss: 2.8859622912262037

Epoch: 214| Step: 0
Training loss: 0.5377313515210839
Validation loss: 2.91027412602522

Epoch: 6| Step: 1
Training loss: 0.75051941369633
Validation loss: 2.9156512854489387

Epoch: 6| Step: 2
Training loss: 0.4794597731314743
Validation loss: 2.8638356891956804

Epoch: 6| Step: 3
Training loss: 0.4534065752900487
Validation loss: 2.92343776477926

Epoch: 6| Step: 4
Training loss: 0.5891467390867442
Validation loss: 2.878710667226482

Epoch: 6| Step: 5
Training loss: 0.6931938726056408
Validation loss: 2.9208989680629953

Epoch: 6| Step: 6
Training loss: 0.8160110685331777
Validation loss: 2.9302361139977875

Epoch: 6| Step: 7
Training loss: 0.5045159370128169
Validation loss: 2.9650226014698045

Epoch: 6| Step: 8
Training loss: 0.42507792487733065
Validation loss: 2.8957151530642222

Epoch: 6| Step: 9
Training loss: 0.5756952674465128
Validation loss: 2.92985993280533

Epoch: 6| Step: 10
Training loss: 0.6585359948515506
Validation loss: 2.8966987240740036

Epoch: 6| Step: 11
Training loss: 0.5110219331558143
Validation loss: 3.0084881176495433

Epoch: 6| Step: 12
Training loss: 0.5359280999696668
Validation loss: 2.949200493290795

Epoch: 6| Step: 13
Training loss: 1.281644481314799
Validation loss: 2.8334381888191604

Epoch: 215| Step: 0
Training loss: 0.6598334567228958
Validation loss: 2.868813839093366

Epoch: 6| Step: 1
Training loss: 0.43288914246331955
Validation loss: 2.855139536390032

Epoch: 6| Step: 2
Training loss: 0.49188465307668733
Validation loss: 2.8829911477302232

Epoch: 6| Step: 3
Training loss: 0.6040905926482626
Validation loss: 2.9080274062126747

Epoch: 6| Step: 4
Training loss: 0.4786507240629443
Validation loss: 2.928857656994776

Epoch: 6| Step: 5
Training loss: 0.33382212172131365
Validation loss: 2.908438046892087

Epoch: 6| Step: 6
Training loss: 0.890448870727313
Validation loss: 2.919475038970847

Epoch: 6| Step: 7
Training loss: 0.954796497971721
Validation loss: 2.8552375000544035

Epoch: 6| Step: 8
Training loss: 0.6134251468248305
Validation loss: 2.8772710731091067

Epoch: 6| Step: 9
Training loss: 1.3437391768618454
Validation loss: 2.920472731666898

Epoch: 6| Step: 10
Training loss: 0.5870375923746216
Validation loss: 2.8531187365916857

Epoch: 6| Step: 11
Training loss: 0.6286230456613323
Validation loss: 2.8742970560931327

Epoch: 6| Step: 12
Training loss: 0.7748833830063521
Validation loss: 2.949910616194047

Epoch: 6| Step: 13
Training loss: 0.6473367379168086
Validation loss: 2.9216306859651753

Epoch: 216| Step: 0
Training loss: 0.4924120466488235
Validation loss: 2.876468677223564

Epoch: 6| Step: 1
Training loss: 0.5412241674958562
Validation loss: 2.8802466686013077

Epoch: 6| Step: 2
Training loss: 0.5554339799045088
Validation loss: 2.900824647704325

Epoch: 6| Step: 3
Training loss: 1.5072053467613191
Validation loss: 2.939382396366678

Epoch: 6| Step: 4
Training loss: 0.7436715797947104
Validation loss: 2.8779492109516918

Epoch: 6| Step: 5
Training loss: 0.6326174494291437
Validation loss: 2.9457468375349514

Epoch: 6| Step: 6
Training loss: 0.4527470887236411
Validation loss: 2.9640908606738767

Epoch: 6| Step: 7
Training loss: 0.6218798479054177
Validation loss: 2.9552967220117963

Epoch: 6| Step: 8
Training loss: 0.9202805000272845
Validation loss: 2.9843257280846

Epoch: 6| Step: 9
Training loss: 0.6596020059197659
Validation loss: 2.9321651036179874

Epoch: 6| Step: 10
Training loss: 0.5671781870179865
Validation loss: 2.936235020213474

Epoch: 6| Step: 11
Training loss: 0.731706193306688
Validation loss: 2.8335125857104493

Epoch: 6| Step: 12
Training loss: 0.8393618243355764
Validation loss: 2.824939394894367

Epoch: 6| Step: 13
Training loss: 0.6989795979099623
Validation loss: 2.913287512275592

Epoch: 217| Step: 0
Training loss: 0.8255966745350274
Validation loss: 2.919238391778766

Epoch: 6| Step: 1
Training loss: 0.5115988787542588
Validation loss: 2.9246425067853554

Epoch: 6| Step: 2
Training loss: 0.6268795124701644
Validation loss: 2.835270350425445

Epoch: 6| Step: 3
Training loss: 0.5176184584538893
Validation loss: 2.8960994671351057

Epoch: 6| Step: 4
Training loss: 0.6465029526544988
Validation loss: 2.9425286072167145

Epoch: 6| Step: 5
Training loss: 0.5745131587753391
Validation loss: 2.8961074662756294

Epoch: 6| Step: 6
Training loss: 0.45508107196688646
Validation loss: 2.813220772397296

Epoch: 6| Step: 7
Training loss: 0.7460688242318685
Validation loss: 2.918040460661186

Epoch: 6| Step: 8
Training loss: 0.5831105510724649
Validation loss: 2.8184628043579276

Epoch: 6| Step: 9
Training loss: 0.44380337165842804
Validation loss: 2.9196145668897886

Epoch: 6| Step: 10
Training loss: 0.6154392446286152
Validation loss: 2.8822987140826246

Epoch: 6| Step: 11
Training loss: 0.6898600860424074
Validation loss: 2.9074087943294034

Epoch: 6| Step: 12
Training loss: 0.5407898083891085
Validation loss: 2.8857490999899587

Epoch: 6| Step: 13
Training loss: 1.4812916101977147
Validation loss: 2.870629748437322

Epoch: 218| Step: 0
Training loss: 0.5719196979585592
Validation loss: 2.96462132654532

Epoch: 6| Step: 1
Training loss: 0.6709388598573547
Validation loss: 2.912338401338856

Epoch: 6| Step: 2
Training loss: 0.5683373253599157
Validation loss: 2.9515477430689265

Epoch: 6| Step: 3
Training loss: 0.8607146139036863
Validation loss: 2.9567802991251337

Epoch: 6| Step: 4
Training loss: 0.9014804888733341
Validation loss: 2.86704271108593

Epoch: 6| Step: 5
Training loss: 0.48691312236672174
Validation loss: 2.9266711088449515

Epoch: 6| Step: 6
Training loss: 0.5521485691994725
Validation loss: 2.9520762631680055

Epoch: 6| Step: 7
Training loss: 0.49761165976064964
Validation loss: 2.9129948027905224

Epoch: 6| Step: 8
Training loss: 0.5154371208299612
Validation loss: 2.944077290930166

Epoch: 6| Step: 9
Training loss: 0.9021640284847537
Validation loss: 2.910358628440925

Epoch: 6| Step: 10
Training loss: 1.4756862724925641
Validation loss: 2.94493159926577

Epoch: 6| Step: 11
Training loss: 0.45137523015052594
Validation loss: 2.921456196463716

Epoch: 6| Step: 12
Training loss: 0.4773729343514452
Validation loss: 2.938936247641346

Epoch: 6| Step: 13
Training loss: 0.472648084585735
Validation loss: 2.863474243931909

Epoch: 219| Step: 0
Training loss: 0.6290743822244298
Validation loss: 2.9942371861298116

Epoch: 6| Step: 1
Training loss: 0.531318996661209
Validation loss: 2.8900352082533263

Epoch: 6| Step: 2
Training loss: 0.5311574013734518
Validation loss: 2.920689524231629

Epoch: 6| Step: 3
Training loss: 0.4953483177495723
Validation loss: 2.877703266537479

Epoch: 6| Step: 4
Training loss: 0.4990158229776963
Validation loss: 2.9372532382425254

Epoch: 6| Step: 5
Training loss: 0.7570731105194735
Validation loss: 2.9455332112609

Epoch: 6| Step: 6
Training loss: 0.46175431761610247
Validation loss: 2.9714733415263983

Epoch: 6| Step: 7
Training loss: 0.5918216259504824
Validation loss: 2.8693724716686115

Epoch: 6| Step: 8
Training loss: 1.3188461196365076
Validation loss: 2.9381511994501377

Epoch: 6| Step: 9
Training loss: 0.7239874872791348
Validation loss: 2.894142141885386

Epoch: 6| Step: 10
Training loss: 0.5525215197381114
Validation loss: 2.9028150707163265

Epoch: 6| Step: 11
Training loss: 0.4937298239436599
Validation loss: 2.964470492637281

Epoch: 6| Step: 12
Training loss: 0.864345740031998
Validation loss: 2.873453761060462

Epoch: 6| Step: 13
Training loss: 0.5986767452479463
Validation loss: 2.9308887511231063

Epoch: 220| Step: 0
Training loss: 1.4669568092733465
Validation loss: 2.8123224696890405

Epoch: 6| Step: 1
Training loss: 0.5062526220088922
Validation loss: 2.776050894449343

Epoch: 6| Step: 2
Training loss: 0.6302543549771162
Validation loss: 2.731968283752609

Epoch: 6| Step: 3
Training loss: 0.46325286340832145
Validation loss: 2.8499250474632927

Epoch: 6| Step: 4
Training loss: 0.47565141732317395
Validation loss: 2.9816322305551908

Epoch: 6| Step: 5
Training loss: 0.35945675790663406
Validation loss: 2.919823509439158

Epoch: 6| Step: 6
Training loss: 0.6133055712499867
Validation loss: 2.791389413607216

Epoch: 6| Step: 7
Training loss: 0.640051701513758
Validation loss: 2.9633401401071144

Epoch: 6| Step: 8
Training loss: 0.4356532629797364
Validation loss: 3.010491133740128

Epoch: 6| Step: 9
Training loss: 0.4552419474024155
Validation loss: 2.833794981615319

Epoch: 6| Step: 10
Training loss: 0.6118284378025629
Validation loss: 2.9120894938181943

Epoch: 6| Step: 11
Training loss: 0.6209530461078205
Validation loss: 2.930130446115679

Epoch: 6| Step: 12
Training loss: 0.5774727828147532
Validation loss: 2.865319997682184

Epoch: 6| Step: 13
Training loss: 0.5931235823699764
Validation loss: 2.9150271485222055

Epoch: 221| Step: 0
Training loss: 0.455145474799725
Validation loss: 2.9307394351692335

Epoch: 6| Step: 1
Training loss: 0.5259348663336668
Validation loss: 2.861788372220757

Epoch: 6| Step: 2
Training loss: 0.36120665286866444
Validation loss: 2.918105633311151

Epoch: 6| Step: 3
Training loss: 0.46871541213538326
Validation loss: 2.777295025891263

Epoch: 6| Step: 4
Training loss: 0.7463467553448025
Validation loss: 3.0013035088106137

Epoch: 6| Step: 5
Training loss: 0.4813639357312359
Validation loss: 2.89989184747918

Epoch: 6| Step: 6
Training loss: 0.5235324318047669
Validation loss: 2.9217658881011705

Epoch: 6| Step: 7
Training loss: 0.6085002930247871
Validation loss: 2.9512797381593763

Epoch: 6| Step: 8
Training loss: 1.4651807880492773
Validation loss: 2.826119626961033

Epoch: 6| Step: 9
Training loss: 0.3343775481724126
Validation loss: 2.8801780731285525

Epoch: 6| Step: 10
Training loss: 0.641352798334888
Validation loss: 2.9360813340459866

Epoch: 6| Step: 11
Training loss: 0.7149563893443052
Validation loss: 2.9143234013409973

Epoch: 6| Step: 12
Training loss: 0.4440918304292353
Validation loss: 2.989484929360429

Epoch: 6| Step: 13
Training loss: 0.4717102672702482
Validation loss: 2.9006720032870454

Epoch: 222| Step: 0
Training loss: 0.4273426578933179
Validation loss: 2.9082729586553073

Epoch: 6| Step: 1
Training loss: 0.7321524569583185
Validation loss: 2.8602549548650087

Epoch: 6| Step: 2
Training loss: 0.4903060587112829
Validation loss: 2.888173426365416

Epoch: 6| Step: 3
Training loss: 0.4817537012576663
Validation loss: 2.8516219877543922

Epoch: 6| Step: 4
Training loss: 1.3101806128823623
Validation loss: 2.9004248894274096

Epoch: 6| Step: 5
Training loss: 0.7528194044912122
Validation loss: 3.004483488698058

Epoch: 6| Step: 6
Training loss: 0.5833544954366867
Validation loss: 2.9046159477921862

Epoch: 6| Step: 7
Training loss: 0.5237090132524249
Validation loss: 2.9498353966087287

Epoch: 6| Step: 8
Training loss: 0.4985153538043037
Validation loss: 2.8767301771314666

Epoch: 6| Step: 9
Training loss: 0.48418567402944557
Validation loss: 2.98232760943464

Epoch: 6| Step: 10
Training loss: 0.45543913376903694
Validation loss: 2.9485789701898506

Epoch: 6| Step: 11
Training loss: 0.7700728625961119
Validation loss: 2.9653253846785246

Epoch: 6| Step: 12
Training loss: 0.5289744278256053
Validation loss: 2.9160484521631598

Epoch: 6| Step: 13
Training loss: 0.5703614880150367
Validation loss: 2.9096917995742997

Epoch: 223| Step: 0
Training loss: 0.5964308249387762
Validation loss: 2.8915279181078826

Epoch: 6| Step: 1
Training loss: 0.9221337165518796
Validation loss: 2.972158061926462

Epoch: 6| Step: 2
Training loss: 0.8391908813803914
Validation loss: 2.947488535782443

Epoch: 6| Step: 3
Training loss: 0.5074353504814312
Validation loss: 2.9343606392614294

Epoch: 6| Step: 4
Training loss: 0.4056374994359359
Validation loss: 2.8940160981903467

Epoch: 6| Step: 5
Training loss: 0.4819784868195851
Validation loss: 2.8834459527206238

Epoch: 6| Step: 6
Training loss: 0.4484346927993581
Validation loss: 2.889558488830238

Epoch: 6| Step: 7
Training loss: 0.4576775146784946
Validation loss: 2.859735587753065

Epoch: 6| Step: 8
Training loss: 1.322222169418405
Validation loss: 2.9192365677813568

Epoch: 6| Step: 9
Training loss: 0.6958198839208896
Validation loss: 2.8816806876784833

Epoch: 6| Step: 10
Training loss: 0.6159461853715575
Validation loss: 2.9144471624565886

Epoch: 6| Step: 11
Training loss: 0.6496514596341809
Validation loss: 2.894734034468462

Epoch: 6| Step: 12
Training loss: 0.624414598967674
Validation loss: 2.9652796890963358

Epoch: 6| Step: 13
Training loss: 0.47954296456972095
Validation loss: 2.972899845951633

Epoch: 224| Step: 0
Training loss: 0.39617347742537834
Validation loss: 2.979688869850072

Epoch: 6| Step: 1
Training loss: 0.6034909585893358
Validation loss: 2.988317046439329

Epoch: 6| Step: 2
Training loss: 0.7423986034324681
Validation loss: 2.9425572089265457

Epoch: 6| Step: 3
Training loss: 0.43339970688636137
Validation loss: 2.93555277681889

Epoch: 6| Step: 4
Training loss: 0.4094397690182713
Validation loss: 2.9937864169969948

Epoch: 6| Step: 5
Training loss: 0.7198352912751962
Validation loss: 2.9748608121181124

Epoch: 6| Step: 6
Training loss: 0.9057522426222631
Validation loss: 2.965661017919718

Epoch: 6| Step: 7
Training loss: 0.5297565786503184
Validation loss: 2.933314527285142

Epoch: 6| Step: 8
Training loss: 0.5596801490237052
Validation loss: 2.8269758893264383

Epoch: 6| Step: 9
Training loss: 0.5715089293372235
Validation loss: 2.9468233262430044

Epoch: 6| Step: 10
Training loss: 0.5602178372160603
Validation loss: 2.9801422913607323

Epoch: 6| Step: 11
Training loss: 1.3204082928278953
Validation loss: 2.9254720513449586

Epoch: 6| Step: 12
Training loss: 0.6173933868805971
Validation loss: 2.813997322215903

Epoch: 6| Step: 13
Training loss: 0.5535097648186554
Validation loss: 2.876765303513837

Epoch: 225| Step: 0
Training loss: 0.48989698494931233
Validation loss: 2.8426315148135233

Epoch: 6| Step: 1
Training loss: 0.6174160497951253
Validation loss: 2.8630816505879375

Epoch: 6| Step: 2
Training loss: 1.2973953490050258
Validation loss: 2.920446117889583

Epoch: 6| Step: 3
Training loss: 0.4826220510215345
Validation loss: 2.908859462386012

Epoch: 6| Step: 4
Training loss: 0.5596751169850823
Validation loss: 2.9772351323466912

Epoch: 6| Step: 5
Training loss: 0.7343842931930485
Validation loss: 2.9014432390607916

Epoch: 6| Step: 6
Training loss: 0.6973835821312548
Validation loss: 2.8660336146613945

Epoch: 6| Step: 7
Training loss: 0.3448428641317835
Validation loss: 2.848381267640542

Epoch: 6| Step: 8
Training loss: 0.7192002420408035
Validation loss: 2.9034272298363324

Epoch: 6| Step: 9
Training loss: 0.7712658536447021
Validation loss: 2.9530779180524354

Epoch: 6| Step: 10
Training loss: 0.8561859608112927
Validation loss: 2.9041486410259325

Epoch: 6| Step: 11
Training loss: 0.9961369822974966
Validation loss: 2.9716878442300287

Epoch: 6| Step: 12
Training loss: 0.6448257235980756
Validation loss: 2.8384912375540607

Epoch: 6| Step: 13
Training loss: 0.5866268172285739
Validation loss: 2.9288118537322574

Epoch: 226| Step: 0
Training loss: 0.822252540756109
Validation loss: 2.9100154697579446

Epoch: 6| Step: 1
Training loss: 0.6258617658882534
Validation loss: 3.02395061702622

Epoch: 6| Step: 2
Training loss: 0.5476698412548765
Validation loss: 2.9144456217809442

Epoch: 6| Step: 3
Training loss: 0.4253071236253081
Validation loss: 2.7770074210602935

Epoch: 6| Step: 4
Training loss: 0.7460856811726236
Validation loss: 2.8941692652765263

Epoch: 6| Step: 5
Training loss: 0.7712810006858998
Validation loss: 2.9019550321597274

Epoch: 6| Step: 6
Training loss: 0.599486670846202
Validation loss: 2.830827900212505

Epoch: 6| Step: 7
Training loss: 0.6706785816285401
Validation loss: 2.8290776427415123

Epoch: 6| Step: 8
Training loss: 1.429628881701521
Validation loss: 2.897121243674368

Epoch: 6| Step: 9
Training loss: 0.690030685447378
Validation loss: 2.879064561622373

Epoch: 6| Step: 10
Training loss: 0.6530630292193926
Validation loss: 2.907759339456289

Epoch: 6| Step: 11
Training loss: 0.7378193858761245
Validation loss: 2.8997601338643118

Epoch: 6| Step: 12
Training loss: 0.6741996293876306
Validation loss: 2.8794308119384566

Epoch: 6| Step: 13
Training loss: 0.4771896050986952
Validation loss: 2.908836717590253

Epoch: 227| Step: 0
Training loss: 0.7920633041870205
Validation loss: 2.9031751493537405

Epoch: 6| Step: 1
Training loss: 0.6397934610914503
Validation loss: 2.872640277125472

Epoch: 6| Step: 2
Training loss: 0.8926158204247038
Validation loss: 2.8513604636885725

Epoch: 6| Step: 3
Training loss: 0.46011877895047293
Validation loss: 2.9234155004024602

Epoch: 6| Step: 4
Training loss: 0.598618872824039
Validation loss: 2.9063391586355003

Epoch: 6| Step: 5
Training loss: 0.4406278211083971
Validation loss: 2.852985093417994

Epoch: 6| Step: 6
Training loss: 0.34749328351219433
Validation loss: 2.904503423977611

Epoch: 6| Step: 7
Training loss: 0.5637308535316665
Validation loss: 2.923755713657441

Epoch: 6| Step: 8
Training loss: 0.5781828877103531
Validation loss: 2.9499484273206407

Epoch: 6| Step: 9
Training loss: 0.5801467084318335
Validation loss: 2.8786175400625154

Epoch: 6| Step: 10
Training loss: 0.7862911467709572
Validation loss: 2.8119161070377965

Epoch: 6| Step: 11
Training loss: 0.5844169214073042
Validation loss: 2.850768758311371

Epoch: 6| Step: 12
Training loss: 1.3282068563929117
Validation loss: 2.8345283180836933

Epoch: 6| Step: 13
Training loss: 0.4189022548930387
Validation loss: 2.889051184211716

Epoch: 228| Step: 0
Training loss: 0.6608095942615299
Validation loss: 2.8175071649197965

Epoch: 6| Step: 1
Training loss: 0.5262580716019261
Validation loss: 2.8392140469984395

Epoch: 6| Step: 2
Training loss: 0.8246607024944177
Validation loss: 2.8819703178827405

Epoch: 6| Step: 3
Training loss: 0.5972575933740965
Validation loss: 2.893945302613763

Epoch: 6| Step: 4
Training loss: 0.5923593196367267
Validation loss: 2.8943315952785955

Epoch: 6| Step: 5
Training loss: 0.4842673305084747
Validation loss: 2.9092549884872803

Epoch: 6| Step: 6
Training loss: 0.6213391137251592
Validation loss: 2.9687925235312873

Epoch: 6| Step: 7
Training loss: 0.4885686867595366
Validation loss: 2.9531447260229764

Epoch: 6| Step: 8
Training loss: 0.6564238635857512
Validation loss: 2.919009518845134

Epoch: 6| Step: 9
Training loss: 0.5933821442123559
Validation loss: 2.9118679397692833

Epoch: 6| Step: 10
Training loss: 0.6168643733290995
Validation loss: 2.8422470802352304

Epoch: 6| Step: 11
Training loss: 0.5201020511110741
Validation loss: 2.9663435167054306

Epoch: 6| Step: 12
Training loss: 1.3560060870672566
Validation loss: 2.9036214282916135

Epoch: 6| Step: 13
Training loss: 0.6255274454403136
Validation loss: 3.0213949711795207

Epoch: 229| Step: 0
Training loss: 0.7403577636304473
Validation loss: 3.0358525234023923

Epoch: 6| Step: 1
Training loss: 0.6956116322195199
Validation loss: 2.9169677624373214

Epoch: 6| Step: 2
Training loss: 0.773319736339256
Validation loss: 2.926102244174568

Epoch: 6| Step: 3
Training loss: 0.3930528531788523
Validation loss: 2.925951964181572

Epoch: 6| Step: 4
Training loss: 0.3407086295960516
Validation loss: 2.8377520428272858

Epoch: 6| Step: 5
Training loss: 0.5522456080588879
Validation loss: 2.9227220460062147

Epoch: 6| Step: 6
Training loss: 1.263623149704812
Validation loss: 2.94524477232378

Epoch: 6| Step: 7
Training loss: 0.6091749400852506
Validation loss: 2.8868471081819123

Epoch: 6| Step: 8
Training loss: 0.7092908296769688
Validation loss: 2.8296815863353904

Epoch: 6| Step: 9
Training loss: 0.48521941936282387
Validation loss: 3.009202657368325

Epoch: 6| Step: 10
Training loss: 0.3877655849620471
Validation loss: 2.9228200625068874

Epoch: 6| Step: 11
Training loss: 0.7229008028853097
Validation loss: 2.9046853478450916

Epoch: 6| Step: 12
Training loss: 0.42035218303213834
Validation loss: 2.9157504050327505

Epoch: 6| Step: 13
Training loss: 0.41187223508772197
Validation loss: 2.900659222051977

Epoch: 230| Step: 0
Training loss: 0.31147837537159334
Validation loss: 2.7895162731502143

Epoch: 6| Step: 1
Training loss: 0.6242276187500646
Validation loss: 2.9682136720430417

Epoch: 6| Step: 2
Training loss: 0.5440709296049483
Validation loss: 2.960916255717028

Epoch: 6| Step: 3
Training loss: 0.6266539385657897
Validation loss: 2.859447985553181

Epoch: 6| Step: 4
Training loss: 0.5042524405360324
Validation loss: 2.8890931890661893

Epoch: 6| Step: 5
Training loss: 0.45376012948449646
Validation loss: 2.868779584944019

Epoch: 6| Step: 6
Training loss: 0.596096796750423
Validation loss: 2.944745893811963

Epoch: 6| Step: 7
Training loss: 0.9005729838167493
Validation loss: 2.939479472062328

Epoch: 6| Step: 8
Training loss: 0.5286378311779298
Validation loss: 2.924422447263736

Epoch: 6| Step: 9
Training loss: 0.486978670279782
Validation loss: 2.9658573312870176

Epoch: 6| Step: 10
Training loss: 0.39389178886939225
Validation loss: 2.8426756873142742

Epoch: 6| Step: 11
Training loss: 1.3035614270836253
Validation loss: 2.849524277306928

Epoch: 6| Step: 12
Training loss: 0.43478292343397773
Validation loss: 2.9123308833934494

Epoch: 6| Step: 13
Training loss: 0.4337932024830761
Validation loss: 2.875799537827843

Epoch: 231| Step: 0
Training loss: 1.2754218432123978
Validation loss: 2.858605425444964

Epoch: 6| Step: 1
Training loss: 0.6022108968040878
Validation loss: 2.873982111099801

Epoch: 6| Step: 2
Training loss: 0.6386694718528588
Validation loss: 2.9297123751114102

Epoch: 6| Step: 3
Training loss: 0.7468641208510746
Validation loss: 2.9315459329085267

Epoch: 6| Step: 4
Training loss: 0.784638457108279
Validation loss: 2.902517485520744

Epoch: 6| Step: 5
Training loss: 0.5012801888048412
Validation loss: 2.879323569373166

Epoch: 6| Step: 6
Training loss: 0.6078165618054704
Validation loss: 2.9865316484222957

Epoch: 6| Step: 7
Training loss: 0.5809620502900842
Validation loss: 2.919739512316729

Epoch: 6| Step: 8
Training loss: 0.3988731470952621
Validation loss: 2.922229915285641

Epoch: 6| Step: 9
Training loss: 0.6711244382935857
Validation loss: 2.9509708143338127

Epoch: 6| Step: 10
Training loss: 0.7262913597922871
Validation loss: 2.9436129279596672

Epoch: 6| Step: 11
Training loss: 0.4174327086853221
Validation loss: 2.849013616849583

Epoch: 6| Step: 12
Training loss: 0.6279395593605812
Validation loss: 2.9132767095962624

Epoch: 6| Step: 13
Training loss: 0.527429757345384
Validation loss: 2.8935293985515482

Epoch: 232| Step: 0
Training loss: 0.39670571599149734
Validation loss: 2.928961200118937

Epoch: 6| Step: 1
Training loss: 0.8444024847994286
Validation loss: 2.8686968220177724

Epoch: 6| Step: 2
Training loss: 0.45188220365277537
Validation loss: 2.8843695649123036

Epoch: 6| Step: 3
Training loss: 0.4608769134531426
Validation loss: 2.936301602423999

Epoch: 6| Step: 4
Training loss: 0.7426611744022974
Validation loss: 2.9891421339185547

Epoch: 6| Step: 5
Training loss: 0.49067725735465473
Validation loss: 2.8787074302919247

Epoch: 6| Step: 6
Training loss: 0.7231059968869828
Validation loss: 2.975854971458142

Epoch: 6| Step: 7
Training loss: 0.4935144067591936
Validation loss: 2.948193295622969

Epoch: 6| Step: 8
Training loss: 0.6065166388444048
Validation loss: 2.885248369801339

Epoch: 6| Step: 9
Training loss: 0.5172411703514904
Validation loss: 2.8184149250452126

Epoch: 6| Step: 10
Training loss: 0.48769132454387026
Validation loss: 2.8776897066730895

Epoch: 6| Step: 11
Training loss: 0.6149069262841723
Validation loss: 2.967313090809078

Epoch: 6| Step: 12
Training loss: 0.527007610425341
Validation loss: 2.9372402915048452

Epoch: 6| Step: 13
Training loss: 1.419899458885345
Validation loss: 2.9251301970129173

Epoch: 233| Step: 0
Training loss: 0.42632930375869976
Validation loss: 2.8864536740116185

Epoch: 6| Step: 1
Training loss: 0.8475239734015891
Validation loss: 3.024612947403006

Epoch: 6| Step: 2
Training loss: 0.552826567061684
Validation loss: 2.9627091971037744

Epoch: 6| Step: 3
Training loss: 0.8424530658043752
Validation loss: 2.8875751248890213

Epoch: 6| Step: 4
Training loss: 0.5281335920278254
Validation loss: 2.9002334089729445

Epoch: 6| Step: 5
Training loss: 0.6971646831545639
Validation loss: 2.926488596452691

Epoch: 6| Step: 6
Training loss: 0.40278523491208135
Validation loss: 2.932395327933895

Epoch: 6| Step: 7
Training loss: 0.6075683368111711
Validation loss: 2.9019496371181983

Epoch: 6| Step: 8
Training loss: 1.2560909170514325
Validation loss: 2.946418385949083

Epoch: 6| Step: 9
Training loss: 0.4715844289181936
Validation loss: 2.8537238304218198

Epoch: 6| Step: 10
Training loss: 0.5855228228270274
Validation loss: 2.9270350541627836

Epoch: 6| Step: 11
Training loss: 0.5264212557566618
Validation loss: 2.872988702222716

Epoch: 6| Step: 12
Training loss: 0.6450282868015593
Validation loss: 2.9768339151839966

Epoch: 6| Step: 13
Training loss: 0.6240348038809799
Validation loss: 2.965029798189628

Epoch: 234| Step: 0
Training loss: 0.5015767092489459
Validation loss: 3.011804654503853

Epoch: 6| Step: 1
Training loss: 0.6416807082320137
Validation loss: 2.884129541270761

Epoch: 6| Step: 2
Training loss: 0.5483649529188209
Validation loss: 2.9123485798692266

Epoch: 6| Step: 3
Training loss: 0.5087171858906375
Validation loss: 2.861616593576186

Epoch: 6| Step: 4
Training loss: 0.5953870090904902
Validation loss: 2.9177344388564537

Epoch: 6| Step: 5
Training loss: 1.264875543299631
Validation loss: 2.7958214336507767

Epoch: 6| Step: 6
Training loss: 0.7627963146975849
Validation loss: 2.9054951935238598

Epoch: 6| Step: 7
Training loss: 0.6861350424600269
Validation loss: 2.808827241504105

Epoch: 6| Step: 8
Training loss: 0.5230257777887157
Validation loss: 2.9020976000287044

Epoch: 6| Step: 9
Training loss: 0.6666611929509836
Validation loss: 2.7460271719634495

Epoch: 6| Step: 10
Training loss: 0.5349829177268387
Validation loss: 2.8504135534496915

Epoch: 6| Step: 11
Training loss: 0.704042344903274
Validation loss: 2.764385311927683

Epoch: 6| Step: 12
Training loss: 0.4973009694761748
Validation loss: 2.8808622164092625

Epoch: 6| Step: 13
Training loss: 0.46096252114871344
Validation loss: 2.7769213505918464

Epoch: 235| Step: 0
Training loss: 0.4459240712614633
Validation loss: 2.8617250828972747

Epoch: 6| Step: 1
Training loss: 1.288085104571139
Validation loss: 2.937586032338065

Epoch: 6| Step: 2
Training loss: 0.627611901537663
Validation loss: 2.900828181869227

Epoch: 6| Step: 3
Training loss: 0.44229925179082935
Validation loss: 2.8207559703621836

Epoch: 6| Step: 4
Training loss: 0.6600018834318395
Validation loss: 2.8529906437280634

Epoch: 6| Step: 5
Training loss: 0.4015416418217198
Validation loss: 2.8420661720019114

Epoch: 6| Step: 6
Training loss: 0.574238108613547
Validation loss: 2.921356318330145

Epoch: 6| Step: 7
Training loss: 0.7161319153329129
Validation loss: 2.915480295224484

Epoch: 6| Step: 8
Training loss: 0.6291403719689431
Validation loss: 2.895819455852235

Epoch: 6| Step: 9
Training loss: 0.5357942050403312
Validation loss: 2.938368959612999

Epoch: 6| Step: 10
Training loss: 0.40911005196913997
Validation loss: 2.8803804057608207

Epoch: 6| Step: 11
Training loss: 0.5477492837069836
Validation loss: 2.9214401329496615

Epoch: 6| Step: 12
Training loss: 0.579758835590736
Validation loss: 2.899353444712165

Epoch: 6| Step: 13
Training loss: 0.5842805959568627
Validation loss: 2.8886233848644185

Epoch: 236| Step: 0
Training loss: 1.3096017627509622
Validation loss: 2.829120327359814

Epoch: 6| Step: 1
Training loss: 0.593849224031421
Validation loss: 2.930350334631358

Epoch: 6| Step: 2
Training loss: 0.48568160197292576
Validation loss: 2.9675060677727463

Epoch: 6| Step: 3
Training loss: 0.5674784541976428
Validation loss: 2.8954429958008445

Epoch: 6| Step: 4
Training loss: 0.43029018097662236
Validation loss: 2.9604074210000855

Epoch: 6| Step: 5
Training loss: 0.7561029243898035
Validation loss: 2.9116518005256524

Epoch: 6| Step: 6
Training loss: 0.37618093509399453
Validation loss: 2.92653861809182

Epoch: 6| Step: 7
Training loss: 0.29133165084738943
Validation loss: 2.9035404933187965

Epoch: 6| Step: 8
Training loss: 0.648754364175395
Validation loss: 2.872374593610677

Epoch: 6| Step: 9
Training loss: 0.7221162170066205
Validation loss: 2.7721827001139143

Epoch: 6| Step: 10
Training loss: 0.5849160764683718
Validation loss: 2.839969399605245

Epoch: 6| Step: 11
Training loss: 0.41476664859360163
Validation loss: 2.851404905101325

Epoch: 6| Step: 12
Training loss: 0.7024591259926903
Validation loss: 2.932990075115949

Epoch: 6| Step: 13
Training loss: 0.559204194827302
Validation loss: 2.8687519513956716

Epoch: 237| Step: 0
Training loss: 0.5538994469917596
Validation loss: 2.88922460502521

Epoch: 6| Step: 1
Training loss: 0.43566337019671153
Validation loss: 2.829077656787231

Epoch: 6| Step: 2
Training loss: 0.647888364715479
Validation loss: 2.878155041378049

Epoch: 6| Step: 3
Training loss: 0.5000239008913023
Validation loss: 2.8350404664055184

Epoch: 6| Step: 4
Training loss: 0.7209950504556357
Validation loss: 2.836648100632703

Epoch: 6| Step: 5
Training loss: 0.5170651755063722
Validation loss: 2.8398105876513267

Epoch: 6| Step: 6
Training loss: 0.5638492085861195
Validation loss: 2.846853190958602

Epoch: 6| Step: 7
Training loss: 0.4892651829573641
Validation loss: 2.8500572516730838

Epoch: 6| Step: 8
Training loss: 0.41001161114021917
Validation loss: 2.928773525510965

Epoch: 6| Step: 9
Training loss: 0.5745305363181472
Validation loss: 2.7867153203708033

Epoch: 6| Step: 10
Training loss: 0.5480190843753524
Validation loss: 2.8904918330680474

Epoch: 6| Step: 11
Training loss: 1.269638479546007
Validation loss: 2.868625540100842

Epoch: 6| Step: 12
Training loss: 0.5033199240727789
Validation loss: 2.8953413007867983

Epoch: 6| Step: 13
Training loss: 0.4680320964346348
Validation loss: 2.8514419321150695

Epoch: 238| Step: 0
Training loss: 0.4036801190325342
Validation loss: 2.892506978260921

Epoch: 6| Step: 1
Training loss: 0.6461993738853233
Validation loss: 2.872000553235538

Epoch: 6| Step: 2
Training loss: 1.2615700270924546
Validation loss: 2.9277460879718653

Epoch: 6| Step: 3
Training loss: 0.46659891567701045
Validation loss: 2.936044136074656

Epoch: 6| Step: 4
Training loss: 0.6686212130453769
Validation loss: 2.8990162479830888

Epoch: 6| Step: 5
Training loss: 0.6176247074286318
Validation loss: 2.8931624127002613

Epoch: 6| Step: 6
Training loss: 0.6184406354843002
Validation loss: 2.917548963522147

Epoch: 6| Step: 7
Training loss: 0.579543924159649
Validation loss: 2.8579237821536467

Epoch: 6| Step: 8
Training loss: 0.6775784711684041
Validation loss: 2.8848869076120303

Epoch: 6| Step: 9
Training loss: 0.4835682888446264
Validation loss: 2.927418039175215

Epoch: 6| Step: 10
Training loss: 0.47252482959559977
Validation loss: 2.887199695598699

Epoch: 6| Step: 11
Training loss: 0.38621600060063455
Validation loss: 2.8451816602074267

Epoch: 6| Step: 12
Training loss: 0.46475670905192956
Validation loss: 2.939872770886806

Epoch: 6| Step: 13
Training loss: 0.6093482720797937
Validation loss: 2.9035207040051967

Epoch: 239| Step: 0
Training loss: 0.3540438925423331
Validation loss: 2.8792240238319087

Epoch: 6| Step: 1
Training loss: 0.5246051461510205
Validation loss: 2.938094342754858

Epoch: 6| Step: 2
Training loss: 0.401659819391593
Validation loss: 2.898274611619842

Epoch: 6| Step: 3
Training loss: 0.37826491675554236
Validation loss: 2.9942064105937867

Epoch: 6| Step: 4
Training loss: 0.65588670847442
Validation loss: 2.894065033453266

Epoch: 6| Step: 5
Training loss: 1.2392776283261069
Validation loss: 2.8215922712855983

Epoch: 6| Step: 6
Training loss: 0.398668932551597
Validation loss: 2.9396231803833803

Epoch: 6| Step: 7
Training loss: 0.6476049939017811
Validation loss: 2.9537905930291073

Epoch: 6| Step: 8
Training loss: 0.5324921111744835
Validation loss: 2.9278185227719944

Epoch: 6| Step: 9
Training loss: 0.5893895503621615
Validation loss: 2.882264234170809

Epoch: 6| Step: 10
Training loss: 0.5927122986386562
Validation loss: 2.8856289827934716

Epoch: 6| Step: 11
Training loss: 0.4251106300538782
Validation loss: 2.8515492896205132

Epoch: 6| Step: 12
Training loss: 0.41475816982608643
Validation loss: 2.958760530673047

Epoch: 6| Step: 13
Training loss: 0.5853620882713982
Validation loss: 2.844358958902699

Epoch: 240| Step: 0
Training loss: 0.666829079474347
Validation loss: 2.8673067960252445

Epoch: 6| Step: 1
Training loss: 0.6583186424604046
Validation loss: 2.864102039941763

Epoch: 6| Step: 2
Training loss: 0.5156049435500623
Validation loss: 2.8808758027206403

Epoch: 6| Step: 3
Training loss: 0.4829938177726022
Validation loss: 2.9346057891817026

Epoch: 6| Step: 4
Training loss: 1.2624917983742387
Validation loss: 2.822772910386209

Epoch: 6| Step: 5
Training loss: 0.4959899012687337
Validation loss: 2.932255046247668

Epoch: 6| Step: 6
Training loss: 0.4171528205316251
Validation loss: 2.8220425949937367

Epoch: 6| Step: 7
Training loss: 0.5271108042176171
Validation loss: 2.8435279144648433

Epoch: 6| Step: 8
Training loss: 0.5559155744718103
Validation loss: 2.7844409139918116

Epoch: 6| Step: 9
Training loss: 0.7736070235224481
Validation loss: 2.8907968830865123

Epoch: 6| Step: 10
Training loss: 0.5443333554899573
Validation loss: 2.8775124145425606

Epoch: 6| Step: 11
Training loss: 0.7723059420367787
Validation loss: 2.837127856079229

Epoch: 6| Step: 12
Training loss: 0.5905577020804502
Validation loss: 2.8221907133832405

Epoch: 6| Step: 13
Training loss: 0.45408956860525734
Validation loss: 2.845048265723745

Epoch: 241| Step: 0
Training loss: 0.36582238501732056
Validation loss: 2.877253271374329

Epoch: 6| Step: 1
Training loss: 0.4436495163474988
Validation loss: 2.89147638378276

Epoch: 6| Step: 2
Training loss: 0.48500186595361167
Validation loss: 2.8531120514480115

Epoch: 6| Step: 3
Training loss: 0.3741576748187359
Validation loss: 2.803552459875932

Epoch: 6| Step: 4
Training loss: 0.46713648297449073
Validation loss: 2.905607897743094

Epoch: 6| Step: 5
Training loss: 1.2734320704806605
Validation loss: 3.0351881420762523

Epoch: 6| Step: 6
Training loss: 0.4618200646019804
Validation loss: 2.908440451484741

Epoch: 6| Step: 7
Training loss: 0.684809274364888
Validation loss: 2.9679944331741566

Epoch: 6| Step: 8
Training loss: 0.45018141056863936
Validation loss: 2.8321713046816384

Epoch: 6| Step: 9
Training loss: 0.5705450968458059
Validation loss: 2.8467725822598484

Epoch: 6| Step: 10
Training loss: 0.6926928257939243
Validation loss: 2.8497031085098667

Epoch: 6| Step: 11
Training loss: 0.7976742270720188
Validation loss: 2.9160369102346753

Epoch: 6| Step: 12
Training loss: 0.7344309197096078
Validation loss: 2.9859634086886166

Epoch: 6| Step: 13
Training loss: 0.5388420870646383
Validation loss: 2.92890605083664

Epoch: 242| Step: 0
Training loss: 0.6883971256394478
Validation loss: 2.9428091296372174

Epoch: 6| Step: 1
Training loss: 0.5639008721073778
Validation loss: 2.9280685902484636

Epoch: 6| Step: 2
Training loss: 0.39642758268063644
Validation loss: 2.9049470503375603

Epoch: 6| Step: 3
Training loss: 0.41516976486335383
Validation loss: 2.866383383489802

Epoch: 6| Step: 4
Training loss: 1.2837149471708682
Validation loss: 2.9280941305090558

Epoch: 6| Step: 5
Training loss: 0.47643634814919195
Validation loss: 2.935361800934331

Epoch: 6| Step: 6
Training loss: 0.5601277395997392
Validation loss: 2.896165915585599

Epoch: 6| Step: 7
Training loss: 0.616760009282369
Validation loss: 2.861687119739856

Epoch: 6| Step: 8
Training loss: 0.6584378058999052
Validation loss: 2.7703984189323023

Epoch: 6| Step: 9
Training loss: 0.6296534394170208
Validation loss: 2.8797287096126887

Epoch: 6| Step: 10
Training loss: 0.6034353752237108
Validation loss: 2.870489673687403

Epoch: 6| Step: 11
Training loss: 0.5878722229165426
Validation loss: 2.8949766241128003

Epoch: 6| Step: 12
Training loss: 0.4938027957261591
Validation loss: 2.864874729016392

Epoch: 6| Step: 13
Training loss: 0.3610754418281462
Validation loss: 2.8670193296308004

Epoch: 243| Step: 0
Training loss: 0.48423657438960327
Validation loss: 2.80691817894908

Epoch: 6| Step: 1
Training loss: 0.7208173294348821
Validation loss: 2.8356762530144364

Epoch: 6| Step: 2
Training loss: 0.5155898862500107
Validation loss: 2.804733488508104

Epoch: 6| Step: 3
Training loss: 0.6316799342675306
Validation loss: 2.7974046741933734

Epoch: 6| Step: 4
Training loss: 0.6313412364329442
Validation loss: 2.9675761395022167

Epoch: 6| Step: 5
Training loss: 0.5995145095186077
Validation loss: 2.8171421876050062

Epoch: 6| Step: 6
Training loss: 0.4563384551694781
Validation loss: 2.839906197709161

Epoch: 6| Step: 7
Training loss: 0.8814212335111966
Validation loss: 2.8547232890273766

Epoch: 6| Step: 8
Training loss: 0.48157380345153367
Validation loss: 2.9240186311116925

Epoch: 6| Step: 9
Training loss: 0.46869489027953026
Validation loss: 2.8855312246632634

Epoch: 6| Step: 10
Training loss: 0.6235821854817302
Validation loss: 2.8927524332969208

Epoch: 6| Step: 11
Training loss: 0.712255576521954
Validation loss: 2.8734289244205247

Epoch: 6| Step: 12
Training loss: 1.2548873723166183
Validation loss: 2.847648044987751

Epoch: 6| Step: 13
Training loss: 0.34387669612656196
Validation loss: 2.8662998304819802

Epoch: 244| Step: 0
Training loss: 0.41173626972831034
Validation loss: 2.9216752281505998

Epoch: 6| Step: 1
Training loss: 0.6290099727798247
Validation loss: 2.950086870907961

Epoch: 6| Step: 2
Training loss: 0.7897670357688071
Validation loss: 2.996816508995581

Epoch: 6| Step: 3
Training loss: 0.6560067452586943
Validation loss: 2.896079750462831

Epoch: 6| Step: 4
Training loss: 0.7729515321447534
Validation loss: 2.9386587630538905

Epoch: 6| Step: 5
Training loss: 0.5531029432823648
Validation loss: 2.9366307494304884

Epoch: 6| Step: 6
Training loss: 0.5652748647026881
Validation loss: 2.950225981445915

Epoch: 6| Step: 7
Training loss: 0.6264033536399208
Validation loss: 2.964486229155806

Epoch: 6| Step: 8
Training loss: 0.555024514773801
Validation loss: 2.860440193036918

Epoch: 6| Step: 9
Training loss: 0.589920013752162
Validation loss: 2.9873269279710404

Epoch: 6| Step: 10
Training loss: 0.49108032552908276
Validation loss: 2.9813077386560405

Epoch: 6| Step: 11
Training loss: 0.5707183334548751
Validation loss: 2.9882617426216838

Epoch: 6| Step: 12
Training loss: 1.3964896675489744
Validation loss: 2.9035570937938826

Epoch: 6| Step: 13
Training loss: 0.518377183897166
Validation loss: 2.971843218976101

Epoch: 245| Step: 0
Training loss: 0.6862841171372207
Validation loss: 2.943451014060203

Epoch: 6| Step: 1
Training loss: 0.5756620317324793
Validation loss: 2.918741650674928

Epoch: 6| Step: 2
Training loss: 0.3577973733228241
Validation loss: 2.867265095643881

Epoch: 6| Step: 3
Training loss: 0.8000267381968142
Validation loss: 2.866243780533899

Epoch: 6| Step: 4
Training loss: 0.7836893527280339
Validation loss: 2.881439709158578

Epoch: 6| Step: 5
Training loss: 1.2806412716190654
Validation loss: 2.905219329415611

Epoch: 6| Step: 6
Training loss: 0.39013058844991044
Validation loss: 2.9085926472247414

Epoch: 6| Step: 7
Training loss: 0.7559072001307456
Validation loss: 2.9218421566999173

Epoch: 6| Step: 8
Training loss: 0.5754960832984539
Validation loss: 2.927023419799877

Epoch: 6| Step: 9
Training loss: 0.6287033037929213
Validation loss: 2.9443981798803884

Epoch: 6| Step: 10
Training loss: 0.5475444783037279
Validation loss: 2.9262065230350855

Epoch: 6| Step: 11
Training loss: 0.4490222832995527
Validation loss: 2.9084989876739082

Epoch: 6| Step: 12
Training loss: 0.39480407648368576
Validation loss: 2.8846610327312177

Epoch: 6| Step: 13
Training loss: 0.509413966929261
Validation loss: 2.869898028517165

Epoch: 246| Step: 0
Training loss: 0.7191716077140493
Validation loss: 2.9105872054892377

Epoch: 6| Step: 1
Training loss: 0.5504978884917189
Validation loss: 2.9414750927437914

Epoch: 6| Step: 2
Training loss: 0.38985007668905763
Validation loss: 2.8714744955519182

Epoch: 6| Step: 3
Training loss: 0.3459946647698516
Validation loss: 2.8658233848466397

Epoch: 6| Step: 4
Training loss: 0.4753029547340469
Validation loss: 2.9576981807379634

Epoch: 6| Step: 5
Training loss: 0.7641405779490755
Validation loss: 2.9457903675865023

Epoch: 6| Step: 6
Training loss: 0.7122067450299584
Validation loss: 2.9386315973082238

Epoch: 6| Step: 7
Training loss: 0.4119997285453124
Validation loss: 2.9296752386896197

Epoch: 6| Step: 8
Training loss: 0.35914164720796005
Validation loss: 2.9277488838771095

Epoch: 6| Step: 9
Training loss: 0.5994434686323247
Validation loss: 2.8709131577628204

Epoch: 6| Step: 10
Training loss: 1.3335060166751365
Validation loss: 2.9388638434838215

Epoch: 6| Step: 11
Training loss: 0.5564228903583441
Validation loss: 2.9337635896961514

Epoch: 6| Step: 12
Training loss: 0.6045255636389979
Validation loss: 2.9311514896847206

Epoch: 6| Step: 13
Training loss: 0.3468445077158
Validation loss: 2.971002828213409

Epoch: 247| Step: 0
Training loss: 0.414738050023081
Validation loss: 2.8749646861906784

Epoch: 6| Step: 1
Training loss: 0.5814253450296125
Validation loss: 2.907556506761579

Epoch: 6| Step: 2
Training loss: 0.3740547704893955
Validation loss: 2.92645682330629

Epoch: 6| Step: 3
Training loss: 0.3520115845085277
Validation loss: 2.9105675733068628

Epoch: 6| Step: 4
Training loss: 0.3195029239177486
Validation loss: 2.8409880475718525

Epoch: 6| Step: 5
Training loss: 0.55199984752957
Validation loss: 2.8875489510134194

Epoch: 6| Step: 6
Training loss: 0.7166691804072925
Validation loss: 2.854211101510945

Epoch: 6| Step: 7
Training loss: 0.6386263069905533
Validation loss: 2.92705226804781

Epoch: 6| Step: 8
Training loss: 0.5707559298734866
Validation loss: 2.9334118308777044

Epoch: 6| Step: 9
Training loss: 1.3320005978276512
Validation loss: 3.026440518083593

Epoch: 6| Step: 10
Training loss: 0.3041570643429078
Validation loss: 2.9965798167315363

Epoch: 6| Step: 11
Training loss: 0.4821228150586997
Validation loss: 2.9299398491579716

Epoch: 6| Step: 12
Training loss: 0.5240472686501315
Validation loss: 2.949369609418533

Epoch: 6| Step: 13
Training loss: 0.588679092251606
Validation loss: 2.892422764856162

Epoch: 248| Step: 0
Training loss: 0.304628941214999
Validation loss: 2.920254739183664

Epoch: 6| Step: 1
Training loss: 0.5066843853642203
Validation loss: 2.9244752761031396

Epoch: 6| Step: 2
Training loss: 0.5075495699459325
Validation loss: 2.9383758159154945

Epoch: 6| Step: 3
Training loss: 0.4391419729073996
Validation loss: 2.9303284075441063

Epoch: 6| Step: 4
Training loss: 0.5835168300120294
Validation loss: 2.9155116019321508

Epoch: 6| Step: 5
Training loss: 0.595605010410726
Validation loss: 2.8550500036516056

Epoch: 6| Step: 6
Training loss: 1.2131333653408727
Validation loss: 2.7876281754429

Epoch: 6| Step: 7
Training loss: 0.48944167529427046
Validation loss: 2.898565654543421

Epoch: 6| Step: 8
Training loss: 0.4416600063409586
Validation loss: 2.916094060729965

Epoch: 6| Step: 9
Training loss: 0.48772368067868427
Validation loss: 2.843926951733333

Epoch: 6| Step: 10
Training loss: 0.7588839477755517
Validation loss: 2.9655621997975907

Epoch: 6| Step: 11
Training loss: 0.3699121234257023
Validation loss: 2.8382917288304936

Epoch: 6| Step: 12
Training loss: 0.496461011455429
Validation loss: 2.8334760536450623

Epoch: 6| Step: 13
Training loss: 0.4644813086297841
Validation loss: 2.8354807364133956

Epoch: 249| Step: 0
Training loss: 0.7446126166891397
Validation loss: 2.8252941456699845

Epoch: 6| Step: 1
Training loss: 0.7544748010491078
Validation loss: 2.866627346552794

Epoch: 6| Step: 2
Training loss: 0.47595739251667474
Validation loss: 2.8907372530199478

Epoch: 6| Step: 3
Training loss: 1.1929358996831594
Validation loss: 2.8221329777750377

Epoch: 6| Step: 4
Training loss: 0.510253614215676
Validation loss: 2.894685055605643

Epoch: 6| Step: 5
Training loss: 0.3740191745764125
Validation loss: 2.8787630305214096

Epoch: 6| Step: 6
Training loss: 0.46015636074926214
Validation loss: 2.9094202395267073

Epoch: 6| Step: 7
Training loss: 0.6162639903401362
Validation loss: 2.89074616049393

Epoch: 6| Step: 8
Training loss: 0.3184474518992486
Validation loss: 2.9438675119280147

Epoch: 6| Step: 9
Training loss: 0.6505765677756243
Validation loss: 2.9337836219779985

Epoch: 6| Step: 10
Training loss: 0.6519687054179755
Validation loss: 2.891061093538471

Epoch: 6| Step: 11
Training loss: 0.490767291871581
Validation loss: 2.9415452712372523

Epoch: 6| Step: 12
Training loss: 0.37208735309336116
Validation loss: 2.9755541811547284

Epoch: 6| Step: 13
Training loss: 0.5626884780463439
Validation loss: 2.902451928622589

Epoch: 250| Step: 0
Training loss: 0.5707721164577232
Validation loss: 2.8818083739936564

Epoch: 6| Step: 1
Training loss: 0.4944030004835435
Validation loss: 2.9011547036923533

Epoch: 6| Step: 2
Training loss: 0.5335529283851621
Validation loss: 2.8415592404491616

Epoch: 6| Step: 3
Training loss: 0.5904990087076082
Validation loss: 2.919346454785426

Epoch: 6| Step: 4
Training loss: 0.5210851219641103
Validation loss: 2.8729063925076446

Epoch: 6| Step: 5
Training loss: 1.2778313782179742
Validation loss: 2.9394379709387546

Epoch: 6| Step: 6
Training loss: 0.7590391318947651
Validation loss: 2.8438406290557174

Epoch: 6| Step: 7
Training loss: 0.40017387291749607
Validation loss: 2.8960813695126553

Epoch: 6| Step: 8
Training loss: 0.5183078731660166
Validation loss: 2.9236887098229536

Epoch: 6| Step: 9
Training loss: 0.4493619773420908
Validation loss: 2.9396216664201895

Epoch: 6| Step: 10
Training loss: 0.4863631147796699
Validation loss: 2.930156727831494

Epoch: 6| Step: 11
Training loss: 0.4507068202356077
Validation loss: 2.895913189306086

Epoch: 6| Step: 12
Training loss: 0.7113606377953078
Validation loss: 2.9592838954094556

Epoch: 6| Step: 13
Training loss: 0.27250781732685353
Validation loss: 2.9184015336955307

Epoch: 251| Step: 0
Training loss: 0.4216415324403682
Validation loss: 2.838438110329098

Epoch: 6| Step: 1
Training loss: 0.5932744782257003
Validation loss: 2.8617523677377688

Epoch: 6| Step: 2
Training loss: 0.441642394238607
Validation loss: 2.8339697506415753

Epoch: 6| Step: 3
Training loss: 0.3823859894449355
Validation loss: 2.9023051954594896

Epoch: 6| Step: 4
Training loss: 0.49381212012726927
Validation loss: 2.904355788857253

Epoch: 6| Step: 5
Training loss: 0.40302158404283894
Validation loss: 2.854028605628081

Epoch: 6| Step: 6
Training loss: 0.4115875882124927
Validation loss: 2.9020835242963967

Epoch: 6| Step: 7
Training loss: 0.5564367088116006
Validation loss: 2.875910435139243

Epoch: 6| Step: 8
Training loss: 0.7472845032257068
Validation loss: 2.881179084925692

Epoch: 6| Step: 9
Training loss: 0.45542894192713196
Validation loss: 2.8446473602678

Epoch: 6| Step: 10
Training loss: 0.34721841995488617
Validation loss: 2.911055949366344

Epoch: 6| Step: 11
Training loss: 0.37044959126152716
Validation loss: 2.874792879356248

Epoch: 6| Step: 12
Training loss: 0.9047195402542958
Validation loss: 2.88066808377971

Epoch: 6| Step: 13
Training loss: 1.216568780035727
Validation loss: 2.8572836699300286

Epoch: 252| Step: 0
Training loss: 0.4007512771076835
Validation loss: 2.876644541827357

Epoch: 6| Step: 1
Training loss: 0.477284384998982
Validation loss: 2.9263075256342312

Epoch: 6| Step: 2
Training loss: 0.7295408015668609
Validation loss: 2.869266085719729

Epoch: 6| Step: 3
Training loss: 0.6627948779506792
Validation loss: 2.834220906155215

Epoch: 6| Step: 4
Training loss: 0.6406933352612426
Validation loss: 2.860096546846545

Epoch: 6| Step: 5
Training loss: 1.241491254581371
Validation loss: 2.8499873439887047

Epoch: 6| Step: 6
Training loss: 0.4590729323643622
Validation loss: 2.8923224199405757

Epoch: 6| Step: 7
Training loss: 0.6201605834194417
Validation loss: 2.8863714178668096

Epoch: 6| Step: 8
Training loss: 0.45312881468120847
Validation loss: 2.9341044042890414

Epoch: 6| Step: 9
Training loss: 0.705321209287133
Validation loss: 2.894728790694847

Epoch: 6| Step: 10
Training loss: 0.4197807962163402
Validation loss: 2.8140104405856308

Epoch: 6| Step: 11
Training loss: 0.7448296748424498
Validation loss: 2.968506973759583

Epoch: 6| Step: 12
Training loss: 0.6033491380300487
Validation loss: 2.9642731490664977

Epoch: 6| Step: 13
Training loss: 0.4661510261232203
Validation loss: 2.892133934092382

Epoch: 253| Step: 0
Training loss: 1.229229402826897
Validation loss: 2.9001905104663566

Epoch: 6| Step: 1
Training loss: 0.36849794501892347
Validation loss: 2.8736159476150447

Epoch: 6| Step: 2
Training loss: 0.6707993702159329
Validation loss: 2.8469290378214183

Epoch: 6| Step: 3
Training loss: 0.33417981547403924
Validation loss: 2.937157861250449

Epoch: 6| Step: 4
Training loss: 0.47338177822025795
Validation loss: 2.9014545651356576

Epoch: 6| Step: 5
Training loss: 0.4095624530931338
Validation loss: 2.8843424664691533

Epoch: 6| Step: 6
Training loss: 0.41414878953745077
Validation loss: 2.8959849521455014

Epoch: 6| Step: 7
Training loss: 0.3441836482854769
Validation loss: 2.9093602809403922

Epoch: 6| Step: 8
Training loss: 0.5002065768271284
Validation loss: 2.899899479888754

Epoch: 6| Step: 9
Training loss: 0.368667622432769
Validation loss: 2.897744204675139

Epoch: 6| Step: 10
Training loss: 0.48621829834198765
Validation loss: 2.851458724411079

Epoch: 6| Step: 11
Training loss: 0.46083266472322454
Validation loss: 2.8864400175888543

Epoch: 6| Step: 12
Training loss: 0.39511246878747447
Validation loss: 2.8959132579138567

Epoch: 6| Step: 13
Training loss: 0.6178933706498697
Validation loss: 2.8816142775268894

Epoch: 254| Step: 0
Training loss: 0.43859929531439146
Validation loss: 2.928920838814965

Epoch: 6| Step: 1
Training loss: 0.6683625961930614
Validation loss: 2.8255466629933776

Epoch: 6| Step: 2
Training loss: 0.44836490588474975
Validation loss: 2.883061192372411

Epoch: 6| Step: 3
Training loss: 0.3955900883751132
Validation loss: 2.8773438394895026

Epoch: 6| Step: 4
Training loss: 0.5246593107883695
Validation loss: 2.8571278092010775

Epoch: 6| Step: 5
Training loss: 1.2759441675838323
Validation loss: 2.8868001565910015

Epoch: 6| Step: 6
Training loss: 0.4928940893303305
Validation loss: 2.913115039713747

Epoch: 6| Step: 7
Training loss: 0.5130829716986247
Validation loss: 2.8613168484028364

Epoch: 6| Step: 8
Training loss: 0.44520423643910423
Validation loss: 2.92639350681537

Epoch: 6| Step: 9
Training loss: 0.47416235825715997
Validation loss: 2.9149967226737408

Epoch: 6| Step: 10
Training loss: 0.37164522653729726
Validation loss: 2.908662239284091

Epoch: 6| Step: 11
Training loss: 0.7085538034839984
Validation loss: 2.9118958737564804

Epoch: 6| Step: 12
Training loss: 0.4362294105054096
Validation loss: 2.926611232131193

Epoch: 6| Step: 13
Training loss: 0.4299648430224866
Validation loss: 2.951009285144683

Epoch: 255| Step: 0
Training loss: 0.47660971235703475
Validation loss: 2.9435391403886855

Epoch: 6| Step: 1
Training loss: 0.6496703825177746
Validation loss: 2.9079782823042875

Epoch: 6| Step: 2
Training loss: 0.47594363255598093
Validation loss: 2.9389070698592974

Epoch: 6| Step: 3
Training loss: 0.4871710095113584
Validation loss: 2.9174412561651764

Epoch: 6| Step: 4
Training loss: 0.7684491677656947
Validation loss: 2.9073412087425745

Epoch: 6| Step: 5
Training loss: 0.4720878967116223
Validation loss: 3.0578389931559147

Epoch: 6| Step: 6
Training loss: 0.5579347524591318
Validation loss: 2.9299011966333763

Epoch: 6| Step: 7
Training loss: 0.5202115702754356
Validation loss: 2.951782284616699

Epoch: 6| Step: 8
Training loss: 0.40658956787993666
Validation loss: 2.8962408552051495

Epoch: 6| Step: 9
Training loss: 0.4766798031381743
Validation loss: 2.9417954415798344

Epoch: 6| Step: 10
Training loss: 0.5166367517035102
Validation loss: 2.9154611866551994

Epoch: 6| Step: 11
Training loss: 1.2333015409873986
Validation loss: 2.9388900809014187

Epoch: 6| Step: 12
Training loss: 0.4772816063469909
Validation loss: 2.9383346643370936

Epoch: 6| Step: 13
Training loss: 0.4544416241291445
Validation loss: 2.883262171905359

Epoch: 256| Step: 0
Training loss: 0.37174276517281174
Validation loss: 2.9265224059604082

Epoch: 6| Step: 1
Training loss: 0.5597072254072348
Validation loss: 2.8826428288510173

Epoch: 6| Step: 2
Training loss: 0.5550158697299423
Validation loss: 2.9844118685217547

Epoch: 6| Step: 3
Training loss: 0.3923344211540331
Validation loss: 2.947325688806143

Epoch: 6| Step: 4
Training loss: 0.37647204757111313
Validation loss: 2.8584026496942188

Epoch: 6| Step: 5
Training loss: 0.671086425208373
Validation loss: 2.9229244244763253

Epoch: 6| Step: 6
Training loss: 0.4880303310364384
Validation loss: 2.9108281599454413

Epoch: 6| Step: 7
Training loss: 0.49988712586454737
Validation loss: 2.93339152513206

Epoch: 6| Step: 8
Training loss: 0.46608051893820357
Validation loss: 2.8537216025148338

Epoch: 6| Step: 9
Training loss: 0.5084839123606947
Validation loss: 2.9128221969407617

Epoch: 6| Step: 10
Training loss: 1.1111129257399257
Validation loss: 2.9697110678391816

Epoch: 6| Step: 11
Training loss: 0.34529231603675
Validation loss: 2.90649577096303

Epoch: 6| Step: 12
Training loss: 0.7439706763492824
Validation loss: 2.8203629394980316

Epoch: 6| Step: 13
Training loss: 0.6896848640339668
Validation loss: 2.930856049505394

Epoch: 257| Step: 0
Training loss: 0.5515397712844212
Validation loss: 2.895517501257329

Epoch: 6| Step: 1
Training loss: 0.7762199598141925
Validation loss: 2.9058604645909707

Epoch: 6| Step: 2
Training loss: 1.3105140374926207
Validation loss: 2.9053822387496595

Epoch: 6| Step: 3
Training loss: 0.3748206464700491
Validation loss: 2.8452015340674977

Epoch: 6| Step: 4
Training loss: 0.6680054905474468
Validation loss: 2.8766519251151395

Epoch: 6| Step: 5
Training loss: 0.4536576921713769
Validation loss: 2.9334809018715116

Epoch: 6| Step: 6
Training loss: 0.3485252150221133
Validation loss: 2.8089087835276665

Epoch: 6| Step: 7
Training loss: 0.5353802678492329
Validation loss: 2.8722814754479504

Epoch: 6| Step: 8
Training loss: 0.46223920544532765
Validation loss: 2.8274334927985727

Epoch: 6| Step: 9
Training loss: 0.46248660583690093
Validation loss: 2.844756943723473

Epoch: 6| Step: 10
Training loss: 0.6122921785722608
Validation loss: 2.8752031392741415

Epoch: 6| Step: 11
Training loss: 0.43779669646684904
Validation loss: 2.9234950832157924

Epoch: 6| Step: 12
Training loss: 0.45512091963441575
Validation loss: 2.8784394629843146

Epoch: 6| Step: 13
Training loss: 0.45764559023897794
Validation loss: 2.891006472048689

Epoch: 258| Step: 0
Training loss: 0.7702079160312729
Validation loss: 2.9054643669755245

Epoch: 6| Step: 1
Training loss: 0.5535145029340636
Validation loss: 2.858448455167881

Epoch: 6| Step: 2
Training loss: 0.6988408223465133
Validation loss: 2.8649591973835027

Epoch: 6| Step: 3
Training loss: 0.447328887863119
Validation loss: 2.9201534727994622

Epoch: 6| Step: 4
Training loss: 0.7230180401773987
Validation loss: 2.884760803893582

Epoch: 6| Step: 5
Training loss: 0.44368834201503393
Validation loss: 2.973424263391986

Epoch: 6| Step: 6
Training loss: 0.44363979260548564
Validation loss: 2.9579970522382903

Epoch: 6| Step: 7
Training loss: 1.2235890690442783
Validation loss: 2.912313268675847

Epoch: 6| Step: 8
Training loss: 0.5881534635201052
Validation loss: 2.8353397240290525

Epoch: 6| Step: 9
Training loss: 0.4923634139056294
Validation loss: 2.89472178983045

Epoch: 6| Step: 10
Training loss: 0.42139614267077474
Validation loss: 2.8939761282861842

Epoch: 6| Step: 11
Training loss: 0.531748537747588
Validation loss: 2.8882324352203033

Epoch: 6| Step: 12
Training loss: 0.4148655427715124
Validation loss: 2.8784027694546754

Epoch: 6| Step: 13
Training loss: 0.48598060294088274
Validation loss: 2.876487098546887

Epoch: 259| Step: 0
Training loss: 0.6009983538574931
Validation loss: 2.8325850162390185

Epoch: 6| Step: 1
Training loss: 0.6481847385328912
Validation loss: 2.943663623781748

Epoch: 6| Step: 2
Training loss: 0.4898005842205378
Validation loss: 2.8825233955459497

Epoch: 6| Step: 3
Training loss: 0.536140483530333
Validation loss: 2.9167035418404628

Epoch: 6| Step: 4
Training loss: 1.1739503920567742
Validation loss: 2.925812541554963

Epoch: 6| Step: 5
Training loss: 0.43596575997474124
Validation loss: 2.878171318860548

Epoch: 6| Step: 6
Training loss: 0.6454888599285467
Validation loss: 2.920096537831887

Epoch: 6| Step: 7
Training loss: 0.4662764453291422
Validation loss: 2.9362771958885756

Epoch: 6| Step: 8
Training loss: 0.6114580546502469
Validation loss: 2.914307203066697

Epoch: 6| Step: 9
Training loss: 0.6828453544900567
Validation loss: 2.8416140293231806

Epoch: 6| Step: 10
Training loss: 0.5103479910082109
Validation loss: 2.901709828345167

Epoch: 6| Step: 11
Training loss: 0.4067816007152088
Validation loss: 2.9080810111330497

Epoch: 6| Step: 12
Training loss: 0.6957937782336729
Validation loss: 2.937308068464486

Epoch: 6| Step: 13
Training loss: 0.4246508440334278
Validation loss: 2.8728356991525565

Epoch: 260| Step: 0
Training loss: 0.5053036852122622
Validation loss: 2.9538024179201496

Epoch: 6| Step: 1
Training loss: 0.5735372274716374
Validation loss: 2.884514172889547

Epoch: 6| Step: 2
Training loss: 0.42569791345736874
Validation loss: 2.8761860156468284

Epoch: 6| Step: 3
Training loss: 0.6730997101363886
Validation loss: 2.865328554262472

Epoch: 6| Step: 4
Training loss: 0.4245707602256824
Validation loss: 2.9421258850723

Epoch: 6| Step: 5
Training loss: 0.415236679601868
Validation loss: 2.810564986138115

Epoch: 6| Step: 6
Training loss: 0.4714317222847031
Validation loss: 2.9456665338957446

Epoch: 6| Step: 7
Training loss: 0.575060350941234
Validation loss: 2.9306460698528882

Epoch: 6| Step: 8
Training loss: 0.3303936122128722
Validation loss: 2.91794773759813

Epoch: 6| Step: 9
Training loss: 0.6293863868630349
Validation loss: 2.9434628264892826

Epoch: 6| Step: 10
Training loss: 0.40323214918193295
Validation loss: 2.9105955607311347

Epoch: 6| Step: 11
Training loss: 0.4405904336992963
Validation loss: 2.9161549164638014

Epoch: 6| Step: 12
Training loss: 1.2088227541467744
Validation loss: 2.8717764460132806

Epoch: 6| Step: 13
Training loss: 0.7555102742252013
Validation loss: 2.910527885312603

Epoch: 261| Step: 0
Training loss: 0.4372993077044761
Validation loss: 2.9091306376860104

Epoch: 6| Step: 1
Training loss: 0.5471254047952697
Validation loss: 2.908817141896906

Epoch: 6| Step: 2
Training loss: 0.42090790775558035
Validation loss: 2.8632052811783444

Epoch: 6| Step: 3
Training loss: 0.419271808725806
Validation loss: 2.947658464606348

Epoch: 6| Step: 4
Training loss: 0.6539991242187072
Validation loss: 2.881568964406343

Epoch: 6| Step: 5
Training loss: 0.48088635540161373
Validation loss: 2.8682082851119213

Epoch: 6| Step: 6
Training loss: 0.45276059921449957
Validation loss: 2.8520567722537375

Epoch: 6| Step: 7
Training loss: 0.7813309436827734
Validation loss: 2.895630058637109

Epoch: 6| Step: 8
Training loss: 0.26670189950071316
Validation loss: 2.8794998116060126

Epoch: 6| Step: 9
Training loss: 0.45264198604675265
Validation loss: 2.8979678120454495

Epoch: 6| Step: 10
Training loss: 1.2255985335352468
Validation loss: 2.8950199704752433

Epoch: 6| Step: 11
Training loss: 0.4908075060010473
Validation loss: 2.9559085517033368

Epoch: 6| Step: 12
Training loss: 0.543737457393814
Validation loss: 2.915017211082428

Epoch: 6| Step: 13
Training loss: 0.5194143866559291
Validation loss: 2.863673538459375

Epoch: 262| Step: 0
Training loss: 0.4891573865693668
Validation loss: 2.9028690593508504

Epoch: 6| Step: 1
Training loss: 0.5446920696511142
Validation loss: 2.910261264075447

Epoch: 6| Step: 2
Training loss: 0.5387635438637197
Validation loss: 2.917074165941914

Epoch: 6| Step: 3
Training loss: 1.1268398287463253
Validation loss: 2.7698358207780376

Epoch: 6| Step: 4
Training loss: 0.5620353156868829
Validation loss: 2.872887222069071

Epoch: 6| Step: 5
Training loss: 0.5506362724232842
Validation loss: 2.939113687748554

Epoch: 6| Step: 6
Training loss: 0.43037155494119905
Validation loss: 2.8893084440460517

Epoch: 6| Step: 7
Training loss: 0.3585079763714233
Validation loss: 2.8646722444549986

Epoch: 6| Step: 8
Training loss: 0.4030028379887027
Validation loss: 2.859363979742218

Epoch: 6| Step: 9
Training loss: 0.6115445859816463
Validation loss: 2.831020215094251

Epoch: 6| Step: 10
Training loss: 0.6216519324710239
Validation loss: 2.8506102064858836

Epoch: 6| Step: 11
Training loss: 0.46634150683502523
Validation loss: 2.866132994441708

Epoch: 6| Step: 12
Training loss: 0.4744493348102005
Validation loss: 2.9325357113111226

Epoch: 6| Step: 13
Training loss: 0.6122816163603552
Validation loss: 2.852216323378663

Epoch: 263| Step: 0
Training loss: 0.5816348729512082
Validation loss: 2.8628928774176243

Epoch: 6| Step: 1
Training loss: 0.6294804197058315
Validation loss: 2.8728050201018767

Epoch: 6| Step: 2
Training loss: 0.43279531355244655
Validation loss: 2.8844822335690425

Epoch: 6| Step: 3
Training loss: 0.44466862223613146
Validation loss: 2.918130130552247

Epoch: 6| Step: 4
Training loss: 0.5047311462803561
Validation loss: 2.903241312676042

Epoch: 6| Step: 5
Training loss: 0.45637319743548294
Validation loss: 2.8871708345157594

Epoch: 6| Step: 6
Training loss: 0.27861609552769134
Validation loss: 2.871009240669164

Epoch: 6| Step: 7
Training loss: 0.4601115407418298
Validation loss: 2.85002082014008

Epoch: 6| Step: 8
Training loss: 1.2716651705928483
Validation loss: 2.9784857409703025

Epoch: 6| Step: 9
Training loss: 0.5888135135918467
Validation loss: 2.9509543055296494

Epoch: 6| Step: 10
Training loss: 0.4496512942819495
Validation loss: 2.91135775279199

Epoch: 6| Step: 11
Training loss: 0.5041850597662537
Validation loss: 2.8655077650632492

Epoch: 6| Step: 12
Training loss: 0.5149469251968142
Validation loss: 2.9084669838466968

Epoch: 6| Step: 13
Training loss: 0.5600747170160375
Validation loss: 2.9353886314408806

Epoch: 264| Step: 0
Training loss: 0.6200923404071053
Validation loss: 2.8427528966810036

Epoch: 6| Step: 1
Training loss: 0.4714372220989947
Validation loss: 2.913264529254478

Epoch: 6| Step: 2
Training loss: 0.5186997262883756
Validation loss: 2.8336308313773886

Epoch: 6| Step: 3
Training loss: 0.6996529791878746
Validation loss: 2.9306882920620008

Epoch: 6| Step: 4
Training loss: 0.5726558149265859
Validation loss: 2.834319494700042

Epoch: 6| Step: 5
Training loss: 0.5108166671334647
Validation loss: 2.9093119990393808

Epoch: 6| Step: 6
Training loss: 0.451597351656439
Validation loss: 2.894570319924059

Epoch: 6| Step: 7
Training loss: 1.329568908280022
Validation loss: 2.925072374019062

Epoch: 6| Step: 8
Training loss: 0.31461917449868576
Validation loss: 2.949158953803645

Epoch: 6| Step: 9
Training loss: 0.41886294606736696
Validation loss: 2.856863965603128

Epoch: 6| Step: 10
Training loss: 0.6442093941441482
Validation loss: 3.014653525406367

Epoch: 6| Step: 11
Training loss: 0.8838698545167782
Validation loss: 2.976866458782058

Epoch: 6| Step: 12
Training loss: 0.3965589143186629
Validation loss: 2.9583949275163963

Epoch: 6| Step: 13
Training loss: 0.4630919875606889
Validation loss: 2.915194580428072

Epoch: 265| Step: 0
Training loss: 0.8611933111793023
Validation loss: 2.8841132836378396

Epoch: 6| Step: 1
Training loss: 0.7962532984187678
Validation loss: 2.9891682424152077

Epoch: 6| Step: 2
Training loss: 0.33648278095407175
Validation loss: 2.916115290886146

Epoch: 6| Step: 3
Training loss: 1.1643324673348465
Validation loss: 2.8969111780831325

Epoch: 6| Step: 4
Training loss: 0.5671937926392604
Validation loss: 2.9847251859728803

Epoch: 6| Step: 5
Training loss: 0.43358962598334383
Validation loss: 2.857477666901639

Epoch: 6| Step: 6
Training loss: 0.5077806609516153
Validation loss: 2.8264394131288673

Epoch: 6| Step: 7
Training loss: 0.6297282657726853
Validation loss: 2.8932384739178723

Epoch: 6| Step: 8
Training loss: 0.47622327769645556
Validation loss: 2.9012743150622677

Epoch: 6| Step: 9
Training loss: 0.4893426117343284
Validation loss: 2.926256454441101

Epoch: 6| Step: 10
Training loss: 0.5935280284562184
Validation loss: 2.8383528107045577

Epoch: 6| Step: 11
Training loss: 0.6269320903351115
Validation loss: 2.9146638987715066

Epoch: 6| Step: 12
Training loss: 0.459835448428317
Validation loss: 2.911042203605346

Epoch: 6| Step: 13
Training loss: 0.45511171929130256
Validation loss: 2.9897976753054514

Epoch: 266| Step: 0
Training loss: 1.1721032492560133
Validation loss: 2.9205259040702964

Epoch: 6| Step: 1
Training loss: 0.627175502614834
Validation loss: 2.888969896069235

Epoch: 6| Step: 2
Training loss: 0.36449610711204894
Validation loss: 2.898993919410921

Epoch: 6| Step: 3
Training loss: 0.4362789382463464
Validation loss: 2.8606181681971408

Epoch: 6| Step: 4
Training loss: 0.40591681095111065
Validation loss: 2.838225633485989

Epoch: 6| Step: 5
Training loss: 0.7029489932704168
Validation loss: 2.976259751830613

Epoch: 6| Step: 6
Training loss: 0.4223680793621972
Validation loss: 2.830921118626023

Epoch: 6| Step: 7
Training loss: 0.8351628288102706
Validation loss: 2.872160476813668

Epoch: 6| Step: 8
Training loss: 0.46001446973288196
Validation loss: 2.931600747884533

Epoch: 6| Step: 9
Training loss: 0.6697239931090099
Validation loss: 2.8447619304036373

Epoch: 6| Step: 10
Training loss: 0.5623874021791849
Validation loss: 2.9510172431672124

Epoch: 6| Step: 11
Training loss: 0.5856246621732439
Validation loss: 2.8917103972046143

Epoch: 6| Step: 12
Training loss: 0.5001596851463297
Validation loss: 2.889193893698962

Epoch: 6| Step: 13
Training loss: 0.575894563826591
Validation loss: 2.8457917090779334

Epoch: 267| Step: 0
Training loss: 0.49362792304635333
Validation loss: 2.8939897491468614

Epoch: 6| Step: 1
Training loss: 0.5247337744859076
Validation loss: 2.88001895348617

Epoch: 6| Step: 2
Training loss: 0.6439945182478137
Validation loss: 2.8195615069720525

Epoch: 6| Step: 3
Training loss: 0.562558594936671
Validation loss: 2.805709383516947

Epoch: 6| Step: 4
Training loss: 0.449096746048089
Validation loss: 2.8125890576426418

Epoch: 6| Step: 5
Training loss: 0.6014391289571699
Validation loss: 2.858859976435201

Epoch: 6| Step: 6
Training loss: 0.4708505138565359
Validation loss: 2.9300542169573744

Epoch: 6| Step: 7
Training loss: 0.46979657006365644
Validation loss: 2.883948222142178

Epoch: 6| Step: 8
Training loss: 0.5673332783650074
Validation loss: 2.8223776543193644

Epoch: 6| Step: 9
Training loss: 0.6858426838821035
Validation loss: 2.9283322060470134

Epoch: 6| Step: 10
Training loss: 0.3487321087134478
Validation loss: 2.8454536323382476

Epoch: 6| Step: 11
Training loss: 1.2122677295447994
Validation loss: 2.938342088703246

Epoch: 6| Step: 12
Training loss: 0.465023903437451
Validation loss: 2.8624257418177788

Epoch: 6| Step: 13
Training loss: 0.37928601533250766
Validation loss: 2.824346656417923

Epoch: 268| Step: 0
Training loss: 0.4206708040280824
Validation loss: 2.885219447881896

Epoch: 6| Step: 1
Training loss: 1.2152689591345154
Validation loss: 2.90972902716481

Epoch: 6| Step: 2
Training loss: 0.45057200727355196
Validation loss: 2.9060556763795726

Epoch: 6| Step: 3
Training loss: 0.492774703923434
Validation loss: 2.93891783917171

Epoch: 6| Step: 4
Training loss: 0.5910132731449509
Validation loss: 2.920456635530972

Epoch: 6| Step: 5
Training loss: 0.2996665810453005
Validation loss: 2.873490780531222

Epoch: 6| Step: 6
Training loss: 0.5447771707457668
Validation loss: 2.9000728137642127

Epoch: 6| Step: 7
Training loss: 0.5551538790204744
Validation loss: 2.8932253851581153

Epoch: 6| Step: 8
Training loss: 0.5512652063326804
Validation loss: 2.9163131408788807

Epoch: 6| Step: 9
Training loss: 0.6220942182753273
Validation loss: 2.849770764283693

Epoch: 6| Step: 10
Training loss: 0.364757409999009
Validation loss: 2.916693501121964

Epoch: 6| Step: 11
Training loss: 0.4564171602433253
Validation loss: 2.89437720283101

Epoch: 6| Step: 12
Training loss: 0.5548327081301876
Validation loss: 2.91400078238549

Epoch: 6| Step: 13
Training loss: 0.44744289833048856
Validation loss: 2.876651041055487

Epoch: 269| Step: 0
Training loss: 0.5565671102599524
Validation loss: 2.8982860323391617

Epoch: 6| Step: 1
Training loss: 0.47539712341932405
Validation loss: 2.9315839266816606

Epoch: 6| Step: 2
Training loss: 0.44135942463927375
Validation loss: 2.845242622099789

Epoch: 6| Step: 3
Training loss: 0.31224715017143717
Validation loss: 2.960174556194667

Epoch: 6| Step: 4
Training loss: 0.44725391422582467
Validation loss: 2.9298539856124353

Epoch: 6| Step: 5
Training loss: 0.3960779296002897
Validation loss: 2.86780000358376

Epoch: 6| Step: 6
Training loss: 1.2678129334292707
Validation loss: 2.8382045207321682

Epoch: 6| Step: 7
Training loss: 0.6455916265187498
Validation loss: 2.9078348412083375

Epoch: 6| Step: 8
Training loss: 0.5720738424841478
Validation loss: 2.907067775180762

Epoch: 6| Step: 9
Training loss: 0.28209295047009864
Validation loss: 2.8762303635978146

Epoch: 6| Step: 10
Training loss: 0.4752741267347508
Validation loss: 2.920390454036464

Epoch: 6| Step: 11
Training loss: 0.4492384035538115
Validation loss: 2.9160976308954094

Epoch: 6| Step: 12
Training loss: 0.5768219206538043
Validation loss: 2.8964277567595498

Epoch: 6| Step: 13
Training loss: 0.46188873802267527
Validation loss: 2.9183173867150702

Epoch: 270| Step: 0
Training loss: 0.33181598641523213
Validation loss: 2.9809999671653653

Epoch: 6| Step: 1
Training loss: 1.1935543019726866
Validation loss: 2.8032461445691546

Epoch: 6| Step: 2
Training loss: 0.5238821219449636
Validation loss: 2.923006759926332

Epoch: 6| Step: 3
Training loss: 0.37300077622872346
Validation loss: 2.911555107205305

Epoch: 6| Step: 4
Training loss: 0.31912343365277
Validation loss: 2.9556944095847846

Epoch: 6| Step: 5
Training loss: 0.742099555978975
Validation loss: 2.862153098618137

Epoch: 6| Step: 6
Training loss: 0.593493607024652
Validation loss: 2.9612820574967054

Epoch: 6| Step: 7
Training loss: 0.5864241549987859
Validation loss: 2.8853087881328734

Epoch: 6| Step: 8
Training loss: 0.44389589758848785
Validation loss: 2.902556475326206

Epoch: 6| Step: 9
Training loss: 0.3957665621339663
Validation loss: 2.929355422802952

Epoch: 6| Step: 10
Training loss: 0.4962662374448782
Validation loss: 2.7700473320700802

Epoch: 6| Step: 11
Training loss: 0.4358131039789091
Validation loss: 2.860006530171833

Epoch: 6| Step: 12
Training loss: 0.37586152930267724
Validation loss: 2.828197682045622

Epoch: 6| Step: 13
Training loss: 0.4467908179747546
Validation loss: 2.8734614775229246

Epoch: 271| Step: 0
Training loss: 1.159265349516231
Validation loss: 2.8769591332066633

Epoch: 6| Step: 1
Training loss: 0.5170684608310467
Validation loss: 2.8817242340359477

Epoch: 6| Step: 2
Training loss: 0.4218837595842629
Validation loss: 2.9303903779238714

Epoch: 6| Step: 3
Training loss: 0.4082719297691998
Validation loss: 2.814598268591171

Epoch: 6| Step: 4
Training loss: 0.4772726770861298
Validation loss: 2.8963848979224864

Epoch: 6| Step: 5
Training loss: 0.6472003349015109
Validation loss: 2.918652299093948

Epoch: 6| Step: 6
Training loss: 0.5601782566998896
Validation loss: 2.819130435823176

Epoch: 6| Step: 7
Training loss: 0.5059246772239165
Validation loss: 2.848459570892141

Epoch: 6| Step: 8
Training loss: 0.45308658831668275
Validation loss: 2.886445992281764

Epoch: 6| Step: 9
Training loss: 0.39495701996644306
Validation loss: 2.958121014529279

Epoch: 6| Step: 10
Training loss: 0.34416674147890647
Validation loss: 2.8872829878645643

Epoch: 6| Step: 11
Training loss: 0.2544881022572611
Validation loss: 2.938848740468317

Epoch: 6| Step: 12
Training loss: 0.707981798417561
Validation loss: 2.9364611499922173

Epoch: 6| Step: 13
Training loss: 0.47851986007373337
Validation loss: 2.897353799997232

Epoch: 272| Step: 0
Training loss: 0.5852217307842634
Validation loss: 2.9204523087438874

Epoch: 6| Step: 1
Training loss: 0.5369300681705406
Validation loss: 2.8603516736371892

Epoch: 6| Step: 2
Training loss: 0.40482885035161603
Validation loss: 3.028572368086149

Epoch: 6| Step: 3
Training loss: 0.38626638599933555
Validation loss: 2.9653893171103975

Epoch: 6| Step: 4
Training loss: 0.4281006729565334
Validation loss: 2.937834375708031

Epoch: 6| Step: 5
Training loss: 0.8315775175863805
Validation loss: 2.877899601242642

Epoch: 6| Step: 6
Training loss: 0.5123624175016485
Validation loss: 2.920123603852364

Epoch: 6| Step: 7
Training loss: 0.5102591920423737
Validation loss: 2.9232637161750428

Epoch: 6| Step: 8
Training loss: 0.40156190330371977
Validation loss: 3.009672506328915

Epoch: 6| Step: 9
Training loss: 0.7129641978302244
Validation loss: 2.9126390486720672

Epoch: 6| Step: 10
Training loss: 1.1271951240385358
Validation loss: 2.8533961075008074

Epoch: 6| Step: 11
Training loss: 0.5474544724822014
Validation loss: 2.8597880831147817

Epoch: 6| Step: 12
Training loss: 0.5325973758852751
Validation loss: 2.9211922050072596

Epoch: 6| Step: 13
Training loss: 0.4349792271071749
Validation loss: 2.8982350432094104

Epoch: 273| Step: 0
Training loss: 0.44904124858056005
Validation loss: 2.9745738945137212

Epoch: 6| Step: 1
Training loss: 0.4815027693998607
Validation loss: 2.9364030088310273

Epoch: 6| Step: 2
Training loss: 0.6481166413447815
Validation loss: 2.948751719971409

Epoch: 6| Step: 3
Training loss: 0.5350592866472916
Validation loss: 2.9280264795448785

Epoch: 6| Step: 4
Training loss: 0.577261718373329
Validation loss: 2.8902058065451

Epoch: 6| Step: 5
Training loss: 1.1614523689333556
Validation loss: 2.9379554016765463

Epoch: 6| Step: 6
Training loss: 0.6009793365483918
Validation loss: 2.824166339196255

Epoch: 6| Step: 7
Training loss: 0.3528427126629928
Validation loss: 2.8987918990115915

Epoch: 6| Step: 8
Training loss: 0.4100512415569084
Validation loss: 2.9482869476226106

Epoch: 6| Step: 9
Training loss: 0.46660150246122795
Validation loss: 2.8825110990382843

Epoch: 6| Step: 10
Training loss: 0.43947270667635835
Validation loss: 2.9532959230936844

Epoch: 6| Step: 11
Training loss: 0.5044042506947902
Validation loss: 2.8181779273883514

Epoch: 6| Step: 12
Training loss: 0.556227922537222
Validation loss: 2.9158532416169285

Epoch: 6| Step: 13
Training loss: 0.26478207300446116
Validation loss: 2.879594793843811

Epoch: 274| Step: 0
Training loss: 0.4268881208210147
Validation loss: 2.937827409935623

Epoch: 6| Step: 1
Training loss: 0.5633629166953719
Validation loss: 2.873412868995053

Epoch: 6| Step: 2
Training loss: 1.1037436460698762
Validation loss: 2.878757315949522

Epoch: 6| Step: 3
Training loss: 0.39950413143065117
Validation loss: 2.8397527974853745

Epoch: 6| Step: 4
Training loss: 0.3283404369642746
Validation loss: 2.948827088477493

Epoch: 6| Step: 5
Training loss: 0.49403813019113824
Validation loss: 2.9737660378698045

Epoch: 6| Step: 6
Training loss: 0.527124316867515
Validation loss: 2.900766641580208

Epoch: 6| Step: 7
Training loss: 0.5202050679503732
Validation loss: 2.898361232470469

Epoch: 6| Step: 8
Training loss: 0.63680914956755
Validation loss: 2.893905043379209

Epoch: 6| Step: 9
Training loss: 0.5267623239224305
Validation loss: 2.8760950656692432

Epoch: 6| Step: 10
Training loss: 0.48258919845062026
Validation loss: 2.9093013181824654

Epoch: 6| Step: 11
Training loss: 0.48938751024452426
Validation loss: 2.884290610883974

Epoch: 6| Step: 12
Training loss: 0.5350927050655557
Validation loss: 2.963681093141858

Epoch: 6| Step: 13
Training loss: 0.32313922037306586
Validation loss: 2.933223628210687

Epoch: 275| Step: 0
Training loss: 0.39163500864174566
Validation loss: 2.9523948829881834

Epoch: 6| Step: 1
Training loss: 0.6029730027150885
Validation loss: 2.962066247361071

Epoch: 6| Step: 2
Training loss: 0.5217732404532883
Validation loss: 2.8465280622230007

Epoch: 6| Step: 3
Training loss: 0.5304967364427455
Validation loss: 2.89299450233694

Epoch: 6| Step: 4
Training loss: 0.394123338635951
Validation loss: 2.899911908203905

Epoch: 6| Step: 5
Training loss: 0.5717216744756014
Validation loss: 2.8682187587885624

Epoch: 6| Step: 6
Training loss: 0.4462709652760246
Validation loss: 2.9353098042847763

Epoch: 6| Step: 7
Training loss: 1.106595223650474
Validation loss: 2.9054038070364214

Epoch: 6| Step: 8
Training loss: 0.47206474367202217
Validation loss: 2.9256483386501757

Epoch: 6| Step: 9
Training loss: 0.37597386743149325
Validation loss: 2.881911387630575

Epoch: 6| Step: 10
Training loss: 0.6352417084844494
Validation loss: 2.9448914028712494

Epoch: 6| Step: 11
Training loss: 0.4053873660341993
Validation loss: 2.915354397159493

Epoch: 6| Step: 12
Training loss: 0.34366721543580603
Validation loss: 2.8418730945131934

Epoch: 6| Step: 13
Training loss: 0.38144765561151306
Validation loss: 2.9763215268664536

Epoch: 276| Step: 0
Training loss: 0.30676662990537795
Validation loss: 2.9307759750982285

Epoch: 6| Step: 1
Training loss: 0.5641110977836725
Validation loss: 2.936639483871251

Epoch: 6| Step: 2
Training loss: 0.5204341184969614
Validation loss: 2.9105027643210377

Epoch: 6| Step: 3
Training loss: 0.5630854103490801
Validation loss: 2.9518678199281747

Epoch: 6| Step: 4
Training loss: 0.7487909983394454
Validation loss: 2.939534504081839

Epoch: 6| Step: 5
Training loss: 0.4838447437114794
Validation loss: 2.8843222836808473

Epoch: 6| Step: 6
Training loss: 0.5365477243654081
Validation loss: 2.91070491389182

Epoch: 6| Step: 7
Training loss: 1.1617165294182186
Validation loss: 2.8889339414979758

Epoch: 6| Step: 8
Training loss: 0.5868260322348828
Validation loss: 2.920341769405645

Epoch: 6| Step: 9
Training loss: 0.49923667159171164
Validation loss: 2.8799047649275997

Epoch: 6| Step: 10
Training loss: 0.4680134072115431
Validation loss: 2.8699783338333713

Epoch: 6| Step: 11
Training loss: 0.5040514241543079
Validation loss: 2.9370440406532303

Epoch: 6| Step: 12
Training loss: 0.4502307935787736
Validation loss: 2.86090354156202

Epoch: 6| Step: 13
Training loss: 0.43311403560659606
Validation loss: 2.830706463219433

Epoch: 277| Step: 0
Training loss: 0.7111481574544725
Validation loss: 2.809419286914195

Epoch: 6| Step: 1
Training loss: 0.40328624664604695
Validation loss: 2.8797713644393905

Epoch: 6| Step: 2
Training loss: 0.4976975506183626
Validation loss: 2.8207633379352344

Epoch: 6| Step: 3
Training loss: 0.3645250500913329
Validation loss: 2.8348826258389836

Epoch: 6| Step: 4
Training loss: 0.5908528973129628
Validation loss: 2.868745503529423

Epoch: 6| Step: 5
Training loss: 0.47827958493969475
Validation loss: 2.803401967643691

Epoch: 6| Step: 6
Training loss: 0.6998940302473634
Validation loss: 2.8161754892795052

Epoch: 6| Step: 7
Training loss: 0.36536808932147796
Validation loss: 2.8676208390369684

Epoch: 6| Step: 8
Training loss: 1.1251574512078497
Validation loss: 2.8481566133879967

Epoch: 6| Step: 9
Training loss: 0.4627367560656921
Validation loss: 2.909273837332009

Epoch: 6| Step: 10
Training loss: 0.4088168846027045
Validation loss: 2.861244743790082

Epoch: 6| Step: 11
Training loss: 0.5297523031288189
Validation loss: 2.9422155772264103

Epoch: 6| Step: 12
Training loss: 0.44371134697107456
Validation loss: 2.933808313371816

Epoch: 6| Step: 13
Training loss: 0.4316037192469015
Validation loss: 2.970745767709093

Epoch: 278| Step: 0
Training loss: 0.39985294991836473
Validation loss: 2.8571668621031194

Epoch: 6| Step: 1
Training loss: 0.5055657790388107
Validation loss: 2.8586503380429504

Epoch: 6| Step: 2
Training loss: 0.5677759905988349
Validation loss: 2.923882636184509

Epoch: 6| Step: 3
Training loss: 0.5487586958333055
Validation loss: 2.9252227671203532

Epoch: 6| Step: 4
Training loss: 0.7126291291860481
Validation loss: 3.0187208791608975

Epoch: 6| Step: 5
Training loss: 0.27218830318748494
Validation loss: 2.929616752618003

Epoch: 6| Step: 6
Training loss: 0.5853585243765721
Validation loss: 2.8693937359215287

Epoch: 6| Step: 7
Training loss: 0.489356938902124
Validation loss: 2.954065190030902

Epoch: 6| Step: 8
Training loss: 0.3887630336575914
Validation loss: 2.9262184729732024

Epoch: 6| Step: 9
Training loss: 0.38695697960415343
Validation loss: 2.8799280831620755

Epoch: 6| Step: 10
Training loss: 0.630745467068006
Validation loss: 2.9076494518649287

Epoch: 6| Step: 11
Training loss: 0.48661910394839364
Validation loss: 2.8649499739472977

Epoch: 6| Step: 12
Training loss: 0.6683942543796436
Validation loss: 2.9733976691887967

Epoch: 6| Step: 13
Training loss: 1.281604066633709
Validation loss: 2.994911978696022

Epoch: 279| Step: 0
Training loss: 0.5512919932435977
Validation loss: 2.9494504589147943

Epoch: 6| Step: 1
Training loss: 0.4424413511774413
Validation loss: 2.908036820964334

Epoch: 6| Step: 2
Training loss: 0.5175607354463758
Validation loss: 2.9401982812991876

Epoch: 6| Step: 3
Training loss: 0.29730319213090156
Validation loss: 2.92868648805893

Epoch: 6| Step: 4
Training loss: 0.6233624463329006
Validation loss: 2.9185405206760873

Epoch: 6| Step: 5
Training loss: 0.4449680736425963
Validation loss: 2.945063370506971

Epoch: 6| Step: 6
Training loss: 0.4015450930255086
Validation loss: 2.7944618911105845

Epoch: 6| Step: 7
Training loss: 0.3923356365366096
Validation loss: 2.8828921561190004

Epoch: 6| Step: 8
Training loss: 0.6534216877699354
Validation loss: 2.955394041357629

Epoch: 6| Step: 9
Training loss: 0.7958852567926991
Validation loss: 2.93376612252095

Epoch: 6| Step: 10
Training loss: 0.4726884216204784
Validation loss: 2.8932082996365565

Epoch: 6| Step: 11
Training loss: 1.132001757714757
Validation loss: 2.8829617345376315

Epoch: 6| Step: 12
Training loss: 0.442149119514366
Validation loss: 2.9495284635769083

Epoch: 6| Step: 13
Training loss: 0.5198287398954917
Validation loss: 2.9056515641535663

Epoch: 280| Step: 0
Training loss: 0.40125883918604566
Validation loss: 2.8511491867899954

Epoch: 6| Step: 1
Training loss: 0.552919336651256
Validation loss: 2.924219601741704

Epoch: 6| Step: 2
Training loss: 0.3388203525333407
Validation loss: 2.9010043230284257

Epoch: 6| Step: 3
Training loss: 0.6740195182215449
Validation loss: 2.8686545462092607

Epoch: 6| Step: 4
Training loss: 0.38374538027439853
Validation loss: 2.972464636743912

Epoch: 6| Step: 5
Training loss: 0.3527979864171148
Validation loss: 2.872878494359494

Epoch: 6| Step: 6
Training loss: 1.1085351263115117
Validation loss: 2.862917319671404

Epoch: 6| Step: 7
Training loss: 0.5008397203610483
Validation loss: 2.9462782392091245

Epoch: 6| Step: 8
Training loss: 0.5003924915478427
Validation loss: 2.9350665002510237

Epoch: 6| Step: 9
Training loss: 0.3405905443665956
Validation loss: 2.8554852681306246

Epoch: 6| Step: 10
Training loss: 0.5385988978578982
Validation loss: 2.8439175622780506

Epoch: 6| Step: 11
Training loss: 0.31297554549611445
Validation loss: 2.9299993188008804

Epoch: 6| Step: 12
Training loss: 0.32370020291949897
Validation loss: 2.950504182845448

Epoch: 6| Step: 13
Training loss: 0.4943016302592385
Validation loss: 2.912706654575014

Epoch: 281| Step: 0
Training loss: 0.3710606008079158
Validation loss: 2.8646384401511735

Epoch: 6| Step: 1
Training loss: 0.505893897568679
Validation loss: 2.7925657039324654

Epoch: 6| Step: 2
Training loss: 1.1088892450811987
Validation loss: 2.8933700037388874

Epoch: 6| Step: 3
Training loss: 0.4300741017055549
Validation loss: 2.94593193360403

Epoch: 6| Step: 4
Training loss: 0.579898382525845
Validation loss: 2.905375988429914

Epoch: 6| Step: 5
Training loss: 0.39866035437304503
Validation loss: 2.886488420505624

Epoch: 6| Step: 6
Training loss: 0.6847801159088697
Validation loss: 2.937745997091395

Epoch: 6| Step: 7
Training loss: 0.5843462381067688
Validation loss: 2.79568865459045

Epoch: 6| Step: 8
Training loss: 0.4672686056715855
Validation loss: 2.888701959109001

Epoch: 6| Step: 9
Training loss: 0.40805538369469385
Validation loss: 2.888224606882476

Epoch: 6| Step: 10
Training loss: 0.6831432274832345
Validation loss: 2.887289222301356

Epoch: 6| Step: 11
Training loss: 0.5382433209392435
Validation loss: 2.8788860567058436

Epoch: 6| Step: 12
Training loss: 0.4853686323944296
Validation loss: 2.9642281343401584

Epoch: 6| Step: 13
Training loss: 0.4573777670243586
Validation loss: 2.9753833748127008

Epoch: 282| Step: 0
Training loss: 0.5574570942093282
Validation loss: 2.9517614321481505

Epoch: 6| Step: 1
Training loss: 0.4226035432510849
Validation loss: 2.9034296248928655

Epoch: 6| Step: 2
Training loss: 0.45370618774187466
Validation loss: 2.8842039669931094

Epoch: 6| Step: 3
Training loss: 0.4988436589701263
Validation loss: 2.882485320314964

Epoch: 6| Step: 4
Training loss: 0.4883437765141836
Validation loss: 2.8673643218770035

Epoch: 6| Step: 5
Training loss: 1.1284178102857148
Validation loss: 2.8051864194433107

Epoch: 6| Step: 6
Training loss: 0.473298117764299
Validation loss: 2.9129418339490365

Epoch: 6| Step: 7
Training loss: 0.3739034196210094
Validation loss: 2.8463731621436765

Epoch: 6| Step: 8
Training loss: 0.34729951064563835
Validation loss: 2.8184649191498035

Epoch: 6| Step: 9
Training loss: 0.38903511747646713
Validation loss: 2.8901038447535883

Epoch: 6| Step: 10
Training loss: 0.6268966982158363
Validation loss: 2.940445863494924

Epoch: 6| Step: 11
Training loss: 0.5341556411156766
Validation loss: 2.8609096668111067

Epoch: 6| Step: 12
Training loss: 0.4755381691381606
Validation loss: 2.829036165428992

Epoch: 6| Step: 13
Training loss: 0.4815527465297976
Validation loss: 2.8565082180128223

Epoch: 283| Step: 0
Training loss: 0.48588414589253004
Validation loss: 2.9483521659886462

Epoch: 6| Step: 1
Training loss: 0.4038147562610748
Validation loss: 2.929010948900445

Epoch: 6| Step: 2
Training loss: 0.4089943914635156
Validation loss: 2.930969649452855

Epoch: 6| Step: 3
Training loss: 0.40448627550491545
Validation loss: 2.940867340447598

Epoch: 6| Step: 4
Training loss: 0.4454303217502579
Validation loss: 2.874462519728411

Epoch: 6| Step: 5
Training loss: 0.4693406833848462
Validation loss: 2.8570223164107977

Epoch: 6| Step: 6
Training loss: 0.3932158381580065
Validation loss: 2.887050349797282

Epoch: 6| Step: 7
Training loss: 0.29183703226653357
Validation loss: 2.901261111896563

Epoch: 6| Step: 8
Training loss: 0.4169379027005439
Validation loss: 2.8907544081305523

Epoch: 6| Step: 9
Training loss: 0.3073574362162271
Validation loss: 2.8276002161674474

Epoch: 6| Step: 10
Training loss: 1.1887402332117285
Validation loss: 2.949833093113366

Epoch: 6| Step: 11
Training loss: 0.4798293783010073
Validation loss: 2.8970611128404573

Epoch: 6| Step: 12
Training loss: 0.2973058485370079
Validation loss: 2.949805477970434

Epoch: 6| Step: 13
Training loss: 0.4570032420909413
Validation loss: 2.940808617551144

Epoch: 284| Step: 0
Training loss: 0.6584368327625806
Validation loss: 2.8423771880724233

Epoch: 6| Step: 1
Training loss: 0.4561122392368008
Validation loss: 2.835483336009388

Epoch: 6| Step: 2
Training loss: 0.3351115452577906
Validation loss: 2.8077398354098935

Epoch: 6| Step: 3
Training loss: 0.5169160458966249
Validation loss: 2.9230255880655096

Epoch: 6| Step: 4
Training loss: 0.3218574134873929
Validation loss: 2.8941771324540375

Epoch: 6| Step: 5
Training loss: 0.5968565733297172
Validation loss: 2.8923731148908165

Epoch: 6| Step: 6
Training loss: 0.40255019067506986
Validation loss: 2.9516840115264986

Epoch: 6| Step: 7
Training loss: 0.3434971833370395
Validation loss: 2.9030862425813204

Epoch: 6| Step: 8
Training loss: 0.4311847955364848
Validation loss: 2.9299305454740874

Epoch: 6| Step: 9
Training loss: 1.0836218425296815
Validation loss: 2.9040472645525672

Epoch: 6| Step: 10
Training loss: 0.36702854693031683
Validation loss: 2.9303305772075494

Epoch: 6| Step: 11
Training loss: 0.3855496082769439
Validation loss: 2.9087854899214136

Epoch: 6| Step: 12
Training loss: 0.535111780476948
Validation loss: 2.878994254117662

Epoch: 6| Step: 13
Training loss: 0.38835293896686396
Validation loss: 2.9715501395795627

Epoch: 285| Step: 0
Training loss: 0.5159180993002893
Validation loss: 2.9964883172325023

Epoch: 6| Step: 1
Training loss: 0.47980721995787806
Validation loss: 2.881067866308016

Epoch: 6| Step: 2
Training loss: 0.5368458326718898
Validation loss: 2.8925948295995263

Epoch: 6| Step: 3
Training loss: 0.5198675228974449
Validation loss: 2.8899830285732273

Epoch: 6| Step: 4
Training loss: 0.3524666920610388
Validation loss: 2.9388710231354147

Epoch: 6| Step: 5
Training loss: 0.3925124156105925
Validation loss: 2.8579226628854393

Epoch: 6| Step: 6
Training loss: 0.43313048074400523
Validation loss: 2.8853242402588615

Epoch: 6| Step: 7
Training loss: 0.5119637638024563
Validation loss: 2.923416886833805

Epoch: 6| Step: 8
Training loss: 1.1204793489247726
Validation loss: 2.875840009071592

Epoch: 6| Step: 9
Training loss: 0.5278927806015908
Validation loss: 2.813252284847136

Epoch: 6| Step: 10
Training loss: 0.43537228767279573
Validation loss: 2.937285543959791

Epoch: 6| Step: 11
Training loss: 0.7638137958685112
Validation loss: 2.975569912473258

Epoch: 6| Step: 12
Training loss: 0.6424485745611535
Validation loss: 2.916692261356496

Epoch: 6| Step: 13
Training loss: 0.35924365919247364
Validation loss: 2.868451400320311

Epoch: 286| Step: 0
Training loss: 0.2988284366581108
Validation loss: 2.9299369604079746

Epoch: 6| Step: 1
Training loss: 0.396984367620144
Validation loss: 2.895797034020096

Epoch: 6| Step: 2
Training loss: 1.1060196006203877
Validation loss: 2.9503809241141226

Epoch: 6| Step: 3
Training loss: 0.522881710991596
Validation loss: 2.985397669609058

Epoch: 6| Step: 4
Training loss: 0.49078216950999304
Validation loss: 2.8813267353511303

Epoch: 6| Step: 5
Training loss: 0.4347282379883168
Validation loss: 3.018340250537795

Epoch: 6| Step: 6
Training loss: 0.4464372184460941
Validation loss: 2.92517462478131

Epoch: 6| Step: 7
Training loss: 0.3089995552896182
Validation loss: 2.8940533901211682

Epoch: 6| Step: 8
Training loss: 0.5724914417709941
Validation loss: 2.9095486478137027

Epoch: 6| Step: 9
Training loss: 0.42132928662429103
Validation loss: 2.87883065209409

Epoch: 6| Step: 10
Training loss: 0.6036822882092698
Validation loss: 2.894411840476902

Epoch: 6| Step: 11
Training loss: 0.6299369847859212
Validation loss: 2.8698973639120693

Epoch: 6| Step: 12
Training loss: 0.4420077521347732
Validation loss: 2.8808061187476826

Epoch: 6| Step: 13
Training loss: 0.6466134625313906
Validation loss: 2.901500731786329

Epoch: 287| Step: 0
Training loss: 0.580073706613276
Validation loss: 2.9391758311660294

Epoch: 6| Step: 1
Training loss: 0.3656364308714099
Validation loss: 2.838439762257791

Epoch: 6| Step: 2
Training loss: 0.5122924384377235
Validation loss: 2.8785986147194813

Epoch: 6| Step: 3
Training loss: 0.475163673761862
Validation loss: 2.8972179523955504

Epoch: 6| Step: 4
Training loss: 0.5737388837481283
Validation loss: 2.915913325612812

Epoch: 6| Step: 5
Training loss: 0.45175430553772133
Validation loss: 2.8811696651620626

Epoch: 6| Step: 6
Training loss: 0.4577059696705413
Validation loss: 2.8875750836054928

Epoch: 6| Step: 7
Training loss: 0.49914913498028685
Validation loss: 2.835718403909664

Epoch: 6| Step: 8
Training loss: 0.7468084936178964
Validation loss: 2.878398130961644

Epoch: 6| Step: 9
Training loss: 0.60117662116861
Validation loss: 2.8916585088462714

Epoch: 6| Step: 10
Training loss: 0.6089938267628273
Validation loss: 2.986230296829348

Epoch: 6| Step: 11
Training loss: 1.138863287356258
Validation loss: 2.8604988293795675

Epoch: 6| Step: 12
Training loss: 0.39154025618201105
Validation loss: 2.893135465288631

Epoch: 6| Step: 13
Training loss: 0.8751918718593452
Validation loss: 2.896247564278277

Epoch: 288| Step: 0
Training loss: 0.39584138719831224
Validation loss: 2.8597499830831397

Epoch: 6| Step: 1
Training loss: 0.4119870334200496
Validation loss: 2.830517229547192

Epoch: 6| Step: 2
Training loss: 1.1246517490090309
Validation loss: 2.8674216941378416

Epoch: 6| Step: 3
Training loss: 0.4762553804449092
Validation loss: 2.907792041179791

Epoch: 6| Step: 4
Training loss: 0.48973331453759705
Validation loss: 2.96137466491377

Epoch: 6| Step: 5
Training loss: 0.847861023529139
Validation loss: 2.9087205456011658

Epoch: 6| Step: 6
Training loss: 0.8064092345793215
Validation loss: 2.8538055377089213

Epoch: 6| Step: 7
Training loss: 0.5314346160989875
Validation loss: 2.8791811159234144

Epoch: 6| Step: 8
Training loss: 0.37198571872985237
Validation loss: 2.873198227966076

Epoch: 6| Step: 9
Training loss: 0.4864660320312651
Validation loss: 2.90582340623498

Epoch: 6| Step: 10
Training loss: 0.6466863034485125
Validation loss: 2.958732958563122

Epoch: 6| Step: 11
Training loss: 0.8499063959192762
Validation loss: 2.862160040312081

Epoch: 6| Step: 12
Training loss: 0.4172298995628224
Validation loss: 2.929318810893879

Epoch: 6| Step: 13
Training loss: 0.4903693450302174
Validation loss: 2.894967057079637

Epoch: 289| Step: 0
Training loss: 0.41594247667414896
Validation loss: 2.912221386616782

Epoch: 6| Step: 1
Training loss: 0.5074864441136999
Validation loss: 2.947112594956127

Epoch: 6| Step: 2
Training loss: 0.6184403945369361
Validation loss: 2.8532538079568632

Epoch: 6| Step: 3
Training loss: 0.4527994828232181
Validation loss: 2.9027382063614717

Epoch: 6| Step: 4
Training loss: 0.5052062719506226
Validation loss: 2.9010130209110616

Epoch: 6| Step: 5
Training loss: 1.2141102235268577
Validation loss: 2.9059819607202124

Epoch: 6| Step: 6
Training loss: 0.7789829166679133
Validation loss: 2.9368644189085864

Epoch: 6| Step: 7
Training loss: 0.6848891273624713
Validation loss: 2.8510714452152617

Epoch: 6| Step: 8
Training loss: 0.48209379213945813
Validation loss: 2.9153043880725305

Epoch: 6| Step: 9
Training loss: 0.7721695959407653
Validation loss: 3.05541257716419

Epoch: 6| Step: 10
Training loss: 0.9909200908728015
Validation loss: 2.9473014949017133

Epoch: 6| Step: 11
Training loss: 0.708068845025651
Validation loss: 2.955121127645843

Epoch: 6| Step: 12
Training loss: 0.35082540595249223
Validation loss: 2.893213326416237

Epoch: 6| Step: 13
Training loss: 0.4210366997794702
Validation loss: 2.9934185739230794

Epoch: 290| Step: 0
Training loss: 0.49962581103433
Validation loss: 2.994090578142462

Epoch: 6| Step: 1
Training loss: 0.5674305828423715
Validation loss: 2.8871315543523197

Epoch: 6| Step: 2
Training loss: 0.37290268752821887
Validation loss: 2.8178101178657293

Epoch: 6| Step: 3
Training loss: 0.4446315578462899
Validation loss: 2.854517759647294

Epoch: 6| Step: 4
Training loss: 0.484837311417035
Validation loss: 2.918094385481758

Epoch: 6| Step: 5
Training loss: 0.3053838890037387
Validation loss: 2.9269270578029123

Epoch: 6| Step: 6
Training loss: 0.5699364192955328
Validation loss: 2.965454427344611

Epoch: 6| Step: 7
Training loss: 0.6286526755208429
Validation loss: 2.876472331106223

Epoch: 6| Step: 8
Training loss: 1.1756699214710347
Validation loss: 2.8704201667207982

Epoch: 6| Step: 9
Training loss: 0.389842833401323
Validation loss: 2.8725518293494

Epoch: 6| Step: 10
Training loss: 0.40727398273813276
Validation loss: 3.0011736640294275

Epoch: 6| Step: 11
Training loss: 0.6676434176385999
Validation loss: 2.9280712501372173

Epoch: 6| Step: 12
Training loss: 0.45565471222625015
Validation loss: 2.9150560200686275

Epoch: 6| Step: 13
Training loss: 0.49197464836329413
Validation loss: 2.89787025076257

Epoch: 291| Step: 0
Training loss: 0.43711863653685246
Validation loss: 2.8713508196766897

Epoch: 6| Step: 1
Training loss: 0.2853158608621987
Validation loss: 2.881595744188171

Epoch: 6| Step: 2
Training loss: 0.41035409424557745
Validation loss: 2.909984882267401

Epoch: 6| Step: 3
Training loss: 0.40915714465843034
Validation loss: 2.876175667693206

Epoch: 6| Step: 4
Training loss: 1.115387433400123
Validation loss: 2.836698557842155

Epoch: 6| Step: 5
Training loss: 0.5045294345836047
Validation loss: 2.8999192939139173

Epoch: 6| Step: 6
Training loss: 0.5035751201084647
Validation loss: 2.9835959677643453

Epoch: 6| Step: 7
Training loss: 0.5074774003282039
Validation loss: 2.8754233864001533

Epoch: 6| Step: 8
Training loss: 0.7039556894500146
Validation loss: 2.868413152151189

Epoch: 6| Step: 9
Training loss: 0.48963526862885176
Validation loss: 2.8363874794782977

Epoch: 6| Step: 10
Training loss: 0.3803012377310308
Validation loss: 2.98414351279544

Epoch: 6| Step: 11
Training loss: 0.5287644076357151
Validation loss: 2.9390489674266265

Epoch: 6| Step: 12
Training loss: 0.38186009323319176
Validation loss: 2.8863427825416514

Epoch: 6| Step: 13
Training loss: 0.4873901017122349
Validation loss: 2.8911482466271456

Epoch: 292| Step: 0
Training loss: 0.48507972949256156
Validation loss: 2.915514014320141

Epoch: 6| Step: 1
Training loss: 0.46801627272860136
Validation loss: 2.8924819274333355

Epoch: 6| Step: 2
Training loss: 0.6252841303622388
Validation loss: 2.929830020404935

Epoch: 6| Step: 3
Training loss: 0.4015592315184574
Validation loss: 2.9284566234832234

Epoch: 6| Step: 4
Training loss: 0.4903182911576449
Validation loss: 2.952568297752323

Epoch: 6| Step: 5
Training loss: 0.5150746963551184
Validation loss: 2.8887100200013096

Epoch: 6| Step: 6
Training loss: 0.35669601194185846
Validation loss: 2.923751989752375

Epoch: 6| Step: 7
Training loss: 0.5206102338439366
Validation loss: 2.8575560407241194

Epoch: 6| Step: 8
Training loss: 0.35561409797785437
Validation loss: 2.9082405629341164

Epoch: 6| Step: 9
Training loss: 1.0434709118717322
Validation loss: 2.8236243474145235

Epoch: 6| Step: 10
Training loss: 0.42972646016443133
Validation loss: 2.8867605410223436

Epoch: 6| Step: 11
Training loss: 0.3915412076258826
Validation loss: 2.933547831047702

Epoch: 6| Step: 12
Training loss: 0.5389420195023621
Validation loss: 2.884213101302463

Epoch: 6| Step: 13
Training loss: 0.5063641066348235
Validation loss: 2.9751401691914734

Epoch: 293| Step: 0
Training loss: 0.4236275686218245
Validation loss: 2.8794426523989296

Epoch: 6| Step: 1
Training loss: 0.4896669941974208
Validation loss: 2.8727096197160598

Epoch: 6| Step: 2
Training loss: 0.40271904487921717
Validation loss: 2.9159259445936643

Epoch: 6| Step: 3
Training loss: 1.1582602990176503
Validation loss: 2.907804832058922

Epoch: 6| Step: 4
Training loss: 0.5509841220665712
Validation loss: 2.922048526173852

Epoch: 6| Step: 5
Training loss: 0.5849773933248543
Validation loss: 2.9182852114274236

Epoch: 6| Step: 6
Training loss: 0.7105341175647449
Validation loss: 2.970998013298323

Epoch: 6| Step: 7
Training loss: 0.6877619937723131
Validation loss: 2.9691388728785655

Epoch: 6| Step: 8
Training loss: 0.6001764653899732
Validation loss: 2.8613570523237346

Epoch: 6| Step: 9
Training loss: 0.4321961086626705
Validation loss: 2.8841168245029856

Epoch: 6| Step: 10
Training loss: 0.45237376981485217
Validation loss: 2.978990273933459

Epoch: 6| Step: 11
Training loss: 0.42796775686838906
Validation loss: 2.8906603836780738

Epoch: 6| Step: 12
Training loss: 0.5213175874797301
Validation loss: 2.864980931287933

Epoch: 6| Step: 13
Training loss: 0.40762993390964347
Validation loss: 2.858093224571336

Epoch: 294| Step: 0
Training loss: 0.45119922109191707
Validation loss: 2.8487700144974277

Epoch: 6| Step: 1
Training loss: 0.46879030690148404
Validation loss: 2.846372827094715

Epoch: 6| Step: 2
Training loss: 0.4365852704728158
Validation loss: 2.948313377475285

Epoch: 6| Step: 3
Training loss: 0.6194629973135933
Validation loss: 2.8676801045270066

Epoch: 6| Step: 4
Training loss: 0.4039361606937512
Validation loss: 2.798383877608057

Epoch: 6| Step: 5
Training loss: 0.4898166776778055
Validation loss: 2.9290092123878075

Epoch: 6| Step: 6
Training loss: 0.5208462014198119
Validation loss: 2.8927393560745878

Epoch: 6| Step: 7
Training loss: 0.555363364222054
Validation loss: 2.9133018748667587

Epoch: 6| Step: 8
Training loss: 0.4796573175881554
Validation loss: 2.9197910105150737

Epoch: 6| Step: 9
Training loss: 0.6447945721570577
Validation loss: 2.960431769536308

Epoch: 6| Step: 10
Training loss: 0.5875172490773436
Validation loss: 2.9369615372418822

Epoch: 6| Step: 11
Training loss: 1.0681654843090567
Validation loss: 2.89280192565249

Epoch: 6| Step: 12
Training loss: 0.674756811627001
Validation loss: 2.854418337416193

Epoch: 6| Step: 13
Training loss: 0.4534670262414708
Validation loss: 2.897185474206181

Epoch: 295| Step: 0
Training loss: 0.42843154805707595
Validation loss: 2.87596228984061

Epoch: 6| Step: 1
Training loss: 0.7097279246284279
Validation loss: 2.8334962339881637

Epoch: 6| Step: 2
Training loss: 0.39533092169377204
Validation loss: 2.8603358782208756

Epoch: 6| Step: 3
Training loss: 0.44980423960827
Validation loss: 2.8855551446582983

Epoch: 6| Step: 4
Training loss: 0.5357609694439742
Validation loss: 2.915642045200537

Epoch: 6| Step: 5
Training loss: 0.5515807281162127
Validation loss: 2.930941734561721

Epoch: 6| Step: 6
Training loss: 0.31351323373749074
Validation loss: 2.917012968394811

Epoch: 6| Step: 7
Training loss: 0.6494774350100153
Validation loss: 2.9542435776383877

Epoch: 6| Step: 8
Training loss: 1.0700644323967556
Validation loss: 2.8730877446133944

Epoch: 6| Step: 9
Training loss: 0.5191010149332029
Validation loss: 2.8301474012307692

Epoch: 6| Step: 10
Training loss: 0.6018635380526011
Validation loss: 2.8992870007883784

Epoch: 6| Step: 11
Training loss: 0.36197480763982803
Validation loss: 2.8462784184983443

Epoch: 6| Step: 12
Training loss: 0.5078721818331721
Validation loss: 2.928534983808036

Epoch: 6| Step: 13
Training loss: 0.7180101069347359
Validation loss: 2.899211756140057

Epoch: 296| Step: 0
Training loss: 0.4123705357347221
Validation loss: 3.005317968068902

Epoch: 6| Step: 1
Training loss: 0.5136129541291246
Validation loss: 2.979915209189029

Epoch: 6| Step: 2
Training loss: 0.4096947389569804
Validation loss: 2.826489785466164

Epoch: 6| Step: 3
Training loss: 0.45589406617786454
Validation loss: 2.9386095156584506

Epoch: 6| Step: 4
Training loss: 0.66557624172669
Validation loss: 2.9263815440133167

Epoch: 6| Step: 5
Training loss: 0.4069707052996277
Validation loss: 2.8832001602053556

Epoch: 6| Step: 6
Training loss: 1.0603844393546447
Validation loss: 2.8780466053157983

Epoch: 6| Step: 7
Training loss: 0.5689101025273593
Validation loss: 3.0053698905655253

Epoch: 6| Step: 8
Training loss: 0.4219770308137376
Validation loss: 2.9193795167200256

Epoch: 6| Step: 9
Training loss: 0.48338394913972804
Validation loss: 2.7926630168474174

Epoch: 6| Step: 10
Training loss: 0.3785608821618305
Validation loss: 2.8573027086386458

Epoch: 6| Step: 11
Training loss: 0.34757248801669693
Validation loss: 2.875330857575316

Epoch: 6| Step: 12
Training loss: 0.5452888920873896
Validation loss: 2.8870325808349886

Epoch: 6| Step: 13
Training loss: 0.43142242440005685
Validation loss: 2.838264862469644

Epoch: 297| Step: 0
Training loss: 0.3109252711627769
Validation loss: 2.971903347624937

Epoch: 6| Step: 1
Training loss: 0.545443623471367
Validation loss: 2.9327321961020494

Epoch: 6| Step: 2
Training loss: 0.49724920385056287
Validation loss: 2.944059069823516

Epoch: 6| Step: 3
Training loss: 0.3611392790657432
Validation loss: 2.9542558109587524

Epoch: 6| Step: 4
Training loss: 0.4252120947340488
Validation loss: 2.8908101546640412

Epoch: 6| Step: 5
Training loss: 0.33679492336655437
Validation loss: 2.972645315516943

Epoch: 6| Step: 6
Training loss: 1.0539332200453042
Validation loss: 2.8380190213573875

Epoch: 6| Step: 7
Training loss: 0.4184264413342355
Validation loss: 2.866884664260457

Epoch: 6| Step: 8
Training loss: 0.5494339067039806
Validation loss: 2.818483888761977

Epoch: 6| Step: 9
Training loss: 0.5476327823067658
Validation loss: 2.845394727847915

Epoch: 6| Step: 10
Training loss: 0.5269160478922014
Validation loss: 2.8936197524834677

Epoch: 6| Step: 11
Training loss: 0.4236237169259261
Validation loss: 2.900414833455894

Epoch: 6| Step: 12
Training loss: 0.4972999806608729
Validation loss: 2.925809703055316

Epoch: 6| Step: 13
Training loss: 0.3729549114854625
Validation loss: 2.8608035078604312

Epoch: 298| Step: 0
Training loss: 0.37115550280292864
Validation loss: 2.8987245648885613

Epoch: 6| Step: 1
Training loss: 0.6258510993521808
Validation loss: 2.877414843284914

Epoch: 6| Step: 2
Training loss: 0.5061717596935642
Validation loss: 2.870942472940295

Epoch: 6| Step: 3
Training loss: 1.1283070911321567
Validation loss: 2.9048943314453983

Epoch: 6| Step: 4
Training loss: 0.3570398258706817
Validation loss: 2.8397058648484306

Epoch: 6| Step: 5
Training loss: 0.38813153763577024
Validation loss: 2.9120202429315847

Epoch: 6| Step: 6
Training loss: 0.38795043852936545
Validation loss: 2.8363974542396835

Epoch: 6| Step: 7
Training loss: 0.3139239769615983
Validation loss: 2.9254547466637084

Epoch: 6| Step: 8
Training loss: 0.4733253031315883
Validation loss: 2.877694484392273

Epoch: 6| Step: 9
Training loss: 0.49640882804184355
Validation loss: 2.877806661854461

Epoch: 6| Step: 10
Training loss: 0.36908444981303146
Validation loss: 2.8788075458198565

Epoch: 6| Step: 11
Training loss: 0.27234529618455194
Validation loss: 2.926157921590736

Epoch: 6| Step: 12
Training loss: 0.4700196079719333
Validation loss: 2.8983120407000915

Epoch: 6| Step: 13
Training loss: 0.460510848482935
Validation loss: 2.838996771396415

Epoch: 299| Step: 0
Training loss: 0.4315412760880702
Validation loss: 2.8468862014812544

Epoch: 6| Step: 1
Training loss: 0.4117340439737247
Validation loss: 2.9382098131692747

Epoch: 6| Step: 2
Training loss: 0.39291198730042093
Validation loss: 2.8660181278534815

Epoch: 6| Step: 3
Training loss: 0.4222986778288262
Validation loss: 2.85942023403055

Epoch: 6| Step: 4
Training loss: 0.5777574608080482
Validation loss: 2.9234275025265264

Epoch: 6| Step: 5
Training loss: 1.2092789150974255
Validation loss: 2.939405296840612

Epoch: 6| Step: 6
Training loss: 0.4695243162128744
Validation loss: 2.8636304391751053

Epoch: 6| Step: 7
Training loss: 0.3896619560172066
Validation loss: 2.921030177414003

Epoch: 6| Step: 8
Training loss: 0.5213790958731126
Validation loss: 2.9111336724383374

Epoch: 6| Step: 9
Training loss: 0.5412735031786623
Validation loss: 2.9475067222072058

Epoch: 6| Step: 10
Training loss: 0.37277047667875995
Validation loss: 2.930822276431795

Epoch: 6| Step: 11
Training loss: 0.4318065583282281
Validation loss: 2.9241323200280376

Epoch: 6| Step: 12
Training loss: 0.4876805081333776
Validation loss: 2.899080888846721

Epoch: 6| Step: 13
Training loss: 0.30896935360126987
Validation loss: 2.9238706427238856

Epoch: 300| Step: 0
Training loss: 1.085094096942173
Validation loss: 2.8927579828565984

Epoch: 6| Step: 1
Training loss: 0.5885298792466035
Validation loss: 2.906803051135984

Epoch: 6| Step: 2
Training loss: 0.41290993694950806
Validation loss: 2.8150903852597713

Epoch: 6| Step: 3
Training loss: 0.4437412012597973
Validation loss: 2.9140493820481526

Epoch: 6| Step: 4
Training loss: 0.3182803564943966
Validation loss: 2.8159326868591505

Epoch: 6| Step: 5
Training loss: 0.5048885382026942
Validation loss: 2.977067719283556

Epoch: 6| Step: 6
Training loss: 0.523688242054837
Validation loss: 2.9315223204046945

Epoch: 6| Step: 7
Training loss: 0.5041103984497339
Validation loss: 2.973728970547764

Epoch: 6| Step: 8
Training loss: 0.4610768770176897
Validation loss: 2.824747840632714

Epoch: 6| Step: 9
Training loss: 0.5117637963888186
Validation loss: 2.910136232584609

Epoch: 6| Step: 10
Training loss: 0.34924995871757314
Validation loss: 2.8904832135042833

Epoch: 6| Step: 11
Training loss: 0.2862456427996316
Validation loss: 2.9176325470300637

Epoch: 6| Step: 12
Training loss: 0.4780843387093605
Validation loss: 2.928382264041292

Epoch: 6| Step: 13
Training loss: 0.4457729368507709
Validation loss: 2.8988968861288726

Epoch: 301| Step: 0
Training loss: 0.3562103751381318
Validation loss: 2.8786790776264226

Epoch: 6| Step: 1
Training loss: 0.31922189618547403
Validation loss: 2.821703623217767

Epoch: 6| Step: 2
Training loss: 0.6320725577191787
Validation loss: 2.9036476078227595

Epoch: 6| Step: 3
Training loss: 0.5748840681631159
Validation loss: 2.900364881887193

Epoch: 6| Step: 4
Training loss: 0.44863500399421724
Validation loss: 2.888489767975525

Epoch: 6| Step: 5
Training loss: 0.7409658315737122
Validation loss: 2.850482670027673

Epoch: 6| Step: 6
Training loss: 0.45831732469113323
Validation loss: 2.832209754667564

Epoch: 6| Step: 7
Training loss: 0.5029344873291893
Validation loss: 2.9045387890747802

Epoch: 6| Step: 8
Training loss: 1.081979853652281
Validation loss: 2.9724759595672565

Epoch: 6| Step: 9
Training loss: 0.4583819717551134
Validation loss: 2.827704635486917

Epoch: 6| Step: 10
Training loss: 0.4620342138696528
Validation loss: 2.919744466199818

Epoch: 6| Step: 11
Training loss: 0.46828722362253045
Validation loss: 2.8315027063810274

Epoch: 6| Step: 12
Training loss: 0.44070784419007575
Validation loss: 2.8466715494675343

Epoch: 6| Step: 13
Training loss: 0.5060579948361386
Validation loss: 2.9465090532856952

Epoch: 302| Step: 0
Training loss: 0.2969262179313182
Validation loss: 2.8271132709114646

Epoch: 6| Step: 1
Training loss: 0.6675047796771195
Validation loss: 2.82185365338593

Epoch: 6| Step: 2
Training loss: 0.4215367338593193
Validation loss: 2.9065435527909487

Epoch: 6| Step: 3
Training loss: 1.1423806565972507
Validation loss: 2.890381041533582

Epoch: 6| Step: 4
Training loss: 0.33629810584740366
Validation loss: 2.886167109617962

Epoch: 6| Step: 5
Training loss: 0.5172077509208557
Validation loss: 2.8731147832428126

Epoch: 6| Step: 6
Training loss: 0.48467909588589597
Validation loss: 2.8815651170331007

Epoch: 6| Step: 7
Training loss: 0.5173743080600887
Validation loss: 2.8970801507486215

Epoch: 6| Step: 8
Training loss: 0.4268890807481059
Validation loss: 2.88186128080146

Epoch: 6| Step: 9
Training loss: 0.31197257833683456
Validation loss: 2.859669022304325

Epoch: 6| Step: 10
Training loss: 0.6007753647217122
Validation loss: 2.8983327293139443

Epoch: 6| Step: 11
Training loss: 0.4861381956532709
Validation loss: 2.9655515071443768

Epoch: 6| Step: 12
Training loss: 0.5522203785164925
Validation loss: 2.880283035128163

Epoch: 6| Step: 13
Training loss: 0.4148716128775083
Validation loss: 2.882086506499387

Epoch: 303| Step: 0
Training loss: 0.41252224024147793
Validation loss: 2.868588333173251

Epoch: 6| Step: 1
Training loss: 0.41342873925163176
Validation loss: 2.92958704797405

Epoch: 6| Step: 2
Training loss: 1.019313686732472
Validation loss: 2.94478172693688

Epoch: 6| Step: 3
Training loss: 0.35216295039970336
Validation loss: 2.8828646027113236

Epoch: 6| Step: 4
Training loss: 0.4954708875010328
Validation loss: 2.9095382273141897

Epoch: 6| Step: 5
Training loss: 0.5303381218281435
Validation loss: 2.887911896274912

Epoch: 6| Step: 6
Training loss: 0.30602433298170867
Validation loss: 2.841098541416288

Epoch: 6| Step: 7
Training loss: 0.4914926741006529
Validation loss: 2.93684352817032

Epoch: 6| Step: 8
Training loss: 0.3281754954403133
Validation loss: 2.902938815998285

Epoch: 6| Step: 9
Training loss: 0.43098105876440457
Validation loss: 2.9375614403325696

Epoch: 6| Step: 10
Training loss: 0.4757412885849561
Validation loss: 2.9728718703240293

Epoch: 6| Step: 11
Training loss: 0.45095947352198285
Validation loss: 2.9002016222132423

Epoch: 6| Step: 12
Training loss: 0.38380335036222335
Validation loss: 2.9409859311803785

Epoch: 6| Step: 13
Training loss: 0.5870186812451659
Validation loss: 2.9645644145548675

Epoch: 304| Step: 0
Training loss: 0.5837133537813793
Validation loss: 2.8926450664528196

Epoch: 6| Step: 1
Training loss: 0.5341494201230654
Validation loss: 2.9732707086591046

Epoch: 6| Step: 2
Training loss: 0.5377548223640154
Validation loss: 2.943591383152085

Epoch: 6| Step: 3
Training loss: 0.4161007216553869
Validation loss: 2.881024006595359

Epoch: 6| Step: 4
Training loss: 0.5712903145018332
Validation loss: 2.9370403065377526

Epoch: 6| Step: 5
Training loss: 0.5044095682448961
Validation loss: 2.9148242762683716

Epoch: 6| Step: 6
Training loss: 1.0704683065128147
Validation loss: 2.8930456799758626

Epoch: 6| Step: 7
Training loss: 0.5477093734770028
Validation loss: 2.864224364012454

Epoch: 6| Step: 8
Training loss: 0.4469490263387076
Validation loss: 2.871619365440578

Epoch: 6| Step: 9
Training loss: 0.42633059698936226
Validation loss: 2.9026807518358697

Epoch: 6| Step: 10
Training loss: 0.37477538216401984
Validation loss: 2.8895395663869947

Epoch: 6| Step: 11
Training loss: 0.3817869774534859
Validation loss: 2.9319077551557156

Epoch: 6| Step: 12
Training loss: 0.46125207285428194
Validation loss: 2.8439731021320926

Epoch: 6| Step: 13
Training loss: 0.31397683934956955
Validation loss: 2.8808725613222226

Epoch: 305| Step: 0
Training loss: 0.35532298610247787
Validation loss: 2.9248226481519346

Epoch: 6| Step: 1
Training loss: 0.39656449433915686
Validation loss: 2.898418614959201

Epoch: 6| Step: 2
Training loss: 0.5000423473068185
Validation loss: 2.918249059760578

Epoch: 6| Step: 3
Training loss: 0.43505030494611735
Validation loss: 2.879568050651049

Epoch: 6| Step: 4
Training loss: 0.34817536847479974
Validation loss: 2.918007056730826

Epoch: 6| Step: 5
Training loss: 0.37248507232965583
Validation loss: 2.8869150772060252

Epoch: 6| Step: 6
Training loss: 0.489453761898762
Validation loss: 2.8061668086305565

Epoch: 6| Step: 7
Training loss: 1.0548197345488939
Validation loss: 2.9927068646369053

Epoch: 6| Step: 8
Training loss: 0.6307948407213136
Validation loss: 2.8713364271509376

Epoch: 6| Step: 9
Training loss: 0.5269528105489529
Validation loss: 2.8482912852972873

Epoch: 6| Step: 10
Training loss: 0.34995159257193126
Validation loss: 2.8512066065992516

Epoch: 6| Step: 11
Training loss: 0.3964165502705355
Validation loss: 2.94022139165485

Epoch: 6| Step: 12
Training loss: 0.29061770276168275
Validation loss: 2.8600363322709006

Epoch: 6| Step: 13
Training loss: 0.30452670231452883
Validation loss: 2.9126075610162685

Epoch: 306| Step: 0
Training loss: 0.45082486832487273
Validation loss: 2.9209275775094836

Epoch: 6| Step: 1
Training loss: 0.3454860717074799
Validation loss: 2.9069384371355267

Epoch: 6| Step: 2
Training loss: 1.0405587917034742
Validation loss: 2.935162567952281

Epoch: 6| Step: 3
Training loss: 0.540192952916046
Validation loss: 2.9848946856179954

Epoch: 6| Step: 4
Training loss: 0.32936368741871
Validation loss: 2.8797634165114885

Epoch: 6| Step: 5
Training loss: 0.4041560199488834
Validation loss: 2.8724080647784267

Epoch: 6| Step: 6
Training loss: 0.42161986795576706
Validation loss: 2.8747543699958547

Epoch: 6| Step: 7
Training loss: 0.5588043456135928
Validation loss: 2.8691012087876375

Epoch: 6| Step: 8
Training loss: 0.4636407239134324
Validation loss: 2.9337401440323077

Epoch: 6| Step: 9
Training loss: 0.563568425086778
Validation loss: 2.9405164043875094

Epoch: 6| Step: 10
Training loss: 0.3637651891257211
Validation loss: 2.909692830645674

Epoch: 6| Step: 11
Training loss: 0.44119168020425076
Validation loss: 2.849090926428229

Epoch: 6| Step: 12
Training loss: 0.3359699011857375
Validation loss: 2.8103189912812465

Epoch: 6| Step: 13
Training loss: 0.651307522215791
Validation loss: 2.988584030203903

Epoch: 307| Step: 0
Training loss: 0.3918467298832926
Validation loss: 2.905244386671982

Epoch: 6| Step: 1
Training loss: 0.42426695716611396
Validation loss: 2.842564248281848

Epoch: 6| Step: 2
Training loss: 0.4729264803076844
Validation loss: 2.8234330487422903

Epoch: 6| Step: 3
Training loss: 0.4787190219129583
Validation loss: 2.8754241810116223

Epoch: 6| Step: 4
Training loss: 0.4861596669817957
Validation loss: 2.88800445542824

Epoch: 6| Step: 5
Training loss: 0.41318646012756566
Validation loss: 2.8423192823273067

Epoch: 6| Step: 6
Training loss: 0.5666784224506262
Validation loss: 2.922169281254753

Epoch: 6| Step: 7
Training loss: 0.35739619261811506
Validation loss: 2.975602403125082

Epoch: 6| Step: 8
Training loss: 0.28399396510243563
Validation loss: 2.832625698096191

Epoch: 6| Step: 9
Training loss: 0.46312948896572337
Validation loss: 2.9427555226731195

Epoch: 6| Step: 10
Training loss: 1.0855959348241246
Validation loss: 2.796056965233089

Epoch: 6| Step: 11
Training loss: 0.2693479163235671
Validation loss: 2.8652842317320397

Epoch: 6| Step: 12
Training loss: 0.4562615980999566
Validation loss: 2.8085876096924505

Epoch: 6| Step: 13
Training loss: 0.508527369935719
Validation loss: 2.8428136660438694

Epoch: 308| Step: 0
Training loss: 0.4137931163369237
Validation loss: 2.8662125734219495

Epoch: 6| Step: 1
Training loss: 0.5907495377450395
Validation loss: 2.8425317187791634

Epoch: 6| Step: 2
Training loss: 0.4767335522209385
Validation loss: 2.8722780721716292

Epoch: 6| Step: 3
Training loss: 0.4519668774832731
Validation loss: 2.8797967052123576

Epoch: 6| Step: 4
Training loss: 0.45173321107341885
Validation loss: 2.81074059167613

Epoch: 6| Step: 5
Training loss: 0.3649166173276471
Validation loss: 2.8545216991575137

Epoch: 6| Step: 6
Training loss: 0.4700538145616374
Validation loss: 2.91142921000992

Epoch: 6| Step: 7
Training loss: 0.49360627847091304
Validation loss: 2.8402655356924984

Epoch: 6| Step: 8
Training loss: 1.0002295707403124
Validation loss: 2.873985871840624

Epoch: 6| Step: 9
Training loss: 0.37859390598849657
Validation loss: 2.8601723620577335

Epoch: 6| Step: 10
Training loss: 0.5168857189575369
Validation loss: 2.918034087662001

Epoch: 6| Step: 11
Training loss: 0.5900236449110389
Validation loss: 2.900837476154435

Epoch: 6| Step: 12
Training loss: 0.4367254075854836
Validation loss: 2.9478909836224316

Epoch: 6| Step: 13
Training loss: 0.3649295616116202
Validation loss: 2.87190630220851

Epoch: 309| Step: 0
Training loss: 0.37798736684114304
Validation loss: 2.8005650364600685

Epoch: 6| Step: 1
Training loss: 0.5189754409859465
Validation loss: 2.886826736433261

Epoch: 6| Step: 2
Training loss: 0.5183557678419113
Validation loss: 2.862823366449139

Epoch: 6| Step: 3
Training loss: 0.407629403852943
Validation loss: 2.919598118961598

Epoch: 6| Step: 4
Training loss: 0.29910183507362115
Validation loss: 2.7876215898256222

Epoch: 6| Step: 5
Training loss: 0.42176411195717567
Validation loss: 2.960046947961802

Epoch: 6| Step: 6
Training loss: 0.400689213764701
Validation loss: 2.9141961306561566

Epoch: 6| Step: 7
Training loss: 0.45902589650745684
Validation loss: 2.9220122306814935

Epoch: 6| Step: 8
Training loss: 0.3878088335698478
Validation loss: 2.910098354779256

Epoch: 6| Step: 9
Training loss: 1.0899404393993226
Validation loss: 2.7884461107341605

Epoch: 6| Step: 10
Training loss: 0.6761116366822767
Validation loss: 2.8382968808706326

Epoch: 6| Step: 11
Training loss: 0.4369745164092571
Validation loss: 2.8607565177592766

Epoch: 6| Step: 12
Training loss: 0.388636793537399
Validation loss: 2.847464319083163

Epoch: 6| Step: 13
Training loss: 0.49708979780156387
Validation loss: 2.888363119926734

Epoch: 310| Step: 0
Training loss: 0.4751633601611612
Validation loss: 2.9326373089110533

Epoch: 6| Step: 1
Training loss: 0.589506798304604
Validation loss: 2.904788083692563

Epoch: 6| Step: 2
Training loss: 0.2811285657457253
Validation loss: 2.865745757098633

Epoch: 6| Step: 3
Training loss: 0.5719763118867407
Validation loss: 2.9460721103059266

Epoch: 6| Step: 4
Training loss: 0.3826087876741954
Validation loss: 2.7861942748448176

Epoch: 6| Step: 5
Training loss: 0.42363040021154147
Validation loss: 2.8657711872292784

Epoch: 6| Step: 6
Training loss: 0.7229737692568644
Validation loss: 2.9283728739920893

Epoch: 6| Step: 7
Training loss: 0.43928597556304694
Validation loss: 2.921074320655503

Epoch: 6| Step: 8
Training loss: 0.37120369738045605
Validation loss: 2.876016520042882

Epoch: 6| Step: 9
Training loss: 1.1317838536704516
Validation loss: 2.875692740199865

Epoch: 6| Step: 10
Training loss: 0.45663438177613325
Validation loss: 2.8604080196360124

Epoch: 6| Step: 11
Training loss: 0.47323720868774594
Validation loss: 2.929676283073145

Epoch: 6| Step: 12
Training loss: 0.48295767370016646
Validation loss: 2.8899169879593676

Epoch: 6| Step: 13
Training loss: 0.33909994700855234
Validation loss: 2.9071336722192602

Epoch: 311| Step: 0
Training loss: 0.23250974068182295
Validation loss: 3.042344348784572

Epoch: 6| Step: 1
Training loss: 0.4575714440140531
Validation loss: 2.8543026235085853

Epoch: 6| Step: 2
Training loss: 0.35934506167225405
Validation loss: 2.81583722239513

Epoch: 6| Step: 3
Training loss: 0.6188059964513932
Validation loss: 2.8592727309318473

Epoch: 6| Step: 4
Training loss: 0.4879068999557647
Validation loss: 2.8010921970707208

Epoch: 6| Step: 5
Training loss: 0.4500769999641828
Validation loss: 2.822412809518117

Epoch: 6| Step: 6
Training loss: 0.5650562113675782
Validation loss: 2.8872214134766017

Epoch: 6| Step: 7
Training loss: 0.43682502722723987
Validation loss: 2.90385124723014

Epoch: 6| Step: 8
Training loss: 0.4264349512691891
Validation loss: 2.9313675873792153

Epoch: 6| Step: 9
Training loss: 0.38543310216278565
Validation loss: 2.7984370978699635

Epoch: 6| Step: 10
Training loss: 0.3089208438727389
Validation loss: 2.910008587600604

Epoch: 6| Step: 11
Training loss: 1.0510986869676786
Validation loss: 2.9219164785885114

Epoch: 6| Step: 12
Training loss: 0.6363895477942927
Validation loss: 2.8550759326660047

Epoch: 6| Step: 13
Training loss: 0.4485109142859425
Validation loss: 2.8935327425006654

Epoch: 312| Step: 0
Training loss: 0.19385230685788246
Validation loss: 2.8983221313877223

Epoch: 6| Step: 1
Training loss: 0.40290212310426665
Validation loss: 2.831225639726879

Epoch: 6| Step: 2
Training loss: 0.6537614368072902
Validation loss: 2.896382634233882

Epoch: 6| Step: 3
Training loss: 0.4054985432345826
Validation loss: 2.912407794742591

Epoch: 6| Step: 4
Training loss: 1.0480697418914489
Validation loss: 2.849235832651968

Epoch: 6| Step: 5
Training loss: 0.3398691803636325
Validation loss: 2.8976177828407206

Epoch: 6| Step: 6
Training loss: 0.43795053240707443
Validation loss: 2.8229426890695244

Epoch: 6| Step: 7
Training loss: 0.49169832473870595
Validation loss: 2.8440452115041617

Epoch: 6| Step: 8
Training loss: 0.4436899037030714
Validation loss: 2.8769509841417205

Epoch: 6| Step: 9
Training loss: 0.40414783476514154
Validation loss: 2.93730073618222

Epoch: 6| Step: 10
Training loss: 0.4792171396403188
Validation loss: 2.8821763574723374

Epoch: 6| Step: 11
Training loss: 0.3325053252603976
Validation loss: 2.8690488422792937

Epoch: 6| Step: 12
Training loss: 0.5679004822307299
Validation loss: 2.9249389549688716

Epoch: 6| Step: 13
Training loss: 0.3428578612431453
Validation loss: 2.887665479357788

Epoch: 313| Step: 0
Training loss: 0.41506302708272236
Validation loss: 2.915715393976593

Epoch: 6| Step: 1
Training loss: 0.3466651591090899
Validation loss: 2.90525951392847

Epoch: 6| Step: 2
Training loss: 0.43956107615068474
Validation loss: 2.9455015086434186

Epoch: 6| Step: 3
Training loss: 0.46529763766110677
Validation loss: 2.8590210103137697

Epoch: 6| Step: 4
Training loss: 0.6087785148991919
Validation loss: 2.931627667030129

Epoch: 6| Step: 5
Training loss: 0.359858498612692
Validation loss: 2.9168160718162923

Epoch: 6| Step: 6
Training loss: 1.098752109408388
Validation loss: 2.901283286058625

Epoch: 6| Step: 7
Training loss: 0.39035320362947407
Validation loss: 2.836637573425455

Epoch: 6| Step: 8
Training loss: 0.3444491991531868
Validation loss: 2.889123846447728

Epoch: 6| Step: 9
Training loss: 0.43619154360845924
Validation loss: 2.9261407975031095

Epoch: 6| Step: 10
Training loss: 0.5492889261789612
Validation loss: 2.8894479915622635

Epoch: 6| Step: 11
Training loss: 0.4533816630123904
Validation loss: 2.8790912542850196

Epoch: 6| Step: 12
Training loss: 0.488920068566894
Validation loss: 2.8826344890821796

Epoch: 6| Step: 13
Training loss: 0.4716859584099272
Validation loss: 2.877270803805173

Epoch: 314| Step: 0
Training loss: 0.434115087840293
Validation loss: 2.940196497334356

Epoch: 6| Step: 1
Training loss: 0.5475163649808789
Validation loss: 2.8939542894639745

Epoch: 6| Step: 2
Training loss: 0.342210856820663
Validation loss: 2.805810404261715

Epoch: 6| Step: 3
Training loss: 0.5254292527077101
Validation loss: 2.943053582567705

Epoch: 6| Step: 4
Training loss: 0.41848136982417206
Validation loss: 2.927140087152173

Epoch: 6| Step: 5
Training loss: 0.33468447472837237
Validation loss: 2.817296607397226

Epoch: 6| Step: 6
Training loss: 0.6743473871780794
Validation loss: 2.9026002355567537

Epoch: 6| Step: 7
Training loss: 0.5768035271157794
Validation loss: 2.82341808825408

Epoch: 6| Step: 8
Training loss: 0.3375116659726661
Validation loss: 2.793783763422612

Epoch: 6| Step: 9
Training loss: 0.43716748407883504
Validation loss: 2.873892245904506

Epoch: 6| Step: 10
Training loss: 0.5817673616183339
Validation loss: 2.8401074398564536

Epoch: 6| Step: 11
Training loss: 0.4475867771744661
Validation loss: 2.8609378205651117

Epoch: 6| Step: 12
Training loss: 1.0626065817837504
Validation loss: 2.824908413710551

Epoch: 6| Step: 13
Training loss: 0.4810664947956471
Validation loss: 2.887272528293572

Epoch: 315| Step: 0
Training loss: 0.44235293390623315
Validation loss: 2.9156716329723382

Epoch: 6| Step: 1
Training loss: 0.42939096101860363
Validation loss: 2.954813506453551

Epoch: 6| Step: 2
Training loss: 0.47140991204457494
Validation loss: 2.9481512230251465

Epoch: 6| Step: 3
Training loss: 1.123048201850439
Validation loss: 2.8110471999861417

Epoch: 6| Step: 4
Training loss: 0.4740535008249613
Validation loss: 2.882403130140148

Epoch: 6| Step: 5
Training loss: 0.3264245065684627
Validation loss: 2.8880243097851364

Epoch: 6| Step: 6
Training loss: 0.35210753683080576
Validation loss: 2.9106844497364013

Epoch: 6| Step: 7
Training loss: 0.5659699436706151
Validation loss: 2.8380312866160304

Epoch: 6| Step: 8
Training loss: 0.5697795520264041
Validation loss: 2.858447579379668

Epoch: 6| Step: 9
Training loss: 0.3121515596453461
Validation loss: 2.9030943935657483

Epoch: 6| Step: 10
Training loss: 0.3449845253887788
Validation loss: 2.9697493360257323

Epoch: 6| Step: 11
Training loss: 0.3264789506361663
Validation loss: 2.8646438915902985

Epoch: 6| Step: 12
Training loss: 0.523347078171214
Validation loss: 2.8258921342643766

Epoch: 6| Step: 13
Training loss: 0.3735310074320251
Validation loss: 2.8761358228886

Epoch: 316| Step: 0
Training loss: 0.36268501164399336
Validation loss: 2.8796080549530614

Epoch: 6| Step: 1
Training loss: 0.5118752451373249
Validation loss: 2.7856431047779724

Epoch: 6| Step: 2
Training loss: 0.3781557417423952
Validation loss: 2.898254950876361

Epoch: 6| Step: 3
Training loss: 0.469136428496612
Validation loss: 2.83029618354467

Epoch: 6| Step: 4
Training loss: 0.4549641282225271
Validation loss: 2.878916947005476

Epoch: 6| Step: 5
Training loss: 0.5533417778012306
Validation loss: 2.8772181785707143

Epoch: 6| Step: 6
Training loss: 1.101266807748306
Validation loss: 2.9362054501907005

Epoch: 6| Step: 7
Training loss: 0.42918772676638833
Validation loss: 2.910532022063791

Epoch: 6| Step: 8
Training loss: 0.5260114440797139
Validation loss: 2.949533124930082

Epoch: 6| Step: 9
Training loss: 0.5224027226894837
Validation loss: 2.8732128393600904

Epoch: 6| Step: 10
Training loss: 0.49311175682744657
Validation loss: 2.9050167160516214

Epoch: 6| Step: 11
Training loss: 0.3529659866893553
Validation loss: 2.9060911456483947

Epoch: 6| Step: 12
Training loss: 0.7166723408215663
Validation loss: 2.931954906000624

Epoch: 6| Step: 13
Training loss: 0.3966519795464923
Validation loss: 2.906857608187324

Epoch: 317| Step: 0
Training loss: 0.5063647246173977
Validation loss: 2.9594653788820495

Epoch: 6| Step: 1
Training loss: 0.38552740370600524
Validation loss: 2.867857443335512

Epoch: 6| Step: 2
Training loss: 0.5032080907507048
Validation loss: 2.867056820253504

Epoch: 6| Step: 3
Training loss: 0.5265981701731085
Validation loss: 2.9518459449860357

Epoch: 6| Step: 4
Training loss: 0.5202126874068025
Validation loss: 2.9037686354780448

Epoch: 6| Step: 5
Training loss: 0.49974150234037507
Validation loss: 2.8746770870919875

Epoch: 6| Step: 6
Training loss: 0.2862623787164879
Validation loss: 2.8968132794336814

Epoch: 6| Step: 7
Training loss: 0.424115202404109
Validation loss: 2.861576962635985

Epoch: 6| Step: 8
Training loss: 0.5799395206176537
Validation loss: 2.9153808393390066

Epoch: 6| Step: 9
Training loss: 1.1572441775755853
Validation loss: 2.88745662496997

Epoch: 6| Step: 10
Training loss: 0.4603098459160785
Validation loss: 2.8917085008774017

Epoch: 6| Step: 11
Training loss: 0.46657135435723157
Validation loss: 2.958279331591958

Epoch: 6| Step: 12
Training loss: 0.5387307403910069
Validation loss: 2.870222918905854

Epoch: 6| Step: 13
Training loss: 0.3797778104590097
Validation loss: 2.9338534968654346

Epoch: 318| Step: 0
Training loss: 0.6249482371829657
Validation loss: 2.866812935320832

Epoch: 6| Step: 1
Training loss: 1.102412822243681
Validation loss: 2.900684839261725

Epoch: 6| Step: 2
Training loss: 0.3188582881539405
Validation loss: 2.945902015788231

Epoch: 6| Step: 3
Training loss: 0.4653986175706329
Validation loss: 2.8235702930966644

Epoch: 6| Step: 4
Training loss: 0.3453280790620734
Validation loss: 2.9186616523435878

Epoch: 6| Step: 5
Training loss: 0.42267236590729745
Validation loss: 2.875955809781167

Epoch: 6| Step: 6
Training loss: 0.40614754044998375
Validation loss: 2.8584620646041974

Epoch: 6| Step: 7
Training loss: 0.3648424340495979
Validation loss: 2.8478228568695925

Epoch: 6| Step: 8
Training loss: 0.3779035258540775
Validation loss: 2.8251043244175196

Epoch: 6| Step: 9
Training loss: 0.5478425322687703
Validation loss: 2.8880256994474167

Epoch: 6| Step: 10
Training loss: 0.3110882341019465
Validation loss: 2.844989087464333

Epoch: 6| Step: 11
Training loss: 0.44258076194792406
Validation loss: 2.850160506675593

Epoch: 6| Step: 12
Training loss: 0.39122550582994425
Validation loss: 2.8640552149525815

Epoch: 6| Step: 13
Training loss: 0.5749529860806037
Validation loss: 2.8721624828924934

Epoch: 319| Step: 0
Training loss: 0.5388093989966332
Validation loss: 2.8772133931552406

Epoch: 6| Step: 1
Training loss: 0.5446938752125746
Validation loss: 2.845383004060963

Epoch: 6| Step: 2
Training loss: 0.4117477240311349
Validation loss: 2.8076244904796326

Epoch: 6| Step: 3
Training loss: 0.4298405981416284
Validation loss: 2.8505868714624985

Epoch: 6| Step: 4
Training loss: 0.41653077373181197
Validation loss: 2.824782783461885

Epoch: 6| Step: 5
Training loss: 0.9585909220833325
Validation loss: 2.8667294502775924

Epoch: 6| Step: 6
Training loss: 0.3905420978312729
Validation loss: 2.962199402700818

Epoch: 6| Step: 7
Training loss: 0.9279003757736279
Validation loss: 2.9422066770128836

Epoch: 6| Step: 8
Training loss: 0.5866412704653204
Validation loss: 2.9603404682043233

Epoch: 6| Step: 9
Training loss: 0.8004020351268702
Validation loss: 3.0108259818160406

Epoch: 6| Step: 10
Training loss: 0.6951047394064769
Validation loss: 3.0035209921305466

Epoch: 6| Step: 11
Training loss: 0.6228039545984102
Validation loss: 2.874173570799579

Epoch: 6| Step: 12
Training loss: 0.3771420731642138
Validation loss: 2.8809488228742537

Epoch: 6| Step: 13
Training loss: 0.5763670509930264
Validation loss: 2.9154883365963697

Epoch: 320| Step: 0
Training loss: 0.8707265721514548
Validation loss: 2.940012459328476

Epoch: 6| Step: 1
Training loss: 0.6526262733711543
Validation loss: 2.8599468694655807

Epoch: 6| Step: 2
Training loss: 0.5183644781026772
Validation loss: 2.8785002658113443

Epoch: 6| Step: 3
Training loss: 0.3192937513944885
Validation loss: 2.961067230415577

Epoch: 6| Step: 4
Training loss: 0.6484714637042551
Validation loss: 2.9760531626314535

Epoch: 6| Step: 5
Training loss: 0.5304827479003014
Validation loss: 2.983319506977229

Epoch: 6| Step: 6
Training loss: 1.2060945203126083
Validation loss: 2.9711258065246953

Epoch: 6| Step: 7
Training loss: 0.4805819835436626
Validation loss: 2.916282442307318

Epoch: 6| Step: 8
Training loss: 0.3566466089688825
Validation loss: 2.873811296382024

Epoch: 6| Step: 9
Training loss: 0.44959737329182387
Validation loss: 2.9333964288673644

Epoch: 6| Step: 10
Training loss: 0.6957034180098125
Validation loss: 2.95255845974836

Epoch: 6| Step: 11
Training loss: 0.49290417159047467
Validation loss: 2.997331465563865

Epoch: 6| Step: 12
Training loss: 0.4118992057136014
Validation loss: 2.907785126428968

Epoch: 6| Step: 13
Training loss: 0.45627464528343037
Validation loss: 2.9216194109042757

Epoch: 321| Step: 0
Training loss: 0.3972667810353851
Validation loss: 2.9005919997739475

Epoch: 6| Step: 1
Training loss: 0.4537244317703771
Validation loss: 2.8913874677343343

Epoch: 6| Step: 2
Training loss: 1.0653729585392822
Validation loss: 3.0289732913735854

Epoch: 6| Step: 3
Training loss: 0.6234963449036043
Validation loss: 2.959884362324675

Epoch: 6| Step: 4
Training loss: 0.3288478269359646
Validation loss: 2.881372203979839

Epoch: 6| Step: 5
Training loss: 0.4703477333026395
Validation loss: 2.924187511780362

Epoch: 6| Step: 6
Training loss: 0.5436951697317582
Validation loss: 2.9136315061983806

Epoch: 6| Step: 7
Training loss: 0.48649208338413336
Validation loss: 2.908918707304341

Epoch: 6| Step: 8
Training loss: 0.6723891220723092
Validation loss: 2.8245785362231803

Epoch: 6| Step: 9
Training loss: 0.5175882014607281
Validation loss: 2.899930762966206

Epoch: 6| Step: 10
Training loss: 0.449411997485732
Validation loss: 2.8343622686120504

Epoch: 6| Step: 11
Training loss: 0.5722736969987182
Validation loss: 2.949954825664264

Epoch: 6| Step: 12
Training loss: 0.7138735331241564
Validation loss: 2.925466020525751

Epoch: 6| Step: 13
Training loss: 0.43556613622935597
Validation loss: 2.787893269256881

Epoch: 322| Step: 0
Training loss: 0.5266416043141021
Validation loss: 2.8866625046057646

Epoch: 6| Step: 1
Training loss: 0.6433949250507576
Validation loss: 2.8566625267972143

Epoch: 6| Step: 2
Training loss: 0.687332869935951
Validation loss: 2.8369003777056268

Epoch: 6| Step: 3
Training loss: 0.5794374929343132
Validation loss: 2.8112606567524585

Epoch: 6| Step: 4
Training loss: 0.3748135102999316
Validation loss: 2.8430387844213665

Epoch: 6| Step: 5
Training loss: 0.4147771031064553
Validation loss: 2.8544249777375303

Epoch: 6| Step: 6
Training loss: 0.548608484811841
Validation loss: 2.881956585063155

Epoch: 6| Step: 7
Training loss: 0.45278098760856983
Validation loss: 2.8503870453057734

Epoch: 6| Step: 8
Training loss: 0.2923804416190876
Validation loss: 2.894015384201711

Epoch: 6| Step: 9
Training loss: 0.6067973664557906
Validation loss: 2.950397651617194

Epoch: 6| Step: 10
Training loss: 0.4591101291532028
Validation loss: 2.8890043647216417

Epoch: 6| Step: 11
Training loss: 0.5567856449147078
Validation loss: 2.8937365307092797

Epoch: 6| Step: 12
Training loss: 1.1853796952599236
Validation loss: 2.8453550036358015

Epoch: 6| Step: 13
Training loss: 0.7429318760848125
Validation loss: 2.8968734702799304

Epoch: 323| Step: 0
Training loss: 0.41785222505929
Validation loss: 2.901610879626552

Epoch: 6| Step: 1
Training loss: 0.4487827341153322
Validation loss: 2.866184429888782

Epoch: 6| Step: 2
Training loss: 0.5101197280779628
Validation loss: 2.976951086489688

Epoch: 6| Step: 3
Training loss: 0.6704350054998462
Validation loss: 2.9122988602761137

Epoch: 6| Step: 4
Training loss: 0.6293855345373771
Validation loss: 2.9292528567559453

Epoch: 6| Step: 5
Training loss: 0.3503910681340064
Validation loss: 2.8002428914486694

Epoch: 6| Step: 6
Training loss: 0.4517179215066359
Validation loss: 2.8914422881684

Epoch: 6| Step: 7
Training loss: 0.6261884357549344
Validation loss: 2.859584057223416

Epoch: 6| Step: 8
Training loss: 0.4417229250699454
Validation loss: 2.8578149677681006

Epoch: 6| Step: 9
Training loss: 0.38127977692683984
Validation loss: 2.919059648228235

Epoch: 6| Step: 10
Training loss: 0.40665214148491907
Validation loss: 2.8102494595619913

Epoch: 6| Step: 11
Training loss: 0.5137551533888401
Validation loss: 2.850855449652799

Epoch: 6| Step: 12
Training loss: 0.9591457130226952
Validation loss: 2.896632767981216

Epoch: 6| Step: 13
Training loss: 0.43670404781372485
Validation loss: 2.915144718540817

Epoch: 324| Step: 0
Training loss: 0.49875641190080994
Validation loss: 2.8830855876864803

Epoch: 6| Step: 1
Training loss: 0.49330498221108743
Validation loss: 2.82544423833064

Epoch: 6| Step: 2
Training loss: 0.6221330691889826
Validation loss: 2.8614440547298483

Epoch: 6| Step: 3
Training loss: 0.5391046811614731
Validation loss: 2.8401544917759582

Epoch: 6| Step: 4
Training loss: 0.5299736004228482
Validation loss: 2.9067083974855303

Epoch: 6| Step: 5
Training loss: 0.4925841897565409
Validation loss: 2.9043104200938763

Epoch: 6| Step: 6
Training loss: 0.3030962841943908
Validation loss: 2.840461926033699

Epoch: 6| Step: 7
Training loss: 0.3694064681692522
Validation loss: 2.982833317636882

Epoch: 6| Step: 8
Training loss: 0.9824202065425227
Validation loss: 2.9294391984621515

Epoch: 6| Step: 9
Training loss: 0.3368943802986203
Validation loss: 2.9381742041895054

Epoch: 6| Step: 10
Training loss: 0.2862090442126799
Validation loss: 2.8685862414813115

Epoch: 6| Step: 11
Training loss: 0.3588113718671262
Validation loss: 2.9320171537127355

Epoch: 6| Step: 12
Training loss: 0.4701155164472599
Validation loss: 2.8582223608386217

Epoch: 6| Step: 13
Training loss: 0.5197289456409978
Validation loss: 2.8818001283312245

Epoch: 325| Step: 0
Training loss: 0.2726035206478182
Validation loss: 2.8952070194689843

Epoch: 6| Step: 1
Training loss: 0.3995942919318684
Validation loss: 2.8399814675514463

Epoch: 6| Step: 2
Training loss: 0.39072397885412163
Validation loss: 2.9074824191453263

Epoch: 6| Step: 3
Training loss: 0.2531908373512697
Validation loss: 2.8891659740281757

Epoch: 6| Step: 4
Training loss: 0.5457489409495417
Validation loss: 2.826740256069851

Epoch: 6| Step: 5
Training loss: 0.3847584796377594
Validation loss: 2.9332581322596076

Epoch: 6| Step: 6
Training loss: 0.35577643356447225
Validation loss: 2.9049790587466533

Epoch: 6| Step: 7
Training loss: 0.365117161347672
Validation loss: 2.812257939977699

Epoch: 6| Step: 8
Training loss: 0.3513868316875813
Validation loss: 2.980235986049076

Epoch: 6| Step: 9
Training loss: 1.0925163941713658
Validation loss: 2.890945086928492

Epoch: 6| Step: 10
Training loss: 0.4665702046028394
Validation loss: 2.887736483931783

Epoch: 6| Step: 11
Training loss: 0.40195279431862385
Validation loss: 3.0310141874791197

Epoch: 6| Step: 12
Training loss: 0.504366464932631
Validation loss: 2.9403373055930904

Epoch: 6| Step: 13
Training loss: 0.5413043081687539
Validation loss: 3.0269987438868475

Epoch: 326| Step: 0
Training loss: 0.3197996406720751
Validation loss: 2.9337681135635085

Epoch: 6| Step: 1
Training loss: 0.5452686150061098
Validation loss: 2.919848332494291

Epoch: 6| Step: 2
Training loss: 0.49645391291247054
Validation loss: 2.955643711731307

Epoch: 6| Step: 3
Training loss: 0.42939429249517186
Validation loss: 2.951283831253684

Epoch: 6| Step: 4
Training loss: 0.32783595478526983
Validation loss: 2.893115055410232

Epoch: 6| Step: 5
Training loss: 0.37291295708599626
Validation loss: 2.9306013792733068

Epoch: 6| Step: 6
Training loss: 0.2642247937107355
Validation loss: 2.906412359371764

Epoch: 6| Step: 7
Training loss: 0.32482772534411114
Validation loss: 2.839044695504261

Epoch: 6| Step: 8
Training loss: 0.1917855339038028
Validation loss: 2.867478469373139

Epoch: 6| Step: 9
Training loss: 0.3517013911230316
Validation loss: 2.921806756240909

Epoch: 6| Step: 10
Training loss: 0.3716227725899233
Validation loss: 2.9303194305445364

Epoch: 6| Step: 11
Training loss: 1.0052483045046192
Validation loss: 2.8837918734641734

Epoch: 6| Step: 12
Training loss: 0.37547355791649734
Validation loss: 2.832856016531436

Epoch: 6| Step: 13
Training loss: 0.5773509746507277
Validation loss: 2.912237132574933

Epoch: 327| Step: 0
Training loss: 0.6091343575723073
Validation loss: 2.8481839514775666

Epoch: 6| Step: 1
Training loss: 0.3060084587389723
Validation loss: 2.8925893003328147

Epoch: 6| Step: 2
Training loss: 0.513723682648367
Validation loss: 2.9298790084976583

Epoch: 6| Step: 3
Training loss: 0.39443938441605403
Validation loss: 2.8973873597512094

Epoch: 6| Step: 4
Training loss: 0.33598285191493243
Validation loss: 2.8570251328476988

Epoch: 6| Step: 5
Training loss: 0.47623214840910555
Validation loss: 2.857713671839163

Epoch: 6| Step: 6
Training loss: 0.5512525557547423
Validation loss: 2.8805237517465496

Epoch: 6| Step: 7
Training loss: 0.5002889990067347
Validation loss: 2.8861329788180767

Epoch: 6| Step: 8
Training loss: 0.5359771168916325
Validation loss: 2.9432040491867935

Epoch: 6| Step: 9
Training loss: 0.36611294261787486
Validation loss: 2.856034792883164

Epoch: 6| Step: 10
Training loss: 0.4266458709343985
Validation loss: 2.867379995427444

Epoch: 6| Step: 11
Training loss: 0.36168566360917115
Validation loss: 2.7807122614355535

Epoch: 6| Step: 12
Training loss: 0.4704583033906673
Validation loss: 2.897382079635874

Epoch: 6| Step: 13
Training loss: 1.1089884662183198
Validation loss: 2.942931031209113

Epoch: 328| Step: 0
Training loss: 0.3720746378008927
Validation loss: 2.879009415785036

Epoch: 6| Step: 1
Training loss: 0.35552768428329123
Validation loss: 2.895135305972856

Epoch: 6| Step: 2
Training loss: 0.3957413348986164
Validation loss: 2.9736529770842375

Epoch: 6| Step: 3
Training loss: 0.46753254782241144
Validation loss: 2.9415591041056057

Epoch: 6| Step: 4
Training loss: 0.5812172542084936
Validation loss: 2.8740212253290274

Epoch: 6| Step: 5
Training loss: 0.5381381360886391
Validation loss: 2.849175249079181

Epoch: 6| Step: 6
Training loss: 0.3891183024147729
Validation loss: 2.8961504938634435

Epoch: 6| Step: 7
Training loss: 0.4412776455850531
Validation loss: 2.8380416056338995

Epoch: 6| Step: 8
Training loss: 1.0191487146409601
Validation loss: 2.9513103150523596

Epoch: 6| Step: 9
Training loss: 0.4385835139075928
Validation loss: 2.8337529283128977

Epoch: 6| Step: 10
Training loss: 0.3729798821017314
Validation loss: 2.95177402576443

Epoch: 6| Step: 11
Training loss: 0.3771794484692664
Validation loss: 2.9395796265951604

Epoch: 6| Step: 12
Training loss: 0.4587810471810165
Validation loss: 2.9352020176167426

Epoch: 6| Step: 13
Training loss: 0.29747285374438537
Validation loss: 2.855544354107167

Epoch: 329| Step: 0
Training loss: 0.3468968315815004
Validation loss: 2.885392169412305

Epoch: 6| Step: 1
Training loss: 0.4205916984151513
Validation loss: 2.931081767294034

Epoch: 6| Step: 2
Training loss: 0.3795415527151497
Validation loss: 2.8793398678508124

Epoch: 6| Step: 3
Training loss: 0.510747672465469
Validation loss: 2.8024581365438976

Epoch: 6| Step: 4
Training loss: 0.35115145919911606
Validation loss: 2.912586114289788

Epoch: 6| Step: 5
Training loss: 0.2947393951756956
Validation loss: 2.883440688418706

Epoch: 6| Step: 6
Training loss: 0.415526662393408
Validation loss: 2.8733615491135174

Epoch: 6| Step: 7
Training loss: 0.3946831476873151
Validation loss: 2.950421921143048

Epoch: 6| Step: 8
Training loss: 0.957415538628356
Validation loss: 2.9038794225411912

Epoch: 6| Step: 9
Training loss: 0.34579122896960046
Validation loss: 2.847366925312558

Epoch: 6| Step: 10
Training loss: 0.46546423396045133
Validation loss: 2.90226535340403

Epoch: 6| Step: 11
Training loss: 0.5082216815067597
Validation loss: 2.909044528744079

Epoch: 6| Step: 12
Training loss: 0.3578758483514247
Validation loss: 2.9364540185769217

Epoch: 6| Step: 13
Training loss: 0.30705492010918933
Validation loss: 2.957558588655239

Epoch: 330| Step: 0
Training loss: 0.4407090614161116
Validation loss: 2.8348530078526446

Epoch: 6| Step: 1
Training loss: 0.5536410171524195
Validation loss: 2.833260960683073

Epoch: 6| Step: 2
Training loss: 1.0690751545950758
Validation loss: 2.840676977327631

Epoch: 6| Step: 3
Training loss: 0.4599202455958641
Validation loss: 2.868395946542627

Epoch: 6| Step: 4
Training loss: 0.4087217039410884
Validation loss: 2.875064793837919

Epoch: 6| Step: 5
Training loss: 0.2839379216207186
Validation loss: 2.8689190091038337

Epoch: 6| Step: 6
Training loss: 0.5015880875284779
Validation loss: 2.8346249824487253

Epoch: 6| Step: 7
Training loss: 0.3091445305235104
Validation loss: 2.8839912520217315

Epoch: 6| Step: 8
Training loss: 0.3988367399206244
Validation loss: 2.877640893393964

Epoch: 6| Step: 9
Training loss: 0.4540304476930234
Validation loss: 2.8515376120400067

Epoch: 6| Step: 10
Training loss: 0.2857717377511916
Validation loss: 2.8508070829138727

Epoch: 6| Step: 11
Training loss: 0.35488298381492667
Validation loss: 2.909366836836877

Epoch: 6| Step: 12
Training loss: 0.35890286986669584
Validation loss: 2.9363453063286253

Epoch: 6| Step: 13
Training loss: 0.4119671038160904
Validation loss: 2.9302925265019546

Epoch: 331| Step: 0
Training loss: 0.3828113711593489
Validation loss: 2.8642437034178796

Epoch: 6| Step: 1
Training loss: 0.3773137872461335
Validation loss: 2.9083386780945673

Epoch: 6| Step: 2
Training loss: 0.4771665903043181
Validation loss: 2.8890432618131436

Epoch: 6| Step: 3
Training loss: 0.35491090536326625
Validation loss: 2.9631869210488753

Epoch: 6| Step: 4
Training loss: 0.3856901495877603
Validation loss: 2.9379875508973665

Epoch: 6| Step: 5
Training loss: 0.46375544758190795
Validation loss: 2.9089312883272003

Epoch: 6| Step: 6
Training loss: 0.4254226924694898
Validation loss: 2.850505991963948

Epoch: 6| Step: 7
Training loss: 0.2940540429458926
Validation loss: 2.836979319992234

Epoch: 6| Step: 8
Training loss: 0.6794542811369537
Validation loss: 2.963208430661278

Epoch: 6| Step: 9
Training loss: 1.0354674825089265
Validation loss: 2.9153303809102664

Epoch: 6| Step: 10
Training loss: 0.25773782804684625
Validation loss: 2.858031633060086

Epoch: 6| Step: 11
Training loss: 0.3344996754668961
Validation loss: 2.8633438943113783

Epoch: 6| Step: 12
Training loss: 0.5920283554139282
Validation loss: 2.915686637987373

Epoch: 6| Step: 13
Training loss: 0.2573159377558965
Validation loss: 2.820870172625372

Epoch: 332| Step: 0
Training loss: 0.35942226596653964
Validation loss: 2.897787852455866

Epoch: 6| Step: 1
Training loss: 0.39966405678984773
Validation loss: 2.91036025320077

Epoch: 6| Step: 2
Training loss: 0.38635095773768013
Validation loss: 2.9363458273342475

Epoch: 6| Step: 3
Training loss: 0.337601488360349
Validation loss: 2.833308897661041

Epoch: 6| Step: 4
Training loss: 0.981541111763786
Validation loss: 2.8645087954909454

Epoch: 6| Step: 5
Training loss: 0.36984460299562333
Validation loss: 2.9329661152110638

Epoch: 6| Step: 6
Training loss: 0.5095186183174364
Validation loss: 2.942011540830906

Epoch: 6| Step: 7
Training loss: 0.4276152144324085
Validation loss: 2.933769427379967

Epoch: 6| Step: 8
Training loss: 0.2369944109921629
Validation loss: 2.836044505669081

Epoch: 6| Step: 9
Training loss: 0.516407142211328
Validation loss: 2.874743256645898

Epoch: 6| Step: 10
Training loss: 0.6048962008676211
Validation loss: 2.903240751512292

Epoch: 6| Step: 11
Training loss: 0.35607430994617373
Validation loss: 2.853582027636602

Epoch: 6| Step: 12
Training loss: 0.45088839191508134
Validation loss: 2.9146734420520786

Epoch: 6| Step: 13
Training loss: 0.597764173748878
Validation loss: 2.8071706647869554

Epoch: 333| Step: 0
Training loss: 0.25063728525963863
Validation loss: 2.9730974455636425

Epoch: 6| Step: 1
Training loss: 0.3292864950587199
Validation loss: 2.829274922033422

Epoch: 6| Step: 2
Training loss: 0.2837849395515467
Validation loss: 2.945440072046549

Epoch: 6| Step: 3
Training loss: 0.4109125340061222
Validation loss: 2.8579474048673528

Epoch: 6| Step: 4
Training loss: 0.5693596496355244
Validation loss: 2.8421901854561282

Epoch: 6| Step: 5
Training loss: 0.2946366705802322
Validation loss: 2.8935688184534083

Epoch: 6| Step: 6
Training loss: 0.35204841094469047
Validation loss: 2.852436576202802

Epoch: 6| Step: 7
Training loss: 0.46253386966305476
Validation loss: 2.894487278544672

Epoch: 6| Step: 8
Training loss: 0.24431214982927688
Validation loss: 2.9342418213868693

Epoch: 6| Step: 9
Training loss: 0.44990268555734386
Validation loss: 2.8102591736035807

Epoch: 6| Step: 10
Training loss: 0.3240395935703192
Validation loss: 2.8785074027600563

Epoch: 6| Step: 11
Training loss: 0.4721558972682515
Validation loss: 2.8721901943069774

Epoch: 6| Step: 12
Training loss: 0.49011200065175814
Validation loss: 2.934461767439301

Epoch: 6| Step: 13
Training loss: 1.0338857087032824
Validation loss: 2.815655139475293

Epoch: 334| Step: 0
Training loss: 0.43830972058850853
Validation loss: 2.89710079329586

Epoch: 6| Step: 1
Training loss: 0.4900440743388852
Validation loss: 2.8977663097596724

Epoch: 6| Step: 2
Training loss: 0.29065983419953273
Validation loss: 2.8349047445119453

Epoch: 6| Step: 3
Training loss: 0.4440236765502705
Validation loss: 2.830238086786001

Epoch: 6| Step: 4
Training loss: 0.4298177695040778
Validation loss: 2.9931734085974258

Epoch: 6| Step: 5
Training loss: 0.3519328709573816
Validation loss: 2.8846927978854877

Epoch: 6| Step: 6
Training loss: 0.5145630159369673
Validation loss: 2.9623797417763473

Epoch: 6| Step: 7
Training loss: 0.4375909302085398
Validation loss: 2.9722992143334395

Epoch: 6| Step: 8
Training loss: 0.411021364741517
Validation loss: 2.8439098774329494

Epoch: 6| Step: 9
Training loss: 0.37845594646248976
Validation loss: 2.8723819532891968

Epoch: 6| Step: 10
Training loss: 0.2397244165879877
Validation loss: 2.8572671621961336

Epoch: 6| Step: 11
Training loss: 0.9470975746452396
Validation loss: 2.8095199196806266

Epoch: 6| Step: 12
Training loss: 0.3476795124457845
Validation loss: 2.8955955316251853

Epoch: 6| Step: 13
Training loss: 0.5493540297445416
Validation loss: 2.834187131219156

Epoch: 335| Step: 0
Training loss: 0.38938196769958405
Validation loss: 2.836303841405014

Epoch: 6| Step: 1
Training loss: 0.9756637099294777
Validation loss: 2.9193044768863903

Epoch: 6| Step: 2
Training loss: 0.5343627337113135
Validation loss: 2.8829209773356768

Epoch: 6| Step: 3
Training loss: 0.25387316268132093
Validation loss: 2.8475132728827743

Epoch: 6| Step: 4
Training loss: 0.38570170129702935
Validation loss: 2.767642590927985

Epoch: 6| Step: 5
Training loss: 0.32107529877230917
Validation loss: 2.8352067634719638

Epoch: 6| Step: 6
Training loss: 0.4094328904897652
Validation loss: 2.872379338668724

Epoch: 6| Step: 7
Training loss: 0.4947844220350505
Validation loss: 2.884435360581048

Epoch: 6| Step: 8
Training loss: 0.615332023500734
Validation loss: 2.8577613933061246

Epoch: 6| Step: 9
Training loss: 0.3243627343403745
Validation loss: 2.895580093142059

Epoch: 6| Step: 10
Training loss: 0.5175833647840609
Validation loss: 2.9115106285644106

Epoch: 6| Step: 11
Training loss: 0.32734298614922674
Validation loss: 2.845511453352897

Epoch: 6| Step: 12
Training loss: 0.46358028172445126
Validation loss: 2.8810613425628384

Epoch: 6| Step: 13
Training loss: 0.38514112168134224
Validation loss: 2.850135606473111

Epoch: 336| Step: 0
Training loss: 0.3252593999724104
Validation loss: 2.900960572968156

Epoch: 6| Step: 1
Training loss: 0.5234491717047883
Validation loss: 2.9157651779641935

Epoch: 6| Step: 2
Training loss: 0.3130788805874863
Validation loss: 2.9416594174721706

Epoch: 6| Step: 3
Training loss: 0.9620609074541431
Validation loss: 2.922265392205383

Epoch: 6| Step: 4
Training loss: 0.47552922280784404
Validation loss: 2.8998495742545054

Epoch: 6| Step: 5
Training loss: 0.40294790739876246
Validation loss: 2.903387800078777

Epoch: 6| Step: 6
Training loss: 0.432638352954887
Validation loss: 2.821299330077695

Epoch: 6| Step: 7
Training loss: 0.4510919904790164
Validation loss: 2.913093167043563

Epoch: 6| Step: 8
Training loss: 0.3769320150996869
Validation loss: 2.806220950377726

Epoch: 6| Step: 9
Training loss: 0.2887160183574705
Validation loss: 2.8610512175252785

Epoch: 6| Step: 10
Training loss: 0.3425166371752868
Validation loss: 2.9221145885244137

Epoch: 6| Step: 11
Training loss: 0.4107767407099786
Validation loss: 2.8212481749166303

Epoch: 6| Step: 12
Training loss: 0.3424537667861413
Validation loss: 2.899349374243292

Epoch: 6| Step: 13
Training loss: 0.5146160079322418
Validation loss: 2.964935743590921

Epoch: 337| Step: 0
Training loss: 0.39781963836426415
Validation loss: 2.83116264966401

Epoch: 6| Step: 1
Training loss: 0.44702713450804427
Validation loss: 2.889523916772727

Epoch: 6| Step: 2
Training loss: 0.4168922608332267
Validation loss: 2.9157829626209275

Epoch: 6| Step: 3
Training loss: 0.6625437704058142
Validation loss: 2.9474500324995545

Epoch: 6| Step: 4
Training loss: 0.42991049788746455
Validation loss: 2.985578364278936

Epoch: 6| Step: 5
Training loss: 0.60019133715767
Validation loss: 2.961164963975863

Epoch: 6| Step: 6
Training loss: 0.2930993107110505
Validation loss: 2.9711883035025566

Epoch: 6| Step: 7
Training loss: 0.39961178089957644
Validation loss: 2.8954931420677745

Epoch: 6| Step: 8
Training loss: 0.48799894182684567
Validation loss: 2.904616905422965

Epoch: 6| Step: 9
Training loss: 0.9686418288350807
Validation loss: 2.920950588660754

Epoch: 6| Step: 10
Training loss: 0.3684974597677722
Validation loss: 2.8717090180990392

Epoch: 6| Step: 11
Training loss: 0.5321087348070496
Validation loss: 2.915622351653057

Epoch: 6| Step: 12
Training loss: 0.6872125371419959
Validation loss: 2.8487475292222437

Epoch: 6| Step: 13
Training loss: 0.38432833225446117
Validation loss: 2.796784951804521

Epoch: 338| Step: 0
Training loss: 0.4225242881170327
Validation loss: 2.8688343387525834

Epoch: 6| Step: 1
Training loss: 0.43456770649675086
Validation loss: 2.909862269630226

Epoch: 6| Step: 2
Training loss: 0.6846893685897338
Validation loss: 2.911202220991482

Epoch: 6| Step: 3
Training loss: 0.7428752322863351
Validation loss: 2.8805354911508423

Epoch: 6| Step: 4
Training loss: 0.4116215462642549
Validation loss: 2.841027070572312

Epoch: 6| Step: 5
Training loss: 0.4565683939172788
Validation loss: 2.866174780613794

Epoch: 6| Step: 6
Training loss: 0.5298942769965544
Validation loss: 2.8589397300628847

Epoch: 6| Step: 7
Training loss: 0.5553293409997803
Validation loss: 2.8625756157961693

Epoch: 6| Step: 8
Training loss: 0.4740243453562137
Validation loss: 2.825653717619603

Epoch: 6| Step: 9
Training loss: 0.35911542391200324
Validation loss: 2.8029502369054717

Epoch: 6| Step: 10
Training loss: 0.8841875558363588
Validation loss: 2.8862822757159248

Epoch: 6| Step: 11
Training loss: 0.37648073551265615
Validation loss: 2.9090817782771703

Epoch: 6| Step: 12
Training loss: 0.7630926799256614
Validation loss: 2.8173938418238045

Epoch: 6| Step: 13
Training loss: 0.3485560826939823
Validation loss: 2.8297109916409813

Epoch: 339| Step: 0
Training loss: 0.5543793372981247
Validation loss: 2.792915055619138

Epoch: 6| Step: 1
Training loss: 0.6783475053753312
Validation loss: 2.9165114406878168

Epoch: 6| Step: 2
Training loss: 0.2620842502337389
Validation loss: 2.8411498706391503

Epoch: 6| Step: 3
Training loss: 0.32756696660665446
Validation loss: 2.8634115608403468

Epoch: 6| Step: 4
Training loss: 0.9865884871590028
Validation loss: 2.8698417165353054

Epoch: 6| Step: 5
Training loss: 0.6250155446980473
Validation loss: 2.871264103616927

Epoch: 6| Step: 6
Training loss: 0.5114733566232421
Validation loss: 2.8426627990795947

Epoch: 6| Step: 7
Training loss: 0.38105057049848606
Validation loss: 2.8817337898775177

Epoch: 6| Step: 8
Training loss: 0.41615706712299244
Validation loss: 2.841131870551317

Epoch: 6| Step: 9
Training loss: 0.4824137204365204
Validation loss: 2.882830336325172

Epoch: 6| Step: 10
Training loss: 0.2898759865120982
Validation loss: 2.8540721770932493

Epoch: 6| Step: 11
Training loss: 0.3614000197358857
Validation loss: 2.871872818274598

Epoch: 6| Step: 12
Training loss: 0.256374161576156
Validation loss: 2.880380143645372

Epoch: 6| Step: 13
Training loss: 0.25569762147364844
Validation loss: 2.8502464288281475

Epoch: 340| Step: 0
Training loss: 0.9504906880375589
Validation loss: 2.840800338050695

Epoch: 6| Step: 1
Training loss: 0.3369198342533807
Validation loss: 2.8964769256557736

Epoch: 6| Step: 2
Training loss: 0.3405124727792121
Validation loss: 2.8656286147388443

Epoch: 6| Step: 3
Training loss: 0.56025076564888
Validation loss: 2.792979406234224

Epoch: 6| Step: 4
Training loss: 0.3596965553674999
Validation loss: 2.928897462921379

Epoch: 6| Step: 5
Training loss: 0.5696392004115213
Validation loss: 2.870782329252046

Epoch: 6| Step: 6
Training loss: 0.4504569528379956
Validation loss: 2.915546520031455

Epoch: 6| Step: 7
Training loss: 0.47622959829170397
Validation loss: 2.894659975581238

Epoch: 6| Step: 8
Training loss: 0.29083894320235776
Validation loss: 2.9117407664619908

Epoch: 6| Step: 9
Training loss: 0.33608120794228785
Validation loss: 2.940567741417641

Epoch: 6| Step: 10
Training loss: 0.32668510763672787
Validation loss: 2.9419400092655303

Epoch: 6| Step: 11
Training loss: 0.5584741210884137
Validation loss: 2.8697462868722825

Epoch: 6| Step: 12
Training loss: 0.28842049262347236
Validation loss: 2.8501018110014833

Epoch: 6| Step: 13
Training loss: 0.49309605799982864
Validation loss: 2.8787512355773632

Epoch: 341| Step: 0
Training loss: 0.34244466158790854
Validation loss: 2.8952999630070058

Epoch: 6| Step: 1
Training loss: 0.4061002088372906
Validation loss: 2.8637382555481707

Epoch: 6| Step: 2
Training loss: 0.9204138474934271
Validation loss: 2.8999804479663367

Epoch: 6| Step: 3
Training loss: 0.38309056051021734
Validation loss: 2.8877728662191813

Epoch: 6| Step: 4
Training loss: 0.6040237164467436
Validation loss: 2.8414045170060334

Epoch: 6| Step: 5
Training loss: 0.6694211729136954
Validation loss: 2.8116149216122497

Epoch: 6| Step: 6
Training loss: 0.36748646678789043
Validation loss: 2.8786137439606496

Epoch: 6| Step: 7
Training loss: 0.40236843366737146
Validation loss: 2.8093782265785707

Epoch: 6| Step: 8
Training loss: 0.45658972189689495
Validation loss: 2.9020698455767313

Epoch: 6| Step: 9
Training loss: 0.38224598752866684
Validation loss: 2.8479283555597186

Epoch: 6| Step: 10
Training loss: 0.5667443154465989
Validation loss: 2.9191373759971007

Epoch: 6| Step: 11
Training loss: 0.3716013999833548
Validation loss: 2.8653300520080953

Epoch: 6| Step: 12
Training loss: 0.3725744121588087
Validation loss: 2.8108298959116347

Epoch: 6| Step: 13
Training loss: 0.31019433121669515
Validation loss: 2.839995704164077

Epoch: 342| Step: 0
Training loss: 0.3669148914413486
Validation loss: 2.8455635966923385

Epoch: 6| Step: 1
Training loss: 0.5527782355385977
Validation loss: 2.8342107204395925

Epoch: 6| Step: 2
Training loss: 0.42533811204803296
Validation loss: 2.8008561029012795

Epoch: 6| Step: 3
Training loss: 0.33301612418532933
Validation loss: 2.8787671439018823

Epoch: 6| Step: 4
Training loss: 0.5360566521141379
Validation loss: 2.8335287129598976

Epoch: 6| Step: 5
Training loss: 0.4373638418038423
Validation loss: 2.8852824835212862

Epoch: 6| Step: 6
Training loss: 0.45582803652799153
Validation loss: 2.876552604839235

Epoch: 6| Step: 7
Training loss: 0.3005702777474148
Validation loss: 2.8274476309732064

Epoch: 6| Step: 8
Training loss: 0.4157330623486557
Validation loss: 2.880860106042457

Epoch: 6| Step: 9
Training loss: 0.5420278176633092
Validation loss: 2.8273891805466933

Epoch: 6| Step: 10
Training loss: 0.37184594866330783
Validation loss: 2.8383659425058045

Epoch: 6| Step: 11
Training loss: 0.34325776837220573
Validation loss: 2.8282433585169287

Epoch: 6| Step: 12
Training loss: 0.9811496877724515
Validation loss: 2.8612166902717764

Epoch: 6| Step: 13
Training loss: 0.43106594926566644
Validation loss: 2.9188680016395883

Epoch: 343| Step: 0
Training loss: 0.5132762415161101
Validation loss: 2.8425239323324565

Epoch: 6| Step: 1
Training loss: 0.3623028366987557
Validation loss: 2.8033921164459006

Epoch: 6| Step: 2
Training loss: 0.36825078858487287
Validation loss: 2.827490663431517

Epoch: 6| Step: 3
Training loss: 0.4661877220839608
Validation loss: 2.846031098501257

Epoch: 6| Step: 4
Training loss: 0.41915335302589657
Validation loss: 2.842635806285947

Epoch: 6| Step: 5
Training loss: 0.5302519679772647
Validation loss: 2.858965220732272

Epoch: 6| Step: 6
Training loss: 0.4431572676129726
Validation loss: 2.9040403135188257

Epoch: 6| Step: 7
Training loss: 0.9809942774824469
Validation loss: 2.9321503726576825

Epoch: 6| Step: 8
Training loss: 0.42039909746996895
Validation loss: 2.8543470887195683

Epoch: 6| Step: 9
Training loss: 0.44828339098541753
Validation loss: 2.878606745316088

Epoch: 6| Step: 10
Training loss: 0.39723397788115833
Validation loss: 2.890152117565766

Epoch: 6| Step: 11
Training loss: 0.4968043067113513
Validation loss: 2.891085764960116

Epoch: 6| Step: 12
Training loss: 0.5302967326349709
Validation loss: 2.876222737456795

Epoch: 6| Step: 13
Training loss: 0.3577005102819952
Validation loss: 2.9827171101278576

Epoch: 344| Step: 0
Training loss: 0.3912383795039321
Validation loss: 2.8923860563861528

Epoch: 6| Step: 1
Training loss: 0.4031435599970776
Validation loss: 2.8464639310389246

Epoch: 6| Step: 2
Training loss: 0.4313309710960962
Validation loss: 2.794936149199952

Epoch: 6| Step: 3
Training loss: 0.4648321134248749
Validation loss: 2.8336414609050604

Epoch: 6| Step: 4
Training loss: 0.3250131870308729
Validation loss: 2.8730709680877817

Epoch: 6| Step: 5
Training loss: 0.2407059808801237
Validation loss: 2.961414174651788

Epoch: 6| Step: 6
Training loss: 0.3851569456206379
Validation loss: 2.8261023325911143

Epoch: 6| Step: 7
Training loss: 0.5760428332638324
Validation loss: 2.840316194452225

Epoch: 6| Step: 8
Training loss: 0.3822859042129212
Validation loss: 2.8622956637506314

Epoch: 6| Step: 9
Training loss: 0.3309421741958785
Validation loss: 2.9102301466603566

Epoch: 6| Step: 10
Training loss: 0.4130829795208441
Validation loss: 2.8094602193555684

Epoch: 6| Step: 11
Training loss: 0.49354852477054056
Validation loss: 2.957572521289018

Epoch: 6| Step: 12
Training loss: 0.29153235215223977
Validation loss: 2.8964136671926273

Epoch: 6| Step: 13
Training loss: 0.9476267018314846
Validation loss: 2.9060978319809525

Epoch: 345| Step: 0
Training loss: 0.37189713901046034
Validation loss: 2.9158835903901417

Epoch: 6| Step: 1
Training loss: 0.3958642930756158
Validation loss: 2.941403507604583

Epoch: 6| Step: 2
Training loss: 0.34947253058434524
Validation loss: 2.869216402047298

Epoch: 6| Step: 3
Training loss: 0.373598559614658
Validation loss: 2.8559164312951646

Epoch: 6| Step: 4
Training loss: 0.34796533881829167
Validation loss: 2.8982945738561274

Epoch: 6| Step: 5
Training loss: 0.6422541999055915
Validation loss: 2.861505732486859

Epoch: 6| Step: 6
Training loss: 0.49402716619490483
Validation loss: 2.8639848026018044

Epoch: 6| Step: 7
Training loss: 0.2867952042180013
Validation loss: 2.8849106125671984

Epoch: 6| Step: 8
Training loss: 0.2773916310631785
Validation loss: 2.8438494598546082

Epoch: 6| Step: 9
Training loss: 0.461053865905976
Validation loss: 2.8887986195554194

Epoch: 6| Step: 10
Training loss: 1.1165187407960913
Validation loss: 2.9529444052292892

Epoch: 6| Step: 11
Training loss: 0.3195062702180068
Validation loss: 2.8235459816855917

Epoch: 6| Step: 12
Training loss: 0.21234598398612403
Validation loss: 2.8798294278027528

Epoch: 6| Step: 13
Training loss: 0.3659128629044694
Validation loss: 2.847978864063636

Epoch: 346| Step: 0
Training loss: 1.0414525129798249
Validation loss: 2.824193170835279

Epoch: 6| Step: 1
Training loss: 0.4319172141315588
Validation loss: 2.876731655127886

Epoch: 6| Step: 2
Training loss: 0.4141327780336557
Validation loss: 2.84245841070531

Epoch: 6| Step: 3
Training loss: 0.31453870710467163
Validation loss: 2.85471168010892

Epoch: 6| Step: 4
Training loss: 0.46442038225752164
Validation loss: 2.9283435638182445

Epoch: 6| Step: 5
Training loss: 0.4682169744695583
Validation loss: 2.9488282204053293

Epoch: 6| Step: 6
Training loss: 0.4033166178610285
Validation loss: 2.8258354656406803

Epoch: 6| Step: 7
Training loss: 0.35229293389132876
Validation loss: 2.864882121831711

Epoch: 6| Step: 8
Training loss: 0.4400706720491396
Validation loss: 2.963671224987984

Epoch: 6| Step: 9
Training loss: 0.650860590866651
Validation loss: 2.842299905588091

Epoch: 6| Step: 10
Training loss: 0.46762783516088374
Validation loss: 2.8907232869252395

Epoch: 6| Step: 11
Training loss: 0.8208766632132936
Validation loss: 2.9016935801987955

Epoch: 6| Step: 12
Training loss: 0.3076784466495013
Validation loss: 2.8647144958060804

Epoch: 6| Step: 13
Training loss: 0.47156572248547207
Validation loss: 2.846062275589201

Epoch: 347| Step: 0
Training loss: 1.0641538426745007
Validation loss: 2.8607294873366134

Epoch: 6| Step: 1
Training loss: 0.5697542881488328
Validation loss: 2.906233619999273

Epoch: 6| Step: 2
Training loss: 0.510108364831362
Validation loss: 2.932279940232205

Epoch: 6| Step: 3
Training loss: 0.4437738237567507
Validation loss: 2.879357118467551

Epoch: 6| Step: 4
Training loss: 0.6432477945778464
Validation loss: 2.9107413367291275

Epoch: 6| Step: 5
Training loss: 0.6679261177244677
Validation loss: 2.9079477280444883

Epoch: 6| Step: 6
Training loss: 0.4429041504220379
Validation loss: 2.892033565415271

Epoch: 6| Step: 7
Training loss: 0.4248372734112096
Validation loss: 2.8916461824759767

Epoch: 6| Step: 8
Training loss: 0.5028459794093042
Validation loss: 2.901655770211427

Epoch: 6| Step: 9
Training loss: 0.41251066295251376
Validation loss: 2.893017632654093

Epoch: 6| Step: 10
Training loss: 0.4274229718966277
Validation loss: 2.8143846202157583

Epoch: 6| Step: 11
Training loss: 0.3807206121162917
Validation loss: 2.868892554215876

Epoch: 6| Step: 12
Training loss: 0.39878239383478165
Validation loss: 2.804695433992376

Epoch: 6| Step: 13
Training loss: 0.43664132730233346
Validation loss: 2.923723992358032

Epoch: 348| Step: 0
Training loss: 0.45501777346973504
Validation loss: 2.8400558119649135

Epoch: 6| Step: 1
Training loss: 0.4075576936215807
Validation loss: 2.904989440885647

Epoch: 6| Step: 2
Training loss: 0.4866581758184118
Validation loss: 2.864639660830556

Epoch: 6| Step: 3
Training loss: 1.0197209441171418
Validation loss: 2.920488732471488

Epoch: 6| Step: 4
Training loss: 0.49718204284300915
Validation loss: 2.9324501270325407

Epoch: 6| Step: 5
Training loss: 0.44990690844641923
Validation loss: 2.8261658572449466

Epoch: 6| Step: 6
Training loss: 0.4715655802884626
Validation loss: 2.7980627169993384

Epoch: 6| Step: 7
Training loss: 0.3830321518684396
Validation loss: 2.8631664216668233

Epoch: 6| Step: 8
Training loss: 0.2922090216477651
Validation loss: 2.8922283090727747

Epoch: 6| Step: 9
Training loss: 0.37670146862945775
Validation loss: 2.8619399387678315

Epoch: 6| Step: 10
Training loss: 0.37226137877341203
Validation loss: 2.794189598891206

Epoch: 6| Step: 11
Training loss: 0.5015732036173383
Validation loss: 2.8557488355852683

Epoch: 6| Step: 12
Training loss: 0.3917109652926086
Validation loss: 2.8658373405633366

Epoch: 6| Step: 13
Training loss: 0.5034111607088453
Validation loss: 2.8491359332214947

Epoch: 349| Step: 0
Training loss: 0.2933870889142108
Validation loss: 2.82088718916975

Epoch: 6| Step: 1
Training loss: 0.3486523128580241
Validation loss: 2.859012003997619

Epoch: 6| Step: 2
Training loss: 0.6140870552880272
Validation loss: 2.8435778653094377

Epoch: 6| Step: 3
Training loss: 0.42490864501152453
Validation loss: 2.864565448127168

Epoch: 6| Step: 4
Training loss: 0.5483241906993336
Validation loss: 2.8204096374972654

Epoch: 6| Step: 5
Training loss: 0.36070885042104506
Validation loss: 2.8565110697336755

Epoch: 6| Step: 6
Training loss: 0.4049167948188325
Validation loss: 2.926019527305826

Epoch: 6| Step: 7
Training loss: 0.5276239286627395
Validation loss: 2.900076376249046

Epoch: 6| Step: 8
Training loss: 0.22931064973751686
Validation loss: 2.8876769076343396

Epoch: 6| Step: 9
Training loss: 0.9762098056954102
Validation loss: 2.8314845046272197

Epoch: 6| Step: 10
Training loss: 0.4998261775427495
Validation loss: 2.847387593333424

Epoch: 6| Step: 11
Training loss: 0.40560728363587734
Validation loss: 2.840928651857946

Epoch: 6| Step: 12
Training loss: 0.4222588205980283
Validation loss: 2.91178062897943

Epoch: 6| Step: 13
Training loss: 0.5194101407572264
Validation loss: 2.8764731599636475

Epoch: 350| Step: 0
Training loss: 0.3220000588879028
Validation loss: 2.8867523645655773

Epoch: 6| Step: 1
Training loss: 0.530968872185249
Validation loss: 2.8514240806114484

Epoch: 6| Step: 2
Training loss: 0.3564002648720255
Validation loss: 2.8802025618446474

Epoch: 6| Step: 3
Training loss: 0.4438073336138448
Validation loss: 2.8639671680257472

Epoch: 6| Step: 4
Training loss: 0.37816722807471975
Validation loss: 2.938050549906926

Epoch: 6| Step: 5
Training loss: 0.4711639396291474
Validation loss: 2.8847898406069366

Epoch: 6| Step: 6
Training loss: 0.9771308770775876
Validation loss: 2.9140042937519186

Epoch: 6| Step: 7
Training loss: 0.49606947952134006
Validation loss: 2.934895652809352

Epoch: 6| Step: 8
Training loss: 0.480677272548453
Validation loss: 2.952601445258993

Epoch: 6| Step: 9
Training loss: 0.5809964703799005
Validation loss: 2.9408609898917817

Epoch: 6| Step: 10
Training loss: 0.36667369850236176
Validation loss: 2.8788052269003743

Epoch: 6| Step: 11
Training loss: 0.3319463172442562
Validation loss: 2.9406776826188503

Epoch: 6| Step: 12
Training loss: 0.42547093903941213
Validation loss: 2.918097013610425

Epoch: 6| Step: 13
Training loss: 0.23321998829150598
Validation loss: 2.88357777762918

Testing loss: 2.9426544724010477
