Epoch: 1| Step: 0
Training loss: 3.6285075614380475
Validation loss: 3.5240545585380247

Epoch: 5| Step: 1
Training loss: 4.153493095946025
Validation loss: 3.501348576273088

Epoch: 5| Step: 2
Training loss: 3.7008618871670613
Validation loss: 3.47420231859802

Epoch: 5| Step: 3
Training loss: 3.08601367711555
Validation loss: 3.451348565584791

Epoch: 5| Step: 4
Training loss: 3.5601157525349865
Validation loss: 3.4288608710553574

Epoch: 5| Step: 5
Training loss: 3.5464658795313646
Validation loss: 3.4069541996500305

Epoch: 5| Step: 6
Training loss: 3.7275675891707096
Validation loss: 3.3852946694718336

Epoch: 5| Step: 7
Training loss: 3.234562080611921
Validation loss: 3.3662000537353665

Epoch: 5| Step: 8
Training loss: 3.009613211484037
Validation loss: 3.345562500085137

Epoch: 5| Step: 9
Training loss: 3.8033424835585357
Validation loss: 3.327375473846922

Epoch: 5| Step: 10
Training loss: 3.208608409104114
Validation loss: 3.3073614258305177

Epoch: 5| Step: 11
Training loss: 4.606228857108341
Validation loss: 3.285286839173076

Epoch: 2| Step: 0
Training loss: 3.763976436658797
Validation loss: 3.2638830135283556

Epoch: 5| Step: 1
Training loss: 3.030942763656229
Validation loss: 3.244444047279711

Epoch: 5| Step: 2
Training loss: 3.1735677477329336
Validation loss: 3.2199654922946452

Epoch: 5| Step: 3
Training loss: 3.4223487560885406
Validation loss: 3.2005245042143033

Epoch: 5| Step: 4
Training loss: 2.881210916051346
Validation loss: 3.1787824600228474

Epoch: 5| Step: 5
Training loss: 3.6351174538380797
Validation loss: 3.1552494685322174

Epoch: 5| Step: 6
Training loss: 3.2651089347203746
Validation loss: 3.1302456538831303

Epoch: 5| Step: 7
Training loss: 3.2513935329341264
Validation loss: 3.1071764267411424

Epoch: 5| Step: 8
Training loss: 3.1022903779779276
Validation loss: 3.0791158517525523

Epoch: 5| Step: 9
Training loss: 3.147770586207183
Validation loss: 3.0563569771130212

Epoch: 5| Step: 10
Training loss: 3.0284010880371204
Validation loss: 3.0309439042481228

Epoch: 5| Step: 11
Training loss: 4.49753842314613
Validation loss: 3.006699161984789

Epoch: 3| Step: 0
Training loss: 3.4074529920821375
Validation loss: 2.9751991093146235

Epoch: 5| Step: 1
Training loss: 2.713984818738674
Validation loss: 2.946829276271231

Epoch: 5| Step: 2
Training loss: 3.265582070684486
Validation loss: 2.91498273989964

Epoch: 5| Step: 3
Training loss: 2.954609815523414
Validation loss: 2.8886476437900233

Epoch: 5| Step: 4
Training loss: 2.490309243666207
Validation loss: 2.8585189621893443

Epoch: 5| Step: 5
Training loss: 3.201200176716716
Validation loss: 2.829901062046954

Epoch: 5| Step: 6
Training loss: 2.842808997437331
Validation loss: 2.8048644404087097

Epoch: 5| Step: 7
Training loss: 3.3106864427162024
Validation loss: 2.7677806204957305

Epoch: 5| Step: 8
Training loss: 2.779636815312879
Validation loss: 2.7382029233315284

Epoch: 5| Step: 9
Training loss: 2.577906188927109
Validation loss: 2.7064544811920723

Epoch: 5| Step: 10
Training loss: 2.557436242972899
Validation loss: 2.680401802320244

Epoch: 5| Step: 11
Training loss: 3.291005192861804
Validation loss: 2.64841352768873

Epoch: 4| Step: 0
Training loss: 2.880949084937962
Validation loss: 2.621449794549735

Epoch: 5| Step: 1
Training loss: 2.7032917831213044
Validation loss: 2.59456228842429

Epoch: 5| Step: 2
Training loss: 2.6287898906559817
Validation loss: 2.5688990694339373

Epoch: 5| Step: 3
Training loss: 2.573444811608513
Validation loss: 2.539808601895768

Epoch: 5| Step: 4
Training loss: 2.6684943333537574
Validation loss: 2.5184849501016173

Epoch: 5| Step: 5
Training loss: 3.031855100032852
Validation loss: 2.4975560839290196

Epoch: 5| Step: 6
Training loss: 1.9759543467124305
Validation loss: 2.481989176786526

Epoch: 5| Step: 7
Training loss: 2.403100169119266
Validation loss: 2.4565870149278304

Epoch: 5| Step: 8
Training loss: 2.6813280961194037
Validation loss: 2.449946525048533

Epoch: 5| Step: 9
Training loss: 2.919140193760004
Validation loss: 2.4446339910041837

Epoch: 5| Step: 10
Training loss: 2.5317376691326405
Validation loss: 2.4401059810559755

Epoch: 5| Step: 11
Training loss: 2.080376688703427
Validation loss: 2.437196484440874

Epoch: 5| Step: 0
Training loss: 2.4850835209709095
Validation loss: 2.4368077175364764

Epoch: 5| Step: 1
Training loss: 2.3110365489808027
Validation loss: 2.4399708711795394

Epoch: 5| Step: 2
Training loss: 2.6325557594878677
Validation loss: 2.440856017097083

Epoch: 5| Step: 3
Training loss: 2.37005320911795
Validation loss: 2.447474974831308

Epoch: 5| Step: 4
Training loss: 2.7783179097089787
Validation loss: 2.4421587300655103

Epoch: 5| Step: 5
Training loss: 2.6918005135466903
Validation loss: 2.4452278764441076

Epoch: 5| Step: 6
Training loss: 2.474577966022553
Validation loss: 2.449344061931661

Epoch: 5| Step: 7
Training loss: 2.390985798256313
Validation loss: 2.4524005378985123

Epoch: 5| Step: 8
Training loss: 2.8984411193331514
Validation loss: 2.4554700859730496

Epoch: 5| Step: 9
Training loss: 2.4899679123676197
Validation loss: 2.4567568594949143

Epoch: 5| Step: 10
Training loss: 2.308025257838465
Validation loss: 2.4573131979699343

Epoch: 5| Step: 11
Training loss: 1.3705120537278948
Validation loss: 2.447044390973638

Epoch: 6| Step: 0
Training loss: 2.632919897950919
Validation loss: 2.4557908348088517

Epoch: 5| Step: 1
Training loss: 2.570932980115318
Validation loss: 2.451825261262626

Epoch: 5| Step: 2
Training loss: 2.20630551449361
Validation loss: 2.451954041775037

Epoch: 5| Step: 3
Training loss: 2.4589260055001456
Validation loss: 2.4529344440159653

Epoch: 5| Step: 4
Training loss: 3.2051493876808728
Validation loss: 2.451406182467368

Epoch: 5| Step: 5
Training loss: 2.24356982854591
Validation loss: 2.4544772573885996

Epoch: 5| Step: 6
Training loss: 2.4132029166556976
Validation loss: 2.4465263368379326

Epoch: 5| Step: 7
Training loss: 2.2453720392815972
Validation loss: 2.456530681213653

Epoch: 5| Step: 8
Training loss: 2.724464286851562
Validation loss: 2.440592910581695

Epoch: 5| Step: 9
Training loss: 2.381892492569908
Validation loss: 2.4571400119501257

Epoch: 5| Step: 10
Training loss: 2.3180403453748695
Validation loss: 2.4449318090796623

Epoch: 5| Step: 11
Training loss: 2.6791974834688888
Validation loss: 2.442654380663416

Epoch: 7| Step: 0
Training loss: 2.2450850104058366
Validation loss: 2.4483952838964202

Epoch: 5| Step: 1
Training loss: 2.7877614809569042
Validation loss: 2.4345141589373958

Epoch: 5| Step: 2
Training loss: 2.2999125007903025
Validation loss: 2.4385675880024533

Epoch: 5| Step: 3
Training loss: 2.116418677793776
Validation loss: 2.4357570505503157

Epoch: 5| Step: 4
Training loss: 2.0993701035538153
Validation loss: 2.435404957193028

Epoch: 5| Step: 5
Training loss: 2.3345669709593966
Validation loss: 2.4290119307251046

Epoch: 5| Step: 6
Training loss: 2.5758414588025853
Validation loss: 2.4376948881896467

Epoch: 5| Step: 7
Training loss: 2.569851448426539
Validation loss: 2.443307859272585

Epoch: 5| Step: 8
Training loss: 2.534173478135456
Validation loss: 2.4335545046332476

Epoch: 5| Step: 9
Training loss: 2.417481307043255
Validation loss: 2.431265013255335

Epoch: 5| Step: 10
Training loss: 3.079892033753001
Validation loss: 2.4317736751408794

Epoch: 5| Step: 11
Training loss: 3.704403041053169
Validation loss: 2.4334904305378533

Epoch: 8| Step: 0
Training loss: 2.300052961486076
Validation loss: 2.4350346748355807

Epoch: 5| Step: 1
Training loss: 2.707879884368981
Validation loss: 2.4329327072796825

Epoch: 5| Step: 2
Training loss: 3.064699434163999
Validation loss: 2.4356668376975623

Epoch: 5| Step: 3
Training loss: 2.5167034041226453
Validation loss: 2.4289016188623074

Epoch: 5| Step: 4
Training loss: 2.8196940496876595
Validation loss: 2.4295194124095376

Epoch: 5| Step: 5
Training loss: 2.60673325264156
Validation loss: 2.4267172387234477

Epoch: 5| Step: 6
Training loss: 2.2168267739586116
Validation loss: 2.431330257356122

Epoch: 5| Step: 7
Training loss: 2.4036512336932043
Validation loss: 2.432969684296458

Epoch: 5| Step: 8
Training loss: 2.3543493036863308
Validation loss: 2.4365916352802883

Epoch: 5| Step: 9
Training loss: 2.239545481753775
Validation loss: 2.4307148878158897

Epoch: 5| Step: 10
Training loss: 2.1594859733717775
Validation loss: 2.433901829045032

Epoch: 5| Step: 11
Training loss: 2.343379589056579
Validation loss: 2.426063693153911

Epoch: 9| Step: 0
Training loss: 2.3516555717020893
Validation loss: 2.4279443021460305

Epoch: 5| Step: 1
Training loss: 2.2646675980889523
Validation loss: 2.4260411637730046

Epoch: 5| Step: 2
Training loss: 2.5360677576369453
Validation loss: 2.430201268638897

Epoch: 5| Step: 3
Training loss: 2.5279398809117093
Validation loss: 2.428203043426034

Epoch: 5| Step: 4
Training loss: 2.4973753503006524
Validation loss: 2.4343752190553487

Epoch: 5| Step: 5
Training loss: 2.089930338268991
Validation loss: 2.425632552105913

Epoch: 5| Step: 6
Training loss: 2.566992380687431
Validation loss: 2.430628914104464

Epoch: 5| Step: 7
Training loss: 2.802843257902436
Validation loss: 2.4320460174370355

Epoch: 5| Step: 8
Training loss: 2.695106299432451
Validation loss: 2.430998375986902

Epoch: 5| Step: 9
Training loss: 2.8836212264379446
Validation loss: 2.419996905452941

Epoch: 5| Step: 10
Training loss: 2.1361749434748174
Validation loss: 2.431568562411376

Epoch: 5| Step: 11
Training loss: 2.3108227807716673
Validation loss: 2.42583469612514

Epoch: 10| Step: 0
Training loss: 2.335955973778591
Validation loss: 2.428426163700571

Epoch: 5| Step: 1
Training loss: 3.1056336557041595
Validation loss: 2.423401013412635

Epoch: 5| Step: 2
Training loss: 2.4870298583504993
Validation loss: 2.428289818948766

Epoch: 5| Step: 3
Training loss: 2.756806273778816
Validation loss: 2.4240489636767357

Epoch: 5| Step: 4
Training loss: 2.1639006516291013
Validation loss: 2.4272898898550515

Epoch: 5| Step: 5
Training loss: 2.168689504873527
Validation loss: 2.435690640282946

Epoch: 5| Step: 6
Training loss: 2.364585629992833
Validation loss: 2.4283979741130617

Epoch: 5| Step: 7
Training loss: 2.2399177360755878
Validation loss: 2.426507923915053

Epoch: 5| Step: 8
Training loss: 2.6823446817930314
Validation loss: 2.43035625155305

Epoch: 5| Step: 9
Training loss: 2.1671679968255444
Validation loss: 2.4339457992544

Epoch: 5| Step: 10
Training loss: 2.572649232708269
Validation loss: 2.431365530444741

Epoch: 5| Step: 11
Training loss: 3.3766582794938858
Validation loss: 2.4357778831714954

Epoch: 11| Step: 0
Training loss: 2.110518760006727
Validation loss: 2.4296308962656914

Epoch: 5| Step: 1
Training loss: 2.8975027381548317
Validation loss: 2.4318708032542244

Epoch: 5| Step: 2
Training loss: 2.4789417282340422
Validation loss: 2.430585541918626

Epoch: 5| Step: 3
Training loss: 2.2361374952867163
Validation loss: 2.4265445116583635

Epoch: 5| Step: 4
Training loss: 2.37964256680022
Validation loss: 2.424733794240289

Epoch: 5| Step: 5
Training loss: 1.994168243067504
Validation loss: 2.4231289314406705

Epoch: 5| Step: 6
Training loss: 1.975592635365407
Validation loss: 2.426932063457242

Epoch: 5| Step: 7
Training loss: 2.6161905240198373
Validation loss: 2.4268245327103584

Epoch: 5| Step: 8
Training loss: 2.915425572418296
Validation loss: 2.426685085012768

Epoch: 5| Step: 9
Training loss: 2.7903899979186813
Validation loss: 2.4226553244344498

Epoch: 5| Step: 10
Training loss: 2.7761827233831062
Validation loss: 2.4182643309142637

Epoch: 5| Step: 11
Training loss: 2.2310270823190415
Validation loss: 2.4183450425568016

Epoch: 12| Step: 0
Training loss: 2.5046843511474766
Validation loss: 2.41529390106562

Epoch: 5| Step: 1
Training loss: 2.0964549796622127
Validation loss: 2.419742088012498

Epoch: 5| Step: 2
Training loss: 2.1146840289214115
Validation loss: 2.4277165852900238

Epoch: 5| Step: 3
Training loss: 2.560525272839845
Validation loss: 2.4129345510728273

Epoch: 5| Step: 4
Training loss: 2.654564356291234
Validation loss: 2.417980315263459

Epoch: 5| Step: 5
Training loss: 2.778758529670587
Validation loss: 2.421427117228858

Epoch: 5| Step: 6
Training loss: 2.721643508544747
Validation loss: 2.420081727806091

Epoch: 5| Step: 7
Training loss: 2.2700319771888053
Validation loss: 2.419166588701682

Epoch: 5| Step: 8
Training loss: 2.1337103997228053
Validation loss: 2.414764695162683

Epoch: 5| Step: 9
Training loss: 3.0242806769504833
Validation loss: 2.4140717054601004

Epoch: 5| Step: 10
Training loss: 2.131467178331843
Validation loss: 2.418430545157898

Epoch: 5| Step: 11
Training loss: 3.263287013046294
Validation loss: 2.4264168390400043

Epoch: 13| Step: 0
Training loss: 2.7745085031829726
Validation loss: 2.416773854679319

Epoch: 5| Step: 1
Training loss: 2.462585672350213
Validation loss: 2.4133124765549527

Epoch: 5| Step: 2
Training loss: 2.305912842955397
Validation loss: 2.4160134992124993

Epoch: 5| Step: 3
Training loss: 2.7466572472339825
Validation loss: 2.4174699654039906

Epoch: 5| Step: 4
Training loss: 1.8309818344881819
Validation loss: 2.422687209742489

Epoch: 5| Step: 5
Training loss: 2.2531357213372365
Validation loss: 2.409268137783953

Epoch: 5| Step: 6
Training loss: 2.830597697518196
Validation loss: 2.4217330091137748

Epoch: 5| Step: 7
Training loss: 1.8616420485127563
Validation loss: 2.41327325126596

Epoch: 5| Step: 8
Training loss: 2.9788445963308248
Validation loss: 2.41491844121797

Epoch: 5| Step: 9
Training loss: 2.29057152908179
Validation loss: 2.4183144843481856

Epoch: 5| Step: 10
Training loss: 2.6592453168544647
Validation loss: 2.4147494387056136

Epoch: 5| Step: 11
Training loss: 2.6459525274226423
Validation loss: 2.419609415008892

Epoch: 14| Step: 0
Training loss: 2.813291141711904
Validation loss: 2.4217089852479283

Epoch: 5| Step: 1
Training loss: 2.172297374902839
Validation loss: 2.4165479792575444

Epoch: 5| Step: 2
Training loss: 2.2475262924879886
Validation loss: 2.422487526006244

Epoch: 5| Step: 3
Training loss: 2.1824416395077275
Validation loss: 2.410757874880231

Epoch: 5| Step: 4
Training loss: 2.9027101021096904
Validation loss: 2.423212252359447

Epoch: 5| Step: 5
Training loss: 2.630113706995356
Validation loss: 2.418737046012394

Epoch: 5| Step: 6
Training loss: 2.1149727473746442
Validation loss: 2.415359607427498

Epoch: 5| Step: 7
Training loss: 2.499126472450959
Validation loss: 2.4235222413663924

Epoch: 5| Step: 8
Training loss: 2.0388847653621283
Validation loss: 2.4234828124082535

Epoch: 5| Step: 9
Training loss: 2.4091319870759142
Validation loss: 2.414159834544511

Epoch: 5| Step: 10
Training loss: 2.9880753988534825
Validation loss: 2.4256226205687175

Epoch: 5| Step: 11
Training loss: 2.6319008898814817
Validation loss: 2.4208275980944385

Epoch: 15| Step: 0
Training loss: 2.7068179268061963
Validation loss: 2.420920801360772

Epoch: 5| Step: 1
Training loss: 2.3418615235225215
Validation loss: 2.422583486642579

Epoch: 5| Step: 2
Training loss: 2.472431576421368
Validation loss: 2.4250003010136787

Epoch: 5| Step: 3
Training loss: 2.8884741126734994
Validation loss: 2.4202001174109107

Epoch: 5| Step: 4
Training loss: 1.5261220118839975
Validation loss: 2.4208291164258604

Epoch: 5| Step: 5
Training loss: 3.107318907637613
Validation loss: 2.4279601671622926

Epoch: 5| Step: 6
Training loss: 2.519150437548729
Validation loss: 2.43154360412935

Epoch: 5| Step: 7
Training loss: 2.3040449895572372
Validation loss: 2.427463738396201

Epoch: 5| Step: 8
Training loss: 1.7047271891728029
Validation loss: 2.4396951278971857

Epoch: 5| Step: 9
Training loss: 2.740091506376725
Validation loss: 2.4417390459212758

Epoch: 5| Step: 10
Training loss: 2.1601586781603666
Validation loss: 2.4345003238619527

Epoch: 5| Step: 11
Training loss: 3.672549701144022
Validation loss: 2.4282729108314713

Epoch: 16| Step: 0
Training loss: 2.168175709786525
Validation loss: 2.4269172621190975

Epoch: 5| Step: 1
Training loss: 2.4119789984059192
Validation loss: 2.4184196762464603

Epoch: 5| Step: 2
Training loss: 2.318915771974788
Validation loss: 2.41455273141194

Epoch: 5| Step: 3
Training loss: 2.333118996539645
Validation loss: 2.413823968816442

Epoch: 5| Step: 4
Training loss: 2.27304965247027
Validation loss: 2.416611725632102

Epoch: 5| Step: 5
Training loss: 2.207583738058598
Validation loss: 2.4081724834735785

Epoch: 5| Step: 6
Training loss: 2.8512800520969246
Validation loss: 2.407519614518394

Epoch: 5| Step: 7
Training loss: 2.558456580292538
Validation loss: 2.409996583864949

Epoch: 5| Step: 8
Training loss: 2.906258695856026
Validation loss: 2.4107127111419704

Epoch: 5| Step: 9
Training loss: 2.523342449653851
Validation loss: 2.4085242435548966

Epoch: 5| Step: 10
Training loss: 2.4424242994589713
Validation loss: 2.4147119852065995

Epoch: 5| Step: 11
Training loss: 2.4970831066963
Validation loss: 2.408601722205034

Epoch: 17| Step: 0
Training loss: 2.412498485979781
Validation loss: 2.4080950570177606

Epoch: 5| Step: 1
Training loss: 2.2415187782183463
Validation loss: 2.4038500934959797

Epoch: 5| Step: 2
Training loss: 2.3625765672012986
Validation loss: 2.411194905722326

Epoch: 5| Step: 3
Training loss: 2.397210220310799
Validation loss: 2.4080458293447555

Epoch: 5| Step: 4
Training loss: 2.3581065627165176
Validation loss: 2.4081141405663513

Epoch: 5| Step: 5
Training loss: 2.266787842241664
Validation loss: 2.4164019856259604

Epoch: 5| Step: 6
Training loss: 2.6250822871798385
Validation loss: 2.4222385338745385

Epoch: 5| Step: 7
Training loss: 3.053598663540059
Validation loss: 2.412444968823012

Epoch: 5| Step: 8
Training loss: 2.5420664696935704
Validation loss: 2.4245010495179975

Epoch: 5| Step: 9
Training loss: 1.9502032589738578
Validation loss: 2.429335275287128

Epoch: 5| Step: 10
Training loss: 2.701114855293424
Validation loss: 2.427111598219987

Epoch: 5| Step: 11
Training loss: 2.775625649795508
Validation loss: 2.4271393648045905

Epoch: 18| Step: 0
Training loss: 2.7855874860641316
Validation loss: 2.4272585479512996

Epoch: 5| Step: 1
Training loss: 2.4968658829046335
Validation loss: 2.4259847738873677

Epoch: 5| Step: 2
Training loss: 2.428087007870959
Validation loss: 2.429306523750193

Epoch: 5| Step: 3
Training loss: 2.671262615140153
Validation loss: 2.426076865906562

Epoch: 5| Step: 4
Training loss: 1.7628528133625336
Validation loss: 2.4281914777586757

Epoch: 5| Step: 5
Training loss: 2.7236018242343456
Validation loss: 2.4247541479957624

Epoch: 5| Step: 6
Training loss: 2.5335263977602827
Validation loss: 2.4308789184968185

Epoch: 5| Step: 7
Training loss: 2.3007921306048433
Validation loss: 2.427420966495134

Epoch: 5| Step: 8
Training loss: 2.024115842723233
Validation loss: 2.425140318710792

Epoch: 5| Step: 9
Training loss: 2.4760844735016154
Validation loss: 2.4228906614220582

Epoch: 5| Step: 10
Training loss: 2.558421727578356
Validation loss: 2.4200725287873643

Epoch: 5| Step: 11
Training loss: 2.9799895495033075
Validation loss: 2.4262084134360564

Epoch: 19| Step: 0
Training loss: 2.2239159632867143
Validation loss: 2.4216149631484494

Epoch: 5| Step: 1
Training loss: 2.3705729332055423
Validation loss: 2.4177874536701474

Epoch: 5| Step: 2
Training loss: 2.297606682526479
Validation loss: 2.414221860199608

Epoch: 5| Step: 3
Training loss: 2.923074894105153
Validation loss: 2.409157734206363

Epoch: 5| Step: 4
Training loss: 2.1486425683381145
Validation loss: 2.401534968333963

Epoch: 5| Step: 5
Training loss: 2.6189138611577714
Validation loss: 2.405147683948585

Epoch: 5| Step: 6
Training loss: 2.557153287563378
Validation loss: 2.4053904166398032

Epoch: 5| Step: 7
Training loss: 2.32086760691385
Validation loss: 2.404791303133007

Epoch: 5| Step: 8
Training loss: 2.0948194363152544
Validation loss: 2.397331624839419

Epoch: 5| Step: 9
Training loss: 2.3126734075740347
Validation loss: 2.4039029238428564

Epoch: 5| Step: 10
Training loss: 2.769556731414865
Validation loss: 2.4108311405319154

Epoch: 5| Step: 11
Training loss: 3.4784258360200657
Validation loss: 2.407283635265687

Epoch: 20| Step: 0
Training loss: 2.8113948770103394
Validation loss: 2.412910474601191

Epoch: 5| Step: 1
Training loss: 2.3670075099489103
Validation loss: 2.4014954762153766

Epoch: 5| Step: 2
Training loss: 2.2771915234419864
Validation loss: 2.405381248165345

Epoch: 5| Step: 3
Training loss: 2.6308789496766214
Validation loss: 2.4029588196255727

Epoch: 5| Step: 4
Training loss: 2.3013781565010065
Validation loss: 2.414534558639312

Epoch: 5| Step: 5
Training loss: 2.130100188428737
Validation loss: 2.414087885915532

Epoch: 5| Step: 6
Training loss: 2.3824050304782447
Validation loss: 2.40776416483328

Epoch: 5| Step: 7
Training loss: 2.6668023035204564
Validation loss: 2.4127244584680256

Epoch: 5| Step: 8
Training loss: 2.460259044313121
Validation loss: 2.411977124417524

Epoch: 5| Step: 9
Training loss: 2.5130123052633526
Validation loss: 2.39697722756209

Epoch: 5| Step: 10
Training loss: 2.6992948882961887
Validation loss: 2.400753410782901

Epoch: 5| Step: 11
Training loss: 1.8996176485528238
Validation loss: 2.3998397844865766

Epoch: 21| Step: 0
Training loss: 2.1153101181037153
Validation loss: 2.402376558240044

Epoch: 5| Step: 1
Training loss: 2.4765632701595806
Validation loss: 2.406985447113626

Epoch: 5| Step: 2
Training loss: 2.5179147665431265
Validation loss: 2.404140708018495

Epoch: 5| Step: 3
Training loss: 2.7643863468855816
Validation loss: 2.4114289594362144

Epoch: 5| Step: 4
Training loss: 2.650397551604112
Validation loss: 2.4213343273150647

Epoch: 5| Step: 5
Training loss: 2.382293444522872
Validation loss: 2.42359815434366

Epoch: 5| Step: 6
Training loss: 2.33128971342158
Validation loss: 2.422215673625427

Epoch: 5| Step: 7
Training loss: 2.8199863403747014
Validation loss: 2.4468935404302865

Epoch: 5| Step: 8
Training loss: 2.348022838539944
Validation loss: 2.4345737971895396

Epoch: 5| Step: 9
Training loss: 2.562391790570874
Validation loss: 2.4333167084252274

Epoch: 5| Step: 10
Training loss: 2.074127942412565
Validation loss: 2.430194188608362

Epoch: 5| Step: 11
Training loss: 2.2602398242128565
Validation loss: 2.4303506312191807

Epoch: 22| Step: 0
Training loss: 2.193884334092049
Validation loss: 2.429613498652475

Epoch: 5| Step: 1
Training loss: 2.140395883146521
Validation loss: 2.423334239938121

Epoch: 5| Step: 2
Training loss: 2.386321339087892
Validation loss: 2.420684413110191

Epoch: 5| Step: 3
Training loss: 2.5133192975523375
Validation loss: 2.4177848446063805

Epoch: 5| Step: 4
Training loss: 2.7663568078066403
Validation loss: 2.417079554561806

Epoch: 5| Step: 5
Training loss: 2.916613242250437
Validation loss: 2.4208228132924323

Epoch: 5| Step: 6
Training loss: 1.9399695501199126
Validation loss: 2.4207182428990706

Epoch: 5| Step: 7
Training loss: 2.296522256143281
Validation loss: 2.4130624594756216

Epoch: 5| Step: 8
Training loss: 2.3332248617118023
Validation loss: 2.407968394690953

Epoch: 5| Step: 9
Training loss: 2.8301539440542625
Validation loss: 2.4078836633924805

Epoch: 5| Step: 10
Training loss: 2.3752527604371614
Validation loss: 2.4062480018244123

Epoch: 5| Step: 11
Training loss: 2.320939207373017
Validation loss: 2.4139652170869033

Epoch: 23| Step: 0
Training loss: 2.5019723741087194
Validation loss: 2.4146650934625864

Epoch: 5| Step: 1
Training loss: 2.669950271600545
Validation loss: 2.402931621130808

Epoch: 5| Step: 2
Training loss: 2.4776699345854234
Validation loss: 2.4065190903779397

Epoch: 5| Step: 3
Training loss: 2.0835327688761494
Validation loss: 2.401072168190961

Epoch: 5| Step: 4
Training loss: 2.9508251135416357
Validation loss: 2.397240861061672

Epoch: 5| Step: 5
Training loss: 2.6376869967010714
Validation loss: 2.4018960178874122

Epoch: 5| Step: 6
Training loss: 2.2990264158851024
Validation loss: 2.4031488945694495

Epoch: 5| Step: 7
Training loss: 2.126868604481711
Validation loss: 2.4022974438843603

Epoch: 5| Step: 8
Training loss: 2.3249155747046806
Validation loss: 2.400804600352259

Epoch: 5| Step: 9
Training loss: 2.197584829244613
Validation loss: 2.4012582368194786

Epoch: 5| Step: 10
Training loss: 2.577770324354614
Validation loss: 2.401898284383664

Epoch: 5| Step: 11
Training loss: 1.8165595533424836
Validation loss: 2.4104798427920087

Epoch: 24| Step: 0
Training loss: 2.4578736624410213
Validation loss: 2.4034432890346196

Epoch: 5| Step: 1
Training loss: 1.8907910739059335
Validation loss: 2.403140395486806

Epoch: 5| Step: 2
Training loss: 2.676160175752827
Validation loss: 2.408556658269177

Epoch: 5| Step: 3
Training loss: 2.3992056843468013
Validation loss: 2.408548718581182

Epoch: 5| Step: 4
Training loss: 2.2227089176742734
Validation loss: 2.400862160935191

Epoch: 5| Step: 5
Training loss: 2.3610904343640895
Validation loss: 2.4105172281106557

Epoch: 5| Step: 6
Training loss: 2.0857061479264156
Validation loss: 2.4133568465903417

Epoch: 5| Step: 7
Training loss: 2.703495860155004
Validation loss: 2.3962714389007136

Epoch: 5| Step: 8
Training loss: 2.5031952465930254
Validation loss: 2.4182184898726296

Epoch: 5| Step: 9
Training loss: 2.615156062850312
Validation loss: 2.423157231520983

Epoch: 5| Step: 10
Training loss: 2.8143700210828833
Validation loss: 2.4195433477867687

Epoch: 5| Step: 11
Training loss: 1.5102085978695061
Validation loss: 2.416994641235339

Epoch: 25| Step: 0
Training loss: 2.6363145306477365
Validation loss: 2.418114244380118

Epoch: 5| Step: 1
Training loss: 2.220888531006674
Validation loss: 2.4200174283550786

Epoch: 5| Step: 2
Training loss: 2.4217195522504658
Validation loss: 2.4126595347203237

Epoch: 5| Step: 3
Training loss: 2.112556601223168
Validation loss: 2.4203302933178636

Epoch: 5| Step: 4
Training loss: 2.365263203981512
Validation loss: 2.418359041940531

Epoch: 5| Step: 5
Training loss: 2.9563590612315314
Validation loss: 2.417649699470789

Epoch: 5| Step: 6
Training loss: 2.32637962099067
Validation loss: 2.4105727311443834

Epoch: 5| Step: 7
Training loss: 1.958315977736598
Validation loss: 2.405067508342194

Epoch: 5| Step: 8
Training loss: 2.5428277370656915
Validation loss: 2.3949592668298814

Epoch: 5| Step: 9
Training loss: 2.3485813444529553
Validation loss: 2.407846480601573

Epoch: 5| Step: 10
Training loss: 2.843519599719555
Validation loss: 2.4096052425095826

Epoch: 5| Step: 11
Training loss: 2.125357653869191
Validation loss: 2.413887865319698

Epoch: 26| Step: 0
Training loss: 1.9513794690225688
Validation loss: 2.4103612539526567

Epoch: 5| Step: 1
Training loss: 1.9230997788464887
Validation loss: 2.4069327339532687

Epoch: 5| Step: 2
Training loss: 2.9081660691687223
Validation loss: 2.412743316002385

Epoch: 5| Step: 3
Training loss: 2.2673454329562164
Validation loss: 2.4073194133810705

Epoch: 5| Step: 4
Training loss: 2.8059431150384255
Validation loss: 2.408386990720519

Epoch: 5| Step: 5
Training loss: 2.3058008640522942
Validation loss: 2.40796915378542

Epoch: 5| Step: 6
Training loss: 2.9415808394089447
Validation loss: 2.4101958186581736

Epoch: 5| Step: 7
Training loss: 2.9616944646380516
Validation loss: 2.414743072392274

Epoch: 5| Step: 8
Training loss: 2.0713498377752755
Validation loss: 2.404562393430671

Epoch: 5| Step: 9
Training loss: 2.420420252825295
Validation loss: 2.411809909367631

Epoch: 5| Step: 10
Training loss: 1.9053262442227126
Validation loss: 2.411125474591353

Epoch: 5| Step: 11
Training loss: 1.8345466702405058
Validation loss: 2.402801616837708

Epoch: 27| Step: 0
Training loss: 2.0715956831924474
Validation loss: 2.4113899918848976

Epoch: 5| Step: 1
Training loss: 2.418414985265058
Validation loss: 2.413271110713427

Epoch: 5| Step: 2
Training loss: 2.2226267512665183
Validation loss: 2.403553314467324

Epoch: 5| Step: 3
Training loss: 2.6230281508197115
Validation loss: 2.4068256119057714

Epoch: 5| Step: 4
Training loss: 2.9952948548339977
Validation loss: 2.41845076711824

Epoch: 5| Step: 5
Training loss: 1.879800880925613
Validation loss: 2.42220242450716

Epoch: 5| Step: 6
Training loss: 2.5401677469745527
Validation loss: 2.427465741616072

Epoch: 5| Step: 7
Training loss: 2.5094733992080904
Validation loss: 2.4310467711091683

Epoch: 5| Step: 8
Training loss: 2.6468901038161157
Validation loss: 2.427238317515665

Epoch: 5| Step: 9
Training loss: 2.420223731425723
Validation loss: 2.4193567370933686

Epoch: 5| Step: 10
Training loss: 2.395408979788303
Validation loss: 2.4196069043929933

Epoch: 5| Step: 11
Training loss: 1.0746205636110724
Validation loss: 2.408562399575307

Epoch: 28| Step: 0
Training loss: 2.839611857311331
Validation loss: 2.4181408530733064

Epoch: 5| Step: 1
Training loss: 1.6839385420849797
Validation loss: 2.3995682518426538

Epoch: 5| Step: 2
Training loss: 1.6805631262588567
Validation loss: 2.3959493332575574

Epoch: 5| Step: 3
Training loss: 2.661724866048842
Validation loss: 2.404256948949913

Epoch: 5| Step: 4
Training loss: 2.374218259951311
Validation loss: 2.412440667715783

Epoch: 5| Step: 5
Training loss: 1.9214505603077034
Validation loss: 2.395402603544964

Epoch: 5| Step: 6
Training loss: 2.2462564691398414
Validation loss: 2.3956185507212737

Epoch: 5| Step: 7
Training loss: 2.545711509008271
Validation loss: 2.400616996484968

Epoch: 5| Step: 8
Training loss: 2.797171891294316
Validation loss: 2.3974086820523444

Epoch: 5| Step: 9
Training loss: 2.7085743919101115
Validation loss: 2.3944601325322408

Epoch: 5| Step: 10
Training loss: 2.8552544926991383
Validation loss: 2.3959923912544734

Epoch: 5| Step: 11
Training loss: 1.897312411759693
Validation loss: 2.4145820618220992

Epoch: 29| Step: 0
Training loss: 2.0867678243392946
Validation loss: 2.3970948539975123

Epoch: 5| Step: 1
Training loss: 2.2072089469739393
Validation loss: 2.395335103488418

Epoch: 5| Step: 2
Training loss: 2.819526034355889
Validation loss: 2.41098331828987

Epoch: 5| Step: 3
Training loss: 2.5791891964948825
Validation loss: 2.416843631173518

Epoch: 5| Step: 4
Training loss: 2.0735440351171874
Validation loss: 2.4197535709026714

Epoch: 5| Step: 5
Training loss: 2.8071477189016725
Validation loss: 2.4159365995450903

Epoch: 5| Step: 6
Training loss: 2.5251789520604673
Validation loss: 2.423115017010821

Epoch: 5| Step: 7
Training loss: 2.7342680119973397
Validation loss: 2.4245051960652457

Epoch: 5| Step: 8
Training loss: 1.9564777132047393
Validation loss: 2.4202196924727235

Epoch: 5| Step: 9
Training loss: 2.2989683408278823
Validation loss: 2.4218791551451777

Epoch: 5| Step: 10
Training loss: 2.327263999307587
Validation loss: 2.418279986258682

Epoch: 5| Step: 11
Training loss: 2.5008160213018273
Validation loss: 2.418503477740487

Epoch: 30| Step: 0
Training loss: 1.9330000148838318
Validation loss: 2.413219205849735

Epoch: 5| Step: 1
Training loss: 2.0863288198018877
Validation loss: 2.4135495827130296

Epoch: 5| Step: 2
Training loss: 2.0178905440892487
Validation loss: 2.419178792943029

Epoch: 5| Step: 3
Training loss: 2.7543216040386644
Validation loss: 2.4203431853386443

Epoch: 5| Step: 4
Training loss: 2.7643824657914635
Validation loss: 2.4204369900634326

Epoch: 5| Step: 5
Training loss: 2.465673630383511
Validation loss: 2.419903914965059

Epoch: 5| Step: 6
Training loss: 2.591472867075512
Validation loss: 2.424435424956423

Epoch: 5| Step: 7
Training loss: 1.9758267446810585
Validation loss: 2.4200648157054436

Epoch: 5| Step: 8
Training loss: 2.4224432493949792
Validation loss: 2.419231674539893

Epoch: 5| Step: 9
Training loss: 2.7894377469358878
Validation loss: 2.417113907443162

Epoch: 5| Step: 10
Training loss: 2.194917039107226
Validation loss: 2.4235605158226288

Epoch: 5| Step: 11
Training loss: 3.8018838629806635
Validation loss: 2.4125299866942407

Epoch: 31| Step: 0
Training loss: 2.417681798716736
Validation loss: 2.400813790442299

Epoch: 5| Step: 1
Training loss: 2.257276530817252
Validation loss: 2.401306879672917

Epoch: 5| Step: 2
Training loss: 2.0145918689798115
Validation loss: 2.4023128269758818

Epoch: 5| Step: 3
Training loss: 2.81337520968953
Validation loss: 2.3986151812715892

Epoch: 5| Step: 4
Training loss: 2.471991427027086
Validation loss: 2.393661141800579

Epoch: 5| Step: 5
Training loss: 2.634006127792796
Validation loss: 2.3955515253490294

Epoch: 5| Step: 6
Training loss: 1.907370003786524
Validation loss: 2.3968168948747137

Epoch: 5| Step: 7
Training loss: 2.4390175814649866
Validation loss: 2.4009886892325847

Epoch: 5| Step: 8
Training loss: 2.4870961958960054
Validation loss: 2.396042078018872

Epoch: 5| Step: 9
Training loss: 2.552498068813449
Validation loss: 2.406658237060338

Epoch: 5| Step: 10
Training loss: 2.474240727954862
Validation loss: 2.4029441352051677

Epoch: 5| Step: 11
Training loss: 1.9036611894717892
Validation loss: 2.4049148818912167

Epoch: 32| Step: 0
Training loss: 2.448181127236421
Validation loss: 2.389181274595155

Epoch: 5| Step: 1
Training loss: 2.360086093883957
Validation loss: 2.397522232919179

Epoch: 5| Step: 2
Training loss: 2.232890029105795
Validation loss: 2.3961218777649362

Epoch: 5| Step: 3
Training loss: 2.6503752424767777
Validation loss: 2.4041380138992725

Epoch: 5| Step: 4
Training loss: 2.343381929106227
Validation loss: 2.396788441281667

Epoch: 5| Step: 5
Training loss: 2.61541323516687
Validation loss: 2.4132959862865575

Epoch: 5| Step: 6
Training loss: 2.2994997765959226
Validation loss: 2.4057362594274196

Epoch: 5| Step: 7
Training loss: 2.337805775924781
Validation loss: 2.411759404419644

Epoch: 5| Step: 8
Training loss: 2.673714879872216
Validation loss: 2.4111276829704766

Epoch: 5| Step: 9
Training loss: 1.933707987175452
Validation loss: 2.4189376389452737

Epoch: 5| Step: 10
Training loss: 2.7038471822781562
Validation loss: 2.42360688500338

Epoch: 5| Step: 11
Training loss: 1.3320049383971166
Validation loss: 2.4320598848550206

Epoch: 33| Step: 0
Training loss: 2.244975626076155
Validation loss: 2.416438919604626

Epoch: 5| Step: 1
Training loss: 2.301088477769952
Validation loss: 2.4184782757780057

Epoch: 5| Step: 2
Training loss: 2.436786449356625
Validation loss: 2.4155261428693278

Epoch: 5| Step: 3
Training loss: 2.4102868241068096
Validation loss: 2.4294688585366884

Epoch: 5| Step: 4
Training loss: 2.849687351679011
Validation loss: 2.428773599779276

Epoch: 5| Step: 5
Training loss: 2.624345243630051
Validation loss: 2.414684635228289

Epoch: 5| Step: 6
Training loss: 1.914339878458778
Validation loss: 2.4074191291756697

Epoch: 5| Step: 7
Training loss: 2.0425568670529746
Validation loss: 2.4114546676234374

Epoch: 5| Step: 8
Training loss: 2.610858974953869
Validation loss: 2.4011830655800077

Epoch: 5| Step: 9
Training loss: 2.7253807151890923
Validation loss: 2.4132926931590517

Epoch: 5| Step: 10
Training loss: 1.8172895355311238
Validation loss: 2.4197392306241383

Epoch: 5| Step: 11
Training loss: 2.871119824764675
Validation loss: 2.4107380334333683

Epoch: 34| Step: 0
Training loss: 1.8962758005558373
Validation loss: 2.411788313652972

Epoch: 5| Step: 1
Training loss: 2.292888269522986
Validation loss: 2.3944861867791274

Epoch: 5| Step: 2
Training loss: 2.7243737122265093
Validation loss: 2.3969080269936596

Epoch: 5| Step: 3
Training loss: 2.479429877490997
Validation loss: 2.401485928845487

Epoch: 5| Step: 4
Training loss: 2.6379147678051673
Validation loss: 2.400199400380204

Epoch: 5| Step: 5
Training loss: 2.3538761353489237
Validation loss: 2.4148118729401853

Epoch: 5| Step: 6
Training loss: 2.542853052463579
Validation loss: 2.395421039654499

Epoch: 5| Step: 7
Training loss: 2.5593922075338247
Validation loss: 2.3991613838528076

Epoch: 5| Step: 8
Training loss: 2.5124789640390564
Validation loss: 2.3981993802435904

Epoch: 5| Step: 9
Training loss: 2.2864549386267927
Validation loss: 2.3969433611024233

Epoch: 5| Step: 10
Training loss: 2.1966368457967764
Validation loss: 2.3951782339894145

Epoch: 5| Step: 11
Training loss: 1.4128462476777246
Validation loss: 2.402769891423371

Epoch: 35| Step: 0
Training loss: 2.30328719707974
Validation loss: 2.4040184076654927

Epoch: 5| Step: 1
Training loss: 2.3546235195446266
Validation loss: 2.3935545588389164

Epoch: 5| Step: 2
Training loss: 2.1543674820563226
Validation loss: 2.3946515043263803

Epoch: 5| Step: 3
Training loss: 2.458702016652171
Validation loss: 2.3991872504056775

Epoch: 5| Step: 4
Training loss: 2.615958491751428
Validation loss: 2.398817272541689

Epoch: 5| Step: 5
Training loss: 2.4308495395221743
Validation loss: 2.3997764577669844

Epoch: 5| Step: 6
Training loss: 2.568343501168864
Validation loss: 2.401096659187108

Epoch: 5| Step: 7
Training loss: 2.2989824449052283
Validation loss: 2.4123784336038177

Epoch: 5| Step: 8
Training loss: 2.2710395042783107
Validation loss: 2.3983727031160025

Epoch: 5| Step: 9
Training loss: 2.371671653343779
Validation loss: 2.4112123249921398

Epoch: 5| Step: 10
Training loss: 2.287813646670303
Validation loss: 2.418709320560846

Epoch: 5| Step: 11
Training loss: 2.619600373723342
Validation loss: 2.408238683202398

Epoch: 36| Step: 0
Training loss: 2.707889569435498
Validation loss: 2.4171791492425587

Epoch: 5| Step: 1
Training loss: 2.161733758375913
Validation loss: 2.416450109863847

Epoch: 5| Step: 2
Training loss: 2.513432085979265
Validation loss: 2.4249928022880836

Epoch: 5| Step: 3
Training loss: 2.4028154111743585
Validation loss: 2.414713466243515

Epoch: 5| Step: 4
Training loss: 2.6913603625102147
Validation loss: 2.415483757979373

Epoch: 5| Step: 5
Training loss: 2.0297186140651897
Validation loss: 2.4073459680744738

Epoch: 5| Step: 6
Training loss: 2.232445156880456
Validation loss: 2.406443724327161

Epoch: 5| Step: 7
Training loss: 2.2030349604827824
Validation loss: 2.3988726176691237

Epoch: 5| Step: 8
Training loss: 2.23099267154244
Validation loss: 2.395872569108426

Epoch: 5| Step: 9
Training loss: 2.501630346842321
Validation loss: 2.4053210100060824

Epoch: 5| Step: 10
Training loss: 2.4286716704957976
Validation loss: 2.390722185540526

Epoch: 5| Step: 11
Training loss: 2.7959978656897087
Validation loss: 2.404728214215862

Epoch: 37| Step: 0
Training loss: 2.268146453528908
Validation loss: 2.395652230646493

Epoch: 5| Step: 1
Training loss: 2.544374888754392
Validation loss: 2.40749136788183

Epoch: 5| Step: 2
Training loss: 2.1877671214904835
Validation loss: 2.4150688312493895

Epoch: 5| Step: 3
Training loss: 2.198030031965746
Validation loss: 2.4133153786000126

Epoch: 5| Step: 4
Training loss: 2.4427526560803985
Validation loss: 2.4062188753369216

Epoch: 5| Step: 5
Training loss: 1.9870322150818778
Validation loss: 2.4244020219624387

Epoch: 5| Step: 6
Training loss: 2.2855203452597377
Validation loss: 2.425113305495922

Epoch: 5| Step: 7
Training loss: 2.7197485657491898
Validation loss: 2.422785595989226

Epoch: 5| Step: 8
Training loss: 2.8198009248902594
Validation loss: 2.425299010407831

Epoch: 5| Step: 9
Training loss: 2.4418358020550848
Validation loss: 2.4245908378890944

Epoch: 5| Step: 10
Training loss: 2.317148536771258
Validation loss: 2.4381396685115595

Epoch: 5| Step: 11
Training loss: 1.3678275217892106
Validation loss: 2.421805639196656

Epoch: 38| Step: 0
Training loss: 2.6515142073361258
Validation loss: 2.428857839549153

Epoch: 5| Step: 1
Training loss: 2.0689109808760624
Validation loss: 2.41632605213109

Epoch: 5| Step: 2
Training loss: 1.998082970734104
Validation loss: 2.4041299211932388

Epoch: 5| Step: 3
Training loss: 2.4440422293141038
Validation loss: 2.4137432006563695

Epoch: 5| Step: 4
Training loss: 2.5469800307258996
Validation loss: 2.397374152472865

Epoch: 5| Step: 5
Training loss: 2.380644165026015
Validation loss: 2.3976183516547414

Epoch: 5| Step: 6
Training loss: 2.365717566832116
Validation loss: 2.397424887951347

Epoch: 5| Step: 7
Training loss: 2.3002305205550315
Validation loss: 2.4062124018188165

Epoch: 5| Step: 8
Training loss: 2.0451390716719606
Validation loss: 2.405172428762407

Epoch: 5| Step: 9
Training loss: 2.7508332984028323
Validation loss: 2.399547386372686

Epoch: 5| Step: 10
Training loss: 2.411490344720091
Validation loss: 2.4015597152114703

Epoch: 5| Step: 11
Training loss: 2.4002749086924573
Validation loss: 2.4066433853342453

Epoch: 39| Step: 0
Training loss: 2.642069043662927
Validation loss: 2.41578507100725

Epoch: 5| Step: 1
Training loss: 2.271757153756385
Validation loss: 2.4078553158210405

Epoch: 5| Step: 2
Training loss: 2.1919916088542295
Validation loss: 2.3948354605616338

Epoch: 5| Step: 3
Training loss: 2.4498321397847973
Validation loss: 2.403089342485243

Epoch: 5| Step: 4
Training loss: 2.2193066610580545
Validation loss: 2.414827746072207

Epoch: 5| Step: 5
Training loss: 2.243915490128173
Validation loss: 2.406421894687848

Epoch: 5| Step: 6
Training loss: 2.539482856579962
Validation loss: 2.415967467436376

Epoch: 5| Step: 7
Training loss: 2.0747250156426627
Validation loss: 2.4322101196788664

Epoch: 5| Step: 8
Training loss: 1.5997925445054813
Validation loss: 2.420718653277546

Epoch: 5| Step: 9
Training loss: 2.9961053681428096
Validation loss: 2.4205272246848772

Epoch: 5| Step: 10
Training loss: 2.567959250260513
Validation loss: 2.422608611044335

Epoch: 5| Step: 11
Training loss: 2.494793429337571
Validation loss: 2.4251959438076867

Epoch: 40| Step: 0
Training loss: 2.460111739869562
Validation loss: 2.397017113237134

Epoch: 5| Step: 1
Training loss: 2.4791307099456956
Validation loss: 2.4124557225869947

Epoch: 5| Step: 2
Training loss: 2.514255790795573
Validation loss: 2.400504651425138

Epoch: 5| Step: 3
Training loss: 2.518927260756632
Validation loss: 2.404892408428815

Epoch: 5| Step: 4
Training loss: 2.1759721271609047
Validation loss: 2.4030215994718356

Epoch: 5| Step: 5
Training loss: 1.8488827398902987
Validation loss: 2.3926220138572623

Epoch: 5| Step: 6
Training loss: 2.2801164920226342
Validation loss: 2.395504212924281

Epoch: 5| Step: 7
Training loss: 2.2105497957120326
Validation loss: 2.4039473311821578

Epoch: 5| Step: 8
Training loss: 2.5598368878852664
Validation loss: 2.3843085048497774

Epoch: 5| Step: 9
Training loss: 1.825723358398689
Validation loss: 2.3988418486773613

Epoch: 5| Step: 10
Training loss: 2.845796121453603
Validation loss: 2.3888440115604443

Epoch: 5| Step: 11
Training loss: 2.8073484925774457
Validation loss: 2.3924553249271145

Epoch: 41| Step: 0
Training loss: 2.0620189452535875
Validation loss: 2.3926078451996577

Epoch: 5| Step: 1
Training loss: 2.2594544667136134
Validation loss: 2.3966722940658305

Epoch: 5| Step: 2
Training loss: 2.3452865649980708
Validation loss: 2.3958239195818405

Epoch: 5| Step: 3
Training loss: 1.8737125427085253
Validation loss: 2.4198402512120833

Epoch: 5| Step: 4
Training loss: 2.119621651194823
Validation loss: 2.4178407067171364

Epoch: 5| Step: 5
Training loss: 2.6540190359725084
Validation loss: 2.438454897408366

Epoch: 5| Step: 6
Training loss: 2.9729672643948795
Validation loss: 2.460621009134188

Epoch: 5| Step: 7
Training loss: 1.939552327641339
Validation loss: 2.4623805543166317

Epoch: 5| Step: 8
Training loss: 2.8309470580933755
Validation loss: 2.4415400964286915

Epoch: 5| Step: 9
Training loss: 2.315456562376984
Validation loss: 2.444420681341823

Epoch: 5| Step: 10
Training loss: 2.2588268496217823
Validation loss: 2.435032433062755

Epoch: 5| Step: 11
Training loss: 3.49622959320583
Validation loss: 2.42328475201861

Epoch: 42| Step: 0
Training loss: 1.8852726862045386
Validation loss: 2.4093560653054658

Epoch: 5| Step: 1
Training loss: 1.9747921097869596
Validation loss: 2.4000862369342526

Epoch: 5| Step: 2
Training loss: 2.1444274098977565
Validation loss: 2.393362053359691

Epoch: 5| Step: 3
Training loss: 2.545175746103252
Validation loss: 2.395312063205096

Epoch: 5| Step: 4
Training loss: 2.3330255941269833
Validation loss: 2.379152148503658

Epoch: 5| Step: 5
Training loss: 3.082665826524578
Validation loss: 2.3857824733610324

Epoch: 5| Step: 6
Training loss: 2.60909694629245
Validation loss: 2.3865310045686323

Epoch: 5| Step: 7
Training loss: 2.4128397094631073
Validation loss: 2.382880140084537

Epoch: 5| Step: 8
Training loss: 2.065607677392853
Validation loss: 2.385805056047189

Epoch: 5| Step: 9
Training loss: 2.2495784364597444
Validation loss: 2.3898117701774786

Epoch: 5| Step: 10
Training loss: 2.4612573809341103
Validation loss: 2.3834618647692

Epoch: 5| Step: 11
Training loss: 1.5512301854567216
Validation loss: 2.384887538067121

Epoch: 43| Step: 0
Training loss: 2.4027643099231617
Validation loss: 2.379100543159392

Epoch: 5| Step: 1
Training loss: 2.2862665071303425
Validation loss: 2.380642347742477

Epoch: 5| Step: 2
Training loss: 1.9040937266441431
Validation loss: 2.382508793221225

Epoch: 5| Step: 3
Training loss: 2.004273022257148
Validation loss: 2.383687978953519

Epoch: 5| Step: 4
Training loss: 2.151106961962654
Validation loss: 2.3928036039852225

Epoch: 5| Step: 5
Training loss: 2.5544903880379204
Validation loss: 2.388255415986672

Epoch: 5| Step: 6
Training loss: 2.830100702441861
Validation loss: 2.4020289537892

Epoch: 5| Step: 7
Training loss: 2.4811492707299574
Validation loss: 2.4114909276276855

Epoch: 5| Step: 8
Training loss: 2.2128068010795268
Validation loss: 2.411370025868907

Epoch: 5| Step: 9
Training loss: 2.7036499219371257
Validation loss: 2.4144563240524217

Epoch: 5| Step: 10
Training loss: 2.126517259059087
Validation loss: 2.409402901635938

Epoch: 5| Step: 11
Training loss: 2.3961296782833243
Validation loss: 2.406271158265729

Epoch: 44| Step: 0
Training loss: 2.412115107849969
Validation loss: 2.410504118691068

Epoch: 5| Step: 1
Training loss: 1.6888943315858869
Validation loss: 2.41498164237096

Epoch: 5| Step: 2
Training loss: 2.2896499661117797
Validation loss: 2.411065847590435

Epoch: 5| Step: 3
Training loss: 2.5157740767952226
Validation loss: 2.4226682286856693

Epoch: 5| Step: 4
Training loss: 2.473325521280268
Validation loss: 2.4178422228155685

Epoch: 5| Step: 5
Training loss: 2.597655974653416
Validation loss: 2.410145141806783

Epoch: 5| Step: 6
Training loss: 2.3118283095315415
Validation loss: 2.409049420390727

Epoch: 5| Step: 7
Training loss: 2.6755964452034706
Validation loss: 2.3964060237131855

Epoch: 5| Step: 8
Training loss: 2.340958013132762
Validation loss: 2.3916906794783603

Epoch: 5| Step: 9
Training loss: 2.2246516008530914
Validation loss: 2.3902620443101776

Epoch: 5| Step: 10
Training loss: 2.070274381466593
Validation loss: 2.3887708575331055

Epoch: 5| Step: 11
Training loss: 2.6234736773488287
Validation loss: 2.3997148432140243

Epoch: 45| Step: 0
Training loss: 2.026718248957348
Validation loss: 2.3946371547725493

Epoch: 5| Step: 1
Training loss: 2.193510789137306
Validation loss: 2.393483136343772

Epoch: 5| Step: 2
Training loss: 1.8873567312068773
Validation loss: 2.3989439438921

Epoch: 5| Step: 3
Training loss: 1.7355400502587792
Validation loss: 2.4044852783361663

Epoch: 5| Step: 4
Training loss: 2.5827188889096813
Validation loss: 2.401710075190849

Epoch: 5| Step: 5
Training loss: 2.684428033982082
Validation loss: 2.398140564802474

Epoch: 5| Step: 6
Training loss: 2.837871638088153
Validation loss: 2.417309594682261

Epoch: 5| Step: 7
Training loss: 2.546277028662741
Validation loss: 2.4214694391126286

Epoch: 5| Step: 8
Training loss: 2.048559762199824
Validation loss: 2.413403841961448

Epoch: 5| Step: 9
Training loss: 2.491725005760767
Validation loss: 2.40366250828297

Epoch: 5| Step: 10
Training loss: 2.5661904347340547
Validation loss: 2.413763128521836

Epoch: 5| Step: 11
Training loss: 1.2670617131691921
Validation loss: 2.40244692035567

Epoch: 46| Step: 0
Training loss: 2.3709161682496656
Validation loss: 2.4080296330429314

Epoch: 5| Step: 1
Training loss: 2.207385225520003
Validation loss: 2.398105979481457

Epoch: 5| Step: 2
Training loss: 2.3784130067407436
Validation loss: 2.4008969548128674

Epoch: 5| Step: 3
Training loss: 2.141677708974591
Validation loss: 2.407751601544656

Epoch: 5| Step: 4
Training loss: 2.8730327675873055
Validation loss: 2.408345379408791

Epoch: 5| Step: 5
Training loss: 1.835145690289968
Validation loss: 2.4147088338861407

Epoch: 5| Step: 6
Training loss: 2.741659695076316
Validation loss: 2.403248450651456

Epoch: 5| Step: 7
Training loss: 1.8485020320717103
Validation loss: 2.4070851664255257

Epoch: 5| Step: 8
Training loss: 2.337085454564303
Validation loss: 2.408123447144786

Epoch: 5| Step: 9
Training loss: 2.5863304185417824
Validation loss: 2.400251239136734

Epoch: 5| Step: 10
Training loss: 2.026089495279836
Validation loss: 2.3871571730756274

Epoch: 5| Step: 11
Training loss: 2.0564334544056324
Validation loss: 2.3906670859627783

Epoch: 47| Step: 0
Training loss: 2.406258719292238
Validation loss: 2.3924973745408065

Epoch: 5| Step: 1
Training loss: 3.0404865292170897
Validation loss: 2.405230161541111

Epoch: 5| Step: 2
Training loss: 2.665403861815697
Validation loss: 2.410316503175167

Epoch: 5| Step: 3
Training loss: 1.8932284250655858
Validation loss: 2.4080659569964626

Epoch: 5| Step: 4
Training loss: 2.7746246805779893
Validation loss: 2.4201547850809364

Epoch: 5| Step: 5
Training loss: 1.877985611755861
Validation loss: 2.401116971278298

Epoch: 5| Step: 6
Training loss: 2.255628750724771
Validation loss: 2.4032885711983667

Epoch: 5| Step: 7
Training loss: 1.644341029675718
Validation loss: 2.3960161236126023

Epoch: 5| Step: 8
Training loss: 1.929908276488279
Validation loss: 2.4105500549219605

Epoch: 5| Step: 9
Training loss: 2.5170798507773267
Validation loss: 2.4029472523447044

Epoch: 5| Step: 10
Training loss: 2.2094980683103542
Validation loss: 2.4210934516190146

Epoch: 5| Step: 11
Training loss: 1.8456113439274973
Validation loss: 2.4050545096548146

Epoch: 48| Step: 0
Training loss: 2.344565796335421
Validation loss: 2.3999248991249433

Epoch: 5| Step: 1
Training loss: 2.3552143725037
Validation loss: 2.4112089857591776

Epoch: 5| Step: 2
Training loss: 1.6673355508723735
Validation loss: 2.402458146842514

Epoch: 5| Step: 3
Training loss: 2.265739911552462
Validation loss: 2.4242867735927374

Epoch: 5| Step: 4
Training loss: 2.3734888991616034
Validation loss: 2.4393885176089682

Epoch: 5| Step: 5
Training loss: 2.2531757195593225
Validation loss: 2.4305719440149898

Epoch: 5| Step: 6
Training loss: 2.08083367751667
Validation loss: 2.423463554742365

Epoch: 5| Step: 7
Training loss: 2.4763617689932538
Validation loss: 2.429058835879007

Epoch: 5| Step: 8
Training loss: 2.587529916636429
Validation loss: 2.4060008737482432

Epoch: 5| Step: 9
Training loss: 2.665844363346477
Validation loss: 2.4181660626605

Epoch: 5| Step: 10
Training loss: 2.191135002117319
Validation loss: 2.3950484455215544

Epoch: 5| Step: 11
Training loss: 2.462277777079886
Validation loss: 2.4043865997983933

Epoch: 49| Step: 0
Training loss: 2.3568629350457115
Validation loss: 2.398151513195773

Epoch: 5| Step: 1
Training loss: 1.9409658749984053
Validation loss: 2.397434370692634

Epoch: 5| Step: 2
Training loss: 2.8440279981949197
Validation loss: 2.403811718033847

Epoch: 5| Step: 3
Training loss: 1.9162196868270593
Validation loss: 2.4209649519395713

Epoch: 5| Step: 4
Training loss: 2.214272938528868
Validation loss: 2.40683888582198

Epoch: 5| Step: 5
Training loss: 1.9666433416481244
Validation loss: 2.422199161944243

Epoch: 5| Step: 6
Training loss: 2.801475789929747
Validation loss: 2.4420286316064046

Epoch: 5| Step: 7
Training loss: 2.636170913862978
Validation loss: 2.4315986558185267

Epoch: 5| Step: 8
Training loss: 1.9685183191975526
Validation loss: 2.4141926900084116

Epoch: 5| Step: 9
Training loss: 2.2584525392421417
Validation loss: 2.405791565132032

Epoch: 5| Step: 10
Training loss: 2.218392141791704
Validation loss: 2.3950653683588903

Epoch: 5| Step: 11
Training loss: 2.4486480486035913
Validation loss: 2.390628480181519

Epoch: 50| Step: 0
Training loss: 2.0339511224656066
Validation loss: 2.3949932691901603

Epoch: 5| Step: 1
Training loss: 2.8846730583489792
Validation loss: 2.389073190276381

Epoch: 5| Step: 2
Training loss: 2.990785912915214
Validation loss: 2.385756615537721

Epoch: 5| Step: 3
Training loss: 1.8204861013777194
Validation loss: 2.3954324939828853

Epoch: 5| Step: 4
Training loss: 1.6448336434237276
Validation loss: 2.401084801596044

Epoch: 5| Step: 5
Training loss: 2.0971762109667775
Validation loss: 2.398861099014051

Epoch: 5| Step: 6
Training loss: 2.37498825471885
Validation loss: 2.388669090654066

Epoch: 5| Step: 7
Training loss: 2.5363054066223216
Validation loss: 2.3931974312743582

Epoch: 5| Step: 8
Training loss: 2.2432342106467433
Validation loss: 2.3918132779135592

Epoch: 5| Step: 9
Training loss: 2.2464242708579576
Validation loss: 2.3838272664677183

Epoch: 5| Step: 10
Training loss: 2.064623115636154
Validation loss: 2.3998387413354294

Epoch: 5| Step: 11
Training loss: 2.472582968157758
Validation loss: 2.3843141212207546

Epoch: 51| Step: 0
Training loss: 2.8487103137490406
Validation loss: 2.3980255063033797

Epoch: 5| Step: 1
Training loss: 2.5370376729487445
Validation loss: 2.4111118411015675

Epoch: 5| Step: 2
Training loss: 1.966757719981713
Validation loss: 2.415342849400599

Epoch: 5| Step: 3
Training loss: 2.2341943414385783
Validation loss: 2.4260121070324376

Epoch: 5| Step: 4
Training loss: 1.9787188441606478
Validation loss: 2.4416015140012752

Epoch: 5| Step: 5
Training loss: 1.9066455618261609
Validation loss: 2.4512981002344603

Epoch: 5| Step: 6
Training loss: 1.9427843326160708
Validation loss: 2.4672316537795274

Epoch: 5| Step: 7
Training loss: 2.4371199678391666
Validation loss: 2.4987463231621834

Epoch: 5| Step: 8
Training loss: 2.4829586958290046
Validation loss: 2.47652140040746

Epoch: 5| Step: 9
Training loss: 2.8962958718899654
Validation loss: 2.4912455142781984

Epoch: 5| Step: 10
Training loss: 1.647582930936329
Validation loss: 2.4581480414394306

Epoch: 5| Step: 11
Training loss: 2.9263467280432596
Validation loss: 2.449392019548376

Epoch: 52| Step: 0
Training loss: 2.739262251416858
Validation loss: 2.4254906603674575

Epoch: 5| Step: 1
Training loss: 2.8967168178394496
Validation loss: 2.4191214710743965

Epoch: 5| Step: 2
Training loss: 2.2816170175118367
Validation loss: 2.4057608598558273

Epoch: 5| Step: 3
Training loss: 2.407672907244169
Validation loss: 2.393172346788963

Epoch: 5| Step: 4
Training loss: 1.7839757576223338
Validation loss: 2.38751441150663

Epoch: 5| Step: 5
Training loss: 2.235457471585914
Validation loss: 2.3923166726433895

Epoch: 5| Step: 6
Training loss: 2.393492132495503
Validation loss: 2.373644370798453

Epoch: 5| Step: 7
Training loss: 1.464175873135647
Validation loss: 2.391998964135372

Epoch: 5| Step: 8
Training loss: 2.2073786369305433
Validation loss: 2.381416514307615

Epoch: 5| Step: 9
Training loss: 2.465269314985719
Validation loss: 2.3842934680763013

Epoch: 5| Step: 10
Training loss: 2.191847377719438
Validation loss: 2.3778154433194567

Epoch: 5| Step: 11
Training loss: 1.765151036205765
Validation loss: 2.3739916748198437

Epoch: 53| Step: 0
Training loss: 2.190154835178756
Validation loss: 2.3860295617496448

Epoch: 5| Step: 1
Training loss: 2.2961920936189855
Validation loss: 2.382945714676683

Epoch: 5| Step: 2
Training loss: 1.8945087234888216
Validation loss: 2.379661991235643

Epoch: 5| Step: 3
Training loss: 2.1745415653862046
Validation loss: 2.393089719299573

Epoch: 5| Step: 4
Training loss: 2.1557873215672454
Validation loss: 2.4023843260442352

Epoch: 5| Step: 5
Training loss: 2.3868644907106438
Validation loss: 2.4053864973277457

Epoch: 5| Step: 6
Training loss: 2.1530744970237063
Validation loss: 2.4233730359237975

Epoch: 5| Step: 7
Training loss: 2.396577094910695
Validation loss: 2.425125475714587

Epoch: 5| Step: 8
Training loss: 2.2018795957363047
Validation loss: 2.419374105810882

Epoch: 5| Step: 9
Training loss: 2.8927624197493746
Validation loss: 2.4275698985870497

Epoch: 5| Step: 10
Training loss: 2.146914188299427
Validation loss: 2.4242271609236745

Epoch: 5| Step: 11
Training loss: 2.6135341367971647
Validation loss: 2.4261579973483864

Epoch: 54| Step: 0
Training loss: 2.2511375518623433
Validation loss: 2.4267787264684513

Epoch: 5| Step: 1
Training loss: 2.261734035091107
Validation loss: 2.407345400669558

Epoch: 5| Step: 2
Training loss: 1.9292236882702158
Validation loss: 2.3976011195121103

Epoch: 5| Step: 3
Training loss: 2.713801209868429
Validation loss: 2.3865750483379915

Epoch: 5| Step: 4
Training loss: 2.3696806717474543
Validation loss: 2.401259283491012

Epoch: 5| Step: 5
Training loss: 2.2553303416126393
Validation loss: 2.393169611264893

Epoch: 5| Step: 6
Training loss: 2.435489901661715
Validation loss: 2.380563798456401

Epoch: 5| Step: 7
Training loss: 2.119289241800509
Validation loss: 2.394777468893258

Epoch: 5| Step: 8
Training loss: 2.232259108649669
Validation loss: 2.37550041297567

Epoch: 5| Step: 9
Training loss: 2.525267702018523
Validation loss: 2.37069879014897

Epoch: 5| Step: 10
Training loss: 1.8755888967779686
Validation loss: 2.385158155556934

Epoch: 5| Step: 11
Training loss: 2.177637920895084
Validation loss: 2.395956829592286

Epoch: 55| Step: 0
Training loss: 2.035488108927009
Validation loss: 2.3860842063649166

Epoch: 5| Step: 1
Training loss: 2.302207414093818
Validation loss: 2.3877553774943836

Epoch: 5| Step: 2
Training loss: 2.1451297334861423
Validation loss: 2.39742975674389

Epoch: 5| Step: 3
Training loss: 2.4582142127535778
Validation loss: 2.3949413477339787

Epoch: 5| Step: 4
Training loss: 2.6096574093702425
Validation loss: 2.401294419120889

Epoch: 5| Step: 5
Training loss: 2.2362755648504105
Validation loss: 2.417790095601141

Epoch: 5| Step: 6
Training loss: 2.3644373060220665
Validation loss: 2.4288244319340726

Epoch: 5| Step: 7
Training loss: 2.616101668846596
Validation loss: 2.4110342824237154

Epoch: 5| Step: 8
Training loss: 1.5095926953133445
Validation loss: 2.412305490858453

Epoch: 5| Step: 9
Training loss: 2.200385480401018
Validation loss: 2.396555158818007

Epoch: 5| Step: 10
Training loss: 1.8178051227789092
Validation loss: 2.412705382563333

Epoch: 5| Step: 11
Training loss: 3.6089104687881237
Validation loss: 2.4055874312782364

Epoch: 56| Step: 0
Training loss: 2.306892400658898
Validation loss: 2.388232041187769

Epoch: 5| Step: 1
Training loss: 2.0682962063949386
Validation loss: 2.372459759707609

Epoch: 5| Step: 2
Training loss: 2.0970078359447473
Validation loss: 2.38867123453834

Epoch: 5| Step: 3
Training loss: 2.7656493967133238
Validation loss: 2.3991905815270416

Epoch: 5| Step: 4
Training loss: 2.644648809933156
Validation loss: 2.3932978869600814

Epoch: 5| Step: 5
Training loss: 1.5267509227029683
Validation loss: 2.392366954800636

Epoch: 5| Step: 6
Training loss: 2.150451603855549
Validation loss: 2.399540180705443

Epoch: 5| Step: 7
Training loss: 2.9353378130084193
Validation loss: 2.4029337502230517

Epoch: 5| Step: 8
Training loss: 2.2820159462347385
Validation loss: 2.4085736882960855

Epoch: 5| Step: 9
Training loss: 2.2464199194220615
Validation loss: 2.401456310246765

Epoch: 5| Step: 10
Training loss: 1.971811608506172
Validation loss: 2.4079490665800227

Epoch: 5| Step: 11
Training loss: 1.9550998316883146
Validation loss: 2.3850520339757115

Epoch: 57| Step: 0
Training loss: 2.1883719749941832
Validation loss: 2.389294973239463

Epoch: 5| Step: 1
Training loss: 2.1516899874502147
Validation loss: 2.3991374093215465

Epoch: 5| Step: 2
Training loss: 2.3233426534537833
Validation loss: 2.438185951923499

Epoch: 5| Step: 3
Training loss: 2.2791336903345467
Validation loss: 2.4517471955461847

Epoch: 5| Step: 4
Training loss: 2.5228486215459553
Validation loss: 2.497507104128489

Epoch: 5| Step: 5
Training loss: 2.2635025079543483
Validation loss: 2.5109193398864007

Epoch: 5| Step: 6
Training loss: 2.2118313872863165
Validation loss: 2.55283633560906

Epoch: 5| Step: 7
Training loss: 1.5924232794996842
Validation loss: 2.5604492797409253

Epoch: 5| Step: 8
Training loss: 2.4931089796353425
Validation loss: 2.553872766953053

Epoch: 5| Step: 9
Training loss: 2.7276598626691
Validation loss: 2.5305035868146133

Epoch: 5| Step: 10
Training loss: 2.0584955354891847
Validation loss: 2.499998601277278

Epoch: 5| Step: 11
Training loss: 3.814906627067324
Validation loss: 2.458457536846466

Epoch: 58| Step: 0
Training loss: 2.454735876974956
Validation loss: 2.4106974867331297

Epoch: 5| Step: 1
Training loss: 2.2717050984696145
Validation loss: 2.4029485628650264

Epoch: 5| Step: 2
Training loss: 2.1956906247559362
Validation loss: 2.385487548463545

Epoch: 5| Step: 3
Training loss: 2.4152331430431113
Validation loss: 2.3865874317294327

Epoch: 5| Step: 4
Training loss: 2.38246427399147
Validation loss: 2.399783461954913

Epoch: 5| Step: 5
Training loss: 2.143941495922744
Validation loss: 2.4072938157824026

Epoch: 5| Step: 6
Training loss: 2.1756534778601804
Validation loss: 2.3921514304490086

Epoch: 5| Step: 7
Training loss: 2.3127520655815674
Validation loss: 2.412965099191402

Epoch: 5| Step: 8
Training loss: 2.109339508888345
Validation loss: 2.402642245472949

Epoch: 5| Step: 9
Training loss: 2.2096420105157826
Validation loss: 2.3987055927921754

Epoch: 5| Step: 10
Training loss: 2.3699261525877726
Validation loss: 2.395608503047844

Epoch: 5| Step: 11
Training loss: 2.435884967699973
Validation loss: 2.389149761248803

Epoch: 59| Step: 0
Training loss: 1.9788707177262403
Validation loss: 2.395706854812735

Epoch: 5| Step: 1
Training loss: 2.2337070346963155
Validation loss: 2.392133174705461

Epoch: 5| Step: 2
Training loss: 2.9931129239615966
Validation loss: 2.390736450556085

Epoch: 5| Step: 3
Training loss: 2.5441188760369897
Validation loss: 2.384089960248552

Epoch: 5| Step: 4
Training loss: 2.0569587019584277
Validation loss: 2.392382484793326

Epoch: 5| Step: 5
Training loss: 2.263972028000102
Validation loss: 2.4139551943372872

Epoch: 5| Step: 6
Training loss: 2.2506563500888066
Validation loss: 2.4011834875715192

Epoch: 5| Step: 7
Training loss: 2.084538479961086
Validation loss: 2.418731474661711

Epoch: 5| Step: 8
Training loss: 1.8440572191740392
Validation loss: 2.4016328581690023

Epoch: 5| Step: 9
Training loss: 1.8923234482807658
Validation loss: 2.4055701653697867

Epoch: 5| Step: 10
Training loss: 2.0442215121853473
Validation loss: 2.4130332999700235

Epoch: 5| Step: 11
Training loss: 2.933229629533002
Validation loss: 2.4251151119846126

Epoch: 60| Step: 0
Training loss: 2.3448351573144812
Validation loss: 2.434040173547235

Epoch: 5| Step: 1
Training loss: 1.936875150273709
Validation loss: 2.4348981126308824

Epoch: 5| Step: 2
Training loss: 2.194165999483306
Validation loss: 2.437021823995351

Epoch: 5| Step: 3
Training loss: 2.250656244155893
Validation loss: 2.4158111337701254

Epoch: 5| Step: 4
Training loss: 2.0060552484695204
Validation loss: 2.425312887731678

Epoch: 5| Step: 5
Training loss: 2.624382037130407
Validation loss: 2.433728622038292

Epoch: 5| Step: 6
Training loss: 2.304623153564124
Validation loss: 2.4256870458292097

Epoch: 5| Step: 7
Training loss: 1.6956788119963548
Validation loss: 2.4143817941476406

Epoch: 5| Step: 8
Training loss: 2.178777470549555
Validation loss: 2.3904639212667638

Epoch: 5| Step: 9
Training loss: 2.434324592587524
Validation loss: 2.397421357552613

Epoch: 5| Step: 10
Training loss: 2.2701742866593047
Validation loss: 2.405560266633544

Epoch: 5| Step: 11
Training loss: 2.7537033114499163
Validation loss: 2.402648071201049

Epoch: 61| Step: 0
Training loss: 2.3496307854061396
Validation loss: 2.3953365529597272

Epoch: 5| Step: 1
Training loss: 2.8146198337163777
Validation loss: 2.3772669271324536

Epoch: 5| Step: 2
Training loss: 1.673090198997084
Validation loss: 2.3711166255042273

Epoch: 5| Step: 3
Training loss: 2.1836945266534156
Validation loss: 2.378911223508149

Epoch: 5| Step: 4
Training loss: 2.2536366002248016
Validation loss: 2.386421301621159

Epoch: 5| Step: 5
Training loss: 1.756267631686614
Validation loss: 2.3923701438554885

Epoch: 5| Step: 6
Training loss: 2.1530575546530755
Validation loss: 2.366075101200074

Epoch: 5| Step: 7
Training loss: 2.1954940775107468
Validation loss: 2.37893807025042

Epoch: 5| Step: 8
Training loss: 1.9471807738769418
Validation loss: 2.39503183364949

Epoch: 5| Step: 9
Training loss: 2.8267574481361613
Validation loss: 2.3983310692416175

Epoch: 5| Step: 10
Training loss: 1.8857756285267953
Validation loss: 2.399924646625131

Epoch: 5| Step: 11
Training loss: 2.552502925919697
Validation loss: 2.4069204573002536

Epoch: 62| Step: 0
Training loss: 1.9077029085042247
Validation loss: 2.3981773906410284

Epoch: 5| Step: 1
Training loss: 2.0942534795037524
Validation loss: 2.4076340893315935

Epoch: 5| Step: 2
Training loss: 2.0217547986768576
Validation loss: 2.4225352792103267

Epoch: 5| Step: 3
Training loss: 2.031594349943455
Validation loss: 2.4155979006103836

Epoch: 5| Step: 4
Training loss: 2.669573500926574
Validation loss: 2.430207081443005

Epoch: 5| Step: 5
Training loss: 2.1669605006978028
Validation loss: 2.418197785326634

Epoch: 5| Step: 6
Training loss: 2.4770993393962923
Validation loss: 2.4068536744303475

Epoch: 5| Step: 7
Training loss: 2.1750639412787667
Validation loss: 2.414346112460214

Epoch: 5| Step: 8
Training loss: 2.289196440127343
Validation loss: 2.404544126563026

Epoch: 5| Step: 9
Training loss: 2.123932289710963
Validation loss: 2.3818477657952934

Epoch: 5| Step: 10
Training loss: 2.2441199080106085
Validation loss: 2.3961491846505236

Epoch: 5| Step: 11
Training loss: 2.3264134407329453
Validation loss: 2.3912608520678997

Epoch: 63| Step: 0
Training loss: 1.8901004536489676
Validation loss: 2.388145137090642

Epoch: 5| Step: 1
Training loss: 2.172534650344109
Validation loss: 2.38972308197276

Epoch: 5| Step: 2
Training loss: 1.9261356050955807
Validation loss: 2.381470745431311

Epoch: 5| Step: 3
Training loss: 2.5416190554636042
Validation loss: 2.407552861814784

Epoch: 5| Step: 4
Training loss: 2.4116295464679007
Validation loss: 2.4116210484380796

Epoch: 5| Step: 5
Training loss: 2.2874435584604247
Validation loss: 2.430930384994813

Epoch: 5| Step: 6
Training loss: 2.0827993725923166
Validation loss: 2.439403695307422

Epoch: 5| Step: 7
Training loss: 2.1142357100461333
Validation loss: 2.4248447340650214

Epoch: 5| Step: 8
Training loss: 2.2434429415509163
Validation loss: 2.440070748821268

Epoch: 5| Step: 9
Training loss: 1.907862872084359
Validation loss: 2.4305927577274873

Epoch: 5| Step: 10
Training loss: 2.699285349044974
Validation loss: 2.435917222234479

Epoch: 5| Step: 11
Training loss: 1.5029536413275482
Validation loss: 2.408741181619257

Epoch: 64| Step: 0
Training loss: 1.776283098592971
Validation loss: 2.413169901575906

Epoch: 5| Step: 1
Training loss: 2.238437081283281
Validation loss: 2.4030092366929106

Epoch: 5| Step: 2
Training loss: 1.819981033205406
Validation loss: 2.402385829153831

Epoch: 5| Step: 3
Training loss: 2.0762423829014165
Validation loss: 2.381943668328898

Epoch: 5| Step: 4
Training loss: 2.0257465634684655
Validation loss: 2.388832766837193

Epoch: 5| Step: 5
Training loss: 2.468563217630052
Validation loss: 2.3942150095905212

Epoch: 5| Step: 6
Training loss: 2.6742016215866613
Validation loss: 2.3794538037939925

Epoch: 5| Step: 7
Training loss: 2.015729679671858
Validation loss: 2.380675732542826

Epoch: 5| Step: 8
Training loss: 2.247018003621656
Validation loss: 2.3892460359405634

Epoch: 5| Step: 9
Training loss: 2.1489419240936787
Validation loss: 2.3859995035551766

Epoch: 5| Step: 10
Training loss: 2.3103755781018913
Validation loss: 2.384817357690688

Epoch: 5| Step: 11
Training loss: 2.4998796434041277
Validation loss: 2.3755388317891364

Epoch: 65| Step: 0
Training loss: 2.204680847114674
Validation loss: 2.39735988137217

Epoch: 5| Step: 1
Training loss: 2.2258725887689765
Validation loss: 2.376613081695378

Epoch: 5| Step: 2
Training loss: 2.08384708427809
Validation loss: 2.38619924948591

Epoch: 5| Step: 3
Training loss: 2.2955102304319137
Validation loss: 2.4091947709956525

Epoch: 5| Step: 4
Training loss: 2.0422079445735672
Validation loss: 2.385729071026354

Epoch: 5| Step: 5
Training loss: 2.4994747563777824
Validation loss: 2.4116507728749785

Epoch: 5| Step: 6
Training loss: 2.0882715318470098
Validation loss: 2.4148871362072075

Epoch: 5| Step: 7
Training loss: 2.381992686839372
Validation loss: 2.3972870327923608

Epoch: 5| Step: 8
Training loss: 1.6738436507903776
Validation loss: 2.401352964950956

Epoch: 5| Step: 9
Training loss: 2.0800514183658185
Validation loss: 2.4192597697278426

Epoch: 5| Step: 10
Training loss: 2.3285626505720565
Validation loss: 2.4175519280969473

Epoch: 5| Step: 11
Training loss: 1.523126815024677
Validation loss: 2.399172170243394

Epoch: 66| Step: 0
Training loss: 2.207131820682863
Validation loss: 2.3969016360875606

Epoch: 5| Step: 1
Training loss: 2.034109362532574
Validation loss: 2.3907602807956514

Epoch: 5| Step: 2
Training loss: 2.4456121974018217
Validation loss: 2.4256274778121956

Epoch: 5| Step: 3
Training loss: 1.5649560317666804
Validation loss: 2.4170928666952043

Epoch: 5| Step: 4
Training loss: 2.83214624631827
Validation loss: 2.416624489503884

Epoch: 5| Step: 5
Training loss: 1.6532213121708754
Validation loss: 2.4418093539285106

Epoch: 5| Step: 6
Training loss: 1.909766970794135
Validation loss: 2.4464524509589096

Epoch: 5| Step: 7
Training loss: 2.148405872458964
Validation loss: 2.439937774510964

Epoch: 5| Step: 8
Training loss: 2.453036069776644
Validation loss: 2.4319279430753533

Epoch: 5| Step: 9
Training loss: 2.343645322369451
Validation loss: 2.4004803551005987

Epoch: 5| Step: 10
Training loss: 1.716317206370638
Validation loss: 2.4025321286990953

Epoch: 5| Step: 11
Training loss: 2.528896132134581
Validation loss: 2.4033086932233534

Epoch: 67| Step: 0
Training loss: 1.9048478019169977
Validation loss: 2.3772338433945066

Epoch: 5| Step: 1
Training loss: 2.2648284564204237
Validation loss: 2.3981355918210943

Epoch: 5| Step: 2
Training loss: 2.230638273781626
Validation loss: 2.3528886838493874

Epoch: 5| Step: 3
Training loss: 2.337576912823246
Validation loss: 2.3771540447943447

Epoch: 5| Step: 4
Training loss: 2.027204740311907
Validation loss: 2.3745965907827933

Epoch: 5| Step: 5
Training loss: 2.4646299725911054
Validation loss: 2.3902064436969876

Epoch: 5| Step: 6
Training loss: 1.7595579848321834
Validation loss: 2.3789455930466294

Epoch: 5| Step: 7
Training loss: 2.41239264056627
Validation loss: 2.3778858700369967

Epoch: 5| Step: 8
Training loss: 1.9626842485181113
Validation loss: 2.384986804699733

Epoch: 5| Step: 9
Training loss: 2.345612663157318
Validation loss: 2.404588476616314

Epoch: 5| Step: 10
Training loss: 1.723451599450769
Validation loss: 2.393909898535259

Epoch: 5| Step: 11
Training loss: 2.744480055047311
Validation loss: 2.400103128389764

Epoch: 68| Step: 0
Training loss: 2.2029924285176743
Validation loss: 2.390720577448668

Epoch: 5| Step: 1
Training loss: 2.32810072918216
Validation loss: 2.383403613036885

Epoch: 5| Step: 2
Training loss: 2.3808455556792336
Validation loss: 2.371943703260776

Epoch: 5| Step: 3
Training loss: 1.9225078874284838
Validation loss: 2.3834130452793225

Epoch: 5| Step: 4
Training loss: 2.3970002580562193
Validation loss: 2.4110710761364382

Epoch: 5| Step: 5
Training loss: 2.40001802835051
Validation loss: 2.400004418686932

Epoch: 5| Step: 6
Training loss: 2.1414330064339913
Validation loss: 2.393235240149583

Epoch: 5| Step: 7
Training loss: 1.47484549343565
Validation loss: 2.3798238574523567

Epoch: 5| Step: 8
Training loss: 2.0745640124312397
Validation loss: 2.3723991776466176

Epoch: 5| Step: 9
Training loss: 2.0302538263016885
Validation loss: 2.3721686811743012

Epoch: 5| Step: 10
Training loss: 2.014946993563686
Validation loss: 2.3893246989369135

Epoch: 5| Step: 11
Training loss: 2.014260591719393
Validation loss: 2.379632587346156

Epoch: 69| Step: 0
Training loss: 2.5260850935411483
Validation loss: 2.3976785823858804

Epoch: 5| Step: 1
Training loss: 1.7377873436969933
Validation loss: 2.4024558353896586

Epoch: 5| Step: 2
Training loss: 2.246750073945785
Validation loss: 2.4114431637533333

Epoch: 5| Step: 3
Training loss: 2.197897804022628
Validation loss: 2.385878711135218

Epoch: 5| Step: 4
Training loss: 2.513722808250737
Validation loss: 2.379702557444968

Epoch: 5| Step: 5
Training loss: 2.2803641911811776
Validation loss: 2.3980441873736993

Epoch: 5| Step: 6
Training loss: 2.092789272972928
Validation loss: 2.3910022865891007

Epoch: 5| Step: 7
Training loss: 1.8300223652457925
Validation loss: 2.3894100613341167

Epoch: 5| Step: 8
Training loss: 1.6614920235051214
Validation loss: 2.399829303280629

Epoch: 5| Step: 9
Training loss: 1.9812538652352256
Validation loss: 2.407272893473968

Epoch: 5| Step: 10
Training loss: 2.0528186958627144
Validation loss: 2.4239160202610774

Epoch: 5| Step: 11
Training loss: 2.434649047312886
Validation loss: 2.428238746502309

Epoch: 70| Step: 0
Training loss: 2.4690056197703893
Validation loss: 2.420012424387184

Epoch: 5| Step: 1
Training loss: 2.6093627563920276
Validation loss: 2.44314281907654

Epoch: 5| Step: 2
Training loss: 2.319110186381749
Validation loss: 2.4141281349452655

Epoch: 5| Step: 3
Training loss: 1.5830077371944384
Validation loss: 2.4058578159223787

Epoch: 5| Step: 4
Training loss: 1.565355209891987
Validation loss: 2.385018383464433

Epoch: 5| Step: 5
Training loss: 2.3766869025240567
Validation loss: 2.4135391960301527

Epoch: 5| Step: 6
Training loss: 1.8262101276491622
Validation loss: 2.417921822811004

Epoch: 5| Step: 7
Training loss: 1.8268962545395029
Validation loss: 2.443326812128712

Epoch: 5| Step: 8
Training loss: 2.4229428798037116
Validation loss: 2.4357381325977228

Epoch: 5| Step: 9
Training loss: 2.1801448875365725
Validation loss: 2.4277165505084044

Epoch: 5| Step: 10
Training loss: 1.8231803993907278
Validation loss: 2.403882951430352

Epoch: 5| Step: 11
Training loss: 2.149028350039543
Validation loss: 2.3838054693403126

Epoch: 71| Step: 0
Training loss: 2.016458974604901
Validation loss: 2.3994797193160737

Epoch: 5| Step: 1
Training loss: 1.7409512363070645
Validation loss: 2.405499723226161

Epoch: 5| Step: 2
Training loss: 1.930336970328109
Validation loss: 2.383030969995858

Epoch: 5| Step: 3
Training loss: 1.9140603824525915
Validation loss: 2.37715256334126

Epoch: 5| Step: 4
Training loss: 2.2602115543902888
Validation loss: 2.393887581120974

Epoch: 5| Step: 5
Training loss: 2.625625717428137
Validation loss: 2.3959128836541463

Epoch: 5| Step: 6
Training loss: 1.9925608565586759
Validation loss: 2.376231388799756

Epoch: 5| Step: 7
Training loss: 1.6915048478000958
Validation loss: 2.3906253615235697

Epoch: 5| Step: 8
Training loss: 1.9298583043911453
Validation loss: 2.393898984690006

Epoch: 5| Step: 9
Training loss: 2.2924255039503705
Validation loss: 2.440159284416319

Epoch: 5| Step: 10
Training loss: 2.417429726811066
Validation loss: 2.4561668739456817

Epoch: 5| Step: 11
Training loss: 2.9608358803575383
Validation loss: 2.459588733806968

Epoch: 72| Step: 0
Training loss: 1.5947060802707165
Validation loss: 2.430761539419937

Epoch: 5| Step: 1
Training loss: 2.0748999100410197
Validation loss: 2.4275804932760483

Epoch: 5| Step: 2
Training loss: 2.3150235402700323
Validation loss: 2.4087507662188754

Epoch: 5| Step: 3
Training loss: 1.952600210258225
Validation loss: 2.3961388655740343

Epoch: 5| Step: 4
Training loss: 1.811197404749396
Validation loss: 2.3841547369722393

Epoch: 5| Step: 5
Training loss: 2.3175486534632737
Validation loss: 2.3888731170165687

Epoch: 5| Step: 6
Training loss: 1.7338486981231662
Validation loss: 2.3653138197501526

Epoch: 5| Step: 7
Training loss: 2.4523095397410244
Validation loss: 2.387460253169963

Epoch: 5| Step: 8
Training loss: 2.296041947410277
Validation loss: 2.3846644141329025

Epoch: 5| Step: 9
Training loss: 1.9390087406105059
Validation loss: 2.3840122433581112

Epoch: 5| Step: 10
Training loss: 2.3394114711159655
Validation loss: 2.3701004889064614

Epoch: 5| Step: 11
Training loss: 2.181274383321193
Validation loss: 2.36572032570109

Epoch: 73| Step: 0
Training loss: 2.1550795101004363
Validation loss: 2.384144347230942

Epoch: 5| Step: 1
Training loss: 2.3614325236046017
Validation loss: 2.379374158972834

Epoch: 5| Step: 2
Training loss: 1.7898444586577194
Validation loss: 2.408419498026385

Epoch: 5| Step: 3
Training loss: 2.172072696607304
Validation loss: 2.382724151641094

Epoch: 5| Step: 4
Training loss: 1.7458695986796586
Validation loss: 2.401215591806355

Epoch: 5| Step: 5
Training loss: 2.5644640954996687
Validation loss: 2.399209839417069

Epoch: 5| Step: 6
Training loss: 1.807648710514911
Validation loss: 2.3957788806753384

Epoch: 5| Step: 7
Training loss: 1.996885377859929
Validation loss: 2.3934134674227088

Epoch: 5| Step: 8
Training loss: 2.2239310793729157
Validation loss: 2.4259926319421874

Epoch: 5| Step: 9
Training loss: 1.4417224733580132
Validation loss: 2.438842941460598

Epoch: 5| Step: 10
Training loss: 2.415760714529587
Validation loss: 2.475562442264256

Epoch: 5| Step: 11
Training loss: 2.284509916274419
Validation loss: 2.4721822701189367

Epoch: 74| Step: 0
Training loss: 2.3382681252633453
Validation loss: 2.4605904511059498

Epoch: 5| Step: 1
Training loss: 3.022702149855848
Validation loss: 2.4115494504210293

Epoch: 5| Step: 2
Training loss: 2.271721890627934
Validation loss: 2.3862115931962897

Epoch: 5| Step: 3
Training loss: 1.2967046602823347
Validation loss: 2.3784764386500896

Epoch: 5| Step: 4
Training loss: 1.856159796273084
Validation loss: 2.371334916261562

Epoch: 5| Step: 5
Training loss: 2.098981896608167
Validation loss: 2.383552686449474

Epoch: 5| Step: 6
Training loss: 2.4597438278795423
Validation loss: 2.396053367683248

Epoch: 5| Step: 7
Training loss: 1.8461210877617726
Validation loss: 2.3537173151781285

Epoch: 5| Step: 8
Training loss: 1.956915267583641
Validation loss: 2.35622236638683

Epoch: 5| Step: 9
Training loss: 1.4526567422464494
Validation loss: 2.3783589022078884

Epoch: 5| Step: 10
Training loss: 1.971804716426472
Validation loss: 2.392901317540123

Epoch: 5| Step: 11
Training loss: 1.08802934238192
Validation loss: 2.4039907252780215

Epoch: 75| Step: 0
Training loss: 2.0023383537514463
Validation loss: 2.389936722053424

Epoch: 5| Step: 1
Training loss: 2.2440435190995722
Validation loss: 2.404724380577192

Epoch: 5| Step: 2
Training loss: 2.3682854753026072
Validation loss: 2.377102745025928

Epoch: 5| Step: 3
Training loss: 2.4258776659394345
Validation loss: 2.3775665862395776

Epoch: 5| Step: 4
Training loss: 1.9564329287279965
Validation loss: 2.367174440186317

Epoch: 5| Step: 5
Training loss: 1.763536754345197
Validation loss: 2.373092868605156

Epoch: 5| Step: 6
Training loss: 1.594202164478912
Validation loss: 2.3972204187432324

Epoch: 5| Step: 7
Training loss: 1.509943429758803
Validation loss: 2.397736102005342

Epoch: 5| Step: 8
Training loss: 1.8867389685769664
Validation loss: 2.4114752797024983

Epoch: 5| Step: 9
Training loss: 2.2598958155155877
Validation loss: 2.4232369684892

Epoch: 5| Step: 10
Training loss: 2.1747520656240416
Validation loss: 2.429629636936179

Epoch: 5| Step: 11
Training loss: 1.7184782333527184
Validation loss: 2.481008351823812

Epoch: 76| Step: 0
Training loss: 2.5167565496027344
Validation loss: 2.492645110048407

Epoch: 5| Step: 1
Training loss: 1.8884912856196097
Validation loss: 2.5206896501897553

Epoch: 5| Step: 2
Training loss: 1.6549151097449186
Validation loss: 2.5100843610619497

Epoch: 5| Step: 3
Training loss: 2.354196891478114
Validation loss: 2.5100184133951045

Epoch: 5| Step: 4
Training loss: 1.9312722806663778
Validation loss: 2.4713588000389106

Epoch: 5| Step: 5
Training loss: 2.438653624021936
Validation loss: 2.4253592029300806

Epoch: 5| Step: 6
Training loss: 1.622079205014946
Validation loss: 2.4120036340102797

Epoch: 5| Step: 7
Training loss: 2.6026605345127427
Validation loss: 2.4058958552615692

Epoch: 5| Step: 8
Training loss: 1.8531978161868743
Validation loss: 2.4127784696762395

Epoch: 5| Step: 9
Training loss: 1.9479478503772392
Validation loss: 2.3948051623715942

Epoch: 5| Step: 10
Training loss: 1.614830621630007
Validation loss: 2.3891248338516626

Epoch: 5| Step: 11
Training loss: 0.3776631561329657
Validation loss: 2.39868163441277

Epoch: 77| Step: 0
Training loss: 1.7670488945716485
Validation loss: 2.3828376893760153

Epoch: 5| Step: 1
Training loss: 2.1925154817876242
Validation loss: 2.3910722791996575

Epoch: 5| Step: 2
Training loss: 2.1244586928318534
Validation loss: 2.3880077779087854

Epoch: 5| Step: 3
Training loss: 2.092716930087559
Validation loss: 2.358903671495367

Epoch: 5| Step: 4
Training loss: 1.7012546313332801
Validation loss: 2.410280349149709

Epoch: 5| Step: 5
Training loss: 1.766384197841499
Validation loss: 2.4026563590915244

Epoch: 5| Step: 6
Training loss: 2.3161773311210907
Validation loss: 2.4015675022037573

Epoch: 5| Step: 7
Training loss: 1.9274792719813738
Validation loss: 2.4168904827053748

Epoch: 5| Step: 8
Training loss: 2.250872654699088
Validation loss: 2.4424556724869078

Epoch: 5| Step: 9
Training loss: 1.7274562541981944
Validation loss: 2.414642947308305

Epoch: 5| Step: 10
Training loss: 2.0860017345125006
Validation loss: 2.438502619019401

Epoch: 5| Step: 11
Training loss: 2.1458098277560693
Validation loss: 2.402429106728552

Epoch: 78| Step: 0
Training loss: 1.8548926814414135
Validation loss: 2.3932197571999447

Epoch: 5| Step: 1
Training loss: 1.7769201423634762
Validation loss: 2.4091627236088464

Epoch: 5| Step: 2
Training loss: 1.5151317619712263
Validation loss: 2.4189133614401332

Epoch: 5| Step: 3
Training loss: 1.694508586079492
Validation loss: 2.404674881473819

Epoch: 5| Step: 4
Training loss: 2.26662091695205
Validation loss: 2.4324225928923893

Epoch: 5| Step: 5
Training loss: 1.8172176394665094
Validation loss: 2.4085257840782943

Epoch: 5| Step: 6
Training loss: 2.441050169345205
Validation loss: 2.437696514196074

Epoch: 5| Step: 7
Training loss: 1.6886184659229007
Validation loss: 2.3983581438718655

Epoch: 5| Step: 8
Training loss: 2.272295163431331
Validation loss: 2.419501443855258

Epoch: 5| Step: 9
Training loss: 1.8421614964585553
Validation loss: 2.421672820809568

Epoch: 5| Step: 10
Training loss: 2.188140557371925
Validation loss: 2.373887004146155

Epoch: 5| Step: 11
Training loss: 3.484164244431903
Validation loss: 2.3948448436309215

Epoch: 79| Step: 0
Training loss: 1.832090917725864
Validation loss: 2.3718781532799387

Epoch: 5| Step: 1
Training loss: 1.2324399629405107
Validation loss: 2.383897265549663

Epoch: 5| Step: 2
Training loss: 2.031401291128103
Validation loss: 2.381106761485706

Epoch: 5| Step: 3
Training loss: 1.8682415911733987
Validation loss: 2.396592937519434

Epoch: 5| Step: 4
Training loss: 2.0455814380010953
Validation loss: 2.3994328341942026

Epoch: 5| Step: 5
Training loss: 2.056656970532446
Validation loss: 2.3723384097896645

Epoch: 5| Step: 6
Training loss: 1.447463460932138
Validation loss: 2.3857176679636045

Epoch: 5| Step: 7
Training loss: 1.862342133968205
Validation loss: 2.415426891308115

Epoch: 5| Step: 8
Training loss: 2.285871240642479
Validation loss: 2.434231512797478

Epoch: 5| Step: 9
Training loss: 2.4072708342467997
Validation loss: 2.475252119702931

Epoch: 5| Step: 10
Training loss: 2.350395039571224
Validation loss: 2.485988137212783

Epoch: 5| Step: 11
Training loss: 2.5519698033414793
Validation loss: 2.487123264844935

Epoch: 80| Step: 0
Training loss: 2.025596968643126
Validation loss: 2.463039053897062

Epoch: 5| Step: 1
Training loss: 2.4413926757435136
Validation loss: 2.443470387995099

Epoch: 5| Step: 2
Training loss: 2.273460991072793
Validation loss: 2.4157652338405535

Epoch: 5| Step: 3
Training loss: 1.766427321985312
Validation loss: 2.3975638249029334

Epoch: 5| Step: 4
Training loss: 2.276145554418676
Validation loss: 2.375436443666295

Epoch: 5| Step: 5
Training loss: 1.497720973885271
Validation loss: 2.374258666034045

Epoch: 5| Step: 6
Training loss: 2.042328772587346
Validation loss: 2.375678818717069

Epoch: 5| Step: 7
Training loss: 1.6669497090644483
Validation loss: 2.4015077826695297

Epoch: 5| Step: 8
Training loss: 1.5015659105974697
Validation loss: 2.4326288342181135

Epoch: 5| Step: 9
Training loss: 2.1713518569237373
Validation loss: 2.4219481549443187

Epoch: 5| Step: 10
Training loss: 1.8120036267629542
Validation loss: 2.426209367454092

Epoch: 5| Step: 11
Training loss: 1.731427824617339
Validation loss: 2.4233808553057634

Epoch: 81| Step: 0
Training loss: 1.603587809899866
Validation loss: 2.373867329494539

Epoch: 5| Step: 1
Training loss: 2.463893507712172
Validation loss: 2.3702953949061523

Epoch: 5| Step: 2
Training loss: 1.8028048649290813
Validation loss: 2.397633373225525

Epoch: 5| Step: 3
Training loss: 1.7543301824016762
Validation loss: 2.3963700909504504

Epoch: 5| Step: 4
Training loss: 2.096395500833931
Validation loss: 2.402760564109084

Epoch: 5| Step: 5
Training loss: 2.269053318565674
Validation loss: 2.365274388557326

Epoch: 5| Step: 6
Training loss: 1.9577779658773686
Validation loss: 2.3793259299017806

Epoch: 5| Step: 7
Training loss: 1.8689510045984945
Validation loss: 2.395431656267749

Epoch: 5| Step: 8
Training loss: 1.9855035891590518
Validation loss: 2.4183434815876317

Epoch: 5| Step: 9
Training loss: 2.1071822460640277
Validation loss: 2.4152521126087727

Epoch: 5| Step: 10
Training loss: 1.879466903058195
Validation loss: 2.4521180534227454

Epoch: 5| Step: 11
Training loss: 0.9900365628127967
Validation loss: 2.444134848097411

Epoch: 82| Step: 0
Training loss: 2.0814116452424023
Validation loss: 2.450435749783539

Epoch: 5| Step: 1
Training loss: 1.5808346591126803
Validation loss: 2.439132339484482

Epoch: 5| Step: 2
Training loss: 1.823236499158407
Validation loss: 2.4202831451231677

Epoch: 5| Step: 3
Training loss: 2.1913625131414167
Validation loss: 2.4347125931330758

Epoch: 5| Step: 4
Training loss: 1.3671810912935733
Validation loss: 2.398624205803581

Epoch: 5| Step: 5
Training loss: 2.1188831928889855
Validation loss: 2.392622273355703

Epoch: 5| Step: 6
Training loss: 1.714432373755675
Validation loss: 2.387601190855884

Epoch: 5| Step: 7
Training loss: 1.9218726429498376
Validation loss: 2.380076980027074

Epoch: 5| Step: 8
Training loss: 1.8683887272817508
Validation loss: 2.4067894879919525

Epoch: 5| Step: 9
Training loss: 2.1022775560928113
Validation loss: 2.373937557397921

Epoch: 5| Step: 10
Training loss: 2.2099285721779376
Validation loss: 2.389718970684383

Epoch: 5| Step: 11
Training loss: 2.1203909986634857
Validation loss: 2.42239815998861

Epoch: 83| Step: 0
Training loss: 2.4832290789676192
Validation loss: 2.4403778148001094

Epoch: 5| Step: 1
Training loss: 2.0471865584316427
Validation loss: 2.43197262296383

Epoch: 5| Step: 2
Training loss: 1.186379305401563
Validation loss: 2.475548218609681

Epoch: 5| Step: 3
Training loss: 2.095088701578162
Validation loss: 2.4464581479985297

Epoch: 5| Step: 4
Training loss: 1.6771659909683914
Validation loss: 2.4333839836357796

Epoch: 5| Step: 5
Training loss: 2.1582783543520287
Validation loss: 2.393066771555947

Epoch: 5| Step: 6
Training loss: 2.085118851052946
Validation loss: 2.411990963066731

Epoch: 5| Step: 7
Training loss: 1.8007513941608897
Validation loss: 2.3945391324501086

Epoch: 5| Step: 8
Training loss: 1.679040189701671
Validation loss: 2.392905975508106

Epoch: 5| Step: 9
Training loss: 1.6073217534603108
Validation loss: 2.394918278774568

Epoch: 5| Step: 10
Training loss: 1.996220175962817
Validation loss: 2.3851162764357388

Epoch: 5| Step: 11
Training loss: 1.4265439854367843
Validation loss: 2.4037996775340185

Epoch: 84| Step: 0
Training loss: 2.0174795682456304
Validation loss: 2.3935007903516983

Epoch: 5| Step: 1
Training loss: 1.6886164892407025
Validation loss: 2.4044882158239336

Epoch: 5| Step: 2
Training loss: 1.8510773743502185
Validation loss: 2.3724294730578044

Epoch: 5| Step: 3
Training loss: 1.915204948932146
Validation loss: 2.386574532188517

Epoch: 5| Step: 4
Training loss: 2.2389447625158527
Validation loss: 2.4130404138844446

Epoch: 5| Step: 5
Training loss: 1.6484918811379492
Validation loss: 2.421029070301757

Epoch: 5| Step: 6
Training loss: 2.004373893678013
Validation loss: 2.4214364628965304

Epoch: 5| Step: 7
Training loss: 1.9168673769585047
Validation loss: 2.4051419675340964

Epoch: 5| Step: 8
Training loss: 1.618302334188355
Validation loss: 2.4114415324032996

Epoch: 5| Step: 9
Training loss: 1.4436617935780736
Validation loss: 2.402510052639098

Epoch: 5| Step: 10
Training loss: 2.2363855879284964
Validation loss: 2.3984913897595384

Epoch: 5| Step: 11
Training loss: 2.161395691726103
Validation loss: 2.3994604366811574

Epoch: 85| Step: 0
Training loss: 2.1841870970669834
Validation loss: 2.4311990033042026

Epoch: 5| Step: 1
Training loss: 1.3397398260534288
Validation loss: 2.425147726861886

Epoch: 5| Step: 2
Training loss: 1.9701232964519393
Validation loss: 2.4276808274763244

Epoch: 5| Step: 3
Training loss: 1.8805561395616375
Validation loss: 2.4065419346138266

Epoch: 5| Step: 4
Training loss: 1.36455059254901
Validation loss: 2.372110533212984

Epoch: 5| Step: 5
Training loss: 1.4967122604686605
Validation loss: 2.4043078697318863

Epoch: 5| Step: 6
Training loss: 1.7626954477579588
Validation loss: 2.3794836461698963

Epoch: 5| Step: 7
Training loss: 1.894773676197725
Validation loss: 2.388455524352446

Epoch: 5| Step: 8
Training loss: 2.132168179955213
Validation loss: 2.388690460789869

Epoch: 5| Step: 9
Training loss: 1.5567247088037899
Validation loss: 2.422137810178506

Epoch: 5| Step: 10
Training loss: 2.3339245138113256
Validation loss: 2.4041786154434104

Epoch: 5| Step: 11
Training loss: 2.036788198254983
Validation loss: 2.3694128690923577

Epoch: 86| Step: 0
Training loss: 1.9314669539675793
Validation loss: 2.4011710925742484

Epoch: 5| Step: 1
Training loss: 1.8946531905424964
Validation loss: 2.3776495818821144

Epoch: 5| Step: 2
Training loss: 2.066787771040181
Validation loss: 2.3972783388833863

Epoch: 5| Step: 3
Training loss: 1.78317745394994
Validation loss: 2.3880481420277677

Epoch: 5| Step: 4
Training loss: 1.7301222064564346
Validation loss: 2.394411255161962

Epoch: 5| Step: 5
Training loss: 2.1441672316707496
Validation loss: 2.408408138461951

Epoch: 5| Step: 6
Training loss: 1.7822405420042489
Validation loss: 2.3786596912715114

Epoch: 5| Step: 7
Training loss: 1.7648698660449404
Validation loss: 2.3840885622752848

Epoch: 5| Step: 8
Training loss: 1.4932601827915797
Validation loss: 2.3893288732691773

Epoch: 5| Step: 9
Training loss: 1.7014912459882245
Validation loss: 2.416302093734337

Epoch: 5| Step: 10
Training loss: 1.8676015482592379
Validation loss: 2.4412019079523444

Epoch: 5| Step: 11
Training loss: 1.7612498943039137
Validation loss: 2.464421638662108

Epoch: 87| Step: 0
Training loss: 1.633816278188779
Validation loss: 2.447186350267868

Epoch: 5| Step: 1
Training loss: 2.162701891697299
Validation loss: 2.486631907773256

Epoch: 5| Step: 2
Training loss: 1.754557940896409
Validation loss: 2.466085567496642

Epoch: 5| Step: 3
Training loss: 1.4131455794417214
Validation loss: 2.4052115837814245

Epoch: 5| Step: 4
Training loss: 2.122049077889328
Validation loss: 2.4521929353145175

Epoch: 5| Step: 5
Training loss: 1.5428646776858017
Validation loss: 2.4364284540186936

Epoch: 5| Step: 6
Training loss: 2.095921998268816
Validation loss: 2.416064135209127

Epoch: 5| Step: 7
Training loss: 1.8003832859345765
Validation loss: 2.4003013343850976

Epoch: 5| Step: 8
Training loss: 2.253658287649269
Validation loss: 2.4100551408841144

Epoch: 5| Step: 9
Training loss: 1.4390779210692295
Validation loss: 2.3947135561338952

Epoch: 5| Step: 10
Training loss: 1.5326358207269004
Validation loss: 2.3757649494829987

Epoch: 5| Step: 11
Training loss: 2.1254056655528286
Validation loss: 2.3935947298134703

Epoch: 88| Step: 0
Training loss: 1.8859564779443982
Validation loss: 2.4002612797916054

Epoch: 5| Step: 1
Training loss: 1.6644198611520435
Validation loss: 2.403963645900317

Epoch: 5| Step: 2
Training loss: 2.009619823390536
Validation loss: 2.4012784110226524

Epoch: 5| Step: 3
Training loss: 1.8080498884880014
Validation loss: 2.424098112247904

Epoch: 5| Step: 4
Training loss: 1.525852343518796
Validation loss: 2.4265763663317212

Epoch: 5| Step: 5
Training loss: 0.9877436083888804
Validation loss: 2.4555399178930726

Epoch: 5| Step: 6
Training loss: 2.0512449485070365
Validation loss: 2.488183299581562

Epoch: 5| Step: 7
Training loss: 1.7176901584062372
Validation loss: 2.4382487557171157

Epoch: 5| Step: 8
Training loss: 1.7468875045192334
Validation loss: 2.4269183468441233

Epoch: 5| Step: 9
Training loss: 2.0858584042529764
Validation loss: 2.4123459240527847

Epoch: 5| Step: 10
Training loss: 2.1653235992266087
Validation loss: 2.4003932798705643

Epoch: 5| Step: 11
Training loss: 1.7121155745898622
Validation loss: 2.415827425938209

Epoch: 89| Step: 0
Training loss: 1.9034940465138117
Validation loss: 2.3957625102203792

Epoch: 5| Step: 1
Training loss: 1.7313510548538193
Validation loss: 2.3634600821265317

Epoch: 5| Step: 2
Training loss: 2.3018427474253125
Validation loss: 2.3624508242055646

Epoch: 5| Step: 3
Training loss: 1.3918353610481733
Validation loss: 2.3856546138930494

Epoch: 5| Step: 4
Training loss: 1.986476296268802
Validation loss: 2.3847931598112018

Epoch: 5| Step: 5
Training loss: 1.9689484148102296
Validation loss: 2.3904634682928423

Epoch: 5| Step: 6
Training loss: 1.3825911005228977
Validation loss: 2.376219549269922

Epoch: 5| Step: 7
Training loss: 1.6521519759334522
Validation loss: 2.380491401957701

Epoch: 5| Step: 8
Training loss: 1.71660369029159
Validation loss: 2.4370016297682056

Epoch: 5| Step: 9
Training loss: 1.9696170169324525
Validation loss: 2.4683415481431545

Epoch: 5| Step: 10
Training loss: 1.2425286166543432
Validation loss: 2.443212734978455

Epoch: 5| Step: 11
Training loss: 1.187914424659079
Validation loss: 2.4285490020115836

Epoch: 90| Step: 0
Training loss: 1.6430202619356165
Validation loss: 2.424067769997478

Epoch: 5| Step: 1
Training loss: 1.5314221188093091
Validation loss: 2.4798056449539967

Epoch: 5| Step: 2
Training loss: 2.107744844452285
Validation loss: 2.4480872737330235

Epoch: 5| Step: 3
Training loss: 1.264118993979699
Validation loss: 2.3946322574853642

Epoch: 5| Step: 4
Training loss: 1.5374811248861247
Validation loss: 2.406034402147361

Epoch: 5| Step: 5
Training loss: 1.6708370801672778
Validation loss: 2.382685694421172

Epoch: 5| Step: 6
Training loss: 1.9627492369787696
Validation loss: 2.383413337040535

Epoch: 5| Step: 7
Training loss: 1.7274678475994123
Validation loss: 2.3560395021119733

Epoch: 5| Step: 8
Training loss: 2.086814895865691
Validation loss: 2.3908963392267397

Epoch: 5| Step: 9
Training loss: 2.017498240038779
Validation loss: 2.39514635990057

Epoch: 5| Step: 10
Training loss: 1.7464658609499772
Validation loss: 2.411586431941733

Epoch: 5| Step: 11
Training loss: 1.948368353331806
Validation loss: 2.4173966297376226

Epoch: 91| Step: 0
Training loss: 1.5226264555332012
Validation loss: 2.4098600208618897

Epoch: 5| Step: 1
Training loss: 1.7512535646281153
Validation loss: 2.442613572734258

Epoch: 5| Step: 2
Training loss: 1.9882294473850897
Validation loss: 2.416518434275446

Epoch: 5| Step: 3
Training loss: 1.908020198179295
Validation loss: 2.411342911948129

Epoch: 5| Step: 4
Training loss: 1.402811424032314
Validation loss: 2.4051736595944386

Epoch: 5| Step: 5
Training loss: 1.592653308597357
Validation loss: 2.338688564713548

Epoch: 5| Step: 6
Training loss: 1.5814752048957172
Validation loss: 2.3760309073341013

Epoch: 5| Step: 7
Training loss: 1.9562320257464114
Validation loss: 2.3567886323766043

Epoch: 5| Step: 8
Training loss: 1.447364299257241
Validation loss: 2.383969018986605

Epoch: 5| Step: 9
Training loss: 2.043887571785056
Validation loss: 2.3899256819911

Epoch: 5| Step: 10
Training loss: 1.551552376613264
Validation loss: 2.4056889057334865

Epoch: 5| Step: 11
Training loss: 2.2558132943074907
Validation loss: 2.413898705251693

Epoch: 92| Step: 0
Training loss: 1.8485872854520056
Validation loss: 2.423139828425111

Epoch: 5| Step: 1
Training loss: 1.679763082533663
Validation loss: 2.3932153053145164

Epoch: 5| Step: 2
Training loss: 1.4941051204676632
Validation loss: 2.388474271954482

Epoch: 5| Step: 3
Training loss: 1.4010252638451068
Validation loss: 2.3738729454597953

Epoch: 5| Step: 4
Training loss: 1.9652641559513664
Validation loss: 2.4047514431263646

Epoch: 5| Step: 5
Training loss: 1.4042947527746046
Validation loss: 2.394959275125728

Epoch: 5| Step: 6
Training loss: 1.7641826578579853
Validation loss: 2.3610578728888245

Epoch: 5| Step: 7
Training loss: 1.9367751334516774
Validation loss: 2.4503206109771094

Epoch: 5| Step: 8
Training loss: 1.9590392024239616
Validation loss: 2.449522138561075

Epoch: 5| Step: 9
Training loss: 1.7218628870820116
Validation loss: 2.4417614609757994

Epoch: 5| Step: 10
Training loss: 1.8053740149304274
Validation loss: 2.4474936721792693

Epoch: 5| Step: 11
Training loss: 0.8392104844172971
Validation loss: 2.3852949146089135

Epoch: 93| Step: 0
Training loss: 1.3755586962945634
Validation loss: 2.395911299777566

Epoch: 5| Step: 1
Training loss: 1.4422509837617525
Validation loss: 2.3948068797217488

Epoch: 5| Step: 2
Training loss: 1.4628973070712712
Validation loss: 2.392950725996084

Epoch: 5| Step: 3
Training loss: 1.6167662435847874
Validation loss: 2.4164951725378843

Epoch: 5| Step: 4
Training loss: 1.5743073469272484
Validation loss: 2.409791033590194

Epoch: 5| Step: 5
Training loss: 2.352183922057549
Validation loss: 2.406939112670265

Epoch: 5| Step: 6
Training loss: 1.8404627445121995
Validation loss: 2.3622106223520856

Epoch: 5| Step: 7
Training loss: 1.3319169607941217
Validation loss: 2.404955643808577

Epoch: 5| Step: 8
Training loss: 1.5490748628635143
Validation loss: 2.416409377400179

Epoch: 5| Step: 9
Training loss: 1.5031173420352124
Validation loss: 2.3966789508601147

Epoch: 5| Step: 10
Training loss: 2.152736510288022
Validation loss: 2.4449348523718437

Epoch: 5| Step: 11
Training loss: 0.8115868572330034
Validation loss: 2.418669747426694

Epoch: 94| Step: 0
Training loss: 1.6617292783158848
Validation loss: 2.449430826629277

Epoch: 5| Step: 1
Training loss: 1.5363846152342013
Validation loss: 2.4246271063019686

Epoch: 5| Step: 2
Training loss: 1.5413790082191854
Validation loss: 2.4828836755331323

Epoch: 5| Step: 3
Training loss: 1.6643592677302181
Validation loss: 2.4902098570969295

Epoch: 5| Step: 4
Training loss: 1.7138422863664677
Validation loss: 2.446191777917337

Epoch: 5| Step: 5
Training loss: 1.735827276128028
Validation loss: 2.410039357916588

Epoch: 5| Step: 6
Training loss: 1.7612342591188075
Validation loss: 2.402752489503248

Epoch: 5| Step: 7
Training loss: 1.6084348284200949
Validation loss: 2.4136275524081325

Epoch: 5| Step: 8
Training loss: 1.7510700360446532
Validation loss: 2.380101893665413

Epoch: 5| Step: 9
Training loss: 1.6709938222746965
Validation loss: 2.4094686635106366

Epoch: 5| Step: 10
Training loss: 2.1147410767697647
Validation loss: 2.4137393484106116

Epoch: 5| Step: 11
Training loss: 1.3618007370412184
Validation loss: 2.4085260666105905

Epoch: 95| Step: 0
Training loss: 1.385121761092747
Validation loss: 2.4532460792287556

Epoch: 5| Step: 1
Training loss: 1.8669697143721786
Validation loss: 2.441208789215213

Epoch: 5| Step: 2
Training loss: 1.325033156861798
Validation loss: 2.4860257496525784

Epoch: 5| Step: 3
Training loss: 1.686209997970917
Validation loss: 2.4833160998772663

Epoch: 5| Step: 4
Training loss: 1.6428889321870812
Validation loss: 2.5261960614923673

Epoch: 5| Step: 5
Training loss: 1.3053805400785985
Validation loss: 2.4973331214156556

Epoch: 5| Step: 6
Training loss: 1.676473550134489
Validation loss: 2.475395679875047

Epoch: 5| Step: 7
Training loss: 1.2336656487876516
Validation loss: 2.4044456446236366

Epoch: 5| Step: 8
Training loss: 1.8971448351317088
Validation loss: 2.35637222979804

Epoch: 5| Step: 9
Training loss: 2.0522262859091978
Validation loss: 2.358914606172588

Epoch: 5| Step: 10
Training loss: 2.042233278189033
Validation loss: 2.3564301485157877

Epoch: 5| Step: 11
Training loss: 1.922590913247576
Validation loss: 2.385248966791094

Epoch: 96| Step: 0
Training loss: 1.432449008506776
Validation loss: 2.3770975086303254

Epoch: 5| Step: 1
Training loss: 2.0681930345427393
Validation loss: 2.374248762276825

Epoch: 5| Step: 2
Training loss: 1.6376450860198288
Validation loss: 2.385095975938733

Epoch: 5| Step: 3
Training loss: 1.2077338386769865
Validation loss: 2.444812292871529

Epoch: 5| Step: 4
Training loss: 1.9156122278780288
Validation loss: 2.5019367087443793

Epoch: 5| Step: 5
Training loss: 1.4923076481406972
Validation loss: 2.5378918497110896

Epoch: 5| Step: 6
Training loss: 1.34807768051158
Validation loss: 2.5916867878389356

Epoch: 5| Step: 7
Training loss: 2.149292598829792
Validation loss: 2.5041874347297393

Epoch: 5| Step: 8
Training loss: 1.1812716325666237
Validation loss: 2.467340111033965

Epoch: 5| Step: 9
Training loss: 2.0202571663650923
Validation loss: 2.490592864916941

Epoch: 5| Step: 10
Training loss: 1.519738033708795
Validation loss: 2.4216752000655304

Epoch: 5| Step: 11
Training loss: 0.7995937940368151
Validation loss: 2.3618269404797516

Epoch: 97| Step: 0
Training loss: 1.7706683886133767
Validation loss: 2.3731403410915264

Epoch: 5| Step: 1
Training loss: 1.6531939111779757
Validation loss: 2.40059369446274

Epoch: 5| Step: 2
Training loss: 1.342259844960745
Validation loss: 2.3780512784541585

Epoch: 5| Step: 3
Training loss: 1.214758081880712
Validation loss: 2.3900632135857967

Epoch: 5| Step: 4
Training loss: 1.6470911394483214
Validation loss: 2.3718096737918555

Epoch: 5| Step: 5
Training loss: 1.1973456749595073
Validation loss: 2.3917290396703805

Epoch: 5| Step: 6
Training loss: 1.7083844510625956
Validation loss: 2.3757848781201316

Epoch: 5| Step: 7
Training loss: 2.374700828582109
Validation loss: 2.4082843573968127

Epoch: 5| Step: 8
Training loss: 1.609766643980204
Validation loss: 2.477021556872099

Epoch: 5| Step: 9
Training loss: 1.5573590199206158
Validation loss: 2.521773700184348

Epoch: 5| Step: 10
Training loss: 1.3332386082538625
Validation loss: 2.559993419294169

Epoch: 5| Step: 11
Training loss: 1.9695808837156623
Validation loss: 2.464918847811601

Epoch: 98| Step: 0
Training loss: 1.7456629688956316
Validation loss: 2.3837960011444936

Epoch: 5| Step: 1
Training loss: 1.3834138414020012
Validation loss: 2.376499996914186

Epoch: 5| Step: 2
Training loss: 1.6421657049037592
Validation loss: 2.3891664264928534

Epoch: 5| Step: 3
Training loss: 1.9171289287347055
Validation loss: 2.4051656839569047

Epoch: 5| Step: 4
Training loss: 1.777063972334882
Validation loss: 2.3862952165098044

Epoch: 5| Step: 5
Training loss: 1.343243037558097
Validation loss: 2.353823271043311

Epoch: 5| Step: 6
Training loss: 1.6579204268922976
Validation loss: 2.391812293562492

Epoch: 5| Step: 7
Training loss: 1.414500553291458
Validation loss: 2.3889609656038457

Epoch: 5| Step: 8
Training loss: 1.8857670312684098
Validation loss: 2.4072190888800167

Epoch: 5| Step: 9
Training loss: 1.466329080932052
Validation loss: 2.4628017711014447

Epoch: 5| Step: 10
Training loss: 1.4433832437609047
Validation loss: 2.491746287418678

Epoch: 5| Step: 11
Training loss: 2.0983968382849016
Validation loss: 2.496585031476883

Epoch: 99| Step: 0
Training loss: 1.15603707904814
Validation loss: 2.435076503204622

Epoch: 5| Step: 1
Training loss: 1.4881674254937376
Validation loss: 2.375005274482358

Epoch: 5| Step: 2
Training loss: 2.226335694657294
Validation loss: 2.3769391554978596

Epoch: 5| Step: 3
Training loss: 1.3157542167507577
Validation loss: 2.3919794945260553

Epoch: 5| Step: 4
Training loss: 1.5480750467113162
Validation loss: 2.4012199647339934

Epoch: 5| Step: 5
Training loss: 1.2456282460677155
Validation loss: 2.3898033837023505

Epoch: 5| Step: 6
Training loss: 1.6268354467214035
Validation loss: 2.4091479017544453

Epoch: 5| Step: 7
Training loss: 1.5480464006414079
Validation loss: 2.412284274330566

Epoch: 5| Step: 8
Training loss: 1.4897395321061657
Validation loss: 2.4165301010306104

Epoch: 5| Step: 9
Training loss: 1.5090936939635804
Validation loss: 2.408006373873858

Epoch: 5| Step: 10
Training loss: 1.6630746120889333
Validation loss: 2.3971694613720267

Epoch: 5| Step: 11
Training loss: 1.5925022551611918
Validation loss: 2.3808885697203936

Epoch: 100| Step: 0
Training loss: 1.8107439939975214
Validation loss: 2.4166579033977746

Epoch: 5| Step: 1
Training loss: 1.6512761556212858
Validation loss: 2.469594529316779

Epoch: 5| Step: 2
Training loss: 1.9337675382562274
Validation loss: 2.458186045507065

Epoch: 5| Step: 3
Training loss: 1.29144316964935
Validation loss: 2.4840019793745705

Epoch: 5| Step: 4
Training loss: 1.8413803907997461
Validation loss: 2.465566211865032

Epoch: 5| Step: 5
Training loss: 1.601175028752955
Validation loss: 2.4235006188494883

Epoch: 5| Step: 6
Training loss: 1.5003444752923927
Validation loss: 2.4139555009258107

Epoch: 5| Step: 7
Training loss: 1.3037547357752985
Validation loss: 2.406328513776007

Epoch: 5| Step: 8
Training loss: 1.2705540688939736
Validation loss: 2.3678053436735027

Epoch: 5| Step: 9
Training loss: 1.2170844312325741
Validation loss: 2.423098509408141

Epoch: 5| Step: 10
Training loss: 1.460030993563749
Validation loss: 2.37497678962877

Epoch: 5| Step: 11
Training loss: 1.5357556907800491
Validation loss: 2.396563250159014

Epoch: 101| Step: 0
Training loss: 1.7253008759750807
Validation loss: 2.338161715175309

Epoch: 5| Step: 1
Training loss: 1.0186988677316156
Validation loss: 2.4422380622353077

Epoch: 5| Step: 2
Training loss: 1.2244202195482956
Validation loss: 2.4415234184123746

Epoch: 5| Step: 3
Training loss: 1.5112226593851132
Validation loss: 2.4678090652371716

Epoch: 5| Step: 4
Training loss: 1.4877039473028755
Validation loss: 2.536019249391881

Epoch: 5| Step: 5
Training loss: 1.2823683347282466
Validation loss: 2.4668525091498594

Epoch: 5| Step: 6
Training loss: 1.9165315234873206
Validation loss: 2.4937653325182363

Epoch: 5| Step: 7
Training loss: 1.4338860070956145
Validation loss: 2.4493819511427204

Epoch: 5| Step: 8
Training loss: 1.5249670713027672
Validation loss: 2.413818476667196

Epoch: 5| Step: 9
Training loss: 1.876734439999282
Validation loss: 2.3736962537956727

Epoch: 5| Step: 10
Training loss: 1.9626945131937807
Validation loss: 2.403155438346549

Epoch: 5| Step: 11
Training loss: 1.5653050992413389
Validation loss: 2.3427282437408086

Epoch: 102| Step: 0
Training loss: 1.3387371865450932
Validation loss: 2.3894560372309543

Epoch: 5| Step: 1
Training loss: 1.1445686412340939
Validation loss: 2.41478741408453

Epoch: 5| Step: 2
Training loss: 1.4029819237162453
Validation loss: 2.4381289159825963

Epoch: 5| Step: 3
Training loss: 2.0526466822744234
Validation loss: 2.498367682668939

Epoch: 5| Step: 4
Training loss: 1.2687239677126283
Validation loss: 2.509021234021342

Epoch: 5| Step: 5
Training loss: 1.599087472809734
Validation loss: 2.531567286789927

Epoch: 5| Step: 6
Training loss: 2.086833290032868
Validation loss: 2.49355324580078

Epoch: 5| Step: 7
Training loss: 1.4383570562522896
Validation loss: 2.3739753654463764

Epoch: 5| Step: 8
Training loss: 1.4484172568609275
Validation loss: 2.3731757779164724

Epoch: 5| Step: 9
Training loss: 1.3822850660076906
Validation loss: 2.36611066063387

Epoch: 5| Step: 10
Training loss: 1.6859401982155917
Validation loss: 2.364928969498753

Epoch: 5| Step: 11
Training loss: 1.4891334957078026
Validation loss: 2.3734129467670013

Epoch: 103| Step: 0
Training loss: 1.2242625352226708
Validation loss: 2.3531513169578715

Epoch: 5| Step: 1
Training loss: 1.635965615571064
Validation loss: 2.3834171716131505

Epoch: 5| Step: 2
Training loss: 1.249193455843804
Validation loss: 2.4029797298869204

Epoch: 5| Step: 3
Training loss: 1.7004929949675882
Validation loss: 2.428632136979908

Epoch: 5| Step: 4
Training loss: 1.7611961520040125
Validation loss: 2.404239462759145

Epoch: 5| Step: 5
Training loss: 1.633794388930536
Validation loss: 2.4562291714704867

Epoch: 5| Step: 6
Training loss: 1.4679159677709381
Validation loss: 2.416452995807673

Epoch: 5| Step: 7
Training loss: 1.0734393257225536
Validation loss: 2.3810356602693274

Epoch: 5| Step: 8
Training loss: 1.206382601866498
Validation loss: 2.4309854546573004

Epoch: 5| Step: 9
Training loss: 1.4754996536445792
Validation loss: 2.422620746689055

Epoch: 5| Step: 10
Training loss: 1.6673006600299418
Validation loss: 2.38102095537832

Epoch: 5| Step: 11
Training loss: 0.8902599858294652
Validation loss: 2.392111330752798

Epoch: 104| Step: 0
Training loss: 1.242819715157126
Validation loss: 2.4381220667721255

Epoch: 5| Step: 1
Training loss: 1.3184699570231517
Validation loss: 2.4034149717568747

Epoch: 5| Step: 2
Training loss: 1.3827090467127667
Validation loss: 2.4075989059315726

Epoch: 5| Step: 3
Training loss: 1.3787534807425836
Validation loss: 2.4223283404933165

Epoch: 5| Step: 4
Training loss: 1.261559396607194
Validation loss: 2.4229564385226285

Epoch: 5| Step: 5
Training loss: 1.8798073493376335
Validation loss: 2.447221628226421

Epoch: 5| Step: 6
Training loss: 1.5118851286732953
Validation loss: 2.3474138910211106

Epoch: 5| Step: 7
Training loss: 1.2318284530013082
Validation loss: 2.3831877553657113

Epoch: 5| Step: 8
Training loss: 2.094384168549598
Validation loss: 2.3928257612930626

Epoch: 5| Step: 9
Training loss: 1.5189108869318784
Validation loss: 2.3666620961892852

Epoch: 5| Step: 10
Training loss: 1.1926390226567498
Validation loss: 2.3992044959995216

Epoch: 5| Step: 11
Training loss: 2.192820699414682
Validation loss: 2.3477690209984527

Epoch: 105| Step: 0
Training loss: 1.33292996245599
Validation loss: 2.389273799769055

Epoch: 5| Step: 1
Training loss: 1.2493405509958728
Validation loss: 2.4456514503451827

Epoch: 5| Step: 2
Training loss: 1.2240435739689708
Validation loss: 2.529601256762022

Epoch: 5| Step: 3
Training loss: 1.6934566623851668
Validation loss: 2.6106175378618666

Epoch: 5| Step: 4
Training loss: 1.7812687387651949
Validation loss: 2.6240581987636555

Epoch: 5| Step: 5
Training loss: 1.5436369016662537
Validation loss: 2.569888635565277

Epoch: 5| Step: 6
Training loss: 1.777515847394345
Validation loss: 2.4720784195648005

Epoch: 5| Step: 7
Training loss: 1.1699295171064572
Validation loss: 2.3879613061194953

Epoch: 5| Step: 8
Training loss: 1.3866763686030226
Validation loss: 2.3601418989835996

Epoch: 5| Step: 9
Training loss: 1.4253776919781012
Validation loss: 2.409174772354718

Epoch: 5| Step: 10
Training loss: 1.5413335319956702
Validation loss: 2.4312369832505176

Epoch: 5| Step: 11
Training loss: 0.9923217862785442
Validation loss: 2.3813970728967844

Epoch: 106| Step: 0
Training loss: 1.3923015560605856
Validation loss: 2.4013924718236463

Epoch: 5| Step: 1
Training loss: 1.6003849818079205
Validation loss: 2.3774030390748924

Epoch: 5| Step: 2
Training loss: 0.9302851575088743
Validation loss: 2.3409630799948786

Epoch: 5| Step: 3
Training loss: 1.1046948099501501
Validation loss: 2.3727550018362864

Epoch: 5| Step: 4
Training loss: 1.3571730131728348
Validation loss: 2.3662284885059437

Epoch: 5| Step: 5
Training loss: 1.0161952838502222
Validation loss: 2.4435689639574756

Epoch: 5| Step: 6
Training loss: 0.9577376580674117
Validation loss: 2.4789426900095055

Epoch: 5| Step: 7
Training loss: 1.5709660626636381
Validation loss: 2.478772201464309

Epoch: 5| Step: 8
Training loss: 1.5900130498098668
Validation loss: 2.5661385143483546

Epoch: 5| Step: 9
Training loss: 1.9273315132411375
Validation loss: 2.5528600866588222

Epoch: 5| Step: 10
Training loss: 1.3537892426978466
Validation loss: 2.515223405899701

Epoch: 5| Step: 11
Training loss: 2.194372552855672
Validation loss: 2.4229850112140756

Epoch: 107| Step: 0
Training loss: 1.602603332234999
Validation loss: 2.3948706157713286

Epoch: 5| Step: 1
Training loss: 1.3690799367735096
Validation loss: 2.397255130798931

Epoch: 5| Step: 2
Training loss: 1.6767594476868484
Validation loss: 2.4385311684320694

Epoch: 5| Step: 3
Training loss: 1.3789785220304163
Validation loss: 2.4894114611898397

Epoch: 5| Step: 4
Training loss: 1.609549355552729
Validation loss: 2.4711183563432044

Epoch: 5| Step: 5
Training loss: 1.3890086864092717
Validation loss: 2.4274577328190614

Epoch: 5| Step: 6
Training loss: 1.2328739939003561
Validation loss: 2.4229628140052974

Epoch: 5| Step: 7
Training loss: 1.9532282077223493
Validation loss: 2.478742993374231

Epoch: 5| Step: 8
Training loss: 1.0127835359466055
Validation loss: 2.535569810173441

Epoch: 5| Step: 9
Training loss: 1.5988178833485038
Validation loss: 2.6740671946814367

Epoch: 5| Step: 10
Training loss: 1.7735751598554401
Validation loss: 2.7809638436941486

Epoch: 5| Step: 11
Training loss: 2.0557774890767546
Validation loss: 2.670602037905576

Epoch: 108| Step: 0
Training loss: 1.8058910237550203
Validation loss: 2.5728099288627955

Epoch: 5| Step: 1
Training loss: 1.2574742022194478
Validation loss: 2.471803306121821

Epoch: 5| Step: 2
Training loss: 1.1764052753340581
Validation loss: 2.4369378215959197

Epoch: 5| Step: 3
Training loss: 1.35495891382067
Validation loss: 2.409807933284058

Epoch: 5| Step: 4
Training loss: 1.7323960019558962
Validation loss: 2.4006051572154905

Epoch: 5| Step: 5
Training loss: 1.8956345324680663
Validation loss: 2.4355840978401204

Epoch: 5| Step: 6
Training loss: 1.474806614499304
Validation loss: 2.4091367662325527

Epoch: 5| Step: 7
Training loss: 1.3301958432528518
Validation loss: 2.3270629384733157

Epoch: 5| Step: 8
Training loss: 1.4056429082358124
Validation loss: 2.396434448683832

Epoch: 5| Step: 9
Training loss: 1.3402594986208805
Validation loss: 2.4738315241922972

Epoch: 5| Step: 10
Training loss: 1.3553444753177297
Validation loss: 2.4885676332452062

Epoch: 5| Step: 11
Training loss: 0.9210237031531093
Validation loss: 2.523782641543137

Epoch: 109| Step: 0
Training loss: 1.589991982037943
Validation loss: 2.566851708370199

Epoch: 5| Step: 1
Training loss: 1.3483541699384223
Validation loss: 2.5504656290212333

Epoch: 5| Step: 2
Training loss: 1.6468247031361587
Validation loss: 2.471204193731374

Epoch: 5| Step: 3
Training loss: 0.8613499229942637
Validation loss: 2.4264392584859436

Epoch: 5| Step: 4
Training loss: 1.355601851114859
Validation loss: 2.413436522489596

Epoch: 5| Step: 5
Training loss: 1.5924957426244817
Validation loss: 2.378529473394587

Epoch: 5| Step: 6
Training loss: 1.471668266145752
Validation loss: 2.371508839036551

Epoch: 5| Step: 7
Training loss: 1.5410052590450627
Validation loss: 2.34603983177432

Epoch: 5| Step: 8
Training loss: 1.120374069756553
Validation loss: 2.3941632393032264

Epoch: 5| Step: 9
Training loss: 1.0809753995384672
Validation loss: 2.34901278165542

Epoch: 5| Step: 10
Training loss: 1.699365578808051
Validation loss: 2.4226744983145343

Epoch: 5| Step: 11
Training loss: 0.9354307226018475
Validation loss: 2.4111259319237632

Epoch: 110| Step: 0
Training loss: 1.1222474014071986
Validation loss: 2.519254644622009

Epoch: 5| Step: 1
Training loss: 1.642807662112097
Validation loss: 2.594644346359586

Epoch: 5| Step: 2
Training loss: 1.6993548459327203
Validation loss: 2.5337292613300666

Epoch: 5| Step: 3
Training loss: 1.49745948545645
Validation loss: 2.5450673777786443

Epoch: 5| Step: 4
Training loss: 1.1283280102779383
Validation loss: 2.475844446613335

Epoch: 5| Step: 5
Training loss: 1.0832458729774288
Validation loss: 2.478458456988873

Epoch: 5| Step: 6
Training loss: 1.2666837243554514
Validation loss: 2.410421351728005

Epoch: 5| Step: 7
Training loss: 1.370418632338125
Validation loss: 2.3980892603715316

Epoch: 5| Step: 8
Training loss: 1.3212121911535386
Validation loss: 2.442204292582945

Epoch: 5| Step: 9
Training loss: 1.6244938869202794
Validation loss: 2.436259722405638

Epoch: 5| Step: 10
Training loss: 1.2812017571275556
Validation loss: 2.429484284254657

Epoch: 5| Step: 11
Training loss: 1.4283756428479515
Validation loss: 2.3809865490414492

Epoch: 111| Step: 0
Training loss: 1.2219659971416845
Validation loss: 2.455429893588355

Epoch: 5| Step: 1
Training loss: 1.1005258755343474
Validation loss: 2.390010788080509

Epoch: 5| Step: 2
Training loss: 1.628511449598494
Validation loss: 2.426304288325888

Epoch: 5| Step: 3
Training loss: 1.3369326983783762
Validation loss: 2.4041996845069455

Epoch: 5| Step: 4
Training loss: 1.2633514705620865
Validation loss: 2.4005981016286677

Epoch: 5| Step: 5
Training loss: 1.6788017599004357
Validation loss: 2.4008945984114547

Epoch: 5| Step: 6
Training loss: 1.186211439014439
Validation loss: 2.435162874697634

Epoch: 5| Step: 7
Training loss: 1.3560536466581055
Validation loss: 2.4544000369469736

Epoch: 5| Step: 8
Training loss: 1.157829649022163
Validation loss: 2.4095558230589633

Epoch: 5| Step: 9
Training loss: 0.9353869785335575
Validation loss: 2.4077119762140806

Epoch: 5| Step: 10
Training loss: 1.1764434267863597
Validation loss: 2.405025756986163

Epoch: 5| Step: 11
Training loss: 1.5074715500609503
Validation loss: 2.4576726984843127

Epoch: 112| Step: 0
Training loss: 1.4584340560280642
Validation loss: 2.3853339024030085

Epoch: 5| Step: 1
Training loss: 0.7708710755739608
Validation loss: 2.4262753248129556

Epoch: 5| Step: 2
Training loss: 1.7704544858902436
Validation loss: 2.401772486470823

Epoch: 5| Step: 3
Training loss: 1.5231850439359194
Validation loss: 2.4620710355918827

Epoch: 5| Step: 4
Training loss: 1.2071982456472603
Validation loss: 2.4425363798695687

Epoch: 5| Step: 5
Training loss: 1.4413531533983195
Validation loss: 2.414890026075729

Epoch: 5| Step: 6
Training loss: 1.4182617053015045
Validation loss: 2.3935480593700196

Epoch: 5| Step: 7
Training loss: 1.0783051050098744
Validation loss: 2.386695549535292

Epoch: 5| Step: 8
Training loss: 1.1247843429704774
Validation loss: 2.3565790228303864

Epoch: 5| Step: 9
Training loss: 1.0736237698875608
Validation loss: 2.3902022542726287

Epoch: 5| Step: 10
Training loss: 1.2126837168461866
Validation loss: 2.398393017566567

Epoch: 5| Step: 11
Training loss: 0.8517994682204661
Validation loss: 2.4033996949202465

Epoch: 113| Step: 0
Training loss: 1.2121583752281473
Validation loss: 2.3745926227366683

Epoch: 5| Step: 1
Training loss: 1.0611883931424977
Validation loss: 2.464695538610524

Epoch: 5| Step: 2
Training loss: 1.3529545225097381
Validation loss: 2.44430792326755

Epoch: 5| Step: 3
Training loss: 1.6724296434141588
Validation loss: 2.4565225063384912

Epoch: 5| Step: 4
Training loss: 1.209951380706558
Validation loss: 2.4743268043106967

Epoch: 5| Step: 5
Training loss: 1.2064828460175803
Validation loss: 2.4492771074804716

Epoch: 5| Step: 6
Training loss: 1.0635910042662449
Validation loss: 2.464763625949018

Epoch: 5| Step: 7
Training loss: 1.1690328592327426
Validation loss: 2.428062304289169

Epoch: 5| Step: 8
Training loss: 1.3869964321588395
Validation loss: 2.416147724426893

Epoch: 5| Step: 9
Training loss: 1.41172428605008
Validation loss: 2.485711799700203

Epoch: 5| Step: 10
Training loss: 1.1919190350755948
Validation loss: 2.4130951590357324

Epoch: 5| Step: 11
Training loss: 0.2359032871375095
Validation loss: 2.4197906179394355

Epoch: 114| Step: 0
Training loss: 1.0462133679648185
Validation loss: 2.4298590367512367

Epoch: 5| Step: 1
Training loss: 0.7687269160828928
Validation loss: 2.4315030877411887

Epoch: 5| Step: 2
Training loss: 1.1365684069022948
Validation loss: 2.4783885333035043

Epoch: 5| Step: 3
Training loss: 1.2736122151911637
Validation loss: 2.470258408882585

Epoch: 5| Step: 4
Training loss: 1.0835142473622859
Validation loss: 2.4016085153480318

Epoch: 5| Step: 5
Training loss: 1.2425985555878942
Validation loss: 2.4534910095013327

Epoch: 5| Step: 6
Training loss: 0.7329697251176173
Validation loss: 2.385781261672189

Epoch: 5| Step: 7
Training loss: 1.349323027026417
Validation loss: 2.4439108002971928

Epoch: 5| Step: 8
Training loss: 1.780024927050467
Validation loss: 2.410762453018511

Epoch: 5| Step: 9
Training loss: 1.4490605599573643
Validation loss: 2.4409801670835685

Epoch: 5| Step: 10
Training loss: 0.9642163912766382
Validation loss: 2.3987490382282872

Epoch: 5| Step: 11
Training loss: 1.3782685185653007
Validation loss: 2.4343221073501193

Epoch: 115| Step: 0
Training loss: 1.0495572246490947
Validation loss: 2.364896956551911

Epoch: 5| Step: 1
Training loss: 1.4293827086367157
Validation loss: 2.3744657275257537

Epoch: 5| Step: 2
Training loss: 0.8578606527741521
Validation loss: 2.4107843381300817

Epoch: 5| Step: 3
Training loss: 1.7171419423996086
Validation loss: 2.429707047689455

Epoch: 5| Step: 4
Training loss: 1.075991856079764
Validation loss: 2.387184900857591

Epoch: 5| Step: 5
Training loss: 1.2307607637283795
Validation loss: 2.424423140640941

Epoch: 5| Step: 6
Training loss: 1.2825729704058122
Validation loss: 2.396559386878703

Epoch: 5| Step: 7
Training loss: 1.0891797630633726
Validation loss: 2.4019503925279198

Epoch: 5| Step: 8
Training loss: 0.9228886672538233
Validation loss: 2.388623881488205

Epoch: 5| Step: 9
Training loss: 1.1777719267114017
Validation loss: 2.46614453289853

Epoch: 5| Step: 10
Training loss: 1.2524704838699365
Validation loss: 2.452291630562452

Epoch: 5| Step: 11
Training loss: 1.1426583547219373
Validation loss: 2.495744066812618

Epoch: 116| Step: 0
Training loss: 1.4994373855873806
Validation loss: 2.4650257404123463

Epoch: 5| Step: 1
Training loss: 1.1780576752466665
Validation loss: 2.535156653609437

Epoch: 5| Step: 2
Training loss: 1.028947398087782
Validation loss: 2.3736071057438064

Epoch: 5| Step: 3
Training loss: 1.2121570475746632
Validation loss: 2.411249527978134

Epoch: 5| Step: 4
Training loss: 0.943846519536628
Validation loss: 2.399987613460578

Epoch: 5| Step: 5
Training loss: 1.0794299424351774
Validation loss: 2.378825336117949

Epoch: 5| Step: 6
Training loss: 1.192848108533156
Validation loss: 2.431603864726427

Epoch: 5| Step: 7
Training loss: 1.7386428971147998
Validation loss: 2.391025152355188

Epoch: 5| Step: 8
Training loss: 1.6280458954614523
Validation loss: 2.424516767025199

Epoch: 5| Step: 9
Training loss: 0.9945029926705726
Validation loss: 2.4313231826561528

Epoch: 5| Step: 10
Training loss: 0.8604002299058856
Validation loss: 2.4683852892090523

Epoch: 5| Step: 11
Training loss: 0.9753933736558469
Validation loss: 2.533039845596859

Epoch: 117| Step: 0
Training loss: 1.218397529691971
Validation loss: 2.4517895228130406

Epoch: 5| Step: 1
Training loss: 1.242446440572774
Validation loss: 2.4987457387435272

Epoch: 5| Step: 2
Training loss: 1.3297169737009134
Validation loss: 2.494149889389831

Epoch: 5| Step: 3
Training loss: 0.9672717844979013
Validation loss: 2.3349597802738313

Epoch: 5| Step: 4
Training loss: 0.7915536440095245
Validation loss: 2.3856757341213193

Epoch: 5| Step: 5
Training loss: 1.3318076295609202
Validation loss: 2.351566576610931

Epoch: 5| Step: 6
Training loss: 1.3455253228930733
Validation loss: 2.3807006732974494

Epoch: 5| Step: 7
Training loss: 1.3396256605771197
Validation loss: 2.424564795752359

Epoch: 5| Step: 8
Training loss: 0.951912593487424
Validation loss: 2.4101746371416417

Epoch: 5| Step: 9
Training loss: 1.0152397598881153
Validation loss: 2.4225917760427134

Epoch: 5| Step: 10
Training loss: 1.6811424164225481
Validation loss: 2.3987648188670154

Epoch: 5| Step: 11
Training loss: 0.37777586573969285
Validation loss: 2.4130422644044636

Epoch: 118| Step: 0
Training loss: 1.255969717538443
Validation loss: 2.4937212677864373

Epoch: 5| Step: 1
Training loss: 1.4288920706853119
Validation loss: 2.522218498367505

Epoch: 5| Step: 2
Training loss: 1.5956324511487399
Validation loss: 2.4852302086961813

Epoch: 5| Step: 3
Training loss: 0.8896172493954383
Validation loss: 2.5548529887285585

Epoch: 5| Step: 4
Training loss: 1.3451313636756164
Validation loss: 2.4395874572858043

Epoch: 5| Step: 5
Training loss: 0.9180240046327602
Validation loss: 2.4205080420036027

Epoch: 5| Step: 6
Training loss: 1.340307394610781
Validation loss: 2.4289117455790965

Epoch: 5| Step: 7
Training loss: 1.2268142927699783
Validation loss: 2.376815056323738

Epoch: 5| Step: 8
Training loss: 1.0861761805096384
Validation loss: 2.3888188023475787

Epoch: 5| Step: 9
Training loss: 1.226141887880223
Validation loss: 2.410629903949724

Epoch: 5| Step: 10
Training loss: 0.8667272085049064
Validation loss: 2.4540919728616086

Epoch: 5| Step: 11
Training loss: 0.8813891118409978
Validation loss: 2.373794659714559

Epoch: 119| Step: 0
Training loss: 0.8264453696780855
Validation loss: 2.4522893316480174

Epoch: 5| Step: 1
Training loss: 1.150859795380546
Validation loss: 2.438908125402765

Epoch: 5| Step: 2
Training loss: 1.6341998033731893
Validation loss: 2.453056622015886

Epoch: 5| Step: 3
Training loss: 1.271124441647339
Validation loss: 2.4821262738868666

Epoch: 5| Step: 4
Training loss: 1.4270741910247142
Validation loss: 2.4992445360598237

Epoch: 5| Step: 5
Training loss: 1.0165133772390589
Validation loss: 2.4715366570827495

Epoch: 5| Step: 6
Training loss: 1.047724308133092
Validation loss: 2.448906890305034

Epoch: 5| Step: 7
Training loss: 1.1548753247533614
Validation loss: 2.4071651345153713

Epoch: 5| Step: 8
Training loss: 1.3200395290640452
Validation loss: 2.4185022085093117

Epoch: 5| Step: 9
Training loss: 1.0813825845740122
Validation loss: 2.4353299384641267

Epoch: 5| Step: 10
Training loss: 0.8167971902460833
Validation loss: 2.441982862409015

Epoch: 5| Step: 11
Training loss: 1.1082908813453893
Validation loss: 2.4217700648391016

Epoch: 120| Step: 0
Training loss: 0.8674618055196966
Validation loss: 2.4023710254475077

Epoch: 5| Step: 1
Training loss: 0.7597941807575503
Validation loss: 2.3956227306737055

Epoch: 5| Step: 2
Training loss: 1.2599726543789411
Validation loss: 2.435346063341571

Epoch: 5| Step: 3
Training loss: 1.0585360352946294
Validation loss: 2.375937922892996

Epoch: 5| Step: 4
Training loss: 1.1094361409276825
Validation loss: 2.3935526870268866

Epoch: 5| Step: 5
Training loss: 1.7541684504822324
Validation loss: 2.3712389994191665

Epoch: 5| Step: 6
Training loss: 1.1172051595079084
Validation loss: 2.398060830160538

Epoch: 5| Step: 7
Training loss: 1.1468709524639333
Validation loss: 2.469901862408535

Epoch: 5| Step: 8
Training loss: 1.0686935097560946
Validation loss: 2.4043683171342605

Epoch: 5| Step: 9
Training loss: 0.9127114246986232
Validation loss: 2.418847256725023

Epoch: 5| Step: 10
Training loss: 1.0373198157421006
Validation loss: 2.3988344359002984

Epoch: 5| Step: 11
Training loss: 0.5607956390788131
Validation loss: 2.4499752188584067

Epoch: 121| Step: 0
Training loss: 0.9725506583505903
Validation loss: 2.425028904926114

Epoch: 5| Step: 1
Training loss: 1.1165973198172687
Validation loss: 2.3919674837579965

Epoch: 5| Step: 2
Training loss: 0.9386965427340298
Validation loss: 2.450137836445573

Epoch: 5| Step: 3
Training loss: 0.9103392715786555
Validation loss: 2.3689115098496845

Epoch: 5| Step: 4
Training loss: 1.0452232995627257
Validation loss: 2.4158504720544647

Epoch: 5| Step: 5
Training loss: 1.24919154726223
Validation loss: 2.4558656856147754

Epoch: 5| Step: 6
Training loss: 0.9264145628501002
Validation loss: 2.3399789502584123

Epoch: 5| Step: 7
Training loss: 1.067514926171755
Validation loss: 2.4198113950685185

Epoch: 5| Step: 8
Training loss: 1.5940789275976546
Validation loss: 2.3917200265031466

Epoch: 5| Step: 9
Training loss: 1.3407193095151342
Validation loss: 2.408050759170476

Epoch: 5| Step: 10
Training loss: 0.9290147799783122
Validation loss: 2.4311225390262527

Epoch: 5| Step: 11
Training loss: 0.9033167493595267
Validation loss: 2.453330543637849

Epoch: 122| Step: 0
Training loss: 0.7553293503888876
Validation loss: 2.4642470534801975

Epoch: 5| Step: 1
Training loss: 0.7353280153595244
Validation loss: 2.4000707650679454

Epoch: 5| Step: 2
Training loss: 1.4267901469802409
Validation loss: 2.419117374843305

Epoch: 5| Step: 3
Training loss: 1.3134233315044215
Validation loss: 2.370372467690634

Epoch: 5| Step: 4
Training loss: 0.8616954340335341
Validation loss: 2.4425125707877466

Epoch: 5| Step: 5
Training loss: 1.584628612678191
Validation loss: 2.3982053886701387

Epoch: 5| Step: 6
Training loss: 0.8171908245420207
Validation loss: 2.3890947667818896

Epoch: 5| Step: 7
Training loss: 0.8213965383053142
Validation loss: 2.400490090627226

Epoch: 5| Step: 8
Training loss: 0.8342526292539414
Validation loss: 2.3994100878833584

Epoch: 5| Step: 9
Training loss: 1.1937662233378699
Validation loss: 2.4255161068830473

Epoch: 5| Step: 10
Training loss: 1.3085739361985276
Validation loss: 2.425918366370126

Epoch: 5| Step: 11
Training loss: 0.7324667954974803
Validation loss: 2.429973822565194

Epoch: 123| Step: 0
Training loss: 0.899747308384165
Validation loss: 2.4125477751512796

Epoch: 5| Step: 1
Training loss: 1.0708518792313986
Validation loss: 2.425316123577947

Epoch: 5| Step: 2
Training loss: 0.5201404126576048
Validation loss: 2.4631377823936864

Epoch: 5| Step: 3
Training loss: 1.428776601975929
Validation loss: 2.414146623513983

Epoch: 5| Step: 4
Training loss: 1.0813204637620832
Validation loss: 2.4258763841862363

Epoch: 5| Step: 5
Training loss: 0.998386123839794
Validation loss: 2.4647367205307384

Epoch: 5| Step: 6
Training loss: 0.8711389777925538
Validation loss: 2.451795083872382

Epoch: 5| Step: 7
Training loss: 1.2918344921890539
Validation loss: 2.4036503327156407

Epoch: 5| Step: 8
Training loss: 0.853693893286911
Validation loss: 2.450235523853289

Epoch: 5| Step: 9
Training loss: 0.6113607379635777
Validation loss: 2.4080478177777667

Epoch: 5| Step: 10
Training loss: 1.720486821100589
Validation loss: 2.440983349603065

Epoch: 5| Step: 11
Training loss: 0.8177116944715745
Validation loss: 2.502462183920348

Epoch: 124| Step: 0
Training loss: 0.9990406799320019
Validation loss: 2.4716352631851914

Epoch: 5| Step: 1
Training loss: 1.0217717716444645
Validation loss: 2.4342963121499785

Epoch: 5| Step: 2
Training loss: 1.0437197606623136
Validation loss: 2.453575659822478

Epoch: 5| Step: 3
Training loss: 0.7849933967798558
Validation loss: 2.390583335081221

Epoch: 5| Step: 4
Training loss: 1.0216754566849588
Validation loss: 2.44083576708792

Epoch: 5| Step: 5
Training loss: 1.0649646334977003
Validation loss: 2.396436562821598

Epoch: 5| Step: 6
Training loss: 0.745166421966012
Validation loss: 2.3689378115396615

Epoch: 5| Step: 7
Training loss: 1.155452814308241
Validation loss: 2.3575343727000826

Epoch: 5| Step: 8
Training loss: 0.8449131048543623
Validation loss: 2.4404568588618756

Epoch: 5| Step: 9
Training loss: 1.7606743467847839
Validation loss: 2.4393397259831318

Epoch: 5| Step: 10
Training loss: 0.9264501738369466
Validation loss: 2.4009119620771675

Epoch: 5| Step: 11
Training loss: 0.5491049940397283
Validation loss: 2.454405879461168

Epoch: 125| Step: 0
Training loss: 1.2360522789593067
Validation loss: 2.4734124568555815

Epoch: 5| Step: 1
Training loss: 0.8933069438084962
Validation loss: 2.4781740743356746

Epoch: 5| Step: 2
Training loss: 1.0316628294479504
Validation loss: 2.49420201786869

Epoch: 5| Step: 3
Training loss: 0.6996758527923577
Validation loss: 2.4361102755977813

Epoch: 5| Step: 4
Training loss: 1.0969280393117613
Validation loss: 2.440017899515338

Epoch: 5| Step: 5
Training loss: 0.810969892674408
Validation loss: 2.4494892905856998

Epoch: 5| Step: 6
Training loss: 1.7433043864213216
Validation loss: 2.4710151807009186

Epoch: 5| Step: 7
Training loss: 0.5101718088204718
Validation loss: 2.4944417438643502

Epoch: 5| Step: 8
Training loss: 0.9156559154512101
Validation loss: 2.384694149644762

Epoch: 5| Step: 9
Training loss: 1.207861852192768
Validation loss: 2.4158740442887

Epoch: 5| Step: 10
Training loss: 1.0400265688436796
Validation loss: 2.4210881298287585

Epoch: 5| Step: 11
Training loss: 1.1666947372783427
Validation loss: 2.4375708887600394

Epoch: 126| Step: 0
Training loss: 0.9267797758918602
Validation loss: 2.3456844294150008

Epoch: 5| Step: 1
Training loss: 0.9698792305711627
Validation loss: 2.4503818773903756

Epoch: 5| Step: 2
Training loss: 1.0696095852415957
Validation loss: 2.372447103678452

Epoch: 5| Step: 3
Training loss: 1.0470519983774509
Validation loss: 2.438840301969137

Epoch: 5| Step: 4
Training loss: 0.9064799050041151
Validation loss: 2.4853509549463073

Epoch: 5| Step: 5
Training loss: 1.411475665935029
Validation loss: 2.517346813702084

Epoch: 5| Step: 6
Training loss: 0.5827274894588843
Validation loss: 2.53798552144833

Epoch: 5| Step: 7
Training loss: 1.3165152756456344
Validation loss: 2.493444183706551

Epoch: 5| Step: 8
Training loss: 0.8444384133042685
Validation loss: 2.460261874830233

Epoch: 5| Step: 9
Training loss: 1.1090217350239324
Validation loss: 2.4423860216634443

Epoch: 5| Step: 10
Training loss: 1.0516964355241496
Validation loss: 2.4422879999511737

Epoch: 5| Step: 11
Training loss: 0.8856667146839459
Validation loss: 2.4456172017961753

Epoch: 127| Step: 0
Training loss: 0.9802343080641764
Validation loss: 2.4377767964052457

Epoch: 5| Step: 1
Training loss: 0.963356601710168
Validation loss: 2.4309015705921935

Epoch: 5| Step: 2
Training loss: 0.6937693069108404
Validation loss: 2.467953223404724

Epoch: 5| Step: 3
Training loss: 1.528102598435663
Validation loss: 2.48551062054342

Epoch: 5| Step: 4
Training loss: 0.9874770016949739
Validation loss: 2.5178698559864916

Epoch: 5| Step: 5
Training loss: 1.35028112451412
Validation loss: 2.5103605245641307

Epoch: 5| Step: 6
Training loss: 0.8820894706979863
Validation loss: 2.495101918710671

Epoch: 5| Step: 7
Training loss: 0.8814513591928339
Validation loss: 2.4824572744979405

Epoch: 5| Step: 8
Training loss: 1.4016239369683574
Validation loss: 2.438060382266081

Epoch: 5| Step: 9
Training loss: 1.0671738317907309
Validation loss: 2.450516362579732

Epoch: 5| Step: 10
Training loss: 1.216346277658532
Validation loss: 2.511930908608556

Epoch: 5| Step: 11
Training loss: 1.0096052326488463
Validation loss: 2.430100225002579

Epoch: 128| Step: 0
Training loss: 1.0113346740581333
Validation loss: 2.4257362431166203

Epoch: 5| Step: 1
Training loss: 1.8407829463009635
Validation loss: 2.4025546345765467

Epoch: 5| Step: 2
Training loss: 0.9433096799535977
Validation loss: 2.4652452277928543

Epoch: 5| Step: 3
Training loss: 1.2127008704317546
Validation loss: 2.5279402110085516

Epoch: 5| Step: 4
Training loss: 1.25906783302827
Validation loss: 2.687259800105375

Epoch: 5| Step: 5
Training loss: 0.9732156087333915
Validation loss: 2.596302618639274

Epoch: 5| Step: 6
Training loss: 1.040485468952243
Validation loss: 2.513646759721852

Epoch: 5| Step: 7
Training loss: 1.0531587046315067
Validation loss: 2.4311270461254213

Epoch: 5| Step: 8
Training loss: 0.8120483096578492
Validation loss: 2.452466880491754

Epoch: 5| Step: 9
Training loss: 0.8973506158177165
Validation loss: 2.4842240429645956

Epoch: 5| Step: 10
Training loss: 1.3341871249941375
Validation loss: 2.4319418315908514

Epoch: 5| Step: 11
Training loss: 0.991940024443308
Validation loss: 2.43815192038805

Epoch: 129| Step: 0
Training loss: 0.9201810111395033
Validation loss: 2.454008684324833

Epoch: 5| Step: 1
Training loss: 0.7266423581443816
Validation loss: 2.423073781616572

Epoch: 5| Step: 2
Training loss: 1.016542343188416
Validation loss: 2.4985174352770265

Epoch: 5| Step: 3
Training loss: 1.3496610904838127
Validation loss: 2.5467838239829317

Epoch: 5| Step: 4
Training loss: 1.6987181178140394
Validation loss: 2.565309827405625

Epoch: 5| Step: 5
Training loss: 1.100169714926677
Validation loss: 2.607265365799159

Epoch: 5| Step: 6
Training loss: 0.9101047419433824
Validation loss: 2.558910953961292

Epoch: 5| Step: 7
Training loss: 0.6251850569460979
Validation loss: 2.504958014694743

Epoch: 5| Step: 8
Training loss: 1.0139261562576058
Validation loss: 2.534138824584245

Epoch: 5| Step: 9
Training loss: 1.075108717810294
Validation loss: 2.409311860737838

Epoch: 5| Step: 10
Training loss: 1.06550498577439
Validation loss: 2.4166353664892433

Epoch: 5| Step: 11
Training loss: 1.046981122915176
Validation loss: 2.4371314544500957

Epoch: 130| Step: 0
Training loss: 1.062895981544868
Validation loss: 2.461996809221881

Epoch: 5| Step: 1
Training loss: 0.8521727029308216
Validation loss: 2.4782782266331136

Epoch: 5| Step: 2
Training loss: 0.9885052513808912
Validation loss: 2.4346822607582768

Epoch: 5| Step: 3
Training loss: 1.590820237564263
Validation loss: 2.44231915711928

Epoch: 5| Step: 4
Training loss: 0.5917992670495567
Validation loss: 2.516984836621608

Epoch: 5| Step: 5
Training loss: 0.9142884195343084
Validation loss: 2.5501114441479387

Epoch: 5| Step: 6
Training loss: 1.2477607219910263
Validation loss: 2.505011954643876

Epoch: 5| Step: 7
Training loss: 1.2423246295979913
Validation loss: 2.4529984151977904

Epoch: 5| Step: 8
Training loss: 0.729127356059955
Validation loss: 2.4996868732176756

Epoch: 5| Step: 9
Training loss: 0.7367632564236155
Validation loss: 2.398781291001531

Epoch: 5| Step: 10
Training loss: 0.8883185721871385
Validation loss: 2.380867031503393

Epoch: 5| Step: 11
Training loss: 1.0717468118337663
Validation loss: 2.3389352383731556

Epoch: 131| Step: 0
Training loss: 0.8791855431891054
Validation loss: 2.3849608736874126

Epoch: 5| Step: 1
Training loss: 0.8142756353318604
Validation loss: 2.3887231862339684

Epoch: 5| Step: 2
Training loss: 0.721962838381566
Validation loss: 2.367909190302434

Epoch: 5| Step: 3
Training loss: 0.9644167491902149
Validation loss: 2.4366481751624405

Epoch: 5| Step: 4
Training loss: 0.9331206715222155
Validation loss: 2.4590487139715305

Epoch: 5| Step: 5
Training loss: 0.8823388440978814
Validation loss: 2.471177754404965

Epoch: 5| Step: 6
Training loss: 1.1952806855000697
Validation loss: 2.4220414155779935

Epoch: 5| Step: 7
Training loss: 1.078531713756028
Validation loss: 2.4773495343141887

Epoch: 5| Step: 8
Training loss: 0.8949375146226064
Validation loss: 2.456971819249333

Epoch: 5| Step: 9
Training loss: 1.3812248037810562
Validation loss: 2.3983480745392267

Epoch: 5| Step: 10
Training loss: 1.0537385415464453
Validation loss: 2.389464757522124

Epoch: 5| Step: 11
Training loss: 1.359192496139487
Validation loss: 2.439174174966346

Epoch: 132| Step: 0
Training loss: 1.5470365960071455
Validation loss: 2.5041916437114686

Epoch: 5| Step: 1
Training loss: 0.947103112821606
Validation loss: 2.4431708507345444

Epoch: 5| Step: 2
Training loss: 1.3364900483639657
Validation loss: 2.403681720012502

Epoch: 5| Step: 3
Training loss: 0.7258876825153899
Validation loss: 2.4790379680492234

Epoch: 5| Step: 4
Training loss: 0.5461422234279554
Validation loss: 2.3637042925386336

Epoch: 5| Step: 5
Training loss: 0.9440392360453644
Validation loss: 2.363104951866467

Epoch: 5| Step: 6
Training loss: 0.7084852411029158
Validation loss: 2.369035886759209

Epoch: 5| Step: 7
Training loss: 0.9846486513542633
Validation loss: 2.3587471461316722

Epoch: 5| Step: 8
Training loss: 1.0852773292613698
Validation loss: 2.4180311442486904

Epoch: 5| Step: 9
Training loss: 0.858242398293641
Validation loss: 2.4335532514162885

Epoch: 5| Step: 10
Training loss: 0.8887955464255811
Validation loss: 2.402657336932541

Epoch: 5| Step: 11
Training loss: 0.24826457765271753
Validation loss: 2.3941630691818188

Epoch: 133| Step: 0
Training loss: 0.7129719308969875
Validation loss: 2.469116640429589

Epoch: 5| Step: 1
Training loss: 0.94632348469425
Validation loss: 2.443145730415431

Epoch: 5| Step: 2
Training loss: 1.1274587465508217
Validation loss: 2.4220179423325985

Epoch: 5| Step: 3
Training loss: 1.0808089751530954
Validation loss: 2.5027262604642773

Epoch: 5| Step: 4
Training loss: 0.7608143450264075
Validation loss: 2.4547464434473016

Epoch: 5| Step: 5
Training loss: 0.8366334816505453
Validation loss: 2.421865930847907

Epoch: 5| Step: 6
Training loss: 1.472761803039178
Validation loss: 2.4521408253111905

Epoch: 5| Step: 7
Training loss: 0.6833685149657359
Validation loss: 2.439392052428849

Epoch: 5| Step: 8
Training loss: 0.9077617926560446
Validation loss: 2.468059829620437

Epoch: 5| Step: 9
Training loss: 0.5421696003094653
Validation loss: 2.3965089273892017

Epoch: 5| Step: 10
Training loss: 0.7781429687018593
Validation loss: 2.4239063193971777

Epoch: 5| Step: 11
Training loss: 1.67842118190858
Validation loss: 2.454145773932012

Epoch: 134| Step: 0
Training loss: 0.7731649901302071
Validation loss: 2.4455470134175834

Epoch: 5| Step: 1
Training loss: 0.7384130773973325
Validation loss: 2.4732024366473

Epoch: 5| Step: 2
Training loss: 1.0279540943145298
Validation loss: 2.443743160527667

Epoch: 5| Step: 3
Training loss: 1.3610792767225202
Validation loss: 2.474564890874415

Epoch: 5| Step: 4
Training loss: 0.8733265405371322
Validation loss: 2.433892767973071

Epoch: 5| Step: 5
Training loss: 0.7349597145250837
Validation loss: 2.4210606959580185

Epoch: 5| Step: 6
Training loss: 0.9903951360159392
Validation loss: 2.463255195548444

Epoch: 5| Step: 7
Training loss: 0.886980765866361
Validation loss: 2.4100892826877125

Epoch: 5| Step: 8
Training loss: 0.9504698683082916
Validation loss: 2.424322556881307

Epoch: 5| Step: 9
Training loss: 1.129332518039831
Validation loss: 2.455059005917779

Epoch: 5| Step: 10
Training loss: 0.8514241097366272
Validation loss: 2.4810717713270023

Epoch: 5| Step: 11
Training loss: 0.5610006270311628
Validation loss: 2.428245963148345

Epoch: 135| Step: 0
Training loss: 0.6917698222147541
Validation loss: 2.4531696846004336

Epoch: 5| Step: 1
Training loss: 1.0075658452025968
Validation loss: 2.4335826242844694

Epoch: 5| Step: 2
Training loss: 0.6306355554701064
Validation loss: 2.4689162958849833

Epoch: 5| Step: 3
Training loss: 0.7310708975924778
Validation loss: 2.3710431675383457

Epoch: 5| Step: 4
Training loss: 1.6944032683172574
Validation loss: 2.381094232772724

Epoch: 5| Step: 5
Training loss: 0.7470289829764708
Validation loss: 2.408321207559368

Epoch: 5| Step: 6
Training loss: 0.7962511650088904
Validation loss: 2.363844337322471

Epoch: 5| Step: 7
Training loss: 0.6549958097163693
Validation loss: 2.3414138467975394

Epoch: 5| Step: 8
Training loss: 0.9281590824740931
Validation loss: 2.390983810175748

Epoch: 5| Step: 9
Training loss: 0.47217355466455724
Validation loss: 2.40203175987027

Epoch: 5| Step: 10
Training loss: 0.9796303740034324
Validation loss: 2.3990719170514123

Epoch: 5| Step: 11
Training loss: 0.7068107640552648
Validation loss: 2.464687429107024

Epoch: 136| Step: 0
Training loss: 0.66084544755993
Validation loss: 2.377442175091441

Epoch: 5| Step: 1
Training loss: 0.6023262674488616
Validation loss: 2.3883098495346635

Epoch: 5| Step: 2
Training loss: 1.081159936318154
Validation loss: 2.4120288294884866

Epoch: 5| Step: 3
Training loss: 0.7944684809343799
Validation loss: 2.3541379746795705

Epoch: 5| Step: 4
Training loss: 0.8509189728937965
Validation loss: 2.386755789528158

Epoch: 5| Step: 5
Training loss: 0.6262592742522539
Validation loss: 2.4616073584810563

Epoch: 5| Step: 6
Training loss: 0.5190334947211264
Validation loss: 2.4080855832544232

Epoch: 5| Step: 7
Training loss: 1.006795384712386
Validation loss: 2.438164705952076

Epoch: 5| Step: 8
Training loss: 0.9514494692564447
Validation loss: 2.4457271780884415

Epoch: 5| Step: 9
Training loss: 1.4637126981052684
Validation loss: 2.519270626654599

Epoch: 5| Step: 10
Training loss: 0.9300415262569941
Validation loss: 2.4980127343694893

Epoch: 5| Step: 11
Training loss: 1.131245074603913
Validation loss: 2.4603114830508237

Epoch: 137| Step: 0
Training loss: 0.9353585899919041
Validation loss: 2.5261811496463493

Epoch: 5| Step: 1
Training loss: 1.3608095338838404
Validation loss: 2.4601824131843686

Epoch: 5| Step: 2
Training loss: 0.689805651225054
Validation loss: 2.4386013448735486

Epoch: 5| Step: 3
Training loss: 0.9594053754440024
Validation loss: 2.4477978062011125

Epoch: 5| Step: 4
Training loss: 0.9512218485713164
Validation loss: 2.435160969597138

Epoch: 5| Step: 5
Training loss: 0.8922914340915298
Validation loss: 2.4347830407984374

Epoch: 5| Step: 6
Training loss: 0.4761726160333139
Validation loss: 2.439685231210963

Epoch: 5| Step: 7
Training loss: 0.8100917779472984
Validation loss: 2.434081904731117

Epoch: 5| Step: 8
Training loss: 0.9944729052957504
Validation loss: 2.436542261696917

Epoch: 5| Step: 9
Training loss: 0.7323725162404738
Validation loss: 2.4361513311083454

Epoch: 5| Step: 10
Training loss: 0.5125723555126366
Validation loss: 2.480633030855432

Epoch: 5| Step: 11
Training loss: 0.5232422307873431
Validation loss: 2.4534987349207955

Epoch: 138| Step: 0
Training loss: 0.7281445332800849
Validation loss: 2.503561130014293

Epoch: 5| Step: 1
Training loss: 0.6802888818652967
Validation loss: 2.4177293222401914

Epoch: 5| Step: 2
Training loss: 1.0003731746559217
Validation loss: 2.4081174944039483

Epoch: 5| Step: 3
Training loss: 0.893406623288111
Validation loss: 2.39871438299324

Epoch: 5| Step: 4
Training loss: 0.7585083038262793
Validation loss: 2.4544548592989988

Epoch: 5| Step: 5
Training loss: 1.5973743292579285
Validation loss: 2.485462054861144

Epoch: 5| Step: 6
Training loss: 0.7563370173809946
Validation loss: 2.4855013399391037

Epoch: 5| Step: 7
Training loss: 0.5880498575413929
Validation loss: 2.4482929481627598

Epoch: 5| Step: 8
Training loss: 1.0460725812073504
Validation loss: 2.468669181820732

Epoch: 5| Step: 9
Training loss: 0.7892640489059516
Validation loss: 2.432196034601059

Epoch: 5| Step: 10
Training loss: 0.6705022583311141
Validation loss: 2.400087010938856

Epoch: 5| Step: 11
Training loss: 0.4829046945291967
Validation loss: 2.4040250358536768

Epoch: 139| Step: 0
Training loss: 0.9201910511962171
Validation loss: 2.4160543164727457

Epoch: 5| Step: 1
Training loss: 0.6988612491781172
Validation loss: 2.43811536015001

Epoch: 5| Step: 2
Training loss: 0.9154346958330233
Validation loss: 2.386872814677236

Epoch: 5| Step: 3
Training loss: 0.5614687420287753
Validation loss: 2.432117612493802

Epoch: 5| Step: 4
Training loss: 0.9590909630612313
Validation loss: 2.373001297040789

Epoch: 5| Step: 5
Training loss: 0.848629125097624
Validation loss: 2.448988007744695

Epoch: 5| Step: 6
Training loss: 0.9501787519433021
Validation loss: 2.4652069638309517

Epoch: 5| Step: 7
Training loss: 0.8028556565044067
Validation loss: 2.53914741178506

Epoch: 5| Step: 8
Training loss: 0.7208603684825837
Validation loss: 2.5308687017086124

Epoch: 5| Step: 9
Training loss: 0.8237783692819188
Validation loss: 2.4346139850109076

Epoch: 5| Step: 10
Training loss: 1.2816494109815573
Validation loss: 2.432406258725656

Epoch: 5| Step: 11
Training loss: 0.6766017717412112
Validation loss: 2.433524308864609

Epoch: 140| Step: 0
Training loss: 0.9167105635333876
Validation loss: 2.4041887099403105

Epoch: 5| Step: 1
Training loss: 0.6915541022023978
Validation loss: 2.461623319299302

Epoch: 5| Step: 2
Training loss: 0.8812353511702019
Validation loss: 2.4817266323533875

Epoch: 5| Step: 3
Training loss: 0.8398908734962681
Validation loss: 2.425025773157233

Epoch: 5| Step: 4
Training loss: 0.875915559241434
Validation loss: 2.5006147105742533

Epoch: 5| Step: 5
Training loss: 0.6738873884151674
Validation loss: 2.4477679078915195

Epoch: 5| Step: 6
Training loss: 0.6793366984824344
Validation loss: 2.4872477814108547

Epoch: 5| Step: 7
Training loss: 1.4606484519894143
Validation loss: 2.4497686495833593

Epoch: 5| Step: 8
Training loss: 0.7028566696175644
Validation loss: 2.515414231121036

Epoch: 5| Step: 9
Training loss: 0.7432508781343232
Validation loss: 2.470549127053992

Epoch: 5| Step: 10
Training loss: 0.6364339647971294
Validation loss: 2.4166371567064426

Epoch: 5| Step: 11
Training loss: 0.6731974428345907
Validation loss: 2.4333565414205967

Epoch: 141| Step: 0
Training loss: 0.8014869371754924
Validation loss: 2.477343936384024

Epoch: 5| Step: 1
Training loss: 0.8155511274536602
Validation loss: 2.4473287092736014

Epoch: 5| Step: 2
Training loss: 0.9968160366689474
Validation loss: 2.431893676908968

Epoch: 5| Step: 3
Training loss: 0.7618715573139971
Validation loss: 2.44561498394085

Epoch: 5| Step: 4
Training loss: 0.652398021519115
Validation loss: 2.4305998345534907

Epoch: 5| Step: 5
Training loss: 1.0146610086670105
Validation loss: 2.4678216951374523

Epoch: 5| Step: 6
Training loss: 0.6509001056627102
Validation loss: 2.4299298213641607

Epoch: 5| Step: 7
Training loss: 0.7051840620686525
Validation loss: 2.4763914745174915

Epoch: 5| Step: 8
Training loss: 1.4008486117214938
Validation loss: 2.4587633893634755

Epoch: 5| Step: 9
Training loss: 0.5075205036775728
Validation loss: 2.393426583290066

Epoch: 5| Step: 10
Training loss: 0.7382752756351358
Validation loss: 2.4352031058294163

Epoch: 5| Step: 11
Training loss: 0.4823631528875901
Validation loss: 2.4195510296849143

Epoch: 142| Step: 0
Training loss: 1.3615989470402718
Validation loss: 2.4693867369295384

Epoch: 5| Step: 1
Training loss: 0.5954700701980951
Validation loss: 2.494140545340437

Epoch: 5| Step: 2
Training loss: 0.7780368341341367
Validation loss: 2.407424895890067

Epoch: 5| Step: 3
Training loss: 0.9770930260595709
Validation loss: 2.4160499128305277

Epoch: 5| Step: 4
Training loss: 0.9983564818558481
Validation loss: 2.4501616869824105

Epoch: 5| Step: 5
Training loss: 0.7380812439639319
Validation loss: 2.419860241761647

Epoch: 5| Step: 6
Training loss: 0.8692487670828255
Validation loss: 2.43498564501819

Epoch: 5| Step: 7
Training loss: 0.8060933397073546
Validation loss: 2.4327129078208665

Epoch: 5| Step: 8
Training loss: 0.49670435656308737
Validation loss: 2.458549830769004

Epoch: 5| Step: 9
Training loss: 0.6408926474483538
Validation loss: 2.4498254003396553

Epoch: 5| Step: 10
Training loss: 0.8801290186673925
Validation loss: 2.5036989623156174

Epoch: 5| Step: 11
Training loss: 0.7110130353770845
Validation loss: 2.4246336781524334

Epoch: 143| Step: 0
Training loss: 0.7301801223493188
Validation loss: 2.450182159943982

Epoch: 5| Step: 1
Training loss: 0.5784130409877094
Validation loss: 2.4220496494119423

Epoch: 5| Step: 2
Training loss: 1.0458981525552542
Validation loss: 2.4823940784769944

Epoch: 5| Step: 3
Training loss: 1.265552565774204
Validation loss: 2.500239567404345

Epoch: 5| Step: 4
Training loss: 1.1612902407043695
Validation loss: 2.473452692392859

Epoch: 5| Step: 5
Training loss: 0.6344988922758782
Validation loss: 2.4457235143226206

Epoch: 5| Step: 6
Training loss: 0.7101902230742738
Validation loss: 2.483043601802033

Epoch: 5| Step: 7
Training loss: 0.6677468360674534
Validation loss: 2.5330001094804033

Epoch: 5| Step: 8
Training loss: 0.7758110693725779
Validation loss: 2.4411948435487605

Epoch: 5| Step: 9
Training loss: 0.9178847903550714
Validation loss: 2.4979160762740564

Epoch: 5| Step: 10
Training loss: 0.48337262017251426
Validation loss: 2.5301699473041044

Epoch: 5| Step: 11
Training loss: 0.3486380696902073
Validation loss: 2.441932011259274

Epoch: 144| Step: 0
Training loss: 0.5412208911389309
Validation loss: 2.4333684785364604

Epoch: 5| Step: 1
Training loss: 0.5166588158421194
Validation loss: 2.4189355547403615

Epoch: 5| Step: 2
Training loss: 0.9005083846994438
Validation loss: 2.4114771540808824

Epoch: 5| Step: 3
Training loss: 0.6151831469325136
Validation loss: 2.4455609870733146

Epoch: 5| Step: 4
Training loss: 1.3993442089378476
Validation loss: 2.5056694872598664

Epoch: 5| Step: 5
Training loss: 0.5768598683894827
Validation loss: 2.4346238145841848

Epoch: 5| Step: 6
Training loss: 0.6615030669056907
Validation loss: 2.4944026354344753

Epoch: 5| Step: 7
Training loss: 0.8693306018783021
Validation loss: 2.48084620810288

Epoch: 5| Step: 8
Training loss: 0.8459643870020623
Validation loss: 2.4699606240888143

Epoch: 5| Step: 9
Training loss: 0.9021998369135167
Validation loss: 2.527487391576564

Epoch: 5| Step: 10
Training loss: 0.7063296298481568
Validation loss: 2.4899785647178194

Epoch: 5| Step: 11
Training loss: 0.35461753541675917
Validation loss: 2.50529629056595

Epoch: 145| Step: 0
Training loss: 0.8255010095055252
Validation loss: 2.451404681048318

Epoch: 5| Step: 1
Training loss: 0.7326975799442486
Validation loss: 2.475990137011502

Epoch: 5| Step: 2
Training loss: 0.7884361878519105
Validation loss: 2.438967132821853

Epoch: 5| Step: 3
Training loss: 0.5463885459835259
Validation loss: 2.4565718342098606

Epoch: 5| Step: 4
Training loss: 0.9564260943964834
Validation loss: 2.480675171600801

Epoch: 5| Step: 5
Training loss: 1.3155658427731574
Validation loss: 2.486258570479064

Epoch: 5| Step: 6
Training loss: 0.6144385382781551
Validation loss: 2.4683145468995256

Epoch: 5| Step: 7
Training loss: 0.7133214615416251
Validation loss: 2.5119210493491226

Epoch: 5| Step: 8
Training loss: 0.6540839688659307
Validation loss: 2.4684449743806534

Epoch: 5| Step: 9
Training loss: 0.7695359747881999
Validation loss: 2.5024928578615606

Epoch: 5| Step: 10
Training loss: 0.5627583334368045
Validation loss: 2.477920380587371

Epoch: 5| Step: 11
Training loss: 1.671139635594789
Validation loss: 2.4111903984451684

Epoch: 146| Step: 0
Training loss: 0.4342498798062735
Validation loss: 2.445942554818753

Epoch: 5| Step: 1
Training loss: 0.6442983958075004
Validation loss: 2.395255731671805

Epoch: 5| Step: 2
Training loss: 0.9926200884851362
Validation loss: 2.4863150357293664

Epoch: 5| Step: 3
Training loss: 0.9823819222488505
Validation loss: 2.4529947015453955

Epoch: 5| Step: 4
Training loss: 0.6164527092312158
Validation loss: 2.390881927662752

Epoch: 5| Step: 5
Training loss: 0.7773436733226643
Validation loss: 2.5349388323219135

Epoch: 5| Step: 6
Training loss: 0.5973561100500493
Validation loss: 2.472238036228945

Epoch: 5| Step: 7
Training loss: 0.7554648303588047
Validation loss: 2.459894665770234

Epoch: 5| Step: 8
Training loss: 1.3186778948266955
Validation loss: 2.437551905413562

Epoch: 5| Step: 9
Training loss: 0.7269477233194076
Validation loss: 2.4729056451022147

Epoch: 5| Step: 10
Training loss: 0.8814585946128588
Validation loss: 2.472539448000731

Epoch: 5| Step: 11
Training loss: 0.4801015769004152
Validation loss: 2.478103463142263

Epoch: 147| Step: 0
Training loss: 0.5957577539628506
Validation loss: 2.5265684987635693

Epoch: 5| Step: 1
Training loss: 0.6865721206442423
Validation loss: 2.482002112762214

Epoch: 5| Step: 2
Training loss: 0.7690576170479937
Validation loss: 2.4450698748422144

Epoch: 5| Step: 3
Training loss: 0.8305602704179772
Validation loss: 2.467790723085216

Epoch: 5| Step: 4
Training loss: 0.6403257089558444
Validation loss: 2.482704888795144

Epoch: 5| Step: 5
Training loss: 0.8763774860168898
Validation loss: 2.478843324609785

Epoch: 5| Step: 6
Training loss: 0.8445111479647339
Validation loss: 2.4579040562026577

Epoch: 5| Step: 7
Training loss: 0.5427111007512483
Validation loss: 2.4998037181730863

Epoch: 5| Step: 8
Training loss: 1.2524589195291127
Validation loss: 2.505748442059848

Epoch: 5| Step: 9
Training loss: 0.5044220642669912
Validation loss: 2.502361044981269

Epoch: 5| Step: 10
Training loss: 0.7626900764314904
Validation loss: 2.444143645622196

Epoch: 5| Step: 11
Training loss: 1.0272192353770866
Validation loss: 2.4265326341099915

Epoch: 148| Step: 0
Training loss: 0.4968471363340198
Validation loss: 2.5047707654693365

Epoch: 5| Step: 1
Training loss: 0.7395438241927326
Validation loss: 2.55914210687113

Epoch: 5| Step: 2
Training loss: 1.2600812649633053
Validation loss: 2.4896788412525863

Epoch: 5| Step: 3
Training loss: 0.7407309041981673
Validation loss: 2.504475604712444

Epoch: 5| Step: 4
Training loss: 0.43601911115867487
Validation loss: 2.4591434822187512

Epoch: 5| Step: 5
Training loss: 0.6236653382480705
Validation loss: 2.4831498602054656

Epoch: 5| Step: 6
Training loss: 1.0755796377933704
Validation loss: 2.5128508271475

Epoch: 5| Step: 7
Training loss: 0.6724170006794403
Validation loss: 2.4011465588963334

Epoch: 5| Step: 8
Training loss: 0.8306798212748249
Validation loss: 2.482770253568849

Epoch: 5| Step: 9
Training loss: 0.5708069682703745
Validation loss: 2.4133004402343605

Epoch: 5| Step: 10
Training loss: 0.8294401342462097
Validation loss: 2.4775994954690983

Epoch: 5| Step: 11
Training loss: 0.7008592764157311
Validation loss: 2.455395698492358

Epoch: 149| Step: 0
Training loss: 0.5234829612462121
Validation loss: 2.515189265390555

Epoch: 5| Step: 1
Training loss: 0.7676183093086422
Validation loss: 2.471254058648679

Epoch: 5| Step: 2
Training loss: 0.6053695597462265
Validation loss: 2.563590395383054

Epoch: 5| Step: 3
Training loss: 0.7347867501287877
Validation loss: 2.4917066024420693

Epoch: 5| Step: 4
Training loss: 0.6974353102967481
Validation loss: 2.5047795423768284

Epoch: 5| Step: 5
Training loss: 0.6309247056892883
Validation loss: 2.5218017008109785

Epoch: 5| Step: 6
Training loss: 0.7853366777346673
Validation loss: 2.483077172107514

Epoch: 5| Step: 7
Training loss: 0.9183201543366566
Validation loss: 2.5260846294931274

Epoch: 5| Step: 8
Training loss: 1.1783977809980934
Validation loss: 2.481815447144458

Epoch: 5| Step: 9
Training loss: 0.7401096772416715
Validation loss: 2.491148908643654

Epoch: 5| Step: 10
Training loss: 0.8022053035459006
Validation loss: 2.490716745369199

Epoch: 5| Step: 11
Training loss: 0.6758529095885601
Validation loss: 2.5123631613272295

Epoch: 150| Step: 0
Training loss: 0.8378753660719964
Validation loss: 2.5096881503208546

Epoch: 5| Step: 1
Training loss: 0.6510272876423179
Validation loss: 2.5029360537547873

Epoch: 5| Step: 2
Training loss: 0.9126085634840099
Validation loss: 2.488086840562062

Epoch: 5| Step: 3
Training loss: 1.0696849236107664
Validation loss: 2.458507605749539

Epoch: 5| Step: 4
Training loss: 0.7280959487817003
Validation loss: 2.442020884138816

Epoch: 5| Step: 5
Training loss: 0.6097345269708415
Validation loss: 2.4438015247809184

Epoch: 5| Step: 6
Training loss: 0.7325706229161899
Validation loss: 2.5190754559487427

Epoch: 5| Step: 7
Training loss: 1.2617493616884423
Validation loss: 2.5130198556110805

Epoch: 5| Step: 8
Training loss: 0.6530322479022825
Validation loss: 2.486411557492058

Epoch: 5| Step: 9
Training loss: 0.608161819025577
Validation loss: 2.4498575646004688

Epoch: 5| Step: 10
Training loss: 0.5465259528005081
Validation loss: 2.588673234559974

Epoch: 5| Step: 11
Training loss: 0.7628661683552859
Validation loss: 2.5520255036841055

Epoch: 151| Step: 0
Training loss: 0.5469164696365196
Validation loss: 2.501828784418887

Epoch: 5| Step: 1
Training loss: 0.8495035390594928
Validation loss: 2.4614658373894414

Epoch: 5| Step: 2
Training loss: 0.5250011830089502
Validation loss: 2.3934919415740645

Epoch: 5| Step: 3
Training loss: 1.1294215521113704
Validation loss: 2.4758497008610063

Epoch: 5| Step: 4
Training loss: 0.9156644428597872
Validation loss: 2.4114001715438538

Epoch: 5| Step: 5
Training loss: 0.5617298576095031
Validation loss: 2.5451792979332177

Epoch: 5| Step: 6
Training loss: 0.4971936116061724
Validation loss: 2.501926867674586

Epoch: 5| Step: 7
Training loss: 0.6187263330114076
Validation loss: 2.471623635482302

Epoch: 5| Step: 8
Training loss: 0.7369020689052239
Validation loss: 2.568217796997286

Epoch: 5| Step: 9
Training loss: 0.5809490716940084
Validation loss: 2.5380035383101123

Epoch: 5| Step: 10
Training loss: 0.9679395608141707
Validation loss: 2.5721853191070028

Epoch: 5| Step: 11
Training loss: 0.9142379918320371
Validation loss: 2.5533217027111283

Epoch: 152| Step: 0
Training loss: 0.6217881165966147
Validation loss: 2.5368339892262632

Epoch: 5| Step: 1
Training loss: 0.4773825484520822
Validation loss: 2.4352273168016194

Epoch: 5| Step: 2
Training loss: 1.146095690891362
Validation loss: 2.448740229487339

Epoch: 5| Step: 3
Training loss: 0.6301604612679371
Validation loss: 2.4061932020378514

Epoch: 5| Step: 4
Training loss: 0.9175619969223365
Validation loss: 2.4728312337548113

Epoch: 5| Step: 5
Training loss: 0.747524626973673
Validation loss: 2.46557067614632

Epoch: 5| Step: 6
Training loss: 0.6722527484447491
Validation loss: 2.4083181798737594

Epoch: 5| Step: 7
Training loss: 0.4422477532842399
Validation loss: 2.4568115766903413

Epoch: 5| Step: 8
Training loss: 0.9875610501696566
Validation loss: 2.484483240676625

Epoch: 5| Step: 9
Training loss: 0.8097547958246137
Validation loss: 2.456999826558839

Epoch: 5| Step: 10
Training loss: 0.7438915166134995
Validation loss: 2.4865872312284876

Epoch: 5| Step: 11
Training loss: 0.34092975160096434
Validation loss: 2.4487885741784585

Epoch: 153| Step: 0
Training loss: 0.979860702365568
Validation loss: 2.519597733283357

Epoch: 5| Step: 1
Training loss: 0.3548231445269362
Validation loss: 2.453080717525372

Epoch: 5| Step: 2
Training loss: 0.9177309742854233
Validation loss: 2.4811666993540293

Epoch: 5| Step: 3
Training loss: 0.4171534099295002
Validation loss: 2.5292664318633733

Epoch: 5| Step: 4
Training loss: 0.642335306686032
Validation loss: 2.4246182154285383

Epoch: 5| Step: 5
Training loss: 0.847401277367928
Validation loss: 2.4695179867410904

Epoch: 5| Step: 6
Training loss: 0.5333743536591888
Validation loss: 2.423371127703818

Epoch: 5| Step: 7
Training loss: 0.5904809150341067
Validation loss: 2.443313545348152

Epoch: 5| Step: 8
Training loss: 0.5747868588605869
Validation loss: 2.4558332359832584

Epoch: 5| Step: 9
Training loss: 0.6774891786309342
Validation loss: 2.3772515031557955

Epoch: 5| Step: 10
Training loss: 0.46523910827535025
Validation loss: 2.4773074131881883

Epoch: 5| Step: 11
Training loss: 2.435367140145363
Validation loss: 2.499262367146962

Epoch: 154| Step: 0
Training loss: 0.6494806470652709
Validation loss: 2.54932485443997

Epoch: 5| Step: 1
Training loss: 0.6270139432981182
Validation loss: 2.504186228761945

Epoch: 5| Step: 2
Training loss: 0.5601345233614172
Validation loss: 2.5400760720781013

Epoch: 5| Step: 3
Training loss: 0.7963035628958975
Validation loss: 2.566300907227773

Epoch: 5| Step: 4
Training loss: 0.6488385166941383
Validation loss: 2.555104873891235

Epoch: 5| Step: 5
Training loss: 1.1542186936496852
Validation loss: 2.521996073631046

Epoch: 5| Step: 6
Training loss: 0.7301211422513155
Validation loss: 2.479871791184083

Epoch: 5| Step: 7
Training loss: 0.7918125988491008
Validation loss: 2.50417435153495

Epoch: 5| Step: 8
Training loss: 0.6655268735597087
Validation loss: 2.5565742618116305

Epoch: 5| Step: 9
Training loss: 0.601894410950303
Validation loss: 2.5031341338258897

Epoch: 5| Step: 10
Training loss: 0.6671806728183473
Validation loss: 2.4783229246949237

Epoch: 5| Step: 11
Training loss: 1.6055079545851925
Validation loss: 2.5533449609726606

Epoch: 155| Step: 0
Training loss: 0.6907810034985503
Validation loss: 2.5750762097954256

Epoch: 5| Step: 1
Training loss: 0.507008899730994
Validation loss: 2.62000248909485

Epoch: 5| Step: 2
Training loss: 0.6444500033871458
Validation loss: 2.5557765525362224

Epoch: 5| Step: 3
Training loss: 0.4064358139577988
Validation loss: 2.5506661989398887

Epoch: 5| Step: 4
Training loss: 0.6161086636894918
Validation loss: 2.4763716294214975

Epoch: 5| Step: 5
Training loss: 0.4737157690016203
Validation loss: 2.4675373447018116

Epoch: 5| Step: 6
Training loss: 1.3910913864024825
Validation loss: 2.5064907571921626

Epoch: 5| Step: 7
Training loss: 0.7261707931764947
Validation loss: 2.4838964333233973

Epoch: 5| Step: 8
Training loss: 0.6808060835852271
Validation loss: 2.4906007783893402

Epoch: 5| Step: 9
Training loss: 0.5100538819964738
Validation loss: 2.547999315228812

Epoch: 5| Step: 10
Training loss: 0.6512390651260788
Validation loss: 2.545549355842585

Epoch: 5| Step: 11
Training loss: 0.5409123842082297
Validation loss: 2.4634165392679996

Epoch: 156| Step: 0
Training loss: 0.4696476289091278
Validation loss: 2.5004595930125735

Epoch: 5| Step: 1
Training loss: 0.7207893795511745
Validation loss: 2.4430693106860164

Epoch: 5| Step: 2
Training loss: 0.6842227548715936
Validation loss: 2.4816375261644987

Epoch: 5| Step: 3
Training loss: 0.6352562284903629
Validation loss: 2.468183223030863

Epoch: 5| Step: 4
Training loss: 1.1726432316697277
Validation loss: 2.472315390637423

Epoch: 5| Step: 5
Training loss: 0.78609505319838
Validation loss: 2.483483548442873

Epoch: 5| Step: 6
Training loss: 0.48019371844853864
Validation loss: 2.5295194982011076

Epoch: 5| Step: 7
Training loss: 0.9595938802535107
Validation loss: 2.590140121019153

Epoch: 5| Step: 8
Training loss: 0.6835070309811043
Validation loss: 2.568003420222907

Epoch: 5| Step: 9
Training loss: 0.7938492870560426
Validation loss: 2.5480638549369923

Epoch: 5| Step: 10
Training loss: 0.4589407392821556
Validation loss: 2.536631781243777

Epoch: 5| Step: 11
Training loss: 0.6977196078349663
Validation loss: 2.4945968174881896

Epoch: 157| Step: 0
Training loss: 0.806053890360056
Validation loss: 2.474566697392701

Epoch: 5| Step: 1
Training loss: 0.5656234857106882
Validation loss: 2.499953803986663

Epoch: 5| Step: 2
Training loss: 0.6258289799960011
Validation loss: 2.543983182911999

Epoch: 5| Step: 3
Training loss: 0.7297051666538987
Validation loss: 2.470979424307465

Epoch: 5| Step: 4
Training loss: 0.7555571353496915
Validation loss: 2.4642772396342085

Epoch: 5| Step: 5
Training loss: 0.6797092039655
Validation loss: 2.4476043413999373

Epoch: 5| Step: 6
Training loss: 0.5683164809777773
Validation loss: 2.4872000205088343

Epoch: 5| Step: 7
Training loss: 0.6315069034649109
Validation loss: 2.5015241705368307

Epoch: 5| Step: 8
Training loss: 0.5290772661648429
Validation loss: 2.490513481505719

Epoch: 5| Step: 9
Training loss: 0.5097686065937409
Validation loss: 2.5018708599938444

Epoch: 5| Step: 10
Training loss: 1.1820750549227326
Validation loss: 2.500689280379055

Epoch: 5| Step: 11
Training loss: 0.2827153181161014
Validation loss: 2.479664601615073

Epoch: 158| Step: 0
Training loss: 0.49359539544923203
Validation loss: 2.4688629977606142

Epoch: 5| Step: 1
Training loss: 0.6906469885316172
Validation loss: 2.5899622733266305

Epoch: 5| Step: 2
Training loss: 0.5629542424018479
Validation loss: 2.454583445188379

Epoch: 5| Step: 3
Training loss: 0.9005759621479095
Validation loss: 2.480160663525267

Epoch: 5| Step: 4
Training loss: 0.5508877806750893
Validation loss: 2.494355696543969

Epoch: 5| Step: 5
Training loss: 0.4695596378523017
Validation loss: 2.4785515311916653

Epoch: 5| Step: 6
Training loss: 1.142648443682846
Validation loss: 2.4913601473600546

Epoch: 5| Step: 7
Training loss: 0.38894438655076813
Validation loss: 2.5146844697117614

Epoch: 5| Step: 8
Training loss: 0.81149747327269
Validation loss: 2.544183689890975

Epoch: 5| Step: 9
Training loss: 0.6618753205209448
Validation loss: 2.522715797008987

Epoch: 5| Step: 10
Training loss: 0.568521483069933
Validation loss: 2.5623021165689637

Epoch: 5| Step: 11
Training loss: 0.29465949152976845
Validation loss: 2.5158516977178413

Epoch: 159| Step: 0
Training loss: 1.1892788262906255
Validation loss: 2.49181530404391

Epoch: 5| Step: 1
Training loss: 0.6289482813467084
Validation loss: 2.546874348615005

Epoch: 5| Step: 2
Training loss: 0.5710957517993249
Validation loss: 2.4602370218904337

Epoch: 5| Step: 3
Training loss: 0.6846367862223879
Validation loss: 2.5197706872687773

Epoch: 5| Step: 4
Training loss: 0.6604005936994258
Validation loss: 2.493068909911856

Epoch: 5| Step: 5
Training loss: 0.6007651953170451
Validation loss: 2.5079315648479064

Epoch: 5| Step: 6
Training loss: 0.5467426139810584
Validation loss: 2.503025969420756

Epoch: 5| Step: 7
Training loss: 0.44210478275203957
Validation loss: 2.59651727396817

Epoch: 5| Step: 8
Training loss: 0.6027477527451521
Validation loss: 2.540710274491857

Epoch: 5| Step: 9
Training loss: 0.4793176274987243
Validation loss: 2.4809761189276616

Epoch: 5| Step: 10
Training loss: 0.6544620362397223
Validation loss: 2.4635279912481667

Epoch: 5| Step: 11
Training loss: 1.3326236157218228
Validation loss: 2.5385739604746576

Epoch: 160| Step: 0
Training loss: 0.7135223098319773
Validation loss: 2.4765124631814945

Epoch: 5| Step: 1
Training loss: 0.7237082582338609
Validation loss: 2.498902475327212

Epoch: 5| Step: 2
Training loss: 0.5092394221260185
Validation loss: 2.515967335913992

Epoch: 5| Step: 3
Training loss: 0.6030939351121146
Validation loss: 2.5355475759968065

Epoch: 5| Step: 4
Training loss: 0.5575287276080999
Validation loss: 2.4743462000853254

Epoch: 5| Step: 5
Training loss: 0.8577290117391626
Validation loss: 2.533993490112652

Epoch: 5| Step: 6
Training loss: 0.6262986519469058
Validation loss: 2.5674149047037567

Epoch: 5| Step: 7
Training loss: 0.42054053576583283
Validation loss: 2.461686174860573

Epoch: 5| Step: 8
Training loss: 0.41083936571111995
Validation loss: 2.493670832302318

Epoch: 5| Step: 9
Training loss: 1.0898802282866649
Validation loss: 2.541320940773499

Epoch: 5| Step: 10
Training loss: 0.6751269662620418
Validation loss: 2.5228805714762306

Epoch: 5| Step: 11
Training loss: 0.41154522722707265
Validation loss: 2.4816807346594274

Epoch: 161| Step: 0
Training loss: 0.39450058015265793
Validation loss: 2.618225237330765

Epoch: 5| Step: 1
Training loss: 0.5989908762397778
Validation loss: 2.5195048683224446

Epoch: 5| Step: 2
Training loss: 0.47440357220211027
Validation loss: 2.5291718205352844

Epoch: 5| Step: 3
Training loss: 0.6990173092296617
Validation loss: 2.5820387370298703

Epoch: 5| Step: 4
Training loss: 0.4943341867452823
Validation loss: 2.524666454455529

Epoch: 5| Step: 5
Training loss: 0.7188755008760106
Validation loss: 2.5486869003126937

Epoch: 5| Step: 6
Training loss: 0.8416550377398067
Validation loss: 2.4477608299702807

Epoch: 5| Step: 7
Training loss: 0.616426070635591
Validation loss: 2.5142073971040393

Epoch: 5| Step: 8
Training loss: 1.1034781930702038
Validation loss: 2.5175167043694264

Epoch: 5| Step: 9
Training loss: 0.5084880736648774
Validation loss: 2.5047914742417334

Epoch: 5| Step: 10
Training loss: 0.5537556625145582
Validation loss: 2.5176255660893183

Epoch: 5| Step: 11
Training loss: 0.7068772965047349
Validation loss: 2.4822410839805746

Epoch: 162| Step: 0
Training loss: 0.6387751317912302
Validation loss: 2.4968026556930067

Epoch: 5| Step: 1
Training loss: 0.6081652002877082
Validation loss: 2.5913672130589718

Epoch: 5| Step: 2
Training loss: 1.131146804570742
Validation loss: 2.460957633042103

Epoch: 5| Step: 3
Training loss: 0.45297743597844653
Validation loss: 2.5301777016575993

Epoch: 5| Step: 4
Training loss: 0.39216772614741385
Validation loss: 2.514464618174004

Epoch: 5| Step: 5
Training loss: 0.713132968627379
Validation loss: 2.4436752517663693

Epoch: 5| Step: 6
Training loss: 0.4743466690207886
Validation loss: 2.469797081353473

Epoch: 5| Step: 7
Training loss: 0.5794245830581956
Validation loss: 2.488147562329211

Epoch: 5| Step: 8
Training loss: 0.7147085760334072
Validation loss: 2.5044192593507084

Epoch: 5| Step: 9
Training loss: 0.8974850125243546
Validation loss: 2.4988855361405955

Epoch: 5| Step: 10
Training loss: 0.5621081682925232
Validation loss: 2.480979806712523

Epoch: 5| Step: 11
Training loss: 0.5065013096896954
Validation loss: 2.5550269155148406

Epoch: 163| Step: 0
Training loss: 0.5406949576830454
Validation loss: 2.5343902813991264

Epoch: 5| Step: 1
Training loss: 0.8810733780498874
Validation loss: 2.497698384012016

Epoch: 5| Step: 2
Training loss: 0.6906385739748835
Validation loss: 2.5668340991160883

Epoch: 5| Step: 3
Training loss: 0.6600534483190804
Validation loss: 2.5067142010702415

Epoch: 5| Step: 4
Training loss: 0.5594366955964979
Validation loss: 2.473835491677636

Epoch: 5| Step: 5
Training loss: 0.6491049353475246
Validation loss: 2.436436486333129

Epoch: 5| Step: 6
Training loss: 0.5199443637446672
Validation loss: 2.3962824911834346

Epoch: 5| Step: 7
Training loss: 0.704273091875741
Validation loss: 2.4929402648516166

Epoch: 5| Step: 8
Training loss: 0.3980971359850371
Validation loss: 2.4579160155598156

Epoch: 5| Step: 9
Training loss: 1.1339191687401122
Validation loss: 2.525840103654672

Epoch: 5| Step: 10
Training loss: 0.5609169512626951
Validation loss: 2.506810630885586

Epoch: 5| Step: 11
Training loss: 0.5203184030100613
Validation loss: 2.5877487853904255

Epoch: 164| Step: 0
Training loss: 0.5691010136064569
Validation loss: 2.597736584943707

Epoch: 5| Step: 1
Training loss: 0.542454290573855
Validation loss: 2.585121690694543

Epoch: 5| Step: 2
Training loss: 1.08722829603477
Validation loss: 2.6097195373098616

Epoch: 5| Step: 3
Training loss: 0.8464001608846616
Validation loss: 2.5455642244754824

Epoch: 5| Step: 4
Training loss: 0.6674774772616076
Validation loss: 2.4960287440854088

Epoch: 5| Step: 5
Training loss: 0.5615139371648772
Validation loss: 2.5303646587975916

Epoch: 5| Step: 6
Training loss: 0.5979321908652304
Validation loss: 2.4983180229242965

Epoch: 5| Step: 7
Training loss: 0.3846774314845671
Validation loss: 2.538879726384916

Epoch: 5| Step: 8
Training loss: 0.4855228942939749
Validation loss: 2.5298731457938306

Epoch: 5| Step: 9
Training loss: 0.669700007497643
Validation loss: 2.5869725241030825

Epoch: 5| Step: 10
Training loss: 0.4754090342409107
Validation loss: 2.5298779697666856

Epoch: 5| Step: 11
Training loss: 0.8171628886322296
Validation loss: 2.5630969616015955

Epoch: 165| Step: 0
Training loss: 0.381504900722099
Validation loss: 2.560029715487255

Epoch: 5| Step: 1
Training loss: 0.31778282193873514
Validation loss: 2.60436332468715

Epoch: 5| Step: 2
Training loss: 0.5016427175005604
Validation loss: 2.5888708942722074

Epoch: 5| Step: 3
Training loss: 0.6479013363495434
Validation loss: 2.5503160248133625

Epoch: 5| Step: 4
Training loss: 0.5975495286787892
Validation loss: 2.5413952328145775

Epoch: 5| Step: 5
Training loss: 0.47213623508298974
Validation loss: 2.514893123240403

Epoch: 5| Step: 6
Training loss: 1.1572677669352098
Validation loss: 2.509027248275405

Epoch: 5| Step: 7
Training loss: 0.9176212708262712
Validation loss: 2.531736911833395

Epoch: 5| Step: 8
Training loss: 0.4864967850376003
Validation loss: 2.560125937586519

Epoch: 5| Step: 9
Training loss: 0.5571510517824213
Validation loss: 2.605357581897772

Epoch: 5| Step: 10
Training loss: 0.7890028978253467
Validation loss: 2.5616426119009

Epoch: 5| Step: 11
Training loss: 0.7507994285391297
Validation loss: 2.5632917336332186

Epoch: 166| Step: 0
Training loss: 0.5573548402958163
Validation loss: 2.5804362793266455

Epoch: 5| Step: 1
Training loss: 0.29603883037689416
Validation loss: 2.546192315624428

Epoch: 5| Step: 2
Training loss: 0.5024739098299676
Validation loss: 2.611485573761332

Epoch: 5| Step: 3
Training loss: 0.5684685094343315
Validation loss: 2.52736379820838

Epoch: 5| Step: 4
Training loss: 1.008125079273805
Validation loss: 2.481078525995154

Epoch: 5| Step: 5
Training loss: 0.5756427210048477
Validation loss: 2.612150490271168

Epoch: 5| Step: 6
Training loss: 0.4983614956298909
Validation loss: 2.5096990791731026

Epoch: 5| Step: 7
Training loss: 0.4567034434240725
Validation loss: 2.545537706734875

Epoch: 5| Step: 8
Training loss: 0.6565794798858209
Validation loss: 2.5261209586896087

Epoch: 5| Step: 9
Training loss: 0.4884159665233152
Validation loss: 2.5086217626233047

Epoch: 5| Step: 10
Training loss: 0.7448884505408071
Validation loss: 2.552069855998258

Epoch: 5| Step: 11
Training loss: 0.2698496720592463
Validation loss: 2.5201809008604426

Epoch: 167| Step: 0
Training loss: 0.4847898552531111
Validation loss: 2.5351640635538017

Epoch: 5| Step: 1
Training loss: 0.631823461489015
Validation loss: 2.561684040479331

Epoch: 5| Step: 2
Training loss: 0.5192827476529913
Validation loss: 2.5310204935618223

Epoch: 5| Step: 3
Training loss: 0.7850389155685606
Validation loss: 2.4892756353084207

Epoch: 5| Step: 4
Training loss: 0.36173452256421185
Validation loss: 2.489817587686399

Epoch: 5| Step: 5
Training loss: 0.5223809011600242
Validation loss: 2.482276077851205

Epoch: 5| Step: 6
Training loss: 0.9384733233758162
Validation loss: 2.570262290054491

Epoch: 5| Step: 7
Training loss: 0.5630425379895589
Validation loss: 2.5318561699401743

Epoch: 5| Step: 8
Training loss: 0.5746824766502693
Validation loss: 2.567676533675579

Epoch: 5| Step: 9
Training loss: 0.5113841994322271
Validation loss: 2.4837175894972647

Epoch: 5| Step: 10
Training loss: 0.44787772327247805
Validation loss: 2.590765461566927

Epoch: 5| Step: 11
Training loss: 0.6026188381808203
Validation loss: 2.5408443400039395

Epoch: 168| Step: 0
Training loss: 0.3800335464916318
Validation loss: 2.5989709878026064

Epoch: 5| Step: 1
Training loss: 0.4167173672664946
Validation loss: 2.5737989890932726

Epoch: 5| Step: 2
Training loss: 0.6176285194137657
Validation loss: 2.461149830211022

Epoch: 5| Step: 3
Training loss: 0.95015124447167
Validation loss: 2.5284253281931455

Epoch: 5| Step: 4
Training loss: 0.5289861182084247
Validation loss: 2.5685035539391716

Epoch: 5| Step: 5
Training loss: 0.4329319964544095
Validation loss: 2.500905572275206

Epoch: 5| Step: 6
Training loss: 0.5447462612459715
Validation loss: 2.5579911976049656

Epoch: 5| Step: 7
Training loss: 0.4186218008543914
Validation loss: 2.566059354255702

Epoch: 5| Step: 8
Training loss: 0.5952516940243779
Validation loss: 2.578008128898418

Epoch: 5| Step: 9
Training loss: 0.47720848139794414
Validation loss: 2.5850690630031554

Epoch: 5| Step: 10
Training loss: 0.7141036491307216
Validation loss: 2.5050061012747062

Epoch: 5| Step: 11
Training loss: 0.5194013906538116
Validation loss: 2.5883184652726383

Epoch: 169| Step: 0
Training loss: 0.44707599934585335
Validation loss: 2.607610307568735

Epoch: 5| Step: 1
Training loss: 0.5536220149469853
Validation loss: 2.5422456790555863

Epoch: 5| Step: 2
Training loss: 0.5376190818792603
Validation loss: 2.4645327791546907

Epoch: 5| Step: 3
Training loss: 0.5832778586394552
Validation loss: 2.5213460276082995

Epoch: 5| Step: 4
Training loss: 0.6168908480663654
Validation loss: 2.5302501104671626

Epoch: 5| Step: 5
Training loss: 0.47739692241997556
Validation loss: 2.500912412401377

Epoch: 5| Step: 6
Training loss: 1.0692362142249006
Validation loss: 2.6114719515793974

Epoch: 5| Step: 7
Training loss: 0.5426602482009988
Validation loss: 2.527438264678319

Epoch: 5| Step: 8
Training loss: 0.7873070707595021
Validation loss: 2.5803029773116486

Epoch: 5| Step: 9
Training loss: 0.6048529415866047
Validation loss: 2.604252323013495

Epoch: 5| Step: 10
Training loss: 0.4951304748076453
Validation loss: 2.5662284201098524

Epoch: 5| Step: 11
Training loss: 0.4159620008697023
Validation loss: 2.506895965384521

Epoch: 170| Step: 0
Training loss: 0.5163573930167693
Validation loss: 2.5186510347434394

Epoch: 5| Step: 1
Training loss: 0.5029590190741304
Validation loss: 2.5841224731542196

Epoch: 5| Step: 2
Training loss: 0.727965773825898
Validation loss: 2.4906712008043748

Epoch: 5| Step: 3
Training loss: 0.4520709504864894
Validation loss: 2.5167055988037235

Epoch: 5| Step: 4
Training loss: 0.4463226672986844
Validation loss: 2.509623118509611

Epoch: 5| Step: 5
Training loss: 0.5869297273040165
Validation loss: 2.5410092173169856

Epoch: 5| Step: 6
Training loss: 0.4777698388274859
Validation loss: 2.5572066490403946

Epoch: 5| Step: 7
Training loss: 1.0207119824170796
Validation loss: 2.5411540997222115

Epoch: 5| Step: 8
Training loss: 0.5290520020652811
Validation loss: 2.5475322873768267

Epoch: 5| Step: 9
Training loss: 0.35798667100249415
Validation loss: 2.5705027215170673

Epoch: 5| Step: 10
Training loss: 0.7136197894319257
Validation loss: 2.50931621243541

Epoch: 5| Step: 11
Training loss: 0.5835802600123642
Validation loss: 2.5349170393664537

Epoch: 171| Step: 0
Training loss: 0.5718313919700787
Validation loss: 2.539669007464434

Epoch: 5| Step: 1
Training loss: 0.529884378309288
Validation loss: 2.4639650865423937

Epoch: 5| Step: 2
Training loss: 0.5391941186302575
Validation loss: 2.5629791920460123

Epoch: 5| Step: 3
Training loss: 0.43901667644264714
Validation loss: 2.5193240176592493

Epoch: 5| Step: 4
Training loss: 0.39766232499014537
Validation loss: 2.4586353190604693

Epoch: 5| Step: 5
Training loss: 0.7296133489732346
Validation loss: 2.457704925769723

Epoch: 5| Step: 6
Training loss: 0.609636690729682
Validation loss: 2.4974840895750896

Epoch: 5| Step: 7
Training loss: 0.5586314155310941
Validation loss: 2.447534167389267

Epoch: 5| Step: 8
Training loss: 0.2627667751746426
Validation loss: 2.5427738472451593

Epoch: 5| Step: 9
Training loss: 0.9842539516076062
Validation loss: 2.5387776259023154

Epoch: 5| Step: 10
Training loss: 0.48680849365415535
Validation loss: 2.6382898543103357

Epoch: 5| Step: 11
Training loss: 0.4622232156640594
Validation loss: 2.547125314530572

Epoch: 172| Step: 0
Training loss: 0.39919370061294124
Validation loss: 2.5574289208668546

Epoch: 5| Step: 1
Training loss: 0.6160664577954921
Validation loss: 2.557002897461836

Epoch: 5| Step: 2
Training loss: 0.886817792158973
Validation loss: 2.528424424529866

Epoch: 5| Step: 3
Training loss: 0.6573214866253831
Validation loss: 2.551150514786497

Epoch: 5| Step: 4
Training loss: 0.36663951971967346
Validation loss: 2.56972588567166

Epoch: 5| Step: 5
Training loss: 0.38251756478165233
Validation loss: 2.5533885550524253

Epoch: 5| Step: 6
Training loss: 0.5053457649997082
Validation loss: 2.5454004988690517

Epoch: 5| Step: 7
Training loss: 0.5100359437468371
Validation loss: 2.5865942667467214

Epoch: 5| Step: 8
Training loss: 0.6079197158981033
Validation loss: 2.4699601012326626

Epoch: 5| Step: 9
Training loss: 0.5513065889943528
Validation loss: 2.4784314657582036

Epoch: 5| Step: 10
Training loss: 0.5561250674933
Validation loss: 2.5496538347229403

Epoch: 5| Step: 11
Training loss: 0.48623368292253955
Validation loss: 2.5495626080697145

Epoch: 173| Step: 0
Training loss: 0.9171719928320846
Validation loss: 2.553052491785251

Epoch: 5| Step: 1
Training loss: 0.5240602631768547
Validation loss: 2.5237371268785656

Epoch: 5| Step: 2
Training loss: 0.4982739697484036
Validation loss: 2.6151598235280993

Epoch: 5| Step: 3
Training loss: 0.4002159295791775
Validation loss: 2.5864500553911727

Epoch: 5| Step: 4
Training loss: 0.5087207008754175
Validation loss: 2.6062839687277415

Epoch: 5| Step: 5
Training loss: 0.49086567327188696
Validation loss: 2.551603674415263

Epoch: 5| Step: 6
Training loss: 0.3968878135715236
Validation loss: 2.551432654414922

Epoch: 5| Step: 7
Training loss: 0.6898291969708323
Validation loss: 2.5116841940235566

Epoch: 5| Step: 8
Training loss: 0.411014132008454
Validation loss: 2.5428731991209683

Epoch: 5| Step: 9
Training loss: 0.5301138565738016
Validation loss: 2.5224196208740923

Epoch: 5| Step: 10
Training loss: 0.581369189890944
Validation loss: 2.505236731914837

Epoch: 5| Step: 11
Training loss: 0.38879668565679665
Validation loss: 2.5826277628127263

Epoch: 174| Step: 0
Training loss: 0.6421560043073854
Validation loss: 2.5982479253397446

Epoch: 5| Step: 1
Training loss: 0.6503923891518985
Validation loss: 2.5862901491343226

Epoch: 5| Step: 2
Training loss: 0.4793437098570181
Validation loss: 2.5995958740128358

Epoch: 5| Step: 3
Training loss: 0.5777502649687123
Validation loss: 2.4680124420455716

Epoch: 5| Step: 4
Training loss: 0.4246780031221663
Validation loss: 2.50820946250265

Epoch: 5| Step: 5
Training loss: 0.9659842727083781
Validation loss: 2.5144836055719013

Epoch: 5| Step: 6
Training loss: 0.3619374473003915
Validation loss: 2.5084079063351856

Epoch: 5| Step: 7
Training loss: 0.47418851991732053
Validation loss: 2.5189430595096627

Epoch: 5| Step: 8
Training loss: 0.7430100550837562
Validation loss: 2.52710573194871

Epoch: 5| Step: 9
Training loss: 0.7169823679385382
Validation loss: 2.5426683810068593

Epoch: 5| Step: 10
Training loss: 0.47685998480519803
Validation loss: 2.549248418344045

Epoch: 5| Step: 11
Training loss: 0.6629934794218951
Validation loss: 2.4847195704245615

Epoch: 175| Step: 0
Training loss: 0.4361522555768622
Validation loss: 2.4898586652979486

Epoch: 5| Step: 1
Training loss: 0.45685968683883765
Validation loss: 2.4975180186645356

Epoch: 5| Step: 2
Training loss: 0.7325889295163853
Validation loss: 2.5641921589249215

Epoch: 5| Step: 3
Training loss: 0.496357975078221
Validation loss: 2.486681948705185

Epoch: 5| Step: 4
Training loss: 0.592674008220812
Validation loss: 2.554707051706887

Epoch: 5| Step: 5
Training loss: 0.5038312516105837
Validation loss: 2.6179072818429017

Epoch: 5| Step: 6
Training loss: 0.8226142923318738
Validation loss: 2.64129618855723

Epoch: 5| Step: 7
Training loss: 1.0325612488284133
Validation loss: 2.54135265651497

Epoch: 5| Step: 8
Training loss: 0.44631754243825733
Validation loss: 2.5495472016704124

Epoch: 5| Step: 9
Training loss: 0.6660440388544687
Validation loss: 2.5950096396142848

Epoch: 5| Step: 10
Training loss: 0.5788930482169883
Validation loss: 2.5625048924221074

Epoch: 5| Step: 11
Training loss: 0.36158809073446047
Validation loss: 2.552949273214739

Testing loss: 2.47831294474146
