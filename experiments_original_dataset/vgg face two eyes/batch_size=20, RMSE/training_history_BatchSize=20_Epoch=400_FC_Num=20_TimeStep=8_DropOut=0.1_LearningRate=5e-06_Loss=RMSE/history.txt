Epoch: 1| Step: 0
Training loss: 6.166178641038802
Validation loss: 5.3047711942097635

Epoch: 5| Step: 1
Training loss: 4.947200854540476
Validation loss: 5.269894417025398

Epoch: 5| Step: 2
Training loss: 5.2996924904917275
Validation loss: 5.234718706224209

Epoch: 5| Step: 3
Training loss: 5.341461941053648
Validation loss: 5.207224509145777

Epoch: 5| Step: 4
Training loss: 5.463952101524044
Validation loss: 5.177356937887268

Epoch: 5| Step: 5
Training loss: 5.50964065404621
Validation loss: 5.1473349595194335

Epoch: 5| Step: 6
Training loss: 5.777197825024919
Validation loss: 5.117616933416287

Epoch: 5| Step: 7
Training loss: 5.776227099025083
Validation loss: 5.089810218807932

Epoch: 5| Step: 8
Training loss: 4.6696874287657675
Validation loss: 5.060281997633022

Epoch: 5| Step: 9
Training loss: 4.798887147645271
Validation loss: 5.025787231119168

Epoch: 5| Step: 10
Training loss: 4.430855302759193
Validation loss: 5.0003426752283975

Epoch: 5| Step: 11
Training loss: 2.871065848078707
Validation loss: 4.970509423539425

Epoch: 2| Step: 0
Training loss: 4.731808612051935
Validation loss: 4.940312666876011

Epoch: 5| Step: 1
Training loss: 5.17214734607935
Validation loss: 4.911182807106069

Epoch: 5| Step: 2
Training loss: 4.8874801908516
Validation loss: 4.88068008449735

Epoch: 5| Step: 3
Training loss: 4.271991603685907
Validation loss: 4.848784531354564

Epoch: 5| Step: 4
Training loss: 5.645005656966829
Validation loss: 4.812610203855951

Epoch: 5| Step: 5
Training loss: 4.808206203285228
Validation loss: 4.7768759156603515

Epoch: 5| Step: 6
Training loss: 5.110510090490945
Validation loss: 4.740041575095243

Epoch: 5| Step: 7
Training loss: 4.571194868415086
Validation loss: 4.703894880612943

Epoch: 5| Step: 8
Training loss: 4.823597189209522
Validation loss: 4.6669481510464275

Epoch: 5| Step: 9
Training loss: 5.0683595631623275
Validation loss: 4.629230115589014

Epoch: 5| Step: 10
Training loss: 4.642582233380597
Validation loss: 4.584379023416042

Epoch: 5| Step: 11
Training loss: 4.176081105127922
Validation loss: 4.53804819370327

Epoch: 3| Step: 0
Training loss: 4.418805138488086
Validation loss: 4.499199292683512

Epoch: 5| Step: 1
Training loss: 5.076608848184085
Validation loss: 4.45259895117655

Epoch: 5| Step: 2
Training loss: 4.253471303234736
Validation loss: 4.403093257850102

Epoch: 5| Step: 3
Training loss: 5.066993508755802
Validation loss: 4.357357009274942

Epoch: 5| Step: 4
Training loss: 4.975909754704449
Validation loss: 4.303166041551322

Epoch: 5| Step: 5
Training loss: 4.099391398966308
Validation loss: 4.24902129123908

Epoch: 5| Step: 6
Training loss: 3.6764148972725055
Validation loss: 4.1932808700341315

Epoch: 5| Step: 7
Training loss: 3.686846529716039
Validation loss: 4.1348906918415365

Epoch: 5| Step: 8
Training loss: 4.727118139473671
Validation loss: 4.08142137854054

Epoch: 5| Step: 9
Training loss: 4.364328721418522
Validation loss: 4.01306649721947

Epoch: 5| Step: 10
Training loss: 3.1891639704543784
Validation loss: 3.95390115187479

Epoch: 5| Step: 11
Training loss: 2.9873230438815717
Validation loss: 3.8835240664459407

Epoch: 4| Step: 0
Training loss: 3.9855195439818667
Validation loss: 3.818305436815992

Epoch: 5| Step: 1
Training loss: 3.475922051919886
Validation loss: 3.7465885645700348

Epoch: 5| Step: 2
Training loss: 3.4735662342948355
Validation loss: 3.678357407004692

Epoch: 5| Step: 3
Training loss: 3.624327893267589
Validation loss: 3.6037084953431187

Epoch: 5| Step: 4
Training loss: 4.082909360919895
Validation loss: 3.5266195055729366

Epoch: 5| Step: 5
Training loss: 3.3280043602511378
Validation loss: 3.4551362499453537

Epoch: 5| Step: 6
Training loss: 3.746191888663341
Validation loss: 3.369243887825353

Epoch: 5| Step: 7
Training loss: 3.529595586720714
Validation loss: 3.2844301253609816

Epoch: 5| Step: 8
Training loss: 2.7616837862167514
Validation loss: 3.198562287674725

Epoch: 5| Step: 9
Training loss: 2.7448194431200004
Validation loss: 3.1191956848240565

Epoch: 5| Step: 10
Training loss: 3.4624111232987866
Validation loss: 3.044913310882485

Epoch: 5| Step: 11
Training loss: 4.212484043894809
Validation loss: 2.9655347981216202

Epoch: 5| Step: 0
Training loss: 2.098069702546988
Validation loss: 2.8969864516232766

Epoch: 5| Step: 1
Training loss: 2.856228624259712
Validation loss: 2.8353348083694816

Epoch: 5| Step: 2
Training loss: 2.881582602544665
Validation loss: 2.769075414451473

Epoch: 5| Step: 3
Training loss: 2.7460073617557272
Validation loss: 2.7240150724133825

Epoch: 5| Step: 4
Training loss: 2.6491609108634244
Validation loss: 2.669127131369882

Epoch: 5| Step: 5
Training loss: 2.471789263794917
Validation loss: 2.6478720017174444

Epoch: 5| Step: 6
Training loss: 2.0524935885107376
Validation loss: 2.612648880289243

Epoch: 5| Step: 7
Training loss: 3.0153330923526367
Validation loss: 2.607828881433415

Epoch: 5| Step: 8
Training loss: 2.70018189135453
Validation loss: 2.613943007634463

Epoch: 5| Step: 9
Training loss: 3.2058051085082813
Validation loss: 2.6264067316774455

Epoch: 5| Step: 10
Training loss: 3.0184722267125563
Validation loss: 2.617144577661287

Epoch: 5| Step: 11
Training loss: 1.691210587881792
Validation loss: 2.6486018307096577

Epoch: 6| Step: 0
Training loss: 2.73111177003006
Validation loss: 2.6750459946335408

Epoch: 5| Step: 1
Training loss: 2.367243599305608
Validation loss: 2.6800291420084013

Epoch: 5| Step: 2
Training loss: 2.8282404923435593
Validation loss: 2.6853449964071947

Epoch: 5| Step: 3
Training loss: 2.824178481705273
Validation loss: 2.7151015820183897

Epoch: 5| Step: 4
Training loss: 1.8634051075841516
Validation loss: 2.7114595429081563

Epoch: 5| Step: 5
Training loss: 2.327053770892394
Validation loss: 2.7160843025082273

Epoch: 5| Step: 6
Training loss: 2.9976414310028385
Validation loss: 2.7030831739831713

Epoch: 5| Step: 7
Training loss: 2.13845191416662
Validation loss: 2.7090447017348893

Epoch: 5| Step: 8
Training loss: 3.500676498429307
Validation loss: 2.676858663717675

Epoch: 5| Step: 9
Training loss: 3.144894255541836
Validation loss: 2.6674657769228904

Epoch: 5| Step: 10
Training loss: 2.8107416378400027
Validation loss: 2.6256225865634555

Epoch: 5| Step: 11
Training loss: 2.416103352192903
Validation loss: 2.6379681111546827

Epoch: 7| Step: 0
Training loss: 2.7001999039291884
Validation loss: 2.61099283618984

Epoch: 5| Step: 1
Training loss: 2.2661766696013483
Validation loss: 2.596671427808893

Epoch: 5| Step: 2
Training loss: 2.6729003544996264
Validation loss: 2.583660613883625

Epoch: 5| Step: 3
Training loss: 2.7413591399864425
Validation loss: 2.5837964147905823

Epoch: 5| Step: 4
Training loss: 2.997803996931106
Validation loss: 2.587670205763926

Epoch: 5| Step: 5
Training loss: 2.6610748452688817
Validation loss: 2.58392144374283

Epoch: 5| Step: 6
Training loss: 2.613315279843129
Validation loss: 2.5781930355766485

Epoch: 5| Step: 7
Training loss: 2.605224414904436
Validation loss: 2.585267912811696

Epoch: 5| Step: 8
Training loss: 2.4694427290935397
Validation loss: 2.5795824497397817

Epoch: 5| Step: 9
Training loss: 2.5333520144058235
Validation loss: 2.5818163560634138

Epoch: 5| Step: 10
Training loss: 2.5029049208684926
Validation loss: 2.585436973266612

Epoch: 5| Step: 11
Training loss: 2.448270039044311
Validation loss: 2.5951505254106277

Epoch: 8| Step: 0
Training loss: 2.446107387839757
Validation loss: 2.5769837907353645

Epoch: 5| Step: 1
Training loss: 2.3453326158976076
Validation loss: 2.569779167768567

Epoch: 5| Step: 2
Training loss: 2.7039332421825675
Validation loss: 2.5721718305916053

Epoch: 5| Step: 3
Training loss: 2.487449614814876
Validation loss: 2.5574986120943026

Epoch: 5| Step: 4
Training loss: 3.1224947233132583
Validation loss: 2.5721500595730094

Epoch: 5| Step: 5
Training loss: 2.862237883315011
Validation loss: 2.5641515418412335

Epoch: 5| Step: 6
Training loss: 2.545261175997569
Validation loss: 2.554784325758633

Epoch: 5| Step: 7
Training loss: 2.7720241330184816
Validation loss: 2.559119518509864

Epoch: 5| Step: 8
Training loss: 2.4600446746615328
Validation loss: 2.552954907706534

Epoch: 5| Step: 9
Training loss: 2.5191952976724417
Validation loss: 2.5530846182074356

Epoch: 5| Step: 10
Training loss: 2.1199318529368325
Validation loss: 2.5600422920456465

Epoch: 5| Step: 11
Training loss: 2.7956246932549993
Validation loss: 2.5401595577301284

Epoch: 9| Step: 0
Training loss: 2.3754132563788395
Validation loss: 2.5455693289624985

Epoch: 5| Step: 1
Training loss: 2.608027675704146
Validation loss: 2.547701446060561

Epoch: 5| Step: 2
Training loss: 2.9838428921696543
Validation loss: 2.55589326640447

Epoch: 5| Step: 3
Training loss: 2.5541821834555454
Validation loss: 2.5447779527175727

Epoch: 5| Step: 4
Training loss: 2.341367706093586
Validation loss: 2.5642470242844815

Epoch: 5| Step: 5
Training loss: 2.4868506806155897
Validation loss: 2.553756789311866

Epoch: 5| Step: 6
Training loss: 2.492590988166641
Validation loss: 2.5519731082598067

Epoch: 5| Step: 7
Training loss: 2.4855200090264806
Validation loss: 2.5390743001027882

Epoch: 5| Step: 8
Training loss: 2.263742230221386
Validation loss: 2.5336836724522582

Epoch: 5| Step: 9
Training loss: 2.5873223137775265
Validation loss: 2.5344575017944573

Epoch: 5| Step: 10
Training loss: 2.988623825083861
Validation loss: 2.5475816506954483

Epoch: 5| Step: 11
Training loss: 2.7092492731087576
Validation loss: 2.53470162741831

Epoch: 10| Step: 0
Training loss: 2.4887976477376133
Validation loss: 2.5337236076088256

Epoch: 5| Step: 1
Training loss: 2.708356700698598
Validation loss: 2.539995047659564

Epoch: 5| Step: 2
Training loss: 2.49205050196534
Validation loss: 2.538508524004621

Epoch: 5| Step: 3
Training loss: 2.2982237093394904
Validation loss: 2.549789703336801

Epoch: 5| Step: 4
Training loss: 2.620849507033795
Validation loss: 2.5566415342324946

Epoch: 5| Step: 5
Training loss: 2.2960901281763713
Validation loss: 2.5606615131553583

Epoch: 5| Step: 6
Training loss: 3.061333881940804
Validation loss: 2.540535344117292

Epoch: 5| Step: 7
Training loss: 2.842978236514641
Validation loss: 2.5430247959381154

Epoch: 5| Step: 8
Training loss: 2.229256696457627
Validation loss: 2.53928275693553

Epoch: 5| Step: 9
Training loss: 2.152780810391604
Validation loss: 2.548511813865773

Epoch: 5| Step: 10
Training loss: 2.6602292043846223
Validation loss: 2.548404320259765

Epoch: 5| Step: 11
Training loss: 3.7551986263888644
Validation loss: 2.5334658794069123

Epoch: 11| Step: 0
Training loss: 2.317262745289534
Validation loss: 2.5354703092477227

Epoch: 5| Step: 1
Training loss: 1.8294827888306808
Validation loss: 2.5282854922811686

Epoch: 5| Step: 2
Training loss: 3.0329440387577757
Validation loss: 2.5351218920212886

Epoch: 5| Step: 3
Training loss: 2.664292043154624
Validation loss: 2.536374986964618

Epoch: 5| Step: 4
Training loss: 2.2802279547458073
Validation loss: 2.5319647741335696

Epoch: 5| Step: 5
Training loss: 2.2631986055833035
Validation loss: 2.5316620322614707

Epoch: 5| Step: 6
Training loss: 2.5518049957666586
Validation loss: 2.5364782122408096

Epoch: 5| Step: 7
Training loss: 3.0201653805348556
Validation loss: 2.5456498325496923

Epoch: 5| Step: 8
Training loss: 3.2645583167433183
Validation loss: 2.5355201111323598

Epoch: 5| Step: 9
Training loss: 2.013014056024497
Validation loss: 2.548417281634478

Epoch: 5| Step: 10
Training loss: 2.7437192111362463
Validation loss: 2.5290742322023587

Epoch: 5| Step: 11
Training loss: 1.6243166587130808
Validation loss: 2.530710610269797

Epoch: 12| Step: 0
Training loss: 2.197484906592846
Validation loss: 2.5399968604415104

Epoch: 5| Step: 1
Training loss: 2.4468714220744316
Validation loss: 2.5280419966719205

Epoch: 5| Step: 2
Training loss: 2.5768963284642608
Validation loss: 2.5250033627226443

Epoch: 5| Step: 3
Training loss: 2.6682211001173286
Validation loss: 2.523168019962769

Epoch: 5| Step: 4
Training loss: 2.5875807781786935
Validation loss: 2.5138667578686094

Epoch: 5| Step: 5
Training loss: 2.3081932172241455
Validation loss: 2.523990476033368

Epoch: 5| Step: 6
Training loss: 2.6322133092736952
Validation loss: 2.509946515284768

Epoch: 5| Step: 7
Training loss: 2.2400383302270144
Validation loss: 2.5157324410629767

Epoch: 5| Step: 8
Training loss: 3.3609822531415747
Validation loss: 2.5177488306145275

Epoch: 5| Step: 9
Training loss: 2.578014302044624
Validation loss: 2.515819356451373

Epoch: 5| Step: 10
Training loss: 1.8907549474526117
Validation loss: 2.50879628106298

Epoch: 5| Step: 11
Training loss: 3.497319148461617
Validation loss: 2.509254369848909

Epoch: 13| Step: 0
Training loss: 2.1199445614673675
Validation loss: 2.512684167371936

Epoch: 5| Step: 1
Training loss: 2.893102790185243
Validation loss: 2.5139967227579088

Epoch: 5| Step: 2
Training loss: 2.4347606818621608
Validation loss: 2.5053555226590216

Epoch: 5| Step: 3
Training loss: 2.125829646896023
Validation loss: 2.5218415582291756

Epoch: 5| Step: 4
Training loss: 2.41517292643558
Validation loss: 2.517338214784758

Epoch: 5| Step: 5
Training loss: 2.6081603186835203
Validation loss: 2.5330709885188925

Epoch: 5| Step: 6
Training loss: 2.723851996267565
Validation loss: 2.5273787738273725

Epoch: 5| Step: 7
Training loss: 2.980170838752271
Validation loss: 2.5395180181115826

Epoch: 5| Step: 8
Training loss: 2.930133266868401
Validation loss: 2.52367501769861

Epoch: 5| Step: 9
Training loss: 2.353098624234857
Validation loss: 2.522979529427405

Epoch: 5| Step: 10
Training loss: 2.368440705491114
Validation loss: 2.5214883108425967

Epoch: 5| Step: 11
Training loss: 1.934660707737119
Validation loss: 2.517721491189922

Epoch: 14| Step: 0
Training loss: 2.881384684627456
Validation loss: 2.4964053576865104

Epoch: 5| Step: 1
Training loss: 2.7853812919963
Validation loss: 2.513318985298125

Epoch: 5| Step: 2
Training loss: 2.4169974155562146
Validation loss: 2.5094147472788704

Epoch: 5| Step: 3
Training loss: 2.0621578048276805
Validation loss: 2.5001370412300292

Epoch: 5| Step: 4
Training loss: 2.785100350481066
Validation loss: 2.521874564799886

Epoch: 5| Step: 5
Training loss: 2.2747103873557166
Validation loss: 2.50582615351391

Epoch: 5| Step: 6
Training loss: 2.5269579821445727
Validation loss: 2.501464323507544

Epoch: 5| Step: 7
Training loss: 2.6163126380008914
Validation loss: 2.5035193189463865

Epoch: 5| Step: 8
Training loss: 2.447227435107049
Validation loss: 2.5061484804623984

Epoch: 5| Step: 9
Training loss: 2.6067248380695442
Validation loss: 2.5067277188255463

Epoch: 5| Step: 10
Training loss: 2.3199789404735385
Validation loss: 2.510399518937129

Epoch: 5| Step: 11
Training loss: 3.7250848235642935
Validation loss: 2.484112175848556

Epoch: 15| Step: 0
Training loss: 2.2719252757894024
Validation loss: 2.5014731874710887

Epoch: 5| Step: 1
Training loss: 2.3774069585555044
Validation loss: 2.4924109148515257

Epoch: 5| Step: 2
Training loss: 2.2243960900417594
Validation loss: 2.4998230891416378

Epoch: 5| Step: 3
Training loss: 2.2299687615160995
Validation loss: 2.4911648157730966

Epoch: 5| Step: 4
Training loss: 2.875885536812898
Validation loss: 2.5092666981066643

Epoch: 5| Step: 5
Training loss: 2.9186474931185016
Validation loss: 2.5218064831041387

Epoch: 5| Step: 6
Training loss: 2.157862184962133
Validation loss: 2.507649112342407

Epoch: 5| Step: 7
Training loss: 2.5720433491780947
Validation loss: 2.5251222189038223

Epoch: 5| Step: 8
Training loss: 2.409697008199513
Validation loss: 2.5051372436038464

Epoch: 5| Step: 9
Training loss: 2.586782634272284
Validation loss: 2.506564296126807

Epoch: 5| Step: 10
Training loss: 2.749590756569654
Validation loss: 2.5165239390475014

Epoch: 5| Step: 11
Training loss: 3.4513295196468903
Validation loss: 2.5031900735556945

Epoch: 16| Step: 0
Training loss: 2.6089527450908236
Validation loss: 2.5224855081855866

Epoch: 5| Step: 1
Training loss: 2.6073984666552246
Validation loss: 2.5116728980673293

Epoch: 5| Step: 2
Training loss: 2.6948116998231364
Validation loss: 2.507007120962774

Epoch: 5| Step: 3
Training loss: 2.071305637751925
Validation loss: 2.5216909649462598

Epoch: 5| Step: 4
Training loss: 3.0407945262230407
Validation loss: 2.5131400019139347

Epoch: 5| Step: 5
Training loss: 2.2819671548724685
Validation loss: 2.49927505075189

Epoch: 5| Step: 6
Training loss: 2.3689437746691975
Validation loss: 2.5194030965697145

Epoch: 5| Step: 7
Training loss: 2.746087932987482
Validation loss: 2.5225154857519323

Epoch: 5| Step: 8
Training loss: 2.545846087667812
Validation loss: 2.4979619540408846

Epoch: 5| Step: 9
Training loss: 2.344349390315635
Validation loss: 2.508764282436799

Epoch: 5| Step: 10
Training loss: 2.2733558037095754
Validation loss: 2.496018724502985

Epoch: 5| Step: 11
Training loss: 1.8998843358621968
Validation loss: 2.5065578578406145

Epoch: 17| Step: 0
Training loss: 3.070368564860654
Validation loss: 2.5048730444764162

Epoch: 5| Step: 1
Training loss: 2.372070614032247
Validation loss: 2.473421310898765

Epoch: 5| Step: 2
Training loss: 2.0491648670926543
Validation loss: 2.488498185231525

Epoch: 5| Step: 3
Training loss: 2.651265752548621
Validation loss: 2.4867123778614406

Epoch: 5| Step: 4
Training loss: 2.7742495785125305
Validation loss: 2.491254482389668

Epoch: 5| Step: 5
Training loss: 2.4755429837866267
Validation loss: 2.4876708015990836

Epoch: 5| Step: 6
Training loss: 2.6225373660208424
Validation loss: 2.487923033923416

Epoch: 5| Step: 7
Training loss: 2.5058374916839687
Validation loss: 2.4838442985342373

Epoch: 5| Step: 8
Training loss: 2.323764686148181
Validation loss: 2.4895029706766763

Epoch: 5| Step: 9
Training loss: 2.7799705391290197
Validation loss: 2.4818024341430007

Epoch: 5| Step: 10
Training loss: 1.9500615623733264
Validation loss: 2.4844272096214204

Epoch: 5| Step: 11
Training loss: 2.153870748809149
Validation loss: 2.4886855072013763

Epoch: 18| Step: 0
Training loss: 2.0902058225338
Validation loss: 2.4747225347396857

Epoch: 5| Step: 1
Training loss: 3.1185073544096116
Validation loss: 2.4894410249639587

Epoch: 5| Step: 2
Training loss: 2.6715963117918715
Validation loss: 2.4724975281887214

Epoch: 5| Step: 3
Training loss: 2.3516214052851208
Validation loss: 2.489176732275906

Epoch: 5| Step: 4
Training loss: 2.779725246162439
Validation loss: 2.4851880852296033

Epoch: 5| Step: 5
Training loss: 2.743294343064858
Validation loss: 2.5082725031712156

Epoch: 5| Step: 6
Training loss: 2.3160305393952862
Validation loss: 2.4929931239354493

Epoch: 5| Step: 7
Training loss: 2.5594399952815894
Validation loss: 2.517036922378269

Epoch: 5| Step: 8
Training loss: 2.303380252766935
Validation loss: 2.4916276213181887

Epoch: 5| Step: 9
Training loss: 2.384737131759296
Validation loss: 2.5071624673969963

Epoch: 5| Step: 10
Training loss: 2.0561338490433654
Validation loss: 2.4898491934286

Epoch: 5| Step: 11
Training loss: 1.3765225650394124
Validation loss: 2.511313014584042

Epoch: 19| Step: 0
Training loss: 2.6125530146280176
Validation loss: 2.4777045940814766

Epoch: 5| Step: 1
Training loss: 2.6953275376052432
Validation loss: 2.4930516720820943

Epoch: 5| Step: 2
Training loss: 2.409626264124287
Validation loss: 2.5091474254117037

Epoch: 5| Step: 3
Training loss: 3.0380426181217284
Validation loss: 2.495870394158254

Epoch: 5| Step: 4
Training loss: 2.0622689088770048
Validation loss: 2.471197158815826

Epoch: 5| Step: 5
Training loss: 2.524804751712742
Validation loss: 2.4823556486510387

Epoch: 5| Step: 6
Training loss: 1.9526770726598786
Validation loss: 2.4936558793327146

Epoch: 5| Step: 7
Training loss: 1.8962207300571283
Validation loss: 2.4994009154472976

Epoch: 5| Step: 8
Training loss: 2.6592235302401637
Validation loss: 2.4882661109355984

Epoch: 5| Step: 9
Training loss: 2.6091603630555906
Validation loss: 2.4757192963263375

Epoch: 5| Step: 10
Training loss: 2.377484076573972
Validation loss: 2.4775350207520246

Epoch: 5| Step: 11
Training loss: 3.672986970092693
Validation loss: 2.4703791470015353

Epoch: 20| Step: 0
Training loss: 1.9897335721423488
Validation loss: 2.4726239363500913

Epoch: 5| Step: 1
Training loss: 2.3427246902819774
Validation loss: 2.4762174163335793

Epoch: 5| Step: 2
Training loss: 2.012921553347681
Validation loss: 2.491842327709021

Epoch: 5| Step: 3
Training loss: 3.2432625700185755
Validation loss: 2.4814740884516815

Epoch: 5| Step: 4
Training loss: 2.388070730328002
Validation loss: 2.4816044287651593

Epoch: 5| Step: 5
Training loss: 2.3796712212309465
Validation loss: 2.489633776474254

Epoch: 5| Step: 6
Training loss: 2.5486109147748834
Validation loss: 2.4870664304965318

Epoch: 5| Step: 7
Training loss: 2.7146310407340617
Validation loss: 2.4777917147953885

Epoch: 5| Step: 8
Training loss: 2.6765941860730713
Validation loss: 2.4737404710644917

Epoch: 5| Step: 9
Training loss: 2.9426148706408224
Validation loss: 2.4636201879610575

Epoch: 5| Step: 10
Training loss: 1.9744165403724312
Validation loss: 2.487962040570213

Epoch: 5| Step: 11
Training loss: 2.0068071869138846
Validation loss: 2.4623982973284244

Epoch: 21| Step: 0
Training loss: 2.215479845207138
Validation loss: 2.471143829484681

Epoch: 5| Step: 1
Training loss: 3.059592599114888
Validation loss: 2.4536288203669425

Epoch: 5| Step: 2
Training loss: 2.338787267032239
Validation loss: 2.4704042879698345

Epoch: 5| Step: 3
Training loss: 2.6652695055416835
Validation loss: 2.4601510138408993

Epoch: 5| Step: 4
Training loss: 2.4490118836768393
Validation loss: 2.47664595662884

Epoch: 5| Step: 5
Training loss: 2.5846582112240015
Validation loss: 2.4754273152492887

Epoch: 5| Step: 6
Training loss: 2.4189614767828918
Validation loss: 2.46323060067215

Epoch: 5| Step: 7
Training loss: 3.0211584683537804
Validation loss: 2.463969245295801

Epoch: 5| Step: 8
Training loss: 1.6385869037117393
Validation loss: 2.472130661839324

Epoch: 5| Step: 9
Training loss: 2.440371264994477
Validation loss: 2.4705230084330716

Epoch: 5| Step: 10
Training loss: 2.3704743683979563
Validation loss: 2.484021091644737

Epoch: 5| Step: 11
Training loss: 0.6875383193000819
Validation loss: 2.465981798581018

Epoch: 22| Step: 0
Training loss: 2.396440102961837
Validation loss: 2.480091456757314

Epoch: 5| Step: 1
Training loss: 1.8608450968339656
Validation loss: 2.4846895966384865

Epoch: 5| Step: 2
Training loss: 2.6040791204359985
Validation loss: 2.48890441884246

Epoch: 5| Step: 3
Training loss: 2.4863820156301255
Validation loss: 2.50645168219114

Epoch: 5| Step: 4
Training loss: 2.4619605465911087
Validation loss: 2.5166710007758644

Epoch: 5| Step: 5
Training loss: 2.4117747704092047
Validation loss: 2.50906623961366

Epoch: 5| Step: 6
Training loss: 2.4022558180680704
Validation loss: 2.510372455624443

Epoch: 5| Step: 7
Training loss: 2.6484864717080043
Validation loss: 2.5178693351881996

Epoch: 5| Step: 8
Training loss: 2.7022501681981814
Validation loss: 2.5110569502771733

Epoch: 5| Step: 9
Training loss: 2.5461818945516876
Validation loss: 2.4994832378994714

Epoch: 5| Step: 10
Training loss: 2.736951388076851
Validation loss: 2.491815995735386

Epoch: 5| Step: 11
Training loss: 2.435812732958744
Validation loss: 2.472614563183271

Epoch: 23| Step: 0
Training loss: 2.157880967895691
Validation loss: 2.483976812061711

Epoch: 5| Step: 1
Training loss: 2.3911705641207464
Validation loss: 2.466968436780297

Epoch: 5| Step: 2
Training loss: 2.5318765688938165
Validation loss: 2.4693752052463456

Epoch: 5| Step: 3
Training loss: 2.6278070246131007
Validation loss: 2.4801754114710204

Epoch: 5| Step: 4
Training loss: 2.308276675891211
Validation loss: 2.4817280894091356

Epoch: 5| Step: 5
Training loss: 1.8187808686353653
Validation loss: 2.4632886725774745

Epoch: 5| Step: 6
Training loss: 2.2801099044679045
Validation loss: 2.456281530422157

Epoch: 5| Step: 7
Training loss: 2.9018838551452126
Validation loss: 2.4766578174623795

Epoch: 5| Step: 8
Training loss: 2.4421191342010946
Validation loss: 2.472778261056041

Epoch: 5| Step: 9
Training loss: 2.8697310554948494
Validation loss: 2.466786549421473

Epoch: 5| Step: 10
Training loss: 2.6118348000292904
Validation loss: 2.465788578043266

Epoch: 5| Step: 11
Training loss: 2.6632084078687264
Validation loss: 2.475370856478

Epoch: 24| Step: 0
Training loss: 2.408822010272418
Validation loss: 2.464867295013193

Epoch: 5| Step: 1
Training loss: 2.9910427523216416
Validation loss: 2.4671361553477698

Epoch: 5| Step: 2
Training loss: 2.4482133617918103
Validation loss: 2.467509924009671

Epoch: 5| Step: 3
Training loss: 2.595765583099203
Validation loss: 2.4534265369310764

Epoch: 5| Step: 4
Training loss: 2.578266764124404
Validation loss: 2.469391139994786

Epoch: 5| Step: 5
Training loss: 2.013598228906058
Validation loss: 2.4675917141497763

Epoch: 5| Step: 6
Training loss: 2.202634066810779
Validation loss: 2.4542043745083304

Epoch: 5| Step: 7
Training loss: 2.7655937063741978
Validation loss: 2.4614909402498597

Epoch: 5| Step: 8
Training loss: 1.9892117284756181
Validation loss: 2.4427443700272713

Epoch: 5| Step: 9
Training loss: 2.371460133734817
Validation loss: 2.4514675777642783

Epoch: 5| Step: 10
Training loss: 2.567368789930563
Validation loss: 2.4616797200874663

Epoch: 5| Step: 11
Training loss: 2.449419174633101
Validation loss: 2.4483113410352355

Epoch: 25| Step: 0
Training loss: 2.820574042960711
Validation loss: 2.468716428021428

Epoch: 5| Step: 1
Training loss: 2.4417470465265625
Validation loss: 2.4712472831570924

Epoch: 5| Step: 2
Training loss: 1.5971172888006038
Validation loss: 2.4743682414662187

Epoch: 5| Step: 3
Training loss: 2.7136367419983083
Validation loss: 2.4821798975491633

Epoch: 5| Step: 4
Training loss: 2.080384137921629
Validation loss: 2.487503612937412

Epoch: 5| Step: 5
Training loss: 2.451331582508736
Validation loss: 2.495014741490274

Epoch: 5| Step: 6
Training loss: 2.7095914021696013
Validation loss: 2.490298245676772

Epoch: 5| Step: 7
Training loss: 2.7555837297366517
Validation loss: 2.512863096251146

Epoch: 5| Step: 8
Training loss: 2.861935828971004
Validation loss: 2.5096041180884017

Epoch: 5| Step: 9
Training loss: 2.3481485418744343
Validation loss: 2.481939733681397

Epoch: 5| Step: 10
Training loss: 2.2392352402918156
Validation loss: 2.491240027325249

Epoch: 5| Step: 11
Training loss: 1.8049927820711245
Validation loss: 2.4710174601836097

Epoch: 26| Step: 0
Training loss: 3.1300749197576563
Validation loss: 2.4842648011884694

Epoch: 5| Step: 1
Training loss: 2.0947275868660085
Validation loss: 2.4486392834902877

Epoch: 5| Step: 2
Training loss: 2.6056551430528603
Validation loss: 2.4642445157785255

Epoch: 5| Step: 3
Training loss: 2.723866351138533
Validation loss: 2.4681751088870763

Epoch: 5| Step: 4
Training loss: 2.3873118461246268
Validation loss: 2.4714212170674434

Epoch: 5| Step: 5
Training loss: 2.1532994967814756
Validation loss: 2.47111179756475

Epoch: 5| Step: 6
Training loss: 2.681009483664962
Validation loss: 2.4579191458381824

Epoch: 5| Step: 7
Training loss: 2.452726586905586
Validation loss: 2.4601253562094696

Epoch: 5| Step: 8
Training loss: 2.28627370264146
Validation loss: 2.4558459173600027

Epoch: 5| Step: 9
Training loss: 1.6879801596881203
Validation loss: 2.4541388156025112

Epoch: 5| Step: 10
Training loss: 2.340076874342386
Validation loss: 2.463021279201412

Epoch: 5| Step: 11
Training loss: 3.300896384132913
Validation loss: 2.4537939912917657

Epoch: 27| Step: 0
Training loss: 2.7955710498866955
Validation loss: 2.46122305691762

Epoch: 5| Step: 1
Training loss: 2.347750695180643
Validation loss: 2.46215423699663

Epoch: 5| Step: 2
Training loss: 1.574742611032154
Validation loss: 2.4474646062957652

Epoch: 5| Step: 3
Training loss: 2.148556903642181
Validation loss: 2.4831862694655946

Epoch: 5| Step: 4
Training loss: 2.582353303478123
Validation loss: 2.4715988465483636

Epoch: 5| Step: 5
Training loss: 2.996933641546148
Validation loss: 2.476004464449476

Epoch: 5| Step: 6
Training loss: 2.6695348295835855
Validation loss: 2.4932108166329288

Epoch: 5| Step: 7
Training loss: 2.2333002239828605
Validation loss: 2.4712576343159256

Epoch: 5| Step: 8
Training loss: 1.886840058211993
Validation loss: 2.4797408550301627

Epoch: 5| Step: 9
Training loss: 2.668402216314288
Validation loss: 2.5020892870279243

Epoch: 5| Step: 10
Training loss: 2.5853132433701753
Validation loss: 2.504374967555557

Epoch: 5| Step: 11
Training loss: 3.0311159713845366
Validation loss: 2.4993693013152884

Epoch: 28| Step: 0
Training loss: 2.7716066146679164
Validation loss: 2.487171560438422

Epoch: 5| Step: 1
Training loss: 2.8608504694103107
Validation loss: 2.4747375639742275

Epoch: 5| Step: 2
Training loss: 2.6372125911954214
Validation loss: 2.4776244549137463

Epoch: 5| Step: 3
Training loss: 2.403091339153376
Validation loss: 2.454409032429798

Epoch: 5| Step: 4
Training loss: 2.024236690628717
Validation loss: 2.4677787149702732

Epoch: 5| Step: 5
Training loss: 2.467584842046521
Validation loss: 2.4616317375298946

Epoch: 5| Step: 6
Training loss: 3.090086955109309
Validation loss: 2.445972713033245

Epoch: 5| Step: 7
Training loss: 1.6595307013098877
Validation loss: 2.4493978334507784

Epoch: 5| Step: 8
Training loss: 2.2458112721489054
Validation loss: 2.4568429216703658

Epoch: 5| Step: 9
Training loss: 2.2543870753511372
Validation loss: 2.4488943230882048

Epoch: 5| Step: 10
Training loss: 2.1764906543449545
Validation loss: 2.4671240534485124

Epoch: 5| Step: 11
Training loss: 2.1048791516334036
Validation loss: 2.4627509282965234

Epoch: 29| Step: 0
Training loss: 2.36810778364184
Validation loss: 2.461213470809159

Epoch: 5| Step: 1
Training loss: 2.2298950954104644
Validation loss: 2.453663542123588

Epoch: 5| Step: 2
Training loss: 2.4986403582717003
Validation loss: 2.465321522236547

Epoch: 5| Step: 3
Training loss: 2.0947564965445684
Validation loss: 2.4586737499428093

Epoch: 5| Step: 4
Training loss: 2.6386707003779306
Validation loss: 2.463125959301155

Epoch: 5| Step: 5
Training loss: 2.7274939577366153
Validation loss: 2.4688335597709163

Epoch: 5| Step: 6
Training loss: 2.6168393942645305
Validation loss: 2.463471701329465

Epoch: 5| Step: 7
Training loss: 2.5379183494834936
Validation loss: 2.453392411091676

Epoch: 5| Step: 8
Training loss: 2.010088272813399
Validation loss: 2.46415549703274

Epoch: 5| Step: 9
Training loss: 2.3381066091100218
Validation loss: 2.479260830867382

Epoch: 5| Step: 10
Training loss: 2.8815733357883446
Validation loss: 2.472640119342307

Epoch: 5| Step: 11
Training loss: 1.8119992847062272
Validation loss: 2.468947370502314

Epoch: 30| Step: 0
Training loss: 2.64178360119646
Validation loss: 2.449820449147025

Epoch: 5| Step: 1
Training loss: 2.5006042703857667
Validation loss: 2.457271869402335

Epoch: 5| Step: 2
Training loss: 2.1988818925310714
Validation loss: 2.4708780942939854

Epoch: 5| Step: 3
Training loss: 2.696922109110655
Validation loss: 2.463714371098929

Epoch: 5| Step: 4
Training loss: 2.785777147163726
Validation loss: 2.4795915248944724

Epoch: 5| Step: 5
Training loss: 2.1721632512319236
Validation loss: 2.487371209419146

Epoch: 5| Step: 6
Training loss: 2.7136960464659596
Validation loss: 2.465115326168985

Epoch: 5| Step: 7
Training loss: 2.6702787750953743
Validation loss: 2.463663676159399

Epoch: 5| Step: 8
Training loss: 1.9060250446599518
Validation loss: 2.4731156905144207

Epoch: 5| Step: 9
Training loss: 2.298621726675834
Validation loss: 2.471092163336284

Epoch: 5| Step: 10
Training loss: 2.0048392876881698
Validation loss: 2.4544591049952174

Epoch: 5| Step: 11
Training loss: 1.91089770196877
Validation loss: 2.464918390384249

Epoch: 31| Step: 0
Training loss: 2.3647161998194366
Validation loss: 2.455871660151152

Epoch: 5| Step: 1
Training loss: 2.2509114220848456
Validation loss: 2.469572907928847

Epoch: 5| Step: 2
Training loss: 2.386590682619193
Validation loss: 2.464138782604907

Epoch: 5| Step: 3
Training loss: 2.0024539674570967
Validation loss: 2.4550896145863588

Epoch: 5| Step: 4
Training loss: 2.191209862488873
Validation loss: 2.4603448951539804

Epoch: 5| Step: 5
Training loss: 2.5313025575055774
Validation loss: 2.4638366979566433

Epoch: 5| Step: 6
Training loss: 2.607437419487841
Validation loss: 2.449790735698473

Epoch: 5| Step: 7
Training loss: 1.865823990067394
Validation loss: 2.4641965730839215

Epoch: 5| Step: 8
Training loss: 3.148911509080019
Validation loss: 2.46178835333903

Epoch: 5| Step: 9
Training loss: 1.7490023085075659
Validation loss: 2.4608927081840526

Epoch: 5| Step: 10
Training loss: 3.0488737935000536
Validation loss: 2.4687217920035813

Epoch: 5| Step: 11
Training loss: 2.7729765173120318
Validation loss: 2.458881261884072

Epoch: 32| Step: 0
Training loss: 2.2825171726746523
Validation loss: 2.445089640836616

Epoch: 5| Step: 1
Training loss: 2.6798061867279306
Validation loss: 2.4494981094353574

Epoch: 5| Step: 2
Training loss: 2.8410957441567892
Validation loss: 2.4719218589241128

Epoch: 5| Step: 3
Training loss: 2.0442168469599844
Validation loss: 2.454855776044656

Epoch: 5| Step: 4
Training loss: 2.281121550823754
Validation loss: 2.45441602844393

Epoch: 5| Step: 5
Training loss: 2.471785694925222
Validation loss: 2.444933527788529

Epoch: 5| Step: 6
Training loss: 2.1238693146309884
Validation loss: 2.4589908792673816

Epoch: 5| Step: 7
Training loss: 2.1257881498102145
Validation loss: 2.46656786171961

Epoch: 5| Step: 8
Training loss: 2.712084261066299
Validation loss: 2.4446588034515933

Epoch: 5| Step: 9
Training loss: 2.607008357600551
Validation loss: 2.4739553364518065

Epoch: 5| Step: 10
Training loss: 2.209316130937005
Validation loss: 2.450442801735449

Epoch: 5| Step: 11
Training loss: 3.0069421871451896
Validation loss: 2.455918913893602

Epoch: 33| Step: 0
Training loss: 1.7888243404271256
Validation loss: 2.4676587594300785

Epoch: 5| Step: 1
Training loss: 2.6600334598473236
Validation loss: 2.453207865001866

Epoch: 5| Step: 2
Training loss: 2.5323833236101865
Validation loss: 2.4810426824007434

Epoch: 5| Step: 3
Training loss: 2.798953940630978
Validation loss: 2.488326075782421

Epoch: 5| Step: 4
Training loss: 2.7102136882414634
Validation loss: 2.480918334907414

Epoch: 5| Step: 5
Training loss: 2.084609047990795
Validation loss: 2.475752271773739

Epoch: 5| Step: 6
Training loss: 2.1279794337920865
Validation loss: 2.4830399910968093

Epoch: 5| Step: 7
Training loss: 2.1395097040757327
Validation loss: 2.4952593161358045

Epoch: 5| Step: 8
Training loss: 2.862176242160242
Validation loss: 2.5149863006870907

Epoch: 5| Step: 9
Training loss: 2.4415154272463515
Validation loss: 2.473743159657499

Epoch: 5| Step: 10
Training loss: 2.4657632651198003
Validation loss: 2.480961223584488

Epoch: 5| Step: 11
Training loss: 2.052945054528158
Validation loss: 2.457489407614527

Epoch: 34| Step: 0
Training loss: 1.8864579109291124
Validation loss: 2.4645641307346073

Epoch: 5| Step: 1
Training loss: 2.806458320616732
Validation loss: 2.4822486959097882

Epoch: 5| Step: 2
Training loss: 3.024877082282029
Validation loss: 2.4624785810433036

Epoch: 5| Step: 3
Training loss: 2.239369711926898
Validation loss: 2.4586392969260804

Epoch: 5| Step: 4
Training loss: 2.43540894240913
Validation loss: 2.488494963678076

Epoch: 5| Step: 5
Training loss: 2.329466055893561
Validation loss: 2.4456963730394787

Epoch: 5| Step: 6
Training loss: 2.2774164047560244
Validation loss: 2.464655702231938

Epoch: 5| Step: 7
Training loss: 2.793163543524006
Validation loss: 2.4585781595119442

Epoch: 5| Step: 8
Training loss: 2.388772383764164
Validation loss: 2.4475556749967424

Epoch: 5| Step: 9
Training loss: 1.7032951479971978
Validation loss: 2.4448586023370034

Epoch: 5| Step: 10
Training loss: 2.4697076412877412
Validation loss: 2.4367741376169834

Epoch: 5| Step: 11
Training loss: 1.6444770278509198
Validation loss: 2.435984486796974

Epoch: 35| Step: 0
Training loss: 2.432180419817464
Validation loss: 2.4372570393592037

Epoch: 5| Step: 1
Training loss: 2.2248268188629616
Validation loss: 2.442308886686765

Epoch: 5| Step: 2
Training loss: 2.1252271867368346
Validation loss: 2.436932053381987

Epoch: 5| Step: 3
Training loss: 2.0322476797917726
Validation loss: 2.4438648102596843

Epoch: 5| Step: 4
Training loss: 2.2104718152596132
Validation loss: 2.4647254713952957

Epoch: 5| Step: 5
Training loss: 2.408600884945745
Validation loss: 2.4620466084392736

Epoch: 5| Step: 6
Training loss: 2.5326845789804193
Validation loss: 2.4425809023111444

Epoch: 5| Step: 7
Training loss: 1.9078779304650342
Validation loss: 2.4291720666438215

Epoch: 5| Step: 8
Training loss: 2.42309106629358
Validation loss: 2.456461073596448

Epoch: 5| Step: 9
Training loss: 3.0539073679627493
Validation loss: 2.475167817389227

Epoch: 5| Step: 10
Training loss: 3.010262103661284
Validation loss: 2.477968047737041

Epoch: 5| Step: 11
Training loss: 2.173281536635714
Validation loss: 2.476468983999537

Epoch: 36| Step: 0
Training loss: 2.8010086967444927
Validation loss: 2.473257482873464

Epoch: 5| Step: 1
Training loss: 2.478641058931978
Validation loss: 2.4465836662922773

Epoch: 5| Step: 2
Training loss: 2.1196858772542693
Validation loss: 2.4355840448165362

Epoch: 5| Step: 3
Training loss: 1.9762697266879568
Validation loss: 2.4437921650493677

Epoch: 5| Step: 4
Training loss: 2.483778780044278
Validation loss: 2.4647715457712667

Epoch: 5| Step: 5
Training loss: 1.8358614642042361
Validation loss: 2.4524001490246814

Epoch: 5| Step: 6
Training loss: 2.7360418852059483
Validation loss: 2.452418693376848

Epoch: 5| Step: 7
Training loss: 2.541769609294796
Validation loss: 2.4483642385396283

Epoch: 5| Step: 8
Training loss: 2.244430748999497
Validation loss: 2.445291959861151

Epoch: 5| Step: 9
Training loss: 2.387331320511006
Validation loss: 2.460228570622346

Epoch: 5| Step: 10
Training loss: 2.504529283348938
Validation loss: 2.442666925080682

Epoch: 5| Step: 11
Training loss: 2.8165309418099946
Validation loss: 2.4638875647231537

Epoch: 37| Step: 0
Training loss: 2.4730108648633014
Validation loss: 2.437643768276635

Epoch: 5| Step: 1
Training loss: 2.3642126344557948
Validation loss: 2.4303813834833536

Epoch: 5| Step: 2
Training loss: 2.7208077546845644
Validation loss: 2.448210350978952

Epoch: 5| Step: 3
Training loss: 1.7572684569334522
Validation loss: 2.430654682832539

Epoch: 5| Step: 4
Training loss: 2.012001032607191
Validation loss: 2.4401449012138254

Epoch: 5| Step: 5
Training loss: 2.736889015888391
Validation loss: 2.449598620583808

Epoch: 5| Step: 6
Training loss: 2.3937903497945534
Validation loss: 2.4736160295822973

Epoch: 5| Step: 7
Training loss: 2.6295412835526957
Validation loss: 2.4493094939031455

Epoch: 5| Step: 8
Training loss: 2.4172880974163267
Validation loss: 2.43935578566658

Epoch: 5| Step: 9
Training loss: 2.4241563450276757
Validation loss: 2.464051914938198

Epoch: 5| Step: 10
Training loss: 2.244744945727333
Validation loss: 2.466531613933566

Epoch: 5| Step: 11
Training loss: 2.9629723795988423
Validation loss: 2.461451275998746

Epoch: 38| Step: 0
Training loss: 2.1209397514739368
Validation loss: 2.4635929192392654

Epoch: 5| Step: 1
Training loss: 1.834622630572701
Validation loss: 2.462323939618148

Epoch: 5| Step: 2
Training loss: 2.469440798142321
Validation loss: 2.440056071966048

Epoch: 5| Step: 3
Training loss: 2.726547809550324
Validation loss: 2.434435287140423

Epoch: 5| Step: 4
Training loss: 2.36593715770005
Validation loss: 2.4478965893726947

Epoch: 5| Step: 5
Training loss: 2.207745731799311
Validation loss: 2.441571527608667

Epoch: 5| Step: 6
Training loss: 2.299076608145555
Validation loss: 2.447263169141523

Epoch: 5| Step: 7
Training loss: 2.455618593242052
Validation loss: 2.4482193326853334

Epoch: 5| Step: 8
Training loss: 2.8246929778307495
Validation loss: 2.458079960799461

Epoch: 5| Step: 9
Training loss: 2.683071035592862
Validation loss: 2.4293635684955537

Epoch: 5| Step: 10
Training loss: 2.3627171371220146
Validation loss: 2.4431039324457373

Epoch: 5| Step: 11
Training loss: 1.4290808552744192
Validation loss: 2.4384670458531423

Epoch: 39| Step: 0
Training loss: 2.087372818230514
Validation loss: 2.449686832102656

Epoch: 5| Step: 1
Training loss: 2.0979511756925135
Validation loss: 2.446462460360397

Epoch: 5| Step: 2
Training loss: 2.4234775286577714
Validation loss: 2.442464488261666

Epoch: 5| Step: 3
Training loss: 2.183035081288822
Validation loss: 2.452355436224516

Epoch: 5| Step: 4
Training loss: 2.817948806476376
Validation loss: 2.4511312858797547

Epoch: 5| Step: 5
Training loss: 1.6297878011411968
Validation loss: 2.4310159884413105

Epoch: 5| Step: 6
Training loss: 2.006740655052522
Validation loss: 2.44718098373562

Epoch: 5| Step: 7
Training loss: 2.9566904977772017
Validation loss: 2.437724852991059

Epoch: 5| Step: 8
Training loss: 2.2014354964282017
Validation loss: 2.455012613705656

Epoch: 5| Step: 9
Training loss: 2.3856943182684796
Validation loss: 2.4468638787274664

Epoch: 5| Step: 10
Training loss: 2.895841932398335
Validation loss: 2.453164434419744

Epoch: 5| Step: 11
Training loss: 2.9250066773428056
Validation loss: 2.445282522552009

Epoch: 40| Step: 0
Training loss: 2.4890236218727373
Validation loss: 2.481291246591834

Epoch: 5| Step: 1
Training loss: 2.451045424402688
Validation loss: 2.451117060277651

Epoch: 5| Step: 2
Training loss: 2.4159972699762546
Validation loss: 2.437425359577573

Epoch: 5| Step: 3
Training loss: 2.4170993110730565
Validation loss: 2.440524897881283

Epoch: 5| Step: 4
Training loss: 2.0862429963046316
Validation loss: 2.4374429439322585

Epoch: 5| Step: 5
Training loss: 2.520972403060896
Validation loss: 2.444981848204698

Epoch: 5| Step: 6
Training loss: 2.543622239112246
Validation loss: 2.443912757517083

Epoch: 5| Step: 7
Training loss: 2.507445691814661
Validation loss: 2.4510281544734562

Epoch: 5| Step: 8
Training loss: 2.312311628762863
Validation loss: 2.4346744348300056

Epoch: 5| Step: 9
Training loss: 2.03059294417309
Validation loss: 2.4527724512843294

Epoch: 5| Step: 10
Training loss: 2.441389648381054
Validation loss: 2.432100494081978

Epoch: 5| Step: 11
Training loss: 2.196010275074974
Validation loss: 2.457743858256779

Epoch: 41| Step: 0
Training loss: 2.6926648390385104
Validation loss: 2.4523977793234417

Epoch: 5| Step: 1
Training loss: 1.7840563434461862
Validation loss: 2.422314528092757

Epoch: 5| Step: 2
Training loss: 1.9772235835354939
Validation loss: 2.452693164177689

Epoch: 5| Step: 3
Training loss: 2.9013995640969537
Validation loss: 2.444026385366753

Epoch: 5| Step: 4
Training loss: 1.6826335532022956
Validation loss: 2.437488470294778

Epoch: 5| Step: 5
Training loss: 2.403893741430072
Validation loss: 2.4262396788275216

Epoch: 5| Step: 6
Training loss: 1.996574985849027
Validation loss: 2.4563711924336484

Epoch: 5| Step: 7
Training loss: 2.080445564304126
Validation loss: 2.4247130920669546

Epoch: 5| Step: 8
Training loss: 2.498993957274093
Validation loss: 2.465315852669659

Epoch: 5| Step: 9
Training loss: 2.5369107092998857
Validation loss: 2.43555132904502

Epoch: 5| Step: 10
Training loss: 3.121808367715932
Validation loss: 2.4462402907412586

Epoch: 5| Step: 11
Training loss: 1.9377214858912943
Validation loss: 2.449460290966811

Epoch: 42| Step: 0
Training loss: 2.8259633270065514
Validation loss: 2.457674840785305

Epoch: 5| Step: 1
Training loss: 2.0042751634485345
Validation loss: 2.444580610473254

Epoch: 5| Step: 2
Training loss: 2.5416837806333943
Validation loss: 2.4434342813736922

Epoch: 5| Step: 3
Training loss: 1.7269839639764073
Validation loss: 2.4284245642130693

Epoch: 5| Step: 4
Training loss: 2.3654259904125907
Validation loss: 2.4370091791839705

Epoch: 5| Step: 5
Training loss: 2.567176645154984
Validation loss: 2.455165233295801

Epoch: 5| Step: 6
Training loss: 2.6253160558893756
Validation loss: 2.4543601892936104

Epoch: 5| Step: 7
Training loss: 2.4316002287056175
Validation loss: 2.469403156360405

Epoch: 5| Step: 8
Training loss: 2.4733478850410453
Validation loss: 2.444479311859347

Epoch: 5| Step: 9
Training loss: 2.516382517994368
Validation loss: 2.4648013144022616

Epoch: 5| Step: 10
Training loss: 1.9861794625223526
Validation loss: 2.4677394255234213

Epoch: 5| Step: 11
Training loss: 1.445829226939648
Validation loss: 2.441025338530284

Epoch: 43| Step: 0
Training loss: 2.123720007960252
Validation loss: 2.4510430128615597

Epoch: 5| Step: 1
Training loss: 2.564801926726476
Validation loss: 2.444216314932889

Epoch: 5| Step: 2
Training loss: 2.5815185407186636
Validation loss: 2.462114101274043

Epoch: 5| Step: 3
Training loss: 2.1008756855386865
Validation loss: 2.4560672585258554

Epoch: 5| Step: 4
Training loss: 2.2086378883185693
Validation loss: 2.467189861213532

Epoch: 5| Step: 5
Training loss: 2.547547702061927
Validation loss: 2.44133900460776

Epoch: 5| Step: 6
Training loss: 2.0010108777255255
Validation loss: 2.4650244346849384

Epoch: 5| Step: 7
Training loss: 2.40366988137319
Validation loss: 2.4702750577749253

Epoch: 5| Step: 8
Training loss: 2.505100959068219
Validation loss: 2.46983973277887

Epoch: 5| Step: 9
Training loss: 1.984609154530518
Validation loss: 2.46595220131247

Epoch: 5| Step: 10
Training loss: 2.909948313408082
Validation loss: 2.464170538308288

Epoch: 5| Step: 11
Training loss: 1.1972769756930342
Validation loss: 2.4516651158832525

Epoch: 44| Step: 0
Training loss: 2.826724047918122
Validation loss: 2.468812346174178

Epoch: 5| Step: 1
Training loss: 2.31421690431526
Validation loss: 2.476910190664376

Epoch: 5| Step: 2
Training loss: 1.9998916358200995
Validation loss: 2.462805935852909

Epoch: 5| Step: 3
Training loss: 2.7439890972399077
Validation loss: 2.479898418229093

Epoch: 5| Step: 4
Training loss: 2.1865773026108566
Validation loss: 2.4819015609932524

Epoch: 5| Step: 5
Training loss: 2.724952637847036
Validation loss: 2.4702732521396107

Epoch: 5| Step: 6
Training loss: 2.544383509524946
Validation loss: 2.447267260884527

Epoch: 5| Step: 7
Training loss: 1.7673329557396595
Validation loss: 2.4946595172219794

Epoch: 5| Step: 8
Training loss: 2.5015289399697345
Validation loss: 2.4671922428793374

Epoch: 5| Step: 9
Training loss: 1.6086923577356729
Validation loss: 2.449136386847268

Epoch: 5| Step: 10
Training loss: 2.3366361357925003
Validation loss: 2.451129697155638

Epoch: 5| Step: 11
Training loss: 2.7079027762885612
Validation loss: 2.443620224162953

Epoch: 45| Step: 0
Training loss: 2.777170682898897
Validation loss: 2.441460558477992

Epoch: 5| Step: 1
Training loss: 1.782935365794415
Validation loss: 2.435456140414205

Epoch: 5| Step: 2
Training loss: 2.6139974254253993
Validation loss: 2.463319217297738

Epoch: 5| Step: 3
Training loss: 1.8841831394281379
Validation loss: 2.4440539069447986

Epoch: 5| Step: 4
Training loss: 2.63096132484466
Validation loss: 2.421997780917763

Epoch: 5| Step: 5
Training loss: 2.7219831162713177
Validation loss: 2.4519226788635082

Epoch: 5| Step: 6
Training loss: 2.030952314424639
Validation loss: 2.455660807257146

Epoch: 5| Step: 7
Training loss: 3.0579476289125482
Validation loss: 2.445162448605838

Epoch: 5| Step: 8
Training loss: 2.006960439416607
Validation loss: 2.442563609138002

Epoch: 5| Step: 9
Training loss: 2.322606452333644
Validation loss: 2.449793620889112

Epoch: 5| Step: 10
Training loss: 1.6839620448476709
Validation loss: 2.4447170503528857

Epoch: 5| Step: 11
Training loss: 2.607604014003594
Validation loss: 2.450977442351604

Epoch: 46| Step: 0
Training loss: 1.7966443121067297
Validation loss: 2.441463874645462

Epoch: 5| Step: 1
Training loss: 2.17847619529748
Validation loss: 2.446512941228923

Epoch: 5| Step: 2
Training loss: 2.15034128629678
Validation loss: 2.4803873223984216

Epoch: 5| Step: 3
Training loss: 2.246493892685998
Validation loss: 2.484607173859249

Epoch: 5| Step: 4
Training loss: 2.7277656239819144
Validation loss: 2.513337005069523

Epoch: 5| Step: 5
Training loss: 2.1276049635351426
Validation loss: 2.495696341130754

Epoch: 5| Step: 6
Training loss: 2.408517141048738
Validation loss: 2.482239355084882

Epoch: 5| Step: 7
Training loss: 2.753495768804089
Validation loss: 2.473558808575255

Epoch: 5| Step: 8
Training loss: 3.0797627540966523
Validation loss: 2.4945890560714234

Epoch: 5| Step: 9
Training loss: 2.2886786545905196
Validation loss: 2.455209061421958

Epoch: 5| Step: 10
Training loss: 1.9551512926493533
Validation loss: 2.4411252869743185

Epoch: 5| Step: 11
Training loss: 1.2235233047816254
Validation loss: 2.4645416671141622

Epoch: 47| Step: 0
Training loss: 2.3272744487626036
Validation loss: 2.4498781678341017

Epoch: 5| Step: 1
Training loss: 2.160064198634874
Validation loss: 2.4816987159607424

Epoch: 5| Step: 2
Training loss: 2.5874754605074086
Validation loss: 2.4518409332623667

Epoch: 5| Step: 3
Training loss: 2.649855422628514
Validation loss: 2.4521765890243725

Epoch: 5| Step: 4
Training loss: 2.4591506526076152
Validation loss: 2.455710378974791

Epoch: 5| Step: 5
Training loss: 2.1285982521612676
Validation loss: 2.441736855056827

Epoch: 5| Step: 6
Training loss: 1.764386848520729
Validation loss: 2.4544201204047695

Epoch: 5| Step: 7
Training loss: 2.08665105494955
Validation loss: 2.459677810801719

Epoch: 5| Step: 8
Training loss: 1.977810913991812
Validation loss: 2.4467290324020174

Epoch: 5| Step: 9
Training loss: 2.864277123933365
Validation loss: 2.4469688014291773

Epoch: 5| Step: 10
Training loss: 2.4756629826521857
Validation loss: 2.458303351677435

Epoch: 5| Step: 11
Training loss: 2.7445798692053516
Validation loss: 2.4367604682517214

Epoch: 48| Step: 0
Training loss: 2.5394581647845507
Validation loss: 2.4450647758804243

Epoch: 5| Step: 1
Training loss: 1.8321964539177837
Validation loss: 2.4359701074909954

Epoch: 5| Step: 2
Training loss: 2.2979037517646965
Validation loss: 2.454494968490743

Epoch: 5| Step: 3
Training loss: 2.401582525960289
Validation loss: 2.4281536711019216

Epoch: 5| Step: 4
Training loss: 2.411930068297568
Validation loss: 2.462831271104512

Epoch: 5| Step: 5
Training loss: 2.3745098612121307
Validation loss: 2.448120463119301

Epoch: 5| Step: 6
Training loss: 2.8618010354715397
Validation loss: 2.443648835744376

Epoch: 5| Step: 7
Training loss: 2.3025840341348953
Validation loss: 2.438391644668657

Epoch: 5| Step: 8
Training loss: 2.1843686170580248
Validation loss: 2.454173169885729

Epoch: 5| Step: 9
Training loss: 2.049751531848598
Validation loss: 2.430120055525691

Epoch: 5| Step: 10
Training loss: 2.199408351930414
Validation loss: 2.46233698294029

Epoch: 5| Step: 11
Training loss: 2.6230398761715543
Validation loss: 2.4655667719152037

Epoch: 49| Step: 0
Training loss: 1.9107576449354962
Validation loss: 2.470758699337404

Epoch: 5| Step: 1
Training loss: 2.9842441390341814
Validation loss: 2.4580890216226385

Epoch: 5| Step: 2
Training loss: 2.2441447683749285
Validation loss: 2.472796096181709

Epoch: 5| Step: 3
Training loss: 1.775295947480689
Validation loss: 2.457680309707482

Epoch: 5| Step: 4
Training loss: 2.6108698417805116
Validation loss: 2.4589631511730774

Epoch: 5| Step: 5
Training loss: 1.2687132092483182
Validation loss: 2.4491752000067106

Epoch: 5| Step: 6
Training loss: 2.0860072206425255
Validation loss: 2.462634386633141

Epoch: 5| Step: 7
Training loss: 2.2375526507272654
Validation loss: 2.4400052620877917

Epoch: 5| Step: 8
Training loss: 2.697381328556778
Validation loss: 2.4724319983061247

Epoch: 5| Step: 9
Training loss: 2.7488371384475467
Validation loss: 2.4502680030197443

Epoch: 5| Step: 10
Training loss: 2.4983701161261314
Validation loss: 2.450941553731414

Epoch: 5| Step: 11
Training loss: 2.3992519921670845
Validation loss: 2.4784767382301447

Epoch: 50| Step: 0
Training loss: 2.802047379462765
Validation loss: 2.4680124802844468

Epoch: 5| Step: 1
Training loss: 2.42751173132469
Validation loss: 2.450685802964662

Epoch: 5| Step: 2
Training loss: 2.239770417198833
Validation loss: 2.4226378767277796

Epoch: 5| Step: 3
Training loss: 2.290075709328311
Validation loss: 2.4650139001798723

Epoch: 5| Step: 4
Training loss: 1.9345457257437173
Validation loss: 2.451255713823666

Epoch: 5| Step: 5
Training loss: 1.9713886078245209
Validation loss: 2.4569739379020685

Epoch: 5| Step: 6
Training loss: 2.061614106396696
Validation loss: 2.41406722412964

Epoch: 5| Step: 7
Training loss: 2.164752726188271
Validation loss: 2.4736269290541357

Epoch: 5| Step: 8
Training loss: 2.8243087395435733
Validation loss: 2.4379058442967354

Epoch: 5| Step: 9
Training loss: 2.742579244687583
Validation loss: 2.4518955980988757

Epoch: 5| Step: 10
Training loss: 2.0803676350023177
Validation loss: 2.45363160589913

Epoch: 5| Step: 11
Training loss: 1.3924653380786716
Validation loss: 2.455045725654944

Epoch: 51| Step: 0
Training loss: 2.404056788092735
Validation loss: 2.459443239156401

Epoch: 5| Step: 1
Training loss: 2.3490446177760207
Validation loss: 2.4529074493452314

Epoch: 5| Step: 2
Training loss: 2.2773287790634096
Validation loss: 2.5007402476467253

Epoch: 5| Step: 3
Training loss: 2.364507687964941
Validation loss: 2.473586997556543

Epoch: 5| Step: 4
Training loss: 1.940395836806053
Validation loss: 2.4967048466092776

Epoch: 5| Step: 5
Training loss: 2.5654453005567914
Validation loss: 2.4920414629713448

Epoch: 5| Step: 6
Training loss: 2.050583370289611
Validation loss: 2.4669922514457334

Epoch: 5| Step: 7
Training loss: 2.3967617281691167
Validation loss: 2.510618052708424

Epoch: 5| Step: 8
Training loss: 2.3251834181762137
Validation loss: 2.525781745253771

Epoch: 5| Step: 9
Training loss: 1.9416741353274711
Validation loss: 2.4934247233402154

Epoch: 5| Step: 10
Training loss: 2.536637401069454
Validation loss: 2.472693183386056

Epoch: 5| Step: 11
Training loss: 3.453873911293982
Validation loss: 2.445071195288753

Epoch: 52| Step: 0
Training loss: 2.239595090850012
Validation loss: 2.4643977225656735

Epoch: 5| Step: 1
Training loss: 2.365493420024292
Validation loss: 2.4582677013450835

Epoch: 5| Step: 2
Training loss: 2.111476501276274
Validation loss: 2.4131063771511103

Epoch: 5| Step: 3
Training loss: 2.3057479229177043
Validation loss: 2.471801598058271

Epoch: 5| Step: 4
Training loss: 2.158593051950326
Validation loss: 2.440100987750208

Epoch: 5| Step: 5
Training loss: 2.5948217544638714
Validation loss: 2.4531951983343534

Epoch: 5| Step: 6
Training loss: 2.6030076970189207
Validation loss: 2.4491146598895788

Epoch: 5| Step: 7
Training loss: 2.6379120563600758
Validation loss: 2.4674365336106097

Epoch: 5| Step: 8
Training loss: 1.9589083077750893
Validation loss: 2.4511931804729055

Epoch: 5| Step: 9
Training loss: 2.7202203216798866
Validation loss: 2.4247662831446797

Epoch: 5| Step: 10
Training loss: 1.6475194752168705
Validation loss: 2.466641874016925

Epoch: 5| Step: 11
Training loss: 2.3453157408385024
Validation loss: 2.4693774580824597

Epoch: 53| Step: 0
Training loss: 2.2528378286431376
Validation loss: 2.455123577238378

Epoch: 5| Step: 1
Training loss: 2.8015595316405775
Validation loss: 2.455107738040114

Epoch: 5| Step: 2
Training loss: 1.6773678398090368
Validation loss: 2.4576170667199455

Epoch: 5| Step: 3
Training loss: 2.480696636154583
Validation loss: 2.5096082981934105

Epoch: 5| Step: 4
Training loss: 2.386490581488271
Validation loss: 2.5032721682181927

Epoch: 5| Step: 5
Training loss: 2.215509116258851
Validation loss: 2.481578876854609

Epoch: 5| Step: 6
Training loss: 2.502315688534168
Validation loss: 2.474480753835015

Epoch: 5| Step: 7
Training loss: 2.750740905136498
Validation loss: 2.497910283827932

Epoch: 5| Step: 8
Training loss: 1.7915311215013434
Validation loss: 2.471711474932287

Epoch: 5| Step: 9
Training loss: 2.182322014087047
Validation loss: 2.4462301200217444

Epoch: 5| Step: 10
Training loss: 2.2128126192948088
Validation loss: 2.435485708554096

Epoch: 5| Step: 11
Training loss: 2.5304571723260922
Validation loss: 2.459567335461156

Epoch: 54| Step: 0
Training loss: 2.5750356949489515
Validation loss: 2.409532003486492

Epoch: 5| Step: 1
Training loss: 2.3976905479725006
Validation loss: 2.46225523208226

Epoch: 5| Step: 2
Training loss: 2.405828761100939
Validation loss: 2.4567824309992328

Epoch: 5| Step: 3
Training loss: 2.29214790377647
Validation loss: 2.442941232950631

Epoch: 5| Step: 4
Training loss: 2.3749145693220988
Validation loss: 2.462259896024974

Epoch: 5| Step: 5
Training loss: 2.2698900789375207
Validation loss: 2.44775834619949

Epoch: 5| Step: 6
Training loss: 2.026133740317945
Validation loss: 2.47865254550278

Epoch: 5| Step: 7
Training loss: 1.9885816665657563
Validation loss: 2.4647051837258216

Epoch: 5| Step: 8
Training loss: 2.603560496671176
Validation loss: 2.4271308064763675

Epoch: 5| Step: 9
Training loss: 2.0710178541208673
Validation loss: 2.4408932668259253

Epoch: 5| Step: 10
Training loss: 2.381557346644255
Validation loss: 2.4377398535917276

Epoch: 5| Step: 11
Training loss: 2.681778428439905
Validation loss: 2.418187474067959

Epoch: 55| Step: 0
Training loss: 2.5417158611935697
Validation loss: 2.4386208536999674

Epoch: 5| Step: 1
Training loss: 2.004427539028615
Validation loss: 2.458423165657418

Epoch: 5| Step: 2
Training loss: 1.8773986732173435
Validation loss: 2.4616565562109263

Epoch: 5| Step: 3
Training loss: 2.335021793173924
Validation loss: 2.448532949476635

Epoch: 5| Step: 4
Training loss: 2.529619327448891
Validation loss: 2.4311564360481546

Epoch: 5| Step: 5
Training loss: 2.57594734468607
Validation loss: 2.4355996704089646

Epoch: 5| Step: 6
Training loss: 1.7288394603075792
Validation loss: 2.474771849073924

Epoch: 5| Step: 7
Training loss: 1.9595755904856722
Validation loss: 2.4481243545950795

Epoch: 5| Step: 8
Training loss: 2.685794289029258
Validation loss: 2.4834577758596263

Epoch: 5| Step: 9
Training loss: 2.6860402600757047
Validation loss: 2.432271881077499

Epoch: 5| Step: 10
Training loss: 2.170092722761984
Validation loss: 2.4645044422717155

Epoch: 5| Step: 11
Training loss: 2.5344368923546163
Validation loss: 2.4449403782331434

Epoch: 56| Step: 0
Training loss: 2.5523956003985426
Validation loss: 2.4372817088463172

Epoch: 5| Step: 1
Training loss: 2.2150827107368416
Validation loss: 2.42385906862666

Epoch: 5| Step: 2
Training loss: 2.124716571530984
Validation loss: 2.4513795113736885

Epoch: 5| Step: 3
Training loss: 1.7899462919862121
Validation loss: 2.445973762908501

Epoch: 5| Step: 4
Training loss: 2.898422035525625
Validation loss: 2.4331885990989783

Epoch: 5| Step: 5
Training loss: 2.208700173576439
Validation loss: 2.4744131506740703

Epoch: 5| Step: 6
Training loss: 2.181983312946851
Validation loss: 2.477165993005659

Epoch: 5| Step: 7
Training loss: 2.130106904118578
Validation loss: 2.4333618996578577

Epoch: 5| Step: 8
Training loss: 2.070471876235754
Validation loss: 2.4261967481809026

Epoch: 5| Step: 9
Training loss: 2.128264108108081
Validation loss: 2.416476782102289

Epoch: 5| Step: 10
Training loss: 2.840071594249241
Validation loss: 2.436544402190931

Epoch: 5| Step: 11
Training loss: 2.1230035266819978
Validation loss: 2.457878989459919

Epoch: 57| Step: 0
Training loss: 2.194994811831797
Validation loss: 2.4795585904889816

Epoch: 5| Step: 1
Training loss: 2.7848421537639463
Validation loss: 2.4101245698747915

Epoch: 5| Step: 2
Training loss: 1.5758001747186445
Validation loss: 2.4481090118376962

Epoch: 5| Step: 3
Training loss: 2.233044528317337
Validation loss: 2.433478042929732

Epoch: 5| Step: 4
Training loss: 2.7311560293831505
Validation loss: 2.4204448579208204

Epoch: 5| Step: 5
Training loss: 2.52732167536486
Validation loss: 2.4282018160851

Epoch: 5| Step: 6
Training loss: 2.0387820931626996
Validation loss: 2.429721308694778

Epoch: 5| Step: 7
Training loss: 2.226114328353144
Validation loss: 2.4551145297487036

Epoch: 5| Step: 8
Training loss: 2.0371957469854594
Validation loss: 2.4460478338210345

Epoch: 5| Step: 9
Training loss: 2.5356554853502797
Validation loss: 2.4260766427442673

Epoch: 5| Step: 10
Training loss: 2.194414600003049
Validation loss: 2.438658231262922

Epoch: 5| Step: 11
Training loss: 1.1054773229259844
Validation loss: 2.464724292470031

Epoch: 58| Step: 0
Training loss: 1.4879142729306343
Validation loss: 2.4531468878415477

Epoch: 5| Step: 1
Training loss: 2.130820661240324
Validation loss: 2.4829043748076227

Epoch: 5| Step: 2
Training loss: 2.3298421581979967
Validation loss: 2.4680463456074038

Epoch: 5| Step: 3
Training loss: 2.4032844004453215
Validation loss: 2.492297039594319

Epoch: 5| Step: 4
Training loss: 1.9920135422096914
Validation loss: 2.436222165325328

Epoch: 5| Step: 5
Training loss: 2.829023355516375
Validation loss: 2.4521995122855236

Epoch: 5| Step: 6
Training loss: 2.170507425846947
Validation loss: 2.479716493773182

Epoch: 5| Step: 7
Training loss: 2.6966656370439988
Validation loss: 2.455095609219773

Epoch: 5| Step: 8
Training loss: 1.8725810660116695
Validation loss: 2.478739141952477

Epoch: 5| Step: 9
Training loss: 2.6187145731493917
Validation loss: 2.4581119725948817

Epoch: 5| Step: 10
Training loss: 1.8144939898435781
Validation loss: 2.4377429873648895

Epoch: 5| Step: 11
Training loss: 2.989395153401221
Validation loss: 2.4025113096444017

Epoch: 59| Step: 0
Training loss: 2.7918463312286415
Validation loss: 2.447046008737717

Epoch: 5| Step: 1
Training loss: 1.8529095477833897
Validation loss: 2.437992262243322

Epoch: 5| Step: 2
Training loss: 2.661986674939631
Validation loss: 2.4211931601925873

Epoch: 5| Step: 3
Training loss: 2.1355487193393925
Validation loss: 2.4497253607878475

Epoch: 5| Step: 4
Training loss: 1.9779705716519564
Validation loss: 2.4522631036161573

Epoch: 5| Step: 5
Training loss: 2.105797793238539
Validation loss: 2.456238453476341

Epoch: 5| Step: 6
Training loss: 2.1319397199028205
Validation loss: 2.4419066544463024

Epoch: 5| Step: 7
Training loss: 2.456554469682753
Validation loss: 2.450043121269816

Epoch: 5| Step: 8
Training loss: 1.9754513116242016
Validation loss: 2.4327674471179517

Epoch: 5| Step: 9
Training loss: 2.070228431002425
Validation loss: 2.446058047941854

Epoch: 5| Step: 10
Training loss: 2.7390647561759818
Validation loss: 2.413563994753153

Epoch: 5| Step: 11
Training loss: 1.6120877411677657
Validation loss: 2.4587585490960038

Epoch: 60| Step: 0
Training loss: 2.3399645944508842
Validation loss: 2.465175705051761

Epoch: 5| Step: 1
Training loss: 1.9037062134845075
Validation loss: 2.4221380193488744

Epoch: 5| Step: 2
Training loss: 1.774860768834778
Validation loss: 2.457001407444082

Epoch: 5| Step: 3
Training loss: 2.047383136138969
Validation loss: 2.499751175974992

Epoch: 5| Step: 4
Training loss: 2.5250951088093125
Validation loss: 2.496125558840511

Epoch: 5| Step: 5
Training loss: 2.6913607168567624
Validation loss: 2.4883587923448767

Epoch: 5| Step: 6
Training loss: 2.2770912200521254
Validation loss: 2.4526409797446647

Epoch: 5| Step: 7
Training loss: 2.177030413652173
Validation loss: 2.4370669811711307

Epoch: 5| Step: 8
Training loss: 2.2851345485080645
Validation loss: 2.485654807186606

Epoch: 5| Step: 9
Training loss: 2.106129615127947
Validation loss: 2.4840897210391257

Epoch: 5| Step: 10
Training loss: 2.5547014988506938
Validation loss: 2.476033893413055

Epoch: 5| Step: 11
Training loss: 1.8850736218147728
Validation loss: 2.454268527116414

Epoch: 61| Step: 0
Training loss: 2.6321782556539275
Validation loss: 2.424401772011902

Epoch: 5| Step: 1
Training loss: 2.3164281731479957
Validation loss: 2.404526758140404

Epoch: 5| Step: 2
Training loss: 2.091720052496303
Validation loss: 2.4516885868873715

Epoch: 5| Step: 3
Training loss: 2.1877272351632078
Validation loss: 2.448065162104649

Epoch: 5| Step: 4
Training loss: 2.166953899222358
Validation loss: 2.4545024195812175

Epoch: 5| Step: 5
Training loss: 1.7439804088997033
Validation loss: 2.434024815475202

Epoch: 5| Step: 6
Training loss: 2.097009541363855
Validation loss: 2.4487536169690403

Epoch: 5| Step: 7
Training loss: 2.4287440194582968
Validation loss: 2.4192495985026525

Epoch: 5| Step: 8
Training loss: 2.636114477922089
Validation loss: 2.4205032360491563

Epoch: 5| Step: 9
Training loss: 2.4471563145853876
Validation loss: 2.4386055020712987

Epoch: 5| Step: 10
Training loss: 1.7143184752399276
Validation loss: 2.4443872750947095

Epoch: 5| Step: 11
Training loss: 2.285641871310004
Validation loss: 2.4399728722738447

Epoch: 62| Step: 0
Training loss: 1.768616159719899
Validation loss: 2.407159282577213

Epoch: 5| Step: 1
Training loss: 1.9988897937701693
Validation loss: 2.4261664690276747

Epoch: 5| Step: 2
Training loss: 2.442635920792665
Validation loss: 2.3861551051074117

Epoch: 5| Step: 3
Training loss: 2.0743793202694563
Validation loss: 2.4257463379997763

Epoch: 5| Step: 4
Training loss: 2.869197296974763
Validation loss: 2.4123071133880365

Epoch: 5| Step: 5
Training loss: 2.630152414061095
Validation loss: 2.4055640617733633

Epoch: 5| Step: 6
Training loss: 2.4058534369726
Validation loss: 2.4325320794158634

Epoch: 5| Step: 7
Training loss: 2.19360567579975
Validation loss: 2.4552726132428395

Epoch: 5| Step: 8
Training loss: 2.27836133361592
Validation loss: 2.4482379959449956

Epoch: 5| Step: 9
Training loss: 1.7880791372839697
Validation loss: 2.4546361184929433

Epoch: 5| Step: 10
Training loss: 1.717153605438136
Validation loss: 2.4525218068150467

Epoch: 5| Step: 11
Training loss: 3.031953867568885
Validation loss: 2.460596450505682

Epoch: 63| Step: 0
Training loss: 2.0464122918983403
Validation loss: 2.430645078342512

Epoch: 5| Step: 1
Training loss: 2.1860292122329565
Validation loss: 2.4344093829605016

Epoch: 5| Step: 2
Training loss: 2.5936635014461937
Validation loss: 2.4482957843989626

Epoch: 5| Step: 3
Training loss: 1.9671881399236946
Validation loss: 2.3937716749519717

Epoch: 5| Step: 4
Training loss: 2.0168532540041815
Validation loss: 2.4236039583913724

Epoch: 5| Step: 5
Training loss: 2.0257159627507417
Validation loss: 2.4310735079488173

Epoch: 5| Step: 6
Training loss: 2.204021082242463
Validation loss: 2.421117104106575

Epoch: 5| Step: 7
Training loss: 2.1885098987169846
Validation loss: 2.4375537271365646

Epoch: 5| Step: 8
Training loss: 2.7506765920441785
Validation loss: 2.436855145275929

Epoch: 5| Step: 9
Training loss: 2.237275488474346
Validation loss: 2.419071205014098

Epoch: 5| Step: 10
Training loss: 1.831483738795019
Validation loss: 2.4303301281310334

Epoch: 5| Step: 11
Training loss: 3.6212118678904828
Validation loss: 2.4446394200184582

Epoch: 64| Step: 0
Training loss: 2.0805786103806287
Validation loss: 2.395965679632051

Epoch: 5| Step: 1
Training loss: 2.4725764112554884
Validation loss: 2.442631709449887

Epoch: 5| Step: 2
Training loss: 2.1531564386339785
Validation loss: 2.416563226415332

Epoch: 5| Step: 3
Training loss: 2.8577856430702218
Validation loss: 2.43208820763625

Epoch: 5| Step: 4
Training loss: 2.120857689298562
Validation loss: 2.417226364145515

Epoch: 5| Step: 5
Training loss: 1.9006356907562376
Validation loss: 2.4401905705405182

Epoch: 5| Step: 6
Training loss: 2.2722586495428647
Validation loss: 2.4144795642889045

Epoch: 5| Step: 7
Training loss: 1.8866225192405583
Validation loss: 2.398852653069496

Epoch: 5| Step: 8
Training loss: 2.319782235021193
Validation loss: 2.406826439463943

Epoch: 5| Step: 9
Training loss: 2.056601557491892
Validation loss: 2.421946032313058

Epoch: 5| Step: 10
Training loss: 2.3357060040235043
Validation loss: 2.4246977671006675

Epoch: 5| Step: 11
Training loss: 0.48676563790235344
Validation loss: 2.462419800170449

Epoch: 65| Step: 0
Training loss: 2.101375302057016
Validation loss: 2.424877090387128

Epoch: 5| Step: 1
Training loss: 2.4154577081350066
Validation loss: 2.4143076610662684

Epoch: 5| Step: 2
Training loss: 2.1895885850992807
Validation loss: 2.4445909323172446

Epoch: 5| Step: 3
Training loss: 2.5409005891884444
Validation loss: 2.4076064939042996

Epoch: 5| Step: 4
Training loss: 2.5568507190522136
Validation loss: 2.4024430169166457

Epoch: 5| Step: 5
Training loss: 2.199015579189263
Validation loss: 2.4159963448201567

Epoch: 5| Step: 6
Training loss: 2.021726024392598
Validation loss: 2.4304366352113997

Epoch: 5| Step: 7
Training loss: 1.6838200321940202
Validation loss: 2.4192021910774497

Epoch: 5| Step: 8
Training loss: 2.1027777465905415
Validation loss: 2.4316024593437473

Epoch: 5| Step: 9
Training loss: 2.0486813793595435
Validation loss: 2.3716423451639126

Epoch: 5| Step: 10
Training loss: 2.297002983420149
Validation loss: 2.4127070583503407

Epoch: 5| Step: 11
Training loss: 2.709596681600588
Validation loss: 2.391239631611742

Epoch: 66| Step: 0
Training loss: 2.0380559899872117
Validation loss: 2.4023351901762515

Epoch: 5| Step: 1
Training loss: 1.8985308086556811
Validation loss: 2.423056584962499

Epoch: 5| Step: 2
Training loss: 2.011963112813398
Validation loss: 2.432153503175139

Epoch: 5| Step: 3
Training loss: 2.283499666638702
Validation loss: 2.4288893121452095

Epoch: 5| Step: 4
Training loss: 2.250511747019802
Validation loss: 2.4426181847070043

Epoch: 5| Step: 5
Training loss: 2.137953044329337
Validation loss: 2.423995252775353

Epoch: 5| Step: 6
Training loss: 2.343261464383842
Validation loss: 2.4037592576288866

Epoch: 5| Step: 7
Training loss: 2.5952421744944925
Validation loss: 2.4115442105540144

Epoch: 5| Step: 8
Training loss: 2.3265664433022533
Validation loss: 2.4119658516258435

Epoch: 5| Step: 9
Training loss: 1.886900330329586
Validation loss: 2.4195751673558052

Epoch: 5| Step: 10
Training loss: 2.468837881334853
Validation loss: 2.4434862721375445

Epoch: 5| Step: 11
Training loss: 2.098440694913044
Validation loss: 2.4196347591507283

Epoch: 67| Step: 0
Training loss: 2.0051338347100116
Validation loss: 2.47238091758363

Epoch: 5| Step: 1
Training loss: 2.1690497375385416
Validation loss: 2.4584126958051957

Epoch: 5| Step: 2
Training loss: 1.748568221618212
Validation loss: 2.498884409110141

Epoch: 5| Step: 3
Training loss: 2.7272782137844502
Validation loss: 2.473413609549775

Epoch: 5| Step: 4
Training loss: 2.1828784624098594
Validation loss: 2.519392158552706

Epoch: 5| Step: 5
Training loss: 2.0285304717797477
Validation loss: 2.5009181522140707

Epoch: 5| Step: 6
Training loss: 2.522134544885761
Validation loss: 2.497648313221568

Epoch: 5| Step: 7
Training loss: 2.463745743173515
Validation loss: 2.488986591555367

Epoch: 5| Step: 8
Training loss: 1.7238298427798842
Validation loss: 2.4716306591358532

Epoch: 5| Step: 9
Training loss: 2.107253300356365
Validation loss: 2.443207880167441

Epoch: 5| Step: 10
Training loss: 2.3037087641402954
Validation loss: 2.4139144218320165

Epoch: 5| Step: 11
Training loss: 2.872738155787741
Validation loss: 2.407329647392396

Epoch: 68| Step: 0
Training loss: 1.7591483232682361
Validation loss: 2.425868947547287

Epoch: 5| Step: 1
Training loss: 2.6393967881456244
Validation loss: 2.44323184917831

Epoch: 5| Step: 2
Training loss: 2.293302911327465
Validation loss: 2.4270570300618397

Epoch: 5| Step: 3
Training loss: 3.0049748498051403
Validation loss: 2.4145345915536716

Epoch: 5| Step: 4
Training loss: 1.942835997067708
Validation loss: 2.445404451162828

Epoch: 5| Step: 5
Training loss: 1.9794655691275795
Validation loss: 2.468692215512836

Epoch: 5| Step: 6
Training loss: 2.122155698207387
Validation loss: 2.4033727122183324

Epoch: 5| Step: 7
Training loss: 1.862787145203053
Validation loss: 2.4246252871581686

Epoch: 5| Step: 8
Training loss: 1.8357747107225446
Validation loss: 2.4346496634386634

Epoch: 5| Step: 9
Training loss: 2.595587481699006
Validation loss: 2.477505238720269

Epoch: 5| Step: 10
Training loss: 2.2948152817665304
Validation loss: 2.4279554107369634

Epoch: 5| Step: 11
Training loss: 0.9356655292485953
Validation loss: 2.4253517462735923

Epoch: 69| Step: 0
Training loss: 3.0500950157499256
Validation loss: 2.419865131097746

Epoch: 5| Step: 1
Training loss: 1.870674102169349
Validation loss: 2.4417653096966525

Epoch: 5| Step: 2
Training loss: 1.6353511513709846
Validation loss: 2.437668655951104

Epoch: 5| Step: 3
Training loss: 1.5907781980594098
Validation loss: 2.441577288930591

Epoch: 5| Step: 4
Training loss: 1.9038219309572262
Validation loss: 2.4288155277945624

Epoch: 5| Step: 5
Training loss: 1.896889326113754
Validation loss: 2.401416552081367

Epoch: 5| Step: 6
Training loss: 2.1315388771787194
Validation loss: 2.449115205448889

Epoch: 5| Step: 7
Training loss: 2.067749509873838
Validation loss: 2.4482698889130012

Epoch: 5| Step: 8
Training loss: 2.464764238577398
Validation loss: 2.3973793590829633

Epoch: 5| Step: 9
Training loss: 2.4171797985898644
Validation loss: 2.4273307016621737

Epoch: 5| Step: 10
Training loss: 2.320833398167206
Validation loss: 2.415947635879212

Epoch: 5| Step: 11
Training loss: 2.5780704376920465
Validation loss: 2.4192112620027015

Epoch: 70| Step: 0
Training loss: 2.3824817865722268
Validation loss: 2.366944809444797

Epoch: 5| Step: 1
Training loss: 2.3718579237653685
Validation loss: 2.450109600677785

Epoch: 5| Step: 2
Training loss: 2.062529361400265
Validation loss: 2.413635203744596

Epoch: 5| Step: 3
Training loss: 1.9351774877523233
Validation loss: 2.4239910807663163

Epoch: 5| Step: 4
Training loss: 1.8314328385561192
Validation loss: 2.4077562555390215

Epoch: 5| Step: 5
Training loss: 3.078833019331398
Validation loss: 2.4119844741504792

Epoch: 5| Step: 6
Training loss: 2.5494970386620346
Validation loss: 2.4041564925213756

Epoch: 5| Step: 7
Training loss: 2.1310961178351735
Validation loss: 2.397855412595427

Epoch: 5| Step: 8
Training loss: 1.882606526738509
Validation loss: 2.448475065188619

Epoch: 5| Step: 9
Training loss: 1.462809541337041
Validation loss: 2.3934928671278537

Epoch: 5| Step: 10
Training loss: 1.8395963530837554
Validation loss: 2.4074398067544553

Epoch: 5| Step: 11
Training loss: 1.6906122542092972
Validation loss: 2.4578479648690124

Epoch: 71| Step: 0
Training loss: 2.033539406178177
Validation loss: 2.443158506110163

Epoch: 5| Step: 1
Training loss: 2.2687240977424397
Validation loss: 2.4387139594509

Epoch: 5| Step: 2
Training loss: 1.991128976883426
Validation loss: 2.41472295308621

Epoch: 5| Step: 3
Training loss: 2.1047985022144795
Validation loss: 2.417496001783692

Epoch: 5| Step: 4
Training loss: 2.1556088143855643
Validation loss: 2.4057584318264116

Epoch: 5| Step: 5
Training loss: 2.188537133811482
Validation loss: 2.437528968704103

Epoch: 5| Step: 6
Training loss: 2.393742342705095
Validation loss: 2.4103399255175577

Epoch: 5| Step: 7
Training loss: 1.8887615636222903
Validation loss: 2.399946373929822

Epoch: 5| Step: 8
Training loss: 2.431692590119943
Validation loss: 2.43664355188992

Epoch: 5| Step: 9
Training loss: 1.9346799939724266
Validation loss: 2.3901310329350145

Epoch: 5| Step: 10
Training loss: 1.9118636599775234
Validation loss: 2.39180106694761

Epoch: 5| Step: 11
Training loss: 2.99386270904216
Validation loss: 2.4021768816961426

Epoch: 72| Step: 0
Training loss: 2.038347374635599
Validation loss: 2.40873377868596

Epoch: 5| Step: 1
Training loss: 2.1081698895856835
Validation loss: 2.440928139219941

Epoch: 5| Step: 2
Training loss: 2.1704054876391012
Validation loss: 2.4662758626095784

Epoch: 5| Step: 3
Training loss: 1.5721373322075909
Validation loss: 2.4621713845047197

Epoch: 5| Step: 4
Training loss: 2.167477993792938
Validation loss: 2.446906069204685

Epoch: 5| Step: 5
Training loss: 2.2248975451593944
Validation loss: 2.4671725532992195

Epoch: 5| Step: 6
Training loss: 1.8912933681480075
Validation loss: 2.491952813318273

Epoch: 5| Step: 7
Training loss: 1.5371166650776142
Validation loss: 2.4919933893231883

Epoch: 5| Step: 8
Training loss: 2.708301328812303
Validation loss: 2.4561109269707564

Epoch: 5| Step: 9
Training loss: 2.068138045877654
Validation loss: 2.4524401378940976

Epoch: 5| Step: 10
Training loss: 2.6834909566546004
Validation loss: 2.4492817434091907

Epoch: 5| Step: 11
Training loss: 1.5972783544139988
Validation loss: 2.3772309098388695

Epoch: 73| Step: 0
Training loss: 2.460934206036982
Validation loss: 2.431199812350664

Epoch: 5| Step: 1
Training loss: 1.9839885665810222
Validation loss: 2.3918618304233377

Epoch: 5| Step: 2
Training loss: 2.0775092797468035
Validation loss: 2.4079562656490765

Epoch: 5| Step: 3
Training loss: 2.125606450328293
Validation loss: 2.4135831955810896

Epoch: 5| Step: 4
Training loss: 1.622474909325374
Validation loss: 2.4293602930593265

Epoch: 5| Step: 5
Training loss: 2.345908023419866
Validation loss: 2.349918982448438

Epoch: 5| Step: 6
Training loss: 2.2541400120464328
Validation loss: 2.3500131591469025

Epoch: 5| Step: 7
Training loss: 2.0606528593892715
Validation loss: 2.392798781827054

Epoch: 5| Step: 8
Training loss: 2.6403646848679636
Validation loss: 2.4042434376558335

Epoch: 5| Step: 9
Training loss: 1.9462964736789716
Validation loss: 2.3515907911117537

Epoch: 5| Step: 10
Training loss: 1.6899287089146657
Validation loss: 2.388028615247609

Epoch: 5| Step: 11
Training loss: 2.574820417790027
Validation loss: 2.414130040183796

Epoch: 74| Step: 0
Training loss: 1.796779862248731
Validation loss: 2.4045944670125996

Epoch: 5| Step: 1
Training loss: 2.079387883386352
Validation loss: 2.3986127170176217

Epoch: 5| Step: 2
Training loss: 2.299128977001282
Validation loss: 2.41741081953667

Epoch: 5| Step: 3
Training loss: 2.0735280526689475
Validation loss: 2.452278938907499

Epoch: 5| Step: 4
Training loss: 2.265215817036846
Validation loss: 2.4378464648185476

Epoch: 5| Step: 5
Training loss: 2.3341056249559333
Validation loss: 2.448204276591874

Epoch: 5| Step: 6
Training loss: 1.8970977702667757
Validation loss: 2.3929278101310953

Epoch: 5| Step: 7
Training loss: 2.0310189922727595
Validation loss: 2.4057834263725435

Epoch: 5| Step: 8
Training loss: 2.076060366574248
Validation loss: 2.391575792515689

Epoch: 5| Step: 9
Training loss: 2.056358441215277
Validation loss: 2.3835382596582213

Epoch: 5| Step: 10
Training loss: 2.3795472833272484
Validation loss: 2.38992026585754

Epoch: 5| Step: 11
Training loss: 1.2154005927137945
Validation loss: 2.4059622291132747

Epoch: 75| Step: 0
Training loss: 1.9119222079855727
Validation loss: 2.414848956708541

Epoch: 5| Step: 1
Training loss: 2.39714298664965
Validation loss: 2.407698484308596

Epoch: 5| Step: 2
Training loss: 2.250874243539495
Validation loss: 2.3940441264632693

Epoch: 5| Step: 3
Training loss: 1.7851676022358545
Validation loss: 2.3987969782491194

Epoch: 5| Step: 4
Training loss: 1.9851341897878954
Validation loss: 2.4209880763533267

Epoch: 5| Step: 5
Training loss: 1.6782750067982313
Validation loss: 2.3723567445775107

Epoch: 5| Step: 6
Training loss: 2.0505194215298936
Validation loss: 2.412457526200384

Epoch: 5| Step: 7
Training loss: 2.1352140997354305
Validation loss: 2.414243271611628

Epoch: 5| Step: 8
Training loss: 1.4486547642526224
Validation loss: 2.4317946154183923

Epoch: 5| Step: 9
Training loss: 2.56036688246928
Validation loss: 2.3748436801061312

Epoch: 5| Step: 10
Training loss: 2.40005736679816
Validation loss: 2.415922417535012

Epoch: 5| Step: 11
Training loss: 2.8493848036295963
Validation loss: 2.4467090157391684

Epoch: 76| Step: 0
Training loss: 2.0791257585413927
Validation loss: 2.4424396514888307

Epoch: 5| Step: 1
Training loss: 1.7603122145985894
Validation loss: 2.4418469450886304

Epoch: 5| Step: 2
Training loss: 1.8677177793480595
Validation loss: 2.432951310186549

Epoch: 5| Step: 3
Training loss: 2.3828880423156042
Validation loss: 2.3969124077800203

Epoch: 5| Step: 4
Training loss: 2.4159881910957597
Validation loss: 2.3774760874372336

Epoch: 5| Step: 5
Training loss: 1.981791218382516
Validation loss: 2.3833833312968045

Epoch: 5| Step: 6
Training loss: 2.0405990248424573
Validation loss: 2.4035770610312683

Epoch: 5| Step: 7
Training loss: 2.3487995937079407
Validation loss: 2.4202622940572933

Epoch: 5| Step: 8
Training loss: 2.3930074750286954
Validation loss: 2.369536268004854

Epoch: 5| Step: 9
Training loss: 2.0807613772945524
Validation loss: 2.4141628734210756

Epoch: 5| Step: 10
Training loss: 1.7659447304532565
Validation loss: 2.419721942531506

Epoch: 5| Step: 11
Training loss: 0.9874228568064284
Validation loss: 2.36836181234471

Epoch: 77| Step: 0
Training loss: 2.037307627202845
Validation loss: 2.4679660276643687

Epoch: 5| Step: 1
Training loss: 2.418144355276443
Validation loss: 2.439691019382661

Epoch: 5| Step: 2
Training loss: 2.1377298867264583
Validation loss: 2.4555984609264803

Epoch: 5| Step: 3
Training loss: 2.176870734193901
Validation loss: 2.480163273060892

Epoch: 5| Step: 4
Training loss: 2.263032890495486
Validation loss: 2.423660346286801

Epoch: 5| Step: 5
Training loss: 1.4820315685281928
Validation loss: 2.415843495944876

Epoch: 5| Step: 6
Training loss: 1.8934449532452347
Validation loss: 2.426577135980652

Epoch: 5| Step: 7
Training loss: 2.3603774208606323
Validation loss: 2.422504944040104

Epoch: 5| Step: 8
Training loss: 2.4659021103388183
Validation loss: 2.366446757901309

Epoch: 5| Step: 9
Training loss: 1.683096473698585
Validation loss: 2.426143510667316

Epoch: 5| Step: 10
Training loss: 1.5371502455206119
Validation loss: 2.3916739695190516

Epoch: 5| Step: 11
Training loss: 2.991039563885689
Validation loss: 2.43835797656164

Epoch: 78| Step: 0
Training loss: 2.242804146748848
Validation loss: 2.4215022056543813

Epoch: 5| Step: 1
Training loss: 2.284718319916283
Validation loss: 2.4383892511684118

Epoch: 5| Step: 2
Training loss: 2.5554464070420098
Validation loss: 2.453947791835188

Epoch: 5| Step: 3
Training loss: 1.6320092812863265
Validation loss: 2.409244523595328

Epoch: 5| Step: 4
Training loss: 1.9091391634725743
Validation loss: 2.4396460919787177

Epoch: 5| Step: 5
Training loss: 2.0223458780947863
Validation loss: 2.414201845593748

Epoch: 5| Step: 6
Training loss: 1.836356452053139
Validation loss: 2.393199519214872

Epoch: 5| Step: 7
Training loss: 2.0699793133646454
Validation loss: 2.4262651215818565

Epoch: 5| Step: 8
Training loss: 1.9305607599726478
Validation loss: 2.42274946607301

Epoch: 5| Step: 9
Training loss: 2.2157015207525
Validation loss: 2.4294365102120463

Epoch: 5| Step: 10
Training loss: 2.0569742336115198
Validation loss: 2.389364828769443

Epoch: 5| Step: 11
Training loss: 1.1430530571758972
Validation loss: 2.3985427270062623

Epoch: 79| Step: 0
Training loss: 2.0120126454010934
Validation loss: 2.412710850483228

Epoch: 5| Step: 1
Training loss: 2.4533943951651023
Validation loss: 2.397793040222089

Epoch: 5| Step: 2
Training loss: 1.8928815757840285
Validation loss: 2.422780210261047

Epoch: 5| Step: 3
Training loss: 2.3456285196425806
Validation loss: 2.400501518698754

Epoch: 5| Step: 4
Training loss: 2.246310281682341
Validation loss: 2.3966238431548894

Epoch: 5| Step: 5
Training loss: 1.8138805261990036
Validation loss: 2.405644708111494

Epoch: 5| Step: 6
Training loss: 2.0418291870619796
Validation loss: 2.4069970424507408

Epoch: 5| Step: 7
Training loss: 1.779872294570385
Validation loss: 2.3546345648060547

Epoch: 5| Step: 8
Training loss: 1.8105925684886046
Validation loss: 2.4330659256172256

Epoch: 5| Step: 9
Training loss: 1.7083164152222567
Validation loss: 2.406041165161697

Epoch: 5| Step: 10
Training loss: 2.125438869260391
Validation loss: 2.492544704656192

Epoch: 5| Step: 11
Training loss: 2.0273301081850756
Validation loss: 2.4765878589827994

Epoch: 80| Step: 0
Training loss: 2.129808035425078
Validation loss: 2.4740031763663906

Epoch: 5| Step: 1
Training loss: 2.3042451078320147
Validation loss: 2.4369784881358227

Epoch: 5| Step: 2
Training loss: 2.0060804443963978
Validation loss: 2.4278636927597756

Epoch: 5| Step: 3
Training loss: 1.8358415943825102
Validation loss: 2.398346562685962

Epoch: 5| Step: 4
Training loss: 2.2902507106687047
Validation loss: 2.354631189636173

Epoch: 5| Step: 5
Training loss: 1.8020537342735112
Validation loss: 2.4127868112903497

Epoch: 5| Step: 6
Training loss: 1.8510171594179885
Validation loss: 2.358775186820329

Epoch: 5| Step: 7
Training loss: 2.2002015975137708
Validation loss: 2.3942729153035236

Epoch: 5| Step: 8
Training loss: 1.975802731651737
Validation loss: 2.3881528492707815

Epoch: 5| Step: 9
Training loss: 1.5802291590458888
Validation loss: 2.3834625483099834

Epoch: 5| Step: 10
Training loss: 1.95230072938827
Validation loss: 2.3889674338900426

Epoch: 5| Step: 11
Training loss: 2.969792393836275
Validation loss: 2.4275868320616873

Epoch: 81| Step: 0
Training loss: 2.2305484897770285
Validation loss: 2.376272580037668

Epoch: 5| Step: 1
Training loss: 2.439351772282794
Validation loss: 2.4281510895416125

Epoch: 5| Step: 2
Training loss: 1.7005305696435558
Validation loss: 2.3934709484238352

Epoch: 5| Step: 3
Training loss: 2.201751713848779
Validation loss: 2.446405432617872

Epoch: 5| Step: 4
Training loss: 2.320121166419477
Validation loss: 2.4261074000475955

Epoch: 5| Step: 5
Training loss: 1.9038909949066019
Validation loss: 2.513830295047325

Epoch: 5| Step: 6
Training loss: 1.689414880573269
Validation loss: 2.4340805803637067

Epoch: 5| Step: 7
Training loss: 1.6064768501131104
Validation loss: 2.4897552268621403

Epoch: 5| Step: 8
Training loss: 1.8792726789909848
Validation loss: 2.37402067154211

Epoch: 5| Step: 9
Training loss: 1.919581960428237
Validation loss: 2.3806670196996382

Epoch: 5| Step: 10
Training loss: 2.199361738905911
Validation loss: 2.42263467010856

Epoch: 5| Step: 11
Training loss: 1.8887884504442567
Validation loss: 2.4006846004504094

Epoch: 82| Step: 0
Training loss: 1.6341109520211976
Validation loss: 2.3971154569381627

Epoch: 5| Step: 1
Training loss: 1.855908022632172
Validation loss: 2.5319019780934213

Epoch: 5| Step: 2
Training loss: 1.9588091116763593
Validation loss: 2.638253548472653

Epoch: 5| Step: 3
Training loss: 2.179140849595709
Validation loss: 2.5974968041457536

Epoch: 5| Step: 4
Training loss: 1.7913705521964152
Validation loss: 2.656596254706371

Epoch: 5| Step: 5
Training loss: 2.685663083423227
Validation loss: 2.55001641607922

Epoch: 5| Step: 6
Training loss: 1.380250918133276
Validation loss: 2.5119995387389737

Epoch: 5| Step: 7
Training loss: 1.9756233487096666
Validation loss: 2.469976197107453

Epoch: 5| Step: 8
Training loss: 1.6601871263213301
Validation loss: 2.3931063321995203

Epoch: 5| Step: 9
Training loss: 2.3580565147454373
Validation loss: 2.3732324054127028

Epoch: 5| Step: 10
Training loss: 2.2806723921606475
Validation loss: 2.42074374368538

Epoch: 5| Step: 11
Training loss: 3.241883633633162
Validation loss: 2.455614325277756

Epoch: 83| Step: 0
Training loss: 1.974593255857335
Validation loss: 2.44638466613309

Epoch: 5| Step: 1
Training loss: 1.9710154139449714
Validation loss: 2.434976145325904

Epoch: 5| Step: 2
Training loss: 1.8218995735513435
Validation loss: 2.4048732187635404

Epoch: 5| Step: 3
Training loss: 2.170702281469154
Validation loss: 2.3763710590263187

Epoch: 5| Step: 4
Training loss: 1.9910067780559897
Validation loss: 2.392885697505545

Epoch: 5| Step: 5
Training loss: 1.6594115977014074
Validation loss: 2.3692477569719737

Epoch: 5| Step: 6
Training loss: 2.2775044458138614
Validation loss: 2.3722008891291675

Epoch: 5| Step: 7
Training loss: 2.21411669872767
Validation loss: 2.354739061890909

Epoch: 5| Step: 8
Training loss: 1.568354358403792
Validation loss: 2.469009969197795

Epoch: 5| Step: 9
Training loss: 2.377312387791716
Validation loss: 2.451477586950434

Epoch: 5| Step: 10
Training loss: 1.7722013761609108
Validation loss: 2.4321351800825024

Epoch: 5| Step: 11
Training loss: 1.0272734295235748
Validation loss: 2.435501763059348

Epoch: 84| Step: 0
Training loss: 1.8562732759294385
Validation loss: 2.426316681852386

Epoch: 5| Step: 1
Training loss: 1.7628569383570312
Validation loss: 2.4092418083817475

Epoch: 5| Step: 2
Training loss: 1.5204126307415713
Validation loss: 2.427448606768797

Epoch: 5| Step: 3
Training loss: 1.6836800608449893
Validation loss: 2.413487329860591

Epoch: 5| Step: 4
Training loss: 2.1917056390853307
Validation loss: 2.410813261116227

Epoch: 5| Step: 5
Training loss: 1.8841113916742216
Validation loss: 2.401169437696607

Epoch: 5| Step: 6
Training loss: 2.6088240721440368
Validation loss: 2.3548647969271217

Epoch: 5| Step: 7
Training loss: 1.7641894150415867
Validation loss: 2.402492396606947

Epoch: 5| Step: 8
Training loss: 2.0561782592502715
Validation loss: 2.3908313379604045

Epoch: 5| Step: 9
Training loss: 2.0581632160307457
Validation loss: 2.398149497916386

Epoch: 5| Step: 10
Training loss: 1.8647439841283235
Validation loss: 2.3926690324393594

Epoch: 5| Step: 11
Training loss: 1.8490205208076513
Validation loss: 2.408954883566261

Epoch: 85| Step: 0
Training loss: 1.7417080480353373
Validation loss: 2.3832246225968636

Epoch: 5| Step: 1
Training loss: 2.3767744763583494
Validation loss: 2.327149146118995

Epoch: 5| Step: 2
Training loss: 1.7642729316941144
Validation loss: 2.3326465001697714

Epoch: 5| Step: 3
Training loss: 1.9598032189866075
Validation loss: 2.3824713957898416

Epoch: 5| Step: 4
Training loss: 2.3250670351598597
Validation loss: 2.3774230793363884

Epoch: 5| Step: 5
Training loss: 1.483700006505631
Validation loss: 2.419489791427879

Epoch: 5| Step: 6
Training loss: 1.9850283170549199
Validation loss: 2.4096296859426256

Epoch: 5| Step: 7
Training loss: 1.9454617117528585
Validation loss: 2.4845154840507995

Epoch: 5| Step: 8
Training loss: 1.957107572913706
Validation loss: 2.4397050978365216

Epoch: 5| Step: 9
Training loss: 1.82861373758756
Validation loss: 2.3814855497440948

Epoch: 5| Step: 10
Training loss: 1.984722617632565
Validation loss: 2.386387441462728

Epoch: 5| Step: 11
Training loss: 2.2848046187127067
Validation loss: 2.4242746217013704

Epoch: 86| Step: 0
Training loss: 1.98681094622852
Validation loss: 2.4360643503480386

Epoch: 5| Step: 1
Training loss: 2.277014366657434
Validation loss: 2.3961449848871106

Epoch: 5| Step: 2
Training loss: 1.5965957666210278
Validation loss: 2.378470551628646

Epoch: 5| Step: 3
Training loss: 1.862620878457351
Validation loss: 2.3942762345911497

Epoch: 5| Step: 4
Training loss: 1.2560492530720613
Validation loss: 2.3413520010755313

Epoch: 5| Step: 5
Training loss: 1.6185961499248396
Validation loss: 2.4041802765137628

Epoch: 5| Step: 6
Training loss: 2.4556015051584064
Validation loss: 2.3946648955063368

Epoch: 5| Step: 7
Training loss: 1.7726774225361779
Validation loss: 2.400879456563528

Epoch: 5| Step: 8
Training loss: 1.6103001870310687
Validation loss: 2.4026778218867832

Epoch: 5| Step: 9
Training loss: 1.8683507639570667
Validation loss: 2.46859981989485

Epoch: 5| Step: 10
Training loss: 2.3866662052445347
Validation loss: 2.4596884933622825

Epoch: 5| Step: 11
Training loss: 2.8252289839583082
Validation loss: 2.4203750149144163

Epoch: 87| Step: 0
Training loss: 1.8029011394036931
Validation loss: 2.4545965620193932

Epoch: 5| Step: 1
Training loss: 2.176129462219638
Validation loss: 2.4359287471422313

Epoch: 5| Step: 2
Training loss: 2.2381314798414165
Validation loss: 2.4303554320069933

Epoch: 5| Step: 3
Training loss: 1.8953942289916041
Validation loss: 2.4126086316827013

Epoch: 5| Step: 4
Training loss: 1.6656260420633173
Validation loss: 2.449736447658555

Epoch: 5| Step: 5
Training loss: 1.7271579043767251
Validation loss: 2.406090557711369

Epoch: 5| Step: 6
Training loss: 2.0625136403875413
Validation loss: 2.4763965330459374

Epoch: 5| Step: 7
Training loss: 1.8365448292142899
Validation loss: 2.4043787041835483

Epoch: 5| Step: 8
Training loss: 2.0932331870759344
Validation loss: 2.3838448190425945

Epoch: 5| Step: 9
Training loss: 1.7680587199501527
Validation loss: 2.4022026578827673

Epoch: 5| Step: 10
Training loss: 1.6815130205288356
Validation loss: 2.420836359263995

Epoch: 5| Step: 11
Training loss: 0.9289920032596413
Validation loss: 2.3306025543489204

Epoch: 88| Step: 0
Training loss: 1.6735640932955889
Validation loss: 2.3895170806795254

Epoch: 5| Step: 1
Training loss: 2.074321047456821
Validation loss: 2.3844116285617925

Epoch: 5| Step: 2
Training loss: 1.719002583757537
Validation loss: 2.3793776931861017

Epoch: 5| Step: 3
Training loss: 1.9638356832730701
Validation loss: 2.3919154405526823

Epoch: 5| Step: 4
Training loss: 1.762961412458661
Validation loss: 2.3827377286759184

Epoch: 5| Step: 5
Training loss: 1.8024812894741569
Validation loss: 2.415411077636268

Epoch: 5| Step: 6
Training loss: 1.7731195240386644
Validation loss: 2.3845182348303213

Epoch: 5| Step: 7
Training loss: 2.098602024880322
Validation loss: 2.4941404079276848

Epoch: 5| Step: 8
Training loss: 2.2147750709286775
Validation loss: 2.4595997762176207

Epoch: 5| Step: 9
Training loss: 2.396101220675558
Validation loss: 2.443712415837075

Epoch: 5| Step: 10
Training loss: 1.3603024004879634
Validation loss: 2.498660137824547

Epoch: 5| Step: 11
Training loss: 2.1759853849411064
Validation loss: 2.3905450957165213

Epoch: 89| Step: 0
Training loss: 1.4300010629129793
Validation loss: 2.37671687159628

Epoch: 5| Step: 1
Training loss: 1.6477274879766342
Validation loss: 2.4123474127193574

Epoch: 5| Step: 2
Training loss: 1.5957945630549022
Validation loss: 2.4222818012473555

Epoch: 5| Step: 3
Training loss: 1.8533633202704287
Validation loss: 2.417346855883045

Epoch: 5| Step: 4
Training loss: 1.722541995595453
Validation loss: 2.42127808834058

Epoch: 5| Step: 5
Training loss: 1.9290300863321468
Validation loss: 2.3886137378487082

Epoch: 5| Step: 6
Training loss: 1.5834085379692802
Validation loss: 2.359068351674677

Epoch: 5| Step: 7
Training loss: 2.297108022067131
Validation loss: 2.426452687127192

Epoch: 5| Step: 8
Training loss: 2.171256876195057
Validation loss: 2.376659085703936

Epoch: 5| Step: 9
Training loss: 2.1729364888599805
Validation loss: 2.4305183690874603

Epoch: 5| Step: 10
Training loss: 1.7593191514035653
Validation loss: 2.4406331865252335

Epoch: 5| Step: 11
Training loss: 2.7432136028701226
Validation loss: 2.4785563628664247

Epoch: 90| Step: 0
Training loss: 1.8551913726676774
Validation loss: 2.5214095908534055

Epoch: 5| Step: 1
Training loss: 2.1916111053076817
Validation loss: 2.5463997313574462

Epoch: 5| Step: 2
Training loss: 1.4665751486459795
Validation loss: 2.483976234166342

Epoch: 5| Step: 3
Training loss: 1.6354137671702087
Validation loss: 2.430112386597992

Epoch: 5| Step: 4
Training loss: 2.0921225984291434
Validation loss: 2.41508723034959

Epoch: 5| Step: 5
Training loss: 2.0018077071804625
Validation loss: 2.418919431352616

Epoch: 5| Step: 6
Training loss: 1.6306987020870918
Validation loss: 2.4385872335683585

Epoch: 5| Step: 7
Training loss: 1.9335289530059867
Validation loss: 2.4026579633294314

Epoch: 5| Step: 8
Training loss: 1.7396767490302136
Validation loss: 2.39454340140831

Epoch: 5| Step: 9
Training loss: 1.713731270207087
Validation loss: 2.366545526136458

Epoch: 5| Step: 10
Training loss: 1.9861469917642771
Validation loss: 2.363345054416708

Epoch: 5| Step: 11
Training loss: 1.5466642910566393
Validation loss: 2.3760481892994734

Epoch: 91| Step: 0
Training loss: 1.3350045141936713
Validation loss: 2.392355909343417

Epoch: 5| Step: 1
Training loss: 1.9110864663876115
Validation loss: 2.3717370121706383

Epoch: 5| Step: 2
Training loss: 1.5714532305281328
Validation loss: 2.378658968763429

Epoch: 5| Step: 3
Training loss: 2.180675870433772
Validation loss: 2.425039215770358

Epoch: 5| Step: 4
Training loss: 1.7656000861376597
Validation loss: 2.44047737863669

Epoch: 5| Step: 5
Training loss: 1.7871086412438726
Validation loss: 2.442139019671027

Epoch: 5| Step: 6
Training loss: 2.086957018012527
Validation loss: 2.4850897010895694

Epoch: 5| Step: 7
Training loss: 1.6728324644086425
Validation loss: 2.4016619534107617

Epoch: 5| Step: 8
Training loss: 1.8968528130379105
Validation loss: 2.4388964557192394

Epoch: 5| Step: 9
Training loss: 1.302888738131382
Validation loss: 2.394300025450519

Epoch: 5| Step: 10
Training loss: 1.9414511354964321
Validation loss: 2.34832931958048

Epoch: 5| Step: 11
Training loss: 3.282883010680765
Validation loss: 2.4392640789113478

Epoch: 92| Step: 0
Training loss: 1.473260568329382
Validation loss: 2.3496442640530617

Epoch: 5| Step: 1
Training loss: 1.6973570699168254
Validation loss: 2.3965228304877466

Epoch: 5| Step: 2
Training loss: 1.5494445113038475
Validation loss: 2.3792342036649696

Epoch: 5| Step: 3
Training loss: 1.8460704619576944
Validation loss: 2.379901341702837

Epoch: 5| Step: 4
Training loss: 1.498218909460591
Validation loss: 2.4279246747987013

Epoch: 5| Step: 5
Training loss: 2.288025500695632
Validation loss: 2.383257816997884

Epoch: 5| Step: 6
Training loss: 1.85604842918615
Validation loss: 2.432723643453011

Epoch: 5| Step: 7
Training loss: 1.7533130619680624
Validation loss: 2.4675561094426675

Epoch: 5| Step: 8
Training loss: 1.643673707185075
Validation loss: 2.470188454158204

Epoch: 5| Step: 9
Training loss: 2.0893287095337425
Validation loss: 2.5285807652585865

Epoch: 5| Step: 10
Training loss: 1.7308744553425794
Validation loss: 2.526682480743292

Epoch: 5| Step: 11
Training loss: 2.834141522499479
Validation loss: 2.458818718438482

Epoch: 93| Step: 0
Training loss: 1.7118470722328436
Validation loss: 2.45921659092742

Epoch: 5| Step: 1
Training loss: 1.368971962546228
Validation loss: 2.4431294943708886

Epoch: 5| Step: 2
Training loss: 1.678114540451102
Validation loss: 2.403629374559673

Epoch: 5| Step: 3
Training loss: 1.6296485289086258
Validation loss: 2.4181242498911173

Epoch: 5| Step: 4
Training loss: 1.6839570894731883
Validation loss: 2.386703382943104

Epoch: 5| Step: 5
Training loss: 2.016068165875546
Validation loss: 2.4174520693396118

Epoch: 5| Step: 6
Training loss: 1.9004470173857788
Validation loss: 2.431508597143502

Epoch: 5| Step: 7
Training loss: 1.741674920873232
Validation loss: 2.416541171652121

Epoch: 5| Step: 8
Training loss: 1.6126278346052836
Validation loss: 2.4052377156847053

Epoch: 5| Step: 9
Training loss: 2.470779453953125
Validation loss: 2.4718661740961703

Epoch: 5| Step: 10
Training loss: 1.62976980760419
Validation loss: 2.377248707523196

Epoch: 5| Step: 11
Training loss: 1.5817697567936617
Validation loss: 2.471849403297045

Epoch: 94| Step: 0
Training loss: 1.40361683472903
Validation loss: 2.503915359234519

Epoch: 5| Step: 1
Training loss: 1.4650657383878212
Validation loss: 2.5424426423788855

Epoch: 5| Step: 2
Training loss: 1.9937308522802741
Validation loss: 2.4795911783453146

Epoch: 5| Step: 3
Training loss: 1.9434220040355756
Validation loss: 2.484753873713627

Epoch: 5| Step: 4
Training loss: 2.3142462658085017
Validation loss: 2.4559645528161296

Epoch: 5| Step: 5
Training loss: 1.816523197470107
Validation loss: 2.420531671482847

Epoch: 5| Step: 6
Training loss: 1.2769747326441445
Validation loss: 2.3862957535346077

Epoch: 5| Step: 7
Training loss: 1.4705019302848383
Validation loss: 2.451740858447409

Epoch: 5| Step: 8
Training loss: 1.877884108951895
Validation loss: 2.427597369386598

Epoch: 5| Step: 9
Training loss: 1.842638100737116
Validation loss: 2.427546994421942

Epoch: 5| Step: 10
Training loss: 1.756148708042551
Validation loss: 2.377930387252715

Epoch: 5| Step: 11
Training loss: 1.158431392516714
Validation loss: 2.410382400858213

Epoch: 95| Step: 0
Training loss: 1.6150349467367286
Validation loss: 2.411750381669256

Epoch: 5| Step: 1
Training loss: 2.10762403365264
Validation loss: 2.430762458956354

Epoch: 5| Step: 2
Training loss: 1.1330508277380653
Validation loss: 2.4942784879934337

Epoch: 5| Step: 3
Training loss: 1.4066725202110195
Validation loss: 2.43767244796762

Epoch: 5| Step: 4
Training loss: 1.6848771233283844
Validation loss: 2.455240463275344

Epoch: 5| Step: 5
Training loss: 1.6323555484906567
Validation loss: 2.4785321823541038

Epoch: 5| Step: 6
Training loss: 1.220488604197421
Validation loss: 2.495773812307622

Epoch: 5| Step: 7
Training loss: 1.6700258099965664
Validation loss: 2.4586813338245466

Epoch: 5| Step: 8
Training loss: 2.618819635963036
Validation loss: 2.423319014885626

Epoch: 5| Step: 9
Training loss: 1.4365813595668813
Validation loss: 2.4510164087444832

Epoch: 5| Step: 10
Training loss: 1.9747994743627721
Validation loss: 2.418292449664303

Epoch: 5| Step: 11
Training loss: 2.064649098026039
Validation loss: 2.367663475167749

Epoch: 96| Step: 0
Training loss: 1.9724655814606746
Validation loss: 2.3899090449032543

Epoch: 5| Step: 1
Training loss: 1.627095265493303
Validation loss: 2.4362672272280737

Epoch: 5| Step: 2
Training loss: 1.591839861143127
Validation loss: 2.38971648062863

Epoch: 5| Step: 3
Training loss: 1.3087292956852328
Validation loss: 2.4027400943309933

Epoch: 5| Step: 4
Training loss: 2.278640613368277
Validation loss: 2.4641077642611244

Epoch: 5| Step: 5
Training loss: 1.2461460305849157
Validation loss: 2.484492804975117

Epoch: 5| Step: 6
Training loss: 1.5102003096040517
Validation loss: 2.5215461500791863

Epoch: 5| Step: 7
Training loss: 1.6074248414690124
Validation loss: 2.5707830676621457

Epoch: 5| Step: 8
Training loss: 1.5003968349686803
Validation loss: 2.466412479818502

Epoch: 5| Step: 9
Training loss: 2.1639147546234576
Validation loss: 2.4354156034568986

Epoch: 5| Step: 10
Training loss: 1.9383857917192497
Validation loss: 2.418415847880534

Epoch: 5| Step: 11
Training loss: 1.18341496190523
Validation loss: 2.420023717166341

Epoch: 97| Step: 0
Training loss: 1.8572373484058515
Validation loss: 2.486359087882838

Epoch: 5| Step: 1
Training loss: 1.8496651887780644
Validation loss: 2.4442162661609004

Epoch: 5| Step: 2
Training loss: 1.5088861625561236
Validation loss: 2.4488391044558386

Epoch: 5| Step: 3
Training loss: 1.8989468115036614
Validation loss: 2.424425386077506

Epoch: 5| Step: 4
Training loss: 1.3502236498906843
Validation loss: 2.412344289195213

Epoch: 5| Step: 5
Training loss: 1.4734569366241055
Validation loss: 2.44700872884866

Epoch: 5| Step: 6
Training loss: 1.5590559577613474
Validation loss: 2.5926017402652795

Epoch: 5| Step: 7
Training loss: 1.9304040975948498
Validation loss: 2.677638494814062

Epoch: 5| Step: 8
Training loss: 2.225100710014774
Validation loss: 2.6156481718664772

Epoch: 5| Step: 9
Training loss: 1.6852357296511364
Validation loss: 2.5671618010863178

Epoch: 5| Step: 10
Training loss: 1.757304003600039
Validation loss: 2.510706573514664

Epoch: 5| Step: 11
Training loss: 2.985880526922859
Validation loss: 2.4062205473843674

Epoch: 98| Step: 0
Training loss: 1.356397151435329
Validation loss: 2.4509829586427005

Epoch: 5| Step: 1
Training loss: 1.850473977277788
Validation loss: 2.5002085638468654

Epoch: 5| Step: 2
Training loss: 1.784983353203264
Validation loss: 2.57753492403528

Epoch: 5| Step: 3
Training loss: 2.020099021448582
Validation loss: 2.5607452315748187

Epoch: 5| Step: 4
Training loss: 1.4851603789374976
Validation loss: 2.49068303872215

Epoch: 5| Step: 5
Training loss: 1.9869673609018303
Validation loss: 2.455809207931949

Epoch: 5| Step: 6
Training loss: 2.3241455066584376
Validation loss: 2.409849783168383

Epoch: 5| Step: 7
Training loss: 1.1380474806167458
Validation loss: 2.4161123977477987

Epoch: 5| Step: 8
Training loss: 2.2991155997238493
Validation loss: 2.632473751201708

Epoch: 5| Step: 9
Training loss: 1.6261846918924632
Validation loss: 2.724346353284447

Epoch: 5| Step: 10
Training loss: 1.8602081483845194
Validation loss: 2.774367012825383

Epoch: 5| Step: 11
Training loss: 1.7680403131489049
Validation loss: 2.6667801800548863

Epoch: 99| Step: 0
Training loss: 2.2576420597567965
Validation loss: 2.630326600138382

Epoch: 5| Step: 1
Training loss: 1.6500209778116846
Validation loss: 2.4768161583609944

Epoch: 5| Step: 2
Training loss: 1.2592936733292004
Validation loss: 2.4393496057451194

Epoch: 5| Step: 3
Training loss: 2.1408094340596935
Validation loss: 2.42066431856221

Epoch: 5| Step: 4
Training loss: 1.3871028744226461
Validation loss: 2.4269872831950052

Epoch: 5| Step: 5
Training loss: 1.5872834606119586
Validation loss: 2.3434304761308673

Epoch: 5| Step: 6
Training loss: 2.178117740569749
Validation loss: 2.397029264476728

Epoch: 5| Step: 7
Training loss: 1.4105734591011232
Validation loss: 2.324077003494959

Epoch: 5| Step: 8
Training loss: 1.8416419181484214
Validation loss: 2.3557803494576803

Epoch: 5| Step: 9
Training loss: 1.4582608432010216
Validation loss: 2.3814756134699304

Epoch: 5| Step: 10
Training loss: 1.7338374224062723
Validation loss: 2.4093005095040207

Epoch: 5| Step: 11
Training loss: 2.0588888286204683
Validation loss: 2.501531517286478

Epoch: 100| Step: 0
Training loss: 1.4348692663633
Validation loss: 2.527983144844151

Epoch: 5| Step: 1
Training loss: 1.3145796330919297
Validation loss: 2.4306999664699718

Epoch: 5| Step: 2
Training loss: 1.3532270644108488
Validation loss: 2.4644026888127812

Epoch: 5| Step: 3
Training loss: 1.3803558078887017
Validation loss: 2.3892748600062035

Epoch: 5| Step: 4
Training loss: 1.50468286056041
Validation loss: 2.379361986459199

Epoch: 5| Step: 5
Training loss: 1.6870618887257784
Validation loss: 2.3797604259755896

Epoch: 5| Step: 6
Training loss: 2.293312475900653
Validation loss: 2.3362495401068015

Epoch: 5| Step: 7
Training loss: 2.1130730884294273
Validation loss: 2.3686557115226674

Epoch: 5| Step: 8
Training loss: 1.418438373909139
Validation loss: 2.412448749014321

Epoch: 5| Step: 9
Training loss: 1.8648486951962997
Validation loss: 2.387198338083466

Epoch: 5| Step: 10
Training loss: 1.612548292161389
Validation loss: 2.3734740324140784

Epoch: 5| Step: 11
Training loss: 1.019092801698408
Validation loss: 2.3775674657645705

Epoch: 101| Step: 0
Training loss: 1.8815931115022737
Validation loss: 2.403920774071933

Epoch: 5| Step: 1
Training loss: 1.231189335136996
Validation loss: 2.39392626091042

Epoch: 5| Step: 2
Training loss: 1.3147279358583026
Validation loss: 2.472110336488856

Epoch: 5| Step: 3
Training loss: 2.1660057184596493
Validation loss: 2.4511910041376748

Epoch: 5| Step: 4
Training loss: 1.9819478487684878
Validation loss: 2.4778140502737527

Epoch: 5| Step: 5
Training loss: 1.228465553803738
Validation loss: 2.47241648897155

Epoch: 5| Step: 6
Training loss: 1.8580824262076716
Validation loss: 2.489413995184371

Epoch: 5| Step: 7
Training loss: 1.291303224602201
Validation loss: 2.4771827378364986

Epoch: 5| Step: 8
Training loss: 1.8388615474928445
Validation loss: 2.4481848360172958

Epoch: 5| Step: 9
Training loss: 1.442761123003575
Validation loss: 2.4210653612971904

Epoch: 5| Step: 10
Training loss: 1.289229827193404
Validation loss: 2.4491503562483654

Epoch: 5| Step: 11
Training loss: 0.7588560646747285
Validation loss: 2.4501840817460288

Epoch: 102| Step: 0
Training loss: 1.6607369159146899
Validation loss: 2.4392284272518987

Epoch: 5| Step: 1
Training loss: 1.5528491475614743
Validation loss: 2.426154557895477

Epoch: 5| Step: 2
Training loss: 1.5190461862861697
Validation loss: 2.401644340780217

Epoch: 5| Step: 3
Training loss: 1.6634333321065677
Validation loss: 2.444046066314124

Epoch: 5| Step: 4
Training loss: 1.3166785255735056
Validation loss: 2.401997309156515

Epoch: 5| Step: 5
Training loss: 2.082167973421803
Validation loss: 2.433875621230616

Epoch: 5| Step: 6
Training loss: 1.5549175149806354
Validation loss: 2.4140494756748487

Epoch: 5| Step: 7
Training loss: 1.2159308080751328
Validation loss: 2.4475349426242974

Epoch: 5| Step: 8
Training loss: 1.7088892970203848
Validation loss: 2.471866752813304

Epoch: 5| Step: 9
Training loss: 1.596123368057993
Validation loss: 2.457524236518817

Epoch: 5| Step: 10
Training loss: 1.4258177870157989
Validation loss: 2.4528364378286387

Epoch: 5| Step: 11
Training loss: 1.5796782149014645
Validation loss: 2.506036492002866

Epoch: 103| Step: 0
Training loss: 0.9078282392650832
Validation loss: 2.520046370728679

Epoch: 5| Step: 1
Training loss: 1.9624959520431855
Validation loss: 2.5625093700268637

Epoch: 5| Step: 2
Training loss: 1.3590072046584365
Validation loss: 2.570119651508964

Epoch: 5| Step: 3
Training loss: 1.4737048071483179
Validation loss: 2.5047760383598345

Epoch: 5| Step: 4
Training loss: 1.575014807616365
Validation loss: 2.5251683734553754

Epoch: 5| Step: 5
Training loss: 1.365914455089385
Validation loss: 2.5032933755188127

Epoch: 5| Step: 6
Training loss: 1.4793274035450275
Validation loss: 2.5009618816071453

Epoch: 5| Step: 7
Training loss: 1.654349766485862
Validation loss: 2.4109136791622348

Epoch: 5| Step: 8
Training loss: 1.390544331814727
Validation loss: 2.472913119054583

Epoch: 5| Step: 9
Training loss: 2.0745063194459994
Validation loss: 2.468864526788215

Epoch: 5| Step: 10
Training loss: 1.78152068908909
Validation loss: 2.5176690348845066

Epoch: 5| Step: 11
Training loss: 2.3813642259169536
Validation loss: 2.4828419183677104

Epoch: 104| Step: 0
Training loss: 1.6944852999502347
Validation loss: 2.4332827496387748

Epoch: 5| Step: 1
Training loss: 1.3329082745288572
Validation loss: 2.4741210716663633

Epoch: 5| Step: 2
Training loss: 0.985911456941493
Validation loss: 2.480055610913846

Epoch: 5| Step: 3
Training loss: 1.5269025472684825
Validation loss: 2.4952124013233514

Epoch: 5| Step: 4
Training loss: 1.6385503821637333
Validation loss: 2.5658502542578523

Epoch: 5| Step: 5
Training loss: 1.6981828009042093
Validation loss: 2.507229607520241

Epoch: 5| Step: 6
Training loss: 2.2225032814096055
Validation loss: 2.4997578662598867

Epoch: 5| Step: 7
Training loss: 1.6702634941598573
Validation loss: 2.4678938503800407

Epoch: 5| Step: 8
Training loss: 1.5199185934352426
Validation loss: 2.4342521666688586

Epoch: 5| Step: 9
Training loss: 1.341404753446994
Validation loss: 2.4266487368268

Epoch: 5| Step: 10
Training loss: 1.4453054891880215
Validation loss: 2.436460232472315

Epoch: 5| Step: 11
Training loss: 1.7834719803055252
Validation loss: 2.4153013867167683

Epoch: 105| Step: 0
Training loss: 1.483472208244245
Validation loss: 2.448362374142148

Epoch: 5| Step: 1
Training loss: 1.5216264964411046
Validation loss: 2.4860665262890427

Epoch: 5| Step: 2
Training loss: 1.363647280634905
Validation loss: 2.5796634938667085

Epoch: 5| Step: 3
Training loss: 1.3980254093556965
Validation loss: 2.6527000940697687

Epoch: 5| Step: 4
Training loss: 1.6329936241917788
Validation loss: 2.623370743538907

Epoch: 5| Step: 5
Training loss: 1.9868262462508235
Validation loss: 2.495594482158853

Epoch: 5| Step: 6
Training loss: 1.8133932083192865
Validation loss: 2.4555606656131634

Epoch: 5| Step: 7
Training loss: 1.0389576335563213
Validation loss: 2.4077446287880346

Epoch: 5| Step: 8
Training loss: 2.120971676174685
Validation loss: 2.456036020944897

Epoch: 5| Step: 9
Training loss: 1.5616939754534271
Validation loss: 2.4936293095548847

Epoch: 5| Step: 10
Training loss: 1.445087064740241
Validation loss: 2.381501451033618

Epoch: 5| Step: 11
Training loss: 1.8985183133479524
Validation loss: 2.428115608151346

Epoch: 106| Step: 0
Training loss: 1.235380608138035
Validation loss: 2.493876790525826

Epoch: 5| Step: 1
Training loss: 1.3815843548585238
Validation loss: 2.5323305766982895

Epoch: 5| Step: 2
Training loss: 1.4550597733742063
Validation loss: 2.622697338713804

Epoch: 5| Step: 3
Training loss: 1.4728572313690054
Validation loss: 2.7020725818166214

Epoch: 5| Step: 4
Training loss: 1.1379917004287645
Validation loss: 2.7234047180642342

Epoch: 5| Step: 5
Training loss: 1.6949973099048614
Validation loss: 2.5932821058600695

Epoch: 5| Step: 6
Training loss: 1.5540920631700381
Validation loss: 2.56541560391463

Epoch: 5| Step: 7
Training loss: 2.138576669185117
Validation loss: 2.5367274301543135

Epoch: 5| Step: 8
Training loss: 1.645751355539917
Validation loss: 2.4260451275178547

Epoch: 5| Step: 9
Training loss: 1.6100408417396443
Validation loss: 2.460559521263251

Epoch: 5| Step: 10
Training loss: 1.3997249111618986
Validation loss: 2.4450169060648523

Epoch: 5| Step: 11
Training loss: 1.47797895036608
Validation loss: 2.4929158771693656

Epoch: 107| Step: 0
Training loss: 1.021988928273915
Validation loss: 2.4207335622803843

Epoch: 5| Step: 1
Training loss: 1.4165917638536838
Validation loss: 2.445189837546978

Epoch: 5| Step: 2
Training loss: 1.447074352397266
Validation loss: 2.437845486829858

Epoch: 5| Step: 3
Training loss: 1.4485314891159002
Validation loss: 2.515453822470382

Epoch: 5| Step: 4
Training loss: 0.9616549535023683
Validation loss: 2.5693967979469696

Epoch: 5| Step: 5
Training loss: 1.2718494553308783
Validation loss: 2.5463119032570956

Epoch: 5| Step: 6
Training loss: 1.0738580826528112
Validation loss: 2.5617704399643313

Epoch: 5| Step: 7
Training loss: 1.8174247265409524
Validation loss: 2.5413064753556527

Epoch: 5| Step: 8
Training loss: 1.4346777536189532
Validation loss: 2.5879943942012242

Epoch: 5| Step: 9
Training loss: 1.751022925457198
Validation loss: 2.4794752439160623

Epoch: 5| Step: 10
Training loss: 2.220502993675504
Validation loss: 2.4715657332894345

Epoch: 5| Step: 11
Training loss: 2.263438781375567
Validation loss: 2.506827651256483

Epoch: 108| Step: 0
Training loss: 1.3226097031146684
Validation loss: 2.4818873636614547

Epoch: 5| Step: 1
Training loss: 2.0190293298927187
Validation loss: 2.537168144346135

Epoch: 5| Step: 2
Training loss: 1.2476040766537795
Validation loss: 2.556715402463994

Epoch: 5| Step: 3
Training loss: 1.4704341566487453
Validation loss: 2.5237452906866475

Epoch: 5| Step: 4
Training loss: 1.2695184795030772
Validation loss: 2.507259018646755

Epoch: 5| Step: 5
Training loss: 1.9495965442453091
Validation loss: 2.5270150318229536

Epoch: 5| Step: 6
Training loss: 1.626239304034562
Validation loss: 2.6205232229559408

Epoch: 5| Step: 7
Training loss: 1.3379715275493402
Validation loss: 2.429522587452867

Epoch: 5| Step: 8
Training loss: 1.8205372421952062
Validation loss: 2.547949152937175

Epoch: 5| Step: 9
Training loss: 0.9922019777217902
Validation loss: 2.6566433035693944

Epoch: 5| Step: 10
Training loss: 1.0771004604746257
Validation loss: 2.5205493023490044

Epoch: 5| Step: 11
Training loss: 0.767266868013106
Validation loss: 2.521181217863594

Epoch: 109| Step: 0
Training loss: 1.8760854122548145
Validation loss: 2.549445156277098

Epoch: 5| Step: 1
Training loss: 2.0024320597082834
Validation loss: 2.525203071429089

Epoch: 5| Step: 2
Training loss: 1.2245167966464017
Validation loss: 2.528604123406338

Epoch: 5| Step: 3
Training loss: 1.5625823189985386
Validation loss: 2.458432916197563

Epoch: 5| Step: 4
Training loss: 1.4378752840524847
Validation loss: 2.5244974207442783

Epoch: 5| Step: 5
Training loss: 1.4384588278035242
Validation loss: 2.49562692430847

Epoch: 5| Step: 6
Training loss: 1.1701705235331357
Validation loss: 2.5332669475812595

Epoch: 5| Step: 7
Training loss: 1.4981199244229018
Validation loss: 2.556253258657205

Epoch: 5| Step: 8
Training loss: 1.7270919885483689
Validation loss: 2.6082327659301066

Epoch: 5| Step: 9
Training loss: 1.5029494375377517
Validation loss: 2.597328903491468

Epoch: 5| Step: 10
Training loss: 1.266285523785259
Validation loss: 2.6150010840338944

Epoch: 5| Step: 11
Training loss: 0.9967911317278512
Validation loss: 2.5713963914206155

Epoch: 110| Step: 0
Training loss: 1.2195657787530134
Validation loss: 2.542436148424051

Epoch: 5| Step: 1
Training loss: 1.5319575796354847
Validation loss: 2.5128538316701228

Epoch: 5| Step: 2
Training loss: 1.8836646466577098
Validation loss: 2.506848388609251

Epoch: 5| Step: 3
Training loss: 0.9510073353036242
Validation loss: 2.48435013636657

Epoch: 5| Step: 4
Training loss: 1.666771273509113
Validation loss: 2.485158169060208

Epoch: 5| Step: 5
Training loss: 1.242587139213266
Validation loss: 2.4531720414075484

Epoch: 5| Step: 6
Training loss: 1.8560323080218784
Validation loss: 2.459307386025495

Epoch: 5| Step: 7
Training loss: 1.5892965888911161
Validation loss: 2.4456637925411058

Epoch: 5| Step: 8
Training loss: 1.1635130539224514
Validation loss: 2.431104925300638

Epoch: 5| Step: 9
Training loss: 1.3973097702786634
Validation loss: 2.442213607554167

Epoch: 5| Step: 10
Training loss: 1.402550259741871
Validation loss: 2.538131691927692

Epoch: 5| Step: 11
Training loss: 1.115523479554828
Validation loss: 2.485316454046727

Epoch: 111| Step: 0
Training loss: 1.1504705689506654
Validation loss: 2.5328935930628007

Epoch: 5| Step: 1
Training loss: 1.581605981252819
Validation loss: 2.554941713009813

Epoch: 5| Step: 2
Training loss: 1.5370021913571146
Validation loss: 2.5538716583538785

Epoch: 5| Step: 3
Training loss: 1.733471127987297
Validation loss: 2.5069204706775774

Epoch: 5| Step: 4
Training loss: 1.206018807190215
Validation loss: 2.4276357125867505

Epoch: 5| Step: 5
Training loss: 1.292354795242465
Validation loss: 2.392255837668473

Epoch: 5| Step: 6
Training loss: 1.2241161758695338
Validation loss: 2.484101054444714

Epoch: 5| Step: 7
Training loss: 1.2268981960161798
Validation loss: 2.4065432514325233

Epoch: 5| Step: 8
Training loss: 1.328425025710874
Validation loss: 2.490063702088907

Epoch: 5| Step: 9
Training loss: 1.622373512404348
Validation loss: 2.508655628196365

Epoch: 5| Step: 10
Training loss: 1.8552458619211791
Validation loss: 2.4911188666619926

Epoch: 5| Step: 11
Training loss: 1.1081076353964177
Validation loss: 2.563781018781688

Epoch: 112| Step: 0
Training loss: 1.1162156900086107
Validation loss: 2.5125492318866947

Epoch: 5| Step: 1
Training loss: 1.2485861411666606
Validation loss: 2.5704454428198327

Epoch: 5| Step: 2
Training loss: 1.7831051852853161
Validation loss: 2.6479847463824404

Epoch: 5| Step: 3
Training loss: 1.5928245550264137
Validation loss: 2.57674758412929

Epoch: 5| Step: 4
Training loss: 1.5383710518232487
Validation loss: 2.585703661546368

Epoch: 5| Step: 5
Training loss: 0.9234875944592088
Validation loss: 2.541845218973917

Epoch: 5| Step: 6
Training loss: 1.5404487214980782
Validation loss: 2.52095560428866

Epoch: 5| Step: 7
Training loss: 1.550867880604344
Validation loss: 2.533526968274359

Epoch: 5| Step: 8
Training loss: 1.2585410620318478
Validation loss: 2.4881510039236083

Epoch: 5| Step: 9
Training loss: 1.4332546903785333
Validation loss: 2.423891753684089

Epoch: 5| Step: 10
Training loss: 1.1091561974753372
Validation loss: 2.4405873219621825

Epoch: 5| Step: 11
Training loss: 1.0010811802226915
Validation loss: 2.4695066547949054

Epoch: 113| Step: 0
Training loss: 1.4091510095672082
Validation loss: 2.5143770198575273

Epoch: 5| Step: 1
Training loss: 1.327938650184859
Validation loss: 2.5192890849282703

Epoch: 5| Step: 2
Training loss: 1.1182237101141754
Validation loss: 2.5373607508030327

Epoch: 5| Step: 3
Training loss: 1.5349404375032731
Validation loss: 2.52906623878707

Epoch: 5| Step: 4
Training loss: 1.35868181992829
Validation loss: 2.5854695099300637

Epoch: 5| Step: 5
Training loss: 1.4107103606405718
Validation loss: 2.5676052828544687

Epoch: 5| Step: 6
Training loss: 1.1498589574319058
Validation loss: 2.562422782230739

Epoch: 5| Step: 7
Training loss: 1.966221593614029
Validation loss: 2.6808105725179994

Epoch: 5| Step: 8
Training loss: 1.3918746305549998
Validation loss: 2.60321936861817

Epoch: 5| Step: 9
Training loss: 1.131775585339549
Validation loss: 2.558783247047926

Epoch: 5| Step: 10
Training loss: 1.318641960093555
Validation loss: 2.54318194611446

Epoch: 5| Step: 11
Training loss: 1.114353774248887
Validation loss: 2.6300303647605534

Epoch: 114| Step: 0
Training loss: 1.2192030822537225
Validation loss: 2.5523594778226513

Epoch: 5| Step: 1
Training loss: 0.9879411255345282
Validation loss: 2.5732207131500133

Epoch: 5| Step: 2
Training loss: 1.3333070523930333
Validation loss: 2.5345713014540228

Epoch: 5| Step: 3
Training loss: 1.8381805353423462
Validation loss: 2.5362680482606064

Epoch: 5| Step: 4
Training loss: 1.7061409101440987
Validation loss: 2.587544298330298

Epoch: 5| Step: 5
Training loss: 1.3229937893872374
Validation loss: 2.478162258841415

Epoch: 5| Step: 6
Training loss: 1.6119720836806306
Validation loss: 2.549192183840626

Epoch: 5| Step: 7
Training loss: 1.0272333934385782
Validation loss: 2.56395296060025

Epoch: 5| Step: 8
Training loss: 0.949623555336843
Validation loss: 2.533726869674216

Epoch: 5| Step: 9
Training loss: 1.1786043866408462
Validation loss: 2.5569440575642606

Epoch: 5| Step: 10
Training loss: 1.3027800361832431
Validation loss: 2.6092222363189244

Epoch: 5| Step: 11
Training loss: 1.651986085676104
Validation loss: 2.539686124461819

Epoch: 115| Step: 0
Training loss: 1.2050030405156569
Validation loss: 2.5918147592662955

Epoch: 5| Step: 1
Training loss: 1.7230056788903876
Validation loss: 2.6097059515887477

Epoch: 5| Step: 2
Training loss: 1.212220920811075
Validation loss: 2.6387134382135526

Epoch: 5| Step: 3
Training loss: 1.4464857133884403
Validation loss: 2.4618901381842697

Epoch: 5| Step: 4
Training loss: 1.288124066555642
Validation loss: 2.4922159725464126

Epoch: 5| Step: 5
Training loss: 1.16847437500187
Validation loss: 2.5213522153732693

Epoch: 5| Step: 6
Training loss: 1.3389781680531652
Validation loss: 2.5375920268066006

Epoch: 5| Step: 7
Training loss: 1.1372896838422741
Validation loss: 2.5314280090219414

Epoch: 5| Step: 8
Training loss: 1.7611980472263633
Validation loss: 2.5976346466772324

Epoch: 5| Step: 9
Training loss: 1.2519514586724725
Validation loss: 2.6038960939352926

Epoch: 5| Step: 10
Training loss: 1.3309809775594548
Validation loss: 2.515406152829519

Epoch: 5| Step: 11
Training loss: 0.7241481742502418
Validation loss: 2.4733276299409153

Epoch: 116| Step: 0
Training loss: 1.7276782405116489
Validation loss: 2.543553685010367

Epoch: 5| Step: 1
Training loss: 0.9233284500201804
Validation loss: 2.5369675821567017

Epoch: 5| Step: 2
Training loss: 0.9907246115389312
Validation loss: 2.6091736356052677

Epoch: 5| Step: 3
Training loss: 1.2605694239502505
Validation loss: 2.5084046351056166

Epoch: 5| Step: 4
Training loss: 1.8989948349410892
Validation loss: 2.524234614336667

Epoch: 5| Step: 5
Training loss: 1.2531748982909297
Validation loss: 2.5581938064583327

Epoch: 5| Step: 6
Training loss: 1.1448032719883254
Validation loss: 2.50701426144355

Epoch: 5| Step: 7
Training loss: 0.8285880323799393
Validation loss: 2.624701581371329

Epoch: 5| Step: 8
Training loss: 1.5526019345787543
Validation loss: 2.6205088516638537

Epoch: 5| Step: 9
Training loss: 1.6388275472652065
Validation loss: 2.6283310954915517

Epoch: 5| Step: 10
Training loss: 1.352635789848451
Validation loss: 2.657048913077621

Epoch: 5| Step: 11
Training loss: 1.5210837937447015
Validation loss: 2.585499902215829

Epoch: 117| Step: 0
Training loss: 1.433431174391334
Validation loss: 2.4649065697872

Epoch: 5| Step: 1
Training loss: 1.660318954572978
Validation loss: 2.604173056912529

Epoch: 5| Step: 2
Training loss: 1.2929179939380406
Validation loss: 2.558104952259792

Epoch: 5| Step: 3
Training loss: 1.3205646973764558
Validation loss: 2.611290614967406

Epoch: 5| Step: 4
Training loss: 1.560676578865583
Validation loss: 2.6574819438125936

Epoch: 5| Step: 5
Training loss: 1.9059349800339636
Validation loss: 2.5583421462111215

Epoch: 5| Step: 6
Training loss: 1.0960809120954462
Validation loss: 2.565370150232101

Epoch: 5| Step: 7
Training loss: 0.8120751737481855
Validation loss: 2.6689329885660498

Epoch: 5| Step: 8
Training loss: 1.213326834898793
Validation loss: 2.72277817528388

Epoch: 5| Step: 9
Training loss: 1.5716580372017568
Validation loss: 2.768533409436071

Epoch: 5| Step: 10
Training loss: 1.1709287256136576
Validation loss: 2.7348506259517573

Epoch: 5| Step: 11
Training loss: 1.1015329018803142
Validation loss: 2.676624252548212

Epoch: 118| Step: 0
Training loss: 1.379190475089336
Validation loss: 2.6360715886630217

Epoch: 5| Step: 1
Training loss: 0.8227527471245544
Validation loss: 2.504419556848027

Epoch: 5| Step: 2
Training loss: 1.2832504101174207
Validation loss: 2.58005263965465

Epoch: 5| Step: 3
Training loss: 1.4249111917495663
Validation loss: 2.5283155798545445

Epoch: 5| Step: 4
Training loss: 1.3943910501566037
Validation loss: 2.5243821201726186

Epoch: 5| Step: 5
Training loss: 1.500379117103705
Validation loss: 2.5413188709396737

Epoch: 5| Step: 6
Training loss: 1.2400396239194862
Validation loss: 2.588005011567683

Epoch: 5| Step: 7
Training loss: 2.015981125236134
Validation loss: 2.5235428015564314

Epoch: 5| Step: 8
Training loss: 1.3458977767506495
Validation loss: 2.526206281876074

Epoch: 5| Step: 9
Training loss: 1.0792631692831767
Validation loss: 2.6983887113406384

Epoch: 5| Step: 10
Training loss: 1.334277588551746
Validation loss: 2.6265527299543825

Epoch: 5| Step: 11
Training loss: 0.5120213029143785
Validation loss: 2.6988055754383136

Epoch: 119| Step: 0
Training loss: 1.494936821919904
Validation loss: 2.68073984582134

Epoch: 5| Step: 1
Training loss: 1.0977568665135282
Validation loss: 2.7079564908310902

Epoch: 5| Step: 2
Training loss: 1.06756311064797
Validation loss: 2.6159368838761154

Epoch: 5| Step: 3
Training loss: 1.4545305898838838
Validation loss: 2.592392596898846

Epoch: 5| Step: 4
Training loss: 1.5180628725282528
Validation loss: 2.564041683818433

Epoch: 5| Step: 5
Training loss: 1.010860122950444
Validation loss: 2.5913345280987112

Epoch: 5| Step: 6
Training loss: 0.9980497416177032
Validation loss: 2.433365661643673

Epoch: 5| Step: 7
Training loss: 1.4964157833589538
Validation loss: 2.5349565749646796

Epoch: 5| Step: 8
Training loss: 1.5896798314126486
Validation loss: 2.546677154626354

Epoch: 5| Step: 9
Training loss: 1.77282684164367
Validation loss: 2.573795853080218

Epoch: 5| Step: 10
Training loss: 1.3119170392894153
Validation loss: 2.495584681760282

Epoch: 5| Step: 11
Training loss: 1.1323679610830635
Validation loss: 2.5879772742778084

Epoch: 120| Step: 0
Training loss: 1.8208508002565844
Validation loss: 2.571349386069495

Epoch: 5| Step: 1
Training loss: 1.0143513836699898
Validation loss: 2.617075360680834

Epoch: 5| Step: 2
Training loss: 1.4272686450493444
Validation loss: 2.6695801563451433

Epoch: 5| Step: 3
Training loss: 1.1360464303575364
Validation loss: 2.6581457329467773

Epoch: 5| Step: 4
Training loss: 1.3181026406560004
Validation loss: 2.5741401355492135

Epoch: 5| Step: 5
Training loss: 1.2076173612374532
Validation loss: 2.5724017880336016

Epoch: 5| Step: 6
Training loss: 1.3429063322020942
Validation loss: 2.5650973221482616

Epoch: 5| Step: 7
Training loss: 1.1982200514809185
Validation loss: 2.5104790332903546

Epoch: 5| Step: 8
Training loss: 1.2941737711052927
Validation loss: 2.5573788969205165

Epoch: 5| Step: 9
Training loss: 1.565706700917231
Validation loss: 2.5028198075184838

Epoch: 5| Step: 10
Training loss: 1.4850825982290083
Validation loss: 2.4859039791907405

Epoch: 5| Step: 11
Training loss: 1.2456244658274254
Validation loss: 2.5452017172818264

Epoch: 121| Step: 0
Training loss: 1.1959857914377257
Validation loss: 2.5630020060807364

Epoch: 5| Step: 1
Training loss: 1.2470111399736508
Validation loss: 2.665819008532243

Epoch: 5| Step: 2
Training loss: 1.5141936947067642
Validation loss: 2.734034815017441

Epoch: 5| Step: 3
Training loss: 1.6240906004743683
Validation loss: 2.73793133120184

Epoch: 5| Step: 4
Training loss: 1.786731383992485
Validation loss: 2.604149163505225

Epoch: 5| Step: 5
Training loss: 0.929781804791414
Validation loss: 2.583987704327996

Epoch: 5| Step: 6
Training loss: 1.2975474533047242
Validation loss: 2.510443146488149

Epoch: 5| Step: 7
Training loss: 1.3982060416705362
Validation loss: 2.5011701746004493

Epoch: 5| Step: 8
Training loss: 1.6808213066738749
Validation loss: 2.524686502282629

Epoch: 5| Step: 9
Training loss: 1.3731424615832315
Validation loss: 2.5220225474176323

Epoch: 5| Step: 10
Training loss: 0.9921221373647595
Validation loss: 2.5203829466750878

Epoch: 5| Step: 11
Training loss: 1.1811259512379206
Validation loss: 2.5753092330136087

Epoch: 122| Step: 0
Training loss: 0.9787055952344655
Validation loss: 2.6236168343231565

Epoch: 5| Step: 1
Training loss: 1.0009518503999844
Validation loss: 2.5525371472404568

Epoch: 5| Step: 2
Training loss: 1.197644470913389
Validation loss: 2.635494207791973

Epoch: 5| Step: 3
Training loss: 1.2426960222135937
Validation loss: 2.5533366856001054

Epoch: 5| Step: 4
Training loss: 1.1038882006379773
Validation loss: 2.565543220756172

Epoch: 5| Step: 5
Training loss: 1.5894685719644843
Validation loss: 2.541275581904099

Epoch: 5| Step: 6
Training loss: 1.3091974943834588
Validation loss: 2.5195505422400624

Epoch: 5| Step: 7
Training loss: 1.8661305776049326
Validation loss: 2.531414787988074

Epoch: 5| Step: 8
Training loss: 1.2332433027622665
Validation loss: 2.498176251228412

Epoch: 5| Step: 9
Training loss: 0.8799727009743791
Validation loss: 2.5231705869875247

Epoch: 5| Step: 10
Training loss: 1.5655645453988591
Validation loss: 2.582454021582484

Epoch: 5| Step: 11
Training loss: 1.5232326271998515
Validation loss: 2.5153554491592804

Epoch: 123| Step: 0
Training loss: 1.1185392724732295
Validation loss: 2.6537921716672686

Epoch: 5| Step: 1
Training loss: 1.0838427751863031
Validation loss: 2.641944288583492

Epoch: 5| Step: 2
Training loss: 1.0959112884197681
Validation loss: 2.6844322860165155

Epoch: 5| Step: 3
Training loss: 1.5995504254295396
Validation loss: 2.5578496807163686

Epoch: 5| Step: 4
Training loss: 1.3759471058992137
Validation loss: 2.563101938152147

Epoch: 5| Step: 5
Training loss: 1.3658712972439115
Validation loss: 2.473110536904663

Epoch: 5| Step: 6
Training loss: 1.2817591609162435
Validation loss: 2.5508650044997956

Epoch: 5| Step: 7
Training loss: 1.732479537468712
Validation loss: 2.527634015874232

Epoch: 5| Step: 8
Training loss: 1.2510135356314127
Validation loss: 2.5466294121472237

Epoch: 5| Step: 9
Training loss: 0.818745815470245
Validation loss: 2.532671003646816

Epoch: 5| Step: 10
Training loss: 1.3478959906916843
Validation loss: 2.5313992868363835

Epoch: 5| Step: 11
Training loss: 2.2370744950599555
Validation loss: 2.592043288321731

Epoch: 124| Step: 0
Training loss: 1.8077046328372617
Validation loss: 2.619580066293174

Epoch: 5| Step: 1
Training loss: 1.2874739597983385
Validation loss: 2.5821260481998776

Epoch: 5| Step: 2
Training loss: 0.8970101670015408
Validation loss: 2.573189822586461

Epoch: 5| Step: 3
Training loss: 1.0882964276243319
Validation loss: 2.6487320761458957

Epoch: 5| Step: 4
Training loss: 1.2114628298351562
Validation loss: 2.5961700356305624

Epoch: 5| Step: 5
Training loss: 1.040986481163785
Validation loss: 2.638492215748988

Epoch: 5| Step: 6
Training loss: 1.3244327608540105
Validation loss: 2.61179073613759

Epoch: 5| Step: 7
Training loss: 1.1145590425975804
Validation loss: 2.5565069681914836

Epoch: 5| Step: 8
Training loss: 0.8101976124753971
Validation loss: 2.6518295343945764

Epoch: 5| Step: 9
Training loss: 1.3987102562215574
Validation loss: 2.6442796145109195

Epoch: 5| Step: 10
Training loss: 1.4333366974340187
Validation loss: 2.62717984909856

Epoch: 5| Step: 11
Training loss: 1.5657126396456946
Validation loss: 2.6175777552382917

Epoch: 125| Step: 0
Training loss: 1.3620960581735395
Validation loss: 2.6148093051197456

Epoch: 5| Step: 1
Training loss: 0.9957133445649293
Validation loss: 2.6240751703612206

Epoch: 5| Step: 2
Training loss: 1.8178701101049917
Validation loss: 2.5734900300301162

Epoch: 5| Step: 3
Training loss: 1.03011317159136
Validation loss: 2.5109255988442927

Epoch: 5| Step: 4
Training loss: 1.2309094321078968
Validation loss: 2.5949916663492365

Epoch: 5| Step: 5
Training loss: 1.0511313496875447
Validation loss: 2.613048822532989

Epoch: 5| Step: 6
Training loss: 1.3554741587242367
Validation loss: 2.6353683875616047

Epoch: 5| Step: 7
Training loss: 1.189771186885249
Validation loss: 2.6350784059546046

Epoch: 5| Step: 8
Training loss: 1.0346397982943922
Validation loss: 2.5640015699673895

Epoch: 5| Step: 9
Training loss: 1.5295951620566102
Validation loss: 2.656666472453737

Epoch: 5| Step: 10
Training loss: 1.0331268570843464
Validation loss: 2.5739303527653266

Epoch: 5| Step: 11
Training loss: 0.7089737400066468
Validation loss: 2.6093207446946995

Epoch: 126| Step: 0
Training loss: 1.4058419377294107
Validation loss: 2.5120026154636124

Epoch: 5| Step: 1
Training loss: 1.2705500813401338
Validation loss: 2.5528906473019175

Epoch: 5| Step: 2
Training loss: 1.29679732492231
Validation loss: 2.613793950519386

Epoch: 5| Step: 3
Training loss: 1.281376902180578
Validation loss: 2.6142727700984616

Epoch: 5| Step: 4
Training loss: 1.5827967169408754
Validation loss: 2.544484032269049

Epoch: 5| Step: 5
Training loss: 0.7082343640094436
Validation loss: 2.6330742371026727

Epoch: 5| Step: 6
Training loss: 0.8773807426120137
Validation loss: 2.602841533478044

Epoch: 5| Step: 7
Training loss: 1.3706947898230826
Validation loss: 2.6265000492669395

Epoch: 5| Step: 8
Training loss: 1.4064819144704357
Validation loss: 2.569426989854059

Epoch: 5| Step: 9
Training loss: 0.9887269112149382
Validation loss: 2.6142783816695334

Epoch: 5| Step: 10
Training loss: 1.1332194682497363
Validation loss: 2.7199581319319117

Epoch: 5| Step: 11
Training loss: 0.5830376392191687
Validation loss: 2.547472117349101

Epoch: 127| Step: 0
Training loss: 1.2402397576162725
Validation loss: 2.5602533524783735

Epoch: 5| Step: 1
Training loss: 0.7222627135280523
Validation loss: 2.5881797235582753

Epoch: 5| Step: 2
Training loss: 1.1679925310144295
Validation loss: 2.70049224931579

Epoch: 5| Step: 3
Training loss: 0.9097988098041149
Validation loss: 2.664484943296288

Epoch: 5| Step: 4
Training loss: 1.4574473096375982
Validation loss: 2.6698123971762087

Epoch: 5| Step: 5
Training loss: 1.342016699051749
Validation loss: 2.665164630038276

Epoch: 5| Step: 6
Training loss: 1.276259355725586
Validation loss: 2.5893046382312743

Epoch: 5| Step: 7
Training loss: 1.784749925978093
Validation loss: 2.5750247772037054

Epoch: 5| Step: 8
Training loss: 1.1988823633239303
Validation loss: 2.5870263399436704

Epoch: 5| Step: 9
Training loss: 0.8167882144419578
Validation loss: 2.6195361440635416

Epoch: 5| Step: 10
Training loss: 1.0888983341432361
Validation loss: 2.5279965744123607

Epoch: 5| Step: 11
Training loss: 1.1638403046805388
Validation loss: 2.5344794868413745

Epoch: 128| Step: 0
Training loss: 0.8297347132581163
Validation loss: 2.6113262799450734

Epoch: 5| Step: 1
Training loss: 0.9108272256730764
Validation loss: 2.623093495507355

Epoch: 5| Step: 2
Training loss: 1.3191764051777155
Validation loss: 2.7067073905360144

Epoch: 5| Step: 3
Training loss: 1.2161101091625799
Validation loss: 2.665489679608401

Epoch: 5| Step: 4
Training loss: 1.030434372612636
Validation loss: 2.6740119932165367

Epoch: 5| Step: 5
Training loss: 0.9936304788269263
Validation loss: 2.606722178022559

Epoch: 5| Step: 6
Training loss: 1.7480086849878547
Validation loss: 2.5422875292261193

Epoch: 5| Step: 7
Training loss: 1.402900606491542
Validation loss: 2.566017481419517

Epoch: 5| Step: 8
Training loss: 1.1402953729783363
Validation loss: 2.571687769109988

Epoch: 5| Step: 9
Training loss: 1.2971544998665532
Validation loss: 2.537866324336341

Epoch: 5| Step: 10
Training loss: 1.013909931196754
Validation loss: 2.5858061412320366

Epoch: 5| Step: 11
Training loss: 0.5135915715212298
Validation loss: 2.539220979097373

Epoch: 129| Step: 0
Training loss: 0.8742218303881827
Validation loss: 2.5088943611796677

Epoch: 5| Step: 1
Training loss: 1.3276324087944937
Validation loss: 2.519687716729172

Epoch: 5| Step: 2
Training loss: 1.6130700515794378
Validation loss: 2.5749752764147638

Epoch: 5| Step: 3
Training loss: 1.3877324227532644
Validation loss: 2.6261256014766197

Epoch: 5| Step: 4
Training loss: 1.1193713737527033
Validation loss: 2.6199460157930954

Epoch: 5| Step: 5
Training loss: 0.8823772471483471
Validation loss: 2.5567896065897298

Epoch: 5| Step: 6
Training loss: 1.247492516367144
Validation loss: 2.583750380928345

Epoch: 5| Step: 7
Training loss: 1.2241916948066365
Validation loss: 2.689604785182591

Epoch: 5| Step: 8
Training loss: 1.2106012677420332
Validation loss: 2.559073768606751

Epoch: 5| Step: 9
Training loss: 1.0556351536860422
Validation loss: 2.5239921133562513

Epoch: 5| Step: 10
Training loss: 1.1025503612442813
Validation loss: 2.593944392905321

Epoch: 5| Step: 11
Training loss: 1.143975601459631
Validation loss: 2.570038457173325

Epoch: 130| Step: 0
Training loss: 1.083537461538479
Validation loss: 2.5667686883871426

Epoch: 5| Step: 1
Training loss: 0.8912660399888889
Validation loss: 2.5741837286412013

Epoch: 5| Step: 2
Training loss: 1.1010418466347096
Validation loss: 2.6047559751660603

Epoch: 5| Step: 3
Training loss: 1.2440427445216014
Validation loss: 2.63762946330881

Epoch: 5| Step: 4
Training loss: 1.1408278402489291
Validation loss: 2.6504891999667572

Epoch: 5| Step: 5
Training loss: 1.2438619592010052
Validation loss: 2.6011776758845273

Epoch: 5| Step: 6
Training loss: 0.9834004679623868
Validation loss: 2.5929599156104213

Epoch: 5| Step: 7
Training loss: 0.7572351989962008
Validation loss: 2.628136966752164

Epoch: 5| Step: 8
Training loss: 1.2527378616308278
Validation loss: 2.577779230377959

Epoch: 5| Step: 9
Training loss: 1.0633798770723195
Validation loss: 2.5930487592535774

Epoch: 5| Step: 10
Training loss: 1.8187075895103584
Validation loss: 2.583105724572615

Epoch: 5| Step: 11
Training loss: 1.421908619242186
Validation loss: 2.5734154852192037

Epoch: 131| Step: 0
Training loss: 1.0926406684243453
Validation loss: 2.575325160344722

Epoch: 5| Step: 1
Training loss: 0.9597518864022129
Validation loss: 2.5430718326331263

Epoch: 5| Step: 2
Training loss: 1.0670098353739716
Validation loss: 2.7288034915734167

Epoch: 5| Step: 3
Training loss: 1.1305754573631386
Validation loss: 2.614811432654593

Epoch: 5| Step: 4
Training loss: 0.9098332695649723
Validation loss: 2.687211668087212

Epoch: 5| Step: 5
Training loss: 1.2035938686948715
Validation loss: 2.713929349377949

Epoch: 5| Step: 6
Training loss: 1.6425951799194483
Validation loss: 2.551674488301896

Epoch: 5| Step: 7
Training loss: 1.1651626610883279
Validation loss: 2.635269829399966

Epoch: 5| Step: 8
Training loss: 1.3764559666677878
Validation loss: 2.489150681403365

Epoch: 5| Step: 9
Training loss: 1.0654363448427147
Validation loss: 2.562783403929553

Epoch: 5| Step: 10
Training loss: 1.1382891631784076
Validation loss: 2.5159157887020585

Epoch: 5| Step: 11
Training loss: 0.2556902930993684
Validation loss: 2.5625470184261436

Epoch: 132| Step: 0
Training loss: 1.051669514667828
Validation loss: 2.5657887502183208

Epoch: 5| Step: 1
Training loss: 0.7862710203384143
Validation loss: 2.5629191482259883

Epoch: 5| Step: 2
Training loss: 1.227117619361998
Validation loss: 2.5351175110320456

Epoch: 5| Step: 3
Training loss: 1.2949298841133823
Validation loss: 2.5816048459046863

Epoch: 5| Step: 4
Training loss: 1.139489954738019
Validation loss: 2.660806577324762

Epoch: 5| Step: 5
Training loss: 0.938414064483743
Validation loss: 2.603771905860313

Epoch: 5| Step: 6
Training loss: 1.2097515574676017
Validation loss: 2.5485058947408867

Epoch: 5| Step: 7
Training loss: 0.7779663123287787
Validation loss: 2.6161888342808037

Epoch: 5| Step: 8
Training loss: 1.6585402578459625
Validation loss: 2.6675489811271875

Epoch: 5| Step: 9
Training loss: 1.036967179775012
Validation loss: 2.5482781763284543

Epoch: 5| Step: 10
Training loss: 0.8606811654152302
Validation loss: 2.6014170830364143

Epoch: 5| Step: 11
Training loss: 0.8073053830529979
Validation loss: 2.630996913849985

Epoch: 133| Step: 0
Training loss: 1.4554860612102891
Validation loss: 2.6036990368916664

Epoch: 5| Step: 1
Training loss: 1.3450565196502977
Validation loss: 2.599332688202704

Epoch: 5| Step: 2
Training loss: 0.8562830006720852
Validation loss: 2.5411077038489087

Epoch: 5| Step: 3
Training loss: 1.0546899301006436
Validation loss: 2.5362529234119635

Epoch: 5| Step: 4
Training loss: 0.8085413745374053
Validation loss: 2.680714150142072

Epoch: 5| Step: 5
Training loss: 0.887508729435072
Validation loss: 2.64791496620954

Epoch: 5| Step: 6
Training loss: 1.433748408402322
Validation loss: 2.6461406414155895

Epoch: 5| Step: 7
Training loss: 0.876159444747147
Validation loss: 2.6356377577991164

Epoch: 5| Step: 8
Training loss: 1.4206992517711672
Validation loss: 2.723347386882649

Epoch: 5| Step: 9
Training loss: 1.0781338456385312
Validation loss: 2.745223303966797

Epoch: 5| Step: 10
Training loss: 0.6383223670967025
Validation loss: 2.6018974768237184

Epoch: 5| Step: 11
Training loss: 0.8959036880781732
Validation loss: 2.6716571183627966

Epoch: 134| Step: 0
Training loss: 0.9774897331420583
Validation loss: 2.625350902203702

Epoch: 5| Step: 1
Training loss: 1.3642771671044547
Validation loss: 2.6338072047624173

Epoch: 5| Step: 2
Training loss: 1.2505825115957048
Validation loss: 2.5908855281922727

Epoch: 5| Step: 3
Training loss: 1.110500248571898
Validation loss: 2.7290628258166825

Epoch: 5| Step: 4
Training loss: 1.0337280785889764
Validation loss: 2.5990889955342538

Epoch: 5| Step: 5
Training loss: 0.8148181563808176
Validation loss: 2.6439137679375406

Epoch: 5| Step: 6
Training loss: 0.9523731768523426
Validation loss: 2.623644285703012

Epoch: 5| Step: 7
Training loss: 1.068157504743938
Validation loss: 2.583436992062727

Epoch: 5| Step: 8
Training loss: 0.9193171236452425
Validation loss: 2.5984108500472183

Epoch: 5| Step: 9
Training loss: 0.6742900205141584
Validation loss: 2.5590993483593807

Epoch: 5| Step: 10
Training loss: 1.5329616089136335
Validation loss: 2.569329190604808

Epoch: 5| Step: 11
Training loss: 1.211623065449099
Validation loss: 2.651336403721307

Epoch: 135| Step: 0
Training loss: 1.5710455099370015
Validation loss: 2.574502328275481

Epoch: 5| Step: 1
Training loss: 1.0256553090305265
Validation loss: 2.683672115804952

Epoch: 5| Step: 2
Training loss: 0.7668584891160863
Validation loss: 2.542385411388785

Epoch: 5| Step: 3
Training loss: 0.8404403696482814
Validation loss: 2.545482278106148

Epoch: 5| Step: 4
Training loss: 1.4643810304329505
Validation loss: 2.552284660313132

Epoch: 5| Step: 5
Training loss: 1.1689051316063064
Validation loss: 2.6135459503548217

Epoch: 5| Step: 6
Training loss: 0.54346097960156
Validation loss: 2.6456456618445054

Epoch: 5| Step: 7
Training loss: 1.291852209649594
Validation loss: 2.560747958778502

Epoch: 5| Step: 8
Training loss: 1.0152826759323434
Validation loss: 2.610745707661946

Epoch: 5| Step: 9
Training loss: 0.7879674886299671
Validation loss: 2.5656093248453

Epoch: 5| Step: 10
Training loss: 1.146492225321159
Validation loss: 2.621734120218014

Epoch: 5| Step: 11
Training loss: 0.9235297400658696
Validation loss: 2.5807529465047785

Epoch: 136| Step: 0
Training loss: 1.1881744075898801
Validation loss: 2.6309228977689703

Epoch: 5| Step: 1
Training loss: 1.0827351838399315
Validation loss: 2.726400995435462

Epoch: 5| Step: 2
Training loss: 0.9147752770421202
Validation loss: 2.753553976700225

Epoch: 5| Step: 3
Training loss: 1.2113507949887585
Validation loss: 2.7646602377487555

Epoch: 5| Step: 4
Training loss: 0.9886193281457879
Validation loss: 2.708943262867758

Epoch: 5| Step: 5
Training loss: 1.5683868899847466
Validation loss: 2.701231008136623

Epoch: 5| Step: 6
Training loss: 0.9421276636560499
Validation loss: 2.6132953265181165

Epoch: 5| Step: 7
Training loss: 1.0870946852321717
Validation loss: 2.6529224197096046

Epoch: 5| Step: 8
Training loss: 0.9016905563090106
Validation loss: 2.61373920353004

Epoch: 5| Step: 9
Training loss: 1.2183935182024541
Validation loss: 2.6290009676613617

Epoch: 5| Step: 10
Training loss: 0.842606405279649
Validation loss: 2.537074366076652

Epoch: 5| Step: 11
Training loss: 1.04223595639524
Validation loss: 2.6040248139211646

Epoch: 137| Step: 0
Training loss: 1.594744054414556
Validation loss: 2.612760696302123

Epoch: 5| Step: 1
Training loss: 1.0941923064583179
Validation loss: 2.5979632088704254

Epoch: 5| Step: 2
Training loss: 1.3125967262593425
Validation loss: 2.6159759431134098

Epoch: 5| Step: 3
Training loss: 0.8758266495057319
Validation loss: 2.61146659930919

Epoch: 5| Step: 4
Training loss: 1.03743909634076
Validation loss: 2.593620032765583

Epoch: 5| Step: 5
Training loss: 1.03837981778753
Validation loss: 2.6492861323035566

Epoch: 5| Step: 6
Training loss: 1.214546338930753
Validation loss: 2.690606307032356

Epoch: 5| Step: 7
Training loss: 0.9146843123828433
Validation loss: 2.6219842897839745

Epoch: 5| Step: 8
Training loss: 0.9001582046378973
Validation loss: 2.697689475186236

Epoch: 5| Step: 9
Training loss: 0.8944361940211377
Validation loss: 2.601729776161562

Epoch: 5| Step: 10
Training loss: 1.0939646918894732
Validation loss: 2.6078247063931848

Epoch: 5| Step: 11
Training loss: 0.6483341272524146
Validation loss: 2.586119773103371

Epoch: 138| Step: 0
Training loss: 0.9606985399816638
Validation loss: 2.5777700969827797

Epoch: 5| Step: 1
Training loss: 0.7587982923420105
Validation loss: 2.617427071002

Epoch: 5| Step: 2
Training loss: 1.0517168949140874
Validation loss: 2.6322692269074635

Epoch: 5| Step: 3
Training loss: 1.0992527547753637
Validation loss: 2.6836454783511225

Epoch: 5| Step: 4
Training loss: 1.263182602842552
Validation loss: 2.6660550739876987

Epoch: 5| Step: 5
Training loss: 1.0322280638367156
Validation loss: 2.600089969056516

Epoch: 5| Step: 6
Training loss: 0.948686207020059
Validation loss: 2.5959050368135994

Epoch: 5| Step: 7
Training loss: 0.7228717791851494
Validation loss: 2.582288097355017

Epoch: 5| Step: 8
Training loss: 1.492552547839688
Validation loss: 2.50551157812553

Epoch: 5| Step: 9
Training loss: 0.973571836653191
Validation loss: 2.5169816771834186

Epoch: 5| Step: 10
Training loss: 0.8629329893765552
Validation loss: 2.6124201231552977

Epoch: 5| Step: 11
Training loss: 0.4120929226596888
Validation loss: 2.5872496572886168

Epoch: 139| Step: 0
Training loss: 0.9945577709320733
Validation loss: 2.6570761872996504

Epoch: 5| Step: 1
Training loss: 1.0197754782981916
Validation loss: 2.62265078313275

Epoch: 5| Step: 2
Training loss: 1.1010395729721119
Validation loss: 2.6205757982405675

Epoch: 5| Step: 3
Training loss: 0.7314437234655011
Validation loss: 2.712802692376999

Epoch: 5| Step: 4
Training loss: 1.0331989136810145
Validation loss: 2.5788338813693223

Epoch: 5| Step: 5
Training loss: 0.9436488053086634
Validation loss: 2.617917337712488

Epoch: 5| Step: 6
Training loss: 0.7968755983836602
Validation loss: 2.679637382046063

Epoch: 5| Step: 7
Training loss: 1.6347990226296532
Validation loss: 2.613376199454254

Epoch: 5| Step: 8
Training loss: 0.7978391611356427
Validation loss: 2.594333069922829

Epoch: 5| Step: 9
Training loss: 0.9489244232372158
Validation loss: 2.638983037312035

Epoch: 5| Step: 10
Training loss: 1.1817534589884287
Validation loss: 2.632004029822139

Epoch: 5| Step: 11
Training loss: 1.0182024016443962
Validation loss: 2.539158624639025

Epoch: 140| Step: 0
Training loss: 1.0235480911257209
Validation loss: 2.6183873932314574

Epoch: 5| Step: 1
Training loss: 0.8160159259392022
Validation loss: 2.5853061731310962

Epoch: 5| Step: 2
Training loss: 0.8372379775597978
Validation loss: 2.599756150242396

Epoch: 5| Step: 3
Training loss: 0.7692984601644945
Validation loss: 2.6149707724966174

Epoch: 5| Step: 4
Training loss: 1.0110473761772987
Validation loss: 2.6620680800453864

Epoch: 5| Step: 5
Training loss: 1.1461583572411176
Validation loss: 2.6724780259211816

Epoch: 5| Step: 6
Training loss: 1.1147305875577802
Validation loss: 2.5915642935587466

Epoch: 5| Step: 7
Training loss: 0.9863359205485561
Validation loss: 2.5228887695567765

Epoch: 5| Step: 8
Training loss: 1.0444623560643407
Validation loss: 2.7012012927847864

Epoch: 5| Step: 9
Training loss: 1.526677291130733
Validation loss: 2.6168600911937436

Epoch: 5| Step: 10
Training loss: 1.1609059489957123
Validation loss: 2.67794804146075

Epoch: 5| Step: 11
Training loss: 0.2779530963703621
Validation loss: 2.704837587314399

Epoch: 141| Step: 0
Training loss: 0.6270827875314494
Validation loss: 2.634203037065987

Epoch: 5| Step: 1
Training loss: 1.5182314611540828
Validation loss: 2.6274876311930857

Epoch: 5| Step: 2
Training loss: 0.9724165839480907
Validation loss: 2.6826110717570413

Epoch: 5| Step: 3
Training loss: 0.8889208769671897
Validation loss: 2.689924787441289

Epoch: 5| Step: 4
Training loss: 1.160481468368284
Validation loss: 2.6583298002018263

Epoch: 5| Step: 5
Training loss: 0.9144480291629528
Validation loss: 2.605079040283128

Epoch: 5| Step: 6
Training loss: 0.8712287421896423
Validation loss: 2.663172348480097

Epoch: 5| Step: 7
Training loss: 1.243302762309396
Validation loss: 2.649222213636358

Epoch: 5| Step: 8
Training loss: 0.8730373168695188
Validation loss: 2.629117616164657

Epoch: 5| Step: 9
Training loss: 0.8469439559396572
Validation loss: 2.6085798647239575

Epoch: 5| Step: 10
Training loss: 1.1971769564529509
Validation loss: 2.727787853730811

Epoch: 5| Step: 11
Training loss: 0.9434144377187759
Validation loss: 2.701747374187083

Epoch: 142| Step: 0
Training loss: 1.8286584581160061
Validation loss: 2.7969832550352716

Epoch: 5| Step: 1
Training loss: 1.20545649346124
Validation loss: 2.8266418916831877

Epoch: 5| Step: 2
Training loss: 1.0509952483246714
Validation loss: 2.7403594224366388

Epoch: 5| Step: 3
Training loss: 1.1119490834558492
Validation loss: 2.7196975459908592

Epoch: 5| Step: 4
Training loss: 0.8057491743040337
Validation loss: 2.6120924058266684

Epoch: 5| Step: 5
Training loss: 1.1259014438739494
Validation loss: 2.636588628878405

Epoch: 5| Step: 6
Training loss: 0.9041424283647727
Validation loss: 2.62273781423938

Epoch: 5| Step: 7
Training loss: 0.6418915765213496
Validation loss: 2.6496726187727404

Epoch: 5| Step: 8
Training loss: 0.9200260565011804
Validation loss: 2.665089089686007

Epoch: 5| Step: 9
Training loss: 0.9502830347261859
Validation loss: 2.6366577744203386

Epoch: 5| Step: 10
Training loss: 0.9556359532329187
Validation loss: 2.6188643819733817

Epoch: 5| Step: 11
Training loss: 1.3562712918205566
Validation loss: 2.692833059485575

Epoch: 143| Step: 0
Training loss: 0.8148838797733674
Validation loss: 2.5373591240643147

Epoch: 5| Step: 1
Training loss: 0.5427664235730162
Validation loss: 2.570025821301267

Epoch: 5| Step: 2
Training loss: 1.698538457682714
Validation loss: 2.5607240190293763

Epoch: 5| Step: 3
Training loss: 0.8912396903063691
Validation loss: 2.5986102845196135

Epoch: 5| Step: 4
Training loss: 0.8449332805680282
Validation loss: 2.555265367112204

Epoch: 5| Step: 5
Training loss: 0.8666655198114094
Validation loss: 2.54777821320352

Epoch: 5| Step: 6
Training loss: 1.114304029223379
Validation loss: 2.6876178649073825

Epoch: 5| Step: 7
Training loss: 0.7320908268773162
Validation loss: 2.6675572634196048

Epoch: 5| Step: 8
Training loss: 1.0705149104163691
Validation loss: 2.7218230809348833

Epoch: 5| Step: 9
Training loss: 0.8510550990886991
Validation loss: 2.684049583342096

Epoch: 5| Step: 10
Training loss: 1.0132984215804188
Validation loss: 2.6842351791921524

Epoch: 5| Step: 11
Training loss: 0.2659869812991932
Validation loss: 2.702002922710661

Epoch: 144| Step: 0
Training loss: 1.033073143093173
Validation loss: 2.6799599682311417

Epoch: 5| Step: 1
Training loss: 0.9826790262628593
Validation loss: 2.652726126642894

Epoch: 5| Step: 2
Training loss: 1.00044735200642
Validation loss: 2.7015855076672253

Epoch: 5| Step: 3
Training loss: 0.8512748092307448
Validation loss: 2.753811088342724

Epoch: 5| Step: 4
Training loss: 1.0149697170531908
Validation loss: 2.647949522631454

Epoch: 5| Step: 5
Training loss: 0.850258064364129
Validation loss: 2.706406727247121

Epoch: 5| Step: 6
Training loss: 1.4349643070154907
Validation loss: 2.6364929761887685

Epoch: 5| Step: 7
Training loss: 0.7429838626259174
Validation loss: 2.5641528009649943

Epoch: 5| Step: 8
Training loss: 0.7950998617827255
Validation loss: 2.6299466327110474

Epoch: 5| Step: 9
Training loss: 1.0418959111047135
Validation loss: 2.637449160533344

Epoch: 5| Step: 10
Training loss: 0.8048262245078615
Validation loss: 2.6296509419659846

Epoch: 5| Step: 11
Training loss: 1.0563909267334886
Validation loss: 2.655741613019371

Epoch: 145| Step: 0
Training loss: 1.1133650898734875
Validation loss: 2.640084062656406

Epoch: 5| Step: 1
Training loss: 1.1546969938597675
Validation loss: 2.6936594146107224

Epoch: 5| Step: 2
Training loss: 0.7013859966478633
Validation loss: 2.6123650488608936

Epoch: 5| Step: 3
Training loss: 0.6982306419431715
Validation loss: 2.5644074663764047

Epoch: 5| Step: 4
Training loss: 0.8493467078363566
Validation loss: 2.641957716045893

Epoch: 5| Step: 5
Training loss: 1.4533848683963906
Validation loss: 2.6263277805617617

Epoch: 5| Step: 6
Training loss: 0.6569467433511065
Validation loss: 2.588181489157408

Epoch: 5| Step: 7
Training loss: 1.073564364781059
Validation loss: 2.634803750959635

Epoch: 5| Step: 8
Training loss: 0.7370664097848758
Validation loss: 2.731562688635704

Epoch: 5| Step: 9
Training loss: 0.9813657206435664
Validation loss: 2.58348451961582

Epoch: 5| Step: 10
Training loss: 0.9216347720839958
Validation loss: 2.665135675517013

Epoch: 5| Step: 11
Training loss: 0.8171350611825479
Validation loss: 2.684316520216751

Epoch: 146| Step: 0
Training loss: 0.8863132574751896
Validation loss: 2.7218313805654093

Epoch: 5| Step: 1
Training loss: 0.8387117075244765
Validation loss: 2.6647586379098054

Epoch: 5| Step: 2
Training loss: 1.4892982352352169
Validation loss: 2.5474816206424107

Epoch: 5| Step: 3
Training loss: 0.7521513046095096
Validation loss: 2.713986165743497

Epoch: 5| Step: 4
Training loss: 0.7612894266626697
Validation loss: 2.5971394801658687

Epoch: 5| Step: 5
Training loss: 1.1167957179145918
Validation loss: 2.6714969910443997

Epoch: 5| Step: 6
Training loss: 0.9930580405150106
Validation loss: 2.6651919479381307

Epoch: 5| Step: 7
Training loss: 0.6161355578569918
Validation loss: 2.644882851183513

Epoch: 5| Step: 8
Training loss: 0.9383489261966809
Validation loss: 2.6109173531766117

Epoch: 5| Step: 9
Training loss: 0.696336078527757
Validation loss: 2.685242913817391

Epoch: 5| Step: 10
Training loss: 1.0644819063267796
Validation loss: 2.6991943343549294

Epoch: 5| Step: 11
Training loss: 0.35828795016279474
Validation loss: 2.735298133518049

Epoch: 147| Step: 0
Training loss: 0.8384551878381064
Validation loss: 2.7242014079320946

Epoch: 5| Step: 1
Training loss: 1.480314141003418
Validation loss: 2.6416628150631074

Epoch: 5| Step: 2
Training loss: 0.9382549425132669
Validation loss: 2.671705530603425

Epoch: 5| Step: 3
Training loss: 0.9103289591764356
Validation loss: 2.720932700025622

Epoch: 5| Step: 4
Training loss: 0.538466220517029
Validation loss: 2.69132963753422

Epoch: 5| Step: 5
Training loss: 1.1281878023287184
Validation loss: 2.648142262734831

Epoch: 5| Step: 6
Training loss: 0.7809859020167168
Validation loss: 2.6019521732631152

Epoch: 5| Step: 7
Training loss: 0.6172559917448059
Validation loss: 2.6243288680853065

Epoch: 5| Step: 8
Training loss: 1.0591392659910683
Validation loss: 2.6240393152242807

Epoch: 5| Step: 9
Training loss: 0.8302849366103583
Validation loss: 2.7203696494514724

Epoch: 5| Step: 10
Training loss: 1.0805817407760208
Validation loss: 2.6549932536166985

Epoch: 5| Step: 11
Training loss: 0.638196996126365
Validation loss: 2.596733139576347

Epoch: 148| Step: 0
Training loss: 0.8165382388073263
Validation loss: 2.6607371408828673

Epoch: 5| Step: 1
Training loss: 0.6964917416271245
Validation loss: 2.7242338844712526

Epoch: 5| Step: 2
Training loss: 1.4060447119173365
Validation loss: 2.707104691559205

Epoch: 5| Step: 3
Training loss: 1.0566797725173596
Validation loss: 2.7245088182713726

Epoch: 5| Step: 4
Training loss: 0.8647913433623592
Validation loss: 2.68542981441723

Epoch: 5| Step: 5
Training loss: 0.9386041814466675
Validation loss: 2.6610997711836846

Epoch: 5| Step: 6
Training loss: 1.054243149577502
Validation loss: 2.661209753014967

Epoch: 5| Step: 7
Training loss: 0.680239004248844
Validation loss: 2.64741738026884

Epoch: 5| Step: 8
Training loss: 1.137747178102907
Validation loss: 2.7612407294008814

Epoch: 5| Step: 9
Training loss: 0.7777565478273348
Validation loss: 2.6821845221492753

Epoch: 5| Step: 10
Training loss: 0.956686744185735
Validation loss: 2.6086510664820075

Epoch: 5| Step: 11
Training loss: 0.8970703337619745
Validation loss: 2.609758893248744

Epoch: 149| Step: 0
Training loss: 0.7880028890082366
Validation loss: 2.7690116778759233

Epoch: 5| Step: 1
Training loss: 1.0646188589440524
Validation loss: 2.8624883701471346

Epoch: 5| Step: 2
Training loss: 1.1012075948182414
Validation loss: 2.8859800736626546

Epoch: 5| Step: 3
Training loss: 0.7348027302581741
Validation loss: 2.8170360190876456

Epoch: 5| Step: 4
Training loss: 1.450649490905742
Validation loss: 2.7031584353574964

Epoch: 5| Step: 5
Training loss: 0.7366200078526108
Validation loss: 2.577462554364254

Epoch: 5| Step: 6
Training loss: 0.9034151594526333
Validation loss: 2.5998859406480754

Epoch: 5| Step: 7
Training loss: 1.2072501863600729
Validation loss: 2.7144319400353165

Epoch: 5| Step: 8
Training loss: 1.482000600189211
Validation loss: 2.7407738681786085

Epoch: 5| Step: 9
Training loss: 0.7766706149638046
Validation loss: 2.6806566508132206

Epoch: 5| Step: 10
Training loss: 1.0524610967989594
Validation loss: 2.607769203626586

Epoch: 5| Step: 11
Training loss: 0.8662532894958307
Validation loss: 2.7242902780807237

Epoch: 150| Step: 0
Training loss: 1.2470950704460486
Validation loss: 2.7445732599234463

Epoch: 5| Step: 1
Training loss: 0.9393654066599758
Validation loss: 2.735473310509233

Epoch: 5| Step: 2
Training loss: 0.9711915289954045
Validation loss: 2.7311798137605905

Epoch: 5| Step: 3
Training loss: 1.3802636573307903
Validation loss: 2.672901848573312

Epoch: 5| Step: 4
Training loss: 0.8497016242797526
Validation loss: 2.5517829341943834

Epoch: 5| Step: 5
Training loss: 0.870381222105652
Validation loss: 2.5567764448201578

Epoch: 5| Step: 6
Training loss: 0.867684677155702
Validation loss: 2.5830942025307357

Epoch: 5| Step: 7
Training loss: 0.8691631871413175
Validation loss: 2.574571889177002

Epoch: 5| Step: 8
Training loss: 0.8439366169582839
Validation loss: 2.5462375225322607

Epoch: 5| Step: 9
Training loss: 0.6867523028929113
Validation loss: 2.5306515830086727

Epoch: 5| Step: 10
Training loss: 0.7639534667683364
Validation loss: 2.5471822381709175

Epoch: 5| Step: 11
Training loss: 0.5199794986699899
Validation loss: 2.5745775226499252

Epoch: 151| Step: 0
Training loss: 0.7086821192910474
Validation loss: 2.5782635969419143

Epoch: 5| Step: 1
Training loss: 1.000283975811224
Validation loss: 2.670884013674585

Epoch: 5| Step: 2
Training loss: 1.287470163536643
Validation loss: 2.576574514379148

Epoch: 5| Step: 3
Training loss: 0.6223752458644304
Validation loss: 2.631482625163667

Epoch: 5| Step: 4
Training loss: 0.9356399840210678
Validation loss: 2.679511684511124

Epoch: 5| Step: 5
Training loss: 0.6542868086766462
Validation loss: 2.735611924647214

Epoch: 5| Step: 6
Training loss: 0.733315088485848
Validation loss: 2.61440204407264

Epoch: 5| Step: 7
Training loss: 1.0628272281962103
Validation loss: 2.672768519650106

Epoch: 5| Step: 8
Training loss: 1.5344512330053235
Validation loss: 2.6236426386283207

Epoch: 5| Step: 9
Training loss: 0.7221093660193862
Validation loss: 2.666509783247673

Epoch: 5| Step: 10
Training loss: 0.9790330687481673
Validation loss: 2.6834993304171295

Epoch: 5| Step: 11
Training loss: 0.6239252863959779
Validation loss: 2.6937496759129775

Epoch: 152| Step: 0
Training loss: 0.5761477449181138
Validation loss: 2.720602171942549

Epoch: 5| Step: 1
Training loss: 0.8196768341359468
Validation loss: 2.6306950273087915

Epoch: 5| Step: 2
Training loss: 0.6198974219957663
Validation loss: 2.567237425226001

Epoch: 5| Step: 3
Training loss: 0.8357258109752376
Validation loss: 2.6144713242286532

Epoch: 5| Step: 4
Training loss: 1.6120350159895687
Validation loss: 2.6215889240794072

Epoch: 5| Step: 5
Training loss: 0.956155524230536
Validation loss: 2.650886517364655

Epoch: 5| Step: 6
Training loss: 1.0962710073409105
Validation loss: 2.610499617457902

Epoch: 5| Step: 7
Training loss: 0.7464995553845093
Validation loss: 2.6404545407325153

Epoch: 5| Step: 8
Training loss: 0.7801498678088833
Validation loss: 2.6211682691370504

Epoch: 5| Step: 9
Training loss: 0.723206099542915
Validation loss: 2.5668393896453483

Epoch: 5| Step: 10
Training loss: 0.7237888430514207
Validation loss: 2.5689292826587806

Epoch: 5| Step: 11
Training loss: 1.4543219118219894
Validation loss: 2.5976052109525174

Epoch: 153| Step: 0
Training loss: 0.8926862321489551
Validation loss: 2.5381719661006636

Epoch: 5| Step: 1
Training loss: 0.8497440275278099
Validation loss: 2.586665451528405

Epoch: 5| Step: 2
Training loss: 0.6617850350392707
Validation loss: 2.5964086113019667

Epoch: 5| Step: 3
Training loss: 1.2229228353696793
Validation loss: 2.583543516396846

Epoch: 5| Step: 4
Training loss: 1.0064459710588156
Validation loss: 2.6778802365921943

Epoch: 5| Step: 5
Training loss: 1.4626509466279891
Validation loss: 2.7203407603108207

Epoch: 5| Step: 6
Training loss: 0.6975764161639154
Validation loss: 2.740013137191873

Epoch: 5| Step: 7
Training loss: 0.6865919575472715
Validation loss: 2.6987325448500474

Epoch: 5| Step: 8
Training loss: 0.9604517631710386
Validation loss: 2.7472355414662224

Epoch: 5| Step: 9
Training loss: 0.8790877769353809
Validation loss: 2.7280904374440342

Epoch: 5| Step: 10
Training loss: 0.8011199979014365
Validation loss: 2.6974330392527803

Epoch: 5| Step: 11
Training loss: 0.8814373953404757
Validation loss: 2.674730678470855

Epoch: 154| Step: 0
Training loss: 0.6891315780234359
Validation loss: 2.6826295670690175

Epoch: 5| Step: 1
Training loss: 1.0172204617317762
Validation loss: 2.632724734087689

Epoch: 5| Step: 2
Training loss: 0.6145382530575734
Validation loss: 2.673233122067142

Epoch: 5| Step: 3
Training loss: 1.102796850485277
Validation loss: 2.632216562503709

Epoch: 5| Step: 4
Training loss: 0.8417782526987816
Validation loss: 2.7206557197393413

Epoch: 5| Step: 5
Training loss: 0.9331953723021776
Validation loss: 2.7427035332529206

Epoch: 5| Step: 6
Training loss: 1.368388406030134
Validation loss: 2.703701858121304

Epoch: 5| Step: 7
Training loss: 0.8211466589812263
Validation loss: 2.717182324963746

Epoch: 5| Step: 8
Training loss: 0.6845601471542092
Validation loss: 2.6151770579994453

Epoch: 5| Step: 9
Training loss: 0.9616321441055761
Validation loss: 2.583224084041213

Epoch: 5| Step: 10
Training loss: 0.8712070203274959
Validation loss: 2.650807748203592

Epoch: 5| Step: 11
Training loss: 0.432395206445754
Validation loss: 2.5843261315900516

Epoch: 155| Step: 0
Training loss: 0.945841995625314
Validation loss: 2.627668761161022

Epoch: 5| Step: 1
Training loss: 1.1385734607181304
Validation loss: 2.6310210354117647

Epoch: 5| Step: 2
Training loss: 0.5975102763708796
Validation loss: 2.556235828997716

Epoch: 5| Step: 3
Training loss: 0.8490038588473238
Validation loss: 2.6667468510930386

Epoch: 5| Step: 4
Training loss: 1.0351804334586672
Validation loss: 2.7837289057005057

Epoch: 5| Step: 5
Training loss: 0.85919652299284
Validation loss: 2.740698117390351

Epoch: 5| Step: 6
Training loss: 0.9175539418716491
Validation loss: 2.7191304967342993

Epoch: 5| Step: 7
Training loss: 1.3863066584821444
Validation loss: 2.674312966496422

Epoch: 5| Step: 8
Training loss: 0.9717354456560177
Validation loss: 2.597324260253092

Epoch: 5| Step: 9
Training loss: 0.6886660916955966
Validation loss: 2.7027952805307733

Epoch: 5| Step: 10
Training loss: 0.7277732113904439
Validation loss: 2.633831551406764

Epoch: 5| Step: 11
Training loss: 0.7918527200480513
Validation loss: 2.5979942044574504

Epoch: 156| Step: 0
Training loss: 0.828520842180098
Validation loss: 2.5449135175886353

Epoch: 5| Step: 1
Training loss: 1.0521634452206934
Validation loss: 2.6034614956096838

Epoch: 5| Step: 2
Training loss: 0.8168538887780834
Validation loss: 2.5252048063152595

Epoch: 5| Step: 3
Training loss: 0.5671599799171265
Validation loss: 2.5830845610496533

Epoch: 5| Step: 4
Training loss: 1.4679530802200522
Validation loss: 2.6686368806615537

Epoch: 5| Step: 5
Training loss: 0.8109069024636526
Validation loss: 2.7631390205055775

Epoch: 5| Step: 6
Training loss: 0.9254260448087682
Validation loss: 2.6877134851932096

Epoch: 5| Step: 7
Training loss: 1.0352874096962925
Validation loss: 2.644375787595269

Epoch: 5| Step: 8
Training loss: 0.5181160201064129
Validation loss: 2.6229734469674484

Epoch: 5| Step: 9
Training loss: 1.0923612224505779
Validation loss: 2.533551551231381

Epoch: 5| Step: 10
Training loss: 0.5964102378593962
Validation loss: 2.6125189254233434

Epoch: 5| Step: 11
Training loss: 0.745015828649331
Validation loss: 2.6453732606174034

Epoch: 157| Step: 0
Training loss: 1.0658580223208565
Validation loss: 2.691912540232779

Epoch: 5| Step: 1
Training loss: 0.8636497643106431
Validation loss: 2.5720099899259647

Epoch: 5| Step: 2
Training loss: 0.6733032393654773
Validation loss: 2.617808106131735

Epoch: 5| Step: 3
Training loss: 0.5086079456322972
Validation loss: 2.671346641932051

Epoch: 5| Step: 4
Training loss: 1.261128384914841
Validation loss: 2.7397309699848145

Epoch: 5| Step: 5
Training loss: 1.0731966461988005
Validation loss: 2.740769121809294

Epoch: 5| Step: 6
Training loss: 1.075773743580412
Validation loss: 2.734730546633057

Epoch: 5| Step: 7
Training loss: 0.6708406204120069
Validation loss: 2.7247693487714075

Epoch: 5| Step: 8
Training loss: 0.7279793245686028
Validation loss: 2.6623000787767808

Epoch: 5| Step: 9
Training loss: 0.8389407248899324
Validation loss: 2.673249357831747

Epoch: 5| Step: 10
Training loss: 1.4664137094721532
Validation loss: 2.5699940148857823

Epoch: 5| Step: 11
Training loss: 0.386295125109244
Validation loss: 2.595020302927076

Epoch: 158| Step: 0
Training loss: 0.44427318758711576
Validation loss: 2.5640889413025465

Epoch: 5| Step: 1
Training loss: 0.8822175105493839
Validation loss: 2.582486855481754

Epoch: 5| Step: 2
Training loss: 0.698044499509043
Validation loss: 2.628276150500068

Epoch: 5| Step: 3
Training loss: 0.8477020251312132
Validation loss: 2.6061956791816145

Epoch: 5| Step: 4
Training loss: 0.6336138560989005
Validation loss: 2.6160608552111184

Epoch: 5| Step: 5
Training loss: 0.7958317079244529
Validation loss: 2.6475488152594893

Epoch: 5| Step: 6
Training loss: 0.890151952298252
Validation loss: 2.5495489258358104

Epoch: 5| Step: 7
Training loss: 0.6689445996802772
Validation loss: 2.665652761579386

Epoch: 5| Step: 8
Training loss: 0.6263960029675492
Validation loss: 2.6521262228095535

Epoch: 5| Step: 9
Training loss: 0.7666168405747673
Validation loss: 2.5884774479617096

Epoch: 5| Step: 10
Training loss: 1.7108673360015658
Validation loss: 2.5995392057873326

Epoch: 5| Step: 11
Training loss: 0.33997860786865347
Validation loss: 2.5643363067989133

Epoch: 159| Step: 0
Training loss: 0.8112664027973044
Validation loss: 2.5881242908095126

Epoch: 5| Step: 1
Training loss: 0.8125680014690546
Validation loss: 2.6006951380192422

Epoch: 5| Step: 2
Training loss: 0.9745329557437229
Validation loss: 2.5847345110572477

Epoch: 5| Step: 3
Training loss: 0.6908200251843192
Validation loss: 2.630598969612083

Epoch: 5| Step: 4
Training loss: 0.7109552318331935
Validation loss: 2.5913675331594646

Epoch: 5| Step: 5
Training loss: 1.2955350732947293
Validation loss: 2.5958656430466074

Epoch: 5| Step: 6
Training loss: 0.5958622204062561
Validation loss: 2.6131145840400523

Epoch: 5| Step: 7
Training loss: 0.9783459362071766
Validation loss: 2.645540320073603

Epoch: 5| Step: 8
Training loss: 0.7582455606981494
Validation loss: 2.544964243257322

Epoch: 5| Step: 9
Training loss: 0.49045276716670666
Validation loss: 2.6776405427474304

Epoch: 5| Step: 10
Training loss: 0.8533159105253283
Validation loss: 2.6786727355539695

Epoch: 5| Step: 11
Training loss: 0.8749641002374936
Validation loss: 2.6203267983653253

Epoch: 160| Step: 0
Training loss: 0.7342653801449865
Validation loss: 2.645175444043055

Epoch: 5| Step: 1
Training loss: 0.9135699779222455
Validation loss: 2.596033290113482

Epoch: 5| Step: 2
Training loss: 0.9727277614548524
Validation loss: 2.6922984718245213

Epoch: 5| Step: 3
Training loss: 0.5917498881505515
Validation loss: 2.6118913840505473

Epoch: 5| Step: 4
Training loss: 1.0029518548434166
Validation loss: 2.662485381132536

Epoch: 5| Step: 5
Training loss: 0.7558582315756653
Validation loss: 2.650667251547593

Epoch: 5| Step: 6
Training loss: 0.7729134759211593
Validation loss: 2.5854063189594294

Epoch: 5| Step: 7
Training loss: 0.8042733691552306
Validation loss: 2.6843021721928593

Epoch: 5| Step: 8
Training loss: 0.7655071245655524
Validation loss: 2.6403805809591083

Epoch: 5| Step: 9
Training loss: 1.4110693683023718
Validation loss: 2.6824835119188073

Epoch: 5| Step: 10
Training loss: 0.5825581565771139
Validation loss: 2.65493554896152

Epoch: 5| Step: 11
Training loss: 0.7949786716575171
Validation loss: 2.605675029071521

Epoch: 161| Step: 0
Training loss: 0.8211992829337801
Validation loss: 2.771447095201316

Epoch: 5| Step: 1
Training loss: 1.29292753678298
Validation loss: 2.8111213872733867

Epoch: 5| Step: 2
Training loss: 0.6201948702957721
Validation loss: 2.71588604356107

Epoch: 5| Step: 3
Training loss: 1.005669377724653
Validation loss: 2.651089639110986

Epoch: 5| Step: 4
Training loss: 0.7504218425145085
Validation loss: 2.6184023566428998

Epoch: 5| Step: 5
Training loss: 0.7446985431065247
Validation loss: 2.62266128671371

Epoch: 5| Step: 6
Training loss: 1.481634642158737
Validation loss: 2.6143274650657027

Epoch: 5| Step: 7
Training loss: 0.7199325784269446
Validation loss: 2.651366198348112

Epoch: 5| Step: 8
Training loss: 0.5627776096676802
Validation loss: 2.613941373449046

Epoch: 5| Step: 9
Training loss: 0.720928787423522
Validation loss: 2.605726500977525

Epoch: 5| Step: 10
Training loss: 0.7663396108355548
Validation loss: 2.717893721394809

Epoch: 5| Step: 11
Training loss: 0.7640507141327627
Validation loss: 2.684854214207259

Epoch: 162| Step: 0
Training loss: 0.9183997258546467
Validation loss: 2.822905295279897

Epoch: 5| Step: 1
Training loss: 0.888754671033557
Validation loss: 2.76447324243743

Epoch: 5| Step: 2
Training loss: 0.7858760438101808
Validation loss: 2.6218588366671436

Epoch: 5| Step: 3
Training loss: 0.69074862396429
Validation loss: 2.6050223750253627

Epoch: 5| Step: 4
Training loss: 0.6505838971891909
Validation loss: 2.6002280523469743

Epoch: 5| Step: 5
Training loss: 0.9072054397538497
Validation loss: 2.5926128522110354

Epoch: 5| Step: 6
Training loss: 1.5077048149593189
Validation loss: 2.6458388100715085

Epoch: 5| Step: 7
Training loss: 0.7479426856726242
Validation loss: 2.5752598302727816

Epoch: 5| Step: 8
Training loss: 0.8213089476728388
Validation loss: 2.6428238518807787

Epoch: 5| Step: 9
Training loss: 1.011403097156341
Validation loss: 2.633811044418565

Epoch: 5| Step: 10
Training loss: 0.6208556096562928
Validation loss: 2.720415591719159

Epoch: 5| Step: 11
Training loss: 0.5993610576165568
Validation loss: 2.7369809983982645

Epoch: 163| Step: 0
Training loss: 0.9172761617564948
Validation loss: 2.7925540393881523

Epoch: 5| Step: 1
Training loss: 0.5493891553389627
Validation loss: 2.648069667497672

Epoch: 5| Step: 2
Training loss: 1.4424857875712227
Validation loss: 2.6789977258205315

Epoch: 5| Step: 3
Training loss: 0.8213920392626176
Validation loss: 2.6122433207781826

Epoch: 5| Step: 4
Training loss: 0.8568350276068297
Validation loss: 2.6324683963476203

Epoch: 5| Step: 5
Training loss: 0.7233323929234148
Validation loss: 2.6506649728987246

Epoch: 5| Step: 6
Training loss: 0.6598870896801637
Validation loss: 2.6006968970316207

Epoch: 5| Step: 7
Training loss: 0.9414025460957836
Validation loss: 2.6176518573935517

Epoch: 5| Step: 8
Training loss: 0.7184862399233742
Validation loss: 2.6522058555028076

Epoch: 5| Step: 9
Training loss: 0.7705896138329631
Validation loss: 2.66231111996754

Epoch: 5| Step: 10
Training loss: 0.729423672932437
Validation loss: 2.6806304873950424

Epoch: 5| Step: 11
Training loss: 0.7606130546691303
Validation loss: 2.679263445607681

Epoch: 164| Step: 0
Training loss: 0.800201541130586
Validation loss: 2.7379119286597526

Epoch: 5| Step: 1
Training loss: 0.7652019577598553
Validation loss: 2.6768266626554427

Epoch: 5| Step: 2
Training loss: 0.8046045353165449
Validation loss: 2.601007830092018

Epoch: 5| Step: 3
Training loss: 0.7510734664244623
Validation loss: 2.6106141892211534

Epoch: 5| Step: 4
Training loss: 0.4699639495760694
Validation loss: 2.5815122181769925

Epoch: 5| Step: 5
Training loss: 0.6010162796617932
Validation loss: 2.6470189304244136

Epoch: 5| Step: 6
Training loss: 0.8388407906230431
Validation loss: 2.7012747604551004

Epoch: 5| Step: 7
Training loss: 0.8396561523991709
Validation loss: 2.672389362044607

Epoch: 5| Step: 8
Training loss: 0.9628883346313721
Validation loss: 2.6867523668971574

Epoch: 5| Step: 9
Training loss: 1.4135037155885173
Validation loss: 2.6254285091751988

Epoch: 5| Step: 10
Training loss: 0.7049135348885582
Validation loss: 2.5846805687074514

Epoch: 5| Step: 11
Training loss: 1.891672017878331
Validation loss: 2.6408115298509753

Epoch: 165| Step: 0
Training loss: 0.6567463814047981
Validation loss: 2.6009090737088014

Epoch: 5| Step: 1
Training loss: 0.9107139745011853
Validation loss: 2.684650659081553

Epoch: 5| Step: 2
Training loss: 1.4671293204475433
Validation loss: 2.578393375030114

Epoch: 5| Step: 3
Training loss: 0.7939703492818783
Validation loss: 2.6853612588257034

Epoch: 5| Step: 4
Training loss: 0.4256246961404889
Validation loss: 2.7361963291634983

Epoch: 5| Step: 5
Training loss: 0.9301498289317586
Validation loss: 2.7265614871193535

Epoch: 5| Step: 6
Training loss: 1.00771088790228
Validation loss: 2.6705546918619456

Epoch: 5| Step: 7
Training loss: 0.7406707121829853
Validation loss: 2.648665107991675

Epoch: 5| Step: 8
Training loss: 0.6823345685288295
Validation loss: 2.669943905460204

Epoch: 5| Step: 9
Training loss: 0.9366468044010029
Validation loss: 2.627202602863518

Epoch: 5| Step: 10
Training loss: 0.6877798681217975
Validation loss: 2.6045910731031627

Epoch: 5| Step: 11
Training loss: 0.7373809977066188
Validation loss: 2.6166498039900934

Epoch: 166| Step: 0
Training loss: 0.6523008503770468
Validation loss: 2.578052997546968

Epoch: 5| Step: 1
Training loss: 0.5865875198970678
Validation loss: 2.6680289355257396

Epoch: 5| Step: 2
Training loss: 1.3881063476710864
Validation loss: 2.622969568722484

Epoch: 5| Step: 3
Training loss: 0.8042407971805138
Validation loss: 2.637769846573417

Epoch: 5| Step: 4
Training loss: 0.5492654056185645
Validation loss: 2.7281370234798006

Epoch: 5| Step: 5
Training loss: 1.223145505862885
Validation loss: 2.661711344229507

Epoch: 5| Step: 6
Training loss: 0.4883654254836935
Validation loss: 2.629295928626957

Epoch: 5| Step: 7
Training loss: 0.7460001941762472
Validation loss: 2.651087576288136

Epoch: 5| Step: 8
Training loss: 0.6816202067730097
Validation loss: 2.6793890213145315

Epoch: 5| Step: 9
Training loss: 0.6888760320897643
Validation loss: 2.6229439698894703

Epoch: 5| Step: 10
Training loss: 0.8377040486359391
Validation loss: 2.6695817360045364

Epoch: 5| Step: 11
Training loss: 0.8464195969550191
Validation loss: 2.5705159386048733

Epoch: 167| Step: 0
Training loss: 0.7757906710541492
Validation loss: 2.5829500803658196

Epoch: 5| Step: 1
Training loss: 0.5316802134128341
Validation loss: 2.5827595909378007

Epoch: 5| Step: 2
Training loss: 1.5391212103629814
Validation loss: 2.6634944671896594

Epoch: 5| Step: 3
Training loss: 0.8181091508721704
Validation loss: 2.6458737803293695

Epoch: 5| Step: 4
Training loss: 0.789013285093545
Validation loss: 2.6226316830224303

Epoch: 5| Step: 5
Training loss: 0.7370916399821031
Validation loss: 2.672678709451509

Epoch: 5| Step: 6
Training loss: 0.5978202345527699
Validation loss: 2.6546550824343527

Epoch: 5| Step: 7
Training loss: 0.7457919484027896
Validation loss: 2.6582528137002717

Epoch: 5| Step: 8
Training loss: 0.8810096155847779
Validation loss: 2.572312980492081

Epoch: 5| Step: 9
Training loss: 0.8016209363550344
Validation loss: 2.565296045217191

Epoch: 5| Step: 10
Training loss: 0.6377159454138974
Validation loss: 2.5537932733375728

Epoch: 5| Step: 11
Training loss: 0.866897156369677
Validation loss: 2.6001367146359677

Epoch: 168| Step: 0
Training loss: 0.7741906323605529
Validation loss: 2.5929908484083986

Epoch: 5| Step: 1
Training loss: 0.725626927651696
Validation loss: 2.6567077840624993

Epoch: 5| Step: 2
Training loss: 0.6547718203194283
Validation loss: 2.6605061969812756

Epoch: 5| Step: 3
Training loss: 0.7898251087015136
Validation loss: 2.6868745460459587

Epoch: 5| Step: 4
Training loss: 0.7744513523124233
Validation loss: 2.651949025868906

Epoch: 5| Step: 5
Training loss: 0.6481302291673883
Validation loss: 2.666448972925872

Epoch: 5| Step: 6
Training loss: 0.7274110822314303
Validation loss: 2.612185523621895

Epoch: 5| Step: 7
Training loss: 1.2545943704248628
Validation loss: 2.5892264818203428

Epoch: 5| Step: 8
Training loss: 0.8980860810683957
Validation loss: 2.649148772386144

Epoch: 5| Step: 9
Training loss: 0.45157983014072006
Validation loss: 2.6799859565632618

Epoch: 5| Step: 10
Training loss: 0.7690269250558633
Validation loss: 2.636206615302634

Epoch: 5| Step: 11
Training loss: 0.4321714908285484
Validation loss: 2.6786304442776885

Epoch: 169| Step: 0
Training loss: 0.6279736113425367
Validation loss: 2.6744105259977737

Epoch: 5| Step: 1
Training loss: 0.6828726971102321
Validation loss: 2.619175409346321

Epoch: 5| Step: 2
Training loss: 0.4898984449596685
Validation loss: 2.632862864087127

Epoch: 5| Step: 3
Training loss: 0.7022805547235927
Validation loss: 2.6050537632954587

Epoch: 5| Step: 4
Training loss: 0.6417995942720466
Validation loss: 2.6030569356909408

Epoch: 5| Step: 5
Training loss: 0.5840690321784087
Validation loss: 2.5815887533694717

Epoch: 5| Step: 6
Training loss: 1.3500589817019464
Validation loss: 2.6576671709369353

Epoch: 5| Step: 7
Training loss: 0.6652507249096372
Validation loss: 2.692033998080322

Epoch: 5| Step: 8
Training loss: 0.9332182699757351
Validation loss: 2.747569295942444

Epoch: 5| Step: 9
Training loss: 0.6500798075539236
Validation loss: 2.719481862975047

Epoch: 5| Step: 10
Training loss: 0.7253385509725211
Validation loss: 2.6348638495028296

Epoch: 5| Step: 11
Training loss: 0.4610708657987638
Validation loss: 2.635813053135297

Epoch: 170| Step: 0
Training loss: 0.6098883007528031
Validation loss: 2.6209192194205815

Epoch: 5| Step: 1
Training loss: 0.778546883069914
Validation loss: 2.5833282868018133

Epoch: 5| Step: 2
Training loss: 0.6935129344836858
Validation loss: 2.588253344181877

Epoch: 5| Step: 3
Training loss: 1.5458850197321201
Validation loss: 2.6695118133191604

Epoch: 5| Step: 4
Training loss: 0.6371038945358196
Validation loss: 2.609616449267672

Epoch: 5| Step: 5
Training loss: 0.7240130497588845
Validation loss: 2.621721659614259

Epoch: 5| Step: 6
Training loss: 0.8465453572612839
Validation loss: 2.533272014103767

Epoch: 5| Step: 7
Training loss: 0.5475353069330386
Validation loss: 2.550515410750077

Epoch: 5| Step: 8
Training loss: 0.586161227428887
Validation loss: 2.6281349747415947

Epoch: 5| Step: 9
Training loss: 0.5651124054151434
Validation loss: 2.64729319057079

Epoch: 5| Step: 10
Training loss: 0.7109470157196062
Validation loss: 2.6325116877101675

Epoch: 5| Step: 11
Training loss: 0.6626239678620045
Validation loss: 2.5368455647392008

Epoch: 171| Step: 0
Training loss: 0.6995934915363633
Validation loss: 2.6454798125583845

Epoch: 5| Step: 1
Training loss: 1.286639763191755
Validation loss: 2.5981629759376297

Epoch: 5| Step: 2
Training loss: 0.4268533001881507
Validation loss: 2.5904971871561098

Epoch: 5| Step: 3
Training loss: 1.0402356172468996
Validation loss: 2.605878348803961

Epoch: 5| Step: 4
Training loss: 0.39287311231989236
Validation loss: 2.6612486013250822

Epoch: 5| Step: 5
Training loss: 0.8455661724461122
Validation loss: 2.6214414347955066

Epoch: 5| Step: 6
Training loss: 0.714727423536511
Validation loss: 2.7100867439829504

Epoch: 5| Step: 7
Training loss: 0.4382820972563634
Validation loss: 2.6437161615549374

Epoch: 5| Step: 8
Training loss: 0.7524633484846176
Validation loss: 2.6808604999361823

Epoch: 5| Step: 9
Training loss: 0.7131506458722717
Validation loss: 2.6646655547724114

Epoch: 5| Step: 10
Training loss: 0.5579838390761701
Validation loss: 2.6167578083513576

Epoch: 5| Step: 11
Training loss: 0.6359529160639137
Validation loss: 2.59618796821325

Epoch: 172| Step: 0
Training loss: 0.4768449540378353
Validation loss: 2.7118709946792046

Epoch: 5| Step: 1
Training loss: 0.5877461810424
Validation loss: 2.65167586167258

Epoch: 5| Step: 2
Training loss: 0.4884409833943729
Validation loss: 2.6131642899429344

Epoch: 5| Step: 3
Training loss: 0.446155185778084
Validation loss: 2.72720399322016

Epoch: 5| Step: 4
Training loss: 0.5703405608498263
Validation loss: 2.606456205350759

Epoch: 5| Step: 5
Training loss: 0.7949544913983883
Validation loss: 2.5822981418981357

Epoch: 5| Step: 6
Training loss: 0.6326384128308683
Validation loss: 2.63400623716578

Epoch: 5| Step: 7
Training loss: 0.6216872156989504
Validation loss: 2.6848792153604837

Epoch: 5| Step: 8
Training loss: 1.3228470441064362
Validation loss: 2.6413409975994333

Epoch: 5| Step: 9
Training loss: 0.9043687499383317
Validation loss: 2.7007785086838094

Epoch: 5| Step: 10
Training loss: 0.6469156722398937
Validation loss: 2.6502813486779027

Epoch: 5| Step: 11
Training loss: 0.8871953078541455
Validation loss: 2.6181786249939836

Epoch: 173| Step: 0
Training loss: 1.2497782987445727
Validation loss: 2.669380864302388

Epoch: 5| Step: 1
Training loss: 0.5521655171481502
Validation loss: 2.723912493366844

Epoch: 5| Step: 2
Training loss: 0.583093838119725
Validation loss: 2.6201609483330555

Epoch: 5| Step: 3
Training loss: 0.7001643898917905
Validation loss: 2.5713339170374994

Epoch: 5| Step: 4
Training loss: 0.5820947906833807
Validation loss: 2.6181060659380044

Epoch: 5| Step: 5
Training loss: 0.9301425877853677
Validation loss: 2.596727160129478

Epoch: 5| Step: 6
Training loss: 0.7629674994844949
Validation loss: 2.6094075922348687

Epoch: 5| Step: 7
Training loss: 0.7471684011254426
Validation loss: 2.701360791988312

Epoch: 5| Step: 8
Training loss: 0.7872192457581488
Validation loss: 2.7283132774343706

Epoch: 5| Step: 9
Training loss: 0.8269554012016789
Validation loss: 2.7189857556081143

Epoch: 5| Step: 10
Training loss: 0.7052019808289182
Validation loss: 2.612418309292794

Epoch: 5| Step: 11
Training loss: 0.4144362436320672
Validation loss: 2.6827429617073535

Epoch: 174| Step: 0
Training loss: 0.6166645683648092
Validation loss: 2.6878168081991123

Epoch: 5| Step: 1
Training loss: 1.2963206473717477
Validation loss: 2.6801984094188187

Epoch: 5| Step: 2
Training loss: 0.49498056185732425
Validation loss: 2.7073859037050596

Epoch: 5| Step: 3
Training loss: 0.5518424180242271
Validation loss: 2.6291017086530704

Epoch: 5| Step: 4
Training loss: 0.8541301897835604
Validation loss: 2.742856399667541

Epoch: 5| Step: 5
Training loss: 0.9384304198037049
Validation loss: 2.6127066557886716

Epoch: 5| Step: 6
Training loss: 0.8622490421023292
Validation loss: 2.5990075786463445

Epoch: 5| Step: 7
Training loss: 0.5619996812792379
Validation loss: 2.6222072193815267

Epoch: 5| Step: 8
Training loss: 0.6105010070948687
Validation loss: 2.652877877434491

Epoch: 5| Step: 9
Training loss: 0.6149085256731494
Validation loss: 2.6628666875971203

Epoch: 5| Step: 10
Training loss: 0.5616000711973531
Validation loss: 2.6799526435608465

Epoch: 5| Step: 11
Training loss: 0.4542927985365157
Validation loss: 2.6400386904279998

Epoch: 175| Step: 0
Training loss: 0.5695075533820622
Validation loss: 2.7073076555680893

Epoch: 5| Step: 1
Training loss: 0.6551198082834448
Validation loss: 2.6305526860494606

Epoch: 5| Step: 2
Training loss: 0.6270585253762643
Validation loss: 2.6217912142994564

Epoch: 5| Step: 3
Training loss: 0.6003114150443095
Validation loss: 2.6934321308152547

Epoch: 5| Step: 4
Training loss: 0.8725672691012141
Validation loss: 2.715387365862004

Epoch: 5| Step: 5
Training loss: 0.6771388886963744
Validation loss: 2.667020887203929

Epoch: 5| Step: 6
Training loss: 1.3758288399622782
Validation loss: 2.723867532786127

Epoch: 5| Step: 7
Training loss: 0.8028511649235517
Validation loss: 2.5973541657755823

Epoch: 5| Step: 8
Training loss: 0.6617705792122794
Validation loss: 2.6566170719304667

Epoch: 5| Step: 9
Training loss: 0.4229655475586819
Validation loss: 2.6789395926273136

Epoch: 5| Step: 10
Training loss: 0.46453552285188265
Validation loss: 2.6927914867929252

Epoch: 5| Step: 11
Training loss: 0.4627560287064328
Validation loss: 2.7470947799741148

Epoch: 176| Step: 0
Training loss: 1.3071486507573256
Validation loss: 2.6793638762413776

Epoch: 5| Step: 1
Training loss: 0.7250549098300603
Validation loss: 2.646902001193282

Epoch: 5| Step: 2
Training loss: 0.5435146633686366
Validation loss: 2.712715950732948

Epoch: 5| Step: 3
Training loss: 0.7083951745432718
Validation loss: 2.5945095554889432

Epoch: 5| Step: 4
Training loss: 0.6085035009886834
Validation loss: 2.723680078409334

Epoch: 5| Step: 5
Training loss: 0.8515707243076011
Validation loss: 2.630149464215969

Epoch: 5| Step: 6
Training loss: 0.6495180892803984
Validation loss: 2.7051034496971904

Epoch: 5| Step: 7
Training loss: 0.5253567312432927
Validation loss: 2.618503717845603

Epoch: 5| Step: 8
Training loss: 0.6896422561718523
Validation loss: 2.6556670764747854

Epoch: 5| Step: 9
Training loss: 0.5919008069318558
Validation loss: 2.632880129827518

Epoch: 5| Step: 10
Training loss: 0.6162986390686979
Validation loss: 2.669336254279602

Epoch: 5| Step: 11
Training loss: 0.6619820036228317
Validation loss: 2.6555330393469316

Epoch: 177| Step: 0
Training loss: 0.5565769359894733
Validation loss: 2.729014994262659

Epoch: 5| Step: 1
Training loss: 0.6828118130049752
Validation loss: 2.5747919558766115

Epoch: 5| Step: 2
Training loss: 0.5754068241571267
Validation loss: 2.5792036478064926

Epoch: 5| Step: 3
Training loss: 1.3804448434932575
Validation loss: 2.6504512734011154

Epoch: 5| Step: 4
Training loss: 0.5236803032562323
Validation loss: 2.6629288536962403

Epoch: 5| Step: 5
Training loss: 0.7561864810466641
Validation loss: 2.682796868952851

Epoch: 5| Step: 6
Training loss: 0.5617406010522648
Validation loss: 2.769626086736111

Epoch: 5| Step: 7
Training loss: 0.7317764082907818
Validation loss: 2.6555322836832045

Epoch: 5| Step: 8
Training loss: 0.40033833232022126
Validation loss: 2.6706113671495615

Epoch: 5| Step: 9
Training loss: 0.6828549561733456
Validation loss: 2.669086239022155

Epoch: 5| Step: 10
Training loss: 0.5269933596125711
Validation loss: 2.6098368116130226

Epoch: 5| Step: 11
Training loss: 0.6057745868669645
Validation loss: 2.6571717476836785

Epoch: 178| Step: 0
Training loss: 0.6800804317814303
Validation loss: 2.665480727494882

Epoch: 5| Step: 1
Training loss: 1.0137600134603122
Validation loss: 2.622436611511317

Epoch: 5| Step: 2
Training loss: 0.5278641005521529
Validation loss: 2.739201781435915

Epoch: 5| Step: 3
Training loss: 0.5650499086364235
Validation loss: 2.703240515238099

Epoch: 5| Step: 4
Training loss: 0.6521998035346972
Validation loss: 2.6775469520766677

Epoch: 5| Step: 5
Training loss: 0.441461711538776
Validation loss: 2.7207852816951204

Epoch: 5| Step: 6
Training loss: 0.5660994652573581
Validation loss: 2.7381049084443263

Epoch: 5| Step: 7
Training loss: 1.2082289398523782
Validation loss: 2.7067607581194735

Epoch: 5| Step: 8
Training loss: 0.6606370878963308
Validation loss: 2.7342514882121587

Epoch: 5| Step: 9
Training loss: 0.5389948816321818
Validation loss: 2.7772056520218724

Epoch: 5| Step: 10
Training loss: 0.7226669723127688
Validation loss: 2.755343478349088

Epoch: 5| Step: 11
Training loss: 0.2018048042455633
Validation loss: 2.707726771337955

Epoch: 179| Step: 0
Training loss: 0.4392520359689059
Validation loss: 2.69099163595327

Epoch: 5| Step: 1
Training loss: 0.830358516234919
Validation loss: 2.562171492415125

Epoch: 5| Step: 2
Training loss: 0.5896353195464857
Validation loss: 2.6901669373379096

Epoch: 5| Step: 3
Training loss: 0.4859186923199016
Validation loss: 2.6400621668342783

Epoch: 5| Step: 4
Training loss: 0.5567511733187922
Validation loss: 2.704292809513042

Epoch: 5| Step: 5
Training loss: 0.7214035311080266
Validation loss: 2.622307565990979

Epoch: 5| Step: 6
Training loss: 0.5005541948783823
Validation loss: 2.7942511079962404

Epoch: 5| Step: 7
Training loss: 1.3527543209939616
Validation loss: 2.642112004761658

Epoch: 5| Step: 8
Training loss: 0.5095832176811397
Validation loss: 2.6579094733223454

Epoch: 5| Step: 9
Training loss: 0.3936416681309391
Validation loss: 2.709940057164303

Epoch: 5| Step: 10
Training loss: 0.4376184098903313
Validation loss: 2.709830660051264

Epoch: 5| Step: 11
Training loss: 0.13999924246549017
Validation loss: 2.661092633518593

Epoch: 180| Step: 0
Training loss: 0.713553760361107
Validation loss: 2.8036566285821922

Epoch: 5| Step: 1
Training loss: 0.5648243089551375
Validation loss: 2.7374100435186843

Epoch: 5| Step: 2
Training loss: 1.225408995724435
Validation loss: 2.656470899185458

Epoch: 5| Step: 3
Training loss: 0.6146836495290997
Validation loss: 2.6073240302273564

Epoch: 5| Step: 4
Training loss: 0.6107147357018007
Validation loss: 2.6968930866729717

Epoch: 5| Step: 5
Training loss: 0.8822907788220787
Validation loss: 2.6348239033528857

Epoch: 5| Step: 6
Training loss: 0.7384867306513463
Validation loss: 2.7342610290026808

Epoch: 5| Step: 7
Training loss: 0.8390012196587665
Validation loss: 2.648940457773642

Epoch: 5| Step: 8
Training loss: 0.662591584191158
Validation loss: 2.6698170110893895

Epoch: 5| Step: 9
Training loss: 0.6555615401488737
Validation loss: 2.7227341409539574

Epoch: 5| Step: 10
Training loss: 0.6038649945892013
Validation loss: 2.618173438205648

Epoch: 5| Step: 11
Training loss: 0.756231999774178
Validation loss: 2.711877903452832

Epoch: 181| Step: 0
Training loss: 0.7140332823270366
Validation loss: 2.680822628776761

Epoch: 5| Step: 1
Training loss: 0.974686032875378
Validation loss: 2.742143788220261

Epoch: 5| Step: 2
Training loss: 0.8644916455166886
Validation loss: 2.790874263172454

Epoch: 5| Step: 3
Training loss: 0.6751301887141893
Validation loss: 2.635119686557271

Epoch: 5| Step: 4
Training loss: 0.6921359807253127
Validation loss: 2.653045411670387

Epoch: 5| Step: 5
Training loss: 0.8051845163735545
Validation loss: 2.6174543254210736

Epoch: 5| Step: 6
Training loss: 1.6986468174736342
Validation loss: 2.7119355100709237

Epoch: 5| Step: 7
Training loss: 0.7346967438733268
Validation loss: 2.620874049856446

Epoch: 5| Step: 8
Training loss: 0.6067791693992088
Validation loss: 2.6800214338809587

Epoch: 5| Step: 9
Training loss: 0.5800323982069153
Validation loss: 2.6954762690082155

Epoch: 5| Step: 10
Training loss: 0.6904327306181278
Validation loss: 2.749122703661717

Epoch: 5| Step: 11
Training loss: 0.8743110396664574
Validation loss: 2.7774208977380046

Epoch: 182| Step: 0
Training loss: 0.6986846162371555
Validation loss: 2.79287803520367

Epoch: 5| Step: 1
Training loss: 1.037533718158703
Validation loss: 2.7140890559022988

Epoch: 5| Step: 2
Training loss: 0.597116114064157
Validation loss: 2.6141943635913303

Epoch: 5| Step: 3
Training loss: 0.8309739966839985
Validation loss: 2.5915363087839585

Epoch: 5| Step: 4
Training loss: 0.763259425090394
Validation loss: 2.6559467703579727

Epoch: 5| Step: 5
Training loss: 0.8297672183142994
Validation loss: 2.6978541125160738

Epoch: 5| Step: 6
Training loss: 1.0278379462790013
Validation loss: 2.712314856783883

Epoch: 5| Step: 7
Training loss: 0.8201705809852956
Validation loss: 2.6390369331231125

Epoch: 5| Step: 8
Training loss: 1.2562649132901433
Validation loss: 2.6775043703180685

Epoch: 5| Step: 9
Training loss: 0.6883372713773761
Validation loss: 2.687410704289922

Epoch: 5| Step: 10
Training loss: 0.9304069171798447
Validation loss: 2.8430404965721885

Epoch: 5| Step: 11
Training loss: 0.7599723946426584
Validation loss: 2.8660053376558285

Epoch: 183| Step: 0
Training loss: 0.9095246247622208
Validation loss: 2.768744180643067

Epoch: 5| Step: 1
Training loss: 0.5900473590609738
Validation loss: 2.640899666490483

Epoch: 5| Step: 2
Training loss: 0.711188932120191
Validation loss: 2.6499623247983255

Epoch: 5| Step: 3
Training loss: 0.5257035922194236
Validation loss: 2.6611460684816532

Epoch: 5| Step: 4
Training loss: 0.8925865056084784
Validation loss: 2.688796425629483

Epoch: 5| Step: 5
Training loss: 0.7226097298160024
Validation loss: 2.5941789341346606

Epoch: 5| Step: 6
Training loss: 0.7331185651335792
Validation loss: 2.686468344072315

Epoch: 5| Step: 7
Training loss: 1.2794695322718086
Validation loss: 2.708169981113897

Epoch: 5| Step: 8
Training loss: 0.5449095967321218
Validation loss: 2.6012215949418205

Epoch: 5| Step: 9
Training loss: 0.656148948155352
Validation loss: 2.7454405614156863

Epoch: 5| Step: 10
Training loss: 0.9710142070819147
Validation loss: 2.815228636204588

Epoch: 5| Step: 11
Training loss: 0.8409096983783224
Validation loss: 2.780316612338083

Epoch: 184| Step: 0
Training loss: 0.8484733616115357
Validation loss: 2.795144396369094

Epoch: 5| Step: 1
Training loss: 0.7788371018121891
Validation loss: 2.7121455700800707

Epoch: 5| Step: 2
Training loss: 0.7855724161739096
Validation loss: 2.722003510073254

Epoch: 5| Step: 3
Training loss: 0.6392877624749864
Validation loss: 2.6266021418411865

Epoch: 5| Step: 4
Training loss: 0.7135074820764425
Validation loss: 2.6674355885952816

Epoch: 5| Step: 5
Training loss: 0.6599923105225417
Validation loss: 2.665713275164784

Epoch: 5| Step: 6
Training loss: 0.6834063027739598
Validation loss: 2.566108384403359

Epoch: 5| Step: 7
Training loss: 1.3327568963852205
Validation loss: 2.64248106318425

Epoch: 5| Step: 8
Training loss: 0.8668803452902466
Validation loss: 2.636470146233118

Epoch: 5| Step: 9
Training loss: 0.5622761598898434
Validation loss: 2.6209279901930778

Epoch: 5| Step: 10
Training loss: 0.7136210422964062
Validation loss: 2.711381089913684

Epoch: 5| Step: 11
Training loss: 0.5041665580318534
Validation loss: 2.7304701434465235

Epoch: 185| Step: 0
Training loss: 0.8163728113946767
Validation loss: 2.766807217264241

Epoch: 5| Step: 1
Training loss: 0.6799239262634634
Validation loss: 2.754237446810872

Epoch: 5| Step: 2
Training loss: 0.8105329765139359
Validation loss: 2.7405710627526987

Epoch: 5| Step: 3
Training loss: 0.8348434633300563
Validation loss: 2.5796950520574917

Epoch: 5| Step: 4
Training loss: 1.318674007594623
Validation loss: 2.617897254394861

Epoch: 5| Step: 5
Training loss: 0.6660234333374869
Validation loss: 2.6540314179299793

Epoch: 5| Step: 6
Training loss: 0.8790032227319307
Validation loss: 2.652408934266475

Epoch: 5| Step: 7
Training loss: 0.5940891100579038
Validation loss: 2.590733512903505

Epoch: 5| Step: 8
Training loss: 0.6110910315417788
Validation loss: 2.6655958951469487

Epoch: 5| Step: 9
Training loss: 0.5117605061274917
Validation loss: 2.671968216785073

Epoch: 5| Step: 10
Training loss: 0.619055757211458
Validation loss: 2.7058829789169088

Epoch: 5| Step: 11
Training loss: 0.9312500844865799
Validation loss: 2.6513451975173403

Epoch: 186| Step: 0
Training loss: 0.7569934311938284
Validation loss: 2.6813902195068833

Epoch: 5| Step: 1
Training loss: 0.5131816192501858
Validation loss: 2.682896604498994

Epoch: 5| Step: 2
Training loss: 0.3829584621944853
Validation loss: 2.6473318246961854

Epoch: 5| Step: 3
Training loss: 0.6491438683614623
Validation loss: 2.6550346062267316

Epoch: 5| Step: 4
Training loss: 0.6467039536347761
Validation loss: 2.642587177254528

Epoch: 5| Step: 5
Training loss: 0.9771481703262833
Validation loss: 2.6146139444532452

Epoch: 5| Step: 6
Training loss: 0.6707154403382344
Validation loss: 2.6490771328628933

Epoch: 5| Step: 7
Training loss: 1.276200649192799
Validation loss: 2.697916672803567

Epoch: 5| Step: 8
Training loss: 0.6203190512515407
Validation loss: 2.710858592150145

Epoch: 5| Step: 9
Training loss: 0.40692079623270916
Validation loss: 2.719206753360371

Epoch: 5| Step: 10
Training loss: 0.6560827223706567
Validation loss: 2.7073057071331004

Epoch: 5| Step: 11
Training loss: 0.7391539164292502
Validation loss: 2.6894935193026

Epoch: 187| Step: 0
Training loss: 0.6016615996539277
Validation loss: 2.696703053632882

Epoch: 5| Step: 1
Training loss: 0.5915423056595959
Validation loss: 2.616975530894089

Epoch: 5| Step: 2
Training loss: 0.38693281471990837
Validation loss: 2.6389094560362656

Epoch: 5| Step: 3
Training loss: 0.5571008486289862
Validation loss: 2.706077760056338

Epoch: 5| Step: 4
Training loss: 0.46309510877160087
Validation loss: 2.635699955537248

Epoch: 5| Step: 5
Training loss: 1.2023770372964588
Validation loss: 2.6541654522911498

Epoch: 5| Step: 6
Training loss: 0.5376034215744444
Validation loss: 2.6684114527321747

Epoch: 5| Step: 7
Training loss: 0.5790729226143491
Validation loss: 2.6731551042939317

Epoch: 5| Step: 8
Training loss: 0.8911439822408304
Validation loss: 2.6946940242289172

Epoch: 5| Step: 9
Training loss: 0.5728679780789845
Validation loss: 2.659820778223973

Epoch: 5| Step: 10
Training loss: 0.6679015990295094
Validation loss: 2.615310724809126

Epoch: 5| Step: 11
Training loss: 0.5913189257877525
Validation loss: 2.64247179628044

Epoch: 188| Step: 0
Training loss: 0.7138659350675145
Validation loss: 2.6097833652708924

Epoch: 5| Step: 1
Training loss: 0.4906177769268963
Validation loss: 2.599505817233659

Epoch: 5| Step: 2
Training loss: 1.2055403504582278
Validation loss: 2.6671047943527926

Epoch: 5| Step: 3
Training loss: 0.6285795227913694
Validation loss: 2.6493097329985176

Epoch: 5| Step: 4
Training loss: 0.5326440695961479
Validation loss: 2.6748699520561465

Epoch: 5| Step: 5
Training loss: 0.6190507986088377
Validation loss: 2.651173939930554

Epoch: 5| Step: 6
Training loss: 0.4568050998751711
Validation loss: 2.63379429397186

Epoch: 5| Step: 7
Training loss: 0.8005341683648134
Validation loss: 2.6559476493344993

Epoch: 5| Step: 8
Training loss: 0.5389314298645144
Validation loss: 2.609820573419858

Epoch: 5| Step: 9
Training loss: 0.7413747654169844
Validation loss: 2.64322869938187

Epoch: 5| Step: 10
Training loss: 0.5029398204190082
Validation loss: 2.712261528894525

Epoch: 5| Step: 11
Training loss: 0.4602903737320255
Validation loss: 2.6650730241321834

Epoch: 189| Step: 0
Training loss: 0.4536276035901614
Validation loss: 2.6414880151136795

Epoch: 5| Step: 1
Training loss: 1.211420861033942
Validation loss: 2.5937110139605526

Epoch: 5| Step: 2
Training loss: 0.5311816676455087
Validation loss: 2.619750776534256

Epoch: 5| Step: 3
Training loss: 0.4695949092370132
Validation loss: 2.604424270604461

Epoch: 5| Step: 4
Training loss: 0.5653858332518551
Validation loss: 2.6299032707943737

Epoch: 5| Step: 5
Training loss: 0.8611311914468078
Validation loss: 2.633980907769985

Epoch: 5| Step: 6
Training loss: 0.4460716803280695
Validation loss: 2.740560818960615

Epoch: 5| Step: 7
Training loss: 0.6300211200125841
Validation loss: 2.65964851631403

Epoch: 5| Step: 8
Training loss: 0.637485089782181
Validation loss: 2.661171299833973

Epoch: 5| Step: 9
Training loss: 0.4163810128299179
Validation loss: 2.7148732849270942

Epoch: 5| Step: 10
Training loss: 0.4263159343199177
Validation loss: 2.5959277336892366

Epoch: 5| Step: 11
Training loss: 0.6961677520496302
Validation loss: 2.632989237934666

Epoch: 190| Step: 0
Training loss: 0.701183095858162
Validation loss: 2.6775892549010627

Epoch: 5| Step: 1
Training loss: 0.5847087692314935
Validation loss: 2.6729994075473367

Epoch: 5| Step: 2
Training loss: 0.5839771027893647
Validation loss: 2.610816013257627

Epoch: 5| Step: 3
Training loss: 0.4964416665617107
Validation loss: 2.647029652556852

Epoch: 5| Step: 4
Training loss: 0.3037356768280488
Validation loss: 2.680673519782574

Epoch: 5| Step: 5
Training loss: 0.46000297014169045
Validation loss: 2.7128940158398946

Epoch: 5| Step: 6
Training loss: 0.46809465373628345
Validation loss: 2.572274098229072

Epoch: 5| Step: 7
Training loss: 0.5023347761856567
Validation loss: 2.673806293733732

Epoch: 5| Step: 8
Training loss: 0.8736042061515829
Validation loss: 2.712695585984126

Epoch: 5| Step: 9
Training loss: 1.2192503562271257
Validation loss: 2.7355259098998346

Epoch: 5| Step: 10
Training loss: 0.5268064799614814
Validation loss: 2.6963632240214515

Epoch: 5| Step: 11
Training loss: 0.8798743447627714
Validation loss: 2.6023730866240564

Epoch: 191| Step: 0
Training loss: 0.5350732947883584
Validation loss: 2.626175655006882

Epoch: 5| Step: 1
Training loss: 1.3631394539354913
Validation loss: 2.6518382872210604

Epoch: 5| Step: 2
Training loss: 0.5964494626283523
Validation loss: 2.639002598786047

Epoch: 5| Step: 3
Training loss: 0.4915917590697944
Validation loss: 2.694854874392472

Epoch: 5| Step: 4
Training loss: 0.3604519298516621
Validation loss: 2.721938558129131

Epoch: 5| Step: 5
Training loss: 0.5992271621690557
Validation loss: 2.6087886395141933

Epoch: 5| Step: 6
Training loss: 0.5247851431656834
Validation loss: 2.5859602766772234

Epoch: 5| Step: 7
Training loss: 0.5030645985805413
Validation loss: 2.625376394322487

Epoch: 5| Step: 8
Training loss: 0.6696636269391069
Validation loss: 2.6333626154486773

Epoch: 5| Step: 9
Training loss: 0.39444554219443884
Validation loss: 2.6927264795239148

Epoch: 5| Step: 10
Training loss: 0.6941818087698193
Validation loss: 2.6489036022376986

Epoch: 5| Step: 11
Training loss: 0.5495708503587653
Validation loss: 2.611609288526437

Epoch: 192| Step: 0
Training loss: 1.1794790121606926
Validation loss: 2.6230190424272144

Epoch: 5| Step: 1
Training loss: 0.4970960179485399
Validation loss: 2.6099955492846467

Epoch: 5| Step: 2
Training loss: 0.75346772875718
Validation loss: 2.666064914718164

Epoch: 5| Step: 3
Training loss: 0.48165577897907813
Validation loss: 2.694475152609755

Epoch: 5| Step: 4
Training loss: 0.5260152967534981
Validation loss: 2.628345628111761

Epoch: 5| Step: 5
Training loss: 0.9509729886335501
Validation loss: 2.658998499784636

Epoch: 5| Step: 6
Training loss: 0.5449326490205338
Validation loss: 2.619542225034351

Epoch: 5| Step: 7
Training loss: 0.5405367718626433
Validation loss: 2.685100926219702

Epoch: 5| Step: 8
Training loss: 0.3800729702230456
Validation loss: 2.671710566987757

Epoch: 5| Step: 9
Training loss: 0.4190182744584071
Validation loss: 2.692805874433332

Epoch: 5| Step: 10
Training loss: 0.47238318381850497
Validation loss: 2.7308255909749937

Epoch: 5| Step: 11
Training loss: 0.5796525209469295
Validation loss: 2.763602914837221

Epoch: 193| Step: 0
Training loss: 0.36002769492829206
Validation loss: 2.6671744039579393

Epoch: 5| Step: 1
Training loss: 0.5949650929733963
Validation loss: 2.6542949849604565

Epoch: 5| Step: 2
Training loss: 0.6490751601165902
Validation loss: 2.6034181103922807

Epoch: 5| Step: 3
Training loss: 0.4783548201687247
Validation loss: 2.691205479073059

Epoch: 5| Step: 4
Training loss: 1.1600088931433374
Validation loss: 2.6306323071698015

Epoch: 5| Step: 5
Training loss: 0.9688424712316213
Validation loss: 2.627730266669339

Epoch: 5| Step: 6
Training loss: 0.4923936170083331
Validation loss: 2.6348673407562457

Epoch: 5| Step: 7
Training loss: 0.4002873357268061
Validation loss: 2.6551561412692655

Epoch: 5| Step: 8
Training loss: 0.43593395464149376
Validation loss: 2.773707699933788

Epoch: 5| Step: 9
Training loss: 0.36057198252105305
Validation loss: 2.6426125143801635

Epoch: 5| Step: 10
Training loss: 0.4648998130521442
Validation loss: 2.6308249414914493

Epoch: 5| Step: 11
Training loss: 0.3103386522780361
Validation loss: 2.602846205040437

Epoch: 194| Step: 0
Training loss: 0.5200086995460818
Validation loss: 2.6962259486243845

Epoch: 5| Step: 1
Training loss: 0.47504892912879393
Validation loss: 2.6267336502002037

Epoch: 5| Step: 2
Training loss: 0.7320032169344312
Validation loss: 2.646869172559356

Epoch: 5| Step: 3
Training loss: 0.35460163034880804
Validation loss: 2.5733863669532426

Epoch: 5| Step: 4
Training loss: 0.5127891527308885
Validation loss: 2.5791306200933946

Epoch: 5| Step: 5
Training loss: 0.4582290277858812
Validation loss: 2.5995229453057207

Epoch: 5| Step: 6
Training loss: 0.6485271621668647
Validation loss: 2.7323013689918656

Epoch: 5| Step: 7
Training loss: 0.6111529407008836
Validation loss: 2.6182248161729516

Epoch: 5| Step: 8
Training loss: 0.5808016698991924
Validation loss: 2.585199114283796

Epoch: 5| Step: 9
Training loss: 0.7089787842921574
Validation loss: 2.644068990751354

Epoch: 5| Step: 10
Training loss: 1.4123144146016242
Validation loss: 2.5703946325596823

Epoch: 5| Step: 11
Training loss: 0.47038831511625534
Validation loss: 2.654504475487822

Epoch: 195| Step: 0
Training loss: 0.4625141367169411
Validation loss: 2.6457573111318147

Epoch: 5| Step: 1
Training loss: 0.8144551009558989
Validation loss: 2.670493227797188

Epoch: 5| Step: 2
Training loss: 0.3452570024832648
Validation loss: 2.7411906394845715

Epoch: 5| Step: 3
Training loss: 1.2303164433267626
Validation loss: 2.7414914087226663

Epoch: 5| Step: 4
Training loss: 0.528431766057051
Validation loss: 2.7796553476413615

Epoch: 5| Step: 5
Training loss: 0.5714322945780035
Validation loss: 2.645643863251761

Epoch: 5| Step: 6
Training loss: 0.44395437101293267
Validation loss: 2.8114428370075673

Epoch: 5| Step: 7
Training loss: 0.6559110174698727
Validation loss: 2.7345693174072063

Epoch: 5| Step: 8
Training loss: 0.6177644085533337
Validation loss: 2.6518381167725433

Epoch: 5| Step: 9
Training loss: 0.6259372835735036
Validation loss: 2.6515609230182178

Epoch: 5| Step: 10
Training loss: 0.6815455897846976
Validation loss: 2.7013790577990444

Epoch: 5| Step: 11
Training loss: 0.3366046867212335
Validation loss: 2.745916549876489

Epoch: 196| Step: 0
Training loss: 1.1484342821556215
Validation loss: 2.7010837962587857

Epoch: 5| Step: 1
Training loss: 0.4703427593344199
Validation loss: 2.7634715875989784

Epoch: 5| Step: 2
Training loss: 0.6137008203664776
Validation loss: 2.659272508779204

Epoch: 5| Step: 3
Training loss: 0.4493906272802502
Validation loss: 2.743312999592818

Epoch: 5| Step: 4
Training loss: 0.41571497911206745
Validation loss: 2.7260472995951064

Epoch: 5| Step: 5
Training loss: 0.3810832417170514
Validation loss: 2.675456232904069

Epoch: 5| Step: 6
Training loss: 0.7924554601120772
Validation loss: 2.7218240335322847

Epoch: 5| Step: 7
Training loss: 0.8539746968163529
Validation loss: 2.7227645644503378

Epoch: 5| Step: 8
Training loss: 0.4533870859862185
Validation loss: 2.644220992294768

Epoch: 5| Step: 9
Training loss: 0.5141698649794874
Validation loss: 2.6675777791132376

Epoch: 5| Step: 10
Training loss: 0.47468266490309574
Validation loss: 2.7377094645902194

Epoch: 5| Step: 11
Training loss: 0.2275177450385831
Validation loss: 2.615168731374616

Epoch: 197| Step: 0
Training loss: 0.40940630334461126
Validation loss: 2.6304394019324837

Epoch: 5| Step: 1
Training loss: 0.3567531562751097
Validation loss: 2.5636379498739292

Epoch: 5| Step: 2
Training loss: 0.627558668289211
Validation loss: 2.7273744687576205

Epoch: 5| Step: 3
Training loss: 0.39272639572873674
Validation loss: 2.640004504584072

Epoch: 5| Step: 4
Training loss: 0.5879123214824252
Validation loss: 2.7038207399106007

Epoch: 5| Step: 5
Training loss: 0.3767706671578981
Validation loss: 2.6196433240832073

Epoch: 5| Step: 6
Training loss: 0.5692736688132023
Validation loss: 2.619217627083477

Epoch: 5| Step: 7
Training loss: 0.8061004011956009
Validation loss: 2.5941294561060566

Epoch: 5| Step: 8
Training loss: 1.2685459480248897
Validation loss: 2.688382927810994

Epoch: 5| Step: 9
Training loss: 0.4256041447183544
Validation loss: 2.6581675881900377

Epoch: 5| Step: 10
Training loss: 0.556881340581587
Validation loss: 2.684136115159555

Epoch: 5| Step: 11
Training loss: 0.5565476189261938
Validation loss: 2.5706584971952355

Epoch: 198| Step: 0
Training loss: 0.5154957464803005
Validation loss: 2.6865731200867304

Epoch: 5| Step: 1
Training loss: 0.3043700055646703
Validation loss: 2.5473191433749016

Epoch: 5| Step: 2
Training loss: 0.4426505350268466
Validation loss: 2.671347904452097

Epoch: 5| Step: 3
Training loss: 0.5204225509693682
Validation loss: 2.687278206123157

Epoch: 5| Step: 4
Training loss: 0.5501518982593543
Validation loss: 2.6413217938172853

Epoch: 5| Step: 5
Training loss: 0.6100106958327075
Validation loss: 2.688737318291899

Epoch: 5| Step: 6
Training loss: 0.47785753423357896
Validation loss: 2.7318138662221076

Epoch: 5| Step: 7
Training loss: 0.7872876516783036
Validation loss: 2.6772973603414223

Epoch: 5| Step: 8
Training loss: 0.5151913293031867
Validation loss: 2.637760926548291

Epoch: 5| Step: 9
Training loss: 1.0706424065470406
Validation loss: 2.6162094186453535

Epoch: 5| Step: 10
Training loss: 0.4654983111339626
Validation loss: 2.5796033608701427

Epoch: 5| Step: 11
Training loss: 0.59186797769282
Validation loss: 2.6084170077210462

Epoch: 199| Step: 0
Training loss: 0.5293307698225377
Validation loss: 2.7186964219758987

Epoch: 5| Step: 1
Training loss: 0.3617925803387402
Validation loss: 2.7771506906359815

Epoch: 5| Step: 2
Training loss: 0.4262749495713592
Validation loss: 2.765396184130311

Epoch: 5| Step: 3
Training loss: 0.5073322666326596
Validation loss: 2.7311728556058443

Epoch: 5| Step: 4
Training loss: 0.8602828345846248
Validation loss: 2.7551744142883052

Epoch: 5| Step: 5
Training loss: 0.6727270445747129
Validation loss: 2.6724742046475645

Epoch: 5| Step: 6
Training loss: 0.4441616513015024
Validation loss: 2.6673168970388765

Epoch: 5| Step: 7
Training loss: 0.536987263063159
Validation loss: 2.651214482808282

Epoch: 5| Step: 8
Training loss: 0.751457982716709
Validation loss: 2.6974187057555605

Epoch: 5| Step: 9
Training loss: 1.193330755062266
Validation loss: 2.662089996379308

Epoch: 5| Step: 10
Training loss: 0.352175390277353
Validation loss: 2.7646652467307162

Epoch: 5| Step: 11
Training loss: 0.6685944911153011
Validation loss: 2.706702355042276

Epoch: 200| Step: 0
Training loss: 0.5263826442282115
Validation loss: 2.7394503239638595

Epoch: 5| Step: 1
Training loss: 0.886704600217069
Validation loss: 2.703440638582869

Epoch: 5| Step: 2
Training loss: 1.1076460784604367
Validation loss: 2.7977002487408575

Epoch: 5| Step: 3
Training loss: 0.6690134501038874
Validation loss: 2.6824289576878257

Epoch: 5| Step: 4
Training loss: 0.4085616768380367
Validation loss: 2.6881863046730543

Epoch: 5| Step: 5
Training loss: 0.5886829397962691
Validation loss: 2.6533044639790813

Epoch: 5| Step: 6
Training loss: 0.8620555340608467
Validation loss: 2.5912196176014115

Epoch: 5| Step: 7
Training loss: 0.9068332636750843
Validation loss: 2.6451872627548965

Epoch: 5| Step: 8
Training loss: 0.6508327504968252
Validation loss: 2.6166690863357176

Epoch: 5| Step: 9
Training loss: 0.31477563324689545
Validation loss: 2.6233024595734946

Epoch: 5| Step: 10
Training loss: 0.49129300351506006
Validation loss: 2.5449580543505133

Epoch: 5| Step: 11
Training loss: 0.32743804411124794
Validation loss: 2.7454528965202005

Epoch: 201| Step: 0
Training loss: 0.6276344328951903
Validation loss: 2.6207435097233613

Epoch: 5| Step: 1
Training loss: 0.5807743454082209
Validation loss: 2.6264608609732596

Epoch: 5| Step: 2
Training loss: 0.4201362594893524
Validation loss: 2.6872363145977616

Epoch: 5| Step: 3
Training loss: 0.4918122299015197
Validation loss: 2.6516633319733867

Epoch: 5| Step: 4
Training loss: 0.8219443665447443
Validation loss: 2.55741668493994

Epoch: 5| Step: 5
Training loss: 0.6696154502528073
Validation loss: 2.6272717553274734

Epoch: 5| Step: 6
Training loss: 0.47971708535775387
Validation loss: 2.582399648835107

Epoch: 5| Step: 7
Training loss: 0.5332527277304859
Validation loss: 2.6066376801031157

Epoch: 5| Step: 8
Training loss: 0.6427746735951846
Validation loss: 2.6361017310554358

Epoch: 5| Step: 9
Training loss: 0.4361403488963529
Validation loss: 2.6533638402209028

Epoch: 5| Step: 10
Training loss: 1.104349493089467
Validation loss: 2.6092526298656624

Epoch: 5| Step: 11
Training loss: 0.3453683255669355
Validation loss: 2.6077446460372085

Epoch: 202| Step: 0
Training loss: 0.48734190040034364
Validation loss: 2.7085093196520535

Epoch: 5| Step: 1
Training loss: 1.1143990242465664
Validation loss: 2.717752152968526

Epoch: 5| Step: 2
Training loss: 0.6805541334223864
Validation loss: 2.658799582184809

Epoch: 5| Step: 3
Training loss: 0.5280860480215229
Validation loss: 2.663172009033858

Epoch: 5| Step: 4
Training loss: 0.6834274743717957
Validation loss: 2.6990333857837094

Epoch: 5| Step: 5
Training loss: 0.652844927481366
Validation loss: 2.632769983327536

Epoch: 5| Step: 6
Training loss: 0.5763831317057458
Validation loss: 2.646137776969166

Epoch: 5| Step: 7
Training loss: 0.6447418100148244
Validation loss: 2.647788344264463

Epoch: 5| Step: 8
Training loss: 0.4496864372118916
Validation loss: 2.6449035352436243

Epoch: 5| Step: 9
Training loss: 0.5035081222129082
Validation loss: 2.6485552016128717

Epoch: 5| Step: 10
Training loss: 0.45612248114917237
Validation loss: 2.7113085922433826

Epoch: 5| Step: 11
Training loss: 0.3413742286103514
Validation loss: 2.7372096890475146

Epoch: 203| Step: 0
Training loss: 1.273380442084096
Validation loss: 2.701959752060956

Epoch: 5| Step: 1
Training loss: 0.42642974464490624
Validation loss: 2.7657072015532593

Epoch: 5| Step: 2
Training loss: 0.4778986476083232
Validation loss: 2.720261420409993

Epoch: 5| Step: 3
Training loss: 0.4927663880462743
Validation loss: 2.6363937893526317

Epoch: 5| Step: 4
Training loss: 0.5097507460019507
Validation loss: 2.657629552394563

Epoch: 5| Step: 5
Training loss: 0.5011987620966329
Validation loss: 2.663505346781355

Epoch: 5| Step: 6
Training loss: 0.6078279615852938
Validation loss: 2.7247767279671136

Epoch: 5| Step: 7
Training loss: 0.7498384142695966
Validation loss: 2.7154235330525776

Epoch: 5| Step: 8
Training loss: 0.5829569476509253
Validation loss: 2.654919537961168

Epoch: 5| Step: 9
Training loss: 0.34225396246807155
Validation loss: 2.6722084305833183

Epoch: 5| Step: 10
Training loss: 0.6797247909313235
Validation loss: 2.8285322019121737

Epoch: 5| Step: 11
Training loss: 0.738672707737252
Validation loss: 2.7508358768758385

Epoch: 204| Step: 0
Training loss: 0.6343756313978539
Validation loss: 2.710588361260728

Epoch: 5| Step: 1
Training loss: 1.287918230292561
Validation loss: 2.6637547782307323

Epoch: 5| Step: 2
Training loss: 0.501994238924883
Validation loss: 2.6791543050117927

Epoch: 5| Step: 3
Training loss: 0.6006011216640003
Validation loss: 2.6113055695896112

Epoch: 5| Step: 4
Training loss: 0.37775048238343517
Validation loss: 2.6137591021571

Epoch: 5| Step: 5
Training loss: 0.5393844417130204
Validation loss: 2.6621262794008294

Epoch: 5| Step: 6
Training loss: 0.5562183853337679
Validation loss: 2.6349090846288306

Epoch: 5| Step: 7
Training loss: 0.5227925611799293
Validation loss: 2.7387493928751643

Epoch: 5| Step: 8
Training loss: 0.45783781951569036
Validation loss: 2.638567007801297

Epoch: 5| Step: 9
Training loss: 0.7438498502110261
Validation loss: 2.6674560791554143

Epoch: 5| Step: 10
Training loss: 0.5578577755203483
Validation loss: 2.6995656682577893

Epoch: 5| Step: 11
Training loss: 0.5416848900981779
Validation loss: 2.7143661884009953

Epoch: 205| Step: 0
Training loss: 0.47059981609305224
Validation loss: 2.6581686794526043

Epoch: 5| Step: 1
Training loss: 0.7043217964015828
Validation loss: 2.670320679674591

Epoch: 5| Step: 2
Training loss: 0.40350963591777556
Validation loss: 2.663259722741175

Epoch: 5| Step: 3
Training loss: 0.727589076838465
Validation loss: 2.633602310629961

Epoch: 5| Step: 4
Training loss: 0.559500458569718
Validation loss: 2.613581018213705

Epoch: 5| Step: 5
Training loss: 0.47322447173319704
Validation loss: 2.618081151874818

Epoch: 5| Step: 6
Training loss: 0.5582803500595548
Validation loss: 2.7028584358039325

Epoch: 5| Step: 7
Training loss: 0.39572331714984443
Validation loss: 2.5797112488264804

Epoch: 5| Step: 8
Training loss: 0.4889159692985035
Validation loss: 2.6766272513831533

Epoch: 5| Step: 9
Training loss: 1.1439324071962849
Validation loss: 2.678565265784667

Epoch: 5| Step: 10
Training loss: 0.6034213983253405
Validation loss: 2.6629533854781084

Epoch: 5| Step: 11
Training loss: 0.5404798974472607
Validation loss: 2.571575252698972

Epoch: 206| Step: 0
Training loss: 0.6250357140827528
Validation loss: 2.6727207510951088

Epoch: 5| Step: 1
Training loss: 0.684058265899478
Validation loss: 2.676194679268145

Epoch: 5| Step: 2
Training loss: 1.0876509506870278
Validation loss: 2.6951653592401756

Epoch: 5| Step: 3
Training loss: 0.5053242389870065
Validation loss: 2.718006324636265

Epoch: 5| Step: 4
Training loss: 0.56885520045963
Validation loss: 2.651590456615704

Epoch: 5| Step: 5
Training loss: 0.40301444807373626
Validation loss: 2.6475393109439413

Epoch: 5| Step: 6
Training loss: 0.36963894426026844
Validation loss: 2.6769012186371244

Epoch: 5| Step: 7
Training loss: 0.4516347352168284
Validation loss: 2.694795796720871

Epoch: 5| Step: 8
Training loss: 0.32766242573111165
Validation loss: 2.6509141285513715

Epoch: 5| Step: 9
Training loss: 0.6658653917659557
Validation loss: 2.6976462097305185

Epoch: 5| Step: 10
Training loss: 0.41056427415152896
Validation loss: 2.6996219847225533

Epoch: 5| Step: 11
Training loss: 0.30327056653693524
Validation loss: 2.6761750945409353

Epoch: 207| Step: 0
Training loss: 0.38130498395814444
Validation loss: 2.66360938879116

Epoch: 5| Step: 1
Training loss: 0.38258919723034074
Validation loss: 2.705364629857124

Epoch: 5| Step: 2
Training loss: 0.6446068459307349
Validation loss: 2.6307137120246766

Epoch: 5| Step: 3
Training loss: 0.5842205067781866
Validation loss: 2.5974409850756133

Epoch: 5| Step: 4
Training loss: 0.3411514728264435
Validation loss: 2.6061490232207047

Epoch: 5| Step: 5
Training loss: 0.5610028582141435
Validation loss: 2.723893930076208

Epoch: 5| Step: 6
Training loss: 0.3517700430413382
Validation loss: 2.753095344213424

Epoch: 5| Step: 7
Training loss: 1.0805505198928227
Validation loss: 2.6693061540949445

Epoch: 5| Step: 8
Training loss: 0.46111565719161063
Validation loss: 2.630019709304139

Epoch: 5| Step: 9
Training loss: 0.7161303755507998
Validation loss: 2.7116989583419957

Epoch: 5| Step: 10
Training loss: 0.5052847525882016
Validation loss: 2.730635358232413

Epoch: 5| Step: 11
Training loss: 0.3915021394388587
Validation loss: 2.6656440187098487

Epoch: 208| Step: 0
Training loss: 0.5107834108248025
Validation loss: 2.724167534336089

Epoch: 5| Step: 1
Training loss: 1.1159829001056634
Validation loss: 2.702722309966104

Epoch: 5| Step: 2
Training loss: 0.5158378855186506
Validation loss: 2.6561762257223047

Epoch: 5| Step: 3
Training loss: 0.42721243589522256
Validation loss: 2.71405067843899

Epoch: 5| Step: 4
Training loss: 0.44669305391916714
Validation loss: 2.6528430294635292

Epoch: 5| Step: 5
Training loss: 0.40749622811286057
Validation loss: 2.740608137275322

Epoch: 5| Step: 6
Training loss: 0.46182445277921574
Validation loss: 2.7433415490495188

Epoch: 5| Step: 7
Training loss: 0.44717901132498805
Validation loss: 2.7427291226543864

Epoch: 5| Step: 8
Training loss: 0.39498633397279526
Validation loss: 2.6953067871622918

Epoch: 5| Step: 9
Training loss: 0.4423955784991472
Validation loss: 2.720357025325487

Epoch: 5| Step: 10
Training loss: 0.8554731395034003
Validation loss: 2.7366249019740283

Epoch: 5| Step: 11
Training loss: 0.32184596625184575
Validation loss: 2.740046611868574

Epoch: 209| Step: 0
Training loss: 0.4379036437795302
Validation loss: 2.7754831605142827

Epoch: 5| Step: 1
Training loss: 0.48147633976802673
Validation loss: 2.712895725905491

Epoch: 5| Step: 2
Training loss: 0.43804555324996597
Validation loss: 2.7489856236298036

Epoch: 5| Step: 3
Training loss: 0.3921043231803612
Validation loss: 2.6848016470154805

Epoch: 5| Step: 4
Training loss: 0.49964597208588213
Validation loss: 2.6595991114174717

Epoch: 5| Step: 5
Training loss: 0.4074418484554796
Validation loss: 2.6685010975616317

Epoch: 5| Step: 6
Training loss: 1.1631448187925473
Validation loss: 2.6585297282287454

Epoch: 5| Step: 7
Training loss: 0.4084172212138624
Validation loss: 2.7174262591408165

Epoch: 5| Step: 8
Training loss: 0.3762667836282755
Validation loss: 2.6914983326699304

Epoch: 5| Step: 9
Training loss: 0.7684090656916348
Validation loss: 2.7835470136597715

Epoch: 5| Step: 10
Training loss: 0.4587761914107064
Validation loss: 2.7049219520189163

Epoch: 5| Step: 11
Training loss: 0.6904711245521655
Validation loss: 2.7624552193057283

Epoch: 210| Step: 0
Training loss: 0.4296468195298194
Validation loss: 2.772546691392443

Epoch: 5| Step: 1
Training loss: 0.4435938076705868
Validation loss: 2.701026772853884

Epoch: 5| Step: 2
Training loss: 0.4903643614339166
Validation loss: 2.693814370845865

Epoch: 5| Step: 3
Training loss: 0.36396943814361704
Validation loss: 2.6633473235267355

Epoch: 5| Step: 4
Training loss: 0.7169750522279509
Validation loss: 2.623287618784882

Epoch: 5| Step: 5
Training loss: 0.4903988809150417
Validation loss: 2.6334901686533714

Epoch: 5| Step: 6
Training loss: 1.0856191593906885
Validation loss: 2.7484764950812255

Epoch: 5| Step: 7
Training loss: 0.7348676611684258
Validation loss: 2.739843865010165

Epoch: 5| Step: 8
Training loss: 0.37356866424463064
Validation loss: 2.8046123508738763

Epoch: 5| Step: 9
Training loss: 0.5846818821941457
Validation loss: 2.7742210105285916

Epoch: 5| Step: 10
Training loss: 0.6854734245577414
Validation loss: 2.8278277400756937

Epoch: 5| Step: 11
Training loss: 0.4657829957485915
Validation loss: 2.6907574444175504

Epoch: 211| Step: 0
Training loss: 0.3621562232006727
Validation loss: 2.6314055459506864

Epoch: 5| Step: 1
Training loss: 0.3944598784900829
Validation loss: 2.6528126597538306

Epoch: 5| Step: 2
Training loss: 0.4743034412857576
Validation loss: 2.6901380709751606

Epoch: 5| Step: 3
Training loss: 0.46532258447462727
Validation loss: 2.6602826230826198

Epoch: 5| Step: 4
Training loss: 0.3437360955807437
Validation loss: 2.762246854325443

Epoch: 5| Step: 5
Training loss: 0.7998796178723495
Validation loss: 2.6853691014491115

Epoch: 5| Step: 6
Training loss: 1.0726186035840408
Validation loss: 2.7263993120590726

Epoch: 5| Step: 7
Training loss: 0.5633531564219334
Validation loss: 2.624754292478139

Epoch: 5| Step: 8
Training loss: 0.5056988671363843
Validation loss: 2.679434472419061

Epoch: 5| Step: 9
Training loss: 0.3658144826674
Validation loss: 2.6603131240992766

Epoch: 5| Step: 10
Training loss: 0.4776316671936918
Validation loss: 2.584587347831193

Epoch: 5| Step: 11
Training loss: 0.6099268053260363
Validation loss: 2.661232105700845

Epoch: 212| Step: 0
Training loss: 0.4138252370257192
Validation loss: 2.7178118830163998

Epoch: 5| Step: 1
Training loss: 0.7041582145597488
Validation loss: 2.674321090399755

Epoch: 5| Step: 2
Training loss: 0.8216634615925251
Validation loss: 2.754675445270614

Epoch: 5| Step: 3
Training loss: 0.5609008787734177
Validation loss: 2.772785724473498

Epoch: 5| Step: 4
Training loss: 0.3824935674438131
Validation loss: 2.6701310472796287

Epoch: 5| Step: 5
Training loss: 0.38833407957935806
Validation loss: 2.746670491920357

Epoch: 5| Step: 6
Training loss: 0.48698439229789603
Validation loss: 2.757976274967617

Epoch: 5| Step: 7
Training loss: 1.0798660815180101
Validation loss: 2.728485190991621

Epoch: 5| Step: 8
Training loss: 0.3726993759760585
Validation loss: 2.734709760973207

Epoch: 5| Step: 9
Training loss: 0.4855835818642554
Validation loss: 2.7043146922169123

Epoch: 5| Step: 10
Training loss: 0.3810789991138288
Validation loss: 2.5850275480486036

Epoch: 5| Step: 11
Training loss: 0.37311713071413055
Validation loss: 2.7276981542736247

Epoch: 213| Step: 0
Training loss: 1.1918109144035929
Validation loss: 2.6768271970611077

Epoch: 5| Step: 1
Training loss: 0.45626824420874634
Validation loss: 2.7455532506130904

Epoch: 5| Step: 2
Training loss: 0.3780879987787984
Validation loss: 2.604586984410827

Epoch: 5| Step: 3
Training loss: 0.4320054734664779
Validation loss: 2.713500435650764

Epoch: 5| Step: 4
Training loss: 0.40980329313141883
Validation loss: 2.6910976866046363

Epoch: 5| Step: 5
Training loss: 0.4325599029709982
Validation loss: 2.6110821353429636

Epoch: 5| Step: 6
Training loss: 0.3212480373916345
Validation loss: 2.68588588724927

Epoch: 5| Step: 7
Training loss: 0.3744759474161893
Validation loss: 2.6297957949779853

Epoch: 5| Step: 8
Training loss: 0.40338379958312764
Validation loss: 2.7111792845918306

Epoch: 5| Step: 9
Training loss: 0.31028969630020514
Validation loss: 2.707128544132855

Epoch: 5| Step: 10
Training loss: 0.6239054154854535
Validation loss: 2.6876942320431256

Epoch: 5| Step: 11
Training loss: 0.3743097588844335
Validation loss: 2.650855990329714

Epoch: 214| Step: 0
Training loss: 0.3384030045904926
Validation loss: 2.7124974346002264

Epoch: 5| Step: 1
Training loss: 1.0273949207862798
Validation loss: 2.6570092406422674

Epoch: 5| Step: 2
Training loss: 0.49321598497263563
Validation loss: 2.6871705296851496

Epoch: 5| Step: 3
Training loss: 0.38689004591493353
Validation loss: 2.711446635489352

Epoch: 5| Step: 4
Training loss: 0.5005294261860325
Validation loss: 2.657748719559649

Epoch: 5| Step: 5
Training loss: 0.3999096284046809
Validation loss: 2.7923619925053713

Epoch: 5| Step: 6
Training loss: 0.6074363976609972
Validation loss: 2.6763567229100245

Epoch: 5| Step: 7
Training loss: 0.4554877995323721
Validation loss: 2.671498333442278

Epoch: 5| Step: 8
Training loss: 0.7557294867050647
Validation loss: 2.5950442153089153

Epoch: 5| Step: 9
Training loss: 0.37399973184147567
Validation loss: 2.625267840148119

Epoch: 5| Step: 10
Training loss: 0.51181568072187
Validation loss: 2.6679585551136467

Epoch: 5| Step: 11
Training loss: 0.24969485405749486
Validation loss: 2.6379203394394932

Epoch: 215| Step: 0
Training loss: 0.3228815146766296
Validation loss: 2.6706831878458037

Epoch: 5| Step: 1
Training loss: 0.4823283363501731
Validation loss: 2.6564160276397972

Epoch: 5| Step: 2
Training loss: 0.3309469694812592
Validation loss: 2.7244380336469627

Epoch: 5| Step: 3
Training loss: 0.4657691751557427
Validation loss: 2.71484611931933

Epoch: 5| Step: 4
Training loss: 0.361268342717314
Validation loss: 2.6768275793095384

Epoch: 5| Step: 5
Training loss: 0.564288844717286
Validation loss: 2.701040018779714

Epoch: 5| Step: 6
Training loss: 0.4664961193154313
Validation loss: 2.7293401049086734

Epoch: 5| Step: 7
Training loss: 0.24578636894060893
Validation loss: 2.6648588845345023

Epoch: 5| Step: 8
Training loss: 1.1373111190758167
Validation loss: 2.7082269403149732

Epoch: 5| Step: 9
Training loss: 0.46972470669766425
Validation loss: 2.6987309233571506

Epoch: 5| Step: 10
Training loss: 0.445254539599401
Validation loss: 2.7225600982282017

Epoch: 5| Step: 11
Training loss: 0.3944866041851108
Validation loss: 2.6544405552345594

Epoch: 216| Step: 0
Training loss: 0.46728793056704837
Validation loss: 2.7278429975846743

Epoch: 5| Step: 1
Training loss: 1.0544913215442882
Validation loss: 2.771278389822731

Epoch: 5| Step: 2
Training loss: 0.4971128344381732
Validation loss: 2.6952613604573052

Epoch: 5| Step: 3
Training loss: 0.5926677729087105
Validation loss: 2.732801471453123

Epoch: 5| Step: 4
Training loss: 0.7337747515089327
Validation loss: 2.7070642481228937

Epoch: 5| Step: 5
Training loss: 0.47331592144416446
Validation loss: 2.725922021996464

Epoch: 5| Step: 6
Training loss: 0.4201548794872648
Validation loss: 2.6898817737944976

Epoch: 5| Step: 7
Training loss: 0.3936000069018301
Validation loss: 2.674244738850086

Epoch: 5| Step: 8
Training loss: 0.4450302902906715
Validation loss: 2.6853162224873013

Epoch: 5| Step: 9
Training loss: 0.44840269186256604
Validation loss: 2.642480822583507

Epoch: 5| Step: 10
Training loss: 0.34890409541543194
Validation loss: 2.631413285118973

Epoch: 5| Step: 11
Training loss: 0.4696536731277428
Validation loss: 2.723468883637792

Epoch: 217| Step: 0
Training loss: 0.5507431017062273
Validation loss: 2.703384328173824

Epoch: 5| Step: 1
Training loss: 0.4377078856705427
Validation loss: 2.6172890752562776

Epoch: 5| Step: 2
Training loss: 0.42403726647456635
Validation loss: 2.683245422026942

Epoch: 5| Step: 3
Training loss: 0.5032770531286028
Validation loss: 2.7375622257435657

Epoch: 5| Step: 4
Training loss: 1.0707929326512122
Validation loss: 2.62436593435947

Epoch: 5| Step: 5
Training loss: 0.5844552683653919
Validation loss: 2.6361422287587515

Epoch: 5| Step: 6
Training loss: 0.6505417748392525
Validation loss: 2.7448690296154896

Epoch: 5| Step: 7
Training loss: 0.4520867390072193
Validation loss: 2.629569198204915

Epoch: 5| Step: 8
Training loss: 0.29895024515745805
Validation loss: 2.6900381330649474

Epoch: 5| Step: 9
Training loss: 0.5308511583199017
Validation loss: 2.639115208546816

Epoch: 5| Step: 10
Training loss: 0.3575162294011842
Validation loss: 2.6991404417596727

Epoch: 5| Step: 11
Training loss: 0.7300145578239225
Validation loss: 2.6291219803226262

Epoch: 218| Step: 0
Training loss: 0.3865779080785614
Validation loss: 2.6904012264308657

Epoch: 5| Step: 1
Training loss: 0.6953749682193127
Validation loss: 2.7303476120286643

Epoch: 5| Step: 2
Training loss: 0.4515532000946895
Validation loss: 2.6936870520391984

Epoch: 5| Step: 3
Training loss: 0.5135244876033529
Validation loss: 2.7214759629051444

Epoch: 5| Step: 4
Training loss: 0.3388827537457246
Validation loss: 2.721874549915322

Epoch: 5| Step: 5
Training loss: 0.39426853384189775
Validation loss: 2.678792564936831

Epoch: 5| Step: 6
Training loss: 0.4524477139187038
Validation loss: 2.7070895028647066

Epoch: 5| Step: 7
Training loss: 0.7574047289319682
Validation loss: 2.7015636212427694

Epoch: 5| Step: 8
Training loss: 1.0954410015047409
Validation loss: 2.7246024219419662

Epoch: 5| Step: 9
Training loss: 0.5440011946019913
Validation loss: 2.793047767357254

Epoch: 5| Step: 10
Training loss: 0.4067243594274835
Validation loss: 2.683925802463089

Epoch: 5| Step: 11
Training loss: 0.2968326588602844
Validation loss: 2.7027333018049053

Epoch: 219| Step: 0
Training loss: 0.4372322080382834
Validation loss: 2.6670646010459502

Epoch: 5| Step: 1
Training loss: 0.48118616832643524
Validation loss: 2.670342580359126

Epoch: 5| Step: 2
Training loss: 0.37593823522430847
Validation loss: 2.669943220848065

Epoch: 5| Step: 3
Training loss: 1.115746856360224
Validation loss: 2.6236485605196287

Epoch: 5| Step: 4
Training loss: 0.4302195116519732
Validation loss: 2.6301648139500697

Epoch: 5| Step: 5
Training loss: 0.3907149020691018
Validation loss: 2.672885718479908

Epoch: 5| Step: 6
Training loss: 0.47114229094529864
Validation loss: 2.68339548577028

Epoch: 5| Step: 7
Training loss: 0.49407878684814494
Validation loss: 2.624580898585575

Epoch: 5| Step: 8
Training loss: 0.585307329178438
Validation loss: 2.703200377808003

Epoch: 5| Step: 9
Training loss: 0.42617835329273546
Validation loss: 2.6112402190479798

Epoch: 5| Step: 10
Training loss: 0.40574759815678024
Validation loss: 2.6045768808888994

Epoch: 5| Step: 11
Training loss: 0.38660847411308785
Validation loss: 2.643973922415014

Epoch: 220| Step: 0
Training loss: 0.4636845921971431
Validation loss: 2.7093348387572593

Epoch: 5| Step: 1
Training loss: 0.5469531684595403
Validation loss: 2.6786900249596193

Epoch: 5| Step: 2
Training loss: 0.29371213060134926
Validation loss: 2.703778478246421

Epoch: 5| Step: 3
Training loss: 0.4615131436756626
Validation loss: 2.656976488284316

Epoch: 5| Step: 4
Training loss: 0.3635720350521146
Validation loss: 2.6052963012939694

Epoch: 5| Step: 5
Training loss: 0.7471477792505319
Validation loss: 2.702421938509546

Epoch: 5| Step: 6
Training loss: 0.9934481924224972
Validation loss: 2.733812710304834

Epoch: 5| Step: 7
Training loss: 0.6182947487715629
Validation loss: 2.712489075279796

Epoch: 5| Step: 8
Training loss: 0.4319520405179459
Validation loss: 2.7170403684734774

Epoch: 5| Step: 9
Training loss: 0.42159850278571326
Validation loss: 2.702321522983303

Epoch: 5| Step: 10
Training loss: 0.5296468105835569
Validation loss: 2.7785644102218057

Epoch: 5| Step: 11
Training loss: 0.3997868894073267
Validation loss: 2.7001397769268682

Epoch: 221| Step: 0
Training loss: 0.39531951943298355
Validation loss: 2.6839336048651052

Epoch: 5| Step: 1
Training loss: 0.5076558678491433
Validation loss: 2.743344717571868

Epoch: 5| Step: 2
Training loss: 0.5415033834057581
Validation loss: 2.7416521330470442

Epoch: 5| Step: 3
Training loss: 0.4187213503587942
Validation loss: 2.7192414230590654

Epoch: 5| Step: 4
Training loss: 0.49266291167706333
Validation loss: 2.7579604515322704

Epoch: 5| Step: 5
Training loss: 0.3825182659799249
Validation loss: 2.7675011120914292

Epoch: 5| Step: 6
Training loss: 0.3416164248828287
Validation loss: 2.74287595737718

Epoch: 5| Step: 7
Training loss: 0.3709925865013584
Validation loss: 2.7266856751405064

Epoch: 5| Step: 8
Training loss: 0.644209417275076
Validation loss: 2.7525783069638576

Epoch: 5| Step: 9
Training loss: 0.4366178133198626
Validation loss: 2.7232563118293727

Epoch: 5| Step: 10
Training loss: 0.4858675694821202
Validation loss: 2.725905298202232

Epoch: 5| Step: 11
Training loss: 2.102118889993436
Validation loss: 2.7090301418128435

Epoch: 222| Step: 0
Training loss: 0.7478481656284053
Validation loss: 2.6792828854043007

Epoch: 5| Step: 1
Training loss: 0.49501373594665393
Validation loss: 2.7069736527796704

Epoch: 5| Step: 2
Training loss: 0.44355633431737407
Validation loss: 2.684376557556577

Epoch: 5| Step: 3
Training loss: 0.44200960631525466
Validation loss: 2.687942560854024

Epoch: 5| Step: 4
Training loss: 0.5066440049810906
Validation loss: 2.711818702091702

Epoch: 5| Step: 5
Training loss: 0.23109739848797453
Validation loss: 2.7700677162918246

Epoch: 5| Step: 6
Training loss: 0.4486808209770339
Validation loss: 2.715332719052429

Epoch: 5| Step: 7
Training loss: 0.45437887604646165
Validation loss: 2.7559039109828904

Epoch: 5| Step: 8
Training loss: 0.9768071898039571
Validation loss: 2.6111177727318955

Epoch: 5| Step: 9
Training loss: 0.32313269521157245
Validation loss: 2.737983509660991

Epoch: 5| Step: 10
Training loss: 0.4284297394553959
Validation loss: 2.7873807051923696

Epoch: 5| Step: 11
Training loss: 0.3005435177501743
Validation loss: 2.7062458368670224

Epoch: 223| Step: 0
Training loss: 0.48128434095844697
Validation loss: 2.675635556155111

Epoch: 5| Step: 1
Training loss: 0.998599651464275
Validation loss: 2.6799703806455

Epoch: 5| Step: 2
Training loss: 0.3427774586672631
Validation loss: 2.676908046955738

Epoch: 5| Step: 3
Training loss: 0.7212291751545948
Validation loss: 2.6835154041179616

Epoch: 5| Step: 4
Training loss: 0.5439077806108785
Validation loss: 2.7674691181705477

Epoch: 5| Step: 5
Training loss: 0.4115391261618518
Validation loss: 2.744012125972956

Epoch: 5| Step: 6
Training loss: 0.559744390070252
Validation loss: 2.7879073228870945

Epoch: 5| Step: 7
Training loss: 0.5201801177462022
Validation loss: 2.809039749436448

Epoch: 5| Step: 8
Training loss: 0.5288329678005315
Validation loss: 2.7468356147404664

Epoch: 5| Step: 9
Training loss: 0.37652698206882945
Validation loss: 2.7081993522271124

Epoch: 5| Step: 10
Training loss: 0.5647771624601527
Validation loss: 2.722045067263668

Epoch: 5| Step: 11
Training loss: 0.44552513533732996
Validation loss: 2.765148189987251

Epoch: 224| Step: 0
Training loss: 0.3505360878699563
Validation loss: 2.77374018060689

Epoch: 5| Step: 1
Training loss: 0.4293699478285296
Validation loss: 2.71367988612699

Epoch: 5| Step: 2
Training loss: 0.7755508833768446
Validation loss: 2.779584187543857

Epoch: 5| Step: 3
Training loss: 0.40918130806030706
Validation loss: 2.74360977776181

Epoch: 5| Step: 4
Training loss: 0.4155118157144713
Validation loss: 2.740182993473521

Epoch: 5| Step: 5
Training loss: 0.5471928081766949
Validation loss: 2.760136591300272

Epoch: 5| Step: 6
Training loss: 0.5258684219264481
Validation loss: 2.689257571946973

Epoch: 5| Step: 7
Training loss: 0.45677578951308234
Validation loss: 2.6626356597749568

Epoch: 5| Step: 8
Training loss: 0.9570896053039504
Validation loss: 2.7020783906438988

Epoch: 5| Step: 9
Training loss: 0.40057452560827156
Validation loss: 2.8073502123406886

Epoch: 5| Step: 10
Training loss: 0.4564698022974044
Validation loss: 2.813908930486731

Epoch: 5| Step: 11
Training loss: 0.2320179675375299
Validation loss: 2.7462305873242028

Epoch: 225| Step: 0
Training loss: 0.37343391592308955
Validation loss: 2.6552439448673657

Epoch: 5| Step: 1
Training loss: 0.354065441176613
Validation loss: 2.726248377837839

Epoch: 5| Step: 2
Training loss: 0.381848620426053
Validation loss: 2.720945699356744

Epoch: 5| Step: 3
Training loss: 0.4580800339097261
Validation loss: 2.708579640314604

Epoch: 5| Step: 4
Training loss: 0.5081903665687183
Validation loss: 2.674467665595881

Epoch: 5| Step: 5
Training loss: 0.3811547723253441
Validation loss: 2.723968357532114

Epoch: 5| Step: 6
Training loss: 0.44642879043301253
Validation loss: 2.661791916164365

Epoch: 5| Step: 7
Training loss: 0.9773586232420514
Validation loss: 2.7427474172096282

Epoch: 5| Step: 8
Training loss: 0.43405714274781254
Validation loss: 2.7406108667349236

Epoch: 5| Step: 9
Training loss: 0.4076033753932438
Validation loss: 2.7925876988830107

Epoch: 5| Step: 10
Training loss: 0.7381045013863117
Validation loss: 2.655234078997943

Epoch: 5| Step: 11
Training loss: 0.523245477327867
Validation loss: 2.7311450264469275

Epoch: 226| Step: 0
Training loss: 0.37200572737391757
Validation loss: 2.79717841536035

Epoch: 5| Step: 1
Training loss: 0.9656206470379043
Validation loss: 2.692019495608393

Epoch: 5| Step: 2
Training loss: 0.41688479038849585
Validation loss: 2.6715831039442732

Epoch: 5| Step: 3
Training loss: 0.6009294721411352
Validation loss: 2.665717124763199

Epoch: 5| Step: 4
Training loss: 0.3874778041327842
Validation loss: 2.693558908456958

Epoch: 5| Step: 5
Training loss: 0.4301431840546599
Validation loss: 2.725232777437897

Epoch: 5| Step: 6
Training loss: 0.45188286316758697
Validation loss: 2.732137276673161

Epoch: 5| Step: 7
Training loss: 0.43010847104149036
Validation loss: 2.650371647961041

Epoch: 5| Step: 8
Training loss: 0.4068360136840573
Validation loss: 2.7064059784468086

Epoch: 5| Step: 9
Training loss: 0.6426624138460214
Validation loss: 2.6974488899791096

Epoch: 5| Step: 10
Training loss: 0.3471141617895876
Validation loss: 2.7074727023689693

Epoch: 5| Step: 11
Training loss: 0.24102743790672307
Validation loss: 2.7064721180047955

Epoch: 227| Step: 0
Training loss: 0.9401699828605773
Validation loss: 2.611422086027182

Epoch: 5| Step: 1
Training loss: 0.401249332249166
Validation loss: 2.7000185255015574

Epoch: 5| Step: 2
Training loss: 0.533918131896207
Validation loss: 2.7117210157379996

Epoch: 5| Step: 3
Training loss: 0.5300695543713732
Validation loss: 2.752028937792465

Epoch: 5| Step: 4
Training loss: 0.43975958416954686
Validation loss: 2.736456405823872

Epoch: 5| Step: 5
Training loss: 0.6950939134912205
Validation loss: 2.791770752821552

Epoch: 5| Step: 6
Training loss: 0.5189592467975987
Validation loss: 2.7470414763292226

Epoch: 5| Step: 7
Training loss: 0.3997306967709468
Validation loss: 2.715697174956842

Epoch: 5| Step: 8
Training loss: 0.36065871631482077
Validation loss: 2.724466073518792

Epoch: 5| Step: 9
Training loss: 0.5640465615258257
Validation loss: 2.700486058177108

Epoch: 5| Step: 10
Training loss: 0.681234528427126
Validation loss: 2.643609904912851

Epoch: 5| Step: 11
Training loss: 0.36146365536482916
Validation loss: 2.7391600874152653

Epoch: 228| Step: 0
Training loss: 0.45148016565106236
Validation loss: 2.725510493562081

Epoch: 5| Step: 1
Training loss: 0.4226767374597855
Validation loss: 2.702709529898694

Epoch: 5| Step: 2
Training loss: 0.41535313111145994
Validation loss: 2.7735943279789037

Epoch: 5| Step: 3
Training loss: 0.6230141801536797
Validation loss: 2.7517101486510906

Epoch: 5| Step: 4
Training loss: 0.8939539283235565
Validation loss: 2.7088103436724125

Epoch: 5| Step: 5
Training loss: 0.43017998995329615
Validation loss: 2.7933187305479192

Epoch: 5| Step: 6
Training loss: 0.47745627093178317
Validation loss: 2.7711259369530885

Epoch: 5| Step: 7
Training loss: 0.34334242022666445
Validation loss: 2.691142013416172

Epoch: 5| Step: 8
Training loss: 0.44760323987862943
Validation loss: 2.7200686519855313

Epoch: 5| Step: 9
Training loss: 0.512741726182223
Validation loss: 2.7061422924195426

Epoch: 5| Step: 10
Training loss: 0.7039055200841847
Validation loss: 2.7185211194915766

Epoch: 5| Step: 11
Training loss: 0.4175566665088913
Validation loss: 2.742610224992492

Epoch: 229| Step: 0
Training loss: 0.46075456836296436
Validation loss: 2.7530834186198034

Epoch: 5| Step: 1
Training loss: 0.4310169806708872
Validation loss: 2.6459769049811785

Epoch: 5| Step: 2
Training loss: 0.4147363074585005
Validation loss: 2.7341241158330347

Epoch: 5| Step: 3
Training loss: 0.720631086682754
Validation loss: 2.674336650930331

Epoch: 5| Step: 4
Training loss: 0.4372989669500606
Validation loss: 2.6444954919017523

Epoch: 5| Step: 5
Training loss: 0.44508039549237904
Validation loss: 2.666612033483029

Epoch: 5| Step: 6
Training loss: 0.35661777870229
Validation loss: 2.7175502249092616

Epoch: 5| Step: 7
Training loss: 0.9336004855499541
Validation loss: 2.7107664964959604

Epoch: 5| Step: 8
Training loss: 0.3788571670045621
Validation loss: 2.7421280835444692

Epoch: 5| Step: 9
Training loss: 0.37479810445549444
Validation loss: 2.6577249321555403

Epoch: 5| Step: 10
Training loss: 0.43405341793195895
Validation loss: 2.637790650432895

Epoch: 5| Step: 11
Training loss: 0.26431632229451235
Validation loss: 2.7254765341786675

Epoch: 230| Step: 0
Training loss: 0.4324819211268315
Validation loss: 2.694327641661352

Epoch: 5| Step: 1
Training loss: 0.37520228334272987
Validation loss: 2.711190397868755

Epoch: 5| Step: 2
Training loss: 0.9964987436392866
Validation loss: 2.6342112582699606

Epoch: 5| Step: 3
Training loss: 0.5667415810133447
Validation loss: 2.7253815225641738

Epoch: 5| Step: 4
Training loss: 0.5773343530698027
Validation loss: 2.711450299253418

Epoch: 5| Step: 5
Training loss: 0.4345813364066562
Validation loss: 2.7293712391269453

Epoch: 5| Step: 6
Training loss: 0.3219176639132779
Validation loss: 2.769521088216098

Epoch: 5| Step: 7
Training loss: 0.5228970997658987
Validation loss: 2.7051631248514703

Epoch: 5| Step: 8
Training loss: 0.6229215394236693
Validation loss: 2.6524000803265966

Epoch: 5| Step: 9
Training loss: 0.3737517881829087
Validation loss: 2.7769576106954394

Epoch: 5| Step: 10
Training loss: 0.5207023042527846
Validation loss: 2.65488890762694

Epoch: 5| Step: 11
Training loss: 0.3941796501809105
Validation loss: 2.688605317804958

Epoch: 231| Step: 0
Training loss: 0.33245189051599044
Validation loss: 2.7687064280070226

Epoch: 5| Step: 1
Training loss: 0.6952998770950298
Validation loss: 2.7463612903194154

Epoch: 5| Step: 2
Training loss: 0.4929985448475345
Validation loss: 2.668892056021857

Epoch: 5| Step: 3
Training loss: 0.43753794096871174
Validation loss: 2.7538107167801495

Epoch: 5| Step: 4
Training loss: 0.9094491266405703
Validation loss: 2.695134799277817

Epoch: 5| Step: 5
Training loss: 0.5470895346410888
Validation loss: 2.7677111902151603

Epoch: 5| Step: 6
Training loss: 0.4738288080598919
Validation loss: 2.7750394000730245

Epoch: 5| Step: 7
Training loss: 0.38418861149952455
Validation loss: 2.7387319022572676

Epoch: 5| Step: 8
Training loss: 0.43318015640500074
Validation loss: 2.799886854190399

Epoch: 5| Step: 9
Training loss: 0.4591919287668815
Validation loss: 2.750602423183686

Epoch: 5| Step: 10
Training loss: 0.4377561228229712
Validation loss: 2.668288141497744

Epoch: 5| Step: 11
Training loss: 0.3313483789392804
Validation loss: 2.7497871995722907

Epoch: 232| Step: 0
Training loss: 0.4182084724117173
Validation loss: 2.7173092594545785

Epoch: 5| Step: 1
Training loss: 0.3153101455403977
Validation loss: 2.6759473280403405

Epoch: 5| Step: 2
Training loss: 0.44693152263614744
Validation loss: 2.677597532107678

Epoch: 5| Step: 3
Training loss: 0.4391801622146094
Validation loss: 2.7763605393902515

Epoch: 5| Step: 4
Training loss: 0.9662135358397257
Validation loss: 2.7701528378036593

Epoch: 5| Step: 5
Training loss: 0.8177574693693794
Validation loss: 2.7383123369760534

Epoch: 5| Step: 6
Training loss: 0.32863720017513404
Validation loss: 2.8270447496233024

Epoch: 5| Step: 7
Training loss: 0.4530371219001596
Validation loss: 2.713884999428492

Epoch: 5| Step: 8
Training loss: 0.474925873644349
Validation loss: 2.7009266236081206

Epoch: 5| Step: 9
Training loss: 0.44909891935195984
Validation loss: 2.6427236602924156

Epoch: 5| Step: 10
Training loss: 0.4073263727541344
Validation loss: 2.730861802887395

Epoch: 5| Step: 11
Training loss: 0.23448952419961544
Validation loss: 2.765487818359902

Epoch: 233| Step: 0
Training loss: 0.5656788858278966
Validation loss: 2.8160247209225395

Epoch: 5| Step: 1
Training loss: 0.45793237451241564
Validation loss: 2.760350850358306

Epoch: 5| Step: 2
Training loss: 0.4056770980129059
Validation loss: 2.6911463692759745

Epoch: 5| Step: 3
Training loss: 0.4404221933746513
Validation loss: 2.7225330056711043

Epoch: 5| Step: 4
Training loss: 0.33696955348261043
Validation loss: 2.7166686202600006

Epoch: 5| Step: 5
Training loss: 0.9676521294529332
Validation loss: 2.6856256609832942

Epoch: 5| Step: 6
Training loss: 0.4724391249391418
Validation loss: 2.6979840183074564

Epoch: 5| Step: 7
Training loss: 0.407558808763809
Validation loss: 2.6841027167253384

Epoch: 5| Step: 8
Training loss: 0.3763064435906443
Validation loss: 2.7147033398953875

Epoch: 5| Step: 9
Training loss: 0.6409413789271875
Validation loss: 2.846703860669368

Epoch: 5| Step: 10
Training loss: 0.42692053025643334
Validation loss: 2.7260461881311215

Epoch: 5| Step: 11
Training loss: 0.3050497786751985
Validation loss: 2.7079871628904044

Epoch: 234| Step: 0
Training loss: 0.6283710405897702
Validation loss: 2.755554575277952

Epoch: 5| Step: 1
Training loss: 0.3902030764258083
Validation loss: 2.708719421645998

Epoch: 5| Step: 2
Training loss: 0.5060783413092711
Validation loss: 2.6485236162346593

Epoch: 5| Step: 3
Training loss: 0.9182324943691345
Validation loss: 2.682441604769089

Epoch: 5| Step: 4
Training loss: 0.6686467527743835
Validation loss: 2.708820872562766

Epoch: 5| Step: 5
Training loss: 0.4918818205781037
Validation loss: 2.655284848363465

Epoch: 5| Step: 6
Training loss: 0.3432262722505003
Validation loss: 2.6518952295240656

Epoch: 5| Step: 7
Training loss: 0.6584890406803798
Validation loss: 2.6895783172923107

Epoch: 5| Step: 8
Training loss: 0.4829079653976624
Validation loss: 2.671631286987319

Epoch: 5| Step: 9
Training loss: 0.5406725790883901
Validation loss: 2.789784157332932

Epoch: 5| Step: 10
Training loss: 0.3341811643263503
Validation loss: 2.7417797752767803

Epoch: 5| Step: 11
Training loss: 0.3425074792657884
Validation loss: 2.742365151181764

Epoch: 235| Step: 0
Training loss: 0.45381529614084
Validation loss: 2.6308638042364523

Epoch: 5| Step: 1
Training loss: 0.3984124044855128
Validation loss: 2.7019323021986827

Epoch: 5| Step: 2
Training loss: 0.5504335428673705
Validation loss: 2.7777668648081564

Epoch: 5| Step: 3
Training loss: 0.32374289648444704
Validation loss: 2.724786728495408

Epoch: 5| Step: 4
Training loss: 0.5286801394401055
Validation loss: 2.775396001185544

Epoch: 5| Step: 5
Training loss: 0.3972179785618851
Validation loss: 2.6910350822298676

Epoch: 5| Step: 6
Training loss: 0.8720647762588477
Validation loss: 2.755694129580281

Epoch: 5| Step: 7
Training loss: 0.49360421056431536
Validation loss: 2.6384557620909805

Epoch: 5| Step: 8
Training loss: 0.41287770896205395
Validation loss: 2.7646657964964763

Epoch: 5| Step: 9
Training loss: 0.5232520842604083
Validation loss: 2.6714896171404234

Epoch: 5| Step: 10
Training loss: 0.6179300983364168
Validation loss: 2.7222151177717997

Epoch: 5| Step: 11
Training loss: 0.3419091939301693
Validation loss: 2.756436982015331

Epoch: 236| Step: 0
Training loss: 0.47070646482683615
Validation loss: 2.7653539348746574

Epoch: 5| Step: 1
Training loss: 0.4475474406781075
Validation loss: 2.6902884093736303

Epoch: 5| Step: 2
Training loss: 0.6055455312958821
Validation loss: 2.6453623702937694

Epoch: 5| Step: 3
Training loss: 0.9072535318856174
Validation loss: 2.7023904496960913

Epoch: 5| Step: 4
Training loss: 0.4189558050091048
Validation loss: 2.698628991891763

Epoch: 5| Step: 5
Training loss: 0.48952213540649286
Validation loss: 2.7516018399847653

Epoch: 5| Step: 6
Training loss: 0.5315299138167804
Validation loss: 2.828801578220631

Epoch: 5| Step: 7
Training loss: 0.4763162164136427
Validation loss: 2.8219342768721134

Epoch: 5| Step: 8
Training loss: 0.3890761185372916
Validation loss: 2.7297504664529946

Epoch: 5| Step: 9
Training loss: 0.43039727976375447
Validation loss: 2.7180848458964975

Epoch: 5| Step: 10
Training loss: 0.48030417810501563
Validation loss: 2.6734374090358557

Epoch: 5| Step: 11
Training loss: 0.1898398238039023
Validation loss: 2.7236386884131503

Epoch: 237| Step: 0
Training loss: 1.0822371965101703
Validation loss: 2.7891516613354805

Epoch: 5| Step: 1
Training loss: 0.60900686832996
Validation loss: 2.681901349059969

Epoch: 5| Step: 2
Training loss: 0.5754065651896637
Validation loss: 2.73718973154981

Epoch: 5| Step: 3
Training loss: 0.3389579585416598
Validation loss: 2.7746154074746743

Epoch: 5| Step: 4
Training loss: 0.44026495650456254
Validation loss: 2.795810631907625

Epoch: 5| Step: 5
Training loss: 0.5788821597627503
Validation loss: 2.8188827145073265

Epoch: 5| Step: 6
Training loss: 0.5414641961688726
Validation loss: 2.7181620126442274

Epoch: 5| Step: 7
Training loss: 0.6445840756124979
Validation loss: 2.6637555017269796

Epoch: 5| Step: 8
Training loss: 0.45800122416949024
Validation loss: 2.655121107129087

Epoch: 5| Step: 9
Training loss: 0.4233469890972642
Validation loss: 2.724953177396876

Epoch: 5| Step: 10
Training loss: 0.36724459427451
Validation loss: 2.6693111596511594

Epoch: 5| Step: 11
Training loss: 0.3220408956535179
Validation loss: 2.699224311024246

Epoch: 238| Step: 0
Training loss: 0.5870147974076022
Validation loss: 2.7544857416467714

Epoch: 5| Step: 1
Training loss: 0.3783956607272913
Validation loss: 2.768980598319053

Epoch: 5| Step: 2
Training loss: 0.3818038185445227
Validation loss: 2.7662529169691554

Epoch: 5| Step: 3
Training loss: 0.5009314979674357
Validation loss: 2.7399792632886846

Epoch: 5| Step: 4
Training loss: 0.4331588110174135
Validation loss: 2.7280276241453696

Epoch: 5| Step: 5
Training loss: 0.6063506072419986
Validation loss: 2.846592230350329

Epoch: 5| Step: 6
Training loss: 0.3170362957759211
Validation loss: 2.707807410357007

Epoch: 5| Step: 7
Training loss: 0.4262848596777297
Validation loss: 2.695540424974529

Epoch: 5| Step: 8
Training loss: 0.9352499345271076
Validation loss: 2.696725388403499

Epoch: 5| Step: 9
Training loss: 0.3276596402423558
Validation loss: 2.7477414002726896

Epoch: 5| Step: 10
Training loss: 0.3404246878680871
Validation loss: 2.7236797063836184

Epoch: 5| Step: 11
Training loss: 0.19988722005565326
Validation loss: 2.7412694316186315

Epoch: 239| Step: 0
Training loss: 0.6774592651987059
Validation loss: 2.727576081065362

Epoch: 5| Step: 1
Training loss: 0.37264519681073055
Validation loss: 2.68823371526643

Epoch: 5| Step: 2
Training loss: 0.3829444151936193
Validation loss: 2.775298365599309

Epoch: 5| Step: 3
Training loss: 0.9383328235437376
Validation loss: 2.7036077035326587

Epoch: 5| Step: 4
Training loss: 0.28688144069913035
Validation loss: 2.7015326372345356

Epoch: 5| Step: 5
Training loss: 0.43850656929227955
Validation loss: 2.769761366939671

Epoch: 5| Step: 6
Training loss: 0.4393998516428909
Validation loss: 2.805905629234867

Epoch: 5| Step: 7
Training loss: 0.381268188949449
Validation loss: 2.7390218142360014

Epoch: 5| Step: 8
Training loss: 0.2999999811251952
Validation loss: 2.726572927547944

Epoch: 5| Step: 9
Training loss: 0.4497794425396372
Validation loss: 2.6921986897553913

Epoch: 5| Step: 10
Training loss: 0.3237149679348032
Validation loss: 2.68389817741006

Epoch: 5| Step: 11
Training loss: 0.12324911859793941
Validation loss: 2.7145449174303318

Epoch: 240| Step: 0
Training loss: 0.8472134184944492
Validation loss: 2.7493609278270275

Epoch: 5| Step: 1
Training loss: 0.4722579191855517
Validation loss: 2.7248185782745784

Epoch: 5| Step: 2
Training loss: 0.5437787552607475
Validation loss: 2.6826371769761517

Epoch: 5| Step: 3
Training loss: 0.31358399733815145
Validation loss: 2.682725576223045

Epoch: 5| Step: 4
Training loss: 0.3686884578169238
Validation loss: 2.727712397855813

Epoch: 5| Step: 5
Training loss: 0.5312340958402484
Validation loss: 2.7157742778630856

Epoch: 5| Step: 6
Training loss: 0.5322344018201332
Validation loss: 2.7350401768647905

Epoch: 5| Step: 7
Training loss: 0.38272436256183673
Validation loss: 2.6676287492596105

Epoch: 5| Step: 8
Training loss: 0.5172806370706821
Validation loss: 2.8092018392321108

Epoch: 5| Step: 9
Training loss: 0.6888502473102931
Validation loss: 2.7015488316263907

Epoch: 5| Step: 10
Training loss: 0.45680917740590926
Validation loss: 2.764119580852739

Epoch: 5| Step: 11
Training loss: 0.3603635956530657
Validation loss: 2.7997060367416093

Epoch: 241| Step: 0
Training loss: 0.9013911581933353
Validation loss: 2.7613560331820057

Epoch: 5| Step: 1
Training loss: 0.3979244669138065
Validation loss: 2.6737706410647295

Epoch: 5| Step: 2
Training loss: 0.5253318555217296
Validation loss: 2.7249380954803697

Epoch: 5| Step: 3
Training loss: 0.35361274944645743
Validation loss: 2.7602584625589826

Epoch: 5| Step: 4
Training loss: 0.36063037207187143
Validation loss: 2.665289891620036

Epoch: 5| Step: 5
Training loss: 0.33159968434607523
Validation loss: 2.711412661169363

Epoch: 5| Step: 6
Training loss: 0.32707272692611206
Validation loss: 2.724779320160071

Epoch: 5| Step: 7
Training loss: 0.48110230086713424
Validation loss: 2.64965989401518

Epoch: 5| Step: 8
Training loss: 0.3207604602110083
Validation loss: 2.69969581182647

Epoch: 5| Step: 9
Training loss: 0.3168359711178703
Validation loss: 2.6863039075632473

Epoch: 5| Step: 10
Training loss: 0.7249132943100337
Validation loss: 2.716734248522064

Epoch: 5| Step: 11
Training loss: 0.4938260460489812
Validation loss: 2.746217915679335

Epoch: 242| Step: 0
Training loss: 0.4631628049125756
Validation loss: 2.646652199466819

Epoch: 5| Step: 1
Training loss: 0.6787930884831574
Validation loss: 2.710826417111067

Epoch: 5| Step: 2
Training loss: 0.4440014261209937
Validation loss: 2.6689064347801383

Epoch: 5| Step: 3
Training loss: 0.38043694177157006
Validation loss: 2.6465064429082137

Epoch: 5| Step: 4
Training loss: 0.3068165122815186
Validation loss: 2.7526144077443746

Epoch: 5| Step: 5
Training loss: 0.3684807384314594
Validation loss: 2.7011870749030513

Epoch: 5| Step: 6
Training loss: 0.5775918822247736
Validation loss: 2.7263492220267027

Epoch: 5| Step: 7
Training loss: 0.5179778948360665
Validation loss: 2.7727891800022078

Epoch: 5| Step: 8
Training loss: 0.46848591677079277
Validation loss: 2.784999930412022

Epoch: 5| Step: 9
Training loss: 0.8757006020211405
Validation loss: 2.7195573225618994

Epoch: 5| Step: 10
Training loss: 0.37020623336193537
Validation loss: 2.6754277090884324

Epoch: 5| Step: 11
Training loss: 0.5801590371777697
Validation loss: 2.6800431959860602

Epoch: 243| Step: 0
Training loss: 0.44533609026614196
Validation loss: 2.6914071432332705

Epoch: 5| Step: 1
Training loss: 0.8705052325043802
Validation loss: 2.7777270174686786

Epoch: 5| Step: 2
Training loss: 0.393000626835311
Validation loss: 2.7409193723965872

Epoch: 5| Step: 3
Training loss: 0.2823984223437885
Validation loss: 2.7489578085654682

Epoch: 5| Step: 4
Training loss: 0.4241975501508172
Validation loss: 2.741059762418952

Epoch: 5| Step: 5
Training loss: 0.3303527028566047
Validation loss: 2.7576377712439513

Epoch: 5| Step: 6
Training loss: 0.712512524812604
Validation loss: 2.746130999569785

Epoch: 5| Step: 7
Training loss: 0.5216534801142932
Validation loss: 2.8069700730414398

Epoch: 5| Step: 8
Training loss: 0.4128382054944784
Validation loss: 2.7240534024883316

Epoch: 5| Step: 9
Training loss: 0.4659823729553899
Validation loss: 2.707991121141856

Epoch: 5| Step: 10
Training loss: 0.5800910203315979
Validation loss: 2.813177200309941

Epoch: 5| Step: 11
Training loss: 0.45114284273347044
Validation loss: 2.8153333238369385

Epoch: 244| Step: 0
Training loss: 0.3703179934452313
Validation loss: 2.738979043902339

Epoch: 5| Step: 1
Training loss: 0.6956012640551115
Validation loss: 2.8120455162745

Epoch: 5| Step: 2
Training loss: 0.3824082205558669
Validation loss: 2.8096197179420024

Epoch: 5| Step: 3
Training loss: 0.4735045269142477
Validation loss: 2.7529174147656312

Epoch: 5| Step: 4
Training loss: 0.38476432761346346
Validation loss: 2.7680699663626633

Epoch: 5| Step: 5
Training loss: 0.9070715633242595
Validation loss: 2.7339005649055004

Epoch: 5| Step: 6
Training loss: 0.4170049982537513
Validation loss: 2.7022340147719848

Epoch: 5| Step: 7
Training loss: 0.3365499878968795
Validation loss: 2.736787948437758

Epoch: 5| Step: 8
Training loss: 0.40089585597160404
Validation loss: 2.7312715047983387

Epoch: 5| Step: 9
Training loss: 0.3363396654796326
Validation loss: 2.7703467290764263

Epoch: 5| Step: 10
Training loss: 0.38483902671601083
Validation loss: 2.764368245847292

Epoch: 5| Step: 11
Training loss: 0.3281801268272938
Validation loss: 2.726924500576768

Epoch: 245| Step: 0
Training loss: 0.495347144542853
Validation loss: 2.68456239353389

Epoch: 5| Step: 1
Training loss: 0.38509807650299444
Validation loss: 2.7089750715598835

Epoch: 5| Step: 2
Training loss: 0.42234045419031524
Validation loss: 2.685274059888109

Epoch: 5| Step: 3
Training loss: 0.35582264900173255
Validation loss: 2.7338148360724785

Epoch: 5| Step: 4
Training loss: 0.3201896385331438
Validation loss: 2.7878204629065464

Epoch: 5| Step: 5
Training loss: 0.348282838717671
Validation loss: 2.719188117758004

Epoch: 5| Step: 6
Training loss: 0.8458845547417887
Validation loss: 2.805496619778468

Epoch: 5| Step: 7
Training loss: 0.6732912661572504
Validation loss: 2.711381822684607

Epoch: 5| Step: 8
Training loss: 0.39564860157526044
Validation loss: 2.6767228968673185

Epoch: 5| Step: 9
Training loss: 0.5205072971935477
Validation loss: 2.736823589622923

Epoch: 5| Step: 10
Training loss: 0.2931732862471402
Validation loss: 2.7051735540971413

Epoch: 5| Step: 11
Training loss: 0.20240922590196858
Validation loss: 2.7459480786021198

Epoch: 246| Step: 0
Training loss: 0.5857336579834174
Validation loss: 2.7150165091235703

Epoch: 5| Step: 1
Training loss: 0.3754856223618677
Validation loss: 2.7426681767465166

Epoch: 5| Step: 2
Training loss: 0.4009160014191741
Validation loss: 2.750210761172318

Epoch: 5| Step: 3
Training loss: 0.8607769368123007
Validation loss: 2.678291639368645

Epoch: 5| Step: 4
Training loss: 0.5028278136544146
Validation loss: 2.7578668778113204

Epoch: 5| Step: 5
Training loss: 0.4462210438520635
Validation loss: 2.664824707684924

Epoch: 5| Step: 6
Training loss: 0.4483784653354515
Validation loss: 2.7700841770510714

Epoch: 5| Step: 7
Training loss: 0.41179518451607844
Validation loss: 2.7558296142528422

Epoch: 5| Step: 8
Training loss: 0.4301784658185866
Validation loss: 2.797300810695378

Epoch: 5| Step: 9
Training loss: 0.3553435136450227
Validation loss: 2.705113921404882

Epoch: 5| Step: 10
Training loss: 0.5441902198289799
Validation loss: 2.684673534456598

Epoch: 5| Step: 11
Training loss: 0.5009565739798929
Validation loss: 2.668060464990739

Epoch: 247| Step: 0
Training loss: 0.3826212892025273
Validation loss: 2.787576773003935

Epoch: 5| Step: 1
Training loss: 0.5735858881158817
Validation loss: 2.796812177552797

Epoch: 5| Step: 2
Training loss: 0.6556863407717093
Validation loss: 2.7371724487255538

Epoch: 5| Step: 3
Training loss: 0.5549305396818022
Validation loss: 2.810974251190758

Epoch: 5| Step: 4
Training loss: 0.34820198772707733
Validation loss: 2.707966520460295

Epoch: 5| Step: 5
Training loss: 0.356051376252045
Validation loss: 2.6548898767572697

Epoch: 5| Step: 6
Training loss: 0.31122067366939277
Validation loss: 2.733766295482301

Epoch: 5| Step: 7
Training loss: 0.44212663993283247
Validation loss: 2.809578809039144

Epoch: 5| Step: 8
Training loss: 0.5610571475985302
Validation loss: 2.730310536440964

Epoch: 5| Step: 9
Training loss: 0.5565640848641639
Validation loss: 2.751166540593234

Epoch: 5| Step: 10
Training loss: 0.6643458491162616
Validation loss: 2.7145867973963274

Epoch: 5| Step: 11
Training loss: 1.8211706537204397
Validation loss: 2.6136662760758065

Epoch: 248| Step: 0
Training loss: 0.2903908160324228
Validation loss: 2.725845271727463

Epoch: 5| Step: 1
Training loss: 0.4016008277146484
Validation loss: 2.6586061873263227

Epoch: 5| Step: 2
Training loss: 0.3453358353199836
Validation loss: 2.6853134775176613

Epoch: 5| Step: 3
Training loss: 0.4897227562224492
Validation loss: 2.72822435991181

Epoch: 5| Step: 4
Training loss: 0.4348957172172833
Validation loss: 2.7066988133081966

Epoch: 5| Step: 5
Training loss: 0.799236053547964
Validation loss: 2.6873821964615585

Epoch: 5| Step: 6
Training loss: 0.44167613328229194
Validation loss: 2.78583783998238

Epoch: 5| Step: 7
Training loss: 0.3748442604598926
Validation loss: 2.7047613552917738

Epoch: 5| Step: 8
Training loss: 0.3780472446919932
Validation loss: 2.739964575886583

Epoch: 5| Step: 9
Training loss: 0.6312541376110482
Validation loss: 2.718323688772584

Epoch: 5| Step: 10
Training loss: 0.5309165020001732
Validation loss: 2.7453121775129574

Epoch: 5| Step: 11
Training loss: 1.1800188016201794
Validation loss: 2.7760435334581657

Epoch: 249| Step: 0
Training loss: 0.4423939785590234
Validation loss: 2.8066019415263495

Epoch: 5| Step: 1
Training loss: 0.5982684073336283
Validation loss: 2.842715676115195

Epoch: 5| Step: 2
Training loss: 0.6536387763585971
Validation loss: 2.7965236386287264

Epoch: 5| Step: 3
Training loss: 0.39872697524559075
Validation loss: 2.82908300117827

Epoch: 5| Step: 4
Training loss: 0.3270338854293964
Validation loss: 2.762919724628166

Epoch: 5| Step: 5
Training loss: 0.8683564838562068
Validation loss: 2.7982378468307085

Epoch: 5| Step: 6
Training loss: 0.4328614313993637
Validation loss: 2.800425692680293

Epoch: 5| Step: 7
Training loss: 0.551644318647543
Validation loss: 2.7850815601151666

Epoch: 5| Step: 8
Training loss: 0.594836596001787
Validation loss: 2.8361005464733386

Epoch: 5| Step: 9
Training loss: 0.4859571612388468
Validation loss: 2.787851001040475

Epoch: 5| Step: 10
Training loss: 0.5322461325870912
Validation loss: 2.7750665706805906

Epoch: 5| Step: 11
Training loss: 0.472819371094733
Validation loss: 2.7048740094200676

Epoch: 250| Step: 0
Training loss: 0.35131210310974126
Validation loss: 2.7024389215837323

Epoch: 5| Step: 1
Training loss: 0.29574439946189995
Validation loss: 2.7109585119013957

Epoch: 5| Step: 2
Training loss: 0.4859115777660471
Validation loss: 2.6989149630227462

Epoch: 5| Step: 3
Training loss: 0.9849772351921341
Validation loss: 2.7266329380034633

Epoch: 5| Step: 4
Training loss: 0.4434226910925613
Validation loss: 2.708320479484769

Epoch: 5| Step: 5
Training loss: 0.43517289121301717
Validation loss: 2.7292801357782572

Epoch: 5| Step: 6
Training loss: 0.4893998874411241
Validation loss: 2.789091186660855

Epoch: 5| Step: 7
Training loss: 0.5025620978213493
Validation loss: 2.618319707766636

Epoch: 5| Step: 8
Training loss: 0.4452353628174051
Validation loss: 2.6963853958165505

Epoch: 5| Step: 9
Training loss: 0.36688264406679255
Validation loss: 2.7256561601923885

Epoch: 5| Step: 10
Training loss: 0.2928707721908142
Validation loss: 2.6674142077830303

Epoch: 5| Step: 11
Training loss: 0.43528996575627743
Validation loss: 2.6461940648379887

Epoch: 251| Step: 0
Training loss: 0.40411442864771474
Validation loss: 2.6973328247096546

Epoch: 5| Step: 1
Training loss: 0.4136582686624351
Validation loss: 2.8005700060544276

Epoch: 5| Step: 2
Training loss: 0.3522604055011633
Validation loss: 2.789013293176829

Epoch: 5| Step: 3
Training loss: 0.34804527076839553
Validation loss: 2.6443767718485978

Epoch: 5| Step: 4
Training loss: 0.4763046567696833
Validation loss: 2.650188838480309

Epoch: 5| Step: 5
Training loss: 0.4098917517000371
Validation loss: 2.6900121421374483

Epoch: 5| Step: 6
Training loss: 0.7956657209860855
Validation loss: 2.730071574199759

Epoch: 5| Step: 7
Training loss: 0.7009711230543408
Validation loss: 2.7164072744202823

Epoch: 5| Step: 8
Training loss: 0.4620364553231206
Validation loss: 2.7551249267318276

Epoch: 5| Step: 9
Training loss: 0.5127826725237213
Validation loss: 2.738457964728872

Epoch: 5| Step: 10
Training loss: 0.357209564688909
Validation loss: 2.775718510315335

Epoch: 5| Step: 11
Training loss: 0.2594037367516667
Validation loss: 2.712106813479666

Epoch: 252| Step: 0
Training loss: 0.5291173989596888
Validation loss: 2.7155527117684466

Epoch: 5| Step: 1
Training loss: 0.41882304650493646
Validation loss: 2.7633292157618357

Epoch: 5| Step: 2
Training loss: 0.4273670308747205
Validation loss: 2.7755515338051397

Epoch: 5| Step: 3
Training loss: 0.32551671089105133
Validation loss: 2.6961232168554385

Epoch: 5| Step: 4
Training loss: 0.8230689105110763
Validation loss: 2.6995394581067567

Epoch: 5| Step: 5
Training loss: 0.3587470580854312
Validation loss: 2.6428725479663813

Epoch: 5| Step: 6
Training loss: 0.432197418816223
Validation loss: 2.6821894221895444

Epoch: 5| Step: 7
Training loss: 0.2862766412139771
Validation loss: 2.668817179517012

Epoch: 5| Step: 8
Training loss: 0.37577965274082725
Validation loss: 2.7502263402271083

Epoch: 5| Step: 9
Training loss: 0.4655506625135835
Validation loss: 2.7274300835410252

Epoch: 5| Step: 10
Training loss: 0.45618884382195024
Validation loss: 2.727332025708732

Epoch: 5| Step: 11
Training loss: 0.6356611302702632
Validation loss: 2.6479283784016565

Epoch: 253| Step: 0
Training loss: 0.5626666299063248
Validation loss: 2.7359735775175045

Epoch: 5| Step: 1
Training loss: 0.4187825204548019
Validation loss: 2.7180441455301607

Epoch: 5| Step: 2
Training loss: 0.8465313456996227
Validation loss: 2.700158691157912

Epoch: 5| Step: 3
Training loss: 0.46522890691482466
Validation loss: 2.693236033063811

Epoch: 5| Step: 4
Training loss: 0.33052874171648844
Validation loss: 2.716843082447305

Epoch: 5| Step: 5
Training loss: 0.6508190588254733
Validation loss: 2.6592467177366226

Epoch: 5| Step: 6
Training loss: 0.31543494299889047
Validation loss: 2.744619396070857

Epoch: 5| Step: 7
Training loss: 0.46733612771101235
Validation loss: 2.7337001621742645

Epoch: 5| Step: 8
Training loss: 0.44845266947858214
Validation loss: 2.6579939147703993

Epoch: 5| Step: 9
Training loss: 0.47391968524124245
Validation loss: 2.7482460454084547

Epoch: 5| Step: 10
Training loss: 0.440762092014428
Validation loss: 2.7531038815355555

Epoch: 5| Step: 11
Training loss: 0.26779743590658694
Validation loss: 2.716936599206301

Epoch: 254| Step: 0
Training loss: 0.38048824910479545
Validation loss: 2.7150901737483095

Epoch: 5| Step: 1
Training loss: 0.6512037355240851
Validation loss: 2.699530204915087

Epoch: 5| Step: 2
Training loss: 0.4617217552745628
Validation loss: 2.6642852011454505

Epoch: 5| Step: 3
Training loss: 0.42706223373706254
Validation loss: 2.7198951399566345

Epoch: 5| Step: 4
Training loss: 0.519710710549691
Validation loss: 2.696909986691166

Epoch: 5| Step: 5
Training loss: 0.44471757868830397
Validation loss: 2.7036673088203087

Epoch: 5| Step: 6
Training loss: 0.36562078098569073
Validation loss: 2.7121459510135706

Epoch: 5| Step: 7
Training loss: 0.3421340369347084
Validation loss: 2.6999777220466257

Epoch: 5| Step: 8
Training loss: 0.9034704135215639
Validation loss: 2.7699472341836757

Epoch: 5| Step: 9
Training loss: 0.31498988761640323
Validation loss: 2.713559076811035

Epoch: 5| Step: 10
Training loss: 0.3740548700814899
Validation loss: 2.7087164803452315

Epoch: 5| Step: 11
Training loss: 0.48507393892767176
Validation loss: 2.782418748406742

Epoch: 255| Step: 0
Training loss: 0.3292311574537817
Validation loss: 2.6685717205263524

Epoch: 5| Step: 1
Training loss: 0.5174429663037539
Validation loss: 2.739817864323213

Epoch: 5| Step: 2
Training loss: 0.8001493612572809
Validation loss: 2.6966013660165316

Epoch: 5| Step: 3
Training loss: 0.5446767494948513
Validation loss: 2.7088239751119914

Epoch: 5| Step: 4
Training loss: 0.5287439477632772
Validation loss: 2.7738216546011882

Epoch: 5| Step: 5
Training loss: 0.46643010498588416
Validation loss: 2.769627496349942

Epoch: 5| Step: 6
Training loss: 0.4529171664344302
Validation loss: 2.688341544969066

Epoch: 5| Step: 7
Training loss: 0.40686335478142643
Validation loss: 2.718051199426822

Epoch: 5| Step: 8
Training loss: 0.7083339597661857
Validation loss: 2.708193006303563

Epoch: 5| Step: 9
Training loss: 0.43066079274707403
Validation loss: 2.6706460018687648

Epoch: 5| Step: 10
Training loss: 0.48506788717590477
Validation loss: 2.71349501005297

Epoch: 5| Step: 11
Training loss: 0.19203459503202938
Validation loss: 2.771749471684162

Epoch: 256| Step: 0
Training loss: 0.5178385241454686
Validation loss: 2.7147054513518003

Epoch: 5| Step: 1
Training loss: 0.415401686283825
Validation loss: 2.698519704995345

Epoch: 5| Step: 2
Training loss: 0.39210698338501476
Validation loss: 2.729089933631921

Epoch: 5| Step: 3
Training loss: 0.41259980511528993
Validation loss: 2.738730567423276

Epoch: 5| Step: 4
Training loss: 0.6088888723523462
Validation loss: 2.699669663654819

Epoch: 5| Step: 5
Training loss: 0.423996641348186
Validation loss: 2.6467492002747384

Epoch: 5| Step: 6
Training loss: 0.3844084849155024
Validation loss: 2.696625073883905

Epoch: 5| Step: 7
Training loss: 0.5256894761319242
Validation loss: 2.748538165176379

Epoch: 5| Step: 8
Training loss: 0.8896139328731721
Validation loss: 2.687400694054766

Epoch: 5| Step: 9
Training loss: 0.4390837749064618
Validation loss: 2.6236079816652045

Epoch: 5| Step: 10
Training loss: 0.5367474255404587
Validation loss: 2.7795784584888623

Epoch: 5| Step: 11
Training loss: 0.3509759035778282
Validation loss: 2.7109151723860174

Epoch: 257| Step: 0
Training loss: 0.4187857939951357
Validation loss: 2.7243562788180427

Epoch: 5| Step: 1
Training loss: 0.30976608776620784
Validation loss: 2.6481402201241773

Epoch: 5| Step: 2
Training loss: 0.4617970905229236
Validation loss: 2.6944499602922263

Epoch: 5| Step: 3
Training loss: 0.3290094308907324
Validation loss: 2.7047579762932696

Epoch: 5| Step: 4
Training loss: 0.6027647365554918
Validation loss: 2.684391612015209

Epoch: 5| Step: 5
Training loss: 0.5258477927011909
Validation loss: 2.7458477895893525

Epoch: 5| Step: 6
Training loss: 0.8210927250036344
Validation loss: 2.6681253211351184

Epoch: 5| Step: 7
Training loss: 0.4647868145607209
Validation loss: 2.6325407104870426

Epoch: 5| Step: 8
Training loss: 0.37355915067312717
Validation loss: 2.6678715693292343

Epoch: 5| Step: 9
Training loss: 0.46818381129797626
Validation loss: 2.6484608907051137

Epoch: 5| Step: 10
Training loss: 0.358193154232651
Validation loss: 2.7579744703873845

Epoch: 5| Step: 11
Training loss: 0.295863662539577
Validation loss: 2.774953504837286

Epoch: 258| Step: 0
Training loss: 0.4508478726982314
Validation loss: 2.7889419479745556

Epoch: 5| Step: 1
Training loss: 0.3202458986962238
Validation loss: 2.7394434466504483

Epoch: 5| Step: 2
Training loss: 0.3655604166880356
Validation loss: 2.6610315930076216

Epoch: 5| Step: 3
Training loss: 0.4538565354033334
Validation loss: 2.681302887721743

Epoch: 5| Step: 4
Training loss: 0.5116451880309354
Validation loss: 2.730456212587547

Epoch: 5| Step: 5
Training loss: 0.9242841953765002
Validation loss: 2.6966794330210644

Epoch: 5| Step: 6
Training loss: 0.39987516019698116
Validation loss: 2.7348916828097627

Epoch: 5| Step: 7
Training loss: 0.4133045168350398
Validation loss: 2.6986611945597985

Epoch: 5| Step: 8
Training loss: 0.4532257494238339
Validation loss: 2.6908086344856468

Epoch: 5| Step: 9
Training loss: 0.37423451097782257
Validation loss: 2.7156106538031484

Epoch: 5| Step: 10
Training loss: 0.44714793693359167
Validation loss: 2.721865410975819

Epoch: 5| Step: 11
Training loss: 0.6004138234706733
Validation loss: 2.7392962828737986

Epoch: 259| Step: 0
Training loss: 0.38332603031264545
Validation loss: 2.733383714736879

Epoch: 5| Step: 1
Training loss: 0.5042411814813573
Validation loss: 2.7358858348732804

Epoch: 5| Step: 2
Training loss: 0.4682919171314513
Validation loss: 2.7765511778180416

Epoch: 5| Step: 3
Training loss: 0.34799195272634176
Validation loss: 2.706138904132476

Epoch: 5| Step: 4
Training loss: 0.6837350971683015
Validation loss: 2.6496389583942173

Epoch: 5| Step: 5
Training loss: 0.4234717668413618
Validation loss: 2.6901311525294256

Epoch: 5| Step: 6
Training loss: 0.4332439282999448
Validation loss: 2.689514850175005

Epoch: 5| Step: 7
Training loss: 0.4635811013867396
Validation loss: 2.729761758866743

Epoch: 5| Step: 8
Training loss: 0.8396202322248238
Validation loss: 2.7273305669163794

Epoch: 5| Step: 9
Training loss: 0.25560618387283884
Validation loss: 2.726953735264064

Epoch: 5| Step: 10
Training loss: 0.3862425444170438
Validation loss: 2.7030274276175676

Epoch: 5| Step: 11
Training loss: 0.46102374288357467
Validation loss: 2.713451355928018

Epoch: 260| Step: 0
Training loss: 0.406949486455325
Validation loss: 2.712380683782685

Epoch: 5| Step: 1
Training loss: 0.4087264799064767
Validation loss: 2.8057839527001334

Epoch: 5| Step: 2
Training loss: 0.5003622054428069
Validation loss: 2.7062648625953165

Epoch: 5| Step: 3
Training loss: 0.345269119334092
Validation loss: 2.672416409076433

Epoch: 5| Step: 4
Training loss: 0.3898161907048852
Validation loss: 2.646490598626696

Epoch: 5| Step: 5
Training loss: 0.3431540221220224
Validation loss: 2.7476805492718976

Epoch: 5| Step: 6
Training loss: 0.9196489905312881
Validation loss: 2.7002253773896987

Epoch: 5| Step: 7
Training loss: 0.3086113381504189
Validation loss: 2.699584704266923

Epoch: 5| Step: 8
Training loss: 0.30491211754612224
Validation loss: 2.684232233267764

Epoch: 5| Step: 9
Training loss: 0.379496203610878
Validation loss: 2.682821689324109

Epoch: 5| Step: 10
Training loss: 0.43590149747880524
Validation loss: 2.7073064043133894

Epoch: 5| Step: 11
Training loss: 0.11490294915895226
Validation loss: 2.7206975969238787

Epoch: 261| Step: 0
Training loss: 0.3483725572800861
Validation loss: 2.7646783764007608

Epoch: 5| Step: 1
Training loss: 0.5211758504586411
Validation loss: 2.7708990488409984

Epoch: 5| Step: 2
Training loss: 0.35691259403266934
Validation loss: 2.792953062569193

Epoch: 5| Step: 3
Training loss: 0.4018388190823905
Validation loss: 2.6736457991035576

Epoch: 5| Step: 4
Training loss: 0.3953620170972639
Validation loss: 2.6764874122837194

Epoch: 5| Step: 5
Training loss: 0.3487282203039936
Validation loss: 2.783709495836726

Epoch: 5| Step: 6
Training loss: 0.34855470396779503
Validation loss: 2.7592331412411153

Epoch: 5| Step: 7
Training loss: 0.8860753283522208
Validation loss: 2.679351996947508

Epoch: 5| Step: 8
Training loss: 0.4089830786566971
Validation loss: 2.7073802126741473

Epoch: 5| Step: 9
Training loss: 0.44966986851592655
Validation loss: 2.7258144307032643

Epoch: 5| Step: 10
Training loss: 0.3937866246886164
Validation loss: 2.705515515603205

Epoch: 5| Step: 11
Training loss: 0.2672971935300423
Validation loss: 2.679815209610622

Epoch: 262| Step: 0
Training loss: 0.3655414616281168
Validation loss: 2.7450628792081484

Epoch: 5| Step: 1
Training loss: 0.35660177480921346
Validation loss: 2.6932753968695766

Epoch: 5| Step: 2
Training loss: 0.4088890481959484
Validation loss: 2.80884289509663

Epoch: 5| Step: 3
Training loss: 0.36017451291729524
Validation loss: 2.746007368991038

Epoch: 5| Step: 4
Training loss: 0.7590416054737575
Validation loss: 2.702422846481797

Epoch: 5| Step: 5
Training loss: 0.3896362379262865
Validation loss: 2.791977179514632

Epoch: 5| Step: 6
Training loss: 0.3666571378372824
Validation loss: 2.717914737999178

Epoch: 5| Step: 7
Training loss: 0.5858664405967445
Validation loss: 2.8022660913156563

Epoch: 5| Step: 8
Training loss: 0.3700995126494791
Validation loss: 2.7521821669669135

Epoch: 5| Step: 9
Training loss: 0.2531880417956655
Validation loss: 2.8144125634367207

Epoch: 5| Step: 10
Training loss: 0.38327963217927646
Validation loss: 2.764541638286769

Epoch: 5| Step: 11
Training loss: 0.4451976427226625
Validation loss: 2.7263157249199517

Epoch: 263| Step: 0
Training loss: 0.31314215247636007
Validation loss: 2.7629436957940863

Epoch: 5| Step: 1
Training loss: 0.44479457115755666
Validation loss: 2.7610945511028597

Epoch: 5| Step: 2
Training loss: 0.3869327376979443
Validation loss: 2.7490176592100406

Epoch: 5| Step: 3
Training loss: 0.4082843571926794
Validation loss: 2.769321288421109

Epoch: 5| Step: 4
Training loss: 0.7869201129710075
Validation loss: 2.7398749995201244

Epoch: 5| Step: 5
Training loss: 0.31917821272930785
Validation loss: 2.7799211928120178

Epoch: 5| Step: 6
Training loss: 0.3784508081768981
Validation loss: 2.727280938372148

Epoch: 5| Step: 7
Training loss: 0.4037306132548625
Validation loss: 2.7539629558379475

Epoch: 5| Step: 8
Training loss: 0.2834115149584887
Validation loss: 2.75869971926796

Epoch: 5| Step: 9
Training loss: 0.3797490489977945
Validation loss: 2.73891688291826

Epoch: 5| Step: 10
Training loss: 0.601064451062365
Validation loss: 2.7163282548328986

Epoch: 5| Step: 11
Training loss: 0.3027166792096898
Validation loss: 2.739561930574038

Epoch: 264| Step: 0
Training loss: 0.3692149132954209
Validation loss: 2.7274839052167756

Epoch: 5| Step: 1
Training loss: 0.31205523550103254
Validation loss: 2.721430801456364

Epoch: 5| Step: 2
Training loss: 0.7678636403299993
Validation loss: 2.720908535818181

Epoch: 5| Step: 3
Training loss: 0.6075368692646308
Validation loss: 2.6920815494033326

Epoch: 5| Step: 4
Training loss: 0.3146475196981275
Validation loss: 2.7409748718209825

Epoch: 5| Step: 5
Training loss: 0.3260237077432767
Validation loss: 2.7395125997619925

Epoch: 5| Step: 6
Training loss: 0.5059391975020924
Validation loss: 2.7362605759794003

Epoch: 5| Step: 7
Training loss: 0.28289852204002486
Validation loss: 2.6928852522458517

Epoch: 5| Step: 8
Training loss: 0.474381961419614
Validation loss: 2.711546211171769

Epoch: 5| Step: 9
Training loss: 0.4738320629588346
Validation loss: 2.7258957172331373

Epoch: 5| Step: 10
Training loss: 0.4259909192324066
Validation loss: 2.773214601684497

Epoch: 5| Step: 11
Training loss: 0.19310414201634296
Validation loss: 2.748072071226534

Epoch: 265| Step: 0
Training loss: 0.40074826526801827
Validation loss: 2.702020342251196

Epoch: 5| Step: 1
Training loss: 0.827875423610417
Validation loss: 2.741648665449263

Epoch: 5| Step: 2
Training loss: 0.5300832727079692
Validation loss: 2.7689582077629833

Epoch: 5| Step: 3
Training loss: 0.45170881679384595
Validation loss: 2.728162702173915

Epoch: 5| Step: 4
Training loss: 0.3241057026499697
Validation loss: 2.694231120466489

Epoch: 5| Step: 5
Training loss: 0.2842563643686622
Validation loss: 2.6918066840665915

Epoch: 5| Step: 6
Training loss: 0.3255887215077094
Validation loss: 2.698394800528284

Epoch: 5| Step: 7
Training loss: 0.3359663973067628
Validation loss: 2.6598847036363513

Epoch: 5| Step: 8
Training loss: 0.4261111634923916
Validation loss: 2.6712670257292346

Epoch: 5| Step: 9
Training loss: 0.4006934160799302
Validation loss: 2.6201234699656886

Epoch: 5| Step: 10
Training loss: 0.40492921481434546
Validation loss: 2.6674021709918687

Epoch: 5| Step: 11
Training loss: 0.5030973877052876
Validation loss: 2.683635452220421

Epoch: 266| Step: 0
Training loss: 0.5260307921491068
Validation loss: 2.683337673683289

Epoch: 5| Step: 1
Training loss: 0.3842025160491646
Validation loss: 2.660755666902918

Epoch: 5| Step: 2
Training loss: 0.4018819436382618
Validation loss: 2.6609837406879753

Epoch: 5| Step: 3
Training loss: 0.28132052332113744
Validation loss: 2.652671748739182

Epoch: 5| Step: 4
Training loss: 0.42170999973712775
Validation loss: 2.6959497776461627

Epoch: 5| Step: 5
Training loss: 0.2953849970925378
Validation loss: 2.7667872147456776

Epoch: 5| Step: 6
Training loss: 0.4979314632957193
Validation loss: 2.7268099048663386

Epoch: 5| Step: 7
Training loss: 0.8138429839982337
Validation loss: 2.6813956656083247

Epoch: 5| Step: 8
Training loss: 0.4256868345238336
Validation loss: 2.794553201468512

Epoch: 5| Step: 9
Training loss: 0.34660191267983176
Validation loss: 2.6998231195567906

Epoch: 5| Step: 10
Training loss: 0.3190138239256882
Validation loss: 2.739289842170139

Epoch: 5| Step: 11
Training loss: 0.488852342417535
Validation loss: 2.7395036538337543

Epoch: 267| Step: 0
Training loss: 0.45715082674657886
Validation loss: 2.7741162235239956

Epoch: 5| Step: 1
Training loss: 0.30494312420517905
Validation loss: 2.6810482636906916

Epoch: 5| Step: 2
Training loss: 0.3580249222466535
Validation loss: 2.7330235020479248

Epoch: 5| Step: 3
Training loss: 0.5330724870549272
Validation loss: 2.703112960524015

Epoch: 5| Step: 4
Training loss: 0.5688599417346224
Validation loss: 2.7562823620955776

Epoch: 5| Step: 5
Training loss: 0.3033890321486121
Validation loss: 2.7304709147534316

Epoch: 5| Step: 6
Training loss: 0.43324532127055265
Validation loss: 2.7385823496489134

Epoch: 5| Step: 7
Training loss: 0.3917182120771028
Validation loss: 2.748818844668478

Epoch: 5| Step: 8
Training loss: 0.2847422246122596
Validation loss: 2.733725803147805

Epoch: 5| Step: 9
Training loss: 0.48024933930231944
Validation loss: 2.686010624465466

Epoch: 5| Step: 10
Training loss: 0.7531639358142909
Validation loss: 2.763045884623143

Epoch: 5| Step: 11
Training loss: 0.2546726397994295
Validation loss: 2.6991063070178023

Epoch: 268| Step: 0
Training loss: 0.33012572628087233
Validation loss: 2.7089638061769348

Epoch: 5| Step: 1
Training loss: 0.23525555817121868
Validation loss: 2.7114456682548123

Epoch: 5| Step: 2
Training loss: 0.39587993305699287
Validation loss: 2.762236086723095

Epoch: 5| Step: 3
Training loss: 0.3485513586637562
Validation loss: 2.783053152940395

Epoch: 5| Step: 4
Training loss: 0.5351076869788158
Validation loss: 2.757610018233819

Epoch: 5| Step: 5
Training loss: 0.47846916128851835
Validation loss: 2.825267704232796

Epoch: 5| Step: 6
Training loss: 0.42706106484516876
Validation loss: 2.8077299640506626

Epoch: 5| Step: 7
Training loss: 0.39447750065346543
Validation loss: 2.740414425695925

Epoch: 5| Step: 8
Training loss: 0.3493640401141363
Validation loss: 2.774420378696942

Epoch: 5| Step: 9
Training loss: 0.38893145610190427
Validation loss: 2.6869870738764523

Epoch: 5| Step: 10
Training loss: 0.7991231732537788
Validation loss: 2.6493476309100936

Epoch: 5| Step: 11
Training loss: 0.5667077413099213
Validation loss: 2.6814737918651104

Epoch: 269| Step: 0
Training loss: 0.5447631112438277
Validation loss: 2.7535955267309897

Epoch: 5| Step: 1
Training loss: 0.5637431976601548
Validation loss: 2.760074354335803

Epoch: 5| Step: 2
Training loss: 0.47931459638172197
Validation loss: 2.7346164160831443

Epoch: 5| Step: 3
Training loss: 0.5714590748879348
Validation loss: 2.767895364717187

Epoch: 5| Step: 4
Training loss: 0.43625832514210927
Validation loss: 2.7104333084400904

Epoch: 5| Step: 5
Training loss: 0.40653248282477356
Validation loss: 2.700540788381207

Epoch: 5| Step: 6
Training loss: 0.6141558685371427
Validation loss: 2.73346864847058

Epoch: 5| Step: 7
Training loss: 0.5725385776582008
Validation loss: 2.636850567572111

Epoch: 5| Step: 8
Training loss: 0.4307642017985653
Validation loss: 2.721818679273596

Epoch: 5| Step: 9
Training loss: 0.3006828196590875
Validation loss: 2.703974838290718

Epoch: 5| Step: 10
Training loss: 0.759788650124575
Validation loss: 2.708357555329996

Epoch: 5| Step: 11
Training loss: 0.5429991295089207
Validation loss: 2.745259164933665

Epoch: 270| Step: 0
Training loss: 0.4884369106130528
Validation loss: 2.7839168307201496

Epoch: 5| Step: 1
Training loss: 0.30431733509468184
Validation loss: 2.7161220002096442

Epoch: 5| Step: 2
Training loss: 0.4921744511403461
Validation loss: 2.733183793861017

Epoch: 5| Step: 3
Training loss: 0.3677931721032284
Validation loss: 2.703684093008913

Epoch: 5| Step: 4
Training loss: 0.3507604350687788
Validation loss: 2.7220390766004203

Epoch: 5| Step: 5
Training loss: 0.42996912310323687
Validation loss: 2.7990461336899357

Epoch: 5| Step: 6
Training loss: 0.5823935334891351
Validation loss: 2.7131280394651864

Epoch: 5| Step: 7
Training loss: 0.7419456087751769
Validation loss: 2.7263547568620043

Epoch: 5| Step: 8
Training loss: 0.44417354424837585
Validation loss: 2.7431361992700745

Epoch: 5| Step: 9
Training loss: 0.4896527826141519
Validation loss: 2.747304505672835

Epoch: 5| Step: 10
Training loss: 0.3727207455914678
Validation loss: 2.806782254561372

Epoch: 5| Step: 11
Training loss: 0.2913795218597562
Validation loss: 2.747112278821718

Epoch: 271| Step: 0
Training loss: 0.3392061193039608
Validation loss: 2.763242571841099

Epoch: 5| Step: 1
Training loss: 0.44815345168405474
Validation loss: 2.718368828752446

Epoch: 5| Step: 2
Training loss: 0.5204650116977755
Validation loss: 2.71682658431782

Epoch: 5| Step: 3
Training loss: 0.376676230449848
Validation loss: 2.74271802488808

Epoch: 5| Step: 4
Training loss: 0.37069958282161153
Validation loss: 2.721045734260435

Epoch: 5| Step: 5
Training loss: 0.29422812306632007
Validation loss: 2.7027119227200544

Epoch: 5| Step: 6
Training loss: 0.43849559309342384
Validation loss: 2.807843266769478

Epoch: 5| Step: 7
Training loss: 0.5125237459403618
Validation loss: 2.7136665335033805

Epoch: 5| Step: 8
Training loss: 0.8300272488429936
Validation loss: 2.740773929796178

Epoch: 5| Step: 9
Training loss: 0.3273556408964364
Validation loss: 2.750514628923369

Epoch: 5| Step: 10
Training loss: 0.5252222408202049
Validation loss: 2.728828883682957

Epoch: 5| Step: 11
Training loss: 0.4196729410107479
Validation loss: 2.722114556534103

Epoch: 272| Step: 0
Training loss: 0.3891098200505171
Validation loss: 2.6787758065014695

Epoch: 5| Step: 1
Training loss: 0.4127312618833563
Validation loss: 2.68427659573412

Epoch: 5| Step: 2
Training loss: 0.34079705189025244
Validation loss: 2.7709597663906855

Epoch: 5| Step: 3
Training loss: 0.5166676123928315
Validation loss: 2.6977323422497888

Epoch: 5| Step: 4
Training loss: 0.4036793438527055
Validation loss: 2.7400887075158624

Epoch: 5| Step: 5
Training loss: 0.4146111110825578
Validation loss: 2.706604249129609

Epoch: 5| Step: 6
Training loss: 0.3984173227324859
Validation loss: 2.77152468665684

Epoch: 5| Step: 7
Training loss: 0.4953290948584845
Validation loss: 2.691778030886815

Epoch: 5| Step: 8
Training loss: 0.431085393422989
Validation loss: 2.6902403647751822

Epoch: 5| Step: 9
Training loss: 0.7602214083527673
Validation loss: 2.7608545939633133

Epoch: 5| Step: 10
Training loss: 0.3433036290246135
Validation loss: 2.6922585882217045

Epoch: 5| Step: 11
Training loss: 0.3359507846423418
Validation loss: 2.741390509137599

Epoch: 273| Step: 0
Training loss: 0.7979657057656833
Validation loss: 2.74961437787237

Epoch: 5| Step: 1
Training loss: 0.5069404156262053
Validation loss: 2.781642400370219

Epoch: 5| Step: 2
Training loss: 0.500551813326607
Validation loss: 2.6674910490498975

Epoch: 5| Step: 3
Training loss: 0.2341848476245457
Validation loss: 2.7348324238687325

Epoch: 5| Step: 4
Training loss: 0.2754832443431331
Validation loss: 2.704284775647325

Epoch: 5| Step: 5
Training loss: 0.3235766245216676
Validation loss: 2.63488653125668

Epoch: 5| Step: 6
Training loss: 0.5323280727629759
Validation loss: 2.7462740097825264

Epoch: 5| Step: 7
Training loss: 0.5334208396808382
Validation loss: 2.6898266346630963

Epoch: 5| Step: 8
Training loss: 0.4184959509253742
Validation loss: 2.787388684882668

Epoch: 5| Step: 9
Training loss: 0.4009467194196663
Validation loss: 2.6613119698508245

Epoch: 5| Step: 10
Training loss: 0.543756065115591
Validation loss: 2.731036702446749

Epoch: 5| Step: 11
Training loss: 0.5009053200078812
Validation loss: 2.848901480758955

Epoch: 274| Step: 0
Training loss: 0.4080931227825476
Validation loss: 2.803497579161364

Epoch: 5| Step: 1
Training loss: 0.7203579207723548
Validation loss: 2.786606309948564

Epoch: 5| Step: 2
Training loss: 0.3964448542699854
Validation loss: 2.7917952341868664

Epoch: 5| Step: 3
Training loss: 0.3787077747702777
Validation loss: 2.741942263412132

Epoch: 5| Step: 4
Training loss: 0.320397470415532
Validation loss: 2.6454024089113175

Epoch: 5| Step: 5
Training loss: 0.536690260618277
Validation loss: 2.7208155097397104

Epoch: 5| Step: 6
Training loss: 0.4871800020434932
Validation loss: 2.7010473230442225

Epoch: 5| Step: 7
Training loss: 0.43202177109761947
Validation loss: 2.742825407655775

Epoch: 5| Step: 8
Training loss: 0.5400214304468602
Validation loss: 2.7823505295887445

Epoch: 5| Step: 9
Training loss: 0.5584918909636793
Validation loss: 2.8417968715042865

Epoch: 5| Step: 10
Training loss: 0.33702079077608343
Validation loss: 2.7003921703759284

Epoch: 5| Step: 11
Training loss: 0.24247793502805093
Validation loss: 2.7333891117599673

Epoch: 275| Step: 0
Training loss: 0.3043700422827109
Validation loss: 2.7333784121967457

Epoch: 5| Step: 1
Training loss: 0.27307633662599967
Validation loss: 2.695043047276307

Epoch: 5| Step: 2
Training loss: 0.35733352152768444
Validation loss: 2.651943433137697

Epoch: 5| Step: 3
Training loss: 0.3943235587169959
Validation loss: 2.698298535268886

Epoch: 5| Step: 4
Training loss: 0.28868593999850395
Validation loss: 2.6552993644074294

Epoch: 5| Step: 5
Training loss: 0.37033952059128095
Validation loss: 2.7181118256346197

Epoch: 5| Step: 6
Training loss: 0.36593230773994956
Validation loss: 2.7160063196025863

Epoch: 5| Step: 7
Training loss: 0.35880975222336975
Validation loss: 2.6847119803369517

Epoch: 5| Step: 8
Training loss: 0.3795523885821373
Validation loss: 2.738642615664068

Epoch: 5| Step: 9
Training loss: 0.7906976131220336
Validation loss: 2.744558050551618

Epoch: 5| Step: 10
Training loss: 0.61204732691179
Validation loss: 2.800654576485994

Epoch: 5| Step: 11
Training loss: 0.28057559270853094
Validation loss: 2.7581918651821176

Epoch: 276| Step: 0
Training loss: 0.41656279063804885
Validation loss: 2.648889407422357

Epoch: 5| Step: 1
Training loss: 0.4421000977260876
Validation loss: 2.722510327990103

Epoch: 5| Step: 2
Training loss: 0.353828102393138
Validation loss: 2.696688432601711

Epoch: 5| Step: 3
Training loss: 0.7843593519861262
Validation loss: 2.7008820270439795

Epoch: 5| Step: 4
Training loss: 0.33814184959510335
Validation loss: 2.6765446671401985

Epoch: 5| Step: 5
Training loss: 0.3240462614164278
Validation loss: 2.7209562433550203

Epoch: 5| Step: 6
Training loss: 0.32051045418440444
Validation loss: 2.6080381810425117

Epoch: 5| Step: 7
Training loss: 0.44425494116040803
Validation loss: 2.7348020601563046

Epoch: 5| Step: 8
Training loss: 0.43364017684781964
Validation loss: 2.70376232843973

Epoch: 5| Step: 9
Training loss: 0.27520361428230034
Validation loss: 2.7112542919150173

Epoch: 5| Step: 10
Training loss: 0.5456903979074097
Validation loss: 2.7524828864560833

Epoch: 5| Step: 11
Training loss: 0.3085312357488811
Validation loss: 2.6807176039165785

Epoch: 277| Step: 0
Training loss: 0.4711699485834304
Validation loss: 2.6937905405155127

Epoch: 5| Step: 1
Training loss: 0.767125042084122
Validation loss: 2.619942542573261

Epoch: 5| Step: 2
Training loss: 0.40364425617853317
Validation loss: 2.6294940406626366

Epoch: 5| Step: 3
Training loss: 0.35345011573084845
Validation loss: 2.713627959701843

Epoch: 5| Step: 4
Training loss: 0.33142222479735745
Validation loss: 2.751588174966242

Epoch: 5| Step: 5
Training loss: 0.303124465646961
Validation loss: 2.785933769025317

Epoch: 5| Step: 6
Training loss: 0.502763828223992
Validation loss: 2.7546935234501633

Epoch: 5| Step: 7
Training loss: 0.37292356600142074
Validation loss: 2.7279957972661513

Epoch: 5| Step: 8
Training loss: 0.3738107898483612
Validation loss: 2.7358691501993815

Epoch: 5| Step: 9
Training loss: 0.384196484988316
Validation loss: 2.769526726880884

Epoch: 5| Step: 10
Training loss: 0.32262116673264074
Validation loss: 2.673404802203808

Epoch: 5| Step: 11
Training loss: 0.30359057282941526
Validation loss: 2.6929889633560715

Epoch: 278| Step: 0
Training loss: 0.37322522438743216
Validation loss: 2.724303576810958

Epoch: 5| Step: 1
Training loss: 0.4356848664927181
Validation loss: 2.7948841134183278

Epoch: 5| Step: 2
Training loss: 0.49621523473500967
Validation loss: 2.767558980555647

Epoch: 5| Step: 3
Training loss: 0.7383514048027416
Validation loss: 2.7564833700841

Epoch: 5| Step: 4
Training loss: 0.3864307872726567
Validation loss: 2.698796910521241

Epoch: 5| Step: 5
Training loss: 0.4239533586546069
Validation loss: 2.8212005224580965

Epoch: 5| Step: 6
Training loss: 0.35994648068685803
Validation loss: 2.8172549072709443

Epoch: 5| Step: 7
Training loss: 0.3743225574858806
Validation loss: 2.73087424203868

Epoch: 5| Step: 8
Training loss: 0.37484445922453724
Validation loss: 2.7179520009529794

Epoch: 5| Step: 9
Training loss: 0.5241293249590925
Validation loss: 2.734808907368173

Epoch: 5| Step: 10
Training loss: 0.36322131739279023
Validation loss: 2.707555803538123

Epoch: 5| Step: 11
Training loss: 0.252199983535996
Validation loss: 2.7562389405274477

Epoch: 279| Step: 0
Training loss: 0.47615224345595114
Validation loss: 2.7806037194811086

Epoch: 5| Step: 1
Training loss: 0.2883993868170858
Validation loss: 2.707903366926874

Epoch: 5| Step: 2
Training loss: 0.5231698618786522
Validation loss: 2.689916836228275

Epoch: 5| Step: 3
Training loss: 0.38444373904024454
Validation loss: 2.763576539173426

Epoch: 5| Step: 4
Training loss: 0.32582399238838056
Validation loss: 2.7750753446895304

Epoch: 5| Step: 5
Training loss: 0.26148133398361456
Validation loss: 2.7592296651351447

Epoch: 5| Step: 6
Training loss: 0.34578006771762926
Validation loss: 2.725849688753115

Epoch: 5| Step: 7
Training loss: 0.7208643787144636
Validation loss: 2.7503589843756195

Epoch: 5| Step: 8
Training loss: 0.3634654982746649
Validation loss: 2.7281836396710353

Epoch: 5| Step: 9
Training loss: 0.46586224829046613
Validation loss: 2.734057671435158

Epoch: 5| Step: 10
Training loss: 0.41648830728958974
Validation loss: 2.6911014814335354

Epoch: 5| Step: 11
Training loss: 0.5678480279753048
Validation loss: 2.688263732858997

Epoch: 280| Step: 0
Training loss: 0.46689949344183496
Validation loss: 2.7085937533742155

Epoch: 5| Step: 1
Training loss: 0.3638515098417261
Validation loss: 2.795519743746681

Epoch: 5| Step: 2
Training loss: 0.47114996060740943
Validation loss: 2.733163765167787

Epoch: 5| Step: 3
Training loss: 0.4754895498368911
Validation loss: 2.743451507308965

Epoch: 5| Step: 4
Training loss: 0.4285645115384986
Validation loss: 2.6848388700365584

Epoch: 5| Step: 5
Training loss: 0.3755013373080643
Validation loss: 2.7319898356948618

Epoch: 5| Step: 6
Training loss: 0.5575976794249301
Validation loss: 2.7170480026578945

Epoch: 5| Step: 7
Training loss: 0.8025684417226604
Validation loss: 2.7056303394811576

Epoch: 5| Step: 8
Training loss: 0.543488617259326
Validation loss: 2.7281741650183298

Epoch: 5| Step: 9
Training loss: 0.39668761057151214
Validation loss: 2.6621247344997796

Epoch: 5| Step: 10
Training loss: 0.4648394384104057
Validation loss: 2.758684504955408

Epoch: 5| Step: 11
Training loss: 0.4642351157000926
Validation loss: 2.8172049516393676

Epoch: 281| Step: 0
Training loss: 0.39156512616518235
Validation loss: 2.7561042833627076

Epoch: 5| Step: 1
Training loss: 0.3638195848271537
Validation loss: 2.681670783073138

Epoch: 5| Step: 2
Training loss: 0.3712824090946452
Validation loss: 2.8129359507889737

Epoch: 5| Step: 3
Training loss: 0.3976577533925834
Validation loss: 2.7859830908575978

Epoch: 5| Step: 4
Training loss: 0.3913966377585608
Validation loss: 2.764765774792447

Epoch: 5| Step: 5
Training loss: 0.3799994125487154
Validation loss: 2.732772455636367

Epoch: 5| Step: 6
Training loss: 0.6798017997660638
Validation loss: 2.768721253566613

Epoch: 5| Step: 7
Training loss: 0.3194321187147688
Validation loss: 2.695700410212195

Epoch: 5| Step: 8
Training loss: 0.3711455660331992
Validation loss: 2.692076394298943

Epoch: 5| Step: 9
Training loss: 0.5565655038571568
Validation loss: 2.745807088302968

Epoch: 5| Step: 10
Training loss: 0.40923667638315897
Validation loss: 2.76538610414376

Epoch: 5| Step: 11
Training loss: 0.2858764880391413
Validation loss: 2.7278649244406887

Epoch: 282| Step: 0
Training loss: 0.3592621999433081
Validation loss: 2.7775814814880753

Epoch: 5| Step: 1
Training loss: 0.35663735428947163
Validation loss: 2.7805083532568604

Epoch: 5| Step: 2
Training loss: 0.4292474574212037
Validation loss: 2.830161669761455

Epoch: 5| Step: 3
Training loss: 0.3560029511731227
Validation loss: 2.7613731178787377

Epoch: 5| Step: 4
Training loss: 0.5934494663375935
Validation loss: 2.7633490815383057

Epoch: 5| Step: 5
Training loss: 0.45384409178497886
Validation loss: 2.708588156571952

Epoch: 5| Step: 6
Training loss: 0.42478148298356083
Validation loss: 2.6689886449503453

Epoch: 5| Step: 7
Training loss: 0.3596327935117851
Validation loss: 2.8060224467725816

Epoch: 5| Step: 8
Training loss: 0.21080317458871745
Validation loss: 2.6822371072991746

Epoch: 5| Step: 9
Training loss: 0.27958117867012366
Validation loss: 2.7253696233257227

Epoch: 5| Step: 10
Training loss: 0.7906535509103457
Validation loss: 2.7449994644947378

Epoch: 5| Step: 11
Training loss: 0.32837534618540953
Validation loss: 2.7717690943255264

Epoch: 283| Step: 0
Training loss: 0.45737200040790194
Validation loss: 2.8125131889316592

Epoch: 5| Step: 1
Training loss: 0.28219105322238813
Validation loss: 2.750416669924079

Epoch: 5| Step: 2
Training loss: 0.6623703208897729
Validation loss: 2.7960983277750855

Epoch: 5| Step: 3
Training loss: 0.5202637291581093
Validation loss: 2.731086282748084

Epoch: 5| Step: 4
Training loss: 0.4287464761450178
Validation loss: 2.699408620660455

Epoch: 5| Step: 5
Training loss: 0.5156427438168272
Validation loss: 2.726152307210852

Epoch: 5| Step: 6
Training loss: 0.3585923629102287
Validation loss: 2.710078309412768

Epoch: 5| Step: 7
Training loss: 0.35836708700906267
Validation loss: 2.726779098433125

Epoch: 5| Step: 8
Training loss: 0.2843247138616044
Validation loss: 2.7291142092218164

Epoch: 5| Step: 9
Training loss: 0.42502204332967436
Validation loss: 2.849578139107991

Epoch: 5| Step: 10
Training loss: 0.5195232763610681
Validation loss: 2.727339756748813

Epoch: 5| Step: 11
Training loss: 0.20500348867378687
Validation loss: 2.7326406628060202

Epoch: 284| Step: 0
Training loss: 0.37315363130352613
Validation loss: 2.7822833159757114

Epoch: 5| Step: 1
Training loss: 0.4340289912736671
Validation loss: 2.8159729249020184

Epoch: 5| Step: 2
Training loss: 0.3399093937231766
Validation loss: 2.7571352234199877

Epoch: 5| Step: 3
Training loss: 0.4230029603773375
Validation loss: 2.809895132145457

Epoch: 5| Step: 4
Training loss: 0.5128237608812859
Validation loss: 2.8350205808842235

Epoch: 5| Step: 5
Training loss: 0.4263716637607518
Validation loss: 2.73904845355085

Epoch: 5| Step: 6
Training loss: 0.33434899264649237
Validation loss: 2.745749378271541

Epoch: 5| Step: 7
Training loss: 0.4960293465208115
Validation loss: 2.7501705940392234

Epoch: 5| Step: 8
Training loss: 0.42758637746343003
Validation loss: 2.7238210360253667

Epoch: 5| Step: 9
Training loss: 0.7360801380366961
Validation loss: 2.7272131251977365

Epoch: 5| Step: 10
Training loss: 0.44859355045581234
Validation loss: 2.780883132655185

Epoch: 5| Step: 11
Training loss: 0.4343076447882338
Validation loss: 2.789655723848037

Epoch: 285| Step: 0
Training loss: 0.3674201025687896
Validation loss: 2.786285321339932

Epoch: 5| Step: 1
Training loss: 0.7942763948506408
Validation loss: 2.803719667930213

Epoch: 5| Step: 2
Training loss: 0.5538477114801735
Validation loss: 2.796321050388975

Epoch: 5| Step: 3
Training loss: 0.5666647222663207
Validation loss: 2.808253388347023

Epoch: 5| Step: 4
Training loss: 0.3753243077157347
Validation loss: 2.722757823769746

Epoch: 5| Step: 5
Training loss: 0.3804488488226911
Validation loss: 2.777664766926789

Epoch: 5| Step: 6
Training loss: 0.5331965295851823
Validation loss: 2.75128911971098

Epoch: 5| Step: 7
Training loss: 0.6138924875364891
Validation loss: 2.6889724652831335

Epoch: 5| Step: 8
Training loss: 0.5781094317015403
Validation loss: 2.66610046549821

Epoch: 5| Step: 9
Training loss: 0.35302217302980865
Validation loss: 2.8086206950388233

Epoch: 5| Step: 10
Training loss: 0.3800570914396955
Validation loss: 2.754501869956256

Epoch: 5| Step: 11
Training loss: 0.9271832887292257
Validation loss: 2.9232500244193256

Epoch: 286| Step: 0
Training loss: 0.8480927358743755
Validation loss: 2.8615784311012518

Epoch: 5| Step: 1
Training loss: 0.44998761597123255
Validation loss: 2.8127901987192554

Epoch: 5| Step: 2
Training loss: 0.27057827193706746
Validation loss: 2.7220786169238895

Epoch: 5| Step: 3
Training loss: 0.5938296515594843
Validation loss: 2.6964847908607315

Epoch: 5| Step: 4
Training loss: 0.5700645430312568
Validation loss: 2.7251281390262085

Epoch: 5| Step: 5
Training loss: 0.4944627337728326
Validation loss: 2.8193051308214074

Epoch: 5| Step: 6
Training loss: 0.3754172189682353
Validation loss: 2.7065329411863597

Epoch: 5| Step: 7
Training loss: 0.6026467299754101
Validation loss: 2.7195333653059786

Epoch: 5| Step: 8
Training loss: 0.4164161008202846
Validation loss: 2.7895633201555468

Epoch: 5| Step: 9
Training loss: 0.3618288231081998
Validation loss: 2.7625242440783824

Epoch: 5| Step: 10
Training loss: 0.45752570311984897
Validation loss: 2.8598655564768762

Epoch: 5| Step: 11
Training loss: 0.36936741880843993
Validation loss: 2.798782621565254

Epoch: 287| Step: 0
Training loss: 0.3957369858619524
Validation loss: 2.779524814590329

Epoch: 5| Step: 1
Training loss: 0.4457099546265295
Validation loss: 2.7407570320319175

Epoch: 5| Step: 2
Training loss: 0.3721111605591575
Validation loss: 2.7038754467044046

Epoch: 5| Step: 3
Training loss: 0.45244323479793186
Validation loss: 2.7702613517455896

Epoch: 5| Step: 4
Training loss: 0.37697994551833347
Validation loss: 2.7066209343592065

Epoch: 5| Step: 5
Training loss: 0.42033413898681726
Validation loss: 2.703721820309974

Epoch: 5| Step: 6
Training loss: 0.8001354311510575
Validation loss: 2.752654853192928

Epoch: 5| Step: 7
Training loss: 0.4234654681270213
Validation loss: 2.7050779597423515

Epoch: 5| Step: 8
Training loss: 0.3336591643045116
Validation loss: 2.6754554271717166

Epoch: 5| Step: 9
Training loss: 0.5929179384678568
Validation loss: 2.715174249158862

Epoch: 5| Step: 10
Training loss: 0.5369516869465645
Validation loss: 2.7056826470310327

Epoch: 5| Step: 11
Training loss: 0.46737856514288467
Validation loss: 2.7446379983485913

Epoch: 288| Step: 0
Training loss: 0.7355970806181095
Validation loss: 2.7747090214311663

Epoch: 5| Step: 1
Training loss: 0.5270253103030658
Validation loss: 2.797710641948117

Epoch: 5| Step: 2
Training loss: 0.42016826764245224
Validation loss: 2.8162366980926943

Epoch: 5| Step: 3
Training loss: 0.34064289929668484
Validation loss: 2.6925256317893873

Epoch: 5| Step: 4
Training loss: 0.3941503895966829
Validation loss: 2.737472258678367

Epoch: 5| Step: 5
Training loss: 0.4106215426329939
Validation loss: 2.7187803986556305

Epoch: 5| Step: 6
Training loss: 0.3810359447724698
Validation loss: 2.7140960249132395

Epoch: 5| Step: 7
Training loss: 0.614103943879782
Validation loss: 2.7619984551224475

Epoch: 5| Step: 8
Training loss: 0.5088801677650417
Validation loss: 2.669172206390171

Epoch: 5| Step: 9
Training loss: 0.343616947520306
Validation loss: 2.7187748301311245

Epoch: 5| Step: 10
Training loss: 0.3769910328833239
Validation loss: 2.727716651613826

Epoch: 5| Step: 11
Training loss: 0.48393925170896707
Validation loss: 2.759749466258639

Epoch: 289| Step: 0
Training loss: 0.3475573967111569
Validation loss: 2.755550523119052

Epoch: 5| Step: 1
Training loss: 0.38337063486943157
Validation loss: 2.632221185706499

Epoch: 5| Step: 2
Training loss: 0.36841287477234974
Validation loss: 2.6552441768289667

Epoch: 5| Step: 3
Training loss: 0.3835894038620381
Validation loss: 2.7029529619688426

Epoch: 5| Step: 4
Training loss: 0.7237159176775214
Validation loss: 2.6746268907934225

Epoch: 5| Step: 5
Training loss: 0.2669265080267436
Validation loss: 2.6408337993948434

Epoch: 5| Step: 6
Training loss: 0.48612161257920444
Validation loss: 2.6759135860936882

Epoch: 5| Step: 7
Training loss: 0.5169836985399496
Validation loss: 2.7494844654222725

Epoch: 5| Step: 8
Training loss: 0.40769702621177273
Validation loss: 2.7080398376089914

Epoch: 5| Step: 9
Training loss: 0.31488165473417545
Validation loss: 2.817681992290767

Epoch: 5| Step: 10
Training loss: 0.5292255592865461
Validation loss: 2.709879182149385

Epoch: 5| Step: 11
Training loss: 0.28528594634049176
Validation loss: 2.7048146510891593

Epoch: 290| Step: 0
Training loss: 0.4244241698352285
Validation loss: 2.7065329411863597

Epoch: 5| Step: 1
Training loss: 0.3225016105596854
Validation loss: 2.67469005007124

Epoch: 5| Step: 2
Training loss: 0.5195887540959194
Validation loss: 2.750134784473189

Epoch: 5| Step: 3
Training loss: 0.39099904271957403
Validation loss: 2.734988882999968

Epoch: 5| Step: 4
Training loss: 0.49203299564792075
Validation loss: 2.7176461810813715

Epoch: 5| Step: 5
Training loss: 0.35266496729523966
Validation loss: 2.7314329486885787

Epoch: 5| Step: 6
Training loss: 0.37840213865579053
Validation loss: 2.779542280824262

Epoch: 5| Step: 7
Training loss: 0.747145864618183
Validation loss: 2.7793405100045896

Epoch: 5| Step: 8
Training loss: 0.3056819898326723
Validation loss: 2.7582740991739905

Epoch: 5| Step: 9
Training loss: 0.37669559437656785
Validation loss: 2.740530482467103

Epoch: 5| Step: 10
Training loss: 0.36682153279682
Validation loss: 2.7222182670929995

Epoch: 5| Step: 11
Training loss: 0.349387551373955
Validation loss: 2.770605821279941

Epoch: 291| Step: 0
Training loss: 0.45977486250290756
Validation loss: 2.8592098514968693

Epoch: 5| Step: 1
Training loss: 0.29319365451804114
Validation loss: 2.730898541781813

Epoch: 5| Step: 2
Training loss: 0.3137034845636542
Validation loss: 2.7482816030627992

Epoch: 5| Step: 3
Training loss: 0.1851940011921667
Validation loss: 2.755314615191207

Epoch: 5| Step: 4
Training loss: 0.3615732341086266
Validation loss: 2.7511287164595557

Epoch: 5| Step: 5
Training loss: 0.3148114431574404
Validation loss: 2.7477622319674824

Epoch: 5| Step: 6
Training loss: 0.3963459882088758
Validation loss: 2.7475280308067314

Epoch: 5| Step: 7
Training loss: 0.24120638144201909
Validation loss: 2.725126290821671

Epoch: 5| Step: 8
Training loss: 0.5444228098532604
Validation loss: 2.6957797507002557

Epoch: 5| Step: 9
Training loss: 0.33142206743290614
Validation loss: 2.708565985639379

Epoch: 5| Step: 10
Training loss: 0.24722533959990228
Validation loss: 2.7118997579198925

Epoch: 5| Step: 11
Training loss: 1.3386027202214361
Validation loss: 2.6905315732962496

Epoch: 292| Step: 0
Training loss: 0.3785049633811842
Validation loss: 2.7077255532961444

Epoch: 5| Step: 1
Training loss: 0.43333006049106226
Validation loss: 2.7657774256424834

Epoch: 5| Step: 2
Training loss: 0.5184234625518027
Validation loss: 2.6785020940374986

Epoch: 5| Step: 3
Training loss: 0.2893971490725492
Validation loss: 2.723054733560528

Epoch: 5| Step: 4
Training loss: 0.32694513637030526
Validation loss: 2.7358040590276085

Epoch: 5| Step: 5
Training loss: 0.42905216062886625
Validation loss: 2.7512796235269814

Epoch: 5| Step: 6
Training loss: 0.3251149991956511
Validation loss: 2.686557759849535

Epoch: 5| Step: 7
Training loss: 0.4178054704552697
Validation loss: 2.726956886398562

Epoch: 5| Step: 8
Training loss: 0.6523248132938092
Validation loss: 2.7845212596864433

Epoch: 5| Step: 9
Training loss: 0.3218484432412746
Validation loss: 2.6712796103717067

Epoch: 5| Step: 10
Training loss: 0.36967812617357637
Validation loss: 2.776603693129689

Epoch: 5| Step: 11
Training loss: 0.18167939336371947
Validation loss: 2.784586309084819

Epoch: 293| Step: 0
Training loss: 0.30658121201611765
Validation loss: 2.7314214031403696

Epoch: 5| Step: 1
Training loss: 0.48451201746713773
Validation loss: 2.739191206123985

Epoch: 5| Step: 2
Training loss: 0.3673711479805374
Validation loss: 2.7199078575356355

Epoch: 5| Step: 3
Training loss: 0.24597857822938973
Validation loss: 2.81672214847486

Epoch: 5| Step: 4
Training loss: 0.35549126019310895
Validation loss: 2.799846810737074

Epoch: 5| Step: 5
Training loss: 0.39544095074670527
Validation loss: 2.754916769992854

Epoch: 5| Step: 6
Training loss: 0.4623826213042526
Validation loss: 2.7623464436667806

Epoch: 5| Step: 7
Training loss: 0.6554375796812257
Validation loss: 2.796097809059485

Epoch: 5| Step: 8
Training loss: 0.4709505404392604
Validation loss: 2.7132827552288172

Epoch: 5| Step: 9
Training loss: 0.40597970847338055
Validation loss: 2.7988814078008866

Epoch: 5| Step: 10
Training loss: 0.2758524384081575
Validation loss: 2.7410301925346734

Epoch: 5| Step: 11
Training loss: 0.39765638565031186
Validation loss: 2.6992065385246904

Epoch: 294| Step: 0
Training loss: 0.44455410139349816
Validation loss: 2.724146175776174

Epoch: 5| Step: 1
Training loss: 0.37491924687978906
Validation loss: 2.7326726428000154

Epoch: 5| Step: 2
Training loss: 0.7213856016578768
Validation loss: 2.702182105520643

Epoch: 5| Step: 3
Training loss: 0.44561920980835507
Validation loss: 2.712506905413626

Epoch: 5| Step: 4
Training loss: 0.3223368941598235
Validation loss: 2.757638066640532

Epoch: 5| Step: 5
Training loss: 0.4926048053773076
Validation loss: 2.7469657067087536

Epoch: 5| Step: 6
Training loss: 0.44775294113471165
Validation loss: 2.7242396752170377

Epoch: 5| Step: 7
Training loss: 0.36628242303591924
Validation loss: 2.7041720161522225

Epoch: 5| Step: 8
Training loss: 0.5093840709416874
Validation loss: 2.743594182860965

Epoch: 5| Step: 9
Training loss: 0.41751314448034527
Validation loss: 2.7247982857499786

Epoch: 5| Step: 10
Training loss: 0.39443409544990066
Validation loss: 2.7412968717105684

Epoch: 5| Step: 11
Training loss: 0.5557537844447963
Validation loss: 2.764545492206956

Epoch: 295| Step: 0
Training loss: 0.3312950724400816
Validation loss: 2.7454099568014687

Epoch: 5| Step: 1
Training loss: 0.3595866326519249
Validation loss: 2.618028921120569

Epoch: 5| Step: 2
Training loss: 0.39205198948455966
Validation loss: 2.7227069114813474

Epoch: 5| Step: 3
Training loss: 0.32826581839705066
Validation loss: 2.7423482070737966

Epoch: 5| Step: 4
Training loss: 0.5139091146916417
Validation loss: 2.805177017180655

Epoch: 5| Step: 5
Training loss: 0.2791364916226648
Validation loss: 2.753702571903178

Epoch: 5| Step: 6
Training loss: 0.3495125023661737
Validation loss: 2.755190848647791

Epoch: 5| Step: 7
Training loss: 0.7171778692791467
Validation loss: 2.747691399222283

Epoch: 5| Step: 8
Training loss: 0.5789091102436774
Validation loss: 2.7650262360480666

Epoch: 5| Step: 9
Training loss: 0.31871112745400704
Validation loss: 2.70706444995626

Epoch: 5| Step: 10
Training loss: 0.3717461322642225
Validation loss: 2.804716016222429

Epoch: 5| Step: 11
Training loss: 0.135782565142339
Validation loss: 2.7899459807317606

Epoch: 296| Step: 0
Training loss: 0.30907670388594827
Validation loss: 2.695788849095601

Epoch: 5| Step: 1
Training loss: 0.3286157979202828
Validation loss: 2.70310924135881

Epoch: 5| Step: 2
Training loss: 0.5701216809578241
Validation loss: 2.7349648665926822

Epoch: 5| Step: 3
Training loss: 0.3469276079029668
Validation loss: 2.7675817934243914

Epoch: 5| Step: 4
Training loss: 0.40220824987656373
Validation loss: 2.743787767705023

Epoch: 5| Step: 5
Training loss: 0.6922654454625263
Validation loss: 2.668372101870441

Epoch: 5| Step: 6
Training loss: 0.30679568846851735
Validation loss: 2.6720897261091365

Epoch: 5| Step: 7
Training loss: 0.3969854186236473
Validation loss: 2.6577058542344734

Epoch: 5| Step: 8
Training loss: 0.41430214478768324
Validation loss: 2.700655284883347

Epoch: 5| Step: 9
Training loss: 0.389544403796662
Validation loss: 2.754289965579659

Epoch: 5| Step: 10
Training loss: 0.35134060532769906
Validation loss: 2.768844325609484

Epoch: 5| Step: 11
Training loss: 0.4079530305730456
Validation loss: 2.750145994992705

Epoch: 297| Step: 0
Training loss: 0.430454125129961
Validation loss: 2.7094173951665472

Epoch: 5| Step: 1
Training loss: 0.7517426827965491
Validation loss: 2.7034666179963955

Epoch: 5| Step: 2
Training loss: 0.31528592450422377
Validation loss: 2.6843585794321876

Epoch: 5| Step: 3
Training loss: 0.35614174235291707
Validation loss: 2.774888192035067

Epoch: 5| Step: 4
Training loss: 0.36767912479415366
Validation loss: 2.712205460227376

Epoch: 5| Step: 5
Training loss: 0.33188548534877066
Validation loss: 2.7448105796340916

Epoch: 5| Step: 6
Training loss: 0.29528393531585156
Validation loss: 2.6558519700969154

Epoch: 5| Step: 7
Training loss: 0.36139362875558345
Validation loss: 2.7104060763407025

Epoch: 5| Step: 8
Training loss: 0.4963685423566166
Validation loss: 2.6903767123029105

Epoch: 5| Step: 9
Training loss: 0.26126626027989724
Validation loss: 2.6680921057821507

Epoch: 5| Step: 10
Training loss: 0.393366482319118
Validation loss: 2.7310027699488484

Epoch: 5| Step: 11
Training loss: 0.28766619605544913
Validation loss: 2.6871530323647606

Epoch: 298| Step: 0
Training loss: 0.335305117732941
Validation loss: 2.774941716140537

Epoch: 5| Step: 1
Training loss: 0.28377740446168787
Validation loss: 2.691812913620182

Epoch: 5| Step: 2
Training loss: 0.4205561261521039
Validation loss: 2.7572145399127987

Epoch: 5| Step: 3
Training loss: 0.3692186263088644
Validation loss: 2.7772888915004423

Epoch: 5| Step: 4
Training loss: 0.43775729719688583
Validation loss: 2.7300099581815123

Epoch: 5| Step: 5
Training loss: 0.40068722415760466
Validation loss: 2.7242784561223474

Epoch: 5| Step: 6
Training loss: 0.48428433092649553
Validation loss: 2.730615541862743

Epoch: 5| Step: 7
Training loss: 0.4388617711736725
Validation loss: 2.733988082395604

Epoch: 5| Step: 8
Training loss: 0.3224626921173362
Validation loss: 2.6697576547203297

Epoch: 5| Step: 9
Training loss: 0.6211773558192407
Validation loss: 2.7734401577502488

Epoch: 5| Step: 10
Training loss: 0.5130459413016025
Validation loss: 2.7564812491844948

Epoch: 5| Step: 11
Training loss: 0.514748203517156
Validation loss: 2.7394493793088612

Epoch: 299| Step: 0
Training loss: 0.32645451982693435
Validation loss: 2.7563251666764095

Epoch: 5| Step: 1
Training loss: 0.3408356365267496
Validation loss: 2.834474443670033

Epoch: 5| Step: 2
Training loss: 0.6245289219327802
Validation loss: 2.8262536195903074

Epoch: 5| Step: 3
Training loss: 0.3411689985820952
Validation loss: 2.832782138943009

Epoch: 5| Step: 4
Training loss: 0.43695821594404516
Validation loss: 2.819995372691766

Epoch: 5| Step: 5
Training loss: 0.3101931422702534
Validation loss: 2.7525371241397467

Epoch: 5| Step: 6
Training loss: 0.5207599079509923
Validation loss: 2.811636931838379

Epoch: 5| Step: 7
Training loss: 0.3400383753717569
Validation loss: 2.7579334221716243

Epoch: 5| Step: 8
Training loss: 0.5981509585911053
Validation loss: 2.7382752531369614

Epoch: 5| Step: 9
Training loss: 0.32363234193591556
Validation loss: 2.8210186202043137

Epoch: 5| Step: 10
Training loss: 0.4623627368757983
Validation loss: 2.73066952266938

Epoch: 5| Step: 11
Training loss: 0.31389198229024073
Validation loss: 2.728532310949999

Epoch: 300| Step: 0
Training loss: 0.3101882543314475
Validation loss: 2.7798670462906756

Epoch: 5| Step: 1
Training loss: 0.4495369489120942
Validation loss: 2.732883264444419

Epoch: 5| Step: 2
Training loss: 0.3354184221237559
Validation loss: 2.8020805101250437

Epoch: 5| Step: 3
Training loss: 0.40512939099289474
Validation loss: 2.7632614819530774

Epoch: 5| Step: 4
Training loss: 0.2824173912441639
Validation loss: 2.710169585389338

Epoch: 5| Step: 5
Training loss: 0.37647719307322836
Validation loss: 2.6747589868785036

Epoch: 5| Step: 6
Training loss: 0.7363293392262452
Validation loss: 2.6761974224548455

Epoch: 5| Step: 7
Training loss: 0.3981757706827799
Validation loss: 2.8038956206963377

Epoch: 5| Step: 8
Training loss: 0.4266013375791584
Validation loss: 2.7699721953365657

Epoch: 5| Step: 9
Training loss: 0.47913645738934746
Validation loss: 2.7661801515572964

Epoch: 5| Step: 10
Training loss: 0.42797506867417173
Validation loss: 2.7524075409319084

Epoch: 5| Step: 11
Training loss: 0.2616065624682583
Validation loss: 2.6545342869484605

Epoch: 301| Step: 0
Training loss: 0.37547415321072247
Validation loss: 2.727156679105974

Epoch: 5| Step: 1
Training loss: 0.6243660572774793
Validation loss: 2.7353896265855475

Epoch: 5| Step: 2
Training loss: 0.4258001305829892
Validation loss: 2.7048337529934066

Epoch: 5| Step: 3
Training loss: 0.31467009694183184
Validation loss: 2.6897973805498023

Epoch: 5| Step: 4
Training loss: 0.6403510275439265
Validation loss: 2.7519697428432375

Epoch: 5| Step: 5
Training loss: 0.352189310571845
Validation loss: 2.697744678234123

Epoch: 5| Step: 6
Training loss: 0.4825946637420215
Validation loss: 2.7395766455178285

Epoch: 5| Step: 7
Training loss: 0.40924951144231814
Validation loss: 2.829458519447471

Epoch: 5| Step: 8
Training loss: 0.5029952219514309
Validation loss: 2.7958827185402666

Epoch: 5| Step: 9
Training loss: 0.3958903217283648
Validation loss: 2.7286255108262862

Epoch: 5| Step: 10
Training loss: 0.26283406560370887
Validation loss: 2.7138304578069357

Epoch: 5| Step: 11
Training loss: 0.17741663271215474
Validation loss: 2.6301223186868863

Epoch: 302| Step: 0
Training loss: 0.8112603414079171
Validation loss: 2.688172729335718

Epoch: 5| Step: 1
Training loss: 0.4660947778826642
Validation loss: 2.6738694909710894

Epoch: 5| Step: 2
Training loss: 0.3052502350583683
Validation loss: 2.7109343632250256

Epoch: 5| Step: 3
Training loss: 0.281913464854652
Validation loss: 2.6870954526960276

Epoch: 5| Step: 4
Training loss: 0.6025254605085711
Validation loss: 2.7480518708842254

Epoch: 5| Step: 5
Training loss: 0.5397502547701243
Validation loss: 2.8040032645726667

Epoch: 5| Step: 6
Training loss: 0.34418368075613726
Validation loss: 2.7511120917307035

Epoch: 5| Step: 7
Training loss: 0.32433921230665563
Validation loss: 2.7101248073577517

Epoch: 5| Step: 8
Training loss: 0.38686067693323234
Validation loss: 2.6983963209823054

Epoch: 5| Step: 9
Training loss: 0.5620610060568584
Validation loss: 2.677077187012817

Epoch: 5| Step: 10
Training loss: 0.3861033233974777
Validation loss: 2.7210890548041995

Epoch: 5| Step: 11
Training loss: 0.33087977286810155
Validation loss: 2.741440808105653

Epoch: 303| Step: 0
Training loss: 0.3325693930549783
Validation loss: 2.7804014933262757

Epoch: 5| Step: 1
Training loss: 0.43072409006038487
Validation loss: 2.785774016205723

Epoch: 5| Step: 2
Training loss: 0.2865815403435641
Validation loss: 2.7635408691700345

Epoch: 5| Step: 3
Training loss: 0.35766253681248666
Validation loss: 2.769873721205782

Epoch: 5| Step: 4
Training loss: 0.39260059501148126
Validation loss: 2.7762934276556925

Epoch: 5| Step: 5
Training loss: 0.2818371022623993
Validation loss: 2.756825981162697

Epoch: 5| Step: 6
Training loss: 0.3308151976761695
Validation loss: 2.7500569995117017

Epoch: 5| Step: 7
Training loss: 0.3301723955054728
Validation loss: 2.7183671075121025

Epoch: 5| Step: 8
Training loss: 0.39282169662064526
Validation loss: 2.715961831657995

Epoch: 5| Step: 9
Training loss: 0.6524143980226124
Validation loss: 2.8302701117538343

Epoch: 5| Step: 10
Training loss: 0.523930644699803
Validation loss: 2.7662156295135043

Epoch: 5| Step: 11
Training loss: 0.4908073693787791
Validation loss: 2.6650870768377026

Epoch: 304| Step: 0
Training loss: 0.46574732370575156
Validation loss: 2.7243298513666847

Epoch: 5| Step: 1
Training loss: 0.4121177455540144
Validation loss: 2.7188689728352444

Epoch: 5| Step: 2
Training loss: 0.46166304689611015
Validation loss: 2.6325928910577128

Epoch: 5| Step: 3
Training loss: 0.37286712150422086
Validation loss: 2.7142557033305446

Epoch: 5| Step: 4
Training loss: 0.4394604152498595
Validation loss: 2.701646882109669

Epoch: 5| Step: 5
Training loss: 0.39431722897970894
Validation loss: 2.6786819736436733

Epoch: 5| Step: 6
Training loss: 0.6781042447407761
Validation loss: 2.711959067403825

Epoch: 5| Step: 7
Training loss: 0.6335048420306282
Validation loss: 2.6970283501537295

Epoch: 5| Step: 8
Training loss: 0.49089369189288506
Validation loss: 2.6842048019673577

Epoch: 5| Step: 9
Training loss: 0.3298173585396152
Validation loss: 2.6257491178172407

Epoch: 5| Step: 10
Training loss: 0.42241962035057007
Validation loss: 2.77959701979793

Epoch: 5| Step: 11
Training loss: 0.32719748969071105
Validation loss: 2.75348783520418

Epoch: 305| Step: 0
Training loss: 0.5592190903489132
Validation loss: 2.7165023750132367

Epoch: 5| Step: 1
Training loss: 0.6462480049545217
Validation loss: 2.7568514538917346

Epoch: 5| Step: 2
Training loss: 0.33358526643422765
Validation loss: 2.7402103683134267

Epoch: 5| Step: 3
Training loss: 0.3791263177209248
Validation loss: 2.7045828833016685

Epoch: 5| Step: 4
Training loss: 0.5027470525582147
Validation loss: 2.7016909953929504

Epoch: 5| Step: 5
Training loss: 0.5097770251172289
Validation loss: 2.685239014521423

Epoch: 5| Step: 6
Training loss: 0.32221063086859975
Validation loss: 2.703596320250362

Epoch: 5| Step: 7
Training loss: 0.24425749461038787
Validation loss: 2.6518359515135024

Epoch: 5| Step: 8
Training loss: 0.5585882813512767
Validation loss: 2.8217628550362415

Epoch: 5| Step: 9
Training loss: 0.5114825919536686
Validation loss: 2.7350008947567406

Epoch: 5| Step: 10
Training loss: 0.4013771371466741
Validation loss: 2.776916005978529

Epoch: 5| Step: 11
Training loss: 0.43320084718289403
Validation loss: 2.731026606586008

Epoch: 306| Step: 0
Training loss: 0.3722623794910539
Validation loss: 2.7257171712253205

Epoch: 5| Step: 1
Training loss: 0.45507047916914817
Validation loss: 2.711953492199066

Epoch: 5| Step: 2
Training loss: 0.4325323430685493
Validation loss: 2.650129243035257

Epoch: 5| Step: 3
Training loss: 0.28095931024724285
Validation loss: 2.709977745026942

Epoch: 5| Step: 4
Training loss: 0.39424818100688036
Validation loss: 2.660383460321309

Epoch: 5| Step: 5
Training loss: 0.3741060768246216
Validation loss: 2.771546997337786

Epoch: 5| Step: 6
Training loss: 0.4185154094058164
Validation loss: 2.7244598457022287

Epoch: 5| Step: 7
Training loss: 0.531159561537418
Validation loss: 2.674874585099453

Epoch: 5| Step: 8
Training loss: 0.4764646367133008
Validation loss: 2.6862804876602984

Epoch: 5| Step: 9
Training loss: 0.6354686189477362
Validation loss: 2.7462006534986716

Epoch: 5| Step: 10
Training loss: 0.3217051168835243
Validation loss: 2.6500881868659873

Epoch: 5| Step: 11
Training loss: 0.23782175348101636
Validation loss: 2.6868052693573876

Epoch: 307| Step: 0
Training loss: 0.3157232353566195
Validation loss: 2.759004920459179

Epoch: 5| Step: 1
Training loss: 0.42745767640420534
Validation loss: 2.745999717639919

Epoch: 5| Step: 2
Training loss: 0.3193571917725535
Validation loss: 2.7234679389109053

Epoch: 5| Step: 3
Training loss: 0.30466692194773193
Validation loss: 2.706245062326533

Epoch: 5| Step: 4
Training loss: 0.32603884742460437
Validation loss: 2.823252922995657

Epoch: 5| Step: 5
Training loss: 0.4477201259770553
Validation loss: 2.7273751662714227

Epoch: 5| Step: 6
Training loss: 0.5172248642438878
Validation loss: 2.7580951081192

Epoch: 5| Step: 7
Training loss: 0.4559490726876913
Validation loss: 2.675009017851891

Epoch: 5| Step: 8
Training loss: 0.3335898227147797
Validation loss: 2.7522901297550955

Epoch: 5| Step: 9
Training loss: 0.2220208487869672
Validation loss: 2.7574448777249123

Epoch: 5| Step: 10
Training loss: 0.6438849937227709
Validation loss: 2.6780388805262993

Epoch: 5| Step: 11
Training loss: 0.33522900456376464
Validation loss: 2.7241450161295755

Epoch: 308| Step: 0
Training loss: 0.38641179550887067
Validation loss: 2.67070137333716

Epoch: 5| Step: 1
Training loss: 0.3071460082321809
Validation loss: 2.722043406739995

Epoch: 5| Step: 2
Training loss: 0.34608714009123415
Validation loss: 2.6952188705914972

Epoch: 5| Step: 3
Training loss: 0.40779323166968884
Validation loss: 2.683516825647441

Epoch: 5| Step: 4
Training loss: 0.4137012777424482
Validation loss: 2.7251144105183984

Epoch: 5| Step: 5
Training loss: 0.3103223024646711
Validation loss: 2.768797400149898

Epoch: 5| Step: 6
Training loss: 0.36721738734255016
Validation loss: 2.748949807662049

Epoch: 5| Step: 7
Training loss: 0.6511614473145274
Validation loss: 2.6872083890158978

Epoch: 5| Step: 8
Training loss: 0.27669774967163624
Validation loss: 2.704231891864276

Epoch: 5| Step: 9
Training loss: 0.5296627624046532
Validation loss: 2.6722643384524702

Epoch: 5| Step: 10
Training loss: 0.44672974713383307
Validation loss: 2.737076015676526

Epoch: 5| Step: 11
Training loss: 0.24795861063023825
Validation loss: 2.707636190824384

Epoch: 309| Step: 0
Training loss: 0.4256653759272629
Validation loss: 2.6663737111304813

Epoch: 5| Step: 1
Training loss: 0.298235323963743
Validation loss: 2.6721530977789456

Epoch: 5| Step: 2
Training loss: 0.38726086621095457
Validation loss: 2.8177211829343185

Epoch: 5| Step: 3
Training loss: 0.42102494960531145
Validation loss: 2.7603505048680304

Epoch: 5| Step: 4
Training loss: 0.28920241140238095
Validation loss: 2.7656109552691324

Epoch: 5| Step: 5
Training loss: 0.3203541798339915
Validation loss: 2.763992668378135

Epoch: 5| Step: 6
Training loss: 0.5500625087155928
Validation loss: 2.7975370096026135

Epoch: 5| Step: 7
Training loss: 0.3086512306858099
Validation loss: 2.713466216128732

Epoch: 5| Step: 8
Training loss: 0.401495771392939
Validation loss: 2.69947702558755

Epoch: 5| Step: 9
Training loss: 0.6203629374717786
Validation loss: 2.776356245661824

Epoch: 5| Step: 10
Training loss: 0.3327833185252534
Validation loss: 2.6723694947919374

Epoch: 5| Step: 11
Training loss: 0.3214309286417131
Validation loss: 2.651964417993229

Epoch: 310| Step: 0
Training loss: 0.3541739640699574
Validation loss: 2.6899842084423486

Epoch: 5| Step: 1
Training loss: 0.3521308860699877
Validation loss: 2.745577018816983

Epoch: 5| Step: 2
Training loss: 0.38525371285592025
Validation loss: 2.702099030262087

Epoch: 5| Step: 3
Training loss: 0.42683739869377413
Validation loss: 2.6958696978050773

Epoch: 5| Step: 4
Training loss: 0.7633822933540095
Validation loss: 2.7218929919390202

Epoch: 5| Step: 5
Training loss: 0.3175412765465161
Validation loss: 2.7071168233713894

Epoch: 5| Step: 6
Training loss: 0.27055767439841105
Validation loss: 2.646187662193149

Epoch: 5| Step: 7
Training loss: 0.2661668076185388
Validation loss: 2.6863542154722286

Epoch: 5| Step: 8
Training loss: 0.3955659988364305
Validation loss: 2.709949969478555

Epoch: 5| Step: 9
Training loss: 0.4045744785979409
Validation loss: 2.723080606105271

Epoch: 5| Step: 10
Training loss: 0.540499499533366
Validation loss: 2.6753830439398474

Epoch: 5| Step: 11
Training loss: 0.5821947213839458
Validation loss: 2.6811102601741315

Epoch: 311| Step: 0
Training loss: 0.30743042862466846
Validation loss: 2.7213073446574643

Epoch: 5| Step: 1
Training loss: 0.3123506069718789
Validation loss: 2.7286102598904978

Epoch: 5| Step: 2
Training loss: 0.3673935170213741
Validation loss: 2.7470185019223323

Epoch: 5| Step: 3
Training loss: 0.4187748346508429
Validation loss: 2.7765909382757874

Epoch: 5| Step: 4
Training loss: 0.3282921115761518
Validation loss: 2.754100556428983

Epoch: 5| Step: 5
Training loss: 0.4628731607611261
Validation loss: 2.720135587826006

Epoch: 5| Step: 6
Training loss: 0.5003790908425165
Validation loss: 2.69883677847973

Epoch: 5| Step: 7
Training loss: 0.34852434923428516
Validation loss: 2.7812303120919943

Epoch: 5| Step: 8
Training loss: 0.6160789384640875
Validation loss: 2.8191940893842298

Epoch: 5| Step: 9
Training loss: 0.45895051222532723
Validation loss: 2.7505509590435495

Epoch: 5| Step: 10
Training loss: 0.3577288992221721
Validation loss: 2.822488271341432

Epoch: 5| Step: 11
Training loss: 0.30870701123781435
Validation loss: 2.7190650450476785

Epoch: 312| Step: 0
Training loss: 0.37172502731275936
Validation loss: 2.738804076633137

Epoch: 5| Step: 1
Training loss: 0.3207175670907869
Validation loss: 2.7142248019874433

Epoch: 5| Step: 2
Training loss: 0.3708629291847078
Validation loss: 2.7060618754392047

Epoch: 5| Step: 3
Training loss: 0.22764835270659123
Validation loss: 2.78298786602466

Epoch: 5| Step: 4
Training loss: 0.3829827611220852
Validation loss: 2.7060501867683873

Epoch: 5| Step: 5
Training loss: 0.6951684266745434
Validation loss: 2.7672403291397787

Epoch: 5| Step: 6
Training loss: 0.5034845642974055
Validation loss: 2.754263931746097

Epoch: 5| Step: 7
Training loss: 0.4331295174477332
Validation loss: 2.737405935468408

Epoch: 5| Step: 8
Training loss: 0.23993378729207152
Validation loss: 2.761015051037013

Epoch: 5| Step: 9
Training loss: 0.32190825559055936
Validation loss: 2.739229775351586

Epoch: 5| Step: 10
Training loss: 0.3268012866680655
Validation loss: 2.7044387080028898

Epoch: 5| Step: 11
Training loss: 0.6369085672533943
Validation loss: 2.733065380554326

Epoch: 313| Step: 0
Training loss: 0.5553756260238372
Validation loss: 2.756816176135227

Epoch: 5| Step: 1
Training loss: 0.4337959677169386
Validation loss: 2.7123969013057647

Epoch: 5| Step: 2
Training loss: 0.676090015588845
Validation loss: 2.8076308027296686

Epoch: 5| Step: 3
Training loss: 0.3478542471283561
Validation loss: 2.8159564960248096

Epoch: 5| Step: 4
Training loss: 0.5818448376238978
Validation loss: 2.802850268512084

Epoch: 5| Step: 5
Training loss: 0.2938669169874872
Validation loss: 2.7491581198910313

Epoch: 5| Step: 6
Training loss: 0.3717635484585414
Validation loss: 2.834060979886127

Epoch: 5| Step: 7
Training loss: 0.3138615629669025
Validation loss: 2.7416931750128177

Epoch: 5| Step: 8
Training loss: 0.32432726687079677
Validation loss: 2.7986094710379676

Epoch: 5| Step: 9
Training loss: 0.33296914869022354
Validation loss: 2.749383358744311

Epoch: 5| Step: 10
Training loss: 0.5430670724668156
Validation loss: 2.7617411812640653

Epoch: 5| Step: 11
Training loss: 0.1581640960682018
Validation loss: 2.797435718498963

Epoch: 314| Step: 0
Training loss: 0.8742056715245222
Validation loss: 2.785354168508643

Epoch: 5| Step: 1
Training loss: 0.4293783983432045
Validation loss: 2.722483253182291

Epoch: 5| Step: 2
Training loss: 0.3998454592609729
Validation loss: 2.712120153636558

Epoch: 5| Step: 3
Training loss: 0.5947218019392031
Validation loss: 2.6779488204759634

Epoch: 5| Step: 4
Training loss: 0.3410612855735494
Validation loss: 2.679844001819088

Epoch: 5| Step: 5
Training loss: 0.39965728964727426
Validation loss: 2.712721689162703

Epoch: 5| Step: 6
Training loss: 0.512427152713211
Validation loss: 2.72443128799104

Epoch: 5| Step: 7
Training loss: 0.32485660177095427
Validation loss: 2.7071665573616417

Epoch: 5| Step: 8
Training loss: 0.2769618696115465
Validation loss: 2.7441134522745525

Epoch: 5| Step: 9
Training loss: 0.3594308270753846
Validation loss: 2.7169875538084263

Epoch: 5| Step: 10
Training loss: 0.280092998732181
Validation loss: 2.6941048759369974

Epoch: 5| Step: 11
Training loss: 0.37377036673893044
Validation loss: 2.646534204893689

Epoch: 315| Step: 0
Training loss: 0.34485970538432337
Validation loss: 2.7026332304994334

Epoch: 5| Step: 1
Training loss: 0.3509032744501379
Validation loss: 2.660713466069335

Epoch: 5| Step: 2
Training loss: 0.3572773041725397
Validation loss: 2.705304995868597

Epoch: 5| Step: 3
Training loss: 0.5628365993052936
Validation loss: 2.7179356484454757

Epoch: 5| Step: 4
Training loss: 0.4314865424167196
Validation loss: 2.666901169588843

Epoch: 5| Step: 5
Training loss: 0.3615395005015321
Validation loss: 2.7158383091423226

Epoch: 5| Step: 6
Training loss: 0.28687016908986984
Validation loss: 2.7027336895783725

Epoch: 5| Step: 7
Training loss: 0.5873745398786504
Validation loss: 2.731194384726639

Epoch: 5| Step: 8
Training loss: 0.3482566321303541
Validation loss: 2.750643308128305

Epoch: 5| Step: 9
Training loss: 0.29778920756034083
Validation loss: 2.739494798532686

Epoch: 5| Step: 10
Training loss: 0.31046919180959087
Validation loss: 2.6779411898267114

Epoch: 5| Step: 11
Training loss: 0.33653805524413766
Validation loss: 2.7166240316294568

Epoch: 316| Step: 0
Training loss: 0.3543969228647515
Validation loss: 2.6579066327719874

Epoch: 5| Step: 1
Training loss: 0.3454399508028174
Validation loss: 2.7267923595231984

Epoch: 5| Step: 2
Training loss: 0.31993594947941495
Validation loss: 2.6986974165804107

Epoch: 5| Step: 3
Training loss: 0.34296025241760875
Validation loss: 2.71266354625954

Epoch: 5| Step: 4
Training loss: 0.5259440743845185
Validation loss: 2.756465006318971

Epoch: 5| Step: 5
Training loss: 0.4365302987807563
Validation loss: 2.762713478435879

Epoch: 5| Step: 6
Training loss: 0.35819126138624197
Validation loss: 2.7824370283522604

Epoch: 5| Step: 7
Training loss: 0.6916747784043148
Validation loss: 2.684306781554782

Epoch: 5| Step: 8
Training loss: 0.3645387031849516
Validation loss: 2.640623803674551

Epoch: 5| Step: 9
Training loss: 0.3151549805373051
Validation loss: 2.694806074397133

Epoch: 5| Step: 10
Training loss: 0.43516080364262316
Validation loss: 2.7369117522837336

Epoch: 5| Step: 11
Training loss: 0.6702328952568875
Validation loss: 2.688897534662811

Epoch: 317| Step: 0
Training loss: 0.31381722831848696
Validation loss: 2.712593529227007

Epoch: 5| Step: 1
Training loss: 0.2705154417869447
Validation loss: 2.714839728555971

Epoch: 5| Step: 2
Training loss: 0.24989373958871844
Validation loss: 2.778396993337594

Epoch: 5| Step: 3
Training loss: 0.36137641377866875
Validation loss: 2.732858088123826

Epoch: 5| Step: 4
Training loss: 0.4151108623556535
Validation loss: 2.712429552144935

Epoch: 5| Step: 5
Training loss: 0.471642818550088
Validation loss: 2.6638663509645504

Epoch: 5| Step: 6
Training loss: 0.4571502563210905
Validation loss: 2.6343994866526947

Epoch: 5| Step: 7
Training loss: 0.2998119813112596
Validation loss: 2.6070184174045496

Epoch: 5| Step: 8
Training loss: 0.8157630102094534
Validation loss: 2.6807517300823456

Epoch: 5| Step: 9
Training loss: 0.5418048981813034
Validation loss: 2.6383811702074467

Epoch: 5| Step: 10
Training loss: 0.41369358758615593
Validation loss: 2.670885341502924

Epoch: 5| Step: 11
Training loss: 0.4091257865564866
Validation loss: 2.7106608122269695

Epoch: 318| Step: 0
Training loss: 0.49756650010585307
Validation loss: 2.729710849836053

Epoch: 5| Step: 1
Training loss: 0.39301190679654696
Validation loss: 2.7411813221341745

Epoch: 5| Step: 2
Training loss: 0.32773112317041764
Validation loss: 2.6980218474064643

Epoch: 5| Step: 3
Training loss: 0.3269418320249405
Validation loss: 2.6824742943277777

Epoch: 5| Step: 4
Training loss: 0.3003285332685855
Validation loss: 2.657282236028426

Epoch: 5| Step: 5
Training loss: 0.4684337343773324
Validation loss: 2.718921718070757

Epoch: 5| Step: 6
Training loss: 0.28916250251763753
Validation loss: 2.6660265576484288

Epoch: 5| Step: 7
Training loss: 0.602291705583351
Validation loss: 2.7208481727378473

Epoch: 5| Step: 8
Training loss: 0.3578731418845186
Validation loss: 2.7517435947534397

Epoch: 5| Step: 9
Training loss: 0.32279896385565454
Validation loss: 2.7065876408743756

Epoch: 5| Step: 10
Training loss: 0.3055549158585721
Validation loss: 2.739017066644043

Epoch: 5| Step: 11
Training loss: 0.30802883881937826
Validation loss: 2.730297809101552

Epoch: 319| Step: 0
Training loss: 0.3638842920121382
Validation loss: 2.662726495180082

Epoch: 5| Step: 1
Training loss: 0.5074967209470453
Validation loss: 2.731261367977877

Epoch: 5| Step: 2
Training loss: 0.49208694520745055
Validation loss: 2.709772286478629

Epoch: 5| Step: 3
Training loss: 0.6225232402262673
Validation loss: 2.739564809748658

Epoch: 5| Step: 4
Training loss: 0.251727128508045
Validation loss: 2.707917622915642

Epoch: 5| Step: 5
Training loss: 0.3584200569305281
Validation loss: 2.8163137116487045

Epoch: 5| Step: 6
Training loss: 0.4475216028923646
Validation loss: 2.770616204973313

Epoch: 5| Step: 7
Training loss: 0.4229300692584664
Validation loss: 2.752822749404283

Epoch: 5| Step: 8
Training loss: 0.44227150702056445
Validation loss: 2.7453915985731836

Epoch: 5| Step: 9
Training loss: 0.3458769409806274
Validation loss: 2.783197878113201

Epoch: 5| Step: 10
Training loss: 0.30389146253996147
Validation loss: 2.759070151983773

Epoch: 5| Step: 11
Training loss: 0.3687806569303074
Validation loss: 2.769054796909664

Epoch: 320| Step: 0
Training loss: 0.4129620990946483
Validation loss: 2.6807662379254404

Epoch: 5| Step: 1
Training loss: 0.28410763171135855
Validation loss: 2.663244828586588

Epoch: 5| Step: 2
Training loss: 0.35018311206438507
Validation loss: 2.7846430430065126

Epoch: 5| Step: 3
Training loss: 0.3091837036296095
Validation loss: 2.777403067640774

Epoch: 5| Step: 4
Training loss: 0.4132582032496617
Validation loss: 2.711969102377203

Epoch: 5| Step: 5
Training loss: 0.4558538447995027
Validation loss: 2.7967151759566486

Epoch: 5| Step: 6
Training loss: 0.5707272106103947
Validation loss: 2.719016672261229

Epoch: 5| Step: 7
Training loss: 0.301320917084353
Validation loss: 2.69725587232163

Epoch: 5| Step: 8
Training loss: 0.38999959471877144
Validation loss: 2.6963614887336838

Epoch: 5| Step: 9
Training loss: 0.32697473725746506
Validation loss: 2.7017543014944416

Epoch: 5| Step: 10
Training loss: 0.21263989724118726
Validation loss: 2.75047011041827

Epoch: 5| Step: 11
Training loss: 0.06811428411224264
Validation loss: 2.7458788922012647

Epoch: 321| Step: 0
Training loss: 0.29287390127232343
Validation loss: 2.7420927540350113

Epoch: 5| Step: 1
Training loss: 0.38806058266169585
Validation loss: 2.760475126883021

Epoch: 5| Step: 2
Training loss: 0.47239132226754915
Validation loss: 2.6993044882377695

Epoch: 5| Step: 3
Training loss: 0.3120358596560595
Validation loss: 2.646742275382783

Epoch: 5| Step: 4
Training loss: 0.5506782976610548
Validation loss: 2.697034556596392

Epoch: 5| Step: 5
Training loss: 0.2762939032453219
Validation loss: 2.687076819909778

Epoch: 5| Step: 6
Training loss: 0.27466023762267316
Validation loss: 2.688900056151665

Epoch: 5| Step: 7
Training loss: 0.36923511244476764
Validation loss: 2.723312521405191

Epoch: 5| Step: 8
Training loss: 0.21554770881184612
Validation loss: 2.6962423259512125

Epoch: 5| Step: 9
Training loss: 0.31652276519361267
Validation loss: 2.7440082450240966

Epoch: 5| Step: 10
Training loss: 0.3683383235801924
Validation loss: 2.7031767661957358

Epoch: 5| Step: 11
Training loss: 0.7788418466769504
Validation loss: 2.7050606223227573

Epoch: 322| Step: 0
Training loss: 0.29572190158345346
Validation loss: 2.6837292506969472

Epoch: 5| Step: 1
Training loss: 0.4486646635102697
Validation loss: 2.761988423880042

Epoch: 5| Step: 2
Training loss: 0.3317642260162504
Validation loss: 2.7296611117168528

Epoch: 5| Step: 3
Training loss: 0.4350078651659891
Validation loss: 2.734763777206008

Epoch: 5| Step: 4
Training loss: 0.41907870785450185
Validation loss: 2.7431337004742535

Epoch: 5| Step: 5
Training loss: 0.3298228704583422
Validation loss: 2.8158725545021377

Epoch: 5| Step: 6
Training loss: 0.23122774835444798
Validation loss: 2.7491514692197705

Epoch: 5| Step: 7
Training loss: 0.3318748891330972
Validation loss: 2.7279145059440575

Epoch: 5| Step: 8
Training loss: 0.3689471550204311
Validation loss: 2.758055940065005

Epoch: 5| Step: 9
Training loss: 0.6447612929906422
Validation loss: 2.6798469340325672

Epoch: 5| Step: 10
Training loss: 0.32730554253010896
Validation loss: 2.6988211273118834

Epoch: 5| Step: 11
Training loss: 0.36778142254913115
Validation loss: 2.732659468411081

Epoch: 323| Step: 0
Training loss: 0.32252087743590596
Validation loss: 2.724016197470123

Epoch: 5| Step: 1
Training loss: 0.390274634589951
Validation loss: 2.7186455797919087

Epoch: 5| Step: 2
Training loss: 0.6749866201699463
Validation loss: 2.6636458748870933

Epoch: 5| Step: 3
Training loss: 0.26559321830454813
Validation loss: 2.7163502856093964

Epoch: 5| Step: 4
Training loss: 0.5964485632357951
Validation loss: 2.708781426603477

Epoch: 5| Step: 5
Training loss: 0.32231692281561913
Validation loss: 2.7627039352215905

Epoch: 5| Step: 6
Training loss: 0.39908782394701425
Validation loss: 2.807436167313169

Epoch: 5| Step: 7
Training loss: 0.2973140807391444
Validation loss: 2.7305403496737215

Epoch: 5| Step: 8
Training loss: 0.5061957518628789
Validation loss: 2.7196747022121155

Epoch: 5| Step: 9
Training loss: 0.4176109422397468
Validation loss: 2.6789010639053332

Epoch: 5| Step: 10
Training loss: 0.3005925242871645
Validation loss: 2.6889998442528147

Epoch: 5| Step: 11
Training loss: 0.26174989201890525
Validation loss: 2.6656153489027954

Epoch: 324| Step: 0
Training loss: 0.37727516135405115
Validation loss: 2.7040469741684166

Epoch: 5| Step: 1
Training loss: 0.5089013676794215
Validation loss: 2.742747634526914

Epoch: 5| Step: 2
Training loss: 0.4185735836204903
Validation loss: 2.7221770811284793

Epoch: 5| Step: 3
Training loss: 0.426116216645676
Validation loss: 2.7309458820077466

Epoch: 5| Step: 4
Training loss: 0.38058571398208824
Validation loss: 2.71759154313846

Epoch: 5| Step: 5
Training loss: 0.481553504656845
Validation loss: 2.7453631880366456

Epoch: 5| Step: 6
Training loss: 0.26646774902191533
Validation loss: 2.786588014573765

Epoch: 5| Step: 7
Training loss: 0.30819486841472793
Validation loss: 2.7882736793102474

Epoch: 5| Step: 8
Training loss: 0.30261048273705254
Validation loss: 2.6696691200409237

Epoch: 5| Step: 9
Training loss: 0.4168353891498661
Validation loss: 2.742916014028656

Epoch: 5| Step: 10
Training loss: 0.6970089565560899
Validation loss: 2.7603601299949987

Epoch: 5| Step: 11
Training loss: 0.8115154683700737
Validation loss: 2.785780267420194

Epoch: 325| Step: 0
Training loss: 0.6232484114864226
Validation loss: 2.8060849568148356

Epoch: 5| Step: 1
Training loss: 0.3898816665527087
Validation loss: 2.830942980503457

Epoch: 5| Step: 2
Training loss: 0.3408528397130558
Validation loss: 2.84208640669734

Epoch: 5| Step: 3
Training loss: 0.3647918876692304
Validation loss: 2.8777169195441217

Epoch: 5| Step: 4
Training loss: 0.40942581167178466
Validation loss: 2.756928807531085

Epoch: 5| Step: 5
Training loss: 0.36159330380245497
Validation loss: 2.8124480860828593

Epoch: 5| Step: 6
Training loss: 0.4047469798676957
Validation loss: 2.803806999081816

Epoch: 5| Step: 7
Training loss: 0.4325499816084053
Validation loss: 2.7808118682259995

Epoch: 5| Step: 8
Training loss: 0.314901163058406
Validation loss: 2.757991911011568

Epoch: 5| Step: 9
Training loss: 0.31514558309754975
Validation loss: 2.79799164870154

Epoch: 5| Step: 10
Training loss: 0.40055622304949534
Validation loss: 2.822560788815763

Epoch: 5| Step: 11
Training loss: 0.3110470851844403
Validation loss: 2.8738546301361927

Epoch: 326| Step: 0
Training loss: 0.3268409650563421
Validation loss: 2.8740674420659524

Epoch: 5| Step: 1
Training loss: 0.29311756169330777
Validation loss: 2.777710530473727

Epoch: 5| Step: 2
Training loss: 0.49294452879779455
Validation loss: 2.7270957840610257

Epoch: 5| Step: 3
Training loss: 0.29181083737714897
Validation loss: 2.722415524845685

Epoch: 5| Step: 4
Training loss: 0.3107013198381893
Validation loss: 2.7216163557623125

Epoch: 5| Step: 5
Training loss: 0.2864419094348093
Validation loss: 2.755945101169967

Epoch: 5| Step: 6
Training loss: 0.5178283950032835
Validation loss: 2.7328636933830466

Epoch: 5| Step: 7
Training loss: 0.330414933135563
Validation loss: 2.6895230463561375

Epoch: 5| Step: 8
Training loss: 0.34582420427077376
Validation loss: 2.694716187638907

Epoch: 5| Step: 9
Training loss: 0.3187953795125135
Validation loss: 2.8265807816684085

Epoch: 5| Step: 10
Training loss: 0.6096214871863629
Validation loss: 2.792029383330316

Epoch: 5| Step: 11
Training loss: 0.4432835451052565
Validation loss: 2.7781269955994428

Epoch: 327| Step: 0
Training loss: 0.36396106567550873
Validation loss: 2.7420981484081377

Epoch: 5| Step: 1
Training loss: 0.333866176547904
Validation loss: 2.70211196027389

Epoch: 5| Step: 2
Training loss: 0.2936631175666388
Validation loss: 2.8023979277487685

Epoch: 5| Step: 3
Training loss: 0.2762555142754183
Validation loss: 2.74442945161792

Epoch: 5| Step: 4
Training loss: 0.42701695864589667
Validation loss: 2.7025576824886546

Epoch: 5| Step: 5
Training loss: 0.36806472530978096
Validation loss: 2.7030312369370826

Epoch: 5| Step: 6
Training loss: 0.4461364151148108
Validation loss: 2.7370739359952507

Epoch: 5| Step: 7
Training loss: 0.29994798398081984
Validation loss: 2.769554550582226

Epoch: 5| Step: 8
Training loss: 0.36549148077892685
Validation loss: 2.741504736343653

Epoch: 5| Step: 9
Training loss: 0.4383265997124084
Validation loss: 2.7649608504264065

Epoch: 5| Step: 10
Training loss: 0.6099951840429462
Validation loss: 2.790611680993295

Epoch: 5| Step: 11
Training loss: 0.3445470412737754
Validation loss: 2.8210354597812524

Epoch: 328| Step: 0
Training loss: 0.3829164169332847
Validation loss: 2.7558579691579843

Epoch: 5| Step: 1
Training loss: 0.34883836088295417
Validation loss: 2.732851170592868

Epoch: 5| Step: 2
Training loss: 0.36161623628811695
Validation loss: 2.7851170148756563

Epoch: 5| Step: 3
Training loss: 0.7864345942739688
Validation loss: 2.748289190226632

Epoch: 5| Step: 4
Training loss: 0.5562491931266504
Validation loss: 2.718822805299472

Epoch: 5| Step: 5
Training loss: 0.3085616010506377
Validation loss: 2.75695517292599

Epoch: 5| Step: 6
Training loss: 0.32178941857427235
Validation loss: 2.786602306508733

Epoch: 5| Step: 7
Training loss: 0.4115627695486798
Validation loss: 2.699120611310392

Epoch: 5| Step: 8
Training loss: 0.3767153528630714
Validation loss: 2.7841448719814252

Epoch: 5| Step: 9
Training loss: 0.5298211010811559
Validation loss: 2.7783316327642655

Epoch: 5| Step: 10
Training loss: 0.31217918617855345
Validation loss: 2.732662274881156

Epoch: 5| Step: 11
Training loss: 0.2590825557883165
Validation loss: 2.70952033599444

Epoch: 329| Step: 0
Training loss: 0.26272489246471836
Validation loss: 2.6386883121244877

Epoch: 5| Step: 1
Training loss: 0.3211214271738667
Validation loss: 2.776217729998397

Epoch: 5| Step: 2
Training loss: 0.40385351888260124
Validation loss: 2.6129361710276418

Epoch: 5| Step: 3
Training loss: 0.3349346005954377
Validation loss: 2.746651552577895

Epoch: 5| Step: 4
Training loss: 0.34351985986913175
Validation loss: 2.738551323778013

Epoch: 5| Step: 5
Training loss: 0.29972025524211265
Validation loss: 2.7514216729077265

Epoch: 5| Step: 6
Training loss: 0.5032194913664303
Validation loss: 2.7843044239237527

Epoch: 5| Step: 7
Training loss: 0.4415397273439216
Validation loss: 2.729721534660942

Epoch: 5| Step: 8
Training loss: 0.36568853119773387
Validation loss: 2.7152693929377465

Epoch: 5| Step: 9
Training loss: 0.4363806062041569
Validation loss: 2.7842287870778835

Epoch: 5| Step: 10
Training loss: 0.3546045929056208
Validation loss: 2.746377567621045

Epoch: 5| Step: 11
Training loss: 1.182290143027423
Validation loss: 2.7515161554064567

Epoch: 330| Step: 0
Training loss: 0.32486452571089514
Validation loss: 2.720250033779405

Epoch: 5| Step: 1
Training loss: 0.35292911877821176
Validation loss: 2.7564296191012563

Epoch: 5| Step: 2
Training loss: 0.48180659049741503
Validation loss: 2.809209661459338

Epoch: 5| Step: 3
Training loss: 0.3939114981168915
Validation loss: 2.704680856850449

Epoch: 5| Step: 4
Training loss: 0.3068764381219609
Validation loss: 2.7976033986686843

Epoch: 5| Step: 5
Training loss: 0.24908695532849817
Validation loss: 2.770323417227531

Epoch: 5| Step: 6
Training loss: 0.3666838580494072
Validation loss: 2.8178458606253636

Epoch: 5| Step: 7
Training loss: 0.31586985391184536
Validation loss: 2.7534252928146925

Epoch: 5| Step: 8
Training loss: 0.601531932103711
Validation loss: 2.7368324245286977

Epoch: 5| Step: 9
Training loss: 0.2768853119335625
Validation loss: 2.7451116796379695

Epoch: 5| Step: 10
Training loss: 0.3985499429051142
Validation loss: 2.7280822497117496

Epoch: 5| Step: 11
Training loss: 0.2900327559790546
Validation loss: 2.7166828759612813

Epoch: 331| Step: 0
Training loss: 0.5147425295902326
Validation loss: 2.6732375517018743

Epoch: 5| Step: 1
Training loss: 0.34211689817280416
Validation loss: 2.799367440529959

Epoch: 5| Step: 2
Training loss: 0.27199579000107493
Validation loss: 2.759348422707673

Epoch: 5| Step: 3
Training loss: 0.1857074043124302
Validation loss: 2.758144128184057

Epoch: 5| Step: 4
Training loss: 0.19873817297695998
Validation loss: 2.732166950076265

Epoch: 5| Step: 5
Training loss: 0.30521589091885326
Validation loss: 2.7622948297055308

Epoch: 5| Step: 6
Training loss: 0.25003316778461365
Validation loss: 2.811028335684053

Epoch: 5| Step: 7
Training loss: 0.36598491560228275
Validation loss: 2.7203346435592177

Epoch: 5| Step: 8
Training loss: 0.38435545228083556
Validation loss: 2.775427978894219

Epoch: 5| Step: 9
Training loss: 0.4082034535383883
Validation loss: 2.7473064438197388

Epoch: 5| Step: 10
Training loss: 0.4055597236316054
Validation loss: 2.7758448043692345

Epoch: 5| Step: 11
Training loss: 0.4475638049473814
Validation loss: 2.7627769791655012

Epoch: 332| Step: 0
Training loss: 0.45907059529270916
Validation loss: 2.7351895563211017

Epoch: 5| Step: 1
Training loss: 0.3134194556772891
Validation loss: 2.8069960533488523

Epoch: 5| Step: 2
Training loss: 0.1537040718610194
Validation loss: 2.730098837561358

Epoch: 5| Step: 3
Training loss: 0.3019286847802798
Validation loss: 2.8090528131560495

Epoch: 5| Step: 4
Training loss: 0.2748091626158766
Validation loss: 2.851028873209089

Epoch: 5| Step: 5
Training loss: 0.28290043143589755
Validation loss: 2.802466608563743

Epoch: 5| Step: 6
Training loss: 0.6124432177400823
Validation loss: 2.795295404247236

Epoch: 5| Step: 7
Training loss: 0.31069380205462505
Validation loss: 2.855321874289669

Epoch: 5| Step: 8
Training loss: 0.5020970832028862
Validation loss: 2.778382169351132

Epoch: 5| Step: 9
Training loss: 0.27467796424137025
Validation loss: 2.829381653019705

Epoch: 5| Step: 10
Training loss: 0.3165951035703808
Validation loss: 2.8562458092556517

Epoch: 5| Step: 11
Training loss: 0.4372403873196137
Validation loss: 2.8185093505602308

Epoch: 333| Step: 0
Training loss: 0.2165907489908295
Validation loss: 2.826498522859488

Epoch: 5| Step: 1
Training loss: 0.31444335116722244
Validation loss: 2.8064477721985868

Epoch: 5| Step: 2
Training loss: 0.4019060624489014
Validation loss: 2.812419536993726

Epoch: 5| Step: 3
Training loss: 0.46663131331600993
Validation loss: 2.7583861614385303

Epoch: 5| Step: 4
Training loss: 0.2761974420003297
Validation loss: 2.788036820334787

Epoch: 5| Step: 5
Training loss: 0.20745160056873813
Validation loss: 2.7986373037706476

Epoch: 5| Step: 6
Training loss: 0.30046999295791416
Validation loss: 2.7772815409443252

Epoch: 5| Step: 7
Training loss: 0.24019688414516863
Validation loss: 2.779303290904135

Epoch: 5| Step: 8
Training loss: 0.5452116055864735
Validation loss: 2.7645697511187453

Epoch: 5| Step: 9
Training loss: 0.4222428519489198
Validation loss: 2.763158727663077

Epoch: 5| Step: 10
Training loss: 0.39631017607070856
Validation loss: 2.7627110153260785

Epoch: 5| Step: 11
Training loss: 0.22973197422097646
Validation loss: 2.8172639095574485

Epoch: 334| Step: 0
Training loss: 0.37167972678957567
Validation loss: 2.74873105307296

Epoch: 5| Step: 1
Training loss: 0.2891098318784446
Validation loss: 2.7229527038859103

Epoch: 5| Step: 2
Training loss: 0.41138611735202313
Validation loss: 2.7461135306444038

Epoch: 5| Step: 3
Training loss: 0.35110738754100407
Validation loss: 2.729257410423923

Epoch: 5| Step: 4
Training loss: 0.460931034366067
Validation loss: 2.7499890435607433

Epoch: 5| Step: 5
Training loss: 0.3240309596553844
Validation loss: 2.744716979258691

Epoch: 5| Step: 6
Training loss: 0.44127886123934573
Validation loss: 2.7787901612361265

Epoch: 5| Step: 7
Training loss: 0.30605674845203024
Validation loss: 2.772215227322321

Epoch: 5| Step: 8
Training loss: 0.3283125704567901
Validation loss: 2.716831897223735

Epoch: 5| Step: 9
Training loss: 0.3648863986000102
Validation loss: 2.70604893126117

Epoch: 5| Step: 10
Training loss: 0.5808522617132854
Validation loss: 2.7832895722822757

Epoch: 5| Step: 11
Training loss: 0.20436099780234843
Validation loss: 2.7361382639345013

Epoch: 335| Step: 0
Training loss: 0.48609238391710013
Validation loss: 2.685407857360083

Epoch: 5| Step: 1
Training loss: 0.3551639046202842
Validation loss: 2.7177682982311757

Epoch: 5| Step: 2
Training loss: 0.2741350540721341
Validation loss: 2.736511551061556

Epoch: 5| Step: 3
Training loss: 0.3391201493260475
Validation loss: 2.792132638834553

Epoch: 5| Step: 4
Training loss: 0.23992749128410643
Validation loss: 2.763403429489049

Epoch: 5| Step: 5
Training loss: 0.6020674629715715
Validation loss: 2.69961187625387

Epoch: 5| Step: 6
Training loss: 0.25010163506229266
Validation loss: 2.7471991711176473

Epoch: 5| Step: 7
Training loss: 0.45206691262385645
Validation loss: 2.772097468918994

Epoch: 5| Step: 8
Training loss: 0.3498428886167852
Validation loss: 2.7394130361348807

Epoch: 5| Step: 9
Training loss: 0.3110485942339101
Validation loss: 2.7014038251144115

Epoch: 5| Step: 10
Training loss: 0.3663948309446825
Validation loss: 2.64217079784454

Epoch: 5| Step: 11
Training loss: 0.3817895534274689
Validation loss: 2.7654532686353352

Epoch: 336| Step: 0
Training loss: 0.3322755139509725
Validation loss: 2.7246200397241718

Epoch: 5| Step: 1
Training loss: 0.5093635347164241
Validation loss: 2.734217611960402

Epoch: 5| Step: 2
Training loss: 0.46318112685760887
Validation loss: 2.7900425981359676

Epoch: 5| Step: 3
Training loss: 0.3302439098366936
Validation loss: 2.7609495488328295

Epoch: 5| Step: 4
Training loss: 0.46985009169160036
Validation loss: 2.793816632949017

Epoch: 5| Step: 5
Training loss: 0.641926582960407
Validation loss: 2.76693639895797

Epoch: 5| Step: 6
Training loss: 0.37808378168345325
Validation loss: 2.7382081512257312

Epoch: 5| Step: 7
Training loss: 0.2483274570005579
Validation loss: 2.726643286950072

Epoch: 5| Step: 8
Training loss: 0.38170635239170014
Validation loss: 2.6927093614075774

Epoch: 5| Step: 9
Training loss: 0.490181331120509
Validation loss: 2.750930220602148

Epoch: 5| Step: 10
Training loss: 0.7200623845518417
Validation loss: 2.6793805790920144

Epoch: 5| Step: 11
Training loss: 0.5571281306054937
Validation loss: 2.725133760184968

Epoch: 337| Step: 0
Training loss: 0.3373070788008806
Validation loss: 2.7124444618926544

Epoch: 5| Step: 1
Training loss: 0.7161628351216324
Validation loss: 2.763179135738879

Epoch: 5| Step: 2
Training loss: 0.6334708521474378
Validation loss: 2.894140930216955

Epoch: 5| Step: 3
Training loss: 0.5920418965441255
Validation loss: 2.798218647663089

Epoch: 5| Step: 4
Training loss: 0.31204539850027113
Validation loss: 2.738463348123897

Epoch: 5| Step: 5
Training loss: 0.3326277143746817
Validation loss: 2.781151776954608

Epoch: 5| Step: 6
Training loss: 0.5668195071917186
Validation loss: 2.7421700747842865

Epoch: 5| Step: 7
Training loss: 0.4954650228908147
Validation loss: 2.732352138862785

Epoch: 5| Step: 8
Training loss: 0.43875077812690966
Validation loss: 2.8136602728168136

Epoch: 5| Step: 9
Training loss: 0.34033367315304036
Validation loss: 2.7248175756830384

Epoch: 5| Step: 10
Training loss: 0.5200897599199987
Validation loss: 2.7437466267280435

Epoch: 5| Step: 11
Training loss: 0.8197840850621679
Validation loss: 2.783855307388191

Epoch: 338| Step: 0
Training loss: 0.37082077828416915
Validation loss: 2.7363243202838317

Epoch: 5| Step: 1
Training loss: 0.5015815220253118
Validation loss: 2.7255563090823545

Epoch: 5| Step: 2
Training loss: 0.5474749135667117
Validation loss: 2.690719827006631

Epoch: 5| Step: 3
Training loss: 0.8538876907551465
Validation loss: 2.686603873576468

Epoch: 5| Step: 4
Training loss: 0.4941662416113215
Validation loss: 2.7019952092522375

Epoch: 5| Step: 5
Training loss: 0.37279222195036316
Validation loss: 2.72281842544619

Epoch: 5| Step: 6
Training loss: 0.6166356673911919
Validation loss: 2.774964298270653

Epoch: 5| Step: 7
Training loss: 0.7979659298528939
Validation loss: 2.7665623227707594

Epoch: 5| Step: 8
Training loss: 0.6578845829556563
Validation loss: 2.77792040511706

Epoch: 5| Step: 9
Training loss: 0.3344872687273371
Validation loss: 2.740906157909695

Epoch: 5| Step: 10
Training loss: 0.31446575352680606
Validation loss: 2.701568684700483

Epoch: 5| Step: 11
Training loss: 0.3636149647699296
Validation loss: 2.6902316593462765

Epoch: 339| Step: 0
Training loss: 0.6419827099905089
Validation loss: 2.7735205337917805

Epoch: 5| Step: 1
Training loss: 0.5458409478721736
Validation loss: 2.7157327015323003

Epoch: 5| Step: 2
Training loss: 0.4470280845234012
Validation loss: 2.6798251666266792

Epoch: 5| Step: 3
Training loss: 0.4477906456437537
Validation loss: 2.745706533640733

Epoch: 5| Step: 4
Training loss: 0.6242547121538499
Validation loss: 2.7530973973588226

Epoch: 5| Step: 5
Training loss: 0.453999349924496
Validation loss: 2.8589157541713357

Epoch: 5| Step: 6
Training loss: 0.44456727429994103
Validation loss: 2.8102387839753744

Epoch: 5| Step: 7
Training loss: 0.5563593103394474
Validation loss: 2.8174868242180806

Epoch: 5| Step: 8
Training loss: 0.3230137896864149
Validation loss: 2.7735636543631244

Epoch: 5| Step: 9
Training loss: 0.3766170050718536
Validation loss: 2.7489869462567484

Epoch: 5| Step: 10
Training loss: 0.5371317078542401
Validation loss: 2.737579157743006

Epoch: 5| Step: 11
Training loss: 0.3186975333098298
Validation loss: 2.7203336338374067

Epoch: 340| Step: 0
Training loss: 0.4326104191580006
Validation loss: 2.68006386815423

Epoch: 5| Step: 1
Training loss: 0.36175118500727005
Validation loss: 2.6592943323484213

Epoch: 5| Step: 2
Training loss: 0.2758068159318582
Validation loss: 2.7633013617326796

Epoch: 5| Step: 3
Training loss: 0.45902844481228167
Validation loss: 2.7363028061117665

Epoch: 5| Step: 4
Training loss: 0.3807836017058598
Validation loss: 2.7506989977867753

Epoch: 5| Step: 5
Training loss: 0.4950026580951106
Validation loss: 2.719579551828182

Epoch: 5| Step: 6
Training loss: 0.39999526438294003
Validation loss: 2.6248184701428214

Epoch: 5| Step: 7
Training loss: 0.4689298443703821
Validation loss: 2.678526397886657

Epoch: 5| Step: 8
Training loss: 0.4538528417527521
Validation loss: 2.7193379077092787

Epoch: 5| Step: 9
Training loss: 0.44047124966835344
Validation loss: 2.7010871191696055

Epoch: 5| Step: 10
Training loss: 0.3351358340787635
Validation loss: 2.6520083013520175

Epoch: 5| Step: 11
Training loss: 0.3217626403320429
Validation loss: 2.634275329985039

Epoch: 341| Step: 0
Training loss: 0.3328023371689484
Validation loss: 2.7358189285353034

Epoch: 5| Step: 1
Training loss: 0.3778111077118139
Validation loss: 2.7749694103697164

Epoch: 5| Step: 2
Training loss: 0.2601883825442475
Validation loss: 2.7340586433873235

Epoch: 5| Step: 3
Training loss: 0.34757348479150774
Validation loss: 2.6931779379402734

Epoch: 5| Step: 4
Training loss: 0.5988953405233071
Validation loss: 2.767390896088992

Epoch: 5| Step: 5
Training loss: 0.3409677749394692
Validation loss: 2.7263686685972357

Epoch: 5| Step: 6
Training loss: 0.42008871268405173
Validation loss: 2.767122527755697

Epoch: 5| Step: 7
Training loss: 0.366162920029065
Validation loss: 2.684487380523824

Epoch: 5| Step: 8
Training loss: 0.28398789163587074
Validation loss: 2.7932970365356415

Epoch: 5| Step: 9
Training loss: 0.3946802971938512
Validation loss: 2.716469509824291

Epoch: 5| Step: 10
Training loss: 0.35091062084468444
Validation loss: 2.716144570301283

Epoch: 5| Step: 11
Training loss: 0.4414014900423489
Validation loss: 2.697730490006076

Epoch: 342| Step: 0
Training loss: 0.31190620273918035
Validation loss: 2.79099508055059

Epoch: 5| Step: 1
Training loss: 0.2810976622533467
Validation loss: 2.7956279695322963

Epoch: 5| Step: 2
Training loss: 0.43813111560814194
Validation loss: 2.7109179134192676

Epoch: 5| Step: 3
Training loss: 0.37970929730802033
Validation loss: 2.7690339101464843

Epoch: 5| Step: 4
Training loss: 0.2903440394069078
Validation loss: 2.832904188296311

Epoch: 5| Step: 5
Training loss: 0.40988775275221656
Validation loss: 2.730418749175453

Epoch: 5| Step: 6
Training loss: 0.4143400701412214
Validation loss: 2.722240396171896

Epoch: 5| Step: 7
Training loss: 0.3514730763617224
Validation loss: 2.7703746521173045

Epoch: 5| Step: 8
Training loss: 0.5181133166331515
Validation loss: 2.780392046552198

Epoch: 5| Step: 9
Training loss: 0.463687613010457
Validation loss: 2.7270664962547984

Epoch: 5| Step: 10
Training loss: 0.2856206639417741
Validation loss: 2.739893856991768

Epoch: 5| Step: 11
Training loss: 0.39380942304989586
Validation loss: 2.7275586280617246

Epoch: 343| Step: 0
Training loss: 0.44571202743158167
Validation loss: 2.836178362157279

Epoch: 5| Step: 1
Training loss: 0.46139778173357393
Validation loss: 2.8302694553930494

Epoch: 5| Step: 2
Training loss: 0.5532044208211366
Validation loss: 2.788312959085449

Epoch: 5| Step: 3
Training loss: 0.3436552480676262
Validation loss: 2.797505866991424

Epoch: 5| Step: 4
Training loss: 0.2622637128035829
Validation loss: 2.7380803969180447

Epoch: 5| Step: 5
Training loss: 0.33817677150876246
Validation loss: 2.7567372067364126

Epoch: 5| Step: 6
Training loss: 0.3452823254619183
Validation loss: 2.710911544543631

Epoch: 5| Step: 7
Training loss: 0.37631380883486437
Validation loss: 2.769884037707463

Epoch: 5| Step: 8
Training loss: 0.2957232242944345
Validation loss: 2.7947728090411905

Epoch: 5| Step: 9
Training loss: 0.35628669031167154
Validation loss: 2.7926267579024207

Epoch: 5| Step: 10
Training loss: 0.3464139537789171
Validation loss: 2.8593148779324253

Epoch: 5| Step: 11
Training loss: 0.15536907537601116
Validation loss: 2.7832944281699086

Epoch: 344| Step: 0
Training loss: 0.45165590026499863
Validation loss: 2.8212406571988065

Epoch: 5| Step: 1
Training loss: 0.29823619834017556
Validation loss: 2.8051743399204394

Epoch: 5| Step: 2
Training loss: 0.3948443652722992
Validation loss: 2.7550452688286144

Epoch: 5| Step: 3
Training loss: 0.34270004834457785
Validation loss: 2.720756740183276

Epoch: 5| Step: 4
Training loss: 0.33433133223417466
Validation loss: 2.7632800108612305

Epoch: 5| Step: 5
Training loss: 0.4139248061205753
Validation loss: 2.7016894547311128

Epoch: 5| Step: 6
Training loss: 0.6951089196652649
Validation loss: 2.8010358885316182

Epoch: 5| Step: 7
Training loss: 0.2562526127054022
Validation loss: 2.8076069088070454

Epoch: 5| Step: 8
Training loss: 0.3148118218260703
Validation loss: 2.7375544491815096

Epoch: 5| Step: 9
Training loss: 0.3329867806603033
Validation loss: 2.80001922484451

Epoch: 5| Step: 10
Training loss: 0.33342445017296
Validation loss: 2.790445456828842

Epoch: 5| Step: 11
Training loss: 0.39531009582874066
Validation loss: 2.7745436598181277

Epoch: 345| Step: 0
Training loss: 0.3580440463362845
Validation loss: 2.771709444649123

Epoch: 5| Step: 1
Training loss: 0.33309439822734327
Validation loss: 2.6688948923246016

Epoch: 5| Step: 2
Training loss: 0.3715021997581754
Validation loss: 2.7912478536098466

Epoch: 5| Step: 3
Training loss: 0.30360832811537997
Validation loss: 2.703793466929625

Epoch: 5| Step: 4
Training loss: 0.41678406929000156
Validation loss: 2.7075401807570314

Epoch: 5| Step: 5
Training loss: 0.6963452160035812
Validation loss: 2.70500128644935

Epoch: 5| Step: 6
Training loss: 0.3190544941352638
Validation loss: 2.6751385327591293

Epoch: 5| Step: 7
Training loss: 0.2963443078455491
Validation loss: 2.6984552369954917

Epoch: 5| Step: 8
Training loss: 0.3328488997133649
Validation loss: 2.7712072081955004

Epoch: 5| Step: 9
Training loss: 0.31783568716844557
Validation loss: 2.7478560991724503

Epoch: 5| Step: 10
Training loss: 0.32756381637943427
Validation loss: 2.733241491160693

Epoch: 5| Step: 11
Training loss: 0.2318524750850546
Validation loss: 2.7781924181990445

Epoch: 346| Step: 0
Training loss: 0.2830881608907545
Validation loss: 2.671624553014942

Epoch: 5| Step: 1
Training loss: 0.48942471701099455
Validation loss: 2.704077312176599

Epoch: 5| Step: 2
Training loss: 0.49883663914045306
Validation loss: 2.7455863827598246

Epoch: 5| Step: 3
Training loss: 0.27845635017439624
Validation loss: 2.7112921703559536

Epoch: 5| Step: 4
Training loss: 0.3189841499673506
Validation loss: 2.7064880993171108

Epoch: 5| Step: 5
Training loss: 0.3506929239653474
Validation loss: 2.7756675816474847

Epoch: 5| Step: 6
Training loss: 0.30950006355799575
Validation loss: 2.727214651440707

Epoch: 5| Step: 7
Training loss: 0.2477313009195867
Validation loss: 2.7640012798642197

Epoch: 5| Step: 8
Training loss: 0.31714738770710665
Validation loss: 2.7520820221090454

Epoch: 5| Step: 9
Training loss: 0.2508170812327678
Validation loss: 2.6766408091927567

Epoch: 5| Step: 10
Training loss: 0.4312049600328751
Validation loss: 2.7768081205769777

Epoch: 5| Step: 11
Training loss: 0.38632054490231293
Validation loss: 2.7383426037207936

Epoch: 347| Step: 0
Training loss: 0.5026143687370715
Validation loss: 2.7236959769902245

Epoch: 5| Step: 1
Training loss: 0.30635222461080125
Validation loss: 2.700444161857296

Epoch: 5| Step: 2
Training loss: 0.3917075035267131
Validation loss: 2.7380851352497366

Epoch: 5| Step: 3
Training loss: 0.3494162212409624
Validation loss: 2.7287431647983555

Epoch: 5| Step: 4
Training loss: 0.332414047382147
Validation loss: 2.8007702155540946

Epoch: 5| Step: 5
Training loss: 0.42412314277240043
Validation loss: 2.7945435145927213

Epoch: 5| Step: 6
Training loss: 0.3381372885489419
Validation loss: 2.761018080543821

Epoch: 5| Step: 7
Training loss: 0.5505596283157776
Validation loss: 2.7744379433062107

Epoch: 5| Step: 8
Training loss: 0.4260291331654202
Validation loss: 2.815088846669018

Epoch: 5| Step: 9
Training loss: 0.33848454531475286
Validation loss: 2.765856190804714

Epoch: 5| Step: 10
Training loss: 0.2681251697717587
Validation loss: 2.7376124988879704

Epoch: 5| Step: 11
Training loss: 0.04023313300521279
Validation loss: 2.7311909656851703

Epoch: 348| Step: 0
Training loss: 0.436387111190881
Validation loss: 2.728298345173282

Epoch: 5| Step: 1
Training loss: 0.3471638267473882
Validation loss: 2.698574616807194

Epoch: 5| Step: 2
Training loss: 0.36928640242209704
Validation loss: 2.7429731100437618

Epoch: 5| Step: 3
Training loss: 0.33899760965753617
Validation loss: 2.733205556111974

Epoch: 5| Step: 4
Training loss: 0.31771119955468874
Validation loss: 2.7198443055705215

Epoch: 5| Step: 5
Training loss: 0.3333029236432665
Validation loss: 2.7611082590200566

Epoch: 5| Step: 6
Training loss: 0.2955074685971515
Validation loss: 2.7821122879441984

Epoch: 5| Step: 7
Training loss: 0.2369283195413599
Validation loss: 2.7411678733473575

Epoch: 5| Step: 8
Training loss: 0.2952882877899527
Validation loss: 2.6907857872700394

Epoch: 5| Step: 9
Training loss: 0.33663421286573403
Validation loss: 2.749643710926825

Epoch: 5| Step: 10
Training loss: 0.5933404815257526
Validation loss: 2.7460287745726175

Epoch: 5| Step: 11
Training loss: 0.1406575933407952
Validation loss: 2.7335345020979944

Epoch: 349| Step: 0
Training loss: 0.42227129513359285
Validation loss: 2.7263821612364856

Epoch: 5| Step: 1
Training loss: 0.37019244714690486
Validation loss: 2.7332536886889254

Epoch: 5| Step: 2
Training loss: 0.265205051334887
Validation loss: 2.711267757178817

Epoch: 5| Step: 3
Training loss: 0.30562652259868645
Validation loss: 2.7029855100476428

Epoch: 5| Step: 4
Training loss: 0.5883235921224403
Validation loss: 2.715802077975528

Epoch: 5| Step: 5
Training loss: 0.36261692627759007
Validation loss: 2.783056793827732

Epoch: 5| Step: 6
Training loss: 0.3279989318263292
Validation loss: 2.7590338044210494

Epoch: 5| Step: 7
Training loss: 0.30595369601996375
Validation loss: 2.7323969889178534

Epoch: 5| Step: 8
Training loss: 0.4119368820417304
Validation loss: 2.7368468637668792

Epoch: 5| Step: 9
Training loss: 0.25584702789566355
Validation loss: 2.718762971401329

Epoch: 5| Step: 10
Training loss: 0.24269946652425692
Validation loss: 2.7465584381220474

Epoch: 5| Step: 11
Training loss: 0.19681380244163604
Validation loss: 2.7337445758509364

Epoch: 350| Step: 0
Training loss: 0.41589378757767
Validation loss: 2.7788361707932308

Epoch: 5| Step: 1
Training loss: 0.28229887408853926
Validation loss: 2.680658826145415

Epoch: 5| Step: 2
Training loss: 0.3202456893094757
Validation loss: 2.6323504471691317

Epoch: 5| Step: 3
Training loss: 0.28680507597268695
Validation loss: 2.755271122486792

Epoch: 5| Step: 4
Training loss: 0.564752360821535
Validation loss: 2.7369170842750323

Epoch: 5| Step: 5
Training loss: 0.38739109354725904
Validation loss: 2.761756526215645

Epoch: 5| Step: 6
Training loss: 0.4229075546723722
Validation loss: 2.741320430397617

Epoch: 5| Step: 7
Training loss: 0.27826537543741925
Validation loss: 2.749196289121067

Epoch: 5| Step: 8
Training loss: 0.2802180989890578
Validation loss: 2.73314448870679

Epoch: 5| Step: 9
Training loss: 0.3121926942456208
Validation loss: 2.7083412439279693

Epoch: 5| Step: 10
Training loss: 0.4188764110895452
Validation loss: 2.733970877438807

Epoch: 5| Step: 11
Training loss: 0.30099369572139734
Validation loss: 2.696406683220952

Epoch: 351| Step: 0
Training loss: 0.35095932397555785
Validation loss: 2.691737349785781

Epoch: 5| Step: 1
Training loss: 0.36995518342083605
Validation loss: 2.6993800444930103

Epoch: 5| Step: 2
Training loss: 0.2924391983286196
Validation loss: 2.8170643538875875

Epoch: 5| Step: 3
Training loss: 0.31631131572912485
Validation loss: 2.723787288996995

Epoch: 5| Step: 4
Training loss: 0.45435754267595535
Validation loss: 2.859792612844082

Epoch: 5| Step: 5
Training loss: 0.32045333371403695
Validation loss: 2.7658181994067133

Epoch: 5| Step: 6
Training loss: 0.5445433638551085
Validation loss: 2.7391273762138715

Epoch: 5| Step: 7
Training loss: 0.3384009570138387
Validation loss: 2.762822122766002

Epoch: 5| Step: 8
Training loss: 0.48585301673704767
Validation loss: 2.7209154362483314

Epoch: 5| Step: 9
Training loss: 0.5149574003841072
Validation loss: 2.7094443530512518

Epoch: 5| Step: 10
Training loss: 0.2544257644546253
Validation loss: 2.727965666992804

Epoch: 5| Step: 11
Training loss: 0.2764189034860144
Validation loss: 2.7514039054018777

Epoch: 352| Step: 0
Training loss: 0.42361420185580567
Validation loss: 2.8256049089477595

Epoch: 5| Step: 1
Training loss: 0.5881067430052243
Validation loss: 2.8001884035178364

Epoch: 5| Step: 2
Training loss: 0.4354850143499644
Validation loss: 2.750000292604604

Epoch: 5| Step: 3
Training loss: 0.559457977363373
Validation loss: 2.78856329987297

Epoch: 5| Step: 4
Training loss: 0.3637914049369498
Validation loss: 2.772068799915993

Epoch: 5| Step: 5
Training loss: 0.2734313282951308
Validation loss: 2.74661434081112

Epoch: 5| Step: 6
Training loss: 0.37614662980944596
Validation loss: 2.7389177280138877

Epoch: 5| Step: 7
Training loss: 0.5210575543004534
Validation loss: 2.722333975663835

Epoch: 5| Step: 8
Training loss: 0.37972158035731646
Validation loss: 2.6667796175599356

Epoch: 5| Step: 9
Training loss: 0.3497586917083507
Validation loss: 2.70968574111794

Epoch: 5| Step: 10
Training loss: 0.2743744465207576
Validation loss: 2.636481711953298

Epoch: 5| Step: 11
Training loss: 0.29255779689764594
Validation loss: 2.7582694585517125

Epoch: 353| Step: 0
Training loss: 0.476536453035548
Validation loss: 2.7530452166805923

Epoch: 5| Step: 1
Training loss: 0.8440419151284569
Validation loss: 2.8147712931826105

Epoch: 5| Step: 2
Training loss: 0.48669750479534124
Validation loss: 2.7565835982987323

Epoch: 5| Step: 3
Training loss: 0.26761607437002516
Validation loss: 2.6533561912846766

Epoch: 5| Step: 4
Training loss: 0.41772421698047396
Validation loss: 2.6871821821792827

Epoch: 5| Step: 5
Training loss: 0.6261447912535507
Validation loss: 2.6943416007778467

Epoch: 5| Step: 6
Training loss: 0.7736433121398001
Validation loss: 2.649629851497439

Epoch: 5| Step: 7
Training loss: 0.480115109067426
Validation loss: 2.698411013751724

Epoch: 5| Step: 8
Training loss: 0.29806513399162954
Validation loss: 2.699291520856033

Epoch: 5| Step: 9
Training loss: 0.40451821428132073
Validation loss: 2.7624492191808443

Epoch: 5| Step: 10
Training loss: 0.39917414018461095
Validation loss: 2.785363808879087

Epoch: 5| Step: 11
Training loss: 0.6869986179732147
Validation loss: 2.719266173811679

Epoch: 354| Step: 0
Training loss: 0.3203191407608525
Validation loss: 2.769229804359187

Epoch: 5| Step: 1
Training loss: 0.49122207052609634
Validation loss: 2.72543495276675

Epoch: 5| Step: 2
Training loss: 0.5163093129645991
Validation loss: 2.660583954651983

Epoch: 5| Step: 3
Training loss: 0.39606192120459655
Validation loss: 2.706468829234283

Epoch: 5| Step: 4
Training loss: 0.4019824507593088
Validation loss: 2.689655118147303

Epoch: 5| Step: 5
Training loss: 0.3232980201652606
Validation loss: 2.6832562881766155

Epoch: 5| Step: 6
Training loss: 0.4365465640229391
Validation loss: 2.7329762505163457

Epoch: 5| Step: 7
Training loss: 0.3784304315299071
Validation loss: 2.7586343097324844

Epoch: 5| Step: 8
Training loss: 0.4277102668273797
Validation loss: 2.6898424969737733

Epoch: 5| Step: 9
Training loss: 0.4407727075105318
Validation loss: 2.7151604520280026

Epoch: 5| Step: 10
Training loss: 0.548587787175293
Validation loss: 2.701380326508913

Epoch: 5| Step: 11
Training loss: 0.39297135429960295
Validation loss: 2.709008904098282

Epoch: 355| Step: 0
Training loss: 0.24587700396653472
Validation loss: 2.7236184253953213

Epoch: 5| Step: 1
Training loss: 0.4410529790690978
Validation loss: 2.699674156624934

Epoch: 5| Step: 2
Training loss: 0.2982453791379496
Validation loss: 2.7694697693823533

Epoch: 5| Step: 3
Training loss: 0.5287966740075835
Validation loss: 2.7474402341222826

Epoch: 5| Step: 4
Training loss: 0.2739073395258576
Validation loss: 2.7151392421411806

Epoch: 5| Step: 5
Training loss: 0.32167946653931745
Validation loss: 2.777737624884846

Epoch: 5| Step: 6
Training loss: 0.41728364643776344
Validation loss: 2.762410837492309

Epoch: 5| Step: 7
Training loss: 0.3638838006085272
Validation loss: 2.791067515790246

Epoch: 5| Step: 8
Training loss: 0.2648260780222502
Validation loss: 2.7444208402547394

Epoch: 5| Step: 9
Training loss: 0.3332093263968029
Validation loss: 2.7600219906256838

Epoch: 5| Step: 10
Training loss: 0.3769570385033048
Validation loss: 2.692665801951364

Epoch: 5| Step: 11
Training loss: 0.3988476493457734
Validation loss: 2.7734287494646743

Epoch: 356| Step: 0
Training loss: 0.41228611487296546
Validation loss: 2.7623157674250782

Epoch: 5| Step: 1
Training loss: 0.533870907652829
Validation loss: 2.8234923234439697

Epoch: 5| Step: 2
Training loss: 0.20247546294574256
Validation loss: 2.754215214128786

Epoch: 5| Step: 3
Training loss: 0.40833017662670634
Validation loss: 2.788373176311327

Epoch: 5| Step: 4
Training loss: 0.2801037982788349
Validation loss: 2.8141005094631097

Epoch: 5| Step: 5
Training loss: 0.3268309005836106
Validation loss: 2.7553249807970346

Epoch: 5| Step: 6
Training loss: 0.3528283958131628
Validation loss: 2.7595649568891543

Epoch: 5| Step: 7
Training loss: 0.32004452172149683
Validation loss: 2.710992968282207

Epoch: 5| Step: 8
Training loss: 0.35942624597470785
Validation loss: 2.82160239340991

Epoch: 5| Step: 9
Training loss: 0.28310222801519563
Validation loss: 2.7972530130848625

Epoch: 5| Step: 10
Training loss: 0.37472699082110605
Validation loss: 2.770540864944734

Epoch: 5| Step: 11
Training loss: 0.42840243559852
Validation loss: 2.7981821518407295

Epoch: 357| Step: 0
Training loss: 0.22729720002865264
Validation loss: 2.790491252853791

Epoch: 5| Step: 1
Training loss: 0.18510132550399203
Validation loss: 2.7820583126155523

Epoch: 5| Step: 2
Training loss: 0.3665476357453632
Validation loss: 2.715702822952544

Epoch: 5| Step: 3
Training loss: 0.4889878919931762
Validation loss: 2.7802547181310695

Epoch: 5| Step: 4
Training loss: 0.22729061954413265
Validation loss: 2.75388564875407

Epoch: 5| Step: 5
Training loss: 0.2758961359905897
Validation loss: 2.707690299553421

Epoch: 5| Step: 6
Training loss: 0.40653644146926443
Validation loss: 2.7438829294211526

Epoch: 5| Step: 7
Training loss: 0.29532498479620445
Validation loss: 2.8355579875415264

Epoch: 5| Step: 8
Training loss: 0.48147304369931454
Validation loss: 2.809029677528857

Epoch: 5| Step: 9
Training loss: 0.4653663262361472
Validation loss: 2.745170029120646

Epoch: 5| Step: 10
Training loss: 0.3211273435668246
Validation loss: 2.6756048362475315

Epoch: 5| Step: 11
Training loss: 0.3315385865945783
Validation loss: 2.74932436157083

Epoch: 358| Step: 0
Training loss: 0.31798955582165933
Validation loss: 2.7134640670975947

Epoch: 5| Step: 1
Training loss: 0.24280573782716217
Validation loss: 2.6927391760047836

Epoch: 5| Step: 2
Training loss: 0.4905619343844159
Validation loss: 2.73866556239694

Epoch: 5| Step: 3
Training loss: 0.3784133418630948
Validation loss: 2.702320795107835

Epoch: 5| Step: 4
Training loss: 0.40608565967892085
Validation loss: 2.781500008593983

Epoch: 5| Step: 5
Training loss: 0.5193922674381994
Validation loss: 2.726824273310775

Epoch: 5| Step: 6
Training loss: 0.32612785453468257
Validation loss: 2.7479662346773712

Epoch: 5| Step: 7
Training loss: 0.4840528893794231
Validation loss: 2.712872656407273

Epoch: 5| Step: 8
Training loss: 0.44474031262089103
Validation loss: 2.7133377893094566

Epoch: 5| Step: 9
Training loss: 0.39211659797419995
Validation loss: 2.8146784646094027

Epoch: 5| Step: 10
Training loss: 0.2681544425111248
Validation loss: 2.7477990106223844

Epoch: 5| Step: 11
Training loss: 0.32932086282516293
Validation loss: 2.71307176901114

Epoch: 359| Step: 0
Training loss: 0.36494422035673685
Validation loss: 2.717405915069001

Epoch: 5| Step: 1
Training loss: 0.33240502580376213
Validation loss: 2.696590669686482

Epoch: 5| Step: 2
Training loss: 0.5451965460148704
Validation loss: 2.683397214634592

Epoch: 5| Step: 3
Training loss: 0.21522251034139772
Validation loss: 2.7038987582959986

Epoch: 5| Step: 4
Training loss: 0.4040305877793419
Validation loss: 2.7379951926231674

Epoch: 5| Step: 5
Training loss: 0.37693940765247286
Validation loss: 2.704435971422548

Epoch: 5| Step: 6
Training loss: 0.3435920872806357
Validation loss: 2.7687893345882566

Epoch: 5| Step: 7
Training loss: 0.3086217553673872
Validation loss: 2.7642782491895534

Epoch: 5| Step: 8
Training loss: 0.5117299901295644
Validation loss: 2.701155597438207

Epoch: 5| Step: 9
Training loss: 0.25309067834887644
Validation loss: 2.676695217888443

Epoch: 5| Step: 10
Training loss: 0.3460111592689988
Validation loss: 2.6768698044360657

Epoch: 5| Step: 11
Training loss: 0.21497502217914294
Validation loss: 2.7268947628405873

Epoch: 360| Step: 0
Training loss: 0.3572056225562165
Validation loss: 2.732809937673843

Epoch: 5| Step: 1
Training loss: 0.27941557222649355
Validation loss: 2.696284479148623

Epoch: 5| Step: 2
Training loss: 0.43079625045123976
Validation loss: 2.766059810775922

Epoch: 5| Step: 3
Training loss: 0.3013131899862375
Validation loss: 2.6783003594976558

Epoch: 5| Step: 4
Training loss: 0.5455554300812221
Validation loss: 2.7204415295314317

Epoch: 5| Step: 5
Training loss: 0.30623209521444844
Validation loss: 2.7559583769168774

Epoch: 5| Step: 6
Training loss: 0.2488002450076657
Validation loss: 2.7533477541539715

Epoch: 5| Step: 7
Training loss: 0.22020238430867928
Validation loss: 2.7427802790096227

Epoch: 5| Step: 8
Training loss: 0.35146225453721724
Validation loss: 2.745667313683073

Epoch: 5| Step: 9
Training loss: 0.33344953220327184
Validation loss: 2.7786362685682757

Epoch: 5| Step: 10
Training loss: 0.44889368652438477
Validation loss: 2.722220952953856

Epoch: 5| Step: 11
Training loss: 0.4334355314797253
Validation loss: 2.7654227992852856

Epoch: 361| Step: 0
Training loss: 0.5324782869899946
Validation loss: 2.7141830555186104

Epoch: 5| Step: 1
Training loss: 0.3470477984011096
Validation loss: 2.7468138320876685

Epoch: 5| Step: 2
Training loss: 0.30763054470550966
Validation loss: 2.7320130201150943

Epoch: 5| Step: 3
Training loss: 0.32586845401763714
Validation loss: 2.707143407849578

Epoch: 5| Step: 4
Training loss: 0.3288146672992233
Validation loss: 2.7596541173193976

Epoch: 5| Step: 5
Training loss: 0.2444952639709084
Validation loss: 2.7506319930942533

Epoch: 5| Step: 6
Training loss: 0.21752762713578172
Validation loss: 2.752856862220309

Epoch: 5| Step: 7
Training loss: 0.2938412453588194
Validation loss: 2.762459964375783

Epoch: 5| Step: 8
Training loss: 0.267101517723803
Validation loss: 2.7330037884135208

Epoch: 5| Step: 9
Training loss: 0.3732634509870144
Validation loss: 2.7706178363856884

Epoch: 5| Step: 10
Training loss: 0.28160668643475906
Validation loss: 2.713304019901634

Epoch: 5| Step: 11
Training loss: 0.24280478657925092
Validation loss: 2.724666479097955

Epoch: 362| Step: 0
Training loss: 0.544229539342052
Validation loss: 2.739203660036439

Epoch: 5| Step: 1
Training loss: 0.3412541904122314
Validation loss: 2.766491723609723

Epoch: 5| Step: 2
Training loss: 0.38114364969872655
Validation loss: 2.7361300458242153

Epoch: 5| Step: 3
Training loss: 0.27659734840452976
Validation loss: 2.739992946322149

Epoch: 5| Step: 4
Training loss: 0.31922862965162446
Validation loss: 2.7361461570730743

Epoch: 5| Step: 5
Training loss: 0.36037238249554254
Validation loss: 2.6899446192078402

Epoch: 5| Step: 6
Training loss: 0.41588751741219915
Validation loss: 2.681431602190868

Epoch: 5| Step: 7
Training loss: 0.2510832029357717
Validation loss: 2.721146137858785

Epoch: 5| Step: 8
Training loss: 0.3643388427932646
Validation loss: 2.7574943812875925

Epoch: 5| Step: 9
Training loss: 0.3926780915020404
Validation loss: 2.742558763011254

Epoch: 5| Step: 10
Training loss: 0.35739696395029574
Validation loss: 2.7655980635083752

Epoch: 5| Step: 11
Training loss: 0.492390636123184
Validation loss: 2.696540812476885

Epoch: 363| Step: 0
Training loss: 0.2607748604066548
Validation loss: 2.7313772462872827

Epoch: 5| Step: 1
Training loss: 0.5097554816044376
Validation loss: 2.77307533800881

Epoch: 5| Step: 2
Training loss: 0.30175238051972764
Validation loss: 2.7152209086260974

Epoch: 5| Step: 3
Training loss: 0.26935445820047166
Validation loss: 2.767920606371949

Epoch: 5| Step: 4
Training loss: 0.3583895398940243
Validation loss: 2.7160122376184046

Epoch: 5| Step: 5
Training loss: 0.3079476413237604
Validation loss: 2.686580872277092

Epoch: 5| Step: 6
Training loss: 0.2884852858085161
Validation loss: 2.770423913885873

Epoch: 5| Step: 7
Training loss: 0.5230089112592993
Validation loss: 2.706329397838453

Epoch: 5| Step: 8
Training loss: 0.24330529550438978
Validation loss: 2.7193030638880105

Epoch: 5| Step: 9
Training loss: 0.38527806040730495
Validation loss: 2.668957042703209

Epoch: 5| Step: 10
Training loss: 0.3729198898765743
Validation loss: 2.7204410694231616

Epoch: 5| Step: 11
Training loss: 0.22197406397455793
Validation loss: 2.7618837860306065

Epoch: 364| Step: 0
Training loss: 0.34601419537701744
Validation loss: 2.7208737723532543

Epoch: 5| Step: 1
Training loss: 0.3896970407867452
Validation loss: 2.7231201623140104

Epoch: 5| Step: 2
Training loss: 0.36287715956688876
Validation loss: 2.74655822291475

Epoch: 5| Step: 3
Training loss: 0.23022001389319263
Validation loss: 2.6967932535853705

Epoch: 5| Step: 4
Training loss: 0.33637239339847
Validation loss: 2.71243923561606

Epoch: 5| Step: 5
Training loss: 0.21763235919512305
Validation loss: 2.685122373380368

Epoch: 5| Step: 6
Training loss: 0.3154896894612574
Validation loss: 2.6852829164195153

Epoch: 5| Step: 7
Training loss: 0.22430364284316626
Validation loss: 2.701460217256336

Epoch: 5| Step: 8
Training loss: 0.3248429895734304
Validation loss: 2.757102388592156

Epoch: 5| Step: 9
Training loss: 0.5600658572589828
Validation loss: 2.7509124499221227

Epoch: 5| Step: 10
Training loss: 0.2772613053618178
Validation loss: 2.6905055649818044

Epoch: 5| Step: 11
Training loss: 0.16907422434050604
Validation loss: 2.744702224914901

Epoch: 365| Step: 0
Training loss: 0.36524575771607093
Validation loss: 2.7276595166801147

Epoch: 5| Step: 1
Training loss: 0.42163746822547393
Validation loss: 2.7393587960789456

Epoch: 5| Step: 2
Training loss: 0.30105823297468226
Validation loss: 2.6985275774810566

Epoch: 5| Step: 3
Training loss: 0.40547349886603123
Validation loss: 2.688752207936176

Epoch: 5| Step: 4
Training loss: 0.5110378831717387
Validation loss: 2.7222158987162146

Epoch: 5| Step: 5
Training loss: 0.2866419665975046
Validation loss: 2.775091299640002

Epoch: 5| Step: 6
Training loss: 0.2920819275400902
Validation loss: 2.6847264982314334

Epoch: 5| Step: 7
Training loss: 0.29450999165523206
Validation loss: 2.7562050425754787

Epoch: 5| Step: 8
Training loss: 0.2301630077289336
Validation loss: 2.7331065260208054

Epoch: 5| Step: 9
Training loss: 0.41416096866008983
Validation loss: 2.7370188256804355

Epoch: 5| Step: 10
Training loss: 0.2467615814669958
Validation loss: 2.6670344938472685

Epoch: 5| Step: 11
Training loss: 0.1654694661367191
Validation loss: 2.767570003837707

Epoch: 366| Step: 0
Training loss: 0.31260466015115895
Validation loss: 2.730017432377251

Epoch: 5| Step: 1
Training loss: 0.21290590073962662
Validation loss: 2.7659750481610064

Epoch: 5| Step: 2
Training loss: 0.26596055153926673
Validation loss: 2.759296461048234

Epoch: 5| Step: 3
Training loss: 0.3035329806399152
Validation loss: 2.7130238441035104

Epoch: 5| Step: 4
Training loss: 0.3440101137913139
Validation loss: 2.771061107528202

Epoch: 5| Step: 5
Training loss: 0.28356697124229274
Validation loss: 2.7563827742171623

Epoch: 5| Step: 6
Training loss: 0.5342983971730401
Validation loss: 2.786405621086487

Epoch: 5| Step: 7
Training loss: 0.2927286944768448
Validation loss: 2.7864573089502658

Epoch: 5| Step: 8
Training loss: 0.2667169146706489
Validation loss: 2.746454160073153

Epoch: 5| Step: 9
Training loss: 0.3095519725288759
Validation loss: 2.7681522639810945

Epoch: 5| Step: 10
Training loss: 0.274881216426464
Validation loss: 2.805973958667466

Epoch: 5| Step: 11
Training loss: 0.37460174871007
Validation loss: 2.750983903897887

Epoch: 367| Step: 0
Training loss: 0.30036369669327906
Validation loss: 2.7402579428216005

Epoch: 5| Step: 1
Training loss: 0.4126800815932883
Validation loss: 2.705298989250361

Epoch: 5| Step: 2
Training loss: 0.4221324311828783
Validation loss: 2.812606993158929

Epoch: 5| Step: 3
Training loss: 0.2685898081616167
Validation loss: 2.816750623977234

Epoch: 5| Step: 4
Training loss: 0.4069757947284928
Validation loss: 2.784436186757883

Epoch: 5| Step: 5
Training loss: 0.3119167010076879
Validation loss: 2.713609058814834

Epoch: 5| Step: 6
Training loss: 0.5325535321079933
Validation loss: 2.8035819726982303

Epoch: 5| Step: 7
Training loss: 0.3993775740467393
Validation loss: 2.784051584226728

Epoch: 5| Step: 8
Training loss: 0.3548976376533082
Validation loss: 2.834642578779479

Epoch: 5| Step: 9
Training loss: 0.39803220667592676
Validation loss: 2.797829342632372

Epoch: 5| Step: 10
Training loss: 0.32150704082622306
Validation loss: 2.737816183854575

Epoch: 5| Step: 11
Training loss: 0.259770328794642
Validation loss: 2.6874560123362747

Epoch: 368| Step: 0
Training loss: 0.462374193891579
Validation loss: 2.707060750898721

Epoch: 5| Step: 1
Training loss: 0.4447643687814956
Validation loss: 2.715702963786484

Epoch: 5| Step: 2
Training loss: 0.4937621616121225
Validation loss: 2.675836459516111

Epoch: 5| Step: 3
Training loss: 0.47257570888855804
Validation loss: 2.723398615489654

Epoch: 5| Step: 4
Training loss: 0.357522043668937
Validation loss: 2.736996166395439

Epoch: 5| Step: 5
Training loss: 0.41872136815244254
Validation loss: 2.760135792291925

Epoch: 5| Step: 6
Training loss: 0.357771009846579
Validation loss: 2.755485931117953

Epoch: 5| Step: 7
Training loss: 0.3119893909279815
Validation loss: 2.779257787705281

Epoch: 5| Step: 8
Training loss: 0.2525237076554342
Validation loss: 2.7653042415093663

Epoch: 5| Step: 9
Training loss: 0.28757717661971965
Validation loss: 2.733803618541485

Epoch: 5| Step: 10
Training loss: 0.3215848610409143
Validation loss: 2.783683415961105

Epoch: 5| Step: 11
Training loss: 0.11684365691175932
Validation loss: 2.7788584174099737

Epoch: 369| Step: 0
Training loss: 0.31271474135760946
Validation loss: 2.740349344609146

Epoch: 5| Step: 1
Training loss: 0.3437471172905472
Validation loss: 2.7323986904132305

Epoch: 5| Step: 2
Training loss: 0.29401870774415023
Validation loss: 2.6946374333445733

Epoch: 5| Step: 3
Training loss: 0.29521609150543665
Validation loss: 2.7419494206757773

Epoch: 5| Step: 4
Training loss: 0.31683380767742275
Validation loss: 2.708249396466207

Epoch: 5| Step: 5
Training loss: 0.45641190386609864
Validation loss: 2.757687289355642

Epoch: 5| Step: 6
Training loss: 0.30744092220643676
Validation loss: 2.723053868949247

Epoch: 5| Step: 7
Training loss: 0.39514999215754615
Validation loss: 2.7718599014415766

Epoch: 5| Step: 8
Training loss: 0.265905162378226
Validation loss: 2.7727480143258285

Epoch: 5| Step: 9
Training loss: 0.3927582664348263
Validation loss: 2.7237403130793076

Epoch: 5| Step: 10
Training loss: 0.2777727865062086
Validation loss: 2.7655267284915324

Epoch: 5| Step: 11
Training loss: 0.1981413636534867
Validation loss: 2.74517130654211

Epoch: 370| Step: 0
Training loss: 0.49838702983703426
Validation loss: 2.804053122378892

Epoch: 5| Step: 1
Training loss: 0.3206417554712079
Validation loss: 2.759323127837923

Epoch: 5| Step: 2
Training loss: 0.2811369801305542
Validation loss: 2.7612182437031354

Epoch: 5| Step: 3
Training loss: 0.32619054820808585
Validation loss: 2.7153374165920194

Epoch: 5| Step: 4
Training loss: 0.46835090814084773
Validation loss: 2.7084617266421103

Epoch: 5| Step: 5
Training loss: 0.24601836790831375
Validation loss: 2.7490299421270734

Epoch: 5| Step: 6
Training loss: 0.291615041637157
Validation loss: 2.787875752006041

Epoch: 5| Step: 7
Training loss: 0.28416282892199324
Validation loss: 2.7569694094858117

Epoch: 5| Step: 8
Training loss: 0.30756460073366426
Validation loss: 2.735684569885865

Epoch: 5| Step: 9
Training loss: 0.22256841098077967
Validation loss: 2.7440165318569396

Epoch: 5| Step: 10
Training loss: 0.3849119885899452
Validation loss: 2.7734217611949807

Epoch: 5| Step: 11
Training loss: 0.3398261778223768
Validation loss: 2.670112950915974

Epoch: 371| Step: 0
Training loss: 0.3103006454385455
Validation loss: 2.6749028678443136

Epoch: 5| Step: 1
Training loss: 0.35027113145324607
Validation loss: 2.7291094225541404

Epoch: 5| Step: 2
Training loss: 0.2992735516236272
Validation loss: 2.769800387399026

Epoch: 5| Step: 3
Training loss: 0.30772117189360976
Validation loss: 2.7036853551257134

Epoch: 5| Step: 4
Training loss: 0.4473439277171569
Validation loss: 2.795043558794691

Epoch: 5| Step: 5
Training loss: 0.2756572271610174
Validation loss: 2.7673374126083843

Epoch: 5| Step: 6
Training loss: 0.2949380428101463
Validation loss: 2.795706165527578

Epoch: 5| Step: 7
Training loss: 0.3156670778383305
Validation loss: 2.7470724497060264

Epoch: 5| Step: 8
Training loss: 0.21776715085659049
Validation loss: 2.785540960349565

Epoch: 5| Step: 9
Training loss: 0.2735569965287432
Validation loss: 2.7233062800071832

Epoch: 5| Step: 10
Training loss: 0.2455540369987701
Validation loss: 2.7388204460015717

Epoch: 5| Step: 11
Training loss: 0.10013065724547134
Validation loss: 2.7222772459439972

Epoch: 372| Step: 0
Training loss: 0.24444948877036135
Validation loss: 2.79124301155868

Epoch: 5| Step: 1
Training loss: 0.37614991786488877
Validation loss: 2.7623710671280395

Epoch: 5| Step: 2
Training loss: 0.24640742247840144
Validation loss: 2.7465896628944897

Epoch: 5| Step: 3
Training loss: 0.5510077585653737
Validation loss: 2.794771245046975

Epoch: 5| Step: 4
Training loss: 0.4452744517886639
Validation loss: 2.7436134890961785

Epoch: 5| Step: 5
Training loss: 0.34708460411825254
Validation loss: 2.751364961631685

Epoch: 5| Step: 6
Training loss: 0.25171709463852693
Validation loss: 2.7758768377461327

Epoch: 5| Step: 7
Training loss: 0.4124851050722112
Validation loss: 2.766431191680376

Epoch: 5| Step: 8
Training loss: 0.2723185122554883
Validation loss: 2.747532572062916

Epoch: 5| Step: 9
Training loss: 0.1562711045794245
Validation loss: 2.721205431997113

Epoch: 5| Step: 10
Training loss: 0.2770926856969887
Validation loss: 2.746201648283613

Epoch: 5| Step: 11
Training loss: 0.2083281526318764
Validation loss: 2.719710750294166

Epoch: 373| Step: 0
Training loss: 0.40146706259672693
Validation loss: 2.6825842811946443

Epoch: 5| Step: 1
Training loss: 0.47856988404610373
Validation loss: 2.738785088333358

Epoch: 5| Step: 2
Training loss: 0.4674643369321405
Validation loss: 2.6798085592226255

Epoch: 5| Step: 3
Training loss: 0.29205259125739935
Validation loss: 2.768684681078137

Epoch: 5| Step: 4
Training loss: 0.22696808980693178
Validation loss: 2.6999153493338777

Epoch: 5| Step: 5
Training loss: 0.22836409541395514
Validation loss: 2.7066227181238167

Epoch: 5| Step: 6
Training loss: 0.36646420685378794
Validation loss: 2.714118952247329

Epoch: 5| Step: 7
Training loss: 0.2371224696708571
Validation loss: 2.732197670308088

Epoch: 5| Step: 8
Training loss: 0.2942466585249924
Validation loss: 2.7864176322364984

Epoch: 5| Step: 9
Training loss: 0.3952390534696546
Validation loss: 2.6973399290862017

Epoch: 5| Step: 10
Training loss: 0.36768927682372377
Validation loss: 2.7684540763393453

Epoch: 5| Step: 11
Training loss: 0.30469479918906783
Validation loss: 2.6797989061217224

Epoch: 374| Step: 0
Training loss: 0.34656514169358643
Validation loss: 2.7795148751927368

Epoch: 5| Step: 1
Training loss: 0.3230068698638178
Validation loss: 2.7824998040554805

Epoch: 5| Step: 2
Training loss: 0.4818456969647057
Validation loss: 2.6717858067250004

Epoch: 5| Step: 3
Training loss: 0.26769969433947655
Validation loss: 2.724734155128806

Epoch: 5| Step: 4
Training loss: 0.25854500832704824
Validation loss: 2.7236709747066405

Epoch: 5| Step: 5
Training loss: 0.30412505885341967
Validation loss: 2.703610044117687

Epoch: 5| Step: 6
Training loss: 0.30589338237787983
Validation loss: 2.7983013543813606

Epoch: 5| Step: 7
Training loss: 0.3621766308790226
Validation loss: 2.797422252514413

Epoch: 5| Step: 8
Training loss: 0.24230658771975758
Validation loss: 2.7464906705001897

Epoch: 5| Step: 9
Training loss: 0.48555643834879597
Validation loss: 2.7457069569527186

Epoch: 5| Step: 10
Training loss: 0.3609500453469665
Validation loss: 2.7839639188270877

Epoch: 5| Step: 11
Training loss: 0.40340576005652223
Validation loss: 2.7247634607130684

Epoch: 375| Step: 0
Training loss: 0.38515514659916983
Validation loss: 2.780459706040848

Epoch: 5| Step: 1
Training loss: 0.3248210620709539
Validation loss: 2.6731727006705666

Epoch: 5| Step: 2
Training loss: 0.2997522215025144
Validation loss: 2.6740981588645636

Epoch: 5| Step: 3
Training loss: 0.3780125963216424
Validation loss: 2.733448561898996

Epoch: 5| Step: 4
Training loss: 0.32655279108609003
Validation loss: 2.757535286533793

Epoch: 5| Step: 5
Training loss: 0.41699272352269046
Validation loss: 2.7592538987770703

Epoch: 5| Step: 6
Training loss: 0.4503271609056745
Validation loss: 2.776222662664457

Epoch: 5| Step: 7
Training loss: 0.5776476564766441
Validation loss: 2.746432428651369

Epoch: 5| Step: 8
Training loss: 0.338863405761724
Validation loss: 2.773137756053516

Epoch: 5| Step: 9
Training loss: 0.3313765072818869
Validation loss: 2.7597011298553378

Epoch: 5| Step: 10
Training loss: 0.2723069114523103
Validation loss: 2.7216934150830494

Epoch: 5| Step: 11
Training loss: 0.22344660607035505
Validation loss: 2.751241309882904

Epoch: 376| Step: 0
Training loss: 0.44785618003996813
Validation loss: 2.745451568572333

Epoch: 5| Step: 1
Training loss: 0.5391353336832428
Validation loss: 2.7230901787385986

Epoch: 5| Step: 2
Training loss: 0.1940366462710364
Validation loss: 2.769091353747382

Epoch: 5| Step: 3
Training loss: 0.2867582470664912
Validation loss: 2.737020571486537

Epoch: 5| Step: 4
Training loss: 0.34804588086535343
Validation loss: 2.744520182396761

Epoch: 5| Step: 5
Training loss: 0.4382481649222202
Validation loss: 2.7686720906728146

Epoch: 5| Step: 6
Training loss: 0.2648143740766168
Validation loss: 2.762016305536493

Epoch: 5| Step: 7
Training loss: 0.3691712624082255
Validation loss: 2.711831662688289

Epoch: 5| Step: 8
Training loss: 0.4974860380839781
Validation loss: 2.8004959436414607

Epoch: 5| Step: 9
Training loss: 0.3374992043874334
Validation loss: 2.655980055312834

Epoch: 5| Step: 10
Training loss: 0.3693245323675525
Validation loss: 2.644088129495633

Epoch: 5| Step: 11
Training loss: 0.24243416837697887
Validation loss: 2.683282089089621

Epoch: 377| Step: 0
Training loss: 0.2859637701755453
Validation loss: 2.729570644026763

Epoch: 5| Step: 1
Training loss: 0.3692172742919877
Validation loss: 2.665391845762479

Epoch: 5| Step: 2
Training loss: 0.2679087413181207
Validation loss: 2.7046686516716023

Epoch: 5| Step: 3
Training loss: 0.4810233598080716
Validation loss: 2.6798770603940856

Epoch: 5| Step: 4
Training loss: 0.3778625546941409
Validation loss: 2.6557953800780787

Epoch: 5| Step: 5
Training loss: 0.31171158039003105
Validation loss: 2.6878815461419223

Epoch: 5| Step: 6
Training loss: 0.3604908288974275
Validation loss: 2.7185821627554425

Epoch: 5| Step: 7
Training loss: 0.3246460592058626
Validation loss: 2.6913512399160995

Epoch: 5| Step: 8
Training loss: 0.3809023319374303
Validation loss: 2.7103206837924687

Epoch: 5| Step: 9
Training loss: 0.2552476807189098
Validation loss: 2.61898071195344

Epoch: 5| Step: 10
Training loss: 0.4155629161844681
Validation loss: 2.665061524714583

Epoch: 5| Step: 11
Training loss: 0.296556502704657
Validation loss: 2.7226838156546607

Epoch: 378| Step: 0
Training loss: 0.3652071611190121
Validation loss: 2.6943544279106737

Epoch: 5| Step: 1
Training loss: 0.25696473463953334
Validation loss: 2.7517372301154897

Epoch: 5| Step: 2
Training loss: 0.2910935726359754
Validation loss: 2.6895709818805855

Epoch: 5| Step: 3
Training loss: 0.2726503486322566
Validation loss: 2.737302277738935

Epoch: 5| Step: 4
Training loss: 0.23853690862421914
Validation loss: 2.7116000806815586

Epoch: 5| Step: 5
Training loss: 0.3360876368876034
Validation loss: 2.739562256928996

Epoch: 5| Step: 6
Training loss: 0.31962500038639285
Validation loss: 2.7152492631996052

Epoch: 5| Step: 7
Training loss: 0.20312834700247756
Validation loss: 2.7032361715164104

Epoch: 5| Step: 8
Training loss: 0.4523464782579861
Validation loss: 2.720823673700435

Epoch: 5| Step: 9
Training loss: 0.35471742478560764
Validation loss: 2.686601055969477

Epoch: 5| Step: 10
Training loss: 0.3528003728047713
Validation loss: 2.731129513140879

Epoch: 5| Step: 11
Training loss: 0.36048551721355954
Validation loss: 2.7179800949452013

Epoch: 379| Step: 0
Training loss: 0.35604725388945235
Validation loss: 2.7803669860058466

Epoch: 5| Step: 1
Training loss: 0.3308249382464077
Validation loss: 2.761325245205159

Epoch: 5| Step: 2
Training loss: 0.33813580123797865
Validation loss: 2.7540533527017623

Epoch: 5| Step: 3
Training loss: 0.26721018533160534
Validation loss: 2.654829041627724

Epoch: 5| Step: 4
Training loss: 0.29494895558098766
Validation loss: 2.6394444597459668

Epoch: 5| Step: 5
Training loss: 0.27774749166899415
Validation loss: 2.6430367041111715

Epoch: 5| Step: 6
Training loss: 0.41871597664241517
Validation loss: 2.6464610775605992

Epoch: 5| Step: 7
Training loss: 0.21036078061845015
Validation loss: 2.7110333128019466

Epoch: 5| Step: 8
Training loss: 0.38952485612930626
Validation loss: 2.738841555922342

Epoch: 5| Step: 9
Training loss: 0.2537548787723811
Validation loss: 2.754331187116244

Epoch: 5| Step: 10
Training loss: 0.23450728497952764
Validation loss: 2.711038809284051

Epoch: 5| Step: 11
Training loss: 0.8450341871783369
Validation loss: 2.7645816918439863

Epoch: 380| Step: 0
Training loss: 0.42141129476195943
Validation loss: 2.80604578066648

Epoch: 5| Step: 1
Training loss: 0.3481796803326454
Validation loss: 2.7453273392842377

Epoch: 5| Step: 2
Training loss: 0.3259169216005451
Validation loss: 2.7540006256165137

Epoch: 5| Step: 3
Training loss: 0.3145375819547192
Validation loss: 2.740120499071643

Epoch: 5| Step: 4
Training loss: 0.3365199562109657
Validation loss: 2.7611061686570286

Epoch: 5| Step: 5
Training loss: 0.37645568044868066
Validation loss: 2.71240865052569

Epoch: 5| Step: 6
Training loss: 0.3440699930267296
Validation loss: 2.712815520105408

Epoch: 5| Step: 7
Training loss: 0.3877626067595656
Validation loss: 2.7704000325439133

Epoch: 5| Step: 8
Training loss: 0.23222717175993313
Validation loss: 2.7274052721083706

Epoch: 5| Step: 9
Training loss: 0.3392036812069709
Validation loss: 2.692261388838137

Epoch: 5| Step: 10
Training loss: 0.2769021696231977
Validation loss: 2.767767986496555

Epoch: 5| Step: 11
Training loss: 0.22191544318646772
Validation loss: 2.7248164454884964

Epoch: 381| Step: 0
Training loss: 0.32810483598060525
Validation loss: 2.6682730818130502

Epoch: 5| Step: 1
Training loss: 0.31312829276693044
Validation loss: 2.710952707444043

Epoch: 5| Step: 2
Training loss: 0.33818935132722827
Validation loss: 2.769403649292936

Epoch: 5| Step: 3
Training loss: 0.2591101903239497
Validation loss: 2.7242878130498362

Epoch: 5| Step: 4
Training loss: 0.3024342187181993
Validation loss: 2.705183527943769

Epoch: 5| Step: 5
Training loss: 0.31092178458366765
Validation loss: 2.7938949827540864

Epoch: 5| Step: 6
Training loss: 0.3340609836276318
Validation loss: 2.7505173088233663

Epoch: 5| Step: 7
Training loss: 0.39342350820518046
Validation loss: 2.7794632047635606

Epoch: 5| Step: 8
Training loss: 0.2867976462100017
Validation loss: 2.746882025717299

Epoch: 5| Step: 9
Training loss: 0.48665684387449065
Validation loss: 2.7369013314593142

Epoch: 5| Step: 10
Training loss: 0.2325774641735567
Validation loss: 2.750282150301638

Epoch: 5| Step: 11
Training loss: 0.05345916693605641
Validation loss: 2.753873571468025

Epoch: 382| Step: 0
Training loss: 0.3592950068469003
Validation loss: 2.7652400156520334

Epoch: 5| Step: 1
Training loss: 0.33887169474921464
Validation loss: 2.6963139907843283

Epoch: 5| Step: 2
Training loss: 0.4255491901724811
Validation loss: 2.734431916507362

Epoch: 5| Step: 3
Training loss: 0.2630845345259359
Validation loss: 2.8009986739844956

Epoch: 5| Step: 4
Training loss: 0.3041790608053878
Validation loss: 2.70291588182018

Epoch: 5| Step: 5
Training loss: 0.3412718091360476
Validation loss: 2.6903443698544036

Epoch: 5| Step: 6
Training loss: 0.49717673790563166
Validation loss: 2.6692738466323345

Epoch: 5| Step: 7
Training loss: 0.2808997967405592
Validation loss: 2.7645361493608647

Epoch: 5| Step: 8
Training loss: 0.2647549460636173
Validation loss: 2.7001729586034093

Epoch: 5| Step: 9
Training loss: 0.25067234526758153
Validation loss: 2.7297743504170624

Epoch: 5| Step: 10
Training loss: 0.41477597144510175
Validation loss: 2.7284634183978587

Epoch: 5| Step: 11
Training loss: 0.3227929396117774
Validation loss: 2.7258331686031703

Epoch: 383| Step: 0
Training loss: 0.36012386995672524
Validation loss: 2.7746640712297257

Epoch: 5| Step: 1
Training loss: 0.227721963482072
Validation loss: 2.7339265401113115

Epoch: 5| Step: 2
Training loss: 0.2775757450610495
Validation loss: 2.8001206424528746

Epoch: 5| Step: 3
Training loss: 0.4605735538122658
Validation loss: 2.7089812139608638

Epoch: 5| Step: 4
Training loss: 0.41023406244315813
Validation loss: 2.724299157278527

Epoch: 5| Step: 5
Training loss: 0.4755196025730792
Validation loss: 2.7654297610692247

Epoch: 5| Step: 6
Training loss: 0.38213137931228197
Validation loss: 2.828499352985596

Epoch: 5| Step: 7
Training loss: 0.26943876918953047
Validation loss: 2.744481676658231

Epoch: 5| Step: 8
Training loss: 0.49284648678891524
Validation loss: 2.792836027393095

Epoch: 5| Step: 9
Training loss: 0.41798550581100863
Validation loss: 2.835526537302229

Epoch: 5| Step: 10
Training loss: 0.36342486752362474
Validation loss: 2.727298294806086

Epoch: 5| Step: 11
Training loss: 0.07447113241642063
Validation loss: 2.777042163296642

Epoch: 384| Step: 0
Training loss: 0.287304182849599
Validation loss: 2.780307267106817

Epoch: 5| Step: 1
Training loss: 0.33267386463737236
Validation loss: 2.7163914575211496

Epoch: 5| Step: 2
Training loss: 0.445788447030819
Validation loss: 2.67849475054511

Epoch: 5| Step: 3
Training loss: 0.488963466891481
Validation loss: 2.6937532992095687

Epoch: 5| Step: 4
Training loss: 0.2610218106050414
Validation loss: 2.6540672309570117

Epoch: 5| Step: 5
Training loss: 0.20734955052970297
Validation loss: 2.7171863941251067

Epoch: 5| Step: 6
Training loss: 0.34877143903348196
Validation loss: 2.733609432042106

Epoch: 5| Step: 7
Training loss: 0.318994532079382
Validation loss: 2.729508303354145

Epoch: 5| Step: 8
Training loss: 0.3625941803691361
Validation loss: 2.782622900373908

Epoch: 5| Step: 9
Training loss: 0.32518703003379623
Validation loss: 2.6857623463512335

Epoch: 5| Step: 10
Training loss: 0.24320908401595173
Validation loss: 2.7550589924212034

Epoch: 5| Step: 11
Training loss: 0.19767368714687947
Validation loss: 2.714398068956497

Epoch: 385| Step: 0
Training loss: 0.1936165804020537
Validation loss: 2.717337917605094

Epoch: 5| Step: 1
Training loss: 0.26390164571735353
Validation loss: 2.732232142440069

Epoch: 5| Step: 2
Training loss: 0.42748082279670485
Validation loss: 2.7653803313052654

Epoch: 5| Step: 3
Training loss: 0.2365048197215846
Validation loss: 2.7958683638976667

Epoch: 5| Step: 4
Training loss: 0.2655966687520651
Validation loss: 2.7418752276934475

Epoch: 5| Step: 5
Training loss: 0.420924865176202
Validation loss: 2.7411544027501984

Epoch: 5| Step: 6
Training loss: 0.33386118886925054
Validation loss: 2.8309963045288136

Epoch: 5| Step: 7
Training loss: 0.3340564672284001
Validation loss: 2.68980385481792

Epoch: 5| Step: 8
Training loss: 0.46137221898429565
Validation loss: 2.7653773317235673

Epoch: 5| Step: 9
Training loss: 0.26338458481191407
Validation loss: 2.7261740508906454

Epoch: 5| Step: 10
Training loss: 0.4528356812350372
Validation loss: 2.6851306495633707

Epoch: 5| Step: 11
Training loss: 0.24806581259697666
Validation loss: 2.6808592974795107

Epoch: 386| Step: 0
Training loss: 0.37163810958476146
Validation loss: 2.7242594285689608

Epoch: 5| Step: 1
Training loss: 0.3232799634728108
Validation loss: 2.698758437070016

Epoch: 5| Step: 2
Training loss: 0.42235407295552796
Validation loss: 2.708959820009703

Epoch: 5| Step: 3
Training loss: 0.40991098245871377
Validation loss: 2.6658363738484367

Epoch: 5| Step: 4
Training loss: 0.2813831252700504
Validation loss: 2.715175445565474

Epoch: 5| Step: 5
Training loss: 0.49394044100650786
Validation loss: 2.719998745222597

Epoch: 5| Step: 6
Training loss: 0.25978747971461275
Validation loss: 2.7248064888189036

Epoch: 5| Step: 7
Training loss: 0.2677717135072688
Validation loss: 2.6545127685413665

Epoch: 5| Step: 8
Training loss: 0.3556840265694653
Validation loss: 2.615288389871732

Epoch: 5| Step: 9
Training loss: 0.31149208126289707
Validation loss: 2.712594448443441

Epoch: 5| Step: 10
Training loss: 0.3429935976381811
Validation loss: 2.7409826423030936

Epoch: 5| Step: 11
Training loss: 0.6956359453873949
Validation loss: 2.6511187489113466

Epoch: 387| Step: 0
Training loss: 0.2746788729201492
Validation loss: 2.691202138424081

Epoch: 5| Step: 1
Training loss: 0.5100346874614159
Validation loss: 2.781925340875616

Epoch: 5| Step: 2
Training loss: 0.46507722136507273
Validation loss: 2.85372171739133

Epoch: 5| Step: 3
Training loss: 0.3191353520829734
Validation loss: 2.7807792986770994

Epoch: 5| Step: 4
Training loss: 0.4221685236146922
Validation loss: 2.687013541411689

Epoch: 5| Step: 5
Training loss: 0.4060596790529858
Validation loss: 2.740003378954774

Epoch: 5| Step: 6
Training loss: 0.2854452628175756
Validation loss: 2.6853384891925827

Epoch: 5| Step: 7
Training loss: 0.4326143458425913
Validation loss: 2.7369004984449914

Epoch: 5| Step: 8
Training loss: 0.5615539807844697
Validation loss: 2.7419286281482194

Epoch: 5| Step: 9
Training loss: 0.33185229247115944
Validation loss: 2.706820455456822

Epoch: 5| Step: 10
Training loss: 0.5610506671457902
Validation loss: 2.7144708281239067

Epoch: 5| Step: 11
Training loss: 0.2542956374177835
Validation loss: 2.751332548989515

Epoch: 388| Step: 0
Training loss: 0.28448172704428404
Validation loss: 2.7497635869795913

Epoch: 5| Step: 1
Training loss: 0.38619477966776833
Validation loss: 2.711256570938517

Epoch: 5| Step: 2
Training loss: 0.33229300335263473
Validation loss: 2.7429553711109564

Epoch: 5| Step: 3
Training loss: 0.32697360932819824
Validation loss: 2.7930599633463506

Epoch: 5| Step: 4
Training loss: 0.4318558514513845
Validation loss: 2.6949808183859116

Epoch: 5| Step: 5
Training loss: 0.3284138815651301
Validation loss: 2.7729233314401585

Epoch: 5| Step: 6
Training loss: 0.3331268746536211
Validation loss: 2.7244347082229954

Epoch: 5| Step: 7
Training loss: 0.34196778520268306
Validation loss: 2.7458358650794006

Epoch: 5| Step: 8
Training loss: 0.28911762742877445
Validation loss: 2.73781608951413

Epoch: 5| Step: 9
Training loss: 0.32635615048788247
Validation loss: 2.7054972263137023

Epoch: 5| Step: 10
Training loss: 0.4698460480481887
Validation loss: 2.722623517475005

Epoch: 5| Step: 11
Training loss: 0.2460485068618556
Validation loss: 2.7126894336832383

Epoch: 389| Step: 0
Training loss: 0.3171646424687637
Validation loss: 2.704612539462108

Epoch: 5| Step: 1
Training loss: 0.37722851275054153
Validation loss: 2.730876493775464

Epoch: 5| Step: 2
Training loss: 0.3741217700590684
Validation loss: 2.762223466924634

Epoch: 5| Step: 3
Training loss: 0.43604081204666734
Validation loss: 2.8227447877384813

Epoch: 5| Step: 4
Training loss: 0.42479819808037195
Validation loss: 2.7628616924758447

Epoch: 5| Step: 5
Training loss: 0.3502526359213862
Validation loss: 2.7610724276042324

Epoch: 5| Step: 6
Training loss: 0.2937048755643709
Validation loss: 2.7683147741354386

Epoch: 5| Step: 7
Training loss: 0.4185955659571348
Validation loss: 2.6692737982508623

Epoch: 5| Step: 8
Training loss: 0.4559056203833763
Validation loss: 2.7850887902121153

Epoch: 5| Step: 9
Training loss: 0.29982052987951596
Validation loss: 2.77545327015886

Epoch: 5| Step: 10
Training loss: 0.20431975059736862
Validation loss: 2.7073811923689095

Epoch: 5| Step: 11
Training loss: 0.31039021697210784
Validation loss: 2.7298010581403602

Epoch: 390| Step: 0
Training loss: 0.39500342337416544
Validation loss: 2.700807029594464

Epoch: 5| Step: 1
Training loss: 0.35540968016405833
Validation loss: 2.7395098655819177

Epoch: 5| Step: 2
Training loss: 0.43809479063751144
Validation loss: 2.7447948522145116

Epoch: 5| Step: 3
Training loss: 0.206255503060879
Validation loss: 2.701846035165195

Epoch: 5| Step: 4
Training loss: 0.2637336799806334
Validation loss: 2.793154207487908

Epoch: 5| Step: 5
Training loss: 0.34855811336603204
Validation loss: 2.737270315541729

Epoch: 5| Step: 6
Training loss: 0.33377321717948527
Validation loss: 2.687527305257316

Epoch: 5| Step: 7
Training loss: 0.30118943050689617
Validation loss: 2.7234420882839494

Epoch: 5| Step: 8
Training loss: 0.22672228276072182
Validation loss: 2.7345758673140566

Epoch: 5| Step: 9
Training loss: 0.2943365085649424
Validation loss: 2.726019552945527

Epoch: 5| Step: 10
Training loss: 0.36481990858838603
Validation loss: 2.764737617242804

Epoch: 5| Step: 11
Training loss: 0.26263100783617727
Validation loss: 2.738506737756302

Epoch: 391| Step: 0
Training loss: 0.43554001533340986
Validation loss: 2.693395834296349

Epoch: 5| Step: 1
Training loss: 0.4021639190554412
Validation loss: 2.6608445018944495

Epoch: 5| Step: 2
Training loss: 0.513273860930467
Validation loss: 2.6870646863473646

Epoch: 5| Step: 3
Training loss: 0.22628150154229387
Validation loss: 2.6861956484340177

Epoch: 5| Step: 4
Training loss: 0.46558842995423977
Validation loss: 2.7700736263970316

Epoch: 5| Step: 5
Training loss: 0.34204462064467417
Validation loss: 2.7150405519722556

Epoch: 5| Step: 6
Training loss: 0.3623490627700436
Validation loss: 2.7133595533025754

Epoch: 5| Step: 7
Training loss: 0.49799773029878747
Validation loss: 2.7942670956622484

Epoch: 5| Step: 8
Training loss: 0.30553265266607604
Validation loss: 2.7300797505077554

Epoch: 5| Step: 9
Training loss: 0.3193564335489622
Validation loss: 2.7415962052687552

Epoch: 5| Step: 10
Training loss: 0.35704266385922157
Validation loss: 2.719161714971556

Epoch: 5| Step: 11
Training loss: 0.21235703609913967
Validation loss: 2.7246601204835104

Epoch: 392| Step: 0
Training loss: 0.25534810241717193
Validation loss: 2.732072220217759

Epoch: 5| Step: 1
Training loss: 0.41633547097266393
Validation loss: 2.7471525810752473

Epoch: 5| Step: 2
Training loss: 0.34312037763626274
Validation loss: 2.775342682709143

Epoch: 5| Step: 3
Training loss: 0.29194689243065436
Validation loss: 2.6596130324334086

Epoch: 5| Step: 4
Training loss: 0.3292457196921245
Validation loss: 2.7770228962905055

Epoch: 5| Step: 5
Training loss: 0.3676767741844681
Validation loss: 2.723871154313985

Epoch: 5| Step: 6
Training loss: 0.2182669500283015
Validation loss: 2.7105109055947163

Epoch: 5| Step: 7
Training loss: 0.30710399144552847
Validation loss: 2.695327242751045

Epoch: 5| Step: 8
Training loss: 0.4358307806940738
Validation loss: 2.7166276152754745

Epoch: 5| Step: 9
Training loss: 0.3590021687311955
Validation loss: 2.6937683252358857

Epoch: 5| Step: 10
Training loss: 0.3520715419028731
Validation loss: 2.7053249719323524

Epoch: 5| Step: 11
Training loss: 0.2526704350619715
Validation loss: 2.764061940482259

Epoch: 393| Step: 0
Training loss: 0.2546923865101111
Validation loss: 2.6560224809631148

Epoch: 5| Step: 1
Training loss: 0.34486560340916605
Validation loss: 2.779714624888331

Epoch: 5| Step: 2
Training loss: 0.3433882153304086
Validation loss: 2.744701645814791

Epoch: 5| Step: 3
Training loss: 0.5043722555849269
Validation loss: 2.775184815212194

Epoch: 5| Step: 4
Training loss: 0.3301916886395584
Validation loss: 2.732145566787587

Epoch: 5| Step: 5
Training loss: 0.3107817379509886
Validation loss: 2.712455002313345

Epoch: 5| Step: 6
Training loss: 0.2687952940498049
Validation loss: 2.7639663305780537

Epoch: 5| Step: 7
Training loss: 0.32282678701759454
Validation loss: 2.7715197062015737

Epoch: 5| Step: 8
Training loss: 0.2625931608553688
Validation loss: 2.784910882286465

Epoch: 5| Step: 9
Training loss: 0.19679384186070428
Validation loss: 2.7130729553601896

Epoch: 5| Step: 10
Training loss: 0.4211285486510562
Validation loss: 2.730633124486901

Epoch: 5| Step: 11
Training loss: 0.21436403644097232
Validation loss: 2.729449287855375

Epoch: 394| Step: 0
Training loss: 0.24830395600122612
Validation loss: 2.7568378455236187

Epoch: 5| Step: 1
Training loss: 0.2368795880852187
Validation loss: 2.747562827629089

Epoch: 5| Step: 2
Training loss: 0.3106598318745561
Validation loss: 2.7240316017659256

Epoch: 5| Step: 3
Training loss: 0.30890498582178977
Validation loss: 2.737283772590423

Epoch: 5| Step: 4
Training loss: 0.2782426960115875
Validation loss: 2.7660007149759096

Epoch: 5| Step: 5
Training loss: 0.2965495433730535
Validation loss: 2.7750224066737554

Epoch: 5| Step: 6
Training loss: 0.42450989766034153
Validation loss: 2.7371768220670782

Epoch: 5| Step: 7
Training loss: 0.3100936509385662
Validation loss: 2.71029732114234

Epoch: 5| Step: 8
Training loss: 0.30202896626453224
Validation loss: 2.6788666267687207

Epoch: 5| Step: 9
Training loss: 0.32250360891629454
Validation loss: 2.7390876776116015

Epoch: 5| Step: 10
Training loss: 0.3788398999197345
Validation loss: 2.7044159079798176

Epoch: 5| Step: 11
Training loss: 0.20777813225706426
Validation loss: 2.703874252645839

Epoch: 395| Step: 0
Training loss: 0.3316742492452785
Validation loss: 2.7230585294561758

Epoch: 5| Step: 1
Training loss: 0.32965937128342293
Validation loss: 2.8058643581596265

Epoch: 5| Step: 2
Training loss: 0.43275957369227785
Validation loss: 2.7714967483197706

Epoch: 5| Step: 3
Training loss: 0.4133823674897636
Validation loss: 2.758505401881925

Epoch: 5| Step: 4
Training loss: 0.18421773183863202
Validation loss: 2.7115879396191405

Epoch: 5| Step: 5
Training loss: 0.30290738976155035
Validation loss: 2.729746022986373

Epoch: 5| Step: 6
Training loss: 0.30884637029413037
Validation loss: 2.702136820134119

Epoch: 5| Step: 7
Training loss: 0.2320777445105388
Validation loss: 2.7331468094494173

Epoch: 5| Step: 8
Training loss: 0.5281833887270858
Validation loss: 2.7741550305388807

Epoch: 5| Step: 9
Training loss: 0.2679907130813663
Validation loss: 2.727061700528698

Epoch: 5| Step: 10
Training loss: 0.1664415785400427
Validation loss: 2.720193227731018

Epoch: 5| Step: 11
Training loss: 0.23504670370194966
Validation loss: 2.7250184657844843

Epoch: 396| Step: 0
Training loss: 0.31174903282743566
Validation loss: 2.726449561489854

Epoch: 5| Step: 1
Training loss: 0.2465835193551361
Validation loss: 2.7909279185084968

Epoch: 5| Step: 2
Training loss: 0.30162809725822043
Validation loss: 2.739792073689507

Epoch: 5| Step: 3
Training loss: 0.2846201207040511
Validation loss: 2.787474229006391

Epoch: 5| Step: 4
Training loss: 0.35518823811059846
Validation loss: 2.701272425201739

Epoch: 5| Step: 5
Training loss: 0.3118140918563364
Validation loss: 2.687504553975823

Epoch: 5| Step: 6
Training loss: 0.39054700072702947
Validation loss: 2.6982262567543893

Epoch: 5| Step: 7
Training loss: 0.21614019930440567
Validation loss: 2.711856341866707

Epoch: 5| Step: 8
Training loss: 0.364515525325016
Validation loss: 2.6378240948163767

Epoch: 5| Step: 9
Training loss: 0.33358169283730726
Validation loss: 2.720149443719032

Epoch: 5| Step: 10
Training loss: 0.42241842097398946
Validation loss: 2.684433951302317

Epoch: 5| Step: 11
Training loss: 0.2604747357793395
Validation loss: 2.733298113254873

Epoch: 397| Step: 0
Training loss: 0.3129408944808472
Validation loss: 2.7512231729110286

Epoch: 5| Step: 1
Training loss: 0.22443636990026036
Validation loss: 2.730450442302343

Epoch: 5| Step: 2
Training loss: 0.2978227695243554
Validation loss: 2.736512062920905

Epoch: 5| Step: 3
Training loss: 0.3683449783829003
Validation loss: 2.732997641845162

Epoch: 5| Step: 4
Training loss: 0.27294227168159846
Validation loss: 2.676321579333615

Epoch: 5| Step: 5
Training loss: 0.38536911318796263
Validation loss: 2.6577684886591784

Epoch: 5| Step: 6
Training loss: 0.2660430675585215
Validation loss: 2.665013591923744

Epoch: 5| Step: 7
Training loss: 0.47390987511822685
Validation loss: 2.7062246378707915

Epoch: 5| Step: 8
Training loss: 0.290945159778497
Validation loss: 2.7358647130393794

Epoch: 5| Step: 9
Training loss: 0.3293356247046298
Validation loss: 2.806560188685826

Epoch: 5| Step: 10
Training loss: 0.3117088435805024
Validation loss: 2.802342219724965

Epoch: 5| Step: 11
Training loss: 0.15829034449667873
Validation loss: 2.82706962479988

Epoch: 398| Step: 0
Training loss: 0.38861790958119125
Validation loss: 2.7393068650330803

Epoch: 5| Step: 1
Training loss: 0.37405445179451513
Validation loss: 2.7894178924522146

Epoch: 5| Step: 2
Training loss: 0.3990839407709044
Validation loss: 2.753161329158894

Epoch: 5| Step: 3
Training loss: 0.3526347128325895
Validation loss: 2.741998454041327

Epoch: 5| Step: 4
Training loss: 0.4468065262732796
Validation loss: 2.725865629345573

Epoch: 5| Step: 5
Training loss: 0.36590347607481766
Validation loss: 2.742016293360657

Epoch: 5| Step: 6
Training loss: 0.332720982590393
Validation loss: 2.6896264586671275

Epoch: 5| Step: 7
Training loss: 0.39039887559076103
Validation loss: 2.769022645148693

Epoch: 5| Step: 8
Training loss: 0.37659607417065505
Validation loss: 2.7345225339779358

Epoch: 5| Step: 9
Training loss: 0.29805673505439684
Validation loss: 2.7394800976543587

Epoch: 5| Step: 10
Training loss: 0.539947502003849
Validation loss: 2.7530938142763137

Epoch: 5| Step: 11
Training loss: 0.14501172825021227
Validation loss: 2.743908974858127

Epoch: 399| Step: 0
Training loss: 0.21494597690546005
Validation loss: 2.7108895978259144

Epoch: 5| Step: 1
Training loss: 0.3937428027206698
Validation loss: 2.735549703492427

Epoch: 5| Step: 2
Training loss: 0.45775631504505
Validation loss: 2.6740895383382575

Epoch: 5| Step: 3
Training loss: 0.3304296461376575
Validation loss: 2.6944293395063643

Epoch: 5| Step: 4
Training loss: 0.333843569604728
Validation loss: 2.700803149091049

Epoch: 5| Step: 5
Training loss: 0.43255783603922393
Validation loss: 2.682982929128509

Epoch: 5| Step: 6
Training loss: 0.43848736925974924
Validation loss: 2.6456237838896124

Epoch: 5| Step: 7
Training loss: 0.38417856577955284
Validation loss: 2.6635241854893024

Epoch: 5| Step: 8
Training loss: 0.3540112935314887
Validation loss: 2.731434678061656

Epoch: 5| Step: 9
Training loss: 0.22116259625158477
Validation loss: 2.711025013092851

Epoch: 5| Step: 10
Training loss: 0.3567461181581805
Validation loss: 2.7153191568734476

Epoch: 5| Step: 11
Training loss: 0.679181864535267
Validation loss: 2.7288728851920117

Epoch: 400| Step: 0
Training loss: 0.3088038489838735
Validation loss: 2.7265745197311753

Epoch: 5| Step: 1
Training loss: 0.4073573572529437
Validation loss: 2.70849511812627

Epoch: 5| Step: 2
Training loss: 0.22111910886879618
Validation loss: 2.7095639269647758

Epoch: 5| Step: 3
Training loss: 0.3702883764851727
Validation loss: 2.749703192588241

Epoch: 5| Step: 4
Training loss: 0.22031176309935788
Validation loss: 2.729434532871398

Epoch: 5| Step: 5
Training loss: 0.44528152960445166
Validation loss: 2.8164526908668064

Epoch: 5| Step: 6
Training loss: 0.23135343570985933
Validation loss: 2.8148264975914175

Epoch: 5| Step: 7
Training loss: 0.2885783755136983
Validation loss: 2.748934412904323

Epoch: 5| Step: 8
Training loss: 0.2503553934052685
Validation loss: 2.708981617341933

Epoch: 5| Step: 9
Training loss: 0.2762383204360227
Validation loss: 2.803279278782508

Epoch: 5| Step: 10
Training loss: 0.3498876944948025
Validation loss: 2.757500783073427

Epoch: 5| Step: 11
Training loss: 0.18751686735578427
Validation loss: 2.7084674374073243

Testing loss: 2.6387142936522356
