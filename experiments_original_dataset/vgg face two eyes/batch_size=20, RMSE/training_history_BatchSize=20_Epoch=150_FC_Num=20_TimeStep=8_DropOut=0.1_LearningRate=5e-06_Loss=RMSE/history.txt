Epoch: 1| Step: 0
Training loss: 4.252590736170171
Validation loss: 4.2293010026364275

Epoch: 5| Step: 1
Training loss: 4.596177478308402
Validation loss: 4.206124040551322

Epoch: 5| Step: 2
Training loss: 4.417376815036882
Validation loss: 4.184411523121605

Epoch: 5| Step: 3
Training loss: 5.022422486272459
Validation loss: 4.161142805962304

Epoch: 5| Step: 4
Training loss: 4.227266884032506
Validation loss: 4.138413180393798

Epoch: 5| Step: 5
Training loss: 4.298168084906452
Validation loss: 4.117645527735193

Epoch: 5| Step: 6
Training loss: 4.193043242479235
Validation loss: 4.093591609346472

Epoch: 5| Step: 7
Training loss: 4.334182411541267
Validation loss: 4.072026697798883

Epoch: 5| Step: 8
Training loss: 4.2007852728471295
Validation loss: 4.0476783877986335

Epoch: 5| Step: 9
Training loss: 3.7382873726438888
Validation loss: 4.023631923879065

Epoch: 5| Step: 10
Training loss: 3.387993279046212
Validation loss: 3.997688832764339

Epoch: 5| Step: 11
Training loss: 3.5205014465528435
Validation loss: 3.9710641957299657

Epoch: 2| Step: 0
Training loss: 4.351114739713194
Validation loss: 3.9472513351169187

Epoch: 5| Step: 1
Training loss: 4.24865768776765
Validation loss: 3.9248375057187643

Epoch: 5| Step: 2
Training loss: 3.7996074122363726
Validation loss: 3.8976248006800134

Epoch: 5| Step: 3
Training loss: 3.609196646110856
Validation loss: 3.87041466662422

Epoch: 5| Step: 4
Training loss: 3.650556647299702
Validation loss: 3.8415208932991196

Epoch: 5| Step: 5
Training loss: 4.246322611630668
Validation loss: 3.81231851093668

Epoch: 5| Step: 6
Training loss: 3.084523941973607
Validation loss: 3.7860989494078647

Epoch: 5| Step: 7
Training loss: 3.6921136733272473
Validation loss: 3.75390072973337

Epoch: 5| Step: 8
Training loss: 4.400392358799037
Validation loss: 3.7229416835537115

Epoch: 5| Step: 9
Training loss: 3.8636617598489447
Validation loss: 3.690476735469526

Epoch: 5| Step: 10
Training loss: 3.9422359746310587
Validation loss: 3.655083201148938

Epoch: 5| Step: 11
Training loss: 4.252249627207914
Validation loss: 3.620906294134061

Epoch: 3| Step: 0
Training loss: 3.0899292443331694
Validation loss: 3.5850408204511064

Epoch: 5| Step: 1
Training loss: 4.095806973677471
Validation loss: 3.5455879699559323

Epoch: 5| Step: 2
Training loss: 3.4632918571311455
Validation loss: 3.506186110378522

Epoch: 5| Step: 3
Training loss: 3.4358819100955826
Validation loss: 3.4610668471070647

Epoch: 5| Step: 4
Training loss: 2.907037935810556
Validation loss: 3.422549891000247

Epoch: 5| Step: 5
Training loss: 3.4369631261326483
Validation loss: 3.384556797084327

Epoch: 5| Step: 6
Training loss: 4.152826720721546
Validation loss: 3.3364506311215574

Epoch: 5| Step: 7
Training loss: 4.023824313930095
Validation loss: 3.285708507637409

Epoch: 5| Step: 8
Training loss: 3.5397819141517544
Validation loss: 3.2451693109456463

Epoch: 5| Step: 9
Training loss: 3.332283967464258
Validation loss: 3.191128261478974

Epoch: 5| Step: 10
Training loss: 2.4534082917323734
Validation loss: 3.138296887086025

Epoch: 5| Step: 11
Training loss: 2.6025938446978207
Validation loss: 3.0886177366687133

Epoch: 4| Step: 0
Training loss: 3.2892918450138784
Validation loss: 3.0372354626419793

Epoch: 5| Step: 1
Training loss: 3.347486458281632
Validation loss: 2.980612421801789

Epoch: 5| Step: 2
Training loss: 3.1437684075667915
Validation loss: 2.9323453858752906

Epoch: 5| Step: 3
Training loss: 3.0572609756376274
Validation loss: 2.877337027645553

Epoch: 5| Step: 4
Training loss: 3.150713303956815
Validation loss: 2.834057986396462

Epoch: 5| Step: 5
Training loss: 3.1004447556439856
Validation loss: 2.781398631707039

Epoch: 5| Step: 6
Training loss: 2.739487930396587
Validation loss: 2.7288417962536253

Epoch: 5| Step: 7
Training loss: 2.9291060620943803
Validation loss: 2.693486476939308

Epoch: 5| Step: 8
Training loss: 2.0387985818712417
Validation loss: 2.6422155168590566

Epoch: 5| Step: 9
Training loss: 2.056781470537793
Validation loss: 2.59627507713303

Epoch: 5| Step: 10
Training loss: 2.33145149730582
Validation loss: 2.5881919906090993

Epoch: 5| Step: 11
Training loss: 3.124076706866485
Validation loss: 2.569566589465042

Epoch: 5| Step: 0
Training loss: 2.329528999693414
Validation loss: 2.5824009317596994

Epoch: 5| Step: 1
Training loss: 2.6794689745536715
Validation loss: 2.571641897064533

Epoch: 5| Step: 2
Training loss: 2.0917354400190034
Validation loss: 2.574780689856774

Epoch: 5| Step: 3
Training loss: 2.6343261714224773
Validation loss: 2.577333694936382

Epoch: 5| Step: 4
Training loss: 2.710364905138485
Validation loss: 2.5902763109029707

Epoch: 5| Step: 5
Training loss: 2.821946619081811
Validation loss: 2.590652918617243

Epoch: 5| Step: 6
Training loss: 2.685626596828072
Validation loss: 2.618525092087936

Epoch: 5| Step: 7
Training loss: 2.9945454283392823
Validation loss: 2.6273510599615997

Epoch: 5| Step: 8
Training loss: 2.1135137574628224
Validation loss: 2.614688842032676

Epoch: 5| Step: 9
Training loss: 2.9105789594426725
Validation loss: 2.611896655578733

Epoch: 5| Step: 10
Training loss: 2.9102663569774307
Validation loss: 2.60370526740366

Epoch: 5| Step: 11
Training loss: 2.146640317214148
Validation loss: 2.6136928437592473

Epoch: 6| Step: 0
Training loss: 2.306781399506651
Validation loss: 2.5881209859945096

Epoch: 5| Step: 1
Training loss: 2.0245856485185447
Validation loss: 2.5704223972622953

Epoch: 5| Step: 2
Training loss: 2.676755229471346
Validation loss: 2.5642651781761883

Epoch: 5| Step: 3
Training loss: 2.7095930739905265
Validation loss: 2.561440717976053

Epoch: 5| Step: 4
Training loss: 2.5804375651522604
Validation loss: 2.563429950593091

Epoch: 5| Step: 5
Training loss: 2.682693530351409
Validation loss: 2.5527244709720742

Epoch: 5| Step: 6
Training loss: 2.442848987772881
Validation loss: 2.573121558202456

Epoch: 5| Step: 7
Training loss: 2.396242908353863
Validation loss: 2.5497191059385202

Epoch: 5| Step: 8
Training loss: 2.859857737330827
Validation loss: 2.542021958475641

Epoch: 5| Step: 9
Training loss: 2.923678407677314
Validation loss: 2.5445781328260484

Epoch: 5| Step: 10
Training loss: 2.3542960364879977
Validation loss: 2.551332165985033

Epoch: 5| Step: 11
Training loss: 3.3969490387120094
Validation loss: 2.5337645438726772

Epoch: 7| Step: 0
Training loss: 2.4647899688318478
Validation loss: 2.5387526220348495

Epoch: 5| Step: 1
Training loss: 2.180743655483188
Validation loss: 2.5357107213460277

Epoch: 5| Step: 2
Training loss: 3.0021951909153857
Validation loss: 2.5511652066987587

Epoch: 5| Step: 3
Training loss: 2.7491367892649663
Validation loss: 2.5352947841855853

Epoch: 5| Step: 4
Training loss: 2.0864248099437535
Validation loss: 2.5347842456394107

Epoch: 5| Step: 5
Training loss: 2.571371677692684
Validation loss: 2.534515068583102

Epoch: 5| Step: 6
Training loss: 2.287578531386838
Validation loss: 2.5360447992332484

Epoch: 5| Step: 7
Training loss: 2.5964503192346866
Validation loss: 2.5323730300852225

Epoch: 5| Step: 8
Training loss: 2.442008226566689
Validation loss: 2.535291627973301

Epoch: 5| Step: 9
Training loss: 3.029045955416394
Validation loss: 2.5229647560692023

Epoch: 5| Step: 10
Training loss: 2.426135051191729
Validation loss: 2.5243492132892396

Epoch: 5| Step: 11
Training loss: 3.311613864052166
Validation loss: 2.521042245031995

Epoch: 8| Step: 0
Training loss: 2.4878508047282324
Validation loss: 2.5315704810002546

Epoch: 5| Step: 1
Training loss: 2.4491133233701596
Validation loss: 2.5166117350054824

Epoch: 5| Step: 2
Training loss: 2.6508006128064365
Validation loss: 2.5198116550596317

Epoch: 5| Step: 3
Training loss: 2.9544345434752293
Validation loss: 2.521749670135879

Epoch: 5| Step: 4
Training loss: 2.331576969238345
Validation loss: 2.5121506101687827

Epoch: 5| Step: 5
Training loss: 2.306450017923793
Validation loss: 2.5207028920076833

Epoch: 5| Step: 6
Training loss: 1.9276941173489235
Validation loss: 2.5169144557919636

Epoch: 5| Step: 7
Training loss: 2.728444059576185
Validation loss: 2.516885425889264

Epoch: 5| Step: 8
Training loss: 3.009421178477312
Validation loss: 2.5278280817052217

Epoch: 5| Step: 9
Training loss: 2.2669722136084838
Validation loss: 2.5083696413950363

Epoch: 5| Step: 10
Training loss: 2.502429639835142
Validation loss: 2.5095101925389005

Epoch: 5| Step: 11
Training loss: 3.5826460748508278
Validation loss: 2.5155307049187488

Epoch: 9| Step: 0
Training loss: 2.5471727630110297
Validation loss: 2.513795195081086

Epoch: 5| Step: 1
Training loss: 2.6492060893596303
Validation loss: 2.5232687894720707

Epoch: 5| Step: 2
Training loss: 2.4759363772856635
Validation loss: 2.510402704466513

Epoch: 5| Step: 3
Training loss: 2.8298118997883224
Validation loss: 2.515069477671269

Epoch: 5| Step: 4
Training loss: 2.5002750245451515
Validation loss: 2.498634187814328

Epoch: 5| Step: 5
Training loss: 2.9270947185761025
Validation loss: 2.507988195711705

Epoch: 5| Step: 6
Training loss: 2.1432499071479616
Validation loss: 2.4979710014379086

Epoch: 5| Step: 7
Training loss: 2.6444520924383674
Validation loss: 2.507393212686236

Epoch: 5| Step: 8
Training loss: 2.746929448513573
Validation loss: 2.512314669889187

Epoch: 5| Step: 9
Training loss: 2.467042936374345
Validation loss: 2.502807697563503

Epoch: 5| Step: 10
Training loss: 2.1411352732800153
Validation loss: 2.517429885070967

Epoch: 5| Step: 11
Training loss: 1.1522011878843297
Validation loss: 2.512380118380548

Epoch: 10| Step: 0
Training loss: 2.7574751434174236
Validation loss: 2.495240700010629

Epoch: 5| Step: 1
Training loss: 2.761980662140767
Validation loss: 2.5056786792885926

Epoch: 5| Step: 2
Training loss: 2.6193469803298375
Validation loss: 2.5009929274629723

Epoch: 5| Step: 3
Training loss: 2.002205824371454
Validation loss: 2.4998470299333233

Epoch: 5| Step: 4
Training loss: 2.276481137886889
Validation loss: 2.501536449524677

Epoch: 5| Step: 5
Training loss: 2.3754105464060418
Validation loss: 2.492578597358436

Epoch: 5| Step: 6
Training loss: 2.9212229608044225
Validation loss: 2.491324782651941

Epoch: 5| Step: 7
Training loss: 2.111802463375215
Validation loss: 2.496356164294873

Epoch: 5| Step: 8
Training loss: 3.0191171616333383
Validation loss: 2.498412510387272

Epoch: 5| Step: 9
Training loss: 2.7689427879156776
Validation loss: 2.493863430168247

Epoch: 5| Step: 10
Training loss: 2.1384218113295996
Validation loss: 2.4906635906846653

Epoch: 5| Step: 11
Training loss: 1.5461659974059783
Validation loss: 2.489045194033678

Epoch: 11| Step: 0
Training loss: 2.4115126887238176
Validation loss: 2.4838511236525043

Epoch: 5| Step: 1
Training loss: 2.907301517708159
Validation loss: 2.4898995587027515

Epoch: 5| Step: 2
Training loss: 2.2337329715705163
Validation loss: 2.4936155813602343

Epoch: 5| Step: 3
Training loss: 2.350070822439911
Validation loss: 2.507759802750874

Epoch: 5| Step: 4
Training loss: 2.3300421073284983
Validation loss: 2.4835385147933176

Epoch: 5| Step: 5
Training loss: 2.654827320352703
Validation loss: 2.487295473498804

Epoch: 5| Step: 6
Training loss: 2.918919338239653
Validation loss: 2.495876607270315

Epoch: 5| Step: 7
Training loss: 2.47250505560656
Validation loss: 2.4889913211534282

Epoch: 5| Step: 8
Training loss: 2.302598219608363
Validation loss: 2.4950153765526295

Epoch: 5| Step: 9
Training loss: 2.6523644245673426
Validation loss: 2.4927776239894945

Epoch: 5| Step: 10
Training loss: 2.573165840304784
Validation loss: 2.4868042942633246

Epoch: 5| Step: 11
Training loss: 1.2431637748244464
Validation loss: 2.5004426524557934

Epoch: 12| Step: 0
Training loss: 2.381942039713435
Validation loss: 2.482630146933031

Epoch: 5| Step: 1
Training loss: 2.4246103897940725
Validation loss: 2.4939086097177294

Epoch: 5| Step: 2
Training loss: 2.585542677504052
Validation loss: 2.4857538003940736

Epoch: 5| Step: 3
Training loss: 2.054627624335519
Validation loss: 2.497356734037702

Epoch: 5| Step: 4
Training loss: 2.8054784652979405
Validation loss: 2.490642383535515

Epoch: 5| Step: 5
Training loss: 2.6266256475715126
Validation loss: 2.4753459385213525

Epoch: 5| Step: 6
Training loss: 2.213381114447801
Validation loss: 2.4911415472252307

Epoch: 5| Step: 7
Training loss: 2.340326682868002
Validation loss: 2.492877119391316

Epoch: 5| Step: 8
Training loss: 2.4178280396570404
Validation loss: 2.4840773198187205

Epoch: 5| Step: 9
Training loss: 3.0411902973478355
Validation loss: 2.4932861776363597

Epoch: 5| Step: 10
Training loss: 2.725455860189907
Validation loss: 2.4880760263942863

Epoch: 5| Step: 11
Training loss: 1.8288038900574288
Validation loss: 2.485969755361884

Epoch: 13| Step: 0
Training loss: 2.349179299076898
Validation loss: 2.4666250757521446

Epoch: 5| Step: 1
Training loss: 2.6345445499182873
Validation loss: 2.4728397986257744

Epoch: 5| Step: 2
Training loss: 2.3025159012269234
Validation loss: 2.4689888214936193

Epoch: 5| Step: 3
Training loss: 2.512854525477139
Validation loss: 2.4703972588189242

Epoch: 5| Step: 4
Training loss: 2.572333657212991
Validation loss: 2.4731698288773822

Epoch: 5| Step: 5
Training loss: 2.0194460114839266
Validation loss: 2.48709107525013

Epoch: 5| Step: 6
Training loss: 3.1832986706615736
Validation loss: 2.470039738993079

Epoch: 5| Step: 7
Training loss: 2.2138215250859954
Validation loss: 2.4752370654989124

Epoch: 5| Step: 8
Training loss: 2.216998846457271
Validation loss: 2.471455467782193

Epoch: 5| Step: 9
Training loss: 2.570887538971145
Validation loss: 2.4543241295441396

Epoch: 5| Step: 10
Training loss: 2.5060502274724556
Validation loss: 2.4737614215319224

Epoch: 5| Step: 11
Training loss: 3.7693053182778202
Validation loss: 2.4605696791816305

Epoch: 14| Step: 0
Training loss: 3.152905344424548
Validation loss: 2.456053660135326

Epoch: 5| Step: 1
Training loss: 2.4858081450695746
Validation loss: 2.464319220671183

Epoch: 5| Step: 2
Training loss: 2.6221193220221917
Validation loss: 2.471241860338518

Epoch: 5| Step: 3
Training loss: 2.245034035847349
Validation loss: 2.4608699849873474

Epoch: 5| Step: 4
Training loss: 2.1759230398004146
Validation loss: 2.467977805431466

Epoch: 5| Step: 5
Training loss: 2.3069207185335
Validation loss: 2.4597787500598427

Epoch: 5| Step: 6
Training loss: 2.831758304465561
Validation loss: 2.467723355315316

Epoch: 5| Step: 7
Training loss: 2.798848569360083
Validation loss: 2.4553791307728132

Epoch: 5| Step: 8
Training loss: 2.5984347216693937
Validation loss: 2.46062975780882

Epoch: 5| Step: 9
Training loss: 2.207858256455093
Validation loss: 2.4635231946181415

Epoch: 5| Step: 10
Training loss: 1.9396061678429022
Validation loss: 2.4575361916608744

Epoch: 5| Step: 11
Training loss: 2.4410811306958653
Validation loss: 2.4576343691703073

Epoch: 15| Step: 0
Training loss: 2.744287539856185
Validation loss: 2.4524097493293513

Epoch: 5| Step: 1
Training loss: 2.4372590752891545
Validation loss: 2.473183550060845

Epoch: 5| Step: 2
Training loss: 2.3156720649579805
Validation loss: 2.4555129195005296

Epoch: 5| Step: 3
Training loss: 2.3010042403081346
Validation loss: 2.4513853428508505

Epoch: 5| Step: 4
Training loss: 3.077666892415647
Validation loss: 2.4448761596403887

Epoch: 5| Step: 5
Training loss: 2.3417734585594268
Validation loss: 2.4622472456650284

Epoch: 5| Step: 6
Training loss: 2.098537835217036
Validation loss: 2.461445048637126

Epoch: 5| Step: 7
Training loss: 1.9430573655287364
Validation loss: 2.461959481340514

Epoch: 5| Step: 8
Training loss: 2.3642596276712364
Validation loss: 2.453748992152759

Epoch: 5| Step: 9
Training loss: 2.744185803676139
Validation loss: 2.4623053286587324

Epoch: 5| Step: 10
Training loss: 2.668081702861539
Validation loss: 2.4542970509913324

Epoch: 5| Step: 11
Training loss: 3.155326632656664
Validation loss: 2.4659440234282526

Epoch: 16| Step: 0
Training loss: 2.335087037680022
Validation loss: 2.454188021376424

Epoch: 5| Step: 1
Training loss: 2.555620308990912
Validation loss: 2.447566134468816

Epoch: 5| Step: 2
Training loss: 2.368565023240364
Validation loss: 2.4609994547477902

Epoch: 5| Step: 3
Training loss: 2.4824251404507436
Validation loss: 2.44236474511583

Epoch: 5| Step: 4
Training loss: 2.433439050842708
Validation loss: 2.453902370446171

Epoch: 5| Step: 5
Training loss: 2.6487284362692907
Validation loss: 2.4457305981398316

Epoch: 5| Step: 6
Training loss: 2.6701135015472692
Validation loss: 2.4526239762255875

Epoch: 5| Step: 7
Training loss: 2.2837136956530646
Validation loss: 2.454075355860434

Epoch: 5| Step: 8
Training loss: 2.063067733769566
Validation loss: 2.4465462250606134

Epoch: 5| Step: 9
Training loss: 2.773683950730295
Validation loss: 2.4313848603542074

Epoch: 5| Step: 10
Training loss: 2.6457119310616313
Validation loss: 2.4390930569755

Epoch: 5| Step: 11
Training loss: 2.4486427907564696
Validation loss: 2.442334617597835

Epoch: 17| Step: 0
Training loss: 3.126674661144889
Validation loss: 2.4594710385815386

Epoch: 5| Step: 1
Training loss: 2.3146134075565254
Validation loss: 2.442413008568169

Epoch: 5| Step: 2
Training loss: 1.8868289386172545
Validation loss: 2.45461487325728

Epoch: 5| Step: 3
Training loss: 2.238149163041952
Validation loss: 2.4537864773228892

Epoch: 5| Step: 4
Training loss: 2.530773165023917
Validation loss: 2.4633104015512366

Epoch: 5| Step: 5
Training loss: 2.3142325638246803
Validation loss: 2.4519291491934343

Epoch: 5| Step: 6
Training loss: 2.7160232725986284
Validation loss: 2.4596293327992718

Epoch: 5| Step: 7
Training loss: 2.4837329922666362
Validation loss: 2.4786143221892494

Epoch: 5| Step: 8
Training loss: 2.719655730114427
Validation loss: 2.4747011127042122

Epoch: 5| Step: 9
Training loss: 2.131005272560274
Validation loss: 2.4704132915269383

Epoch: 5| Step: 10
Training loss: 2.8165306878607983
Validation loss: 2.4560342331547105

Epoch: 5| Step: 11
Training loss: 1.019646006005001
Validation loss: 2.4508786820223367

Epoch: 18| Step: 0
Training loss: 2.2854318827490867
Validation loss: 2.4573170587171855

Epoch: 5| Step: 1
Training loss: 2.8318862772699998
Validation loss: 2.444438631931051

Epoch: 5| Step: 2
Training loss: 1.8038690866348697
Validation loss: 2.4538051528937914

Epoch: 5| Step: 3
Training loss: 2.7311262613370677
Validation loss: 2.452985739349121

Epoch: 5| Step: 4
Training loss: 1.9839602059403518
Validation loss: 2.449598521226454

Epoch: 5| Step: 5
Training loss: 2.651183558615776
Validation loss: 2.445396080660579

Epoch: 5| Step: 6
Training loss: 1.9016017837666903
Validation loss: 2.445631837153689

Epoch: 5| Step: 7
Training loss: 2.591659070787818
Validation loss: 2.4369871504777114

Epoch: 5| Step: 8
Training loss: 3.1121448850467197
Validation loss: 2.439613563020197

Epoch: 5| Step: 9
Training loss: 2.6055655625871212
Validation loss: 2.4346803430409545

Epoch: 5| Step: 10
Training loss: 2.4906868078586895
Validation loss: 2.438609184678575

Epoch: 5| Step: 11
Training loss: 1.275333093627878
Validation loss: 2.4337726280311216

Epoch: 19| Step: 0
Training loss: 1.9521804356588406
Validation loss: 2.427258195976721

Epoch: 5| Step: 1
Training loss: 2.641484137726293
Validation loss: 2.4374746826682907

Epoch: 5| Step: 2
Training loss: 2.3593832862152713
Validation loss: 2.441498700235242

Epoch: 5| Step: 3
Training loss: 2.509670626849953
Validation loss: 2.431217317108169

Epoch: 5| Step: 4
Training loss: 2.8276432533300637
Validation loss: 2.42647504483118

Epoch: 5| Step: 5
Training loss: 1.854194862351363
Validation loss: 2.4477585612973867

Epoch: 5| Step: 6
Training loss: 3.017655711735166
Validation loss: 2.4223801485968823

Epoch: 5| Step: 7
Training loss: 1.8496532012033173
Validation loss: 2.4208517681761514

Epoch: 5| Step: 8
Training loss: 2.776034662310631
Validation loss: 2.42493451585544

Epoch: 5| Step: 9
Training loss: 2.405501806683081
Validation loss: 2.417285533019327

Epoch: 5| Step: 10
Training loss: 2.713963471551257
Validation loss: 2.4333344878124303

Epoch: 5| Step: 11
Training loss: 1.637048000822725
Validation loss: 2.434728326322577

Epoch: 20| Step: 0
Training loss: 2.0245812913322108
Validation loss: 2.4257204761765263

Epoch: 5| Step: 1
Training loss: 2.4073897795833323
Validation loss: 2.4287149173390548

Epoch: 5| Step: 2
Training loss: 2.4075253562344603
Validation loss: 2.435422409291237

Epoch: 5| Step: 3
Training loss: 2.415702484980541
Validation loss: 2.428430743301542

Epoch: 5| Step: 4
Training loss: 1.8912273109623117
Validation loss: 2.4275070313130205

Epoch: 5| Step: 5
Training loss: 3.01726870632481
Validation loss: 2.4325182575705058

Epoch: 5| Step: 6
Training loss: 3.0005063583288853
Validation loss: 2.4231867816504806

Epoch: 5| Step: 7
Training loss: 2.6089536589384883
Validation loss: 2.410317653072003

Epoch: 5| Step: 8
Training loss: 2.3416710343325824
Validation loss: 2.44367236748238

Epoch: 5| Step: 9
Training loss: 2.8040937469962306
Validation loss: 2.4238085872775654

Epoch: 5| Step: 10
Training loss: 1.8745862504312214
Validation loss: 2.428668974956285

Epoch: 5| Step: 11
Training loss: 1.7449368392750157
Validation loss: 2.415806844824216

Epoch: 21| Step: 0
Training loss: 2.248062040939015
Validation loss: 2.42065601230188

Epoch: 5| Step: 1
Training loss: 2.913397746417919
Validation loss: 2.421709625176412

Epoch: 5| Step: 2
Training loss: 2.2652016079672794
Validation loss: 2.433642558858002

Epoch: 5| Step: 3
Training loss: 2.28306758011637
Validation loss: 2.427937702432396

Epoch: 5| Step: 4
Training loss: 2.3284561638550616
Validation loss: 2.4286259727203166

Epoch: 5| Step: 5
Training loss: 2.8988344481069865
Validation loss: 2.424993857149819

Epoch: 5| Step: 6
Training loss: 2.2135857671196693
Validation loss: 2.426655037108875

Epoch: 5| Step: 7
Training loss: 2.3913734610751356
Validation loss: 2.416620395206463

Epoch: 5| Step: 8
Training loss: 3.217159878434804
Validation loss: 2.4242823582691644

Epoch: 5| Step: 9
Training loss: 1.8593301847811239
Validation loss: 2.4288726372416027

Epoch: 5| Step: 10
Training loss: 1.9997107177378481
Validation loss: 2.422859024801042

Epoch: 5| Step: 11
Training loss: 2.325033093288716
Validation loss: 2.4128122950310353

Epoch: 22| Step: 0
Training loss: 2.343494147005091
Validation loss: 2.422209009088074

Epoch: 5| Step: 1
Training loss: 2.9094353723869157
Validation loss: 2.415220018089466

Epoch: 5| Step: 2
Training loss: 2.0404486493821357
Validation loss: 2.4063016051996815

Epoch: 5| Step: 3
Training loss: 2.10641407313414
Validation loss: 2.426640295487555

Epoch: 5| Step: 4
Training loss: 2.970194415013279
Validation loss: 2.4222485387542263

Epoch: 5| Step: 5
Training loss: 2.4131509485754
Validation loss: 2.424906267242312

Epoch: 5| Step: 6
Training loss: 2.123615711585013
Validation loss: 2.4271840632632764

Epoch: 5| Step: 7
Training loss: 2.099882681158089
Validation loss: 2.4152107717615308

Epoch: 5| Step: 8
Training loss: 2.7939654512556267
Validation loss: 2.422127232696506

Epoch: 5| Step: 9
Training loss: 2.355924799407109
Validation loss: 2.4090026988382136

Epoch: 5| Step: 10
Training loss: 2.6700514431973157
Validation loss: 2.416937016843239

Epoch: 5| Step: 11
Training loss: 1.458255529598881
Validation loss: 2.414554358602817

Epoch: 23| Step: 0
Training loss: 2.7344257459018837
Validation loss: 2.422995457853709

Epoch: 5| Step: 1
Training loss: 2.2600793777299364
Validation loss: 2.405467203306399

Epoch: 5| Step: 2
Training loss: 2.222603044727869
Validation loss: 2.4161644213658278

Epoch: 5| Step: 3
Training loss: 2.878427701226655
Validation loss: 2.3967676303626653

Epoch: 5| Step: 4
Training loss: 2.121364850164782
Validation loss: 2.421721800193816

Epoch: 5| Step: 5
Training loss: 2.357884321389194
Validation loss: 2.416802814912667

Epoch: 5| Step: 6
Training loss: 2.3433826412947862
Validation loss: 2.419417309441603

Epoch: 5| Step: 7
Training loss: 2.659653581132486
Validation loss: 2.426262230931538

Epoch: 5| Step: 8
Training loss: 2.5500446091284212
Validation loss: 2.412495298825758

Epoch: 5| Step: 9
Training loss: 2.630492685388671
Validation loss: 2.4145301933683703

Epoch: 5| Step: 10
Training loss: 2.1267899099452494
Validation loss: 2.4101080763426617

Epoch: 5| Step: 11
Training loss: 2.0583742665327573
Validation loss: 2.423068619968292

Epoch: 24| Step: 0
Training loss: 2.5162259918143928
Validation loss: 2.418359423964832

Epoch: 5| Step: 1
Training loss: 2.361326004671039
Validation loss: 2.418332649255398

Epoch: 5| Step: 2
Training loss: 1.933259137418023
Validation loss: 2.413925216376089

Epoch: 5| Step: 3
Training loss: 2.9074835671692756
Validation loss: 2.4101555492991578

Epoch: 5| Step: 4
Training loss: 2.184995252660836
Validation loss: 2.4121230605093693

Epoch: 5| Step: 5
Training loss: 2.347408744980201
Validation loss: 2.417785292461621

Epoch: 5| Step: 6
Training loss: 2.7076937482694983
Validation loss: 2.4109565275920235

Epoch: 5| Step: 7
Training loss: 3.042129969040632
Validation loss: 2.4141348958605082

Epoch: 5| Step: 8
Training loss: 2.181436582088974
Validation loss: 2.4137320636983026

Epoch: 5| Step: 9
Training loss: 2.4836833638898073
Validation loss: 2.4155034905289137

Epoch: 5| Step: 10
Training loss: 1.9048064347295846
Validation loss: 2.4073445815429517

Epoch: 5| Step: 11
Training loss: 2.5955587308173302
Validation loss: 2.4110904781044207

Epoch: 25| Step: 0
Training loss: 2.505920076415512
Validation loss: 2.4140497143518975

Epoch: 5| Step: 1
Training loss: 3.1626910969893323
Validation loss: 2.4209067552389527

Epoch: 5| Step: 2
Training loss: 2.188275009195403
Validation loss: 2.4262529366076

Epoch: 5| Step: 3
Training loss: 2.566499891271093
Validation loss: 2.432075655628098

Epoch: 5| Step: 4
Training loss: 2.0483180193823936
Validation loss: 2.4373616114073466

Epoch: 5| Step: 5
Training loss: 2.713906808449308
Validation loss: 2.4560248735260215

Epoch: 5| Step: 6
Training loss: 2.340414700400045
Validation loss: 2.4678471036844436

Epoch: 5| Step: 7
Training loss: 2.0421003023895596
Validation loss: 2.4481744441127167

Epoch: 5| Step: 8
Training loss: 2.5848568966359484
Validation loss: 2.4342571964578696

Epoch: 5| Step: 9
Training loss: 2.1469679366739403
Validation loss: 2.43265223774569

Epoch: 5| Step: 10
Training loss: 2.2688556657044794
Validation loss: 2.4389662815480517

Epoch: 5| Step: 11
Training loss: 2.2419986445944344
Validation loss: 2.439640124534366

Epoch: 26| Step: 0
Training loss: 3.157017076399605
Validation loss: 2.434504310558914

Epoch: 5| Step: 1
Training loss: 2.643850309304181
Validation loss: 2.4133101096361855

Epoch: 5| Step: 2
Training loss: 2.3412806408817537
Validation loss: 2.412940113164724

Epoch: 5| Step: 3
Training loss: 2.0564275415641595
Validation loss: 2.414399519586905

Epoch: 5| Step: 4
Training loss: 2.473811501947545
Validation loss: 2.407496496906419

Epoch: 5| Step: 5
Training loss: 1.832013941441091
Validation loss: 2.406609281329515

Epoch: 5| Step: 6
Training loss: 2.442649683353292
Validation loss: 2.413251804490368

Epoch: 5| Step: 7
Training loss: 2.4682180097051023
Validation loss: 2.4206100893304208

Epoch: 5| Step: 8
Training loss: 2.5165109910457772
Validation loss: 2.4076830531068847

Epoch: 5| Step: 9
Training loss: 2.236469380944133
Validation loss: 2.408165524311135

Epoch: 5| Step: 10
Training loss: 2.757256643670691
Validation loss: 2.4174887263368183

Epoch: 5| Step: 11
Training loss: 1.4177874824951797
Validation loss: 2.4199652617893217

Epoch: 27| Step: 0
Training loss: 2.2677633783204256
Validation loss: 2.4104613652504305

Epoch: 5| Step: 1
Training loss: 1.932420841091073
Validation loss: 2.407773872971675

Epoch: 5| Step: 2
Training loss: 2.7130602350350097
Validation loss: 2.433146538216531

Epoch: 5| Step: 3
Training loss: 2.9907015703976065
Validation loss: 2.420054836689644

Epoch: 5| Step: 4
Training loss: 3.110468533171427
Validation loss: 2.4286127728895237

Epoch: 5| Step: 5
Training loss: 2.2999667165255335
Validation loss: 2.441956419943303

Epoch: 5| Step: 6
Training loss: 1.83082544137848
Validation loss: 2.425022043295101

Epoch: 5| Step: 7
Training loss: 2.5169565219147567
Validation loss: 2.4430904469128905

Epoch: 5| Step: 8
Training loss: 2.345822651253247
Validation loss: 2.4529217556869916

Epoch: 5| Step: 9
Training loss: 2.440450789599643
Validation loss: 2.4447988655223813

Epoch: 5| Step: 10
Training loss: 2.1293625648791568
Validation loss: 2.457708175556561

Epoch: 5| Step: 11
Training loss: 1.5214705068717695
Validation loss: 2.4434037238837125

Epoch: 28| Step: 0
Training loss: 2.5330832165505766
Validation loss: 2.4427613223468736

Epoch: 5| Step: 1
Training loss: 2.507454059214211
Validation loss: 2.44072745690587

Epoch: 5| Step: 2
Training loss: 2.4418411721980813
Validation loss: 2.440951971895868

Epoch: 5| Step: 3
Training loss: 2.9922623986015933
Validation loss: 2.4353942293015156

Epoch: 5| Step: 4
Training loss: 2.3024602958246376
Validation loss: 2.439959495649905

Epoch: 5| Step: 5
Training loss: 2.3480636573233644
Validation loss: 2.424781714197544

Epoch: 5| Step: 6
Training loss: 2.2062129031080233
Validation loss: 2.416762540548813

Epoch: 5| Step: 7
Training loss: 1.8787074628267002
Validation loss: 2.4304046921609723

Epoch: 5| Step: 8
Training loss: 2.39031401961452
Validation loss: 2.423380406434978

Epoch: 5| Step: 9
Training loss: 2.0872191874141572
Validation loss: 2.4156380771876824

Epoch: 5| Step: 10
Training loss: 2.638844629106174
Validation loss: 2.4264899962516604

Epoch: 5| Step: 11
Training loss: 2.6122245533854036
Validation loss: 2.418267035997418

Epoch: 29| Step: 0
Training loss: 1.9028251399188785
Validation loss: 2.4132008542555856

Epoch: 5| Step: 1
Training loss: 2.289728165530023
Validation loss: 2.401006525958925

Epoch: 5| Step: 2
Training loss: 2.2623256468639736
Validation loss: 2.401449757702952

Epoch: 5| Step: 3
Training loss: 3.038644325493365
Validation loss: 2.4130324724820884

Epoch: 5| Step: 4
Training loss: 2.392225938683766
Validation loss: 2.4118561687724505

Epoch: 5| Step: 5
Training loss: 2.4650674709348195
Validation loss: 2.3964078808602527

Epoch: 5| Step: 6
Training loss: 2.5915475709623843
Validation loss: 2.395508028142613

Epoch: 5| Step: 7
Training loss: 2.42704467306058
Validation loss: 2.4045295798979045

Epoch: 5| Step: 8
Training loss: 2.508934459281804
Validation loss: 2.399847964100491

Epoch: 5| Step: 9
Training loss: 2.1751572212308594
Validation loss: 2.3981265219546968

Epoch: 5| Step: 10
Training loss: 2.070409808481145
Validation loss: 2.4185185913983887

Epoch: 5| Step: 11
Training loss: 3.484273182018539
Validation loss: 2.38622805831597

Epoch: 30| Step: 0
Training loss: 2.1165706397474127
Validation loss: 2.4104306061247387

Epoch: 5| Step: 1
Training loss: 2.4796496863748057
Validation loss: 2.4162734851856866

Epoch: 5| Step: 2
Training loss: 2.662231711181616
Validation loss: 2.412519618269193

Epoch: 5| Step: 3
Training loss: 1.6263768891803
Validation loss: 2.4193636065797635

Epoch: 5| Step: 4
Training loss: 2.344069090420605
Validation loss: 2.411061673809955

Epoch: 5| Step: 5
Training loss: 2.27853493266212
Validation loss: 2.4183758879224984

Epoch: 5| Step: 6
Training loss: 2.0996675137299454
Validation loss: 2.421426140813737

Epoch: 5| Step: 7
Training loss: 2.5686138070564493
Validation loss: 2.429239399384375

Epoch: 5| Step: 8
Training loss: 2.9766781601749788
Validation loss: 2.4443822397339265

Epoch: 5| Step: 9
Training loss: 2.288435606017391
Validation loss: 2.4313059503741603

Epoch: 5| Step: 10
Training loss: 2.588850057999253
Validation loss: 2.4393563619154603

Epoch: 5| Step: 11
Training loss: 3.076556895547841
Validation loss: 2.4096051188282317

Epoch: 31| Step: 0
Training loss: 2.4837580460608617
Validation loss: 2.421555151379142

Epoch: 5| Step: 1
Training loss: 2.6745589311560902
Validation loss: 2.426220324303859

Epoch: 5| Step: 2
Training loss: 2.829023355516375
Validation loss: 2.4260769191379326

Epoch: 5| Step: 3
Training loss: 2.6534454799159666
Validation loss: 2.405280838693106

Epoch: 5| Step: 4
Training loss: 2.408650476590094
Validation loss: 2.407415479323176

Epoch: 5| Step: 5
Training loss: 2.059363320857318
Validation loss: 2.4117369741417116

Epoch: 5| Step: 6
Training loss: 2.607120019249073
Validation loss: 2.4167875343275016

Epoch: 5| Step: 7
Training loss: 1.904596956524655
Validation loss: 2.3928533652668236

Epoch: 5| Step: 8
Training loss: 2.315147122019298
Validation loss: 2.3965240367456246

Epoch: 5| Step: 9
Training loss: 2.0376748226499064
Validation loss: 2.3956726863463094

Epoch: 5| Step: 10
Training loss: 2.3827206453222796
Validation loss: 2.4085609972460493

Epoch: 5| Step: 11
Training loss: 2.0898950873513376
Validation loss: 2.4122843196300288

Epoch: 32| Step: 0
Training loss: 2.5285708530570075
Validation loss: 2.39731950413927

Epoch: 5| Step: 1
Training loss: 2.792164848248563
Validation loss: 2.4094552907004982

Epoch: 5| Step: 2
Training loss: 2.4419212347476376
Validation loss: 2.4068784058324795

Epoch: 5| Step: 3
Training loss: 2.1467280574968592
Validation loss: 2.4101670984717525

Epoch: 5| Step: 4
Training loss: 2.5664817764107895
Validation loss: 2.4191019240846607

Epoch: 5| Step: 5
Training loss: 2.2147734561913452
Validation loss: 2.424553483151128

Epoch: 5| Step: 6
Training loss: 2.5043560225184467
Validation loss: 2.4262683418277664

Epoch: 5| Step: 7
Training loss: 2.624844046910095
Validation loss: 2.4456275537920917

Epoch: 5| Step: 8
Training loss: 2.0690463818992653
Validation loss: 2.4342840286252674

Epoch: 5| Step: 9
Training loss: 1.8297439318912154
Validation loss: 2.4491600990877966

Epoch: 5| Step: 10
Training loss: 2.348723564060082
Validation loss: 2.425460999050959

Epoch: 5| Step: 11
Training loss: 2.9195841412120984
Validation loss: 2.4307552293473194

Epoch: 33| Step: 0
Training loss: 2.1887187287576495
Validation loss: 2.4384261963653313

Epoch: 5| Step: 1
Training loss: 2.1783226416086356
Validation loss: 2.423011740663936

Epoch: 5| Step: 2
Training loss: 2.2645414721127226
Validation loss: 2.4343834825856834

Epoch: 5| Step: 3
Training loss: 2.9188213200810305
Validation loss: 2.412731515649889

Epoch: 5| Step: 4
Training loss: 2.4976684188188374
Validation loss: 2.4083119739313474

Epoch: 5| Step: 5
Training loss: 2.8905941523375143
Validation loss: 2.4085324514192012

Epoch: 5| Step: 6
Training loss: 2.7933409116121735
Validation loss: 2.4092391426451636

Epoch: 5| Step: 7
Training loss: 2.0700902279709736
Validation loss: 2.3881844132091237

Epoch: 5| Step: 8
Training loss: 2.632419636107428
Validation loss: 2.4021029426610254

Epoch: 5| Step: 9
Training loss: 1.9295736425995682
Validation loss: 2.4000359612823794

Epoch: 5| Step: 10
Training loss: 1.742180794330915
Validation loss: 2.396534138613368

Epoch: 5| Step: 11
Training loss: 3.0711041466093736
Validation loss: 2.399406080138245

Epoch: 34| Step: 0
Training loss: 1.8298883003790187
Validation loss: 2.399261958334489

Epoch: 5| Step: 1
Training loss: 2.345038911541356
Validation loss: 2.4008294933738132

Epoch: 5| Step: 2
Training loss: 2.3356334271481822
Validation loss: 2.393776742073661

Epoch: 5| Step: 3
Training loss: 2.0515263248458804
Validation loss: 2.3938875977200946

Epoch: 5| Step: 4
Training loss: 2.466641068540525
Validation loss: 2.4091205607708357

Epoch: 5| Step: 5
Training loss: 2.1943359375
Validation loss: 2.3955682621702725

Epoch: 5| Step: 6
Training loss: 2.7830039505212607
Validation loss: 2.3899630105808662

Epoch: 5| Step: 7
Training loss: 2.8038253096501773
Validation loss: 2.3955341871063873

Epoch: 5| Step: 8
Training loss: 2.4380988339113077
Validation loss: 2.3945723421720624

Epoch: 5| Step: 9
Training loss: 2.2208226154157034
Validation loss: 2.4122375413046653

Epoch: 5| Step: 10
Training loss: 2.8506771019487975
Validation loss: 2.405899075932413

Epoch: 5| Step: 11
Training loss: 1.8718388931281966
Validation loss: 2.398976989112586

Epoch: 35| Step: 0
Training loss: 2.6543520261355504
Validation loss: 2.4012193296877586

Epoch: 5| Step: 1
Training loss: 2.6000475438979542
Validation loss: 2.386859612852731

Epoch: 5| Step: 2
Training loss: 2.4790967616208537
Validation loss: 2.3995959893888825

Epoch: 5| Step: 3
Training loss: 2.6055721508366125
Validation loss: 2.400759385921064

Epoch: 5| Step: 4
Training loss: 1.9850246537452785
Validation loss: 2.393473889053141

Epoch: 5| Step: 5
Training loss: 2.4968440162541006
Validation loss: 2.4102962129697856

Epoch: 5| Step: 6
Training loss: 2.1445803888524413
Validation loss: 2.4024602598144664

Epoch: 5| Step: 7
Training loss: 1.783567159540552
Validation loss: 2.401837481158451

Epoch: 5| Step: 8
Training loss: 2.5297503326322306
Validation loss: 2.4005505803663185

Epoch: 5| Step: 9
Training loss: 2.4692076246830124
Validation loss: 2.3962598600667273

Epoch: 5| Step: 10
Training loss: 2.509428365289597
Validation loss: 2.39735911270275

Epoch: 5| Step: 11
Training loss: 1.4742470807788417
Validation loss: 2.394861855016907

Epoch: 36| Step: 0
Training loss: 2.623958290123318
Validation loss: 2.405250705121634

Epoch: 5| Step: 1
Training loss: 2.287541010754782
Validation loss: 2.391680723297423

Epoch: 5| Step: 2
Training loss: 1.7586024565038463
Validation loss: 2.4039966179878935

Epoch: 5| Step: 3
Training loss: 2.3665952035922864
Validation loss: 2.401731360312231

Epoch: 5| Step: 4
Training loss: 2.0613825689820717
Validation loss: 2.3902667365138393

Epoch: 5| Step: 5
Training loss: 2.60902219660109
Validation loss: 2.392249596286277

Epoch: 5| Step: 6
Training loss: 3.205209639859649
Validation loss: 2.4090132844626466

Epoch: 5| Step: 7
Training loss: 2.115292084277403
Validation loss: 2.4097087327162448

Epoch: 5| Step: 8
Training loss: 2.3103693864099215
Validation loss: 2.380256833195181

Epoch: 5| Step: 9
Training loss: 2.635717402451548
Validation loss: 2.4079972524888658

Epoch: 5| Step: 10
Training loss: 1.9278621921080468
Validation loss: 2.4159908308824645

Epoch: 5| Step: 11
Training loss: 1.0977182608359621
Validation loss: 2.405040874794749

Epoch: 37| Step: 0
Training loss: 1.9915495804828978
Validation loss: 2.401766964695225

Epoch: 5| Step: 1
Training loss: 2.8136182469314015
Validation loss: 2.416429632718995

Epoch: 5| Step: 2
Training loss: 2.3507444663448696
Validation loss: 2.4146636206241516

Epoch: 5| Step: 3
Training loss: 2.1983420757305927
Validation loss: 2.4229103746493754

Epoch: 5| Step: 4
Training loss: 2.3217187595296833
Validation loss: 2.4177023392164307

Epoch: 5| Step: 5
Training loss: 2.77193537047486
Validation loss: 2.4111283957491274

Epoch: 5| Step: 6
Training loss: 2.4702043715958344
Validation loss: 2.4090643088292363

Epoch: 5| Step: 7
Training loss: 2.4814779796649438
Validation loss: 2.4171626524746466

Epoch: 5| Step: 8
Training loss: 2.044239239944629
Validation loss: 2.401093477585205

Epoch: 5| Step: 9
Training loss: 2.5706951934780204
Validation loss: 2.4119902052379962

Epoch: 5| Step: 10
Training loss: 1.678639781568955
Validation loss: 2.4194521813780505

Epoch: 5| Step: 11
Training loss: 2.606035391115653
Validation loss: 2.417841577754834

Epoch: 38| Step: 0
Training loss: 2.4604744611816636
Validation loss: 2.418328882369299

Epoch: 5| Step: 1
Training loss: 1.7864349259899597
Validation loss: 2.443351617521783

Epoch: 5| Step: 2
Training loss: 2.0064292328534727
Validation loss: 2.458239700398483

Epoch: 5| Step: 3
Training loss: 2.8688944794751152
Validation loss: 2.477230371057971

Epoch: 5| Step: 4
Training loss: 2.6907997278418927
Validation loss: 2.4641095945719487

Epoch: 5| Step: 5
Training loss: 2.6870467225113037
Validation loss: 2.4684807473641706

Epoch: 5| Step: 6
Training loss: 2.1160075710932778
Validation loss: 2.4471623306821426

Epoch: 5| Step: 7
Training loss: 1.9685902606404233
Validation loss: 2.4414370562835037

Epoch: 5| Step: 8
Training loss: 2.393366619115955
Validation loss: 2.4263433643637167

Epoch: 5| Step: 9
Training loss: 2.629318590404634
Validation loss: 2.418822557345125

Epoch: 5| Step: 10
Training loss: 2.5428264244085574
Validation loss: 2.4043262354909376

Epoch: 5| Step: 11
Training loss: 1.649671625927012
Validation loss: 2.398757039341911

Epoch: 39| Step: 0
Training loss: 2.1877740960741083
Validation loss: 2.395491429825094

Epoch: 5| Step: 1
Training loss: 2.3339830470380636
Validation loss: 2.3953948462777435

Epoch: 5| Step: 2
Training loss: 2.3267656492512616
Validation loss: 2.4123418451428478

Epoch: 5| Step: 3
Training loss: 2.193105110519638
Validation loss: 2.41203724371053

Epoch: 5| Step: 4
Training loss: 2.473068709119675
Validation loss: 2.4014753679540766

Epoch: 5| Step: 5
Training loss: 2.265203502515038
Validation loss: 2.3846134925615687

Epoch: 5| Step: 6
Training loss: 2.1467524908612643
Validation loss: 2.4002051492603753

Epoch: 5| Step: 7
Training loss: 2.924869084485142
Validation loss: 2.413146617851524

Epoch: 5| Step: 8
Training loss: 2.281617853475221
Validation loss: 2.39754317816556

Epoch: 5| Step: 9
Training loss: 2.523244466573154
Validation loss: 2.4099885809068566

Epoch: 5| Step: 10
Training loss: 1.9496743199226554
Validation loss: 2.405061552168137

Epoch: 5| Step: 11
Training loss: 3.5665249757757245
Validation loss: 2.4102427643798334

Epoch: 40| Step: 0
Training loss: 2.731190511025078
Validation loss: 2.4013005459807464

Epoch: 5| Step: 1
Training loss: 2.635104395845059
Validation loss: 2.3964836557931815

Epoch: 5| Step: 2
Training loss: 2.6378552057528353
Validation loss: 2.391051524473989

Epoch: 5| Step: 3
Training loss: 1.9752056304502212
Validation loss: 2.3883817657192794

Epoch: 5| Step: 4
Training loss: 2.3927181280785645
Validation loss: 2.4129336082743364

Epoch: 5| Step: 5
Training loss: 1.8502420473271894
Validation loss: 2.4181838671710785

Epoch: 5| Step: 6
Training loss: 2.490959223550951
Validation loss: 2.4170315908180684

Epoch: 5| Step: 7
Training loss: 2.50438258361049
Validation loss: 2.4136509426197263

Epoch: 5| Step: 8
Training loss: 2.331062972106403
Validation loss: 2.418113790423494

Epoch: 5| Step: 9
Training loss: 1.8377675127718838
Validation loss: 2.40942900251206

Epoch: 5| Step: 10
Training loss: 2.56535571005824
Validation loss: 2.4186369301901958

Epoch: 5| Step: 11
Training loss: 2.0252684332867275
Validation loss: 2.425652484680748

Epoch: 41| Step: 0
Training loss: 2.246209660732012
Validation loss: 2.4211960733067377

Epoch: 5| Step: 1
Training loss: 2.793251972910335
Validation loss: 2.4089556217307555

Epoch: 5| Step: 2
Training loss: 2.0946751159183514
Validation loss: 2.4195650138794296

Epoch: 5| Step: 3
Training loss: 2.4027979475680343
Validation loss: 2.4098762749402547

Epoch: 5| Step: 4
Training loss: 2.371519550131108
Validation loss: 2.4236258689561003

Epoch: 5| Step: 5
Training loss: 2.666505828616433
Validation loss: 2.4193086994165633

Epoch: 5| Step: 6
Training loss: 2.0201887170999036
Validation loss: 2.4173440244300273

Epoch: 5| Step: 7
Training loss: 2.68060642868372
Validation loss: 2.4140829313827132

Epoch: 5| Step: 8
Training loss: 2.139554835212994
Validation loss: 2.3907897867492003

Epoch: 5| Step: 9
Training loss: 2.367465465579781
Validation loss: 2.4141117160887053

Epoch: 5| Step: 10
Training loss: 2.071274559045757
Validation loss: 2.4049557801210857

Epoch: 5| Step: 11
Training loss: 1.3240904169153453
Validation loss: 2.406988377422994

Epoch: 42| Step: 0
Training loss: 2.2727544748238935
Validation loss: 2.4216831582495226

Epoch: 5| Step: 1
Training loss: 2.3589277032929163
Validation loss: 2.408118189509926

Epoch: 5| Step: 2
Training loss: 2.002034702034566
Validation loss: 2.3939336888855673

Epoch: 5| Step: 3
Training loss: 2.2388885366577846
Validation loss: 2.3984428347715676

Epoch: 5| Step: 4
Training loss: 3.0133468640566616
Validation loss: 2.4045668408331684

Epoch: 5| Step: 5
Training loss: 2.538385013280486
Validation loss: 2.4125218047835046

Epoch: 5| Step: 6
Training loss: 2.606755660880207
Validation loss: 2.400907501697961

Epoch: 5| Step: 7
Training loss: 1.7185168021398745
Validation loss: 2.383782840623228

Epoch: 5| Step: 8
Training loss: 2.628391617939271
Validation loss: 2.4017349546912974

Epoch: 5| Step: 9
Training loss: 2.469135109524571
Validation loss: 2.392177958337586

Epoch: 5| Step: 10
Training loss: 1.8565836237354372
Validation loss: 2.3941988649492476

Epoch: 5| Step: 11
Training loss: 1.1802526471852304
Validation loss: 2.390950980639776

Epoch: 43| Step: 0
Training loss: 2.315308489256052
Validation loss: 2.4071494976756336

Epoch: 5| Step: 1
Training loss: 2.328535926959442
Validation loss: 2.4167135963048745

Epoch: 5| Step: 2
Training loss: 2.073739838854066
Validation loss: 2.4184146155726167

Epoch: 5| Step: 3
Training loss: 2.641593981042725
Validation loss: 2.42377367555342

Epoch: 5| Step: 4
Training loss: 1.9053189239468737
Validation loss: 2.4381877018710862

Epoch: 5| Step: 5
Training loss: 2.0550613353328364
Validation loss: 2.422989996743161

Epoch: 5| Step: 6
Training loss: 2.8937000311539367
Validation loss: 2.4348841104208243

Epoch: 5| Step: 7
Training loss: 2.268210783634665
Validation loss: 2.4241692822681458

Epoch: 5| Step: 8
Training loss: 2.4681443062918564
Validation loss: 2.422484581638764

Epoch: 5| Step: 9
Training loss: 2.2350432990400844
Validation loss: 2.431319004834924

Epoch: 5| Step: 10
Training loss: 2.4055404607795032
Validation loss: 2.4232155361059196

Epoch: 5| Step: 11
Training loss: 2.713605551721184
Validation loss: 2.4255121955174417

Epoch: 44| Step: 0
Training loss: 2.416874997158953
Validation loss: 2.41528593005554

Epoch: 5| Step: 1
Training loss: 2.382398925910897
Validation loss: 2.4191086793122087

Epoch: 5| Step: 2
Training loss: 2.2515939788417985
Validation loss: 2.3838071946149015

Epoch: 5| Step: 3
Training loss: 1.935266807456556
Validation loss: 2.4079320857679876

Epoch: 5| Step: 4
Training loss: 2.6865073744010424
Validation loss: 2.4207872963060817

Epoch: 5| Step: 5
Training loss: 2.4669691978544934
Validation loss: 2.4064486677552357

Epoch: 5| Step: 6
Training loss: 2.236389532453848
Validation loss: 2.416584610916183

Epoch: 5| Step: 7
Training loss: 2.028607689266681
Validation loss: 2.4099560927049093

Epoch: 5| Step: 8
Training loss: 3.1273196956825355
Validation loss: 2.4277953234607628

Epoch: 5| Step: 9
Training loss: 1.769795446483519
Validation loss: 2.400076576342427

Epoch: 5| Step: 10
Training loss: 2.2049889221259136
Validation loss: 2.396096353329427

Epoch: 5| Step: 11
Training loss: 1.661793626139445
Validation loss: 2.3938130499070245

Epoch: 45| Step: 0
Training loss: 1.9958974962001768
Validation loss: 2.4050926794169665

Epoch: 5| Step: 1
Training loss: 1.795685548594676
Validation loss: 2.396697619629135

Epoch: 5| Step: 2
Training loss: 2.1957311265045916
Validation loss: 2.4037829876939134

Epoch: 5| Step: 3
Training loss: 2.9055703301557587
Validation loss: 2.432445440938344

Epoch: 5| Step: 4
Training loss: 2.437488458068126
Validation loss: 2.418393146614078

Epoch: 5| Step: 5
Training loss: 2.593533610314235
Validation loss: 2.4097440522720044

Epoch: 5| Step: 6
Training loss: 2.559055339147788
Validation loss: 2.435484068834951

Epoch: 5| Step: 7
Training loss: 2.0173089142300764
Validation loss: 2.4153846116105306

Epoch: 5| Step: 8
Training loss: 2.2643347914071597
Validation loss: 2.432649861058518

Epoch: 5| Step: 9
Training loss: 2.5632931482003456
Validation loss: 2.4234408946108825

Epoch: 5| Step: 10
Training loss: 2.1829001975004068
Validation loss: 2.414909901284196

Epoch: 5| Step: 11
Training loss: 2.4017897052296173
Validation loss: 2.4250267194475374

Epoch: 46| Step: 0
Training loss: 2.563244688173842
Validation loss: 2.3948485209378365

Epoch: 5| Step: 1
Training loss: 2.223904384938433
Validation loss: 2.38951442827577

Epoch: 5| Step: 2
Training loss: 2.4839519404432204
Validation loss: 2.3741988516489725

Epoch: 5| Step: 3
Training loss: 2.419620670665319
Validation loss: 2.396178060415862

Epoch: 5| Step: 4
Training loss: 2.391128985567813
Validation loss: 2.395487488096564

Epoch: 5| Step: 5
Training loss: 2.171025281487451
Validation loss: 2.3892071826702947

Epoch: 5| Step: 6
Training loss: 2.3096561988523256
Validation loss: 2.384583093654397

Epoch: 5| Step: 7
Training loss: 1.8068086123335763
Validation loss: 2.389716405802207

Epoch: 5| Step: 8
Training loss: 2.6098225832157707
Validation loss: 2.399396180813517

Epoch: 5| Step: 9
Training loss: 2.3068152998664098
Validation loss: 2.406240785259091

Epoch: 5| Step: 10
Training loss: 2.4252588074998744
Validation loss: 2.401894483451692

Epoch: 5| Step: 11
Training loss: 1.2961279314441918
Validation loss: 2.3942533480094474

Epoch: 47| Step: 0
Training loss: 2.881871180898948
Validation loss: 2.418934248774595

Epoch: 5| Step: 1
Training loss: 2.4663981570768696
Validation loss: 2.4225821887942818

Epoch: 5| Step: 2
Training loss: 2.2484260988244644
Validation loss: 2.4048736029301203

Epoch: 5| Step: 3
Training loss: 2.1727659744379495
Validation loss: 2.4093475695647113

Epoch: 5| Step: 4
Training loss: 2.072397815683904
Validation loss: 2.4039757826894967

Epoch: 5| Step: 5
Training loss: 2.0358352553485672
Validation loss: 2.405541245418191

Epoch: 5| Step: 6
Training loss: 2.0971967879459013
Validation loss: 2.411208376003616

Epoch: 5| Step: 7
Training loss: 2.3391270120881464
Validation loss: 2.4109109493465732

Epoch: 5| Step: 8
Training loss: 1.995231666212089
Validation loss: 2.41957461924161

Epoch: 5| Step: 9
Training loss: 2.3158352487434226
Validation loss: 2.41320237121073

Epoch: 5| Step: 10
Training loss: 2.5539295810440117
Validation loss: 2.415287583487038

Epoch: 5| Step: 11
Training loss: 3.0858976337416992
Validation loss: 2.402892424825678

Epoch: 48| Step: 0
Training loss: 2.2618861424724255
Validation loss: 2.407734297518615

Epoch: 5| Step: 1
Training loss: 2.364812786604055
Validation loss: 2.4083859430218504

Epoch: 5| Step: 2
Training loss: 2.375500375338561
Validation loss: 2.393259294560312

Epoch: 5| Step: 3
Training loss: 2.101544121303814
Validation loss: 2.3872796714271187

Epoch: 5| Step: 4
Training loss: 2.2060845159006006
Validation loss: 2.4209405019044024

Epoch: 5| Step: 5
Training loss: 2.007249211362379
Validation loss: 2.4151671309192193

Epoch: 5| Step: 6
Training loss: 2.4251469321815695
Validation loss: 2.426851238291919

Epoch: 5| Step: 7
Training loss: 2.0898949732697325
Validation loss: 2.424139033113404

Epoch: 5| Step: 8
Training loss: 2.5454361484531587
Validation loss: 2.4388110474141533

Epoch: 5| Step: 9
Training loss: 2.8012726377962336
Validation loss: 2.426690406809824

Epoch: 5| Step: 10
Training loss: 2.1404150421312655
Validation loss: 2.433882408922448

Epoch: 5| Step: 11
Training loss: 2.7008413911169797
Validation loss: 2.416123340768149

Epoch: 49| Step: 0
Training loss: 2.1278382588492843
Validation loss: 2.3971409062880955

Epoch: 5| Step: 1
Training loss: 2.515178569726186
Validation loss: 2.397591245881908

Epoch: 5| Step: 2
Training loss: 2.2961109992719826
Validation loss: 2.380740787847999

Epoch: 5| Step: 3
Training loss: 2.082980342206346
Validation loss: 2.4082032528784665

Epoch: 5| Step: 4
Training loss: 2.271076877611367
Validation loss: 2.4041036470859587

Epoch: 5| Step: 5
Training loss: 2.282248813976089
Validation loss: 2.4170234159256787

Epoch: 5| Step: 6
Training loss: 2.4912347676547912
Validation loss: 2.413625099365595

Epoch: 5| Step: 7
Training loss: 2.119926567065415
Validation loss: 2.390371259300506

Epoch: 5| Step: 8
Training loss: 2.1900407477293857
Validation loss: 2.4035106440446588

Epoch: 5| Step: 9
Training loss: 2.225834135081343
Validation loss: 2.3965998826174837

Epoch: 5| Step: 10
Training loss: 3.0581512715739065
Validation loss: 2.390173659592807

Epoch: 5| Step: 11
Training loss: 1.7281068135247908
Validation loss: 2.3936616273707525

Epoch: 50| Step: 0
Training loss: 2.2389430587227173
Validation loss: 2.3997938315927674

Epoch: 5| Step: 1
Training loss: 2.1798817537768462
Validation loss: 2.400502213940894

Epoch: 5| Step: 2
Training loss: 2.3766589143295795
Validation loss: 2.400088703814365

Epoch: 5| Step: 3
Training loss: 2.5694899706773757
Validation loss: 2.4190733609672104

Epoch: 5| Step: 4
Training loss: 2.17370210266868
Validation loss: 2.425514091813806

Epoch: 5| Step: 5
Training loss: 2.3909655559041965
Validation loss: 2.4440482103978467

Epoch: 5| Step: 6
Training loss: 2.083771341691685
Validation loss: 2.4383502683575093

Epoch: 5| Step: 7
Training loss: 2.9773532888299212
Validation loss: 2.447599318745585

Epoch: 5| Step: 8
Training loss: 1.854505429413953
Validation loss: 2.4466915933948616

Epoch: 5| Step: 9
Training loss: 2.348466120968725
Validation loss: 2.4481553806760084

Epoch: 5| Step: 10
Training loss: 2.194763875265439
Validation loss: 2.437540074369519

Epoch: 5| Step: 11
Training loss: 1.1585284286060078
Validation loss: 2.4115935233487114

Epoch: 51| Step: 0
Training loss: 2.9979051587535834
Validation loss: 2.427231932799376

Epoch: 5| Step: 1
Training loss: 2.410967079915653
Validation loss: 2.4173647034125954

Epoch: 5| Step: 2
Training loss: 1.908385222227904
Validation loss: 2.3982237348859665

Epoch: 5| Step: 3
Training loss: 2.0504815164145507
Validation loss: 2.395950726383485

Epoch: 5| Step: 4
Training loss: 2.486610989837919
Validation loss: 2.3900756828144254

Epoch: 5| Step: 5
Training loss: 2.5017650095776327
Validation loss: 2.3867343791776676

Epoch: 5| Step: 6
Training loss: 2.2724198098717068
Validation loss: 2.3844220171384545

Epoch: 5| Step: 7
Training loss: 1.9225809925018744
Validation loss: 2.381861191423185

Epoch: 5| Step: 8
Training loss: 2.309525716403479
Validation loss: 2.386582740616941

Epoch: 5| Step: 9
Training loss: 2.120887816603046
Validation loss: 2.3975909392725137

Epoch: 5| Step: 10
Training loss: 2.4489858902960506
Validation loss: 2.3866842613912493

Epoch: 5| Step: 11
Training loss: 1.8804391805545124
Validation loss: 2.3821038948743283

Epoch: 52| Step: 0
Training loss: 3.1317188513446075
Validation loss: 2.411035394895826

Epoch: 5| Step: 1
Training loss: 2.562521585513126
Validation loss: 2.4051927498012065

Epoch: 5| Step: 2
Training loss: 1.4078350035703162
Validation loss: 2.403785616087959

Epoch: 5| Step: 3
Training loss: 2.5514988028710195
Validation loss: 2.406959971844184

Epoch: 5| Step: 4
Training loss: 1.9937939917036964
Validation loss: 2.3959455705696424

Epoch: 5| Step: 5
Training loss: 1.5265817912355797
Validation loss: 2.4202894209304624

Epoch: 5| Step: 6
Training loss: 2.461827677232941
Validation loss: 2.427474683445592

Epoch: 5| Step: 7
Training loss: 1.8251604349346202
Validation loss: 2.406128281656566

Epoch: 5| Step: 8
Training loss: 2.4011681137936725
Validation loss: 2.440257139238674

Epoch: 5| Step: 9
Training loss: 2.088273929421851
Validation loss: 2.420405674342103

Epoch: 5| Step: 10
Training loss: 2.4002343818339984
Validation loss: 2.4155819461764265

Epoch: 5| Step: 11
Training loss: 3.220774190013426
Validation loss: 2.396784410501368

Epoch: 53| Step: 0
Training loss: 2.143993539572704
Validation loss: 2.3991053104030264

Epoch: 5| Step: 1
Training loss: 2.6669143223998106
Validation loss: 2.389398958553542

Epoch: 5| Step: 2
Training loss: 2.0428326709131364
Validation loss: 2.398459586622701

Epoch: 5| Step: 3
Training loss: 2.035227475960918
Validation loss: 2.4046892950635015

Epoch: 5| Step: 4
Training loss: 1.956512016811264
Validation loss: 2.4182874729363735

Epoch: 5| Step: 5
Training loss: 2.446207486008845
Validation loss: 2.4302076414662954

Epoch: 5| Step: 6
Training loss: 2.2661562592718023
Validation loss: 2.423251427451714

Epoch: 5| Step: 7
Training loss: 2.594091737594143
Validation loss: 2.4393253868179845

Epoch: 5| Step: 8
Training loss: 2.565723624523449
Validation loss: 2.432173374139416

Epoch: 5| Step: 9
Training loss: 2.685342765681051
Validation loss: 2.4144726335911737

Epoch: 5| Step: 10
Training loss: 2.5257555822548436
Validation loss: 2.416300410162389

Epoch: 5| Step: 11
Training loss: 2.118762454556119
Validation loss: 2.3961393008915377

Epoch: 54| Step: 0
Training loss: 2.3302072519621873
Validation loss: 2.3898900924068527

Epoch: 5| Step: 1
Training loss: 2.587184916307339
Validation loss: 2.384718194396668

Epoch: 5| Step: 2
Training loss: 1.8007727765527326
Validation loss: 2.400829720951776

Epoch: 5| Step: 3
Training loss: 1.68130500448221
Validation loss: 2.4313544027046916

Epoch: 5| Step: 4
Training loss: 2.5629197684004494
Validation loss: 2.462706407458522

Epoch: 5| Step: 5
Training loss: 1.9179060978183546
Validation loss: 2.473127957910185

Epoch: 5| Step: 6
Training loss: 2.7126424303763526
Validation loss: 2.504103674125411

Epoch: 5| Step: 7
Training loss: 3.1124952752870296
Validation loss: 2.536532043910835

Epoch: 5| Step: 8
Training loss: 2.159729513610547
Validation loss: 2.476205124125062

Epoch: 5| Step: 9
Training loss: 2.263225468615434
Validation loss: 2.462948406448215

Epoch: 5| Step: 10
Training loss: 2.1132671475600966
Validation loss: 2.438580958003545

Epoch: 5| Step: 11
Training loss: 2.202503197761838
Validation loss: 2.413213529137785

Epoch: 55| Step: 0
Training loss: 2.1490461007663364
Validation loss: 2.4055069895066397

Epoch: 5| Step: 1
Training loss: 2.419485180532908
Validation loss: 2.405391707244325

Epoch: 5| Step: 2
Training loss: 2.4140341550280198
Validation loss: 2.3987707285559416

Epoch: 5| Step: 3
Training loss: 1.9977916804397922
Validation loss: 2.3753149760672967

Epoch: 5| Step: 4
Training loss: 2.6797897274881524
Validation loss: 2.3737196482746317

Epoch: 5| Step: 5
Training loss: 2.3719697996150044
Validation loss: 2.3812690071622282

Epoch: 5| Step: 6
Training loss: 2.5481390127470855
Validation loss: 2.39439824426186

Epoch: 5| Step: 7
Training loss: 2.2930966395207055
Validation loss: 2.403330809482311

Epoch: 5| Step: 8
Training loss: 2.07591439747219
Validation loss: 2.3982577385983173

Epoch: 5| Step: 9
Training loss: 2.2289257691842703
Validation loss: 2.3912077174857904

Epoch: 5| Step: 10
Training loss: 2.1659930600365986
Validation loss: 2.3775097485973204

Epoch: 5| Step: 11
Training loss: 0.889315093617173
Validation loss: 2.3905296826111897

Epoch: 56| Step: 0
Training loss: 1.794236343856959
Validation loss: 2.3804748157824145

Epoch: 5| Step: 1
Training loss: 2.7113559191122403
Validation loss: 2.3790778070569796

Epoch: 5| Step: 2
Training loss: 2.2671774971108376
Validation loss: 2.3919452769681744

Epoch: 5| Step: 3
Training loss: 2.4944265227133022
Validation loss: 2.398067031562711

Epoch: 5| Step: 4
Training loss: 2.3070234454236425
Validation loss: 2.394570433818252

Epoch: 5| Step: 5
Training loss: 2.427217558940726
Validation loss: 2.398868041686583

Epoch: 5| Step: 6
Training loss: 2.4348730946395363
Validation loss: 2.407376079545681

Epoch: 5| Step: 7
Training loss: 1.8726011189353213
Validation loss: 2.4117721960309697

Epoch: 5| Step: 8
Training loss: 2.1205093955794494
Validation loss: 2.4066505924367863

Epoch: 5| Step: 9
Training loss: 2.461630490535904
Validation loss: 2.4327589800498424

Epoch: 5| Step: 10
Training loss: 1.9699701433775463
Validation loss: 2.4151966842054104

Epoch: 5| Step: 11
Training loss: 2.3508960882188177
Validation loss: 2.440114160040249

Epoch: 57| Step: 0
Training loss: 2.002137353375389
Validation loss: 2.4147629755506617

Epoch: 5| Step: 1
Training loss: 2.6387436163105407
Validation loss: 2.415338205911535

Epoch: 5| Step: 2
Training loss: 2.1582377021056516
Validation loss: 2.4290770840253035

Epoch: 5| Step: 3
Training loss: 2.564141747774378
Validation loss: 2.424015733629123

Epoch: 5| Step: 4
Training loss: 2.2235750200068334
Validation loss: 2.4024276884141234

Epoch: 5| Step: 5
Training loss: 2.0714269553492963
Validation loss: 2.403338706473042

Epoch: 5| Step: 6
Training loss: 1.9392114894043448
Validation loss: 2.3729026007521465

Epoch: 5| Step: 7
Training loss: 2.1485996254524444
Validation loss: 2.378836803539675

Epoch: 5| Step: 8
Training loss: 2.378018518938828
Validation loss: 2.3812633168606587

Epoch: 5| Step: 9
Training loss: 2.4673885019575423
Validation loss: 2.3718446949097918

Epoch: 5| Step: 10
Training loss: 2.3379003130999663
Validation loss: 2.3816973301929263

Epoch: 5| Step: 11
Training loss: 1.8891555498174972
Validation loss: 2.367714071092032

Epoch: 58| Step: 0
Training loss: 2.0675723962435986
Validation loss: 2.383845940035982

Epoch: 5| Step: 1
Training loss: 3.096254664245468
Validation loss: 2.3928952252198283

Epoch: 5| Step: 2
Training loss: 2.5493825725976955
Validation loss: 2.400634086973721

Epoch: 5| Step: 3
Training loss: 2.2901156870176487
Validation loss: 2.4129256212330406

Epoch: 5| Step: 4
Training loss: 2.068140582074662
Validation loss: 2.393217510503555

Epoch: 5| Step: 5
Training loss: 2.0263685993970983
Validation loss: 2.406556943827494

Epoch: 5| Step: 6
Training loss: 2.4179350275945084
Validation loss: 2.377944747804005

Epoch: 5| Step: 7
Training loss: 1.9923446892451993
Validation loss: 2.399634134201197

Epoch: 5| Step: 8
Training loss: 2.0115967945057407
Validation loss: 2.3921558448628937

Epoch: 5| Step: 9
Training loss: 2.3918608419389553
Validation loss: 2.412979105086272

Epoch: 5| Step: 10
Training loss: 1.7761590719338363
Validation loss: 2.3969724179447334

Epoch: 5| Step: 11
Training loss: 1.2530883783711304
Validation loss: 2.391580149839119

Epoch: 59| Step: 0
Training loss: 2.030763538503783
Validation loss: 2.397198409800493

Epoch: 5| Step: 1
Training loss: 2.2292962675359473
Validation loss: 2.411149111559135

Epoch: 5| Step: 2
Training loss: 2.852825397249608
Validation loss: 2.3821330826827674

Epoch: 5| Step: 3
Training loss: 2.5600718647585405
Validation loss: 2.3698300969846917

Epoch: 5| Step: 4
Training loss: 1.936409797354319
Validation loss: 2.3789238534995354

Epoch: 5| Step: 5
Training loss: 2.3120152764459165
Validation loss: 2.3969044730385773

Epoch: 5| Step: 6
Training loss: 2.00477328514603
Validation loss: 2.3880194633144387

Epoch: 5| Step: 7
Training loss: 2.04800290779563
Validation loss: 2.362592461204659

Epoch: 5| Step: 8
Training loss: 2.12761123886396
Validation loss: 2.390580133253946

Epoch: 5| Step: 9
Training loss: 2.212813696740404
Validation loss: 2.3804153307855285

Epoch: 5| Step: 10
Training loss: 2.1362655689080654
Validation loss: 2.4031747657408267

Epoch: 5| Step: 11
Training loss: 2.7311212854150164
Validation loss: 2.3695837761096152

Epoch: 60| Step: 0
Training loss: 2.1271891817613313
Validation loss: 2.395493190226745

Epoch: 5| Step: 1
Training loss: 2.316772740723488
Validation loss: 2.412432676983528

Epoch: 5| Step: 2
Training loss: 1.8333609174329415
Validation loss: 2.4369337532740136

Epoch: 5| Step: 3
Training loss: 2.211591105009983
Validation loss: 2.4847546413342587

Epoch: 5| Step: 4
Training loss: 2.561520738269403
Validation loss: 2.4961345432472277

Epoch: 5| Step: 5
Training loss: 1.7999504638849302
Validation loss: 2.491454854837794

Epoch: 5| Step: 6
Training loss: 2.740705562438342
Validation loss: 2.4845833261182695

Epoch: 5| Step: 7
Training loss: 2.1351803780681404
Validation loss: 2.4636694503344025

Epoch: 5| Step: 8
Training loss: 2.1734506942600835
Validation loss: 2.42652044331462

Epoch: 5| Step: 9
Training loss: 2.071923431704981
Validation loss: 2.4066103834635864

Epoch: 5| Step: 10
Training loss: 2.7564575497773163
Validation loss: 2.394801124104966

Epoch: 5| Step: 11
Training loss: 2.3187595912190027
Validation loss: 2.367178871802121

Epoch: 61| Step: 0
Training loss: 1.8844107021916165
Validation loss: 2.3578816102291213

Epoch: 5| Step: 1
Training loss: 2.680107951196354
Validation loss: 2.3619811819643437

Epoch: 5| Step: 2
Training loss: 2.728996523923746
Validation loss: 2.361288132919178

Epoch: 5| Step: 3
Training loss: 2.1747776093186855
Validation loss: 2.3810358229843107

Epoch: 5| Step: 4
Training loss: 2.256255038353533
Validation loss: 2.388959701468721

Epoch: 5| Step: 5
Training loss: 1.7477840289902549
Validation loss: 2.383555583050221

Epoch: 5| Step: 6
Training loss: 2.466534840008119
Validation loss: 2.376753755607218

Epoch: 5| Step: 7
Training loss: 1.6794796837284578
Validation loss: 2.368760173007455

Epoch: 5| Step: 8
Training loss: 2.2689493979691204
Validation loss: 2.3848487158444143

Epoch: 5| Step: 9
Training loss: 2.6434864138244523
Validation loss: 2.3800472786559075

Epoch: 5| Step: 10
Training loss: 1.8629591561476502
Validation loss: 2.381216813571258

Epoch: 5| Step: 11
Training loss: 2.948127029156224
Validation loss: 2.3905272744343673

Epoch: 62| Step: 0
Training loss: 1.5553474750690712
Validation loss: 2.3991079273587994

Epoch: 5| Step: 1
Training loss: 2.2621862162293787
Validation loss: 2.368755752737664

Epoch: 5| Step: 2
Training loss: 2.759308579402591
Validation loss: 2.3848951837211523

Epoch: 5| Step: 3
Training loss: 2.2975596750373355
Validation loss: 2.3990808736125637

Epoch: 5| Step: 4
Training loss: 2.3657921433454665
Validation loss: 2.3796948825841056

Epoch: 5| Step: 5
Training loss: 2.0595058324351085
Validation loss: 2.383288914315461

Epoch: 5| Step: 6
Training loss: 2.4876393878164733
Validation loss: 2.376410667690726

Epoch: 5| Step: 7
Training loss: 1.9938037972681095
Validation loss: 2.3834650240597166

Epoch: 5| Step: 8
Training loss: 2.612761532774937
Validation loss: 2.3892655215875322

Epoch: 5| Step: 9
Training loss: 1.8159821702317145
Validation loss: 2.37495629789065

Epoch: 5| Step: 10
Training loss: 1.9665025265403675
Validation loss: 2.3749271369097014

Epoch: 5| Step: 11
Training loss: 3.1138426921804365
Validation loss: 2.3553833953929684

Epoch: 63| Step: 0
Training loss: 1.8497838357985288
Validation loss: 2.3755114949873697

Epoch: 5| Step: 1
Training loss: 1.9791962939270094
Validation loss: 2.3871145175218214

Epoch: 5| Step: 2
Training loss: 2.55129808035761
Validation loss: 2.379564616987414

Epoch: 5| Step: 3
Training loss: 2.007043238418786
Validation loss: 2.365802993696327

Epoch: 5| Step: 4
Training loss: 2.377291928722191
Validation loss: 2.3884346200307647

Epoch: 5| Step: 5
Training loss: 2.961177765853703
Validation loss: 2.381438270728841

Epoch: 5| Step: 6
Training loss: 1.7784096676008145
Validation loss: 2.3613259710150087

Epoch: 5| Step: 7
Training loss: 1.8218573698627032
Validation loss: 2.389417272605079

Epoch: 5| Step: 8
Training loss: 2.206830635067807
Validation loss: 2.400694581360599

Epoch: 5| Step: 9
Training loss: 2.165239034940525
Validation loss: 2.423604487149266

Epoch: 5| Step: 10
Training loss: 2.2577381583781753
Validation loss: 2.385941345005231

Epoch: 5| Step: 11
Training loss: 2.023490286473628
Validation loss: 2.4025735884718413

Epoch: 64| Step: 0
Training loss: 2.4767016061891374
Validation loss: 2.412603750287453

Epoch: 5| Step: 1
Training loss: 2.0072021744209634
Validation loss: 2.447972351144291

Epoch: 5| Step: 2
Training loss: 1.675694247746086
Validation loss: 2.444525430537679

Epoch: 5| Step: 3
Training loss: 2.1906160231989977
Validation loss: 2.4393344989782775

Epoch: 5| Step: 4
Training loss: 1.6960389299288228
Validation loss: 2.446990249050289

Epoch: 5| Step: 5
Training loss: 2.6295357527216296
Validation loss: 2.451315493891297

Epoch: 5| Step: 6
Training loss: 2.65081230525391
Validation loss: 2.42084816114532

Epoch: 5| Step: 7
Training loss: 2.1417038697847164
Validation loss: 2.4133533230326014

Epoch: 5| Step: 8
Training loss: 2.630039282675825
Validation loss: 2.397416613053168

Epoch: 5| Step: 9
Training loss: 2.168692033416276
Validation loss: 2.3802249387555565

Epoch: 5| Step: 10
Training loss: 1.8631046619348153
Validation loss: 2.357230877454193

Epoch: 5| Step: 11
Training loss: 2.058603246909427
Validation loss: 2.383835232235606

Epoch: 65| Step: 0
Training loss: 2.3720136237565375
Validation loss: 2.380412647373682

Epoch: 5| Step: 1
Training loss: 2.679029022367161
Validation loss: 2.3853878591427717

Epoch: 5| Step: 2
Training loss: 1.6970988763474724
Validation loss: 2.3756085293827875

Epoch: 5| Step: 3
Training loss: 2.4825270395640704
Validation loss: 2.3857468677734572

Epoch: 5| Step: 4
Training loss: 1.9918686555510623
Validation loss: 2.3851664146742366

Epoch: 5| Step: 5
Training loss: 2.427524695698043
Validation loss: 2.3816128717947005

Epoch: 5| Step: 6
Training loss: 2.284133760627426
Validation loss: 2.382161607070728

Epoch: 5| Step: 7
Training loss: 1.6160122936602643
Validation loss: 2.399633426288019

Epoch: 5| Step: 8
Training loss: 2.449666494908908
Validation loss: 2.4003309837900697

Epoch: 5| Step: 9
Training loss: 1.8094396734456193
Validation loss: 2.378062653528435

Epoch: 5| Step: 10
Training loss: 2.080872748381913
Validation loss: 2.379505284580797

Epoch: 5| Step: 11
Training loss: 1.6509615119546817
Validation loss: 2.3814766396361846

Epoch: 66| Step: 0
Training loss: 2.0640029055404914
Validation loss: 2.3752319866785268

Epoch: 5| Step: 1
Training loss: 2.101776906247486
Validation loss: 2.3948376673699183

Epoch: 5| Step: 2
Training loss: 1.9648856126333774
Validation loss: 2.380962827509147

Epoch: 5| Step: 3
Training loss: 2.087936186761706
Validation loss: 2.3714041635018566

Epoch: 5| Step: 4
Training loss: 2.2658959588443977
Validation loss: 2.3658222000390414

Epoch: 5| Step: 5
Training loss: 2.4926002662869746
Validation loss: 2.3896552219458247

Epoch: 5| Step: 6
Training loss: 2.0516244081452064
Validation loss: 2.3700062385643297

Epoch: 5| Step: 7
Training loss: 2.014352322745792
Validation loss: 2.3720778591705507

Epoch: 5| Step: 8
Training loss: 1.9319766285629851
Validation loss: 2.3817478949329733

Epoch: 5| Step: 9
Training loss: 2.2930279127868416
Validation loss: 2.367238131276472

Epoch: 5| Step: 10
Training loss: 2.3615431770482176
Validation loss: 2.3508262622361347

Epoch: 5| Step: 11
Training loss: 2.5376844216964987
Validation loss: 2.3661917762961884

Epoch: 67| Step: 0
Training loss: 2.898479122058377
Validation loss: 2.4102806129293324

Epoch: 5| Step: 1
Training loss: 1.8141502234304103
Validation loss: 2.3934617342902644

Epoch: 5| Step: 2
Training loss: 1.9482817146287865
Validation loss: 2.4088418386332906

Epoch: 5| Step: 3
Training loss: 2.3278236962247734
Validation loss: 2.4042600189367276

Epoch: 5| Step: 4
Training loss: 2.434726604489884
Validation loss: 2.3891966880834357

Epoch: 5| Step: 5
Training loss: 2.201510656327122
Validation loss: 2.370655429888505

Epoch: 5| Step: 6
Training loss: 2.2724113114679634
Validation loss: 2.3917316646970317

Epoch: 5| Step: 7
Training loss: 2.1524036766059127
Validation loss: 2.3786377862324057

Epoch: 5| Step: 8
Training loss: 1.938970991829525
Validation loss: 2.386797750178039

Epoch: 5| Step: 9
Training loss: 1.742020329550578
Validation loss: 2.3635681734802536

Epoch: 5| Step: 10
Training loss: 1.9325955983903422
Validation loss: 2.376210987313286

Epoch: 5| Step: 11
Training loss: 1.3433128355527488
Validation loss: 2.3898720355405643

Epoch: 68| Step: 0
Training loss: 2.537363651915702
Validation loss: 2.4034028693358502

Epoch: 5| Step: 1
Training loss: 1.710534035128577
Validation loss: 2.444439272005095

Epoch: 5| Step: 2
Training loss: 2.1148783911695808
Validation loss: 2.4533837904764617

Epoch: 5| Step: 3
Training loss: 2.0943802980852864
Validation loss: 2.477071222468726

Epoch: 5| Step: 4
Training loss: 2.1082878419494144
Validation loss: 2.4937111552757685

Epoch: 5| Step: 5
Training loss: 2.8925263621085917
Validation loss: 2.4671385249857085

Epoch: 5| Step: 6
Training loss: 2.7875537371053056
Validation loss: 2.4460377577419665

Epoch: 5| Step: 7
Training loss: 1.6358429015170142
Validation loss: 2.387665241990824

Epoch: 5| Step: 8
Training loss: 1.6013819150762725
Validation loss: 2.4198850064962327

Epoch: 5| Step: 9
Training loss: 2.122318370942296
Validation loss: 2.3962367644165847

Epoch: 5| Step: 10
Training loss: 1.869207845374014
Validation loss: 2.3973824482362565

Epoch: 5| Step: 11
Training loss: 1.586974908689273
Validation loss: 2.3898023798174814

Epoch: 69| Step: 0
Training loss: 1.8793831138828956
Validation loss: 2.3713448112421105

Epoch: 5| Step: 1
Training loss: 2.6520222846888615
Validation loss: 2.3546848880151727

Epoch: 5| Step: 2
Training loss: 2.1171123871376616
Validation loss: 2.408837145496064

Epoch: 5| Step: 3
Training loss: 2.3397796571133687
Validation loss: 2.366444856251727

Epoch: 5| Step: 4
Training loss: 2.3889677000229472
Validation loss: 2.3748815030100734

Epoch: 5| Step: 5
Training loss: 2.255591332830969
Validation loss: 2.3675166112161943

Epoch: 5| Step: 6
Training loss: 1.8247752351700115
Validation loss: 2.357357981905553

Epoch: 5| Step: 7
Training loss: 1.7717763372062125
Validation loss: 2.369140058927791

Epoch: 5| Step: 8
Training loss: 2.0473378364333765
Validation loss: 2.379184145008651

Epoch: 5| Step: 9
Training loss: 1.7867761520152092
Validation loss: 2.398130651968906

Epoch: 5| Step: 10
Training loss: 2.1015003294416954
Validation loss: 2.428654143299925

Epoch: 5| Step: 11
Training loss: 3.4722146267278036
Validation loss: 2.405527642224911

Epoch: 70| Step: 0
Training loss: 2.0604777970870782
Validation loss: 2.4357394458676915

Epoch: 5| Step: 1
Training loss: 2.193760876750881
Validation loss: 2.4522269725187003

Epoch: 5| Step: 2
Training loss: 2.0895242892512864
Validation loss: 2.4312983035737443

Epoch: 5| Step: 3
Training loss: 2.565059686007236
Validation loss: 2.410076888151889

Epoch: 5| Step: 4
Training loss: 1.996532414380278
Validation loss: 2.3933376450940327

Epoch: 5| Step: 5
Training loss: 1.2753065937394341
Validation loss: 2.3856365395429187

Epoch: 5| Step: 6
Training loss: 1.8257305407552038
Validation loss: 2.3899255739179486

Epoch: 5| Step: 7
Training loss: 2.4178818793398875
Validation loss: 2.3750522047295046

Epoch: 5| Step: 8
Training loss: 2.1884629446182178
Validation loss: 2.3912504371181367

Epoch: 5| Step: 9
Training loss: 1.9719294956131026
Validation loss: 2.3621640110273683

Epoch: 5| Step: 10
Training loss: 2.46898997625307
Validation loss: 2.3636358452217827

Epoch: 5| Step: 11
Training loss: 1.7448707752418489
Validation loss: 2.37216773473708

Epoch: 71| Step: 0
Training loss: 1.7961457472712714
Validation loss: 2.3448465537165064

Epoch: 5| Step: 1
Training loss: 2.23770235308092
Validation loss: 2.3604225755119828

Epoch: 5| Step: 2
Training loss: 2.2303127895684822
Validation loss: 2.3891496032444355

Epoch: 5| Step: 3
Training loss: 1.575129394665586
Validation loss: 2.3758256715106643

Epoch: 5| Step: 4
Training loss: 2.638759518402439
Validation loss: 2.423722917813029

Epoch: 5| Step: 5
Training loss: 1.8789185585047075
Validation loss: 2.3857233871987127

Epoch: 5| Step: 6
Training loss: 2.581017830593117
Validation loss: 2.3940732413155827

Epoch: 5| Step: 7
Training loss: 1.6789659236564876
Validation loss: 2.402748743670743

Epoch: 5| Step: 8
Training loss: 2.089891094491461
Validation loss: 2.3787691967367146

Epoch: 5| Step: 9
Training loss: 2.105498418085849
Validation loss: 2.3632524178587846

Epoch: 5| Step: 10
Training loss: 2.157588267018146
Validation loss: 2.3582290451683563

Epoch: 5| Step: 11
Training loss: 2.699757766453886
Validation loss: 2.3556567191409683

Epoch: 72| Step: 0
Training loss: 1.6930978258443983
Validation loss: 2.3483104080054016

Epoch: 5| Step: 1
Training loss: 1.7316970082850573
Validation loss: 2.354655927409708

Epoch: 5| Step: 2
Training loss: 2.6270150216337096
Validation loss: 2.356413262290648

Epoch: 5| Step: 3
Training loss: 1.3667034491186985
Validation loss: 2.3558965919661423

Epoch: 5| Step: 4
Training loss: 2.0618531339792012
Validation loss: 2.338878167006512

Epoch: 5| Step: 5
Training loss: 1.9342255764193723
Validation loss: 2.3740453976685543

Epoch: 5| Step: 6
Training loss: 2.611937218605292
Validation loss: 2.348683274877612

Epoch: 5| Step: 7
Training loss: 2.0369743090260917
Validation loss: 2.3757662540904594

Epoch: 5| Step: 8
Training loss: 2.3225434235782845
Validation loss: 2.3936123394206397

Epoch: 5| Step: 9
Training loss: 2.2150083342797955
Validation loss: 2.36772336864159

Epoch: 5| Step: 10
Training loss: 1.9748303811355499
Validation loss: 2.367466904839561

Epoch: 5| Step: 11
Training loss: 2.286543570097741
Validation loss: 2.385127621980874

Epoch: 73| Step: 0
Training loss: 2.311490843929481
Validation loss: 2.418858809574208

Epoch: 5| Step: 1
Training loss: 1.803831549775086
Validation loss: 2.4379500112261843

Epoch: 5| Step: 2
Training loss: 2.415882794638266
Validation loss: 2.4418635517350276

Epoch: 5| Step: 3
Training loss: 1.66358496749536
Validation loss: 2.408444167977977

Epoch: 5| Step: 4
Training loss: 2.121846271033882
Validation loss: 2.4325781550696695

Epoch: 5| Step: 5
Training loss: 1.9499585538518793
Validation loss: 2.4122087486482027

Epoch: 5| Step: 6
Training loss: 1.590812594100559
Validation loss: 2.4134631683487515

Epoch: 5| Step: 7
Training loss: 2.0949611292399015
Validation loss: 2.4149048990738944

Epoch: 5| Step: 8
Training loss: 2.1721695075938388
Validation loss: 2.3800821597813635

Epoch: 5| Step: 9
Training loss: 2.1507416177985585
Validation loss: 2.397891658671335

Epoch: 5| Step: 10
Training loss: 2.2381707874888606
Validation loss: 2.4099660310949815

Epoch: 5| Step: 11
Training loss: 2.551902162518032
Validation loss: 2.383400099381574

Epoch: 74| Step: 0
Training loss: 1.7474187478971144
Validation loss: 2.366364467130655

Epoch: 5| Step: 1
Training loss: 2.105425039768335
Validation loss: 2.3949428617368502

Epoch: 5| Step: 2
Training loss: 2.2130214184510164
Validation loss: 2.395922490548037

Epoch: 5| Step: 3
Training loss: 2.1571848957256594
Validation loss: 2.448393593990704

Epoch: 5| Step: 4
Training loss: 1.9820215882820287
Validation loss: 2.363535410767827

Epoch: 5| Step: 5
Training loss: 1.8585850937117803
Validation loss: 2.407902534083857

Epoch: 5| Step: 6
Training loss: 1.8826775720139082
Validation loss: 2.356593009745497

Epoch: 5| Step: 7
Training loss: 2.76394326323203
Validation loss: 2.343217532814473

Epoch: 5| Step: 8
Training loss: 1.9173792537187166
Validation loss: 2.3333382514209235

Epoch: 5| Step: 9
Training loss: 2.446573633024169
Validation loss: 2.3649827701002804

Epoch: 5| Step: 10
Training loss: 2.051124878204935
Validation loss: 2.4394441782102896

Epoch: 5| Step: 11
Training loss: 2.3419801260139956
Validation loss: 2.417026605328915

Epoch: 75| Step: 0
Training loss: 2.72066342776024
Validation loss: 2.3930261724400834

Epoch: 5| Step: 1
Training loss: 2.0451947952801146
Validation loss: 2.3859735773036577

Epoch: 5| Step: 2
Training loss: 1.6617738988106754
Validation loss: 2.3909150302954445

Epoch: 5| Step: 3
Training loss: 1.9441210303718883
Validation loss: 2.371976753987384

Epoch: 5| Step: 4
Training loss: 1.7899267116652946
Validation loss: 2.372942966441589

Epoch: 5| Step: 5
Training loss: 1.7752711693388334
Validation loss: 2.3638083004229697

Epoch: 5| Step: 6
Training loss: 1.9791793688985548
Validation loss: 2.380784010326727

Epoch: 5| Step: 7
Training loss: 2.2100976218156796
Validation loss: 2.3847110605623576

Epoch: 5| Step: 8
Training loss: 1.9011547594963605
Validation loss: 2.370226989139102

Epoch: 5| Step: 9
Training loss: 2.4153098430068614
Validation loss: 2.367947904284648

Epoch: 5| Step: 10
Training loss: 2.2943771170261127
Validation loss: 2.3622727420198104

Epoch: 5| Step: 11
Training loss: 1.474659657410513
Validation loss: 2.3727995734480416

Epoch: 76| Step: 0
Training loss: 1.563078353655615
Validation loss: 2.4072616151600847

Epoch: 5| Step: 1
Training loss: 2.2107992499703437
Validation loss: 2.4919573798211423

Epoch: 5| Step: 2
Training loss: 1.8594883475496295
Validation loss: 2.484399907369135

Epoch: 5| Step: 3
Training loss: 2.1909875588771146
Validation loss: 2.522609216514072

Epoch: 5| Step: 4
Training loss: 1.940620125044199
Validation loss: 2.5264614595377246

Epoch: 5| Step: 5
Training loss: 1.4876465733224138
Validation loss: 2.4944817437463294

Epoch: 5| Step: 6
Training loss: 2.3576768233166194
Validation loss: 2.5056303598041003

Epoch: 5| Step: 7
Training loss: 3.0105842798863525
Validation loss: 2.4198103810535163

Epoch: 5| Step: 8
Training loss: 2.1447024528941525
Validation loss: 2.3964882632728957

Epoch: 5| Step: 9
Training loss: 2.064458321932023
Validation loss: 2.352166952556401

Epoch: 5| Step: 10
Training loss: 2.0868812740536655
Validation loss: 2.360680490537956

Epoch: 5| Step: 11
Training loss: 1.4953043874681973
Validation loss: 2.38530763157573

Epoch: 77| Step: 0
Training loss: 2.305951718939086
Validation loss: 2.400425554005343

Epoch: 5| Step: 1
Training loss: 2.1621361707562117
Validation loss: 2.39271386001562

Epoch: 5| Step: 2
Training loss: 1.9283822158556811
Validation loss: 2.3924124274973395

Epoch: 5| Step: 3
Training loss: 1.8627016457586707
Validation loss: 2.3786939308031934

Epoch: 5| Step: 4
Training loss: 2.2195137750997778
Validation loss: 2.351144770444737

Epoch: 5| Step: 5
Training loss: 1.8386165470367533
Validation loss: 2.364660565687647

Epoch: 5| Step: 6
Training loss: 2.048700348657975
Validation loss: 2.397022556850892

Epoch: 5| Step: 7
Training loss: 2.4077274691193264
Validation loss: 2.4499447895822866

Epoch: 5| Step: 8
Training loss: 2.0328157699054334
Validation loss: 2.4413249498182044

Epoch: 5| Step: 9
Training loss: 2.3771268456700567
Validation loss: 2.3908344002560984

Epoch: 5| Step: 10
Training loss: 2.1260553992832674
Validation loss: 2.401472044138652

Epoch: 5| Step: 11
Training loss: 1.67388752105271
Validation loss: 2.3611708684134736

Epoch: 78| Step: 0
Training loss: 2.039845400356296
Validation loss: 2.37645237834946

Epoch: 5| Step: 1
Training loss: 1.7912502987868704
Validation loss: 2.3788303954042322

Epoch: 5| Step: 2
Training loss: 1.8876211089633503
Validation loss: 2.369437379169353

Epoch: 5| Step: 3
Training loss: 2.269671384913597
Validation loss: 2.3716362945734586

Epoch: 5| Step: 4
Training loss: 2.132146151344546
Validation loss: 2.3654207386671446

Epoch: 5| Step: 5
Training loss: 1.683809200228835
Validation loss: 2.34522767427138

Epoch: 5| Step: 6
Training loss: 2.1554353806116935
Validation loss: 2.3800992203347375

Epoch: 5| Step: 7
Training loss: 2.324120476191801
Validation loss: 2.3515979514929635

Epoch: 5| Step: 8
Training loss: 1.8973237840653872
Validation loss: 2.3932736835068322

Epoch: 5| Step: 9
Training loss: 1.7879265256331487
Validation loss: 2.401750084941438

Epoch: 5| Step: 10
Training loss: 2.1732332661571516
Validation loss: 2.3948687906168002

Epoch: 5| Step: 11
Training loss: 3.5655903044741906
Validation loss: 2.3958249686274806

Epoch: 79| Step: 0
Training loss: 2.164684770818361
Validation loss: 2.4012135232474603

Epoch: 5| Step: 1
Training loss: 1.826476176810633
Validation loss: 2.38440576869299

Epoch: 5| Step: 2
Training loss: 2.0598938399802367
Validation loss: 2.3971703751456723

Epoch: 5| Step: 3
Training loss: 2.725870301444856
Validation loss: 2.4386788313489087

Epoch: 5| Step: 4
Training loss: 1.9380633857919642
Validation loss: 2.47367476728813

Epoch: 5| Step: 5
Training loss: 2.1867084706001134
Validation loss: 2.466168550885523

Epoch: 5| Step: 6
Training loss: 1.8812470952515339
Validation loss: 2.4416090288509102

Epoch: 5| Step: 7
Training loss: 2.25614619557837
Validation loss: 2.390673090465597

Epoch: 5| Step: 8
Training loss: 1.7737067602154903
Validation loss: 2.389276439966572

Epoch: 5| Step: 9
Training loss: 1.8538056640087408
Validation loss: 2.376956758937811

Epoch: 5| Step: 10
Training loss: 2.3063610143226603
Validation loss: 2.4126102766550876

Epoch: 5| Step: 11
Training loss: 2.2425587841821883
Validation loss: 2.4729961826509927

Epoch: 80| Step: 0
Training loss: 2.369270843172664
Validation loss: 2.483084449414558

Epoch: 5| Step: 1
Training loss: 2.2110842598776204
Validation loss: 2.531559316942899

Epoch: 5| Step: 2
Training loss: 1.910536527322916
Validation loss: 2.5396199010689005

Epoch: 5| Step: 3
Training loss: 1.8297313577427037
Validation loss: 2.4906360018115037

Epoch: 5| Step: 4
Training loss: 2.6651473982595153
Validation loss: 2.423473318865395

Epoch: 5| Step: 5
Training loss: 1.4051077548209892
Validation loss: 2.390455038390948

Epoch: 5| Step: 6
Training loss: 2.011940716099477
Validation loss: 2.397434401769942

Epoch: 5| Step: 7
Training loss: 2.0085935743250967
Validation loss: 2.4093381130958873

Epoch: 5| Step: 8
Training loss: 2.269535241968843
Validation loss: 2.3651392881105227

Epoch: 5| Step: 9
Training loss: 1.809326748377531
Validation loss: 2.3582637140244707

Epoch: 5| Step: 10
Training loss: 1.5841338325855667
Validation loss: 2.396043753022015

Epoch: 5| Step: 11
Training loss: 1.2192593023881184
Validation loss: 2.4006131811098492

Epoch: 81| Step: 0
Training loss: 1.7552839615674964
Validation loss: 2.3606822158805376

Epoch: 5| Step: 1
Training loss: 2.2137141500851807
Validation loss: 2.361873743521767

Epoch: 5| Step: 2
Training loss: 2.1525880982981995
Validation loss: 2.3693635672646725

Epoch: 5| Step: 3
Training loss: 2.4480441012929077
Validation loss: 2.3543515041391747

Epoch: 5| Step: 4
Training loss: 1.8378008537786172
Validation loss: 2.3441175448131073

Epoch: 5| Step: 5
Training loss: 1.5983642650842502
Validation loss: 2.3313431653862744

Epoch: 5| Step: 6
Training loss: 1.9998920530751771
Validation loss: 2.3625735271456167

Epoch: 5| Step: 7
Training loss: 2.09244758749965
Validation loss: 2.36850207456399

Epoch: 5| Step: 8
Training loss: 2.147896993444006
Validation loss: 2.3656860306735505

Epoch: 5| Step: 9
Training loss: 1.6687351583328032
Validation loss: 2.4227391352330017

Epoch: 5| Step: 10
Training loss: 1.784856925594466
Validation loss: 2.3979262512262944

Epoch: 5| Step: 11
Training loss: 1.0902242235663069
Validation loss: 2.404194536053083

Epoch: 82| Step: 0
Training loss: 1.9009334028238432
Validation loss: 2.4593074546951645

Epoch: 5| Step: 1
Training loss: 2.110906539452764
Validation loss: 2.4417978120243755

Epoch: 5| Step: 2
Training loss: 1.709337993549019
Validation loss: 2.4604688288956997

Epoch: 5| Step: 3
Training loss: 1.9957317464481863
Validation loss: 2.445198084842885

Epoch: 5| Step: 4
Training loss: 1.4322753165496713
Validation loss: 2.43573884429225

Epoch: 5| Step: 5
Training loss: 1.7851631949058016
Validation loss: 2.4239011287837977

Epoch: 5| Step: 6
Training loss: 2.2736723998062307
Validation loss: 2.3958571653977545

Epoch: 5| Step: 7
Training loss: 2.190029534615411
Validation loss: 2.3506511071150067

Epoch: 5| Step: 8
Training loss: 2.1059975039765293
Validation loss: 2.3667678922733955

Epoch: 5| Step: 9
Training loss: 2.2744681522657966
Validation loss: 2.3563102918511847

Epoch: 5| Step: 10
Training loss: 1.7116754760565018
Validation loss: 2.4051736637247467

Epoch: 5| Step: 11
Training loss: 1.3073483134404693
Validation loss: 2.3844597464350237

Epoch: 83| Step: 0
Training loss: 1.813906814242566
Validation loss: 2.370121412426704

Epoch: 5| Step: 1
Training loss: 2.195125585452227
Validation loss: 2.3766736441193714

Epoch: 5| Step: 2
Training loss: 1.8294768592515696
Validation loss: 2.3469142788623603

Epoch: 5| Step: 3
Training loss: 1.950392131014089
Validation loss: 2.3634034117344047

Epoch: 5| Step: 4
Training loss: 2.267558568431495
Validation loss: 2.3381807555697507

Epoch: 5| Step: 5
Training loss: 2.126976216228535
Validation loss: 2.3560558070425985

Epoch: 5| Step: 6
Training loss: 1.5424847193723088
Validation loss: 2.356654815909316

Epoch: 5| Step: 7
Training loss: 2.2792238617670577
Validation loss: 2.413887752146271

Epoch: 5| Step: 8
Training loss: 1.6675609652971577
Validation loss: 2.4171494599110663

Epoch: 5| Step: 9
Training loss: 2.125551488783494
Validation loss: 2.430316677994906

Epoch: 5| Step: 10
Training loss: 1.5837837214443946
Validation loss: 2.367942379148403

Epoch: 5| Step: 11
Training loss: 1.8717543803536096
Validation loss: 2.3628270177719335

Epoch: 84| Step: 0
Training loss: 2.0863656165449234
Validation loss: 2.4098221038714844

Epoch: 5| Step: 1
Training loss: 2.1282073107246564
Validation loss: 2.441597691468723

Epoch: 5| Step: 2
Training loss: 1.4066664185154651
Validation loss: 2.4762893108910795

Epoch: 5| Step: 3
Training loss: 1.7908136052103711
Validation loss: 2.493804442975416

Epoch: 5| Step: 4
Training loss: 1.875261542834605
Validation loss: 2.444315027443929

Epoch: 5| Step: 5
Training loss: 2.5055058884849317
Validation loss: 2.408302432959777

Epoch: 5| Step: 6
Training loss: 2.5048573037200166
Validation loss: 2.3824139162651927

Epoch: 5| Step: 7
Training loss: 1.456102090290383
Validation loss: 2.384992100831179

Epoch: 5| Step: 8
Training loss: 1.761218285366441
Validation loss: 2.3546027578568487

Epoch: 5| Step: 9
Training loss: 1.424629979864529
Validation loss: 2.342681938102975

Epoch: 5| Step: 10
Training loss: 2.219272283413197
Validation loss: 2.391841877911577

Epoch: 5| Step: 11
Training loss: 2.8198708481669503
Validation loss: 2.3596202352369637

Epoch: 85| Step: 0
Training loss: 1.8302273521527967
Validation loss: 2.365133353190949

Epoch: 5| Step: 1
Training loss: 2.257502656683726
Validation loss: 2.3768374817968505

Epoch: 5| Step: 2
Training loss: 2.124655190710446
Validation loss: 2.336646039540002

Epoch: 5| Step: 3
Training loss: 1.7215916810719258
Validation loss: 2.382998099681306

Epoch: 5| Step: 4
Training loss: 1.8377768535040229
Validation loss: 2.4221974435089595

Epoch: 5| Step: 5
Training loss: 1.9546701041712249
Validation loss: 2.3952382502750584

Epoch: 5| Step: 6
Training loss: 2.1137480440587537
Validation loss: 2.425192011444646

Epoch: 5| Step: 7
Training loss: 1.9589467677331756
Validation loss: 2.4141224089331588

Epoch: 5| Step: 8
Training loss: 1.9194288736507088
Validation loss: 2.394827869457456

Epoch: 5| Step: 9
Training loss: 2.0089124939290315
Validation loss: 2.389042145380599

Epoch: 5| Step: 10
Training loss: 1.7072299867776122
Validation loss: 2.356666838035775

Epoch: 5| Step: 11
Training loss: 1.443243081411103
Validation loss: 2.355798469438862

Epoch: 86| Step: 0
Training loss: 1.9971703539276318
Validation loss: 2.342189069819078

Epoch: 5| Step: 1
Training loss: 1.7682717664153702
Validation loss: 2.36051660249287

Epoch: 5| Step: 2
Training loss: 1.9472290158058805
Validation loss: 2.359050766348098

Epoch: 5| Step: 3
Training loss: 1.6513308764164656
Validation loss: 2.37357081946465

Epoch: 5| Step: 4
Training loss: 1.4688389528000323
Validation loss: 2.37045778128129

Epoch: 5| Step: 5
Training loss: 1.5503937744047125
Validation loss: 2.416277709577734

Epoch: 5| Step: 6
Training loss: 2.14876373588428
Validation loss: 2.3826363045008145

Epoch: 5| Step: 7
Training loss: 2.006518945463366
Validation loss: 2.398841726511668

Epoch: 5| Step: 8
Training loss: 1.735619107361057
Validation loss: 2.4284773140189913

Epoch: 5| Step: 9
Training loss: 1.9047844678246322
Validation loss: 2.397666848760957

Epoch: 5| Step: 10
Training loss: 2.0593077490886453
Validation loss: 2.4088489690501182

Epoch: 5| Step: 11
Training loss: 3.811863455241256
Validation loss: 2.3787036135038453

Epoch: 87| Step: 0
Training loss: 1.715582686216864
Validation loss: 2.339975683433714

Epoch: 5| Step: 1
Training loss: 1.9658022414019742
Validation loss: 2.4082752267522167

Epoch: 5| Step: 2
Training loss: 2.228072233498175
Validation loss: 2.401155267760109

Epoch: 5| Step: 3
Training loss: 1.845919286593815
Validation loss: 2.4168003116573162

Epoch: 5| Step: 4
Training loss: 1.8251837520325103
Validation loss: 2.4266089779442734

Epoch: 5| Step: 5
Training loss: 1.4325127540806182
Validation loss: 2.394893942368132

Epoch: 5| Step: 6
Training loss: 1.8648244677003416
Validation loss: 2.3849442373710574

Epoch: 5| Step: 7
Training loss: 2.2595084925215705
Validation loss: 2.4277290186640075

Epoch: 5| Step: 8
Training loss: 2.4763705302544676
Validation loss: 2.418995540109234

Epoch: 5| Step: 9
Training loss: 1.6033311707580533
Validation loss: 2.3461867423380034

Epoch: 5| Step: 10
Training loss: 1.694689095489522
Validation loss: 2.3949395848527164

Epoch: 5| Step: 11
Training loss: 1.353440011514726
Validation loss: 2.417607793535023

Epoch: 88| Step: 0
Training loss: 2.2362654364848984
Validation loss: 2.4353326551850834

Epoch: 5| Step: 1
Training loss: 1.7646858620910446
Validation loss: 2.453179085493666

Epoch: 5| Step: 2
Training loss: 1.4240958507618027
Validation loss: 2.4861330333882137

Epoch: 5| Step: 3
Training loss: 1.4134980228951346
Validation loss: 2.4725384616367436

Epoch: 5| Step: 4
Training loss: 2.1311448952272403
Validation loss: 2.42157320993047

Epoch: 5| Step: 5
Training loss: 1.3857206379220959
Validation loss: 2.397412831949726

Epoch: 5| Step: 6
Training loss: 2.059978215000551
Validation loss: 2.3715460553790626

Epoch: 5| Step: 7
Training loss: 1.9340907219217456
Validation loss: 2.3665826904034692

Epoch: 5| Step: 8
Training loss: 1.755514652074796
Validation loss: 2.354822136485723

Epoch: 5| Step: 9
Training loss: 2.030854876308371
Validation loss: 2.339941556623883

Epoch: 5| Step: 10
Training loss: 2.0011935249094237
Validation loss: 2.340957117731365

Epoch: 5| Step: 11
Training loss: 1.4673945076764658
Validation loss: 2.3555689337550936

Epoch: 89| Step: 0
Training loss: 2.2940010203697643
Validation loss: 2.402992783205152

Epoch: 5| Step: 1
Training loss: 2.3473786810420454
Validation loss: 2.4724170675598716

Epoch: 5| Step: 2
Training loss: 1.978432234638241
Validation loss: 2.4620909233275388

Epoch: 5| Step: 3
Training loss: 1.9609982910460049
Validation loss: 2.4864577673879573

Epoch: 5| Step: 4
Training loss: 2.2821285698501237
Validation loss: 2.4071891735338014

Epoch: 5| Step: 5
Training loss: 1.6631270810658632
Validation loss: 2.3760033838671317

Epoch: 5| Step: 6
Training loss: 1.8274487932078631
Validation loss: 2.3361489020622397

Epoch: 5| Step: 7
Training loss: 2.061774039385413
Validation loss: 2.462438704765382

Epoch: 5| Step: 8
Training loss: 2.0560138323277752
Validation loss: 2.5018267275755837

Epoch: 5| Step: 9
Training loss: 1.591047950976308
Validation loss: 2.5618343651762663

Epoch: 5| Step: 10
Training loss: 1.7809342221552706
Validation loss: 2.4913357003479493

Epoch: 5| Step: 11
Training loss: 0.694267988568769
Validation loss: 2.4156815923203196

Epoch: 90| Step: 0
Training loss: 2.095949753952549
Validation loss: 2.3961120125499873

Epoch: 5| Step: 1
Training loss: 1.7962074034756286
Validation loss: 2.3746145002474317

Epoch: 5| Step: 2
Training loss: 1.7741676205617127
Validation loss: 2.36328893823135

Epoch: 5| Step: 3
Training loss: 1.481626354966461
Validation loss: 2.3907945734855347

Epoch: 5| Step: 4
Training loss: 1.5117965007965048
Validation loss: 2.3829805283633365

Epoch: 5| Step: 5
Training loss: 1.74358930770263
Validation loss: 2.3108590679086176

Epoch: 5| Step: 6
Training loss: 2.6893571159163545
Validation loss: 2.368071203344807

Epoch: 5| Step: 7
Training loss: 1.4101051046548645
Validation loss: 2.34921457298524

Epoch: 5| Step: 8
Training loss: 2.0763236821999023
Validation loss: 2.3778391565613557

Epoch: 5| Step: 9
Training loss: 2.0953853540463396
Validation loss: 2.3623020129525734

Epoch: 5| Step: 10
Training loss: 1.6226214093364815
Validation loss: 2.3285912787123926

Epoch: 5| Step: 11
Training loss: 0.7980160864568627
Validation loss: 2.3785484203529976

Epoch: 91| Step: 0
Training loss: 1.9999502891084642
Validation loss: 2.396685356867294

Epoch: 5| Step: 1
Training loss: 1.6935160739294655
Validation loss: 2.4287908602536707

Epoch: 5| Step: 2
Training loss: 1.5274704980576626
Validation loss: 2.4577836753026387

Epoch: 5| Step: 3
Training loss: 1.8256229330362637
Validation loss: 2.423183622903146

Epoch: 5| Step: 4
Training loss: 2.242549215773972
Validation loss: 2.376439779115604

Epoch: 5| Step: 5
Training loss: 1.511875588021513
Validation loss: 2.367227862426302

Epoch: 5| Step: 6
Training loss: 2.043113805460726
Validation loss: 2.3526653901424854

Epoch: 5| Step: 7
Training loss: 1.6926407394607044
Validation loss: 2.2932153576751286

Epoch: 5| Step: 8
Training loss: 1.7145112916714194
Validation loss: 2.3004698162080275

Epoch: 5| Step: 9
Training loss: 2.38033688877668
Validation loss: 2.3286122680499743

Epoch: 5| Step: 10
Training loss: 1.6327275888367767
Validation loss: 2.3432233218659775

Epoch: 5| Step: 11
Training loss: 2.291429565186212
Validation loss: 2.3446488415876865

Epoch: 92| Step: 0
Training loss: 1.5302499113240222
Validation loss: 2.305272772661593

Epoch: 5| Step: 1
Training loss: 1.7314390471765169
Validation loss: 2.3690551968839224

Epoch: 5| Step: 2
Training loss: 1.8686131736651115
Validation loss: 2.380863096856496

Epoch: 5| Step: 3
Training loss: 1.8014032113159397
Validation loss: 2.42292609837523

Epoch: 5| Step: 4
Training loss: 1.5986832207041934
Validation loss: 2.3683097537605344

Epoch: 5| Step: 5
Training loss: 2.2055652712147014
Validation loss: 2.3916766091438033

Epoch: 5| Step: 6
Training loss: 1.746306950398926
Validation loss: 2.4295883281130655

Epoch: 5| Step: 7
Training loss: 1.8730945441869753
Validation loss: 2.3637758016027055

Epoch: 5| Step: 8
Training loss: 1.9998271986697211
Validation loss: 2.3504007771320143

Epoch: 5| Step: 9
Training loss: 1.621731331696786
Validation loss: 2.3549110338559083

Epoch: 5| Step: 10
Training loss: 1.8865817634340873
Validation loss: 2.333429221044955

Epoch: 5| Step: 11
Training loss: 2.07171594806139
Validation loss: 2.361474694435262

Epoch: 93| Step: 0
Training loss: 1.4987166796011586
Validation loss: 2.377488505686329

Epoch: 5| Step: 1
Training loss: 1.6464391229277815
Validation loss: 2.397102734233983

Epoch: 5| Step: 2
Training loss: 1.149423604065112
Validation loss: 2.384715157572875

Epoch: 5| Step: 3
Training loss: 1.779352616443008
Validation loss: 2.3809860233359683

Epoch: 5| Step: 4
Training loss: 1.961396243476246
Validation loss: 2.4189584870557828

Epoch: 5| Step: 5
Training loss: 1.848072545452425
Validation loss: 2.4259043000443428

Epoch: 5| Step: 6
Training loss: 1.4414709226577969
Validation loss: 2.4373306965514567

Epoch: 5| Step: 7
Training loss: 2.0402085164034762
Validation loss: 2.442447365089878

Epoch: 5| Step: 8
Training loss: 1.9792639323644383
Validation loss: 2.418734218240356

Epoch: 5| Step: 9
Training loss: 2.009912246382707
Validation loss: 2.4073788113064

Epoch: 5| Step: 10
Training loss: 2.103215131486255
Validation loss: 2.3586146116729294

Epoch: 5| Step: 11
Training loss: 2.406764582317869
Validation loss: 2.374109222439755

Epoch: 94| Step: 0
Training loss: 1.9822488643524154
Validation loss: 2.3751390859802095

Epoch: 5| Step: 1
Training loss: 1.6752893397248292
Validation loss: 2.4205271918520053

Epoch: 5| Step: 2
Training loss: 1.9812849721619847
Validation loss: 2.438453711892908

Epoch: 5| Step: 3
Training loss: 1.8226788901612385
Validation loss: 2.4012877006556477

Epoch: 5| Step: 4
Training loss: 1.6078581837798847
Validation loss: 2.4462199472294412

Epoch: 5| Step: 5
Training loss: 2.1379708870100154
Validation loss: 2.3600055365713013

Epoch: 5| Step: 6
Training loss: 1.2952900588941159
Validation loss: 2.3672391426320067

Epoch: 5| Step: 7
Training loss: 1.5854946326168255
Validation loss: 2.3039197149321993

Epoch: 5| Step: 8
Training loss: 1.6252680337372163
Validation loss: 2.368599985383189

Epoch: 5| Step: 9
Training loss: 2.082495088422646
Validation loss: 2.4778910943018126

Epoch: 5| Step: 10
Training loss: 1.928955557074401
Validation loss: 2.497727422144659

Epoch: 5| Step: 11
Training loss: 2.1915393047772485
Validation loss: 2.4659366915090004

Epoch: 95| Step: 0
Training loss: 2.0920201457568917
Validation loss: 2.458003813404765

Epoch: 5| Step: 1
Training loss: 1.333159385699104
Validation loss: 2.4375593064095056

Epoch: 5| Step: 2
Training loss: 1.3776924042545424
Validation loss: 2.3616211117537262

Epoch: 5| Step: 3
Training loss: 1.0497730055175754
Validation loss: 2.415066910297916

Epoch: 5| Step: 4
Training loss: 1.6346835864411655
Validation loss: 2.365262492081261

Epoch: 5| Step: 5
Training loss: 1.4034214819514512
Validation loss: 2.3818388195054294

Epoch: 5| Step: 6
Training loss: 2.1253826694378195
Validation loss: 2.349960558810571

Epoch: 5| Step: 7
Training loss: 1.970819747695175
Validation loss: 2.3803848740920563

Epoch: 5| Step: 8
Training loss: 1.5795732405908716
Validation loss: 2.381479899588241

Epoch: 5| Step: 9
Training loss: 1.9765734766478191
Validation loss: 2.369420277484822

Epoch: 5| Step: 10
Training loss: 2.3096264693225637
Validation loss: 2.3861962811574995

Epoch: 5| Step: 11
Training loss: 1.0733640287484296
Validation loss: 2.420110420638538

Epoch: 96| Step: 0
Training loss: 1.4957875070308533
Validation loss: 2.3654592098997274

Epoch: 5| Step: 1
Training loss: 1.8347373123697057
Validation loss: 2.4010813179520905

Epoch: 5| Step: 2
Training loss: 1.9425182573400661
Validation loss: 2.407609819566157

Epoch: 5| Step: 3
Training loss: 1.5307617966257954
Validation loss: 2.4569852791323075

Epoch: 5| Step: 4
Training loss: 1.9341263471041648
Validation loss: 2.438844240838833

Epoch: 5| Step: 5
Training loss: 1.360587708186014
Validation loss: 2.422166294094809

Epoch: 5| Step: 6
Training loss: 1.7852867963540777
Validation loss: 2.386435307197818

Epoch: 5| Step: 7
Training loss: 1.8056301941075656
Validation loss: 2.3837102480825902

Epoch: 5| Step: 8
Training loss: 1.7078703819022052
Validation loss: 2.359786094657153

Epoch: 5| Step: 9
Training loss: 1.7216804491410327
Validation loss: 2.327050496595135

Epoch: 5| Step: 10
Training loss: 1.9576784080379739
Validation loss: 2.3294145993530253

Epoch: 5| Step: 11
Training loss: 1.7634363703679319
Validation loss: 2.3499382256105887

Epoch: 97| Step: 0
Training loss: 1.6894785972835884
Validation loss: 2.327075440049908

Epoch: 5| Step: 1
Training loss: 1.1976205321557984
Validation loss: 2.3412258203835963

Epoch: 5| Step: 2
Training loss: 1.461634342237803
Validation loss: 2.360946058522467

Epoch: 5| Step: 3
Training loss: 1.304745518656408
Validation loss: 2.3262945655818856

Epoch: 5| Step: 4
Training loss: 1.7199753987970412
Validation loss: 2.363685905344715

Epoch: 5| Step: 5
Training loss: 1.8238326977288266
Validation loss: 2.4444264115646166

Epoch: 5| Step: 6
Training loss: 2.0083264832228127
Validation loss: 2.4126486562806977

Epoch: 5| Step: 7
Training loss: 2.2287519431627225
Validation loss: 2.4366353225246695

Epoch: 5| Step: 8
Training loss: 1.8456283311978514
Validation loss: 2.464068444502261

Epoch: 5| Step: 9
Training loss: 1.8157403853449579
Validation loss: 2.3749874955400254

Epoch: 5| Step: 10
Training loss: 1.7337021080833794
Validation loss: 2.34189388529175

Epoch: 5| Step: 11
Training loss: 2.0972827315987246
Validation loss: 2.355015995338475

Epoch: 98| Step: 0
Training loss: 1.184708929167439
Validation loss: 2.3799142732394376

Epoch: 5| Step: 1
Training loss: 1.5741789933478132
Validation loss: 2.420128588485021

Epoch: 5| Step: 2
Training loss: 1.571183907052734
Validation loss: 2.3576700374403985

Epoch: 5| Step: 3
Training loss: 1.6423717827301252
Validation loss: 2.3671830516139707

Epoch: 5| Step: 4
Training loss: 1.828038792330028
Validation loss: 2.4060450214751588

Epoch: 5| Step: 5
Training loss: 1.7144844530345749
Validation loss: 2.355783674486777

Epoch: 5| Step: 6
Training loss: 2.6252661070591556
Validation loss: 2.3633099451766264

Epoch: 5| Step: 7
Training loss: 1.0818046029479402
Validation loss: 2.3945789384267804

Epoch: 5| Step: 8
Training loss: 1.701568382119905
Validation loss: 2.3482264896229723

Epoch: 5| Step: 9
Training loss: 1.9871808137644718
Validation loss: 2.383749205534652

Epoch: 5| Step: 10
Training loss: 1.7125605718662307
Validation loss: 2.389885177078657

Epoch: 5| Step: 11
Training loss: 0.7446181399708355
Validation loss: 2.337706647585107

Epoch: 99| Step: 0
Training loss: 1.9848082662655502
Validation loss: 2.3897724241562197

Epoch: 5| Step: 1
Training loss: 1.7327191120433325
Validation loss: 2.3798241976580816

Epoch: 5| Step: 2
Training loss: 2.3372084818322967
Validation loss: 2.4331562001987685

Epoch: 5| Step: 3
Training loss: 1.4928544236769197
Validation loss: 2.382838656589382

Epoch: 5| Step: 4
Training loss: 1.115088725558471
Validation loss: 2.3582675557910098

Epoch: 5| Step: 5
Training loss: 1.5685594176984772
Validation loss: 2.3758124835641437

Epoch: 5| Step: 6
Training loss: 1.3896462929039584
Validation loss: 2.396291437442469

Epoch: 5| Step: 7
Training loss: 1.7323130817508006
Validation loss: 2.353625882469305

Epoch: 5| Step: 8
Training loss: 1.898453072692045
Validation loss: 2.340137299818811

Epoch: 5| Step: 9
Training loss: 1.7277785631704776
Validation loss: 2.377880081818641

Epoch: 5| Step: 10
Training loss: 1.5165352201965767
Validation loss: 2.356268058103917

Epoch: 5| Step: 11
Training loss: 1.1198946291879468
Validation loss: 2.3563070012929273

Epoch: 100| Step: 0
Training loss: 1.6437840157241892
Validation loss: 2.4232274370873705

Epoch: 5| Step: 1
Training loss: 1.554206045161532
Validation loss: 2.5091202159607873

Epoch: 5| Step: 2
Training loss: 1.400048037113579
Validation loss: 2.597685035029806

Epoch: 5| Step: 3
Training loss: 1.826590456393768
Validation loss: 2.5165771435821145

Epoch: 5| Step: 4
Training loss: 1.6080451581981283
Validation loss: 2.4079793809098264

Epoch: 5| Step: 5
Training loss: 1.6468660357989546
Validation loss: 2.3789666788812416

Epoch: 5| Step: 6
Training loss: 1.6738576096349307
Validation loss: 2.371602485122951

Epoch: 5| Step: 7
Training loss: 2.091505299254363
Validation loss: 2.329786160326756

Epoch: 5| Step: 8
Training loss: 1.8806541386353473
Validation loss: 2.3642839138560325

Epoch: 5| Step: 9
Training loss: 1.756413899440582
Validation loss: 2.3337981869375035

Epoch: 5| Step: 10
Training loss: 1.8522622118266852
Validation loss: 2.4093056924023766

Epoch: 5| Step: 11
Training loss: 0.9929804599410645
Validation loss: 2.324010981828718

Epoch: 101| Step: 0
Training loss: 1.5316148440062367
Validation loss: 2.3602127478398294

Epoch: 5| Step: 1
Training loss: 1.8946575948528004
Validation loss: 2.412065649215425

Epoch: 5| Step: 2
Training loss: 1.683440588691049
Validation loss: 2.417120057907506

Epoch: 5| Step: 3
Training loss: 1.498206815176483
Validation loss: 2.3867374945953896

Epoch: 5| Step: 4
Training loss: 1.0054517197667228
Validation loss: 2.43608891569321

Epoch: 5| Step: 5
Training loss: 1.8121314496198375
Validation loss: 2.429090837524127

Epoch: 5| Step: 6
Training loss: 2.1169900837315985
Validation loss: 2.4740142166786203

Epoch: 5| Step: 7
Training loss: 1.7673617573028895
Validation loss: 2.447747152965865

Epoch: 5| Step: 8
Training loss: 1.3411256757783037
Validation loss: 2.3841729663066533

Epoch: 5| Step: 9
Training loss: 1.4615168111371317
Validation loss: 2.379019063812537

Epoch: 5| Step: 10
Training loss: 2.061813818332311
Validation loss: 2.3780809963999197

Epoch: 5| Step: 11
Training loss: 1.263028625254503
Validation loss: 2.39568444217828

Epoch: 102| Step: 0
Training loss: 1.400377558137804
Validation loss: 2.392885070626282

Epoch: 5| Step: 1
Training loss: 1.8612065630802188
Validation loss: 2.398082319586876

Epoch: 5| Step: 2
Training loss: 1.582146007002051
Validation loss: 2.3973133505295863

Epoch: 5| Step: 3
Training loss: 1.6323800130215487
Validation loss: 2.368245663629819

Epoch: 5| Step: 4
Training loss: 1.350503407326799
Validation loss: 2.3726840334444086

Epoch: 5| Step: 5
Training loss: 1.9817738944459016
Validation loss: 2.431630626080853

Epoch: 5| Step: 6
Training loss: 1.370324595625244
Validation loss: 2.4236788195236847

Epoch: 5| Step: 7
Training loss: 1.791210634021278
Validation loss: 2.4050425228779733

Epoch: 5| Step: 8
Training loss: 1.4069979479977435
Validation loss: 2.4028574820683977

Epoch: 5| Step: 9
Training loss: 1.980830232935838
Validation loss: 2.418033545575465

Epoch: 5| Step: 10
Training loss: 1.215355523059794
Validation loss: 2.4056401078451883

Epoch: 5| Step: 11
Training loss: 1.38111644116416
Validation loss: 2.3923218155155723

Epoch: 103| Step: 0
Training loss: 1.606168496999357
Validation loss: 2.367050645353314

Epoch: 5| Step: 1
Training loss: 1.049991920985067
Validation loss: 2.3664626175153507

Epoch: 5| Step: 2
Training loss: 1.361825685137804
Validation loss: 2.405735988955512

Epoch: 5| Step: 3
Training loss: 1.4298568375157021
Validation loss: 2.3891924719408695

Epoch: 5| Step: 4
Training loss: 2.1112642093268366
Validation loss: 2.399565796847371

Epoch: 5| Step: 5
Training loss: 1.178534139728612
Validation loss: 2.363889711515336

Epoch: 5| Step: 6
Training loss: 1.2732269487494563
Validation loss: 2.361688073729107

Epoch: 5| Step: 7
Training loss: 1.5846411005658472
Validation loss: 2.3923221331815174

Epoch: 5| Step: 8
Training loss: 2.1522238917823784
Validation loss: 2.364404095285747

Epoch: 5| Step: 9
Training loss: 2.1376804788701307
Validation loss: 2.412110334594371

Epoch: 5| Step: 10
Training loss: 1.2161457897679104
Validation loss: 2.3631774627342446

Epoch: 5| Step: 11
Training loss: 1.9709721694444622
Validation loss: 2.3805164927882307

Epoch: 104| Step: 0
Training loss: 1.2559887476799727
Validation loss: 2.4205122672135704

Epoch: 5| Step: 1
Training loss: 1.93348684304365
Validation loss: 2.3830523552582656

Epoch: 5| Step: 2
Training loss: 1.797456199526177
Validation loss: 2.420811401132145

Epoch: 5| Step: 3
Training loss: 1.702924664115125
Validation loss: 2.455046700838175

Epoch: 5| Step: 4
Training loss: 1.3708974583632216
Validation loss: 2.512462946711873

Epoch: 5| Step: 5
Training loss: 1.7647850942130925
Validation loss: 2.451212730928443

Epoch: 5| Step: 6
Training loss: 1.424444371367433
Validation loss: 2.3882329105455393

Epoch: 5| Step: 7
Training loss: 1.605218872524207
Validation loss: 2.3749384704784355

Epoch: 5| Step: 8
Training loss: 1.540709413146443
Validation loss: 2.4275580557243006

Epoch: 5| Step: 9
Training loss: 0.742867008146342
Validation loss: 2.3233413258229905

Epoch: 5| Step: 10
Training loss: 1.9539142082262775
Validation loss: 2.4183267955858163

Epoch: 5| Step: 11
Training loss: 2.4464892398762106
Validation loss: 2.346432511309132

Epoch: 105| Step: 0
Training loss: 1.2258007332473333
Validation loss: 2.3949249051863575

Epoch: 5| Step: 1
Training loss: 1.8173774337893942
Validation loss: 2.3889732056407604

Epoch: 5| Step: 2
Training loss: 1.4715414912615106
Validation loss: 2.397713861636132

Epoch: 5| Step: 3
Training loss: 0.9855223735435349
Validation loss: 2.3738355961118613

Epoch: 5| Step: 4
Training loss: 1.444058425788605
Validation loss: 2.3843214166502453

Epoch: 5| Step: 5
Training loss: 1.6204746029142776
Validation loss: 2.3518509418596203

Epoch: 5| Step: 6
Training loss: 1.5632247007132545
Validation loss: 2.4209376131032023

Epoch: 5| Step: 7
Training loss: 1.4639162102469456
Validation loss: 2.4060878079730728

Epoch: 5| Step: 8
Training loss: 1.565180729555301
Validation loss: 2.4263637783134366

Epoch: 5| Step: 9
Training loss: 1.9100330523681825
Validation loss: 2.434740521922603

Epoch: 5| Step: 10
Training loss: 1.527746981493428
Validation loss: 2.449127102262218

Epoch: 5| Step: 11
Training loss: 1.6278439357898287
Validation loss: 2.4829374308730663

Epoch: 106| Step: 0
Training loss: 0.8128954585241929
Validation loss: 2.4868060878956793

Epoch: 5| Step: 1
Training loss: 1.4932075728669187
Validation loss: 2.4498919829736217

Epoch: 5| Step: 2
Training loss: 1.6341955724659711
Validation loss: 2.346331958616258

Epoch: 5| Step: 3
Training loss: 1.9659127271962376
Validation loss: 2.4064320829783434

Epoch: 5| Step: 4
Training loss: 1.3317231300153967
Validation loss: 2.431030707615073

Epoch: 5| Step: 5
Training loss: 1.829102670452314
Validation loss: 2.4493216047334103

Epoch: 5| Step: 6
Training loss: 1.7486677548289624
Validation loss: 2.2891665295081367

Epoch: 5| Step: 7
Training loss: 2.073265876940142
Validation loss: 2.363139259129225

Epoch: 5| Step: 8
Training loss: 1.163409056089113
Validation loss: 2.354236204391897

Epoch: 5| Step: 9
Training loss: 1.0441963315090115
Validation loss: 2.4284771258480093

Epoch: 5| Step: 10
Training loss: 1.6256884070397524
Validation loss: 2.3873188827214538

Epoch: 5| Step: 11
Training loss: 1.267310209718183
Validation loss: 2.3929507841157527

Epoch: 107| Step: 0
Training loss: 1.828299424417154
Validation loss: 2.3705070435886624

Epoch: 5| Step: 1
Training loss: 0.9136631411118271
Validation loss: 2.535558095627145

Epoch: 5| Step: 2
Training loss: 1.5354961766326118
Validation loss: 2.511342468869493

Epoch: 5| Step: 3
Training loss: 1.9706957451159515
Validation loss: 2.532073314819135

Epoch: 5| Step: 4
Training loss: 1.3073018543510093
Validation loss: 2.4694842642932655

Epoch: 5| Step: 5
Training loss: 1.4017670702193379
Validation loss: 2.451647907047432

Epoch: 5| Step: 6
Training loss: 1.6180979796356738
Validation loss: 2.372724572417338

Epoch: 5| Step: 7
Training loss: 1.592133019650479
Validation loss: 2.336260676487992

Epoch: 5| Step: 8
Training loss: 1.5785163167618272
Validation loss: 2.3668559884072615

Epoch: 5| Step: 9
Training loss: 1.3302934783156297
Validation loss: 2.411719290919975

Epoch: 5| Step: 10
Training loss: 1.639181464780883
Validation loss: 2.375602440804294

Epoch: 5| Step: 11
Training loss: 0.7854765433263853
Validation loss: 2.3502134697083092

Epoch: 108| Step: 0
Training loss: 1.4391584366454662
Validation loss: 2.3418327606650147

Epoch: 5| Step: 1
Training loss: 1.6583402147901112
Validation loss: 2.417026424486576

Epoch: 5| Step: 2
Training loss: 1.925407017370845
Validation loss: 2.3668792490337207

Epoch: 5| Step: 3
Training loss: 1.0890161797238447
Validation loss: 2.350751515203919

Epoch: 5| Step: 4
Training loss: 1.310006361356243
Validation loss: 2.3787411662231888

Epoch: 5| Step: 5
Training loss: 1.5631863421789343
Validation loss: 2.3672882704903615

Epoch: 5| Step: 6
Training loss: 1.3916835399373817
Validation loss: 2.472474881511623

Epoch: 5| Step: 7
Training loss: 0.9587623976362208
Validation loss: 2.4395509165253313

Epoch: 5| Step: 8
Training loss: 1.8785911502041215
Validation loss: 2.410201803361166

Epoch: 5| Step: 9
Training loss: 1.4842864963849904
Validation loss: 2.377779304819815

Epoch: 5| Step: 10
Training loss: 1.8106260807032812
Validation loss: 2.4022828856824265

Epoch: 5| Step: 11
Training loss: 1.925522297439108
Validation loss: 2.3785375529657933

Epoch: 109| Step: 0
Training loss: 2.062494682536351
Validation loss: 2.4433743328771995

Epoch: 5| Step: 1
Training loss: 1.272701495392581
Validation loss: 2.469524692557669

Epoch: 5| Step: 2
Training loss: 1.905284011475175
Validation loss: 2.4163455105734895

Epoch: 5| Step: 3
Training loss: 1.1936195701725698
Validation loss: 2.442144350503349

Epoch: 5| Step: 4
Training loss: 1.4451354872071678
Validation loss: 2.3973580498252214

Epoch: 5| Step: 5
Training loss: 1.0824201965869678
Validation loss: 2.374889080485807

Epoch: 5| Step: 6
Training loss: 1.3995059316631404
Validation loss: 2.485500120907969

Epoch: 5| Step: 7
Training loss: 1.8312298093340185
Validation loss: 2.4927124917430974

Epoch: 5| Step: 8
Training loss: 1.7856092149612937
Validation loss: 2.5343623630194516

Epoch: 5| Step: 9
Training loss: 1.545862887872005
Validation loss: 2.4938325106643164

Epoch: 5| Step: 10
Training loss: 1.4263675686040331
Validation loss: 2.400194421317351

Epoch: 5| Step: 11
Training loss: 1.5635956546714285
Validation loss: 2.3474631756408635

Epoch: 110| Step: 0
Training loss: 1.8134291667835511
Validation loss: 2.408210785320687

Epoch: 5| Step: 1
Training loss: 1.4537977076645812
Validation loss: 2.4330745120640254

Epoch: 5| Step: 2
Training loss: 2.183346428965347
Validation loss: 2.4635714367176025

Epoch: 5| Step: 3
Training loss: 1.0426917690570878
Validation loss: 2.4237867295969484

Epoch: 5| Step: 4
Training loss: 1.0453599813537175
Validation loss: 2.3729985487298912

Epoch: 5| Step: 5
Training loss: 1.1176529561616477
Validation loss: 2.4796950407660696

Epoch: 5| Step: 6
Training loss: 1.4230701328401096
Validation loss: 2.5331078842090586

Epoch: 5| Step: 7
Training loss: 2.337063827211079
Validation loss: 2.5383525481835774

Epoch: 5| Step: 8
Training loss: 1.5511810018116743
Validation loss: 2.521043407472264

Epoch: 5| Step: 9
Training loss: 1.4191793523114333
Validation loss: 2.448508245261198

Epoch: 5| Step: 10
Training loss: 1.4578599797374299
Validation loss: 2.4140247436665416

Epoch: 5| Step: 11
Training loss: 0.8783838372546662
Validation loss: 2.4590875565078085

Epoch: 111| Step: 0
Training loss: 1.479385986545188
Validation loss: 2.4629232317233005

Epoch: 5| Step: 1
Training loss: 1.2557073949094386
Validation loss: 2.4256193114124467

Epoch: 5| Step: 2
Training loss: 1.564627838856303
Validation loss: 2.535535880937544

Epoch: 5| Step: 3
Training loss: 1.5847447612800432
Validation loss: 2.481432165446077

Epoch: 5| Step: 4
Training loss: 1.5688816972750226
Validation loss: 2.450606545636066

Epoch: 5| Step: 5
Training loss: 1.019749059102007
Validation loss: 2.35945562725954

Epoch: 5| Step: 6
Training loss: 1.6393804280012687
Validation loss: 2.432595290538889

Epoch: 5| Step: 7
Training loss: 1.7751968999908665
Validation loss: 2.3815893400340244

Epoch: 5| Step: 8
Training loss: 1.0605264735498867
Validation loss: 2.378422116280097

Epoch: 5| Step: 9
Training loss: 1.8469606666899885
Validation loss: 2.439975907501241

Epoch: 5| Step: 10
Training loss: 1.4431646935847093
Validation loss: 2.3985961567511276

Epoch: 5| Step: 11
Training loss: 1.3954551051485782
Validation loss: 2.346442083700858

Epoch: 112| Step: 0
Training loss: 1.628128341700663
Validation loss: 2.35170909724583

Epoch: 5| Step: 1
Training loss: 1.1783366268728828
Validation loss: 2.3997766481884395

Epoch: 5| Step: 2
Training loss: 1.1146995745262374
Validation loss: 2.4002888872372203

Epoch: 5| Step: 3
Training loss: 1.0668627422144814
Validation loss: 2.402930947262384

Epoch: 5| Step: 4
Training loss: 1.5190126764899892
Validation loss: 2.416830276563438

Epoch: 5| Step: 5
Training loss: 1.4416181207028167
Validation loss: 2.377072266784994

Epoch: 5| Step: 6
Training loss: 1.5304851568101092
Validation loss: 2.366983658813284

Epoch: 5| Step: 7
Training loss: 1.662074159278265
Validation loss: 2.4290788814316695

Epoch: 5| Step: 8
Training loss: 1.3329652437113215
Validation loss: 2.410603515243098

Epoch: 5| Step: 9
Training loss: 1.4484004669228734
Validation loss: 2.437952199381515

Epoch: 5| Step: 10
Training loss: 1.845156763338206
Validation loss: 2.4639042163454796

Epoch: 5| Step: 11
Training loss: 0.8822889547895589
Validation loss: 2.501852819182581

Epoch: 113| Step: 0
Training loss: 1.3624229899349973
Validation loss: 2.506971891783644

Epoch: 5| Step: 1
Training loss: 1.3264797566807147
Validation loss: 2.437840050835575

Epoch: 5| Step: 2
Training loss: 1.2579181697836899
Validation loss: 2.418452050753119

Epoch: 5| Step: 3
Training loss: 1.3696324312705306
Validation loss: 2.4396036558230496

Epoch: 5| Step: 4
Training loss: 1.92014967225741
Validation loss: 2.428209069661021

Epoch: 5| Step: 5
Training loss: 1.5916420703338934
Validation loss: 2.468689595863716

Epoch: 5| Step: 6
Training loss: 1.514966526731835
Validation loss: 2.4308297966844292

Epoch: 5| Step: 7
Training loss: 1.6135157675621365
Validation loss: 2.3683612272110723

Epoch: 5| Step: 8
Training loss: 1.3460661422014943
Validation loss: 2.427021440581814

Epoch: 5| Step: 9
Training loss: 1.0124231191574942
Validation loss: 2.422537157333421

Epoch: 5| Step: 10
Training loss: 1.4251599774156645
Validation loss: 2.4565546395273476

Epoch: 5| Step: 11
Training loss: 0.8872405881944136
Validation loss: 2.4355133470370434

Epoch: 114| Step: 0
Training loss: 1.9043518371475416
Validation loss: 2.4360535682690454

Epoch: 5| Step: 1
Training loss: 1.4583068663602283
Validation loss: 2.4347406076057596

Epoch: 5| Step: 2
Training loss: 1.8242933106960397
Validation loss: 2.4763029144977864

Epoch: 5| Step: 3
Training loss: 1.500648993920331
Validation loss: 2.5416111347250108

Epoch: 5| Step: 4
Training loss: 1.396080161328992
Validation loss: 2.467008386818029

Epoch: 5| Step: 5
Training loss: 0.9361890528033353
Validation loss: 2.4443003049502017

Epoch: 5| Step: 6
Training loss: 1.0528803849746617
Validation loss: 2.440343665247489

Epoch: 5| Step: 7
Training loss: 1.2788746377233955
Validation loss: 2.4209845618505907

Epoch: 5| Step: 8
Training loss: 1.8542889186832283
Validation loss: 2.4475037666177517

Epoch: 5| Step: 9
Training loss: 1.0915043802457423
Validation loss: 2.442077198657618

Epoch: 5| Step: 10
Training loss: 1.091702916123452
Validation loss: 2.4626472104796564

Epoch: 5| Step: 11
Training loss: 1.8830258577002659
Validation loss: 2.4227957421191535

Epoch: 115| Step: 0
Training loss: 1.5110339602397436
Validation loss: 2.4717062862416466

Epoch: 5| Step: 1
Training loss: 1.1101048177768693
Validation loss: 2.41983804257362

Epoch: 5| Step: 2
Training loss: 1.2962261093277634
Validation loss: 2.4407862941702114

Epoch: 5| Step: 3
Training loss: 2.0408782474699696
Validation loss: 2.38825167029401

Epoch: 5| Step: 4
Training loss: 1.38239911468387
Validation loss: 2.3836103635675974

Epoch: 5| Step: 5
Training loss: 1.2098706375675592
Validation loss: 2.391681171887193

Epoch: 5| Step: 6
Training loss: 1.0977507309621255
Validation loss: 2.5066719947688143

Epoch: 5| Step: 7
Training loss: 1.2517644826372354
Validation loss: 2.451996825309231

Epoch: 5| Step: 8
Training loss: 1.1229187469368789
Validation loss: 2.432948051829906

Epoch: 5| Step: 9
Training loss: 1.4390176142713993
Validation loss: 2.4088269776880464

Epoch: 5| Step: 10
Training loss: 1.2684822326125562
Validation loss: 2.4117603744508305

Epoch: 5| Step: 11
Training loss: 1.3482010334558152
Validation loss: 2.392433841013808

Epoch: 116| Step: 0
Training loss: 1.2390967250104326
Validation loss: 2.492043155169187

Epoch: 5| Step: 1
Training loss: 1.5349976746482508
Validation loss: 2.4062388696454393

Epoch: 5| Step: 2
Training loss: 0.7184990983982574
Validation loss: 2.4694276595883182

Epoch: 5| Step: 3
Training loss: 1.218591043914635
Validation loss: 2.4886812799783273

Epoch: 5| Step: 4
Training loss: 1.8674253048953267
Validation loss: 2.3945373900160027

Epoch: 5| Step: 5
Training loss: 1.2578582755342336
Validation loss: 2.415062529535628

Epoch: 5| Step: 6
Training loss: 1.389138659694726
Validation loss: 2.3546817027668

Epoch: 5| Step: 7
Training loss: 1.3936776505923747
Validation loss: 2.415032847090931

Epoch: 5| Step: 8
Training loss: 0.7531188648021466
Validation loss: 2.42040363039234

Epoch: 5| Step: 9
Training loss: 1.6499489458450718
Validation loss: 2.430817918619612

Epoch: 5| Step: 10
Training loss: 0.8737800131296833
Validation loss: 2.3873726198325125

Epoch: 5| Step: 11
Training loss: 2.718569519366466
Validation loss: 2.3912581434375433

Epoch: 117| Step: 0
Training loss: 1.3032107190085311
Validation loss: 2.4320837064028984

Epoch: 5| Step: 1
Training loss: 1.5345371541347717
Validation loss: 2.402235157897771

Epoch: 5| Step: 2
Training loss: 1.423526936138543
Validation loss: 2.4407194590636316

Epoch: 5| Step: 3
Training loss: 1.2179464968250526
Validation loss: 2.4549851826080133

Epoch: 5| Step: 4
Training loss: 1.8388463777325903
Validation loss: 2.443279058700164

Epoch: 5| Step: 5
Training loss: 1.5035509358573553
Validation loss: 2.452266713050733

Epoch: 5| Step: 6
Training loss: 1.4530388591214425
Validation loss: 2.5179684309052286

Epoch: 5| Step: 7
Training loss: 0.9385635383307068
Validation loss: 2.4658707475697597

Epoch: 5| Step: 8
Training loss: 1.2070453729389687
Validation loss: 2.4800679000601256

Epoch: 5| Step: 9
Training loss: 1.1182232303873432
Validation loss: 2.406907734832799

Epoch: 5| Step: 10
Training loss: 1.2927639617549593
Validation loss: 2.4937112548673674

Epoch: 5| Step: 11
Training loss: 1.054110503428272
Validation loss: 2.391483692874724

Epoch: 118| Step: 0
Training loss: 1.383453866962189
Validation loss: 2.439392101297291

Epoch: 5| Step: 1
Training loss: 0.8490571430642436
Validation loss: 2.465311944005433

Epoch: 5| Step: 2
Training loss: 1.8882661717057079
Validation loss: 2.471033669777657

Epoch: 5| Step: 3
Training loss: 1.4977785190903679
Validation loss: 2.4375900981423144

Epoch: 5| Step: 4
Training loss: 1.231316652769139
Validation loss: 2.414806518794241

Epoch: 5| Step: 5
Training loss: 1.6725558026730887
Validation loss: 2.4860221592625744

Epoch: 5| Step: 6
Training loss: 0.9538437993932233
Validation loss: 2.4133441065996544

Epoch: 5| Step: 7
Training loss: 1.2769921428405842
Validation loss: 2.430918593239367

Epoch: 5| Step: 8
Training loss: 1.3787764793474797
Validation loss: 2.418814339221501

Epoch: 5| Step: 9
Training loss: 1.1032550875548397
Validation loss: 2.4230477744230003

Epoch: 5| Step: 10
Training loss: 0.9306363945257664
Validation loss: 2.476324719828249

Epoch: 5| Step: 11
Training loss: 1.7859417879415251
Validation loss: 2.419804631539365

Epoch: 119| Step: 0
Training loss: 1.31577641392802
Validation loss: 2.4349229794109304

Epoch: 5| Step: 1
Training loss: 1.6745937025450428
Validation loss: 2.3946483224581745

Epoch: 5| Step: 2
Training loss: 1.4078858926929667
Validation loss: 2.4113812169926296

Epoch: 5| Step: 3
Training loss: 1.1858023002265061
Validation loss: 2.405407440174019

Epoch: 5| Step: 4
Training loss: 1.447547792426434
Validation loss: 2.486922910896214

Epoch: 5| Step: 5
Training loss: 1.1468488643485115
Validation loss: 2.4462404328751908

Epoch: 5| Step: 6
Training loss: 1.063360202613258
Validation loss: 2.472242970653386

Epoch: 5| Step: 7
Training loss: 1.516562103328028
Validation loss: 2.484816693882266

Epoch: 5| Step: 8
Training loss: 1.2817200519537018
Validation loss: 2.469987904960476

Epoch: 5| Step: 9
Training loss: 1.0908379070942817
Validation loss: 2.5006983457164873

Epoch: 5| Step: 10
Training loss: 1.421088284004357
Validation loss: 2.452132285371404

Epoch: 5| Step: 11
Training loss: 1.086673953396602
Validation loss: 2.426240260238791

Epoch: 120| Step: 0
Training loss: 0.9446986703972552
Validation loss: 2.448712340693819

Epoch: 5| Step: 1
Training loss: 1.4962440196135283
Validation loss: 2.4513415010685096

Epoch: 5| Step: 2
Training loss: 0.9373743608846189
Validation loss: 2.4966349644318298

Epoch: 5| Step: 3
Training loss: 1.3706958334623673
Validation loss: 2.4165699805178416

Epoch: 5| Step: 4
Training loss: 1.1833184051019778
Validation loss: 2.4274500309259857

Epoch: 5| Step: 5
Training loss: 1.2226560549994852
Validation loss: 2.5081037488902593

Epoch: 5| Step: 6
Training loss: 1.3587481489405793
Validation loss: 2.480840764220922

Epoch: 5| Step: 7
Training loss: 1.470713662240223
Validation loss: 2.5277097457655002

Epoch: 5| Step: 8
Training loss: 1.2438113556876693
Validation loss: 2.4647999259329496

Epoch: 5| Step: 9
Training loss: 1.3821212851360665
Validation loss: 2.554441617123936

Epoch: 5| Step: 10
Training loss: 1.5445546173041507
Validation loss: 2.4641883893733136

Epoch: 5| Step: 11
Training loss: 1.4858073501468783
Validation loss: 2.4311500228030027

Epoch: 121| Step: 0
Training loss: 0.925560196508328
Validation loss: 2.4885661762021116

Epoch: 5| Step: 1
Training loss: 0.8145393673543355
Validation loss: 2.4702107759427006

Epoch: 5| Step: 2
Training loss: 1.7491621327746574
Validation loss: 2.440221237473744

Epoch: 5| Step: 3
Training loss: 1.2096592709502785
Validation loss: 2.395345469573664

Epoch: 5| Step: 4
Training loss: 1.4012525983474966
Validation loss: 2.4443451264884732

Epoch: 5| Step: 5
Training loss: 1.0422011275880314
Validation loss: 2.4065325104640047

Epoch: 5| Step: 6
Training loss: 1.2668631819487626
Validation loss: 2.477486731778879

Epoch: 5| Step: 7
Training loss: 1.2173657993086864
Validation loss: 2.415734478508199

Epoch: 5| Step: 8
Training loss: 1.5572762717142041
Validation loss: 2.403759873406784

Epoch: 5| Step: 9
Training loss: 1.3551594054146776
Validation loss: 2.4679676216511743

Epoch: 5| Step: 10
Training loss: 1.4496988082349307
Validation loss: 2.575408807111061

Epoch: 5| Step: 11
Training loss: 1.1418477650334842
Validation loss: 2.531919178988068

Epoch: 122| Step: 0
Training loss: 1.2112785597387732
Validation loss: 2.4744024473734645

Epoch: 5| Step: 1
Training loss: 1.6295704756622669
Validation loss: 2.452877424993345

Epoch: 5| Step: 2
Training loss: 1.1494652956269842
Validation loss: 2.4110068824856534

Epoch: 5| Step: 3
Training loss: 1.1725810657774165
Validation loss: 2.470732520610858

Epoch: 5| Step: 4
Training loss: 1.5406821776142583
Validation loss: 2.4766704644096627

Epoch: 5| Step: 5
Training loss: 1.36985461981207
Validation loss: 2.4476623842722804

Epoch: 5| Step: 6
Training loss: 1.1201499129339714
Validation loss: 2.480153882324688

Epoch: 5| Step: 7
Training loss: 1.052660654632653
Validation loss: 2.504105026916737

Epoch: 5| Step: 8
Training loss: 1.091234529785404
Validation loss: 2.558217063140061

Epoch: 5| Step: 9
Training loss: 1.5975911096849866
Validation loss: 2.6256385359626684

Epoch: 5| Step: 10
Training loss: 1.3939791315697714
Validation loss: 2.5394094415974013

Epoch: 5| Step: 11
Training loss: 0.3347053998903047
Validation loss: 2.524863203516612

Epoch: 123| Step: 0
Training loss: 1.1695045911544701
Validation loss: 2.4644082838908776

Epoch: 5| Step: 1
Training loss: 1.5875754330953293
Validation loss: 2.45643673220154

Epoch: 5| Step: 2
Training loss: 0.788407875680803
Validation loss: 2.4675886887358507

Epoch: 5| Step: 3
Training loss: 1.9019299317499199
Validation loss: 2.3799904063409434

Epoch: 5| Step: 4
Training loss: 0.9792550162098511
Validation loss: 2.481031214903741

Epoch: 5| Step: 5
Training loss: 1.3586537431804828
Validation loss: 2.431738573422611

Epoch: 5| Step: 6
Training loss: 1.364509226216023
Validation loss: 2.480179204586834

Epoch: 5| Step: 7
Training loss: 1.2648035374093096
Validation loss: 2.388800180128695

Epoch: 5| Step: 8
Training loss: 1.5186356992056573
Validation loss: 2.455837329627821

Epoch: 5| Step: 9
Training loss: 1.3656100518916499
Validation loss: 2.4830383187684

Epoch: 5| Step: 10
Training loss: 1.1566036817531309
Validation loss: 2.4933999718615154

Epoch: 5| Step: 11
Training loss: 0.7150800970869899
Validation loss: 2.4623299711041877

Epoch: 124| Step: 0
Training loss: 1.011412231672783
Validation loss: 2.4110419419898084

Epoch: 5| Step: 1
Training loss: 1.298179154568177
Validation loss: 2.3962401431694667

Epoch: 5| Step: 2
Training loss: 1.0291583494604513
Validation loss: 2.4017006072633764

Epoch: 5| Step: 3
Training loss: 1.3690552079442566
Validation loss: 2.3978014919704957

Epoch: 5| Step: 4
Training loss: 0.8763541574106715
Validation loss: 2.4472313198842297

Epoch: 5| Step: 5
Training loss: 1.2205605385474647
Validation loss: 2.427219163316413

Epoch: 5| Step: 6
Training loss: 1.4027244454916505
Validation loss: 2.4003643120321128

Epoch: 5| Step: 7
Training loss: 1.4064867879936591
Validation loss: 2.4186128365513784

Epoch: 5| Step: 8
Training loss: 0.8735662362042745
Validation loss: 2.5052732841230143

Epoch: 5| Step: 9
Training loss: 0.9368589116624382
Validation loss: 2.41619365820507

Epoch: 5| Step: 10
Training loss: 1.7159899658674476
Validation loss: 2.479069520879546

Epoch: 5| Step: 11
Training loss: 1.8982386229782164
Validation loss: 2.473496798914806

Epoch: 125| Step: 0
Training loss: 0.9451074298970624
Validation loss: 2.481203253823764

Epoch: 5| Step: 1
Training loss: 1.3970757359405164
Validation loss: 2.5228684278728055

Epoch: 5| Step: 2
Training loss: 1.4414987922052094
Validation loss: 2.473655125291071

Epoch: 5| Step: 3
Training loss: 1.4725594324316615
Validation loss: 2.492249813915165

Epoch: 5| Step: 4
Training loss: 1.0570663750811533
Validation loss: 2.429001100982002

Epoch: 5| Step: 5
Training loss: 1.2541787395128563
Validation loss: 2.4698114447175175

Epoch: 5| Step: 6
Training loss: 1.0457608001501473
Validation loss: 2.5239635899376585

Epoch: 5| Step: 7
Training loss: 1.2152135844155074
Validation loss: 2.5418936687991076

Epoch: 5| Step: 8
Training loss: 1.1277248444268437
Validation loss: 2.636215082735911

Epoch: 5| Step: 9
Training loss: 1.2509839476844604
Validation loss: 2.5221571257521345

Epoch: 5| Step: 10
Training loss: 1.5851369255922267
Validation loss: 2.4901673810337117

Epoch: 5| Step: 11
Training loss: 3.165916671947994
Validation loss: 2.4653233274690387

Epoch: 126| Step: 0
Training loss: 0.9420412699776616
Validation loss: 2.4187543514123853

Epoch: 5| Step: 1
Training loss: 0.6859613453537222
Validation loss: 2.4471890984799014

Epoch: 5| Step: 2
Training loss: 1.1615763491671385
Validation loss: 2.4871241076243615

Epoch: 5| Step: 3
Training loss: 1.477445792351089
Validation loss: 2.4329393546911815

Epoch: 5| Step: 4
Training loss: 1.4498653974210978
Validation loss: 2.454949945397937

Epoch: 5| Step: 5
Training loss: 1.247823584794187
Validation loss: 2.503089231917357

Epoch: 5| Step: 6
Training loss: 1.1642876733701575
Validation loss: 2.496027193888494

Epoch: 5| Step: 7
Training loss: 1.1752642638723014
Validation loss: 2.528336445469744

Epoch: 5| Step: 8
Training loss: 1.8323583249936968
Validation loss: 2.5608080379897302

Epoch: 5| Step: 9
Training loss: 1.5267740343200036
Validation loss: 2.3693494901237266

Epoch: 5| Step: 10
Training loss: 0.8503465983638306
Validation loss: 2.421274918897518

Epoch: 5| Step: 11
Training loss: 1.2530320587319228
Validation loss: 2.380679402526377

Epoch: 127| Step: 0
Training loss: 1.0709509511592108
Validation loss: 2.326015201292197

Epoch: 5| Step: 1
Training loss: 1.2539430892143648
Validation loss: 2.4086147058734073

Epoch: 5| Step: 2
Training loss: 1.4208643748601857
Validation loss: 2.378538260892798

Epoch: 5| Step: 3
Training loss: 0.72658830002128
Validation loss: 2.4439146253090573

Epoch: 5| Step: 4
Training loss: 1.1332983093366245
Validation loss: 2.411620397594038

Epoch: 5| Step: 5
Training loss: 1.035989390090608
Validation loss: 2.424690513263175

Epoch: 5| Step: 6
Training loss: 1.4982319584471078
Validation loss: 2.4201975027387492

Epoch: 5| Step: 7
Training loss: 0.828826607087815
Validation loss: 2.4863060018549556

Epoch: 5| Step: 8
Training loss: 1.8768381010093846
Validation loss: 2.463122444425759

Epoch: 5| Step: 9
Training loss: 1.608508200684128
Validation loss: 2.392797957720704

Epoch: 5| Step: 10
Training loss: 1.1221360203135011
Validation loss: 2.383985091227066

Epoch: 5| Step: 11
Training loss: 0.9109189353870182
Validation loss: 2.429457597394047

Epoch: 128| Step: 0
Training loss: 1.3195790618130336
Validation loss: 2.410736558195698

Epoch: 5| Step: 1
Training loss: 1.3324250564827984
Validation loss: 2.4032043073553773

Epoch: 5| Step: 2
Training loss: 1.2787302873719724
Validation loss: 2.467494637374951

Epoch: 5| Step: 3
Training loss: 0.9957994512489433
Validation loss: 2.4506579342851866

Epoch: 5| Step: 4
Training loss: 1.6996476256989828
Validation loss: 2.4084729087097343

Epoch: 5| Step: 5
Training loss: 0.8650064275756347
Validation loss: 2.452597073323109

Epoch: 5| Step: 6
Training loss: 1.4361836584587553
Validation loss: 2.452787461111103

Epoch: 5| Step: 7
Training loss: 0.9810682189117592
Validation loss: 2.4529604765518442

Epoch: 5| Step: 8
Training loss: 1.111635886218481
Validation loss: 2.4642181247356194

Epoch: 5| Step: 9
Training loss: 1.0233715705893331
Validation loss: 2.4537798782902973

Epoch: 5| Step: 10
Training loss: 1.0293523494820203
Validation loss: 2.452427463210588

Epoch: 5| Step: 11
Training loss: 0.9484428405611358
Validation loss: 2.464620951937525

Epoch: 129| Step: 0
Training loss: 1.0211136621169623
Validation loss: 2.4506801806107723

Epoch: 5| Step: 1
Training loss: 1.3904429970270509
Validation loss: 2.422274402786441

Epoch: 5| Step: 2
Training loss: 1.4666826836116011
Validation loss: 2.474764388763369

Epoch: 5| Step: 3
Training loss: 1.1962947424928931
Validation loss: 2.385778251184873

Epoch: 5| Step: 4
Training loss: 0.905486903695705
Validation loss: 2.427166103758071

Epoch: 5| Step: 5
Training loss: 0.9274895917303314
Validation loss: 2.404662004599649

Epoch: 5| Step: 6
Training loss: 1.1112000939713145
Validation loss: 2.4943762050368634

Epoch: 5| Step: 7
Training loss: 1.106107062464309
Validation loss: 2.4019863121199614

Epoch: 5| Step: 8
Training loss: 0.7107286670527817
Validation loss: 2.512225169717834

Epoch: 5| Step: 9
Training loss: 0.9973746049313421
Validation loss: 2.4923176268085685

Epoch: 5| Step: 10
Training loss: 1.1341308288928964
Validation loss: 2.4700957404853203

Epoch: 5| Step: 11
Training loss: 2.919661718918389
Validation loss: 2.5089101162031135

Epoch: 130| Step: 0
Training loss: 1.166067508840305
Validation loss: 2.4247120493741505

Epoch: 5| Step: 1
Training loss: 1.09122721050713
Validation loss: 2.494797240047295

Epoch: 5| Step: 2
Training loss: 1.0215600534563243
Validation loss: 2.4942811843191044

Epoch: 5| Step: 3
Training loss: 0.9991992486239282
Validation loss: 2.4397157884490963

Epoch: 5| Step: 4
Training loss: 0.7243884796125949
Validation loss: 2.5077505965629068

Epoch: 5| Step: 5
Training loss: 1.0812396517572622
Validation loss: 2.426681740462031

Epoch: 5| Step: 6
Training loss: 1.7221295509563441
Validation loss: 2.4029461940060046

Epoch: 5| Step: 7
Training loss: 0.9590349980373395
Validation loss: 2.4702696046718207

Epoch: 5| Step: 8
Training loss: 1.0417401224303855
Validation loss: 2.4768205101160055

Epoch: 5| Step: 9
Training loss: 1.148389490901678
Validation loss: 2.542345489206892

Epoch: 5| Step: 10
Training loss: 0.9427127240888374
Validation loss: 2.5483047318230887

Epoch: 5| Step: 11
Training loss: 1.0029650480431163
Validation loss: 2.430497548607021

Epoch: 131| Step: 0
Training loss: 0.8847000737780616
Validation loss: 2.4327787215236416

Epoch: 5| Step: 1
Training loss: 0.8049077223376163
Validation loss: 2.495751382812282

Epoch: 5| Step: 2
Training loss: 1.3059626304251417
Validation loss: 2.4216371686096694

Epoch: 5| Step: 3
Training loss: 0.9551639011300642
Validation loss: 2.476024079785272

Epoch: 5| Step: 4
Training loss: 1.5917512664813849
Validation loss: 2.422342189724422

Epoch: 5| Step: 5
Training loss: 1.3667439204377863
Validation loss: 2.4396172400338085

Epoch: 5| Step: 6
Training loss: 0.9034168418652103
Validation loss: 2.407897913377298

Epoch: 5| Step: 7
Training loss: 0.7564760201404579
Validation loss: 2.438048235869573

Epoch: 5| Step: 8
Training loss: 1.2438841455089076
Validation loss: 2.5405182582583525

Epoch: 5| Step: 9
Training loss: 1.4901113396847172
Validation loss: 2.5503503728584116

Epoch: 5| Step: 10
Training loss: 1.1548748086400042
Validation loss: 2.564887204491059

Epoch: 5| Step: 11
Training loss: 0.71095355508303
Validation loss: 2.4739574847303576

Epoch: 132| Step: 0
Training loss: 1.0145071480181014
Validation loss: 2.4844574984562193

Epoch: 5| Step: 1
Training loss: 0.5837400046315812
Validation loss: 2.3718188715187765

Epoch: 5| Step: 2
Training loss: 0.9119736041486337
Validation loss: 2.4965512926435296

Epoch: 5| Step: 3
Training loss: 1.106266340576868
Validation loss: 2.4668272937259315

Epoch: 5| Step: 4
Training loss: 1.0310827177370592
Validation loss: 2.350267410620148

Epoch: 5| Step: 5
Training loss: 1.2014976493885479
Validation loss: 2.3680440404306844

Epoch: 5| Step: 6
Training loss: 1.1358632542248555
Validation loss: 2.459564986801632

Epoch: 5| Step: 7
Training loss: 1.7695382562292314
Validation loss: 2.478394172965369

Epoch: 5| Step: 8
Training loss: 0.915697184767087
Validation loss: 2.457442026414959

Epoch: 5| Step: 9
Training loss: 1.2502587527445637
Validation loss: 2.4234733721539516

Epoch: 5| Step: 10
Training loss: 1.0711741077154158
Validation loss: 2.4660598366609845

Epoch: 5| Step: 11
Training loss: 0.687305119376929
Validation loss: 2.460201932584521

Epoch: 133| Step: 0
Training loss: 0.9821499396972917
Validation loss: 2.483216817467139

Epoch: 5| Step: 1
Training loss: 1.0263857708236783
Validation loss: 2.4897749573023966

Epoch: 5| Step: 2
Training loss: 1.0564888723557382
Validation loss: 2.5016163726667027

Epoch: 5| Step: 3
Training loss: 1.266808321627912
Validation loss: 2.4920084977714336

Epoch: 5| Step: 4
Training loss: 1.198859145333993
Validation loss: 2.403291274536911

Epoch: 5| Step: 5
Training loss: 1.0577455620597076
Validation loss: 2.410493469553327

Epoch: 5| Step: 6
Training loss: 1.132469493631929
Validation loss: 2.4753397701947537

Epoch: 5| Step: 7
Training loss: 1.2877699874455417
Validation loss: 2.4706684778571075

Epoch: 5| Step: 8
Training loss: 1.12241198298732
Validation loss: 2.489777462997271

Epoch: 5| Step: 9
Training loss: 0.9244179969573301
Validation loss: 2.4671662075033107

Epoch: 5| Step: 10
Training loss: 0.942154836009384
Validation loss: 2.468935229197347

Epoch: 5| Step: 11
Training loss: 2.994490810154068
Validation loss: 2.501851306345351

Epoch: 134| Step: 0
Training loss: 1.3291186934914991
Validation loss: 2.4432998922391898

Epoch: 5| Step: 1
Training loss: 1.0641989308193252
Validation loss: 2.543507684418199

Epoch: 5| Step: 2
Training loss: 1.4436766568665225
Validation loss: 2.475390232032575

Epoch: 5| Step: 3
Training loss: 0.9548621684367173
Validation loss: 2.4674322256966597

Epoch: 5| Step: 4
Training loss: 1.041157152815035
Validation loss: 2.427276150707835

Epoch: 5| Step: 5
Training loss: 1.0068718120351625
Validation loss: 2.428089339928466

Epoch: 5| Step: 6
Training loss: 1.7575193711755706
Validation loss: 2.4610396348860952

Epoch: 5| Step: 7
Training loss: 0.9519758332134277
Validation loss: 2.460731683430054

Epoch: 5| Step: 8
Training loss: 0.9977282409264343
Validation loss: 2.444280000159123

Epoch: 5| Step: 9
Training loss: 1.168561293927454
Validation loss: 2.381503745282261

Epoch: 5| Step: 10
Training loss: 0.7475301686070955
Validation loss: 2.4480900777443018

Epoch: 5| Step: 11
Training loss: 0.6342357595436648
Validation loss: 2.43052876393372

Epoch: 135| Step: 0
Training loss: 1.0292268037922492
Validation loss: 2.5199169484712565

Epoch: 5| Step: 1
Training loss: 0.8825466126945611
Validation loss: 2.57141503956176

Epoch: 5| Step: 2
Training loss: 0.8942266886943799
Validation loss: 2.462106945567824

Epoch: 5| Step: 3
Training loss: 1.3266022872799266
Validation loss: 2.4936307277854284

Epoch: 5| Step: 4
Training loss: 1.0244071385646907
Validation loss: 2.4474716728968837

Epoch: 5| Step: 5
Training loss: 1.2043533989988884
Validation loss: 2.4434578172107604

Epoch: 5| Step: 6
Training loss: 1.2610279471516956
Validation loss: 2.413683066234377

Epoch: 5| Step: 7
Training loss: 1.7943664289088415
Validation loss: 2.443083469294534

Epoch: 5| Step: 8
Training loss: 1.0754169232263349
Validation loss: 2.517645058384579

Epoch: 5| Step: 9
Training loss: 1.0711822317403288
Validation loss: 2.4492688049685265

Epoch: 5| Step: 10
Training loss: 0.770714252312325
Validation loss: 2.5010910276101566

Epoch: 5| Step: 11
Training loss: 0.5001433882151494
Validation loss: 2.45903461698876

Epoch: 136| Step: 0
Training loss: 1.0123537640871885
Validation loss: 2.4592835575345333

Epoch: 5| Step: 1
Training loss: 1.1317882248018711
Validation loss: 2.4541517121766634

Epoch: 5| Step: 2
Training loss: 0.9020766486315942
Validation loss: 2.56348457650037

Epoch: 5| Step: 3
Training loss: 0.7729670317110049
Validation loss: 2.436317674692818

Epoch: 5| Step: 4
Training loss: 0.8962404006380089
Validation loss: 2.509886002282207

Epoch: 5| Step: 5
Training loss: 1.1435662585812432
Validation loss: 2.432412605355789

Epoch: 5| Step: 6
Training loss: 0.9085213052564025
Validation loss: 2.4427082099724733

Epoch: 5| Step: 7
Training loss: 1.7796822726178785
Validation loss: 2.4417714041703307

Epoch: 5| Step: 8
Training loss: 1.1038804253043244
Validation loss: 2.511307527963289

Epoch: 5| Step: 9
Training loss: 0.9466093326442221
Validation loss: 2.5110869099907567

Epoch: 5| Step: 10
Training loss: 0.9017826333863374
Validation loss: 2.4607298021620236

Epoch: 5| Step: 11
Training loss: 0.8644619975300505
Validation loss: 2.4854865916206443

Epoch: 137| Step: 0
Training loss: 0.9595243095491078
Validation loss: 2.46415168731423

Epoch: 5| Step: 1
Training loss: 0.9147015155621622
Validation loss: 2.43416790748555

Epoch: 5| Step: 2
Training loss: 1.5547508341861689
Validation loss: 2.4425209043994993

Epoch: 5| Step: 3
Training loss: 0.6949949503790648
Validation loss: 2.4741634538175035

Epoch: 5| Step: 4
Training loss: 1.0793742806189812
Validation loss: 2.465361392180729

Epoch: 5| Step: 5
Training loss: 0.6607906295604983
Validation loss: 2.4664496597531493

Epoch: 5| Step: 6
Training loss: 0.8694561674839643
Validation loss: 2.4328998946064564

Epoch: 5| Step: 7
Training loss: 0.8578639878348974
Validation loss: 2.4091717457418125

Epoch: 5| Step: 8
Training loss: 1.1193813311441996
Validation loss: 2.458742428270016

Epoch: 5| Step: 9
Training loss: 0.9283548629177265
Validation loss: 2.459941575702443

Epoch: 5| Step: 10
Training loss: 1.1640218433218281
Validation loss: 2.4087424518695917

Epoch: 5| Step: 11
Training loss: 1.635109340033114
Validation loss: 2.4467748671010177

Epoch: 138| Step: 0
Training loss: 0.9525292207335785
Validation loss: 2.478268818732815

Epoch: 5| Step: 1
Training loss: 1.0230973238921472
Validation loss: 2.552603537551583

Epoch: 5| Step: 2
Training loss: 1.1936158249630549
Validation loss: 2.55119163090051

Epoch: 5| Step: 3
Training loss: 0.7985110598009016
Validation loss: 2.488358966006995

Epoch: 5| Step: 4
Training loss: 1.0416215632528567
Validation loss: 2.464426512147983

Epoch: 5| Step: 5
Training loss: 1.0024102489982596
Validation loss: 2.3995231569460085

Epoch: 5| Step: 6
Training loss: 1.5494752087796309
Validation loss: 2.5094327317465757

Epoch: 5| Step: 7
Training loss: 0.8251790603752762
Validation loss: 2.4509437971655568

Epoch: 5| Step: 8
Training loss: 1.0710340977146373
Validation loss: 2.486408584942985

Epoch: 5| Step: 9
Training loss: 1.2150804099016885
Validation loss: 2.4769725760896497

Epoch: 5| Step: 10
Training loss: 1.037247125992617
Validation loss: 2.4509602813783866

Epoch: 5| Step: 11
Training loss: 1.0642384723901959
Validation loss: 2.481199710506074

Epoch: 139| Step: 0
Training loss: 1.382267214058849
Validation loss: 2.494529201953946

Epoch: 5| Step: 1
Training loss: 0.9533836764156767
Validation loss: 2.4822530581510245

Epoch: 5| Step: 2
Training loss: 1.0773269906514324
Validation loss: 2.5151533549518965

Epoch: 5| Step: 3
Training loss: 1.3832259772286668
Validation loss: 2.5281887341903295

Epoch: 5| Step: 4
Training loss: 1.1469022389017467
Validation loss: 2.4390536027705725

Epoch: 5| Step: 5
Training loss: 1.0542142583384702
Validation loss: 2.4935490467494468

Epoch: 5| Step: 6
Training loss: 0.6540672013013116
Validation loss: 2.453910973046506

Epoch: 5| Step: 7
Training loss: 1.189412935326519
Validation loss: 2.5251484120694245

Epoch: 5| Step: 8
Training loss: 0.8912874067356091
Validation loss: 2.4653906681438627

Epoch: 5| Step: 9
Training loss: 0.6787443523277398
Validation loss: 2.4477135283140967

Epoch: 5| Step: 10
Training loss: 1.02039706710699
Validation loss: 2.509634932344812

Epoch: 5| Step: 11
Training loss: 1.4177221498883543
Validation loss: 2.4690145761222606

Epoch: 140| Step: 0
Training loss: 0.8629064652598046
Validation loss: 2.467350237010878

Epoch: 5| Step: 1
Training loss: 0.7103210962919103
Validation loss: 2.4834444074517474

Epoch: 5| Step: 2
Training loss: 0.8579068561071451
Validation loss: 2.465154181920784

Epoch: 5| Step: 3
Training loss: 0.9843255287939234
Validation loss: 2.4680018317410553

Epoch: 5| Step: 4
Training loss: 1.0062625410352826
Validation loss: 2.4557063215264443

Epoch: 5| Step: 5
Training loss: 0.8123042897954702
Validation loss: 2.497696021491921

Epoch: 5| Step: 6
Training loss: 1.2459052251190468
Validation loss: 2.4717412202677287

Epoch: 5| Step: 7
Training loss: 1.0399027130583118
Validation loss: 2.5610297334829983

Epoch: 5| Step: 8
Training loss: 1.0573902115521918
Validation loss: 2.5385214204623927

Epoch: 5| Step: 9
Training loss: 1.182649191463502
Validation loss: 2.531949311660531

Epoch: 5| Step: 10
Training loss: 1.6092646292459605
Validation loss: 2.5217868929775253

Epoch: 5| Step: 11
Training loss: 1.1864431095011783
Validation loss: 2.4701289941010836

Epoch: 141| Step: 0
Training loss: 1.5493604940494772
Validation loss: 2.5375150532894524

Epoch: 5| Step: 1
Training loss: 0.9009438757483926
Validation loss: 2.4487488664498205

Epoch: 5| Step: 2
Training loss: 0.6269691679140827
Validation loss: 2.473553266324305

Epoch: 5| Step: 3
Training loss: 1.0425111145232069
Validation loss: 2.517369449353202

Epoch: 5| Step: 4
Training loss: 1.3649693396901146
Validation loss: 2.533805636300256

Epoch: 5| Step: 5
Training loss: 0.9193444191043219
Validation loss: 2.5103601050963014

Epoch: 5| Step: 6
Training loss: 0.8530271341272281
Validation loss: 2.5194170588360545

Epoch: 5| Step: 7
Training loss: 0.7650383239072497
Validation loss: 2.491720247463383

Epoch: 5| Step: 8
Training loss: 1.059837989572142
Validation loss: 2.5202015460747225

Epoch: 5| Step: 9
Training loss: 0.7473298463479169
Validation loss: 2.4165395910187706

Epoch: 5| Step: 10
Training loss: 0.8157736777944378
Validation loss: 2.4742856796265276

Epoch: 5| Step: 11
Training loss: 0.8004888977815349
Validation loss: 2.547328881227729

Epoch: 142| Step: 0
Training loss: 0.9986232877232704
Validation loss: 2.4874651182786494

Epoch: 5| Step: 1
Training loss: 0.7964276572814231
Validation loss: 2.504229964558072

Epoch: 5| Step: 2
Training loss: 0.9248052997848917
Validation loss: 2.503808597400191

Epoch: 5| Step: 3
Training loss: 1.2848914433056269
Validation loss: 2.49588369003999

Epoch: 5| Step: 4
Training loss: 1.022101542241566
Validation loss: 2.5296673143825172

Epoch: 5| Step: 5
Training loss: 1.2303274406551057
Validation loss: 2.4560767433789015

Epoch: 5| Step: 6
Training loss: 1.3734389894236538
Validation loss: 2.4937101752942215

Epoch: 5| Step: 7
Training loss: 0.864513432691274
Validation loss: 2.451802393252871

Epoch: 5| Step: 8
Training loss: 0.8121855200537531
Validation loss: 2.494517641142885

Epoch: 5| Step: 9
Training loss: 1.131536672951114
Validation loss: 2.44368641690126

Epoch: 5| Step: 10
Training loss: 0.8018888675385532
Validation loss: 2.4722388720279147

Epoch: 5| Step: 11
Training loss: 0.47710206801542576
Validation loss: 2.4278906815107595

Epoch: 143| Step: 0
Training loss: 0.7135510873288684
Validation loss: 2.4794192439264093

Epoch: 5| Step: 1
Training loss: 1.1327700376773666
Validation loss: 2.5057994650034234

Epoch: 5| Step: 2
Training loss: 0.7315316855920504
Validation loss: 2.4811754656694367

Epoch: 5| Step: 3
Training loss: 0.9935494334473971
Validation loss: 2.4898661561884814

Epoch: 5| Step: 4
Training loss: 0.7356213483825126
Validation loss: 2.447279126088702

Epoch: 5| Step: 5
Training loss: 1.5090743403188476
Validation loss: 2.37894901514894

Epoch: 5| Step: 6
Training loss: 0.8794212019549252
Validation loss: 2.436519975984672

Epoch: 5| Step: 7
Training loss: 0.9911867336080445
Validation loss: 2.4842496876332048

Epoch: 5| Step: 8
Training loss: 0.8462876905108383
Validation loss: 2.5256881597598815

Epoch: 5| Step: 9
Training loss: 1.0398742831796641
Validation loss: 2.59682067970358

Epoch: 5| Step: 10
Training loss: 0.9302973309895743
Validation loss: 2.513527661276756

Epoch: 5| Step: 11
Training loss: 0.6129977305900794
Validation loss: 2.4621583120623116

Epoch: 144| Step: 0
Training loss: 1.194116979382985
Validation loss: 2.598235614004286

Epoch: 5| Step: 1
Training loss: 0.7026419781878384
Validation loss: 2.476576888306355

Epoch: 5| Step: 2
Training loss: 0.9315219379694039
Validation loss: 2.501880133480079

Epoch: 5| Step: 3
Training loss: 1.0177933068203608
Validation loss: 2.4947450523295545

Epoch: 5| Step: 4
Training loss: 0.9525291581584413
Validation loss: 2.50830200108152

Epoch: 5| Step: 5
Training loss: 0.9617944013650378
Validation loss: 2.4347626199167722

Epoch: 5| Step: 6
Training loss: 0.7812336729250962
Validation loss: 2.5069529525023055

Epoch: 5| Step: 7
Training loss: 1.5176941423487964
Validation loss: 2.48391297880619

Epoch: 5| Step: 8
Training loss: 0.8119702079104184
Validation loss: 2.493580475720128

Epoch: 5| Step: 9
Training loss: 0.8226644314524839
Validation loss: 2.5203327077239552

Epoch: 5| Step: 10
Training loss: 0.9662693935190088
Validation loss: 2.476101099268449

Epoch: 5| Step: 11
Training loss: 1.7217885295112305
Validation loss: 2.495235615984806

Epoch: 145| Step: 0
Training loss: 0.9477181523696927
Validation loss: 2.473728146468558

Epoch: 5| Step: 1
Training loss: 0.7958918471736351
Validation loss: 2.519390760738531

Epoch: 5| Step: 2
Training loss: 1.1563975265827466
Validation loss: 2.5254279751239403

Epoch: 5| Step: 3
Training loss: 0.9449189683192168
Validation loss: 2.509739690861873

Epoch: 5| Step: 4
Training loss: 1.1258369087898483
Validation loss: 2.562148880357132

Epoch: 5| Step: 5
Training loss: 0.9776423168241201
Validation loss: 2.5068507781689755

Epoch: 5| Step: 6
Training loss: 1.5395034700498906
Validation loss: 2.5650573390552687

Epoch: 5| Step: 7
Training loss: 0.5869392986235521
Validation loss: 2.449909232527751

Epoch: 5| Step: 8
Training loss: 0.780385645507666
Validation loss: 2.439948303282123

Epoch: 5| Step: 9
Training loss: 0.9017422805912599
Validation loss: 2.4942608084682636

Epoch: 5| Step: 10
Training loss: 1.1151173759056998
Validation loss: 2.523198591798064

Epoch: 5| Step: 11
Training loss: 0.5482989709555393
Validation loss: 2.585982730466075

Epoch: 146| Step: 0
Training loss: 1.0163784460183622
Validation loss: 2.664512085477804

Epoch: 5| Step: 1
Training loss: 1.0748821637531203
Validation loss: 2.6514642612209873

Epoch: 5| Step: 2
Training loss: 0.9429459702617081
Validation loss: 2.6133354839024974

Epoch: 5| Step: 3
Training loss: 0.8350263246509702
Validation loss: 2.5034346352088086

Epoch: 5| Step: 4
Training loss: 1.5719418399622413
Validation loss: 2.5540390980545054

Epoch: 5| Step: 5
Training loss: 0.5626525142326375
Validation loss: 2.4567960051384006

Epoch: 5| Step: 6
Training loss: 0.8792856033531421
Validation loss: 2.5329929481282183

Epoch: 5| Step: 7
Training loss: 1.099415628225757
Validation loss: 2.542131167840604

Epoch: 5| Step: 8
Training loss: 0.7213209445248512
Validation loss: 2.4973293941333163

Epoch: 5| Step: 9
Training loss: 0.9273805927519827
Validation loss: 2.515861200020574

Epoch: 5| Step: 10
Training loss: 0.5938472668132562
Validation loss: 2.5057402751208295

Epoch: 5| Step: 11
Training loss: 0.43507082115998075
Validation loss: 2.5333463363146445

Epoch: 147| Step: 0
Training loss: 0.9546013014317978
Validation loss: 2.4624721011164405

Epoch: 5| Step: 1
Training loss: 1.422536339857127
Validation loss: 2.5790752470693006

Epoch: 5| Step: 2
Training loss: 0.8827363040415818
Validation loss: 2.533571117047914

Epoch: 5| Step: 3
Training loss: 0.8637860923546622
Validation loss: 2.55030164547342

Epoch: 5| Step: 4
Training loss: 0.730805263422452
Validation loss: 2.501773930052794

Epoch: 5| Step: 5
Training loss: 0.9988564568933359
Validation loss: 2.536439822453834

Epoch: 5| Step: 6
Training loss: 0.9325301044810281
Validation loss: 2.491812690764007

Epoch: 5| Step: 7
Training loss: 0.8074684605772323
Validation loss: 2.4657694352443853

Epoch: 5| Step: 8
Training loss: 1.0009176097350176
Validation loss: 2.513171640459965

Epoch: 5| Step: 9
Training loss: 1.0186072360680731
Validation loss: 2.4857575410370876

Epoch: 5| Step: 10
Training loss: 0.3809014908417149
Validation loss: 2.538281802929487

Epoch: 5| Step: 11
Training loss: 0.4114823294132999
Validation loss: 2.5435093013660097

Epoch: 148| Step: 0
Training loss: 0.8339853041060764
Validation loss: 2.468657878170995

Epoch: 5| Step: 1
Training loss: 1.313230901385007
Validation loss: 2.536365798473783

Epoch: 5| Step: 2
Training loss: 0.9278260516997944
Validation loss: 2.4804621258344333

Epoch: 5| Step: 3
Training loss: 0.7443629455871534
Validation loss: 2.49151927635396

Epoch: 5| Step: 4
Training loss: 1.1335292258850977
Validation loss: 2.5107398768201312

Epoch: 5| Step: 5
Training loss: 0.8889725061333853
Validation loss: 2.479513608207189

Epoch: 5| Step: 6
Training loss: 1.1735537901855468
Validation loss: 2.5137620824254423

Epoch: 5| Step: 7
Training loss: 1.0851373812282554
Validation loss: 2.501576709250276

Epoch: 5| Step: 8
Training loss: 0.6481761635548641
Validation loss: 2.4675718647097074

Epoch: 5| Step: 9
Training loss: 0.9078082138721968
Validation loss: 2.5174431716581163

Epoch: 5| Step: 10
Training loss: 0.7542735573766357
Validation loss: 2.501329676356604

Epoch: 5| Step: 11
Training loss: 0.4762277834759111
Validation loss: 2.4258966587397293

Epoch: 149| Step: 0
Training loss: 1.4533920042782593
Validation loss: 2.5071732289564537

Epoch: 5| Step: 1
Training loss: 0.6048952647655879
Validation loss: 2.5387124862040475

Epoch: 5| Step: 2
Training loss: 0.8236129848815578
Validation loss: 2.5855104837192147

Epoch: 5| Step: 3
Training loss: 0.9362999546999902
Validation loss: 2.503320122494318

Epoch: 5| Step: 4
Training loss: 0.8101363279859989
Validation loss: 2.5435076687955096

Epoch: 5| Step: 5
Training loss: 1.040342188257115
Validation loss: 2.4670479335370183

Epoch: 5| Step: 6
Training loss: 0.8454789355680893
Validation loss: 2.486448438379943

Epoch: 5| Step: 7
Training loss: 0.6046985773062558
Validation loss: 2.5137400189351267

Epoch: 5| Step: 8
Training loss: 0.6097593562544996
Validation loss: 2.521237149222385

Epoch: 5| Step: 9
Training loss: 1.0844662806543792
Validation loss: 2.518588553619183

Epoch: 5| Step: 10
Training loss: 0.8145619418041993
Validation loss: 2.5455816042752653

Epoch: 5| Step: 11
Training loss: 0.964501942001294
Validation loss: 2.525993068791271

Epoch: 150| Step: 0
Training loss: 0.8869390340085755
Validation loss: 2.5674544177269856

Epoch: 5| Step: 1
Training loss: 0.5343050347642327
Validation loss: 2.4808080245950146

Epoch: 5| Step: 2
Training loss: 0.7691552264918492
Validation loss: 2.4842636375339557

Epoch: 5| Step: 3
Training loss: 0.920450694357611
Validation loss: 2.4813432248376346

Epoch: 5| Step: 4
Training loss: 0.5837835011068976
Validation loss: 2.5523954992046685

Epoch: 5| Step: 5
Training loss: 1.3287986393349127
Validation loss: 2.522841269933379

Epoch: 5| Step: 6
Training loss: 0.728839955478711
Validation loss: 2.5138374457853527

Epoch: 5| Step: 7
Training loss: 1.1923321737398078
Validation loss: 2.5510630391104274

Epoch: 5| Step: 8
Training loss: 0.8667614207982834
Validation loss: 2.626992355110479

Epoch: 5| Step: 9
Training loss: 1.0059218896494233
Validation loss: 2.564405717336477

Epoch: 5| Step: 10
Training loss: 0.8542637808572631
Validation loss: 2.5638750465334414

Epoch: 5| Step: 11
Training loss: 0.42377624545782716
Validation loss: 2.5787868266789817

Testing loss: 2.2220180376693897
