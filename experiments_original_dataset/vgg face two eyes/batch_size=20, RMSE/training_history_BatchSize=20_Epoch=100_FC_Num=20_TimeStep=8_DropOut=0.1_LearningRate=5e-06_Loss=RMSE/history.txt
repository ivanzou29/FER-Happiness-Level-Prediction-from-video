Epoch: 1| Step: 0
Training loss: 4.534507475060752
Validation loss: 3.667617824397953

Epoch: 5| Step: 1
Training loss: 2.9421841224817142
Validation loss: 3.6484595494825913

Epoch: 5| Step: 2
Training loss: 3.664682169165694
Validation loss: 3.6321344597398735

Epoch: 5| Step: 3
Training loss: 3.8385831018883176
Validation loss: 3.614202312574867

Epoch: 5| Step: 4
Training loss: 3.4058168468320544
Validation loss: 3.593410431672321

Epoch: 5| Step: 5
Training loss: 3.6286262264555162
Validation loss: 3.575118493959627

Epoch: 5| Step: 6
Training loss: 4.29644751069511
Validation loss: 3.554000447147823

Epoch: 5| Step: 7
Training loss: 3.370761894786218
Validation loss: 3.5331211084083147

Epoch: 5| Step: 8
Training loss: 4.246697882073945
Validation loss: 3.5120985810858554

Epoch: 5| Step: 9
Training loss: 3.4988002083062764
Validation loss: 3.4894391310014905

Epoch: 5| Step: 10
Training loss: 3.0170621461672695
Validation loss: 3.4691893210592677

Epoch: 5| Step: 11
Training loss: 3.3050179102148327
Validation loss: 3.4471090625227085

Epoch: 2| Step: 0
Training loss: 3.7027654674491055
Validation loss: 3.426671520330527

Epoch: 5| Step: 1
Training loss: 3.7639051126566034
Validation loss: 3.4022913219618434

Epoch: 5| Step: 2
Training loss: 3.6301300317683367
Validation loss: 3.3775461447307364

Epoch: 5| Step: 3
Training loss: 3.4822248316467457
Validation loss: 3.3557915434229733

Epoch: 5| Step: 4
Training loss: 2.807918122459072
Validation loss: 3.3283912241782865

Epoch: 5| Step: 5
Training loss: 3.7931427370625626
Validation loss: 3.3097083486085785

Epoch: 5| Step: 6
Training loss: 2.8881675377961358
Validation loss: 3.2815419142921125

Epoch: 5| Step: 7
Training loss: 3.008917588185199
Validation loss: 3.255874850383763

Epoch: 5| Step: 8
Training loss: 3.9056652394341755
Validation loss: 3.227918443106074

Epoch: 5| Step: 9
Training loss: 3.3037370618147563
Validation loss: 3.2003419617635673

Epoch: 5| Step: 10
Training loss: 3.0471970608032826
Validation loss: 3.170657370484982

Epoch: 5| Step: 11
Training loss: 4.088707533790476
Validation loss: 3.1397556632693235

Epoch: 3| Step: 0
Training loss: 2.868038207199999
Validation loss: 3.110436125862861

Epoch: 5| Step: 1
Training loss: 3.2046293866241746
Validation loss: 3.074742228602519

Epoch: 5| Step: 2
Training loss: 3.4125685576654137
Validation loss: 3.043565246854861

Epoch: 5| Step: 3
Training loss: 3.066532671806759
Validation loss: 3.011044784321169

Epoch: 5| Step: 4
Training loss: 2.6841066805904954
Validation loss: 2.9772298036497253

Epoch: 5| Step: 5
Training loss: 2.8887271733952327
Validation loss: 2.945070390000405

Epoch: 5| Step: 6
Training loss: 3.1164051116153284
Validation loss: 2.9125761616999024

Epoch: 5| Step: 7
Training loss: 3.4021679978465627
Validation loss: 2.87591174775313

Epoch: 5| Step: 8
Training loss: 3.170858887524755
Validation loss: 2.8426493027148103

Epoch: 5| Step: 9
Training loss: 2.7043867749494948
Validation loss: 2.8012803864153764

Epoch: 5| Step: 10
Training loss: 3.1083516492806824
Validation loss: 2.7705051913790784

Epoch: 5| Step: 11
Training loss: 1.5527379065899303
Validation loss: 2.7283471978681377

Epoch: 4| Step: 0
Training loss: 2.744217254546171
Validation loss: 2.697732077117566

Epoch: 5| Step: 1
Training loss: 2.685872583231698
Validation loss: 2.6617887569290746

Epoch: 5| Step: 2
Training loss: 2.668760213006018
Validation loss: 2.630422977464311

Epoch: 5| Step: 3
Training loss: 2.759950149749369
Validation loss: 2.5947986803811216

Epoch: 5| Step: 4
Training loss: 2.8868446167798267
Validation loss: 2.5687639041162353

Epoch: 5| Step: 5
Training loss: 2.9118583463547534
Validation loss: 2.5548323299561853

Epoch: 5| Step: 6
Training loss: 2.2859058683009916
Validation loss: 2.5236931859285248

Epoch: 5| Step: 7
Training loss: 2.5236998619476485
Validation loss: 2.5072885443289357

Epoch: 5| Step: 8
Training loss: 2.626880335597034
Validation loss: 2.491732859822035

Epoch: 5| Step: 9
Training loss: 2.5263860618496734
Validation loss: 2.483917538093174

Epoch: 5| Step: 10
Training loss: 2.4012250078639266
Validation loss: 2.478294957936377

Epoch: 5| Step: 11
Training loss: 2.021099138639777
Validation loss: 2.4719012706339587

Epoch: 5| Step: 0
Training loss: 2.3081506604055053
Validation loss: 2.478310432487542

Epoch: 5| Step: 1
Training loss: 2.4292665957207573
Validation loss: 2.4794905808894194

Epoch: 5| Step: 2
Training loss: 2.10678902811902
Validation loss: 2.4989458205967376

Epoch: 5| Step: 3
Training loss: 2.983603332775836
Validation loss: 2.504025268503237

Epoch: 5| Step: 4
Training loss: 3.016574848386489
Validation loss: 2.513446484558016

Epoch: 5| Step: 5
Training loss: 1.9175961631723786
Validation loss: 2.5242227133780113

Epoch: 5| Step: 6
Training loss: 2.6396484375
Validation loss: 2.5268819977723727

Epoch: 5| Step: 7
Training loss: 2.9559341874907106
Validation loss: 2.525926041988279

Epoch: 5| Step: 8
Training loss: 2.4843246166950372
Validation loss: 2.5178185627557244

Epoch: 5| Step: 9
Training loss: 2.4545864927027305
Validation loss: 2.5085391559519095

Epoch: 5| Step: 10
Training loss: 2.6297567049055792
Validation loss: 2.504590992725189

Epoch: 5| Step: 11
Training loss: 2.8589775768146564
Validation loss: 2.497327325628444

Epoch: 6| Step: 0
Training loss: 2.0030475286062157
Validation loss: 2.4839629785294375

Epoch: 5| Step: 1
Training loss: 2.3569928199940318
Validation loss: 2.486663276356422

Epoch: 5| Step: 2
Training loss: 2.5206977450474315
Validation loss: 2.4921928094789396

Epoch: 5| Step: 3
Training loss: 2.5765894160301963
Validation loss: 2.4716749207566107

Epoch: 5| Step: 4
Training loss: 2.6997130806672818
Validation loss: 2.4743465413468173

Epoch: 5| Step: 5
Training loss: 2.352136788944782
Validation loss: 2.458689370208595

Epoch: 5| Step: 6
Training loss: 3.009981240502384
Validation loss: 2.4705448748302383

Epoch: 5| Step: 7
Training loss: 2.245918598809411
Validation loss: 2.464583224449467

Epoch: 5| Step: 8
Training loss: 2.6437985463115385
Validation loss: 2.4537111501327487

Epoch: 5| Step: 9
Training loss: 2.6630890709495225
Validation loss: 2.4580869403035877

Epoch: 5| Step: 10
Training loss: 2.2933908623125863
Validation loss: 2.4558500837948487

Epoch: 5| Step: 11
Training loss: 3.6978821802098265
Validation loss: 2.4576191282260886

Epoch: 7| Step: 0
Training loss: 3.0341150960195225
Validation loss: 2.4531318397183646

Epoch: 5| Step: 1
Training loss: 2.5591809246925195
Validation loss: 2.458081462182595

Epoch: 5| Step: 2
Training loss: 2.777548566474317
Validation loss: 2.4634371057194144

Epoch: 5| Step: 3
Training loss: 2.118655438408808
Validation loss: 2.4480903861447674

Epoch: 5| Step: 4
Training loss: 2.6128634587850454
Validation loss: 2.4583570686638487

Epoch: 5| Step: 5
Training loss: 2.5568189216381505
Validation loss: 2.453045574449377

Epoch: 5| Step: 6
Training loss: 2.52830579038172
Validation loss: 2.4507194273713493

Epoch: 5| Step: 7
Training loss: 2.667776969395129
Validation loss: 2.4573495797133638

Epoch: 5| Step: 8
Training loss: 2.188475690958104
Validation loss: 2.457777547779766

Epoch: 5| Step: 9
Training loss: 2.6461066958367256
Validation loss: 2.449728108179102

Epoch: 5| Step: 10
Training loss: 1.8631886073339499
Validation loss: 2.4452426603863824

Epoch: 5| Step: 11
Training loss: 2.480830897529832
Validation loss: 2.4473162110771542

Epoch: 8| Step: 0
Training loss: 2.2563938845249476
Validation loss: 2.448837303298169

Epoch: 5| Step: 1
Training loss: 2.150699603675
Validation loss: 2.445501854403374

Epoch: 5| Step: 2
Training loss: 3.0146797556682268
Validation loss: 2.4438939067619194

Epoch: 5| Step: 3
Training loss: 2.0286127429723266
Validation loss: 2.441534463186105

Epoch: 5| Step: 4
Training loss: 2.5748606042259974
Validation loss: 2.4431088667537186

Epoch: 5| Step: 5
Training loss: 2.237794939773161
Validation loss: 2.4437717706697564

Epoch: 5| Step: 6
Training loss: 2.5399685695535816
Validation loss: 2.4404758765999106

Epoch: 5| Step: 7
Training loss: 2.3157637993402345
Validation loss: 2.4420878117660263

Epoch: 5| Step: 8
Training loss: 2.565659691672475
Validation loss: 2.4391198563088894

Epoch: 5| Step: 9
Training loss: 2.947003352261369
Validation loss: 2.4383301055032462

Epoch: 5| Step: 10
Training loss: 2.4341458449038536
Validation loss: 2.4432346059044314

Epoch: 5| Step: 11
Training loss: 3.755934787415689
Validation loss: 2.438529710008416

Epoch: 9| Step: 0
Training loss: 1.8252305812704015
Validation loss: 2.442942619610956

Epoch: 5| Step: 1
Training loss: 2.3521279703865408
Validation loss: 2.4321140425939545

Epoch: 5| Step: 2
Training loss: 2.960104309254571
Validation loss: 2.4341214395213404

Epoch: 5| Step: 3
Training loss: 2.926729626626458
Validation loss: 2.435101878106147

Epoch: 5| Step: 4
Training loss: 2.1436665777318016
Validation loss: 2.4387605333972484

Epoch: 5| Step: 5
Training loss: 2.524468934516064
Validation loss: 2.437759573067336

Epoch: 5| Step: 6
Training loss: 2.8234025506546554
Validation loss: 2.4291075600052157

Epoch: 5| Step: 7
Training loss: 2.24560817611342
Validation loss: 2.4348074558695183

Epoch: 5| Step: 8
Training loss: 2.279436409543773
Validation loss: 2.4343732439654264

Epoch: 5| Step: 9
Training loss: 2.481635160363592
Validation loss: 2.431346655953443

Epoch: 5| Step: 10
Training loss: 2.7297888087932356
Validation loss: 2.4340869614000558

Epoch: 5| Step: 11
Training loss: 1.8122099282550468
Validation loss: 2.433368156022814

Epoch: 10| Step: 0
Training loss: 2.255575900411487
Validation loss: 2.432945601934819

Epoch: 5| Step: 1
Training loss: 2.2584413490880184
Validation loss: 2.433948980768018

Epoch: 5| Step: 2
Training loss: 2.613125601154615
Validation loss: 2.433355839235487

Epoch: 5| Step: 3
Training loss: 2.0917341862250933
Validation loss: 2.432566928739953

Epoch: 5| Step: 4
Training loss: 2.6741636412656824
Validation loss: 2.4342370445915136

Epoch: 5| Step: 5
Training loss: 2.4585652861570275
Validation loss: 2.4329527923698935

Epoch: 5| Step: 6
Training loss: 2.537219602379633
Validation loss: 2.4306472771610252

Epoch: 5| Step: 7
Training loss: 3.0052650662272926
Validation loss: 2.4312658672256275

Epoch: 5| Step: 8
Training loss: 2.6617200291045227
Validation loss: 2.426939453859299

Epoch: 5| Step: 9
Training loss: 2.578873126982408
Validation loss: 2.4242677251532276

Epoch: 5| Step: 10
Training loss: 2.1056383733418116
Validation loss: 2.4274818737166504

Epoch: 5| Step: 11
Training loss: 2.4824843019909206
Validation loss: 2.4245177299035845

Epoch: 11| Step: 0
Training loss: 2.235108368569741
Validation loss: 2.4236592560048296

Epoch: 5| Step: 1
Training loss: 2.4480753637506307
Validation loss: 2.436027271459087

Epoch: 5| Step: 2
Training loss: 2.362275014992954
Validation loss: 2.4265793057343035

Epoch: 5| Step: 3
Training loss: 2.6721279626860137
Validation loss: 2.4347759618508618

Epoch: 5| Step: 4
Training loss: 2.0656162186751934
Validation loss: 2.436130701494002

Epoch: 5| Step: 5
Training loss: 2.971803560411146
Validation loss: 2.435647348035964

Epoch: 5| Step: 6
Training loss: 2.3887234773465944
Validation loss: 2.433701871508072

Epoch: 5| Step: 7
Training loss: 2.3297557879647335
Validation loss: 2.426041511829372

Epoch: 5| Step: 8
Training loss: 2.1152633425489364
Validation loss: 2.4292159813792984

Epoch: 5| Step: 9
Training loss: 2.648978839114364
Validation loss: 2.4306349445426334

Epoch: 5| Step: 10
Training loss: 2.8270313825076485
Validation loss: 2.4366898616812236

Epoch: 5| Step: 11
Training loss: 3.168296561819568
Validation loss: 2.422155733142597

Epoch: 12| Step: 0
Training loss: 2.5572159413445132
Validation loss: 2.430164539734502

Epoch: 5| Step: 1
Training loss: 2.4023329323625853
Validation loss: 2.4249645010981506

Epoch: 5| Step: 2
Training loss: 2.0025888615202354
Validation loss: 2.42049721115

Epoch: 5| Step: 3
Training loss: 2.462544912325651
Validation loss: 2.4226705618588036

Epoch: 5| Step: 4
Training loss: 2.841584942967242
Validation loss: 2.4226677632809177

Epoch: 5| Step: 5
Training loss: 2.851265000801813
Validation loss: 2.427962382732716

Epoch: 5| Step: 6
Training loss: 2.619146632927953
Validation loss: 2.421270532955875

Epoch: 5| Step: 7
Training loss: 2.267822567876803
Validation loss: 2.421422448484088

Epoch: 5| Step: 8
Training loss: 2.180752839102007
Validation loss: 2.425905487597561

Epoch: 5| Step: 9
Training loss: 2.135180601392192
Validation loss: 2.4219547914876403

Epoch: 5| Step: 10
Training loss: 2.5612316248966724
Validation loss: 2.4137446411313017

Epoch: 5| Step: 11
Training loss: 3.361222721555197
Validation loss: 2.412142307813438

Epoch: 13| Step: 0
Training loss: 2.9333456978392825
Validation loss: 2.4191460195701238

Epoch: 5| Step: 1
Training loss: 2.3452135729781327
Validation loss: 2.4157494676180065

Epoch: 5| Step: 2
Training loss: 2.7110555221855117
Validation loss: 2.4118646906869388

Epoch: 5| Step: 3
Training loss: 2.565569551080119
Validation loss: 2.4130265009749214

Epoch: 5| Step: 4
Training loss: 2.2917803880622887
Validation loss: 2.4151452649565472

Epoch: 5| Step: 5
Training loss: 2.6007392199240718
Validation loss: 2.423223800796449

Epoch: 5| Step: 6
Training loss: 2.007362404332277
Validation loss: 2.4121662992898285

Epoch: 5| Step: 7
Training loss: 1.8741346269613572
Validation loss: 2.416815051642476

Epoch: 5| Step: 8
Training loss: 2.291401680162401
Validation loss: 2.409918474022743

Epoch: 5| Step: 9
Training loss: 2.840090902243767
Validation loss: 2.4191916952066004

Epoch: 5| Step: 10
Training loss: 2.7139159449054353
Validation loss: 2.417314945338888

Epoch: 5| Step: 11
Training loss: 1.8521811180204315
Validation loss: 2.406803170731051

Epoch: 14| Step: 0
Training loss: 2.6298621425106754
Validation loss: 2.4163617518599567

Epoch: 5| Step: 1
Training loss: 2.6264914862151456
Validation loss: 2.415416934259187

Epoch: 5| Step: 2
Training loss: 2.5196193472667354
Validation loss: 2.4056069600647993

Epoch: 5| Step: 3
Training loss: 2.1407975176048426
Validation loss: 2.411838564683618

Epoch: 5| Step: 4
Training loss: 2.0186873246139148
Validation loss: 2.419746172922469

Epoch: 5| Step: 5
Training loss: 2.34420954967357
Validation loss: 2.4244672725124867

Epoch: 5| Step: 6
Training loss: 2.824906683536806
Validation loss: 2.4191364186658593

Epoch: 5| Step: 7
Training loss: 2.923396566034072
Validation loss: 2.426065892029936

Epoch: 5| Step: 8
Training loss: 2.0570160757650413
Validation loss: 2.4343103707923937

Epoch: 5| Step: 9
Training loss: 2.7572278491797664
Validation loss: 2.4295384258072947

Epoch: 5| Step: 10
Training loss: 1.9831186357330526
Validation loss: 2.4239363399000187

Epoch: 5| Step: 11
Training loss: 3.546384130448336
Validation loss: 2.4218743970316474

Epoch: 15| Step: 0
Training loss: 2.5787801199192746
Validation loss: 2.4217527789378277

Epoch: 5| Step: 1
Training loss: 2.8638597348991723
Validation loss: 2.406832092029484

Epoch: 5| Step: 2
Training loss: 2.3380291100248796
Validation loss: 2.4162694807430003

Epoch: 5| Step: 3
Training loss: 2.4632195442908587
Validation loss: 2.411568341859632

Epoch: 5| Step: 4
Training loss: 2.527974776625044
Validation loss: 2.4093433247754703

Epoch: 5| Step: 5
Training loss: 2.229179156497179
Validation loss: 2.4071951141263415

Epoch: 5| Step: 6
Training loss: 2.7862195824750744
Validation loss: 2.4055859136507345

Epoch: 5| Step: 7
Training loss: 2.2688601842769245
Validation loss: 2.404298635152115

Epoch: 5| Step: 8
Training loss: 2.123728989109333
Validation loss: 2.408432482677114

Epoch: 5| Step: 9
Training loss: 2.220180641248128
Validation loss: 2.40786143011224

Epoch: 5| Step: 10
Training loss: 2.6590459133630167
Validation loss: 2.4030173889822932

Epoch: 5| Step: 11
Training loss: 2.6593372131603696
Validation loss: 2.407380606343855

Epoch: 16| Step: 0
Training loss: 2.2822278161100535
Validation loss: 2.4060789807138825

Epoch: 5| Step: 1
Training loss: 2.641122443842144
Validation loss: 2.406728824847912

Epoch: 5| Step: 2
Training loss: 2.3578740075887943
Validation loss: 2.410396570129056

Epoch: 5| Step: 3
Training loss: 2.5740655555350362
Validation loss: 2.411166634160833

Epoch: 5| Step: 4
Training loss: 2.0412536774302596
Validation loss: 2.3997081865618806

Epoch: 5| Step: 5
Training loss: 2.4446695963406215
Validation loss: 2.4025207537026914

Epoch: 5| Step: 6
Training loss: 3.02017880068352
Validation loss: 2.3971837481106046

Epoch: 5| Step: 7
Training loss: 2.389168089684483
Validation loss: 2.4048125816369192

Epoch: 5| Step: 8
Training loss: 2.3153688317406043
Validation loss: 2.404701052258404

Epoch: 5| Step: 9
Training loss: 2.3856007756199333
Validation loss: 2.4010445159652476

Epoch: 5| Step: 10
Training loss: 2.4356103076643403
Validation loss: 2.4066145525804132

Epoch: 5| Step: 11
Training loss: 2.84779975016735
Validation loss: 2.4012073899598625

Epoch: 17| Step: 0
Training loss: 2.6786742672025183
Validation loss: 2.409432016432788

Epoch: 5| Step: 1
Training loss: 1.730771625957299
Validation loss: 2.425923280351176

Epoch: 5| Step: 2
Training loss: 3.164960568922152
Validation loss: 2.4330042027490593

Epoch: 5| Step: 3
Training loss: 2.1691115108262475
Validation loss: 2.431816609460311

Epoch: 5| Step: 4
Training loss: 2.4864651506637063
Validation loss: 2.4446252379123665

Epoch: 5| Step: 5
Training loss: 2.0786396049139206
Validation loss: 2.4496181513226043

Epoch: 5| Step: 6
Training loss: 2.378484478723236
Validation loss: 2.4553582581191398

Epoch: 5| Step: 7
Training loss: 3.024748919447001
Validation loss: 2.4550621904186336

Epoch: 5| Step: 8
Training loss: 2.606038959109492
Validation loss: 2.448465165446712

Epoch: 5| Step: 9
Training loss: 2.296073306558254
Validation loss: 2.434924845939137

Epoch: 5| Step: 10
Training loss: 2.328305435869133
Validation loss: 2.442419288522521

Epoch: 5| Step: 11
Training loss: 2.685596235341833
Validation loss: 2.422248889406157

Epoch: 18| Step: 0
Training loss: 2.513832259081846
Validation loss: 2.416150816309048

Epoch: 5| Step: 1
Training loss: 2.918260919735296
Validation loss: 2.4300878998278206

Epoch: 5| Step: 2
Training loss: 2.6623355940084847
Validation loss: 2.427782880196737

Epoch: 5| Step: 3
Training loss: 1.7957751681414769
Validation loss: 2.4264137029213

Epoch: 5| Step: 4
Training loss: 2.5873999018818683
Validation loss: 2.41926682221758

Epoch: 5| Step: 5
Training loss: 3.088727322552688
Validation loss: 2.4147774173738625

Epoch: 5| Step: 6
Training loss: 2.1767406163449854
Validation loss: 2.4166611323348066

Epoch: 5| Step: 7
Training loss: 2.351439007022627
Validation loss: 2.4126077319914474

Epoch: 5| Step: 8
Training loss: 2.4033334073698516
Validation loss: 2.4059010248490864

Epoch: 5| Step: 9
Training loss: 2.0666893691179844
Validation loss: 2.4071106259255464

Epoch: 5| Step: 10
Training loss: 2.3524264652706184
Validation loss: 2.4136784051470443

Epoch: 5| Step: 11
Training loss: 1.7162866452632866
Validation loss: 2.409079724997988

Epoch: 19| Step: 0
Training loss: 2.8033290963097426
Validation loss: 2.4126559236767267

Epoch: 5| Step: 1
Training loss: 2.662167409262875
Validation loss: 2.4025748123657

Epoch: 5| Step: 2
Training loss: 2.2022216243381676
Validation loss: 2.408804012841833

Epoch: 5| Step: 3
Training loss: 2.4275254814154152
Validation loss: 2.4160814905915378

Epoch: 5| Step: 4
Training loss: 2.4351707480093565
Validation loss: 2.4180085235923494

Epoch: 5| Step: 5
Training loss: 2.696350959086719
Validation loss: 2.4106580519971517

Epoch: 5| Step: 6
Training loss: 2.098921239886418
Validation loss: 2.4094805148877083

Epoch: 5| Step: 7
Training loss: 2.0798610233681187
Validation loss: 2.4092702798313455

Epoch: 5| Step: 8
Training loss: 2.1219069465850335
Validation loss: 2.419558173705129

Epoch: 5| Step: 9
Training loss: 2.6560900471716096
Validation loss: 2.4127620148726368

Epoch: 5| Step: 10
Training loss: 2.623697866182666
Validation loss: 2.412323824555627

Epoch: 5| Step: 11
Training loss: 2.68021549995335
Validation loss: 2.4037905091912313

Epoch: 20| Step: 0
Training loss: 2.6065192213902915
Validation loss: 2.409167082111486

Epoch: 5| Step: 1
Training loss: 2.415540224391446
Validation loss: 2.4165577631013173

Epoch: 5| Step: 2
Training loss: 2.2028804129247375
Validation loss: 2.4125939215856564

Epoch: 5| Step: 3
Training loss: 2.839477347515853
Validation loss: 2.4046566381822614

Epoch: 5| Step: 4
Training loss: 2.37810895114852
Validation loss: 2.410232151182103

Epoch: 5| Step: 5
Training loss: 2.2334321707115787
Validation loss: 2.3982890867026994

Epoch: 5| Step: 6
Training loss: 2.2263785302972305
Validation loss: 2.4134284733118547

Epoch: 5| Step: 7
Training loss: 2.738622015674812
Validation loss: 2.4067536896160604

Epoch: 5| Step: 8
Training loss: 2.390570845645051
Validation loss: 2.410990252837566

Epoch: 5| Step: 9
Training loss: 2.204179011155903
Validation loss: 2.4011844536008287

Epoch: 5| Step: 10
Training loss: 2.6399454901587496
Validation loss: 2.40461932906334

Epoch: 5| Step: 11
Training loss: 2.5134489706067713
Validation loss: 2.3969724697502284

Epoch: 21| Step: 0
Training loss: 2.530977493499561
Validation loss: 2.4027298779818405

Epoch: 5| Step: 1
Training loss: 2.61773912680128
Validation loss: 2.4030199169305075

Epoch: 5| Step: 2
Training loss: 2.1101671779989384
Validation loss: 2.401473216885503

Epoch: 5| Step: 3
Training loss: 2.072894519578972
Validation loss: 2.4032551719024955

Epoch: 5| Step: 4
Training loss: 3.079014373716012
Validation loss: 2.4084747359289325

Epoch: 5| Step: 5
Training loss: 1.65513594965053
Validation loss: 2.414799821467043

Epoch: 5| Step: 6
Training loss: 2.5207946921505457
Validation loss: 2.41798640395187

Epoch: 5| Step: 7
Training loss: 2.6521093071092428
Validation loss: 2.4193914333433497

Epoch: 5| Step: 8
Training loss: 2.4650345862943177
Validation loss: 2.4192152656822947

Epoch: 5| Step: 9
Training loss: 2.566803365840551
Validation loss: 2.411240151066999

Epoch: 5| Step: 10
Training loss: 2.4690506184712953
Validation loss: 2.420215994197856

Epoch: 5| Step: 11
Training loss: 2.352547879517257
Validation loss: 2.4153100856723366

Epoch: 22| Step: 0
Training loss: 2.147638900758919
Validation loss: 2.4144398477680213

Epoch: 5| Step: 1
Training loss: 2.6454877152072083
Validation loss: 2.411990219653219

Epoch: 5| Step: 2
Training loss: 2.584207007634428
Validation loss: 2.394858810315394

Epoch: 5| Step: 3
Training loss: 2.743603810649783
Validation loss: 2.4046898651607154

Epoch: 5| Step: 4
Training loss: 2.2470965195329113
Validation loss: 2.4054272058246036

Epoch: 5| Step: 5
Training loss: 2.383616327499544
Validation loss: 2.400380448313848

Epoch: 5| Step: 6
Training loss: 2.4898753187837297
Validation loss: 2.39140771173937

Epoch: 5| Step: 7
Training loss: 2.5701290169478503
Validation loss: 2.3875180044044564

Epoch: 5| Step: 8
Training loss: 2.289550520916625
Validation loss: 2.3794051275207186

Epoch: 5| Step: 9
Training loss: 2.2033746456172576
Validation loss: 2.3967053167235806

Epoch: 5| Step: 10
Training loss: 2.1263064687901294
Validation loss: 2.3944604561376828

Epoch: 5| Step: 11
Training loss: 3.9137417172612645
Validation loss: 2.388903265886391

Epoch: 23| Step: 0
Training loss: 2.716319609240315
Validation loss: 2.3897706439519366

Epoch: 5| Step: 1
Training loss: 2.7453937967906876
Validation loss: 2.39729392408103

Epoch: 5| Step: 2
Training loss: 2.5744152775535785
Validation loss: 2.386548689190831

Epoch: 5| Step: 3
Training loss: 2.210753847723855
Validation loss: 2.393263845984598

Epoch: 5| Step: 4
Training loss: 2.822822869538453
Validation loss: 2.391058624849816

Epoch: 5| Step: 5
Training loss: 2.3712367308491213
Validation loss: 2.3984466618829914

Epoch: 5| Step: 6
Training loss: 2.2596797415750896
Validation loss: 2.3992472347256704

Epoch: 5| Step: 7
Training loss: 2.750059387259368
Validation loss: 2.4018458587026155

Epoch: 5| Step: 8
Training loss: 2.300706016981463
Validation loss: 2.3960770828534725

Epoch: 5| Step: 9
Training loss: 1.8100242807013711
Validation loss: 2.403315443240424

Epoch: 5| Step: 10
Training loss: 2.176933928356618
Validation loss: 2.402158706278752

Epoch: 5| Step: 11
Training loss: 1.5917134456184776
Validation loss: 2.402668225465134

Epoch: 24| Step: 0
Training loss: 2.3693247799794994
Validation loss: 2.4070224182765894

Epoch: 5| Step: 1
Training loss: 2.5177439419731567
Validation loss: 2.4040840895590083

Epoch: 5| Step: 2
Training loss: 2.9445158591896785
Validation loss: 2.4121510902329204

Epoch: 5| Step: 3
Training loss: 2.8830179280846013
Validation loss: 2.417353455744694

Epoch: 5| Step: 4
Training loss: 2.4672296405693976
Validation loss: 2.410044871043787

Epoch: 5| Step: 5
Training loss: 2.247199434883424
Validation loss: 2.415902791206298

Epoch: 5| Step: 6
Training loss: 1.9784444662479717
Validation loss: 2.407050585810972

Epoch: 5| Step: 7
Training loss: 2.4647541785552503
Validation loss: 2.411780553482453

Epoch: 5| Step: 8
Training loss: 2.511476591073663
Validation loss: 2.4030771805495235

Epoch: 5| Step: 9
Training loss: 2.018659923894112
Validation loss: 2.4081056445693942

Epoch: 5| Step: 10
Training loss: 2.3532964960552563
Validation loss: 2.401486336305506

Epoch: 5| Step: 11
Training loss: 1.83794938904627
Validation loss: 2.39827376893016

Epoch: 25| Step: 0
Training loss: 2.3590685917033714
Validation loss: 2.4092328133129213

Epoch: 5| Step: 1
Training loss: 3.188659158008605
Validation loss: 2.4083824885003726

Epoch: 5| Step: 2
Training loss: 2.611946164065609
Validation loss: 2.3968297268580163

Epoch: 5| Step: 3
Training loss: 1.988605105662225
Validation loss: 2.4142626666030083

Epoch: 5| Step: 4
Training loss: 2.4866525059348796
Validation loss: 2.4111929240046135

Epoch: 5| Step: 5
Training loss: 2.2519889094213448
Validation loss: 2.4161864261187187

Epoch: 5| Step: 6
Training loss: 2.2923142182961813
Validation loss: 2.41552787427586

Epoch: 5| Step: 7
Training loss: 2.1373024654019566
Validation loss: 2.4175947780367384

Epoch: 5| Step: 8
Training loss: 2.3336674814290475
Validation loss: 2.4271822521751685

Epoch: 5| Step: 9
Training loss: 2.432305988756989
Validation loss: 2.4198332722360827

Epoch: 5| Step: 10
Training loss: 2.6608937679332625
Validation loss: 2.4162146224990657

Epoch: 5| Step: 11
Training loss: 2.005706038366866
Validation loss: 2.410745075826453

Epoch: 26| Step: 0
Training loss: 2.592942997045113
Validation loss: 2.4027033094823675

Epoch: 5| Step: 1
Training loss: 2.223942550376855
Validation loss: 2.4158082676201555

Epoch: 5| Step: 2
Training loss: 2.471470938932875
Validation loss: 2.4167265487245486

Epoch: 5| Step: 3
Training loss: 2.78459788927742
Validation loss: 2.411150252818753

Epoch: 5| Step: 4
Training loss: 2.8688333137731017
Validation loss: 2.391509276925651

Epoch: 5| Step: 5
Training loss: 1.6914806746039381
Validation loss: 2.396878123871957

Epoch: 5| Step: 6
Training loss: 2.473650257939124
Validation loss: 2.4015749272273363

Epoch: 5| Step: 7
Training loss: 2.0857671889596228
Validation loss: 2.3848924699437344

Epoch: 5| Step: 8
Training loss: 2.743125472539173
Validation loss: 2.3801811155492305

Epoch: 5| Step: 9
Training loss: 2.311806136500734
Validation loss: 2.3905644461083058

Epoch: 5| Step: 10
Training loss: 2.5540032359904057
Validation loss: 2.3878362716744945

Epoch: 5| Step: 11
Training loss: 1.9477465618202594
Validation loss: 2.3934300531720654

Epoch: 27| Step: 0
Training loss: 2.373051496587578
Validation loss: 2.3888417285199544

Epoch: 5| Step: 1
Training loss: 2.2933914860663926
Validation loss: 2.392024941364335

Epoch: 5| Step: 2
Training loss: 2.430145024340101
Validation loss: 2.398189163191392

Epoch: 5| Step: 3
Training loss: 1.9378245297252177
Validation loss: 2.4035725456684065

Epoch: 5| Step: 4
Training loss: 2.561692738728161
Validation loss: 2.4302581574888746

Epoch: 5| Step: 5
Training loss: 2.328361755212185
Validation loss: 2.4208713502793207

Epoch: 5| Step: 6
Training loss: 2.5398021383640446
Validation loss: 2.4311564912113877

Epoch: 5| Step: 7
Training loss: 2.6700397457064837
Validation loss: 2.4301864422464736

Epoch: 5| Step: 8
Training loss: 2.5382438396257743
Validation loss: 2.4385068436039616

Epoch: 5| Step: 9
Training loss: 2.7572220556572664
Validation loss: 2.435648932583701

Epoch: 5| Step: 10
Training loss: 2.408017487807789
Validation loss: 2.4362932502909453

Epoch: 5| Step: 11
Training loss: 2.393869131126777
Validation loss: 2.4335003258829215

Epoch: 28| Step: 0
Training loss: 1.983212588612441
Validation loss: 2.4220647101804933

Epoch: 5| Step: 1
Training loss: 2.100643822206287
Validation loss: 2.422156040743798

Epoch: 5| Step: 2
Training loss: 2.574226437269203
Validation loss: 2.4198038043143195

Epoch: 5| Step: 3
Training loss: 2.2052660339139294
Validation loss: 2.412026749610183

Epoch: 5| Step: 4
Training loss: 1.8830161083502819
Validation loss: 2.426533286071716

Epoch: 5| Step: 5
Training loss: 2.463572904511061
Validation loss: 2.4187028424810517

Epoch: 5| Step: 6
Training loss: 2.8359437212074496
Validation loss: 2.4184334082001366

Epoch: 5| Step: 7
Training loss: 2.602441129577432
Validation loss: 2.425979980829968

Epoch: 5| Step: 8
Training loss: 2.5724910327395487
Validation loss: 2.410666227870858

Epoch: 5| Step: 9
Training loss: 2.4040963579692223
Validation loss: 2.4042852625087394

Epoch: 5| Step: 10
Training loss: 2.837687979365826
Validation loss: 2.3958202334059675

Epoch: 5| Step: 11
Training loss: 2.083095486097365
Validation loss: 2.3899607764101978

Epoch: 29| Step: 0
Training loss: 2.5431580363199955
Validation loss: 2.3969159140611587

Epoch: 5| Step: 1
Training loss: 2.236987527306905
Validation loss: 2.3850258100260695

Epoch: 5| Step: 2
Training loss: 2.728657963834942
Validation loss: 2.3944115414341605

Epoch: 5| Step: 3
Training loss: 2.272632784179731
Validation loss: 2.3820986215137423

Epoch: 5| Step: 4
Training loss: 2.5526562002363784
Validation loss: 2.3888119760195696

Epoch: 5| Step: 5
Training loss: 2.2928672651093773
Validation loss: 2.391487340041429

Epoch: 5| Step: 6
Training loss: 2.360156605583803
Validation loss: 2.3877013494393156

Epoch: 5| Step: 7
Training loss: 2.0867994720601635
Validation loss: 2.392183369359512

Epoch: 5| Step: 8
Training loss: 2.48853697128992
Validation loss: 2.3921835313162347

Epoch: 5| Step: 9
Training loss: 2.880675477446195
Validation loss: 2.3891417570670606

Epoch: 5| Step: 10
Training loss: 2.1895004934313405
Validation loss: 2.383070772275869

Epoch: 5| Step: 11
Training loss: 2.7637715136356227
Validation loss: 2.39022002602626

Epoch: 30| Step: 0
Training loss: 2.266554122356025
Validation loss: 2.3830669079655045

Epoch: 5| Step: 1
Training loss: 2.6048193355301925
Validation loss: 2.3911157158414746

Epoch: 5| Step: 2
Training loss: 2.5685734300652583
Validation loss: 2.3881622752349085

Epoch: 5| Step: 3
Training loss: 2.796935864004743
Validation loss: 2.390217731831629

Epoch: 5| Step: 4
Training loss: 2.808465394972112
Validation loss: 2.3961011957998792

Epoch: 5| Step: 5
Training loss: 2.500597024201922
Validation loss: 2.3856375743297056

Epoch: 5| Step: 6
Training loss: 2.387552917852686
Validation loss: 2.397697291018293

Epoch: 5| Step: 7
Training loss: 2.081908832551138
Validation loss: 2.391271676172844

Epoch: 5| Step: 8
Training loss: 1.8500944989787325
Validation loss: 2.3952228093053383

Epoch: 5| Step: 9
Training loss: 2.8531991102907392
Validation loss: 2.3955852995204574

Epoch: 5| Step: 10
Training loss: 1.5757769499962635
Validation loss: 2.399608086170577

Epoch: 5| Step: 11
Training loss: 1.944142736763753
Validation loss: 2.397980146261069

Epoch: 31| Step: 0
Training loss: 2.681195782733499
Validation loss: 2.400138144358486

Epoch: 5| Step: 1
Training loss: 2.7319588585879346
Validation loss: 2.4048001351188533

Epoch: 5| Step: 2
Training loss: 2.5718807549487557
Validation loss: 2.4075217127324287

Epoch: 5| Step: 3
Training loss: 2.441666099452798
Validation loss: 2.416187741792662

Epoch: 5| Step: 4
Training loss: 1.645010545343148
Validation loss: 2.4083105570190226

Epoch: 5| Step: 5
Training loss: 2.826186469408801
Validation loss: 2.4077753706537988

Epoch: 5| Step: 6
Training loss: 2.431729455267531
Validation loss: 2.4007590424751597

Epoch: 5| Step: 7
Training loss: 2.693396199440068
Validation loss: 2.4018660589900924

Epoch: 5| Step: 8
Training loss: 2.1243716040076563
Validation loss: 2.4031586172185704

Epoch: 5| Step: 9
Training loss: 2.007847885829351
Validation loss: 2.400827883776335

Epoch: 5| Step: 10
Training loss: 2.272615684023968
Validation loss: 2.3941074595802254

Epoch: 5| Step: 11
Training loss: 1.469607731777321
Validation loss: 2.4029820656402845

Epoch: 32| Step: 0
Training loss: 2.444665987880014
Validation loss: 2.3936111856487883

Epoch: 5| Step: 1
Training loss: 2.883734000119856
Validation loss: 2.3940244037661227

Epoch: 5| Step: 2
Training loss: 2.475178714041245
Validation loss: 2.3913021583006815

Epoch: 5| Step: 3
Training loss: 2.2046429970924786
Validation loss: 2.39650293750823

Epoch: 5| Step: 4
Training loss: 2.6836700650709577
Validation loss: 2.403000999628008

Epoch: 5| Step: 5
Training loss: 1.7942005987128726
Validation loss: 2.3932800612712657

Epoch: 5| Step: 6
Training loss: 2.4277822991548983
Validation loss: 2.3898706908306298

Epoch: 5| Step: 7
Training loss: 2.4994160923938775
Validation loss: 2.3906666891248634

Epoch: 5| Step: 8
Training loss: 2.314869877760812
Validation loss: 2.3870524596125815

Epoch: 5| Step: 9
Training loss: 2.534873064914832
Validation loss: 2.394038902225836

Epoch: 5| Step: 10
Training loss: 2.1919402697493107
Validation loss: 2.3895989545285494

Epoch: 5| Step: 11
Training loss: 1.9399500706726658
Validation loss: 2.38119068922936

Epoch: 33| Step: 0
Training loss: 2.706284104764443
Validation loss: 2.3963108243437854

Epoch: 5| Step: 1
Training loss: 2.365042744062757
Validation loss: 2.3974381766239135

Epoch: 5| Step: 2
Training loss: 1.8187868986286686
Validation loss: 2.3894427997889247

Epoch: 5| Step: 3
Training loss: 2.0870004296003044
Validation loss: 2.393132679308352

Epoch: 5| Step: 4
Training loss: 2.3634650545129303
Validation loss: 2.38510363550232

Epoch: 5| Step: 5
Training loss: 2.6598103616274145
Validation loss: 2.396559034540597

Epoch: 5| Step: 6
Training loss: 2.201436796044797
Validation loss: 2.3982146798509443

Epoch: 5| Step: 7
Training loss: 1.6753573648500415
Validation loss: 2.393694596110073

Epoch: 5| Step: 8
Training loss: 2.4656269262037984
Validation loss: 2.4018208376564463

Epoch: 5| Step: 9
Training loss: 2.8367200880328536
Validation loss: 2.3920935626681423

Epoch: 5| Step: 10
Training loss: 3.014729579356249
Validation loss: 2.4045758017148424

Epoch: 5| Step: 11
Training loss: 2.054222373387597
Validation loss: 2.397965307071059

Epoch: 34| Step: 0
Training loss: 2.8165107104522584
Validation loss: 2.3917893501764365

Epoch: 5| Step: 1
Training loss: 2.4136916187403057
Validation loss: 2.3896274355272182

Epoch: 5| Step: 2
Training loss: 2.748525310803005
Validation loss: 2.392423343971704

Epoch: 5| Step: 3
Training loss: 2.166169830969581
Validation loss: 2.392480674367971

Epoch: 5| Step: 4
Training loss: 2.5587401370038734
Validation loss: 2.3872019501833135

Epoch: 5| Step: 5
Training loss: 2.7218479615017084
Validation loss: 2.382803353047142

Epoch: 5| Step: 6
Training loss: 1.947327026501065
Validation loss: 2.3839401703557974

Epoch: 5| Step: 7
Training loss: 2.2629798970326225
Validation loss: 2.3801586485392603

Epoch: 5| Step: 8
Training loss: 2.153852595068135
Validation loss: 2.374316248848428

Epoch: 5| Step: 9
Training loss: 2.5284402582353676
Validation loss: 2.3828941706434708

Epoch: 5| Step: 10
Training loss: 2.052335952726552
Validation loss: 2.3722932432558106

Epoch: 5| Step: 11
Training loss: 2.3420431406883733
Validation loss: 2.385193545027735

Epoch: 35| Step: 0
Training loss: 2.328038054001198
Validation loss: 2.3857020841755037

Epoch: 5| Step: 1
Training loss: 2.5431942231850955
Validation loss: 2.383558029528973

Epoch: 5| Step: 2
Training loss: 2.295703199775075
Validation loss: 2.3892852606997974

Epoch: 5| Step: 3
Training loss: 2.2961611514275724
Validation loss: 2.390146789425658

Epoch: 5| Step: 4
Training loss: 2.25574543983111
Validation loss: 2.406875756051549

Epoch: 5| Step: 5
Training loss: 2.2141454494016326
Validation loss: 2.4153572322325734

Epoch: 5| Step: 6
Training loss: 2.3305160226097192
Validation loss: 2.4134949939897936

Epoch: 5| Step: 7
Training loss: 2.569874456582503
Validation loss: 2.4100890642278725

Epoch: 5| Step: 8
Training loss: 2.7776836718407205
Validation loss: 2.423628824233648

Epoch: 5| Step: 9
Training loss: 2.3408989413681938
Validation loss: 2.4308932237098793

Epoch: 5| Step: 10
Training loss: 2.532616046532528
Validation loss: 2.439459245611473

Epoch: 5| Step: 11
Training loss: 1.6870416795910432
Validation loss: 2.4193724921267785

Epoch: 36| Step: 0
Training loss: 2.4185044984647512
Validation loss: 2.4047375049807775

Epoch: 5| Step: 1
Training loss: 2.0130382173551675
Validation loss: 2.405231507989438

Epoch: 5| Step: 2
Training loss: 1.7487359249920116
Validation loss: 2.41657284576439

Epoch: 5| Step: 3
Training loss: 2.941070010558544
Validation loss: 2.410332737689375

Epoch: 5| Step: 4
Training loss: 2.446865088587695
Validation loss: 2.401289351314798

Epoch: 5| Step: 5
Training loss: 2.251105354910936
Validation loss: 2.399128925012935

Epoch: 5| Step: 6
Training loss: 2.510232773584092
Validation loss: 2.398946320844206

Epoch: 5| Step: 7
Training loss: 2.3663233825944383
Validation loss: 2.3930267183325595

Epoch: 5| Step: 8
Training loss: 2.598420040877107
Validation loss: 2.391699402005821

Epoch: 5| Step: 9
Training loss: 2.433512629692328
Validation loss: 2.394960200112453

Epoch: 5| Step: 10
Training loss: 2.562318097613119
Validation loss: 2.3927186138401098

Epoch: 5| Step: 11
Training loss: 1.6478487382561433
Validation loss: 2.38622813741488

Epoch: 37| Step: 0
Training loss: 2.456041582501071
Validation loss: 2.380255147082665

Epoch: 5| Step: 1
Training loss: 2.104441319534594
Validation loss: 2.3805605852394676

Epoch: 5| Step: 2
Training loss: 2.0377368344698428
Validation loss: 2.3820224223396105

Epoch: 5| Step: 3
Training loss: 2.4926397696498857
Validation loss: 2.389312458621775

Epoch: 5| Step: 4
Training loss: 2.1730346876835016
Validation loss: 2.3855268017082722

Epoch: 5| Step: 5
Training loss: 2.348744068960484
Validation loss: 2.3843725590257994

Epoch: 5| Step: 6
Training loss: 2.348264897768208
Validation loss: 2.392558730689092

Epoch: 5| Step: 7
Training loss: 2.403606796085414
Validation loss: 2.390183800768403

Epoch: 5| Step: 8
Training loss: 2.5922508963201567
Validation loss: 2.3990328026157863

Epoch: 5| Step: 9
Training loss: 2.599238643679036
Validation loss: 2.387024913407459

Epoch: 5| Step: 10
Training loss: 2.4810983414508083
Validation loss: 2.3985834605384126

Epoch: 5| Step: 11
Training loss: 3.1156411984557284
Validation loss: 2.40133808041297

Epoch: 38| Step: 0
Training loss: 2.3567464978277135
Validation loss: 2.4011774100591565

Epoch: 5| Step: 1
Training loss: 2.1689154130368227
Validation loss: 2.4001561157128517

Epoch: 5| Step: 2
Training loss: 1.7684984709021525
Validation loss: 2.412309740730581

Epoch: 5| Step: 3
Training loss: 2.0405318421485172
Validation loss: 2.4048289937575857

Epoch: 5| Step: 4
Training loss: 2.1230012806310397
Validation loss: 2.400780596713867

Epoch: 5| Step: 5
Training loss: 2.639123794629829
Validation loss: 2.4045628912592276

Epoch: 5| Step: 6
Training loss: 2.7250853638883528
Validation loss: 2.4191971854232843

Epoch: 5| Step: 7
Training loss: 2.431631016233525
Validation loss: 2.391585636981544

Epoch: 5| Step: 8
Training loss: 2.684833889729846
Validation loss: 2.392404901371037

Epoch: 5| Step: 9
Training loss: 2.5123833093067827
Validation loss: 2.396847834924295

Epoch: 5| Step: 10
Training loss: 2.410458340252993
Validation loss: 2.3976515394429505

Epoch: 5| Step: 11
Training loss: 3.392108083082621
Validation loss: 2.3954212718934174

Epoch: 39| Step: 0
Training loss: 2.444545930383722
Validation loss: 2.386006396218451

Epoch: 5| Step: 1
Training loss: 2.1254134056526457
Validation loss: 2.38552181700676

Epoch: 5| Step: 2
Training loss: 2.3415921259336816
Validation loss: 2.371607572383842

Epoch: 5| Step: 3
Training loss: 2.2797657566875134
Validation loss: 2.3840823265961686

Epoch: 5| Step: 4
Training loss: 2.235290339853502
Validation loss: 2.387659697991888

Epoch: 5| Step: 5
Training loss: 2.438117315910491
Validation loss: 2.3804888626048557

Epoch: 5| Step: 6
Training loss: 2.6810590164706527
Validation loss: 2.3788077736502387

Epoch: 5| Step: 7
Training loss: 2.8187917905022934
Validation loss: 2.377931302152969

Epoch: 5| Step: 8
Training loss: 2.166916270428296
Validation loss: 2.3835793433790213

Epoch: 5| Step: 9
Training loss: 2.078844791895904
Validation loss: 2.3851176925493127

Epoch: 5| Step: 10
Training loss: 2.5513439638514255
Validation loss: 2.38615872919453

Epoch: 5| Step: 11
Training loss: 2.8285009650609254
Validation loss: 2.3827511534584835

Epoch: 40| Step: 0
Training loss: 2.6533231879125014
Validation loss: 2.3829410643367197

Epoch: 5| Step: 1
Training loss: 2.167867352288119
Validation loss: 2.379021694512028

Epoch: 5| Step: 2
Training loss: 2.2380074804622483
Validation loss: 2.388639681191845

Epoch: 5| Step: 3
Training loss: 2.5237516319870457
Validation loss: 2.3829371852250385

Epoch: 5| Step: 4
Training loss: 2.2409474203400577
Validation loss: 2.3975853830062945

Epoch: 5| Step: 5
Training loss: 2.1079760398226903
Validation loss: 2.3940910776963262

Epoch: 5| Step: 6
Training loss: 2.011453496241338
Validation loss: 2.4115266556807287

Epoch: 5| Step: 7
Training loss: 2.711227797210238
Validation loss: 2.4258060075251056

Epoch: 5| Step: 8
Training loss: 2.6427188675103737
Validation loss: 2.445112721952819

Epoch: 5| Step: 9
Training loss: 2.37467171257264
Validation loss: 2.4486993160782693

Epoch: 5| Step: 10
Training loss: 2.301848133436856
Validation loss: 2.4312098457302387

Epoch: 5| Step: 11
Training loss: 3.5439957683184917
Validation loss: 2.4343881754422743

Epoch: 41| Step: 0
Training loss: 1.7724016163885123
Validation loss: 2.4139703714512764

Epoch: 5| Step: 1
Training loss: 2.2597995976405922
Validation loss: 2.413765490880771

Epoch: 5| Step: 2
Training loss: 2.1361561929051582
Validation loss: 2.4006045116611943

Epoch: 5| Step: 3
Training loss: 2.6682858816197013
Validation loss: 2.3893935204381105

Epoch: 5| Step: 4
Training loss: 2.446525004995277
Validation loss: 2.3900742280744374

Epoch: 5| Step: 5
Training loss: 2.9062273578377065
Validation loss: 2.3868461300186987

Epoch: 5| Step: 6
Training loss: 1.9027314153376886
Validation loss: 2.38423706995636

Epoch: 5| Step: 7
Training loss: 2.600305568638611
Validation loss: 2.3777731904655792

Epoch: 5| Step: 8
Training loss: 2.48498815491461
Validation loss: 2.38216382561992

Epoch: 5| Step: 9
Training loss: 2.520985170525798
Validation loss: 2.38284800768802

Epoch: 5| Step: 10
Training loss: 2.1961967886491083
Validation loss: 2.3793802859133475

Epoch: 5| Step: 11
Training loss: 2.892781211219806
Validation loss: 2.3881179570727578

Epoch: 42| Step: 0
Training loss: 2.4562239783852426
Validation loss: 2.3848384582578124

Epoch: 5| Step: 1
Training loss: 2.0442253609882566
Validation loss: 2.3848182157965563

Epoch: 5| Step: 2
Training loss: 2.6025706677548563
Validation loss: 2.386601688159339

Epoch: 5| Step: 3
Training loss: 2.050944236454849
Validation loss: 2.3973644374427296

Epoch: 5| Step: 4
Training loss: 2.685387335460003
Validation loss: 2.4086542256175028

Epoch: 5| Step: 5
Training loss: 2.4511790727608465
Validation loss: 2.4146876631593077

Epoch: 5| Step: 6
Training loss: 2.7486333051876377
Validation loss: 2.422890378514758

Epoch: 5| Step: 7
Training loss: 2.3144083139451532
Validation loss: 2.4253073622069916

Epoch: 5| Step: 8
Training loss: 2.6328434701790298
Validation loss: 2.4254657255540226

Epoch: 5| Step: 9
Training loss: 2.385332419783174
Validation loss: 2.4363717989472655

Epoch: 5| Step: 10
Training loss: 1.7392014714432207
Validation loss: 2.434759759755636

Epoch: 5| Step: 11
Training loss: 1.891216847494122
Validation loss: 2.429077304867113

Epoch: 43| Step: 0
Training loss: 2.392870278718921
Validation loss: 2.4270195065784432

Epoch: 5| Step: 1
Training loss: 2.0973865186435345
Validation loss: 2.4252596799694444

Epoch: 5| Step: 2
Training loss: 2.0993328533388094
Validation loss: 2.422103719268411

Epoch: 5| Step: 3
Training loss: 2.221991736327152
Validation loss: 2.406584055943186

Epoch: 5| Step: 4
Training loss: 2.1844371606716773
Validation loss: 2.4056101088551496

Epoch: 5| Step: 5
Training loss: 2.1423201705617676
Validation loss: 2.4022237773597728

Epoch: 5| Step: 6
Training loss: 2.8654603667479543
Validation loss: 2.3962522776206

Epoch: 5| Step: 7
Training loss: 2.2484004374849946
Validation loss: 2.4012836794962773

Epoch: 5| Step: 8
Training loss: 2.6040352648326297
Validation loss: 2.3926296181879088

Epoch: 5| Step: 9
Training loss: 2.670201898720702
Validation loss: 2.386149761598443

Epoch: 5| Step: 10
Training loss: 2.5403212024315818
Validation loss: 2.3873633530343294

Epoch: 5| Step: 11
Training loss: 1.2991408351673441
Validation loss: 2.3927430886210748

Epoch: 44| Step: 0
Training loss: 2.4284496036395304
Validation loss: 2.3863654075412315

Epoch: 5| Step: 1
Training loss: 2.968721891571292
Validation loss: 2.3887206556320018

Epoch: 5| Step: 2
Training loss: 2.370193737980147
Validation loss: 2.3891974385892953

Epoch: 5| Step: 3
Training loss: 2.284272477840864
Validation loss: 2.3840959563153534

Epoch: 5| Step: 4
Training loss: 2.0680837474592577
Validation loss: 2.3885730963157332

Epoch: 5| Step: 5
Training loss: 2.2893932741494423
Validation loss: 2.395576025096227

Epoch: 5| Step: 6
Training loss: 2.4444775603199376
Validation loss: 2.3833334848319407

Epoch: 5| Step: 7
Training loss: 2.4068181741881323
Validation loss: 2.380719029225495

Epoch: 5| Step: 8
Training loss: 1.9707499442762875
Validation loss: 2.388923829276578

Epoch: 5| Step: 9
Training loss: 2.285126097390545
Validation loss: 2.384191476751033

Epoch: 5| Step: 10
Training loss: 2.308596435132216
Validation loss: 2.3943274423179006

Epoch: 5| Step: 11
Training loss: 2.509866794075958
Validation loss: 2.394614284085913

Epoch: 45| Step: 0
Training loss: 2.990422218646786
Validation loss: 2.3958033946834227

Epoch: 5| Step: 1
Training loss: 2.4917720819158666
Validation loss: 2.39258848434593

Epoch: 5| Step: 2
Training loss: 2.296238506124322
Validation loss: 2.409179332884149

Epoch: 5| Step: 3
Training loss: 2.4413322254402705
Validation loss: 2.3938581382488673

Epoch: 5| Step: 4
Training loss: 1.9608793212041504
Validation loss: 2.393449863777613

Epoch: 5| Step: 5
Training loss: 2.4079370900867976
Validation loss: 2.402245672027858

Epoch: 5| Step: 6
Training loss: 2.0755695894099526
Validation loss: 2.3995734909515063

Epoch: 5| Step: 7
Training loss: 2.223597643963217
Validation loss: 2.408588346643746

Epoch: 5| Step: 8
Training loss: 2.011895684914792
Validation loss: 2.4225315598661905

Epoch: 5| Step: 9
Training loss: 2.550876679906359
Validation loss: 2.432198060471992

Epoch: 5| Step: 10
Training loss: 2.4737906844237645
Validation loss: 2.413660602385829

Epoch: 5| Step: 11
Training loss: 2.044192820880758
Validation loss: 2.4043382878149573

Epoch: 46| Step: 0
Training loss: 2.700232750079528
Validation loss: 2.4018662140899227

Epoch: 5| Step: 1
Training loss: 2.128223554707027
Validation loss: 2.3947071510745532

Epoch: 5| Step: 2
Training loss: 1.9335216161971176
Validation loss: 2.38666677964688

Epoch: 5| Step: 3
Training loss: 2.89086418193311
Validation loss: 2.390668216223285

Epoch: 5| Step: 4
Training loss: 1.9229620363690623
Validation loss: 2.382000268801619

Epoch: 5| Step: 5
Training loss: 2.5853269841708197
Validation loss: 2.374688642571585

Epoch: 5| Step: 6
Training loss: 2.730243810029982
Validation loss: 2.3771833330785443

Epoch: 5| Step: 7
Training loss: 2.004060200211505
Validation loss: 2.380673583544715

Epoch: 5| Step: 8
Training loss: 2.199107084268207
Validation loss: 2.3792145544422523

Epoch: 5| Step: 9
Training loss: 2.1877275621032726
Validation loss: 2.378663671326551

Epoch: 5| Step: 10
Training loss: 2.5110439503483515
Validation loss: 2.385609024876498

Epoch: 5| Step: 11
Training loss: 2.0194074050442636
Validation loss: 2.3804890921274096

Epoch: 47| Step: 0
Training loss: 2.6848317584813572
Validation loss: 2.3849905909246707

Epoch: 5| Step: 1
Training loss: 2.092435623509477
Validation loss: 2.3773641865604356

Epoch: 5| Step: 2
Training loss: 1.8857122860419004
Validation loss: 2.3768597482370324

Epoch: 5| Step: 3
Training loss: 1.6988578325394577
Validation loss: 2.374996634949425

Epoch: 5| Step: 4
Training loss: 2.538762752739465
Validation loss: 2.3840401827281448

Epoch: 5| Step: 5
Training loss: 2.060469928769178
Validation loss: 2.380014300350161

Epoch: 5| Step: 6
Training loss: 2.8848211635649017
Validation loss: 2.4000022456039414

Epoch: 5| Step: 7
Training loss: 2.539872166578191
Validation loss: 2.385640068642892

Epoch: 5| Step: 8
Training loss: 2.313348562903206
Validation loss: 2.3947256319472374

Epoch: 5| Step: 9
Training loss: 2.48213613142649
Validation loss: 2.402871001155677

Epoch: 5| Step: 10
Training loss: 2.385922163218911
Validation loss: 2.418187506932598

Epoch: 5| Step: 11
Training loss: 2.1874949863921342
Validation loss: 2.401149123980632

Epoch: 48| Step: 0
Training loss: 2.2148547298421626
Validation loss: 2.409682121608904

Epoch: 5| Step: 1
Training loss: 1.8746089527521534
Validation loss: 2.4007664782749

Epoch: 5| Step: 2
Training loss: 2.105647318385738
Validation loss: 2.392564742900767

Epoch: 5| Step: 3
Training loss: 2.324881425520603
Validation loss: 2.40442376792269

Epoch: 5| Step: 4
Training loss: 2.5586275753668195
Validation loss: 2.3962949860883302

Epoch: 5| Step: 5
Training loss: 2.703569056028818
Validation loss: 2.4158489937706196

Epoch: 5| Step: 6
Training loss: 1.8214858043451527
Validation loss: 2.4084670805724206

Epoch: 5| Step: 7
Training loss: 2.7541940958000923
Validation loss: 2.40412597503362

Epoch: 5| Step: 8
Training loss: 2.442911059677696
Validation loss: 2.4102649756936625

Epoch: 5| Step: 9
Training loss: 2.649894921000867
Validation loss: 2.401609218542583

Epoch: 5| Step: 10
Training loss: 2.094056747512875
Validation loss: 2.3925673005773955

Epoch: 5| Step: 11
Training loss: 1.7946109606220344
Validation loss: 2.395953748966417

Epoch: 49| Step: 0
Training loss: 2.1403208050070313
Validation loss: 2.390137094894447

Epoch: 5| Step: 1
Training loss: 2.6023316492161808
Validation loss: 2.39191818997068

Epoch: 5| Step: 2
Training loss: 2.681193470748015
Validation loss: 2.377407727408086

Epoch: 5| Step: 3
Training loss: 2.627565855585632
Validation loss: 2.391033316421475

Epoch: 5| Step: 4
Training loss: 2.498758866264334
Validation loss: 2.384675186945932

Epoch: 5| Step: 5
Training loss: 1.786994104889046
Validation loss: 2.386198487629181

Epoch: 5| Step: 6
Training loss: 2.6605266475622673
Validation loss: 2.3904843361720425

Epoch: 5| Step: 7
Training loss: 2.552212043682493
Validation loss: 2.3883251230662657

Epoch: 5| Step: 8
Training loss: 1.8998645081646073
Validation loss: 2.3888601175381954

Epoch: 5| Step: 9
Training loss: 1.5735496443149735
Validation loss: 2.3926437431212344

Epoch: 5| Step: 10
Training loss: 2.641259111640548
Validation loss: 2.383885791216803

Epoch: 5| Step: 11
Training loss: 1.533655262751646
Validation loss: 2.3926601349146344

Epoch: 50| Step: 0
Training loss: 2.346995027319862
Validation loss: 2.3990754098243823

Epoch: 5| Step: 1
Training loss: 2.1379721136888414
Validation loss: 2.4042503275989224

Epoch: 5| Step: 2
Training loss: 3.2493797590716524
Validation loss: 2.4186813914830574

Epoch: 5| Step: 3
Training loss: 2.516209220574736
Validation loss: 2.4281032892677863

Epoch: 5| Step: 4
Training loss: 1.3894128123846738
Validation loss: 2.4201632572505845

Epoch: 5| Step: 5
Training loss: 1.521379068082254
Validation loss: 2.4341118119795637

Epoch: 5| Step: 6
Training loss: 2.349156362189131
Validation loss: 2.436796608533355

Epoch: 5| Step: 7
Training loss: 2.2058921372439735
Validation loss: 2.4323536676404918

Epoch: 5| Step: 8
Training loss: 2.623896775704178
Validation loss: 2.4377395805579845

Epoch: 5| Step: 9
Training loss: 2.392133847462814
Validation loss: 2.4425008979894627

Epoch: 5| Step: 10
Training loss: 2.3288399027549262
Validation loss: 2.4350995446053423

Epoch: 5| Step: 11
Training loss: 2.768495783103527
Validation loss: 2.4286427024926387

Epoch: 51| Step: 0
Training loss: 2.7302517565946967
Validation loss: 2.4181273063805766

Epoch: 5| Step: 1
Training loss: 2.378519562360738
Validation loss: 2.387995597403721

Epoch: 5| Step: 2
Training loss: 2.3951662102287563
Validation loss: 2.3844865223746394

Epoch: 5| Step: 3
Training loss: 2.3117124917737506
Validation loss: 2.37584360934198

Epoch: 5| Step: 4
Training loss: 1.7514300634048425
Validation loss: 2.3808176622708395

Epoch: 5| Step: 5
Training loss: 2.4947438298512354
Validation loss: 2.381545174861076

Epoch: 5| Step: 6
Training loss: 1.8722880778567104
Validation loss: 2.3884899374751423

Epoch: 5| Step: 7
Training loss: 2.393956673965452
Validation loss: 2.3796104616555747

Epoch: 5| Step: 8
Training loss: 2.7436343992033083
Validation loss: 2.3783226946927187

Epoch: 5| Step: 9
Training loss: 2.262047830995064
Validation loss: 2.379748480857276

Epoch: 5| Step: 10
Training loss: 2.458852314451738
Validation loss: 2.379210617062552

Epoch: 5| Step: 11
Training loss: 1.6383082426264193
Validation loss: 2.386469801485726

Epoch: 52| Step: 0
Training loss: 1.725842286839907
Validation loss: 2.3874411335190664

Epoch: 5| Step: 1
Training loss: 1.9879487064966905
Validation loss: 2.3814077270014664

Epoch: 5| Step: 2
Training loss: 1.866232144780732
Validation loss: 2.4142755539917586

Epoch: 5| Step: 3
Training loss: 2.360414591757751
Validation loss: 2.401872128555973

Epoch: 5| Step: 4
Training loss: 2.636861523188953
Validation loss: 2.4186656175724246

Epoch: 5| Step: 5
Training loss: 2.6502044994693463
Validation loss: 2.4212990845139495

Epoch: 5| Step: 6
Training loss: 1.8664443320744035
Validation loss: 2.4128112780745714

Epoch: 5| Step: 7
Training loss: 2.4513848808719287
Validation loss: 2.4310710990709157

Epoch: 5| Step: 8
Training loss: 2.427133671534609
Validation loss: 2.4343428135034837

Epoch: 5| Step: 9
Training loss: 2.173342641135725
Validation loss: 2.4465804098495907

Epoch: 5| Step: 10
Training loss: 3.19575135591316
Validation loss: 2.4368484290520986

Epoch: 5| Step: 11
Training loss: 2.1535881308436835
Validation loss: 2.420679615713608

Epoch: 53| Step: 0
Training loss: 1.5867919123661536
Validation loss: 2.414782539150547

Epoch: 5| Step: 1
Training loss: 2.3145356368796715
Validation loss: 2.4069922776179573

Epoch: 5| Step: 2
Training loss: 2.5922314898234444
Validation loss: 2.406838287341637

Epoch: 5| Step: 3
Training loss: 2.355932186964212
Validation loss: 2.3930162508745245

Epoch: 5| Step: 4
Training loss: 2.2478636029768113
Validation loss: 2.4016019839017475

Epoch: 5| Step: 5
Training loss: 2.7581269082296838
Validation loss: 2.3923510655206224

Epoch: 5| Step: 6
Training loss: 2.576351318588125
Validation loss: 2.3891554743470587

Epoch: 5| Step: 7
Training loss: 2.528907539713816
Validation loss: 2.39714038412535

Epoch: 5| Step: 8
Training loss: 1.713818358679423
Validation loss: 2.3855326380017767

Epoch: 5| Step: 9
Training loss: 2.11101349666298
Validation loss: 2.38003062886343

Epoch: 5| Step: 10
Training loss: 1.9004085026338244
Validation loss: 2.38708351790013

Epoch: 5| Step: 11
Training loss: 3.627312284485537
Validation loss: 2.382306333885083

Epoch: 54| Step: 0
Training loss: 2.108815889081009
Validation loss: 2.3791198154374866

Epoch: 5| Step: 1
Training loss: 2.0639197347100695
Validation loss: 2.3881331153577996

Epoch: 5| Step: 2
Training loss: 2.0436399097714224
Validation loss: 2.388687595368727

Epoch: 5| Step: 3
Training loss: 2.631696787253711
Validation loss: 2.3839734110485558

Epoch: 5| Step: 4
Training loss: 2.801313235357719
Validation loss: 2.3917830992700737

Epoch: 5| Step: 5
Training loss: 2.424580496457329
Validation loss: 2.3886624843176807

Epoch: 5| Step: 6
Training loss: 2.715071370853467
Validation loss: 2.4063369210962837

Epoch: 5| Step: 7
Training loss: 1.4338932400150948
Validation loss: 2.3910117989571655

Epoch: 5| Step: 8
Training loss: 1.8692670279147305
Validation loss: 2.395942185182022

Epoch: 5| Step: 9
Training loss: 2.542569130526897
Validation loss: 2.4005930323526057

Epoch: 5| Step: 10
Training loss: 2.4214783374448343
Validation loss: 2.41390987436381

Epoch: 5| Step: 11
Training loss: 2.2592241038984473
Validation loss: 2.400158011347636

Epoch: 55| Step: 0
Training loss: 2.2556427030008708
Validation loss: 2.397170466315813

Epoch: 5| Step: 1
Training loss: 2.584133660004086
Validation loss: 2.40382110325892

Epoch: 5| Step: 2
Training loss: 1.872521988213755
Validation loss: 2.40150516005568

Epoch: 5| Step: 3
Training loss: 2.5418329236628447
Validation loss: 2.4030101565139637

Epoch: 5| Step: 4
Training loss: 1.9394542928425171
Validation loss: 2.390811462028623

Epoch: 5| Step: 5
Training loss: 2.2555884788983374
Validation loss: 2.3930285884803637

Epoch: 5| Step: 6
Training loss: 2.332965197359589
Validation loss: 2.377070544980481

Epoch: 5| Step: 7
Training loss: 2.340330961574578
Validation loss: 2.388334515075054

Epoch: 5| Step: 8
Training loss: 2.5021955386075914
Validation loss: 2.3862218844297924

Epoch: 5| Step: 9
Training loss: 2.087918259069348
Validation loss: 2.3869095063759773

Epoch: 5| Step: 10
Training loss: 2.529039147402475
Validation loss: 2.3931624341314888

Epoch: 5| Step: 11
Training loss: 1.9660774741173266
Validation loss: 2.383101903298423

Epoch: 56| Step: 0
Training loss: 2.4821840618042015
Validation loss: 2.379845632607832

Epoch: 5| Step: 1
Training loss: 2.0006903410623824
Validation loss: 2.401203660334146

Epoch: 5| Step: 2
Training loss: 2.571879457119942
Validation loss: 2.41210172500118

Epoch: 5| Step: 3
Training loss: 2.438897343676179
Validation loss: 2.4256806693159345

Epoch: 5| Step: 4
Training loss: 2.0636893802198593
Validation loss: 2.430460562590531

Epoch: 5| Step: 5
Training loss: 2.2679841485520784
Validation loss: 2.4272630826889756

Epoch: 5| Step: 6
Training loss: 2.294462740806966
Validation loss: 2.4362062582868482

Epoch: 5| Step: 7
Training loss: 2.1520843072564677
Validation loss: 2.413851937634409

Epoch: 5| Step: 8
Training loss: 2.8841584327871934
Validation loss: 2.4174685148209276

Epoch: 5| Step: 9
Training loss: 1.8387373981264423
Validation loss: 2.41749559085816

Epoch: 5| Step: 10
Training loss: 2.2517782178118506
Validation loss: 2.4253676507760464

Epoch: 5| Step: 11
Training loss: 0.7302285681808228
Validation loss: 2.4037463489867763

Epoch: 57| Step: 0
Training loss: 2.3492047729685326
Validation loss: 2.397007187468769

Epoch: 5| Step: 1
Training loss: 1.972885269618803
Validation loss: 2.4021099524720047

Epoch: 5| Step: 2
Training loss: 2.0238999239715874
Validation loss: 2.4062792747335116

Epoch: 5| Step: 3
Training loss: 2.583513397176154
Validation loss: 2.397879959232033

Epoch: 5| Step: 4
Training loss: 2.623108227566879
Validation loss: 2.382871103868913

Epoch: 5| Step: 5
Training loss: 1.5268191634284984
Validation loss: 2.390393929544313

Epoch: 5| Step: 6
Training loss: 2.260764544975842
Validation loss: 2.387964738182128

Epoch: 5| Step: 7
Training loss: 2.8595736075044194
Validation loss: 2.372800243313709

Epoch: 5| Step: 8
Training loss: 2.559046022467158
Validation loss: 2.3763725974015437

Epoch: 5| Step: 9
Training loss: 1.9905684530469856
Validation loss: 2.3814418123075027

Epoch: 5| Step: 10
Training loss: 1.9818446930511175
Validation loss: 2.3674461760574155

Epoch: 5| Step: 11
Training loss: 2.6766769357993385
Validation loss: 2.3797970979282326

Epoch: 58| Step: 0
Training loss: 2.478102340690856
Validation loss: 2.384153028616043

Epoch: 5| Step: 1
Training loss: 2.2476325825760144
Validation loss: 2.3802285280490882

Epoch: 5| Step: 2
Training loss: 1.8419298142223661
Validation loss: 2.3832964046213783

Epoch: 5| Step: 3
Training loss: 2.4657324203085764
Validation loss: 2.3869739651996147

Epoch: 5| Step: 4
Training loss: 2.3422588436771226
Validation loss: 2.396715310060263

Epoch: 5| Step: 5
Training loss: 2.3198666128091947
Validation loss: 2.4025540970511576

Epoch: 5| Step: 6
Training loss: 2.2634866028109677
Validation loss: 2.3942869019206006

Epoch: 5| Step: 7
Training loss: 2.118853262126318
Validation loss: 2.409347171680462

Epoch: 5| Step: 8
Training loss: 2.336207447593149
Validation loss: 2.410658468209134

Epoch: 5| Step: 9
Training loss: 2.180568940701341
Validation loss: 2.4302812731856

Epoch: 5| Step: 10
Training loss: 2.509287082751946
Validation loss: 2.4318435400440417

Epoch: 5| Step: 11
Training loss: 1.3322853897499631
Validation loss: 2.4287552225564277

Epoch: 59| Step: 0
Training loss: 3.1469059477631967
Validation loss: 2.434405865389924

Epoch: 5| Step: 1
Training loss: 2.0963876535967367
Validation loss: 2.4116436486825266

Epoch: 5| Step: 2
Training loss: 1.939459025670782
Validation loss: 2.408079434467113

Epoch: 5| Step: 3
Training loss: 1.8809988063258876
Validation loss: 2.4009308130873808

Epoch: 5| Step: 4
Training loss: 1.8799706376603242
Validation loss: 2.3994193847497858

Epoch: 5| Step: 5
Training loss: 2.22161443928912
Validation loss: 2.3988790944294913

Epoch: 5| Step: 6
Training loss: 1.6812365818551804
Validation loss: 2.3930814709228465

Epoch: 5| Step: 7
Training loss: 2.142987360857825
Validation loss: 2.386571472751836

Epoch: 5| Step: 8
Training loss: 2.9303876116591523
Validation loss: 2.396755709906235

Epoch: 5| Step: 9
Training loss: 2.5917242021296913
Validation loss: 2.3953317628580697

Epoch: 5| Step: 10
Training loss: 2.123805327343099
Validation loss: 2.3856659402216795

Epoch: 5| Step: 11
Training loss: 1.3348514090578063
Validation loss: 2.39180709352397

Epoch: 60| Step: 0
Training loss: 2.4741643130568653
Validation loss: 2.3846352906348756

Epoch: 5| Step: 1
Training loss: 2.1597458516825223
Validation loss: 2.3832100583475673

Epoch: 5| Step: 2
Training loss: 2.288059366342996
Validation loss: 2.3892152157381226

Epoch: 5| Step: 3
Training loss: 2.524134961753286
Validation loss: 2.3977164718242765

Epoch: 5| Step: 4
Training loss: 1.8316107879505916
Validation loss: 2.396195147325471

Epoch: 5| Step: 5
Training loss: 2.187366481520918
Validation loss: 2.405737207111192

Epoch: 5| Step: 6
Training loss: 2.104806204820547
Validation loss: 2.3938610929269393

Epoch: 5| Step: 7
Training loss: 2.370309916968249
Validation loss: 2.419763746167572

Epoch: 5| Step: 8
Training loss: 2.5189149561174835
Validation loss: 2.453011981928109

Epoch: 5| Step: 9
Training loss: 2.1484791144762325
Validation loss: 2.446708183399743

Epoch: 5| Step: 10
Training loss: 2.438963621824644
Validation loss: 2.4360968920368733

Epoch: 5| Step: 11
Training loss: 1.6072723578700179
Validation loss: 2.4184937674889193

Epoch: 61| Step: 0
Training loss: 1.8699594774802508
Validation loss: 2.4148301115034485

Epoch: 5| Step: 1
Training loss: 2.5253802400332686
Validation loss: 2.4223046116592246

Epoch: 5| Step: 2
Training loss: 2.2446161070204207
Validation loss: 2.397545896269184

Epoch: 5| Step: 3
Training loss: 2.4108150824409686
Validation loss: 2.406381640610923

Epoch: 5| Step: 4
Training loss: 2.245766153079801
Validation loss: 2.399229413903918

Epoch: 5| Step: 5
Training loss: 2.1462880982898347
Validation loss: 2.400616239203838

Epoch: 5| Step: 6
Training loss: 2.3708902237094107
Validation loss: 2.3857459558703633

Epoch: 5| Step: 7
Training loss: 2.018083123286223
Validation loss: 2.3873185373419634

Epoch: 5| Step: 8
Training loss: 1.6465989114873358
Validation loss: 2.3905790777512177

Epoch: 5| Step: 9
Training loss: 2.1328459237522415
Validation loss: 2.3794528644294135

Epoch: 5| Step: 10
Training loss: 2.6415990353499925
Validation loss: 2.3828617820437845

Epoch: 5| Step: 11
Training loss: 3.4383166643540846
Validation loss: 2.398106571856107

Epoch: 62| Step: 0
Training loss: 2.773976104446387
Validation loss: 2.3896495620065985

Epoch: 5| Step: 1
Training loss: 2.030762364469271
Validation loss: 2.379934546975755

Epoch: 5| Step: 2
Training loss: 2.347409252813687
Validation loss: 2.3783885703648435

Epoch: 5| Step: 3
Training loss: 2.18440441717551
Validation loss: 2.386018257964444

Epoch: 5| Step: 4
Training loss: 2.3182561219898794
Validation loss: 2.37344255327562

Epoch: 5| Step: 5
Training loss: 2.3194594950641334
Validation loss: 2.3728262925681816

Epoch: 5| Step: 6
Training loss: 2.579692202401453
Validation loss: 2.3810274660952735

Epoch: 5| Step: 7
Training loss: 1.8741642678894097
Validation loss: 2.3653843457037143

Epoch: 5| Step: 8
Training loss: 1.7401677899193382
Validation loss: 2.3706134349454744

Epoch: 5| Step: 9
Training loss: 2.269334269131573
Validation loss: 2.3774534110121817

Epoch: 5| Step: 10
Training loss: 2.311455052358996
Validation loss: 2.385080563022936

Epoch: 5| Step: 11
Training loss: 2.0547408760593204
Validation loss: 2.3860263808740676

Epoch: 63| Step: 0
Training loss: 1.736272512774692
Validation loss: 2.4134957266496353

Epoch: 5| Step: 1
Training loss: 1.9601652288858409
Validation loss: 2.4301710925224027

Epoch: 5| Step: 2
Training loss: 2.1207279571355375
Validation loss: 2.433942934051919

Epoch: 5| Step: 3
Training loss: 2.372776998864481
Validation loss: 2.46675317221675

Epoch: 5| Step: 4
Training loss: 2.268315894260494
Validation loss: 2.462160506946379

Epoch: 5| Step: 5
Training loss: 2.5528167501174415
Validation loss: 2.4669356056682825

Epoch: 5| Step: 6
Training loss: 2.3546205831333284
Validation loss: 2.426369266631434

Epoch: 5| Step: 7
Training loss: 2.7056583594761414
Validation loss: 2.4235568574870747

Epoch: 5| Step: 8
Training loss: 1.9976336666258374
Validation loss: 2.400638920290843

Epoch: 5| Step: 9
Training loss: 2.185857319537236
Validation loss: 2.3946662292272536

Epoch: 5| Step: 10
Training loss: 2.291338521409712
Validation loss: 2.3880482356261377

Epoch: 5| Step: 11
Training loss: 2.4872372052339715
Validation loss: 2.3763526465205516

Epoch: 64| Step: 0
Training loss: 1.4950115383302567
Validation loss: 2.3675415940879008

Epoch: 5| Step: 1
Training loss: 2.5124406266669976
Validation loss: 2.3837729639335143

Epoch: 5| Step: 2
Training loss: 2.0936330506415217
Validation loss: 2.3691326245002227

Epoch: 5| Step: 3
Training loss: 1.6153812364745521
Validation loss: 2.359139380152925

Epoch: 5| Step: 4
Training loss: 2.7836352631896477
Validation loss: 2.3784043858515607

Epoch: 5| Step: 5
Training loss: 2.063657724684711
Validation loss: 2.3704894907350353

Epoch: 5| Step: 6
Training loss: 2.311431122239039
Validation loss: 2.363022353438276

Epoch: 5| Step: 7
Training loss: 2.195051836170746
Validation loss: 2.3747974694212886

Epoch: 5| Step: 8
Training loss: 2.284564184451472
Validation loss: 2.3903456007303503

Epoch: 5| Step: 9
Training loss: 2.0090060119235145
Validation loss: 2.3909263628662583

Epoch: 5| Step: 10
Training loss: 2.7263510548272603
Validation loss: 2.369709274760071

Epoch: 5| Step: 11
Training loss: 3.0177889160802156
Validation loss: 2.3822154605176533

Epoch: 65| Step: 0
Training loss: 1.9042399080020835
Validation loss: 2.4001729611485394

Epoch: 5| Step: 1
Training loss: 1.8606864087187223
Validation loss: 2.4043794148312627

Epoch: 5| Step: 2
Training loss: 2.612307425524266
Validation loss: 2.416078910523032

Epoch: 5| Step: 3
Training loss: 2.4944501309895237
Validation loss: 2.4296335048747473

Epoch: 5| Step: 4
Training loss: 2.198075046226583
Validation loss: 2.4490614723436077

Epoch: 5| Step: 5
Training loss: 2.395895042177579
Validation loss: 2.4462348104566405

Epoch: 5| Step: 6
Training loss: 2.4922072071982377
Validation loss: 2.428782138003209

Epoch: 5| Step: 7
Training loss: 2.616046896102947
Validation loss: 2.4223326773575895

Epoch: 5| Step: 8
Training loss: 1.5269911571264128
Validation loss: 2.4006882170868393

Epoch: 5| Step: 9
Training loss: 1.8470529615763707
Validation loss: 2.3996493604937417

Epoch: 5| Step: 10
Training loss: 2.291087221813911
Validation loss: 2.3792324061811945

Epoch: 5| Step: 11
Training loss: 2.143944498475351
Validation loss: 2.3712325162884835

Epoch: 66| Step: 0
Training loss: 2.0892613820579258
Validation loss: 2.3703970097543547

Epoch: 5| Step: 1
Training loss: 2.60453246535691
Validation loss: 2.3617859894231388

Epoch: 5| Step: 2
Training loss: 1.6080445651336317
Validation loss: 2.3809034527565074

Epoch: 5| Step: 3
Training loss: 2.1638377379331186
Validation loss: 2.391658445309809

Epoch: 5| Step: 4
Training loss: 2.1167718120301307
Validation loss: 2.3942729526455353

Epoch: 5| Step: 5
Training loss: 2.5239282845285276
Validation loss: 2.373306124200609

Epoch: 5| Step: 6
Training loss: 1.9039211117646124
Validation loss: 2.4078425590987242

Epoch: 5| Step: 7
Training loss: 1.97084200684438
Validation loss: 2.4043243885919288

Epoch: 5| Step: 8
Training loss: 2.5561133089336847
Validation loss: 2.3965868234952423

Epoch: 5| Step: 9
Training loss: 2.3871499528964506
Validation loss: 2.381101016559565

Epoch: 5| Step: 10
Training loss: 2.409840765635056
Validation loss: 2.386155356982685

Epoch: 5| Step: 11
Training loss: 1.4337655362099782
Validation loss: 2.390365864956014

Epoch: 67| Step: 0
Training loss: 1.835428370230256
Validation loss: 2.379775712633982

Epoch: 5| Step: 1
Training loss: 1.8992156643452092
Validation loss: 2.386300705397154

Epoch: 5| Step: 2
Training loss: 1.5481219419557741
Validation loss: 2.378971414242502

Epoch: 5| Step: 3
Training loss: 2.1182884366219628
Validation loss: 2.3756348363787616

Epoch: 5| Step: 4
Training loss: 2.7608329507044713
Validation loss: 2.3979953954837776

Epoch: 5| Step: 5
Training loss: 2.1899245857945164
Validation loss: 2.403005112996445

Epoch: 5| Step: 6
Training loss: 2.3920194261584977
Validation loss: 2.402903707110037

Epoch: 5| Step: 7
Training loss: 2.326929591970666
Validation loss: 2.4100790068100184

Epoch: 5| Step: 8
Training loss: 1.9418720016726454
Validation loss: 2.418555176780134

Epoch: 5| Step: 9
Training loss: 2.6539945114412453
Validation loss: 2.4101239722103474

Epoch: 5| Step: 10
Training loss: 2.2237271643629932
Validation loss: 2.3983228761700373

Epoch: 5| Step: 11
Training loss: 2.2160577693047063
Validation loss: 2.3988770611261696

Epoch: 68| Step: 0
Training loss: 2.3778562937852326
Validation loss: 2.3884865415200736

Epoch: 5| Step: 1
Training loss: 2.012789483900451
Validation loss: 2.397953034220996

Epoch: 5| Step: 2
Training loss: 1.9061771441435726
Validation loss: 2.434123867827051

Epoch: 5| Step: 3
Training loss: 2.1436716938453175
Validation loss: 2.4033053285415056

Epoch: 5| Step: 4
Training loss: 2.364311460306245
Validation loss: 2.432019732438103

Epoch: 5| Step: 5
Training loss: 2.0982688989459706
Validation loss: 2.4134738990534585

Epoch: 5| Step: 6
Training loss: 2.3493712091275802
Validation loss: 2.4150170184984403

Epoch: 5| Step: 7
Training loss: 2.097589076154709
Validation loss: 2.3876652565529057

Epoch: 5| Step: 8
Training loss: 2.215326273462735
Validation loss: 2.4083576756097433

Epoch: 5| Step: 9
Training loss: 1.8248793000322732
Validation loss: 2.396638545575209

Epoch: 5| Step: 10
Training loss: 2.6776531716352587
Validation loss: 2.3790431680098063

Epoch: 5| Step: 11
Training loss: 0.641076789276443
Validation loss: 2.401458362049738

Epoch: 69| Step: 0
Training loss: 2.3763183147276705
Validation loss: 2.3977224545305087

Epoch: 5| Step: 1
Training loss: 2.3113856336986385
Validation loss: 2.396009676428155

Epoch: 5| Step: 2
Training loss: 2.0569985740259815
Validation loss: 2.378050474301604

Epoch: 5| Step: 3
Training loss: 1.9534444929115844
Validation loss: 2.397914622383561

Epoch: 5| Step: 4
Training loss: 1.7304622744746927
Validation loss: 2.3973432647977084

Epoch: 5| Step: 5
Training loss: 1.9356686951210758
Validation loss: 2.402180276906764

Epoch: 5| Step: 6
Training loss: 2.5311505333466315
Validation loss: 2.4156193491749143

Epoch: 5| Step: 7
Training loss: 2.416613764567513
Validation loss: 2.432928554679867

Epoch: 5| Step: 8
Training loss: 2.277891011511997
Validation loss: 2.436255228879591

Epoch: 5| Step: 9
Training loss: 2.6497349444574465
Validation loss: 2.438987314848153

Epoch: 5| Step: 10
Training loss: 1.6806948457832356
Validation loss: 2.449472027935246

Epoch: 5| Step: 11
Training loss: 1.8099139608303265
Validation loss: 2.4300232233172703

Epoch: 70| Step: 0
Training loss: 1.8468877311048286
Validation loss: 2.39682791770174

Epoch: 5| Step: 1
Training loss: 2.032306220469983
Validation loss: 2.4056306182195786

Epoch: 5| Step: 2
Training loss: 2.3936997131961992
Validation loss: 2.404862908205301

Epoch: 5| Step: 3
Training loss: 2.3460507099625576
Validation loss: 2.3941785916731737

Epoch: 5| Step: 4
Training loss: 2.1245893193746825
Validation loss: 2.381090398631268

Epoch: 5| Step: 5
Training loss: 1.9607611345108502
Validation loss: 2.413399495226457

Epoch: 5| Step: 6
Training loss: 2.2829961495285547
Validation loss: 2.3912474127444896

Epoch: 5| Step: 7
Training loss: 2.409755283926537
Validation loss: 2.4144558508931193

Epoch: 5| Step: 8
Training loss: 2.3336983349827314
Validation loss: 2.397751758803228

Epoch: 5| Step: 9
Training loss: 2.4040289201948677
Validation loss: 2.3920662780086817

Epoch: 5| Step: 10
Training loss: 1.8095266354390596
Validation loss: 2.4014804270942998

Epoch: 5| Step: 11
Training loss: 1.492862568687023
Validation loss: 2.4077120711110074

Epoch: 71| Step: 0
Training loss: 1.794298198548483
Validation loss: 2.4548235922905968

Epoch: 5| Step: 1
Training loss: 2.184115707441442
Validation loss: 2.5351462146029444

Epoch: 5| Step: 2
Training loss: 2.1164389550381157
Validation loss: 2.5938801024259015

Epoch: 5| Step: 3
Training loss: 2.1752387694040527
Validation loss: 2.6643146235245245

Epoch: 5| Step: 4
Training loss: 3.0300282641310634
Validation loss: 2.6841338982329264

Epoch: 5| Step: 5
Training loss: 2.087918144879731
Validation loss: 2.603626482569183

Epoch: 5| Step: 6
Training loss: 2.0618331293466707
Validation loss: 2.5519745797061657

Epoch: 5| Step: 7
Training loss: 2.607349454752703
Validation loss: 2.478324584171609

Epoch: 5| Step: 8
Training loss: 2.188343648351147
Validation loss: 2.4163680419630937

Epoch: 5| Step: 9
Training loss: 2.652207114024769
Validation loss: 2.390120895691847

Epoch: 5| Step: 10
Training loss: 1.833976379962106
Validation loss: 2.4059387930560088

Epoch: 5| Step: 11
Training loss: 1.585755586761347
Validation loss: 2.3823800450188917

Epoch: 72| Step: 0
Training loss: 2.226353257369351
Validation loss: 2.378211050861953

Epoch: 5| Step: 1
Training loss: 2.677732238100898
Validation loss: 2.3849396867310104

Epoch: 5| Step: 2
Training loss: 2.25665337927253
Validation loss: 2.393818390834564

Epoch: 5| Step: 3
Training loss: 2.27282108720143
Validation loss: 2.378448584285201

Epoch: 5| Step: 4
Training loss: 2.1233952016315785
Validation loss: 2.3880860095488052

Epoch: 5| Step: 5
Training loss: 1.6478364400066883
Validation loss: 2.3852152607499795

Epoch: 5| Step: 6
Training loss: 1.713193894858552
Validation loss: 2.354559010470224

Epoch: 5| Step: 7
Training loss: 2.392846365703072
Validation loss: 2.384460342199826

Epoch: 5| Step: 8
Training loss: 1.9770751408955585
Validation loss: 2.393056206719395

Epoch: 5| Step: 9
Training loss: 2.0882215246585702
Validation loss: 2.4282333994610563

Epoch: 5| Step: 10
Training loss: 2.170348474851174
Validation loss: 2.46426074775214

Epoch: 5| Step: 11
Training loss: 2.7470840253057136
Validation loss: 2.4882391322716972

Epoch: 73| Step: 0
Training loss: 1.9775361086976397
Validation loss: 2.465914236363536

Epoch: 5| Step: 1
Training loss: 1.7787014313512173
Validation loss: 2.459301419835745

Epoch: 5| Step: 2
Training loss: 2.2375871737243824
Validation loss: 2.436813261827346

Epoch: 5| Step: 3
Training loss: 1.8093107380103859
Validation loss: 2.4194069561613056

Epoch: 5| Step: 4
Training loss: 1.9901053524404821
Validation loss: 2.406822904282033

Epoch: 5| Step: 5
Training loss: 1.7756656983386456
Validation loss: 2.3935041169357674

Epoch: 5| Step: 6
Training loss: 1.9771898201449054
Validation loss: 2.3896363027722076

Epoch: 5| Step: 7
Training loss: 2.1472917310554887
Validation loss: 2.4044045683197304

Epoch: 5| Step: 8
Training loss: 2.4598486050485957
Validation loss: 2.387916659735291

Epoch: 5| Step: 9
Training loss: 2.5072996381615225
Validation loss: 2.394874303408847

Epoch: 5| Step: 10
Training loss: 2.470015382602993
Validation loss: 2.375957174832221

Epoch: 5| Step: 11
Training loss: 3.0247443477326517
Validation loss: 2.3849260764125044

Epoch: 74| Step: 0
Training loss: 1.7545913683543426
Validation loss: 2.368701257766171

Epoch: 5| Step: 1
Training loss: 2.1413500595096684
Validation loss: 2.3756814572969467

Epoch: 5| Step: 2
Training loss: 2.15102549647672
Validation loss: 2.376533389743989

Epoch: 5| Step: 3
Training loss: 2.051851120669534
Validation loss: 2.372854258984011

Epoch: 5| Step: 4
Training loss: 1.9907363093948658
Validation loss: 2.3909576035046913

Epoch: 5| Step: 5
Training loss: 2.03329611207424
Validation loss: 2.366175322895034

Epoch: 5| Step: 6
Training loss: 2.2701646246011604
Validation loss: 2.3925178842032246

Epoch: 5| Step: 7
Training loss: 2.1119476453982178
Validation loss: 2.397927320066153

Epoch: 5| Step: 8
Training loss: 2.6131095430673823
Validation loss: 2.4050921341979214

Epoch: 5| Step: 9
Training loss: 2.1882277231911855
Validation loss: 2.423305531984638

Epoch: 5| Step: 10
Training loss: 2.179214699716046
Validation loss: 2.4246826386971456

Epoch: 5| Step: 11
Training loss: 2.3052303386131503
Validation loss: 2.431175626648507

Epoch: 75| Step: 0
Training loss: 1.8770473111245953
Validation loss: 2.4810068703209964

Epoch: 5| Step: 1
Training loss: 2.4735059679282085
Validation loss: 2.495650465501213

Epoch: 5| Step: 2
Training loss: 1.225268075765683
Validation loss: 2.5027613172038046

Epoch: 5| Step: 3
Training loss: 2.3069039758905205
Validation loss: 2.5013099278425135

Epoch: 5| Step: 4
Training loss: 2.282924090092145
Validation loss: 2.497471436651286

Epoch: 5| Step: 5
Training loss: 2.97625698814549
Validation loss: 2.475600768878156

Epoch: 5| Step: 6
Training loss: 2.430424422102344
Validation loss: 2.417198535061359

Epoch: 5| Step: 7
Training loss: 1.8939269055619465
Validation loss: 2.3849702893578493

Epoch: 5| Step: 8
Training loss: 2.0236831574831826
Validation loss: 2.3927268510123234

Epoch: 5| Step: 9
Training loss: 1.9013226723811238
Validation loss: 2.3873889354683446

Epoch: 5| Step: 10
Training loss: 1.98949426847765
Validation loss: 2.393845385783273

Epoch: 5| Step: 11
Training loss: 2.15674894890318
Validation loss: 2.387467324697377

Epoch: 76| Step: 0
Training loss: 2.1755058621095458
Validation loss: 2.370014879522681

Epoch: 5| Step: 1
Training loss: 2.147088865597146
Validation loss: 2.3835994192343772

Epoch: 5| Step: 2
Training loss: 2.0723809040302315
Validation loss: 2.393224974923654

Epoch: 5| Step: 3
Training loss: 2.191203334069893
Validation loss: 2.3813872780866046

Epoch: 5| Step: 4
Training loss: 2.2750522607522785
Validation loss: 2.399568518869814

Epoch: 5| Step: 5
Training loss: 1.836102547227231
Validation loss: 2.388325114747375

Epoch: 5| Step: 6
Training loss: 2.5163491669853744
Validation loss: 2.393654123848016

Epoch: 5| Step: 7
Training loss: 1.696650947967643
Validation loss: 2.3940535209330362

Epoch: 5| Step: 8
Training loss: 1.7789432915477792
Validation loss: 2.4182428503515454

Epoch: 5| Step: 9
Training loss: 1.8160109879501591
Validation loss: 2.4347096676299382

Epoch: 5| Step: 10
Training loss: 2.0606813215172544
Validation loss: 2.442769960115432

Epoch: 5| Step: 11
Training loss: 3.1706115010111597
Validation loss: 2.4523167665699837

Epoch: 77| Step: 0
Training loss: 2.3826581060700134
Validation loss: 2.458288579603471

Epoch: 5| Step: 1
Training loss: 1.941948858992214
Validation loss: 2.478819299185404

Epoch: 5| Step: 2
Training loss: 1.7337265864567326
Validation loss: 2.4535046099483493

Epoch: 5| Step: 3
Training loss: 1.8743425488182968
Validation loss: 2.4391857048488963

Epoch: 5| Step: 4
Training loss: 2.1622840376605206
Validation loss: 2.4511380217343426

Epoch: 5| Step: 5
Training loss: 1.8372261232513414
Validation loss: 2.439304767757105

Epoch: 5| Step: 6
Training loss: 2.0903098468988945
Validation loss: 2.4151978687972355

Epoch: 5| Step: 7
Training loss: 2.4859632297721244
Validation loss: 2.4414491085105317

Epoch: 5| Step: 8
Training loss: 2.156299535210003
Validation loss: 2.4137516665210104

Epoch: 5| Step: 9
Training loss: 2.6336669440949083
Validation loss: 2.3947553254951806

Epoch: 5| Step: 10
Training loss: 1.6422914306970808
Validation loss: 2.3691171056340536

Epoch: 5| Step: 11
Training loss: 1.9697384245273712
Validation loss: 2.3930866702678046

Epoch: 78| Step: 0
Training loss: 2.1467532682819304
Validation loss: 2.3832942746592085

Epoch: 5| Step: 1
Training loss: 1.9374200742910008
Validation loss: 2.3650588189096724

Epoch: 5| Step: 2
Training loss: 2.2278037375979993
Validation loss: 2.392870477993049

Epoch: 5| Step: 3
Training loss: 2.000277023203452
Validation loss: 2.3899790051035574

Epoch: 5| Step: 4
Training loss: 2.145032146719817
Validation loss: 2.3842210910798207

Epoch: 5| Step: 5
Training loss: 2.1086079651055556
Validation loss: 2.373395775366909

Epoch: 5| Step: 6
Training loss: 1.7219984394558205
Validation loss: 2.3955247652677585

Epoch: 5| Step: 7
Training loss: 1.8343057076723113
Validation loss: 2.389442246841415

Epoch: 5| Step: 8
Training loss: 1.951793857906984
Validation loss: 2.3741989499775187

Epoch: 5| Step: 9
Training loss: 1.8900106393423801
Validation loss: 2.3950368815139362

Epoch: 5| Step: 10
Training loss: 2.5761279145048035
Validation loss: 2.422899411031516

Epoch: 5| Step: 11
Training loss: 1.9688559609614482
Validation loss: 2.423660120852599

Epoch: 79| Step: 0
Training loss: 1.868504654206606
Validation loss: 2.4662423093159958

Epoch: 5| Step: 1
Training loss: 2.1447624818416666
Validation loss: 2.5153836219404893

Epoch: 5| Step: 2
Training loss: 2.350652778540465
Validation loss: 2.5432540042114082

Epoch: 5| Step: 3
Training loss: 1.833179626379265
Validation loss: 2.5273332354854072

Epoch: 5| Step: 4
Training loss: 1.8021282197804835
Validation loss: 2.4752038303404174

Epoch: 5| Step: 5
Training loss: 2.2856559533100897
Validation loss: 2.479851771640084

Epoch: 5| Step: 6
Training loss: 1.4926209144878197
Validation loss: 2.4744167478719814

Epoch: 5| Step: 7
Training loss: 2.1307856392274975
Validation loss: 2.413465078228338

Epoch: 5| Step: 8
Training loss: 2.5807657300179074
Validation loss: 2.4021961714739124

Epoch: 5| Step: 9
Training loss: 1.8777894569287081
Validation loss: 2.409637774607138

Epoch: 5| Step: 10
Training loss: 2.3124901023859135
Validation loss: 2.3915547098534446

Epoch: 5| Step: 11
Training loss: 2.236248271465966
Validation loss: 2.377051011606028

Epoch: 80| Step: 0
Training loss: 1.8372671952978763
Validation loss: 2.3882547878920324

Epoch: 5| Step: 1
Training loss: 2.3483551559174294
Validation loss: 2.3718497774628426

Epoch: 5| Step: 2
Training loss: 1.5754266463781441
Validation loss: 2.3754973685498184

Epoch: 5| Step: 3
Training loss: 2.2125338664938172
Validation loss: 2.376427739971076

Epoch: 5| Step: 4
Training loss: 2.2166573770467046
Validation loss: 2.360509919470617

Epoch: 5| Step: 5
Training loss: 2.1396971313562876
Validation loss: 2.372849327205876

Epoch: 5| Step: 6
Training loss: 1.6555804932755023
Validation loss: 2.36235040665375

Epoch: 5| Step: 7
Training loss: 2.103623184670267
Validation loss: 2.404811776105838

Epoch: 5| Step: 8
Training loss: 2.285088536490083
Validation loss: 2.404587129807922

Epoch: 5| Step: 9
Training loss: 2.0852059785380694
Validation loss: 2.4215705228987616

Epoch: 5| Step: 10
Training loss: 1.9683540793845589
Validation loss: 2.3945422729769503

Epoch: 5| Step: 11
Training loss: 1.9906223506700262
Validation loss: 2.417532797827298

Epoch: 81| Step: 0
Training loss: 2.4078851073727785
Validation loss: 2.427861577346208

Epoch: 5| Step: 1
Training loss: 1.723851764377696
Validation loss: 2.442012213210657

Epoch: 5| Step: 2
Training loss: 1.6105204829631012
Validation loss: 2.4343836743808693

Epoch: 5| Step: 3
Training loss: 2.079124841161073
Validation loss: 2.442621962939212

Epoch: 5| Step: 4
Training loss: 1.31152102881329
Validation loss: 2.455157632483643

Epoch: 5| Step: 5
Training loss: 2.0649621312546205
Validation loss: 2.426679812328483

Epoch: 5| Step: 6
Training loss: 2.0982825340603966
Validation loss: 2.396634926972655

Epoch: 5| Step: 7
Training loss: 2.2470616121219007
Validation loss: 2.412660337631221

Epoch: 5| Step: 8
Training loss: 2.3386858334243437
Validation loss: 2.388305091094187

Epoch: 5| Step: 9
Training loss: 2.108748957662545
Validation loss: 2.376519628870025

Epoch: 5| Step: 10
Training loss: 1.7949827762935642
Validation loss: 2.3670977626867264

Epoch: 5| Step: 11
Training loss: 2.84725367417577
Validation loss: 2.386165656785147

Epoch: 82| Step: 0
Training loss: 2.0142253185482044
Validation loss: 2.366202058039436

Epoch: 5| Step: 1
Training loss: 1.8416920831344745
Validation loss: 2.3856039903765147

Epoch: 5| Step: 2
Training loss: 2.361520057368508
Validation loss: 2.3549211623662347

Epoch: 5| Step: 3
Training loss: 2.1208759006307902
Validation loss: 2.372942585478429

Epoch: 5| Step: 4
Training loss: 2.2099555433125726
Validation loss: 2.385569185825472

Epoch: 5| Step: 5
Training loss: 2.3227937834072994
Validation loss: 2.3960154208496096

Epoch: 5| Step: 6
Training loss: 1.5535785035972915
Validation loss: 2.4152247317287854

Epoch: 5| Step: 7
Training loss: 2.3987102539840777
Validation loss: 2.4588572232168753

Epoch: 5| Step: 8
Training loss: 1.686173023251235
Validation loss: 2.4098900803089967

Epoch: 5| Step: 9
Training loss: 1.7449170954775248
Validation loss: 2.425418759104653

Epoch: 5| Step: 10
Training loss: 1.885691361060894
Validation loss: 2.436068995109418

Epoch: 5| Step: 11
Training loss: 1.742446948520443
Validation loss: 2.3998190704003277

Epoch: 83| Step: 0
Training loss: 1.7781584161658845
Validation loss: 2.3807212908463002

Epoch: 5| Step: 1
Training loss: 1.5070189131908616
Validation loss: 2.39289761648334

Epoch: 5| Step: 2
Training loss: 1.702286400076239
Validation loss: 2.3878879003989217

Epoch: 5| Step: 3
Training loss: 1.6170553991940102
Validation loss: 2.4018543768420977

Epoch: 5| Step: 4
Training loss: 2.2439914584073786
Validation loss: 2.3507016952067246

Epoch: 5| Step: 5
Training loss: 2.0710552682542827
Validation loss: 2.3700392261912677

Epoch: 5| Step: 6
Training loss: 1.9837774142875142
Validation loss: 2.4013841444081034

Epoch: 5| Step: 7
Training loss: 1.745933030346198
Validation loss: 2.3699928463788993

Epoch: 5| Step: 8
Training loss: 2.637014414846625
Validation loss: 2.357084606773388

Epoch: 5| Step: 9
Training loss: 1.7621389763285875
Validation loss: 2.387221849925722

Epoch: 5| Step: 10
Training loss: 2.252372550449429
Validation loss: 2.4064612440381663

Epoch: 5| Step: 11
Training loss: 2.214450915717885
Validation loss: 2.382683726515514

Epoch: 84| Step: 0
Training loss: 1.9043067031997982
Validation loss: 2.4738858818019316

Epoch: 5| Step: 1
Training loss: 2.0427117559886416
Validation loss: 2.515647599807854

Epoch: 5| Step: 2
Training loss: 1.974568201497974
Validation loss: 2.5006912229541283

Epoch: 5| Step: 3
Training loss: 2.5188277807602564
Validation loss: 2.524380302080475

Epoch: 5| Step: 4
Training loss: 2.119684864949688
Validation loss: 2.495061474879219

Epoch: 5| Step: 5
Training loss: 1.530726985750292
Validation loss: 2.438337915624388

Epoch: 5| Step: 6
Training loss: 1.503648612012455
Validation loss: 2.36957021803424

Epoch: 5| Step: 7
Training loss: 1.919678650329053
Validation loss: 2.3732968464289783

Epoch: 5| Step: 8
Training loss: 2.1134578045833208
Validation loss: 2.370051184616586

Epoch: 5| Step: 9
Training loss: 1.9761190406988884
Validation loss: 2.362607846329877

Epoch: 5| Step: 10
Training loss: 2.290047703708377
Validation loss: 2.3764806762193

Epoch: 5| Step: 11
Training loss: 2.2013251345200855
Validation loss: 2.361639552881671

Epoch: 85| Step: 0
Training loss: 2.299406149119994
Validation loss: 2.355573543243985

Epoch: 5| Step: 1
Training loss: 1.85611541722555
Validation loss: 2.3250358833428875

Epoch: 5| Step: 2
Training loss: 1.8656143520441137
Validation loss: 2.375680378448476

Epoch: 5| Step: 3
Training loss: 1.5687981890689837
Validation loss: 2.349566807285978

Epoch: 5| Step: 4
Training loss: 1.5583705503266045
Validation loss: 2.399353639335839

Epoch: 5| Step: 5
Training loss: 1.7136409773257413
Validation loss: 2.416294898974217

Epoch: 5| Step: 6
Training loss: 2.3386576962873495
Validation loss: 2.43809578819804

Epoch: 5| Step: 7
Training loss: 2.2827338004727578
Validation loss: 2.440254470744892

Epoch: 5| Step: 8
Training loss: 1.7381819450215859
Validation loss: 2.4194517379372944

Epoch: 5| Step: 9
Training loss: 1.9491778352223645
Validation loss: 2.437775078763263

Epoch: 5| Step: 10
Training loss: 2.0488441837579665
Validation loss: 2.410788434097636

Epoch: 5| Step: 11
Training loss: 2.0809084958622894
Validation loss: 2.410418433834693

Epoch: 86| Step: 0
Training loss: 1.605131684721232
Validation loss: 2.388574011298501

Epoch: 5| Step: 1
Training loss: 1.7612297242123114
Validation loss: 2.4009427459155033

Epoch: 5| Step: 2
Training loss: 2.0234498719533085
Validation loss: 2.401729976743711

Epoch: 5| Step: 3
Training loss: 1.6477595376948455
Validation loss: 2.407982941209583

Epoch: 5| Step: 4
Training loss: 1.7630248377278848
Validation loss: 2.4379908564685313

Epoch: 5| Step: 5
Training loss: 2.3065165874778675
Validation loss: 2.4099265534736447

Epoch: 5| Step: 6
Training loss: 1.661573025403021
Validation loss: 2.4191910587184453

Epoch: 5| Step: 7
Training loss: 1.855977135328335
Validation loss: 2.4183056770713316

Epoch: 5| Step: 8
Training loss: 1.9955807379339878
Validation loss: 2.396960121360833

Epoch: 5| Step: 9
Training loss: 2.4711672380912875
Validation loss: 2.4157692761288225

Epoch: 5| Step: 10
Training loss: 1.5871856738712977
Validation loss: 2.3931985271320317

Epoch: 5| Step: 11
Training loss: 2.2024945378316985
Validation loss: 2.3804394876158628

Epoch: 87| Step: 0
Training loss: 1.7095053614364681
Validation loss: 2.360071841442268

Epoch: 5| Step: 1
Training loss: 1.7175623865471432
Validation loss: 2.358051697361538

Epoch: 5| Step: 2
Training loss: 2.1800380411241203
Validation loss: 2.3819282183327726

Epoch: 5| Step: 3
Training loss: 1.8690432978595444
Validation loss: 2.3624746033650714

Epoch: 5| Step: 4
Training loss: 1.9565453449612786
Validation loss: 2.355539861715892

Epoch: 5| Step: 5
Training loss: 1.7517162490321923
Validation loss: 2.377190525024089

Epoch: 5| Step: 6
Training loss: 2.0245454913921566
Validation loss: 2.3527214451484757

Epoch: 5| Step: 7
Training loss: 2.2963598802552694
Validation loss: 2.3616072513677477

Epoch: 5| Step: 8
Training loss: 2.2001180487085628
Validation loss: 2.360644645208548

Epoch: 5| Step: 9
Training loss: 1.7194215329639266
Validation loss: 2.3953353543983926

Epoch: 5| Step: 10
Training loss: 1.8378886791385156
Validation loss: 2.438331898125856

Epoch: 5| Step: 11
Training loss: 1.4057072333760972
Validation loss: 2.4255991655976006

Epoch: 88| Step: 0
Training loss: 1.7540769770052185
Validation loss: 2.4228665485812964

Epoch: 5| Step: 1
Training loss: 1.7663903392157843
Validation loss: 2.3891182017480697

Epoch: 5| Step: 2
Training loss: 1.9373498673876621
Validation loss: 2.3959469367473702

Epoch: 5| Step: 3
Training loss: 1.8548138235597553
Validation loss: 2.3752899034814896

Epoch: 5| Step: 4
Training loss: 1.189711970084392
Validation loss: 2.3669490001625024

Epoch: 5| Step: 5
Training loss: 2.5050263421354435
Validation loss: 2.3538711553675946

Epoch: 5| Step: 6
Training loss: 2.065586901153234
Validation loss: 2.346719945466232

Epoch: 5| Step: 7
Training loss: 2.0940991010998142
Validation loss: 2.315837565149717

Epoch: 5| Step: 8
Training loss: 2.0089101203192232
Validation loss: 2.316842066576471

Epoch: 5| Step: 9
Training loss: 1.675311327227449
Validation loss: 2.3239909811104793

Epoch: 5| Step: 10
Training loss: 1.9498636711589215
Validation loss: 2.3844493642720503

Epoch: 5| Step: 11
Training loss: 1.3274991524329056
Validation loss: 2.3788928118714034

Epoch: 89| Step: 0
Training loss: 1.909048371542939
Validation loss: 2.463965798147328

Epoch: 5| Step: 1
Training loss: 2.014923091774319
Validation loss: 2.465046337767694

Epoch: 5| Step: 2
Training loss: 1.569253061191599
Validation loss: 2.405971213700487

Epoch: 5| Step: 3
Training loss: 2.1588445340360782
Validation loss: 2.3849713119378246

Epoch: 5| Step: 4
Training loss: 1.5285282468871757
Validation loss: 2.366662119275636

Epoch: 5| Step: 5
Training loss: 1.6760408782799074
Validation loss: 2.3756241605657324

Epoch: 5| Step: 6
Training loss: 1.6423925415142853
Validation loss: 2.360998066988483

Epoch: 5| Step: 7
Training loss: 1.5450701732809902
Validation loss: 2.346334094611941

Epoch: 5| Step: 8
Training loss: 1.6802544634975
Validation loss: 2.3444457971053967

Epoch: 5| Step: 9
Training loss: 2.0883530478474213
Validation loss: 2.3430622744870613

Epoch: 5| Step: 10
Training loss: 2.4612345198361942
Validation loss: 2.380045943003751

Epoch: 5| Step: 11
Training loss: 2.3879672966256087
Validation loss: 2.3704342896520574

Epoch: 90| Step: 0
Training loss: 1.659969615543302
Validation loss: 2.5032268104215656

Epoch: 5| Step: 1
Training loss: 1.719501885766107
Validation loss: 2.5544120142300337

Epoch: 5| Step: 2
Training loss: 2.1288270708111106
Validation loss: 2.587284256053972

Epoch: 5| Step: 3
Training loss: 2.6374152725857107
Validation loss: 2.5966829049084623

Epoch: 5| Step: 4
Training loss: 1.6261635062858917
Validation loss: 2.4624961357602753

Epoch: 5| Step: 5
Training loss: 2.255301693106426
Validation loss: 2.40304338558854

Epoch: 5| Step: 6
Training loss: 1.11572463287913
Validation loss: 2.3508843492825156

Epoch: 5| Step: 7
Training loss: 1.9326116360376937
Validation loss: 2.325769846115883

Epoch: 5| Step: 8
Training loss: 2.000468437649477
Validation loss: 2.3387909071766804

Epoch: 5| Step: 9
Training loss: 1.5873192090993946
Validation loss: 2.3598855099985103

Epoch: 5| Step: 10
Training loss: 2.048088121917404
Validation loss: 2.365089724984622

Epoch: 5| Step: 11
Training loss: 2.494820378934029
Validation loss: 2.3342820194558604

Epoch: 91| Step: 0
Training loss: 1.537882396006448
Validation loss: 2.345407342909741

Epoch: 5| Step: 1
Training loss: 1.7465523409859398
Validation loss: 2.3522911611519355

Epoch: 5| Step: 2
Training loss: 1.3608288061312332
Validation loss: 2.368287820105791

Epoch: 5| Step: 3
Training loss: 1.3028904308088607
Validation loss: 2.3905718803737344

Epoch: 5| Step: 4
Training loss: 2.123133232094002
Validation loss: 2.4768557129259077

Epoch: 5| Step: 5
Training loss: 1.8325194661978739
Validation loss: 2.4204964231511807

Epoch: 5| Step: 6
Training loss: 1.8676280375842054
Validation loss: 2.4288881812656182

Epoch: 5| Step: 7
Training loss: 2.4377309249649595
Validation loss: 2.3902034845011784

Epoch: 5| Step: 8
Training loss: 2.2362064778254505
Validation loss: 2.36965150243955

Epoch: 5| Step: 9
Training loss: 1.769417529630878
Validation loss: 2.3307205384732312

Epoch: 5| Step: 10
Training loss: 2.1519890300797297
Validation loss: 2.403842047345493

Epoch: 5| Step: 11
Training loss: 1.3650182462877058
Validation loss: 2.3501447393774892

Epoch: 92| Step: 0
Training loss: 2.308802767875001
Validation loss: 2.360871377318166

Epoch: 5| Step: 1
Training loss: 1.674017700712446
Validation loss: 2.387389784327754

Epoch: 5| Step: 2
Training loss: 2.377341371172148
Validation loss: 2.342657120533447

Epoch: 5| Step: 3
Training loss: 1.7419609298835736
Validation loss: 2.329681983137858

Epoch: 5| Step: 4
Training loss: 1.725273099648743
Validation loss: 2.3837562338946396

Epoch: 5| Step: 5
Training loss: 1.7429247609071448
Validation loss: 2.4001975171947203

Epoch: 5| Step: 6
Training loss: 1.8333226839392036
Validation loss: 2.3833316758512413

Epoch: 5| Step: 7
Training loss: 1.5480843642703441
Validation loss: 2.443852469140699

Epoch: 5| Step: 8
Training loss: 1.5833007240283636
Validation loss: 2.3929196587555532

Epoch: 5| Step: 9
Training loss: 1.4135327690517274
Validation loss: 2.420724886918034

Epoch: 5| Step: 10
Training loss: 1.7684769005101366
Validation loss: 2.411817154577426

Epoch: 5| Step: 11
Training loss: 1.107692893906381
Validation loss: 2.3769215623760394

Epoch: 93| Step: 0
Training loss: 1.3678290033771978
Validation loss: 2.3561378401716513

Epoch: 5| Step: 1
Training loss: 2.1449129914819
Validation loss: 2.3741641079438187

Epoch: 5| Step: 2
Training loss: 1.3272215070110907
Validation loss: 2.35211708651692

Epoch: 5| Step: 3
Training loss: 1.7998898631415472
Validation loss: 2.346245058566299

Epoch: 5| Step: 4
Training loss: 1.2911932703280062
Validation loss: 2.353042820968436

Epoch: 5| Step: 5
Training loss: 2.3542613007646014
Validation loss: 2.3964308090462114

Epoch: 5| Step: 6
Training loss: 1.9414200043526855
Validation loss: 2.403561449412285

Epoch: 5| Step: 7
Training loss: 1.8836881888411205
Validation loss: 2.3775008737299745

Epoch: 5| Step: 8
Training loss: 2.173429961640526
Validation loss: 2.3882298490737095

Epoch: 5| Step: 9
Training loss: 1.484578008321883
Validation loss: 2.3449977478024664

Epoch: 5| Step: 10
Training loss: 1.341197317178411
Validation loss: 2.3545824643008975

Epoch: 5| Step: 11
Training loss: 2.1138822649287894
Validation loss: 2.3208195274725423

Epoch: 94| Step: 0
Training loss: 1.7111690138161701
Validation loss: 2.3463581958754505

Epoch: 5| Step: 1
Training loss: 1.7349418195044553
Validation loss: 2.3638743431379927

Epoch: 5| Step: 2
Training loss: 1.9952892018319408
Validation loss: 2.366532989597358

Epoch: 5| Step: 3
Training loss: 1.5230858812720793
Validation loss: 2.415796749528381

Epoch: 5| Step: 4
Training loss: 2.5542165339602585
Validation loss: 2.4148769897588855

Epoch: 5| Step: 5
Training loss: 2.1822267460479425
Validation loss: 2.417421150545613

Epoch: 5| Step: 6
Training loss: 0.9348295643447614
Validation loss: 2.393362734072996

Epoch: 5| Step: 7
Training loss: 1.5280440108167435
Validation loss: 2.417131335430605

Epoch: 5| Step: 8
Training loss: 1.9048211417750802
Validation loss: 2.4225277338976317

Epoch: 5| Step: 9
Training loss: 1.3644092778833474
Validation loss: 2.3654718634198573

Epoch: 5| Step: 10
Training loss: 1.4556090749522181
Validation loss: 2.3340018555054405

Epoch: 5| Step: 11
Training loss: 0.6338738148218749
Validation loss: 2.331306457773371

Epoch: 95| Step: 0
Training loss: 1.621749855461367
Validation loss: 2.3456388152891585

Epoch: 5| Step: 1
Training loss: 1.5812515409560102
Validation loss: 2.3501937870855607

Epoch: 5| Step: 2
Training loss: 1.7187923079398661
Validation loss: 2.344751339100577

Epoch: 5| Step: 3
Training loss: 2.039295987028656
Validation loss: 2.392698056076181

Epoch: 5| Step: 4
Training loss: 1.3780378681759853
Validation loss: 2.383335506387089

Epoch: 5| Step: 5
Training loss: 1.3959983993783427
Validation loss: 2.372265096440647

Epoch: 5| Step: 6
Training loss: 1.6737716469422548
Validation loss: 2.3555750361597707

Epoch: 5| Step: 7
Training loss: 2.0603194992661686
Validation loss: 2.330938305697609

Epoch: 5| Step: 8
Training loss: 2.229436685720953
Validation loss: 2.3877185885407166

Epoch: 5| Step: 9
Training loss: 1.3237623480346072
Validation loss: 2.3707426042632815

Epoch: 5| Step: 10
Training loss: 1.9939370644565364
Validation loss: 2.3706155469675596

Epoch: 5| Step: 11
Training loss: 1.0297941277132616
Validation loss: 2.407582005173359

Epoch: 96| Step: 0
Training loss: 2.059341092329803
Validation loss: 2.3699727558630332

Epoch: 5| Step: 1
Training loss: 1.8321833760883495
Validation loss: 2.397308212149803

Epoch: 5| Step: 2
Training loss: 1.8910485415872869
Validation loss: 2.4045172434636912

Epoch: 5| Step: 3
Training loss: 2.0370160938239548
Validation loss: 2.3540366539177078

Epoch: 5| Step: 4
Training loss: 1.4832924358573418
Validation loss: 2.3587781854443852

Epoch: 5| Step: 5
Training loss: 1.3187649025459203
Validation loss: 2.3315699731884005

Epoch: 5| Step: 6
Training loss: 1.8133849910198683
Validation loss: 2.353859718251945

Epoch: 5| Step: 7
Training loss: 1.8651205457536144
Validation loss: 2.3821985006080486

Epoch: 5| Step: 8
Training loss: 1.3914681353935097
Validation loss: 2.3452340746802007

Epoch: 5| Step: 9
Training loss: 1.6457791701792344
Validation loss: 2.378325543363022

Epoch: 5| Step: 10
Training loss: 1.534632236648528
Validation loss: 2.3479460940904606

Epoch: 5| Step: 11
Training loss: 0.9860014723927335
Validation loss: 2.3817737086885105

Epoch: 97| Step: 0
Training loss: 1.7739396245675099
Validation loss: 2.3434987251371053

Epoch: 5| Step: 1
Training loss: 1.5611912396065208
Validation loss: 2.3393662081611075

Epoch: 5| Step: 2
Training loss: 1.6898576726176775
Validation loss: 2.33596253142453

Epoch: 5| Step: 3
Training loss: 1.6357640506934414
Validation loss: 2.3438946530949676

Epoch: 5| Step: 4
Training loss: 1.7589076720746477
Validation loss: 2.401283226494877

Epoch: 5| Step: 5
Training loss: 2.0762490431331515
Validation loss: 2.368664711798228

Epoch: 5| Step: 6
Training loss: 1.5490791723459603
Validation loss: 2.363922885353217

Epoch: 5| Step: 7
Training loss: 1.718716499695716
Validation loss: 2.4563740314750073

Epoch: 5| Step: 8
Training loss: 1.4496678892808643
Validation loss: 2.4022263454291983

Epoch: 5| Step: 9
Training loss: 1.288072101556306
Validation loss: 2.40934278464148

Epoch: 5| Step: 10
Training loss: 2.0025530255901574
Validation loss: 2.373457784358847

Epoch: 5| Step: 11
Training loss: 1.9967239489906712
Validation loss: 2.367087602343473

Epoch: 98| Step: 0
Training loss: 1.421342938822507
Validation loss: 2.367486424976169

Epoch: 5| Step: 1
Training loss: 1.6773841145904087
Validation loss: 2.3944708073399683

Epoch: 5| Step: 2
Training loss: 1.0429422325163609
Validation loss: 2.343993903290769

Epoch: 5| Step: 3
Training loss: 1.5169476901989087
Validation loss: 2.331947776710513

Epoch: 5| Step: 4
Training loss: 1.6283439562219046
Validation loss: 2.3856140676942004

Epoch: 5| Step: 5
Training loss: 1.6513713744125662
Validation loss: 2.366199988259679

Epoch: 5| Step: 6
Training loss: 1.774721529433365
Validation loss: 2.3680135253042613

Epoch: 5| Step: 7
Training loss: 1.3121240168143782
Validation loss: 2.3579997355527302

Epoch: 5| Step: 8
Training loss: 2.211344435482928
Validation loss: 2.363100445349164

Epoch: 5| Step: 9
Training loss: 1.9386641173829149
Validation loss: 2.3401929948154048

Epoch: 5| Step: 10
Training loss: 1.7127086929910524
Validation loss: 2.2965347682482617

Epoch: 5| Step: 11
Training loss: 2.0451159890631936
Validation loss: 2.371983394231775

Epoch: 99| Step: 0
Training loss: 1.5295363198563694
Validation loss: 2.3457972295658074

Epoch: 5| Step: 1
Training loss: 1.7460355130240304
Validation loss: 2.372191596565567

Epoch: 5| Step: 2
Training loss: 1.695571246815463
Validation loss: 2.3850112359497357

Epoch: 5| Step: 3
Training loss: 1.5983387578183363
Validation loss: 2.3666823701158446

Epoch: 5| Step: 4
Training loss: 1.5604241887494017
Validation loss: 2.361079941026475

Epoch: 5| Step: 5
Training loss: 1.3815268019106914
Validation loss: 2.3997300317373766

Epoch: 5| Step: 6
Training loss: 1.663655979128025
Validation loss: 2.4112044661484084

Epoch: 5| Step: 7
Training loss: 1.8202140028340847
Validation loss: 2.4159152010844718

Epoch: 5| Step: 8
Training loss: 2.009280013572801
Validation loss: 2.399038999435022

Epoch: 5| Step: 9
Training loss: 1.4636940475181246
Validation loss: 2.3531113779957944

Epoch: 5| Step: 10
Training loss: 1.7227806686485911
Validation loss: 2.3627974842625146

Epoch: 5| Step: 11
Training loss: 1.9021295509141047
Validation loss: 2.338323427196554

Epoch: 100| Step: 0
Training loss: 2.354794938864436
Validation loss: 2.3543058807148483

Epoch: 5| Step: 1
Training loss: 1.6342337961267452
Validation loss: 2.3378404077051336

Epoch: 5| Step: 2
Training loss: 1.656281165063695
Validation loss: 2.3642587074804364

Epoch: 5| Step: 3
Training loss: 1.667338696732119
Validation loss: 2.340344754831858

Epoch: 5| Step: 4
Training loss: 1.1663686962176056
Validation loss: 2.3652193492660984

Epoch: 5| Step: 5
Training loss: 1.4641915051794698
Validation loss: 2.3340685458149038

Epoch: 5| Step: 6
Training loss: 1.4362455782643804
Validation loss: 2.379264917254544

Epoch: 5| Step: 7
Training loss: 1.6338054795246975
Validation loss: 2.383172749036739

Epoch: 5| Step: 8
Training loss: 1.9484068989740635
Validation loss: 2.463976607259901

Epoch: 5| Step: 9
Training loss: 1.4844353914524149
Validation loss: 2.404242408811063

Epoch: 5| Step: 10
Training loss: 1.2536337963498938
Validation loss: 2.348435778690197

Epoch: 5| Step: 11
Training loss: 1.9311032680829714
Validation loss: 2.352427901062791

Testing loss: 2.0853561089860473
