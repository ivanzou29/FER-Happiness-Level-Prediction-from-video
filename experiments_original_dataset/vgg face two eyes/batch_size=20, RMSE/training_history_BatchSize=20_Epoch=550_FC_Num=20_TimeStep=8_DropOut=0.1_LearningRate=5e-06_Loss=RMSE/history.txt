Epoch: 1| Step: 0
Training loss: 7.267037728077968
Validation loss: 7.28595636114343

Epoch: 5| Step: 1
Training loss: 6.852405944200992
Validation loss: 7.248868843056484

Epoch: 5| Step: 2
Training loss: 7.3842730656779
Validation loss: 7.212151212759788

Epoch: 5| Step: 3
Training loss: 7.405813727426044
Validation loss: 7.179673774271655

Epoch: 5| Step: 4
Training loss: 6.885842945409636
Validation loss: 7.1471242007483005

Epoch: 5| Step: 5
Training loss: 7.154839122571034
Validation loss: 7.115546675585918

Epoch: 5| Step: 6
Training loss: 7.591640603292581
Validation loss: 7.085147834694597

Epoch: 5| Step: 7
Training loss: 6.839021067921963
Validation loss: 7.054160683169891

Epoch: 5| Step: 8
Training loss: 7.2667686956866415
Validation loss: 7.027421228145334

Epoch: 5| Step: 9
Training loss: 7.443255337438758
Validation loss: 6.9980914034373

Epoch: 5| Step: 10
Training loss: 7.409992029183202
Validation loss: 6.971560984695176

Epoch: 5| Step: 11
Training loss: 6.681570401194845
Validation loss: 6.942727819836555

Epoch: 2| Step: 0
Training loss: 7.015347685568696
Validation loss: 6.91379151468797

Epoch: 5| Step: 1
Training loss: 7.6323641876722395
Validation loss: 6.887194747760596

Epoch: 5| Step: 2
Training loss: 7.547403952817283
Validation loss: 6.859066746997024

Epoch: 5| Step: 3
Training loss: 7.51673217992998
Validation loss: 6.8277977254666

Epoch: 5| Step: 4
Training loss: 5.4875764115907195
Validation loss: 6.802013036609043

Epoch: 5| Step: 5
Training loss: 6.539411346354956
Validation loss: 6.768555133676283

Epoch: 5| Step: 6
Training loss: 6.947143999761194
Validation loss: 6.737838479942603

Epoch: 5| Step: 7
Training loss: 6.442695965108715
Validation loss: 6.707082698967577

Epoch: 5| Step: 8
Training loss: 6.501530980494674
Validation loss: 6.669859534847762

Epoch: 5| Step: 9
Training loss: 6.4728713612791635
Validation loss: 6.63714397071837

Epoch: 5| Step: 10
Training loss: 6.703419783363726
Validation loss: 6.602211487299585

Epoch: 5| Step: 11
Training loss: 8.643377655460965
Validation loss: 6.56135689604064

Epoch: 3| Step: 0
Training loss: 7.014385700151388
Validation loss: 6.524491812354023

Epoch: 5| Step: 1
Training loss: 6.5102675113122395
Validation loss: 6.482442679759254

Epoch: 5| Step: 2
Training loss: 6.224600182374762
Validation loss: 6.438904544232375

Epoch: 5| Step: 3
Training loss: 6.982819864094629
Validation loss: 6.396826883323605

Epoch: 5| Step: 4
Training loss: 6.487107916653958
Validation loss: 6.3460165901131536

Epoch: 5| Step: 5
Training loss: 6.223299289004776
Validation loss: 6.299650629639841

Epoch: 5| Step: 6
Training loss: 6.444106776427288
Validation loss: 6.245028069491357

Epoch: 5| Step: 7
Training loss: 5.799325430216573
Validation loss: 6.1917533448297375

Epoch: 5| Step: 8
Training loss: 6.2172653496319725
Validation loss: 6.140720072261861

Epoch: 5| Step: 9
Training loss: 5.786537845132813
Validation loss: 6.078868294240192

Epoch: 5| Step: 10
Training loss: 6.393732411350135
Validation loss: 6.014032379310181

Epoch: 5| Step: 11
Training loss: 5.962697100630485
Validation loss: 5.952848826866658

Epoch: 4| Step: 0
Training loss: 6.265366242124176
Validation loss: 5.8789400997433585

Epoch: 5| Step: 1
Training loss: 6.003375693254211
Validation loss: 5.809914037612398

Epoch: 5| Step: 2
Training loss: 5.458535731787883
Validation loss: 5.732553135475484

Epoch: 5| Step: 3
Training loss: 5.686046372660953
Validation loss: 5.652735396259381

Epoch: 5| Step: 4
Training loss: 5.975660866936046
Validation loss: 5.570355993442595

Epoch: 5| Step: 5
Training loss: 4.6234039439498105
Validation loss: 5.47713018750154

Epoch: 5| Step: 6
Training loss: 5.1365731918540245
Validation loss: 5.388285283020849

Epoch: 5| Step: 7
Training loss: 5.406476319267097
Validation loss: 5.2810183969008815

Epoch: 5| Step: 8
Training loss: 5.382468955893496
Validation loss: 5.180811572574008

Epoch: 5| Step: 9
Training loss: 4.576338800372619
Validation loss: 5.0719478185929745

Epoch: 5| Step: 10
Training loss: 5.868307644196373
Validation loss: 4.963789897314224

Epoch: 5| Step: 11
Training loss: 4.899701650450539
Validation loss: 4.8367137707012136

Epoch: 5| Step: 0
Training loss: 5.527780252751105
Validation loss: 4.723074945737596

Epoch: 5| Step: 1
Training loss: 4.498028429252778
Validation loss: 4.580592344437185

Epoch: 5| Step: 2
Training loss: 3.9058415313780084
Validation loss: 4.455327186607536

Epoch: 5| Step: 3
Training loss: 4.457531699486691
Validation loss: 4.321173537841973

Epoch: 5| Step: 4
Training loss: 4.463091275235036
Validation loss: 4.175670977981066

Epoch: 5| Step: 5
Training loss: 3.853492980364599
Validation loss: 4.039730619342701

Epoch: 5| Step: 6
Training loss: 4.013719158404577
Validation loss: 3.9080221301681797

Epoch: 5| Step: 7
Training loss: 3.785587313802814
Validation loss: 3.7608144748726873

Epoch: 5| Step: 8
Training loss: 3.227307693106421
Validation loss: 3.6208401357647584

Epoch: 5| Step: 9
Training loss: 3.892978676314984
Validation loss: 3.4809891140135734

Epoch: 5| Step: 10
Training loss: 2.992989136405625
Validation loss: 3.355707902420091

Epoch: 5| Step: 11
Training loss: 2.6255834021992706
Validation loss: 3.239940928177728

Epoch: 6| Step: 0
Training loss: 2.91355273822367
Validation loss: 3.1510649509462896

Epoch: 5| Step: 1
Training loss: 2.977207864800013
Validation loss: 3.108395353462143

Epoch: 5| Step: 2
Training loss: 2.5050227254419206
Validation loss: 3.0375004425624113

Epoch: 5| Step: 3
Training loss: 3.1309883724107612
Validation loss: 3.000450567345239

Epoch: 5| Step: 4
Training loss: 2.8039567680835407
Validation loss: 2.98703893963651

Epoch: 5| Step: 5
Training loss: 3.2570075268703835
Validation loss: 2.986213051487674

Epoch: 5| Step: 6
Training loss: 2.6298908810043793
Validation loss: 2.995179883700583

Epoch: 5| Step: 7
Training loss: 2.8452087685091523
Validation loss: 2.976456913114109

Epoch: 5| Step: 8
Training loss: 3.5940815648252475
Validation loss: 2.9995248537491688

Epoch: 5| Step: 9
Training loss: 2.6054387355373896
Validation loss: 3.028315175386394

Epoch: 5| Step: 10
Training loss: 3.58315566457858
Validation loss: 3.056188879461539

Epoch: 5| Step: 11
Training loss: 3.620156176027571
Validation loss: 3.0283328993756227

Epoch: 7| Step: 0
Training loss: 3.549096038060668
Validation loss: 3.0481468317593943

Epoch: 5| Step: 1
Training loss: 2.931890773076143
Validation loss: 3.0287121049098054

Epoch: 5| Step: 2
Training loss: 2.5875673257665697
Validation loss: 3.021894989683933

Epoch: 5| Step: 3
Training loss: 2.9742889131487202
Validation loss: 3.01897876746714

Epoch: 5| Step: 4
Training loss: 2.600185453696663
Validation loss: 2.9771136677190735

Epoch: 5| Step: 5
Training loss: 2.687711042057789
Validation loss: 2.969904859016532

Epoch: 5| Step: 6
Training loss: 2.3667965808546505
Validation loss: 2.9653080311605957

Epoch: 5| Step: 7
Training loss: 3.414560801020709
Validation loss: 2.943884711750226

Epoch: 5| Step: 8
Training loss: 3.668125007071717
Validation loss: 2.9371447585096475

Epoch: 5| Step: 9
Training loss: 2.812934841872734
Validation loss: 2.921558203157312

Epoch: 5| Step: 10
Training loss: 3.10070896655521
Validation loss: 2.900301608893496

Epoch: 5| Step: 11
Training loss: 1.9841775871060716
Validation loss: 2.8994041229416876

Epoch: 8| Step: 0
Training loss: 2.8097319650934187
Validation loss: 2.891038459557421

Epoch: 5| Step: 1
Training loss: 2.8352732655524484
Validation loss: 2.8903684106990415

Epoch: 5| Step: 2
Training loss: 2.875290897413856
Validation loss: 2.8834796123296527

Epoch: 5| Step: 3
Training loss: 2.869654288122073
Validation loss: 2.875899167360654

Epoch: 5| Step: 4
Training loss: 2.293252072872205
Validation loss: 2.8882893344916307

Epoch: 5| Step: 5
Training loss: 3.3691315670168094
Validation loss: 2.897222447606126

Epoch: 5| Step: 6
Training loss: 2.6463061733707636
Validation loss: 2.902208618605326

Epoch: 5| Step: 7
Training loss: 3.132961050873289
Validation loss: 2.8991139728702278

Epoch: 5| Step: 8
Training loss: 3.364404789741181
Validation loss: 2.909296479686744

Epoch: 5| Step: 9
Training loss: 2.8693224366960814
Validation loss: 2.886504282746804

Epoch: 5| Step: 10
Training loss: 2.8883093554218164
Validation loss: 2.897962416436969

Epoch: 5| Step: 11
Training loss: 1.3344216474826327
Validation loss: 2.878652674473202

Epoch: 9| Step: 0
Training loss: 2.8961422615937997
Validation loss: 2.8749554464785634

Epoch: 5| Step: 1
Training loss: 2.40236240782897
Validation loss: 2.8758061771405803

Epoch: 5| Step: 2
Training loss: 2.2094809111551594
Validation loss: 2.865614248939905

Epoch: 5| Step: 3
Training loss: 2.36082595773773
Validation loss: 2.8535292405559316

Epoch: 5| Step: 4
Training loss: 3.6556082920443322
Validation loss: 2.8481097494742103

Epoch: 5| Step: 5
Training loss: 2.578015966710734
Validation loss: 2.863419019880995

Epoch: 5| Step: 6
Training loss: 3.2629681598443776
Validation loss: 2.852608165885588

Epoch: 5| Step: 7
Training loss: 2.7712788522446083
Validation loss: 2.8408227428549586

Epoch: 5| Step: 8
Training loss: 3.0152212870857777
Validation loss: 2.8421115906350924

Epoch: 5| Step: 9
Training loss: 2.8042567355318297
Validation loss: 2.819301536745704

Epoch: 5| Step: 10
Training loss: 2.589448694446023
Validation loss: 2.8375045608282194

Epoch: 5| Step: 11
Training loss: 4.435553325209973
Validation loss: 2.8228318681449784

Epoch: 10| Step: 0
Training loss: 3.0939666980413456
Validation loss: 2.810516887449147

Epoch: 5| Step: 1
Training loss: 2.1990917975471844
Validation loss: 2.838925139162978

Epoch: 5| Step: 2
Training loss: 3.0870507658654196
Validation loss: 2.8258158493138574

Epoch: 5| Step: 3
Training loss: 2.8215987635322892
Validation loss: 2.7974263576579217

Epoch: 5| Step: 4
Training loss: 3.1953596563986713
Validation loss: 2.8353718595493675

Epoch: 5| Step: 5
Training loss: 2.687366837152222
Validation loss: 2.8159892337398644

Epoch: 5| Step: 6
Training loss: 2.4911516003811456
Validation loss: 2.7945044894737228

Epoch: 5| Step: 7
Training loss: 3.054115183258861
Validation loss: 2.8154439776928246

Epoch: 5| Step: 8
Training loss: 2.624914531224613
Validation loss: 2.801212644672657

Epoch: 5| Step: 9
Training loss: 2.7301722899067125
Validation loss: 2.786713038892199

Epoch: 5| Step: 10
Training loss: 2.877366957517816
Validation loss: 2.814826321131025

Epoch: 5| Step: 11
Training loss: 1.9152027704041983
Validation loss: 2.7957280647047016

Epoch: 11| Step: 0
Training loss: 2.1685037038822923
Validation loss: 2.795487853723706

Epoch: 5| Step: 1
Training loss: 2.166932004184833
Validation loss: 2.806464518678834

Epoch: 5| Step: 2
Training loss: 3.005120516881792
Validation loss: 2.7980676058297216

Epoch: 5| Step: 3
Training loss: 2.6256246277741457
Validation loss: 2.7913519280969625

Epoch: 5| Step: 4
Training loss: 2.5585767905568653
Validation loss: 2.785202129426632

Epoch: 5| Step: 5
Training loss: 2.578082367515644
Validation loss: 2.776173083336093

Epoch: 5| Step: 6
Training loss: 2.6471506779135883
Validation loss: 2.769446582872013

Epoch: 5| Step: 7
Training loss: 3.012717154499429
Validation loss: 2.7640718204390744

Epoch: 5| Step: 8
Training loss: 3.359919730090492
Validation loss: 2.7755049866056742

Epoch: 5| Step: 9
Training loss: 3.066548221484531
Validation loss: 2.7760338678781253

Epoch: 5| Step: 10
Training loss: 3.290482819212511
Validation loss: 2.7862930724196286

Epoch: 5| Step: 11
Training loss: 1.4859323463390681
Validation loss: 2.7843301768749895

Epoch: 12| Step: 0
Training loss: 3.1374012357813315
Validation loss: 2.787637180750434

Epoch: 5| Step: 1
Training loss: 2.3979226221385703
Validation loss: 2.7532679654548455

Epoch: 5| Step: 2
Training loss: 3.16619605198023
Validation loss: 2.7534854612530606

Epoch: 5| Step: 3
Training loss: 2.0971421050318715
Validation loss: 2.7553927005937133

Epoch: 5| Step: 4
Training loss: 3.375440356878527
Validation loss: 2.750188264760336

Epoch: 5| Step: 5
Training loss: 2.0440507580003335
Validation loss: 2.746570865862722

Epoch: 5| Step: 6
Training loss: 2.5194383234437803
Validation loss: 2.75901478251905

Epoch: 5| Step: 7
Training loss: 3.1746053735785966
Validation loss: 2.7378089160022716

Epoch: 5| Step: 8
Training loss: 2.5207968675061867
Validation loss: 2.7677040941873305

Epoch: 5| Step: 9
Training loss: 2.9477211895261806
Validation loss: 2.7493926555254258

Epoch: 5| Step: 10
Training loss: 2.480978124987207
Validation loss: 2.7273421206761284

Epoch: 5| Step: 11
Training loss: 2.6222582531283707
Validation loss: 2.742925325486537

Epoch: 13| Step: 0
Training loss: 3.3921065367846235
Validation loss: 2.7367586264181187

Epoch: 5| Step: 1
Training loss: 2.844086847162312
Validation loss: 2.736487969125603

Epoch: 5| Step: 2
Training loss: 2.2788316632744587
Validation loss: 2.764208946567869

Epoch: 5| Step: 3
Training loss: 2.5586238480755945
Validation loss: 2.731088352439196

Epoch: 5| Step: 4
Training loss: 2.2024788416215326
Validation loss: 2.7470161476947488

Epoch: 5| Step: 5
Training loss: 2.5848506245351333
Validation loss: 2.7279620326927203

Epoch: 5| Step: 6
Training loss: 3.0755846413699084
Validation loss: 2.7114153064406605

Epoch: 5| Step: 7
Training loss: 2.1258280767507647
Validation loss: 2.7233954748287865

Epoch: 5| Step: 8
Training loss: 2.9807627921591004
Validation loss: 2.716324122213819

Epoch: 5| Step: 9
Training loss: 2.9636062230664098
Validation loss: 2.72145015176151

Epoch: 5| Step: 10
Training loss: 2.787191666455517
Validation loss: 2.7128190904729212

Epoch: 5| Step: 11
Training loss: 1.846966152878593
Validation loss: 2.7106511407268523

Epoch: 14| Step: 0
Training loss: 2.165680868906138
Validation loss: 2.7228258756013295

Epoch: 5| Step: 1
Training loss: 2.255906300242462
Validation loss: 2.7121659609355473

Epoch: 5| Step: 2
Training loss: 2.5792606511245055
Validation loss: 2.714827419021484

Epoch: 5| Step: 3
Training loss: 2.4017162464891437
Validation loss: 2.732038880547447

Epoch: 5| Step: 4
Training loss: 2.600434938144616
Validation loss: 2.701432600514875

Epoch: 5| Step: 5
Training loss: 2.7273929063732023
Validation loss: 2.693566262513028

Epoch: 5| Step: 6
Training loss: 3.0401697176689733
Validation loss: 2.6892536747780755

Epoch: 5| Step: 7
Training loss: 2.7837278493848707
Validation loss: 2.712771902651751

Epoch: 5| Step: 8
Training loss: 2.8120982412972837
Validation loss: 2.715758431671659

Epoch: 5| Step: 9
Training loss: 2.826430513875773
Validation loss: 2.7213433784137178

Epoch: 5| Step: 10
Training loss: 3.122114909655671
Validation loss: 2.7080326659250535

Epoch: 5| Step: 11
Training loss: 3.3165851090977103
Validation loss: 2.7109000160344867

Epoch: 15| Step: 0
Training loss: 2.7755172453633
Validation loss: 2.68591770640461

Epoch: 5| Step: 1
Training loss: 2.508792008531503
Validation loss: 2.732334200088927

Epoch: 5| Step: 2
Training loss: 2.7266324534364386
Validation loss: 2.674740799262394

Epoch: 5| Step: 3
Training loss: 2.527314128436825
Validation loss: 2.7259495837808094

Epoch: 5| Step: 4
Training loss: 3.033148888510191
Validation loss: 2.707783204228552

Epoch: 5| Step: 5
Training loss: 2.1905405983331048
Validation loss: 2.714417648724052

Epoch: 5| Step: 6
Training loss: 2.753121598379088
Validation loss: 2.727481224538561

Epoch: 5| Step: 7
Training loss: 3.4700191341169426
Validation loss: 2.6701348681861248

Epoch: 5| Step: 8
Training loss: 2.1259564883712927
Validation loss: 2.69941345631424

Epoch: 5| Step: 9
Training loss: 2.045968706840683
Validation loss: 2.6566414451139786

Epoch: 5| Step: 10
Training loss: 2.8495752386149316
Validation loss: 2.698637646304528

Epoch: 5| Step: 11
Training loss: 3.226059844462925
Validation loss: 2.6893761872455832

Epoch: 16| Step: 0
Training loss: 2.9088998834790605
Validation loss: 2.6787522206524956

Epoch: 5| Step: 1
Training loss: 3.3118704431505703
Validation loss: 2.678817552203399

Epoch: 5| Step: 2
Training loss: 2.883651487257671
Validation loss: 2.6884580760042636

Epoch: 5| Step: 3
Training loss: 2.8224384611329127
Validation loss: 2.6777164338983437

Epoch: 5| Step: 4
Training loss: 2.729966975700535
Validation loss: 2.6707904875220314

Epoch: 5| Step: 5
Training loss: 2.491963726269548
Validation loss: 2.658312572699132

Epoch: 5| Step: 6
Training loss: 1.6625320488845066
Validation loss: 2.68711059173972

Epoch: 5| Step: 7
Training loss: 2.4914230082951003
Validation loss: 2.6789217152208917

Epoch: 5| Step: 8
Training loss: 2.3356151549775155
Validation loss: 2.6654935108950912

Epoch: 5| Step: 9
Training loss: 2.564415750572568
Validation loss: 2.690583234722023

Epoch: 5| Step: 10
Training loss: 2.5638307976975416
Validation loss: 2.6699485340289715

Epoch: 5| Step: 11
Training loss: 2.9321012192307503
Validation loss: 2.6849227679455905

Epoch: 17| Step: 0
Training loss: 2.477652036311215
Validation loss: 2.6693405787342313

Epoch: 5| Step: 1
Training loss: 2.7268628498779837
Validation loss: 2.671153534417938

Epoch: 5| Step: 2
Training loss: 2.393468126080384
Validation loss: 2.6779539322939763

Epoch: 5| Step: 3
Training loss: 2.7429851882428973
Validation loss: 2.676205407005274

Epoch: 5| Step: 4
Training loss: 2.610760349585214
Validation loss: 2.6700400303311533

Epoch: 5| Step: 5
Training loss: 2.4617280205080223
Validation loss: 2.7103324016947425

Epoch: 5| Step: 6
Training loss: 2.6293120616564365
Validation loss: 2.6987400026005193

Epoch: 5| Step: 7
Training loss: 2.6477843973142234
Validation loss: 2.6915659310374265

Epoch: 5| Step: 8
Training loss: 3.288121322110615
Validation loss: 2.7057851590386437

Epoch: 5| Step: 9
Training loss: 2.0219315628559356
Validation loss: 2.687973690426453

Epoch: 5| Step: 10
Training loss: 2.937989052177583
Validation loss: 2.681474506875822

Epoch: 5| Step: 11
Training loss: 2.440671178402864
Validation loss: 2.6823141498302387

Epoch: 18| Step: 0
Training loss: 2.590827214317748
Validation loss: 2.6430325752901247

Epoch: 5| Step: 1
Training loss: 2.314658420648404
Validation loss: 2.6449907881210377

Epoch: 5| Step: 2
Training loss: 2.310533873391674
Validation loss: 2.6539825410520175

Epoch: 5| Step: 3
Training loss: 3.0454295324284395
Validation loss: 2.6561941327970455

Epoch: 5| Step: 4
Training loss: 2.5609516024710373
Validation loss: 2.6555220896836964

Epoch: 5| Step: 5
Training loss: 2.916722615023287
Validation loss: 2.699566702306968

Epoch: 5| Step: 6
Training loss: 2.8214661835410544
Validation loss: 2.7226271807935354

Epoch: 5| Step: 7
Training loss: 2.0360055275338014
Validation loss: 2.6852896420366337

Epoch: 5| Step: 8
Training loss: 2.0837171073930785
Validation loss: 2.676894308657839

Epoch: 5| Step: 9
Training loss: 3.1553293528394364
Validation loss: 2.6813098456188507

Epoch: 5| Step: 10
Training loss: 3.054141412884718
Validation loss: 2.656205767842936

Epoch: 5| Step: 11
Training loss: 2.4278104836156893
Validation loss: 2.66981804177697

Epoch: 19| Step: 0
Training loss: 2.561024869274502
Validation loss: 2.6600172928018555

Epoch: 5| Step: 1
Training loss: 2.5010898122055236
Validation loss: 2.6171933871530393

Epoch: 5| Step: 2
Training loss: 2.777197897041598
Validation loss: 2.652516847710371

Epoch: 5| Step: 3
Training loss: 2.352953325268292
Validation loss: 2.6309350032834575

Epoch: 5| Step: 4
Training loss: 2.835769354088912
Validation loss: 2.656262334159189

Epoch: 5| Step: 5
Training loss: 2.6159688816961184
Validation loss: 2.662906977841256

Epoch: 5| Step: 6
Training loss: 2.5954133181250025
Validation loss: 2.678131430227601

Epoch: 5| Step: 7
Training loss: 2.3768249326694386
Validation loss: 2.6578489128786527

Epoch: 5| Step: 8
Training loss: 2.523924222603625
Validation loss: 2.6416228965137534

Epoch: 5| Step: 9
Training loss: 2.8298043170578695
Validation loss: 2.66230120565945

Epoch: 5| Step: 10
Training loss: 2.4650973568893524
Validation loss: 2.638917024501476

Epoch: 5| Step: 11
Training loss: 2.2555793885703315
Validation loss: 2.682316868240826

Epoch: 20| Step: 0
Training loss: 2.4979985808833467
Validation loss: 2.629348710090922

Epoch: 5| Step: 1
Training loss: 3.0089885839903054
Validation loss: 2.653166874022298

Epoch: 5| Step: 2
Training loss: 2.8231566398693726
Validation loss: 2.6513966220933662

Epoch: 5| Step: 3
Training loss: 2.708302297169802
Validation loss: 2.633203041700275

Epoch: 5| Step: 4
Training loss: 2.1794826178841014
Validation loss: 2.65512821220794

Epoch: 5| Step: 5
Training loss: 2.627025186337367
Validation loss: 2.635802897823223

Epoch: 5| Step: 6
Training loss: 2.9535160512208725
Validation loss: 2.6237668440909494

Epoch: 5| Step: 7
Training loss: 2.571867591226134
Validation loss: 2.628246766912237

Epoch: 5| Step: 8
Training loss: 2.419087929000028
Validation loss: 2.6378063605522213

Epoch: 5| Step: 9
Training loss: 2.627636266889734
Validation loss: 2.652337566325452

Epoch: 5| Step: 10
Training loss: 1.940041935752585
Validation loss: 2.6467671861425384

Epoch: 5| Step: 11
Training loss: 2.9188454981993135
Validation loss: 2.6358517462306077

Epoch: 21| Step: 0
Training loss: 2.2796352367410786
Validation loss: 2.6546369404475225

Epoch: 5| Step: 1
Training loss: 2.9020831682945
Validation loss: 2.6282140756783376

Epoch: 5| Step: 2
Training loss: 2.4034334022051556
Validation loss: 2.615588953521048

Epoch: 5| Step: 3
Training loss: 2.2893585950975486
Validation loss: 2.65369250649888

Epoch: 5| Step: 4
Training loss: 2.844921164333805
Validation loss: 2.6275725928313474

Epoch: 5| Step: 5
Training loss: 1.910832759204395
Validation loss: 2.6426714579698847

Epoch: 5| Step: 6
Training loss: 2.7250317317969963
Validation loss: 2.609073202684109

Epoch: 5| Step: 7
Training loss: 2.540252876009053
Validation loss: 2.646725223932025

Epoch: 5| Step: 8
Training loss: 2.139721645006455
Validation loss: 2.6414754803383773

Epoch: 5| Step: 9
Training loss: 2.4648814735004523
Validation loss: 2.6435798725553292

Epoch: 5| Step: 10
Training loss: 3.5074854233126866
Validation loss: 2.63021084373027

Epoch: 5| Step: 11
Training loss: 2.780059302404183
Validation loss: 2.629232974861149

Epoch: 22| Step: 0
Training loss: 3.1285599839610216
Validation loss: 2.633995495962764

Epoch: 5| Step: 1
Training loss: 2.2480781612655143
Validation loss: 2.6257039518895198

Epoch: 5| Step: 2
Training loss: 2.7735250109983327
Validation loss: 2.6527641723499173

Epoch: 5| Step: 3
Training loss: 2.222111479331023
Validation loss: 2.6101142422446006

Epoch: 5| Step: 4
Training loss: 2.5914056133353434
Validation loss: 2.630678698842918

Epoch: 5| Step: 5
Training loss: 2.58592837236989
Validation loss: 2.6470731260992664

Epoch: 5| Step: 6
Training loss: 2.4398905451254125
Validation loss: 2.599455250165262

Epoch: 5| Step: 7
Training loss: 2.293080835673506
Validation loss: 2.6223735839950484

Epoch: 5| Step: 8
Training loss: 2.755151258909873
Validation loss: 2.6509192850060552

Epoch: 5| Step: 9
Training loss: 2.289914229839885
Validation loss: 2.639699683501672

Epoch: 5| Step: 10
Training loss: 2.465545022535219
Validation loss: 2.6085922719519594

Epoch: 5| Step: 11
Training loss: 2.9753825735088646
Validation loss: 2.6157977537457833

Epoch: 23| Step: 0
Training loss: 1.9630168209977885
Validation loss: 2.6304978818746534

Epoch: 5| Step: 1
Training loss: 2.395167504268676
Validation loss: 2.6255197767303367

Epoch: 5| Step: 2
Training loss: 3.180454021167688
Validation loss: 2.6387133704479764

Epoch: 5| Step: 3
Training loss: 2.421621001675703
Validation loss: 2.6312092277285597

Epoch: 5| Step: 4
Training loss: 2.2340657480344053
Validation loss: 2.6305986561735932

Epoch: 5| Step: 5
Training loss: 2.6283088900974207
Validation loss: 2.644825064914125

Epoch: 5| Step: 6
Training loss: 2.734280393871183
Validation loss: 2.6329481314447047

Epoch: 5| Step: 7
Training loss: 2.5853611053062435
Validation loss: 2.624866292969357

Epoch: 5| Step: 8
Training loss: 2.609335801977992
Validation loss: 2.660591116084509

Epoch: 5| Step: 9
Training loss: 2.8320881594497562
Validation loss: 2.6317792727115332

Epoch: 5| Step: 10
Training loss: 2.1903541473683097
Validation loss: 2.6088773210934444

Epoch: 5| Step: 11
Training loss: 2.1354805045161283
Validation loss: 2.62257282123247

Epoch: 24| Step: 0
Training loss: 2.579535728347646
Validation loss: 2.5955343849402057

Epoch: 5| Step: 1
Training loss: 2.1776079218121236
Validation loss: 2.610439192032093

Epoch: 5| Step: 2
Training loss: 1.919840782835704
Validation loss: 2.6439678018252266

Epoch: 5| Step: 3
Training loss: 2.882057318462257
Validation loss: 2.6189601493705545

Epoch: 5| Step: 4
Training loss: 2.681662496212249
Validation loss: 2.6415623086679316

Epoch: 5| Step: 5
Training loss: 3.0421117866236362
Validation loss: 2.5745089516423887

Epoch: 5| Step: 6
Training loss: 2.491743759782796
Validation loss: 2.6088484996252537

Epoch: 5| Step: 7
Training loss: 1.9372773811668815
Validation loss: 2.634963516182439

Epoch: 5| Step: 8
Training loss: 2.450981418459808
Validation loss: 2.6119658728755994

Epoch: 5| Step: 9
Training loss: 2.700434762778027
Validation loss: 2.6144231440699643

Epoch: 5| Step: 10
Training loss: 2.5873071091851445
Validation loss: 2.583410847690478

Epoch: 5| Step: 11
Training loss: 2.2437426128637754
Validation loss: 2.6229328349440544

Epoch: 25| Step: 0
Training loss: 2.7752085014575933
Validation loss: 2.6239379179855558

Epoch: 5| Step: 1
Training loss: 2.8263119950849007
Validation loss: 2.6499674643612527

Epoch: 5| Step: 2
Training loss: 2.1439715212595916
Validation loss: 2.6077993017387984

Epoch: 5| Step: 3
Training loss: 1.7345585081602757
Validation loss: 2.678258587188471

Epoch: 5| Step: 4
Training loss: 2.8210952813718237
Validation loss: 2.649641946529321

Epoch: 5| Step: 5
Training loss: 2.7520372474001658
Validation loss: 2.660078909296294

Epoch: 5| Step: 6
Training loss: 2.952149729676363
Validation loss: 2.6374584639172816

Epoch: 5| Step: 7
Training loss: 2.8094210407698004
Validation loss: 2.65108932622152

Epoch: 5| Step: 8
Training loss: 2.009090625342377
Validation loss: 2.6525389122453222

Epoch: 5| Step: 9
Training loss: 2.4118685829964925
Validation loss: 2.5920716949464877

Epoch: 5| Step: 10
Training loss: 2.5023698065214277
Validation loss: 2.628572470196326

Epoch: 5| Step: 11
Training loss: 2.634614503229541
Validation loss: 2.612323674878669

Epoch: 26| Step: 0
Training loss: 2.0654766681639702
Validation loss: 2.6558447360378583

Epoch: 5| Step: 1
Training loss: 2.280278456231094
Validation loss: 2.692530994490729

Epoch: 5| Step: 2
Training loss: 2.1356629268414435
Validation loss: 2.646772403222392

Epoch: 5| Step: 3
Training loss: 2.3475675899374977
Validation loss: 2.6493556626329533

Epoch: 5| Step: 4
Training loss: 2.254208972508059
Validation loss: 2.6782129863053266

Epoch: 5| Step: 5
Training loss: 2.7806654755211695
Validation loss: 2.729094483728942

Epoch: 5| Step: 6
Training loss: 3.2664531041096634
Validation loss: 2.745738336128664

Epoch: 5| Step: 7
Training loss: 2.1112652256689346
Validation loss: 2.6748593749460445

Epoch: 5| Step: 8
Training loss: 2.1173917664809294
Validation loss: 2.6892229737552706

Epoch: 5| Step: 9
Training loss: 2.4693117106289493
Validation loss: 2.612047053196854

Epoch: 5| Step: 10
Training loss: 3.194899702572378
Validation loss: 2.665706738660647

Epoch: 5| Step: 11
Training loss: 3.9864119764346757
Validation loss: 2.6235092600099277

Epoch: 27| Step: 0
Training loss: 2.5335845542456172
Validation loss: 2.6413416971470283

Epoch: 5| Step: 1
Training loss: 2.869369632730053
Validation loss: 2.6543889763061967

Epoch: 5| Step: 2
Training loss: 2.563716227635872
Validation loss: 2.632595453267657

Epoch: 5| Step: 3
Training loss: 3.0007507656369437
Validation loss: 2.6131850996133936

Epoch: 5| Step: 4
Training loss: 2.417556752245868
Validation loss: 2.598074161881604

Epoch: 5| Step: 5
Training loss: 1.8888272652515803
Validation loss: 2.591491984084922

Epoch: 5| Step: 6
Training loss: 1.9760828453952113
Validation loss: 2.653812827463993

Epoch: 5| Step: 7
Training loss: 2.1944725085796506
Validation loss: 2.6615846433483923

Epoch: 5| Step: 8
Training loss: 2.6472982021003046
Validation loss: 2.6335028546027353

Epoch: 5| Step: 9
Training loss: 2.9724409749785523
Validation loss: 2.64563453232823

Epoch: 5| Step: 10
Training loss: 2.115408625166358
Validation loss: 2.6064851695167577

Epoch: 5| Step: 11
Training loss: 2.4218148500910095
Validation loss: 2.599617927244866

Epoch: 28| Step: 0
Training loss: 2.259946560354461
Validation loss: 2.586023550148098

Epoch: 5| Step: 1
Training loss: 2.882024393670687
Validation loss: 2.6360492148221315

Epoch: 5| Step: 2
Training loss: 3.134219036995148
Validation loss: 2.6012267467895995

Epoch: 5| Step: 3
Training loss: 1.8022517160531037
Validation loss: 2.5799770061074483

Epoch: 5| Step: 4
Training loss: 1.8989660838002627
Validation loss: 2.6435774017850013

Epoch: 5| Step: 5
Training loss: 2.1177367451630915
Validation loss: 2.6263429219001115

Epoch: 5| Step: 6
Training loss: 3.0837578524213938
Validation loss: 2.62020374164137

Epoch: 5| Step: 7
Training loss: 2.6982015412700386
Validation loss: 2.63332639634953

Epoch: 5| Step: 8
Training loss: 2.3926947117640425
Validation loss: 2.606649200975665

Epoch: 5| Step: 9
Training loss: 2.280436122408657
Validation loss: 2.6282530526237475

Epoch: 5| Step: 10
Training loss: 2.506156873994342
Validation loss: 2.65330057390715

Epoch: 5| Step: 11
Training loss: 1.392621696400454
Validation loss: 2.6576155013735567

Epoch: 29| Step: 0
Training loss: 2.7921079789735135
Validation loss: 2.6243103423227336

Epoch: 5| Step: 1
Training loss: 1.8466107432760748
Validation loss: 2.6415712816685195

Epoch: 5| Step: 2
Training loss: 2.1416376322201893
Validation loss: 2.664104218962695

Epoch: 5| Step: 3
Training loss: 2.9858944205585463
Validation loss: 2.6249906789523347

Epoch: 5| Step: 4
Training loss: 2.227495285868339
Validation loss: 2.676386231576889

Epoch: 5| Step: 5
Training loss: 2.503098475093056
Validation loss: 2.656555218084

Epoch: 5| Step: 6
Training loss: 2.6439587918704652
Validation loss: 2.6352463291491146

Epoch: 5| Step: 7
Training loss: 2.572821415876816
Validation loss: 2.643869472175949

Epoch: 5| Step: 8
Training loss: 2.3726278806415384
Validation loss: 2.6567780661669893

Epoch: 5| Step: 9
Training loss: 2.751974610677304
Validation loss: 2.672505525548187

Epoch: 5| Step: 10
Training loss: 2.461877261972078
Validation loss: 2.668983251695382

Epoch: 5| Step: 11
Training loss: 0.9598556258994374
Validation loss: 2.737613202865104

Epoch: 30| Step: 0
Training loss: 2.6446176173927527
Validation loss: 2.695062708682448

Epoch: 5| Step: 1
Training loss: 2.295933121614343
Validation loss: 2.62211277345438

Epoch: 5| Step: 2
Training loss: 1.9124521137301167
Validation loss: 2.6097923828239327

Epoch: 5| Step: 3
Training loss: 2.4195622383968707
Validation loss: 2.6185427900106504

Epoch: 5| Step: 4
Training loss: 2.428763456125723
Validation loss: 2.6237951420012444

Epoch: 5| Step: 5
Training loss: 2.4945317546438965
Validation loss: 2.6101272739726715

Epoch: 5| Step: 6
Training loss: 2.523510155355216
Validation loss: 2.598832218471407

Epoch: 5| Step: 7
Training loss: 2.1664514679287477
Validation loss: 2.632826789039904

Epoch: 5| Step: 8
Training loss: 2.6300185232634274
Validation loss: 2.6002609387917617

Epoch: 5| Step: 9
Training loss: 3.0257573653503957
Validation loss: 2.596804505488132

Epoch: 5| Step: 10
Training loss: 2.574678556507985
Validation loss: 2.6670184847097342

Epoch: 5| Step: 11
Training loss: 1.742830440106738
Validation loss: 2.6004596430764146

Epoch: 31| Step: 0
Training loss: 2.371535937132482
Validation loss: 2.639412908363896

Epoch: 5| Step: 1
Training loss: 2.5560902701841015
Validation loss: 2.6149449471999398

Epoch: 5| Step: 2
Training loss: 2.911406833327405
Validation loss: 2.6630565015459737

Epoch: 5| Step: 3
Training loss: 2.6804299618864533
Validation loss: 2.6687585156056963

Epoch: 5| Step: 4
Training loss: 2.750817610834308
Validation loss: 2.6410304666752964

Epoch: 5| Step: 5
Training loss: 1.4742578352703293
Validation loss: 2.692950489929224

Epoch: 5| Step: 6
Training loss: 2.4534762185753394
Validation loss: 2.627017131720516

Epoch: 5| Step: 7
Training loss: 2.286552850135418
Validation loss: 2.616507017576348

Epoch: 5| Step: 8
Training loss: 2.9242937001461318
Validation loss: 2.6763826719952113

Epoch: 5| Step: 9
Training loss: 1.9738314612152996
Validation loss: 2.667952452312416

Epoch: 5| Step: 10
Training loss: 2.489589185721144
Validation loss: 2.6717402403757844

Epoch: 5| Step: 11
Training loss: 2.354792508908113
Validation loss: 2.610571037034918

Epoch: 32| Step: 0
Training loss: 2.18984630637644
Validation loss: 2.646300835245039

Epoch: 5| Step: 1
Training loss: 2.8913418267655766
Validation loss: 2.6005006633648415

Epoch: 5| Step: 2
Training loss: 2.7242966995486433
Validation loss: 2.6658225635868695

Epoch: 5| Step: 3
Training loss: 2.129823931370313
Validation loss: 2.6550999077655484

Epoch: 5| Step: 4
Training loss: 2.9575073987621585
Validation loss: 2.6878705323749905

Epoch: 5| Step: 5
Training loss: 2.1436156383703486
Validation loss: 2.7153581383519114

Epoch: 5| Step: 6
Training loss: 2.142397070496531
Validation loss: 2.6551532089140255

Epoch: 5| Step: 7
Training loss: 2.996900546827212
Validation loss: 2.681775809499678

Epoch: 5| Step: 8
Training loss: 2.7847646729575626
Validation loss: 2.6622548948664413

Epoch: 5| Step: 9
Training loss: 2.2676355320171924
Validation loss: 2.6247289078617078

Epoch: 5| Step: 10
Training loss: 2.5590667986184457
Validation loss: 2.627747256135565

Epoch: 5| Step: 11
Training loss: 1.7196607084299855
Validation loss: 2.6557440369369187

Epoch: 33| Step: 0
Training loss: 2.726114230756536
Validation loss: 2.675425429249377

Epoch: 5| Step: 1
Training loss: 2.748665746045504
Validation loss: 2.7241111126584845

Epoch: 5| Step: 2
Training loss: 2.2599941391995486
Validation loss: 2.715641762521133

Epoch: 5| Step: 3
Training loss: 3.099068434012293
Validation loss: 2.7359756725588666

Epoch: 5| Step: 4
Training loss: 2.846817374457516
Validation loss: 2.7536754827103906

Epoch: 5| Step: 5
Training loss: 2.3784714475260738
Validation loss: 2.74365597537017

Epoch: 5| Step: 6
Training loss: 2.5080151817677536
Validation loss: 2.6879556624454204

Epoch: 5| Step: 7
Training loss: 2.2854048634458755
Validation loss: 2.671498943284859

Epoch: 5| Step: 8
Training loss: 2.0825364178132766
Validation loss: 2.630884303989882

Epoch: 5| Step: 9
Training loss: 1.6985273686613573
Validation loss: 2.623003561874683

Epoch: 5| Step: 10
Training loss: 2.9856532689689343
Validation loss: 2.633568441080212

Epoch: 5| Step: 11
Training loss: 1.7226254553431986
Validation loss: 2.599683187818736

Epoch: 34| Step: 0
Training loss: 2.7406529319670807
Validation loss: 2.62464036445852

Epoch: 5| Step: 1
Training loss: 2.102744978740331
Validation loss: 2.6021231618988563

Epoch: 5| Step: 2
Training loss: 3.0502138281738556
Validation loss: 2.5953504113680568

Epoch: 5| Step: 3
Training loss: 2.1852710812359937
Validation loss: 2.6257519061389667

Epoch: 5| Step: 4
Training loss: 2.3870691519837752
Validation loss: 2.5695417730839485

Epoch: 5| Step: 5
Training loss: 1.7810961338980682
Validation loss: 2.5909442126683637

Epoch: 5| Step: 6
Training loss: 3.0002878368894894
Validation loss: 2.6094658049661037

Epoch: 5| Step: 7
Training loss: 2.9358415182928774
Validation loss: 2.6022493259596295

Epoch: 5| Step: 8
Training loss: 2.2125194268532153
Validation loss: 2.6142543431229215

Epoch: 5| Step: 9
Training loss: 2.2140588732079283
Validation loss: 2.590695142927606

Epoch: 5| Step: 10
Training loss: 2.3523183222637645
Validation loss: 2.6637284450712073

Epoch: 5| Step: 11
Training loss: 1.884005030408651
Validation loss: 2.5957264398044892

Epoch: 35| Step: 0
Training loss: 2.444689686591492
Validation loss: 2.5948153494835418

Epoch: 5| Step: 1
Training loss: 2.5150022505945406
Validation loss: 2.6212195542943912

Epoch: 5| Step: 2
Training loss: 2.738083858150425
Validation loss: 2.625771534024133

Epoch: 5| Step: 3
Training loss: 2.2333803964277346
Validation loss: 2.6539746243953344

Epoch: 5| Step: 4
Training loss: 2.1069793660837743
Validation loss: 2.63264818367379

Epoch: 5| Step: 5
Training loss: 1.953433447323911
Validation loss: 2.685742468907076

Epoch: 5| Step: 6
Training loss: 3.0067431642171245
Validation loss: 2.71587485073818

Epoch: 5| Step: 7
Training loss: 2.7555924684434623
Validation loss: 2.7075176893708983

Epoch: 5| Step: 8
Training loss: 2.7546948325178042
Validation loss: 2.6516156964725166

Epoch: 5| Step: 9
Training loss: 2.3213299405450947
Validation loss: 2.642690456471758

Epoch: 5| Step: 10
Training loss: 2.3734951270957283
Validation loss: 2.6347483980083655

Epoch: 5| Step: 11
Training loss: 1.6372234140015027
Validation loss: 2.5577474888404677

Epoch: 36| Step: 0
Training loss: 2.2839267651028723
Validation loss: 2.5518822097676472

Epoch: 5| Step: 1
Training loss: 2.4376416287479747
Validation loss: 2.6171845127677003

Epoch: 5| Step: 2
Training loss: 3.0959062864625126
Validation loss: 2.6370641599868163

Epoch: 5| Step: 3
Training loss: 3.18475672536856
Validation loss: 2.6108463045421626

Epoch: 5| Step: 4
Training loss: 2.737152171572757
Validation loss: 2.6446659123343754

Epoch: 5| Step: 5
Training loss: 1.7576820833781739
Validation loss: 2.6538289162642306

Epoch: 5| Step: 6
Training loss: 2.389132164487693
Validation loss: 2.5793378385420014

Epoch: 5| Step: 7
Training loss: 2.141201080992718
Validation loss: 2.577232838402982

Epoch: 5| Step: 8
Training loss: 2.7141263384385517
Validation loss: 2.622317502702768

Epoch: 5| Step: 9
Training loss: 2.0392271245805356
Validation loss: 2.587288145554429

Epoch: 5| Step: 10
Training loss: 2.035647049369545
Validation loss: 2.5990600215662614

Epoch: 5| Step: 11
Training loss: 2.090041791142154
Validation loss: 2.596712113898035

Epoch: 37| Step: 0
Training loss: 2.6524513458765706
Validation loss: 2.6145266505223184

Epoch: 5| Step: 1
Training loss: 1.9687845741748047
Validation loss: 2.651330708533198

Epoch: 5| Step: 2
Training loss: 2.220172909369349
Validation loss: 2.622348873370795

Epoch: 5| Step: 3
Training loss: 2.1949387636093345
Validation loss: 2.660417137852933

Epoch: 5| Step: 4
Training loss: 2.159432426163811
Validation loss: 2.6438692091570806

Epoch: 5| Step: 5
Training loss: 2.72507110292956
Validation loss: 2.7175923784160103

Epoch: 5| Step: 6
Training loss: 2.946410766151432
Validation loss: 2.675243332897829

Epoch: 5| Step: 7
Training loss: 2.0452564625243355
Validation loss: 2.707374800496322

Epoch: 5| Step: 8
Training loss: 2.3526412162596846
Validation loss: 2.6705417913330787

Epoch: 5| Step: 9
Training loss: 3.2184208081245287
Validation loss: 2.6591664347912016

Epoch: 5| Step: 10
Training loss: 2.1935687215738398
Validation loss: 2.615926057086234

Epoch: 5| Step: 11
Training loss: 1.3587724950870737
Validation loss: 2.621582709544627

Epoch: 38| Step: 0
Training loss: 2.63249399313101
Validation loss: 2.590245947814134

Epoch: 5| Step: 1
Training loss: 1.9711533061558197
Validation loss: 2.6414618736652744

Epoch: 5| Step: 2
Training loss: 2.6294012864786716
Validation loss: 2.6132903505175413

Epoch: 5| Step: 3
Training loss: 2.8088950896127614
Validation loss: 2.653984625954837

Epoch: 5| Step: 4
Training loss: 2.142164136451733
Validation loss: 2.6347429120418813

Epoch: 5| Step: 5
Training loss: 3.154690045397763
Validation loss: 2.656676998598963

Epoch: 5| Step: 6
Training loss: 2.500371523907669
Validation loss: 2.626579751633739

Epoch: 5| Step: 7
Training loss: 1.9283991539925391
Validation loss: 2.5982676080617106

Epoch: 5| Step: 8
Training loss: 2.2994326928447677
Validation loss: 2.6089500530460508

Epoch: 5| Step: 9
Training loss: 2.885680222209078
Validation loss: 2.6352159074351835

Epoch: 5| Step: 10
Training loss: 2.394259314474418
Validation loss: 2.64632820147188

Epoch: 5| Step: 11
Training loss: 1.7058698601004119
Validation loss: 2.627355869434273

Epoch: 39| Step: 0
Training loss: 2.89928857693044
Validation loss: 2.623048280065581

Epoch: 5| Step: 1
Training loss: 2.46212826938996
Validation loss: 2.664077240426758

Epoch: 5| Step: 2
Training loss: 2.445377044313408
Validation loss: 2.717668336423123

Epoch: 5| Step: 3
Training loss: 2.52184517049815
Validation loss: 2.6752863219734953

Epoch: 5| Step: 4
Training loss: 2.5716196927691857
Validation loss: 2.6819864463601175

Epoch: 5| Step: 5
Training loss: 2.748744764821756
Validation loss: 2.672578191151601

Epoch: 5| Step: 6
Training loss: 2.003893519429896
Validation loss: 2.632020259482088

Epoch: 5| Step: 7
Training loss: 2.17608322705258
Validation loss: 2.6242733774710514

Epoch: 5| Step: 8
Training loss: 2.4099640360004697
Validation loss: 2.589032064660706

Epoch: 5| Step: 9
Training loss: 2.8031327127373946
Validation loss: 2.631381444902268

Epoch: 5| Step: 10
Training loss: 1.9645897642362753
Validation loss: 2.5970536759256704

Epoch: 5| Step: 11
Training loss: 1.2174616141407202
Validation loss: 2.632495204471955

Epoch: 40| Step: 0
Training loss: 1.9705253346965084
Validation loss: 2.637441932497017

Epoch: 5| Step: 1
Training loss: 2.526780975275732
Validation loss: 2.5843644096960134

Epoch: 5| Step: 2
Training loss: 2.599506470716391
Validation loss: 2.6407272311553855

Epoch: 5| Step: 3
Training loss: 2.4504036356797805
Validation loss: 2.599227892568454

Epoch: 5| Step: 4
Training loss: 2.391654098513164
Validation loss: 2.633217494615847

Epoch: 5| Step: 5
Training loss: 3.0423589641446696
Validation loss: 2.6082501566262315

Epoch: 5| Step: 6
Training loss: 1.839905043307913
Validation loss: 2.629434474876623

Epoch: 5| Step: 7
Training loss: 2.123202292781877
Validation loss: 2.6733967089592734

Epoch: 5| Step: 8
Training loss: 2.5732609959879507
Validation loss: 2.61063656414802

Epoch: 5| Step: 9
Training loss: 2.356245377837082
Validation loss: 2.6475718273437003

Epoch: 5| Step: 10
Training loss: 2.7897239776855316
Validation loss: 2.6623286051796757

Epoch: 5| Step: 11
Training loss: 1.5920570207764433
Validation loss: 2.6402046350560435

Epoch: 41| Step: 0
Training loss: 2.075399806100881
Validation loss: 2.6205387731283456

Epoch: 5| Step: 1
Training loss: 2.3670843624396345
Validation loss: 2.6392792615148553

Epoch: 5| Step: 2
Training loss: 2.2506165189617673
Validation loss: 2.6163266830214824

Epoch: 5| Step: 3
Training loss: 3.0493621847169194
Validation loss: 2.634715663020522

Epoch: 5| Step: 4
Training loss: 2.0451604053665813
Validation loss: 2.6095258475004983

Epoch: 5| Step: 5
Training loss: 2.3099665811936956
Validation loss: 2.6175691829229413

Epoch: 5| Step: 6
Training loss: 2.4384652207385416
Validation loss: 2.6282080355607866

Epoch: 5| Step: 7
Training loss: 1.9883277752722124
Validation loss: 2.592555073404803

Epoch: 5| Step: 8
Training loss: 2.2223972913869745
Validation loss: 2.6379983919224093

Epoch: 5| Step: 9
Training loss: 2.7397705033526547
Validation loss: 2.6326561154067725

Epoch: 5| Step: 10
Training loss: 2.3827243475945497
Validation loss: 2.6552348048159033

Epoch: 5| Step: 11
Training loss: 4.351414347511676
Validation loss: 2.5975721417341258

Epoch: 42| Step: 0
Training loss: 2.837181638091219
Validation loss: 2.656087526326499

Epoch: 5| Step: 1
Training loss: 2.1123788426433863
Validation loss: 2.663547149063772

Epoch: 5| Step: 2
Training loss: 2.3547649692278707
Validation loss: 2.743171232872103

Epoch: 5| Step: 3
Training loss: 2.461663323798091
Validation loss: 2.689289458333811

Epoch: 5| Step: 4
Training loss: 2.1508321837114615
Validation loss: 2.7247540726061175

Epoch: 5| Step: 5
Training loss: 2.2853194219254105
Validation loss: 2.7684938490258864

Epoch: 5| Step: 6
Training loss: 2.4796869923351323
Validation loss: 2.749906404665349

Epoch: 5| Step: 7
Training loss: 2.8709356355271782
Validation loss: 2.7493845294250465

Epoch: 5| Step: 8
Training loss: 2.336384401981408
Validation loss: 2.7041431339770154

Epoch: 5| Step: 9
Training loss: 2.2812248124077716
Validation loss: 2.656122155946374

Epoch: 5| Step: 10
Training loss: 2.5242640792002184
Validation loss: 2.6477420572735584

Epoch: 5| Step: 11
Training loss: 2.6560172483906763
Validation loss: 2.636345734760938

Epoch: 43| Step: 0
Training loss: 2.1516997382914345
Validation loss: 2.6305092434872073

Epoch: 5| Step: 1
Training loss: 2.505931969153812
Validation loss: 2.5900321611901655

Epoch: 5| Step: 2
Training loss: 2.0507857840351664
Validation loss: 2.660839248936982

Epoch: 5| Step: 3
Training loss: 2.7216562106540385
Validation loss: 2.645181257639082

Epoch: 5| Step: 4
Training loss: 2.327354662134277
Validation loss: 2.7124613053042013

Epoch: 5| Step: 5
Training loss: 2.5553223174080224
Validation loss: 2.6512777202163638

Epoch: 5| Step: 6
Training loss: 2.128975459382478
Validation loss: 2.6138333971342638

Epoch: 5| Step: 7
Training loss: 2.896510385819656
Validation loss: 2.618929481577037

Epoch: 5| Step: 8
Training loss: 2.4380252956802373
Validation loss: 2.6440613900690906

Epoch: 5| Step: 9
Training loss: 2.5216908743386166
Validation loss: 2.5792887036124155

Epoch: 5| Step: 10
Training loss: 2.5996099252793368
Validation loss: 2.6503321417004346

Epoch: 5| Step: 11
Training loss: 1.6586628019501493
Validation loss: 2.6651167661960344

Epoch: 44| Step: 0
Training loss: 2.2359052633098258
Validation loss: 2.617009486127421

Epoch: 5| Step: 1
Training loss: 2.3943589912423056
Validation loss: 2.693711163564648

Epoch: 5| Step: 2
Training loss: 2.121340124388318
Validation loss: 2.7293064661595903

Epoch: 5| Step: 3
Training loss: 3.238998131266541
Validation loss: 2.7269801901090913

Epoch: 5| Step: 4
Training loss: 1.5346893299350537
Validation loss: 2.692501655384477

Epoch: 5| Step: 5
Training loss: 2.1126342459915834
Validation loss: 2.712336722380479

Epoch: 5| Step: 6
Training loss: 3.0849986519339163
Validation loss: 2.6924980285587727

Epoch: 5| Step: 7
Training loss: 2.5177930883668016
Validation loss: 2.6641132912963266

Epoch: 5| Step: 8
Training loss: 2.2209761291553938
Validation loss: 2.6358204495849495

Epoch: 5| Step: 9
Training loss: 2.626193002538936
Validation loss: 2.6230061694310307

Epoch: 5| Step: 10
Training loss: 2.246240548022152
Validation loss: 2.6125559653291113

Epoch: 5| Step: 11
Training loss: 1.6899785101387637
Validation loss: 2.596857604968114

Epoch: 45| Step: 0
Training loss: 2.048669043402509
Validation loss: 2.6389661766468326

Epoch: 5| Step: 1
Training loss: 2.3743146610249672
Validation loss: 2.639861792248442

Epoch: 5| Step: 2
Training loss: 2.744738052877242
Validation loss: 2.6225032550790353

Epoch: 5| Step: 3
Training loss: 2.0973086504218394
Validation loss: 2.6089530649375425

Epoch: 5| Step: 4
Training loss: 2.605838869449048
Validation loss: 2.6500862001098655

Epoch: 5| Step: 5
Training loss: 2.0995416958568844
Validation loss: 2.6000845742530836

Epoch: 5| Step: 6
Training loss: 2.3801207300226688
Validation loss: 2.6076620346127997

Epoch: 5| Step: 7
Training loss: 2.4385755073538156
Validation loss: 2.5793959942939924

Epoch: 5| Step: 8
Training loss: 2.305640796122286
Validation loss: 2.615895235996732

Epoch: 5| Step: 9
Training loss: 2.7067569742342807
Validation loss: 2.5986354770047035

Epoch: 5| Step: 10
Training loss: 2.7021412023868625
Validation loss: 2.6503712094222913

Epoch: 5| Step: 11
Training loss: 1.6075870989849208
Validation loss: 2.578586972393828

Epoch: 46| Step: 0
Training loss: 2.2792627745547884
Validation loss: 2.6608951306138544

Epoch: 5| Step: 1
Training loss: 2.3366828673377493
Validation loss: 2.6292734820154067

Epoch: 5| Step: 2
Training loss: 1.9179851585665217
Validation loss: 2.6300307235929674

Epoch: 5| Step: 3
Training loss: 2.7241037207194942
Validation loss: 2.583832094026075

Epoch: 5| Step: 4
Training loss: 2.0336030682157213
Validation loss: 2.653974530817691

Epoch: 5| Step: 5
Training loss: 2.9019768586974513
Validation loss: 2.6227625590756904

Epoch: 5| Step: 6
Training loss: 2.5560716151739946
Validation loss: 2.644496894962625

Epoch: 5| Step: 7
Training loss: 2.5602300871328065
Validation loss: 2.6403468096461857

Epoch: 5| Step: 8
Training loss: 1.945526233865829
Validation loss: 2.6340786787984363

Epoch: 5| Step: 9
Training loss: 1.7949431275945287
Validation loss: 2.6021978463558613

Epoch: 5| Step: 10
Training loss: 2.7927684792161735
Validation loss: 2.623368997836331

Epoch: 5| Step: 11
Training loss: 2.777416630686037
Validation loss: 2.6536151159203856

Epoch: 47| Step: 0
Training loss: 2.7238208354336524
Validation loss: 2.631922747914833

Epoch: 5| Step: 1
Training loss: 1.9686963513043132
Validation loss: 2.6300400116696796

Epoch: 5| Step: 2
Training loss: 2.615587798917099
Validation loss: 2.655504930007889

Epoch: 5| Step: 3
Training loss: 1.945262801060206
Validation loss: 2.667268876285247

Epoch: 5| Step: 4
Training loss: 2.504655413502417
Validation loss: 2.647868910288054

Epoch: 5| Step: 5
Training loss: 1.8984577821503694
Validation loss: 2.7285768997641116

Epoch: 5| Step: 6
Training loss: 2.323690710270687
Validation loss: 2.672651336124218

Epoch: 5| Step: 7
Training loss: 2.620421822348183
Validation loss: 2.7181177902330727

Epoch: 5| Step: 8
Training loss: 2.4939962776970024
Validation loss: 2.61556839845609

Epoch: 5| Step: 9
Training loss: 2.1762166709034885
Validation loss: 2.6526200530268493

Epoch: 5| Step: 10
Training loss: 2.603365619799494
Validation loss: 2.640913334365305

Epoch: 5| Step: 11
Training loss: 1.8227484125871538
Validation loss: 2.655732972184187

Epoch: 48| Step: 0
Training loss: 1.5456086957775752
Validation loss: 2.5977485697697094

Epoch: 5| Step: 1
Training loss: 2.655263470725364
Validation loss: 2.6481593200666036

Epoch: 5| Step: 2
Training loss: 2.3484025679761245
Validation loss: 2.670282376295979

Epoch: 5| Step: 3
Training loss: 2.9625037084628687
Validation loss: 2.6528124163453817

Epoch: 5| Step: 4
Training loss: 2.6882644275869505
Validation loss: 2.649251780805103

Epoch: 5| Step: 5
Training loss: 2.624006537499076
Validation loss: 2.625580049944369

Epoch: 5| Step: 6
Training loss: 2.2233142381655453
Validation loss: 2.631889879644663

Epoch: 5| Step: 7
Training loss: 2.2335621882607444
Validation loss: 2.662144303180162

Epoch: 5| Step: 8
Training loss: 2.016301123011751
Validation loss: 2.643401234605706

Epoch: 5| Step: 9
Training loss: 2.5250886882654155
Validation loss: 2.6528464090552255

Epoch: 5| Step: 10
Training loss: 2.192566154986923
Validation loss: 2.6188234482800796

Epoch: 5| Step: 11
Training loss: 2.1326654963432996
Validation loss: 2.643618059285365

Epoch: 49| Step: 0
Training loss: 3.1138431515843017
Validation loss: 2.7447155369450043

Epoch: 5| Step: 1
Training loss: 2.2359215779140795
Validation loss: 2.6838776143552123

Epoch: 5| Step: 2
Training loss: 1.9695358524473012
Validation loss: 2.678077191668362

Epoch: 5| Step: 3
Training loss: 2.422849102395718
Validation loss: 2.6548696259758326

Epoch: 5| Step: 4
Training loss: 1.8809947502878235
Validation loss: 2.6902065620740503

Epoch: 5| Step: 5
Training loss: 2.788454988709708
Validation loss: 2.614819163949687

Epoch: 5| Step: 6
Training loss: 2.387618025014475
Validation loss: 2.6804425739258066

Epoch: 5| Step: 7
Training loss: 2.1146069104112666
Validation loss: 2.655404745514421

Epoch: 5| Step: 8
Training loss: 1.8158522550668723
Validation loss: 2.6124299225542114

Epoch: 5| Step: 9
Training loss: 2.5457998241294137
Validation loss: 2.6409318659119743

Epoch: 5| Step: 10
Training loss: 2.6612834138864465
Validation loss: 2.638973144530241

Epoch: 5| Step: 11
Training loss: 1.7285063834940098
Validation loss: 2.6635840611868926

Epoch: 50| Step: 0
Training loss: 2.017249347379841
Validation loss: 2.634457742938451

Epoch: 5| Step: 1
Training loss: 2.7433289328625206
Validation loss: 2.60682196222417

Epoch: 5| Step: 2
Training loss: 2.6637841579873243
Validation loss: 2.6262781271017634

Epoch: 5| Step: 3
Training loss: 2.6381294150316665
Validation loss: 2.601761463793588

Epoch: 5| Step: 4
Training loss: 1.7603036140693016
Validation loss: 2.601003279356238

Epoch: 5| Step: 5
Training loss: 2.2866574304281087
Validation loss: 2.624988620218709

Epoch: 5| Step: 6
Training loss: 2.1703290308411343
Validation loss: 2.6404223919249024

Epoch: 5| Step: 7
Training loss: 2.3321549528146686
Validation loss: 2.6222003925812576

Epoch: 5| Step: 8
Training loss: 2.7102340972971506
Validation loss: 2.6852889502385104

Epoch: 5| Step: 9
Training loss: 2.304538631480409
Validation loss: 2.631541925638354

Epoch: 5| Step: 10
Training loss: 2.2099802485830495
Validation loss: 2.6033795858500217

Epoch: 5| Step: 11
Training loss: 2.423155808940452
Validation loss: 2.6123037634161625

Epoch: 51| Step: 0
Training loss: 1.9250604545711447
Validation loss: 2.567846462153139

Epoch: 5| Step: 1
Training loss: 2.1061953845994226
Validation loss: 2.6426528126908098

Epoch: 5| Step: 2
Training loss: 2.393027102325291
Validation loss: 2.611092008245765

Epoch: 5| Step: 3
Training loss: 1.7916457670308752
Validation loss: 2.6173100381129655

Epoch: 5| Step: 4
Training loss: 2.051966384679281
Validation loss: 2.6511227058859848

Epoch: 5| Step: 5
Training loss: 2.3905892961615893
Validation loss: 2.633922987925082

Epoch: 5| Step: 6
Training loss: 3.16375926884168
Validation loss: 2.6892935955574058

Epoch: 5| Step: 7
Training loss: 2.2876978637503917
Validation loss: 2.705912084824666

Epoch: 5| Step: 8
Training loss: 2.029779929272949
Validation loss: 2.679376734294112

Epoch: 5| Step: 9
Training loss: 2.958737806867996
Validation loss: 2.67448041346941

Epoch: 5| Step: 10
Training loss: 2.5245644146473296
Validation loss: 2.733774638798248

Epoch: 5| Step: 11
Training loss: 2.791844196273472
Validation loss: 2.705988288100555

Epoch: 52| Step: 0
Training loss: 2.4129665813005254
Validation loss: 2.6211786422209324

Epoch: 5| Step: 1
Training loss: 2.49314149397345
Validation loss: 2.5978255979171903

Epoch: 5| Step: 2
Training loss: 2.1186197651584555
Validation loss: 2.6236847011842297

Epoch: 5| Step: 3
Training loss: 1.8642592192814886
Validation loss: 2.658809106029607

Epoch: 5| Step: 4
Training loss: 2.510345985610004
Validation loss: 2.6867468540074673

Epoch: 5| Step: 5
Training loss: 2.200390572990635
Validation loss: 2.698605038423414

Epoch: 5| Step: 6
Training loss: 2.818056424698921
Validation loss: 2.678054007706159

Epoch: 5| Step: 7
Training loss: 2.836700757094892
Validation loss: 2.644418891537071

Epoch: 5| Step: 8
Training loss: 2.0696332861003
Validation loss: 2.611636828081887

Epoch: 5| Step: 9
Training loss: 2.7556002553865775
Validation loss: 2.6039606979297933

Epoch: 5| Step: 10
Training loss: 2.042267950876846
Validation loss: 2.635418798925771

Epoch: 5| Step: 11
Training loss: 2.2208900339452193
Validation loss: 2.6763589945321646

Epoch: 53| Step: 0
Training loss: 2.4012935172590364
Validation loss: 2.7313220464892054

Epoch: 5| Step: 1
Training loss: 2.496723316536283
Validation loss: 2.7630523706206898

Epoch: 5| Step: 2
Training loss: 2.518045812570312
Validation loss: 2.739668918524995

Epoch: 5| Step: 3
Training loss: 2.5658842859498314
Validation loss: 2.7722876049938985

Epoch: 5| Step: 4
Training loss: 2.5638749690405263
Validation loss: 2.8064914877000313

Epoch: 5| Step: 5
Training loss: 2.8023823480471033
Validation loss: 2.819322829815607

Epoch: 5| Step: 6
Training loss: 2.393243888557877
Validation loss: 2.7337942542116545

Epoch: 5| Step: 7
Training loss: 2.0936873697051785
Validation loss: 2.7171896443313757

Epoch: 5| Step: 8
Training loss: 1.9783631818662653
Validation loss: 2.7304241811655805

Epoch: 5| Step: 9
Training loss: 2.0281384624863157
Validation loss: 2.677472903829575

Epoch: 5| Step: 10
Training loss: 1.9292466127159018
Validation loss: 2.604448262566461

Epoch: 5| Step: 11
Training loss: 2.6602582421825325
Validation loss: 2.584245268284347

Epoch: 54| Step: 0
Training loss: 2.1795401574653654
Validation loss: 2.5793163937589783

Epoch: 5| Step: 1
Training loss: 2.498134680092891
Validation loss: 2.6074433134152506

Epoch: 5| Step: 2
Training loss: 1.9953261838726037
Validation loss: 2.6021885505235276

Epoch: 5| Step: 3
Training loss: 1.8482150307516276
Validation loss: 2.6203815233499723

Epoch: 5| Step: 4
Training loss: 2.3204908719843935
Validation loss: 2.6450340961188856

Epoch: 5| Step: 5
Training loss: 2.452461687541198
Validation loss: 2.6330348976450724

Epoch: 5| Step: 6
Training loss: 2.0388840637473313
Validation loss: 2.5591503285348476

Epoch: 5| Step: 7
Training loss: 3.304500204780377
Validation loss: 2.645496156689593

Epoch: 5| Step: 8
Training loss: 2.5567972879808387
Validation loss: 2.5925719255299793

Epoch: 5| Step: 9
Training loss: 2.6414514636480355
Validation loss: 2.6869715976972035

Epoch: 5| Step: 10
Training loss: 2.224678286321556
Validation loss: 2.6051868780005853

Epoch: 5| Step: 11
Training loss: 1.1252904622961162
Validation loss: 2.6503912172103665

Epoch: 55| Step: 0
Training loss: 2.278403923635908
Validation loss: 2.631257070318948

Epoch: 5| Step: 1
Training loss: 1.689613361146687
Validation loss: 2.6482452540357966

Epoch: 5| Step: 2
Training loss: 3.2593333401673816
Validation loss: 2.702629477592584

Epoch: 5| Step: 3
Training loss: 2.2929490980511673
Validation loss: 2.736224593446414

Epoch: 5| Step: 4
Training loss: 2.4623985192161206
Validation loss: 2.7140779178923022

Epoch: 5| Step: 5
Training loss: 2.67360466189797
Validation loss: 2.7104011430132093

Epoch: 5| Step: 6
Training loss: 2.1316981496069274
Validation loss: 2.6696868584687286

Epoch: 5| Step: 7
Training loss: 2.157046958592577
Validation loss: 2.664575167611867

Epoch: 5| Step: 8
Training loss: 2.238691735033941
Validation loss: 2.6141215723404656

Epoch: 5| Step: 9
Training loss: 2.454156549386466
Validation loss: 2.6372023000134996

Epoch: 5| Step: 10
Training loss: 2.113567678392684
Validation loss: 2.622470424062277

Epoch: 5| Step: 11
Training loss: 3.2125039839070477
Validation loss: 2.60079023757471

Epoch: 56| Step: 0
Training loss: 2.3258308525805726
Validation loss: 2.592723091628076

Epoch: 5| Step: 1
Training loss: 2.046433379311003
Validation loss: 2.595629057390774

Epoch: 5| Step: 2
Training loss: 2.972877925271964
Validation loss: 2.6196835585952116

Epoch: 5| Step: 3
Training loss: 2.2710015004269386
Validation loss: 2.605682932349293

Epoch: 5| Step: 4
Training loss: 2.265576066113525
Validation loss: 2.6392046439732035

Epoch: 5| Step: 5
Training loss: 1.7784553824279616
Validation loss: 2.601601062905068

Epoch: 5| Step: 6
Training loss: 2.381842043510265
Validation loss: 2.636387534354605

Epoch: 5| Step: 7
Training loss: 2.628407310536513
Validation loss: 2.599920676928704

Epoch: 5| Step: 8
Training loss: 2.3344180673816486
Validation loss: 2.559848638793497

Epoch: 5| Step: 9
Training loss: 2.7613865330150356
Validation loss: 2.5966747255673632

Epoch: 5| Step: 10
Training loss: 1.920138248890346
Validation loss: 2.631949599341246

Epoch: 5| Step: 11
Training loss: 3.139191409436214
Validation loss: 2.63032055354161

Epoch: 57| Step: 0
Training loss: 2.481650532024633
Validation loss: 2.657976714990443

Epoch: 5| Step: 1
Training loss: 2.6204312847512385
Validation loss: 2.6238256317682627

Epoch: 5| Step: 2
Training loss: 2.638344858095787
Validation loss: 2.647632303933502

Epoch: 5| Step: 3
Training loss: 2.4589302717563717
Validation loss: 2.6272862711205645

Epoch: 5| Step: 4
Training loss: 2.1820970568378035
Validation loss: 2.5731255115789278

Epoch: 5| Step: 5
Training loss: 1.6986463262207503
Validation loss: 2.602610341730758

Epoch: 5| Step: 6
Training loss: 2.18064678781503
Validation loss: 2.648301000087627

Epoch: 5| Step: 7
Training loss: 2.2729905990292054
Validation loss: 2.606587933587497

Epoch: 5| Step: 8
Training loss: 2.4580353594006668
Validation loss: 2.5894522200762324

Epoch: 5| Step: 9
Training loss: 2.361579622895891
Validation loss: 2.587117512700847

Epoch: 5| Step: 10
Training loss: 2.5768640382225008
Validation loss: 2.588735390263814

Epoch: 5| Step: 11
Training loss: 1.3560558004263445
Validation loss: 2.613052631864195

Epoch: 58| Step: 0
Training loss: 1.7548943605717005
Validation loss: 2.6062291001931084

Epoch: 5| Step: 1
Training loss: 1.865756328311857
Validation loss: 2.6207075597263367

Epoch: 5| Step: 2
Training loss: 2.1284564461744853
Validation loss: 2.5878137579484406

Epoch: 5| Step: 3
Training loss: 2.5706306422955607
Validation loss: 2.6517962610280583

Epoch: 5| Step: 4
Training loss: 3.2239798122464958
Validation loss: 2.6869014213856017

Epoch: 5| Step: 5
Training loss: 2.452066667014509
Validation loss: 2.6675244450573765

Epoch: 5| Step: 6
Training loss: 2.52277452954169
Validation loss: 2.6801180850413147

Epoch: 5| Step: 7
Training loss: 2.033335627361734
Validation loss: 2.660606760648471

Epoch: 5| Step: 8
Training loss: 1.9300395320144481
Validation loss: 2.7135289802669615

Epoch: 5| Step: 9
Training loss: 2.121349677563388
Validation loss: 2.6970074728281257

Epoch: 5| Step: 10
Training loss: 2.541860218703901
Validation loss: 2.624739036001113

Epoch: 5| Step: 11
Training loss: 1.0949737242590012
Validation loss: 2.5410104918177616

Epoch: 59| Step: 0
Training loss: 2.3708995758438554
Validation loss: 2.6072704942742537

Epoch: 5| Step: 1
Training loss: 1.6905257331629364
Validation loss: 2.660359240912621

Epoch: 5| Step: 2
Training loss: 2.658086343928614
Validation loss: 2.586000858541043

Epoch: 5| Step: 3
Training loss: 1.9042385933589367
Validation loss: 2.6154405371590683

Epoch: 5| Step: 4
Training loss: 2.6605170589216276
Validation loss: 2.672377046558575

Epoch: 5| Step: 5
Training loss: 2.3074447431798597
Validation loss: 2.7243518557246946

Epoch: 5| Step: 6
Training loss: 2.338473471232714
Validation loss: 2.6375203136366916

Epoch: 5| Step: 7
Training loss: 2.3840204897774497
Validation loss: 2.5930831005860773

Epoch: 5| Step: 8
Training loss: 2.5979193762117854
Validation loss: 2.5944314812087446

Epoch: 5| Step: 9
Training loss: 2.9109758899755667
Validation loss: 2.636689309791758

Epoch: 5| Step: 10
Training loss: 2.444854986028816
Validation loss: 2.6353003277688445

Epoch: 5| Step: 11
Training loss: 1.8363954662771393
Validation loss: 2.726998743319481

Epoch: 60| Step: 0
Training loss: 3.012158867606616
Validation loss: 2.817846870659772

Epoch: 5| Step: 1
Training loss: 2.4401890520430367
Validation loss: 2.7907037046809986

Epoch: 5| Step: 2
Training loss: 2.9450162136492946
Validation loss: 2.84882202496493

Epoch: 5| Step: 3
Training loss: 2.194215982619156
Validation loss: 2.7609509304938284

Epoch: 5| Step: 4
Training loss: 1.5224709599172996
Validation loss: 2.7182773274203735

Epoch: 5| Step: 5
Training loss: 2.499868961714719
Validation loss: 2.706353191173279

Epoch: 5| Step: 6
Training loss: 1.7765417951653946
Validation loss: 2.7035316021829336

Epoch: 5| Step: 7
Training loss: 2.5834456593693917
Validation loss: 2.7022638768448495

Epoch: 5| Step: 8
Training loss: 2.057341163780225
Validation loss: 2.6002917923782993

Epoch: 5| Step: 9
Training loss: 2.1077434870660348
Validation loss: 2.5964799325697525

Epoch: 5| Step: 10
Training loss: 2.4968358997630298
Validation loss: 2.616524535518431

Epoch: 5| Step: 11
Training loss: 2.4438020471362156
Validation loss: 2.6201726106878316

Epoch: 61| Step: 0
Training loss: 2.0864848015398736
Validation loss: 2.577305453500548

Epoch: 5| Step: 1
Training loss: 2.2706503021485314
Validation loss: 2.5629330129654604

Epoch: 5| Step: 2
Training loss: 2.0239118218947127
Validation loss: 2.6055389158455933

Epoch: 5| Step: 3
Training loss: 2.261933153495334
Validation loss: 2.5614466634461

Epoch: 5| Step: 4
Training loss: 2.144566603405656
Validation loss: 2.5675141194669426

Epoch: 5| Step: 5
Training loss: 3.0591197140162096
Validation loss: 2.597064814724673

Epoch: 5| Step: 6
Training loss: 2.4228432965397086
Validation loss: 2.642409566205799

Epoch: 5| Step: 7
Training loss: 2.51719521746882
Validation loss: 2.6600976901113653

Epoch: 5| Step: 8
Training loss: 1.985112871569086
Validation loss: 2.609562899435279

Epoch: 5| Step: 9
Training loss: 1.8554139460450838
Validation loss: 2.6473540956783275

Epoch: 5| Step: 10
Training loss: 2.4029970846868856
Validation loss: 2.610693615538398

Epoch: 5| Step: 11
Training loss: 1.8447479521448855
Validation loss: 2.6377385821012944

Epoch: 62| Step: 0
Training loss: 1.7653366123415832
Validation loss: 2.65199587623569

Epoch: 5| Step: 1
Training loss: 2.5843665200109327
Validation loss: 2.621789960122412

Epoch: 5| Step: 2
Training loss: 1.9522131660573183
Validation loss: 2.67361275637082

Epoch: 5| Step: 3
Training loss: 2.3048130841711023
Validation loss: 2.6098649370207854

Epoch: 5| Step: 4
Training loss: 2.3173565772653695
Validation loss: 2.645691324663245

Epoch: 5| Step: 5
Training loss: 2.2740031059867967
Validation loss: 2.6662549853438495

Epoch: 5| Step: 6
Training loss: 2.3854635531108443
Validation loss: 2.7154006789269807

Epoch: 5| Step: 7
Training loss: 2.541350381485129
Validation loss: 2.722971912038604

Epoch: 5| Step: 8
Training loss: 2.6513746510887124
Validation loss: 2.708850496995334

Epoch: 5| Step: 9
Training loss: 2.2832100168977463
Validation loss: 2.6576990961919686

Epoch: 5| Step: 10
Training loss: 2.1036081107801983
Validation loss: 2.5778605161694452

Epoch: 5| Step: 11
Training loss: 2.3609798606844095
Validation loss: 2.6286548080477568

Epoch: 63| Step: 0
Training loss: 2.4261785848288615
Validation loss: 2.6238646928333607

Epoch: 5| Step: 1
Training loss: 2.361768001606912
Validation loss: 2.629982582954444

Epoch: 5| Step: 2
Training loss: 2.353782746284228
Validation loss: 2.5477646598066

Epoch: 5| Step: 3
Training loss: 2.0236385054149726
Validation loss: 2.650822071406084

Epoch: 5| Step: 4
Training loss: 2.7616287929015213
Validation loss: 2.654390252505676

Epoch: 5| Step: 5
Training loss: 2.3397562204843405
Validation loss: 2.622845620932077

Epoch: 5| Step: 6
Training loss: 1.7206902389823255
Validation loss: 2.6222034271378445

Epoch: 5| Step: 7
Training loss: 2.3699502968706856
Validation loss: 2.6333539917191877

Epoch: 5| Step: 8
Training loss: 1.9040010036578057
Validation loss: 2.6222841086859217

Epoch: 5| Step: 9
Training loss: 2.6445084406039503
Validation loss: 2.6517902221782044

Epoch: 5| Step: 10
Training loss: 2.390398401229712
Validation loss: 2.657552388608779

Epoch: 5| Step: 11
Training loss: 2.1842115480230695
Validation loss: 2.6296006391402393

Epoch: 64| Step: 0
Training loss: 2.1210224849187154
Validation loss: 2.737144785817529

Epoch: 5| Step: 1
Training loss: 2.570988621238832
Validation loss: 2.7340123217613628

Epoch: 5| Step: 2
Training loss: 2.6074514094476653
Validation loss: 2.7781668193231317

Epoch: 5| Step: 3
Training loss: 2.6336764494371407
Validation loss: 2.7819481091393987

Epoch: 5| Step: 4
Training loss: 1.7672970037152274
Validation loss: 2.756454234150575

Epoch: 5| Step: 5
Training loss: 2.444850890248589
Validation loss: 2.738594828094858

Epoch: 5| Step: 6
Training loss: 2.356249324080069
Validation loss: 2.6609028400128296

Epoch: 5| Step: 7
Training loss: 2.368370440427515
Validation loss: 2.652975730905534

Epoch: 5| Step: 8
Training loss: 1.7911000871450542
Validation loss: 2.6679817337159575

Epoch: 5| Step: 9
Training loss: 1.7852456635968843
Validation loss: 2.675716642541851

Epoch: 5| Step: 10
Training loss: 2.2289848134621777
Validation loss: 2.6633905997244742

Epoch: 5| Step: 11
Training loss: 2.526632736635826
Validation loss: 2.6482338278445994

Epoch: 65| Step: 0
Training loss: 2.2006879814515554
Validation loss: 2.6543348813511325

Epoch: 5| Step: 1
Training loss: 1.8395165154435553
Validation loss: 2.6555076160076285

Epoch: 5| Step: 2
Training loss: 2.5065374727976963
Validation loss: 2.5996232809816893

Epoch: 5| Step: 3
Training loss: 2.6233384459598006
Validation loss: 2.6546118565515258

Epoch: 5| Step: 4
Training loss: 2.2291522040447593
Validation loss: 2.614645878675696

Epoch: 5| Step: 5
Training loss: 2.3061620101063824
Validation loss: 2.613340243142669

Epoch: 5| Step: 6
Training loss: 1.6939003684099503
Validation loss: 2.612338414434976

Epoch: 5| Step: 7
Training loss: 2.7258792228727247
Validation loss: 2.6182652204550676

Epoch: 5| Step: 8
Training loss: 2.084315894803044
Validation loss: 2.5569483001429423

Epoch: 5| Step: 9
Training loss: 2.1571340545395294
Validation loss: 2.5934697616426923

Epoch: 5| Step: 10
Training loss: 2.3225834583279106
Validation loss: 2.635485717311122

Epoch: 5| Step: 11
Training loss: 2.1344343453642254
Validation loss: 2.709647594585241

Epoch: 66| Step: 0
Training loss: 2.2340217791309347
Validation loss: 2.7152758028121315

Epoch: 5| Step: 1
Training loss: 1.0886926622325845
Validation loss: 2.750617319235161

Epoch: 5| Step: 2
Training loss: 2.306206774629589
Validation loss: 2.8318671062738043

Epoch: 5| Step: 3
Training loss: 2.746511848061641
Validation loss: 2.843905629800564

Epoch: 5| Step: 4
Training loss: 1.9009700256504916
Validation loss: 2.7792184460766807

Epoch: 5| Step: 5
Training loss: 3.127293164970763
Validation loss: 2.799933765967679

Epoch: 5| Step: 6
Training loss: 1.6837934831358352
Validation loss: 2.737807094500568

Epoch: 5| Step: 7
Training loss: 2.6826029674040655
Validation loss: 2.64993279554814

Epoch: 5| Step: 8
Training loss: 2.0413959349624586
Validation loss: 2.6830896147426473

Epoch: 5| Step: 9
Training loss: 2.4423757840512628
Validation loss: 2.635720813424754

Epoch: 5| Step: 10
Training loss: 2.479376412716524
Validation loss: 2.623955337100699

Epoch: 5| Step: 11
Training loss: 2.9267600934258713
Validation loss: 2.5959528680183244

Epoch: 67| Step: 0
Training loss: 1.8971332732437023
Validation loss: 2.6743068113323805

Epoch: 5| Step: 1
Training loss: 2.497859610785376
Validation loss: 2.583018261912987

Epoch: 5| Step: 2
Training loss: 2.1586956584123187
Validation loss: 2.662779311631495

Epoch: 5| Step: 3
Training loss: 2.738926353052204
Validation loss: 2.657149723488349

Epoch: 5| Step: 4
Training loss: 2.349295806889597
Validation loss: 2.6282165552219494

Epoch: 5| Step: 5
Training loss: 1.9359103418743655
Validation loss: 2.626794417454762

Epoch: 5| Step: 6
Training loss: 1.8301560946112494
Validation loss: 2.6297785618731107

Epoch: 5| Step: 7
Training loss: 2.3785342973341734
Validation loss: 2.6907198196226534

Epoch: 5| Step: 8
Training loss: 2.088219012850396
Validation loss: 2.6690841882471616

Epoch: 5| Step: 9
Training loss: 2.619670999123027
Validation loss: 2.684336724635706

Epoch: 5| Step: 10
Training loss: 2.4300609436556053
Validation loss: 2.702020901086433

Epoch: 5| Step: 11
Training loss: 1.6353665321910547
Validation loss: 2.7109928363645364

Epoch: 68| Step: 0
Training loss: 2.2392531277207866
Validation loss: 2.7007597716719483

Epoch: 5| Step: 1
Training loss: 2.4844979309761275
Validation loss: 2.6928914608592978

Epoch: 5| Step: 2
Training loss: 2.33351494445658
Validation loss: 2.688720662482927

Epoch: 5| Step: 3
Training loss: 2.3880556548452607
Validation loss: 2.7478703864892573

Epoch: 5| Step: 4
Training loss: 2.2528098892617994
Validation loss: 2.685679761893337

Epoch: 5| Step: 5
Training loss: 1.7747361725858144
Validation loss: 2.680759393494305

Epoch: 5| Step: 6
Training loss: 2.386481090644172
Validation loss: 2.6630805807848965

Epoch: 5| Step: 7
Training loss: 2.4209416713754988
Validation loss: 2.6156493264437763

Epoch: 5| Step: 8
Training loss: 2.469789117312768
Validation loss: 2.6484974954687

Epoch: 5| Step: 9
Training loss: 1.6397601800117816
Validation loss: 2.6628338767118374

Epoch: 5| Step: 10
Training loss: 2.0330659231895725
Validation loss: 2.6111330136830193

Epoch: 5| Step: 11
Training loss: 3.5012286618177315
Validation loss: 2.628734445082977

Epoch: 69| Step: 0
Training loss: 1.6971538054721826
Validation loss: 2.646752000253009

Epoch: 5| Step: 1
Training loss: 2.6337196304170813
Validation loss: 2.681625236509679

Epoch: 5| Step: 2
Training loss: 2.655644156983252
Validation loss: 2.6073862671057824

Epoch: 5| Step: 3
Training loss: 1.8484052305395617
Validation loss: 2.6569430213882756

Epoch: 5| Step: 4
Training loss: 1.7476216912636289
Validation loss: 2.6127479894867154

Epoch: 5| Step: 5
Training loss: 1.6533508117710705
Validation loss: 2.580877718738316

Epoch: 5| Step: 6
Training loss: 2.856160509306057
Validation loss: 2.6264218309545373

Epoch: 5| Step: 7
Training loss: 2.254860396705386
Validation loss: 2.55229884165448

Epoch: 5| Step: 8
Training loss: 2.4026465248416673
Validation loss: 2.664112392640736

Epoch: 5| Step: 9
Training loss: 2.4202040291522136
Validation loss: 2.6453272205295457

Epoch: 5| Step: 10
Training loss: 1.8999484607331807
Validation loss: 2.6505396629339795

Epoch: 5| Step: 11
Training loss: 2.3771392824596735
Validation loss: 2.6043787653698764

Epoch: 70| Step: 0
Training loss: 2.5169577533387972
Validation loss: 2.6633444981008783

Epoch: 5| Step: 1
Training loss: 2.4577259240056235
Validation loss: 2.625568343503725

Epoch: 5| Step: 2
Training loss: 2.1694137568900924
Validation loss: 2.645143341346021

Epoch: 5| Step: 3
Training loss: 2.542924684298024
Validation loss: 2.6563355806065316

Epoch: 5| Step: 4
Training loss: 2.252705854351439
Validation loss: 2.671155557570985

Epoch: 5| Step: 5
Training loss: 2.2660066480480157
Validation loss: 2.633013686465091

Epoch: 5| Step: 6
Training loss: 1.4653937769448828
Validation loss: 2.652228666120678

Epoch: 5| Step: 7
Training loss: 1.9959557890572972
Validation loss: 2.6324119489567286

Epoch: 5| Step: 8
Training loss: 2.0392543658609292
Validation loss: 2.630644300732449

Epoch: 5| Step: 9
Training loss: 2.008382634656539
Validation loss: 2.6269282834983185

Epoch: 5| Step: 10
Training loss: 2.6333968875153047
Validation loss: 2.608625437576516

Epoch: 5| Step: 11
Training loss: 2.2323719996957574
Validation loss: 2.7319077395936473

Epoch: 71| Step: 0
Training loss: 2.2653669539200676
Validation loss: 2.6882453853243913

Epoch: 5| Step: 1
Training loss: 2.0066224367499266
Validation loss: 2.6041280908906375

Epoch: 5| Step: 2
Training loss: 2.2621245604874733
Validation loss: 2.618528111934874

Epoch: 5| Step: 3
Training loss: 2.382320165581841
Validation loss: 2.6145483650412267

Epoch: 5| Step: 4
Training loss: 2.087813316177188
Validation loss: 2.558670368940164

Epoch: 5| Step: 5
Training loss: 2.7834439143373224
Validation loss: 2.648555126597576

Epoch: 5| Step: 6
Training loss: 1.8690100039259796
Validation loss: 2.6451053550298016

Epoch: 5| Step: 7
Training loss: 1.9152025214294177
Validation loss: 2.6113887904407163

Epoch: 5| Step: 8
Training loss: 2.583885738828639
Validation loss: 2.6261668506933424

Epoch: 5| Step: 9
Training loss: 1.7636980327301293
Validation loss: 2.668119855393095

Epoch: 5| Step: 10
Training loss: 2.2799222034432804
Validation loss: 2.622647540763884

Epoch: 5| Step: 11
Training loss: 2.3820233148159278
Validation loss: 2.6798330699355004

Epoch: 72| Step: 0
Training loss: 2.512175665271271
Validation loss: 2.711569738914385

Epoch: 5| Step: 1
Training loss: 1.823417667388932
Validation loss: 2.653063399787083

Epoch: 5| Step: 2
Training loss: 2.63573422736386
Validation loss: 2.688527265764106

Epoch: 5| Step: 3
Training loss: 2.238685345080855
Validation loss: 2.6579870378617367

Epoch: 5| Step: 4
Training loss: 2.0101433075637565
Validation loss: 2.73069856083145

Epoch: 5| Step: 5
Training loss: 2.238039546252389
Validation loss: 2.644758630741306

Epoch: 5| Step: 6
Training loss: 2.4624242741903406
Validation loss: 2.722569311460599

Epoch: 5| Step: 7
Training loss: 2.142666587985468
Validation loss: 2.6562644733707823

Epoch: 5| Step: 8
Training loss: 1.838453346558937
Validation loss: 2.667456161087545

Epoch: 5| Step: 9
Training loss: 2.2270203236824595
Validation loss: 2.6726651018076586

Epoch: 5| Step: 10
Training loss: 2.226996556855355
Validation loss: 2.7064329938563927

Epoch: 5| Step: 11
Training loss: 1.9403278878956969
Validation loss: 2.632249373858678

Epoch: 73| Step: 0
Training loss: 1.8543875344845688
Validation loss: 2.6223577908910545

Epoch: 5| Step: 1
Training loss: 2.1129989576504147
Validation loss: 2.5990231314145062

Epoch: 5| Step: 2
Training loss: 1.6832136180848958
Validation loss: 2.664861963709941

Epoch: 5| Step: 3
Training loss: 2.49863453768603
Validation loss: 2.609529361232705

Epoch: 5| Step: 4
Training loss: 2.6946406757259593
Validation loss: 2.570884181086021

Epoch: 5| Step: 5
Training loss: 2.1253984863046123
Validation loss: 2.618012517451093

Epoch: 5| Step: 6
Training loss: 2.692166734505758
Validation loss: 2.611938698107433

Epoch: 5| Step: 7
Training loss: 2.0654804773601607
Validation loss: 2.6928046828444945

Epoch: 5| Step: 8
Training loss: 2.4611495638106913
Validation loss: 2.61726885996513

Epoch: 5| Step: 9
Training loss: 1.9632941443326877
Validation loss: 2.5869613303290344

Epoch: 5| Step: 10
Training loss: 2.1923411613874833
Validation loss: 2.6799289123812255

Epoch: 5| Step: 11
Training loss: 1.2956367924213856
Validation loss: 2.58854405053155

Epoch: 74| Step: 0
Training loss: 2.0255269342240525
Validation loss: 2.6170061646455567

Epoch: 5| Step: 1
Training loss: 1.9903907602130981
Validation loss: 2.703497583514371

Epoch: 5| Step: 2
Training loss: 2.642418337077106
Validation loss: 2.6576936762892682

Epoch: 5| Step: 3
Training loss: 2.0751912913563983
Validation loss: 2.6666820135767715

Epoch: 5| Step: 4
Training loss: 2.5832732614075167
Validation loss: 2.6400386791394066

Epoch: 5| Step: 5
Training loss: 2.6582681506385812
Validation loss: 2.632502446090465

Epoch: 5| Step: 6
Training loss: 1.7363371189086174
Validation loss: 2.599940897196472

Epoch: 5| Step: 7
Training loss: 1.8073269257051376
Validation loss: 2.6885586546033933

Epoch: 5| Step: 8
Training loss: 2.5503989337698743
Validation loss: 2.6544662657322453

Epoch: 5| Step: 9
Training loss: 1.8251343089808738
Validation loss: 2.6144910368010366

Epoch: 5| Step: 10
Training loss: 1.714892410595905
Validation loss: 2.62858079593371

Epoch: 5| Step: 11
Training loss: 1.7488890254919915
Validation loss: 2.6419280183632847

Epoch: 75| Step: 0
Training loss: 2.130565199926178
Validation loss: 2.6593715838041674

Epoch: 5| Step: 1
Training loss: 2.2309282300579905
Validation loss: 2.67173351411447

Epoch: 5| Step: 2
Training loss: 1.6869057916047818
Validation loss: 2.699253691149474

Epoch: 5| Step: 3
Training loss: 2.0400308816105714
Validation loss: 2.7265342230000003

Epoch: 5| Step: 4
Training loss: 2.209127055584917
Validation loss: 2.7161884334999176

Epoch: 5| Step: 5
Training loss: 1.9340249553715376
Validation loss: 2.7007928206718517

Epoch: 5| Step: 6
Training loss: 2.127379711798387
Validation loss: 2.6078735798485684

Epoch: 5| Step: 7
Training loss: 2.4357248346797875
Validation loss: 2.6685928500955125

Epoch: 5| Step: 8
Training loss: 2.4405028602037824
Validation loss: 2.7229666694850163

Epoch: 5| Step: 9
Training loss: 2.219759966443279
Validation loss: 2.713154588842779

Epoch: 5| Step: 10
Training loss: 2.2336176942687374
Validation loss: 2.6883376945106274

Epoch: 5| Step: 11
Training loss: 3.1781319977299742
Validation loss: 2.6270505071692125

Epoch: 76| Step: 0
Training loss: 1.6632912867983707
Validation loss: 2.5926528126734003

Epoch: 5| Step: 1
Training loss: 2.1983720087790317
Validation loss: 2.6367680975923258

Epoch: 5| Step: 2
Training loss: 2.372561357225315
Validation loss: 2.5700555535755365

Epoch: 5| Step: 3
Training loss: 2.643167208742493
Validation loss: 2.6427951450145684

Epoch: 5| Step: 4
Training loss: 2.6987076315440692
Validation loss: 2.6309458551539637

Epoch: 5| Step: 5
Training loss: 2.3723160485684986
Validation loss: 2.645966681676951

Epoch: 5| Step: 6
Training loss: 2.214878734601621
Validation loss: 2.6183660785692244

Epoch: 5| Step: 7
Training loss: 1.7531699353339405
Validation loss: 2.651382470599129

Epoch: 5| Step: 8
Training loss: 1.9610219990431523
Validation loss: 2.6362175585223446

Epoch: 5| Step: 9
Training loss: 2.0093875154903413
Validation loss: 2.6072601230088424

Epoch: 5| Step: 10
Training loss: 1.7075039625889834
Validation loss: 2.6749411644808267

Epoch: 5| Step: 11
Training loss: 1.6798380939486708
Validation loss: 2.666231687405092

Epoch: 77| Step: 0
Training loss: 1.8579089371505528
Validation loss: 2.6055752009464768

Epoch: 5| Step: 1
Training loss: 2.070461167089953
Validation loss: 2.647208556018426

Epoch: 5| Step: 2
Training loss: 2.312076839186521
Validation loss: 2.654602111826229

Epoch: 5| Step: 3
Training loss: 2.0076842508286483
Validation loss: 2.6638939767823633

Epoch: 5| Step: 4
Training loss: 2.8326336239762218
Validation loss: 2.68864435036536

Epoch: 5| Step: 5
Training loss: 1.4612793547958876
Validation loss: 2.605904568925638

Epoch: 5| Step: 6
Training loss: 2.0845230393118994
Validation loss: 2.586285582104515

Epoch: 5| Step: 7
Training loss: 2.210366974133335
Validation loss: 2.6186585690326374

Epoch: 5| Step: 8
Training loss: 2.7209020406354005
Validation loss: 2.642476074473742

Epoch: 5| Step: 9
Training loss: 1.8890067496959158
Validation loss: 2.6352968653613145

Epoch: 5| Step: 10
Training loss: 2.1896408504211387
Validation loss: 2.705005179292723

Epoch: 5| Step: 11
Training loss: 2.08925567623991
Validation loss: 2.620743013158857

Epoch: 78| Step: 0
Training loss: 2.164964838953799
Validation loss: 2.686915175066658

Epoch: 5| Step: 1
Training loss: 2.600819891255542
Validation loss: 2.72441651676939

Epoch: 5| Step: 2
Training loss: 2.146281988653144
Validation loss: 2.72110776135538

Epoch: 5| Step: 3
Training loss: 2.8813914696640297
Validation loss: 2.786034219617244

Epoch: 5| Step: 4
Training loss: 2.1472355480145224
Validation loss: 2.7290514322272896

Epoch: 5| Step: 5
Training loss: 1.9919682400787473
Validation loss: 2.742995053575084

Epoch: 5| Step: 6
Training loss: 2.4342819881666538
Validation loss: 2.6760614215977454

Epoch: 5| Step: 7
Training loss: 1.7198479353419804
Validation loss: 2.6703909941108006

Epoch: 5| Step: 8
Training loss: 1.831544661006283
Validation loss: 2.7156357833390676

Epoch: 5| Step: 9
Training loss: 1.9932268610345287
Validation loss: 2.629698933791661

Epoch: 5| Step: 10
Training loss: 2.2403505888829987
Validation loss: 2.5961542055703952

Epoch: 5| Step: 11
Training loss: 1.277272447001668
Validation loss: 2.6590008684288176

Epoch: 79| Step: 0
Training loss: 1.9411875181342741
Validation loss: 2.6648878607020383

Epoch: 5| Step: 1
Training loss: 2.1468401155039154
Validation loss: 2.5863634432899096

Epoch: 5| Step: 2
Training loss: 2.57025294829141
Validation loss: 2.665984227853792

Epoch: 5| Step: 3
Training loss: 2.4155796061565016
Validation loss: 2.566753810996777

Epoch: 5| Step: 4
Training loss: 1.928962849450592
Validation loss: 2.632332638289716

Epoch: 5| Step: 5
Training loss: 2.171154204491564
Validation loss: 2.7045102401288466

Epoch: 5| Step: 6
Training loss: 2.216364370494308
Validation loss: 2.6880528228892344

Epoch: 5| Step: 7
Training loss: 2.0364336043187325
Validation loss: 2.7442045048239314

Epoch: 5| Step: 8
Training loss: 2.1622199742700947
Validation loss: 2.794099983237249

Epoch: 5| Step: 9
Training loss: 2.4893309865667024
Validation loss: 2.7543063150475935

Epoch: 5| Step: 10
Training loss: 2.2303653833384742
Validation loss: 2.8595306374972504

Epoch: 5| Step: 11
Training loss: 3.141950944203109
Validation loss: 2.678533325908257

Epoch: 80| Step: 0
Training loss: 2.5424569782529436
Validation loss: 2.651967512140315

Epoch: 5| Step: 1
Training loss: 1.9515761681132278
Validation loss: 2.6186245099926913

Epoch: 5| Step: 2
Training loss: 2.1978349956748096
Validation loss: 2.6156934525629887

Epoch: 5| Step: 3
Training loss: 2.203104654853976
Validation loss: 2.637523044316772

Epoch: 5| Step: 4
Training loss: 2.2277082741037924
Validation loss: 2.747945867262316

Epoch: 5| Step: 5
Training loss: 2.2941124320510347
Validation loss: 2.6563735372201744

Epoch: 5| Step: 6
Training loss: 2.3326369222703556
Validation loss: 2.653209853865385

Epoch: 5| Step: 7
Training loss: 2.1502071236490368
Validation loss: 2.5429811960785935

Epoch: 5| Step: 8
Training loss: 1.8481862636676967
Validation loss: 2.577924439306664

Epoch: 5| Step: 9
Training loss: 1.7500940025150535
Validation loss: 2.6011527104341767

Epoch: 5| Step: 10
Training loss: 2.354153140769069
Validation loss: 2.695624734235963

Epoch: 5| Step: 11
Training loss: 2.222287541330176
Validation loss: 2.765129687968163

Epoch: 81| Step: 0
Training loss: 2.380362029229536
Validation loss: 2.767964496083499

Epoch: 5| Step: 1
Training loss: 2.1237182117258784
Validation loss: 2.803370397621718

Epoch: 5| Step: 2
Training loss: 2.152321041700478
Validation loss: 2.871108735406568

Epoch: 5| Step: 3
Training loss: 2.5665055579447285
Validation loss: 2.8333162992096264

Epoch: 5| Step: 4
Training loss: 1.8130851327273205
Validation loss: 2.8655075050541496

Epoch: 5| Step: 5
Training loss: 2.8699513764200146
Validation loss: 2.7819681954783793

Epoch: 5| Step: 6
Training loss: 1.5769752619949273
Validation loss: 2.727755448639951

Epoch: 5| Step: 7
Training loss: 1.9952313077295059
Validation loss: 2.6539227743891143

Epoch: 5| Step: 8
Training loss: 2.1956061441734107
Validation loss: 2.6257416078722198

Epoch: 5| Step: 9
Training loss: 1.9490908655326107
Validation loss: 2.588517249674677

Epoch: 5| Step: 10
Training loss: 2.482105105858888
Validation loss: 2.617960167694975

Epoch: 5| Step: 11
Training loss: 1.731849068234485
Validation loss: 2.626792004641856

Epoch: 82| Step: 0
Training loss: 1.9446021318831426
Validation loss: 2.604211621214361

Epoch: 5| Step: 1
Training loss: 1.8177838095777608
Validation loss: 2.5427991827133614

Epoch: 5| Step: 2
Training loss: 2.536350715333326
Validation loss: 2.562466543646023

Epoch: 5| Step: 3
Training loss: 2.135423005877754
Validation loss: 2.64841638592281

Epoch: 5| Step: 4
Training loss: 1.8747981916542196
Validation loss: 2.639722030165118

Epoch: 5| Step: 5
Training loss: 1.9719696360759384
Validation loss: 2.6002935344718208

Epoch: 5| Step: 6
Training loss: 2.359060405447795
Validation loss: 2.702192840376785

Epoch: 5| Step: 7
Training loss: 1.6001450383490403
Validation loss: 2.6728883907302197

Epoch: 5| Step: 8
Training loss: 2.3135546779366885
Validation loss: 2.71606437997425

Epoch: 5| Step: 9
Training loss: 2.17094170805673
Validation loss: 2.695788031015137

Epoch: 5| Step: 10
Training loss: 2.4857394712014704
Validation loss: 2.6674952014616564

Epoch: 5| Step: 11
Training loss: 1.580110943315508
Validation loss: 2.5938084530659133

Epoch: 83| Step: 0
Training loss: 2.074454141539784
Validation loss: 2.6506432994021063

Epoch: 5| Step: 1
Training loss: 2.1371715003222254
Validation loss: 2.615714168054147

Epoch: 5| Step: 2
Training loss: 2.3152998393512347
Validation loss: 2.6663945153558726

Epoch: 5| Step: 3
Training loss: 1.8394195002708558
Validation loss: 2.5964039472872886

Epoch: 5| Step: 4
Training loss: 2.202865585313091
Validation loss: 2.576943448514852

Epoch: 5| Step: 5
Training loss: 2.4185237216823174
Validation loss: 2.6099494522566347

Epoch: 5| Step: 6
Training loss: 2.057182392807656
Validation loss: 2.6057734428048325

Epoch: 5| Step: 7
Training loss: 2.07005797926933
Validation loss: 2.67491060000614

Epoch: 5| Step: 8
Training loss: 1.8556822322706323
Validation loss: 2.574456708963062

Epoch: 5| Step: 9
Training loss: 2.594768462095839
Validation loss: 2.6394070670073604

Epoch: 5| Step: 10
Training loss: 1.8501486228835273
Validation loss: 2.643635288602638

Epoch: 5| Step: 11
Training loss: 1.317522973253005
Validation loss: 2.6425841247535593

Epoch: 84| Step: 0
Training loss: 2.3558939333357465
Validation loss: 2.64287544978121

Epoch: 5| Step: 1
Training loss: 2.262201287377367
Validation loss: 2.663988968178386

Epoch: 5| Step: 2
Training loss: 1.8386541517678718
Validation loss: 2.7136432216235815

Epoch: 5| Step: 3
Training loss: 2.3137217206993976
Validation loss: 2.7694521732635917

Epoch: 5| Step: 4
Training loss: 1.940990257596423
Validation loss: 2.840603782258424

Epoch: 5| Step: 5
Training loss: 2.559187632352393
Validation loss: 2.7888242244004804

Epoch: 5| Step: 6
Training loss: 1.753622393163002
Validation loss: 2.801854419693652

Epoch: 5| Step: 7
Training loss: 2.3170503746816244
Validation loss: 2.703162231629912

Epoch: 5| Step: 8
Training loss: 2.433575233646201
Validation loss: 2.656306890738614

Epoch: 5| Step: 9
Training loss: 1.9149622456785584
Validation loss: 2.6997615196730433

Epoch: 5| Step: 10
Training loss: 1.4853892826304387
Validation loss: 2.633700327686202

Epoch: 5| Step: 11
Training loss: 2.843917674057462
Validation loss: 2.5789174220349604

Epoch: 85| Step: 0
Training loss: 2.2010819722240487
Validation loss: 2.6276303237404526

Epoch: 5| Step: 1
Training loss: 1.8430616095848407
Validation loss: 2.578078240635238

Epoch: 5| Step: 2
Training loss: 2.1414235428533224
Validation loss: 2.6749515481524093

Epoch: 5| Step: 3
Training loss: 1.6952455568940286
Validation loss: 2.61792781474911

Epoch: 5| Step: 4
Training loss: 2.766897393759218
Validation loss: 2.6051869695174656

Epoch: 5| Step: 5
Training loss: 2.3211619045814693
Validation loss: 2.6254234275212185

Epoch: 5| Step: 6
Training loss: 2.225658567883002
Validation loss: 2.6287821966700666

Epoch: 5| Step: 7
Training loss: 2.0016149914519343
Validation loss: 2.646382775415147

Epoch: 5| Step: 8
Training loss: 1.8627495156915834
Validation loss: 2.7243885857783816

Epoch: 5| Step: 9
Training loss: 1.4592786540671607
Validation loss: 2.7627273940660584

Epoch: 5| Step: 10
Training loss: 2.004329763056036
Validation loss: 2.7274414511228993

Epoch: 5| Step: 11
Training loss: 3.2104236349384614
Validation loss: 2.7852782534378484

Epoch: 86| Step: 0
Training loss: 1.8368202197669954
Validation loss: 2.6898799973940197

Epoch: 5| Step: 1
Training loss: 2.1977728364235554
Validation loss: 2.7034764217611165

Epoch: 5| Step: 2
Training loss: 2.0905891586447396
Validation loss: 2.7115486438223244

Epoch: 5| Step: 3
Training loss: 2.2098407518827323
Validation loss: 2.6930257338399093

Epoch: 5| Step: 4
Training loss: 2.2516331573560504
Validation loss: 2.6701642149468383

Epoch: 5| Step: 5
Training loss: 1.8413591562560196
Validation loss: 2.6820392465180536

Epoch: 5| Step: 6
Training loss: 2.3947775684509733
Validation loss: 2.6796278914484506

Epoch: 5| Step: 7
Training loss: 1.9401443647960839
Validation loss: 2.6585774378874447

Epoch: 5| Step: 8
Training loss: 1.9466551165151003
Validation loss: 2.669846610641145

Epoch: 5| Step: 9
Training loss: 2.3050066193591086
Validation loss: 2.5964912536508553

Epoch: 5| Step: 10
Training loss: 2.144101403799025
Validation loss: 2.65163558622456

Epoch: 5| Step: 11
Training loss: 0.9426990037881466
Validation loss: 2.6412592395188184

Epoch: 87| Step: 0
Training loss: 1.776016645357811
Validation loss: 2.6460632927651604

Epoch: 5| Step: 1
Training loss: 2.2346932778052384
Validation loss: 2.6544412513299163

Epoch: 5| Step: 2
Training loss: 2.0762971569312074
Validation loss: 2.7416904719941546

Epoch: 5| Step: 3
Training loss: 1.8483930413130647
Validation loss: 2.765497729144247

Epoch: 5| Step: 4
Training loss: 2.352540582677747
Validation loss: 2.8737759005576975

Epoch: 5| Step: 5
Training loss: 2.26465685975687
Validation loss: 2.8085030482276028

Epoch: 5| Step: 6
Training loss: 2.3411530412188877
Validation loss: 2.808575375018895

Epoch: 5| Step: 7
Training loss: 2.124121091505132
Validation loss: 2.7131813979216926

Epoch: 5| Step: 8
Training loss: 1.682721330161857
Validation loss: 2.6882255964533486

Epoch: 5| Step: 9
Training loss: 1.89840635423268
Validation loss: 2.679614719481299

Epoch: 5| Step: 10
Training loss: 2.6786005690669814
Validation loss: 2.634125696153467

Epoch: 5| Step: 11
Training loss: 2.4209693445898584
Validation loss: 2.621245412517821

Epoch: 88| Step: 0
Training loss: 2.1842367627848587
Validation loss: 2.6392786141158786

Epoch: 5| Step: 1
Training loss: 1.787654805982627
Validation loss: 2.671107637440515

Epoch: 5| Step: 2
Training loss: 1.9055351417802424
Validation loss: 2.6097597573293405

Epoch: 5| Step: 3
Training loss: 1.4068705990763584
Validation loss: 2.719330166705994

Epoch: 5| Step: 4
Training loss: 2.5877073748504147
Validation loss: 2.822603744439418

Epoch: 5| Step: 5
Training loss: 2.150989805863333
Validation loss: 2.7749252090169874

Epoch: 5| Step: 6
Training loss: 2.4597668966865855
Validation loss: 2.7782376474285355

Epoch: 5| Step: 7
Training loss: 1.9865187231871846
Validation loss: 2.786512247199777

Epoch: 5| Step: 8
Training loss: 2.0750488229545985
Validation loss: 2.7823268720103096

Epoch: 5| Step: 9
Training loss: 2.0497144267585683
Validation loss: 2.738449320077118

Epoch: 5| Step: 10
Training loss: 2.2501290602227
Validation loss: 2.671977310750095

Epoch: 5| Step: 11
Training loss: 1.8036021482233624
Validation loss: 2.635293325671614

Epoch: 89| Step: 0
Training loss: 2.5380754166047814
Validation loss: 2.6178633998527685

Epoch: 5| Step: 1
Training loss: 1.264574674715987
Validation loss: 2.7025618214554226

Epoch: 5| Step: 2
Training loss: 2.155899019286354
Validation loss: 2.624853324955178

Epoch: 5| Step: 3
Training loss: 2.346462561968125
Validation loss: 2.6201387040293516

Epoch: 5| Step: 4
Training loss: 2.3761579802553845
Validation loss: 2.638088317088272

Epoch: 5| Step: 5
Training loss: 1.6832007283521027
Validation loss: 2.741736720058809

Epoch: 5| Step: 6
Training loss: 2.2262974631525987
Validation loss: 2.628733530553771

Epoch: 5| Step: 7
Training loss: 2.0441129263049684
Validation loss: 2.6871618013720218

Epoch: 5| Step: 8
Training loss: 2.2660281118684464
Validation loss: 2.5818452561295895

Epoch: 5| Step: 9
Training loss: 2.1375098289576075
Validation loss: 2.6288826966423273

Epoch: 5| Step: 10
Training loss: 1.5382866622496365
Validation loss: 2.63340663903448

Epoch: 5| Step: 11
Training loss: 1.325704905301765
Validation loss: 2.69196458846802

Epoch: 90| Step: 0
Training loss: 1.74883415352347
Validation loss: 2.655310363625009

Epoch: 5| Step: 1
Training loss: 2.458401296505895
Validation loss: 2.7443530488068424

Epoch: 5| Step: 2
Training loss: 1.6287717329143068
Validation loss: 2.735834734787835

Epoch: 5| Step: 3
Training loss: 2.014181640510418
Validation loss: 2.748017561050591

Epoch: 5| Step: 4
Training loss: 2.239627240364175
Validation loss: 2.7703545462653314

Epoch: 5| Step: 5
Training loss: 2.767045168282923
Validation loss: 2.8040906400326775

Epoch: 5| Step: 6
Training loss: 1.440367947564558
Validation loss: 2.752515585107709

Epoch: 5| Step: 7
Training loss: 2.123071356301468
Validation loss: 2.7434393008053446

Epoch: 5| Step: 8
Training loss: 1.88471047118136
Validation loss: 2.722936866634737

Epoch: 5| Step: 9
Training loss: 2.1655980800700476
Validation loss: 2.6800735462473755

Epoch: 5| Step: 10
Training loss: 2.393374887263311
Validation loss: 2.636208864997172

Epoch: 5| Step: 11
Training loss: 1.0669677709236387
Validation loss: 2.6656644075140905

Epoch: 91| Step: 0
Training loss: 2.0898339387182077
Validation loss: 2.6257723323024025

Epoch: 5| Step: 1
Training loss: 2.4158970056647657
Validation loss: 2.713605075810423

Epoch: 5| Step: 2
Training loss: 1.877287296076575
Validation loss: 2.5916484607249233

Epoch: 5| Step: 3
Training loss: 2.0431243078697996
Validation loss: 2.6164591786454876

Epoch: 5| Step: 4
Training loss: 2.197286458234569
Validation loss: 2.6489548116988817

Epoch: 5| Step: 5
Training loss: 1.675059058443517
Validation loss: 2.6297587145755768

Epoch: 5| Step: 6
Training loss: 2.0423764013762695
Validation loss: 2.639842287943581

Epoch: 5| Step: 7
Training loss: 2.1916891041273145
Validation loss: 2.664533146576223

Epoch: 5| Step: 8
Training loss: 2.447452084439538
Validation loss: 2.6610148123147663

Epoch: 5| Step: 9
Training loss: 2.067846247175846
Validation loss: 2.739644326714381

Epoch: 5| Step: 10
Training loss: 2.0222047563411087
Validation loss: 2.722597129760044

Epoch: 5| Step: 11
Training loss: 1.6438602338024293
Validation loss: 2.6587067257124835

Epoch: 92| Step: 0
Training loss: 2.0394497207762243
Validation loss: 2.6977461659131983

Epoch: 5| Step: 1
Training loss: 1.9892599698533957
Validation loss: 2.7130565038747743

Epoch: 5| Step: 2
Training loss: 1.9987640137983336
Validation loss: 2.6473716646680145

Epoch: 5| Step: 3
Training loss: 1.9529006829193343
Validation loss: 2.6356731385492127

Epoch: 5| Step: 4
Training loss: 2.2898924693218956
Validation loss: 2.656112046492819

Epoch: 5| Step: 5
Training loss: 2.361397388032464
Validation loss: 2.665468063296263

Epoch: 5| Step: 6
Training loss: 1.9381273546053877
Validation loss: 2.676262909170485

Epoch: 5| Step: 7
Training loss: 1.8115370593111504
Validation loss: 2.6574638472915315

Epoch: 5| Step: 8
Training loss: 1.826455421670245
Validation loss: 2.6566450573219047

Epoch: 5| Step: 9
Training loss: 2.5948250622299494
Validation loss: 2.6056049088298034

Epoch: 5| Step: 10
Training loss: 1.739950891218289
Validation loss: 2.637348614095002

Epoch: 5| Step: 11
Training loss: 1.9692208468807333
Validation loss: 2.638854612719026

Epoch: 93| Step: 0
Training loss: 1.73768464897994
Validation loss: 2.5913395155911525

Epoch: 5| Step: 1
Training loss: 2.4217786216017183
Validation loss: 2.6442918880441657

Epoch: 5| Step: 2
Training loss: 1.7726681422662254
Validation loss: 2.5981443630142698

Epoch: 5| Step: 3
Training loss: 2.2624766606765694
Validation loss: 2.7634454605221976

Epoch: 5| Step: 4
Training loss: 1.885942382300504
Validation loss: 2.7851393076277473

Epoch: 5| Step: 5
Training loss: 1.6384841756885946
Validation loss: 2.7481348113572475

Epoch: 5| Step: 6
Training loss: 1.9986623224491566
Validation loss: 2.7813151134055425

Epoch: 5| Step: 7
Training loss: 2.227790895213604
Validation loss: 2.771755184664768

Epoch: 5| Step: 8
Training loss: 1.933975952598556
Validation loss: 2.7165509790720153

Epoch: 5| Step: 9
Training loss: 2.12526589020408
Validation loss: 2.7279144658859167

Epoch: 5| Step: 10
Training loss: 2.2343099091125422
Validation loss: 2.692714242295374

Epoch: 5| Step: 11
Training loss: 0.920406918304981
Validation loss: 2.6346858610838026

Epoch: 94| Step: 0
Training loss: 1.7332956890762359
Validation loss: 2.6047218964274923

Epoch: 5| Step: 1
Training loss: 1.815531661610365
Validation loss: 2.6779633175367676

Epoch: 5| Step: 2
Training loss: 2.3616350477745187
Validation loss: 2.6508353677058474

Epoch: 5| Step: 3
Training loss: 2.1355803140101965
Validation loss: 2.635587375122944

Epoch: 5| Step: 4
Training loss: 2.1315488320541465
Validation loss: 2.707113487678903

Epoch: 5| Step: 5
Training loss: 1.9986132343921013
Validation loss: 2.6776123315854488

Epoch: 5| Step: 6
Training loss: 1.8464621300242055
Validation loss: 2.6601200764157604

Epoch: 5| Step: 7
Training loss: 1.717670795438426
Validation loss: 2.6886504394528052

Epoch: 5| Step: 8
Training loss: 2.220534560651193
Validation loss: 2.6849487156413026

Epoch: 5| Step: 9
Training loss: 2.0743442648288446
Validation loss: 2.6369306615750574

Epoch: 5| Step: 10
Training loss: 2.206664684540626
Validation loss: 2.653967362760402

Epoch: 5| Step: 11
Training loss: 2.349031321765371
Validation loss: 2.62268877460947

Epoch: 95| Step: 0
Training loss: 1.6751404005961992
Validation loss: 2.6975228833549876

Epoch: 5| Step: 1
Training loss: 2.2943518657136295
Validation loss: 2.617675621859548

Epoch: 5| Step: 2
Training loss: 2.1011170549788853
Validation loss: 2.5914963157718884

Epoch: 5| Step: 3
Training loss: 1.777416856540773
Validation loss: 2.568927298875447

Epoch: 5| Step: 4
Training loss: 2.014188861064396
Validation loss: 2.646653760906394

Epoch: 5| Step: 5
Training loss: 2.1286100128970586
Validation loss: 2.6970228877357

Epoch: 5| Step: 6
Training loss: 2.3464394969150826
Validation loss: 2.7258417293551838

Epoch: 5| Step: 7
Training loss: 1.8302565317713457
Validation loss: 2.668257050322297

Epoch: 5| Step: 8
Training loss: 1.885465912851943
Validation loss: 2.6752334739427246

Epoch: 5| Step: 9
Training loss: 1.6380371028251874
Validation loss: 2.6829464653277024

Epoch: 5| Step: 10
Training loss: 2.0029669450840584
Validation loss: 2.7615553552617804

Epoch: 5| Step: 11
Training loss: 2.504864442397308
Validation loss: 2.7318445286054676

Epoch: 96| Step: 0
Training loss: 2.4037227487432755
Validation loss: 2.7216681498527184

Epoch: 5| Step: 1
Training loss: 1.7774905636693872
Validation loss: 2.6981298971172207

Epoch: 5| Step: 2
Training loss: 2.0658258152935596
Validation loss: 2.70024039131416

Epoch: 5| Step: 3
Training loss: 2.3464933488882838
Validation loss: 2.751505580488837

Epoch: 5| Step: 4
Training loss: 1.4749238948261618
Validation loss: 2.6888946825143263

Epoch: 5| Step: 5
Training loss: 2.1121547890929726
Validation loss: 2.6776668986196888

Epoch: 5| Step: 6
Training loss: 1.86688664139297
Validation loss: 2.7386695053270977

Epoch: 5| Step: 7
Training loss: 2.3788378976607816
Validation loss: 2.683292962495224

Epoch: 5| Step: 8
Training loss: 1.5428147637511165
Validation loss: 2.703512891600745

Epoch: 5| Step: 9
Training loss: 1.3655864823624893
Validation loss: 2.698775947490824

Epoch: 5| Step: 10
Training loss: 1.736868843872098
Validation loss: 2.75279409618868

Epoch: 5| Step: 11
Training loss: 2.173557645108334
Validation loss: 2.703116025523905

Epoch: 97| Step: 0
Training loss: 1.660092413179833
Validation loss: 2.6648294085188757

Epoch: 5| Step: 1
Training loss: 2.02694868821331
Validation loss: 2.647308472797939

Epoch: 5| Step: 2
Training loss: 2.3829394697536928
Validation loss: 2.707227122755795

Epoch: 5| Step: 3
Training loss: 2.2286524550935445
Validation loss: 2.6448223643094586

Epoch: 5| Step: 4
Training loss: 1.344826422413846
Validation loss: 2.6675024597874044

Epoch: 5| Step: 5
Training loss: 2.2522380082908624
Validation loss: 2.6782134425405553

Epoch: 5| Step: 6
Training loss: 2.024719068090065
Validation loss: 2.683992025924924

Epoch: 5| Step: 7
Training loss: 1.8605526312355187
Validation loss: 2.672029881143239

Epoch: 5| Step: 8
Training loss: 1.6361718914369134
Validation loss: 2.6535021350251324

Epoch: 5| Step: 9
Training loss: 2.2332414005583283
Validation loss: 2.699797859395755

Epoch: 5| Step: 10
Training loss: 1.9674786292421724
Validation loss: 2.602261507598952

Epoch: 5| Step: 11
Training loss: 0.3367860412624964
Validation loss: 2.766163527505679

Epoch: 98| Step: 0
Training loss: 1.9574066228506446
Validation loss: 2.727340273971914

Epoch: 5| Step: 1
Training loss: 1.2084267459585212
Validation loss: 2.7264803060623333

Epoch: 5| Step: 2
Training loss: 2.2248765418272742
Validation loss: 2.7294739824391954

Epoch: 5| Step: 3
Training loss: 1.9112891209791858
Validation loss: 2.7021966380057494

Epoch: 5| Step: 4
Training loss: 1.427407954066017
Validation loss: 2.6432991857916677

Epoch: 5| Step: 5
Training loss: 2.3526310821563223
Validation loss: 2.692077667392928

Epoch: 5| Step: 6
Training loss: 2.1774178450247614
Validation loss: 2.7047072136783274

Epoch: 5| Step: 7
Training loss: 1.9468432305990688
Validation loss: 2.6758006853943166

Epoch: 5| Step: 8
Training loss: 1.9931038936670933
Validation loss: 2.72798158429615

Epoch: 5| Step: 9
Training loss: 2.0668302220055375
Validation loss: 2.728063911432787

Epoch: 5| Step: 10
Training loss: 1.6019065673432507
Validation loss: 2.707871941854868

Epoch: 5| Step: 11
Training loss: 2.2392984844894435
Validation loss: 2.723357976298467

Epoch: 99| Step: 0
Training loss: 2.490721555439254
Validation loss: 2.695265189967301

Epoch: 5| Step: 1
Training loss: 1.8388540922844263
Validation loss: 2.7611670439856457

Epoch: 5| Step: 2
Training loss: 2.2705457196096375
Validation loss: 2.7102895763097354

Epoch: 5| Step: 3
Training loss: 2.1604516929305713
Validation loss: 2.657313575240594

Epoch: 5| Step: 4
Training loss: 1.875900433816132
Validation loss: 2.614928113892648

Epoch: 5| Step: 5
Training loss: 1.660515959422059
Validation loss: 2.7127300642454797

Epoch: 5| Step: 6
Training loss: 2.0275481310304375
Validation loss: 2.7548933564238656

Epoch: 5| Step: 7
Training loss: 1.2863300377918134
Validation loss: 2.7210378082713786

Epoch: 5| Step: 8
Training loss: 2.0250141378780437
Validation loss: 2.768407330860852

Epoch: 5| Step: 9
Training loss: 1.5937354891247337
Validation loss: 2.794165824678019

Epoch: 5| Step: 10
Training loss: 1.8630358776337905
Validation loss: 2.837562823895487

Epoch: 5| Step: 11
Training loss: 0.8007740299550654
Validation loss: 2.8403477630345697

Epoch: 100| Step: 0
Training loss: 1.8056625440476646
Validation loss: 2.8214000707794122

Epoch: 5| Step: 1
Training loss: 1.5985398961715342
Validation loss: 2.815856807691236

Epoch: 5| Step: 2
Training loss: 1.7904517764042545
Validation loss: 2.692591217612777

Epoch: 5| Step: 3
Training loss: 2.2275692453977705
Validation loss: 2.66495909383917

Epoch: 5| Step: 4
Training loss: 2.3241951564585053
Validation loss: 2.65023751543982

Epoch: 5| Step: 5
Training loss: 1.6411289712597934
Validation loss: 2.6698785390920468

Epoch: 5| Step: 6
Training loss: 1.939358588889019
Validation loss: 2.7322147628097073

Epoch: 5| Step: 7
Training loss: 2.0117310755083584
Validation loss: 2.730663378122688

Epoch: 5| Step: 8
Training loss: 2.2334366542013404
Validation loss: 2.709047807694784

Epoch: 5| Step: 9
Training loss: 2.063659226600636
Validation loss: 2.7070154480429354

Epoch: 5| Step: 10
Training loss: 1.6453766813013855
Validation loss: 2.645962176352229

Epoch: 5| Step: 11
Training loss: 1.2290339748506875
Validation loss: 2.8039142956090815

Epoch: 101| Step: 0
Training loss: 1.9796506256547268
Validation loss: 2.8514639676284745

Epoch: 5| Step: 1
Training loss: 1.660646325872854
Validation loss: 2.934643452220051

Epoch: 5| Step: 2
Training loss: 2.2984968415048375
Validation loss: 2.9362771214574668

Epoch: 5| Step: 3
Training loss: 2.2061012671806135
Validation loss: 3.003682710674655

Epoch: 5| Step: 4
Training loss: 1.8196040399781177
Validation loss: 2.917274446967598

Epoch: 5| Step: 5
Training loss: 1.703352746697347
Validation loss: 2.896173945413312

Epoch: 5| Step: 6
Training loss: 1.8029778379156225
Validation loss: 2.693033377079703

Epoch: 5| Step: 7
Training loss: 1.9627490547711404
Validation loss: 2.718266579338302

Epoch: 5| Step: 8
Training loss: 2.0695532216179835
Validation loss: 2.628931643404476

Epoch: 5| Step: 9
Training loss: 1.6260508294084617
Validation loss: 2.7262539146998077

Epoch: 5| Step: 10
Training loss: 2.0490424641369502
Validation loss: 2.6491497811155997

Epoch: 5| Step: 11
Training loss: 2.115803396346978
Validation loss: 2.714982513613793

Epoch: 102| Step: 0
Training loss: 1.955429914380705
Validation loss: 2.7181871350389972

Epoch: 5| Step: 1
Training loss: 1.9173931804282243
Validation loss: 2.7029010812262917

Epoch: 5| Step: 2
Training loss: 2.148545363059394
Validation loss: 2.668616134865644

Epoch: 5| Step: 3
Training loss: 2.1289557494962144
Validation loss: 2.6816835559762002

Epoch: 5| Step: 4
Training loss: 1.8587315832584044
Validation loss: 2.6959852512384925

Epoch: 5| Step: 5
Training loss: 1.347637275893942
Validation loss: 2.7266358709073004

Epoch: 5| Step: 6
Training loss: 2.391321218001374
Validation loss: 2.747815178179657

Epoch: 5| Step: 7
Training loss: 1.7164521549356118
Validation loss: 2.832887703314132

Epoch: 5| Step: 8
Training loss: 2.126228538373474
Validation loss: 2.8950996132635733

Epoch: 5| Step: 9
Training loss: 2.044720979603313
Validation loss: 2.8568479214018314

Epoch: 5| Step: 10
Training loss: 1.9650198097298193
Validation loss: 2.809849090234521

Epoch: 5| Step: 11
Training loss: 1.1784359691026243
Validation loss: 2.7903150849870277

Epoch: 103| Step: 0
Training loss: 1.7573189275587195
Validation loss: 2.7483624618491107

Epoch: 5| Step: 1
Training loss: 1.8690492932558298
Validation loss: 2.6812651487810246

Epoch: 5| Step: 2
Training loss: 2.1601201583854843
Validation loss: 2.6774295009137745

Epoch: 5| Step: 3
Training loss: 2.3478187339778143
Validation loss: 2.6334545812780514

Epoch: 5| Step: 4
Training loss: 1.9312887613795438
Validation loss: 2.6585040869227927

Epoch: 5| Step: 5
Training loss: 1.6884160557722514
Validation loss: 2.7035336268277197

Epoch: 5| Step: 6
Training loss: 2.067449929900718
Validation loss: 2.7132030276977024

Epoch: 5| Step: 7
Training loss: 1.6731997793912001
Validation loss: 2.6938631445539887

Epoch: 5| Step: 8
Training loss: 1.5736306277474517
Validation loss: 2.6607898288144742

Epoch: 5| Step: 9
Training loss: 1.7663617242788394
Validation loss: 2.6671559411453623

Epoch: 5| Step: 10
Training loss: 1.8762743751726625
Validation loss: 2.8183569587596704

Epoch: 5| Step: 11
Training loss: 2.50619321459131
Validation loss: 2.8816492306104755

Epoch: 104| Step: 0
Training loss: 2.183142217857071
Validation loss: 2.8021528963343467

Epoch: 5| Step: 1
Training loss: 1.6971193871749126
Validation loss: 2.751662716185909

Epoch: 5| Step: 2
Training loss: 1.9142313980009766
Validation loss: 2.656113104939075

Epoch: 5| Step: 3
Training loss: 1.279582217476964
Validation loss: 2.718711238891706

Epoch: 5| Step: 4
Training loss: 1.9633471513185272
Validation loss: 2.7200364872820253

Epoch: 5| Step: 5
Training loss: 1.7250255803961982
Validation loss: 2.658439777050879

Epoch: 5| Step: 6
Training loss: 2.4122519014698733
Validation loss: 2.6439848222147817

Epoch: 5| Step: 7
Training loss: 1.833109914286436
Validation loss: 2.7184425359190283

Epoch: 5| Step: 8
Training loss: 2.298290413429706
Validation loss: 2.7408491058239868

Epoch: 5| Step: 9
Training loss: 1.8824205425864888
Validation loss: 2.7616462212390687

Epoch: 5| Step: 10
Training loss: 2.0482920626317753
Validation loss: 2.789770554709617

Epoch: 5| Step: 11
Training loss: 1.9797125883251454
Validation loss: 2.8983590731502424

Epoch: 105| Step: 0
Training loss: 2.3622003274411107
Validation loss: 2.893261674388763

Epoch: 5| Step: 1
Training loss: 1.9979959222257468
Validation loss: 2.8132776633418715

Epoch: 5| Step: 2
Training loss: 1.513238817840104
Validation loss: 2.8213251749123853

Epoch: 5| Step: 3
Training loss: 2.190710055758379
Validation loss: 2.723192894551569

Epoch: 5| Step: 4
Training loss: 1.3747476432878598
Validation loss: 2.7106234233870086

Epoch: 5| Step: 5
Training loss: 1.7666506193739746
Validation loss: 2.669469159209576

Epoch: 5| Step: 6
Training loss: 1.9128977443008728
Validation loss: 2.698928607633184

Epoch: 5| Step: 7
Training loss: 1.8315304069525564
Validation loss: 2.64552368519789

Epoch: 5| Step: 8
Training loss: 1.4614403823036477
Validation loss: 2.740079763468525

Epoch: 5| Step: 9
Training loss: 1.8877667977443653
Validation loss: 2.722210755061847

Epoch: 5| Step: 10
Training loss: 1.6314441112329843
Validation loss: 2.686422109686309

Epoch: 5| Step: 11
Training loss: 2.1109278861503875
Validation loss: 2.7773974306594402

Epoch: 106| Step: 0
Training loss: 1.8279371898720118
Validation loss: 2.743789509204212

Epoch: 5| Step: 1
Training loss: 1.803065111564002
Validation loss: 2.7498391602904504

Epoch: 5| Step: 2
Training loss: 2.24502638956375
Validation loss: 2.824591461252854

Epoch: 5| Step: 3
Training loss: 2.1499785843603205
Validation loss: 2.8245895515174997

Epoch: 5| Step: 4
Training loss: 1.5308036153556768
Validation loss: 2.7771398985458906

Epoch: 5| Step: 5
Training loss: 2.4846819801926547
Validation loss: 2.756983375728188

Epoch: 5| Step: 6
Training loss: 1.475201176000776
Validation loss: 2.7931340913360723

Epoch: 5| Step: 7
Training loss: 1.8328812504172505
Validation loss: 2.8353858530321494

Epoch: 5| Step: 8
Training loss: 1.9573596671166693
Validation loss: 2.7348443563994196

Epoch: 5| Step: 9
Training loss: 1.5468195124991302
Validation loss: 2.7072887839438597

Epoch: 5| Step: 10
Training loss: 1.4470328325238857
Validation loss: 2.7019471154525965

Epoch: 5| Step: 11
Training loss: 0.9120464752531517
Validation loss: 2.695235736877946

Epoch: 107| Step: 0
Training loss: 1.9342182422529108
Validation loss: 2.702187686180631

Epoch: 5| Step: 1
Training loss: 1.2083806763067093
Validation loss: 2.7274121269630345

Epoch: 5| Step: 2
Training loss: 1.933011053891455
Validation loss: 2.7714523876334494

Epoch: 5| Step: 3
Training loss: 1.806300643686111
Validation loss: 2.706636448667606

Epoch: 5| Step: 4
Training loss: 1.7796330390883108
Validation loss: 2.759199415087645

Epoch: 5| Step: 5
Training loss: 2.247140020410786
Validation loss: 2.7522842608694784

Epoch: 5| Step: 6
Training loss: 1.1913971947497837
Validation loss: 2.7390998599864247

Epoch: 5| Step: 7
Training loss: 2.0721494190880287
Validation loss: 2.772571535984865

Epoch: 5| Step: 8
Training loss: 1.3223768269196048
Validation loss: 2.707355522047535

Epoch: 5| Step: 9
Training loss: 1.9597986569433188
Validation loss: 2.7141428127202953

Epoch: 5| Step: 10
Training loss: 2.091932960165469
Validation loss: 2.7904024476107767

Epoch: 5| Step: 11
Training loss: 2.593462457000128
Validation loss: 2.7347902582108334

Epoch: 108| Step: 0
Training loss: 1.9105038940861223
Validation loss: 2.734435514961179

Epoch: 5| Step: 1
Training loss: 1.2837637456141309
Validation loss: 2.8019658363033035

Epoch: 5| Step: 2
Training loss: 2.086290651065929
Validation loss: 2.8758857751580535

Epoch: 5| Step: 3
Training loss: 1.9806852504513661
Validation loss: 2.810884191697784

Epoch: 5| Step: 4
Training loss: 1.9329909492829411
Validation loss: 2.8147205699571676

Epoch: 5| Step: 5
Training loss: 1.799011751260593
Validation loss: 2.6823719506455204

Epoch: 5| Step: 6
Training loss: 1.7617239603105117
Validation loss: 2.7721011600315864

Epoch: 5| Step: 7
Training loss: 2.1644261464336174
Validation loss: 2.765563227795187

Epoch: 5| Step: 8
Training loss: 1.975140931135158
Validation loss: 2.7854565444712827

Epoch: 5| Step: 9
Training loss: 1.260978079784555
Validation loss: 2.677666375511572

Epoch: 5| Step: 10
Training loss: 1.5652321389213033
Validation loss: 2.677406548805365

Epoch: 5| Step: 11
Training loss: 1.2232672776327995
Validation loss: 2.7314417082883597

Epoch: 109| Step: 0
Training loss: 1.578100298697657
Validation loss: 2.7549699645358086

Epoch: 5| Step: 1
Training loss: 1.835744449935933
Validation loss: 2.762311167757592

Epoch: 5| Step: 2
Training loss: 2.0519659199180493
Validation loss: 2.861393898478113

Epoch: 5| Step: 3
Training loss: 1.780276584674776
Validation loss: 2.960818024089418

Epoch: 5| Step: 4
Training loss: 2.443757851824622
Validation loss: 2.8962774599387293

Epoch: 5| Step: 5
Training loss: 1.7044896249586845
Validation loss: 2.8798122973005396

Epoch: 5| Step: 6
Training loss: 2.032837584778392
Validation loss: 2.798606876236515

Epoch: 5| Step: 7
Training loss: 1.2574328684852119
Validation loss: 2.750937952130207

Epoch: 5| Step: 8
Training loss: 1.3596814128131893
Validation loss: 2.7437151125324237

Epoch: 5| Step: 9
Training loss: 1.643461119356397
Validation loss: 2.7293360029107205

Epoch: 5| Step: 10
Training loss: 2.2062422971077686
Validation loss: 2.7229954979324997

Epoch: 5| Step: 11
Training loss: 1.9455520911300568
Validation loss: 2.734699745875877

Epoch: 110| Step: 0
Training loss: 2.4575049303069383
Validation loss: 2.6917243920819938

Epoch: 5| Step: 1
Training loss: 1.6408697036630953
Validation loss: 2.7748299125576827

Epoch: 5| Step: 2
Training loss: 1.4801322937167056
Validation loss: 2.728168863276709

Epoch: 5| Step: 3
Training loss: 1.7357701369398646
Validation loss: 2.8445662455373575

Epoch: 5| Step: 4
Training loss: 1.1968357129533942
Validation loss: 2.88200355696409

Epoch: 5| Step: 5
Training loss: 2.086401384185554
Validation loss: 2.9104724208777033

Epoch: 5| Step: 6
Training loss: 1.5855448570342003
Validation loss: 2.872145593740278

Epoch: 5| Step: 7
Training loss: 1.6998709293061192
Validation loss: 2.939406679109672

Epoch: 5| Step: 8
Training loss: 2.066955608760485
Validation loss: 2.922411979794308

Epoch: 5| Step: 9
Training loss: 2.1362891174984906
Validation loss: 2.8758982036215643

Epoch: 5| Step: 10
Training loss: 1.7468999925712434
Validation loss: 2.886280217497839

Epoch: 5| Step: 11
Training loss: 1.7301560371238256
Validation loss: 2.7014526272772295

Epoch: 111| Step: 0
Training loss: 2.300355933470796
Validation loss: 2.7336590946887895

Epoch: 5| Step: 1
Training loss: 1.7342051517384096
Validation loss: 2.784096372159034

Epoch: 5| Step: 2
Training loss: 2.0103186021780686
Validation loss: 2.774325082800656

Epoch: 5| Step: 3
Training loss: 2.0258045858678697
Validation loss: 2.7108973097959757

Epoch: 5| Step: 4
Training loss: 1.6419903115045933
Validation loss: 2.655122712227552

Epoch: 5| Step: 5
Training loss: 1.6779303297508519
Validation loss: 2.682930092001656

Epoch: 5| Step: 6
Training loss: 1.9021816302077799
Validation loss: 2.7913528534075573

Epoch: 5| Step: 7
Training loss: 2.011806330579928
Validation loss: 2.7686856929007586

Epoch: 5| Step: 8
Training loss: 1.6993098092070311
Validation loss: 2.82828193917577

Epoch: 5| Step: 9
Training loss: 2.274169803932666
Validation loss: 2.8406710812251537

Epoch: 5| Step: 10
Training loss: 0.9863522063988611
Validation loss: 2.9462264959115037

Epoch: 5| Step: 11
Training loss: 2.365501080067867
Validation loss: 3.013604262873559

Epoch: 112| Step: 0
Training loss: 1.9174099669525604
Validation loss: 2.855899494765745

Epoch: 5| Step: 1
Training loss: 1.7791228057433977
Validation loss: 2.748816958183348

Epoch: 5| Step: 2
Training loss: 2.6150000697294558
Validation loss: 2.6855378269852315

Epoch: 5| Step: 3
Training loss: 1.6079642028714645
Validation loss: 2.691110876196065

Epoch: 5| Step: 4
Training loss: 1.7641942126262322
Validation loss: 2.644030220656162

Epoch: 5| Step: 5
Training loss: 1.9532327240800351
Validation loss: 2.660104412184358

Epoch: 5| Step: 6
Training loss: 1.9340979333005694
Validation loss: 2.672781550668544

Epoch: 5| Step: 7
Training loss: 1.6168672548631298
Validation loss: 2.687269637119114

Epoch: 5| Step: 8
Training loss: 1.8779959585128052
Validation loss: 2.754391036414337

Epoch: 5| Step: 9
Training loss: 1.8260135031176838
Validation loss: 2.7328897166116812

Epoch: 5| Step: 10
Training loss: 1.3023051823132488
Validation loss: 2.7865032703424504

Epoch: 5| Step: 11
Training loss: 2.2664737558551664
Validation loss: 2.9479752502191814

Epoch: 113| Step: 0
Training loss: 1.8099756090617796
Validation loss: 2.898567011733874

Epoch: 5| Step: 1
Training loss: 1.5502945835375448
Validation loss: 2.8869616208870092

Epoch: 5| Step: 2
Training loss: 1.8850533221365313
Validation loss: 2.7919913798176825

Epoch: 5| Step: 3
Training loss: 1.6232295295039119
Validation loss: 2.7710892097859685

Epoch: 5| Step: 4
Training loss: 1.939077289042301
Validation loss: 2.7538502933237208

Epoch: 5| Step: 5
Training loss: 1.8702495159612058
Validation loss: 2.6659048874881104

Epoch: 5| Step: 6
Training loss: 1.4779129714998493
Validation loss: 2.692846461921523

Epoch: 5| Step: 7
Training loss: 1.7895547780906935
Validation loss: 2.6483112556428727

Epoch: 5| Step: 8
Training loss: 1.9820497962285444
Validation loss: 2.6617273516973645

Epoch: 5| Step: 9
Training loss: 1.8637394691543308
Validation loss: 2.719519243265905

Epoch: 5| Step: 10
Training loss: 1.696388711676158
Validation loss: 2.793019740210536

Epoch: 5| Step: 11
Training loss: 3.488551899319838
Validation loss: 2.8162456577773805

Epoch: 114| Step: 0
Training loss: 1.37074510102942
Validation loss: 2.675777697038728

Epoch: 5| Step: 1
Training loss: 1.9262704595411262
Validation loss: 2.751190162809867

Epoch: 5| Step: 2
Training loss: 1.654224452715764
Validation loss: 2.729538995276618

Epoch: 5| Step: 3
Training loss: 1.7818120772304955
Validation loss: 2.7530868609901034

Epoch: 5| Step: 4
Training loss: 1.6545110966900267
Validation loss: 2.7207617606193026

Epoch: 5| Step: 5
Training loss: 1.6598654099560908
Validation loss: 2.660520706940461

Epoch: 5| Step: 6
Training loss: 1.9321808556163744
Validation loss: 2.642946682322078

Epoch: 5| Step: 7
Training loss: 1.8146524473824897
Validation loss: 2.7436376108368137

Epoch: 5| Step: 8
Training loss: 1.8012756198646758
Validation loss: 2.726467251138674

Epoch: 5| Step: 9
Training loss: 1.4120212384968962
Validation loss: 2.766813680082625

Epoch: 5| Step: 10
Training loss: 2.2810113860451953
Validation loss: 2.80649801487923

Epoch: 5| Step: 11
Training loss: 2.4398025983161014
Validation loss: 2.8010195387342995

Epoch: 115| Step: 0
Training loss: 2.074064489688123
Validation loss: 2.711104454740663

Epoch: 5| Step: 1
Training loss: 1.7538995891351108
Validation loss: 2.6969069256887495

Epoch: 5| Step: 2
Training loss: 1.8297193698729877
Validation loss: 2.666397592757953

Epoch: 5| Step: 3
Training loss: 1.8081883414837039
Validation loss: 2.687361231259691

Epoch: 5| Step: 4
Training loss: 1.3798660093716617
Validation loss: 2.7429901969677477

Epoch: 5| Step: 5
Training loss: 1.7595900300850222
Validation loss: 2.748370316266048

Epoch: 5| Step: 6
Training loss: 1.5868904745843098
Validation loss: 2.7587964047134506

Epoch: 5| Step: 7
Training loss: 1.7389150085694811
Validation loss: 2.744280423079859

Epoch: 5| Step: 8
Training loss: 1.877970059774691
Validation loss: 2.7999551069827393

Epoch: 5| Step: 9
Training loss: 1.6088547838019902
Validation loss: 2.744851407891474

Epoch: 5| Step: 10
Training loss: 1.9265509686275752
Validation loss: 2.6778763896401547

Epoch: 5| Step: 11
Training loss: 1.5683333037265257
Validation loss: 2.681397040098845

Epoch: 116| Step: 0
Training loss: 1.8243894966806717
Validation loss: 2.6433413188925146

Epoch: 5| Step: 1
Training loss: 1.7772487740763967
Validation loss: 2.6849804941045425

Epoch: 5| Step: 2
Training loss: 2.3272713753983516
Validation loss: 2.665183706751009

Epoch: 5| Step: 3
Training loss: 1.5264844111106708
Validation loss: 2.736520641088515

Epoch: 5| Step: 4
Training loss: 1.6038294681355956
Validation loss: 2.760065403067775

Epoch: 5| Step: 5
Training loss: 1.8662762193824554
Validation loss: 2.8045684909630895

Epoch: 5| Step: 6
Training loss: 2.1387411027965166
Validation loss: 2.8567172242208367

Epoch: 5| Step: 7
Training loss: 1.2025960775207671
Validation loss: 2.7596452654820336

Epoch: 5| Step: 8
Training loss: 1.5348712375078113
Validation loss: 2.8041418035254244

Epoch: 5| Step: 9
Training loss: 1.4620693942246525
Validation loss: 2.6219574158680587

Epoch: 5| Step: 10
Training loss: 2.2145581473362466
Validation loss: 2.7045852414080698

Epoch: 5| Step: 11
Training loss: 0.8079868194973324
Validation loss: 2.7205494410296573

Epoch: 117| Step: 0
Training loss: 1.659542984730168
Validation loss: 2.7515926950802765

Epoch: 5| Step: 1
Training loss: 1.892489247159255
Validation loss: 2.7697581192448735

Epoch: 5| Step: 2
Training loss: 1.2628564576878873
Validation loss: 2.771226759397163

Epoch: 5| Step: 3
Training loss: 1.3707042695174136
Validation loss: 2.752149991352734

Epoch: 5| Step: 4
Training loss: 1.735742665506784
Validation loss: 2.6576924016760626

Epoch: 5| Step: 5
Training loss: 2.0699834598120015
Validation loss: 2.6968670107832557

Epoch: 5| Step: 6
Training loss: 1.7954970010186913
Validation loss: 2.8075131250529286

Epoch: 5| Step: 7
Training loss: 1.7816470858024573
Validation loss: 2.8102980824575816

Epoch: 5| Step: 8
Training loss: 1.5599356398388535
Validation loss: 2.7512652094846812

Epoch: 5| Step: 9
Training loss: 1.7176159672128648
Validation loss: 2.7520626417234544

Epoch: 5| Step: 10
Training loss: 1.8439140893365287
Validation loss: 2.7022062570488448

Epoch: 5| Step: 11
Training loss: 1.5065298208329498
Validation loss: 2.7476686977942943

Epoch: 118| Step: 0
Training loss: 1.5108708016823347
Validation loss: 2.8353969384562143

Epoch: 5| Step: 1
Training loss: 2.194828835419922
Validation loss: 2.773365170247558

Epoch: 5| Step: 2
Training loss: 1.183952352757172
Validation loss: 2.848692853135983

Epoch: 5| Step: 3
Training loss: 1.7062712839217384
Validation loss: 2.8415936724012485

Epoch: 5| Step: 4
Training loss: 1.5757572049304998
Validation loss: 2.9648081895038443

Epoch: 5| Step: 5
Training loss: 1.5037606305058173
Validation loss: 2.912596036149006

Epoch: 5| Step: 6
Training loss: 1.7046545317457489
Validation loss: 2.9127280083281404

Epoch: 5| Step: 7
Training loss: 1.799930926163207
Validation loss: 2.816371167970127

Epoch: 5| Step: 8
Training loss: 1.6476670765419328
Validation loss: 2.812964077914761

Epoch: 5| Step: 9
Training loss: 1.8213926720487394
Validation loss: 2.7441989408294765

Epoch: 5| Step: 10
Training loss: 1.820591590016932
Validation loss: 2.723475142901086

Epoch: 5| Step: 11
Training loss: 0.8846908436681366
Validation loss: 2.718235858812273

Epoch: 119| Step: 0
Training loss: 2.001254999272466
Validation loss: 2.6954184801578442

Epoch: 5| Step: 1
Training loss: 1.6475758402246594
Validation loss: 2.644705777440737

Epoch: 5| Step: 2
Training loss: 1.5117048711410705
Validation loss: 2.754729059186792

Epoch: 5| Step: 3
Training loss: 1.8016488391207108
Validation loss: 2.7528676376395596

Epoch: 5| Step: 4
Training loss: 1.391860455975302
Validation loss: 2.663130831273011

Epoch: 5| Step: 5
Training loss: 1.83217003790745
Validation loss: 2.7887350080683597

Epoch: 5| Step: 6
Training loss: 2.11385519585957
Validation loss: 2.845001713752789

Epoch: 5| Step: 7
Training loss: 1.6446011272453926
Validation loss: 2.848289973905687

Epoch: 5| Step: 8
Training loss: 1.6277057422731405
Validation loss: 2.8476416714351354

Epoch: 5| Step: 9
Training loss: 1.3356467929002886
Validation loss: 2.93334179984482

Epoch: 5| Step: 10
Training loss: 1.787046070749527
Validation loss: 2.843422154682376

Epoch: 5| Step: 11
Training loss: 1.6359946167164772
Validation loss: 2.797995437020741

Epoch: 120| Step: 0
Training loss: 1.6006319645704439
Validation loss: 2.816938599508314

Epoch: 5| Step: 1
Training loss: 1.6646049940524525
Validation loss: 2.8160944151848026

Epoch: 5| Step: 2
Training loss: 1.5792122296660775
Validation loss: 2.8092366960688078

Epoch: 5| Step: 3
Training loss: 2.1764830958881833
Validation loss: 2.7404985035462617

Epoch: 5| Step: 4
Training loss: 1.224386143149297
Validation loss: 2.785917829813883

Epoch: 5| Step: 5
Training loss: 1.6512003520516088
Validation loss: 2.763626407388565

Epoch: 5| Step: 6
Training loss: 1.3344733708948873
Validation loss: 2.7692220324241945

Epoch: 5| Step: 7
Training loss: 1.6225951813697619
Validation loss: 2.8194276895844754

Epoch: 5| Step: 8
Training loss: 1.7702068192939917
Validation loss: 2.8638927158963665

Epoch: 5| Step: 9
Training loss: 1.3586341768537982
Validation loss: 2.9068505340095547

Epoch: 5| Step: 10
Training loss: 2.1983660438924755
Validation loss: 2.988360554758548

Epoch: 5| Step: 11
Training loss: 1.042737899549099
Validation loss: 2.931158935634359

Epoch: 121| Step: 0
Training loss: 1.243685892264423
Validation loss: 2.834460764620969

Epoch: 5| Step: 1
Training loss: 1.1124391817763546
Validation loss: 2.8325509061556935

Epoch: 5| Step: 2
Training loss: 2.094180845654606
Validation loss: 2.7682184964988434

Epoch: 5| Step: 3
Training loss: 1.4402216150035683
Validation loss: 2.7233542410080256

Epoch: 5| Step: 4
Training loss: 1.7160087920499418
Validation loss: 2.747215338588954

Epoch: 5| Step: 5
Training loss: 1.1402548097803016
Validation loss: 2.744745338574965

Epoch: 5| Step: 6
Training loss: 1.635070043224262
Validation loss: 2.7483646341958474

Epoch: 5| Step: 7
Training loss: 1.4651693973966378
Validation loss: 2.8178604258858275

Epoch: 5| Step: 8
Training loss: 1.9291587444936455
Validation loss: 2.745453634670781

Epoch: 5| Step: 9
Training loss: 2.0925128754979636
Validation loss: 2.85583342777501

Epoch: 5| Step: 10
Training loss: 1.5050796488980167
Validation loss: 2.777003292886762

Epoch: 5| Step: 11
Training loss: 2.127225383781545
Validation loss: 2.8499636134674744

Epoch: 122| Step: 0
Training loss: 1.7121507358102617
Validation loss: 2.9400140203954757

Epoch: 5| Step: 1
Training loss: 1.992461660631314
Validation loss: 2.90379564500377

Epoch: 5| Step: 2
Training loss: 1.5944216939622624
Validation loss: 2.847047193828122

Epoch: 5| Step: 3
Training loss: 1.6478292780426573
Validation loss: 2.8052695864848176

Epoch: 5| Step: 4
Training loss: 1.7029472748305101
Validation loss: 2.80995853532062

Epoch: 5| Step: 5
Training loss: 1.1993878273330167
Validation loss: 2.7301357977666565

Epoch: 5| Step: 6
Training loss: 1.7329733055907164
Validation loss: 2.773848665232377

Epoch: 5| Step: 7
Training loss: 1.3183652524463894
Validation loss: 2.7971285451126233

Epoch: 5| Step: 8
Training loss: 1.774808782029364
Validation loss: 2.8772204193577635

Epoch: 5| Step: 9
Training loss: 1.4566191635126207
Validation loss: 2.9087303713573527

Epoch: 5| Step: 10
Training loss: 1.3630915293897918
Validation loss: 2.7866718008444304

Epoch: 5| Step: 11
Training loss: 2.4976282313269498
Validation loss: 2.854526745341991

Epoch: 123| Step: 0
Training loss: 1.1165049675447867
Validation loss: 2.7796723466688498

Epoch: 5| Step: 1
Training loss: 1.597313953843052
Validation loss: 2.8700375039140185

Epoch: 5| Step: 2
Training loss: 2.2050572572570495
Validation loss: 2.8962172704259657

Epoch: 5| Step: 3
Training loss: 1.3678972854116584
Validation loss: 2.855997376709445

Epoch: 5| Step: 4
Training loss: 1.3339234724985098
Validation loss: 2.7802790329196525

Epoch: 5| Step: 5
Training loss: 1.7678215744381762
Validation loss: 2.8420844737640976

Epoch: 5| Step: 6
Training loss: 1.7083926151813584
Validation loss: 2.859883629703322

Epoch: 5| Step: 7
Training loss: 1.6201001166972857
Validation loss: 2.793373761455418

Epoch: 5| Step: 8
Training loss: 1.8259664328164915
Validation loss: 2.84854132455566

Epoch: 5| Step: 9
Training loss: 1.6055876230750237
Validation loss: 2.7916810274940933

Epoch: 5| Step: 10
Training loss: 1.460197465293491
Validation loss: 2.8275988986929526

Epoch: 5| Step: 11
Training loss: 1.672357578685533
Validation loss: 2.845764138556677

Epoch: 124| Step: 0
Training loss: 1.620265592891165
Validation loss: 2.8831482840749403

Epoch: 5| Step: 1
Training loss: 1.8368807702948973
Validation loss: 2.9643073386214995

Epoch: 5| Step: 2
Training loss: 1.640168626071186
Validation loss: 2.9414711143363137

Epoch: 5| Step: 3
Training loss: 1.574007384543443
Validation loss: 3.0215263339127154

Epoch: 5| Step: 4
Training loss: 1.9592240587225398
Validation loss: 2.886200319297364

Epoch: 5| Step: 5
Training loss: 1.4814489335661496
Validation loss: 2.7444626480072407

Epoch: 5| Step: 6
Training loss: 2.2322759839277064
Validation loss: 2.7865021473419804

Epoch: 5| Step: 7
Training loss: 1.6055520585992578
Validation loss: 2.788289605054507

Epoch: 5| Step: 8
Training loss: 1.5798021224005119
Validation loss: 2.699931678525683

Epoch: 5| Step: 9
Training loss: 1.4473452732753964
Validation loss: 2.754547672109172

Epoch: 5| Step: 10
Training loss: 1.323859106868001
Validation loss: 2.8397016738969416

Epoch: 5| Step: 11
Training loss: 1.4542028060109538
Validation loss: 2.8598323067217644

Epoch: 125| Step: 0
Training loss: 1.7786966058755422
Validation loss: 2.94843124755563

Epoch: 5| Step: 1
Training loss: 1.746531455118476
Validation loss: 2.9362150824722404

Epoch: 5| Step: 2
Training loss: 1.411339514354084
Validation loss: 2.9741124326439636

Epoch: 5| Step: 3
Training loss: 1.280151268246173
Validation loss: 2.9742216282062315

Epoch: 5| Step: 4
Training loss: 1.402310681816548
Validation loss: 2.9313541300320534

Epoch: 5| Step: 5
Training loss: 2.247689862575074
Validation loss: 2.879209708615731

Epoch: 5| Step: 6
Training loss: 1.4179514313788282
Validation loss: 2.8047081991722904

Epoch: 5| Step: 7
Training loss: 1.5552059823401896
Validation loss: 2.82142028468216

Epoch: 5| Step: 8
Training loss: 1.5387397853781883
Validation loss: 2.659373208750246

Epoch: 5| Step: 9
Training loss: 1.9041230890252814
Validation loss: 2.78929078835644

Epoch: 5| Step: 10
Training loss: 1.5798295890076104
Validation loss: 2.7481985658063666

Epoch: 5| Step: 11
Training loss: 1.044803277531488
Validation loss: 2.75383512075926

Epoch: 126| Step: 0
Training loss: 1.1954136724601858
Validation loss: 2.761971760211826

Epoch: 5| Step: 1
Training loss: 1.438359376856482
Validation loss: 2.747948918407589

Epoch: 5| Step: 2
Training loss: 1.7524376648878632
Validation loss: 2.7722453102606277

Epoch: 5| Step: 3
Training loss: 1.7957127004703775
Validation loss: 2.832656472130163

Epoch: 5| Step: 4
Training loss: 2.02786877252337
Validation loss: 2.809714873918131

Epoch: 5| Step: 5
Training loss: 1.8387417418750243
Validation loss: 2.904076850730045

Epoch: 5| Step: 6
Training loss: 1.4789429705897918
Validation loss: 2.8722133019358203

Epoch: 5| Step: 7
Training loss: 1.6760275066276247
Validation loss: 2.9925627975227362

Epoch: 5| Step: 8
Training loss: 1.7679126739037305
Validation loss: 2.9074700095241828

Epoch: 5| Step: 9
Training loss: 1.5618127455865545
Validation loss: 2.9822616017796255

Epoch: 5| Step: 10
Training loss: 1.4001918848554216
Validation loss: 2.825777994339804

Epoch: 5| Step: 11
Training loss: 0.7393088077508113
Validation loss: 2.7271286304715074

Epoch: 127| Step: 0
Training loss: 1.3286483631037673
Validation loss: 2.7856913440904316

Epoch: 5| Step: 1
Training loss: 1.2867769266397713
Validation loss: 2.836415908156242

Epoch: 5| Step: 2
Training loss: 2.071842189891511
Validation loss: 2.7925131615169483

Epoch: 5| Step: 3
Training loss: 1.3416283292012023
Validation loss: 2.801409510363905

Epoch: 5| Step: 4
Training loss: 1.20648082046662
Validation loss: 2.8333686599679586

Epoch: 5| Step: 5
Training loss: 1.672817926909368
Validation loss: 2.8753247768672208

Epoch: 5| Step: 6
Training loss: 1.9670932398749106
Validation loss: 2.8956632747161146

Epoch: 5| Step: 7
Training loss: 1.4460312989041
Validation loss: 2.9554571062934754

Epoch: 5| Step: 8
Training loss: 1.5377039456206911
Validation loss: 2.869303598919106

Epoch: 5| Step: 9
Training loss: 1.7417085271425636
Validation loss: 2.8201334994248763

Epoch: 5| Step: 10
Training loss: 1.496937725369577
Validation loss: 2.835872190509859

Epoch: 5| Step: 11
Training loss: 2.456162145853741
Validation loss: 2.822017253079743

Epoch: 128| Step: 0
Training loss: 1.6654039447379003
Validation loss: 2.7162821520022904

Epoch: 5| Step: 1
Training loss: 1.4509751198053216
Validation loss: 2.710869952266345

Epoch: 5| Step: 2
Training loss: 1.5673455444848945
Validation loss: 2.7954029102037183

Epoch: 5| Step: 3
Training loss: 1.4771687711138095
Validation loss: 2.7753203076862474

Epoch: 5| Step: 4
Training loss: 1.9244437070340532
Validation loss: 2.79502085811018

Epoch: 5| Step: 5
Training loss: 1.524871698829523
Validation loss: 2.902511098973544

Epoch: 5| Step: 6
Training loss: 1.7018495035660721
Validation loss: 2.920492514961803

Epoch: 5| Step: 7
Training loss: 1.8135834448258608
Validation loss: 2.8365257780976036

Epoch: 5| Step: 8
Training loss: 1.8443125496984891
Validation loss: 2.8335818796441217

Epoch: 5| Step: 9
Training loss: 1.1662187000093618
Validation loss: 2.833081221349909

Epoch: 5| Step: 10
Training loss: 1.1790597015679274
Validation loss: 2.786930975832715

Epoch: 5| Step: 11
Training loss: 1.4171491624048045
Validation loss: 2.8109367087877115

Epoch: 129| Step: 0
Training loss: 1.8809732658153429
Validation loss: 2.793366047804945

Epoch: 5| Step: 1
Training loss: 1.4114083941682078
Validation loss: 2.884060228695259

Epoch: 5| Step: 2
Training loss: 1.6233209592019913
Validation loss: 2.8172977992233204

Epoch: 5| Step: 3
Training loss: 1.6228894686429667
Validation loss: 2.821557619898507

Epoch: 5| Step: 4
Training loss: 2.143441011720999
Validation loss: 2.7814563360362543

Epoch: 5| Step: 5
Training loss: 1.4479261530650016
Validation loss: 2.7090812726282913

Epoch: 5| Step: 6
Training loss: 1.2246244633428043
Validation loss: 2.8084719104893594

Epoch: 5| Step: 7
Training loss: 1.0519451516433924
Validation loss: 2.8318347240090826

Epoch: 5| Step: 8
Training loss: 1.4300488291586677
Validation loss: 2.8432153157203524

Epoch: 5| Step: 9
Training loss: 1.6356545131587619
Validation loss: 2.773007562830384

Epoch: 5| Step: 10
Training loss: 1.1485869122320986
Validation loss: 2.8405687437792326

Epoch: 5| Step: 11
Training loss: 1.4848298028585738
Validation loss: 2.81374796977592

Epoch: 130| Step: 0
Training loss: 1.1333118784968044
Validation loss: 2.882228837030981

Epoch: 5| Step: 1
Training loss: 1.6891410759955718
Validation loss: 2.829768755185159

Epoch: 5| Step: 2
Training loss: 1.9739457853886373
Validation loss: 2.9157309507122613

Epoch: 5| Step: 3
Training loss: 1.2695270244821506
Validation loss: 2.9661634621614033

Epoch: 5| Step: 4
Training loss: 1.2017037555422259
Validation loss: 2.89640005601597

Epoch: 5| Step: 5
Training loss: 1.6345817799803488
Validation loss: 2.8780065482440422

Epoch: 5| Step: 6
Training loss: 1.341792965901329
Validation loss: 2.7897399806131498

Epoch: 5| Step: 7
Training loss: 1.5038677260183553
Validation loss: 2.733669782251475

Epoch: 5| Step: 8
Training loss: 1.8146534984642455
Validation loss: 2.666749715753601

Epoch: 5| Step: 9
Training loss: 1.4068825888376095
Validation loss: 2.7745745589066035

Epoch: 5| Step: 10
Training loss: 1.8097241290493835
Validation loss: 2.755005630122788

Epoch: 5| Step: 11
Training loss: 1.266596291912704
Validation loss: 2.690426312656213

Epoch: 131| Step: 0
Training loss: 1.5496976896006016
Validation loss: 2.781649400129112

Epoch: 5| Step: 1
Training loss: 1.3105599733883437
Validation loss: 2.8379641000714173

Epoch: 5| Step: 2
Training loss: 1.2545836333231513
Validation loss: 2.940424481297241

Epoch: 5| Step: 3
Training loss: 1.6725632151245127
Validation loss: 2.968836957093006

Epoch: 5| Step: 4
Training loss: 1.6846088084369555
Validation loss: 2.945907731625256

Epoch: 5| Step: 5
Training loss: 1.1698448907299652
Validation loss: 2.9033266425210766

Epoch: 5| Step: 6
Training loss: 1.6759898805016895
Validation loss: 2.8254420936031774

Epoch: 5| Step: 7
Training loss: 1.3179125219266452
Validation loss: 2.8734792336051576

Epoch: 5| Step: 8
Training loss: 1.400434208701141
Validation loss: 2.8045185395957195

Epoch: 5| Step: 9
Training loss: 2.1360400026697466
Validation loss: 2.6905146073672244

Epoch: 5| Step: 10
Training loss: 1.6479320022248822
Validation loss: 2.7079614946448904

Epoch: 5| Step: 11
Training loss: 1.0292896943683354
Validation loss: 2.804030700115559

Epoch: 132| Step: 0
Training loss: 1.220907795341877
Validation loss: 2.7638374845132403

Epoch: 5| Step: 1
Training loss: 1.5948117029620341
Validation loss: 2.6988678817776472

Epoch: 5| Step: 2
Training loss: 1.7013932269121086
Validation loss: 2.72791839886419

Epoch: 5| Step: 3
Training loss: 1.475082786305802
Validation loss: 2.711137824668453

Epoch: 5| Step: 4
Training loss: 1.5108171480170696
Validation loss: 2.7665374062591988

Epoch: 5| Step: 5
Training loss: 1.2457563846431414
Validation loss: 2.826787639428842

Epoch: 5| Step: 6
Training loss: 1.5652440199567919
Validation loss: 2.859397568465979

Epoch: 5| Step: 7
Training loss: 2.088041694392905
Validation loss: 3.0438055341486083

Epoch: 5| Step: 8
Training loss: 1.727043671683663
Validation loss: 3.0957759619967877

Epoch: 5| Step: 9
Training loss: 2.156684057803346
Validation loss: 3.0910929177481137

Epoch: 5| Step: 10
Training loss: 1.585495083741428
Validation loss: 3.066454180365146

Epoch: 5| Step: 11
Training loss: 0.9878805199977762
Validation loss: 2.9098591356277486

Epoch: 133| Step: 0
Training loss: 1.4013645929717924
Validation loss: 2.8391217516865956

Epoch: 5| Step: 1
Training loss: 1.6312967227953148
Validation loss: 2.794303486192706

Epoch: 5| Step: 2
Training loss: 1.1318429415126527
Validation loss: 2.7422133876524097

Epoch: 5| Step: 3
Training loss: 2.1768927483132217
Validation loss: 2.7655664642518683

Epoch: 5| Step: 4
Training loss: 1.8418772610125274
Validation loss: 2.70349226277658

Epoch: 5| Step: 5
Training loss: 1.7988844540668119
Validation loss: 2.78746770004695

Epoch: 5| Step: 6
Training loss: 1.5659242111857177
Validation loss: 2.7105426262555006

Epoch: 5| Step: 7
Training loss: 1.0910504951190276
Validation loss: 2.776985613932085

Epoch: 5| Step: 8
Training loss: 1.842893886622302
Validation loss: 2.911926161428569

Epoch: 5| Step: 9
Training loss: 1.1052993267159779
Validation loss: 3.0292710107010317

Epoch: 5| Step: 10
Training loss: 1.3590006696574488
Validation loss: 3.0784150324211894

Epoch: 5| Step: 11
Training loss: 2.041418826053159
Validation loss: 3.07145512085959

Epoch: 134| Step: 0
Training loss: 1.660105051485346
Validation loss: 3.0919880746635724

Epoch: 5| Step: 1
Training loss: 1.1111622772091954
Validation loss: 3.017118090939637

Epoch: 5| Step: 2
Training loss: 1.8603449623611594
Validation loss: 2.9234879371618634

Epoch: 5| Step: 3
Training loss: 1.1747984469811654
Validation loss: 2.7413528237147062

Epoch: 5| Step: 4
Training loss: 1.56889241092696
Validation loss: 2.7009831875434727

Epoch: 5| Step: 5
Training loss: 1.622439788500507
Validation loss: 2.7338820585336157

Epoch: 5| Step: 6
Training loss: 1.2621329368817031
Validation loss: 2.701812682840966

Epoch: 5| Step: 7
Training loss: 2.026658958663002
Validation loss: 2.6880082825237914

Epoch: 5| Step: 8
Training loss: 1.4255457853512852
Validation loss: 2.723121986343716

Epoch: 5| Step: 9
Training loss: 1.5700928643576817
Validation loss: 2.6461095565625636

Epoch: 5| Step: 10
Training loss: 1.8276693966446438
Validation loss: 2.731705163263934

Epoch: 5| Step: 11
Training loss: 1.6477009361577903
Validation loss: 2.7275043835445927

Epoch: 135| Step: 0
Training loss: 1.2757917302128097
Validation loss: 2.7473866334492953

Epoch: 5| Step: 1
Training loss: 1.4064297031447022
Validation loss: 2.673133828689139

Epoch: 5| Step: 2
Training loss: 1.2073929624326172
Validation loss: 2.6755089094507563

Epoch: 5| Step: 3
Training loss: 1.0023056510648003
Validation loss: 2.6598462387689117

Epoch: 5| Step: 4
Training loss: 1.8782105615202924
Validation loss: 2.8230792675602916

Epoch: 5| Step: 5
Training loss: 1.010407116769447
Validation loss: 2.7555756903903172

Epoch: 5| Step: 6
Training loss: 2.17360415337383
Validation loss: 2.751306429400835

Epoch: 5| Step: 7
Training loss: 1.752065121272171
Validation loss: 2.735426658753514

Epoch: 5| Step: 8
Training loss: 1.5877256788704415
Validation loss: 2.8219487453440895

Epoch: 5| Step: 9
Training loss: 1.6626312835026267
Validation loss: 2.755405950159607

Epoch: 5| Step: 10
Training loss: 1.1362580089895336
Validation loss: 2.796284938350129

Epoch: 5| Step: 11
Training loss: 1.5168841922137268
Validation loss: 2.7251830195581626

Epoch: 136| Step: 0
Training loss: 1.5566940011286818
Validation loss: 2.746470878103846

Epoch: 5| Step: 1
Training loss: 1.4975124236341408
Validation loss: 2.7361534329727313

Epoch: 5| Step: 2
Training loss: 1.289349240865346
Validation loss: 2.763534014063733

Epoch: 5| Step: 3
Training loss: 0.9950202093516128
Validation loss: 2.7092409092663

Epoch: 5| Step: 4
Training loss: 2.283921023658561
Validation loss: 2.772076099789018

Epoch: 5| Step: 5
Training loss: 1.3409721583037073
Validation loss: 2.750848371962894

Epoch: 5| Step: 6
Training loss: 1.397845308024139
Validation loss: 2.73729185840124

Epoch: 5| Step: 7
Training loss: 1.2925681793116157
Validation loss: 2.806259883361948

Epoch: 5| Step: 8
Training loss: 1.3758304429019084
Validation loss: 2.830061353270032

Epoch: 5| Step: 9
Training loss: 1.8224707648466416
Validation loss: 2.814634057431935

Epoch: 5| Step: 10
Training loss: 0.8961815748603467
Validation loss: 2.862648058203694

Epoch: 5| Step: 11
Training loss: 1.6308704124579718
Validation loss: 2.906801270598575

Epoch: 137| Step: 0
Training loss: 0.8470344900024575
Validation loss: 2.959322895959608

Epoch: 5| Step: 1
Training loss: 1.2669842332402397
Validation loss: 3.003260059740057

Epoch: 5| Step: 2
Training loss: 1.7589265810904746
Validation loss: 3.077179755549175

Epoch: 5| Step: 3
Training loss: 1.102411308354178
Validation loss: 2.9370330615284206

Epoch: 5| Step: 4
Training loss: 1.809421226424859
Validation loss: 2.8855168684397663

Epoch: 5| Step: 5
Training loss: 1.2521468799648614
Validation loss: 2.735553905117239

Epoch: 5| Step: 6
Training loss: 1.5967071624165174
Validation loss: 2.7811160394646333

Epoch: 5| Step: 7
Training loss: 1.3842464705965292
Validation loss: 2.6895058228965785

Epoch: 5| Step: 8
Training loss: 1.7571253811125578
Validation loss: 2.679073552569728

Epoch: 5| Step: 9
Training loss: 1.4896511071354896
Validation loss: 2.721692133942227

Epoch: 5| Step: 10
Training loss: 1.6243271535099197
Validation loss: 2.7622616174528205

Epoch: 5| Step: 11
Training loss: 2.398996095502315
Validation loss: 2.744769978784417

Epoch: 138| Step: 0
Training loss: 1.4047530365826397
Validation loss: 2.7953408756027742

Epoch: 5| Step: 1
Training loss: 1.7969157338708368
Validation loss: 2.9153891535830048

Epoch: 5| Step: 2
Training loss: 1.72514692593012
Validation loss: 3.0535558179904077

Epoch: 5| Step: 3
Training loss: 1.5305869554843823
Validation loss: 3.135628051011181

Epoch: 5| Step: 4
Training loss: 1.5389040173101791
Validation loss: 3.1609929646710686

Epoch: 5| Step: 5
Training loss: 1.5089851523566953
Validation loss: 3.047408981481777

Epoch: 5| Step: 6
Training loss: 1.2278975006685746
Validation loss: 2.8815822888268396

Epoch: 5| Step: 7
Training loss: 1.3615754831818827
Validation loss: 2.8304885696501993

Epoch: 5| Step: 8
Training loss: 1.5793110384743558
Validation loss: 2.7442312169082785

Epoch: 5| Step: 9
Training loss: 1.6996570241180393
Validation loss: 2.7633492505010473

Epoch: 5| Step: 10
Training loss: 1.6259046384007942
Validation loss: 2.7549573907828395

Epoch: 5| Step: 11
Training loss: 1.580357398401814
Validation loss: 2.6871075121804773

Epoch: 139| Step: 0
Training loss: 1.2468246182084137
Validation loss: 2.741736832380799

Epoch: 5| Step: 1
Training loss: 1.273864955188346
Validation loss: 2.723493347937678

Epoch: 5| Step: 2
Training loss: 1.112288343461874
Validation loss: 2.7226944696780437

Epoch: 5| Step: 3
Training loss: 1.1742469687760788
Validation loss: 2.8659434794336307

Epoch: 5| Step: 4
Training loss: 1.0291936775606358
Validation loss: 2.9086367982104893

Epoch: 5| Step: 5
Training loss: 1.5656888845966843
Validation loss: 2.888233074969293

Epoch: 5| Step: 6
Training loss: 1.4793889680113563
Validation loss: 2.9409113582051427

Epoch: 5| Step: 7
Training loss: 1.5869243539329752
Validation loss: 2.776526583509216

Epoch: 5| Step: 8
Training loss: 1.0973454371345257
Validation loss: 2.8343954246090717

Epoch: 5| Step: 9
Training loss: 1.410683192657186
Validation loss: 2.8825679113599283

Epoch: 5| Step: 10
Training loss: 2.033300216071586
Validation loss: 2.8400401520185348

Epoch: 5| Step: 11
Training loss: 2.0259809967083693
Validation loss: 2.841760019454459

Epoch: 140| Step: 0
Training loss: 1.35138996765017
Validation loss: 2.7427817676148494

Epoch: 5| Step: 1
Training loss: 1.9206128201407269
Validation loss: 2.713672269922999

Epoch: 5| Step: 2
Training loss: 1.6410427469919344
Validation loss: 2.68796511624801

Epoch: 5| Step: 3
Training loss: 1.2297204542773248
Validation loss: 2.762073977806493

Epoch: 5| Step: 4
Training loss: 1.162955250352265
Validation loss: 2.7419849947705

Epoch: 5| Step: 5
Training loss: 1.2700991724746684
Validation loss: 2.8046767253190605

Epoch: 5| Step: 6
Training loss: 1.290148468345227
Validation loss: 2.95246789743067

Epoch: 5| Step: 7
Training loss: 2.131935470291562
Validation loss: 3.054385099540672

Epoch: 5| Step: 8
Training loss: 1.7607778671466403
Validation loss: 2.950318834887729

Epoch: 5| Step: 9
Training loss: 1.106902362263425
Validation loss: 2.9054893161271123

Epoch: 5| Step: 10
Training loss: 1.4104570823449698
Validation loss: 2.7900801368425343

Epoch: 5| Step: 11
Training loss: 0.7321807057370309
Validation loss: 2.705481386022079

Epoch: 141| Step: 0
Training loss: 1.763797455601404
Validation loss: 2.6800113256177203

Epoch: 5| Step: 1
Training loss: 1.2817873874521741
Validation loss: 2.7309145874966627

Epoch: 5| Step: 2
Training loss: 1.233141077152401
Validation loss: 2.6596673300490044

Epoch: 5| Step: 3
Training loss: 1.4942536753851328
Validation loss: 2.7455159353119014

Epoch: 5| Step: 4
Training loss: 1.3212439507496632
Validation loss: 2.7553907609240267

Epoch: 5| Step: 5
Training loss: 1.1867067799771251
Validation loss: 2.8505411417901176

Epoch: 5| Step: 6
Training loss: 1.244207982226645
Validation loss: 2.8309775766672445

Epoch: 5| Step: 7
Training loss: 2.060199842111152
Validation loss: 3.0249864026229054

Epoch: 5| Step: 8
Training loss: 1.73109331764693
Validation loss: 3.090465401134107

Epoch: 5| Step: 9
Training loss: 1.3384527877016474
Validation loss: 3.0017333950287592

Epoch: 5| Step: 10
Training loss: 1.7871200477823381
Validation loss: 2.95209471072901

Epoch: 5| Step: 11
Training loss: 1.1197518748229152
Validation loss: 2.900124835884543

Epoch: 142| Step: 0
Training loss: 1.7505518179499517
Validation loss: 2.8147038937736384

Epoch: 5| Step: 1
Training loss: 1.665473304124599
Validation loss: 2.7572292291027956

Epoch: 5| Step: 2
Training loss: 1.3460907177218457
Validation loss: 2.7297850131584767

Epoch: 5| Step: 3
Training loss: 1.4102592958963212
Validation loss: 2.701126388788355

Epoch: 5| Step: 4
Training loss: 1.290386098405816
Validation loss: 2.6774017401912835

Epoch: 5| Step: 5
Training loss: 1.4226130152694334
Validation loss: 2.740681121292156

Epoch: 5| Step: 6
Training loss: 1.1992663644290837
Validation loss: 2.8120206283072267

Epoch: 5| Step: 7
Training loss: 1.3904142327192566
Validation loss: 2.775393237927697

Epoch: 5| Step: 8
Training loss: 1.250204975488331
Validation loss: 2.7811110565397468

Epoch: 5| Step: 9
Training loss: 0.8128516463283759
Validation loss: 2.7295616727934333

Epoch: 5| Step: 10
Training loss: 1.4267692591568975
Validation loss: 2.8693813519887734

Epoch: 5| Step: 11
Training loss: 0.8148561939375566
Validation loss: 2.841422518862856

Epoch: 143| Step: 0
Training loss: 1.0077262072620694
Validation loss: 2.8822669432231933

Epoch: 5| Step: 1
Training loss: 2.228681125229197
Validation loss: 3.007338835836651

Epoch: 5| Step: 2
Training loss: 1.663467157455324
Validation loss: 3.031433552169329

Epoch: 5| Step: 3
Training loss: 1.416435316306234
Validation loss: 3.0181278193093255

Epoch: 5| Step: 4
Training loss: 1.0502051720662746
Validation loss: 2.9196273263896226

Epoch: 5| Step: 5
Training loss: 1.3458855094283226
Validation loss: 2.802824590030766

Epoch: 5| Step: 6
Training loss: 1.3481802543596457
Validation loss: 2.8057772963985443

Epoch: 5| Step: 7
Training loss: 1.2281058254152548
Validation loss: 2.7517949156523196

Epoch: 5| Step: 8
Training loss: 1.4740005145647868
Validation loss: 2.6875499195815067

Epoch: 5| Step: 9
Training loss: 1.2839236856432414
Validation loss: 2.6993790766149464

Epoch: 5| Step: 10
Training loss: 1.5787992642192417
Validation loss: 2.6941536443859517

Epoch: 5| Step: 11
Training loss: 2.238022181778548
Validation loss: 2.6627165637645085

Epoch: 144| Step: 0
Training loss: 1.3871379379902493
Validation loss: 2.7218765755147714

Epoch: 5| Step: 1
Training loss: 1.4126527197318728
Validation loss: 2.651477606753208

Epoch: 5| Step: 2
Training loss: 1.3197962186032837
Validation loss: 2.8036047528837322

Epoch: 5| Step: 3
Training loss: 1.7748024682826309
Validation loss: 2.947489735631567

Epoch: 5| Step: 4
Training loss: 1.2515438559449592
Validation loss: 2.9694978207127742

Epoch: 5| Step: 5
Training loss: 1.585202051274688
Validation loss: 2.9335615255361245

Epoch: 5| Step: 6
Training loss: 1.1971145210934726
Validation loss: 2.9014397878175817

Epoch: 5| Step: 7
Training loss: 1.9044444178619937
Validation loss: 2.869958268099216

Epoch: 5| Step: 8
Training loss: 1.270525545880517
Validation loss: 2.785852157161363

Epoch: 5| Step: 9
Training loss: 1.309617510349725
Validation loss: 2.7641705372025864

Epoch: 5| Step: 10
Training loss: 1.1042865052358728
Validation loss: 2.726933094332324

Epoch: 5| Step: 11
Training loss: 0.758734230996284
Validation loss: 2.7702591607096947

Epoch: 145| Step: 0
Training loss: 1.229391055988912
Validation loss: 2.699601867103063

Epoch: 5| Step: 1
Training loss: 1.421124102838216
Validation loss: 2.7524249879569442

Epoch: 5| Step: 2
Training loss: 1.373995761009685
Validation loss: 2.694062555889304

Epoch: 5| Step: 3
Training loss: 1.2933453705725637
Validation loss: 2.7849768767661085

Epoch: 5| Step: 4
Training loss: 1.3140517099416034
Validation loss: 2.8511532947140266

Epoch: 5| Step: 5
Training loss: 1.6379227682171602
Validation loss: 2.8628566820954693

Epoch: 5| Step: 6
Training loss: 0.8148130723805372
Validation loss: 2.826072568099952

Epoch: 5| Step: 7
Training loss: 1.5010923540750738
Validation loss: 2.832164826147858

Epoch: 5| Step: 8
Training loss: 1.3359222411237952
Validation loss: 2.782044332991813

Epoch: 5| Step: 9
Training loss: 1.6017554190210443
Validation loss: 2.8148529735833687

Epoch: 5| Step: 10
Training loss: 1.2798965562804059
Validation loss: 2.874813167057507

Epoch: 5| Step: 11
Training loss: 0.3620258296648045
Validation loss: 2.8455824415125988

Epoch: 146| Step: 0
Training loss: 1.2733776803973769
Validation loss: 2.79929218584512

Epoch: 5| Step: 1
Training loss: 1.425677988153837
Validation loss: 2.761594335189719

Epoch: 5| Step: 2
Training loss: 1.0617705814602414
Validation loss: 2.857809711869988

Epoch: 5| Step: 3
Training loss: 0.8933127487418204
Validation loss: 2.8200222193573077

Epoch: 5| Step: 4
Training loss: 2.137154654997776
Validation loss: 2.816609379272322

Epoch: 5| Step: 5
Training loss: 1.3785481622865823
Validation loss: 2.9305776981423204

Epoch: 5| Step: 6
Training loss: 1.0865183861515804
Validation loss: 2.865835572704325

Epoch: 5| Step: 7
Training loss: 1.296566248529973
Validation loss: 2.8307004726514946

Epoch: 5| Step: 8
Training loss: 1.6022975816403815
Validation loss: 2.7678924539982734

Epoch: 5| Step: 9
Training loss: 1.2204807902992332
Validation loss: 2.78785200234352

Epoch: 5| Step: 10
Training loss: 1.2774251276161117
Validation loss: 2.7839880620565274

Epoch: 5| Step: 11
Training loss: 0.8980756611501781
Validation loss: 2.83366799949238

Epoch: 147| Step: 0
Training loss: 1.2964595910692047
Validation loss: 2.863240368782387

Epoch: 5| Step: 1
Training loss: 1.1323403788701036
Validation loss: 2.824327142305348

Epoch: 5| Step: 2
Training loss: 1.2632135565366727
Validation loss: 2.785291400071814

Epoch: 5| Step: 3
Training loss: 1.266132017703874
Validation loss: 2.8598482438653288

Epoch: 5| Step: 4
Training loss: 1.3971273155961135
Validation loss: 2.8804771937084537

Epoch: 5| Step: 5
Training loss: 1.062607030526555
Validation loss: 2.876272887252559

Epoch: 5| Step: 6
Training loss: 0.9923465030651798
Validation loss: 2.818253435631866

Epoch: 5| Step: 7
Training loss: 1.2022822512439368
Validation loss: 2.8067666319485736

Epoch: 5| Step: 8
Training loss: 1.3864149593654518
Validation loss: 2.7967525540619222

Epoch: 5| Step: 9
Training loss: 1.2514141190065102
Validation loss: 2.8384668684504066

Epoch: 5| Step: 10
Training loss: 2.0402082826836474
Validation loss: 2.8337882596492716

Epoch: 5| Step: 11
Training loss: 1.7537658227382122
Validation loss: 2.910865850790276

Epoch: 148| Step: 0
Training loss: 1.554083932237484
Validation loss: 2.9447539024958687

Epoch: 5| Step: 1
Training loss: 1.0248515137839118
Validation loss: 2.9895835648291804

Epoch: 5| Step: 2
Training loss: 0.7267151128808724
Validation loss: 2.910772926482074

Epoch: 5| Step: 3
Training loss: 1.6418915718790243
Validation loss: 2.8694279204224453

Epoch: 5| Step: 4
Training loss: 1.450654174958352
Validation loss: 2.9182949334941846

Epoch: 5| Step: 5
Training loss: 1.6419174190018002
Validation loss: 2.8125082051192796

Epoch: 5| Step: 6
Training loss: 1.0078353287824438
Validation loss: 2.7455366789623756

Epoch: 5| Step: 7
Training loss: 1.6204492965529576
Validation loss: 2.8536125582663665

Epoch: 5| Step: 8
Training loss: 1.3269773124531945
Validation loss: 2.8167220532503787

Epoch: 5| Step: 9
Training loss: 1.3013179462293794
Validation loss: 2.833802164548638

Epoch: 5| Step: 10
Training loss: 1.105465838425108
Validation loss: 2.8979214125694246

Epoch: 5| Step: 11
Training loss: 1.3765539145228993
Validation loss: 2.8482142923340583

Epoch: 149| Step: 0
Training loss: 1.2545932777151718
Validation loss: 2.799584328502265

Epoch: 5| Step: 1
Training loss: 1.1555629957450675
Validation loss: 2.9300837202230197

Epoch: 5| Step: 2
Training loss: 1.6495434996531388
Validation loss: 2.9514669476577233

Epoch: 5| Step: 3
Training loss: 1.2280564655468458
Validation loss: 2.935988087850177

Epoch: 5| Step: 4
Training loss: 1.3200790830966425
Validation loss: 2.885738149469071

Epoch: 5| Step: 5
Training loss: 1.251215058104644
Validation loss: 2.83129410895317

Epoch: 5| Step: 6
Training loss: 1.6955823551697045
Validation loss: 2.8341482453802396

Epoch: 5| Step: 7
Training loss: 0.8642713987500261
Validation loss: 2.7784053921312926

Epoch: 5| Step: 8
Training loss: 0.8323775094792601
Validation loss: 2.7948092854034865

Epoch: 5| Step: 9
Training loss: 1.62196168759744
Validation loss: 2.747949373910029

Epoch: 5| Step: 10
Training loss: 1.3018103300634467
Validation loss: 2.8573447421534888

Epoch: 5| Step: 11
Training loss: 1.3258266533364254
Validation loss: 2.8712658266155278

Epoch: 150| Step: 0
Training loss: 1.9079592186750096
Validation loss: 2.9106181108905025

Epoch: 5| Step: 1
Training loss: 1.2384041806401798
Validation loss: 2.995054397115545

Epoch: 5| Step: 2
Training loss: 1.122807804037329
Validation loss: 3.094535609082281

Epoch: 5| Step: 3
Training loss: 1.3083476731958172
Validation loss: 3.0900767029961123

Epoch: 5| Step: 4
Training loss: 2.028843084563167
Validation loss: 3.0730595517748642

Epoch: 5| Step: 5
Training loss: 1.4389395761747037
Validation loss: 2.9097916649933384

Epoch: 5| Step: 6
Training loss: 1.0892602048741267
Validation loss: 2.8008428377964236

Epoch: 5| Step: 7
Training loss: 1.3213451342586617
Validation loss: 2.7864664784725375

Epoch: 5| Step: 8
Training loss: 1.198229851072396
Validation loss: 2.6037065913378457

Epoch: 5| Step: 9
Training loss: 1.5239490139359702
Validation loss: 2.748610463355692

Epoch: 5| Step: 10
Training loss: 0.8874718916834139
Validation loss: 2.7355506258894384

Epoch: 5| Step: 11
Training loss: 2.123347818194478
Validation loss: 2.7474285117762602

Epoch: 151| Step: 0
Training loss: 1.4682701625650951
Validation loss: 2.700616582253952

Epoch: 5| Step: 1
Training loss: 1.2138292302084084
Validation loss: 2.709191455365861

Epoch: 5| Step: 2
Training loss: 1.1162005780290816
Validation loss: 2.8286046733096355

Epoch: 5| Step: 3
Training loss: 0.851267877410616
Validation loss: 2.8540488460103757

Epoch: 5| Step: 4
Training loss: 0.9426889821519981
Validation loss: 2.816402853277224

Epoch: 5| Step: 5
Training loss: 1.7116079192710938
Validation loss: 2.910227286135338

Epoch: 5| Step: 6
Training loss: 1.1478735129292645
Validation loss: 2.950611201779742

Epoch: 5| Step: 7
Training loss: 2.164382525306197
Validation loss: 2.980375639268082

Epoch: 5| Step: 8
Training loss: 1.1968938303131005
Validation loss: 2.815307552790465

Epoch: 5| Step: 9
Training loss: 1.1342075571111454
Validation loss: 2.8558915708425694

Epoch: 5| Step: 10
Training loss: 1.3131017213888712
Validation loss: 2.784357899029268

Epoch: 5| Step: 11
Training loss: 1.1648027255473108
Validation loss: 2.720451650067867

Epoch: 152| Step: 0
Training loss: 1.5734158496446786
Validation loss: 2.7085552980480814

Epoch: 5| Step: 1
Training loss: 1.2173670233576708
Validation loss: 2.6887490896155155

Epoch: 5| Step: 2
Training loss: 0.9771526537111718
Validation loss: 2.799248215959176

Epoch: 5| Step: 3
Training loss: 1.2983714283131715
Validation loss: 2.8340791125141376

Epoch: 5| Step: 4
Training loss: 1.3159268012661602
Validation loss: 2.7948846288047946

Epoch: 5| Step: 5
Training loss: 1.1270391209945088
Validation loss: 2.7983996144677885

Epoch: 5| Step: 6
Training loss: 1.4890869843110182
Validation loss: 2.912465306376928

Epoch: 5| Step: 7
Training loss: 1.2258038938727192
Validation loss: 2.8424448242496867

Epoch: 5| Step: 8
Training loss: 1.5273609989684966
Validation loss: 2.755632888207004

Epoch: 5| Step: 9
Training loss: 1.8542238576691232
Validation loss: 2.788413145836851

Epoch: 5| Step: 10
Training loss: 1.2242318625560373
Validation loss: 2.8956292146788885

Epoch: 5| Step: 11
Training loss: 0.9320624973785947
Validation loss: 2.8262836334901986

Epoch: 153| Step: 0
Training loss: 0.7924624926960374
Validation loss: 2.7243517208074723

Epoch: 5| Step: 1
Training loss: 1.225748460183994
Validation loss: 2.755546121256412

Epoch: 5| Step: 2
Training loss: 0.9192668745407724
Validation loss: 2.712461927911452

Epoch: 5| Step: 3
Training loss: 2.051700756472568
Validation loss: 2.7115318277143974

Epoch: 5| Step: 4
Training loss: 1.2049898829371792
Validation loss: 2.7740199234175256

Epoch: 5| Step: 5
Training loss: 1.5670374789938144
Validation loss: 2.889267387847894

Epoch: 5| Step: 6
Training loss: 0.8898957261604127
Validation loss: 2.730921426267355

Epoch: 5| Step: 7
Training loss: 1.2943592258820251
Validation loss: 2.6994141739333557

Epoch: 5| Step: 8
Training loss: 0.7688305370663938
Validation loss: 2.805093599492893

Epoch: 5| Step: 9
Training loss: 1.2725034225058105
Validation loss: 2.76669947267715

Epoch: 5| Step: 10
Training loss: 1.164227877140682
Validation loss: 2.82090209616991

Epoch: 5| Step: 11
Training loss: 1.6081602085735143
Validation loss: 2.8775153006846437

Epoch: 154| Step: 0
Training loss: 1.8360794986434397
Validation loss: 2.8440794387143624

Epoch: 5| Step: 1
Training loss: 1.424070989044784
Validation loss: 2.878523578167773

Epoch: 5| Step: 2
Training loss: 1.3943114548262494
Validation loss: 2.82927921269815

Epoch: 5| Step: 3
Training loss: 1.3568439817814746
Validation loss: 2.79809918597705

Epoch: 5| Step: 4
Training loss: 1.063887139433199
Validation loss: 2.8055794412448045

Epoch: 5| Step: 5
Training loss: 1.3338439778161357
Validation loss: 2.8266448262521013

Epoch: 5| Step: 6
Training loss: 0.7532180253822137
Validation loss: 2.83415017671582

Epoch: 5| Step: 7
Training loss: 1.2168531573215642
Validation loss: 2.7861040490260516

Epoch: 5| Step: 8
Training loss: 1.1218647183342947
Validation loss: 2.790896363999362

Epoch: 5| Step: 9
Training loss: 1.465144337649115
Validation loss: 2.86027354312767

Epoch: 5| Step: 10
Training loss: 0.9688056191505878
Validation loss: 2.8211285580790912

Epoch: 5| Step: 11
Training loss: 0.864788931028456
Validation loss: 2.866034009802668

Epoch: 155| Step: 0
Training loss: 1.335153807162957
Validation loss: 2.9454239723838795

Epoch: 5| Step: 1
Training loss: 1.3262230662380345
Validation loss: 2.7874843146505803

Epoch: 5| Step: 2
Training loss: 1.3214976392097761
Validation loss: 2.8319813235036584

Epoch: 5| Step: 3
Training loss: 1.4949975043693815
Validation loss: 2.8115904891584855

Epoch: 5| Step: 4
Training loss: 0.6759163164760187
Validation loss: 2.824799674451086

Epoch: 5| Step: 5
Training loss: 1.7580059707982867
Validation loss: 2.791527936226018

Epoch: 5| Step: 6
Training loss: 1.203513194288791
Validation loss: 2.7484716590029463

Epoch: 5| Step: 7
Training loss: 1.175833463301585
Validation loss: 2.7386963366891135

Epoch: 5| Step: 8
Training loss: 0.9988759398997189
Validation loss: 2.766079389381909

Epoch: 5| Step: 9
Training loss: 1.6036106318440373
Validation loss: 2.80921988124419

Epoch: 5| Step: 10
Training loss: 1.0234005753939535
Validation loss: 2.7618342676243053

Epoch: 5| Step: 11
Training loss: 0.4603272293645099
Validation loss: 2.797397976646438

Epoch: 156| Step: 0
Training loss: 1.4695650639311875
Validation loss: 2.826948490220725

Epoch: 5| Step: 1
Training loss: 1.333581687725202
Validation loss: 2.891976028754141

Epoch: 5| Step: 2
Training loss: 1.069224953662001
Validation loss: 2.825337358603131

Epoch: 5| Step: 3
Training loss: 0.9623788398183476
Validation loss: 2.8322065347380305

Epoch: 5| Step: 4
Training loss: 0.8086404832981328
Validation loss: 2.8961270661346217

Epoch: 5| Step: 5
Training loss: 0.8909321305599198
Validation loss: 2.78337681635471

Epoch: 5| Step: 6
Training loss: 1.6990926059948404
Validation loss: 2.833706043543599

Epoch: 5| Step: 7
Training loss: 1.1565884275295124
Validation loss: 2.7922957349739663

Epoch: 5| Step: 8
Training loss: 1.025294998796239
Validation loss: 2.8467390923384195

Epoch: 5| Step: 9
Training loss: 1.2196093244077932
Validation loss: 2.840213403513746

Epoch: 5| Step: 10
Training loss: 1.5326891772699653
Validation loss: 2.752045260985912

Epoch: 5| Step: 11
Training loss: 1.1577773445341732
Validation loss: 2.7684547509439885

Epoch: 157| Step: 0
Training loss: 1.2188615992387137
Validation loss: 2.792883299474076

Epoch: 5| Step: 1
Training loss: 1.600843165677066
Validation loss: 2.9646021560657587

Epoch: 5| Step: 2
Training loss: 1.2552981628100637
Validation loss: 2.926301340377635

Epoch: 5| Step: 3
Training loss: 1.2956688109009586
Validation loss: 2.8463277940613203

Epoch: 5| Step: 4
Training loss: 1.1059654387097653
Validation loss: 2.9574932676428394

Epoch: 5| Step: 5
Training loss: 0.9414954875264588
Validation loss: 2.814612891246477

Epoch: 5| Step: 6
Training loss: 1.5108308772245804
Validation loss: 2.8930177991944532

Epoch: 5| Step: 7
Training loss: 1.5148177996060839
Validation loss: 2.8746897747761886

Epoch: 5| Step: 8
Training loss: 0.7065001120813582
Validation loss: 2.853882804500703

Epoch: 5| Step: 9
Training loss: 1.2518000992733023
Validation loss: 2.8870553976215807

Epoch: 5| Step: 10
Training loss: 1.2135834366099991
Validation loss: 2.7958561623935094

Epoch: 5| Step: 11
Training loss: 0.8389585931469844
Validation loss: 2.76849453079738

Epoch: 158| Step: 0
Training loss: 0.7584273606649367
Validation loss: 2.8618702866331542

Epoch: 5| Step: 1
Training loss: 1.5256752207802873
Validation loss: 2.960987704613849

Epoch: 5| Step: 2
Training loss: 1.8707733198479073
Validation loss: 2.899475480745354

Epoch: 5| Step: 3
Training loss: 1.3047808311110347
Validation loss: 2.911387104307294

Epoch: 5| Step: 4
Training loss: 1.0466179603331713
Validation loss: 2.9296115204177537

Epoch: 5| Step: 5
Training loss: 1.1740453331885077
Validation loss: 2.862020349365353

Epoch: 5| Step: 6
Training loss: 0.7547586000804806
Validation loss: 2.794950565499217

Epoch: 5| Step: 7
Training loss: 1.0864047136300015
Validation loss: 2.7075880101048577

Epoch: 5| Step: 8
Training loss: 0.8902116452069272
Validation loss: 2.803234446503603

Epoch: 5| Step: 9
Training loss: 1.2681465461445984
Validation loss: 2.7627830343117403

Epoch: 5| Step: 10
Training loss: 1.4144938954248236
Validation loss: 2.8235324326448197

Epoch: 5| Step: 11
Training loss: 0.9057036101011637
Validation loss: 2.799598433445376

Epoch: 159| Step: 0
Training loss: 0.8743768243995595
Validation loss: 2.9037722960617964

Epoch: 5| Step: 1
Training loss: 1.263645460745959
Validation loss: 2.9938722586836963

Epoch: 5| Step: 2
Training loss: 1.419265532410781
Validation loss: 3.0214298360908467

Epoch: 5| Step: 3
Training loss: 1.8772598635203188
Validation loss: 2.91815965905451

Epoch: 5| Step: 4
Training loss: 1.0590442670083897
Validation loss: 2.838417139150761

Epoch: 5| Step: 5
Training loss: 1.5318781284532232
Validation loss: 2.7278405976739375

Epoch: 5| Step: 6
Training loss: 0.9086100333305344
Validation loss: 2.8249239570938243

Epoch: 5| Step: 7
Training loss: 1.4002127860350895
Validation loss: 2.7698551844017993

Epoch: 5| Step: 8
Training loss: 1.2004579484844136
Validation loss: 2.8544178641012943

Epoch: 5| Step: 9
Training loss: 1.3240205509544292
Validation loss: 2.8163442194823043

Epoch: 5| Step: 10
Training loss: 0.906306626754049
Validation loss: 2.8391310625294985

Epoch: 5| Step: 11
Training loss: 0.6679359561834147
Validation loss: 2.890822206248333

Epoch: 160| Step: 0
Training loss: 1.3432469868103458
Validation loss: 2.8884004057385986

Epoch: 5| Step: 1
Training loss: 0.7317167422755619
Validation loss: 2.8989846363489513

Epoch: 5| Step: 2
Training loss: 1.6765911572683339
Validation loss: 2.9323329832284166

Epoch: 5| Step: 3
Training loss: 1.4607148842339017
Validation loss: 2.8956753232554355

Epoch: 5| Step: 4
Training loss: 1.0892258947059035
Validation loss: 2.8876768904334758

Epoch: 5| Step: 5
Training loss: 0.8486485101193985
Validation loss: 2.7871414571233073

Epoch: 5| Step: 6
Training loss: 0.7721682450947834
Validation loss: 2.7985083039465946

Epoch: 5| Step: 7
Training loss: 2.0965561921449396
Validation loss: 2.723527558195174

Epoch: 5| Step: 8
Training loss: 0.8775866286943057
Validation loss: 2.6940354643674898

Epoch: 5| Step: 9
Training loss: 0.9568413059374461
Validation loss: 2.7793515616188462

Epoch: 5| Step: 10
Training loss: 0.9328319681714335
Validation loss: 2.843373333085756

Epoch: 5| Step: 11
Training loss: 1.6740987374230953
Validation loss: 2.8714189721501477

Epoch: 161| Step: 0
Training loss: 1.1272019982522616
Validation loss: 2.8678611203133677

Epoch: 5| Step: 1
Training loss: 1.0151660175508253
Validation loss: 2.8743395426831055

Epoch: 5| Step: 2
Training loss: 1.3430622026151222
Validation loss: 2.967834177469927

Epoch: 5| Step: 3
Training loss: 1.0861171875632203
Validation loss: 2.8608037231547137

Epoch: 5| Step: 4
Training loss: 1.0854121522327538
Validation loss: 2.8703019103365555

Epoch: 5| Step: 5
Training loss: 1.4632130408899435
Validation loss: 2.843138478799857

Epoch: 5| Step: 6
Training loss: 0.995757730691999
Validation loss: 2.7597142939418218

Epoch: 5| Step: 7
Training loss: 1.9974374447648922
Validation loss: 2.840019031766468

Epoch: 5| Step: 8
Training loss: 1.2042172910791105
Validation loss: 2.7851514241095168

Epoch: 5| Step: 9
Training loss: 1.0329000392640884
Validation loss: 2.858051452324399

Epoch: 5| Step: 10
Training loss: 1.200758005188994
Validation loss: 2.808165024535047

Epoch: 5| Step: 11
Training loss: 0.46455201041969374
Validation loss: 2.9205751944861995

Epoch: 162| Step: 0
Training loss: 1.1641639818849145
Validation loss: 2.895425168552525

Epoch: 5| Step: 1
Training loss: 1.8525034770855724
Validation loss: 2.8813863188297986

Epoch: 5| Step: 2
Training loss: 1.3741609440844957
Validation loss: 2.84554218927197

Epoch: 5| Step: 3
Training loss: 0.8879776810856922
Validation loss: 2.8489911509314276

Epoch: 5| Step: 4
Training loss: 0.9858701945937807
Validation loss: 2.7946998904345723

Epoch: 5| Step: 5
Training loss: 1.3592686227852646
Validation loss: 2.785875374726586

Epoch: 5| Step: 6
Training loss: 1.0425015092285355
Validation loss: 2.772412815551994

Epoch: 5| Step: 7
Training loss: 1.0923881772075157
Validation loss: 2.850107049744091

Epoch: 5| Step: 8
Training loss: 0.9190935102547216
Validation loss: 2.872411621802

Epoch: 5| Step: 9
Training loss: 1.3106413350976929
Validation loss: 2.8812458361018414

Epoch: 5| Step: 10
Training loss: 1.1747188901449326
Validation loss: 2.8798477517390415

Epoch: 5| Step: 11
Training loss: 0.4687859998230579
Validation loss: 2.9411627173452826

Epoch: 163| Step: 0
Training loss: 1.0744344598761415
Validation loss: 2.9595709224621336

Epoch: 5| Step: 1
Training loss: 0.9622177032061623
Validation loss: 2.8957415275749483

Epoch: 5| Step: 2
Training loss: 1.164261973654701
Validation loss: 2.869288448284978

Epoch: 5| Step: 3
Training loss: 0.8989527676005954
Validation loss: 2.8755030191969806

Epoch: 5| Step: 4
Training loss: 0.9975302716014339
Validation loss: 2.8555371632449584

Epoch: 5| Step: 5
Training loss: 1.4049558830801376
Validation loss: 2.801389563421764

Epoch: 5| Step: 6
Training loss: 1.170682885673137
Validation loss: 2.8552946184590735

Epoch: 5| Step: 7
Training loss: 0.7119607373754387
Validation loss: 2.877191130165331

Epoch: 5| Step: 8
Training loss: 1.898123632787891
Validation loss: 2.9237061031058524

Epoch: 5| Step: 9
Training loss: 1.3448976007642526
Validation loss: 3.032276373068637

Epoch: 5| Step: 10
Training loss: 1.3991316878486892
Validation loss: 2.925408642228156

Epoch: 5| Step: 11
Training loss: 0.8796596095811635
Validation loss: 2.9164075202710906

Epoch: 164| Step: 0
Training loss: 1.2530379571911878
Validation loss: 2.8189379899350913

Epoch: 5| Step: 1
Training loss: 1.194100008078175
Validation loss: 2.800670183534222

Epoch: 5| Step: 2
Training loss: 0.8762020981738045
Validation loss: 2.7772161898893293

Epoch: 5| Step: 3
Training loss: 1.1012180412063086
Validation loss: 2.771762678901899

Epoch: 5| Step: 4
Training loss: 1.250916526479478
Validation loss: 2.728497941349645

Epoch: 5| Step: 5
Training loss: 1.3569694368804197
Validation loss: 2.696952567784439

Epoch: 5| Step: 6
Training loss: 0.8252147423979178
Validation loss: 2.7470173953271297

Epoch: 5| Step: 7
Training loss: 1.4729040124647268
Validation loss: 2.871122803832986

Epoch: 5| Step: 8
Training loss: 1.4366204431949958
Validation loss: 2.9442733192849486

Epoch: 5| Step: 9
Training loss: 1.0548032343907796
Validation loss: 2.9662985032568

Epoch: 5| Step: 10
Training loss: 1.8980558663277143
Validation loss: 3.0116559659925763

Epoch: 5| Step: 11
Training loss: 1.2776076018075628
Validation loss: 2.997862816212749

Epoch: 165| Step: 0
Training loss: 1.1805599599020586
Validation loss: 2.8171199153636417

Epoch: 5| Step: 1
Training loss: 1.318879834333014
Validation loss: 2.798033813434715

Epoch: 5| Step: 2
Training loss: 0.8675536336451923
Validation loss: 2.773479561643481

Epoch: 5| Step: 3
Training loss: 1.513172800789397
Validation loss: 2.727581289264762

Epoch: 5| Step: 4
Training loss: 1.1477618143599073
Validation loss: 2.7252861176050622

Epoch: 5| Step: 5
Training loss: 1.591402756280299
Validation loss: 2.7832602975784417

Epoch: 5| Step: 6
Training loss: 0.8858538875784987
Validation loss: 2.747617751766443

Epoch: 5| Step: 7
Training loss: 1.8911761276632872
Validation loss: 2.7763519054112566

Epoch: 5| Step: 8
Training loss: 0.8897107769326605
Validation loss: 2.823613409273991

Epoch: 5| Step: 9
Training loss: 1.2076877425928478
Validation loss: 2.8400798596260093

Epoch: 5| Step: 10
Training loss: 0.6065488717672194
Validation loss: 2.900304619641034

Epoch: 5| Step: 11
Training loss: 0.860666206664335
Validation loss: 2.941938739618563

Epoch: 166| Step: 0
Training loss: 1.0696768439361422
Validation loss: 2.816199779658154

Epoch: 5| Step: 1
Training loss: 1.2098645286544392
Validation loss: 2.7810453400337694

Epoch: 5| Step: 2
Training loss: 1.0556108177230648
Validation loss: 2.7890427514809804

Epoch: 5| Step: 3
Training loss: 0.560958711015909
Validation loss: 2.808777970668639

Epoch: 5| Step: 4
Training loss: 1.1536775273202482
Validation loss: 2.866666488360983

Epoch: 5| Step: 5
Training loss: 0.788712036561297
Validation loss: 2.7803709662673906

Epoch: 5| Step: 6
Training loss: 1.4274348454880186
Validation loss: 2.745343333233831

Epoch: 5| Step: 7
Training loss: 1.1105363167050528
Validation loss: 2.7644687397905616

Epoch: 5| Step: 8
Training loss: 1.8114956013065162
Validation loss: 2.740193245928709

Epoch: 5| Step: 9
Training loss: 0.7540593757675336
Validation loss: 2.812219584579048

Epoch: 5| Step: 10
Training loss: 0.9501702206347831
Validation loss: 2.75678541313067

Epoch: 5| Step: 11
Training loss: 0.31268816289882934
Validation loss: 2.7879946772242024

Epoch: 167| Step: 0
Training loss: 1.2276547179443773
Validation loss: 2.776962522371956

Epoch: 5| Step: 1
Training loss: 1.0939074811641072
Validation loss: 2.799933609856579

Epoch: 5| Step: 2
Training loss: 1.1045990343295822
Validation loss: 2.8436582361863296

Epoch: 5| Step: 3
Training loss: 1.3227497155681818
Validation loss: 2.8566054670424745

Epoch: 5| Step: 4
Training loss: 1.73824483426129
Validation loss: 2.7790974956313526

Epoch: 5| Step: 5
Training loss: 1.0167732789990773
Validation loss: 2.7653691232707893

Epoch: 5| Step: 6
Training loss: 0.9495747530489426
Validation loss: 2.8921957027209753

Epoch: 5| Step: 7
Training loss: 1.268082246619031
Validation loss: 2.8780423217727478

Epoch: 5| Step: 8
Training loss: 0.9536780956956366
Validation loss: 2.9031425632948826

Epoch: 5| Step: 9
Training loss: 1.2001228527919623
Validation loss: 2.8173804007111642

Epoch: 5| Step: 10
Training loss: 1.1036086321770717
Validation loss: 2.798699545718574

Epoch: 5| Step: 11
Training loss: 0.7319855878302306
Validation loss: 2.8095711964524193

Epoch: 168| Step: 0
Training loss: 1.740347947375981
Validation loss: 2.767894069070798

Epoch: 5| Step: 1
Training loss: 1.0380588359291518
Validation loss: 2.833389040922899

Epoch: 5| Step: 2
Training loss: 1.025764789434702
Validation loss: 2.823324213955266

Epoch: 5| Step: 3
Training loss: 0.8685640286972034
Validation loss: 2.8919296035629665

Epoch: 5| Step: 4
Training loss: 0.9103059768312083
Validation loss: 2.95882244947011

Epoch: 5| Step: 5
Training loss: 0.7085524995987613
Validation loss: 2.868222914998852

Epoch: 5| Step: 6
Training loss: 1.009231101251511
Validation loss: 2.8619800159197384

Epoch: 5| Step: 7
Training loss: 1.0166825290651507
Validation loss: 2.7614363040762475

Epoch: 5| Step: 8
Training loss: 1.5023052462574773
Validation loss: 2.760703776681241

Epoch: 5| Step: 9
Training loss: 1.4849940565099489
Validation loss: 2.7688548791538428

Epoch: 5| Step: 10
Training loss: 0.9286539439333727
Validation loss: 2.801721976188311

Epoch: 5| Step: 11
Training loss: 1.2951115948230267
Validation loss: 2.813631568318824

Epoch: 169| Step: 0
Training loss: 0.9646568580656913
Validation loss: 2.8741473854843513

Epoch: 5| Step: 1
Training loss: 0.9999166394297893
Validation loss: 2.8965541756592947

Epoch: 5| Step: 2
Training loss: 0.7545560892187131
Validation loss: 2.9279087719626062

Epoch: 5| Step: 3
Training loss: 1.3180430845272026
Validation loss: 2.892772344353318

Epoch: 5| Step: 4
Training loss: 0.9381205094730017
Validation loss: 2.9068334516788767

Epoch: 5| Step: 5
Training loss: 1.8195267974943174
Validation loss: 2.8054462989667273

Epoch: 5| Step: 6
Training loss: 0.8562054183937321
Validation loss: 2.7492126761077853

Epoch: 5| Step: 7
Training loss: 1.083683556408557
Validation loss: 2.7632783679265867

Epoch: 5| Step: 8
Training loss: 1.3721530224181093
Validation loss: 2.7799770928429366

Epoch: 5| Step: 9
Training loss: 1.1154284734223388
Validation loss: 2.8170268044858164

Epoch: 5| Step: 10
Training loss: 0.7641370288408177
Validation loss: 2.848852107957772

Epoch: 5| Step: 11
Training loss: 0.7634435053685602
Validation loss: 2.738551817118591

Epoch: 170| Step: 0
Training loss: 0.8016478152910383
Validation loss: 2.768453674447139

Epoch: 5| Step: 1
Training loss: 0.7591403849924165
Validation loss: 2.728400338790433

Epoch: 5| Step: 2
Training loss: 1.3474828636198026
Validation loss: 2.802243495225851

Epoch: 5| Step: 3
Training loss: 1.1700846410767174
Validation loss: 2.8152631502430685

Epoch: 5| Step: 4
Training loss: 0.8865957973118157
Validation loss: 2.9201969012952693

Epoch: 5| Step: 5
Training loss: 1.1267059954338063
Validation loss: 2.918705831407258

Epoch: 5| Step: 6
Training loss: 1.1437838460781729
Validation loss: 2.8959978466278398

Epoch: 5| Step: 7
Training loss: 1.0960934193747274
Validation loss: 2.871038046229444

Epoch: 5| Step: 8
Training loss: 0.8903457471505067
Validation loss: 2.790809045313658

Epoch: 5| Step: 9
Training loss: 1.0786446687233737
Validation loss: 2.803905654358714

Epoch: 5| Step: 10
Training loss: 1.65945628051544
Validation loss: 2.8295793991181353

Epoch: 5| Step: 11
Training loss: 1.2115101598454519
Validation loss: 2.7469717858586047

Epoch: 171| Step: 0
Training loss: 1.0340905804019067
Validation loss: 2.808348661365806

Epoch: 5| Step: 1
Training loss: 1.0378276973853338
Validation loss: 2.8778838538127407

Epoch: 5| Step: 2
Training loss: 1.2908525926660785
Validation loss: 2.9612683503062898

Epoch: 5| Step: 3
Training loss: 2.001918587735622
Validation loss: 2.872539600821999

Epoch: 5| Step: 4
Training loss: 1.4394989213426
Validation loss: 3.025195429665641

Epoch: 5| Step: 5
Training loss: 0.8921202104783863
Validation loss: 2.8928326124107713

Epoch: 5| Step: 6
Training loss: 0.787117780541153
Validation loss: 2.799236195983947

Epoch: 5| Step: 7
Training loss: 0.9634643454930317
Validation loss: 2.793890762196572

Epoch: 5| Step: 8
Training loss: 0.8438192268512017
Validation loss: 2.911710608214839

Epoch: 5| Step: 9
Training loss: 1.1456291999469361
Validation loss: 2.7543655156842988

Epoch: 5| Step: 10
Training loss: 0.8065007344790648
Validation loss: 2.771595005285369

Epoch: 5| Step: 11
Training loss: 1.2782141376928164
Validation loss: 2.8595456001237527

Epoch: 172| Step: 0
Training loss: 1.576206135997874
Validation loss: 2.8268186175880206

Epoch: 5| Step: 1
Training loss: 0.7104442688025584
Validation loss: 2.7674962015708853

Epoch: 5| Step: 2
Training loss: 0.7659141228173276
Validation loss: 2.851809805331714

Epoch: 5| Step: 3
Training loss: 1.233874062404174
Validation loss: 2.783443846526348

Epoch: 5| Step: 4
Training loss: 1.0888224639603084
Validation loss: 2.8200355316295425

Epoch: 5| Step: 5
Training loss: 1.0235296309840372
Validation loss: 2.928381246335102

Epoch: 5| Step: 6
Training loss: 0.8750611351999196
Validation loss: 2.835628818495098

Epoch: 5| Step: 7
Training loss: 1.026459752345022
Validation loss: 2.926321624032485

Epoch: 5| Step: 8
Training loss: 1.0357459350034741
Validation loss: 2.858133598963692

Epoch: 5| Step: 9
Training loss: 1.1486793834246554
Validation loss: 2.840466010942941

Epoch: 5| Step: 10
Training loss: 1.2262365308949301
Validation loss: 2.8998633490901344

Epoch: 5| Step: 11
Training loss: 1.1245713476951222
Validation loss: 2.8425511044225424

Epoch: 173| Step: 0
Training loss: 1.2476411019530143
Validation loss: 2.8061796520792375

Epoch: 5| Step: 1
Training loss: 0.842226206610131
Validation loss: 2.797097808160771

Epoch: 5| Step: 2
Training loss: 1.1545861619143538
Validation loss: 2.7490721893053065

Epoch: 5| Step: 3
Training loss: 1.7290629926495011
Validation loss: 2.8355270978531584

Epoch: 5| Step: 4
Training loss: 1.1403340007650309
Validation loss: 2.9351545940195147

Epoch: 5| Step: 5
Training loss: 0.9774136915421547
Validation loss: 2.9400440184007572

Epoch: 5| Step: 6
Training loss: 0.9557546392193994
Validation loss: 2.908233338406803

Epoch: 5| Step: 7
Training loss: 0.8782640951096768
Validation loss: 2.8049978192582157

Epoch: 5| Step: 8
Training loss: 0.7832719958078478
Validation loss: 2.8267823188123784

Epoch: 5| Step: 9
Training loss: 1.2098451671372807
Validation loss: 2.8427869996708672

Epoch: 5| Step: 10
Training loss: 0.5914860277274998
Validation loss: 2.8008684528702363

Epoch: 5| Step: 11
Training loss: 1.0319292547980017
Validation loss: 2.7835318959005675

Epoch: 174| Step: 0
Training loss: 0.9877012759921221
Validation loss: 2.7950676347536914

Epoch: 5| Step: 1
Training loss: 1.2539901942975509
Validation loss: 2.798612303663893

Epoch: 5| Step: 2
Training loss: 0.9394811043171425
Validation loss: 2.7635499421844254

Epoch: 5| Step: 3
Training loss: 1.2129875795494256
Validation loss: 2.9078373180425583

Epoch: 5| Step: 4
Training loss: 0.813429044546937
Validation loss: 2.9490061634909543

Epoch: 5| Step: 5
Training loss: 0.9313866611027686
Validation loss: 2.9457226981107256

Epoch: 5| Step: 6
Training loss: 1.4155863775580355
Validation loss: 2.873174485156707

Epoch: 5| Step: 7
Training loss: 0.9925301928696084
Validation loss: 2.849198756048872

Epoch: 5| Step: 8
Training loss: 0.9569138435437954
Validation loss: 2.7255864040292805

Epoch: 5| Step: 9
Training loss: 1.773599356772754
Validation loss: 2.7621836219331963

Epoch: 5| Step: 10
Training loss: 1.1343708763362872
Validation loss: 2.8466376116670955

Epoch: 5| Step: 11
Training loss: 0.8086048438743982
Validation loss: 2.7817004299819406

Epoch: 175| Step: 0
Training loss: 0.8777807531594766
Validation loss: 2.767591359302696

Epoch: 5| Step: 1
Training loss: 1.7276712715273521
Validation loss: 2.7735612617781777

Epoch: 5| Step: 2
Training loss: 1.0515585934706702
Validation loss: 2.8531088585900104

Epoch: 5| Step: 3
Training loss: 0.9278856334855541
Validation loss: 3.008290676402746

Epoch: 5| Step: 4
Training loss: 0.9929534178599847
Validation loss: 2.9055782451001035

Epoch: 5| Step: 5
Training loss: 1.395693468326843
Validation loss: 3.0028672291946346

Epoch: 5| Step: 6
Training loss: 1.2265244982232606
Validation loss: 2.909175634194588

Epoch: 5| Step: 7
Training loss: 0.7650905612249166
Validation loss: 2.959353007067362

Epoch: 5| Step: 8
Training loss: 1.1650265279704746
Validation loss: 2.812026301864643

Epoch: 5| Step: 9
Training loss: 0.6681128006366457
Validation loss: 2.839454218381905

Epoch: 5| Step: 10
Training loss: 0.8577284558091355
Validation loss: 2.8491787636310324

Epoch: 5| Step: 11
Training loss: 0.8599302405519431
Validation loss: 2.7899686443738583

Epoch: 176| Step: 0
Training loss: 0.9166597814012362
Validation loss: 2.8004867242787785

Epoch: 5| Step: 1
Training loss: 0.9911193805371217
Validation loss: 2.7011245793274843

Epoch: 5| Step: 2
Training loss: 1.1282202408338042
Validation loss: 2.785593118953765

Epoch: 5| Step: 3
Training loss: 0.8447196827867427
Validation loss: 2.767655867994715

Epoch: 5| Step: 4
Training loss: 1.065499559553638
Validation loss: 2.782439116971203

Epoch: 5| Step: 5
Training loss: 0.9435494746713863
Validation loss: 2.8173971456761437

Epoch: 5| Step: 6
Training loss: 0.8463195245940185
Validation loss: 2.864118657426098

Epoch: 5| Step: 7
Training loss: 1.1867583619187376
Validation loss: 2.8633005159778535

Epoch: 5| Step: 8
Training loss: 1.8263834947990696
Validation loss: 2.957258796083717

Epoch: 5| Step: 9
Training loss: 0.8353876819164547
Validation loss: 2.8388727304189953

Epoch: 5| Step: 10
Training loss: 1.3740996534171228
Validation loss: 2.8514348772309175

Epoch: 5| Step: 11
Training loss: 1.205973288071022
Validation loss: 2.8939839685273276

Epoch: 177| Step: 0
Training loss: 1.0602975907136203
Validation loss: 2.7848603642943766

Epoch: 5| Step: 1
Training loss: 1.4332755668591508
Validation loss: 2.7542561843067195

Epoch: 5| Step: 2
Training loss: 0.7437088482154838
Validation loss: 2.673425317614274

Epoch: 5| Step: 3
Training loss: 0.9295491989231602
Validation loss: 2.744371357875334

Epoch: 5| Step: 4
Training loss: 1.2215683945079099
Validation loss: 2.6404657786142467

Epoch: 5| Step: 5
Training loss: 1.0623515530274565
Validation loss: 2.76619496910907

Epoch: 5| Step: 6
Training loss: 1.0466237691928757
Validation loss: 2.807308555556943

Epoch: 5| Step: 7
Training loss: 1.7607819970021266
Validation loss: 2.8506470033665843

Epoch: 5| Step: 8
Training loss: 0.6954864541523388
Validation loss: 2.8735973834330664

Epoch: 5| Step: 9
Training loss: 0.8420573316206106
Validation loss: 2.9077652293467233

Epoch: 5| Step: 10
Training loss: 0.8536332876429045
Validation loss: 2.9204091289624547

Epoch: 5| Step: 11
Training loss: 0.5206278649992038
Validation loss: 2.9150076893748116

Epoch: 178| Step: 0
Training loss: 0.8927735963970236
Validation loss: 2.9525238582455717

Epoch: 5| Step: 1
Training loss: 0.9076951770180706
Validation loss: 2.8371866485900306

Epoch: 5| Step: 2
Training loss: 1.0956282700589393
Validation loss: 2.8312338291742187

Epoch: 5| Step: 3
Training loss: 0.7161901333140711
Validation loss: 2.787251487339882

Epoch: 5| Step: 4
Training loss: 0.8575713911449818
Validation loss: 2.7862056201648024

Epoch: 5| Step: 5
Training loss: 0.9313178632958226
Validation loss: 2.7935410560115836

Epoch: 5| Step: 6
Training loss: 0.9907187456605607
Validation loss: 2.762985719439087

Epoch: 5| Step: 7
Training loss: 1.0249132189416765
Validation loss: 2.7711492402584983

Epoch: 5| Step: 8
Training loss: 0.820475171626512
Validation loss: 2.7568083890231474

Epoch: 5| Step: 9
Training loss: 1.2492862571048968
Validation loss: 2.790146945447159

Epoch: 5| Step: 10
Training loss: 1.6195614846439497
Validation loss: 2.8921959878091794

Epoch: 5| Step: 11
Training loss: 0.7592556769416609
Validation loss: 2.846669780175236

Epoch: 179| Step: 0
Training loss: 0.9979990072398323
Validation loss: 3.0065805926199998

Epoch: 5| Step: 1
Training loss: 0.8810318061226909
Validation loss: 2.885315863481581

Epoch: 5| Step: 2
Training loss: 0.9531968511795944
Validation loss: 2.8663835325161364

Epoch: 5| Step: 3
Training loss: 1.0677044690069963
Validation loss: 2.7569655251571166

Epoch: 5| Step: 4
Training loss: 1.1076853067098376
Validation loss: 2.6856621808816374

Epoch: 5| Step: 5
Training loss: 1.9022336454075721
Validation loss: 2.8539662824488894

Epoch: 5| Step: 6
Training loss: 0.9358854378054122
Validation loss: 2.6896368188856163

Epoch: 5| Step: 7
Training loss: 0.9642147531335381
Validation loss: 2.871168465193597

Epoch: 5| Step: 8
Training loss: 0.9622886586698
Validation loss: 2.8025757535382563

Epoch: 5| Step: 9
Training loss: 1.0080611047994668
Validation loss: 2.8489765617628966

Epoch: 5| Step: 10
Training loss: 0.8990070693742692
Validation loss: 2.9416754448699374

Epoch: 5| Step: 11
Training loss: 1.6627814147945696
Validation loss: 2.8779411061119404

Epoch: 180| Step: 0
Training loss: 0.9386191364003069
Validation loss: 2.7675066256479717

Epoch: 5| Step: 1
Training loss: 1.2723476684465003
Validation loss: 2.836746695872954

Epoch: 5| Step: 2
Training loss: 1.0012126960424916
Validation loss: 2.7251002080381723

Epoch: 5| Step: 3
Training loss: 1.28365268119247
Validation loss: 2.8496213010242517

Epoch: 5| Step: 4
Training loss: 2.0425772939225455
Validation loss: 2.8850784355996058

Epoch: 5| Step: 5
Training loss: 1.0574124773028555
Validation loss: 2.895462377147781

Epoch: 5| Step: 6
Training loss: 1.0449044769835196
Validation loss: 2.934422730994409

Epoch: 5| Step: 7
Training loss: 0.8210571542237569
Validation loss: 3.072837871683547

Epoch: 5| Step: 8
Training loss: 1.0816855308658941
Validation loss: 3.1183462705977556

Epoch: 5| Step: 9
Training loss: 1.081915343098224
Validation loss: 3.1073609095774333

Epoch: 5| Step: 10
Training loss: 1.0479055996886193
Validation loss: 3.084773150624813

Epoch: 5| Step: 11
Training loss: 0.5039824494700739
Validation loss: 2.967227957210162

Epoch: 181| Step: 0
Training loss: 1.0800808842711702
Validation loss: 2.8202762936058297

Epoch: 5| Step: 1
Training loss: 0.8515837430491664
Validation loss: 2.7528528060904143

Epoch: 5| Step: 2
Training loss: 1.8847859910250053
Validation loss: 2.810760875169095

Epoch: 5| Step: 3
Training loss: 0.7616610774190602
Validation loss: 2.706536707032698

Epoch: 5| Step: 4
Training loss: 1.0994065200945424
Validation loss: 2.8213444386671855

Epoch: 5| Step: 5
Training loss: 0.9019636203953195
Validation loss: 2.7736625651703744

Epoch: 5| Step: 6
Training loss: 1.1017083686942197
Validation loss: 2.741982958665096

Epoch: 5| Step: 7
Training loss: 0.7574549745957753
Validation loss: 2.9000413506672955

Epoch: 5| Step: 8
Training loss: 0.6866402452055276
Validation loss: 3.071063744912644

Epoch: 5| Step: 9
Training loss: 0.7706576782995417
Validation loss: 2.938810970758879

Epoch: 5| Step: 10
Training loss: 0.9311820127004307
Validation loss: 3.02332508098299

Epoch: 5| Step: 11
Training loss: 0.9281350003612453
Validation loss: 2.978541249649635

Epoch: 182| Step: 0
Training loss: 1.5606990353305905
Validation loss: 2.8839713354538006

Epoch: 5| Step: 1
Training loss: 1.0613494702419124
Validation loss: 2.8590882440691416

Epoch: 5| Step: 2
Training loss: 0.8397056998412517
Validation loss: 2.8413297638533574

Epoch: 5| Step: 3
Training loss: 0.9356919337445272
Validation loss: 2.8455536854816965

Epoch: 5| Step: 4
Training loss: 1.144376412291309
Validation loss: 2.7132286317107432

Epoch: 5| Step: 5
Training loss: 1.0552511333937569
Validation loss: 2.7673654952440643

Epoch: 5| Step: 6
Training loss: 1.027559671084736
Validation loss: 2.840501501842089

Epoch: 5| Step: 7
Training loss: 0.8389439930687653
Validation loss: 2.8543183409400212

Epoch: 5| Step: 8
Training loss: 0.9395047369914189
Validation loss: 2.805460459421518

Epoch: 5| Step: 9
Training loss: 0.6647748380240696
Validation loss: 2.838268950540956

Epoch: 5| Step: 10
Training loss: 0.5895785815673141
Validation loss: 2.812933641134911

Epoch: 5| Step: 11
Training loss: 0.5515561435754647
Validation loss: 2.880795470137788

Epoch: 183| Step: 0
Training loss: 0.9190097506527836
Validation loss: 2.8626245749184402

Epoch: 5| Step: 1
Training loss: 0.7755677912022296
Validation loss: 2.8584955144883373

Epoch: 5| Step: 2
Training loss: 1.1436961385416422
Validation loss: 2.7861349767905392

Epoch: 5| Step: 3
Training loss: 0.8353363442433928
Validation loss: 2.8032251865340325

Epoch: 5| Step: 4
Training loss: 0.5720491488088713
Validation loss: 2.832709027445242

Epoch: 5| Step: 5
Training loss: 1.6619042383141875
Validation loss: 2.8878302664640776

Epoch: 5| Step: 6
Training loss: 1.1123061879242515
Validation loss: 2.885610729994979

Epoch: 5| Step: 7
Training loss: 1.015847577867992
Validation loss: 2.8328568616571776

Epoch: 5| Step: 8
Training loss: 1.3795848181803063
Validation loss: 2.8601279978297605

Epoch: 5| Step: 9
Training loss: 0.6828137989162774
Validation loss: 2.8649763785548523

Epoch: 5| Step: 10
Training loss: 0.8672157489196419
Validation loss: 2.9071684073262345

Epoch: 5| Step: 11
Training loss: 0.6399185192871035
Validation loss: 2.7965033868593765

Epoch: 184| Step: 0
Training loss: 0.6669343445747665
Validation loss: 2.7024638335754267

Epoch: 5| Step: 1
Training loss: 0.7683704741955794
Validation loss: 2.753113169361434

Epoch: 5| Step: 2
Training loss: 0.8716402264141345
Validation loss: 2.79838601112389

Epoch: 5| Step: 3
Training loss: 1.0839090407028886
Validation loss: 2.7143843593753725

Epoch: 5| Step: 4
Training loss: 0.9401168540598634
Validation loss: 2.822962617441506

Epoch: 5| Step: 5
Training loss: 0.9028590328785703
Validation loss: 2.8067809627083786

Epoch: 5| Step: 6
Training loss: 0.9306190695999597
Validation loss: 2.7905227122653584

Epoch: 5| Step: 7
Training loss: 1.6846680366808433
Validation loss: 2.813960206712358

Epoch: 5| Step: 8
Training loss: 0.8981260672120276
Validation loss: 2.7499971967740655

Epoch: 5| Step: 9
Training loss: 0.687569939783834
Validation loss: 2.8804712118081897

Epoch: 5| Step: 10
Training loss: 1.0881736291386177
Validation loss: 2.8850416887754307

Epoch: 5| Step: 11
Training loss: 0.7653521226662726
Validation loss: 2.751215608281612

Epoch: 185| Step: 0
Training loss: 0.9280798018011166
Validation loss: 2.82915188392706

Epoch: 5| Step: 1
Training loss: 0.7366478425709166
Validation loss: 2.7861750007088943

Epoch: 5| Step: 2
Training loss: 0.9419765723427307
Validation loss: 2.825017911859852

Epoch: 5| Step: 3
Training loss: 1.3505541617737058
Validation loss: 2.770122011322998

Epoch: 5| Step: 4
Training loss: 0.973636424403249
Validation loss: 2.804828601287864

Epoch: 5| Step: 5
Training loss: 0.5405346216058144
Validation loss: 2.806437514000901

Epoch: 5| Step: 6
Training loss: 0.5354482313665692
Validation loss: 2.86141123645538

Epoch: 5| Step: 7
Training loss: 1.6028837383085324
Validation loss: 2.8766596329987233

Epoch: 5| Step: 8
Training loss: 1.1075668643718832
Validation loss: 2.8555942060792168

Epoch: 5| Step: 9
Training loss: 0.845966359813369
Validation loss: 2.9070243487489327

Epoch: 5| Step: 10
Training loss: 0.899149736793614
Validation loss: 2.921054231822382

Epoch: 5| Step: 11
Training loss: 0.3956782409435453
Validation loss: 2.831768881384508

Epoch: 186| Step: 0
Training loss: 0.8232484864777925
Validation loss: 2.7399864256799864

Epoch: 5| Step: 1
Training loss: 1.0455352979126116
Validation loss: 2.820910135986339

Epoch: 5| Step: 2
Training loss: 0.5968634639244315
Validation loss: 2.844351781673353

Epoch: 5| Step: 3
Training loss: 0.8657008995080562
Validation loss: 2.7645865931679756

Epoch: 5| Step: 4
Training loss: 0.944824502634405
Validation loss: 2.761450999588487

Epoch: 5| Step: 5
Training loss: 0.852231594017861
Validation loss: 2.8922909549652815

Epoch: 5| Step: 6
Training loss: 1.1663543362572086
Validation loss: 2.9014452043502295

Epoch: 5| Step: 7
Training loss: 1.8902533299851043
Validation loss: 2.8096057517024593

Epoch: 5| Step: 8
Training loss: 0.7709410867039345
Validation loss: 2.8389287503861977

Epoch: 5| Step: 9
Training loss: 0.9211536106527728
Validation loss: 2.755253935053733

Epoch: 5| Step: 10
Training loss: 1.0075255584314668
Validation loss: 2.7563502187522686

Epoch: 5| Step: 11
Training loss: 0.7297802704808729
Validation loss: 2.6913771459355855

Epoch: 187| Step: 0
Training loss: 1.0117885020597885
Validation loss: 2.7649820517911126

Epoch: 5| Step: 1
Training loss: 0.9239057383285079
Validation loss: 2.750239186650022

Epoch: 5| Step: 2
Training loss: 1.6955410851574517
Validation loss: 2.856859410366579

Epoch: 5| Step: 3
Training loss: 1.169198603901925
Validation loss: 2.860668966599856

Epoch: 5| Step: 4
Training loss: 1.2463788988800173
Validation loss: 2.9720967919680326

Epoch: 5| Step: 5
Training loss: 0.6450022046103245
Validation loss: 2.9820679773366425

Epoch: 5| Step: 6
Training loss: 0.970202495340863
Validation loss: 2.9386337845048573

Epoch: 5| Step: 7
Training loss: 0.9007366450598433
Validation loss: 2.85632332652743

Epoch: 5| Step: 8
Training loss: 0.7917059252859445
Validation loss: 2.7489565003796

Epoch: 5| Step: 9
Training loss: 0.7860723815816125
Validation loss: 2.733698178041287

Epoch: 5| Step: 10
Training loss: 0.9279037160416465
Validation loss: 2.7220176101009117

Epoch: 5| Step: 11
Training loss: 0.9002162408661676
Validation loss: 2.8258869139082883

Epoch: 188| Step: 0
Training loss: 0.8206098471736623
Validation loss: 2.8632106833026105

Epoch: 5| Step: 1
Training loss: 1.0767715361890147
Validation loss: 2.8408533266836753

Epoch: 5| Step: 2
Training loss: 0.8661873350830713
Validation loss: 2.9417210714822364

Epoch: 5| Step: 3
Training loss: 0.714495381168842
Validation loss: 2.8486749425577096

Epoch: 5| Step: 4
Training loss: 1.4120988225476654
Validation loss: 2.9314782836613293

Epoch: 5| Step: 5
Training loss: 0.8065939236253857
Validation loss: 2.8780002833435403

Epoch: 5| Step: 6
Training loss: 0.7711959492864913
Validation loss: 2.7948930171504847

Epoch: 5| Step: 7
Training loss: 1.6551816121515825
Validation loss: 2.8064463350620388

Epoch: 5| Step: 8
Training loss: 0.7831004543978771
Validation loss: 2.787393150505545

Epoch: 5| Step: 9
Training loss: 1.3259364777362594
Validation loss: 2.7589605893625597

Epoch: 5| Step: 10
Training loss: 0.9961858071068049
Validation loss: 2.7692376193200605

Epoch: 5| Step: 11
Training loss: 0.41115934236515644
Validation loss: 2.919104750324447

Epoch: 189| Step: 0
Training loss: 1.1941723341096362
Validation loss: 2.876646123468711

Epoch: 5| Step: 1
Training loss: 1.0161375659715153
Validation loss: 2.972146980216133

Epoch: 5| Step: 2
Training loss: 0.5865826170717745
Validation loss: 2.9304036430761227

Epoch: 5| Step: 3
Training loss: 0.8661589149929293
Validation loss: 2.8871054108639402

Epoch: 5| Step: 4
Training loss: 1.0535399799410112
Validation loss: 2.8693113957864775

Epoch: 5| Step: 5
Training loss: 0.8101036606497204
Validation loss: 2.8327715096977184

Epoch: 5| Step: 6
Training loss: 0.7704723818988718
Validation loss: 2.7686020045915667

Epoch: 5| Step: 7
Training loss: 1.554946341125409
Validation loss: 2.7590316944834368

Epoch: 5| Step: 8
Training loss: 0.48857974274810423
Validation loss: 2.749888602081247

Epoch: 5| Step: 9
Training loss: 1.081726086272186
Validation loss: 2.775629529484746

Epoch: 5| Step: 10
Training loss: 1.0671167487041848
Validation loss: 2.762726905042517

Epoch: 5| Step: 11
Training loss: 1.480013493012446
Validation loss: 2.849991221790849

Epoch: 190| Step: 0
Training loss: 0.7534628636550019
Validation loss: 2.839498741184777

Epoch: 5| Step: 1
Training loss: 0.8897876818963739
Validation loss: 2.842390458555363

Epoch: 5| Step: 2
Training loss: 0.8988046973804728
Validation loss: 2.878625087388354

Epoch: 5| Step: 3
Training loss: 0.6096547536106665
Validation loss: 2.9037066169614767

Epoch: 5| Step: 4
Training loss: 0.6852070544903532
Validation loss: 2.8234903144505923

Epoch: 5| Step: 5
Training loss: 1.069438716878595
Validation loss: 2.6808943093137882

Epoch: 5| Step: 6
Training loss: 0.5201254293581642
Validation loss: 2.829934856543444

Epoch: 5| Step: 7
Training loss: 0.8700208000459024
Validation loss: 2.827656350550446

Epoch: 5| Step: 8
Training loss: 1.5772823690230167
Validation loss: 2.8534793020273894

Epoch: 5| Step: 9
Training loss: 0.7395680833417341
Validation loss: 2.8188047984534887

Epoch: 5| Step: 10
Training loss: 1.3384127523880684
Validation loss: 2.8590547976451064

Epoch: 5| Step: 11
Training loss: 0.7295264627965882
Validation loss: 2.82023079455261

Epoch: 191| Step: 0
Training loss: 0.7307849546431983
Validation loss: 2.8554655215083775

Epoch: 5| Step: 1
Training loss: 1.0387602058028633
Validation loss: 2.8715885903682956

Epoch: 5| Step: 2
Training loss: 0.7069674721293883
Validation loss: 2.910211198189869

Epoch: 5| Step: 3
Training loss: 0.8244997964584627
Validation loss: 2.8542784972917645

Epoch: 5| Step: 4
Training loss: 1.0121095116282834
Validation loss: 2.8616560851093835

Epoch: 5| Step: 5
Training loss: 1.0780379771618656
Validation loss: 2.826096878866944

Epoch: 5| Step: 6
Training loss: 0.8759736366180582
Validation loss: 2.657965885649897

Epoch: 5| Step: 7
Training loss: 0.7216885660371268
Validation loss: 2.7548740931781657

Epoch: 5| Step: 8
Training loss: 0.9741768345385129
Validation loss: 2.75454594823091

Epoch: 5| Step: 9
Training loss: 0.8197707430840547
Validation loss: 2.8465236701764045

Epoch: 5| Step: 10
Training loss: 1.5151714157473737
Validation loss: 2.8680984442805912

Epoch: 5| Step: 11
Training loss: 1.0416805584299114
Validation loss: 2.976207548455818

Epoch: 192| Step: 0
Training loss: 0.9917583288309877
Validation loss: 2.8266079910410533

Epoch: 5| Step: 1
Training loss: 0.6945279227521429
Validation loss: 2.8416066074363697

Epoch: 5| Step: 2
Training loss: 0.7074504052427586
Validation loss: 2.8359930350030256

Epoch: 5| Step: 3
Training loss: 0.7001811389206813
Validation loss: 2.857642109002459

Epoch: 5| Step: 4
Training loss: 0.76321315403055
Validation loss: 2.8310984792016662

Epoch: 5| Step: 5
Training loss: 1.6344767580757518
Validation loss: 2.8520405129189763

Epoch: 5| Step: 6
Training loss: 0.9441210592039418
Validation loss: 2.728613845997889

Epoch: 5| Step: 7
Training loss: 0.9750562113672872
Validation loss: 2.832767091062074

Epoch: 5| Step: 8
Training loss: 0.7474529408469959
Validation loss: 2.7908927048634307

Epoch: 5| Step: 9
Training loss: 0.45652302581149684
Validation loss: 2.8371976149339115

Epoch: 5| Step: 10
Training loss: 1.1168532505063071
Validation loss: 2.8367912086415585

Epoch: 5| Step: 11
Training loss: 0.5372818548522714
Validation loss: 2.8921542993718314

Epoch: 193| Step: 0
Training loss: 0.6165983792676855
Validation loss: 2.9251956362114004

Epoch: 5| Step: 1
Training loss: 0.8137328990774274
Validation loss: 2.8892701040870485

Epoch: 5| Step: 2
Training loss: 1.0752852261096235
Validation loss: 2.821500195254627

Epoch: 5| Step: 3
Training loss: 1.531009421620447
Validation loss: 2.7800945639364345

Epoch: 5| Step: 4
Training loss: 0.8450661037479106
Validation loss: 2.764583596318416

Epoch: 5| Step: 5
Training loss: 0.7770487546684606
Validation loss: 2.772142478655553

Epoch: 5| Step: 6
Training loss: 0.789227421210125
Validation loss: 2.848230604901437

Epoch: 5| Step: 7
Training loss: 1.2474708720382461
Validation loss: 2.769774436586254

Epoch: 5| Step: 8
Training loss: 0.951747305076397
Validation loss: 2.8334381186986435

Epoch: 5| Step: 9
Training loss: 0.9119053679881252
Validation loss: 2.802189315625711

Epoch: 5| Step: 10
Training loss: 0.6236677753170863
Validation loss: 2.887143851826054

Epoch: 5| Step: 11
Training loss: 0.798559540083219
Validation loss: 2.8243634409793517

Epoch: 194| Step: 0
Training loss: 0.8919635551773674
Validation loss: 2.90664095966392

Epoch: 5| Step: 1
Training loss: 1.181909350900109
Validation loss: 2.8484781628899327

Epoch: 5| Step: 2
Training loss: 0.7950548815227655
Validation loss: 2.876065143285366

Epoch: 5| Step: 3
Training loss: 0.8718896488613481
Validation loss: 2.8456812333884076

Epoch: 5| Step: 4
Training loss: 1.7104309586343323
Validation loss: 2.833949710380681

Epoch: 5| Step: 5
Training loss: 0.7241480096301994
Validation loss: 2.822578055612047

Epoch: 5| Step: 6
Training loss: 1.1173232736312964
Validation loss: 2.8845818972681587

Epoch: 5| Step: 7
Training loss: 0.5569529142578685
Validation loss: 2.8483065894716395

Epoch: 5| Step: 8
Training loss: 0.7409224319373859
Validation loss: 2.8702521338402707

Epoch: 5| Step: 9
Training loss: 0.9698942256555407
Validation loss: 2.871665651967347

Epoch: 5| Step: 10
Training loss: 0.5519846492115195
Validation loss: 2.939084261607987

Epoch: 5| Step: 11
Training loss: 0.9690471624091239
Validation loss: 2.8783356382735903

Epoch: 195| Step: 0
Training loss: 0.835755051997255
Validation loss: 2.8562001840989866

Epoch: 5| Step: 1
Training loss: 1.515748166457698
Validation loss: 2.902352265884139

Epoch: 5| Step: 2
Training loss: 0.8790343805800025
Validation loss: 2.929526844282115

Epoch: 5| Step: 3
Training loss: 0.628994621560128
Validation loss: 2.8743486945158283

Epoch: 5| Step: 4
Training loss: 0.8867650965203286
Validation loss: 2.9735871911268457

Epoch: 5| Step: 5
Training loss: 0.899426952025328
Validation loss: 2.8790970061487626

Epoch: 5| Step: 6
Training loss: 0.7362831972212288
Validation loss: 2.929114208502341

Epoch: 5| Step: 7
Training loss: 0.7310548358889568
Validation loss: 2.8126266027142273

Epoch: 5| Step: 8
Training loss: 0.46114280137291164
Validation loss: 2.9331608337287847

Epoch: 5| Step: 9
Training loss: 0.7000590554939252
Validation loss: 2.9465631920747657

Epoch: 5| Step: 10
Training loss: 1.0679977893020667
Validation loss: 2.9087981500699027

Epoch: 5| Step: 11
Training loss: 0.881788351775334
Validation loss: 2.799827647439348

Epoch: 196| Step: 0
Training loss: 0.8728503319626416
Validation loss: 2.882546537513831

Epoch: 5| Step: 1
Training loss: 0.9791642588051483
Validation loss: 2.888016590955741

Epoch: 5| Step: 2
Training loss: 0.9231109093253786
Validation loss: 2.898706989150186

Epoch: 5| Step: 3
Training loss: 0.8864471086687195
Validation loss: 2.8577406473583795

Epoch: 5| Step: 4
Training loss: 0.6013363252001103
Validation loss: 2.833567978922569

Epoch: 5| Step: 5
Training loss: 1.0525195410357402
Validation loss: 2.8222268564978004

Epoch: 5| Step: 6
Training loss: 0.8702301397339554
Validation loss: 2.8659220855922842

Epoch: 5| Step: 7
Training loss: 1.4194157890932702
Validation loss: 2.822628236419222

Epoch: 5| Step: 8
Training loss: 0.9266157292584492
Validation loss: 2.895820906953199

Epoch: 5| Step: 9
Training loss: 0.884201240318997
Validation loss: 2.9090037340162294

Epoch: 5| Step: 10
Training loss: 1.0544547495278684
Validation loss: 2.901600290249918

Epoch: 5| Step: 11
Training loss: 0.386402308917897
Validation loss: 2.812512274114882

Epoch: 197| Step: 0
Training loss: 0.8782326045236922
Validation loss: 2.853019655587151

Epoch: 5| Step: 1
Training loss: 1.1730051313322178
Validation loss: 2.8476955793095455

Epoch: 5| Step: 2
Training loss: 1.46786943376823
Validation loss: 2.8771273268241804

Epoch: 5| Step: 3
Training loss: 0.8251451826951572
Validation loss: 2.900768535410465

Epoch: 5| Step: 4
Training loss: 0.8390142913551444
Validation loss: 2.894258765172085

Epoch: 5| Step: 5
Training loss: 0.9605786033252035
Validation loss: 2.8624768482476934

Epoch: 5| Step: 6
Training loss: 0.7670755075417787
Validation loss: 2.872442225510736

Epoch: 5| Step: 7
Training loss: 0.828606879187665
Validation loss: 2.848463581556591

Epoch: 5| Step: 8
Training loss: 0.5768172448240357
Validation loss: 2.8524231365311437

Epoch: 5| Step: 9
Training loss: 0.7865637314930408
Validation loss: 2.8517584293586795

Epoch: 5| Step: 10
Training loss: 0.7087058789280278
Validation loss: 2.8743119176578293

Epoch: 5| Step: 11
Training loss: 0.3782275896171709
Validation loss: 2.7718329897008287

Epoch: 198| Step: 0
Training loss: 0.7960153318347142
Validation loss: 2.829893879742974

Epoch: 5| Step: 1
Training loss: 1.0952337827163205
Validation loss: 2.8308276405273487

Epoch: 5| Step: 2
Training loss: 0.6879433372875812
Validation loss: 2.9033742404158875

Epoch: 5| Step: 3
Training loss: 1.4289555578134874
Validation loss: 2.9196610146037485

Epoch: 5| Step: 4
Training loss: 0.6497981491654262
Validation loss: 2.899238972587783

Epoch: 5| Step: 5
Training loss: 0.7922500585650504
Validation loss: 2.938990367063043

Epoch: 5| Step: 6
Training loss: 1.1359279018243216
Validation loss: 2.9698807386681674

Epoch: 5| Step: 7
Training loss: 0.7252734655077299
Validation loss: 2.9385222556847763

Epoch: 5| Step: 8
Training loss: 0.7436583149921338
Validation loss: 2.9036971265883884

Epoch: 5| Step: 9
Training loss: 0.6337816564188938
Validation loss: 2.8036844377849843

Epoch: 5| Step: 10
Training loss: 0.9671612910107548
Validation loss: 2.8237104015548695

Epoch: 5| Step: 11
Training loss: 0.4708526500464079
Validation loss: 2.8975186086687406

Epoch: 199| Step: 0
Training loss: 0.7296038316221388
Validation loss: 2.737951120020385

Epoch: 5| Step: 1
Training loss: 1.1667276377867508
Validation loss: 2.8408784131503375

Epoch: 5| Step: 2
Training loss: 0.6992811889048343
Validation loss: 2.880184122895528

Epoch: 5| Step: 3
Training loss: 0.9883123098928198
Validation loss: 2.800126826161507

Epoch: 5| Step: 4
Training loss: 0.6292442692862088
Validation loss: 2.850138851458634

Epoch: 5| Step: 5
Training loss: 0.6467537909206061
Validation loss: 2.8978070124309516

Epoch: 5| Step: 6
Training loss: 1.4497347424673404
Validation loss: 2.916405275530158

Epoch: 5| Step: 7
Training loss: 0.740320125233005
Validation loss: 2.8536650861988906

Epoch: 5| Step: 8
Training loss: 0.9090013503262905
Validation loss: 2.8962697047953236

Epoch: 5| Step: 9
Training loss: 0.7619828768831265
Validation loss: 2.818134361443869

Epoch: 5| Step: 10
Training loss: 0.6633827320551805
Validation loss: 2.789880570256213

Epoch: 5| Step: 11
Training loss: 0.47784417201494983
Validation loss: 2.885678476834116

Epoch: 200| Step: 0
Training loss: 0.7094584579779823
Validation loss: 2.8104678653854136

Epoch: 5| Step: 1
Training loss: 0.9161902547927995
Validation loss: 2.8668424968707944

Epoch: 5| Step: 2
Training loss: 0.740037474198901
Validation loss: 2.8801613413522342

Epoch: 5| Step: 3
Training loss: 0.749908759607191
Validation loss: 2.8779387864943184

Epoch: 5| Step: 4
Training loss: 1.6113536485904656
Validation loss: 2.8132453919702947

Epoch: 5| Step: 5
Training loss: 0.7135013838115016
Validation loss: 2.896460877947204

Epoch: 5| Step: 6
Training loss: 0.8636507650251506
Validation loss: 2.8244506367888484

Epoch: 5| Step: 7
Training loss: 0.6477501224825415
Validation loss: 2.801691550243221

Epoch: 5| Step: 8
Training loss: 0.9073907315595381
Validation loss: 2.8732616794625065

Epoch: 5| Step: 9
Training loss: 0.9229607734445282
Validation loss: 2.848163812420449

Epoch: 5| Step: 10
Training loss: 0.6236300713598053
Validation loss: 2.848578130724456

Epoch: 5| Step: 11
Training loss: 0.3097971136533103
Validation loss: 2.9351657697035693

Epoch: 201| Step: 0
Training loss: 1.1653387255081964
Validation loss: 2.960932802919606

Epoch: 5| Step: 1
Training loss: 0.9472906994204717
Validation loss: 2.9995364122359076

Epoch: 5| Step: 2
Training loss: 0.7486354016727744
Validation loss: 3.0113377047622376

Epoch: 5| Step: 3
Training loss: 0.9077478067323773
Validation loss: 2.9009344993169512

Epoch: 5| Step: 4
Training loss: 0.7809137002005726
Validation loss: 2.772357841564388

Epoch: 5| Step: 5
Training loss: 0.7159032006042056
Validation loss: 2.8485735482881993

Epoch: 5| Step: 6
Training loss: 1.0366141938506823
Validation loss: 2.7796541378884654

Epoch: 5| Step: 7
Training loss: 1.6049398400270962
Validation loss: 2.790692676664776

Epoch: 5| Step: 8
Training loss: 0.7801384838976186
Validation loss: 2.7975736345742663

Epoch: 5| Step: 9
Training loss: 0.6647109512044488
Validation loss: 2.937801261090177

Epoch: 5| Step: 10
Training loss: 0.5799744124769959
Validation loss: 2.9057922242023313

Epoch: 5| Step: 11
Training loss: 1.2719961328957512
Validation loss: 2.8949377998803154

Epoch: 202| Step: 0
Training loss: 0.8748691324734077
Validation loss: 2.880559680242558

Epoch: 5| Step: 1
Training loss: 0.7512815176244255
Validation loss: 3.0228503574658876

Epoch: 5| Step: 2
Training loss: 0.6991293013488287
Validation loss: 2.9262550727499352

Epoch: 5| Step: 3
Training loss: 0.6220172278542102
Validation loss: 2.8797357469264444

Epoch: 5| Step: 4
Training loss: 0.7888395542141543
Validation loss: 2.8938373312189167

Epoch: 5| Step: 5
Training loss: 0.8424925441015845
Validation loss: 2.8176519114450467

Epoch: 5| Step: 6
Training loss: 1.6355069210473998
Validation loss: 2.738403437305843

Epoch: 5| Step: 7
Training loss: 1.158494935095017
Validation loss: 2.7119582248966134

Epoch: 5| Step: 8
Training loss: 1.0637061061387287
Validation loss: 2.7782209560727837

Epoch: 5| Step: 9
Training loss: 0.811828849602586
Validation loss: 2.737432017128158

Epoch: 5| Step: 10
Training loss: 0.8073616776820846
Validation loss: 2.837128052161333

Epoch: 5| Step: 11
Training loss: 1.0716488702541254
Validation loss: 2.9730314535121027

Epoch: 203| Step: 0
Training loss: 0.9736995999339633
Validation loss: 2.8919002881527027

Epoch: 5| Step: 1
Training loss: 0.6243912116037679
Validation loss: 2.8305975887223265

Epoch: 5| Step: 2
Training loss: 0.5250272948117972
Validation loss: 2.8135610062632312

Epoch: 5| Step: 3
Training loss: 0.5823598868363278
Validation loss: 2.79116545395819

Epoch: 5| Step: 4
Training loss: 0.7406724826061927
Validation loss: 2.8278824577512554

Epoch: 5| Step: 5
Training loss: 0.7887373150320856
Validation loss: 2.74868289154924

Epoch: 5| Step: 6
Training loss: 1.636040011949608
Validation loss: 2.8207890080716984

Epoch: 5| Step: 7
Training loss: 1.0345990102632316
Validation loss: 2.859379839589066

Epoch: 5| Step: 8
Training loss: 0.5798402549003047
Validation loss: 2.7714724783522215

Epoch: 5| Step: 9
Training loss: 0.9037298480434454
Validation loss: 2.837403964771584

Epoch: 5| Step: 10
Training loss: 0.47066909223805936
Validation loss: 2.8908058522328424

Epoch: 5| Step: 11
Training loss: 0.9047937202357113
Validation loss: 2.9158196490950514

Epoch: 204| Step: 0
Training loss: 0.7944010309956018
Validation loss: 2.7477581249328997

Epoch: 5| Step: 1
Training loss: 0.685787321782171
Validation loss: 2.7675825113150925

Epoch: 5| Step: 2
Training loss: 0.6964553484642096
Validation loss: 2.715378183138314

Epoch: 5| Step: 3
Training loss: 0.8829103601280561
Validation loss: 2.830976074783529

Epoch: 5| Step: 4
Training loss: 0.9902900514619316
Validation loss: 2.8278579234544727

Epoch: 5| Step: 5
Training loss: 1.5294533913760175
Validation loss: 2.7302532520308005

Epoch: 5| Step: 6
Training loss: 0.9315733815363515
Validation loss: 2.8916715256836127

Epoch: 5| Step: 7
Training loss: 0.4965383834936259
Validation loss: 2.864962415176816

Epoch: 5| Step: 8
Training loss: 0.9397117908967669
Validation loss: 2.845049592576439

Epoch: 5| Step: 9
Training loss: 0.5795580655186141
Validation loss: 2.8593816288105156

Epoch: 5| Step: 10
Training loss: 0.7199701236115843
Validation loss: 2.8703583897975253

Epoch: 5| Step: 11
Training loss: 0.27034793356918274
Validation loss: 2.8696836923178446

Epoch: 205| Step: 0
Training loss: 0.7370026026437837
Validation loss: 2.8041401065930835

Epoch: 5| Step: 1
Training loss: 0.42517839852836115
Validation loss: 2.8859757537041384

Epoch: 5| Step: 2
Training loss: 0.7105699783939606
Validation loss: 2.735190892883186

Epoch: 5| Step: 3
Training loss: 0.9372170975130515
Validation loss: 2.7787674207222812

Epoch: 5| Step: 4
Training loss: 0.9798488709150645
Validation loss: 2.8258963421807493

Epoch: 5| Step: 5
Training loss: 0.7614013793213367
Validation loss: 2.7448462179844624

Epoch: 5| Step: 6
Training loss: 0.7374008015012925
Validation loss: 2.864873709555372

Epoch: 5| Step: 7
Training loss: 0.7335802607164477
Validation loss: 2.7814800081619766

Epoch: 5| Step: 8
Training loss: 0.644872540366652
Validation loss: 2.838485056928013

Epoch: 5| Step: 9
Training loss: 0.7088440895532142
Validation loss: 2.813125915109084

Epoch: 5| Step: 10
Training loss: 1.5327030216671342
Validation loss: 2.9501542382409967

Epoch: 5| Step: 11
Training loss: 0.6947482959606993
Validation loss: 2.840857636578187

Epoch: 206| Step: 0
Training loss: 0.8038235072195059
Validation loss: 2.7913561080071925

Epoch: 5| Step: 1
Training loss: 0.7455710132684282
Validation loss: 2.7520953742453806

Epoch: 5| Step: 2
Training loss: 0.9081592836360513
Validation loss: 2.767194503726493

Epoch: 5| Step: 3
Training loss: 1.0557034720687957
Validation loss: 2.816178201938922

Epoch: 5| Step: 4
Training loss: 0.8237373066851819
Validation loss: 2.807585250893995

Epoch: 5| Step: 5
Training loss: 1.4506346168840278
Validation loss: 2.7841237184199055

Epoch: 5| Step: 6
Training loss: 0.6274515470286427
Validation loss: 2.991808791800317

Epoch: 5| Step: 7
Training loss: 0.740319561648877
Validation loss: 2.9361421307707927

Epoch: 5| Step: 8
Training loss: 0.9921314494002794
Validation loss: 2.931008762391206

Epoch: 5| Step: 9
Training loss: 0.8391527748915297
Validation loss: 2.9651492853091757

Epoch: 5| Step: 10
Training loss: 0.7575416867585384
Validation loss: 2.9231053650121592

Epoch: 5| Step: 11
Training loss: 1.4349917214184724
Validation loss: 2.8609195039892543

Epoch: 207| Step: 0
Training loss: 0.8149733311437967
Validation loss: 2.8209571348226574

Epoch: 5| Step: 1
Training loss: 0.7737599480995511
Validation loss: 2.745132194739482

Epoch: 5| Step: 2
Training loss: 0.7688901137775276
Validation loss: 2.7323237672598153

Epoch: 5| Step: 3
Training loss: 0.5705468989443679
Validation loss: 2.822766871307905

Epoch: 5| Step: 4
Training loss: 0.3961671584383991
Validation loss: 2.9092631256031645

Epoch: 5| Step: 5
Training loss: 0.5674976751305101
Validation loss: 2.9316710610941414

Epoch: 5| Step: 6
Training loss: 0.9405470603513658
Validation loss: 2.9643395539234962

Epoch: 5| Step: 7
Training loss: 1.496739818226794
Validation loss: 2.9900771020168193

Epoch: 5| Step: 8
Training loss: 1.1892998757945026
Validation loss: 2.8995488342024953

Epoch: 5| Step: 9
Training loss: 0.7970747603816032
Validation loss: 2.9133646063704677

Epoch: 5| Step: 10
Training loss: 0.6311764702604277
Validation loss: 2.895694051224291

Epoch: 5| Step: 11
Training loss: 0.5630134517339881
Validation loss: 2.798423182317563

Epoch: 208| Step: 0
Training loss: 0.9715982220874914
Validation loss: 2.8903671287092125

Epoch: 5| Step: 1
Training loss: 0.6505305738205984
Validation loss: 2.798280824371572

Epoch: 5| Step: 2
Training loss: 0.7630273386880831
Validation loss: 2.7749962809540625

Epoch: 5| Step: 3
Training loss: 0.9766538653549207
Validation loss: 2.917647855205189

Epoch: 5| Step: 4
Training loss: 0.4858793923081564
Validation loss: 2.977045802597697

Epoch: 5| Step: 5
Training loss: 0.7693970461552447
Validation loss: 2.954009813297366

Epoch: 5| Step: 6
Training loss: 1.5101866536008022
Validation loss: 2.8833854574570976

Epoch: 5| Step: 7
Training loss: 0.6843012608904652
Validation loss: 3.040624297306284

Epoch: 5| Step: 8
Training loss: 0.8046079800026329
Validation loss: 2.9347656117308993

Epoch: 5| Step: 9
Training loss: 0.8487139312990516
Validation loss: 2.839003430292445

Epoch: 5| Step: 10
Training loss: 0.8039294255273844
Validation loss: 2.747563879770532

Epoch: 5| Step: 11
Training loss: 0.201256946982852
Validation loss: 2.7692152164927935

Epoch: 209| Step: 0
Training loss: 0.5484505980576798
Validation loss: 2.8712616644303934

Epoch: 5| Step: 1
Training loss: 0.6756702398068624
Validation loss: 2.8154878992931547

Epoch: 5| Step: 2
Training loss: 0.6604031885338143
Validation loss: 2.8462208294619677

Epoch: 5| Step: 3
Training loss: 0.7480721332478929
Validation loss: 2.7898776361847903

Epoch: 5| Step: 4
Training loss: 0.5366553589812298
Validation loss: 2.8614691550919615

Epoch: 5| Step: 5
Training loss: 0.8218115778482764
Validation loss: 2.8046382945781994

Epoch: 5| Step: 6
Training loss: 1.5199258091036691
Validation loss: 2.936957532425644

Epoch: 5| Step: 7
Training loss: 0.6408068933683486
Validation loss: 2.8569371822101886

Epoch: 5| Step: 8
Training loss: 0.6946660583591665
Validation loss: 2.875508950974762

Epoch: 5| Step: 9
Training loss: 1.094523129375211
Validation loss: 2.860934754500017

Epoch: 5| Step: 10
Training loss: 0.49918986790645764
Validation loss: 2.834286278230175

Epoch: 5| Step: 11
Training loss: 0.5814619672527997
Validation loss: 2.8498207102815276

Epoch: 210| Step: 0
Training loss: 0.9254645920672473
Validation loss: 2.8428663201262694

Epoch: 5| Step: 1
Training loss: 0.8504126598918549
Validation loss: 2.847201034937443

Epoch: 5| Step: 2
Training loss: 0.8909762175197787
Validation loss: 2.896138690839565

Epoch: 5| Step: 3
Training loss: 0.6267489519738167
Validation loss: 2.9277685976477676

Epoch: 5| Step: 4
Training loss: 1.6124348856472532
Validation loss: 2.942645863345371

Epoch: 5| Step: 5
Training loss: 0.5636877659112794
Validation loss: 2.786963665973234

Epoch: 5| Step: 6
Training loss: 0.6838527297861693
Validation loss: 2.760341953969929

Epoch: 5| Step: 7
Training loss: 0.7849791597527831
Validation loss: 2.7621930842266367

Epoch: 5| Step: 8
Training loss: 0.6286277154198977
Validation loss: 2.6778132906766534

Epoch: 5| Step: 9
Training loss: 0.6804350107721576
Validation loss: 2.766820358312429

Epoch: 5| Step: 10
Training loss: 0.6832073754624964
Validation loss: 2.7457344648557394

Epoch: 5| Step: 11
Training loss: 0.7808486670579982
Validation loss: 2.799239918739395

Epoch: 211| Step: 0
Training loss: 0.5945743058964446
Validation loss: 2.8943701050141115

Epoch: 5| Step: 1
Training loss: 0.6990684049286162
Validation loss: 2.832123709736878

Epoch: 5| Step: 2
Training loss: 0.8711715800322727
Validation loss: 2.7559302321133194

Epoch: 5| Step: 3
Training loss: 0.6267915321378186
Validation loss: 2.8561818162722177

Epoch: 5| Step: 4
Training loss: 0.5009986024882761
Validation loss: 2.962376173733886

Epoch: 5| Step: 5
Training loss: 1.5654861906423962
Validation loss: 2.840627045415597

Epoch: 5| Step: 6
Training loss: 1.0047373022191632
Validation loss: 2.8218481650472365

Epoch: 5| Step: 7
Training loss: 0.679272404340185
Validation loss: 2.8224211794037832

Epoch: 5| Step: 8
Training loss: 0.7907472885307258
Validation loss: 2.9084344707399596

Epoch: 5| Step: 9
Training loss: 0.7642019632134058
Validation loss: 2.739736144200136

Epoch: 5| Step: 10
Training loss: 0.6949349996647187
Validation loss: 2.851245831190086

Epoch: 5| Step: 11
Training loss: 0.2909483095695213
Validation loss: 2.7678434127695604

Epoch: 212| Step: 0
Training loss: 0.9065249782241285
Validation loss: 2.8235256176392065

Epoch: 5| Step: 1
Training loss: 0.6250675403341021
Validation loss: 2.8235854146183947

Epoch: 5| Step: 2
Training loss: 0.6574165103759206
Validation loss: 2.9781585846241794

Epoch: 5| Step: 3
Training loss: 0.864202327348082
Validation loss: 2.8401856039574085

Epoch: 5| Step: 4
Training loss: 0.789197740201523
Validation loss: 2.895029345173146

Epoch: 5| Step: 5
Training loss: 0.7195947492747194
Validation loss: 2.8940923841151607

Epoch: 5| Step: 6
Training loss: 0.7748186129911743
Validation loss: 2.8223353112229113

Epoch: 5| Step: 7
Training loss: 0.6407981498999326
Validation loss: 2.9492221537521965

Epoch: 5| Step: 8
Training loss: 0.7714158812430256
Validation loss: 2.81459234609415

Epoch: 5| Step: 9
Training loss: 0.7871917227177107
Validation loss: 2.771850171098031

Epoch: 5| Step: 10
Training loss: 0.675242126272056
Validation loss: 2.811565621896421

Epoch: 5| Step: 11
Training loss: 2.9817288635942756
Validation loss: 2.7963973441970356

Epoch: 213| Step: 0
Training loss: 0.5926767487202981
Validation loss: 2.861971084865629

Epoch: 5| Step: 1
Training loss: 0.6781050578054898
Validation loss: 2.833801021730792

Epoch: 5| Step: 2
Training loss: 0.9090317094557712
Validation loss: 2.906925194765614

Epoch: 5| Step: 3
Training loss: 0.7437867452055359
Validation loss: 2.942858306754028

Epoch: 5| Step: 4
Training loss: 0.7804718338272526
Validation loss: 2.9503001321041027

Epoch: 5| Step: 5
Training loss: 0.7241460341867724
Validation loss: 2.794226121974334

Epoch: 5| Step: 6
Training loss: 0.990933865312246
Validation loss: 2.83868004289534

Epoch: 5| Step: 7
Training loss: 0.6649760974087486
Validation loss: 2.8801578887513717

Epoch: 5| Step: 8
Training loss: 0.7095577559133193
Validation loss: 2.8198901359482984

Epoch: 5| Step: 9
Training loss: 0.7060847401323744
Validation loss: 2.8271421055785995

Epoch: 5| Step: 10
Training loss: 0.7954819039804704
Validation loss: 2.872530591932961

Epoch: 5| Step: 11
Training loss: 2.949306380631055
Validation loss: 2.863670020882731

Epoch: 214| Step: 0
Training loss: 0.7822828713103365
Validation loss: 2.927007044050279

Epoch: 5| Step: 1
Training loss: 1.088621267422926
Validation loss: 2.9748071816412462

Epoch: 5| Step: 2
Training loss: 0.9541091528193312
Validation loss: 2.975002547538158

Epoch: 5| Step: 3
Training loss: 0.7340808847592734
Validation loss: 2.918286664973778

Epoch: 5| Step: 4
Training loss: 0.5394961506385403
Validation loss: 2.9031722818773615

Epoch: 5| Step: 5
Training loss: 0.8345644360778881
Validation loss: 2.8626704204141906

Epoch: 5| Step: 6
Training loss: 0.7504460677198481
Validation loss: 2.858819386432892

Epoch: 5| Step: 7
Training loss: 0.8749423348635013
Validation loss: 2.9426493692257703

Epoch: 5| Step: 8
Training loss: 0.6160907174678415
Validation loss: 2.9296396548285006

Epoch: 5| Step: 9
Training loss: 1.4233313008963184
Validation loss: 2.959451918389556

Epoch: 5| Step: 10
Training loss: 0.6332271300748151
Validation loss: 2.9059525375176776

Epoch: 5| Step: 11
Training loss: 0.44108281058820953
Validation loss: 2.8213691105880203

Epoch: 215| Step: 0
Training loss: 0.6927745017857385
Validation loss: 2.910023007340166

Epoch: 5| Step: 1
Training loss: 0.6999957493244267
Validation loss: 2.9130391462325504

Epoch: 5| Step: 2
Training loss: 1.3559992299091774
Validation loss: 2.834719299047212

Epoch: 5| Step: 3
Training loss: 0.853610035718075
Validation loss: 2.947645688267617

Epoch: 5| Step: 4
Training loss: 0.4870109972691245
Validation loss: 2.83276040698585

Epoch: 5| Step: 5
Training loss: 1.0406827412299975
Validation loss: 2.819918227176867

Epoch: 5| Step: 6
Training loss: 0.8683826012707698
Validation loss: 2.8796914874563417

Epoch: 5| Step: 7
Training loss: 0.7190602918157446
Validation loss: 2.8561353483777103

Epoch: 5| Step: 8
Training loss: 0.5835541891760703
Validation loss: 2.9733440056389777

Epoch: 5| Step: 9
Training loss: 0.6371440286292621
Validation loss: 2.94406358461934

Epoch: 5| Step: 10
Training loss: 0.6215839730567297
Validation loss: 2.9214940188216807

Epoch: 5| Step: 11
Training loss: 0.27214498214094074
Validation loss: 2.936199079401952

Epoch: 216| Step: 0
Training loss: 0.8356205348235775
Validation loss: 2.818643997494228

Epoch: 5| Step: 1
Training loss: 0.5919387949366599
Validation loss: 2.854287709966716

Epoch: 5| Step: 2
Training loss: 1.5272361151581904
Validation loss: 2.784381168300134

Epoch: 5| Step: 3
Training loss: 0.6564590030458117
Validation loss: 2.8506034631855783

Epoch: 5| Step: 4
Training loss: 0.842999513080678
Validation loss: 2.8668265327707236

Epoch: 5| Step: 5
Training loss: 0.661233192835988
Validation loss: 2.8848337291546313

Epoch: 5| Step: 6
Training loss: 0.6301200715568273
Validation loss: 2.78309488007936

Epoch: 5| Step: 7
Training loss: 0.4560749939802517
Validation loss: 2.885873384284992

Epoch: 5| Step: 8
Training loss: 0.6172143954440709
Validation loss: 2.8999502410675646

Epoch: 5| Step: 9
Training loss: 0.7983380518901909
Validation loss: 2.8864339189840287

Epoch: 5| Step: 10
Training loss: 0.6781944230576785
Validation loss: 2.9029412491007007

Epoch: 5| Step: 11
Training loss: 0.618523491716294
Validation loss: 2.959900054422958

Epoch: 217| Step: 0
Training loss: 0.6325035282835727
Validation loss: 2.867249885732702

Epoch: 5| Step: 1
Training loss: 0.6529841905508584
Validation loss: 2.909589178831596

Epoch: 5| Step: 2
Training loss: 0.7269230839970348
Validation loss: 2.8121117217876375

Epoch: 5| Step: 3
Training loss: 1.0081844382787926
Validation loss: 2.8024291117060014

Epoch: 5| Step: 4
Training loss: 0.6696338979939183
Validation loss: 2.7326620531265013

Epoch: 5| Step: 5
Training loss: 0.8823919053917753
Validation loss: 2.743615976592599

Epoch: 5| Step: 6
Training loss: 0.8322700193706848
Validation loss: 2.8211859163412694

Epoch: 5| Step: 7
Training loss: 0.9969240505384358
Validation loss: 2.9224080162268034

Epoch: 5| Step: 8
Training loss: 0.6704584536343008
Validation loss: 2.8247981727994635

Epoch: 5| Step: 9
Training loss: 1.390217796456209
Validation loss: 2.866103030442096

Epoch: 5| Step: 10
Training loss: 0.6427863806803952
Validation loss: 2.862610423083539

Epoch: 5| Step: 11
Training loss: 0.5569871058367007
Validation loss: 2.875899505878251

Epoch: 218| Step: 0
Training loss: 0.7390822651903732
Validation loss: 2.962425099806234

Epoch: 5| Step: 1
Training loss: 0.8099858927969988
Validation loss: 2.828887734734008

Epoch: 5| Step: 2
Training loss: 0.8637205706273925
Validation loss: 2.895071843194138

Epoch: 5| Step: 3
Training loss: 1.4867363067247812
Validation loss: 2.872592128480322

Epoch: 5| Step: 4
Training loss: 0.6033204389567689
Validation loss: 2.887595505118933

Epoch: 5| Step: 5
Training loss: 0.5483823710499008
Validation loss: 2.912288289295464

Epoch: 5| Step: 6
Training loss: 0.6679029599633776
Validation loss: 2.8647249614498995

Epoch: 5| Step: 7
Training loss: 0.6824603903458586
Validation loss: 2.8200312022417364

Epoch: 5| Step: 8
Training loss: 0.7436841631047549
Validation loss: 2.8486637449018173

Epoch: 5| Step: 9
Training loss: 0.6891562927838359
Validation loss: 2.8027396101243665

Epoch: 5| Step: 10
Training loss: 0.9805421839718778
Validation loss: 2.9047159090614234

Epoch: 5| Step: 11
Training loss: 0.6853138236795384
Validation loss: 2.970012366288382

Epoch: 219| Step: 0
Training loss: 0.4307911311286874
Validation loss: 2.845427308410178

Epoch: 5| Step: 1
Training loss: 0.7010816553244564
Validation loss: 2.781480468887832

Epoch: 5| Step: 2
Training loss: 1.084608733301949
Validation loss: 2.8174525701304165

Epoch: 5| Step: 3
Training loss: 1.0837879999663933
Validation loss: 2.7530055960873043

Epoch: 5| Step: 4
Training loss: 0.5479383756835735
Validation loss: 2.8944263379178836

Epoch: 5| Step: 5
Training loss: 1.4873233626176936
Validation loss: 2.8166386776912296

Epoch: 5| Step: 6
Training loss: 0.6419464299276583
Validation loss: 2.9035415026249174

Epoch: 5| Step: 7
Training loss: 0.6294651036320004
Validation loss: 2.919308887044237

Epoch: 5| Step: 8
Training loss: 0.6859305848487787
Validation loss: 2.901768671481769

Epoch: 5| Step: 9
Training loss: 0.7085104795608332
Validation loss: 2.8900565404651988

Epoch: 5| Step: 10
Training loss: 0.6111331421560762
Validation loss: 2.798661934496556

Epoch: 5| Step: 11
Training loss: 0.6695800665526667
Validation loss: 2.8196338812813098

Epoch: 220| Step: 0
Training loss: 0.6857091597488942
Validation loss: 2.869890060168848

Epoch: 5| Step: 1
Training loss: 0.9880085444486315
Validation loss: 2.8074673943849766

Epoch: 5| Step: 2
Training loss: 0.6069752808522801
Validation loss: 2.819720413036775

Epoch: 5| Step: 3
Training loss: 0.9506755372006307
Validation loss: 2.9231262995578566

Epoch: 5| Step: 4
Training loss: 0.5351984049211633
Validation loss: 2.8562245862401996

Epoch: 5| Step: 5
Training loss: 0.537974905199863
Validation loss: 2.8389125558337764

Epoch: 5| Step: 6
Training loss: 1.4553990771765783
Validation loss: 2.9063685574157105

Epoch: 5| Step: 7
Training loss: 0.5761077327909201
Validation loss: 2.8961612540906088

Epoch: 5| Step: 8
Training loss: 0.6975834440066346
Validation loss: 2.8888766113248585

Epoch: 5| Step: 9
Training loss: 0.6165178746635519
Validation loss: 2.8815010002845405

Epoch: 5| Step: 10
Training loss: 0.8382491476234951
Validation loss: 2.802176992748997

Epoch: 5| Step: 11
Training loss: 0.6866074316699877
Validation loss: 2.827314622526434

Epoch: 221| Step: 0
Training loss: 1.5166275798386115
Validation loss: 2.9039764740637257

Epoch: 5| Step: 1
Training loss: 0.5141354923545665
Validation loss: 2.9122830941850704

Epoch: 5| Step: 2
Training loss: 0.6888758590407701
Validation loss: 2.8811971451330827

Epoch: 5| Step: 3
Training loss: 0.85504481292984
Validation loss: 2.8715223412011888

Epoch: 5| Step: 4
Training loss: 0.8715479056038113
Validation loss: 2.7718577582601855

Epoch: 5| Step: 5
Training loss: 0.6800452639086492
Validation loss: 2.858044107881379

Epoch: 5| Step: 6
Training loss: 0.622119919552101
Validation loss: 2.861301252740175

Epoch: 5| Step: 7
Training loss: 0.5855770273824071
Validation loss: 2.871336226485405

Epoch: 5| Step: 8
Training loss: 0.4242945973857224
Validation loss: 2.8711818759394547

Epoch: 5| Step: 9
Training loss: 0.4914402663400339
Validation loss: 2.91032922217899

Epoch: 5| Step: 10
Training loss: 0.8642319497586881
Validation loss: 2.9360912340269896

Epoch: 5| Step: 11
Training loss: 0.4188305535341231
Validation loss: 2.9537481864819237

Epoch: 222| Step: 0
Training loss: 0.8208214770266019
Validation loss: 2.8867811197125537

Epoch: 5| Step: 1
Training loss: 0.7803426814477369
Validation loss: 2.991570328557736

Epoch: 5| Step: 2
Training loss: 0.565035166827531
Validation loss: 3.0605336902872415

Epoch: 5| Step: 3
Training loss: 0.8372140211095885
Validation loss: 2.943113445427529

Epoch: 5| Step: 4
Training loss: 0.7266695497467289
Validation loss: 2.8884967357957563

Epoch: 5| Step: 5
Training loss: 0.8378207304285965
Validation loss: 2.773221798241152

Epoch: 5| Step: 6
Training loss: 0.5911284596807175
Validation loss: 2.8661461168072186

Epoch: 5| Step: 7
Training loss: 0.6643331985744653
Validation loss: 2.77178940854105

Epoch: 5| Step: 8
Training loss: 1.3752572945971868
Validation loss: 2.8989839989726205

Epoch: 5| Step: 9
Training loss: 0.4398467610935385
Validation loss: 2.9015079730773046

Epoch: 5| Step: 10
Training loss: 0.8134855748440971
Validation loss: 2.901244125058944

Epoch: 5| Step: 11
Training loss: 0.3160720991638619
Validation loss: 2.8570698060335813

Epoch: 223| Step: 0
Training loss: 0.44682525211139934
Validation loss: 2.8426755230665317

Epoch: 5| Step: 1
Training loss: 1.5002561986204301
Validation loss: 2.8807546822873107

Epoch: 5| Step: 2
Training loss: 0.5568581139501453
Validation loss: 2.8479134853785246

Epoch: 5| Step: 3
Training loss: 0.8733055192459129
Validation loss: 2.860062820449335

Epoch: 5| Step: 4
Training loss: 0.6762198639957516
Validation loss: 2.789710460232339

Epoch: 5| Step: 5
Training loss: 0.5080141987412019
Validation loss: 2.8732950815208826

Epoch: 5| Step: 6
Training loss: 0.7952179228601124
Validation loss: 2.8509373785273473

Epoch: 5| Step: 7
Training loss: 0.8218383403768151
Validation loss: 2.915401594237425

Epoch: 5| Step: 8
Training loss: 0.9476039321684984
Validation loss: 2.872808305182704

Epoch: 5| Step: 9
Training loss: 0.450909691136204
Validation loss: 2.785251792349708

Epoch: 5| Step: 10
Training loss: 0.7730964139743424
Validation loss: 2.778015613440626

Epoch: 5| Step: 11
Training loss: 0.5913915977527476
Validation loss: 2.8537046912516586

Epoch: 224| Step: 0
Training loss: 0.7471105228149187
Validation loss: 2.7867819030752514

Epoch: 5| Step: 1
Training loss: 0.9878342111211509
Validation loss: 2.827590737363936

Epoch: 5| Step: 2
Training loss: 0.6847899733467238
Validation loss: 2.7908031435241334

Epoch: 5| Step: 3
Training loss: 0.45881755313291345
Validation loss: 2.7451426928825944

Epoch: 5| Step: 4
Training loss: 0.5861836234380511
Validation loss: 2.863959373952515

Epoch: 5| Step: 5
Training loss: 0.70585327652459
Validation loss: 2.8418888771921362

Epoch: 5| Step: 6
Training loss: 0.5420137693215086
Validation loss: 2.933628764411303

Epoch: 5| Step: 7
Training loss: 0.7615865739438368
Validation loss: 2.9252025471627756

Epoch: 5| Step: 8
Training loss: 0.8310178934596915
Validation loss: 2.905024051167281

Epoch: 5| Step: 9
Training loss: 0.7540046746238072
Validation loss: 2.9360095091240472

Epoch: 5| Step: 10
Training loss: 0.7057797224979622
Validation loss: 2.8359629732359317

Epoch: 5| Step: 11
Training loss: 2.8308648594839587
Validation loss: 2.730456510924786

Epoch: 225| Step: 0
Training loss: 0.7227084579167095
Validation loss: 2.7591714941650975

Epoch: 5| Step: 1
Training loss: 0.8747131013547823
Validation loss: 2.8272034599646707

Epoch: 5| Step: 2
Training loss: 0.9831218614667594
Validation loss: 2.8423905878697457

Epoch: 5| Step: 3
Training loss: 0.6472301503361226
Validation loss: 2.784586683675906

Epoch: 5| Step: 4
Training loss: 0.8173770152334178
Validation loss: 2.8518891726589004

Epoch: 5| Step: 5
Training loss: 0.6173734746876681
Validation loss: 2.945745566156409

Epoch: 5| Step: 6
Training loss: 0.6707479205360554
Validation loss: 2.9049956954567424

Epoch: 5| Step: 7
Training loss: 1.3350976010337947
Validation loss: 2.8385456516809517

Epoch: 5| Step: 8
Training loss: 0.687958369474572
Validation loss: 2.9294372349975566

Epoch: 5| Step: 9
Training loss: 0.9145163363086839
Validation loss: 2.805860987620364

Epoch: 5| Step: 10
Training loss: 0.7983555223517779
Validation loss: 2.899881412832868

Epoch: 5| Step: 11
Training loss: 0.5635921154839293
Validation loss: 2.832191276852232

Epoch: 226| Step: 0
Training loss: 0.9343218976499439
Validation loss: 2.830178732232242

Epoch: 5| Step: 1
Training loss: 0.7341233897867833
Validation loss: 2.848046225945048

Epoch: 5| Step: 2
Training loss: 0.6448788716924082
Validation loss: 2.8100597709699695

Epoch: 5| Step: 3
Training loss: 0.5194038292220383
Validation loss: 2.8505378519576294

Epoch: 5| Step: 4
Training loss: 0.5939834537320843
Validation loss: 2.8308343326764107

Epoch: 5| Step: 5
Training loss: 0.4882382793592086
Validation loss: 2.952056681437084

Epoch: 5| Step: 6
Training loss: 1.3162856230665514
Validation loss: 2.837382009128434

Epoch: 5| Step: 7
Training loss: 1.0459499542342814
Validation loss: 2.9685191516467246

Epoch: 5| Step: 8
Training loss: 0.6156336624000803
Validation loss: 2.956454057351463

Epoch: 5| Step: 9
Training loss: 0.6520408109708502
Validation loss: 2.9120396811053193

Epoch: 5| Step: 10
Training loss: 0.47862149060114173
Validation loss: 2.8487316311049717

Epoch: 5| Step: 11
Training loss: 0.44149094165784786
Validation loss: 2.861357743215193

Epoch: 227| Step: 0
Training loss: 0.5994610929264097
Validation loss: 2.8306788861471714

Epoch: 5| Step: 1
Training loss: 1.4013185286630638
Validation loss: 2.890538504741247

Epoch: 5| Step: 2
Training loss: 0.4234861233373283
Validation loss: 2.869230974859616

Epoch: 5| Step: 3
Training loss: 0.7705860170774389
Validation loss: 2.884159435098556

Epoch: 5| Step: 4
Training loss: 0.745108068167901
Validation loss: 2.8133689844797627

Epoch: 5| Step: 5
Training loss: 0.46953839123669766
Validation loss: 2.8383428393148957

Epoch: 5| Step: 6
Training loss: 0.6074120621946526
Validation loss: 2.8195651183327564

Epoch: 5| Step: 7
Training loss: 0.9145902104796243
Validation loss: 2.8521960142645297

Epoch: 5| Step: 8
Training loss: 0.5220499579175412
Validation loss: 2.7848490241954877

Epoch: 5| Step: 9
Training loss: 0.6804510190911405
Validation loss: 2.904598074239791

Epoch: 5| Step: 10
Training loss: 0.8003184772403794
Validation loss: 2.761069743557376

Epoch: 5| Step: 11
Training loss: 0.6541045632212378
Validation loss: 2.812974510077496

Epoch: 228| Step: 0
Training loss: 1.3734402045699605
Validation loss: 2.886452982243773

Epoch: 5| Step: 1
Training loss: 0.8384351406000233
Validation loss: 2.8988598929626725

Epoch: 5| Step: 2
Training loss: 0.7410886962769785
Validation loss: 2.9083753406301867

Epoch: 5| Step: 3
Training loss: 0.6596571259980483
Validation loss: 2.874873075586011

Epoch: 5| Step: 4
Training loss: 0.6807831888475492
Validation loss: 2.9136677083390823

Epoch: 5| Step: 5
Training loss: 0.6698820808536111
Validation loss: 2.941462789383052

Epoch: 5| Step: 6
Training loss: 0.656087650925736
Validation loss: 2.831808168241029

Epoch: 5| Step: 7
Training loss: 0.5448526864922983
Validation loss: 2.8463246284946218

Epoch: 5| Step: 8
Training loss: 0.32142832094704993
Validation loss: 2.840564921309952

Epoch: 5| Step: 9
Training loss: 0.6117111809701946
Validation loss: 2.77039276769845

Epoch: 5| Step: 10
Training loss: 0.6989246367865831
Validation loss: 2.7434562544690952

Epoch: 5| Step: 11
Training loss: 0.48803834595363754
Validation loss: 2.8062007438114747

Epoch: 229| Step: 0
Training loss: 0.8512268454809792
Validation loss: 2.8289923874534737

Epoch: 5| Step: 1
Training loss: 0.42165510310022214
Validation loss: 2.8629440969549287

Epoch: 5| Step: 2
Training loss: 0.5272188957195613
Validation loss: 2.955595594348447

Epoch: 5| Step: 3
Training loss: 1.3663268950131424
Validation loss: 2.860759584015399

Epoch: 5| Step: 4
Training loss: 0.5094833469420859
Validation loss: 2.885978493694513

Epoch: 5| Step: 5
Training loss: 0.618215983592245
Validation loss: 2.7808535361153885

Epoch: 5| Step: 6
Training loss: 0.5939755513284558
Validation loss: 2.978874563466658

Epoch: 5| Step: 7
Training loss: 0.6585277356857872
Validation loss: 2.8675794065079665

Epoch: 5| Step: 8
Training loss: 0.8037586591974949
Validation loss: 2.8341901175622266

Epoch: 5| Step: 9
Training loss: 0.40050605412644796
Validation loss: 2.8251048659381954

Epoch: 5| Step: 10
Training loss: 0.912311245717687
Validation loss: 2.8918788974027505

Epoch: 5| Step: 11
Training loss: 0.8451623398964642
Validation loss: 2.8246882335550616

Epoch: 230| Step: 0
Training loss: 0.5036766652949978
Validation loss: 2.839946323450553

Epoch: 5| Step: 1
Training loss: 0.5260700243366121
Validation loss: 2.830295256926172

Epoch: 5| Step: 2
Training loss: 0.6362302111188202
Validation loss: 2.913824397255169

Epoch: 5| Step: 3
Training loss: 0.651916729623716
Validation loss: 2.899114803820903

Epoch: 5| Step: 4
Training loss: 0.600452389639398
Validation loss: 2.9120650685703167

Epoch: 5| Step: 5
Training loss: 0.587408026131077
Validation loss: 2.9741725421372562

Epoch: 5| Step: 6
Training loss: 0.6717926241033405
Validation loss: 2.7881141995201775

Epoch: 5| Step: 7
Training loss: 0.7797248831370114
Validation loss: 2.805437701386411

Epoch: 5| Step: 8
Training loss: 1.4296666545077823
Validation loss: 2.887614811848219

Epoch: 5| Step: 9
Training loss: 0.7447239149173122
Validation loss: 2.881926351258091

Epoch: 5| Step: 10
Training loss: 0.4286854938438448
Validation loss: 2.869847576937524

Epoch: 5| Step: 11
Training loss: 0.6617939515601471
Validation loss: 2.9924641872197495

Epoch: 231| Step: 0
Training loss: 1.313861776255441
Validation loss: 3.0032577972213508

Epoch: 5| Step: 1
Training loss: 0.7329056426436007
Validation loss: 2.95091415750997

Epoch: 5| Step: 2
Training loss: 0.9074904732427425
Validation loss: 2.8596782940380914

Epoch: 5| Step: 3
Training loss: 0.8555435078324483
Validation loss: 2.901421521496714

Epoch: 5| Step: 4
Training loss: 0.5319564273780464
Validation loss: 2.8292564145171353

Epoch: 5| Step: 5
Training loss: 0.7809751790189512
Validation loss: 2.912548739035029

Epoch: 5| Step: 6
Training loss: 0.7788632364745378
Validation loss: 2.8730919525600367

Epoch: 5| Step: 7
Training loss: 1.049687493458572
Validation loss: 2.7551415705148714

Epoch: 5| Step: 8
Training loss: 0.6597858270021947
Validation loss: 2.806203735157105

Epoch: 5| Step: 9
Training loss: 0.42485286395618443
Validation loss: 2.853458390911942

Epoch: 5| Step: 10
Training loss: 0.6432049832965311
Validation loss: 2.9414641470443805

Epoch: 5| Step: 11
Training loss: 0.7916762619106313
Validation loss: 3.037452336579705

Epoch: 232| Step: 0
Training loss: 1.3623885590361295
Validation loss: 2.9999395072983965

Epoch: 5| Step: 1
Training loss: 0.6045881697419433
Validation loss: 2.9791730311576954

Epoch: 5| Step: 2
Training loss: 0.5932321800130841
Validation loss: 2.9201348098462305

Epoch: 5| Step: 3
Training loss: 0.6348951236970194
Validation loss: 2.887054403197451

Epoch: 5| Step: 4
Training loss: 0.6364855426980364
Validation loss: 2.841086509684315

Epoch: 5| Step: 5
Training loss: 0.7732510968239692
Validation loss: 2.800057743816776

Epoch: 5| Step: 6
Training loss: 0.8021175492820307
Validation loss: 2.858394532873825

Epoch: 5| Step: 7
Training loss: 0.5511143536092027
Validation loss: 2.8960872042588575

Epoch: 5| Step: 8
Training loss: 0.8011010996609927
Validation loss: 2.954351567390039

Epoch: 5| Step: 9
Training loss: 0.9525429871638442
Validation loss: 2.8852783897584677

Epoch: 5| Step: 10
Training loss: 0.5588759663060929
Validation loss: 2.9103796529680412

Epoch: 5| Step: 11
Training loss: 0.6894779795200217
Validation loss: 2.9228104438612723

Epoch: 233| Step: 0
Training loss: 1.3770209978839398
Validation loss: 2.8283577536950686

Epoch: 5| Step: 1
Training loss: 0.5929274633858329
Validation loss: 2.803784280772342

Epoch: 5| Step: 2
Training loss: 0.5420222643505774
Validation loss: 2.895799181528672

Epoch: 5| Step: 3
Training loss: 0.6232962273791849
Validation loss: 2.8934992032713294

Epoch: 5| Step: 4
Training loss: 0.5985007210347127
Validation loss: 2.8013096146522067

Epoch: 5| Step: 5
Training loss: 0.6485885995592826
Validation loss: 2.8597018223605577

Epoch: 5| Step: 6
Training loss: 0.47840951794123593
Validation loss: 2.8104901514609772

Epoch: 5| Step: 7
Training loss: 0.868832582898465
Validation loss: 2.755130692213116

Epoch: 5| Step: 8
Training loss: 0.6415065654409748
Validation loss: 2.80507422767747

Epoch: 5| Step: 9
Training loss: 0.40983336318797936
Validation loss: 2.8074800797308033

Epoch: 5| Step: 10
Training loss: 0.3718235268752361
Validation loss: 2.9043628964747588

Epoch: 5| Step: 11
Training loss: 0.11378526783439112
Validation loss: 2.8200216240200344

Epoch: 234| Step: 0
Training loss: 0.4827819746669941
Validation loss: 2.9137258565320567

Epoch: 5| Step: 1
Training loss: 0.7072733259187373
Validation loss: 2.9222922579687056

Epoch: 5| Step: 2
Training loss: 0.7487978042091469
Validation loss: 2.9645237840063077

Epoch: 5| Step: 3
Training loss: 0.8733588563730017
Validation loss: 2.8500696638025675

Epoch: 5| Step: 4
Training loss: 0.5416051083822518
Validation loss: 2.84181852037504

Epoch: 5| Step: 5
Training loss: 0.5155567066164477
Validation loss: 2.8925397871672063

Epoch: 5| Step: 6
Training loss: 0.6121626937225617
Validation loss: 2.8289550490491018

Epoch: 5| Step: 7
Training loss: 0.6833307686811871
Validation loss: 2.87809997821083

Epoch: 5| Step: 8
Training loss: 1.3997505885438248
Validation loss: 2.784474346901695

Epoch: 5| Step: 9
Training loss: 0.6328946283993397
Validation loss: 2.8578771096878195

Epoch: 5| Step: 10
Training loss: 0.7667357503476709
Validation loss: 2.899672547576018

Epoch: 5| Step: 11
Training loss: 0.5821550480822351
Validation loss: 2.8689513294434663

Epoch: 235| Step: 0
Training loss: 0.7785874964742145
Validation loss: 2.881625809092107

Epoch: 5| Step: 1
Training loss: 1.3989781874182565
Validation loss: 2.8760782617831104

Epoch: 5| Step: 2
Training loss: 0.563377517113946
Validation loss: 2.8394898303826546

Epoch: 5| Step: 3
Training loss: 0.3969943145061379
Validation loss: 2.805060968354106

Epoch: 5| Step: 4
Training loss: 0.6592503940666448
Validation loss: 2.7228859248586965

Epoch: 5| Step: 5
Training loss: 0.95374206204692
Validation loss: 2.796968248968809

Epoch: 5| Step: 6
Training loss: 0.602891049446094
Validation loss: 2.832237264221301

Epoch: 5| Step: 7
Training loss: 0.5561729474224131
Validation loss: 2.833897006306924

Epoch: 5| Step: 8
Training loss: 0.7081217075685489
Validation loss: 2.85408185336288

Epoch: 5| Step: 9
Training loss: 0.49111691858716233
Validation loss: 2.800205797625158

Epoch: 5| Step: 10
Training loss: 0.7078802164792578
Validation loss: 2.8465767424668216

Epoch: 5| Step: 11
Training loss: 0.4329896103160881
Validation loss: 2.830399724231158

Epoch: 236| Step: 0
Training loss: 0.9130431139690549
Validation loss: 2.9254103808780787

Epoch: 5| Step: 1
Training loss: 0.9588962988409367
Validation loss: 2.7892395697055594

Epoch: 5| Step: 2
Training loss: 0.5642428683014898
Validation loss: 2.875879298380489

Epoch: 5| Step: 3
Training loss: 0.6591034795719324
Validation loss: 2.878010120784504

Epoch: 5| Step: 4
Training loss: 0.7740522311426182
Validation loss: 2.8958919225341475

Epoch: 5| Step: 5
Training loss: 0.686229528945186
Validation loss: 2.7766612198338505

Epoch: 5| Step: 6
Training loss: 0.696630364830487
Validation loss: 2.9193882891630785

Epoch: 5| Step: 7
Training loss: 0.7151399426125187
Validation loss: 2.924478013991516

Epoch: 5| Step: 8
Training loss: 0.5440245045076053
Validation loss: 2.8436383200992803

Epoch: 5| Step: 9
Training loss: 1.2732844348492676
Validation loss: 2.7540493073517727

Epoch: 5| Step: 10
Training loss: 0.549565996899689
Validation loss: 2.8103247000877225

Epoch: 5| Step: 11
Training loss: 0.43784138439231785
Validation loss: 2.7334633388266933

Epoch: 237| Step: 0
Training loss: 0.5343396994994251
Validation loss: 2.7664645226485445

Epoch: 5| Step: 1
Training loss: 0.5852772362265033
Validation loss: 2.8281049534489386

Epoch: 5| Step: 2
Training loss: 0.6333300981522633
Validation loss: 2.8168214164824734

Epoch: 5| Step: 3
Training loss: 0.4924668926884434
Validation loss: 2.884533121411364

Epoch: 5| Step: 4
Training loss: 0.6054475842129599
Validation loss: 2.882966145157333

Epoch: 5| Step: 5
Training loss: 0.8191714024980882
Validation loss: 2.8572583346219593

Epoch: 5| Step: 6
Training loss: 1.2863736401477432
Validation loss: 2.9455909968350116

Epoch: 5| Step: 7
Training loss: 0.6075265922927067
Validation loss: 2.8855713425273675

Epoch: 5| Step: 8
Training loss: 0.6903675704271717
Validation loss: 2.8888063362952505

Epoch: 5| Step: 9
Training loss: 0.7015613122602914
Validation loss: 2.931159898149909

Epoch: 5| Step: 10
Training loss: 0.5445576753046879
Validation loss: 2.8361988822905713

Epoch: 5| Step: 11
Training loss: 0.4783838830326965
Validation loss: 2.851260755416361

Epoch: 238| Step: 0
Training loss: 0.5516880227571878
Validation loss: 2.906131102751605

Epoch: 5| Step: 1
Training loss: 1.3032651446245689
Validation loss: 2.888218948865872

Epoch: 5| Step: 2
Training loss: 0.6603878224528997
Validation loss: 2.848559647488978

Epoch: 5| Step: 3
Training loss: 0.5180564829085399
Validation loss: 2.840843238182925

Epoch: 5| Step: 4
Training loss: 0.5085244689725591
Validation loss: 2.9078302223339207

Epoch: 5| Step: 5
Training loss: 0.6128985431808807
Validation loss: 2.9707855273373323

Epoch: 5| Step: 6
Training loss: 0.3535905200171854
Validation loss: 2.8869711077776823

Epoch: 5| Step: 7
Training loss: 0.7780355700841657
Validation loss: 2.87330165401558

Epoch: 5| Step: 8
Training loss: 0.8135097538106
Validation loss: 2.8924151230208905

Epoch: 5| Step: 9
Training loss: 0.7076872001040223
Validation loss: 2.8793003083462483

Epoch: 5| Step: 10
Training loss: 0.48454424762237996
Validation loss: 2.904091985778528

Epoch: 5| Step: 11
Training loss: 0.8892197816769372
Validation loss: 2.844558590383292

Epoch: 239| Step: 0
Training loss: 0.663666079508785
Validation loss: 2.874286739357105

Epoch: 5| Step: 1
Training loss: 0.6440571746531977
Validation loss: 2.9233330915092823

Epoch: 5| Step: 2
Training loss: 0.4996470606402216
Validation loss: 2.8445071131279294

Epoch: 5| Step: 3
Training loss: 0.898136619275031
Validation loss: 2.8811002641386954

Epoch: 5| Step: 4
Training loss: 0.9580219357195132
Validation loss: 2.945856538237849

Epoch: 5| Step: 5
Training loss: 0.5958761245416041
Validation loss: 2.9171336118123636

Epoch: 5| Step: 6
Training loss: 0.5228289297546922
Validation loss: 2.8191267111432565

Epoch: 5| Step: 7
Training loss: 0.41408556747959774
Validation loss: 2.8852652407871306

Epoch: 5| Step: 8
Training loss: 0.5449889220415496
Validation loss: 2.7900473728396644

Epoch: 5| Step: 9
Training loss: 0.5896109317300539
Validation loss: 2.8240418508448095

Epoch: 5| Step: 10
Training loss: 1.2888673114386353
Validation loss: 2.8221649539156606

Epoch: 5| Step: 11
Training loss: 0.43113625519091603
Validation loss: 2.8480137241757038

Epoch: 240| Step: 0
Training loss: 0.5931482528373314
Validation loss: 2.8458574803437044

Epoch: 5| Step: 1
Training loss: 0.6004943777864563
Validation loss: 2.8651558540886097

Epoch: 5| Step: 2
Training loss: 0.7796095600810311
Validation loss: 2.9666339862198594

Epoch: 5| Step: 3
Training loss: 1.3499960669707474
Validation loss: 2.844383288003784

Epoch: 5| Step: 4
Training loss: 0.8541921906418173
Validation loss: 2.8791307718070094

Epoch: 5| Step: 5
Training loss: 0.5704991544688827
Validation loss: 2.7917185014685586

Epoch: 5| Step: 6
Training loss: 0.5875167418184453
Validation loss: 2.845665834802628

Epoch: 5| Step: 7
Training loss: 0.611159353146236
Validation loss: 2.7956486149657622

Epoch: 5| Step: 8
Training loss: 0.6707818653273587
Validation loss: 2.9138372980255305

Epoch: 5| Step: 9
Training loss: 0.4194405747211269
Validation loss: 2.9110099206045787

Epoch: 5| Step: 10
Training loss: 0.828752747613141
Validation loss: 2.8736106895041664

Epoch: 5| Step: 11
Training loss: 0.49364064671574903
Validation loss: 2.793391297572789

Epoch: 241| Step: 0
Training loss: 0.6113722910176598
Validation loss: 2.8389774874533287

Epoch: 5| Step: 1
Training loss: 0.48083080823566954
Validation loss: 2.881341838200508

Epoch: 5| Step: 2
Training loss: 0.6808894261848304
Validation loss: 2.8530393599449146

Epoch: 5| Step: 3
Training loss: 0.678847989303051
Validation loss: 2.8393237491846577

Epoch: 5| Step: 4
Training loss: 0.5255869105233294
Validation loss: 2.8806043988340435

Epoch: 5| Step: 5
Training loss: 0.7501237687665119
Validation loss: 2.8817965294644727

Epoch: 5| Step: 6
Training loss: 1.2204731228630075
Validation loss: 2.8528657190949436

Epoch: 5| Step: 7
Training loss: 0.6722801229098389
Validation loss: 2.939791276138889

Epoch: 5| Step: 8
Training loss: 0.4889830162125758
Validation loss: 2.900705805478141

Epoch: 5| Step: 9
Training loss: 0.4342924451250389
Validation loss: 2.8523459207510333

Epoch: 5| Step: 10
Training loss: 0.7861980908698922
Validation loss: 2.8922229199307483

Epoch: 5| Step: 11
Training loss: 0.22386309997895257
Validation loss: 2.943148285827739

Epoch: 242| Step: 0
Training loss: 0.6954226245895372
Validation loss: 2.859626772831912

Epoch: 5| Step: 1
Training loss: 0.9952891971369427
Validation loss: 2.742006645505983

Epoch: 5| Step: 2
Training loss: 0.7639782771397605
Validation loss: 2.7861395906102286

Epoch: 5| Step: 3
Training loss: 0.5686085210623261
Validation loss: 2.867090429729573

Epoch: 5| Step: 4
Training loss: 0.5674861479005507
Validation loss: 2.939640668629337

Epoch: 5| Step: 5
Training loss: 0.5946030762604074
Validation loss: 3.0737549861367475

Epoch: 5| Step: 6
Training loss: 1.2690373325552986
Validation loss: 2.8956661907965735

Epoch: 5| Step: 7
Training loss: 0.7891411694882717
Validation loss: 2.9489066895697316

Epoch: 5| Step: 8
Training loss: 0.7437723204525197
Validation loss: 2.8783728399991055

Epoch: 5| Step: 9
Training loss: 0.29198411145731423
Validation loss: 2.77306449423487

Epoch: 5| Step: 10
Training loss: 0.6591590256455079
Validation loss: 2.7931160343345227

Epoch: 5| Step: 11
Training loss: 0.48745572304781476
Validation loss: 2.7671840605237836

Epoch: 243| Step: 0
Training loss: 0.9200583516668681
Validation loss: 2.8390022825700183

Epoch: 5| Step: 1
Training loss: 0.7830120053253996
Validation loss: 2.798876257742313

Epoch: 5| Step: 2
Training loss: 0.36199967122721627
Validation loss: 2.8194408813437346

Epoch: 5| Step: 3
Training loss: 0.943325160573012
Validation loss: 2.8738976141135972

Epoch: 5| Step: 4
Training loss: 0.46265479410001054
Validation loss: 2.8946452836926113

Epoch: 5| Step: 5
Training loss: 0.8127219923902794
Validation loss: 2.9501229758950647

Epoch: 5| Step: 6
Training loss: 1.3550460552116632
Validation loss: 2.875358763023625

Epoch: 5| Step: 7
Training loss: 0.5771486698672994
Validation loss: 2.9008092028052466

Epoch: 5| Step: 8
Training loss: 0.48140965575363365
Validation loss: 2.827430857693596

Epoch: 5| Step: 9
Training loss: 0.6338770354217005
Validation loss: 2.874167238786404

Epoch: 5| Step: 10
Training loss: 0.6020032828374554
Validation loss: 2.7810914926687476

Epoch: 5| Step: 11
Training loss: 0.3741004008099556
Validation loss: 2.835702215545702

Epoch: 244| Step: 0
Training loss: 0.6964901370303862
Validation loss: 2.819343647045046

Epoch: 5| Step: 1
Training loss: 0.5597403169861834
Validation loss: 2.816125493334508

Epoch: 5| Step: 2
Training loss: 0.43477668576767264
Validation loss: 2.8649585801770443

Epoch: 5| Step: 3
Training loss: 0.7027291137091232
Validation loss: 2.7948335304399707

Epoch: 5| Step: 4
Training loss: 0.5604011000512168
Validation loss: 2.7993534302382628

Epoch: 5| Step: 5
Training loss: 0.7167518871855997
Validation loss: 2.838421115006888

Epoch: 5| Step: 6
Training loss: 0.5547717930319661
Validation loss: 2.8031067923100155

Epoch: 5| Step: 7
Training loss: 0.7753833222705937
Validation loss: 2.815442329913796

Epoch: 5| Step: 8
Training loss: 0.3681398985848158
Validation loss: 2.879693160566375

Epoch: 5| Step: 9
Training loss: 1.3350105862429928
Validation loss: 2.863114633608726

Epoch: 5| Step: 10
Training loss: 0.5692637742963986
Validation loss: 2.8511041455756954

Epoch: 5| Step: 11
Training loss: 0.36235146850287314
Validation loss: 2.9215896555512098

Epoch: 245| Step: 0
Training loss: 1.2650131347788547
Validation loss: 2.864567636389063

Epoch: 5| Step: 1
Training loss: 0.395222125069987
Validation loss: 2.7932644738626062

Epoch: 5| Step: 2
Training loss: 0.7133527538145604
Validation loss: 2.7790504966507212

Epoch: 5| Step: 3
Training loss: 0.4807473902143003
Validation loss: 2.826981571524042

Epoch: 5| Step: 4
Training loss: 0.6419904392591161
Validation loss: 2.813941796167757

Epoch: 5| Step: 5
Training loss: 0.7263963570908858
Validation loss: 2.864104634370632

Epoch: 5| Step: 6
Training loss: 0.5465692210234057
Validation loss: 2.820350787606479

Epoch: 5| Step: 7
Training loss: 0.695919971630733
Validation loss: 2.8487966248659746

Epoch: 5| Step: 8
Training loss: 0.6724804656300826
Validation loss: 2.909656705374143

Epoch: 5| Step: 9
Training loss: 0.6721546345244012
Validation loss: 2.852034110867558

Epoch: 5| Step: 10
Training loss: 0.5713820161757969
Validation loss: 2.837626340548931

Epoch: 5| Step: 11
Training loss: 0.5529081253488247
Validation loss: 2.8132529098663834

Epoch: 246| Step: 0
Training loss: 0.5152381254787032
Validation loss: 2.821545106988631

Epoch: 5| Step: 1
Training loss: 0.6073946440747278
Validation loss: 2.8580681831940518

Epoch: 5| Step: 2
Training loss: 1.323699894534063
Validation loss: 2.8314213554226813

Epoch: 5| Step: 3
Training loss: 0.40347353631726807
Validation loss: 2.939390679896957

Epoch: 5| Step: 4
Training loss: 0.5275359757074283
Validation loss: 2.8840918730221246

Epoch: 5| Step: 5
Training loss: 0.8011652328238192
Validation loss: 2.8479030172546023

Epoch: 5| Step: 6
Training loss: 0.43382693369719194
Validation loss: 2.8957353233428296

Epoch: 5| Step: 7
Training loss: 0.8962506423798923
Validation loss: 2.9303536094419953

Epoch: 5| Step: 8
Training loss: 0.5987553183333342
Validation loss: 2.836594592176908

Epoch: 5| Step: 9
Training loss: 0.5710789481565736
Validation loss: 2.7867842807449366

Epoch: 5| Step: 10
Training loss: 0.5248905908022877
Validation loss: 2.8552489293935386

Epoch: 5| Step: 11
Training loss: 0.6030612951443173
Validation loss: 2.7822893286699597

Epoch: 247| Step: 0
Training loss: 0.3981325066785498
Validation loss: 2.8480270311801994

Epoch: 5| Step: 1
Training loss: 0.4411282803474837
Validation loss: 2.953855763867976

Epoch: 5| Step: 2
Training loss: 0.5430706395116459
Validation loss: 2.8430708434008567

Epoch: 5| Step: 3
Training loss: 1.260055201168973
Validation loss: 2.8376891381221525

Epoch: 5| Step: 4
Training loss: 0.4711960392067004
Validation loss: 2.8713498405720568

Epoch: 5| Step: 5
Training loss: 0.7001221005352988
Validation loss: 2.792849223818253

Epoch: 5| Step: 6
Training loss: 0.6283481799234315
Validation loss: 2.7933066743881243

Epoch: 5| Step: 7
Training loss: 0.543562886501463
Validation loss: 2.807688206755762

Epoch: 5| Step: 8
Training loss: 0.6899686620340671
Validation loss: 2.8398806409088153

Epoch: 5| Step: 9
Training loss: 0.712190718197885
Validation loss: 2.851167043498985

Epoch: 5| Step: 10
Training loss: 0.5398843830014866
Validation loss: 2.8774344876120583

Epoch: 5| Step: 11
Training loss: 0.4728703289885291
Validation loss: 2.8598849149370626

Epoch: 248| Step: 0
Training loss: 0.5565160243802494
Validation loss: 2.8979827870345245

Epoch: 5| Step: 1
Training loss: 1.2243283571449752
Validation loss: 2.8183401260899448

Epoch: 5| Step: 2
Training loss: 0.48646198866272033
Validation loss: 2.9088925615518515

Epoch: 5| Step: 3
Training loss: 0.6064587282917497
Validation loss: 2.8341797214294506

Epoch: 5| Step: 4
Training loss: 0.7111140859768486
Validation loss: 2.9022328495488585

Epoch: 5| Step: 5
Training loss: 0.4586092775695724
Validation loss: 2.8515007221375526

Epoch: 5| Step: 6
Training loss: 0.42964564032831526
Validation loss: 2.8028386999334702

Epoch: 5| Step: 7
Training loss: 0.6703570984629088
Validation loss: 2.732394967481798

Epoch: 5| Step: 8
Training loss: 0.5972444449462208
Validation loss: 2.7955015795554328

Epoch: 5| Step: 9
Training loss: 0.5766793295493485
Validation loss: 2.874849232576621

Epoch: 5| Step: 10
Training loss: 0.8117847962812113
Validation loss: 2.8139393514219506

Epoch: 5| Step: 11
Training loss: 0.7938390756923019
Validation loss: 2.8293532203738816

Epoch: 249| Step: 0
Training loss: 0.7733074425674002
Validation loss: 2.880128860526895

Epoch: 5| Step: 1
Training loss: 0.6722719661007956
Validation loss: 2.9068424174800374

Epoch: 5| Step: 2
Training loss: 1.245840734547008
Validation loss: 2.9097817916103503

Epoch: 5| Step: 3
Training loss: 0.7782497780882571
Validation loss: 2.9814499739322984

Epoch: 5| Step: 4
Training loss: 0.38213927569067097
Validation loss: 2.8384044100739247

Epoch: 5| Step: 5
Training loss: 0.5878091546571358
Validation loss: 2.8844149545786384

Epoch: 5| Step: 6
Training loss: 0.45343538045880744
Validation loss: 2.8622121718956173

Epoch: 5| Step: 7
Training loss: 0.4799035166837516
Validation loss: 2.938654581384406

Epoch: 5| Step: 8
Training loss: 0.6984637995809831
Validation loss: 2.876976349756955

Epoch: 5| Step: 9
Training loss: 0.47286894245185385
Validation loss: 2.868137967791169

Epoch: 5| Step: 10
Training loss: 0.48509098787313276
Validation loss: 2.9018035050430164

Epoch: 5| Step: 11
Training loss: 0.3755576636373887
Validation loss: 2.8998109334530393

Epoch: 250| Step: 0
Training loss: 0.4430477206498391
Validation loss: 2.8133942418676505

Epoch: 5| Step: 1
Training loss: 1.2451803752348962
Validation loss: 3.001463377529035

Epoch: 5| Step: 2
Training loss: 0.4257211730289956
Validation loss: 2.9113755029532116

Epoch: 5| Step: 3
Training loss: 0.7569358316761726
Validation loss: 2.8839483151469327

Epoch: 5| Step: 4
Training loss: 0.6837197105979474
Validation loss: 2.845340605304915

Epoch: 5| Step: 5
Training loss: 0.4936512268838596
Validation loss: 2.8529346178315627

Epoch: 5| Step: 6
Training loss: 0.5959697439415367
Validation loss: 2.878062772958314

Epoch: 5| Step: 7
Training loss: 0.44735640225121076
Validation loss: 2.8013539245315617

Epoch: 5| Step: 8
Training loss: 0.5789046057138502
Validation loss: 2.833129238510075

Epoch: 5| Step: 9
Training loss: 0.5905311570471027
Validation loss: 2.7671327809187085

Epoch: 5| Step: 10
Training loss: 0.6407709420674308
Validation loss: 2.822919111262503

Epoch: 5| Step: 11
Training loss: 0.794584835499819
Validation loss: 2.8495789705588828

Epoch: 251| Step: 0
Training loss: 0.8169483046267715
Validation loss: 2.8508884661016607

Epoch: 5| Step: 1
Training loss: 1.2619580493671043
Validation loss: 2.94579221223748

Epoch: 5| Step: 2
Training loss: 0.5919698581996312
Validation loss: 2.8309173884043926

Epoch: 5| Step: 3
Training loss: 0.7836111627775771
Validation loss: 2.8631607141316477

Epoch: 5| Step: 4
Training loss: 0.41042290148703076
Validation loss: 2.8756840831863997

Epoch: 5| Step: 5
Training loss: 0.5653907090424605
Validation loss: 2.73698188038748

Epoch: 5| Step: 6
Training loss: 0.5966081841762663
Validation loss: 2.820287970297982

Epoch: 5| Step: 7
Training loss: 0.5589792748517797
Validation loss: 2.776342165764099

Epoch: 5| Step: 8
Training loss: 0.6996617538806107
Validation loss: 2.840547599479384

Epoch: 5| Step: 9
Training loss: 0.37156250109083017
Validation loss: 2.849630392797577

Epoch: 5| Step: 10
Training loss: 0.7832091371681258
Validation loss: 2.954291992775283

Epoch: 5| Step: 11
Training loss: 1.0774259650690985
Validation loss: 2.8812077129568032

Epoch: 252| Step: 0
Training loss: 0.6357445782735144
Validation loss: 2.9923291450884926

Epoch: 5| Step: 1
Training loss: 0.7269364081935311
Validation loss: 2.8658520276165302

Epoch: 5| Step: 2
Training loss: 0.5186612581849146
Validation loss: 2.8220580379960047

Epoch: 5| Step: 3
Training loss: 0.3667488318556662
Validation loss: 2.734182587166147

Epoch: 5| Step: 4
Training loss: 0.6430415189962819
Validation loss: 2.811084910541016

Epoch: 5| Step: 5
Training loss: 0.7883436875809229
Validation loss: 2.7821920456803273

Epoch: 5| Step: 6
Training loss: 0.4158228396172731
Validation loss: 2.801740183375357

Epoch: 5| Step: 7
Training loss: 0.4617923632707751
Validation loss: 2.775917388014057

Epoch: 5| Step: 8
Training loss: 0.6357367027503182
Validation loss: 2.844641720342205

Epoch: 5| Step: 9
Training loss: 0.7354031933494953
Validation loss: 2.8529424681392146

Epoch: 5| Step: 10
Training loss: 1.4252127572228752
Validation loss: 2.9926102109748407

Epoch: 5| Step: 11
Training loss: 0.21102571408933138
Validation loss: 2.8200026224791506

Epoch: 253| Step: 0
Training loss: 0.4909515150851205
Validation loss: 2.801345867597229

Epoch: 5| Step: 1
Training loss: 0.3462505209398999
Validation loss: 2.7230267302302846

Epoch: 5| Step: 2
Training loss: 0.5183469999398561
Validation loss: 2.7975353832353753

Epoch: 5| Step: 3
Training loss: 0.786755427819103
Validation loss: 2.7777178441310695

Epoch: 5| Step: 4
Training loss: 0.49592643078840254
Validation loss: 2.75392587352642

Epoch: 5| Step: 5
Training loss: 0.50675596219937
Validation loss: 2.799843102980945

Epoch: 5| Step: 6
Training loss: 0.8058529164309248
Validation loss: 2.7663187424843034

Epoch: 5| Step: 7
Training loss: 0.5343591643100757
Validation loss: 2.962530306568531

Epoch: 5| Step: 8
Training loss: 0.735907639466651
Validation loss: 2.856399739219783

Epoch: 5| Step: 9
Training loss: 1.24307070828845
Validation loss: 2.888254066224484

Epoch: 5| Step: 10
Training loss: 0.49076537899963474
Validation loss: 2.8756533999782796

Epoch: 5| Step: 11
Training loss: 0.7811057529797769
Validation loss: 2.8086071907185204

Epoch: 254| Step: 0
Training loss: 0.5841242389898488
Validation loss: 2.862867130240909

Epoch: 5| Step: 1
Training loss: 0.8017047674029952
Validation loss: 2.8912679146292604

Epoch: 5| Step: 2
Training loss: 1.273026382454588
Validation loss: 2.8747778578643444

Epoch: 5| Step: 3
Training loss: 0.3922499238446309
Validation loss: 2.954267950074847

Epoch: 5| Step: 4
Training loss: 0.6651158225507638
Validation loss: 2.792018410362839

Epoch: 5| Step: 5
Training loss: 0.40296920752675003
Validation loss: 2.8363928486221246

Epoch: 5| Step: 6
Training loss: 0.4552114397840616
Validation loss: 2.8139215444295718

Epoch: 5| Step: 7
Training loss: 0.4155649600725684
Validation loss: 2.875651651972104

Epoch: 5| Step: 8
Training loss: 0.5415960565418522
Validation loss: 2.885954763088562

Epoch: 5| Step: 9
Training loss: 0.775517912057089
Validation loss: 2.7449230377396026

Epoch: 5| Step: 10
Training loss: 0.47929191680059785
Validation loss: 2.7133390286297585

Epoch: 5| Step: 11
Training loss: 0.6444504889550959
Validation loss: 2.8807386814848397

Epoch: 255| Step: 0
Training loss: 0.6271891402226446
Validation loss: 2.8439288100593494

Epoch: 5| Step: 1
Training loss: 0.554081733787172
Validation loss: 2.8774218689955275

Epoch: 5| Step: 2
Training loss: 0.5176033445727792
Validation loss: 2.8699128297866

Epoch: 5| Step: 3
Training loss: 0.47009922400570564
Validation loss: 2.81850879367397

Epoch: 5| Step: 4
Training loss: 0.5570479926847404
Validation loss: 2.796166655279343

Epoch: 5| Step: 5
Training loss: 0.6504377972332842
Validation loss: 2.8395249206587736

Epoch: 5| Step: 6
Training loss: 0.4098700114950312
Validation loss: 2.836757898546449

Epoch: 5| Step: 7
Training loss: 0.4189853782435521
Validation loss: 2.818006578457159

Epoch: 5| Step: 8
Training loss: 0.34555065434989635
Validation loss: 2.866013677287115

Epoch: 5| Step: 9
Training loss: 0.5823068158448675
Validation loss: 2.8060825848785202

Epoch: 5| Step: 10
Training loss: 1.3930386802248749
Validation loss: 2.944371208793625

Epoch: 5| Step: 11
Training loss: 0.2400395448461021
Validation loss: 2.925560101247877

Epoch: 256| Step: 0
Training loss: 0.9398337879746929
Validation loss: 2.8065430711159305

Epoch: 5| Step: 1
Training loss: 0.581097615683802
Validation loss: 2.907052568485477

Epoch: 5| Step: 2
Training loss: 1.2634827178932513
Validation loss: 2.8825686385228173

Epoch: 5| Step: 3
Training loss: 0.5436157926918704
Validation loss: 2.8859437100808867

Epoch: 5| Step: 4
Training loss: 0.5122552636259166
Validation loss: 2.9032834064915045

Epoch: 5| Step: 5
Training loss: 0.6096559757077772
Validation loss: 2.924810053969583

Epoch: 5| Step: 6
Training loss: 0.5292275583971862
Validation loss: 2.8443473915051616

Epoch: 5| Step: 7
Training loss: 0.45882864400118833
Validation loss: 2.8889996504080844

Epoch: 5| Step: 8
Training loss: 0.6257052019370335
Validation loss: 2.980422899952631

Epoch: 5| Step: 9
Training loss: 0.6347143533980825
Validation loss: 2.910521564126988

Epoch: 5| Step: 10
Training loss: 0.32788391566325586
Validation loss: 2.891160252133764

Epoch: 5| Step: 11
Training loss: 0.5125162738449257
Validation loss: 2.8681997925391585

Epoch: 257| Step: 0
Training loss: 0.5377877684896457
Validation loss: 2.7537808906033536

Epoch: 5| Step: 1
Training loss: 1.3265202420067375
Validation loss: 2.8666659373644707

Epoch: 5| Step: 2
Training loss: 0.4479821142538963
Validation loss: 2.8459640379827587

Epoch: 5| Step: 3
Training loss: 0.4771024271907484
Validation loss: 2.89976146994069

Epoch: 5| Step: 4
Training loss: 0.4713828058833144
Validation loss: 2.86609193033843

Epoch: 5| Step: 5
Training loss: 0.7533561794929652
Validation loss: 2.883056016955794

Epoch: 5| Step: 6
Training loss: 0.5675554915534089
Validation loss: 2.8342519572901965

Epoch: 5| Step: 7
Training loss: 0.48115247444226933
Validation loss: 2.850510125210095

Epoch: 5| Step: 8
Training loss: 0.5943837046662725
Validation loss: 2.9628008110299437

Epoch: 5| Step: 9
Training loss: 0.3766387260814844
Validation loss: 2.8202237637439085

Epoch: 5| Step: 10
Training loss: 0.447115660601074
Validation loss: 2.921350268812884

Epoch: 5| Step: 11
Training loss: 0.5018217159693049
Validation loss: 2.907234705293285

Epoch: 258| Step: 0
Training loss: 0.6103242425526284
Validation loss: 2.8082625150005196

Epoch: 5| Step: 1
Training loss: 0.519442500514826
Validation loss: 2.952294056159477

Epoch: 5| Step: 2
Training loss: 0.7354979350400109
Validation loss: 2.8314357894502598

Epoch: 5| Step: 3
Training loss: 0.5578859820437799
Validation loss: 2.890011672515572

Epoch: 5| Step: 4
Training loss: 0.523269968124792
Validation loss: 2.8122416942800577

Epoch: 5| Step: 5
Training loss: 0.5059027340249757
Validation loss: 2.8991948361045714

Epoch: 5| Step: 6
Training loss: 0.6288667749372394
Validation loss: 2.902810395943256

Epoch: 5| Step: 7
Training loss: 0.5619237650330952
Validation loss: 2.8135961974780823

Epoch: 5| Step: 8
Training loss: 0.45884488197773665
Validation loss: 2.9492409913695954

Epoch: 5| Step: 9
Training loss: 0.5147132615554193
Validation loss: 2.8294415755177993

Epoch: 5| Step: 10
Training loss: 1.2264838709806813
Validation loss: 2.8987891848406306

Epoch: 5| Step: 11
Training loss: 0.6432690833263617
Validation loss: 2.8465408561794696

Epoch: 259| Step: 0
Training loss: 1.1734110111746587
Validation loss: 2.9278282369336686

Epoch: 5| Step: 1
Training loss: 0.5414289967876392
Validation loss: 2.9537176718216043

Epoch: 5| Step: 2
Training loss: 0.6332523324473934
Validation loss: 2.917619765187079

Epoch: 5| Step: 3
Training loss: 0.44784303732742037
Validation loss: 2.8129047067299715

Epoch: 5| Step: 4
Training loss: 0.559064919822066
Validation loss: 2.792734882371302

Epoch: 5| Step: 5
Training loss: 0.5783566449008285
Validation loss: 2.7724821030096733

Epoch: 5| Step: 6
Training loss: 0.43601629167268957
Validation loss: 2.8501354217423525

Epoch: 5| Step: 7
Training loss: 0.38494895788681693
Validation loss: 2.809108699303104

Epoch: 5| Step: 8
Training loss: 0.9499030452744114
Validation loss: 2.9281624652171545

Epoch: 5| Step: 9
Training loss: 0.8153166367062905
Validation loss: 2.931983495659323

Epoch: 5| Step: 10
Training loss: 0.5505718347124234
Validation loss: 2.8763889261066953

Epoch: 5| Step: 11
Training loss: 0.6053089546253397
Validation loss: 2.8755647719626727

Epoch: 260| Step: 0
Training loss: 0.6898134278905278
Validation loss: 2.8842152023272947

Epoch: 5| Step: 1
Training loss: 1.28268807814909
Validation loss: 2.819346134672541

Epoch: 5| Step: 2
Training loss: 0.46684820299982416
Validation loss: 2.843809825840822

Epoch: 5| Step: 3
Training loss: 0.44006838643672214
Validation loss: 2.787012730762709

Epoch: 5| Step: 4
Training loss: 0.441400527917013
Validation loss: 2.850858181582445

Epoch: 5| Step: 5
Training loss: 0.7662831805514333
Validation loss: 2.7887789620423478

Epoch: 5| Step: 6
Training loss: 0.561016962272645
Validation loss: 2.7777903359182257

Epoch: 5| Step: 7
Training loss: 0.6979838713747254
Validation loss: 2.7491798369940246

Epoch: 5| Step: 8
Training loss: 0.4627828673793564
Validation loss: 2.901503847426741

Epoch: 5| Step: 9
Training loss: 0.6394913109136111
Validation loss: 2.922305651664562

Epoch: 5| Step: 10
Training loss: 0.7039761372038629
Validation loss: 2.884510343220435

Epoch: 5| Step: 11
Training loss: 0.26889632256030066
Validation loss: 2.7936078423012103

Epoch: 261| Step: 0
Training loss: 0.6313064219498775
Validation loss: 2.7971176489737557

Epoch: 5| Step: 1
Training loss: 0.6534551871855472
Validation loss: 2.7723039594055563

Epoch: 5| Step: 2
Training loss: 0.5432656388978782
Validation loss: 2.735092047270426

Epoch: 5| Step: 3
Training loss: 0.7630027708100771
Validation loss: 2.6903501338470397

Epoch: 5| Step: 4
Training loss: 0.5435908753400486
Validation loss: 2.8084496260844207

Epoch: 5| Step: 5
Training loss: 0.43154619659853366
Validation loss: 2.797781692528993

Epoch: 5| Step: 6
Training loss: 0.46216265257614475
Validation loss: 2.8087075908511094

Epoch: 5| Step: 7
Training loss: 0.39169342789973705
Validation loss: 2.8262077703615196

Epoch: 5| Step: 8
Training loss: 0.501976398566723
Validation loss: 2.80063696169936

Epoch: 5| Step: 9
Training loss: 0.5605892471089252
Validation loss: 2.779727304655014

Epoch: 5| Step: 10
Training loss: 0.4836538083401257
Validation loss: 2.8652765209840165

Epoch: 5| Step: 11
Training loss: 2.5578043644518793
Validation loss: 2.846954761648175

Epoch: 262| Step: 0
Training loss: 0.6231268947958953
Validation loss: 2.9018034554033494

Epoch: 5| Step: 1
Training loss: 0.5526110508160684
Validation loss: 2.777322203046912

Epoch: 5| Step: 2
Training loss: 0.4509795633631702
Validation loss: 2.8174694204433908

Epoch: 5| Step: 3
Training loss: 0.4610708496394675
Validation loss: 2.8050389437145173

Epoch: 5| Step: 4
Training loss: 0.6181273969289439
Validation loss: 2.7885206641877702

Epoch: 5| Step: 5
Training loss: 1.347449024135057
Validation loss: 2.7931691131215373

Epoch: 5| Step: 6
Training loss: 0.6679509701509682
Validation loss: 2.898975096249864

Epoch: 5| Step: 7
Training loss: 0.43565945389173355
Validation loss: 2.8841005633539414

Epoch: 5| Step: 8
Training loss: 0.5426991843284042
Validation loss: 3.0336441927873334

Epoch: 5| Step: 9
Training loss: 0.841645689661971
Validation loss: 3.009873843944727

Epoch: 5| Step: 10
Training loss: 0.526043709351253
Validation loss: 2.9299890761394205

Epoch: 5| Step: 11
Training loss: 0.350588381447947
Validation loss: 2.9193540771666715

Epoch: 263| Step: 0
Training loss: 0.6988196912483683
Validation loss: 2.847590162699071

Epoch: 5| Step: 1
Training loss: 0.9685610617696926
Validation loss: 2.8274601283018095

Epoch: 5| Step: 2
Training loss: 0.6597144776162998
Validation loss: 2.8581683560760376

Epoch: 5| Step: 3
Training loss: 0.4861460578557748
Validation loss: 2.874569179901684

Epoch: 5| Step: 4
Training loss: 0.5572209060761584
Validation loss: 2.961113386876956

Epoch: 5| Step: 5
Training loss: 1.4049957616070117
Validation loss: 2.95927129346921

Epoch: 5| Step: 6
Training loss: 0.9417969458828002
Validation loss: 3.0391922525068567

Epoch: 5| Step: 7
Training loss: 0.6494704831503163
Validation loss: 3.046256949837236

Epoch: 5| Step: 8
Training loss: 0.5297309812630542
Validation loss: 2.9197709843019513

Epoch: 5| Step: 9
Training loss: 0.8474592691947093
Validation loss: 2.865966588901038

Epoch: 5| Step: 10
Training loss: 0.5790428916711589
Validation loss: 2.8948025835803017

Epoch: 5| Step: 11
Training loss: 1.058333811922541
Validation loss: 2.844344803503077

Epoch: 264| Step: 0
Training loss: 0.5086291568930299
Validation loss: 2.9066760185037306

Epoch: 5| Step: 1
Training loss: 0.6799158830717278
Validation loss: 2.980020781882999

Epoch: 5| Step: 2
Training loss: 0.7359399151610574
Validation loss: 3.0616466118199517

Epoch: 5| Step: 3
Training loss: 0.5651707822383033
Validation loss: 3.0108013578266064

Epoch: 5| Step: 4
Training loss: 0.6338094934306236
Validation loss: 3.027248254725986

Epoch: 5| Step: 5
Training loss: 0.4783816247276515
Validation loss: 2.9643987389518207

Epoch: 5| Step: 6
Training loss: 0.6871070822742026
Validation loss: 2.9155779214310633

Epoch: 5| Step: 7
Training loss: 0.8070026905955636
Validation loss: 2.8989703056279215

Epoch: 5| Step: 8
Training loss: 0.6898198003704915
Validation loss: 2.761983661814602

Epoch: 5| Step: 9
Training loss: 0.6942704568238512
Validation loss: 2.7518387087773175

Epoch: 5| Step: 10
Training loss: 1.2265397573901713
Validation loss: 2.8177947291434005

Epoch: 5| Step: 11
Training loss: 0.4378298980229372
Validation loss: 2.893497950134641

Epoch: 265| Step: 0
Training loss: 0.659453203887989
Validation loss: 2.8962751275669563

Epoch: 5| Step: 1
Training loss: 0.7076185537562498
Validation loss: 2.8280480059967257

Epoch: 5| Step: 2
Training loss: 0.6325003478083201
Validation loss: 2.9429932442308986

Epoch: 5| Step: 3
Training loss: 0.47787524600350695
Validation loss: 2.801656681086869

Epoch: 5| Step: 4
Training loss: 1.1906259952250648
Validation loss: 2.84132054063036

Epoch: 5| Step: 5
Training loss: 0.6894387305813008
Validation loss: 2.8539594983468572

Epoch: 5| Step: 6
Training loss: 0.6039591520562028
Validation loss: 2.812722162020058

Epoch: 5| Step: 7
Training loss: 0.5438008142164279
Validation loss: 2.815745272168689

Epoch: 5| Step: 8
Training loss: 0.5292376946166124
Validation loss: 2.870240560040903

Epoch: 5| Step: 9
Training loss: 0.5879409362961812
Validation loss: 2.8092622628963464

Epoch: 5| Step: 10
Training loss: 0.4273331035843012
Validation loss: 2.8511884330759636

Epoch: 5| Step: 11
Training loss: 0.5152806953160215
Validation loss: 2.8963904165135035

Epoch: 266| Step: 0
Training loss: 0.8116931209979074
Validation loss: 2.964962711887787

Epoch: 5| Step: 1
Training loss: 0.6194334330551803
Validation loss: 2.874026911296294

Epoch: 5| Step: 2
Training loss: 1.1776536499496815
Validation loss: 2.8585671080885295

Epoch: 5| Step: 3
Training loss: 0.37981790806980087
Validation loss: 2.8704352629298158

Epoch: 5| Step: 4
Training loss: 0.4629491777045444
Validation loss: 2.827190371187552

Epoch: 5| Step: 5
Training loss: 0.6902394983763169
Validation loss: 2.717287781180879

Epoch: 5| Step: 6
Training loss: 0.5307358048472801
Validation loss: 2.755109166245799

Epoch: 5| Step: 7
Training loss: 0.572280232630396
Validation loss: 2.8672577748014874

Epoch: 5| Step: 8
Training loss: 0.6034759705981556
Validation loss: 2.813926984682457

Epoch: 5| Step: 9
Training loss: 0.4467145198156071
Validation loss: 2.775465436084197

Epoch: 5| Step: 10
Training loss: 0.5477602197450209
Validation loss: 2.8843807892691338

Epoch: 5| Step: 11
Training loss: 0.26709398618620506
Validation loss: 2.8018011721578504

Epoch: 267| Step: 0
Training loss: 0.590310953803635
Validation loss: 2.829329397543133

Epoch: 5| Step: 1
Training loss: 0.5826334302366387
Validation loss: 2.8669044119273757

Epoch: 5| Step: 2
Training loss: 0.6533280216782873
Validation loss: 2.810417707813957

Epoch: 5| Step: 3
Training loss: 0.4990902312903927
Validation loss: 2.8006144021249515

Epoch: 5| Step: 4
Training loss: 0.5398352792078044
Validation loss: 2.7103765898626575

Epoch: 5| Step: 5
Training loss: 0.5478306458640072
Validation loss: 2.7589252449564663

Epoch: 5| Step: 6
Training loss: 0.5605893534339028
Validation loss: 2.8380904069394135

Epoch: 5| Step: 7
Training loss: 0.5062978604145866
Validation loss: 2.9217432097770115

Epoch: 5| Step: 8
Training loss: 0.550777245906046
Validation loss: 2.953359845156717

Epoch: 5| Step: 9
Training loss: 1.2591432912000318
Validation loss: 2.8414959340717263

Epoch: 5| Step: 10
Training loss: 0.3703322175969388
Validation loss: 2.9029498333845654

Epoch: 5| Step: 11
Training loss: 0.389545168851758
Validation loss: 2.826491142118709

Epoch: 268| Step: 0
Training loss: 0.4546218352733399
Validation loss: 2.7266657972761914

Epoch: 5| Step: 1
Training loss: 0.5060880284164097
Validation loss: 2.8433209329612716

Epoch: 5| Step: 2
Training loss: 0.5255059608444431
Validation loss: 2.834127375655552

Epoch: 5| Step: 3
Training loss: 0.44708478178421884
Validation loss: 2.7156327891704497

Epoch: 5| Step: 4
Training loss: 0.3817380696801365
Validation loss: 2.778803113343112

Epoch: 5| Step: 5
Training loss: 0.561478561598445
Validation loss: 2.868319642165242

Epoch: 5| Step: 6
Training loss: 1.295569946694604
Validation loss: 2.8044849418239957

Epoch: 5| Step: 7
Training loss: 0.49381116958958454
Validation loss: 2.8523986356970106

Epoch: 5| Step: 8
Training loss: 0.625334769237994
Validation loss: 2.8496382400065223

Epoch: 5| Step: 9
Training loss: 0.5317415880112687
Validation loss: 2.899858200234835

Epoch: 5| Step: 10
Training loss: 0.4949433964097357
Validation loss: 2.8136331571363318

Epoch: 5| Step: 11
Training loss: 0.49627628122300477
Validation loss: 2.7860822382206636

Epoch: 269| Step: 0
Training loss: 0.5882413711304069
Validation loss: 2.783481595569594

Epoch: 5| Step: 1
Training loss: 0.7085772730079799
Validation loss: 2.7974150684987773

Epoch: 5| Step: 2
Training loss: 1.1513977305572975
Validation loss: 2.893185576011238

Epoch: 5| Step: 3
Training loss: 0.5475779783553761
Validation loss: 2.854858367989951

Epoch: 5| Step: 4
Training loss: 0.4572141884388566
Validation loss: 2.892868882530518

Epoch: 5| Step: 5
Training loss: 0.3784989202728392
Validation loss: 2.9608663183025334

Epoch: 5| Step: 6
Training loss: 0.8834338744243959
Validation loss: 2.9245300469709634

Epoch: 5| Step: 7
Training loss: 0.4828627575638982
Validation loss: 2.86734798650945

Epoch: 5| Step: 8
Training loss: 0.4446632940013373
Validation loss: 2.837752988015071

Epoch: 5| Step: 9
Training loss: 0.4758680630862927
Validation loss: 2.7930185202407825

Epoch: 5| Step: 10
Training loss: 0.3905740132434938
Validation loss: 2.7858706534926267

Epoch: 5| Step: 11
Training loss: 0.360320423300475
Validation loss: 2.92062100447263

Epoch: 270| Step: 0
Training loss: 0.8016523136141457
Validation loss: 2.8474705185953484

Epoch: 5| Step: 1
Training loss: 0.7308829046363117
Validation loss: 2.7620780959237687

Epoch: 5| Step: 2
Training loss: 0.5222365993973632
Validation loss: 2.9250146687512046

Epoch: 5| Step: 3
Training loss: 0.664052671471958
Validation loss: 2.9410551215363925

Epoch: 5| Step: 4
Training loss: 0.7085627203122763
Validation loss: 2.9728211212220326

Epoch: 5| Step: 5
Training loss: 1.1582669374020864
Validation loss: 2.885804475046454

Epoch: 5| Step: 6
Training loss: 0.4085237439432684
Validation loss: 2.892912095645145

Epoch: 5| Step: 7
Training loss: 0.43460009183540377
Validation loss: 2.9243954753817945

Epoch: 5| Step: 8
Training loss: 0.4386282405739
Validation loss: 2.8471761332764305

Epoch: 5| Step: 9
Training loss: 0.8301791140888024
Validation loss: 2.8093449521323133

Epoch: 5| Step: 10
Training loss: 0.6547483793736021
Validation loss: 2.8198859930496765

Epoch: 5| Step: 11
Training loss: 0.3635005699071916
Validation loss: 2.778904593853926

Epoch: 271| Step: 0
Training loss: 0.4714482057314956
Validation loss: 2.9147786052304783

Epoch: 5| Step: 1
Training loss: 0.5031213487765114
Validation loss: 2.9384544594008317

Epoch: 5| Step: 2
Training loss: 0.6912238532393234
Validation loss: 2.9386771224393944

Epoch: 5| Step: 3
Training loss: 0.5647353156596768
Validation loss: 2.902808599267855

Epoch: 5| Step: 4
Training loss: 0.5538478729089423
Validation loss: 2.8624604121084647

Epoch: 5| Step: 5
Training loss: 0.5977307441510408
Validation loss: 2.8272082017764886

Epoch: 5| Step: 6
Training loss: 0.5600327849157686
Validation loss: 2.840643551929913

Epoch: 5| Step: 7
Training loss: 0.438627051545697
Validation loss: 2.8375853032749103

Epoch: 5| Step: 8
Training loss: 0.5910868398215575
Validation loss: 2.8043840575350005

Epoch: 5| Step: 9
Training loss: 1.2828435060050594
Validation loss: 2.7432342154564626

Epoch: 5| Step: 10
Training loss: 0.44083546556246767
Validation loss: 2.954841710206375

Epoch: 5| Step: 11
Training loss: 0.15788245963793784
Validation loss: 2.8872503738337016

Epoch: 272| Step: 0
Training loss: 1.2469878143290267
Validation loss: 2.8909683676567797

Epoch: 5| Step: 1
Training loss: 0.5898835124577569
Validation loss: 2.9866669127735253

Epoch: 5| Step: 2
Training loss: 0.4974898271143596
Validation loss: 2.898459651207743

Epoch: 5| Step: 3
Training loss: 0.7195740826808615
Validation loss: 2.913496032282904

Epoch: 5| Step: 4
Training loss: 0.4702866322193373
Validation loss: 2.86625298940905

Epoch: 5| Step: 5
Training loss: 0.6690141405769392
Validation loss: 2.8946936969758696

Epoch: 5| Step: 6
Training loss: 0.38703774290833365
Validation loss: 2.8733669079421733

Epoch: 5| Step: 7
Training loss: 0.5349969557203151
Validation loss: 2.8749514105740506

Epoch: 5| Step: 8
Training loss: 0.5344112250112831
Validation loss: 2.9136729214375694

Epoch: 5| Step: 9
Training loss: 0.5065636758008204
Validation loss: 2.8696460871571334

Epoch: 5| Step: 10
Training loss: 0.5629974390957523
Validation loss: 2.833492398471889

Epoch: 5| Step: 11
Training loss: 0.549581939945185
Validation loss: 2.8559809937180836

Epoch: 273| Step: 0
Training loss: 0.6383533675168233
Validation loss: 2.8301014395754525

Epoch: 5| Step: 1
Training loss: 0.5040810451891824
Validation loss: 2.801321313663238

Epoch: 5| Step: 2
Training loss: 0.4765147669916696
Validation loss: 2.994003234683901

Epoch: 5| Step: 3
Training loss: 0.4425042766698435
Validation loss: 2.881308824210391

Epoch: 5| Step: 4
Training loss: 0.4607981131628434
Validation loss: 2.92670963770842

Epoch: 5| Step: 5
Training loss: 0.5861670743696616
Validation loss: 3.001785614495843

Epoch: 5| Step: 6
Training loss: 0.4283226357539217
Validation loss: 2.840777384045814

Epoch: 5| Step: 7
Training loss: 1.177316569398685
Validation loss: 2.902321043135347

Epoch: 5| Step: 8
Training loss: 0.28245016829512154
Validation loss: 2.8302898937646614

Epoch: 5| Step: 9
Training loss: 0.621508262074519
Validation loss: 2.721090142737513

Epoch: 5| Step: 10
Training loss: 0.5594915364522728
Validation loss: 2.8184736990437727

Epoch: 5| Step: 11
Training loss: 1.0372420116603327
Validation loss: 2.792199124378043

Epoch: 274| Step: 0
Training loss: 0.7024785354837535
Validation loss: 2.827686026350829

Epoch: 5| Step: 1
Training loss: 0.32571388115236305
Validation loss: 2.7527487033272426

Epoch: 5| Step: 2
Training loss: 0.6459975238994704
Validation loss: 2.923557082910549

Epoch: 5| Step: 3
Training loss: 0.3533000183181585
Validation loss: 2.858880759433059

Epoch: 5| Step: 4
Training loss: 0.5298936864550577
Validation loss: 2.818104535709093

Epoch: 5| Step: 5
Training loss: 0.5688357372426874
Validation loss: 2.838569411162596

Epoch: 5| Step: 6
Training loss: 1.1546184266198456
Validation loss: 2.8498215102888174

Epoch: 5| Step: 7
Training loss: 0.3258768220491323
Validation loss: 2.9162183155868098

Epoch: 5| Step: 8
Training loss: 0.5996970196515504
Validation loss: 2.8183652754819017

Epoch: 5| Step: 9
Training loss: 0.3984778140747411
Validation loss: 2.788046123623438

Epoch: 5| Step: 10
Training loss: 0.523809215594073
Validation loss: 2.8137487818047195

Epoch: 5| Step: 11
Training loss: 0.6639201741005218
Validation loss: 2.846262825945499

Epoch: 275| Step: 0
Training loss: 0.5603826195775119
Validation loss: 2.818132031374786

Epoch: 5| Step: 1
Training loss: 0.5283320737647236
Validation loss: 2.8646404931116547

Epoch: 5| Step: 2
Training loss: 0.6492587025602269
Validation loss: 2.890000301595362

Epoch: 5| Step: 3
Training loss: 0.3198417716997069
Validation loss: 2.8149239267433503

Epoch: 5| Step: 4
Training loss: 0.4092452695453154
Validation loss: 2.8362790437132888

Epoch: 5| Step: 5
Training loss: 0.6702258029526976
Validation loss: 2.863685659148955

Epoch: 5| Step: 6
Training loss: 0.3251814968164283
Validation loss: 2.886843236872498

Epoch: 5| Step: 7
Training loss: 0.4833634643233729
Validation loss: 2.901703494797035

Epoch: 5| Step: 8
Training loss: 1.1549426239591976
Validation loss: 2.763208188180447

Epoch: 5| Step: 9
Training loss: 0.5813975628821776
Validation loss: 2.8676128539682066

Epoch: 5| Step: 10
Training loss: 0.6458470871188913
Validation loss: 2.8333426585230987

Epoch: 5| Step: 11
Training loss: 0.4120818938000989
Validation loss: 2.817018933435815

Epoch: 276| Step: 0
Training loss: 0.5648137824628714
Validation loss: 2.879129122522867

Epoch: 5| Step: 1
Training loss: 0.49256122871721814
Validation loss: 2.8654748286561307

Epoch: 5| Step: 2
Training loss: 0.5142484264915327
Validation loss: 2.855494052480886

Epoch: 5| Step: 3
Training loss: 0.2922293423970556
Validation loss: 2.871954230598211

Epoch: 5| Step: 4
Training loss: 0.4703598036692343
Validation loss: 2.9463125634027967

Epoch: 5| Step: 5
Training loss: 0.44229000372745486
Validation loss: 2.852591829596538

Epoch: 5| Step: 6
Training loss: 0.7450718297189438
Validation loss: 2.794189613112299

Epoch: 5| Step: 7
Training loss: 0.4491716111370459
Validation loss: 2.85359701101043

Epoch: 5| Step: 8
Training loss: 0.6630761619150664
Validation loss: 2.8731980862082214

Epoch: 5| Step: 9
Training loss: 0.3576365592205789
Validation loss: 2.839862520837118

Epoch: 5| Step: 10
Training loss: 1.224759763399583
Validation loss: 2.8451719816012733

Epoch: 5| Step: 11
Training loss: 0.5023737825757169
Validation loss: 2.747895884393091

Epoch: 277| Step: 0
Training loss: 1.1061558828889153
Validation loss: 2.885359079541436

Epoch: 5| Step: 1
Training loss: 0.3775082784338673
Validation loss: 2.8765634798168787

Epoch: 5| Step: 2
Training loss: 0.46197428724026596
Validation loss: 2.9271968579705225

Epoch: 5| Step: 3
Training loss: 0.6208032852513603
Validation loss: 2.95817752324844

Epoch: 5| Step: 4
Training loss: 0.5353652100630976
Validation loss: 2.9517576055897496

Epoch: 5| Step: 5
Training loss: 0.37840406823007744
Validation loss: 2.9293282555622366

Epoch: 5| Step: 6
Training loss: 0.44143215879848974
Validation loss: 2.8848247517712244

Epoch: 5| Step: 7
Training loss: 0.3428895107137323
Validation loss: 2.8481258987069293

Epoch: 5| Step: 8
Training loss: 0.385539810595196
Validation loss: 2.860117897430222

Epoch: 5| Step: 9
Training loss: 0.5086864287377661
Validation loss: 2.9466847798943654

Epoch: 5| Step: 10
Training loss: 0.6086757266814241
Validation loss: 2.7924620517746614

Epoch: 5| Step: 11
Training loss: 0.34386379352503643
Validation loss: 2.86856792872251

Epoch: 278| Step: 0
Training loss: 0.5603036385988074
Validation loss: 2.8588663076035354

Epoch: 5| Step: 1
Training loss: 0.6943865192944573
Validation loss: 2.8436069138129625

Epoch: 5| Step: 2
Training loss: 0.5203472698611067
Validation loss: 2.86894464656616

Epoch: 5| Step: 3
Training loss: 0.4445208322011589
Validation loss: 2.9340712645027325

Epoch: 5| Step: 4
Training loss: 0.39143558323753436
Validation loss: 2.9288448800459386

Epoch: 5| Step: 5
Training loss: 0.4277004942692007
Validation loss: 2.9121261278945987

Epoch: 5| Step: 6
Training loss: 0.6175936075063807
Validation loss: 2.7993328831030997

Epoch: 5| Step: 7
Training loss: 0.4086622002123147
Validation loss: 2.85635769179849

Epoch: 5| Step: 8
Training loss: 0.4146242110388917
Validation loss: 2.9381571298484466

Epoch: 5| Step: 9
Training loss: 0.4890623634996315
Validation loss: 2.7891167743149943

Epoch: 5| Step: 10
Training loss: 1.1930713961645927
Validation loss: 2.8314324318087007

Epoch: 5| Step: 11
Training loss: 0.6916146691628196
Validation loss: 2.8009610510749656

Epoch: 279| Step: 0
Training loss: 0.3713363256176957
Validation loss: 2.864018281635883

Epoch: 5| Step: 1
Training loss: 0.5039497770687246
Validation loss: 2.84660192157662

Epoch: 5| Step: 2
Training loss: 0.3959350538893291
Validation loss: 2.9516350252077115

Epoch: 5| Step: 3
Training loss: 0.5697197381134947
Validation loss: 2.902485395203656

Epoch: 5| Step: 4
Training loss: 1.193820545848241
Validation loss: 2.9313978704205295

Epoch: 5| Step: 5
Training loss: 0.881857904475323
Validation loss: 2.9458293916567087

Epoch: 5| Step: 6
Training loss: 0.2875659322809489
Validation loss: 2.8503336135343806

Epoch: 5| Step: 7
Training loss: 0.3226664160542428
Validation loss: 2.737378666858263

Epoch: 5| Step: 8
Training loss: 0.604012442230129
Validation loss: 2.815112977039102

Epoch: 5| Step: 9
Training loss: 0.5292800675429787
Validation loss: 2.7996013431354907

Epoch: 5| Step: 10
Training loss: 0.46209756702289473
Validation loss: 2.7819740588765627

Epoch: 5| Step: 11
Training loss: 0.20325428259714284
Validation loss: 2.824378818532736

Epoch: 280| Step: 0
Training loss: 0.4277900067386962
Validation loss: 2.899620873645429

Epoch: 5| Step: 1
Training loss: 0.6038466598108182
Validation loss: 2.832677696374515

Epoch: 5| Step: 2
Training loss: 0.5514840045867726
Validation loss: 2.7562177944536423

Epoch: 5| Step: 3
Training loss: 0.5959780699548398
Validation loss: 2.7499696989991014

Epoch: 5| Step: 4
Training loss: 0.43310128847532553
Validation loss: 2.8625613873713913

Epoch: 5| Step: 5
Training loss: 0.38663874867928805
Validation loss: 2.8775983105538043

Epoch: 5| Step: 6
Training loss: 0.4016885329595746
Validation loss: 2.7571253005910488

Epoch: 5| Step: 7
Training loss: 1.1746525717512815
Validation loss: 2.7810266830142045

Epoch: 5| Step: 8
Training loss: 0.5648956412173711
Validation loss: 2.834599819611099

Epoch: 5| Step: 9
Training loss: 0.3882080454292853
Validation loss: 2.8820042911632604

Epoch: 5| Step: 10
Training loss: 0.5401800982060749
Validation loss: 2.909636636723112

Epoch: 5| Step: 11
Training loss: 0.4286894912395401
Validation loss: 2.7884600297626965

Epoch: 281| Step: 0
Training loss: 0.43120857122701417
Validation loss: 2.8221092876001377

Epoch: 5| Step: 1
Training loss: 0.5811478227616746
Validation loss: 2.9112506796952213

Epoch: 5| Step: 2
Training loss: 0.6234224198126092
Validation loss: 2.9043587304142497

Epoch: 5| Step: 3
Training loss: 0.3838241794040972
Validation loss: 2.8140244343873237

Epoch: 5| Step: 4
Training loss: 0.4701056586366636
Validation loss: 2.819678924912785

Epoch: 5| Step: 5
Training loss: 0.4699958774710505
Validation loss: 2.8184510531354974

Epoch: 5| Step: 6
Training loss: 0.7367087273507577
Validation loss: 2.777319602664609

Epoch: 5| Step: 7
Training loss: 0.4046048267710646
Validation loss: 2.7823996257414576

Epoch: 5| Step: 8
Training loss: 1.2293435901533232
Validation loss: 2.736177595065567

Epoch: 5| Step: 9
Training loss: 0.622156589339925
Validation loss: 2.8288203836996186

Epoch: 5| Step: 10
Training loss: 0.3850252659978741
Validation loss: 2.7952065312879983

Epoch: 5| Step: 11
Training loss: 0.5776691185836279
Validation loss: 2.835529161380314

Epoch: 282| Step: 0
Training loss: 0.7625678391843019
Validation loss: 2.9459078766286466

Epoch: 5| Step: 1
Training loss: 0.5645934725715495
Validation loss: 2.9375942025737585

Epoch: 5| Step: 2
Training loss: 0.45256665787342926
Validation loss: 2.9235395901998666

Epoch: 5| Step: 3
Training loss: 1.1734475329664817
Validation loss: 2.8991622738385963

Epoch: 5| Step: 4
Training loss: 0.47276843922732437
Validation loss: 2.775265480779754

Epoch: 5| Step: 5
Training loss: 0.39447417648996325
Validation loss: 2.8392425610875147

Epoch: 5| Step: 6
Training loss: 0.46635077320687945
Validation loss: 2.779344441696457

Epoch: 5| Step: 7
Training loss: 0.5440188620133806
Validation loss: 2.841977803871113

Epoch: 5| Step: 8
Training loss: 0.6384329159236432
Validation loss: 2.7864404671830063

Epoch: 5| Step: 9
Training loss: 0.31787671906024795
Validation loss: 2.900867841616328

Epoch: 5| Step: 10
Training loss: 0.5839217289523304
Validation loss: 2.911274108563047

Epoch: 5| Step: 11
Training loss: 0.5416896491187995
Validation loss: 2.903439550670381

Epoch: 283| Step: 0
Training loss: 0.3900353750055526
Validation loss: 2.8269479139124565

Epoch: 5| Step: 1
Training loss: 0.48474161056313797
Validation loss: 2.750308666101601

Epoch: 5| Step: 2
Training loss: 0.5261046935241371
Validation loss: 2.8093322469183106

Epoch: 5| Step: 3
Training loss: 0.4139741407440665
Validation loss: 2.8115494039983187

Epoch: 5| Step: 4
Training loss: 0.5093915012237763
Validation loss: 2.8221091080750216

Epoch: 5| Step: 5
Training loss: 1.1900367745559515
Validation loss: 2.8768876761704782

Epoch: 5| Step: 6
Training loss: 0.5381525624977723
Validation loss: 2.879424387985274

Epoch: 5| Step: 7
Training loss: 0.509951152145142
Validation loss: 2.8897290258846877

Epoch: 5| Step: 8
Training loss: 0.43042362620490127
Validation loss: 2.832239049544575

Epoch: 5| Step: 9
Training loss: 0.4625676956122064
Validation loss: 2.919841133285664

Epoch: 5| Step: 10
Training loss: 0.6133384191994993
Validation loss: 2.8204308834573277

Epoch: 5| Step: 11
Training loss: 0.301556825831501
Validation loss: 2.904286935050012

Epoch: 284| Step: 0
Training loss: 0.6904553701326314
Validation loss: 2.891284173262403

Epoch: 5| Step: 1
Training loss: 0.5294092488384929
Validation loss: 2.8234573664034026

Epoch: 5| Step: 2
Training loss: 0.34475428007828635
Validation loss: 2.7794240179443803

Epoch: 5| Step: 3
Training loss: 0.3291166851066942
Validation loss: 2.872941617509261

Epoch: 5| Step: 4
Training loss: 0.30854075012912313
Validation loss: 2.929445838286039

Epoch: 5| Step: 5
Training loss: 0.505539133634263
Validation loss: 2.8229207124481674

Epoch: 5| Step: 6
Training loss: 0.4587714492710335
Validation loss: 2.862247785342977

Epoch: 5| Step: 7
Training loss: 0.4157410732040375
Validation loss: 2.8366885140993814

Epoch: 5| Step: 8
Training loss: 0.381711778674681
Validation loss: 2.832680701843718

Epoch: 5| Step: 9
Training loss: 0.37176926015127515
Validation loss: 2.7572539378948675

Epoch: 5| Step: 10
Training loss: 0.5164629167869134
Validation loss: 2.8744597722167793

Epoch: 5| Step: 11
Training loss: 2.4598840790084853
Validation loss: 2.853019488452946

Epoch: 285| Step: 0
Training loss: 0.6285226967308837
Validation loss: 2.8661616930394858

Epoch: 5| Step: 1
Training loss: 0.5112000960078321
Validation loss: 2.9631625180436316

Epoch: 5| Step: 2
Training loss: 0.37669648442077275
Validation loss: 2.87266433385466

Epoch: 5| Step: 3
Training loss: 0.46316533045640623
Validation loss: 2.8831926059052946

Epoch: 5| Step: 4
Training loss: 0.3716335787214408
Validation loss: 2.8238921550415226

Epoch: 5| Step: 5
Training loss: 1.1750659477719365
Validation loss: 2.885696508881945

Epoch: 5| Step: 6
Training loss: 0.49432101368466647
Validation loss: 2.8813923108971258

Epoch: 5| Step: 7
Training loss: 0.5886529181553642
Validation loss: 2.9176606573540314

Epoch: 5| Step: 8
Training loss: 0.44650079892205574
Validation loss: 2.912491041450748

Epoch: 5| Step: 9
Training loss: 0.43579966646044266
Validation loss: 2.9162375213894562

Epoch: 5| Step: 10
Training loss: 0.681609450887138
Validation loss: 2.8755092895382965

Epoch: 5| Step: 11
Training loss: 0.32939447334531063
Validation loss: 2.902692606972869

Epoch: 286| Step: 0
Training loss: 0.4716025658657396
Validation loss: 2.9363039097682524

Epoch: 5| Step: 1
Training loss: 0.7115676937324178
Validation loss: 2.9166394175664405

Epoch: 5| Step: 2
Training loss: 0.5410035610575358
Validation loss: 2.938826788901396

Epoch: 5| Step: 3
Training loss: 0.4273041255231301
Validation loss: 2.8175490234993217

Epoch: 5| Step: 4
Training loss: 0.4244051929289654
Validation loss: 2.788176255953951

Epoch: 5| Step: 5
Training loss: 0.4184810849624345
Validation loss: 2.8754911694237135

Epoch: 5| Step: 6
Training loss: 0.5063515113970738
Validation loss: 2.936208593288501

Epoch: 5| Step: 7
Training loss: 0.5226888284380118
Validation loss: 2.8674321568297656

Epoch: 5| Step: 8
Training loss: 0.47668367940157624
Validation loss: 2.89032839378859

Epoch: 5| Step: 9
Training loss: 1.1268118996284007
Validation loss: 2.8727749527928164

Epoch: 5| Step: 10
Training loss: 0.6052135791211989
Validation loss: 2.88737981967267

Epoch: 5| Step: 11
Training loss: 0.44024759321838375
Validation loss: 2.8634643756338343

Epoch: 287| Step: 0
Training loss: 0.3851384327077168
Validation loss: 2.825679645675099

Epoch: 5| Step: 1
Training loss: 0.4999969005488651
Validation loss: 2.8890867487740977

Epoch: 5| Step: 2
Training loss: 0.5157907681885536
Validation loss: 2.8424508547217995

Epoch: 5| Step: 3
Training loss: 1.0631735293767923
Validation loss: 2.8993332019536013

Epoch: 5| Step: 4
Training loss: 0.47199519881235225
Validation loss: 2.9421654574634974

Epoch: 5| Step: 5
Training loss: 0.42066848385577554
Validation loss: 2.938935967087129

Epoch: 5| Step: 6
Training loss: 0.6551861086554702
Validation loss: 2.856862383441638

Epoch: 5| Step: 7
Training loss: 0.560828958704959
Validation loss: 2.9066357783840355

Epoch: 5| Step: 8
Training loss: 0.4157243882282749
Validation loss: 2.963683734476383

Epoch: 5| Step: 9
Training loss: 0.6431112194160414
Validation loss: 2.850994422798986

Epoch: 5| Step: 10
Training loss: 0.4745002746772172
Validation loss: 2.745506735762114

Epoch: 5| Step: 11
Training loss: 0.30919105330569696
Validation loss: 2.7947343114246546

Epoch: 288| Step: 0
Training loss: 0.4435217303819586
Validation loss: 2.8801509593930965

Epoch: 5| Step: 1
Training loss: 0.6154776924608983
Validation loss: 2.805934720782712

Epoch: 5| Step: 2
Training loss: 0.41599877193503493
Validation loss: 2.8744151342888116

Epoch: 5| Step: 3
Training loss: 0.4680484926682586
Validation loss: 2.8234779332496975

Epoch: 5| Step: 4
Training loss: 0.6235144125550582
Validation loss: 2.7878935044348463

Epoch: 5| Step: 5
Training loss: 1.118588456153199
Validation loss: 2.8385578761673282

Epoch: 5| Step: 6
Training loss: 0.6254798954111943
Validation loss: 2.857351625995257

Epoch: 5| Step: 7
Training loss: 0.6350851809822612
Validation loss: 2.9159435613354776

Epoch: 5| Step: 8
Training loss: 0.4508228851342793
Validation loss: 2.8108635309370773

Epoch: 5| Step: 9
Training loss: 0.5081105457985585
Validation loss: 2.8312497062486464

Epoch: 5| Step: 10
Training loss: 0.29440441588006716
Validation loss: 2.7725046227625567

Epoch: 5| Step: 11
Training loss: 0.5969090996233813
Validation loss: 2.779623806334303

Epoch: 289| Step: 0
Training loss: 0.5621534710647406
Validation loss: 2.824011709346013

Epoch: 5| Step: 1
Training loss: 0.4205048351474786
Validation loss: 2.744093298815052

Epoch: 5| Step: 2
Training loss: 0.43730031292845484
Validation loss: 2.8137386526113124

Epoch: 5| Step: 3
Training loss: 0.6747984602954125
Validation loss: 2.9033383581561094

Epoch: 5| Step: 4
Training loss: 0.42419077041554576
Validation loss: 2.84135705574725

Epoch: 5| Step: 5
Training loss: 0.4429636462151379
Validation loss: 2.872481455813609

Epoch: 5| Step: 6
Training loss: 0.42155914491940083
Validation loss: 2.931446547652745

Epoch: 5| Step: 7
Training loss: 1.0932294424249605
Validation loss: 2.883642516528655

Epoch: 5| Step: 8
Training loss: 0.7282833516569981
Validation loss: 2.854802082965793

Epoch: 5| Step: 9
Training loss: 0.4379714401222381
Validation loss: 2.722861006347122

Epoch: 5| Step: 10
Training loss: 0.5537099686871485
Validation loss: 2.7673221632193576

Epoch: 5| Step: 11
Training loss: 0.42069458948400634
Validation loss: 2.885069951366915

Epoch: 290| Step: 0
Training loss: 0.4745353201401759
Validation loss: 2.864444858787585

Epoch: 5| Step: 1
Training loss: 0.45787526309114895
Validation loss: 2.7930094184671157

Epoch: 5| Step: 2
Training loss: 0.5730689857757426
Validation loss: 2.8326884697569334

Epoch: 5| Step: 3
Training loss: 1.0893606667114613
Validation loss: 2.919524357336474

Epoch: 5| Step: 4
Training loss: 0.6110645493797544
Validation loss: 2.9071785561183

Epoch: 5| Step: 5
Training loss: 0.4605547398744167
Validation loss: 2.9045090502718725

Epoch: 5| Step: 6
Training loss: 0.38543109179471263
Validation loss: 2.8913951122856547

Epoch: 5| Step: 7
Training loss: 0.38259651942217854
Validation loss: 2.7741436842790224

Epoch: 5| Step: 8
Training loss: 0.7446776127128859
Validation loss: 2.769451332104977

Epoch: 5| Step: 9
Training loss: 0.5970164845329714
Validation loss: 2.790853176634911

Epoch: 5| Step: 10
Training loss: 0.5078293430762942
Validation loss: 2.6992152959761944

Epoch: 5| Step: 11
Training loss: 0.26512457888298635
Validation loss: 2.777222116975078

Epoch: 291| Step: 0
Training loss: 0.5040069597724965
Validation loss: 2.8965771780925844

Epoch: 5| Step: 1
Training loss: 0.5180623218831987
Validation loss: 2.922456911181098

Epoch: 5| Step: 2
Training loss: 0.29662710430766864
Validation loss: 2.8241075711067425

Epoch: 5| Step: 3
Training loss: 0.43286563120261395
Validation loss: 2.8638703389486375

Epoch: 5| Step: 4
Training loss: 1.185479503143883
Validation loss: 2.793415743398176

Epoch: 5| Step: 5
Training loss: 0.586523144823853
Validation loss: 2.770526558282949

Epoch: 5| Step: 6
Training loss: 0.45738555347019777
Validation loss: 2.8374097801351312

Epoch: 5| Step: 7
Training loss: 0.40603132965150524
Validation loss: 2.7622447486403092

Epoch: 5| Step: 8
Training loss: 0.5401395735236748
Validation loss: 2.792980587096128

Epoch: 5| Step: 9
Training loss: 0.43916075411453254
Validation loss: 2.797005593502715

Epoch: 5| Step: 10
Training loss: 0.532346743392478
Validation loss: 2.789054414682218

Epoch: 5| Step: 11
Training loss: 0.5068220603380805
Validation loss: 2.8341513299083068

Epoch: 292| Step: 0
Training loss: 0.38693487505175683
Validation loss: 2.8367301316638365

Epoch: 5| Step: 1
Training loss: 0.4668856420670117
Validation loss: 2.864547907292338

Epoch: 5| Step: 2
Training loss: 0.4536512541711659
Validation loss: 2.8135742855523294

Epoch: 5| Step: 3
Training loss: 1.1205272240010404
Validation loss: 2.908032841219982

Epoch: 5| Step: 4
Training loss: 0.5751040115821471
Validation loss: 2.8284041001803577

Epoch: 5| Step: 5
Training loss: 0.4244172883909595
Validation loss: 2.8003517009470418

Epoch: 5| Step: 6
Training loss: 0.5971434643537651
Validation loss: 2.831653676788131

Epoch: 5| Step: 7
Training loss: 0.47801928566988117
Validation loss: 2.809487453101151

Epoch: 5| Step: 8
Training loss: 0.4163282410801693
Validation loss: 2.8687479206152466

Epoch: 5| Step: 9
Training loss: 0.6463298324770825
Validation loss: 2.861136823037629

Epoch: 5| Step: 10
Training loss: 0.5893801705304523
Validation loss: 2.916991571086405

Epoch: 5| Step: 11
Training loss: 0.5102494965139145
Validation loss: 2.8684525449176577

Epoch: 293| Step: 0
Training loss: 0.5166308389311123
Validation loss: 2.9062106324677686

Epoch: 5| Step: 1
Training loss: 0.43839235920360303
Validation loss: 2.7833248749811936

Epoch: 5| Step: 2
Training loss: 0.42978372363419703
Validation loss: 2.8899591246027505

Epoch: 5| Step: 3
Training loss: 0.6262111135124058
Validation loss: 2.7957293332385067

Epoch: 5| Step: 4
Training loss: 0.444407983325743
Validation loss: 2.834459730716294

Epoch: 5| Step: 5
Training loss: 0.3564196015582676
Validation loss: 2.8558104206728516

Epoch: 5| Step: 6
Training loss: 0.4507102255841311
Validation loss: 2.854360742073263

Epoch: 5| Step: 7
Training loss: 0.50438419120951
Validation loss: 2.8536611176566686

Epoch: 5| Step: 8
Training loss: 1.1019139912717604
Validation loss: 2.8455096170073766

Epoch: 5| Step: 9
Training loss: 0.4425362158895994
Validation loss: 2.8590610936359764

Epoch: 5| Step: 10
Training loss: 0.6107802693614568
Validation loss: 2.8323745291484603

Epoch: 5| Step: 11
Training loss: 0.43475372215901936
Validation loss: 2.786860475607112

Epoch: 294| Step: 0
Training loss: 0.42884572545323285
Validation loss: 2.861887042038378

Epoch: 5| Step: 1
Training loss: 0.36432422104175505
Validation loss: 2.853362496871695

Epoch: 5| Step: 2
Training loss: 0.3942331755512795
Validation loss: 2.9135675461653645

Epoch: 5| Step: 3
Training loss: 0.4952809741941097
Validation loss: 2.8199339882979353

Epoch: 5| Step: 4
Training loss: 0.38403913974720444
Validation loss: 2.869081604352476

Epoch: 5| Step: 5
Training loss: 0.618254282847439
Validation loss: 2.886857421324857

Epoch: 5| Step: 6
Training loss: 0.4571357998718322
Validation loss: 2.8791489656256632

Epoch: 5| Step: 7
Training loss: 0.4685398584446575
Validation loss: 2.8365371497489815

Epoch: 5| Step: 8
Training loss: 0.37767603836962227
Validation loss: 2.884330487691355

Epoch: 5| Step: 9
Training loss: 0.48285164782379314
Validation loss: 2.8577482115819732

Epoch: 5| Step: 10
Training loss: 1.093749509538813
Validation loss: 2.900308495246033

Epoch: 5| Step: 11
Training loss: 0.43708606279404
Validation loss: 2.90987591513326

Epoch: 295| Step: 0
Training loss: 0.38496807987858667
Validation loss: 2.9173733479560666

Epoch: 5| Step: 1
Training loss: 1.0984729158815678
Validation loss: 2.8372138612913775

Epoch: 5| Step: 2
Training loss: 0.4876999713887528
Validation loss: 2.871228041503313

Epoch: 5| Step: 3
Training loss: 0.5629213132838268
Validation loss: 2.790684200939024

Epoch: 5| Step: 4
Training loss: 0.38184655216224406
Validation loss: 2.897135004050693

Epoch: 5| Step: 5
Training loss: 0.4061535023743599
Validation loss: 2.859541469515623

Epoch: 5| Step: 6
Training loss: 0.45981153260585933
Validation loss: 2.87521576417305

Epoch: 5| Step: 7
Training loss: 0.5778142506318628
Validation loss: 2.8425183790591846

Epoch: 5| Step: 8
Training loss: 0.4218137131432042
Validation loss: 2.8983652563422813

Epoch: 5| Step: 9
Training loss: 0.3875663985001093
Validation loss: 2.846091909562426

Epoch: 5| Step: 10
Training loss: 0.4561145914666845
Validation loss: 2.8317553260822512

Epoch: 5| Step: 11
Training loss: 0.2964056973610544
Validation loss: 2.914961941123267

Epoch: 296| Step: 0
Training loss: 0.4307098191362273
Validation loss: 2.832857436763347

Epoch: 5| Step: 1
Training loss: 0.3782176810562068
Validation loss: 2.8646411936147254

Epoch: 5| Step: 2
Training loss: 0.40614286257112375
Validation loss: 2.782401364495581

Epoch: 5| Step: 3
Training loss: 0.5150593631752091
Validation loss: 2.8676572375047376

Epoch: 5| Step: 4
Training loss: 0.5197072125502333
Validation loss: 2.817405036825391

Epoch: 5| Step: 5
Training loss: 1.0260728873264835
Validation loss: 2.933047372839475

Epoch: 5| Step: 6
Training loss: 0.591673532858037
Validation loss: 2.9078809680561264

Epoch: 5| Step: 7
Training loss: 0.510853917462742
Validation loss: 2.849408852745044

Epoch: 5| Step: 8
Training loss: 0.4495358550333399
Validation loss: 2.8800460960586762

Epoch: 5| Step: 9
Training loss: 0.64797582622019
Validation loss: 2.845791229092035

Epoch: 5| Step: 10
Training loss: 0.4453330788123856
Validation loss: 2.920260239880717

Epoch: 5| Step: 11
Training loss: 0.3574846973345207
Validation loss: 2.879484897467938

Epoch: 297| Step: 0
Training loss: 0.3292969483073414
Validation loss: 2.8812912818726133

Epoch: 5| Step: 1
Training loss: 0.4439579624130917
Validation loss: 2.898291399924592

Epoch: 5| Step: 2
Training loss: 0.5154661743155216
Validation loss: 2.8713991102251746

Epoch: 5| Step: 3
Training loss: 0.46214735337795165
Validation loss: 2.8562120686912387

Epoch: 5| Step: 4
Training loss: 0.286993509385354
Validation loss: 2.7757939674894216

Epoch: 5| Step: 5
Training loss: 0.5945805713381793
Validation loss: 2.8509319217862448

Epoch: 5| Step: 6
Training loss: 0.42046455979430003
Validation loss: 2.8030351749857396

Epoch: 5| Step: 7
Training loss: 0.4176757712606126
Validation loss: 2.938891105109182

Epoch: 5| Step: 8
Training loss: 0.41167774466745594
Validation loss: 2.8202591113446704

Epoch: 5| Step: 9
Training loss: 0.4162816732688111
Validation loss: 2.8510000083443434

Epoch: 5| Step: 10
Training loss: 0.3776649316587658
Validation loss: 2.8847479556056297

Epoch: 5| Step: 11
Training loss: 2.4794685329587502
Validation loss: 2.855020104269002

Epoch: 298| Step: 0
Training loss: 0.6711071861263189
Validation loss: 2.8680212902970736

Epoch: 5| Step: 1
Training loss: 0.6274114341850364
Validation loss: 2.895209294370439

Epoch: 5| Step: 2
Training loss: 0.554157245407712
Validation loss: 2.858487441372915

Epoch: 5| Step: 3
Training loss: 0.47126916431547256
Validation loss: 2.9401566348984756

Epoch: 5| Step: 4
Training loss: 1.042636832810035
Validation loss: 2.8391991521699076

Epoch: 5| Step: 5
Training loss: 0.38365776786432476
Validation loss: 2.839981729897533

Epoch: 5| Step: 6
Training loss: 0.44767842129698243
Validation loss: 2.748504882472287

Epoch: 5| Step: 7
Training loss: 0.3592701012476829
Validation loss: 2.92296201372124

Epoch: 5| Step: 8
Training loss: 0.3441993204348393
Validation loss: 2.901234564996937

Epoch: 5| Step: 9
Training loss: 0.47641221788070875
Validation loss: 2.901936789621688

Epoch: 5| Step: 10
Training loss: 0.39976396600208686
Validation loss: 2.8645511879706795

Epoch: 5| Step: 11
Training loss: 0.41866796600971345
Validation loss: 2.893872085176559

Epoch: 299| Step: 0
Training loss: 1.0567054940158938
Validation loss: 2.91450771854487

Epoch: 5| Step: 1
Training loss: 0.5837841137101663
Validation loss: 2.8546643008949557

Epoch: 5| Step: 2
Training loss: 0.40496148662174825
Validation loss: 2.873060031482993

Epoch: 5| Step: 3
Training loss: 0.5669595318048917
Validation loss: 2.7232811355277082

Epoch: 5| Step: 4
Training loss: 0.6631717991471722
Validation loss: 2.9235753638366733

Epoch: 5| Step: 5
Training loss: 0.5756453872698633
Validation loss: 2.91837628304818

Epoch: 5| Step: 6
Training loss: 0.327416665871574
Validation loss: 2.7968822049380226

Epoch: 5| Step: 7
Training loss: 0.3826195950941093
Validation loss: 2.8822827356381886

Epoch: 5| Step: 8
Training loss: 0.40310528359509856
Validation loss: 2.9468980917728733

Epoch: 5| Step: 9
Training loss: 0.5110675657883625
Validation loss: 2.9419578349160376

Epoch: 5| Step: 10
Training loss: 0.3897271327809565
Validation loss: 2.8704842160463233

Epoch: 5| Step: 11
Training loss: 0.25434415175634334
Validation loss: 2.893186067019233

Epoch: 300| Step: 0
Training loss: 0.5711523169507173
Validation loss: 2.9162673722289436

Epoch: 5| Step: 1
Training loss: 0.40416339384634997
Validation loss: 2.908968214885981

Epoch: 5| Step: 2
Training loss: 0.5020436305523911
Validation loss: 2.7862242888560282

Epoch: 5| Step: 3
Training loss: 0.43023241343621677
Validation loss: 2.8540478922965304

Epoch: 5| Step: 4
Training loss: 0.4408390654706226
Validation loss: 2.856665802621284

Epoch: 5| Step: 5
Training loss: 1.061521023043051
Validation loss: 2.876863811873657

Epoch: 5| Step: 6
Training loss: 0.3997573310151205
Validation loss: 2.916085084197347

Epoch: 5| Step: 7
Training loss: 0.5068058306327768
Validation loss: 2.93176893427445

Epoch: 5| Step: 8
Training loss: 0.5092370811924934
Validation loss: 2.926523067889643

Epoch: 5| Step: 9
Training loss: 0.41278093770356344
Validation loss: 2.833427134298171

Epoch: 5| Step: 10
Training loss: 0.6792999127118815
Validation loss: 2.8922096445316785

Epoch: 5| Step: 11
Training loss: 0.2293166280423245
Validation loss: 2.8360357976854735

Epoch: 301| Step: 0
Training loss: 0.5516190886173193
Validation loss: 2.9639836078468087

Epoch: 5| Step: 1
Training loss: 0.37076751021219756
Validation loss: 2.8719372295324637

Epoch: 5| Step: 2
Training loss: 0.5968330548312508
Validation loss: 2.976022152318766

Epoch: 5| Step: 3
Training loss: 0.49009292203170074
Validation loss: 2.8929569975905873

Epoch: 5| Step: 4
Training loss: 1.0105226729849148
Validation loss: 2.9215152607421873

Epoch: 5| Step: 5
Training loss: 0.3909670286057606
Validation loss: 2.88980411867782

Epoch: 5| Step: 6
Training loss: 0.43218061062389374
Validation loss: 2.884756585418857

Epoch: 5| Step: 7
Training loss: 0.6072818557923899
Validation loss: 2.816758873143182

Epoch: 5| Step: 8
Training loss: 0.4527429746085897
Validation loss: 2.806327301495651

Epoch: 5| Step: 9
Training loss: 0.46800138776830175
Validation loss: 2.88262390236566

Epoch: 5| Step: 10
Training loss: 0.5576185236445518
Validation loss: 2.849669112689901

Epoch: 5| Step: 11
Training loss: 0.3468825270721037
Validation loss: 2.8367464192199385

Epoch: 302| Step: 0
Training loss: 1.050641188805989
Validation loss: 2.8605233893289226

Epoch: 5| Step: 1
Training loss: 0.5490001802461533
Validation loss: 2.897309785660381

Epoch: 5| Step: 2
Training loss: 0.557900699085947
Validation loss: 2.885881941886538

Epoch: 5| Step: 3
Training loss: 0.3997245272142197
Validation loss: 2.9247525812856043

Epoch: 5| Step: 4
Training loss: 0.38736866755816635
Validation loss: 2.9030357774862714

Epoch: 5| Step: 5
Training loss: 0.45375101648957705
Validation loss: 2.8548579921801776

Epoch: 5| Step: 6
Training loss: 0.47775790888788916
Validation loss: 2.863433854640833

Epoch: 5| Step: 7
Training loss: 0.402153636867266
Validation loss: 2.905417134981397

Epoch: 5| Step: 8
Training loss: 0.45363262944179616
Validation loss: 2.854893888749668

Epoch: 5| Step: 9
Training loss: 0.4682149694692776
Validation loss: 2.8626117244445

Epoch: 5| Step: 10
Training loss: 0.45076690598116453
Validation loss: 2.9548491737840816

Epoch: 5| Step: 11
Training loss: 0.5686439247562849
Validation loss: 2.786960653976542

Epoch: 303| Step: 0
Training loss: 0.5822993947325517
Validation loss: 2.7957130519009703

Epoch: 5| Step: 1
Training loss: 0.8218033095738084
Validation loss: 2.781794973265219

Epoch: 5| Step: 2
Training loss: 0.46054250959377147
Validation loss: 2.852753708305664

Epoch: 5| Step: 3
Training loss: 1.0308642388359524
Validation loss: 2.8729928377015517

Epoch: 5| Step: 4
Training loss: 0.5017515735230912
Validation loss: 2.9358561664418503

Epoch: 5| Step: 5
Training loss: 0.7905734863386424
Validation loss: 2.909554056079211

Epoch: 5| Step: 6
Training loss: 0.6357571179677394
Validation loss: 2.90248229088475

Epoch: 5| Step: 7
Training loss: 0.4728905751121012
Validation loss: 2.8738884055375684

Epoch: 5| Step: 8
Training loss: 0.4075048214094768
Validation loss: 2.8397696134255597

Epoch: 5| Step: 9
Training loss: 0.3824638413810029
Validation loss: 2.84072324347211

Epoch: 5| Step: 10
Training loss: 0.5922739353359238
Validation loss: 2.8169818841926997

Epoch: 5| Step: 11
Training loss: 0.46123679191266004
Validation loss: 2.8454297557776846

Epoch: 304| Step: 0
Training loss: 0.6283295872329562
Validation loss: 2.8053710409167456

Epoch: 5| Step: 1
Training loss: 0.4781811849456086
Validation loss: 2.9477491847921904

Epoch: 5| Step: 2
Training loss: 0.767803168855325
Validation loss: 2.988110403192684

Epoch: 5| Step: 3
Training loss: 0.5035027359525411
Validation loss: 2.9717480696224245

Epoch: 5| Step: 4
Training loss: 0.5716328686777997
Validation loss: 2.827535165570315

Epoch: 5| Step: 5
Training loss: 0.6016893872288609
Validation loss: 2.9081362718114616

Epoch: 5| Step: 6
Training loss: 0.4555173072646484
Validation loss: 2.8134168790458225

Epoch: 5| Step: 7
Training loss: 1.0997557737420465
Validation loss: 2.749352198219543

Epoch: 5| Step: 8
Training loss: 0.39523294575650153
Validation loss: 2.767546603988657

Epoch: 5| Step: 9
Training loss: 0.43298394907853693
Validation loss: 2.766133838115913

Epoch: 5| Step: 10
Training loss: 0.36782797289043423
Validation loss: 2.894493645043227

Epoch: 5| Step: 11
Training loss: 0.5227781099545195
Validation loss: 2.8430162957487357

Epoch: 305| Step: 0
Training loss: 0.7109594236913015
Validation loss: 2.8261103013718647

Epoch: 5| Step: 1
Training loss: 0.4734027579121661
Validation loss: 2.9419840413639045

Epoch: 5| Step: 2
Training loss: 0.39872592883266456
Validation loss: 2.904561458080809

Epoch: 5| Step: 3
Training loss: 0.34628184957033237
Validation loss: 2.8026975480871226

Epoch: 5| Step: 4
Training loss: 0.44846190675250247
Validation loss: 2.845742659336714

Epoch: 5| Step: 5
Training loss: 0.4992100465639696
Validation loss: 2.784533594697482

Epoch: 5| Step: 6
Training loss: 0.31804292549411595
Validation loss: 2.896502741049983

Epoch: 5| Step: 7
Training loss: 1.112759705565684
Validation loss: 2.8309062714024043

Epoch: 5| Step: 8
Training loss: 0.36293482926983844
Validation loss: 2.861631147810921

Epoch: 5| Step: 9
Training loss: 0.5181605966209798
Validation loss: 2.871791230682909

Epoch: 5| Step: 10
Training loss: 0.32366718346843915
Validation loss: 2.8732772966413322

Epoch: 5| Step: 11
Training loss: 1.085060973409859
Validation loss: 2.8825245259397616

Epoch: 306| Step: 0
Training loss: 0.23772638630301823
Validation loss: 2.783228052931129

Epoch: 5| Step: 1
Training loss: 0.4224457764958365
Validation loss: 2.744068768376139

Epoch: 5| Step: 2
Training loss: 0.5718964306927588
Validation loss: 2.7526664522330613

Epoch: 5| Step: 3
Training loss: 0.46616806389280235
Validation loss: 2.8597331873664116

Epoch: 5| Step: 4
Training loss: 0.4716434504329716
Validation loss: 2.827052940640071

Epoch: 5| Step: 5
Training loss: 0.44578303189996193
Validation loss: 2.875617914553832

Epoch: 5| Step: 6
Training loss: 0.4570712536641658
Validation loss: 2.9391159726054013

Epoch: 5| Step: 7
Training loss: 1.0296125416540907
Validation loss: 2.852168523065575

Epoch: 5| Step: 8
Training loss: 0.5429159179891175
Validation loss: 2.8407855389633663

Epoch: 5| Step: 9
Training loss: 0.4650554335274809
Validation loss: 2.8073833618098414

Epoch: 5| Step: 10
Training loss: 0.36203395877066785
Validation loss: 2.880527248742138

Epoch: 5| Step: 11
Training loss: 0.7585290883219347
Validation loss: 2.7745137629217744

Epoch: 307| Step: 0
Training loss: 0.3772844232397161
Validation loss: 2.8481222607776138

Epoch: 5| Step: 1
Training loss: 0.4500251001404436
Validation loss: 2.7618711664208186

Epoch: 5| Step: 2
Training loss: 0.5110154305384653
Validation loss: 2.8453321003400256

Epoch: 5| Step: 3
Training loss: 0.3486024004496832
Validation loss: 2.8436313366847368

Epoch: 5| Step: 4
Training loss: 0.5276047237452296
Validation loss: 2.928493853379509

Epoch: 5| Step: 5
Training loss: 0.5775567948293133
Validation loss: 2.8910730375566334

Epoch: 5| Step: 6
Training loss: 0.4673939959809682
Validation loss: 2.784969082785713

Epoch: 5| Step: 7
Training loss: 1.1370738939615928
Validation loss: 2.8214551138017416

Epoch: 5| Step: 8
Training loss: 0.6412377334745107
Validation loss: 2.7944583397364564

Epoch: 5| Step: 9
Training loss: 0.39216664323402745
Validation loss: 2.8374558789860354

Epoch: 5| Step: 10
Training loss: 0.7201042685243555
Validation loss: 2.9138332546084076

Epoch: 5| Step: 11
Training loss: 0.6462087360541278
Validation loss: 2.8477333749130613

Epoch: 308| Step: 0
Training loss: 0.3582307802796061
Validation loss: 2.9022125721068868

Epoch: 5| Step: 1
Training loss: 0.5405815393696356
Validation loss: 2.831655266018288

Epoch: 5| Step: 2
Training loss: 0.615197365268279
Validation loss: 2.7950263067177823

Epoch: 5| Step: 3
Training loss: 0.549502626855349
Validation loss: 2.8591972844774745

Epoch: 5| Step: 4
Training loss: 0.5088145419896194
Validation loss: 2.878850324718145

Epoch: 5| Step: 5
Training loss: 1.0548805907772902
Validation loss: 2.8684956565973883

Epoch: 5| Step: 6
Training loss: 0.6752352851950697
Validation loss: 2.9630673682066164

Epoch: 5| Step: 7
Training loss: 0.5672810080716923
Validation loss: 2.865188813231915

Epoch: 5| Step: 8
Training loss: 0.5025567607231701
Validation loss: 2.8301600656522465

Epoch: 5| Step: 9
Training loss: 0.4145217364125747
Validation loss: 2.734846052739738

Epoch: 5| Step: 10
Training loss: 0.5388773171612414
Validation loss: 2.874063460217943

Epoch: 5| Step: 11
Training loss: 0.24481321385425367
Validation loss: 2.8386493359131957

Epoch: 309| Step: 0
Training loss: 0.45708272921169607
Validation loss: 2.8182425224698826

Epoch: 5| Step: 1
Training loss: 0.5760736931376331
Validation loss: 2.87423153987001

Epoch: 5| Step: 2
Training loss: 0.24354696957520341
Validation loss: 2.7814576825098833

Epoch: 5| Step: 3
Training loss: 0.3657798162185355
Validation loss: 2.860727386425902

Epoch: 5| Step: 4
Training loss: 0.580013027455923
Validation loss: 2.882665477060195

Epoch: 5| Step: 5
Training loss: 1.0846267583836529
Validation loss: 2.833852342912204

Epoch: 5| Step: 6
Training loss: 0.467906160579187
Validation loss: 2.898792144040789

Epoch: 5| Step: 7
Training loss: 0.4070044444624121
Validation loss: 2.8908095326675944

Epoch: 5| Step: 8
Training loss: 0.49588209428032504
Validation loss: 2.9090662611112252

Epoch: 5| Step: 9
Training loss: 0.3930217646488277
Validation loss: 2.821545128113455

Epoch: 5| Step: 10
Training loss: 0.5909638790010358
Validation loss: 2.797513686411687

Epoch: 5| Step: 11
Training loss: 0.37051076772232167
Validation loss: 2.8410446517274828

Epoch: 310| Step: 0
Training loss: 0.44057085096800436
Validation loss: 2.842937566522062

Epoch: 5| Step: 1
Training loss: 0.3086935678639888
Validation loss: 2.9050335816605215

Epoch: 5| Step: 2
Training loss: 0.5140851175266239
Validation loss: 2.9194957477499197

Epoch: 5| Step: 3
Training loss: 0.4938857133476248
Validation loss: 2.983266584663706

Epoch: 5| Step: 4
Training loss: 0.4957119681649472
Validation loss: 2.8820547470881817

Epoch: 5| Step: 5
Training loss: 1.1240627835410988
Validation loss: 2.8628806423326028

Epoch: 5| Step: 6
Training loss: 0.34510829635591794
Validation loss: 2.8294248386356013

Epoch: 5| Step: 7
Training loss: 0.4685841902889471
Validation loss: 2.8327423535888685

Epoch: 5| Step: 8
Training loss: 0.4328480743771649
Validation loss: 2.805563381719742

Epoch: 5| Step: 9
Training loss: 0.4551049416953755
Validation loss: 2.830501121990788

Epoch: 5| Step: 10
Training loss: 0.38727281355597404
Validation loss: 2.8128308878628414

Epoch: 5| Step: 11
Training loss: 0.5362685957487595
Validation loss: 2.814289498585957

Epoch: 311| Step: 0
Training loss: 0.299418844146271
Validation loss: 2.84087941674427

Epoch: 5| Step: 1
Training loss: 0.4420576774434432
Validation loss: 2.8968838574638602

Epoch: 5| Step: 2
Training loss: 0.4454011661531404
Validation loss: 2.90715460217847

Epoch: 5| Step: 3
Training loss: 0.5872829249275976
Validation loss: 2.8161496289322137

Epoch: 5| Step: 4
Training loss: 0.43379773677035044
Validation loss: 2.791989999285251

Epoch: 5| Step: 5
Training loss: 0.5417070068107618
Validation loss: 2.8497586611016454

Epoch: 5| Step: 6
Training loss: 1.0399580229944159
Validation loss: 2.785423943636815

Epoch: 5| Step: 7
Training loss: 0.40526055005276485
Validation loss: 2.822033174967269

Epoch: 5| Step: 8
Training loss: 0.560962908071084
Validation loss: 2.7408106318742123

Epoch: 5| Step: 9
Training loss: 0.38934218530166737
Validation loss: 2.8107733866077096

Epoch: 5| Step: 10
Training loss: 0.41189220545928484
Validation loss: 2.9012973417051557

Epoch: 5| Step: 11
Training loss: 0.4044047594101182
Validation loss: 2.914636114013866

Epoch: 312| Step: 0
Training loss: 0.5304548258913301
Validation loss: 2.871191245432673

Epoch: 5| Step: 1
Training loss: 0.43625692471361466
Validation loss: 2.8690443167764506

Epoch: 5| Step: 2
Training loss: 0.40953803928981164
Validation loss: 2.8931872550522164

Epoch: 5| Step: 3
Training loss: 0.4918283787242638
Validation loss: 2.8486782868506375

Epoch: 5| Step: 4
Training loss: 1.060350937420669
Validation loss: 2.873205028877361

Epoch: 5| Step: 5
Training loss: 0.5631062102067323
Validation loss: 2.8403498335519726

Epoch: 5| Step: 6
Training loss: 0.35897626732770493
Validation loss: 2.821950940250572

Epoch: 5| Step: 7
Training loss: 0.32792264511607616
Validation loss: 2.820775051350669

Epoch: 5| Step: 8
Training loss: 0.3395033040946329
Validation loss: 2.789419071260483

Epoch: 5| Step: 9
Training loss: 0.48624119115661285
Validation loss: 2.7078543912006516

Epoch: 5| Step: 10
Training loss: 0.405715590883608
Validation loss: 2.8490551380585236

Epoch: 5| Step: 11
Training loss: 0.6764673267405392
Validation loss: 2.8989719401972422

Epoch: 313| Step: 0
Training loss: 0.4123185878707258
Validation loss: 2.851700752425431

Epoch: 5| Step: 1
Training loss: 1.0556318788095402
Validation loss: 2.8707391671311835

Epoch: 5| Step: 2
Training loss: 0.4157771828619874
Validation loss: 2.9718236906086206

Epoch: 5| Step: 3
Training loss: 0.6192558012972814
Validation loss: 2.9300421029701544

Epoch: 5| Step: 4
Training loss: 0.3205932340631741
Validation loss: 2.839323430797637

Epoch: 5| Step: 5
Training loss: 0.4212768340690395
Validation loss: 2.8686414941893674

Epoch: 5| Step: 6
Training loss: 0.3490466805495992
Validation loss: 2.7569770880452653

Epoch: 5| Step: 7
Training loss: 0.47382023829149306
Validation loss: 2.8390346460650346

Epoch: 5| Step: 8
Training loss: 0.5987503658205957
Validation loss: 2.7615177453690163

Epoch: 5| Step: 9
Training loss: 0.38673539559346515
Validation loss: 2.725665457720553

Epoch: 5| Step: 10
Training loss: 0.4900716990446847
Validation loss: 2.7385670308277894

Epoch: 5| Step: 11
Training loss: 0.6749331273402587
Validation loss: 2.8775645061999153

Epoch: 314| Step: 0
Training loss: 0.42657955820259175
Validation loss: 2.8150960455726457

Epoch: 5| Step: 1
Training loss: 0.6882785160560304
Validation loss: 2.930908053990087

Epoch: 5| Step: 2
Training loss: 0.5191850584373866
Validation loss: 2.8858072668354766

Epoch: 5| Step: 3
Training loss: 0.46449194345683575
Validation loss: 2.760627592173522

Epoch: 5| Step: 4
Training loss: 0.27675061536219137
Validation loss: 2.7883310115638853

Epoch: 5| Step: 5
Training loss: 0.330316739483697
Validation loss: 2.7823859727349705

Epoch: 5| Step: 6
Training loss: 0.4928386407715174
Validation loss: 2.8372320227881866

Epoch: 5| Step: 7
Training loss: 0.31923011169529386
Validation loss: 2.8085868103196274

Epoch: 5| Step: 8
Training loss: 0.4714617334221607
Validation loss: 2.785792755543096

Epoch: 5| Step: 9
Training loss: 0.5636497509078273
Validation loss: 2.885613618365161

Epoch: 5| Step: 10
Training loss: 1.0643354718343834
Validation loss: 2.821799818623725

Epoch: 5| Step: 11
Training loss: 0.4770090637395547
Validation loss: 2.8629878623710447

Epoch: 315| Step: 0
Training loss: 0.4746496552379597
Validation loss: 2.7603009625543606

Epoch: 5| Step: 1
Training loss: 0.4932177674917521
Validation loss: 2.8024766898795095

Epoch: 5| Step: 2
Training loss: 0.4739938520040855
Validation loss: 2.774535850851493

Epoch: 5| Step: 3
Training loss: 0.41144386901863017
Validation loss: 2.8138290549907783

Epoch: 5| Step: 4
Training loss: 0.4641479445636214
Validation loss: 2.833445649632293

Epoch: 5| Step: 5
Training loss: 0.4252100446511794
Validation loss: 2.8084178439724066

Epoch: 5| Step: 6
Training loss: 0.4940815464332109
Validation loss: 2.8931945514868675

Epoch: 5| Step: 7
Training loss: 0.9989444406847415
Validation loss: 2.843557487511044

Epoch: 5| Step: 8
Training loss: 0.743217636763905
Validation loss: 2.8531164629482246

Epoch: 5| Step: 9
Training loss: 0.3860149336752523
Validation loss: 2.8231346508382233

Epoch: 5| Step: 10
Training loss: 0.42786266197226713
Validation loss: 2.9304575166730196

Epoch: 5| Step: 11
Training loss: 0.615204777081325
Validation loss: 2.8355293400557695

Epoch: 316| Step: 0
Training loss: 0.4777043218509401
Validation loss: 2.928056393406208

Epoch: 5| Step: 1
Training loss: 0.502825442871269
Validation loss: 2.9386739819818417

Epoch: 5| Step: 2
Training loss: 0.4411931156309574
Validation loss: 2.89087531234606

Epoch: 5| Step: 3
Training loss: 0.419600305965292
Validation loss: 2.929718125924993

Epoch: 5| Step: 4
Training loss: 0.39933225731327904
Validation loss: 2.91741854422383

Epoch: 5| Step: 5
Training loss: 0.528740114971855
Validation loss: 2.835198107224995

Epoch: 5| Step: 6
Training loss: 0.6523815303986554
Validation loss: 2.7879413092892475

Epoch: 5| Step: 7
Training loss: 0.5378337068161417
Validation loss: 2.8468361307192245

Epoch: 5| Step: 8
Training loss: 0.38652403582294836
Validation loss: 2.801564641307403

Epoch: 5| Step: 9
Training loss: 0.40721580436272903
Validation loss: 2.7762177908292975

Epoch: 5| Step: 10
Training loss: 1.0675234130507392
Validation loss: 2.8538891571532763

Epoch: 5| Step: 11
Training loss: 0.4487718930389618
Validation loss: 2.8759401795137376

Epoch: 317| Step: 0
Training loss: 0.5519851621278326
Validation loss: 2.8879145140321794

Epoch: 5| Step: 1
Training loss: 0.432187713242352
Validation loss: 2.954581844916018

Epoch: 5| Step: 2
Training loss: 0.33785119681107545
Validation loss: 2.8387469937784395

Epoch: 5| Step: 3
Training loss: 0.3494879975413637
Validation loss: 2.7776314523356813

Epoch: 5| Step: 4
Training loss: 0.6196616113807749
Validation loss: 2.809010484928007

Epoch: 5| Step: 5
Training loss: 0.4030536943403358
Validation loss: 2.7674401786631164

Epoch: 5| Step: 6
Training loss: 0.4263736208868523
Validation loss: 2.7929262953868323

Epoch: 5| Step: 7
Training loss: 1.0161790363642758
Validation loss: 2.8416161129016735

Epoch: 5| Step: 8
Training loss: 0.5012656524763787
Validation loss: 2.8707849833915895

Epoch: 5| Step: 9
Training loss: 0.4389834797842087
Validation loss: 2.9001871913203883

Epoch: 5| Step: 10
Training loss: 0.4220697695098872
Validation loss: 2.8801964396851436

Epoch: 5| Step: 11
Training loss: 0.31713794358708
Validation loss: 2.8706523080140545

Epoch: 318| Step: 0
Training loss: 0.6164745365508797
Validation loss: 2.820086828556677

Epoch: 5| Step: 1
Training loss: 0.43921091822505404
Validation loss: 2.7829693648120766

Epoch: 5| Step: 2
Training loss: 0.30821550100254597
Validation loss: 2.7942587267686583

Epoch: 5| Step: 3
Training loss: 0.42839744419578585
Validation loss: 2.8613603783222885

Epoch: 5| Step: 4
Training loss: 0.47494302018877277
Validation loss: 2.815520399001552

Epoch: 5| Step: 5
Training loss: 1.043597771056702
Validation loss: 2.8812924196454013

Epoch: 5| Step: 6
Training loss: 0.4433753393046627
Validation loss: 2.9268320468995848

Epoch: 5| Step: 7
Training loss: 0.49224238619478805
Validation loss: 2.884518233297558

Epoch: 5| Step: 8
Training loss: 0.49506590086630037
Validation loss: 2.9231687765137955

Epoch: 5| Step: 9
Training loss: 0.44173172960349116
Validation loss: 2.788748808102059

Epoch: 5| Step: 10
Training loss: 0.43864532825178487
Validation loss: 2.8177694301127665

Epoch: 5| Step: 11
Training loss: 0.3562862511645094
Validation loss: 2.7781885563918327

Epoch: 319| Step: 0
Training loss: 0.4749720094615253
Validation loss: 2.7703870590799613

Epoch: 5| Step: 1
Training loss: 0.4288655482367775
Validation loss: 2.7567172230424744

Epoch: 5| Step: 2
Training loss: 0.33761476269793206
Validation loss: 2.8872945139926625

Epoch: 5| Step: 3
Training loss: 0.3987548349798883
Validation loss: 2.8640250644571603

Epoch: 5| Step: 4
Training loss: 0.5128635675363356
Validation loss: 2.9137516384319255

Epoch: 5| Step: 5
Training loss: 0.5253863706735572
Validation loss: 2.7522963992703704

Epoch: 5| Step: 6
Training loss: 0.3624733997319381
Validation loss: 2.892300599543811

Epoch: 5| Step: 7
Training loss: 0.3309481063814534
Validation loss: 2.829636378943765

Epoch: 5| Step: 8
Training loss: 0.3730549037528733
Validation loss: 2.8415721476731006

Epoch: 5| Step: 9
Training loss: 1.009579728094243
Validation loss: 2.8788567361494564

Epoch: 5| Step: 10
Training loss: 0.5724437553562945
Validation loss: 2.9160047676989787

Epoch: 5| Step: 11
Training loss: 0.297468696037197
Validation loss: 2.8237985462801896

Epoch: 320| Step: 0
Training loss: 0.4774830167056946
Validation loss: 2.8392441023341872

Epoch: 5| Step: 1
Training loss: 0.5786033404176387
Validation loss: 2.8555510822608268

Epoch: 5| Step: 2
Training loss: 0.3995738187989053
Validation loss: 2.83482423059177

Epoch: 5| Step: 3
Training loss: 0.3610996245529898
Validation loss: 2.8707350803129175

Epoch: 5| Step: 4
Training loss: 0.35669860201466236
Validation loss: 2.8463882619916188

Epoch: 5| Step: 5
Training loss: 0.5240155913639624
Validation loss: 2.8537203145053143

Epoch: 5| Step: 6
Training loss: 0.46098379128979056
Validation loss: 2.794950313143533

Epoch: 5| Step: 7
Training loss: 0.9798426357744123
Validation loss: 2.84063200087711

Epoch: 5| Step: 8
Training loss: 0.2809183761741189
Validation loss: 2.7713500929694206

Epoch: 5| Step: 9
Training loss: 0.4105961937866836
Validation loss: 2.874351283152048

Epoch: 5| Step: 10
Training loss: 0.36366432255852804
Validation loss: 2.7906704567527947

Epoch: 5| Step: 11
Training loss: 0.29217141051030837
Validation loss: 2.8261288365213417

Epoch: 321| Step: 0
Training loss: 0.47955169619229543
Validation loss: 2.8522231812855887

Epoch: 5| Step: 1
Training loss: 0.3199253068118075
Validation loss: 2.889044888244831

Epoch: 5| Step: 2
Training loss: 0.24556965500468067
Validation loss: 2.8933541448034372

Epoch: 5| Step: 3
Training loss: 0.3422314850743039
Validation loss: 2.7046303994835865

Epoch: 5| Step: 4
Training loss: 0.40415321783257
Validation loss: 2.8365421438752785

Epoch: 5| Step: 5
Training loss: 1.0282665792919092
Validation loss: 2.8319623074964158

Epoch: 5| Step: 6
Training loss: 0.3922651191287263
Validation loss: 2.7676835525737578

Epoch: 5| Step: 7
Training loss: 0.44963508883736464
Validation loss: 2.7525930064590747

Epoch: 5| Step: 8
Training loss: 0.6444382802784465
Validation loss: 2.808405732363954

Epoch: 5| Step: 9
Training loss: 0.4263983113579745
Validation loss: 2.858571733582994

Epoch: 5| Step: 10
Training loss: 0.41526136839897243
Validation loss: 2.876796489387118

Epoch: 5| Step: 11
Training loss: 0.15451672741310274
Validation loss: 2.687742285194049

Epoch: 322| Step: 0
Training loss: 0.39962065560536203
Validation loss: 2.946759624791384

Epoch: 5| Step: 1
Training loss: 0.4699797711178746
Validation loss: 2.827319443208119

Epoch: 5| Step: 2
Training loss: 0.36057987578723616
Validation loss: 2.858173979737088

Epoch: 5| Step: 3
Training loss: 0.5292051454005587
Validation loss: 2.802177662780223

Epoch: 5| Step: 4
Training loss: 0.3965535784680521
Validation loss: 2.875148935192077

Epoch: 5| Step: 5
Training loss: 0.41231103455805107
Validation loss: 2.8148690242234387

Epoch: 5| Step: 6
Training loss: 0.5437907850381947
Validation loss: 2.810310274282546

Epoch: 5| Step: 7
Training loss: 0.37550600007593116
Validation loss: 2.836070047999347

Epoch: 5| Step: 8
Training loss: 0.4985589181466019
Validation loss: 2.8302139923568905

Epoch: 5| Step: 9
Training loss: 1.029495364889685
Validation loss: 2.8321478843787515

Epoch: 5| Step: 10
Training loss: 0.37577025462855734
Validation loss: 2.926202298109208

Epoch: 5| Step: 11
Training loss: 0.17577454766105566
Validation loss: 2.932044675508129

Epoch: 323| Step: 0
Training loss: 0.3669898942080922
Validation loss: 2.844195446297619

Epoch: 5| Step: 1
Training loss: 0.4975171731735653
Validation loss: 2.7772760986587337

Epoch: 5| Step: 2
Training loss: 0.39850554165762164
Validation loss: 2.7943295664923635

Epoch: 5| Step: 3
Training loss: 0.31677124964017567
Validation loss: 2.828674003185936

Epoch: 5| Step: 4
Training loss: 0.3691454690282371
Validation loss: 2.9191055534641897

Epoch: 5| Step: 5
Training loss: 1.0270840856976233
Validation loss: 2.7609923512181185

Epoch: 5| Step: 6
Training loss: 0.35604836295616277
Validation loss: 2.8732194708201284

Epoch: 5| Step: 7
Training loss: 0.5009436345572555
Validation loss: 2.791210380434737

Epoch: 5| Step: 8
Training loss: 0.5531724737020972
Validation loss: 2.930780232410973

Epoch: 5| Step: 9
Training loss: 0.4330048212989934
Validation loss: 2.9100181393205475

Epoch: 5| Step: 10
Training loss: 0.3628845920615608
Validation loss: 2.8668442086661323

Epoch: 5| Step: 11
Training loss: 0.46508575999655505
Validation loss: 2.888481823401841

Epoch: 324| Step: 0
Training loss: 0.4644747800406723
Validation loss: 2.840626723677501

Epoch: 5| Step: 1
Training loss: 0.5216207147454698
Validation loss: 2.8044506245700505

Epoch: 5| Step: 2
Training loss: 0.4831591697936746
Validation loss: 2.8317231460119276

Epoch: 5| Step: 3
Training loss: 0.3712031554520637
Validation loss: 2.8192791406177973

Epoch: 5| Step: 4
Training loss: 0.3223295437395425
Validation loss: 2.897763807176371

Epoch: 5| Step: 5
Training loss: 0.4747457426100236
Validation loss: 2.9118871810886473

Epoch: 5| Step: 6
Training loss: 0.4464891682098032
Validation loss: 2.917520426499164

Epoch: 5| Step: 7
Training loss: 0.4203865319325513
Validation loss: 2.8044737235853847

Epoch: 5| Step: 8
Training loss: 0.5951075594116627
Validation loss: 2.823858784255734

Epoch: 5| Step: 9
Training loss: 1.0123469342986677
Validation loss: 2.911247591547545

Epoch: 5| Step: 10
Training loss: 0.42259123719956415
Validation loss: 2.7732903025074958

Epoch: 5| Step: 11
Training loss: 0.20250609450529297
Validation loss: 2.8662579594859423

Epoch: 325| Step: 0
Training loss: 0.9610734548768608
Validation loss: 2.8416732953479977

Epoch: 5| Step: 1
Training loss: 0.5217194902266843
Validation loss: 2.8070620488311184

Epoch: 5| Step: 2
Training loss: 0.4207470792089889
Validation loss: 2.8255854984507325

Epoch: 5| Step: 3
Training loss: 0.4602881237757083
Validation loss: 2.7685057656497545

Epoch: 5| Step: 4
Training loss: 0.39953838922345386
Validation loss: 2.865411053917784

Epoch: 5| Step: 5
Training loss: 0.4388010909826753
Validation loss: 2.850551917358927

Epoch: 5| Step: 6
Training loss: 0.3242706578996925
Validation loss: 2.919023645685087

Epoch: 5| Step: 7
Training loss: 0.4410140396508644
Validation loss: 2.8164986548077158

Epoch: 5| Step: 8
Training loss: 0.42731301791695486
Validation loss: 2.8199543272004903

Epoch: 5| Step: 9
Training loss: 0.2850138295524212
Validation loss: 2.74582188555155

Epoch: 5| Step: 10
Training loss: 0.5735141817216858
Validation loss: 2.7456043471125406

Epoch: 5| Step: 11
Training loss: 0.628989717619322
Validation loss: 2.9045232476383056

Epoch: 326| Step: 0
Training loss: 0.3963581880356266
Validation loss: 2.881105167226924

Epoch: 5| Step: 1
Training loss: 0.5503954246208843
Validation loss: 2.9029583355135253

Epoch: 5| Step: 2
Training loss: 0.43356006938268954
Validation loss: 2.9197090573191935

Epoch: 5| Step: 3
Training loss: 0.4982430165342629
Validation loss: 2.846515271698947

Epoch: 5| Step: 4
Training loss: 0.3401031162115274
Validation loss: 2.8274553359675423

Epoch: 5| Step: 5
Training loss: 0.9881294344972035
Validation loss: 2.8386701933900986

Epoch: 5| Step: 6
Training loss: 0.48036048413693255
Validation loss: 2.816657447987957

Epoch: 5| Step: 7
Training loss: 0.48840611196500494
Validation loss: 2.8323724861207378

Epoch: 5| Step: 8
Training loss: 0.5508625700958996
Validation loss: 2.8021864298936188

Epoch: 5| Step: 9
Training loss: 0.44165535033621645
Validation loss: 2.7982057854251483

Epoch: 5| Step: 10
Training loss: 0.5415516755727692
Validation loss: 2.820769839133331

Epoch: 5| Step: 11
Training loss: 0.5897412242584142
Validation loss: 2.871020157404998

Epoch: 327| Step: 0
Training loss: 0.9910944226566529
Validation loss: 2.8837824725695724

Epoch: 5| Step: 1
Training loss: 0.4651313180748083
Validation loss: 2.834495612245094

Epoch: 5| Step: 2
Training loss: 0.2506355313873335
Validation loss: 2.790600317987902

Epoch: 5| Step: 3
Training loss: 0.40018375914369914
Validation loss: 2.8694919468900246

Epoch: 5| Step: 4
Training loss: 0.5733365138884232
Validation loss: 2.828203456626409

Epoch: 5| Step: 5
Training loss: 0.4188813380766782
Validation loss: 2.8518763957290862

Epoch: 5| Step: 6
Training loss: 0.5557794702483716
Validation loss: 2.8320251429700227

Epoch: 5| Step: 7
Training loss: 0.5803179518074311
Validation loss: 2.835597421591744

Epoch: 5| Step: 8
Training loss: 0.668369240077669
Validation loss: 2.965167403617514

Epoch: 5| Step: 9
Training loss: 0.460481369498026
Validation loss: 2.952436249088047

Epoch: 5| Step: 10
Training loss: 0.5548873863582224
Validation loss: 2.906725953892621

Epoch: 5| Step: 11
Training loss: 0.44879445480067576
Validation loss: 2.8456170831194956

Epoch: 328| Step: 0
Training loss: 0.5086546150973855
Validation loss: 2.8265015278698558

Epoch: 5| Step: 1
Training loss: 1.0680582295056225
Validation loss: 2.8422567163741985

Epoch: 5| Step: 2
Training loss: 0.5781871401408689
Validation loss: 2.8442213415424558

Epoch: 5| Step: 3
Training loss: 0.40278878644536487
Validation loss: 2.9175106780165407

Epoch: 5| Step: 4
Training loss: 0.37986392486610315
Validation loss: 2.8686861804021717

Epoch: 5| Step: 5
Training loss: 0.5055852906014378
Validation loss: 2.8732372975471505

Epoch: 5| Step: 6
Training loss: 0.4982310534242187
Validation loss: 2.903682309364924

Epoch: 5| Step: 7
Training loss: 0.40513523916777894
Validation loss: 2.815496169800621

Epoch: 5| Step: 8
Training loss: 0.4194070543412645
Validation loss: 2.932657945070033

Epoch: 5| Step: 9
Training loss: 0.45493879354581007
Validation loss: 2.875931706318893

Epoch: 5| Step: 10
Training loss: 0.46695449594031885
Validation loss: 2.8440545306792506

Epoch: 5| Step: 11
Training loss: 0.3812609780403867
Validation loss: 2.8259089553461716

Epoch: 329| Step: 0
Training loss: 0.4502472092511808
Validation loss: 2.889987669096779

Epoch: 5| Step: 1
Training loss: 0.5509049837986255
Validation loss: 2.902173153230557

Epoch: 5| Step: 2
Training loss: 0.7305141985621103
Validation loss: 2.877662666151949

Epoch: 5| Step: 3
Training loss: 0.39733082284123594
Validation loss: 2.8126520539612656

Epoch: 5| Step: 4
Training loss: 0.4103312890892538
Validation loss: 2.781942956300531

Epoch: 5| Step: 5
Training loss: 0.6546828768255105
Validation loss: 2.757912995089665

Epoch: 5| Step: 6
Training loss: 1.0229645429751646
Validation loss: 2.7527251901189613

Epoch: 5| Step: 7
Training loss: 0.36896005886772193
Validation loss: 2.8022476003965955

Epoch: 5| Step: 8
Training loss: 0.5003713182689834
Validation loss: 2.85074843888459

Epoch: 5| Step: 9
Training loss: 0.6709281548327631
Validation loss: 2.8903277751254866

Epoch: 5| Step: 10
Training loss: 0.4292085058533312
Validation loss: 2.8659247476991943

Epoch: 5| Step: 11
Training loss: 0.3504859441688318
Validation loss: 2.8687367770708194

Epoch: 330| Step: 0
Training loss: 0.9655770669539941
Validation loss: 2.843232453588871

Epoch: 5| Step: 1
Training loss: 0.5232915532489424
Validation loss: 2.8523396517312234

Epoch: 5| Step: 2
Training loss: 0.4473963883662602
Validation loss: 2.780423145039875

Epoch: 5| Step: 3
Training loss: 0.4386677314650928
Validation loss: 2.8137139031913496

Epoch: 5| Step: 4
Training loss: 0.3434822600391152
Validation loss: 2.785546447114792

Epoch: 5| Step: 5
Training loss: 0.49589755466498286
Validation loss: 2.7991105527459403

Epoch: 5| Step: 6
Training loss: 0.44402988499295964
Validation loss: 2.797277510394508

Epoch: 5| Step: 7
Training loss: 0.4743981695987793
Validation loss: 2.8620328692788646

Epoch: 5| Step: 8
Training loss: 0.49497797286027495
Validation loss: 2.796165934069085

Epoch: 5| Step: 9
Training loss: 0.48660359375085604
Validation loss: 2.8997819495164485

Epoch: 5| Step: 10
Training loss: 0.47985535520968037
Validation loss: 2.809270831090919

Epoch: 5| Step: 11
Training loss: 0.5786751372033075
Validation loss: 2.802806967615951

Epoch: 331| Step: 0
Training loss: 0.5559223560245504
Validation loss: 2.7757762557805337

Epoch: 5| Step: 1
Training loss: 1.0337728793507972
Validation loss: 2.820723907812536

Epoch: 5| Step: 2
Training loss: 0.47921455876495517
Validation loss: 2.7916883792791976

Epoch: 5| Step: 3
Training loss: 0.4726232091531268
Validation loss: 2.746909803937437

Epoch: 5| Step: 4
Training loss: 0.41607814193714665
Validation loss: 2.80159298720103

Epoch: 5| Step: 5
Training loss: 0.2988657958776473
Validation loss: 2.8840920590223664

Epoch: 5| Step: 6
Training loss: 0.4726105029453725
Validation loss: 2.904036719978372

Epoch: 5| Step: 7
Training loss: 0.5274524717930615
Validation loss: 2.936449593572386

Epoch: 5| Step: 8
Training loss: 0.412895736013085
Validation loss: 2.847016802151435

Epoch: 5| Step: 9
Training loss: 0.49035536652214384
Validation loss: 2.87606327463719

Epoch: 5| Step: 10
Training loss: 0.4500650643624078
Validation loss: 2.8383250454247597

Epoch: 5| Step: 11
Training loss: 0.35966076062965496
Validation loss: 2.808486138812561

Epoch: 332| Step: 0
Training loss: 0.5272527828170246
Validation loss: 2.809848008383727

Epoch: 5| Step: 1
Training loss: 0.9144050086853773
Validation loss: 2.8169742422407964

Epoch: 5| Step: 2
Training loss: 0.31254387785905724
Validation loss: 2.798211213630485

Epoch: 5| Step: 3
Training loss: 0.4846143131351969
Validation loss: 2.861438534703666

Epoch: 5| Step: 4
Training loss: 0.5296481891549628
Validation loss: 2.864469547901789

Epoch: 5| Step: 5
Training loss: 0.5496000244386327
Validation loss: 2.8193177206210445

Epoch: 5| Step: 6
Training loss: 0.3531634647384157
Validation loss: 2.783404401673253

Epoch: 5| Step: 7
Training loss: 0.43829171887302654
Validation loss: 2.799791527406606

Epoch: 5| Step: 8
Training loss: 0.40233476869503026
Validation loss: 2.803672847845605

Epoch: 5| Step: 9
Training loss: 0.5303592788034927
Validation loss: 2.7855255930698366

Epoch: 5| Step: 10
Training loss: 0.45536115955803785
Validation loss: 2.792061035332114

Epoch: 5| Step: 11
Training loss: 0.5275116264725264
Validation loss: 2.9902126544850383

Epoch: 333| Step: 0
Training loss: 0.45669141997590135
Validation loss: 2.832695332857116

Epoch: 5| Step: 1
Training loss: 0.46382563354686607
Validation loss: 2.914731682652856

Epoch: 5| Step: 2
Training loss: 0.5003682806786984
Validation loss: 2.97318515425105

Epoch: 5| Step: 3
Training loss: 0.3950441633355553
Validation loss: 2.924588403787514

Epoch: 5| Step: 4
Training loss: 0.445277396709136
Validation loss: 2.840405488634118

Epoch: 5| Step: 5
Training loss: 0.5846274926909557
Validation loss: 2.8413713798659317

Epoch: 5| Step: 6
Training loss: 0.6533519241143528
Validation loss: 2.8369446184325997

Epoch: 5| Step: 7
Training loss: 0.3926014679758394
Validation loss: 2.7474782608949377

Epoch: 5| Step: 8
Training loss: 0.3814266186580503
Validation loss: 2.829975404492089

Epoch: 5| Step: 9
Training loss: 0.4535534904502952
Validation loss: 2.8112880956766344

Epoch: 5| Step: 10
Training loss: 0.9483454576353055
Validation loss: 2.8483290154491514

Epoch: 5| Step: 11
Training loss: 0.4815342726161099
Validation loss: 2.9102496991952176

Epoch: 334| Step: 0
Training loss: 0.4349533279089035
Validation loss: 2.9197372020895296

Epoch: 5| Step: 1
Training loss: 0.5620189835305062
Validation loss: 2.8229669564097275

Epoch: 5| Step: 2
Training loss: 0.3440491826549025
Validation loss: 2.840834286138394

Epoch: 5| Step: 3
Training loss: 0.3761309814408556
Validation loss: 2.8074798249629156

Epoch: 5| Step: 4
Training loss: 0.9455365002272645
Validation loss: 2.781948909024826

Epoch: 5| Step: 5
Training loss: 0.45262886707199435
Validation loss: 2.800616356585836

Epoch: 5| Step: 6
Training loss: 0.48789220951699575
Validation loss: 2.769188304161864

Epoch: 5| Step: 7
Training loss: 0.4277282087325759
Validation loss: 2.8932805724889206

Epoch: 5| Step: 8
Training loss: 0.6227045344414136
Validation loss: 2.8339680996126693

Epoch: 5| Step: 9
Training loss: 0.5180885533121038
Validation loss: 2.96791641511871

Epoch: 5| Step: 10
Training loss: 0.4762603865264329
Validation loss: 2.8424970535502374

Epoch: 5| Step: 11
Training loss: 0.1555694900657237
Validation loss: 2.8409753544911207

Epoch: 335| Step: 0
Training loss: 0.28960607299898067
Validation loss: 2.867484050524565

Epoch: 5| Step: 1
Training loss: 0.3396430793326403
Validation loss: 2.8214129822020393

Epoch: 5| Step: 2
Training loss: 0.4437108936002508
Validation loss: 2.806160546188974

Epoch: 5| Step: 3
Training loss: 0.5695845779130012
Validation loss: 2.831982302187903

Epoch: 5| Step: 4
Training loss: 0.3732406552301771
Validation loss: 2.8081557560610517

Epoch: 5| Step: 5
Training loss: 1.0105604220242794
Validation loss: 2.855721291621582

Epoch: 5| Step: 6
Training loss: 0.5260371374810258
Validation loss: 2.812001118742389

Epoch: 5| Step: 7
Training loss: 0.31997460476868556
Validation loss: 2.851920759436

Epoch: 5| Step: 8
Training loss: 0.38367757561141597
Validation loss: 2.8382239989332367

Epoch: 5| Step: 9
Training loss: 0.5810012151652906
Validation loss: 2.8584513675092937

Epoch: 5| Step: 10
Training loss: 0.432147061241377
Validation loss: 2.8308401018787404

Epoch: 5| Step: 11
Training loss: 0.4280795268112997
Validation loss: 2.8453790239674532

Epoch: 336| Step: 0
Training loss: 0.9187949824836815
Validation loss: 2.8060861746440455

Epoch: 5| Step: 1
Training loss: 0.38074796954619844
Validation loss: 2.8888554818843377

Epoch: 5| Step: 2
Training loss: 0.4883883854633172
Validation loss: 2.8582329232417467

Epoch: 5| Step: 3
Training loss: 0.33887084827039776
Validation loss: 2.8947279945189655

Epoch: 5| Step: 4
Training loss: 0.4180258239567326
Validation loss: 2.884557662696092

Epoch: 5| Step: 5
Training loss: 0.4330547866497727
Validation loss: 2.898154859308817

Epoch: 5| Step: 6
Training loss: 0.37780418579318154
Validation loss: 2.8378188283212826

Epoch: 5| Step: 7
Training loss: 0.49491425217054874
Validation loss: 2.8689967899091813

Epoch: 5| Step: 8
Training loss: 0.44170209372185937
Validation loss: 2.928346769632798

Epoch: 5| Step: 9
Training loss: 0.5138057635781806
Validation loss: 2.842547656814181

Epoch: 5| Step: 10
Training loss: 0.5900465004182878
Validation loss: 2.8806456716122284

Epoch: 5| Step: 11
Training loss: 0.4075206911064589
Validation loss: 2.8817743225646475

Epoch: 337| Step: 0
Training loss: 0.9533530103268919
Validation loss: 2.798221189572285

Epoch: 5| Step: 1
Training loss: 0.605441382004953
Validation loss: 2.8534154715554787

Epoch: 5| Step: 2
Training loss: 0.555439560092382
Validation loss: 2.7815446447537857

Epoch: 5| Step: 3
Training loss: 0.454465740567153
Validation loss: 2.8695200649077757

Epoch: 5| Step: 4
Training loss: 0.4013486240669903
Validation loss: 2.8498325308456853

Epoch: 5| Step: 5
Training loss: 0.5447818206957425
Validation loss: 2.915761927653135

Epoch: 5| Step: 6
Training loss: 0.4807069699613967
Validation loss: 2.9451822914867734

Epoch: 5| Step: 7
Training loss: 0.4179551487786358
Validation loss: 2.861383769565126

Epoch: 5| Step: 8
Training loss: 0.5858007398585046
Validation loss: 2.8924806772903824

Epoch: 5| Step: 9
Training loss: 0.39524461442268977
Validation loss: 2.7891518429819184

Epoch: 5| Step: 10
Training loss: 0.5769169015431628
Validation loss: 2.8547784585839064

Epoch: 5| Step: 11
Training loss: 0.21249427121518485
Validation loss: 2.894796917830394

Epoch: 338| Step: 0
Training loss: 0.4007017647966878
Validation loss: 2.8365435132309527

Epoch: 5| Step: 1
Training loss: 0.4520380367345804
Validation loss: 2.8681089980221506

Epoch: 5| Step: 2
Training loss: 0.3170115720565125
Validation loss: 2.872045982730789

Epoch: 5| Step: 3
Training loss: 0.4849911585473832
Validation loss: 2.910693470228245

Epoch: 5| Step: 4
Training loss: 0.523052529496047
Validation loss: 2.8527368365747314

Epoch: 5| Step: 5
Training loss: 0.3393683780986588
Validation loss: 2.907075204220502

Epoch: 5| Step: 6
Training loss: 0.47454032866655294
Validation loss: 2.87341425016621

Epoch: 5| Step: 7
Training loss: 0.42164948405185954
Validation loss: 2.9283242101225047

Epoch: 5| Step: 8
Training loss: 0.6213790190449138
Validation loss: 2.89972135997448

Epoch: 5| Step: 9
Training loss: 0.976592925551425
Validation loss: 2.8052970946319107

Epoch: 5| Step: 10
Training loss: 0.38108382824834275
Validation loss: 2.810678672925564

Epoch: 5| Step: 11
Training loss: 0.7004661089617404
Validation loss: 2.7892057415877183

Epoch: 339| Step: 0
Training loss: 0.32525755598746103
Validation loss: 2.841093170675618

Epoch: 5| Step: 1
Training loss: 0.5898705280617039
Validation loss: 2.9199772960289683

Epoch: 5| Step: 2
Training loss: 0.38862600007884024
Validation loss: 2.944574089814882

Epoch: 5| Step: 3
Training loss: 0.681864660658451
Validation loss: 2.9134764197013805

Epoch: 5| Step: 4
Training loss: 1.0611774403599494
Validation loss: 2.925707235108892

Epoch: 5| Step: 5
Training loss: 0.3753859600051174
Validation loss: 2.7947100566408847

Epoch: 5| Step: 6
Training loss: 0.43697403899841775
Validation loss: 2.7477522391367217

Epoch: 5| Step: 7
Training loss: 0.7476293130484579
Validation loss: 2.7984117037096947

Epoch: 5| Step: 8
Training loss: 0.36459046992628624
Validation loss: 2.7788096841101595

Epoch: 5| Step: 9
Training loss: 0.569117011612617
Validation loss: 2.744536054364307

Epoch: 5| Step: 10
Training loss: 0.45586239275223556
Validation loss: 2.8138798189995082

Epoch: 5| Step: 11
Training loss: 0.7618728481822493
Validation loss: 2.922614563283772

Epoch: 340| Step: 0
Training loss: 0.5756922390380059
Validation loss: 2.8941347002423665

Epoch: 5| Step: 1
Training loss: 0.33984118493526183
Validation loss: 2.844785508761777

Epoch: 5| Step: 2
Training loss: 0.3237842612935121
Validation loss: 2.907038086170038

Epoch: 5| Step: 3
Training loss: 0.4940343448499268
Validation loss: 2.754592416831324

Epoch: 5| Step: 4
Training loss: 0.49779297583847887
Validation loss: 2.732676768871789

Epoch: 5| Step: 5
Training loss: 1.0985087820612756
Validation loss: 2.73353814897722

Epoch: 5| Step: 6
Training loss: 0.4375087192211502
Validation loss: 2.8229355418476287

Epoch: 5| Step: 7
Training loss: 0.37957657186527805
Validation loss: 2.788064231275874

Epoch: 5| Step: 8
Training loss: 0.3423761853514058
Validation loss: 2.958436250015811

Epoch: 5| Step: 9
Training loss: 0.3819545551849886
Validation loss: 2.947382256197471

Epoch: 5| Step: 10
Training loss: 0.5647862912997162
Validation loss: 2.8885558377805727

Epoch: 5| Step: 11
Training loss: 0.6562326519807559
Validation loss: 2.8907815358160223

Epoch: 341| Step: 0
Training loss: 0.48689191379965996
Validation loss: 2.8107608186200936

Epoch: 5| Step: 1
Training loss: 0.9910267625903851
Validation loss: 2.8075742998026434

Epoch: 5| Step: 2
Training loss: 0.5333136698952422
Validation loss: 2.778347973051748

Epoch: 5| Step: 3
Training loss: 0.5118351578257091
Validation loss: 2.8074434459942657

Epoch: 5| Step: 4
Training loss: 0.5219600665266527
Validation loss: 2.856541016108424

Epoch: 5| Step: 5
Training loss: 0.4214713496757835
Validation loss: 2.8514292298271235

Epoch: 5| Step: 6
Training loss: 0.3483763854995349
Validation loss: 2.820055878606402

Epoch: 5| Step: 7
Training loss: 0.39895674586499
Validation loss: 3.0070244190181095

Epoch: 5| Step: 8
Training loss: 0.7393125969808271
Validation loss: 2.9540523640552796

Epoch: 5| Step: 9
Training loss: 0.3498877264361098
Validation loss: 2.8706572220262756

Epoch: 5| Step: 10
Training loss: 0.3174149482303638
Validation loss: 2.8178978108261186

Epoch: 5| Step: 11
Training loss: 0.5936724461551353
Validation loss: 2.8499127985346155

Epoch: 342| Step: 0
Training loss: 0.4620179589752596
Validation loss: 2.7892796301003475

Epoch: 5| Step: 1
Training loss: 0.36781154522249276
Validation loss: 2.850070681587816

Epoch: 5| Step: 2
Training loss: 0.5692190374163715
Validation loss: 2.849525382442785

Epoch: 5| Step: 3
Training loss: 0.41547064388743005
Validation loss: 2.8365531897587317

Epoch: 5| Step: 4
Training loss: 0.4003574636729571
Validation loss: 2.8750501987663504

Epoch: 5| Step: 5
Training loss: 0.9820546246814147
Validation loss: 2.8508233806451617

Epoch: 5| Step: 6
Training loss: 0.4822909683348816
Validation loss: 2.8598322580904147

Epoch: 5| Step: 7
Training loss: 0.45743598297280386
Validation loss: 2.83026888678091

Epoch: 5| Step: 8
Training loss: 0.40381300346060905
Validation loss: 2.8253047555787014

Epoch: 5| Step: 9
Training loss: 0.5444446237584336
Validation loss: 2.869147615573539

Epoch: 5| Step: 10
Training loss: 0.391457909469957
Validation loss: 2.8644606488861357

Epoch: 5| Step: 11
Training loss: 0.31178152221946154
Validation loss: 2.8599080803078105

Epoch: 343| Step: 0
Training loss: 0.477660774057294
Validation loss: 2.799497774047521

Epoch: 5| Step: 1
Training loss: 0.48854802282735776
Validation loss: 2.90585833819255

Epoch: 5| Step: 2
Training loss: 0.3614995807378825
Validation loss: 2.8473594207324067

Epoch: 5| Step: 3
Training loss: 0.4463617778946684
Validation loss: 2.896379437628173

Epoch: 5| Step: 4
Training loss: 0.45062827517817877
Validation loss: 2.9193704209822284

Epoch: 5| Step: 5
Training loss: 0.9659428996018814
Validation loss: 2.835472401574056

Epoch: 5| Step: 6
Training loss: 0.3563146064132633
Validation loss: 2.892753703927242

Epoch: 5| Step: 7
Training loss: 0.502506559575856
Validation loss: 2.9154658513656404

Epoch: 5| Step: 8
Training loss: 0.4302912891509783
Validation loss: 2.7394193314946937

Epoch: 5| Step: 9
Training loss: 0.44130680348083184
Validation loss: 2.8541259739520406

Epoch: 5| Step: 10
Training loss: 0.4421221068052754
Validation loss: 2.821672895198947

Epoch: 5| Step: 11
Training loss: 0.2809381477976492
Validation loss: 2.8705840542829346

Epoch: 344| Step: 0
Training loss: 0.38085092388460196
Validation loss: 2.906445975173585

Epoch: 5| Step: 1
Training loss: 0.352276870994724
Validation loss: 2.970419608319947

Epoch: 5| Step: 2
Training loss: 0.3852720655215543
Validation loss: 2.870274904046757

Epoch: 5| Step: 3
Training loss: 0.2624226967201644
Validation loss: 2.85137571306607

Epoch: 5| Step: 4
Training loss: 0.6223391636117495
Validation loss: 2.935927589079008

Epoch: 5| Step: 5
Training loss: 0.3405065649949958
Validation loss: 2.8443281997197865

Epoch: 5| Step: 6
Training loss: 0.3902373297563253
Validation loss: 2.8277571669031225

Epoch: 5| Step: 7
Training loss: 0.9085788072848104
Validation loss: 2.8031512403447185

Epoch: 5| Step: 8
Training loss: 0.3312494948221349
Validation loss: 2.9640875292954436

Epoch: 5| Step: 9
Training loss: 0.403488899815689
Validation loss: 2.8739056473968163

Epoch: 5| Step: 10
Training loss: 0.34967707399399733
Validation loss: 2.863466746873266

Epoch: 5| Step: 11
Training loss: 0.3701386860665407
Validation loss: 2.8600672559621856

Epoch: 345| Step: 0
Training loss: 0.39631168005761774
Validation loss: 2.950524555999661

Epoch: 5| Step: 1
Training loss: 0.4263838956514977
Validation loss: 2.904430510322444

Epoch: 5| Step: 2
Training loss: 0.5323937669640659
Validation loss: 2.944485655394744

Epoch: 5| Step: 3
Training loss: 0.36559208778859736
Validation loss: 2.964928109397484

Epoch: 5| Step: 4
Training loss: 0.35685940035314623
Validation loss: 2.8842883411475717

Epoch: 5| Step: 5
Training loss: 0.45287957615426355
Validation loss: 2.847306640402154

Epoch: 5| Step: 6
Training loss: 0.49957061748478926
Validation loss: 2.7990706401498042

Epoch: 5| Step: 7
Training loss: 0.412587363210645
Validation loss: 2.8064573153329535

Epoch: 5| Step: 8
Training loss: 0.9934709613033043
Validation loss: 2.8136801892588963

Epoch: 5| Step: 9
Training loss: 0.4427911587447172
Validation loss: 2.9131183611806373

Epoch: 5| Step: 10
Training loss: 0.5359757267967901
Validation loss: 2.969329583327819

Epoch: 5| Step: 11
Training loss: 0.5796671223721825
Validation loss: 2.8698478642457714

Epoch: 346| Step: 0
Training loss: 0.39452058003415735
Validation loss: 2.886117863178055

Epoch: 5| Step: 1
Training loss: 0.4196624309241702
Validation loss: 2.925610145553412

Epoch: 5| Step: 2
Training loss: 0.4460323104370058
Validation loss: 2.8589805094652885

Epoch: 5| Step: 3
Training loss: 0.9318739880684898
Validation loss: 2.841273223067664

Epoch: 5| Step: 4
Training loss: 0.602784389712532
Validation loss: 2.8138837271441455

Epoch: 5| Step: 5
Training loss: 0.34621668240449466
Validation loss: 2.910913120644779

Epoch: 5| Step: 6
Training loss: 0.39430676107180157
Validation loss: 2.9577026108985573

Epoch: 5| Step: 7
Training loss: 0.5681125327694816
Validation loss: 2.9390251650780423

Epoch: 5| Step: 8
Training loss: 0.6172091806201153
Validation loss: 2.8051019679341183

Epoch: 5| Step: 9
Training loss: 0.3830834811491588
Validation loss: 2.8628712803405723

Epoch: 5| Step: 10
Training loss: 0.4853545405643827
Validation loss: 2.7729585905700933

Epoch: 5| Step: 11
Training loss: 0.5247399935156747
Validation loss: 2.7700527473160337

Epoch: 347| Step: 0
Training loss: 0.3579438364125175
Validation loss: 2.8012438453709976

Epoch: 5| Step: 1
Training loss: 0.3162770537350657
Validation loss: 2.8368485408708004

Epoch: 5| Step: 2
Training loss: 0.38629591588674017
Validation loss: 2.8731315318518735

Epoch: 5| Step: 3
Training loss: 0.457445885787927
Validation loss: 2.9344769505836856

Epoch: 5| Step: 4
Training loss: 1.0432984477498615
Validation loss: 2.895089555951758

Epoch: 5| Step: 5
Training loss: 0.3268697092164192
Validation loss: 2.8874140114249123

Epoch: 5| Step: 6
Training loss: 0.6713134947640592
Validation loss: 2.8010940270703837

Epoch: 5| Step: 7
Training loss: 0.49880700540903994
Validation loss: 2.824077882326983

Epoch: 5| Step: 8
Training loss: 0.3457969279641484
Validation loss: 2.840428253287481

Epoch: 5| Step: 9
Training loss: 0.43466615798631303
Validation loss: 2.7844442997566894

Epoch: 5| Step: 10
Training loss: 0.4054111476547367
Validation loss: 2.83014864029668

Epoch: 5| Step: 11
Training loss: 0.16217531448775982
Validation loss: 2.8274050089403073

Epoch: 348| Step: 0
Training loss: 0.4592563229324416
Validation loss: 2.8504706883609905

Epoch: 5| Step: 1
Training loss: 0.5152068320917187
Validation loss: 2.8548682190599797

Epoch: 5| Step: 2
Training loss: 0.4292017705535543
Validation loss: 2.957311871414703

Epoch: 5| Step: 3
Training loss: 0.6093084592435781
Validation loss: 2.8766468832087897

Epoch: 5| Step: 4
Training loss: 0.3805315024697825
Validation loss: 2.8863933828960513

Epoch: 5| Step: 5
Training loss: 1.0148491463580123
Validation loss: 2.8493437369772834

Epoch: 5| Step: 6
Training loss: 0.4766074925430421
Validation loss: 2.7512603819190637

Epoch: 5| Step: 7
Training loss: 0.4031175560966274
Validation loss: 2.8332194359176297

Epoch: 5| Step: 8
Training loss: 0.5636853867442675
Validation loss: 2.8018924702492467

Epoch: 5| Step: 9
Training loss: 0.4457904526181472
Validation loss: 2.8137793068564894

Epoch: 5| Step: 10
Training loss: 0.3101406319286848
Validation loss: 2.8610728248690833

Epoch: 5| Step: 11
Training loss: 0.3621734833987948
Validation loss: 2.9731544414690685

Epoch: 349| Step: 0
Training loss: 0.5707919574509116
Validation loss: 2.9996032469045564

Epoch: 5| Step: 1
Training loss: 0.4396083472880351
Validation loss: 2.979819957534222

Epoch: 5| Step: 2
Training loss: 0.3867101572026135
Validation loss: 2.9332359627435745

Epoch: 5| Step: 3
Training loss: 0.44206067750183775
Validation loss: 2.828490779820098

Epoch: 5| Step: 4
Training loss: 0.2845343379188828
Validation loss: 2.8898119152357893

Epoch: 5| Step: 5
Training loss: 0.5582446628115549
Validation loss: 2.8643446054107713

Epoch: 5| Step: 6
Training loss: 0.5118782435536817
Validation loss: 2.8037675359990786

Epoch: 5| Step: 7
Training loss: 0.4199237734729523
Validation loss: 2.811827819466835

Epoch: 5| Step: 8
Training loss: 0.9710613180868908
Validation loss: 2.830739647998841

Epoch: 5| Step: 9
Training loss: 0.46089453416133797
Validation loss: 2.8969429958035393

Epoch: 5| Step: 10
Training loss: 0.518481520611317
Validation loss: 2.987502338562799

Epoch: 5| Step: 11
Training loss: 0.27058665644860086
Validation loss: 2.931578636996587

Epoch: 350| Step: 0
Training loss: 0.4897063706053931
Validation loss: 2.918157013961061

Epoch: 5| Step: 1
Training loss: 0.3735186404896594
Validation loss: 2.8357013782744183

Epoch: 5| Step: 2
Training loss: 0.41667490196036905
Validation loss: 2.8163164347570078

Epoch: 5| Step: 3
Training loss: 0.9729706895575206
Validation loss: 2.819090669237004

Epoch: 5| Step: 4
Training loss: 0.3556985007826896
Validation loss: 2.8006434599581516

Epoch: 5| Step: 5
Training loss: 0.47884547484252227
Validation loss: 2.78241472466042

Epoch: 5| Step: 6
Training loss: 0.2530231818530814
Validation loss: 2.8656970107620485

Epoch: 5| Step: 7
Training loss: 0.4040735890518267
Validation loss: 2.833392497922217

Epoch: 5| Step: 8
Training loss: 0.3305541448981552
Validation loss: 2.789154013834021

Epoch: 5| Step: 9
Training loss: 0.5097297860478562
Validation loss: 2.8964871667842913

Epoch: 5| Step: 10
Training loss: 0.42394455396049574
Validation loss: 2.7952866475057867

Epoch: 5| Step: 11
Training loss: 0.3731374980041048
Validation loss: 2.8735901409496614

Epoch: 351| Step: 0
Training loss: 0.34952929980945135
Validation loss: 2.831500155756809

Epoch: 5| Step: 1
Training loss: 0.5993361456313185
Validation loss: 2.857096964958583

Epoch: 5| Step: 2
Training loss: 0.46625193306570767
Validation loss: 2.8548116976052325

Epoch: 5| Step: 3
Training loss: 0.5894201917909199
Validation loss: 2.861209784481084

Epoch: 5| Step: 4
Training loss: 0.35823629177883665
Validation loss: 2.880595949704761

Epoch: 5| Step: 5
Training loss: 0.3834856692947712
Validation loss: 2.8622320489810575

Epoch: 5| Step: 6
Training loss: 0.5705367914484313
Validation loss: 2.870942542144798

Epoch: 5| Step: 7
Training loss: 0.40025792597846016
Validation loss: 2.8782473344514674

Epoch: 5| Step: 8
Training loss: 0.9179255373908967
Validation loss: 2.878050982047802

Epoch: 5| Step: 9
Training loss: 0.386236545211119
Validation loss: 2.857877288704096

Epoch: 5| Step: 10
Training loss: 0.3547795499762417
Validation loss: 2.829074134820995

Epoch: 5| Step: 11
Training loss: 0.4180884858226339
Validation loss: 2.81073644236018

Epoch: 352| Step: 0
Training loss: 0.4860584629779503
Validation loss: 2.8808235709341563

Epoch: 5| Step: 1
Training loss: 0.49036440701581957
Validation loss: 2.793943132926111

Epoch: 5| Step: 2
Training loss: 0.9803636350176037
Validation loss: 2.8661449834198582

Epoch: 5| Step: 3
Training loss: 0.2783044375526731
Validation loss: 2.8565466638391865

Epoch: 5| Step: 4
Training loss: 0.34221241350798143
Validation loss: 2.8296533954319782

Epoch: 5| Step: 5
Training loss: 0.40420372668506155
Validation loss: 2.9050702055470543

Epoch: 5| Step: 6
Training loss: 0.4556743007512022
Validation loss: 2.852082603088538

Epoch: 5| Step: 7
Training loss: 0.6500067050294573
Validation loss: 2.967796644425733

Epoch: 5| Step: 8
Training loss: 0.34517706161138095
Validation loss: 2.9202882194564195

Epoch: 5| Step: 9
Training loss: 0.492841498006187
Validation loss: 2.841726264207461

Epoch: 5| Step: 10
Training loss: 0.47761110725753864
Validation loss: 2.7916375747037843

Epoch: 5| Step: 11
Training loss: 0.4300481843011245
Validation loss: 2.816607841511329

Epoch: 353| Step: 0
Training loss: 0.5935687993271573
Validation loss: 2.856160147580153

Epoch: 5| Step: 1
Training loss: 0.4225529063128342
Validation loss: 2.8596502772610566

Epoch: 5| Step: 2
Training loss: 0.5222361713968942
Validation loss: 2.874701750530235

Epoch: 5| Step: 3
Training loss: 0.3104598445219857
Validation loss: 2.865676627323254

Epoch: 5| Step: 4
Training loss: 0.9949129473402116
Validation loss: 2.9336606325804024

Epoch: 5| Step: 5
Training loss: 0.45332113493549336
Validation loss: 2.877482427493123

Epoch: 5| Step: 6
Training loss: 0.3740426997311816
Validation loss: 2.8665094916555116

Epoch: 5| Step: 7
Training loss: 0.44457880446258385
Validation loss: 2.7943917088644343

Epoch: 5| Step: 8
Training loss: 0.35202575467659125
Validation loss: 2.7224535946471375

Epoch: 5| Step: 9
Training loss: 0.48476050018380434
Validation loss: 2.7987907071750247

Epoch: 5| Step: 10
Training loss: 0.3404695514881352
Validation loss: 2.843274813903634

Epoch: 5| Step: 11
Training loss: 0.17039798485428775
Validation loss: 2.7963109788539593

Epoch: 354| Step: 0
Training loss: 0.3666997673345493
Validation loss: 2.8529221816046997

Epoch: 5| Step: 1
Training loss: 0.9440517056961454
Validation loss: 2.840185327639366

Epoch: 5| Step: 2
Training loss: 0.3236510695819752
Validation loss: 2.8435529039710405

Epoch: 5| Step: 3
Training loss: 0.42138655962007243
Validation loss: 2.768150139461446

Epoch: 5| Step: 4
Training loss: 0.3571462767301064
Validation loss: 2.822279704585699

Epoch: 5| Step: 5
Training loss: 0.34320638761439304
Validation loss: 2.811002898007689

Epoch: 5| Step: 6
Training loss: 0.38530644782542567
Validation loss: 2.8054338487553814

Epoch: 5| Step: 7
Training loss: 0.3941558902986537
Validation loss: 2.8688963112403503

Epoch: 5| Step: 8
Training loss: 0.3550209746410398
Validation loss: 2.776941891841265

Epoch: 5| Step: 9
Training loss: 0.38630943600276235
Validation loss: 2.869397367654603

Epoch: 5| Step: 10
Training loss: 0.37044737890569723
Validation loss: 2.91081588403703

Epoch: 5| Step: 11
Training loss: 0.4853849034975279
Validation loss: 2.796692591851263

Epoch: 355| Step: 0
Training loss: 0.33971179943678514
Validation loss: 2.824975671635301

Epoch: 5| Step: 1
Training loss: 1.005138190528405
Validation loss: 2.807358418356965

Epoch: 5| Step: 2
Training loss: 0.4024749097645215
Validation loss: 2.7488249667013407

Epoch: 5| Step: 3
Training loss: 0.40993989960447536
Validation loss: 2.8149608724979207

Epoch: 5| Step: 4
Training loss: 0.41405800151180694
Validation loss: 2.828540321891671

Epoch: 5| Step: 5
Training loss: 0.4321507852478996
Validation loss: 2.9162118193776854

Epoch: 5| Step: 6
Training loss: 0.33135434882310794
Validation loss: 2.8127617396315747

Epoch: 5| Step: 7
Training loss: 0.4118491340931909
Validation loss: 2.851512654186739

Epoch: 5| Step: 8
Training loss: 0.3672387716330982
Validation loss: 2.8377192901257158

Epoch: 5| Step: 9
Training loss: 0.33517336990629837
Validation loss: 2.8407709671023795

Epoch: 5| Step: 10
Training loss: 0.46277372276340506
Validation loss: 2.805338398840526

Epoch: 5| Step: 11
Training loss: 0.4072723728823204
Validation loss: 2.8288028845996824

Epoch: 356| Step: 0
Training loss: 0.3070202924991067
Validation loss: 2.8459971809880353

Epoch: 5| Step: 1
Training loss: 0.5278533169021308
Validation loss: 2.969823024311695

Epoch: 5| Step: 2
Training loss: 0.3610644641523669
Validation loss: 2.9756008123199846

Epoch: 5| Step: 3
Training loss: 0.5115309217676721
Validation loss: 2.9368986907629093

Epoch: 5| Step: 4
Training loss: 0.9394388495171555
Validation loss: 2.916726017529756

Epoch: 5| Step: 5
Training loss: 0.4194607531599416
Validation loss: 2.8282136920770076

Epoch: 5| Step: 6
Training loss: 0.3501907714276997
Validation loss: 2.877079191119734

Epoch: 5| Step: 7
Training loss: 0.3138204571843903
Validation loss: 2.7964444495040732

Epoch: 5| Step: 8
Training loss: 0.4354356700759661
Validation loss: 2.9027943866706827

Epoch: 5| Step: 9
Training loss: 0.3830437837367437
Validation loss: 2.7838570273907735

Epoch: 5| Step: 10
Training loss: 0.4525871537774928
Validation loss: 2.884691213768562

Epoch: 5| Step: 11
Training loss: 0.5717655379382042
Validation loss: 2.8391059816173287

Epoch: 357| Step: 0
Training loss: 0.4551853823022634
Validation loss: 2.9249396070674107

Epoch: 5| Step: 1
Training loss: 0.3442790879757077
Validation loss: 2.9468638974436043

Epoch: 5| Step: 2
Training loss: 0.4062797462136852
Validation loss: 2.8835683071351044

Epoch: 5| Step: 3
Training loss: 0.6280244129926952
Validation loss: 2.8376097009545864

Epoch: 5| Step: 4
Training loss: 0.34052900309003875
Validation loss: 2.8915618134506063

Epoch: 5| Step: 5
Training loss: 0.3634824708256492
Validation loss: 2.900437517568415

Epoch: 5| Step: 6
Training loss: 0.5056087801091702
Validation loss: 2.8871783870087047

Epoch: 5| Step: 7
Training loss: 0.3780874864239302
Validation loss: 2.992990324652426

Epoch: 5| Step: 8
Training loss: 0.5028420677524378
Validation loss: 2.8428897709370724

Epoch: 5| Step: 9
Training loss: 0.4693847649900769
Validation loss: 2.868829352362472

Epoch: 5| Step: 10
Training loss: 0.9592938516200881
Validation loss: 2.790721449799613

Epoch: 5| Step: 11
Training loss: 0.46267440832410134
Validation loss: 2.796953413306325

Epoch: 358| Step: 0
Training loss: 0.40138755059853287
Validation loss: 2.8536898233209893

Epoch: 5| Step: 1
Training loss: 0.4115257288466629
Validation loss: 2.9349209305717747

Epoch: 5| Step: 2
Training loss: 0.620747643729388
Validation loss: 2.918878296939705

Epoch: 5| Step: 3
Training loss: 0.4664574510339682
Validation loss: 2.9066582704034185

Epoch: 5| Step: 4
Training loss: 0.568613893341321
Validation loss: 2.939444709841827

Epoch: 5| Step: 5
Training loss: 0.3955698600418233
Validation loss: 2.8263550378041264

Epoch: 5| Step: 6
Training loss: 0.9903273679869685
Validation loss: 2.775883658792839

Epoch: 5| Step: 7
Training loss: 0.3721707226089054
Validation loss: 2.72734660084092

Epoch: 5| Step: 8
Training loss: 0.5429907595338225
Validation loss: 2.7911360767837237

Epoch: 5| Step: 9
Training loss: 0.3101708757041302
Validation loss: 2.808543201711444

Epoch: 5| Step: 10
Training loss: 0.35128349253123037
Validation loss: 2.8436722552672697

Epoch: 5| Step: 11
Training loss: 0.27035243946556586
Validation loss: 2.8367936634596282

Epoch: 359| Step: 0
Training loss: 0.40402559033635105
Validation loss: 2.9126757269961634

Epoch: 5| Step: 1
Training loss: 0.39209881269902225
Validation loss: 2.838598003470006

Epoch: 5| Step: 2
Training loss: 0.3865705649321761
Validation loss: 2.895695728810754

Epoch: 5| Step: 3
Training loss: 0.9071198596764024
Validation loss: 2.828694716478181

Epoch: 5| Step: 4
Training loss: 0.28590703134850054
Validation loss: 2.833562152168561

Epoch: 5| Step: 5
Training loss: 0.3813555493191236
Validation loss: 2.8091014656054605

Epoch: 5| Step: 6
Training loss: 0.40394411038717043
Validation loss: 2.8507411488062724

Epoch: 5| Step: 7
Training loss: 0.4883817035340931
Validation loss: 2.851512695992371

Epoch: 5| Step: 8
Training loss: 0.2713416293732545
Validation loss: 2.8307241400586616

Epoch: 5| Step: 9
Training loss: 0.40053764063274305
Validation loss: 2.825753986683087

Epoch: 5| Step: 10
Training loss: 0.4964304554830988
Validation loss: 2.761900871059577

Epoch: 5| Step: 11
Training loss: 0.8085539803422835
Validation loss: 2.8498577021048432

Epoch: 360| Step: 0
Training loss: 0.39161653561398674
Validation loss: 2.8227812017803635

Epoch: 5| Step: 1
Training loss: 0.8836944023568014
Validation loss: 2.835104841976999

Epoch: 5| Step: 2
Training loss: 0.3862186820718999
Validation loss: 2.8495878445825307

Epoch: 5| Step: 3
Training loss: 0.2527832137357088
Validation loss: 2.8558467192141794

Epoch: 5| Step: 4
Training loss: 0.3047725729894736
Validation loss: 2.930956583445967

Epoch: 5| Step: 5
Training loss: 0.43856689949867866
Validation loss: 2.8524155303245653

Epoch: 5| Step: 6
Training loss: 0.3850912275230942
Validation loss: 2.8368743876201417

Epoch: 5| Step: 7
Training loss: 0.319561962899425
Validation loss: 2.8607931251007863

Epoch: 5| Step: 8
Training loss: 0.4243069593916564
Validation loss: 2.847929129937189

Epoch: 5| Step: 9
Training loss: 0.4060273477323791
Validation loss: 2.808868882838444

Epoch: 5| Step: 10
Training loss: 0.38499498066788523
Validation loss: 2.826096293597176

Epoch: 5| Step: 11
Training loss: 0.5448726782245006
Validation loss: 2.7879877414992578

Epoch: 361| Step: 0
Training loss: 0.42371240257754755
Validation loss: 2.889631867132949

Epoch: 5| Step: 1
Training loss: 0.3955992416385174
Validation loss: 2.925695323828262

Epoch: 5| Step: 2
Training loss: 0.6601466341841981
Validation loss: 2.97312264912873

Epoch: 5| Step: 3
Training loss: 0.9411289550641397
Validation loss: 2.897168964091744

Epoch: 5| Step: 4
Training loss: 0.3638706348397171
Validation loss: 2.847515561466269

Epoch: 5| Step: 5
Training loss: 0.5605399633107748
Validation loss: 2.8172296950737796

Epoch: 5| Step: 6
Training loss: 0.5047103026349635
Validation loss: 2.863556685997485

Epoch: 5| Step: 7
Training loss: 0.7259555044909657
Validation loss: 2.7778382145082

Epoch: 5| Step: 8
Training loss: 0.25530033334717017
Validation loss: 2.7792859125267393

Epoch: 5| Step: 9
Training loss: 0.4610937306356604
Validation loss: 2.833132566089459

Epoch: 5| Step: 10
Training loss: 0.48792719402352563
Validation loss: 2.907488757188555

Epoch: 5| Step: 11
Training loss: 0.31253831151722583
Validation loss: 2.8859286536890254

Epoch: 362| Step: 0
Training loss: 0.44169914183193215
Validation loss: 2.904868224706737

Epoch: 5| Step: 1
Training loss: 0.3527919042233635
Validation loss: 2.781685684311275

Epoch: 5| Step: 2
Training loss: 0.42560549266997705
Validation loss: 2.84544787880023

Epoch: 5| Step: 3
Training loss: 0.4463475061792869
Validation loss: 2.840096428783254

Epoch: 5| Step: 4
Training loss: 0.23809265271199465
Validation loss: 2.7836509085600394

Epoch: 5| Step: 5
Training loss: 0.862448242956567
Validation loss: 2.7812277582257914

Epoch: 5| Step: 6
Training loss: 0.32414238961218256
Validation loss: 2.811794114717013

Epoch: 5| Step: 7
Training loss: 0.5738024078069982
Validation loss: 2.8483745120881188

Epoch: 5| Step: 8
Training loss: 0.3010905026001897
Validation loss: 2.8027365406484357

Epoch: 5| Step: 9
Training loss: 0.37338604911799944
Validation loss: 2.7884011432825946

Epoch: 5| Step: 10
Training loss: 0.38843281740786517
Validation loss: 2.8372101375924474

Epoch: 5| Step: 11
Training loss: 0.5283328916846675
Validation loss: 2.8593645182488663

Epoch: 363| Step: 0
Training loss: 0.370884163548194
Validation loss: 2.7599088789576425

Epoch: 5| Step: 1
Training loss: 0.37838028258664713
Validation loss: 2.8388762979675106

Epoch: 5| Step: 2
Training loss: 0.9337440593178142
Validation loss: 2.8221863133815153

Epoch: 5| Step: 3
Training loss: 0.42386873112247075
Validation loss: 2.8676660330678323

Epoch: 5| Step: 4
Training loss: 0.35420829397417536
Validation loss: 2.8922911816544623

Epoch: 5| Step: 5
Training loss: 0.38119513554641565
Validation loss: 2.8911728314047584

Epoch: 5| Step: 6
Training loss: 0.40468856708282824
Validation loss: 2.8165243179609627

Epoch: 5| Step: 7
Training loss: 0.5320378800257723
Validation loss: 2.825887571286993

Epoch: 5| Step: 8
Training loss: 0.3767610762372204
Validation loss: 2.8496335268032085

Epoch: 5| Step: 9
Training loss: 0.3478022279619212
Validation loss: 2.8788959704853525

Epoch: 5| Step: 10
Training loss: 0.3626183645436215
Validation loss: 2.8061635481977625

Epoch: 5| Step: 11
Training loss: 0.3472551754043311
Validation loss: 2.802349862583975

Epoch: 364| Step: 0
Training loss: 0.900390095410636
Validation loss: 2.7729125157322088

Epoch: 5| Step: 1
Training loss: 0.4237823109981638
Validation loss: 2.8238427249082303

Epoch: 5| Step: 2
Training loss: 0.4224156694501428
Validation loss: 2.90565538647176

Epoch: 5| Step: 3
Training loss: 0.4116643337648264
Validation loss: 2.9080329505349214

Epoch: 5| Step: 4
Training loss: 0.5278002705577317
Validation loss: 2.8809999489835545

Epoch: 5| Step: 5
Training loss: 0.4121941574172174
Validation loss: 2.8352570045713628

Epoch: 5| Step: 6
Training loss: 0.3442259549578651
Validation loss: 2.8208803501652864

Epoch: 5| Step: 7
Training loss: 0.32273292184732033
Validation loss: 2.7495286927794185

Epoch: 5| Step: 8
Training loss: 0.4483344620946882
Validation loss: 2.848291634071547

Epoch: 5| Step: 9
Training loss: 0.48412139467807225
Validation loss: 2.8178068744306706

Epoch: 5| Step: 10
Training loss: 0.42321779104210194
Validation loss: 2.8185573939221285

Epoch: 5| Step: 11
Training loss: 0.8072749269452185
Validation loss: 2.8959377267714697

Epoch: 365| Step: 0
Training loss: 0.42132191253614637
Validation loss: 2.8501579866901907

Epoch: 5| Step: 1
Training loss: 0.37872526427973713
Validation loss: 2.7314126562049186

Epoch: 5| Step: 2
Training loss: 0.5518036949862893
Validation loss: 2.8040782546568654

Epoch: 5| Step: 3
Training loss: 0.4935073866102955
Validation loss: 2.8034275628781495

Epoch: 5| Step: 4
Training loss: 0.4109586586962363
Validation loss: 2.808992575959412

Epoch: 5| Step: 5
Training loss: 0.4773044438887937
Validation loss: 2.772104281347234

Epoch: 5| Step: 6
Training loss: 0.45892109536150877
Validation loss: 2.914952678241785

Epoch: 5| Step: 7
Training loss: 0.9327087676935049
Validation loss: 2.883321756732905

Epoch: 5| Step: 8
Training loss: 0.42462277079826094
Validation loss: 2.906952004094528

Epoch: 5| Step: 9
Training loss: 0.4390185093138521
Validation loss: 2.862047794526987

Epoch: 5| Step: 10
Training loss: 0.31771197343002144
Validation loss: 2.8205775790627556

Epoch: 5| Step: 11
Training loss: 0.6514873937044426
Validation loss: 2.793103290865294

Epoch: 366| Step: 0
Training loss: 0.5687792822876782
Validation loss: 2.837285956881585

Epoch: 5| Step: 1
Training loss: 0.7338619469112216
Validation loss: 2.79088147114377

Epoch: 5| Step: 2
Training loss: 0.6013702233917132
Validation loss: 2.7545510585530764

Epoch: 5| Step: 3
Training loss: 0.37160913917422705
Validation loss: 2.815595163489972

Epoch: 5| Step: 4
Training loss: 0.3802399709245477
Validation loss: 2.80265443269184

Epoch: 5| Step: 5
Training loss: 0.37550963104229923
Validation loss: 2.860161938801005

Epoch: 5| Step: 6
Training loss: 0.6299720878321525
Validation loss: 2.918581964964009

Epoch: 5| Step: 7
Training loss: 0.49802576656115005
Validation loss: 2.9450683357630685

Epoch: 5| Step: 8
Training loss: 1.0267027969525864
Validation loss: 2.847011456532502

Epoch: 5| Step: 9
Training loss: 0.4437358283076835
Validation loss: 2.8687959121598294

Epoch: 5| Step: 10
Training loss: 0.3985324447304038
Validation loss: 2.781406237467923

Epoch: 5| Step: 11
Training loss: 0.2692422007986965
Validation loss: 2.826000972098129

Epoch: 367| Step: 0
Training loss: 0.511447572562558
Validation loss: 2.832690293372299

Epoch: 5| Step: 1
Training loss: 0.5489391879724963
Validation loss: 2.782438381491891

Epoch: 5| Step: 2
Training loss: 0.5156122841856557
Validation loss: 2.832100787131213

Epoch: 5| Step: 3
Training loss: 0.8546480396373916
Validation loss: 2.860244962581963

Epoch: 5| Step: 4
Training loss: 0.46159642207884566
Validation loss: 2.92979119350456

Epoch: 5| Step: 5
Training loss: 0.4741437221041901
Validation loss: 2.978708199701195

Epoch: 5| Step: 6
Training loss: 0.6121878626590139
Validation loss: 2.8712741059899636

Epoch: 5| Step: 7
Training loss: 0.43813534992416703
Validation loss: 2.8796210952142594

Epoch: 5| Step: 8
Training loss: 0.4664283798309597
Validation loss: 2.9086582194111728

Epoch: 5| Step: 9
Training loss: 0.44556861338793846
Validation loss: 2.7969659119220998

Epoch: 5| Step: 10
Training loss: 0.43019784617476736
Validation loss: 2.8122305811656014

Epoch: 5| Step: 11
Training loss: 0.4808928006266093
Validation loss: 2.9256395102759547

Epoch: 368| Step: 0
Training loss: 0.4215607002168981
Validation loss: 2.825609887238861

Epoch: 5| Step: 1
Training loss: 0.37208462985468943
Validation loss: 2.8214629583924813

Epoch: 5| Step: 2
Training loss: 0.847274413003893
Validation loss: 2.842843770684095

Epoch: 5| Step: 3
Training loss: 0.6154160972942111
Validation loss: 2.907586590222897

Epoch: 5| Step: 4
Training loss: 0.4221499218371485
Validation loss: 2.84974665198916

Epoch: 5| Step: 5
Training loss: 0.45236769235658325
Validation loss: 2.8845431845342855

Epoch: 5| Step: 6
Training loss: 0.3021402497220928
Validation loss: 2.803847120612319

Epoch: 5| Step: 7
Training loss: 0.3723579756516093
Validation loss: 2.672986823568847

Epoch: 5| Step: 8
Training loss: 0.40027600019998416
Validation loss: 2.7714294901299956

Epoch: 5| Step: 9
Training loss: 0.41926240813831295
Validation loss: 2.755426990699857

Epoch: 5| Step: 10
Training loss: 0.38436208176032916
Validation loss: 2.8309006848116915

Epoch: 5| Step: 11
Training loss: 0.2904477178624483
Validation loss: 2.7911856768346377

Epoch: 369| Step: 0
Training loss: 0.864628426781482
Validation loss: 2.755168583997243

Epoch: 5| Step: 1
Training loss: 0.45090070229359525
Validation loss: 2.805432411099432

Epoch: 5| Step: 2
Training loss: 0.3410151998335907
Validation loss: 2.9038078274321477

Epoch: 5| Step: 3
Training loss: 0.46530580396682725
Validation loss: 2.8767714882266873

Epoch: 5| Step: 4
Training loss: 0.31155077297137457
Validation loss: 2.830074842971924

Epoch: 5| Step: 5
Training loss: 0.38496163502189196
Validation loss: 2.7475719570216612

Epoch: 5| Step: 6
Training loss: 0.3644403199852347
Validation loss: 2.843130241532329

Epoch: 5| Step: 7
Training loss: 0.4040355113988859
Validation loss: 2.73484826488217

Epoch: 5| Step: 8
Training loss: 0.23798944240532557
Validation loss: 2.7942227693934947

Epoch: 5| Step: 9
Training loss: 0.4284144703791998
Validation loss: 2.7766925354123106

Epoch: 5| Step: 10
Training loss: 0.36045190918155273
Validation loss: 2.828869786554698

Epoch: 5| Step: 11
Training loss: 0.5865269811055098
Validation loss: 2.8169193444162315

Epoch: 370| Step: 0
Training loss: 0.4270605065673145
Validation loss: 2.8958443405893557

Epoch: 5| Step: 1
Training loss: 0.36730447894314294
Validation loss: 2.788950404061417

Epoch: 5| Step: 2
Training loss: 0.511811954076422
Validation loss: 2.81785432339811

Epoch: 5| Step: 3
Training loss: 0.3808415726633638
Validation loss: 2.836234011531467

Epoch: 5| Step: 4
Training loss: 0.40294452368104366
Validation loss: 2.8483209867602306

Epoch: 5| Step: 5
Training loss: 0.46455890679685885
Validation loss: 2.882354169213162

Epoch: 5| Step: 6
Training loss: 0.4301140835149151
Validation loss: 2.793806132805909

Epoch: 5| Step: 7
Training loss: 0.8988265149012157
Validation loss: 2.880660941838514

Epoch: 5| Step: 8
Training loss: 0.35770930005525936
Validation loss: 2.853660522374859

Epoch: 5| Step: 9
Training loss: 0.39905780302553084
Validation loss: 2.91089473630843

Epoch: 5| Step: 10
Training loss: 0.3292082209050783
Validation loss: 2.8027800623839583

Epoch: 5| Step: 11
Training loss: 0.2831405570532887
Validation loss: 2.817241137560456

Epoch: 371| Step: 0
Training loss: 0.4660549252766607
Validation loss: 2.726411188585231

Epoch: 5| Step: 1
Training loss: 0.46955205328582483
Validation loss: 2.858760872016653

Epoch: 5| Step: 2
Training loss: 0.34691418520943834
Validation loss: 2.85512931048207

Epoch: 5| Step: 3
Training loss: 0.41123484525614157
Validation loss: 2.784323034004932

Epoch: 5| Step: 4
Training loss: 0.22310225672706857
Validation loss: 2.848577007784137

Epoch: 5| Step: 5
Training loss: 0.3322010615820174
Validation loss: 2.8961400320167443

Epoch: 5| Step: 6
Training loss: 0.4234984561639815
Validation loss: 2.902008167305742

Epoch: 5| Step: 7
Training loss: 0.4249036301014953
Validation loss: 2.819035234701786

Epoch: 5| Step: 8
Training loss: 0.3035782281831357
Validation loss: 2.8388736087467064

Epoch: 5| Step: 9
Training loss: 0.855132955899176
Validation loss: 2.825405399173655

Epoch: 5| Step: 10
Training loss: 0.4462580763996918
Validation loss: 2.772672330942794

Epoch: 5| Step: 11
Training loss: 0.07299788101840873
Validation loss: 2.820842340916086

Epoch: 372| Step: 0
Training loss: 0.4390442196173018
Validation loss: 2.837109812966219

Epoch: 5| Step: 1
Training loss: 0.4549694504542828
Validation loss: 2.912085519612348

Epoch: 5| Step: 2
Training loss: 0.4063007799836788
Validation loss: 2.881196617602857

Epoch: 5| Step: 3
Training loss: 0.39019471311585235
Validation loss: 2.800153292138246

Epoch: 5| Step: 4
Training loss: 0.36783240884265145
Validation loss: 2.7477798205628723

Epoch: 5| Step: 5
Training loss: 0.3500205557611131
Validation loss: 2.915984950550492

Epoch: 5| Step: 6
Training loss: 0.9353383893152549
Validation loss: 2.8519512259931536

Epoch: 5| Step: 7
Training loss: 0.3407290754645628
Validation loss: 2.7382302816874406

Epoch: 5| Step: 8
Training loss: 0.41700483745174993
Validation loss: 2.844990148968617

Epoch: 5| Step: 9
Training loss: 0.43577973166851286
Validation loss: 2.8766136789267236

Epoch: 5| Step: 10
Training loss: 0.31910293431243425
Validation loss: 2.847929806645257

Epoch: 5| Step: 11
Training loss: 0.336675288411413
Validation loss: 2.8925023761235056

Epoch: 373| Step: 0
Training loss: 0.270849817336783
Validation loss: 2.825873161651337

Epoch: 5| Step: 1
Training loss: 0.3589783843394664
Validation loss: 2.857260163416643

Epoch: 5| Step: 2
Training loss: 0.42744083870773164
Validation loss: 2.8392015489234903

Epoch: 5| Step: 3
Training loss: 0.433402096430774
Validation loss: 2.828837549077184

Epoch: 5| Step: 4
Training loss: 0.47057790396460636
Validation loss: 2.8709934658260523

Epoch: 5| Step: 5
Training loss: 0.31171030162175734
Validation loss: 2.819912541314967

Epoch: 5| Step: 6
Training loss: 0.23879865067045267
Validation loss: 2.7926520072400938

Epoch: 5| Step: 7
Training loss: 0.43522122101839966
Validation loss: 2.8838204617787273

Epoch: 5| Step: 8
Training loss: 0.906061021240358
Validation loss: 2.8638393175706818

Epoch: 5| Step: 9
Training loss: 0.3082272852528349
Validation loss: 2.9384054959477384

Epoch: 5| Step: 10
Training loss: 0.42793551379668127
Validation loss: 2.86092841401976

Epoch: 5| Step: 11
Training loss: 0.43850429251819734
Validation loss: 2.8996774912048635

Epoch: 374| Step: 0
Training loss: 0.4200443000647841
Validation loss: 2.8853434692261044

Epoch: 5| Step: 1
Training loss: 0.2952152460406582
Validation loss: 2.8441676926482935

Epoch: 5| Step: 2
Training loss: 0.46199475283243935
Validation loss: 2.8407922181451233

Epoch: 5| Step: 3
Training loss: 0.4812769876071778
Validation loss: 2.8429908682394416

Epoch: 5| Step: 4
Training loss: 0.4168371944356704
Validation loss: 2.869849979248974

Epoch: 5| Step: 5
Training loss: 0.7974501011822495
Validation loss: 2.815712686853415

Epoch: 5| Step: 6
Training loss: 0.32123310100325614
Validation loss: 2.888845363288034

Epoch: 5| Step: 7
Training loss: 0.47921884985127633
Validation loss: 2.9179794740288316

Epoch: 5| Step: 8
Training loss: 0.3914008446660915
Validation loss: 2.941880348772868

Epoch: 5| Step: 9
Training loss: 0.4147154859400456
Validation loss: 2.9331230873022016

Epoch: 5| Step: 10
Training loss: 0.28850641115558906
Validation loss: 2.806991668458911

Epoch: 5| Step: 11
Training loss: 0.4050806897044495
Validation loss: 2.7594875691465606

Epoch: 375| Step: 0
Training loss: 0.4320516916029785
Validation loss: 2.81134979252418

Epoch: 5| Step: 1
Training loss: 0.5735718073501789
Validation loss: 2.7754703432428713

Epoch: 5| Step: 2
Training loss: 0.6617442787047025
Validation loss: 2.723954685177132

Epoch: 5| Step: 3
Training loss: 0.45514824126531445
Validation loss: 2.816017303910789

Epoch: 5| Step: 4
Training loss: 0.3330979211332967
Validation loss: 2.831199429125646

Epoch: 5| Step: 5
Training loss: 0.6458637681578391
Validation loss: 2.939942173286409

Epoch: 5| Step: 6
Training loss: 0.9700479119059674
Validation loss: 2.9732995124694526

Epoch: 5| Step: 7
Training loss: 0.5688985777235164
Validation loss: 2.8752750458662035

Epoch: 5| Step: 8
Training loss: 0.2880048476066179
Validation loss: 2.8385144025327356

Epoch: 5| Step: 9
Training loss: 0.4252221697839897
Validation loss: 2.8500977887002246

Epoch: 5| Step: 10
Training loss: 0.5424403356888307
Validation loss: 2.7925557220167954

Epoch: 5| Step: 11
Training loss: 0.5268274959177253
Validation loss: 2.811742376786655

Epoch: 376| Step: 0
Training loss: 0.9692834800347492
Validation loss: 2.7584165176418143

Epoch: 5| Step: 1
Training loss: 0.3631360779154195
Validation loss: 2.773672260503267

Epoch: 5| Step: 2
Training loss: 0.4091570354009234
Validation loss: 2.8702394836475014

Epoch: 5| Step: 3
Training loss: 0.5141430568478151
Validation loss: 2.945227570325328

Epoch: 5| Step: 4
Training loss: 0.5092314336460676
Validation loss: 2.8649224803028233

Epoch: 5| Step: 5
Training loss: 0.46227229544356085
Validation loss: 2.8355454768553887

Epoch: 5| Step: 6
Training loss: 0.44401939770815735
Validation loss: 2.7391832057065564

Epoch: 5| Step: 7
Training loss: 0.43797208656131564
Validation loss: 2.773547486466016

Epoch: 5| Step: 8
Training loss: 0.5542519699736168
Validation loss: 2.693802275006603

Epoch: 5| Step: 9
Training loss: 0.4884669141644003
Validation loss: 2.770982291345489

Epoch: 5| Step: 10
Training loss: 0.40847882173425426
Validation loss: 2.7229667862295344

Epoch: 5| Step: 11
Training loss: 0.21144910864291477
Validation loss: 2.8063555426457523

Epoch: 377| Step: 0
Training loss: 0.47991932104003393
Validation loss: 2.938470122259606

Epoch: 5| Step: 1
Training loss: 0.5926949010666679
Validation loss: 2.9667297750807844

Epoch: 5| Step: 2
Training loss: 0.4396687804997473
Validation loss: 2.7900031183936354

Epoch: 5| Step: 3
Training loss: 0.36274195193006414
Validation loss: 2.8628171585434306

Epoch: 5| Step: 4
Training loss: 0.41118032584112096
Validation loss: 2.888805455955206

Epoch: 5| Step: 5
Training loss: 0.9212051156029923
Validation loss: 2.7841357572549223

Epoch: 5| Step: 6
Training loss: 0.36792133941073557
Validation loss: 2.8064958308952552

Epoch: 5| Step: 7
Training loss: 0.2779126846356101
Validation loss: 2.8397847781208445

Epoch: 5| Step: 8
Training loss: 0.3960733773373857
Validation loss: 2.8498300314854257

Epoch: 5| Step: 9
Training loss: 0.3026544034603194
Validation loss: 2.814435363614656

Epoch: 5| Step: 10
Training loss: 0.39239790086612497
Validation loss: 2.859727309710701

Epoch: 5| Step: 11
Training loss: 0.2563940387726157
Validation loss: 2.835229314088796

Epoch: 378| Step: 0
Training loss: 0.4654163392298317
Validation loss: 2.8589810515188674

Epoch: 5| Step: 1
Training loss: 0.46107303113934306
Validation loss: 2.785215864930099

Epoch: 5| Step: 2
Training loss: 0.2935018394142882
Validation loss: 2.8091610727694873

Epoch: 5| Step: 3
Training loss: 0.5542943125068086
Validation loss: 2.8855126476276163

Epoch: 5| Step: 4
Training loss: 0.3260486278562684
Validation loss: 2.7767995237650456

Epoch: 5| Step: 5
Training loss: 0.37910782476222277
Validation loss: 2.7704330217308315

Epoch: 5| Step: 6
Training loss: 0.33823989721127035
Validation loss: 2.7606562216595756

Epoch: 5| Step: 7
Training loss: 0.3088279390804967
Validation loss: 2.8019102154164623

Epoch: 5| Step: 8
Training loss: 0.2719476027395147
Validation loss: 2.7524718857627812

Epoch: 5| Step: 9
Training loss: 0.3957299256357237
Validation loss: 2.8296419750520685

Epoch: 5| Step: 10
Training loss: 0.90608055898475
Validation loss: 2.7892324215998743

Epoch: 5| Step: 11
Training loss: 0.1288190749201083
Validation loss: 2.853371681170339

Epoch: 379| Step: 0
Training loss: 0.36342925471549437
Validation loss: 2.873437764546512

Epoch: 5| Step: 1
Training loss: 0.883769268003898
Validation loss: 2.9066835066452623

Epoch: 5| Step: 2
Training loss: 0.35342661121570773
Validation loss: 2.8219398671323668

Epoch: 5| Step: 3
Training loss: 0.4648500650441741
Validation loss: 2.816885376138016

Epoch: 5| Step: 4
Training loss: 0.33921191795072303
Validation loss: 2.8927943775391904

Epoch: 5| Step: 5
Training loss: 0.4710529974016554
Validation loss: 2.81834605833535

Epoch: 5| Step: 6
Training loss: 0.317328909184633
Validation loss: 2.857770024660596

Epoch: 5| Step: 7
Training loss: 0.30157377439384414
Validation loss: 2.9274943471572206

Epoch: 5| Step: 8
Training loss: 0.3896805025832233
Validation loss: 2.8308025000840153

Epoch: 5| Step: 9
Training loss: 0.36170986733127597
Validation loss: 2.883591595744256

Epoch: 5| Step: 10
Training loss: 0.356851821487426
Validation loss: 2.894747490469727

Epoch: 5| Step: 11
Training loss: 0.2805536311713611
Validation loss: 2.8022502024619844

Epoch: 380| Step: 0
Training loss: 0.3236271850244011
Validation loss: 2.7715620514350356

Epoch: 5| Step: 1
Training loss: 0.37634645572213316
Validation loss: 2.823835467390009

Epoch: 5| Step: 2
Training loss: 0.5517074697027896
Validation loss: 2.8100081531229897

Epoch: 5| Step: 3
Training loss: 0.9205750821028317
Validation loss: 2.8856283149262296

Epoch: 5| Step: 4
Training loss: 0.3545752814141105
Validation loss: 2.802533114802248

Epoch: 5| Step: 5
Training loss: 0.3294362027962883
Validation loss: 2.9045666704222954

Epoch: 5| Step: 6
Training loss: 0.33168601993584945
Validation loss: 2.9548018335377604

Epoch: 5| Step: 7
Training loss: 0.2964227393696077
Validation loss: 2.9024422048279246

Epoch: 5| Step: 8
Training loss: 0.44672521068148113
Validation loss: 2.918012149731462

Epoch: 5| Step: 9
Training loss: 0.38652106733014696
Validation loss: 2.909579656431921

Epoch: 5| Step: 10
Training loss: 0.4453952444733944
Validation loss: 2.910533182537491

Epoch: 5| Step: 11
Training loss: 0.4543354047605369
Validation loss: 2.807143238699224

Epoch: 381| Step: 0
Training loss: 0.476311289130157
Validation loss: 2.841232240215514

Epoch: 5| Step: 1
Training loss: 0.3103402848112197
Validation loss: 2.821536165892559

Epoch: 5| Step: 2
Training loss: 0.4371136594397026
Validation loss: 2.9203985839369553

Epoch: 5| Step: 3
Training loss: 0.2823716552953387
Validation loss: 2.8887171626759107

Epoch: 5| Step: 4
Training loss: 0.8339945951099123
Validation loss: 2.9386507309979457

Epoch: 5| Step: 5
Training loss: 0.41190430659918137
Validation loss: 2.816223247929846

Epoch: 5| Step: 6
Training loss: 0.31700849320739816
Validation loss: 2.8729040428909642

Epoch: 5| Step: 7
Training loss: 0.3460368253854198
Validation loss: 2.8835946101584677

Epoch: 5| Step: 8
Training loss: 0.5543993349120869
Validation loss: 2.841780175927946

Epoch: 5| Step: 9
Training loss: 0.3414030258235971
Validation loss: 2.826690042829422

Epoch: 5| Step: 10
Training loss: 0.4588278158489831
Validation loss: 2.856810084687354

Epoch: 5| Step: 11
Training loss: 0.7020152553261991
Validation loss: 2.9493295745574164

Epoch: 382| Step: 0
Training loss: 0.3782270183553
Validation loss: 2.901474399355543

Epoch: 5| Step: 1
Training loss: 0.3045087559017408
Validation loss: 2.8548484994872703

Epoch: 5| Step: 2
Training loss: 0.394564183437479
Validation loss: 2.8117457932718066

Epoch: 5| Step: 3
Training loss: 0.49723729174999487
Validation loss: 2.876186557911729

Epoch: 5| Step: 4
Training loss: 0.3909666474695684
Validation loss: 2.8532989579838093

Epoch: 5| Step: 5
Training loss: 0.32852772566818045
Validation loss: 2.847188847560715

Epoch: 5| Step: 6
Training loss: 0.8779664503978153
Validation loss: 2.899653677430839

Epoch: 5| Step: 7
Training loss: 0.3135406808848214
Validation loss: 2.9000761844230514

Epoch: 5| Step: 8
Training loss: 0.4195115146932173
Validation loss: 2.8691257643482504

Epoch: 5| Step: 9
Training loss: 0.5435539220927227
Validation loss: 2.8998487520787104

Epoch: 5| Step: 10
Training loss: 0.35646107259946747
Validation loss: 2.830250743781742

Epoch: 5| Step: 11
Training loss: 0.19699601359739316
Validation loss: 2.7850905094529295

Epoch: 383| Step: 0
Training loss: 0.5557538916948784
Validation loss: 2.7636366914951624

Epoch: 5| Step: 1
Training loss: 0.37834857919758186
Validation loss: 2.8276526722331443

Epoch: 5| Step: 2
Training loss: 0.3387852660434519
Validation loss: 2.8683740688111947

Epoch: 5| Step: 3
Training loss: 0.34519662768527926
Validation loss: 2.833513486735285

Epoch: 5| Step: 4
Training loss: 0.33285370110526596
Validation loss: 2.8237200481801463

Epoch: 5| Step: 5
Training loss: 0.34103392325791715
Validation loss: 2.9286591687555488

Epoch: 5| Step: 6
Training loss: 0.46592424940562654
Validation loss: 2.872673603413855

Epoch: 5| Step: 7
Training loss: 0.5081003986892382
Validation loss: 2.8652232767317916

Epoch: 5| Step: 8
Training loss: 0.31721245521881514
Validation loss: 2.8244161154347354

Epoch: 5| Step: 9
Training loss: 0.8562037824422883
Validation loss: 2.8649902586468987

Epoch: 5| Step: 10
Training loss: 0.36224858345718325
Validation loss: 2.895860405436335

Epoch: 5| Step: 11
Training loss: 0.33238157976186194
Validation loss: 2.7450269975822725

Epoch: 384| Step: 0
Training loss: 0.3470471006755689
Validation loss: 2.82224587826272

Epoch: 5| Step: 1
Training loss: 0.38332198746448504
Validation loss: 2.8392348163540566

Epoch: 5| Step: 2
Training loss: 0.8383835629671015
Validation loss: 2.823915538278307

Epoch: 5| Step: 3
Training loss: 0.2995778073387907
Validation loss: 2.8156178464809236

Epoch: 5| Step: 4
Training loss: 0.30850170066401833
Validation loss: 2.902630558620638

Epoch: 5| Step: 5
Training loss: 0.3933180862168262
Validation loss: 2.94763223109337

Epoch: 5| Step: 6
Training loss: 0.4798517064161885
Validation loss: 2.8587687462871902

Epoch: 5| Step: 7
Training loss: 0.3255003108866917
Validation loss: 2.8414230537774237

Epoch: 5| Step: 8
Training loss: 0.3618454606183551
Validation loss: 2.8251920142507787

Epoch: 5| Step: 9
Training loss: 0.4099075289862838
Validation loss: 2.731497102059374

Epoch: 5| Step: 10
Training loss: 0.5028791383691058
Validation loss: 2.834742151416993

Epoch: 5| Step: 11
Training loss: 0.43617892057893876
Validation loss: 2.8482727025429555

Epoch: 385| Step: 0
Training loss: 0.7989670462466892
Validation loss: 2.903797468437049

Epoch: 5| Step: 1
Training loss: 0.5594986741576111
Validation loss: 2.8964843338434547

Epoch: 5| Step: 2
Training loss: 0.5014584252114787
Validation loss: 2.9576517056358647

Epoch: 5| Step: 3
Training loss: 0.6149797185019203
Validation loss: 3.017443930266433

Epoch: 5| Step: 4
Training loss: 0.42185871657982754
Validation loss: 2.8609633628777638

Epoch: 5| Step: 5
Training loss: 0.3611607756859661
Validation loss: 2.8014379039261676

Epoch: 5| Step: 6
Training loss: 0.6644712424345212
Validation loss: 2.7677842312246717

Epoch: 5| Step: 7
Training loss: 0.6584809393329105
Validation loss: 2.8004283283647142

Epoch: 5| Step: 8
Training loss: 0.3587061836652977
Validation loss: 2.8347726291336746

Epoch: 5| Step: 9
Training loss: 0.3434673144005348
Validation loss: 2.8360246271878675

Epoch: 5| Step: 10
Training loss: 0.5879490718746961
Validation loss: 2.8940454985790587

Epoch: 5| Step: 11
Training loss: 0.36113919654266274
Validation loss: 3.009650463992937

Epoch: 386| Step: 0
Training loss: 0.5921136996298406
Validation loss: 2.9585261864104173

Epoch: 5| Step: 1
Training loss: 0.5914610107950699
Validation loss: 2.9087849913010038

Epoch: 5| Step: 2
Training loss: 0.3550478990571351
Validation loss: 2.8677571949443292

Epoch: 5| Step: 3
Training loss: 0.4435237294206352
Validation loss: 2.8023644179897276

Epoch: 5| Step: 4
Training loss: 0.486789591671549
Validation loss: 2.794466253002361

Epoch: 5| Step: 5
Training loss: 0.6222085843999517
Validation loss: 2.7493938876265873

Epoch: 5| Step: 6
Training loss: 0.4812719872641394
Validation loss: 2.7711779958478444

Epoch: 5| Step: 7
Training loss: 0.44291977788287606
Validation loss: 2.765217519364688

Epoch: 5| Step: 8
Training loss: 0.8611331641200164
Validation loss: 2.779365658439491

Epoch: 5| Step: 9
Training loss: 0.5201987660599813
Validation loss: 2.8479946163944554

Epoch: 5| Step: 10
Training loss: 0.3782528030747997
Validation loss: 2.8409417752495427

Epoch: 5| Step: 11
Training loss: 0.42628451011881474
Validation loss: 2.83041490052062

Epoch: 387| Step: 0
Training loss: 0.4395819072639993
Validation loss: 2.84785246903441

Epoch: 5| Step: 1
Training loss: 0.53034534282961
Validation loss: 2.7578410362373837

Epoch: 5| Step: 2
Training loss: 0.4006975625690158
Validation loss: 2.8164449399000464

Epoch: 5| Step: 3
Training loss: 0.3132584309056078
Validation loss: 2.7709509793500753

Epoch: 5| Step: 4
Training loss: 0.5231918783518469
Validation loss: 2.823212739449345

Epoch: 5| Step: 5
Training loss: 0.42597710190939564
Validation loss: 2.825588254812717

Epoch: 5| Step: 6
Training loss: 0.2858602768684917
Validation loss: 2.840197349198226

Epoch: 5| Step: 7
Training loss: 0.4611439646592619
Validation loss: 2.8216328158960904

Epoch: 5| Step: 8
Training loss: 0.34097502948557523
Validation loss: 2.8370250616720267

Epoch: 5| Step: 9
Training loss: 0.8246686168733428
Validation loss: 2.8710133201768895

Epoch: 5| Step: 10
Training loss: 0.28643696734191393
Validation loss: 2.770757829502655

Epoch: 5| Step: 11
Training loss: 0.5700021709434259
Validation loss: 2.8086167194415808

Epoch: 388| Step: 0
Training loss: 0.3524035037306564
Validation loss: 2.8020753003587884

Epoch: 5| Step: 1
Training loss: 0.41091688561316025
Validation loss: 2.705559371207504

Epoch: 5| Step: 2
Training loss: 0.37905393259000847
Validation loss: 2.8492888352484105

Epoch: 5| Step: 3
Training loss: 0.7601420982431406
Validation loss: 2.791307253024768

Epoch: 5| Step: 4
Training loss: 0.35115750615444447
Validation loss: 2.8840205513785833

Epoch: 5| Step: 5
Training loss: 0.5117482766521677
Validation loss: 2.85772302291783

Epoch: 5| Step: 6
Training loss: 0.537174040629642
Validation loss: 2.8532482790488176

Epoch: 5| Step: 7
Training loss: 0.3935095143482736
Validation loss: 2.803722498936446

Epoch: 5| Step: 8
Training loss: 0.3278687021099297
Validation loss: 2.7703405398552525

Epoch: 5| Step: 9
Training loss: 0.5514660359176036
Validation loss: 2.853942564127497

Epoch: 5| Step: 10
Training loss: 0.5550335892402011
Validation loss: 2.8082625291503467

Epoch: 5| Step: 11
Training loss: 0.4291242201964985
Validation loss: 2.746146554742176

Epoch: 389| Step: 0
Training loss: 0.5021855747492217
Validation loss: 2.8249584898247964

Epoch: 5| Step: 1
Training loss: 0.5113455015396233
Validation loss: 2.878408743574196

Epoch: 5| Step: 2
Training loss: 0.4976848857551811
Validation loss: 2.8506910133315353

Epoch: 5| Step: 3
Training loss: 0.3925524461233433
Validation loss: 2.875673501972936

Epoch: 5| Step: 4
Training loss: 0.6422755215876172
Validation loss: 2.875937015453683

Epoch: 5| Step: 5
Training loss: 0.822273816138128
Validation loss: 2.860579874328557

Epoch: 5| Step: 6
Training loss: 0.36447681051566405
Validation loss: 2.8148531853338334

Epoch: 5| Step: 7
Training loss: 0.528452632784378
Validation loss: 2.7834011217150363

Epoch: 5| Step: 8
Training loss: 0.3851577774234221
Validation loss: 2.87642912658229

Epoch: 5| Step: 9
Training loss: 0.45586701805944607
Validation loss: 2.845268909330619

Epoch: 5| Step: 10
Training loss: 0.4380718989170135
Validation loss: 2.846086090996268

Epoch: 5| Step: 11
Training loss: 0.33560892048825447
Validation loss: 2.83241092636103

Epoch: 390| Step: 0
Training loss: 0.45342709895481736
Validation loss: 2.8665622407075895

Epoch: 5| Step: 1
Training loss: 0.5794755265348259
Validation loss: 2.9086664196728043

Epoch: 5| Step: 2
Training loss: 0.8564171955012604
Validation loss: 2.92443962557323

Epoch: 5| Step: 3
Training loss: 0.38444209172324273
Validation loss: 2.8706143279527496

Epoch: 5| Step: 4
Training loss: 0.30565689614764613
Validation loss: 2.8156059810660796

Epoch: 5| Step: 5
Training loss: 0.43960680499697574
Validation loss: 2.728965167015608

Epoch: 5| Step: 6
Training loss: 0.416324733463331
Validation loss: 2.7567083833963646

Epoch: 5| Step: 7
Training loss: 0.4704431314375856
Validation loss: 2.831240537906917

Epoch: 5| Step: 8
Training loss: 0.4001627389842717
Validation loss: 2.8795914268094727

Epoch: 5| Step: 9
Training loss: 0.24271790044917538
Validation loss: 2.8902933703744407

Epoch: 5| Step: 10
Training loss: 0.4286565898257902
Validation loss: 2.8698146055289033

Epoch: 5| Step: 11
Training loss: 0.18099377419173118
Validation loss: 2.949703131301997

Epoch: 391| Step: 0
Training loss: 0.5781450268137703
Validation loss: 2.9317353614716435

Epoch: 5| Step: 1
Training loss: 0.43263080997417935
Validation loss: 2.8901252795766044

Epoch: 5| Step: 2
Training loss: 0.32491478261248924
Validation loss: 2.9241429382193855

Epoch: 5| Step: 3
Training loss: 0.3961219446504392
Validation loss: 2.868274732045033

Epoch: 5| Step: 4
Training loss: 0.31887029827394553
Validation loss: 2.725997228604002

Epoch: 5| Step: 5
Training loss: 0.4023139349991999
Validation loss: 2.800300659772205

Epoch: 5| Step: 6
Training loss: 0.5731137341356143
Validation loss: 2.739738910787781

Epoch: 5| Step: 7
Training loss: 0.2727901971358985
Validation loss: 2.7863214595844554

Epoch: 5| Step: 8
Training loss: 0.7826821742197593
Validation loss: 2.847468470699457

Epoch: 5| Step: 9
Training loss: 0.3992403580702221
Validation loss: 2.7657299309201555

Epoch: 5| Step: 10
Training loss: 0.6108671894249363
Validation loss: 2.876821997943859

Epoch: 5| Step: 11
Training loss: 0.3570452931520027
Validation loss: 2.898486011027188

Epoch: 392| Step: 0
Training loss: 0.4603462953715306
Validation loss: 2.942923692682888

Epoch: 5| Step: 1
Training loss: 0.45727162682918626
Validation loss: 2.837735519493666

Epoch: 5| Step: 2
Training loss: 0.8940470688630554
Validation loss: 2.815974032621877

Epoch: 5| Step: 3
Training loss: 0.3554386084217157
Validation loss: 2.776351518974768

Epoch: 5| Step: 4
Training loss: 0.4084696287610169
Validation loss: 2.79721695569475

Epoch: 5| Step: 5
Training loss: 0.42806803957852113
Validation loss: 2.7662035162792793

Epoch: 5| Step: 6
Training loss: 0.2797453021412698
Validation loss: 2.79743152814152

Epoch: 5| Step: 7
Training loss: 0.38156110233735113
Validation loss: 2.8080320013141424

Epoch: 5| Step: 8
Training loss: 0.34857365295942205
Validation loss: 2.881898795510638

Epoch: 5| Step: 9
Training loss: 0.43901306159089803
Validation loss: 2.8250785493198536

Epoch: 5| Step: 10
Training loss: 0.27344357620027615
Validation loss: 2.8059974204158276

Epoch: 5| Step: 11
Training loss: 0.13471706178811252
Validation loss: 2.780924331514406

Epoch: 393| Step: 0
Training loss: 0.3921380684389229
Validation loss: 2.863777762919089

Epoch: 5| Step: 1
Training loss: 0.31025157539757686
Validation loss: 2.7967820960159586

Epoch: 5| Step: 2
Training loss: 0.31689139248508763
Validation loss: 2.7225027273670612

Epoch: 5| Step: 3
Training loss: 0.3273576779008604
Validation loss: 2.7750825077827472

Epoch: 5| Step: 4
Training loss: 0.4512030520545596
Validation loss: 2.795924250654222

Epoch: 5| Step: 5
Training loss: 0.45760886054088723
Validation loss: 2.7791489941341547

Epoch: 5| Step: 6
Training loss: 0.3721644565293429
Validation loss: 2.8057064766205664

Epoch: 5| Step: 7
Training loss: 0.35137668573456227
Validation loss: 2.8160443878151273

Epoch: 5| Step: 8
Training loss: 0.8408160946127693
Validation loss: 2.8967611618335045

Epoch: 5| Step: 9
Training loss: 0.49696345951373316
Validation loss: 2.8294940606429204

Epoch: 5| Step: 10
Training loss: 0.38154343037983773
Validation loss: 2.7989950474123644

Epoch: 5| Step: 11
Training loss: 0.2471495942181716
Validation loss: 2.7608055140767798

Epoch: 394| Step: 0
Training loss: 0.3103471269524647
Validation loss: 2.755757114343424

Epoch: 5| Step: 1
Training loss: 0.42387802955289505
Validation loss: 2.812305577940294

Epoch: 5| Step: 2
Training loss: 0.4801394256613563
Validation loss: 2.802229552489641

Epoch: 5| Step: 3
Training loss: 0.395861620477873
Validation loss: 2.83259405572803

Epoch: 5| Step: 4
Training loss: 0.35445624555492555
Validation loss: 2.806940075591312

Epoch: 5| Step: 5
Training loss: 0.38554000384576376
Validation loss: 2.8894412460725887

Epoch: 5| Step: 6
Training loss: 0.4304393952151966
Validation loss: 2.8492110673197484

Epoch: 5| Step: 7
Training loss: 0.8123872018423947
Validation loss: 2.9269370328694255

Epoch: 5| Step: 8
Training loss: 0.3321776123584959
Validation loss: 2.76720599874283

Epoch: 5| Step: 9
Training loss: 0.4130663134375339
Validation loss: 2.784232444267806

Epoch: 5| Step: 10
Training loss: 0.4814937482073463
Validation loss: 2.7942956009069633

Epoch: 5| Step: 11
Training loss: 0.7922605161104352
Validation loss: 2.748011693885165

Epoch: 395| Step: 0
Training loss: 0.3827120980146984
Validation loss: 2.8499926456836153

Epoch: 5| Step: 1
Training loss: 0.37011763036696377
Validation loss: 2.9026869326668017

Epoch: 5| Step: 2
Training loss: 0.2749430760075938
Validation loss: 2.773845671226819

Epoch: 5| Step: 3
Training loss: 0.3883420992477203
Validation loss: 2.876780570165066

Epoch: 5| Step: 4
Training loss: 0.3295482128836552
Validation loss: 2.8164005288300977

Epoch: 5| Step: 5
Training loss: 0.5133641993183191
Validation loss: 2.8138116215313698

Epoch: 5| Step: 6
Training loss: 0.30875549423487586
Validation loss: 2.907818553835583

Epoch: 5| Step: 7
Training loss: 0.8486140943774119
Validation loss: 2.853746182498615

Epoch: 5| Step: 8
Training loss: 0.32386037254133854
Validation loss: 2.7727981027342374

Epoch: 5| Step: 9
Training loss: 0.24417429119683698
Validation loss: 2.84687843043389

Epoch: 5| Step: 10
Training loss: 0.32843722520375757
Validation loss: 2.822205384699422

Epoch: 5| Step: 11
Training loss: 0.1330078315454769
Validation loss: 2.746358845098658

Epoch: 396| Step: 0
Training loss: 0.426136865760045
Validation loss: 2.848818942373012

Epoch: 5| Step: 1
Training loss: 0.36388511101668175
Validation loss: 2.8395630751568435

Epoch: 5| Step: 2
Training loss: 0.42216051118481807
Validation loss: 2.967766762922923

Epoch: 5| Step: 3
Training loss: 0.40549869022557666
Validation loss: 2.821062391626773

Epoch: 5| Step: 4
Training loss: 0.4402981919183283
Validation loss: 2.84192093166563

Epoch: 5| Step: 5
Training loss: 0.38136480979096166
Validation loss: 2.814914175862981

Epoch: 5| Step: 6
Training loss: 0.4884184835225845
Validation loss: 2.7853193587541814

Epoch: 5| Step: 7
Training loss: 0.868142641573471
Validation loss: 2.8142487493429043

Epoch: 5| Step: 8
Training loss: 0.42325863174721673
Validation loss: 2.797375227594749

Epoch: 5| Step: 9
Training loss: 0.39992520333373344
Validation loss: 2.824154653916672

Epoch: 5| Step: 10
Training loss: 0.4408984005663476
Validation loss: 2.846813504545535

Epoch: 5| Step: 11
Training loss: 0.4456741136341479
Validation loss: 2.827735227698974

Epoch: 397| Step: 0
Training loss: 0.8903764746066115
Validation loss: 2.9092550875123275

Epoch: 5| Step: 1
Training loss: 0.42695590382166415
Validation loss: 2.849186249472558

Epoch: 5| Step: 2
Training loss: 0.6018530899290517
Validation loss: 2.798300239665692

Epoch: 5| Step: 3
Training loss: 0.35495366516085614
Validation loss: 2.739626207245856

Epoch: 5| Step: 4
Training loss: 0.5082334094513203
Validation loss: 2.759922445187778

Epoch: 5| Step: 5
Training loss: 0.6193597688543997
Validation loss: 2.8518562130793774

Epoch: 5| Step: 6
Training loss: 0.5919292541097121
Validation loss: 2.751553165492887

Epoch: 5| Step: 7
Training loss: 0.3550701841299455
Validation loss: 2.7531849126109775

Epoch: 5| Step: 8
Training loss: 0.3752308969139915
Validation loss: 2.8776795954189787

Epoch: 5| Step: 9
Training loss: 0.4326583291634431
Validation loss: 2.9378777660116695

Epoch: 5| Step: 10
Training loss: 0.5013136891264272
Validation loss: 2.858532189012754

Epoch: 5| Step: 11
Training loss: 0.3617300736238839
Validation loss: 2.8994009776348553

Epoch: 398| Step: 0
Training loss: 0.305697162042609
Validation loss: 2.8435565302784522

Epoch: 5| Step: 1
Training loss: 0.43049943679568925
Validation loss: 2.824397955942785

Epoch: 5| Step: 2
Training loss: 0.4855640030875813
Validation loss: 2.8049521432059152

Epoch: 5| Step: 3
Training loss: 0.51862071850734
Validation loss: 2.79513598389932

Epoch: 5| Step: 4
Training loss: 0.44686810348097544
Validation loss: 2.775848884162949

Epoch: 5| Step: 5
Training loss: 0.2803279013001606
Validation loss: 2.814215952551124

Epoch: 5| Step: 6
Training loss: 0.28937120964501023
Validation loss: 2.9597928158747613

Epoch: 5| Step: 7
Training loss: 0.9854556010796319
Validation loss: 2.914179935083317

Epoch: 5| Step: 8
Training loss: 0.4844242193995056
Validation loss: 2.8754428266794507

Epoch: 5| Step: 9
Training loss: 0.42411149567686374
Validation loss: 2.8832080435313605

Epoch: 5| Step: 10
Training loss: 0.4063112689546632
Validation loss: 2.848279444385821

Epoch: 5| Step: 11
Training loss: 0.23577586188710428
Validation loss: 2.787731351645965

Epoch: 399| Step: 0
Training loss: 0.4217175083771074
Validation loss: 2.7766883173285852

Epoch: 5| Step: 1
Training loss: 0.44725118222301613
Validation loss: 2.7609902067969854

Epoch: 5| Step: 2
Training loss: 0.5016504406707601
Validation loss: 2.7922818261714832

Epoch: 5| Step: 3
Training loss: 0.815469121836051
Validation loss: 2.8122073162516874

Epoch: 5| Step: 4
Training loss: 0.2765272236540721
Validation loss: 2.8090028884837084

Epoch: 5| Step: 5
Training loss: 0.5209130861892315
Validation loss: 2.7980692354379513

Epoch: 5| Step: 6
Training loss: 0.5429379022192121
Validation loss: 2.84153538360573

Epoch: 5| Step: 7
Training loss: 0.27377334133778203
Validation loss: 2.792410994459975

Epoch: 5| Step: 8
Training loss: 0.3359944716648728
Validation loss: 2.8552427119778936

Epoch: 5| Step: 9
Training loss: 0.45962648320004135
Validation loss: 2.8246122607546686

Epoch: 5| Step: 10
Training loss: 0.2864346263207806
Validation loss: 2.8145349205214956

Epoch: 5| Step: 11
Training loss: 0.2887829898385116
Validation loss: 2.7680382553591842

Epoch: 400| Step: 0
Training loss: 0.8030971255085094
Validation loss: 2.7894696455835195

Epoch: 5| Step: 1
Training loss: 0.37189217054973017
Validation loss: 2.808237108870519

Epoch: 5| Step: 2
Training loss: 0.3386809307150455
Validation loss: 2.7285261433862162

Epoch: 5| Step: 3
Training loss: 0.3381875558125907
Validation loss: 2.7465175846026986

Epoch: 5| Step: 4
Training loss: 0.2904815509513798
Validation loss: 2.783006656248572

Epoch: 5| Step: 5
Training loss: 0.3401105534984426
Validation loss: 2.7500251422079542

Epoch: 5| Step: 6
Training loss: 0.3535994751686305
Validation loss: 2.8283995570606804

Epoch: 5| Step: 7
Training loss: 0.5028287915992058
Validation loss: 2.8344713770173238

Epoch: 5| Step: 8
Training loss: 0.30062481911905603
Validation loss: 2.8206130138007017

Epoch: 5| Step: 9
Training loss: 0.40504664314380223
Validation loss: 2.8201471634267765

Epoch: 5| Step: 10
Training loss: 0.3453950317281167
Validation loss: 2.8023572785478383

Epoch: 5| Step: 11
Training loss: 0.2366468628860602
Validation loss: 2.788323943072337

Epoch: 401| Step: 0
Training loss: 0.2593204297259779
Validation loss: 2.7943162064128875

Epoch: 5| Step: 1
Training loss: 0.33291407633471154
Validation loss: 2.909013049989752

Epoch: 5| Step: 2
Training loss: 0.365584751098286
Validation loss: 2.8455383368268907

Epoch: 5| Step: 3
Training loss: 0.41777130169208826
Validation loss: 2.796217814547177

Epoch: 5| Step: 4
Training loss: 0.3291111953185874
Validation loss: 2.8206161307402478

Epoch: 5| Step: 5
Training loss: 0.3551229954266526
Validation loss: 2.7770777850848036

Epoch: 5| Step: 6
Training loss: 0.8163940939842426
Validation loss: 2.813769569662204

Epoch: 5| Step: 7
Training loss: 0.4745930013461697
Validation loss: 2.8255208532564833

Epoch: 5| Step: 8
Training loss: 0.2604779393909788
Validation loss: 2.768850371074968

Epoch: 5| Step: 9
Training loss: 0.27256955951977113
Validation loss: 2.7688385994472156

Epoch: 5| Step: 10
Training loss: 0.29582649086484897
Validation loss: 2.849676248638571

Epoch: 5| Step: 11
Training loss: 0.7036486053600435
Validation loss: 2.9214485319614654

Epoch: 402| Step: 0
Training loss: 0.5260819208839309
Validation loss: 2.963547608828272

Epoch: 5| Step: 1
Training loss: 0.5743193765299774
Validation loss: 2.924398773845695

Epoch: 5| Step: 2
Training loss: 0.492149472659812
Validation loss: 2.9629514013639913

Epoch: 5| Step: 3
Training loss: 0.2846913532578355
Validation loss: 2.908823664865884

Epoch: 5| Step: 4
Training loss: 0.4963069667836783
Validation loss: 2.809716281097847

Epoch: 5| Step: 5
Training loss: 0.4221045611253714
Validation loss: 2.8690426547690233

Epoch: 5| Step: 6
Training loss: 0.5199102295818799
Validation loss: 2.75781508095308

Epoch: 5| Step: 7
Training loss: 0.7896546511956396
Validation loss: 2.7845865802174203

Epoch: 5| Step: 8
Training loss: 0.3311152445003028
Validation loss: 2.8733245072336198

Epoch: 5| Step: 9
Training loss: 0.46203345596566053
Validation loss: 2.8736166321021437

Epoch: 5| Step: 10
Training loss: 0.31675403225311055
Validation loss: 2.849522834005825

Epoch: 5| Step: 11
Training loss: 0.43071260416583335
Validation loss: 2.8646128335069543

Epoch: 403| Step: 0
Training loss: 0.3622496118352586
Validation loss: 2.8082436001550577

Epoch: 5| Step: 1
Training loss: 0.3557493757964909
Validation loss: 2.7995519028315035

Epoch: 5| Step: 2
Training loss: 0.36209680397574295
Validation loss: 2.85588481218484

Epoch: 5| Step: 3
Training loss: 0.44998816236184797
Validation loss: 2.8289019534318856

Epoch: 5| Step: 4
Training loss: 0.7827405824195236
Validation loss: 2.8041579739283313

Epoch: 5| Step: 5
Training loss: 0.4560203130865672
Validation loss: 2.7992578723589294

Epoch: 5| Step: 6
Training loss: 0.28853862562309945
Validation loss: 2.8366271722541767

Epoch: 5| Step: 7
Training loss: 0.3355243160138507
Validation loss: 2.8368989700029728

Epoch: 5| Step: 8
Training loss: 0.35765680815526923
Validation loss: 2.7932430390518452

Epoch: 5| Step: 9
Training loss: 0.36789616721355733
Validation loss: 2.7874573826917652

Epoch: 5| Step: 10
Training loss: 0.27782047294615714
Validation loss: 2.761684671108083

Epoch: 5| Step: 11
Training loss: 0.2385476140081855
Validation loss: 2.816300790957747

Epoch: 404| Step: 0
Training loss: 0.36796434889832114
Validation loss: 2.8093852951376017

Epoch: 5| Step: 1
Training loss: 0.416942870464456
Validation loss: 2.844642764515032

Epoch: 5| Step: 2
Training loss: 0.401371976726388
Validation loss: 2.7856427838216655

Epoch: 5| Step: 3
Training loss: 0.2788777173831947
Validation loss: 2.8621654201133078

Epoch: 5| Step: 4
Training loss: 0.5134824106050995
Validation loss: 2.738001367883036

Epoch: 5| Step: 5
Training loss: 0.34923102508750137
Validation loss: 2.88306796312646

Epoch: 5| Step: 6
Training loss: 0.42347268173062447
Validation loss: 2.83457194046818

Epoch: 5| Step: 7
Training loss: 0.5268818846011811
Validation loss: 2.863086542896738

Epoch: 5| Step: 8
Training loss: 0.7799285393771882
Validation loss: 2.8824111638436865

Epoch: 5| Step: 9
Training loss: 0.41997973021345775
Validation loss: 2.809414322365377

Epoch: 5| Step: 10
Training loss: 0.38773486034171545
Validation loss: 2.790161329524945

Epoch: 5| Step: 11
Training loss: 0.2021796345249491
Validation loss: 2.794075383404558

Epoch: 405| Step: 0
Training loss: 0.958498798819333
Validation loss: 2.751402314949966

Epoch: 5| Step: 1
Training loss: 0.434511365
Validation loss: 2.750762295551574

Epoch: 5| Step: 2
Training loss: 0.29421594270976437
Validation loss: 2.8144773614154457

Epoch: 5| Step: 3
Training loss: 0.3153405314481506
Validation loss: 2.822287997428807

Epoch: 5| Step: 4
Training loss: 0.40806244976915707
Validation loss: 2.865044564770988

Epoch: 5| Step: 5
Training loss: 0.40685438168343707
Validation loss: 2.908438497753361

Epoch: 5| Step: 6
Training loss: 0.3944019634563076
Validation loss: 2.893120957945382

Epoch: 5| Step: 7
Training loss: 0.4920602361451843
Validation loss: 2.907803803734448

Epoch: 5| Step: 8
Training loss: 0.25286360654370543
Validation loss: 2.872458962478524

Epoch: 5| Step: 9
Training loss: 0.43311357114281185
Validation loss: 2.7816232973671613

Epoch: 5| Step: 10
Training loss: 0.5536077224901872
Validation loss: 2.8011539730843533

Epoch: 5| Step: 11
Training loss: 0.32556115727212726
Validation loss: 2.791644894576695

Epoch: 406| Step: 0
Training loss: 0.3990487477644609
Validation loss: 2.8287719141231693

Epoch: 5| Step: 1
Training loss: 0.3549070216703981
Validation loss: 2.7875994273986553

Epoch: 5| Step: 2
Training loss: 0.3864964510926219
Validation loss: 2.8205387803141266

Epoch: 5| Step: 3
Training loss: 0.4253492000646301
Validation loss: 2.808978779892912

Epoch: 5| Step: 4
Training loss: 0.8494027423608683
Validation loss: 2.903136390277704

Epoch: 5| Step: 5
Training loss: 0.32656976563981516
Validation loss: 2.891136900793447

Epoch: 5| Step: 6
Training loss: 0.36840357186634043
Validation loss: 2.870512310501357

Epoch: 5| Step: 7
Training loss: 0.34793453651305034
Validation loss: 2.8871145480365987

Epoch: 5| Step: 8
Training loss: 0.3115030359744798
Validation loss: 2.816553959387907

Epoch: 5| Step: 9
Training loss: 0.3654218386404054
Validation loss: 2.7832508676460703

Epoch: 5| Step: 10
Training loss: 0.2942063322804631
Validation loss: 2.810769025282041

Epoch: 5| Step: 11
Training loss: 0.5933576341494249
Validation loss: 2.764526702274

Epoch: 407| Step: 0
Training loss: 0.4046433295811257
Validation loss: 2.824196702405909

Epoch: 5| Step: 1
Training loss: 0.4913319008382328
Validation loss: 2.8976580522013435

Epoch: 5| Step: 2
Training loss: 0.365589479204466
Validation loss: 2.8183120402808775

Epoch: 5| Step: 3
Training loss: 0.3457254521115888
Validation loss: 2.7614124025669042

Epoch: 5| Step: 4
Training loss: 0.2692002876712756
Validation loss: 2.771823054977006

Epoch: 5| Step: 5
Training loss: 0.3730457565530518
Validation loss: 2.7883186630684715

Epoch: 5| Step: 6
Training loss: 0.7946303674319474
Validation loss: 2.8788664257343743

Epoch: 5| Step: 7
Training loss: 0.3384382627976998
Validation loss: 2.856864563694715

Epoch: 5| Step: 8
Training loss: 0.35371721958288
Validation loss: 2.8094667290297486

Epoch: 5| Step: 9
Training loss: 0.30453889842090254
Validation loss: 2.917209865305211

Epoch: 5| Step: 10
Training loss: 0.47726947687330307
Validation loss: 2.8428651879409688

Epoch: 5| Step: 11
Training loss: 0.5152599313918056
Validation loss: 2.8265032148918197

Epoch: 408| Step: 0
Training loss: 0.3787722596466758
Validation loss: 2.819841449459215

Epoch: 5| Step: 1
Training loss: 0.5039243768787993
Validation loss: 2.7708150222479215

Epoch: 5| Step: 2
Training loss: 0.8319341755146384
Validation loss: 2.829423241130656

Epoch: 5| Step: 3
Training loss: 0.4370579529924914
Validation loss: 2.853759528912946

Epoch: 5| Step: 4
Training loss: 0.36176232720167256
Validation loss: 2.82084809533731

Epoch: 5| Step: 5
Training loss: 0.4874523909869841
Validation loss: 2.898247214734839

Epoch: 5| Step: 6
Training loss: 0.4442685254280396
Validation loss: 2.9089390165452627

Epoch: 5| Step: 7
Training loss: 0.4527878987202433
Validation loss: 2.961344329476999

Epoch: 5| Step: 8
Training loss: 0.3924862958252935
Validation loss: 2.853444562649867

Epoch: 5| Step: 9
Training loss: 0.40862548004710325
Validation loss: 2.883790998482972

Epoch: 5| Step: 10
Training loss: 0.5954746245847918
Validation loss: 2.849319645474431

Epoch: 5| Step: 11
Training loss: 0.5543368130920863
Validation loss: 2.8092107612372788

Epoch: 409| Step: 0
Training loss: 0.2767884376826983
Validation loss: 2.763119318600399

Epoch: 5| Step: 1
Training loss: 0.3688437867914815
Validation loss: 2.858381338430023

Epoch: 5| Step: 2
Training loss: 0.3685522891048957
Validation loss: 2.8748761267858396

Epoch: 5| Step: 3
Training loss: 0.35909050585737295
Validation loss: 2.853453325430969

Epoch: 5| Step: 4
Training loss: 0.41808294358456133
Validation loss: 2.8843257622943654

Epoch: 5| Step: 5
Training loss: 0.7415917264031376
Validation loss: 2.839904021927013

Epoch: 5| Step: 6
Training loss: 0.3531894232630575
Validation loss: 2.8461132639822346

Epoch: 5| Step: 7
Training loss: 0.39041845583158
Validation loss: 2.8283205017464903

Epoch: 5| Step: 8
Training loss: 0.2914485655223304
Validation loss: 2.87114174385353

Epoch: 5| Step: 9
Training loss: 0.3351740812346661
Validation loss: 2.8287780808535454

Epoch: 5| Step: 10
Training loss: 0.3121716920518084
Validation loss: 2.8300579167731166

Epoch: 5| Step: 11
Training loss: 0.3055397731625748
Validation loss: 2.8684995803739612

Epoch: 410| Step: 0
Training loss: 0.4459079642829983
Validation loss: 2.8815114084073428

Epoch: 5| Step: 1
Training loss: 0.6060858750132897
Validation loss: 2.8908031374366985

Epoch: 5| Step: 2
Training loss: 0.35515249247814223
Validation loss: 2.8796178386042968

Epoch: 5| Step: 3
Training loss: 0.3913690347548909
Validation loss: 2.7667613739058394

Epoch: 5| Step: 4
Training loss: 0.41563745781147216
Validation loss: 2.8113901102938463

Epoch: 5| Step: 5
Training loss: 0.49307875698046805
Validation loss: 2.7916783194986703

Epoch: 5| Step: 6
Training loss: 0.4546498423971794
Validation loss: 2.8139442161992396

Epoch: 5| Step: 7
Training loss: 0.33759399579805555
Validation loss: 2.8558848817542235

Epoch: 5| Step: 8
Training loss: 0.303056766754725
Validation loss: 2.896711196986963

Epoch: 5| Step: 9
Training loss: 0.3743449092037864
Validation loss: 2.8359491612498515

Epoch: 5| Step: 10
Training loss: 0.7714001959736432
Validation loss: 2.8675161687832444

Epoch: 5| Step: 11
Training loss: 0.276614466057644
Validation loss: 2.8723841632641687

Epoch: 411| Step: 0
Training loss: 0.8102901557757497
Validation loss: 2.8489224689092896

Epoch: 5| Step: 1
Training loss: 0.4387470252324736
Validation loss: 2.819185220116268

Epoch: 5| Step: 2
Training loss: 0.333618923372032
Validation loss: 2.8840435022187294

Epoch: 5| Step: 3
Training loss: 0.2983542031486416
Validation loss: 2.8535970632292997

Epoch: 5| Step: 4
Training loss: 0.3682727400355286
Validation loss: 2.9399646132365835

Epoch: 5| Step: 5
Training loss: 0.3504617412612941
Validation loss: 2.810303066654521

Epoch: 5| Step: 6
Training loss: 0.26412309256143374
Validation loss: 2.805829516076744

Epoch: 5| Step: 7
Training loss: 0.32900235409822004
Validation loss: 2.883735006023616

Epoch: 5| Step: 8
Training loss: 0.4144925996639757
Validation loss: 2.864740344281753

Epoch: 5| Step: 9
Training loss: 0.2808230391171157
Validation loss: 2.9007436415466095

Epoch: 5| Step: 10
Training loss: 0.3143357478411778
Validation loss: 2.790048651077374

Epoch: 5| Step: 11
Training loss: 0.2843492663970172
Validation loss: 2.786761478916038

Epoch: 412| Step: 0
Training loss: 0.27083094608037267
Validation loss: 2.8212449072646932

Epoch: 5| Step: 1
Training loss: 0.24672279494716193
Validation loss: 2.9018920985133096

Epoch: 5| Step: 2
Training loss: 0.38300452962866127
Validation loss: 2.919157879584138

Epoch: 5| Step: 3
Training loss: 0.4897962793592478
Validation loss: 2.8768978558160825

Epoch: 5| Step: 4
Training loss: 0.7955259984609522
Validation loss: 2.827984049395066

Epoch: 5| Step: 5
Training loss: 0.3964619371801979
Validation loss: 2.813811099020186

Epoch: 5| Step: 6
Training loss: 0.436617489097901
Validation loss: 2.8697940332549505

Epoch: 5| Step: 7
Training loss: 0.40865622019186054
Validation loss: 2.771057171253498

Epoch: 5| Step: 8
Training loss: 0.35916450804454836
Validation loss: 2.736496220648166

Epoch: 5| Step: 9
Training loss: 0.29747848909811464
Validation loss: 2.7607824239192733

Epoch: 5| Step: 10
Training loss: 0.2370788614287655
Validation loss: 2.7432525428561565

Epoch: 5| Step: 11
Training loss: 0.381282219541549
Validation loss: 2.8402747570950324

Epoch: 413| Step: 0
Training loss: 0.42843093939390137
Validation loss: 2.8726654041522406

Epoch: 5| Step: 1
Training loss: 0.530696861424428
Validation loss: 2.8001604123656936

Epoch: 5| Step: 2
Training loss: 0.4252703164656156
Validation loss: 2.8148647680599885

Epoch: 5| Step: 3
Training loss: 0.47156964078619534
Validation loss: 2.718546139904439

Epoch: 5| Step: 4
Training loss: 0.4040861087165397
Validation loss: 2.791950913567053

Epoch: 5| Step: 5
Training loss: 0.3317580277004193
Validation loss: 2.767619066063455

Epoch: 5| Step: 6
Training loss: 0.37938803098945023
Validation loss: 2.7913064273495327

Epoch: 5| Step: 7
Training loss: 0.43034054808117644
Validation loss: 2.7437163218384284

Epoch: 5| Step: 8
Training loss: 0.27614966415161757
Validation loss: 2.8253607263630798

Epoch: 5| Step: 9
Training loss: 0.4608619272381575
Validation loss: 2.944954193473578

Epoch: 5| Step: 10
Training loss: 0.7656852931980326
Validation loss: 2.865520838290355

Epoch: 5| Step: 11
Training loss: 0.3609401991772151
Validation loss: 2.8810026695691935

Epoch: 414| Step: 0
Training loss: 0.2892576280756845
Validation loss: 2.8124283110347683

Epoch: 5| Step: 1
Training loss: 0.3684787973323825
Validation loss: 2.806118790320994

Epoch: 5| Step: 2
Training loss: 0.4242803384883901
Validation loss: 2.849278424475481

Epoch: 5| Step: 3
Training loss: 0.40230552713995665
Validation loss: 2.7568566878615854

Epoch: 5| Step: 4
Training loss: 0.34311478618713614
Validation loss: 2.7337574179626767

Epoch: 5| Step: 5
Training loss: 0.47238772622595865
Validation loss: 2.864525219876912

Epoch: 5| Step: 6
Training loss: 0.37560424204640863
Validation loss: 2.887832805175639

Epoch: 5| Step: 7
Training loss: 0.5111412983453408
Validation loss: 2.894530282168413

Epoch: 5| Step: 8
Training loss: 0.7566657287182925
Validation loss: 2.855859481859525

Epoch: 5| Step: 9
Training loss: 0.3526412731162839
Validation loss: 2.968210254927336

Epoch: 5| Step: 10
Training loss: 0.45378209843873785
Validation loss: 2.8557558171969064

Epoch: 5| Step: 11
Training loss: 0.13427457633201126
Validation loss: 2.859514514458698

Epoch: 415| Step: 0
Training loss: 0.5198860104498537
Validation loss: 2.8581249513284774

Epoch: 5| Step: 1
Training loss: 0.3941788185147097
Validation loss: 2.845133074808629

Epoch: 5| Step: 2
Training loss: 0.46005936397649155
Validation loss: 2.880398388203182

Epoch: 5| Step: 3
Training loss: 0.353667800775364
Validation loss: 2.805790938259234

Epoch: 5| Step: 4
Training loss: 0.38589787299080824
Validation loss: 2.878011218433726

Epoch: 5| Step: 5
Training loss: 0.39378747610342685
Validation loss: 2.8428741091295873

Epoch: 5| Step: 6
Training loss: 0.8151319131404483
Validation loss: 2.8579083939153707

Epoch: 5| Step: 7
Training loss: 0.44496819085113415
Validation loss: 2.834442932341054

Epoch: 5| Step: 8
Training loss: 0.6226543996058291
Validation loss: 2.7954985323377692

Epoch: 5| Step: 9
Training loss: 0.3089126556727966
Validation loss: 2.8478419762681515

Epoch: 5| Step: 10
Training loss: 0.3155206602257075
Validation loss: 2.8648974483392835

Epoch: 5| Step: 11
Training loss: 0.12390851155245973
Validation loss: 2.8487708688506928

Epoch: 416| Step: 0
Training loss: 0.3414524304649926
Validation loss: 2.8830891987267298

Epoch: 5| Step: 1
Training loss: 0.40269873060817823
Validation loss: 2.8179640709725624

Epoch: 5| Step: 2
Training loss: 0.38093073249795134
Validation loss: 2.8236417062163772

Epoch: 5| Step: 3
Training loss: 0.2713600258124481
Validation loss: 2.868269013894123

Epoch: 5| Step: 4
Training loss: 0.42941494013279263
Validation loss: 2.90568451866195

Epoch: 5| Step: 5
Training loss: 0.4667900755319216
Validation loss: 2.7951165697274223

Epoch: 5| Step: 6
Training loss: 0.7781196823857621
Validation loss: 2.821259939136499

Epoch: 5| Step: 7
Training loss: 0.33878875176454976
Validation loss: 2.8137068225576143

Epoch: 5| Step: 8
Training loss: 0.3906932389736884
Validation loss: 2.795771372194265

Epoch: 5| Step: 9
Training loss: 0.34187191820586266
Validation loss: 2.7408249015500568

Epoch: 5| Step: 10
Training loss: 0.34612927868004245
Validation loss: 2.8150756168711606

Epoch: 5| Step: 11
Training loss: 0.1975836692204135
Validation loss: 2.7726634310947067

Epoch: 417| Step: 0
Training loss: 0.42461178663984955
Validation loss: 2.815815042142982

Epoch: 5| Step: 1
Training loss: 0.3948367984644366
Validation loss: 2.8649117310448178

Epoch: 5| Step: 2
Training loss: 0.367142654277614
Validation loss: 2.785238431526851

Epoch: 5| Step: 3
Training loss: 0.3933492460338911
Validation loss: 2.7929342058797606

Epoch: 5| Step: 4
Training loss: 0.3890401734223392
Validation loss: 2.8613324057901797

Epoch: 5| Step: 5
Training loss: 0.3655333086118725
Validation loss: 2.8435179682099583

Epoch: 5| Step: 6
Training loss: 0.4635777262974266
Validation loss: 2.7709224060388604

Epoch: 5| Step: 7
Training loss: 0.19250637288505626
Validation loss: 2.8228885090867633

Epoch: 5| Step: 8
Training loss: 0.802831268031773
Validation loss: 2.8058140510241696

Epoch: 5| Step: 9
Training loss: 0.33292176373836574
Validation loss: 2.781242359879533

Epoch: 5| Step: 10
Training loss: 0.49727088463961583
Validation loss: 2.7771946169073547

Epoch: 5| Step: 11
Training loss: 0.22391933925993107
Validation loss: 2.7874634127361166

Epoch: 418| Step: 0
Training loss: 0.35309000896845805
Validation loss: 2.7908079454032872

Epoch: 5| Step: 1
Training loss: 0.31290978743301234
Validation loss: 2.816438104217462

Epoch: 5| Step: 2
Training loss: 0.7689086409223282
Validation loss: 2.912511530431754

Epoch: 5| Step: 3
Training loss: 0.5967514569313089
Validation loss: 2.9102791438086824

Epoch: 5| Step: 4
Training loss: 0.30693676492070543
Validation loss: 2.7763841082629472

Epoch: 5| Step: 5
Training loss: 0.36903155698593076
Validation loss: 2.7479451840077562

Epoch: 5| Step: 6
Training loss: 0.4145587969792437
Validation loss: 2.809241533627468

Epoch: 5| Step: 7
Training loss: 0.425117920897087
Validation loss: 2.7632524079915406

Epoch: 5| Step: 8
Training loss: 0.3824045381912182
Validation loss: 2.7844667191959953

Epoch: 5| Step: 9
Training loss: 0.38475274776074925
Validation loss: 2.831766853706258

Epoch: 5| Step: 10
Training loss: 0.44151826298116603
Validation loss: 2.809473762006793

Epoch: 5| Step: 11
Training loss: 0.43872549216788287
Validation loss: 2.9076426802701256

Epoch: 419| Step: 0
Training loss: 0.4639075331960876
Validation loss: 2.813609247103351

Epoch: 5| Step: 1
Training loss: 0.4205228895858877
Validation loss: 2.837301597016701

Epoch: 5| Step: 2
Training loss: 0.276586142569291
Validation loss: 2.8391959961496953

Epoch: 5| Step: 3
Training loss: 0.30193213948786024
Validation loss: 2.808128558927186

Epoch: 5| Step: 4
Training loss: 0.4319947632598043
Validation loss: 2.815638165402584

Epoch: 5| Step: 5
Training loss: 0.23518287184827485
Validation loss: 2.8655534500291666

Epoch: 5| Step: 6
Training loss: 0.41759418924119157
Validation loss: 2.744610041497131

Epoch: 5| Step: 7
Training loss: 0.7497324863816539
Validation loss: 2.8656620537689426

Epoch: 5| Step: 8
Training loss: 0.37844202765001517
Validation loss: 2.903013173561504

Epoch: 5| Step: 9
Training loss: 0.24820138219234109
Validation loss: 2.8798775934271457

Epoch: 5| Step: 10
Training loss: 0.4662304558122138
Validation loss: 2.871747966111091

Epoch: 5| Step: 11
Training loss: 0.5766240301614011
Validation loss: 2.854780483836856

Epoch: 420| Step: 0
Training loss: 0.39107784725080125
Validation loss: 2.8159936328413173

Epoch: 5| Step: 1
Training loss: 0.3158548519047495
Validation loss: 2.773941431245917

Epoch: 5| Step: 2
Training loss: 0.424098723908807
Validation loss: 2.8173060397349174

Epoch: 5| Step: 3
Training loss: 0.5065105474189125
Validation loss: 2.7655640036830382

Epoch: 5| Step: 4
Training loss: 0.37050023048537856
Validation loss: 2.8415900331010238

Epoch: 5| Step: 5
Training loss: 0.453488960106502
Validation loss: 2.800771854230584

Epoch: 5| Step: 6
Training loss: 0.31205758726232324
Validation loss: 2.856240804366676

Epoch: 5| Step: 7
Training loss: 0.35961507987884705
Validation loss: 2.81508135837816

Epoch: 5| Step: 8
Training loss: 0.3360829592878545
Validation loss: 2.9755227382998135

Epoch: 5| Step: 9
Training loss: 0.4748786350853168
Validation loss: 2.885734428141447

Epoch: 5| Step: 10
Training loss: 0.7527003551292266
Validation loss: 2.7710707474341683

Epoch: 5| Step: 11
Training loss: 0.39534788312614216
Validation loss: 2.7316452296897493

Epoch: 421| Step: 0
Training loss: 0.3076681791155917
Validation loss: 2.7810451060627304

Epoch: 5| Step: 1
Training loss: 0.43104588197564775
Validation loss: 2.8600736747657827

Epoch: 5| Step: 2
Training loss: 0.3257403231374276
Validation loss: 2.7871341681942603

Epoch: 5| Step: 3
Training loss: 0.3750822652545755
Validation loss: 2.766519721468269

Epoch: 5| Step: 4
Training loss: 0.4402270474708365
Validation loss: 2.8672432612541363

Epoch: 5| Step: 5
Training loss: 0.3922520702142102
Validation loss: 2.889225715605567

Epoch: 5| Step: 6
Training loss: 0.43894342321423985
Validation loss: 2.860986318124872

Epoch: 5| Step: 7
Training loss: 0.7817380143879347
Validation loss: 2.827411515947896

Epoch: 5| Step: 8
Training loss: 0.385861573878231
Validation loss: 2.883537025689542

Epoch: 5| Step: 9
Training loss: 0.25320175443594384
Validation loss: 2.7940419160492636

Epoch: 5| Step: 10
Training loss: 0.6283344963258592
Validation loss: 2.7692641867935195

Epoch: 5| Step: 11
Training loss: 0.6356568169296615
Validation loss: 2.7838042991936875

Epoch: 422| Step: 0
Training loss: 0.32108006738250344
Validation loss: 2.8709686598050994

Epoch: 5| Step: 1
Training loss: 0.7594751425436672
Validation loss: 2.894160958722087

Epoch: 5| Step: 2
Training loss: 0.5954226474537222
Validation loss: 2.8520324946782036

Epoch: 5| Step: 3
Training loss: 0.2133126232282102
Validation loss: 2.8696955903039045

Epoch: 5| Step: 4
Training loss: 0.30699177699383784
Validation loss: 2.862934079358549

Epoch: 5| Step: 5
Training loss: 0.3263002930896763
Validation loss: 2.85055232510119

Epoch: 5| Step: 6
Training loss: 0.5293202131130315
Validation loss: 2.780053281313487

Epoch: 5| Step: 7
Training loss: 0.45840966788319365
Validation loss: 2.827273481257735

Epoch: 5| Step: 8
Training loss: 0.4263206704697157
Validation loss: 2.8103886909496945

Epoch: 5| Step: 9
Training loss: 0.3080219088989166
Validation loss: 2.8007149185278117

Epoch: 5| Step: 10
Training loss: 0.44807677032056276
Validation loss: 2.8331771216151833

Epoch: 5| Step: 11
Training loss: 0.18945091285593868
Validation loss: 2.801444506709071

Epoch: 423| Step: 0
Training loss: 0.4798346265883848
Validation loss: 2.885999387756665

Epoch: 5| Step: 1
Training loss: 0.5013009967214194
Validation loss: 2.8645103768970697

Epoch: 5| Step: 2
Training loss: 0.374797070750359
Validation loss: 2.863110452634589

Epoch: 5| Step: 3
Training loss: 0.3655790650620227
Validation loss: 2.8141402547833994

Epoch: 5| Step: 4
Training loss: 0.4735575508019155
Validation loss: 2.7502027675261314

Epoch: 5| Step: 5
Training loss: 0.3250490380851362
Validation loss: 2.7769456659484155

Epoch: 5| Step: 6
Training loss: 0.47760845530451945
Validation loss: 2.836884126051126

Epoch: 5| Step: 7
Training loss: 0.28866784760139624
Validation loss: 2.784768857404246

Epoch: 5| Step: 8
Training loss: 0.299786234731994
Validation loss: 2.809519442337643

Epoch: 5| Step: 9
Training loss: 0.41342219741770075
Validation loss: 2.8178565902394004

Epoch: 5| Step: 10
Training loss: 0.7764775803492553
Validation loss: 2.837813272841906

Epoch: 5| Step: 11
Training loss: 0.6856368350917476
Validation loss: 2.8181666896317052

Epoch: 424| Step: 0
Training loss: 0.3420930287841487
Validation loss: 2.8241553556679695

Epoch: 5| Step: 1
Training loss: 0.4482999943045029
Validation loss: 2.77780226272812

Epoch: 5| Step: 2
Training loss: 0.41572064252943214
Validation loss: 2.8053921033175877

Epoch: 5| Step: 3
Training loss: 0.46320628416850257
Validation loss: 2.7350049265108716

Epoch: 5| Step: 4
Training loss: 0.47290796875482216
Validation loss: 2.779535611716585

Epoch: 5| Step: 5
Training loss: 0.39694335754305937
Validation loss: 2.8690659677977384

Epoch: 5| Step: 6
Training loss: 0.6377976059471264
Validation loss: 2.899615292682491

Epoch: 5| Step: 7
Training loss: 0.7110922927858279
Validation loss: 3.05814589546238

Epoch: 5| Step: 8
Training loss: 0.4727348388407343
Validation loss: 2.9389021617979885

Epoch: 5| Step: 9
Training loss: 0.3928682194888392
Validation loss: 2.860328720242942

Epoch: 5| Step: 10
Training loss: 0.8501974241202886
Validation loss: 2.778448599572701

Epoch: 5| Step: 11
Training loss: 0.5100341615735765
Validation loss: 2.719945560680721

Epoch: 425| Step: 0
Training loss: 0.6632569532134184
Validation loss: 2.8489453607760162

Epoch: 5| Step: 1
Training loss: 0.5307031509666712
Validation loss: 2.75238702230936

Epoch: 5| Step: 2
Training loss: 0.5055576440863501
Validation loss: 2.806749278500337

Epoch: 5| Step: 3
Training loss: 0.37803664160301376
Validation loss: 2.8715601362788163

Epoch: 5| Step: 4
Training loss: 0.3378348442296188
Validation loss: 2.867101226257039

Epoch: 5| Step: 5
Training loss: 0.37332175148868907
Validation loss: 2.9191485585522163

Epoch: 5| Step: 6
Training loss: 0.35144064168867345
Validation loss: 3.009548023435197

Epoch: 5| Step: 7
Training loss: 0.3817261247707132
Validation loss: 2.872763859449692

Epoch: 5| Step: 8
Training loss: 0.47499334242823116
Validation loss: 2.899020387453937

Epoch: 5| Step: 9
Training loss: 0.3431494951277249
Validation loss: 2.8934752322173436

Epoch: 5| Step: 10
Training loss: 0.5237233818865016
Validation loss: 2.77658081306253

Epoch: 5| Step: 11
Training loss: 1.6179599115193841
Validation loss: 2.86297934390318

Epoch: 426| Step: 0
Training loss: 0.3534774970468997
Validation loss: 2.8243419608029363

Epoch: 5| Step: 1
Training loss: 0.350209089392202
Validation loss: 2.878781958234363

Epoch: 5| Step: 2
Training loss: 0.2671542883191992
Validation loss: 2.8626071939706517

Epoch: 5| Step: 3
Training loss: 0.7314321111855259
Validation loss: 2.8527969649481753

Epoch: 5| Step: 4
Training loss: 0.4120945679232776
Validation loss: 2.939090643042767

Epoch: 5| Step: 5
Training loss: 0.3789755571039784
Validation loss: 2.899105889506692

Epoch: 5| Step: 6
Training loss: 0.3790526353098101
Validation loss: 2.8313488263025244

Epoch: 5| Step: 7
Training loss: 0.4973239364056927
Validation loss: 2.7883605697065086

Epoch: 5| Step: 8
Training loss: 0.5841956123367504
Validation loss: 2.8149069941397697

Epoch: 5| Step: 9
Training loss: 0.4912454884931041
Validation loss: 2.898431913331055

Epoch: 5| Step: 10
Training loss: 0.3770445282957799
Validation loss: 2.8448733427115895

Epoch: 5| Step: 11
Training loss: 0.3312783062734548
Validation loss: 2.802090330481508

Epoch: 427| Step: 0
Training loss: 0.4907723624643143
Validation loss: 2.8863799258077156

Epoch: 5| Step: 1
Training loss: 0.563823943268633
Validation loss: 2.9258286048306252

Epoch: 5| Step: 2
Training loss: 0.6717384332655524
Validation loss: 2.8911933512016352

Epoch: 5| Step: 3
Training loss: 0.4234147583038133
Validation loss: 2.7688570551558622

Epoch: 5| Step: 4
Training loss: 0.3354372802564492
Validation loss: 2.754304266410118

Epoch: 5| Step: 5
Training loss: 0.4950026580951106
Validation loss: 2.7731905975045947

Epoch: 5| Step: 6
Training loss: 0.38645883938875336
Validation loss: 2.7519884614861976

Epoch: 5| Step: 7
Training loss: 0.5264351823871913
Validation loss: 2.8121134174422258

Epoch: 5| Step: 8
Training loss: 0.36696303385301254
Validation loss: 2.87944447745392

Epoch: 5| Step: 9
Training loss: 0.39228318175696647
Validation loss: 2.902537723184406

Epoch: 5| Step: 10
Training loss: 0.4940604344613741
Validation loss: 2.9304761274450506

Epoch: 5| Step: 11
Training loss: 0.6148309262791201
Validation loss: 2.8812497735454388

Epoch: 428| Step: 0
Training loss: 0.32472633935412926
Validation loss: 2.9061746108965694

Epoch: 5| Step: 1
Training loss: 0.3521328009139772
Validation loss: 2.82588969106862

Epoch: 5| Step: 2
Training loss: 0.426521986829546
Validation loss: 2.8012048497633253

Epoch: 5| Step: 3
Training loss: 0.4553248182946206
Validation loss: 2.800416600791576

Epoch: 5| Step: 4
Training loss: 0.40865443346145336
Validation loss: 2.7552370359563847

Epoch: 5| Step: 5
Training loss: 0.2856113512379955
Validation loss: 2.820115833699132

Epoch: 5| Step: 6
Training loss: 0.2891690599074987
Validation loss: 2.7733851683071706

Epoch: 5| Step: 7
Training loss: 0.4348481565218612
Validation loss: 2.9037616837773204

Epoch: 5| Step: 8
Training loss: 0.8221916473527654
Validation loss: 2.890871824431824

Epoch: 5| Step: 9
Training loss: 0.4010859151267431
Validation loss: 2.9560632402060865

Epoch: 5| Step: 10
Training loss: 0.3559424838218722
Validation loss: 2.889046461378203

Epoch: 5| Step: 11
Training loss: 0.4679884287114849
Validation loss: 2.902641178463034

Epoch: 429| Step: 0
Training loss: 0.30207690555486394
Validation loss: 2.81551136997027

Epoch: 5| Step: 1
Training loss: 0.3931382012993552
Validation loss: 2.8534989005105014

Epoch: 5| Step: 2
Training loss: 0.6412808387434922
Validation loss: 2.7828252881666757

Epoch: 5| Step: 3
Training loss: 0.5400815536586636
Validation loss: 2.803263165326815

Epoch: 5| Step: 4
Training loss: 0.2831836825306913
Validation loss: 2.779945646310396

Epoch: 5| Step: 5
Training loss: 0.3849128015655445
Validation loss: 2.823202267706205

Epoch: 5| Step: 6
Training loss: 0.4423847324759143
Validation loss: 2.939869175528222

Epoch: 5| Step: 7
Training loss: 0.5694001359552182
Validation loss: 2.9801478215225092

Epoch: 5| Step: 8
Training loss: 0.39927504902097066
Validation loss: 2.912124773612055

Epoch: 5| Step: 9
Training loss: 0.3850521821415305
Validation loss: 2.9495817554723107

Epoch: 5| Step: 10
Training loss: 0.7630315178827213
Validation loss: 2.8737841260337595

Epoch: 5| Step: 11
Training loss: 0.39439752408618145
Validation loss: 2.839064629819355

Epoch: 430| Step: 0
Training loss: 0.3906571756462871
Validation loss: 2.8382523602150167

Epoch: 5| Step: 1
Training loss: 0.5398844382027886
Validation loss: 2.8198909673455876

Epoch: 5| Step: 2
Training loss: 0.3489168650152279
Validation loss: 2.8646188086422697

Epoch: 5| Step: 3
Training loss: 0.2804207630599855
Validation loss: 2.8961559031378825

Epoch: 5| Step: 4
Training loss: 0.4919143100235961
Validation loss: 2.870623948462269

Epoch: 5| Step: 5
Training loss: 0.40166032022722803
Validation loss: 2.893893763278358

Epoch: 5| Step: 6
Training loss: 0.4462081535337331
Validation loss: 2.8215029978578756

Epoch: 5| Step: 7
Training loss: 0.7813918938526074
Validation loss: 2.858734065974567

Epoch: 5| Step: 8
Training loss: 0.33720333562439325
Validation loss: 2.8816509163732937

Epoch: 5| Step: 9
Training loss: 0.27243145745602126
Validation loss: 2.852328761017938

Epoch: 5| Step: 10
Training loss: 0.2694982149086258
Validation loss: 2.8476566895535607

Epoch: 5| Step: 11
Training loss: 0.3743993001066293
Validation loss: 2.868683524320791

Epoch: 431| Step: 0
Training loss: 0.4458429456577758
Validation loss: 2.811765959988934

Epoch: 5| Step: 1
Training loss: 0.6774019860880783
Validation loss: 2.898624976196622

Epoch: 5| Step: 2
Training loss: 0.29020318932959505
Validation loss: 2.8720518732241036

Epoch: 5| Step: 3
Training loss: 0.33805987358448264
Validation loss: 2.9419984597068747

Epoch: 5| Step: 4
Training loss: 0.33608502098676263
Validation loss: 2.8501178931787363

Epoch: 5| Step: 5
Training loss: 0.4625701921913818
Validation loss: 2.8592575896847454

Epoch: 5| Step: 6
Training loss: 0.4061598127466698
Validation loss: 2.8092249044846738

Epoch: 5| Step: 7
Training loss: 0.48570821694681965
Validation loss: 2.8116417529011053

Epoch: 5| Step: 8
Training loss: 0.2689605974495576
Validation loss: 2.815401096311289

Epoch: 5| Step: 9
Training loss: 0.28158529481480293
Validation loss: 2.849427480385169

Epoch: 5| Step: 10
Training loss: 0.3294911441662092
Validation loss: 2.8534134627411016

Epoch: 5| Step: 11
Training loss: 0.3877194875103062
Validation loss: 2.808314578807779

Epoch: 432| Step: 0
Training loss: 0.3141148447663848
Validation loss: 2.8102484520994246

Epoch: 5| Step: 1
Training loss: 0.3657327811007225
Validation loss: 2.8569017042415394

Epoch: 5| Step: 2
Training loss: 0.24443416496328987
Validation loss: 2.7937403611166944

Epoch: 5| Step: 3
Training loss: 0.24199475801963816
Validation loss: 2.836849675457342

Epoch: 5| Step: 4
Training loss: 0.39169405560739096
Validation loss: 2.827101502937582

Epoch: 5| Step: 5
Training loss: 0.3796878696957896
Validation loss: 2.781268098322243

Epoch: 5| Step: 6
Training loss: 0.3673125115096496
Validation loss: 2.8546497998795743

Epoch: 5| Step: 7
Training loss: 0.388529094751738
Validation loss: 2.7790778389441675

Epoch: 5| Step: 8
Training loss: 0.3865333844987246
Validation loss: 2.768115289211287

Epoch: 5| Step: 9
Training loss: 0.3137362821399329
Validation loss: 2.7790291791981807

Epoch: 5| Step: 10
Training loss: 0.3793989497925315
Validation loss: 2.8218893783726857

Epoch: 5| Step: 11
Training loss: 1.39205666043897
Validation loss: 2.8956449873939993

Epoch: 433| Step: 0
Training loss: 0.3103311377130792
Validation loss: 2.839119802738914

Epoch: 5| Step: 1
Training loss: 0.37306283247605826
Validation loss: 2.7864403566630287

Epoch: 5| Step: 2
Training loss: 0.35115346425373806
Validation loss: 2.874696694836372

Epoch: 5| Step: 3
Training loss: 0.27594136569122374
Validation loss: 2.8424527804160813

Epoch: 5| Step: 4
Training loss: 0.708650284334068
Validation loss: 2.888173106484332

Epoch: 5| Step: 5
Training loss: 0.28188440510184753
Validation loss: 2.8202283570197144

Epoch: 5| Step: 6
Training loss: 0.3310769560309566
Validation loss: 2.889459526244358

Epoch: 5| Step: 7
Training loss: 0.30857111449460606
Validation loss: 2.864477035399778

Epoch: 5| Step: 8
Training loss: 0.37771801602464355
Validation loss: 2.8890114344582614

Epoch: 5| Step: 9
Training loss: 0.3845828827779217
Validation loss: 2.8209722421797925

Epoch: 5| Step: 10
Training loss: 0.40046505120005915
Validation loss: 2.867756540235302

Epoch: 5| Step: 11
Training loss: 0.2935904201300464
Validation loss: 2.8816648264644287

Epoch: 434| Step: 0
Training loss: 0.3859918486594265
Validation loss: 2.910602700894337

Epoch: 5| Step: 1
Training loss: 0.3027437270165879
Validation loss: 2.859109946162405

Epoch: 5| Step: 2
Training loss: 0.23881837622175078
Validation loss: 2.8946783429110483

Epoch: 5| Step: 3
Training loss: 0.29862487962064876
Validation loss: 2.9167149517058912

Epoch: 5| Step: 4
Training loss: 0.2653423656912269
Validation loss: 2.9510129746535663

Epoch: 5| Step: 5
Training loss: 0.31974129803070317
Validation loss: 2.812018279041309

Epoch: 5| Step: 6
Training loss: 0.41720191630625586
Validation loss: 2.9060317952266916

Epoch: 5| Step: 7
Training loss: 0.37394763387535135
Validation loss: 2.9036623362712284

Epoch: 5| Step: 8
Training loss: 0.7212390922633931
Validation loss: 2.825455190479103

Epoch: 5| Step: 9
Training loss: 0.4487973766235782
Validation loss: 2.881138430081253

Epoch: 5| Step: 10
Training loss: 0.3271113018765399
Validation loss: 2.8388750049722695

Epoch: 5| Step: 11
Training loss: 0.5668003158412315
Validation loss: 2.894527162453755

Epoch: 435| Step: 0
Training loss: 0.43144844920933706
Validation loss: 2.8805478857578577

Epoch: 5| Step: 1
Training loss: 0.36483322389762796
Validation loss: 2.9374501210570485

Epoch: 5| Step: 2
Training loss: 0.6502897625403156
Validation loss: 2.9441302833410927

Epoch: 5| Step: 3
Training loss: 0.3581113366987428
Validation loss: 2.89177591248494

Epoch: 5| Step: 4
Training loss: 0.28637168469668345
Validation loss: 2.8612890455682414

Epoch: 5| Step: 5
Training loss: 0.19749019606014148
Validation loss: 2.859194286034771

Epoch: 5| Step: 6
Training loss: 0.502619112283394
Validation loss: 2.8447882884250073

Epoch: 5| Step: 7
Training loss: 0.41139174980923454
Validation loss: 2.791508424008041

Epoch: 5| Step: 8
Training loss: 0.4209873433045441
Validation loss: 2.791935296917283

Epoch: 5| Step: 9
Training loss: 0.4788602561084964
Validation loss: 2.8780618133953886

Epoch: 5| Step: 10
Training loss: 0.39998323137182495
Validation loss: 2.8954749823301733

Epoch: 5| Step: 11
Training loss: 0.3363668226781215
Validation loss: 2.864225730538574

Epoch: 436| Step: 0
Training loss: 0.2129804876511619
Validation loss: 2.8495964867498893

Epoch: 5| Step: 1
Training loss: 0.3675300542388528
Validation loss: 2.82674346114002

Epoch: 5| Step: 2
Training loss: 0.6203827777323498
Validation loss: 2.8753118967794244

Epoch: 5| Step: 3
Training loss: 0.3127989769298135
Validation loss: 2.7602721098470484

Epoch: 5| Step: 4
Training loss: 0.4686737475363359
Validation loss: 2.844473645427526

Epoch: 5| Step: 5
Training loss: 0.3553761581726738
Validation loss: 2.8279056885551506

Epoch: 5| Step: 6
Training loss: 0.3941230361688713
Validation loss: 2.8365641375386335

Epoch: 5| Step: 7
Training loss: 0.2617260234448373
Validation loss: 2.822555731236394

Epoch: 5| Step: 8
Training loss: 0.3009527138798863
Validation loss: 2.821564879754939

Epoch: 5| Step: 9
Training loss: 0.4477817605775969
Validation loss: 2.7900984395827466

Epoch: 5| Step: 10
Training loss: 0.3093113462874054
Validation loss: 2.820245771948379

Epoch: 5| Step: 11
Training loss: 0.33313737513474817
Validation loss: 2.8121079560177487

Epoch: 437| Step: 0
Training loss: 0.3963606129179325
Validation loss: 2.80483767887507

Epoch: 5| Step: 1
Training loss: 0.22426638745125357
Validation loss: 2.7995062798658266

Epoch: 5| Step: 2
Training loss: 0.4033011554297107
Validation loss: 2.8468629615548697

Epoch: 5| Step: 3
Training loss: 0.2893736427720211
Validation loss: 2.787422419225386

Epoch: 5| Step: 4
Training loss: 0.42272184289570786
Validation loss: 2.729787098392799

Epoch: 5| Step: 5
Training loss: 0.4153604497275357
Validation loss: 2.7711820394946467

Epoch: 5| Step: 6
Training loss: 0.2983619569365564
Validation loss: 2.7912618903501762

Epoch: 5| Step: 7
Training loss: 0.6623738753623651
Validation loss: 2.8125244316170193

Epoch: 5| Step: 8
Training loss: 0.47059704546841946
Validation loss: 2.827564809266125

Epoch: 5| Step: 9
Training loss: 0.3994285935274588
Validation loss: 2.8342562018652413

Epoch: 5| Step: 10
Training loss: 0.3594111963370708
Validation loss: 2.8277670350981357

Epoch: 5| Step: 11
Training loss: 0.30153211776587974
Validation loss: 2.823331145560067

Epoch: 438| Step: 0
Training loss: 0.26698377829021935
Validation loss: 2.8176426248180966

Epoch: 5| Step: 1
Training loss: 0.4657541223999821
Validation loss: 2.8346451861531947

Epoch: 5| Step: 2
Training loss: 0.45511374927623693
Validation loss: 2.7290003606973783

Epoch: 5| Step: 3
Training loss: 0.28609401192436956
Validation loss: 2.7607874939111863

Epoch: 5| Step: 4
Training loss: 0.4097943662267814
Validation loss: 2.803711631967035

Epoch: 5| Step: 5
Training loss: 0.33528807432902497
Validation loss: 2.832631754733063

Epoch: 5| Step: 6
Training loss: 0.4167592025363233
Validation loss: 2.7737337339272994

Epoch: 5| Step: 7
Training loss: 0.2617899527412939
Validation loss: 2.792925598238

Epoch: 5| Step: 8
Training loss: 0.38717820588195573
Validation loss: 2.800811866724146

Epoch: 5| Step: 9
Training loss: 0.7002814970086264
Validation loss: 2.829806876231669

Epoch: 5| Step: 10
Training loss: 0.26144863537486795
Validation loss: 2.809167314376764

Epoch: 5| Step: 11
Training loss: 0.42761493565531083
Validation loss: 2.778827691078197

Epoch: 439| Step: 0
Training loss: 0.31030922919678805
Validation loss: 2.7966785432948327

Epoch: 5| Step: 1
Training loss: 0.4829287626656743
Validation loss: 2.8354084022246435

Epoch: 5| Step: 2
Training loss: 0.36926971681082604
Validation loss: 2.8126102991021846

Epoch: 5| Step: 3
Training loss: 0.4358647986602975
Validation loss: 2.747197536646454

Epoch: 5| Step: 4
Training loss: 0.39704911174927016
Validation loss: 2.7711731635387844

Epoch: 5| Step: 5
Training loss: 0.33945098191474815
Validation loss: 2.773731241207174

Epoch: 5| Step: 6
Training loss: 0.40528305226146677
Validation loss: 2.6978075761476514

Epoch: 5| Step: 7
Training loss: 0.3080357685839366
Validation loss: 2.769964527696007

Epoch: 5| Step: 8
Training loss: 0.7359447341207033
Validation loss: 2.7958356215348714

Epoch: 5| Step: 9
Training loss: 0.31525194102604087
Validation loss: 2.7757764275656847

Epoch: 5| Step: 10
Training loss: 0.39298568749755586
Validation loss: 2.85351557277964

Epoch: 5| Step: 11
Training loss: 0.19141559188777968
Validation loss: 2.790293823332344

Epoch: 440| Step: 0
Training loss: 0.32809584351836446
Validation loss: 2.790276880112761

Epoch: 5| Step: 1
Training loss: 0.32601160691886627
Validation loss: 2.799160831301861

Epoch: 5| Step: 2
Training loss: 0.7393807594932736
Validation loss: 2.806495305252181

Epoch: 5| Step: 3
Training loss: 0.305108561932931
Validation loss: 2.857941662577629

Epoch: 5| Step: 4
Training loss: 0.273751296776265
Validation loss: 2.753221864183445

Epoch: 5| Step: 5
Training loss: 0.37201748370287424
Validation loss: 2.7776933924784992

Epoch: 5| Step: 6
Training loss: 0.3003393990202797
Validation loss: 2.8104994511176504

Epoch: 5| Step: 7
Training loss: 0.3903726525604095
Validation loss: 2.785866542018771

Epoch: 5| Step: 8
Training loss: 0.31823491665171333
Validation loss: 2.82324114244957

Epoch: 5| Step: 9
Training loss: 0.4397334751637326
Validation loss: 2.8485409409376006

Epoch: 5| Step: 10
Training loss: 0.29436897087402325
Validation loss: 2.808344795041414

Epoch: 5| Step: 11
Training loss: 0.25883264714420473
Validation loss: 2.7930887405478684

Epoch: 441| Step: 0
Training loss: 0.37474892078648886
Validation loss: 2.8501948695736963

Epoch: 5| Step: 1
Training loss: 0.3849277058139041
Validation loss: 2.855463061868453

Epoch: 5| Step: 2
Training loss: 0.22299154032817883
Validation loss: 2.866864337777957

Epoch: 5| Step: 3
Training loss: 0.431380042219912
Validation loss: 2.8078790178806696

Epoch: 5| Step: 4
Training loss: 0.3362099850963436
Validation loss: 2.8019851622466576

Epoch: 5| Step: 5
Training loss: 0.3030519481016972
Validation loss: 2.800765508787504

Epoch: 5| Step: 6
Training loss: 0.30354920524307133
Validation loss: 2.8154083932139

Epoch: 5| Step: 7
Training loss: 0.44621561727379866
Validation loss: 2.8143534240076336

Epoch: 5| Step: 8
Training loss: 0.3094232492680769
Validation loss: 2.789556019748777

Epoch: 5| Step: 9
Training loss: 0.7761684715223254
Validation loss: 2.7353868810209168

Epoch: 5| Step: 10
Training loss: 0.3199932670816269
Validation loss: 2.812539626654751

Epoch: 5| Step: 11
Training loss: 0.2744492477720811
Validation loss: 2.9511059716450734

Epoch: 442| Step: 0
Training loss: 0.25602684655273716
Validation loss: 2.82006431184983

Epoch: 5| Step: 1
Training loss: 0.362212547245846
Validation loss: 2.826225081661108

Epoch: 5| Step: 2
Training loss: 0.37949585021995624
Validation loss: 2.901600735326338

Epoch: 5| Step: 3
Training loss: 0.2417386263693634
Validation loss: 2.8069160271444074

Epoch: 5| Step: 4
Training loss: 0.2854007561047435
Validation loss: 2.8247015871409293

Epoch: 5| Step: 5
Training loss: 0.7539799708557042
Validation loss: 2.8161403585166385

Epoch: 5| Step: 6
Training loss: 0.24026603024965731
Validation loss: 2.8436263759696403

Epoch: 5| Step: 7
Training loss: 0.3569162889035191
Validation loss: 2.8067285094353145

Epoch: 5| Step: 8
Training loss: 0.42147845599072614
Validation loss: 2.821204837727177

Epoch: 5| Step: 9
Training loss: 0.2960463302203817
Validation loss: 2.913191582536005

Epoch: 5| Step: 10
Training loss: 0.498448707191489
Validation loss: 2.893290989739176

Epoch: 5| Step: 11
Training loss: 0.452929076226839
Validation loss: 2.8335294106366606

Epoch: 443| Step: 0
Training loss: 0.22053862661354903
Validation loss: 2.753258743097444

Epoch: 5| Step: 1
Training loss: 0.48448101544757066
Validation loss: 2.8207623130971142

Epoch: 5| Step: 2
Training loss: 0.7257000305918003
Validation loss: 2.784249106721089

Epoch: 5| Step: 3
Training loss: 0.3844257538324608
Validation loss: 2.750692876313325

Epoch: 5| Step: 4
Training loss: 0.4352371414581446
Validation loss: 2.8187421651986484

Epoch: 5| Step: 5
Training loss: 0.35350803767539835
Validation loss: 2.813624686963305

Epoch: 5| Step: 6
Training loss: 0.394993765878373
Validation loss: 2.849984395112711

Epoch: 5| Step: 7
Training loss: 0.3393544807694139
Validation loss: 2.853013339300178

Epoch: 5| Step: 8
Training loss: 0.33649235746269507
Validation loss: 2.823491456164167

Epoch: 5| Step: 9
Training loss: 0.46265669436499457
Validation loss: 2.8232300902258873

Epoch: 5| Step: 10
Training loss: 0.36586881805817056
Validation loss: 2.772285741645519

Epoch: 5| Step: 11
Training loss: 0.23164181475792142
Validation loss: 2.8447876738263362

Epoch: 444| Step: 0
Training loss: 0.19313870949216172
Validation loss: 2.82272105342758

Epoch: 5| Step: 1
Training loss: 0.31125095612405895
Validation loss: 2.8218516361850723

Epoch: 5| Step: 2
Training loss: 0.33570703097160226
Validation loss: 2.824996869189573

Epoch: 5| Step: 3
Training loss: 0.32630321576570687
Validation loss: 2.8058995007469316

Epoch: 5| Step: 4
Training loss: 0.32006590352691144
Validation loss: 2.9016379160847126

Epoch: 5| Step: 5
Training loss: 0.38038882017148157
Validation loss: 2.8387458879459797

Epoch: 5| Step: 6
Training loss: 0.30979023531386624
Validation loss: 2.816739694412333

Epoch: 5| Step: 7
Training loss: 0.2803496014719254
Validation loss: 2.829490138950389

Epoch: 5| Step: 8
Training loss: 0.6641102044417374
Validation loss: 2.8183766199519735

Epoch: 5| Step: 9
Training loss: 0.38208565509857545
Validation loss: 2.7795256366173047

Epoch: 5| Step: 10
Training loss: 0.31147066105757404
Validation loss: 2.820434557104286

Epoch: 5| Step: 11
Training loss: 0.23207629180843722
Validation loss: 2.8332667670190688

Epoch: 445| Step: 0
Training loss: 0.32170351886312915
Validation loss: 2.835696379164162

Epoch: 5| Step: 1
Training loss: 0.3379311289242288
Validation loss: 2.7867602366004514

Epoch: 5| Step: 2
Training loss: 0.32088742182114993
Validation loss: 2.8228573505508816

Epoch: 5| Step: 3
Training loss: 0.3373948025999296
Validation loss: 2.8695052823841594

Epoch: 5| Step: 4
Training loss: 0.23478783170811393
Validation loss: 2.8088738907915434

Epoch: 5| Step: 5
Training loss: 0.31055016186012396
Validation loss: 2.786990403093473

Epoch: 5| Step: 6
Training loss: 0.3220584087589451
Validation loss: 2.8565602440820443

Epoch: 5| Step: 7
Training loss: 0.428132816577475
Validation loss: 2.8784968146692567

Epoch: 5| Step: 8
Training loss: 0.39865132746296633
Validation loss: 2.8206671388784685

Epoch: 5| Step: 9
Training loss: 0.6537846624255157
Validation loss: 2.7586183172180125

Epoch: 5| Step: 10
Training loss: 0.5273837604179366
Validation loss: 2.8209165628927604

Epoch: 5| Step: 11
Training loss: 0.5842746026193039
Validation loss: 2.809324958986433

Epoch: 446| Step: 0
Training loss: 0.3318569848007624
Validation loss: 2.8617471780839434

Epoch: 5| Step: 1
Training loss: 0.5074721736514103
Validation loss: 2.966086152871525

Epoch: 5| Step: 2
Training loss: 0.3995416712530024
Validation loss: 2.981354974568639

Epoch: 5| Step: 3
Training loss: 0.4201411007681948
Validation loss: 2.922328145456769

Epoch: 5| Step: 4
Training loss: 0.6767588033297333
Validation loss: 2.943740661401103

Epoch: 5| Step: 5
Training loss: 0.32899888924509746
Validation loss: 2.900481731041397

Epoch: 5| Step: 6
Training loss: 0.3077947437180249
Validation loss: 2.845530790767337

Epoch: 5| Step: 7
Training loss: 0.3769894320539751
Validation loss: 2.825808596863207

Epoch: 5| Step: 8
Training loss: 0.4942049881704222
Validation loss: 2.8675421652206157

Epoch: 5| Step: 9
Training loss: 0.3916492005099344
Validation loss: 2.873129121911455

Epoch: 5| Step: 10
Training loss: 0.4603122414395913
Validation loss: 2.8894831146118283

Epoch: 5| Step: 11
Training loss: 0.38392147662809034
Validation loss: 2.900610887788629

Epoch: 447| Step: 0
Training loss: 0.4848992986449403
Validation loss: 2.843115854646223

Epoch: 5| Step: 1
Training loss: 0.413913304062521
Validation loss: 2.937539485909503

Epoch: 5| Step: 2
Training loss: 0.37537174872058343
Validation loss: 2.855125577094501

Epoch: 5| Step: 3
Training loss: 0.4083737468507594
Validation loss: 2.891341167089563

Epoch: 5| Step: 4
Training loss: 0.20840872155567394
Validation loss: 2.8251746614582465

Epoch: 5| Step: 5
Training loss: 0.2825212491112127
Validation loss: 2.7586993015506764

Epoch: 5| Step: 6
Training loss: 0.3533506693538287
Validation loss: 2.798826889815128

Epoch: 5| Step: 7
Training loss: 0.6503559825022296
Validation loss: 2.8401151629725394

Epoch: 5| Step: 8
Training loss: 0.46216402286950004
Validation loss: 2.7560434656187542

Epoch: 5| Step: 9
Training loss: 0.31754480776033905
Validation loss: 2.919415804110201

Epoch: 5| Step: 10
Training loss: 0.3120137007147414
Validation loss: 2.8765907931313466

Epoch: 5| Step: 11
Training loss: 0.36699789305713604
Validation loss: 2.808254884695734

Epoch: 448| Step: 0
Training loss: 0.2990555863692422
Validation loss: 2.84014936758972

Epoch: 5| Step: 1
Training loss: 0.3965683646102865
Validation loss: 2.7158521284342814

Epoch: 5| Step: 2
Training loss: 0.30810626675219804
Validation loss: 2.85111021870736

Epoch: 5| Step: 3
Training loss: 0.4470939973262701
Validation loss: 2.7879394635296713

Epoch: 5| Step: 4
Training loss: 0.6196270545108141
Validation loss: 2.7995098177392554

Epoch: 5| Step: 5
Training loss: 0.28841992431109925
Validation loss: 2.8455589814727977

Epoch: 5| Step: 6
Training loss: 0.49615129752803966
Validation loss: 2.82519346998172

Epoch: 5| Step: 7
Training loss: 0.2744532519828053
Validation loss: 2.916019617696704

Epoch: 5| Step: 8
Training loss: 0.3505142159803298
Validation loss: 2.8371876955065543

Epoch: 5| Step: 9
Training loss: 0.37825087272886254
Validation loss: 2.8042511879557193

Epoch: 5| Step: 10
Training loss: 0.42506195696647564
Validation loss: 2.765298314026005

Epoch: 5| Step: 11
Training loss: 0.6474729050670928
Validation loss: 2.8301957279093557

Epoch: 449| Step: 0
Training loss: 0.25180719274579066
Validation loss: 2.911243954012489

Epoch: 5| Step: 1
Training loss: 0.5070244175901727
Validation loss: 2.9296935696009174

Epoch: 5| Step: 2
Training loss: 0.26717017045066555
Validation loss: 2.9229167128436266

Epoch: 5| Step: 3
Training loss: 0.6220073338701807
Validation loss: 2.950491506369624

Epoch: 5| Step: 4
Training loss: 0.40975572921397024
Validation loss: 2.833502712983753

Epoch: 5| Step: 5
Training loss: 0.6750643240338301
Validation loss: 2.867367945786864

Epoch: 5| Step: 6
Training loss: 0.4086709330727864
Validation loss: 2.8002142551736875

Epoch: 5| Step: 7
Training loss: 0.47333342538192463
Validation loss: 2.726974969832952

Epoch: 5| Step: 8
Training loss: 0.39812872646869424
Validation loss: 2.79780022006502

Epoch: 5| Step: 9
Training loss: 0.4522637205863021
Validation loss: 2.7584269832336994

Epoch: 5| Step: 10
Training loss: 0.46290654344188237
Validation loss: 2.772229880029536

Epoch: 5| Step: 11
Training loss: 0.1626539447943546
Validation loss: 2.821238104339251

Epoch: 450| Step: 0
Training loss: 0.39813840148863006
Validation loss: 2.8680850953178543

Epoch: 5| Step: 1
Training loss: 0.44437996782404465
Validation loss: 2.8778141698833473

Epoch: 5| Step: 2
Training loss: 0.3950783175376889
Validation loss: 2.8257742643599557

Epoch: 5| Step: 3
Training loss: 0.4006025172335897
Validation loss: 2.848054583283613

Epoch: 5| Step: 4
Training loss: 0.3589465033112593
Validation loss: 2.847865904114021

Epoch: 5| Step: 5
Training loss: 0.46689395613276874
Validation loss: 2.7227239869428828

Epoch: 5| Step: 6
Training loss: 0.44213735747708066
Validation loss: 2.8031199013994303

Epoch: 5| Step: 7
Training loss: 0.3395315687631865
Validation loss: 2.8107221953863024

Epoch: 5| Step: 8
Training loss: 0.3134467565323963
Validation loss: 2.784915383986525

Epoch: 5| Step: 9
Training loss: 0.7032663415202849
Validation loss: 2.888889991447247

Epoch: 5| Step: 10
Training loss: 0.530056397928172
Validation loss: 2.876499234314853

Epoch: 5| Step: 11
Training loss: 0.3638226771095265
Validation loss: 2.8129790851725445

Epoch: 451| Step: 0
Training loss: 0.3661700823564804
Validation loss: 2.8461951548469373

Epoch: 5| Step: 1
Training loss: 0.7421265426498913
Validation loss: 2.8258428199704073

Epoch: 5| Step: 2
Training loss: 0.3924957872274003
Validation loss: 2.789311961496566

Epoch: 5| Step: 3
Training loss: 0.44156135939594526
Validation loss: 2.690986519368793

Epoch: 5| Step: 4
Training loss: 0.46247890527405283
Validation loss: 2.8304113977672323

Epoch: 5| Step: 5
Training loss: 0.3706489909353483
Validation loss: 2.874142498177609

Epoch: 5| Step: 6
Training loss: 0.3723157738834155
Validation loss: 2.8546271938780974

Epoch: 5| Step: 7
Training loss: 0.3211906885433094
Validation loss: 2.8684271783861566

Epoch: 5| Step: 8
Training loss: 0.30649790510096436
Validation loss: 2.7945125910166526

Epoch: 5| Step: 9
Training loss: 0.3001518352050826
Validation loss: 2.8712954859022424

Epoch: 5| Step: 10
Training loss: 0.27624991796673554
Validation loss: 2.806264832251418

Epoch: 5| Step: 11
Training loss: 0.4997252812276323
Validation loss: 2.814244449882121

Epoch: 452| Step: 0
Training loss: 0.2909753118665584
Validation loss: 2.821682034777546

Epoch: 5| Step: 1
Training loss: 0.32489085336219514
Validation loss: 2.8052376266935033

Epoch: 5| Step: 2
Training loss: 0.42547902921712927
Validation loss: 2.8430172147268804

Epoch: 5| Step: 3
Training loss: 0.3062540156237411
Validation loss: 2.7827067149991214

Epoch: 5| Step: 4
Training loss: 0.3798659646973451
Validation loss: 2.7260090649736983

Epoch: 5| Step: 5
Training loss: 0.709306669935454
Validation loss: 2.855622794905421

Epoch: 5| Step: 6
Training loss: 0.37330658345664786
Validation loss: 2.8129953442691082

Epoch: 5| Step: 7
Training loss: 0.3360189960011746
Validation loss: 2.8982740220736862

Epoch: 5| Step: 8
Training loss: 0.36284061083126873
Validation loss: 2.8762322252297117

Epoch: 5| Step: 9
Training loss: 0.3851857481642288
Validation loss: 2.7979785936953276

Epoch: 5| Step: 10
Training loss: 0.40268302242282894
Validation loss: 2.8741724474903996

Epoch: 5| Step: 11
Training loss: 0.3775130545651517
Validation loss: 2.818856826133841

Epoch: 453| Step: 0
Training loss: 0.4322236900044525
Validation loss: 2.7728318784453543

Epoch: 5| Step: 1
Training loss: 0.3113911865197155
Validation loss: 2.813575913240725

Epoch: 5| Step: 2
Training loss: 0.408199584069477
Validation loss: 2.79473488904389

Epoch: 5| Step: 3
Training loss: 0.2856728564181216
Validation loss: 2.8260335846665976

Epoch: 5| Step: 4
Training loss: 0.39066385075964205
Validation loss: 2.769948844471734

Epoch: 5| Step: 5
Training loss: 0.6533535206199582
Validation loss: 2.84228943076984

Epoch: 5| Step: 6
Training loss: 0.35603049191340885
Validation loss: 2.796797525764254

Epoch: 5| Step: 7
Training loss: 0.3457768033065367
Validation loss: 2.7214597848841957

Epoch: 5| Step: 8
Training loss: 0.4814576462719168
Validation loss: 2.868367672045465

Epoch: 5| Step: 9
Training loss: 0.3880308990538372
Validation loss: 2.7518449612711584

Epoch: 5| Step: 10
Training loss: 0.4036542789026887
Validation loss: 2.8352875293097535

Epoch: 5| Step: 11
Training loss: 0.1226023067925055
Validation loss: 2.878372294694791

Epoch: 454| Step: 0
Training loss: 0.687753175588783
Validation loss: 2.7990955829273014

Epoch: 5| Step: 1
Training loss: 0.3196827000269752
Validation loss: 2.8324879666078715

Epoch: 5| Step: 2
Training loss: 0.33516302213073657
Validation loss: 2.7869363796595206

Epoch: 5| Step: 3
Training loss: 0.42113456386735926
Validation loss: 2.846594875636112

Epoch: 5| Step: 4
Training loss: 0.37476397079983803
Validation loss: 2.8202674136516217

Epoch: 5| Step: 5
Training loss: 0.47151181094565575
Validation loss: 2.787347367730886

Epoch: 5| Step: 6
Training loss: 0.38183972290972495
Validation loss: 2.7595014074452955

Epoch: 5| Step: 7
Training loss: 0.39752575395034123
Validation loss: 2.84761667943601

Epoch: 5| Step: 8
Training loss: 0.3623916028177792
Validation loss: 2.834471836139255

Epoch: 5| Step: 9
Training loss: 0.3223389859940763
Validation loss: 2.824116920897167

Epoch: 5| Step: 10
Training loss: 0.28581660377898
Validation loss: 2.8469255728335026

Epoch: 5| Step: 11
Training loss: 0.38719970003478
Validation loss: 2.8434482630968865

Epoch: 455| Step: 0
Training loss: 0.37739835150595685
Validation loss: 2.7945302195232062

Epoch: 5| Step: 1
Training loss: 0.4537891092338975
Validation loss: 2.81055109882192

Epoch: 5| Step: 2
Training loss: 0.44950552369862073
Validation loss: 2.735443447811892

Epoch: 5| Step: 3
Training loss: 0.35582438693685575
Validation loss: 2.7821179082311365

Epoch: 5| Step: 4
Training loss: 0.45885904102428243
Validation loss: 2.7790833366822842

Epoch: 5| Step: 5
Training loss: 0.35210679623150626
Validation loss: 2.824714079034531

Epoch: 5| Step: 6
Training loss: 0.43448536932075554
Validation loss: 2.9090969880245554

Epoch: 5| Step: 7
Training loss: 0.7145960227425366
Validation loss: 2.8650233167816834

Epoch: 5| Step: 8
Training loss: 0.39244779634463317
Validation loss: 2.8560439790232217

Epoch: 5| Step: 9
Training loss: 0.3841267233616571
Validation loss: 2.8107522090213397

Epoch: 5| Step: 10
Training loss: 0.27293256732736587
Validation loss: 2.735861437815187

Epoch: 5| Step: 11
Training loss: 0.7298017914687059
Validation loss: 2.7462442771928393

Epoch: 456| Step: 0
Training loss: 0.4706663061913703
Validation loss: 2.776702556465934

Epoch: 5| Step: 1
Training loss: 0.24729701712207708
Validation loss: 2.7875106903977382

Epoch: 5| Step: 2
Training loss: 0.36384735299075815
Validation loss: 2.826982864688011

Epoch: 5| Step: 3
Training loss: 0.31369714314500874
Validation loss: 2.9343225968041806

Epoch: 5| Step: 4
Training loss: 0.4767536499141769
Validation loss: 2.904207917052291

Epoch: 5| Step: 5
Training loss: 0.4282026993071346
Validation loss: 2.796301543196003

Epoch: 5| Step: 6
Training loss: 0.42548107800395824
Validation loss: 2.7600326498894647

Epoch: 5| Step: 7
Training loss: 0.3034721367904015
Validation loss: 2.7734990216089503

Epoch: 5| Step: 8
Training loss: 0.37801502062835524
Validation loss: 2.7411638071692335

Epoch: 5| Step: 9
Training loss: 0.7913578752982559
Validation loss: 2.7039666381546947

Epoch: 5| Step: 10
Training loss: 0.5297796433684943
Validation loss: 2.6764407085464823

Epoch: 5| Step: 11
Training loss: 0.4624162971945161
Validation loss: 2.803269848860695

Epoch: 457| Step: 0
Training loss: 0.30096120529057924
Validation loss: 2.8485972729526647

Epoch: 5| Step: 1
Training loss: 0.3408944888130475
Validation loss: 2.9007204632460657

Epoch: 5| Step: 2
Training loss: 0.4282766762635021
Validation loss: 2.867562064253303

Epoch: 5| Step: 3
Training loss: 0.3125178570413764
Validation loss: 2.822967649658696

Epoch: 5| Step: 4
Training loss: 0.33342770144679706
Validation loss: 2.862460752215343

Epoch: 5| Step: 5
Training loss: 0.33539409823144295
Validation loss: 2.8534784438617615

Epoch: 5| Step: 6
Training loss: 0.4078121959933613
Validation loss: 2.828131895250096

Epoch: 5| Step: 7
Training loss: 0.7087052481514983
Validation loss: 2.8102508275895306

Epoch: 5| Step: 8
Training loss: 0.35128020502862656
Validation loss: 2.7700359205701064

Epoch: 5| Step: 9
Training loss: 0.245255716093433
Validation loss: 2.789693983522076

Epoch: 5| Step: 10
Training loss: 0.5412284900540598
Validation loss: 2.8855014207880867

Epoch: 5| Step: 11
Training loss: 0.3887340361761075
Validation loss: 2.839932128566481

Epoch: 458| Step: 0
Training loss: 0.449893875323898
Validation loss: 2.8600333868092047

Epoch: 5| Step: 1
Training loss: 0.4348018929296855
Validation loss: 2.8931697778703915

Epoch: 5| Step: 2
Training loss: 0.41547010590101413
Validation loss: 2.8594903592601235

Epoch: 5| Step: 3
Training loss: 0.28204337117784684
Validation loss: 2.8074641885395524

Epoch: 5| Step: 4
Training loss: 0.24186950233776386
Validation loss: 2.817985042774863

Epoch: 5| Step: 5
Training loss: 0.31064057286177027
Validation loss: 2.858237556228236

Epoch: 5| Step: 6
Training loss: 0.4030791108678721
Validation loss: 2.826926667734158

Epoch: 5| Step: 7
Training loss: 0.4704027444177565
Validation loss: 2.7456112071848007

Epoch: 5| Step: 8
Training loss: 0.38478223890655994
Validation loss: 2.7155289917228633

Epoch: 5| Step: 9
Training loss: 0.6679971700054458
Validation loss: 2.7995573177814146

Epoch: 5| Step: 10
Training loss: 0.31933860894348587
Validation loss: 2.937650135613466

Epoch: 5| Step: 11
Training loss: 0.47542241788701434
Validation loss: 2.881724290916051

Epoch: 459| Step: 0
Training loss: 0.372956629517417
Validation loss: 2.859850873416008

Epoch: 5| Step: 1
Training loss: 0.3450372392832332
Validation loss: 2.8908123642967443

Epoch: 5| Step: 2
Training loss: 0.6677350979666402
Validation loss: 2.7780997190408656

Epoch: 5| Step: 3
Training loss: 0.2940669900995263
Validation loss: 2.80871272288294

Epoch: 5| Step: 4
Training loss: 0.35271508638316684
Validation loss: 2.7446408504815936

Epoch: 5| Step: 5
Training loss: 0.366731522885828
Validation loss: 2.8148583979194184

Epoch: 5| Step: 6
Training loss: 0.3023612645716919
Validation loss: 2.8290171559613557

Epoch: 5| Step: 7
Training loss: 0.41461817325035605
Validation loss: 2.845639858445843

Epoch: 5| Step: 8
Training loss: 0.2974167698952355
Validation loss: 2.7578685527864994

Epoch: 5| Step: 9
Training loss: 0.24850669053298818
Validation loss: 2.798261660999821

Epoch: 5| Step: 10
Training loss: 0.3222904080196003
Validation loss: 2.7633305351184103

Epoch: 5| Step: 11
Training loss: 0.16016510031832662
Validation loss: 2.8779454864561904

Epoch: 460| Step: 0
Training loss: 0.2646162710313322
Validation loss: 2.8123081848290927

Epoch: 5| Step: 1
Training loss: 0.6252563189385892
Validation loss: 2.7595458324512117

Epoch: 5| Step: 2
Training loss: 0.35048340384553844
Validation loss: 2.762728143782129

Epoch: 5| Step: 3
Training loss: 0.33951199441404945
Validation loss: 2.8126951114652794

Epoch: 5| Step: 4
Training loss: 0.41279479965623356
Validation loss: 2.7580974889080925

Epoch: 5| Step: 5
Training loss: 0.34108891873819713
Validation loss: 2.8432091104238317

Epoch: 5| Step: 6
Training loss: 0.27834468534061263
Validation loss: 2.79837178114602

Epoch: 5| Step: 7
Training loss: 0.41601881285686243
Validation loss: 2.7537687082415614

Epoch: 5| Step: 8
Training loss: 0.44164281599256094
Validation loss: 2.7576106810815535

Epoch: 5| Step: 9
Training loss: 0.4062330902688496
Validation loss: 2.7823850587237757

Epoch: 5| Step: 10
Training loss: 0.4526013275104259
Validation loss: 2.8212204596150836

Epoch: 5| Step: 11
Training loss: 0.37780765662863286
Validation loss: 2.8407117242167925

Epoch: 461| Step: 0
Training loss: 0.44385227247131054
Validation loss: 2.933850852377074

Epoch: 5| Step: 1
Training loss: 0.3463798515815677
Validation loss: 2.80667290152456

Epoch: 5| Step: 2
Training loss: 0.3200011251847036
Validation loss: 2.817821124364262

Epoch: 5| Step: 3
Training loss: 0.18833576141398561
Validation loss: 2.801385531462603

Epoch: 5| Step: 4
Training loss: 0.46793990070149577
Validation loss: 2.745128203190908

Epoch: 5| Step: 5
Training loss: 0.2769685275552419
Validation loss: 2.806234515741416

Epoch: 5| Step: 6
Training loss: 0.3858433458019181
Validation loss: 2.724270298868226

Epoch: 5| Step: 7
Training loss: 0.2485729705882318
Validation loss: 2.751404631124238

Epoch: 5| Step: 8
Training loss: 0.7545041100381854
Validation loss: 2.8104437163408336

Epoch: 5| Step: 9
Training loss: 0.42216970605292004
Validation loss: 2.8682520186926617

Epoch: 5| Step: 10
Training loss: 0.295059904425254
Validation loss: 2.812895775251561

Epoch: 5| Step: 11
Training loss: 0.27132509897149937
Validation loss: 2.856841881331314

Epoch: 462| Step: 0
Training loss: 0.4840487181078827
Validation loss: 2.837426221339294

Epoch: 5| Step: 1
Training loss: 0.32059696405839017
Validation loss: 2.8271332823281816

Epoch: 5| Step: 2
Training loss: 0.32379593913557847
Validation loss: 2.693184972127627

Epoch: 5| Step: 3
Training loss: 0.3028449318114546
Validation loss: 2.768117675737108

Epoch: 5| Step: 4
Training loss: 0.1653003148471842
Validation loss: 2.7831511732461696

Epoch: 5| Step: 5
Training loss: 0.6717703094535588
Validation loss: 2.748583121577822

Epoch: 5| Step: 6
Training loss: 0.3975049306155848
Validation loss: 2.846705776507273

Epoch: 5| Step: 7
Training loss: 0.30012063144235585
Validation loss: 2.765210050499341

Epoch: 5| Step: 8
Training loss: 0.1652579915189046
Validation loss: 2.7913660176969843

Epoch: 5| Step: 9
Training loss: 0.4448091439499343
Validation loss: 2.8447002597810287

Epoch: 5| Step: 10
Training loss: 0.25582102131392237
Validation loss: 2.8035275000560373

Epoch: 5| Step: 11
Training loss: 0.26786895595341376
Validation loss: 2.7899783684975525

Epoch: 463| Step: 0
Training loss: 0.36442007996453535
Validation loss: 2.778889797599192

Epoch: 5| Step: 1
Training loss: 0.3593060800559763
Validation loss: 2.760762039507213

Epoch: 5| Step: 2
Training loss: 0.3611524825157496
Validation loss: 2.798935967315669

Epoch: 5| Step: 3
Training loss: 0.3333461418770547
Validation loss: 2.814707927830904

Epoch: 5| Step: 4
Training loss: 0.6385425588364044
Validation loss: 2.8597880101666284

Epoch: 5| Step: 5
Training loss: 0.40858076961168677
Validation loss: 2.8835771816331985

Epoch: 5| Step: 6
Training loss: 0.2969112123187717
Validation loss: 2.8463031988766416

Epoch: 5| Step: 7
Training loss: 0.3565760960439914
Validation loss: 2.809256594365309

Epoch: 5| Step: 8
Training loss: 0.3388876455326323
Validation loss: 2.7962141339533226

Epoch: 5| Step: 9
Training loss: 0.3982966679027837
Validation loss: 2.7906714321259214

Epoch: 5| Step: 10
Training loss: 0.34250455346874425
Validation loss: 2.868713592957608

Epoch: 5| Step: 11
Training loss: 0.4555479906618355
Validation loss: 2.787059092897914

Epoch: 464| Step: 0
Training loss: 0.2765919071662359
Validation loss: 2.869677471558913

Epoch: 5| Step: 1
Training loss: 0.4287251185546085
Validation loss: 2.7948320837767833

Epoch: 5| Step: 2
Training loss: 0.37024137079407565
Validation loss: 2.882863045157153

Epoch: 5| Step: 3
Training loss: 0.2774602081362281
Validation loss: 2.897300788645777

Epoch: 5| Step: 4
Training loss: 0.24858651070930474
Validation loss: 2.894911318531417

Epoch: 5| Step: 5
Training loss: 0.34677418240325736
Validation loss: 2.8074837526319487

Epoch: 5| Step: 6
Training loss: 0.47296427313478834
Validation loss: 2.857812816049076

Epoch: 5| Step: 7
Training loss: 0.2497999463738719
Validation loss: 2.8568173175508456

Epoch: 5| Step: 8
Training loss: 0.38052694044095214
Validation loss: 2.833257079267049

Epoch: 5| Step: 9
Training loss: 0.6140925392782265
Validation loss: 2.8358023500071763

Epoch: 5| Step: 10
Training loss: 0.28506497006474224
Validation loss: 2.830059071633117

Epoch: 5| Step: 11
Training loss: 0.3378118081310714
Validation loss: 2.8004157778021432

Epoch: 465| Step: 0
Training loss: 0.3452505176893879
Validation loss: 2.8312832986867877

Epoch: 5| Step: 1
Training loss: 0.4906734612701074
Validation loss: 2.8324646927197787

Epoch: 5| Step: 2
Training loss: 0.36962386698544347
Validation loss: 2.798773733756536

Epoch: 5| Step: 3
Training loss: 0.31099694704507586
Validation loss: 2.890689866309029

Epoch: 5| Step: 4
Training loss: 0.3398950253094254
Validation loss: 2.8043818878453113

Epoch: 5| Step: 5
Training loss: 0.379968138381713
Validation loss: 2.8512807593664764

Epoch: 5| Step: 6
Training loss: 0.25925122145619767
Validation loss: 2.822957476125029

Epoch: 5| Step: 7
Training loss: 0.43949062611257866
Validation loss: 2.8609980717234387

Epoch: 5| Step: 8
Training loss: 0.29458207013256377
Validation loss: 2.7936694637811503

Epoch: 5| Step: 9
Training loss: 0.5889888656693967
Validation loss: 2.837286720158593

Epoch: 5| Step: 10
Training loss: 0.3163100084471622
Validation loss: 2.8554401596314896

Epoch: 5| Step: 11
Training loss: 0.419652968070366
Validation loss: 2.8288230104867322

Epoch: 466| Step: 0
Training loss: 0.42456668895382843
Validation loss: 2.822193360420974

Epoch: 5| Step: 1
Training loss: 0.36095605199786385
Validation loss: 2.822484234325752

Epoch: 5| Step: 2
Training loss: 0.4535758307922388
Validation loss: 2.8226262971999434

Epoch: 5| Step: 3
Training loss: 0.2579535040922231
Validation loss: 2.785372236596984

Epoch: 5| Step: 4
Training loss: 0.3603924363688445
Validation loss: 2.813874883502861

Epoch: 5| Step: 5
Training loss: 0.4620668509386974
Validation loss: 2.8793321015894184

Epoch: 5| Step: 6
Training loss: 0.19447532524015979
Validation loss: 2.851208812082213

Epoch: 5| Step: 7
Training loss: 0.6416114098012393
Validation loss: 2.896312750552416

Epoch: 5| Step: 8
Training loss: 0.44691288460688894
Validation loss: 2.8121841677185926

Epoch: 5| Step: 9
Training loss: 0.26106022786801714
Validation loss: 2.859497203195868

Epoch: 5| Step: 10
Training loss: 0.31735329123897377
Validation loss: 2.7384727835501605

Epoch: 5| Step: 11
Training loss: 0.24241914745767063
Validation loss: 2.792331366736474

Epoch: 467| Step: 0
Training loss: 0.4189587037407167
Validation loss: 2.7518617981700815

Epoch: 5| Step: 1
Training loss: 0.38530619644738645
Validation loss: 2.7562906769009343

Epoch: 5| Step: 2
Training loss: 0.3317962488034247
Validation loss: 2.847514448573001

Epoch: 5| Step: 3
Training loss: 0.2853569213029795
Validation loss: 2.832993382975262

Epoch: 5| Step: 4
Training loss: 0.39593102688454523
Validation loss: 2.8460901817950726

Epoch: 5| Step: 5
Training loss: 0.6318393571575374
Validation loss: 2.8356021300984042

Epoch: 5| Step: 6
Training loss: 0.34864557066581653
Validation loss: 2.8135900327801604

Epoch: 5| Step: 7
Training loss: 0.423532514715632
Validation loss: 2.8348944491181483

Epoch: 5| Step: 8
Training loss: 0.37052114379257794
Validation loss: 2.804699588703537

Epoch: 5| Step: 9
Training loss: 0.36446849058741054
Validation loss: 2.7826702727709667

Epoch: 5| Step: 10
Training loss: 0.3691550761628579
Validation loss: 2.7611987763375656

Epoch: 5| Step: 11
Training loss: 0.36472409346693563
Validation loss: 2.7983177733107056

Epoch: 468| Step: 0
Training loss: 0.3356572912086566
Validation loss: 2.8756388959857735

Epoch: 5| Step: 1
Training loss: 0.6903444531610569
Validation loss: 2.797750478075732

Epoch: 5| Step: 2
Training loss: 0.32544584046239117
Validation loss: 2.888902408668068

Epoch: 5| Step: 3
Training loss: 0.28580987823404985
Validation loss: 2.831709593998903

Epoch: 5| Step: 4
Training loss: 0.3299712397404406
Validation loss: 2.8348749059890195

Epoch: 5| Step: 5
Training loss: 0.4089750082989194
Validation loss: 2.7941488622736594

Epoch: 5| Step: 6
Training loss: 0.34150880936071837
Validation loss: 2.7996104323492177

Epoch: 5| Step: 7
Training loss: 0.3340066266594594
Validation loss: 2.799190663693559

Epoch: 5| Step: 8
Training loss: 0.3667209380076035
Validation loss: 2.8446119804629166

Epoch: 5| Step: 9
Training loss: 0.36993381517227886
Validation loss: 2.868033364902598

Epoch: 5| Step: 10
Training loss: 0.3419208737652295
Validation loss: 2.84216511755839

Epoch: 5| Step: 11
Training loss: 0.21737287658029386
Validation loss: 2.8509169557664613

Epoch: 469| Step: 0
Training loss: 0.3212391892888873
Validation loss: 2.871318048897793

Epoch: 5| Step: 1
Training loss: 0.4028417967566317
Validation loss: 2.8891676794739314

Epoch: 5| Step: 2
Training loss: 0.3139166312924446
Validation loss: 2.8674570246244557

Epoch: 5| Step: 3
Training loss: 0.26793507622987756
Validation loss: 2.800929542208726

Epoch: 5| Step: 4
Training loss: 0.4283709209582985
Validation loss: 2.9091814119458306

Epoch: 5| Step: 5
Training loss: 0.40361228516329084
Validation loss: 2.8208670454015805

Epoch: 5| Step: 6
Training loss: 0.2613146494768117
Validation loss: 2.942931972996572

Epoch: 5| Step: 7
Training loss: 0.45099200341648477
Validation loss: 2.8472523588172503

Epoch: 5| Step: 8
Training loss: 0.3843177861377301
Validation loss: 2.8868589904885216

Epoch: 5| Step: 9
Training loss: 0.5400891686039768
Validation loss: 2.8315869423493667

Epoch: 5| Step: 10
Training loss: 0.7115002595119579
Validation loss: 2.867299019691555

Epoch: 5| Step: 11
Training loss: 0.23322634557392474
Validation loss: 2.78529195646624

Epoch: 470| Step: 0
Training loss: 0.4491731537608193
Validation loss: 3.001670696711937

Epoch: 5| Step: 1
Training loss: 0.4314014583488719
Validation loss: 2.842529073206979

Epoch: 5| Step: 2
Training loss: 0.29096674668666445
Validation loss: 2.9034319070377523

Epoch: 5| Step: 3
Training loss: 0.3527945757554074
Validation loss: 2.7706722927381353

Epoch: 5| Step: 4
Training loss: 0.7185603181743321
Validation loss: 2.78744997341728

Epoch: 5| Step: 5
Training loss: 0.37615696926037084
Validation loss: 2.7636384168920314

Epoch: 5| Step: 6
Training loss: 0.44302632934847036
Validation loss: 2.8105352603406386

Epoch: 5| Step: 7
Training loss: 0.4243501709035721
Validation loss: 2.81256298771721

Epoch: 5| Step: 8
Training loss: 0.43507383514662207
Validation loss: 2.8509243743225254

Epoch: 5| Step: 9
Training loss: 0.3280126969842729
Validation loss: 2.8816211964715577

Epoch: 5| Step: 10
Training loss: 0.36808322656526427
Validation loss: 2.848610622566744

Epoch: 5| Step: 11
Training loss: 0.09104307603872702
Validation loss: 2.8112773180242527

Epoch: 471| Step: 0
Training loss: 0.3230034560300627
Validation loss: 2.824723546390067

Epoch: 5| Step: 1
Training loss: 0.4177829472055572
Validation loss: 2.8515150405905847

Epoch: 5| Step: 2
Training loss: 0.32349099209860066
Validation loss: 2.870574959661327

Epoch: 5| Step: 3
Training loss: 0.2659136942373864
Validation loss: 2.8101820330072895

Epoch: 5| Step: 4
Training loss: 0.43992477537976327
Validation loss: 2.8393494421998016

Epoch: 5| Step: 5
Training loss: 0.6536375909009519
Validation loss: 2.8272815064697965

Epoch: 5| Step: 6
Training loss: 0.38067262423630693
Validation loss: 2.8034991737220727

Epoch: 5| Step: 7
Training loss: 0.3480362904455869
Validation loss: 2.773300883908741

Epoch: 5| Step: 8
Training loss: 0.3098069017961478
Validation loss: 2.8101321213264074

Epoch: 5| Step: 9
Training loss: 0.312653194071311
Validation loss: 2.7965605646049214

Epoch: 5| Step: 10
Training loss: 0.35593145249799796
Validation loss: 2.8271375516463384

Epoch: 5| Step: 11
Training loss: 0.5578251065237484
Validation loss: 2.821707282885609

Epoch: 472| Step: 0
Training loss: 0.2859103539093411
Validation loss: 2.8326316214661484

Epoch: 5| Step: 1
Training loss: 0.4625753463767323
Validation loss: 2.8176806772300336

Epoch: 5| Step: 2
Training loss: 0.4428266778478568
Validation loss: 2.8997222267228677

Epoch: 5| Step: 3
Training loss: 0.36390226873805454
Validation loss: 2.780892581333301

Epoch: 5| Step: 4
Training loss: 0.4296121878080103
Validation loss: 2.779927349982317

Epoch: 5| Step: 5
Training loss: 0.37192494513799784
Validation loss: 2.7926101987946885

Epoch: 5| Step: 6
Training loss: 0.41023404428137816
Validation loss: 2.807348124562129

Epoch: 5| Step: 7
Training loss: 0.2848543894795324
Validation loss: 2.754730811800057

Epoch: 5| Step: 8
Training loss: 0.35681189929526047
Validation loss: 2.7428643603965526

Epoch: 5| Step: 9
Training loss: 0.7425314658333918
Validation loss: 2.8392429372147596

Epoch: 5| Step: 10
Training loss: 0.25567830208566716
Validation loss: 2.7473128512658156

Epoch: 5| Step: 11
Training loss: 0.25224030562260713
Validation loss: 2.8372627118472065

Epoch: 473| Step: 0
Training loss: 0.3328967650392696
Validation loss: 2.818788181675069

Epoch: 5| Step: 1
Training loss: 0.6303621582532606
Validation loss: 2.8140643078679775

Epoch: 5| Step: 2
Training loss: 0.4669755729294781
Validation loss: 2.849434655288745

Epoch: 5| Step: 3
Training loss: 0.342411937443223
Validation loss: 2.827715462947536

Epoch: 5| Step: 4
Training loss: 0.2684783827143995
Validation loss: 2.80867910454392

Epoch: 5| Step: 5
Training loss: 0.2708507388586354
Validation loss: 2.822825903096146

Epoch: 5| Step: 6
Training loss: 0.3699845854022671
Validation loss: 2.8497245125608965

Epoch: 5| Step: 7
Training loss: 0.4038384090980473
Validation loss: 2.7983554530580634

Epoch: 5| Step: 8
Training loss: 0.3803190457698368
Validation loss: 2.778476167675131

Epoch: 5| Step: 9
Training loss: 0.3367626236834192
Validation loss: 2.79252379103054

Epoch: 5| Step: 10
Training loss: 0.34662024834653854
Validation loss: 2.844271049692765

Epoch: 5| Step: 11
Training loss: 0.27352959580576613
Validation loss: 2.823189923948352

Epoch: 474| Step: 0
Training loss: 0.41174528119707515
Validation loss: 2.910712439449816

Epoch: 5| Step: 1
Training loss: 0.5426131257096093
Validation loss: 2.9105293734514963

Epoch: 5| Step: 2
Training loss: 0.284484201989902
Validation loss: 2.798044237356342

Epoch: 5| Step: 3
Training loss: 0.6214786272724251
Validation loss: 2.8593327844001375

Epoch: 5| Step: 4
Training loss: 0.36424241020631604
Validation loss: 2.8049418830800787

Epoch: 5| Step: 5
Training loss: 0.4232509568119669
Validation loss: 2.808830463477523

Epoch: 5| Step: 6
Training loss: 0.32213205979781795
Validation loss: 2.7469529480447363

Epoch: 5| Step: 7
Training loss: 0.3090957831386366
Validation loss: 2.759116483180334

Epoch: 5| Step: 8
Training loss: 0.3716910524379732
Validation loss: 2.870075995223312

Epoch: 5| Step: 9
Training loss: 0.42121192250653544
Validation loss: 2.8248385447948223

Epoch: 5| Step: 10
Training loss: 0.34445658586216554
Validation loss: 2.869285647347741

Epoch: 5| Step: 11
Training loss: 0.23949890445864822
Validation loss: 2.8373312139515146

Epoch: 475| Step: 0
Training loss: 0.29811048666297246
Validation loss: 2.922748214197977

Epoch: 5| Step: 1
Training loss: 0.6456475964974353
Validation loss: 2.838603987869993

Epoch: 5| Step: 2
Training loss: 0.2902691631595354
Validation loss: 2.8906077960078025

Epoch: 5| Step: 3
Training loss: 0.1967872825365477
Validation loss: 2.8063842047508007

Epoch: 5| Step: 4
Training loss: 0.3245244251281099
Validation loss: 2.869810766628466

Epoch: 5| Step: 5
Training loss: 0.2985547005367513
Validation loss: 2.8030304294936847

Epoch: 5| Step: 6
Training loss: 0.3253076147506011
Validation loss: 2.8808056152845003

Epoch: 5| Step: 7
Training loss: 0.24999669937100727
Validation loss: 2.823577157250232

Epoch: 5| Step: 8
Training loss: 0.46032169392423583
Validation loss: 2.837067413124807

Epoch: 5| Step: 9
Training loss: 0.3159662884840916
Validation loss: 2.863819812399374

Epoch: 5| Step: 10
Training loss: 0.303617959954257
Validation loss: 2.8662623299578738

Epoch: 5| Step: 11
Training loss: 0.09717462986489679
Validation loss: 2.78588390430723

Epoch: 476| Step: 0
Training loss: 0.3880037862971487
Validation loss: 2.8226002003172526

Epoch: 5| Step: 1
Training loss: 0.4070517624502353
Validation loss: 2.7762333921221716

Epoch: 5| Step: 2
Training loss: 0.35693158985415596
Validation loss: 2.836639426020648

Epoch: 5| Step: 3
Training loss: 0.2693566295705813
Validation loss: 2.8091442009106635

Epoch: 5| Step: 4
Training loss: 0.32107232850729256
Validation loss: 2.864246602930105

Epoch: 5| Step: 5
Training loss: 0.4209120144170003
Validation loss: 2.9368680483886034

Epoch: 5| Step: 6
Training loss: 0.6284435536734642
Validation loss: 2.866278432368719

Epoch: 5| Step: 7
Training loss: 0.3482333761438715
Validation loss: 2.8002597601777546

Epoch: 5| Step: 8
Training loss: 0.3284779761804869
Validation loss: 2.859155187860801

Epoch: 5| Step: 9
Training loss: 0.33795538044735574
Validation loss: 2.8377125967096557

Epoch: 5| Step: 10
Training loss: 0.3001847358979825
Validation loss: 2.8908049278278596

Epoch: 5| Step: 11
Training loss: 0.20863298482910994
Validation loss: 2.834525570415245

Epoch: 477| Step: 0
Training loss: 0.4512978084895174
Validation loss: 2.876681675636047

Epoch: 5| Step: 1
Training loss: 0.41441297992856513
Validation loss: 2.912251186521135

Epoch: 5| Step: 2
Training loss: 0.4906416033711398
Validation loss: 2.8808913200029704

Epoch: 5| Step: 3
Training loss: 0.31142609369855
Validation loss: 2.832511303433846

Epoch: 5| Step: 4
Training loss: 0.4386495915746141
Validation loss: 2.796790933322359

Epoch: 5| Step: 5
Training loss: 0.3667443624815971
Validation loss: 2.778155337476629

Epoch: 5| Step: 6
Training loss: 0.45258703854207266
Validation loss: 2.7541986549201116

Epoch: 5| Step: 7
Training loss: 0.3282653644609214
Validation loss: 2.800211190024823

Epoch: 5| Step: 8
Training loss: 0.36305200870726834
Validation loss: 2.8589836071611194

Epoch: 5| Step: 9
Training loss: 0.3179745132336391
Validation loss: 2.785025990825438

Epoch: 5| Step: 10
Training loss: 0.7252935177128241
Validation loss: 2.8703171040749487

Epoch: 5| Step: 11
Training loss: 0.33430648351287917
Validation loss: 2.869498756585453

Epoch: 478| Step: 0
Training loss: 0.31901925392626
Validation loss: 2.8542179337419595

Epoch: 5| Step: 1
Training loss: 0.2527014685880604
Validation loss: 2.8471329098678257

Epoch: 5| Step: 2
Training loss: 0.34088662057211805
Validation loss: 2.8143683267878967

Epoch: 5| Step: 3
Training loss: 0.44994161743683697
Validation loss: 2.7321209836162006

Epoch: 5| Step: 4
Training loss: 0.2568117717789226
Validation loss: 2.83733917570394

Epoch: 5| Step: 5
Training loss: 0.5861037717779533
Validation loss: 2.8360489367124226

Epoch: 5| Step: 6
Training loss: 0.3911204438619266
Validation loss: 2.848786020501747

Epoch: 5| Step: 7
Training loss: 0.29523013596167774
Validation loss: 2.889579412012573

Epoch: 5| Step: 8
Training loss: 0.3821571150559453
Validation loss: 2.8963573871263777

Epoch: 5| Step: 9
Training loss: 0.3994165247908898
Validation loss: 2.8209020081297433

Epoch: 5| Step: 10
Training loss: 0.23498591435352653
Validation loss: 2.777639374198977

Epoch: 5| Step: 11
Training loss: 0.18725443694010857
Validation loss: 2.8126129904761967

Epoch: 479| Step: 0
Training loss: 0.3326357331764467
Validation loss: 2.7935728686885963

Epoch: 5| Step: 1
Training loss: 0.3994905729625808
Validation loss: 2.879322851741208

Epoch: 5| Step: 2
Training loss: 0.3455023748423859
Validation loss: 2.856504486427454

Epoch: 5| Step: 3
Training loss: 0.24923555652308935
Validation loss: 2.834676618134976

Epoch: 5| Step: 4
Training loss: 0.6496344400365563
Validation loss: 2.8687031453280976

Epoch: 5| Step: 5
Training loss: 0.32750631087898396
Validation loss: 2.855079112885858

Epoch: 5| Step: 6
Training loss: 0.3340261890492997
Validation loss: 2.8019167816316686

Epoch: 5| Step: 7
Training loss: 0.2399792828782441
Validation loss: 2.7135988523543264

Epoch: 5| Step: 8
Training loss: 0.30349375328095857
Validation loss: 2.8539197645573138

Epoch: 5| Step: 9
Training loss: 0.3176462107515389
Validation loss: 2.838978026327769

Epoch: 5| Step: 10
Training loss: 0.34837748690683507
Validation loss: 2.856442693725429

Epoch: 5| Step: 11
Training loss: 0.3312082187825792
Validation loss: 2.8301999680375935

Epoch: 480| Step: 0
Training loss: 0.3725372748318548
Validation loss: 2.818383967309267

Epoch: 5| Step: 1
Training loss: 0.4101146495248964
Validation loss: 2.812750564999182

Epoch: 5| Step: 2
Training loss: 0.2781081344548534
Validation loss: 2.777470109643115

Epoch: 5| Step: 3
Training loss: 0.2757584975801738
Validation loss: 2.8731892695474355

Epoch: 5| Step: 4
Training loss: 0.6743026831443816
Validation loss: 2.8508451212624695

Epoch: 5| Step: 5
Training loss: 0.3077023948250496
Validation loss: 2.827390730011557

Epoch: 5| Step: 6
Training loss: 0.2214576516689696
Validation loss: 2.858828779068358

Epoch: 5| Step: 7
Training loss: 0.2978449961454414
Validation loss: 2.760156598825772

Epoch: 5| Step: 8
Training loss: 0.3180095412124525
Validation loss: 2.7311274616677843

Epoch: 5| Step: 9
Training loss: 0.34297810934934503
Validation loss: 2.7727229205188335

Epoch: 5| Step: 10
Training loss: 0.2695058174850112
Validation loss: 2.7082590545347527

Epoch: 5| Step: 11
Training loss: 0.19802443285009524
Validation loss: 2.7979147628205827

Epoch: 481| Step: 0
Training loss: 0.26987681143798986
Validation loss: 2.865125616358883

Epoch: 5| Step: 1
Training loss: 0.5970872401819325
Validation loss: 2.768360620477474

Epoch: 5| Step: 2
Training loss: 0.2752956740729164
Validation loss: 2.94158660754514

Epoch: 5| Step: 3
Training loss: 0.2419278152353462
Validation loss: 2.8085416029402914

Epoch: 5| Step: 4
Training loss: 0.32140621843648487
Validation loss: 2.817394984244902

Epoch: 5| Step: 5
Training loss: 0.370738833509424
Validation loss: 2.8073602124245984

Epoch: 5| Step: 6
Training loss: 0.3916243168410629
Validation loss: 2.8043514429367904

Epoch: 5| Step: 7
Training loss: 0.3210387022627099
Validation loss: 2.838229221098473

Epoch: 5| Step: 8
Training loss: 0.33705165099189655
Validation loss: 2.7413819335253318

Epoch: 5| Step: 9
Training loss: 0.3240053669660128
Validation loss: 2.755222761600745

Epoch: 5| Step: 10
Training loss: 0.34028454398653124
Validation loss: 2.7654651732159135

Epoch: 5| Step: 11
Training loss: 0.41188813548929165
Validation loss: 2.7964910851078493

Epoch: 482| Step: 0
Training loss: 0.2465859214551384
Validation loss: 2.7702005148922155

Epoch: 5| Step: 1
Training loss: 0.3742104204879461
Validation loss: 2.778400794071987

Epoch: 5| Step: 2
Training loss: 0.1894898329891081
Validation loss: 2.8050491503626938

Epoch: 5| Step: 3
Training loss: 0.24376590964163347
Validation loss: 2.8422642029710414

Epoch: 5| Step: 4
Training loss: 0.4956774128527353
Validation loss: 2.8426149848958495

Epoch: 5| Step: 5
Training loss: 0.4019032261073772
Validation loss: 2.8513209898240515

Epoch: 5| Step: 6
Training loss: 0.567711975949235
Validation loss: 2.793134041543438

Epoch: 5| Step: 7
Training loss: 0.3624058913702546
Validation loss: 2.7410658836604513

Epoch: 5| Step: 8
Training loss: 0.455888673025546
Validation loss: 2.7704358544796555

Epoch: 5| Step: 9
Training loss: 0.3873807462110358
Validation loss: 2.7396600710101793

Epoch: 5| Step: 10
Training loss: 0.42047717615797475
Validation loss: 2.8083080417011113

Epoch: 5| Step: 11
Training loss: 0.3411267823682596
Validation loss: 2.8950904378122946

Epoch: 483| Step: 0
Training loss: 0.36542811839400396
Validation loss: 2.831729281758338

Epoch: 5| Step: 1
Training loss: 0.46647059637320054
Validation loss: 2.8674977902961247

Epoch: 5| Step: 2
Training loss: 0.3186288407005596
Validation loss: 2.864744779487769

Epoch: 5| Step: 3
Training loss: 0.34089613893498283
Validation loss: 2.8515343338084813

Epoch: 5| Step: 4
Training loss: 0.47267879085544945
Validation loss: 2.780465234988446

Epoch: 5| Step: 5
Training loss: 0.4608337317867982
Validation loss: 2.8377049965826355

Epoch: 5| Step: 6
Training loss: 0.6735072380829603
Validation loss: 2.846906429833318

Epoch: 5| Step: 7
Training loss: 0.28121570537015633
Validation loss: 2.787561409819789

Epoch: 5| Step: 8
Training loss: 0.3867120067894772
Validation loss: 2.8735762712837145

Epoch: 5| Step: 9
Training loss: 0.29199721418155744
Validation loss: 2.862934495747043

Epoch: 5| Step: 10
Training loss: 0.4286099186711272
Validation loss: 2.8454817958786394

Epoch: 5| Step: 11
Training loss: 0.5971514496035158
Validation loss: 2.843220413417215

Epoch: 484| Step: 0
Training loss: 0.39749906389857975
Validation loss: 2.838965954116115

Epoch: 5| Step: 1
Training loss: 0.46079221149082034
Validation loss: 2.8499703408532846

Epoch: 5| Step: 2
Training loss: 0.30697382906875204
Validation loss: 2.7609488436097616

Epoch: 5| Step: 3
Training loss: 0.32123782088426495
Validation loss: 2.7981833056556296

Epoch: 5| Step: 4
Training loss: 0.41722572094429117
Validation loss: 2.8327987087031175

Epoch: 5| Step: 5
Training loss: 0.2563799011295791
Validation loss: 2.7918896740238193

Epoch: 5| Step: 6
Training loss: 0.3869100155491163
Validation loss: 2.7538386631961984

Epoch: 5| Step: 7
Training loss: 0.43442627309167126
Validation loss: 2.814323717045834

Epoch: 5| Step: 8
Training loss: 0.4072195734023481
Validation loss: 2.8329403314856485

Epoch: 5| Step: 9
Training loss: 0.348290850052232
Validation loss: 2.8376486548864803

Epoch: 5| Step: 10
Training loss: 0.7035394718548992
Validation loss: 2.7911080517957947

Epoch: 5| Step: 11
Training loss: 0.32585679328753614
Validation loss: 2.8781776765799845

Epoch: 485| Step: 0
Training loss: 0.4172758080390382
Validation loss: 2.7406815200075454

Epoch: 5| Step: 1
Training loss: 0.40342561395511783
Validation loss: 2.7863016149829463

Epoch: 5| Step: 2
Training loss: 0.3134580470050919
Validation loss: 2.827201411443285

Epoch: 5| Step: 3
Training loss: 0.37930226032429404
Validation loss: 2.8973257600927

Epoch: 5| Step: 4
Training loss: 0.34799892167973895
Validation loss: 2.8214494451207113

Epoch: 5| Step: 5
Training loss: 0.3860082553761466
Validation loss: 2.808057200574664

Epoch: 5| Step: 6
Training loss: 0.2873952182271435
Validation loss: 2.79472633138054

Epoch: 5| Step: 7
Training loss: 0.432124164792358
Validation loss: 2.75080433916815

Epoch: 5| Step: 8
Training loss: 0.6315110799779391
Validation loss: 2.8070928129259105

Epoch: 5| Step: 9
Training loss: 0.5081698407497014
Validation loss: 2.774216401953112

Epoch: 5| Step: 10
Training loss: 0.376815414969172
Validation loss: 2.804402297031423

Epoch: 5| Step: 11
Training loss: 0.3842632480154298
Validation loss: 2.8383018089002756

Epoch: 486| Step: 0
Training loss: 0.4259020082907833
Validation loss: 2.8789867250123864

Epoch: 5| Step: 1
Training loss: 0.4021154329930488
Validation loss: 2.8690297845664148

Epoch: 5| Step: 2
Training loss: 0.22549606778994183
Validation loss: 2.7691086310799706

Epoch: 5| Step: 3
Training loss: 0.40547373774112294
Validation loss: 2.780168619559475

Epoch: 5| Step: 4
Training loss: 0.39179091976732455
Validation loss: 2.69925239935813

Epoch: 5| Step: 5
Training loss: 0.7381253759139329
Validation loss: 2.750255897926905

Epoch: 5| Step: 6
Training loss: 0.31366883082830693
Validation loss: 2.7087667314065205

Epoch: 5| Step: 7
Training loss: 0.3727767925317336
Validation loss: 2.7749758470188683

Epoch: 5| Step: 8
Training loss: 0.3467295436201931
Validation loss: 2.8504759438510066

Epoch: 5| Step: 9
Training loss: 0.5311362481348058
Validation loss: 2.8298926195030054

Epoch: 5| Step: 10
Training loss: 0.37054489103039884
Validation loss: 2.795641557869167

Epoch: 5| Step: 11
Training loss: 0.26089553038634783
Validation loss: 2.7617519687811205

Epoch: 487| Step: 0
Training loss: 0.32687688916318713
Validation loss: 2.7726843227621676

Epoch: 5| Step: 1
Training loss: 0.4074832464062306
Validation loss: 2.706889586895635

Epoch: 5| Step: 2
Training loss: 0.40977076626326064
Validation loss: 2.7516967964506023

Epoch: 5| Step: 3
Training loss: 0.40343774743814953
Validation loss: 2.762639648912328

Epoch: 5| Step: 4
Training loss: 0.22118170508527307
Validation loss: 2.7843640285494136

Epoch: 5| Step: 5
Training loss: 0.2575061307103215
Validation loss: 2.7867278078682585

Epoch: 5| Step: 6
Training loss: 0.29602287370188574
Validation loss: 2.804787595940937

Epoch: 5| Step: 7
Training loss: 0.22876623057020876
Validation loss: 2.769560841992769

Epoch: 5| Step: 8
Training loss: 0.33620740338845084
Validation loss: 2.774051061110114

Epoch: 5| Step: 9
Training loss: 0.2741380301021415
Validation loss: 2.745148613224122

Epoch: 5| Step: 10
Training loss: 0.595286990042163
Validation loss: 2.852741751847821

Epoch: 5| Step: 11
Training loss: 0.4083753888537304
Validation loss: 2.7596177846478422

Epoch: 488| Step: 0
Training loss: 0.27221666002483946
Validation loss: 2.8112330408745243

Epoch: 5| Step: 1
Training loss: 0.2495007297910364
Validation loss: 2.7504947643541096

Epoch: 5| Step: 2
Training loss: 0.356286564841109
Validation loss: 2.764381258338849

Epoch: 5| Step: 3
Training loss: 0.31376473084478085
Validation loss: 2.7245708358026097

Epoch: 5| Step: 4
Training loss: 0.25023523826581223
Validation loss: 2.7545154267515755

Epoch: 5| Step: 5
Training loss: 0.30765812919279145
Validation loss: 2.8476807881481108

Epoch: 5| Step: 6
Training loss: 0.2839802307498155
Validation loss: 2.7959213904334574

Epoch: 5| Step: 7
Training loss: 0.3668882489777102
Validation loss: 2.78456193558309

Epoch: 5| Step: 8
Training loss: 0.23716020306408991
Validation loss: 2.6865463856741134

Epoch: 5| Step: 9
Training loss: 0.3836934210728508
Validation loss: 2.729317405532106

Epoch: 5| Step: 10
Training loss: 0.30355127927884135
Validation loss: 2.78852055731274

Epoch: 5| Step: 11
Training loss: 1.1043588303147014
Validation loss: 2.803652630001142

Epoch: 489| Step: 0
Training loss: 0.40321980625733544
Validation loss: 2.8801931009470407

Epoch: 5| Step: 1
Training loss: 0.45673957711966384
Validation loss: 2.8391023881146955

Epoch: 5| Step: 2
Training loss: 0.31669986900053454
Validation loss: 2.942807887371016

Epoch: 5| Step: 3
Training loss: 0.517363536183294
Validation loss: 2.818766281915458

Epoch: 5| Step: 4
Training loss: 0.33603700007071663
Validation loss: 2.808579370128479

Epoch: 5| Step: 5
Training loss: 0.31892010974063756
Validation loss: 2.808907566922226

Epoch: 5| Step: 6
Training loss: 0.3051152894148212
Validation loss: 2.822906037811502

Epoch: 5| Step: 7
Training loss: 0.32828248876658395
Validation loss: 2.8814239638377246

Epoch: 5| Step: 8
Training loss: 0.4073971910030586
Validation loss: 2.8521612679640636

Epoch: 5| Step: 9
Training loss: 0.30172373755198256
Validation loss: 2.9906889879057257

Epoch: 5| Step: 10
Training loss: 0.35619870368672374
Validation loss: 2.9402030148824427

Epoch: 5| Step: 11
Training loss: 0.28791206414610354
Validation loss: 2.8390450419153552

Epoch: 490| Step: 0
Training loss: 0.2463718689545861
Validation loss: 2.8428585590568742

Epoch: 5| Step: 1
Training loss: 0.3041492500718601
Validation loss: 2.88561535000883

Epoch: 5| Step: 2
Training loss: 0.42586614479866214
Validation loss: 2.839006185874121

Epoch: 5| Step: 3
Training loss: 0.3281844630176247
Validation loss: 2.8364104970278436

Epoch: 5| Step: 4
Training loss: 0.3654690972530808
Validation loss: 2.7979729662126163

Epoch: 5| Step: 5
Training loss: 0.31647684934431186
Validation loss: 2.8798028144233383

Epoch: 5| Step: 6
Training loss: 0.6163374201223214
Validation loss: 2.859538596498712

Epoch: 5| Step: 7
Training loss: 0.3769052504739807
Validation loss: 2.926869307642871

Epoch: 5| Step: 8
Training loss: 0.4012388223653911
Validation loss: 2.8805194615410343

Epoch: 5| Step: 9
Training loss: 0.2809536882983268
Validation loss: 2.862840144036398

Epoch: 5| Step: 10
Training loss: 0.3115984309224299
Validation loss: 2.8579045807339614

Epoch: 5| Step: 11
Training loss: 0.33827108671853884
Validation loss: 2.8068144551323675

Epoch: 491| Step: 0
Training loss: 0.5381681791343161
Validation loss: 2.9097311814614573

Epoch: 5| Step: 1
Training loss: 0.3548489291486295
Validation loss: 2.829433433547825

Epoch: 5| Step: 2
Training loss: 0.328206642529753
Validation loss: 2.856335551443525

Epoch: 5| Step: 3
Training loss: 0.37713172120909644
Validation loss: 2.793302950837989

Epoch: 5| Step: 4
Training loss: 0.2956081389000041
Validation loss: 2.76472694018718

Epoch: 5| Step: 5
Training loss: 0.313563480389351
Validation loss: 2.869876176082496

Epoch: 5| Step: 6
Training loss: 0.31831724672132
Validation loss: 2.9547838399435973

Epoch: 5| Step: 7
Training loss: 0.3588985519015396
Validation loss: 2.835581439236274

Epoch: 5| Step: 8
Training loss: 0.21428196891707463
Validation loss: 2.8656583514364886

Epoch: 5| Step: 9
Training loss: 0.41290273729818067
Validation loss: 2.770108695869921

Epoch: 5| Step: 10
Training loss: 0.32756776268816024
Validation loss: 2.8618014832663885

Epoch: 5| Step: 11
Training loss: 0.32918416240326287
Validation loss: 2.8721922799155966

Epoch: 492| Step: 0
Training loss: 0.3496885796019769
Validation loss: 2.820873349148692

Epoch: 5| Step: 1
Training loss: 0.3057075688901649
Validation loss: 2.8579945141488494

Epoch: 5| Step: 2
Training loss: 0.2929531601890491
Validation loss: 2.806638504838065

Epoch: 5| Step: 3
Training loss: 0.31605682387412004
Validation loss: 2.794515026096269

Epoch: 5| Step: 4
Training loss: 0.26706811234183203
Validation loss: 2.886963393014403

Epoch: 5| Step: 5
Training loss: 0.3691052616679678
Validation loss: 2.765415061554398

Epoch: 5| Step: 6
Training loss: 0.3486339878949352
Validation loss: 2.769076842283207

Epoch: 5| Step: 7
Training loss: 0.6430662672177384
Validation loss: 2.8816120367091607

Epoch: 5| Step: 8
Training loss: 0.2993520743445848
Validation loss: 2.8441099595795905

Epoch: 5| Step: 9
Training loss: 0.2635402492188544
Validation loss: 2.8507314298344344

Epoch: 5| Step: 10
Training loss: 0.3563345331988698
Validation loss: 2.8533224501292693

Epoch: 5| Step: 11
Training loss: 0.2828987459008975
Validation loss: 2.754490026189003

Epoch: 493| Step: 0
Training loss: 0.3873836119507856
Validation loss: 2.7958092461546604

Epoch: 5| Step: 1
Training loss: 0.43585594398801447
Validation loss: 2.7569706382008925

Epoch: 5| Step: 2
Training loss: 0.4717298840336191
Validation loss: 2.8276006237061

Epoch: 5| Step: 3
Training loss: 0.42437269673684536
Validation loss: 2.847184130302699

Epoch: 5| Step: 4
Training loss: 0.33433473068253045
Validation loss: 2.845554142815529

Epoch: 5| Step: 5
Training loss: 0.4229837083373383
Validation loss: 2.8674250650689115

Epoch: 5| Step: 6
Training loss: 0.4453451077753261
Validation loss: 2.9355781572121415

Epoch: 5| Step: 7
Training loss: 0.3359118274371537
Validation loss: 2.834439683405331

Epoch: 5| Step: 8
Training loss: 0.4052104855098627
Validation loss: 2.8251315972388844

Epoch: 5| Step: 9
Training loss: 0.6077772615705821
Validation loss: 2.8488932758460517

Epoch: 5| Step: 10
Training loss: 0.28708308612072786
Validation loss: 2.8017704031444093

Epoch: 5| Step: 11
Training loss: 0.40591530584285906
Validation loss: 2.792020018595529

Epoch: 494| Step: 0
Training loss: 0.2635356127127795
Validation loss: 2.864467165354322

Epoch: 5| Step: 1
Training loss: 0.5105218065407326
Validation loss: 2.8584720735456335

Epoch: 5| Step: 2
Training loss: 0.5336285525320097
Validation loss: 2.8482162141316487

Epoch: 5| Step: 3
Training loss: 0.29856340987777774
Validation loss: 2.8416399166287487

Epoch: 5| Step: 4
Training loss: 0.36789187379480487
Validation loss: 2.837118370591275

Epoch: 5| Step: 5
Training loss: 0.34533956775474967
Validation loss: 2.755848885238441

Epoch: 5| Step: 6
Training loss: 0.2657115458696596
Validation loss: 2.7805996966809463

Epoch: 5| Step: 7
Training loss: 0.33832788564417826
Validation loss: 2.777779785923762

Epoch: 5| Step: 8
Training loss: 0.36487194172909526
Validation loss: 2.807296064063163

Epoch: 5| Step: 9
Training loss: 0.39566033330608585
Validation loss: 2.8520775316809606

Epoch: 5| Step: 10
Training loss: 0.3233067773555496
Validation loss: 2.8835559289560844

Epoch: 5| Step: 11
Training loss: 0.3066074329076186
Validation loss: 2.8722697818566405

Epoch: 495| Step: 0
Training loss: 0.44960602362184915
Validation loss: 2.9010074905674443

Epoch: 5| Step: 1
Training loss: 0.610844185963908
Validation loss: 2.870164097033441

Epoch: 5| Step: 2
Training loss: 0.41180781318613224
Validation loss: 2.802024448348018

Epoch: 5| Step: 3
Training loss: 0.33822282546505567
Validation loss: 2.8430664931845118

Epoch: 5| Step: 4
Training loss: 0.3805577183907175
Validation loss: 2.7383257272312482

Epoch: 5| Step: 5
Training loss: 0.31029433052214145
Validation loss: 2.842804832027421

Epoch: 5| Step: 6
Training loss: 0.28956278475346636
Validation loss: 2.8823173428517586

Epoch: 5| Step: 7
Training loss: 0.4036826660414907
Validation loss: 2.8100137352918835

Epoch: 5| Step: 8
Training loss: 0.407783694364384
Validation loss: 2.8640576602765178

Epoch: 5| Step: 9
Training loss: 0.3028564699135293
Validation loss: 2.87482813653169

Epoch: 5| Step: 10
Training loss: 0.3067474907941096
Validation loss: 2.7703029022079226

Epoch: 5| Step: 11
Training loss: 0.2615154102737321
Validation loss: 2.8330422957858588

Epoch: 496| Step: 0
Training loss: 0.27255512646745744
Validation loss: 2.8357329526894026

Epoch: 5| Step: 1
Training loss: 0.25282326598755794
Validation loss: 2.7441550330239712

Epoch: 5| Step: 2
Training loss: 0.23197856266358197
Validation loss: 2.8063343388005526

Epoch: 5| Step: 3
Training loss: 0.3469596162466665
Validation loss: 2.787891277369991

Epoch: 5| Step: 4
Training loss: 0.42526087327766393
Validation loss: 2.791008506358282

Epoch: 5| Step: 5
Training loss: 0.28880755032638333
Validation loss: 2.842414682182073

Epoch: 5| Step: 6
Training loss: 0.32863845842110045
Validation loss: 2.7425837796494386

Epoch: 5| Step: 7
Training loss: 0.3515923063570492
Validation loss: 2.82070648174846

Epoch: 5| Step: 8
Training loss: 0.2864654222247054
Validation loss: 2.810204222369269

Epoch: 5| Step: 9
Training loss: 0.5674553724630399
Validation loss: 2.8704449844034086

Epoch: 5| Step: 10
Training loss: 0.31835126573964956
Validation loss: 2.7694120897090686

Epoch: 5| Step: 11
Training loss: 0.4405332557722942
Validation loss: 2.7866560298391176

Epoch: 497| Step: 0
Training loss: 0.3943509549157542
Validation loss: 2.7692000922398337

Epoch: 5| Step: 1
Training loss: 0.3056193309874446
Validation loss: 2.7854417277406816

Epoch: 5| Step: 2
Training loss: 0.371223406979158
Validation loss: 2.8547268802659715

Epoch: 5| Step: 3
Training loss: 0.5894988106124307
Validation loss: 2.8862485076748445

Epoch: 5| Step: 4
Training loss: 0.39052714075730455
Validation loss: 2.814266165974807

Epoch: 5| Step: 5
Training loss: 0.2867366031628546
Validation loss: 2.8597666293300823

Epoch: 5| Step: 6
Training loss: 0.33440499839623355
Validation loss: 2.8468927163034494

Epoch: 5| Step: 7
Training loss: 0.4258036826287591
Validation loss: 2.757954133659062

Epoch: 5| Step: 8
Training loss: 0.33884871814536544
Validation loss: 2.861667811656968

Epoch: 5| Step: 9
Training loss: 0.3080886014018119
Validation loss: 2.801224056834728

Epoch: 5| Step: 10
Training loss: 0.2896402616369443
Validation loss: 2.7870554643677523

Epoch: 5| Step: 11
Training loss: 0.30103261773436185
Validation loss: 2.810465992003841

Epoch: 498| Step: 0
Training loss: 0.5269599365518051
Validation loss: 2.814823310715024

Epoch: 5| Step: 1
Training loss: 0.3146219688757531
Validation loss: 2.81431732450153

Epoch: 5| Step: 2
Training loss: 0.32094526593507977
Validation loss: 2.806814391425293

Epoch: 5| Step: 3
Training loss: 0.5139526644073102
Validation loss: 2.824768842956661

Epoch: 5| Step: 4
Training loss: 0.26767424089280123
Validation loss: 2.8113011984193546

Epoch: 5| Step: 5
Training loss: 0.36878150546728783
Validation loss: 2.8467921728262837

Epoch: 5| Step: 6
Training loss: 0.2395563481862408
Validation loss: 2.8911258916499842

Epoch: 5| Step: 7
Training loss: 0.34857382395522063
Validation loss: 2.922520401336582

Epoch: 5| Step: 8
Training loss: 0.28425469997935626
Validation loss: 2.863326859468714

Epoch: 5| Step: 9
Training loss: 0.24390192188086
Validation loss: 2.8731066958840366

Epoch: 5| Step: 10
Training loss: 0.3696853211661952
Validation loss: 2.897820454162873

Epoch: 5| Step: 11
Training loss: 0.39277304370012467
Validation loss: 2.832701126324756

Epoch: 499| Step: 0
Training loss: 0.3644820027087956
Validation loss: 2.8124715167828533

Epoch: 5| Step: 1
Training loss: 0.5482327092475623
Validation loss: 2.8330112173662014

Epoch: 5| Step: 2
Training loss: 0.21773541550512573
Validation loss: 2.8572406550540608

Epoch: 5| Step: 3
Training loss: 0.305973834450895
Validation loss: 2.8301384223743367

Epoch: 5| Step: 4
Training loss: 0.36886941948097957
Validation loss: 2.911665325051668

Epoch: 5| Step: 5
Training loss: 0.3871061523180177
Validation loss: 2.8418328998462727

Epoch: 5| Step: 6
Training loss: 0.2633265600636133
Validation loss: 2.8811600867617564

Epoch: 5| Step: 7
Training loss: 0.3931133171189254
Validation loss: 2.8976261343393372

Epoch: 5| Step: 8
Training loss: 0.3453503225507289
Validation loss: 2.803204781181215

Epoch: 5| Step: 9
Training loss: 0.3433136554783992
Validation loss: 2.8316483618066224

Epoch: 5| Step: 10
Training loss: 0.31166178821036755
Validation loss: 2.9081363572107204

Epoch: 5| Step: 11
Training loss: 0.32849651829951637
Validation loss: 2.868896519001929

Epoch: 500| Step: 0
Training loss: 0.42913849176431873
Validation loss: 2.8320646069195514

Epoch: 5| Step: 1
Training loss: 0.31561011949718887
Validation loss: 2.880862192271089

Epoch: 5| Step: 2
Training loss: 0.3742561114620646
Validation loss: 2.8635087627594094

Epoch: 5| Step: 3
Training loss: 0.285832165770375
Validation loss: 2.734054045233002

Epoch: 5| Step: 4
Training loss: 0.3188873079422637
Validation loss: 2.7454389150423086

Epoch: 5| Step: 5
Training loss: 0.604158916642917
Validation loss: 2.7545844899963097

Epoch: 5| Step: 6
Training loss: 0.3244307066467623
Validation loss: 2.735608529283947

Epoch: 5| Step: 7
Training loss: 0.3440160913550444
Validation loss: 2.7714436989349376

Epoch: 5| Step: 8
Training loss: 0.28589873129251947
Validation loss: 2.7510818102005845

Epoch: 5| Step: 9
Training loss: 0.34261444403842023
Validation loss: 2.7862170403129647

Epoch: 5| Step: 10
Training loss: 0.38032474651695575
Validation loss: 2.8127854908756573

Epoch: 5| Step: 11
Training loss: 0.22749338796721935
Validation loss: 2.7773936857803636

Epoch: 501| Step: 0
Training loss: 0.3725799714400839
Validation loss: 2.817954224853195

Epoch: 5| Step: 1
Training loss: 0.39813359207870763
Validation loss: 2.7941592473588512

Epoch: 5| Step: 2
Training loss: 0.32400407923011365
Validation loss: 2.7912387442828095

Epoch: 5| Step: 3
Training loss: 0.2045395090462464
Validation loss: 2.8223198556584603

Epoch: 5| Step: 4
Training loss: 0.3057634234799696
Validation loss: 2.7712465076197974

Epoch: 5| Step: 5
Training loss: 0.24128925735394127
Validation loss: 2.783889978438374

Epoch: 5| Step: 6
Training loss: 0.22698827724078985
Validation loss: 2.7698374149914793

Epoch: 5| Step: 7
Training loss: 0.3556289521451951
Validation loss: 2.7658515162117863

Epoch: 5| Step: 8
Training loss: 0.23147260931461208
Validation loss: 2.810614490733972

Epoch: 5| Step: 9
Training loss: 0.5161071026305012
Validation loss: 2.8277608907543432

Epoch: 5| Step: 10
Training loss: 0.34551243452794206
Validation loss: 2.814354768861484

Epoch: 5| Step: 11
Training loss: 1.1943984182987357
Validation loss: 2.8151525316250723

Epoch: 502| Step: 0
Training loss: 0.4263671029231031
Validation loss: 2.864400718532442

Epoch: 5| Step: 1
Training loss: 0.47478491280229473
Validation loss: 2.9137584026482264

Epoch: 5| Step: 2
Training loss: 0.2905857444215901
Validation loss: 2.8726959463694333

Epoch: 5| Step: 3
Training loss: 0.2612020316644464
Validation loss: 2.8482503737802616

Epoch: 5| Step: 4
Training loss: 0.3431767321849344
Validation loss: 2.8444225158835414

Epoch: 5| Step: 5
Training loss: 0.3806273120189785
Validation loss: 2.8231683187234626

Epoch: 5| Step: 6
Training loss: 0.5216811019781168
Validation loss: 2.819094401012273

Epoch: 5| Step: 7
Training loss: 0.32096594937899997
Validation loss: 2.8665277586501774

Epoch: 5| Step: 8
Training loss: 0.4362862986134608
Validation loss: 2.875039052006961

Epoch: 5| Step: 9
Training loss: 0.3381152316073255
Validation loss: 2.85743760308652

Epoch: 5| Step: 10
Training loss: 0.44896559838467087
Validation loss: 2.88026790775727

Epoch: 5| Step: 11
Training loss: 0.1607111644820228
Validation loss: 2.892011313462014

Epoch: 503| Step: 0
Training loss: 0.21961800330659415
Validation loss: 2.8810409505918027

Epoch: 5| Step: 1
Training loss: 0.49899011190857456
Validation loss: 2.8294995376618894

Epoch: 5| Step: 2
Training loss: 0.34259597009790066
Validation loss: 2.833187353122777

Epoch: 5| Step: 3
Training loss: 0.26520350617907446
Validation loss: 2.794852923474182

Epoch: 5| Step: 4
Training loss: 0.372452026964731
Validation loss: 2.843722304883526

Epoch: 5| Step: 5
Training loss: 0.3734656574694821
Validation loss: 2.84647113086238

Epoch: 5| Step: 6
Training loss: 0.4182726031874906
Validation loss: 2.8435719298060005

Epoch: 5| Step: 7
Training loss: 0.2770521081214302
Validation loss: 2.903001901475724

Epoch: 5| Step: 8
Training loss: 0.32970583534780856
Validation loss: 2.8726430782499937

Epoch: 5| Step: 9
Training loss: 0.2769701819285466
Validation loss: 2.7926834138533674

Epoch: 5| Step: 10
Training loss: 0.2996203324802225
Validation loss: 2.8858155836656825

Epoch: 5| Step: 11
Training loss: 0.5277623528462865
Validation loss: 2.837203738841217

Epoch: 504| Step: 0
Training loss: 0.35419058251507846
Validation loss: 2.8582257356679506

Epoch: 5| Step: 1
Training loss: 0.37100013756813727
Validation loss: 2.897570652647524

Epoch: 5| Step: 2
Training loss: 0.3683217568469839
Validation loss: 2.8746358530275082

Epoch: 5| Step: 3
Training loss: 0.2733826446005064
Validation loss: 2.903338356445302

Epoch: 5| Step: 4
Training loss: 0.4959552751851889
Validation loss: 2.9170368584080677

Epoch: 5| Step: 5
Training loss: 0.32407489710594806
Validation loss: 2.887088268479695

Epoch: 5| Step: 6
Training loss: 0.301940492313934
Validation loss: 2.8350764632243597

Epoch: 5| Step: 7
Training loss: 0.30572998993398287
Validation loss: 2.812893170673137

Epoch: 5| Step: 8
Training loss: 0.5794663976697579
Validation loss: 2.8028241629401642

Epoch: 5| Step: 9
Training loss: 0.24510391169003962
Validation loss: 2.813734726612288

Epoch: 5| Step: 10
Training loss: 0.36405966024969416
Validation loss: 2.890034287039212

Epoch: 5| Step: 11
Training loss: 0.4818981586635642
Validation loss: 2.9006034798657083

Epoch: 505| Step: 0
Training loss: 0.3700478320198584
Validation loss: 2.8417948439897796

Epoch: 5| Step: 1
Training loss: 0.3141926936837151
Validation loss: 2.834054179682555

Epoch: 5| Step: 2
Training loss: 0.3020705050452169
Validation loss: 2.7580557653752096

Epoch: 5| Step: 3
Training loss: 0.6602975592522903
Validation loss: 2.794843589526933

Epoch: 5| Step: 4
Training loss: 0.46374450667487455
Validation loss: 2.7440233633163094

Epoch: 5| Step: 5
Training loss: 0.4885152332445261
Validation loss: 2.7677722971374146

Epoch: 5| Step: 6
Training loss: 0.3260959948145795
Validation loss: 2.8404554769013277

Epoch: 5| Step: 7
Training loss: 0.35506302871758744
Validation loss: 2.894402518693824

Epoch: 5| Step: 8
Training loss: 0.4298932709866729
Validation loss: 2.826954495767582

Epoch: 5| Step: 9
Training loss: 0.4629800122706824
Validation loss: 2.860916153171693

Epoch: 5| Step: 10
Training loss: 0.35517164536827384
Validation loss: 2.8382781381797373

Epoch: 5| Step: 11
Training loss: 0.46907443898641205
Validation loss: 2.7992204531807188

Epoch: 506| Step: 0
Training loss: 0.40333060189115655
Validation loss: 2.7898347677675375

Epoch: 5| Step: 1
Training loss: 0.511826452903789
Validation loss: 2.814454621582198

Epoch: 5| Step: 2
Training loss: 0.5504867632190075
Validation loss: 2.8120913420590603

Epoch: 5| Step: 3
Training loss: 0.20833752250433232
Validation loss: 2.814619297237362

Epoch: 5| Step: 4
Training loss: 0.33515375220872995
Validation loss: 2.8671071719524934

Epoch: 5| Step: 5
Training loss: 0.34031090472419323
Validation loss: 2.805298461533318

Epoch: 5| Step: 6
Training loss: 0.21648076354875592
Validation loss: 2.7672887025776234

Epoch: 5| Step: 7
Training loss: 0.26697948065590577
Validation loss: 2.775013192176964

Epoch: 5| Step: 8
Training loss: 0.42495067324209695
Validation loss: 2.807649254657226

Epoch: 5| Step: 9
Training loss: 0.399862825446241
Validation loss: 2.7801731753898475

Epoch: 5| Step: 10
Training loss: 0.22076152771468419
Validation loss: 2.7922361253326575

Epoch: 5| Step: 11
Training loss: 0.18279782709104778
Validation loss: 2.8259664064072334

Epoch: 507| Step: 0
Training loss: 0.294110654036049
Validation loss: 2.7998826852415926

Epoch: 5| Step: 1
Training loss: 0.39080680431105874
Validation loss: 2.804833469470844

Epoch: 5| Step: 2
Training loss: 0.44990924343865507
Validation loss: 2.8433650353573587

Epoch: 5| Step: 3
Training loss: 0.39160392170716246
Validation loss: 2.797637114592114

Epoch: 5| Step: 4
Training loss: 0.3647319377312281
Validation loss: 2.8840014169275503

Epoch: 5| Step: 5
Training loss: 0.34793086403681756
Validation loss: 2.7756704162120935

Epoch: 5| Step: 6
Training loss: 0.2638734823813047
Validation loss: 2.832640876487722

Epoch: 5| Step: 7
Training loss: 0.2655041363568125
Validation loss: 2.865729710625538

Epoch: 5| Step: 8
Training loss: 0.2710154483516378
Validation loss: 2.8319088192488198

Epoch: 5| Step: 9
Training loss: 0.6230694996902387
Validation loss: 2.803689752629576

Epoch: 5| Step: 10
Training loss: 0.36364362957316787
Validation loss: 2.873627227803358

Epoch: 5| Step: 11
Training loss: 0.3057512274824317
Validation loss: 2.761460989614212

Epoch: 508| Step: 0
Training loss: 0.29805058568241943
Validation loss: 2.734098140687579

Epoch: 5| Step: 1
Training loss: 0.3603453803630545
Validation loss: 2.782658059805406

Epoch: 5| Step: 2
Training loss: 0.6329484958275525
Validation loss: 2.7580623099317303

Epoch: 5| Step: 3
Training loss: 0.2749953713894502
Validation loss: 2.754924043195631

Epoch: 5| Step: 4
Training loss: 0.29334862558554275
Validation loss: 2.7982685943356524

Epoch: 5| Step: 5
Training loss: 0.4592778505374839
Validation loss: 2.8735675318386873

Epoch: 5| Step: 6
Training loss: 0.5485776553703531
Validation loss: 2.883924140699004

Epoch: 5| Step: 7
Training loss: 0.28159378815713015
Validation loss: 2.763645092011022

Epoch: 5| Step: 8
Training loss: 0.25259413977841505
Validation loss: 2.8100145696112975

Epoch: 5| Step: 9
Training loss: 0.3027929680019719
Validation loss: 2.7010197866730294

Epoch: 5| Step: 10
Training loss: 0.4110562939690861
Validation loss: 2.6890658467057875

Epoch: 5| Step: 11
Training loss: 0.30356560078404426
Validation loss: 2.7993810639454484

Epoch: 509| Step: 0
Training loss: 0.5738290515370221
Validation loss: 2.7667118853489274

Epoch: 5| Step: 1
Training loss: 0.28163471665448064
Validation loss: 2.8069696554293038

Epoch: 5| Step: 2
Training loss: 0.41809789498462335
Validation loss: 2.8151391450942054

Epoch: 5| Step: 3
Training loss: 0.27972864242651946
Validation loss: 2.8254070956400854

Epoch: 5| Step: 4
Training loss: 0.3033810261857561
Validation loss: 2.7983436209478376

Epoch: 5| Step: 5
Training loss: 0.33682253050330996
Validation loss: 2.81815882529041

Epoch: 5| Step: 6
Training loss: 0.3840494607150594
Validation loss: 2.844908953222725

Epoch: 5| Step: 7
Training loss: 0.4300984238382607
Validation loss: 2.8074461387830247

Epoch: 5| Step: 8
Training loss: 0.3156496349956203
Validation loss: 2.797785200626871

Epoch: 5| Step: 9
Training loss: 0.42618674471724327
Validation loss: 2.891651191358538

Epoch: 5| Step: 10
Training loss: 0.24897901849457946
Validation loss: 2.820070458872278

Epoch: 5| Step: 11
Training loss: 0.16969108254600765
Validation loss: 2.850878650063877

Epoch: 510| Step: 0
Training loss: 0.281838371176466
Validation loss: 2.806891759062042

Epoch: 5| Step: 1
Training loss: 0.36749810412949424
Validation loss: 2.883801481015889

Epoch: 5| Step: 2
Training loss: 0.3278596804461565
Validation loss: 2.876876961260363

Epoch: 5| Step: 3
Training loss: 0.5489171183373702
Validation loss: 2.823738254248563

Epoch: 5| Step: 4
Training loss: 0.24540319133063435
Validation loss: 2.813751097850792

Epoch: 5| Step: 5
Training loss: 0.2612814595021226
Validation loss: 2.849137272117377

Epoch: 5| Step: 6
Training loss: 0.33961850956333506
Validation loss: 2.768533700081891

Epoch: 5| Step: 7
Training loss: 0.4374370189020417
Validation loss: 2.7561848117330814

Epoch: 5| Step: 8
Training loss: 0.22462647414426923
Validation loss: 2.7804810000209876

Epoch: 5| Step: 9
Training loss: 0.3725940292525003
Validation loss: 2.8793750658995085

Epoch: 5| Step: 10
Training loss: 0.26265727622190804
Validation loss: 2.9003789488346534

Epoch: 5| Step: 11
Training loss: 0.06749241318826688
Validation loss: 2.9352687281756307

Epoch: 511| Step: 0
Training loss: 0.31303579175163343
Validation loss: 2.8468544995225473

Epoch: 5| Step: 1
Training loss: 0.33154101364166033
Validation loss: 2.817032961662825

Epoch: 5| Step: 2
Training loss: 0.24187525494140674
Validation loss: 2.7860776742247437

Epoch: 5| Step: 3
Training loss: 0.387923435387047
Validation loss: 2.8403550203313412

Epoch: 5| Step: 4
Training loss: 0.415342063253455
Validation loss: 2.769404804336527

Epoch: 5| Step: 5
Training loss: 0.3324242790126276
Validation loss: 2.766763366642802

Epoch: 5| Step: 6
Training loss: 0.554809476308951
Validation loss: 2.834311293138737

Epoch: 5| Step: 7
Training loss: 0.43706316938093986
Validation loss: 2.8381073727396697

Epoch: 5| Step: 8
Training loss: 0.35136368746071855
Validation loss: 2.8110982792724366

Epoch: 5| Step: 9
Training loss: 0.3984809178650116
Validation loss: 2.904931706010405

Epoch: 5| Step: 10
Training loss: 0.36645235369417384
Validation loss: 2.8845587888488287

Epoch: 5| Step: 11
Training loss: 0.3726915194857461
Validation loss: 2.82944189501679

Epoch: 512| Step: 0
Training loss: 0.29892033668901097
Validation loss: 2.7928161365988604

Epoch: 5| Step: 1
Training loss: 0.5199265374505534
Validation loss: 2.7244122396270627

Epoch: 5| Step: 2
Training loss: 0.2906085117338957
Validation loss: 2.7591247426389502

Epoch: 5| Step: 3
Training loss: 0.3527458091901891
Validation loss: 2.825518708587176

Epoch: 5| Step: 4
Training loss: 0.31739692069755127
Validation loss: 2.9076712732389725

Epoch: 5| Step: 5
Training loss: 0.4095529569878873
Validation loss: 2.9003777431968336

Epoch: 5| Step: 6
Training loss: 0.42144607002203655
Validation loss: 2.9194718336225423

Epoch: 5| Step: 7
Training loss: 0.37231557376880525
Validation loss: 2.933567847871104

Epoch: 5| Step: 8
Training loss: 0.35440024452513186
Validation loss: 2.895794495429629

Epoch: 5| Step: 9
Training loss: 0.2890616880869417
Validation loss: 2.8845900385509298

Epoch: 5| Step: 10
Training loss: 0.4804817446060182
Validation loss: 2.860116872800353

Epoch: 5| Step: 11
Training loss: 0.19058129560037
Validation loss: 2.8385817790332397

Epoch: 513| Step: 0
Training loss: 0.3070794992173037
Validation loss: 2.831939892227067

Epoch: 5| Step: 1
Training loss: 0.25889363605204
Validation loss: 2.8237210578724254

Epoch: 5| Step: 2
Training loss: 0.30144352270615543
Validation loss: 2.889957708370513

Epoch: 5| Step: 3
Training loss: 0.23097986991497488
Validation loss: 2.8780896923648336

Epoch: 5| Step: 4
Training loss: 0.4839928411523778
Validation loss: 2.9153746547527852

Epoch: 5| Step: 5
Training loss: 0.22298241868122223
Validation loss: 2.887958509886631

Epoch: 5| Step: 6
Training loss: 0.2619473896257702
Validation loss: 2.8656075790802027

Epoch: 5| Step: 7
Training loss: 0.2725024174661758
Validation loss: 2.7998784559697376

Epoch: 5| Step: 8
Training loss: 0.3563070996016921
Validation loss: 2.764590154168445

Epoch: 5| Step: 9
Training loss: 0.2985067696594442
Validation loss: 2.81443598837117

Epoch: 5| Step: 10
Training loss: 0.4866597527128242
Validation loss: 2.8048319978602194

Epoch: 5| Step: 11
Training loss: 0.22950340405912856
Validation loss: 2.8736821865428497

Epoch: 514| Step: 0
Training loss: 0.4367709556862663
Validation loss: 2.825307608907752

Epoch: 5| Step: 1
Training loss: 0.47451269475880087
Validation loss: 2.8707225153000806

Epoch: 5| Step: 2
Training loss: 0.45136318031688044
Validation loss: 2.7917406027288343

Epoch: 5| Step: 3
Training loss: 0.4139128900544721
Validation loss: 2.7529185009463286

Epoch: 5| Step: 4
Training loss: 0.673404991976139
Validation loss: 2.7770289346833428

Epoch: 5| Step: 5
Training loss: 0.33709354871816544
Validation loss: 2.744925625383551

Epoch: 5| Step: 6
Training loss: 0.3072744973553255
Validation loss: 2.812818767002531

Epoch: 5| Step: 7
Training loss: 0.38032329685053257
Validation loss: 2.786633970245241

Epoch: 5| Step: 8
Training loss: 0.4007350649629731
Validation loss: 2.890236620544037

Epoch: 5| Step: 9
Training loss: 0.4285917355347178
Validation loss: 2.8940998258669888

Epoch: 5| Step: 10
Training loss: 0.30418399631872217
Validation loss: 2.8584758755440642

Epoch: 5| Step: 11
Training loss: 0.16517019423208013
Validation loss: 2.8211753525645213

Epoch: 515| Step: 0
Training loss: 0.365793137322567
Validation loss: 2.7622732265021956

Epoch: 5| Step: 1
Training loss: 0.33945811523702696
Validation loss: 2.8166807008333463

Epoch: 5| Step: 2
Training loss: 0.3331653971627993
Validation loss: 2.819149369243028

Epoch: 5| Step: 3
Training loss: 0.23296259643594447
Validation loss: 2.841132405520607

Epoch: 5| Step: 4
Training loss: 0.35451696640299557
Validation loss: 2.779702731300382

Epoch: 5| Step: 5
Training loss: 0.4823521861038975
Validation loss: 2.827169752287688

Epoch: 5| Step: 6
Training loss: 0.255006694285093
Validation loss: 2.8209469610813205

Epoch: 5| Step: 7
Training loss: 0.28443548481511727
Validation loss: 2.74019687125729

Epoch: 5| Step: 8
Training loss: 0.22100649719429427
Validation loss: 2.730309033759325

Epoch: 5| Step: 9
Training loss: 0.27358100395206386
Validation loss: 2.8156715912797483

Epoch: 5| Step: 10
Training loss: 0.5424462418355617
Validation loss: 2.7095917321343395

Epoch: 5| Step: 11
Training loss: 0.7363640247771013
Validation loss: 2.7506090522886852

Epoch: 516| Step: 0
Training loss: 0.26482105608008943
Validation loss: 2.8178297722972343

Epoch: 5| Step: 1
Training loss: 0.30581131334618367
Validation loss: 2.8165637469157545

Epoch: 5| Step: 2
Training loss: 0.3021358110074238
Validation loss: 2.8198222969786246

Epoch: 5| Step: 3
Training loss: 0.41680350043653724
Validation loss: 2.7996577798803246

Epoch: 5| Step: 4
Training loss: 0.5292923142352804
Validation loss: 2.808744996817207

Epoch: 5| Step: 5
Training loss: 0.4037326801352611
Validation loss: 2.8362136930515476

Epoch: 5| Step: 6
Training loss: 0.3364882058305734
Validation loss: 2.7996474684166675

Epoch: 5| Step: 7
Training loss: 0.24119007159342704
Validation loss: 2.825554485677319

Epoch: 5| Step: 8
Training loss: 0.3244913058615101
Validation loss: 2.7695041291093094

Epoch: 5| Step: 9
Training loss: 0.27527703993210084
Validation loss: 2.814597717990066

Epoch: 5| Step: 10
Training loss: 0.25668523450102004
Validation loss: 2.8271194518013867

Epoch: 5| Step: 11
Training loss: 0.11739343192102063
Validation loss: 2.8274635012008225

Epoch: 517| Step: 0
Training loss: 0.24885462106338815
Validation loss: 2.871522624882343

Epoch: 5| Step: 1
Training loss: 0.23089458435901605
Validation loss: 2.8072366313930246

Epoch: 5| Step: 2
Training loss: 0.4278259179384478
Validation loss: 2.8223010209447765

Epoch: 5| Step: 3
Training loss: 0.31197407096857743
Validation loss: 2.8399384617042793

Epoch: 5| Step: 4
Training loss: 0.30384948612218016
Validation loss: 2.825534441984017

Epoch: 5| Step: 5
Training loss: 0.36408734871211607
Validation loss: 2.829345320415391

Epoch: 5| Step: 6
Training loss: 0.43423198431326754
Validation loss: 2.8084627314582655

Epoch: 5| Step: 7
Training loss: 0.6275218392557383
Validation loss: 2.825465861311653

Epoch: 5| Step: 8
Training loss: 0.2539092870677362
Validation loss: 2.873024213205772

Epoch: 5| Step: 9
Training loss: 0.3037475490274954
Validation loss: 2.799551959606917

Epoch: 5| Step: 10
Training loss: 0.26659751022668665
Validation loss: 2.8620235912888834

Epoch: 5| Step: 11
Training loss: 0.7539641600193331
Validation loss: 2.8685719909236127

Epoch: 518| Step: 0
Training loss: 0.3696271929077592
Validation loss: 2.852912297699327

Epoch: 5| Step: 1
Training loss: 0.39975515039142767
Validation loss: 2.8472111741810475

Epoch: 5| Step: 2
Training loss: 0.2618918060245152
Validation loss: 2.8736679992823877

Epoch: 5| Step: 3
Training loss: 0.3483466354918616
Validation loss: 2.833128197106662

Epoch: 5| Step: 4
Training loss: 0.33310370309183385
Validation loss: 2.8305788090888027

Epoch: 5| Step: 5
Training loss: 0.4102677511609114
Validation loss: 2.723005822397172

Epoch: 5| Step: 6
Training loss: 0.34930802256031307
Validation loss: 2.722505277938561

Epoch: 5| Step: 7
Training loss: 0.36690100186175567
Validation loss: 2.774693737370304

Epoch: 5| Step: 8
Training loss: 0.4860090258293948
Validation loss: 2.729319809603936

Epoch: 5| Step: 9
Training loss: 0.3652748044734633
Validation loss: 2.7565064007503546

Epoch: 5| Step: 10
Training loss: 0.5217342278217363
Validation loss: 2.7943464958041395

Epoch: 5| Step: 11
Training loss: 0.22524029397481157
Validation loss: 2.808746988062594

Epoch: 519| Step: 0
Training loss: 0.437262249105977
Validation loss: 2.73323891789689

Epoch: 5| Step: 1
Training loss: 0.33477624633747355
Validation loss: 2.808241665152462

Epoch: 5| Step: 2
Training loss: 0.2621162157828919
Validation loss: 2.7072554913332816

Epoch: 5| Step: 3
Training loss: 0.3305968435409393
Validation loss: 2.7624262884066946

Epoch: 5| Step: 4
Training loss: 0.26157248381106585
Validation loss: 2.667733326806886

Epoch: 5| Step: 5
Training loss: 0.3223844944752771
Validation loss: 2.76899857234057

Epoch: 5| Step: 6
Training loss: 0.3526061144859048
Validation loss: 2.783293227137115

Epoch: 5| Step: 7
Training loss: 0.5883450193658408
Validation loss: 2.785094238632417

Epoch: 5| Step: 8
Training loss: 0.29765141751028573
Validation loss: 2.81478210333717

Epoch: 5| Step: 9
Training loss: 0.2985009415586117
Validation loss: 2.8349628525132977

Epoch: 5| Step: 10
Training loss: 0.4271839554422662
Validation loss: 2.8677235343928364

Epoch: 5| Step: 11
Training loss: 0.2556532983575713
Validation loss: 2.754253912008914

Epoch: 520| Step: 0
Training loss: 0.23551591698195615
Validation loss: 2.8158532109781502

Epoch: 5| Step: 1
Training loss: 0.27612334368594516
Validation loss: 2.746752627803779

Epoch: 5| Step: 2
Training loss: 0.31895160003089745
Validation loss: 2.8013030718375256

Epoch: 5| Step: 3
Training loss: 0.1679858819962964
Validation loss: 2.8048829813691687

Epoch: 5| Step: 4
Training loss: 0.26175037591500966
Validation loss: 2.7734188777674484

Epoch: 5| Step: 5
Training loss: 0.35369084689263397
Validation loss: 2.794805745134263

Epoch: 5| Step: 6
Training loss: 0.5647959212740115
Validation loss: 2.8266968045187504

Epoch: 5| Step: 7
Training loss: 0.28823126020913126
Validation loss: 2.8153341389370445

Epoch: 5| Step: 8
Training loss: 0.35598784053053106
Validation loss: 2.821279104744924

Epoch: 5| Step: 9
Training loss: 0.25896406194734456
Validation loss: 2.851196868308904

Epoch: 5| Step: 10
Training loss: 0.37175657406210155
Validation loss: 2.832957145783992

Epoch: 5| Step: 11
Training loss: 0.2025121282842646
Validation loss: 2.883434952110189

Epoch: 521| Step: 0
Training loss: 0.4229873544908566
Validation loss: 2.843064938286292

Epoch: 5| Step: 1
Training loss: 0.26260771584952725
Validation loss: 2.743680638035411

Epoch: 5| Step: 2
Training loss: 0.19774736935207674
Validation loss: 2.811015323553271

Epoch: 5| Step: 3
Training loss: 0.4694399841775124
Validation loss: 2.7490141214017507

Epoch: 5| Step: 4
Training loss: 0.4180377118983663
Validation loss: 2.802870619737622

Epoch: 5| Step: 5
Training loss: 0.3430065221124706
Validation loss: 2.771741529402978

Epoch: 5| Step: 6
Training loss: 0.2553038353541119
Validation loss: 2.80100292993792

Epoch: 5| Step: 7
Training loss: 0.3932693052542908
Validation loss: 2.8716308420088335

Epoch: 5| Step: 8
Training loss: 0.3894044882077312
Validation loss: 2.854838655308684

Epoch: 5| Step: 9
Training loss: 0.565612368152838
Validation loss: 2.9158913035888516

Epoch: 5| Step: 10
Training loss: 0.2718762512835943
Validation loss: 2.8729225268360663

Epoch: 5| Step: 11
Training loss: 0.1625465793975457
Validation loss: 2.7721510469071555

Epoch: 522| Step: 0
Training loss: 0.3351869182293545
Validation loss: 2.805201344363892

Epoch: 5| Step: 1
Training loss: 0.3220675119587096
Validation loss: 2.775407487288741

Epoch: 5| Step: 2
Training loss: 0.47255481861149323
Validation loss: 2.7659535509203415

Epoch: 5| Step: 3
Training loss: 0.41314256789442866
Validation loss: 2.7394926554149808

Epoch: 5| Step: 4
Training loss: 0.2618531693256376
Validation loss: 2.8159771652795

Epoch: 5| Step: 5
Training loss: 0.4014638334246268
Validation loss: 2.869733037309329

Epoch: 5| Step: 6
Training loss: 0.28421296911248306
Validation loss: 2.8957350060123805

Epoch: 5| Step: 7
Training loss: 0.4602568984263233
Validation loss: 2.8120396502234164

Epoch: 5| Step: 8
Training loss: 0.47313697265634314
Validation loss: 2.8150499158084648

Epoch: 5| Step: 9
Training loss: 0.3359467261178573
Validation loss: 2.7681232562518634

Epoch: 5| Step: 10
Training loss: 0.39825012438593166
Validation loss: 2.848444570957042

Epoch: 5| Step: 11
Training loss: 0.34257667958771315
Validation loss: 2.810861085281043

Epoch: 523| Step: 0
Training loss: 0.21134109210495325
Validation loss: 2.8037889505833617

Epoch: 5| Step: 1
Training loss: 0.2580718556577016
Validation loss: 2.8464407190749816

Epoch: 5| Step: 2
Training loss: 0.31754984055204116
Validation loss: 2.8464728758483577

Epoch: 5| Step: 3
Training loss: 0.512600757417257
Validation loss: 2.8960806560331833

Epoch: 5| Step: 4
Training loss: 0.3709803156900356
Validation loss: 2.9028295843671788

Epoch: 5| Step: 5
Training loss: 0.4341396984332777
Validation loss: 2.8479868344190606

Epoch: 5| Step: 6
Training loss: 0.25539389338929835
Validation loss: 2.821236371914624

Epoch: 5| Step: 7
Training loss: 0.23115597114891695
Validation loss: 2.8220722699836736

Epoch: 5| Step: 8
Training loss: 0.3062532006310573
Validation loss: 2.8440233700045128

Epoch: 5| Step: 9
Training loss: 0.3056558967450227
Validation loss: 2.8076105532360476

Epoch: 5| Step: 10
Training loss: 0.33080165048721416
Validation loss: 2.8361249411634204

Epoch: 5| Step: 11
Training loss: 0.38060002421976874
Validation loss: 2.8101449749327743

Epoch: 524| Step: 0
Training loss: 0.42542968024258304
Validation loss: 2.8048167964845923

Epoch: 5| Step: 1
Training loss: 0.23882424131460805
Validation loss: 2.885894964125319

Epoch: 5| Step: 2
Training loss: 0.2941552613202335
Validation loss: 2.869611789283853

Epoch: 5| Step: 3
Training loss: 0.3659178107459585
Validation loss: 2.874424303161028

Epoch: 5| Step: 4
Training loss: 0.45673380244556755
Validation loss: 2.950631890671693

Epoch: 5| Step: 5
Training loss: 0.5369867913204027
Validation loss: 2.856434653063934

Epoch: 5| Step: 6
Training loss: 0.5170927542945855
Validation loss: 2.7279073063942447

Epoch: 5| Step: 7
Training loss: 0.37535317002880286
Validation loss: 2.7698451744402015

Epoch: 5| Step: 8
Training loss: 0.5292688904293471
Validation loss: 2.7961438464707515

Epoch: 5| Step: 9
Training loss: 0.38282921812959303
Validation loss: 2.7842890926342125

Epoch: 5| Step: 10
Training loss: 0.41208091746060205
Validation loss: 2.745782663623592

Epoch: 5| Step: 11
Training loss: 0.2963572303644897
Validation loss: 2.869456939192045

Epoch: 525| Step: 0
Training loss: 0.5566890494715968
Validation loss: 2.8840511627916845

Epoch: 5| Step: 1
Training loss: 0.4884477712877738
Validation loss: 2.951532301067566

Epoch: 5| Step: 2
Training loss: 0.5777653271248558
Validation loss: 2.894634009908308

Epoch: 5| Step: 3
Training loss: 0.3591624543628193
Validation loss: 2.826202772033565

Epoch: 5| Step: 4
Training loss: 0.3347178875817044
Validation loss: 2.8203631825353286

Epoch: 5| Step: 5
Training loss: 0.5563033571262335
Validation loss: 2.7285491205852335

Epoch: 5| Step: 6
Training loss: 0.4274017224923761
Validation loss: 2.6975961124077843

Epoch: 5| Step: 7
Training loss: 0.3434446018585033
Validation loss: 2.807603098073796

Epoch: 5| Step: 8
Training loss: 0.3248694107063623
Validation loss: 2.827952300642007

Epoch: 5| Step: 9
Training loss: 0.21388918619802655
Validation loss: 2.8251682512710476

Epoch: 5| Step: 10
Training loss: 0.44792035751892123
Validation loss: 2.9580332823267943

Epoch: 5| Step: 11
Training loss: 0.19537995127397623
Validation loss: 2.949134623357131

Epoch: 526| Step: 0
Training loss: 0.4436323191183292
Validation loss: 2.9492089008225784

Epoch: 5| Step: 1
Training loss: 0.33455244908520343
Validation loss: 2.861401279456047

Epoch: 5| Step: 2
Training loss: 0.3407214548751805
Validation loss: 2.8514639153705414

Epoch: 5| Step: 3
Training loss: 0.3777197518422593
Validation loss: 2.6835849138065364

Epoch: 5| Step: 4
Training loss: 0.5552979454833744
Validation loss: 2.7352247752402645

Epoch: 5| Step: 5
Training loss: 0.41219619993409046
Validation loss: 2.834047680916058

Epoch: 5| Step: 6
Training loss: 0.25096396032376767
Validation loss: 2.8246021072124674

Epoch: 5| Step: 7
Training loss: 0.5164299952231685
Validation loss: 2.7774969309982436

Epoch: 5| Step: 8
Training loss: 0.37086387340645316
Validation loss: 2.8351382731076846

Epoch: 5| Step: 9
Training loss: 0.4279718654222522
Validation loss: 2.8520454276505474

Epoch: 5| Step: 10
Training loss: 0.2718782928968936
Validation loss: 2.724290828701224

Epoch: 5| Step: 11
Training loss: 0.34638660561038404
Validation loss: 2.736605695269085

Epoch: 527| Step: 0
Training loss: 0.5460398427745288
Validation loss: 2.7419188133248116

Epoch: 5| Step: 1
Training loss: 0.40420811365243037
Validation loss: 2.783514062121086

Epoch: 5| Step: 2
Training loss: 0.32481715120498017
Validation loss: 2.7960956880090744

Epoch: 5| Step: 3
Training loss: 0.3553773112642884
Validation loss: 2.7998749469465456

Epoch: 5| Step: 4
Training loss: 0.3984537121335489
Validation loss: 2.8212993054299194

Epoch: 5| Step: 5
Training loss: 0.26764264686253264
Validation loss: 2.8322629496184946

Epoch: 5| Step: 6
Training loss: 0.27450785272862166
Validation loss: 2.741013847235609

Epoch: 5| Step: 7
Training loss: 0.29112797047109784
Validation loss: 2.7440480317301756

Epoch: 5| Step: 8
Training loss: 0.24140705985022937
Validation loss: 2.721460277672806

Epoch: 5| Step: 9
Training loss: 0.30547487784480876
Validation loss: 2.7483015017018406

Epoch: 5| Step: 10
Training loss: 0.3730183735290287
Validation loss: 2.7329119882855215

Epoch: 5| Step: 11
Training loss: 0.2792834965629493
Validation loss: 2.750508070019638

Epoch: 528| Step: 0
Training loss: 0.4788268964779393
Validation loss: 2.822780434581078

Epoch: 5| Step: 1
Training loss: 0.36588964991535905
Validation loss: 2.775409377175894

Epoch: 5| Step: 2
Training loss: 0.29569171697060354
Validation loss: 2.83466622378644

Epoch: 5| Step: 3
Training loss: 0.3404493745330004
Validation loss: 2.727952630102301

Epoch: 5| Step: 4
Training loss: 0.42382188432027884
Validation loss: 2.7393855300295935

Epoch: 5| Step: 5
Training loss: 0.3367973457179168
Validation loss: 2.7824267030540435

Epoch: 5| Step: 6
Training loss: 0.26954845705254127
Validation loss: 2.774186548081769

Epoch: 5| Step: 7
Training loss: 0.25487370675728455
Validation loss: 2.7742393015203497

Epoch: 5| Step: 8
Training loss: 0.2663161598084799
Validation loss: 2.830823890881591

Epoch: 5| Step: 9
Training loss: 0.3489525448143482
Validation loss: 2.777724471110555

Epoch: 5| Step: 10
Training loss: 0.33653319572164675
Validation loss: 2.772740752049526

Epoch: 5| Step: 11
Training loss: 0.1638503860571815
Validation loss: 2.815879003489901

Epoch: 529| Step: 0
Training loss: 0.3954233526777385
Validation loss: 2.80484915420663

Epoch: 5| Step: 1
Training loss: 0.26294949794840317
Validation loss: 2.796601592895524

Epoch: 5| Step: 2
Training loss: 0.5716923260375085
Validation loss: 2.7982429235116637

Epoch: 5| Step: 3
Training loss: 0.29139896721215064
Validation loss: 2.800218703890724

Epoch: 5| Step: 4
Training loss: 0.3932133749344601
Validation loss: 2.7731552481862622

Epoch: 5| Step: 5
Training loss: 0.3822508019201276
Validation loss: 2.8145752420786776

Epoch: 5| Step: 6
Training loss: 0.2901536092396637
Validation loss: 2.7477294659036313

Epoch: 5| Step: 7
Training loss: 0.3455368762949024
Validation loss: 2.7750949151758233

Epoch: 5| Step: 8
Training loss: 0.2895661425576514
Validation loss: 2.8422881445699426

Epoch: 5| Step: 9
Training loss: 0.36279298928672765
Validation loss: 2.824372550747755

Epoch: 5| Step: 10
Training loss: 0.3311705260036717
Validation loss: 2.835948744402155

Epoch: 5| Step: 11
Training loss: 0.13412754372746996
Validation loss: 2.7217680779065176

Epoch: 530| Step: 0
Training loss: 0.2958190987860659
Validation loss: 2.7790671615764526

Epoch: 5| Step: 1
Training loss: 0.30136963651086024
Validation loss: 2.760809605300069

Epoch: 5| Step: 2
Training loss: 0.3319854031493606
Validation loss: 2.7133182822967172

Epoch: 5| Step: 3
Training loss: 0.2746912143790308
Validation loss: 2.7589429568237387

Epoch: 5| Step: 4
Training loss: 0.28273553064325696
Validation loss: 2.819346458839135

Epoch: 5| Step: 5
Training loss: 0.2713648169191445
Validation loss: 2.82169160736299

Epoch: 5| Step: 6
Training loss: 0.2957776644651119
Validation loss: 2.9081603987104083

Epoch: 5| Step: 7
Training loss: 0.27975535608538576
Validation loss: 2.829836357466095

Epoch: 5| Step: 8
Training loss: 0.4921729978816659
Validation loss: 2.837178367781841

Epoch: 5| Step: 9
Training loss: 0.26951383451505856
Validation loss: 2.845995903444905

Epoch: 5| Step: 10
Training loss: 0.2886544259750786
Validation loss: 2.809230412180829

Epoch: 5| Step: 11
Training loss: 0.4483226961459883
Validation loss: 2.8719762885959796

Epoch: 531| Step: 0
Training loss: 0.390682292551411
Validation loss: 2.7883101658752656

Epoch: 5| Step: 1
Training loss: 0.21397257955853302
Validation loss: 2.859663498851787

Epoch: 5| Step: 2
Training loss: 0.521354601996739
Validation loss: 2.769862730404113

Epoch: 5| Step: 3
Training loss: 0.3737568515289922
Validation loss: 2.784006577908986

Epoch: 5| Step: 4
Training loss: 0.2676692306346071
Validation loss: 2.8223777317542043

Epoch: 5| Step: 5
Training loss: 0.2689519129256914
Validation loss: 2.860335864328651

Epoch: 5| Step: 6
Training loss: 0.36059138476885944
Validation loss: 2.794276363987114

Epoch: 5| Step: 7
Training loss: 0.5609036151140391
Validation loss: 2.8054056054089913

Epoch: 5| Step: 8
Training loss: 0.27967560705547173
Validation loss: 2.821105445774892

Epoch: 5| Step: 9
Training loss: 0.40666438023257967
Validation loss: 2.8673237864354535

Epoch: 5| Step: 10
Training loss: 0.34485891681291747
Validation loss: 2.859847906921408

Epoch: 5| Step: 11
Training loss: 0.4200441049510649
Validation loss: 2.852910734238902

Epoch: 532| Step: 0
Training loss: 0.28376312137295595
Validation loss: 2.787079473886219

Epoch: 5| Step: 1
Training loss: 0.4144548680361409
Validation loss: 2.776384673598563

Epoch: 5| Step: 2
Training loss: 0.5061940150446312
Validation loss: 2.8567342410993954

Epoch: 5| Step: 3
Training loss: 0.2940973667996134
Validation loss: 2.789577411667168

Epoch: 5| Step: 4
Training loss: 0.4003277612973872
Validation loss: 2.8192588338426843

Epoch: 5| Step: 5
Training loss: 0.4065544931325549
Validation loss: 2.8379128532475524

Epoch: 5| Step: 6
Training loss: 0.40911668096628245
Validation loss: 2.845443769621843

Epoch: 5| Step: 7
Training loss: 0.28481987487456323
Validation loss: 2.857496899002097

Epoch: 5| Step: 8
Training loss: 0.27559739324927984
Validation loss: 2.8276794988959426

Epoch: 5| Step: 9
Training loss: 0.3317414982920188
Validation loss: 2.830616371740778

Epoch: 5| Step: 10
Training loss: 0.3184115127276816
Validation loss: 2.792847825924956

Epoch: 5| Step: 11
Training loss: 0.31577736557237607
Validation loss: 2.774470614150433

Epoch: 533| Step: 0
Training loss: 0.21913592321618364
Validation loss: 2.7843349078567576

Epoch: 5| Step: 1
Training loss: 0.22187888652460058
Validation loss: 2.777749358800048

Epoch: 5| Step: 2
Training loss: 0.3300485767027528
Validation loss: 2.727356296912204

Epoch: 5| Step: 3
Training loss: 0.33777668305195757
Validation loss: 2.8549880646435546

Epoch: 5| Step: 4
Training loss: 0.3272343536975844
Validation loss: 2.8047658649005744

Epoch: 5| Step: 5
Training loss: 0.3992235433510949
Validation loss: 2.8072816262333977

Epoch: 5| Step: 6
Training loss: 0.42412045500951173
Validation loss: 2.8538473755849822

Epoch: 5| Step: 7
Training loss: 0.33817471154644035
Validation loss: 2.848878839605338

Epoch: 5| Step: 8
Training loss: 0.3747429165173874
Validation loss: 2.77112572544615

Epoch: 5| Step: 9
Training loss: 0.27041503196500427
Validation loss: 2.7601184299993675

Epoch: 5| Step: 10
Training loss: 0.28825350268635286
Validation loss: 2.8138407160719305

Epoch: 5| Step: 11
Training loss: 0.3382194770989158
Validation loss: 2.802468930388978

Epoch: 534| Step: 0
Training loss: 0.34956836992747736
Validation loss: 2.8045790960389163

Epoch: 5| Step: 1
Training loss: 0.3430863498154084
Validation loss: 2.819882850642921

Epoch: 5| Step: 2
Training loss: 0.3219821145239391
Validation loss: 2.8645640297441597

Epoch: 5| Step: 3
Training loss: 0.5103527794643511
Validation loss: 2.851663882051495

Epoch: 5| Step: 4
Training loss: 0.409268626741691
Validation loss: 2.837350376038155

Epoch: 5| Step: 5
Training loss: 0.3424701816394204
Validation loss: 2.8274394217757917

Epoch: 5| Step: 6
Training loss: 0.31880413184805906
Validation loss: 2.7860051199479625

Epoch: 5| Step: 7
Training loss: 0.2986951170471125
Validation loss: 2.808075504654966

Epoch: 5| Step: 8
Training loss: 0.22795441990993856
Validation loss: 2.771194181153977

Epoch: 5| Step: 9
Training loss: 0.2838280196206747
Validation loss: 2.887484643738442

Epoch: 5| Step: 10
Training loss: 0.3051782958880772
Validation loss: 2.7946630180759886

Epoch: 5| Step: 11
Training loss: 0.15353203993923495
Validation loss: 2.7965961793269756

Epoch: 535| Step: 0
Training loss: 0.386087827710404
Validation loss: 2.800121213639385

Epoch: 5| Step: 1
Training loss: 0.4289814610365794
Validation loss: 2.772428026190994

Epoch: 5| Step: 2
Training loss: 0.26846514509531794
Validation loss: 2.7866457629522503

Epoch: 5| Step: 3
Training loss: 0.4738012584544772
Validation loss: 2.7808585123570833

Epoch: 5| Step: 4
Training loss: 0.43243387097102515
Validation loss: 2.8005716058291794

Epoch: 5| Step: 5
Training loss: 0.37981967352288
Validation loss: 2.8867636897779265

Epoch: 5| Step: 6
Training loss: 0.2557451852389995
Validation loss: 2.87138648238398

Epoch: 5| Step: 7
Training loss: 0.3816293806529961
Validation loss: 2.789107431856566

Epoch: 5| Step: 8
Training loss: 0.5108835232655811
Validation loss: 2.853349771799511

Epoch: 5| Step: 9
Training loss: 0.2944458663179347
Validation loss: 2.835195537150224

Epoch: 5| Step: 10
Training loss: 0.3289105571365138
Validation loss: 2.921789722252142

Epoch: 5| Step: 11
Training loss: 0.31024362644915554
Validation loss: 2.7726651723715805

Epoch: 536| Step: 0
Training loss: 0.28355003682090724
Validation loss: 2.7763955974344086

Epoch: 5| Step: 1
Training loss: 0.30079902249628254
Validation loss: 2.807487425528289

Epoch: 5| Step: 2
Training loss: 0.3140030239970991
Validation loss: 2.7964672558608585

Epoch: 5| Step: 3
Training loss: 0.3987149226446483
Validation loss: 2.8466651702388552

Epoch: 5| Step: 4
Training loss: 0.46840192269065833
Validation loss: 2.779281862798748

Epoch: 5| Step: 5
Training loss: 0.34184604836010457
Validation loss: 2.8205144145962184

Epoch: 5| Step: 6
Training loss: 0.3110773366356416
Validation loss: 2.742542932122757

Epoch: 5| Step: 7
Training loss: 0.3360322552494497
Validation loss: 2.7946752816638796

Epoch: 5| Step: 8
Training loss: 0.3300749987392112
Validation loss: 2.722697359392267

Epoch: 5| Step: 9
Training loss: 0.36517211056935467
Validation loss: 2.7338735865487456

Epoch: 5| Step: 10
Training loss: 0.2714726699391514
Validation loss: 2.736956618361626

Epoch: 5| Step: 11
Training loss: 0.49436178271713677
Validation loss: 2.7895717316249264

Epoch: 537| Step: 0
Training loss: 0.31026131318219874
Validation loss: 2.848953202897961

Epoch: 5| Step: 1
Training loss: 0.3903912226176349
Validation loss: 2.8941421796427513

Epoch: 5| Step: 2
Training loss: 0.6818644858300551
Validation loss: 2.8208227673440223

Epoch: 5| Step: 3
Training loss: 0.3174561987910816
Validation loss: 2.8088828845719034

Epoch: 5| Step: 4
Training loss: 0.31200376688535597
Validation loss: 2.843344079554853

Epoch: 5| Step: 5
Training loss: 0.3937796808591006
Validation loss: 2.78461266947177

Epoch: 5| Step: 6
Training loss: 0.3751386147850027
Validation loss: 2.7841833197780623

Epoch: 5| Step: 7
Training loss: 0.24893114960405133
Validation loss: 2.763704412513668

Epoch: 5| Step: 8
Training loss: 0.3649787620348977
Validation loss: 2.766608467456995

Epoch: 5| Step: 9
Training loss: 0.44384431575445527
Validation loss: 2.766997232183688

Epoch: 5| Step: 10
Training loss: 0.420770010417379
Validation loss: 2.8617795256155203

Epoch: 5| Step: 11
Training loss: 0.26467699692119556
Validation loss: 2.9087929009133235

Epoch: 538| Step: 0
Training loss: 0.4352139282353888
Validation loss: 2.837819573951902

Epoch: 5| Step: 1
Training loss: 0.405578516837425
Validation loss: 2.886107466504371

Epoch: 5| Step: 2
Training loss: 0.3701173485425936
Validation loss: 2.8069441809715197

Epoch: 5| Step: 3
Training loss: 0.40416449991936626
Validation loss: 2.779649466843537

Epoch: 5| Step: 4
Training loss: 0.5308137954108609
Validation loss: 2.7777340932563486

Epoch: 5| Step: 5
Training loss: 0.46981241310081273
Validation loss: 2.743305976250571

Epoch: 5| Step: 6
Training loss: 0.3491122798207236
Validation loss: 2.789146243992159

Epoch: 5| Step: 7
Training loss: 0.3270862121617324
Validation loss: 2.771745457537672

Epoch: 5| Step: 8
Training loss: 0.2284544512386243
Validation loss: 2.7908187593899862

Epoch: 5| Step: 9
Training loss: 0.3745739423842687
Validation loss: 2.8284338787706

Epoch: 5| Step: 10
Training loss: 0.32699763679817034
Validation loss: 2.7247499855793547

Epoch: 5| Step: 11
Training loss: 0.27963802869778404
Validation loss: 2.7348466193970835

Epoch: 539| Step: 0
Training loss: 0.540349557200406
Validation loss: 2.7679278095148745

Epoch: 5| Step: 1
Training loss: 0.27099733094628903
Validation loss: 2.7278174251343392

Epoch: 5| Step: 2
Training loss: 0.2621223554509638
Validation loss: 2.7948144962735233

Epoch: 5| Step: 3
Training loss: 0.32830091710757026
Validation loss: 2.8313468930560695

Epoch: 5| Step: 4
Training loss: 0.33505199962899357
Validation loss: 2.8202874947775265

Epoch: 5| Step: 5
Training loss: 0.33542103211699525
Validation loss: 2.809718550969171

Epoch: 5| Step: 6
Training loss: 0.4304741853900461
Validation loss: 2.7294117232707804

Epoch: 5| Step: 7
Training loss: 0.2904119695249849
Validation loss: 2.727132458944979

Epoch: 5| Step: 8
Training loss: 0.33756145253378267
Validation loss: 2.7813641421152253

Epoch: 5| Step: 9
Training loss: 0.3798169468752299
Validation loss: 2.731976708920513

Epoch: 5| Step: 10
Training loss: 0.3398021804115432
Validation loss: 2.787686215867847

Epoch: 5| Step: 11
Training loss: 0.2506994803387506
Validation loss: 2.7854905821741966

Epoch: 540| Step: 0
Training loss: 0.3609762592064655
Validation loss: 2.811377456724799

Epoch: 5| Step: 1
Training loss: 0.38883481851357615
Validation loss: 2.818275825811239

Epoch: 5| Step: 2
Training loss: 0.24418465026635694
Validation loss: 2.786770902316238

Epoch: 5| Step: 3
Training loss: 0.3322988665806224
Validation loss: 2.8448561099694234

Epoch: 5| Step: 4
Training loss: 0.22540416247142808
Validation loss: 2.792137207164642

Epoch: 5| Step: 5
Training loss: 0.24919139209651778
Validation loss: 2.786984653618395

Epoch: 5| Step: 6
Training loss: 0.27719353919777584
Validation loss: 2.851771286937221

Epoch: 5| Step: 7
Training loss: 0.2112500824025236
Validation loss: 2.852843845883447

Epoch: 5| Step: 8
Training loss: 0.4904871133342232
Validation loss: 2.8091359382247485

Epoch: 5| Step: 9
Training loss: 0.3827851344078182
Validation loss: 2.843961983768899

Epoch: 5| Step: 10
Training loss: 0.3553773951253508
Validation loss: 2.785689610955948

Epoch: 5| Step: 11
Training loss: 0.3863814067451328
Validation loss: 2.8093907972152636

Epoch: 541| Step: 0
Training loss: 0.26449196049978113
Validation loss: 2.85463779046358

Epoch: 5| Step: 1
Training loss: 0.3461604353336681
Validation loss: 2.758835261585425

Epoch: 5| Step: 2
Training loss: 0.3257989864872787
Validation loss: 2.8489894179485407

Epoch: 5| Step: 3
Training loss: 0.25509019796825494
Validation loss: 2.843829821070705

Epoch: 5| Step: 4
Training loss: 0.3322848081130068
Validation loss: 2.809427048424149

Epoch: 5| Step: 5
Training loss: 0.3169285501755951
Validation loss: 2.6627465910735286

Epoch: 5| Step: 6
Training loss: 0.31939808651966645
Validation loss: 2.7796356287821915

Epoch: 5| Step: 7
Training loss: 0.4064032375659635
Validation loss: 2.7398205691893303

Epoch: 5| Step: 8
Training loss: 0.45119081597801275
Validation loss: 2.778483926238385

Epoch: 5| Step: 9
Training loss: 0.3661927689177966
Validation loss: 2.812046187487032

Epoch: 5| Step: 10
Training loss: 0.36871046403914504
Validation loss: 2.779686888590519

Epoch: 5| Step: 11
Training loss: 0.3452613292081064
Validation loss: 2.8348980479547436

Epoch: 542| Step: 0
Training loss: 0.45552157624058565
Validation loss: 2.777316487210254

Epoch: 5| Step: 1
Training loss: 0.31745034306354886
Validation loss: 2.7323551856067585

Epoch: 5| Step: 2
Training loss: 0.35165373360135127
Validation loss: 2.7506482740158815

Epoch: 5| Step: 3
Training loss: 0.2394449942050033
Validation loss: 2.7606734978058487

Epoch: 5| Step: 4
Training loss: 0.3035869774723178
Validation loss: 2.824344475683844

Epoch: 5| Step: 5
Training loss: 0.34717257210942953
Validation loss: 2.765072510557793

Epoch: 5| Step: 6
Training loss: 0.3922547294168686
Validation loss: 2.779430812415135

Epoch: 5| Step: 7
Training loss: 0.3667053344054047
Validation loss: 2.811124899927338

Epoch: 5| Step: 8
Training loss: 0.26304309895509853
Validation loss: 2.8356308434117676

Epoch: 5| Step: 9
Training loss: 0.341015571253402
Validation loss: 2.8679743509108886

Epoch: 5| Step: 10
Training loss: 0.2879454577335623
Validation loss: 2.7878755667131334

Epoch: 5| Step: 11
Training loss: 0.24559825636358534
Validation loss: 2.7959714563099296

Epoch: 543| Step: 0
Training loss: 0.36769452496862415
Validation loss: 2.8213516568196266

Epoch: 5| Step: 1
Training loss: 0.3447950257351874
Validation loss: 2.7815125016480042

Epoch: 5| Step: 2
Training loss: 0.3246342627651043
Validation loss: 2.788523952374191

Epoch: 5| Step: 3
Training loss: 0.29087242341058156
Validation loss: 2.797044734670516

Epoch: 5| Step: 4
Training loss: 0.2754209380003785
Validation loss: 2.8160936779123875

Epoch: 5| Step: 5
Training loss: 0.349399407699429
Validation loss: 2.846978231122395

Epoch: 5| Step: 6
Training loss: 0.4367403860993794
Validation loss: 2.7957777289722987

Epoch: 5| Step: 7
Training loss: 0.27473892043095505
Validation loss: 2.8130606198523975

Epoch: 5| Step: 8
Training loss: 0.30937075274856196
Validation loss: 2.8098192401920006

Epoch: 5| Step: 9
Training loss: 0.23078967234662426
Validation loss: 2.818660417755849

Epoch: 5| Step: 10
Training loss: 0.2291752838913258
Validation loss: 2.8353569935880225

Epoch: 5| Step: 11
Training loss: 0.4805160127049684
Validation loss: 2.8095488394423946

Epoch: 544| Step: 0
Training loss: 0.3407890611546548
Validation loss: 2.812623745350576

Epoch: 5| Step: 1
Training loss: 0.32120123129385386
Validation loss: 2.7807154481078684

Epoch: 5| Step: 2
Training loss: 0.35364846110128434
Validation loss: 2.814570932528051

Epoch: 5| Step: 3
Training loss: 0.3857404684680347
Validation loss: 2.7835039121263296

Epoch: 5| Step: 4
Training loss: 0.3395346408679939
Validation loss: 2.887651766742304

Epoch: 5| Step: 5
Training loss: 0.36896522835754925
Validation loss: 2.7728554808937877

Epoch: 5| Step: 6
Training loss: 0.4654728295184917
Validation loss: 2.7831496169986663

Epoch: 5| Step: 7
Training loss: 0.3200585125907748
Validation loss: 2.793520064282627

Epoch: 5| Step: 8
Training loss: 0.4188884883303769
Validation loss: 2.790949132619784

Epoch: 5| Step: 9
Training loss: 0.3050340124809641
Validation loss: 2.809936025837025

Epoch: 5| Step: 10
Training loss: 0.3131481839351628
Validation loss: 2.7779855035889276

Epoch: 5| Step: 11
Training loss: 0.47700351883132136
Validation loss: 2.8162380808490415

Epoch: 545| Step: 0
Training loss: 0.357328308866059
Validation loss: 2.7829395155966523

Epoch: 5| Step: 1
Training loss: 0.34413662755508573
Validation loss: 2.8332932460043385

Epoch: 5| Step: 2
Training loss: 0.2779967585664563
Validation loss: 2.786757199430601

Epoch: 5| Step: 3
Training loss: 0.3208353729410281
Validation loss: 2.794549966588955

Epoch: 5| Step: 4
Training loss: 0.34511557180893243
Validation loss: 2.7470669186423438

Epoch: 5| Step: 5
Training loss: 0.2801838774922371
Validation loss: 2.8542177457949163

Epoch: 5| Step: 6
Training loss: 0.48963572512642867
Validation loss: 2.7912580928921487

Epoch: 5| Step: 7
Training loss: 0.3500914100930395
Validation loss: 2.766409337091326

Epoch: 5| Step: 8
Training loss: 0.33165660365851507
Validation loss: 2.8178717142193768

Epoch: 5| Step: 9
Training loss: 0.2460177319298049
Validation loss: 2.8058312226089166

Epoch: 5| Step: 10
Training loss: 0.3101094121663393
Validation loss: 2.8057224308771254

Epoch: 5| Step: 11
Training loss: 0.39253636987404
Validation loss: 2.7843071390909695

Epoch: 546| Step: 0
Training loss: 0.3448847874956336
Validation loss: 2.8222891765874567

Epoch: 5| Step: 1
Training loss: 0.3558466652569608
Validation loss: 2.7881340169685984

Epoch: 5| Step: 2
Training loss: 0.3338031165399194
Validation loss: 2.7306559093329885

Epoch: 5| Step: 3
Training loss: 0.3185847368223578
Validation loss: 2.8007204908433643

Epoch: 5| Step: 4
Training loss: 0.3182564434446547
Validation loss: 2.8452407855807618

Epoch: 5| Step: 5
Training loss: 0.2511821898957193
Validation loss: 2.7969929263580458

Epoch: 5| Step: 6
Training loss: 0.34876992230271386
Validation loss: 2.8300812455557853

Epoch: 5| Step: 7
Training loss: 0.4014319671553658
Validation loss: 2.8189145565987186

Epoch: 5| Step: 8
Training loss: 0.48317932403342057
Validation loss: 2.835774426636409

Epoch: 5| Step: 9
Training loss: 0.4000004425642426
Validation loss: 2.6893380813907393

Epoch: 5| Step: 10
Training loss: 0.377826213224946
Validation loss: 2.762598069494231

Epoch: 5| Step: 11
Training loss: 0.6086795702303262
Validation loss: 2.734230014045287

Epoch: 547| Step: 0
Training loss: 0.3604848144946566
Validation loss: 2.718744659783976

Epoch: 5| Step: 1
Training loss: 0.2881179791751516
Validation loss: 2.775964440040366

Epoch: 5| Step: 2
Training loss: 0.490040090901165
Validation loss: 2.833911462779615

Epoch: 5| Step: 3
Training loss: 0.3284464918733209
Validation loss: 2.8306571626088886

Epoch: 5| Step: 4
Training loss: 0.39456916853479534
Validation loss: 2.8273893316283387

Epoch: 5| Step: 5
Training loss: 0.287749763510215
Validation loss: 2.8240308439672677

Epoch: 5| Step: 6
Training loss: 0.2521616051011054
Validation loss: 2.7905926821077216

Epoch: 5| Step: 7
Training loss: 0.2569190351420546
Validation loss: 2.7460952838370685

Epoch: 5| Step: 8
Training loss: 0.3364928556551075
Validation loss: 2.8239596412024337

Epoch: 5| Step: 9
Training loss: 0.3607291540942115
Validation loss: 2.732503526661497

Epoch: 5| Step: 10
Training loss: 0.3011930173782944
Validation loss: 2.7572003802810365

Epoch: 5| Step: 11
Training loss: 0.3478424666520447
Validation loss: 2.864654281200006

Epoch: 548| Step: 0
Training loss: 0.2356564300226835
Validation loss: 2.8674625781022254

Epoch: 5| Step: 1
Training loss: 0.5121387767135164
Validation loss: 2.9226945655838015

Epoch: 5| Step: 2
Training loss: 0.3851659986333915
Validation loss: 2.838284791761674

Epoch: 5| Step: 3
Training loss: 0.23364183670930805
Validation loss: 2.8361162702052907

Epoch: 5| Step: 4
Training loss: 0.2835996154304703
Validation loss: 2.8008448559407597

Epoch: 5| Step: 5
Training loss: 0.3059445030065513
Validation loss: 2.803708903702694

Epoch: 5| Step: 6
Training loss: 0.41934245743677756
Validation loss: 2.8494251305828886

Epoch: 5| Step: 7
Training loss: 0.613553005193613
Validation loss: 2.804374833242662

Epoch: 5| Step: 8
Training loss: 0.19041476068927063
Validation loss: 2.862665211603298

Epoch: 5| Step: 9
Training loss: 0.3889373754274027
Validation loss: 2.874290378732534

Epoch: 5| Step: 10
Training loss: 0.3430613968307263
Validation loss: 2.816950275929534

Epoch: 5| Step: 11
Training loss: 0.2880144192129153
Validation loss: 2.8120154987797097

Epoch: 549| Step: 0
Training loss: 0.32337280584710876
Validation loss: 2.8643161695335966

Epoch: 5| Step: 1
Training loss: 0.3681977962348689
Validation loss: 2.8196195770913683

Epoch: 5| Step: 2
Training loss: 0.2617175828139056
Validation loss: 2.831387852336605

Epoch: 5| Step: 3
Training loss: 0.4161318406230034
Validation loss: 2.7206280422507705

Epoch: 5| Step: 4
Training loss: 0.22173327163874448
Validation loss: 2.8682236769700853

Epoch: 5| Step: 5
Training loss: 0.42027704167320823
Validation loss: 2.893364383251466

Epoch: 5| Step: 6
Training loss: 0.34209959520995104
Validation loss: 2.8771163365825765

Epoch: 5| Step: 7
Training loss: 0.502621632274169
Validation loss: 2.922481371948291

Epoch: 5| Step: 8
Training loss: 0.4386896070393604
Validation loss: 2.849563634870077

Epoch: 5| Step: 9
Training loss: 0.22158416504923212
Validation loss: 2.8387368627972402

Epoch: 5| Step: 10
Training loss: 0.41421439425762313
Validation loss: 2.7762046441671897

Epoch: 5| Step: 11
Training loss: 0.25435184113245024
Validation loss: 2.8526169834727777

Epoch: 550| Step: 0
Training loss: 0.4655681703437023
Validation loss: 2.7820624618543413

Epoch: 5| Step: 1
Training loss: 0.42158614972444314
Validation loss: 2.8161398928785215

Epoch: 5| Step: 2
Training loss: 0.23864825704690582
Validation loss: 2.902157604260302

Epoch: 5| Step: 3
Training loss: 0.4552964926781259
Validation loss: 2.916294225119503

Epoch: 5| Step: 4
Training loss: 0.5241069498245132
Validation loss: 2.870501717145271

Epoch: 5| Step: 5
Training loss: 0.4215128191664962
Validation loss: 2.8239595321508264

Epoch: 5| Step: 6
Training loss: 0.33550731705533404
Validation loss: 2.7712457118146725

Epoch: 5| Step: 7
Training loss: 0.5585837196569953
Validation loss: 2.80659730825178

Epoch: 5| Step: 8
Training loss: 0.5434853271356712
Validation loss: 2.786811422395766

Epoch: 5| Step: 9
Training loss: 0.3568050502694987
Validation loss: 2.869983058623578

Epoch: 5| Step: 10
Training loss: 0.29499872734716653
Validation loss: 2.841465860601067

Epoch: 5| Step: 11
Training loss: 0.21852695640285655
Validation loss: 2.88246303600819

Testing loss: 2.850427677131937
