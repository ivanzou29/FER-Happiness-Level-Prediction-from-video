Epoch: 1| Step: 0
Training loss: 6.361650439428165
Validation loss: 5.894284299847609

Epoch: 6| Step: 1
Training loss: 5.35087654562489
Validation loss: 5.892850959521375

Epoch: 6| Step: 2
Training loss: 6.225436349305791
Validation loss: 5.891445085962135

Epoch: 6| Step: 3
Training loss: 5.284897667535602
Validation loss: 5.889914418339797

Epoch: 6| Step: 4
Training loss: 6.390095807761653
Validation loss: 5.888331147938609

Epoch: 6| Step: 5
Training loss: 6.392635113269508
Validation loss: 5.886749989764833

Epoch: 6| Step: 6
Training loss: 6.259517899251882
Validation loss: 5.885155578043376

Epoch: 6| Step: 7
Training loss: 6.027218751235444
Validation loss: 5.883430276275559

Epoch: 6| Step: 8
Training loss: 6.265529413041135
Validation loss: 5.88168887569349

Epoch: 6| Step: 9
Training loss: 6.239883780742072
Validation loss: 5.879918819178492

Epoch: 6| Step: 10
Training loss: 6.066963676196769
Validation loss: 5.878034876460907

Epoch: 6| Step: 11
Training loss: 5.96633430848175
Validation loss: 5.876211379675645

Epoch: 6| Step: 12
Training loss: 5.158485251774346
Validation loss: 5.874312529686472

Epoch: 6| Step: 13
Training loss: 5.82625797424229
Validation loss: 5.872412416106252

Epoch: 2| Step: 0
Training loss: 6.2150441538438415
Validation loss: 5.870365316752279

Epoch: 6| Step: 1
Training loss: 6.224587925519994
Validation loss: 5.868312682086837

Epoch: 6| Step: 2
Training loss: 7.119537401065871
Validation loss: 5.86605820029124

Epoch: 6| Step: 3
Training loss: 5.85941731755552
Validation loss: 5.863712695617132

Epoch: 6| Step: 4
Training loss: 5.0988379033342035
Validation loss: 5.861370753864476

Epoch: 6| Step: 5
Training loss: 5.971763289607968
Validation loss: 5.858780161863593

Epoch: 6| Step: 6
Training loss: 5.937170722263487
Validation loss: 5.8562287288511525

Epoch: 6| Step: 7
Training loss: 5.994710498020578
Validation loss: 5.853615903456823

Epoch: 6| Step: 8
Training loss: 6.299582985291504
Validation loss: 5.850591072152855

Epoch: 6| Step: 9
Training loss: 5.471268602513462
Validation loss: 5.847693814157209

Epoch: 6| Step: 10
Training loss: 5.134773425607426
Validation loss: 5.844514195050557

Epoch: 6| Step: 11
Training loss: 6.842429952600903
Validation loss: 5.841288246961815

Epoch: 6| Step: 12
Training loss: 5.658264812940392
Validation loss: 5.837854059606199

Epoch: 6| Step: 13
Training loss: 5.395709395979759
Validation loss: 5.834303920471563

Epoch: 3| Step: 0
Training loss: 5.301375646021924
Validation loss: 5.830614909770112

Epoch: 6| Step: 1
Training loss: 7.0617718616627565
Validation loss: 5.826698762789272

Epoch: 6| Step: 2
Training loss: 6.2780805344096375
Validation loss: 5.82255283736303

Epoch: 6| Step: 3
Training loss: 6.596612245792373
Validation loss: 5.818453621205059

Epoch: 6| Step: 4
Training loss: 5.925747131370137
Validation loss: 5.81356044379613

Epoch: 6| Step: 5
Training loss: 6.492859659849426
Validation loss: 5.808806144629639

Epoch: 6| Step: 6
Training loss: 4.126638144998995
Validation loss: 5.803794494366329

Epoch: 6| Step: 7
Training loss: 6.307659446101088
Validation loss: 5.798727173192572

Epoch: 6| Step: 8
Training loss: 5.026586989893617
Validation loss: 5.793344222710797

Epoch: 6| Step: 9
Training loss: 5.742549547472428
Validation loss: 5.787629135811332

Epoch: 6| Step: 10
Training loss: 6.116219591368818
Validation loss: 5.782083427222296

Epoch: 6| Step: 11
Training loss: 6.44712924206326
Validation loss: 5.776171624040537

Epoch: 6| Step: 12
Training loss: 5.347341836139187
Validation loss: 5.770036066208132

Epoch: 6| Step: 13
Training loss: 5.420786811615304
Validation loss: 5.763438622634635

Epoch: 4| Step: 0
Training loss: 4.992679959694156
Validation loss: 5.757004465920966

Epoch: 6| Step: 1
Training loss: 5.5733978158849675
Validation loss: 5.7504047030235625

Epoch: 6| Step: 2
Training loss: 5.799963444561694
Validation loss: 5.743584412355708

Epoch: 6| Step: 3
Training loss: 5.963850477016257
Validation loss: 5.7361746172074515

Epoch: 6| Step: 4
Training loss: 5.909867727797179
Validation loss: 5.7288536494894045

Epoch: 6| Step: 5
Training loss: 6.226344393137367
Validation loss: 5.721849723633697

Epoch: 6| Step: 6
Training loss: 6.215812257580209
Validation loss: 5.7142098614789925

Epoch: 6| Step: 7
Training loss: 5.83759853108343
Validation loss: 5.706351704298699

Epoch: 6| Step: 8
Training loss: 6.206717193321369
Validation loss: 5.698354933189089

Epoch: 6| Step: 9
Training loss: 5.424525248062738
Validation loss: 5.6905557437252705

Epoch: 6| Step: 10
Training loss: 5.799954565462197
Validation loss: 5.682506143477397

Epoch: 6| Step: 11
Training loss: 5.911311811292165
Validation loss: 5.67435484480525

Epoch: 6| Step: 12
Training loss: 6.214878122940772
Validation loss: 5.666309270621003

Epoch: 6| Step: 13
Training loss: 5.323896324151373
Validation loss: 5.658389647498077

Epoch: 5| Step: 0
Training loss: 5.697022232438147
Validation loss: 5.650196496252915

Epoch: 6| Step: 1
Training loss: 5.540811840850841
Validation loss: 5.642360825237039

Epoch: 6| Step: 2
Training loss: 4.514792817728375
Validation loss: 5.634737191219421

Epoch: 6| Step: 3
Training loss: 6.3350090353162924
Validation loss: 5.627246012684731

Epoch: 6| Step: 4
Training loss: 5.631759989652852
Validation loss: 5.619720383110401

Epoch: 6| Step: 5
Training loss: 5.347541044344331
Validation loss: 5.612149599914065

Epoch: 6| Step: 6
Training loss: 5.9318377349329285
Validation loss: 5.604884284869886

Epoch: 6| Step: 7
Training loss: 5.953963733771512
Validation loss: 5.597559081301463

Epoch: 6| Step: 8
Training loss: 5.448729921790959
Validation loss: 5.5898733789141675

Epoch: 6| Step: 9
Training loss: 5.634415100936661
Validation loss: 5.582639831440814

Epoch: 6| Step: 10
Training loss: 5.236122317966888
Validation loss: 5.575326853523531

Epoch: 6| Step: 11
Training loss: 6.708637522875273
Validation loss: 5.568019971223436

Epoch: 6| Step: 12
Training loss: 5.998399839012244
Validation loss: 5.560601842814236

Epoch: 6| Step: 13
Training loss: 5.792577584989691
Validation loss: 5.553427451818003

Epoch: 6| Step: 0
Training loss: 5.071037158406402
Validation loss: 5.546045776853255

Epoch: 6| Step: 1
Training loss: 5.997559368925752
Validation loss: 5.538781449935954

Epoch: 6| Step: 2
Training loss: 5.7209711816252256
Validation loss: 5.5312234766552315

Epoch: 6| Step: 3
Training loss: 5.546076843433697
Validation loss: 5.524218240150842

Epoch: 6| Step: 4
Training loss: 5.419496745714185
Validation loss: 5.516872131731823

Epoch: 6| Step: 5
Training loss: 6.139734412298667
Validation loss: 5.509665233044982

Epoch: 6| Step: 6
Training loss: 5.490266857505742
Validation loss: 5.502393028540159

Epoch: 6| Step: 7
Training loss: 4.980425091720413
Validation loss: 5.495236356799021

Epoch: 6| Step: 8
Training loss: 5.386062593172155
Validation loss: 5.4883089944991195

Epoch: 6| Step: 9
Training loss: 5.906164098044292
Validation loss: 5.481389811873842

Epoch: 6| Step: 10
Training loss: 4.605263327691785
Validation loss: 5.474559640811599

Epoch: 6| Step: 11
Training loss: 6.006652958240736
Validation loss: 5.467644076467295

Epoch: 6| Step: 12
Training loss: 6.402881164525174
Validation loss: 5.460815311896765

Epoch: 6| Step: 13
Training loss: 5.7269781568113
Validation loss: 5.453798210612348

Epoch: 7| Step: 0
Training loss: 6.543759280601704
Validation loss: 5.447050717485552

Epoch: 6| Step: 1
Training loss: 5.475151457063375
Validation loss: 5.440125164200243

Epoch: 6| Step: 2
Training loss: 5.864053470758103
Validation loss: 5.433098425594484

Epoch: 6| Step: 3
Training loss: 5.08660199912092
Validation loss: 5.426228002506413

Epoch: 6| Step: 4
Training loss: 5.307772698532513
Validation loss: 5.419446564415489

Epoch: 6| Step: 5
Training loss: 6.14058213546585
Validation loss: 5.412522868166122

Epoch: 6| Step: 6
Training loss: 6.2244288906411676
Validation loss: 5.405531554361039

Epoch: 6| Step: 7
Training loss: 5.948572375424549
Validation loss: 5.398559274509926

Epoch: 6| Step: 8
Training loss: 5.294564162229857
Validation loss: 5.3911347226552415

Epoch: 6| Step: 9
Training loss: 5.258138978069647
Validation loss: 5.383791867186297

Epoch: 6| Step: 10
Training loss: 5.105514327694417
Validation loss: 5.37705549222805

Epoch: 6| Step: 11
Training loss: 4.63030783764824
Validation loss: 5.36998485238646

Epoch: 6| Step: 12
Training loss: 5.068899372124738
Validation loss: 5.362872258850298

Epoch: 6| Step: 13
Training loss: 5.0574786868285075
Validation loss: 5.356131414571862

Epoch: 8| Step: 0
Training loss: 5.639859387964883
Validation loss: 5.349144189187837

Epoch: 6| Step: 1
Training loss: 5.441619364993895
Validation loss: 5.342512972834868

Epoch: 6| Step: 2
Training loss: 5.096243031777471
Validation loss: 5.335965649375558

Epoch: 6| Step: 3
Training loss: 5.176730271190414
Validation loss: 5.329412429706165

Epoch: 6| Step: 4
Training loss: 4.053907021614158
Validation loss: 5.322768008351633

Epoch: 6| Step: 5
Training loss: 5.020572681968825
Validation loss: 5.3161337598357905

Epoch: 6| Step: 6
Training loss: 4.079166907731628
Validation loss: 5.309808655216974

Epoch: 6| Step: 7
Training loss: 6.015182042843335
Validation loss: 5.303373238593029

Epoch: 6| Step: 8
Training loss: 5.438167136471554
Validation loss: 5.297065063787528

Epoch: 6| Step: 9
Training loss: 5.933030222890528
Validation loss: 5.290651579487988

Epoch: 6| Step: 10
Training loss: 6.458421800889372
Validation loss: 5.2841265667569575

Epoch: 6| Step: 11
Training loss: 6.385043143154274
Validation loss: 5.2770816221157855

Epoch: 6| Step: 12
Training loss: 5.201988302250681
Validation loss: 5.2707360099080045

Epoch: 6| Step: 13
Training loss: 5.426067391437908
Validation loss: 5.26438730788465

Epoch: 9| Step: 0
Training loss: 4.673034115915563
Validation loss: 5.257990765584404

Epoch: 6| Step: 1
Training loss: 5.609556572400785
Validation loss: 5.252470464585554

Epoch: 6| Step: 2
Training loss: 6.193501653994863
Validation loss: 5.246907367799581

Epoch: 6| Step: 3
Training loss: 4.462728004080388
Validation loss: 5.241650617824582

Epoch: 6| Step: 4
Training loss: 4.880585429612127
Validation loss: 5.23630117020291

Epoch: 6| Step: 5
Training loss: 5.221317961480876
Validation loss: 5.2314018953634385

Epoch: 6| Step: 6
Training loss: 5.788133307260398
Validation loss: 5.226329423832683

Epoch: 6| Step: 7
Training loss: 5.097571314546248
Validation loss: 5.221165552957927

Epoch: 6| Step: 8
Training loss: 6.573209035651247
Validation loss: 5.215817935545236

Epoch: 6| Step: 9
Training loss: 6.199035987972306
Validation loss: 5.210723582790199

Epoch: 6| Step: 10
Training loss: 4.4735438103390095
Validation loss: 5.205147534373441

Epoch: 6| Step: 11
Training loss: 3.7418810374496534
Validation loss: 5.199996175520053

Epoch: 6| Step: 12
Training loss: 5.4021615682405315
Validation loss: 5.195093564270059

Epoch: 6| Step: 13
Training loss: 5.772364701262799
Validation loss: 5.190474427282485

Epoch: 10| Step: 0
Training loss: 5.28457266213982
Validation loss: 5.185904077366845

Epoch: 6| Step: 1
Training loss: 5.210797309419501
Validation loss: 5.1812422055568135

Epoch: 6| Step: 2
Training loss: 5.682023650182254
Validation loss: 5.176410204021809

Epoch: 6| Step: 3
Training loss: 6.043930085742857
Validation loss: 5.171575009345881

Epoch: 6| Step: 4
Training loss: 5.219451674385922
Validation loss: 5.167057186667884

Epoch: 6| Step: 5
Training loss: 5.282883069961305
Validation loss: 5.161824182298028

Epoch: 6| Step: 6
Training loss: 5.432215084463883
Validation loss: 5.157280219839768

Epoch: 6| Step: 7
Training loss: 5.355014639869147
Validation loss: 5.15217941365298

Epoch: 6| Step: 8
Training loss: 4.980755008623955
Validation loss: 5.148321602905649

Epoch: 6| Step: 9
Training loss: 5.2407759515612655
Validation loss: 5.143878251335165

Epoch: 6| Step: 10
Training loss: 5.574783649437627
Validation loss: 5.139282391348672

Epoch: 6| Step: 11
Training loss: 4.504634801561007
Validation loss: 5.134163982925411

Epoch: 6| Step: 12
Training loss: 5.788553109969157
Validation loss: 5.130055020231242

Epoch: 6| Step: 13
Training loss: 3.99129110227329
Validation loss: 5.125229884628602

Epoch: 11| Step: 0
Training loss: 5.367737410136119
Validation loss: 5.121096574407672

Epoch: 6| Step: 1
Training loss: 4.568685023397605
Validation loss: 5.116691460482058

Epoch: 6| Step: 2
Training loss: 5.189344331048157
Validation loss: 5.112392922471608

Epoch: 6| Step: 3
Training loss: 5.980270372485457
Validation loss: 5.108575040856215

Epoch: 6| Step: 4
Training loss: 4.8839002694609785
Validation loss: 5.103679628555839

Epoch: 6| Step: 5
Training loss: 4.925853078319971
Validation loss: 5.0991225977601395

Epoch: 6| Step: 6
Training loss: 5.333726371746772
Validation loss: 5.095218719739282

Epoch: 6| Step: 7
Training loss: 4.105960253939825
Validation loss: 5.090465212024251

Epoch: 6| Step: 8
Training loss: 4.549691393101398
Validation loss: 5.086119195883188

Epoch: 6| Step: 9
Training loss: 6.075274036647345
Validation loss: 5.08182394830047

Epoch: 6| Step: 10
Training loss: 4.520784064286659
Validation loss: 5.077333421878119

Epoch: 6| Step: 11
Training loss: 5.450713840596506
Validation loss: 5.073438780729326

Epoch: 6| Step: 12
Training loss: 6.150503196909608
Validation loss: 5.0687084825025055

Epoch: 6| Step: 13
Training loss: 5.445232461918504
Validation loss: 5.064318153827788

Epoch: 12| Step: 0
Training loss: 5.009420675258665
Validation loss: 5.059771552124494

Epoch: 6| Step: 1
Training loss: 5.396624689973687
Validation loss: 5.05576152288795

Epoch: 6| Step: 2
Training loss: 4.712855415196904
Validation loss: 5.050903192962316

Epoch: 6| Step: 3
Training loss: 4.363445173034282
Validation loss: 5.046133799890335

Epoch: 6| Step: 4
Training loss: 5.313277243809143
Validation loss: 5.042265212834654

Epoch: 6| Step: 5
Training loss: 5.7855742906860055
Validation loss: 5.037231396502124

Epoch: 6| Step: 6
Training loss: 5.6299570917422095
Validation loss: 5.032287301175022

Epoch: 6| Step: 7
Training loss: 6.065747207440342
Validation loss: 5.027680641392802

Epoch: 6| Step: 8
Training loss: 4.98282668601236
Validation loss: 5.02295065063642

Epoch: 6| Step: 9
Training loss: 5.025641116716672
Validation loss: 5.01845560188211

Epoch: 6| Step: 10
Training loss: 5.214327097241442
Validation loss: 5.013420373096794

Epoch: 6| Step: 11
Training loss: 4.857346089703332
Validation loss: 5.008992151903211

Epoch: 6| Step: 12
Training loss: 4.713678931947564
Validation loss: 5.004233443645506

Epoch: 6| Step: 13
Training loss: 4.8409529947332475
Validation loss: 4.99925483873006

Epoch: 13| Step: 0
Training loss: 6.252213963338057
Validation loss: 4.994840980368555

Epoch: 6| Step: 1
Training loss: 5.19326021200928
Validation loss: 4.990015710667079

Epoch: 6| Step: 2
Training loss: 5.728525280741096
Validation loss: 4.985609421894

Epoch: 6| Step: 3
Training loss: 4.204044737747497
Validation loss: 4.980631284367915

Epoch: 6| Step: 4
Training loss: 4.531161182453892
Validation loss: 4.975622482589866

Epoch: 6| Step: 5
Training loss: 5.378238678107037
Validation loss: 4.970586441359266

Epoch: 6| Step: 6
Training loss: 5.251963293733183
Validation loss: 4.966042602725039

Epoch: 6| Step: 7
Training loss: 4.572408498742224
Validation loss: 4.961495724006617

Epoch: 6| Step: 8
Training loss: 3.9450789882937647
Validation loss: 4.957350379685398

Epoch: 6| Step: 9
Training loss: 5.639441199520276
Validation loss: 4.952454434319535

Epoch: 6| Step: 10
Training loss: 4.605308885849247
Validation loss: 4.947413604326382

Epoch: 6| Step: 11
Training loss: 5.624173082393337
Validation loss: 4.943043425777557

Epoch: 6| Step: 12
Training loss: 5.243352769030332
Validation loss: 4.937830145377254

Epoch: 6| Step: 13
Training loss: 4.541400983312897
Validation loss: 4.933599355759385

Epoch: 14| Step: 0
Training loss: 5.315930863090876
Validation loss: 4.929131349043135

Epoch: 6| Step: 1
Training loss: 5.285070357995704
Validation loss: 4.924380194686317

Epoch: 6| Step: 2
Training loss: 4.81169280181295
Validation loss: 4.919177798806209

Epoch: 6| Step: 3
Training loss: 4.855385077592609
Validation loss: 4.91433246075194

Epoch: 6| Step: 4
Training loss: 5.161433533250628
Validation loss: 4.909771151780709

Epoch: 6| Step: 5
Training loss: 5.534015201394696
Validation loss: 4.9049550025942095

Epoch: 6| Step: 6
Training loss: 4.989858642288329
Validation loss: 4.899510900260104

Epoch: 6| Step: 7
Training loss: 4.581941959847711
Validation loss: 4.895738522308219

Epoch: 6| Step: 8
Training loss: 5.262574169515185
Validation loss: 4.890646190008341

Epoch: 6| Step: 9
Training loss: 5.495525620845129
Validation loss: 4.88544349690155

Epoch: 6| Step: 10
Training loss: 5.031603688194136
Validation loss: 4.880665055124154

Epoch: 6| Step: 11
Training loss: 5.18550016163046
Validation loss: 4.8757238258256885

Epoch: 6| Step: 12
Training loss: 4.046047759471436
Validation loss: 4.870773667926468

Epoch: 6| Step: 13
Training loss: 4.558270728165452
Validation loss: 4.865986013933562

Epoch: 15| Step: 0
Training loss: 5.783948773591217
Validation loss: 4.8609811922907715

Epoch: 6| Step: 1
Training loss: 3.5239357606572876
Validation loss: 4.856116736771171

Epoch: 6| Step: 2
Training loss: 5.521194542158724
Validation loss: 4.85153943566713

Epoch: 6| Step: 3
Training loss: 4.766529835335406
Validation loss: 4.847006131990412

Epoch: 6| Step: 4
Training loss: 4.910777341759836
Validation loss: 4.842118577116842

Epoch: 6| Step: 5
Training loss: 5.1545991971540115
Validation loss: 4.8369466276181

Epoch: 6| Step: 6
Training loss: 4.012655265870075
Validation loss: 4.832379455273325

Epoch: 6| Step: 7
Training loss: 5.62269545076737
Validation loss: 4.827171190318705

Epoch: 6| Step: 8
Training loss: 4.261859950900413
Validation loss: 4.822862870621471

Epoch: 6| Step: 9
Training loss: 5.253311202943407
Validation loss: 4.8180427174039595

Epoch: 6| Step: 10
Training loss: 4.664855787331647
Validation loss: 4.813635225700039

Epoch: 6| Step: 11
Training loss: 5.6622821824914515
Validation loss: 4.808214864257577

Epoch: 6| Step: 12
Training loss: 5.125504259562655
Validation loss: 4.803544451785868

Epoch: 6| Step: 13
Training loss: 4.537019831364561
Validation loss: 4.798285824610176

Epoch: 16| Step: 0
Training loss: 5.602768772117797
Validation loss: 4.793734339324159

Epoch: 6| Step: 1
Training loss: 5.628920142787331
Validation loss: 4.78961304595523

Epoch: 6| Step: 2
Training loss: 5.050164913090865
Validation loss: 4.783635792933489

Epoch: 6| Step: 3
Training loss: 5.197627832291171
Validation loss: 4.779344432465844

Epoch: 6| Step: 4
Training loss: 4.612587640027935
Validation loss: 4.77361777173832

Epoch: 6| Step: 5
Training loss: 5.185708345532158
Validation loss: 4.768368974348245

Epoch: 6| Step: 6
Training loss: 5.3403180797011345
Validation loss: 4.763423056606128

Epoch: 6| Step: 7
Training loss: 4.839462252922419
Validation loss: 4.758100545815244

Epoch: 6| Step: 8
Training loss: 4.885896877391989
Validation loss: 4.7527386985097175

Epoch: 6| Step: 9
Training loss: 4.26042243689758
Validation loss: 4.7481342800877036

Epoch: 6| Step: 10
Training loss: 5.0208737489121
Validation loss: 4.743075191866117

Epoch: 6| Step: 11
Training loss: 4.372307521101647
Validation loss: 4.737937283695702

Epoch: 6| Step: 12
Training loss: 4.08998015867611
Validation loss: 4.733256544690218

Epoch: 6| Step: 13
Training loss: 4.00560510833701
Validation loss: 4.728418108924504

Epoch: 17| Step: 0
Training loss: 5.1774311933822
Validation loss: 4.7234729095454195

Epoch: 6| Step: 1
Training loss: 5.498141234758663
Validation loss: 4.718072838437024

Epoch: 6| Step: 2
Training loss: 4.340936641614765
Validation loss: 4.71275973358911

Epoch: 6| Step: 3
Training loss: 4.997687567987987
Validation loss: 4.707908825037128

Epoch: 6| Step: 4
Training loss: 3.545640907191396
Validation loss: 4.704032396416899

Epoch: 6| Step: 5
Training loss: 4.966579130967325
Validation loss: 4.699169299255778

Epoch: 6| Step: 6
Training loss: 5.480766304622801
Validation loss: 4.693513564763743

Epoch: 6| Step: 7
Training loss: 4.3992086652593745
Validation loss: 4.688788749706234

Epoch: 6| Step: 8
Training loss: 4.98202066813699
Validation loss: 4.683853324630743

Epoch: 6| Step: 9
Training loss: 5.078479554930171
Validation loss: 4.679991052597274

Epoch: 6| Step: 10
Training loss: 4.598409560206489
Validation loss: 4.674573410345081

Epoch: 6| Step: 11
Training loss: 4.780768476186688
Validation loss: 4.669877134390926

Epoch: 6| Step: 12
Training loss: 4.173159740806724
Validation loss: 4.665315069016948

Epoch: 6| Step: 13
Training loss: 5.072210723615084
Validation loss: 4.6601397931601625

Epoch: 18| Step: 0
Training loss: 4.88092268116208
Validation loss: 4.655979839910533

Epoch: 6| Step: 1
Training loss: 5.26176768664604
Validation loss: 4.650304014597537

Epoch: 6| Step: 2
Training loss: 5.457328684516776
Validation loss: 4.644646679786272

Epoch: 6| Step: 3
Training loss: 5.452259596221538
Validation loss: 4.639240096776315

Epoch: 6| Step: 4
Training loss: 4.612976322545799
Validation loss: 4.634077065739254

Epoch: 6| Step: 5
Training loss: 4.083840993866386
Validation loss: 4.62931014604592

Epoch: 6| Step: 6
Training loss: 4.179774887740082
Validation loss: 4.624724629082968

Epoch: 6| Step: 7
Training loss: 4.802280027563445
Validation loss: 4.61891987806083

Epoch: 6| Step: 8
Training loss: 4.032903997306316
Validation loss: 4.6139134020495165

Epoch: 6| Step: 9
Training loss: 4.868695608675043
Validation loss: 4.608707565003276

Epoch: 6| Step: 10
Training loss: 3.6623445237004013
Validation loss: 4.604050797375287

Epoch: 6| Step: 11
Training loss: 4.900671052720002
Validation loss: 4.599339430137081

Epoch: 6| Step: 12
Training loss: 5.243167427447002
Validation loss: 4.594060943529212

Epoch: 6| Step: 13
Training loss: 4.6401738933337375
Validation loss: 4.5891247774651465

Epoch: 19| Step: 0
Training loss: 4.459276949172795
Validation loss: 4.584375378609338

Epoch: 6| Step: 1
Training loss: 4.650783940344426
Validation loss: 4.578854968101599

Epoch: 6| Step: 2
Training loss: 5.108434561410461
Validation loss: 4.573559112721757

Epoch: 6| Step: 3
Training loss: 4.5287734005118425
Validation loss: 4.568622261345534

Epoch: 6| Step: 4
Training loss: 5.229610267253506
Validation loss: 4.5633365613165715

Epoch: 6| Step: 5
Training loss: 5.1459994064075705
Validation loss: 4.5580605633918845

Epoch: 6| Step: 6
Training loss: 4.414565228216116
Validation loss: 4.552396046294624

Epoch: 6| Step: 7
Training loss: 4.5717061844046185
Validation loss: 4.546062698428656

Epoch: 6| Step: 8
Training loss: 5.39967978905609
Validation loss: 4.541982563943345

Epoch: 6| Step: 9
Training loss: 3.995635512582956
Validation loss: 4.535464832410534

Epoch: 6| Step: 10
Training loss: 4.459931963414479
Validation loss: 4.530390918894406

Epoch: 6| Step: 11
Training loss: 4.0817494856403655
Validation loss: 4.524890110796138

Epoch: 6| Step: 12
Training loss: 4.723673695909234
Validation loss: 4.5199343524374145

Epoch: 6| Step: 13
Training loss: 4.483182635604917
Validation loss: 4.5146306404952865

Epoch: 20| Step: 0
Training loss: 5.071184973747641
Validation loss: 4.510002287520838

Epoch: 6| Step: 1
Training loss: 4.283016981819326
Validation loss: 4.504370827272205

Epoch: 6| Step: 2
Training loss: 3.9265584147956143
Validation loss: 4.499238656241687

Epoch: 6| Step: 3
Training loss: 4.424238564017303
Validation loss: 4.494121455870498

Epoch: 6| Step: 4
Training loss: 4.55396695596386
Validation loss: 4.489703797083598

Epoch: 6| Step: 5
Training loss: 4.8251367104883505
Validation loss: 4.484564463725671

Epoch: 6| Step: 6
Training loss: 4.5716440201125526
Validation loss: 4.478774486790305

Epoch: 6| Step: 7
Training loss: 4.495389695974839
Validation loss: 4.474092238009575

Epoch: 6| Step: 8
Training loss: 5.034925172888077
Validation loss: 4.469207188976595

Epoch: 6| Step: 9
Training loss: 4.9067565267737825
Validation loss: 4.464387093255753

Epoch: 6| Step: 10
Training loss: 4.816444662889197
Validation loss: 4.459313911673618

Epoch: 6| Step: 11
Training loss: 4.206924252933712
Validation loss: 4.453912034114893

Epoch: 6| Step: 12
Training loss: 4.9835123971942
Validation loss: 4.4495011246464

Epoch: 6| Step: 13
Training loss: 4.1911061260355105
Validation loss: 4.446163513926816

Epoch: 21| Step: 0
Training loss: 3.552375460756446
Validation loss: 4.438601039348219

Epoch: 6| Step: 1
Training loss: 4.538256890508518
Validation loss: 4.433781081847921

Epoch: 6| Step: 2
Training loss: 5.078250636967454
Validation loss: 4.430044349322121

Epoch: 6| Step: 3
Training loss: 4.445178199174034
Validation loss: 4.423803135995693

Epoch: 6| Step: 4
Training loss: 4.526444616550524
Validation loss: 4.418746326666226

Epoch: 6| Step: 5
Training loss: 5.334333723340962
Validation loss: 4.41357483997292

Epoch: 6| Step: 6
Training loss: 4.105033408620285
Validation loss: 4.408862482533627

Epoch: 6| Step: 7
Training loss: 3.9717888199215365
Validation loss: 4.403687491765998

Epoch: 6| Step: 8
Training loss: 4.6961066007715955
Validation loss: 4.398231153690162

Epoch: 6| Step: 9
Training loss: 5.267359959968179
Validation loss: 4.393338108426762

Epoch: 6| Step: 10
Training loss: 4.68323088473923
Validation loss: 4.388433395898498

Epoch: 6| Step: 11
Training loss: 4.781881053892309
Validation loss: 4.38361741560818

Epoch: 6| Step: 12
Training loss: 3.9489217131431213
Validation loss: 4.377682853262345

Epoch: 6| Step: 13
Training loss: 4.177751495625859
Validation loss: 4.373118731788765

Epoch: 22| Step: 0
Training loss: 4.342751587215944
Validation loss: 4.3676750989116995

Epoch: 6| Step: 1
Training loss: 4.878392530750475
Validation loss: 4.362151944358772

Epoch: 6| Step: 2
Training loss: 4.416202640749194
Validation loss: 4.3564680974393415

Epoch: 6| Step: 3
Training loss: 4.842976563753981
Validation loss: 4.352243531113565

Epoch: 6| Step: 4
Training loss: 4.354143401210022
Validation loss: 4.3478582883070835

Epoch: 6| Step: 5
Training loss: 3.481100142864448
Validation loss: 4.341663875078608

Epoch: 6| Step: 6
Training loss: 5.236834776519353
Validation loss: 4.336830830693391

Epoch: 6| Step: 7
Training loss: 3.955061728361074
Validation loss: 4.331279463527883

Epoch: 6| Step: 8
Training loss: 4.7430533760826625
Validation loss: 4.326346186792316

Epoch: 6| Step: 9
Training loss: 3.406187424391172
Validation loss: 4.321420924012174

Epoch: 6| Step: 10
Training loss: 4.448602675602853
Validation loss: 4.31648924964978

Epoch: 6| Step: 11
Training loss: 4.3068695907104875
Validation loss: 4.3117667233585575

Epoch: 6| Step: 12
Training loss: 4.560679033149363
Validation loss: 4.3073201791664495

Epoch: 6| Step: 13
Training loss: 5.108228082283033
Validation loss: 4.302236959132875

Epoch: 23| Step: 0
Training loss: 4.011527854589747
Validation loss: 4.296985453717672

Epoch: 6| Step: 1
Training loss: 4.491420833015224
Validation loss: 4.291790870918539

Epoch: 6| Step: 2
Training loss: 4.685329901317482
Validation loss: 4.287123278202114

Epoch: 6| Step: 3
Training loss: 4.82032733834578
Validation loss: 4.282839384925887

Epoch: 6| Step: 4
Training loss: 5.172613638601674
Validation loss: 4.277681111541269

Epoch: 6| Step: 5
Training loss: 4.241005074118196
Validation loss: 4.272812318139961

Epoch: 6| Step: 6
Training loss: 4.487478850163426
Validation loss: 4.267644271512544

Epoch: 6| Step: 7
Training loss: 4.2249272086289125
Validation loss: 4.262116177935458

Epoch: 6| Step: 8
Training loss: 4.552353327911131
Validation loss: 4.25740806221978

Epoch: 6| Step: 9
Training loss: 4.206055254346085
Validation loss: 4.252254505191641

Epoch: 6| Step: 10
Training loss: 4.456573757058174
Validation loss: 4.247200792029997

Epoch: 6| Step: 11
Training loss: 3.9879060544472056
Validation loss: 4.241936457859344

Epoch: 6| Step: 12
Training loss: 4.363269447303867
Validation loss: 4.237231315264152

Epoch: 6| Step: 13
Training loss: 3.6491131371364838
Validation loss: 4.232253628308762

Epoch: 24| Step: 0
Training loss: 4.36502310905151
Validation loss: 4.227527350802144

Epoch: 6| Step: 1
Training loss: 4.831041362644601
Validation loss: 4.222153597547315

Epoch: 6| Step: 2
Training loss: 4.4606435381608485
Validation loss: 4.217809181329837

Epoch: 6| Step: 3
Training loss: 4.392079177003793
Validation loss: 4.21322431968547

Epoch: 6| Step: 4
Training loss: 3.9104922033109544
Validation loss: 4.208025905345667

Epoch: 6| Step: 5
Training loss: 4.134608089597541
Validation loss: 4.202863020927841

Epoch: 6| Step: 6
Training loss: 4.926368623905799
Validation loss: 4.197639449868283

Epoch: 6| Step: 7
Training loss: 4.3775509617931005
Validation loss: 4.193123680376471

Epoch: 6| Step: 8
Training loss: 4.8542962227533355
Validation loss: 4.188516408064144

Epoch: 6| Step: 9
Training loss: 4.153738539407574
Validation loss: 4.183467422605923

Epoch: 6| Step: 10
Training loss: 3.1734461909616036
Validation loss: 4.178517210456875

Epoch: 6| Step: 11
Training loss: 4.399095069421616
Validation loss: 4.173959085292889

Epoch: 6| Step: 12
Training loss: 5.105206296752117
Validation loss: 4.169038682328259

Epoch: 6| Step: 13
Training loss: 2.9458886349535245
Validation loss: 4.163969915623963

Epoch: 25| Step: 0
Training loss: 4.6642070600895975
Validation loss: 4.160025867693511

Epoch: 6| Step: 1
Training loss: 4.201294227283315
Validation loss: 4.155030858108505

Epoch: 6| Step: 2
Training loss: 4.160059280339931
Validation loss: 4.150316807707528

Epoch: 6| Step: 3
Training loss: 3.7722680469389425
Validation loss: 4.145982915329991

Epoch: 6| Step: 4
Training loss: 4.358463752696509
Validation loss: 4.140601276833574

Epoch: 6| Step: 5
Training loss: 4.430312662565243
Validation loss: 4.136287581487386

Epoch: 6| Step: 6
Training loss: 4.3322439046937165
Validation loss: 4.131148139594319

Epoch: 6| Step: 7
Training loss: 4.818288517289084
Validation loss: 4.127005638586416

Epoch: 6| Step: 8
Training loss: 4.583834580264488
Validation loss: 4.121750293278722

Epoch: 6| Step: 9
Training loss: 3.2834514680577844
Validation loss: 4.116722896258832

Epoch: 6| Step: 10
Training loss: 4.338103651976066
Validation loss: 4.111773952253942

Epoch: 6| Step: 11
Training loss: 3.55154984719892
Validation loss: 4.107573158911295

Epoch: 6| Step: 12
Training loss: 3.8718955617486466
Validation loss: 4.102852270393777

Epoch: 6| Step: 13
Training loss: 4.9440688849035945
Validation loss: 4.097917953876292

Epoch: 26| Step: 0
Training loss: 4.648227411218845
Validation loss: 4.092818506081145

Epoch: 6| Step: 1
Training loss: 3.775357407583112
Validation loss: 4.087933395072084

Epoch: 6| Step: 2
Training loss: 4.413715936339721
Validation loss: 4.083495286078356

Epoch: 6| Step: 3
Training loss: 4.860739169953508
Validation loss: 4.07932599970601

Epoch: 6| Step: 4
Training loss: 4.534531240577944
Validation loss: 4.074378971449603

Epoch: 6| Step: 5
Training loss: 3.9673227462161487
Validation loss: 4.068686132911278

Epoch: 6| Step: 6
Training loss: 4.073816822741177
Validation loss: 4.064480655741295

Epoch: 6| Step: 7
Training loss: 3.7478228288869357
Validation loss: 4.059828031151968

Epoch: 6| Step: 8
Training loss: 3.528897067014355
Validation loss: 4.055137183036129

Epoch: 6| Step: 9
Training loss: 4.222614016396683
Validation loss: 4.050883680254539

Epoch: 6| Step: 10
Training loss: 4.081604624087571
Validation loss: 4.045461518278727

Epoch: 6| Step: 11
Training loss: 4.1304816612184725
Validation loss: 4.041195589645765

Epoch: 6| Step: 12
Training loss: 4.404705669775622
Validation loss: 4.036479997474205

Epoch: 6| Step: 13
Training loss: 4.138569562798606
Validation loss: 4.031604583680655

Epoch: 27| Step: 0
Training loss: 4.662144354380192
Validation loss: 4.026768502396089

Epoch: 6| Step: 1
Training loss: 3.681004120625182
Validation loss: 4.02200803578676

Epoch: 6| Step: 2
Training loss: 4.327278357371725
Validation loss: 4.017282443245761

Epoch: 6| Step: 3
Training loss: 4.603183739229771
Validation loss: 4.012726802892681

Epoch: 6| Step: 4
Training loss: 3.96372210793259
Validation loss: 4.008214205414376

Epoch: 6| Step: 5
Training loss: 3.761685665377289
Validation loss: 4.003086687272444

Epoch: 6| Step: 6
Training loss: 4.17357632239398
Validation loss: 3.998341057406734

Epoch: 6| Step: 7
Training loss: 2.7701384358982004
Validation loss: 3.993611638513544

Epoch: 6| Step: 8
Training loss: 3.56651989524915
Validation loss: 3.989445729617511

Epoch: 6| Step: 9
Training loss: 4.23677361037976
Validation loss: 3.9851260206717134

Epoch: 6| Step: 10
Training loss: 4.78049497938496
Validation loss: 3.9806490362217004

Epoch: 6| Step: 11
Training loss: 4.372382988909936
Validation loss: 3.9762455402354453

Epoch: 6| Step: 12
Training loss: 3.925441867715216
Validation loss: 3.971248911312227

Epoch: 6| Step: 13
Training loss: 4.533337763241866
Validation loss: 3.966956086112102

Epoch: 28| Step: 0
Training loss: 4.093737653174964
Validation loss: 3.9622595873563933

Epoch: 6| Step: 1
Training loss: 4.30032664987839
Validation loss: 3.9575111271405987

Epoch: 6| Step: 2
Training loss: 4.181041234482549
Validation loss: 3.9532061180265803

Epoch: 6| Step: 3
Training loss: 3.908259126871067
Validation loss: 3.9480084666077935

Epoch: 6| Step: 4
Training loss: 3.2583481602115967
Validation loss: 3.9433420831793358

Epoch: 6| Step: 5
Training loss: 4.574433697113993
Validation loss: 3.9388870944682774

Epoch: 6| Step: 6
Training loss: 3.984625834628916
Validation loss: 3.9341462197823205

Epoch: 6| Step: 7
Training loss: 3.939933146185495
Validation loss: 3.929271435815644

Epoch: 6| Step: 8
Training loss: 4.071988805789212
Validation loss: 3.924827872387614

Epoch: 6| Step: 9
Training loss: 4.629137405225198
Validation loss: 3.9198487659397467

Epoch: 6| Step: 10
Training loss: 3.6158508072010553
Validation loss: 3.915284007437633

Epoch: 6| Step: 11
Training loss: 3.6617447735167117
Validation loss: 3.9109146749470756

Epoch: 6| Step: 12
Training loss: 4.459103930654665
Validation loss: 3.9064004691071665

Epoch: 6| Step: 13
Training loss: 4.012084825373972
Validation loss: 3.9018530958812345

Epoch: 29| Step: 0
Training loss: 4.7538103581382565
Validation loss: 3.8966837004220456

Epoch: 6| Step: 1
Training loss: 3.5288030197587257
Validation loss: 3.8920903440172125

Epoch: 6| Step: 2
Training loss: 4.20379792112679
Validation loss: 3.8874133232242047

Epoch: 6| Step: 3
Training loss: 3.934424152627772
Validation loss: 3.883109702409613

Epoch: 6| Step: 4
Training loss: 4.39206766883125
Validation loss: 3.8787965941511846

Epoch: 6| Step: 5
Training loss: 3.4124026944885957
Validation loss: 3.8738285262798207

Epoch: 6| Step: 6
Training loss: 3.721884936776657
Validation loss: 3.8695325118612924

Epoch: 6| Step: 7
Training loss: 4.522139025231908
Validation loss: 3.8650638593470417

Epoch: 6| Step: 8
Training loss: 3.5547627535389412
Validation loss: 3.8604797553012635

Epoch: 6| Step: 9
Training loss: 4.428452846152447
Validation loss: 3.856067326287715

Epoch: 6| Step: 10
Training loss: 2.9853451734679752
Validation loss: 3.851102501028681

Epoch: 6| Step: 11
Training loss: 3.9406842873913495
Validation loss: 3.8468475266443187

Epoch: 6| Step: 12
Training loss: 4.194198261528279
Validation loss: 3.8423569178451586

Epoch: 6| Step: 13
Training loss: 4.0571060758493065
Validation loss: 3.8375710856659935

Epoch: 30| Step: 0
Training loss: 3.599010697171106
Validation loss: 3.8331809773782495

Epoch: 6| Step: 1
Training loss: 3.8605416577041543
Validation loss: 3.828439857873068

Epoch: 6| Step: 2
Training loss: 4.091183855481867
Validation loss: 3.8238664879814666

Epoch: 6| Step: 3
Training loss: 4.120821136569702
Validation loss: 3.8194629684153174

Epoch: 6| Step: 4
Training loss: 3.979883871636692
Validation loss: 3.8146295592949797

Epoch: 6| Step: 5
Training loss: 4.097169569004052
Validation loss: 3.8102537740126343

Epoch: 6| Step: 6
Training loss: 3.909033676115602
Validation loss: 3.805783363973696

Epoch: 6| Step: 7
Training loss: 4.258479466826718
Validation loss: 3.800864072069154

Epoch: 6| Step: 8
Training loss: 3.3652125538867397
Validation loss: 3.7967387359405835

Epoch: 6| Step: 9
Training loss: 3.868077894260835
Validation loss: 3.791965696399654

Epoch: 6| Step: 10
Training loss: 3.7966314794993585
Validation loss: 3.7876486116468167

Epoch: 6| Step: 11
Training loss: 4.571511761725836
Validation loss: 3.7830976485616454

Epoch: 6| Step: 12
Training loss: 3.9469625214140023
Validation loss: 3.778743154620718

Epoch: 6| Step: 13
Training loss: 3.5333075816337676
Validation loss: 3.7739074288049204

Epoch: 31| Step: 0
Training loss: 3.174130394260076
Validation loss: 3.7693456100054337

Epoch: 6| Step: 1
Training loss: 4.219351266470152
Validation loss: 3.7649842873997312

Epoch: 6| Step: 2
Training loss: 3.8239785918749813
Validation loss: 3.760613003974164

Epoch: 6| Step: 3
Training loss: 3.893552115664124
Validation loss: 3.756081079798901

Epoch: 6| Step: 4
Training loss: 3.6841317003465073
Validation loss: 3.7523274722286644

Epoch: 6| Step: 5
Training loss: 3.727970009433465
Validation loss: 3.7477500947780027

Epoch: 6| Step: 6
Training loss: 3.2691457651056646
Validation loss: 3.743337625708855

Epoch: 6| Step: 7
Training loss: 3.2916652502386854
Validation loss: 3.7392990230913874

Epoch: 6| Step: 8
Training loss: 4.079472227929401
Validation loss: 3.735298925623141

Epoch: 6| Step: 9
Training loss: 4.241398353309328
Validation loss: 3.7309813674847305

Epoch: 6| Step: 10
Training loss: 4.03079575929183
Validation loss: 3.7268975171928247

Epoch: 6| Step: 11
Training loss: 4.457983318148754
Validation loss: 3.722755198649716

Epoch: 6| Step: 12
Training loss: 4.26345087894968
Validation loss: 3.7181956628687383

Epoch: 6| Step: 13
Training loss: 3.844193595782537
Validation loss: 3.713920695189993

Epoch: 32| Step: 0
Training loss: 2.06973730770071
Validation loss: 3.709258717720476

Epoch: 6| Step: 1
Training loss: 3.791007952360538
Validation loss: 3.7047306233651076

Epoch: 6| Step: 2
Training loss: 4.401443348748918
Validation loss: 3.700687029777784

Epoch: 6| Step: 3
Training loss: 3.784412165238
Validation loss: 3.6962752805156427

Epoch: 6| Step: 4
Training loss: 4.381576390971847
Validation loss: 3.6919941428976

Epoch: 6| Step: 5
Training loss: 3.516205599843891
Validation loss: 3.687327666485265

Epoch: 6| Step: 6
Training loss: 3.603159519370977
Validation loss: 3.6829046506254475

Epoch: 6| Step: 7
Training loss: 4.061025263801902
Validation loss: 3.67883563051878

Epoch: 6| Step: 8
Training loss: 3.955747676736578
Validation loss: 3.674472144661116

Epoch: 6| Step: 9
Training loss: 4.319977179926187
Validation loss: 3.6700374469353796

Epoch: 6| Step: 10
Training loss: 4.130981039505614
Validation loss: 3.665690068033016

Epoch: 6| Step: 11
Training loss: 2.9925952762998094
Validation loss: 3.660875595118602

Epoch: 6| Step: 12
Training loss: 3.390719785991502
Validation loss: 3.6565094119475545

Epoch: 6| Step: 13
Training loss: 4.325995076099544
Validation loss: 3.652341878689917

Epoch: 33| Step: 0
Training loss: 3.771738495209486
Validation loss: 3.647755005611415

Epoch: 6| Step: 1
Training loss: 4.022998971095512
Validation loss: 3.6432088433717493

Epoch: 6| Step: 2
Training loss: 4.195059031638371
Validation loss: 3.6388652079218535

Epoch: 6| Step: 3
Training loss: 3.52604196718441
Validation loss: 3.634058059950785

Epoch: 6| Step: 4
Training loss: 4.136636216274162
Validation loss: 3.6293943670224804

Epoch: 6| Step: 5
Training loss: 3.8707103982106963
Validation loss: 3.624579942415672

Epoch: 6| Step: 6
Training loss: 2.887657828373135
Validation loss: 3.6203351753983446

Epoch: 6| Step: 7
Training loss: 3.8462373702443484
Validation loss: 3.6160683709815107

Epoch: 6| Step: 8
Training loss: 4.366461132153075
Validation loss: 3.612134662884946

Epoch: 6| Step: 9
Training loss: 3.4341239302883495
Validation loss: 3.6076017705635337

Epoch: 6| Step: 10
Training loss: 3.8279031494628337
Validation loss: 3.6037443644937923

Epoch: 6| Step: 11
Training loss: 3.347243863392398
Validation loss: 3.598987400730667

Epoch: 6| Step: 12
Training loss: 3.0094393999571016
Validation loss: 3.5947381361132793

Epoch: 6| Step: 13
Training loss: 4.0138861902939915
Validation loss: 3.59069147848015

Epoch: 34| Step: 0
Training loss: 3.375799155105041
Validation loss: 3.586702662704486

Epoch: 6| Step: 1
Training loss: 4.160417804644637
Validation loss: 3.581957944940122

Epoch: 6| Step: 2
Training loss: 3.385139352248747
Validation loss: 3.578171797755912

Epoch: 6| Step: 3
Training loss: 3.131897904604057
Validation loss: 3.57370579552884

Epoch: 6| Step: 4
Training loss: 3.347460532949316
Validation loss: 3.569399705170236

Epoch: 6| Step: 5
Training loss: 3.889666826155378
Validation loss: 3.565529254828084

Epoch: 6| Step: 6
Training loss: 3.9901442701983934
Validation loss: 3.561663077576798

Epoch: 6| Step: 7
Training loss: 3.394602890048839
Validation loss: 3.5577056926811244

Epoch: 6| Step: 8
Training loss: 3.9024620305522952
Validation loss: 3.553105241803894

Epoch: 6| Step: 9
Training loss: 3.92912613061334
Validation loss: 3.549447089106513

Epoch: 6| Step: 10
Training loss: 3.8739165975783054
Validation loss: 3.5456284896785895

Epoch: 6| Step: 11
Training loss: 3.897593680204708
Validation loss: 3.5418701936173003

Epoch: 6| Step: 12
Training loss: 3.760322351232759
Validation loss: 3.537214143164428

Epoch: 6| Step: 13
Training loss: 3.548501335050265
Validation loss: 3.532609424718571

Epoch: 35| Step: 0
Training loss: 3.9955802580107895
Validation loss: 3.5285411110666383

Epoch: 6| Step: 1
Training loss: 2.569637870954154
Validation loss: 3.524127652961175

Epoch: 6| Step: 2
Training loss: 3.2003933307194408
Validation loss: 3.520916428046274

Epoch: 6| Step: 3
Training loss: 3.569297863382773
Validation loss: 3.5165115029935037

Epoch: 6| Step: 4
Training loss: 3.6409319965116977
Validation loss: 3.5120962786544347

Epoch: 6| Step: 5
Training loss: 3.6883242704197103
Validation loss: 3.5084496183597516

Epoch: 6| Step: 6
Training loss: 3.2857813472893818
Validation loss: 3.5039536420834323

Epoch: 6| Step: 7
Training loss: 3.506630475349436
Validation loss: 3.499835510021672

Epoch: 6| Step: 8
Training loss: 2.570419819455237
Validation loss: 3.4959713138331625

Epoch: 6| Step: 9
Training loss: 4.169141009293292
Validation loss: 3.4925761963040034

Epoch: 6| Step: 10
Training loss: 4.107584167844021
Validation loss: 3.4886202987385353

Epoch: 6| Step: 11
Training loss: 3.7548382383163794
Validation loss: 3.4851475701633396

Epoch: 6| Step: 12
Training loss: 4.222318821075292
Validation loss: 3.4809639832064296

Epoch: 6| Step: 13
Training loss: 4.145720948400512
Validation loss: 3.476241319086108

Epoch: 36| Step: 0
Training loss: 3.7358426198873
Validation loss: 3.471938286086343

Epoch: 6| Step: 1
Training loss: 3.490575909248022
Validation loss: 3.467904775473002

Epoch: 6| Step: 2
Training loss: 3.231546095483759
Validation loss: 3.46377252177462

Epoch: 6| Step: 3
Training loss: 3.1375782930248675
Validation loss: 3.4597494986890007

Epoch: 6| Step: 4
Training loss: 3.7856261096566652
Validation loss: 3.4560428564209227

Epoch: 6| Step: 5
Training loss: 3.6545501409178818
Validation loss: 3.451954339670996

Epoch: 6| Step: 6
Training loss: 2.554680220567324
Validation loss: 3.448213216853839

Epoch: 6| Step: 7
Training loss: 4.422813504645544
Validation loss: 3.444388475441915

Epoch: 6| Step: 8
Training loss: 3.604686251252764
Validation loss: 3.4402063293457354

Epoch: 6| Step: 9
Training loss: 3.258273085275386
Validation loss: 3.436522720595561

Epoch: 6| Step: 10
Training loss: 3.45665867408802
Validation loss: 3.4325423354140274

Epoch: 6| Step: 11
Training loss: 3.274037017184225
Validation loss: 3.428937199927249

Epoch: 6| Step: 12
Training loss: 4.536151208419373
Validation loss: 3.424827381991032

Epoch: 6| Step: 13
Training loss: 3.5748986770036275
Validation loss: 3.420788039272727

Epoch: 37| Step: 0
Training loss: 3.5158604521849672
Validation loss: 3.41695213675978

Epoch: 6| Step: 1
Training loss: 3.1011409136688166
Validation loss: 3.412886241624627

Epoch: 6| Step: 2
Training loss: 3.1055687078547374
Validation loss: 3.409258292741754

Epoch: 6| Step: 3
Training loss: 3.702169947057338
Validation loss: 3.405257030725042

Epoch: 6| Step: 4
Training loss: 3.6071003934311303
Validation loss: 3.4013280042110354

Epoch: 6| Step: 5
Training loss: 3.6470281913636304
Validation loss: 3.3977305177507056

Epoch: 6| Step: 6
Training loss: 3.796999454420893
Validation loss: 3.393651733474491

Epoch: 6| Step: 7
Training loss: 2.6977773701609693
Validation loss: 3.389343113154546

Epoch: 6| Step: 8
Training loss: 3.4808774080987686
Validation loss: 3.3859949918876273

Epoch: 6| Step: 9
Training loss: 3.8811927041755863
Validation loss: 3.3826251958217783

Epoch: 6| Step: 10
Training loss: 4.18771680583805
Validation loss: 3.378657043322392

Epoch: 6| Step: 11
Training loss: 3.37446363920178
Validation loss: 3.375016777562013

Epoch: 6| Step: 12
Training loss: 3.9624509308962734
Validation loss: 3.3715375399663734

Epoch: 6| Step: 13
Training loss: 3.068313685707732
Validation loss: 3.367616890113101

Epoch: 38| Step: 0
Training loss: 2.5686752531216857
Validation loss: 3.363577386251551

Epoch: 6| Step: 1
Training loss: 2.3437670897814438
Validation loss: 3.360183819537458

Epoch: 6| Step: 2
Training loss: 3.370162605415127
Validation loss: 3.3564820600682097

Epoch: 6| Step: 3
Training loss: 4.211680727111107
Validation loss: 3.3532155190912447

Epoch: 6| Step: 4
Training loss: 3.1027841924428206
Validation loss: 3.3497953342908215

Epoch: 6| Step: 5
Training loss: 3.2742117828680946
Validation loss: 3.3460760255792907

Epoch: 6| Step: 6
Training loss: 4.438622561026992
Validation loss: 3.342476385352239

Epoch: 6| Step: 7
Training loss: 4.246041193183244
Validation loss: 3.338923955603801

Epoch: 6| Step: 8
Training loss: 3.6312050164960628
Validation loss: 3.3349974452003712

Epoch: 6| Step: 9
Training loss: 3.1749766551683902
Validation loss: 3.3313767810431405

Epoch: 6| Step: 10
Training loss: 3.047392346402911
Validation loss: 3.3274918313598487

Epoch: 6| Step: 11
Training loss: 3.5376793050985635
Validation loss: 3.3239338353393046

Epoch: 6| Step: 12
Training loss: 3.3776090921421456
Validation loss: 3.320201605646601

Epoch: 6| Step: 13
Training loss: 3.7092936840319632
Validation loss: 3.3162266383454786

Epoch: 39| Step: 0
Training loss: 3.7350377727676953
Validation loss: 3.3128385550751167

Epoch: 6| Step: 1
Training loss: 3.4395127386053277
Validation loss: 3.309384746495136

Epoch: 6| Step: 2
Training loss: 3.0425095805485136
Validation loss: 3.3056304524233013

Epoch: 6| Step: 3
Training loss: 2.932444991354371
Validation loss: 3.3021573841604552

Epoch: 6| Step: 4
Training loss: 3.936057780306909
Validation loss: 3.2988753194013443

Epoch: 6| Step: 5
Training loss: 3.5992596394803997
Validation loss: 3.2954274837136137

Epoch: 6| Step: 6
Training loss: 4.095501241224341
Validation loss: 3.2915818690391028

Epoch: 6| Step: 7
Training loss: 3.0833676997838437
Validation loss: 3.287734656909709

Epoch: 6| Step: 8
Training loss: 3.6175730687204837
Validation loss: 3.2840251994031564

Epoch: 6| Step: 9
Training loss: 4.103202099740333
Validation loss: 3.280456277427332

Epoch: 6| Step: 10
Training loss: 2.890013594017924
Validation loss: 3.2767010719055643

Epoch: 6| Step: 11
Training loss: 3.038070242144446
Validation loss: 3.27266531662464

Epoch: 6| Step: 12
Training loss: 3.2938911711752694
Validation loss: 3.2694000132726977

Epoch: 6| Step: 13
Training loss: 2.843273080930522
Validation loss: 3.26627573346973

Epoch: 40| Step: 0
Training loss: 2.908764807348262
Validation loss: 3.2630189660694393

Epoch: 6| Step: 1
Training loss: 3.1615076370207347
Validation loss: 3.2604527984339593

Epoch: 6| Step: 2
Training loss: 3.6814170708818463
Validation loss: 3.2570738957609024

Epoch: 6| Step: 3
Training loss: 4.030918314691678
Validation loss: 3.2532768602498705

Epoch: 6| Step: 4
Training loss: 4.175751103434211
Validation loss: 3.249563786992061

Epoch: 6| Step: 5
Training loss: 3.6560972785027874
Validation loss: 3.245670320059901

Epoch: 6| Step: 6
Training loss: 2.8290262208966017
Validation loss: 3.242375796568419

Epoch: 6| Step: 7
Training loss: 3.140741298666824
Validation loss: 3.238814202333242

Epoch: 6| Step: 8
Training loss: 3.385724723689457
Validation loss: 3.2360652493750317

Epoch: 6| Step: 9
Training loss: 3.6411082720584593
Validation loss: 3.2323560817511114

Epoch: 6| Step: 10
Training loss: 3.1232740595135224
Validation loss: 3.2286387145264497

Epoch: 6| Step: 11
Training loss: 3.2016221405327507
Validation loss: 3.2254862495160412

Epoch: 6| Step: 12
Training loss: 3.331100351719032
Validation loss: 3.221874954613366

Epoch: 6| Step: 13
Training loss: 2.754256249229486
Validation loss: 3.219073825583325

Epoch: 41| Step: 0
Training loss: 2.9560054879557005
Validation loss: 3.2159776816123498

Epoch: 6| Step: 1
Training loss: 3.4908335405721367
Validation loss: 3.21386400993636

Epoch: 6| Step: 2
Training loss: 3.5176052365695893
Validation loss: 3.2111286808715347

Epoch: 6| Step: 3
Training loss: 3.1153127439202057
Validation loss: 3.2074125297911067

Epoch: 6| Step: 4
Training loss: 2.7021611430176535
Validation loss: 3.2040457541905187

Epoch: 6| Step: 5
Training loss: 3.276760117552238
Validation loss: 3.200461668249327

Epoch: 6| Step: 6
Training loss: 3.100646683706116
Validation loss: 3.19736191766331

Epoch: 6| Step: 7
Training loss: 3.2128463973969565
Validation loss: 3.19512933953832

Epoch: 6| Step: 8
Training loss: 3.4911717381977674
Validation loss: 3.192401421104599

Epoch: 6| Step: 9
Training loss: 3.3414619674835686
Validation loss: 3.1898131361056077

Epoch: 6| Step: 10
Training loss: 3.8455378398568643
Validation loss: 3.1864701895084306

Epoch: 6| Step: 11
Training loss: 3.7110540431946326
Validation loss: 3.183190692748289

Epoch: 6| Step: 12
Training loss: 3.21029916622958
Validation loss: 3.1801622990711387

Epoch: 6| Step: 13
Training loss: 3.5483368537231965
Validation loss: 3.1763808594256404

Epoch: 42| Step: 0
Training loss: 3.529788904983571
Validation loss: 3.1735257393010676

Epoch: 6| Step: 1
Training loss: 3.1837465214495007
Validation loss: 3.1702843045804103

Epoch: 6| Step: 2
Training loss: 2.2692346690963796
Validation loss: 3.166974169875641

Epoch: 6| Step: 3
Training loss: 3.4814251785445154
Validation loss: 3.1639826383833736

Epoch: 6| Step: 4
Training loss: 3.3897715254679106
Validation loss: 3.161600783195701

Epoch: 6| Step: 5
Training loss: 3.164895783888622
Validation loss: 3.1605811790207987

Epoch: 6| Step: 6
Training loss: 3.2755704135491657
Validation loss: 3.155278487552217

Epoch: 6| Step: 7
Training loss: 3.121984170984759
Validation loss: 3.1524028433768323

Epoch: 6| Step: 8
Training loss: 3.2712986770990566
Validation loss: 3.1499870027546453

Epoch: 6| Step: 9
Training loss: 2.8827676743741426
Validation loss: 3.1465907079882216

Epoch: 6| Step: 10
Training loss: 3.5852222934474534
Validation loss: 3.144030519664131

Epoch: 6| Step: 11
Training loss: 3.2959973943477814
Validation loss: 3.1414616673889486

Epoch: 6| Step: 12
Training loss: 3.676876346860876
Validation loss: 3.1392253584742593

Epoch: 6| Step: 13
Training loss: 3.7063410833015684
Validation loss: 3.1358678414984387

Epoch: 43| Step: 0
Training loss: 3.4729209773252965
Validation loss: 3.132630771810703

Epoch: 6| Step: 1
Training loss: 3.2906107758217322
Validation loss: 3.1296158080095724

Epoch: 6| Step: 2
Training loss: 3.4035107158449045
Validation loss: 3.126482700827336

Epoch: 6| Step: 3
Training loss: 2.805408778196283
Validation loss: 3.1233280668414434

Epoch: 6| Step: 4
Training loss: 3.1398432883257312
Validation loss: 3.1199500670472147

Epoch: 6| Step: 5
Training loss: 3.4726259039292064
Validation loss: 3.117634064851582

Epoch: 6| Step: 6
Training loss: 2.9071030544074823
Validation loss: 3.1141699492168673

Epoch: 6| Step: 7
Training loss: 3.428677421021388
Validation loss: 3.1108378383039432

Epoch: 6| Step: 8
Training loss: 2.602896225345569
Validation loss: 3.1079107316009877

Epoch: 6| Step: 9
Training loss: 3.344737539899869
Validation loss: 3.1051368647995807

Epoch: 6| Step: 10
Training loss: 3.379386453187589
Validation loss: 3.1021312253050572

Epoch: 6| Step: 11
Training loss: 3.4970306334578733
Validation loss: 3.099207614307802

Epoch: 6| Step: 12
Training loss: 3.3748488215743007
Validation loss: 3.0960317988762838

Epoch: 6| Step: 13
Training loss: 3.2758814899401982
Validation loss: 3.093571487568355

Epoch: 44| Step: 0
Training loss: 3.424760829621874
Validation loss: 3.092384897761125

Epoch: 6| Step: 1
Training loss: 2.905488437422796
Validation loss: 3.087366769466948

Epoch: 6| Step: 2
Training loss: 3.2244830877943333
Validation loss: 3.0839130440874687

Epoch: 6| Step: 3
Training loss: 3.682823966408619
Validation loss: 3.081113278113504

Epoch: 6| Step: 4
Training loss: 2.92044113798407
Validation loss: 3.0777601487343036

Epoch: 6| Step: 5
Training loss: 3.0454865250791174
Validation loss: 3.0747316765470183

Epoch: 6| Step: 6
Training loss: 2.6110868035756463
Validation loss: 3.0727844899517156

Epoch: 6| Step: 7
Training loss: 3.5191759952677764
Validation loss: 3.06962667090188

Epoch: 6| Step: 8
Training loss: 3.2406049060106588
Validation loss: 3.0677614752544202

Epoch: 6| Step: 9
Training loss: 3.1700286753226954
Validation loss: 3.0686759955345675

Epoch: 6| Step: 10
Training loss: 3.268599620153511
Validation loss: 3.063331659757249

Epoch: 6| Step: 11
Training loss: 3.048490125552855
Validation loss: 3.0592775583254452

Epoch: 6| Step: 12
Training loss: 3.4437008502865996
Validation loss: 3.056045399521673

Epoch: 6| Step: 13
Training loss: 3.32341651784338
Validation loss: 3.053846811057837

Epoch: 45| Step: 0
Training loss: 3.361289538927278
Validation loss: 3.050832008007949

Epoch: 6| Step: 1
Training loss: 2.7562739157125695
Validation loss: 3.0478900490200638

Epoch: 6| Step: 2
Training loss: 3.2211336365163237
Validation loss: 3.0463301994818797

Epoch: 6| Step: 3
Training loss: 3.435946720487358
Validation loss: 3.042862321839423

Epoch: 6| Step: 4
Training loss: 2.9304600218457564
Validation loss: 3.0409333812688475

Epoch: 6| Step: 5
Training loss: 3.122807611075882
Validation loss: 3.0391964788903665

Epoch: 6| Step: 6
Training loss: 2.7866316601807073
Validation loss: 3.035242891977438

Epoch: 6| Step: 7
Training loss: 3.430573994067461
Validation loss: 3.031842727651891

Epoch: 6| Step: 8
Training loss: 3.041351319431145
Validation loss: 3.0307711980151217

Epoch: 6| Step: 9
Training loss: 3.4644611409733628
Validation loss: 3.0282532865882845

Epoch: 6| Step: 10
Training loss: 2.7929327262209163
Validation loss: 3.027410927304057

Epoch: 6| Step: 11
Training loss: 3.185542983117641
Validation loss: 3.0233836929041336

Epoch: 6| Step: 12
Training loss: 3.3312170145144444
Validation loss: 3.0206640042607784

Epoch: 6| Step: 13
Training loss: 3.466210475273959
Validation loss: 3.0177022075141

Epoch: 46| Step: 0
Training loss: 2.8616140802077012
Validation loss: 3.014680348812213

Epoch: 6| Step: 1
Training loss: 2.9307720974130858
Validation loss: 3.01198219502773

Epoch: 6| Step: 2
Training loss: 3.447559964417146
Validation loss: 3.010006600580762

Epoch: 6| Step: 3
Training loss: 3.6566756563125407
Validation loss: 3.007538331322104

Epoch: 6| Step: 4
Training loss: 2.8741911704048504
Validation loss: 3.004412016106551

Epoch: 6| Step: 5
Training loss: 3.459774467747252
Validation loss: 3.003198799128928

Epoch: 6| Step: 6
Training loss: 2.9530654174606843
Validation loss: 3.001088699842629

Epoch: 6| Step: 7
Training loss: 3.5615538294305815
Validation loss: 2.9978454986106

Epoch: 6| Step: 8
Training loss: 3.7564603470540265
Validation loss: 2.994197917074073

Epoch: 6| Step: 9
Training loss: 2.505321465764437
Validation loss: 2.9918332334245736

Epoch: 6| Step: 10
Training loss: 3.0023565573497324
Validation loss: 2.988660588008608

Epoch: 6| Step: 11
Training loss: 2.957822585453949
Validation loss: 2.9870268538819276

Epoch: 6| Step: 12
Training loss: 2.169966153878505
Validation loss: 2.9851893833387857

Epoch: 6| Step: 13
Training loss: 3.396304950065994
Validation loss: 2.982059825680017

Epoch: 47| Step: 0
Training loss: 3.2779538992711705
Validation loss: 2.979241314644144

Epoch: 6| Step: 1
Training loss: 2.7178757237421713
Validation loss: 2.9759984320487742

Epoch: 6| Step: 2
Training loss: 3.549759418770847
Validation loss: 2.974602027795492

Epoch: 6| Step: 3
Training loss: 3.085081962102567
Validation loss: 2.9711954451663867

Epoch: 6| Step: 4
Training loss: 3.2165445716363457
Validation loss: 2.9691215684156496

Epoch: 6| Step: 5
Training loss: 2.9848951914931985
Validation loss: 2.966987756076222

Epoch: 6| Step: 6
Training loss: 2.6763966096420146
Validation loss: 2.9640509106978064

Epoch: 6| Step: 7
Training loss: 3.704349106256778
Validation loss: 2.9617804784236146

Epoch: 6| Step: 8
Training loss: 2.784849345243276
Validation loss: 2.9596219457590256

Epoch: 6| Step: 9
Training loss: 2.8299974175970473
Validation loss: 2.9574825962013542

Epoch: 6| Step: 10
Training loss: 3.4388745420776696
Validation loss: 2.954913477440472

Epoch: 6| Step: 11
Training loss: 2.8922873176319075
Validation loss: 2.9522224271459403

Epoch: 6| Step: 12
Training loss: 3.317858410629272
Validation loss: 2.9497719353271576

Epoch: 6| Step: 13
Training loss: 2.77557445456908
Validation loss: 2.9472016095219518

Epoch: 48| Step: 0
Training loss: 2.8612324669377003
Validation loss: 2.94565482473272

Epoch: 6| Step: 1
Training loss: 3.0736860615959176
Validation loss: 2.942575709412312

Epoch: 6| Step: 2
Training loss: 3.331203415994056
Validation loss: 2.94062723936022

Epoch: 6| Step: 3
Training loss: 2.788789281632557
Validation loss: 2.939335364668587

Epoch: 6| Step: 4
Training loss: 3.0328975015055604
Validation loss: 2.9365193102999694

Epoch: 6| Step: 5
Training loss: 3.415717729738939
Validation loss: 2.936632867078078

Epoch: 6| Step: 6
Training loss: 3.446691812193569
Validation loss: 2.932785281727569

Epoch: 6| Step: 7
Training loss: 3.3573201837057436
Validation loss: 2.929485765081292

Epoch: 6| Step: 8
Training loss: 2.94407712896527
Validation loss: 2.9257306042350755

Epoch: 6| Step: 9
Training loss: 3.2438995620851894
Validation loss: 2.9243460149620124

Epoch: 6| Step: 10
Training loss: 2.6834321396764054
Validation loss: 2.9213629561221923

Epoch: 6| Step: 11
Training loss: 2.5277567176733355
Validation loss: 2.918973954707807

Epoch: 6| Step: 12
Training loss: 3.214016591264859
Validation loss: 2.9174301964593026

Epoch: 6| Step: 13
Training loss: 2.928905657393995
Validation loss: 2.91579956153601

Epoch: 49| Step: 0
Training loss: 2.9788060181185183
Validation loss: 2.916661880125932

Epoch: 6| Step: 1
Training loss: 3.5384248744379208
Validation loss: 2.9116296234423875

Epoch: 6| Step: 2
Training loss: 2.3626015939010765
Validation loss: 2.909096380182562

Epoch: 6| Step: 3
Training loss: 2.9612309051323136
Validation loss: 2.907634241378646

Epoch: 6| Step: 4
Training loss: 3.115266212611605
Validation loss: 2.905803495720132

Epoch: 6| Step: 5
Training loss: 3.2606401133319562
Validation loss: 2.9030571630221984

Epoch: 6| Step: 6
Training loss: 2.919295370706051
Validation loss: 2.9009645726879816

Epoch: 6| Step: 7
Training loss: 2.9841938063654974
Validation loss: 2.901052250092319

Epoch: 6| Step: 8
Training loss: 2.7077410319252615
Validation loss: 2.8975217320195257

Epoch: 6| Step: 9
Training loss: 2.6927656884544335
Validation loss: 2.895896558734616

Epoch: 6| Step: 10
Training loss: 2.664702665765176
Validation loss: 2.8928329008702494

Epoch: 6| Step: 11
Training loss: 3.6362217810444926
Validation loss: 2.8904568322554627

Epoch: 6| Step: 12
Training loss: 2.919113894533794
Validation loss: 2.8896245101345457

Epoch: 6| Step: 13
Training loss: 3.538164643842346
Validation loss: 2.8873114762407788

Epoch: 50| Step: 0
Training loss: 2.979336144666298
Validation loss: 2.8864064269192373

Epoch: 6| Step: 1
Training loss: 2.723019984726377
Validation loss: 2.8848478167375613

Epoch: 6| Step: 2
Training loss: 2.6729214052518575
Validation loss: 2.8829698390461407

Epoch: 6| Step: 3
Training loss: 2.8706067561045976
Validation loss: 2.8827500995612483

Epoch: 6| Step: 4
Training loss: 3.176269493718774
Validation loss: 2.87865274004139

Epoch: 6| Step: 5
Training loss: 2.0047974268684405
Validation loss: 2.8774231360383187

Epoch: 6| Step: 6
Training loss: 3.4211427784830324
Validation loss: 2.876666802140723

Epoch: 6| Step: 7
Training loss: 3.0194726619983125
Validation loss: 2.8771574246099143

Epoch: 6| Step: 8
Training loss: 3.5149980452248575
Validation loss: 2.874666968697135

Epoch: 6| Step: 9
Training loss: 2.5180852007945824
Validation loss: 2.8711619812346685

Epoch: 6| Step: 10
Training loss: 3.3895076193830085
Validation loss: 2.8680469080743567

Epoch: 6| Step: 11
Training loss: 3.5654762283835884
Validation loss: 2.866387320555022

Epoch: 6| Step: 12
Training loss: 3.1566615072474735
Validation loss: 2.8647260780604027

Epoch: 6| Step: 13
Training loss: 2.790009837252868
Validation loss: 2.865626590219415

Testing loss: 2.424809729650119
