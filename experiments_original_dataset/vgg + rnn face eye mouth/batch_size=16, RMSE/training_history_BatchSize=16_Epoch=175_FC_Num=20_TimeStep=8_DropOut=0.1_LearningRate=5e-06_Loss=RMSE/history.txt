Epoch: 1| Step: 0
Training loss: 6.557433870413315
Validation loss: 5.919876929112206

Epoch: 6| Step: 1
Training loss: 5.809817115413426
Validation loss: 5.918030174280721

Epoch: 6| Step: 2
Training loss: 5.903407790527414
Validation loss: 5.916144558431525

Epoch: 6| Step: 3
Training loss: 5.57731387441221
Validation loss: 5.914060914322016

Epoch: 6| Step: 4
Training loss: 5.826158779946732
Validation loss: 5.912099857782644

Epoch: 6| Step: 5
Training loss: 5.83012948836252
Validation loss: 5.909884698499327

Epoch: 6| Step: 6
Training loss: 5.898092135998433
Validation loss: 5.907845337177941

Epoch: 6| Step: 7
Training loss: 6.343795701036122
Validation loss: 5.905572896154206

Epoch: 6| Step: 8
Training loss: 6.22373325680459
Validation loss: 5.903246241910205

Epoch: 6| Step: 9
Training loss: 6.295330000053239
Validation loss: 5.901012540668504

Epoch: 6| Step: 10
Training loss: 6.333554648832368
Validation loss: 5.898691012763976

Epoch: 6| Step: 11
Training loss: 6.350190900200886
Validation loss: 5.89612269505857

Epoch: 6| Step: 12
Training loss: 5.518310411859389
Validation loss: 5.893543764876996

Epoch: 6| Step: 13
Training loss: 5.735693008337238
Validation loss: 5.8908500055028705

Epoch: 2| Step: 0
Training loss: 6.392113547222541
Validation loss: 5.887986729852263

Epoch: 6| Step: 1
Training loss: 6.995721872095742
Validation loss: 5.885174078428832

Epoch: 6| Step: 2
Training loss: 6.7037663364158
Validation loss: 5.882022340216957

Epoch: 6| Step: 3
Training loss: 5.99742230039436
Validation loss: 5.8787016874190074

Epoch: 6| Step: 4
Training loss: 6.011156200836043
Validation loss: 5.875484798259913

Epoch: 6| Step: 5
Training loss: 6.640881199101964
Validation loss: 5.871848431185872

Epoch: 6| Step: 6
Training loss: 6.1824486660860405
Validation loss: 5.868146483590259

Epoch: 6| Step: 7
Training loss: 6.151288972082713
Validation loss: 5.864172352494489

Epoch: 6| Step: 8
Training loss: 6.207688197810072
Validation loss: 5.860137076092857

Epoch: 6| Step: 9
Training loss: 6.447185748141969
Validation loss: 5.855601676736762

Epoch: 6| Step: 10
Training loss: 4.591566747742497
Validation loss: 5.850924434600077

Epoch: 6| Step: 11
Training loss: 5.016997247662853
Validation loss: 5.846461627428548

Epoch: 6| Step: 12
Training loss: 5.343665406745453
Validation loss: 5.841842748116863

Epoch: 6| Step: 13
Training loss: 4.3949717661153604
Validation loss: 5.836812625688846

Epoch: 3| Step: 0
Training loss: 4.351681719641557
Validation loss: 5.831555377123249

Epoch: 6| Step: 1
Training loss: 5.622262924576403
Validation loss: 5.826307952686483

Epoch: 6| Step: 2
Training loss: 7.008664899036919
Validation loss: 5.821091540468491

Epoch: 6| Step: 3
Training loss: 6.133107327706247
Validation loss: 5.815068542216459

Epoch: 6| Step: 4
Training loss: 6.152571300355407
Validation loss: 5.808631347862935

Epoch: 6| Step: 5
Training loss: 5.842950286815661
Validation loss: 5.802103431799257

Epoch: 6| Step: 6
Training loss: 6.157618026934197
Validation loss: 5.795577953790381

Epoch: 6| Step: 7
Training loss: 6.197357032791844
Validation loss: 5.788281565239831

Epoch: 6| Step: 8
Training loss: 5.665247047471691
Validation loss: 5.781428373867045

Epoch: 6| Step: 9
Training loss: 6.224742360126335
Validation loss: 5.773935588158955

Epoch: 6| Step: 10
Training loss: 5.759785825138366
Validation loss: 5.766041259074627

Epoch: 6| Step: 11
Training loss: 6.212324186788534
Validation loss: 5.757533956525028

Epoch: 6| Step: 12
Training loss: 5.577422282089114
Validation loss: 5.750063882002971

Epoch: 6| Step: 13
Training loss: 5.374324667444601
Validation loss: 5.7414009922315135

Epoch: 4| Step: 0
Training loss: 5.780863980989279
Validation loss: 5.73276884641651

Epoch: 6| Step: 1
Training loss: 4.6851825325988665
Validation loss: 5.724313444368953

Epoch: 6| Step: 2
Training loss: 5.7927517686310805
Validation loss: 5.715673067069104

Epoch: 6| Step: 3
Training loss: 6.59889952992948
Validation loss: 5.706856232521995

Epoch: 6| Step: 4
Training loss: 5.72015497011052
Validation loss: 5.698120206536793

Epoch: 6| Step: 5
Training loss: 5.7357625088227975
Validation loss: 5.689542717953395

Epoch: 6| Step: 6
Training loss: 5.7949445857113115
Validation loss: 5.680196887038051

Epoch: 6| Step: 7
Training loss: 4.9988968585935485
Validation loss: 5.671796561715502

Epoch: 6| Step: 8
Training loss: 6.505675845504993
Validation loss: 5.662859853463681

Epoch: 6| Step: 9
Training loss: 5.78878738223209
Validation loss: 5.653935838943189

Epoch: 6| Step: 10
Training loss: 6.107656407892883
Validation loss: 5.6452448445537

Epoch: 6| Step: 11
Training loss: 6.1218776919021645
Validation loss: 5.636428723327696

Epoch: 6| Step: 12
Training loss: 5.322248781510044
Validation loss: 5.627550352287334

Epoch: 6| Step: 13
Training loss: 5.837881476866369
Validation loss: 5.619201497179265

Epoch: 5| Step: 0
Training loss: 4.619395804262235
Validation loss: 5.610600188047008

Epoch: 6| Step: 1
Training loss: 6.72062791706321
Validation loss: 5.602461724525765

Epoch: 6| Step: 2
Training loss: 4.15923001719519
Validation loss: 5.593899715984462

Epoch: 6| Step: 3
Training loss: 6.250762587754137
Validation loss: 5.585579273323687

Epoch: 6| Step: 4
Training loss: 5.087407569139328
Validation loss: 5.577740311380691

Epoch: 6| Step: 5
Training loss: 6.065745949657078
Validation loss: 5.569993190521516

Epoch: 6| Step: 6
Training loss: 5.653095862301394
Validation loss: 5.562153523259181

Epoch: 6| Step: 7
Training loss: 4.9014593170074665
Validation loss: 5.5541330911242035

Epoch: 6| Step: 8
Training loss: 5.535992501997969
Validation loss: 5.546281838379045

Epoch: 6| Step: 9
Training loss: 5.534201831143938
Validation loss: 5.538552817213327

Epoch: 6| Step: 10
Training loss: 5.74638551636466
Validation loss: 5.531266465674424

Epoch: 6| Step: 11
Training loss: 5.604568334694628
Validation loss: 5.523263456416358

Epoch: 6| Step: 12
Training loss: 6.4452106999536385
Validation loss: 5.515497280007327

Epoch: 6| Step: 13
Training loss: 6.506956046397278
Validation loss: 5.508155931087049

Epoch: 6| Step: 0
Training loss: 5.737976107654311
Validation loss: 5.499985550370164

Epoch: 6| Step: 1
Training loss: 6.018447174344963
Validation loss: 5.492482596618556

Epoch: 6| Step: 2
Training loss: 4.856029671441668
Validation loss: 5.484888818912828

Epoch: 6| Step: 3
Training loss: 6.50955730005319
Validation loss: 5.477128243168518

Epoch: 6| Step: 4
Training loss: 5.050193050207126
Validation loss: 5.469214806558686

Epoch: 6| Step: 5
Training loss: 5.639533869913139
Validation loss: 5.461840553546106

Epoch: 6| Step: 6
Training loss: 6.337833445427737
Validation loss: 5.454577116922517

Epoch: 6| Step: 7
Training loss: 6.201812528422261
Validation loss: 5.447236562646568

Epoch: 6| Step: 8
Training loss: 5.3888423017517795
Validation loss: 5.439919558238877

Epoch: 6| Step: 9
Training loss: 5.126648242422927
Validation loss: 5.432808880370028

Epoch: 6| Step: 10
Training loss: 5.337862753769168
Validation loss: 5.425607882193177

Epoch: 6| Step: 11
Training loss: 5.69252211628849
Validation loss: 5.418687570601665

Epoch: 6| Step: 12
Training loss: 4.852827856199341
Validation loss: 5.412080417547787

Epoch: 6| Step: 13
Training loss: 4.924217804889446
Validation loss: 5.405958399322913

Epoch: 7| Step: 0
Training loss: 5.491692250741612
Validation loss: 5.399182501477898

Epoch: 6| Step: 1
Training loss: 5.574741566231877
Validation loss: 5.392929631241971

Epoch: 6| Step: 2
Training loss: 5.329927290658481
Validation loss: 5.3862822948050395

Epoch: 6| Step: 3
Training loss: 5.689939541621219
Validation loss: 5.380578332705197

Epoch: 6| Step: 4
Training loss: 5.897142604139287
Validation loss: 5.37490040295019

Epoch: 6| Step: 5
Training loss: 5.517235885403627
Validation loss: 5.368894406479687

Epoch: 6| Step: 6
Training loss: 5.624851479159042
Validation loss: 5.362844754558059

Epoch: 6| Step: 7
Training loss: 5.099876417270869
Validation loss: 5.357347703680573

Epoch: 6| Step: 8
Training loss: 5.987844233482792
Validation loss: 5.351546431839853

Epoch: 6| Step: 9
Training loss: 5.097488622722866
Validation loss: 5.345876140626264

Epoch: 6| Step: 10
Training loss: 5.601896353207117
Validation loss: 5.340622044073826

Epoch: 6| Step: 11
Training loss: 5.122730590038882
Validation loss: 5.334633112515775

Epoch: 6| Step: 12
Training loss: 5.181876938165835
Validation loss: 5.329426864622777

Epoch: 6| Step: 13
Training loss: 5.4553629045899745
Validation loss: 5.323731760025276

Epoch: 8| Step: 0
Training loss: 6.170273353295989
Validation loss: 5.318079901506384

Epoch: 6| Step: 1
Training loss: 5.903305369217025
Validation loss: 5.31236350688243

Epoch: 6| Step: 2
Training loss: 5.776556966055132
Validation loss: 5.306948075732388

Epoch: 6| Step: 3
Training loss: 4.6127664794032075
Validation loss: 5.300555485579679

Epoch: 6| Step: 4
Training loss: 5.956567604907707
Validation loss: 5.294907946388295

Epoch: 6| Step: 5
Training loss: 4.850491858641962
Validation loss: 5.2891069764408885

Epoch: 6| Step: 6
Training loss: 4.76278571926317
Validation loss: 5.283400058425272

Epoch: 6| Step: 7
Training loss: 4.737738393457248
Validation loss: 5.277040990074004

Epoch: 6| Step: 8
Training loss: 5.164498869079709
Validation loss: 5.271742982234599

Epoch: 6| Step: 9
Training loss: 5.659725238614621
Validation loss: 5.266114828115114

Epoch: 6| Step: 10
Training loss: 5.16168924758861
Validation loss: 5.260107513508659

Epoch: 6| Step: 11
Training loss: 5.411722048910861
Validation loss: 5.254285032475332

Epoch: 6| Step: 12
Training loss: 5.750531047679185
Validation loss: 5.24845542590453

Epoch: 6| Step: 13
Training loss: 5.430205966703317
Validation loss: 5.242449189659786

Epoch: 9| Step: 0
Training loss: 5.9489218624624405
Validation loss: 5.23660406978952

Epoch: 6| Step: 1
Training loss: 5.189524427906838
Validation loss: 5.230482485551109

Epoch: 6| Step: 2
Training loss: 5.527007636644566
Validation loss: 5.224852140971985

Epoch: 6| Step: 3
Training loss: 5.096425108756152
Validation loss: 5.219091042588902

Epoch: 6| Step: 4
Training loss: 5.757185385518901
Validation loss: 5.21355452204087

Epoch: 6| Step: 5
Training loss: 5.158454932205733
Validation loss: 5.208166694518469

Epoch: 6| Step: 6
Training loss: 5.389046346629712
Validation loss: 5.201913014675248

Epoch: 6| Step: 7
Training loss: 4.3572415289326205
Validation loss: 5.196080323655393

Epoch: 6| Step: 8
Training loss: 5.068494661910712
Validation loss: 5.190245089712841

Epoch: 6| Step: 9
Training loss: 6.331578195544067
Validation loss: 5.18484165451378

Epoch: 6| Step: 10
Training loss: 5.465826157564545
Validation loss: 5.179501199800159

Epoch: 6| Step: 11
Training loss: 5.04506213812467
Validation loss: 5.173559369789272

Epoch: 6| Step: 12
Training loss: 5.359023902892434
Validation loss: 5.168068675072075

Epoch: 6| Step: 13
Training loss: 4.519003900805261
Validation loss: 5.162974956299262

Epoch: 10| Step: 0
Training loss: 4.729809262258747
Validation loss: 5.15771223200167

Epoch: 6| Step: 1
Training loss: 4.409404518250328
Validation loss: 5.152483371619561

Epoch: 6| Step: 2
Training loss: 4.192139062875342
Validation loss: 5.14710180836314

Epoch: 6| Step: 3
Training loss: 5.226016348228184
Validation loss: 5.142384514965393

Epoch: 6| Step: 4
Training loss: 5.106977454373812
Validation loss: 5.136787226502149

Epoch: 6| Step: 5
Training loss: 4.76911453313671
Validation loss: 5.13170693547224

Epoch: 6| Step: 6
Training loss: 5.321009922109385
Validation loss: 5.128186080664938

Epoch: 6| Step: 7
Training loss: 6.166453314862199
Validation loss: 5.1224352924460685

Epoch: 6| Step: 8
Training loss: 5.311674525136714
Validation loss: 5.117694610239807

Epoch: 6| Step: 9
Training loss: 6.6052628659332076
Validation loss: 5.113272142122889

Epoch: 6| Step: 10
Training loss: 5.910441853744451
Validation loss: 5.107688882241502

Epoch: 6| Step: 11
Training loss: 5.588995079378265
Validation loss: 5.102408073727367

Epoch: 6| Step: 12
Training loss: 4.573957297315533
Validation loss: 5.097163049606764

Epoch: 6| Step: 13
Training loss: 4.9797762999024675
Validation loss: 5.092333450402946

Epoch: 11| Step: 0
Training loss: 5.355848036008346
Validation loss: 5.087577996683176

Epoch: 6| Step: 1
Training loss: 5.306637390158197
Validation loss: 5.083331181051497

Epoch: 6| Step: 2
Training loss: 4.466445435316563
Validation loss: 5.0783961140568685

Epoch: 6| Step: 3
Training loss: 5.25431065474273
Validation loss: 5.0740152327494705

Epoch: 6| Step: 4
Training loss: 5.366498922407803
Validation loss: 5.0690251123264485

Epoch: 6| Step: 5
Training loss: 5.232035828773941
Validation loss: 5.063893412908106

Epoch: 6| Step: 6
Training loss: 4.8918182574844105
Validation loss: 5.059901634235234

Epoch: 6| Step: 7
Training loss: 5.5115284173816494
Validation loss: 5.055423578814994

Epoch: 6| Step: 8
Training loss: 4.66063939009833
Validation loss: 5.050409077609089

Epoch: 6| Step: 9
Training loss: 5.399206965106152
Validation loss: 5.046402821532827

Epoch: 6| Step: 10
Training loss: 5.472823538663709
Validation loss: 5.042202230124033

Epoch: 6| Step: 11
Training loss: 5.195190795390743
Validation loss: 5.037693801824639

Epoch: 6| Step: 12
Training loss: 5.191100376323447
Validation loss: 5.033061299751683

Epoch: 6| Step: 13
Training loss: 5.143691426681807
Validation loss: 5.028589022799672

Epoch: 12| Step: 0
Training loss: 5.100254890205818
Validation loss: 5.024200776976111

Epoch: 6| Step: 1
Training loss: 4.4124925910520085
Validation loss: 5.019659176790723

Epoch: 6| Step: 2
Training loss: 4.703948598334327
Validation loss: 5.015944457848349

Epoch: 6| Step: 3
Training loss: 4.955106802057833
Validation loss: 5.011885947701416

Epoch: 6| Step: 4
Training loss: 5.1189222816846645
Validation loss: 5.0071969053146015

Epoch: 6| Step: 5
Training loss: 4.800306453458898
Validation loss: 5.002596848373448

Epoch: 6| Step: 6
Training loss: 4.712301736804574
Validation loss: 4.998281596849767

Epoch: 6| Step: 7
Training loss: 5.710330288983059
Validation loss: 4.99427964095725

Epoch: 6| Step: 8
Training loss: 5.0220442244307915
Validation loss: 4.98982651767609

Epoch: 6| Step: 9
Training loss: 6.22940148088551
Validation loss: 4.985800097915448

Epoch: 6| Step: 10
Training loss: 5.6506405830147335
Validation loss: 4.981702895498052

Epoch: 6| Step: 11
Training loss: 5.0030645515750205
Validation loss: 4.9772095711199285

Epoch: 6| Step: 12
Training loss: 4.938746427796852
Validation loss: 4.972954161041445

Epoch: 6| Step: 13
Training loss: 5.058096206528408
Validation loss: 4.968553391251534

Epoch: 13| Step: 0
Training loss: 5.1299838512382125
Validation loss: 4.963867475684872

Epoch: 6| Step: 1
Training loss: 4.981483505691901
Validation loss: 4.960303430761448

Epoch: 6| Step: 2
Training loss: 5.584766185104365
Validation loss: 4.956093268784557

Epoch: 6| Step: 3
Training loss: 4.53840776931364
Validation loss: 4.951557669572529

Epoch: 6| Step: 4
Training loss: 5.757674693059148
Validation loss: 4.947439627154554

Epoch: 6| Step: 5
Training loss: 5.2915565098788475
Validation loss: 4.94221294186275

Epoch: 6| Step: 6
Training loss: 4.617059437997729
Validation loss: 4.938068019208433

Epoch: 6| Step: 7
Training loss: 4.425056310607898
Validation loss: 4.934270808783033

Epoch: 6| Step: 8
Training loss: 5.215383940303474
Validation loss: 4.929778810069569

Epoch: 6| Step: 9
Training loss: 5.827660263391116
Validation loss: 4.92593400492971

Epoch: 6| Step: 10
Training loss: 5.134944107360641
Validation loss: 4.921414534408838

Epoch: 6| Step: 11
Training loss: 4.745883563375648
Validation loss: 4.916357752691472

Epoch: 6| Step: 12
Training loss: 5.137641388741203
Validation loss: 4.912220037893619

Epoch: 6| Step: 13
Training loss: 4.182607725116252
Validation loss: 4.907968013792884

Epoch: 14| Step: 0
Training loss: 4.987230015381119
Validation loss: 4.903258462503263

Epoch: 6| Step: 1
Training loss: 5.672710262619872
Validation loss: 4.899032759406953

Epoch: 6| Step: 2
Training loss: 5.245851603449164
Validation loss: 4.894157036117379

Epoch: 6| Step: 3
Training loss: 5.563705827978615
Validation loss: 4.889447705284472

Epoch: 6| Step: 4
Training loss: 4.430804291814668
Validation loss: 4.884360138847536

Epoch: 6| Step: 5
Training loss: 4.869455950855723
Validation loss: 4.879894505699835

Epoch: 6| Step: 6
Training loss: 4.835403831998509
Validation loss: 4.875073000369479

Epoch: 6| Step: 7
Training loss: 5.310756442111308
Validation loss: 4.870471481226694

Epoch: 6| Step: 8
Training loss: 5.440459399740486
Validation loss: 4.865913073228311

Epoch: 6| Step: 9
Training loss: 5.217367206047907
Validation loss: 4.861461849577832

Epoch: 6| Step: 10
Training loss: 4.74787052004345
Validation loss: 4.856692801522806

Epoch: 6| Step: 11
Training loss: 4.28569145650687
Validation loss: 4.8519423249609765

Epoch: 6| Step: 12
Training loss: 4.894480200377234
Validation loss: 4.847472927941911

Epoch: 6| Step: 13
Training loss: 4.235344694807955
Validation loss: 4.842925101970324

Epoch: 15| Step: 0
Training loss: 4.5262798543691884
Validation loss: 4.8386198050516995

Epoch: 6| Step: 1
Training loss: 4.755997335011319
Validation loss: 4.834333294436028

Epoch: 6| Step: 2
Training loss: 5.370664045311125
Validation loss: 4.83021027964847

Epoch: 6| Step: 3
Training loss: 4.639456553697584
Validation loss: 4.825840645197579

Epoch: 6| Step: 4
Training loss: 4.859460566218117
Validation loss: 4.82098355972767

Epoch: 6| Step: 5
Training loss: 5.66724822856127
Validation loss: 4.816304276153362

Epoch: 6| Step: 6
Training loss: 5.083465491072579
Validation loss: 4.811715958046272

Epoch: 6| Step: 7
Training loss: 4.990154300054708
Validation loss: 4.807836411492815

Epoch: 6| Step: 8
Training loss: 4.265137585190596
Validation loss: 4.803424832630519

Epoch: 6| Step: 9
Training loss: 5.232347875899842
Validation loss: 4.799439447838511

Epoch: 6| Step: 10
Training loss: 4.98067975962317
Validation loss: 4.794021238025086

Epoch: 6| Step: 11
Training loss: 5.3830534461676
Validation loss: 4.789981805664634

Epoch: 6| Step: 12
Training loss: 4.967525115273603
Validation loss: 4.784529548140509

Epoch: 6| Step: 13
Training loss: 4.157022275379102
Validation loss: 4.780420268748535

Epoch: 16| Step: 0
Training loss: 5.182963398348772
Validation loss: 4.776012901738141

Epoch: 6| Step: 1
Training loss: 5.529377076036597
Validation loss: 4.770794658698475

Epoch: 6| Step: 2
Training loss: 5.439942611503827
Validation loss: 4.76688811025671

Epoch: 6| Step: 3
Training loss: 4.5270939149950875
Validation loss: 4.763585655909648

Epoch: 6| Step: 4
Training loss: 4.414530447402637
Validation loss: 4.756990375281586

Epoch: 6| Step: 5
Training loss: 4.457852180162624
Validation loss: 4.752860094957004

Epoch: 6| Step: 6
Training loss: 4.703806273331338
Validation loss: 4.748291645360233

Epoch: 6| Step: 7
Training loss: 4.680929436295023
Validation loss: 4.743811239819785

Epoch: 6| Step: 8
Training loss: 4.604553597648546
Validation loss: 4.7387066487944205

Epoch: 6| Step: 9
Training loss: 5.3006484732587715
Validation loss: 4.733547898027604

Epoch: 6| Step: 10
Training loss: 4.335583811588087
Validation loss: 4.728735356541386

Epoch: 6| Step: 11
Training loss: 5.03479940187192
Validation loss: 4.724156934551273

Epoch: 6| Step: 12
Training loss: 4.986979124170474
Validation loss: 4.719739730146212

Epoch: 6| Step: 13
Training loss: 4.830359673228683
Validation loss: 4.713740200968933

Epoch: 17| Step: 0
Training loss: 4.775487481443628
Validation loss: 4.708573641875722

Epoch: 6| Step: 1
Training loss: 4.734511974606814
Validation loss: 4.703935893333422

Epoch: 6| Step: 2
Training loss: 4.891152642887501
Validation loss: 4.698240529786048

Epoch: 6| Step: 3
Training loss: 4.789143746761882
Validation loss: 4.6929702713910295

Epoch: 6| Step: 4
Training loss: 3.9552787371961555
Validation loss: 4.687445881849055

Epoch: 6| Step: 5
Training loss: 5.013891758423346
Validation loss: 4.682513861499045

Epoch: 6| Step: 6
Training loss: 4.593968392714704
Validation loss: 4.678458246063581

Epoch: 6| Step: 7
Training loss: 4.385006605293405
Validation loss: 4.673484601517124

Epoch: 6| Step: 8
Training loss: 4.878304950686717
Validation loss: 4.668776540412687

Epoch: 6| Step: 9
Training loss: 5.077485311271874
Validation loss: 4.663952185573824

Epoch: 6| Step: 10
Training loss: 4.291592544853824
Validation loss: 4.659627385065831

Epoch: 6| Step: 11
Training loss: 5.569949530162251
Validation loss: 4.65349540047483

Epoch: 6| Step: 12
Training loss: 4.62567628607057
Validation loss: 4.64883356196881

Epoch: 6| Step: 13
Training loss: 5.425293825692095
Validation loss: 4.644574609227364

Epoch: 18| Step: 0
Training loss: 5.020805559305744
Validation loss: 4.640296830241557

Epoch: 6| Step: 1
Training loss: 5.276324441254063
Validation loss: 4.634914871086988

Epoch: 6| Step: 2
Training loss: 5.69783104571277
Validation loss: 4.629506604714645

Epoch: 6| Step: 3
Training loss: 4.213507892235942
Validation loss: 4.624391017376868

Epoch: 6| Step: 4
Training loss: 5.698553055600188
Validation loss: 4.619120942303026

Epoch: 6| Step: 5
Training loss: 4.96748787066856
Validation loss: 4.614202094708794

Epoch: 6| Step: 6
Training loss: 4.483598489022696
Validation loss: 4.608129248948895

Epoch: 6| Step: 7
Training loss: 4.524071209253506
Validation loss: 4.603298755619933

Epoch: 6| Step: 8
Training loss: 4.377001495298322
Validation loss: 4.598916398833211

Epoch: 6| Step: 9
Training loss: 3.469836915331056
Validation loss: 4.593161357092609

Epoch: 6| Step: 10
Training loss: 3.8312427514460388
Validation loss: 4.588900196676252

Epoch: 6| Step: 11
Training loss: 4.770775385120175
Validation loss: 4.583739915789353

Epoch: 6| Step: 12
Training loss: 4.716211709949672
Validation loss: 4.579692654632267

Epoch: 6| Step: 13
Training loss: 4.724395810205192
Validation loss: 4.574939457088029

Epoch: 19| Step: 0
Training loss: 4.94939602336424
Validation loss: 4.569090764131123

Epoch: 6| Step: 1
Training loss: 4.342797044467263
Validation loss: 4.564631656522682

Epoch: 6| Step: 2
Training loss: 3.8148970025834017
Validation loss: 4.559337826551787

Epoch: 6| Step: 3
Training loss: 4.839919809354937
Validation loss: 4.554413793245155

Epoch: 6| Step: 4
Training loss: 4.817341932505698
Validation loss: 4.550435318575759

Epoch: 6| Step: 5
Training loss: 4.713452327436608
Validation loss: 4.5458010948895815

Epoch: 6| Step: 6
Training loss: 5.016631123531991
Validation loss: 4.541115765304883

Epoch: 6| Step: 7
Training loss: 4.483982188602024
Validation loss: 4.536454082126428

Epoch: 6| Step: 8
Training loss: 4.059808396953076
Validation loss: 4.530999327993585

Epoch: 6| Step: 9
Training loss: 5.297128316847853
Validation loss: 4.526918748420095

Epoch: 6| Step: 10
Training loss: 4.817549397364278
Validation loss: 4.521597848873072

Epoch: 6| Step: 11
Training loss: 4.758965313436544
Validation loss: 4.516031636339307

Epoch: 6| Step: 12
Training loss: 5.029101558707377
Validation loss: 4.51148663428775

Epoch: 6| Step: 13
Training loss: 4.146365235423351
Validation loss: 4.506477603464071

Epoch: 20| Step: 0
Training loss: 5.142259146725307
Validation loss: 4.501702692950951

Epoch: 6| Step: 1
Training loss: 5.391855116100356
Validation loss: 4.496352165389929

Epoch: 6| Step: 2
Training loss: 4.871825333807636
Validation loss: 4.491120974220378

Epoch: 6| Step: 3
Training loss: 4.299546843315157
Validation loss: 4.485541392480829

Epoch: 6| Step: 4
Training loss: 4.016018503108467
Validation loss: 4.480841934018959

Epoch: 6| Step: 5
Training loss: 4.349842217751805
Validation loss: 4.476980921001622

Epoch: 6| Step: 6
Training loss: 4.679004956941696
Validation loss: 4.472424310392376

Epoch: 6| Step: 7
Training loss: 4.442410827669137
Validation loss: 4.465725637823083

Epoch: 6| Step: 8
Training loss: 3.8899815038716916
Validation loss: 4.461744993650656

Epoch: 6| Step: 9
Training loss: 4.338635843940827
Validation loss: 4.455772656827302

Epoch: 6| Step: 10
Training loss: 4.87032073983703
Validation loss: 4.450206063175059

Epoch: 6| Step: 11
Training loss: 4.149582412116463
Validation loss: 4.4459909324753735

Epoch: 6| Step: 12
Training loss: 4.981967069353927
Validation loss: 4.440989595282624

Epoch: 6| Step: 13
Training loss: 4.68572984968651
Validation loss: 4.436792988936081

Epoch: 21| Step: 0
Training loss: 4.590091208422305
Validation loss: 4.4318632403664076

Epoch: 6| Step: 1
Training loss: 4.722651807405892
Validation loss: 4.426312918852781

Epoch: 6| Step: 2
Training loss: 4.7374291970792415
Validation loss: 4.421582898667998

Epoch: 6| Step: 3
Training loss: 4.392074400030172
Validation loss: 4.415661061565553

Epoch: 6| Step: 4
Training loss: 3.461327662121908
Validation loss: 4.411316612276146

Epoch: 6| Step: 5
Training loss: 4.723475029506361
Validation loss: 4.405852171341305

Epoch: 6| Step: 6
Training loss: 4.433478453897331
Validation loss: 4.400698219155766

Epoch: 6| Step: 7
Training loss: 4.397616321614903
Validation loss: 4.396074056437195

Epoch: 6| Step: 8
Training loss: 4.48041340827853
Validation loss: 4.391309003845278

Epoch: 6| Step: 9
Training loss: 3.673465854887442
Validation loss: 4.387493931258045

Epoch: 6| Step: 10
Training loss: 4.791771575221587
Validation loss: 4.382482687405825

Epoch: 6| Step: 11
Training loss: 4.826423221652029
Validation loss: 4.37710379018214

Epoch: 6| Step: 12
Training loss: 5.254490521357717
Validation loss: 4.371827546617232

Epoch: 6| Step: 13
Training loss: 4.618915783045222
Validation loss: 4.3664737816547685

Epoch: 22| Step: 0
Training loss: 5.319700141429643
Validation loss: 4.362024192767456

Epoch: 6| Step: 1
Training loss: 4.646088437772837
Validation loss: 4.357036259469152

Epoch: 6| Step: 2
Training loss: 4.377574490142692
Validation loss: 4.352085157472853

Epoch: 6| Step: 3
Training loss: 4.900853779428028
Validation loss: 4.346491563688831

Epoch: 6| Step: 4
Training loss: 4.28760096483936
Validation loss: 4.341429641804314

Epoch: 6| Step: 5
Training loss: 4.0241646415140275
Validation loss: 4.336799054853164

Epoch: 6| Step: 6
Training loss: 3.818765713273855
Validation loss: 4.331994889258379

Epoch: 6| Step: 7
Training loss: 5.340091992560959
Validation loss: 4.326419094763326

Epoch: 6| Step: 8
Training loss: 4.568399038546286
Validation loss: 4.320913612161933

Epoch: 6| Step: 9
Training loss: 4.570466493799869
Validation loss: 4.315369190587071

Epoch: 6| Step: 10
Training loss: 4.066406953575227
Validation loss: 4.311160630556761

Epoch: 6| Step: 11
Training loss: 4.134018720181198
Validation loss: 4.3059103740938935

Epoch: 6| Step: 12
Training loss: 4.2994004474767955
Validation loss: 4.3010476676891045

Epoch: 6| Step: 13
Training loss: 3.7523102319806085
Validation loss: 4.295496068542455

Epoch: 23| Step: 0
Training loss: 4.67949308013812
Validation loss: 4.291623970239092

Epoch: 6| Step: 1
Training loss: 4.649029964869856
Validation loss: 4.286062241613054

Epoch: 6| Step: 2
Training loss: 3.6744736586470204
Validation loss: 4.281692519138958

Epoch: 6| Step: 3
Training loss: 4.59704616909978
Validation loss: 4.2769612830812385

Epoch: 6| Step: 4
Training loss: 4.511420064179726
Validation loss: 4.272713924801536

Epoch: 6| Step: 5
Training loss: 3.617164825961602
Validation loss: 4.268143875483271

Epoch: 6| Step: 6
Training loss: 4.342942197045671
Validation loss: 4.26297147423613

Epoch: 6| Step: 7
Training loss: 4.658628329977625
Validation loss: 4.257890463765618

Epoch: 6| Step: 8
Training loss: 4.359745132976435
Validation loss: 4.253384943821372

Epoch: 6| Step: 9
Training loss: 4.289600776289827
Validation loss: 4.248550766331391

Epoch: 6| Step: 10
Training loss: 4.664466725377438
Validation loss: 4.244428760328713

Epoch: 6| Step: 11
Training loss: 4.032816974174799
Validation loss: 4.238782852422023

Epoch: 6| Step: 12
Training loss: 4.466297036624451
Validation loss: 4.23368822372383

Epoch: 6| Step: 13
Training loss: 4.739639226003998
Validation loss: 4.228208323670551

Epoch: 24| Step: 0
Training loss: 3.856597518718633
Validation loss: 4.223177811474618

Epoch: 6| Step: 1
Training loss: 4.068824657218165
Validation loss: 4.219674581301563

Epoch: 6| Step: 2
Training loss: 4.592776240729795
Validation loss: 4.215569547680138

Epoch: 6| Step: 3
Training loss: 4.728116270310637
Validation loss: 4.210076937149914

Epoch: 6| Step: 4
Training loss: 4.53360282059557
Validation loss: 4.204008725655426

Epoch: 6| Step: 5
Training loss: 4.075665313142258
Validation loss: 4.198766857346945

Epoch: 6| Step: 6
Training loss: 4.663116921526644
Validation loss: 4.194241425497062

Epoch: 6| Step: 7
Training loss: 4.733914293087884
Validation loss: 4.189460466285089

Epoch: 6| Step: 8
Training loss: 4.0199960156321355
Validation loss: 4.184164778215085

Epoch: 6| Step: 9
Training loss: 4.052928741574091
Validation loss: 4.178968154944116

Epoch: 6| Step: 10
Training loss: 4.753289940534772
Validation loss: 4.173899374915861

Epoch: 6| Step: 11
Training loss: 4.341886710791817
Validation loss: 4.168549353914832

Epoch: 6| Step: 12
Training loss: 3.991255500232934
Validation loss: 4.164368637883919

Epoch: 6| Step: 13
Training loss: 3.946115423402419
Validation loss: 4.159009872830826

Epoch: 25| Step: 0
Training loss: 4.3050530307884
Validation loss: 4.154152725844234

Epoch: 6| Step: 1
Training loss: 4.129961901990096
Validation loss: 4.14927472360702

Epoch: 6| Step: 2
Training loss: 4.841014261768044
Validation loss: 4.143735453875956

Epoch: 6| Step: 3
Training loss: 3.6464208220392456
Validation loss: 4.138965029233046

Epoch: 6| Step: 4
Training loss: 3.6202909203068545
Validation loss: 4.133639968501209

Epoch: 6| Step: 5
Training loss: 4.020515284370334
Validation loss: 4.129067255716701

Epoch: 6| Step: 6
Training loss: 3.4582805552917315
Validation loss: 4.123964738499593

Epoch: 6| Step: 7
Training loss: 4.076011139095461
Validation loss: 4.119460827660617

Epoch: 6| Step: 8
Training loss: 4.597675748020466
Validation loss: 4.1150000574444885

Epoch: 6| Step: 9
Training loss: 4.251934284524175
Validation loss: 4.110174161805152

Epoch: 6| Step: 10
Training loss: 4.885223623445934
Validation loss: 4.105432260377157

Epoch: 6| Step: 11
Training loss: 3.6300876037283434
Validation loss: 4.100834896400266

Epoch: 6| Step: 12
Training loss: 4.2242084371117405
Validation loss: 4.095604512888027

Epoch: 6| Step: 13
Training loss: 5.389955694692404
Validation loss: 4.091136768055016

Epoch: 26| Step: 0
Training loss: 3.8420931338728668
Validation loss: 4.086240252723088

Epoch: 6| Step: 1
Training loss: 4.072504723571323
Validation loss: 4.0808474635748855

Epoch: 6| Step: 2
Training loss: 3.3940189093454722
Validation loss: 4.076058986180853

Epoch: 6| Step: 3
Training loss: 4.307359589575861
Validation loss: 4.071043372356495

Epoch: 6| Step: 4
Training loss: 5.549136622177086
Validation loss: 4.066391435804448

Epoch: 6| Step: 5
Training loss: 4.442292540197608
Validation loss: 4.061352494373904

Epoch: 6| Step: 6
Training loss: 4.7470886945810005
Validation loss: 4.056228981688541

Epoch: 6| Step: 7
Training loss: 4.574667813274166
Validation loss: 4.050868063780887

Epoch: 6| Step: 8
Training loss: 3.83646254044253
Validation loss: 4.045547562212685

Epoch: 6| Step: 9
Training loss: 3.3530207664877425
Validation loss: 4.040317047885283

Epoch: 6| Step: 10
Training loss: 3.888251626314029
Validation loss: 4.0352481660471025

Epoch: 6| Step: 11
Training loss: 4.40329681342837
Validation loss: 4.030595396058062

Epoch: 6| Step: 12
Training loss: 4.243705126787793
Validation loss: 4.025577487152871

Epoch: 6| Step: 13
Training loss: 3.402650523671609
Validation loss: 4.020528508360779

Epoch: 27| Step: 0
Training loss: 4.652006737636105
Validation loss: 4.015344493682195

Epoch: 6| Step: 1
Training loss: 4.30700377578871
Validation loss: 4.01097603732217

Epoch: 6| Step: 2
Training loss: 3.989013365559864
Validation loss: 4.0056420807760205

Epoch: 6| Step: 3
Training loss: 4.5056676141737375
Validation loss: 4.00042269380699

Epoch: 6| Step: 4
Training loss: 4.166699345778425
Validation loss: 3.9954384185318785

Epoch: 6| Step: 5
Training loss: 4.373176194562314
Validation loss: 3.990840219197148

Epoch: 6| Step: 6
Training loss: 3.8484002492931744
Validation loss: 3.9851270975595763

Epoch: 6| Step: 7
Training loss: 3.816878384266489
Validation loss: 3.9803198829293494

Epoch: 6| Step: 8
Training loss: 3.649839862811781
Validation loss: 3.9754892436029823

Epoch: 6| Step: 9
Training loss: 4.104402383660982
Validation loss: 3.9709553235833486

Epoch: 6| Step: 10
Training loss: 4.606832753641001
Validation loss: 3.9661253012085838

Epoch: 6| Step: 11
Training loss: 3.877617597930308
Validation loss: 3.9609043538790227

Epoch: 6| Step: 12
Training loss: 3.8222671220295994
Validation loss: 3.956263928140286

Epoch: 6| Step: 13
Training loss: 3.763266050099377
Validation loss: 3.951015769148833

Epoch: 28| Step: 0
Training loss: 3.8890834956447247
Validation loss: 3.9464708698737256

Epoch: 6| Step: 1
Training loss: 4.267463930465863
Validation loss: 3.941648770077316

Epoch: 6| Step: 2
Training loss: 3.6916312658766777
Validation loss: 3.9366443047358075

Epoch: 6| Step: 3
Training loss: 4.657708675605584
Validation loss: 3.932253930456048

Epoch: 6| Step: 4
Training loss: 3.6535292715818857
Validation loss: 3.9273995121258385

Epoch: 6| Step: 5
Training loss: 3.6210869024679053
Validation loss: 3.9229968164933293

Epoch: 6| Step: 6
Training loss: 4.431291347036362
Validation loss: 3.9177704669326174

Epoch: 6| Step: 7
Training loss: 4.650902871698425
Validation loss: 3.9132182720323527

Epoch: 6| Step: 8
Training loss: 4.071970537869754
Validation loss: 3.9084912190271375

Epoch: 6| Step: 9
Training loss: 3.9431135338099432
Validation loss: 3.9035188205949845

Epoch: 6| Step: 10
Training loss: 3.700319410404144
Validation loss: 3.8986583945277484

Epoch: 6| Step: 11
Training loss: 3.7248608044724723
Validation loss: 3.8937842476258653

Epoch: 6| Step: 12
Training loss: 4.314921266051857
Validation loss: 3.888815851131189

Epoch: 6| Step: 13
Training loss: 3.858151631920728
Validation loss: 3.883668228301893

Epoch: 29| Step: 0
Training loss: 4.777116372412471
Validation loss: 3.879036738879374

Epoch: 6| Step: 1
Training loss: 3.8723829722837593
Validation loss: 3.8739844396288863

Epoch: 6| Step: 2
Training loss: 4.855683620421625
Validation loss: 3.868747619973284

Epoch: 6| Step: 3
Training loss: 3.168989851863426
Validation loss: 3.8634638985817022

Epoch: 6| Step: 4
Training loss: 4.594828576344943
Validation loss: 3.858727404667595

Epoch: 6| Step: 5
Training loss: 4.112489165781701
Validation loss: 3.8532860789541967

Epoch: 6| Step: 6
Training loss: 2.8968822491502646
Validation loss: 3.8486476802078973

Epoch: 6| Step: 7
Training loss: 3.8373844191451356
Validation loss: 3.8434669576499703

Epoch: 6| Step: 8
Training loss: 3.874078825700595
Validation loss: 3.8387665115542924

Epoch: 6| Step: 9
Training loss: 3.968542859536547
Validation loss: 3.833875486486243

Epoch: 6| Step: 10
Training loss: 3.518129397694653
Validation loss: 3.8290377819687578

Epoch: 6| Step: 11
Training loss: 4.02684265038467
Validation loss: 3.8243212635819925

Epoch: 6| Step: 12
Training loss: 3.7114433505968996
Validation loss: 3.8192523299172643

Epoch: 6| Step: 13
Training loss: 4.049754646310379
Validation loss: 3.814835442809951

Epoch: 30| Step: 0
Training loss: 3.359607067520296
Validation loss: 3.8098548718343195

Epoch: 6| Step: 1
Training loss: 4.02077121719581
Validation loss: 3.80570710167397

Epoch: 6| Step: 2
Training loss: 3.717942093995903
Validation loss: 3.800696356028826

Epoch: 6| Step: 3
Training loss: 3.615334087462021
Validation loss: 3.79593216606526

Epoch: 6| Step: 4
Training loss: 3.9386165186359006
Validation loss: 3.7913449678434237

Epoch: 6| Step: 5
Training loss: 4.1427668951568375
Validation loss: 3.786511714231951

Epoch: 6| Step: 6
Training loss: 4.110707810240455
Validation loss: 3.78203614524919

Epoch: 6| Step: 7
Training loss: 4.37911336172505
Validation loss: 3.7770275153222626

Epoch: 6| Step: 8
Training loss: 3.7346542445526305
Validation loss: 3.772298152504593

Epoch: 6| Step: 9
Training loss: 4.076721183638987
Validation loss: 3.767352793382095

Epoch: 6| Step: 10
Training loss: 3.3034388570807094
Validation loss: 3.7624944862164793

Epoch: 6| Step: 11
Training loss: 4.021865211599394
Validation loss: 3.7576926483900204

Epoch: 6| Step: 12
Training loss: 4.222837375422783
Validation loss: 3.7532613771315666

Epoch: 6| Step: 13
Training loss: 3.989126446544225
Validation loss: 3.7479788101639513

Epoch: 31| Step: 0
Training loss: 4.19732015582306
Validation loss: 3.7430514915757223

Epoch: 6| Step: 1
Training loss: 4.169888484204718
Validation loss: 3.738104326771085

Epoch: 6| Step: 2
Training loss: 3.4270519653245217
Validation loss: 3.733639398585656

Epoch: 6| Step: 3
Training loss: 3.9552792194247526
Validation loss: 3.728517266245328

Epoch: 6| Step: 4
Training loss: 4.0825536074275295
Validation loss: 3.7237256739926177

Epoch: 6| Step: 5
Training loss: 3.5480230548802
Validation loss: 3.7185472171321776

Epoch: 6| Step: 6
Training loss: 4.19699114243266
Validation loss: 3.7137146526491867

Epoch: 6| Step: 7
Training loss: 3.5141525236669406
Validation loss: 3.708794986549299

Epoch: 6| Step: 8
Training loss: 3.720312992177624
Validation loss: 3.7038600530119066

Epoch: 6| Step: 9
Training loss: 3.844290842602772
Validation loss: 3.699106839778922

Epoch: 6| Step: 10
Training loss: 3.10325964321518
Validation loss: 3.6945027814448426

Epoch: 6| Step: 11
Training loss: 4.3077720487990145
Validation loss: 3.690075680612233

Epoch: 6| Step: 12
Training loss: 3.5074277807020944
Validation loss: 3.685189013281246

Epoch: 6| Step: 13
Training loss: 4.081189871048614
Validation loss: 3.6805367971138194

Epoch: 32| Step: 0
Training loss: 3.5526659236980436
Validation loss: 3.6757610778579397

Epoch: 6| Step: 1
Training loss: 3.932881507677313
Validation loss: 3.6711292131725295

Epoch: 6| Step: 2
Training loss: 3.688373526865418
Validation loss: 3.666623866669519

Epoch: 6| Step: 3
Training loss: 4.259661295862472
Validation loss: 3.661846301314722

Epoch: 6| Step: 4
Training loss: 2.9960245176669407
Validation loss: 3.657040850105118

Epoch: 6| Step: 5
Training loss: 4.604076171722133
Validation loss: 3.652161684445232

Epoch: 6| Step: 6
Training loss: 2.881122869305839
Validation loss: 3.6474986859555196

Epoch: 6| Step: 7
Training loss: 4.144087355101708
Validation loss: 3.642618618519337

Epoch: 6| Step: 8
Training loss: 3.394716527730983
Validation loss: 3.63771731239852

Epoch: 6| Step: 9
Training loss: 3.6693646879445994
Validation loss: 3.632970750431442

Epoch: 6| Step: 10
Training loss: 3.5365888358950133
Validation loss: 3.628528697148792

Epoch: 6| Step: 11
Training loss: 4.415711113588826
Validation loss: 3.6238358480849486

Epoch: 6| Step: 12
Training loss: 3.656776846724213
Validation loss: 3.61904292790508

Epoch: 6| Step: 13
Training loss: 3.7971807914010953
Validation loss: 3.614581054041837

Epoch: 33| Step: 0
Training loss: 2.9581930279480724
Validation loss: 3.609793194300652

Epoch: 6| Step: 1
Training loss: 4.13703711187892
Validation loss: 3.60514442690678

Epoch: 6| Step: 2
Training loss: 3.7469363095419266
Validation loss: 3.6004186483956855

Epoch: 6| Step: 3
Training loss: 3.905436194525118
Validation loss: 3.595775575199732

Epoch: 6| Step: 4
Training loss: 4.069907609420483
Validation loss: 3.591102963146271

Epoch: 6| Step: 5
Training loss: 2.6030868325978744
Validation loss: 3.5862385187843926

Epoch: 6| Step: 6
Training loss: 3.6606619535420575
Validation loss: 3.58192473086436

Epoch: 6| Step: 7
Training loss: 3.71323530833667
Validation loss: 3.577605452708307

Epoch: 6| Step: 8
Training loss: 3.944083870419631
Validation loss: 3.5730515316495337

Epoch: 6| Step: 9
Training loss: 3.9185427913609736
Validation loss: 3.568177790511582

Epoch: 6| Step: 10
Training loss: 3.3895076193830085
Validation loss: 3.563381153020151

Epoch: 6| Step: 11
Training loss: 3.9879238704581392
Validation loss: 3.5589889714469503

Epoch: 6| Step: 12
Training loss: 4.4216015195354945
Validation loss: 3.5542685908154934

Epoch: 6| Step: 13
Training loss: 3.144501528392147
Validation loss: 3.549551851345149

Epoch: 34| Step: 0
Training loss: 4.095540594205979
Validation loss: 3.54489879478038

Epoch: 6| Step: 1
Training loss: 3.212987240901039
Validation loss: 3.5400585824713264

Epoch: 6| Step: 2
Training loss: 3.348064028320237
Validation loss: 3.535569668757719

Epoch: 6| Step: 3
Training loss: 3.7640496595392494
Validation loss: 3.531300749737588

Epoch: 6| Step: 4
Training loss: 4.1665711709841196
Validation loss: 3.526585223826565

Epoch: 6| Step: 5
Training loss: 3.3137531429291696
Validation loss: 3.521734160050178

Epoch: 6| Step: 6
Training loss: 2.935712554581085
Validation loss: 3.517285690846325

Epoch: 6| Step: 7
Training loss: 3.638169537042114
Validation loss: 3.5126726879599914

Epoch: 6| Step: 8
Training loss: 4.439646886582205
Validation loss: 3.508727115148322

Epoch: 6| Step: 9
Training loss: 4.247555646885473
Validation loss: 3.50369783743495

Epoch: 6| Step: 10
Training loss: 3.090465458993979
Validation loss: 3.4992814802420926

Epoch: 6| Step: 11
Training loss: 3.1071293835277354
Validation loss: 3.4943488911709926

Epoch: 6| Step: 12
Training loss: 3.5221594545833304
Validation loss: 3.4897196880668995

Epoch: 6| Step: 13
Training loss: 3.855354222352282
Validation loss: 3.485373497920023

Epoch: 35| Step: 0
Training loss: 3.0389939327399094
Validation loss: 3.4808393824071717

Epoch: 6| Step: 1
Training loss: 3.9791428863187623
Validation loss: 3.4763294841957078

Epoch: 6| Step: 2
Training loss: 3.293268916340491
Validation loss: 3.472165576896618

Epoch: 6| Step: 3
Training loss: 3.9951155165298387
Validation loss: 3.4677368150669916

Epoch: 6| Step: 4
Training loss: 3.684673583895979
Validation loss: 3.463245847684438

Epoch: 6| Step: 5
Training loss: 4.129665395191857
Validation loss: 3.4591079824811075

Epoch: 6| Step: 6
Training loss: 3.597404015528412
Validation loss: 3.4543890962358534

Epoch: 6| Step: 7
Training loss: 3.195612289430292
Validation loss: 3.4495372286773254

Epoch: 6| Step: 8
Training loss: 3.9415706604011373
Validation loss: 3.4452017076458623

Epoch: 6| Step: 9
Training loss: 3.7105687008352457
Validation loss: 3.440876660568855

Epoch: 6| Step: 10
Training loss: 3.84855066737855
Validation loss: 3.4361001025240867

Epoch: 6| Step: 11
Training loss: 3.212457672909004
Validation loss: 3.431114044923906

Epoch: 6| Step: 12
Training loss: 2.9611289734944775
Validation loss: 3.426255764896665

Epoch: 6| Step: 13
Training loss: 3.4294610089917663
Validation loss: 3.4221461288825976

Epoch: 36| Step: 0
Training loss: 3.4809000109848904
Validation loss: 3.418218671108448

Epoch: 6| Step: 1
Training loss: 3.241556496860554
Validation loss: 3.41383816166033

Epoch: 6| Step: 2
Training loss: 3.5843971950173086
Validation loss: 3.4096914282653685

Epoch: 6| Step: 3
Training loss: 3.6496224613112274
Validation loss: 3.4054690991190224

Epoch: 6| Step: 4
Training loss: 3.7888753628481573
Validation loss: 3.4012375911966224

Epoch: 6| Step: 5
Training loss: 4.107127920561932
Validation loss: 3.396885484610821

Epoch: 6| Step: 6
Training loss: 3.9515498344004216
Validation loss: 3.392682015529021

Epoch: 6| Step: 7
Training loss: 4.138167202447256
Validation loss: 3.3881711269218386

Epoch: 6| Step: 8
Training loss: 2.7391170689945823
Validation loss: 3.3836392162588567

Epoch: 6| Step: 9
Training loss: 3.678941525532992
Validation loss: 3.3795134188114773

Epoch: 6| Step: 10
Training loss: 3.9356956586330214
Validation loss: 3.374766636068446

Epoch: 6| Step: 11
Training loss: 2.8795561141097146
Validation loss: 3.3706204055159708

Epoch: 6| Step: 12
Training loss: 2.524422656990931
Validation loss: 3.366364392474578

Epoch: 6| Step: 13
Training loss: 3.2571160100246335
Validation loss: 3.362115779891439

Epoch: 37| Step: 0
Training loss: 3.459244772674786
Validation loss: 3.358370963580738

Epoch: 6| Step: 1
Training loss: 3.187481749239264
Validation loss: 3.3539399648944905

Epoch: 6| Step: 2
Training loss: 3.496445349376529
Validation loss: 3.350053354094642

Epoch: 6| Step: 3
Training loss: 3.314851753752048
Validation loss: 3.3461295362944803

Epoch: 6| Step: 4
Training loss: 4.249844940947225
Validation loss: 3.3423341980172108

Epoch: 6| Step: 5
Training loss: 3.8559048144198544
Validation loss: 3.3376785963947495

Epoch: 6| Step: 6
Training loss: 3.3648897549168146
Validation loss: 3.333526645459118

Epoch: 6| Step: 7
Training loss: 3.257886268274526
Validation loss: 3.3293465773787916

Epoch: 6| Step: 8
Training loss: 3.2266430417554233
Validation loss: 3.325125570961608

Epoch: 6| Step: 9
Training loss: 3.6051207733029
Validation loss: 3.3210884892851182

Epoch: 6| Step: 10
Training loss: 3.5130383279231427
Validation loss: 3.3168381648237326

Epoch: 6| Step: 11
Training loss: 3.377900325562617
Validation loss: 3.3124253846407865

Epoch: 6| Step: 12
Training loss: 3.669309848264826
Validation loss: 3.3086136145898037

Epoch: 6| Step: 13
Training loss: 2.8250989373360547
Validation loss: 3.3045862060606215

Epoch: 38| Step: 0
Training loss: 2.7987592945566413
Validation loss: 3.300499657652333

Epoch: 6| Step: 1
Training loss: 3.976666102530564
Validation loss: 3.2968337069994393

Epoch: 6| Step: 2
Training loss: 3.564336738253976
Validation loss: 3.29284140392278

Epoch: 6| Step: 3
Training loss: 3.5475823457501208
Validation loss: 3.2888579557943087

Epoch: 6| Step: 4
Training loss: 3.312574709643575
Validation loss: 3.2844338607474173

Epoch: 6| Step: 5
Training loss: 2.960145064227348
Validation loss: 3.279527363374483

Epoch: 6| Step: 6
Training loss: 2.827477987053648
Validation loss: 3.276230233026202

Epoch: 6| Step: 7
Training loss: 3.399421496822882
Validation loss: 3.2723610381873547

Epoch: 6| Step: 8
Training loss: 3.557970614264229
Validation loss: 3.268852938313089

Epoch: 6| Step: 9
Training loss: 2.7850900778593806
Validation loss: 3.265234672910547

Epoch: 6| Step: 10
Training loss: 3.746639144384586
Validation loss: 3.2613562589982243

Epoch: 6| Step: 11
Training loss: 3.358724415791345
Validation loss: 3.257788398098545

Epoch: 6| Step: 12
Training loss: 3.9863604217671345
Validation loss: 3.253792115431209

Epoch: 6| Step: 13
Training loss: 3.67343586962626
Validation loss: 3.2497834598100077

Epoch: 39| Step: 0
Training loss: 3.042129185318003
Validation loss: 3.2454438306780387

Epoch: 6| Step: 1
Training loss: 2.7015195279429647
Validation loss: 3.2419296836224643

Epoch: 6| Step: 2
Training loss: 2.993234157519375
Validation loss: 3.2384103366598884

Epoch: 6| Step: 3
Training loss: 3.350668621238243
Validation loss: 3.2343890793351093

Epoch: 6| Step: 4
Training loss: 3.61180686768926
Validation loss: 3.2312558624785

Epoch: 6| Step: 5
Training loss: 3.2392494217652104
Validation loss: 3.2283200456473486

Epoch: 6| Step: 6
Training loss: 3.248649610059606
Validation loss: 3.224577951538101

Epoch: 6| Step: 7
Training loss: 3.4341069902250423
Validation loss: 3.220974718143285

Epoch: 6| Step: 8
Training loss: 3.3516512772333114
Validation loss: 3.217078926338017

Epoch: 6| Step: 9
Training loss: 3.204536238754863
Validation loss: 3.213719977692762

Epoch: 6| Step: 10
Training loss: 3.9913687566286833
Validation loss: 3.210102675074342

Epoch: 6| Step: 11
Training loss: 3.564925589406855
Validation loss: 3.205920232578891

Epoch: 6| Step: 12
Training loss: 3.8269624151413217
Validation loss: 3.2016308905174564

Epoch: 6| Step: 13
Training loss: 3.260162603617551
Validation loss: 3.1986141044885015

Epoch: 40| Step: 0
Training loss: 3.0329951345805286
Validation loss: 3.194668009209497

Epoch: 6| Step: 1
Training loss: 2.87052602539597
Validation loss: 3.1894210935293534

Epoch: 6| Step: 2
Training loss: 3.5637887330293574
Validation loss: 3.186811509917337

Epoch: 6| Step: 3
Training loss: 3.9120698832567364
Validation loss: 3.182690938239631

Epoch: 6| Step: 4
Training loss: 3.430850724577789
Validation loss: 3.1792738736843043

Epoch: 6| Step: 5
Training loss: 3.1517369703833085
Validation loss: 3.17441490969925

Epoch: 6| Step: 6
Training loss: 3.330835232849063
Validation loss: 3.1699353631265974

Epoch: 6| Step: 7
Training loss: 3.8306623496688417
Validation loss: 3.1662839524408635

Epoch: 6| Step: 8
Training loss: 3.6648099417540996
Validation loss: 3.1638536925940284

Epoch: 6| Step: 9
Training loss: 3.002751677904811
Validation loss: 3.159072143044878

Epoch: 6| Step: 10
Training loss: 2.6290684008081513
Validation loss: 3.155503238175629

Epoch: 6| Step: 11
Training loss: 3.1899995166455324
Validation loss: 3.151311554923547

Epoch: 6| Step: 12
Training loss: 2.919509338019023
Validation loss: 3.1473425640619146

Epoch: 6| Step: 13
Training loss: 3.5270762125579163
Validation loss: 3.1440686503632875

Epoch: 41| Step: 0
Training loss: 3.399091004426341
Validation loss: 3.142057165031762

Epoch: 6| Step: 1
Training loss: 3.3837742660661343
Validation loss: 3.141240276337306

Epoch: 6| Step: 2
Training loss: 3.509555850714889
Validation loss: 3.136989811404148

Epoch: 6| Step: 3
Training loss: 3.3511074797658136
Validation loss: 3.1317254746704655

Epoch: 6| Step: 4
Training loss: 3.5236900222182803
Validation loss: 3.1270545944597727

Epoch: 6| Step: 5
Training loss: 3.1390115569534784
Validation loss: 3.1228212772499124

Epoch: 6| Step: 6
Training loss: 2.604691556802667
Validation loss: 3.1190528737852095

Epoch: 6| Step: 7
Training loss: 2.9958944838803854
Validation loss: 3.116332661144078

Epoch: 6| Step: 8
Training loss: 2.977054264966901
Validation loss: 3.1160295418313013

Epoch: 6| Step: 9
Training loss: 3.3673242952744986
Validation loss: 3.1367368780731026

Epoch: 6| Step: 10
Training loss: 3.6534860711527193
Validation loss: 3.106019911249241

Epoch: 6| Step: 11
Training loss: 3.004279263556006
Validation loss: 3.10322760559277

Epoch: 6| Step: 12
Training loss: 3.6753980252376612
Validation loss: 3.103426766168781

Epoch: 6| Step: 13
Training loss: 2.923398523361398
Validation loss: 3.1061847621071808

Epoch: 42| Step: 0
Training loss: 3.0028120213227454
Validation loss: 3.10432338105662

Epoch: 6| Step: 1
Training loss: 3.522763612845015
Validation loss: 3.0977215946420005

Epoch: 6| Step: 2
Training loss: 2.9019397233609143
Validation loss: 3.09110428167031

Epoch: 6| Step: 3
Training loss: 3.59038724718056
Validation loss: 3.0878263334513854

Epoch: 6| Step: 4
Training loss: 3.4686567964146406
Validation loss: 3.0842776441942843

Epoch: 6| Step: 5
Training loss: 3.051991709786651
Validation loss: 3.0812951172987506

Epoch: 6| Step: 6
Training loss: 3.049747306486695
Validation loss: 3.0782764997814027

Epoch: 6| Step: 7
Training loss: 3.144588266175642
Validation loss: 3.0770796599954844

Epoch: 6| Step: 8
Training loss: 3.2688617636134842
Validation loss: 3.072318653603726

Epoch: 6| Step: 9
Training loss: 3.1829217681331197
Validation loss: 3.06568560059172

Epoch: 6| Step: 10
Training loss: 3.3952126120959565
Validation loss: 3.0621348312545464

Epoch: 6| Step: 11
Training loss: 2.6780139379273957
Validation loss: 3.05756729590487

Epoch: 6| Step: 12
Training loss: 2.8808838717178826
Validation loss: 3.054669314279107

Epoch: 6| Step: 13
Training loss: 3.729291576374941
Validation loss: 3.0527884978257624

Epoch: 43| Step: 0
Training loss: 3.3319193384085897
Validation loss: 3.0506277595230875

Epoch: 6| Step: 1
Training loss: 2.9013895388948883
Validation loss: 3.046647335578253

Epoch: 6| Step: 2
Training loss: 3.146408904181014
Validation loss: 3.0419595307403062

Epoch: 6| Step: 3
Training loss: 3.1848603332653735
Validation loss: 3.0384272129567758

Epoch: 6| Step: 4
Training loss: 3.1577712821252337
Validation loss: 3.0351081494120637

Epoch: 6| Step: 5
Training loss: 3.1595711938630777
Validation loss: 3.031725528293123

Epoch: 6| Step: 6
Training loss: 2.4154021363882143
Validation loss: 3.0293492391173205

Epoch: 6| Step: 7
Training loss: 3.033498657528071
Validation loss: 3.0259985119122

Epoch: 6| Step: 8
Training loss: 3.571865286692898
Validation loss: 3.023281333235015

Epoch: 6| Step: 9
Training loss: 3.2618683009783283
Validation loss: 3.022178210221624

Epoch: 6| Step: 10
Training loss: 3.1518139778083363
Validation loss: 3.018656483446284

Epoch: 6| Step: 11
Training loss: 3.5761800085670066
Validation loss: 3.013862068205378

Epoch: 6| Step: 12
Training loss: 2.494686201463906
Validation loss: 3.0107461073680084

Epoch: 6| Step: 13
Training loss: 3.690322959226739
Validation loss: 3.0084451645823207

Epoch: 44| Step: 0
Training loss: 3.2363505204415217
Validation loss: 3.0047645880321787

Epoch: 6| Step: 1
Training loss: 3.6002260984839656
Validation loss: 3.0020521747808457

Epoch: 6| Step: 2
Training loss: 3.113368551257932
Validation loss: 2.999116250840657

Epoch: 6| Step: 3
Training loss: 3.091052025279717
Validation loss: 2.996385980352425

Epoch: 6| Step: 4
Training loss: 3.971081627004169
Validation loss: 2.9936913943145687

Epoch: 6| Step: 5
Training loss: 3.2235106289325786
Validation loss: 2.990274294091126

Epoch: 6| Step: 6
Training loss: 2.8252356506906806
Validation loss: 2.9867551675808586

Epoch: 6| Step: 7
Training loss: 3.1855158894971423
Validation loss: 2.9834242766031887

Epoch: 6| Step: 8
Training loss: 2.7477982116417965
Validation loss: 2.9797277833575677

Epoch: 6| Step: 9
Training loss: 2.9120347072922415
Validation loss: 2.977307003758414

Epoch: 6| Step: 10
Training loss: 2.7003860268318474
Validation loss: 2.9751937001745534

Epoch: 6| Step: 11
Training loss: 2.483229655036626
Validation loss: 2.9756070102788037

Epoch: 6| Step: 12
Training loss: 3.18261823627821
Validation loss: 2.968191877404095

Epoch: 6| Step: 13
Training loss: 3.2523871238174937
Validation loss: 2.9658595955409353

Epoch: 45| Step: 0
Training loss: 2.760660834879804
Validation loss: 2.961642769298696

Epoch: 6| Step: 1
Training loss: 3.4535593993768825
Validation loss: 2.9605453620729274

Epoch: 6| Step: 2
Training loss: 3.1376386269875716
Validation loss: 2.958680083320778

Epoch: 6| Step: 3
Training loss: 3.2328977297964814
Validation loss: 2.95556695747885

Epoch: 6| Step: 4
Training loss: 3.190434619630026
Validation loss: 2.954344011766579

Epoch: 6| Step: 5
Training loss: 3.3315223224687274
Validation loss: 2.9522487679275775

Epoch: 6| Step: 6
Training loss: 2.9538812224128184
Validation loss: 2.949388659974342

Epoch: 6| Step: 7
Training loss: 3.2328176388669734
Validation loss: 2.9470151369681026

Epoch: 6| Step: 8
Training loss: 2.8451807803355003
Validation loss: 2.9448555238535987

Epoch: 6| Step: 9
Training loss: 2.855227605027955
Validation loss: 2.9406435223711234

Epoch: 6| Step: 10
Training loss: 3.187745627120762
Validation loss: 2.936851335154018

Epoch: 6| Step: 11
Training loss: 2.5527991919252937
Validation loss: 2.93483518567701

Epoch: 6| Step: 12
Training loss: 3.2285187266035464
Validation loss: 2.9313457356797077

Epoch: 6| Step: 13
Training loss: 3.153169091391816
Validation loss: 2.927821074311818

Epoch: 46| Step: 0
Training loss: 2.480238343598927
Validation loss: 2.925372948739375

Epoch: 6| Step: 1
Training loss: 3.0873921116809138
Validation loss: 2.923270437991436

Epoch: 6| Step: 2
Training loss: 3.623019104720054
Validation loss: 2.923123397277519

Epoch: 6| Step: 3
Training loss: 3.390760709094691
Validation loss: 2.919290701906013

Epoch: 6| Step: 4
Training loss: 3.260938576230656
Validation loss: 2.9142728155226427

Epoch: 6| Step: 5
Training loss: 2.191594895999575
Validation loss: 2.9110773254655187

Epoch: 6| Step: 6
Training loss: 3.1854001776844596
Validation loss: 2.908100455141118

Epoch: 6| Step: 7
Training loss: 2.9251207897318503
Validation loss: 2.9056358372100606

Epoch: 6| Step: 8
Training loss: 2.6687402908184317
Validation loss: 2.9056311601373963

Epoch: 6| Step: 9
Training loss: 2.696283933861928
Validation loss: 2.902644706993754

Epoch: 6| Step: 10
Training loss: 3.4058232871339045
Validation loss: 2.901303405642718

Epoch: 6| Step: 11
Training loss: 3.06517565872621
Validation loss: 2.8982126126439693

Epoch: 6| Step: 12
Training loss: 3.1184177504557375
Validation loss: 2.8937070894183776

Epoch: 6| Step: 13
Training loss: 3.2701755194265103
Validation loss: 2.8915636205497552

Epoch: 47| Step: 0
Training loss: 2.872053709893359
Validation loss: 2.889880522663907

Epoch: 6| Step: 1
Training loss: 2.9295833314814157
Validation loss: 2.887029318821509

Epoch: 6| Step: 2
Training loss: 2.581998746958812
Validation loss: 2.8836801217482213

Epoch: 6| Step: 3
Training loss: 3.2863188329592723
Validation loss: 2.881248525424671

Epoch: 6| Step: 4
Training loss: 3.01003114196281
Validation loss: 2.8790666595034757

Epoch: 6| Step: 5
Training loss: 3.1097313758162985
Validation loss: 2.8742730562319942

Epoch: 6| Step: 6
Training loss: 3.1132798715394534
Validation loss: 2.874355465056103

Epoch: 6| Step: 7
Training loss: 3.147329888144026
Validation loss: 2.8701916304577155

Epoch: 6| Step: 8
Training loss: 3.0085264473288817
Validation loss: 2.8664212567239913

Epoch: 6| Step: 9
Training loss: 2.5628793947299107
Validation loss: 2.862925161690439

Epoch: 6| Step: 10
Training loss: 3.0331971511732867
Validation loss: 2.8609119724570258

Epoch: 6| Step: 11
Training loss: 3.4216612309262344
Validation loss: 2.859206634178392

Epoch: 6| Step: 12
Training loss: 2.745195526774843
Validation loss: 2.858558315805689

Epoch: 6| Step: 13
Training loss: 3.229311310184563
Validation loss: 2.858904134478515

Epoch: 48| Step: 0
Training loss: 3.147617129084888
Validation loss: 2.85328272661745

Epoch: 6| Step: 1
Training loss: 3.2812873474902067
Validation loss: 2.8507705215749843

Epoch: 6| Step: 2
Training loss: 2.964182663142343
Validation loss: 2.854478893233846

Epoch: 6| Step: 3
Training loss: 2.3506966958222217
Validation loss: 2.8574754558275637

Epoch: 6| Step: 4
Training loss: 3.3793135028236447
Validation loss: 2.8671977556618637

Epoch: 6| Step: 5
Training loss: 3.0929575203742057
Validation loss: 2.842400171097631

Epoch: 6| Step: 6
Training loss: 3.1029035998266035
Validation loss: 2.841644961217354

Epoch: 6| Step: 7
Training loss: 2.920184457256818
Validation loss: 2.8403594096753295

Epoch: 6| Step: 8
Training loss: 2.109260725528747
Validation loss: 2.83784136518278

Epoch: 6| Step: 9
Training loss: 3.369847638678959
Validation loss: 2.8385962991385787

Epoch: 6| Step: 10
Training loss: 2.703814115500398
Validation loss: 2.8393462321163176

Epoch: 6| Step: 11
Training loss: 2.953603070027501
Validation loss: 2.8381408875101988

Epoch: 6| Step: 12
Training loss: 3.0610776439790386
Validation loss: 2.8338093264303508

Epoch: 6| Step: 13
Training loss: 3.022395148971001
Validation loss: 2.832235983978968

Epoch: 49| Step: 0
Training loss: 2.8985992139754813
Validation loss: 2.831044441266887

Epoch: 6| Step: 1
Training loss: 3.1547440061378507
Validation loss: 2.829749411866345

Epoch: 6| Step: 2
Training loss: 3.019183969205054
Validation loss: 2.8277234517741188

Epoch: 6| Step: 3
Training loss: 2.84978607445647
Validation loss: 2.823653055873877

Epoch: 6| Step: 4
Training loss: 3.479511784475055
Validation loss: 2.817847995270084

Epoch: 6| Step: 5
Training loss: 2.9073771270215407
Validation loss: 2.8161301250430038

Epoch: 6| Step: 6
Training loss: 2.789967280643805
Validation loss: 2.813738091250277

Epoch: 6| Step: 7
Training loss: 3.054992192284929
Validation loss: 2.814768025070252

Epoch: 6| Step: 8
Training loss: 2.9486735060967058
Validation loss: 2.81768823265103

Epoch: 6| Step: 9
Training loss: 3.287391074809225
Validation loss: 2.8097836976159765

Epoch: 6| Step: 10
Training loss: 3.260285314934543
Validation loss: 2.8015808921844254

Epoch: 6| Step: 11
Training loss: 2.4822537945286056
Validation loss: 2.801231713383531

Epoch: 6| Step: 12
Training loss: 2.3949081846090716
Validation loss: 2.799576248733028

Epoch: 6| Step: 13
Training loss: 2.686597362015678
Validation loss: 2.7971038582651726

Epoch: 50| Step: 0
Training loss: 2.728247179439418
Validation loss: 2.795841999485856

Epoch: 6| Step: 1
Training loss: 3.095272421733844
Validation loss: 2.7964732984485203

Epoch: 6| Step: 2
Training loss: 3.5579505112944325
Validation loss: 2.7966428124005707

Epoch: 6| Step: 3
Training loss: 2.88851835450318
Validation loss: 2.795967764732734

Epoch: 6| Step: 4
Training loss: 3.1119720501465875
Validation loss: 2.795317061427464

Epoch: 6| Step: 5
Training loss: 2.8190222665774085
Validation loss: 2.793439264390457

Epoch: 6| Step: 6
Training loss: 2.4575487813832746
Validation loss: 2.790390752662821

Epoch: 6| Step: 7
Training loss: 2.439192160093145
Validation loss: 2.786481345013345

Epoch: 6| Step: 8
Training loss: 3.120779926435564
Validation loss: 2.7831629628635524

Epoch: 6| Step: 9
Training loss: 3.0575948864864624
Validation loss: 2.7812498428401833

Epoch: 6| Step: 10
Training loss: 3.331778656484867
Validation loss: 2.7804528997930045

Epoch: 6| Step: 11
Training loss: 3.0801315351365557
Validation loss: 2.7764695191508078

Epoch: 6| Step: 12
Training loss: 2.496740600635471
Validation loss: 2.7719663058054715

Epoch: 6| Step: 13
Training loss: 2.587117274630992
Validation loss: 2.7708747306159682

Epoch: 51| Step: 0
Training loss: 3.051754531248236
Validation loss: 2.7701418785915743

Epoch: 6| Step: 1
Training loss: 2.8346674153185503
Validation loss: 2.765482049325911

Epoch: 6| Step: 2
Training loss: 3.191234121735126
Validation loss: 2.7645679041286524

Epoch: 6| Step: 3
Training loss: 3.303615820155639
Validation loss: 2.7650864933551107

Epoch: 6| Step: 4
Training loss: 2.8001043334323614
Validation loss: 2.765642097836964

Epoch: 6| Step: 5
Training loss: 2.7561185567571957
Validation loss: 2.7684821332947838

Epoch: 6| Step: 6
Training loss: 3.127686985686408
Validation loss: 2.7711266288316043

Epoch: 6| Step: 7
Training loss: 3.374945039654856
Validation loss: 2.7695974925825952

Epoch: 6| Step: 8
Training loss: 2.5014665117021817
Validation loss: 2.767002157950562

Epoch: 6| Step: 9
Training loss: 2.7862740904364296
Validation loss: 2.7620375906466923

Epoch: 6| Step: 10
Training loss: 3.202092297321613
Validation loss: 2.7570448429287477

Epoch: 6| Step: 11
Training loss: 2.584250922955081
Validation loss: 2.754222720023516

Epoch: 6| Step: 12
Training loss: 2.6933738038670345
Validation loss: 2.750933156490887

Epoch: 6| Step: 13
Training loss: 2.2969770343979308
Validation loss: 2.747848825337887

Epoch: 52| Step: 0
Training loss: 2.894925439431165
Validation loss: 2.7466121381451756

Epoch: 6| Step: 1
Training loss: 3.248569320345397
Validation loss: 2.7444729025734245

Epoch: 6| Step: 2
Training loss: 3.1916689070120206
Validation loss: 2.7402669587920423

Epoch: 6| Step: 3
Training loss: 2.775160563179764
Validation loss: 2.7397033945519405

Epoch: 6| Step: 4
Training loss: 2.260004161223235
Validation loss: 2.74021031755911

Epoch: 6| Step: 5
Training loss: 2.9195199543094135
Validation loss: 2.739110395756624

Epoch: 6| Step: 6
Training loss: 2.7289159722732443
Validation loss: 2.7400712617020986

Epoch: 6| Step: 7
Training loss: 2.5130300465680095
Validation loss: 2.732603229342277

Epoch: 6| Step: 8
Training loss: 2.916990062405068
Validation loss: 2.7304324837578733

Epoch: 6| Step: 9
Training loss: 2.8768712463951114
Validation loss: 2.7289791091262843

Epoch: 6| Step: 10
Training loss: 3.283105961112448
Validation loss: 2.7282596905913525

Epoch: 6| Step: 11
Training loss: 2.4307754877282934
Validation loss: 2.7285123773626956

Epoch: 6| Step: 12
Training loss: 3.3205309268686993
Validation loss: 2.7285761934555968

Epoch: 6| Step: 13
Training loss: 2.7111552478067282
Validation loss: 2.7275044618518205

Epoch: 53| Step: 0
Training loss: 3.4832745512119905
Validation loss: 2.7299110814519723

Epoch: 6| Step: 1
Training loss: 3.0708709286614515
Validation loss: 2.729763640324629

Epoch: 6| Step: 2
Training loss: 2.959935967551804
Validation loss: 2.7298273107152218

Epoch: 6| Step: 3
Training loss: 3.1947764201132633
Validation loss: 2.730127738064818

Epoch: 6| Step: 4
Training loss: 3.183548815825531
Validation loss: 2.7288843596146792

Epoch: 6| Step: 5
Training loss: 3.0082696740626105
Validation loss: 2.7272236923183075

Epoch: 6| Step: 6
Training loss: 2.394122787411626
Validation loss: 2.7218183544409302

Epoch: 6| Step: 7
Training loss: 2.4979691840073786
Validation loss: 2.7204528678892155

Epoch: 6| Step: 8
Training loss: 2.756098141455059
Validation loss: 2.7175780214762315

Epoch: 6| Step: 9
Training loss: 2.8599187615334114
Validation loss: 2.715898523869978

Epoch: 6| Step: 10
Training loss: 2.251687794362
Validation loss: 2.715053178864738

Epoch: 6| Step: 11
Training loss: 2.8281926099588546
Validation loss: 2.7091359098627197

Epoch: 6| Step: 12
Training loss: 2.61973370487312
Validation loss: 2.7087725992261964

Epoch: 6| Step: 13
Training loss: 2.692120771416893
Validation loss: 2.705245228367563

Epoch: 54| Step: 0
Training loss: 2.560104739311483
Validation loss: 2.702908913385773

Epoch: 6| Step: 1
Training loss: 2.027279773797884
Validation loss: 2.699849785052295

Epoch: 6| Step: 2
Training loss: 3.323389256911399
Validation loss: 2.6995280447898167

Epoch: 6| Step: 3
Training loss: 3.2999788110226165
Validation loss: 2.6983661988982006

Epoch: 6| Step: 4
Training loss: 3.0950408708526833
Validation loss: 2.698279254560701

Epoch: 6| Step: 5
Training loss: 2.682724013560577
Validation loss: 2.701742741264607

Epoch: 6| Step: 6
Training loss: 2.6971473529803602
Validation loss: 2.6976601958648754

Epoch: 6| Step: 7
Training loss: 2.1600438894122065
Validation loss: 2.703037414895862

Epoch: 6| Step: 8
Training loss: 2.230544855586456
Validation loss: 2.690006802111869

Epoch: 6| Step: 9
Training loss: 2.7284511375588876
Validation loss: 2.691687744065974

Epoch: 6| Step: 10
Training loss: 3.2531061734434368
Validation loss: 2.689154950772363

Epoch: 6| Step: 11
Training loss: 3.0474929574160607
Validation loss: 2.689150872441751

Epoch: 6| Step: 12
Training loss: 3.3652365004255476
Validation loss: 2.686397962322034

Epoch: 6| Step: 13
Training loss: 2.7485358068289556
Validation loss: 2.6854746675898706

Epoch: 55| Step: 0
Training loss: 2.78853544496496
Validation loss: 2.679196771558364

Epoch: 6| Step: 1
Training loss: 2.492507770491782
Validation loss: 2.6809077918143807

Epoch: 6| Step: 2
Training loss: 2.9682534856693064
Validation loss: 2.67821286390074

Epoch: 6| Step: 3
Training loss: 2.3576029002445895
Validation loss: 2.6797515446282136

Epoch: 6| Step: 4
Training loss: 3.234578738959723
Validation loss: 2.6785897841657196

Epoch: 6| Step: 5
Training loss: 3.134170656398623
Validation loss: 2.6762651511768194

Epoch: 6| Step: 6
Training loss: 2.597025354396012
Validation loss: 2.6823251567836204

Epoch: 6| Step: 7
Training loss: 3.045763018240462
Validation loss: 2.6933664271553037

Epoch: 6| Step: 8
Training loss: 2.810790750554388
Validation loss: 2.6986336706525997

Epoch: 6| Step: 9
Training loss: 2.6965201947859896
Validation loss: 2.6844375520167523

Epoch: 6| Step: 10
Training loss: 3.071574410432813
Validation loss: 2.671554040500147

Epoch: 6| Step: 11
Training loss: 2.705505469544211
Validation loss: 2.6692511035221043

Epoch: 6| Step: 12
Training loss: 3.051186040186841
Validation loss: 2.6711789092578346

Epoch: 6| Step: 13
Training loss: 2.3359734267722176
Validation loss: 2.6707819511680313

Epoch: 56| Step: 0
Training loss: 2.696817790426929
Validation loss: 2.6708953727225713

Epoch: 6| Step: 1
Training loss: 2.951266395171082
Validation loss: 2.672128364195051

Epoch: 6| Step: 2
Training loss: 2.5801466904567465
Validation loss: 2.6729026290592337

Epoch: 6| Step: 3
Training loss: 2.7716866137837584
Validation loss: 2.67457794829151

Epoch: 6| Step: 4
Training loss: 3.1918897134185187
Validation loss: 2.6775002408495028

Epoch: 6| Step: 5
Training loss: 2.5911359368267877
Validation loss: 2.6787535853739453

Epoch: 6| Step: 6
Training loss: 3.4898914409903155
Validation loss: 2.6786409341786

Epoch: 6| Step: 7
Training loss: 2.639828533615327
Validation loss: 2.6770861485883306

Epoch: 6| Step: 8
Training loss: 2.5242922253601447
Validation loss: 2.673936104666602

Epoch: 6| Step: 9
Training loss: 2.7189846595255647
Validation loss: 2.6715149664769293

Epoch: 6| Step: 10
Training loss: 2.5390000555722807
Validation loss: 2.6665150082695925

Epoch: 6| Step: 11
Training loss: 3.0218574278832424
Validation loss: 2.664751263999287

Epoch: 6| Step: 12
Training loss: 2.567277966401145
Validation loss: 2.660430804408981

Epoch: 6| Step: 13
Training loss: 2.871432371347132
Validation loss: 2.6565946318011413

Epoch: 57| Step: 0
Training loss: 2.730165740351233
Validation loss: 2.6570788118913082

Epoch: 6| Step: 1
Training loss: 3.005903792719252
Validation loss: 2.6543297502448087

Epoch: 6| Step: 2
Training loss: 2.455264573767411
Validation loss: 2.6538132804073533

Epoch: 6| Step: 3
Training loss: 3.0559060868617594
Validation loss: 2.650289422550849

Epoch: 6| Step: 4
Training loss: 3.0122753771855
Validation loss: 2.64373293932016

Epoch: 6| Step: 5
Training loss: 2.641696689888373
Validation loss: 2.64557954867671

Epoch: 6| Step: 6
Training loss: 2.1389894571922827
Validation loss: 2.6433279134912073

Epoch: 6| Step: 7
Training loss: 3.0133652200390215
Validation loss: 2.6407168069564055

Epoch: 6| Step: 8
Training loss: 3.165198303566985
Validation loss: 2.6393711491553

Epoch: 6| Step: 9
Training loss: 2.35945078747018
Validation loss: 2.642049251092524

Epoch: 6| Step: 10
Training loss: 2.424666045485214
Validation loss: 2.640988597629078

Epoch: 6| Step: 11
Training loss: 2.9255312314945803
Validation loss: 2.637985565662781

Epoch: 6| Step: 12
Training loss: 3.0310061641820476
Validation loss: 2.6331292857012913

Epoch: 6| Step: 13
Training loss: 2.7453818124131577
Validation loss: 2.634798140686902

Epoch: 58| Step: 0
Training loss: 2.9653046542480053
Validation loss: 2.6299017145190797

Epoch: 6| Step: 1
Training loss: 2.795263582743008
Validation loss: 2.6335051820509796

Epoch: 6| Step: 2
Training loss: 2.5129013955519803
Validation loss: 2.6305276708345735

Epoch: 6| Step: 3
Training loss: 2.6986869586262094
Validation loss: 2.6329060206796946

Epoch: 6| Step: 4
Training loss: 3.1822878540482393
Validation loss: 2.6312282636866717

Epoch: 6| Step: 5
Training loss: 2.6261648590797626
Validation loss: 2.6298877079999925

Epoch: 6| Step: 6
Training loss: 2.729774485066275
Validation loss: 2.6267831891576794

Epoch: 6| Step: 7
Training loss: 2.5828239389894336
Validation loss: 2.6246649967353335

Epoch: 6| Step: 8
Training loss: 2.8912352871386484
Validation loss: 2.623523281649642

Epoch: 6| Step: 9
Training loss: 2.799296093063073
Validation loss: 2.624567965119186

Epoch: 6| Step: 10
Training loss: 2.830766487518946
Validation loss: 2.627685596022203

Epoch: 6| Step: 11
Training loss: 2.8151409888998513
Validation loss: 2.6334981355725096

Epoch: 6| Step: 12
Training loss: 2.359945872381154
Validation loss: 2.629026367708225

Epoch: 6| Step: 13
Training loss: 2.842987293624258
Validation loss: 2.6218192493572183

Epoch: 59| Step: 0
Training loss: 2.778517420100599
Validation loss: 2.6222408871426435

Epoch: 6| Step: 1
Training loss: 2.640098203219729
Validation loss: 2.618670765384424

Epoch: 6| Step: 2
Training loss: 2.7068453197838247
Validation loss: 2.6156881715961546

Epoch: 6| Step: 3
Training loss: 2.7123412090179513
Validation loss: 2.6176726086191757

Epoch: 6| Step: 4
Training loss: 2.744916031183743
Validation loss: 2.6134006870195985

Epoch: 6| Step: 5
Training loss: 2.786445308666746
Validation loss: 2.6142363577679464

Epoch: 6| Step: 6
Training loss: 3.0210531922057777
Validation loss: 2.607110638086566

Epoch: 6| Step: 7
Training loss: 2.3588658471863067
Validation loss: 2.6087559405388525

Epoch: 6| Step: 8
Training loss: 2.703189033234978
Validation loss: 2.6121699579499236

Epoch: 6| Step: 9
Training loss: 3.095763658960599
Validation loss: 2.6221670425351085

Epoch: 6| Step: 10
Training loss: 2.6759886723893023
Validation loss: 2.6068612056669935

Epoch: 6| Step: 11
Training loss: 2.590278600488645
Validation loss: 2.60959619738093

Epoch: 6| Step: 12
Training loss: 3.0495911058338234
Validation loss: 2.612149938830606

Epoch: 6| Step: 13
Training loss: 2.5308238483142773
Validation loss: 2.6079292632350985

Epoch: 60| Step: 0
Training loss: 2.8263936512683316
Validation loss: 2.6186331632614577

Epoch: 6| Step: 1
Training loss: 2.831676129405208
Validation loss: 2.630267519646902

Epoch: 6| Step: 2
Training loss: 3.1980007959952923
Validation loss: 2.634288310068501

Epoch: 6| Step: 3
Training loss: 2.8854366444103827
Validation loss: 2.6012277931977605

Epoch: 6| Step: 4
Training loss: 3.1043528729259426
Validation loss: 2.6015714811336155

Epoch: 6| Step: 5
Training loss: 2.967452880176758
Validation loss: 2.606160008792562

Epoch: 6| Step: 6
Training loss: 2.700041495110285
Validation loss: 2.6107270322414835

Epoch: 6| Step: 7
Training loss: 2.86307224067687
Validation loss: 2.612201127230756

Epoch: 6| Step: 8
Training loss: 2.477475741024174
Validation loss: 2.615714240213422

Epoch: 6| Step: 9
Training loss: 2.8061932530432205
Validation loss: 2.620728665815573

Epoch: 6| Step: 10
Training loss: 2.928529719145423
Validation loss: 2.620040325601869

Epoch: 6| Step: 11
Training loss: 1.7614663359830394
Validation loss: 2.623990227986376

Epoch: 6| Step: 12
Training loss: 2.2397769105037413
Validation loss: 2.620976710276567

Epoch: 6| Step: 13
Training loss: 2.8055911507777225
Validation loss: 2.6160130081213033

Epoch: 61| Step: 0
Training loss: 3.079680229035208
Validation loss: 2.6153463083765893

Epoch: 6| Step: 1
Training loss: 2.538558017791278
Validation loss: 2.6101024017366585

Epoch: 6| Step: 2
Training loss: 3.1631026707742786
Validation loss: 2.6092781155506564

Epoch: 6| Step: 3
Training loss: 2.5724082681299083
Validation loss: 2.6068490264679065

Epoch: 6| Step: 4
Training loss: 2.8558985521052724
Validation loss: 2.606191127975133

Epoch: 6| Step: 5
Training loss: 2.8189006452207095
Validation loss: 2.602604028440824

Epoch: 6| Step: 6
Training loss: 2.768831194167173
Validation loss: 2.601633065214629

Epoch: 6| Step: 7
Training loss: 2.7643524518129445
Validation loss: 2.5993393266459885

Epoch: 6| Step: 8
Training loss: 2.44468217714811
Validation loss: 2.5980312908452547

Epoch: 6| Step: 9
Training loss: 2.5376278624242476
Validation loss: 2.596665807837302

Epoch: 6| Step: 10
Training loss: 2.2868417637055223
Validation loss: 2.5944592222473135

Epoch: 6| Step: 11
Training loss: 2.8287022459927407
Validation loss: 2.5882825101278812

Epoch: 6| Step: 12
Training loss: 2.4784803215139877
Validation loss: 2.5883611901432637

Epoch: 6| Step: 13
Training loss: 3.0328144873367395
Validation loss: 2.586552572716391

Epoch: 62| Step: 0
Training loss: 3.0211996623696264
Validation loss: 2.5814735321967675

Epoch: 6| Step: 1
Training loss: 2.9882327406193405
Validation loss: 2.587151172485955

Epoch: 6| Step: 2
Training loss: 3.322409006082594
Validation loss: 2.585731767074957

Epoch: 6| Step: 3
Training loss: 2.717211408548315
Validation loss: 2.5881923130214157

Epoch: 6| Step: 4
Training loss: 2.6772259230186943
Validation loss: 2.5894802753281354

Epoch: 6| Step: 5
Training loss: 2.6227209097420086
Validation loss: 2.5917252447084826

Epoch: 6| Step: 6
Training loss: 2.6027561691221326
Validation loss: 2.592461392290827

Epoch: 6| Step: 7
Training loss: 2.41276026295337
Validation loss: 2.592066758685419

Epoch: 6| Step: 8
Training loss: 2.3434583355305105
Validation loss: 2.5938868965269637

Epoch: 6| Step: 9
Training loss: 2.551856195631402
Validation loss: 2.5956833309799507

Epoch: 6| Step: 10
Training loss: 2.8802356316282824
Validation loss: 2.5953751034566896

Epoch: 6| Step: 11
Training loss: 2.82290682257218
Validation loss: 2.592434561040565

Epoch: 6| Step: 12
Training loss: 2.871794198677138
Validation loss: 2.591082062567511

Epoch: 6| Step: 13
Training loss: 2.2233140236942064
Validation loss: 2.5904645372368726

Epoch: 63| Step: 0
Training loss: 3.2089044302085274
Validation loss: 2.5875576203299175

Epoch: 6| Step: 1
Training loss: 2.681129445742574
Validation loss: 2.5835029074685316

Epoch: 6| Step: 2
Training loss: 3.0975417203764435
Validation loss: 2.5831135276886106

Epoch: 6| Step: 3
Training loss: 2.1798509105832458
Validation loss: 2.577941071085643

Epoch: 6| Step: 4
Training loss: 2.367345622103927
Validation loss: 2.5870097569735195

Epoch: 6| Step: 5
Training loss: 2.9179942424840255
Validation loss: 2.593586391819493

Epoch: 6| Step: 6
Training loss: 2.2658476621458377
Validation loss: 2.591812743172152

Epoch: 6| Step: 7
Training loss: 2.560276648653258
Validation loss: 2.5864521601635664

Epoch: 6| Step: 8
Training loss: 2.760908685176549
Validation loss: 2.5847929297174295

Epoch: 6| Step: 9
Training loss: 2.638967682403855
Validation loss: 2.5819545163108693

Epoch: 6| Step: 10
Training loss: 2.910422007055897
Validation loss: 2.577725635769451

Epoch: 6| Step: 11
Training loss: 2.5428716169285197
Validation loss: 2.573523003385884

Epoch: 6| Step: 12
Training loss: 3.315595512007332
Validation loss: 2.5752995122399898

Epoch: 6| Step: 13
Training loss: 2.297543383034111
Validation loss: 2.57655214053528

Epoch: 64| Step: 0
Training loss: 2.6044856880601785
Validation loss: 2.5722969997523015

Epoch: 6| Step: 1
Training loss: 2.4373717641110058
Validation loss: 2.5695096262548427

Epoch: 6| Step: 2
Training loss: 3.1223801884751055
Validation loss: 2.571636025383644

Epoch: 6| Step: 3
Training loss: 2.181548168712887
Validation loss: 2.571541396761518

Epoch: 6| Step: 4
Training loss: 3.2520148560676154
Validation loss: 2.564721207020522

Epoch: 6| Step: 5
Training loss: 2.3530291169225785
Validation loss: 2.569781031056324

Epoch: 6| Step: 6
Training loss: 2.7884181370886383
Validation loss: 2.565847931259008

Epoch: 6| Step: 7
Training loss: 3.259945397651087
Validation loss: 2.5673443044214923

Epoch: 6| Step: 8
Training loss: 2.140114270840377
Validation loss: 2.567519954144508

Epoch: 6| Step: 9
Training loss: 2.6952896780623474
Validation loss: 2.5721483254534396

Epoch: 6| Step: 10
Training loss: 3.0235333883373317
Validation loss: 2.567472548940096

Epoch: 6| Step: 11
Training loss: 2.6783930819038093
Validation loss: 2.5655332616279143

Epoch: 6| Step: 12
Training loss: 2.4421272372903164
Validation loss: 2.564856306516486

Epoch: 6| Step: 13
Training loss: 2.5622325850725036
Validation loss: 2.563250083001382

Epoch: 65| Step: 0
Training loss: 3.220235093105875
Validation loss: 2.562015084386289

Epoch: 6| Step: 1
Training loss: 2.1586047597156344
Validation loss: 2.562097936582324

Epoch: 6| Step: 2
Training loss: 2.129040523109353
Validation loss: 2.5595293581491614

Epoch: 6| Step: 3
Training loss: 2.486898615998916
Validation loss: 2.557085162265673

Epoch: 6| Step: 4
Training loss: 2.6095111377403093
Validation loss: 2.5583064959067943

Epoch: 6| Step: 5
Training loss: 2.948961016780522
Validation loss: 2.5561616865228416

Epoch: 6| Step: 6
Training loss: 2.5915504229153905
Validation loss: 2.5552975609605357

Epoch: 6| Step: 7
Training loss: 2.5616435969184037
Validation loss: 2.5595235052562715

Epoch: 6| Step: 8
Training loss: 2.7162416660059856
Validation loss: 2.56559417743266

Epoch: 6| Step: 9
Training loss: 2.681247624038319
Validation loss: 2.57154587794725

Epoch: 6| Step: 10
Training loss: 2.9128931066751362
Validation loss: 2.560580705603011

Epoch: 6| Step: 11
Training loss: 2.726843876788942
Validation loss: 2.551794842873375

Epoch: 6| Step: 12
Training loss: 2.8790054614752973
Validation loss: 2.5547724407357837

Epoch: 6| Step: 13
Training loss: 2.9365773476719226
Validation loss: 2.5554797998086625

Epoch: 66| Step: 0
Training loss: 2.887842437123326
Validation loss: 2.5656391392766205

Epoch: 6| Step: 1
Training loss: 3.0475787010388884
Validation loss: 2.5738395369155103

Epoch: 6| Step: 2
Training loss: 2.9348499437799003
Validation loss: 2.579227866667419

Epoch: 6| Step: 3
Training loss: 2.4896359192044266
Validation loss: 2.592565534150242

Epoch: 6| Step: 4
Training loss: 2.7626350749552584
Validation loss: 2.594782811326749

Epoch: 6| Step: 5
Training loss: 2.2220205997023763
Validation loss: 2.609218577495298

Epoch: 6| Step: 6
Training loss: 2.511940574046345
Validation loss: 2.5968831606544285

Epoch: 6| Step: 7
Training loss: 2.576038417873244
Validation loss: 2.5945252481720624

Epoch: 6| Step: 8
Training loss: 2.3765179651866677
Validation loss: 2.5974632707776526

Epoch: 6| Step: 9
Training loss: 2.715697668791132
Validation loss: 2.602004356397246

Epoch: 6| Step: 10
Training loss: 3.1529829282482953
Validation loss: 2.5974108893217736

Epoch: 6| Step: 11
Training loss: 2.788278164892609
Validation loss: 2.5810648022733846

Epoch: 6| Step: 12
Training loss: 2.1933672013996612
Validation loss: 2.5659463858490255

Epoch: 6| Step: 13
Training loss: 3.1296137511105324
Validation loss: 2.560297104413518

Epoch: 67| Step: 0
Training loss: 2.5347433591568103
Validation loss: 2.557149154100228

Epoch: 6| Step: 1
Training loss: 3.071743464248968
Validation loss: 2.5547445215050195

Epoch: 6| Step: 2
Training loss: 2.808220043972454
Validation loss: 2.5540286428756733

Epoch: 6| Step: 3
Training loss: 2.738283165510653
Validation loss: 2.549029798068381

Epoch: 6| Step: 4
Training loss: 3.119305725123318
Validation loss: 2.5508394336928664

Epoch: 6| Step: 5
Training loss: 2.3141363385852594
Validation loss: 2.545994112855508

Epoch: 6| Step: 6
Training loss: 2.301781428866967
Validation loss: 2.546824105657212

Epoch: 6| Step: 7
Training loss: 2.389691039509657
Validation loss: 2.5444712538766687

Epoch: 6| Step: 8
Training loss: 2.2731728940527387
Validation loss: 2.537318282988643

Epoch: 6| Step: 9
Training loss: 2.7671221974711027
Validation loss: 2.5456869088460743

Epoch: 6| Step: 10
Training loss: 3.359583932456332
Validation loss: 2.5439237255662004

Epoch: 6| Step: 11
Training loss: 2.267816365136076
Validation loss: 2.552824050429519

Epoch: 6| Step: 12
Training loss: 2.4694806719786495
Validation loss: 2.5466905772832593

Epoch: 6| Step: 13
Training loss: 2.802698306605897
Validation loss: 2.5484512069897973

Epoch: 68| Step: 0
Training loss: 2.5199680156797286
Validation loss: 2.551674250818398

Epoch: 6| Step: 1
Training loss: 2.685809557465568
Validation loss: 2.5599132755858567

Epoch: 6| Step: 2
Training loss: 2.2729500054543483
Validation loss: 2.5666741589853825

Epoch: 6| Step: 3
Training loss: 2.91195725389693
Validation loss: 2.5720735370550982

Epoch: 6| Step: 4
Training loss: 2.2435025602036607
Validation loss: 2.567263153874582

Epoch: 6| Step: 5
Training loss: 2.614775591059692
Validation loss: 2.5390168953736962

Epoch: 6| Step: 6
Training loss: 3.1546433391380346
Validation loss: 2.5321876217865884

Epoch: 6| Step: 7
Training loss: 2.707851445291648
Validation loss: 2.5339658790314403

Epoch: 6| Step: 8
Training loss: 2.7539543851068093
Validation loss: 2.542196505201787

Epoch: 6| Step: 9
Training loss: 2.8930394991496637
Validation loss: 2.544021482297477

Epoch: 6| Step: 10
Training loss: 2.7130767560675397
Validation loss: 2.551139615536914

Epoch: 6| Step: 11
Training loss: 2.434550040811361
Validation loss: 2.554575879752848

Epoch: 6| Step: 12
Training loss: 2.5898873856264584
Validation loss: 2.5605756310410537

Epoch: 6| Step: 13
Training loss: 2.9742841035533076
Validation loss: 2.5665130360768513

Epoch: 69| Step: 0
Training loss: 2.8416673348911727
Validation loss: 2.5693755447039455

Epoch: 6| Step: 1
Training loss: 2.4557471384231593
Validation loss: 2.5849238288424594

Epoch: 6| Step: 2
Training loss: 2.6100631080685743
Validation loss: 2.5932131905008373

Epoch: 6| Step: 3
Training loss: 3.172228412952458
Validation loss: 2.607843935902538

Epoch: 6| Step: 4
Training loss: 2.6043209996585857
Validation loss: 2.6088774734058138

Epoch: 6| Step: 5
Training loss: 2.7053646445451367
Validation loss: 2.6003495941126387

Epoch: 6| Step: 6
Training loss: 2.736795454940434
Validation loss: 2.5936819933206516

Epoch: 6| Step: 7
Training loss: 2.7595902459424093
Validation loss: 2.57754281917097

Epoch: 6| Step: 8
Training loss: 2.345643461232525
Validation loss: 2.5725830314836813

Epoch: 6| Step: 9
Training loss: 2.653801271767153
Validation loss: 2.5598858470599075

Epoch: 6| Step: 10
Training loss: 2.9883887975949213
Validation loss: 2.554636247997655

Epoch: 6| Step: 11
Training loss: 2.605200803782185
Validation loss: 2.557441152850834

Epoch: 6| Step: 12
Training loss: 2.9790766953618606
Validation loss: 2.5530167462150475

Epoch: 6| Step: 13
Training loss: 2.3166192971562123
Validation loss: 2.545438653993852

Epoch: 70| Step: 0
Training loss: 2.2584590844009296
Validation loss: 2.544902981980507

Epoch: 6| Step: 1
Training loss: 2.6843812278524326
Validation loss: 2.544505571503804

Epoch: 6| Step: 2
Training loss: 2.7750190631108578
Validation loss: 2.5448630875818727

Epoch: 6| Step: 3
Training loss: 2.599039773423148
Validation loss: 2.5384618273611133

Epoch: 6| Step: 4
Training loss: 2.7860091563373506
Validation loss: 2.5387656639889333

Epoch: 6| Step: 5
Training loss: 2.6093147864789605
Validation loss: 2.5384584931115985

Epoch: 6| Step: 6
Training loss: 2.8700013865823086
Validation loss: 2.5367651772722226

Epoch: 6| Step: 7
Training loss: 2.923266400825507
Validation loss: 2.5366142010954635

Epoch: 6| Step: 8
Training loss: 3.293860770576064
Validation loss: 2.53544794490164

Epoch: 6| Step: 9
Training loss: 2.5283731194997094
Validation loss: 2.5336657797452986

Epoch: 6| Step: 10
Training loss: 2.4357960932161484
Validation loss: 2.5324014470166314

Epoch: 6| Step: 11
Training loss: 2.5089895748136217
Validation loss: 2.534888051035901

Epoch: 6| Step: 12
Training loss: 2.343475223964549
Validation loss: 2.5363561203641085

Epoch: 6| Step: 13
Training loss: 2.587352906989616
Validation loss: 2.5346357519534375

Epoch: 71| Step: 0
Training loss: 2.8045593062407645
Validation loss: 2.530463594951759

Epoch: 6| Step: 1
Training loss: 2.4927359907181077
Validation loss: 2.525590590220795

Epoch: 6| Step: 2
Training loss: 2.9479882509056963
Validation loss: 2.5249345509699097

Epoch: 6| Step: 3
Training loss: 3.1020993169334763
Validation loss: 2.5177196209398955

Epoch: 6| Step: 4
Training loss: 2.7553561675150604
Validation loss: 2.5242824576707394

Epoch: 6| Step: 5
Training loss: 2.5264008781153753
Validation loss: 2.526191633564157

Epoch: 6| Step: 6
Training loss: 2.501728795258762
Validation loss: 2.5236476184772894

Epoch: 6| Step: 7
Training loss: 2.866100302645429
Validation loss: 2.5119055821377176

Epoch: 6| Step: 8
Training loss: 2.150404594854146
Validation loss: 2.51725304090252

Epoch: 6| Step: 9
Training loss: 2.6841059699820464
Validation loss: 2.514097788744632

Epoch: 6| Step: 10
Training loss: 2.1975239648477833
Validation loss: 2.5160793660209597

Epoch: 6| Step: 11
Training loss: 2.913680391597102
Validation loss: 2.513035897059909

Epoch: 6| Step: 12
Training loss: 2.6056306208208837
Validation loss: 2.5114406750149336

Epoch: 6| Step: 13
Training loss: 2.5148970219971236
Validation loss: 2.516626399604389

Epoch: 72| Step: 0
Training loss: 2.2382855107398365
Validation loss: 2.5122944047103486

Epoch: 6| Step: 1
Training loss: 2.268285938228401
Validation loss: 2.5125308862056137

Epoch: 6| Step: 2
Training loss: 2.855176334046382
Validation loss: 2.5096823276496085

Epoch: 6| Step: 3
Training loss: 1.7132295210196196
Validation loss: 2.510979962499274

Epoch: 6| Step: 4
Training loss: 2.442394721769745
Validation loss: 2.514631213280412

Epoch: 6| Step: 5
Training loss: 2.866675889939249
Validation loss: 2.5118285412718526

Epoch: 6| Step: 6
Training loss: 3.15566678843611
Validation loss: 2.518330542737255

Epoch: 6| Step: 7
Training loss: 2.7969567484070463
Validation loss: 2.513529012948309

Epoch: 6| Step: 8
Training loss: 2.2936371279185925
Validation loss: 2.515019946262548

Epoch: 6| Step: 9
Training loss: 3.060536903701051
Validation loss: 2.5189983583086315

Epoch: 6| Step: 10
Training loss: 2.6849978131901593
Validation loss: 2.515966325117077

Epoch: 6| Step: 11
Training loss: 2.5353452732521564
Validation loss: 2.5122578992967135

Epoch: 6| Step: 12
Training loss: 2.703345493739287
Validation loss: 2.5123085765130875

Epoch: 6| Step: 13
Training loss: 3.059778834060838
Validation loss: 2.511032524914074

Epoch: 73| Step: 0
Training loss: 2.4793065028997616
Validation loss: 2.5103671806386014

Epoch: 6| Step: 1
Training loss: 2.5178777429110952
Validation loss: 2.5039241986516654

Epoch: 6| Step: 2
Training loss: 2.6098167365324545
Validation loss: 2.510363539981743

Epoch: 6| Step: 3
Training loss: 2.8097903444265317
Validation loss: 2.561631916292757

Epoch: 6| Step: 4
Training loss: 2.765108221878256
Validation loss: 2.5661808652340277

Epoch: 6| Step: 5
Training loss: 2.6908063732161907
Validation loss: 2.5326127830363716

Epoch: 6| Step: 6
Training loss: 2.3137750976454323
Validation loss: 2.518597933183592

Epoch: 6| Step: 7
Training loss: 2.7569333152855986
Validation loss: 2.5129468732369946

Epoch: 6| Step: 8
Training loss: 2.9368980277896553
Validation loss: 2.502855069341462

Epoch: 6| Step: 9
Training loss: 2.9560809806912083
Validation loss: 2.5067153701548612

Epoch: 6| Step: 10
Training loss: 2.4512492984535346
Validation loss: 2.5056295430729083

Epoch: 6| Step: 11
Training loss: 2.9084988988697527
Validation loss: 2.508557645668005

Epoch: 6| Step: 12
Training loss: 2.32200165476317
Validation loss: 2.5153779250097634

Epoch: 6| Step: 13
Training loss: 2.4613269316127484
Validation loss: 2.5116570338077353

Epoch: 74| Step: 0
Training loss: 3.053422202381468
Validation loss: 2.513409446487975

Epoch: 6| Step: 1
Training loss: 2.585452400183949
Validation loss: 2.514117071311414

Epoch: 6| Step: 2
Training loss: 1.8330587990711185
Validation loss: 2.5135217724068273

Epoch: 6| Step: 3
Training loss: 2.5032125812500845
Validation loss: 2.513398095046171

Epoch: 6| Step: 4
Training loss: 1.86364198787458
Validation loss: 2.513603061306168

Epoch: 6| Step: 5
Training loss: 2.608651614854054
Validation loss: 2.5176553371556185

Epoch: 6| Step: 6
Training loss: 2.7283349165060318
Validation loss: 2.5129925714725307

Epoch: 6| Step: 7
Training loss: 2.472150368188013
Validation loss: 2.5122714781704603

Epoch: 6| Step: 8
Training loss: 2.9514906463035393
Validation loss: 2.5107956174222212

Epoch: 6| Step: 9
Training loss: 3.0951387005172246
Validation loss: 2.5104442980077972

Epoch: 6| Step: 10
Training loss: 2.724640089292606
Validation loss: 2.508105537192646

Epoch: 6| Step: 11
Training loss: 2.836883807390303
Validation loss: 2.508556568524008

Epoch: 6| Step: 12
Training loss: 2.823990977534937
Validation loss: 2.5092029618655887

Epoch: 6| Step: 13
Training loss: 2.5079535804115323
Validation loss: 2.506083683827959

Epoch: 75| Step: 0
Training loss: 2.531168995255739
Validation loss: 2.4984272460218135

Epoch: 6| Step: 1
Training loss: 2.3596365070049306
Validation loss: 2.5004673362072727

Epoch: 6| Step: 2
Training loss: 2.465216123380087
Validation loss: 2.5036814127971008

Epoch: 6| Step: 3
Training loss: 2.3740053603795506
Validation loss: 2.5045661076641017

Epoch: 6| Step: 4
Training loss: 2.6192175436423892
Validation loss: 2.495929742478427

Epoch: 6| Step: 5
Training loss: 2.8755273749916155
Validation loss: 2.497429400322201

Epoch: 6| Step: 6
Training loss: 2.4485204939417864
Validation loss: 2.4995131177451806

Epoch: 6| Step: 7
Training loss: 2.573779889267145
Validation loss: 2.4973050214680286

Epoch: 6| Step: 8
Training loss: 2.8953716175283732
Validation loss: 2.4953711094957067

Epoch: 6| Step: 9
Training loss: 2.2693190352321535
Validation loss: 2.5002266940015474

Epoch: 6| Step: 10
Training loss: 2.8705901450331983
Validation loss: 2.494483280965156

Epoch: 6| Step: 11
Training loss: 2.3900371152797084
Validation loss: 2.5025963176137127

Epoch: 6| Step: 12
Training loss: 3.1795414321678637
Validation loss: 2.49977931002237

Epoch: 6| Step: 13
Training loss: 2.6255557062403083
Validation loss: 2.496133134398877

Epoch: 76| Step: 0
Training loss: 2.914336736216415
Validation loss: 2.498228908067409

Epoch: 6| Step: 1
Training loss: 2.441816274162812
Validation loss: 2.5040171772730253

Epoch: 6| Step: 2
Training loss: 2.230918398026051
Validation loss: 2.507846360656376

Epoch: 6| Step: 3
Training loss: 2.4924102014035623
Validation loss: 2.521856483917772

Epoch: 6| Step: 4
Training loss: 3.0567691666262777
Validation loss: 2.5299629110198567

Epoch: 6| Step: 5
Training loss: 3.5031623178173725
Validation loss: 2.553042380818304

Epoch: 6| Step: 6
Training loss: 2.5303069818791526
Validation loss: 2.5493196561566505

Epoch: 6| Step: 7
Training loss: 2.340171014128286
Validation loss: 2.5284162443980045

Epoch: 6| Step: 8
Training loss: 1.8298995053990312
Validation loss: 2.5003443798653

Epoch: 6| Step: 9
Training loss: 2.841121087227293
Validation loss: 2.4947805278319697

Epoch: 6| Step: 10
Training loss: 2.751626314097996
Validation loss: 2.492626625844194

Epoch: 6| Step: 11
Training loss: 2.4830418494604305
Validation loss: 2.503529282717791

Epoch: 6| Step: 12
Training loss: 2.859464383421936
Validation loss: 2.5024518864109817

Epoch: 6| Step: 13
Training loss: 1.897856195563322
Validation loss: 2.497088493287944

Epoch: 77| Step: 0
Training loss: 3.30838332694945
Validation loss: 2.503927499539114

Epoch: 6| Step: 1
Training loss: 2.807996407813576
Validation loss: 2.501869345182187

Epoch: 6| Step: 2
Training loss: 2.4368629601243033
Validation loss: 2.505842692953208

Epoch: 6| Step: 3
Training loss: 2.956844832920185
Validation loss: 2.505253961244086

Epoch: 6| Step: 4
Training loss: 2.7254576972361595
Validation loss: 2.5097249029000155

Epoch: 6| Step: 5
Training loss: 2.6906648675000793
Validation loss: 2.5109817269937893

Epoch: 6| Step: 6
Training loss: 3.1740114129768076
Validation loss: 2.5096631772596396

Epoch: 6| Step: 7
Training loss: 1.5966233923084225
Validation loss: 2.5105281873654146

Epoch: 6| Step: 8
Training loss: 2.6408922410074367
Validation loss: 2.512130830064456

Epoch: 6| Step: 9
Training loss: 2.443116978758777
Validation loss: 2.511523953601976

Epoch: 6| Step: 10
Training loss: 2.3789433318256235
Validation loss: 2.51008698500157

Epoch: 6| Step: 11
Training loss: 1.9986383452013168
Validation loss: 2.5117540450950915

Epoch: 6| Step: 12
Training loss: 2.5749583824275937
Validation loss: 2.5058866892332192

Epoch: 6| Step: 13
Training loss: 2.718980801311475
Validation loss: 2.5048052383516715

Epoch: 78| Step: 0
Training loss: 2.4160315128380696
Validation loss: 2.499899941667303

Epoch: 6| Step: 1
Training loss: 2.738897714048263
Validation loss: 2.499195541650896

Epoch: 6| Step: 2
Training loss: 2.998735797271233
Validation loss: 2.494627424871722

Epoch: 6| Step: 3
Training loss: 2.9429966248036976
Validation loss: 2.4980215032072968

Epoch: 6| Step: 4
Training loss: 2.4483699514179524
Validation loss: 2.4977194795469324

Epoch: 6| Step: 5
Training loss: 2.5121640868079957
Validation loss: 2.493438884860461

Epoch: 6| Step: 6
Training loss: 2.5487138159832092
Validation loss: 2.496356892532865

Epoch: 6| Step: 7
Training loss: 2.323946281298123
Validation loss: 2.4934150279612917

Epoch: 6| Step: 8
Training loss: 2.8718841917868407
Validation loss: 2.4889417537210337

Epoch: 6| Step: 9
Training loss: 2.613308984811719
Validation loss: 2.4900388473840587

Epoch: 6| Step: 10
Training loss: 2.399341325973224
Validation loss: 2.4903357152327072

Epoch: 6| Step: 11
Training loss: 2.9978569641601442
Validation loss: 2.488510688172695

Epoch: 6| Step: 12
Training loss: 2.2852267784255043
Validation loss: 2.49144948397701

Epoch: 6| Step: 13
Training loss: 2.401376619510503
Validation loss: 2.4933116135526685

Epoch: 79| Step: 0
Training loss: 2.2285982161787876
Validation loss: 2.493369640257694

Epoch: 6| Step: 1
Training loss: 2.7390551813422794
Validation loss: 2.493189085274367

Epoch: 6| Step: 2
Training loss: 2.893188329775276
Validation loss: 2.4946853891139398

Epoch: 6| Step: 3
Training loss: 2.602660900935577
Validation loss: 2.496198832051635

Epoch: 6| Step: 4
Training loss: 2.3010874416575424
Validation loss: 2.495554643418321

Epoch: 6| Step: 5
Training loss: 2.3882412463810114
Validation loss: 2.4950596473663333

Epoch: 6| Step: 6
Training loss: 2.3093010711193016
Validation loss: 2.4879677184239997

Epoch: 6| Step: 7
Training loss: 3.0701531521745973
Validation loss: 2.490585354274467

Epoch: 6| Step: 8
Training loss: 2.719357302131832
Validation loss: 2.490346366009646

Epoch: 6| Step: 9
Training loss: 2.440275323999607
Validation loss: 2.4908153619135995

Epoch: 6| Step: 10
Training loss: 2.218951363895674
Validation loss: 2.491932791167409

Epoch: 6| Step: 11
Training loss: 2.27246618331743
Validation loss: 2.492737042816616

Epoch: 6| Step: 12
Training loss: 2.9932435564994355
Validation loss: 2.4978748826028463

Epoch: 6| Step: 13
Training loss: 3.0024097619007524
Validation loss: 2.4944716363098314

Epoch: 80| Step: 0
Training loss: 2.1393183597663987
Validation loss: 2.4924476671097517

Epoch: 6| Step: 1
Training loss: 2.524942427630361
Validation loss: 2.4905014792412845

Epoch: 6| Step: 2
Training loss: 2.4125103451205594
Validation loss: 2.489373766220161

Epoch: 6| Step: 3
Training loss: 2.581219844318688
Validation loss: 2.488401496892153

Epoch: 6| Step: 4
Training loss: 2.677394497571058
Validation loss: 2.4866462737705444

Epoch: 6| Step: 5
Training loss: 2.231609847599229
Validation loss: 2.487477123212811

Epoch: 6| Step: 6
Training loss: 3.051827342957918
Validation loss: 2.4967864522562535

Epoch: 6| Step: 7
Training loss: 2.2949450422700313
Validation loss: 2.4901680572256013

Epoch: 6| Step: 8
Training loss: 2.6024380147186754
Validation loss: 2.494901002997982

Epoch: 6| Step: 9
Training loss: 3.3446098006535725
Validation loss: 2.4985173915410166

Epoch: 6| Step: 10
Training loss: 2.339578196337918
Validation loss: 2.4937096773359704

Epoch: 6| Step: 11
Training loss: 2.8605706055170095
Validation loss: 2.4952177879721518

Epoch: 6| Step: 12
Training loss: 2.657080756031605
Validation loss: 2.495301894625407

Epoch: 6| Step: 13
Training loss: 2.8423275586431904
Validation loss: 2.5011474916396685

Epoch: 81| Step: 0
Training loss: 2.780007331207269
Validation loss: 2.504311039381323

Epoch: 6| Step: 1
Training loss: 2.9169761675154335
Validation loss: 2.50686952602867

Epoch: 6| Step: 2
Training loss: 2.7511852484522503
Validation loss: 2.5101289755776746

Epoch: 6| Step: 3
Training loss: 2.5677353945860752
Validation loss: 2.511277733069417

Epoch: 6| Step: 4
Training loss: 2.565607187485745
Validation loss: 2.5084556000609646

Epoch: 6| Step: 5
Training loss: 2.4593120717161674
Validation loss: 2.50541956295893

Epoch: 6| Step: 6
Training loss: 2.882702336881407
Validation loss: 2.5052196055665603

Epoch: 6| Step: 7
Training loss: 3.3709904907961525
Validation loss: 2.5021245035621815

Epoch: 6| Step: 8
Training loss: 2.6743457814167453
Validation loss: 2.505245110657532

Epoch: 6| Step: 9
Training loss: 2.485480872127253
Validation loss: 2.508832492355942

Epoch: 6| Step: 10
Training loss: 2.251929938932297
Validation loss: 2.5026135929074367

Epoch: 6| Step: 11
Training loss: 2.3570466331559037
Validation loss: 2.4971161103278847

Epoch: 6| Step: 12
Training loss: 2.498632056776541
Validation loss: 2.5017532082146343

Epoch: 6| Step: 13
Training loss: 2.0039478914868103
Validation loss: 2.4944661245935555

Epoch: 82| Step: 0
Training loss: 2.244788492175437
Validation loss: 2.495477941702063

Epoch: 6| Step: 1
Training loss: 3.477368344982949
Validation loss: 2.4925880628414707

Epoch: 6| Step: 2
Training loss: 2.2669175242938775
Validation loss: 2.4990114959832983

Epoch: 6| Step: 3
Training loss: 3.1414312589836233
Validation loss: 2.4875070114931495

Epoch: 6| Step: 4
Training loss: 2.337012206398684
Validation loss: 2.486650979855057

Epoch: 6| Step: 5
Training loss: 2.0982098124262194
Validation loss: 2.4857791475363897

Epoch: 6| Step: 6
Training loss: 2.915048713604208
Validation loss: 2.4880158558817627

Epoch: 6| Step: 7
Training loss: 3.113231318706404
Validation loss: 2.4876810944035

Epoch: 6| Step: 8
Training loss: 2.8019260423798755
Validation loss: 2.4837525585656057

Epoch: 6| Step: 9
Training loss: 2.6083343623670148
Validation loss: 2.4858627503108406

Epoch: 6| Step: 10
Training loss: 2.0839628667177346
Validation loss: 2.488918636017475

Epoch: 6| Step: 11
Training loss: 1.983140275946258
Validation loss: 2.48263776967365

Epoch: 6| Step: 12
Training loss: 2.5139626643792994
Validation loss: 2.487706068503419

Epoch: 6| Step: 13
Training loss: 2.3331463829714068
Validation loss: 2.48398543848386

Epoch: 83| Step: 0
Training loss: 2.5380636744827267
Validation loss: 2.478080035872461

Epoch: 6| Step: 1
Training loss: 2.8912082393020073
Validation loss: 2.479724506053165

Epoch: 6| Step: 2
Training loss: 2.6006976915471363
Validation loss: 2.477367907947367

Epoch: 6| Step: 3
Training loss: 2.1277985937275057
Validation loss: 2.483873912572547

Epoch: 6| Step: 4
Training loss: 2.2242748621892794
Validation loss: 2.488210552335085

Epoch: 6| Step: 5
Training loss: 2.124832034485119
Validation loss: 2.4879232215912124

Epoch: 6| Step: 6
Training loss: 3.2307984853824316
Validation loss: 2.486277333769885

Epoch: 6| Step: 7
Training loss: 2.7193025926275647
Validation loss: 2.4822716916382874

Epoch: 6| Step: 8
Training loss: 3.0567601189702076
Validation loss: 2.488833826691601

Epoch: 6| Step: 9
Training loss: 3.068700313748572
Validation loss: 2.48091899159707

Epoch: 6| Step: 10
Training loss: 2.286594244900964
Validation loss: 2.476743753661708

Epoch: 6| Step: 11
Training loss: 1.9359979652401973
Validation loss: 2.4794979889180686

Epoch: 6| Step: 12
Training loss: 2.537971708303873
Validation loss: 2.485108225363517

Epoch: 6| Step: 13
Training loss: 2.587943690493674
Validation loss: 2.4901032696288605

Epoch: 84| Step: 0
Training loss: 1.8684260518153495
Validation loss: 2.4853083938416978

Epoch: 6| Step: 1
Training loss: 2.825610734531883
Validation loss: 2.482885734065403

Epoch: 6| Step: 2
Training loss: 2.546903926006414
Validation loss: 2.4907755105471154

Epoch: 6| Step: 3
Training loss: 2.733950859962099
Validation loss: 2.4841301115567567

Epoch: 6| Step: 4
Training loss: 2.5896452630622937
Validation loss: 2.4849625538461413

Epoch: 6| Step: 5
Training loss: 2.4119045649384834
Validation loss: 2.4834870005006837

Epoch: 6| Step: 6
Training loss: 2.3799377109486723
Validation loss: 2.491039302610308

Epoch: 6| Step: 7
Training loss: 2.9254171351157274
Validation loss: 2.482486719004386

Epoch: 6| Step: 8
Training loss: 2.406170534085047
Validation loss: 2.481096179335636

Epoch: 6| Step: 9
Training loss: 3.044226174833276
Validation loss: 2.476156704907281

Epoch: 6| Step: 10
Training loss: 2.3258174238636937
Validation loss: 2.4771047614229253

Epoch: 6| Step: 11
Training loss: 2.608678576337517
Validation loss: 2.478596330535667

Epoch: 6| Step: 12
Training loss: 2.8030178870379925
Validation loss: 2.4771905818615423

Epoch: 6| Step: 13
Training loss: 2.5509599561729788
Validation loss: 2.478670059815674

Epoch: 85| Step: 0
Training loss: 2.7718293161508942
Validation loss: 2.479209263753514

Epoch: 6| Step: 1
Training loss: 2.760085166363501
Validation loss: 2.4822518415267165

Epoch: 6| Step: 2
Training loss: 3.214309740733615
Validation loss: 2.4853934193941787

Epoch: 6| Step: 3
Training loss: 2.738856887716407
Validation loss: 2.4846714010905746

Epoch: 6| Step: 4
Training loss: 2.2605820930760583
Validation loss: 2.480017994051432

Epoch: 6| Step: 5
Training loss: 2.7942847506036412
Validation loss: 2.484336916713603

Epoch: 6| Step: 6
Training loss: 2.359477059891616
Validation loss: 2.490948503608984

Epoch: 6| Step: 7
Training loss: 2.498419071055586
Validation loss: 2.4884834307220594

Epoch: 6| Step: 8
Training loss: 2.36470268945364
Validation loss: 2.4810425903086255

Epoch: 6| Step: 9
Training loss: 3.205723448231005
Validation loss: 2.484446190667757

Epoch: 6| Step: 10
Training loss: 2.340201170661411
Validation loss: 2.4825480079170585

Epoch: 6| Step: 11
Training loss: 2.2442698097064366
Validation loss: 2.475818510247634

Epoch: 6| Step: 12
Training loss: 2.3703107216513395
Validation loss: 2.4816219742847356

Epoch: 6| Step: 13
Training loss: 2.156357030008978
Validation loss: 2.4865585024638026

Epoch: 86| Step: 0
Training loss: 2.764593503157637
Validation loss: 2.4819948322817162

Epoch: 6| Step: 1
Training loss: 3.0399956140988484
Validation loss: 2.48258479014203

Epoch: 6| Step: 2
Training loss: 2.395484722040162
Validation loss: 2.4799260624636283

Epoch: 6| Step: 3
Training loss: 2.683161760456473
Validation loss: 2.483394045268985

Epoch: 6| Step: 4
Training loss: 2.3345630901910788
Validation loss: 2.4819335297089147

Epoch: 6| Step: 5
Training loss: 2.412358642547969
Validation loss: 2.4762293193376554

Epoch: 6| Step: 6
Training loss: 2.4329520614862084
Validation loss: 2.4815518795321467

Epoch: 6| Step: 7
Training loss: 2.680791777467654
Validation loss: 2.4952316347514008

Epoch: 6| Step: 8
Training loss: 2.2199347113554184
Validation loss: 2.5174716150577066

Epoch: 6| Step: 9
Training loss: 2.317553797223992
Validation loss: 2.5376404208211483

Epoch: 6| Step: 10
Training loss: 2.7710160121117817
Validation loss: 2.523026967387219

Epoch: 6| Step: 11
Training loss: 2.709125627879419
Validation loss: 2.501814898708394

Epoch: 6| Step: 12
Training loss: 3.040030435610551
Validation loss: 2.4894568013446854

Epoch: 6| Step: 13
Training loss: 2.8025198292775113
Validation loss: 2.4833688357928216

Epoch: 87| Step: 0
Training loss: 2.6464692400397483
Validation loss: 2.4784832875392007

Epoch: 6| Step: 1
Training loss: 2.305241301643121
Validation loss: 2.4762557488570027

Epoch: 6| Step: 2
Training loss: 2.3028894684438566
Validation loss: 2.475300400096805

Epoch: 6| Step: 3
Training loss: 2.6953165690073453
Validation loss: 2.4740396318964444

Epoch: 6| Step: 4
Training loss: 1.9223041830554244
Validation loss: 2.479472427319474

Epoch: 6| Step: 5
Training loss: 1.9997229384203044
Validation loss: 2.4798088898138495

Epoch: 6| Step: 6
Training loss: 2.619391398759689
Validation loss: 2.482576178860586

Epoch: 6| Step: 7
Training loss: 3.0195028246964117
Validation loss: 2.47824671583889

Epoch: 6| Step: 8
Training loss: 2.7455186743656075
Validation loss: 2.476048260718651

Epoch: 6| Step: 9
Training loss: 2.755589872790867
Validation loss: 2.4847479486338964

Epoch: 6| Step: 10
Training loss: 2.7377248244958157
Validation loss: 2.4778782411012825

Epoch: 6| Step: 11
Training loss: 2.766067383293635
Validation loss: 2.474044731371535

Epoch: 6| Step: 12
Training loss: 2.6011352188178734
Validation loss: 2.4846767506194785

Epoch: 6| Step: 13
Training loss: 2.941083791618955
Validation loss: 2.481394269193819

Epoch: 88| Step: 0
Training loss: 2.413235816021561
Validation loss: 2.480773090104779

Epoch: 6| Step: 1
Training loss: 2.9067287255874557
Validation loss: 2.4781074398231575

Epoch: 6| Step: 2
Training loss: 2.500960546976249
Validation loss: 2.48012787486668

Epoch: 6| Step: 3
Training loss: 2.751224938590032
Validation loss: 2.479689027480913

Epoch: 6| Step: 4
Training loss: 1.8881195112727576
Validation loss: 2.4758008553878366

Epoch: 6| Step: 5
Training loss: 2.6474535529337255
Validation loss: 2.4770502117649364

Epoch: 6| Step: 6
Training loss: 3.0328591391796405
Validation loss: 2.4788825142059974

Epoch: 6| Step: 7
Training loss: 2.5613611062983503
Validation loss: 2.4819945761236846

Epoch: 6| Step: 8
Training loss: 2.546476929804847
Validation loss: 2.480974537302724

Epoch: 6| Step: 9
Training loss: 2.858041587895398
Validation loss: 2.4806189143666133

Epoch: 6| Step: 10
Training loss: 2.271736583664643
Validation loss: 2.4790376154118174

Epoch: 6| Step: 11
Training loss: 2.5990283984650557
Validation loss: 2.476046326894605

Epoch: 6| Step: 12
Training loss: 2.968086088129907
Validation loss: 2.475791193311262

Epoch: 6| Step: 13
Training loss: 2.182293827416952
Validation loss: 2.4737541730195622

Epoch: 89| Step: 0
Training loss: 2.9118581825977587
Validation loss: 2.4732275971160504

Epoch: 6| Step: 1
Training loss: 2.3308020440043724
Validation loss: 2.4693941491202884

Epoch: 6| Step: 2
Training loss: 2.651613924407882
Validation loss: 2.477385720056167

Epoch: 6| Step: 3
Training loss: 2.406996574015887
Validation loss: 2.477818552626358

Epoch: 6| Step: 4
Training loss: 2.6000519453875106
Validation loss: 2.4738313555338727

Epoch: 6| Step: 5
Training loss: 2.3174159404896115
Validation loss: 2.4725308660181935

Epoch: 6| Step: 6
Training loss: 2.5760519304905296
Validation loss: 2.471510313760222

Epoch: 6| Step: 7
Training loss: 2.7136237387714197
Validation loss: 2.474582574624466

Epoch: 6| Step: 8
Training loss: 2.5902121441536776
Validation loss: 2.470154117507138

Epoch: 6| Step: 9
Training loss: 1.889963775267431
Validation loss: 2.4743636404947282

Epoch: 6| Step: 10
Training loss: 2.7138981112173037
Validation loss: 2.4770721328349516

Epoch: 6| Step: 11
Training loss: 2.5504625948010387
Validation loss: 2.476295673424781

Epoch: 6| Step: 12
Training loss: 2.6004200852753705
Validation loss: 2.4766157367170902

Epoch: 6| Step: 13
Training loss: 3.046894092989056
Validation loss: 2.468252655022717

Epoch: 90| Step: 0
Training loss: 2.944598933631514
Validation loss: 2.477028226333018

Epoch: 6| Step: 1
Training loss: 2.9276820935854824
Validation loss: 2.47875516879719

Epoch: 6| Step: 2
Training loss: 2.6430712322287597
Validation loss: 2.4847127017137365

Epoch: 6| Step: 3
Training loss: 2.239779997478161
Validation loss: 2.486255278098269

Epoch: 6| Step: 4
Training loss: 2.031213261198706
Validation loss: 2.4864661255101645

Epoch: 6| Step: 5
Training loss: 3.26805455120039
Validation loss: 2.4829917431695483

Epoch: 6| Step: 6
Training loss: 2.348299823717737
Validation loss: 2.4836740844572103

Epoch: 6| Step: 7
Training loss: 3.0449434858317455
Validation loss: 2.477609567487303

Epoch: 6| Step: 8
Training loss: 2.336342868908293
Validation loss: 2.4790606008541864

Epoch: 6| Step: 9
Training loss: 2.435096729715033
Validation loss: 2.4811695140272985

Epoch: 6| Step: 10
Training loss: 2.5817586550035125
Validation loss: 2.4815763468688914

Epoch: 6| Step: 11
Training loss: 2.649956101827683
Validation loss: 2.4840158006920094

Epoch: 6| Step: 12
Training loss: 2.172920688858284
Validation loss: 2.4815009905420955

Epoch: 6| Step: 13
Training loss: 2.297422278981425
Validation loss: 2.484640830990685

Epoch: 91| Step: 0
Training loss: 2.572357199276365
Validation loss: 2.479177031508719

Epoch: 6| Step: 1
Training loss: 2.68076100547614
Validation loss: 2.4784551983364413

Epoch: 6| Step: 2
Training loss: 2.6677321053999483
Validation loss: 2.478270526347537

Epoch: 6| Step: 3
Training loss: 2.6698773149456834
Validation loss: 2.475897578400231

Epoch: 6| Step: 4
Training loss: 2.199845599044954
Validation loss: 2.475980447588226

Epoch: 6| Step: 5
Training loss: 2.436949251995067
Validation loss: 2.472470068086656

Epoch: 6| Step: 6
Training loss: 2.2377216378516613
Validation loss: 2.4693464049692952

Epoch: 6| Step: 7
Training loss: 3.120813082606811
Validation loss: 2.474581948368961

Epoch: 6| Step: 8
Training loss: 2.4612677458534584
Validation loss: 2.4696321641593113

Epoch: 6| Step: 9
Training loss: 1.8084885502780537
Validation loss: 2.490624251419395

Epoch: 6| Step: 10
Training loss: 2.9748945393823254
Validation loss: 2.490386280089093

Epoch: 6| Step: 11
Training loss: 2.958837403528213
Validation loss: 2.4745717355645103

Epoch: 6| Step: 12
Training loss: 2.7817325816297807
Validation loss: 2.4709710379230505

Epoch: 6| Step: 13
Training loss: 2.4392693773371654
Validation loss: 2.483409814062248

Epoch: 92| Step: 0
Training loss: 2.4313617592354415
Validation loss: 2.47457139834855

Epoch: 6| Step: 1
Training loss: 2.9877364316460966
Validation loss: 2.475332104913866

Epoch: 6| Step: 2
Training loss: 2.886244965982983
Validation loss: 2.4782895665728395

Epoch: 6| Step: 3
Training loss: 2.1236224477812
Validation loss: 2.478191389595212

Epoch: 6| Step: 4
Training loss: 2.727505933298848
Validation loss: 2.4879496546585504

Epoch: 6| Step: 5
Training loss: 2.72646543663415
Validation loss: 2.4867075240824295

Epoch: 6| Step: 6
Training loss: 2.328967665176357
Validation loss: 2.486120894097296

Epoch: 6| Step: 7
Training loss: 2.208986641556364
Validation loss: 2.485606002523997

Epoch: 6| Step: 8
Training loss: 2.2141939047488925
Validation loss: 2.4851689539527393

Epoch: 6| Step: 9
Training loss: 2.8214956744666355
Validation loss: 2.4859385418684923

Epoch: 6| Step: 10
Training loss: 3.094740429718063
Validation loss: 2.4810257093652233

Epoch: 6| Step: 11
Training loss: 2.3101684569989986
Validation loss: 2.481927109581708

Epoch: 6| Step: 12
Training loss: 2.458461036167
Validation loss: 2.479237937437076

Epoch: 6| Step: 13
Training loss: 2.775124995535287
Validation loss: 2.4787136326448245

Epoch: 93| Step: 0
Training loss: 2.4523982046546022
Validation loss: 2.485944248320577

Epoch: 6| Step: 1
Training loss: 2.676944674650131
Validation loss: 2.4762473241774563

Epoch: 6| Step: 2
Training loss: 2.4587548643450963
Validation loss: 2.4715484982223073

Epoch: 6| Step: 3
Training loss: 2.7376932990401563
Validation loss: 2.4760618616376395

Epoch: 6| Step: 4
Training loss: 2.3812298631192124
Validation loss: 2.4791677993216186

Epoch: 6| Step: 5
Training loss: 2.5996156114923314
Validation loss: 2.4733296181050215

Epoch: 6| Step: 6
Training loss: 2.8165283176671934
Validation loss: 2.476958330453054

Epoch: 6| Step: 7
Training loss: 2.5237549384315847
Validation loss: 2.4688379376680385

Epoch: 6| Step: 8
Training loss: 2.24426131094111
Validation loss: 2.477224861082398

Epoch: 6| Step: 9
Training loss: 2.9896720492040583
Validation loss: 2.479359087702651

Epoch: 6| Step: 10
Training loss: 2.5446824073108116
Validation loss: 2.479666480536372

Epoch: 6| Step: 11
Training loss: 2.3156366468952627
Validation loss: 2.477401206301525

Epoch: 6| Step: 12
Training loss: 3.003608440821054
Validation loss: 2.4779266868154797

Epoch: 6| Step: 13
Training loss: 2.291900645940355
Validation loss: 2.4701551229206635

Epoch: 94| Step: 0
Training loss: 2.835504167726239
Validation loss: 2.4691875327579695

Epoch: 6| Step: 1
Training loss: 2.8366594052548675
Validation loss: 2.4679551756460256

Epoch: 6| Step: 2
Training loss: 2.6695145559305256
Validation loss: 2.4707131929657353

Epoch: 6| Step: 3
Training loss: 3.270250466929877
Validation loss: 2.472733731936601

Epoch: 6| Step: 4
Training loss: 2.282112794520745
Validation loss: 2.4694010523943506

Epoch: 6| Step: 5
Training loss: 2.568661516062469
Validation loss: 2.4764387739625424

Epoch: 6| Step: 6
Training loss: 2.705175074413399
Validation loss: 2.4843957448289173

Epoch: 6| Step: 7
Training loss: 2.563615416626295
Validation loss: 2.4732128639735174

Epoch: 6| Step: 8
Training loss: 2.479616322063713
Validation loss: 2.47620616318813

Epoch: 6| Step: 9
Training loss: 2.6520809891763553
Validation loss: 2.4807325488210354

Epoch: 6| Step: 10
Training loss: 2.5743591548156988
Validation loss: 2.4661598782540572

Epoch: 6| Step: 11
Training loss: 1.7880415356225852
Validation loss: 2.466890648926805

Epoch: 6| Step: 12
Training loss: 2.3793314536548533
Validation loss: 2.4720138510806717

Epoch: 6| Step: 13
Training loss: 2.201094970442823
Validation loss: 2.470076433999153

Epoch: 95| Step: 0
Training loss: 2.8923527683251207
Validation loss: 2.4717794413528362

Epoch: 6| Step: 1
Training loss: 2.4884844686503693
Validation loss: 2.4679297682116883

Epoch: 6| Step: 2
Training loss: 2.4547162574525903
Validation loss: 2.4710226020777606

Epoch: 6| Step: 3
Training loss: 2.863250940430471
Validation loss: 2.474314378248082

Epoch: 6| Step: 4
Training loss: 1.9592681709625843
Validation loss: 2.4758154447310106

Epoch: 6| Step: 5
Training loss: 2.4786389427679776
Validation loss: 2.4708371413803563

Epoch: 6| Step: 6
Training loss: 2.858759746126242
Validation loss: 2.473546659784304

Epoch: 6| Step: 7
Training loss: 2.674299601191608
Validation loss: 2.474201428700363

Epoch: 6| Step: 8
Training loss: 2.707250544925698
Validation loss: 2.4685127530602053

Epoch: 6| Step: 9
Training loss: 2.583532407740081
Validation loss: 2.4775029110755074

Epoch: 6| Step: 10
Training loss: 2.3491764573507448
Validation loss: 2.474918032101248

Epoch: 6| Step: 11
Training loss: 2.6546892854303974
Validation loss: 2.464734364705656

Epoch: 6| Step: 12
Training loss: 2.285727509392225
Validation loss: 2.4631398029813423

Epoch: 6| Step: 13
Training loss: 2.6173564799401547
Validation loss: 2.4603755894741175

Epoch: 96| Step: 0
Training loss: 2.829106450364694
Validation loss: 2.4650554455240252

Epoch: 6| Step: 1
Training loss: 2.8451658643700135
Validation loss: 2.4748614031585183

Epoch: 6| Step: 2
Training loss: 2.819892915491666
Validation loss: 2.462177380052312

Epoch: 6| Step: 3
Training loss: 2.6637785192472876
Validation loss: 2.460333952992521

Epoch: 6| Step: 4
Training loss: 2.409399968078517
Validation loss: 2.4622301854290973

Epoch: 6| Step: 5
Training loss: 2.1006307699118008
Validation loss: 2.466321418631688

Epoch: 6| Step: 6
Training loss: 2.9526985304557205
Validation loss: 2.4746518792544374

Epoch: 6| Step: 7
Training loss: 2.481619788607336
Validation loss: 2.471076078750729

Epoch: 6| Step: 8
Training loss: 2.4418892100428176
Validation loss: 2.479727550712771

Epoch: 6| Step: 9
Training loss: 2.642077165191466
Validation loss: 2.4753002074587003

Epoch: 6| Step: 10
Training loss: 2.3456712096470573
Validation loss: 2.4833061430123125

Epoch: 6| Step: 11
Training loss: 2.7084398004194847
Validation loss: 2.4806923913135304

Epoch: 6| Step: 12
Training loss: 2.0066987150849975
Validation loss: 2.4753247044840374

Epoch: 6| Step: 13
Training loss: 2.6042142533087076
Validation loss: 2.4746883452996453

Epoch: 97| Step: 0
Training loss: 2.62049688374058
Validation loss: 2.4776477862539883

Epoch: 6| Step: 1
Training loss: 2.2985497421979795
Validation loss: 2.4701105143396416

Epoch: 6| Step: 2
Training loss: 3.11235110987696
Validation loss: 2.470271402266873

Epoch: 6| Step: 3
Training loss: 2.1411655606680484
Validation loss: 2.4744435259554627

Epoch: 6| Step: 4
Training loss: 2.4148342047224705
Validation loss: 2.4684653621069743

Epoch: 6| Step: 5
Training loss: 2.99693141402846
Validation loss: 2.4648736467276327

Epoch: 6| Step: 6
Training loss: 2.694237536147116
Validation loss: 2.461582708801661

Epoch: 6| Step: 7
Training loss: 2.367817105705028
Validation loss: 2.4604319219630413

Epoch: 6| Step: 8
Training loss: 2.3178144680681907
Validation loss: 2.462358837309408

Epoch: 6| Step: 9
Training loss: 2.731980065162726
Validation loss: 2.4604144312509

Epoch: 6| Step: 10
Training loss: 2.4794193000191833
Validation loss: 2.454457676272715

Epoch: 6| Step: 11
Training loss: 2.5479583308467197
Validation loss: 2.4594097097840444

Epoch: 6| Step: 12
Training loss: 2.53486798591646
Validation loss: 2.464413096937809

Epoch: 6| Step: 13
Training loss: 2.476436575687599
Validation loss: 2.4631824728884526

Epoch: 98| Step: 0
Training loss: 2.3321972760728205
Validation loss: 2.464714083155182

Epoch: 6| Step: 1
Training loss: 2.2089407703200705
Validation loss: 2.463457930084685

Epoch: 6| Step: 2
Training loss: 2.6127007585257584
Validation loss: 2.470885307018408

Epoch: 6| Step: 3
Training loss: 2.2738869344068777
Validation loss: 2.4683150379070398

Epoch: 6| Step: 4
Training loss: 2.5071550975247687
Validation loss: 2.4703507203489807

Epoch: 6| Step: 5
Training loss: 3.0357087367672255
Validation loss: 2.477193661717345

Epoch: 6| Step: 6
Training loss: 2.1134996565743376
Validation loss: 2.4727963311971473

Epoch: 6| Step: 7
Training loss: 2.8266844900786885
Validation loss: 2.464780174922671

Epoch: 6| Step: 8
Training loss: 2.7159256570048895
Validation loss: 2.4665312313152055

Epoch: 6| Step: 9
Training loss: 2.8638675604625345
Validation loss: 2.463703953973799

Epoch: 6| Step: 10
Training loss: 3.0604937462981967
Validation loss: 2.457474369912752

Epoch: 6| Step: 11
Training loss: 2.2522662723379825
Validation loss: 2.456010146397601

Epoch: 6| Step: 12
Training loss: 2.8357599376230924
Validation loss: 2.4662088361276844

Epoch: 6| Step: 13
Training loss: 1.8562427071065242
Validation loss: 2.4660979564709584

Epoch: 99| Step: 0
Training loss: 2.6636970694486464
Validation loss: 2.4632831838438682

Epoch: 6| Step: 1
Training loss: 2.401287162846657
Validation loss: 2.469598567969934

Epoch: 6| Step: 2
Training loss: 2.2420324610896225
Validation loss: 2.4659520804572357

Epoch: 6| Step: 3
Training loss: 1.8865550979183432
Validation loss: 2.4696497022183688

Epoch: 6| Step: 4
Training loss: 2.6852397729238335
Validation loss: 2.470707982074854

Epoch: 6| Step: 5
Training loss: 2.366688087079892
Validation loss: 2.467731426662879

Epoch: 6| Step: 6
Training loss: 3.0110980432030523
Validation loss: 2.460160737342978

Epoch: 6| Step: 7
Training loss: 1.8574230944191252
Validation loss: 2.46619244980921

Epoch: 6| Step: 8
Training loss: 2.934757169591756
Validation loss: 2.4666330137620576

Epoch: 6| Step: 9
Training loss: 2.6585503883199824
Validation loss: 2.467499090115303

Epoch: 6| Step: 10
Training loss: 2.5355510198582474
Validation loss: 2.4609231292466482

Epoch: 6| Step: 11
Training loss: 2.8717277812893585
Validation loss: 2.4619113347604467

Epoch: 6| Step: 12
Training loss: 2.3945420033149656
Validation loss: 2.470726783046111

Epoch: 6| Step: 13
Training loss: 2.9954061303506387
Validation loss: 2.475508938105409

Epoch: 100| Step: 0
Training loss: 2.5796926645080513
Validation loss: 2.471796031772393

Epoch: 6| Step: 1
Training loss: 2.237253642238781
Validation loss: 2.47772106263503

Epoch: 6| Step: 2
Training loss: 2.1691770193659194
Validation loss: 2.4785080336706744

Epoch: 6| Step: 3
Training loss: 2.8983471797227023
Validation loss: 2.471164576845792

Epoch: 6| Step: 4
Training loss: 3.0872172731998244
Validation loss: 2.474643272482868

Epoch: 6| Step: 5
Training loss: 2.051830437531002
Validation loss: 2.4729419320242476

Epoch: 6| Step: 6
Training loss: 2.9571684751328973
Validation loss: 2.468106085262945

Epoch: 6| Step: 7
Training loss: 2.7397176808726535
Validation loss: 2.4742833670202593

Epoch: 6| Step: 8
Training loss: 2.2714067021060034
Validation loss: 2.466483882841857

Epoch: 6| Step: 9
Training loss: 1.6230235918672564
Validation loss: 2.461446477339759

Epoch: 6| Step: 10
Training loss: 2.527024969782945
Validation loss: 2.4631061101713585

Epoch: 6| Step: 11
Training loss: 2.9231254635382893
Validation loss: 2.4663990754103806

Epoch: 6| Step: 12
Training loss: 2.9117836722097947
Validation loss: 2.4653242784391947

Epoch: 6| Step: 13
Training loss: 2.5050647929753023
Validation loss: 2.4694070706175304

Epoch: 101| Step: 0
Training loss: 2.9645799763263523
Validation loss: 2.461811988103581

Epoch: 6| Step: 1
Training loss: 2.9553009574465463
Validation loss: 2.4678486333414713

Epoch: 6| Step: 2
Training loss: 2.0584925241211813
Validation loss: 2.46009074180739

Epoch: 6| Step: 3
Training loss: 2.3697232302890114
Validation loss: 2.4618191547553234

Epoch: 6| Step: 4
Training loss: 1.959567986191059
Validation loss: 2.470130630930742

Epoch: 6| Step: 5
Training loss: 2.3676755295067147
Validation loss: 2.4714220451034654

Epoch: 6| Step: 6
Training loss: 2.366100603113992
Validation loss: 2.470053011033215

Epoch: 6| Step: 7
Training loss: 2.7410107122613447
Validation loss: 2.467486931619046

Epoch: 6| Step: 8
Training loss: 2.484848936927427
Validation loss: 2.471189412345652

Epoch: 6| Step: 9
Training loss: 2.020086038853325
Validation loss: 2.4799657276564417

Epoch: 6| Step: 10
Training loss: 2.3648113751345625
Validation loss: 2.4721983957273563

Epoch: 6| Step: 11
Training loss: 3.021814664851797
Validation loss: 2.473545711975294

Epoch: 6| Step: 12
Training loss: 2.8693247632793275
Validation loss: 2.466820876567798

Epoch: 6| Step: 13
Training loss: 3.057534064713714
Validation loss: 2.4675749948165806

Epoch: 102| Step: 0
Training loss: 2.288163460994637
Validation loss: 2.464895095733733

Epoch: 6| Step: 1
Training loss: 2.37861037645892
Validation loss: 2.459011167623182

Epoch: 6| Step: 2
Training loss: 2.880965139742856
Validation loss: 2.45808799510822

Epoch: 6| Step: 3
Training loss: 2.1932530636385006
Validation loss: 2.470823640359411

Epoch: 6| Step: 4
Training loss: 2.3644701780784763
Validation loss: 2.472497389573126

Epoch: 6| Step: 5
Training loss: 2.7369313524729506
Validation loss: 2.4768755020037134

Epoch: 6| Step: 6
Training loss: 2.581890800684439
Validation loss: 2.4879382828839414

Epoch: 6| Step: 7
Training loss: 2.505057369344274
Validation loss: 2.4785213004453834

Epoch: 6| Step: 8
Training loss: 3.2632437607262723
Validation loss: 2.4830781442833563

Epoch: 6| Step: 9
Training loss: 2.7301629458694467
Validation loss: 2.476195363329861

Epoch: 6| Step: 10
Training loss: 2.1180206573890996
Validation loss: 2.4585699570996224

Epoch: 6| Step: 11
Training loss: 2.08660352268088
Validation loss: 2.4759636605224937

Epoch: 6| Step: 12
Training loss: 2.4436171629722123
Validation loss: 2.466168724096152

Epoch: 6| Step: 13
Training loss: 3.0664028289192697
Validation loss: 2.4674795398681977

Epoch: 103| Step: 0
Training loss: 2.963709356639879
Validation loss: 2.4603311750485815

Epoch: 6| Step: 1
Training loss: 2.040629986556826
Validation loss: 2.4661995473381

Epoch: 6| Step: 2
Training loss: 2.6156129570140263
Validation loss: 2.460506841528976

Epoch: 6| Step: 3
Training loss: 2.9553474258177492
Validation loss: 2.4708152695285532

Epoch: 6| Step: 4
Training loss: 2.7230649884860543
Validation loss: 2.464918551592136

Epoch: 6| Step: 5
Training loss: 2.388893647398633
Validation loss: 2.4682008156587374

Epoch: 6| Step: 6
Training loss: 2.6278186379128616
Validation loss: 2.4688241359991157

Epoch: 6| Step: 7
Training loss: 2.5417989685978584
Validation loss: 2.4640692588827955

Epoch: 6| Step: 8
Training loss: 2.5638924513829164
Validation loss: 2.4572851780612646

Epoch: 6| Step: 9
Training loss: 2.30683896781006
Validation loss: 2.4644757543728035

Epoch: 6| Step: 10
Training loss: 2.579784437237876
Validation loss: 2.4594091442925774

Epoch: 6| Step: 11
Training loss: 2.5506637569549815
Validation loss: 2.4662725677205293

Epoch: 6| Step: 12
Training loss: 2.2568280142723856
Validation loss: 2.462035548758429

Epoch: 6| Step: 13
Training loss: 2.662397563557702
Validation loss: 2.4637827093313343

Epoch: 104| Step: 0
Training loss: 1.992558343815689
Validation loss: 2.4541169123201807

Epoch: 6| Step: 1
Training loss: 2.1005843484855684
Validation loss: 2.456646863408113

Epoch: 6| Step: 2
Training loss: 2.473283492286182
Validation loss: 2.4566824968242926

Epoch: 6| Step: 3
Training loss: 2.228946306501811
Validation loss: 2.448056680990305

Epoch: 6| Step: 4
Training loss: 2.631187865912253
Validation loss: 2.4508720630005505

Epoch: 6| Step: 5
Training loss: 3.212492999948675
Validation loss: 2.4497596836951736

Epoch: 6| Step: 6
Training loss: 3.1011123138331853
Validation loss: 2.45167781476776

Epoch: 6| Step: 7
Training loss: 2.7655991375247315
Validation loss: 2.4584550558009455

Epoch: 6| Step: 8
Training loss: 2.629669758764612
Validation loss: 2.4590353421400097

Epoch: 6| Step: 9
Training loss: 2.2436276373265653
Validation loss: 2.4535330657752086

Epoch: 6| Step: 10
Training loss: 3.203212085563505
Validation loss: 2.461240412724261

Epoch: 6| Step: 11
Training loss: 2.178399474529381
Validation loss: 2.4606901821617195

Epoch: 6| Step: 12
Training loss: 2.570189313632394
Validation loss: 2.4651230030695537

Epoch: 6| Step: 13
Training loss: 1.96786406429024
Validation loss: 2.465588601685371

Epoch: 105| Step: 0
Training loss: 1.786053922234338
Validation loss: 2.470822683464716

Epoch: 6| Step: 1
Training loss: 2.68408891532283
Validation loss: 2.4735811822751206

Epoch: 6| Step: 2
Training loss: 2.508569335818698
Validation loss: 2.4682804739592004

Epoch: 6| Step: 3
Training loss: 2.101545142346708
Validation loss: 2.4665031832139537

Epoch: 6| Step: 4
Training loss: 2.4423969669534373
Validation loss: 2.4650136785275993

Epoch: 6| Step: 5
Training loss: 2.3941675006330794
Validation loss: 2.4649399437852226

Epoch: 6| Step: 6
Training loss: 3.152492439327506
Validation loss: 2.4625876248126835

Epoch: 6| Step: 7
Training loss: 3.09610389016681
Validation loss: 2.465409993191725

Epoch: 6| Step: 8
Training loss: 2.545487757410399
Validation loss: 2.4552019725830996

Epoch: 6| Step: 9
Training loss: 2.669149157224216
Validation loss: 2.4576655359097006

Epoch: 6| Step: 10
Training loss: 2.2277844739936445
Validation loss: 2.454073955250565

Epoch: 6| Step: 11
Training loss: 2.6751014904128008
Validation loss: 2.4491082125456245

Epoch: 6| Step: 12
Training loss: 2.642229033176993
Validation loss: 2.454616312006066

Epoch: 6| Step: 13
Training loss: 2.284848758191412
Validation loss: 2.455842151382229

Epoch: 106| Step: 0
Training loss: 2.4868947812022517
Validation loss: 2.4558212786187603

Epoch: 6| Step: 1
Training loss: 2.057331429270277
Validation loss: 2.447157499944353

Epoch: 6| Step: 2
Training loss: 2.2004561254855246
Validation loss: 2.4526928401548305

Epoch: 6| Step: 3
Training loss: 2.2084874033414303
Validation loss: 2.450170856149535

Epoch: 6| Step: 4
Training loss: 3.0209958964486963
Validation loss: 2.4515144828079674

Epoch: 6| Step: 5
Training loss: 2.0151678942077513
Validation loss: 2.4536399705741627

Epoch: 6| Step: 6
Training loss: 2.746458287142981
Validation loss: 2.4565668278683406

Epoch: 6| Step: 7
Training loss: 2.7088720715050894
Validation loss: 2.458795331657632

Epoch: 6| Step: 8
Training loss: 2.7618138837817985
Validation loss: 2.4532795673116206

Epoch: 6| Step: 9
Training loss: 2.5082706971654374
Validation loss: 2.4641813828053944

Epoch: 6| Step: 10
Training loss: 2.738757648466043
Validation loss: 2.46548920979895

Epoch: 6| Step: 11
Training loss: 2.2935799559050998
Validation loss: 2.471652405205308

Epoch: 6| Step: 12
Training loss: 2.7379765796816105
Validation loss: 2.463941905848868

Epoch: 6| Step: 13
Training loss: 3.0231736336629598
Validation loss: 2.4668590369689447

Epoch: 107| Step: 0
Training loss: 2.5608908089832076
Validation loss: 2.4656157093332367

Epoch: 6| Step: 1
Training loss: 1.7525028994940308
Validation loss: 2.463521240880915

Epoch: 6| Step: 2
Training loss: 2.2495464291636416
Validation loss: 2.459844098074442

Epoch: 6| Step: 3
Training loss: 2.6633144010683356
Validation loss: 2.4567895718872745

Epoch: 6| Step: 4
Training loss: 2.888939608430267
Validation loss: 2.4570290181888215

Epoch: 6| Step: 5
Training loss: 2.9003000367271574
Validation loss: 2.4541074239405565

Epoch: 6| Step: 6
Training loss: 2.436787819135733
Validation loss: 2.4556620006471213

Epoch: 6| Step: 7
Training loss: 2.425686304565522
Validation loss: 2.4458162806456385

Epoch: 6| Step: 8
Training loss: 2.5178002850606838
Validation loss: 2.447373063351658

Epoch: 6| Step: 9
Training loss: 2.724220297320413
Validation loss: 2.4468840078007004

Epoch: 6| Step: 10
Training loss: 2.4185490566638803
Validation loss: 2.4507136713272235

Epoch: 6| Step: 11
Training loss: 2.4722220233912395
Validation loss: 2.4545118295355093

Epoch: 6| Step: 12
Training loss: 2.3855355134590055
Validation loss: 2.4537997279647996

Epoch: 6| Step: 13
Training loss: 2.9736610348619674
Validation loss: 2.459429728098204

Epoch: 108| Step: 0
Training loss: 1.973785077412071
Validation loss: 2.4552733293901032

Epoch: 6| Step: 1
Training loss: 1.8153625771367288
Validation loss: 2.464037151121619

Epoch: 6| Step: 2
Training loss: 2.0031185870134887
Validation loss: 2.4521382122872315

Epoch: 6| Step: 3
Training loss: 2.2648369832775015
Validation loss: 2.452675099838011

Epoch: 6| Step: 4
Training loss: 2.4547653059644916
Validation loss: 2.451691486052349

Epoch: 6| Step: 5
Training loss: 2.8621799073471053
Validation loss: 2.4532288855324302

Epoch: 6| Step: 6
Training loss: 3.011917760782536
Validation loss: 2.4509133414091515

Epoch: 6| Step: 7
Training loss: 2.275208822035553
Validation loss: 2.457957098883167

Epoch: 6| Step: 8
Training loss: 2.5148503787239838
Validation loss: 2.464760852997605

Epoch: 6| Step: 9
Training loss: 2.605157973758464
Validation loss: 2.457092510808071

Epoch: 6| Step: 10
Training loss: 2.758076857737296
Validation loss: 2.456059217606823

Epoch: 6| Step: 11
Training loss: 2.9564050291030757
Validation loss: 2.460497749235078

Epoch: 6| Step: 12
Training loss: 3.0233185816204813
Validation loss: 2.4512930669118567

Epoch: 6| Step: 13
Training loss: 2.7086326629334514
Validation loss: 2.461121591615523

Epoch: 109| Step: 0
Training loss: 2.427376288768973
Validation loss: 2.459908075333814

Epoch: 6| Step: 1
Training loss: 1.96844255983605
Validation loss: 2.453127802302548

Epoch: 6| Step: 2
Training loss: 2.2861853735681397
Validation loss: 2.462148749768819

Epoch: 6| Step: 3
Training loss: 2.380814211560205
Validation loss: 2.450547113118888

Epoch: 6| Step: 4
Training loss: 3.2846026050454395
Validation loss: 2.4494948365893623

Epoch: 6| Step: 5
Training loss: 3.0702227319693547
Validation loss: 2.4494055636686656

Epoch: 6| Step: 6
Training loss: 2.37250015805468
Validation loss: 2.4541491498683614

Epoch: 6| Step: 7
Training loss: 2.9101962298008814
Validation loss: 2.446305923251525

Epoch: 6| Step: 8
Training loss: 2.44893731016684
Validation loss: 2.4470829348761662

Epoch: 6| Step: 9
Training loss: 2.8839853273566085
Validation loss: 2.445433446068611

Epoch: 6| Step: 10
Training loss: 2.7959714314388773
Validation loss: 2.455454471525178

Epoch: 6| Step: 11
Training loss: 2.246441464253929
Validation loss: 2.459479506589543

Epoch: 6| Step: 12
Training loss: 1.75498239513816
Validation loss: 2.4638534870086826

Epoch: 6| Step: 13
Training loss: 2.3668641728832727
Validation loss: 2.4738631273655876

Epoch: 110| Step: 0
Training loss: 2.660125149672505
Validation loss: 2.468918533045172

Epoch: 6| Step: 1
Training loss: 2.221448305258759
Validation loss: 2.4645814751053483

Epoch: 6| Step: 2
Training loss: 2.4688819173986642
Validation loss: 2.4621793731853576

Epoch: 6| Step: 3
Training loss: 2.1899747746029443
Validation loss: 2.4637875477926174

Epoch: 6| Step: 4
Training loss: 2.6216176357967065
Validation loss: 2.4624110255812313

Epoch: 6| Step: 5
Training loss: 2.7352809604084634
Validation loss: 2.4577266515639984

Epoch: 6| Step: 6
Training loss: 2.0732017078302096
Validation loss: 2.463878734882605

Epoch: 6| Step: 7
Training loss: 3.146615459569668
Validation loss: 2.464005929913961

Epoch: 6| Step: 8
Training loss: 2.208833805689882
Validation loss: 2.454267450431799

Epoch: 6| Step: 9
Training loss: 2.1905311292270633
Validation loss: 2.456890811757688

Epoch: 6| Step: 10
Training loss: 2.4571738876398475
Validation loss: 2.4558504033560644

Epoch: 6| Step: 11
Training loss: 3.3096086370973703
Validation loss: 2.4587567552048046

Epoch: 6| Step: 12
Training loss: 2.3947341608944783
Validation loss: 2.454490249320166

Epoch: 6| Step: 13
Training loss: 2.632186135965714
Validation loss: 2.462014728502087

Epoch: 111| Step: 0
Training loss: 2.6912413880192254
Validation loss: 2.460954680206235

Epoch: 6| Step: 1
Training loss: 2.52114650788146
Validation loss: 2.460890512169227

Epoch: 6| Step: 2
Training loss: 2.811176412458039
Validation loss: 2.457674590176606

Epoch: 6| Step: 3
Training loss: 2.420766859952974
Validation loss: 2.4537567491482277

Epoch: 6| Step: 4
Training loss: 2.002925283203044
Validation loss: 2.4519846183030958

Epoch: 6| Step: 5
Training loss: 2.3828951461717582
Validation loss: 2.452520826577285

Epoch: 6| Step: 6
Training loss: 2.1179148420553275
Validation loss: 2.457479293557497

Epoch: 6| Step: 7
Training loss: 2.6704643942911424
Validation loss: 2.4528167109737407

Epoch: 6| Step: 8
Training loss: 2.862939499344039
Validation loss: 2.457708430203856

Epoch: 6| Step: 9
Training loss: 2.2314131519495897
Validation loss: 2.449331488846216

Epoch: 6| Step: 10
Training loss: 2.110241295274023
Validation loss: 2.451045886445591

Epoch: 6| Step: 11
Training loss: 2.914750986864862
Validation loss: 2.447154447237908

Epoch: 6| Step: 12
Training loss: 2.83460837079546
Validation loss: 2.4522391337570313

Epoch: 6| Step: 13
Training loss: 2.6813724658803464
Validation loss: 2.4499396034503595

Epoch: 112| Step: 0
Training loss: 2.5537901069229014
Validation loss: 2.4629717779944587

Epoch: 6| Step: 1
Training loss: 2.9879956077737457
Validation loss: 2.4572287410900975

Epoch: 6| Step: 2
Training loss: 2.2191157509662545
Validation loss: 2.457871641565885

Epoch: 6| Step: 3
Training loss: 2.4369827112861144
Validation loss: 2.4587706861092844

Epoch: 6| Step: 4
Training loss: 2.145953153456201
Validation loss: 2.4623445394018373

Epoch: 6| Step: 5
Training loss: 2.8914602361719037
Validation loss: 2.4606715790313634

Epoch: 6| Step: 6
Training loss: 2.616345261517642
Validation loss: 2.4636840187758535

Epoch: 6| Step: 7
Training loss: 2.3252574490988827
Validation loss: 2.46250156170171

Epoch: 6| Step: 8
Training loss: 3.13961183517739
Validation loss: 2.4691945573062175

Epoch: 6| Step: 9
Training loss: 2.139690780046572
Validation loss: 2.461105389393436

Epoch: 6| Step: 10
Training loss: 1.9636327450892312
Validation loss: 2.4488926720642867

Epoch: 6| Step: 11
Training loss: 2.8132461405827365
Validation loss: 2.4556281162370674

Epoch: 6| Step: 12
Training loss: 2.563052606311413
Validation loss: 2.4437895593587653

Epoch: 6| Step: 13
Training loss: 2.4065204815130694
Validation loss: 2.4471536678228865

Epoch: 113| Step: 0
Training loss: 2.7512084733185285
Validation loss: 2.4501235320938286

Epoch: 6| Step: 1
Training loss: 2.7375320084324826
Validation loss: 2.4446750902929404

Epoch: 6| Step: 2
Training loss: 2.561590917340533
Validation loss: 2.4455067777797774

Epoch: 6| Step: 3
Training loss: 2.177575842043524
Validation loss: 2.4557089914333887

Epoch: 6| Step: 4
Training loss: 2.369104899288807
Validation loss: 2.4482433074108676

Epoch: 6| Step: 5
Training loss: 3.0707067959584817
Validation loss: 2.4470790945187755

Epoch: 6| Step: 6
Training loss: 2.3548264268216808
Validation loss: 2.4482838510854164

Epoch: 6| Step: 7
Training loss: 2.448842873090011
Validation loss: 2.450631171947342

Epoch: 6| Step: 8
Training loss: 2.0090049438491686
Validation loss: 2.4423361998407116

Epoch: 6| Step: 9
Training loss: 2.3507573469778027
Validation loss: 2.4476081383168515

Epoch: 6| Step: 10
Training loss: 2.6684111511809467
Validation loss: 2.4541645965394734

Epoch: 6| Step: 11
Training loss: 2.836023586847657
Validation loss: 2.4486847396236944

Epoch: 6| Step: 12
Training loss: 2.611818734005903
Validation loss: 2.457185288590425

Epoch: 6| Step: 13
Training loss: 2.437155968278313
Validation loss: 2.459220521398153

Epoch: 114| Step: 0
Training loss: 2.810435575888674
Validation loss: 2.458378505830558

Epoch: 6| Step: 1
Training loss: 2.255853773498186
Validation loss: 2.4556887243398777

Epoch: 6| Step: 2
Training loss: 2.3349526667239027
Validation loss: 2.4582510842826184

Epoch: 6| Step: 3
Training loss: 1.9109370034342734
Validation loss: 2.457657225356789

Epoch: 6| Step: 4
Training loss: 2.929095154961485
Validation loss: 2.4538027238225912

Epoch: 6| Step: 5
Training loss: 2.878936063490472
Validation loss: 2.451748066693393

Epoch: 6| Step: 6
Training loss: 2.299818371774575
Validation loss: 2.4580507331529065

Epoch: 6| Step: 7
Training loss: 2.5755911657734907
Validation loss: 2.4598596220617623

Epoch: 6| Step: 8
Training loss: 2.643391170454233
Validation loss: 2.4492732300040427

Epoch: 6| Step: 9
Training loss: 2.4872378762314242
Validation loss: 2.456428538815152

Epoch: 6| Step: 10
Training loss: 2.439675167536798
Validation loss: 2.4581631639280492

Epoch: 6| Step: 11
Training loss: 2.196410532399888
Validation loss: 2.4498237864384884

Epoch: 6| Step: 12
Training loss: 3.0407772767062706
Validation loss: 2.455670010503808

Epoch: 6| Step: 13
Training loss: 2.4102892970330028
Validation loss: 2.454283697795288

Epoch: 115| Step: 0
Training loss: 1.9538579557323477
Validation loss: 2.4482792579006056

Epoch: 6| Step: 1
Training loss: 2.952695462106338
Validation loss: 2.4446041068280326

Epoch: 6| Step: 2
Training loss: 2.395745969644552
Validation loss: 2.44890037953742

Epoch: 6| Step: 3
Training loss: 2.138883230138562
Validation loss: 2.457788299227991

Epoch: 6| Step: 4
Training loss: 2.5941056157113356
Validation loss: 2.458160108724058

Epoch: 6| Step: 5
Training loss: 2.0753748773414995
Validation loss: 2.471382411611816

Epoch: 6| Step: 6
Training loss: 2.4698534081082517
Validation loss: 2.4706677259640895

Epoch: 6| Step: 7
Training loss: 2.5144904759246205
Validation loss: 2.478823547234018

Epoch: 6| Step: 8
Training loss: 3.2058186439816874
Validation loss: 2.4555859542516645

Epoch: 6| Step: 9
Training loss: 2.313273429406476
Validation loss: 2.453103342790837

Epoch: 6| Step: 10
Training loss: 3.053187321443645
Validation loss: 2.450280713199236

Epoch: 6| Step: 11
Training loss: 2.493474072174884
Validation loss: 2.461660757201929

Epoch: 6| Step: 12
Training loss: 2.4260609537692592
Validation loss: 2.471691777141841

Epoch: 6| Step: 13
Training loss: 2.7249121275566437
Validation loss: 2.4750510897645492

Epoch: 116| Step: 0
Training loss: 2.5660049844754362
Validation loss: 2.481951757336174

Epoch: 6| Step: 1
Training loss: 2.4737217733151966
Validation loss: 2.487029930249086

Epoch: 6| Step: 2
Training loss: 2.674893107907849
Validation loss: 2.482724271134515

Epoch: 6| Step: 3
Training loss: 2.511326214861859
Validation loss: 2.4846689462206903

Epoch: 6| Step: 4
Training loss: 3.536695214916447
Validation loss: 2.4738510322724956

Epoch: 6| Step: 5
Training loss: 2.017415988312143
Validation loss: 2.4627629931961033

Epoch: 6| Step: 6
Training loss: 2.64284381531702
Validation loss: 2.4536792752578056

Epoch: 6| Step: 7
Training loss: 2.512159151709068
Validation loss: 2.45715567835233

Epoch: 6| Step: 8
Training loss: 2.9993988070503983
Validation loss: 2.450356721534555

Epoch: 6| Step: 9
Training loss: 2.125524568324666
Validation loss: 2.455251302708607

Epoch: 6| Step: 10
Training loss: 2.690437397192901
Validation loss: 2.4537361177533374

Epoch: 6| Step: 11
Training loss: 1.8715003095540457
Validation loss: 2.469302007068975

Epoch: 6| Step: 12
Training loss: 2.4555480070367306
Validation loss: 2.46167944970898

Epoch: 6| Step: 13
Training loss: 2.2353620149793847
Validation loss: 2.455869738754783

Epoch: 117| Step: 0
Training loss: 2.4191635212060354
Validation loss: 2.4492571846492956

Epoch: 6| Step: 1
Training loss: 2.3332006439446147
Validation loss: 2.464329072848572

Epoch: 6| Step: 2
Training loss: 2.785588769914623
Validation loss: 2.4522128018857625

Epoch: 6| Step: 3
Training loss: 2.3193595804715987
Validation loss: 2.4548948993962463

Epoch: 6| Step: 4
Training loss: 3.025572030703628
Validation loss: 2.45062920995894

Epoch: 6| Step: 5
Training loss: 2.4128402035252567
Validation loss: 2.450432500486996

Epoch: 6| Step: 6
Training loss: 2.5946330210486446
Validation loss: 2.4549249739360732

Epoch: 6| Step: 7
Training loss: 2.577718529303519
Validation loss: 2.4474566304693037

Epoch: 6| Step: 8
Training loss: 2.842454552333261
Validation loss: 2.450702215948478

Epoch: 6| Step: 9
Training loss: 2.7191132927567465
Validation loss: 2.4532179116312194

Epoch: 6| Step: 10
Training loss: 1.932987680722532
Validation loss: 2.456007743776127

Epoch: 6| Step: 11
Training loss: 2.160802485840041
Validation loss: 2.460587556370161

Epoch: 6| Step: 12
Training loss: 2.803150574090113
Validation loss: 2.464544311326304

Epoch: 6| Step: 13
Training loss: 2.177695618699417
Validation loss: 2.4582595059790924

Epoch: 118| Step: 0
Training loss: 2.4168702620762446
Validation loss: 2.4641725782061834

Epoch: 6| Step: 1
Training loss: 2.4280433120635116
Validation loss: 2.4700270460297986

Epoch: 6| Step: 2
Training loss: 2.4560345931397167
Validation loss: 2.4623579658817514

Epoch: 6| Step: 3
Training loss: 2.3467741719820907
Validation loss: 2.4659615554896375

Epoch: 6| Step: 4
Training loss: 2.594616940400515
Validation loss: 2.4591403757170287

Epoch: 6| Step: 5
Training loss: 2.801461322104163
Validation loss: 2.4626246164227785

Epoch: 6| Step: 6
Training loss: 2.3942871965058425
Validation loss: 2.4571445845284203

Epoch: 6| Step: 7
Training loss: 2.9112664684388387
Validation loss: 2.458804963555618

Epoch: 6| Step: 8
Training loss: 2.4546346696380623
Validation loss: 2.462861728725583

Epoch: 6| Step: 9
Training loss: 3.0438300151608084
Validation loss: 2.466268974755815

Epoch: 6| Step: 10
Training loss: 2.857430886328067
Validation loss: 2.467485144073485

Epoch: 6| Step: 11
Training loss: 2.3871057074944213
Validation loss: 2.4634927068661345

Epoch: 6| Step: 12
Training loss: 1.721402981787823
Validation loss: 2.4633931981539487

Epoch: 6| Step: 13
Training loss: 2.3729679047431125
Validation loss: 2.449285681710947

Epoch: 119| Step: 0
Training loss: 2.5619383405759564
Validation loss: 2.448325603227074

Epoch: 6| Step: 1
Training loss: 2.7816026442626285
Validation loss: 2.455369040390188

Epoch: 6| Step: 2
Training loss: 2.5822323534699834
Validation loss: 2.4416367241474073

Epoch: 6| Step: 3
Training loss: 2.729071482000724
Validation loss: 2.443609520141936

Epoch: 6| Step: 4
Training loss: 2.112491594105988
Validation loss: 2.4581245856370018

Epoch: 6| Step: 5
Training loss: 1.7358970493166972
Validation loss: 2.4451469552226266

Epoch: 6| Step: 6
Training loss: 3.322261319166081
Validation loss: 2.443567362185772

Epoch: 6| Step: 7
Training loss: 2.421227842435348
Validation loss: 2.4455900512090727

Epoch: 6| Step: 8
Training loss: 2.3841484952161034
Validation loss: 2.4410925254158626

Epoch: 6| Step: 9
Training loss: 2.735403772010442
Validation loss: 2.444902525833

Epoch: 6| Step: 10
Training loss: 2.518049883977814
Validation loss: 2.4434618462111013

Epoch: 6| Step: 11
Training loss: 2.2817954887469254
Validation loss: 2.4504322734617494

Epoch: 6| Step: 12
Training loss: 2.101160174009412
Validation loss: 2.456333613246543

Epoch: 6| Step: 13
Training loss: 2.9697573910147637
Validation loss: 2.4522313476546924

Epoch: 120| Step: 0
Training loss: 2.566133853385519
Validation loss: 2.4467217850085183

Epoch: 6| Step: 1
Training loss: 2.8567093895025053
Validation loss: 2.4498288633300285

Epoch: 6| Step: 2
Training loss: 2.5839982151344207
Validation loss: 2.4612248651562094

Epoch: 6| Step: 3
Training loss: 2.366613337314419
Validation loss: 2.4658294818569204

Epoch: 6| Step: 4
Training loss: 2.752623693612862
Validation loss: 2.4694790709229717

Epoch: 6| Step: 5
Training loss: 2.3105547172045697
Validation loss: 2.4649382914182203

Epoch: 6| Step: 6
Training loss: 3.0178495908434706
Validation loss: 2.468412376205445

Epoch: 6| Step: 7
Training loss: 3.0256457876883327
Validation loss: 2.4728519549067074

Epoch: 6| Step: 8
Training loss: 2.3612888481211853
Validation loss: 2.462489338188521

Epoch: 6| Step: 9
Training loss: 1.6992501793070378
Validation loss: 2.46534753679847

Epoch: 6| Step: 10
Training loss: 2.8673177164635932
Validation loss: 2.456199582062134

Epoch: 6| Step: 11
Training loss: 2.258023050911949
Validation loss: 2.446507674732666

Epoch: 6| Step: 12
Training loss: 2.136464998286611
Validation loss: 2.455383597392459

Epoch: 6| Step: 13
Training loss: 2.502918637802375
Validation loss: 2.460116730921053

Epoch: 121| Step: 0
Training loss: 2.884678843851691
Validation loss: 2.4471074220872646

Epoch: 6| Step: 1
Training loss: 3.113346649593435
Validation loss: 2.454445445078898

Epoch: 6| Step: 2
Training loss: 1.990864572526099
Validation loss: 2.4584156820007066

Epoch: 6| Step: 3
Training loss: 2.6996179663623963
Validation loss: 2.4665700889273148

Epoch: 6| Step: 4
Training loss: 2.7019993196679986
Validation loss: 2.4740400494916504

Epoch: 6| Step: 5
Training loss: 2.812650295056514
Validation loss: 2.471016032994517

Epoch: 6| Step: 6
Training loss: 2.4552811786741082
Validation loss: 2.4804430622362674

Epoch: 6| Step: 7
Training loss: 2.945712682113856
Validation loss: 2.474615798054674

Epoch: 6| Step: 8
Training loss: 1.983231102154568
Validation loss: 2.4742365362782563

Epoch: 6| Step: 9
Training loss: 2.380349609278044
Validation loss: 2.4801874917436506

Epoch: 6| Step: 10
Training loss: 2.6669592895490206
Validation loss: 2.4735283380898627

Epoch: 6| Step: 11
Training loss: 2.3418718060364028
Validation loss: 2.4770749000253898

Epoch: 6| Step: 12
Training loss: 2.6603770787562944
Validation loss: 2.4792109146229957

Epoch: 6| Step: 13
Training loss: 1.9045049465653008
Validation loss: 2.473540362470175

Epoch: 122| Step: 0
Training loss: 3.073034734666816
Validation loss: 2.476474884761777

Epoch: 6| Step: 1
Training loss: 2.593028048497862
Validation loss: 2.4667736464147003

Epoch: 6| Step: 2
Training loss: 2.4949957353329952
Validation loss: 2.4643839202159583

Epoch: 6| Step: 3
Training loss: 2.811073619691364
Validation loss: 2.4679219591568216

Epoch: 6| Step: 4
Training loss: 2.3993613982951603
Validation loss: 2.4681100941518075

Epoch: 6| Step: 5
Training loss: 2.611824667491959
Validation loss: 2.474324800888343

Epoch: 6| Step: 6
Training loss: 3.2403835931396263
Validation loss: 2.47722662555917

Epoch: 6| Step: 7
Training loss: 2.598505555326606
Validation loss: 2.4619782522797156

Epoch: 6| Step: 8
Training loss: 2.0577469591552306
Validation loss: 2.463941357524753

Epoch: 6| Step: 9
Training loss: 2.0787742575711365
Validation loss: 2.468101561167693

Epoch: 6| Step: 10
Training loss: 2.4574766013194744
Validation loss: 2.4684556391222947

Epoch: 6| Step: 11
Training loss: 2.3913475390819587
Validation loss: 2.464499778545811

Epoch: 6| Step: 12
Training loss: 2.177824365783587
Validation loss: 2.4607716014993524

Epoch: 6| Step: 13
Training loss: 2.329950832781394
Validation loss: 2.4703350853495762

Epoch: 123| Step: 0
Training loss: 2.5685895809378994
Validation loss: 2.4615572517354893

Epoch: 6| Step: 1
Training loss: 2.1980252593153655
Validation loss: 2.46676612365676

Epoch: 6| Step: 2
Training loss: 2.0017370786625013
Validation loss: 2.4641380529082966

Epoch: 6| Step: 3
Training loss: 3.298637027750208
Validation loss: 2.4691819565559565

Epoch: 6| Step: 4
Training loss: 1.7090093469157677
Validation loss: 2.4678524655307044

Epoch: 6| Step: 5
Training loss: 3.1301550498316097
Validation loss: 2.4703527390582543

Epoch: 6| Step: 6
Training loss: 2.3336121074719443
Validation loss: 2.467840131656718

Epoch: 6| Step: 7
Training loss: 2.8170580063529447
Validation loss: 2.4701473611176303

Epoch: 6| Step: 8
Training loss: 2.7703514444934743
Validation loss: 2.463514998589361

Epoch: 6| Step: 9
Training loss: 2.415698438468195
Validation loss: 2.4578571397171616

Epoch: 6| Step: 10
Training loss: 2.4445382254364763
Validation loss: 2.4535259478005234

Epoch: 6| Step: 11
Training loss: 2.5560381290893135
Validation loss: 2.4613361661418733

Epoch: 6| Step: 12
Training loss: 2.595347085133233
Validation loss: 2.4595870899617864

Epoch: 6| Step: 13
Training loss: 2.1671266312085593
Validation loss: 2.4675981272903833

Epoch: 124| Step: 0
Training loss: 2.520964837125257
Validation loss: 2.470743863017449

Epoch: 6| Step: 1
Training loss: 2.757587456098799
Validation loss: 2.4728568640025577

Epoch: 6| Step: 2
Training loss: 2.3176420623791505
Validation loss: 2.4645941154994384

Epoch: 6| Step: 3
Training loss: 2.6288937345889867
Validation loss: 2.4746469335759254

Epoch: 6| Step: 4
Training loss: 2.489636493790975
Validation loss: 2.46946783132198

Epoch: 6| Step: 5
Training loss: 1.961139683729933
Validation loss: 2.4691091992422685

Epoch: 6| Step: 6
Training loss: 2.9742542838881567
Validation loss: 2.4654448230247286

Epoch: 6| Step: 7
Training loss: 2.971521308782726
Validation loss: 2.4635246442941954

Epoch: 6| Step: 8
Training loss: 2.9739998426507883
Validation loss: 2.4629899120157774

Epoch: 6| Step: 9
Training loss: 2.473173982194462
Validation loss: 2.464709980070819

Epoch: 6| Step: 10
Training loss: 2.264640646884508
Validation loss: 2.4608349329651173

Epoch: 6| Step: 11
Training loss: 2.5691478374763346
Validation loss: 2.459469473420654

Epoch: 6| Step: 12
Training loss: 2.141675259861114
Validation loss: 2.466032101440012

Epoch: 6| Step: 13
Training loss: 2.2126551988554874
Validation loss: 2.467902235145329

Epoch: 125| Step: 0
Training loss: 1.561225905709695
Validation loss: 2.4696892026200064

Epoch: 6| Step: 1
Training loss: 2.4040671021082605
Validation loss: 2.467221007905737

Epoch: 6| Step: 2
Training loss: 2.4246684054156153
Validation loss: 2.466194616934272

Epoch: 6| Step: 3
Training loss: 2.277648800658931
Validation loss: 2.4725716221345095

Epoch: 6| Step: 4
Training loss: 2.8305633318537082
Validation loss: 2.468500261511379

Epoch: 6| Step: 5
Training loss: 2.0342497756318427
Validation loss: 2.460296821959365

Epoch: 6| Step: 6
Training loss: 2.601208545330664
Validation loss: 2.462992041625179

Epoch: 6| Step: 7
Training loss: 2.8103328408610464
Validation loss: 2.464631447815494

Epoch: 6| Step: 8
Training loss: 2.1374909785565515
Validation loss: 2.456666985110189

Epoch: 6| Step: 9
Training loss: 3.5191465923348924
Validation loss: 2.451609133035166

Epoch: 6| Step: 10
Training loss: 2.0056634824014403
Validation loss: 2.4563874016171234

Epoch: 6| Step: 11
Training loss: 1.8038240819615838
Validation loss: 2.457655956135631

Epoch: 6| Step: 12
Training loss: 2.87804284988114
Validation loss: 2.462293350275526

Epoch: 6| Step: 13
Training loss: 3.260800242585537
Validation loss: 2.451808017085111

Epoch: 126| Step: 0
Training loss: 2.1364740374536786
Validation loss: 2.454390893698025

Epoch: 6| Step: 1
Training loss: 2.660326802392165
Validation loss: 2.458203123706814

Epoch: 6| Step: 2
Training loss: 2.2856993461869974
Validation loss: 2.4691436228436965

Epoch: 6| Step: 3
Training loss: 2.5712629143775856
Validation loss: 2.465632599084423

Epoch: 6| Step: 4
Training loss: 2.959979141264957
Validation loss: 2.4608572164690536

Epoch: 6| Step: 5
Training loss: 2.3534009470245514
Validation loss: 2.4579519256151148

Epoch: 6| Step: 6
Training loss: 2.5604527366669596
Validation loss: 2.4653252938814982

Epoch: 6| Step: 7
Training loss: 2.59423235349231
Validation loss: 2.4475019279474983

Epoch: 6| Step: 8
Training loss: 2.065671389891341
Validation loss: 2.447655023971658

Epoch: 6| Step: 9
Training loss: 2.1549585870361456
Validation loss: 2.454690648236149

Epoch: 6| Step: 10
Training loss: 2.4379391396916232
Validation loss: 2.4584500775391884

Epoch: 6| Step: 11
Training loss: 2.600301809400109
Validation loss: 2.4632790703102967

Epoch: 6| Step: 12
Training loss: 2.7785655578820236
Validation loss: 2.4574716695845154

Epoch: 6| Step: 13
Training loss: 2.984295749111348
Validation loss: 2.4689584475049355

Epoch: 127| Step: 0
Training loss: 2.3720608644701713
Validation loss: 2.4585105514227537

Epoch: 6| Step: 1
Training loss: 2.6482974215121846
Validation loss: 2.466768765484432

Epoch: 6| Step: 2
Training loss: 2.8718008403314323
Validation loss: 2.461902699588679

Epoch: 6| Step: 3
Training loss: 3.33324200187175
Validation loss: 2.474031520898662

Epoch: 6| Step: 4
Training loss: 2.0209075547054414
Validation loss: 2.468285247257933

Epoch: 6| Step: 5
Training loss: 2.254641090808969
Validation loss: 2.478102557163667

Epoch: 6| Step: 6
Training loss: 2.4206764454869534
Validation loss: 2.457942726870966

Epoch: 6| Step: 7
Training loss: 2.5552373171962683
Validation loss: 2.4619001251717956

Epoch: 6| Step: 8
Training loss: 2.281957647226467
Validation loss: 2.463184118367233

Epoch: 6| Step: 9
Training loss: 2.3359434197902624
Validation loss: 2.4517122318987585

Epoch: 6| Step: 10
Training loss: 2.953427576781585
Validation loss: 2.447129181074546

Epoch: 6| Step: 11
Training loss: 2.3302872620676798
Validation loss: 2.4554614625378224

Epoch: 6| Step: 12
Training loss: 2.3625707141445513
Validation loss: 2.448840122677269

Epoch: 6| Step: 13
Training loss: 2.3498516766429494
Validation loss: 2.456157826254517

Epoch: 128| Step: 0
Training loss: 2.113823276470086
Validation loss: 2.452646180416334

Epoch: 6| Step: 1
Training loss: 2.6983377920879295
Validation loss: 2.4581830630738324

Epoch: 6| Step: 2
Training loss: 2.5498405930304195
Validation loss: 2.460512154772201

Epoch: 6| Step: 3
Training loss: 2.6948923861616336
Validation loss: 2.4512512113135996

Epoch: 6| Step: 4
Training loss: 2.8161193447561685
Validation loss: 2.4606320146146263

Epoch: 6| Step: 5
Training loss: 2.542896181820271
Validation loss: 2.4553545399441483

Epoch: 6| Step: 6
Training loss: 2.262304569466025
Validation loss: 2.455763602529421

Epoch: 6| Step: 7
Training loss: 2.6370117928881736
Validation loss: 2.454414352802211

Epoch: 6| Step: 8
Training loss: 2.282296763602595
Validation loss: 2.45798860708379

Epoch: 6| Step: 9
Training loss: 2.211172785556445
Validation loss: 2.4666904920853576

Epoch: 6| Step: 10
Training loss: 2.465303550430283
Validation loss: 2.459203991565224

Epoch: 6| Step: 11
Training loss: 2.8200746050225454
Validation loss: 2.467112323951656

Epoch: 6| Step: 12
Training loss: 2.2222660841851676
Validation loss: 2.469223797879958

Epoch: 6| Step: 13
Training loss: 2.679308094268681
Validation loss: 2.468730596474154

Epoch: 129| Step: 0
Training loss: 2.7353859040931545
Validation loss: 2.471002926937826

Epoch: 6| Step: 1
Training loss: 2.7019750541535026
Validation loss: 2.4668823291820137

Epoch: 6| Step: 2
Training loss: 2.559058693144512
Validation loss: 2.4652067905527475

Epoch: 6| Step: 3
Training loss: 2.1342748302897863
Validation loss: 2.464639678422786

Epoch: 6| Step: 4
Training loss: 2.4985462730448167
Validation loss: 2.4550940837558914

Epoch: 6| Step: 5
Training loss: 2.7580784137248315
Validation loss: 2.4576772741136006

Epoch: 6| Step: 6
Training loss: 2.2555596222655536
Validation loss: 2.4689206173040996

Epoch: 6| Step: 7
Training loss: 1.9507588206121969
Validation loss: 2.457640749683402

Epoch: 6| Step: 8
Training loss: 2.608119548368664
Validation loss: 2.451852472457709

Epoch: 6| Step: 9
Training loss: 2.6447219216424553
Validation loss: 2.4621706582597405

Epoch: 6| Step: 10
Training loss: 2.284237199167759
Validation loss: 2.451066143293577

Epoch: 6| Step: 11
Training loss: 2.831351447235265
Validation loss: 2.458296651620419

Epoch: 6| Step: 12
Training loss: 2.3188835907571796
Validation loss: 2.4529802883090737

Epoch: 6| Step: 13
Training loss: 2.5615333967055247
Validation loss: 2.4496751245503265

Epoch: 130| Step: 0
Training loss: 1.7560790606625214
Validation loss: 2.4550850199721697

Epoch: 6| Step: 1
Training loss: 2.2242035801286115
Validation loss: 2.458229520728654

Epoch: 6| Step: 2
Training loss: 2.589024110554349
Validation loss: 2.4674984459580642

Epoch: 6| Step: 3
Training loss: 2.490462612089729
Validation loss: 2.4620020990747533

Epoch: 6| Step: 4
Training loss: 2.588130516593561
Validation loss: 2.454292885967686

Epoch: 6| Step: 5
Training loss: 2.933274496817787
Validation loss: 2.4584206118419214

Epoch: 6| Step: 6
Training loss: 2.581450473491332
Validation loss: 2.452710385931006

Epoch: 6| Step: 7
Training loss: 2.906973471883662
Validation loss: 2.4597178832904447

Epoch: 6| Step: 8
Training loss: 3.1669420490654185
Validation loss: 2.4592280026056645

Epoch: 6| Step: 9
Training loss: 2.2781926400146872
Validation loss: 2.459198126113929

Epoch: 6| Step: 10
Training loss: 2.784235862398044
Validation loss: 2.461755138383719

Epoch: 6| Step: 11
Training loss: 2.212969058903459
Validation loss: 2.4666675363573485

Epoch: 6| Step: 12
Training loss: 2.38288033810964
Validation loss: 2.4616935497056605

Epoch: 6| Step: 13
Training loss: 2.032907601902038
Validation loss: 2.45806809519282

Epoch: 131| Step: 0
Training loss: 2.506367014296103
Validation loss: 2.4591493922365517

Epoch: 6| Step: 1
Training loss: 2.355299505476543
Validation loss: 2.450696824686589

Epoch: 6| Step: 2
Training loss: 2.463006884306232
Validation loss: 2.4592945084089406

Epoch: 6| Step: 3
Training loss: 3.103218001924496
Validation loss: 2.4543228140757583

Epoch: 6| Step: 4
Training loss: 2.083118720126708
Validation loss: 2.4588139570638865

Epoch: 6| Step: 5
Training loss: 2.5427371621337116
Validation loss: 2.4606619059939425

Epoch: 6| Step: 6
Training loss: 2.616913738451432
Validation loss: 2.4537678744830558

Epoch: 6| Step: 7
Training loss: 2.318218275113311
Validation loss: 2.463418152329218

Epoch: 6| Step: 8
Training loss: 2.667549424290068
Validation loss: 2.4539323114134426

Epoch: 6| Step: 9
Training loss: 2.4729969820404456
Validation loss: 2.455543411257456

Epoch: 6| Step: 10
Training loss: 1.5730247039407117
Validation loss: 2.446135913473712

Epoch: 6| Step: 11
Training loss: 2.542229564016288
Validation loss: 2.4549311085789873

Epoch: 6| Step: 12
Training loss: 3.0889647495855517
Validation loss: 2.461238346178819

Epoch: 6| Step: 13
Training loss: 2.3903433440596427
Validation loss: 2.4631782139970935

Epoch: 132| Step: 0
Training loss: 2.565740443802408
Validation loss: 2.4587947175420513

Epoch: 6| Step: 1
Training loss: 2.6159086376708323
Validation loss: 2.4693381739581652

Epoch: 6| Step: 2
Training loss: 2.2122425770117204
Validation loss: 2.460811212114926

Epoch: 6| Step: 3
Training loss: 2.2424941434751857
Validation loss: 2.463697728273963

Epoch: 6| Step: 4
Training loss: 2.2227167479958596
Validation loss: 2.458822643484938

Epoch: 6| Step: 5
Training loss: 2.369338364616008
Validation loss: 2.4625515443470993

Epoch: 6| Step: 6
Training loss: 2.943099022420742
Validation loss: 2.4573723293992176

Epoch: 6| Step: 7
Training loss: 2.5017002046367174
Validation loss: 2.4614830583021265

Epoch: 6| Step: 8
Training loss: 2.5950949984822254
Validation loss: 2.4591757952594917

Epoch: 6| Step: 9
Training loss: 2.727773053341478
Validation loss: 2.467731233433919

Epoch: 6| Step: 10
Training loss: 2.826598709237221
Validation loss: 2.461216227575964

Epoch: 6| Step: 11
Training loss: 2.5614819248804506
Validation loss: 2.461171602286002

Epoch: 6| Step: 12
Training loss: 2.6372161170083954
Validation loss: 2.4785674410133955

Epoch: 6| Step: 13
Training loss: 2.021215566555333
Validation loss: 2.4774903205043506

Epoch: 133| Step: 0
Training loss: 2.539425492382059
Validation loss: 2.477123128850983

Epoch: 6| Step: 1
Training loss: 3.028752192529128
Validation loss: 2.482509016242786

Epoch: 6| Step: 2
Training loss: 3.0253241121037537
Validation loss: 2.4716034345797744

Epoch: 6| Step: 3
Training loss: 2.4048330916066356
Validation loss: 2.4716937867175326

Epoch: 6| Step: 4
Training loss: 2.406552382456454
Validation loss: 2.462911873467891

Epoch: 6| Step: 5
Training loss: 3.365890642625698
Validation loss: 2.467480280654684

Epoch: 6| Step: 6
Training loss: 2.0896580123361113
Validation loss: 2.464212980737113

Epoch: 6| Step: 7
Training loss: 2.1970618395082866
Validation loss: 2.458309890074939

Epoch: 6| Step: 8
Training loss: 2.1059241430490454
Validation loss: 2.4596725361441196

Epoch: 6| Step: 9
Training loss: 2.695905625692257
Validation loss: 2.4616033551445446

Epoch: 6| Step: 10
Training loss: 2.4247576877618826
Validation loss: 2.4512622588618043

Epoch: 6| Step: 11
Training loss: 1.9884084724538909
Validation loss: 2.463577033683572

Epoch: 6| Step: 12
Training loss: 2.621479580220712
Validation loss: 2.464290470147661

Epoch: 6| Step: 13
Training loss: 1.642576673509317
Validation loss: 2.4646517703523045

Epoch: 134| Step: 0
Training loss: 2.3074059956787063
Validation loss: 2.4685146444941113

Epoch: 6| Step: 1
Training loss: 2.7011256238131756
Validation loss: 2.4589411312842735

Epoch: 6| Step: 2
Training loss: 2.0536224737990616
Validation loss: 2.457580472677025

Epoch: 6| Step: 3
Training loss: 2.9000736358764856
Validation loss: 2.4609927055181546

Epoch: 6| Step: 4
Training loss: 2.093113361188458
Validation loss: 2.4680459189478787

Epoch: 6| Step: 5
Training loss: 2.5628903719659606
Validation loss: 2.4766931348937704

Epoch: 6| Step: 6
Training loss: 3.089425812244928
Validation loss: 2.4783224116197813

Epoch: 6| Step: 7
Training loss: 2.7625104532863944
Validation loss: 2.473851417774383

Epoch: 6| Step: 8
Training loss: 2.9928548282857554
Validation loss: 2.4741231334741363

Epoch: 6| Step: 9
Training loss: 2.6562110449234524
Validation loss: 2.4680147323519037

Epoch: 6| Step: 10
Training loss: 1.8825005237229062
Validation loss: 2.4722001477183477

Epoch: 6| Step: 11
Training loss: 2.022797118667261
Validation loss: 2.4730090491744643

Epoch: 6| Step: 12
Training loss: 2.5231326837354167
Validation loss: 2.4643942639233827

Epoch: 6| Step: 13
Training loss: 2.5865936829734855
Validation loss: 2.477798201767129

Epoch: 135| Step: 0
Training loss: 2.420165609257538
Validation loss: 2.4834956566245454

Epoch: 6| Step: 1
Training loss: 1.9981560551410946
Validation loss: 2.465916484304424

Epoch: 6| Step: 2
Training loss: 2.8402970698622987
Validation loss: 2.4658222462863706

Epoch: 6| Step: 3
Training loss: 2.438933415635224
Validation loss: 2.4759448832682236

Epoch: 6| Step: 4
Training loss: 3.117478435964883
Validation loss: 2.4644947641236703

Epoch: 6| Step: 5
Training loss: 2.6925706268653307
Validation loss: 2.4641447128936536

Epoch: 6| Step: 6
Training loss: 2.8673243684868743
Validation loss: 2.4654985496157256

Epoch: 6| Step: 7
Training loss: 2.5107426622969697
Validation loss: 2.466585925000787

Epoch: 6| Step: 8
Training loss: 2.624719695611283
Validation loss: 2.4650282027544343

Epoch: 6| Step: 9
Training loss: 1.7769262473236571
Validation loss: 2.4708847280714057

Epoch: 6| Step: 10
Training loss: 2.4423052055905377
Validation loss: 2.4677674635993596

Epoch: 6| Step: 11
Training loss: 2.1560167932864878
Validation loss: 2.4600248228800443

Epoch: 6| Step: 12
Training loss: 1.7870840268864898
Validation loss: 2.4735664030453393

Epoch: 6| Step: 13
Training loss: 3.0025766751347875
Validation loss: 2.4677532292333533

Epoch: 136| Step: 0
Training loss: 2.4760502908310666
Validation loss: 2.4563030544566042

Epoch: 6| Step: 1
Training loss: 2.1777464177778008
Validation loss: 2.4609179783606914

Epoch: 6| Step: 2
Training loss: 2.6264419228439575
Validation loss: 2.462284869754778

Epoch: 6| Step: 3
Training loss: 2.2092027092517306
Validation loss: 2.4702871583124946

Epoch: 6| Step: 4
Training loss: 2.426941426812453
Validation loss: 2.459200679121997

Epoch: 6| Step: 5
Training loss: 2.604087909779144
Validation loss: 2.4612222012328244

Epoch: 6| Step: 6
Training loss: 2.650816442569124
Validation loss: 2.462908783819751

Epoch: 6| Step: 7
Training loss: 2.727500950772044
Validation loss: 2.4551644402390442

Epoch: 6| Step: 8
Training loss: 2.766578553033729
Validation loss: 2.4662845871967307

Epoch: 6| Step: 9
Training loss: 2.720307528837987
Validation loss: 2.470342243360556

Epoch: 6| Step: 10
Training loss: 2.1650474317610002
Validation loss: 2.4697334728895965

Epoch: 6| Step: 11
Training loss: 2.3857582769425227
Validation loss: 2.480175763946652

Epoch: 6| Step: 12
Training loss: 2.197288085822701
Validation loss: 2.4753659282887246

Epoch: 6| Step: 13
Training loss: 2.7432085619610667
Validation loss: 2.469839065099085

Epoch: 137| Step: 0
Training loss: 2.3552569899889058
Validation loss: 2.466738730636602

Epoch: 6| Step: 1
Training loss: 2.5111758296451083
Validation loss: 2.4665679140771375

Epoch: 6| Step: 2
Training loss: 1.7082354664875872
Validation loss: 2.4591173818267267

Epoch: 6| Step: 3
Training loss: 2.3545781566441684
Validation loss: 2.4585727451147625

Epoch: 6| Step: 4
Training loss: 2.1732055101464876
Validation loss: 2.4623594828111774

Epoch: 6| Step: 5
Training loss: 2.0501601086872316
Validation loss: 2.4615733783412623

Epoch: 6| Step: 6
Training loss: 2.8110070398623193
Validation loss: 2.4615936373409277

Epoch: 6| Step: 7
Training loss: 2.4715362471033777
Validation loss: 2.4634983524012206

Epoch: 6| Step: 8
Training loss: 2.505678308594966
Validation loss: 2.4646211373489675

Epoch: 6| Step: 9
Training loss: 1.8977692609283694
Validation loss: 2.4617287791669398

Epoch: 6| Step: 10
Training loss: 3.3683747147993075
Validation loss: 2.4671674557258765

Epoch: 6| Step: 11
Training loss: 2.4041290844426566
Validation loss: 2.4603551266365735

Epoch: 6| Step: 12
Training loss: 2.9037584679258828
Validation loss: 2.468941371276734

Epoch: 6| Step: 13
Training loss: 2.9453069954980062
Validation loss: 2.4710428961732105

Epoch: 138| Step: 0
Training loss: 2.821618366928392
Validation loss: 2.4607128868333694

Epoch: 6| Step: 1
Training loss: 2.122763185752392
Validation loss: 2.472381753334298

Epoch: 6| Step: 2
Training loss: 1.8275814715592757
Validation loss: 2.4657616374774403

Epoch: 6| Step: 3
Training loss: 2.4618681585987225
Validation loss: 2.4692960529585712

Epoch: 6| Step: 4
Training loss: 2.5796008885132897
Validation loss: 2.47415266913359

Epoch: 6| Step: 5
Training loss: 2.818243985315431
Validation loss: 2.459231848228315

Epoch: 6| Step: 6
Training loss: 2.3045505289011974
Validation loss: 2.4733255534122534

Epoch: 6| Step: 7
Training loss: 2.6035449290361337
Validation loss: 2.462553448427816

Epoch: 6| Step: 8
Training loss: 2.120354455070359
Validation loss: 2.467139592026688

Epoch: 6| Step: 9
Training loss: 3.0532005964464752
Validation loss: 2.4637543073720067

Epoch: 6| Step: 10
Training loss: 2.3187476638823306
Validation loss: 2.4692960529585712

Epoch: 6| Step: 11
Training loss: 2.51908891920256
Validation loss: 2.463223964429549

Epoch: 6| Step: 12
Training loss: 2.7532895094252585
Validation loss: 2.4797165658838174

Epoch: 6| Step: 13
Training loss: 2.253396860935134
Validation loss: 2.4636877122834404

Epoch: 139| Step: 0
Training loss: 2.635744177530279
Validation loss: 2.474582783376266

Epoch: 6| Step: 1
Training loss: 2.4407754067783927
Validation loss: 2.4806803695638897

Epoch: 6| Step: 2
Training loss: 2.6106686611784866
Validation loss: 2.4713598692774257

Epoch: 6| Step: 3
Training loss: 2.828985768201136
Validation loss: 2.4828664650162757

Epoch: 6| Step: 4
Training loss: 2.3127217573083225
Validation loss: 2.476122442994656

Epoch: 6| Step: 5
Training loss: 1.809829454554084
Validation loss: 2.470207025832657

Epoch: 6| Step: 6
Training loss: 2.630199006822625
Validation loss: 2.4759998584941396

Epoch: 6| Step: 7
Training loss: 2.1900665485600164
Validation loss: 2.474519482600468

Epoch: 6| Step: 8
Training loss: 2.382072058528605
Validation loss: 2.475644074709769

Epoch: 6| Step: 9
Training loss: 2.068406865454563
Validation loss: 2.4740752236040424

Epoch: 6| Step: 10
Training loss: 2.507258559038648
Validation loss: 2.4696978749250325

Epoch: 6| Step: 11
Training loss: 3.032369505235828
Validation loss: 2.4709599257188417

Epoch: 6| Step: 12
Training loss: 2.376849909651738
Validation loss: 2.4709101533661015

Epoch: 6| Step: 13
Training loss: 2.8225327309264068
Validation loss: 2.470860010124237

Epoch: 140| Step: 0
Training loss: 2.677663322190524
Validation loss: 2.4726867352495168

Epoch: 6| Step: 1
Training loss: 2.13455453232112
Validation loss: 2.4814108673911717

Epoch: 6| Step: 2
Training loss: 2.491977886126325
Validation loss: 2.474521457763305

Epoch: 6| Step: 3
Training loss: 2.1730004557483125
Validation loss: 2.4731390202050725

Epoch: 6| Step: 4
Training loss: 2.1630236614553873
Validation loss: 2.4686064376616073

Epoch: 6| Step: 5
Training loss: 2.5084621265419598
Validation loss: 2.4668314275186747

Epoch: 6| Step: 6
Training loss: 2.7740647157464906
Validation loss: 2.4693382785557416

Epoch: 6| Step: 7
Training loss: 2.363043049559412
Validation loss: 2.4658248246658387

Epoch: 6| Step: 8
Training loss: 2.5945571195144925
Validation loss: 2.461902102388764

Epoch: 6| Step: 9
Training loss: 2.294754814398071
Validation loss: 2.4614258296809903

Epoch: 6| Step: 10
Training loss: 3.0845223960712675
Validation loss: 2.460138810952931

Epoch: 6| Step: 11
Training loss: 2.9287954371041933
Validation loss: 2.4596165901515024

Epoch: 6| Step: 12
Training loss: 2.4381888956646454
Validation loss: 2.4662949309886026

Epoch: 6| Step: 13
Training loss: 2.333740017281642
Validation loss: 2.4657560777008807

Epoch: 141| Step: 0
Training loss: 2.07540118464105
Validation loss: 2.465668344378583

Epoch: 6| Step: 1
Training loss: 2.565964380601307
Validation loss: 2.464762892406942

Epoch: 6| Step: 2
Training loss: 2.4788946007792387
Validation loss: 2.465314736484734

Epoch: 6| Step: 3
Training loss: 2.447967355622688
Validation loss: 2.4616604827858284

Epoch: 6| Step: 4
Training loss: 2.989998995675521
Validation loss: 2.4647130190946673

Epoch: 6| Step: 5
Training loss: 2.8382209433320984
Validation loss: 2.4586332321431286

Epoch: 6| Step: 6
Training loss: 2.043027800368515
Validation loss: 2.4689121595474965

Epoch: 6| Step: 7
Training loss: 2.0732849662920523
Validation loss: 2.4578752548894585

Epoch: 6| Step: 8
Training loss: 2.3948545253270077
Validation loss: 2.4517586987162407

Epoch: 6| Step: 9
Training loss: 2.1934130722361767
Validation loss: 2.4603254980196727

Epoch: 6| Step: 10
Training loss: 3.0549978113244642
Validation loss: 2.4635471454153506

Epoch: 6| Step: 11
Training loss: 2.1480344082085034
Validation loss: 2.461409847402429

Epoch: 6| Step: 12
Training loss: 2.9315283929841223
Validation loss: 2.455615373053564

Epoch: 6| Step: 13
Training loss: 2.410210953498168
Validation loss: 2.4596585941922355

Epoch: 142| Step: 0
Training loss: 2.163792782718107
Validation loss: 2.464435428707615

Epoch: 6| Step: 1
Training loss: 2.245207132244352
Validation loss: 2.460723593159906

Epoch: 6| Step: 2
Training loss: 2.048890613806645
Validation loss: 2.454232437685946

Epoch: 6| Step: 3
Training loss: 2.1250267027130865
Validation loss: 2.459675040194314

Epoch: 6| Step: 4
Training loss: 2.2482915325911894
Validation loss: 2.468765709420614

Epoch: 6| Step: 5
Training loss: 2.479336986514781
Validation loss: 2.469460493773905

Epoch: 6| Step: 6
Training loss: 3.14497461451245
Validation loss: 2.4686699866354007

Epoch: 6| Step: 7
Training loss: 2.463335497712805
Validation loss: 2.4658976466575617

Epoch: 6| Step: 8
Training loss: 2.963213445972396
Validation loss: 2.4635716786616393

Epoch: 6| Step: 9
Training loss: 1.6894388010817996
Validation loss: 2.4617314748254575

Epoch: 6| Step: 10
Training loss: 2.378462024923649
Validation loss: 2.457960994993481

Epoch: 6| Step: 11
Training loss: 2.92491782961463
Validation loss: 2.4662834754782

Epoch: 6| Step: 12
Training loss: 3.0680673558626226
Validation loss: 2.4684871742925485

Epoch: 6| Step: 13
Training loss: 2.527207525670897
Validation loss: 2.4703302114560737

Epoch: 143| Step: 0
Training loss: 3.258912118172217
Validation loss: 2.4626621238151634

Epoch: 6| Step: 1
Training loss: 2.0764440176912924
Validation loss: 2.468157797819527

Epoch: 6| Step: 2
Training loss: 2.3078051154367825
Validation loss: 2.4639300845989913

Epoch: 6| Step: 3
Training loss: 2.4571405092335885
Validation loss: 2.45486450075176

Epoch: 6| Step: 4
Training loss: 2.594780958335544
Validation loss: 2.4584239738263265

Epoch: 6| Step: 5
Training loss: 2.421072057704986
Validation loss: 2.458871739367881

Epoch: 6| Step: 6
Training loss: 2.801580636880082
Validation loss: 2.4572766236581502

Epoch: 6| Step: 7
Training loss: 2.571518264447524
Validation loss: 2.4580813914579727

Epoch: 6| Step: 8
Training loss: 2.5752880787116794
Validation loss: 2.458803226261371

Epoch: 6| Step: 9
Training loss: 2.5991979168767028
Validation loss: 2.46459501838225

Epoch: 6| Step: 10
Training loss: 1.7575222877836498
Validation loss: 2.4716295116390263

Epoch: 6| Step: 11
Training loss: 2.3462474486835574
Validation loss: 2.4751489979755896

Epoch: 6| Step: 12
Training loss: 2.369025596348331
Validation loss: 2.479434685417813

Epoch: 6| Step: 13
Training loss: 2.6802240396200787
Validation loss: 2.4827067534115796

Epoch: 144| Step: 0
Training loss: 2.474742328832683
Validation loss: 2.4777298511646455

Epoch: 6| Step: 1
Training loss: 2.79290250686303
Validation loss: 2.478918773748928

Epoch: 6| Step: 2
Training loss: 3.4749343316988224
Validation loss: 2.4763816502721396

Epoch: 6| Step: 3
Training loss: 1.982139589854411
Validation loss: 2.469556041103534

Epoch: 6| Step: 4
Training loss: 2.292205319533613
Validation loss: 2.477607771206802

Epoch: 6| Step: 5
Training loss: 2.436565317776342
Validation loss: 2.468636779764262

Epoch: 6| Step: 6
Training loss: 2.34445342634187
Validation loss: 2.4676758727137647

Epoch: 6| Step: 7
Training loss: 2.674087946481944
Validation loss: 2.4690568145801084

Epoch: 6| Step: 8
Training loss: 2.478232124774416
Validation loss: 2.469974214287962

Epoch: 6| Step: 9
Training loss: 2.14541002067188
Validation loss: 2.4624928156430026

Epoch: 6| Step: 10
Training loss: 1.9723921495162642
Validation loss: 2.469362609440845

Epoch: 6| Step: 11
Training loss: 2.63661982597994
Validation loss: 2.464399351108847

Epoch: 6| Step: 12
Training loss: 2.654835762073425
Validation loss: 2.472056190997111

Epoch: 6| Step: 13
Training loss: 2.22635389990497
Validation loss: 2.4721851030580098

Epoch: 145| Step: 0
Training loss: 3.3100971647908533
Validation loss: 2.4726647994067905

Epoch: 6| Step: 1
Training loss: 2.1277775283339673
Validation loss: 2.4724784011720278

Epoch: 6| Step: 2
Training loss: 2.7454675256145538
Validation loss: 2.460828829187529

Epoch: 6| Step: 3
Training loss: 2.6283685777712447
Validation loss: 2.4654746077021685

Epoch: 6| Step: 4
Training loss: 2.0590707418138168
Validation loss: 2.4584257033068972

Epoch: 6| Step: 5
Training loss: 2.4586989136330604
Validation loss: 2.463145408994303

Epoch: 6| Step: 6
Training loss: 2.524719668397206
Validation loss: 2.4696493643303343

Epoch: 6| Step: 7
Training loss: 2.199460709103182
Validation loss: 2.4683659733690475

Epoch: 6| Step: 8
Training loss: 1.890062358776095
Validation loss: 2.471159857348998

Epoch: 6| Step: 9
Training loss: 2.4843528314717003
Validation loss: 2.462346298403974

Epoch: 6| Step: 10
Training loss: 1.9916329004572393
Validation loss: 2.4588818719379466

Epoch: 6| Step: 11
Training loss: 2.293690556475735
Validation loss: 2.47287916772612

Epoch: 6| Step: 12
Training loss: 2.826488885716967
Validation loss: 2.46557437085676

Epoch: 6| Step: 13
Training loss: 2.7436956621841704
Validation loss: 2.475028331992597

Epoch: 146| Step: 0
Training loss: 2.256258419792548
Validation loss: 2.4633651788465794

Epoch: 6| Step: 1
Training loss: 2.6925019136526522
Validation loss: 2.4652835153384594

Epoch: 6| Step: 2
Training loss: 2.593289253952032
Validation loss: 2.4679695054524355

Epoch: 6| Step: 3
Training loss: 2.7050842064744365
Validation loss: 2.4673718577449537

Epoch: 6| Step: 4
Training loss: 2.907620342778482
Validation loss: 2.4662038171243004

Epoch: 6| Step: 5
Training loss: 2.059553642802383
Validation loss: 2.4717957263296286

Epoch: 6| Step: 6
Training loss: 2.8150889031310786
Validation loss: 2.4707155732455677

Epoch: 6| Step: 7
Training loss: 2.139706602572599
Validation loss: 2.467006139872085

Epoch: 6| Step: 8
Training loss: 1.9595717579248755
Validation loss: 2.470617609969163

Epoch: 6| Step: 9
Training loss: 2.3837062472812454
Validation loss: 2.4673764395447177

Epoch: 6| Step: 10
Training loss: 1.917234571604991
Validation loss: 2.4684303495241804

Epoch: 6| Step: 11
Training loss: 2.5334409485931473
Validation loss: 2.4744828534819776

Epoch: 6| Step: 12
Training loss: 2.7509216151439166
Validation loss: 2.463495755456688

Epoch: 6| Step: 13
Training loss: 2.67411041441521
Validation loss: 2.4663566544896924

Epoch: 147| Step: 0
Training loss: 2.7174295309943934
Validation loss: 2.471302242289633

Epoch: 6| Step: 1
Training loss: 2.1387764404374785
Validation loss: 2.4677573031044093

Epoch: 6| Step: 2
Training loss: 2.038727597616993
Validation loss: 2.471952461736167

Epoch: 6| Step: 3
Training loss: 2.574819769616565
Validation loss: 2.4666404402687503

Epoch: 6| Step: 4
Training loss: 2.3527830891234602
Validation loss: 2.469938732409241

Epoch: 6| Step: 5
Training loss: 2.916011863956466
Validation loss: 2.46773463909212

Epoch: 6| Step: 6
Training loss: 2.9115247542573495
Validation loss: 2.480446730788812

Epoch: 6| Step: 7
Training loss: 2.6153955502518818
Validation loss: 2.4760388804542957

Epoch: 6| Step: 8
Training loss: 2.6101940034695295
Validation loss: 2.487652981269599

Epoch: 6| Step: 9
Training loss: 2.059638726304166
Validation loss: 2.479428579349158

Epoch: 6| Step: 10
Training loss: 2.66634005294788
Validation loss: 2.4778928983951167

Epoch: 6| Step: 11
Training loss: 3.1446701493003033
Validation loss: 2.4792265577588624

Epoch: 6| Step: 12
Training loss: 2.1992675342196897
Validation loss: 2.4795483821567337

Epoch: 6| Step: 13
Training loss: 2.002250835333269
Validation loss: 2.47646136633939

Epoch: 148| Step: 0
Training loss: 2.3186494666666806
Validation loss: 2.4759208738536023

Epoch: 6| Step: 1
Training loss: 2.3886531102339394
Validation loss: 2.473822778033115

Epoch: 6| Step: 2
Training loss: 2.0715395188333674
Validation loss: 2.477121765334803

Epoch: 6| Step: 3
Training loss: 2.298773778695963
Validation loss: 2.4746043489480907

Epoch: 6| Step: 4
Training loss: 2.864428447813211
Validation loss: 2.47247644848434

Epoch: 6| Step: 5
Training loss: 2.307575963217525
Validation loss: 2.486769012572799

Epoch: 6| Step: 6
Training loss: 2.2370687399454696
Validation loss: 2.4803881534488528

Epoch: 6| Step: 7
Training loss: 2.626849658162209
Validation loss: 2.4844695419140663

Epoch: 6| Step: 8
Training loss: 3.048338553241858
Validation loss: 2.4859256983072675

Epoch: 6| Step: 9
Training loss: 2.250476045051759
Validation loss: 2.478521524897759

Epoch: 6| Step: 10
Training loss: 2.376735855992962
Validation loss: 2.4731184219634064

Epoch: 6| Step: 11
Training loss: 2.5823016003510864
Validation loss: 2.4685083101969894

Epoch: 6| Step: 12
Training loss: 2.8317384344851364
Validation loss: 2.4707055696216496

Epoch: 6| Step: 13
Training loss: 2.807128778850123
Validation loss: 2.4653232549374016

Epoch: 149| Step: 0
Training loss: 2.492045527034664
Validation loss: 2.461579528700619

Epoch: 6| Step: 1
Training loss: 2.4956025549196696
Validation loss: 2.468948404572588

Epoch: 6| Step: 2
Training loss: 2.905423939116495
Validation loss: 2.4698211020318186

Epoch: 6| Step: 3
Training loss: 2.96470398504355
Validation loss: 2.4761854861522705

Epoch: 6| Step: 4
Training loss: 2.305038373714606
Validation loss: 2.4819622119447153

Epoch: 6| Step: 5
Training loss: 3.0168362887696283
Validation loss: 2.479166589197323

Epoch: 6| Step: 6
Training loss: 2.855595660226957
Validation loss: 2.4753996709387738

Epoch: 6| Step: 7
Training loss: 2.192161389152566
Validation loss: 2.4635242410464215

Epoch: 6| Step: 8
Training loss: 1.691181405784645
Validation loss: 2.4729556544721953

Epoch: 6| Step: 9
Training loss: 2.276149325294278
Validation loss: 2.473985568783404

Epoch: 6| Step: 10
Training loss: 2.4432697965818595
Validation loss: 2.4774297565570893

Epoch: 6| Step: 11
Training loss: 1.8366867809036576
Validation loss: 2.4756877971011235

Epoch: 6| Step: 12
Training loss: 2.471039109133975
Validation loss: 2.4764757351763858

Epoch: 6| Step: 13
Training loss: 2.4429518545046554
Validation loss: 2.4682417559673273

Epoch: 150| Step: 0
Training loss: 2.3428621772220235
Validation loss: 2.474702636117526

Epoch: 6| Step: 1
Training loss: 1.937297379758466
Validation loss: 2.475994514291322

Epoch: 6| Step: 2
Training loss: 2.309714314848709
Validation loss: 2.479596074098873

Epoch: 6| Step: 3
Training loss: 3.1303195690293424
Validation loss: 2.4911503402495856

Epoch: 6| Step: 4
Training loss: 1.7344049674529556
Validation loss: 2.476927272114464

Epoch: 6| Step: 5
Training loss: 2.333789258646113
Validation loss: 2.4869970484119013

Epoch: 6| Step: 6
Training loss: 2.392858421878432
Validation loss: 2.4927665013945557

Epoch: 6| Step: 7
Training loss: 2.523975137887373
Validation loss: 2.481779818336791

Epoch: 6| Step: 8
Training loss: 2.9715349486194333
Validation loss: 2.4784071317133405

Epoch: 6| Step: 9
Training loss: 3.0269918520275554
Validation loss: 2.481337699973753

Epoch: 6| Step: 10
Training loss: 2.5192047617315194
Validation loss: 2.4749798456007195

Epoch: 6| Step: 11
Training loss: 2.5128803325900675
Validation loss: 2.468814156901804

Epoch: 6| Step: 12
Training loss: 2.0867109257855936
Validation loss: 2.4656078284841745

Epoch: 6| Step: 13
Training loss: 2.5846037868354825
Validation loss: 2.4693324210846344

Epoch: 151| Step: 0
Training loss: 2.437767209787721
Validation loss: 2.4661177754778194

Epoch: 6| Step: 1
Training loss: 1.7775831794859713
Validation loss: 2.469988242802199

Epoch: 6| Step: 2
Training loss: 2.5085838771496296
Validation loss: 2.462733813060084

Epoch: 6| Step: 3
Training loss: 2.3661756713606996
Validation loss: 2.45992253278471

Epoch: 6| Step: 4
Training loss: 2.368260710012388
Validation loss: 2.465249827648869

Epoch: 6| Step: 5
Training loss: 2.41060126105269
Validation loss: 2.4584204178811424

Epoch: 6| Step: 6
Training loss: 2.6806904775850176
Validation loss: 2.462376298072644

Epoch: 6| Step: 7
Training loss: 2.5473416140868586
Validation loss: 2.471631569496355

Epoch: 6| Step: 8
Training loss: 2.5718151210706757
Validation loss: 2.4705602390954136

Epoch: 6| Step: 9
Training loss: 2.663956536565666
Validation loss: 2.489511757517377

Epoch: 6| Step: 10
Training loss: 2.953459382678942
Validation loss: 2.5190043842347687

Epoch: 6| Step: 11
Training loss: 2.5106360206428597
Validation loss: 2.562307614183464

Epoch: 6| Step: 12
Training loss: 2.390835322683612
Validation loss: 2.5196809157441185

Epoch: 6| Step: 13
Training loss: 2.5845333101617105
Validation loss: 2.4875572664451764

Epoch: 152| Step: 0
Training loss: 2.5465845047677282
Validation loss: 2.470080198383677

Epoch: 6| Step: 1
Training loss: 2.507808507042674
Validation loss: 2.4695582857294314

Epoch: 6| Step: 2
Training loss: 2.5955052698648093
Validation loss: 2.4779838550679005

Epoch: 6| Step: 3
Training loss: 2.3753335618133105
Validation loss: 2.477196276383589

Epoch: 6| Step: 4
Training loss: 2.2795674638213796
Validation loss: 2.486256348921627

Epoch: 6| Step: 5
Training loss: 2.481078257730676
Validation loss: 2.466068147095654

Epoch: 6| Step: 6
Training loss: 2.5126461612832642
Validation loss: 2.470876317242707

Epoch: 6| Step: 7
Training loss: 2.5579148185273004
Validation loss: 2.4774172618509005

Epoch: 6| Step: 8
Training loss: 2.608277689753615
Validation loss: 2.481695413527592

Epoch: 6| Step: 9
Training loss: 3.0380664752470476
Validation loss: 2.477685635563596

Epoch: 6| Step: 10
Training loss: 2.8950514435356367
Validation loss: 2.479818007446709

Epoch: 6| Step: 11
Training loss: 2.2341685166351883
Validation loss: 2.475378064137806

Epoch: 6| Step: 12
Training loss: 2.6785478754370438
Validation loss: 2.4734936783098505

Epoch: 6| Step: 13
Training loss: 2.5073268336920393
Validation loss: 2.480990745907466

Epoch: 153| Step: 0
Training loss: 2.522968071419909
Validation loss: 2.467567860985225

Epoch: 6| Step: 1
Training loss: 2.146163347169067
Validation loss: 2.4717238980040377

Epoch: 6| Step: 2
Training loss: 2.4088497237430873
Validation loss: 2.4648483284385305

Epoch: 6| Step: 3
Training loss: 2.813466393486482
Validation loss: 2.4648368339622913

Epoch: 6| Step: 4
Training loss: 2.678383735256876
Validation loss: 2.4651822735789284

Epoch: 6| Step: 5
Training loss: 2.450984239425632
Validation loss: 2.457866096275975

Epoch: 6| Step: 6
Training loss: 3.1197376957695133
Validation loss: 2.466024238035204

Epoch: 6| Step: 7
Training loss: 2.709489683124212
Validation loss: 2.4568861457095097

Epoch: 6| Step: 8
Training loss: 2.1489628929672895
Validation loss: 2.4647668664289837

Epoch: 6| Step: 9
Training loss: 2.6514687984097476
Validation loss: 2.466214741298362

Epoch: 6| Step: 10
Training loss: 2.2767411705810137
Validation loss: 2.478830833021199

Epoch: 6| Step: 11
Training loss: 2.4016144924951517
Validation loss: 2.4689904349378584

Epoch: 6| Step: 12
Training loss: 2.356319545862907
Validation loss: 2.473258396651769

Epoch: 6| Step: 13
Training loss: 2.5542422965356324
Validation loss: 2.481069833410516

Epoch: 154| Step: 0
Training loss: 2.5081721252987665
Validation loss: 2.47925601659308

Epoch: 6| Step: 1
Training loss: 2.582445812561591
Validation loss: 2.486266226046679

Epoch: 6| Step: 2
Training loss: 2.5889450976700914
Validation loss: 2.485750645221257

Epoch: 6| Step: 3
Training loss: 2.513219975040851
Validation loss: 2.4757234132655226

Epoch: 6| Step: 4
Training loss: 2.148704262557919
Validation loss: 2.4892062669108626

Epoch: 6| Step: 5
Training loss: 2.2462838531983005
Validation loss: 2.50680374344771

Epoch: 6| Step: 6
Training loss: 3.02854846241307
Validation loss: 2.5240747849735077

Epoch: 6| Step: 7
Training loss: 2.5416298431063673
Validation loss: 2.5350817809999002

Epoch: 6| Step: 8
Training loss: 2.3975408909784153
Validation loss: 2.5293930683475656

Epoch: 6| Step: 9
Training loss: 2.2706560771483906
Validation loss: 2.5129166233942146

Epoch: 6| Step: 10
Training loss: 2.402576367040784
Validation loss: 2.492627542485408

Epoch: 6| Step: 11
Training loss: 2.28757081886272
Validation loss: 2.4685510321808706

Epoch: 6| Step: 12
Training loss: 2.8777139542063397
Validation loss: 2.47339964865991

Epoch: 6| Step: 13
Training loss: 2.405750272308242
Validation loss: 2.478636000976384

Epoch: 155| Step: 0
Training loss: 2.318825704567474
Validation loss: 2.4695599671862043

Epoch: 6| Step: 1
Training loss: 2.6405489758263894
Validation loss: 2.476362571307841

Epoch: 6| Step: 2
Training loss: 2.2918538335026133
Validation loss: 2.4754232198896755

Epoch: 6| Step: 3
Training loss: 2.896206472676464
Validation loss: 2.482450943763387

Epoch: 6| Step: 4
Training loss: 1.4656883958066582
Validation loss: 2.4780986045275095

Epoch: 6| Step: 5
Training loss: 2.55958158337012
Validation loss: 2.4743348059393115

Epoch: 6| Step: 6
Training loss: 2.1122069386912514
Validation loss: 2.4731024108091595

Epoch: 6| Step: 7
Training loss: 2.1262449096044644
Validation loss: 2.4739778430905615

Epoch: 6| Step: 8
Training loss: 2.8043752512412046
Validation loss: 2.474728054300904

Epoch: 6| Step: 9
Training loss: 2.676177637296973
Validation loss: 2.4776468961467404

Epoch: 6| Step: 10
Training loss: 3.4098372861909905
Validation loss: 2.4790365094123543

Epoch: 6| Step: 11
Training loss: 2.4654466765189427
Validation loss: 2.4897023149945507

Epoch: 6| Step: 12
Training loss: 2.5393075678005532
Validation loss: 2.498024573287454

Epoch: 6| Step: 13
Training loss: 2.1394891997383674
Validation loss: 2.5283462603629796

Epoch: 156| Step: 0
Training loss: 3.196181200202261
Validation loss: 2.5035170611209114

Epoch: 6| Step: 1
Training loss: 2.2449466330253456
Validation loss: 2.504543292835534

Epoch: 6| Step: 2
Training loss: 2.2665994587452536
Validation loss: 2.518764882008246

Epoch: 6| Step: 3
Training loss: 2.397269794124206
Validation loss: 2.504225235971863

Epoch: 6| Step: 4
Training loss: 2.529440904441632
Validation loss: 2.506778523692045

Epoch: 6| Step: 5
Training loss: 2.946171561917842
Validation loss: 2.5160504567768016

Epoch: 6| Step: 6
Training loss: 2.0081803396787756
Validation loss: 2.4970100484077276

Epoch: 6| Step: 7
Training loss: 2.634410791844037
Validation loss: 2.4916643891169965

Epoch: 6| Step: 8
Training loss: 2.5563244722519247
Validation loss: 2.4827612668147547

Epoch: 6| Step: 9
Training loss: 2.3434890601812524
Validation loss: 2.487336510887901

Epoch: 6| Step: 10
Training loss: 2.2254625246881834
Validation loss: 2.4869281437351685

Epoch: 6| Step: 11
Training loss: 2.0127329815889095
Validation loss: 2.487646288380104

Epoch: 6| Step: 12
Training loss: 2.450411127589382
Validation loss: 2.4838534433485533

Epoch: 6| Step: 13
Training loss: 2.8513768801957835
Validation loss: 2.482419786069698

Epoch: 157| Step: 0
Training loss: 2.471420485501406
Validation loss: 2.478946649314565

Epoch: 6| Step: 1
Training loss: 3.198852369035157
Validation loss: 2.4771107609296874

Epoch: 6| Step: 2
Training loss: 1.997123795891412
Validation loss: 2.4767481175767805

Epoch: 6| Step: 3
Training loss: 2.4334796125609426
Validation loss: 2.476283734634356

Epoch: 6| Step: 4
Training loss: 2.3955641443259412
Validation loss: 2.4834679761224425

Epoch: 6| Step: 5
Training loss: 2.1756843805579225
Validation loss: 2.4762393166935666

Epoch: 6| Step: 6
Training loss: 2.6516275913788907
Validation loss: 2.4786348867819266

Epoch: 6| Step: 7
Training loss: 2.4501026754857365
Validation loss: 2.4829123808014044

Epoch: 6| Step: 8
Training loss: 1.8969137725135432
Validation loss: 2.481779874376212

Epoch: 6| Step: 9
Training loss: 2.12201076517062
Validation loss: 2.4859331471013246

Epoch: 6| Step: 10
Training loss: 2.7075271482506698
Validation loss: 2.4806483806938084

Epoch: 6| Step: 11
Training loss: 2.390699896543021
Validation loss: 2.4781769665676716

Epoch: 6| Step: 12
Training loss: 2.9056707645848463
Validation loss: 2.484689000917318

Epoch: 6| Step: 13
Training loss: 2.7293916468792903
Validation loss: 2.4801578997777125

Epoch: 158| Step: 0
Training loss: 2.5861185707706755
Validation loss: 2.4900826361807247

Epoch: 6| Step: 1
Training loss: 3.0267350698575304
Validation loss: 2.4933005212300943

Epoch: 6| Step: 2
Training loss: 1.9621783582167922
Validation loss: 2.4899439105006707

Epoch: 6| Step: 3
Training loss: 2.4598345510158977
Validation loss: 2.4919069903606754

Epoch: 6| Step: 4
Training loss: 2.8598047152451476
Validation loss: 2.4960947847637804

Epoch: 6| Step: 5
Training loss: 2.47925601659308
Validation loss: 2.485698755142165

Epoch: 6| Step: 6
Training loss: 2.6710259945831702
Validation loss: 2.47942901206318

Epoch: 6| Step: 7
Training loss: 2.3315860700368205
Validation loss: 2.478130882868733

Epoch: 6| Step: 8
Training loss: 1.954666140018061
Validation loss: 2.4756437215889275

Epoch: 6| Step: 9
Training loss: 2.5721345605964983
Validation loss: 2.472998339796814

Epoch: 6| Step: 10
Training loss: 2.1387645126554915
Validation loss: 2.4721768895349365

Epoch: 6| Step: 11
Training loss: 2.6856239335535395
Validation loss: 2.473464761319905

Epoch: 6| Step: 12
Training loss: 2.616425269425963
Validation loss: 2.4686104215929063

Epoch: 6| Step: 13
Training loss: 2.121221099458825
Validation loss: 2.475032056735732

Epoch: 159| Step: 0
Training loss: 2.4916264491413127
Validation loss: 2.4790471846909146

Epoch: 6| Step: 1
Training loss: 2.056228581928609
Validation loss: 2.4839802394384

Epoch: 6| Step: 2
Training loss: 2.8384082634518486
Validation loss: 2.4901832006843554

Epoch: 6| Step: 3
Training loss: 2.580182450962553
Validation loss: 2.49586036000932

Epoch: 6| Step: 4
Training loss: 2.42889783973747
Validation loss: 2.50760663258076

Epoch: 6| Step: 5
Training loss: 2.736885705592858
Validation loss: 2.515439044405689

Epoch: 6| Step: 6
Training loss: 1.9370291353081694
Validation loss: 2.512953372240903

Epoch: 6| Step: 7
Training loss: 2.566684191094885
Validation loss: 2.493086506242052

Epoch: 6| Step: 8
Training loss: 2.3744220030315217
Validation loss: 2.5008274139652875

Epoch: 6| Step: 9
Training loss: 2.45193822059155
Validation loss: 2.5127090708729916

Epoch: 6| Step: 10
Training loss: 1.9824233181952875
Validation loss: 2.501140064325366

Epoch: 6| Step: 11
Training loss: 2.9333427718039586
Validation loss: 2.4853412020903902

Epoch: 6| Step: 12
Training loss: 1.9009868944891255
Validation loss: 2.4829380190125847

Epoch: 6| Step: 13
Training loss: 3.047761289365216
Validation loss: 2.47362873224142

Epoch: 160| Step: 0
Training loss: 2.3320585469704236
Validation loss: 2.479105833787173

Epoch: 6| Step: 1
Training loss: 2.3558487973033446
Validation loss: 2.4815186128545363

Epoch: 6| Step: 2
Training loss: 2.2902746538930416
Validation loss: 2.478003947831879

Epoch: 6| Step: 3
Training loss: 2.6546806636226075
Validation loss: 2.4748014974143295

Epoch: 6| Step: 4
Training loss: 2.434049266720932
Validation loss: 2.475496168847748

Epoch: 6| Step: 5
Training loss: 2.5852214824600237
Validation loss: 2.4897756196360006

Epoch: 6| Step: 6
Training loss: 2.2976859600866257
Validation loss: 2.4778294576673305

Epoch: 6| Step: 7
Training loss: 2.8485270190545307
Validation loss: 2.486823804439753

Epoch: 6| Step: 8
Training loss: 2.3012965196904345
Validation loss: 2.4793465386114497

Epoch: 6| Step: 9
Training loss: 3.044861113288872
Validation loss: 2.4710451233676727

Epoch: 6| Step: 10
Training loss: 1.71903725737828
Validation loss: 2.465514787435556

Epoch: 6| Step: 11
Training loss: 2.4030401445544625
Validation loss: 2.475618617778212

Epoch: 6| Step: 12
Training loss: 2.630626552052945
Validation loss: 2.4888194413893845

Epoch: 6| Step: 13
Training loss: 2.5159729900517456
Validation loss: 2.4753228343068368

Epoch: 161| Step: 0
Training loss: 2.222829801893531
Validation loss: 2.475963829035669

Epoch: 6| Step: 1
Training loss: 2.2762590969350116
Validation loss: 2.4776610496160005

Epoch: 6| Step: 2
Training loss: 2.401247050230408
Validation loss: 2.4761160559439985

Epoch: 6| Step: 3
Training loss: 2.3489633180913594
Validation loss: 2.4786890168157907

Epoch: 6| Step: 4
Training loss: 2.7144643394951102
Validation loss: 2.475952482456229

Epoch: 6| Step: 5
Training loss: 2.14939010308659
Validation loss: 2.4734140754469274

Epoch: 6| Step: 6
Training loss: 2.4705372389036793
Validation loss: 2.4912306843245045

Epoch: 6| Step: 7
Training loss: 2.0221280017789707
Validation loss: 2.486780948961627

Epoch: 6| Step: 8
Training loss: 2.7056412644314904
Validation loss: 2.496361787241725

Epoch: 6| Step: 9
Training loss: 2.6761852098699848
Validation loss: 2.493808645580224

Epoch: 6| Step: 10
Training loss: 3.144868176340245
Validation loss: 2.4799842020782674

Epoch: 6| Step: 11
Training loss: 2.898164391824766
Validation loss: 2.4851993176908613

Epoch: 6| Step: 12
Training loss: 2.1218889688248317
Validation loss: 2.4751531559986804

Epoch: 6| Step: 13
Training loss: 2.395777118410357
Validation loss: 2.4787566917227792

Epoch: 162| Step: 0
Training loss: 3.1163644110299398
Validation loss: 2.484380790015937

Epoch: 6| Step: 1
Training loss: 2.172923541644867
Validation loss: 2.471756187248852

Epoch: 6| Step: 2
Training loss: 3.0543565497671468
Validation loss: 2.472962917376358

Epoch: 6| Step: 3
Training loss: 1.9362746024492723
Validation loss: 2.4729231639627804

Epoch: 6| Step: 4
Training loss: 2.2440471314293227
Validation loss: 2.4788000866934925

Epoch: 6| Step: 5
Training loss: 2.74263348987389
Validation loss: 2.478006641821367

Epoch: 6| Step: 6
Training loss: 2.5485796694038876
Validation loss: 2.486157559529824

Epoch: 6| Step: 7
Training loss: 1.745147448652535
Validation loss: 2.477762920133619

Epoch: 6| Step: 8
Training loss: 2.055234886909195
Validation loss: 2.4794827080818735

Epoch: 6| Step: 9
Training loss: 2.0948881784972953
Validation loss: 2.476931860302636

Epoch: 6| Step: 10
Training loss: 2.5847317284512807
Validation loss: 2.4787911176068596

Epoch: 6| Step: 11
Training loss: 2.7003687218277586
Validation loss: 2.4721962579751984

Epoch: 6| Step: 12
Training loss: 2.507487813781153
Validation loss: 2.469202426707669

Epoch: 6| Step: 13
Training loss: 2.848915522856385
Validation loss: 2.4644324618993116

Epoch: 163| Step: 0
Training loss: 2.5872097055251957
Validation loss: 2.4802129338229943

Epoch: 6| Step: 1
Training loss: 2.8283930698875794
Validation loss: 2.5010427525549876

Epoch: 6| Step: 2
Training loss: 2.5987963017554065
Validation loss: 2.507814623236624

Epoch: 6| Step: 3
Training loss: 2.606768191117438
Validation loss: 2.5295099784793504

Epoch: 6| Step: 4
Training loss: 1.8701211396417117
Validation loss: 2.5261352102256516

Epoch: 6| Step: 5
Training loss: 2.8293488104442175
Validation loss: 2.522270554818396

Epoch: 6| Step: 6
Training loss: 1.9992451435357836
Validation loss: 2.518527810430475

Epoch: 6| Step: 7
Training loss: 2.4411184400667327
Validation loss: 2.4911405941472573

Epoch: 6| Step: 8
Training loss: 1.843241864028001
Validation loss: 2.4697157182175093

Epoch: 6| Step: 9
Training loss: 2.6423810728914554
Validation loss: 2.4741039728496164

Epoch: 6| Step: 10
Training loss: 2.2726363510671685
Validation loss: 2.469432849043904

Epoch: 6| Step: 11
Training loss: 2.3956582931486157
Validation loss: 2.483695483096551

Epoch: 6| Step: 12
Training loss: 2.6348246234823276
Validation loss: 2.4866704992242616

Epoch: 6| Step: 13
Training loss: 3.3261615531254995
Validation loss: 2.490517593933302

Epoch: 164| Step: 0
Training loss: 2.871849656019156
Validation loss: 2.4892296453383613

Epoch: 6| Step: 1
Training loss: 2.0190003986783362
Validation loss: 2.4914520517842043

Epoch: 6| Step: 2
Training loss: 2.78394195922552
Validation loss: 2.4859148207900144

Epoch: 6| Step: 3
Training loss: 3.2174674136061094
Validation loss: 2.4713425845379584

Epoch: 6| Step: 4
Training loss: 2.471825530935244
Validation loss: 2.481111009806287

Epoch: 6| Step: 5
Training loss: 2.329888002708193
Validation loss: 2.4809306998639573

Epoch: 6| Step: 6
Training loss: 2.4800953982063074
Validation loss: 2.4854677624072083

Epoch: 6| Step: 7
Training loss: 2.25222308219028
Validation loss: 2.4755074131818104

Epoch: 6| Step: 8
Training loss: 2.2356671418443117
Validation loss: 2.4728164500428287

Epoch: 6| Step: 9
Training loss: 1.862619342436703
Validation loss: 2.4748937638598703

Epoch: 6| Step: 10
Training loss: 1.9685798450387337
Validation loss: 2.4734257389125553

Epoch: 6| Step: 11
Training loss: 3.209119741657576
Validation loss: 2.4781967531121127

Epoch: 6| Step: 12
Training loss: 2.8420270793787092
Validation loss: 2.4814259922316833

Epoch: 6| Step: 13
Training loss: 2.017220981594834
Validation loss: 2.4721048954710714

Epoch: 165| Step: 0
Training loss: 2.366732613446184
Validation loss: 2.4723743280011616

Epoch: 6| Step: 1
Training loss: 2.1756778055526094
Validation loss: 2.474043872090642

Epoch: 6| Step: 2
Training loss: 2.598204682472396
Validation loss: 2.4746327387814047

Epoch: 6| Step: 3
Training loss: 2.290721929770982
Validation loss: 2.4755463706722587

Epoch: 6| Step: 4
Training loss: 2.4931749641726992
Validation loss: 2.494340371318701

Epoch: 6| Step: 5
Training loss: 2.828836088198042
Validation loss: 2.4882161178328692

Epoch: 6| Step: 6
Training loss: 3.0123782691261916
Validation loss: 2.4810503740825474

Epoch: 6| Step: 7
Training loss: 2.259075511114445
Validation loss: 2.47898351703379

Epoch: 6| Step: 8
Training loss: 2.5065490772519023
Validation loss: 2.4723943217045017

Epoch: 6| Step: 9
Training loss: 2.388974885600165
Validation loss: 2.476792061131262

Epoch: 6| Step: 10
Training loss: 2.1163337365588326
Validation loss: 2.472733916739728

Epoch: 6| Step: 11
Training loss: 2.667672583476892
Validation loss: 2.472852870843498

Epoch: 6| Step: 12
Training loss: 2.855370891684152
Validation loss: 2.4736238809015947

Epoch: 6| Step: 13
Training loss: 1.7236642116031684
Validation loss: 2.478490117399978

Epoch: 166| Step: 0
Training loss: 1.884720591268987
Validation loss: 2.481951237006114

Epoch: 6| Step: 1
Training loss: 2.389627884502439
Validation loss: 2.4967391205101146

Epoch: 6| Step: 2
Training loss: 2.1281779592145074
Validation loss: 2.4903472435997216

Epoch: 6| Step: 3
Training loss: 1.7704912491037836
Validation loss: 2.4828906313248202

Epoch: 6| Step: 4
Training loss: 2.6856738251244314
Validation loss: 2.4891157043607337

Epoch: 6| Step: 5
Training loss: 2.496067291740397
Validation loss: 2.4866236940289492

Epoch: 6| Step: 6
Training loss: 2.7041149641912394
Validation loss: 2.4785496614452343

Epoch: 6| Step: 7
Training loss: 2.8946220188091747
Validation loss: 2.4849058819606746

Epoch: 6| Step: 8
Training loss: 2.8795518086630105
Validation loss: 2.4858424732996345

Epoch: 6| Step: 9
Training loss: 2.391511241722921
Validation loss: 2.4897383451419146

Epoch: 6| Step: 10
Training loss: 2.3143041635211876
Validation loss: 2.4910445826331196

Epoch: 6| Step: 11
Training loss: 2.427977324994209
Validation loss: 2.4895866000314983

Epoch: 6| Step: 12
Training loss: 1.7525990803962654
Validation loss: 2.502737199870941

Epoch: 6| Step: 13
Training loss: 3.258071559787521
Validation loss: 2.4869928223133493

Epoch: 167| Step: 0
Training loss: 2.4670483482889853
Validation loss: 2.4939385364364837

Epoch: 6| Step: 1
Training loss: 2.137651926631165
Validation loss: 2.4782609220015432

Epoch: 6| Step: 2
Training loss: 1.9592023368821512
Validation loss: 2.4790317808583615

Epoch: 6| Step: 3
Training loss: 2.247228823247246
Validation loss: 2.4830261823513315

Epoch: 6| Step: 4
Training loss: 2.841122597734291
Validation loss: 2.482755184932441

Epoch: 6| Step: 5
Training loss: 2.826098733099191
Validation loss: 2.4788024271468636

Epoch: 6| Step: 6
Training loss: 2.1867234077690214
Validation loss: 2.484188608658954

Epoch: 6| Step: 7
Training loss: 2.788080379126465
Validation loss: 2.4905056914084716

Epoch: 6| Step: 8
Training loss: 1.8627906009364046
Validation loss: 2.480280142594644

Epoch: 6| Step: 9
Training loss: 2.72190568558469
Validation loss: 2.4854884581470857

Epoch: 6| Step: 10
Training loss: 2.6308812152547896
Validation loss: 2.486659585015421

Epoch: 6| Step: 11
Training loss: 2.162251620278494
Validation loss: 2.4863641001617607

Epoch: 6| Step: 12
Training loss: 2.6159715247456403
Validation loss: 2.4895368489244563

Epoch: 6| Step: 13
Training loss: 2.7795968446749613
Validation loss: 2.5023894970479947

Epoch: 168| Step: 0
Training loss: 2.3142623372049402
Validation loss: 2.5009361262827925

Epoch: 6| Step: 1
Training loss: 2.1621180864139657
Validation loss: 2.5197410791835098

Epoch: 6| Step: 2
Training loss: 2.4232160239530183
Validation loss: 2.5322967217500967

Epoch: 6| Step: 3
Training loss: 2.5659215460696996
Validation loss: 2.5257319362084676

Epoch: 6| Step: 4
Training loss: 1.9727316058278688
Validation loss: 2.5166350049012447

Epoch: 6| Step: 5
Training loss: 2.2777440551908
Validation loss: 2.5155995211683244

Epoch: 6| Step: 6
Training loss: 2.4399698899709485
Validation loss: 2.5049838932456074

Epoch: 6| Step: 7
Training loss: 2.6920358394827457
Validation loss: 2.483276620213008

Epoch: 6| Step: 8
Training loss: 1.7629171892257176
Validation loss: 2.4755633692367915

Epoch: 6| Step: 9
Training loss: 2.3038485794377936
Validation loss: 2.480937603070661

Epoch: 6| Step: 10
Training loss: 2.8263045716785142
Validation loss: 2.4676990122932394

Epoch: 6| Step: 11
Training loss: 2.686106830827138
Validation loss: 2.4758248338667936

Epoch: 6| Step: 12
Training loss: 3.3912513259901975
Validation loss: 2.4795159539967617

Epoch: 6| Step: 13
Training loss: 2.5301988090837386
Validation loss: 2.4760622869159077

Epoch: 169| Step: 0
Training loss: 2.302090490914059
Validation loss: 2.471869144038913

Epoch: 6| Step: 1
Training loss: 1.6756834343948435
Validation loss: 2.488395125389874

Epoch: 6| Step: 2
Training loss: 2.9466743862114275
Validation loss: 2.4943024720464613

Epoch: 6| Step: 3
Training loss: 2.632020735047359
Validation loss: 2.4976052099347887

Epoch: 6| Step: 4
Training loss: 2.722745918537766
Validation loss: 2.504002323777214

Epoch: 6| Step: 5
Training loss: 2.385009153336528
Validation loss: 2.50806672104036

Epoch: 6| Step: 6
Training loss: 2.634678210709387
Validation loss: 2.537710414737701

Epoch: 6| Step: 7
Training loss: 2.817845245438434
Validation loss: 2.552137659753241

Epoch: 6| Step: 8
Training loss: 2.513780284757966
Validation loss: 2.523107091729733

Epoch: 6| Step: 9
Training loss: 2.9820467669928026
Validation loss: 2.515642967712809

Epoch: 6| Step: 10
Training loss: 2.3607592027495516
Validation loss: 2.5167005305085555

Epoch: 6| Step: 11
Training loss: 1.6917841183083038
Validation loss: 2.513803142211611

Epoch: 6| Step: 12
Training loss: 1.809656807097884
Validation loss: 2.480835414429

Epoch: 6| Step: 13
Training loss: 2.6833792743738556
Validation loss: 2.483317848025009

Epoch: 170| Step: 0
Training loss: 2.3696917390540206
Validation loss: 2.481725563578435

Epoch: 6| Step: 1
Training loss: 2.4677602015065996
Validation loss: 2.47760596690588

Epoch: 6| Step: 2
Training loss: 1.9461223341390474
Validation loss: 2.4796242545414673

Epoch: 6| Step: 3
Training loss: 1.961887205632192
Validation loss: 2.484184001882171

Epoch: 6| Step: 4
Training loss: 1.9615877448805288
Validation loss: 2.4852627781446524

Epoch: 6| Step: 5
Training loss: 2.609553530861578
Validation loss: 2.48663316220458

Epoch: 6| Step: 6
Training loss: 2.6559401387512263
Validation loss: 2.4737934472533607

Epoch: 6| Step: 7
Training loss: 1.7587905536414417
Validation loss: 2.48452366478082

Epoch: 6| Step: 8
Training loss: 2.612253942264134
Validation loss: 2.4813541544234226

Epoch: 6| Step: 9
Training loss: 2.5223220863775464
Validation loss: 2.4799653350935134

Epoch: 6| Step: 10
Training loss: 2.6399815243739195
Validation loss: 2.480618754179045

Epoch: 6| Step: 11
Training loss: 3.1678459247151487
Validation loss: 2.4801621054792897

Epoch: 6| Step: 12
Training loss: 2.93008314385777
Validation loss: 2.4878331074769395

Epoch: 6| Step: 13
Training loss: 2.5179827522553677
Validation loss: 2.4741501877663055

Epoch: 171| Step: 0
Training loss: 2.390804209256436
Validation loss: 2.49243093515439

Epoch: 6| Step: 1
Training loss: 3.1692874670832922
Validation loss: 2.486407066704184

Epoch: 6| Step: 2
Training loss: 2.286511871707477
Validation loss: 2.486407889749544

Epoch: 6| Step: 3
Training loss: 3.031669666302081
Validation loss: 2.5016125246915935

Epoch: 6| Step: 4
Training loss: 3.007725622730714
Validation loss: 2.4847598787395317

Epoch: 6| Step: 5
Training loss: 3.0585591398305216
Validation loss: 2.5030347841969887

Epoch: 6| Step: 6
Training loss: 2.175681750558182
Validation loss: 2.4870697857123543

Epoch: 6| Step: 7
Training loss: 2.3754425640352825
Validation loss: 2.4886794876974543

Epoch: 6| Step: 8
Training loss: 1.9785200836342285
Validation loss: 2.4880186268716353

Epoch: 6| Step: 9
Training loss: 2.401173872766118
Validation loss: 2.4841635112194287

Epoch: 6| Step: 10
Training loss: 1.641342587441563
Validation loss: 2.4819568965902863

Epoch: 6| Step: 11
Training loss: 2.1158640198237033
Validation loss: 2.482345231716626

Epoch: 6| Step: 12
Training loss: 1.804951041659265
Validation loss: 2.4788406195069137

Epoch: 6| Step: 13
Training loss: 2.521303012273556
Validation loss: 2.4769438761817337

Epoch: 172| Step: 0
Training loss: 3.125593052856989
Validation loss: 2.4887960670917106

Epoch: 6| Step: 1
Training loss: 2.412569936420521
Validation loss: 2.4920138594546604

Epoch: 6| Step: 2
Training loss: 1.7604733821001817
Validation loss: 2.492491110680944

Epoch: 6| Step: 3
Training loss: 2.7516469358695304
Validation loss: 2.4988471949548705

Epoch: 6| Step: 4
Training loss: 2.4722744856416603
Validation loss: 2.4961715471205936

Epoch: 6| Step: 5
Training loss: 1.9782861725291216
Validation loss: 2.5073691636774207

Epoch: 6| Step: 6
Training loss: 1.8329116885507941
Validation loss: 2.5151354232386813

Epoch: 6| Step: 7
Training loss: 3.225672416671112
Validation loss: 2.531855961986925

Epoch: 6| Step: 8
Training loss: 2.3531654952213605
Validation loss: 2.5133969883569014

Epoch: 6| Step: 9
Training loss: 3.0147200891934434
Validation loss: 2.4894324832900283

Epoch: 6| Step: 10
Training loss: 2.3228118485093536
Validation loss: 2.4878656428500268

Epoch: 6| Step: 11
Training loss: 2.270817141227272
Validation loss: 2.4889031336249947

Epoch: 6| Step: 12
Training loss: 1.6965507520689451
Validation loss: 2.48086459788427

Epoch: 6| Step: 13
Training loss: 2.827477649765656
Validation loss: 2.481331990934819

Epoch: 173| Step: 0
Training loss: 2.440952203872615
Validation loss: 2.4794179377657457

Epoch: 6| Step: 1
Training loss: 2.3969346099961024
Validation loss: 2.478894071792518

Epoch: 6| Step: 2
Training loss: 2.4543696847911036
Validation loss: 2.4760750532540663

Epoch: 6| Step: 3
Training loss: 2.0392963377652245
Validation loss: 2.4837071382778815

Epoch: 6| Step: 4
Training loss: 3.2595358116732767
Validation loss: 2.4765765874644514

Epoch: 6| Step: 5
Training loss: 2.430586866146836
Validation loss: 2.4723083428111665

Epoch: 6| Step: 6
Training loss: 2.2979440082803695
Validation loss: 2.4757229638533906

Epoch: 6| Step: 7
Training loss: 2.5684909105160494
Validation loss: 2.474380438415558

Epoch: 6| Step: 8
Training loss: 2.081978917135153
Validation loss: 2.4799161680983275

Epoch: 6| Step: 9
Training loss: 2.1581439118008254
Validation loss: 2.4841711412517693

Epoch: 6| Step: 10
Training loss: 2.893684870932421
Validation loss: 2.4914265649843905

Epoch: 6| Step: 11
Training loss: 2.6092472616212192
Validation loss: 2.48804415656685

Epoch: 6| Step: 12
Training loss: 2.4114555430275995
Validation loss: 2.488312038867928

Epoch: 6| Step: 13
Training loss: 2.2519546072062555
Validation loss: 2.4969138010739766

Epoch: 174| Step: 0
Training loss: 2.7591966824140814
Validation loss: 2.484496483541656

Epoch: 6| Step: 1
Training loss: 2.301958751040448
Validation loss: 2.4898593276092846

Epoch: 6| Step: 2
Training loss: 2.094080315340352
Validation loss: 2.481960971162697

Epoch: 6| Step: 3
Training loss: 2.6576692267839013
Validation loss: 2.484249487691389

Epoch: 6| Step: 4
Training loss: 2.257282445654338
Validation loss: 2.475995148213881

Epoch: 6| Step: 5
Training loss: 2.4606636984962345
Validation loss: 2.476001920743494

Epoch: 6| Step: 6
Training loss: 2.5307623311034133
Validation loss: 2.4811021691908257

Epoch: 6| Step: 7
Training loss: 2.4132071649473796
Validation loss: 2.4851374226008556

Epoch: 6| Step: 8
Training loss: 2.3451112990004774
Validation loss: 2.4828109136231853

Epoch: 6| Step: 9
Training loss: 3.3910606561453935
Validation loss: 2.486783921065599

Epoch: 6| Step: 10
Training loss: 2.190712667716302
Validation loss: 2.504490618028595

Epoch: 6| Step: 11
Training loss: 1.8443427345403518
Validation loss: 2.4973907046353236

Epoch: 6| Step: 12
Training loss: 2.5344656781062422
Validation loss: 2.4915179845109936

Epoch: 6| Step: 13
Training loss: 2.2834416143354974
Validation loss: 2.4865617544919285

Epoch: 175| Step: 0
Training loss: 2.820198120164823
Validation loss: 2.4880560229547095

Epoch: 6| Step: 1
Training loss: 2.0302507730441905
Validation loss: 2.4926985572424507

Epoch: 6| Step: 2
Training loss: 2.0931524306487828
Validation loss: 2.491843388158149

Epoch: 6| Step: 3
Training loss: 2.424440169848807
Validation loss: 2.48989550709581

Epoch: 6| Step: 4
Training loss: 2.586175083644365
Validation loss: 2.4992000969074124

Epoch: 6| Step: 5
Training loss: 2.0366753530030928
Validation loss: 2.494615637529345

Epoch: 6| Step: 6
Training loss: 2.477992466272412
Validation loss: 2.4901546211187084

Epoch: 6| Step: 7
Training loss: 2.937220296326585
Validation loss: 2.497356304429996

Epoch: 6| Step: 8
Training loss: 2.544729721766546
Validation loss: 2.5009927209155633

Epoch: 6| Step: 9
Training loss: 1.8056205550337467
Validation loss: 2.497243410510211

Epoch: 6| Step: 10
Training loss: 2.7233633603604406
Validation loss: 2.517838035802157

Epoch: 6| Step: 11
Training loss: 2.3276208933441724
Validation loss: 2.5010571311039373

Epoch: 6| Step: 12
Training loss: 2.031519006375919
Validation loss: 2.490566065021985

Epoch: 6| Step: 13
Training loss: 3.100539338970703
Validation loss: 2.479292430946827

Testing loss: 1.9961062201096844
