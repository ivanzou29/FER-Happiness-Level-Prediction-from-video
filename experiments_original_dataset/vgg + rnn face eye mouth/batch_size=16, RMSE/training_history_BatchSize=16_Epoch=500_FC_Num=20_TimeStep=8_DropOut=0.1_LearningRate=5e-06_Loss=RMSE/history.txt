Epoch: 1| Step: 0
Training loss: 5.259575240821942
Validation loss: 5.8850905426501665

Epoch: 6| Step: 1
Training loss: 5.871659973007893
Validation loss: 5.883506946685728

Epoch: 6| Step: 2
Training loss: 5.938388476904885
Validation loss: 5.882071601647186

Epoch: 6| Step: 3
Training loss: 5.498094748903471
Validation loss: 5.880672448907067

Epoch: 6| Step: 4
Training loss: 6.154119907305682
Validation loss: 5.879323112772758

Epoch: 6| Step: 5
Training loss: 5.702598233913348
Validation loss: 5.878121216532956

Epoch: 6| Step: 6
Training loss: 6.159301001783109
Validation loss: 5.876890135461637

Epoch: 6| Step: 7
Training loss: 5.1562622070168
Validation loss: 5.875663746884348

Epoch: 6| Step: 8
Training loss: 6.521145391665354
Validation loss: 5.87452974534151

Epoch: 6| Step: 9
Training loss: 6.504923789584378
Validation loss: 5.873317667016141

Epoch: 6| Step: 10
Training loss: 5.656299906979413
Validation loss: 5.87199259950343

Epoch: 6| Step: 11
Training loss: 6.792571149951131
Validation loss: 5.870714992235632

Epoch: 6| Step: 12
Training loss: 5.627378172943272
Validation loss: 5.869321310654672

Epoch: 6| Step: 13
Training loss: 6.758585802937184
Validation loss: 5.867836067664471

Epoch: 2| Step: 0
Training loss: 6.97983370957226
Validation loss: 5.866258570536594

Epoch: 6| Step: 1
Training loss: 5.877224764721747
Validation loss: 5.864528034642868

Epoch: 6| Step: 2
Training loss: 5.682433837827684
Validation loss: 5.862729752518192

Epoch: 6| Step: 3
Training loss: 5.195613903968551
Validation loss: 5.860767032995528

Epoch: 6| Step: 4
Training loss: 5.90100704585865
Validation loss: 5.858863367419417

Epoch: 6| Step: 5
Training loss: 6.647417252431931
Validation loss: 5.856716926386553

Epoch: 6| Step: 6
Training loss: 6.041073088152177
Validation loss: 5.8544971015322025

Epoch: 6| Step: 7
Training loss: 5.317425587379605
Validation loss: 5.852216601684825

Epoch: 6| Step: 8
Training loss: 6.615713844910039
Validation loss: 5.849699639763361

Epoch: 6| Step: 9
Training loss: 6.453803001421127
Validation loss: 5.847261349669703

Epoch: 6| Step: 10
Training loss: 5.592339193925214
Validation loss: 5.844528418390141

Epoch: 6| Step: 11
Training loss: 5.319796230457869
Validation loss: 5.841775924524313

Epoch: 6| Step: 12
Training loss: 6.217017464375
Validation loss: 5.838722800156962

Epoch: 6| Step: 13
Training loss: 5.384134027952594
Validation loss: 5.83582193787057

Epoch: 3| Step: 0
Training loss: 7.040364643536927
Validation loss: 5.832588947575529

Epoch: 6| Step: 1
Training loss: 5.9606040771347555
Validation loss: 5.829231627590641

Epoch: 6| Step: 2
Training loss: 5.554773686809384
Validation loss: 5.825766651308692

Epoch: 6| Step: 3
Training loss: 5.542113761744711
Validation loss: 5.822026884807757

Epoch: 6| Step: 4
Training loss: 5.519313886267612
Validation loss: 5.818234557893528

Epoch: 6| Step: 5
Training loss: 5.873818136608685
Validation loss: 5.814261603626209

Epoch: 6| Step: 6
Training loss: 5.9905833418486685
Validation loss: 5.809984325884601

Epoch: 6| Step: 7
Training loss: 5.40485200832859
Validation loss: 5.805666772891503

Epoch: 6| Step: 8
Training loss: 5.6170934422540695
Validation loss: 5.801118461149445

Epoch: 6| Step: 9
Training loss: 6.199798999112353
Validation loss: 5.796301389215083

Epoch: 6| Step: 10
Training loss: 6.111144607143888
Validation loss: 5.7913751963358315

Epoch: 6| Step: 11
Training loss: 6.244603993891634
Validation loss: 5.786197586662752

Epoch: 6| Step: 12
Training loss: 5.8401350784356865
Validation loss: 5.780939592155926

Epoch: 6| Step: 13
Training loss: 5.823662652652069
Validation loss: 5.775345710215949

Epoch: 4| Step: 0
Training loss: 5.42630606544352
Validation loss: 5.769561223404426

Epoch: 6| Step: 1
Training loss: 5.045216007201889
Validation loss: 5.763566501696528

Epoch: 6| Step: 2
Training loss: 7.006336069386588
Validation loss: 5.7576069754190735

Epoch: 6| Step: 3
Training loss: 4.605139075880675
Validation loss: 5.751403664908208

Epoch: 6| Step: 4
Training loss: 5.86573905691669
Validation loss: 5.745107255315725

Epoch: 6| Step: 5
Training loss: 6.2856320710193145
Validation loss: 5.738688164313253

Epoch: 6| Step: 6
Training loss: 6.240590145374781
Validation loss: 5.732165362171451

Epoch: 6| Step: 7
Training loss: 5.74028587772489
Validation loss: 5.725657781490383

Epoch: 6| Step: 8
Training loss: 5.91118500423535
Validation loss: 5.719066979355945

Epoch: 6| Step: 9
Training loss: 6.306532049913172
Validation loss: 5.71200497274957

Epoch: 6| Step: 10
Training loss: 5.7861986579850475
Validation loss: 5.705371013794777

Epoch: 6| Step: 11
Training loss: 5.638673228047985
Validation loss: 5.6983527017275195

Epoch: 6| Step: 12
Training loss: 6.126505141316869
Validation loss: 5.6913611751282165

Epoch: 6| Step: 13
Training loss: 5.452647890571579
Validation loss: 5.684411352543617

Epoch: 5| Step: 0
Training loss: 5.422894736485123
Validation loss: 5.677677377774053

Epoch: 6| Step: 1
Training loss: 6.701395020512316
Validation loss: 5.670654361693265

Epoch: 6| Step: 2
Training loss: 6.5129131281286705
Validation loss: 5.663629681065457

Epoch: 6| Step: 3
Training loss: 5.898916060884353
Validation loss: 5.656467665388441

Epoch: 6| Step: 4
Training loss: 4.992662768358653
Validation loss: 5.64947109166152

Epoch: 6| Step: 5
Training loss: 5.974242554222224
Validation loss: 5.642524181128798

Epoch: 6| Step: 6
Training loss: 5.833831693160259
Validation loss: 5.635506516996024

Epoch: 6| Step: 7
Training loss: 5.925899698058119
Validation loss: 5.628631803946261

Epoch: 6| Step: 8
Training loss: 5.639624340451766
Validation loss: 5.6215433308092555

Epoch: 6| Step: 9
Training loss: 5.447923513180847
Validation loss: 5.614568008467993

Epoch: 6| Step: 10
Training loss: 5.772041864466702
Validation loss: 5.607846957802631

Epoch: 6| Step: 11
Training loss: 4.511904758070414
Validation loss: 5.600663925732071

Epoch: 6| Step: 12
Training loss: 5.641587616419711
Validation loss: 5.593824418068396

Epoch: 6| Step: 13
Training loss: 5.902031254653622
Validation loss: 5.587034943732116

Epoch: 6| Step: 0
Training loss: 6.155597787766503
Validation loss: 5.579998709656852

Epoch: 6| Step: 1
Training loss: 5.761383067551941
Validation loss: 5.572851143805329

Epoch: 6| Step: 2
Training loss: 5.4009090788656895
Validation loss: 5.565763452011919

Epoch: 6| Step: 3
Training loss: 5.713014822367933
Validation loss: 5.558208510309371

Epoch: 6| Step: 4
Training loss: 5.179938631025604
Validation loss: 5.550744998177275

Epoch: 6| Step: 5
Training loss: 5.811513509406954
Validation loss: 5.543668065259455

Epoch: 6| Step: 6
Training loss: 6.114570613330129
Validation loss: 5.535831084535436

Epoch: 6| Step: 7
Training loss: 5.720268673222234
Validation loss: 5.528093173530414

Epoch: 6| Step: 8
Training loss: 6.024753372399752
Validation loss: 5.520537381666859

Epoch: 6| Step: 9
Training loss: 5.142807332055001
Validation loss: 5.513518913832774

Epoch: 6| Step: 10
Training loss: 5.313256602544931
Validation loss: 5.505798202378704

Epoch: 6| Step: 11
Training loss: 4.894203315094045
Validation loss: 5.4981488667271785

Epoch: 6| Step: 12
Training loss: 5.580309186456883
Validation loss: 5.491124852976904

Epoch: 6| Step: 13
Training loss: 6.133442568151788
Validation loss: 5.483348464171955

Epoch: 7| Step: 0
Training loss: 4.883871955374062
Validation loss: 5.4758533956512085

Epoch: 6| Step: 1
Training loss: 5.776264742461169
Validation loss: 5.468219607836241

Epoch: 6| Step: 2
Training loss: 5.664065530710396
Validation loss: 5.460921317073363

Epoch: 6| Step: 3
Training loss: 5.1294235119734015
Validation loss: 5.453654295438394

Epoch: 6| Step: 4
Training loss: 5.344228444236321
Validation loss: 5.446252202700489

Epoch: 6| Step: 5
Training loss: 5.277770030144253
Validation loss: 5.439238493250159

Epoch: 6| Step: 6
Training loss: 4.795769679058326
Validation loss: 5.431760045704536

Epoch: 6| Step: 7
Training loss: 5.328464172844196
Validation loss: 5.424791971369735

Epoch: 6| Step: 8
Training loss: 6.080691386615325
Validation loss: 5.418123909970719

Epoch: 6| Step: 9
Training loss: 5.651637773379003
Validation loss: 5.411279797171269

Epoch: 6| Step: 10
Training loss: 6.054051755937855
Validation loss: 5.4043493733615176

Epoch: 6| Step: 11
Training loss: 5.796053352631662
Validation loss: 5.397154137027118

Epoch: 6| Step: 12
Training loss: 6.007839168097508
Validation loss: 5.390613824952562

Epoch: 6| Step: 13
Training loss: 5.686833269213714
Validation loss: 5.383362349362118

Epoch: 8| Step: 0
Training loss: 5.896686541644397
Validation loss: 5.376978221852754

Epoch: 6| Step: 1
Training loss: 4.542575546921295
Validation loss: 5.37012088727179

Epoch: 6| Step: 2
Training loss: 5.469801621823637
Validation loss: 5.363497261796541

Epoch: 6| Step: 3
Training loss: 4.916546556115598
Validation loss: 5.356970719493442

Epoch: 6| Step: 4
Training loss: 6.013688684918857
Validation loss: 5.350276211414865

Epoch: 6| Step: 5
Training loss: 5.2329936012419935
Validation loss: 5.343995503220027

Epoch: 6| Step: 6
Training loss: 5.261880420446861
Validation loss: 5.337767496188219

Epoch: 6| Step: 7
Training loss: 4.980911247193328
Validation loss: 5.331567362633371

Epoch: 6| Step: 8
Training loss: 4.987350102134376
Validation loss: 5.325143436655142

Epoch: 6| Step: 9
Training loss: 5.747139592429702
Validation loss: 5.319497589872837

Epoch: 6| Step: 10
Training loss: 5.492617941602801
Validation loss: 5.3135696082348645

Epoch: 6| Step: 11
Training loss: 5.896622819466142
Validation loss: 5.308058943111937

Epoch: 6| Step: 12
Training loss: 5.923292005599062
Validation loss: 5.301894218904347

Epoch: 6| Step: 13
Training loss: 5.778690245705383
Validation loss: 5.296315451505612

Epoch: 9| Step: 0
Training loss: 5.214396962660601
Validation loss: 5.2902274489947185

Epoch: 6| Step: 1
Training loss: 6.009090530716579
Validation loss: 5.284011359686509

Epoch: 6| Step: 2
Training loss: 4.745673367442097
Validation loss: 5.278107379637736

Epoch: 6| Step: 3
Training loss: 4.812663880567532
Validation loss: 5.27269483823377

Epoch: 6| Step: 4
Training loss: 5.709462446306241
Validation loss: 5.2668456220201705

Epoch: 6| Step: 5
Training loss: 4.679432959153691
Validation loss: 5.260999812168876

Epoch: 6| Step: 6
Training loss: 6.037583894324439
Validation loss: 5.255948889442728

Epoch: 6| Step: 7
Training loss: 5.936974110654027
Validation loss: 5.25012001021533

Epoch: 6| Step: 8
Training loss: 5.862111990966132
Validation loss: 5.244914786122664

Epoch: 6| Step: 9
Training loss: 4.126383000506633
Validation loss: 5.23941526149719

Epoch: 6| Step: 10
Training loss: 4.8106551163979505
Validation loss: 5.234175493224512

Epoch: 6| Step: 11
Training loss: 5.748838556167067
Validation loss: 5.2292750171312745

Epoch: 6| Step: 12
Training loss: 5.197386363568427
Validation loss: 5.22408209591044

Epoch: 6| Step: 13
Training loss: 5.906672064015927
Validation loss: 5.219003941492738

Epoch: 10| Step: 0
Training loss: 5.567609519069736
Validation loss: 5.214237996136228

Epoch: 6| Step: 1
Training loss: 5.338466240574891
Validation loss: 5.208806812381483

Epoch: 6| Step: 2
Training loss: 5.076066477298934
Validation loss: 5.203700647595826

Epoch: 6| Step: 3
Training loss: 5.476048770595406
Validation loss: 5.199153908340266

Epoch: 6| Step: 4
Training loss: 5.220404813715827
Validation loss: 5.193897331832008

Epoch: 6| Step: 5
Training loss: 5.466661326863232
Validation loss: 5.1891814115155634

Epoch: 6| Step: 6
Training loss: 4.720608174857064
Validation loss: 5.184048005825652

Epoch: 6| Step: 7
Training loss: 5.973551631299162
Validation loss: 5.1793155680473815

Epoch: 6| Step: 8
Training loss: 5.434090784240468
Validation loss: 5.174223429083394

Epoch: 6| Step: 9
Training loss: 4.718397114676456
Validation loss: 5.169524520170926

Epoch: 6| Step: 10
Training loss: 5.3397023001565245
Validation loss: 5.164574671290885

Epoch: 6| Step: 11
Training loss: 4.974208880067658
Validation loss: 5.1593285204039345

Epoch: 6| Step: 12
Training loss: 5.238948270358487
Validation loss: 5.154163285143562

Epoch: 6| Step: 13
Training loss: 5.590945259930215
Validation loss: 5.149372423074661

Epoch: 11| Step: 0
Training loss: 4.497518066912798
Validation loss: 5.145124759872922

Epoch: 6| Step: 1
Training loss: 5.408341725268953
Validation loss: 5.139853994569292

Epoch: 6| Step: 2
Training loss: 5.372052471254004
Validation loss: 5.134472041142696

Epoch: 6| Step: 3
Training loss: 6.301476853458082
Validation loss: 5.129778425402562

Epoch: 6| Step: 4
Training loss: 4.666773022847516
Validation loss: 5.124982973396117

Epoch: 6| Step: 5
Training loss: 5.045012989764698
Validation loss: 5.119856168147252

Epoch: 6| Step: 6
Training loss: 4.724071609277328
Validation loss: 5.114689822619557

Epoch: 6| Step: 7
Training loss: 5.833615250814134
Validation loss: 5.109818061182596

Epoch: 6| Step: 8
Training loss: 5.859287108715811
Validation loss: 5.10471220669247

Epoch: 6| Step: 9
Training loss: 5.248098483185028
Validation loss: 5.099331471626407

Epoch: 6| Step: 10
Training loss: 4.399033284194292
Validation loss: 5.093930418723753

Epoch: 6| Step: 11
Training loss: 4.861964084933536
Validation loss: 5.0888610968647585

Epoch: 6| Step: 12
Training loss: 5.5040171431341
Validation loss: 5.083158219036338

Epoch: 6| Step: 13
Training loss: 5.214200349471032
Validation loss: 5.078087846668974

Epoch: 12| Step: 0
Training loss: 4.58545044062284
Validation loss: 5.072694192612555

Epoch: 6| Step: 1
Training loss: 4.487307769143392
Validation loss: 5.066888171089031

Epoch: 6| Step: 2
Training loss: 5.60419669255529
Validation loss: 5.0619796830905885

Epoch: 6| Step: 3
Training loss: 5.017417706174404
Validation loss: 5.055523559040546

Epoch: 6| Step: 4
Training loss: 5.430282186970301
Validation loss: 5.049696945312853

Epoch: 6| Step: 5
Training loss: 5.554990006376903
Validation loss: 5.044477808744433

Epoch: 6| Step: 6
Training loss: 5.19223064137208
Validation loss: 5.039896310037355

Epoch: 6| Step: 7
Training loss: 5.086123133493008
Validation loss: 5.034716026331571

Epoch: 6| Step: 8
Training loss: 4.929472372980354
Validation loss: 5.03029590350618

Epoch: 6| Step: 9
Training loss: 5.05152117036478
Validation loss: 5.025639440487842

Epoch: 6| Step: 10
Training loss: 5.129934958776223
Validation loss: 5.021977126818522

Epoch: 6| Step: 11
Training loss: 4.758109949394544
Validation loss: 5.017015812954926

Epoch: 6| Step: 12
Training loss: 5.920862921637049
Validation loss: 5.011608444668978

Epoch: 6| Step: 13
Training loss: 5.338325826111817
Validation loss: 5.005696421419447

Epoch: 13| Step: 0
Training loss: 4.95767455439591
Validation loss: 5.000897454145919

Epoch: 6| Step: 1
Training loss: 5.016470294205527
Validation loss: 4.996140707241214

Epoch: 6| Step: 2
Training loss: 4.888574334823969
Validation loss: 4.990851393126784

Epoch: 6| Step: 3
Training loss: 5.183339852250263
Validation loss: 4.984112739639052

Epoch: 6| Step: 4
Training loss: 4.5794300914151105
Validation loss: 4.980365475849197

Epoch: 6| Step: 5
Training loss: 5.039845581716649
Validation loss: 4.975595776589062

Epoch: 6| Step: 6
Training loss: 5.339139499840296
Validation loss: 4.969973527465563

Epoch: 6| Step: 7
Training loss: 4.738835917916297
Validation loss: 4.963994947819748

Epoch: 6| Step: 8
Training loss: 4.63191242705792
Validation loss: 4.9583413046551055

Epoch: 6| Step: 9
Training loss: 6.298069540076596
Validation loss: 4.954276383288984

Epoch: 6| Step: 10
Training loss: 5.363252266001891
Validation loss: 4.948836370287584

Epoch: 6| Step: 11
Training loss: 5.098454648923427
Validation loss: 4.943121177011721

Epoch: 6| Step: 12
Training loss: 4.620825662196642
Validation loss: 4.938558634007575

Epoch: 6| Step: 13
Training loss: 5.2918594605576
Validation loss: 4.9331014814967675

Epoch: 14| Step: 0
Training loss: 4.18421237620995
Validation loss: 4.928841414997395

Epoch: 6| Step: 1
Training loss: 5.451380059733871
Validation loss: 4.923917929710421

Epoch: 6| Step: 2
Training loss: 5.252882756372663
Validation loss: 4.919360031953622

Epoch: 6| Step: 3
Training loss: 3.9090712468174984
Validation loss: 4.913915780550155

Epoch: 6| Step: 4
Training loss: 4.7208514050202055
Validation loss: 4.909341441557192

Epoch: 6| Step: 5
Training loss: 5.358456012909423
Validation loss: 4.905244825541597

Epoch: 6| Step: 6
Training loss: 4.340809217681265
Validation loss: 4.901151303866628

Epoch: 6| Step: 7
Training loss: 4.847483518905913
Validation loss: 4.895296297311375

Epoch: 6| Step: 8
Training loss: 5.386085965484388
Validation loss: 4.890857370074539

Epoch: 6| Step: 9
Training loss: 4.9356850294153425
Validation loss: 4.887060521912993

Epoch: 6| Step: 10
Training loss: 4.763041211712602
Validation loss: 4.882034573447287

Epoch: 6| Step: 11
Training loss: 5.886063891806454
Validation loss: 4.876311215509709

Epoch: 6| Step: 12
Training loss: 4.894245209369223
Validation loss: 4.871791566301941

Epoch: 6| Step: 13
Training loss: 5.926093780383203
Validation loss: 4.869012318091337

Epoch: 15| Step: 0
Training loss: 5.237895635624794
Validation loss: 4.861672629970746

Epoch: 6| Step: 1
Training loss: 5.299559506518892
Validation loss: 4.85711818676782

Epoch: 6| Step: 2
Training loss: 4.770287206228492
Validation loss: 4.853297743841479

Epoch: 6| Step: 3
Training loss: 4.428965353255972
Validation loss: 4.849398299709151

Epoch: 6| Step: 4
Training loss: 5.199196005068581
Validation loss: 4.844643984096416

Epoch: 6| Step: 5
Training loss: 5.884856052761083
Validation loss: 4.838563648689961

Epoch: 6| Step: 6
Training loss: 4.6663532605971385
Validation loss: 4.833753973097147

Epoch: 6| Step: 7
Training loss: 5.295612556103435
Validation loss: 4.829732551146559

Epoch: 6| Step: 8
Training loss: 4.155048856482419
Validation loss: 4.823994833914467

Epoch: 6| Step: 9
Training loss: 4.94049734569579
Validation loss: 4.818735780872257

Epoch: 6| Step: 10
Training loss: 4.583137762347672
Validation loss: 4.813750430727609

Epoch: 6| Step: 11
Training loss: 5.050479699947814
Validation loss: 4.809655575069119

Epoch: 6| Step: 12
Training loss: 4.701662564948041
Validation loss: 4.805006493211078

Epoch: 6| Step: 13
Training loss: 4.9552721249468625
Validation loss: 4.801236964158994

Epoch: 16| Step: 0
Training loss: 5.975886846510309
Validation loss: 4.795894195320699

Epoch: 6| Step: 1
Training loss: 4.776183791491636
Validation loss: 4.79065860704154

Epoch: 6| Step: 2
Training loss: 4.17691273075308
Validation loss: 4.785669283190994

Epoch: 6| Step: 3
Training loss: 5.020901860235102
Validation loss: 4.781471164217384

Epoch: 6| Step: 4
Training loss: 5.723677050060448
Validation loss: 4.776564252988464

Epoch: 6| Step: 5
Training loss: 4.769967923806262
Validation loss: 4.7729956156499185

Epoch: 6| Step: 6
Training loss: 3.8636369531804413
Validation loss: 4.76869239689012

Epoch: 6| Step: 7
Training loss: 4.383605341334256
Validation loss: 4.763301261987871

Epoch: 6| Step: 8
Training loss: 4.875002347505444
Validation loss: 4.757784755147749

Epoch: 6| Step: 9
Training loss: 5.328567799713407
Validation loss: 4.7540951526466415

Epoch: 6| Step: 10
Training loss: 5.41484647637132
Validation loss: 4.749140879252065

Epoch: 6| Step: 11
Training loss: 4.308128020499812
Validation loss: 4.74295441628426

Epoch: 6| Step: 12
Training loss: 4.984457272415635
Validation loss: 4.739019115805752

Epoch: 6| Step: 13
Training loss: 4.416606446821305
Validation loss: 4.734655390830665

Epoch: 17| Step: 0
Training loss: 2.834231196985579
Validation loss: 4.730705643803664

Epoch: 6| Step: 1
Training loss: 5.942742853847298
Validation loss: 4.725524082082515

Epoch: 6| Step: 2
Training loss: 4.8569753922515915
Validation loss: 4.7199870460677325

Epoch: 6| Step: 3
Training loss: 4.424402168536467
Validation loss: 4.717902067348782

Epoch: 6| Step: 4
Training loss: 4.76424460508741
Validation loss: 4.71360788316389

Epoch: 6| Step: 5
Training loss: 4.956871372828096
Validation loss: 4.709263239941204

Epoch: 6| Step: 6
Training loss: 4.742030233826582
Validation loss: 4.70353563444542

Epoch: 6| Step: 7
Training loss: 6.096632055841685
Validation loss: 4.700037875597773

Epoch: 6| Step: 8
Training loss: 4.509582700856506
Validation loss: 4.693608758243036

Epoch: 6| Step: 9
Training loss: 4.911836395869182
Validation loss: 4.689350593629132

Epoch: 6| Step: 10
Training loss: 4.341571069251917
Validation loss: 4.6852141846965685

Epoch: 6| Step: 11
Training loss: 5.540926642471544
Validation loss: 4.680623448625001

Epoch: 6| Step: 12
Training loss: 3.017358627484149
Validation loss: 4.674775106967202

Epoch: 6| Step: 13
Training loss: 5.455264133733474
Validation loss: 4.6710065291749805

Epoch: 18| Step: 0
Training loss: 3.3645731607919136
Validation loss: 4.666047832920225

Epoch: 6| Step: 1
Training loss: 5.381921436985293
Validation loss: 4.662371373042916

Epoch: 6| Step: 2
Training loss: 4.914417636089174
Validation loss: 4.65683320252621

Epoch: 6| Step: 3
Training loss: 5.694347242233891
Validation loss: 4.6528080074157

Epoch: 6| Step: 4
Training loss: 5.032475292677663
Validation loss: 4.647819037661005

Epoch: 6| Step: 5
Training loss: 4.503803553076239
Validation loss: 4.644078948399925

Epoch: 6| Step: 6
Training loss: 4.534998743967641
Validation loss: 4.639328969358539

Epoch: 6| Step: 7
Training loss: 5.007615393510298
Validation loss: 4.63502004691092

Epoch: 6| Step: 8
Training loss: 4.709151452928246
Validation loss: 4.630091124668451

Epoch: 6| Step: 9
Training loss: 5.108692181892169
Validation loss: 4.626029510012502

Epoch: 6| Step: 10
Training loss: 3.836240923470865
Validation loss: 4.621054091596432

Epoch: 6| Step: 11
Training loss: 4.569364217861031
Validation loss: 4.617697716076939

Epoch: 6| Step: 12
Training loss: 5.122498436737194
Validation loss: 4.611535138367424

Epoch: 6| Step: 13
Training loss: 4.437871783088688
Validation loss: 4.606797871816703

Epoch: 19| Step: 0
Training loss: 4.97286720757353
Validation loss: 4.6022787351672525

Epoch: 6| Step: 1
Training loss: 4.234625664643017
Validation loss: 4.5985094530354695

Epoch: 6| Step: 2
Training loss: 4.519750696919542
Validation loss: 4.5946626686466985

Epoch: 6| Step: 3
Training loss: 4.482516764382343
Validation loss: 4.588773146414825

Epoch: 6| Step: 4
Training loss: 4.292454224455162
Validation loss: 4.585192089598299

Epoch: 6| Step: 5
Training loss: 4.931962976779255
Validation loss: 4.581405679331002

Epoch: 6| Step: 6
Training loss: 4.7211081568201285
Validation loss: 4.577202991605141

Epoch: 6| Step: 7
Training loss: 4.99550751086791
Validation loss: 4.572097890396095

Epoch: 6| Step: 8
Training loss: 5.223934681903193
Validation loss: 4.56824930685528

Epoch: 6| Step: 9
Training loss: 4.092324044948932
Validation loss: 4.563809420316261

Epoch: 6| Step: 10
Training loss: 5.019596987045227
Validation loss: 4.557863797559653

Epoch: 6| Step: 11
Training loss: 3.5008584740806064
Validation loss: 4.553678092099091

Epoch: 6| Step: 12
Training loss: 5.690754724204399
Validation loss: 4.550536229600679

Epoch: 6| Step: 13
Training loss: 4.738938552538567
Validation loss: 4.544991084370893

Epoch: 20| Step: 0
Training loss: 4.055718028212173
Validation loss: 4.54018365054412

Epoch: 6| Step: 1
Training loss: 4.394212445033235
Validation loss: 4.535853535760596

Epoch: 6| Step: 2
Training loss: 4.5474228152057625
Validation loss: 4.532619523669295

Epoch: 6| Step: 3
Training loss: 3.68081693061097
Validation loss: 4.527624078233847

Epoch: 6| Step: 4
Training loss: 4.11951845262212
Validation loss: 4.522078956304996

Epoch: 6| Step: 5
Training loss: 5.67736920211544
Validation loss: 4.517625271091717

Epoch: 6| Step: 6
Training loss: 5.592699346489547
Validation loss: 4.513565984408507

Epoch: 6| Step: 7
Training loss: 4.861905631878411
Validation loss: 4.508537952529738

Epoch: 6| Step: 8
Training loss: 4.4838662739532404
Validation loss: 4.50315777927516

Epoch: 6| Step: 9
Training loss: 3.8716834857612024
Validation loss: 4.498378072833936

Epoch: 6| Step: 10
Training loss: 4.575852178200066
Validation loss: 4.494985912924684

Epoch: 6| Step: 11
Training loss: 5.205596978126682
Validation loss: 4.489984422131357

Epoch: 6| Step: 12
Training loss: 4.48705081657402
Validation loss: 4.484431249817348

Epoch: 6| Step: 13
Training loss: 4.883865511455488
Validation loss: 4.4798066620888495

Epoch: 21| Step: 0
Training loss: 4.363116665077964
Validation loss: 4.475236395589294

Epoch: 6| Step: 1
Training loss: 4.525235097268083
Validation loss: 4.470257164813661

Epoch: 6| Step: 2
Training loss: 4.381425335432604
Validation loss: 4.464973223108621

Epoch: 6| Step: 3
Training loss: 4.726318958407954
Validation loss: 4.460904862283919

Epoch: 6| Step: 4
Training loss: 5.283018278882799
Validation loss: 4.456260639051353

Epoch: 6| Step: 5
Training loss: 4.5037432043070345
Validation loss: 4.4519562553914005

Epoch: 6| Step: 6
Training loss: 4.37643627024206
Validation loss: 4.4471001095155875

Epoch: 6| Step: 7
Training loss: 4.400786780325612
Validation loss: 4.441431909384707

Epoch: 6| Step: 8
Training loss: 4.737960817174212
Validation loss: 4.437013339726672

Epoch: 6| Step: 9
Training loss: 4.155123909435047
Validation loss: 4.433386691687773

Epoch: 6| Step: 10
Training loss: 4.702990152954201
Validation loss: 4.428920959853765

Epoch: 6| Step: 11
Training loss: 4.357807055196715
Validation loss: 4.422015472085985

Epoch: 6| Step: 12
Training loss: 4.365305595755689
Validation loss: 4.417397720485596

Epoch: 6| Step: 13
Training loss: 5.022115625433629
Validation loss: 4.415318853227165

Epoch: 22| Step: 0
Training loss: 5.10056864242353
Validation loss: 4.410496858790649

Epoch: 6| Step: 1
Training loss: 3.1816428730712594
Validation loss: 4.404729558268703

Epoch: 6| Step: 2
Training loss: 4.697768091303875
Validation loss: 4.399135807452052

Epoch: 6| Step: 3
Training loss: 5.183885533069833
Validation loss: 4.3944400670517

Epoch: 6| Step: 4
Training loss: 4.376341259943782
Validation loss: 4.38957022490111

Epoch: 6| Step: 5
Training loss: 4.427520921809577
Validation loss: 4.384714585356248

Epoch: 6| Step: 6
Training loss: 3.6898944645291407
Validation loss: 4.38128960229205

Epoch: 6| Step: 7
Training loss: 5.239129210473168
Validation loss: 4.375220265974441

Epoch: 6| Step: 8
Training loss: 4.455997865453788
Validation loss: 4.370205931943435

Epoch: 6| Step: 9
Training loss: 3.9270821460887353
Validation loss: 4.365839823609827

Epoch: 6| Step: 10
Training loss: 4.751351214512295
Validation loss: 4.3611571248104735

Epoch: 6| Step: 11
Training loss: 4.438160806803411
Validation loss: 4.355934033822942

Epoch: 6| Step: 12
Training loss: 4.267855888772383
Validation loss: 4.351320288518825

Epoch: 6| Step: 13
Training loss: 4.8807302200673925
Validation loss: 4.347151414797636

Epoch: 23| Step: 0
Training loss: 4.660130055458652
Validation loss: 4.3407646184208355

Epoch: 6| Step: 1
Training loss: 4.3860575856239254
Validation loss: 4.3359771451770035

Epoch: 6| Step: 2
Training loss: 3.4866653920372506
Validation loss: 4.330953506956516

Epoch: 6| Step: 3
Training loss: 3.783510399482624
Validation loss: 4.327694280425863

Epoch: 6| Step: 4
Training loss: 4.337544571265504
Validation loss: 4.323530584044881

Epoch: 6| Step: 5
Training loss: 4.060219931823323
Validation loss: 4.319073260768893

Epoch: 6| Step: 6
Training loss: 5.182741855511341
Validation loss: 4.312944324841928

Epoch: 6| Step: 7
Training loss: 4.1089584081405714
Validation loss: 4.308201624162457

Epoch: 6| Step: 8
Training loss: 4.307945832190885
Validation loss: 4.302983384582795

Epoch: 6| Step: 9
Training loss: 4.8829499980640545
Validation loss: 4.299267282084368

Epoch: 6| Step: 10
Training loss: 5.032024442410199
Validation loss: 4.295331606100271

Epoch: 6| Step: 11
Training loss: 4.388701862798081
Validation loss: 4.2885737462017985

Epoch: 6| Step: 12
Training loss: 4.917655759127839
Validation loss: 4.284702032375872

Epoch: 6| Step: 13
Training loss: 4.265096890242272
Validation loss: 4.277969087035737

Epoch: 24| Step: 0
Training loss: 4.734764964343861
Validation loss: 4.274488190916078

Epoch: 6| Step: 1
Training loss: 4.662694171206611
Validation loss: 4.268485464423358

Epoch: 6| Step: 2
Training loss: 4.422254350653082
Validation loss: 4.263773571088299

Epoch: 6| Step: 3
Training loss: 3.9111373234602573
Validation loss: 4.259421097787489

Epoch: 6| Step: 4
Training loss: 4.020852334302106
Validation loss: 4.253904363084742

Epoch: 6| Step: 5
Training loss: 5.116364810418723
Validation loss: 4.24866962179882

Epoch: 6| Step: 6
Training loss: 4.865140677414699
Validation loss: 4.243710332955701

Epoch: 6| Step: 7
Training loss: 4.36585260233468
Validation loss: 4.238969831886819

Epoch: 6| Step: 8
Training loss: 4.417687040297302
Validation loss: 4.235472889889963

Epoch: 6| Step: 9
Training loss: 2.8996267012692973
Validation loss: 4.230243539495378

Epoch: 6| Step: 10
Training loss: 3.921278828450186
Validation loss: 4.225709501205001

Epoch: 6| Step: 11
Training loss: 3.620624795811952
Validation loss: 4.219885948682897

Epoch: 6| Step: 12
Training loss: 4.867141649939539
Validation loss: 4.214817125992333

Epoch: 6| Step: 13
Training loss: 4.868663092683513
Validation loss: 4.210844738374403

Epoch: 25| Step: 0
Training loss: 3.0532073120141576
Validation loss: 4.206186930621464

Epoch: 6| Step: 1
Training loss: 4.573456450678195
Validation loss: 4.2021509150282705

Epoch: 6| Step: 2
Training loss: 4.716623395489915
Validation loss: 4.197822677027087

Epoch: 6| Step: 3
Training loss: 4.535646397326091
Validation loss: 4.191621052599359

Epoch: 6| Step: 4
Training loss: 4.46998504431354
Validation loss: 4.186871875321974

Epoch: 6| Step: 5
Training loss: 4.413758718114133
Validation loss: 4.1822174686423335

Epoch: 6| Step: 6
Training loss: 4.869496687116631
Validation loss: 4.177613634549706

Epoch: 6| Step: 7
Training loss: 3.148063997211936
Validation loss: 4.17212069546338

Epoch: 6| Step: 8
Training loss: 4.052496698602912
Validation loss: 4.167016332577399

Epoch: 6| Step: 9
Training loss: 4.259900174471223
Validation loss: 4.162210745780082

Epoch: 6| Step: 10
Training loss: 4.188536558390838
Validation loss: 4.1581565480440466

Epoch: 6| Step: 11
Training loss: 4.00499699319829
Validation loss: 4.153397329265006

Epoch: 6| Step: 12
Training loss: 4.920398696624109
Validation loss: 4.148683395808901

Epoch: 6| Step: 13
Training loss: 4.5882256955122624
Validation loss: 4.144213713125688

Epoch: 26| Step: 0
Training loss: 5.279893689674782
Validation loss: 4.139162873082771

Epoch: 6| Step: 1
Training loss: 3.483523825101713
Validation loss: 4.1339902107173305

Epoch: 6| Step: 2
Training loss: 3.2329421255711464
Validation loss: 4.1295436919247654

Epoch: 6| Step: 3
Training loss: 4.303344960294264
Validation loss: 4.124767740049447

Epoch: 6| Step: 4
Training loss: 4.4758598481873
Validation loss: 4.120087482363091

Epoch: 6| Step: 5
Training loss: 3.7010700946592534
Validation loss: 4.114709193884055

Epoch: 6| Step: 6
Training loss: 3.8223155256706898
Validation loss: 4.110498910433349

Epoch: 6| Step: 7
Training loss: 4.414943694882132
Validation loss: 4.105420548784894

Epoch: 6| Step: 8
Training loss: 4.61164805083291
Validation loss: 4.1008227259444405

Epoch: 6| Step: 9
Training loss: 4.3119285315427955
Validation loss: 4.096915906386198

Epoch: 6| Step: 10
Training loss: 4.931500230056059
Validation loss: 4.091234963375143

Epoch: 6| Step: 11
Training loss: 4.219954029212521
Validation loss: 4.08627531893123

Epoch: 6| Step: 12
Training loss: 4.12506681445948
Validation loss: 4.081792456351511

Epoch: 6| Step: 13
Training loss: 3.9830401409788023
Validation loss: 4.076924016871203

Epoch: 27| Step: 0
Training loss: 4.21531978602306
Validation loss: 4.072109379808838

Epoch: 6| Step: 1
Training loss: 4.472533644948934
Validation loss: 4.06753124807305

Epoch: 6| Step: 2
Training loss: 4.110614546150184
Validation loss: 4.062619799290307

Epoch: 6| Step: 3
Training loss: 3.8813694933988323
Validation loss: 4.057632190418012

Epoch: 6| Step: 4
Training loss: 4.315356207120791
Validation loss: 4.052778320074244

Epoch: 6| Step: 5
Training loss: 4.167155249878136
Validation loss: 4.047685480641163

Epoch: 6| Step: 6
Training loss: 3.7573656859411733
Validation loss: 4.042495439377829

Epoch: 6| Step: 7
Training loss: 4.658787592722644
Validation loss: 4.038016660404333

Epoch: 6| Step: 8
Training loss: 4.08767878990073
Validation loss: 4.033285371374377

Epoch: 6| Step: 9
Training loss: 3.7608983936820333
Validation loss: 4.0286950977800835

Epoch: 6| Step: 10
Training loss: 4.7315955737556425
Validation loss: 4.023406982306137

Epoch: 6| Step: 11
Training loss: 3.4554590130642264
Validation loss: 4.019172140823382

Epoch: 6| Step: 12
Training loss: 4.125613542646898
Validation loss: 4.01576053078964

Epoch: 6| Step: 13
Training loss: 4.495974329498423
Validation loss: 4.009201076954318

Epoch: 28| Step: 0
Training loss: 4.198232533172488
Validation loss: 4.0054872148679825

Epoch: 6| Step: 1
Training loss: 4.266053342447264
Validation loss: 4.000844786763392

Epoch: 6| Step: 2
Training loss: 4.384919175345927
Validation loss: 3.9962320860046674

Epoch: 6| Step: 3
Training loss: 4.078023507327828
Validation loss: 3.990910255475143

Epoch: 6| Step: 4
Training loss: 4.336187132101714
Validation loss: 3.9863400269872233

Epoch: 6| Step: 5
Training loss: 3.7244214319060895
Validation loss: 3.981386946673821

Epoch: 6| Step: 6
Training loss: 4.405200156818173
Validation loss: 3.9770395208909295

Epoch: 6| Step: 7
Training loss: 4.037431103381305
Validation loss: 3.9724426312122243

Epoch: 6| Step: 8
Training loss: 3.4579145951676056
Validation loss: 3.9674377274348496

Epoch: 6| Step: 9
Training loss: 4.124355381391341
Validation loss: 3.962279644764748

Epoch: 6| Step: 10
Training loss: 4.74896610452103
Validation loss: 3.957816997113379

Epoch: 6| Step: 11
Training loss: 3.845626249072912
Validation loss: 3.9529151106891294

Epoch: 6| Step: 12
Training loss: 4.162534164884191
Validation loss: 3.948333490086417

Epoch: 6| Step: 13
Training loss: 3.555543498840023
Validation loss: 3.943332570630277

Epoch: 29| Step: 0
Training loss: 4.520661287798933
Validation loss: 3.938242241872398

Epoch: 6| Step: 1
Training loss: 3.2769331373623056
Validation loss: 3.9337501633681144

Epoch: 6| Step: 2
Training loss: 3.520197493041356
Validation loss: 3.9297970705322642

Epoch: 6| Step: 3
Training loss: 4.259992185057157
Validation loss: 3.924518682040022

Epoch: 6| Step: 4
Training loss: 3.773401232558955
Validation loss: 3.9200714544024904

Epoch: 6| Step: 5
Training loss: 4.612167702053475
Validation loss: 3.915403399091645

Epoch: 6| Step: 6
Training loss: 4.515191608473606
Validation loss: 3.9110666714718008

Epoch: 6| Step: 7
Training loss: 4.734636054065098
Validation loss: 3.9065329487366967

Epoch: 6| Step: 8
Training loss: 3.673629017149071
Validation loss: 3.9019770534289724

Epoch: 6| Step: 9
Training loss: 2.875503993432727
Validation loss: 3.896459552937593

Epoch: 6| Step: 10
Training loss: 4.135444134958103
Validation loss: 3.8920673520780675

Epoch: 6| Step: 11
Training loss: 4.307726443333618
Validation loss: 3.887005389968201

Epoch: 6| Step: 12
Training loss: 4.047670970979069
Validation loss: 3.881742374724119

Epoch: 6| Step: 13
Training loss: 3.8765907714009655
Validation loss: 3.876735770204678

Epoch: 30| Step: 0
Training loss: 4.761058182621857
Validation loss: 3.872827987654295

Epoch: 6| Step: 1
Training loss: 3.8088482737468445
Validation loss: 3.8684486464888796

Epoch: 6| Step: 2
Training loss: 4.049685647326603
Validation loss: 3.8640184358047747

Epoch: 6| Step: 3
Training loss: 4.343892486211266
Validation loss: 3.858394977140311

Epoch: 6| Step: 4
Training loss: 4.137151679275729
Validation loss: 3.853418528485091

Epoch: 6| Step: 5
Training loss: 4.080234493547995
Validation loss: 3.8478744625688526

Epoch: 6| Step: 6
Training loss: 3.0315016809176027
Validation loss: 3.8429387174589476

Epoch: 6| Step: 7
Training loss: 4.029996455264366
Validation loss: 3.838963699777325

Epoch: 6| Step: 8
Training loss: 3.851724431655529
Validation loss: 3.833998138719139

Epoch: 6| Step: 9
Training loss: 4.0968567220016805
Validation loss: 3.8295590368125545

Epoch: 6| Step: 10
Training loss: 4.34826096598913
Validation loss: 3.824777522712433

Epoch: 6| Step: 11
Training loss: 3.7340460596497653
Validation loss: 3.8203808779015636

Epoch: 6| Step: 12
Training loss: 3.3891720801120204
Validation loss: 3.815268777501

Epoch: 6| Step: 13
Training loss: 3.7359980802837396
Validation loss: 3.8105606399514325

Epoch: 31| Step: 0
Training loss: 3.660331339195307
Validation loss: 3.8061380304112684

Epoch: 6| Step: 1
Training loss: 2.6807956906435715
Validation loss: 3.801901756375167

Epoch: 6| Step: 2
Training loss: 4.124652732334386
Validation loss: 3.7973469465735907

Epoch: 6| Step: 3
Training loss: 3.6184570193898775
Validation loss: 3.793106909454345

Epoch: 6| Step: 4
Training loss: 3.8219180487565576
Validation loss: 3.78876425496785

Epoch: 6| Step: 5
Training loss: 4.556984690181956
Validation loss: 3.784375792969742

Epoch: 6| Step: 6
Training loss: 4.7511962588913255
Validation loss: 3.779871560627651

Epoch: 6| Step: 7
Training loss: 3.9867798971173567
Validation loss: 3.7752612901411062

Epoch: 6| Step: 8
Training loss: 3.6581250460918144
Validation loss: 3.7703446480805507

Epoch: 6| Step: 9
Training loss: 3.651096461488487
Validation loss: 3.7662124070111243

Epoch: 6| Step: 10
Training loss: 4.090815067174066
Validation loss: 3.7622105695182637

Epoch: 6| Step: 11
Training loss: 4.4910931921195685
Validation loss: 3.7573135901307597

Epoch: 6| Step: 12
Training loss: 4.092983960412661
Validation loss: 3.752864675945602

Epoch: 6| Step: 13
Training loss: 3.0768075050143446
Validation loss: 3.7481108039305964

Epoch: 32| Step: 0
Training loss: 3.8891579186767733
Validation loss: 3.7435917034870934

Epoch: 6| Step: 1
Training loss: 3.220103747669002
Validation loss: 3.7389240516103737

Epoch: 6| Step: 2
Training loss: 3.8950563495756554
Validation loss: 3.734721764887264

Epoch: 6| Step: 3
Training loss: 4.2668629621014915
Validation loss: 3.730447808384992

Epoch: 6| Step: 4
Training loss: 4.408156395133353
Validation loss: 3.726081182611405

Epoch: 6| Step: 5
Training loss: 3.389903752133749
Validation loss: 3.721658888616661

Epoch: 6| Step: 6
Training loss: 4.059617883524198
Validation loss: 3.717516483491817

Epoch: 6| Step: 7
Training loss: 3.800250777954239
Validation loss: 3.713117549409119

Epoch: 6| Step: 8
Training loss: 4.426793897554503
Validation loss: 3.7085206202385965

Epoch: 6| Step: 9
Training loss: 3.7230421668817284
Validation loss: 3.7038330603014975

Epoch: 6| Step: 10
Training loss: 3.1986547026427035
Validation loss: 3.6989762986410337

Epoch: 6| Step: 11
Training loss: 3.1632250772596464
Validation loss: 3.6951773298192085

Epoch: 6| Step: 12
Training loss: 4.638887741687706
Validation loss: 3.6906848236153693

Epoch: 6| Step: 13
Training loss: 3.4233296407390563
Validation loss: 3.6860761749239694

Epoch: 33| Step: 0
Training loss: 4.469383995058837
Validation loss: 3.6817285232102313

Epoch: 6| Step: 1
Training loss: 3.890720350943147
Validation loss: 3.677254835817492

Epoch: 6| Step: 2
Training loss: 3.7016343605341295
Validation loss: 3.6729153721648973

Epoch: 6| Step: 3
Training loss: 3.8761400576108986
Validation loss: 3.6685156639596244

Epoch: 6| Step: 4
Training loss: 4.162529353591015
Validation loss: 3.663882556826583

Epoch: 6| Step: 5
Training loss: 3.856323518469575
Validation loss: 3.659402211188814

Epoch: 6| Step: 6
Training loss: 3.775711038079929
Validation loss: 3.654991868093118

Epoch: 6| Step: 7
Training loss: 3.457785382963881
Validation loss: 3.650231388021339

Epoch: 6| Step: 8
Training loss: 3.465811094442165
Validation loss: 3.645835651215316

Epoch: 6| Step: 9
Training loss: 3.905676715744681
Validation loss: 3.641393643117111

Epoch: 6| Step: 10
Training loss: 4.104333606300375
Validation loss: 3.6372752571373077

Epoch: 6| Step: 11
Training loss: 3.755880069130132
Validation loss: 3.633103750715682

Epoch: 6| Step: 12
Training loss: 3.330035597006666
Validation loss: 3.62890088450867

Epoch: 6| Step: 13
Training loss: 3.1237050234337578
Validation loss: 3.6248936034625547

Epoch: 34| Step: 0
Training loss: 3.545475755196822
Validation loss: 3.6208088641698883

Epoch: 6| Step: 1
Training loss: 4.083474812035376
Validation loss: 3.6163108867499854

Epoch: 6| Step: 2
Training loss: 3.5415693082704456
Validation loss: 3.612380148759543

Epoch: 6| Step: 3
Training loss: 4.418095027828935
Validation loss: 3.60802479600245

Epoch: 6| Step: 4
Training loss: 4.874703422719444
Validation loss: 3.603793056873439

Epoch: 6| Step: 5
Training loss: 3.5150449825355077
Validation loss: 3.5991613364851824

Epoch: 6| Step: 6
Training loss: 3.6647546435737297
Validation loss: 3.594712700644796

Epoch: 6| Step: 7
Training loss: 4.029662773467662
Validation loss: 3.5904443990353467

Epoch: 6| Step: 8
Training loss: 2.8910767898099206
Validation loss: 3.5861155923516126

Epoch: 6| Step: 9
Training loss: 3.6682859370976786
Validation loss: 3.58212645115419

Epoch: 6| Step: 10
Training loss: 3.3876312680869662
Validation loss: 3.5777709541459757

Epoch: 6| Step: 11
Training loss: 3.49782249289075
Validation loss: 3.573653668758368

Epoch: 6| Step: 12
Training loss: 3.280167028547244
Validation loss: 3.5698096702410367

Epoch: 6| Step: 13
Training loss: 3.4232102667340545
Validation loss: 3.5656373781863637

Epoch: 35| Step: 0
Training loss: 4.001584692807455
Validation loss: 3.5617740850772455

Epoch: 6| Step: 1
Training loss: 3.560247679677555
Validation loss: 3.557660033039304

Epoch: 6| Step: 2
Training loss: 3.5430780328721925
Validation loss: 3.553788671633102

Epoch: 6| Step: 3
Training loss: 3.989014919548603
Validation loss: 3.5495766812664566

Epoch: 6| Step: 4
Training loss: 4.091920866259809
Validation loss: 3.545518265535424

Epoch: 6| Step: 5
Training loss: 3.1526033089006007
Validation loss: 3.541508450433542

Epoch: 6| Step: 6
Training loss: 3.4743906159177813
Validation loss: 3.5375032224966225

Epoch: 6| Step: 7
Training loss: 3.8996961621991404
Validation loss: 3.5337699855747107

Epoch: 6| Step: 8
Training loss: 3.496400344447464
Validation loss: 3.5295664732348015

Epoch: 6| Step: 9
Training loss: 3.0237182171441592
Validation loss: 3.5257575833009307

Epoch: 6| Step: 10
Training loss: 3.5407953125410256
Validation loss: 3.5218251353143724

Epoch: 6| Step: 11
Training loss: 4.064111243354967
Validation loss: 3.517984821786355

Epoch: 6| Step: 12
Training loss: 3.788566887287097
Validation loss: 3.5137423751569195

Epoch: 6| Step: 13
Training loss: 3.6237548794405963
Validation loss: 3.5095177394681105

Epoch: 36| Step: 0
Training loss: 3.5769368826928654
Validation loss: 3.5055725377016245

Epoch: 6| Step: 1
Training loss: 3.794322721937723
Validation loss: 3.5016303579441312

Epoch: 6| Step: 2
Training loss: 3.3679967204370183
Validation loss: 3.4978446000297723

Epoch: 6| Step: 3
Training loss: 3.2160482085491062
Validation loss: 3.4938622426500507

Epoch: 6| Step: 4
Training loss: 3.8646572273915174
Validation loss: 3.4902392591752864

Epoch: 6| Step: 5
Training loss: 3.828520462473668
Validation loss: 3.486261333320864

Epoch: 6| Step: 6
Training loss: 3.8750332246402004
Validation loss: 3.4826640674056577

Epoch: 6| Step: 7
Training loss: 3.593842878385404
Validation loss: 3.4783180404885004

Epoch: 6| Step: 8
Training loss: 3.8377628994331614
Validation loss: 3.4743505863641033

Epoch: 6| Step: 9
Training loss: 3.5720525795888918
Validation loss: 3.4698500392511717

Epoch: 6| Step: 10
Training loss: 3.357200593075063
Validation loss: 3.4658455129857155

Epoch: 6| Step: 11
Training loss: 3.00502245420169
Validation loss: 3.462014678655102

Epoch: 6| Step: 12
Training loss: 4.019231816622668
Validation loss: 3.4580782064680897

Epoch: 6| Step: 13
Training loss: 3.6065869152491103
Validation loss: 3.4543267024707056

Epoch: 37| Step: 0
Training loss: 3.94066976692733
Validation loss: 3.4502524140757247

Epoch: 6| Step: 1
Training loss: 3.4066822582666942
Validation loss: 3.4459390337291316

Epoch: 6| Step: 2
Training loss: 3.721640737545459
Validation loss: 3.4421809144028512

Epoch: 6| Step: 3
Training loss: 4.064489024423991
Validation loss: 3.4385332808709625

Epoch: 6| Step: 4
Training loss: 3.679821230651128
Validation loss: 3.434811922465091

Epoch: 6| Step: 5
Training loss: 3.1051375302433986
Validation loss: 3.4299997985513553

Epoch: 6| Step: 6
Training loss: 2.827991292753938
Validation loss: 3.42630152881967

Epoch: 6| Step: 7
Training loss: 3.9796199174286513
Validation loss: 3.422836818835638

Epoch: 6| Step: 8
Training loss: 2.6945233502801713
Validation loss: 3.418731174266061

Epoch: 6| Step: 9
Training loss: 3.5811265907527736
Validation loss: 3.4151336595732595

Epoch: 6| Step: 10
Training loss: 3.926581852444351
Validation loss: 3.411209928287231

Epoch: 6| Step: 11
Training loss: 3.8307229704799197
Validation loss: 3.407105493002677

Epoch: 6| Step: 12
Training loss: 3.7506322963435763
Validation loss: 3.40312356986771

Epoch: 6| Step: 13
Training loss: 3.0462082353373527
Validation loss: 3.399645056616375

Epoch: 38| Step: 0
Training loss: 3.0697629791117107
Validation loss: 3.395974950041266

Epoch: 6| Step: 1
Training loss: 3.694276047376697
Validation loss: 3.3922721740941038

Epoch: 6| Step: 2
Training loss: 2.603340160183456
Validation loss: 3.389211779118234

Epoch: 6| Step: 3
Training loss: 3.3410667990863385
Validation loss: 3.385914168360346

Epoch: 6| Step: 4
Training loss: 3.256641058403024
Validation loss: 3.382383793660078

Epoch: 6| Step: 5
Training loss: 3.482441044710278
Validation loss: 3.3791949374846446

Epoch: 6| Step: 6
Training loss: 4.131670096271462
Validation loss: 3.375433187588325

Epoch: 6| Step: 7
Training loss: 3.5031409475080943
Validation loss: 3.3720982168637406

Epoch: 6| Step: 8
Training loss: 4.035173739222747
Validation loss: 3.3686341425613215

Epoch: 6| Step: 9
Training loss: 3.2499279601109077
Validation loss: 3.3644323561171414

Epoch: 6| Step: 10
Training loss: 3.395412177120631
Validation loss: 3.361045623085264

Epoch: 6| Step: 11
Training loss: 3.5072564786741998
Validation loss: 3.357283895075024

Epoch: 6| Step: 12
Training loss: 3.8803733978322246
Validation loss: 3.353767150084344

Epoch: 6| Step: 13
Training loss: 3.713317621792531
Validation loss: 3.3505124549438774

Epoch: 39| Step: 0
Training loss: 3.7170906532117742
Validation loss: 3.346505619090141

Epoch: 6| Step: 1
Training loss: 2.812685642473482
Validation loss: 3.342700639103472

Epoch: 6| Step: 2
Training loss: 3.524638239917685
Validation loss: 3.338759456360723

Epoch: 6| Step: 3
Training loss: 4.113303507774537
Validation loss: 3.3350942410980244

Epoch: 6| Step: 4
Training loss: 3.603796144230403
Validation loss: 3.331491394553229

Epoch: 6| Step: 5
Training loss: 3.029252328059388
Validation loss: 3.3278449094394627

Epoch: 6| Step: 6
Training loss: 3.1173308298912907
Validation loss: 3.3237969399463965

Epoch: 6| Step: 7
Training loss: 3.515525579106355
Validation loss: 3.3203321029981985

Epoch: 6| Step: 8
Training loss: 3.874640171202847
Validation loss: 3.3165787830562308

Epoch: 6| Step: 9
Training loss: 3.029464825242302
Validation loss: 3.313382541001984

Epoch: 6| Step: 10
Training loss: 3.733021510816637
Validation loss: 3.3097491808360897

Epoch: 6| Step: 11
Training loss: 3.788899903888918
Validation loss: 3.3061343273174684

Epoch: 6| Step: 12
Training loss: 3.380908738717467
Validation loss: 3.3027567773409237

Epoch: 6| Step: 13
Training loss: 2.9490242394983675
Validation loss: 3.2991013806165737

Epoch: 40| Step: 0
Training loss: 4.009021598957556
Validation loss: 3.2956085183059263

Epoch: 6| Step: 1
Training loss: 3.5444971928380222
Validation loss: 3.291963604116738

Epoch: 6| Step: 2
Training loss: 3.1814014211415396
Validation loss: 3.2886833159605695

Epoch: 6| Step: 3
Training loss: 3.1445248811076807
Validation loss: 3.285034782229398

Epoch: 6| Step: 4
Training loss: 3.3701341662314985
Validation loss: 3.281438210554248

Epoch: 6| Step: 5
Training loss: 2.9597875933859554
Validation loss: 3.2786507014369

Epoch: 6| Step: 6
Training loss: 2.9902630785281406
Validation loss: 3.2749344855591525

Epoch: 6| Step: 7
Training loss: 3.0702345355280944
Validation loss: 3.2720153802768266

Epoch: 6| Step: 8
Training loss: 3.2620361173724732
Validation loss: 3.2689578435791016

Epoch: 6| Step: 9
Training loss: 4.003759286555901
Validation loss: 3.266063995301224

Epoch: 6| Step: 10
Training loss: 3.0522304321531677
Validation loss: 3.2626352206643805

Epoch: 6| Step: 11
Training loss: 3.2490715754812323
Validation loss: 3.2595688486409298

Epoch: 6| Step: 12
Training loss: 3.6933907477762595
Validation loss: 3.2561157711427953

Epoch: 6| Step: 13
Training loss: 3.9749500775351234
Validation loss: 3.2531076880930954

Epoch: 41| Step: 0
Training loss: 4.398603148246238
Validation loss: 3.2492988147916146

Epoch: 6| Step: 1
Training loss: 2.995190898434757
Validation loss: 3.2459933697312935

Epoch: 6| Step: 2
Training loss: 3.3271629124923607
Validation loss: 3.242015984223027

Epoch: 6| Step: 3
Training loss: 3.1633483834372584
Validation loss: 3.238629404087894

Epoch: 6| Step: 4
Training loss: 2.939192264172503
Validation loss: 3.2353446600360893

Epoch: 6| Step: 5
Training loss: 3.034162871845502
Validation loss: 3.2319115857323397

Epoch: 6| Step: 6
Training loss: 3.4658062790290693
Validation loss: 3.2290581387566344

Epoch: 6| Step: 7
Training loss: 3.0980583016590435
Validation loss: 3.2258334563904127

Epoch: 6| Step: 8
Training loss: 3.2473192162590294
Validation loss: 3.22261740921196

Epoch: 6| Step: 9
Training loss: 3.6662167070751974
Validation loss: 3.2195057151551363

Epoch: 6| Step: 10
Training loss: 3.488403044792485
Validation loss: 3.2162700840144653

Epoch: 6| Step: 11
Training loss: 2.694332309456374
Validation loss: 3.2127615024395473

Epoch: 6| Step: 12
Training loss: 3.157610911447264
Validation loss: 3.2100524672659954

Epoch: 6| Step: 13
Training loss: 4.072340564358431
Validation loss: 3.206424607745684

Epoch: 42| Step: 0
Training loss: 3.6077873404225724
Validation loss: 3.203248531781744

Epoch: 6| Step: 1
Training loss: 3.5132455869378365
Validation loss: 3.2000018641347223

Epoch: 6| Step: 2
Training loss: 3.843484512712766
Validation loss: 3.1970975905879837

Epoch: 6| Step: 3
Training loss: 2.8788229362202724
Validation loss: 3.193126723654329

Epoch: 6| Step: 4
Training loss: 2.8665932187570196
Validation loss: 3.1900352916937753

Epoch: 6| Step: 5
Training loss: 3.512936254811791
Validation loss: 3.186752443602298

Epoch: 6| Step: 6
Training loss: 2.7965622199571305
Validation loss: 3.183145415832773

Epoch: 6| Step: 7
Training loss: 3.1714265252625924
Validation loss: 3.1801685716026125

Epoch: 6| Step: 8
Training loss: 3.0302221384233397
Validation loss: 3.1772501833936144

Epoch: 6| Step: 9
Training loss: 2.987204922584274
Validation loss: 3.1740625664614375

Epoch: 6| Step: 10
Training loss: 3.6112900974877236
Validation loss: 3.170853060252866

Epoch: 6| Step: 11
Training loss: 3.728049183639777
Validation loss: 3.1678593213317625

Epoch: 6| Step: 12
Training loss: 3.6363408499784065
Validation loss: 3.164477022121049

Epoch: 6| Step: 13
Training loss: 3.1009082632657714
Validation loss: 3.1617907999216968

Epoch: 43| Step: 0
Training loss: 3.157095314363285
Validation loss: 3.1586828643986826

Epoch: 6| Step: 1
Training loss: 3.2437643238258524
Validation loss: 3.1558941177814734

Epoch: 6| Step: 2
Training loss: 2.9133334232158634
Validation loss: 3.1528557885854114

Epoch: 6| Step: 3
Training loss: 3.661163549734269
Validation loss: 3.150692885250896

Epoch: 6| Step: 4
Training loss: 3.7403254007363524
Validation loss: 3.1475788267575227

Epoch: 6| Step: 5
Training loss: 3.4107109046982047
Validation loss: 3.1444973076988645

Epoch: 6| Step: 6
Training loss: 3.1139766821015797
Validation loss: 3.141569890590014

Epoch: 6| Step: 7
Training loss: 3.6624675606081927
Validation loss: 3.1384418548064543

Epoch: 6| Step: 8
Training loss: 3.1791039383592214
Validation loss: 3.13547179130348

Epoch: 6| Step: 9
Training loss: 3.357283824059707
Validation loss: 3.1324332270059974

Epoch: 6| Step: 10
Training loss: 3.6307030901175144
Validation loss: 3.129666061950077

Epoch: 6| Step: 11
Training loss: 3.1621834155456963
Validation loss: 3.12645822198935

Epoch: 6| Step: 12
Training loss: 2.9272642973396668
Validation loss: 3.1233154842988986

Epoch: 6| Step: 13
Training loss: 2.554988924961759
Validation loss: 3.1199607782058623

Epoch: 44| Step: 0
Training loss: 3.768078776190092
Validation loss: 3.1171442090998465

Epoch: 6| Step: 1
Training loss: 3.553775343346707
Validation loss: 3.114056077980199

Epoch: 6| Step: 2
Training loss: 2.8668340730209496
Validation loss: 3.111186166172067

Epoch: 6| Step: 3
Training loss: 2.9694172962526952
Validation loss: 3.108635832118317

Epoch: 6| Step: 4
Training loss: 3.753344506698248
Validation loss: 3.106243147353168

Epoch: 6| Step: 5
Training loss: 3.464274225229979
Validation loss: 3.102437111429523

Epoch: 6| Step: 6
Training loss: 3.36623855991169
Validation loss: 3.0993886098622494

Epoch: 6| Step: 7
Training loss: 3.331226318733252
Validation loss: 3.0962600415646664

Epoch: 6| Step: 8
Training loss: 3.1351604842825878
Validation loss: 3.093112456010506

Epoch: 6| Step: 9
Training loss: 3.1000639324363735
Validation loss: 3.0907171520435774

Epoch: 6| Step: 10
Training loss: 2.7520330023560997
Validation loss: 3.0878196417000754

Epoch: 6| Step: 11
Training loss: 3.4789069682218408
Validation loss: 3.0852629620484535

Epoch: 6| Step: 12
Training loss: 2.8219270179660145
Validation loss: 3.08274836189124

Epoch: 6| Step: 13
Training loss: 2.789961042371459
Validation loss: 3.080152357098303

Epoch: 45| Step: 0
Training loss: 3.371470124240317
Validation loss: 3.0777141212906978

Epoch: 6| Step: 1
Training loss: 2.874179225358506
Validation loss: 3.074959807404632

Epoch: 6| Step: 2
Training loss: 3.3448715468120525
Validation loss: 3.072793865444135

Epoch: 6| Step: 3
Training loss: 3.1672774947130264
Validation loss: 3.070181082646242

Epoch: 6| Step: 4
Training loss: 3.8001658303065655
Validation loss: 3.0676195210595654

Epoch: 6| Step: 5
Training loss: 3.652236169872828
Validation loss: 3.0647282441448853

Epoch: 6| Step: 6
Training loss: 3.3110339681299483
Validation loss: 3.0619649484564593

Epoch: 6| Step: 7
Training loss: 3.417178480069257
Validation loss: 3.05903247530275

Epoch: 6| Step: 8
Training loss: 2.433649102281068
Validation loss: 3.0562568789289637

Epoch: 6| Step: 9
Training loss: 2.961318663368261
Validation loss: 3.0534053755747044

Epoch: 6| Step: 10
Training loss: 3.40899183880743
Validation loss: 3.0506720594597994

Epoch: 6| Step: 11
Training loss: 2.7003946792923057
Validation loss: 3.04850617133762

Epoch: 6| Step: 12
Training loss: 3.0112495898052107
Validation loss: 3.045650490431614

Epoch: 6| Step: 13
Training loss: 3.114020629540076
Validation loss: 3.0436199962051513

Epoch: 46| Step: 0
Training loss: 3.267554192418333
Validation loss: 3.041019322910237

Epoch: 6| Step: 1
Training loss: 2.8555492384560752
Validation loss: 3.03871647058754

Epoch: 6| Step: 2
Training loss: 3.5689705428139407
Validation loss: 3.0360723460628116

Epoch: 6| Step: 3
Training loss: 3.3266248590547236
Validation loss: 3.034203850017949

Epoch: 6| Step: 4
Training loss: 3.1755310936031518
Validation loss: 3.0312091260953036

Epoch: 6| Step: 5
Training loss: 3.481708138965902
Validation loss: 3.028812437758691

Epoch: 6| Step: 6
Training loss: 3.639486896275911
Validation loss: 3.0260643140215655

Epoch: 6| Step: 7
Training loss: 3.055841174407323
Validation loss: 3.0234190868832274

Epoch: 6| Step: 8
Training loss: 2.4857493503803356
Validation loss: 3.020618185515412

Epoch: 6| Step: 9
Training loss: 3.114491302933724
Validation loss: 3.017953701575913

Epoch: 6| Step: 10
Training loss: 2.6697531858229273
Validation loss: 3.0155423009729976

Epoch: 6| Step: 11
Training loss: 3.2411117791400486
Validation loss: 3.0131890929423366

Epoch: 6| Step: 12
Training loss: 3.1508389158148162
Validation loss: 3.0103333449575085

Epoch: 6| Step: 13
Training loss: 3.1123207745407115
Validation loss: 3.0075749158949066

Epoch: 47| Step: 0
Training loss: 3.2353556892329554
Validation loss: 3.0055993463197885

Epoch: 6| Step: 1
Training loss: 2.7387458091574937
Validation loss: 3.003439520999021

Epoch: 6| Step: 2
Training loss: 3.1186946581133
Validation loss: 3.001120914223679

Epoch: 6| Step: 3
Training loss: 3.147871624472662
Validation loss: 2.999186577723335

Epoch: 6| Step: 4
Training loss: 2.6640488968219413
Validation loss: 2.9969438244630653

Epoch: 6| Step: 5
Training loss: 3.298983943459577
Validation loss: 2.9957964110099833

Epoch: 6| Step: 6
Training loss: 2.997746893074284
Validation loss: 2.99219125825465

Epoch: 6| Step: 7
Training loss: 3.147364431162815
Validation loss: 2.9900191960733915

Epoch: 6| Step: 8
Training loss: 3.369750992039627
Validation loss: 2.9872626004138607

Epoch: 6| Step: 9
Training loss: 3.4105568352294857
Validation loss: 2.985316835284026

Epoch: 6| Step: 10
Training loss: 3.6322945174233476
Validation loss: 2.982342145845454

Epoch: 6| Step: 11
Training loss: 3.3949662644250935
Validation loss: 2.9805172124266575

Epoch: 6| Step: 12
Training loss: 2.556754859371385
Validation loss: 2.978355114890446

Epoch: 6| Step: 13
Training loss: 2.9563269639430643
Validation loss: 2.976362086480142

Epoch: 48| Step: 0
Training loss: 3.288994940202068
Validation loss: 2.9740854070252314

Epoch: 6| Step: 1
Training loss: 3.4016055018975306
Validation loss: 2.9723716462584284

Epoch: 6| Step: 2
Training loss: 2.8389726690714836
Validation loss: 2.9700819674868053

Epoch: 6| Step: 3
Training loss: 3.6146273358366474
Validation loss: 2.9675214132614585

Epoch: 6| Step: 4
Training loss: 2.42127431988257
Validation loss: 2.9650653928822193

Epoch: 6| Step: 5
Training loss: 2.798281353332732
Validation loss: 2.9629637563117166

Epoch: 6| Step: 6
Training loss: 3.3977877993366934
Validation loss: 2.9603579045333257

Epoch: 6| Step: 7
Training loss: 3.1783033352819636
Validation loss: 2.9579836858162376

Epoch: 6| Step: 8
Training loss: 3.808852530270905
Validation loss: 2.9559286221105627

Epoch: 6| Step: 9
Training loss: 2.9180029033413746
Validation loss: 2.9535382501396255

Epoch: 6| Step: 10
Training loss: 2.7870007328707276
Validation loss: 2.950502566724069

Epoch: 6| Step: 11
Training loss: 2.717063029653636
Validation loss: 2.9485054012337737

Epoch: 6| Step: 12
Training loss: 2.7226084372483097
Validation loss: 2.946049686528244

Epoch: 6| Step: 13
Training loss: 3.209186457042416
Validation loss: 2.943690682344726

Epoch: 49| Step: 0
Training loss: 3.4279908869476436
Validation loss: 2.9417424510094845

Epoch: 6| Step: 1
Training loss: 3.1202927804170013
Validation loss: 2.939242894289457

Epoch: 6| Step: 2
Training loss: 3.6567896257265455
Validation loss: 2.937314534927015

Epoch: 6| Step: 3
Training loss: 2.8116859953494258
Validation loss: 2.934833858798068

Epoch: 6| Step: 4
Training loss: 2.8275342292636303
Validation loss: 2.9331996634400213

Epoch: 6| Step: 5
Training loss: 3.0386912454992254
Validation loss: 2.931116716815594

Epoch: 6| Step: 6
Training loss: 3.5683763458733684
Validation loss: 2.92942583738175

Epoch: 6| Step: 7
Training loss: 3.005335354999222
Validation loss: 2.9273898189365117

Epoch: 6| Step: 8
Training loss: 2.939685089995989
Validation loss: 2.925361823936316

Epoch: 6| Step: 9
Training loss: 2.9579613859223906
Validation loss: 2.922680096196323

Epoch: 6| Step: 10
Training loss: 2.879495174880174
Validation loss: 2.921171134174699

Epoch: 6| Step: 11
Training loss: 2.279200848515447
Validation loss: 2.9189145871575923

Epoch: 6| Step: 12
Training loss: 3.0917530743501986
Validation loss: 2.9168682074169725

Epoch: 6| Step: 13
Training loss: 3.151745745391165
Validation loss: 2.914930976128991

Epoch: 50| Step: 0
Training loss: 3.5977235802263627
Validation loss: 2.9132108560331487

Epoch: 6| Step: 1
Training loss: 3.472084710683076
Validation loss: 2.9110269289447435

Epoch: 6| Step: 2
Training loss: 3.479048416656056
Validation loss: 2.9087020620240858

Epoch: 6| Step: 3
Training loss: 3.274458769127028
Validation loss: 2.9068587564580333

Epoch: 6| Step: 4
Training loss: 2.650798274310753
Validation loss: 2.9041077570000713

Epoch: 6| Step: 5
Training loss: 2.999127420046912
Validation loss: 2.9025849370058765

Epoch: 6| Step: 6
Training loss: 2.8033283308742796
Validation loss: 2.9004065858891996

Epoch: 6| Step: 7
Training loss: 2.820900388190188
Validation loss: 2.898260558452079

Epoch: 6| Step: 8
Training loss: 3.1841261716888494
Validation loss: 2.896128980149444

Epoch: 6| Step: 9
Training loss: 3.026771619324272
Validation loss: 2.893156987527987

Epoch: 6| Step: 10
Training loss: 2.6201794276058883
Validation loss: 2.890759425431319

Epoch: 6| Step: 11
Training loss: 2.83104020240344
Validation loss: 2.889498262498497

Epoch: 6| Step: 12
Training loss: 3.14331880498005
Validation loss: 2.887065971528944

Epoch: 6| Step: 13
Training loss: 2.439657576875744
Validation loss: 2.8850690905464575

Epoch: 51| Step: 0
Training loss: 3.1543869714300024
Validation loss: 2.8828200397892525

Epoch: 6| Step: 1
Training loss: 3.0295630411255363
Validation loss: 2.882470542247684

Epoch: 6| Step: 2
Training loss: 3.0559371382454374
Validation loss: 2.8809410575019645

Epoch: 6| Step: 3
Training loss: 3.049096183062997
Validation loss: 2.878786730690017

Epoch: 6| Step: 4
Training loss: 3.4670824046149558
Validation loss: 2.877170144515569

Epoch: 6| Step: 5
Training loss: 3.081713139080604
Validation loss: 2.875166224774425

Epoch: 6| Step: 6
Training loss: 3.1185348772915447
Validation loss: 2.8739069920362623

Epoch: 6| Step: 7
Training loss: 2.991755760658464
Validation loss: 2.8724134945549844

Epoch: 6| Step: 8
Training loss: 2.886456096918586
Validation loss: 2.870805610851389

Epoch: 6| Step: 9
Training loss: 2.634778836431388
Validation loss: 2.8690381777317264

Epoch: 6| Step: 10
Training loss: 2.732508954507268
Validation loss: 2.8676753239799355

Epoch: 6| Step: 11
Training loss: 2.899157493805599
Validation loss: 2.8654357243064505

Epoch: 6| Step: 12
Training loss: 2.831090731488384
Validation loss: 2.8634838329223147

Epoch: 6| Step: 13
Training loss: 3.1930834169754587
Validation loss: 2.8622029118408094

Epoch: 52| Step: 0
Training loss: 3.055085529434992
Validation loss: 2.85945279375156

Epoch: 6| Step: 1
Training loss: 2.8853771514573867
Validation loss: 2.8579715001122556

Epoch: 6| Step: 2
Training loss: 3.004572562540192
Validation loss: 2.856155890341074

Epoch: 6| Step: 3
Training loss: 3.0734235614873624
Validation loss: 2.854120732144316

Epoch: 6| Step: 4
Training loss: 3.218668964439948
Validation loss: 2.8516997979262966

Epoch: 6| Step: 5
Training loss: 2.6275937118297077
Validation loss: 2.8495901454444925

Epoch: 6| Step: 6
Training loss: 3.0022688868984204
Validation loss: 2.8475249530122015

Epoch: 6| Step: 7
Training loss: 3.1784347578274477
Validation loss: 2.846182010303764

Epoch: 6| Step: 8
Training loss: 2.8987936536258094
Validation loss: 2.8446854809825086

Epoch: 6| Step: 9
Training loss: 2.731049526373136
Validation loss: 2.8434616892897746

Epoch: 6| Step: 10
Training loss: 3.107668307619181
Validation loss: 2.8424955262993574

Epoch: 6| Step: 11
Training loss: 3.020226481199994
Validation loss: 2.8399130398685273

Epoch: 6| Step: 12
Training loss: 2.497332866830913
Validation loss: 2.838397763772189

Epoch: 6| Step: 13
Training loss: 3.430914796114267
Validation loss: 2.836260760530537

Epoch: 53| Step: 0
Training loss: 2.882861790843005
Validation loss: 2.8344113225267322

Epoch: 6| Step: 1
Training loss: 2.407930258137008
Validation loss: 2.8324525997621017

Epoch: 6| Step: 2
Training loss: 2.960283594722242
Validation loss: 2.8305725409942646

Epoch: 6| Step: 3
Training loss: 2.8060398082560374
Validation loss: 2.8294401535713036

Epoch: 6| Step: 4
Training loss: 2.811585934770163
Validation loss: 2.8265623268027573

Epoch: 6| Step: 5
Training loss: 2.7149630074413356
Validation loss: 2.825305383205856

Epoch: 6| Step: 6
Training loss: 3.1928298371154096
Validation loss: 2.8232926028067356

Epoch: 6| Step: 7
Training loss: 3.3355506833514093
Validation loss: 2.8212297661556724

Epoch: 6| Step: 8
Training loss: 3.149687639522767
Validation loss: 2.819835731736057

Epoch: 6| Step: 9
Training loss: 3.137334057800408
Validation loss: 2.816271944057884

Epoch: 6| Step: 10
Training loss: 2.8527737487975826
Validation loss: 2.8161950598769017

Epoch: 6| Step: 11
Training loss: 3.0671513326478173
Validation loss: 2.814334341838866

Epoch: 6| Step: 12
Training loss: 2.553025758044802
Validation loss: 2.812581308390493

Epoch: 6| Step: 13
Training loss: 3.459772262575489
Validation loss: 2.8112210368056303

Epoch: 54| Step: 0
Training loss: 2.884527921084254
Validation loss: 2.810161791292153

Epoch: 6| Step: 1
Training loss: 3.058603104032631
Validation loss: 2.808501827909248

Epoch: 6| Step: 2
Training loss: 2.3348445312890806
Validation loss: 2.8064629364221343

Epoch: 6| Step: 3
Training loss: 2.809615966510808
Validation loss: 2.8051667295464275

Epoch: 6| Step: 4
Training loss: 2.9365096350378153
Validation loss: 2.8029318213834045

Epoch: 6| Step: 5
Training loss: 2.9680467274527156
Validation loss: 2.801145663777357

Epoch: 6| Step: 6
Training loss: 3.1791622843447604
Validation loss: 2.7999373281367803

Epoch: 6| Step: 7
Training loss: 2.8288118150188146
Validation loss: 2.7985746309244504

Epoch: 6| Step: 8
Training loss: 2.891732823240816
Validation loss: 2.796361027097727

Epoch: 6| Step: 9
Training loss: 3.013240523751712
Validation loss: 2.7972388572497073

Epoch: 6| Step: 10
Training loss: 3.3847046245134353
Validation loss: 2.7932127803729894

Epoch: 6| Step: 11
Training loss: 3.4349935930794793
Validation loss: 2.7931363569000163

Epoch: 6| Step: 12
Training loss: 2.6762131836598018
Validation loss: 2.7927469232139477

Epoch: 6| Step: 13
Training loss: 2.6196180302517704
Validation loss: 2.791843342290947

Epoch: 55| Step: 0
Training loss: 2.7054935728471587
Validation loss: 2.7911041082011216

Epoch: 6| Step: 1
Training loss: 2.77486578470715
Validation loss: 2.789405723275507

Epoch: 6| Step: 2
Training loss: 2.9676730159980247
Validation loss: 2.7888129342599757

Epoch: 6| Step: 3
Training loss: 3.1242992378354324
Validation loss: 2.7860978270628465

Epoch: 6| Step: 4
Training loss: 3.078546175728295
Validation loss: 2.7847726209037775

Epoch: 6| Step: 5
Training loss: 2.3807487180434594
Validation loss: 2.7814697007403253

Epoch: 6| Step: 6
Training loss: 3.1232740595135224
Validation loss: 2.780784668016949

Epoch: 6| Step: 7
Training loss: 2.6098873526281174
Validation loss: 2.7792468197162616

Epoch: 6| Step: 8
Training loss: 2.8301795535870142
Validation loss: 2.7759221369123437

Epoch: 6| Step: 9
Training loss: 3.445418790877424
Validation loss: 2.7743180574006256

Epoch: 6| Step: 10
Training loss: 3.1122585708557757
Validation loss: 2.779037724429572

Epoch: 6| Step: 11
Training loss: 2.8641980461182666
Validation loss: 2.772391151444813

Epoch: 6| Step: 12
Training loss: 2.6262527383012038
Validation loss: 2.7741090346591593

Epoch: 6| Step: 13
Training loss: 3.1305203316696524
Validation loss: 2.773392998423415

Epoch: 56| Step: 0
Training loss: 3.2256718253684125
Validation loss: 2.767036264696373

Epoch: 6| Step: 1
Training loss: 2.9002850754153044
Validation loss: 2.7664552724653606

Epoch: 6| Step: 2
Training loss: 3.121194429647659
Validation loss: 2.7666903812663657

Epoch: 6| Step: 3
Training loss: 3.113896748236717
Validation loss: 2.7686196904341713

Epoch: 6| Step: 4
Training loss: 2.5343774383947117
Validation loss: 2.7656735489601676

Epoch: 6| Step: 5
Training loss: 3.7136318343862773
Validation loss: 2.7650554810534325

Epoch: 6| Step: 6
Training loss: 3.152579864772972
Validation loss: 2.7631414293055148

Epoch: 6| Step: 7
Training loss: 3.1438806464955347
Validation loss: 2.7608922488712815

Epoch: 6| Step: 8
Training loss: 2.550559812692849
Validation loss: 2.7595748673457527

Epoch: 6| Step: 9
Training loss: 2.5177120294466193
Validation loss: 2.7564824024351195

Epoch: 6| Step: 10
Training loss: 2.5388402284020914
Validation loss: 2.7548721242952223

Epoch: 6| Step: 11
Training loss: 2.1105855223375407
Validation loss: 2.7519720838086372

Epoch: 6| Step: 12
Training loss: 2.771771857612357
Validation loss: 2.7497980303724066

Epoch: 6| Step: 13
Training loss: 2.86266400396291
Validation loss: 2.750614169925148

Epoch: 57| Step: 0
Training loss: 2.39199450790132
Validation loss: 2.7509350920812574

Epoch: 6| Step: 1
Training loss: 3.0056859809779795
Validation loss: 2.7482897613414994

Epoch: 6| Step: 2
Training loss: 2.845317031546707
Validation loss: 2.746254016871547

Epoch: 6| Step: 3
Training loss: 2.5201910057038757
Validation loss: 2.742556308966911

Epoch: 6| Step: 4
Training loss: 2.865044315121898
Validation loss: 2.742793364944692

Epoch: 6| Step: 5
Training loss: 3.172048028445216
Validation loss: 2.7412081977659315

Epoch: 6| Step: 6
Training loss: 2.9620373779143336
Validation loss: 2.740961523502014

Epoch: 6| Step: 7
Training loss: 2.4613587034136484
Validation loss: 2.739898262246677

Epoch: 6| Step: 8
Training loss: 3.0163544874435595
Validation loss: 2.7393517825440794

Epoch: 6| Step: 9
Training loss: 3.01893205113499
Validation loss: 2.738192815799236

Epoch: 6| Step: 10
Training loss: 2.551928415591955
Validation loss: 2.734928954187908

Epoch: 6| Step: 11
Training loss: 3.05054335210008
Validation loss: 2.7346667179536683

Epoch: 6| Step: 12
Training loss: 3.001977268933487
Validation loss: 2.733425098910181

Epoch: 6| Step: 13
Training loss: 3.3106191801654115
Validation loss: 2.7330555811540176

Epoch: 58| Step: 0
Training loss: 2.9362775815770172
Validation loss: 2.7309387704770844

Epoch: 6| Step: 1
Training loss: 2.505896290769587
Validation loss: 2.7301112619953307

Epoch: 6| Step: 2
Training loss: 2.9712030816456103
Validation loss: 2.727416319270016

Epoch: 6| Step: 3
Training loss: 2.9357492627130997
Validation loss: 2.7258672110087856

Epoch: 6| Step: 4
Training loss: 3.3032468717354266
Validation loss: 2.727411278302366

Epoch: 6| Step: 5
Training loss: 2.792785723898161
Validation loss: 2.721450414583044

Epoch: 6| Step: 6
Training loss: 2.9382850734175636
Validation loss: 2.721877626636054

Epoch: 6| Step: 7
Training loss: 2.653729128941935
Validation loss: 2.723150105431059

Epoch: 6| Step: 8
Training loss: 2.3759045133316548
Validation loss: 2.725589101150118

Epoch: 6| Step: 9
Training loss: 2.928673652699063
Validation loss: 2.727974760004968

Epoch: 6| Step: 10
Training loss: 2.5227554391574185
Validation loss: 2.730813167972125

Epoch: 6| Step: 11
Training loss: 3.0403924302235628
Validation loss: 2.732672577364466

Epoch: 6| Step: 12
Training loss: 2.789061474198866
Validation loss: 2.7275276843984466

Epoch: 6| Step: 13
Training loss: 3.270639466454725
Validation loss: 2.723157853815619

Epoch: 59| Step: 0
Training loss: 2.499281589282091
Validation loss: 2.720804775335467

Epoch: 6| Step: 1
Training loss: 2.8638161111541116
Validation loss: 2.7191956107395305

Epoch: 6| Step: 2
Training loss: 2.538194901349928
Validation loss: 2.7159936605650112

Epoch: 6| Step: 3
Training loss: 2.812196503264598
Validation loss: 2.7140939093225245

Epoch: 6| Step: 4
Training loss: 2.9572045944382506
Validation loss: 2.7107733421203744

Epoch: 6| Step: 5
Training loss: 2.965350644250925
Validation loss: 2.707117061897097

Epoch: 6| Step: 6
Training loss: 2.7829730236570445
Validation loss: 2.7056214449124747

Epoch: 6| Step: 7
Training loss: 3.192942890223991
Validation loss: 2.702332088183925

Epoch: 6| Step: 8
Training loss: 3.067196417400594
Validation loss: 2.6999319103273796

Epoch: 6| Step: 9
Training loss: 2.731018622263299
Validation loss: 2.6998859469731693

Epoch: 6| Step: 10
Training loss: 2.77938626025668
Validation loss: 2.6997047498360693

Epoch: 6| Step: 11
Training loss: 2.67866162829434
Validation loss: 2.6993941798893717

Epoch: 6| Step: 12
Training loss: 2.359193807553831
Validation loss: 2.714821136160875

Epoch: 6| Step: 13
Training loss: 3.4453890352982235
Validation loss: 2.7218198289619324

Epoch: 60| Step: 0
Training loss: 2.544976585895027
Validation loss: 2.7095267356379003

Epoch: 6| Step: 1
Training loss: 2.9389803788243056
Validation loss: 2.7047680251286055

Epoch: 6| Step: 2
Training loss: 2.5444587526192124
Validation loss: 2.6865331403935406

Epoch: 6| Step: 3
Training loss: 2.834029467465174
Validation loss: 2.693497523065248

Epoch: 6| Step: 4
Training loss: 2.9896838517962743
Validation loss: 2.696089731097554

Epoch: 6| Step: 5
Training loss: 2.9197221464404026
Validation loss: 2.7037591061826016

Epoch: 6| Step: 6
Training loss: 3.375058632800519
Validation loss: 2.7100450877278224

Epoch: 6| Step: 7
Training loss: 2.8659449075327137
Validation loss: 2.7109067184063855

Epoch: 6| Step: 8
Training loss: 2.857159866554855
Validation loss: 2.7141551802613404

Epoch: 6| Step: 9
Training loss: 2.4851067383099377
Validation loss: 2.704565087245462

Epoch: 6| Step: 10
Training loss: 3.0297372720455598
Validation loss: 2.6978181848017235

Epoch: 6| Step: 11
Training loss: 2.7163684981682024
Validation loss: 2.6940169164555523

Epoch: 6| Step: 12
Training loss: 3.1576713156719434
Validation loss: 2.6905906855233375

Epoch: 6| Step: 13
Training loss: 2.4097549871097663
Validation loss: 2.6869192604879255

Epoch: 61| Step: 0
Training loss: 3.4816550000404463
Validation loss: 2.686954028835279

Epoch: 6| Step: 1
Training loss: 1.915177312565357
Validation loss: 2.686344593288467

Epoch: 6| Step: 2
Training loss: 2.908428073276332
Validation loss: 2.6882365348575896

Epoch: 6| Step: 3
Training loss: 3.032832096592729
Validation loss: 2.689818971231527

Epoch: 6| Step: 4
Training loss: 3.062744130894405
Validation loss: 2.6844921431407225

Epoch: 6| Step: 5
Training loss: 3.3000178249918095
Validation loss: 2.684556265570251

Epoch: 6| Step: 6
Training loss: 3.2118401291278
Validation loss: 2.677709399885239

Epoch: 6| Step: 7
Training loss: 2.850141280838504
Validation loss: 2.676282122064511

Epoch: 6| Step: 8
Training loss: 1.8757367911704366
Validation loss: 2.676078197031431

Epoch: 6| Step: 9
Training loss: 2.650918614217823
Validation loss: 2.6753736644980903

Epoch: 6| Step: 10
Training loss: 2.967841722180453
Validation loss: 2.676616039137785

Epoch: 6| Step: 11
Training loss: 2.9391583570538278
Validation loss: 2.6757854972118817

Epoch: 6| Step: 12
Training loss: 2.4634339280122544
Validation loss: 2.6747509088735453

Epoch: 6| Step: 13
Training loss: 2.335217725417431
Validation loss: 2.6757612018808716

Epoch: 62| Step: 0
Training loss: 3.228787668608755
Validation loss: 2.674633230930583

Epoch: 6| Step: 1
Training loss: 3.476493371854861
Validation loss: 2.673151585004705

Epoch: 6| Step: 2
Training loss: 2.972642134082779
Validation loss: 2.6701727458348996

Epoch: 6| Step: 3
Training loss: 2.5468839867556174
Validation loss: 2.6694863184347097

Epoch: 6| Step: 4
Training loss: 2.797506420956522
Validation loss: 2.667775733113206

Epoch: 6| Step: 5
Training loss: 2.681722774483703
Validation loss: 2.664935352156827

Epoch: 6| Step: 6
Training loss: 2.5418790718085393
Validation loss: 2.6640281041107245

Epoch: 6| Step: 7
Training loss: 2.7241842396253855
Validation loss: 2.660028410690522

Epoch: 6| Step: 8
Training loss: 3.1984518061077067
Validation loss: 2.6591515942940074

Epoch: 6| Step: 9
Training loss: 2.4914732480543043
Validation loss: 2.6585402096298774

Epoch: 6| Step: 10
Training loss: 2.9671044858837323
Validation loss: 2.6558144305773097

Epoch: 6| Step: 11
Training loss: 2.7377075813357643
Validation loss: 2.6553628075672067

Epoch: 6| Step: 12
Training loss: 2.4677968176944494
Validation loss: 2.656051403924155

Epoch: 6| Step: 13
Training loss: 2.202920674257317
Validation loss: 2.6522583383582585

Epoch: 63| Step: 0
Training loss: 2.586668251256687
Validation loss: 2.6504991996863234

Epoch: 6| Step: 1
Training loss: 2.7306763838816144
Validation loss: 2.650777287718696

Epoch: 6| Step: 2
Training loss: 2.746069613658598
Validation loss: 2.6569233957048364

Epoch: 6| Step: 3
Training loss: 2.8503251408941885
Validation loss: 2.6583644155600514

Epoch: 6| Step: 4
Training loss: 2.8665468087386
Validation loss: 2.652336169284929

Epoch: 6| Step: 5
Training loss: 2.8836289983727705
Validation loss: 2.651451383955108

Epoch: 6| Step: 6
Training loss: 2.959699306422197
Validation loss: 2.6442051380755887

Epoch: 6| Step: 7
Training loss: 2.9731563593566044
Validation loss: 2.6463449889541124

Epoch: 6| Step: 8
Training loss: 2.916063046437079
Validation loss: 2.649214099012616

Epoch: 6| Step: 9
Training loss: 2.4039491825032626
Validation loss: 2.650259765752864

Epoch: 6| Step: 10
Training loss: 2.6258478157937835
Validation loss: 2.654383358775679

Epoch: 6| Step: 11
Training loss: 3.084572019149626
Validation loss: 2.660576800667816

Epoch: 6| Step: 12
Training loss: 2.5829780908616113
Validation loss: 2.6608136037526573

Epoch: 6| Step: 13
Training loss: 2.857601762429748
Validation loss: 2.658527131226355

Epoch: 64| Step: 0
Training loss: 2.5740916751876783
Validation loss: 2.656075086631472

Epoch: 6| Step: 1
Training loss: 2.8826917504140592
Validation loss: 2.654342699626088

Epoch: 6| Step: 2
Training loss: 2.9507632221926627
Validation loss: 2.653211299120245

Epoch: 6| Step: 3
Training loss: 3.3556719575219245
Validation loss: 2.650768263433027

Epoch: 6| Step: 4
Training loss: 2.663020402796503
Validation loss: 2.6492768404565337

Epoch: 6| Step: 5
Training loss: 2.236023834715655
Validation loss: 2.6482461205637158

Epoch: 6| Step: 6
Training loss: 2.5516099970940913
Validation loss: 2.6450023222169734

Epoch: 6| Step: 7
Training loss: 2.917844225819374
Validation loss: 2.6449082827515755

Epoch: 6| Step: 8
Training loss: 2.411134196853086
Validation loss: 2.6415777951603308

Epoch: 6| Step: 9
Training loss: 3.1139445250463145
Validation loss: 2.6402339758649047

Epoch: 6| Step: 10
Training loss: 2.57125790725998
Validation loss: 2.634489089709622

Epoch: 6| Step: 11
Training loss: 2.801988753716215
Validation loss: 2.6332986837433316

Epoch: 6| Step: 12
Training loss: 3.100942093225791
Validation loss: 2.6321394123164037

Epoch: 6| Step: 13
Training loss: 2.6076279690905113
Validation loss: 2.629283362175224

Epoch: 65| Step: 0
Training loss: 2.7685000029045987
Validation loss: 2.6280405811929333

Epoch: 6| Step: 1
Training loss: 2.98196041831567
Validation loss: 2.6287519042158887

Epoch: 6| Step: 2
Training loss: 2.9808034246485433
Validation loss: 2.6291938159667354

Epoch: 6| Step: 3
Training loss: 2.518056133102105
Validation loss: 2.62658009580898

Epoch: 6| Step: 4
Training loss: 2.6359741063676854
Validation loss: 2.624943596370169

Epoch: 6| Step: 5
Training loss: 2.3480072013055695
Validation loss: 2.632537857657728

Epoch: 6| Step: 6
Training loss: 2.87739595836595
Validation loss: 2.6338621739230654

Epoch: 6| Step: 7
Training loss: 2.277604521646624
Validation loss: 2.6296963838701846

Epoch: 6| Step: 8
Training loss: 2.8080510873956386
Validation loss: 2.6243843688821835

Epoch: 6| Step: 9
Training loss: 2.873556023248894
Validation loss: 2.6239929841042753

Epoch: 6| Step: 10
Training loss: 2.9921785757863
Validation loss: 2.6250879787657744

Epoch: 6| Step: 11
Training loss: 3.12362884958207
Validation loss: 2.62068431553914

Epoch: 6| Step: 12
Training loss: 2.3546477194844955
Validation loss: 2.616385356902807

Epoch: 6| Step: 13
Training loss: 3.0275264561802087
Validation loss: 2.6155918400286913

Epoch: 66| Step: 0
Training loss: 2.8082370239707855
Validation loss: 2.6168856546364103

Epoch: 6| Step: 1
Training loss: 2.5939483566731627
Validation loss: 2.618400968054058

Epoch: 6| Step: 2
Training loss: 2.8654573713921527
Validation loss: 2.619345326760359

Epoch: 6| Step: 3
Training loss: 2.1436632411294525
Validation loss: 2.6204959587546877

Epoch: 6| Step: 4
Training loss: 3.0423164892843872
Validation loss: 2.621697028102108

Epoch: 6| Step: 5
Training loss: 3.1416130978767085
Validation loss: 2.62345310075524

Epoch: 6| Step: 6
Training loss: 2.7224762034711705
Validation loss: 2.6248531451850874

Epoch: 6| Step: 7
Training loss: 3.0225109484452957
Validation loss: 2.6231814246039344

Epoch: 6| Step: 8
Training loss: 2.9504996442356615
Validation loss: 2.6230306655636695

Epoch: 6| Step: 9
Training loss: 2.5034467778446445
Validation loss: 2.6214015607505234

Epoch: 6| Step: 10
Training loss: 2.7468981154926317
Validation loss: 2.6206652712242873

Epoch: 6| Step: 11
Training loss: 2.3256124981752015
Validation loss: 2.619059653171949

Epoch: 6| Step: 12
Training loss: 2.7398644848189333
Validation loss: 2.6155569130722855

Epoch: 6| Step: 13
Training loss: 2.8959463266699412
Validation loss: 2.6146810191676626

Epoch: 67| Step: 0
Training loss: 2.779428292637019
Validation loss: 2.611328353254127

Epoch: 6| Step: 1
Training loss: 2.4914222427290285
Validation loss: 2.6102510150573393

Epoch: 6| Step: 2
Training loss: 2.8841799255730587
Validation loss: 2.6076782710090938

Epoch: 6| Step: 3
Training loss: 2.572501968961357
Validation loss: 2.6021842633584535

Epoch: 6| Step: 4
Training loss: 2.5185344291425453
Validation loss: 2.600006417119837

Epoch: 6| Step: 5
Training loss: 2.5358368558062123
Validation loss: 2.59944479039419

Epoch: 6| Step: 6
Training loss: 2.2500089009426807
Validation loss: 2.6011561018081784

Epoch: 6| Step: 7
Training loss: 2.9456856488694725
Validation loss: 2.603893453889146

Epoch: 6| Step: 8
Training loss: 2.7110360866946417
Validation loss: 2.6147888730987328

Epoch: 6| Step: 9
Training loss: 2.7585868288707958
Validation loss: 2.6270469374609826

Epoch: 6| Step: 10
Training loss: 2.873615429064104
Validation loss: 2.6260867972293367

Epoch: 6| Step: 11
Training loss: 2.1325678982049086
Validation loss: 2.619076638195149

Epoch: 6| Step: 12
Training loss: 3.3378544822776264
Validation loss: 2.623032316809897

Epoch: 6| Step: 13
Training loss: 3.5053890157141274
Validation loss: 2.6117675228967925

Epoch: 68| Step: 0
Training loss: 2.511490830778547
Validation loss: 2.6069202869316452

Epoch: 6| Step: 1
Training loss: 2.858414118508405
Validation loss: 2.603360582844855

Epoch: 6| Step: 2
Training loss: 2.7438596316877732
Validation loss: 2.6017315631114357

Epoch: 6| Step: 3
Training loss: 2.7979059290638464
Validation loss: 2.598554259991771

Epoch: 6| Step: 4
Training loss: 2.4085334743068634
Validation loss: 2.600226822153585

Epoch: 6| Step: 5
Training loss: 2.907226890535756
Validation loss: 2.6043747068593723

Epoch: 6| Step: 6
Training loss: 2.468337205587162
Validation loss: 2.6058323886171424

Epoch: 6| Step: 7
Training loss: 3.4179374998571417
Validation loss: 2.6068665407175082

Epoch: 6| Step: 8
Training loss: 2.749434412968791
Validation loss: 2.607119150483208

Epoch: 6| Step: 9
Training loss: 2.550998462349052
Validation loss: 2.6072910690357736

Epoch: 6| Step: 10
Training loss: 2.3351320645154154
Validation loss: 2.6056175971038495

Epoch: 6| Step: 11
Training loss: 2.6843557372639957
Validation loss: 2.605841202544589

Epoch: 6| Step: 12
Training loss: 2.8250602006827554
Validation loss: 2.6020959988711616

Epoch: 6| Step: 13
Training loss: 2.9092714744038215
Validation loss: 2.6012707643109416

Epoch: 69| Step: 0
Training loss: 2.6405639641383534
Validation loss: 2.601292959918966

Epoch: 6| Step: 1
Training loss: 2.7998098819765644
Validation loss: 2.5995170639924945

Epoch: 6| Step: 2
Training loss: 2.1779356995996406
Validation loss: 2.5986906893617845

Epoch: 6| Step: 3
Training loss: 2.560972363163112
Validation loss: 2.5946254248691862

Epoch: 6| Step: 4
Training loss: 3.0035620840713606
Validation loss: 2.592124184296418

Epoch: 6| Step: 5
Training loss: 3.2291298320679327
Validation loss: 2.5917997420102754

Epoch: 6| Step: 6
Training loss: 2.9916054580363256
Validation loss: 2.5894811193211584

Epoch: 6| Step: 7
Training loss: 2.9988723860934345
Validation loss: 2.5860217984414917

Epoch: 6| Step: 8
Training loss: 2.6655149555634687
Validation loss: 2.5838079375458225

Epoch: 6| Step: 9
Training loss: 2.642210625401229
Validation loss: 2.5842897172761443

Epoch: 6| Step: 10
Training loss: 2.285952176759425
Validation loss: 2.584980675276458

Epoch: 6| Step: 11
Training loss: 2.5426735889812004
Validation loss: 2.580136972507551

Epoch: 6| Step: 12
Training loss: 3.015142688822531
Validation loss: 2.58069968310983

Epoch: 6| Step: 13
Training loss: 2.490883800122537
Validation loss: 2.5814758565274767

Epoch: 70| Step: 0
Training loss: 2.8126598736570285
Validation loss: 2.582413345512861

Epoch: 6| Step: 1
Training loss: 2.484002043362328
Validation loss: 2.578692310222347

Epoch: 6| Step: 2
Training loss: 2.676819091897065
Validation loss: 2.579548775916863

Epoch: 6| Step: 3
Training loss: 2.544008853872955
Validation loss: 2.578625763319534

Epoch: 6| Step: 4
Training loss: 2.964289798175671
Validation loss: 2.5778857649961116

Epoch: 6| Step: 5
Training loss: 2.996960371629263
Validation loss: 2.57846390779662

Epoch: 6| Step: 6
Training loss: 2.3724043867261995
Validation loss: 2.5778564467383434

Epoch: 6| Step: 7
Training loss: 3.0127885355815858
Validation loss: 2.574761263573222

Epoch: 6| Step: 8
Training loss: 2.8645819276748443
Validation loss: 2.576001118979596

Epoch: 6| Step: 9
Training loss: 2.9104067700999887
Validation loss: 2.574775199583351

Epoch: 6| Step: 10
Training loss: 2.553200945430857
Validation loss: 2.5749071943972086

Epoch: 6| Step: 11
Training loss: 2.5051970821981846
Validation loss: 2.5743091279885384

Epoch: 6| Step: 12
Training loss: 2.2134204307715546
Validation loss: 2.5744644997068526

Epoch: 6| Step: 13
Training loss: 2.974569619727772
Validation loss: 2.570787349229907

Epoch: 71| Step: 0
Training loss: 2.199764963079408
Validation loss: 2.568366925091881

Epoch: 6| Step: 1
Training loss: 2.697799110551702
Validation loss: 2.5710695614677177

Epoch: 6| Step: 2
Training loss: 2.982161894673064
Validation loss: 2.5739039227117297

Epoch: 6| Step: 3
Training loss: 2.7092286806294728
Validation loss: 2.573536915220547

Epoch: 6| Step: 4
Training loss: 3.1494556986104385
Validation loss: 2.5703147416650953

Epoch: 6| Step: 5
Training loss: 3.1559982954825667
Validation loss: 2.576730786578936

Epoch: 6| Step: 6
Training loss: 2.6496650304155396
Validation loss: 2.5667536407035683

Epoch: 6| Step: 7
Training loss: 3.041963815327159
Validation loss: 2.5647697940807133

Epoch: 6| Step: 8
Training loss: 2.689962456593642
Validation loss: 2.564789470338773

Epoch: 6| Step: 9
Training loss: 2.6351004148166712
Validation loss: 2.5676337586587428

Epoch: 6| Step: 10
Training loss: 2.4691259363501254
Validation loss: 2.5686704420653865

Epoch: 6| Step: 11
Training loss: 2.735220119119597
Validation loss: 2.5713549570617222

Epoch: 6| Step: 12
Training loss: 2.3733552959940383
Validation loss: 2.5747746748622986

Epoch: 6| Step: 13
Training loss: 2.355235833186464
Validation loss: 2.583734809278406

Epoch: 72| Step: 0
Training loss: 2.735572160502918
Validation loss: 2.5883219962804156

Epoch: 6| Step: 1
Training loss: 2.887749803975214
Validation loss: 2.5974291250419306

Epoch: 6| Step: 2
Training loss: 2.5503316252245716
Validation loss: 2.6031428549811735

Epoch: 6| Step: 3
Training loss: 2.5335758026268427
Validation loss: 2.5999665735003386

Epoch: 6| Step: 4
Training loss: 2.650076030144353
Validation loss: 2.5900265421544493

Epoch: 6| Step: 5
Training loss: 2.7305922146062493
Validation loss: 2.5867360890140616

Epoch: 6| Step: 6
Training loss: 2.5909226415666136
Validation loss: 2.575844698382798

Epoch: 6| Step: 7
Training loss: 2.801727603232267
Validation loss: 2.5646691019532386

Epoch: 6| Step: 8
Training loss: 2.730208879800912
Validation loss: 2.564638129691417

Epoch: 6| Step: 9
Training loss: 3.036784831182624
Validation loss: 2.562757882268569

Epoch: 6| Step: 10
Training loss: 2.161361165141458
Validation loss: 2.5539631258922193

Epoch: 6| Step: 11
Training loss: 2.604920748568609
Validation loss: 2.559461870531839

Epoch: 6| Step: 12
Training loss: 3.1191063809172195
Validation loss: 2.557821111522821

Epoch: 6| Step: 13
Training loss: 2.7222421076647314
Validation loss: 2.559202181082024

Epoch: 73| Step: 0
Training loss: 3.385699372836445
Validation loss: 2.5557320235548473

Epoch: 6| Step: 1
Training loss: 2.911212253350418
Validation loss: 2.554374605668357

Epoch: 6| Step: 2
Training loss: 2.310035629658237
Validation loss: 2.553441170423035

Epoch: 6| Step: 3
Training loss: 2.191462606157589
Validation loss: 2.556539876928152

Epoch: 6| Step: 4
Training loss: 2.4227243226300295
Validation loss: 2.555461521307559

Epoch: 6| Step: 5
Training loss: 2.9513169662588172
Validation loss: 2.556170112089032

Epoch: 6| Step: 6
Training loss: 2.1731813741968824
Validation loss: 2.5597806317992506

Epoch: 6| Step: 7
Training loss: 2.7523477242988177
Validation loss: 2.556624585153084

Epoch: 6| Step: 8
Training loss: 2.7608269920318516
Validation loss: 2.5575823233472352

Epoch: 6| Step: 9
Training loss: 2.8790649204705647
Validation loss: 2.5583452798106774

Epoch: 6| Step: 10
Training loss: 2.8120503384030826
Validation loss: 2.558229671908842

Epoch: 6| Step: 11
Training loss: 2.902049977771976
Validation loss: 2.5563950426757445

Epoch: 6| Step: 12
Training loss: 2.6107972432148427
Validation loss: 2.5552884327375294

Epoch: 6| Step: 13
Training loss: 2.4315685583259032
Validation loss: 2.5550202163722626

Epoch: 74| Step: 0
Training loss: 2.325712246651256
Validation loss: 2.553520052542604

Epoch: 6| Step: 1
Training loss: 2.4699029282557046
Validation loss: 2.551278214386639

Epoch: 6| Step: 2
Training loss: 2.5728308680098895
Validation loss: 2.5519193687446666

Epoch: 6| Step: 3
Training loss: 2.858545401874036
Validation loss: 2.548110397056246

Epoch: 6| Step: 4
Training loss: 2.37863012255336
Validation loss: 2.550251390182854

Epoch: 6| Step: 5
Training loss: 3.0350622999656616
Validation loss: 2.5496592524630124

Epoch: 6| Step: 6
Training loss: 2.909579758860194
Validation loss: 2.550727574950619

Epoch: 6| Step: 7
Training loss: 2.4887598077570257
Validation loss: 2.54588357862305

Epoch: 6| Step: 8
Training loss: 2.5561953886209734
Validation loss: 2.545297738866309

Epoch: 6| Step: 9
Training loss: 2.3379926029868217
Validation loss: 2.551117123762142

Epoch: 6| Step: 10
Training loss: 2.4588748098480675
Validation loss: 2.5454649971462535

Epoch: 6| Step: 11
Training loss: 2.7280921470875006
Validation loss: 2.547322021446613

Epoch: 6| Step: 12
Training loss: 3.0738284724869547
Validation loss: 2.5447399965386883

Epoch: 6| Step: 13
Training loss: 3.203775479397346
Validation loss: 2.5425173372961005

Epoch: 75| Step: 0
Training loss: 1.9830329141236978
Validation loss: 2.54257897643513

Epoch: 6| Step: 1
Training loss: 2.9072049120582815
Validation loss: 2.5455342451639518

Epoch: 6| Step: 2
Training loss: 2.627770188338342
Validation loss: 2.5438738812298287

Epoch: 6| Step: 3
Training loss: 2.620338478937723
Validation loss: 2.543567233506398

Epoch: 6| Step: 4
Training loss: 2.583536745082155
Validation loss: 2.5442571311016864

Epoch: 6| Step: 5
Training loss: 2.99759339124258
Validation loss: 2.545337454726391

Epoch: 6| Step: 6
Training loss: 2.515820134336662
Validation loss: 2.542365608626989

Epoch: 6| Step: 7
Training loss: 2.732326764952551
Validation loss: 2.5402962528634756

Epoch: 6| Step: 8
Training loss: 3.0591047500777484
Validation loss: 2.53652110142888

Epoch: 6| Step: 9
Training loss: 2.443752778580981
Validation loss: 2.537795892385615

Epoch: 6| Step: 10
Training loss: 2.751412895680303
Validation loss: 2.5380600813825227

Epoch: 6| Step: 11
Training loss: 2.7794890240148713
Validation loss: 2.5410394728546

Epoch: 6| Step: 12
Training loss: 2.355049969088358
Validation loss: 2.537868042737211

Epoch: 6| Step: 13
Training loss: 2.918833899262158
Validation loss: 2.5404032136113446

Epoch: 76| Step: 0
Training loss: 2.890988218839663
Validation loss: 2.53949689230341

Epoch: 6| Step: 1
Training loss: 2.713344681534089
Validation loss: 2.538126533343138

Epoch: 6| Step: 2
Training loss: 2.7673187241976964
Validation loss: 2.536473179538107

Epoch: 6| Step: 3
Training loss: 2.451205237416133
Validation loss: 2.535607766498828

Epoch: 6| Step: 4
Training loss: 2.4362390631268265
Validation loss: 2.535100684514606

Epoch: 6| Step: 5
Training loss: 2.375152984510493
Validation loss: 2.536545367513393

Epoch: 6| Step: 6
Training loss: 2.793317439581084
Validation loss: 2.534964124612558

Epoch: 6| Step: 7
Training loss: 2.981158695382254
Validation loss: 2.5349405017619535

Epoch: 6| Step: 8
Training loss: 2.9639271964168046
Validation loss: 2.5376813995967207

Epoch: 6| Step: 9
Training loss: 2.0876359632608597
Validation loss: 2.5381739543523194

Epoch: 6| Step: 10
Training loss: 2.978569415497892
Validation loss: 2.5347930224791693

Epoch: 6| Step: 11
Training loss: 2.14374620976683
Validation loss: 2.5370874949689632

Epoch: 6| Step: 12
Training loss: 2.6056673125822996
Validation loss: 2.533991494660529

Epoch: 6| Step: 13
Training loss: 2.8977064665729095
Validation loss: 2.531909966479647

Epoch: 77| Step: 0
Training loss: 2.440355242524497
Validation loss: 2.530548595061106

Epoch: 6| Step: 1
Training loss: 2.362443154271765
Validation loss: 2.530916058525314

Epoch: 6| Step: 2
Training loss: 3.391990281271057
Validation loss: 2.5314900319767566

Epoch: 6| Step: 3
Training loss: 2.706981663986015
Validation loss: 2.529983910294587

Epoch: 6| Step: 4
Training loss: 2.312019504425249
Validation loss: 2.5295680230907402

Epoch: 6| Step: 5
Training loss: 2.4620369529089148
Validation loss: 2.5328128683696702

Epoch: 6| Step: 6
Training loss: 2.6786737331653514
Validation loss: 2.5365821500058363

Epoch: 6| Step: 7
Training loss: 2.3427382256237737
Validation loss: 2.5354175090135374

Epoch: 6| Step: 8
Training loss: 2.844664541891714
Validation loss: 2.5366102848061334

Epoch: 6| Step: 9
Training loss: 2.5379158130327624
Validation loss: 2.529672939862609

Epoch: 6| Step: 10
Training loss: 2.564095535390953
Validation loss: 2.528505784362348

Epoch: 6| Step: 11
Training loss: 2.6991341297449454
Validation loss: 2.5309499868924954

Epoch: 6| Step: 12
Training loss: 2.7894668072347715
Validation loss: 2.5290906667419413

Epoch: 6| Step: 13
Training loss: 2.929844071337011
Validation loss: 2.527432659772693

Epoch: 78| Step: 0
Training loss: 2.658605002828678
Validation loss: 2.5299213674385532

Epoch: 6| Step: 1
Training loss: 2.4301892709999566
Validation loss: 2.5301025207263725

Epoch: 6| Step: 2
Training loss: 3.0106108887705805
Validation loss: 2.527692484784876

Epoch: 6| Step: 3
Training loss: 3.014889325946324
Validation loss: 2.53019822800368

Epoch: 6| Step: 4
Training loss: 2.238449117014477
Validation loss: 2.527292776797519

Epoch: 6| Step: 5
Training loss: 2.868082431752468
Validation loss: 2.5267872342588604

Epoch: 6| Step: 6
Training loss: 1.743150043164038
Validation loss: 2.5236292117648946

Epoch: 6| Step: 7
Training loss: 2.71416938145234
Validation loss: 2.5239200189767845

Epoch: 6| Step: 8
Training loss: 2.489582769375236
Validation loss: 2.5193085801253705

Epoch: 6| Step: 9
Training loss: 2.828899298624865
Validation loss: 2.523269301281928

Epoch: 6| Step: 10
Training loss: 2.443404065401146
Validation loss: 2.52048791667895

Epoch: 6| Step: 11
Training loss: 2.694463446857087
Validation loss: 2.5211705909621633

Epoch: 6| Step: 12
Training loss: 2.7505380797656604
Validation loss: 2.526766585846179

Epoch: 6| Step: 13
Training loss: 3.0225753146270438
Validation loss: 2.525818841813553

Epoch: 79| Step: 0
Training loss: 2.4744345972833695
Validation loss: 2.524056924512545

Epoch: 6| Step: 1
Training loss: 2.5937158053798317
Validation loss: 2.519731349047045

Epoch: 6| Step: 2
Training loss: 2.4962001533096863
Validation loss: 2.5228081736296595

Epoch: 6| Step: 3
Training loss: 2.9958803182922313
Validation loss: 2.5167023146759315

Epoch: 6| Step: 4
Training loss: 2.185444765543661
Validation loss: 2.5207800636232753

Epoch: 6| Step: 5
Training loss: 2.646722198723696
Validation loss: 2.5203265213975428

Epoch: 6| Step: 6
Training loss: 2.698771769589095
Validation loss: 2.5240844747520246

Epoch: 6| Step: 7
Training loss: 3.076964493619502
Validation loss: 2.521271475765243

Epoch: 6| Step: 8
Training loss: 2.898960775762021
Validation loss: 2.5204379399539563

Epoch: 6| Step: 9
Training loss: 2.481088539846939
Validation loss: 2.5226556533209474

Epoch: 6| Step: 10
Training loss: 3.025700946651353
Validation loss: 2.5206021184471505

Epoch: 6| Step: 11
Training loss: 2.212749372319081
Validation loss: 2.5194327874867892

Epoch: 6| Step: 12
Training loss: 1.9616198321477187
Validation loss: 2.5186139154391127

Epoch: 6| Step: 13
Training loss: 3.06152795429292
Validation loss: 2.519285709530927

Epoch: 80| Step: 0
Training loss: 1.870466091188213
Validation loss: 2.5205716294145666

Epoch: 6| Step: 1
Training loss: 2.8911714604352428
Validation loss: 2.516378270186821

Epoch: 6| Step: 2
Training loss: 2.908394791209688
Validation loss: 2.517003947092608

Epoch: 6| Step: 3
Training loss: 2.224684609337456
Validation loss: 2.5180159238191107

Epoch: 6| Step: 4
Training loss: 2.775957365109867
Validation loss: 2.516815440936213

Epoch: 6| Step: 5
Training loss: 2.5148366320658337
Validation loss: 2.5245036263629035

Epoch: 6| Step: 6
Training loss: 2.530352021104575
Validation loss: 2.5273572399598927

Epoch: 6| Step: 7
Training loss: 2.421072550087181
Validation loss: 2.517512117146459

Epoch: 6| Step: 8
Training loss: 2.718546103362453
Validation loss: 2.5221905693256406

Epoch: 6| Step: 9
Training loss: 2.4545049005748187
Validation loss: 2.5147328186692106

Epoch: 6| Step: 10
Training loss: 2.779936147958232
Validation loss: 2.516668841590531

Epoch: 6| Step: 11
Training loss: 2.403368822683164
Validation loss: 2.518006076549887

Epoch: 6| Step: 12
Training loss: 3.1499716379009
Validation loss: 2.5096711968495766

Epoch: 6| Step: 13
Training loss: 3.0700848133412206
Validation loss: 2.5162250127055454

Epoch: 81| Step: 0
Training loss: 2.8899367054274654
Validation loss: 2.5146215265803162

Epoch: 6| Step: 1
Training loss: 2.0058591372778585
Validation loss: 2.5103186803243287

Epoch: 6| Step: 2
Training loss: 2.8438358503524777
Validation loss: 2.514567940914279

Epoch: 6| Step: 3
Training loss: 2.4897789871607534
Validation loss: 2.5162988632897747

Epoch: 6| Step: 4
Training loss: 2.7154792316326004
Validation loss: 2.5215466779974482

Epoch: 6| Step: 5
Training loss: 2.528000995249492
Validation loss: 2.51276031619597

Epoch: 6| Step: 6
Training loss: 2.9005223099840713
Validation loss: 2.5225174272714677

Epoch: 6| Step: 7
Training loss: 2.6709245028435635
Validation loss: 2.5193877265524827

Epoch: 6| Step: 8
Training loss: 2.608300907392519
Validation loss: 2.5126320151065737

Epoch: 6| Step: 9
Training loss: 2.727965947394513
Validation loss: 2.5108278710725482

Epoch: 6| Step: 10
Training loss: 2.7361955957768056
Validation loss: 2.513683857527368

Epoch: 6| Step: 11
Training loss: 2.466980311927121
Validation loss: 2.5192972710366885

Epoch: 6| Step: 12
Training loss: 2.730853095993443
Validation loss: 2.5232264191298457

Epoch: 6| Step: 13
Training loss: 2.6260942267474614
Validation loss: 2.5288218559078928

Epoch: 82| Step: 0
Training loss: 2.861823362645636
Validation loss: 2.5228674434665943

Epoch: 6| Step: 1
Training loss: 2.84075350664831
Validation loss: 2.5196703337691346

Epoch: 6| Step: 2
Training loss: 2.3934754973703933
Validation loss: 2.520840027435074

Epoch: 6| Step: 3
Training loss: 2.7524780032797387
Validation loss: 2.5226575750428397

Epoch: 6| Step: 4
Training loss: 2.9079638934196086
Validation loss: 2.514184954252947

Epoch: 6| Step: 5
Training loss: 2.381620915878655
Validation loss: 2.5182609884834726

Epoch: 6| Step: 6
Training loss: 2.417838196318997
Validation loss: 2.5194853549296203

Epoch: 6| Step: 7
Training loss: 2.3852333653638325
Validation loss: 2.513884595887211

Epoch: 6| Step: 8
Training loss: 2.7546505186094468
Validation loss: 2.514074538830149

Epoch: 6| Step: 9
Training loss: 2.708700966947944
Validation loss: 2.5110611358759645

Epoch: 6| Step: 10
Training loss: 2.478912682439259
Validation loss: 2.5113665628985005

Epoch: 6| Step: 11
Training loss: 2.7146998085997955
Validation loss: 2.5122311051243678

Epoch: 6| Step: 12
Training loss: 2.9625301053734696
Validation loss: 2.509078517325338

Epoch: 6| Step: 13
Training loss: 2.317742873945279
Validation loss: 2.508401977723492

Epoch: 83| Step: 0
Training loss: 2.70469593419215
Validation loss: 2.5081964913825936

Epoch: 6| Step: 1
Training loss: 2.5424388796381234
Validation loss: 2.5059398659008623

Epoch: 6| Step: 2
Training loss: 2.8841855467367856
Validation loss: 2.5054659060049813

Epoch: 6| Step: 3
Training loss: 2.260354798579242
Validation loss: 2.5080880224685123

Epoch: 6| Step: 4
Training loss: 2.7791471782803625
Validation loss: 2.5116287776955506

Epoch: 6| Step: 5
Training loss: 2.7521494354772513
Validation loss: 2.5104954233650165

Epoch: 6| Step: 6
Training loss: 2.757477045594835
Validation loss: 2.513541691750185

Epoch: 6| Step: 7
Training loss: 2.5591308030108477
Validation loss: 2.516066344662559

Epoch: 6| Step: 8
Training loss: 2.5617911125868185
Validation loss: 2.5127125104544685

Epoch: 6| Step: 9
Training loss: 2.8690837857074127
Validation loss: 2.512158519003376

Epoch: 6| Step: 10
Training loss: 2.6775708972936982
Validation loss: 2.5103411577405277

Epoch: 6| Step: 11
Training loss: 2.3281891065130504
Validation loss: 2.5089394640754774

Epoch: 6| Step: 12
Training loss: 2.3154177430101024
Validation loss: 2.5098857925086486

Epoch: 6| Step: 13
Training loss: 2.6435169883832965
Validation loss: 2.5100800274000097

Epoch: 84| Step: 0
Training loss: 3.042563963619711
Validation loss: 2.508606116669193

Epoch: 6| Step: 1
Training loss: 2.8237008745125864
Validation loss: 2.5007673834198094

Epoch: 6| Step: 2
Training loss: 2.85901777193484
Validation loss: 2.5021682952465283

Epoch: 6| Step: 3
Training loss: 2.3239992182298614
Validation loss: 2.5003649127394834

Epoch: 6| Step: 4
Training loss: 2.8713330642715422
Validation loss: 2.506208213654405

Epoch: 6| Step: 5
Training loss: 2.633625391767515
Validation loss: 2.505432370029477

Epoch: 6| Step: 6
Training loss: 3.095914141565984
Validation loss: 2.5050870637363913

Epoch: 6| Step: 7
Training loss: 2.260320306883401
Validation loss: 2.5064794021603247

Epoch: 6| Step: 8
Training loss: 2.1662058217892213
Validation loss: 2.5039334347777156

Epoch: 6| Step: 9
Training loss: 2.2304973967895503
Validation loss: 2.504456029751592

Epoch: 6| Step: 10
Training loss: 1.876380348735167
Validation loss: 2.503993198989838

Epoch: 6| Step: 11
Training loss: 2.987387210520433
Validation loss: 2.5024630969588397

Epoch: 6| Step: 12
Training loss: 2.4317429854208594
Validation loss: 2.4982265380960915

Epoch: 6| Step: 13
Training loss: 2.787509432378984
Validation loss: 2.495124115159781

Epoch: 85| Step: 0
Training loss: 2.4933319812233807
Validation loss: 2.495214475562736

Epoch: 6| Step: 1
Training loss: 2.7501631601655454
Validation loss: 2.4997447201410807

Epoch: 6| Step: 2
Training loss: 2.969603887531186
Validation loss: 2.498952534901956

Epoch: 6| Step: 3
Training loss: 2.5317441669862877
Validation loss: 2.499090506103477

Epoch: 6| Step: 4
Training loss: 2.5901984292684257
Validation loss: 2.5024852320857462

Epoch: 6| Step: 5
Training loss: 2.624392302879206
Validation loss: 2.507310304042856

Epoch: 6| Step: 6
Training loss: 2.7488211792823822
Validation loss: 2.499718952275962

Epoch: 6| Step: 7
Training loss: 1.9833251699178116
Validation loss: 2.4982319778926856

Epoch: 6| Step: 8
Training loss: 2.5340964243005017
Validation loss: 2.4982193168273437

Epoch: 6| Step: 9
Training loss: 2.38794473230761
Validation loss: 2.500782669259244

Epoch: 6| Step: 10
Training loss: 2.7962596365532817
Validation loss: 2.4996966495848003

Epoch: 6| Step: 11
Training loss: 2.555487178035149
Validation loss: 2.4970038580079805

Epoch: 6| Step: 12
Training loss: 2.792360551676936
Validation loss: 2.5007008364936287

Epoch: 6| Step: 13
Training loss: 2.681718773755453
Validation loss: 2.5024858037220112

Epoch: 86| Step: 0
Training loss: 2.8224533282628728
Validation loss: 2.4992400444819256

Epoch: 6| Step: 1
Training loss: 2.83931075476669
Validation loss: 2.497279705785807

Epoch: 6| Step: 2
Training loss: 2.861231467010752
Validation loss: 2.5010612460546664

Epoch: 6| Step: 3
Training loss: 2.459155015425538
Validation loss: 2.4992217759987247

Epoch: 6| Step: 4
Training loss: 2.4481299016619555
Validation loss: 2.5038162826268664

Epoch: 6| Step: 5
Training loss: 2.490418861885586
Validation loss: 2.4982261404496775

Epoch: 6| Step: 6
Training loss: 2.3506681953240567
Validation loss: 2.4939034990761906

Epoch: 6| Step: 7
Training loss: 3.0450546695706184
Validation loss: 2.5009778017922057

Epoch: 6| Step: 8
Training loss: 2.715168139061827
Validation loss: 2.501377902188326

Epoch: 6| Step: 9
Training loss: 2.8389195928470534
Validation loss: 2.5003035043227935

Epoch: 6| Step: 10
Training loss: 2.1050654716911303
Validation loss: 2.5004275592129566

Epoch: 6| Step: 11
Training loss: 2.3829381690734137
Validation loss: 2.498546479794466

Epoch: 6| Step: 12
Training loss: 2.493002826932367
Validation loss: 2.495971851824923

Epoch: 6| Step: 13
Training loss: 2.472129922446349
Validation loss: 2.4963858069909763

Epoch: 87| Step: 0
Training loss: 2.309303239215906
Validation loss: 2.491833190286562

Epoch: 6| Step: 1
Training loss: 3.1953924863919054
Validation loss: 2.4942748477500163

Epoch: 6| Step: 2
Training loss: 2.6122418946892396
Validation loss: 2.4985719416782257

Epoch: 6| Step: 3
Training loss: 2.702815043589012
Validation loss: 2.497022094977126

Epoch: 6| Step: 4
Training loss: 2.3721038828547725
Validation loss: 2.5011474519214687

Epoch: 6| Step: 5
Training loss: 2.5245134168069265
Validation loss: 2.5032588222892613

Epoch: 6| Step: 6
Training loss: 2.5605151234861547
Validation loss: 2.5013628582750513

Epoch: 6| Step: 7
Training loss: 2.8417743904823562
Validation loss: 2.497857892700068

Epoch: 6| Step: 8
Training loss: 2.078843989079656
Validation loss: 2.489575331500826

Epoch: 6| Step: 9
Training loss: 3.128932157449703
Validation loss: 2.497573915138122

Epoch: 6| Step: 10
Training loss: 2.524502650464473
Validation loss: 2.4983319360229914

Epoch: 6| Step: 11
Training loss: 2.8536008473541825
Validation loss: 2.495080733359555

Epoch: 6| Step: 12
Training loss: 2.2977976081372846
Validation loss: 2.4950224597763464

Epoch: 6| Step: 13
Training loss: 2.2945054475907085
Validation loss: 2.4977636666378222

Epoch: 88| Step: 0
Training loss: 2.5175243339385336
Validation loss: 2.4996258137734633

Epoch: 6| Step: 1
Training loss: 3.0246724605570674
Validation loss: 2.5008606780210867

Epoch: 6| Step: 2
Training loss: 2.206374781378567
Validation loss: 2.499534515914791

Epoch: 6| Step: 3
Training loss: 2.590132983413233
Validation loss: 2.503879160146822

Epoch: 6| Step: 4
Training loss: 3.13473672348437
Validation loss: 2.5037766858013653

Epoch: 6| Step: 5
Training loss: 2.9274975539017256
Validation loss: 2.499275436307033

Epoch: 6| Step: 6
Training loss: 2.9389354364001625
Validation loss: 2.5007565466246495

Epoch: 6| Step: 7
Training loss: 2.398332922826983
Validation loss: 2.5024180480363105

Epoch: 6| Step: 8
Training loss: 2.6224832731719006
Validation loss: 2.50020652553723

Epoch: 6| Step: 9
Training loss: 2.4598685713293933
Validation loss: 2.502015874643073

Epoch: 6| Step: 10
Training loss: 2.6829392524862987
Validation loss: 2.4970243387834996

Epoch: 6| Step: 11
Training loss: 2.602276128544843
Validation loss: 2.4987794757762822

Epoch: 6| Step: 12
Training loss: 2.0644317596975683
Validation loss: 2.494178972818248

Epoch: 6| Step: 13
Training loss: 2.109744004363215
Validation loss: 2.499195605249648

Epoch: 89| Step: 0
Training loss: 1.7182780224654546
Validation loss: 2.4964031411793655

Epoch: 6| Step: 1
Training loss: 2.7186640583354467
Validation loss: 2.4960649037970315

Epoch: 6| Step: 2
Training loss: 2.56791162105248
Validation loss: 2.4962494373273145

Epoch: 6| Step: 3
Training loss: 2.8118916171418724
Validation loss: 2.4964188357585084

Epoch: 6| Step: 4
Training loss: 2.8574749413006466
Validation loss: 2.493966483118581

Epoch: 6| Step: 5
Training loss: 2.4451560070918448
Validation loss: 2.4909137432417343

Epoch: 6| Step: 6
Training loss: 2.7376862449520325
Validation loss: 2.4889682557965735

Epoch: 6| Step: 7
Training loss: 2.374333840355084
Validation loss: 2.4962042125920956

Epoch: 6| Step: 8
Training loss: 3.0098516512588205
Validation loss: 2.4946123402492786

Epoch: 6| Step: 9
Training loss: 2.6092807044620043
Validation loss: 2.4910612680697075

Epoch: 6| Step: 10
Training loss: 2.213225781209875
Validation loss: 2.4886588344612526

Epoch: 6| Step: 11
Training loss: 2.8059425202543684
Validation loss: 2.4973105746537545

Epoch: 6| Step: 12
Training loss: 3.007028928474844
Validation loss: 2.4976803349381815

Epoch: 6| Step: 13
Training loss: 2.347450285396312
Validation loss: 2.4956112964004546

Epoch: 90| Step: 0
Training loss: 2.7111835642897555
Validation loss: 2.4943479542901654

Epoch: 6| Step: 1
Training loss: 2.7311194521782913
Validation loss: 2.497308983484322

Epoch: 6| Step: 2
Training loss: 2.405110671576112
Validation loss: 2.494706876477937

Epoch: 6| Step: 3
Training loss: 2.326499730090272
Validation loss: 2.4937671370781898

Epoch: 6| Step: 4
Training loss: 2.9000795550779723
Validation loss: 2.496018879722245

Epoch: 6| Step: 5
Training loss: 2.8623889818276926
Validation loss: 2.4957265250438017

Epoch: 6| Step: 6
Training loss: 3.366682470555242
Validation loss: 2.497197233119126

Epoch: 6| Step: 7
Training loss: 2.3075979702569476
Validation loss: 2.494743766138994

Epoch: 6| Step: 8
Training loss: 2.1364520532400104
Validation loss: 2.491198208850028

Epoch: 6| Step: 9
Training loss: 2.8548595023784116
Validation loss: 2.490889399529141

Epoch: 6| Step: 10
Training loss: 2.340569028707188
Validation loss: 2.493584634879875

Epoch: 6| Step: 11
Training loss: 2.683274429180228
Validation loss: 2.494811555043839

Epoch: 6| Step: 12
Training loss: 2.1299762801519666
Validation loss: 2.4907727506010087

Epoch: 6| Step: 13
Training loss: 2.490808661568307
Validation loss: 2.4924337968926884

Epoch: 91| Step: 0
Training loss: 3.0498827051840633
Validation loss: 2.4926376813118294

Epoch: 6| Step: 1
Training loss: 2.6753121737566965
Validation loss: 2.494403854097452

Epoch: 6| Step: 2
Training loss: 2.2947823469885003
Validation loss: 2.4963473338948834

Epoch: 6| Step: 3
Training loss: 1.7787936490373786
Validation loss: 2.492584101292103

Epoch: 6| Step: 4
Training loss: 2.5403780771454687
Validation loss: 2.4916153812127413

Epoch: 6| Step: 5
Training loss: 2.4116289532956814
Validation loss: 2.4895665049815467

Epoch: 6| Step: 6
Training loss: 1.8224432920992304
Validation loss: 2.488728976528924

Epoch: 6| Step: 7
Training loss: 3.128554497042811
Validation loss: 2.488628145687036

Epoch: 6| Step: 8
Training loss: 2.8008971888594973
Validation loss: 2.4905447972114683

Epoch: 6| Step: 9
Training loss: 3.108799866819747
Validation loss: 2.4930741218812997

Epoch: 6| Step: 10
Training loss: 2.1531665150220856
Validation loss: 2.488820327500859

Epoch: 6| Step: 11
Training loss: 2.8393900218904644
Validation loss: 2.489589712435372

Epoch: 6| Step: 12
Training loss: 2.5681758452428105
Validation loss: 2.4927680954635196

Epoch: 6| Step: 13
Training loss: 2.6076066655316796
Validation loss: 2.494993887863878

Epoch: 92| Step: 0
Training loss: 2.67721817528018
Validation loss: 2.4938164612112805

Epoch: 6| Step: 1
Training loss: 2.4897426942606473
Validation loss: 2.4913698965909106

Epoch: 6| Step: 2
Training loss: 2.905099456450274
Validation loss: 2.493774355304945

Epoch: 6| Step: 3
Training loss: 2.359619330077107
Validation loss: 2.4925279534244535

Epoch: 6| Step: 4
Training loss: 2.336615320567559
Validation loss: 2.494076155683425

Epoch: 6| Step: 5
Training loss: 2.8522316343558964
Validation loss: 2.4885785350940015

Epoch: 6| Step: 6
Training loss: 2.874469210513047
Validation loss: 2.490250595139679

Epoch: 6| Step: 7
Training loss: 2.116140634647875
Validation loss: 2.4869726903275184

Epoch: 6| Step: 8
Training loss: 2.0901955566907993
Validation loss: 2.4871520829461984

Epoch: 6| Step: 9
Training loss: 2.556917855988285
Validation loss: 2.4838517235741038

Epoch: 6| Step: 10
Training loss: 3.0441094783490157
Validation loss: 2.487098816128819

Epoch: 6| Step: 11
Training loss: 2.681013396523118
Validation loss: 2.4907876829896995

Epoch: 6| Step: 12
Training loss: 2.6622121879220124
Validation loss: 2.4824643735451715

Epoch: 6| Step: 13
Training loss: 2.42276476851038
Validation loss: 2.4904991178717153

Epoch: 93| Step: 0
Training loss: 2.9585539149042086
Validation loss: 2.4886367200600725

Epoch: 6| Step: 1
Training loss: 2.361941627840624
Validation loss: 2.482768453019655

Epoch: 6| Step: 2
Training loss: 2.6713577572942295
Validation loss: 2.4802626877144816

Epoch: 6| Step: 3
Training loss: 2.1451830820054183
Validation loss: 2.4856136281283545

Epoch: 6| Step: 4
Training loss: 3.004456706514234
Validation loss: 2.4935295134983457

Epoch: 6| Step: 5
Training loss: 2.392078630896485
Validation loss: 2.494811379839927

Epoch: 6| Step: 6
Training loss: 2.322418798170709
Validation loss: 2.4905900130293435

Epoch: 6| Step: 7
Training loss: 2.5973265474506277
Validation loss: 2.4928453428239252

Epoch: 6| Step: 8
Training loss: 2.8781015003748496
Validation loss: 2.4887476653122116

Epoch: 6| Step: 9
Training loss: 2.639408440781162
Validation loss: 2.4858035892502093

Epoch: 6| Step: 10
Training loss: 2.5764372879056734
Validation loss: 2.4864541077041893

Epoch: 6| Step: 11
Training loss: 2.8254426491229063
Validation loss: 2.488669133158634

Epoch: 6| Step: 12
Training loss: 2.6495179979555674
Validation loss: 2.4854819432842494

Epoch: 6| Step: 13
Training loss: 2.0830755710088127
Validation loss: 2.4875220912802236

Epoch: 94| Step: 0
Training loss: 2.659844513270998
Validation loss: 2.492025388031124

Epoch: 6| Step: 1
Training loss: 2.467695759561006
Validation loss: 2.489199147182259

Epoch: 6| Step: 2
Training loss: 2.105608254306928
Validation loss: 2.4913019661875473

Epoch: 6| Step: 3
Training loss: 2.6124450531798344
Validation loss: 2.493634225552815

Epoch: 6| Step: 4
Training loss: 2.510680273205877
Validation loss: 2.4902674055713816

Epoch: 6| Step: 5
Training loss: 2.831279870690419
Validation loss: 2.4834146462852953

Epoch: 6| Step: 6
Training loss: 2.3807106628789354
Validation loss: 2.4851458331324188

Epoch: 6| Step: 7
Training loss: 2.8213409493000428
Validation loss: 2.4861218211288443

Epoch: 6| Step: 8
Training loss: 1.8480424860368183
Validation loss: 2.494774188549216

Epoch: 6| Step: 9
Training loss: 3.332122121736759
Validation loss: 2.4876746092428483

Epoch: 6| Step: 10
Training loss: 2.739922438449578
Validation loss: 2.4832629467976055

Epoch: 6| Step: 11
Training loss: 2.23077422553801
Validation loss: 2.4883931772079757

Epoch: 6| Step: 12
Training loss: 2.3238804162227904
Validation loss: 2.48996875817387

Epoch: 6| Step: 13
Training loss: 2.8856501479082746
Validation loss: 2.4884846762359794

Epoch: 95| Step: 0
Training loss: 2.6521524576636626
Validation loss: 2.49149310444171

Epoch: 6| Step: 1
Training loss: 2.8064109161390833
Validation loss: 2.492370917607218

Epoch: 6| Step: 2
Training loss: 2.515486150665162
Validation loss: 2.49477829793535

Epoch: 6| Step: 3
Training loss: 2.545837659150573
Validation loss: 2.4964133920109965

Epoch: 6| Step: 4
Training loss: 2.503960333610523
Validation loss: 2.502061010214022

Epoch: 6| Step: 5
Training loss: 2.230552337737063
Validation loss: 2.497539437905115

Epoch: 6| Step: 6
Training loss: 2.5961147696659777
Validation loss: 2.4989053554943172

Epoch: 6| Step: 7
Training loss: 2.44738681550985
Validation loss: 2.498901189288792

Epoch: 6| Step: 8
Training loss: 2.6626361149483873
Validation loss: 2.4986062615332036

Epoch: 6| Step: 9
Training loss: 3.104160249093268
Validation loss: 2.4914437741850683

Epoch: 6| Step: 10
Training loss: 2.423903569377577
Validation loss: 2.495698279631194

Epoch: 6| Step: 11
Training loss: 2.6854140592157467
Validation loss: 2.489811720540827

Epoch: 6| Step: 12
Training loss: 2.6907566654186916
Validation loss: 2.4897282663292994

Epoch: 6| Step: 13
Training loss: 2.576481890877752
Validation loss: 2.4896276914297237

Epoch: 96| Step: 0
Training loss: 2.7568826377553566
Validation loss: 2.491977351943999

Epoch: 6| Step: 1
Training loss: 2.4763605173819783
Validation loss: 2.4854991616699342

Epoch: 6| Step: 2
Training loss: 2.5016047095908007
Validation loss: 2.482118841684335

Epoch: 6| Step: 3
Training loss: 2.4427717860804865
Validation loss: 2.4820731673694993

Epoch: 6| Step: 4
Training loss: 2.260581882140485
Validation loss: 2.4838402930429706

Epoch: 6| Step: 5
Training loss: 2.646097505452476
Validation loss: 2.485109280691324

Epoch: 6| Step: 6
Training loss: 2.773843654926997
Validation loss: 2.483363043417491

Epoch: 6| Step: 7
Training loss: 1.971041723071984
Validation loss: 2.4846059024119893

Epoch: 6| Step: 8
Training loss: 2.5774505657853815
Validation loss: 2.483846772216831

Epoch: 6| Step: 9
Training loss: 2.8482854537853326
Validation loss: 2.476990294787958

Epoch: 6| Step: 10
Training loss: 2.7416578688862026
Validation loss: 2.4833826606340343

Epoch: 6| Step: 11
Training loss: 2.6412793313747898
Validation loss: 2.4768758709919076

Epoch: 6| Step: 12
Training loss: 3.1053241048271447
Validation loss: 2.481637962496399

Epoch: 6| Step: 13
Training loss: 2.2709269606394393
Validation loss: 2.4800503115011407

Epoch: 97| Step: 0
Training loss: 2.7892920989945074
Validation loss: 2.4812171988316982

Epoch: 6| Step: 1
Training loss: 2.598112642737379
Validation loss: 2.486585828956064

Epoch: 6| Step: 2
Training loss: 2.5099126750451974
Validation loss: 2.4804626945361616

Epoch: 6| Step: 3
Training loss: 2.6206492744993715
Validation loss: 2.486527252414074

Epoch: 6| Step: 4
Training loss: 2.3864963758797964
Validation loss: 2.4856240833214596

Epoch: 6| Step: 5
Training loss: 2.8365864497257225
Validation loss: 2.4893429904839643

Epoch: 6| Step: 6
Training loss: 2.391452222330493
Validation loss: 2.4861507826989855

Epoch: 6| Step: 7
Training loss: 2.2198686600401314
Validation loss: 2.486624237351395

Epoch: 6| Step: 8
Training loss: 2.568435865068223
Validation loss: 2.488751297673708

Epoch: 6| Step: 9
Training loss: 2.8947014185914597
Validation loss: 2.4852301767181135

Epoch: 6| Step: 10
Training loss: 2.378648565457983
Validation loss: 2.487490302215535

Epoch: 6| Step: 11
Training loss: 2.934580874305037
Validation loss: 2.489586687817302

Epoch: 6| Step: 12
Training loss: 2.4653102233852997
Validation loss: 2.4803223253821063

Epoch: 6| Step: 13
Training loss: 2.352219397971075
Validation loss: 2.4843502923148693

Epoch: 98| Step: 0
Training loss: 2.6683226053314932
Validation loss: 2.4814098425177544

Epoch: 6| Step: 1
Training loss: 1.860939137340373
Validation loss: 2.4768701276042204

Epoch: 6| Step: 2
Training loss: 2.756610035466438
Validation loss: 2.4795271240112866

Epoch: 6| Step: 3
Training loss: 2.650558297708387
Validation loss: 2.4810596793440163

Epoch: 6| Step: 4
Training loss: 1.9455737815558523
Validation loss: 2.4741573588306585

Epoch: 6| Step: 5
Training loss: 2.8069139744344658
Validation loss: 2.4787370859881537

Epoch: 6| Step: 6
Training loss: 2.5228711133309965
Validation loss: 2.482660449689476

Epoch: 6| Step: 7
Training loss: 2.71037414149928
Validation loss: 2.4804906488688427

Epoch: 6| Step: 8
Training loss: 2.5549627966514405
Validation loss: 2.4721438905067137

Epoch: 6| Step: 9
Training loss: 2.8184192674899164
Validation loss: 2.4721232036043905

Epoch: 6| Step: 10
Training loss: 2.6626835719479116
Validation loss: 2.4743917600856293

Epoch: 6| Step: 11
Training loss: 2.79611408815664
Validation loss: 2.4780955979542023

Epoch: 6| Step: 12
Training loss: 2.501030137494794
Validation loss: 2.48155488992429

Epoch: 6| Step: 13
Training loss: 2.5407131053104153
Validation loss: 2.4838770081380446

Epoch: 99| Step: 0
Training loss: 2.3792465793352147
Validation loss: 2.4850019227755378

Epoch: 6| Step: 1
Training loss: 2.218366885353053
Validation loss: 2.486864326315452

Epoch: 6| Step: 2
Training loss: 2.8100299585177617
Validation loss: 2.487497906068978

Epoch: 6| Step: 3
Training loss: 2.5132471065081488
Validation loss: 2.488460165046177

Epoch: 6| Step: 4
Training loss: 2.7354505766843804
Validation loss: 2.4858597611205284

Epoch: 6| Step: 5
Training loss: 2.7484879238063917
Validation loss: 2.485639350382243

Epoch: 6| Step: 6
Training loss: 2.443383574270652
Validation loss: 2.482609487387629

Epoch: 6| Step: 7
Training loss: 3.148925894821385
Validation loss: 2.483286069147128

Epoch: 6| Step: 8
Training loss: 2.435810873228449
Validation loss: 2.478741734949883

Epoch: 6| Step: 9
Training loss: 2.6086439376349113
Validation loss: 2.4762768345007395

Epoch: 6| Step: 10
Training loss: 2.120627898313485
Validation loss: 2.4747932765182714

Epoch: 6| Step: 11
Training loss: 2.317607085913247
Validation loss: 2.484033045237185

Epoch: 6| Step: 12
Training loss: 2.7771114461457906
Validation loss: 2.4768150032394862

Epoch: 6| Step: 13
Training loss: 2.7677322377091578
Validation loss: 2.4762889979791645

Epoch: 100| Step: 0
Training loss: 2.984247174945781
Validation loss: 2.4797093307729594

Epoch: 6| Step: 1
Training loss: 2.8291276871959994
Validation loss: 2.483379044421428

Epoch: 6| Step: 2
Training loss: 2.9702416136107677
Validation loss: 2.4871005176809664

Epoch: 6| Step: 3
Training loss: 1.881142790011203
Validation loss: 2.4890450623263245

Epoch: 6| Step: 4
Training loss: 2.2338300987530846
Validation loss: 2.494905669621244

Epoch: 6| Step: 5
Training loss: 2.7834565057359404
Validation loss: 2.494280774095446

Epoch: 6| Step: 6
Training loss: 2.1931101113023557
Validation loss: 2.4937328701339214

Epoch: 6| Step: 7
Training loss: 2.2879365098053728
Validation loss: 2.4903119722131932

Epoch: 6| Step: 8
Training loss: 2.476369663757487
Validation loss: 2.4975000597725

Epoch: 6| Step: 9
Training loss: 2.451364650972714
Validation loss: 2.4874384963516833

Epoch: 6| Step: 10
Training loss: 2.8002228546012025
Validation loss: 2.4907248578700325

Epoch: 6| Step: 11
Training loss: 2.6209301961476603
Validation loss: 2.4901846208775553

Epoch: 6| Step: 12
Training loss: 2.741044808991174
Validation loss: 2.487330488119319

Epoch: 6| Step: 13
Training loss: 2.7682710048113246
Validation loss: 2.4864966172359533

Epoch: 101| Step: 0
Training loss: 2.5808159858170683
Validation loss: 2.4858099034537626

Epoch: 6| Step: 1
Training loss: 2.854002360791391
Validation loss: 2.4786274801815766

Epoch: 6| Step: 2
Training loss: 2.326795979525165
Validation loss: 2.4791672944353946

Epoch: 6| Step: 3
Training loss: 2.2103923219807684
Validation loss: 2.4783408020905773

Epoch: 6| Step: 4
Training loss: 2.529050648608592
Validation loss: 2.473964897280903

Epoch: 6| Step: 5
Training loss: 2.7818374013491813
Validation loss: 2.477571861361738

Epoch: 6| Step: 6
Training loss: 2.3172659348160045
Validation loss: 2.4769524749592975

Epoch: 6| Step: 7
Training loss: 2.80002506108649
Validation loss: 2.475143314797596

Epoch: 6| Step: 8
Training loss: 2.0162405803954666
Validation loss: 2.4739838260876454

Epoch: 6| Step: 9
Training loss: 2.704539375502338
Validation loss: 2.4696990816440976

Epoch: 6| Step: 10
Training loss: 3.161769158272798
Validation loss: 2.4752247965157914

Epoch: 6| Step: 11
Training loss: 2.846221520537312
Validation loss: 2.4698971686534503

Epoch: 6| Step: 12
Training loss: 2.1391478405153634
Validation loss: 2.480679616700881

Epoch: 6| Step: 13
Training loss: 2.5580056948863112
Validation loss: 2.486837945626743

Epoch: 102| Step: 0
Training loss: 1.710011270720164
Validation loss: 2.486133824557849

Epoch: 6| Step: 1
Training loss: 1.9947296079804544
Validation loss: 2.483161069881824

Epoch: 6| Step: 2
Training loss: 2.795623072882162
Validation loss: 2.4830848654886424

Epoch: 6| Step: 3
Training loss: 2.4207055006127907
Validation loss: 2.4808315222078665

Epoch: 6| Step: 4
Training loss: 1.7615323190098267
Validation loss: 2.481899155417797

Epoch: 6| Step: 5
Training loss: 2.664921060076491
Validation loss: 2.4869654683373295

Epoch: 6| Step: 6
Training loss: 3.2363419748308053
Validation loss: 2.4877033610579495

Epoch: 6| Step: 7
Training loss: 3.0125789774438965
Validation loss: 2.492686350292848

Epoch: 6| Step: 8
Training loss: 2.772311129659474
Validation loss: 2.4924135653687056

Epoch: 6| Step: 9
Training loss: 2.403865673279374
Validation loss: 2.49159919387997

Epoch: 6| Step: 10
Training loss: 2.906670980829426
Validation loss: 2.490837409113024

Epoch: 6| Step: 11
Training loss: 3.066541224139291
Validation loss: 2.4958940007176587

Epoch: 6| Step: 12
Training loss: 2.9218975209066906
Validation loss: 2.493940655551629

Epoch: 6| Step: 13
Training loss: 2.2057533548072987
Validation loss: 2.488178564455069

Epoch: 103| Step: 0
Training loss: 2.5077441434962022
Validation loss: 2.48659916449486

Epoch: 6| Step: 1
Training loss: 2.4020800438026035
Validation loss: 2.4839748324195785

Epoch: 6| Step: 2
Training loss: 2.9332044320250286
Validation loss: 2.4838622901694607

Epoch: 6| Step: 3
Training loss: 2.6016049310013423
Validation loss: 2.4803251450187345

Epoch: 6| Step: 4
Training loss: 2.5032087714456384
Validation loss: 2.4788500051993414

Epoch: 6| Step: 5
Training loss: 2.0821436982268824
Validation loss: 2.475280839226098

Epoch: 6| Step: 6
Training loss: 3.087310099456729
Validation loss: 2.4730437880517724

Epoch: 6| Step: 7
Training loss: 2.6050796332607344
Validation loss: 2.4753540251461468

Epoch: 6| Step: 8
Training loss: 2.762568794878337
Validation loss: 2.472249837844951

Epoch: 6| Step: 9
Training loss: 2.400114883216368
Validation loss: 2.474731811609716

Epoch: 6| Step: 10
Training loss: 2.628264894515659
Validation loss: 2.479629638996757

Epoch: 6| Step: 11
Training loss: 2.782377893008416
Validation loss: 2.4784564969881084

Epoch: 6| Step: 12
Training loss: 2.197502591388724
Validation loss: 2.478179243471429

Epoch: 6| Step: 13
Training loss: 2.592553195830641
Validation loss: 2.482042461206245

Epoch: 104| Step: 0
Training loss: 2.748274174923557
Validation loss: 2.4758551356552854

Epoch: 6| Step: 1
Training loss: 2.935495869795581
Validation loss: 2.478737142096364

Epoch: 6| Step: 2
Training loss: 3.0262373545278867
Validation loss: 2.485774655606008

Epoch: 6| Step: 3
Training loss: 2.268604082611723
Validation loss: 2.478322908661327

Epoch: 6| Step: 4
Training loss: 2.4562420328025607
Validation loss: 2.4735393263034315

Epoch: 6| Step: 5
Training loss: 2.5866544254085424
Validation loss: 2.472821640421343

Epoch: 6| Step: 6
Training loss: 2.4136421306732565
Validation loss: 2.46888835535388

Epoch: 6| Step: 7
Training loss: 2.477879989076326
Validation loss: 2.4713005218203996

Epoch: 6| Step: 8
Training loss: 2.0850258881862205
Validation loss: 2.476657596852196

Epoch: 6| Step: 9
Training loss: 2.3536476193211846
Validation loss: 2.480015790937767

Epoch: 6| Step: 10
Training loss: 2.667107505917247
Validation loss: 2.476180070136461

Epoch: 6| Step: 11
Training loss: 2.351133998217814
Validation loss: 2.4727083334276108

Epoch: 6| Step: 12
Training loss: 2.700906449501037
Validation loss: 2.4869605151903404

Epoch: 6| Step: 13
Training loss: 2.624668100355534
Validation loss: 2.4839238011000715

Epoch: 105| Step: 0
Training loss: 2.7302001471738166
Validation loss: 2.4801065495890398

Epoch: 6| Step: 1
Training loss: 2.399153015567818
Validation loss: 2.480924645527651

Epoch: 6| Step: 2
Training loss: 2.8684692843852146
Validation loss: 2.480623135305306

Epoch: 6| Step: 3
Training loss: 2.244294031011052
Validation loss: 2.481775022958833

Epoch: 6| Step: 4
Training loss: 2.754616070977284
Validation loss: 2.4770333276764527

Epoch: 6| Step: 5
Training loss: 2.2857655813217432
Validation loss: 2.48233084082791

Epoch: 6| Step: 6
Training loss: 2.980278039032836
Validation loss: 2.479985195495143

Epoch: 6| Step: 7
Training loss: 2.5630839543101276
Validation loss: 2.473012503802523

Epoch: 6| Step: 8
Training loss: 2.713459084414082
Validation loss: 2.4729502394169365

Epoch: 6| Step: 9
Training loss: 2.2913700489783357
Validation loss: 2.471961704795975

Epoch: 6| Step: 10
Training loss: 1.9949396010508238
Validation loss: 2.471230496098206

Epoch: 6| Step: 11
Training loss: 2.2947446324507705
Validation loss: 2.4679927066816805

Epoch: 6| Step: 12
Training loss: 2.662897744714151
Validation loss: 2.4637220342201465

Epoch: 6| Step: 13
Training loss: 2.889605698135689
Validation loss: 2.469968084831845

Epoch: 106| Step: 0
Training loss: 2.5035341078513
Validation loss: 2.461673493303748

Epoch: 6| Step: 1
Training loss: 2.7260841452807134
Validation loss: 2.4685871054430772

Epoch: 6| Step: 2
Training loss: 2.219422144559642
Validation loss: 2.465121810229879

Epoch: 6| Step: 3
Training loss: 2.998620351808849
Validation loss: 2.469534753259726

Epoch: 6| Step: 4
Training loss: 2.4047460438602295
Validation loss: 2.4720132563234536

Epoch: 6| Step: 5
Training loss: 2.7448810270892903
Validation loss: 2.4733244448585205

Epoch: 6| Step: 6
Training loss: 3.1415838040083255
Validation loss: 2.4750149100268763

Epoch: 6| Step: 7
Training loss: 2.2327736404699956
Validation loss: 2.4748647909769024

Epoch: 6| Step: 8
Training loss: 2.3992249628183457
Validation loss: 2.4739102542956983

Epoch: 6| Step: 9
Training loss: 2.339435013111608
Validation loss: 2.4747473064340766

Epoch: 6| Step: 10
Training loss: 1.9808918578099226
Validation loss: 2.476267655688547

Epoch: 6| Step: 11
Training loss: 2.3883274981082923
Validation loss: 2.4674895243630086

Epoch: 6| Step: 12
Training loss: 2.7169943216016708
Validation loss: 2.4718299678360927

Epoch: 6| Step: 13
Training loss: 2.7170307379631127
Validation loss: 2.4670170524398514

Epoch: 107| Step: 0
Training loss: 2.4026642872413655
Validation loss: 2.4774982196918227

Epoch: 6| Step: 1
Training loss: 1.5969284377143091
Validation loss: 2.468260237645863

Epoch: 6| Step: 2
Training loss: 2.2479396499528903
Validation loss: 2.4708148031413697

Epoch: 6| Step: 3
Training loss: 2.582679009377378
Validation loss: 2.4675030194708203

Epoch: 6| Step: 4
Training loss: 2.8097811803091504
Validation loss: 2.469564906961681

Epoch: 6| Step: 5
Training loss: 2.7760575933995564
Validation loss: 2.466157348562961

Epoch: 6| Step: 6
Training loss: 2.3328810889348524
Validation loss: 2.4739512928645024

Epoch: 6| Step: 7
Training loss: 2.371592436232193
Validation loss: 2.478170729123424

Epoch: 6| Step: 8
Training loss: 3.7821757546855297
Validation loss: 2.4750412963221975

Epoch: 6| Step: 9
Training loss: 2.2376354410959207
Validation loss: 2.4752645852048643

Epoch: 6| Step: 10
Training loss: 2.556299849865879
Validation loss: 2.4839719209430298

Epoch: 6| Step: 11
Training loss: 2.557933739717405
Validation loss: 2.482382064968332

Epoch: 6| Step: 12
Training loss: 2.339870650147958
Validation loss: 2.4833980054776217

Epoch: 6| Step: 13
Training loss: 2.6188138093662636
Validation loss: 2.48230554851877

Epoch: 108| Step: 0
Training loss: 2.2857907188783173
Validation loss: 2.4752067922649386

Epoch: 6| Step: 1
Training loss: 2.3519881867546752
Validation loss: 2.475706126890102

Epoch: 6| Step: 2
Training loss: 2.2384446435644207
Validation loss: 2.475751549512621

Epoch: 6| Step: 3
Training loss: 2.7128630294110345
Validation loss: 2.475631522838022

Epoch: 6| Step: 4
Training loss: 2.2346236083966384
Validation loss: 2.4698960746492697

Epoch: 6| Step: 5
Training loss: 2.190608839990323
Validation loss: 2.4693526647032833

Epoch: 6| Step: 6
Training loss: 2.2616045829143583
Validation loss: 2.46193468992375

Epoch: 6| Step: 7
Training loss: 3.18531395243639
Validation loss: 2.468044421613867

Epoch: 6| Step: 8
Training loss: 3.020739078147444
Validation loss: 2.4719229480129608

Epoch: 6| Step: 9
Training loss: 2.455955573143007
Validation loss: 2.4698627233774983

Epoch: 6| Step: 10
Training loss: 2.2810848646619966
Validation loss: 2.464562482146421

Epoch: 6| Step: 11
Training loss: 2.3895174340559793
Validation loss: 2.466438386208512

Epoch: 6| Step: 12
Training loss: 2.5921418133665117
Validation loss: 2.4704641998122363

Epoch: 6| Step: 13
Training loss: 3.1287596402722726
Validation loss: 2.4758662098392645

Epoch: 109| Step: 0
Training loss: 2.3741926527581727
Validation loss: 2.4706896634545576

Epoch: 6| Step: 1
Training loss: 2.9042843970394356
Validation loss: 2.47133837990631

Epoch: 6| Step: 2
Training loss: 2.8380529327080106
Validation loss: 2.4764199521730297

Epoch: 6| Step: 3
Training loss: 2.030906296041445
Validation loss: 2.467192258985269

Epoch: 6| Step: 4
Training loss: 3.12637558225352
Validation loss: 2.468160784299275

Epoch: 6| Step: 5
Training loss: 2.449084702615391
Validation loss: 2.467797606691638

Epoch: 6| Step: 6
Training loss: 1.458943439200441
Validation loss: 2.4691635461487773

Epoch: 6| Step: 7
Training loss: 2.7679583517811146
Validation loss: 2.472112369835117

Epoch: 6| Step: 8
Training loss: 2.3776844313333263
Validation loss: 2.4767637120928097

Epoch: 6| Step: 9
Training loss: 2.4083155894258303
Validation loss: 2.477049201129149

Epoch: 6| Step: 10
Training loss: 2.605581850173604
Validation loss: 2.4789542473154698

Epoch: 6| Step: 11
Training loss: 2.7532409297163642
Validation loss: 2.474826111769901

Epoch: 6| Step: 12
Training loss: 2.3235449062577818
Validation loss: 2.4814868509678396

Epoch: 6| Step: 13
Training loss: 2.755056760449029
Validation loss: 2.482320707927404

Epoch: 110| Step: 0
Training loss: 2.3424187503431635
Validation loss: 2.4838482440268086

Epoch: 6| Step: 1
Training loss: 2.8312694287844
Validation loss: 2.4834035657598976

Epoch: 6| Step: 2
Training loss: 2.7153595578452125
Validation loss: 2.486841349086861

Epoch: 6| Step: 3
Training loss: 2.734407522825559
Validation loss: 2.482789339310027

Epoch: 6| Step: 4
Training loss: 2.2405832113840876
Validation loss: 2.479856424521004

Epoch: 6| Step: 5
Training loss: 2.1119123104126647
Validation loss: 2.4837734365805395

Epoch: 6| Step: 6
Training loss: 2.4982115070176034
Validation loss: 2.4730953170232883

Epoch: 6| Step: 7
Training loss: 2.0493442696201156
Validation loss: 2.470167775009494

Epoch: 6| Step: 8
Training loss: 2.5931695495441685
Validation loss: 2.470333251608595

Epoch: 6| Step: 9
Training loss: 2.3557893904896825
Validation loss: 2.464603579629613

Epoch: 6| Step: 10
Training loss: 2.5154124104963684
Validation loss: 2.4660811665860534

Epoch: 6| Step: 11
Training loss: 2.7426522668037965
Validation loss: 2.470304088509845

Epoch: 6| Step: 12
Training loss: 3.192193558696985
Validation loss: 2.4605746773788577

Epoch: 6| Step: 13
Training loss: 2.497913443526436
Validation loss: 2.462465609069891

Epoch: 111| Step: 0
Training loss: 2.0600929085603483
Validation loss: 2.463989488628289

Epoch: 6| Step: 1
Training loss: 2.2628358707556577
Validation loss: 2.4695631772368647

Epoch: 6| Step: 2
Training loss: 2.8397891788407867
Validation loss: 2.459215350787869

Epoch: 6| Step: 3
Training loss: 2.5753206664480017
Validation loss: 2.4674750951446085

Epoch: 6| Step: 4
Training loss: 2.908200501593847
Validation loss: 2.4660143604030598

Epoch: 6| Step: 5
Training loss: 2.8261244637414866
Validation loss: 2.475511281670372

Epoch: 6| Step: 6
Training loss: 2.7787109958452674
Validation loss: 2.478637828574842

Epoch: 6| Step: 7
Training loss: 2.579954203561444
Validation loss: 2.4752977192151717

Epoch: 6| Step: 8
Training loss: 3.147222166032408
Validation loss: 2.475347323081815

Epoch: 6| Step: 9
Training loss: 2.7313328850432086
Validation loss: 2.4781663196096635

Epoch: 6| Step: 10
Training loss: 1.681028318857618
Validation loss: 2.4769214967606277

Epoch: 6| Step: 11
Training loss: 2.047870073794196
Validation loss: 2.4775737057836102

Epoch: 6| Step: 12
Training loss: 2.256910097561833
Validation loss: 2.4703947937858652

Epoch: 6| Step: 13
Training loss: 2.6118557952518033
Validation loss: 2.4663963526310795

Epoch: 112| Step: 0
Training loss: 2.3930388586999682
Validation loss: 2.4666705004773974

Epoch: 6| Step: 1
Training loss: 1.58342336934065
Validation loss: 2.4675665163442737

Epoch: 6| Step: 2
Training loss: 2.5613830737371646
Validation loss: 2.462212997984258

Epoch: 6| Step: 3
Training loss: 2.6191430827903734
Validation loss: 2.469254776095745

Epoch: 6| Step: 4
Training loss: 2.2374717753244475
Validation loss: 2.4607344770700545

Epoch: 6| Step: 5
Training loss: 2.3930251097136894
Validation loss: 2.4706801904712057

Epoch: 6| Step: 6
Training loss: 2.8773107779004463
Validation loss: 2.466002758566001

Epoch: 6| Step: 7
Training loss: 2.2685275722792984
Validation loss: 2.4760481243078756

Epoch: 6| Step: 8
Training loss: 2.69202042923044
Validation loss: 2.4662566490747526

Epoch: 6| Step: 9
Training loss: 3.072276489471413
Validation loss: 2.4659223176611835

Epoch: 6| Step: 10
Training loss: 2.5392439087838525
Validation loss: 2.469070791978861

Epoch: 6| Step: 11
Training loss: 2.776508361254247
Validation loss: 2.473818810527386

Epoch: 6| Step: 12
Training loss: 3.226083493641598
Validation loss: 2.478001823105961

Epoch: 6| Step: 13
Training loss: 2.109635400593548
Validation loss: 2.4775090700067555

Epoch: 113| Step: 0
Training loss: 2.871595772170512
Validation loss: 2.476992420381549

Epoch: 6| Step: 1
Training loss: 2.618403274780473
Validation loss: 2.4817939082084015

Epoch: 6| Step: 2
Training loss: 2.62565177818469
Validation loss: 2.4821612333563006

Epoch: 6| Step: 3
Training loss: 2.4764238673737657
Validation loss: 2.4786890889563176

Epoch: 6| Step: 4
Training loss: 2.8023664385831863
Validation loss: 2.4744254276963007

Epoch: 6| Step: 5
Training loss: 2.4535951589038456
Validation loss: 2.4806610753748943

Epoch: 6| Step: 6
Training loss: 2.806715718049878
Validation loss: 2.4747175049033605

Epoch: 6| Step: 7
Training loss: 2.5019670377369807
Validation loss: 2.4773048708200798

Epoch: 6| Step: 8
Training loss: 2.61645169519076
Validation loss: 2.4746113340334426

Epoch: 6| Step: 9
Training loss: 2.5516350384858932
Validation loss: 2.46877974480202

Epoch: 6| Step: 10
Training loss: 2.161087249399668
Validation loss: 2.466401363187115

Epoch: 6| Step: 11
Training loss: 2.456981082276738
Validation loss: 2.467259629177473

Epoch: 6| Step: 12
Training loss: 1.9461127171152999
Validation loss: 2.4708346164779376

Epoch: 6| Step: 13
Training loss: 2.8615884187280045
Validation loss: 2.4608120840903225

Epoch: 114| Step: 0
Training loss: 2.386154982292186
Validation loss: 2.4641353760083837

Epoch: 6| Step: 1
Training loss: 2.10388089747971
Validation loss: 2.4636736640220054

Epoch: 6| Step: 2
Training loss: 2.2025702028203438
Validation loss: 2.462911825066122

Epoch: 6| Step: 3
Training loss: 2.3564829501242044
Validation loss: 2.467468661554072

Epoch: 6| Step: 4
Training loss: 2.824971838616635
Validation loss: 2.4669186523533972

Epoch: 6| Step: 5
Training loss: 2.329747703383282
Validation loss: 2.46588546415063

Epoch: 6| Step: 6
Training loss: 2.8489253979626668
Validation loss: 2.455629823414088

Epoch: 6| Step: 7
Training loss: 2.270815041377971
Validation loss: 2.459145788864436

Epoch: 6| Step: 8
Training loss: 2.662747145093505
Validation loss: 2.4627448817064295

Epoch: 6| Step: 9
Training loss: 2.942454927499521
Validation loss: 2.465914695620443

Epoch: 6| Step: 10
Training loss: 2.592742356510977
Validation loss: 2.4659773551863386

Epoch: 6| Step: 11
Training loss: 2.71274737095901
Validation loss: 2.473836672284393

Epoch: 6| Step: 12
Training loss: 2.37752799963283
Validation loss: 2.4717519993969925

Epoch: 6| Step: 13
Training loss: 2.854791688818617
Validation loss: 2.4695367324094044

Epoch: 115| Step: 0
Training loss: 2.4577676370046304
Validation loss: 2.470769691827036

Epoch: 6| Step: 1
Training loss: 2.7381447228803486
Validation loss: 2.466122238760643

Epoch: 6| Step: 2
Training loss: 2.873666536994981
Validation loss: 2.4640825227654837

Epoch: 6| Step: 3
Training loss: 2.243848019639855
Validation loss: 2.4630559774499567

Epoch: 6| Step: 4
Training loss: 2.4252032637206575
Validation loss: 2.455524850047303

Epoch: 6| Step: 5
Training loss: 2.743647955385016
Validation loss: 2.4539024918948558

Epoch: 6| Step: 6
Training loss: 2.632451516598863
Validation loss: 2.451796348024003

Epoch: 6| Step: 7
Training loss: 2.1895367540897244
Validation loss: 2.462299692491744

Epoch: 6| Step: 8
Training loss: 2.0020884100630982
Validation loss: 2.469129927489862

Epoch: 6| Step: 9
Training loss: 2.0534181336235786
Validation loss: 2.461613323117533

Epoch: 6| Step: 10
Training loss: 2.8260276140725322
Validation loss: 2.4551509582349857

Epoch: 6| Step: 11
Training loss: 3.1079444853391758
Validation loss: 2.4512319691701814

Epoch: 6| Step: 12
Training loss: 2.2818053105290756
Validation loss: 2.4683793348996574

Epoch: 6| Step: 13
Training loss: 2.799473753931298
Validation loss: 2.4705052393296882

Epoch: 116| Step: 0
Training loss: 3.005202233337523
Validation loss: 2.467840324877151

Epoch: 6| Step: 1
Training loss: 2.3583098779956497
Validation loss: 2.4722506656034415

Epoch: 6| Step: 2
Training loss: 2.5616656550064354
Validation loss: 2.4651554835496587

Epoch: 6| Step: 3
Training loss: 2.132626927166032
Validation loss: 2.470493248430065

Epoch: 6| Step: 4
Training loss: 1.678690982897508
Validation loss: 2.4687334856857164

Epoch: 6| Step: 5
Training loss: 2.987938635638998
Validation loss: 2.470277579227822

Epoch: 6| Step: 6
Training loss: 2.5592293685077006
Validation loss: 2.469302715124392

Epoch: 6| Step: 7
Training loss: 2.5186474573356357
Validation loss: 2.4693736805578808

Epoch: 6| Step: 8
Training loss: 2.687585873673461
Validation loss: 2.46987832919025

Epoch: 6| Step: 9
Training loss: 1.9564851467193651
Validation loss: 2.463719252032089

Epoch: 6| Step: 10
Training loss: 2.709381272463814
Validation loss: 2.4534990952778184

Epoch: 6| Step: 11
Training loss: 3.0550989522688616
Validation loss: 2.4571948459422774

Epoch: 6| Step: 12
Training loss: 2.4822255558927653
Validation loss: 2.461642387397819

Epoch: 6| Step: 13
Training loss: 2.3542327421474747
Validation loss: 2.4574247125041158

Epoch: 117| Step: 0
Training loss: 2.908131636335916
Validation loss: 2.4561963060122274

Epoch: 6| Step: 1
Training loss: 2.1789199407399753
Validation loss: 2.4554651441394895

Epoch: 6| Step: 2
Training loss: 3.0518746852620695
Validation loss: 2.4560726299098183

Epoch: 6| Step: 3
Training loss: 2.371829476503906
Validation loss: 2.4573476614938845

Epoch: 6| Step: 4
Training loss: 2.3721422771092633
Validation loss: 2.4581864415480625

Epoch: 6| Step: 5
Training loss: 2.33741942894124
Validation loss: 2.456630591235903

Epoch: 6| Step: 6
Training loss: 2.867877596510935
Validation loss: 2.456460309266566

Epoch: 6| Step: 7
Training loss: 2.8910452872245367
Validation loss: 2.4628054598816695

Epoch: 6| Step: 8
Training loss: 2.4729752899737103
Validation loss: 2.467398720337223

Epoch: 6| Step: 9
Training loss: 2.365479107771142
Validation loss: 2.465681720527646

Epoch: 6| Step: 10
Training loss: 2.400850455282538
Validation loss: 2.468179500026733

Epoch: 6| Step: 11
Training loss: 2.4112818236596842
Validation loss: 2.4687115791002996

Epoch: 6| Step: 12
Training loss: 1.7618109093220813
Validation loss: 2.474168119403348

Epoch: 6| Step: 13
Training loss: 2.736012867445553
Validation loss: 2.4638729773256967

Epoch: 118| Step: 0
Training loss: 2.2166761995650743
Validation loss: 2.4643390297963403

Epoch: 6| Step: 1
Training loss: 2.7407961192803376
Validation loss: 2.4654445490298134

Epoch: 6| Step: 2
Training loss: 2.478967503687448
Validation loss: 2.4702081196991243

Epoch: 6| Step: 3
Training loss: 2.8105218500503772
Validation loss: 2.472804671217736

Epoch: 6| Step: 4
Training loss: 2.24917439042365
Validation loss: 2.4648307239734386

Epoch: 6| Step: 5
Training loss: 2.451429035937468
Validation loss: 2.4660199437676895

Epoch: 6| Step: 6
Training loss: 1.9883343702613618
Validation loss: 2.4609112289076007

Epoch: 6| Step: 7
Training loss: 2.273221454645445
Validation loss: 2.4632884588356894

Epoch: 6| Step: 8
Training loss: 2.967263582448416
Validation loss: 2.4613481290030905

Epoch: 6| Step: 9
Training loss: 2.5650209261689407
Validation loss: 2.4670471724871117

Epoch: 6| Step: 10
Training loss: 2.6081679059139296
Validation loss: 2.470697576343201

Epoch: 6| Step: 11
Training loss: 2.9482012679857417
Validation loss: 2.4761137771430426

Epoch: 6| Step: 12
Training loss: 2.646212112667284
Validation loss: 2.4756343959702916

Epoch: 6| Step: 13
Training loss: 2.390094573571865
Validation loss: 2.4725721926510857

Epoch: 119| Step: 0
Training loss: 2.039272955195311
Validation loss: 2.475435507954726

Epoch: 6| Step: 1
Training loss: 3.008795560231137
Validation loss: 2.473027101561295

Epoch: 6| Step: 2
Training loss: 2.486239711151391
Validation loss: 2.4700468978599504

Epoch: 6| Step: 3
Training loss: 2.5649895088918195
Validation loss: 2.468556006169374

Epoch: 6| Step: 4
Training loss: 2.388119450442653
Validation loss: 2.459079973878875

Epoch: 6| Step: 5
Training loss: 2.3765623073841144
Validation loss: 2.4597943269612865

Epoch: 6| Step: 6
Training loss: 2.937594148466312
Validation loss: 2.463820287797621

Epoch: 6| Step: 7
Training loss: 3.271957754930346
Validation loss: 2.4634862386800322

Epoch: 6| Step: 8
Training loss: 2.571815862705773
Validation loss: 2.4608420863148206

Epoch: 6| Step: 9
Training loss: 2.6652050980021227
Validation loss: 2.4599187286257003

Epoch: 6| Step: 10
Training loss: 2.514812361920413
Validation loss: 2.4574607227145036

Epoch: 6| Step: 11
Training loss: 1.8298804177366188
Validation loss: 2.4551228529548776

Epoch: 6| Step: 12
Training loss: 2.5807457752379817
Validation loss: 2.4624496335399115

Epoch: 6| Step: 13
Training loss: 2.18203117132955
Validation loss: 2.4701786092641886

Epoch: 120| Step: 0
Training loss: 2.2561057216343303
Validation loss: 2.476132777785446

Epoch: 6| Step: 1
Training loss: 2.6033523405344243
Validation loss: 2.4759702886987562

Epoch: 6| Step: 2
Training loss: 2.572441448438769
Validation loss: 2.4838951495141064

Epoch: 6| Step: 3
Training loss: 2.1806450384722122
Validation loss: 2.483832310037616

Epoch: 6| Step: 4
Training loss: 2.344453222952383
Validation loss: 2.4755049652761745

Epoch: 6| Step: 5
Training loss: 2.191708467420918
Validation loss: 2.48101196748778

Epoch: 6| Step: 6
Training loss: 2.9994356896217593
Validation loss: 2.4721101998607864

Epoch: 6| Step: 7
Training loss: 2.149897630605355
Validation loss: 2.4748999854793348

Epoch: 6| Step: 8
Training loss: 2.3808284316270054
Validation loss: 2.469228496938215

Epoch: 6| Step: 9
Training loss: 3.0305074195135315
Validation loss: 2.473854566037548

Epoch: 6| Step: 10
Training loss: 2.8952008295319955
Validation loss: 2.473852092402541

Epoch: 6| Step: 11
Training loss: 2.7492023524982097
Validation loss: 2.4700219945661916

Epoch: 6| Step: 12
Training loss: 2.56000359981999
Validation loss: 2.471139998379572

Epoch: 6| Step: 13
Training loss: 2.4007594893686157
Validation loss: 2.479040452538618

Epoch: 121| Step: 0
Training loss: 2.9635005114512922
Validation loss: 2.480076788423608

Epoch: 6| Step: 1
Training loss: 2.7664098111000186
Validation loss: 2.4748224429137715

Epoch: 6| Step: 2
Training loss: 2.1727622435995877
Validation loss: 2.468275756997253

Epoch: 6| Step: 3
Training loss: 2.522427288780602
Validation loss: 2.472040197074421

Epoch: 6| Step: 4
Training loss: 2.6820594366088693
Validation loss: 2.462236221179385

Epoch: 6| Step: 5
Training loss: 1.65219238165085
Validation loss: 2.4674046548692745

Epoch: 6| Step: 6
Training loss: 2.6641179859278634
Validation loss: 2.465127838900158

Epoch: 6| Step: 7
Training loss: 2.509356917414709
Validation loss: 2.465367780902084

Epoch: 6| Step: 8
Training loss: 3.1378538137390155
Validation loss: 2.4602572676673358

Epoch: 6| Step: 9
Training loss: 2.0011674334752096
Validation loss: 2.4627920761781414

Epoch: 6| Step: 10
Training loss: 2.7623380104314736
Validation loss: 2.4666331426387202

Epoch: 6| Step: 11
Training loss: 2.169050836722735
Validation loss: 2.466948918569754

Epoch: 6| Step: 12
Training loss: 2.377112001674692
Validation loss: 2.465860470485703

Epoch: 6| Step: 13
Training loss: 2.5696237679072302
Validation loss: 2.468935021979859

Epoch: 122| Step: 0
Training loss: 1.9601674790743029
Validation loss: 2.466089851579177

Epoch: 6| Step: 1
Training loss: 2.7099252179515303
Validation loss: 2.4699531231034264

Epoch: 6| Step: 2
Training loss: 2.3177988327588275
Validation loss: 2.470223980708459

Epoch: 6| Step: 3
Training loss: 2.738117468883865
Validation loss: 2.472101761053617

Epoch: 6| Step: 4
Training loss: 2.5300990184058474
Validation loss: 2.4695912629908707

Epoch: 6| Step: 5
Training loss: 2.3642573082855205
Validation loss: 2.475306805305238

Epoch: 6| Step: 6
Training loss: 2.6874522715034193
Validation loss: 2.4698876765422164

Epoch: 6| Step: 7
Training loss: 2.7217150775865595
Validation loss: 2.4688878483655157

Epoch: 6| Step: 8
Training loss: 2.388808613791141
Validation loss: 2.463121831389032

Epoch: 6| Step: 9
Training loss: 2.043033868689122
Validation loss: 2.4661029756897896

Epoch: 6| Step: 10
Training loss: 2.0956139310003485
Validation loss: 2.462205703370464

Epoch: 6| Step: 11
Training loss: 2.8886659324228936
Validation loss: 2.466242486549478

Epoch: 6| Step: 12
Training loss: 2.7364690119478476
Validation loss: 2.454536768775347

Epoch: 6| Step: 13
Training loss: 2.863287911400846
Validation loss: 2.463081612619855

Epoch: 123| Step: 0
Training loss: 2.3016941092492047
Validation loss: 2.459165728534488

Epoch: 6| Step: 1
Training loss: 2.7482377387965022
Validation loss: 2.4671067833254408

Epoch: 6| Step: 2
Training loss: 2.577391641523967
Validation loss: 2.4667470669745555

Epoch: 6| Step: 3
Training loss: 2.4303333859099867
Validation loss: 2.4639270526731036

Epoch: 6| Step: 4
Training loss: 2.890299020893129
Validation loss: 2.46396170994394

Epoch: 6| Step: 5
Training loss: 2.5018014139698233
Validation loss: 2.469398670847437

Epoch: 6| Step: 6
Training loss: 2.214168277386228
Validation loss: 2.4719384765190973

Epoch: 6| Step: 7
Training loss: 2.7990419315469546
Validation loss: 2.464024507870313

Epoch: 6| Step: 8
Training loss: 2.7071620364611526
Validation loss: 2.4613335992045617

Epoch: 6| Step: 9
Training loss: 2.93696573146925
Validation loss: 2.4615729909165363

Epoch: 6| Step: 10
Training loss: 2.085450533484864
Validation loss: 2.4589434259998053

Epoch: 6| Step: 11
Training loss: 2.5195543391626156
Validation loss: 2.4610167798386464

Epoch: 6| Step: 12
Training loss: 2.366531935962552
Validation loss: 2.4541313391206123

Epoch: 6| Step: 13
Training loss: 2.0723727357671273
Validation loss: 2.4586802146277007

Epoch: 124| Step: 0
Training loss: 2.5561741227731454
Validation loss: 2.4531331639245124

Epoch: 6| Step: 1
Training loss: 2.545552103229063
Validation loss: 2.4541536187266026

Epoch: 6| Step: 2
Training loss: 2.129072662288949
Validation loss: 2.45447888441931

Epoch: 6| Step: 3
Training loss: 2.96913433598737
Validation loss: 2.4550904744317403

Epoch: 6| Step: 4
Training loss: 1.9318884525676068
Validation loss: 2.4674031571461144

Epoch: 6| Step: 5
Training loss: 2.369407594738842
Validation loss: 2.4639340115825608

Epoch: 6| Step: 6
Training loss: 2.7309570749011036
Validation loss: 2.4563631767749494

Epoch: 6| Step: 7
Training loss: 3.1796656052494034
Validation loss: 2.4613722644232965

Epoch: 6| Step: 8
Training loss: 2.4559648925869
Validation loss: 2.4678884684969593

Epoch: 6| Step: 9
Training loss: 2.3111124773306764
Validation loss: 2.471899028135626

Epoch: 6| Step: 10
Training loss: 2.7312746618628334
Validation loss: 2.464197250355306

Epoch: 6| Step: 11
Training loss: 2.54336361961614
Validation loss: 2.4578653687588776

Epoch: 6| Step: 12
Training loss: 2.3960414187970165
Validation loss: 2.4636955347593923

Epoch: 6| Step: 13
Training loss: 2.1705853042905052
Validation loss: 2.463309913578985

Epoch: 125| Step: 0
Training loss: 2.60123860860344
Validation loss: 2.476174405372435

Epoch: 6| Step: 1
Training loss: 2.069943953045589
Validation loss: 2.4642325972129973

Epoch: 6| Step: 2
Training loss: 2.774217350883421
Validation loss: 2.470421880865704

Epoch: 6| Step: 3
Training loss: 2.3727539886450733
Validation loss: 2.4684663440619072

Epoch: 6| Step: 4
Training loss: 2.06171864823619
Validation loss: 2.4614873039832017

Epoch: 6| Step: 5
Training loss: 2.4462452045095433
Validation loss: 2.4586675519102092

Epoch: 6| Step: 6
Training loss: 2.4747654505092354
Validation loss: 2.4621730952142697

Epoch: 6| Step: 7
Training loss: 2.445849374938382
Validation loss: 2.461999847559817

Epoch: 6| Step: 8
Training loss: 2.9504989977862217
Validation loss: 2.463488787244165

Epoch: 6| Step: 9
Training loss: 2.366038732996833
Validation loss: 2.4632332886377064

Epoch: 6| Step: 10
Training loss: 2.537817922886293
Validation loss: 2.4667835371150697

Epoch: 6| Step: 11
Training loss: 2.827985391279632
Validation loss: 2.462960871703817

Epoch: 6| Step: 12
Training loss: 2.511760135861412
Validation loss: 2.461316881758028

Epoch: 6| Step: 13
Training loss: 2.687022499424698
Validation loss: 2.4699137958485173

Epoch: 126| Step: 0
Training loss: 1.803682451999114
Validation loss: 2.4711534976721112

Epoch: 6| Step: 1
Training loss: 2.420599423092891
Validation loss: 2.4667601634254

Epoch: 6| Step: 2
Training loss: 2.5089211553513455
Validation loss: 2.4726728506068354

Epoch: 6| Step: 3
Training loss: 2.764118538607053
Validation loss: 2.4676387555377777

Epoch: 6| Step: 4
Training loss: 2.943143253200956
Validation loss: 2.4656544685617283

Epoch: 6| Step: 5
Training loss: 3.2855196830033364
Validation loss: 2.471615846136739

Epoch: 6| Step: 6
Training loss: 2.555284156301565
Validation loss: 2.4657749970052256

Epoch: 6| Step: 7
Training loss: 2.7138387233124046
Validation loss: 2.462025703542878

Epoch: 6| Step: 8
Training loss: 1.9147727427085133
Validation loss: 2.460388929795902

Epoch: 6| Step: 9
Training loss: 2.0728071046434358
Validation loss: 2.4559660251557967

Epoch: 6| Step: 10
Training loss: 2.79607665532896
Validation loss: 2.4604531835892636

Epoch: 6| Step: 11
Training loss: 2.34315462815628
Validation loss: 2.4582168637719257

Epoch: 6| Step: 12
Training loss: 2.7134474861851343
Validation loss: 2.4559826091405363

Epoch: 6| Step: 13
Training loss: 2.1352094099990144
Validation loss: 2.4561033209958785

Epoch: 127| Step: 0
Training loss: 2.4013665917928297
Validation loss: 2.4553496039468863

Epoch: 6| Step: 1
Training loss: 2.1580324407548517
Validation loss: 2.4547303650705263

Epoch: 6| Step: 2
Training loss: 2.415029585125965
Validation loss: 2.4620379535673926

Epoch: 6| Step: 3
Training loss: 2.211905223837197
Validation loss: 2.4542317090917094

Epoch: 6| Step: 4
Training loss: 2.34044607621995
Validation loss: 2.4554495357288006

Epoch: 6| Step: 5
Training loss: 2.767498007121484
Validation loss: 2.455785907778888

Epoch: 6| Step: 6
Training loss: 2.7375886179894184
Validation loss: 2.4579523944429806

Epoch: 6| Step: 7
Training loss: 2.291806395923636
Validation loss: 2.4564712767709844

Epoch: 6| Step: 8
Training loss: 2.365143349720643
Validation loss: 2.4582174457024

Epoch: 6| Step: 9
Training loss: 2.9617477556446983
Validation loss: 2.4557457954002855

Epoch: 6| Step: 10
Training loss: 2.2919764800604185
Validation loss: 2.4583339583401504

Epoch: 6| Step: 11
Training loss: 2.4468501804695895
Validation loss: 2.4602579944771303

Epoch: 6| Step: 12
Training loss: 2.896608994337458
Validation loss: 2.4629667120607293

Epoch: 6| Step: 13
Training loss: 2.7066471328249713
Validation loss: 2.46194012920779

Epoch: 128| Step: 0
Training loss: 2.233801921631694
Validation loss: 2.458613465937896

Epoch: 6| Step: 1
Training loss: 2.8256724139688334
Validation loss: 2.462103108470668

Epoch: 6| Step: 2
Training loss: 2.4763744776257646
Validation loss: 2.4606462417291586

Epoch: 6| Step: 3
Training loss: 2.8260079568965524
Validation loss: 2.46340472356237

Epoch: 6| Step: 4
Training loss: 2.2601956260882545
Validation loss: 2.4622131755077756

Epoch: 6| Step: 5
Training loss: 2.9828423364185146
Validation loss: 2.4562058429453555

Epoch: 6| Step: 6
Training loss: 1.8731881606482759
Validation loss: 2.464122507497129

Epoch: 6| Step: 7
Training loss: 2.6758167125273222
Validation loss: 2.45801544289307

Epoch: 6| Step: 8
Training loss: 2.539543223722772
Validation loss: 2.4623295313508557

Epoch: 6| Step: 9
Training loss: 1.9892679999815843
Validation loss: 2.4651715140804957

Epoch: 6| Step: 10
Training loss: 2.365247277524676
Validation loss: 2.4609930768877306

Epoch: 6| Step: 11
Training loss: 2.661431498432678
Validation loss: 2.4674638705714993

Epoch: 6| Step: 12
Training loss: 2.704777383440221
Validation loss: 2.461273009020094

Epoch: 6| Step: 13
Training loss: 2.495077627805278
Validation loss: 2.460357581540038

Epoch: 129| Step: 0
Training loss: 2.9506040439617043
Validation loss: 2.4607073479463053

Epoch: 6| Step: 1
Training loss: 2.4908658053630965
Validation loss: 2.467709253540984

Epoch: 6| Step: 2
Training loss: 1.7779668700797195
Validation loss: 2.4637859511014444

Epoch: 6| Step: 3
Training loss: 1.820187674896323
Validation loss: 2.4634086352527618

Epoch: 6| Step: 4
Training loss: 2.1941217743245667
Validation loss: 2.4646645877328237

Epoch: 6| Step: 5
Training loss: 2.0439373805388374
Validation loss: 2.4620213538818287

Epoch: 6| Step: 6
Training loss: 2.8581019835272126
Validation loss: 2.461156861554773

Epoch: 6| Step: 7
Training loss: 2.988837934514266
Validation loss: 2.459233237821575

Epoch: 6| Step: 8
Training loss: 2.740161984521356
Validation loss: 2.4587336526782066

Epoch: 6| Step: 9
Training loss: 2.398940341190168
Validation loss: 2.4631766814396894

Epoch: 6| Step: 10
Training loss: 2.555216416601331
Validation loss: 2.4678230476902723

Epoch: 6| Step: 11
Training loss: 2.8592409196279016
Validation loss: 2.470222484694687

Epoch: 6| Step: 12
Training loss: 2.553765366741894
Validation loss: 2.4638826135653185

Epoch: 6| Step: 13
Training loss: 2.373119010927782
Validation loss: 2.4597257668558012

Epoch: 130| Step: 0
Training loss: 2.5331457127143833
Validation loss: 2.4623330655130307

Epoch: 6| Step: 1
Training loss: 2.784924854655048
Validation loss: 2.463358629670638

Epoch: 6| Step: 2
Training loss: 2.321950109814912
Validation loss: 2.4644163378786876

Epoch: 6| Step: 3
Training loss: 2.318962552181559
Validation loss: 2.470550492187158

Epoch: 6| Step: 4
Training loss: 1.6106551180929725
Validation loss: 2.4748579832234077

Epoch: 6| Step: 5
Training loss: 2.6905684585921787
Validation loss: 2.478281493535174

Epoch: 6| Step: 6
Training loss: 2.1463665222636807
Validation loss: 2.4702761475898107

Epoch: 6| Step: 7
Training loss: 2.757864284299359
Validation loss: 2.461286651224776

Epoch: 6| Step: 8
Training loss: 2.708753602113956
Validation loss: 2.4647989163197948

Epoch: 6| Step: 9
Training loss: 2.846326226984089
Validation loss: 2.4694055741088583

Epoch: 6| Step: 10
Training loss: 2.737714548282194
Validation loss: 2.475077700438844

Epoch: 6| Step: 11
Training loss: 2.67362374527053
Validation loss: 2.4751643537288324

Epoch: 6| Step: 12
Training loss: 2.3420945488195715
Validation loss: 2.473800129433116

Epoch: 6| Step: 13
Training loss: 2.6795792182420577
Validation loss: 2.4760346115797094

Epoch: 131| Step: 0
Training loss: 2.7244645493823305
Validation loss: 2.4781766298422903

Epoch: 6| Step: 1
Training loss: 2.050751836656629
Validation loss: 2.4777047524527505

Epoch: 6| Step: 2
Training loss: 2.7247148172081284
Validation loss: 2.4856286554563054

Epoch: 6| Step: 3
Training loss: 2.3179539468187786
Validation loss: 2.4753679188288964

Epoch: 6| Step: 4
Training loss: 1.7832814728989006
Validation loss: 2.475567045020572

Epoch: 6| Step: 5
Training loss: 2.7957174793539554
Validation loss: 2.476928443226239

Epoch: 6| Step: 6
Training loss: 2.7363619315586525
Validation loss: 2.46629502765935

Epoch: 6| Step: 7
Training loss: 2.850110329617296
Validation loss: 2.4676263078739216

Epoch: 6| Step: 8
Training loss: 2.079242606550407
Validation loss: 2.462587778105126

Epoch: 6| Step: 9
Training loss: 1.7224646913760262
Validation loss: 2.4614066832218415

Epoch: 6| Step: 10
Training loss: 3.074884093046264
Validation loss: 2.463974498660164

Epoch: 6| Step: 11
Training loss: 2.8713516638514416
Validation loss: 2.4673001663674463

Epoch: 6| Step: 12
Training loss: 2.5854495415043472
Validation loss: 2.4583698259220537

Epoch: 6| Step: 13
Training loss: 2.2390883024316897
Validation loss: 2.4628982079974295

Epoch: 132| Step: 0
Training loss: 2.788142290230631
Validation loss: 2.462789317141609

Epoch: 6| Step: 1
Training loss: 2.627367949792608
Validation loss: 2.4677902802794676

Epoch: 6| Step: 2
Training loss: 2.181196012074756
Validation loss: 2.470274024259996

Epoch: 6| Step: 3
Training loss: 2.2085274545052562
Validation loss: 2.4580503775046245

Epoch: 6| Step: 4
Training loss: 2.84747673902648
Validation loss: 2.473088207149535

Epoch: 6| Step: 5
Training loss: 1.9753220476675044
Validation loss: 2.4699411616994404

Epoch: 6| Step: 6
Training loss: 2.3753270375805995
Validation loss: 2.466638861533841

Epoch: 6| Step: 7
Training loss: 1.82053684931348
Validation loss: 2.462194874379602

Epoch: 6| Step: 8
Training loss: 2.0272748343747957
Validation loss: 2.4604958920128315

Epoch: 6| Step: 9
Training loss: 2.8715645540325356
Validation loss: 2.4672642111856495

Epoch: 6| Step: 10
Training loss: 2.219438365481819
Validation loss: 2.4641127673762577

Epoch: 6| Step: 11
Training loss: 3.2762497359257154
Validation loss: 2.4659046564060967

Epoch: 6| Step: 12
Training loss: 2.6221280508947893
Validation loss: 2.470332463421263

Epoch: 6| Step: 13
Training loss: 2.6997008051932414
Validation loss: 2.4872624793463483

Epoch: 133| Step: 0
Training loss: 2.4214200484667967
Validation loss: 2.483054331866792

Epoch: 6| Step: 1
Training loss: 2.4866267142610408
Validation loss: 2.484150810442763

Epoch: 6| Step: 2
Training loss: 2.2843080690861703
Validation loss: 2.4851368309844455

Epoch: 6| Step: 3
Training loss: 2.3886986245180477
Validation loss: 2.4769214165472855

Epoch: 6| Step: 4
Training loss: 2.7714889343525306
Validation loss: 2.469782923041132

Epoch: 6| Step: 5
Training loss: 2.561762820019198
Validation loss: 2.476764097141346

Epoch: 6| Step: 6
Training loss: 2.263968342151974
Validation loss: 2.4682559231200503

Epoch: 6| Step: 7
Training loss: 2.953225593266475
Validation loss: 2.46055174534032

Epoch: 6| Step: 8
Training loss: 2.083479558263567
Validation loss: 2.4611241184098516

Epoch: 6| Step: 9
Training loss: 2.1934414421075465
Validation loss: 2.464563449533266

Epoch: 6| Step: 10
Training loss: 2.9889175435724873
Validation loss: 2.4563529771956394

Epoch: 6| Step: 11
Training loss: 2.766369218424924
Validation loss: 2.4700061322598135

Epoch: 6| Step: 12
Training loss: 2.4139696615694115
Validation loss: 2.468915346298391

Epoch: 6| Step: 13
Training loss: 2.6138679974710133
Validation loss: 2.4752621450857957

Epoch: 134| Step: 0
Training loss: 2.2222767054978414
Validation loss: 2.459175488249226

Epoch: 6| Step: 1
Training loss: 2.1018676536266065
Validation loss: 2.4657779944285383

Epoch: 6| Step: 2
Training loss: 2.7807551597403988
Validation loss: 2.466260709305906

Epoch: 6| Step: 3
Training loss: 2.17880395188888
Validation loss: 2.463050927822418

Epoch: 6| Step: 4
Training loss: 2.424621599700332
Validation loss: 2.466061073358562

Epoch: 6| Step: 5
Training loss: 2.79158508599109
Validation loss: 2.4705201092511335

Epoch: 6| Step: 6
Training loss: 2.5923031367836815
Validation loss: 2.4622874921834383

Epoch: 6| Step: 7
Training loss: 2.199406075503325
Validation loss: 2.466536273817677

Epoch: 6| Step: 8
Training loss: 2.5023061605983408
Validation loss: 2.4766383595686543

Epoch: 6| Step: 9
Training loss: 2.719774601236426
Validation loss: 2.4730636960043366

Epoch: 6| Step: 10
Training loss: 2.389257900313188
Validation loss: 2.4754219035943095

Epoch: 6| Step: 11
Training loss: 2.527548355711559
Validation loss: 2.4756991288430754

Epoch: 6| Step: 12
Training loss: 2.781646357378941
Validation loss: 2.4717068408814447

Epoch: 6| Step: 13
Training loss: 2.736189757721271
Validation loss: 2.471209994506672

Epoch: 135| Step: 0
Training loss: 2.1908019077411818
Validation loss: 2.4565732657466746

Epoch: 6| Step: 1
Training loss: 2.680252327071778
Validation loss: 2.465527068474911

Epoch: 6| Step: 2
Training loss: 2.823582663337778
Validation loss: 2.461950951249049

Epoch: 6| Step: 3
Training loss: 2.094503580242857
Validation loss: 2.4690018296063094

Epoch: 6| Step: 4
Training loss: 2.890728592949484
Validation loss: 2.469571938481717

Epoch: 6| Step: 5
Training loss: 2.141209877471119
Validation loss: 2.457835799048387

Epoch: 6| Step: 6
Training loss: 2.8856408942142
Validation loss: 2.4608056573014445

Epoch: 6| Step: 7
Training loss: 2.7693863630395286
Validation loss: 2.4655426694970575

Epoch: 6| Step: 8
Training loss: 2.1525719274184456
Validation loss: 2.462327385030712

Epoch: 6| Step: 9
Training loss: 2.1657954689738674
Validation loss: 2.473128640769327

Epoch: 6| Step: 10
Training loss: 2.5652141618462334
Validation loss: 2.470516056020197

Epoch: 6| Step: 11
Training loss: 2.671097491725589
Validation loss: 2.462008902026728

Epoch: 6| Step: 12
Training loss: 2.4473413210622184
Validation loss: 2.4588883683963085

Epoch: 6| Step: 13
Training loss: 2.487411083376666
Validation loss: 2.4603977156341816

Epoch: 136| Step: 0
Training loss: 2.9131291508067036
Validation loss: 2.4635785337328096

Epoch: 6| Step: 1
Training loss: 2.0526481922470916
Validation loss: 2.45861976916042

Epoch: 6| Step: 2
Training loss: 2.9054574193320675
Validation loss: 2.4647709049316338

Epoch: 6| Step: 3
Training loss: 2.9860335130490827
Validation loss: 2.474309271298923

Epoch: 6| Step: 4
Training loss: 1.6197898676658853
Validation loss: 2.4689845927357594

Epoch: 6| Step: 5
Training loss: 2.8215442619955304
Validation loss: 2.461945778303122

Epoch: 6| Step: 6
Training loss: 2.5673681398758172
Validation loss: 2.467686097954833

Epoch: 6| Step: 7
Training loss: 1.7062562627991817
Validation loss: 2.4681441774941004

Epoch: 6| Step: 8
Training loss: 2.4870732847183192
Validation loss: 2.4644580746891873

Epoch: 6| Step: 9
Training loss: 2.843761402149188
Validation loss: 2.4671846891857885

Epoch: 6| Step: 10
Training loss: 2.2297439065493476
Validation loss: 2.467783195376682

Epoch: 6| Step: 11
Training loss: 2.3182358616463916
Validation loss: 2.46354396785013

Epoch: 6| Step: 12
Training loss: 2.5922218325079096
Validation loss: 2.4637542347941785

Epoch: 6| Step: 13
Training loss: 2.481848049396943
Validation loss: 2.472147298122813

Epoch: 137| Step: 0
Training loss: 2.059340629232928
Validation loss: 2.473458078234134

Epoch: 6| Step: 1
Training loss: 1.9022802072052512
Validation loss: 2.472639552859016

Epoch: 6| Step: 2
Training loss: 2.131252738525779
Validation loss: 2.4706240916521875

Epoch: 6| Step: 3
Training loss: 2.273278299636914
Validation loss: 2.4818006569083457

Epoch: 6| Step: 4
Training loss: 2.80126140314698
Validation loss: 2.4843765034860983

Epoch: 6| Step: 5
Training loss: 2.507808507042674
Validation loss: 2.4731330110633714

Epoch: 6| Step: 6
Training loss: 2.204388195460178
Validation loss: 2.477668314764853

Epoch: 6| Step: 7
Training loss: 3.11377179003809
Validation loss: 2.472631083717458

Epoch: 6| Step: 8
Training loss: 2.4828058241507756
Validation loss: 2.4712852546133752

Epoch: 6| Step: 9
Training loss: 2.4521113931827028
Validation loss: 2.463751807467802

Epoch: 6| Step: 10
Training loss: 2.9382978938391275
Validation loss: 2.4629562090884956

Epoch: 6| Step: 11
Training loss: 2.664003880546653
Validation loss: 2.4646062560209927

Epoch: 6| Step: 12
Training loss: 2.014896941472049
Validation loss: 2.46117836717034

Epoch: 6| Step: 13
Training loss: 3.1712564701530064
Validation loss: 2.4596084315911657

Epoch: 138| Step: 0
Training loss: 2.5276141014718747
Validation loss: 2.4671754282293037

Epoch: 6| Step: 1
Training loss: 2.757877511184864
Validation loss: 2.4638924271697804

Epoch: 6| Step: 2
Training loss: 2.7537928348210614
Validation loss: 2.464220422599821

Epoch: 6| Step: 3
Training loss: 1.978723362582522
Validation loss: 2.46894822753335

Epoch: 6| Step: 4
Training loss: 2.898232013173731
Validation loss: 2.4603421575993307

Epoch: 6| Step: 5
Training loss: 2.6244799689213267
Validation loss: 2.469378073589112

Epoch: 6| Step: 6
Training loss: 2.3430138003911205
Validation loss: 2.4662852719506487

Epoch: 6| Step: 7
Training loss: 3.0091632138653868
Validation loss: 2.469158863060016

Epoch: 6| Step: 8
Training loss: 2.656657916891829
Validation loss: 2.4649355912063458

Epoch: 6| Step: 9
Training loss: 2.4623341306020063
Validation loss: 2.4629702453086013

Epoch: 6| Step: 10
Training loss: 1.7898593777024672
Validation loss: 2.4682142263812086

Epoch: 6| Step: 11
Training loss: 2.4315911100317624
Validation loss: 2.4679963454390004

Epoch: 6| Step: 12
Training loss: 2.4668352451798583
Validation loss: 2.471698657922228

Epoch: 6| Step: 13
Training loss: 2.1047008579116286
Validation loss: 2.4664915675657038

Epoch: 139| Step: 0
Training loss: 2.6657706682623363
Validation loss: 2.466348502113718

Epoch: 6| Step: 1
Training loss: 2.589500531084765
Validation loss: 2.4668519816078955

Epoch: 6| Step: 2
Training loss: 2.51590855108097
Validation loss: 2.465140170225262

Epoch: 6| Step: 3
Training loss: 1.64287028396279
Validation loss: 2.4613105935148067

Epoch: 6| Step: 4
Training loss: 2.3356445537072217
Validation loss: 2.4603241978732284

Epoch: 6| Step: 5
Training loss: 2.5180435401539594
Validation loss: 2.4598371356716147

Epoch: 6| Step: 6
Training loss: 2.090611625138224
Validation loss: 2.465867254735726

Epoch: 6| Step: 7
Training loss: 2.832596926263899
Validation loss: 2.467972693420525

Epoch: 6| Step: 8
Training loss: 2.6210495423456184
Validation loss: 2.460886152428105

Epoch: 6| Step: 9
Training loss: 2.8952589677533935
Validation loss: 2.467155875417435

Epoch: 6| Step: 10
Training loss: 2.4327954594891823
Validation loss: 2.468665350899314

Epoch: 6| Step: 11
Training loss: 2.5486020276574446
Validation loss: 2.468505839253299

Epoch: 6| Step: 12
Training loss: 2.618386793782666
Validation loss: 2.4637621618932273

Epoch: 6| Step: 13
Training loss: 2.257587355637642
Validation loss: 2.4675763555563366

Epoch: 140| Step: 0
Training loss: 2.7688977548686236
Validation loss: 2.461180788962123

Epoch: 6| Step: 1
Training loss: 2.7957390550919197
Validation loss: 2.467258276315787

Epoch: 6| Step: 2
Training loss: 2.1646721046707618
Validation loss: 2.4650427349556794

Epoch: 6| Step: 3
Training loss: 2.4791213814155015
Validation loss: 2.4632332079786177

Epoch: 6| Step: 4
Training loss: 1.7971269513833539
Validation loss: 2.462511332400302

Epoch: 6| Step: 5
Training loss: 2.6286105801646085
Validation loss: 2.463710647390011

Epoch: 6| Step: 6
Training loss: 2.3108584789618853
Validation loss: 2.463436815370707

Epoch: 6| Step: 7
Training loss: 2.310426349350155
Validation loss: 2.465609117786358

Epoch: 6| Step: 8
Training loss: 2.5497472750023356
Validation loss: 2.4674809248166656

Epoch: 6| Step: 9
Training loss: 2.5295137643795873
Validation loss: 2.465602155546558

Epoch: 6| Step: 10
Training loss: 2.8130959621135085
Validation loss: 2.466633899788977

Epoch: 6| Step: 11
Training loss: 2.5286077201215496
Validation loss: 2.4656606409730606

Epoch: 6| Step: 12
Training loss: 2.574025356686533
Validation loss: 2.46672192094966

Epoch: 6| Step: 13
Training loss: 2.3207999080348927
Validation loss: 2.4755445086883143

Epoch: 141| Step: 0
Training loss: 2.509007439588249
Validation loss: 2.466808972463697

Epoch: 6| Step: 1
Training loss: 2.6571526284045497
Validation loss: 2.4755275902527814

Epoch: 6| Step: 2
Training loss: 2.111269291032433
Validation loss: 2.4715736112185276

Epoch: 6| Step: 3
Training loss: 2.400528781971787
Validation loss: 2.477806901819996

Epoch: 6| Step: 4
Training loss: 2.5165102331119047
Validation loss: 2.4716061837771703

Epoch: 6| Step: 5
Training loss: 2.7877836314052433
Validation loss: 2.469197341371357

Epoch: 6| Step: 6
Training loss: 2.0998275004792175
Validation loss: 2.4735465473324063

Epoch: 6| Step: 7
Training loss: 2.467817782391192
Validation loss: 2.474313229988419

Epoch: 6| Step: 8
Training loss: 2.1813409474822127
Validation loss: 2.4696118102006808

Epoch: 6| Step: 9
Training loss: 2.2248941160574893
Validation loss: 2.4754041495908594

Epoch: 6| Step: 10
Training loss: 2.35253186697867
Validation loss: 2.475679779782109

Epoch: 6| Step: 11
Training loss: 2.0663840972347534
Validation loss: 2.472337329580283

Epoch: 6| Step: 12
Training loss: 3.337402879537722
Validation loss: 2.4755054709093405

Epoch: 6| Step: 13
Training loss: 2.7720414207413393
Validation loss: 2.4684686621179037

Epoch: 142| Step: 0
Training loss: 2.0902576072398404
Validation loss: 2.4743232431159328

Epoch: 6| Step: 1
Training loss: 2.338028090282952
Validation loss: 2.467001452687937

Epoch: 6| Step: 2
Training loss: 2.1715373044289077
Validation loss: 2.4819402540138684

Epoch: 6| Step: 3
Training loss: 1.8192672675580424
Validation loss: 2.4682245781855783

Epoch: 6| Step: 4
Training loss: 3.405669276579208
Validation loss: 2.465200713718717

Epoch: 6| Step: 5
Training loss: 2.3275716239160564
Validation loss: 2.4667862030869667

Epoch: 6| Step: 6
Training loss: 2.3182550935503135
Validation loss: 2.472226089898369

Epoch: 6| Step: 7
Training loss: 2.6167455499344614
Validation loss: 2.4666448180309293

Epoch: 6| Step: 8
Training loss: 2.5075183351251433
Validation loss: 2.4693217842677857

Epoch: 6| Step: 9
Training loss: 2.789503559532158
Validation loss: 2.477534860365064

Epoch: 6| Step: 10
Training loss: 2.1590610921890763
Validation loss: 2.488626852343288

Epoch: 6| Step: 11
Training loss: 2.8691487685491137
Validation loss: 2.488618150198122

Epoch: 6| Step: 12
Training loss: 2.5185976649711335
Validation loss: 2.4730254063939503

Epoch: 6| Step: 13
Training loss: 2.5743449850201108
Validation loss: 2.4691356406020475

Epoch: 143| Step: 0
Training loss: 2.3419011262241125
Validation loss: 2.469072345018283

Epoch: 6| Step: 1
Training loss: 2.102287195891658
Validation loss: 2.467176426803675

Epoch: 6| Step: 2
Training loss: 2.9480073373462563
Validation loss: 2.4708633391009514

Epoch: 6| Step: 3
Training loss: 2.2890623958444407
Validation loss: 2.480026870576842

Epoch: 6| Step: 4
Training loss: 2.6344879886384516
Validation loss: 2.4858322348247492

Epoch: 6| Step: 5
Training loss: 2.4546371950158488
Validation loss: 2.488680804964146

Epoch: 6| Step: 6
Training loss: 2.708039859619245
Validation loss: 2.4708607659792468

Epoch: 6| Step: 7
Training loss: 2.7871985097103753
Validation loss: 2.47581461013944

Epoch: 6| Step: 8
Training loss: 2.4408708397286802
Validation loss: 2.474464370104123

Epoch: 6| Step: 9
Training loss: 2.5513085467261982
Validation loss: 2.4760512778021138

Epoch: 6| Step: 10
Training loss: 2.1962156779647537
Validation loss: 2.481128923166942

Epoch: 6| Step: 11
Training loss: 2.6662827354456793
Validation loss: 2.4665462460206466

Epoch: 6| Step: 12
Training loss: 2.383897978135791
Validation loss: 2.467512359717017

Epoch: 6| Step: 13
Training loss: 2.6805270912183246
Validation loss: 2.4606548813102114

Epoch: 144| Step: 0
Training loss: 2.5792601889405065
Validation loss: 2.4663513538372324

Epoch: 6| Step: 1
Training loss: 2.706893499042977
Validation loss: 2.47458421252273

Epoch: 6| Step: 2
Training loss: 1.96947441700001
Validation loss: 2.4818306135494415

Epoch: 6| Step: 3
Training loss: 1.9870516529252134
Validation loss: 2.477069004702908

Epoch: 6| Step: 4
Training loss: 2.4024320756755775
Validation loss: 2.472540669404064

Epoch: 6| Step: 5
Training loss: 2.307581232527764
Validation loss: 2.48143668925751

Epoch: 6| Step: 6
Training loss: 2.579810683823074
Validation loss: 2.469892728280533

Epoch: 6| Step: 7
Training loss: 2.6628467101249997
Validation loss: 2.4867309979085124

Epoch: 6| Step: 8
Training loss: 2.7110162992870404
Validation loss: 2.475020898544498

Epoch: 6| Step: 9
Training loss: 2.644214605535442
Validation loss: 2.472908894998818

Epoch: 6| Step: 10
Training loss: 2.6691114623091297
Validation loss: 2.469265123537858

Epoch: 6| Step: 11
Training loss: 2.5600469990230708
Validation loss: 2.4686024859173408

Epoch: 6| Step: 12
Training loss: 2.767847149035435
Validation loss: 2.470809077829461

Epoch: 6| Step: 13
Training loss: 2.1850454455784583
Validation loss: 2.470251568326905

Epoch: 145| Step: 0
Training loss: 2.047132170151774
Validation loss: 2.470977904629179

Epoch: 6| Step: 1
Training loss: 2.3733052682110163
Validation loss: 2.4671368056394614

Epoch: 6| Step: 2
Training loss: 2.019741851627776
Validation loss: 2.4715348001168174

Epoch: 6| Step: 3
Training loss: 1.953611206572255
Validation loss: 2.4714946378628753

Epoch: 6| Step: 4
Training loss: 2.476775632525989
Validation loss: 2.4721708378708294

Epoch: 6| Step: 5
Training loss: 2.6420156214307813
Validation loss: 2.4783688765565755

Epoch: 6| Step: 6
Training loss: 2.7863853278653004
Validation loss: 2.47049743841569

Epoch: 6| Step: 7
Training loss: 2.402797649891826
Validation loss: 2.475274393817115

Epoch: 6| Step: 8
Training loss: 2.4956977064402555
Validation loss: 2.470903833250867

Epoch: 6| Step: 9
Training loss: 2.651063050868956
Validation loss: 2.4812352075143846

Epoch: 6| Step: 10
Training loss: 2.7990910791895267
Validation loss: 2.4839257047950793

Epoch: 6| Step: 11
Training loss: 2.5189796021269
Validation loss: 2.472537969459047

Epoch: 6| Step: 12
Training loss: 2.7906864684918626
Validation loss: 2.475515326722485

Epoch: 6| Step: 13
Training loss: 2.4908093316036473
Validation loss: 2.471370489282974

Epoch: 146| Step: 0
Training loss: 2.746292041982862
Validation loss: 2.477002029646041

Epoch: 6| Step: 1
Training loss: 2.7353597557111318
Validation loss: 2.473204541396195

Epoch: 6| Step: 2
Training loss: 1.6476929054144096
Validation loss: 2.4737452579226025

Epoch: 6| Step: 3
Training loss: 2.4502706261467164
Validation loss: 2.4768946411883914

Epoch: 6| Step: 4
Training loss: 2.9097729731351873
Validation loss: 2.4780451270657053

Epoch: 6| Step: 5
Training loss: 2.4056885299559503
Validation loss: 2.4826928127689634

Epoch: 6| Step: 6
Training loss: 2.093871725159428
Validation loss: 2.472994957455601

Epoch: 6| Step: 7
Training loss: 2.084063770673041
Validation loss: 2.474259807220723

Epoch: 6| Step: 8
Training loss: 2.347358672058986
Validation loss: 2.4742724864999537

Epoch: 6| Step: 9
Training loss: 2.4052250648556495
Validation loss: 2.482464413562291

Epoch: 6| Step: 10
Training loss: 3.114708548147769
Validation loss: 2.475133216689251

Epoch: 6| Step: 11
Training loss: 2.42119721803655
Validation loss: 2.483043145713242

Epoch: 6| Step: 12
Training loss: 2.602185790399361
Validation loss: 2.477813950043192

Epoch: 6| Step: 13
Training loss: 2.254069885977984
Validation loss: 2.4740745650978555

Epoch: 147| Step: 0
Training loss: 2.9013901962862487
Validation loss: 2.4784538596022205

Epoch: 6| Step: 1
Training loss: 1.8381081593250157
Validation loss: 2.4808705642728968

Epoch: 6| Step: 2
Training loss: 1.9375015997110963
Validation loss: 2.4836590613023164

Epoch: 6| Step: 3
Training loss: 2.621297677715706
Validation loss: 2.4776072900600177

Epoch: 6| Step: 4
Training loss: 2.953088346385048
Validation loss: 2.4704321912497638

Epoch: 6| Step: 5
Training loss: 2.431425301083909
Validation loss: 2.4735088274646384

Epoch: 6| Step: 6
Training loss: 2.175454901117105
Validation loss: 2.4781225287035067

Epoch: 6| Step: 7
Training loss: 1.4804146386878936
Validation loss: 2.477755318479527

Epoch: 6| Step: 8
Training loss: 2.607915687233767
Validation loss: 2.4859223895010314

Epoch: 6| Step: 9
Training loss: 2.72275029680872
Validation loss: 2.48360439161061

Epoch: 6| Step: 10
Training loss: 2.5772222614592124
Validation loss: 2.5029330532028027

Epoch: 6| Step: 11
Training loss: 3.062944963788329
Validation loss: 2.4897333256908505

Epoch: 6| Step: 12
Training loss: 2.3372694830013576
Validation loss: 2.4802798061547926

Epoch: 6| Step: 13
Training loss: 2.67781299389396
Validation loss: 2.476543582880112

Epoch: 148| Step: 0
Training loss: 2.9485075844752386
Validation loss: 2.475925913282126

Epoch: 6| Step: 1
Training loss: 2.662465441842186
Validation loss: 2.4699991663263434

Epoch: 6| Step: 2
Training loss: 2.681107481256543
Validation loss: 2.472905367916769

Epoch: 6| Step: 3
Training loss: 2.4376081785014123
Validation loss: 2.4780092075229176

Epoch: 6| Step: 4
Training loss: 2.7713008763414146
Validation loss: 2.470813950778359

Epoch: 6| Step: 5
Training loss: 1.9397883898562918
Validation loss: 2.471668337330304

Epoch: 6| Step: 6
Training loss: 2.290250814770222
Validation loss: 2.467892638752936

Epoch: 6| Step: 7
Training loss: 2.5531916073873506
Validation loss: 2.468888307069278

Epoch: 6| Step: 8
Training loss: 2.53873598787018
Validation loss: 2.4724695698685113

Epoch: 6| Step: 9
Training loss: 2.412369711722811
Validation loss: 2.463682922012709

Epoch: 6| Step: 10
Training loss: 2.335654659435095
Validation loss: 2.4675278435127828

Epoch: 6| Step: 11
Training loss: 2.3669052711164773
Validation loss: 2.4635439517203466

Epoch: 6| Step: 12
Training loss: 2.763394593256553
Validation loss: 2.468306747111324

Epoch: 6| Step: 13
Training loss: 2.3671930394878977
Validation loss: 2.4690828541609267

Epoch: 149| Step: 0
Training loss: 2.487971455738408
Validation loss: 2.466420503095241

Epoch: 6| Step: 1
Training loss: 3.289037563927148
Validation loss: 2.462346766395157

Epoch: 6| Step: 2
Training loss: 2.8398716228644183
Validation loss: 2.46403473213723

Epoch: 6| Step: 3
Training loss: 2.403748438096196
Validation loss: 2.473506353483875

Epoch: 6| Step: 4
Training loss: 2.016841314440548
Validation loss: 2.4706841630170335

Epoch: 6| Step: 5
Training loss: 2.5654721585095492
Validation loss: 2.4769996554071967

Epoch: 6| Step: 6
Training loss: 2.448749308642007
Validation loss: 2.4775676272054628

Epoch: 6| Step: 7
Training loss: 2.3056839162899974
Validation loss: 2.469633370910484

Epoch: 6| Step: 8
Training loss: 1.8815102406713982
Validation loss: 2.4724040131279237

Epoch: 6| Step: 9
Training loss: 2.3670995714834513
Validation loss: 2.476254938484311

Epoch: 6| Step: 10
Training loss: 2.397929283747441
Validation loss: 2.487004789583252

Epoch: 6| Step: 11
Training loss: 2.792413829816104
Validation loss: 2.484756416456061

Epoch: 6| Step: 12
Training loss: 1.9345291495336812
Validation loss: 2.4891558856132527

Epoch: 6| Step: 13
Training loss: 2.4929701195130014
Validation loss: 2.477696300624813

Epoch: 150| Step: 0
Training loss: 2.3159203880212167
Validation loss: 2.486393218725384

Epoch: 6| Step: 1
Training loss: 3.0927819172701088
Validation loss: 2.478787502711114

Epoch: 6| Step: 2
Training loss: 2.8025349722185116
Validation loss: 2.476563639194295

Epoch: 6| Step: 3
Training loss: 2.8884366386533626
Validation loss: 2.4728575710401097

Epoch: 6| Step: 4
Training loss: 2.1315094596908803
Validation loss: 2.464811249290482

Epoch: 6| Step: 5
Training loss: 2.0465442885344216
Validation loss: 2.475855151704863

Epoch: 6| Step: 6
Training loss: 2.5823044625155425
Validation loss: 2.4683200445682485

Epoch: 6| Step: 7
Training loss: 2.3672259739937553
Validation loss: 2.4695989380453907

Epoch: 6| Step: 8
Training loss: 2.408403102123757
Validation loss: 2.4808884953867145

Epoch: 6| Step: 9
Training loss: 2.145770605954347
Validation loss: 2.472591855303912

Epoch: 6| Step: 10
Training loss: 2.3941328454696476
Validation loss: 2.4657781152923053

Epoch: 6| Step: 11
Training loss: 2.3821800518257232
Validation loss: 2.4755947336094555

Epoch: 6| Step: 12
Training loss: 2.2187081991207087
Validation loss: 2.4719102325693507

Epoch: 6| Step: 13
Training loss: 2.687170851312411
Validation loss: 2.4670604686797475

Epoch: 151| Step: 0
Training loss: 2.663405172296623
Validation loss: 2.477736033587878

Epoch: 6| Step: 1
Training loss: 2.0351325855599938
Validation loss: 2.476034499240805

Epoch: 6| Step: 2
Training loss: 1.8730276542369515
Validation loss: 2.476267655688547

Epoch: 6| Step: 3
Training loss: 2.3681548002396187
Validation loss: 2.503935132824674

Epoch: 6| Step: 4
Training loss: 2.94649378716762
Validation loss: 2.485395881542472

Epoch: 6| Step: 5
Training loss: 2.5517045550914803
Validation loss: 2.4992079115776984

Epoch: 6| Step: 6
Training loss: 2.105494794525256
Validation loss: 2.486645922212091

Epoch: 6| Step: 7
Training loss: 2.4904541876025093
Validation loss: 2.49005490123784

Epoch: 6| Step: 8
Training loss: 2.292077484299072
Validation loss: 2.479384514242524

Epoch: 6| Step: 9
Training loss: 2.5309286031249894
Validation loss: 2.4745282262971653

Epoch: 6| Step: 10
Training loss: 2.575175314555458
Validation loss: 2.4832452008483816

Epoch: 6| Step: 11
Training loss: 2.8903163435823083
Validation loss: 2.4743769455494418

Epoch: 6| Step: 12
Training loss: 1.9508387497939839
Validation loss: 2.4812651389530567

Epoch: 6| Step: 13
Training loss: 2.9830793993693656
Validation loss: 2.480250247332536

Epoch: 152| Step: 0
Training loss: 1.914750329816137
Validation loss: 2.476183809194567

Epoch: 6| Step: 1
Training loss: 2.4197117157721637
Validation loss: 2.475634355842769

Epoch: 6| Step: 2
Training loss: 2.6805717410673395
Validation loss: 2.4746861936412663

Epoch: 6| Step: 3
Training loss: 2.679924690270236
Validation loss: 2.478051685533154

Epoch: 6| Step: 4
Training loss: 2.5082225048467253
Validation loss: 2.4761514252336108

Epoch: 6| Step: 5
Training loss: 1.5334715006953419
Validation loss: 2.4791987815080496

Epoch: 6| Step: 6
Training loss: 2.4394399308152495
Validation loss: 2.4764446306709322

Epoch: 6| Step: 7
Training loss: 2.007574282515318
Validation loss: 2.4921304662350847

Epoch: 6| Step: 8
Training loss: 2.883679928831527
Validation loss: 2.489564964726784

Epoch: 6| Step: 9
Training loss: 2.255884317367521
Validation loss: 2.488570136163818

Epoch: 6| Step: 10
Training loss: 2.5312224963542427
Validation loss: 2.4872149024537378

Epoch: 6| Step: 11
Training loss: 2.6701666294922775
Validation loss: 2.4794718664036974

Epoch: 6| Step: 12
Training loss: 3.2852034230876623
Validation loss: 2.4794726516857493

Epoch: 6| Step: 13
Training loss: 2.3106711089012086
Validation loss: 2.4763929948851766

Epoch: 153| Step: 0
Training loss: 2.3552891803572464
Validation loss: 2.4718319772994364

Epoch: 6| Step: 1
Training loss: 2.0515686267491104
Validation loss: 2.476629101873526

Epoch: 6| Step: 2
Training loss: 2.0822009505917096
Validation loss: 2.4738243200579157

Epoch: 6| Step: 3
Training loss: 2.330057967451314
Validation loss: 2.47403372131059

Epoch: 6| Step: 4
Training loss: 1.8569785951973814
Validation loss: 2.4769832281787934

Epoch: 6| Step: 5
Training loss: 3.231362529396341
Validation loss: 2.4762385544567764

Epoch: 6| Step: 6
Training loss: 2.0676827481189894
Validation loss: 2.4773749814791146

Epoch: 6| Step: 7
Training loss: 3.007016401088224
Validation loss: 2.473012166373948

Epoch: 6| Step: 8
Training loss: 2.4116390372035696
Validation loss: 2.4749505606443267

Epoch: 6| Step: 9
Training loss: 2.6374419400301554
Validation loss: 2.4723805961409906

Epoch: 6| Step: 10
Training loss: 2.5892723684483743
Validation loss: 2.483597751809002

Epoch: 6| Step: 11
Training loss: 2.505243143856274
Validation loss: 2.4778878549487615

Epoch: 6| Step: 12
Training loss: 2.5350116047791076
Validation loss: 2.478276683371133

Epoch: 6| Step: 13
Training loss: 2.4194227047087202
Validation loss: 2.484178467340432

Epoch: 154| Step: 0
Training loss: 2.4178190662600065
Validation loss: 2.4848677908192522

Epoch: 6| Step: 1
Training loss: 2.397917750203948
Validation loss: 2.4819506126098987

Epoch: 6| Step: 2
Training loss: 2.5560888710630665
Validation loss: 2.4871735874628396

Epoch: 6| Step: 3
Training loss: 1.8256151625731576
Validation loss: 2.4716958284447617

Epoch: 6| Step: 4
Training loss: 2.737111493416477
Validation loss: 2.4782069429605262

Epoch: 6| Step: 5
Training loss: 1.8626098062801693
Validation loss: 2.4859270889636464

Epoch: 6| Step: 6
Training loss: 2.965830280687891
Validation loss: 2.4757277228027155

Epoch: 6| Step: 7
Training loss: 2.9965778541629065
Validation loss: 2.482359766589621

Epoch: 6| Step: 8
Training loss: 2.2009457029433253
Validation loss: 2.4749334936486282

Epoch: 6| Step: 9
Training loss: 2.2687671839375914
Validation loss: 2.488006416924799

Epoch: 6| Step: 10
Training loss: 2.1351654153034625
Validation loss: 2.4833001664739585

Epoch: 6| Step: 11
Training loss: 3.008860061337745
Validation loss: 2.487869252541192

Epoch: 6| Step: 12
Training loss: 1.9695336129621883
Validation loss: 2.490410062289617

Epoch: 6| Step: 13
Training loss: 2.591966498429232
Validation loss: 2.4877090315155854

Epoch: 155| Step: 0
Training loss: 1.756278899148492
Validation loss: 2.479452707047195

Epoch: 6| Step: 1
Training loss: 3.059819508134962
Validation loss: 2.481549061289384

Epoch: 6| Step: 2
Training loss: 1.7812255054596677
Validation loss: 2.486407202546641

Epoch: 6| Step: 3
Training loss: 2.210223726366465
Validation loss: 2.485787459984016

Epoch: 6| Step: 4
Training loss: 2.1356057680339697
Validation loss: 2.494065807617401

Epoch: 6| Step: 5
Training loss: 2.2771441992198316
Validation loss: 2.4867625569919163

Epoch: 6| Step: 6
Training loss: 2.899037096052679
Validation loss: 2.490591959492841

Epoch: 6| Step: 7
Training loss: 3.0544271138621863
Validation loss: 2.481773421828904

Epoch: 6| Step: 8
Training loss: 2.572122047026265
Validation loss: 2.498573516139721

Epoch: 6| Step: 9
Training loss: 2.313857324585156
Validation loss: 2.4889556753284285

Epoch: 6| Step: 10
Training loss: 2.637519771266794
Validation loss: 2.497226853897369

Epoch: 6| Step: 11
Training loss: 2.221603278219011
Validation loss: 2.4839396225209804

Epoch: 6| Step: 12
Training loss: 2.1648802606538657
Validation loss: 2.4962098796576737

Epoch: 6| Step: 13
Training loss: 2.735727814765781
Validation loss: 2.487193382317897

Epoch: 156| Step: 0
Training loss: 2.687488201026743
Validation loss: 2.485938022372904

Epoch: 6| Step: 1
Training loss: 2.476036136178621
Validation loss: 2.4860105908588452

Epoch: 6| Step: 2
Training loss: 2.2653973695252243
Validation loss: 2.483755246319899

Epoch: 6| Step: 3
Training loss: 2.523872456104432
Validation loss: 2.481856415037865

Epoch: 6| Step: 4
Training loss: 2.3785268797399084
Validation loss: 2.4832401362688272

Epoch: 6| Step: 5
Training loss: 2.3283103510660577
Validation loss: 2.484026566549187

Epoch: 6| Step: 6
Training loss: 2.522771599838636
Validation loss: 2.4820101696956716

Epoch: 6| Step: 7
Training loss: 2.2967379782152277
Validation loss: 2.490822349397348

Epoch: 6| Step: 8
Training loss: 1.9669228203763203
Validation loss: 2.4969596336003574

Epoch: 6| Step: 9
Training loss: 2.3696014886917083
Validation loss: 2.4899621752402785

Epoch: 6| Step: 10
Training loss: 2.1812185290670465
Validation loss: 2.4852305604549003

Epoch: 6| Step: 11
Training loss: 2.8080725683687118
Validation loss: 2.48119179107265

Epoch: 6| Step: 12
Training loss: 2.5355400182913086
Validation loss: 2.4756361054021547

Epoch: 6| Step: 13
Training loss: 2.907702667441445
Validation loss: 2.488205250328487

Epoch: 157| Step: 0
Training loss: 2.7338190003919967
Validation loss: 2.481961787677385

Epoch: 6| Step: 1
Training loss: 2.277513134580355
Validation loss: 2.481404125637957

Epoch: 6| Step: 2
Training loss: 2.5725890863561496
Validation loss: 2.489848890200511

Epoch: 6| Step: 3
Training loss: 2.0692880074970694
Validation loss: 2.479543117717791

Epoch: 6| Step: 4
Training loss: 3.056907686017044
Validation loss: 2.481869439764302

Epoch: 6| Step: 5
Training loss: 2.1618994082782095
Validation loss: 2.482586694863817

Epoch: 6| Step: 6
Training loss: 1.7537889335155281
Validation loss: 2.4823434068477037

Epoch: 6| Step: 7
Training loss: 2.6955127586384044
Validation loss: 2.479312096398733

Epoch: 6| Step: 8
Training loss: 2.5410546571752355
Validation loss: 2.4873589883065925

Epoch: 6| Step: 9
Training loss: 2.208410537617753
Validation loss: 2.4829503098963515

Epoch: 6| Step: 10
Training loss: 2.709494258803434
Validation loss: 2.4859202475661437

Epoch: 6| Step: 11
Training loss: 2.309528606917315
Validation loss: 2.4895809657725376

Epoch: 6| Step: 12
Training loss: 2.306615611303302
Validation loss: 2.4855179306935677

Epoch: 6| Step: 13
Training loss: 2.568767419463633
Validation loss: 2.478416783591712

Epoch: 158| Step: 0
Training loss: 2.7221840403813684
Validation loss: 2.4831188633066246

Epoch: 6| Step: 1
Training loss: 1.7869917033493343
Validation loss: 2.486641351947672

Epoch: 6| Step: 2
Training loss: 2.5070702711131405
Validation loss: 2.487255737478024

Epoch: 6| Step: 3
Training loss: 2.379032927148557
Validation loss: 2.487843473481463

Epoch: 6| Step: 4
Training loss: 3.1764708048377868
Validation loss: 2.4815316073282543

Epoch: 6| Step: 5
Training loss: 3.0084394321770276
Validation loss: 2.4879731966222622

Epoch: 6| Step: 6
Training loss: 2.195375271914506
Validation loss: 2.486046586599372

Epoch: 6| Step: 7
Training loss: 1.8277728401795041
Validation loss: 2.4884905844345435

Epoch: 6| Step: 8
Training loss: 1.6647306005513653
Validation loss: 2.483601959685334

Epoch: 6| Step: 9
Training loss: 2.2061560591887233
Validation loss: 2.483315263806172

Epoch: 6| Step: 10
Training loss: 2.66085210317062
Validation loss: 2.490105551585169

Epoch: 6| Step: 11
Training loss: 1.9343159877668372
Validation loss: 2.48537156372416

Epoch: 6| Step: 12
Training loss: 2.7930879153992656
Validation loss: 2.4846834355153424

Epoch: 6| Step: 13
Training loss: 2.7434414770504016
Validation loss: 2.492413629140513

Epoch: 159| Step: 0
Training loss: 1.9855382918750768
Validation loss: 2.493419585810034

Epoch: 6| Step: 1
Training loss: 2.5986287755981423
Validation loss: 2.4892913987697574

Epoch: 6| Step: 2
Training loss: 2.0669038169935225
Validation loss: 2.4989059438510264

Epoch: 6| Step: 3
Training loss: 2.4195534685079796
Validation loss: 2.4922836109790003

Epoch: 6| Step: 4
Training loss: 2.3189835258579747
Validation loss: 2.4974642927527575

Epoch: 6| Step: 5
Training loss: 2.4606733876752087
Validation loss: 2.4915046992228596

Epoch: 6| Step: 6
Training loss: 2.6702618106966205
Validation loss: 2.4805815263076627

Epoch: 6| Step: 7
Training loss: 2.32341089393759
Validation loss: 2.4809248617542017

Epoch: 6| Step: 8
Training loss: 2.6049613858983562
Validation loss: 2.490969321311233

Epoch: 6| Step: 9
Training loss: 2.360633362948931
Validation loss: 2.4898862827332082

Epoch: 6| Step: 10
Training loss: 2.9555060259015926
Validation loss: 2.4781706970542614

Epoch: 6| Step: 11
Training loss: 2.484368666154957
Validation loss: 2.4908485283573736

Epoch: 6| Step: 12
Training loss: 1.81097650625829
Validation loss: 2.4867634997634367

Epoch: 6| Step: 13
Training loss: 2.8209545640988196
Validation loss: 2.4919122844911334

Epoch: 160| Step: 0
Training loss: 1.6062129539640924
Validation loss: 2.4981232274297094

Epoch: 6| Step: 1
Training loss: 2.337021796122004
Validation loss: 2.496464088439887

Epoch: 6| Step: 2
Training loss: 3.0053488413701985
Validation loss: 2.4893005774480956

Epoch: 6| Step: 3
Training loss: 2.4840863138089877
Validation loss: 2.4942691922190705

Epoch: 6| Step: 4
Training loss: 2.413912376501223
Validation loss: 2.491113429277816

Epoch: 6| Step: 5
Training loss: 1.9144441807944057
Validation loss: 2.487294766571425

Epoch: 6| Step: 6
Training loss: 2.133246856168556
Validation loss: 2.4907089359653636

Epoch: 6| Step: 7
Training loss: 2.247869754710683
Validation loss: 2.493943698789027

Epoch: 6| Step: 8
Training loss: 2.722844515493714
Validation loss: 2.484416489484616

Epoch: 6| Step: 9
Training loss: 2.6338410222094724
Validation loss: 2.5001973551099725

Epoch: 6| Step: 10
Training loss: 2.7994039173510616
Validation loss: 2.4970015903127156

Epoch: 6| Step: 11
Training loss: 2.667906373664589
Validation loss: 2.5035020935515093

Epoch: 6| Step: 12
Training loss: 2.1565065093124645
Validation loss: 2.4980967588516836

Epoch: 6| Step: 13
Training loss: 2.62899585134731
Validation loss: 2.497120199947133

Epoch: 161| Step: 0
Training loss: 2.5902845833160297
Validation loss: 2.4942108678124653

Epoch: 6| Step: 1
Training loss: 1.8768224124864543
Validation loss: 2.4908540480786

Epoch: 6| Step: 2
Training loss: 2.9612685851338747
Validation loss: 2.49445846233191

Epoch: 6| Step: 3
Training loss: 2.2349292627870496
Validation loss: 2.485388535060313

Epoch: 6| Step: 4
Training loss: 2.6736849181541458
Validation loss: 2.485409854987233

Epoch: 6| Step: 5
Training loss: 2.3421640752495128
Validation loss: 2.4838910541180383

Epoch: 6| Step: 6
Training loss: 2.908540868777945
Validation loss: 2.484416073633543

Epoch: 6| Step: 7
Training loss: 2.1383793321608984
Validation loss: 2.476187435915062

Epoch: 6| Step: 8
Training loss: 2.578949859906805
Validation loss: 2.482438122175679

Epoch: 6| Step: 9
Training loss: 2.297568910580213
Validation loss: 2.486316194428265

Epoch: 6| Step: 10
Training loss: 2.5977791434452038
Validation loss: 2.5005501300790858

Epoch: 6| Step: 11
Training loss: 1.6636254538127657
Validation loss: 2.500723066669049

Epoch: 6| Step: 12
Training loss: 2.3330661643432595
Validation loss: 2.500702298384001

Epoch: 6| Step: 13
Training loss: 2.615143572802853
Validation loss: 2.5052337222223806

Epoch: 162| Step: 0
Training loss: 2.2772683708579797
Validation loss: 2.5099390585974852

Epoch: 6| Step: 1
Training loss: 1.8645122947870603
Validation loss: 2.5132429640769596

Epoch: 6| Step: 2
Training loss: 2.363030235894571
Validation loss: 2.5112836667594243

Epoch: 6| Step: 3
Training loss: 2.440520737847313
Validation loss: 2.497774357330489

Epoch: 6| Step: 4
Training loss: 2.224939872700786
Validation loss: 2.4982200484986956

Epoch: 6| Step: 5
Training loss: 2.475844029322473
Validation loss: 2.4852357408957246

Epoch: 6| Step: 6
Training loss: 3.045280939430882
Validation loss: 2.4805357836378774

Epoch: 6| Step: 7
Training loss: 2.5085482364827554
Validation loss: 2.4873282675192656

Epoch: 6| Step: 8
Training loss: 2.4321083691382213
Validation loss: 2.490959255455471

Epoch: 6| Step: 9
Training loss: 2.749296792026458
Validation loss: 2.484877561524557

Epoch: 6| Step: 10
Training loss: 3.1016286079030007
Validation loss: 2.489888676602219

Epoch: 6| Step: 11
Training loss: 2.3763265418618564
Validation loss: 2.489470289103238

Epoch: 6| Step: 12
Training loss: 2.3815556447674147
Validation loss: 2.480693881013293

Epoch: 6| Step: 13
Training loss: 2.1735184852545903
Validation loss: 2.48596928782173

Epoch: 163| Step: 0
Training loss: 2.1600617703683014
Validation loss: 2.488456939451432

Epoch: 6| Step: 1
Training loss: 2.2760446811775363
Validation loss: 2.486483480909367

Epoch: 6| Step: 2
Training loss: 2.848052909027434
Validation loss: 2.492845024020093

Epoch: 6| Step: 3
Training loss: 2.3188415385888717
Validation loss: 2.4945380308252427

Epoch: 6| Step: 4
Training loss: 2.2441601731633374
Validation loss: 2.5042967112494585

Epoch: 6| Step: 5
Training loss: 2.5484951927254973
Validation loss: 2.493303071193675

Epoch: 6| Step: 6
Training loss: 2.0796371350684977
Validation loss: 2.5136712742913194

Epoch: 6| Step: 7
Training loss: 1.9632401643849382
Validation loss: 2.5124601591883176

Epoch: 6| Step: 8
Training loss: 2.597029577398958
Validation loss: 2.4985903898516364

Epoch: 6| Step: 9
Training loss: 2.400019419114705
Validation loss: 2.487330983360787

Epoch: 6| Step: 10
Training loss: 2.112853057973077
Validation loss: 2.4955200745953405

Epoch: 6| Step: 11
Training loss: 3.1875804816164606
Validation loss: 2.4967920702553195

Epoch: 6| Step: 12
Training loss: 2.2575848210517284
Validation loss: 2.4907432285584234

Epoch: 6| Step: 13
Training loss: 2.8215334460614945
Validation loss: 2.4930817565202332

Epoch: 164| Step: 0
Training loss: 2.400445551045967
Validation loss: 2.4967965901094145

Epoch: 6| Step: 1
Training loss: 2.674551888838822
Validation loss: 2.488963562076047

Epoch: 6| Step: 2
Training loss: 2.6479124375816525
Validation loss: 2.4905145305543317

Epoch: 6| Step: 3
Training loss: 2.3898572499248383
Validation loss: 2.49796808639005

Epoch: 6| Step: 4
Training loss: 2.4561019619891122
Validation loss: 2.494669142059058

Epoch: 6| Step: 5
Training loss: 1.8730407014651584
Validation loss: 2.4882774173341753

Epoch: 6| Step: 6
Training loss: 2.557590433500056
Validation loss: 2.4973574023162093

Epoch: 6| Step: 7
Training loss: 2.6715346448630632
Validation loss: 2.4982163901397922

Epoch: 6| Step: 8
Training loss: 1.8786953432986757
Validation loss: 2.494163885483581

Epoch: 6| Step: 9
Training loss: 3.197010885354352
Validation loss: 2.5040000227470114

Epoch: 6| Step: 10
Training loss: 2.36483436181858
Validation loss: 2.499510208470233

Epoch: 6| Step: 11
Training loss: 2.1943961297791357
Validation loss: 2.5079273264930344

Epoch: 6| Step: 12
Training loss: 2.0635512013979724
Validation loss: 2.509691867165116

Epoch: 6| Step: 13
Training loss: 2.3122877075077097
Validation loss: 2.503418238588788

Epoch: 165| Step: 0
Training loss: 1.7799817974788616
Validation loss: 2.5034477143330665

Epoch: 6| Step: 1
Training loss: 1.6355689477991322
Validation loss: 2.5088377982860766

Epoch: 6| Step: 2
Training loss: 2.4802817927513514
Validation loss: 2.505572498101663

Epoch: 6| Step: 3
Training loss: 2.6960712636420565
Validation loss: 2.502066044637858

Epoch: 6| Step: 4
Training loss: 1.9141894862810833
Validation loss: 2.4999800204432345

Epoch: 6| Step: 5
Training loss: 3.0567423355681598
Validation loss: 2.4922496504891645

Epoch: 6| Step: 6
Training loss: 2.6315699511926374
Validation loss: 2.490025091415078

Epoch: 6| Step: 7
Training loss: 3.1061398338876463
Validation loss: 2.4845532367356316

Epoch: 6| Step: 8
Training loss: 2.4555726687476067
Validation loss: 2.48866624314088

Epoch: 6| Step: 9
Training loss: 1.95821845617253
Validation loss: 2.4885537693458044

Epoch: 6| Step: 10
Training loss: 2.5384995995626984
Validation loss: 2.485008478872979

Epoch: 6| Step: 11
Training loss: 2.3261679802260637
Validation loss: 2.4946920949753504

Epoch: 6| Step: 12
Training loss: 2.772932495561146
Validation loss: 2.4927537488061455

Epoch: 6| Step: 13
Training loss: 2.0411793912319274
Validation loss: 2.4964949992266225

Epoch: 166| Step: 0
Training loss: 2.135962873864865
Validation loss: 2.484400663103355

Epoch: 6| Step: 1
Training loss: 2.1527097082827416
Validation loss: 2.5024641132099874

Epoch: 6| Step: 2
Training loss: 2.0590079829990837
Validation loss: 2.4935130198732685

Epoch: 6| Step: 3
Training loss: 2.5429154960341687
Validation loss: 2.5052346263200995

Epoch: 6| Step: 4
Training loss: 2.47898385364957
Validation loss: 2.4963168669843627

Epoch: 6| Step: 5
Training loss: 2.3548497134645663
Validation loss: 2.501252456694335

Epoch: 6| Step: 6
Training loss: 2.0891089172456363
Validation loss: 2.5072233749955393

Epoch: 6| Step: 7
Training loss: 3.037651460113132
Validation loss: 2.505094360381436

Epoch: 6| Step: 8
Training loss: 2.4474131181237384
Validation loss: 2.5088734981929024

Epoch: 6| Step: 9
Training loss: 2.707033892213267
Validation loss: 2.50246451018298

Epoch: 6| Step: 10
Training loss: 2.174769277502759
Validation loss: 2.5007614168323897

Epoch: 6| Step: 11
Training loss: 2.739782077170245
Validation loss: 2.5046723969579876

Epoch: 6| Step: 12
Training loss: 1.9311745045544215
Validation loss: 2.50852291546131

Epoch: 6| Step: 13
Training loss: 2.665689905411724
Validation loss: 2.5074397648897517

Epoch: 167| Step: 0
Training loss: 2.7395985437316632
Validation loss: 2.5135282224971967

Epoch: 6| Step: 1
Training loss: 2.284022070970136
Validation loss: 2.5100371257219773

Epoch: 6| Step: 2
Training loss: 2.3296348233219257
Validation loss: 2.5048750234660004

Epoch: 6| Step: 3
Training loss: 2.559439529518373
Validation loss: 2.49995299930896

Epoch: 6| Step: 4
Training loss: 2.0130409414085717
Validation loss: 2.5037796536011774

Epoch: 6| Step: 5
Training loss: 2.3202029629421657
Validation loss: 2.491688470096517

Epoch: 6| Step: 6
Training loss: 2.2038573001698
Validation loss: 2.4866528255326297

Epoch: 6| Step: 7
Training loss: 2.3976950226225164
Validation loss: 2.499625638906993

Epoch: 6| Step: 8
Training loss: 2.2374828572389083
Validation loss: 2.4927583716269828

Epoch: 6| Step: 9
Training loss: 2.3567739131900343
Validation loss: 2.501540472349437

Epoch: 6| Step: 10
Training loss: 2.5473548109554645
Validation loss: 2.5006936859305795

Epoch: 6| Step: 11
Training loss: 2.8638041228329634
Validation loss: 2.5009034749505417

Epoch: 6| Step: 12
Training loss: 2.5482280857996797
Validation loss: 2.500620733128913

Epoch: 6| Step: 13
Training loss: 2.4948188498867006
Validation loss: 2.5004489495570232

Epoch: 168| Step: 0
Training loss: 2.453537827275758
Validation loss: 2.5103187436412764

Epoch: 6| Step: 1
Training loss: 2.1542986457381663
Validation loss: 2.532137209032605

Epoch: 6| Step: 2
Training loss: 2.573175661794234
Validation loss: 2.528159134315692

Epoch: 6| Step: 3
Training loss: 2.6857696995627447
Validation loss: 2.579269324762193

Epoch: 6| Step: 4
Training loss: 2.788032918716558
Validation loss: 2.5621533120570605

Epoch: 6| Step: 5
Training loss: 2.9988404258206427
Validation loss: 2.528870268479223

Epoch: 6| Step: 6
Training loss: 2.2734318369372124
Validation loss: 2.525032193069948

Epoch: 6| Step: 7
Training loss: 2.3734849815817647
Validation loss: 2.5084436717641996

Epoch: 6| Step: 8
Training loss: 2.011372064142738
Validation loss: 2.490223221099408

Epoch: 6| Step: 9
Training loss: 2.5224255874289354
Validation loss: 2.482171815152435

Epoch: 6| Step: 10
Training loss: 2.4482910735670713
Validation loss: 2.4945302094902293

Epoch: 6| Step: 11
Training loss: 2.7240661735899376
Validation loss: 2.4872013625236216

Epoch: 6| Step: 12
Training loss: 1.856786063525498
Validation loss: 2.4946405183137697

Epoch: 6| Step: 13
Training loss: 2.368052107534077
Validation loss: 2.4996870957695476

Epoch: 169| Step: 0
Training loss: 2.316136053322166
Validation loss: 2.4990252819901686

Epoch: 6| Step: 1
Training loss: 2.2911265574831927
Validation loss: 2.4875990063566507

Epoch: 6| Step: 2
Training loss: 2.626994238322561
Validation loss: 2.501087047753571

Epoch: 6| Step: 3
Training loss: 2.6565740051128093
Validation loss: 2.4933003618572838

Epoch: 6| Step: 4
Training loss: 1.9100484056979747
Validation loss: 2.495459518289746

Epoch: 6| Step: 5
Training loss: 2.3916583850819118
Validation loss: 2.4928170647654477

Epoch: 6| Step: 6
Training loss: 2.83598861438096
Validation loss: 2.500487979312087

Epoch: 6| Step: 7
Training loss: 2.4377498009644163
Validation loss: 2.4901466663347955

Epoch: 6| Step: 8
Training loss: 2.5703852217106062
Validation loss: 2.496725799342421

Epoch: 6| Step: 9
Training loss: 2.055965359822732
Validation loss: 2.4953077946449143

Epoch: 6| Step: 10
Training loss: 2.276876149665486
Validation loss: 2.496473543170177

Epoch: 6| Step: 11
Training loss: 2.3683189986365814
Validation loss: 2.510895858764353

Epoch: 6| Step: 12
Training loss: 2.8081939794752575
Validation loss: 2.493640296836722

Epoch: 6| Step: 13
Training loss: 2.4484804735143197
Validation loss: 2.511582548365154

Epoch: 170| Step: 0
Training loss: 2.2261329638107195
Validation loss: 2.522729244772942

Epoch: 6| Step: 1
Training loss: 2.6462214828489894
Validation loss: 2.518824120780605

Epoch: 6| Step: 2
Training loss: 2.5087561807523047
Validation loss: 2.523362590673931

Epoch: 6| Step: 3
Training loss: 2.6766301722748476
Validation loss: 2.5215702135843707

Epoch: 6| Step: 4
Training loss: 2.928265605469688
Validation loss: 2.522753722275845

Epoch: 6| Step: 5
Training loss: 2.3078615218259
Validation loss: 2.5280694641878965

Epoch: 6| Step: 6
Training loss: 1.9427207012311223
Validation loss: 2.5245456525986714

Epoch: 6| Step: 7
Training loss: 2.211760566555967
Validation loss: 2.5103865393470413

Epoch: 6| Step: 8
Training loss: 2.0868482565958475
Validation loss: 2.5035209180728635

Epoch: 6| Step: 9
Training loss: 2.1089925913854697
Validation loss: 2.5040422423474142

Epoch: 6| Step: 10
Training loss: 2.617219566034905
Validation loss: 2.499624430738317

Epoch: 6| Step: 11
Training loss: 2.079882574067974
Validation loss: 2.496978411961961

Epoch: 6| Step: 12
Training loss: 2.6427899576727576
Validation loss: 2.4940957443990825

Epoch: 6| Step: 13
Training loss: 2.612594354559201
Validation loss: 2.4973761379087174

Epoch: 171| Step: 0
Training loss: 2.1135536906685437
Validation loss: 2.496848822477552

Epoch: 6| Step: 1
Training loss: 2.9771407559415923
Validation loss: 2.4918866588816355

Epoch: 6| Step: 2
Training loss: 2.710856939432499
Validation loss: 2.490030612961641

Epoch: 6| Step: 3
Training loss: 2.6445959807324355
Validation loss: 2.4885361729004103

Epoch: 6| Step: 4
Training loss: 2.402266338310693
Validation loss: 2.4922254872391636

Epoch: 6| Step: 5
Training loss: 2.8199668947265173
Validation loss: 2.4876180390765237

Epoch: 6| Step: 6
Training loss: 2.02002537362054
Validation loss: 2.484857996088385

Epoch: 6| Step: 7
Training loss: 2.078581451537921
Validation loss: 2.489863413188571

Epoch: 6| Step: 8
Training loss: 2.44005724448921
Validation loss: 2.4977197579558927

Epoch: 6| Step: 9
Training loss: 2.540785548168563
Validation loss: 2.4957903626382922

Epoch: 6| Step: 10
Training loss: 1.8375629777560956
Validation loss: 2.496379280773158

Epoch: 6| Step: 11
Training loss: 2.769221838708481
Validation loss: 2.501450864678472

Epoch: 6| Step: 12
Training loss: 1.9781277456159054
Validation loss: 2.496161279376778

Epoch: 6| Step: 13
Training loss: 2.581934016672187
Validation loss: 2.493727197439269

Epoch: 172| Step: 0
Training loss: 2.2228390261513855
Validation loss: 2.491494795018388

Epoch: 6| Step: 1
Training loss: 2.601966070541846
Validation loss: 2.4913923695192457

Epoch: 6| Step: 2
Training loss: 3.0630981483987143
Validation loss: 2.4970464027721126

Epoch: 6| Step: 3
Training loss: 1.9983068690431383
Validation loss: 2.4986441909450248

Epoch: 6| Step: 4
Training loss: 2.285325472834158
Validation loss: 2.487399421588237

Epoch: 6| Step: 5
Training loss: 2.3922471670013787
Validation loss: 2.488886433720324

Epoch: 6| Step: 6
Training loss: 2.4849904575586836
Validation loss: 2.495430489594863

Epoch: 6| Step: 7
Training loss: 2.2521712105750673
Validation loss: 2.503818599696259

Epoch: 6| Step: 8
Training loss: 2.7418445687901962
Validation loss: 2.4927418091361124

Epoch: 6| Step: 9
Training loss: 2.223241638435538
Validation loss: 2.4986369072703574

Epoch: 6| Step: 10
Training loss: 2.3715918330460664
Validation loss: 2.509063575013672

Epoch: 6| Step: 11
Training loss: 2.33007832964427
Validation loss: 2.502123725389328

Epoch: 6| Step: 12
Training loss: 2.2385217560713553
Validation loss: 2.513218314889112

Epoch: 6| Step: 13
Training loss: 2.3161787722279628
Validation loss: 2.5162127264363354

Epoch: 173| Step: 0
Training loss: 2.532947583276299
Validation loss: 2.516867052609912

Epoch: 6| Step: 1
Training loss: 2.174932071019646
Validation loss: 2.5195860864157313

Epoch: 6| Step: 2
Training loss: 2.6735260976070876
Validation loss: 2.526829820094264

Epoch: 6| Step: 3
Training loss: 2.569725363785395
Validation loss: 2.5324062799031117

Epoch: 6| Step: 4
Training loss: 2.1814117721423236
Validation loss: 2.5300623929518835

Epoch: 6| Step: 5
Training loss: 2.667345367926339
Validation loss: 2.528810243666796

Epoch: 6| Step: 6
Training loss: 2.4068361039189874
Validation loss: 2.520678173891282

Epoch: 6| Step: 7
Training loss: 2.050274770046793
Validation loss: 2.523155771439054

Epoch: 6| Step: 8
Training loss: 1.5205918560186793
Validation loss: 2.518164653931368

Epoch: 6| Step: 9
Training loss: 2.8652150700184684
Validation loss: 2.5269902024767914

Epoch: 6| Step: 10
Training loss: 3.039075209093365
Validation loss: 2.5146045550125375

Epoch: 6| Step: 11
Training loss: 2.1340190004112456
Validation loss: 2.5125889751311985

Epoch: 6| Step: 12
Training loss: 1.753325980186757
Validation loss: 2.5041093590177663

Epoch: 6| Step: 13
Training loss: 2.561060989875068
Validation loss: 2.505824321958549

Epoch: 174| Step: 0
Training loss: 1.9237558109227908
Validation loss: 2.500067948371648

Epoch: 6| Step: 1
Training loss: 2.377509447754902
Validation loss: 2.5061294279324344

Epoch: 6| Step: 2
Training loss: 2.5421358728119556
Validation loss: 2.5035241083866544

Epoch: 6| Step: 3
Training loss: 2.352990917423356
Validation loss: 2.493747458141947

Epoch: 6| Step: 4
Training loss: 1.755955507831391
Validation loss: 2.5041868515809114

Epoch: 6| Step: 5
Training loss: 2.119382951654599
Validation loss: 2.4959479315744217

Epoch: 6| Step: 6
Training loss: 2.683146299237213
Validation loss: 2.5040830171887807

Epoch: 6| Step: 7
Training loss: 1.8445995119446803
Validation loss: 2.5132397228569547

Epoch: 6| Step: 8
Training loss: 2.173738407501143
Validation loss: 2.517591714637367

Epoch: 6| Step: 9
Training loss: 3.1076224290540924
Validation loss: 2.5122868838160453

Epoch: 6| Step: 10
Training loss: 3.062657877686771
Validation loss: 2.5119354803178084

Epoch: 6| Step: 11
Training loss: 2.5447787217508284
Validation loss: 2.51540939323263

Epoch: 6| Step: 12
Training loss: 2.368436074906386
Validation loss: 2.5157115123713174

Epoch: 6| Step: 13
Training loss: 2.295931460111832
Validation loss: 2.517935811063169

Epoch: 175| Step: 0
Training loss: 2.1107527013117786
Validation loss: 2.5311911462291783

Epoch: 6| Step: 1
Training loss: 1.7442910534277223
Validation loss: 2.518353169546346

Epoch: 6| Step: 2
Training loss: 2.9005502573389625
Validation loss: 2.530136240129318

Epoch: 6| Step: 3
Training loss: 2.786701474618797
Validation loss: 2.546833560661088

Epoch: 6| Step: 4
Training loss: 2.5742965478096056
Validation loss: 2.5375010379231653

Epoch: 6| Step: 5
Training loss: 2.4878173587340977
Validation loss: 2.528474424126596

Epoch: 6| Step: 6
Training loss: 2.692744438672098
Validation loss: 2.515905076383688

Epoch: 6| Step: 7
Training loss: 2.464185043316321
Validation loss: 2.5180671005933535

Epoch: 6| Step: 8
Training loss: 1.9164219852117206
Validation loss: 2.515733736266853

Epoch: 6| Step: 9
Training loss: 2.3104789769054745
Validation loss: 2.5115277587037053

Epoch: 6| Step: 10
Training loss: 1.9870448137057213
Validation loss: 2.5081285255775545

Epoch: 6| Step: 11
Training loss: 2.133532168639114
Validation loss: 2.4958752380784666

Epoch: 6| Step: 12
Training loss: 2.2287342923777405
Validation loss: 2.4919265403166264

Epoch: 6| Step: 13
Training loss: 3.0306213356227203
Validation loss: 2.505282051339472

Epoch: 176| Step: 0
Training loss: 2.681365352541237
Validation loss: 2.4984032140895787

Epoch: 6| Step: 1
Training loss: 2.5024183021037096
Validation loss: 2.5067246435525274

Epoch: 6| Step: 2
Training loss: 1.8663530600031522
Validation loss: 2.510975713464793

Epoch: 6| Step: 3
Training loss: 2.1869394946665808
Validation loss: 2.5071123993870716

Epoch: 6| Step: 4
Training loss: 2.4277008864532084
Validation loss: 2.5188105062406474

Epoch: 6| Step: 5
Training loss: 2.5546646350455653
Validation loss: 2.5270222808767406

Epoch: 6| Step: 6
Training loss: 2.101312331728059
Validation loss: 2.5309345064444986

Epoch: 6| Step: 7
Training loss: 2.2843729877593524
Validation loss: 2.5312155654511623

Epoch: 6| Step: 8
Training loss: 2.5216166537666798
Validation loss: 2.5428567559913966

Epoch: 6| Step: 9
Training loss: 2.8750437857569286
Validation loss: 2.5258443434158675

Epoch: 6| Step: 10
Training loss: 2.3210550783287633
Validation loss: 2.5242061330136987

Epoch: 6| Step: 11
Training loss: 2.1778206436107874
Validation loss: 2.5146274010232044

Epoch: 6| Step: 12
Training loss: 2.5320348582467154
Validation loss: 2.5006532451391834

Epoch: 6| Step: 13
Training loss: 2.5196808526624324
Validation loss: 2.5093049137372274

Epoch: 177| Step: 0
Training loss: 2.066509395685995
Validation loss: 2.502260854767081

Epoch: 6| Step: 1
Training loss: 2.164493338874477
Validation loss: 2.503251440924235

Epoch: 6| Step: 2
Training loss: 1.994826659318127
Validation loss: 2.5030013982169717

Epoch: 6| Step: 3
Training loss: 2.681314669453852
Validation loss: 2.503962460113594

Epoch: 6| Step: 4
Training loss: 2.930184202685886
Validation loss: 2.5041483158533033

Epoch: 6| Step: 5
Training loss: 2.2104818460943854
Validation loss: 2.490957420944888

Epoch: 6| Step: 6
Training loss: 1.8870705855024552
Validation loss: 2.5015536566853402

Epoch: 6| Step: 7
Training loss: 1.9583869547976671
Validation loss: 2.501318536188338

Epoch: 6| Step: 8
Training loss: 2.7429722372243126
Validation loss: 2.4946332229494277

Epoch: 6| Step: 9
Training loss: 1.9602663631838728
Validation loss: 2.4925836389780844

Epoch: 6| Step: 10
Training loss: 3.6536194557258286
Validation loss: 2.487806497474051

Epoch: 6| Step: 11
Training loss: 2.40506636006568
Validation loss: 2.496210564161915

Epoch: 6| Step: 12
Training loss: 2.209603813873027
Validation loss: 2.50420770997631

Epoch: 6| Step: 13
Training loss: 2.1963461617883335
Validation loss: 2.4957175292170946

Epoch: 178| Step: 0
Training loss: 2.603362414465851
Validation loss: 2.4845612174246168

Epoch: 6| Step: 1
Training loss: 2.3184689991589353
Validation loss: 2.491618546900501

Epoch: 6| Step: 2
Training loss: 1.9872469806962538
Validation loss: 2.5016196011489926

Epoch: 6| Step: 3
Training loss: 2.5793205494699034
Validation loss: 2.5020196624413207

Epoch: 6| Step: 4
Training loss: 2.6726070538910234
Validation loss: 2.522682982588918

Epoch: 6| Step: 5
Training loss: 2.2044425974324566
Validation loss: 2.5289962452425323

Epoch: 6| Step: 6
Training loss: 2.7594127820928747
Validation loss: 2.522216674777114

Epoch: 6| Step: 7
Training loss: 2.9785194672106368
Validation loss: 2.5259548736028896

Epoch: 6| Step: 8
Training loss: 2.0005845169409433
Validation loss: 2.520256139287064

Epoch: 6| Step: 9
Training loss: 2.2943857418963334
Validation loss: 2.5106221242908293

Epoch: 6| Step: 10
Training loss: 2.169842214692999
Validation loss: 2.5005330471150256

Epoch: 6| Step: 11
Training loss: 2.547641849330898
Validation loss: 2.5053401180085464

Epoch: 6| Step: 12
Training loss: 2.350011269562666
Validation loss: 2.5106392335697962

Epoch: 6| Step: 13
Training loss: 1.9836632360703172
Validation loss: 2.5047699881186136

Epoch: 179| Step: 0
Training loss: 2.7715028704401794
Validation loss: 2.511444836240997

Epoch: 6| Step: 1
Training loss: 2.8481834980538783
Validation loss: 2.4978122357408457

Epoch: 6| Step: 2
Training loss: 2.1352103032829355
Validation loss: 2.498090475704534

Epoch: 6| Step: 3
Training loss: 2.0296202944347246
Validation loss: 2.5049708935257904

Epoch: 6| Step: 4
Training loss: 1.8354916944406798
Validation loss: 2.5048636650756566

Epoch: 6| Step: 5
Training loss: 2.134764954897539
Validation loss: 2.5049802447648544

Epoch: 6| Step: 6
Training loss: 2.555068614658
Validation loss: 2.50109014584607

Epoch: 6| Step: 7
Training loss: 2.4073952265645926
Validation loss: 2.4992359106331867

Epoch: 6| Step: 8
Training loss: 2.746468270213503
Validation loss: 2.5160529363043467

Epoch: 6| Step: 9
Training loss: 2.509958650164801
Validation loss: 2.511053840744632

Epoch: 6| Step: 10
Training loss: 1.8383835102241486
Validation loss: 2.5220483631293713

Epoch: 6| Step: 11
Training loss: 2.34170768765215
Validation loss: 2.530922087477099

Epoch: 6| Step: 12
Training loss: 2.345405095945456
Validation loss: 2.5332681279407367

Epoch: 6| Step: 13
Training loss: 2.6941987763542596
Validation loss: 2.54958518369254

Epoch: 180| Step: 0
Training loss: 2.3511373446062023
Validation loss: 2.5411054168716696

Epoch: 6| Step: 1
Training loss: 2.5135807237200445
Validation loss: 2.5427282544868555

Epoch: 6| Step: 2
Training loss: 2.597496911231546
Validation loss: 2.5270583685899495

Epoch: 6| Step: 3
Training loss: 1.5711447564736605
Validation loss: 2.5441502386671258

Epoch: 6| Step: 4
Training loss: 1.7592481387866985
Validation loss: 2.5345903812301884

Epoch: 6| Step: 5
Training loss: 2.775383666725751
Validation loss: 2.5269699802957932

Epoch: 6| Step: 6
Training loss: 2.6376776865907297
Validation loss: 2.5277602232392193

Epoch: 6| Step: 7
Training loss: 2.8793101965482597
Validation loss: 2.5279891277403364

Epoch: 6| Step: 8
Training loss: 2.799157772097397
Validation loss: 2.52570569402957

Epoch: 6| Step: 9
Training loss: 2.193837386344341
Validation loss: 2.532423006640312

Epoch: 6| Step: 10
Training loss: 2.400768228601707
Validation loss: 2.5236899266391877

Epoch: 6| Step: 11
Training loss: 2.540781982376728
Validation loss: 2.5262358731732575

Epoch: 6| Step: 12
Training loss: 1.7693012416481004
Validation loss: 2.5063898442320443

Epoch: 6| Step: 13
Training loss: 2.103522198878423
Validation loss: 2.5069136231683165

Epoch: 181| Step: 0
Training loss: 1.9370405821480425
Validation loss: 2.4969904109427996

Epoch: 6| Step: 1
Training loss: 2.5500780804217658
Validation loss: 2.4982265778607298

Epoch: 6| Step: 2
Training loss: 2.380036985767109
Validation loss: 2.5147207621324563

Epoch: 6| Step: 3
Training loss: 2.3287834925963824
Validation loss: 2.508306896243601

Epoch: 6| Step: 4
Training loss: 2.267337967068249
Validation loss: 2.5153942910623526

Epoch: 6| Step: 5
Training loss: 2.821796227725465
Validation loss: 2.510497876722852

Epoch: 6| Step: 6
Training loss: 2.3444803752927976
Validation loss: 2.5137317554501637

Epoch: 6| Step: 7
Training loss: 2.189818652060566
Validation loss: 2.5093310423944266

Epoch: 6| Step: 8
Training loss: 3.1454223128515
Validation loss: 2.507447007146364

Epoch: 6| Step: 9
Training loss: 1.8795636904459692
Validation loss: 2.5099479401269504

Epoch: 6| Step: 10
Training loss: 1.649236982381233
Validation loss: 2.513010850534063

Epoch: 6| Step: 11
Training loss: 2.2646985494671243
Validation loss: 2.5216689235562018

Epoch: 6| Step: 12
Training loss: 2.5721605144740165
Validation loss: 2.510669194311219

Epoch: 6| Step: 13
Training loss: 2.724274733033532
Validation loss: 2.513646170863382

Epoch: 182| Step: 0
Training loss: 1.7769825998118776
Validation loss: 2.50846116024366

Epoch: 6| Step: 1
Training loss: 2.237538585649805
Validation loss: 2.5121233165893693

Epoch: 6| Step: 2
Training loss: 2.5370088224035827
Validation loss: 2.5160066777096723

Epoch: 6| Step: 3
Training loss: 2.2725360564507335
Validation loss: 2.5278639103347658

Epoch: 6| Step: 4
Training loss: 2.0868043848402222
Validation loss: 2.524971935380637

Epoch: 6| Step: 5
Training loss: 2.5363236430058196
Validation loss: 2.5251211999692407

Epoch: 6| Step: 6
Training loss: 2.7891970476453007
Validation loss: 2.5186901176913152

Epoch: 6| Step: 7
Training loss: 2.261853044439694
Validation loss: 2.5186890133273128

Epoch: 6| Step: 8
Training loss: 2.741951869828776
Validation loss: 2.515463158434434

Epoch: 6| Step: 9
Training loss: 2.458788220836251
Validation loss: 2.5125295419047498

Epoch: 6| Step: 10
Training loss: 2.1532617400976615
Validation loss: 2.5138123341373126

Epoch: 6| Step: 11
Training loss: 2.4788870987751985
Validation loss: 2.5264223552549683

Epoch: 6| Step: 12
Training loss: 1.9408869518944631
Validation loss: 2.515226139016216

Epoch: 6| Step: 13
Training loss: 2.73672541280769
Validation loss: 2.506016294977945

Epoch: 183| Step: 0
Training loss: 2.687781829250955
Validation loss: 2.5195578561408105

Epoch: 6| Step: 1
Training loss: 2.795631515867169
Validation loss: 2.5195000225172364

Epoch: 6| Step: 2
Training loss: 2.91306580380865
Validation loss: 2.5122750686117037

Epoch: 6| Step: 3
Training loss: 2.50225785340544
Validation loss: 2.512389714871377

Epoch: 6| Step: 4
Training loss: 2.2043672130286027
Validation loss: 2.5139174737821413

Epoch: 6| Step: 5
Training loss: 2.246933649011266
Validation loss: 2.5232356475942965

Epoch: 6| Step: 6
Training loss: 2.4961588915233257
Validation loss: 2.5315582338893727

Epoch: 6| Step: 7
Training loss: 2.1675985484175917
Validation loss: 2.5433671427296485

Epoch: 6| Step: 8
Training loss: 2.907631494462937
Validation loss: 2.5418465086884154

Epoch: 6| Step: 9
Training loss: 2.125512566176881
Validation loss: 2.54686974210918

Epoch: 6| Step: 10
Training loss: 2.211060429582738
Validation loss: 2.534265566468948

Epoch: 6| Step: 11
Training loss: 2.117798664238642
Validation loss: 2.5230567889017066

Epoch: 6| Step: 12
Training loss: 1.7656652395338548
Validation loss: 2.5111541192508056

Epoch: 6| Step: 13
Training loss: 2.109104619534692
Validation loss: 2.507535172415773

Epoch: 184| Step: 0
Training loss: 1.9106791585996152
Validation loss: 2.5066756606025185

Epoch: 6| Step: 1
Training loss: 3.0257581533136038
Validation loss: 2.5004670342668307

Epoch: 6| Step: 2
Training loss: 1.7425364328787125
Validation loss: 2.5144467329096423

Epoch: 6| Step: 3
Training loss: 2.602135122703635
Validation loss: 2.5041108823921716

Epoch: 6| Step: 4
Training loss: 2.8575468629213248
Validation loss: 2.5150601402458648

Epoch: 6| Step: 5
Training loss: 2.2575782733582805
Validation loss: 2.519228611002707

Epoch: 6| Step: 6
Training loss: 1.6755249254221973
Validation loss: 2.5315982359284472

Epoch: 6| Step: 7
Training loss: 2.5172689054125668
Validation loss: 2.545542300040998

Epoch: 6| Step: 8
Training loss: 2.2640702799682475
Validation loss: 2.529840979849566

Epoch: 6| Step: 9
Training loss: 1.9975423614058756
Validation loss: 2.5445155817005656

Epoch: 6| Step: 10
Training loss: 2.5027981357779074
Validation loss: 2.5325454097290496

Epoch: 6| Step: 11
Training loss: 2.59797636655376
Validation loss: 2.5252404321949324

Epoch: 6| Step: 12
Training loss: 2.7358802358058094
Validation loss: 2.541074954920426

Epoch: 6| Step: 13
Training loss: 2.313879271883275
Validation loss: 2.548142474678083

Epoch: 185| Step: 0
Training loss: 3.0213003564882803
Validation loss: 2.528750186001841

Epoch: 6| Step: 1
Training loss: 2.137326671867595
Validation loss: 2.5432023167226325

Epoch: 6| Step: 2
Training loss: 2.099623682727413
Validation loss: 2.5450588373903673

Epoch: 6| Step: 3
Training loss: 2.0747731647827754
Validation loss: 2.5373119716790793

Epoch: 6| Step: 4
Training loss: 2.229118726933828
Validation loss: 2.5400037067616568

Epoch: 6| Step: 5
Training loss: 2.2071420827397765
Validation loss: 2.524435391265272

Epoch: 6| Step: 6
Training loss: 2.451803154983065
Validation loss: 2.517936986773574

Epoch: 6| Step: 7
Training loss: 2.9256225053939175
Validation loss: 2.519149538445257

Epoch: 6| Step: 8
Training loss: 2.3470651196554644
Validation loss: 2.5249635630833325

Epoch: 6| Step: 9
Training loss: 2.6938946961663524
Validation loss: 2.5131379227051824

Epoch: 6| Step: 10
Training loss: 2.4787547519963393
Validation loss: 2.512619047049028

Epoch: 6| Step: 11
Training loss: 2.400746976320396
Validation loss: 2.5160008736094914

Epoch: 6| Step: 12
Training loss: 1.9912511083452549
Validation loss: 2.5195028771668353

Epoch: 6| Step: 13
Training loss: 2.034773719260333
Validation loss: 2.5090255259592236

Epoch: 186| Step: 0
Training loss: 2.1131815155243316
Validation loss: 2.5167680832552435

Epoch: 6| Step: 1
Training loss: 1.7044508786406767
Validation loss: 2.5149393825670745

Epoch: 6| Step: 2
Training loss: 2.0921904036122143
Validation loss: 2.5165010273551904

Epoch: 6| Step: 3
Training loss: 2.1142657061775276
Validation loss: 2.5247473609231363

Epoch: 6| Step: 4
Training loss: 2.833209783066853
Validation loss: 2.5361825191193477

Epoch: 6| Step: 5
Training loss: 3.1254735969254526
Validation loss: 2.546509074815816

Epoch: 6| Step: 6
Training loss: 2.5054661121836266
Validation loss: 2.555818406583741

Epoch: 6| Step: 7
Training loss: 2.688543250285326
Validation loss: 2.551465396937256

Epoch: 6| Step: 8
Training loss: 1.9028319686016477
Validation loss: 2.5592183600417524

Epoch: 6| Step: 9
Training loss: 2.2755620408876376
Validation loss: 2.544077212184108

Epoch: 6| Step: 10
Training loss: 2.2554539171609167
Validation loss: 2.541167324814739

Epoch: 6| Step: 11
Training loss: 2.668100647018787
Validation loss: 2.522263922278944

Epoch: 6| Step: 12
Training loss: 1.8675854629918196
Validation loss: 2.5220191678007757

Epoch: 6| Step: 13
Training loss: 2.7268511337925068
Validation loss: 2.5272998206572286

Epoch: 187| Step: 0
Training loss: 2.38056374420732
Validation loss: 2.510662451988541

Epoch: 6| Step: 1
Training loss: 2.0997104354312026
Validation loss: 2.5028466071843147

Epoch: 6| Step: 2
Training loss: 2.172074452854104
Validation loss: 2.499876750451086

Epoch: 6| Step: 3
Training loss: 2.2130970467216318
Validation loss: 2.505370300725042

Epoch: 6| Step: 4
Training loss: 2.673581387133047
Validation loss: 2.4907545157357194

Epoch: 6| Step: 5
Training loss: 1.9922981381081017
Validation loss: 2.4987236022954264

Epoch: 6| Step: 6
Training loss: 2.349115156421124
Validation loss: 2.5047850750252594

Epoch: 6| Step: 7
Training loss: 2.391452621115059
Validation loss: 2.5033891275777123

Epoch: 6| Step: 8
Training loss: 2.061735300429142
Validation loss: 2.4951747581573778

Epoch: 6| Step: 9
Training loss: 2.8682968945343355
Validation loss: 2.4964351350952825

Epoch: 6| Step: 10
Training loss: 2.9663884457487657
Validation loss: 2.506758946899749

Epoch: 6| Step: 11
Training loss: 2.6339853996445712
Validation loss: 2.515560236189988

Epoch: 6| Step: 12
Training loss: 2.670542780822217
Validation loss: 2.519096758931739

Epoch: 6| Step: 13
Training loss: 1.963629041864411
Validation loss: 2.530374681750621

Epoch: 188| Step: 0
Training loss: 2.544300111714748
Validation loss: 2.5356881749876696

Epoch: 6| Step: 1
Training loss: 2.5825095144947783
Validation loss: 2.558837350988985

Epoch: 6| Step: 2
Training loss: 1.877084336472842
Validation loss: 2.5448507678153622

Epoch: 6| Step: 3
Training loss: 2.6709827918866202
Validation loss: 2.5459027921334307

Epoch: 6| Step: 4
Training loss: 2.882872707492896
Validation loss: 2.559914005146485

Epoch: 6| Step: 5
Training loss: 1.8833373038776144
Validation loss: 2.564683650575425

Epoch: 6| Step: 6
Training loss: 2.498070162738402
Validation loss: 2.5575378413429037

Epoch: 6| Step: 7
Training loss: 2.0750754790768373
Validation loss: 2.555808875986085

Epoch: 6| Step: 8
Training loss: 2.3332930175386415
Validation loss: 2.5407729192999553

Epoch: 6| Step: 9
Training loss: 2.9191120976836045
Validation loss: 2.53721571051691

Epoch: 6| Step: 10
Training loss: 2.308364366214895
Validation loss: 2.519058522275431

Epoch: 6| Step: 11
Training loss: 2.415065519972342
Validation loss: 2.5283982495863566

Epoch: 6| Step: 12
Training loss: 2.1595871022087456
Validation loss: 2.522664852369851

Epoch: 6| Step: 13
Training loss: 1.9495995403783897
Validation loss: 2.5247810652841545

Epoch: 189| Step: 0
Training loss: 1.5410006175501016
Validation loss: 2.516973888095564

Epoch: 6| Step: 1
Training loss: 2.4964355807787775
Validation loss: 2.5255564797192704

Epoch: 6| Step: 2
Training loss: 2.0612664435235657
Validation loss: 2.5288556552398664

Epoch: 6| Step: 3
Training loss: 2.9339025667598837
Validation loss: 2.545889400441263

Epoch: 6| Step: 4
Training loss: 2.1439893138533783
Validation loss: 2.5367863395356

Epoch: 6| Step: 5
Training loss: 3.15786037342716
Validation loss: 2.540927878606231

Epoch: 6| Step: 6
Training loss: 2.788655569272262
Validation loss: 2.5494465083887

Epoch: 6| Step: 7
Training loss: 2.1811836604220067
Validation loss: 2.562373646668097

Epoch: 6| Step: 8
Training loss: 2.400637931282395
Validation loss: 2.5596746825850962

Epoch: 6| Step: 9
Training loss: 2.6146941649109343
Validation loss: 2.5460953406467173

Epoch: 6| Step: 10
Training loss: 2.1221413176972526
Validation loss: 2.5431675596403323

Epoch: 6| Step: 11
Training loss: 2.2280903175511724
Validation loss: 2.5247709768441022

Epoch: 6| Step: 12
Training loss: 2.048951937095486
Validation loss: 2.539696169300537

Epoch: 6| Step: 13
Training loss: 2.0140482331592615
Validation loss: 2.5220752735808483

Epoch: 190| Step: 0
Training loss: 1.5741093978575122
Validation loss: 2.511415296133339

Epoch: 6| Step: 1
Training loss: 2.8603060514580974
Validation loss: 2.506749023706156

Epoch: 6| Step: 2
Training loss: 2.574297288729823
Validation loss: 2.51508246469262

Epoch: 6| Step: 3
Training loss: 2.452910687263432
Validation loss: 2.5054299513617257

Epoch: 6| Step: 4
Training loss: 1.9932853516042106
Validation loss: 2.5101880540602988

Epoch: 6| Step: 5
Training loss: 2.885853060740202
Validation loss: 2.5134492709876946

Epoch: 6| Step: 6
Training loss: 1.9826231304670003
Validation loss: 2.515135794513335

Epoch: 6| Step: 7
Training loss: 2.1860178694766854
Validation loss: 2.522480754747374

Epoch: 6| Step: 8
Training loss: 2.4597638919382594
Validation loss: 2.5325605351454943

Epoch: 6| Step: 9
Training loss: 3.025359102482647
Validation loss: 2.512835367635813

Epoch: 6| Step: 10
Training loss: 2.656955311202339
Validation loss: 2.529742761534165

Epoch: 6| Step: 11
Training loss: 2.2481943938824167
Validation loss: 2.520665712274497

Epoch: 6| Step: 12
Training loss: 2.297323689134797
Validation loss: 2.520591603398465

Epoch: 6| Step: 13
Training loss: 2.085967788762131
Validation loss: 2.528091076472793

Epoch: 191| Step: 0
Training loss: 1.7019147159846846
Validation loss: 2.523462506023708

Epoch: 6| Step: 1
Training loss: 2.563431640231392
Validation loss: 2.528477912981874

Epoch: 6| Step: 2
Training loss: 2.56222886302551
Validation loss: 2.5400518514567145

Epoch: 6| Step: 3
Training loss: 2.8082871143676944
Validation loss: 2.5318616748095994

Epoch: 6| Step: 4
Training loss: 2.0229796845363106
Validation loss: 2.5367671196338804

Epoch: 6| Step: 5
Training loss: 2.0841305796740097
Validation loss: 2.513027959362198

Epoch: 6| Step: 6
Training loss: 2.1864392569771254
Validation loss: 2.5265809784486564

Epoch: 6| Step: 7
Training loss: 2.596787110825644
Validation loss: 2.517952594474453

Epoch: 6| Step: 8
Training loss: 2.63734638797292
Validation loss: 2.5142467032204188

Epoch: 6| Step: 9
Training loss: 2.632960465345569
Validation loss: 2.5091710040577477

Epoch: 6| Step: 10
Training loss: 1.724209800735016
Validation loss: 2.5184581748453625

Epoch: 6| Step: 11
Training loss: 2.5758865348812
Validation loss: 2.5117494888758234

Epoch: 6| Step: 12
Training loss: 2.298974770638581
Validation loss: 2.52307537303138

Epoch: 6| Step: 13
Training loss: 2.6728369336464852
Validation loss: 2.515116685646695

Epoch: 192| Step: 0
Training loss: 1.9346920092614415
Validation loss: 2.507944628442441

Epoch: 6| Step: 1
Training loss: 2.1399781300862197
Validation loss: 2.5104227712301106

Epoch: 6| Step: 2
Training loss: 1.4887708924794942
Validation loss: 2.498640103820151

Epoch: 6| Step: 3
Training loss: 2.457599034530728
Validation loss: 2.5001898057728624

Epoch: 6| Step: 4
Training loss: 2.3599769885347555
Validation loss: 2.5011269731337316

Epoch: 6| Step: 5
Training loss: 2.939439011853578
Validation loss: 2.5096895001019948

Epoch: 6| Step: 6
Training loss: 2.4872008752445267
Validation loss: 2.507475516395296

Epoch: 6| Step: 7
Training loss: 1.8699801960064766
Validation loss: 2.5084564396335005

Epoch: 6| Step: 8
Training loss: 2.8692064375110213
Validation loss: 2.5152149695560047

Epoch: 6| Step: 9
Training loss: 2.7725490812698945
Validation loss: 2.5162146214946253

Epoch: 6| Step: 10
Training loss: 2.166546329188692
Validation loss: 2.518376727089031

Epoch: 6| Step: 11
Training loss: 2.248242009341601
Validation loss: 2.5132096662713623

Epoch: 6| Step: 12
Training loss: 2.2660679877402257
Validation loss: 2.5209311999615087

Epoch: 6| Step: 13
Training loss: 2.6157152276559392
Validation loss: 2.5067568386206904

Epoch: 193| Step: 0
Training loss: 2.7766363045023503
Validation loss: 2.513122656674934

Epoch: 6| Step: 1
Training loss: 2.02578022372407
Validation loss: 2.5112001349367397

Epoch: 6| Step: 2
Training loss: 2.9253098804619855
Validation loss: 2.514734296104536

Epoch: 6| Step: 3
Training loss: 1.9032292429870565
Validation loss: 2.511527030909226

Epoch: 6| Step: 4
Training loss: 1.4940752002628674
Validation loss: 2.5181944146794306

Epoch: 6| Step: 5
Training loss: 2.3858423200307697
Validation loss: 2.53517889905157

Epoch: 6| Step: 6
Training loss: 2.398525373110341
Validation loss: 2.5396869302408454

Epoch: 6| Step: 7
Training loss: 2.521302634026918
Validation loss: 2.535445147385463

Epoch: 6| Step: 8
Training loss: 2.3201251741052347
Validation loss: 2.54573442315871

Epoch: 6| Step: 9
Training loss: 2.756760177625344
Validation loss: 2.5389027550158922

Epoch: 6| Step: 10
Training loss: 2.5474654373354992
Validation loss: 2.5310931059011152

Epoch: 6| Step: 11
Training loss: 1.850805328972546
Validation loss: 2.5276102970053405

Epoch: 6| Step: 12
Training loss: 2.6814818310937407
Validation loss: 2.5174175849513927

Epoch: 6| Step: 13
Training loss: 2.0045210283812582
Validation loss: 2.5353975421202004

Epoch: 194| Step: 0
Training loss: 2.5651575589634117
Validation loss: 2.521532660548196

Epoch: 6| Step: 1
Training loss: 2.10288080892218
Validation loss: 2.5238223023596653

Epoch: 6| Step: 2
Training loss: 2.770562371411594
Validation loss: 2.5205674359613797

Epoch: 6| Step: 3
Training loss: 2.1197572997460488
Validation loss: 2.5223234569671615

Epoch: 6| Step: 4
Training loss: 2.808740773816101
Validation loss: 2.5334953976751162

Epoch: 6| Step: 5
Training loss: 2.6401112073537405
Validation loss: 2.530812331614831

Epoch: 6| Step: 6
Training loss: 2.1749701092299407
Validation loss: 2.538353814234255

Epoch: 6| Step: 7
Training loss: 2.22785788883799
Validation loss: 2.5428869153209135

Epoch: 6| Step: 8
Training loss: 2.241681191303983
Validation loss: 2.543379664976078

Epoch: 6| Step: 9
Training loss: 2.2661755123195375
Validation loss: 2.551659830467523

Epoch: 6| Step: 10
Training loss: 2.138969282260524
Validation loss: 2.550159201296099

Epoch: 6| Step: 11
Training loss: 2.4282763145558133
Validation loss: 2.552092545680851

Epoch: 6| Step: 12
Training loss: 2.2756439722826647
Validation loss: 2.537140197801608

Epoch: 6| Step: 13
Training loss: 2.139743484203688
Validation loss: 2.5407681257872627

Epoch: 195| Step: 0
Training loss: 1.7870201213623904
Validation loss: 2.5378235283420856

Epoch: 6| Step: 1
Training loss: 2.024333858419361
Validation loss: 2.5366231928728884

Epoch: 6| Step: 2
Training loss: 1.9005356485324798
Validation loss: 2.521821850197291

Epoch: 6| Step: 3
Training loss: 2.197164277176579
Validation loss: 2.5326859753411473

Epoch: 6| Step: 4
Training loss: 1.9031667945920345
Validation loss: 2.5285138227665653

Epoch: 6| Step: 5
Training loss: 2.10796314603233
Validation loss: 2.5244659595578205

Epoch: 6| Step: 6
Training loss: 3.2154619032830793
Validation loss: 2.517443921418889

Epoch: 6| Step: 7
Training loss: 2.241358161694954
Validation loss: 2.5276282659849456

Epoch: 6| Step: 8
Training loss: 2.929629393955026
Validation loss: 2.532049531604839

Epoch: 6| Step: 9
Training loss: 2.7026407326217936
Validation loss: 2.5286575039490486

Epoch: 6| Step: 10
Training loss: 2.3595538545231425
Validation loss: 2.5364788271306495

Epoch: 6| Step: 11
Training loss: 1.9343482192840218
Validation loss: 2.53907222648127

Epoch: 6| Step: 12
Training loss: 2.5210454131730278
Validation loss: 2.5604869952888083

Epoch: 6| Step: 13
Training loss: 2.6064084487429184
Validation loss: 2.5486909598010055

Epoch: 196| Step: 0
Training loss: 2.6911322422372224
Validation loss: 2.564135347517441

Epoch: 6| Step: 1
Training loss: 2.3902315302154076
Validation loss: 2.5370945507905662

Epoch: 6| Step: 2
Training loss: 2.364237845524422
Validation loss: 2.53794896674897

Epoch: 6| Step: 3
Training loss: 2.7686358942841163
Validation loss: 2.536224383166379

Epoch: 6| Step: 4
Training loss: 2.2407553747917692
Validation loss: 2.5579044879334045

Epoch: 6| Step: 5
Training loss: 2.44073262191067
Validation loss: 2.5421269239802373

Epoch: 6| Step: 6
Training loss: 1.3401093066883316
Validation loss: 2.548638760875517

Epoch: 6| Step: 7
Training loss: 1.888321095410404
Validation loss: 2.5379939095013477

Epoch: 6| Step: 8
Training loss: 2.096079199787018
Validation loss: 2.533751205647299

Epoch: 6| Step: 9
Training loss: 2.7323778979216584
Validation loss: 2.549520214920615

Epoch: 6| Step: 10
Training loss: 2.4124317772266535
Validation loss: 2.5381651872466966

Epoch: 6| Step: 11
Training loss: 2.6772668877002297
Validation loss: 2.548509521838801

Epoch: 6| Step: 12
Training loss: 1.8125184156863479
Validation loss: 2.538172561010771

Epoch: 6| Step: 13
Training loss: 2.6524898168600277
Validation loss: 2.538398256713528

Epoch: 197| Step: 0
Training loss: 1.7875207646370963
Validation loss: 2.5285575267223837

Epoch: 6| Step: 1
Training loss: 2.3990616871518258
Validation loss: 2.5207766586952656

Epoch: 6| Step: 2
Training loss: 2.0334784388228035
Validation loss: 2.5180184645345673

Epoch: 6| Step: 3
Training loss: 2.1342140595063173
Validation loss: 2.5069187112499

Epoch: 6| Step: 4
Training loss: 2.682846387272558
Validation loss: 2.51351244504099

Epoch: 6| Step: 5
Training loss: 2.8195398175708446
Validation loss: 2.5066687252369335

Epoch: 6| Step: 6
Training loss: 2.7043969133237304
Validation loss: 2.5138818771189584

Epoch: 6| Step: 7
Training loss: 2.763497088940659
Validation loss: 2.5195836576782575

Epoch: 6| Step: 8
Training loss: 2.078802586278578
Validation loss: 2.5207663335382287

Epoch: 6| Step: 9
Training loss: 1.9578012257561144
Validation loss: 2.527488755434746

Epoch: 6| Step: 10
Training loss: 1.996238449435895
Validation loss: 2.53856939760594

Epoch: 6| Step: 11
Training loss: 2.7711685570642173
Validation loss: 2.5371084352745563

Epoch: 6| Step: 12
Training loss: 2.266339209221533
Validation loss: 2.5554013280585974

Epoch: 6| Step: 13
Training loss: 2.6957526248443995
Validation loss: 2.556751191517137

Epoch: 198| Step: 0
Training loss: 2.053169879393788
Validation loss: 2.5579236111502905

Epoch: 6| Step: 1
Training loss: 2.6248962745154962
Validation loss: 2.555248622729574

Epoch: 6| Step: 2
Training loss: 1.7734752768639614
Validation loss: 2.5741245250601126

Epoch: 6| Step: 3
Training loss: 3.016559831473248
Validation loss: 2.562181856208346

Epoch: 6| Step: 4
Training loss: 2.2625688658291994
Validation loss: 2.5609623552271805

Epoch: 6| Step: 5
Training loss: 2.3429139744282215
Validation loss: 2.556300020855489

Epoch: 6| Step: 6
Training loss: 2.8565599936914667
Validation loss: 2.5378372757482874

Epoch: 6| Step: 7
Training loss: 2.683062949290597
Validation loss: 2.5232894428858823

Epoch: 6| Step: 8
Training loss: 2.5161935862676024
Validation loss: 2.521267519883533

Epoch: 6| Step: 9
Training loss: 2.2070825621454917
Validation loss: 2.506469763223822

Epoch: 6| Step: 10
Training loss: 2.2152996905873055
Validation loss: 2.513220148961446

Epoch: 6| Step: 11
Training loss: 2.2078752102487047
Validation loss: 2.5094490613574223

Epoch: 6| Step: 12
Training loss: 1.8225094876349839
Validation loss: 2.5144846288171134

Epoch: 6| Step: 13
Training loss: 1.7734482550610002
Validation loss: 2.524856121383019

Epoch: 199| Step: 0
Training loss: 2.258400810706939
Validation loss: 2.515510651258235

Epoch: 6| Step: 1
Training loss: 2.2548004439332696
Validation loss: 2.538136819190266

Epoch: 6| Step: 2
Training loss: 2.6794667500580687
Validation loss: 2.52501029494047

Epoch: 6| Step: 3
Training loss: 2.3519321290558235
Validation loss: 2.549127358986398

Epoch: 6| Step: 4
Training loss: 2.1419131447629365
Validation loss: 2.544546533417083

Epoch: 6| Step: 5
Training loss: 2.3680487850486447
Validation loss: 2.561539725900128

Epoch: 6| Step: 6
Training loss: 2.6124538143766247
Validation loss: 2.5821421604699504

Epoch: 6| Step: 7
Training loss: 2.243211678450872
Validation loss: 2.592019388497212

Epoch: 6| Step: 8
Training loss: 1.9981099973609948
Validation loss: 2.605021486492713

Epoch: 6| Step: 9
Training loss: 2.69347020087887
Validation loss: 2.6143843637168485

Epoch: 6| Step: 10
Training loss: 1.6760714619771726
Validation loss: 2.6050617104052898

Epoch: 6| Step: 11
Training loss: 2.180088894982692
Validation loss: 2.5969446416973954

Epoch: 6| Step: 12
Training loss: 2.9125318009764665
Validation loss: 2.587029494478349

Epoch: 6| Step: 13
Training loss: 2.2086301160314097
Validation loss: 2.5677026951065733

Epoch: 200| Step: 0
Training loss: 1.5363741404424138
Validation loss: 2.540944705631234

Epoch: 6| Step: 1
Training loss: 2.3324002943572264
Validation loss: 2.532156385613255

Epoch: 6| Step: 2
Training loss: 2.2471191188745694
Validation loss: 2.501490371239264

Epoch: 6| Step: 3
Training loss: 2.1117917380242774
Validation loss: 2.487555461373887

Epoch: 6| Step: 4
Training loss: 2.1213467554202867
Validation loss: 2.4940841616634777

Epoch: 6| Step: 5
Training loss: 3.0183641712362403
Validation loss: 2.4877701278800997

Epoch: 6| Step: 6
Training loss: 2.236838842986004
Validation loss: 2.499216608648962

Epoch: 6| Step: 7
Training loss: 2.859265935099789
Validation loss: 2.495251660291046

Epoch: 6| Step: 8
Training loss: 3.163556093734253
Validation loss: 2.4918975501965277

Epoch: 6| Step: 9
Training loss: 2.543594025649883
Validation loss: 2.4884060639238488

Epoch: 6| Step: 10
Training loss: 2.1069768766375447
Validation loss: 2.492334662450307

Epoch: 6| Step: 11
Training loss: 2.1440152240540042
Validation loss: 2.5012838722742976

Epoch: 6| Step: 12
Training loss: 2.5339306424170007
Validation loss: 2.512704310800744

Epoch: 6| Step: 13
Training loss: 2.098836385688308
Validation loss: 2.539163378154285

Epoch: 201| Step: 0
Training loss: 2.7426444430986248
Validation loss: 2.533815394722728

Epoch: 6| Step: 1
Training loss: 2.8656597172787937
Validation loss: 2.564376500639297

Epoch: 6| Step: 2
Training loss: 1.8690695754113251
Validation loss: 2.5703878343358166

Epoch: 6| Step: 3
Training loss: 1.6032776371381958
Validation loss: 2.5813834204379185

Epoch: 6| Step: 4
Training loss: 2.064930148848334
Validation loss: 2.5868821584352575

Epoch: 6| Step: 5
Training loss: 2.544945295903837
Validation loss: 2.5736960390253865

Epoch: 6| Step: 6
Training loss: 1.9582071331294384
Validation loss: 2.5565967327767196

Epoch: 6| Step: 7
Training loss: 2.4588592958036575
Validation loss: 2.562745439203779

Epoch: 6| Step: 8
Training loss: 2.1278803882253903
Validation loss: 2.556791102461836

Epoch: 6| Step: 9
Training loss: 2.398164416743078
Validation loss: 2.54430111125525

Epoch: 6| Step: 10
Training loss: 2.4118005717058497
Validation loss: 2.5381516294844477

Epoch: 6| Step: 11
Training loss: 2.7340746905401376
Validation loss: 2.540580209835387

Epoch: 6| Step: 12
Training loss: 2.6903182932644767
Validation loss: 2.537987850378569

Epoch: 6| Step: 13
Training loss: 1.927354522044089
Validation loss: 2.533475901854286

Epoch: 202| Step: 0
Training loss: 2.732755170322225
Validation loss: 2.521701376924644

Epoch: 6| Step: 1
Training loss: 2.279002297266781
Validation loss: 2.527502244620705

Epoch: 6| Step: 2
Training loss: 2.5255175069633777
Validation loss: 2.5502340402598938

Epoch: 6| Step: 3
Training loss: 2.0422671336822233
Validation loss: 2.533293978067518

Epoch: 6| Step: 4
Training loss: 3.353456188957131
Validation loss: 2.5398750139758963

Epoch: 6| Step: 5
Training loss: 2.2876441910121494
Validation loss: 2.540435998572052

Epoch: 6| Step: 6
Training loss: 2.623293367280967
Validation loss: 2.5491201883821613

Epoch: 6| Step: 7
Training loss: 2.556049135705937
Validation loss: 2.547188191571932

Epoch: 6| Step: 8
Training loss: 2.204391872772978
Validation loss: 2.549567330498203

Epoch: 6| Step: 9
Training loss: 1.8859198796192642
Validation loss: 2.54665587561087

Epoch: 6| Step: 10
Training loss: 1.8985974907667504
Validation loss: 2.565004783809333

Epoch: 6| Step: 11
Training loss: 2.091824913371261
Validation loss: 2.5503179140068144

Epoch: 6| Step: 12
Training loss: 1.8883174970096896
Validation loss: 2.551174349674864

Epoch: 6| Step: 13
Training loss: 2.062197345144209
Validation loss: 2.5456676312685733

Epoch: 203| Step: 0
Training loss: 1.7949564103383258
Validation loss: 2.540122615853325

Epoch: 6| Step: 1
Training loss: 1.7349230613469102
Validation loss: 2.5391073526186623

Epoch: 6| Step: 2
Training loss: 2.3630106621306775
Validation loss: 2.5330906992297555

Epoch: 6| Step: 3
Training loss: 1.831491354182251
Validation loss: 2.520695538078101

Epoch: 6| Step: 4
Training loss: 2.3515921049060453
Validation loss: 2.5298447652544613

Epoch: 6| Step: 5
Training loss: 2.359704001016252
Validation loss: 2.5218309577458586

Epoch: 6| Step: 6
Training loss: 2.907516531663573
Validation loss: 2.5231209035705824

Epoch: 6| Step: 7
Training loss: 1.8026962854860156
Validation loss: 2.5181494736052215

Epoch: 6| Step: 8
Training loss: 2.209349584365838
Validation loss: 2.5306711045130146

Epoch: 6| Step: 9
Training loss: 2.375907022044146
Validation loss: 2.5404788404951337

Epoch: 6| Step: 10
Training loss: 2.4816634057174927
Validation loss: 2.534186994460002

Epoch: 6| Step: 11
Training loss: 2.5927099877476474
Validation loss: 2.5410123879296975

Epoch: 6| Step: 12
Training loss: 2.887039682927538
Validation loss: 2.5220894692009836

Epoch: 6| Step: 13
Training loss: 2.7126242367468403
Validation loss: 2.5317035158885544

Epoch: 204| Step: 0
Training loss: 2.1298558348460546
Validation loss: 2.53317325822473

Epoch: 6| Step: 1
Training loss: 2.3563113500566435
Validation loss: 2.5351164843590523

Epoch: 6| Step: 2
Training loss: 3.0202880542632182
Validation loss: 2.542859428153687

Epoch: 6| Step: 3
Training loss: 1.9328113552820985
Validation loss: 2.5430187214572144

Epoch: 6| Step: 4
Training loss: 2.219576614490974
Validation loss: 2.5704685306825303

Epoch: 6| Step: 5
Training loss: 2.258775974075785
Validation loss: 2.5539578514763543

Epoch: 6| Step: 6
Training loss: 2.2323334443607488
Validation loss: 2.57729885851989

Epoch: 6| Step: 7
Training loss: 2.374199079687509
Validation loss: 2.5580628598989703

Epoch: 6| Step: 8
Training loss: 2.672441835118412
Validation loss: 2.5640354983411084

Epoch: 6| Step: 9
Training loss: 1.9479465652319998
Validation loss: 2.547791579371296

Epoch: 6| Step: 10
Training loss: 2.769581696087203
Validation loss: 2.5548753892903333

Epoch: 6| Step: 11
Training loss: 2.079658114872697
Validation loss: 2.5628614015739264

Epoch: 6| Step: 12
Training loss: 2.527727855520104
Validation loss: 2.564272569864802

Epoch: 6| Step: 13
Training loss: 1.7188274019325727
Validation loss: 2.5569715642679434

Epoch: 205| Step: 0
Training loss: 2.446480858873511
Validation loss: 2.542854271346747

Epoch: 6| Step: 1
Training loss: 2.284667186080626
Validation loss: 2.5464029947396503

Epoch: 6| Step: 2
Training loss: 2.7803519867284754
Validation loss: 2.5313415510787505

Epoch: 6| Step: 3
Training loss: 1.8296712873019094
Validation loss: 2.537691139200731

Epoch: 6| Step: 4
Training loss: 2.4625035707089635
Validation loss: 2.539788573694514

Epoch: 6| Step: 5
Training loss: 2.4663537866609007
Validation loss: 2.545893161984289

Epoch: 6| Step: 6
Training loss: 1.967761927114288
Validation loss: 2.5448617915889633

Epoch: 6| Step: 7
Training loss: 1.739897313212036
Validation loss: 2.5385189002676327

Epoch: 6| Step: 8
Training loss: 2.216588323924858
Validation loss: 2.539929896160697

Epoch: 6| Step: 9
Training loss: 1.9600587372834197
Validation loss: 2.5443027042721136

Epoch: 6| Step: 10
Training loss: 2.3638328223845733
Validation loss: 2.5580751937042625

Epoch: 6| Step: 11
Training loss: 2.5040146064819786
Validation loss: 2.562455200175864

Epoch: 6| Step: 12
Training loss: 2.575040046602706
Validation loss: 2.5749017005354693

Epoch: 6| Step: 13
Training loss: 2.768945457155512
Validation loss: 2.5779486239433567

Epoch: 206| Step: 0
Training loss: 1.8447043971380441
Validation loss: 2.574783579672727

Epoch: 6| Step: 1
Training loss: 2.5474553295408064
Validation loss: 2.547123387868026

Epoch: 6| Step: 2
Training loss: 2.315543363009858
Validation loss: 2.520424767689975

Epoch: 6| Step: 3
Training loss: 1.865034641936162
Validation loss: 2.510530624863331

Epoch: 6| Step: 4
Training loss: 2.74741259143413
Validation loss: 2.5091534571794565

Epoch: 6| Step: 5
Training loss: 2.1458844916408815
Validation loss: 2.50487018505183

Epoch: 6| Step: 6
Training loss: 2.086473717508212
Validation loss: 2.498534361055342

Epoch: 6| Step: 7
Training loss: 1.820158661329814
Validation loss: 2.498314861749315

Epoch: 6| Step: 8
Training loss: 2.0447255270767033
Validation loss: 2.5057379201829835

Epoch: 6| Step: 9
Training loss: 2.770442753465939
Validation loss: 2.4999793846551954

Epoch: 6| Step: 10
Training loss: 2.4258208586427643
Validation loss: 2.5108286623737768

Epoch: 6| Step: 11
Training loss: 2.8211186913122233
Validation loss: 2.5047901357022986

Epoch: 6| Step: 12
Training loss: 2.4307473376466584
Validation loss: 2.5324206215963576

Epoch: 6| Step: 13
Training loss: 2.6985623876920304
Validation loss: 2.5215801414861954

Epoch: 207| Step: 0
Training loss: 2.1295738363405645
Validation loss: 2.519813273414637

Epoch: 6| Step: 1
Training loss: 1.9574950500464672
Validation loss: 2.531711771724157

Epoch: 6| Step: 2
Training loss: 2.4695172626566273
Validation loss: 2.5210582275536

Epoch: 6| Step: 3
Training loss: 2.103743771902511
Validation loss: 2.5141687936956125

Epoch: 6| Step: 4
Training loss: 2.1424968916203886
Validation loss: 2.5163746066444412

Epoch: 6| Step: 5
Training loss: 2.405766921660068
Validation loss: 2.5321703520985945

Epoch: 6| Step: 6
Training loss: 2.0873828695180765
Validation loss: 2.5176188779087

Epoch: 6| Step: 7
Training loss: 3.053540573027961
Validation loss: 2.5145843359421884

Epoch: 6| Step: 8
Training loss: 1.7979705124708245
Validation loss: 2.5318212296309985

Epoch: 6| Step: 9
Training loss: 2.1031600382409934
Validation loss: 2.5256363743487604

Epoch: 6| Step: 10
Training loss: 3.221486826174495
Validation loss: 2.530246284444193

Epoch: 6| Step: 11
Training loss: 2.8645170076957003
Validation loss: 2.5401909144934347

Epoch: 6| Step: 12
Training loss: 2.2171018684738937
Validation loss: 2.5540930535649076

Epoch: 6| Step: 13
Training loss: 1.7943965238517938
Validation loss: 2.573911842493417

Epoch: 208| Step: 0
Training loss: 2.058268975655869
Validation loss: 2.573400588350868

Epoch: 6| Step: 1
Training loss: 1.8741184705499527
Validation loss: 2.57495014179441

Epoch: 6| Step: 2
Training loss: 1.7888952451926035
Validation loss: 2.554304477236777

Epoch: 6| Step: 3
Training loss: 2.5715801973900962
Validation loss: 2.5243804162031807

Epoch: 6| Step: 4
Training loss: 2.84806479622499
Validation loss: 2.5163912109759368

Epoch: 6| Step: 5
Training loss: 2.3536987739940667
Validation loss: 2.5232839941175644

Epoch: 6| Step: 6
Training loss: 2.1962139410229717
Validation loss: 2.516825387593775

Epoch: 6| Step: 7
Training loss: 3.256578829337913
Validation loss: 2.5139793557690386

Epoch: 6| Step: 8
Training loss: 2.0239660095708003
Validation loss: 2.5277940917856845

Epoch: 6| Step: 9
Training loss: 1.8989324984011113
Validation loss: 2.526618582268822

Epoch: 6| Step: 10
Training loss: 2.7482691432966644
Validation loss: 2.5350982863153235

Epoch: 6| Step: 11
Training loss: 2.2379460108690505
Validation loss: 2.546193911359618

Epoch: 6| Step: 12
Training loss: 2.2050129261632727
Validation loss: 2.559838711840873

Epoch: 6| Step: 13
Training loss: 2.155076523061644
Validation loss: 2.556810575917038

Epoch: 209| Step: 0
Training loss: 2.267751918707385
Validation loss: 2.581344474683053

Epoch: 6| Step: 1
Training loss: 2.1313222073043945
Validation loss: 2.5852456603156906

Epoch: 6| Step: 2
Training loss: 2.2789995772665583
Validation loss: 2.5609662342767567

Epoch: 6| Step: 3
Training loss: 1.7958274109544332
Validation loss: 2.5636597776788705

Epoch: 6| Step: 4
Training loss: 2.674810213861122
Validation loss: 2.5508968371869805

Epoch: 6| Step: 5
Training loss: 2.0763595079989208
Validation loss: 2.5692995156548815

Epoch: 6| Step: 6
Training loss: 2.3813640256799746
Validation loss: 2.5453153175820806

Epoch: 6| Step: 7
Training loss: 2.0567150482884005
Validation loss: 2.537536663423203

Epoch: 6| Step: 8
Training loss: 2.984791511909646
Validation loss: 2.548193069795113

Epoch: 6| Step: 9
Training loss: 2.794653409783877
Validation loss: 2.533611279431968

Epoch: 6| Step: 10
Training loss: 2.114561246809846
Validation loss: 2.5252800386452026

Epoch: 6| Step: 11
Training loss: 1.9423715198892448
Validation loss: 2.520804686160238

Epoch: 6| Step: 12
Training loss: 2.616764774629578
Validation loss: 2.510597686783611

Epoch: 6| Step: 13
Training loss: 2.0439274655440975
Validation loss: 2.5151758681553176

Epoch: 210| Step: 0
Training loss: 2.0047348718554048
Validation loss: 2.5364216378212316

Epoch: 6| Step: 1
Training loss: 1.6827896215783906
Validation loss: 2.5360325972330315

Epoch: 6| Step: 2
Training loss: 1.9141989523069596
Validation loss: 2.5507626496318863

Epoch: 6| Step: 3
Training loss: 2.7610216353527965
Validation loss: 2.5527249652014907

Epoch: 6| Step: 4
Training loss: 2.1835901468482684
Validation loss: 2.5559472449603864

Epoch: 6| Step: 5
Training loss: 2.329019361920786
Validation loss: 2.5593311130609773

Epoch: 6| Step: 6
Training loss: 2.585054828940371
Validation loss: 2.5609903618331926

Epoch: 6| Step: 7
Training loss: 2.869337393269745
Validation loss: 2.555827004302847

Epoch: 6| Step: 8
Training loss: 2.5160372378530456
Validation loss: 2.5416351743737837

Epoch: 6| Step: 9
Training loss: 1.2151867544812203
Validation loss: 2.5527388425017894

Epoch: 6| Step: 10
Training loss: 2.703752830669669
Validation loss: 2.544836574246168

Epoch: 6| Step: 11
Training loss: 2.6854106854672306
Validation loss: 2.5606794247822973

Epoch: 6| Step: 12
Training loss: 2.195721679782836
Validation loss: 2.564466094356842

Epoch: 6| Step: 13
Training loss: 2.186933171538935
Validation loss: 2.567495268879574

Epoch: 211| Step: 0
Training loss: 2.129044778498977
Validation loss: 2.5556287207933597

Epoch: 6| Step: 1
Training loss: 2.2715534386668605
Validation loss: 2.591465675639439

Epoch: 6| Step: 2
Training loss: 2.74135922695738
Validation loss: 2.5720286181688463

Epoch: 6| Step: 3
Training loss: 2.236495498990417
Validation loss: 2.591709376000607

Epoch: 6| Step: 4
Training loss: 2.0188315265833974
Validation loss: 2.5885929790811977

Epoch: 6| Step: 5
Training loss: 2.473073529413302
Validation loss: 2.586940390353396

Epoch: 6| Step: 6
Training loss: 1.8188194078133555
Validation loss: 2.5434111460843534

Epoch: 6| Step: 7
Training loss: 2.1317352816365642
Validation loss: 2.5314148586260163

Epoch: 6| Step: 8
Training loss: 2.997148271020953
Validation loss: 2.5136702072426518

Epoch: 6| Step: 9
Training loss: 2.4973258020939517
Validation loss: 2.501487718425813

Epoch: 6| Step: 10
Training loss: 2.027184158541197
Validation loss: 2.502682137176113

Epoch: 6| Step: 11
Training loss: 2.513157552580864
Validation loss: 2.503934402823319

Epoch: 6| Step: 12
Training loss: 2.3422146663909844
Validation loss: 2.507085043033953

Epoch: 6| Step: 13
Training loss: 2.1676929195307597
Validation loss: 2.507900185007735

Epoch: 212| Step: 0
Training loss: 2.5722164071138405
Validation loss: 2.5171611668483855

Epoch: 6| Step: 1
Training loss: 2.2511117096088733
Validation loss: 2.5152216206832643

Epoch: 6| Step: 2
Training loss: 2.887438032798195
Validation loss: 2.524670940146075

Epoch: 6| Step: 3
Training loss: 2.336642461951575
Validation loss: 2.5311699842827835

Epoch: 6| Step: 4
Training loss: 2.4463629370706723
Validation loss: 2.554313857881651

Epoch: 6| Step: 5
Training loss: 2.3821814530040784
Validation loss: 2.582945892034082

Epoch: 6| Step: 6
Training loss: 1.8899854098367406
Validation loss: 2.562573765258982

Epoch: 6| Step: 7
Training loss: 1.8563617043327607
Validation loss: 2.5886062419570983

Epoch: 6| Step: 8
Training loss: 2.06227041180438
Validation loss: 2.592613936581122

Epoch: 6| Step: 9
Training loss: 2.5751737406365636
Validation loss: 2.5797362869982123

Epoch: 6| Step: 10
Training loss: 1.5323361028801552
Validation loss: 2.546889595660803

Epoch: 6| Step: 11
Training loss: 1.9126383563091969
Validation loss: 2.5383059582535523

Epoch: 6| Step: 12
Training loss: 2.628600058784708
Validation loss: 2.5316093252576324

Epoch: 6| Step: 13
Training loss: 2.5024085840073114
Validation loss: 2.5358394021713675

Epoch: 213| Step: 0
Training loss: 2.125853198935734
Validation loss: 2.516870304946682

Epoch: 6| Step: 1
Training loss: 2.6341937598967458
Validation loss: 2.517844174978763

Epoch: 6| Step: 2
Training loss: 2.641646960532958
Validation loss: 2.515468489870443

Epoch: 6| Step: 3
Training loss: 1.8307195656869697
Validation loss: 2.5188901258036593

Epoch: 6| Step: 4
Training loss: 2.1688116411139413
Validation loss: 2.5215675503786605

Epoch: 6| Step: 5
Training loss: 2.2115833431014726
Validation loss: 2.5106878780474133

Epoch: 6| Step: 6
Training loss: 2.088953702115027
Validation loss: 2.523763952407196

Epoch: 6| Step: 7
Training loss: 2.690881243299219
Validation loss: 2.5274013098048806

Epoch: 6| Step: 8
Training loss: 2.4946883040155328
Validation loss: 2.5418697859685064

Epoch: 6| Step: 9
Training loss: 1.8757114332266849
Validation loss: 2.536562615247687

Epoch: 6| Step: 10
Training loss: 2.0481812480505046
Validation loss: 2.543469951438396

Epoch: 6| Step: 11
Training loss: 2.324613649815953
Validation loss: 2.5508846711811795

Epoch: 6| Step: 12
Training loss: 2.2173870359804093
Validation loss: 2.548806384543197

Epoch: 6| Step: 13
Training loss: 2.5682485346211132
Validation loss: 2.564090630506598

Epoch: 214| Step: 0
Training loss: 1.4792574554662932
Validation loss: 2.561731261959313

Epoch: 6| Step: 1
Training loss: 1.9484439143095915
Validation loss: 2.5735877367831455

Epoch: 6| Step: 2
Training loss: 3.351014134645036
Validation loss: 2.5969357975752705

Epoch: 6| Step: 3
Training loss: 1.4196887972819712
Validation loss: 2.584544364548919

Epoch: 6| Step: 4
Training loss: 1.8846278639339804
Validation loss: 2.5612073444657733

Epoch: 6| Step: 5
Training loss: 2.7967898393164896
Validation loss: 2.5670719454285233

Epoch: 6| Step: 6
Training loss: 2.1231268312335714
Validation loss: 2.5441598129388394

Epoch: 6| Step: 7
Training loss: 3.0575686864865372
Validation loss: 2.5269591929697572

Epoch: 6| Step: 8
Training loss: 2.6037233102413064
Validation loss: 2.5151845416093885

Epoch: 6| Step: 9
Training loss: 2.378096419173945
Validation loss: 2.5020668387100935

Epoch: 6| Step: 10
Training loss: 2.2105322152969684
Validation loss: 2.4994314023956274

Epoch: 6| Step: 11
Training loss: 2.0541901077057574
Validation loss: 2.5064465693809512

Epoch: 6| Step: 12
Training loss: 1.8823688031765946
Validation loss: 2.5104936347865032

Epoch: 6| Step: 13
Training loss: 2.51335942387214
Validation loss: 2.526517879522219

Epoch: 215| Step: 0
Training loss: 2.76889052195915
Validation loss: 2.529179161602329

Epoch: 6| Step: 1
Training loss: 1.8629499416782445
Validation loss: 2.54765518501959

Epoch: 6| Step: 2
Training loss: 1.7756932906029916
Validation loss: 2.5388469898022947

Epoch: 6| Step: 3
Training loss: 2.5215870594772154
Validation loss: 2.5647855273526967

Epoch: 6| Step: 4
Training loss: 1.7494537318353873
Validation loss: 2.6241408410431353

Epoch: 6| Step: 5
Training loss: 2.4768881598716668
Validation loss: 2.6300294771222665

Epoch: 6| Step: 6
Training loss: 2.012984090834096
Validation loss: 2.642864037962551

Epoch: 6| Step: 7
Training loss: 2.2581160714157464
Validation loss: 2.6290721340283296

Epoch: 6| Step: 8
Training loss: 2.266659730545352
Validation loss: 2.634108559260109

Epoch: 6| Step: 9
Training loss: 3.2105599805631955
Validation loss: 2.5843972097147487

Epoch: 6| Step: 10
Training loss: 2.6423752982490725
Validation loss: 2.5670493610571423

Epoch: 6| Step: 11
Training loss: 1.6919093980452522
Validation loss: 2.547408221697018

Epoch: 6| Step: 12
Training loss: 2.657440457327449
Validation loss: 2.532697914978407

Epoch: 6| Step: 13
Training loss: 2.2886559447583603
Validation loss: 2.5423787531766955

Epoch: 216| Step: 0
Training loss: 2.198414413233322
Validation loss: 2.5316418944857273

Epoch: 6| Step: 1
Training loss: 2.632985457447196
Validation loss: 2.523993904176939

Epoch: 6| Step: 2
Training loss: 2.1731118172790715
Validation loss: 2.5322859100397714

Epoch: 6| Step: 3
Training loss: 2.304389546418015
Validation loss: 2.520962646152155

Epoch: 6| Step: 4
Training loss: 2.3364723639393623
Validation loss: 2.520222382295165

Epoch: 6| Step: 5
Training loss: 2.1216365899378675
Validation loss: 2.524677582101299

Epoch: 6| Step: 6
Training loss: 2.4635399031414362
Validation loss: 2.530039917978999

Epoch: 6| Step: 7
Training loss: 2.6648192463567155
Validation loss: 2.5480853834044064

Epoch: 6| Step: 8
Training loss: 3.017814513394728
Validation loss: 2.556280714501838

Epoch: 6| Step: 9
Training loss: 2.151762120468593
Validation loss: 2.574703774804937

Epoch: 6| Step: 10
Training loss: 2.1893755910111965
Validation loss: 2.58079747874016

Epoch: 6| Step: 11
Training loss: 1.678015084813802
Validation loss: 2.5842262283673056

Epoch: 6| Step: 12
Training loss: 2.4959399634134543
Validation loss: 2.5968148381761784

Epoch: 6| Step: 13
Training loss: 1.8484090356255505
Validation loss: 2.5847108357505704

Epoch: 217| Step: 0
Training loss: 2.2297370632466555
Validation loss: 2.5710155603834854

Epoch: 6| Step: 1
Training loss: 2.257190975190231
Validation loss: 2.5735409297204526

Epoch: 6| Step: 2
Training loss: 2.203964614501026
Validation loss: 2.5368729760950646

Epoch: 6| Step: 3
Training loss: 2.42829958412039
Validation loss: 2.5345927955876832

Epoch: 6| Step: 4
Training loss: 2.7613434489347486
Validation loss: 2.5158712768052047

Epoch: 6| Step: 5
Training loss: 2.331200942272449
Validation loss: 2.5070824912384007

Epoch: 6| Step: 6
Training loss: 2.270518628166444
Validation loss: 2.5141280085704456

Epoch: 6| Step: 7
Training loss: 2.240116239324655
Validation loss: 2.4861241307145603

Epoch: 6| Step: 8
Training loss: 2.4973635122828415
Validation loss: 2.4766152072436216

Epoch: 6| Step: 9
Training loss: 2.76018415707415
Validation loss: 2.4840387800617214

Epoch: 6| Step: 10
Training loss: 2.084019382686867
Validation loss: 2.4745317510660674

Epoch: 6| Step: 11
Training loss: 2.312769281328604
Validation loss: 2.465402627449062

Epoch: 6| Step: 12
Training loss: 2.078615288512802
Validation loss: 2.47297647099113

Epoch: 6| Step: 13
Training loss: 1.8558392927704759
Validation loss: 2.484048194103419

Epoch: 218| Step: 0
Training loss: 2.1997345070599525
Validation loss: 2.5016786979201306

Epoch: 6| Step: 1
Training loss: 2.32119467049486
Validation loss: 2.4971964693232596

Epoch: 6| Step: 2
Training loss: 1.8625683970341522
Validation loss: 2.5021125133209376

Epoch: 6| Step: 3
Training loss: 1.8406834073344545
Validation loss: 2.5337530013325247

Epoch: 6| Step: 4
Training loss: 2.459970823285515
Validation loss: 2.543729747344803

Epoch: 6| Step: 5
Training loss: 2.308978208489429
Validation loss: 2.5810640786912167

Epoch: 6| Step: 6
Training loss: 1.3554716522449568
Validation loss: 2.5717458931278347

Epoch: 6| Step: 7
Training loss: 2.409192354673833
Validation loss: 2.568409564128599

Epoch: 6| Step: 8
Training loss: 2.715207477601544
Validation loss: 2.5638781152510113

Epoch: 6| Step: 9
Training loss: 2.6132862678331406
Validation loss: 2.5759118493351134

Epoch: 6| Step: 10
Training loss: 2.428295558599853
Validation loss: 2.555526346809134

Epoch: 6| Step: 11
Training loss: 2.638565072609546
Validation loss: 2.5816222235751614

Epoch: 6| Step: 12
Training loss: 2.2793887135391513
Validation loss: 2.5710144012178406

Epoch: 6| Step: 13
Training loss: 2.411147545931342
Validation loss: 2.564773953995099

Epoch: 219| Step: 0
Training loss: 2.491634295539279
Validation loss: 2.556274465554203

Epoch: 6| Step: 1
Training loss: 1.555671112370247
Validation loss: 2.5779914436040503

Epoch: 6| Step: 2
Training loss: 1.814782776877772
Validation loss: 2.553077649378192

Epoch: 6| Step: 3
Training loss: 3.050266197970106
Validation loss: 2.5496006522037473

Epoch: 6| Step: 4
Training loss: 1.973535806196235
Validation loss: 2.54322256607823

Epoch: 6| Step: 5
Training loss: 2.2231572396099266
Validation loss: 2.5586267367267674

Epoch: 6| Step: 6
Training loss: 2.350355681428586
Validation loss: 2.5617310990880027

Epoch: 6| Step: 7
Training loss: 2.528539077176212
Validation loss: 2.581130285619709

Epoch: 6| Step: 8
Training loss: 2.3432095731102724
Validation loss: 2.5916050694087076

Epoch: 6| Step: 9
Training loss: 2.5792073145443206
Validation loss: 2.6161278852337833

Epoch: 6| Step: 10
Training loss: 2.0672917046380825
Validation loss: 2.598916603217137

Epoch: 6| Step: 11
Training loss: 2.2655273416452486
Validation loss: 2.5496528314364784

Epoch: 6| Step: 12
Training loss: 2.3750184710938798
Validation loss: 2.5135660532087036

Epoch: 6| Step: 13
Training loss: 2.242050326201927
Validation loss: 2.502962995057757

Epoch: 220| Step: 0
Training loss: 1.9414127587683272
Validation loss: 2.503739135688144

Epoch: 6| Step: 1
Training loss: 1.808368182688851
Validation loss: 2.503611356337674

Epoch: 6| Step: 2
Training loss: 2.5822698393454853
Validation loss: 2.50271212966501

Epoch: 6| Step: 3
Training loss: 2.7823063419535337
Validation loss: 2.5088796909821793

Epoch: 6| Step: 4
Training loss: 2.551676524429997
Validation loss: 2.4908563133941763

Epoch: 6| Step: 5
Training loss: 2.5213361086346815
Validation loss: 2.5062745826384445

Epoch: 6| Step: 6
Training loss: 1.9198479856474013
Validation loss: 2.516141044808497

Epoch: 6| Step: 7
Training loss: 1.8159484942774142
Validation loss: 2.5209459694743384

Epoch: 6| Step: 8
Training loss: 2.7070735251028
Validation loss: 2.5345410745302264

Epoch: 6| Step: 9
Training loss: 1.9439417900820846
Validation loss: 2.5910015634728083

Epoch: 6| Step: 10
Training loss: 2.452342595017797
Validation loss: 2.5883940584911853

Epoch: 6| Step: 11
Training loss: 2.609271749863596
Validation loss: 2.588411313822974

Epoch: 6| Step: 12
Training loss: 2.5028379544799737
Validation loss: 2.5841391034846493

Epoch: 6| Step: 13
Training loss: 2.2872339437882045
Validation loss: 2.5578291432424303

Epoch: 221| Step: 0
Training loss: 1.8658409210954916
Validation loss: 2.546169097369196

Epoch: 6| Step: 1
Training loss: 1.635263164467857
Validation loss: 2.5301164357277397

Epoch: 6| Step: 2
Training loss: 1.865652690534988
Validation loss: 2.536954487885684

Epoch: 6| Step: 3
Training loss: 2.119156375949528
Validation loss: 2.5328895612034965

Epoch: 6| Step: 4
Training loss: 1.8246928544446934
Validation loss: 2.535077627223633

Epoch: 6| Step: 5
Training loss: 1.9476291083852042
Validation loss: 2.532684516222616

Epoch: 6| Step: 6
Training loss: 1.9396632638667501
Validation loss: 2.5519057594854084

Epoch: 6| Step: 7
Training loss: 2.55452426773882
Validation loss: 2.546077782923326

Epoch: 6| Step: 8
Training loss: 2.395954250656768
Validation loss: 2.5726194222883456

Epoch: 6| Step: 9
Training loss: 2.5692880554261275
Validation loss: 2.5898311685646824

Epoch: 6| Step: 10
Training loss: 2.6063223702973883
Validation loss: 2.60129383063063

Epoch: 6| Step: 11
Training loss: 2.6053022019717083
Validation loss: 2.5824834492077042

Epoch: 6| Step: 12
Training loss: 2.9792649224001946
Validation loss: 2.5868484260255284

Epoch: 6| Step: 13
Training loss: 2.57862303576135
Validation loss: 2.574721137319915

Epoch: 222| Step: 0
Training loss: 2.083764934337534
Validation loss: 2.551723055159383

Epoch: 6| Step: 1
Training loss: 1.7650343995889082
Validation loss: 2.5414845813086138

Epoch: 6| Step: 2
Training loss: 1.938626976807632
Validation loss: 2.5436928651283948

Epoch: 6| Step: 3
Training loss: 2.124986424122248
Validation loss: 2.5271081672154776

Epoch: 6| Step: 4
Training loss: 1.5771222847580089
Validation loss: 2.523462742225522

Epoch: 6| Step: 5
Training loss: 2.7380306548247875
Validation loss: 2.5381177973854454

Epoch: 6| Step: 6
Training loss: 3.154395587900062
Validation loss: 2.5497922201836785

Epoch: 6| Step: 7
Training loss: 1.9423639096145313
Validation loss: 2.5843275115798225

Epoch: 6| Step: 8
Training loss: 2.33435801304531
Validation loss: 2.5878880146901144

Epoch: 6| Step: 9
Training loss: 2.0175249474931714
Validation loss: 2.6183802833046723

Epoch: 6| Step: 10
Training loss: 2.445108520970243
Validation loss: 2.6119131661187285

Epoch: 6| Step: 11
Training loss: 2.5146099435767293
Validation loss: 2.6054969187466774

Epoch: 6| Step: 12
Training loss: 2.5073291158210456
Validation loss: 2.5776714349831926

Epoch: 6| Step: 13
Training loss: 2.731893492430771
Validation loss: 2.5757235815912503

Epoch: 223| Step: 0
Training loss: 2.0817423149435226
Validation loss: 2.5671833009660356

Epoch: 6| Step: 1
Training loss: 1.668757303629119
Validation loss: 2.5536778561532394

Epoch: 6| Step: 2
Training loss: 1.9549608681316113
Validation loss: 2.5490345292783796

Epoch: 6| Step: 3
Training loss: 3.0107005336378228
Validation loss: 2.5379406137755693

Epoch: 6| Step: 4
Training loss: 2.2153836354229055
Validation loss: 2.5322747373675405

Epoch: 6| Step: 5
Training loss: 2.213495183718439
Validation loss: 2.5284654976641487

Epoch: 6| Step: 6
Training loss: 2.7587705682455317
Validation loss: 2.509226066885434

Epoch: 6| Step: 7
Training loss: 2.393743737115461
Validation loss: 2.519379580168747

Epoch: 6| Step: 8
Training loss: 1.9376803898666894
Validation loss: 2.494121076466926

Epoch: 6| Step: 9
Training loss: 2.588160271182013
Validation loss: 2.4996448105580904

Epoch: 6| Step: 10
Training loss: 2.29712556263799
Validation loss: 2.4959065462135883

Epoch: 6| Step: 11
Training loss: 2.1336746429562847
Validation loss: 2.506546493204591

Epoch: 6| Step: 12
Training loss: 2.639918215814222
Validation loss: 2.5095416611068995

Epoch: 6| Step: 13
Training loss: 1.7673633761121836
Validation loss: 2.52917178518499

Epoch: 224| Step: 0
Training loss: 1.8337601107141142
Validation loss: 2.5532259400925925

Epoch: 6| Step: 1
Training loss: 2.0693238398876557
Validation loss: 2.566378596682812

Epoch: 6| Step: 2
Training loss: 2.0657662624700954
Validation loss: 2.577373610924149

Epoch: 6| Step: 3
Training loss: 2.4918348487392
Validation loss: 2.5616470250866046

Epoch: 6| Step: 4
Training loss: 1.8694253702624983
Validation loss: 2.559103381625821

Epoch: 6| Step: 5
Training loss: 2.35803022649674
Validation loss: 2.5361009198439324

Epoch: 6| Step: 6
Training loss: 2.7939427524782925
Validation loss: 2.5415093315914317

Epoch: 6| Step: 7
Training loss: 2.612946219415287
Validation loss: 2.5393667811464864

Epoch: 6| Step: 8
Training loss: 2.6079283033181344
Validation loss: 2.533706438568037

Epoch: 6| Step: 9
Training loss: 2.548910065134037
Validation loss: 2.516307067021834

Epoch: 6| Step: 10
Training loss: 2.206192802573906
Validation loss: 2.5298877865328575

Epoch: 6| Step: 11
Training loss: 2.1341779760348794
Validation loss: 2.5416101751667965

Epoch: 6| Step: 12
Training loss: 1.515294147049113
Validation loss: 2.5614713759760543

Epoch: 6| Step: 13
Training loss: 2.330935631385726
Validation loss: 2.5480987323663666

Epoch: 225| Step: 0
Training loss: 2.306999986064036
Validation loss: 2.5908108646485606

Epoch: 6| Step: 1
Training loss: 2.754061127764794
Validation loss: 2.57187129932383

Epoch: 6| Step: 2
Training loss: 2.7487429433387707
Validation loss: 2.588686907638113

Epoch: 6| Step: 3
Training loss: 1.8200141105524055
Validation loss: 2.596613785221976

Epoch: 6| Step: 4
Training loss: 1.362479862449289
Validation loss: 2.5988334416798993

Epoch: 6| Step: 5
Training loss: 2.066880169986872
Validation loss: 2.595627254757911

Epoch: 6| Step: 6
Training loss: 2.7208547228156923
Validation loss: 2.5769485409599344

Epoch: 6| Step: 7
Training loss: 2.2695439612447927
Validation loss: 2.567441239048282

Epoch: 6| Step: 8
Training loss: 2.279649669602631
Validation loss: 2.533056250485644

Epoch: 6| Step: 9
Training loss: 2.876822515916812
Validation loss: 2.5356134865398876

Epoch: 6| Step: 10
Training loss: 2.281575845936154
Validation loss: 2.5224182148917875

Epoch: 6| Step: 11
Training loss: 2.0566453779696383
Validation loss: 2.519654886529142

Epoch: 6| Step: 12
Training loss: 1.599021421631348
Validation loss: 2.5309077372922286

Epoch: 6| Step: 13
Training loss: 2.310826804583691
Validation loss: 2.54410238238713

Epoch: 226| Step: 0
Training loss: 2.1070767916466635
Validation loss: 2.5398916758819934

Epoch: 6| Step: 1
Training loss: 2.677370365256534
Validation loss: 2.5594094099837585

Epoch: 6| Step: 2
Training loss: 2.1251553871338706
Validation loss: 2.578796029665493

Epoch: 6| Step: 3
Training loss: 1.8728057737976005
Validation loss: 2.603036441952852

Epoch: 6| Step: 4
Training loss: 2.292762864079781
Validation loss: 2.6182864031439625

Epoch: 6| Step: 5
Training loss: 2.2004766034679095
Validation loss: 2.6327029694998645

Epoch: 6| Step: 6
Training loss: 2.8204352439313265
Validation loss: 2.6615713186350476

Epoch: 6| Step: 7
Training loss: 2.1994339344728213
Validation loss: 2.6170603555189778

Epoch: 6| Step: 8
Training loss: 2.381777078762301
Validation loss: 2.603990050366677

Epoch: 6| Step: 9
Training loss: 2.268220769353506
Validation loss: 2.568647933627636

Epoch: 6| Step: 10
Training loss: 2.0853301460643388
Validation loss: 2.5643148585918927

Epoch: 6| Step: 11
Training loss: 2.3688590314024047
Validation loss: 2.561498260083446

Epoch: 6| Step: 12
Training loss: 2.5062498173511467
Validation loss: 2.5398141853569807

Epoch: 6| Step: 13
Training loss: 1.9160686333932653
Validation loss: 2.558814888053602

Epoch: 227| Step: 0
Training loss: 2.338283113886087
Validation loss: 2.5472141500317615

Epoch: 6| Step: 1
Training loss: 2.467563585507565
Validation loss: 2.526982921881281

Epoch: 6| Step: 2
Training loss: 2.3648590621729766
Validation loss: 2.5311118351155044

Epoch: 6| Step: 3
Training loss: 2.3450661587685464
Validation loss: 2.5303550284022673

Epoch: 6| Step: 4
Training loss: 2.0123396720759015
Validation loss: 2.525731228239594

Epoch: 6| Step: 5
Training loss: 2.581715897824797
Validation loss: 2.5417253351996845

Epoch: 6| Step: 6
Training loss: 1.5364442038021084
Validation loss: 2.537038784988164

Epoch: 6| Step: 7
Training loss: 2.0637648201034278
Validation loss: 2.5405277973394353

Epoch: 6| Step: 8
Training loss: 1.9213792114886692
Validation loss: 2.5492513916594426

Epoch: 6| Step: 9
Training loss: 2.0805982055955545
Validation loss: 2.5542427710250726

Epoch: 6| Step: 10
Training loss: 2.6514115191102747
Validation loss: 2.5621189593968365

Epoch: 6| Step: 11
Training loss: 2.1985961683285904
Validation loss: 2.567734264890226

Epoch: 6| Step: 12
Training loss: 2.1467105097272063
Validation loss: 2.5842915931659296

Epoch: 6| Step: 13
Training loss: 2.7086000946912456
Validation loss: 2.603939471188832

Epoch: 228| Step: 0
Training loss: 2.1567622143050342
Validation loss: 2.5899781757525155

Epoch: 6| Step: 1
Training loss: 1.8619053396958818
Validation loss: 2.6032229023108653

Epoch: 6| Step: 2
Training loss: 2.7210390824185744
Validation loss: 2.62899193664239

Epoch: 6| Step: 3
Training loss: 2.2503791065844996
Validation loss: 2.60563418936899

Epoch: 6| Step: 4
Training loss: 1.962525230294127
Validation loss: 2.641359787533939

Epoch: 6| Step: 5
Training loss: 2.6102158339549435
Validation loss: 2.6402946205299824

Epoch: 6| Step: 6
Training loss: 2.3338003939973566
Validation loss: 2.6503242516224303

Epoch: 6| Step: 7
Training loss: 2.4209839196787866
Validation loss: 2.62817104993249

Epoch: 6| Step: 8
Training loss: 2.779463633656737
Validation loss: 2.575844065893648

Epoch: 6| Step: 9
Training loss: 2.0785519727752377
Validation loss: 2.555591248410439

Epoch: 6| Step: 10
Training loss: 1.889080961908661
Validation loss: 2.530606560891543

Epoch: 6| Step: 11
Training loss: 2.3492501381393707
Validation loss: 2.5011935722700405

Epoch: 6| Step: 12
Training loss: 2.0498702868850507
Validation loss: 2.5069889605917797

Epoch: 6| Step: 13
Training loss: 2.2675205062393196
Validation loss: 2.489746652351093

Epoch: 229| Step: 0
Training loss: 2.602476400512052
Validation loss: 2.5089413329515677

Epoch: 6| Step: 1
Training loss: 1.9584415554688206
Validation loss: 2.486176179736433

Epoch: 6| Step: 2
Training loss: 2.221002000006574
Validation loss: 2.4901296955122647

Epoch: 6| Step: 3
Training loss: 2.471940116169331
Validation loss: 2.4913035133434325

Epoch: 6| Step: 4
Training loss: 1.9716139655380347
Validation loss: 2.489091885846836

Epoch: 6| Step: 5
Training loss: 1.9555855472689958
Validation loss: 2.483026294373913

Epoch: 6| Step: 6
Training loss: 2.62911247362809
Validation loss: 2.491830662738831

Epoch: 6| Step: 7
Training loss: 2.3238765176084115
Validation loss: 2.4957518405590995

Epoch: 6| Step: 8
Training loss: 2.0594948347359843
Validation loss: 2.507989372124429

Epoch: 6| Step: 9
Training loss: 2.2009756005826944
Validation loss: 2.5179155082727327

Epoch: 6| Step: 10
Training loss: 2.4852481483273756
Validation loss: 2.531962918327912

Epoch: 6| Step: 11
Training loss: 1.8039662955406837
Validation loss: 2.5211359162966924

Epoch: 6| Step: 12
Training loss: 2.3260615888791056
Validation loss: 2.5472608402735504

Epoch: 6| Step: 13
Training loss: 2.7929416895269066
Validation loss: 2.5522646677379988

Epoch: 230| Step: 0
Training loss: 2.3192122705517244
Validation loss: 2.5329520464576167

Epoch: 6| Step: 1
Training loss: 1.788622672976103
Validation loss: 2.5576679525232517

Epoch: 6| Step: 2
Training loss: 2.314105533300175
Validation loss: 2.5395363702935425

Epoch: 6| Step: 3
Training loss: 2.452460520948609
Validation loss: 2.550637506443263

Epoch: 6| Step: 4
Training loss: 2.704129159331236
Validation loss: 2.53656570134218

Epoch: 6| Step: 5
Training loss: 1.5656266781613308
Validation loss: 2.516560145727983

Epoch: 6| Step: 6
Training loss: 2.1949377860113595
Validation loss: 2.523789380304626

Epoch: 6| Step: 7
Training loss: 1.9784327166735534
Validation loss: 2.5475466336045973

Epoch: 6| Step: 8
Training loss: 2.4039636624298635
Validation loss: 2.5319858784324487

Epoch: 6| Step: 9
Training loss: 2.538847834976054
Validation loss: 2.5401785877102316

Epoch: 6| Step: 10
Training loss: 1.7739779283296637
Validation loss: 2.5557263329936375

Epoch: 6| Step: 11
Training loss: 1.6943818099878132
Validation loss: 2.565170881046031

Epoch: 6| Step: 12
Training loss: 3.2050700911119603
Validation loss: 2.555833596386153

Epoch: 6| Step: 13
Training loss: 2.2044916986563092
Validation loss: 2.595933967545987

Epoch: 231| Step: 0
Training loss: 2.512531060173908
Validation loss: 2.574236609744768

Epoch: 6| Step: 1
Training loss: 2.3514221757862406
Validation loss: 2.5716134347389974

Epoch: 6| Step: 2
Training loss: 1.767689940567255
Validation loss: 2.553710221727513

Epoch: 6| Step: 3
Training loss: 1.7951258895209872
Validation loss: 2.536223779965518

Epoch: 6| Step: 4
Training loss: 2.2876781665228187
Validation loss: 2.5361015230740147

Epoch: 6| Step: 5
Training loss: 2.200212867148677
Validation loss: 2.5412754529037036

Epoch: 6| Step: 6
Training loss: 1.6892227986059383
Validation loss: 2.5270441969513895

Epoch: 6| Step: 7
Training loss: 2.0626973144475302
Validation loss: 2.5277791972266974

Epoch: 6| Step: 8
Training loss: 2.4556219914263293
Validation loss: 2.514762564726614

Epoch: 6| Step: 9
Training loss: 2.384276793771056
Validation loss: 2.5055672804122757

Epoch: 6| Step: 10
Training loss: 2.593861313235267
Validation loss: 2.5118068681588746

Epoch: 6| Step: 11
Training loss: 2.9394674002975623
Validation loss: 2.5159766225916433

Epoch: 6| Step: 12
Training loss: 1.926148602034259
Validation loss: 2.537173494777309

Epoch: 6| Step: 13
Training loss: 2.399695051210914
Validation loss: 2.533034335444229

Epoch: 232| Step: 0
Training loss: 1.3301143333223173
Validation loss: 2.5471007358233804

Epoch: 6| Step: 1
Training loss: 2.771974677494529
Validation loss: 2.54340755272693

Epoch: 6| Step: 2
Training loss: 2.131367735533281
Validation loss: 2.54408513110201

Epoch: 6| Step: 3
Training loss: 2.543994233874618
Validation loss: 2.56079649708707

Epoch: 6| Step: 4
Training loss: 2.5045339478979107
Validation loss: 2.54322709716196

Epoch: 6| Step: 5
Training loss: 2.2348224752016668
Validation loss: 2.55069401091884

Epoch: 6| Step: 6
Training loss: 2.1072969726656607
Validation loss: 2.5296968318145834

Epoch: 6| Step: 7
Training loss: 2.6341275968935727
Validation loss: 2.5262508318844796

Epoch: 6| Step: 8
Training loss: 2.8112875974319764
Validation loss: 2.5320832721592392

Epoch: 6| Step: 9
Training loss: 1.4525457068390457
Validation loss: 2.5289272750186336

Epoch: 6| Step: 10
Training loss: 2.0107825017206795
Validation loss: 2.5387479303584137

Epoch: 6| Step: 11
Training loss: 2.2142365445773398
Validation loss: 2.541681154136851

Epoch: 6| Step: 12
Training loss: 2.1178779180137726
Validation loss: 2.5539948032757436

Epoch: 6| Step: 13
Training loss: 2.1804177213005707
Validation loss: 2.5475166932202664

Epoch: 233| Step: 0
Training loss: 2.323444962120772
Validation loss: 2.5439103546962327

Epoch: 6| Step: 1
Training loss: 1.8826787117558346
Validation loss: 2.5303057726559826

Epoch: 6| Step: 2
Training loss: 2.872518712606144
Validation loss: 2.54193466107753

Epoch: 6| Step: 3
Training loss: 2.1694544195102416
Validation loss: 2.5662837432312724

Epoch: 6| Step: 4
Training loss: 1.9859007128918187
Validation loss: 2.580941020585816

Epoch: 6| Step: 5
Training loss: 1.6377929221666114
Validation loss: 2.5732555681009837

Epoch: 6| Step: 6
Training loss: 2.4059046708054876
Validation loss: 2.5980296695934655

Epoch: 6| Step: 7
Training loss: 2.2397102733980234
Validation loss: 2.578362764126026

Epoch: 6| Step: 8
Training loss: 2.338308196672486
Validation loss: 2.5937524205698264

Epoch: 6| Step: 9
Training loss: 2.0032013067747005
Validation loss: 2.605585800050492

Epoch: 6| Step: 10
Training loss: 1.993510805328914
Validation loss: 2.580421596230627

Epoch: 6| Step: 11
Training loss: 2.203587368542941
Validation loss: 2.611340009405026

Epoch: 6| Step: 12
Training loss: 2.8144699826817745
Validation loss: 2.57353335620674

Epoch: 6| Step: 13
Training loss: 2.1540126526584054
Validation loss: 2.541568681256076

Epoch: 234| Step: 0
Training loss: 2.2007173409084584
Validation loss: 2.5443510721621894

Epoch: 6| Step: 1
Training loss: 1.803815358458872
Validation loss: 2.529858171196788

Epoch: 6| Step: 2
Training loss: 2.275535952138818
Validation loss: 2.520735137119808

Epoch: 6| Step: 3
Training loss: 1.7493433401521323
Validation loss: 2.4965486624358064

Epoch: 6| Step: 4
Training loss: 1.7855453901800051
Validation loss: 2.505588722032984

Epoch: 6| Step: 5
Training loss: 2.556914219449405
Validation loss: 2.48437755912473

Epoch: 6| Step: 6
Training loss: 1.885724107605262
Validation loss: 2.4994230558330917

Epoch: 6| Step: 7
Training loss: 2.239382168510562
Validation loss: 2.5099202347172405

Epoch: 6| Step: 8
Training loss: 1.8175738120012497
Validation loss: 2.5153258088490786

Epoch: 6| Step: 9
Training loss: 3.2250924444625753
Validation loss: 2.5252186853617142

Epoch: 6| Step: 10
Training loss: 2.5124087416743515
Validation loss: 2.5477954004915526

Epoch: 6| Step: 11
Training loss: 1.6945195607001589
Validation loss: 2.5590900279570805

Epoch: 6| Step: 12
Training loss: 2.6523983125313384
Validation loss: 2.5510543357707953

Epoch: 6| Step: 13
Training loss: 2.4788162133342047
Validation loss: 2.5771735853727167

Epoch: 235| Step: 0
Training loss: 1.599770711324484
Validation loss: 2.5742698822577483

Epoch: 6| Step: 1
Training loss: 2.834612744506014
Validation loss: 2.5741621598780253

Epoch: 6| Step: 2
Training loss: 1.546657816735522
Validation loss: 2.5659942993076954

Epoch: 6| Step: 3
Training loss: 2.1997153228027693
Validation loss: 2.55597533761147

Epoch: 6| Step: 4
Training loss: 1.7949451200123643
Validation loss: 2.558295840714507

Epoch: 6| Step: 5
Training loss: 2.1515376248164886
Validation loss: 2.5238020311785903

Epoch: 6| Step: 6
Training loss: 1.5307621081289378
Validation loss: 2.540265609140127

Epoch: 6| Step: 7
Training loss: 1.6141443783874432
Validation loss: 2.5576463338155664

Epoch: 6| Step: 8
Training loss: 2.341103038177468
Validation loss: 2.562370901810078

Epoch: 6| Step: 9
Training loss: 1.8168007042925876
Validation loss: 2.5449998033194974

Epoch: 6| Step: 10
Training loss: 2.5329705501430224
Validation loss: 2.5530118044814274

Epoch: 6| Step: 11
Training loss: 3.1620285466815914
Validation loss: 2.5703118970690544

Epoch: 6| Step: 12
Training loss: 2.4892595365210783
Validation loss: 2.613836696043768

Epoch: 6| Step: 13
Training loss: 2.7409252946116736
Validation loss: 2.616523787572282

Epoch: 236| Step: 0
Training loss: 1.948805893346648
Validation loss: 2.6354855966914412

Epoch: 6| Step: 1
Training loss: 2.7453030442241646
Validation loss: 2.6564728587289985

Epoch: 6| Step: 2
Training loss: 2.683236044152683
Validation loss: 2.6518893782020365

Epoch: 6| Step: 3
Training loss: 1.6293668758890696
Validation loss: 2.6394623222602958

Epoch: 6| Step: 4
Training loss: 2.288230979317751
Validation loss: 2.6340450190310545

Epoch: 6| Step: 5
Training loss: 1.7334163181296085
Validation loss: 2.630053477245217

Epoch: 6| Step: 6
Training loss: 2.178265288773139
Validation loss: 2.602657801607478

Epoch: 6| Step: 7
Training loss: 2.4639683058979234
Validation loss: 2.59637492996428

Epoch: 6| Step: 8
Training loss: 2.7401565899620057
Validation loss: 2.5563287003145585

Epoch: 6| Step: 9
Training loss: 2.031714518324897
Validation loss: 2.5546868933814024

Epoch: 6| Step: 10
Training loss: 2.0546865717084404
Validation loss: 2.55069556878574

Epoch: 6| Step: 11
Training loss: 1.942042225493559
Validation loss: 2.544119969362273

Epoch: 6| Step: 12
Training loss: 2.0490055789229262
Validation loss: 2.5325730951347927

Epoch: 6| Step: 13
Training loss: 2.210921648056302
Validation loss: 2.497202325085599

Epoch: 237| Step: 0
Training loss: 1.5588888018127645
Validation loss: 2.521974846345653

Epoch: 6| Step: 1
Training loss: 2.158144464170265
Validation loss: 2.5116166508847413

Epoch: 6| Step: 2
Training loss: 2.0833527627674724
Validation loss: 2.515275224019334

Epoch: 6| Step: 3
Training loss: 2.500164217323819
Validation loss: 2.5372300250248485

Epoch: 6| Step: 4
Training loss: 1.9748539834429304
Validation loss: 2.523958622807386

Epoch: 6| Step: 5
Training loss: 2.1613781527312623
Validation loss: 2.5782966479564533

Epoch: 6| Step: 6
Training loss: 2.3437320962857844
Validation loss: 2.602149797806812

Epoch: 6| Step: 7
Training loss: 2.701933316958802
Validation loss: 2.6117653928823867

Epoch: 6| Step: 8
Training loss: 1.6924478966315328
Validation loss: 2.6714630999226725

Epoch: 6| Step: 9
Training loss: 1.5349046340791903
Validation loss: 2.686699415327575

Epoch: 6| Step: 10
Training loss: 2.4118318096879507
Validation loss: 2.6964250857481957

Epoch: 6| Step: 11
Training loss: 3.091460025870096
Validation loss: 2.697588636764563

Epoch: 6| Step: 12
Training loss: 2.0160831847361553
Validation loss: 2.6700331825880395

Epoch: 6| Step: 13
Training loss: 2.7513044904610173
Validation loss: 2.632123243778035

Epoch: 238| Step: 0
Training loss: 2.473674257264826
Validation loss: 2.632176006288572

Epoch: 6| Step: 1
Training loss: 1.6518837579328305
Validation loss: 2.610374974808104

Epoch: 6| Step: 2
Training loss: 2.0515730428315835
Validation loss: 2.578716880596755

Epoch: 6| Step: 3
Training loss: 2.11649122437213
Validation loss: 2.5674108728863496

Epoch: 6| Step: 4
Training loss: 1.6861838400313331
Validation loss: 2.556011280829898

Epoch: 6| Step: 5
Training loss: 2.407254096254807
Validation loss: 2.5403362815501787

Epoch: 6| Step: 6
Training loss: 2.3834847924539764
Validation loss: 2.521784679082743

Epoch: 6| Step: 7
Training loss: 2.461540899023353
Validation loss: 2.5110888761710015

Epoch: 6| Step: 8
Training loss: 2.1524091042567632
Validation loss: 2.5347130559003617

Epoch: 6| Step: 9
Training loss: 2.261491675169907
Validation loss: 2.5046439906557536

Epoch: 6| Step: 10
Training loss: 1.8642442561876154
Validation loss: 2.4964789072015763

Epoch: 6| Step: 11
Training loss: 2.3790955616958533
Validation loss: 2.4908067152741533

Epoch: 6| Step: 12
Training loss: 2.478268874851627
Validation loss: 2.5269393793938044

Epoch: 6| Step: 13
Training loss: 2.6586442815354157
Validation loss: 2.5431221067534473

Epoch: 239| Step: 0
Training loss: 2.561918518337066
Validation loss: 2.5459936914548105

Epoch: 6| Step: 1
Training loss: 2.4996759204617756
Validation loss: 2.5847493925675926

Epoch: 6| Step: 2
Training loss: 2.6150038078382494
Validation loss: 2.60977038892313

Epoch: 6| Step: 3
Training loss: 2.293873285207814
Validation loss: 2.6039333442432824

Epoch: 6| Step: 4
Training loss: 1.9670625751512194
Validation loss: 2.612991491807803

Epoch: 6| Step: 5
Training loss: 1.868499933052419
Validation loss: 2.6114985035465907

Epoch: 6| Step: 6
Training loss: 2.1741233549803236
Validation loss: 2.59976041466344

Epoch: 6| Step: 7
Training loss: 1.8556409253997808
Validation loss: 2.5919732285586785

Epoch: 6| Step: 8
Training loss: 2.3118662610163425
Validation loss: 2.5795069063876377

Epoch: 6| Step: 9
Training loss: 2.456019934831166
Validation loss: 2.5727162585541987

Epoch: 6| Step: 10
Training loss: 2.139848220113018
Validation loss: 2.5952942322592025

Epoch: 6| Step: 11
Training loss: 1.9787455328230035
Validation loss: 2.584117391002303

Epoch: 6| Step: 12
Training loss: 2.525161201694549
Validation loss: 2.5902368967297793

Epoch: 6| Step: 13
Training loss: 1.6252139024068986
Validation loss: 2.5931853863315686

Epoch: 240| Step: 0
Training loss: 2.0706017634005955
Validation loss: 2.5882396611369787

Epoch: 6| Step: 1
Training loss: 2.9222893242651993
Validation loss: 2.5958204163974425

Epoch: 6| Step: 2
Training loss: 1.5459905851158886
Validation loss: 2.588631631578583

Epoch: 6| Step: 3
Training loss: 1.8103546731897229
Validation loss: 2.577964839391696

Epoch: 6| Step: 4
Training loss: 2.023563219090042
Validation loss: 2.5764428633194107

Epoch: 6| Step: 5
Training loss: 2.3994656325540196
Validation loss: 2.590204719101773

Epoch: 6| Step: 6
Training loss: 2.571283406368399
Validation loss: 2.5792383891678066

Epoch: 6| Step: 7
Training loss: 2.0445865330639648
Validation loss: 2.577038576502751

Epoch: 6| Step: 8
Training loss: 2.2727217448774217
Validation loss: 2.5586717588845462

Epoch: 6| Step: 9
Training loss: 1.8807805283480017
Validation loss: 2.6074358726630558

Epoch: 6| Step: 10
Training loss: 1.7897753232466462
Validation loss: 2.6180122252728424

Epoch: 6| Step: 11
Training loss: 2.4609733457830836
Validation loss: 2.585917369998516

Epoch: 6| Step: 12
Training loss: 2.0599117800886635
Validation loss: 2.583184319987298

Epoch: 6| Step: 13
Training loss: 2.4286555708405633
Validation loss: 2.6031478160332995

Epoch: 241| Step: 0
Training loss: 1.8001693381022537
Validation loss: 2.6301010009217984

Epoch: 6| Step: 1
Training loss: 2.482041324526591
Validation loss: 2.654825000371561

Epoch: 6| Step: 2
Training loss: 2.0208924537216912
Validation loss: 2.6529770527190055

Epoch: 6| Step: 3
Training loss: 1.9010087798596607
Validation loss: 2.6594494717693906

Epoch: 6| Step: 4
Training loss: 1.8999252455210218
Validation loss: 2.5975921546466676

Epoch: 6| Step: 5
Training loss: 2.727341505108196
Validation loss: 2.566152543640551

Epoch: 6| Step: 6
Training loss: 2.4248959312524705
Validation loss: 2.5619995124651656

Epoch: 6| Step: 7
Training loss: 1.9872873516404497
Validation loss: 2.551219690252792

Epoch: 6| Step: 8
Training loss: 2.3111130963015385
Validation loss: 2.551138571947873

Epoch: 6| Step: 9
Training loss: 2.679759566781019
Validation loss: 2.5292634114883334

Epoch: 6| Step: 10
Training loss: 2.6460897566723265
Validation loss: 2.5409223894689514

Epoch: 6| Step: 11
Training loss: 2.0951634660554315
Validation loss: 2.5134052252753527

Epoch: 6| Step: 12
Training loss: 1.9372779965112394
Validation loss: 2.5453347071082257

Epoch: 6| Step: 13
Training loss: 1.4159477691176976
Validation loss: 2.549550279840588

Epoch: 242| Step: 0
Training loss: 2.5924675770040757
Validation loss: 2.5789287816923636

Epoch: 6| Step: 1
Training loss: 2.3437223305658392
Validation loss: 2.5877734809129325

Epoch: 6| Step: 2
Training loss: 2.047972639631258
Validation loss: 2.5862873374735282

Epoch: 6| Step: 3
Training loss: 1.6629273747260527
Validation loss: 2.5818489691355437

Epoch: 6| Step: 4
Training loss: 2.13545449076083
Validation loss: 2.6056624173272906

Epoch: 6| Step: 5
Training loss: 2.0800643705531163
Validation loss: 2.625895483681146

Epoch: 6| Step: 6
Training loss: 1.9142586743777394
Validation loss: 2.6278539613841687

Epoch: 6| Step: 7
Training loss: 2.3088587368409987
Validation loss: 2.6234190585207897

Epoch: 6| Step: 8
Training loss: 2.762203794453535
Validation loss: 2.6444865701451845

Epoch: 6| Step: 9
Training loss: 2.2104933868909833
Validation loss: 2.6148114858429423

Epoch: 6| Step: 10
Training loss: 1.5120876759081063
Validation loss: 2.643162533275662

Epoch: 6| Step: 11
Training loss: 2.164015676494515
Validation loss: 2.6379711652312103

Epoch: 6| Step: 12
Training loss: 1.9923020273835617
Validation loss: 2.609555540863158

Epoch: 6| Step: 13
Training loss: 2.532069980003806
Validation loss: 2.6009262116371437

Epoch: 243| Step: 0
Training loss: 1.5699107097334053
Validation loss: 2.5920235123441144

Epoch: 6| Step: 1
Training loss: 2.0970799171161723
Validation loss: 2.566089333795605

Epoch: 6| Step: 2
Training loss: 2.644162038163267
Validation loss: 2.5458008542983275

Epoch: 6| Step: 3
Training loss: 2.012856408066564
Validation loss: 2.533592066811814

Epoch: 6| Step: 4
Training loss: 2.021005826319734
Validation loss: 2.529773265695573

Epoch: 6| Step: 5
Training loss: 2.569589437798423
Validation loss: 2.5385678479505476

Epoch: 6| Step: 6
Training loss: 2.892699615791399
Validation loss: 2.5081270363295047

Epoch: 6| Step: 7
Training loss: 1.5090908501782776
Validation loss: 2.5497378619722024

Epoch: 6| Step: 8
Training loss: 1.840994440641199
Validation loss: 2.5662685688311355

Epoch: 6| Step: 9
Training loss: 2.3001620069750084
Validation loss: 2.5997927185720013

Epoch: 6| Step: 10
Training loss: 2.424124380691206
Validation loss: 2.631767797679095

Epoch: 6| Step: 11
Training loss: 2.5636595916802527
Validation loss: 2.624677426333663

Epoch: 6| Step: 12
Training loss: 1.9412896411039102
Validation loss: 2.6452762337647333

Epoch: 6| Step: 13
Training loss: 2.024682093025921
Validation loss: 2.633123634133391

Epoch: 244| Step: 0
Training loss: 2.486602648182848
Validation loss: 2.6169169575556093

Epoch: 6| Step: 1
Training loss: 1.5566400123508832
Validation loss: 2.609985264971612

Epoch: 6| Step: 2
Training loss: 1.6952046302897796
Validation loss: 2.5761078466749794

Epoch: 6| Step: 3
Training loss: 2.9278353520361784
Validation loss: 2.5578363360376177

Epoch: 6| Step: 4
Training loss: 1.670101044618876
Validation loss: 2.544257912005929

Epoch: 6| Step: 5
Training loss: 1.9942702233536163
Validation loss: 2.5493337857985527

Epoch: 6| Step: 6
Training loss: 2.434376206599709
Validation loss: 2.557769502850465

Epoch: 6| Step: 7
Training loss: 1.9040374422639301
Validation loss: 2.5668058969666836

Epoch: 6| Step: 8
Training loss: 2.2693291211356232
Validation loss: 2.5590218921066317

Epoch: 6| Step: 9
Training loss: 2.440460363640234
Validation loss: 2.5805918287783145

Epoch: 6| Step: 10
Training loss: 1.8260965423549578
Validation loss: 2.5594090684199933

Epoch: 6| Step: 11
Training loss: 2.5399222928272973
Validation loss: 2.5860736576741306

Epoch: 6| Step: 12
Training loss: 2.6553469749781544
Validation loss: 2.579419129134881

Epoch: 6| Step: 13
Training loss: 2.256152536078234
Validation loss: 2.584230287767805

Epoch: 245| Step: 0
Training loss: 1.8457222427912006
Validation loss: 2.5638324715728324

Epoch: 6| Step: 1
Training loss: 1.7331080577639915
Validation loss: 2.5891206325403986

Epoch: 6| Step: 2
Training loss: 2.485246229656427
Validation loss: 2.5724680634330555

Epoch: 6| Step: 3
Training loss: 1.9001965320734986
Validation loss: 2.5810604761727243

Epoch: 6| Step: 4
Training loss: 1.7453823475193
Validation loss: 2.581199138716014

Epoch: 6| Step: 5
Training loss: 2.77183172456662
Validation loss: 2.563389848483771

Epoch: 6| Step: 6
Training loss: 1.644883650401497
Validation loss: 2.5721313008945605

Epoch: 6| Step: 7
Training loss: 2.0166552372548128
Validation loss: 2.5964901862039507

Epoch: 6| Step: 8
Training loss: 1.9485879921019393
Validation loss: 2.564281154734268

Epoch: 6| Step: 9
Training loss: 2.2396375664347112
Validation loss: 2.5786491708895056

Epoch: 6| Step: 10
Training loss: 2.4178645245547448
Validation loss: 2.554355829234

Epoch: 6| Step: 11
Training loss: 2.304809670523813
Validation loss: 2.574978829577679

Epoch: 6| Step: 12
Training loss: 3.0774285937406822
Validation loss: 2.6074980725835673

Epoch: 6| Step: 13
Training loss: 1.9250854720919846
Validation loss: 2.630884779760491

Epoch: 246| Step: 0
Training loss: 1.9124079189697496
Validation loss: 2.6336698258768916

Epoch: 6| Step: 1
Training loss: 2.679306136595106
Validation loss: 2.631939381941526

Epoch: 6| Step: 2
Training loss: 2.3382963690506346
Validation loss: 2.6279201764922573

Epoch: 6| Step: 3
Training loss: 1.930899791383285
Validation loss: 2.624056116583742

Epoch: 6| Step: 4
Training loss: 2.4826110719724457
Validation loss: 2.6109598566327468

Epoch: 6| Step: 5
Training loss: 1.9601785475312967
Validation loss: 2.636125210491064

Epoch: 6| Step: 6
Training loss: 2.4254325087732824
Validation loss: 2.656157877203455

Epoch: 6| Step: 7
Training loss: 1.8640590619729402
Validation loss: 2.6541429128337466

Epoch: 6| Step: 8
Training loss: 2.061227001017923
Validation loss: 2.6806480680543254

Epoch: 6| Step: 9
Training loss: 2.0931110830633144
Validation loss: 2.656837458255939

Epoch: 6| Step: 10
Training loss: 3.0608206056295084
Validation loss: 2.667168768660732

Epoch: 6| Step: 11
Training loss: 1.9739442152124025
Validation loss: 2.6617172971228285

Epoch: 6| Step: 12
Training loss: 1.347857562522872
Validation loss: 2.6244140228304036

Epoch: 6| Step: 13
Training loss: 1.589948196167017
Validation loss: 2.564879824256571

Epoch: 247| Step: 0
Training loss: 2.247513032393812
Validation loss: 2.545756712747481

Epoch: 6| Step: 1
Training loss: 3.2210528089617094
Validation loss: 2.5227363328773627

Epoch: 6| Step: 2
Training loss: 2.4014616052186035
Validation loss: 2.5193654875724385

Epoch: 6| Step: 3
Training loss: 2.1488584903581884
Validation loss: 2.499963378638025

Epoch: 6| Step: 4
Training loss: 2.222407268396113
Validation loss: 2.506927286466833

Epoch: 6| Step: 5
Training loss: 2.055193820547018
Validation loss: 2.54561425425079

Epoch: 6| Step: 6
Training loss: 1.9642898658609487
Validation loss: 2.57887582345922

Epoch: 6| Step: 7
Training loss: 1.7378905810996848
Validation loss: 2.5822481419223022

Epoch: 6| Step: 8
Training loss: 2.553338397480032
Validation loss: 2.5667265484582784

Epoch: 6| Step: 9
Training loss: 1.981439717352099
Validation loss: 2.563005955686582

Epoch: 6| Step: 10
Training loss: 1.496245533387569
Validation loss: 2.587837880874654

Epoch: 6| Step: 11
Training loss: 1.8030122850648036
Validation loss: 2.60593589701239

Epoch: 6| Step: 12
Training loss: 1.8399338102874825
Validation loss: 2.597323472355147

Epoch: 6| Step: 13
Training loss: 2.55456617341391
Validation loss: 2.6418002069777433

Epoch: 248| Step: 0
Training loss: 2.943900257981386
Validation loss: 2.6438730792892193

Epoch: 6| Step: 1
Training loss: 1.508330656368908
Validation loss: 2.6734378995287544

Epoch: 6| Step: 2
Training loss: 2.261808456196765
Validation loss: 2.696695623403466

Epoch: 6| Step: 3
Training loss: 2.281708658174254
Validation loss: 2.679872052331619

Epoch: 6| Step: 4
Training loss: 1.9339663368143594
Validation loss: 2.6188779770831467

Epoch: 6| Step: 5
Training loss: 2.5334248559715546
Validation loss: 2.5629563274197604

Epoch: 6| Step: 6
Training loss: 2.4984184984888556
Validation loss: 2.5338765633754057

Epoch: 6| Step: 7
Training loss: 2.6639780159807827
Validation loss: 2.5053993887162536

Epoch: 6| Step: 8
Training loss: 1.5004927302752948
Validation loss: 2.500303345396363

Epoch: 6| Step: 9
Training loss: 2.1518051110406997
Validation loss: 2.509008548213688

Epoch: 6| Step: 10
Training loss: 2.7681220037771834
Validation loss: 2.4973445936136858

Epoch: 6| Step: 11
Training loss: 1.8332784673399336
Validation loss: 2.5005308700219193

Epoch: 6| Step: 12
Training loss: 1.8078879509613424
Validation loss: 2.5054421477674413

Epoch: 6| Step: 13
Training loss: 1.819236142446338
Validation loss: 2.5011700117573037

Epoch: 249| Step: 0
Training loss: 2.4566464752064525
Validation loss: 2.510489788546976

Epoch: 6| Step: 1
Training loss: 2.234933103204559
Validation loss: 2.5665793009747304

Epoch: 6| Step: 2
Training loss: 1.6003263587701682
Validation loss: 2.593891722089627

Epoch: 6| Step: 3
Training loss: 2.1153203747738427
Validation loss: 2.6417554282870923

Epoch: 6| Step: 4
Training loss: 1.710515497150263
Validation loss: 2.6667750803446735

Epoch: 6| Step: 5
Training loss: 2.0943163205506714
Validation loss: 2.7063154822011906

Epoch: 6| Step: 6
Training loss: 2.3664370313464156
Validation loss: 2.674263813940391

Epoch: 6| Step: 7
Training loss: 2.0115612375760055
Validation loss: 2.696691644888471

Epoch: 6| Step: 8
Training loss: 2.3623725089737193
Validation loss: 2.654498259423028

Epoch: 6| Step: 9
Training loss: 2.1556964108347993
Validation loss: 2.649339670406315

Epoch: 6| Step: 10
Training loss: 2.759034747771474
Validation loss: 2.621854433896711

Epoch: 6| Step: 11
Training loss: 2.642292557065323
Validation loss: 2.6164482173323687

Epoch: 6| Step: 12
Training loss: 1.878589500327889
Validation loss: 2.5844287370094374

Epoch: 6| Step: 13
Training loss: 2.606167495116874
Validation loss: 2.5772643685390095

Epoch: 250| Step: 0
Training loss: 2.232395602494683
Validation loss: 2.548982805062632

Epoch: 6| Step: 1
Training loss: 2.505249615261047
Validation loss: 2.542410996891307

Epoch: 6| Step: 2
Training loss: 2.2050945595601026
Validation loss: 2.5626286342557805

Epoch: 6| Step: 3
Training loss: 2.1075661144090416
Validation loss: 2.5991529163813474

Epoch: 6| Step: 4
Training loss: 2.692616670820454
Validation loss: 2.591007099878518

Epoch: 6| Step: 5
Training loss: 2.1125614541047995
Validation loss: 2.6404781112596756

Epoch: 6| Step: 6
Training loss: 2.383201692409113
Validation loss: 2.5748075160208965

Epoch: 6| Step: 7
Training loss: 2.202395270950334
Validation loss: 2.5639619456148717

Epoch: 6| Step: 8
Training loss: 2.3147279471593096
Validation loss: 2.530053770501614

Epoch: 6| Step: 9
Training loss: 2.0824970347004417
Validation loss: 2.5346562578742415

Epoch: 6| Step: 10
Training loss: 1.8584633523705794
Validation loss: 2.5090087145074618

Epoch: 6| Step: 11
Training loss: 1.7800768284879798
Validation loss: 2.5136448745838478

Epoch: 6| Step: 12
Training loss: 2.0707689465875636
Validation loss: 2.5069493346256126

Epoch: 6| Step: 13
Training loss: 1.998081001892694
Validation loss: 2.485400326193605

Epoch: 251| Step: 0
Training loss: 2.0240154840080633
Validation loss: 2.5000028292322045

Epoch: 6| Step: 1
Training loss: 2.5468110620628983
Validation loss: 2.517413165259486

Epoch: 6| Step: 2
Training loss: 1.9513898542529244
Validation loss: 2.4946082943054644

Epoch: 6| Step: 3
Training loss: 2.2796598143854117
Validation loss: 2.550645420572572

Epoch: 6| Step: 4
Training loss: 2.0827075654229685
Validation loss: 2.535792587818744

Epoch: 6| Step: 5
Training loss: 2.1068667722782974
Validation loss: 2.541021567437165

Epoch: 6| Step: 6
Training loss: 2.589005692848144
Validation loss: 2.5555286169935862

Epoch: 6| Step: 7
Training loss: 2.679555550487923
Validation loss: 2.561635964961861

Epoch: 6| Step: 8
Training loss: 1.8957628788974035
Validation loss: 2.5808758172724473

Epoch: 6| Step: 9
Training loss: 1.9571325462455547
Validation loss: 2.5908342081409774

Epoch: 6| Step: 10
Training loss: 2.430364483785889
Validation loss: 2.5923218069756753

Epoch: 6| Step: 11
Training loss: 1.571415148714876
Validation loss: 2.5823745230035673

Epoch: 6| Step: 12
Training loss: 1.892203310609846
Validation loss: 2.6032052719604826

Epoch: 6| Step: 13
Training loss: 1.4828616810431785
Validation loss: 2.5740897764275363

Epoch: 252| Step: 0
Training loss: 2.2589855908478484
Validation loss: 2.585935517739634

Epoch: 6| Step: 1
Training loss: 2.0187268896522093
Validation loss: 2.5795969912730654

Epoch: 6| Step: 2
Training loss: 2.0291587040906185
Validation loss: 2.5667700507245104

Epoch: 6| Step: 3
Training loss: 1.5441949149174654
Validation loss: 2.5696758652908116

Epoch: 6| Step: 4
Training loss: 2.236190165299745
Validation loss: 2.5503133020351827

Epoch: 6| Step: 5
Training loss: 1.9572329845500118
Validation loss: 2.5657151838676886

Epoch: 6| Step: 6
Training loss: 2.3481132075298192
Validation loss: 2.600424700064817

Epoch: 6| Step: 7
Training loss: 2.7415069865962685
Validation loss: 2.5850888383825454

Epoch: 6| Step: 8
Training loss: 1.8253281546510658
Validation loss: 2.6247545157799226

Epoch: 6| Step: 9
Training loss: 1.603184766938028
Validation loss: 2.669319417867996

Epoch: 6| Step: 10
Training loss: 2.040725439149805
Validation loss: 2.6960903501162172

Epoch: 6| Step: 11
Training loss: 2.5171020152318477
Validation loss: 2.6770124364190444

Epoch: 6| Step: 12
Training loss: 1.7797036402157158
Validation loss: 2.6429320420510525

Epoch: 6| Step: 13
Training loss: 2.661595698704181
Validation loss: 2.6625114989890544

Epoch: 253| Step: 0
Training loss: 2.207252045786328
Validation loss: 2.5843209306749046

Epoch: 6| Step: 1
Training loss: 1.7196426847712736
Validation loss: 2.6137016045741914

Epoch: 6| Step: 2
Training loss: 2.510117371843091
Validation loss: 2.569901933122527

Epoch: 6| Step: 3
Training loss: 2.53720766835913
Validation loss: 2.5791966301487608

Epoch: 6| Step: 4
Training loss: 2.1161258752588856
Validation loss: 2.572906375715136

Epoch: 6| Step: 5
Training loss: 2.3119212276872685
Validation loss: 2.5567628478153925

Epoch: 6| Step: 6
Training loss: 1.450570928049872
Validation loss: 2.5847428050500807

Epoch: 6| Step: 7
Training loss: 3.1074188059774284
Validation loss: 2.5990134076008333

Epoch: 6| Step: 8
Training loss: 1.5855211735625563
Validation loss: 2.587521915680836

Epoch: 6| Step: 9
Training loss: 2.04900755701119
Validation loss: 2.5949405404385786

Epoch: 6| Step: 10
Training loss: 2.036485936855028
Validation loss: 2.611741080166311

Epoch: 6| Step: 11
Training loss: 1.8562276151700976
Validation loss: 2.570628671418584

Epoch: 6| Step: 12
Training loss: 1.6595426255671226
Validation loss: 2.564795621075088

Epoch: 6| Step: 13
Training loss: 2.449304995927157
Validation loss: 2.554044107812529

Epoch: 254| Step: 0
Training loss: 2.60846278526488
Validation loss: 2.559520547754907

Epoch: 6| Step: 1
Training loss: 1.5442618444308722
Validation loss: 2.620493396087149

Epoch: 6| Step: 2
Training loss: 2.2087244611126096
Validation loss: 2.5996107965547157

Epoch: 6| Step: 3
Training loss: 2.4556788860417638
Validation loss: 2.631506470468549

Epoch: 6| Step: 4
Training loss: 1.6242930268243956
Validation loss: 2.624352556947124

Epoch: 6| Step: 5
Training loss: 2.0022633381986457
Validation loss: 2.587479576239091

Epoch: 6| Step: 6
Training loss: 1.8948681718572538
Validation loss: 2.5738365804255747

Epoch: 6| Step: 7
Training loss: 1.8358049710103477
Validation loss: 2.578996345389238

Epoch: 6| Step: 8
Training loss: 2.480242477068755
Validation loss: 2.54176094839195

Epoch: 6| Step: 9
Training loss: 2.2755153114308313
Validation loss: 2.5555725275618664

Epoch: 6| Step: 10
Training loss: 1.604522351882843
Validation loss: 2.573435855842564

Epoch: 6| Step: 11
Training loss: 2.110125372899788
Validation loss: 2.586239400491309

Epoch: 6| Step: 12
Training loss: 2.0616275213539907
Validation loss: 2.596727997941481

Epoch: 6| Step: 13
Training loss: 2.6638622040837983
Validation loss: 2.6251400955599546

Epoch: 255| Step: 0
Training loss: 1.6906900277033017
Validation loss: 2.6280126011627143

Epoch: 6| Step: 1
Training loss: 2.5343774383947117
Validation loss: 2.641369144841377

Epoch: 6| Step: 2
Training loss: 2.031696915978965
Validation loss: 2.682596494272929

Epoch: 6| Step: 3
Training loss: 2.538437610904701
Validation loss: 2.6755346031396523

Epoch: 6| Step: 4
Training loss: 1.7735992223463475
Validation loss: 2.6709014278862373

Epoch: 6| Step: 5
Training loss: 2.31183594113016
Validation loss: 2.651645776433395

Epoch: 6| Step: 6
Training loss: 1.8038815106347175
Validation loss: 2.5747396572068397

Epoch: 6| Step: 7
Training loss: 2.0055005013449323
Validation loss: 2.580183128590092

Epoch: 6| Step: 8
Training loss: 1.8732085889074828
Validation loss: 2.580627875677151

Epoch: 6| Step: 9
Training loss: 2.225916932865331
Validation loss: 2.5873714746813987

Epoch: 6| Step: 10
Training loss: 1.946222911883862
Validation loss: 2.613100890515453

Epoch: 6| Step: 11
Training loss: 2.5065367118480024
Validation loss: 2.6358643605129415

Epoch: 6| Step: 12
Training loss: 2.3581830986705565
Validation loss: 2.637676963473988

Epoch: 6| Step: 13
Training loss: 2.232854579264748
Validation loss: 2.6650490970872296

Epoch: 256| Step: 0
Training loss: 2.282918032818496
Validation loss: 2.6490987216731674

Epoch: 6| Step: 1
Training loss: 2.4463134277104968
Validation loss: 2.613602828010451

Epoch: 6| Step: 2
Training loss: 2.2469213404008452
Validation loss: 2.608257107540014

Epoch: 6| Step: 3
Training loss: 2.5343787554279165
Validation loss: 2.58887180753411

Epoch: 6| Step: 4
Training loss: 1.4169339694492813
Validation loss: 2.561287507799835

Epoch: 6| Step: 5
Training loss: 2.0388354178660473
Validation loss: 2.5910878058346585

Epoch: 6| Step: 6
Training loss: 1.8382435701969315
Validation loss: 2.5379991388101524

Epoch: 6| Step: 7
Training loss: 2.041523701339841
Validation loss: 2.550788166685205

Epoch: 6| Step: 8
Training loss: 2.1536942968177977
Validation loss: 2.5426499439887142

Epoch: 6| Step: 9
Training loss: 1.7445243592730502
Validation loss: 2.568258637941452

Epoch: 6| Step: 10
Training loss: 1.9540279284953852
Validation loss: 2.5906601544898944

Epoch: 6| Step: 11
Training loss: 2.21706799433071
Validation loss: 2.6125650303487387

Epoch: 6| Step: 12
Training loss: 2.137855353013036
Validation loss: 2.630050659489532

Epoch: 6| Step: 13
Training loss: 2.3533225332485994
Validation loss: 2.6480084036946323

Epoch: 257| Step: 0
Training loss: 2.173394968040386
Validation loss: 2.6842586428463546

Epoch: 6| Step: 1
Training loss: 2.0893042893102187
Validation loss: 2.691926799718923

Epoch: 6| Step: 2
Training loss: 2.3479194683971008
Validation loss: 2.6557930497209616

Epoch: 6| Step: 3
Training loss: 2.2740628670328737
Validation loss: 2.670206824470382

Epoch: 6| Step: 4
Training loss: 1.8494010574346047
Validation loss: 2.617045445169207

Epoch: 6| Step: 5
Training loss: 2.2529734990457264
Validation loss: 2.561991586879324

Epoch: 6| Step: 6
Training loss: 2.148343614781027
Validation loss: 2.544923436400295

Epoch: 6| Step: 7
Training loss: 2.2818615237454276
Validation loss: 2.5293781910593314

Epoch: 6| Step: 8
Training loss: 2.0244200688451057
Validation loss: 2.5035065854189567

Epoch: 6| Step: 9
Training loss: 1.3680537939732673
Validation loss: 2.505055814820461

Epoch: 6| Step: 10
Training loss: 2.290846614343531
Validation loss: 2.5242590260812308

Epoch: 6| Step: 11
Training loss: 2.2491999369315137
Validation loss: 2.5329187488960465

Epoch: 6| Step: 12
Training loss: 2.397735791271351
Validation loss: 2.5268466151968485

Epoch: 6| Step: 13
Training loss: 2.0523993802236404
Validation loss: 2.520784847854628

Epoch: 258| Step: 0
Training loss: 1.865254570816712
Validation loss: 2.5459788955638847

Epoch: 6| Step: 1
Training loss: 1.4115517598255134
Validation loss: 2.5556786468365704

Epoch: 6| Step: 2
Training loss: 1.6845142653719793
Validation loss: 2.5398399375684306

Epoch: 6| Step: 3
Training loss: 2.4876127437939246
Validation loss: 2.5499258978056054

Epoch: 6| Step: 4
Training loss: 2.9460315585495223
Validation loss: 2.582039760435144

Epoch: 6| Step: 5
Training loss: 2.074714903032107
Validation loss: 2.601948446947188

Epoch: 6| Step: 6
Training loss: 2.2193917434391675
Validation loss: 2.622860354383861

Epoch: 6| Step: 7
Training loss: 1.757643831426044
Validation loss: 2.6367714959037527

Epoch: 6| Step: 8
Training loss: 1.7866588587495424
Validation loss: 2.6536362747354656

Epoch: 6| Step: 9
Training loss: 2.3039489597256697
Validation loss: 2.6110870470692165

Epoch: 6| Step: 10
Training loss: 1.8906297920103268
Validation loss: 2.6397796120312056

Epoch: 6| Step: 11
Training loss: 2.0095580117042617
Validation loss: 2.609157621728828

Epoch: 6| Step: 12
Training loss: 1.9574327494833634
Validation loss: 2.552792187293664

Epoch: 6| Step: 13
Training loss: 2.4564074283847197
Validation loss: 2.5597119089039446

Epoch: 259| Step: 0
Training loss: 2.271380565629564
Validation loss: 2.5461109942304563

Epoch: 6| Step: 1
Training loss: 2.081517025425502
Validation loss: 2.5408340612076614

Epoch: 6| Step: 2
Training loss: 2.461581675672839
Validation loss: 2.536584985431365

Epoch: 6| Step: 3
Training loss: 1.6189666396880986
Validation loss: 2.5419407264247726

Epoch: 6| Step: 4
Training loss: 2.2552194455572674
Validation loss: 2.524476710316291

Epoch: 6| Step: 5
Training loss: 2.426577033633734
Validation loss: 2.5314896866459415

Epoch: 6| Step: 6
Training loss: 2.0461293966444303
Validation loss: 2.554378339159981

Epoch: 6| Step: 7
Training loss: 1.7538393683308704
Validation loss: 2.568921007217197

Epoch: 6| Step: 8
Training loss: 2.3092060858414536
Validation loss: 2.6374643434883445

Epoch: 6| Step: 9
Training loss: 2.0326576637217992
Validation loss: 2.6387757140424193

Epoch: 6| Step: 10
Training loss: 1.9351156391414897
Validation loss: 2.675477542023234

Epoch: 6| Step: 11
Training loss: 2.486683954156641
Validation loss: 2.65357968613251

Epoch: 6| Step: 12
Training loss: 2.3216084672580215
Validation loss: 2.5980149559224825

Epoch: 6| Step: 13
Training loss: 1.8164256761394
Validation loss: 2.6028445028217777

Epoch: 260| Step: 0
Training loss: 2.4780686669122245
Validation loss: 2.6164620831769447

Epoch: 6| Step: 1
Training loss: 1.4917421325404527
Validation loss: 2.598120947553178

Epoch: 6| Step: 2
Training loss: 2.5716218251315492
Validation loss: 2.615195675051483

Epoch: 6| Step: 3
Training loss: 1.2323459414441713
Validation loss: 2.6058665157344745

Epoch: 6| Step: 4
Training loss: 2.0791648615011917
Validation loss: 2.607313960172226

Epoch: 6| Step: 5
Training loss: 2.335625975386345
Validation loss: 2.5741368282173993

Epoch: 6| Step: 6
Training loss: 1.93388786776275
Validation loss: 2.595888229287668

Epoch: 6| Step: 7
Training loss: 1.985153165812613
Validation loss: 2.611748033200211

Epoch: 6| Step: 8
Training loss: 2.5173381398055423
Validation loss: 2.6102294436630804

Epoch: 6| Step: 9
Training loss: 1.807903907990506
Validation loss: 2.5690962862002555

Epoch: 6| Step: 10
Training loss: 1.6084325308507124
Validation loss: 2.5917372956623073

Epoch: 6| Step: 11
Training loss: 1.38639759051988
Validation loss: 2.5914375383790027

Epoch: 6| Step: 12
Training loss: 2.933579771209205
Validation loss: 2.586803049403491

Epoch: 6| Step: 13
Training loss: 2.620977680575551
Validation loss: 2.575578792422583

Epoch: 261| Step: 0
Training loss: 2.056727799671935
Validation loss: 2.582732889679687

Epoch: 6| Step: 1
Training loss: 2.3908160762844384
Validation loss: 2.5751658093051457

Epoch: 6| Step: 2
Training loss: 2.625223241123479
Validation loss: 2.613901244375405

Epoch: 6| Step: 3
Training loss: 1.6940499803720477
Validation loss: 2.6311440694934864

Epoch: 6| Step: 4
Training loss: 2.233098872768853
Validation loss: 2.6472406974655693

Epoch: 6| Step: 5
Training loss: 2.4295291174387907
Validation loss: 2.638853709226205

Epoch: 6| Step: 6
Training loss: 1.8022907409677351
Validation loss: 2.6596794429312345

Epoch: 6| Step: 7
Training loss: 1.8940990466248835
Validation loss: 2.7055671552826746

Epoch: 6| Step: 8
Training loss: 2.474030846319431
Validation loss: 2.6755349150268457

Epoch: 6| Step: 9
Training loss: 1.3841550958062905
Validation loss: 2.6586782538605656

Epoch: 6| Step: 10
Training loss: 2.3245697525793743
Validation loss: 2.6296257708401294

Epoch: 6| Step: 11
Training loss: 2.409711552528215
Validation loss: 2.5755139162120497

Epoch: 6| Step: 12
Training loss: 1.6818020307857298
Validation loss: 2.5637230706749636

Epoch: 6| Step: 13
Training loss: 1.9659582052745868
Validation loss: 2.5598078208428725

Epoch: 262| Step: 0
Training loss: 1.831929673752403
Validation loss: 2.5321190052701272

Epoch: 6| Step: 1
Training loss: 2.4881930971924215
Validation loss: 2.5095969533088875

Epoch: 6| Step: 2
Training loss: 2.7510446818310066
Validation loss: 2.541665676512812

Epoch: 6| Step: 3
Training loss: 2.1166964591425206
Validation loss: 2.5400961468989567

Epoch: 6| Step: 4
Training loss: 2.3095079603105493
Validation loss: 2.578976854561422

Epoch: 6| Step: 5
Training loss: 2.1014023049713417
Validation loss: 2.5444932187730185

Epoch: 6| Step: 6
Training loss: 1.8378731121724734
Validation loss: 2.5439705621072797

Epoch: 6| Step: 7
Training loss: 1.9039990001403364
Validation loss: 2.5283995225859752

Epoch: 6| Step: 8
Training loss: 2.126771749254088
Validation loss: 2.5004954721289927

Epoch: 6| Step: 9
Training loss: 1.768889725628745
Validation loss: 2.5320827778241295

Epoch: 6| Step: 10
Training loss: 2.4193139101483716
Validation loss: 2.5150132235033413

Epoch: 6| Step: 11
Training loss: 2.249283888556983
Validation loss: 2.5579740516384426

Epoch: 6| Step: 12
Training loss: 1.8080091417300936
Validation loss: 2.5511770287008373

Epoch: 6| Step: 13
Training loss: 1.8849958368149173
Validation loss: 2.5742553029144823

Epoch: 263| Step: 0
Training loss: 2.414212219138592
Validation loss: 2.603080787603795

Epoch: 6| Step: 1
Training loss: 2.401445223861666
Validation loss: 2.6188995986246186

Epoch: 6| Step: 2
Training loss: 1.7939882392710444
Validation loss: 2.609012974582654

Epoch: 6| Step: 3
Training loss: 1.7852100055372306
Validation loss: 2.6551257877281937

Epoch: 6| Step: 4
Training loss: 1.968704283652773
Validation loss: 2.647330143576533

Epoch: 6| Step: 5
Training loss: 2.385527817803209
Validation loss: 2.6631547531713573

Epoch: 6| Step: 6
Training loss: 1.669610459586749
Validation loss: 2.6550371430379753

Epoch: 6| Step: 7
Training loss: 2.5157345576153065
Validation loss: 2.6417928817954244

Epoch: 6| Step: 8
Training loss: 1.5955538545639005
Validation loss: 2.603083619288375

Epoch: 6| Step: 9
Training loss: 2.267652354310997
Validation loss: 2.6097114787665325

Epoch: 6| Step: 10
Training loss: 1.802533205655034
Validation loss: 2.565742534589049

Epoch: 6| Step: 11
Training loss: 1.8933316237594158
Validation loss: 2.549364351694723

Epoch: 6| Step: 12
Training loss: 2.757997414762684
Validation loss: 2.531550935038305

Epoch: 6| Step: 13
Training loss: 1.8354779906173018
Validation loss: 2.5299040587205615

Epoch: 264| Step: 0
Training loss: 2.085190657170636
Validation loss: 2.533771412913735

Epoch: 6| Step: 1
Training loss: 2.5198752944607774
Validation loss: 2.534781374887058

Epoch: 6| Step: 2
Training loss: 1.7057371493630797
Validation loss: 2.5555573984038116

Epoch: 6| Step: 3
Training loss: 1.4924737146513405
Validation loss: 2.6016803367283305

Epoch: 6| Step: 4
Training loss: 1.6702343743148211
Validation loss: 2.6209401418717246

Epoch: 6| Step: 5
Training loss: 2.3553343271137686
Validation loss: 2.6412098705241918

Epoch: 6| Step: 6
Training loss: 2.433753337495354
Validation loss: 2.6615801719254124

Epoch: 6| Step: 7
Training loss: 2.242128590730381
Validation loss: 2.6586370476010583

Epoch: 6| Step: 8
Training loss: 1.9462313645878835
Validation loss: 2.6426948019745606

Epoch: 6| Step: 9
Training loss: 1.510389270753253
Validation loss: 2.6246307961116404

Epoch: 6| Step: 10
Training loss: 2.4828300230585416
Validation loss: 2.611107789594373

Epoch: 6| Step: 11
Training loss: 2.2854147740382027
Validation loss: 2.5983697432421415

Epoch: 6| Step: 12
Training loss: 1.8616765627801481
Validation loss: 2.6162688355816583

Epoch: 6| Step: 13
Training loss: 2.1179092134320423
Validation loss: 2.611802941738873

Epoch: 265| Step: 0
Training loss: 2.324416516008389
Validation loss: 2.5926044339585723

Epoch: 6| Step: 1
Training loss: 1.6913891939003631
Validation loss: 2.598997499302063

Epoch: 6| Step: 2
Training loss: 2.0053345347402574
Validation loss: 2.6097611162572765

Epoch: 6| Step: 3
Training loss: 2.292465024658441
Validation loss: 2.613397919730948

Epoch: 6| Step: 4
Training loss: 2.0870289893629668
Validation loss: 2.6156802111973767

Epoch: 6| Step: 5
Training loss: 2.85240449362703
Validation loss: 2.587747637559227

Epoch: 6| Step: 6
Training loss: 2.298884129388962
Validation loss: 2.5877383397238622

Epoch: 6| Step: 7
Training loss: 2.0453250054078405
Validation loss: 2.6583556262987895

Epoch: 6| Step: 8
Training loss: 2.5583709386822306
Validation loss: 2.670864382566829

Epoch: 6| Step: 9
Training loss: 1.9021946654757447
Validation loss: 2.639057905796555

Epoch: 6| Step: 10
Training loss: 2.09183311965273
Validation loss: 2.5916772013222196

Epoch: 6| Step: 11
Training loss: 1.481709546619037
Validation loss: 2.5719915314945796

Epoch: 6| Step: 12
Training loss: 1.8946813779515275
Validation loss: 2.563022994348217

Epoch: 6| Step: 13
Training loss: 2.01146771985048
Validation loss: 2.559096627162551

Epoch: 266| Step: 0
Training loss: 1.9330295548801841
Validation loss: 2.55535286609822

Epoch: 6| Step: 1
Training loss: 2.1737612211037605
Validation loss: 2.5674467798280753

Epoch: 6| Step: 2
Training loss: 1.9605492439263308
Validation loss: 2.5788624489065426

Epoch: 6| Step: 3
Training loss: 1.9207756806145997
Validation loss: 2.5883026217349654

Epoch: 6| Step: 4
Training loss: 2.0815078621431087
Validation loss: 2.6306995852135264

Epoch: 6| Step: 5
Training loss: 2.4742264665893443
Validation loss: 2.6692130080992036

Epoch: 6| Step: 6
Training loss: 1.9955947162589576
Validation loss: 2.710435525846635

Epoch: 6| Step: 7
Training loss: 2.001147537038771
Validation loss: 2.7067170871382387

Epoch: 6| Step: 8
Training loss: 1.7885670871368535
Validation loss: 2.6870977115428807

Epoch: 6| Step: 9
Training loss: 1.5913012522843846
Validation loss: 2.681292869503777

Epoch: 6| Step: 10
Training loss: 1.660700091874134
Validation loss: 2.655211346578304

Epoch: 6| Step: 11
Training loss: 1.8622084114141209
Validation loss: 2.6289008085242718

Epoch: 6| Step: 12
Training loss: 2.5063868002526006
Validation loss: 2.6382946890263823

Epoch: 6| Step: 13
Training loss: 2.668466993419762
Validation loss: 2.6531431391455005

Epoch: 267| Step: 0
Training loss: 2.9198676573143634
Validation loss: 2.6350724946701667

Epoch: 6| Step: 1
Training loss: 1.9100439744650537
Validation loss: 2.6315617972367247

Epoch: 6| Step: 2
Training loss: 1.443010961785717
Validation loss: 2.6290536794752937

Epoch: 6| Step: 3
Training loss: 1.4884920546653104
Validation loss: 2.6294250580961616

Epoch: 6| Step: 4
Training loss: 2.338432281133509
Validation loss: 2.6240481664270585

Epoch: 6| Step: 5
Training loss: 1.8500966897389597
Validation loss: 2.575203012284461

Epoch: 6| Step: 6
Training loss: 1.8961213979446063
Validation loss: 2.6008394322868233

Epoch: 6| Step: 7
Training loss: 1.9826951012452603
Validation loss: 2.633378252016516

Epoch: 6| Step: 8
Training loss: 2.0396421346737816
Validation loss: 2.6718493603522777

Epoch: 6| Step: 9
Training loss: 1.8865018921374253
Validation loss: 2.6767302897561236

Epoch: 6| Step: 10
Training loss: 1.8862245279643697
Validation loss: 2.67270214818612

Epoch: 6| Step: 11
Training loss: 1.9027650589838834
Validation loss: 2.6649789436467537

Epoch: 6| Step: 12
Training loss: 2.334511005570939
Validation loss: 2.629906360678029

Epoch: 6| Step: 13
Training loss: 2.0602031981609006
Validation loss: 2.581193981532634

Epoch: 268| Step: 0
Training loss: 2.1532980573892457
Validation loss: 2.5760747135899926

Epoch: 6| Step: 1
Training loss: 2.119298466723918
Validation loss: 2.6032389450627367

Epoch: 6| Step: 2
Training loss: 2.5534793901958137
Validation loss: 2.5993839952466558

Epoch: 6| Step: 3
Training loss: 1.6523971368628663
Validation loss: 2.581915856195652

Epoch: 6| Step: 4
Training loss: 2.2186988502301737
Validation loss: 2.59162664249666

Epoch: 6| Step: 5
Training loss: 1.7589929304734475
Validation loss: 2.6086039669860814

Epoch: 6| Step: 6
Training loss: 1.7483991385198359
Validation loss: 2.601060759739481

Epoch: 6| Step: 7
Training loss: 1.66306644054191
Validation loss: 2.667908324808924

Epoch: 6| Step: 8
Training loss: 2.000155085272845
Validation loss: 2.6364460745267353

Epoch: 6| Step: 9
Training loss: 1.9573772680360928
Validation loss: 2.6514042654424768

Epoch: 6| Step: 10
Training loss: 2.5297093353365843
Validation loss: 2.673960505743349

Epoch: 6| Step: 11
Training loss: 2.5011088773082037
Validation loss: 2.6190456493584957

Epoch: 6| Step: 12
Training loss: 1.966640674559392
Validation loss: 2.636824640102229

Epoch: 6| Step: 13
Training loss: 1.5854798206210887
Validation loss: 2.5921672756639356

Epoch: 269| Step: 0
Training loss: 1.8096133956268339
Validation loss: 2.5900977898575537

Epoch: 6| Step: 1
Training loss: 2.5124707082682587
Validation loss: 2.6048644211913983

Epoch: 6| Step: 2
Training loss: 2.356032473290161
Validation loss: 2.54618653741602

Epoch: 6| Step: 3
Training loss: 2.1347965611679403
Validation loss: 2.563593383064863

Epoch: 6| Step: 4
Training loss: 2.7094462137862028
Validation loss: 2.5870918394286715

Epoch: 6| Step: 5
Training loss: 1.7458814794901272
Validation loss: 2.5581731630152076

Epoch: 6| Step: 6
Training loss: 1.862791880836019
Validation loss: 2.571163913816907

Epoch: 6| Step: 7
Training loss: 2.0496046196729902
Validation loss: 2.5629001553104427

Epoch: 6| Step: 8
Training loss: 1.6677551132716182
Validation loss: 2.54057920883097

Epoch: 6| Step: 9
Training loss: 1.8746134041553908
Validation loss: 2.5831426939814786

Epoch: 6| Step: 10
Training loss: 2.138121428699962
Validation loss: 2.5745644691798133

Epoch: 6| Step: 11
Training loss: 1.6080375966094123
Validation loss: 2.637127894929499

Epoch: 6| Step: 12
Training loss: 1.5947132565561704
Validation loss: 2.652134643162225

Epoch: 6| Step: 13
Training loss: 2.13603140813617
Validation loss: 2.662434458037825

Epoch: 270| Step: 0
Training loss: 2.012588698049626
Validation loss: 2.6892929084832136

Epoch: 6| Step: 1
Training loss: 2.397735393531784
Validation loss: 2.6511719427468945

Epoch: 6| Step: 2
Training loss: 1.6252143425062846
Validation loss: 2.666385789821218

Epoch: 6| Step: 3
Training loss: 1.3035379702236365
Validation loss: 2.665264809211198

Epoch: 6| Step: 4
Training loss: 2.6273602365185793
Validation loss: 2.6560025118553585

Epoch: 6| Step: 5
Training loss: 1.7898845533084986
Validation loss: 2.660422873334184

Epoch: 6| Step: 6
Training loss: 2.058902261334548
Validation loss: 2.657711554450549

Epoch: 6| Step: 7
Training loss: 1.5326827216937033
Validation loss: 2.6598439605138537

Epoch: 6| Step: 8
Training loss: 2.0777935251306734
Validation loss: 2.6553582433617104

Epoch: 6| Step: 9
Training loss: 1.553148130555485
Validation loss: 2.6422449894867

Epoch: 6| Step: 10
Training loss: 2.240911034026263
Validation loss: 2.638863933735242

Epoch: 6| Step: 11
Training loss: 2.2447314567781413
Validation loss: 2.6530686718847685

Epoch: 6| Step: 12
Training loss: 2.360207720198142
Validation loss: 2.63021137249963

Epoch: 6| Step: 13
Training loss: 1.8743185712429857
Validation loss: 2.6155687174938094

Epoch: 271| Step: 0
Training loss: 2.5507685382053085
Validation loss: 2.6659531433459733

Epoch: 6| Step: 1
Training loss: 1.726763062026328
Validation loss: 2.6781015846893577

Epoch: 6| Step: 2
Training loss: 2.101939568141795
Validation loss: 2.703706946968599

Epoch: 6| Step: 3
Training loss: 2.416440218696893
Validation loss: 2.693278170609304

Epoch: 6| Step: 4
Training loss: 2.1286729597306686
Validation loss: 2.7034061851594204

Epoch: 6| Step: 5
Training loss: 1.8405242115139222
Validation loss: 2.692210792799405

Epoch: 6| Step: 6
Training loss: 1.904550701733357
Validation loss: 2.6732258495720544

Epoch: 6| Step: 7
Training loss: 1.43457737577503
Validation loss: 2.669256820021651

Epoch: 6| Step: 8
Training loss: 1.9239624596183025
Validation loss: 2.625203556161088

Epoch: 6| Step: 9
Training loss: 2.034362052255144
Validation loss: 2.6192737519910483

Epoch: 6| Step: 10
Training loss: 2.2825462107665353
Validation loss: 2.644079578318804

Epoch: 6| Step: 11
Training loss: 2.261274488494684
Validation loss: 2.6617943588310182

Epoch: 6| Step: 12
Training loss: 1.5630032301202492
Validation loss: 2.7078235488786517

Epoch: 6| Step: 13
Training loss: 1.8978676902350335
Validation loss: 2.7015089375010763

Epoch: 272| Step: 0
Training loss: 2.4598879559129827
Validation loss: 2.7263881769717555

Epoch: 6| Step: 1
Training loss: 2.0219823841191675
Validation loss: 2.7489139695446645

Epoch: 6| Step: 2
Training loss: 2.6536094555718246
Validation loss: 2.7530936988093275

Epoch: 6| Step: 3
Training loss: 2.0221104338888223
Validation loss: 2.665046428159099

Epoch: 6| Step: 4
Training loss: 1.8851402108134183
Validation loss: 2.6372064436128073

Epoch: 6| Step: 5
Training loss: 1.8724048456886795
Validation loss: 2.617680092378546

Epoch: 6| Step: 6
Training loss: 1.909085775343693
Validation loss: 2.5757715600105007

Epoch: 6| Step: 7
Training loss: 2.5844259310112374
Validation loss: 2.5487700512970233

Epoch: 6| Step: 8
Training loss: 1.9626613502020114
Validation loss: 2.5948779246601075

Epoch: 6| Step: 9
Training loss: 1.299981957090319
Validation loss: 2.6122605288567144

Epoch: 6| Step: 10
Training loss: 1.928605243346047
Validation loss: 2.6013574528960124

Epoch: 6| Step: 11
Training loss: 2.5579382136729305
Validation loss: 2.6509565828131105

Epoch: 6| Step: 12
Training loss: 1.6662965204565763
Validation loss: 2.676062219723218

Epoch: 6| Step: 13
Training loss: 2.0041037419434353
Validation loss: 2.735855428385879

Epoch: 273| Step: 0
Training loss: 2.588204856364643
Validation loss: 2.7357186204291852

Epoch: 6| Step: 1
Training loss: 1.5858589491159323
Validation loss: 2.7162657162966073

Epoch: 6| Step: 2
Training loss: 1.7719031599118131
Validation loss: 2.6520839857973155

Epoch: 6| Step: 3
Training loss: 1.5225610021136988
Validation loss: 2.6225488208339365

Epoch: 6| Step: 4
Training loss: 1.4717903323432826
Validation loss: 2.597219039339324

Epoch: 6| Step: 5
Training loss: 2.1584017424868374
Validation loss: 2.5685979966780343

Epoch: 6| Step: 6
Training loss: 2.0113266646127443
Validation loss: 2.5433120339573745

Epoch: 6| Step: 7
Training loss: 2.6219721088453607
Validation loss: 2.5482405217843764

Epoch: 6| Step: 8
Training loss: 1.6089516981140277
Validation loss: 2.5710348642785408

Epoch: 6| Step: 9
Training loss: 2.2976133236836125
Validation loss: 2.570456642816622

Epoch: 6| Step: 10
Training loss: 1.8534585121930565
Validation loss: 2.5798499299792987

Epoch: 6| Step: 11
Training loss: 2.240587148519576
Validation loss: 2.5876155452760394

Epoch: 6| Step: 12
Training loss: 2.2943762857116075
Validation loss: 2.6198659675229248

Epoch: 6| Step: 13
Training loss: 1.9905606677141459
Validation loss: 2.655764666330832

Epoch: 274| Step: 0
Training loss: 1.9496496179211054
Validation loss: 2.673895267287248

Epoch: 6| Step: 1
Training loss: 2.2029729479541333
Validation loss: 2.7304423726144367

Epoch: 6| Step: 2
Training loss: 2.236153488336809
Validation loss: 2.690510091716728

Epoch: 6| Step: 3
Training loss: 2.1476672092128988
Validation loss: 2.716098310738175

Epoch: 6| Step: 4
Training loss: 2.2016882574200483
Validation loss: 2.68674155186144

Epoch: 6| Step: 5
Training loss: 2.0958162047923046
Validation loss: 2.662227009492277

Epoch: 6| Step: 6
Training loss: 2.080617915216211
Validation loss: 2.601956059927116

Epoch: 6| Step: 7
Training loss: 1.4815439632714924
Validation loss: 2.5997534830651055

Epoch: 6| Step: 8
Training loss: 1.9520798595265922
Validation loss: 2.5959004139894475

Epoch: 6| Step: 9
Training loss: 2.141343713102603
Validation loss: 2.6061235907961566

Epoch: 6| Step: 10
Training loss: 2.033368810229543
Validation loss: 2.5835092905068353

Epoch: 6| Step: 11
Training loss: 1.7941204020902988
Validation loss: 2.5834736683372768

Epoch: 6| Step: 12
Training loss: 2.408316183414137
Validation loss: 2.5776838753668168

Epoch: 6| Step: 13
Training loss: 1.8462574605720008
Validation loss: 2.6035135187596974

Epoch: 275| Step: 0
Training loss: 2.8839210095110306
Validation loss: 2.61393198256374

Epoch: 6| Step: 1
Training loss: 1.7252715795383757
Validation loss: 2.6282527993813014

Epoch: 6| Step: 2
Training loss: 2.348092189434697
Validation loss: 2.706703830457592

Epoch: 6| Step: 3
Training loss: 1.78527524455531
Validation loss: 2.6606440981381936

Epoch: 6| Step: 4
Training loss: 2.7412209396804963
Validation loss: 2.690792890472985

Epoch: 6| Step: 5
Training loss: 1.5574084677213618
Validation loss: 2.6794104845351794

Epoch: 6| Step: 6
Training loss: 1.8790350411859378
Validation loss: 2.6334634310137233

Epoch: 6| Step: 7
Training loss: 1.710200460184031
Validation loss: 2.614774785624949

Epoch: 6| Step: 8
Training loss: 1.4239497714935208
Validation loss: 2.5908381344896037

Epoch: 6| Step: 9
Training loss: 1.8813198393471384
Validation loss: 2.601112196921759

Epoch: 6| Step: 10
Training loss: 2.2040217312885524
Validation loss: 2.5722139122084684

Epoch: 6| Step: 11
Training loss: 2.5638021556621107
Validation loss: 2.586724291271011

Epoch: 6| Step: 12
Training loss: 1.1905594114325306
Validation loss: 2.610852856636614

Epoch: 6| Step: 13
Training loss: 1.4017820800789678
Validation loss: 2.6492872197250086

Epoch: 276| Step: 0
Training loss: 1.3228326705739348
Validation loss: 2.6784823184858406

Epoch: 6| Step: 1
Training loss: 1.9084426276658255
Validation loss: 2.666480122439023

Epoch: 6| Step: 2
Training loss: 2.84198848956661
Validation loss: 2.7350521012247984

Epoch: 6| Step: 3
Training loss: 1.7219710944581899
Validation loss: 2.7002883904288035

Epoch: 6| Step: 4
Training loss: 2.1219295309304265
Validation loss: 2.6663277132464924

Epoch: 6| Step: 5
Training loss: 2.0051674842802156
Validation loss: 2.5975405712710256

Epoch: 6| Step: 6
Training loss: 1.5460653016189572
Validation loss: 2.579577951706531

Epoch: 6| Step: 7
Training loss: 1.4854762760452
Validation loss: 2.534911862483284

Epoch: 6| Step: 8
Training loss: 2.6660610544435226
Validation loss: 2.557828335411038

Epoch: 6| Step: 9
Training loss: 2.142350107333383
Validation loss: 2.5417588535121003

Epoch: 6| Step: 10
Training loss: 2.143275937527589
Validation loss: 2.5875192742850732

Epoch: 6| Step: 11
Training loss: 1.9948521165843387
Validation loss: 2.5957283227375383

Epoch: 6| Step: 12
Training loss: 1.9475696751051137
Validation loss: 2.608762368412184

Epoch: 6| Step: 13
Training loss: 2.2031331163622103
Validation loss: 2.661265302153899

Epoch: 277| Step: 0
Training loss: 1.8539422431599373
Validation loss: 2.693762085453074

Epoch: 6| Step: 1
Training loss: 1.6939717981587394
Validation loss: 2.6992720117020363

Epoch: 6| Step: 2
Training loss: 1.7900665664016653
Validation loss: 2.7535224593011836

Epoch: 6| Step: 3
Training loss: 2.224775915970356
Validation loss: 2.7067051957665713

Epoch: 6| Step: 4
Training loss: 2.478022292559507
Validation loss: 2.6881362546312513

Epoch: 6| Step: 5
Training loss: 1.4461946836557165
Validation loss: 2.648720470154044

Epoch: 6| Step: 6
Training loss: 1.8294823978700125
Validation loss: 2.614556914014941

Epoch: 6| Step: 7
Training loss: 2.927796753160954
Validation loss: 2.609107241721916

Epoch: 6| Step: 8
Training loss: 2.492520779414974
Validation loss: 2.6212041066981513

Epoch: 6| Step: 9
Training loss: 1.670472742428628
Validation loss: 2.6698855528073513

Epoch: 6| Step: 10
Training loss: 2.038623046290246
Validation loss: 2.735947997550353

Epoch: 6| Step: 11
Training loss: 1.7701756396676651
Validation loss: 2.7468369818014096

Epoch: 6| Step: 12
Training loss: 2.3986003211605276
Validation loss: 2.6931339176007025

Epoch: 6| Step: 13
Training loss: 1.994359885182094
Validation loss: 2.6836864264790563

Epoch: 278| Step: 0
Training loss: 2.829780894717712
Validation loss: 2.6176487606347285

Epoch: 6| Step: 1
Training loss: 1.9416732144006612
Validation loss: 2.5918196576786126

Epoch: 6| Step: 2
Training loss: 2.3026279363388276
Validation loss: 2.5603591535878962

Epoch: 6| Step: 3
Training loss: 2.2127754471004897
Validation loss: 2.526510613293415

Epoch: 6| Step: 4
Training loss: 1.6736876029248853
Validation loss: 2.527707120469126

Epoch: 6| Step: 5
Training loss: 1.8041986240907342
Validation loss: 2.571264336149943

Epoch: 6| Step: 6
Training loss: 2.299396298831676
Validation loss: 2.543515577769633

Epoch: 6| Step: 7
Training loss: 1.6345295615990214
Validation loss: 2.5594190203273803

Epoch: 6| Step: 8
Training loss: 1.552482690146446
Validation loss: 2.594021334875836

Epoch: 6| Step: 9
Training loss: 2.0088961159642698
Validation loss: 2.622787027182665

Epoch: 6| Step: 10
Training loss: 2.150165209965333
Validation loss: 2.6737710126039564

Epoch: 6| Step: 11
Training loss: 2.1101954242187038
Validation loss: 2.689908020805787

Epoch: 6| Step: 12
Training loss: 1.943326986225073
Validation loss: 2.6836209210200708

Epoch: 6| Step: 13
Training loss: 1.4092789983088738
Validation loss: 2.668784289173267

Epoch: 279| Step: 0
Training loss: 1.7905641608696052
Validation loss: 2.6216056009380417

Epoch: 6| Step: 1
Training loss: 1.4202553883433382
Validation loss: 2.608359179099572

Epoch: 6| Step: 2
Training loss: 2.315343706392044
Validation loss: 2.591189687284295

Epoch: 6| Step: 3
Training loss: 1.2151762087324407
Validation loss: 2.6049523554354197

Epoch: 6| Step: 4
Training loss: 2.4171921279359885
Validation loss: 2.6009493192066317

Epoch: 6| Step: 5
Training loss: 2.525560271545936
Validation loss: 2.6068346521960257

Epoch: 6| Step: 6
Training loss: 1.9860102606409398
Validation loss: 2.5905433197090657

Epoch: 6| Step: 7
Training loss: 1.921659628112731
Validation loss: 2.645833929066829

Epoch: 6| Step: 8
Training loss: 2.2193357742095996
Validation loss: 2.6092991008874877

Epoch: 6| Step: 9
Training loss: 1.9291392794725533
Validation loss: 2.6068801983970724

Epoch: 6| Step: 10
Training loss: 2.604847892669611
Validation loss: 2.6122541400142687

Epoch: 6| Step: 11
Training loss: 1.5849307016813323
Validation loss: 2.6448465118991744

Epoch: 6| Step: 12
Training loss: 1.7473887989643557
Validation loss: 2.6011174521037828

Epoch: 6| Step: 13
Training loss: 1.8955254217368553
Validation loss: 2.6444235422428513

Epoch: 280| Step: 0
Training loss: 1.7508768881976002
Validation loss: 2.666606356018254

Epoch: 6| Step: 1
Training loss: 1.5256315424496376
Validation loss: 2.6611245251447793

Epoch: 6| Step: 2
Training loss: 1.4768110600924222
Validation loss: 2.656425096313238

Epoch: 6| Step: 3
Training loss: 2.1548482789268695
Validation loss: 2.687448501093493

Epoch: 6| Step: 4
Training loss: 1.6223329518614718
Validation loss: 2.6518770012273705

Epoch: 6| Step: 5
Training loss: 2.196085512084058
Validation loss: 2.633865327052698

Epoch: 6| Step: 6
Training loss: 2.402490428385488
Validation loss: 2.662460292824535

Epoch: 6| Step: 7
Training loss: 1.2395831463383553
Validation loss: 2.638443084895228

Epoch: 6| Step: 8
Training loss: 2.085170190392235
Validation loss: 2.588939526157753

Epoch: 6| Step: 9
Training loss: 2.503516584953592
Validation loss: 2.619882067617816

Epoch: 6| Step: 10
Training loss: 1.6433987376343437
Validation loss: 2.6393748075819534

Epoch: 6| Step: 11
Training loss: 2.191187556977055
Validation loss: 2.6266610475986747

Epoch: 6| Step: 12
Training loss: 1.8834599058553707
Validation loss: 2.647153169741615

Epoch: 6| Step: 13
Training loss: 2.2247920978582756
Validation loss: 2.6900377785441814

Epoch: 281| Step: 0
Training loss: 1.7625632957834638
Validation loss: 2.703421530509761

Epoch: 6| Step: 1
Training loss: 1.5758230965031508
Validation loss: 2.6898208621622133

Epoch: 6| Step: 2
Training loss: 2.4069365475654623
Validation loss: 2.6623920711318267

Epoch: 6| Step: 3
Training loss: 1.845596035873131
Validation loss: 2.677339732042141

Epoch: 6| Step: 4
Training loss: 1.8566902075370344
Validation loss: 2.6062388504485074

Epoch: 6| Step: 5
Training loss: 1.850091535004884
Validation loss: 2.5608264606539604

Epoch: 6| Step: 6
Training loss: 1.910105948380693
Validation loss: 2.5818742713012997

Epoch: 6| Step: 7
Training loss: 1.6204771041029475
Validation loss: 2.5620127579100633

Epoch: 6| Step: 8
Training loss: 2.4170519642229262
Validation loss: 2.546674045677712

Epoch: 6| Step: 9
Training loss: 2.6704488595573648
Validation loss: 2.5614758902919297

Epoch: 6| Step: 10
Training loss: 2.6780085072058206
Validation loss: 2.57727947819853

Epoch: 6| Step: 11
Training loss: 1.4655214903501002
Validation loss: 2.637840186985598

Epoch: 6| Step: 12
Training loss: 1.5411120869236865
Validation loss: 2.7095141453195115

Epoch: 6| Step: 13
Training loss: 1.9617024179839926
Validation loss: 2.7053369134353153

Epoch: 282| Step: 0
Training loss: 2.510758615422967
Validation loss: 2.6944603646409973

Epoch: 6| Step: 1
Training loss: 1.6628700962999423
Validation loss: 2.6729569651855543

Epoch: 6| Step: 2
Training loss: 1.8860808690149293
Validation loss: 2.6520632940605564

Epoch: 6| Step: 3
Training loss: 2.173386740623124
Validation loss: 2.6222129285732096

Epoch: 6| Step: 4
Training loss: 2.374306828583822
Validation loss: 2.5935474301329133

Epoch: 6| Step: 5
Training loss: 2.0213404802348696
Validation loss: 2.603101822901413

Epoch: 6| Step: 6
Training loss: 2.550850602940703
Validation loss: 2.578565008974154

Epoch: 6| Step: 7
Training loss: 1.5142101487484338
Validation loss: 2.6083478143145817

Epoch: 6| Step: 8
Training loss: 2.022549113843151
Validation loss: 2.6473566511067563

Epoch: 6| Step: 9
Training loss: 1.6250337450485104
Validation loss: 2.6483617000929165

Epoch: 6| Step: 10
Training loss: 2.3624435579531124
Validation loss: 2.6701297748830677

Epoch: 6| Step: 11
Training loss: 1.22522113127636
Validation loss: 2.681922047650655

Epoch: 6| Step: 12
Training loss: 1.622769365330582
Validation loss: 2.6623969665554386

Epoch: 6| Step: 13
Training loss: 2.069121165559454
Validation loss: 2.650755926195434

Epoch: 283| Step: 0
Training loss: 1.7375607486780655
Validation loss: 2.638376109735751

Epoch: 6| Step: 1
Training loss: 2.4940339426332665
Validation loss: 2.652425548432609

Epoch: 6| Step: 2
Training loss: 2.5887524361002616
Validation loss: 2.65635957678875

Epoch: 6| Step: 3
Training loss: 2.0893252861551233
Validation loss: 2.667602171319118

Epoch: 6| Step: 4
Training loss: 2.3882378521521153
Validation loss: 2.6434901717784745

Epoch: 6| Step: 5
Training loss: 1.1924575919681917
Validation loss: 2.6160312204976934

Epoch: 6| Step: 6
Training loss: 1.791468306213981
Validation loss: 2.598126942910147

Epoch: 6| Step: 7
Training loss: 1.6998381088812633
Validation loss: 2.584321899360559

Epoch: 6| Step: 8
Training loss: 1.7000856490157366
Validation loss: 2.5894951142199143

Epoch: 6| Step: 9
Training loss: 1.4775001737591276
Validation loss: 2.5885116043238434

Epoch: 6| Step: 10
Training loss: 2.327872140965091
Validation loss: 2.589853032605167

Epoch: 6| Step: 11
Training loss: 1.8866867789329889
Validation loss: 2.5766507335859465

Epoch: 6| Step: 12
Training loss: 2.0220069099330837
Validation loss: 2.608299178264461

Epoch: 6| Step: 13
Training loss: 2.2384252585108695
Validation loss: 2.5974794714871883

Epoch: 284| Step: 0
Training loss: 2.0288585964242722
Validation loss: 2.609478809477015

Epoch: 6| Step: 1
Training loss: 2.4233264142566884
Validation loss: 2.6252440838639504

Epoch: 6| Step: 2
Training loss: 1.6806921504952441
Validation loss: 2.669290612620442

Epoch: 6| Step: 3
Training loss: 2.3264090339459003
Validation loss: 2.712414151545706

Epoch: 6| Step: 4
Training loss: 1.7124517002394772
Validation loss: 2.7944564094080855

Epoch: 6| Step: 5
Training loss: 2.446005920958195
Validation loss: 2.8356084851686565

Epoch: 6| Step: 6
Training loss: 2.4568486229201882
Validation loss: 2.7197022798231507

Epoch: 6| Step: 7
Training loss: 1.6735366692174187
Validation loss: 2.677867378773291

Epoch: 6| Step: 8
Training loss: 1.6096625950700512
Validation loss: 2.576487119183877

Epoch: 6| Step: 9
Training loss: 2.3514537089076404
Validation loss: 2.5258450828169052

Epoch: 6| Step: 10
Training loss: 1.577748470899832
Validation loss: 2.4900759976954747

Epoch: 6| Step: 11
Training loss: 2.1323427234892334
Validation loss: 2.486551319221985

Epoch: 6| Step: 12
Training loss: 2.2339192172328692
Validation loss: 2.5327987485398964

Epoch: 6| Step: 13
Training loss: 2.364235626961171
Validation loss: 2.4878347206792486

Epoch: 285| Step: 0
Training loss: 2.0597101474281416
Validation loss: 2.522092123977901

Epoch: 6| Step: 1
Training loss: 1.681925360734727
Validation loss: 2.5540276082462743

Epoch: 6| Step: 2
Training loss: 1.2001279683226875
Validation loss: 2.5454007584031064

Epoch: 6| Step: 3
Training loss: 1.4025066568009261
Validation loss: 2.559899879573963

Epoch: 6| Step: 4
Training loss: 2.0936485379814926
Validation loss: 2.6397540294448953

Epoch: 6| Step: 5
Training loss: 1.5607215678533666
Validation loss: 2.6900612802155077

Epoch: 6| Step: 6
Training loss: 2.531192920182523
Validation loss: 2.75364416151367

Epoch: 6| Step: 7
Training loss: 2.5903457914484895
Validation loss: 2.7974253846400225

Epoch: 6| Step: 8
Training loss: 2.658186262919516
Validation loss: 2.832388837315906

Epoch: 6| Step: 9
Training loss: 1.8491900733107007
Validation loss: 2.80034369788855

Epoch: 6| Step: 10
Training loss: 2.264857194958638
Validation loss: 2.821281555454526

Epoch: 6| Step: 11
Training loss: 2.086789303711205
Validation loss: 2.7257496260600442

Epoch: 6| Step: 12
Training loss: 1.9089557643219341
Validation loss: 2.6767073093842524

Epoch: 6| Step: 13
Training loss: 1.7572083515827577
Validation loss: 2.6072132803431702

Epoch: 286| Step: 0
Training loss: 2.2896549642903117
Validation loss: 2.5711982692669557

Epoch: 6| Step: 1
Training loss: 1.6143264894363376
Validation loss: 2.5781830443966993

Epoch: 6| Step: 2
Training loss: 1.7080313330329138
Validation loss: 2.57478729900384

Epoch: 6| Step: 3
Training loss: 2.3117299215311764
Validation loss: 2.565304462080885

Epoch: 6| Step: 4
Training loss: 1.8041563367070697
Validation loss: 2.5738899665459014

Epoch: 6| Step: 5
Training loss: 2.656411738239967
Validation loss: 2.5701651100947376

Epoch: 6| Step: 6
Training loss: 2.14900305500053
Validation loss: 2.5990107702394383

Epoch: 6| Step: 7
Training loss: 2.004049849988521
Validation loss: 2.6017347093620775

Epoch: 6| Step: 8
Training loss: 1.5824567811195756
Validation loss: 2.6249229329013195

Epoch: 6| Step: 9
Training loss: 2.1282482005124823
Validation loss: 2.647060490173447

Epoch: 6| Step: 10
Training loss: 1.9137255313637092
Validation loss: 2.642910075854289

Epoch: 6| Step: 11
Training loss: 1.5028506847534995
Validation loss: 2.577556632227917

Epoch: 6| Step: 12
Training loss: 2.4410848421247913
Validation loss: 2.6018067513515644

Epoch: 6| Step: 13
Training loss: 2.082398459167438
Validation loss: 2.6283700669220678

Epoch: 287| Step: 0
Training loss: 1.6474584772784684
Validation loss: 2.6464677085210906

Epoch: 6| Step: 1
Training loss: 2.5836820879732607
Validation loss: 2.6413150013767774

Epoch: 6| Step: 2
Training loss: 1.4138148812837659
Validation loss: 2.624445478209614

Epoch: 6| Step: 3
Training loss: 1.6144722520907555
Validation loss: 2.64211261386726

Epoch: 6| Step: 4
Training loss: 1.728598796330582
Validation loss: 2.6773265228444494

Epoch: 6| Step: 5
Training loss: 2.129380927406528
Validation loss: 2.6723221224428793

Epoch: 6| Step: 6
Training loss: 1.5260407726645429
Validation loss: 2.7049537161853086

Epoch: 6| Step: 7
Training loss: 1.7144701296522988
Validation loss: 2.689274150551169

Epoch: 6| Step: 8
Training loss: 2.452328303526338
Validation loss: 2.7501092224394426

Epoch: 6| Step: 9
Training loss: 1.6336743576179071
Validation loss: 2.7302449161466025

Epoch: 6| Step: 10
Training loss: 2.1829248813106394
Validation loss: 2.769279708881563

Epoch: 6| Step: 11
Training loss: 2.193198927652228
Validation loss: 2.762145747259658

Epoch: 6| Step: 12
Training loss: 2.000233636561009
Validation loss: 2.7679019757344694

Epoch: 6| Step: 13
Training loss: 1.8666530466718152
Validation loss: 2.747575934173296

Epoch: 288| Step: 0
Training loss: 2.379341273628653
Validation loss: 2.73436799548024

Epoch: 6| Step: 1
Training loss: 2.460661857547916
Validation loss: 2.741090980970097

Epoch: 6| Step: 2
Training loss: 2.3698260517909473
Validation loss: 2.7032332058750046

Epoch: 6| Step: 3
Training loss: 1.6429194799881732
Validation loss: 2.718030140018905

Epoch: 6| Step: 4
Training loss: 1.7451465606352161
Validation loss: 2.693446979753136

Epoch: 6| Step: 5
Training loss: 1.6961383829521504
Validation loss: 2.6990615644383773

Epoch: 6| Step: 6
Training loss: 1.54273417174522
Validation loss: 2.6870325406452165

Epoch: 6| Step: 7
Training loss: 2.4017927825062007
Validation loss: 2.650017371210707

Epoch: 6| Step: 8
Training loss: 1.3399808941375797
Validation loss: 2.649059338930947

Epoch: 6| Step: 9
Training loss: 1.4234449501554485
Validation loss: 2.6440509038719804

Epoch: 6| Step: 10
Training loss: 1.73237907417006
Validation loss: 2.6720231072793434

Epoch: 6| Step: 11
Training loss: 2.086599980569432
Validation loss: 2.632323222442308

Epoch: 6| Step: 12
Training loss: 1.6801620877502508
Validation loss: 2.6367576012280445

Epoch: 6| Step: 13
Training loss: 1.9310888229320842
Validation loss: 2.6527015171329453

Epoch: 289| Step: 0
Training loss: 1.9181998865270118
Validation loss: 2.623418467795136

Epoch: 6| Step: 1
Training loss: 2.132496010350635
Validation loss: 2.64718027947809

Epoch: 6| Step: 2
Training loss: 1.3627085534866235
Validation loss: 2.624514141229502

Epoch: 6| Step: 3
Training loss: 1.5500690352540254
Validation loss: 2.6287047265000183

Epoch: 6| Step: 4
Training loss: 1.9682940606062764
Validation loss: 2.6081660167260923

Epoch: 6| Step: 5
Training loss: 2.3459875996774953
Validation loss: 2.6298399311568526

Epoch: 6| Step: 6
Training loss: 2.127127760206177
Validation loss: 2.67171248746699

Epoch: 6| Step: 7
Training loss: 1.556039959931324
Validation loss: 2.706276352117566

Epoch: 6| Step: 8
Training loss: 2.037806215269251
Validation loss: 2.6980805856599783

Epoch: 6| Step: 9
Training loss: 1.6541555585256023
Validation loss: 2.7156519430131363

Epoch: 6| Step: 10
Training loss: 2.115349791980428
Validation loss: 2.725567874008018

Epoch: 6| Step: 11
Training loss: 1.9686603828499545
Validation loss: 2.6881041623948505

Epoch: 6| Step: 12
Training loss: 1.8130168835484513
Validation loss: 2.6947683328670915

Epoch: 6| Step: 13
Training loss: 2.0042955046526205
Validation loss: 2.7208507942313185

Epoch: 290| Step: 0
Training loss: 2.1164853666661654
Validation loss: 2.6915151632166356

Epoch: 6| Step: 1
Training loss: 2.436192969040746
Validation loss: 2.7126192122366715

Epoch: 6| Step: 2
Training loss: 1.864625713641061
Validation loss: 2.692250038759317

Epoch: 6| Step: 3
Training loss: 1.215727064854144
Validation loss: 2.6677640852240696

Epoch: 6| Step: 4
Training loss: 1.9426049689918323
Validation loss: 2.6541802663968697

Epoch: 6| Step: 5
Training loss: 2.136442455999658
Validation loss: 2.664012800332935

Epoch: 6| Step: 6
Training loss: 1.6952401422625512
Validation loss: 2.688981778819016

Epoch: 6| Step: 7
Training loss: 1.6933904906761328
Validation loss: 2.7232085023173878

Epoch: 6| Step: 8
Training loss: 2.0930422825157944
Validation loss: 2.704251262378025

Epoch: 6| Step: 9
Training loss: 2.594172064210558
Validation loss: 2.7149119270235174

Epoch: 6| Step: 10
Training loss: 1.3131658590751405
Validation loss: 2.6872697628078956

Epoch: 6| Step: 11
Training loss: 1.9526207234747464
Validation loss: 2.652664457322963

Epoch: 6| Step: 12
Training loss: 1.633200494398705
Validation loss: 2.6510269424439277

Epoch: 6| Step: 13
Training loss: 1.5013102530935107
Validation loss: 2.6482415741023853

Epoch: 291| Step: 0
Training loss: 2.1760504674178094
Validation loss: 2.638569952000811

Epoch: 6| Step: 1
Training loss: 1.9786364865833286
Validation loss: 2.6572182330536407

Epoch: 6| Step: 2
Training loss: 1.9819978908908682
Validation loss: 2.7148235805137313

Epoch: 6| Step: 3
Training loss: 2.2359295752256267
Validation loss: 2.7426117136900188

Epoch: 6| Step: 4
Training loss: 2.390090882716141
Validation loss: 2.7624764920438416

Epoch: 6| Step: 5
Training loss: 1.8889792349034016
Validation loss: 2.717700492600964

Epoch: 6| Step: 6
Training loss: 1.7344801587366243
Validation loss: 2.669842011662556

Epoch: 6| Step: 7
Training loss: 1.2697986497235867
Validation loss: 2.648395939353646

Epoch: 6| Step: 8
Training loss: 1.8843974173811346
Validation loss: 2.5974637603189867

Epoch: 6| Step: 9
Training loss: 2.303411822529771
Validation loss: 2.6075192703554197

Epoch: 6| Step: 10
Training loss: 2.6216167263634724
Validation loss: 2.571584238122815

Epoch: 6| Step: 11
Training loss: 1.973178001371038
Validation loss: 2.5653616890513242

Epoch: 6| Step: 12
Training loss: 1.612843303951691
Validation loss: 2.5663236917332037

Epoch: 6| Step: 13
Training loss: 1.8567313626567308
Validation loss: 2.5952469362922423

Epoch: 292| Step: 0
Training loss: 1.9542590701685847
Validation loss: 2.578476174837793

Epoch: 6| Step: 1
Training loss: 1.4701746260793656
Validation loss: 2.6625510931709324

Epoch: 6| Step: 2
Training loss: 2.4821261418123792
Validation loss: 2.6538951683018945

Epoch: 6| Step: 3
Training loss: 1.7175453819709214
Validation loss: 2.703361317148334

Epoch: 6| Step: 4
Training loss: 1.734223161529036
Validation loss: 2.728827715105038

Epoch: 6| Step: 5
Training loss: 2.1877837950675016
Validation loss: 2.7591500933337683

Epoch: 6| Step: 6
Training loss: 2.275123311987136
Validation loss: 2.731551778257542

Epoch: 6| Step: 7
Training loss: 2.138142615198066
Validation loss: 2.6602854498933084

Epoch: 6| Step: 8
Training loss: 1.349978626929743
Validation loss: 2.609742403338662

Epoch: 6| Step: 9
Training loss: 1.903984662406918
Validation loss: 2.623678533263187

Epoch: 6| Step: 10
Training loss: 1.2605839873088378
Validation loss: 2.612148539311968

Epoch: 6| Step: 11
Training loss: 2.269507718251499
Validation loss: 2.6227239247578136

Epoch: 6| Step: 12
Training loss: 2.3539302223319334
Validation loss: 2.6054428686470272

Epoch: 6| Step: 13
Training loss: 1.6552035066579454
Validation loss: 2.6186865010601315

Epoch: 293| Step: 0
Training loss: 1.5929740063784967
Validation loss: 2.621128102895611

Epoch: 6| Step: 1
Training loss: 2.4551683407810323
Validation loss: 2.6175942783325046

Epoch: 6| Step: 2
Training loss: 1.7722139548996103
Validation loss: 2.647570562866197

Epoch: 6| Step: 3
Training loss: 1.8066310573015236
Validation loss: 2.6044996633614272

Epoch: 6| Step: 4
Training loss: 1.8344885769829178
Validation loss: 2.631282342876599

Epoch: 6| Step: 5
Training loss: 2.364331830019087
Validation loss: 2.591645394224666

Epoch: 6| Step: 6
Training loss: 1.4050588437311902
Validation loss: 2.6569299612953907

Epoch: 6| Step: 7
Training loss: 2.072557261634208
Validation loss: 2.6378297928037395

Epoch: 6| Step: 8
Training loss: 1.6764988640958565
Validation loss: 2.6455223521502753

Epoch: 6| Step: 9
Training loss: 1.63975894412454
Validation loss: 2.6441411266381847

Epoch: 6| Step: 10
Training loss: 1.5817626725146363
Validation loss: 2.6548667896567135

Epoch: 6| Step: 11
Training loss: 2.553821848690913
Validation loss: 2.7012779672879237

Epoch: 6| Step: 12
Training loss: 1.5615932122172904
Validation loss: 2.7028945133678794

Epoch: 6| Step: 13
Training loss: 1.9696411053753866
Validation loss: 2.6927433909354366

Epoch: 294| Step: 0
Training loss: 1.8075649556878342
Validation loss: 2.6804950264754903

Epoch: 6| Step: 1
Training loss: 1.6288520932056807
Validation loss: 2.68395608661201

Epoch: 6| Step: 2
Training loss: 1.9663566695257324
Validation loss: 2.7012761579285876

Epoch: 6| Step: 3
Training loss: 1.9244703431157317
Validation loss: 2.673969927293177

Epoch: 6| Step: 4
Training loss: 1.1732254385288472
Validation loss: 2.6500458761358825

Epoch: 6| Step: 5
Training loss: 2.1578567710274004
Validation loss: 2.629211400513467

Epoch: 6| Step: 6
Training loss: 1.690808197080309
Validation loss: 2.6377826945954372

Epoch: 6| Step: 7
Training loss: 1.8748261689033296
Validation loss: 2.6362988248270693

Epoch: 6| Step: 8
Training loss: 2.205299008222632
Validation loss: 2.615085725783228

Epoch: 6| Step: 9
Training loss: 1.3934691415579037
Validation loss: 2.5962188185470954

Epoch: 6| Step: 10
Training loss: 1.7035416959513996
Validation loss: 2.5950508302697375

Epoch: 6| Step: 11
Training loss: 2.5596799452209944
Validation loss: 2.602229570281052

Epoch: 6| Step: 12
Training loss: 2.269374717264833
Validation loss: 2.5900925123171272

Epoch: 6| Step: 13
Training loss: 1.80699888234191
Validation loss: 2.582747936576462

Epoch: 295| Step: 0
Training loss: 1.6306967282995601
Validation loss: 2.62052830273962

Epoch: 6| Step: 1
Training loss: 1.5536947483295869
Validation loss: 2.598096996575827

Epoch: 6| Step: 2
Training loss: 1.6574446490267487
Validation loss: 2.6349885665722717

Epoch: 6| Step: 3
Training loss: 1.633613645413281
Validation loss: 2.6667550688236745

Epoch: 6| Step: 4
Training loss: 1.8850316309614918
Validation loss: 2.6499911302142185

Epoch: 6| Step: 5
Training loss: 2.246153192148224
Validation loss: 2.6671855441568417

Epoch: 6| Step: 6
Training loss: 1.5942537596157107
Validation loss: 2.6960961276168898

Epoch: 6| Step: 7
Training loss: 1.5453563903808776
Validation loss: 2.671804073946495

Epoch: 6| Step: 8
Training loss: 2.5470263664339665
Validation loss: 2.680950760463782

Epoch: 6| Step: 9
Training loss: 1.4155247330682634
Validation loss: 2.6289504011130083

Epoch: 6| Step: 10
Training loss: 1.2308404270312927
Validation loss: 2.667055508953603

Epoch: 6| Step: 11
Training loss: 2.0432390140008
Validation loss: 2.647176001381979

Epoch: 6| Step: 12
Training loss: 2.5030329426614304
Validation loss: 2.665846241471271

Epoch: 6| Step: 13
Training loss: 2.4003232817674016
Validation loss: 2.6847518946448576

Epoch: 296| Step: 0
Training loss: 1.8736463110636443
Validation loss: 2.7066994262303843

Epoch: 6| Step: 1
Training loss: 1.7917666592159485
Validation loss: 2.7766058362256185

Epoch: 6| Step: 2
Training loss: 2.3122863670852283
Validation loss: 2.695890650270093

Epoch: 6| Step: 3
Training loss: 1.700667612031928
Validation loss: 2.7639531112655686

Epoch: 6| Step: 4
Training loss: 1.6666644891088884
Validation loss: 2.743728422110482

Epoch: 6| Step: 5
Training loss: 1.6658778787712412
Validation loss: 2.733549970865168

Epoch: 6| Step: 6
Training loss: 1.443613239102686
Validation loss: 2.715690908740611

Epoch: 6| Step: 7
Training loss: 1.9721208809021775
Validation loss: 2.6973667148850757

Epoch: 6| Step: 8
Training loss: 2.1003633502695473
Validation loss: 2.7007397912679485

Epoch: 6| Step: 9
Training loss: 1.8657519835638292
Validation loss: 2.684824728309418

Epoch: 6| Step: 10
Training loss: 2.162668157665587
Validation loss: 2.664732139454777

Epoch: 6| Step: 11
Training loss: 1.6756190508260553
Validation loss: 2.658498956389883

Epoch: 6| Step: 12
Training loss: 2.3455459834307626
Validation loss: 2.6962407158562236

Epoch: 6| Step: 13
Training loss: 1.6095207666845035
Validation loss: 2.688316383860211

Epoch: 297| Step: 0
Training loss: 1.7872010254418993
Validation loss: 2.703032945891995

Epoch: 6| Step: 1
Training loss: 1.5467748898565514
Validation loss: 2.7481997261474937

Epoch: 6| Step: 2
Training loss: 2.1367597000689207
Validation loss: 2.814240079815907

Epoch: 6| Step: 3
Training loss: 1.9667785098175894
Validation loss: 2.8155512329780272

Epoch: 6| Step: 4
Training loss: 2.045242940187597
Validation loss: 2.773630355791968

Epoch: 6| Step: 5
Training loss: 1.648880596180022
Validation loss: 2.746427411735791

Epoch: 6| Step: 6
Training loss: 1.420795240292438
Validation loss: 2.6633681569868424

Epoch: 6| Step: 7
Training loss: 1.4237284893658217
Validation loss: 2.648046654112569

Epoch: 6| Step: 8
Training loss: 2.0502148817999433
Validation loss: 2.5925171844614265

Epoch: 6| Step: 9
Training loss: 2.025053461570039
Validation loss: 2.610333554060317

Epoch: 6| Step: 10
Training loss: 2.2392993362509586
Validation loss: 2.627290664788413

Epoch: 6| Step: 11
Training loss: 2.2047642230141644
Validation loss: 2.623638859818569

Epoch: 6| Step: 12
Training loss: 2.5061456482583817
Validation loss: 2.628071184246143

Epoch: 6| Step: 13
Training loss: 2.01335145933737
Validation loss: 2.627406243594274

Epoch: 298| Step: 0
Training loss: 1.8887204752747093
Validation loss: 2.6853741584493234

Epoch: 6| Step: 1
Training loss: 1.5947835226451086
Validation loss: 2.6981745170789937

Epoch: 6| Step: 2
Training loss: 1.9740110673797078
Validation loss: 2.6394327696321653

Epoch: 6| Step: 3
Training loss: 1.7080866782910695
Validation loss: 2.63765242258204

Epoch: 6| Step: 4
Training loss: 2.482364440781794
Validation loss: 2.5982318135367737

Epoch: 6| Step: 5
Training loss: 1.5429729992771788
Validation loss: 2.6075120012611226

Epoch: 6| Step: 6
Training loss: 2.033232674947369
Validation loss: 2.6185068932632465

Epoch: 6| Step: 7
Training loss: 2.2645136771299685
Validation loss: 2.592137168501416

Epoch: 6| Step: 8
Training loss: 1.3803354264769858
Validation loss: 2.6087578445314192

Epoch: 6| Step: 9
Training loss: 1.4390548921232802
Validation loss: 2.5943654720431946

Epoch: 6| Step: 10
Training loss: 2.0902587478576917
Validation loss: 2.604045290343616

Epoch: 6| Step: 11
Training loss: 1.9695768890479874
Validation loss: 2.609817726206333

Epoch: 6| Step: 12
Training loss: 1.560698042364476
Validation loss: 2.5887541399102516

Epoch: 6| Step: 13
Training loss: 1.992719631558534
Validation loss: 2.5989944720510962

Epoch: 299| Step: 0
Training loss: 1.2574476103742847
Validation loss: 2.6293425894600757

Epoch: 6| Step: 1
Training loss: 1.494898146537455
Validation loss: 2.6335004818859566

Epoch: 6| Step: 2
Training loss: 2.6724781448712456
Validation loss: 2.607940203216176

Epoch: 6| Step: 3
Training loss: 1.528883993993607
Validation loss: 2.6025176027712225

Epoch: 6| Step: 4
Training loss: 2.282427549183752
Validation loss: 2.686224139269401

Epoch: 6| Step: 5
Training loss: 2.0566703018988948
Validation loss: 2.6571528228132424

Epoch: 6| Step: 6
Training loss: 2.2605017251976567
Validation loss: 2.742078077953407

Epoch: 6| Step: 7
Training loss: 1.6019605932687184
Validation loss: 2.7454329193401463

Epoch: 6| Step: 8
Training loss: 1.6098766100733481
Validation loss: 2.745137438387854

Epoch: 6| Step: 9
Training loss: 1.9884710614748704
Validation loss: 2.7792448466531905

Epoch: 6| Step: 10
Training loss: 2.261239061893222
Validation loss: 2.7702887915442873

Epoch: 6| Step: 11
Training loss: 1.4918233217350858
Validation loss: 2.7168817787972164

Epoch: 6| Step: 12
Training loss: 1.6946065109515036
Validation loss: 2.6894789070956557

Epoch: 6| Step: 13
Training loss: 1.7078395998410976
Validation loss: 2.6622211361004364

Epoch: 300| Step: 0
Training loss: 1.9402388626209552
Validation loss: 2.6547902004111466

Epoch: 6| Step: 1
Training loss: 1.3305796211356378
Validation loss: 2.618055467299222

Epoch: 6| Step: 2
Training loss: 2.290303281332714
Validation loss: 2.6308661113634835

Epoch: 6| Step: 3
Training loss: 1.3204947802878495
Validation loss: 2.6167528389350156

Epoch: 6| Step: 4
Training loss: 1.5190402220673898
Validation loss: 2.6313864206693816

Epoch: 6| Step: 5
Training loss: 1.4897504948363784
Validation loss: 2.6627899889559097

Epoch: 6| Step: 6
Training loss: 2.4384728471011945
Validation loss: 2.646430050901165

Epoch: 6| Step: 7
Training loss: 2.3687319108176697
Validation loss: 2.6970765758633855

Epoch: 6| Step: 8
Training loss: 1.9287553149562346
Validation loss: 2.669598909390861

Epoch: 6| Step: 9
Training loss: 1.275888015942292
Validation loss: 2.6888693344659234

Epoch: 6| Step: 10
Training loss: 1.8004375137973734
Validation loss: 2.690975795182895

Epoch: 6| Step: 11
Training loss: 2.128049121461836
Validation loss: 2.669588236972224

Epoch: 6| Step: 12
Training loss: 2.137246354429621
Validation loss: 2.655180457712008

Epoch: 6| Step: 13
Training loss: 1.4578038844010384
Validation loss: 2.6888806692589777

Epoch: 301| Step: 0
Training loss: 1.9246299041092934
Validation loss: 2.6800423434456673

Epoch: 6| Step: 1
Training loss: 1.1726357089079154
Validation loss: 2.6388733149509527

Epoch: 6| Step: 2
Training loss: 2.524498495021771
Validation loss: 2.6502736346203286

Epoch: 6| Step: 3
Training loss: 2.0459985385341404
Validation loss: 2.6243880330593616

Epoch: 6| Step: 4
Training loss: 2.2290782970369816
Validation loss: 2.7011340826612895

Epoch: 6| Step: 5
Training loss: 1.8475610172173769
Validation loss: 2.6803131930054707

Epoch: 6| Step: 6
Training loss: 1.2652275026375617
Validation loss: 2.7089706013500554

Epoch: 6| Step: 7
Training loss: 1.5561674348921137
Validation loss: 2.7377884839087354

Epoch: 6| Step: 8
Training loss: 1.915702584268414
Validation loss: 2.7857797574813756

Epoch: 6| Step: 9
Training loss: 1.835309769472351
Validation loss: 2.748936346288255

Epoch: 6| Step: 10
Training loss: 1.6403724112664304
Validation loss: 2.7287870439131447

Epoch: 6| Step: 11
Training loss: 2.0351303596826664
Validation loss: 2.7043763426696628

Epoch: 6| Step: 12
Training loss: 1.630428197819778
Validation loss: 2.678296364784487

Epoch: 6| Step: 13
Training loss: 2.1499322303914323
Validation loss: 2.7027724372398914

Epoch: 302| Step: 0
Training loss: 1.5648688098654928
Validation loss: 2.6628851801487503

Epoch: 6| Step: 1
Training loss: 1.9752066564484083
Validation loss: 2.6355588570535335

Epoch: 6| Step: 2
Training loss: 1.49263624863315
Validation loss: 2.6576009867665364

Epoch: 6| Step: 3
Training loss: 2.224806243518188
Validation loss: 2.640252141567744

Epoch: 6| Step: 4
Training loss: 2.5101503307416397
Validation loss: 2.671925787786943

Epoch: 6| Step: 5
Training loss: 1.960278525706474
Validation loss: 2.697932347628903

Epoch: 6| Step: 6
Training loss: 2.142102921678365
Validation loss: 2.714692724038519

Epoch: 6| Step: 7
Training loss: 1.9771375460439171
Validation loss: 2.7446819382413246

Epoch: 6| Step: 8
Training loss: 2.160720503166468
Validation loss: 2.758611503896136

Epoch: 6| Step: 9
Training loss: 1.399076901673371
Validation loss: 2.7380035593350116

Epoch: 6| Step: 10
Training loss: 1.482955092878782
Validation loss: 2.676487464246416

Epoch: 6| Step: 11
Training loss: 1.1451697537717338
Validation loss: 2.644198029944562

Epoch: 6| Step: 12
Training loss: 1.975039170275135
Validation loss: 2.6347046645464327

Epoch: 6| Step: 13
Training loss: 1.7305065004523705
Validation loss: 2.6499542874166235

Epoch: 303| Step: 0
Training loss: 1.6771062845432727
Validation loss: 2.692722067192269

Epoch: 6| Step: 1
Training loss: 2.382112994469492
Validation loss: 2.6466050762133504

Epoch: 6| Step: 2
Training loss: 2.052198287403421
Validation loss: 2.6575298890914834

Epoch: 6| Step: 3
Training loss: 1.4491528601461277
Validation loss: 2.6725778082953964

Epoch: 6| Step: 4
Training loss: 1.3735609326756149
Validation loss: 2.727185328484793

Epoch: 6| Step: 5
Training loss: 1.4740893931358736
Validation loss: 2.7666846650085857

Epoch: 6| Step: 6
Training loss: 1.3658764465832671
Validation loss: 2.75757127378641

Epoch: 6| Step: 7
Training loss: 2.5212136499283844
Validation loss: 2.7621050056009713

Epoch: 6| Step: 8
Training loss: 1.7833438412484492
Validation loss: 2.773749521102738

Epoch: 6| Step: 9
Training loss: 1.687266722202452
Validation loss: 2.8078849368480334

Epoch: 6| Step: 10
Training loss: 2.075667685207944
Validation loss: 2.770053643878912

Epoch: 6| Step: 11
Training loss: 1.8592848555567765
Validation loss: 2.7052504722144275

Epoch: 6| Step: 12
Training loss: 1.9057064219414879
Validation loss: 2.65786021176885

Epoch: 6| Step: 13
Training loss: 2.2861997650784427
Validation loss: 2.673258610947136

Epoch: 304| Step: 0
Training loss: 1.5740229861169706
Validation loss: 2.7151277315829603

Epoch: 6| Step: 1
Training loss: 1.6293218800526676
Validation loss: 2.7512533626163216

Epoch: 6| Step: 2
Training loss: 1.4816398719164148
Validation loss: 2.723541903833658

Epoch: 6| Step: 3
Training loss: 2.0816828738646307
Validation loss: 2.7211961739899504

Epoch: 6| Step: 4
Training loss: 1.9267295993879667
Validation loss: 2.724199672143895

Epoch: 6| Step: 5
Training loss: 1.690469178300996
Validation loss: 2.7113122745137255

Epoch: 6| Step: 6
Training loss: 1.422834638443875
Validation loss: 2.6368854385245313

Epoch: 6| Step: 7
Training loss: 2.426047588476016
Validation loss: 2.6488518179838163

Epoch: 6| Step: 8
Training loss: 1.5757854985495217
Validation loss: 2.650685679298784

Epoch: 6| Step: 9
Training loss: 1.478464022382187
Validation loss: 2.6123934132371995

Epoch: 6| Step: 10
Training loss: 2.3639268229820614
Validation loss: 2.6340130823969576

Epoch: 6| Step: 11
Training loss: 1.9943480500516637
Validation loss: 2.6469152646415686

Epoch: 6| Step: 12
Training loss: 1.9998034142200385
Validation loss: 2.6865152876339864

Epoch: 6| Step: 13
Training loss: 2.100620441516946
Validation loss: 2.6758062431114924

Epoch: 305| Step: 0
Training loss: 2.277017089029081
Validation loss: 2.6956744701935613

Epoch: 6| Step: 1
Training loss: 1.9486067122559831
Validation loss: 2.750596617512003

Epoch: 6| Step: 2
Training loss: 1.9053653477839274
Validation loss: 2.7352142499265577

Epoch: 6| Step: 3
Training loss: 1.4994016089548936
Validation loss: 2.7402890726269065

Epoch: 6| Step: 4
Training loss: 1.9760099701726406
Validation loss: 2.814109468888873

Epoch: 6| Step: 5
Training loss: 1.87842888428561
Validation loss: 2.7770903409586634

Epoch: 6| Step: 6
Training loss: 1.7250172876790968
Validation loss: 2.8112850532025577

Epoch: 6| Step: 7
Training loss: 1.7286469318064202
Validation loss: 2.7928105662974017

Epoch: 6| Step: 8
Training loss: 2.1111627985109074
Validation loss: 2.7550753589599837

Epoch: 6| Step: 9
Training loss: 1.617711521333041
Validation loss: 2.7391140515324754

Epoch: 6| Step: 10
Training loss: 2.1336739725111893
Validation loss: 2.6547157643837815

Epoch: 6| Step: 11
Training loss: 1.4830259919104198
Validation loss: 2.6241008944449304

Epoch: 6| Step: 12
Training loss: 1.3943550575570893
Validation loss: 2.6295396363938406

Epoch: 6| Step: 13
Training loss: 1.8881695778669099
Validation loss: 2.6161017903600046

Epoch: 306| Step: 0
Training loss: 1.9297932584252833
Validation loss: 2.606947327290845

Epoch: 6| Step: 1
Training loss: 2.434676662651564
Validation loss: 2.6466088597673285

Epoch: 6| Step: 2
Training loss: 2.0121970191489873
Validation loss: 2.6060720314352737

Epoch: 6| Step: 3
Training loss: 1.4109519340985022
Validation loss: 2.6304659625994953

Epoch: 6| Step: 4
Training loss: 1.7263148894050564
Validation loss: 2.614532954020663

Epoch: 6| Step: 5
Training loss: 2.5909767491877544
Validation loss: 2.6459974152957733

Epoch: 6| Step: 6
Training loss: 1.8641778160424582
Validation loss: 2.6998795005612117

Epoch: 6| Step: 7
Training loss: 2.040740159715366
Validation loss: 2.718976402356155

Epoch: 6| Step: 8
Training loss: 1.8736323136824364
Validation loss: 2.7082156131298176

Epoch: 6| Step: 9
Training loss: 1.450828460270328
Validation loss: 2.655920838549385

Epoch: 6| Step: 10
Training loss: 1.7586322144716864
Validation loss: 2.688783575676253

Epoch: 6| Step: 11
Training loss: 1.3008289958450627
Validation loss: 2.638749398900501

Epoch: 6| Step: 12
Training loss: 1.1300376317838896
Validation loss: 2.654396322865475

Epoch: 6| Step: 13
Training loss: 1.7597524830859865
Validation loss: 2.6734721743551377

Epoch: 307| Step: 0
Training loss: 1.4806450006656613
Validation loss: 2.669623111956208

Epoch: 6| Step: 1
Training loss: 1.9374662211765328
Validation loss: 2.6631843111347475

Epoch: 6| Step: 2
Training loss: 1.4969458481620876
Validation loss: 2.7098991904799115

Epoch: 6| Step: 3
Training loss: 1.9767819007662484
Validation loss: 2.716296524934428

Epoch: 6| Step: 4
Training loss: 1.899214660062666
Validation loss: 2.7157168221762253

Epoch: 6| Step: 5
Training loss: 1.538902545498059
Validation loss: 2.73373678842895

Epoch: 6| Step: 6
Training loss: 1.7702159104423194
Validation loss: 2.766842173750791

Epoch: 6| Step: 7
Training loss: 1.9893216332154608
Validation loss: 2.8212599778692584

Epoch: 6| Step: 8
Training loss: 1.5746762200231812
Validation loss: 2.8242870303210488

Epoch: 6| Step: 9
Training loss: 1.9186131779600195
Validation loss: 2.775179914707893

Epoch: 6| Step: 10
Training loss: 2.66159229476428
Validation loss: 2.7704740640339263

Epoch: 6| Step: 11
Training loss: 1.8426470286118288
Validation loss: 2.715571595469066

Epoch: 6| Step: 12
Training loss: 1.5594374588744715
Validation loss: 2.690836941726579

Epoch: 6| Step: 13
Training loss: 1.7915894765268447
Validation loss: 2.7346792433279172

Epoch: 308| Step: 0
Training loss: 2.6478276183499148
Validation loss: 2.6596168721856492

Epoch: 6| Step: 1
Training loss: 2.4690025297007496
Validation loss: 2.65257005283229

Epoch: 6| Step: 2
Training loss: 1.4566050051740254
Validation loss: 2.675230733480954

Epoch: 6| Step: 3
Training loss: 1.9091305465422852
Validation loss: 2.659376899428685

Epoch: 6| Step: 4
Training loss: 1.4646347507153208
Validation loss: 2.67768587884224

Epoch: 6| Step: 5
Training loss: 1.454109432693611
Validation loss: 2.7264276451128207

Epoch: 6| Step: 6
Training loss: 1.661695776288726
Validation loss: 2.6886421112921153

Epoch: 6| Step: 7
Training loss: 2.0372527411275434
Validation loss: 2.699898427653943

Epoch: 6| Step: 8
Training loss: 1.6946693993723216
Validation loss: 2.6660552267596342

Epoch: 6| Step: 9
Training loss: 1.9830838305614877
Validation loss: 2.637922977441367

Epoch: 6| Step: 10
Training loss: 1.562203798829054
Validation loss: 2.661574259781993

Epoch: 6| Step: 11
Training loss: 1.667936731250057
Validation loss: 2.6581282762784877

Epoch: 6| Step: 12
Training loss: 1.3382750912428294
Validation loss: 2.6461133032828017

Epoch: 6| Step: 13
Training loss: 1.5308634211629595
Validation loss: 2.6735326372880603

Epoch: 309| Step: 0
Training loss: 2.4333278455628826
Validation loss: 2.6600614839871883

Epoch: 6| Step: 1
Training loss: 1.7060244316820237
Validation loss: 2.6791891630028166

Epoch: 6| Step: 2
Training loss: 2.025139405903279
Validation loss: 2.6594596320378856

Epoch: 6| Step: 3
Training loss: 2.0391065804697144
Validation loss: 2.671019255365556

Epoch: 6| Step: 4
Training loss: 1.3837743312829598
Validation loss: 2.7173943921776518

Epoch: 6| Step: 5
Training loss: 1.3195951420350283
Validation loss: 2.679520137442835

Epoch: 6| Step: 6
Training loss: 1.3330230600232587
Validation loss: 2.715441279896574

Epoch: 6| Step: 7
Training loss: 1.1736363716090568
Validation loss: 2.669619405673528

Epoch: 6| Step: 8
Training loss: 1.248374358718171
Validation loss: 2.6652015495785486

Epoch: 6| Step: 9
Training loss: 1.3213162641410754
Validation loss: 2.6827450094470766

Epoch: 6| Step: 10
Training loss: 2.5723512674381817
Validation loss: 2.671411262110796

Epoch: 6| Step: 11
Training loss: 2.1834162058159743
Validation loss: 2.689779246606921

Epoch: 6| Step: 12
Training loss: 1.8522928463406472
Validation loss: 2.662060847951452

Epoch: 6| Step: 13
Training loss: 1.9462374897127857
Validation loss: 2.694335686781695

Epoch: 310| Step: 0
Training loss: 1.6416824565973653
Validation loss: 2.676356136445172

Epoch: 6| Step: 1
Training loss: 1.9574065010473443
Validation loss: 2.691056877089897

Epoch: 6| Step: 2
Training loss: 1.7096614172285864
Validation loss: 2.6972005966564523

Epoch: 6| Step: 3
Training loss: 2.098472621052892
Validation loss: 2.697567793236125

Epoch: 6| Step: 4
Training loss: 1.4345560196488467
Validation loss: 2.721231314823202

Epoch: 6| Step: 5
Training loss: 2.0378249348104718
Validation loss: 2.7103447169831627

Epoch: 6| Step: 6
Training loss: 2.5999554777001372
Validation loss: 2.7100482695199832

Epoch: 6| Step: 7
Training loss: 1.816560603320767
Validation loss: 2.683258798306467

Epoch: 6| Step: 8
Training loss: 1.6510395647711467
Validation loss: 2.6894852011399273

Epoch: 6| Step: 9
Training loss: 1.725749173779368
Validation loss: 2.6855616121754733

Epoch: 6| Step: 10
Training loss: 1.389098368847783
Validation loss: 2.7168477005892737

Epoch: 6| Step: 11
Training loss: 1.8674954595344633
Validation loss: 2.7801935854182744

Epoch: 6| Step: 12
Training loss: 0.9853144204858707
Validation loss: 2.7355314007472633

Epoch: 6| Step: 13
Training loss: 1.7883405269799268
Validation loss: 2.688283628614017

Epoch: 311| Step: 0
Training loss: 2.0695163563544865
Validation loss: 2.7091428182775132

Epoch: 6| Step: 1
Training loss: 1.3112257266638947
Validation loss: 2.683988539351485

Epoch: 6| Step: 2
Training loss: 1.410496129211502
Validation loss: 2.662296078712594

Epoch: 6| Step: 3
Training loss: 1.0887169704398076
Validation loss: 2.673816295418347

Epoch: 6| Step: 4
Training loss: 1.2442109523760234
Validation loss: 2.6561308590966193

Epoch: 6| Step: 5
Training loss: 1.9439504979977684
Validation loss: 2.6374920951881493

Epoch: 6| Step: 6
Training loss: 2.1146703868166195
Validation loss: 2.6233708987965634

Epoch: 6| Step: 7
Training loss: 1.4085656068585404
Validation loss: 2.6367208447860118

Epoch: 6| Step: 8
Training loss: 1.8581780179155731
Validation loss: 2.689482704208634

Epoch: 6| Step: 9
Training loss: 2.38490698643015
Validation loss: 2.6796483518004077

Epoch: 6| Step: 10
Training loss: 2.790077601758458
Validation loss: 2.7082138084055276

Epoch: 6| Step: 11
Training loss: 1.8813075465528748
Validation loss: 2.723076837601288

Epoch: 6| Step: 12
Training loss: 1.2537181867706952
Validation loss: 2.7382711935470874

Epoch: 6| Step: 13
Training loss: 1.5333130620915663
Validation loss: 2.7522907686182725

Epoch: 312| Step: 0
Training loss: 2.0451537604691685
Validation loss: 2.735022172181279

Epoch: 6| Step: 1
Training loss: 2.0527989516186436
Validation loss: 2.702718876959972

Epoch: 6| Step: 2
Training loss: 1.9871644966484563
Validation loss: 2.7028971816771388

Epoch: 6| Step: 3
Training loss: 1.3363450527373482
Validation loss: 2.6847352733142444

Epoch: 6| Step: 4
Training loss: 1.821988034545099
Validation loss: 2.6302060621396572

Epoch: 6| Step: 5
Training loss: 1.827423352305378
Validation loss: 2.7073406062901673

Epoch: 6| Step: 6
Training loss: 1.4603299596335815
Validation loss: 2.6490363135181116

Epoch: 6| Step: 7
Training loss: 1.151249459729394
Validation loss: 2.6578757004770943

Epoch: 6| Step: 8
Training loss: 2.02462486277358
Validation loss: 2.6811087706746624

Epoch: 6| Step: 9
Training loss: 1.5189478521631157
Validation loss: 2.766880375486589

Epoch: 6| Step: 10
Training loss: 1.8445761171447812
Validation loss: 2.743810740199005

Epoch: 6| Step: 11
Training loss: 2.002498020356875
Validation loss: 2.7546093198833095

Epoch: 6| Step: 12
Training loss: 1.4611796622075683
Validation loss: 2.7664484281717137

Epoch: 6| Step: 13
Training loss: 2.2642034872423955
Validation loss: 2.7925683079045984

Epoch: 313| Step: 0
Training loss: 2.3671125645626883
Validation loss: 2.7890388209943273

Epoch: 6| Step: 1
Training loss: 1.053549145146544
Validation loss: 2.6838055137953827

Epoch: 6| Step: 2
Training loss: 2.219753414584065
Validation loss: 2.64995488722207

Epoch: 6| Step: 3
Training loss: 1.2586002134208067
Validation loss: 2.6703119446478767

Epoch: 6| Step: 4
Training loss: 2.0468751164793026
Validation loss: 2.576884161844743

Epoch: 6| Step: 5
Training loss: 1.8962658050019265
Validation loss: 2.6405014520819448

Epoch: 6| Step: 6
Training loss: 1.602492569476202
Validation loss: 2.617528955760332

Epoch: 6| Step: 7
Training loss: 1.4938741209423207
Validation loss: 2.634447354265452

Epoch: 6| Step: 8
Training loss: 2.2242376671734614
Validation loss: 2.688957676607519

Epoch: 6| Step: 9
Training loss: 2.2073231191826057
Validation loss: 2.6738698327745434

Epoch: 6| Step: 10
Training loss: 1.558671151058206
Validation loss: 2.7459007690978376

Epoch: 6| Step: 11
Training loss: 1.7896090676259995
Validation loss: 2.728418004868493

Epoch: 6| Step: 12
Training loss: 1.510186732537592
Validation loss: 2.711749612055072

Epoch: 6| Step: 13
Training loss: 1.463800246812091
Validation loss: 2.6573828581491896

Epoch: 314| Step: 0
Training loss: 2.2268075908486966
Validation loss: 2.6136310155157925

Epoch: 6| Step: 1
Training loss: 1.8055239633910014
Validation loss: 2.6621124200390693

Epoch: 6| Step: 2
Training loss: 2.0272521363949334
Validation loss: 2.6341166299059933

Epoch: 6| Step: 3
Training loss: 1.4239865229322488
Validation loss: 2.627683872088984

Epoch: 6| Step: 4
Training loss: 1.39500517498957
Validation loss: 2.6367054126543463

Epoch: 6| Step: 5
Training loss: 2.5579546181095756
Validation loss: 2.6347387947316965

Epoch: 6| Step: 6
Training loss: 1.496649974880015
Validation loss: 2.621033472163012

Epoch: 6| Step: 7
Training loss: 1.3883993790858404
Validation loss: 2.622515592646905

Epoch: 6| Step: 8
Training loss: 1.9930656143389516
Validation loss: 2.6806213709032214

Epoch: 6| Step: 9
Training loss: 1.5863132877214885
Validation loss: 2.701986319261878

Epoch: 6| Step: 10
Training loss: 1.6343633414266598
Validation loss: 2.759376161833562

Epoch: 6| Step: 11
Training loss: 1.7189941232879296
Validation loss: 2.7607658069465173

Epoch: 6| Step: 12
Training loss: 2.138090317619634
Validation loss: 2.7548004213796142

Epoch: 6| Step: 13
Training loss: 1.8162293706931356
Validation loss: 2.6987101052159397

Epoch: 315| Step: 0
Training loss: 1.8974078490506563
Validation loss: 2.639648813842039

Epoch: 6| Step: 1
Training loss: 2.126887436930445
Validation loss: 2.6434551624718634

Epoch: 6| Step: 2
Training loss: 1.7680342449306683
Validation loss: 2.650609958674665

Epoch: 6| Step: 3
Training loss: 1.9063371732196976
Validation loss: 2.6303574220811785

Epoch: 6| Step: 4
Training loss: 2.0937591097049957
Validation loss: 2.69376602404107

Epoch: 6| Step: 5
Training loss: 1.5982027867810018
Validation loss: 2.6957057057926486

Epoch: 6| Step: 6
Training loss: 1.3371284039965698
Validation loss: 2.793485637221162

Epoch: 6| Step: 7
Training loss: 2.0851953450636693
Validation loss: 2.884448957614408

Epoch: 6| Step: 8
Training loss: 1.7450874040022815
Validation loss: 2.9410441641407274

Epoch: 6| Step: 9
Training loss: 2.936647981489695
Validation loss: 2.930430068111019

Epoch: 6| Step: 10
Training loss: 1.800974407304385
Validation loss: 2.8819792800289092

Epoch: 6| Step: 11
Training loss: 1.6311873968396147
Validation loss: 2.823482475492535

Epoch: 6| Step: 12
Training loss: 2.0312899072101422
Validation loss: 2.8027934955382623

Epoch: 6| Step: 13
Training loss: 1.3404379547455603
Validation loss: 2.7409695694690983

Epoch: 316| Step: 0
Training loss: 1.6105403199618755
Validation loss: 2.689835250919361

Epoch: 6| Step: 1
Training loss: 1.3952950061073082
Validation loss: 2.6971132906196833

Epoch: 6| Step: 2
Training loss: 1.3174730274255235
Validation loss: 2.676861146446741

Epoch: 6| Step: 3
Training loss: 1.4988759120454511
Validation loss: 2.6561908191745234

Epoch: 6| Step: 4
Training loss: 1.8296822981919278
Validation loss: 2.6412683940824064

Epoch: 6| Step: 5
Training loss: 2.1430874882371858
Validation loss: 2.626654406347885

Epoch: 6| Step: 6
Training loss: 1.9283770849308497
Validation loss: 2.6229142879589427

Epoch: 6| Step: 7
Training loss: 1.5028981186275951
Validation loss: 2.599354200977795

Epoch: 6| Step: 8
Training loss: 1.6558296101948555
Validation loss: 2.6392238443402367

Epoch: 6| Step: 9
Training loss: 2.100938782436939
Validation loss: 2.620536430373024

Epoch: 6| Step: 10
Training loss: 2.351680816005836
Validation loss: 2.684522413499719

Epoch: 6| Step: 11
Training loss: 2.1458262718109182
Validation loss: 2.7056338330467824

Epoch: 6| Step: 12
Training loss: 1.9407427323605901
Validation loss: 2.7138348284980833

Epoch: 6| Step: 13
Training loss: 1.5222371385281293
Validation loss: 2.708601341680702

Epoch: 317| Step: 0
Training loss: 1.9615619774526472
Validation loss: 2.682448185671829

Epoch: 6| Step: 1
Training loss: 2.355430691286644
Validation loss: 2.698458368028899

Epoch: 6| Step: 2
Training loss: 1.5811602419984083
Validation loss: 2.6895544937522033

Epoch: 6| Step: 3
Training loss: 1.2446381009983043
Validation loss: 2.674416996655175

Epoch: 6| Step: 4
Training loss: 1.8738233052904063
Validation loss: 2.7238987076739036

Epoch: 6| Step: 5
Training loss: 1.8627465718542042
Validation loss: 2.7208577751319774

Epoch: 6| Step: 6
Training loss: 1.3687549434206803
Validation loss: 2.680482499922988

Epoch: 6| Step: 7
Training loss: 1.4446011829107839
Validation loss: 2.731411721499557

Epoch: 6| Step: 8
Training loss: 1.61417377158541
Validation loss: 2.711870382925867

Epoch: 6| Step: 9
Training loss: 1.636309005687531
Validation loss: 2.7322704972205614

Epoch: 6| Step: 10
Training loss: 2.107341549167147
Validation loss: 2.731772457639916

Epoch: 6| Step: 11
Training loss: 2.0593607738507114
Validation loss: 2.757219519185872

Epoch: 6| Step: 12
Training loss: 1.8450654073560306
Validation loss: 2.7954595951778103

Epoch: 6| Step: 13
Training loss: 1.3532206336358197
Validation loss: 2.7490886131677725

Epoch: 318| Step: 0
Training loss: 2.1956644556684854
Validation loss: 2.7474932443907703

Epoch: 6| Step: 1
Training loss: 0.9120908812908656
Validation loss: 2.723551591565085

Epoch: 6| Step: 2
Training loss: 1.9022056325791181
Validation loss: 2.74056331285266

Epoch: 6| Step: 3
Training loss: 1.3671237167738834
Validation loss: 2.748488371990724

Epoch: 6| Step: 4
Training loss: 1.8328932826458384
Validation loss: 2.6967897946131716

Epoch: 6| Step: 5
Training loss: 1.1282050254947886
Validation loss: 2.6867489911317075

Epoch: 6| Step: 6
Training loss: 2.1402450558471964
Validation loss: 2.689612260855475

Epoch: 6| Step: 7
Training loss: 1.4339241665696314
Validation loss: 2.7041299822356177

Epoch: 6| Step: 8
Training loss: 1.9889317256013073
Validation loss: 2.676109186203954

Epoch: 6| Step: 9
Training loss: 2.509633101589941
Validation loss: 2.689639311980365

Epoch: 6| Step: 10
Training loss: 1.512452413267499
Validation loss: 2.7143026933401906

Epoch: 6| Step: 11
Training loss: 1.4591472080370405
Validation loss: 2.7033987476306938

Epoch: 6| Step: 12
Training loss: 2.1424142084560778
Validation loss: 2.7451400439236933

Epoch: 6| Step: 13
Training loss: 1.6550854601505058
Validation loss: 2.745314913151389

Epoch: 319| Step: 0
Training loss: 1.5173657832108922
Validation loss: 2.73518368343051

Epoch: 6| Step: 1
Training loss: 2.390446674951385
Validation loss: 2.6830136682311747

Epoch: 6| Step: 2
Training loss: 1.8639835977282895
Validation loss: 2.6792135755625757

Epoch: 6| Step: 3
Training loss: 1.0582450489457365
Validation loss: 2.6610058936787673

Epoch: 6| Step: 4
Training loss: 1.4793719655156088
Validation loss: 2.7068302434043927

Epoch: 6| Step: 5
Training loss: 2.2740486083996223
Validation loss: 2.619049806511366

Epoch: 6| Step: 6
Training loss: 0.735783950110516
Validation loss: 2.68540297614002

Epoch: 6| Step: 7
Training loss: 1.7671187841950053
Validation loss: 2.678215044927083

Epoch: 6| Step: 8
Training loss: 1.9308552162577861
Validation loss: 2.6865514071788223

Epoch: 6| Step: 9
Training loss: 2.0984041099135786
Validation loss: 2.6913336977986386

Epoch: 6| Step: 10
Training loss: 1.5675801660946016
Validation loss: 2.675009229531216

Epoch: 6| Step: 11
Training loss: 2.1661864506578543
Validation loss: 2.729026329761532

Epoch: 6| Step: 12
Training loss: 1.8402265081721312
Validation loss: 2.701550387077174

Epoch: 6| Step: 13
Training loss: 1.408009339859719
Validation loss: 2.7369975855552684

Epoch: 320| Step: 0
Training loss: 1.9297663869447417
Validation loss: 2.7421191751313003

Epoch: 6| Step: 1
Training loss: 1.4263174224617463
Validation loss: 2.7506490432762094

Epoch: 6| Step: 2
Training loss: 1.6782020565363593
Validation loss: 2.749298887755136

Epoch: 6| Step: 3
Training loss: 2.1050039709058264
Validation loss: 2.7257595246166173

Epoch: 6| Step: 4
Training loss: 1.567006593039153
Validation loss: 2.7233195434168262

Epoch: 6| Step: 5
Training loss: 2.1602159598791624
Validation loss: 2.701570059958964

Epoch: 6| Step: 6
Training loss: 2.0293349408424484
Validation loss: 2.668576083446164

Epoch: 6| Step: 7
Training loss: 1.1836832849862686
Validation loss: 2.6869756497584825

Epoch: 6| Step: 8
Training loss: 1.5859466702802147
Validation loss: 2.6723076542578563

Epoch: 6| Step: 9
Training loss: 1.8535103511433797
Validation loss: 2.708458653020395

Epoch: 6| Step: 10
Training loss: 1.6939456193295366
Validation loss: 2.696289357249018

Epoch: 6| Step: 11
Training loss: 1.5164729626940374
Validation loss: 2.7375392806487895

Epoch: 6| Step: 12
Training loss: 2.126592600299005
Validation loss: 2.7271855834683776

Epoch: 6| Step: 13
Training loss: 1.8088907282244813
Validation loss: 2.7255505976748697

Epoch: 321| Step: 0
Training loss: 1.467806736409122
Validation loss: 2.752210537793213

Epoch: 6| Step: 1
Training loss: 2.0169677992951587
Validation loss: 2.7138197909482327

Epoch: 6| Step: 2
Training loss: 1.4432712471245623
Validation loss: 2.7612369014486298

Epoch: 6| Step: 3
Training loss: 2.027066662031453
Validation loss: 2.7498631443302366

Epoch: 6| Step: 4
Training loss: 1.7944105414123024
Validation loss: 2.713149913154113

Epoch: 6| Step: 5
Training loss: 2.2553822462818274
Validation loss: 2.726126401869721

Epoch: 6| Step: 6
Training loss: 1.381186698740378
Validation loss: 2.6881110952964202

Epoch: 6| Step: 7
Training loss: 2.0082767410008073
Validation loss: 2.691965016540655

Epoch: 6| Step: 8
Training loss: 1.644615914165661
Validation loss: 2.654865756906519

Epoch: 6| Step: 9
Training loss: 1.9197786885107635
Validation loss: 2.6105019121390147

Epoch: 6| Step: 10
Training loss: 1.9756626900562684
Validation loss: 2.660445411863398

Epoch: 6| Step: 11
Training loss: 1.470379919275929
Validation loss: 2.6706997999195043

Epoch: 6| Step: 12
Training loss: 1.2213237680042561
Validation loss: 2.7071309330482687

Epoch: 6| Step: 13
Training loss: 2.085490432435622
Validation loss: 2.74675675804182

Epoch: 322| Step: 0
Training loss: 1.7994627521684494
Validation loss: 2.764865045248997

Epoch: 6| Step: 1
Training loss: 2.394157940638098
Validation loss: 2.77121827073689

Epoch: 6| Step: 2
Training loss: 2.3922765674118436
Validation loss: 2.774925785389687

Epoch: 6| Step: 3
Training loss: 1.5355007571308898
Validation loss: 2.7570814941532324

Epoch: 6| Step: 4
Training loss: 1.759344628514011
Validation loss: 2.7171381999466746

Epoch: 6| Step: 5
Training loss: 1.4422380068646175
Validation loss: 2.671871698388631

Epoch: 6| Step: 6
Training loss: 1.7362372221177858
Validation loss: 2.6818773017493522

Epoch: 6| Step: 7
Training loss: 1.2517335315289182
Validation loss: 2.657592419261061

Epoch: 6| Step: 8
Training loss: 2.1076411150006336
Validation loss: 2.6829607280350385

Epoch: 6| Step: 9
Training loss: 1.2272992199469075
Validation loss: 2.683784392950398

Epoch: 6| Step: 10
Training loss: 1.959285024618287
Validation loss: 2.6996565600358826

Epoch: 6| Step: 11
Training loss: 1.8503797270293063
Validation loss: 2.6890174219142344

Epoch: 6| Step: 12
Training loss: 1.33132831002881
Validation loss: 2.6957832404488804

Epoch: 6| Step: 13
Training loss: 1.6659237477413467
Validation loss: 2.7026415853849963

Epoch: 323| Step: 0
Training loss: 1.432932189135581
Validation loss: 2.6974186726101808

Epoch: 6| Step: 1
Training loss: 1.7541036176186324
Validation loss: 2.6539350707029823

Epoch: 6| Step: 2
Training loss: 1.8168585757578408
Validation loss: 2.696364207719117

Epoch: 6| Step: 3
Training loss: 2.050628947097528
Validation loss: 2.701214624279475

Epoch: 6| Step: 4
Training loss: 1.7622510693660915
Validation loss: 2.6815968672221584

Epoch: 6| Step: 5
Training loss: 1.717072240208455
Validation loss: 2.699915161683736

Epoch: 6| Step: 6
Training loss: 1.5432165791872248
Validation loss: 2.6859276629895263

Epoch: 6| Step: 7
Training loss: 1.7930745278531823
Validation loss: 2.6903878155061767

Epoch: 6| Step: 8
Training loss: 1.576638305172405
Validation loss: 2.6969312368034983

Epoch: 6| Step: 9
Training loss: 1.3208733896545488
Validation loss: 2.682378235441561

Epoch: 6| Step: 10
Training loss: 1.8980971294187028
Validation loss: 2.717726986344526

Epoch: 6| Step: 11
Training loss: 1.6162737785177435
Validation loss: 2.727382926328089

Epoch: 6| Step: 12
Training loss: 1.3622287305213514
Validation loss: 2.688518316459918

Epoch: 6| Step: 13
Training loss: 2.504188081350389
Validation loss: 2.6857537059321017

Epoch: 324| Step: 0
Training loss: 1.370858979299289
Validation loss: 2.6332344901772795

Epoch: 6| Step: 1
Training loss: 1.3870446050632028
Validation loss: 2.635494024978356

Epoch: 6| Step: 2
Training loss: 1.5352495859130342
Validation loss: 2.623816495855133

Epoch: 6| Step: 3
Training loss: 1.596566348471626
Validation loss: 2.609802317702775

Epoch: 6| Step: 4
Training loss: 1.4912820835291456
Validation loss: 2.623572597240048

Epoch: 6| Step: 5
Training loss: 2.214180122002476
Validation loss: 2.683494821471322

Epoch: 6| Step: 6
Training loss: 1.815727123336455
Validation loss: 2.6673384704352867

Epoch: 6| Step: 7
Training loss: 1.1940156970501878
Validation loss: 2.6213472473995076

Epoch: 6| Step: 8
Training loss: 1.7601019974977186
Validation loss: 2.6808627695948406

Epoch: 6| Step: 9
Training loss: 1.9881261978697444
Validation loss: 2.718872535253488

Epoch: 6| Step: 10
Training loss: 1.7179081328879617
Validation loss: 2.737318536326678

Epoch: 6| Step: 11
Training loss: 2.5785697784539314
Validation loss: 2.753565846140006

Epoch: 6| Step: 12
Training loss: 1.878796738825553
Validation loss: 2.7103998492044385

Epoch: 6| Step: 13
Training loss: 1.9071218029184691
Validation loss: 2.678867492662414

Epoch: 325| Step: 0
Training loss: 1.7446721581671563
Validation loss: 2.6944007547731994

Epoch: 6| Step: 1
Training loss: 1.7025905785573168
Validation loss: 2.663194845089861

Epoch: 6| Step: 2
Training loss: 1.6007737613352013
Validation loss: 2.708848028916208

Epoch: 6| Step: 3
Training loss: 2.270117994090238
Validation loss: 2.6967123331023477

Epoch: 6| Step: 4
Training loss: 1.7749441863405235
Validation loss: 2.7081758355537895

Epoch: 6| Step: 5
Training loss: 1.466722021720003
Validation loss: 2.7471794344513483

Epoch: 6| Step: 6
Training loss: 2.263461217549267
Validation loss: 2.716316976059442

Epoch: 6| Step: 7
Training loss: 1.0976976271463377
Validation loss: 2.7320124710509552

Epoch: 6| Step: 8
Training loss: 1.475275841475472
Validation loss: 2.755089702588185

Epoch: 6| Step: 9
Training loss: 1.5587069439237553
Validation loss: 2.7387758135801468

Epoch: 6| Step: 10
Training loss: 1.9679628645448106
Validation loss: 2.724958645801385

Epoch: 6| Step: 11
Training loss: 1.2307728225169592
Validation loss: 2.7244799073882575

Epoch: 6| Step: 12
Training loss: 2.304479143455117
Validation loss: 2.692068357187367

Epoch: 6| Step: 13
Training loss: 0.9762896347303693
Validation loss: 2.662537139012695

Epoch: 326| Step: 0
Training loss: 1.5721453697702976
Validation loss: 2.6705775987028275

Epoch: 6| Step: 1
Training loss: 1.4825698316315703
Validation loss: 2.6756117569826534

Epoch: 6| Step: 2
Training loss: 2.172548697291283
Validation loss: 2.7245845816337577

Epoch: 6| Step: 3
Training loss: 1.693668042554311
Validation loss: 2.708573841762301

Epoch: 6| Step: 4
Training loss: 1.2711838515034402
Validation loss: 2.7976198536524826

Epoch: 6| Step: 5
Training loss: 2.006613406723923
Validation loss: 2.7142185872723723

Epoch: 6| Step: 6
Training loss: 1.764897964813375
Validation loss: 2.713949364452887

Epoch: 6| Step: 7
Training loss: 1.572131114442213
Validation loss: 2.676495176984039

Epoch: 6| Step: 8
Training loss: 1.678733235244947
Validation loss: 2.6626134308007794

Epoch: 6| Step: 9
Training loss: 1.4342490213625878
Validation loss: 2.6650932160202787

Epoch: 6| Step: 10
Training loss: 1.802174060573643
Validation loss: 2.6597365367051578

Epoch: 6| Step: 11
Training loss: 1.8893249077044845
Validation loss: 2.6833875892516685

Epoch: 6| Step: 12
Training loss: 2.1756524915966415
Validation loss: 2.740804774652766

Epoch: 6| Step: 13
Training loss: 2.0069811097887365
Validation loss: 2.7712898499762857

Epoch: 327| Step: 0
Training loss: 1.3251805596314037
Validation loss: 2.7785330942885533

Epoch: 6| Step: 1
Training loss: 1.5627010216147978
Validation loss: 2.733812183404906

Epoch: 6| Step: 2
Training loss: 1.393113214058735
Validation loss: 2.742025372384785

Epoch: 6| Step: 3
Training loss: 2.18267529984159
Validation loss: 2.767631908927008

Epoch: 6| Step: 4
Training loss: 1.9141835699911394
Validation loss: 2.700257163693172

Epoch: 6| Step: 5
Training loss: 2.2315478812586784
Validation loss: 2.7228820794693016

Epoch: 6| Step: 6
Training loss: 1.1199384844439442
Validation loss: 2.718308467747365

Epoch: 6| Step: 7
Training loss: 2.1283568627060823
Validation loss: 2.742780021853893

Epoch: 6| Step: 8
Training loss: 1.6200926113736493
Validation loss: 2.703871497124059

Epoch: 6| Step: 9
Training loss: 2.0106549163006187
Validation loss: 2.6987130721467705

Epoch: 6| Step: 10
Training loss: 1.4640200320733776
Validation loss: 2.7301412157650384

Epoch: 6| Step: 11
Training loss: 1.412504824064676
Validation loss: 2.6950509501909536

Epoch: 6| Step: 12
Training loss: 1.5650060012507319
Validation loss: 2.784914909560475

Epoch: 6| Step: 13
Training loss: 1.716560495050059
Validation loss: 2.7272871160368464

Epoch: 328| Step: 0
Training loss: 1.4163279221891403
Validation loss: 2.7041789739844964

Epoch: 6| Step: 1
Training loss: 2.031678844078481
Validation loss: 2.710696954526375

Epoch: 6| Step: 2
Training loss: 1.1344105465366439
Validation loss: 2.680157723055853

Epoch: 6| Step: 3
Training loss: 2.0084851989732533
Validation loss: 2.709788244661783

Epoch: 6| Step: 4
Training loss: 1.2551880936422009
Validation loss: 2.6967903250628704

Epoch: 6| Step: 5
Training loss: 1.920781204222391
Validation loss: 2.6644899877363803

Epoch: 6| Step: 6
Training loss: 2.5064935275743228
Validation loss: 2.676908514546484

Epoch: 6| Step: 7
Training loss: 1.7822688351151066
Validation loss: 2.6952085613167975

Epoch: 6| Step: 8
Training loss: 1.5368332572440282
Validation loss: 2.700120038437107

Epoch: 6| Step: 9
Training loss: 1.7131834573663587
Validation loss: 2.7395866065253562

Epoch: 6| Step: 10
Training loss: 1.476830997981943
Validation loss: 2.702120585149267

Epoch: 6| Step: 11
Training loss: 1.5680209468104152
Validation loss: 2.771697179802598

Epoch: 6| Step: 12
Training loss: 1.8526707805003564
Validation loss: 2.7637253611211268

Epoch: 6| Step: 13
Training loss: 1.2765889868912494
Validation loss: 2.790080649555888

Epoch: 329| Step: 0
Training loss: 1.5436327314431109
Validation loss: 2.7765564623101398

Epoch: 6| Step: 1
Training loss: 2.142850623802078
Validation loss: 2.774000284467672

Epoch: 6| Step: 2
Training loss: 1.3317013329174054
Validation loss: 2.7636431904844216

Epoch: 6| Step: 3
Training loss: 1.5248097817028152
Validation loss: 2.721163135497847

Epoch: 6| Step: 4
Training loss: 1.96745390841676
Validation loss: 2.7086094984446345

Epoch: 6| Step: 5
Training loss: 1.820418719029101
Validation loss: 2.702715289574173

Epoch: 6| Step: 6
Training loss: 1.943622636455414
Validation loss: 2.7221106297679376

Epoch: 6| Step: 7
Training loss: 2.0610772051540107
Validation loss: 2.756565110870233

Epoch: 6| Step: 8
Training loss: 1.3941582359854072
Validation loss: 2.8136536104335983

Epoch: 6| Step: 9
Training loss: 1.8846987697623008
Validation loss: 2.8480274741646006

Epoch: 6| Step: 10
Training loss: 1.76764698210581
Validation loss: 2.8057623090404054

Epoch: 6| Step: 11
Training loss: 1.9573799477469669
Validation loss: 2.799731538027901

Epoch: 6| Step: 12
Training loss: 1.246733450443752
Validation loss: 2.8127820050178935

Epoch: 6| Step: 13
Training loss: 1.5996107909553792
Validation loss: 2.757367884427138

Epoch: 330| Step: 0
Training loss: 1.8745019887128624
Validation loss: 2.713238943912292

Epoch: 6| Step: 1
Training loss: 1.4937841052387606
Validation loss: 2.7206538465883776

Epoch: 6| Step: 2
Training loss: 1.892841899430006
Validation loss: 2.677256423955312

Epoch: 6| Step: 3
Training loss: 1.32142700467698
Validation loss: 2.6753859030663847

Epoch: 6| Step: 4
Training loss: 1.5506215049276821
Validation loss: 2.7014622508081625

Epoch: 6| Step: 5
Training loss: 1.2031512071802
Validation loss: 2.6653304676331837

Epoch: 6| Step: 6
Training loss: 2.4137441678324905
Validation loss: 2.681760677383365

Epoch: 6| Step: 7
Training loss: 1.739462667456597
Validation loss: 2.6957253844764573

Epoch: 6| Step: 8
Training loss: 1.4437433746317982
Validation loss: 2.7479981592302667

Epoch: 6| Step: 9
Training loss: 2.464122442993144
Validation loss: 2.779658229960395

Epoch: 6| Step: 10
Training loss: 1.514780654891685
Validation loss: 2.911943116656007

Epoch: 6| Step: 11
Training loss: 2.458478298331201
Validation loss: 2.922671585158342

Epoch: 6| Step: 12
Training loss: 1.4860544441487065
Validation loss: 2.7860731530089144

Epoch: 6| Step: 13
Training loss: 1.6601698930965143
Validation loss: 2.7346833264131565

Epoch: 331| Step: 0
Training loss: 1.9446663760129554
Validation loss: 2.7474862950092827

Epoch: 6| Step: 1
Training loss: 1.6355075041535512
Validation loss: 2.7208946801397143

Epoch: 6| Step: 2
Training loss: 2.067652191501746
Validation loss: 2.687324296397474

Epoch: 6| Step: 3
Training loss: 2.253548261485807
Validation loss: 2.7040243398381634

Epoch: 6| Step: 4
Training loss: 1.3387666159488236
Validation loss: 2.7142671041280884

Epoch: 6| Step: 5
Training loss: 1.1260366961392716
Validation loss: 2.725497681844833

Epoch: 6| Step: 6
Training loss: 1.7012966035826371
Validation loss: 2.728454399832799

Epoch: 6| Step: 7
Training loss: 1.496159405176548
Validation loss: 2.7015924831923286

Epoch: 6| Step: 8
Training loss: 1.7946195295887777
Validation loss: 2.7681628147808683

Epoch: 6| Step: 9
Training loss: 1.358082650266483
Validation loss: 2.712460019802897

Epoch: 6| Step: 10
Training loss: 1.923459028283131
Validation loss: 2.7560010369413774

Epoch: 6| Step: 11
Training loss: 2.3000729673669924
Validation loss: 2.737203228916886

Epoch: 6| Step: 12
Training loss: 1.6376386802130474
Validation loss: 2.7353286242836936

Epoch: 6| Step: 13
Training loss: 1.4626797166263623
Validation loss: 2.6832873869648624

Epoch: 332| Step: 0
Training loss: 1.8036243560449348
Validation loss: 2.721620995005385

Epoch: 6| Step: 1
Training loss: 2.120227390905973
Validation loss: 2.728955258245085

Epoch: 6| Step: 2
Training loss: 1.1918302688246278
Validation loss: 2.669090247519725

Epoch: 6| Step: 3
Training loss: 2.2239378333356687
Validation loss: 2.645662907996369

Epoch: 6| Step: 4
Training loss: 1.7062060284101264
Validation loss: 2.675030011160232

Epoch: 6| Step: 5
Training loss: 1.6828909201312063
Validation loss: 2.6525719778066663

Epoch: 6| Step: 6
Training loss: 1.7104972377421386
Validation loss: 2.6701447534076483

Epoch: 6| Step: 7
Training loss: 1.2787471143255553
Validation loss: 2.6953272869791767

Epoch: 6| Step: 8
Training loss: 1.5409305292767512
Validation loss: 2.7102424397476454

Epoch: 6| Step: 9
Training loss: 1.4295269818689955
Validation loss: 2.69993239600706

Epoch: 6| Step: 10
Training loss: 1.9715669853871698
Validation loss: 2.759438140941643

Epoch: 6| Step: 11
Training loss: 1.434862453767074
Validation loss: 2.765559452522951

Epoch: 6| Step: 12
Training loss: 1.6123548161403878
Validation loss: 2.772127757398573

Epoch: 6| Step: 13
Training loss: 1.7253748749006979
Validation loss: 2.7280289605748522

Epoch: 333| Step: 0
Training loss: 1.9301856629600957
Validation loss: 2.7108488334058616

Epoch: 6| Step: 1
Training loss: 1.6541482797877154
Validation loss: 2.763114896438144

Epoch: 6| Step: 2
Training loss: 2.4894228342159694
Validation loss: 2.7819312686410296

Epoch: 6| Step: 3
Training loss: 1.2799561643544937
Validation loss: 2.7474565014159644

Epoch: 6| Step: 4
Training loss: 1.4033906477024114
Validation loss: 2.760382862004034

Epoch: 6| Step: 5
Training loss: 1.6818315882699106
Validation loss: 2.708362217284505

Epoch: 6| Step: 6
Training loss: 1.7681306597125885
Validation loss: 2.6875319663815485

Epoch: 6| Step: 7
Training loss: 1.928512029893664
Validation loss: 2.6688047693783408

Epoch: 6| Step: 8
Training loss: 1.6220625223228797
Validation loss: 2.6589564130342214

Epoch: 6| Step: 9
Training loss: 1.041795563670171
Validation loss: 2.633382703422952

Epoch: 6| Step: 10
Training loss: 1.3538739499368118
Validation loss: 2.6813341129035644

Epoch: 6| Step: 11
Training loss: 1.348887978072874
Validation loss: 2.647833381101369

Epoch: 6| Step: 12
Training loss: 2.130641293227007
Validation loss: 2.650007144750404

Epoch: 6| Step: 13
Training loss: 1.4754404315616378
Validation loss: 2.7255291223840374

Epoch: 334| Step: 0
Training loss: 1.4103200716930755
Validation loss: 2.7290537182292316

Epoch: 6| Step: 1
Training loss: 1.3218135990825652
Validation loss: 2.7716072024834606

Epoch: 6| Step: 2
Training loss: 1.5783916285919755
Validation loss: 2.769612585970862

Epoch: 6| Step: 3
Training loss: 1.838988346235098
Validation loss: 2.730350366299045

Epoch: 6| Step: 4
Training loss: 2.1710753581121516
Validation loss: 2.7715032145402225

Epoch: 6| Step: 5
Training loss: 1.8992194931675326
Validation loss: 2.7271373474351663

Epoch: 6| Step: 6
Training loss: 1.5596014985923876
Validation loss: 2.744398915363204

Epoch: 6| Step: 7
Training loss: 1.6111344284621094
Validation loss: 2.7493197582349413

Epoch: 6| Step: 8
Training loss: 1.4420738431670996
Validation loss: 2.7622390825231533

Epoch: 6| Step: 9
Training loss: 1.4756745590166649
Validation loss: 2.6599443438092423

Epoch: 6| Step: 10
Training loss: 1.2330742271709092
Validation loss: 2.6797541692538633

Epoch: 6| Step: 11
Training loss: 1.8658101256771402
Validation loss: 2.6923014900988447

Epoch: 6| Step: 12
Training loss: 2.403036076719791
Validation loss: 2.674081824234596

Epoch: 6| Step: 13
Training loss: 1.4182659920030043
Validation loss: 2.7341209366251005

Epoch: 335| Step: 0
Training loss: 1.2121316251885463
Validation loss: 2.703262237416704

Epoch: 6| Step: 1
Training loss: 1.8323036755863535
Validation loss: 2.713315296554445

Epoch: 6| Step: 2
Training loss: 1.4318157260703073
Validation loss: 2.7103613425337665

Epoch: 6| Step: 3
Training loss: 2.0083946245055824
Validation loss: 2.7045521726347554

Epoch: 6| Step: 4
Training loss: 1.073019349946732
Validation loss: 2.7300010211416343

Epoch: 6| Step: 5
Training loss: 2.154795944217981
Validation loss: 2.6947144217983876

Epoch: 6| Step: 6
Training loss: 1.6525949417980481
Validation loss: 2.7217426710228954

Epoch: 6| Step: 7
Training loss: 1.5923785124091026
Validation loss: 2.7011248441267117

Epoch: 6| Step: 8
Training loss: 2.098373546179669
Validation loss: 2.687529038856409

Epoch: 6| Step: 9
Training loss: 1.2457362890987558
Validation loss: 2.6632095418273067

Epoch: 6| Step: 10
Training loss: 1.5017463531830886
Validation loss: 2.6910001451144256

Epoch: 6| Step: 11
Training loss: 1.7149957055129843
Validation loss: 2.706521812455838

Epoch: 6| Step: 12
Training loss: 1.3108558347451766
Validation loss: 2.770465157124122

Epoch: 6| Step: 13
Training loss: 2.2177435513040242
Validation loss: 2.736657459771687

Epoch: 336| Step: 0
Training loss: 1.5348393935885696
Validation loss: 2.7346047586460687

Epoch: 6| Step: 1
Training loss: 1.836416952958373
Validation loss: 2.6931162266364455

Epoch: 6| Step: 2
Training loss: 1.5619909601719255
Validation loss: 2.6916380968339335

Epoch: 6| Step: 3
Training loss: 1.4107196136912055
Validation loss: 2.692766072129518

Epoch: 6| Step: 4
Training loss: 1.7817925413300382
Validation loss: 2.7030104831553894

Epoch: 6| Step: 5
Training loss: 1.9334375183490204
Validation loss: 2.736666926834274

Epoch: 6| Step: 6
Training loss: 1.8227325855135323
Validation loss: 2.714862704496744

Epoch: 6| Step: 7
Training loss: 1.8758985273820596
Validation loss: 2.77090897612229

Epoch: 6| Step: 8
Training loss: 1.809161498760689
Validation loss: 2.77812842593073

Epoch: 6| Step: 9
Training loss: 1.4792221578299067
Validation loss: 2.8021952997879516

Epoch: 6| Step: 10
Training loss: 1.502368170211938
Validation loss: 2.790059784894715

Epoch: 6| Step: 11
Training loss: 1.0410531844185895
Validation loss: 2.7613565440335988

Epoch: 6| Step: 12
Training loss: 1.400889585766085
Validation loss: 2.695361371910297

Epoch: 6| Step: 13
Training loss: 2.316902506325184
Validation loss: 2.7189169061517457

Epoch: 337| Step: 0
Training loss: 1.0351341964963598
Validation loss: 2.6797033518923823

Epoch: 6| Step: 1
Training loss: 1.4388720557227692
Validation loss: 2.690153349838855

Epoch: 6| Step: 2
Training loss: 1.1880079488070916
Validation loss: 2.6906378119175103

Epoch: 6| Step: 3
Training loss: 1.4173047741667903
Validation loss: 2.704720292828249

Epoch: 6| Step: 4
Training loss: 1.2248815206725336
Validation loss: 2.665650365305549

Epoch: 6| Step: 5
Training loss: 1.4065251399131704
Validation loss: 2.717070634524918

Epoch: 6| Step: 6
Training loss: 1.504820865096259
Validation loss: 2.717830473227912

Epoch: 6| Step: 7
Training loss: 2.652554982556599
Validation loss: 2.668212544373748

Epoch: 6| Step: 8
Training loss: 2.4203380999556496
Validation loss: 2.6861098486621113

Epoch: 6| Step: 9
Training loss: 1.4819146093821067
Validation loss: 2.69659007288638

Epoch: 6| Step: 10
Training loss: 0.9323991610537584
Validation loss: 2.6944876325451714

Epoch: 6| Step: 11
Training loss: 1.0819214582688006
Validation loss: 2.665090017832213

Epoch: 6| Step: 12
Training loss: 2.553209723160613
Validation loss: 2.657416457821563

Epoch: 6| Step: 13
Training loss: 1.5944764220826197
Validation loss: 2.6546627912443577

Epoch: 338| Step: 0
Training loss: 1.5493000172716924
Validation loss: 2.674362749626034

Epoch: 6| Step: 1
Training loss: 2.088244929998585
Validation loss: 2.685351866144225

Epoch: 6| Step: 2
Training loss: 1.7061075814863207
Validation loss: 2.710821642126825

Epoch: 6| Step: 3
Training loss: 1.5985664442450491
Validation loss: 2.7152635867199764

Epoch: 6| Step: 4
Training loss: 1.184538913949081
Validation loss: 2.7466724522153174

Epoch: 6| Step: 5
Training loss: 1.2707662825275778
Validation loss: 2.819623290550608

Epoch: 6| Step: 6
Training loss: 1.7716914921214741
Validation loss: 2.724988495805354

Epoch: 6| Step: 7
Training loss: 1.7326928994376345
Validation loss: 2.7370689128144137

Epoch: 6| Step: 8
Training loss: 1.8776254710039468
Validation loss: 2.7971905010015368

Epoch: 6| Step: 9
Training loss: 1.9789771005964316
Validation loss: 2.782076309269125

Epoch: 6| Step: 10
Training loss: 1.4322927116621424
Validation loss: 2.7650552726748816

Epoch: 6| Step: 11
Training loss: 2.2929315255310017
Validation loss: 2.731151780981955

Epoch: 6| Step: 12
Training loss: 1.2880292045587571
Validation loss: 2.720726785330986

Epoch: 6| Step: 13
Training loss: 0.982286690422606
Validation loss: 2.7094855034104772

Epoch: 339| Step: 0
Training loss: 1.411955976794129
Validation loss: 2.7138995607579064

Epoch: 6| Step: 1
Training loss: 1.8984192898351804
Validation loss: 2.6955894438505625

Epoch: 6| Step: 2
Training loss: 2.047088728367753
Validation loss: 2.696332493420399

Epoch: 6| Step: 3
Training loss: 1.3813974500293207
Validation loss: 2.761718850718078

Epoch: 6| Step: 4
Training loss: 1.2287930658968098
Validation loss: 2.7448980731836023

Epoch: 6| Step: 5
Training loss: 1.0651100861152492
Validation loss: 2.728989185260103

Epoch: 6| Step: 6
Training loss: 1.68539438629827
Validation loss: 2.768081335724057

Epoch: 6| Step: 7
Training loss: 2.2615079106174174
Validation loss: 2.766963799924894

Epoch: 6| Step: 8
Training loss: 1.822621595933756
Validation loss: 2.6804099040630778

Epoch: 6| Step: 9
Training loss: 0.9881802232090889
Validation loss: 2.7469368694398693

Epoch: 6| Step: 10
Training loss: 1.2984618165164161
Validation loss: 2.714282007441941

Epoch: 6| Step: 11
Training loss: 2.039345440289384
Validation loss: 2.750111765468775

Epoch: 6| Step: 12
Training loss: 1.3202262714827364
Validation loss: 2.723861763131597

Epoch: 6| Step: 13
Training loss: 1.9268204243343063
Validation loss: 2.716523146397492

Epoch: 340| Step: 0
Training loss: 2.5082438920846943
Validation loss: 2.678248264557759

Epoch: 6| Step: 1
Training loss: 0.9724271879911454
Validation loss: 2.7061077852889377

Epoch: 6| Step: 2
Training loss: 1.7756771112493728
Validation loss: 2.7186407162271404

Epoch: 6| Step: 3
Training loss: 1.5722736619068658
Validation loss: 2.6801446167040983

Epoch: 6| Step: 4
Training loss: 1.0129404828812705
Validation loss: 2.7282823386890254

Epoch: 6| Step: 5
Training loss: 1.7491827827766473
Validation loss: 2.6828481942499653

Epoch: 6| Step: 6
Training loss: 1.4485439981527488
Validation loss: 2.7147184640347986

Epoch: 6| Step: 7
Training loss: 1.7871847501607872
Validation loss: 2.7183479216383173

Epoch: 6| Step: 8
Training loss: 1.653488375959439
Validation loss: 2.7590716462022065

Epoch: 6| Step: 9
Training loss: 1.4858980095366146
Validation loss: 2.7358202502654096

Epoch: 6| Step: 10
Training loss: 1.6337557171909085
Validation loss: 2.7368984676312333

Epoch: 6| Step: 11
Training loss: 1.3281010793887902
Validation loss: 2.7081704359705827

Epoch: 6| Step: 12
Training loss: 1.338403756524359
Validation loss: 2.6961247643826107

Epoch: 6| Step: 13
Training loss: 2.096105815953671
Validation loss: 2.6774799384639794

Epoch: 341| Step: 0
Training loss: 1.544207884184719
Validation loss: 2.662574524052887

Epoch: 6| Step: 1
Training loss: 2.2093616706413686
Validation loss: 2.662366952094084

Epoch: 6| Step: 2
Training loss: 1.966239963998179
Validation loss: 2.672975190954821

Epoch: 6| Step: 3
Training loss: 1.6313366220210113
Validation loss: 2.6447343396142275

Epoch: 6| Step: 4
Training loss: 2.195259500861583
Validation loss: 2.6805216062918205

Epoch: 6| Step: 5
Training loss: 1.705321339393315
Validation loss: 2.748149972015161

Epoch: 6| Step: 6
Training loss: 1.5084356887961405
Validation loss: 2.830738202138809

Epoch: 6| Step: 7
Training loss: 1.8058572256317649
Validation loss: 2.8811892080341184

Epoch: 6| Step: 8
Training loss: 2.204054832385664
Validation loss: 2.849176476383495

Epoch: 6| Step: 9
Training loss: 1.4443169541623508
Validation loss: 2.736738596662829

Epoch: 6| Step: 10
Training loss: 1.5868072379910458
Validation loss: 2.668593743519698

Epoch: 6| Step: 11
Training loss: 1.5702639899660835
Validation loss: 2.64979342969065

Epoch: 6| Step: 12
Training loss: 1.0422715274731442
Validation loss: 2.6665892639450255

Epoch: 6| Step: 13
Training loss: 1.5297594406153319
Validation loss: 2.6692962992624145

Epoch: 342| Step: 0
Training loss: 2.000882430908757
Validation loss: 2.6969213134749483

Epoch: 6| Step: 1
Training loss: 2.021295894368346
Validation loss: 2.6856046395302746

Epoch: 6| Step: 2
Training loss: 1.7692388499276352
Validation loss: 2.6927715026017713

Epoch: 6| Step: 3
Training loss: 2.336963339005913
Validation loss: 2.7197759599839677

Epoch: 6| Step: 4
Training loss: 1.7474509475437803
Validation loss: 2.7488353748487033

Epoch: 6| Step: 5
Training loss: 1.9633565017723495
Validation loss: 2.75621004890212

Epoch: 6| Step: 6
Training loss: 1.7454100770234764
Validation loss: 2.756249796434137

Epoch: 6| Step: 7
Training loss: 1.6667753502059597
Validation loss: 2.8343467209094655

Epoch: 6| Step: 8
Training loss: 1.4919713847456257
Validation loss: 2.7991613920373517

Epoch: 6| Step: 9
Training loss: 2.382174747357343
Validation loss: 2.858542844102395

Epoch: 6| Step: 10
Training loss: 1.545678417672565
Validation loss: 2.8623541926711593

Epoch: 6| Step: 11
Training loss: 2.129793482695133
Validation loss: 2.758350366691557

Epoch: 6| Step: 12
Training loss: 1.2799654778653125
Validation loss: 2.7212921038156392

Epoch: 6| Step: 13
Training loss: 1.4625222489710545
Validation loss: 2.678194584752992

Epoch: 343| Step: 0
Training loss: 1.5758408738952252
Validation loss: 2.6302363076311837

Epoch: 6| Step: 1
Training loss: 2.131756867127594
Validation loss: 2.6467124549770893

Epoch: 6| Step: 2
Training loss: 1.3185563003966398
Validation loss: 2.5946870436390994

Epoch: 6| Step: 3
Training loss: 1.7643557687401155
Validation loss: 2.6600876853946067

Epoch: 6| Step: 4
Training loss: 1.5581667513557456
Validation loss: 2.6594297861387197

Epoch: 6| Step: 5
Training loss: 1.5636517666608483
Validation loss: 2.672828459578863

Epoch: 6| Step: 6
Training loss: 1.703358485464784
Validation loss: 2.68413023419325

Epoch: 6| Step: 7
Training loss: 1.5896621337930519
Validation loss: 2.6824425713517637

Epoch: 6| Step: 8
Training loss: 1.516509437096497
Validation loss: 2.791859454050556

Epoch: 6| Step: 9
Training loss: 1.930575394318858
Validation loss: 2.7760610001244475

Epoch: 6| Step: 10
Training loss: 1.9580009327146901
Validation loss: 2.7894475049621668

Epoch: 6| Step: 11
Training loss: 2.2561112168338218
Validation loss: 2.7786172986315765

Epoch: 6| Step: 12
Training loss: 1.3097529500865097
Validation loss: 2.7968913669213853

Epoch: 6| Step: 13
Training loss: 2.055394852287466
Validation loss: 2.7288763508222176

Epoch: 344| Step: 0
Training loss: 1.7348100271299773
Validation loss: 2.7229032399888236

Epoch: 6| Step: 1
Training loss: 1.941550420247384
Validation loss: 2.7704501472668857

Epoch: 6| Step: 2
Training loss: 1.6416697490811658
Validation loss: 2.704583893394226

Epoch: 6| Step: 3
Training loss: 2.0395441765252467
Validation loss: 2.699491546875282

Epoch: 6| Step: 4
Training loss: 1.5812648847882058
Validation loss: 2.7061891333098176

Epoch: 6| Step: 5
Training loss: 1.278617294003384
Validation loss: 2.7653999021488613

Epoch: 6| Step: 6
Training loss: 1.341792033046554
Validation loss: 2.7622276315723924

Epoch: 6| Step: 7
Training loss: 1.7561979211436762
Validation loss: 2.813598587795464

Epoch: 6| Step: 8
Training loss: 1.3317237118632264
Validation loss: 2.7626132119111975

Epoch: 6| Step: 9
Training loss: 1.4167614886395448
Validation loss: 2.7189918644334305

Epoch: 6| Step: 10
Training loss: 1.2767467912043906
Validation loss: 2.691932084271209

Epoch: 6| Step: 11
Training loss: 1.5093846006858145
Validation loss: 2.6461674687017

Epoch: 6| Step: 12
Training loss: 2.454132747793551
Validation loss: 2.6587163806649556

Epoch: 6| Step: 13
Training loss: 1.8092728528325142
Validation loss: 2.6850161792165848

Epoch: 345| Step: 0
Training loss: 2.067825262829632
Validation loss: 2.6772519267587604

Epoch: 6| Step: 1
Training loss: 1.6641733911665273
Validation loss: 2.718250433380636

Epoch: 6| Step: 2
Training loss: 1.6764179434054265
Validation loss: 2.70049240013955

Epoch: 6| Step: 3
Training loss: 1.7358030334089252
Validation loss: 2.724482386830291

Epoch: 6| Step: 4
Training loss: 2.2107485633162987
Validation loss: 2.767525129723913

Epoch: 6| Step: 5
Training loss: 1.9100443489358392
Validation loss: 2.749982284720032

Epoch: 6| Step: 6
Training loss: 1.7073107737165798
Validation loss: 2.746522800287258

Epoch: 6| Step: 7
Training loss: 1.4441367651031642
Validation loss: 2.7819706129710884

Epoch: 6| Step: 8
Training loss: 1.3329856786881498
Validation loss: 2.784606765251962

Epoch: 6| Step: 9
Training loss: 1.3857779736834437
Validation loss: 2.7672839316839375

Epoch: 6| Step: 10
Training loss: 1.501031679768356
Validation loss: 2.750704978399008

Epoch: 6| Step: 11
Training loss: 1.7448107210703574
Validation loss: 2.7252143653056518

Epoch: 6| Step: 12
Training loss: 1.760510286027566
Validation loss: 2.706584223782039

Epoch: 6| Step: 13
Training loss: 1.438157138722316
Validation loss: 2.676742819023054

Epoch: 346| Step: 0
Training loss: 2.192829723728139
Validation loss: 2.688881659388566

Epoch: 6| Step: 1
Training loss: 1.45384510204819
Validation loss: 2.675830241030943

Epoch: 6| Step: 2
Training loss: 2.0236564134867834
Validation loss: 2.666435661343718

Epoch: 6| Step: 3
Training loss: 1.5944480863094643
Validation loss: 2.696419530003456

Epoch: 6| Step: 4
Training loss: 1.7836902032571909
Validation loss: 2.6997949746077756

Epoch: 6| Step: 5
Training loss: 1.3977156326361868
Validation loss: 2.734602724311041

Epoch: 6| Step: 6
Training loss: 1.6607139458487497
Validation loss: 2.7644196665731124

Epoch: 6| Step: 7
Training loss: 1.5272071562661809
Validation loss: 2.7789075895586306

Epoch: 6| Step: 8
Training loss: 1.4849675652143954
Validation loss: 2.7595356284968755

Epoch: 6| Step: 9
Training loss: 1.3537058510806548
Validation loss: 2.764766768287174

Epoch: 6| Step: 10
Training loss: 1.3315150359762686
Validation loss: 2.7287995380280066

Epoch: 6| Step: 11
Training loss: 1.5744808915869422
Validation loss: 2.7164209262501537

Epoch: 6| Step: 12
Training loss: 2.0164901887374542
Validation loss: 2.6799231333882974

Epoch: 6| Step: 13
Training loss: 1.7558562519525203
Validation loss: 2.7144204228180135

Epoch: 347| Step: 0
Training loss: 1.3202119597126896
Validation loss: 2.659417123008957

Epoch: 6| Step: 1
Training loss: 1.6938953013576932
Validation loss: 2.683331442964571

Epoch: 6| Step: 2
Training loss: 1.2584651414835064
Validation loss: 2.68858903805958

Epoch: 6| Step: 3
Training loss: 1.1513004558660738
Validation loss: 2.6472803999636874

Epoch: 6| Step: 4
Training loss: 1.8192074413451
Validation loss: 2.6613911858515684

Epoch: 6| Step: 5
Training loss: 1.664143090244267
Validation loss: 2.716442897762626

Epoch: 6| Step: 6
Training loss: 1.6731796878146274
Validation loss: 2.7518095940620317

Epoch: 6| Step: 7
Training loss: 2.170806512160521
Validation loss: 2.7864817585658646

Epoch: 6| Step: 8
Training loss: 1.0996424939332812
Validation loss: 2.818170383855271

Epoch: 6| Step: 9
Training loss: 1.4805477393021345
Validation loss: 2.7909767285202216

Epoch: 6| Step: 10
Training loss: 1.3299103797747904
Validation loss: 2.859484144118496

Epoch: 6| Step: 11
Training loss: 1.8113940580904264
Validation loss: 2.778361774620139

Epoch: 6| Step: 12
Training loss: 2.5014328665088406
Validation loss: 2.7615218247451354

Epoch: 6| Step: 13
Training loss: 1.0969027176096402
Validation loss: 2.747336369212947

Epoch: 348| Step: 0
Training loss: 1.4046471680143444
Validation loss: 2.722687453351578

Epoch: 6| Step: 1
Training loss: 1.4792010433160332
Validation loss: 2.730997189970467

Epoch: 6| Step: 2
Training loss: 1.5680204906584467
Validation loss: 2.745009677246861

Epoch: 6| Step: 3
Training loss: 1.4907598406505114
Validation loss: 2.700100075374137

Epoch: 6| Step: 4
Training loss: 1.1572850208566627
Validation loss: 2.7555428622151688

Epoch: 6| Step: 5
Training loss: 0.8805253776476051
Validation loss: 2.6422378911214244

Epoch: 6| Step: 6
Training loss: 1.4088986778161556
Validation loss: 2.646555649289117

Epoch: 6| Step: 7
Training loss: 2.4523769137013725
Validation loss: 2.700381715306338

Epoch: 6| Step: 8
Training loss: 1.7473203715722125
Validation loss: 2.7193691966273192

Epoch: 6| Step: 9
Training loss: 1.7353475782083552
Validation loss: 2.717694936485115

Epoch: 6| Step: 10
Training loss: 1.8532225816325338
Validation loss: 2.733863012428287

Epoch: 6| Step: 11
Training loss: 1.9043938401795448
Validation loss: 2.7320764380988516

Epoch: 6| Step: 12
Training loss: 1.4684877364387225
Validation loss: 2.7297494474768493

Epoch: 6| Step: 13
Training loss: 1.5601240786089796
Validation loss: 2.7831240423020827

Epoch: 349| Step: 0
Training loss: 1.5621557237903954
Validation loss: 2.7892223066606774

Epoch: 6| Step: 1
Training loss: 2.0711040782922754
Validation loss: 2.7421803560372204

Epoch: 6| Step: 2
Training loss: 1.6727031189838868
Validation loss: 2.7894698984350246

Epoch: 6| Step: 3
Training loss: 0.9951308738957768
Validation loss: 2.7004323201156715

Epoch: 6| Step: 4
Training loss: 1.6325451207607036
Validation loss: 2.735664949869843

Epoch: 6| Step: 5
Training loss: 1.5805843565554691
Validation loss: 2.698143987517401

Epoch: 6| Step: 6
Training loss: 1.160912777623343
Validation loss: 2.6911210941166632

Epoch: 6| Step: 7
Training loss: 1.732000426558867
Validation loss: 2.7324797538060777

Epoch: 6| Step: 8
Training loss: 1.7365990889660543
Validation loss: 2.7283831750592866

Epoch: 6| Step: 9
Training loss: 1.297161714044362
Validation loss: 2.737211227862899

Epoch: 6| Step: 10
Training loss: 1.7823517052596733
Validation loss: 2.733197741711945

Epoch: 6| Step: 11
Training loss: 1.6149027436677843
Validation loss: 2.7051958593277523

Epoch: 6| Step: 12
Training loss: 1.6000086247688532
Validation loss: 2.7339535924344296

Epoch: 6| Step: 13
Training loss: 1.8359984692128766
Validation loss: 2.7104125966758184

Epoch: 350| Step: 0
Training loss: 1.7296549862060275
Validation loss: 2.700477288292674

Epoch: 6| Step: 1
Training loss: 2.0920252742079395
Validation loss: 2.719102230128842

Epoch: 6| Step: 2
Training loss: 1.8798303056790562
Validation loss: 2.7087810488641995

Epoch: 6| Step: 3
Training loss: 1.2122494389522274
Validation loss: 2.7337703653957

Epoch: 6| Step: 4
Training loss: 1.2557070151734968
Validation loss: 2.7360294241633616

Epoch: 6| Step: 5
Training loss: 1.3107710758823414
Validation loss: 2.7186848278199878

Epoch: 6| Step: 6
Training loss: 1.5863139640591233
Validation loss: 2.755186882488394

Epoch: 6| Step: 7
Training loss: 1.3706254730015055
Validation loss: 2.7501811054589633

Epoch: 6| Step: 8
Training loss: 1.7243613456802127
Validation loss: 2.69321577552875

Epoch: 6| Step: 9
Training loss: 2.073186642751292
Validation loss: 2.682551359672709

Epoch: 6| Step: 10
Training loss: 1.2664918168169146
Validation loss: 2.7164597200388725

Epoch: 6| Step: 11
Training loss: 1.5644363611968573
Validation loss: 2.6790972208739365

Epoch: 6| Step: 12
Training loss: 1.1257690344312536
Validation loss: 2.6430566189576084

Epoch: 6| Step: 13
Training loss: 1.848727087326387
Validation loss: 2.6782563653967193

Epoch: 351| Step: 0
Training loss: 1.4453745235847124
Validation loss: 2.6565426085626034

Epoch: 6| Step: 1
Training loss: 1.5934590092711187
Validation loss: 2.731596816017249

Epoch: 6| Step: 2
Training loss: 1.0244459469090732
Validation loss: 2.740640752871052

Epoch: 6| Step: 3
Training loss: 1.9361160011296643
Validation loss: 2.7556212944432104

Epoch: 6| Step: 4
Training loss: 1.4324344448248594
Validation loss: 2.7761325833222212

Epoch: 6| Step: 5
Training loss: 1.5103575420865565
Validation loss: 2.7390337974261634

Epoch: 6| Step: 6
Training loss: 1.6327911813612763
Validation loss: 2.7379833137351133

Epoch: 6| Step: 7
Training loss: 1.2110946061140295
Validation loss: 2.691000026983088

Epoch: 6| Step: 8
Training loss: 2.6059293554279166
Validation loss: 2.6851616304528845

Epoch: 6| Step: 9
Training loss: 1.7273208540732263
Validation loss: 2.702996752568706

Epoch: 6| Step: 10
Training loss: 1.442325784618659
Validation loss: 2.705658462281066

Epoch: 6| Step: 11
Training loss: 1.7071542237285888
Validation loss: 2.6848038744911

Epoch: 6| Step: 12
Training loss: 1.2263913369265342
Validation loss: 2.705950206922506

Epoch: 6| Step: 13
Training loss: 1.1164604435467922
Validation loss: 2.6799763189284898

Epoch: 352| Step: 0
Training loss: 1.076662315314587
Validation loss: 2.7129151590591416

Epoch: 6| Step: 1
Training loss: 1.369643310906315
Validation loss: 2.738521287875398

Epoch: 6| Step: 2
Training loss: 1.785411123699663
Validation loss: 2.7632517285217477

Epoch: 6| Step: 3
Training loss: 1.6457613514800349
Validation loss: 2.7808254789478317

Epoch: 6| Step: 4
Training loss: 1.9720314773887078
Validation loss: 2.7620872097090805

Epoch: 6| Step: 5
Training loss: 1.435011658837145
Validation loss: 2.7369290730507507

Epoch: 6| Step: 6
Training loss: 1.2009440880623783
Validation loss: 2.6844749947198814

Epoch: 6| Step: 7
Training loss: 1.9093423369215792
Validation loss: 2.6805815322113635

Epoch: 6| Step: 8
Training loss: 1.3386842476078502
Validation loss: 2.669257951410735

Epoch: 6| Step: 9
Training loss: 1.143311407075469
Validation loss: 2.6689670793092604

Epoch: 6| Step: 10
Training loss: 2.4612918659173593
Validation loss: 2.717276718432729

Epoch: 6| Step: 11
Training loss: 1.718123234997367
Validation loss: 2.752960504415984

Epoch: 6| Step: 12
Training loss: 1.461086245221668
Validation loss: 2.698050776699219

Epoch: 6| Step: 13
Training loss: 1.5678679764109853
Validation loss: 2.764827792971453

Epoch: 353| Step: 0
Training loss: 1.1239289907750518
Validation loss: 2.760729161454317

Epoch: 6| Step: 1
Training loss: 2.0725665795246484
Validation loss: 2.738896408311462

Epoch: 6| Step: 2
Training loss: 1.503809541837848
Validation loss: 2.746871671649304

Epoch: 6| Step: 3
Training loss: 1.3178240558134795
Validation loss: 2.7313302226909753

Epoch: 6| Step: 4
Training loss: 1.6167141871334023
Validation loss: 2.705766302495824

Epoch: 6| Step: 5
Training loss: 1.5015967135942658
Validation loss: 2.710669820360875

Epoch: 6| Step: 6
Training loss: 1.0968458774971732
Validation loss: 2.707661432893829

Epoch: 6| Step: 7
Training loss: 1.8953159241043949
Validation loss: 2.7135334905597617

Epoch: 6| Step: 8
Training loss: 1.4630709487336704
Validation loss: 2.7377273500000383

Epoch: 6| Step: 9
Training loss: 1.6127185348163775
Validation loss: 2.705855047524367

Epoch: 6| Step: 10
Training loss: 1.2140895059888483
Validation loss: 2.7291538927395673

Epoch: 6| Step: 11
Training loss: 1.9333767855902284
Validation loss: 2.7022416687287967

Epoch: 6| Step: 12
Training loss: 1.804152107914189
Validation loss: 2.7448824168385224

Epoch: 6| Step: 13
Training loss: 1.5272469648442508
Validation loss: 2.6830042710338393

Epoch: 354| Step: 0
Training loss: 1.4592943385702735
Validation loss: 2.682004366305763

Epoch: 6| Step: 1
Training loss: 1.4993788704736706
Validation loss: 2.6835372008205636

Epoch: 6| Step: 2
Training loss: 0.9525708322895834
Validation loss: 2.7094942001409286

Epoch: 6| Step: 3
Training loss: 1.8409847277163753
Validation loss: 2.6725592081085012

Epoch: 6| Step: 4
Training loss: 1.4302552143515965
Validation loss: 2.65554586315204

Epoch: 6| Step: 5
Training loss: 1.3437407737237765
Validation loss: 2.6907155812161623

Epoch: 6| Step: 6
Training loss: 1.407765948915719
Validation loss: 2.7038711370690054

Epoch: 6| Step: 7
Training loss: 1.8164603276560274
Validation loss: 2.691506762720076

Epoch: 6| Step: 8
Training loss: 1.2333402038503134
Validation loss: 2.7278770622508173

Epoch: 6| Step: 9
Training loss: 2.045476887320832
Validation loss: 2.7552041027899548

Epoch: 6| Step: 10
Training loss: 1.0380719274542605
Validation loss: 2.764779372883678

Epoch: 6| Step: 11
Training loss: 2.069699984937171
Validation loss: 2.8128372272780116

Epoch: 6| Step: 12
Training loss: 1.999626005490706
Validation loss: 2.8081101526008942

Epoch: 6| Step: 13
Training loss: 1.564189760135544
Validation loss: 2.8085153822561097

Epoch: 355| Step: 0
Training loss: 1.3638427802115358
Validation loss: 2.796148351402832

Epoch: 6| Step: 1
Training loss: 1.3748512187572377
Validation loss: 2.792822304467591

Epoch: 6| Step: 2
Training loss: 1.223375297904161
Validation loss: 2.7517412914998856

Epoch: 6| Step: 3
Training loss: 1.3530747877852232
Validation loss: 2.724659179815664

Epoch: 6| Step: 4
Training loss: 1.0237559631136726
Validation loss: 2.735742528545044

Epoch: 6| Step: 5
Training loss: 1.8819631346477912
Validation loss: 2.7230802595344543

Epoch: 6| Step: 6
Training loss: 1.2409677334755098
Validation loss: 2.651427614988192

Epoch: 6| Step: 7
Training loss: 1.3360519806292108
Validation loss: 2.683524614431014

Epoch: 6| Step: 8
Training loss: 2.026657311685621
Validation loss: 2.690970981283141

Epoch: 6| Step: 9
Training loss: 1.5919038139883712
Validation loss: 2.7116821981179475

Epoch: 6| Step: 10
Training loss: 1.220751561539038
Validation loss: 2.658626914081401

Epoch: 6| Step: 11
Training loss: 1.9332600623529586
Validation loss: 2.682005921979563

Epoch: 6| Step: 12
Training loss: 1.6808832924409138
Validation loss: 2.7310948779576694

Epoch: 6| Step: 13
Training loss: 2.361044185911638
Validation loss: 2.769213171710102

Epoch: 356| Step: 0
Training loss: 1.652129608057821
Validation loss: 2.9050451673059277

Epoch: 6| Step: 1
Training loss: 1.5904941587463777
Validation loss: 2.8824919235500133

Epoch: 6| Step: 2
Training loss: 1.8491376619727438
Validation loss: 2.7696588268945725

Epoch: 6| Step: 3
Training loss: 1.2038997286075959
Validation loss: 2.744680895853333

Epoch: 6| Step: 4
Training loss: 1.6351300452074111
Validation loss: 2.7043098836943438

Epoch: 6| Step: 5
Training loss: 1.801833567280246
Validation loss: 2.684864496639589

Epoch: 6| Step: 6
Training loss: 1.4094576386374744
Validation loss: 2.6765991520195427

Epoch: 6| Step: 7
Training loss: 1.7743268576792948
Validation loss: 2.678873055141993

Epoch: 6| Step: 8
Training loss: 1.3819777560838478
Validation loss: 2.7096215241183135

Epoch: 6| Step: 9
Training loss: 1.6074397478929277
Validation loss: 2.6893885283145043

Epoch: 6| Step: 10
Training loss: 1.5480568734596207
Validation loss: 2.709482276960378

Epoch: 6| Step: 11
Training loss: 1.4344935283016296
Validation loss: 2.735301923318447

Epoch: 6| Step: 12
Training loss: 2.3053185584986835
Validation loss: 2.8275679501621744

Epoch: 6| Step: 13
Training loss: 1.5353719545200788
Validation loss: 2.8173429683554247

Epoch: 357| Step: 0
Training loss: 1.5875948059127778
Validation loss: 2.8570744304751003

Epoch: 6| Step: 1
Training loss: 1.1355979086500247
Validation loss: 2.775038952597024

Epoch: 6| Step: 2
Training loss: 1.3014044657701969
Validation loss: 2.6809061613932874

Epoch: 6| Step: 3
Training loss: 1.588940563043351
Validation loss: 2.6832659584574787

Epoch: 6| Step: 4
Training loss: 1.8239045944735763
Validation loss: 2.6470656241119723

Epoch: 6| Step: 5
Training loss: 1.383616197728135
Validation loss: 2.6368672722324007

Epoch: 6| Step: 6
Training loss: 1.506998820966982
Validation loss: 2.6336745483714386

Epoch: 6| Step: 7
Training loss: 1.4194860825939712
Validation loss: 2.6474795188988125

Epoch: 6| Step: 8
Training loss: 2.131844213437326
Validation loss: 2.6682292984150733

Epoch: 6| Step: 9
Training loss: 1.350888652072802
Validation loss: 2.648230695574122

Epoch: 6| Step: 10
Training loss: 2.2361434660387975
Validation loss: 2.675997685870019

Epoch: 6| Step: 11
Training loss: 2.0320620747493825
Validation loss: 2.724594455254289

Epoch: 6| Step: 12
Training loss: 1.1717291168962938
Validation loss: 2.8053029269760192

Epoch: 6| Step: 13
Training loss: 1.5470607915719452
Validation loss: 2.771700828438825

Epoch: 358| Step: 0
Training loss: 1.5175768681622852
Validation loss: 2.7677388275805836

Epoch: 6| Step: 1
Training loss: 2.189543723036352
Validation loss: 2.750421202798944

Epoch: 6| Step: 2
Training loss: 1.502281520147801
Validation loss: 2.722570431641581

Epoch: 6| Step: 3
Training loss: 1.487781671093674
Validation loss: 2.708931553625222

Epoch: 6| Step: 4
Training loss: 1.8910081963727126
Validation loss: 2.709076549572658

Epoch: 6| Step: 5
Training loss: 1.705571089158508
Validation loss: 2.716725498178722

Epoch: 6| Step: 6
Training loss: 1.2709862924462414
Validation loss: 2.683435952749695

Epoch: 6| Step: 7
Training loss: 1.6376916729517548
Validation loss: 2.73035695179556

Epoch: 6| Step: 8
Training loss: 1.273551233747531
Validation loss: 2.75505983256535

Epoch: 6| Step: 9
Training loss: 1.100094730459658
Validation loss: 2.718703901696635

Epoch: 6| Step: 10
Training loss: 1.299914280192736
Validation loss: 2.7441540628377976

Epoch: 6| Step: 11
Training loss: 1.542810514038118
Validation loss: 2.7513582170028394

Epoch: 6| Step: 12
Training loss: 1.2303572831301102
Validation loss: 2.7944561747824466

Epoch: 6| Step: 13
Training loss: 1.9319508981250308
Validation loss: 2.7679509728578897

Epoch: 359| Step: 0
Training loss: 1.2309851153331437
Validation loss: 2.794550805525112

Epoch: 6| Step: 1
Training loss: 1.1350599422674925
Validation loss: 2.7146452833490757

Epoch: 6| Step: 2
Training loss: 0.9754761413558156
Validation loss: 2.7168833145003846

Epoch: 6| Step: 3
Training loss: 1.79209935338194
Validation loss: 2.760500569537951

Epoch: 6| Step: 4
Training loss: 2.0522198962423492
Validation loss: 2.6637169398489826

Epoch: 6| Step: 5
Training loss: 1.1211177278406803
Validation loss: 2.709224911191459

Epoch: 6| Step: 6
Training loss: 1.581084997441479
Validation loss: 2.6978800463062864

Epoch: 6| Step: 7
Training loss: 2.424287246882165
Validation loss: 2.7352331722178755

Epoch: 6| Step: 8
Training loss: 1.800089738516229
Validation loss: 2.7004159718788108

Epoch: 6| Step: 9
Training loss: 1.0228857635263648
Validation loss: 2.719377993260049

Epoch: 6| Step: 10
Training loss: 1.0143174190478355
Validation loss: 2.6976214631540016

Epoch: 6| Step: 11
Training loss: 1.51412307413376
Validation loss: 2.699115270902806

Epoch: 6| Step: 12
Training loss: 1.9068513140712413
Validation loss: 2.7231866583513398

Epoch: 6| Step: 13
Training loss: 1.6751558430609552
Validation loss: 2.737919179911068

Epoch: 360| Step: 0
Training loss: 1.5670497267038224
Validation loss: 2.754228714625374

Epoch: 6| Step: 1
Training loss: 1.4600441389074452
Validation loss: 2.787567136722966

Epoch: 6| Step: 2
Training loss: 2.4548162959527136
Validation loss: 2.7220030210325477

Epoch: 6| Step: 3
Training loss: 1.3283421058476792
Validation loss: 2.6711259055807837

Epoch: 6| Step: 4
Training loss: 1.5782364154426214
Validation loss: 2.6218153694049406

Epoch: 6| Step: 5
Training loss: 1.047662694855736
Validation loss: 2.692095413153353

Epoch: 6| Step: 6
Training loss: 1.1999755856891423
Validation loss: 2.641482167063597

Epoch: 6| Step: 7
Training loss: 1.7456352434086553
Validation loss: 2.665265837931917

Epoch: 6| Step: 8
Training loss: 1.3318403000878332
Validation loss: 2.6075604310291474

Epoch: 6| Step: 9
Training loss: 1.4948966313990126
Validation loss: 2.6243458038641707

Epoch: 6| Step: 10
Training loss: 2.1449956894766795
Validation loss: 2.639897579243766

Epoch: 6| Step: 11
Training loss: 1.349697259230416
Validation loss: 2.6770620877106914

Epoch: 6| Step: 12
Training loss: 1.5398627200184716
Validation loss: 2.6588235617335543

Epoch: 6| Step: 13
Training loss: 1.20112120978958
Validation loss: 2.6910180862510744

Epoch: 361| Step: 0
Training loss: 2.093302436932672
Validation loss: 2.767010559019606

Epoch: 6| Step: 1
Training loss: 1.1243160075837475
Validation loss: 2.771809353457846

Epoch: 6| Step: 2
Training loss: 2.212010530974445
Validation loss: 2.8022881802885165

Epoch: 6| Step: 3
Training loss: 2.1390500923058813
Validation loss: 2.7872509598496107

Epoch: 6| Step: 4
Training loss: 1.1201290539060578
Validation loss: 2.7126877454601384

Epoch: 6| Step: 5
Training loss: 1.2524368851191545
Validation loss: 2.6680692222819298

Epoch: 6| Step: 6
Training loss: 1.3619669615257632
Validation loss: 2.68463160598775

Epoch: 6| Step: 7
Training loss: 1.561495648888918
Validation loss: 2.601188052306096

Epoch: 6| Step: 8
Training loss: 1.1667993106823005
Validation loss: 2.6431964790816096

Epoch: 6| Step: 9
Training loss: 1.258253790170777
Validation loss: 2.691412185197329

Epoch: 6| Step: 10
Training loss: 1.6406903208490053
Validation loss: 2.6578480569567966

Epoch: 6| Step: 11
Training loss: 1.3736797843809105
Validation loss: 2.678423272834164

Epoch: 6| Step: 12
Training loss: 1.7758133220335728
Validation loss: 2.746125873578558

Epoch: 6| Step: 13
Training loss: 1.4309660817357786
Validation loss: 2.762158536448784

Epoch: 362| Step: 0
Training loss: 1.7360018411793592
Validation loss: 2.7744537211037175

Epoch: 6| Step: 1
Training loss: 1.2324786528311344
Validation loss: 2.7293018181414257

Epoch: 6| Step: 2
Training loss: 1.9887049135555714
Validation loss: 2.7438822668776215

Epoch: 6| Step: 3
Training loss: 1.4898637183160959
Validation loss: 2.7298621730456802

Epoch: 6| Step: 4
Training loss: 1.1674378888682835
Validation loss: 2.669506636958146

Epoch: 6| Step: 5
Training loss: 0.9220078905951248
Validation loss: 2.6838930750629335

Epoch: 6| Step: 6
Training loss: 1.9039087770591623
Validation loss: 2.662962790014

Epoch: 6| Step: 7
Training loss: 1.8280682677244802
Validation loss: 2.671975667443907

Epoch: 6| Step: 8
Training loss: 1.7318940159480911
Validation loss: 2.6696732132484864

Epoch: 6| Step: 9
Training loss: 1.6053733333254345
Validation loss: 2.6568837924364006

Epoch: 6| Step: 10
Training loss: 1.4139946346963532
Validation loss: 2.736586383156174

Epoch: 6| Step: 11
Training loss: 1.2797099836933765
Validation loss: 2.742060282510386

Epoch: 6| Step: 12
Training loss: 1.8820867762246634
Validation loss: 2.7045010865906853

Epoch: 6| Step: 13
Training loss: 1.4743526007813275
Validation loss: 2.8271986004338223

Epoch: 363| Step: 0
Training loss: 1.5208602624189955
Validation loss: 2.778823608508021

Epoch: 6| Step: 1
Training loss: 1.278209054883132
Validation loss: 2.8151553723068408

Epoch: 6| Step: 2
Training loss: 2.2638454420085163
Validation loss: 2.7867446372046527

Epoch: 6| Step: 3
Training loss: 1.2997857485795066
Validation loss: 2.745019868247249

Epoch: 6| Step: 4
Training loss: 1.3252330485110555
Validation loss: 2.6577896443108826

Epoch: 6| Step: 5
Training loss: 1.5482329756067017
Validation loss: 2.6585430495032827

Epoch: 6| Step: 6
Training loss: 1.4608301133452009
Validation loss: 2.6971127455005526

Epoch: 6| Step: 7
Training loss: 1.2080603104750678
Validation loss: 2.675088730644706

Epoch: 6| Step: 8
Training loss: 1.4514372674077556
Validation loss: 2.6605333536159477

Epoch: 6| Step: 9
Training loss: 1.380415741313452
Validation loss: 2.695792585730237

Epoch: 6| Step: 10
Training loss: 1.7067840886079064
Validation loss: 2.7057302779096584

Epoch: 6| Step: 11
Training loss: 1.2065299267683425
Validation loss: 2.6966419718978707

Epoch: 6| Step: 12
Training loss: 2.1565148011302626
Validation loss: 2.7394874372245885

Epoch: 6| Step: 13
Training loss: 1.228832840712484
Validation loss: 2.8143780689701408

Epoch: 364| Step: 0
Training loss: 1.2356997756830617
Validation loss: 2.7374732493773

Epoch: 6| Step: 1
Training loss: 1.367262701963571
Validation loss: 2.731427884219589

Epoch: 6| Step: 2
Training loss: 1.3622940992812094
Validation loss: 2.708910181285045

Epoch: 6| Step: 3
Training loss: 1.30226485957959
Validation loss: 2.712477965492488

Epoch: 6| Step: 4
Training loss: 1.4033728518701907
Validation loss: 2.7035861494785745

Epoch: 6| Step: 5
Training loss: 2.046465767289605
Validation loss: 2.776657842467148

Epoch: 6| Step: 6
Training loss: 1.4624696744725447
Validation loss: 2.6751251381573597

Epoch: 6| Step: 7
Training loss: 2.31103933443989
Validation loss: 2.7006399973834205

Epoch: 6| Step: 8
Training loss: 1.2335353844758683
Validation loss: 2.7306152071624057

Epoch: 6| Step: 9
Training loss: 1.2351124166375211
Validation loss: 2.7878548067028026

Epoch: 6| Step: 10
Training loss: 1.357180742760371
Validation loss: 2.700909230116181

Epoch: 6| Step: 11
Training loss: 1.7052109569357712
Validation loss: 2.774376401340159

Epoch: 6| Step: 12
Training loss: 1.126927896147819
Validation loss: 2.7999727225110296

Epoch: 6| Step: 13
Training loss: 1.5640350430848136
Validation loss: 2.6883748205341584

Epoch: 365| Step: 0
Training loss: 1.2215348728868574
Validation loss: 2.6917493331151108

Epoch: 6| Step: 1
Training loss: 1.8952123302585164
Validation loss: 2.650860243749351

Epoch: 6| Step: 2
Training loss: 0.9450990420115347
Validation loss: 2.692052578105129

Epoch: 6| Step: 3
Training loss: 0.9853850737998838
Validation loss: 2.67894116862195

Epoch: 6| Step: 4
Training loss: 1.5276307911920335
Validation loss: 2.746988482657239

Epoch: 6| Step: 5
Training loss: 1.9004483346517642
Validation loss: 2.702975083385301

Epoch: 6| Step: 6
Training loss: 1.3137238563963387
Validation loss: 2.6467400046148093

Epoch: 6| Step: 7
Training loss: 1.7888669902469456
Validation loss: 2.6973531765439693

Epoch: 6| Step: 8
Training loss: 1.7615987055916669
Validation loss: 2.7111734219809676

Epoch: 6| Step: 9
Training loss: 1.4266682413276706
Validation loss: 2.6956350529748083

Epoch: 6| Step: 10
Training loss: 1.432112591270434
Validation loss: 2.6722687399532425

Epoch: 6| Step: 11
Training loss: 1.5007664788475896
Validation loss: 2.6903452043601876

Epoch: 6| Step: 12
Training loss: 1.6272099945875442
Validation loss: 2.6797417133804733

Epoch: 6| Step: 13
Training loss: 1.5303257858388268
Validation loss: 2.6899722357147895

Epoch: 366| Step: 0
Training loss: 1.1248000815036088
Validation loss: 2.667049400361247

Epoch: 6| Step: 1
Training loss: 1.8748222266798609
Validation loss: 2.6844958584941145

Epoch: 6| Step: 2
Training loss: 1.0022699104400037
Validation loss: 2.675685002807289

Epoch: 6| Step: 3
Training loss: 1.4861072270866493
Validation loss: 2.673966390500761

Epoch: 6| Step: 4
Training loss: 1.2857032238015131
Validation loss: 2.676113566532407

Epoch: 6| Step: 5
Training loss: 0.9865289162691547
Validation loss: 2.7460521190195397

Epoch: 6| Step: 6
Training loss: 1.0244865573654611
Validation loss: 2.7577266229473207

Epoch: 6| Step: 7
Training loss: 2.0845992120715873
Validation loss: 2.738808124551654

Epoch: 6| Step: 8
Training loss: 1.053034978352645
Validation loss: 2.7637764163963947

Epoch: 6| Step: 9
Training loss: 1.639086628782644
Validation loss: 2.775345080917179

Epoch: 6| Step: 10
Training loss: 1.6189896866373894
Validation loss: 2.760816456376327

Epoch: 6| Step: 11
Training loss: 1.9108836655351964
Validation loss: 2.799669911591589

Epoch: 6| Step: 12
Training loss: 1.3808187130737453
Validation loss: 2.7791983791831574

Epoch: 6| Step: 13
Training loss: 1.8622778023918047
Validation loss: 2.8009199163993026

Epoch: 367| Step: 0
Training loss: 1.2616917279541542
Validation loss: 2.7409712801401365

Epoch: 6| Step: 1
Training loss: 1.5128219482530285
Validation loss: 2.7272773978646097

Epoch: 6| Step: 2
Training loss: 1.1902181736313242
Validation loss: 2.66495149309436

Epoch: 6| Step: 3
Training loss: 1.2799877368816401
Validation loss: 2.6665134286562027

Epoch: 6| Step: 4
Training loss: 1.250858727175558
Validation loss: 2.649089661669297

Epoch: 6| Step: 5
Training loss: 1.949558755885897
Validation loss: 2.698133457463069

Epoch: 6| Step: 6
Training loss: 1.4348860484745587
Validation loss: 2.626175087597662

Epoch: 6| Step: 7
Training loss: 1.5468952678547128
Validation loss: 2.6932064655689607

Epoch: 6| Step: 8
Training loss: 1.78593517980817
Validation loss: 2.6719055991995364

Epoch: 6| Step: 9
Training loss: 1.6972718759998884
Validation loss: 2.671347106777498

Epoch: 6| Step: 10
Training loss: 1.47200576622497
Validation loss: 2.6714690943020307

Epoch: 6| Step: 11
Training loss: 1.8138784231390601
Validation loss: 2.741180234926697

Epoch: 6| Step: 12
Training loss: 1.8698062170059369
Validation loss: 2.8181513345818585

Epoch: 6| Step: 13
Training loss: 1.0917955647633015
Validation loss: 2.7939735294727415

Epoch: 368| Step: 0
Training loss: 1.1519507303662537
Validation loss: 2.6803136600021764

Epoch: 6| Step: 1
Training loss: 1.46583820410883
Validation loss: 2.729518566788897

Epoch: 6| Step: 2
Training loss: 1.3844486191164296
Validation loss: 2.705461054941636

Epoch: 6| Step: 3
Training loss: 1.2468933601270522
Validation loss: 2.63647925525464

Epoch: 6| Step: 4
Training loss: 1.4977567110708807
Validation loss: 2.6539385144092873

Epoch: 6| Step: 5
Training loss: 2.81630567987481
Validation loss: 2.6612189248060845

Epoch: 6| Step: 6
Training loss: 2.038270760067272
Validation loss: 2.6792065825586224

Epoch: 6| Step: 7
Training loss: 1.332176357207474
Validation loss: 2.727371940951537

Epoch: 6| Step: 8
Training loss: 1.3489544351685905
Validation loss: 2.7001674105701263

Epoch: 6| Step: 9
Training loss: 1.2004535294848513
Validation loss: 2.692995485284295

Epoch: 6| Step: 10
Training loss: 1.0437716133483939
Validation loss: 2.737676396775969

Epoch: 6| Step: 11
Training loss: 0.9990622176383833
Validation loss: 2.7013625792263007

Epoch: 6| Step: 12
Training loss: 1.2769434123634045
Validation loss: 2.6783540483095796

Epoch: 6| Step: 13
Training loss: 1.1707830809717996
Validation loss: 2.698041056314721

Epoch: 369| Step: 0
Training loss: 1.4337249612658924
Validation loss: 2.682925589504611

Epoch: 6| Step: 1
Training loss: 1.9020606110278615
Validation loss: 2.702216728954978

Epoch: 6| Step: 2
Training loss: 1.3771851689037853
Validation loss: 2.641451869819998

Epoch: 6| Step: 3
Training loss: 1.6284793870773255
Validation loss: 2.7476674649195276

Epoch: 6| Step: 4
Training loss: 2.0917637071731425
Validation loss: 2.7237061310249837

Epoch: 6| Step: 5
Training loss: 1.5566141277053929
Validation loss: 2.721132820046779

Epoch: 6| Step: 6
Training loss: 1.8188603711803895
Validation loss: 2.766608313056169

Epoch: 6| Step: 7
Training loss: 1.3642934195173226
Validation loss: 2.7971151522319166

Epoch: 6| Step: 8
Training loss: 1.515653315014181
Validation loss: 2.809200951627193

Epoch: 6| Step: 9
Training loss: 1.2848968244017125
Validation loss: 2.8007863717273964

Epoch: 6| Step: 10
Training loss: 1.1471907926682094
Validation loss: 2.7939529356618595

Epoch: 6| Step: 11
Training loss: 1.3454116040454802
Validation loss: 2.7170646968772387

Epoch: 6| Step: 12
Training loss: 1.0810760799176293
Validation loss: 2.717370512730765

Epoch: 6| Step: 13
Training loss: 1.1653822004240435
Validation loss: 2.69983631803491

Epoch: 370| Step: 0
Training loss: 1.0982061888676515
Validation loss: 2.7621844742961916

Epoch: 6| Step: 1
Training loss: 1.3855743844264543
Validation loss: 2.7054154792789697

Epoch: 6| Step: 2
Training loss: 1.217009156937892
Validation loss: 2.7872317562844606

Epoch: 6| Step: 3
Training loss: 1.8655590154330355
Validation loss: 2.7195840411280026

Epoch: 6| Step: 4
Training loss: 1.7909434729366516
Validation loss: 2.733211117043504

Epoch: 6| Step: 5
Training loss: 1.4794597962110145
Validation loss: 2.748565501980028

Epoch: 6| Step: 6
Training loss: 1.0368251949993073
Validation loss: 2.729015059785909

Epoch: 6| Step: 7
Training loss: 1.7395629272482342
Validation loss: 2.7309130596838482

Epoch: 6| Step: 8
Training loss: 1.4690053190338874
Validation loss: 2.7493566858771836

Epoch: 6| Step: 9
Training loss: 1.2331200993126818
Validation loss: 2.691518248805449

Epoch: 6| Step: 10
Training loss: 1.5235290499835568
Validation loss: 2.7250337586951168

Epoch: 6| Step: 11
Training loss: 2.028465945323981
Validation loss: 2.6985829732146414

Epoch: 6| Step: 12
Training loss: 1.0920366218490443
Validation loss: 2.716993941347932

Epoch: 6| Step: 13
Training loss: 1.1069957310181606
Validation loss: 2.810124870820093

Epoch: 371| Step: 0
Training loss: 1.6269498277793344
Validation loss: 2.7740206539665886

Epoch: 6| Step: 1
Training loss: 1.133828910764807
Validation loss: 2.786914172573445

Epoch: 6| Step: 2
Training loss: 1.7182585273663173
Validation loss: 2.7143147856606324

Epoch: 6| Step: 3
Training loss: 0.8692781832418375
Validation loss: 2.68063892197531

Epoch: 6| Step: 4
Training loss: 1.2415135312643104
Validation loss: 2.7117471063175906

Epoch: 6| Step: 5
Training loss: 0.9899793066886873
Validation loss: 2.674994798162043

Epoch: 6| Step: 6
Training loss: 1.6093065562091986
Validation loss: 2.6977633772693856

Epoch: 6| Step: 7
Training loss: 1.1169653184743744
Validation loss: 2.70847474731594

Epoch: 6| Step: 8
Training loss: 2.1360161164779434
Validation loss: 2.6755279940929584

Epoch: 6| Step: 9
Training loss: 1.6188391760340337
Validation loss: 2.714961075477404

Epoch: 6| Step: 10
Training loss: 1.42263228822039
Validation loss: 2.661991197925463

Epoch: 6| Step: 11
Training loss: 1.7492422779540322
Validation loss: 2.6924298780088955

Epoch: 6| Step: 12
Training loss: 1.8133126771792878
Validation loss: 2.723980064135219

Epoch: 6| Step: 13
Training loss: 1.0638347544452686
Validation loss: 2.721058563288221

Epoch: 372| Step: 0
Training loss: 1.572120119553002
Validation loss: 2.732360104745884

Epoch: 6| Step: 1
Training loss: 1.1765448033191188
Validation loss: 2.741561397939406

Epoch: 6| Step: 2
Training loss: 1.1998169739541378
Validation loss: 2.7134685152606717

Epoch: 6| Step: 3
Training loss: 1.1281973120848243
Validation loss: 2.7212041104696265

Epoch: 6| Step: 4
Training loss: 1.7845168690310336
Validation loss: 2.6995651236338634

Epoch: 6| Step: 5
Training loss: 1.8032202102144594
Validation loss: 2.698659703704021

Epoch: 6| Step: 6
Training loss: 1.12131548559528
Validation loss: 2.658672372629011

Epoch: 6| Step: 7
Training loss: 1.4565540176468712
Validation loss: 2.698394502327758

Epoch: 6| Step: 8
Training loss: 1.9418702827840773
Validation loss: 2.7058609657141575

Epoch: 6| Step: 9
Training loss: 1.8030259711774754
Validation loss: 2.726546585342612

Epoch: 6| Step: 10
Training loss: 1.5670057562191033
Validation loss: 2.7680983179029073

Epoch: 6| Step: 11
Training loss: 1.1520024198202043
Validation loss: 2.7357619337637167

Epoch: 6| Step: 12
Training loss: 1.398626133647517
Validation loss: 2.6978294525385658

Epoch: 6| Step: 13
Training loss: 1.3833474455347232
Validation loss: 2.70111675302748

Epoch: 373| Step: 0
Training loss: 1.9421124469130173
Validation loss: 2.684124149655707

Epoch: 6| Step: 1
Training loss: 1.2300992865148928
Validation loss: 2.658363929759805

Epoch: 6| Step: 2
Training loss: 1.8274624920086557
Validation loss: 2.6940990720419347

Epoch: 6| Step: 3
Training loss: 1.4689509477521214
Validation loss: 2.6658264018480726

Epoch: 6| Step: 4
Training loss: 1.9397051168274475
Validation loss: 2.6554901831475424

Epoch: 6| Step: 5
Training loss: 0.9504330877624472
Validation loss: 2.6645261299568634

Epoch: 6| Step: 6
Training loss: 1.1950137195039023
Validation loss: 2.6574250408473183

Epoch: 6| Step: 7
Training loss: 1.2575954937178317
Validation loss: 2.67047162594673

Epoch: 6| Step: 8
Training loss: 1.7166897997485717
Validation loss: 2.6775158237164223

Epoch: 6| Step: 9
Training loss: 1.3658957346140714
Validation loss: 2.6633199363517965

Epoch: 6| Step: 10
Training loss: 1.392659616961668
Validation loss: 2.6807638662782978

Epoch: 6| Step: 11
Training loss: 1.2019504907856249
Validation loss: 2.7585171671878213

Epoch: 6| Step: 12
Training loss: 1.1045309341609373
Validation loss: 2.7400924925031878

Epoch: 6| Step: 13
Training loss: 1.3593428158512737
Validation loss: 2.7308083806446604

Epoch: 374| Step: 0
Training loss: 2.05270115673943
Validation loss: 2.797453779577943

Epoch: 6| Step: 1
Training loss: 0.8645621415877043
Validation loss: 2.719871450476606

Epoch: 6| Step: 2
Training loss: 1.1712346679921637
Validation loss: 2.6471981423310083

Epoch: 6| Step: 3
Training loss: 1.457865049471975
Validation loss: 2.6754881760976317

Epoch: 6| Step: 4
Training loss: 1.790921773500341
Validation loss: 2.6737427606138358

Epoch: 6| Step: 5
Training loss: 1.1711502377130567
Validation loss: 2.6523384914430337

Epoch: 6| Step: 6
Training loss: 1.2360850211163068
Validation loss: 2.65986360573104

Epoch: 6| Step: 7
Training loss: 0.981422780855325
Validation loss: 2.6729612168850942

Epoch: 6| Step: 8
Training loss: 1.9108140433006429
Validation loss: 2.7167300762975173

Epoch: 6| Step: 9
Training loss: 1.3137795705035287
Validation loss: 2.7267074619294407

Epoch: 6| Step: 10
Training loss: 1.5299417005913172
Validation loss: 2.6702674357460454

Epoch: 6| Step: 11
Training loss: 1.0280051767389595
Validation loss: 2.6714888473973826

Epoch: 6| Step: 12
Training loss: 1.881041457571616
Validation loss: 2.644148768418412

Epoch: 6| Step: 13
Training loss: 1.131937675741874
Validation loss: 2.6452070280898416

Epoch: 375| Step: 0
Training loss: 1.2246497724036116
Validation loss: 2.6686037796308226

Epoch: 6| Step: 1
Training loss: 2.34419846376763
Validation loss: 2.685910753047044

Epoch: 6| Step: 2
Training loss: 1.5188978586317299
Validation loss: 2.630480947939238

Epoch: 6| Step: 3
Training loss: 1.422145524332781
Validation loss: 2.645942225180382

Epoch: 6| Step: 4
Training loss: 1.1226991861583886
Validation loss: 2.7190588852376423

Epoch: 6| Step: 5
Training loss: 1.2469346608203264
Validation loss: 2.7063046609175885

Epoch: 6| Step: 6
Training loss: 1.2020058318772597
Validation loss: 2.7284780948927723

Epoch: 6| Step: 7
Training loss: 1.2826147486938135
Validation loss: 2.672184626911171

Epoch: 6| Step: 8
Training loss: 1.0279582691368618
Validation loss: 2.6915438044313698

Epoch: 6| Step: 9
Training loss: 1.9241260898101027
Validation loss: 2.687330957759292

Epoch: 6| Step: 10
Training loss: 0.9754531052040741
Validation loss: 2.6484916403909

Epoch: 6| Step: 11
Training loss: 1.6245930969200573
Validation loss: 2.7128097269452507

Epoch: 6| Step: 12
Training loss: 1.0933156922320557
Validation loss: 2.665718347093382

Epoch: 6| Step: 13
Training loss: 1.6556104468875708
Validation loss: 2.674552334555654

Epoch: 376| Step: 0
Training loss: 1.7772146995559852
Validation loss: 2.69830252245944

Epoch: 6| Step: 1
Training loss: 0.9207985622578722
Validation loss: 2.724317046859802

Epoch: 6| Step: 2
Training loss: 1.8325825656749737
Validation loss: 2.7529009054879916

Epoch: 6| Step: 3
Training loss: 1.3566683866613358
Validation loss: 2.8091490881373735

Epoch: 6| Step: 4
Training loss: 1.342907708130554
Validation loss: 2.756888431991134

Epoch: 6| Step: 5
Training loss: 0.922378079491037
Validation loss: 2.7147005697499074

Epoch: 6| Step: 6
Training loss: 1.1640439640079892
Validation loss: 2.7234830909775103

Epoch: 6| Step: 7
Training loss: 0.9942371493922199
Validation loss: 2.7155665032481218

Epoch: 6| Step: 8
Training loss: 1.3061426693566953
Validation loss: 2.6915145874365134

Epoch: 6| Step: 9
Training loss: 1.8442477831243507
Validation loss: 2.6958299812716633

Epoch: 6| Step: 10
Training loss: 2.286917974084429
Validation loss: 2.6654267905609883

Epoch: 6| Step: 11
Training loss: 1.1018105626643995
Validation loss: 2.666538687456278

Epoch: 6| Step: 12
Training loss: 1.658449404055417
Validation loss: 2.7098656989880743

Epoch: 6| Step: 13
Training loss: 1.0702088020377643
Validation loss: 2.6879316545158374

Epoch: 377| Step: 0
Training loss: 1.330110389889498
Validation loss: 2.7068544947545496

Epoch: 6| Step: 1
Training loss: 1.3548684233657096
Validation loss: 2.7043620165860065

Epoch: 6| Step: 2
Training loss: 1.0186783888285513
Validation loss: 2.6841380211968446

Epoch: 6| Step: 3
Training loss: 1.9467794869446755
Validation loss: 2.670436628122929

Epoch: 6| Step: 4
Training loss: 1.7565982948379206
Validation loss: 2.6835627584134696

Epoch: 6| Step: 5
Training loss: 1.8992330509025546
Validation loss: 2.7217278377606733

Epoch: 6| Step: 6
Training loss: 1.7172246927220065
Validation loss: 2.778370784933498

Epoch: 6| Step: 7
Training loss: 1.4086702500577724
Validation loss: 2.8166180168178943

Epoch: 6| Step: 8
Training loss: 1.453697912016119
Validation loss: 2.820887696283736

Epoch: 6| Step: 9
Training loss: 1.141433272671784
Validation loss: 2.826780698728362

Epoch: 6| Step: 10
Training loss: 1.462599925352533
Validation loss: 2.777182859186037

Epoch: 6| Step: 11
Training loss: 1.2982073454803478
Validation loss: 2.7321135115390587

Epoch: 6| Step: 12
Training loss: 1.147848588109767
Validation loss: 2.722347670754835

Epoch: 6| Step: 13
Training loss: 1.1259522646344349
Validation loss: 2.694869678627893

Epoch: 378| Step: 0
Training loss: 1.4197342235711667
Validation loss: 2.671420603403419

Epoch: 6| Step: 1
Training loss: 1.3816007488127215
Validation loss: 2.7009520865367254

Epoch: 6| Step: 2
Training loss: 0.9805375033281718
Validation loss: 2.6498113499075893

Epoch: 6| Step: 3
Training loss: 2.253741967413833
Validation loss: 2.6812256753406483

Epoch: 6| Step: 4
Training loss: 1.0531836632030547
Validation loss: 2.7234219861240723

Epoch: 6| Step: 5
Training loss: 1.6472668581499563
Validation loss: 2.6834312808086644

Epoch: 6| Step: 6
Training loss: 0.7462536305989395
Validation loss: 2.714296837475579

Epoch: 6| Step: 7
Training loss: 1.3746414150483484
Validation loss: 2.691294084120856

Epoch: 6| Step: 8
Training loss: 1.6103879833093357
Validation loss: 2.773376908334418

Epoch: 6| Step: 9
Training loss: 1.5286408597051844
Validation loss: 2.7157541043138376

Epoch: 6| Step: 10
Training loss: 1.5885877592143236
Validation loss: 2.7647966340451813

Epoch: 6| Step: 11
Training loss: 1.3080952164439361
Validation loss: 2.7858394375193236

Epoch: 6| Step: 12
Training loss: 1.383124881956403
Validation loss: 2.852733242830918

Epoch: 6| Step: 13
Training loss: 1.760287970479169
Validation loss: 2.8418639219924007

Epoch: 379| Step: 0
Training loss: 1.2484973458661768
Validation loss: 2.7923988739026337

Epoch: 6| Step: 1
Training loss: 1.9060176645242923
Validation loss: 2.801432230201252

Epoch: 6| Step: 2
Training loss: 1.5479519880670847
Validation loss: 2.7493352086473664

Epoch: 6| Step: 3
Training loss: 1.8132274746265569
Validation loss: 2.7281377954463353

Epoch: 6| Step: 4
Training loss: 1.512883174059402
Validation loss: 2.6688536576948922

Epoch: 6| Step: 5
Training loss: 1.8091523397479625
Validation loss: 2.73601674521213

Epoch: 6| Step: 6
Training loss: 1.167154493975938
Validation loss: 2.652890837647336

Epoch: 6| Step: 7
Training loss: 1.2941132979842662
Validation loss: 2.659968492302209

Epoch: 6| Step: 8
Training loss: 1.0537716880729462
Validation loss: 2.7135043346060423

Epoch: 6| Step: 9
Training loss: 1.3897719606468169
Validation loss: 2.729147690180453

Epoch: 6| Step: 10
Training loss: 1.3241376373745262
Validation loss: 2.7533739806570066

Epoch: 6| Step: 11
Training loss: 1.0091541438398064
Validation loss: 2.755786443295457

Epoch: 6| Step: 12
Training loss: 1.8060161769222698
Validation loss: 2.7639302091422486

Epoch: 6| Step: 13
Training loss: 1.2446642481925636
Validation loss: 2.7878608287608517

Epoch: 380| Step: 0
Training loss: 0.7322483925402896
Validation loss: 2.769820298219895

Epoch: 6| Step: 1
Training loss: 1.1580728132715243
Validation loss: 2.702229331216154

Epoch: 6| Step: 2
Training loss: 1.271701964058889
Validation loss: 2.686017973298842

Epoch: 6| Step: 3
Training loss: 1.0982424436674407
Validation loss: 2.6691537722838765

Epoch: 6| Step: 4
Training loss: 1.2904875767585395
Validation loss: 2.661366206675462

Epoch: 6| Step: 5
Training loss: 1.4101673242023178
Validation loss: 2.6664980050234552

Epoch: 6| Step: 6
Training loss: 1.8287609331034924
Validation loss: 2.644639163724407

Epoch: 6| Step: 7
Training loss: 1.189461643833667
Validation loss: 2.6800275907472186

Epoch: 6| Step: 8
Training loss: 1.237200533149523
Validation loss: 2.7146812189058127

Epoch: 6| Step: 9
Training loss: 1.7242877872060425
Validation loss: 2.671576217394233

Epoch: 6| Step: 10
Training loss: 1.126323133797444
Validation loss: 2.724782440996704

Epoch: 6| Step: 11
Training loss: 1.7198242991551782
Validation loss: 2.732732355721281

Epoch: 6| Step: 12
Training loss: 1.4436603072408123
Validation loss: 2.698740584201121

Epoch: 6| Step: 13
Training loss: 2.3631013659909907
Validation loss: 2.6682588373952423

Epoch: 381| Step: 0
Training loss: 1.4057920769993948
Validation loss: 2.6653546344153343

Epoch: 6| Step: 1
Training loss: 0.9087124944553108
Validation loss: 2.698109466458536

Epoch: 6| Step: 2
Training loss: 1.7867706144517301
Validation loss: 2.6880269088533555

Epoch: 6| Step: 3
Training loss: 2.0059691996163775
Validation loss: 2.6898162530163368

Epoch: 6| Step: 4
Training loss: 1.061951664070691
Validation loss: 2.7075144679139984

Epoch: 6| Step: 5
Training loss: 0.9731313931372133
Validation loss: 2.6696809233460512

Epoch: 6| Step: 6
Training loss: 1.4924784271879235
Validation loss: 2.672282955561623

Epoch: 6| Step: 7
Training loss: 1.2062965305030866
Validation loss: 2.6992360476552824

Epoch: 6| Step: 8
Training loss: 1.165343584549885
Validation loss: 2.6628074934077084

Epoch: 6| Step: 9
Training loss: 1.1931760556630941
Validation loss: 2.714779596462666

Epoch: 6| Step: 10
Training loss: 1.2777067829302844
Validation loss: 2.7295490220305267

Epoch: 6| Step: 11
Training loss: 1.593632413228864
Validation loss: 2.7245258787936124

Epoch: 6| Step: 12
Training loss: 1.9674792957307146
Validation loss: 2.764035258312554

Epoch: 6| Step: 13
Training loss: 1.326555738667757
Validation loss: 2.811279173196869

Epoch: 382| Step: 0
Training loss: 1.113982505119922
Validation loss: 2.781479286715135

Epoch: 6| Step: 1
Training loss: 1.8493704394780297
Validation loss: 2.7246362536709956

Epoch: 6| Step: 2
Training loss: 1.8991137897293917
Validation loss: 2.7363552661233146

Epoch: 6| Step: 3
Training loss: 1.1958781879709917
Validation loss: 2.6785565316830513

Epoch: 6| Step: 4
Training loss: 1.0706130670794398
Validation loss: 2.709834861228295

Epoch: 6| Step: 5
Training loss: 1.2194395804302172
Validation loss: 2.7042374866618446

Epoch: 6| Step: 6
Training loss: 1.4902554931744165
Validation loss: 2.7098586897705914

Epoch: 6| Step: 7
Training loss: 1.1210451015856246
Validation loss: 2.6887723734817572

Epoch: 6| Step: 8
Training loss: 1.7288471830666414
Validation loss: 2.6767937519676632

Epoch: 6| Step: 9
Training loss: 1.1632047219399655
Validation loss: 2.6832890603656296

Epoch: 6| Step: 10
Training loss: 1.2571677219808384
Validation loss: 2.730051309804384

Epoch: 6| Step: 11
Training loss: 1.0761981829354443
Validation loss: 2.720725894421016

Epoch: 6| Step: 12
Training loss: 1.7714431909318262
Validation loss: 2.7414266503467246

Epoch: 6| Step: 13
Training loss: 1.613596444362719
Validation loss: 2.694225840423616

Epoch: 383| Step: 0
Training loss: 1.2168170566017968
Validation loss: 2.7171279409329214

Epoch: 6| Step: 1
Training loss: 1.0505213079166176
Validation loss: 2.6721702843806967

Epoch: 6| Step: 2
Training loss: 1.100571531592442
Validation loss: 2.6787562406452095

Epoch: 6| Step: 3
Training loss: 1.565750707882912
Validation loss: 2.7014241830524504

Epoch: 6| Step: 4
Training loss: 0.7868954199700934
Validation loss: 2.722104301677457

Epoch: 6| Step: 5
Training loss: 1.1646574919171295
Validation loss: 2.6616203024912064

Epoch: 6| Step: 6
Training loss: 1.4435413953014062
Validation loss: 2.732573637021032

Epoch: 6| Step: 7
Training loss: 1.317799541146434
Validation loss: 2.672782401808154

Epoch: 6| Step: 8
Training loss: 2.1592165677679107
Validation loss: 2.6821045794871967

Epoch: 6| Step: 9
Training loss: 1.08085408542057
Validation loss: 2.68773039488203

Epoch: 6| Step: 10
Training loss: 1.895344667719923
Validation loss: 2.680038636745153

Epoch: 6| Step: 11
Training loss: 1.7015743370800391
Validation loss: 2.8412250585841683

Epoch: 6| Step: 12
Training loss: 1.3072720813677277
Validation loss: 2.7638596182273774

Epoch: 6| Step: 13
Training loss: 1.1095124280456128
Validation loss: 2.7864488595581625

Epoch: 384| Step: 0
Training loss: 1.1332313026520067
Validation loss: 2.810589628974675

Epoch: 6| Step: 1
Training loss: 1.286801476474113
Validation loss: 2.743595881033015

Epoch: 6| Step: 2
Training loss: 1.1639002744552271
Validation loss: 2.6989504086844205

Epoch: 6| Step: 3
Training loss: 1.157941354436014
Validation loss: 2.6347313292627548

Epoch: 6| Step: 4
Training loss: 2.2359725469565603
Validation loss: 2.6763219430950076

Epoch: 6| Step: 5
Training loss: 1.5368645944510682
Validation loss: 2.668354548295092

Epoch: 6| Step: 6
Training loss: 1.2070161392599354
Validation loss: 2.653533384107484

Epoch: 6| Step: 7
Training loss: 1.0836402140517543
Validation loss: 2.701402354159188

Epoch: 6| Step: 8
Training loss: 2.078970600839577
Validation loss: 2.6640846050162006

Epoch: 6| Step: 9
Training loss: 0.7809266756489839
Validation loss: 2.642878983074757

Epoch: 6| Step: 10
Training loss: 1.2541406715377375
Validation loss: 2.651426790713764

Epoch: 6| Step: 11
Training loss: 1.6618431227697954
Validation loss: 2.6894825121369

Epoch: 6| Step: 12
Training loss: 1.0991060178816696
Validation loss: 2.694634688653699

Epoch: 6| Step: 13
Training loss: 1.4888710595402965
Validation loss: 2.6691072193647383

Epoch: 385| Step: 0
Training loss: 1.713269321245309
Validation loss: 2.7347896733793395

Epoch: 6| Step: 1
Training loss: 1.6101398317257918
Validation loss: 2.6757590782564917

Epoch: 6| Step: 2
Training loss: 0.776117133411728
Validation loss: 2.6917662949523384

Epoch: 6| Step: 3
Training loss: 1.1681824555612883
Validation loss: 2.72588289639336

Epoch: 6| Step: 4
Training loss: 1.0118652002096848
Validation loss: 2.7451369028051813

Epoch: 6| Step: 5
Training loss: 2.095434735151292
Validation loss: 2.7476952894306472

Epoch: 6| Step: 6
Training loss: 1.4345851868857447
Validation loss: 2.7307104641331326

Epoch: 6| Step: 7
Training loss: 1.2326062241406552
Validation loss: 2.728882961718052

Epoch: 6| Step: 8
Training loss: 1.7144206226715923
Validation loss: 2.708107885122783

Epoch: 6| Step: 9
Training loss: 1.4667452664699607
Validation loss: 2.7263877105796714

Epoch: 6| Step: 10
Training loss: 1.3679334077131176
Validation loss: 2.6880520689761456

Epoch: 6| Step: 11
Training loss: 1.0850965138767565
Validation loss: 2.657491446212443

Epoch: 6| Step: 12
Training loss: 1.2865110636212047
Validation loss: 2.6740861484447347

Epoch: 6| Step: 13
Training loss: 1.140726685890387
Validation loss: 2.648903834754516

Epoch: 386| Step: 0
Training loss: 0.9935357252665762
Validation loss: 2.6426343477202696

Epoch: 6| Step: 1
Training loss: 1.2505490527715242
Validation loss: 2.687968678970305

Epoch: 6| Step: 2
Training loss: 1.9710252723486477
Validation loss: 2.7013174933963597

Epoch: 6| Step: 3
Training loss: 1.2313344180992676
Validation loss: 2.7977361223639456

Epoch: 6| Step: 4
Training loss: 1.7838863471996589
Validation loss: 2.8016110604838538

Epoch: 6| Step: 5
Training loss: 1.4976748883714865
Validation loss: 2.814629596204817

Epoch: 6| Step: 6
Training loss: 1.7945761529256128
Validation loss: 2.766268409268983

Epoch: 6| Step: 7
Training loss: 1.2830529901706855
Validation loss: 2.790244912367011

Epoch: 6| Step: 8
Training loss: 1.0753779589665404
Validation loss: 2.7048187535475723

Epoch: 6| Step: 9
Training loss: 0.9128618097878923
Validation loss: 2.651155455619808

Epoch: 6| Step: 10
Training loss: 1.4036461353006786
Validation loss: 2.6890513799460707

Epoch: 6| Step: 11
Training loss: 1.387767728114707
Validation loss: 2.735193199177637

Epoch: 6| Step: 12
Training loss: 1.7050750487694186
Validation loss: 2.6776374634267364

Epoch: 6| Step: 13
Training loss: 1.339032430767445
Validation loss: 2.6913831291811228

Epoch: 387| Step: 0
Training loss: 1.57032062281695
Validation loss: 2.6807082950206182

Epoch: 6| Step: 1
Training loss: 1.411821771355429
Validation loss: 2.681743652261321

Epoch: 6| Step: 2
Training loss: 1.3781797316013398
Validation loss: 2.6358006515511003

Epoch: 6| Step: 3
Training loss: 0.9808418202471921
Validation loss: 2.655871225914032

Epoch: 6| Step: 4
Training loss: 0.8659381630494722
Validation loss: 2.679300945787034

Epoch: 6| Step: 5
Training loss: 1.3243689887867667
Validation loss: 2.7078402339324334

Epoch: 6| Step: 6
Training loss: 1.7316703671638276
Validation loss: 2.675143141199624

Epoch: 6| Step: 7
Training loss: 1.0160476978699986
Validation loss: 2.7326212027038124

Epoch: 6| Step: 8
Training loss: 1.8887322780098337
Validation loss: 2.6711232129718683

Epoch: 6| Step: 9
Training loss: 1.7966110035560716
Validation loss: 2.669878073990911

Epoch: 6| Step: 10
Training loss: 1.3023688448368647
Validation loss: 2.690656021299686

Epoch: 6| Step: 11
Training loss: 1.5768826570752088
Validation loss: 2.7259009869525235

Epoch: 6| Step: 12
Training loss: 1.0464095604023798
Validation loss: 2.6828988187452683

Epoch: 6| Step: 13
Training loss: 1.4230232213766825
Validation loss: 2.73196342572426

Epoch: 388| Step: 0
Training loss: 1.135940757442458
Validation loss: 2.6436362768894055

Epoch: 6| Step: 1
Training loss: 1.9072785651192588
Validation loss: 2.692869086911839

Epoch: 6| Step: 2
Training loss: 1.2574711685970796
Validation loss: 2.674569858596914

Epoch: 6| Step: 3
Training loss: 0.8764253995302581
Validation loss: 2.6712428454962436

Epoch: 6| Step: 4
Training loss: 1.8799140115105872
Validation loss: 2.767229868160457

Epoch: 6| Step: 5
Training loss: 1.0971036449908336
Validation loss: 2.7303122719826503

Epoch: 6| Step: 6
Training loss: 1.0481408280762403
Validation loss: 2.7084151964775676

Epoch: 6| Step: 7
Training loss: 1.260500623991107
Validation loss: 2.7791794917217247

Epoch: 6| Step: 8
Training loss: 1.7417532204228219
Validation loss: 2.7097978642517138

Epoch: 6| Step: 9
Training loss: 0.9634194614479961
Validation loss: 2.7164038843088467

Epoch: 6| Step: 10
Training loss: 1.4091480486854508
Validation loss: 2.7722711824014987

Epoch: 6| Step: 11
Training loss: 1.3925428987945812
Validation loss: 2.8067119945919177

Epoch: 6| Step: 12
Training loss: 2.0052993423484424
Validation loss: 2.849990955137657

Epoch: 6| Step: 13
Training loss: 0.9331282728154403
Validation loss: 2.8563366574219735

Epoch: 389| Step: 0
Training loss: 1.449809897227269
Validation loss: 2.7585515372951015

Epoch: 6| Step: 1
Training loss: 0.9874675552253251
Validation loss: 2.740382441795678

Epoch: 6| Step: 2
Training loss: 1.2223056375812487
Validation loss: 2.728289803053014

Epoch: 6| Step: 3
Training loss: 1.983623151948147
Validation loss: 2.680449693419907

Epoch: 6| Step: 4
Training loss: 2.096957354911022
Validation loss: 2.6884524409787844

Epoch: 6| Step: 5
Training loss: 1.2559621718413965
Validation loss: 2.6723417131029987

Epoch: 6| Step: 6
Training loss: 1.2708562890569524
Validation loss: 2.7275205457445595

Epoch: 6| Step: 7
Training loss: 1.8199857492203373
Validation loss: 2.792394192158739

Epoch: 6| Step: 8
Training loss: 1.2656368678914054
Validation loss: 2.8304405919259996

Epoch: 6| Step: 9
Training loss: 0.953239621633903
Validation loss: 2.840681327706192

Epoch: 6| Step: 10
Training loss: 1.2927358826748183
Validation loss: 2.831804905758293

Epoch: 6| Step: 11
Training loss: 1.4793144295544598
Validation loss: 2.8282842292711647

Epoch: 6| Step: 12
Training loss: 1.2356090413029213
Validation loss: 2.716530328578616

Epoch: 6| Step: 13
Training loss: 1.0201025637316679
Validation loss: 2.7413170602240626

Epoch: 390| Step: 0
Training loss: 0.816595064806594
Validation loss: 2.6881306078445157

Epoch: 6| Step: 1
Training loss: 1.6468050136570453
Validation loss: 2.640927284289275

Epoch: 6| Step: 2
Training loss: 1.0460206716365732
Validation loss: 2.6030647286119466

Epoch: 6| Step: 3
Training loss: 0.9904758377170633
Validation loss: 2.6691564966540597

Epoch: 6| Step: 4
Training loss: 1.1741915376699068
Validation loss: 2.61291312764392

Epoch: 6| Step: 5
Training loss: 1.408558116933951
Validation loss: 2.605258244937913

Epoch: 6| Step: 6
Training loss: 1.1297331952446754
Validation loss: 2.6269102109596925

Epoch: 6| Step: 7
Training loss: 1.856463677537712
Validation loss: 2.6177178448100604

Epoch: 6| Step: 8
Training loss: 2.2165341124901
Validation loss: 2.676652485258445

Epoch: 6| Step: 9
Training loss: 1.4395949812701718
Validation loss: 2.70053649917419

Epoch: 6| Step: 10
Training loss: 1.1773907870368148
Validation loss: 2.709635309124342

Epoch: 6| Step: 11
Training loss: 0.9260000622174631
Validation loss: 2.72658880561738

Epoch: 6| Step: 12
Training loss: 1.6453855927579988
Validation loss: 2.7083814372167834

Epoch: 6| Step: 13
Training loss: 1.1543817634157199
Validation loss: 2.71550407886708

Epoch: 391| Step: 0
Training loss: 1.6974808849443892
Validation loss: 2.7112839007511575

Epoch: 6| Step: 1
Training loss: 1.3510614249089319
Validation loss: 2.691710995130978

Epoch: 6| Step: 2
Training loss: 1.2514477452164205
Validation loss: 2.7090342323869336

Epoch: 6| Step: 3
Training loss: 1.8718681246164752
Validation loss: 2.6738486631694625

Epoch: 6| Step: 4
Training loss: 1.7176723916770027
Validation loss: 2.6490174655312133

Epoch: 6| Step: 5
Training loss: 1.4498020036937977
Validation loss: 2.6859756404882726

Epoch: 6| Step: 6
Training loss: 0.9566795169873316
Validation loss: 2.676351533805158

Epoch: 6| Step: 7
Training loss: 0.8660261608647772
Validation loss: 2.6390632510442966

Epoch: 6| Step: 8
Training loss: 1.1602082417458892
Validation loss: 2.7197713431615993

Epoch: 6| Step: 9
Training loss: 0.9524258097092579
Validation loss: 2.700318410135806

Epoch: 6| Step: 10
Training loss: 1.1441576351152907
Validation loss: 2.6514733543239273

Epoch: 6| Step: 11
Training loss: 1.1911856024869272
Validation loss: 2.6367207543636284

Epoch: 6| Step: 12
Training loss: 1.2884317878043239
Validation loss: 2.6888233002325106

Epoch: 6| Step: 13
Training loss: 1.6111634326346087
Validation loss: 2.7193817413183394

Epoch: 392| Step: 0
Training loss: 1.167624075053365
Validation loss: 2.679135917340777

Epoch: 6| Step: 1
Training loss: 1.2782293393699677
Validation loss: 2.642305941401929

Epoch: 6| Step: 2
Training loss: 1.0191496503963262
Validation loss: 2.614622067674957

Epoch: 6| Step: 3
Training loss: 1.7916837587945926
Validation loss: 2.6076578364478955

Epoch: 6| Step: 4
Training loss: 1.7756938276744427
Validation loss: 2.6255575375121887

Epoch: 6| Step: 5
Training loss: 1.1767169359634106
Validation loss: 2.674300017233232

Epoch: 6| Step: 6
Training loss: 0.9674562305830815
Validation loss: 2.6812348194181634

Epoch: 6| Step: 7
Training loss: 0.9647601319191499
Validation loss: 2.712015221750908

Epoch: 6| Step: 8
Training loss: 1.8407225241350622
Validation loss: 2.689180174223181

Epoch: 6| Step: 9
Training loss: 1.0632700653945408
Validation loss: 2.6585233422140004

Epoch: 6| Step: 10
Training loss: 1.1788323947430481
Validation loss: 2.7061097676253745

Epoch: 6| Step: 11
Training loss: 1.2400262132304285
Validation loss: 2.679138601896702

Epoch: 6| Step: 12
Training loss: 1.6283107190366009
Validation loss: 2.6170269741344026

Epoch: 6| Step: 13
Training loss: 1.5086428870837163
Validation loss: 2.667404554519184

Epoch: 393| Step: 0
Training loss: 1.0542485771974692
Validation loss: 2.625768382525088

Epoch: 6| Step: 1
Training loss: 0.9638289083592213
Validation loss: 2.643621967362815

Epoch: 6| Step: 2
Training loss: 1.9899710498793468
Validation loss: 2.668149421647444

Epoch: 6| Step: 3
Training loss: 1.5308943354884634
Validation loss: 2.635420204934219

Epoch: 6| Step: 4
Training loss: 1.1188068524625085
Validation loss: 2.722086747900795

Epoch: 6| Step: 5
Training loss: 0.8391497916450872
Validation loss: 2.7769674555037187

Epoch: 6| Step: 6
Training loss: 1.6773041605441632
Validation loss: 2.7805967742523117

Epoch: 6| Step: 7
Training loss: 1.3299427831862063
Validation loss: 2.8012926529498676

Epoch: 6| Step: 8
Training loss: 1.536309039950068
Validation loss: 2.799022823073965

Epoch: 6| Step: 9
Training loss: 1.2794964583699329
Validation loss: 2.8097655531573293

Epoch: 6| Step: 10
Training loss: 1.958288584529321
Validation loss: 2.7765216281267624

Epoch: 6| Step: 11
Training loss: 1.3992365679945604
Validation loss: 2.748827091701296

Epoch: 6| Step: 12
Training loss: 0.8205040117778254
Validation loss: 2.672541247133713

Epoch: 6| Step: 13
Training loss: 1.3754778811840584
Validation loss: 2.7355612515900587

Epoch: 394| Step: 0
Training loss: 1.2107749583767222
Validation loss: 2.6704591565365954

Epoch: 6| Step: 1
Training loss: 2.383578618194451
Validation loss: 2.7065933996378426

Epoch: 6| Step: 2
Training loss: 1.277104579920969
Validation loss: 2.7241170531810046

Epoch: 6| Step: 3
Training loss: 1.488921020447359
Validation loss: 2.753329125933015

Epoch: 6| Step: 4
Training loss: 1.3718523062738504
Validation loss: 2.8560721633495776

Epoch: 6| Step: 5
Training loss: 1.574653887184628
Validation loss: 2.905130984449632

Epoch: 6| Step: 6
Training loss: 1.2255836517191085
Validation loss: 2.8874251929827395

Epoch: 6| Step: 7
Training loss: 1.4144361645077543
Validation loss: 2.842384261943044

Epoch: 6| Step: 8
Training loss: 1.0704787744718942
Validation loss: 2.7646930367139935

Epoch: 6| Step: 9
Training loss: 1.4097631862975495
Validation loss: 2.6473243121844656

Epoch: 6| Step: 10
Training loss: 1.977554735663199
Validation loss: 2.6070822657706465

Epoch: 6| Step: 11
Training loss: 1.5358923780268927
Validation loss: 2.6063483648849375

Epoch: 6| Step: 12
Training loss: 1.5877533087295752
Validation loss: 2.628193003243014

Epoch: 6| Step: 13
Training loss: 1.1845838981534935
Validation loss: 2.595256995752654

Epoch: 395| Step: 0
Training loss: 1.4454287920381215
Validation loss: 2.6402053650057433

Epoch: 6| Step: 1
Training loss: 1.610850722364941
Validation loss: 2.5950113622849083

Epoch: 6| Step: 2
Training loss: 1.4928928325999478
Validation loss: 2.6500146721487714

Epoch: 6| Step: 3
Training loss: 2.0459823409108027
Validation loss: 2.6482552284677188

Epoch: 6| Step: 4
Training loss: 2.1327765046041063
Validation loss: 2.783976258091704

Epoch: 6| Step: 5
Training loss: 1.2768428648696768
Validation loss: 2.861233765453424

Epoch: 6| Step: 6
Training loss: 1.7704448573034053
Validation loss: 2.884878133561221

Epoch: 6| Step: 7
Training loss: 1.478686545809096
Validation loss: 2.932077516332547

Epoch: 6| Step: 8
Training loss: 1.3072149955890933
Validation loss: 2.794279062354398

Epoch: 6| Step: 9
Training loss: 1.2630980425434952
Validation loss: 2.70491333240335

Epoch: 6| Step: 10
Training loss: 1.118450171501982
Validation loss: 2.690387785966621

Epoch: 6| Step: 11
Training loss: 0.8024499765295691
Validation loss: 2.663385597960701

Epoch: 6| Step: 12
Training loss: 0.9472537954319344
Validation loss: 2.6887152238290803

Epoch: 6| Step: 13
Training loss: 1.6681088248047853
Validation loss: 2.6672224766933907

Epoch: 396| Step: 0
Training loss: 1.412400718170541
Validation loss: 2.697485566523382

Epoch: 6| Step: 1
Training loss: 1.298022027227005
Validation loss: 2.6658969876042384

Epoch: 6| Step: 2
Training loss: 1.210080932874006
Validation loss: 2.6506788284027873

Epoch: 6| Step: 3
Training loss: 1.6916137286141708
Validation loss: 2.6737612633975427

Epoch: 6| Step: 4
Training loss: 1.192601539239525
Validation loss: 2.702650407057514

Epoch: 6| Step: 5
Training loss: 1.240875366853391
Validation loss: 2.7031933990821275

Epoch: 6| Step: 6
Training loss: 0.8909478522602109
Validation loss: 2.8015179589598187

Epoch: 6| Step: 7
Training loss: 1.3115299818340074
Validation loss: 2.869111319111593

Epoch: 6| Step: 8
Training loss: 1.8626765583506582
Validation loss: 2.8764229031433577

Epoch: 6| Step: 9
Training loss: 1.3205631176251424
Validation loss: 2.842943908689103

Epoch: 6| Step: 10
Training loss: 1.0394281303327981
Validation loss: 2.75970870002267

Epoch: 6| Step: 11
Training loss: 0.8425634659653449
Validation loss: 2.6845816136382834

Epoch: 6| Step: 12
Training loss: 1.8987376285875717
Validation loss: 2.7040602989809424

Epoch: 6| Step: 13
Training loss: 1.9755257763755931
Validation loss: 2.6619663885819107

Epoch: 397| Step: 0
Training loss: 1.0954901340341565
Validation loss: 2.639357238054562

Epoch: 6| Step: 1
Training loss: 2.1482338548726365
Validation loss: 2.649337660590933

Epoch: 6| Step: 2
Training loss: 1.2836882488549988
Validation loss: 2.7080774822185005

Epoch: 6| Step: 3
Training loss: 1.44924120615709
Validation loss: 2.6857378897504125

Epoch: 6| Step: 4
Training loss: 1.2747106915772592
Validation loss: 2.664003701553981

Epoch: 6| Step: 5
Training loss: 1.1971233339372784
Validation loss: 2.6323007374888863

Epoch: 6| Step: 6
Training loss: 0.6453655507446785
Validation loss: 2.679346832181905

Epoch: 6| Step: 7
Training loss: 1.1206287123985093
Validation loss: 2.74276617162801

Epoch: 6| Step: 8
Training loss: 1.5819622260212491
Validation loss: 2.736016164273667

Epoch: 6| Step: 9
Training loss: 1.2613832009850032
Validation loss: 2.743502454662621

Epoch: 6| Step: 10
Training loss: 1.481031326055369
Validation loss: 2.6928195057294144

Epoch: 6| Step: 11
Training loss: 1.717215182191461
Validation loss: 2.694358207091654

Epoch: 6| Step: 12
Training loss: 1.6216659087714802
Validation loss: 2.7347350255914997

Epoch: 6| Step: 13
Training loss: 0.9421674887586492
Validation loss: 2.719116624688696

Epoch: 398| Step: 0
Training loss: 1.407472714689857
Validation loss: 2.690681503889985

Epoch: 6| Step: 1
Training loss: 1.0703182916414926
Validation loss: 2.6855213954757207

Epoch: 6| Step: 2
Training loss: 1.1557745084711648
Validation loss: 2.6631189131411674

Epoch: 6| Step: 3
Training loss: 0.9438065758224856
Validation loss: 2.719545503772764

Epoch: 6| Step: 4
Training loss: 2.032213070782041
Validation loss: 2.708644413811193

Epoch: 6| Step: 5
Training loss: 1.8915313565879162
Validation loss: 2.7091789441596634

Epoch: 6| Step: 6
Training loss: 1.1140173904253219
Validation loss: 2.7628263116807803

Epoch: 6| Step: 7
Training loss: 1.8000780830401508
Validation loss: 2.7160035946774936

Epoch: 6| Step: 8
Training loss: 1.1872676822890273
Validation loss: 2.7271118047950766

Epoch: 6| Step: 9
Training loss: 0.8881233282966102
Validation loss: 2.750394207703259

Epoch: 6| Step: 10
Training loss: 1.6206935158695464
Validation loss: 2.7499142980225977

Epoch: 6| Step: 11
Training loss: 0.9941194003674255
Validation loss: 2.683212393844959

Epoch: 6| Step: 12
Training loss: 1.2940916043481372
Validation loss: 2.6827868007702067

Epoch: 6| Step: 13
Training loss: 1.303535272429049
Validation loss: 2.6690900390928873

Epoch: 399| Step: 0
Training loss: 0.8540647647519168
Validation loss: 2.6849689689514813

Epoch: 6| Step: 1
Training loss: 0.7911419802871779
Validation loss: 2.6688409276119027

Epoch: 6| Step: 2
Training loss: 1.4054919848978582
Validation loss: 2.6972518136059658

Epoch: 6| Step: 3
Training loss: 2.46080670690379
Validation loss: 2.7471072414504794

Epoch: 6| Step: 4
Training loss: 1.5501638571974825
Validation loss: 2.7177033145186105

Epoch: 6| Step: 5
Training loss: 1.0203000966087834
Validation loss: 2.7744826089388774

Epoch: 6| Step: 6
Training loss: 0.8172334194957799
Validation loss: 2.812612192247428

Epoch: 6| Step: 7
Training loss: 1.3373969956423737
Validation loss: 2.831763791137568

Epoch: 6| Step: 8
Training loss: 1.2904790320069368
Validation loss: 2.8076268257307393

Epoch: 6| Step: 9
Training loss: 1.1262396763911637
Validation loss: 2.7981369041704864

Epoch: 6| Step: 10
Training loss: 1.3185338787866077
Validation loss: 2.7625888459200674

Epoch: 6| Step: 11
Training loss: 0.9343205579634388
Validation loss: 2.727927207986619

Epoch: 6| Step: 12
Training loss: 1.9517424305783344
Validation loss: 2.6758890320540702

Epoch: 6| Step: 13
Training loss: 0.8729189580615673
Validation loss: 2.6883053718747734

Epoch: 400| Step: 0
Training loss: 1.9216921959753044
Validation loss: 2.6501993416239147

Epoch: 6| Step: 1
Training loss: 1.1258953558164921
Validation loss: 2.6889547210792837

Epoch: 6| Step: 2
Training loss: 1.882197046003941
Validation loss: 2.6527295438321508

Epoch: 6| Step: 3
Training loss: 1.5946503134519439
Validation loss: 2.6844904704899073

Epoch: 6| Step: 4
Training loss: 0.9291101474136794
Validation loss: 2.617938413171963

Epoch: 6| Step: 5
Training loss: 1.2596547159269216
Validation loss: 2.6398296776169072

Epoch: 6| Step: 6
Training loss: 0.956939381452386
Validation loss: 2.660273642244055

Epoch: 6| Step: 7
Training loss: 1.5969650153602062
Validation loss: 2.661562734050501

Epoch: 6| Step: 8
Training loss: 1.1451308206510857
Validation loss: 2.6579151095632785

Epoch: 6| Step: 9
Training loss: 0.8063434487531396
Validation loss: 2.6832211238982873

Epoch: 6| Step: 10
Training loss: 1.0342589898183239
Validation loss: 2.6943783970457975

Epoch: 6| Step: 11
Training loss: 1.1940358643504911
Validation loss: 2.6725609030949222

Epoch: 6| Step: 12
Training loss: 1.6292149825220403
Validation loss: 2.6949217434752364

Epoch: 6| Step: 13
Training loss: 1.1106606676409831
Validation loss: 2.66531788471847

Epoch: 401| Step: 0
Training loss: 1.0417796010150442
Validation loss: 2.669552840555905

Epoch: 6| Step: 1
Training loss: 1.1258730679513764
Validation loss: 2.6708624633374862

Epoch: 6| Step: 2
Training loss: 1.2666416558925175
Validation loss: 2.7051567718053517

Epoch: 6| Step: 3
Training loss: 0.8745151266247809
Validation loss: 2.689752832139814

Epoch: 6| Step: 4
Training loss: 1.165613204037294
Validation loss: 2.635488627259249

Epoch: 6| Step: 5
Training loss: 0.8064485926340829
Validation loss: 2.723362630813371

Epoch: 6| Step: 6
Training loss: 1.0418619290763667
Validation loss: 2.6924423637348864

Epoch: 6| Step: 7
Training loss: 1.9498785885892094
Validation loss: 2.7143429227885463

Epoch: 6| Step: 8
Training loss: 1.5971241556920577
Validation loss: 2.70156324249428

Epoch: 6| Step: 9
Training loss: 1.385610433045086
Validation loss: 2.711575215991166

Epoch: 6| Step: 10
Training loss: 1.0770168414273473
Validation loss: 2.7065902284655947

Epoch: 6| Step: 11
Training loss: 1.782293984169924
Validation loss: 2.712028108148721

Epoch: 6| Step: 12
Training loss: 0.6383780640632591
Validation loss: 2.6890015805969094

Epoch: 6| Step: 13
Training loss: 2.0272744815584005
Validation loss: 2.7307285954685017

Epoch: 402| Step: 0
Training loss: 0.850569469761118
Validation loss: 2.671700098213668

Epoch: 6| Step: 1
Training loss: 1.581256139690557
Validation loss: 2.6882594536264732

Epoch: 6| Step: 2
Training loss: 1.3399241342704
Validation loss: 2.713516122962574

Epoch: 6| Step: 3
Training loss: 0.9775235139599167
Validation loss: 2.6563148789803743

Epoch: 6| Step: 4
Training loss: 0.6866407443411161
Validation loss: 2.7396433331744854

Epoch: 6| Step: 5
Training loss: 1.1079736374497227
Validation loss: 2.731368448291807

Epoch: 6| Step: 6
Training loss: 1.846438242330151
Validation loss: 2.671721336898475

Epoch: 6| Step: 7
Training loss: 1.8184497126542687
Validation loss: 2.6724535072262583

Epoch: 6| Step: 8
Training loss: 1.088902986904493
Validation loss: 2.737650908922213

Epoch: 6| Step: 9
Training loss: 0.989253504481072
Validation loss: 2.7285473729996492

Epoch: 6| Step: 10
Training loss: 1.482006793908777
Validation loss: 2.6810339982199793

Epoch: 6| Step: 11
Training loss: 1.3622793106395374
Validation loss: 2.7498773056171584

Epoch: 6| Step: 12
Training loss: 0.8512903180986359
Validation loss: 2.7130537613405736

Epoch: 6| Step: 13
Training loss: 1.700098971683498
Validation loss: 2.7472428747810187

Epoch: 403| Step: 0
Training loss: 1.1568673521971
Validation loss: 2.782142610221706

Epoch: 6| Step: 1
Training loss: 1.155479741640666
Validation loss: 2.7077268557203493

Epoch: 6| Step: 2
Training loss: 1.0973113254524103
Validation loss: 2.7269884594723344

Epoch: 6| Step: 3
Training loss: 1.1573968303338407
Validation loss: 2.6612920740282764

Epoch: 6| Step: 4
Training loss: 1.1017948744230346
Validation loss: 2.691380870239892

Epoch: 6| Step: 5
Training loss: 0.8024871519729934
Validation loss: 2.6799080983104653

Epoch: 6| Step: 6
Training loss: 1.1964380786493614
Validation loss: 2.6625031860762323

Epoch: 6| Step: 7
Training loss: 2.3755680208064494
Validation loss: 2.66378206956648

Epoch: 6| Step: 8
Training loss: 0.9243551932296263
Validation loss: 2.6655460079126896

Epoch: 6| Step: 9
Training loss: 1.6428270366824482
Validation loss: 2.690912726506832

Epoch: 6| Step: 10
Training loss: 1.027166779218902
Validation loss: 2.700555112664711

Epoch: 6| Step: 11
Training loss: 1.2236330073448567
Validation loss: 2.6022957960688538

Epoch: 6| Step: 12
Training loss: 1.7409719837000721
Validation loss: 2.7102515738950994

Epoch: 6| Step: 13
Training loss: 1.1687356223787695
Validation loss: 2.716862363046585

Epoch: 404| Step: 0
Training loss: 1.1508459669925606
Validation loss: 2.7171435232115337

Epoch: 6| Step: 1
Training loss: 1.0613765386800067
Validation loss: 2.7856209801032996

Epoch: 6| Step: 2
Training loss: 0.8438622082167511
Validation loss: 2.731757882484209

Epoch: 6| Step: 3
Training loss: 1.0614005739758572
Validation loss: 2.727076936446678

Epoch: 6| Step: 4
Training loss: 1.1738728595657666
Validation loss: 2.694482470983619

Epoch: 6| Step: 5
Training loss: 1.3543017197778933
Validation loss: 2.644827138255475

Epoch: 6| Step: 6
Training loss: 1.0195656255429655
Validation loss: 2.6549179477069718

Epoch: 6| Step: 7
Training loss: 1.2642454941442787
Validation loss: 2.6280982942619113

Epoch: 6| Step: 8
Training loss: 1.5383864723745493
Validation loss: 2.707483397902864

Epoch: 6| Step: 9
Training loss: 1.4055691236327776
Validation loss: 2.70409314232449

Epoch: 6| Step: 10
Training loss: 0.9538953513382792
Validation loss: 2.7301484276172574

Epoch: 6| Step: 11
Training loss: 1.8939658668286274
Validation loss: 2.704640399207606

Epoch: 6| Step: 12
Training loss: 2.1542672149193485
Validation loss: 2.693608608798274

Epoch: 6| Step: 13
Training loss: 1.1636618110193377
Validation loss: 2.7347806865740716

Epoch: 405| Step: 0
Training loss: 1.3376172308482748
Validation loss: 2.7292824397877604

Epoch: 6| Step: 1
Training loss: 0.9323444387037964
Validation loss: 2.706688870736673

Epoch: 6| Step: 2
Training loss: 1.8647576007353133
Validation loss: 2.6918971587976173

Epoch: 6| Step: 3
Training loss: 1.0850559745800221
Validation loss: 2.668224436030804

Epoch: 6| Step: 4
Training loss: 1.167848204448953
Validation loss: 2.658264742437715

Epoch: 6| Step: 5
Training loss: 1.8660224887273678
Validation loss: 2.691707629274953

Epoch: 6| Step: 6
Training loss: 1.3864309522684568
Validation loss: 2.6693271736463933

Epoch: 6| Step: 7
Training loss: 0.7753318552955432
Validation loss: 2.664383675912131

Epoch: 6| Step: 8
Training loss: 1.4749797431718628
Validation loss: 2.6586564924915255

Epoch: 6| Step: 9
Training loss: 0.802991542785878
Validation loss: 2.7519417034459948

Epoch: 6| Step: 10
Training loss: 0.8411281965707762
Validation loss: 2.74514111508771

Epoch: 6| Step: 11
Training loss: 1.5873064418748764
Validation loss: 2.6956763127943977

Epoch: 6| Step: 12
Training loss: 1.0973529871883572
Validation loss: 2.7100357915947626

Epoch: 6| Step: 13
Training loss: 1.588450653303894
Validation loss: 2.666736487626911

Epoch: 406| Step: 0
Training loss: 0.951945340919524
Validation loss: 2.670090077293995

Epoch: 6| Step: 1
Training loss: 0.94595447526312
Validation loss: 2.6612186411044316

Epoch: 6| Step: 2
Training loss: 1.0096977993231178
Validation loss: 2.6464038719329777

Epoch: 6| Step: 3
Training loss: 0.9912948497713469
Validation loss: 2.7026357924710473

Epoch: 6| Step: 4
Training loss: 1.2103578226008536
Validation loss: 2.63914079356141

Epoch: 6| Step: 5
Training loss: 1.7030498243066892
Validation loss: 2.675979480686596

Epoch: 6| Step: 6
Training loss: 1.0300622515708486
Validation loss: 2.697142476431752

Epoch: 6| Step: 7
Training loss: 1.9520038285921415
Validation loss: 2.6923141092531355

Epoch: 6| Step: 8
Training loss: 1.8251910018257684
Validation loss: 2.653690076963929

Epoch: 6| Step: 9
Training loss: 1.0711790043953426
Validation loss: 2.6464802083901127

Epoch: 6| Step: 10
Training loss: 0.9987695097181497
Validation loss: 2.5990162054943444

Epoch: 6| Step: 11
Training loss: 1.3533994946883183
Validation loss: 2.6971305870451703

Epoch: 6| Step: 12
Training loss: 1.0427032589987426
Validation loss: 2.7024113883642618

Epoch: 6| Step: 13
Training loss: 1.5756529529336016
Validation loss: 2.7287953587675147

Epoch: 407| Step: 0
Training loss: 1.529032054592564
Validation loss: 2.7737763676902194

Epoch: 6| Step: 1
Training loss: 1.6470771708889063
Validation loss: 2.783263517025705

Epoch: 6| Step: 2
Training loss: 1.0787433564831324
Validation loss: 2.753735880169806

Epoch: 6| Step: 3
Training loss: 1.168848529273214
Validation loss: 2.7059839230915297

Epoch: 6| Step: 4
Training loss: 1.1681863843567502
Validation loss: 2.680283230919771

Epoch: 6| Step: 5
Training loss: 0.9836291560556556
Validation loss: 2.702346410324524

Epoch: 6| Step: 6
Training loss: 1.1463166460237109
Validation loss: 2.7256686285676723

Epoch: 6| Step: 7
Training loss: 2.2312092796050647
Validation loss: 2.7264643508457245

Epoch: 6| Step: 8
Training loss: 1.3936575923102066
Validation loss: 2.6877140950526885

Epoch: 6| Step: 9
Training loss: 1.2458195878018001
Validation loss: 2.7210922236825725

Epoch: 6| Step: 10
Training loss: 0.8691575638052687
Validation loss: 2.738029682468518

Epoch: 6| Step: 11
Training loss: 1.085733188647442
Validation loss: 2.705574954022321

Epoch: 6| Step: 12
Training loss: 1.309351641826727
Validation loss: 2.7429879262020833

Epoch: 6| Step: 13
Training loss: 1.260235129700181
Validation loss: 2.7576757150359636

Epoch: 408| Step: 0
Training loss: 0.9594062452167491
Validation loss: 2.7723385778364293

Epoch: 6| Step: 1
Training loss: 0.9242325718056571
Validation loss: 2.736960636345987

Epoch: 6| Step: 2
Training loss: 1.1966178597899013
Validation loss: 2.6877462289073075

Epoch: 6| Step: 3
Training loss: 0.9278047233813259
Validation loss: 2.7090808765959924

Epoch: 6| Step: 4
Training loss: 0.966878960717836
Validation loss: 2.6978484602938657

Epoch: 6| Step: 5
Training loss: 1.1858069748852051
Validation loss: 2.668260088345592

Epoch: 6| Step: 6
Training loss: 1.7546371602202773
Validation loss: 2.642599251891288

Epoch: 6| Step: 7
Training loss: 1.8042200317008255
Validation loss: 2.6666233138693003

Epoch: 6| Step: 8
Training loss: 1.8483683401472675
Validation loss: 2.671161199333429

Epoch: 6| Step: 9
Training loss: 1.3639574095629319
Validation loss: 2.696895219440479

Epoch: 6| Step: 10
Training loss: 1.8831650020124864
Validation loss: 2.732364882083165

Epoch: 6| Step: 11
Training loss: 0.9673557092084186
Validation loss: 2.7631863548371522

Epoch: 6| Step: 12
Training loss: 0.9107194394144791
Validation loss: 2.7299288396445633

Epoch: 6| Step: 13
Training loss: 1.002857298499729
Validation loss: 2.6632045882152187

Epoch: 409| Step: 0
Training loss: 1.0901633720280126
Validation loss: 2.7385483202025758

Epoch: 6| Step: 1
Training loss: 1.1260467004560561
Validation loss: 2.6749652964280908

Epoch: 6| Step: 2
Training loss: 1.815150657580176
Validation loss: 2.6643181283864465

Epoch: 6| Step: 3
Training loss: 0.7453174646879981
Validation loss: 2.7032825519607213

Epoch: 6| Step: 4
Training loss: 1.2245385059737013
Validation loss: 2.678619498169707

Epoch: 6| Step: 5
Training loss: 0.9434491227385807
Validation loss: 2.719930808926337

Epoch: 6| Step: 6
Training loss: 1.6675182868835545
Validation loss: 2.6645316030706803

Epoch: 6| Step: 7
Training loss: 1.75526854490093
Validation loss: 2.691525224585302

Epoch: 6| Step: 8
Training loss: 1.0345833974698175
Validation loss: 2.7280769113771774

Epoch: 6| Step: 9
Training loss: 1.2772964328786243
Validation loss: 2.751157387020035

Epoch: 6| Step: 10
Training loss: 1.5831533714550332
Validation loss: 2.7607099893062172

Epoch: 6| Step: 11
Training loss: 1.115412656092615
Validation loss: 2.6754261978598293

Epoch: 6| Step: 12
Training loss: 1.0313107443750007
Validation loss: 2.7685609740063106

Epoch: 6| Step: 13
Training loss: 1.2498110628390195
Validation loss: 2.7703044405707185

Epoch: 410| Step: 0
Training loss: 1.969938736752084
Validation loss: 2.762801904421074

Epoch: 6| Step: 1
Training loss: 1.3806620110126753
Validation loss: 2.701472782596384

Epoch: 6| Step: 2
Training loss: 1.238362739841914
Validation loss: 2.7565430627378396

Epoch: 6| Step: 3
Training loss: 0.7498592403566189
Validation loss: 2.693316825620969

Epoch: 6| Step: 4
Training loss: 1.0103347325614755
Validation loss: 2.719487890321422

Epoch: 6| Step: 5
Training loss: 1.0899921165846171
Validation loss: 2.72671668665116

Epoch: 6| Step: 6
Training loss: 1.1052160614539257
Validation loss: 2.731508463626313

Epoch: 6| Step: 7
Training loss: 0.8238620076417519
Validation loss: 2.722209118359572

Epoch: 6| Step: 8
Training loss: 1.543585390897935
Validation loss: 2.7383172744362128

Epoch: 6| Step: 9
Training loss: 1.7861368169890868
Validation loss: 2.6842909364930603

Epoch: 6| Step: 10
Training loss: 1.6735759887949504
Validation loss: 2.675435510281968

Epoch: 6| Step: 11
Training loss: 1.3627281925301955
Validation loss: 2.6919979484072267

Epoch: 6| Step: 12
Training loss: 0.8414497810515357
Validation loss: 2.703337247597165

Epoch: 6| Step: 13
Training loss: 1.0335851875117745
Validation loss: 2.695787942573991

Epoch: 411| Step: 0
Training loss: 1.047944618494411
Validation loss: 2.671000272400696

Epoch: 6| Step: 1
Training loss: 1.0660953278063745
Validation loss: 2.6501216203743505

Epoch: 6| Step: 2
Training loss: 1.0717918586182573
Validation loss: 2.642373576380607

Epoch: 6| Step: 3
Training loss: 0.9554279209499466
Validation loss: 2.697155986365036

Epoch: 6| Step: 4
Training loss: 2.165592685474885
Validation loss: 2.7128111038289373

Epoch: 6| Step: 5
Training loss: 0.935658235233571
Validation loss: 2.6441415248829307

Epoch: 6| Step: 6
Training loss: 0.8157412362126256
Validation loss: 2.6697931786536735

Epoch: 6| Step: 7
Training loss: 0.9937864620789034
Validation loss: 2.6987044216569522

Epoch: 6| Step: 8
Training loss: 1.0117628168944273
Validation loss: 2.6604367041573833

Epoch: 6| Step: 9
Training loss: 1.7649413279002155
Validation loss: 2.63006419677612

Epoch: 6| Step: 10
Training loss: 1.0192325783036653
Validation loss: 2.6719343688198864

Epoch: 6| Step: 11
Training loss: 1.838105046314111
Validation loss: 2.628068477765189

Epoch: 6| Step: 12
Training loss: 1.1737668851342746
Validation loss: 2.7276598335331874

Epoch: 6| Step: 13
Training loss: 1.181437022425556
Validation loss: 2.709604410082398

Epoch: 412| Step: 0
Training loss: 1.0376949632681043
Validation loss: 2.7153413970553424

Epoch: 6| Step: 1
Training loss: 1.1923761141102291
Validation loss: 2.7573124879849042

Epoch: 6| Step: 2
Training loss: 1.1669272177259928
Validation loss: 2.722796428762438

Epoch: 6| Step: 3
Training loss: 1.4422416437138073
Validation loss: 2.7446056691414253

Epoch: 6| Step: 4
Training loss: 0.8381451840285148
Validation loss: 2.708868961676444

Epoch: 6| Step: 5
Training loss: 0.9056732381290468
Validation loss: 2.7063835363648248

Epoch: 6| Step: 6
Training loss: 1.7254230312269025
Validation loss: 2.6958733311495844

Epoch: 6| Step: 7
Training loss: 0.7734192354762237
Validation loss: 2.7898278490801096

Epoch: 6| Step: 8
Training loss: 1.9717703765826156
Validation loss: 2.7608583972582705

Epoch: 6| Step: 9
Training loss: 1.0322197487136155
Validation loss: 2.8195941041793584

Epoch: 6| Step: 10
Training loss: 1.987746790792537
Validation loss: 2.8104434936540064

Epoch: 6| Step: 11
Training loss: 1.9052591093571636
Validation loss: 2.8040144315512383

Epoch: 6| Step: 12
Training loss: 1.3596440191556332
Validation loss: 2.757561121966718

Epoch: 6| Step: 13
Training loss: 0.8672513508702322
Validation loss: 2.6688629186060004

Epoch: 413| Step: 0
Training loss: 0.9428979602148795
Validation loss: 2.6188012002023044

Epoch: 6| Step: 1
Training loss: 1.8345747414909808
Validation loss: 2.607902202583359

Epoch: 6| Step: 2
Training loss: 1.0728970251168173
Validation loss: 2.607954998020096

Epoch: 6| Step: 3
Training loss: 1.2929912461458752
Validation loss: 2.6426857576068805

Epoch: 6| Step: 4
Training loss: 1.5779381065365976
Validation loss: 2.6583908579072313

Epoch: 6| Step: 5
Training loss: 1.1252644545943133
Validation loss: 2.641979269029638

Epoch: 6| Step: 6
Training loss: 2.157710810646972
Validation loss: 2.6003759387465286

Epoch: 6| Step: 7
Training loss: 1.256535325931719
Validation loss: 2.709605304649078

Epoch: 6| Step: 8
Training loss: 1.3851981408959608
Validation loss: 2.7441918274434265

Epoch: 6| Step: 9
Training loss: 1.3925412294869128
Validation loss: 2.7587748605368225

Epoch: 6| Step: 10
Training loss: 1.6462634606995024
Validation loss: 2.771033205744504

Epoch: 6| Step: 11
Training loss: 0.8288988060936077
Validation loss: 2.7234235910923874

Epoch: 6| Step: 12
Training loss: 1.1682301104481263
Validation loss: 2.6819820237672642

Epoch: 6| Step: 13
Training loss: 1.0522413355460865
Validation loss: 2.6725975383281804

Epoch: 414| Step: 0
Training loss: 0.9456846592269079
Validation loss: 2.667785206295003

Epoch: 6| Step: 1
Training loss: 1.2894874103637117
Validation loss: 2.6650236377896386

Epoch: 6| Step: 2
Training loss: 1.33741103437928
Validation loss: 2.6434856321693445

Epoch: 6| Step: 3
Training loss: 1.188500685435263
Validation loss: 2.675734381717727

Epoch: 6| Step: 4
Training loss: 1.1267309647520798
Validation loss: 2.744415001597582

Epoch: 6| Step: 5
Training loss: 1.7720056879197705
Validation loss: 2.7992231148421274

Epoch: 6| Step: 6
Training loss: 1.5813448700320512
Validation loss: 2.7417468145263917

Epoch: 6| Step: 7
Training loss: 1.2846797535151695
Validation loss: 2.7712010639133204

Epoch: 6| Step: 8
Training loss: 1.9348718599774173
Validation loss: 2.725941730358814

Epoch: 6| Step: 9
Training loss: 0.8352101807269774
Validation loss: 2.7132719397648284

Epoch: 6| Step: 10
Training loss: 1.2391305411707574
Validation loss: 2.7236065950496187

Epoch: 6| Step: 11
Training loss: 1.0345397264864753
Validation loss: 2.723786508503118

Epoch: 6| Step: 12
Training loss: 0.6950607058201188
Validation loss: 2.718800058305957

Epoch: 6| Step: 13
Training loss: 1.221212930653596
Validation loss: 2.7840469812196242

Epoch: 415| Step: 0
Training loss: 1.1816643326327827
Validation loss: 2.7491576320672806

Epoch: 6| Step: 1
Training loss: 1.6326676445913029
Validation loss: 2.7997329147430237

Epoch: 6| Step: 2
Training loss: 0.9161162819288148
Validation loss: 2.8093756240431023

Epoch: 6| Step: 3
Training loss: 1.2472048980332873
Validation loss: 2.829857367660657

Epoch: 6| Step: 4
Training loss: 1.3834861364576472
Validation loss: 2.7847482490327424

Epoch: 6| Step: 5
Training loss: 1.0629865990670544
Validation loss: 2.7103726754123665

Epoch: 6| Step: 6
Training loss: 1.312142096267908
Validation loss: 2.653804625806793

Epoch: 6| Step: 7
Training loss: 1.7628346226978928
Validation loss: 2.673743102433491

Epoch: 6| Step: 8
Training loss: 0.8367368494920321
Validation loss: 2.6471207457719275

Epoch: 6| Step: 9
Training loss: 1.9701126469196462
Validation loss: 2.6902561840275445

Epoch: 6| Step: 10
Training loss: 0.75893625527988
Validation loss: 2.7672919729145935

Epoch: 6| Step: 11
Training loss: 0.8484777521803248
Validation loss: 2.6927777151666525

Epoch: 6| Step: 12
Training loss: 1.4550955752152035
Validation loss: 2.7232411657967694

Epoch: 6| Step: 13
Training loss: 1.0612140053619683
Validation loss: 2.712218613100166

Epoch: 416| Step: 0
Training loss: 1.1435079850091932
Validation loss: 2.69444661629208

Epoch: 6| Step: 1
Training loss: 0.9196403704436354
Validation loss: 2.728229308346402

Epoch: 6| Step: 2
Training loss: 1.87069392063619
Validation loss: 2.7158618948051956

Epoch: 6| Step: 3
Training loss: 0.8622383273588016
Validation loss: 2.7418455397935704

Epoch: 6| Step: 4
Training loss: 1.4352826141229345
Validation loss: 2.712854446012434

Epoch: 6| Step: 5
Training loss: 0.8187959002958232
Validation loss: 2.793700293568847

Epoch: 6| Step: 6
Training loss: 1.0007052318995455
Validation loss: 2.7223750242395615

Epoch: 6| Step: 7
Training loss: 1.0320523348667894
Validation loss: 2.7552257938709106

Epoch: 6| Step: 8
Training loss: 0.9589224055326158
Validation loss: 2.7134862639079107

Epoch: 6| Step: 9
Training loss: 1.6466234539838167
Validation loss: 2.675186388111753

Epoch: 6| Step: 10
Training loss: 0.9826787533141838
Validation loss: 2.6523732037189323

Epoch: 6| Step: 11
Training loss: 1.9243402564296859
Validation loss: 2.605871578342945

Epoch: 6| Step: 12
Training loss: 0.9743102078920747
Validation loss: 2.6563083268287913

Epoch: 6| Step: 13
Training loss: 1.2153306580195133
Validation loss: 2.5986805055741398

Epoch: 417| Step: 0
Training loss: 1.6415023637580874
Validation loss: 2.601465584264272

Epoch: 6| Step: 1
Training loss: 1.2907450474657547
Validation loss: 2.6734632266761493

Epoch: 6| Step: 2
Training loss: 1.5036298225307103
Validation loss: 2.7170808279439997

Epoch: 6| Step: 3
Training loss: 1.1882283336286126
Validation loss: 2.6858407450483055

Epoch: 6| Step: 4
Training loss: 0.7799399263527783
Validation loss: 2.72098452355861

Epoch: 6| Step: 5
Training loss: 1.6098661691710903
Validation loss: 2.692586461942572

Epoch: 6| Step: 6
Training loss: 1.1444064648405299
Validation loss: 2.601692761586234

Epoch: 6| Step: 7
Training loss: 1.0153268229659267
Validation loss: 2.629723273139925

Epoch: 6| Step: 8
Training loss: 1.9027867359529052
Validation loss: 2.6256588154526446

Epoch: 6| Step: 9
Training loss: 1.122982759718727
Validation loss: 2.6323443410655414

Epoch: 6| Step: 10
Training loss: 0.9844698784532344
Validation loss: 2.623893481870748

Epoch: 6| Step: 11
Training loss: 0.9762347472460975
Validation loss: 2.6581879147503886

Epoch: 6| Step: 12
Training loss: 0.8388690348950117
Validation loss: 2.6842389541156635

Epoch: 6| Step: 13
Training loss: 1.0828988903641994
Validation loss: 2.707161772252449

Epoch: 418| Step: 0
Training loss: 1.2380171533299071
Validation loss: 2.7239146669776706

Epoch: 6| Step: 1
Training loss: 0.8084172963912405
Validation loss: 2.7125294360015384

Epoch: 6| Step: 2
Training loss: 1.2912798681802211
Validation loss: 2.7404648168911057

Epoch: 6| Step: 3
Training loss: 2.0306939170839096
Validation loss: 2.7186794783408996

Epoch: 6| Step: 4
Training loss: 0.7116057640194975
Validation loss: 2.696859474181641

Epoch: 6| Step: 5
Training loss: 1.4398636665974496
Validation loss: 2.670652649035005

Epoch: 6| Step: 6
Training loss: 1.451865029401367
Validation loss: 2.665216339615364

Epoch: 6| Step: 7
Training loss: 1.243604224015084
Validation loss: 2.6738941824429747

Epoch: 6| Step: 8
Training loss: 0.9484510731864914
Validation loss: 2.6461669881705596

Epoch: 6| Step: 9
Training loss: 1.1477920898483989
Validation loss: 2.6404848832796466

Epoch: 6| Step: 10
Training loss: 1.1543195951391312
Validation loss: 2.6729620493849113

Epoch: 6| Step: 11
Training loss: 1.3666938108369249
Validation loss: 2.7162002504383143

Epoch: 6| Step: 12
Training loss: 0.8662898254597585
Validation loss: 2.7003743724535325

Epoch: 6| Step: 13
Training loss: 1.1031018046677203
Validation loss: 2.6983360396621574

Epoch: 419| Step: 0
Training loss: 0.9135086468275352
Validation loss: 2.8078643743088696

Epoch: 6| Step: 1
Training loss: 1.1030992110482554
Validation loss: 2.800669761435653

Epoch: 6| Step: 2
Training loss: 1.2076178548096268
Validation loss: 2.8116206454535857

Epoch: 6| Step: 3
Training loss: 0.9154602188934284
Validation loss: 2.733910134173144

Epoch: 6| Step: 4
Training loss: 0.9662030486707652
Validation loss: 2.7367656756374616

Epoch: 6| Step: 5
Training loss: 1.0680550485275468
Validation loss: 2.7080767558901164

Epoch: 6| Step: 6
Training loss: 1.2020180303773205
Validation loss: 2.7626232229054786

Epoch: 6| Step: 7
Training loss: 1.9583228564151227
Validation loss: 2.6701547985708034

Epoch: 6| Step: 8
Training loss: 1.4260434262376531
Validation loss: 2.7216732781075486

Epoch: 6| Step: 9
Training loss: 1.0989318711889986
Validation loss: 2.6898735565475236

Epoch: 6| Step: 10
Training loss: 0.9700662530807153
Validation loss: 2.7122391975293896

Epoch: 6| Step: 11
Training loss: 1.1008038444718051
Validation loss: 2.733302605464001

Epoch: 6| Step: 12
Training loss: 0.7483171418002308
Validation loss: 2.7461301566939738

Epoch: 6| Step: 13
Training loss: 2.114716499031692
Validation loss: 2.7944967860541636

Epoch: 420| Step: 0
Training loss: 1.149139345539088
Validation loss: 2.8237701946210194

Epoch: 6| Step: 1
Training loss: 1.2251242691378812
Validation loss: 2.837759142230063

Epoch: 6| Step: 2
Training loss: 0.8558451899889926
Validation loss: 2.7371868970579745

Epoch: 6| Step: 3
Training loss: 1.3239739565924193
Validation loss: 2.6973739849020135

Epoch: 6| Step: 4
Training loss: 1.631169711070021
Validation loss: 2.6808851288722866

Epoch: 6| Step: 5
Training loss: 1.636656766823987
Validation loss: 2.6725268544773937

Epoch: 6| Step: 6
Training loss: 0.9866814009000164
Validation loss: 2.668441216787539

Epoch: 6| Step: 7
Training loss: 0.996444580527682
Validation loss: 2.618317901785201

Epoch: 6| Step: 8
Training loss: 1.5951287532726666
Validation loss: 2.648931151588258

Epoch: 6| Step: 9
Training loss: 1.1692730309593884
Validation loss: 2.6254820456752093

Epoch: 6| Step: 10
Training loss: 1.7642223897262435
Validation loss: 2.6745930430464893

Epoch: 6| Step: 11
Training loss: 0.564382423276019
Validation loss: 2.6569838463834565

Epoch: 6| Step: 12
Training loss: 0.9944692192300691
Validation loss: 2.7122923647023605

Epoch: 6| Step: 13
Training loss: 1.0334985667580021
Validation loss: 2.7248649449959372

Epoch: 421| Step: 0
Training loss: 0.7636355808540972
Validation loss: 2.7449814853263854

Epoch: 6| Step: 1
Training loss: 1.7142676426298278
Validation loss: 2.7410364080718197

Epoch: 6| Step: 2
Training loss: 1.3146845484891547
Validation loss: 2.7627384474133114

Epoch: 6| Step: 3
Training loss: 1.0665431231737292
Validation loss: 2.7303995351973356

Epoch: 6| Step: 4
Training loss: 1.6644555285887876
Validation loss: 2.7564686787213915

Epoch: 6| Step: 5
Training loss: 0.9756109560946028
Validation loss: 2.6625581224571695

Epoch: 6| Step: 6
Training loss: 1.0344670142422607
Validation loss: 2.712350848853932

Epoch: 6| Step: 7
Training loss: 1.2883774757883317
Validation loss: 2.6247021188202813

Epoch: 6| Step: 8
Training loss: 0.8651089545080513
Validation loss: 2.6904568190224905

Epoch: 6| Step: 9
Training loss: 1.7719291288527885
Validation loss: 2.635536196162974

Epoch: 6| Step: 10
Training loss: 1.0981888208748785
Validation loss: 2.597727472002948

Epoch: 6| Step: 11
Training loss: 0.8152849080281029
Validation loss: 2.6280437413073185

Epoch: 6| Step: 12
Training loss: 1.0358273040481436
Validation loss: 2.6056124043741637

Epoch: 6| Step: 13
Training loss: 1.1228011152633601
Validation loss: 2.625057492307767

Epoch: 422| Step: 0
Training loss: 1.1774573055553392
Validation loss: 2.7375271602775455

Epoch: 6| Step: 1
Training loss: 0.9367530708293197
Validation loss: 2.726971964435666

Epoch: 6| Step: 2
Training loss: 0.9359819519491507
Validation loss: 2.7605486472385796

Epoch: 6| Step: 3
Training loss: 1.6819649803335261
Validation loss: 2.751411505619093

Epoch: 6| Step: 4
Training loss: 1.0501892237232249
Validation loss: 2.7079798590025197

Epoch: 6| Step: 5
Training loss: 1.6837026467918024
Validation loss: 2.6901198636262045

Epoch: 6| Step: 6
Training loss: 0.6204207270685584
Validation loss: 2.705530834302641

Epoch: 6| Step: 7
Training loss: 1.1730507610814336
Validation loss: 2.7188099675489186

Epoch: 6| Step: 8
Training loss: 0.9816393911807059
Validation loss: 2.7074568332742777

Epoch: 6| Step: 9
Training loss: 1.721947210497391
Validation loss: 2.717673216349558

Epoch: 6| Step: 10
Training loss: 1.0592075271788453
Validation loss: 2.720606626692055

Epoch: 6| Step: 11
Training loss: 0.9499297756039385
Validation loss: 2.6969735670881847

Epoch: 6| Step: 12
Training loss: 0.9537353437505
Validation loss: 2.7560737034475036

Epoch: 6| Step: 13
Training loss: 1.5323543069856433
Validation loss: 2.7176024474199307

Epoch: 423| Step: 0
Training loss: 1.5126913722007267
Validation loss: 2.779376323937822

Epoch: 6| Step: 1
Training loss: 1.488566373811784
Validation loss: 2.7339327645311933

Epoch: 6| Step: 2
Training loss: 0.957403709958349
Validation loss: 2.678107697747394

Epoch: 6| Step: 3
Training loss: 0.9999869464975972
Validation loss: 2.705741923904573

Epoch: 6| Step: 4
Training loss: 1.0377078296287696
Validation loss: 2.6559459587070493

Epoch: 6| Step: 5
Training loss: 1.082860965937693
Validation loss: 2.712078839961229

Epoch: 6| Step: 6
Training loss: 1.3486474414117655
Validation loss: 2.7922332150830314

Epoch: 6| Step: 7
Training loss: 1.2419549016489275
Validation loss: 2.7593113443672515

Epoch: 6| Step: 8
Training loss: 1.0287323476730008
Validation loss: 2.770720893089036

Epoch: 6| Step: 9
Training loss: 1.0933724978069328
Validation loss: 2.676519792271338

Epoch: 6| Step: 10
Training loss: 1.146898081284765
Validation loss: 2.6792480731262014

Epoch: 6| Step: 11
Training loss: 0.8719269398630913
Validation loss: 2.729523516516685

Epoch: 6| Step: 12
Training loss: 1.813570692898981
Validation loss: 2.697188339212642

Epoch: 6| Step: 13
Training loss: 1.2278153162511547
Validation loss: 2.6940329642786547

Epoch: 424| Step: 0
Training loss: 1.0906003014683547
Validation loss: 2.6887810485361885

Epoch: 6| Step: 1
Training loss: 0.8375485662356394
Validation loss: 2.686750758509986

Epoch: 6| Step: 2
Training loss: 0.9803613246716367
Validation loss: 2.6737986847004676

Epoch: 6| Step: 3
Training loss: 0.6741936618208256
Validation loss: 2.682324786429261

Epoch: 6| Step: 4
Training loss: 1.7809980783168358
Validation loss: 2.685834486847986

Epoch: 6| Step: 5
Training loss: 0.5439999071867948
Validation loss: 2.759710276688289

Epoch: 6| Step: 6
Training loss: 0.7557855220072202
Validation loss: 2.730476026475313

Epoch: 6| Step: 7
Training loss: 1.2111956905633512
Validation loss: 2.7457996136722707

Epoch: 6| Step: 8
Training loss: 0.8729278688159627
Validation loss: 2.778958709081513

Epoch: 6| Step: 9
Training loss: 1.190468841484638
Validation loss: 2.725405173262639

Epoch: 6| Step: 10
Training loss: 1.0167498888025535
Validation loss: 2.79616386991456

Epoch: 6| Step: 11
Training loss: 1.726649976904981
Validation loss: 2.7190411729659067

Epoch: 6| Step: 12
Training loss: 0.8395985799940077
Validation loss: 2.6914794498523404

Epoch: 6| Step: 13
Training loss: 1.7153619144137673
Validation loss: 2.748190833801111

Epoch: 425| Step: 0
Training loss: 0.786793761479673
Validation loss: 2.7026613164860382

Epoch: 6| Step: 1
Training loss: 0.8296334545399593
Validation loss: 2.6732263029422803

Epoch: 6| Step: 2
Training loss: 1.0210954498300215
Validation loss: 2.701688689915364

Epoch: 6| Step: 3
Training loss: 1.2691755530099906
Validation loss: 2.7226115167884455

Epoch: 6| Step: 4
Training loss: 1.3595753664575743
Validation loss: 2.726756922394718

Epoch: 6| Step: 5
Training loss: 1.1083745071583844
Validation loss: 2.6793731712701083

Epoch: 6| Step: 6
Training loss: 0.9703855551524345
Validation loss: 2.757512523845178

Epoch: 6| Step: 7
Training loss: 0.6472464964393513
Validation loss: 2.697584114542745

Epoch: 6| Step: 8
Training loss: 0.8439517309840397
Validation loss: 2.7131998770656462

Epoch: 6| Step: 9
Training loss: 1.4690932826371508
Validation loss: 2.681928433511456

Epoch: 6| Step: 10
Training loss: 1.221723109021761
Validation loss: 2.696550727995669

Epoch: 6| Step: 11
Training loss: 0.8365310985669504
Validation loss: 2.724976742496458

Epoch: 6| Step: 12
Training loss: 1.7289690877645305
Validation loss: 2.662887642330726

Epoch: 6| Step: 13
Training loss: 1.6337671728771204
Validation loss: 2.705022495032866

Epoch: 426| Step: 0
Training loss: 0.8357730596786103
Validation loss: 2.7167064981719458

Epoch: 6| Step: 1
Training loss: 0.9134275725455234
Validation loss: 2.701462603829662

Epoch: 6| Step: 2
Training loss: 0.6420356988741116
Validation loss: 2.7138410953394403

Epoch: 6| Step: 3
Training loss: 1.440866260641385
Validation loss: 2.7142508831394587

Epoch: 6| Step: 4
Training loss: 1.614544980813917
Validation loss: 2.7307704746096095

Epoch: 6| Step: 5
Training loss: 0.8854108735437303
Validation loss: 2.7365883724553037

Epoch: 6| Step: 6
Training loss: 1.7032924884718978
Validation loss: 2.70811089311358

Epoch: 6| Step: 7
Training loss: 0.932957963448292
Validation loss: 2.7202112940455434

Epoch: 6| Step: 8
Training loss: 1.3316940820582956
Validation loss: 2.687978243599749

Epoch: 6| Step: 9
Training loss: 1.1051177960607486
Validation loss: 2.7324022279205273

Epoch: 6| Step: 10
Training loss: 0.9195201344818885
Validation loss: 2.734085169372745

Epoch: 6| Step: 11
Training loss: 1.0963730013838593
Validation loss: 2.6656353168056843

Epoch: 6| Step: 12
Training loss: 1.1381257777706297
Validation loss: 2.691057393903541

Epoch: 6| Step: 13
Training loss: 1.425360630647094
Validation loss: 2.6994863580814887

Epoch: 427| Step: 0
Training loss: 0.8609505515658353
Validation loss: 2.70680171989791

Epoch: 6| Step: 1
Training loss: 0.6597844944949443
Validation loss: 2.692996621455696

Epoch: 6| Step: 2
Training loss: 0.8609171468610135
Validation loss: 2.739589405899183

Epoch: 6| Step: 3
Training loss: 1.0237397191762263
Validation loss: 2.76737359008358

Epoch: 6| Step: 4
Training loss: 2.147907427506752
Validation loss: 2.685827488890406

Epoch: 6| Step: 5
Training loss: 1.0318813125537412
Validation loss: 2.678674838325482

Epoch: 6| Step: 6
Training loss: 0.8799927840695604
Validation loss: 2.6900771152924774

Epoch: 6| Step: 7
Training loss: 1.6308146396371908
Validation loss: 2.749371832570949

Epoch: 6| Step: 8
Training loss: 1.38937210048385
Validation loss: 2.71120088820343

Epoch: 6| Step: 9
Training loss: 0.8833453840357425
Validation loss: 2.749029884308234

Epoch: 6| Step: 10
Training loss: 0.9919324832501211
Validation loss: 2.7176470510685

Epoch: 6| Step: 11
Training loss: 1.13177337341913
Validation loss: 2.679293641561502

Epoch: 6| Step: 12
Training loss: 0.6568450500600279
Validation loss: 2.6445041131073976

Epoch: 6| Step: 13
Training loss: 0.7078333988430686
Validation loss: 2.677630711168962

Epoch: 428| Step: 0
Training loss: 0.9993271053878078
Validation loss: 2.693177089557757

Epoch: 6| Step: 1
Training loss: 1.7249210892471687
Validation loss: 2.710685960164657

Epoch: 6| Step: 2
Training loss: 1.395382490463813
Validation loss: 2.698050305408657

Epoch: 6| Step: 3
Training loss: 1.5082011932463428
Validation loss: 2.698686200321724

Epoch: 6| Step: 4
Training loss: 1.4288540271123877
Validation loss: 2.694463771300681

Epoch: 6| Step: 5
Training loss: 0.8646541397944169
Validation loss: 2.712983062319126

Epoch: 6| Step: 6
Training loss: 1.0123193791666745
Validation loss: 2.744140646720696

Epoch: 6| Step: 7
Training loss: 1.150475490788124
Validation loss: 2.7653517794663656

Epoch: 6| Step: 8
Training loss: 0.7047824398124265
Validation loss: 2.7153228995586876

Epoch: 6| Step: 9
Training loss: 0.945168192544117
Validation loss: 2.7544497267042507

Epoch: 6| Step: 10
Training loss: 0.7774073129094555
Validation loss: 2.7245710472774602

Epoch: 6| Step: 11
Training loss: 1.073778263292938
Validation loss: 2.722380132917563

Epoch: 6| Step: 12
Training loss: 0.8844154456497496
Validation loss: 2.766614991781701

Epoch: 6| Step: 13
Training loss: 1.03449138666534
Validation loss: 2.7249293058598787

Epoch: 429| Step: 0
Training loss: 0.7859545772206376
Validation loss: 2.752045174352677

Epoch: 6| Step: 1
Training loss: 1.7346055161157843
Validation loss: 2.731114345298068

Epoch: 6| Step: 2
Training loss: 0.8837746972028304
Validation loss: 2.759506382591929

Epoch: 6| Step: 3
Training loss: 1.0682616250128512
Validation loss: 2.787390712768165

Epoch: 6| Step: 4
Training loss: 1.1109739788520707
Validation loss: 2.764234865175513

Epoch: 6| Step: 5
Training loss: 0.8958075467915371
Validation loss: 2.804811253558024

Epoch: 6| Step: 6
Training loss: 0.8297946580556292
Validation loss: 2.6840993228230685

Epoch: 6| Step: 7
Training loss: 0.7768643688600798
Validation loss: 2.722933141711555

Epoch: 6| Step: 8
Training loss: 1.6746064449682423
Validation loss: 2.729253925258349

Epoch: 6| Step: 9
Training loss: 1.070396698473071
Validation loss: 2.71735858024022

Epoch: 6| Step: 10
Training loss: 1.038506150985523
Validation loss: 2.684852678684118

Epoch: 6| Step: 11
Training loss: 1.3740688552345097
Validation loss: 2.6749364405653933

Epoch: 6| Step: 12
Training loss: 1.005484798276647
Validation loss: 2.747918468259771

Epoch: 6| Step: 13
Training loss: 1.1447553187469799
Validation loss: 2.7056512365539964

Epoch: 430| Step: 0
Training loss: 1.0788140789993053
Validation loss: 2.6791466036372147

Epoch: 6| Step: 1
Training loss: 0.942772250177692
Validation loss: 2.713345120878492

Epoch: 6| Step: 2
Training loss: 1.1011089717007188
Validation loss: 2.7512915063893333

Epoch: 6| Step: 3
Training loss: 1.6466272909782247
Validation loss: 2.7955373623486253

Epoch: 6| Step: 4
Training loss: 0.5982975728958226
Validation loss: 2.7048017707249508

Epoch: 6| Step: 5
Training loss: 1.1436986400975397
Validation loss: 2.749187797479825

Epoch: 6| Step: 6
Training loss: 0.9493825009861467
Validation loss: 2.7486813157864964

Epoch: 6| Step: 7
Training loss: 0.965780814725725
Validation loss: 2.7619537296714785

Epoch: 6| Step: 8
Training loss: 1.655655952299648
Validation loss: 2.7326231948895203

Epoch: 6| Step: 9
Training loss: 0.7093982171783974
Validation loss: 2.7379901783889857

Epoch: 6| Step: 10
Training loss: 0.7083200752663082
Validation loss: 2.7063903049809532

Epoch: 6| Step: 11
Training loss: 0.956210192930146
Validation loss: 2.754619215711991

Epoch: 6| Step: 12
Training loss: 1.2180231323237891
Validation loss: 2.7502660189188877

Epoch: 6| Step: 13
Training loss: 1.4754048002136255
Validation loss: 2.694300069797203

Epoch: 431| Step: 0
Training loss: 1.8190510189373663
Validation loss: 2.737784565109383

Epoch: 6| Step: 1
Training loss: 1.5494185064500432
Validation loss: 2.842391811113616

Epoch: 6| Step: 2
Training loss: 1.0419885837310279
Validation loss: 2.8071901707652627

Epoch: 6| Step: 3
Training loss: 1.0768387350129849
Validation loss: 2.7733417906387685

Epoch: 6| Step: 4
Training loss: 0.7341376793674319
Validation loss: 2.724304678046471

Epoch: 6| Step: 5
Training loss: 0.9354175326903369
Validation loss: 2.7353361202640762

Epoch: 6| Step: 6
Training loss: 1.6917297899592942
Validation loss: 2.786792361954925

Epoch: 6| Step: 7
Training loss: 1.1334403567176916
Validation loss: 2.672996701959796

Epoch: 6| Step: 8
Training loss: 0.6944955891743074
Validation loss: 2.7028280106054345

Epoch: 6| Step: 9
Training loss: 1.062183894089282
Validation loss: 2.6608277162882263

Epoch: 6| Step: 10
Training loss: 0.9111438353956248
Validation loss: 2.719618866738355

Epoch: 6| Step: 11
Training loss: 0.8796315231265682
Validation loss: 2.6571772434228533

Epoch: 6| Step: 12
Training loss: 0.920417538722051
Validation loss: 2.7060103333076904

Epoch: 6| Step: 13
Training loss: 0.933086688512932
Validation loss: 2.7076098771840336

Epoch: 432| Step: 0
Training loss: 1.7567684887952302
Validation loss: 2.68408981839344

Epoch: 6| Step: 1
Training loss: 1.2657431088191606
Validation loss: 2.6973225198316206

Epoch: 6| Step: 2
Training loss: 0.7201668830031982
Validation loss: 2.699766170713857

Epoch: 6| Step: 3
Training loss: 0.976922602064201
Validation loss: 2.756565882083179

Epoch: 6| Step: 4
Training loss: 1.163336200838098
Validation loss: 2.815707659310712

Epoch: 6| Step: 5
Training loss: 0.9736374039001257
Validation loss: 2.863884293776274

Epoch: 6| Step: 6
Training loss: 1.3567892892159474
Validation loss: 2.7986149836519476

Epoch: 6| Step: 7
Training loss: 1.1247604962885345
Validation loss: 2.785677696518719

Epoch: 6| Step: 8
Training loss: 1.7271403730826018
Validation loss: 2.804409257693579

Epoch: 6| Step: 9
Training loss: 0.8600321944442847
Validation loss: 2.7242716262013604

Epoch: 6| Step: 10
Training loss: 0.8291086796431496
Validation loss: 2.711954239467649

Epoch: 6| Step: 11
Training loss: 0.8055128290822947
Validation loss: 2.6518362736801846

Epoch: 6| Step: 12
Training loss: 1.077562931993304
Validation loss: 2.709516433139433

Epoch: 6| Step: 13
Training loss: 1.057699353521394
Validation loss: 2.709725159248582

Epoch: 433| Step: 0
Training loss: 1.6721406529508014
Validation loss: 2.66340691786685

Epoch: 6| Step: 1
Training loss: 0.8986885051884831
Validation loss: 2.702105438291024

Epoch: 6| Step: 2
Training loss: 0.9859642339549012
Validation loss: 2.720740952220808

Epoch: 6| Step: 3
Training loss: 0.8606119443835374
Validation loss: 2.7057659133212435

Epoch: 6| Step: 4
Training loss: 2.1882822000650606
Validation loss: 2.744171598537943

Epoch: 6| Step: 5
Training loss: 0.9682949289387076
Validation loss: 2.9424412338883634

Epoch: 6| Step: 6
Training loss: 0.8005861370293954
Validation loss: 2.936804303513535

Epoch: 6| Step: 7
Training loss: 1.550463819325834
Validation loss: 2.864247019127791

Epoch: 6| Step: 8
Training loss: 1.219060955970723
Validation loss: 2.7377105858335864

Epoch: 6| Step: 9
Training loss: 0.9651160222804315
Validation loss: 2.7354798037778725

Epoch: 6| Step: 10
Training loss: 1.0003066784761703
Validation loss: 2.7187713388358286

Epoch: 6| Step: 11
Training loss: 0.8841730621878392
Validation loss: 2.7453544131506122

Epoch: 6| Step: 12
Training loss: 1.0618343512089579
Validation loss: 2.74608103069545

Epoch: 6| Step: 13
Training loss: 1.0045578322673867
Validation loss: 2.74748024953929

Epoch: 434| Step: 0
Training loss: 0.9413568317532773
Validation loss: 2.720835094441598

Epoch: 6| Step: 1
Training loss: 1.4646659234510528
Validation loss: 2.7167246352097787

Epoch: 6| Step: 2
Training loss: 1.6286273232646278
Validation loss: 2.735033388346638

Epoch: 6| Step: 3
Training loss: 1.5434393442764278
Validation loss: 2.741592487580079

Epoch: 6| Step: 4
Training loss: 1.1032167823367018
Validation loss: 2.816193423119822

Epoch: 6| Step: 5
Training loss: 0.9474888489401692
Validation loss: 2.7958316526298947

Epoch: 6| Step: 6
Training loss: 0.9460395350149053
Validation loss: 2.8771351888091456

Epoch: 6| Step: 7
Training loss: 1.0520278739790045
Validation loss: 2.9097563261847226

Epoch: 6| Step: 8
Training loss: 1.0802692706369645
Validation loss: 2.800262999104013

Epoch: 6| Step: 9
Training loss: 0.6871276844354592
Validation loss: 2.8227154189629555

Epoch: 6| Step: 10
Training loss: 0.8365437813546694
Validation loss: 2.8421842435594793

Epoch: 6| Step: 11
Training loss: 1.8144987858179298
Validation loss: 2.795415046165665

Epoch: 6| Step: 12
Training loss: 0.6306369259389971
Validation loss: 2.8098487084048767

Epoch: 6| Step: 13
Training loss: 0.7436384774591588
Validation loss: 2.792148112065675

Epoch: 435| Step: 0
Training loss: 0.8738116300728759
Validation loss: 2.8503589337178905

Epoch: 6| Step: 1
Training loss: 1.234147835604371
Validation loss: 2.859508629405388

Epoch: 6| Step: 2
Training loss: 0.8493037233066905
Validation loss: 2.8437383882054954

Epoch: 6| Step: 3
Training loss: 1.8342736029341813
Validation loss: 2.831464099437965

Epoch: 6| Step: 4
Training loss: 1.168916961657556
Validation loss: 2.8517071970280155

Epoch: 6| Step: 5
Training loss: 0.8340980756025133
Validation loss: 2.7961790188548385

Epoch: 6| Step: 6
Training loss: 1.0792410781912198
Validation loss: 2.7981821908929336

Epoch: 6| Step: 7
Training loss: 0.9520339975297062
Validation loss: 2.800639001274567

Epoch: 6| Step: 8
Training loss: 0.6046830031747715
Validation loss: 2.7351838359732823

Epoch: 6| Step: 9
Training loss: 0.7495351781497628
Validation loss: 2.8261571961544334

Epoch: 6| Step: 10
Training loss: 1.5105308577243468
Validation loss: 2.8093450440707524

Epoch: 6| Step: 11
Training loss: 1.0893231861181958
Validation loss: 2.8105512013246323

Epoch: 6| Step: 12
Training loss: 0.7127037325921232
Validation loss: 2.882791920547981

Epoch: 6| Step: 13
Training loss: 1.3692343077123448
Validation loss: 2.8802610166030127

Epoch: 436| Step: 0
Training loss: 0.848014263719131
Validation loss: 2.8996631125187786

Epoch: 6| Step: 1
Training loss: 1.2706547387541622
Validation loss: 2.929300511550325

Epoch: 6| Step: 2
Training loss: 1.216655251479923
Validation loss: 2.821250541144981

Epoch: 6| Step: 3
Training loss: 1.1752214588301737
Validation loss: 2.7191140672851515

Epoch: 6| Step: 4
Training loss: 0.8336082879097436
Validation loss: 2.6660074049900944

Epoch: 6| Step: 5
Training loss: 2.29570153810616
Validation loss: 2.7419138424964533

Epoch: 6| Step: 6
Training loss: 1.642216373846721
Validation loss: 2.7767869093353124

Epoch: 6| Step: 7
Training loss: 1.156738487362793
Validation loss: 2.776043579978832

Epoch: 6| Step: 8
Training loss: 0.8558857219476287
Validation loss: 2.790952425063876

Epoch: 6| Step: 9
Training loss: 1.3007502738311556
Validation loss: 2.8552016217221174

Epoch: 6| Step: 10
Training loss: 0.8537652809372899
Validation loss: 2.7974770038376597

Epoch: 6| Step: 11
Training loss: 1.1116254304923423
Validation loss: 2.8517576595045355

Epoch: 6| Step: 12
Training loss: 1.1598445589231547
Validation loss: 2.8862553466729732

Epoch: 6| Step: 13
Training loss: 1.2091097913038162
Validation loss: 2.997691975316808

Epoch: 437| Step: 0
Training loss: 1.5591750817587462
Validation loss: 3.058144410939284

Epoch: 6| Step: 1
Training loss: 1.2058838758089583
Validation loss: 2.934344091174754

Epoch: 6| Step: 2
Training loss: 1.1149127984267213
Validation loss: 2.9589107424531083

Epoch: 6| Step: 3
Training loss: 0.949328506466385
Validation loss: 2.858442171729045

Epoch: 6| Step: 4
Training loss: 1.6863239570161457
Validation loss: 2.7927172709891983

Epoch: 6| Step: 5
Training loss: 1.1189970819846007
Validation loss: 2.7766846180030633

Epoch: 6| Step: 6
Training loss: 1.262868540388161
Validation loss: 2.700571327632525

Epoch: 6| Step: 7
Training loss: 2.0379798324156115
Validation loss: 2.7503532125034846

Epoch: 6| Step: 8
Training loss: 1.3290727711739676
Validation loss: 2.699219206365095

Epoch: 6| Step: 9
Training loss: 1.1860326434784518
Validation loss: 2.735731402436924

Epoch: 6| Step: 10
Training loss: 1.530265881118668
Validation loss: 2.7917405493529532

Epoch: 6| Step: 11
Training loss: 1.4109835324641062
Validation loss: 2.845306201238641

Epoch: 6| Step: 12
Training loss: 0.9471117661573469
Validation loss: 2.975765932684165

Epoch: 6| Step: 13
Training loss: 1.3270588803196817
Validation loss: 3.141927117059072

Epoch: 438| Step: 0
Training loss: 1.124228848961383
Validation loss: 3.0317921235639416

Epoch: 6| Step: 1
Training loss: 1.1062155852918445
Validation loss: 2.938552099887988

Epoch: 6| Step: 2
Training loss: 0.9700531961660808
Validation loss: 2.830368950228813

Epoch: 6| Step: 3
Training loss: 1.8847418432761285
Validation loss: 2.757903878316369

Epoch: 6| Step: 4
Training loss: 1.8423548446889322
Validation loss: 2.7014731503256777

Epoch: 6| Step: 5
Training loss: 1.8552548576345875
Validation loss: 2.708300521847456

Epoch: 6| Step: 6
Training loss: 0.9663821168814368
Validation loss: 2.7700562977033303

Epoch: 6| Step: 7
Training loss: 0.9770048131619203
Validation loss: 2.7256359139952657

Epoch: 6| Step: 8
Training loss: 1.095675979794793
Validation loss: 2.776174135369577

Epoch: 6| Step: 9
Training loss: 1.519502379626124
Validation loss: 2.729435046057922

Epoch: 6| Step: 10
Training loss: 1.0280049448154136
Validation loss: 2.738336610619907

Epoch: 6| Step: 11
Training loss: 1.062895364691202
Validation loss: 2.829377067581454

Epoch: 6| Step: 12
Training loss: 1.1474746508489067
Validation loss: 2.794322989558614

Epoch: 6| Step: 13
Training loss: 0.8482204967644242
Validation loss: 2.8535405653347325

Epoch: 439| Step: 0
Training loss: 0.7881667085119075
Validation loss: 2.848279203730556

Epoch: 6| Step: 1
Training loss: 1.506881505508335
Validation loss: 2.9481612105198223

Epoch: 6| Step: 2
Training loss: 1.2461094391890446
Validation loss: 3.0332473912133664

Epoch: 6| Step: 3
Training loss: 1.113980311375558
Validation loss: 2.925428463455174

Epoch: 6| Step: 4
Training loss: 0.8168025173027038
Validation loss: 2.873307462415003

Epoch: 6| Step: 5
Training loss: 1.07587829019197
Validation loss: 2.787421105926247

Epoch: 6| Step: 6
Training loss: 1.0996062310887005
Validation loss: 2.778687357331571

Epoch: 6| Step: 7
Training loss: 0.9813988821709352
Validation loss: 2.7038386584363536

Epoch: 6| Step: 8
Training loss: 1.7276342871402324
Validation loss: 2.7174506608589377

Epoch: 6| Step: 9
Training loss: 1.2046122585603285
Validation loss: 2.767993336797239

Epoch: 6| Step: 10
Training loss: 0.7556306162610463
Validation loss: 2.721801798873061

Epoch: 6| Step: 11
Training loss: 1.6353348956550966
Validation loss: 2.7203353556593655

Epoch: 6| Step: 12
Training loss: 0.8246047214537577
Validation loss: 2.722876621487933

Epoch: 6| Step: 13
Training loss: 0.7647019875435873
Validation loss: 2.764610068377134

Epoch: 440| Step: 0
Training loss: 0.6433379252505435
Validation loss: 2.8058676897496038

Epoch: 6| Step: 1
Training loss: 0.9889331220766071
Validation loss: 2.780775451179693

Epoch: 6| Step: 2
Training loss: 0.975405320258118
Validation loss: 2.7617155845728263

Epoch: 6| Step: 3
Training loss: 0.8854041753149582
Validation loss: 2.8248913791895722

Epoch: 6| Step: 4
Training loss: 0.9491688279575818
Validation loss: 2.7438597909891858

Epoch: 6| Step: 5
Training loss: 1.2402561936749588
Validation loss: 2.764090318757258

Epoch: 6| Step: 6
Training loss: 2.1475758437240624
Validation loss: 2.7078800604614086

Epoch: 6| Step: 7
Training loss: 0.9079058416969186
Validation loss: 2.7883645830913357

Epoch: 6| Step: 8
Training loss: 1.0512136824568006
Validation loss: 2.834267116457597

Epoch: 6| Step: 9
Training loss: 1.5789754860867353
Validation loss: 2.7329234021299587

Epoch: 6| Step: 10
Training loss: 0.94549347587485
Validation loss: 2.75855111235297

Epoch: 6| Step: 11
Training loss: 0.9463124936630827
Validation loss: 2.7491336671672393

Epoch: 6| Step: 12
Training loss: 0.8754564184804229
Validation loss: 2.720024482485972

Epoch: 6| Step: 13
Training loss: 1.0955548245576074
Validation loss: 2.6961986467177943

Epoch: 441| Step: 0
Training loss: 2.0544253570076156
Validation loss: 2.7755546548197314

Epoch: 6| Step: 1
Training loss: 0.9861425848461747
Validation loss: 2.7586703312623486

Epoch: 6| Step: 2
Training loss: 0.9313311752680262
Validation loss: 2.780096079014544

Epoch: 6| Step: 3
Training loss: 0.8154823514641313
Validation loss: 2.7852697862023277

Epoch: 6| Step: 4
Training loss: 0.5260283843022292
Validation loss: 2.7781005486412473

Epoch: 6| Step: 5
Training loss: 1.701974322572478
Validation loss: 2.811195141483343

Epoch: 6| Step: 6
Training loss: 0.9415874069469664
Validation loss: 2.8233411594118767

Epoch: 6| Step: 7
Training loss: 0.9269016745105763
Validation loss: 2.7702333235681516

Epoch: 6| Step: 8
Training loss: 0.7473764228737074
Validation loss: 2.7351766228700254

Epoch: 6| Step: 9
Training loss: 0.8448126423807343
Validation loss: 2.824751357442652

Epoch: 6| Step: 10
Training loss: 0.715458589886989
Validation loss: 2.762995071123246

Epoch: 6| Step: 11
Training loss: 1.0742797279390404
Validation loss: 2.8047396939237315

Epoch: 6| Step: 12
Training loss: 0.9632881380872886
Validation loss: 2.8000774128748365

Epoch: 6| Step: 13
Training loss: 0.820098122331758
Validation loss: 2.736987495349198

Epoch: 442| Step: 0
Training loss: 1.5997458971426695
Validation loss: 2.744149400147224

Epoch: 6| Step: 1
Training loss: 0.9993239143870138
Validation loss: 2.754489651111498

Epoch: 6| Step: 2
Training loss: 1.5071976747274178
Validation loss: 2.7636755989328194

Epoch: 6| Step: 3
Training loss: 0.5527327304990858
Validation loss: 2.770095143663833

Epoch: 6| Step: 4
Training loss: 0.9331838434142739
Validation loss: 2.7262712849598394

Epoch: 6| Step: 5
Training loss: 0.9884716046624857
Validation loss: 2.772493744508585

Epoch: 6| Step: 6
Training loss: 1.1434310989638587
Validation loss: 2.8069376371341916

Epoch: 6| Step: 7
Training loss: 0.997625810820481
Validation loss: 2.7428734655878517

Epoch: 6| Step: 8
Training loss: 0.8647121119055378
Validation loss: 2.777177751161387

Epoch: 6| Step: 9
Training loss: 1.1090237235962117
Validation loss: 2.8231422831521673

Epoch: 6| Step: 10
Training loss: 1.2937677686272733
Validation loss: 2.7878787451974643

Epoch: 6| Step: 11
Training loss: 0.7035162578878569
Validation loss: 2.8266891712591424

Epoch: 6| Step: 12
Training loss: 0.9523561221814143
Validation loss: 2.809865056323945

Epoch: 6| Step: 13
Training loss: 0.9301819007652212
Validation loss: 2.808793514895325

Epoch: 443| Step: 0
Training loss: 1.128650940004962
Validation loss: 2.7931723922791294

Epoch: 6| Step: 1
Training loss: 0.5587250348515401
Validation loss: 2.753239832838413

Epoch: 6| Step: 2
Training loss: 0.7868152381194203
Validation loss: 2.7319163867634684

Epoch: 6| Step: 3
Training loss: 0.9525473360629608
Validation loss: 2.742001330657532

Epoch: 6| Step: 4
Training loss: 0.786225118015946
Validation loss: 2.7367263711076713

Epoch: 6| Step: 5
Training loss: 1.6633074843029647
Validation loss: 2.7358893424544575

Epoch: 6| Step: 6
Training loss: 0.747482844127144
Validation loss: 2.736670702034147

Epoch: 6| Step: 7
Training loss: 0.6455091975625742
Validation loss: 2.777574289074061

Epoch: 6| Step: 8
Training loss: 1.6405925202560634
Validation loss: 2.8460195797863053

Epoch: 6| Step: 9
Training loss: 0.9854057607121185
Validation loss: 2.760046049945549

Epoch: 6| Step: 10
Training loss: 0.896523069656135
Validation loss: 2.7842085172386413

Epoch: 6| Step: 11
Training loss: 0.6742031214948175
Validation loss: 2.7076655126945908

Epoch: 6| Step: 12
Training loss: 1.5012098837137053
Validation loss: 2.764326016817707

Epoch: 6| Step: 13
Training loss: 1.0720663250254627
Validation loss: 2.7696478083393146

Epoch: 444| Step: 0
Training loss: 0.8100590352338308
Validation loss: 2.718311508304713

Epoch: 6| Step: 1
Training loss: 0.727766864110767
Validation loss: 2.7289385712408922

Epoch: 6| Step: 2
Training loss: 1.1939303316848577
Validation loss: 2.7524536486241695

Epoch: 6| Step: 3
Training loss: 1.0973477184512321
Validation loss: 2.726432381834335

Epoch: 6| Step: 4
Training loss: 1.6634121909143038
Validation loss: 2.7672714964490948

Epoch: 6| Step: 5
Training loss: 0.837445369760635
Validation loss: 2.760653681146548

Epoch: 6| Step: 6
Training loss: 0.8306754801432129
Validation loss: 2.7740819835906123

Epoch: 6| Step: 7
Training loss: 0.8812486756767982
Validation loss: 2.854700864563274

Epoch: 6| Step: 8
Training loss: 0.8505434010290107
Validation loss: 2.8220638427406763

Epoch: 6| Step: 9
Training loss: 1.5170173934663596
Validation loss: 2.83426835021748

Epoch: 6| Step: 10
Training loss: 0.8384652823651976
Validation loss: 2.8622021066172363

Epoch: 6| Step: 11
Training loss: 0.7348516418954686
Validation loss: 2.759997704339109

Epoch: 6| Step: 12
Training loss: 0.7845230206041044
Validation loss: 2.7863007450403003

Epoch: 6| Step: 13
Training loss: 1.3610812473697256
Validation loss: 2.769268365963754

Epoch: 445| Step: 0
Training loss: 1.0814148837812652
Validation loss: 2.736297440249044

Epoch: 6| Step: 1
Training loss: 0.6887326460934986
Validation loss: 2.774775351632888

Epoch: 6| Step: 2
Training loss: 0.6600135784486348
Validation loss: 2.7031492404916615

Epoch: 6| Step: 3
Training loss: 0.9967949885961839
Validation loss: 2.744077330161386

Epoch: 6| Step: 4
Training loss: 0.8426675917903534
Validation loss: 2.7645421036321958

Epoch: 6| Step: 5
Training loss: 1.5164103881842363
Validation loss: 2.7824297770835558

Epoch: 6| Step: 6
Training loss: 1.6975628380809349
Validation loss: 2.7322260377666026

Epoch: 6| Step: 7
Training loss: 1.0872299955329807
Validation loss: 2.683419256631425

Epoch: 6| Step: 8
Training loss: 0.6034617230192552
Validation loss: 2.7497526982401683

Epoch: 6| Step: 9
Training loss: 1.5160558029311844
Validation loss: 2.7852050006553664

Epoch: 6| Step: 10
Training loss: 0.6440587479261359
Validation loss: 2.7911040939643077

Epoch: 6| Step: 11
Training loss: 0.9726819260973159
Validation loss: 2.829932223767624

Epoch: 6| Step: 12
Training loss: 0.7257646261062685
Validation loss: 2.805958154536262

Epoch: 6| Step: 13
Training loss: 0.8308358358143342
Validation loss: 2.881632576323991

Epoch: 446| Step: 0
Training loss: 0.8658767623277663
Validation loss: 2.763144032245176

Epoch: 6| Step: 1
Training loss: 1.0549201991196395
Validation loss: 2.7969583395932096

Epoch: 6| Step: 2
Training loss: 0.8156478498627068
Validation loss: 2.78123382677955

Epoch: 6| Step: 3
Training loss: 0.7901377386422012
Validation loss: 2.833473641530503

Epoch: 6| Step: 4
Training loss: 0.8337059181490171
Validation loss: 2.722962298858514

Epoch: 6| Step: 5
Training loss: 0.737786424912037
Validation loss: 2.7873177792415404

Epoch: 6| Step: 6
Training loss: 0.9055722102646993
Validation loss: 2.7692582857226626

Epoch: 6| Step: 7
Training loss: 0.9193941777431447
Validation loss: 2.801326753562609

Epoch: 6| Step: 8
Training loss: 0.7696664759141574
Validation loss: 2.788770145655259

Epoch: 6| Step: 9
Training loss: 2.124735871897867
Validation loss: 2.803078844476488

Epoch: 6| Step: 10
Training loss: 0.7319466638702323
Validation loss: 2.9567997857381347

Epoch: 6| Step: 11
Training loss: 1.0870629934326133
Validation loss: 2.8880737043012314

Epoch: 6| Step: 12
Training loss: 1.0156458925885932
Validation loss: 2.9619130965626517

Epoch: 6| Step: 13
Training loss: 1.4822187322212956
Validation loss: 2.894302970062993

Epoch: 447| Step: 0
Training loss: 1.42746490983207
Validation loss: 2.83965851863103

Epoch: 6| Step: 1
Training loss: 1.6814307105074746
Validation loss: 2.833874220737105

Epoch: 6| Step: 2
Training loss: 1.8276124545460508
Validation loss: 2.80604079952836

Epoch: 6| Step: 3
Training loss: 0.833548724630791
Validation loss: 2.748347725268594

Epoch: 6| Step: 4
Training loss: 0.9357977353597927
Validation loss: 2.796978271964615

Epoch: 6| Step: 5
Training loss: 0.7772826357640382
Validation loss: 2.7674376443777744

Epoch: 6| Step: 6
Training loss: 1.04591450825801
Validation loss: 2.786924167566348

Epoch: 6| Step: 7
Training loss: 0.9164580555717624
Validation loss: 2.838777939415253

Epoch: 6| Step: 8
Training loss: 0.440729888985148
Validation loss: 2.7984297851138087

Epoch: 6| Step: 9
Training loss: 0.7345162113859832
Validation loss: 2.7623370322464367

Epoch: 6| Step: 10
Training loss: 0.8131060907274875
Validation loss: 2.8017754273311293

Epoch: 6| Step: 11
Training loss: 0.9360675995188531
Validation loss: 2.8011045956496976

Epoch: 6| Step: 12
Training loss: 0.8685690039485687
Validation loss: 2.820753772764966

Epoch: 6| Step: 13
Training loss: 0.9292908150794824
Validation loss: 2.863770682921941

Epoch: 448| Step: 0
Training loss: 0.90824470014677
Validation loss: 2.8272456141995623

Epoch: 6| Step: 1
Training loss: 0.9555199348170736
Validation loss: 2.774732146065941

Epoch: 6| Step: 2
Training loss: 0.9451648817584218
Validation loss: 2.7791059137554663

Epoch: 6| Step: 3
Training loss: 0.9874223738955138
Validation loss: 2.748638480715587

Epoch: 6| Step: 4
Training loss: 0.8598124344461012
Validation loss: 2.804985377681016

Epoch: 6| Step: 5
Training loss: 0.7974785407835461
Validation loss: 2.822227497129275

Epoch: 6| Step: 6
Training loss: 0.9431153291746166
Validation loss: 2.807056697903872

Epoch: 6| Step: 7
Training loss: 0.8255228870899795
Validation loss: 2.801510654245606

Epoch: 6| Step: 8
Training loss: 0.5726016883826538
Validation loss: 2.7229492963856026

Epoch: 6| Step: 9
Training loss: 1.666990757267254
Validation loss: 2.7896250096105004

Epoch: 6| Step: 10
Training loss: 0.8855428418781531
Validation loss: 2.7837121758976746

Epoch: 6| Step: 11
Training loss: 1.4685104661775725
Validation loss: 2.7473290072203933

Epoch: 6| Step: 12
Training loss: 1.3151476811930565
Validation loss: 2.7848727031541736

Epoch: 6| Step: 13
Training loss: 0.8595181432632082
Validation loss: 2.754175181142445

Epoch: 449| Step: 0
Training loss: 1.320708898144131
Validation loss: 2.849675401528843

Epoch: 6| Step: 1
Training loss: 1.0119492551761549
Validation loss: 2.807471180533246

Epoch: 6| Step: 2
Training loss: 1.155796168160015
Validation loss: 2.810335513207027

Epoch: 6| Step: 3
Training loss: 0.7775020342367859
Validation loss: 2.7795566161349914

Epoch: 6| Step: 4
Training loss: 1.5832812233765525
Validation loss: 2.815026645963414

Epoch: 6| Step: 5
Training loss: 0.9141390189722446
Validation loss: 2.7285206348006383

Epoch: 6| Step: 6
Training loss: 0.6457119386674928
Validation loss: 2.7962018557982447

Epoch: 6| Step: 7
Training loss: 0.8659919539379557
Validation loss: 2.704471363090211

Epoch: 6| Step: 8
Training loss: 0.587150208860924
Validation loss: 2.7573478242415277

Epoch: 6| Step: 9
Training loss: 1.7290914664711112
Validation loss: 2.7721755474453422

Epoch: 6| Step: 10
Training loss: 0.8166358661357854
Validation loss: 2.7591932548671294

Epoch: 6| Step: 11
Training loss: 0.5989120354934021
Validation loss: 2.7016906607862774

Epoch: 6| Step: 12
Training loss: 0.7437814561619122
Validation loss: 2.8112056720880507

Epoch: 6| Step: 13
Training loss: 0.9706349646357091
Validation loss: 2.7738935570215246

Epoch: 450| Step: 0
Training loss: 0.8721189410587085
Validation loss: 2.7565546237942735

Epoch: 6| Step: 1
Training loss: 0.7631272034609363
Validation loss: 2.7842775646762346

Epoch: 6| Step: 2
Training loss: 1.5170867792202312
Validation loss: 2.7918625995334123

Epoch: 6| Step: 3
Training loss: 0.7784981901261712
Validation loss: 2.824774540144203

Epoch: 6| Step: 4
Training loss: 0.5938015965579995
Validation loss: 2.848111577167346

Epoch: 6| Step: 5
Training loss: 1.4272652206157228
Validation loss: 2.7902916943097735

Epoch: 6| Step: 6
Training loss: 0.8030470264745295
Validation loss: 2.8547262260484247

Epoch: 6| Step: 7
Training loss: 0.9971694224508305
Validation loss: 2.8307757661850603

Epoch: 6| Step: 8
Training loss: 1.6977624725661078
Validation loss: 2.795261279810173

Epoch: 6| Step: 9
Training loss: 0.9341131066568636
Validation loss: 2.8350837340146966

Epoch: 6| Step: 10
Training loss: 0.8817181851839659
Validation loss: 2.7442604192648505

Epoch: 6| Step: 11
Training loss: 0.8880544341023947
Validation loss: 2.75311028270562

Epoch: 6| Step: 12
Training loss: 0.8771249649484928
Validation loss: 2.76081008027019

Epoch: 6| Step: 13
Training loss: 0.8020984516122671
Validation loss: 2.784151428357551

Epoch: 451| Step: 0
Training loss: 2.009094541445186
Validation loss: 2.6880733410701514

Epoch: 6| Step: 1
Training loss: 0.60456855057412
Validation loss: 2.6977247417824017

Epoch: 6| Step: 2
Training loss: 0.9549015872737993
Validation loss: 2.7446741347993893

Epoch: 6| Step: 3
Training loss: 0.7837779535057179
Validation loss: 2.733020425152796

Epoch: 6| Step: 4
Training loss: 0.7726919646152267
Validation loss: 2.7702933385207484

Epoch: 6| Step: 5
Training loss: 0.6237084872970002
Validation loss: 2.7558247838687002

Epoch: 6| Step: 6
Training loss: 0.7857029468164074
Validation loss: 2.8020415651595307

Epoch: 6| Step: 7
Training loss: 0.9696599931715668
Validation loss: 2.8478029733961256

Epoch: 6| Step: 8
Training loss: 1.153590261988073
Validation loss: 2.8440902282863156

Epoch: 6| Step: 9
Training loss: 0.6206330324020051
Validation loss: 2.881437544052776

Epoch: 6| Step: 10
Training loss: 0.7824779777962342
Validation loss: 2.8406034535233284

Epoch: 6| Step: 11
Training loss: 0.878311328871686
Validation loss: 2.8284755651092777

Epoch: 6| Step: 12
Training loss: 1.6225258258239523
Validation loss: 2.8071271084956484

Epoch: 6| Step: 13
Training loss: 0.7875743467567436
Validation loss: 2.8398264832389306

Epoch: 452| Step: 0
Training loss: 1.5479463662558097
Validation loss: 2.8143571585345883

Epoch: 6| Step: 1
Training loss: 0.6206782168557569
Validation loss: 2.8484766597710034

Epoch: 6| Step: 2
Training loss: 0.9122533909156274
Validation loss: 2.8092391289940877

Epoch: 6| Step: 3
Training loss: 0.8435734811443858
Validation loss: 2.8340102443657975

Epoch: 6| Step: 4
Training loss: 1.020925102520584
Validation loss: 2.855459927303045

Epoch: 6| Step: 5
Training loss: 1.7246568614949855
Validation loss: 2.7979176316551957

Epoch: 6| Step: 6
Training loss: 0.7479730873468253
Validation loss: 2.8170290614136593

Epoch: 6| Step: 7
Training loss: 0.9635503029651056
Validation loss: 2.8163984900873364

Epoch: 6| Step: 8
Training loss: 0.6521852723372853
Validation loss: 2.8360698658551837

Epoch: 6| Step: 9
Training loss: 0.710175199853851
Validation loss: 2.8168509137162308

Epoch: 6| Step: 10
Training loss: 0.7447589297980566
Validation loss: 2.812970171587977

Epoch: 6| Step: 11
Training loss: 1.008053240743767
Validation loss: 2.749440056696773

Epoch: 6| Step: 12
Training loss: 0.8417327927274321
Validation loss: 2.7989966587347905

Epoch: 6| Step: 13
Training loss: 1.1939805532178496
Validation loss: 2.7240582527424237

Epoch: 453| Step: 0
Training loss: 1.0412889304330744
Validation loss: 2.755249936535473

Epoch: 6| Step: 1
Training loss: 1.5618117533285127
Validation loss: 2.771677868473113

Epoch: 6| Step: 2
Training loss: 0.5768800941068783
Validation loss: 2.7578304819704123

Epoch: 6| Step: 3
Training loss: 0.7908140325921084
Validation loss: 2.831350338514348

Epoch: 6| Step: 4
Training loss: 0.9779983340992225
Validation loss: 2.8710377382796373

Epoch: 6| Step: 5
Training loss: 0.6139456436361183
Validation loss: 2.810482573154715

Epoch: 6| Step: 6
Training loss: 0.8367930517322112
Validation loss: 2.783680564575102

Epoch: 6| Step: 7
Training loss: 0.929954939129986
Validation loss: 2.782563288798044

Epoch: 6| Step: 8
Training loss: 0.729193160166131
Validation loss: 2.7201450247413095

Epoch: 6| Step: 9
Training loss: 0.7260649423320916
Validation loss: 2.8323160664072224

Epoch: 6| Step: 10
Training loss: 1.1213484949847616
Validation loss: 2.751409646185467

Epoch: 6| Step: 11
Training loss: 0.769132210533879
Validation loss: 2.7913830503945802

Epoch: 6| Step: 12
Training loss: 2.029731300122211
Validation loss: 2.810627660237584

Epoch: 6| Step: 13
Training loss: 0.6864009655688904
Validation loss: 2.808280265902878

Epoch: 454| Step: 0
Training loss: 0.7711590044572436
Validation loss: 2.894859360576801

Epoch: 6| Step: 1
Training loss: 0.7914680599917995
Validation loss: 2.9161464681395866

Epoch: 6| Step: 2
Training loss: 0.8589239150380789
Validation loss: 2.8731063190035724

Epoch: 6| Step: 3
Training loss: 1.2610144287996106
Validation loss: 2.9068680041216752

Epoch: 6| Step: 4
Training loss: 0.8145124747700868
Validation loss: 2.864927268910904

Epoch: 6| Step: 5
Training loss: 0.9367535480465671
Validation loss: 2.829930103503716

Epoch: 6| Step: 6
Training loss: 0.6030836565542979
Validation loss: 2.8517041175548674

Epoch: 6| Step: 7
Training loss: 0.6578748659847354
Validation loss: 2.819411834022921

Epoch: 6| Step: 8
Training loss: 0.5893921291576555
Validation loss: 2.8281101626855265

Epoch: 6| Step: 9
Training loss: 0.9117159597424432
Validation loss: 2.7753069813790905

Epoch: 6| Step: 10
Training loss: 0.7193610454965738
Validation loss: 2.78020823538132

Epoch: 6| Step: 11
Training loss: 0.8352457553443964
Validation loss: 2.7388510118083134

Epoch: 6| Step: 12
Training loss: 1.7846074502392915
Validation loss: 2.7384804051452556

Epoch: 6| Step: 13
Training loss: 1.649453740294853
Validation loss: 2.7026482457504106

Epoch: 455| Step: 0
Training loss: 0.7803485246988648
Validation loss: 2.7623165909769316

Epoch: 6| Step: 1
Training loss: 0.9782870514908935
Validation loss: 2.7734412108203976

Epoch: 6| Step: 2
Training loss: 0.887852888736106
Validation loss: 2.8296730483479666

Epoch: 6| Step: 3
Training loss: 1.2311336597916958
Validation loss: 2.8139932271256374

Epoch: 6| Step: 4
Training loss: 0.735137381397653
Validation loss: 2.8158299901068817

Epoch: 6| Step: 5
Training loss: 0.7577981455908341
Validation loss: 2.916859965503963

Epoch: 6| Step: 6
Training loss: 1.0099194997867402
Validation loss: 2.7812069521655025

Epoch: 6| Step: 7
Training loss: 0.7823887727070347
Validation loss: 2.819392342130397

Epoch: 6| Step: 8
Training loss: 0.8466183333292837
Validation loss: 2.7478615075379555

Epoch: 6| Step: 9
Training loss: 1.6107361602022856
Validation loss: 2.717224789451867

Epoch: 6| Step: 10
Training loss: 1.1153025698146255
Validation loss: 2.6749880912254236

Epoch: 6| Step: 11
Training loss: 0.6658215729490856
Validation loss: 2.7321158240673067

Epoch: 6| Step: 12
Training loss: 1.5910653334845366
Validation loss: 2.7666285789886107

Epoch: 6| Step: 13
Training loss: 0.880026582240549
Validation loss: 2.7436201550021795

Epoch: 456| Step: 0
Training loss: 0.8718309234088
Validation loss: 2.779873896855909

Epoch: 6| Step: 1
Training loss: 0.49886297045995237
Validation loss: 2.738357970958289

Epoch: 6| Step: 2
Training loss: 0.9272019314004433
Validation loss: 2.739114341673207

Epoch: 6| Step: 3
Training loss: 0.6525856528937738
Validation loss: 2.7881876395271674

Epoch: 6| Step: 4
Training loss: 0.6576200217221906
Validation loss: 2.8387939807615354

Epoch: 6| Step: 5
Training loss: 1.663287129891226
Validation loss: 2.893807097957184

Epoch: 6| Step: 6
Training loss: 0.9828436611554286
Validation loss: 2.8371263154336566

Epoch: 6| Step: 7
Training loss: 0.9832295610877212
Validation loss: 2.808417543305189

Epoch: 6| Step: 8
Training loss: 1.3002860011430857
Validation loss: 2.808990549522718

Epoch: 6| Step: 9
Training loss: 0.7444543052213218
Validation loss: 2.7606496940477343

Epoch: 6| Step: 10
Training loss: 0.9240759099890984
Validation loss: 2.7519704232936784

Epoch: 6| Step: 11
Training loss: 0.970614577002238
Validation loss: 2.7101122051555318

Epoch: 6| Step: 12
Training loss: 1.5594375353182468
Validation loss: 2.7909356531351994

Epoch: 6| Step: 13
Training loss: 0.672257381124892
Validation loss: 2.786564068555845

Epoch: 457| Step: 0
Training loss: 0.7243451153282208
Validation loss: 2.7457612416514467

Epoch: 6| Step: 1
Training loss: 0.7732131324313936
Validation loss: 2.8203292381233744

Epoch: 6| Step: 2
Training loss: 0.7073098155536426
Validation loss: 2.7144594940566096

Epoch: 6| Step: 3
Training loss: 0.9098504989559766
Validation loss: 2.8024615678922595

Epoch: 6| Step: 4
Training loss: 0.7695920503869955
Validation loss: 2.8396057281021525

Epoch: 6| Step: 5
Training loss: 0.7832933407239768
Validation loss: 2.847659640839995

Epoch: 6| Step: 6
Training loss: 0.6343432855430078
Validation loss: 2.7432544802445427

Epoch: 6| Step: 7
Training loss: 1.5646605241056541
Validation loss: 2.8333748272120083

Epoch: 6| Step: 8
Training loss: 0.8271531214125425
Validation loss: 2.8449410400136186

Epoch: 6| Step: 9
Training loss: 0.7765489665335448
Validation loss: 2.8705318809404017

Epoch: 6| Step: 10
Training loss: 1.3562688747094642
Validation loss: 2.8767299008703695

Epoch: 6| Step: 11
Training loss: 1.692931863746467
Validation loss: 2.8376388560642236

Epoch: 6| Step: 12
Training loss: 0.5810121664949917
Validation loss: 2.820510913635934

Epoch: 6| Step: 13
Training loss: 0.9708304676673956
Validation loss: 2.7595202639956

Epoch: 458| Step: 0
Training loss: 0.5322025398642493
Validation loss: 2.7784105586818533

Epoch: 6| Step: 1
Training loss: 0.6833780656881526
Validation loss: 2.742405418149054

Epoch: 6| Step: 2
Training loss: 1.6696970648886955
Validation loss: 2.786635225094309

Epoch: 6| Step: 3
Training loss: 0.6801948626841043
Validation loss: 2.7635779410889776

Epoch: 6| Step: 4
Training loss: 1.4576395110008378
Validation loss: 2.756287539479493

Epoch: 6| Step: 5
Training loss: 0.6760424952411325
Validation loss: 2.758250445784894

Epoch: 6| Step: 6
Training loss: 0.4786734807190035
Validation loss: 2.8256027889524877

Epoch: 6| Step: 7
Training loss: 0.8412510635800037
Validation loss: 2.8616569599156576

Epoch: 6| Step: 8
Training loss: 1.0133264794766215
Validation loss: 2.8193555143474063

Epoch: 6| Step: 9
Training loss: 0.6726320348760584
Validation loss: 2.841960847194323

Epoch: 6| Step: 10
Training loss: 1.432146969046294
Validation loss: 2.8980348758095174

Epoch: 6| Step: 11
Training loss: 0.6976532272837259
Validation loss: 2.9187759583412785

Epoch: 6| Step: 12
Training loss: 0.913474912970234
Validation loss: 2.921665367725328

Epoch: 6| Step: 13
Training loss: 1.0808931831391242
Validation loss: 2.8344586933064786

Epoch: 459| Step: 0
Training loss: 1.5601140688493438
Validation loss: 2.836233538684511

Epoch: 6| Step: 1
Training loss: 1.0504534468868851
Validation loss: 2.789115798398193

Epoch: 6| Step: 2
Training loss: 0.7450801495187267
Validation loss: 2.816739398160226

Epoch: 6| Step: 3
Training loss: 0.6545440207059886
Validation loss: 2.791681351314658

Epoch: 6| Step: 4
Training loss: 0.8201920920512855
Validation loss: 2.758866250187704

Epoch: 6| Step: 5
Training loss: 1.456102090290383
Validation loss: 2.7493956219615985

Epoch: 6| Step: 6
Training loss: 0.6067914481747313
Validation loss: 2.8231594408282374

Epoch: 6| Step: 7
Training loss: 0.6721493803926515
Validation loss: 2.92394403649615

Epoch: 6| Step: 8
Training loss: 1.2930553211376297
Validation loss: 2.8836830292768365

Epoch: 6| Step: 9
Training loss: 0.9670233567187377
Validation loss: 2.9103172035852403

Epoch: 6| Step: 10
Training loss: 0.8482408748847561
Validation loss: 2.9794425214197386

Epoch: 6| Step: 11
Training loss: 0.9456090540780037
Validation loss: 2.8856061375148623

Epoch: 6| Step: 12
Training loss: 0.7011378500500974
Validation loss: 2.871774778668598

Epoch: 6| Step: 13
Training loss: 0.9542629140650134
Validation loss: 2.826458462778668

Epoch: 460| Step: 0
Training loss: 0.74467204985157
Validation loss: 2.7884756088745055

Epoch: 6| Step: 1
Training loss: 1.3319766125702137
Validation loss: 2.7512106542505035

Epoch: 6| Step: 2
Training loss: 1.0707416648567045
Validation loss: 2.734956908296258

Epoch: 6| Step: 3
Training loss: 0.8934165305805366
Validation loss: 2.732252666986694

Epoch: 6| Step: 4
Training loss: 0.733304562510019
Validation loss: 2.7720017132902885

Epoch: 6| Step: 5
Training loss: 0.9500581773712674
Validation loss: 2.7492376990467897

Epoch: 6| Step: 6
Training loss: 1.6425474982745962
Validation loss: 2.7826255368557984

Epoch: 6| Step: 7
Training loss: 0.7171859309027634
Validation loss: 2.780807717121202

Epoch: 6| Step: 8
Training loss: 0.612896111915394
Validation loss: 2.7959470719133503

Epoch: 6| Step: 9
Training loss: 0.6938187917333525
Validation loss: 2.908831212366709

Epoch: 6| Step: 10
Training loss: 0.9045529754712877
Validation loss: 2.924305250250921

Epoch: 6| Step: 11
Training loss: 1.6584340216709978
Validation loss: 2.8877340070574284

Epoch: 6| Step: 12
Training loss: 0.7817939390613592
Validation loss: 2.8485320130845406

Epoch: 6| Step: 13
Training loss: 0.5383300227643112
Validation loss: 2.841268553678142

Epoch: 461| Step: 0
Training loss: 0.8313974464837953
Validation loss: 2.7744978476162134

Epoch: 6| Step: 1
Training loss: 1.2991242723641863
Validation loss: 2.83027544687328

Epoch: 6| Step: 2
Training loss: 0.922046580753634
Validation loss: 2.7774238843128076

Epoch: 6| Step: 3
Training loss: 0.7129399530772038
Validation loss: 2.8123856980444595

Epoch: 6| Step: 4
Training loss: 0.5470992037448517
Validation loss: 2.796106684056982

Epoch: 6| Step: 5
Training loss: 0.6303777834702037
Validation loss: 2.7364269005507342

Epoch: 6| Step: 6
Training loss: 1.1702311875905838
Validation loss: 2.7327822887683886

Epoch: 6| Step: 7
Training loss: 1.5210300300939195
Validation loss: 2.7493772090490505

Epoch: 6| Step: 8
Training loss: 0.6448657468311968
Validation loss: 2.816600748754231

Epoch: 6| Step: 9
Training loss: 0.8138833007975081
Validation loss: 2.8222258638707225

Epoch: 6| Step: 10
Training loss: 1.5312292915033852
Validation loss: 2.8533144929373777

Epoch: 6| Step: 11
Training loss: 0.7900219362569313
Validation loss: 2.816017353298803

Epoch: 6| Step: 12
Training loss: 0.8452417467442676
Validation loss: 2.8505936879854956

Epoch: 6| Step: 13
Training loss: 0.8965634911559281
Validation loss: 2.87018538657171

Epoch: 462| Step: 0
Training loss: 0.9451571250150934
Validation loss: 2.8232686338326296

Epoch: 6| Step: 1
Training loss: 0.8053507617628768
Validation loss: 2.8173643220661653

Epoch: 6| Step: 2
Training loss: 0.6297299931578676
Validation loss: 2.7952812882527645

Epoch: 6| Step: 3
Training loss: 0.6678494129323695
Validation loss: 2.8115730029524015

Epoch: 6| Step: 4
Training loss: 1.4121679185732472
Validation loss: 2.8151820851616423

Epoch: 6| Step: 5
Training loss: 0.7957159102194112
Validation loss: 2.879219883501935

Epoch: 6| Step: 6
Training loss: 0.8577109090824907
Validation loss: 2.883579059192377

Epoch: 6| Step: 7
Training loss: 1.0788519246914572
Validation loss: 2.847157124547926

Epoch: 6| Step: 8
Training loss: 0.8133740492176615
Validation loss: 2.887509235626027

Epoch: 6| Step: 9
Training loss: 0.5876293932684169
Validation loss: 2.8515668825438105

Epoch: 6| Step: 10
Training loss: 0.9935395347800046
Validation loss: 2.9295888383994755

Epoch: 6| Step: 11
Training loss: 1.9890774854408686
Validation loss: 2.900727853746759

Epoch: 6| Step: 12
Training loss: 0.6648103429915859
Validation loss: 2.82398192985542

Epoch: 6| Step: 13
Training loss: 0.713909852387625
Validation loss: 2.847740391873539

Epoch: 463| Step: 0
Training loss: 0.8488960165231644
Validation loss: 2.7749605536879125

Epoch: 6| Step: 1
Training loss: 1.8976386002292633
Validation loss: 2.7836080263314

Epoch: 6| Step: 2
Training loss: 0.695710657540549
Validation loss: 2.8086105013698406

Epoch: 6| Step: 3
Training loss: 0.7443546578088399
Validation loss: 2.808173022991259

Epoch: 6| Step: 4
Training loss: 0.5911208216099432
Validation loss: 2.7210294441556333

Epoch: 6| Step: 5
Training loss: 0.6659379169851257
Validation loss: 2.8063889693504844

Epoch: 6| Step: 6
Training loss: 0.7185236947752389
Validation loss: 2.7835091263160225

Epoch: 6| Step: 7
Training loss: 0.9621830443142503
Validation loss: 2.770579854705114

Epoch: 6| Step: 8
Training loss: 0.7973127845523832
Validation loss: 2.8234301073167205

Epoch: 6| Step: 9
Training loss: 0.7956090482924147
Validation loss: 2.7961603597825397

Epoch: 6| Step: 10
Training loss: 1.3888146264037766
Validation loss: 2.7723499010260735

Epoch: 6| Step: 11
Training loss: 0.9013909267552058
Validation loss: 2.812890498991204

Epoch: 6| Step: 12
Training loss: 0.8361256824341776
Validation loss: 2.832991373706328

Epoch: 6| Step: 13
Training loss: 0.725509536848739
Validation loss: 2.8955089652716928

Epoch: 464| Step: 0
Training loss: 1.001176142450913
Validation loss: 2.807788590216372

Epoch: 6| Step: 1
Training loss: 0.7259513171191063
Validation loss: 2.883438579939064

Epoch: 6| Step: 2
Training loss: 0.6312951156810365
Validation loss: 2.898676928341777

Epoch: 6| Step: 3
Training loss: 0.8366286370828002
Validation loss: 2.853906081246894

Epoch: 6| Step: 4
Training loss: 1.874848613985449
Validation loss: 2.9063497956892514

Epoch: 6| Step: 5
Training loss: 0.6801355573230561
Validation loss: 2.893724954715055

Epoch: 6| Step: 6
Training loss: 1.1017144281034486
Validation loss: 2.90525164940622

Epoch: 6| Step: 7
Training loss: 0.8743340819289328
Validation loss: 2.9692101105295303

Epoch: 6| Step: 8
Training loss: 0.7705861717769468
Validation loss: 2.884595559043898

Epoch: 6| Step: 9
Training loss: 0.84605312373158
Validation loss: 2.902857670351273

Epoch: 6| Step: 10
Training loss: 0.721397210408024
Validation loss: 2.8382659264887713

Epoch: 6| Step: 11
Training loss: 0.718206448895346
Validation loss: 2.778037047737153

Epoch: 6| Step: 12
Training loss: 1.6124557341184833
Validation loss: 2.794350619686475

Epoch: 6| Step: 13
Training loss: 1.113721312165193
Validation loss: 2.824104486161575

Epoch: 465| Step: 0
Training loss: 0.5665672599563071
Validation loss: 2.8192519274620986

Epoch: 6| Step: 1
Training loss: 0.8153106054281825
Validation loss: 2.810036944127252

Epoch: 6| Step: 2
Training loss: 0.8655930716344841
Validation loss: 2.7307426449878824

Epoch: 6| Step: 3
Training loss: 1.3279946207115656
Validation loss: 2.799120436757277

Epoch: 6| Step: 4
Training loss: 0.7455100127685634
Validation loss: 2.8509898059176124

Epoch: 6| Step: 5
Training loss: 1.4478129434368756
Validation loss: 2.9458688333648357

Epoch: 6| Step: 6
Training loss: 0.7202825378673909
Validation loss: 2.990331301456462

Epoch: 6| Step: 7
Training loss: 0.9086013413142473
Validation loss: 2.9987138004299165

Epoch: 6| Step: 8
Training loss: 1.6461811985709356
Validation loss: 2.9655051182700736

Epoch: 6| Step: 9
Training loss: 0.5735346553312505
Validation loss: 2.97574284466068

Epoch: 6| Step: 10
Training loss: 0.8854152829028518
Validation loss: 2.9206182051452445

Epoch: 6| Step: 11
Training loss: 0.6434961966763062
Validation loss: 2.9096187086566534

Epoch: 6| Step: 12
Training loss: 1.0021521536074762
Validation loss: 2.8822236601197595

Epoch: 6| Step: 13
Training loss: 0.8712781360302816
Validation loss: 2.866421048783003

Epoch: 466| Step: 0
Training loss: 0.8705252259010383
Validation loss: 2.7892674389511383

Epoch: 6| Step: 1
Training loss: 1.2874931261193931
Validation loss: 2.7657967063345925

Epoch: 6| Step: 2
Training loss: 0.6723501831640529
Validation loss: 2.817307651162909

Epoch: 6| Step: 3
Training loss: 1.56572786705165
Validation loss: 2.783399779750604

Epoch: 6| Step: 4
Training loss: 0.7749800279566497
Validation loss: 2.849136546882186

Epoch: 6| Step: 5
Training loss: 0.5814471289952625
Validation loss: 2.785605759480398

Epoch: 6| Step: 6
Training loss: 1.746841236532045
Validation loss: 2.7974964637722635

Epoch: 6| Step: 7
Training loss: 0.8427685575023474
Validation loss: 2.8446075837117792

Epoch: 6| Step: 8
Training loss: 0.6767094582461677
Validation loss: 2.757629186717304

Epoch: 6| Step: 9
Training loss: 1.0191843897062727
Validation loss: 2.7532936082087827

Epoch: 6| Step: 10
Training loss: 0.7313419365757905
Validation loss: 2.807860298577788

Epoch: 6| Step: 11
Training loss: 0.8897787390213185
Validation loss: 2.8317770657527204

Epoch: 6| Step: 12
Training loss: 0.6263754967524063
Validation loss: 2.8243787059800423

Epoch: 6| Step: 13
Training loss: 0.6281144032130102
Validation loss: 2.790535261043376

Epoch: 467| Step: 0
Training loss: 0.4560745202271357
Validation loss: 2.8001740815906637

Epoch: 6| Step: 1
Training loss: 0.6971662861987681
Validation loss: 2.755119211718143

Epoch: 6| Step: 2
Training loss: 0.6144247389224796
Validation loss: 2.813753922294641

Epoch: 6| Step: 3
Training loss: 0.8418557485009098
Validation loss: 2.856057944264738

Epoch: 6| Step: 4
Training loss: 0.5709686685039802
Validation loss: 2.8394509821773624

Epoch: 6| Step: 5
Training loss: 0.8002617616370076
Validation loss: 2.8499476628768265

Epoch: 6| Step: 6
Training loss: 0.7647512471543337
Validation loss: 2.864864395687215

Epoch: 6| Step: 7
Training loss: 1.4011864096975353
Validation loss: 2.811424431178902

Epoch: 6| Step: 8
Training loss: 0.691260931401106
Validation loss: 2.7465090919134414

Epoch: 6| Step: 9
Training loss: 0.8388737954710996
Validation loss: 2.7511181869948227

Epoch: 6| Step: 10
Training loss: 0.7200157795607449
Validation loss: 2.77916445029045

Epoch: 6| Step: 11
Training loss: 0.77276771134881
Validation loss: 2.702903312162815

Epoch: 6| Step: 12
Training loss: 1.693509457107056
Validation loss: 2.800437945221827

Epoch: 6| Step: 13
Training loss: 1.2695242544128171
Validation loss: 2.7959975814517817

Epoch: 468| Step: 0
Training loss: 0.6879249039989922
Validation loss: 2.8389070374874423

Epoch: 6| Step: 1
Training loss: 0.681327944854933
Validation loss: 2.854894828262196

Epoch: 6| Step: 2
Training loss: 0.6431661773192768
Validation loss: 2.8368989279819874

Epoch: 6| Step: 3
Training loss: 0.932179804791599
Validation loss: 2.774713980050768

Epoch: 6| Step: 4
Training loss: 0.5292440296551714
Validation loss: 2.855546163126255

Epoch: 6| Step: 5
Training loss: 0.9119014788960645
Validation loss: 2.7803093823368314

Epoch: 6| Step: 6
Training loss: 0.8193658361788153
Validation loss: 2.7185437427491097

Epoch: 6| Step: 7
Training loss: 1.4815989183971914
Validation loss: 2.762612636565596

Epoch: 6| Step: 8
Training loss: 0.6855320942472657
Validation loss: 2.7690818576260257

Epoch: 6| Step: 9
Training loss: 0.6422238054245916
Validation loss: 2.7859688207064206

Epoch: 6| Step: 10
Training loss: 0.866426563626763
Validation loss: 2.790402444050678

Epoch: 6| Step: 11
Training loss: 1.479817591973594
Validation loss: 2.7615171050431173

Epoch: 6| Step: 12
Training loss: 1.331639833637516
Validation loss: 2.810495170663764

Epoch: 6| Step: 13
Training loss: 0.7889137883316334
Validation loss: 2.820931758506417

Epoch: 469| Step: 0
Training loss: 0.7815589675304899
Validation loss: 2.8327008597974492

Epoch: 6| Step: 1
Training loss: 0.6101530438874984
Validation loss: 2.8262745896351893

Epoch: 6| Step: 2
Training loss: 0.6581368342220442
Validation loss: 2.7864496438909976

Epoch: 6| Step: 3
Training loss: 0.8927645165217403
Validation loss: 2.8403259455651884

Epoch: 6| Step: 4
Training loss: 0.6827704130771718
Validation loss: 2.765150902408771

Epoch: 6| Step: 5
Training loss: 0.793051616679704
Validation loss: 2.8471780592638676

Epoch: 6| Step: 6
Training loss: 0.657573953900609
Validation loss: 2.8591838696357983

Epoch: 6| Step: 7
Training loss: 1.8644390227949155
Validation loss: 2.849551239710527

Epoch: 6| Step: 8
Training loss: 0.6999615607606685
Validation loss: 2.8285607551971497

Epoch: 6| Step: 9
Training loss: 0.8233376806224179
Validation loss: 2.879050525102245

Epoch: 6| Step: 10
Training loss: 1.5124683345285812
Validation loss: 2.815468394348279

Epoch: 6| Step: 11
Training loss: 0.4923976570624476
Validation loss: 2.827761336913547

Epoch: 6| Step: 12
Training loss: 0.8456723249434334
Validation loss: 2.7922621609027964

Epoch: 6| Step: 13
Training loss: 0.8399486387535958
Validation loss: 2.812755968667039

Epoch: 470| Step: 0
Training loss: 0.6317191627759621
Validation loss: 2.758513119380864

Epoch: 6| Step: 1
Training loss: 0.707284534251713
Validation loss: 2.7399437719223547

Epoch: 6| Step: 2
Training loss: 0.49723498421575857
Validation loss: 2.726534343235256

Epoch: 6| Step: 3
Training loss: 2.04126138622054
Validation loss: 2.812280194205698

Epoch: 6| Step: 4
Training loss: 0.6018659891264094
Validation loss: 2.7933380523025724

Epoch: 6| Step: 5
Training loss: 0.8597610300193474
Validation loss: 2.7632298991175888

Epoch: 6| Step: 6
Training loss: 0.6808931465987256
Validation loss: 2.8479407874320484

Epoch: 6| Step: 7
Training loss: 0.7743389001764716
Validation loss: 2.878656577503263

Epoch: 6| Step: 8
Training loss: 0.7236964806515801
Validation loss: 2.8386193687699697

Epoch: 6| Step: 9
Training loss: 0.8535720492290605
Validation loss: 2.874182059546448

Epoch: 6| Step: 10
Training loss: 1.3414522975156478
Validation loss: 2.819752983745786

Epoch: 6| Step: 11
Training loss: 0.2913091062975424
Validation loss: 2.8422467516901992

Epoch: 6| Step: 12
Training loss: 0.783447607984792
Validation loss: 2.8971459320677613

Epoch: 6| Step: 13
Training loss: 0.754816918501288
Validation loss: 2.8441750484745043

Epoch: 471| Step: 0
Training loss: 0.7791162726141305
Validation loss: 2.81772251560405

Epoch: 6| Step: 1
Training loss: 1.5766947846731474
Validation loss: 2.854459877453381

Epoch: 6| Step: 2
Training loss: 0.7389531383290568
Validation loss: 2.8388325860034405

Epoch: 6| Step: 3
Training loss: 0.8050869441023665
Validation loss: 2.7521702843405533

Epoch: 6| Step: 4
Training loss: 0.6159800052927621
Validation loss: 2.758704483401125

Epoch: 6| Step: 5
Training loss: 0.7242094514614049
Validation loss: 2.825367660003693

Epoch: 6| Step: 6
Training loss: 0.5334192473781149
Validation loss: 2.8423209739411277

Epoch: 6| Step: 7
Training loss: 0.5279059909663432
Validation loss: 2.837756705750638

Epoch: 6| Step: 8
Training loss: 0.7966025391576755
Validation loss: 2.8010437016440126

Epoch: 6| Step: 9
Training loss: 0.6821320956243665
Validation loss: 2.8015323413899984

Epoch: 6| Step: 10
Training loss: 1.5141829089460708
Validation loss: 2.7678875908297575

Epoch: 6| Step: 11
Training loss: 0.7944255657294509
Validation loss: 2.8718177488069947

Epoch: 6| Step: 12
Training loss: 0.7077509973344476
Validation loss: 2.878798035477482

Epoch: 6| Step: 13
Training loss: 1.139905049151032
Validation loss: 2.9380892980900755

Epoch: 472| Step: 0
Training loss: 0.9659856610369271
Validation loss: 2.8389217903792017

Epoch: 6| Step: 1
Training loss: 1.2558984824538886
Validation loss: 2.8354231943414585

Epoch: 6| Step: 2
Training loss: 1.5862382876036671
Validation loss: 2.795942410323012

Epoch: 6| Step: 3
Training loss: 0.6128329442576043
Validation loss: 2.8413595275981236

Epoch: 6| Step: 4
Training loss: 0.7389983473954157
Validation loss: 2.842756174555573

Epoch: 6| Step: 5
Training loss: 0.8814767505221681
Validation loss: 2.839302189754316

Epoch: 6| Step: 6
Training loss: 1.1426577287641169
Validation loss: 2.847539591481911

Epoch: 6| Step: 7
Training loss: 0.7770087128743538
Validation loss: 2.8638267257715735

Epoch: 6| Step: 8
Training loss: 0.6922249553526792
Validation loss: 2.8967379842464913

Epoch: 6| Step: 9
Training loss: 0.6801155321064809
Validation loss: 2.9293299477994186

Epoch: 6| Step: 10
Training loss: 0.7704070089369972
Validation loss: 2.8962910425370305

Epoch: 6| Step: 11
Training loss: 1.3567699595892124
Validation loss: 2.8555806734247824

Epoch: 6| Step: 12
Training loss: 0.6838465413939281
Validation loss: 2.7555669011588315

Epoch: 6| Step: 13
Training loss: 0.5377545452644077
Validation loss: 2.8336287839967667

Epoch: 473| Step: 0
Training loss: 1.2710209483919692
Validation loss: 2.7561778121802547

Epoch: 6| Step: 1
Training loss: 0.4328481432288516
Validation loss: 2.7132452267753275

Epoch: 6| Step: 2
Training loss: 0.7191181898373139
Validation loss: 2.772848032601839

Epoch: 6| Step: 3
Training loss: 1.0699319093198172
Validation loss: 2.7425488616986065

Epoch: 6| Step: 4
Training loss: 0.8894247031246554
Validation loss: 2.750667043184164

Epoch: 6| Step: 5
Training loss: 1.5508557357003623
Validation loss: 2.698900630034228

Epoch: 6| Step: 6
Training loss: 0.5285461563573239
Validation loss: 2.7363961878645116

Epoch: 6| Step: 7
Training loss: 0.7236450029548422
Validation loss: 2.801489676135207

Epoch: 6| Step: 8
Training loss: 1.3644116368881474
Validation loss: 2.793168664993411

Epoch: 6| Step: 9
Training loss: 0.8189176780865498
Validation loss: 2.845434172205875

Epoch: 6| Step: 10
Training loss: 0.8387907301994959
Validation loss: 2.850208040920596

Epoch: 6| Step: 11
Training loss: 0.694125158237444
Validation loss: 2.848127677558498

Epoch: 6| Step: 12
Training loss: 0.6404899361748138
Validation loss: 2.8383485267562536

Epoch: 6| Step: 13
Training loss: 0.780978155524196
Validation loss: 2.8079087965636527

Epoch: 474| Step: 0
Training loss: 0.5503686211480808
Validation loss: 2.882343285064734

Epoch: 6| Step: 1
Training loss: 0.6303583287158836
Validation loss: 2.760009078158316

Epoch: 6| Step: 2
Training loss: 1.2194582519579884
Validation loss: 2.807761516897159

Epoch: 6| Step: 3
Training loss: 1.306680493395175
Validation loss: 2.7563428411900666

Epoch: 6| Step: 4
Training loss: 0.9494710202407325
Validation loss: 2.872931593279182

Epoch: 6| Step: 5
Training loss: 0.6928369407489541
Validation loss: 2.8870119764094784

Epoch: 6| Step: 6
Training loss: 0.8262784271428621
Validation loss: 2.8626009422172944

Epoch: 6| Step: 7
Training loss: 0.7725510574800699
Validation loss: 2.885603011594681

Epoch: 6| Step: 8
Training loss: 0.6135629869350131
Validation loss: 2.868284343084629

Epoch: 6| Step: 9
Training loss: 1.5317341564586238
Validation loss: 2.8178226826158648

Epoch: 6| Step: 10
Training loss: 0.5886116042541883
Validation loss: 2.898512271214848

Epoch: 6| Step: 11
Training loss: 0.9065010775324566
Validation loss: 2.835006084514101

Epoch: 6| Step: 12
Training loss: 0.6004599586416995
Validation loss: 2.951333930806606

Epoch: 6| Step: 13
Training loss: 0.8528741656437281
Validation loss: 2.8255521617271824

Epoch: 475| Step: 0
Training loss: 0.7385880574522885
Validation loss: 2.834925181003157

Epoch: 6| Step: 1
Training loss: 0.612105925939175
Validation loss: 2.7668083087635162

Epoch: 6| Step: 2
Training loss: 0.6065162703178525
Validation loss: 2.788607277927761

Epoch: 6| Step: 3
Training loss: 0.5649010751846705
Validation loss: 2.813607372282665

Epoch: 6| Step: 4
Training loss: 0.7939718131772274
Validation loss: 2.8103229715401126

Epoch: 6| Step: 5
Training loss: 0.5795833905446481
Validation loss: 2.867017513991155

Epoch: 6| Step: 6
Training loss: 0.6574636544672408
Validation loss: 2.8240494701538967

Epoch: 6| Step: 7
Training loss: 0.7027027557706614
Validation loss: 2.8389402313860903

Epoch: 6| Step: 8
Training loss: 1.4664222452208935
Validation loss: 2.814818168648828

Epoch: 6| Step: 9
Training loss: 1.5762493204331653
Validation loss: 2.7787839550712805

Epoch: 6| Step: 10
Training loss: 0.6552517883090082
Validation loss: 2.8262807547847286

Epoch: 6| Step: 11
Training loss: 0.6637822176770575
Validation loss: 2.8792599340441196

Epoch: 6| Step: 12
Training loss: 0.45726421320136934
Validation loss: 2.8235877859246012

Epoch: 6| Step: 13
Training loss: 1.0854469673383926
Validation loss: 2.954091003230956

Epoch: 476| Step: 0
Training loss: 0.575100772776024
Validation loss: 2.889948186596916

Epoch: 6| Step: 1
Training loss: 0.7194271215254123
Validation loss: 2.9883576559965848

Epoch: 6| Step: 2
Training loss: 0.6516968266182014
Validation loss: 2.890230663998524

Epoch: 6| Step: 3
Training loss: 0.6136982465938081
Validation loss: 2.970614627386896

Epoch: 6| Step: 4
Training loss: 0.6456141766566915
Validation loss: 2.869066473320992

Epoch: 6| Step: 5
Training loss: 0.4191225117291847
Validation loss: 2.8529779413714054

Epoch: 6| Step: 6
Training loss: 0.7319562321903442
Validation loss: 2.8490820839811923

Epoch: 6| Step: 7
Training loss: 0.7023154154356575
Validation loss: 2.8719132064917887

Epoch: 6| Step: 8
Training loss: 0.8357308034172769
Validation loss: 2.8011221862167823

Epoch: 6| Step: 9
Training loss: 0.7076886740323302
Validation loss: 2.7772095295038888

Epoch: 6| Step: 10
Training loss: 0.43685344195350895
Validation loss: 2.781115968024913

Epoch: 6| Step: 11
Training loss: 0.6204490434470616
Validation loss: 2.843169324228461

Epoch: 6| Step: 12
Training loss: 2.079486257674167
Validation loss: 2.8217327877693723

Epoch: 6| Step: 13
Training loss: 1.3439784188524704
Validation loss: 2.9075139213047234

Epoch: 477| Step: 0
Training loss: 1.5273871452235164
Validation loss: 2.8826951551805857

Epoch: 6| Step: 1
Training loss: 0.3640436969862156
Validation loss: 2.849513881339177

Epoch: 6| Step: 2
Training loss: 1.0276343801200463
Validation loss: 2.936458213529193

Epoch: 6| Step: 3
Training loss: 1.0905749968075575
Validation loss: 2.9567377506672288

Epoch: 6| Step: 4
Training loss: 0.6928466405444761
Validation loss: 3.0294522463488214

Epoch: 6| Step: 5
Training loss: 0.7898858184628974
Validation loss: 2.990384188436647

Epoch: 6| Step: 6
Training loss: 0.9186942622086856
Validation loss: 2.9820305901315884

Epoch: 6| Step: 7
Training loss: 0.5867740762482018
Validation loss: 2.911173870859681

Epoch: 6| Step: 8
Training loss: 0.7791949901090766
Validation loss: 2.845229773424698

Epoch: 6| Step: 9
Training loss: 0.5400089027854162
Validation loss: 2.7377164496749105

Epoch: 6| Step: 10
Training loss: 0.6817572201583249
Validation loss: 2.790575260119197

Epoch: 6| Step: 11
Training loss: 0.4595873179858138
Validation loss: 2.749369881427102

Epoch: 6| Step: 12
Training loss: 1.47799935643617
Validation loss: 2.7243070993044447

Epoch: 6| Step: 13
Training loss: 0.8424779698918617
Validation loss: 2.7239102176382146

Epoch: 478| Step: 0
Training loss: 1.4496082697550354
Validation loss: 2.793273197822611

Epoch: 6| Step: 1
Training loss: 0.8078663083127886
Validation loss: 2.885380745858114

Epoch: 6| Step: 2
Training loss: 1.102366485469389
Validation loss: 2.8849133948908254

Epoch: 6| Step: 3
Training loss: 0.8589012227181061
Validation loss: 2.9153383681751563

Epoch: 6| Step: 4
Training loss: 0.8257941426377775
Validation loss: 2.99633049392212

Epoch: 6| Step: 5
Training loss: 0.6898676676940266
Validation loss: 2.9799059948612543

Epoch: 6| Step: 6
Training loss: 1.6202129131087437
Validation loss: 2.970771837244498

Epoch: 6| Step: 7
Training loss: 0.8888819854852377
Validation loss: 3.020328760210221

Epoch: 6| Step: 8
Training loss: 0.7653281745847544
Validation loss: 2.9028971894407793

Epoch: 6| Step: 9
Training loss: 0.6477628208365354
Validation loss: 2.93192534702269

Epoch: 6| Step: 10
Training loss: 0.5890860585730544
Validation loss: 2.87490348377484

Epoch: 6| Step: 11
Training loss: 0.5673731213790878
Validation loss: 2.836417781910271

Epoch: 6| Step: 12
Training loss: 0.7273047972511616
Validation loss: 2.8181368395636395

Epoch: 6| Step: 13
Training loss: 0.6205556205700907
Validation loss: 2.7667996198428813

Epoch: 479| Step: 0
Training loss: 0.9818393808140959
Validation loss: 2.8163180396965495

Epoch: 6| Step: 1
Training loss: 0.8982125373818983
Validation loss: 2.7500448656757164

Epoch: 6| Step: 2
Training loss: 0.5430755235811802
Validation loss: 2.7853633166967207

Epoch: 6| Step: 3
Training loss: 0.8258466147950027
Validation loss: 2.813453795157649

Epoch: 6| Step: 4
Training loss: 0.7010485187288233
Validation loss: 2.8128451665365803

Epoch: 6| Step: 5
Training loss: 0.5487983668394784
Validation loss: 2.798443558638628

Epoch: 6| Step: 6
Training loss: 0.781786009971375
Validation loss: 2.8745465266528223

Epoch: 6| Step: 7
Training loss: 1.31602223395491
Validation loss: 2.851063528779661

Epoch: 6| Step: 8
Training loss: 1.5851318116839992
Validation loss: 2.9051556184530987

Epoch: 6| Step: 9
Training loss: 0.7117098710378298
Validation loss: 2.8655928803740807

Epoch: 6| Step: 10
Training loss: 0.5126692701719241
Validation loss: 2.8541161655682523

Epoch: 6| Step: 11
Training loss: 1.063665424037372
Validation loss: 2.8930365186131994

Epoch: 6| Step: 12
Training loss: 0.8019399679956283
Validation loss: 2.9665847511626375

Epoch: 6| Step: 13
Training loss: 0.8923549247820829
Validation loss: 2.9086643568020007

Epoch: 480| Step: 0
Training loss: 0.6384199853138707
Validation loss: 2.9532530822427816

Epoch: 6| Step: 1
Training loss: 1.140259880258969
Validation loss: 2.929601737568498

Epoch: 6| Step: 2
Training loss: 0.8448940574098388
Validation loss: 2.8983451780574767

Epoch: 6| Step: 3
Training loss: 0.5154799054925553
Validation loss: 2.8004354478928706

Epoch: 6| Step: 4
Training loss: 0.46441090089484005
Validation loss: 2.89270409398403

Epoch: 6| Step: 5
Training loss: 0.4670254933579
Validation loss: 2.814417150312965

Epoch: 6| Step: 6
Training loss: 0.5701023916668416
Validation loss: 2.8411969192811846

Epoch: 6| Step: 7
Training loss: 0.667548845161306
Validation loss: 2.8610105301379765

Epoch: 6| Step: 8
Training loss: 0.6964416978633031
Validation loss: 2.8167523909019434

Epoch: 6| Step: 9
Training loss: 0.6169104859832913
Validation loss: 2.8631391919377003

Epoch: 6| Step: 10
Training loss: 0.7458409385364442
Validation loss: 2.9175309172329347

Epoch: 6| Step: 11
Training loss: 1.539049952112158
Validation loss: 2.855447653411152

Epoch: 6| Step: 12
Training loss: 0.8675760996527392
Validation loss: 2.824769926126535

Epoch: 6| Step: 13
Training loss: 1.1505190092768556
Validation loss: 2.899299568784298

Epoch: 481| Step: 0
Training loss: 0.9017306139675645
Validation loss: 2.981820922608536

Epoch: 6| Step: 1
Training loss: 0.7907397884224524
Validation loss: 3.028136053284955

Epoch: 6| Step: 2
Training loss: 1.4966806401037276
Validation loss: 3.1806020835090374

Epoch: 6| Step: 3
Training loss: 0.681392110648584
Validation loss: 3.0645207465908277

Epoch: 6| Step: 4
Training loss: 1.0094308796346028
Validation loss: 3.1050480395668902

Epoch: 6| Step: 5
Training loss: 0.7172614730550254
Validation loss: 2.9348021624605294

Epoch: 6| Step: 6
Training loss: 1.3326131047668937
Validation loss: 2.912574736000554

Epoch: 6| Step: 7
Training loss: 0.7020085477947074
Validation loss: 2.8065424516816466

Epoch: 6| Step: 8
Training loss: 0.6253834978373014
Validation loss: 2.8310236820042047

Epoch: 6| Step: 9
Training loss: 1.3487580149415082
Validation loss: 2.9021337064345256

Epoch: 6| Step: 10
Training loss: 0.5784984619561985
Validation loss: 2.7489380953671265

Epoch: 6| Step: 11
Training loss: 0.6731055767122444
Validation loss: 2.8321465269282697

Epoch: 6| Step: 12
Training loss: 0.7206651631103461
Validation loss: 2.887524235611309

Epoch: 6| Step: 13
Training loss: 0.6776230470537374
Validation loss: 2.787933961876118

Epoch: 482| Step: 0
Training loss: 0.5887247042881056
Validation loss: 2.8488312343627693

Epoch: 6| Step: 1
Training loss: 0.529135309877261
Validation loss: 2.8559809902397317

Epoch: 6| Step: 2
Training loss: 0.6945254339568924
Validation loss: 2.8445691266917406

Epoch: 6| Step: 3
Training loss: 0.6107652162724564
Validation loss: 2.8173113041997557

Epoch: 6| Step: 4
Training loss: 0.8612623816764218
Validation loss: 2.86005105953388

Epoch: 6| Step: 5
Training loss: 0.6273882535396036
Validation loss: 2.815930033936243

Epoch: 6| Step: 6
Training loss: 0.72598370704286
Validation loss: 2.8399321670445774

Epoch: 6| Step: 7
Training loss: 1.2117237614836072
Validation loss: 2.818217759728222

Epoch: 6| Step: 8
Training loss: 0.924387852990149
Validation loss: 2.8646872253073834

Epoch: 6| Step: 9
Training loss: 0.9464825726600958
Validation loss: 2.7569541423850175

Epoch: 6| Step: 10
Training loss: 0.5995942154250941
Validation loss: 2.8385902237311615

Epoch: 6| Step: 11
Training loss: 0.6961395188686001
Validation loss: 2.861731345242446

Epoch: 6| Step: 12
Training loss: 0.8616457329782923
Validation loss: 2.8300314812318943

Epoch: 6| Step: 13
Training loss: 1.7940699700666964
Validation loss: 2.8810574807194094

Epoch: 483| Step: 0
Training loss: 0.6029639824695822
Validation loss: 2.950742429855484

Epoch: 6| Step: 1
Training loss: 1.5665795285090625
Validation loss: 2.8891878696745943

Epoch: 6| Step: 2
Training loss: 0.5986080195658608
Validation loss: 2.907462793332467

Epoch: 6| Step: 3
Training loss: 0.6450408770301739
Validation loss: 2.8377383900797173

Epoch: 6| Step: 4
Training loss: 0.8966469212193238
Validation loss: 2.859779815645567

Epoch: 6| Step: 5
Training loss: 0.6504271442596601
Validation loss: 2.867677402479641

Epoch: 6| Step: 6
Training loss: 0.5966941219900174
Validation loss: 2.8889810440961834

Epoch: 6| Step: 7
Training loss: 1.2595464944620864
Validation loss: 2.8306105704967006

Epoch: 6| Step: 8
Training loss: 0.49149264378247637
Validation loss: 2.8015583260273376

Epoch: 6| Step: 9
Training loss: 0.5488078429251827
Validation loss: 2.857818638548351

Epoch: 6| Step: 10
Training loss: 1.2034795659750956
Validation loss: 2.8075615228856887

Epoch: 6| Step: 11
Training loss: 0.5499157971169425
Validation loss: 2.7651110672674526

Epoch: 6| Step: 12
Training loss: 0.7369381429264867
Validation loss: 2.8995892891592225

Epoch: 6| Step: 13
Training loss: 0.6429283324061121
Validation loss: 2.829057725841736

Epoch: 484| Step: 0
Training loss: 0.5507126352844897
Validation loss: 2.8976978821830763

Epoch: 6| Step: 1
Training loss: 0.9457648905106972
Validation loss: 2.902159365397165

Epoch: 6| Step: 2
Training loss: 0.633187241916907
Validation loss: 2.942741452371128

Epoch: 6| Step: 3
Training loss: 0.5823334287113111
Validation loss: 2.8811674446862097

Epoch: 6| Step: 4
Training loss: 0.7047067863717884
Validation loss: 2.918990263215767

Epoch: 6| Step: 5
Training loss: 1.1088953727542374
Validation loss: 2.935688001024207

Epoch: 6| Step: 6
Training loss: 0.4089357290694557
Validation loss: 2.929347921400537

Epoch: 6| Step: 7
Training loss: 0.8960612842428907
Validation loss: 2.858103624090567

Epoch: 6| Step: 8
Training loss: 0.6099130504815586
Validation loss: 2.8625877133719495

Epoch: 6| Step: 9
Training loss: 1.58201233652371
Validation loss: 2.8606527284335823

Epoch: 6| Step: 10
Training loss: 1.217498234271702
Validation loss: 2.8333430336804857

Epoch: 6| Step: 11
Training loss: 0.749725609494881
Validation loss: 2.791668156485848

Epoch: 6| Step: 12
Training loss: 0.7012944658906629
Validation loss: 2.8772834334420136

Epoch: 6| Step: 13
Training loss: 0.5898427394833025
Validation loss: 2.869986239631797

Epoch: 485| Step: 0
Training loss: 0.8538741487016596
Validation loss: 2.865516626159256

Epoch: 6| Step: 1
Training loss: 0.48929621684703023
Validation loss: 2.8869540850321576

Epoch: 6| Step: 2
Training loss: 1.8678526391957393
Validation loss: 2.9120708405887203

Epoch: 6| Step: 3
Training loss: 0.7498287164286375
Validation loss: 2.8406677240083105

Epoch: 6| Step: 4
Training loss: 0.5100620913107186
Validation loss: 2.8403519390427845

Epoch: 6| Step: 5
Training loss: 0.5641504552006121
Validation loss: 2.8070849529494026

Epoch: 6| Step: 6
Training loss: 0.9711159455761963
Validation loss: 2.8082880906970624

Epoch: 6| Step: 7
Training loss: 0.8046060169037664
Validation loss: 2.8200691660612196

Epoch: 6| Step: 8
Training loss: 0.5403004956828626
Validation loss: 2.84211042319586

Epoch: 6| Step: 9
Training loss: 0.6222817916350526
Validation loss: 2.8061233146409004

Epoch: 6| Step: 10
Training loss: 0.655683136390694
Validation loss: 2.8462788443038494

Epoch: 6| Step: 11
Training loss: 0.46271778855617113
Validation loss: 2.8869866370312582

Epoch: 6| Step: 12
Training loss: 0.7342655019088096
Validation loss: 2.9012365543963896

Epoch: 6| Step: 13
Training loss: 0.7807333573086179
Validation loss: 2.881633003800153

Epoch: 486| Step: 0
Training loss: 0.8181062366032921
Validation loss: 2.879668619221972

Epoch: 6| Step: 1
Training loss: 0.9457618023939871
Validation loss: 2.8543174778060854

Epoch: 6| Step: 2
Training loss: 0.658792407391785
Validation loss: 2.8742190212489147

Epoch: 6| Step: 3
Training loss: 0.7125182551002927
Validation loss: 2.88812185970142

Epoch: 6| Step: 4
Training loss: 1.6699270147947218
Validation loss: 2.8916787778470656

Epoch: 6| Step: 5
Training loss: 0.6420250225345353
Validation loss: 2.855898941691926

Epoch: 6| Step: 6
Training loss: 0.6812977187916505
Validation loss: 2.8033144254269815

Epoch: 6| Step: 7
Training loss: 0.5727845530916547
Validation loss: 2.8346060717910526

Epoch: 6| Step: 8
Training loss: 0.5436214119588191
Validation loss: 2.916736919828555

Epoch: 6| Step: 9
Training loss: 0.6365861110962062
Validation loss: 2.8884362947265503

Epoch: 6| Step: 10
Training loss: 0.687083421556395
Validation loss: 2.9013582167630654

Epoch: 6| Step: 11
Training loss: 1.155711693077945
Validation loss: 2.9809203999336105

Epoch: 6| Step: 12
Training loss: 0.6618241902805917
Validation loss: 2.9099136968314374

Epoch: 6| Step: 13
Training loss: 0.8493582167942708
Validation loss: 2.883785603907968

Epoch: 487| Step: 0
Training loss: 0.8175015927220499
Validation loss: 2.9053967361572615

Epoch: 6| Step: 1
Training loss: 0.6501913137590831
Validation loss: 2.9426626061231596

Epoch: 6| Step: 2
Training loss: 0.5711910848474797
Validation loss: 2.8697574472666103

Epoch: 6| Step: 3
Training loss: 0.7550232671474575
Validation loss: 2.9032425718723536

Epoch: 6| Step: 4
Training loss: 0.5766698721794752
Validation loss: 2.8630446075586753

Epoch: 6| Step: 5
Training loss: 0.6743153455368196
Validation loss: 2.8667000088490013

Epoch: 6| Step: 6
Training loss: 0.6651513541222674
Validation loss: 2.7957327444189928

Epoch: 6| Step: 7
Training loss: 0.637538452484716
Validation loss: 2.8575511598053938

Epoch: 6| Step: 8
Training loss: 0.6293140297747135
Validation loss: 2.8522459282422616

Epoch: 6| Step: 9
Training loss: 1.606934632330263
Validation loss: 2.938593491822176

Epoch: 6| Step: 10
Training loss: 1.0500448830412261
Validation loss: 2.8127879525172914

Epoch: 6| Step: 11
Training loss: 0.5228294142719186
Validation loss: 2.828393083936698

Epoch: 6| Step: 12
Training loss: 0.5708432275606086
Validation loss: 2.9126134001739894

Epoch: 6| Step: 13
Training loss: 1.2476333625619445
Validation loss: 2.8562159780400114

Epoch: 488| Step: 0
Training loss: 0.7621619084727783
Validation loss: 2.8515568842026964

Epoch: 6| Step: 1
Training loss: 1.9207085892337936
Validation loss: 2.861037460683684

Epoch: 6| Step: 2
Training loss: 0.4881840876229389
Validation loss: 2.9240524895627713

Epoch: 6| Step: 3
Training loss: 0.6479245650452958
Validation loss: 2.8355745165571946

Epoch: 6| Step: 4
Training loss: 0.8744309823122727
Validation loss: 2.894654127662533

Epoch: 6| Step: 5
Training loss: 0.6496373760636589
Validation loss: 2.9957216007652625

Epoch: 6| Step: 6
Training loss: 0.38638751939787885
Validation loss: 2.9047195889713335

Epoch: 6| Step: 7
Training loss: 0.8193450308875972
Validation loss: 2.8910698075911117

Epoch: 6| Step: 8
Training loss: 0.5406996978576194
Validation loss: 2.843825971545761

Epoch: 6| Step: 9
Training loss: 0.6378824564030572
Validation loss: 2.8411469055975624

Epoch: 6| Step: 10
Training loss: 0.6121114520224538
Validation loss: 2.8541394717366497

Epoch: 6| Step: 11
Training loss: 0.716039314440039
Validation loss: 2.848971439496474

Epoch: 6| Step: 12
Training loss: 1.0694741634406555
Validation loss: 2.7509758113868634

Epoch: 6| Step: 13
Training loss: 0.6554730220832781
Validation loss: 2.80191339216181

Epoch: 489| Step: 0
Training loss: 0.864611674997082
Validation loss: 2.7837829771059885

Epoch: 6| Step: 1
Training loss: 0.618319186111341
Validation loss: 2.8058829420791374

Epoch: 6| Step: 2
Training loss: 0.4219900433543165
Validation loss: 2.911876728018866

Epoch: 6| Step: 3
Training loss: 0.46579225723584505
Validation loss: 2.9138579241385507

Epoch: 6| Step: 4
Training loss: 0.550506415008393
Validation loss: 2.90935801368942

Epoch: 6| Step: 5
Training loss: 1.1010270677438971
Validation loss: 2.9238600897968823

Epoch: 6| Step: 6
Training loss: 0.4750656164172736
Validation loss: 2.914718758575063

Epoch: 6| Step: 7
Training loss: 1.494301701259353
Validation loss: 2.896643756194942

Epoch: 6| Step: 8
Training loss: 0.46163459372345056
Validation loss: 2.8868290902034572

Epoch: 6| Step: 9
Training loss: 0.9426821534682296
Validation loss: 2.8710692527919615

Epoch: 6| Step: 10
Training loss: 0.9015586046369418
Validation loss: 2.9114413639090433

Epoch: 6| Step: 11
Training loss: 0.5355832143929548
Validation loss: 2.89441958343737

Epoch: 6| Step: 12
Training loss: 1.0381910068167282
Validation loss: 2.855097421697556

Epoch: 6| Step: 13
Training loss: 0.7163356783686342
Validation loss: 2.91713460619907

Epoch: 490| Step: 0
Training loss: 0.5707161924731716
Validation loss: 2.899077654096455

Epoch: 6| Step: 1
Training loss: 0.7127121375312367
Validation loss: 2.9479479479169104

Epoch: 6| Step: 2
Training loss: 0.5782261837228526
Validation loss: 2.922519728303298

Epoch: 6| Step: 3
Training loss: 0.8653420409301795
Validation loss: 2.9591654471378144

Epoch: 6| Step: 4
Training loss: 0.608062406417772
Validation loss: 2.9067172423462737

Epoch: 6| Step: 5
Training loss: 0.6860547480381982
Validation loss: 2.897535130504781

Epoch: 6| Step: 6
Training loss: 0.6275383425392939
Validation loss: 2.830449969932817

Epoch: 6| Step: 7
Training loss: 1.6040230063312957
Validation loss: 2.836638329872788

Epoch: 6| Step: 8
Training loss: 0.6966316696400782
Validation loss: 2.8583772513201016

Epoch: 6| Step: 9
Training loss: 0.6813503401469552
Validation loss: 2.853564363586021

Epoch: 6| Step: 10
Training loss: 0.5596625500032127
Validation loss: 2.802886086853744

Epoch: 6| Step: 11
Training loss: 1.5100228508742355
Validation loss: 2.8499864098297367

Epoch: 6| Step: 12
Training loss: 0.4692237049899314
Validation loss: 2.872637482914586

Epoch: 6| Step: 13
Training loss: 0.3562472067271699
Validation loss: 2.872609720483524

Epoch: 491| Step: 0
Training loss: 1.091016569044973
Validation loss: 2.8743571931138527

Epoch: 6| Step: 1
Training loss: 0.6819398982687883
Validation loss: 2.951425322264146

Epoch: 6| Step: 2
Training loss: 0.6481540474042918
Validation loss: 2.9822971107219147

Epoch: 6| Step: 3
Training loss: 0.5215668916603088
Validation loss: 2.961723028844186

Epoch: 6| Step: 4
Training loss: 0.5552600538295954
Validation loss: 2.8953713155976994

Epoch: 6| Step: 5
Training loss: 0.7022396447547758
Validation loss: 2.9192356285583654

Epoch: 6| Step: 6
Training loss: 0.5424990921188704
Validation loss: 2.8116695166910497

Epoch: 6| Step: 7
Training loss: 0.6721949591726007
Validation loss: 2.8188072830323

Epoch: 6| Step: 8
Training loss: 0.41898169726316836
Validation loss: 2.8727795969072205

Epoch: 6| Step: 9
Training loss: 1.6002703408496644
Validation loss: 2.880871609591782

Epoch: 6| Step: 10
Training loss: 0.7712321194967194
Validation loss: 2.766715644686321

Epoch: 6| Step: 11
Training loss: 0.5919967918002987
Validation loss: 2.862922344117931

Epoch: 6| Step: 12
Training loss: 0.7873120295514182
Validation loss: 2.8878603524605757

Epoch: 6| Step: 13
Training loss: 1.2106731003091102
Validation loss: 2.8823464283062465

Epoch: 492| Step: 0
Training loss: 1.5411468952773049
Validation loss: 2.854921245836029

Epoch: 6| Step: 1
Training loss: 0.6556264776207753
Validation loss: 2.9108151639307036

Epoch: 6| Step: 2
Training loss: 0.6311181544482103
Validation loss: 2.7936727850226126

Epoch: 6| Step: 3
Training loss: 0.896325988740386
Validation loss: 2.8706575023323526

Epoch: 6| Step: 4
Training loss: 1.2673363124331463
Validation loss: 2.8629292978263394

Epoch: 6| Step: 5
Training loss: 0.5648813174511336
Validation loss: 2.8459398410762775

Epoch: 6| Step: 6
Training loss: 0.75414189426209
Validation loss: 2.8896647464987693

Epoch: 6| Step: 7
Training loss: 0.7518941484583052
Validation loss: 2.8447924928350843

Epoch: 6| Step: 8
Training loss: 0.4886303988510024
Validation loss: 2.8585535617063114

Epoch: 6| Step: 9
Training loss: 0.6346207673504772
Validation loss: 2.8766795518423733

Epoch: 6| Step: 10
Training loss: 0.5247917875032587
Validation loss: 2.814268248621184

Epoch: 6| Step: 11
Training loss: 0.7241100225547576
Validation loss: 2.905949224953039

Epoch: 6| Step: 12
Training loss: 0.45631189057179233
Validation loss: 2.8508100239695557

Epoch: 6| Step: 13
Training loss: 0.7933988109649911
Validation loss: 2.966101552595331

Epoch: 493| Step: 0
Training loss: 0.6715248437462553
Validation loss: 2.896173187365599

Epoch: 6| Step: 1
Training loss: 0.7424226087317484
Validation loss: 2.8190153455213958

Epoch: 6| Step: 2
Training loss: 0.9917079938296528
Validation loss: 2.8269058325491248

Epoch: 6| Step: 3
Training loss: 1.161902093432926
Validation loss: 2.7664210580097137

Epoch: 6| Step: 4
Training loss: 0.5197204589485356
Validation loss: 2.8128534448143556

Epoch: 6| Step: 5
Training loss: 0.488160843308579
Validation loss: 2.785322757717609

Epoch: 6| Step: 6
Training loss: 0.6758384018914517
Validation loss: 2.876555547199898

Epoch: 6| Step: 7
Training loss: 0.4503956843254941
Validation loss: 2.911952859896967

Epoch: 6| Step: 8
Training loss: 0.7215051504468121
Validation loss: 2.905444166792869

Epoch: 6| Step: 9
Training loss: 0.7022337881534431
Validation loss: 2.9342913181342336

Epoch: 6| Step: 10
Training loss: 0.7149538882931955
Validation loss: 2.8755247425029054

Epoch: 6| Step: 11
Training loss: 0.5792696935510652
Validation loss: 2.8226208737139076

Epoch: 6| Step: 12
Training loss: 1.5738826421298093
Validation loss: 2.833702769223119

Epoch: 6| Step: 13
Training loss: 0.9204802549669863
Validation loss: 2.788606736444386

Epoch: 494| Step: 0
Training loss: 0.6759849638197767
Validation loss: 2.7593243123025553

Epoch: 6| Step: 1
Training loss: 1.5723975463871334
Validation loss: 2.790472619829229

Epoch: 6| Step: 2
Training loss: 0.8918086769235397
Validation loss: 2.7632950129304192

Epoch: 6| Step: 3
Training loss: 0.6762670854324567
Validation loss: 2.847572077731194

Epoch: 6| Step: 4
Training loss: 0.5118080236006497
Validation loss: 2.804247787137352

Epoch: 6| Step: 5
Training loss: 0.5488795734876096
Validation loss: 2.88629389532762

Epoch: 6| Step: 6
Training loss: 0.49962485664485873
Validation loss: 2.878206676162287

Epoch: 6| Step: 7
Training loss: 0.63780519902762
Validation loss: 2.8979247291684973

Epoch: 6| Step: 8
Training loss: 0.5245040731062802
Validation loss: 2.932783967470237

Epoch: 6| Step: 9
Training loss: 0.9403195262176088
Validation loss: 2.9358552968263614

Epoch: 6| Step: 10
Training loss: 0.6379790675188283
Validation loss: 2.918957428297106

Epoch: 6| Step: 11
Training loss: 0.7369915632052292
Validation loss: 2.892408724470929

Epoch: 6| Step: 12
Training loss: 1.093484791891065
Validation loss: 2.837855857571391

Epoch: 6| Step: 13
Training loss: 0.7432147897257864
Validation loss: 2.8543940868871323

Epoch: 495| Step: 0
Training loss: 0.9886060942278135
Validation loss: 2.8743390277188423

Epoch: 6| Step: 1
Training loss: 0.6366030113951358
Validation loss: 2.863656665152972

Epoch: 6| Step: 2
Training loss: 0.6355008371814342
Validation loss: 2.821461134562289

Epoch: 6| Step: 3
Training loss: 0.5446598968252447
Validation loss: 2.883557947777664

Epoch: 6| Step: 4
Training loss: 0.897605776384538
Validation loss: 2.858936894663585

Epoch: 6| Step: 5
Training loss: 0.5392512944541537
Validation loss: 2.879972014754809

Epoch: 6| Step: 6
Training loss: 0.8407381485016654
Validation loss: 2.8766882956462676

Epoch: 6| Step: 7
Training loss: 1.0400255945614196
Validation loss: 2.850742588005811

Epoch: 6| Step: 8
Training loss: 1.5271318293525944
Validation loss: 2.8963773248482143

Epoch: 6| Step: 9
Training loss: 0.4838869805051402
Validation loss: 2.8483603417678722

Epoch: 6| Step: 10
Training loss: 0.564465321339769
Validation loss: 2.9079215872266047

Epoch: 6| Step: 11
Training loss: 0.4406024906820945
Validation loss: 2.964461572112041

Epoch: 6| Step: 12
Training loss: 0.6990002765000087
Validation loss: 2.979916502659678

Epoch: 6| Step: 13
Training loss: 0.7269912603133696
Validation loss: 2.9401561551133657

Epoch: 496| Step: 0
Training loss: 0.6119304042354505
Validation loss: 2.928497737473542

Epoch: 6| Step: 1
Training loss: 0.7046085389552416
Validation loss: 2.968884040081975

Epoch: 6| Step: 2
Training loss: 0.5823131109211742
Validation loss: 2.9268466586795534

Epoch: 6| Step: 3
Training loss: 0.6544028125233824
Validation loss: 2.888937297643685

Epoch: 6| Step: 4
Training loss: 0.8927739635959194
Validation loss: 2.9089050607261693

Epoch: 6| Step: 5
Training loss: 0.3755100278670965
Validation loss: 2.8783000029942563

Epoch: 6| Step: 6
Training loss: 0.750831500702829
Validation loss: 2.8247568999262267

Epoch: 6| Step: 7
Training loss: 1.2545510888915512
Validation loss: 2.8563780791366344

Epoch: 6| Step: 8
Training loss: 0.6938521232702792
Validation loss: 2.7654779111322236

Epoch: 6| Step: 9
Training loss: 0.6166623935895081
Validation loss: 2.813014350765457

Epoch: 6| Step: 10
Training loss: 0.524105755698995
Validation loss: 2.822296909744064

Epoch: 6| Step: 11
Training loss: 0.7338113041731462
Validation loss: 2.7757465618416544

Epoch: 6| Step: 12
Training loss: 0.6817778528452949
Validation loss: 2.8567968811869164

Epoch: 6| Step: 13
Training loss: 1.5327964291911254
Validation loss: 2.862634007122662

Epoch: 497| Step: 0
Training loss: 0.6447419717975934
Validation loss: 2.9958043296446344

Epoch: 6| Step: 1
Training loss: 0.6265563422302398
Validation loss: 2.967646691612841

Epoch: 6| Step: 2
Training loss: 0.6290972875611505
Validation loss: 2.970410093643665

Epoch: 6| Step: 3
Training loss: 1.0672425285215439
Validation loss: 2.9409551793885336

Epoch: 6| Step: 4
Training loss: 1.576949862329615
Validation loss: 2.986282817329721

Epoch: 6| Step: 5
Training loss: 0.9276730165770263
Validation loss: 2.9481416128937394

Epoch: 6| Step: 6
Training loss: 0.6482744126730492
Validation loss: 2.937126947617501

Epoch: 6| Step: 7
Training loss: 0.5844167174273953
Validation loss: 2.8659176071464345

Epoch: 6| Step: 8
Training loss: 0.48757809172454314
Validation loss: 2.853881199801022

Epoch: 6| Step: 9
Training loss: 0.45790290851189974
Validation loss: 2.8249543262266603

Epoch: 6| Step: 10
Training loss: 0.6850010364413252
Validation loss: 2.7998871664178044

Epoch: 6| Step: 11
Training loss: 0.8640976579628881
Validation loss: 2.875018810818818

Epoch: 6| Step: 12
Training loss: 0.7258995887686867
Validation loss: 2.8234108824215003

Epoch: 6| Step: 13
Training loss: 0.6920169783890809
Validation loss: 2.8288401898952573

Epoch: 498| Step: 0
Training loss: 0.8055365074214939
Validation loss: 2.770581446697649

Epoch: 6| Step: 1
Training loss: 0.5282020930164617
Validation loss: 2.8784236701906707

Epoch: 6| Step: 2
Training loss: 0.5856890851175321
Validation loss: 2.8667178345334996

Epoch: 6| Step: 3
Training loss: 0.727132143242282
Validation loss: 2.907054803362085

Epoch: 6| Step: 4
Training loss: 1.0205724084295922
Validation loss: 2.8812862446367804

Epoch: 6| Step: 5
Training loss: 0.733955994240546
Validation loss: 2.8682869822185153

Epoch: 6| Step: 6
Training loss: 0.6359441995853623
Validation loss: 2.900535283618089

Epoch: 6| Step: 7
Training loss: 0.488879866822338
Validation loss: 2.838300380892566

Epoch: 6| Step: 8
Training loss: 0.6943449296114175
Validation loss: 2.800459881890713

Epoch: 6| Step: 9
Training loss: 0.8818083597224327
Validation loss: 2.87358575396635

Epoch: 6| Step: 10
Training loss: 0.6768426883202548
Validation loss: 2.882873796398888

Epoch: 6| Step: 11
Training loss: 0.6263747592774072
Validation loss: 2.8180978027551946

Epoch: 6| Step: 12
Training loss: 0.8872820371624921
Validation loss: 2.8688831356628484

Epoch: 6| Step: 13
Training loss: 1.579115226464731
Validation loss: 2.85464240144498

Epoch: 499| Step: 0
Training loss: 0.49084342115826785
Validation loss: 2.879774124131448

Epoch: 6| Step: 1
Training loss: 1.055223568915852
Validation loss: 2.84948650720109

Epoch: 6| Step: 2
Training loss: 0.5122026383290679
Validation loss: 2.8990713353577697

Epoch: 6| Step: 3
Training loss: 0.49218474493315284
Validation loss: 3.0008059054958047

Epoch: 6| Step: 4
Training loss: 1.1404148064903519
Validation loss: 2.994466021980421

Epoch: 6| Step: 5
Training loss: 0.7576427072867228
Validation loss: 2.8654143682768978

Epoch: 6| Step: 6
Training loss: 0.626444101919389
Validation loss: 2.9370073351744095

Epoch: 6| Step: 7
Training loss: 0.7215799100088086
Validation loss: 2.862139062461544

Epoch: 6| Step: 8
Training loss: 0.6689510595812661
Validation loss: 2.889603566651486

Epoch: 6| Step: 9
Training loss: 0.3631293481707614
Validation loss: 2.8163878801357836

Epoch: 6| Step: 10
Training loss: 1.6124096749017591
Validation loss: 2.8910302917633484

Epoch: 6| Step: 11
Training loss: 0.7548756272145505
Validation loss: 2.867127600658301

Epoch: 6| Step: 12
Training loss: 0.5812639132239384
Validation loss: 2.8749423228573594

Epoch: 6| Step: 13
Training loss: 0.3587796213634544
Validation loss: 2.911432847313518

Epoch: 500| Step: 0
Training loss: 0.6892849984648832
Validation loss: 2.9351970492084316

Epoch: 6| Step: 1
Training loss: 0.7254668146978918
Validation loss: 2.8972674919054855

Epoch: 6| Step: 2
Training loss: 0.5779874483349438
Validation loss: 2.8685444488796334

Epoch: 6| Step: 3
Training loss: 0.3941909342057193
Validation loss: 2.916973974296414

Epoch: 6| Step: 4
Training loss: 1.5390436006731418
Validation loss: 2.8573591564819543

Epoch: 6| Step: 5
Training loss: 0.6038534212878289
Validation loss: 2.8403726161387244

Epoch: 6| Step: 6
Training loss: 0.4638770333299246
Validation loss: 2.816867989807231

Epoch: 6| Step: 7
Training loss: 0.5659241564908561
Validation loss: 2.822311510111243

Epoch: 6| Step: 8
Training loss: 0.9789593084741381
Validation loss: 2.8634744382098916

Epoch: 6| Step: 9
Training loss: 0.854745567901626
Validation loss: 2.788802689562245

Epoch: 6| Step: 10
Training loss: 0.4915779214175153
Validation loss: 2.8240760496326014

Epoch: 6| Step: 11
Training loss: 1.1010427669253786
Validation loss: 2.8036197482322414

Epoch: 6| Step: 12
Training loss: 0.7545505991856443
Validation loss: 2.824924491615891

Epoch: 6| Step: 13
Training loss: 0.5926341312624647
Validation loss: 2.79395363255435

Testing loss: 2.353866895565425
