Epoch: 1| Step: 0
Training loss: 6.330012739268135
Validation loss: 5.904061451873823

Epoch: 6| Step: 1
Training loss: 5.286953526748097
Validation loss: 5.902251839737392

Epoch: 6| Step: 2
Training loss: 6.867247493338625
Validation loss: 5.900484045830279

Epoch: 6| Step: 3
Training loss: 6.176663552269902
Validation loss: 5.898682848141315

Epoch: 6| Step: 4
Training loss: 6.2646413587498975
Validation loss: 5.8968647929637115

Epoch: 6| Step: 5
Training loss: 6.065763558599043
Validation loss: 5.8950623546232865

Epoch: 6| Step: 6
Training loss: 6.506231108976087
Validation loss: 5.893261873292426

Epoch: 6| Step: 7
Training loss: 5.857520539870091
Validation loss: 5.891462271605743

Epoch: 6| Step: 8
Training loss: 5.667321933932467
Validation loss: 5.889591898831522

Epoch: 6| Step: 9
Training loss: 5.142119123849846
Validation loss: 5.887731082428178

Epoch: 6| Step: 10
Training loss: 6.158538238186167
Validation loss: 5.885865843069783

Epoch: 6| Step: 11
Training loss: 5.536138238801583
Validation loss: 5.883871049956091

Epoch: 6| Step: 12
Training loss: 6.130534260354705
Validation loss: 5.881707008650803

Epoch: 6| Step: 13
Training loss: 5.900920744350285
Validation loss: 5.879585289419438

Epoch: 2| Step: 0
Training loss: 5.966145371551252
Validation loss: 5.877408230723763

Epoch: 6| Step: 1
Training loss: 5.3580719278426585
Validation loss: 5.875062144065791

Epoch: 6| Step: 2
Training loss: 6.361934662230065
Validation loss: 5.872625588083313

Epoch: 6| Step: 3
Training loss: 4.7144731756813245
Validation loss: 5.869993308484294

Epoch: 6| Step: 4
Training loss: 6.6118009547501035
Validation loss: 5.867448485183118

Epoch: 6| Step: 5
Training loss: 6.719475569470503
Validation loss: 5.864532154282287

Epoch: 6| Step: 6
Training loss: 6.446106721899444
Validation loss: 5.861750766185917

Epoch: 6| Step: 7
Training loss: 5.508985462146688
Validation loss: 5.858594403298875

Epoch: 6| Step: 8
Training loss: 6.3999635695374275
Validation loss: 5.855351293130999

Epoch: 6| Step: 9
Training loss: 6.198788604523808
Validation loss: 5.8518546574331465

Epoch: 6| Step: 10
Training loss: 6.391060737360647
Validation loss: 5.848406427375447

Epoch: 6| Step: 11
Training loss: 5.131502817595659
Validation loss: 5.844690039873009

Epoch: 6| Step: 12
Training loss: 6.251949158952975
Validation loss: 5.840852886262831

Epoch: 6| Step: 13
Training loss: 5.147214614049141
Validation loss: 5.836753260509144

Epoch: 3| Step: 0
Training loss: 6.23963190313508
Validation loss: 5.832599248563549

Epoch: 6| Step: 1
Training loss: 6.209041205209407
Validation loss: 5.828295912294774

Epoch: 6| Step: 2
Training loss: 5.827222657086622
Validation loss: 5.823862134393356

Epoch: 6| Step: 3
Training loss: 5.7149749135879375
Validation loss: 5.818973586952587

Epoch: 6| Step: 4
Training loss: 5.29954061136702
Validation loss: 5.81390645501977

Epoch: 6| Step: 5
Training loss: 6.308418389590611
Validation loss: 5.808683065049712

Epoch: 6| Step: 6
Training loss: 6.499819826416645
Validation loss: 5.803385599256317

Epoch: 6| Step: 7
Training loss: 4.957206320169902
Validation loss: 5.797796705647297

Epoch: 6| Step: 8
Training loss: 5.561791878535773
Validation loss: 5.791965925137518

Epoch: 6| Step: 9
Training loss: 6.537972381038681
Validation loss: 5.786129351264788

Epoch: 6| Step: 10
Training loss: 6.032060163567214
Validation loss: 5.779672713379836

Epoch: 6| Step: 11
Training loss: 6.138989723416936
Validation loss: 5.773184433941183

Epoch: 6| Step: 12
Training loss: 5.556051395329596
Validation loss: 5.766604980329921

Epoch: 6| Step: 13
Training loss: 5.696979378200743
Validation loss: 5.759694372033698

Epoch: 4| Step: 0
Training loss: 5.199713244234303
Validation loss: 5.7524883580383595

Epoch: 6| Step: 1
Training loss: 5.5486036588926195
Validation loss: 5.744902797902557

Epoch: 6| Step: 2
Training loss: 5.899331213336681
Validation loss: 5.737846799521175

Epoch: 6| Step: 3
Training loss: 5.718733657229893
Validation loss: 5.729871819767309

Epoch: 6| Step: 4
Training loss: 6.297648569302784
Validation loss: 5.72183827878543

Epoch: 6| Step: 5
Training loss: 5.417289267729194
Validation loss: 5.713948720123089

Epoch: 6| Step: 6
Training loss: 6.725732200497764
Validation loss: 5.705314794130657

Epoch: 6| Step: 7
Training loss: 4.613332310457796
Validation loss: 5.696923466328222

Epoch: 6| Step: 8
Training loss: 5.971271401746893
Validation loss: 5.688053034349617

Epoch: 6| Step: 9
Training loss: 6.287336295027297
Validation loss: 5.6794276818653495

Epoch: 6| Step: 10
Training loss: 5.718911090520581
Validation loss: 5.670158049294166

Epoch: 6| Step: 11
Training loss: 5.551762708193752
Validation loss: 5.661213083111048

Epoch: 6| Step: 12
Training loss: 6.662608087460916
Validation loss: 5.651858850509697

Epoch: 6| Step: 13
Training loss: 5.434140625561589
Validation loss: 5.642279920205781

Epoch: 5| Step: 0
Training loss: 5.567160550592136
Validation loss: 5.632525235212821

Epoch: 6| Step: 1
Training loss: 4.982458625158468
Validation loss: 5.6234775602202145

Epoch: 6| Step: 2
Training loss: 6.149057281937043
Validation loss: 5.61396971152642

Epoch: 6| Step: 3
Training loss: 4.839709362414905
Validation loss: 5.604262038013806

Epoch: 6| Step: 4
Training loss: 6.108701234626373
Validation loss: 5.594090115740223

Epoch: 6| Step: 5
Training loss: 6.529564745009988
Validation loss: 5.585196492590018

Epoch: 6| Step: 6
Training loss: 5.8967363544412486
Validation loss: 5.575751504012082

Epoch: 6| Step: 7
Training loss: 4.5093371690417605
Validation loss: 5.566101794031309

Epoch: 6| Step: 8
Training loss: 6.1163755148352825
Validation loss: 5.557030721423337

Epoch: 6| Step: 9
Training loss: 5.611692497088981
Validation loss: 5.548224142705061

Epoch: 6| Step: 10
Training loss: 5.287236359067976
Validation loss: 5.539300379915673

Epoch: 6| Step: 11
Training loss: 5.777679165381714
Validation loss: 5.5305045392421

Epoch: 6| Step: 12
Training loss: 5.6554593540012945
Validation loss: 5.522116841761183

Epoch: 6| Step: 13
Training loss: 6.252090104618577
Validation loss: 5.51358216289632

Epoch: 6| Step: 0
Training loss: 5.975652887275098
Validation loss: 5.505068091197483

Epoch: 6| Step: 1
Training loss: 5.907329803740117
Validation loss: 5.496734198638698

Epoch: 6| Step: 2
Training loss: 5.723994284167792
Validation loss: 5.488333292541287

Epoch: 6| Step: 3
Training loss: 5.520272088463037
Validation loss: 5.480777527858204

Epoch: 6| Step: 4
Training loss: 6.095896181559169
Validation loss: 5.4722840434206095

Epoch: 6| Step: 5
Training loss: 5.731944387588067
Validation loss: 5.464244359747711

Epoch: 6| Step: 6
Training loss: 5.076291360656073
Validation loss: 5.456455587189501

Epoch: 6| Step: 7
Training loss: 5.741239093128145
Validation loss: 5.44854261061539

Epoch: 6| Step: 8
Training loss: 5.158312021107728
Validation loss: 5.440842313770267

Epoch: 6| Step: 9
Training loss: 5.758169258897426
Validation loss: 5.433484227868172

Epoch: 6| Step: 10
Training loss: 5.485495776127451
Validation loss: 5.426422850187373

Epoch: 6| Step: 11
Training loss: 5.846135106616546
Validation loss: 5.419493343606923

Epoch: 6| Step: 12
Training loss: 4.992772982893957
Validation loss: 5.4125436594599305

Epoch: 6| Step: 13
Training loss: 4.8874755078260606
Validation loss: 5.405951166438337

Epoch: 7| Step: 0
Training loss: 5.882429254822219
Validation loss: 5.3993040236797665

Epoch: 6| Step: 1
Training loss: 5.436672103819865
Validation loss: 5.39255819992848

Epoch: 6| Step: 2
Training loss: 5.164721379109247
Validation loss: 5.385743722140156

Epoch: 6| Step: 3
Training loss: 5.688623003077509
Validation loss: 5.379078109016185

Epoch: 6| Step: 4
Training loss: 6.0470693000114215
Validation loss: 5.372402835261383

Epoch: 6| Step: 5
Training loss: 5.42247546825778
Validation loss: 5.366042724416539

Epoch: 6| Step: 6
Training loss: 6.080713971028479
Validation loss: 5.359024169827508

Epoch: 6| Step: 7
Training loss: 6.563353274140581
Validation loss: 5.352170975520534

Epoch: 6| Step: 8
Training loss: 4.204448278930328
Validation loss: 5.345232663064353

Epoch: 6| Step: 9
Training loss: 5.242106907505026
Validation loss: 5.338238526708399

Epoch: 6| Step: 10
Training loss: 5.724718991508516
Validation loss: 5.330755246435146

Epoch: 6| Step: 11
Training loss: 5.113943128535887
Validation loss: 5.323712174405935

Epoch: 6| Step: 12
Training loss: 5.26310529331223
Validation loss: 5.316472890465647

Epoch: 6| Step: 13
Training loss: 4.402178675781556
Validation loss: 5.309389647459318

Epoch: 8| Step: 0
Training loss: 5.939630387234789
Validation loss: 5.302469335668501

Epoch: 6| Step: 1
Training loss: 5.151989835740956
Validation loss: 5.295638128485198

Epoch: 6| Step: 2
Training loss: 5.296505175257852
Validation loss: 5.28915953629328

Epoch: 6| Step: 3
Training loss: 5.4049626399750785
Validation loss: 5.283077307593813

Epoch: 6| Step: 4
Training loss: 5.117795765375339
Validation loss: 5.276584106557714

Epoch: 6| Step: 5
Training loss: 4.213905321923333
Validation loss: 5.270413991458112

Epoch: 6| Step: 6
Training loss: 5.582652415797124
Validation loss: 5.26459282513291

Epoch: 6| Step: 7
Training loss: 5.143615038597193
Validation loss: 5.2587394029592

Epoch: 6| Step: 8
Training loss: 5.856925594806178
Validation loss: 5.253146666649095

Epoch: 6| Step: 9
Training loss: 5.7523918152955895
Validation loss: 5.247642835636172

Epoch: 6| Step: 10
Training loss: 6.013748946505961
Validation loss: 5.241900417693346

Epoch: 6| Step: 11
Training loss: 5.71506435675108
Validation loss: 5.236156741122494

Epoch: 6| Step: 12
Training loss: 4.930709805411454
Validation loss: 5.23115524029941

Epoch: 6| Step: 13
Training loss: 5.009210305174832
Validation loss: 5.225672411810586

Epoch: 9| Step: 0
Training loss: 4.861126059857347
Validation loss: 5.220569255428794

Epoch: 6| Step: 1
Training loss: 4.342076699681613
Validation loss: 5.214618867556725

Epoch: 6| Step: 2
Training loss: 5.208691068443623
Validation loss: 5.2102018844627835

Epoch: 6| Step: 3
Training loss: 4.026745786036935
Validation loss: 5.20494562473044

Epoch: 6| Step: 4
Training loss: 5.002755740833386
Validation loss: 5.199812559270795

Epoch: 6| Step: 5
Training loss: 5.468040899898151
Validation loss: 5.194824562965552

Epoch: 6| Step: 6
Training loss: 5.624004360669373
Validation loss: 5.189941459845019

Epoch: 6| Step: 7
Training loss: 6.148605635209028
Validation loss: 5.185200131611753

Epoch: 6| Step: 8
Training loss: 6.060935536300919
Validation loss: 5.180110800943791

Epoch: 6| Step: 9
Training loss: 5.390252584225801
Validation loss: 5.175360021184705

Epoch: 6| Step: 10
Training loss: 5.808605571188375
Validation loss: 5.170632265881162

Epoch: 6| Step: 11
Training loss: 5.159083841889612
Validation loss: 5.16548762660935

Epoch: 6| Step: 12
Training loss: 5.039845581716649
Validation loss: 5.161073005014559

Epoch: 6| Step: 13
Training loss: 5.764642729991457
Validation loss: 5.1563165217260405

Epoch: 10| Step: 0
Training loss: 4.700792919396144
Validation loss: 5.151594861921751

Epoch: 6| Step: 1
Training loss: 3.970082337224665
Validation loss: 5.1468817174451145

Epoch: 6| Step: 2
Training loss: 5.689119213296176
Validation loss: 5.142787953698513

Epoch: 6| Step: 3
Training loss: 5.440226255087464
Validation loss: 5.1377978063000125

Epoch: 6| Step: 4
Training loss: 5.147963460073788
Validation loss: 5.13318275420718

Epoch: 6| Step: 5
Training loss: 5.011339299621183
Validation loss: 5.128423338306779

Epoch: 6| Step: 6
Training loss: 5.459758756848456
Validation loss: 5.123843489004404

Epoch: 6| Step: 7
Training loss: 4.651500148182309
Validation loss: 5.119249296387235

Epoch: 6| Step: 8
Training loss: 5.850693112255917
Validation loss: 5.114915027726763

Epoch: 6| Step: 9
Training loss: 5.823612214812695
Validation loss: 5.109930881199509

Epoch: 6| Step: 10
Training loss: 5.065750397266169
Validation loss: 5.104545247057788

Epoch: 6| Step: 11
Training loss: 5.8183118415522275
Validation loss: 5.0999864964524555

Epoch: 6| Step: 12
Training loss: 5.619717639604054
Validation loss: 5.095525451658479

Epoch: 6| Step: 13
Training loss: 4.803308999403432
Validation loss: 5.090720026367701

Epoch: 11| Step: 0
Training loss: 5.329526476411254
Validation loss: 5.086044474471421

Epoch: 6| Step: 1
Training loss: 5.635551220691296
Validation loss: 5.0815903015170685

Epoch: 6| Step: 2
Training loss: 5.061435352039575
Validation loss: 5.076655780799768

Epoch: 6| Step: 3
Training loss: 5.437407744929485
Validation loss: 5.071862311591203

Epoch: 6| Step: 4
Training loss: 5.402485324993265
Validation loss: 5.068466908631647

Epoch: 6| Step: 5
Training loss: 5.931147660718134
Validation loss: 5.063275218995936

Epoch: 6| Step: 6
Training loss: 4.079864949253883
Validation loss: 5.058695741310147

Epoch: 6| Step: 7
Training loss: 4.975545398970038
Validation loss: 5.053618973096416

Epoch: 6| Step: 8
Training loss: 5.290788512567555
Validation loss: 5.049038607294546

Epoch: 6| Step: 9
Training loss: 5.3440528471498
Validation loss: 5.045188188877171

Epoch: 6| Step: 10
Training loss: 5.7426239470614195
Validation loss: 5.040649731853849

Epoch: 6| Step: 11
Training loss: 4.8772523029730035
Validation loss: 5.035729414360926

Epoch: 6| Step: 12
Training loss: 4.996987579776092
Validation loss: 5.03181844465751

Epoch: 6| Step: 13
Training loss: 4.098267603271224
Validation loss: 5.027604008172111

Epoch: 12| Step: 0
Training loss: 5.402874725352381
Validation loss: 5.022225288560844

Epoch: 6| Step: 1
Training loss: 5.403372467357409
Validation loss: 5.017274199205645

Epoch: 6| Step: 2
Training loss: 3.5410067373544005
Validation loss: 5.011587512388445

Epoch: 6| Step: 3
Training loss: 5.109323857136051
Validation loss: 5.006726984929729

Epoch: 6| Step: 4
Training loss: 6.025881893465399
Validation loss: 5.0015906346936125

Epoch: 6| Step: 5
Training loss: 5.3229937861978
Validation loss: 4.996118755740296

Epoch: 6| Step: 6
Training loss: 4.730139521664153
Validation loss: 4.990906011145982

Epoch: 6| Step: 7
Training loss: 5.822269228550545
Validation loss: 4.985416602477304

Epoch: 6| Step: 8
Training loss: 4.620835155948776
Validation loss: 4.9807198415055485

Epoch: 6| Step: 9
Training loss: 5.370349735400627
Validation loss: 4.976272231199818

Epoch: 6| Step: 10
Training loss: 4.642953205162855
Validation loss: 4.971706350596349

Epoch: 6| Step: 11
Training loss: 3.7936142471383816
Validation loss: 4.967583125429566

Epoch: 6| Step: 12
Training loss: 6.250697592905069
Validation loss: 4.964087035675138

Epoch: 6| Step: 13
Training loss: 4.822108003891689
Validation loss: 4.959405393132754

Epoch: 13| Step: 0
Training loss: 4.798608920067255
Validation loss: 4.9548899557582

Epoch: 6| Step: 1
Training loss: 4.934979145349964
Validation loss: 4.950622792994149

Epoch: 6| Step: 2
Training loss: 4.967574070386409
Validation loss: 4.946736063063432

Epoch: 6| Step: 3
Training loss: 5.3011349452512215
Validation loss: 4.943153235373776

Epoch: 6| Step: 4
Training loss: 5.226749342699175
Validation loss: 4.938268802842181

Epoch: 6| Step: 5
Training loss: 5.0999308338336995
Validation loss: 4.933718331667598

Epoch: 6| Step: 6
Training loss: 5.186285773039209
Validation loss: 4.928919358013591

Epoch: 6| Step: 7
Training loss: 5.066994261607958
Validation loss: 4.924331617103325

Epoch: 6| Step: 8
Training loss: 5.664747062618707
Validation loss: 4.92070753995669

Epoch: 6| Step: 9
Training loss: 5.067513138349878
Validation loss: 4.916236352139393

Epoch: 6| Step: 10
Training loss: 5.111505186857248
Validation loss: 4.911561427512605

Epoch: 6| Step: 11
Training loss: 4.419209569964588
Validation loss: 4.907743222697917

Epoch: 6| Step: 12
Training loss: 4.887250912458173
Validation loss: 4.903033034056005

Epoch: 6| Step: 13
Training loss: 4.9293408158602965
Validation loss: 4.899039507818015

Epoch: 14| Step: 0
Training loss: 5.426886361538695
Validation loss: 4.894183991644721

Epoch: 6| Step: 1
Training loss: 5.03046937182109
Validation loss: 4.890244376714234

Epoch: 6| Step: 2
Training loss: 5.713041531126564
Validation loss: 4.8859212434500465

Epoch: 6| Step: 3
Training loss: 5.145084383228994
Validation loss: 4.881520922929256

Epoch: 6| Step: 4
Training loss: 5.128478381750766
Validation loss: 4.877345018347468

Epoch: 6| Step: 5
Training loss: 5.380883124380438
Validation loss: 4.873201478634676

Epoch: 6| Step: 6
Training loss: 4.288961996488687
Validation loss: 4.868051451232215

Epoch: 6| Step: 7
Training loss: 4.800478100808074
Validation loss: 4.863401488588508

Epoch: 6| Step: 8
Training loss: 5.019006272705195
Validation loss: 4.859024247801891

Epoch: 6| Step: 9
Training loss: 5.275574834517536
Validation loss: 4.854960473551532

Epoch: 6| Step: 10
Training loss: 3.6718339633677632
Validation loss: 4.851273106755309

Epoch: 6| Step: 11
Training loss: 4.286256188237709
Validation loss: 4.84698827641085

Epoch: 6| Step: 12
Training loss: 4.863951659050195
Validation loss: 4.8426599732225295

Epoch: 6| Step: 13
Training loss: 5.49428382684199
Validation loss: 4.8382134410069755

Epoch: 15| Step: 0
Training loss: 4.499694813870019
Validation loss: 4.834234822268514

Epoch: 6| Step: 1
Training loss: 4.258931368186834
Validation loss: 4.830827798033557

Epoch: 6| Step: 2
Training loss: 5.130052820420821
Validation loss: 4.827185184401402

Epoch: 6| Step: 3
Training loss: 5.575063853903169
Validation loss: 4.822184738525249

Epoch: 6| Step: 4
Training loss: 5.3657039718726125
Validation loss: 4.817839810063736

Epoch: 6| Step: 5
Training loss: 5.040383714268245
Validation loss: 4.812085649892386

Epoch: 6| Step: 6
Training loss: 5.183316853651403
Validation loss: 4.807500843637187

Epoch: 6| Step: 7
Training loss: 4.310801517101968
Validation loss: 4.80493877963345

Epoch: 6| Step: 8
Training loss: 4.957765733730936
Validation loss: 4.799702791443422

Epoch: 6| Step: 9
Training loss: 4.857978252087375
Validation loss: 4.795513477590617

Epoch: 6| Step: 10
Training loss: 5.286847460727238
Validation loss: 4.789867041062531

Epoch: 6| Step: 11
Training loss: 4.871747031987268
Validation loss: 4.785584473425249

Epoch: 6| Step: 12
Training loss: 4.136987088499329
Validation loss: 4.781239461783304

Epoch: 6| Step: 13
Training loss: 5.336234714167155
Validation loss: 4.777230744625192

Epoch: 16| Step: 0
Training loss: 5.413962094915843
Validation loss: 4.772880592470727

Epoch: 6| Step: 1
Training loss: 5.403632616386949
Validation loss: 4.768167869997515

Epoch: 6| Step: 2
Training loss: 3.3794945353579373
Validation loss: 4.763331560775679

Epoch: 6| Step: 3
Training loss: 4.380754664305342
Validation loss: 4.75987383573757

Epoch: 6| Step: 4
Training loss: 5.363343129422709
Validation loss: 4.755463436285219

Epoch: 6| Step: 5
Training loss: 5.786314689256494
Validation loss: 4.7505149394878705

Epoch: 6| Step: 6
Training loss: 5.102917244507976
Validation loss: 4.7456318027396165

Epoch: 6| Step: 7
Training loss: 4.338857846075078
Validation loss: 4.741564169760891

Epoch: 6| Step: 8
Training loss: 5.327837536348185
Validation loss: 4.737395746565236

Epoch: 6| Step: 9
Training loss: 4.747899042587523
Validation loss: 4.733294943980678

Epoch: 6| Step: 10
Training loss: 4.328971697345791
Validation loss: 4.728560466256988

Epoch: 6| Step: 11
Training loss: 4.940279600748255
Validation loss: 4.724001271965035

Epoch: 6| Step: 12
Training loss: 4.458053057170459
Validation loss: 4.718003910862454

Epoch: 6| Step: 13
Training loss: 4.710584231869969
Validation loss: 4.713417526493142

Epoch: 17| Step: 0
Training loss: 4.995102581998442
Validation loss: 4.709133361543821

Epoch: 6| Step: 1
Training loss: 5.104558605275043
Validation loss: 4.7047629814972245

Epoch: 6| Step: 2
Training loss: 4.657493885996599
Validation loss: 4.700735403924318

Epoch: 6| Step: 3
Training loss: 4.853515232017087
Validation loss: 4.695335654711002

Epoch: 6| Step: 4
Training loss: 5.31654078574722
Validation loss: 4.690196164711724

Epoch: 6| Step: 5
Training loss: 5.249356911645449
Validation loss: 4.6855045394606805

Epoch: 6| Step: 6
Training loss: 4.129176943882003
Validation loss: 4.680838399328246

Epoch: 6| Step: 7
Training loss: 4.59234306951953
Validation loss: 4.676213796054488

Epoch: 6| Step: 8
Training loss: 4.636874446167009
Validation loss: 4.671747501466458

Epoch: 6| Step: 9
Training loss: 5.043758221209513
Validation loss: 4.667550968218118

Epoch: 6| Step: 10
Training loss: 4.395555870134141
Validation loss: 4.662724885127844

Epoch: 6| Step: 11
Training loss: 4.191956838545749
Validation loss: 4.657206016895689

Epoch: 6| Step: 12
Training loss: 5.67457470077432
Validation loss: 4.65232041548208

Epoch: 6| Step: 13
Training loss: 4.172028842332574
Validation loss: 4.647461279505485

Epoch: 18| Step: 0
Training loss: 4.29288477724401
Validation loss: 4.64366355257617

Epoch: 6| Step: 1
Training loss: 5.089987271935638
Validation loss: 4.639307145370184

Epoch: 6| Step: 2
Training loss: 4.2024841954593875
Validation loss: 4.634503746859522

Epoch: 6| Step: 3
Training loss: 4.995311064327679
Validation loss: 4.629604848088944

Epoch: 6| Step: 4
Training loss: 4.93131225701353
Validation loss: 4.625304907980746

Epoch: 6| Step: 5
Training loss: 4.454342538461897
Validation loss: 4.619749061132837

Epoch: 6| Step: 6
Training loss: 5.011662804758867
Validation loss: 4.614473340149433

Epoch: 6| Step: 7
Training loss: 5.263539068071801
Validation loss: 4.610079298792373

Epoch: 6| Step: 8
Training loss: 4.910635961923578
Validation loss: 4.605164099084446

Epoch: 6| Step: 9
Training loss: 4.231935143044095
Validation loss: 4.600383199404139

Epoch: 6| Step: 10
Training loss: 5.335987721956646
Validation loss: 4.595156776429663

Epoch: 6| Step: 11
Training loss: 5.008781160886485
Validation loss: 4.590376257340999

Epoch: 6| Step: 12
Training loss: 4.817184744211424
Validation loss: 4.5847482173541865

Epoch: 6| Step: 13
Training loss: 3.461920811655974
Validation loss: 4.579342624846106

Epoch: 19| Step: 0
Training loss: 5.0347611395840834
Validation loss: 4.57432650279834

Epoch: 6| Step: 1
Training loss: 4.59896989981499
Validation loss: 4.569132265031821

Epoch: 6| Step: 2
Training loss: 4.922380306402521
Validation loss: 4.564754347192587

Epoch: 6| Step: 3
Training loss: 5.095684409701162
Validation loss: 4.560211443767189

Epoch: 6| Step: 4
Training loss: 4.424878721137715
Validation loss: 4.554262676896416

Epoch: 6| Step: 5
Training loss: 4.819948451609402
Validation loss: 4.549543369002513

Epoch: 6| Step: 6
Training loss: 3.893577956414041
Validation loss: 4.544011458579467

Epoch: 6| Step: 7
Training loss: 5.079829754417199
Validation loss: 4.538691651629281

Epoch: 6| Step: 8
Training loss: 4.250411518593532
Validation loss: 4.534295928426889

Epoch: 6| Step: 9
Training loss: 4.390977947126736
Validation loss: 4.528829748167687

Epoch: 6| Step: 10
Training loss: 3.8766953236074766
Validation loss: 4.523675520305662

Epoch: 6| Step: 11
Training loss: 4.915990017811733
Validation loss: 4.518323345100585

Epoch: 6| Step: 12
Training loss: 4.679512237170882
Validation loss: 4.513044312847655

Epoch: 6| Step: 13
Training loss: 5.167081057430078
Validation loss: 4.508923759979458

Epoch: 20| Step: 0
Training loss: 4.259562561428307
Validation loss: 4.5032111825666465

Epoch: 6| Step: 1
Training loss: 4.23274881027031
Validation loss: 4.498043518020983

Epoch: 6| Step: 2
Training loss: 4.7771189676523145
Validation loss: 4.49298407084878

Epoch: 6| Step: 3
Training loss: 4.975761983974614
Validation loss: 4.487568496847226

Epoch: 6| Step: 4
Training loss: 5.627326992634358
Validation loss: 4.482418612698522

Epoch: 6| Step: 5
Training loss: 4.504624004359775
Validation loss: 4.477085511266369

Epoch: 6| Step: 6
Training loss: 4.933164600545396
Validation loss: 4.471610463135517

Epoch: 6| Step: 7
Training loss: 4.035832602289294
Validation loss: 4.466550129940681

Epoch: 6| Step: 8
Training loss: 5.045009965234598
Validation loss: 4.460677282401035

Epoch: 6| Step: 9
Training loss: 3.888465128623189
Validation loss: 4.455807365416484

Epoch: 6| Step: 10
Training loss: 4.458838508482513
Validation loss: 4.449565942004375

Epoch: 6| Step: 11
Training loss: 4.112413102829081
Validation loss: 4.445177913118956

Epoch: 6| Step: 12
Training loss: 3.8442762061212767
Validation loss: 4.4395715060256284

Epoch: 6| Step: 13
Training loss: 5.271869341491666
Validation loss: 4.433617895119413

Epoch: 21| Step: 0
Training loss: 4.913683659880335
Validation loss: 4.4289075197263

Epoch: 6| Step: 1
Training loss: 4.794876527280471
Validation loss: 4.423662990157397

Epoch: 6| Step: 2
Training loss: 4.099467936161855
Validation loss: 4.418257348898843

Epoch: 6| Step: 3
Training loss: 4.995363183550451
Validation loss: 4.412898645593221

Epoch: 6| Step: 4
Training loss: 5.395894800177268
Validation loss: 4.406301403422182

Epoch: 6| Step: 5
Training loss: 4.9922310554144556
Validation loss: 4.400797146055656

Epoch: 6| Step: 6
Training loss: 4.466499882521158
Validation loss: 4.395069013682278

Epoch: 6| Step: 7
Training loss: 4.786501724107369
Validation loss: 4.3897134868708685

Epoch: 6| Step: 8
Training loss: 4.236228846736085
Validation loss: 4.384051251574772

Epoch: 6| Step: 9
Training loss: 3.680300133117436
Validation loss: 4.377776636299935

Epoch: 6| Step: 10
Training loss: 4.015702896253228
Validation loss: 4.371945213861094

Epoch: 6| Step: 11
Training loss: 3.0361793001627584
Validation loss: 4.365881891322189

Epoch: 6| Step: 12
Training loss: 3.9861431910648735
Validation loss: 4.360919236796767

Epoch: 6| Step: 13
Training loss: 5.294847668698014
Validation loss: 4.355722280288039

Epoch: 22| Step: 0
Training loss: 5.3087313580168844
Validation loss: 4.349730731040274

Epoch: 6| Step: 1
Training loss: 4.771633675199496
Validation loss: 4.343750731836344

Epoch: 6| Step: 2
Training loss: 4.850691614292017
Validation loss: 4.337840352918588

Epoch: 6| Step: 3
Training loss: 4.064417225258923
Validation loss: 4.332829018125838

Epoch: 6| Step: 4
Training loss: 4.177155884884007
Validation loss: 4.326995555346735

Epoch: 6| Step: 5
Training loss: 4.804382413776782
Validation loss: 4.321289982050279

Epoch: 6| Step: 6
Training loss: 4.745362075481385
Validation loss: 4.314582533800219

Epoch: 6| Step: 7
Training loss: 3.7893382178598807
Validation loss: 4.308399148778974

Epoch: 6| Step: 8
Training loss: 4.044195164228253
Validation loss: 4.3034213974026105

Epoch: 6| Step: 9
Training loss: 4.226402293780959
Validation loss: 4.2970560486538005

Epoch: 6| Step: 10
Training loss: 4.029090006959349
Validation loss: 4.290606593096935

Epoch: 6| Step: 11
Training loss: 4.900405415481864
Validation loss: 4.285576298172568

Epoch: 6| Step: 12
Training loss: 4.655262067815726
Validation loss: 4.279980399303772

Epoch: 6| Step: 13
Training loss: 3.4595981873947586
Validation loss: 4.273146782749286

Epoch: 23| Step: 0
Training loss: 4.957259032394597
Validation loss: 4.267570843606727

Epoch: 6| Step: 1
Training loss: 4.368751859869172
Validation loss: 4.261559194065755

Epoch: 6| Step: 2
Training loss: 3.356647750614309
Validation loss: 4.255958139324834

Epoch: 6| Step: 3
Training loss: 4.276270065372049
Validation loss: 4.250110325596792

Epoch: 6| Step: 4
Training loss: 3.9923250954761627
Validation loss: 4.244611203466741

Epoch: 6| Step: 5
Training loss: 4.312446483335284
Validation loss: 4.238137500862452

Epoch: 6| Step: 6
Training loss: 4.162850323389181
Validation loss: 4.232628381159925

Epoch: 6| Step: 7
Training loss: 4.526669627335207
Validation loss: 4.227126445271535

Epoch: 6| Step: 8
Training loss: 3.791211209172624
Validation loss: 4.221421137879973

Epoch: 6| Step: 9
Training loss: 4.684890631149257
Validation loss: 4.215823498335073

Epoch: 6| Step: 10
Training loss: 4.709019411226462
Validation loss: 4.209699459357693

Epoch: 6| Step: 11
Training loss: 5.088952361927529
Validation loss: 4.2039290726174565

Epoch: 6| Step: 12
Training loss: 4.206735641308992
Validation loss: 4.199521397766206

Epoch: 6| Step: 13
Training loss: 4.297933995921852
Validation loss: 4.191885592214673

Epoch: 24| Step: 0
Training loss: 3.6339197583826435
Validation loss: 4.185179603639204

Epoch: 6| Step: 1
Training loss: 4.249637812720826
Validation loss: 4.179567595571306

Epoch: 6| Step: 2
Training loss: 4.298694572124666
Validation loss: 4.174100684580361

Epoch: 6| Step: 3
Training loss: 4.90672465172658
Validation loss: 4.167854591148125

Epoch: 6| Step: 4
Training loss: 5.007766413960131
Validation loss: 4.161474858880999

Epoch: 6| Step: 5
Training loss: 3.470484806679896
Validation loss: 4.154776386038482

Epoch: 6| Step: 6
Training loss: 4.377846581961322
Validation loss: 4.148752050932764

Epoch: 6| Step: 7
Training loss: 4.3651863112566485
Validation loss: 4.143084025003664

Epoch: 6| Step: 8
Training loss: 3.832079779174745
Validation loss: 4.136633007876802

Epoch: 6| Step: 9
Training loss: 3.7201781535814606
Validation loss: 4.129742833860238

Epoch: 6| Step: 10
Training loss: 4.5859713967417415
Validation loss: 4.124116725951987

Epoch: 6| Step: 11
Training loss: 4.880747219474714
Validation loss: 4.118565714161924

Epoch: 6| Step: 12
Training loss: 3.4779083047353994
Validation loss: 4.111554475595599

Epoch: 6| Step: 13
Training loss: 4.643895085611012
Validation loss: 4.105619041239944

Epoch: 25| Step: 0
Training loss: 4.476324318080043
Validation loss: 4.0997826289884

Epoch: 6| Step: 1
Training loss: 3.856902160400539
Validation loss: 4.093566249771203

Epoch: 6| Step: 2
Training loss: 4.0064276074156036
Validation loss: 4.087642510872483

Epoch: 6| Step: 3
Training loss: 4.097450738486223
Validation loss: 4.082177731746786

Epoch: 6| Step: 4
Training loss: 4.565985615383887
Validation loss: 4.0760614623594735

Epoch: 6| Step: 5
Training loss: 3.94160973559525
Validation loss: 4.06947762291713

Epoch: 6| Step: 6
Training loss: 5.097418651670705
Validation loss: 4.063008281504349

Epoch: 6| Step: 7
Training loss: 4.58311133569553
Validation loss: 4.05595912115701

Epoch: 6| Step: 8
Training loss: 4.15116513913011
Validation loss: 4.049859123762528

Epoch: 6| Step: 9
Training loss: 3.737767932690892
Validation loss: 4.0428001675802605

Epoch: 6| Step: 10
Training loss: 3.6809743263118255
Validation loss: 4.037777291018365

Epoch: 6| Step: 11
Training loss: 4.106848806908131
Validation loss: 4.03171919031664

Epoch: 6| Step: 12
Training loss: 4.407483516668784
Validation loss: 4.025133663035289

Epoch: 6| Step: 13
Training loss: 3.7527207994657257
Validation loss: 4.019399588269506

Epoch: 26| Step: 0
Training loss: 4.030386898882972
Validation loss: 4.015162400492095

Epoch: 6| Step: 1
Training loss: 3.4851081658410985
Validation loss: 4.009455670570714

Epoch: 6| Step: 2
Training loss: 4.274530860188873
Validation loss: 4.002214077282213

Epoch: 6| Step: 3
Training loss: 4.7158513545067064
Validation loss: 3.994913423449135

Epoch: 6| Step: 4
Training loss: 4.124014534422369
Validation loss: 3.989057912996979

Epoch: 6| Step: 5
Training loss: 3.600885356541103
Validation loss: 3.9837790847640653

Epoch: 6| Step: 6
Training loss: 4.347309218657784
Validation loss: 3.9771728646758513

Epoch: 6| Step: 7
Training loss: 4.101509021228736
Validation loss: 3.9714972931965793

Epoch: 6| Step: 8
Training loss: 3.7347994128269772
Validation loss: 3.9645547996425647

Epoch: 6| Step: 9
Training loss: 4.105581875448442
Validation loss: 3.9583399655470584

Epoch: 6| Step: 10
Training loss: 4.127141454455251
Validation loss: 3.9524465790463568

Epoch: 6| Step: 11
Training loss: 4.257603295462507
Validation loss: 3.9459827621722776

Epoch: 6| Step: 12
Training loss: 4.6650649228336505
Validation loss: 3.9408430006414554

Epoch: 6| Step: 13
Training loss: 3.724803965485812
Validation loss: 3.934894143522225

Epoch: 27| Step: 0
Training loss: 4.080856402405111
Validation loss: 3.928310307168352

Epoch: 6| Step: 1
Training loss: 4.075454948632125
Validation loss: 3.921726583684297

Epoch: 6| Step: 2
Training loss: 4.559002515547406
Validation loss: 3.9156912272120277

Epoch: 6| Step: 3
Training loss: 3.828518594243058
Validation loss: 3.9092854823722405

Epoch: 6| Step: 4
Training loss: 4.0750351231471384
Validation loss: 3.9024280619176546

Epoch: 6| Step: 5
Training loss: 3.3403566914676808
Validation loss: 3.8966848221468227

Epoch: 6| Step: 6
Training loss: 4.75417846803039
Validation loss: 3.88983160505961

Epoch: 6| Step: 7
Training loss: 3.4707356860898746
Validation loss: 3.8839967944036706

Epoch: 6| Step: 8
Training loss: 3.7819331789372335
Validation loss: 3.8784214624725912

Epoch: 6| Step: 9
Training loss: 4.434411922029604
Validation loss: 3.873947780041203

Epoch: 6| Step: 10
Training loss: 3.570905707095852
Validation loss: 3.8660217583181007

Epoch: 6| Step: 11
Training loss: 4.555012450886866
Validation loss: 3.8599339130654067

Epoch: 6| Step: 12
Training loss: 3.4210786633138173
Validation loss: 3.854047220114702

Epoch: 6| Step: 13
Training loss: 4.045067107182689
Validation loss: 3.8496669517893753

Epoch: 28| Step: 0
Training loss: 4.3856233501281725
Validation loss: 3.842999351417367

Epoch: 6| Step: 1
Training loss: 3.8712505535929664
Validation loss: 3.838243629068801

Epoch: 6| Step: 2
Training loss: 2.9483410065937266
Validation loss: 3.834474697749653

Epoch: 6| Step: 3
Training loss: 4.399855281877445
Validation loss: 3.829433108673838

Epoch: 6| Step: 4
Training loss: 3.9239078435779526
Validation loss: 3.8207898924066086

Epoch: 6| Step: 5
Training loss: 4.136109390981462
Validation loss: 3.8140250319146376

Epoch: 6| Step: 6
Training loss: 4.108760889385336
Validation loss: 3.8109116502682543

Epoch: 6| Step: 7
Training loss: 4.232556167112691
Validation loss: 3.8063618593947353

Epoch: 6| Step: 8
Training loss: 3.652359677856312
Validation loss: 3.7976392858466808

Epoch: 6| Step: 9
Training loss: 3.7459880985003737
Validation loss: 3.7922543010950074

Epoch: 6| Step: 10
Training loss: 3.648881970927033
Validation loss: 3.7889224311658967

Epoch: 6| Step: 11
Training loss: 4.552892314801195
Validation loss: 3.7848143578998767

Epoch: 6| Step: 12
Training loss: 3.21047769860229
Validation loss: 3.777342235166449

Epoch: 6| Step: 13
Training loss: 4.039119638891053
Validation loss: 3.7692527127837363

Epoch: 29| Step: 0
Training loss: 4.170148513674139
Validation loss: 3.7640948636110085

Epoch: 6| Step: 1
Training loss: 3.2309575846894836
Validation loss: 3.760138961949867

Epoch: 6| Step: 2
Training loss: 3.695332371857906
Validation loss: 3.7558992608237594

Epoch: 6| Step: 3
Training loss: 3.6168521206562083
Validation loss: 3.7493080348449626

Epoch: 6| Step: 4
Training loss: 3.897156896849562
Validation loss: 3.742681673745769

Epoch: 6| Step: 5
Training loss: 4.64898811733658
Validation loss: 3.7381963185408753

Epoch: 6| Step: 6
Training loss: 4.192617449357877
Validation loss: 3.7330395001061296

Epoch: 6| Step: 7
Training loss: 4.031124852330084
Validation loss: 3.7269269017327633

Epoch: 6| Step: 8
Training loss: 2.5173049908809735
Validation loss: 3.7196368487652527

Epoch: 6| Step: 9
Training loss: 4.297233205949889
Validation loss: 3.716084334308575

Epoch: 6| Step: 10
Training loss: 3.6140484299573448
Validation loss: 3.7113666487054395

Epoch: 6| Step: 11
Training loss: 4.183945243024921
Validation loss: 3.7054445966597855

Epoch: 6| Step: 12
Training loss: 3.8510159923030223
Validation loss: 3.69978241753254

Epoch: 6| Step: 13
Training loss: 3.707110485520423
Validation loss: 3.694253695892952

Epoch: 30| Step: 0
Training loss: 3.828229381150266
Validation loss: 3.690292615617

Epoch: 6| Step: 1
Training loss: 4.273109214210114
Validation loss: 3.6853240753900347

Epoch: 6| Step: 2
Training loss: 3.216636482321155
Validation loss: 3.6783692630199325

Epoch: 6| Step: 3
Training loss: 3.4070780736220088
Validation loss: 3.672802141163553

Epoch: 6| Step: 4
Training loss: 4.32181593274667
Validation loss: 3.6684059150675563

Epoch: 6| Step: 5
Training loss: 3.2003349248135646
Validation loss: 3.6626730685956357

Epoch: 6| Step: 6
Training loss: 4.204162469615423
Validation loss: 3.657170758502827

Epoch: 6| Step: 7
Training loss: 3.6533843980362173
Validation loss: 3.6518170471659284

Epoch: 6| Step: 8
Training loss: 3.7135835549808514
Validation loss: 3.6467014405465625

Epoch: 6| Step: 9
Training loss: 3.52182084780663
Validation loss: 3.642097360964865

Epoch: 6| Step: 10
Training loss: 3.492495393087834
Validation loss: 3.6367256992163064

Epoch: 6| Step: 11
Training loss: 3.82147261590366
Validation loss: 3.6312946607914975

Epoch: 6| Step: 12
Training loss: 4.205962063823712
Validation loss: 3.6270146964712984

Epoch: 6| Step: 13
Training loss: 3.990291974085624
Validation loss: 3.62238046115856

Epoch: 31| Step: 0
Training loss: 4.455524641285419
Validation loss: 3.61686809494531

Epoch: 6| Step: 1
Training loss: 3.0260260489099626
Validation loss: 3.6123544525076383

Epoch: 6| Step: 2
Training loss: 3.377864046277872
Validation loss: 3.606890969966809

Epoch: 6| Step: 3
Training loss: 4.16462998522298
Validation loss: 3.6024799405840393

Epoch: 6| Step: 4
Training loss: 3.385682894680197
Validation loss: 3.5985632687409104

Epoch: 6| Step: 5
Training loss: 3.3442244148607436
Validation loss: 3.592826636182259

Epoch: 6| Step: 6
Training loss: 3.382494763964472
Validation loss: 3.5873511692237736

Epoch: 6| Step: 7
Training loss: 3.967912240103858
Validation loss: 3.583541701416834

Epoch: 6| Step: 8
Training loss: 3.669007305629773
Validation loss: 3.5777115228953758

Epoch: 6| Step: 9
Training loss: 3.5469059207593556
Validation loss: 3.5734792253498777

Epoch: 6| Step: 10
Training loss: 3.223415068096709
Validation loss: 3.568673846428277

Epoch: 6| Step: 11
Training loss: 3.337296148925403
Validation loss: 3.564187915986312

Epoch: 6| Step: 12
Training loss: 4.925633137084761
Validation loss: 3.559479955879079

Epoch: 6| Step: 13
Training loss: 3.8154375609801665
Validation loss: 3.5554867694744297

Epoch: 32| Step: 0
Training loss: 3.7671708222522007
Validation loss: 3.55054395027501

Epoch: 6| Step: 1
Training loss: 3.4786406402998433
Validation loss: 3.545263431232482

Epoch: 6| Step: 2
Training loss: 3.311653604876852
Validation loss: 3.5401693806832184

Epoch: 6| Step: 3
Training loss: 3.427950269198155
Validation loss: 3.5367404261551805

Epoch: 6| Step: 4
Training loss: 4.087757412799046
Validation loss: 3.5323698355596505

Epoch: 6| Step: 5
Training loss: 3.1574179122052333
Validation loss: 3.528049785577025

Epoch: 6| Step: 6
Training loss: 3.950811017953777
Validation loss: 3.5230601941150295

Epoch: 6| Step: 7
Training loss: 2.8583143591366875
Validation loss: 3.5178395170121086

Epoch: 6| Step: 8
Training loss: 4.050542988110996
Validation loss: 3.51374983899833

Epoch: 6| Step: 9
Training loss: 4.318749364033057
Validation loss: 3.5093737146200272

Epoch: 6| Step: 10
Training loss: 3.7535764805400826
Validation loss: 3.504388147371078

Epoch: 6| Step: 11
Training loss: 3.875130681941452
Validation loss: 3.5010936481612407

Epoch: 6| Step: 12
Training loss: 2.9614688929905024
Validation loss: 3.4956147560166415

Epoch: 6| Step: 13
Training loss: 3.8793487757390577
Validation loss: 3.490591391342139

Epoch: 33| Step: 0
Training loss: 2.9456440463260747
Validation loss: 3.4867683025910066

Epoch: 6| Step: 1
Training loss: 3.9081646918790534
Validation loss: 3.4823837634768395

Epoch: 6| Step: 2
Training loss: 4.427133836645145
Validation loss: 3.47838531598478

Epoch: 6| Step: 3
Training loss: 3.776005410206685
Validation loss: 3.474276999404232

Epoch: 6| Step: 4
Training loss: 3.761977966187284
Validation loss: 3.4692055572033045

Epoch: 6| Step: 5
Training loss: 3.320137863054409
Validation loss: 3.4641649569746624

Epoch: 6| Step: 6
Training loss: 3.7653314626417114
Validation loss: 3.4604186852480066

Epoch: 6| Step: 7
Training loss: 3.5395054824168013
Validation loss: 3.4555070810982786

Epoch: 6| Step: 8
Training loss: 3.9052390049119707
Validation loss: 3.4513830794232856

Epoch: 6| Step: 9
Training loss: 3.244498658561929
Validation loss: 3.44709389234509

Epoch: 6| Step: 10
Training loss: 3.726794733452666
Validation loss: 3.4428333869571266

Epoch: 6| Step: 11
Training loss: 3.1109426562555367
Validation loss: 3.4382136442204443

Epoch: 6| Step: 12
Training loss: 3.0153884399605397
Validation loss: 3.4339416119383364

Epoch: 6| Step: 13
Training loss: 3.609018151283862
Validation loss: 3.4293595651824185

Epoch: 34| Step: 0
Training loss: 3.794969496572987
Validation loss: 3.4262335089818183

Epoch: 6| Step: 1
Training loss: 4.048694569749145
Validation loss: 3.4213982283333895

Epoch: 6| Step: 2
Training loss: 3.6045994728428763
Validation loss: 3.4178352373477225

Epoch: 6| Step: 3
Training loss: 2.948629034843079
Validation loss: 3.41232055173612

Epoch: 6| Step: 4
Training loss: 3.372804846195163
Validation loss: 3.407751026791385

Epoch: 6| Step: 5
Training loss: 3.045720747411985
Validation loss: 3.4038146526067687

Epoch: 6| Step: 6
Training loss: 3.6653808304295037
Validation loss: 3.4002729932730613

Epoch: 6| Step: 7
Training loss: 3.4108480514282133
Validation loss: 3.396521835895642

Epoch: 6| Step: 8
Training loss: 4.33790007843128
Validation loss: 3.3920728694852937

Epoch: 6| Step: 9
Training loss: 3.344217143003807
Validation loss: 3.3877499252408283

Epoch: 6| Step: 10
Training loss: 3.7695423817840816
Validation loss: 3.3831859731920275

Epoch: 6| Step: 11
Training loss: 2.772073759674722
Validation loss: 3.3796439304562123

Epoch: 6| Step: 12
Training loss: 3.3644074826104835
Validation loss: 3.3755430561721864

Epoch: 6| Step: 13
Training loss: 3.7361128207127576
Validation loss: 3.3723115574188127

Epoch: 35| Step: 0
Training loss: 3.092062750136428
Validation loss: 3.368526360726715

Epoch: 6| Step: 1
Training loss: 4.356646158821465
Validation loss: 3.363887600767682

Epoch: 6| Step: 2
Training loss: 3.7611693300906115
Validation loss: 3.358669922639188

Epoch: 6| Step: 3
Training loss: 3.6953725023620256
Validation loss: 3.3553324661733788

Epoch: 6| Step: 4
Training loss: 3.0228277177998457
Validation loss: 3.3519001681727096

Epoch: 6| Step: 5
Training loss: 2.7655809474389206
Validation loss: 3.3478385908276374

Epoch: 6| Step: 6
Training loss: 4.333734175898267
Validation loss: 3.344845066616476

Epoch: 6| Step: 7
Training loss: 3.461541736633838
Validation loss: 3.340180842173192

Epoch: 6| Step: 8
Training loss: 3.7257145650714767
Validation loss: 3.3363466153400854

Epoch: 6| Step: 9
Training loss: 2.622568002988264
Validation loss: 3.331751607092327

Epoch: 6| Step: 10
Training loss: 3.528462482864308
Validation loss: 3.3281716118116975

Epoch: 6| Step: 11
Training loss: 3.2405910743990223
Validation loss: 3.3244525425270317

Epoch: 6| Step: 12
Training loss: 3.0737429957176223
Validation loss: 3.320584226971002

Epoch: 6| Step: 13
Training loss: 3.5732052225899564
Validation loss: 3.3171921372886586

Epoch: 36| Step: 0
Training loss: 3.842434541719281
Validation loss: 3.3138732223019622

Epoch: 6| Step: 1
Training loss: 3.6755194575843366
Validation loss: 3.309795006937838

Epoch: 6| Step: 2
Training loss: 3.4325898214147403
Validation loss: 3.3049416590863747

Epoch: 6| Step: 3
Training loss: 2.945825021202378
Validation loss: 3.3018202491354542

Epoch: 6| Step: 4
Training loss: 3.113541614936189
Validation loss: 3.2977321769952423

Epoch: 6| Step: 5
Training loss: 3.21974196472279
Validation loss: 3.295008656900907

Epoch: 6| Step: 6
Training loss: 2.552186260613105
Validation loss: 3.291883598293714

Epoch: 6| Step: 7
Training loss: 3.6648666703144386
Validation loss: 3.288436769720239

Epoch: 6| Step: 8
Training loss: 3.573009048617009
Validation loss: 3.2837822361973115

Epoch: 6| Step: 9
Training loss: 3.150123920727942
Validation loss: 3.2805422428308524

Epoch: 6| Step: 10
Training loss: 4.304405466245795
Validation loss: 3.277047472396041

Epoch: 6| Step: 11
Training loss: 3.326388483615993
Validation loss: 3.2737223183382955

Epoch: 6| Step: 12
Training loss: 3.108345973284864
Validation loss: 3.2705202054016467

Epoch: 6| Step: 13
Training loss: 3.7275796138005797
Validation loss: 3.2671962407714448

Epoch: 37| Step: 0
Training loss: 3.8617158655537476
Validation loss: 3.2632552557681573

Epoch: 6| Step: 1
Training loss: 3.236615275856661
Validation loss: 3.2590356081351386

Epoch: 6| Step: 2
Training loss: 3.2909333261223055
Validation loss: 3.2547364566836774

Epoch: 6| Step: 3
Training loss: 3.8333526417342707
Validation loss: 3.250544722463731

Epoch: 6| Step: 4
Training loss: 2.888387938209097
Validation loss: 3.2470849976171685

Epoch: 6| Step: 5
Training loss: 2.67664406780744
Validation loss: 3.243909594481415

Epoch: 6| Step: 6
Training loss: 3.4367045088965282
Validation loss: 3.2417859667585183

Epoch: 6| Step: 7
Training loss: 3.5389385412203977
Validation loss: 3.2378151945155635

Epoch: 6| Step: 8
Training loss: 3.625954337941922
Validation loss: 3.233345199510751

Epoch: 6| Step: 9
Training loss: 3.1614699303269242
Validation loss: 3.228918746947441

Epoch: 6| Step: 10
Training loss: 3.5063009764965645
Validation loss: 3.2253240466883697

Epoch: 6| Step: 11
Training loss: 3.130170892797266
Validation loss: 3.2220566193641393

Epoch: 6| Step: 12
Training loss: 3.258103026098824
Validation loss: 3.2191986956390863

Epoch: 6| Step: 13
Training loss: 3.645589300798659
Validation loss: 3.2155598012569118

Epoch: 38| Step: 0
Training loss: 3.602898670509074
Validation loss: 3.212786078177295

Epoch: 6| Step: 1
Training loss: 3.532254776592806
Validation loss: 3.2084526601291845

Epoch: 6| Step: 2
Training loss: 2.9912654561633008
Validation loss: 3.2041486639567904

Epoch: 6| Step: 3
Training loss: 3.401054409562093
Validation loss: 3.2009037783007575

Epoch: 6| Step: 4
Training loss: 2.3385368862542197
Validation loss: 3.197517498506332

Epoch: 6| Step: 5
Training loss: 3.3331730486162106
Validation loss: 3.194096552292179

Epoch: 6| Step: 6
Training loss: 3.8140539535683002
Validation loss: 3.1908147692561672

Epoch: 6| Step: 7
Training loss: 3.0400680800393953
Validation loss: 3.187493305573259

Epoch: 6| Step: 8
Training loss: 3.5095800351773474
Validation loss: 3.1839992522377787

Epoch: 6| Step: 9
Training loss: 3.534068645283393
Validation loss: 3.1810702130090727

Epoch: 6| Step: 10
Training loss: 3.3387954940752698
Validation loss: 3.177411438722995

Epoch: 6| Step: 11
Training loss: 2.9660982837611205
Validation loss: 3.1738521884103803

Epoch: 6| Step: 12
Training loss: 3.387290193598986
Validation loss: 3.170836543325102

Epoch: 6| Step: 13
Training loss: 3.554666841887088
Validation loss: 3.1681290228110686

Epoch: 39| Step: 0
Training loss: 2.4956274895544555
Validation loss: 3.1640966845263048

Epoch: 6| Step: 1
Training loss: 3.5123741208799006
Validation loss: 3.1608515266547244

Epoch: 6| Step: 2
Training loss: 2.7228424139972556
Validation loss: 3.1589890734531982

Epoch: 6| Step: 3
Training loss: 3.8653868519382013
Validation loss: 3.1557771309628677

Epoch: 6| Step: 4
Training loss: 2.6187149373258696
Validation loss: 3.151978854111679

Epoch: 6| Step: 5
Training loss: 3.4145790948816277
Validation loss: 3.1483612934794154

Epoch: 6| Step: 6
Training loss: 3.760227624820911
Validation loss: 3.145096336753151

Epoch: 6| Step: 7
Training loss: 3.2781424202833427
Validation loss: 3.1423250344993927

Epoch: 6| Step: 8
Training loss: 2.7675027453401175
Validation loss: 3.139087496769219

Epoch: 6| Step: 9
Training loss: 3.436201370466876
Validation loss: 3.1364743718286525

Epoch: 6| Step: 10
Training loss: 3.4939012525434108
Validation loss: 3.132975864986705

Epoch: 6| Step: 11
Training loss: 3.6782515329847665
Validation loss: 3.1293612501359016

Epoch: 6| Step: 12
Training loss: 3.8388578715147075
Validation loss: 3.1267226493828546

Epoch: 6| Step: 13
Training loss: 2.598717402500996
Validation loss: 3.123277367409689

Epoch: 40| Step: 0
Training loss: 2.752290811931025
Validation loss: 3.1190079907853794

Epoch: 6| Step: 1
Training loss: 3.4426616409682693
Validation loss: 3.1165124198837053

Epoch: 6| Step: 2
Training loss: 3.1013692416077334
Validation loss: 3.112992653419493

Epoch: 6| Step: 3
Training loss: 3.4321166453601775
Validation loss: 3.1089088435559322

Epoch: 6| Step: 4
Training loss: 3.440610830501307
Validation loss: 3.106048350757576

Epoch: 6| Step: 5
Training loss: 2.771657453083163
Validation loss: 3.102414543415559

Epoch: 6| Step: 6
Training loss: 2.7320713475518925
Validation loss: 3.0993736223906367

Epoch: 6| Step: 7
Training loss: 3.0504891112826806
Validation loss: 3.0962750312738954

Epoch: 6| Step: 8
Training loss: 3.3392530487770897
Validation loss: 3.093818972040315

Epoch: 6| Step: 9
Training loss: 3.239211000754608
Validation loss: 3.0904140275691314

Epoch: 6| Step: 10
Training loss: 3.379715204147388
Validation loss: 3.0876310570375356

Epoch: 6| Step: 11
Training loss: 3.441298172430321
Validation loss: 3.0844460532968716

Epoch: 6| Step: 12
Training loss: 2.940135179642724
Validation loss: 3.0817896784948213

Epoch: 6| Step: 13
Training loss: 4.035021296826663
Validation loss: 3.0795522308189747

Epoch: 41| Step: 0
Training loss: 3.555568175161007
Validation loss: 3.0767148010053953

Epoch: 6| Step: 1
Training loss: 3.5831054940350664
Validation loss: 3.0726086780063935

Epoch: 6| Step: 2
Training loss: 3.2612143486299643
Validation loss: 3.0702383923828465

Epoch: 6| Step: 3
Training loss: 3.198479088315813
Validation loss: 3.0663922805629915

Epoch: 6| Step: 4
Training loss: 3.607446989541029
Validation loss: 3.06428984155757

Epoch: 6| Step: 5
Training loss: 3.0306553208149527
Validation loss: 3.0611405761402217

Epoch: 6| Step: 6
Training loss: 3.055276253005239
Validation loss: 3.058461361387244

Epoch: 6| Step: 7
Training loss: 3.272363308936125
Validation loss: 3.0549661260496874

Epoch: 6| Step: 8
Training loss: 3.401302559364838
Validation loss: 3.052327537965482

Epoch: 6| Step: 9
Training loss: 2.985135605637608
Validation loss: 3.048702715571818

Epoch: 6| Step: 10
Training loss: 2.835720253602152
Validation loss: 3.0458352295486524

Epoch: 6| Step: 11
Training loss: 3.074456366888998
Validation loss: 3.0434025335713764

Epoch: 6| Step: 12
Training loss: 3.1670378082687782
Validation loss: 3.040070066815745

Epoch: 6| Step: 13
Training loss: 2.5740135933102883
Validation loss: 3.0373815547418634

Epoch: 42| Step: 0
Training loss: 3.008752294586283
Validation loss: 3.034170585580202

Epoch: 6| Step: 1
Training loss: 3.2718784743967344
Validation loss: 3.0312149727491913

Epoch: 6| Step: 2
Training loss: 2.876422861699768
Validation loss: 3.0285593262659396

Epoch: 6| Step: 3
Training loss: 3.0257947145808086
Validation loss: 3.025799901937459

Epoch: 6| Step: 4
Training loss: 3.6801186084292086
Validation loss: 3.0230732253949206

Epoch: 6| Step: 5
Training loss: 3.5841541385202556
Validation loss: 3.0204431917661827

Epoch: 6| Step: 6
Training loss: 3.0051559011732563
Validation loss: 3.0165199572539874

Epoch: 6| Step: 7
Training loss: 2.9022496081110534
Validation loss: 3.013764777804576

Epoch: 6| Step: 8
Training loss: 3.741057605633331
Validation loss: 3.0116289507205964

Epoch: 6| Step: 9
Training loss: 2.583804815603198
Validation loss: 3.007157899378622

Epoch: 6| Step: 10
Training loss: 3.1151342680819893
Validation loss: 3.006668586695101

Epoch: 6| Step: 11
Training loss: 3.551799967958519
Validation loss: 3.0043064308899052

Epoch: 6| Step: 12
Training loss: 3.1252189559523735
Validation loss: 3.001699813781191

Epoch: 6| Step: 13
Training loss: 2.434586960620475
Validation loss: 2.9992211575940226

Epoch: 43| Step: 0
Training loss: 2.4745848066620284
Validation loss: 2.997240068557147

Epoch: 6| Step: 1
Training loss: 3.3995575560870326
Validation loss: 2.9940057182070534

Epoch: 6| Step: 2
Training loss: 3.685504179253885
Validation loss: 2.9916302964772195

Epoch: 6| Step: 3
Training loss: 3.4552442856808936
Validation loss: 2.9877230519726043

Epoch: 6| Step: 4
Training loss: 3.0934531329513626
Validation loss: 2.9848880692949407

Epoch: 6| Step: 5
Training loss: 3.191931542410574
Validation loss: 2.982558997765267

Epoch: 6| Step: 6
Training loss: 3.069115169886166
Validation loss: 2.9804658702271474

Epoch: 6| Step: 7
Training loss: 3.1538926187352505
Validation loss: 2.977677424322983

Epoch: 6| Step: 8
Training loss: 3.1091517075916886
Validation loss: 2.974672186178538

Epoch: 6| Step: 9
Training loss: 3.4498430078141893
Validation loss: 2.972365322906725

Epoch: 6| Step: 10
Training loss: 3.1841531273811
Validation loss: 2.968989352565958

Epoch: 6| Step: 11
Training loss: 2.7019910252984665
Validation loss: 2.966289571483932

Epoch: 6| Step: 12
Training loss: 2.614871147292608
Validation loss: 2.964223227988588

Epoch: 6| Step: 13
Training loss: 2.8882482706859043
Validation loss: 2.9626668880364138

Epoch: 44| Step: 0
Training loss: 3.123319402831233
Validation loss: 2.9620261090948325

Epoch: 6| Step: 1
Training loss: 2.8272865696500995
Validation loss: 2.9604516616317094

Epoch: 6| Step: 2
Training loss: 3.3963050904647965
Validation loss: 2.958064219273969

Epoch: 6| Step: 3
Training loss: 3.1099231945992094
Validation loss: 2.955917007370415

Epoch: 6| Step: 4
Training loss: 3.3835668273432487
Validation loss: 2.9524722580517544

Epoch: 6| Step: 5
Training loss: 2.7072862997634215
Validation loss: 2.948973373074697

Epoch: 6| Step: 6
Training loss: 3.510284164750393
Validation loss: 2.9460786047395886

Epoch: 6| Step: 7
Training loss: 2.3204397044651053
Validation loss: 2.942676649795154

Epoch: 6| Step: 8
Training loss: 2.7288522806190327
Validation loss: 2.940500782833807

Epoch: 6| Step: 9
Training loss: 3.3205078067558524
Validation loss: 2.939934310308971

Epoch: 6| Step: 10
Training loss: 3.198621906132182
Validation loss: 2.9387081854065786

Epoch: 6| Step: 11
Training loss: 3.220520421496861
Validation loss: 2.93463943747015

Epoch: 6| Step: 12
Training loss: 3.303087500988215
Validation loss: 2.933111890287627

Epoch: 6| Step: 13
Training loss: 2.835158900629961
Validation loss: 2.9298115479380358

Epoch: 45| Step: 0
Training loss: 2.777735514849119
Validation loss: 2.927785732572954

Epoch: 6| Step: 1
Training loss: 2.7195287882534283
Validation loss: 2.9259902750411206

Epoch: 6| Step: 2
Training loss: 3.239112664444741
Validation loss: 2.92386772759203

Epoch: 6| Step: 3
Training loss: 3.00083498460985
Validation loss: 2.9210910663454674

Epoch: 6| Step: 4
Training loss: 2.6824879596080917
Validation loss: 2.9192160953740447

Epoch: 6| Step: 5
Training loss: 2.9150151799691684
Validation loss: 2.9169453941860075

Epoch: 6| Step: 6
Training loss: 3.0411128406506576
Validation loss: 2.9146933737744343

Epoch: 6| Step: 7
Training loss: 3.397091373125439
Validation loss: 2.9116500400125993

Epoch: 6| Step: 8
Training loss: 3.127969780271073
Validation loss: 2.9094282839901737

Epoch: 6| Step: 9
Training loss: 2.817448395440104
Validation loss: 2.906788574412498

Epoch: 6| Step: 10
Training loss: 3.678513779102489
Validation loss: 2.907209873632083

Epoch: 6| Step: 11
Training loss: 3.260132181027106
Validation loss: 2.901713368279019

Epoch: 6| Step: 12
Training loss: 2.656870690923089
Validation loss: 2.899222035578767

Epoch: 6| Step: 13
Training loss: 3.258215863255881
Validation loss: 2.900011497233609

Epoch: 46| Step: 0
Training loss: 2.707156664212443
Validation loss: 2.8973818739169

Epoch: 6| Step: 1
Training loss: 3.181565688382402
Validation loss: 2.8961083169547974

Epoch: 6| Step: 2
Training loss: 3.1941217194966067
Validation loss: 2.8925822874215705

Epoch: 6| Step: 3
Training loss: 2.537671926151813
Validation loss: 2.8908700512639585

Epoch: 6| Step: 4
Training loss: 3.0792705127788205
Validation loss: 2.888314665880612

Epoch: 6| Step: 5
Training loss: 3.3340550277187155
Validation loss: 2.8854765122653627

Epoch: 6| Step: 6
Training loss: 3.7716102993931226
Validation loss: 2.882157965618413

Epoch: 6| Step: 7
Training loss: 2.331618996224445
Validation loss: 2.880256615637012

Epoch: 6| Step: 8
Training loss: 2.7461426297825704
Validation loss: 2.878975662505763

Epoch: 6| Step: 9
Training loss: 3.0231149585203005
Validation loss: 2.8757804903075854

Epoch: 6| Step: 10
Training loss: 2.895829418005915
Validation loss: 2.872868203650431

Epoch: 6| Step: 11
Training loss: 2.980960670362746
Validation loss: 2.871775629637167

Epoch: 6| Step: 12
Training loss: 2.945966329274694
Validation loss: 2.871082594800112

Epoch: 6| Step: 13
Training loss: 3.3661767987190414
Validation loss: 2.867315582269521

Epoch: 47| Step: 0
Training loss: 2.517218043913365
Validation loss: 2.8657151546738655

Epoch: 6| Step: 1
Training loss: 3.401284334289132
Validation loss: 2.8650870186692976

Epoch: 6| Step: 2
Training loss: 2.6504216596435124
Validation loss: 2.862703592092766

Epoch: 6| Step: 3
Training loss: 2.909267049030261
Validation loss: 2.861395755875576

Epoch: 6| Step: 4
Training loss: 2.8293356648806145
Validation loss: 2.859149083174522

Epoch: 6| Step: 5
Training loss: 2.7666580081329286
Validation loss: 2.8573098707204454

Epoch: 6| Step: 6
Training loss: 3.5080015815461616
Validation loss: 2.8545849393848344

Epoch: 6| Step: 7
Training loss: 3.020196325729052
Validation loss: 2.8514622918902757

Epoch: 6| Step: 8
Training loss: 3.2506214428020215
Validation loss: 2.8490076473415074

Epoch: 6| Step: 9
Training loss: 3.19824278387399
Validation loss: 2.8463685272962063

Epoch: 6| Step: 10
Training loss: 3.1994333719218453
Validation loss: 2.8451794675102158

Epoch: 6| Step: 11
Training loss: 2.7805307722770904
Validation loss: 2.8423152000815435

Epoch: 6| Step: 12
Training loss: 3.170131862075964
Validation loss: 2.840631179047464

Epoch: 6| Step: 13
Training loss: 2.5185560128074256
Validation loss: 2.8389615416224645

Epoch: 48| Step: 0
Training loss: 2.7936348500939023
Validation loss: 2.8370686106515275

Epoch: 6| Step: 1
Training loss: 2.758422265439107
Validation loss: 2.834846167497568

Epoch: 6| Step: 2
Training loss: 2.738941064156654
Validation loss: 2.8329945436517803

Epoch: 6| Step: 3
Training loss: 2.5783277952023362
Validation loss: 2.830906829359037

Epoch: 6| Step: 4
Training loss: 2.8314959421346
Validation loss: 2.8286966269539215

Epoch: 6| Step: 5
Training loss: 3.4366119624858267
Validation loss: 2.827660482064461

Epoch: 6| Step: 6
Training loss: 3.1921757829015105
Validation loss: 2.825936737156061

Epoch: 6| Step: 7
Training loss: 2.610956135562889
Validation loss: 2.824323667175267

Epoch: 6| Step: 8
Training loss: 2.8346223330016915
Validation loss: 2.8219471682490433

Epoch: 6| Step: 9
Training loss: 2.613514249760964
Validation loss: 2.82099614614976

Epoch: 6| Step: 10
Training loss: 2.7856246318992355
Validation loss: 2.817098573905735

Epoch: 6| Step: 11
Training loss: 3.511011512835257
Validation loss: 2.815588308103037

Epoch: 6| Step: 12
Training loss: 3.5395925095506393
Validation loss: 2.8148975749379153

Epoch: 6| Step: 13
Training loss: 3.073527509246933
Validation loss: 2.812991120585813

Epoch: 49| Step: 0
Training loss: 2.851598953641137
Validation loss: 2.8108391131573387

Epoch: 6| Step: 1
Training loss: 3.4034017150863827
Validation loss: 2.808332831687392

Epoch: 6| Step: 2
Training loss: 2.712709227196745
Validation loss: 2.8070326186050347

Epoch: 6| Step: 3
Training loss: 3.034952635544746
Validation loss: 2.8051483710720237

Epoch: 6| Step: 4
Training loss: 3.344021509858816
Validation loss: 2.8038033284503956

Epoch: 6| Step: 5
Training loss: 2.679567740297175
Validation loss: 2.802343495899533

Epoch: 6| Step: 6
Training loss: 2.871329244700044
Validation loss: 2.801480442312686

Epoch: 6| Step: 7
Training loss: 3.1084903244449658
Validation loss: 2.801794290111238

Epoch: 6| Step: 8
Training loss: 3.140295210646567
Validation loss: 2.7973232087745155

Epoch: 6| Step: 9
Training loss: 2.5686981789960908
Validation loss: 2.7992882857193093

Epoch: 6| Step: 10
Training loss: 2.9984218897172146
Validation loss: 2.795192830662412

Epoch: 6| Step: 11
Training loss: 2.366084783058832
Validation loss: 2.791967892882998

Epoch: 6| Step: 12
Training loss: 3.0835888387304125
Validation loss: 2.7904257269975146

Epoch: 6| Step: 13
Training loss: 2.869275239885794
Validation loss: 2.7877799396760756

Epoch: 50| Step: 0
Training loss: 2.7249275267876607
Validation loss: 2.7869219432914276

Epoch: 6| Step: 1
Training loss: 3.0303234768668976
Validation loss: 2.7845198879370816

Epoch: 6| Step: 2
Training loss: 2.1463655225426685
Validation loss: 2.7837446361913165

Epoch: 6| Step: 3
Training loss: 2.7227490708935624
Validation loss: 2.7814606576071292

Epoch: 6| Step: 4
Training loss: 2.916609154997065
Validation loss: 2.782361883441158

Epoch: 6| Step: 5
Training loss: 3.5186457562631746
Validation loss: 2.7788837668247837

Epoch: 6| Step: 6
Training loss: 3.1310524883908597
Validation loss: 2.7766065517831566

Epoch: 6| Step: 7
Training loss: 2.7647527838728396
Validation loss: 2.7759943964633216

Epoch: 6| Step: 8
Training loss: 2.72534729730546
Validation loss: 2.773372738937268

Epoch: 6| Step: 9
Training loss: 3.145613319501104
Validation loss: 2.7721375763566525

Epoch: 6| Step: 10
Training loss: 2.963557631589842
Validation loss: 2.770341784155174

Epoch: 6| Step: 11
Training loss: 2.8192469731807064
Validation loss: 2.769940416450365

Epoch: 6| Step: 12
Training loss: 3.060543914774015
Validation loss: 2.770289365295672

Epoch: 6| Step: 13
Training loss: 2.99586201434318
Validation loss: 2.7701481041178946

Epoch: 51| Step: 0
Training loss: 3.205972438643812
Validation loss: 2.7677851572359073

Epoch: 6| Step: 1
Training loss: 3.4331840470335497
Validation loss: 2.76505578284303

Epoch: 6| Step: 2
Training loss: 3.1707927191627503
Validation loss: 2.7630566526650497

Epoch: 6| Step: 3
Training loss: 2.6874009934751912
Validation loss: 2.7614717062778977

Epoch: 6| Step: 4
Training loss: 2.982808765630847
Validation loss: 2.7585198177058845

Epoch: 6| Step: 5
Training loss: 2.4933084579831655
Validation loss: 2.75756637440329

Epoch: 6| Step: 6
Training loss: 2.5832407739936554
Validation loss: 2.755546294302742

Epoch: 6| Step: 7
Training loss: 2.9386795597566673
Validation loss: 2.7538977223798597

Epoch: 6| Step: 8
Training loss: 2.6828284359227035
Validation loss: 2.751892349081044

Epoch: 6| Step: 9
Training loss: 3.175000534658312
Validation loss: 2.7523707949843317

Epoch: 6| Step: 10
Training loss: 3.0226983638066782
Validation loss: 2.7512144672664913

Epoch: 6| Step: 11
Training loss: 2.0799157021019727
Validation loss: 2.7495726340010034

Epoch: 6| Step: 12
Training loss: 3.119454613481544
Validation loss: 2.748254742382576

Epoch: 6| Step: 13
Training loss: 2.695223687961616
Validation loss: 2.743834990544253

Epoch: 52| Step: 0
Training loss: 3.0286522184891225
Validation loss: 2.7442452298790405

Epoch: 6| Step: 1
Training loss: 3.0817838504256962
Validation loss: 2.744533365004315

Epoch: 6| Step: 2
Training loss: 3.1469629209144414
Validation loss: 2.74095656543486

Epoch: 6| Step: 3
Training loss: 3.0088215510153624
Validation loss: 2.7387435312454436

Epoch: 6| Step: 4
Training loss: 2.9477420570953043
Validation loss: 2.7362081577197355

Epoch: 6| Step: 5
Training loss: 2.9289439160521504
Validation loss: 2.733565074315625

Epoch: 6| Step: 6
Training loss: 2.5163232059508256
Validation loss: 2.7329910263628845

Epoch: 6| Step: 7
Training loss: 2.769542957706213
Validation loss: 2.733736672144366

Epoch: 6| Step: 8
Training loss: 3.054568549374387
Validation loss: 2.7336760581316146

Epoch: 6| Step: 9
Training loss: 2.8354979455543896
Validation loss: 2.735751432303934

Epoch: 6| Step: 10
Training loss: 2.7800945496432408
Validation loss: 2.7387056915120804

Epoch: 6| Step: 11
Training loss: 2.6130158385108095
Validation loss: 2.738072683506036

Epoch: 6| Step: 12
Training loss: 2.5767115561986476
Validation loss: 2.735006844316156

Epoch: 6| Step: 13
Training loss: 2.927326359734091
Validation loss: 2.7323166138681665

Epoch: 53| Step: 0
Training loss: 2.7310465581969763
Validation loss: 2.727138673372872

Epoch: 6| Step: 1
Training loss: 2.975393791742932
Validation loss: 2.725379140533618

Epoch: 6| Step: 2
Training loss: 2.9773371131600785
Validation loss: 2.7219838315897906

Epoch: 6| Step: 3
Training loss: 3.296277321972411
Validation loss: 2.7211430566602677

Epoch: 6| Step: 4
Training loss: 2.6747865039086203
Validation loss: 2.7194524274151894

Epoch: 6| Step: 5
Training loss: 3.1168914883829375
Validation loss: 2.7181024328274326

Epoch: 6| Step: 6
Training loss: 2.975400843182697
Validation loss: 2.7161304599013576

Epoch: 6| Step: 7
Training loss: 2.769824960734947
Validation loss: 2.7137210857409553

Epoch: 6| Step: 8
Training loss: 3.238510951970852
Validation loss: 2.7134419652935855

Epoch: 6| Step: 9
Training loss: 2.454442053360487
Validation loss: 2.7112688050849774

Epoch: 6| Step: 10
Training loss: 2.4196449102816318
Validation loss: 2.7105819219769938

Epoch: 6| Step: 11
Training loss: 3.056404431269748
Validation loss: 2.7087806087795374

Epoch: 6| Step: 12
Training loss: 2.9499242481915293
Validation loss: 2.7078128803690946

Epoch: 6| Step: 13
Training loss: 2.126474317842701
Validation loss: 2.7077206187536844

Epoch: 54| Step: 0
Training loss: 2.960335461448841
Validation loss: 2.7058429467684744

Epoch: 6| Step: 1
Training loss: 2.7648053867495124
Validation loss: 2.704032774923167

Epoch: 6| Step: 2
Training loss: 3.1900424167599306
Validation loss: 2.703646791404437

Epoch: 6| Step: 3
Training loss: 3.0041532377735645
Validation loss: 2.706108034916569

Epoch: 6| Step: 4
Training loss: 2.7685639019632813
Validation loss: 2.7050568103524353

Epoch: 6| Step: 5
Training loss: 2.9063671457615112
Validation loss: 2.7010186134195107

Epoch: 6| Step: 6
Training loss: 2.959683517599986
Validation loss: 2.699580770488295

Epoch: 6| Step: 7
Training loss: 2.833820151599485
Validation loss: 2.696706881095574

Epoch: 6| Step: 8
Training loss: 3.167020945222887
Validation loss: 2.696926632442527

Epoch: 6| Step: 9
Training loss: 2.5499419486225987
Validation loss: 2.695946100186704

Epoch: 6| Step: 10
Training loss: 2.7063337916557724
Validation loss: 2.698987274623297

Epoch: 6| Step: 11
Training loss: 2.60243260951375
Validation loss: 2.6985403147719365

Epoch: 6| Step: 12
Training loss: 2.8969913792611934
Validation loss: 2.702221596346366

Epoch: 6| Step: 13
Training loss: 2.3568002154519165
Validation loss: 2.7013714344950257

Epoch: 55| Step: 0
Training loss: 1.947431398488493
Validation loss: 2.6989544427613743

Epoch: 6| Step: 1
Training loss: 2.8861762377142677
Validation loss: 2.695759110605719

Epoch: 6| Step: 2
Training loss: 2.9683516385690076
Validation loss: 2.694896603253976

Epoch: 6| Step: 3
Training loss: 3.08575516174127
Validation loss: 2.693025704329289

Epoch: 6| Step: 4
Training loss: 3.1268090161885906
Validation loss: 2.6855304213511113

Epoch: 6| Step: 5
Training loss: 3.4688706935470806
Validation loss: 2.685178397128659

Epoch: 6| Step: 6
Training loss: 2.7702035881446125
Validation loss: 2.682007107254234

Epoch: 6| Step: 7
Training loss: 2.853783983252988
Validation loss: 2.682119809666594

Epoch: 6| Step: 8
Training loss: 2.6666636367621694
Validation loss: 2.680423246312636

Epoch: 6| Step: 9
Training loss: 2.3716435054346
Validation loss: 2.681217094403239

Epoch: 6| Step: 10
Training loss: 2.65046726641675
Validation loss: 2.6827641981364927

Epoch: 6| Step: 11
Training loss: 2.950593539512448
Validation loss: 2.6796648415663156

Epoch: 6| Step: 12
Training loss: 2.9498531240333206
Validation loss: 2.6753965375050255

Epoch: 6| Step: 13
Training loss: 2.5912909743459545
Validation loss: 2.6759509698731554

Epoch: 56| Step: 0
Training loss: 3.121032179510418
Validation loss: 2.6741978324943547

Epoch: 6| Step: 1
Training loss: 3.1723210063487866
Validation loss: 2.6754723140828935

Epoch: 6| Step: 2
Training loss: 3.044540998067856
Validation loss: 2.6746380148085445

Epoch: 6| Step: 3
Training loss: 2.8779601738502336
Validation loss: 2.676581656110379

Epoch: 6| Step: 4
Training loss: 2.971311407870933
Validation loss: 2.6735898588142306

Epoch: 6| Step: 5
Training loss: 2.9216142017842435
Validation loss: 2.6709610117498612

Epoch: 6| Step: 6
Training loss: 2.7437544907378895
Validation loss: 2.669982314152429

Epoch: 6| Step: 7
Training loss: 2.6414887409479313
Validation loss: 2.6678380827138684

Epoch: 6| Step: 8
Training loss: 2.8155319825112017
Validation loss: 2.6653163043955983

Epoch: 6| Step: 9
Training loss: 2.4787946683751536
Validation loss: 2.663210362454926

Epoch: 6| Step: 10
Training loss: 2.213562717711635
Validation loss: 2.65924578007958

Epoch: 6| Step: 11
Training loss: 3.0383993567740757
Validation loss: 2.6616053282474286

Epoch: 6| Step: 12
Training loss: 2.1798200669532317
Validation loss: 2.6603904318555287

Epoch: 6| Step: 13
Training loss: 2.9236242596553867
Validation loss: 2.6575675539011567

Epoch: 57| Step: 0
Training loss: 2.518874350381828
Validation loss: 2.661208532346855

Epoch: 6| Step: 1
Training loss: 3.2453659471969547
Validation loss: 2.654410484489359

Epoch: 6| Step: 2
Training loss: 2.561154454219171
Validation loss: 2.6552863972441028

Epoch: 6| Step: 3
Training loss: 3.261558958239714
Validation loss: 2.6544716959670804

Epoch: 6| Step: 4
Training loss: 2.767521611984762
Validation loss: 2.6544260532064405

Epoch: 6| Step: 5
Training loss: 2.8276899645980764
Validation loss: 2.6534113956674332

Epoch: 6| Step: 6
Training loss: 2.6147586312870517
Validation loss: 2.6534922177541054

Epoch: 6| Step: 7
Training loss: 3.1792063806002306
Validation loss: 2.6531861980016553

Epoch: 6| Step: 8
Training loss: 2.9896879986419376
Validation loss: 2.650469440290028

Epoch: 6| Step: 9
Training loss: 2.8127861725069137
Validation loss: 2.6516902457467055

Epoch: 6| Step: 10
Training loss: 2.531111913611501
Validation loss: 2.651487846275202

Epoch: 6| Step: 11
Training loss: 2.7924463597185745
Validation loss: 2.650332003015181

Epoch: 6| Step: 12
Training loss: 2.1235237603705204
Validation loss: 2.6474102207242933

Epoch: 6| Step: 13
Training loss: 2.5743267401357635
Validation loss: 2.6468459817195686

Epoch: 58| Step: 0
Training loss: 3.2206370923529475
Validation loss: 2.645336590090344

Epoch: 6| Step: 1
Training loss: 2.7770820848519873
Validation loss: 2.6441538929823585

Epoch: 6| Step: 2
Training loss: 3.0864693098916955
Validation loss: 2.643293007266042

Epoch: 6| Step: 3
Training loss: 2.70679942978348
Validation loss: 2.641507514788401

Epoch: 6| Step: 4
Training loss: 2.52593086759996
Validation loss: 2.640616753619859

Epoch: 6| Step: 5
Training loss: 2.6040561398257167
Validation loss: 2.6411603125434406

Epoch: 6| Step: 6
Training loss: 3.081833053424089
Validation loss: 2.639258172035122

Epoch: 6| Step: 7
Training loss: 2.703830428494632
Validation loss: 2.637849330818963

Epoch: 6| Step: 8
Training loss: 2.6861012389474905
Validation loss: 2.6373401653678945

Epoch: 6| Step: 9
Training loss: 2.8836443768203757
Validation loss: 2.635704256029549

Epoch: 6| Step: 10
Training loss: 3.2343033492403315
Validation loss: 2.6328851706779215

Epoch: 6| Step: 11
Training loss: 2.0707840292553668
Validation loss: 2.634746637221742

Epoch: 6| Step: 12
Training loss: 2.449094534953213
Validation loss: 2.6332152800917736

Epoch: 6| Step: 13
Training loss: 2.605654319548815
Validation loss: 2.6663045388945044

Epoch: 59| Step: 0
Training loss: 2.5713351456003855
Validation loss: 2.665206678390933

Epoch: 6| Step: 1
Training loss: 2.767154421573627
Validation loss: 2.633911778702057

Epoch: 6| Step: 2
Training loss: 2.5977820803346763
Validation loss: 2.6283393539604876

Epoch: 6| Step: 3
Training loss: 2.9722532783700064
Validation loss: 2.631257666835655

Epoch: 6| Step: 4
Training loss: 2.880595359989098
Validation loss: 2.634806390196709

Epoch: 6| Step: 5
Training loss: 2.639928150210749
Validation loss: 2.639523037344983

Epoch: 6| Step: 6
Training loss: 3.0561129861087113
Validation loss: 2.6439614069397304

Epoch: 6| Step: 7
Training loss: 2.922628866443154
Validation loss: 2.646324792909261

Epoch: 6| Step: 8
Training loss: 2.6573102742292196
Validation loss: 2.6417825482901423

Epoch: 6| Step: 9
Training loss: 2.420131621919215
Validation loss: 2.64042923180932

Epoch: 6| Step: 10
Training loss: 3.2616997449857994
Validation loss: 2.6379316540199285

Epoch: 6| Step: 11
Training loss: 2.4068895951400346
Validation loss: 2.6345594215625154

Epoch: 6| Step: 12
Training loss: 2.703874693529063
Validation loss: 2.62982684601298

Epoch: 6| Step: 13
Training loss: 2.905831583728342
Validation loss: 2.6270426265780524

Epoch: 60| Step: 0
Training loss: 2.905011313017518
Validation loss: 2.623576626052605

Epoch: 6| Step: 1
Training loss: 2.8939318737771758
Validation loss: 2.622649987692161

Epoch: 6| Step: 2
Training loss: 2.7730336069793693
Validation loss: 2.621564024168693

Epoch: 6| Step: 3
Training loss: 2.2546586445252683
Validation loss: 2.6206769161721017

Epoch: 6| Step: 4
Training loss: 2.491059912182761
Validation loss: 2.6201482622406003

Epoch: 6| Step: 5
Training loss: 2.9789625689257235
Validation loss: 2.619223778959982

Epoch: 6| Step: 6
Training loss: 2.211039402638667
Validation loss: 2.617117612294688

Epoch: 6| Step: 7
Training loss: 2.9580629431145047
Validation loss: 2.62002135243827

Epoch: 6| Step: 8
Training loss: 2.8327413576327727
Validation loss: 2.6173652550604443

Epoch: 6| Step: 9
Training loss: 3.0018614715900362
Validation loss: 2.622374038580466

Epoch: 6| Step: 10
Training loss: 2.5446665731677722
Validation loss: 2.6149169638088616

Epoch: 6| Step: 11
Training loss: 2.340830192179036
Validation loss: 2.615758386125441

Epoch: 6| Step: 12
Training loss: 3.164385894449231
Validation loss: 2.6136279596035306

Epoch: 6| Step: 13
Training loss: 2.993877521259794
Validation loss: 2.6111746119720443

Epoch: 61| Step: 0
Training loss: 3.110434960126046
Validation loss: 2.6121871322848804

Epoch: 6| Step: 1
Training loss: 3.0465651134480147
Validation loss: 2.6106698940618878

Epoch: 6| Step: 2
Training loss: 2.6473280121554397
Validation loss: 2.611777214440404

Epoch: 6| Step: 3
Training loss: 2.5982697414946454
Validation loss: 2.6131777132257694

Epoch: 6| Step: 4
Training loss: 2.598068778187018
Validation loss: 2.613990721597819

Epoch: 6| Step: 5
Training loss: 2.7277967397527556
Validation loss: 2.613163252116156

Epoch: 6| Step: 6
Training loss: 3.0178301560911582
Validation loss: 2.615202482151072

Epoch: 6| Step: 7
Training loss: 2.7241461684828003
Validation loss: 2.613233975456609

Epoch: 6| Step: 8
Training loss: 2.6702330602589455
Validation loss: 2.6121320796995415

Epoch: 6| Step: 9
Training loss: 2.4207804513781115
Validation loss: 2.609507483128645

Epoch: 6| Step: 10
Training loss: 2.8745531481243485
Validation loss: 2.607903970066931

Epoch: 6| Step: 11
Training loss: 2.55961595456015
Validation loss: 2.6056251154870824

Epoch: 6| Step: 12
Training loss: 3.0482373444169255
Validation loss: 2.6023764649557197

Epoch: 6| Step: 13
Training loss: 2.2235712671956014
Validation loss: 2.599705289986254

Epoch: 62| Step: 0
Training loss: 2.88916440611748
Validation loss: 2.5987251549175783

Epoch: 6| Step: 1
Training loss: 2.922457550236542
Validation loss: 2.59574447304214

Epoch: 6| Step: 2
Training loss: 2.402375309434471
Validation loss: 2.599414049047715

Epoch: 6| Step: 3
Training loss: 2.0242841562049176
Validation loss: 2.5992836809088598

Epoch: 6| Step: 4
Training loss: 2.615673025549431
Validation loss: 2.5937917621728124

Epoch: 6| Step: 5
Training loss: 2.8058976561791957
Validation loss: 2.5961005808590873

Epoch: 6| Step: 6
Training loss: 3.1577211482874477
Validation loss: 2.5927311378376263

Epoch: 6| Step: 7
Training loss: 3.28746142346626
Validation loss: 2.5972394030360277

Epoch: 6| Step: 8
Training loss: 2.6296695774349326
Validation loss: 2.5926104880527716

Epoch: 6| Step: 9
Training loss: 2.6908652948170917
Validation loss: 2.5939422137878596

Epoch: 6| Step: 10
Training loss: 2.8491843143826654
Validation loss: 2.5959387586890674

Epoch: 6| Step: 11
Training loss: 2.766964173311458
Validation loss: 2.597446978177487

Epoch: 6| Step: 12
Training loss: 2.683479317747632
Validation loss: 2.596199518238534

Epoch: 6| Step: 13
Training loss: 2.3442107701370754
Validation loss: 2.598367846930382

Epoch: 63| Step: 0
Training loss: 3.2274289941991996
Validation loss: 2.5989119093016164

Epoch: 6| Step: 1
Training loss: 2.0901866595860814
Validation loss: 2.595594087620703

Epoch: 6| Step: 2
Training loss: 2.6997016883227336
Validation loss: 2.5942082593920524

Epoch: 6| Step: 3
Training loss: 2.8926110945116346
Validation loss: 2.5938423017754366

Epoch: 6| Step: 4
Training loss: 2.629767856288138
Validation loss: 2.591033217444531

Epoch: 6| Step: 5
Training loss: 2.938305683435037
Validation loss: 2.5896562189068266

Epoch: 6| Step: 6
Training loss: 2.7394043799915155
Validation loss: 2.589420535268588

Epoch: 6| Step: 7
Training loss: 2.7114622284349172
Validation loss: 2.5888277096630072

Epoch: 6| Step: 8
Training loss: 2.7728295747955003
Validation loss: 2.5842468635869964

Epoch: 6| Step: 9
Training loss: 2.6934512581204446
Validation loss: 2.5860644075998023

Epoch: 6| Step: 10
Training loss: 2.3097462109285787
Validation loss: 2.583963337853707

Epoch: 6| Step: 11
Training loss: 2.2255525138725427
Validation loss: 2.580772427768251

Epoch: 6| Step: 12
Training loss: 2.7355523762640135
Validation loss: 2.578652776776723

Epoch: 6| Step: 13
Training loss: 3.2301693907925153
Validation loss: 2.5822163494821733

Epoch: 64| Step: 0
Training loss: 3.011323697592494
Validation loss: 2.580629477065503

Epoch: 6| Step: 1
Training loss: 2.587850364515838
Validation loss: 2.5798698146759396

Epoch: 6| Step: 2
Training loss: 2.0579741557123192
Validation loss: 2.581537058018815

Epoch: 6| Step: 3
Training loss: 1.882440933982812
Validation loss: 2.5840967086168143

Epoch: 6| Step: 4
Training loss: 2.6184202109463883
Validation loss: 2.585594746135498

Epoch: 6| Step: 5
Training loss: 2.6416333321795684
Validation loss: 2.582115383576138

Epoch: 6| Step: 6
Training loss: 3.1260468827513095
Validation loss: 2.576268816809347

Epoch: 6| Step: 7
Training loss: 2.449517190811
Validation loss: 2.575240446179074

Epoch: 6| Step: 8
Training loss: 3.0915244989191
Validation loss: 2.5779646390113027

Epoch: 6| Step: 9
Training loss: 2.559298306202189
Validation loss: 2.5755965655962783

Epoch: 6| Step: 10
Training loss: 3.059152914993301
Validation loss: 2.5788810160951954

Epoch: 6| Step: 11
Training loss: 2.0975178081497594
Validation loss: 2.578216682114001

Epoch: 6| Step: 12
Training loss: 3.314473122315558
Validation loss: 2.578903851242668

Epoch: 6| Step: 13
Training loss: 2.914966432826353
Validation loss: 2.583003974243466

Epoch: 65| Step: 0
Training loss: 2.7444195914419467
Validation loss: 2.5816578866831073

Epoch: 6| Step: 1
Training loss: 3.1814592753526703
Validation loss: 2.5838170419086834

Epoch: 6| Step: 2
Training loss: 1.9869010046654811
Validation loss: 2.5806534823737275

Epoch: 6| Step: 3
Training loss: 2.609294410420462
Validation loss: 2.577146448479362

Epoch: 6| Step: 4
Training loss: 2.6694923172529563
Validation loss: 2.5759969694828584

Epoch: 6| Step: 5
Training loss: 3.068093466209108
Validation loss: 2.5751587574977473

Epoch: 6| Step: 6
Training loss: 2.1477571277093843
Validation loss: 2.572553019494714

Epoch: 6| Step: 7
Training loss: 2.7692428460224616
Validation loss: 2.573789631219006

Epoch: 6| Step: 8
Training loss: 3.046789706087796
Validation loss: 2.573935709758298

Epoch: 6| Step: 9
Training loss: 3.1911117436500755
Validation loss: 2.5727022727775273

Epoch: 6| Step: 10
Training loss: 2.367886178928342
Validation loss: 2.571178533871102

Epoch: 6| Step: 11
Training loss: 2.6569281217352083
Validation loss: 2.568449386740593

Epoch: 6| Step: 12
Training loss: 2.4978039633104996
Validation loss: 2.5667353263770685

Epoch: 6| Step: 13
Training loss: 2.6880405680796726
Validation loss: 2.5662635055164316

Epoch: 66| Step: 0
Training loss: 3.2174131709833884
Validation loss: 2.56583660273784

Epoch: 6| Step: 1
Training loss: 2.760739423968373
Validation loss: 2.561988795081995

Epoch: 6| Step: 2
Training loss: 2.4795865149507756
Validation loss: 2.5625626316014856

Epoch: 6| Step: 3
Training loss: 2.8912900417406675
Validation loss: 2.5612959630468377

Epoch: 6| Step: 4
Training loss: 2.7486169978738357
Validation loss: 2.5630342655389335

Epoch: 6| Step: 5
Training loss: 2.4103028486234916
Validation loss: 2.5606253675218933

Epoch: 6| Step: 6
Training loss: 2.9721907101997767
Validation loss: 2.5602758726348562

Epoch: 6| Step: 7
Training loss: 2.213361617600828
Validation loss: 2.5586433541728604

Epoch: 6| Step: 8
Training loss: 2.6589106978117916
Validation loss: 2.5611456726879296

Epoch: 6| Step: 9
Training loss: 2.454432048168608
Validation loss: 2.558545620298151

Epoch: 6| Step: 10
Training loss: 2.6263241833936033
Validation loss: 2.5567200611694507

Epoch: 6| Step: 11
Training loss: 2.8022931858219615
Validation loss: 2.556710549474888

Epoch: 6| Step: 12
Training loss: 2.8456409581082744
Validation loss: 2.556184040639396

Epoch: 6| Step: 13
Training loss: 2.4641489539887496
Validation loss: 2.55560272341428

Epoch: 67| Step: 0
Training loss: 2.7246979292284847
Validation loss: 2.556499759998605

Epoch: 6| Step: 1
Training loss: 2.337477160663508
Validation loss: 2.558673078942758

Epoch: 6| Step: 2
Training loss: 3.0504898928575033
Validation loss: 2.557168236348016

Epoch: 6| Step: 3
Training loss: 2.745014700372519
Validation loss: 2.556957119400277

Epoch: 6| Step: 4
Training loss: 3.0703724474308296
Validation loss: 2.554013255637314

Epoch: 6| Step: 5
Training loss: 2.5484756401384154
Validation loss: 2.5560845959662686

Epoch: 6| Step: 6
Training loss: 2.4795681497447326
Validation loss: 2.5526089393017437

Epoch: 6| Step: 7
Training loss: 2.1576734626498375
Validation loss: 2.5528523875838296

Epoch: 6| Step: 8
Training loss: 3.171604238895697
Validation loss: 2.550687093978313

Epoch: 6| Step: 9
Training loss: 1.779984074532064
Validation loss: 2.54969478600682

Epoch: 6| Step: 10
Training loss: 2.6108222648352704
Validation loss: 2.5508619824378895

Epoch: 6| Step: 11
Training loss: 2.8890472230151456
Validation loss: 2.549366175349559

Epoch: 6| Step: 12
Training loss: 2.6686787365727715
Validation loss: 2.5489592030072545

Epoch: 6| Step: 13
Training loss: 2.9969546437743797
Validation loss: 2.547163933276901

Epoch: 68| Step: 0
Training loss: 2.8468148619814455
Validation loss: 2.547938009959232

Epoch: 6| Step: 1
Training loss: 2.5774790561539214
Validation loss: 2.548632056634975

Epoch: 6| Step: 2
Training loss: 3.130403196306788
Validation loss: 2.5473132234285574

Epoch: 6| Step: 3
Training loss: 2.333740834574179
Validation loss: 2.5503712159521217

Epoch: 6| Step: 4
Training loss: 3.042972040725515
Validation loss: 2.5488483608412067

Epoch: 6| Step: 5
Training loss: 2.5624862298362867
Validation loss: 2.5474576069178023

Epoch: 6| Step: 6
Training loss: 2.8639907686415067
Validation loss: 2.5468276785918453

Epoch: 6| Step: 7
Training loss: 2.1912941861525836
Validation loss: 2.5401763194504614

Epoch: 6| Step: 8
Training loss: 2.714380370189002
Validation loss: 2.5427914043412647

Epoch: 6| Step: 9
Training loss: 2.7782348405130417
Validation loss: 2.5437135011146137

Epoch: 6| Step: 10
Training loss: 2.7150738296165273
Validation loss: 2.5438511533878017

Epoch: 6| Step: 11
Training loss: 2.2538171813396612
Validation loss: 2.546127287589277

Epoch: 6| Step: 12
Training loss: 2.5952859030870195
Validation loss: 2.540774131361276

Epoch: 6| Step: 13
Training loss: 2.6299136358665276
Validation loss: 2.545969593461854

Epoch: 69| Step: 0
Training loss: 2.3862890677753463
Validation loss: 2.541599981548408

Epoch: 6| Step: 1
Training loss: 2.514546417833436
Validation loss: 2.538413879492519

Epoch: 6| Step: 2
Training loss: 2.893020544533645
Validation loss: 2.5433634790039696

Epoch: 6| Step: 3
Training loss: 2.4966662113136655
Validation loss: 2.5423884747856733

Epoch: 6| Step: 4
Training loss: 2.0776967919671496
Validation loss: 2.550057527105146

Epoch: 6| Step: 5
Training loss: 3.017019947364115
Validation loss: 2.562723382656982

Epoch: 6| Step: 6
Training loss: 2.9884077855665
Validation loss: 2.5713229835746367

Epoch: 6| Step: 7
Training loss: 2.7941231429338287
Validation loss: 2.5679111877742784

Epoch: 6| Step: 8
Training loss: 2.7713530108105253
Validation loss: 2.558501372477561

Epoch: 6| Step: 9
Training loss: 2.742375467927812
Validation loss: 2.54345115699512

Epoch: 6| Step: 10
Training loss: 3.0740634825684454
Validation loss: 2.538738476545363

Epoch: 6| Step: 11
Training loss: 2.261149016782979
Validation loss: 2.546026310784016

Epoch: 6| Step: 12
Training loss: 2.529622249221192
Validation loss: 2.567201178698667

Epoch: 6| Step: 13
Training loss: 2.699544398403897
Validation loss: 2.600907664322105

Epoch: 70| Step: 0
Training loss: 2.980015791524739
Validation loss: 2.6294860653897016

Epoch: 6| Step: 1
Training loss: 2.8987556550240967
Validation loss: 2.6180539039811226

Epoch: 6| Step: 2
Training loss: 3.0128853958976727
Validation loss: 2.6082611600094188

Epoch: 6| Step: 3
Training loss: 2.36740614885294
Validation loss: 2.5993933507906424

Epoch: 6| Step: 4
Training loss: 3.0015771217129057
Validation loss: 2.580340163972828

Epoch: 6| Step: 5
Training loss: 2.2199942095569325
Validation loss: 2.5661798587311413

Epoch: 6| Step: 6
Training loss: 2.993349810712813
Validation loss: 2.5526521995916878

Epoch: 6| Step: 7
Training loss: 2.4101395320467085
Validation loss: 2.5454896150635786

Epoch: 6| Step: 8
Training loss: 2.74430760863163
Validation loss: 2.5414007600196715

Epoch: 6| Step: 9
Training loss: 2.221641268555178
Validation loss: 2.5360991023186603

Epoch: 6| Step: 10
Training loss: 2.4719675078123853
Validation loss: 2.535597501735256

Epoch: 6| Step: 11
Training loss: 2.731403501897778
Validation loss: 2.534842684828511

Epoch: 6| Step: 12
Training loss: 2.885732768861533
Validation loss: 2.5394829035223103

Epoch: 6| Step: 13
Training loss: 2.5880635444882025
Validation loss: 2.5366853981813584

Epoch: 71| Step: 0
Training loss: 2.684639672763722
Validation loss: 2.536511200674392

Epoch: 6| Step: 1
Training loss: 2.613168665537749
Validation loss: 2.543191238881936

Epoch: 6| Step: 2
Training loss: 3.120726447997713
Validation loss: 2.5529234664608107

Epoch: 6| Step: 3
Training loss: 2.7621433735566234
Validation loss: 2.5500769584860885

Epoch: 6| Step: 4
Training loss: 2.7478725700706055
Validation loss: 2.5436057734861888

Epoch: 6| Step: 5
Training loss: 2.6756643450739483
Validation loss: 2.530552316596811

Epoch: 6| Step: 6
Training loss: 2.804294994378592
Validation loss: 2.5306807925875514

Epoch: 6| Step: 7
Training loss: 2.5745806750742575
Validation loss: 2.531439911425246

Epoch: 6| Step: 8
Training loss: 2.5552828500433344
Validation loss: 2.5318590224292463

Epoch: 6| Step: 9
Training loss: 2.6119778380512626
Validation loss: 2.53691121835755

Epoch: 6| Step: 10
Training loss: 2.6483897877224196
Validation loss: 2.5387704534566016

Epoch: 6| Step: 11
Training loss: 2.2370086300870597
Validation loss: 2.541410532276491

Epoch: 6| Step: 12
Training loss: 2.791292212884993
Validation loss: 2.544062647246092

Epoch: 6| Step: 13
Training loss: 2.6694619508880004
Validation loss: 2.544935943182088

Epoch: 72| Step: 0
Training loss: 2.551336207636495
Validation loss: 2.5473600678450756

Epoch: 6| Step: 1
Training loss: 2.845550972897071
Validation loss: 2.5477465053161685

Epoch: 6| Step: 2
Training loss: 2.906784828770696
Validation loss: 2.5511755334308734

Epoch: 6| Step: 3
Training loss: 2.538277278672784
Validation loss: 2.546334815905997

Epoch: 6| Step: 4
Training loss: 2.399399356385539
Validation loss: 2.5404812648978052

Epoch: 6| Step: 5
Training loss: 2.5278408499127853
Validation loss: 2.5404921981430455

Epoch: 6| Step: 6
Training loss: 2.7543558822324994
Validation loss: 2.536123881656638

Epoch: 6| Step: 7
Training loss: 2.837060795204868
Validation loss: 2.5352854174137582

Epoch: 6| Step: 8
Training loss: 2.1685782460737917
Validation loss: 2.5303189955584764

Epoch: 6| Step: 9
Training loss: 1.8620850504044049
Validation loss: 2.528477315790772

Epoch: 6| Step: 10
Training loss: 2.640514574619977
Validation loss: 2.5264663549030435

Epoch: 6| Step: 11
Training loss: 2.76292485901269
Validation loss: 2.524795607675947

Epoch: 6| Step: 12
Training loss: 3.130943140157517
Validation loss: 2.521287370151696

Epoch: 6| Step: 13
Training loss: 3.0231908258949503
Validation loss: 2.523744452263987

Epoch: 73| Step: 0
Training loss: 2.72215251011586
Validation loss: 2.517982199918305

Epoch: 6| Step: 1
Training loss: 2.3959603206870694
Validation loss: 2.518930068729963

Epoch: 6| Step: 2
Training loss: 2.376651189931134
Validation loss: 2.5212014667742553

Epoch: 6| Step: 3
Training loss: 2.365809376232411
Validation loss: 2.5170980764773017

Epoch: 6| Step: 4
Training loss: 3.472978643464279
Validation loss: 2.529763307116892

Epoch: 6| Step: 5
Training loss: 2.809307066167136
Validation loss: 2.5339419018780007

Epoch: 6| Step: 6
Training loss: 2.2800813581774766
Validation loss: 2.5528980330114113

Epoch: 6| Step: 7
Training loss: 2.9297307939509416
Validation loss: 2.578086174566594

Epoch: 6| Step: 8
Training loss: 2.273956344494115
Validation loss: 2.550383088376371

Epoch: 6| Step: 9
Training loss: 2.6724694020274486
Validation loss: 2.5330186951734617

Epoch: 6| Step: 10
Training loss: 2.0516913438186295
Validation loss: 2.5262111384117465

Epoch: 6| Step: 11
Training loss: 3.1831282011982602
Validation loss: 2.5255135813335117

Epoch: 6| Step: 12
Training loss: 2.5433467461001924
Validation loss: 2.520249942918415

Epoch: 6| Step: 13
Training loss: 2.7797942906023074
Validation loss: 2.5204078430821815

Epoch: 74| Step: 0
Training loss: 2.7221786977787445
Validation loss: 2.5189513966049946

Epoch: 6| Step: 1
Training loss: 2.77754822312321
Validation loss: 2.5223939074211534

Epoch: 6| Step: 2
Training loss: 2.363452545767778
Validation loss: 2.5245748580594762

Epoch: 6| Step: 3
Training loss: 2.4244530523077237
Validation loss: 2.527672511891066

Epoch: 6| Step: 4
Training loss: 2.771502784415162
Validation loss: 2.5293157039221335

Epoch: 6| Step: 5
Training loss: 2.8156529026151946
Validation loss: 2.5316323984408093

Epoch: 6| Step: 6
Training loss: 2.320596902288322
Validation loss: 2.5296916795915583

Epoch: 6| Step: 7
Training loss: 2.7964970850159463
Validation loss: 2.530032017923637

Epoch: 6| Step: 8
Training loss: 2.7726955227235024
Validation loss: 2.52814957803631

Epoch: 6| Step: 9
Training loss: 2.302084691204056
Validation loss: 2.524237412470585

Epoch: 6| Step: 10
Training loss: 2.913398892110935
Validation loss: 2.521618450213964

Epoch: 6| Step: 11
Training loss: 2.7178129137786065
Validation loss: 2.5207050280325123

Epoch: 6| Step: 12
Training loss: 2.7723617831588956
Validation loss: 2.5225956066502135

Epoch: 6| Step: 13
Training loss: 2.563964611279389
Validation loss: 2.5248848589840915

Epoch: 75| Step: 0
Training loss: 2.5144863039357888
Validation loss: 2.524119392280607

Epoch: 6| Step: 1
Training loss: 2.8158232658261197
Validation loss: 2.5237544503376634

Epoch: 6| Step: 2
Training loss: 2.6950411010325768
Validation loss: 2.5183018250159495

Epoch: 6| Step: 3
Training loss: 2.6744372480029996
Validation loss: 2.515219993449479

Epoch: 6| Step: 4
Training loss: 2.6617673232940016
Validation loss: 2.5102797084398176

Epoch: 6| Step: 5
Training loss: 2.626096859606274
Validation loss: 2.5105479721827466

Epoch: 6| Step: 6
Training loss: 2.923263464701329
Validation loss: 2.5075639738249365

Epoch: 6| Step: 7
Training loss: 2.448234981104771
Validation loss: 2.509373085208097

Epoch: 6| Step: 8
Training loss: 2.713841710309074
Validation loss: 2.511533327906654

Epoch: 6| Step: 9
Training loss: 1.9806694215010456
Validation loss: 2.5094868427212154

Epoch: 6| Step: 10
Training loss: 2.4414629876219665
Validation loss: 2.507286167072709

Epoch: 6| Step: 11
Training loss: 2.8407164102582896
Validation loss: 2.5072195395880224

Epoch: 6| Step: 12
Training loss: 3.0048106088477433
Validation loss: 2.507585620223377

Epoch: 6| Step: 13
Training loss: 2.4199846334994137
Validation loss: 2.50548484264979

Epoch: 76| Step: 0
Training loss: 2.4416513548838523
Validation loss: 2.5103526654665584

Epoch: 6| Step: 1
Training loss: 2.922439602243264
Validation loss: 2.503953430397808

Epoch: 6| Step: 2
Training loss: 2.396014850761485
Validation loss: 2.5072667685776646

Epoch: 6| Step: 3
Training loss: 2.93386128471744
Validation loss: 2.5108077402854176

Epoch: 6| Step: 4
Training loss: 2.646525274995303
Validation loss: 2.505961177479545

Epoch: 6| Step: 5
Training loss: 2.672850492098799
Validation loss: 2.5056095132518053

Epoch: 6| Step: 6
Training loss: 2.709696636886247
Validation loss: 2.503641964617325

Epoch: 6| Step: 7
Training loss: 2.8883209118481514
Validation loss: 2.5064249131452527

Epoch: 6| Step: 8
Training loss: 2.4669662018785212
Validation loss: 2.5053027816596023

Epoch: 6| Step: 9
Training loss: 1.844924035718219
Validation loss: 2.507315462636346

Epoch: 6| Step: 10
Training loss: 2.2905564364259066
Validation loss: 2.5058905504665523

Epoch: 6| Step: 11
Training loss: 2.6984327748074493
Validation loss: 2.507366818193376

Epoch: 6| Step: 12
Training loss: 2.8795696927840773
Validation loss: 2.5091810285279053

Epoch: 6| Step: 13
Training loss: 2.845767468816148
Validation loss: 2.504258677040004

Epoch: 77| Step: 0
Training loss: 2.840665716670511
Validation loss: 2.5068386559842546

Epoch: 6| Step: 1
Training loss: 2.62945451163308
Validation loss: 2.5060968284065575

Epoch: 6| Step: 2
Training loss: 2.796541076844093
Validation loss: 2.5022093705940223

Epoch: 6| Step: 3
Training loss: 2.425545058983733
Validation loss: 2.508933318947672

Epoch: 6| Step: 4
Training loss: 2.3024638165044538
Validation loss: 2.5079389641269083

Epoch: 6| Step: 5
Training loss: 2.4085548558591854
Validation loss: 2.5104155613011714

Epoch: 6| Step: 6
Training loss: 2.8554410293840844
Validation loss: 2.508973657952478

Epoch: 6| Step: 7
Training loss: 2.509968813972205
Validation loss: 2.507493994145603

Epoch: 6| Step: 8
Training loss: 2.9752341683173853
Validation loss: 2.507896762592938

Epoch: 6| Step: 9
Training loss: 2.3914956894567947
Validation loss: 2.5078708725074716

Epoch: 6| Step: 10
Training loss: 2.755647582223117
Validation loss: 2.5065866486817994

Epoch: 6| Step: 11
Training loss: 2.3642054744632874
Validation loss: 2.5076911714701877

Epoch: 6| Step: 12
Training loss: 3.074355242363836
Validation loss: 2.5084717419818086

Epoch: 6| Step: 13
Training loss: 2.376766150462509
Validation loss: 2.5053543450095495

Epoch: 78| Step: 0
Training loss: 2.5376862067692882
Validation loss: 2.5017147382437552

Epoch: 6| Step: 1
Training loss: 2.562436638025468
Validation loss: 2.5021222166861667

Epoch: 6| Step: 2
Training loss: 2.8692262142079943
Validation loss: 2.5057109611408603

Epoch: 6| Step: 3
Training loss: 2.6143336892472067
Validation loss: 2.499659467392836

Epoch: 6| Step: 4
Training loss: 2.5258125961628783
Validation loss: 2.504130138716865

Epoch: 6| Step: 5
Training loss: 2.5729215881877168
Validation loss: 2.502882805329517

Epoch: 6| Step: 6
Training loss: 2.1583694877198436
Validation loss: 2.5031219857047318

Epoch: 6| Step: 7
Training loss: 2.674125214617324
Validation loss: 2.500997630383979

Epoch: 6| Step: 8
Training loss: 2.636509504139418
Validation loss: 2.5003957594107784

Epoch: 6| Step: 9
Training loss: 2.5826253741279626
Validation loss: 2.5073410652681773

Epoch: 6| Step: 10
Training loss: 2.475289965511232
Validation loss: 2.501562480620734

Epoch: 6| Step: 11
Training loss: 3.0575922353062035
Validation loss: 2.4921331768433346

Epoch: 6| Step: 12
Training loss: 2.5301881611630965
Validation loss: 2.4926070415248507

Epoch: 6| Step: 13
Training loss: 2.8447688027888667
Validation loss: 2.500117362764402

Epoch: 79| Step: 0
Training loss: 2.578584294877675
Validation loss: 2.4991434537295647

Epoch: 6| Step: 1
Training loss: 2.7209738044248892
Validation loss: 2.4984289875724466

Epoch: 6| Step: 2
Training loss: 2.581668891815481
Validation loss: 2.501142590409069

Epoch: 6| Step: 3
Training loss: 3.0018956235343572
Validation loss: 2.502696617448556

Epoch: 6| Step: 4
Training loss: 2.6714000614413864
Validation loss: 2.503734652173339

Epoch: 6| Step: 5
Training loss: 2.78629881975643
Validation loss: 2.499059452514393

Epoch: 6| Step: 6
Training loss: 2.995449588764693
Validation loss: 2.5039898823197517

Epoch: 6| Step: 7
Training loss: 2.5004788893746928
Validation loss: 2.4991020656358827

Epoch: 6| Step: 8
Training loss: 2.5661412861461597
Validation loss: 2.497538809450904

Epoch: 6| Step: 9
Training loss: 2.2120675477929095
Validation loss: 2.499425663143239

Epoch: 6| Step: 10
Training loss: 2.7457948958890808
Validation loss: 2.4964610562334477

Epoch: 6| Step: 11
Training loss: 2.388284771947538
Validation loss: 2.496570794293931

Epoch: 6| Step: 12
Training loss: 2.303488416221578
Validation loss: 2.4946935444584644

Epoch: 6| Step: 13
Training loss: 2.49841458594602
Validation loss: 2.497392852643528

Epoch: 80| Step: 0
Training loss: 2.801656971842255
Validation loss: 2.4923944178097983

Epoch: 6| Step: 1
Training loss: 2.8648848681259755
Validation loss: 2.493669872223575

Epoch: 6| Step: 2
Training loss: 2.474620743795412
Validation loss: 2.493923415780664

Epoch: 6| Step: 3
Training loss: 2.338612839281963
Validation loss: 2.4922674758180565

Epoch: 6| Step: 4
Training loss: 2.8305894430584257
Validation loss: 2.4930123744850796

Epoch: 6| Step: 5
Training loss: 2.608778651271619
Validation loss: 2.494709281649491

Epoch: 6| Step: 6
Training loss: 2.8852056065750173
Validation loss: 2.4931107966242463

Epoch: 6| Step: 7
Training loss: 2.816871128523972
Validation loss: 2.494483878329729

Epoch: 6| Step: 8
Training loss: 2.391429092711877
Validation loss: 2.4947647433065905

Epoch: 6| Step: 9
Training loss: 2.687698711767071
Validation loss: 2.49378235428679

Epoch: 6| Step: 10
Training loss: 2.266609346375583
Validation loss: 2.500721008916293

Epoch: 6| Step: 11
Training loss: 2.670391183835625
Validation loss: 2.4955989882593337

Epoch: 6| Step: 12
Training loss: 2.2625389390829715
Validation loss: 2.5004354415601444

Epoch: 6| Step: 13
Training loss: 2.6626327123385662
Validation loss: 2.4994354246339063

Epoch: 81| Step: 0
Training loss: 2.531724108340874
Validation loss: 2.498727713137721

Epoch: 6| Step: 1
Training loss: 2.924074538453681
Validation loss: 2.499276231265903

Epoch: 6| Step: 2
Training loss: 2.837623620386277
Validation loss: 2.499196368434545

Epoch: 6| Step: 3
Training loss: 2.924715018450165
Validation loss: 2.4969651716403267

Epoch: 6| Step: 4
Training loss: 2.177955951451921
Validation loss: 2.496901738067808

Epoch: 6| Step: 5
Training loss: 2.1738208863171256
Validation loss: 2.493149032776582

Epoch: 6| Step: 6
Training loss: 2.8486919011162564
Validation loss: 2.492403122713266

Epoch: 6| Step: 7
Training loss: 2.7319986535064817
Validation loss: 2.494780241131087

Epoch: 6| Step: 8
Training loss: 2.755866209544812
Validation loss: 2.4954927822429793

Epoch: 6| Step: 9
Training loss: 2.167434104084952
Validation loss: 2.49422052226077

Epoch: 6| Step: 10
Training loss: 2.8002952249745707
Validation loss: 2.491103228417984

Epoch: 6| Step: 11
Training loss: 2.375080408441727
Validation loss: 2.4892841356176945

Epoch: 6| Step: 12
Training loss: 2.847882297162439
Validation loss: 2.4905642621313646

Epoch: 6| Step: 13
Training loss: 2.2859144208346653
Validation loss: 2.489354691055055

Epoch: 82| Step: 0
Training loss: 3.023309749299592
Validation loss: 2.4888595795277513

Epoch: 6| Step: 1
Training loss: 2.38393968280552
Validation loss: 2.490731239366378

Epoch: 6| Step: 2
Training loss: 2.533801452987511
Validation loss: 2.485818343680553

Epoch: 6| Step: 3
Training loss: 2.763309091002266
Validation loss: 2.495657948958647

Epoch: 6| Step: 4
Training loss: 2.528699178293408
Validation loss: 2.4984964140720676

Epoch: 6| Step: 5
Training loss: 2.741062900961298
Validation loss: 2.4943359425978127

Epoch: 6| Step: 6
Training loss: 2.8596853285856176
Validation loss: 2.498950809617435

Epoch: 6| Step: 7
Training loss: 2.462630594731162
Validation loss: 2.488629391128529

Epoch: 6| Step: 8
Training loss: 2.531779951968419
Validation loss: 2.4850224784816866

Epoch: 6| Step: 9
Training loss: 2.8159240225165765
Validation loss: 2.489985682217799

Epoch: 6| Step: 10
Training loss: 2.3326503117284085
Validation loss: 2.4950683748232088

Epoch: 6| Step: 11
Training loss: 1.9459136891841824
Validation loss: 2.4931400834337576

Epoch: 6| Step: 12
Training loss: 2.9017085205541986
Validation loss: 2.4971523517593064

Epoch: 6| Step: 13
Training loss: 2.607942656325411
Validation loss: 2.4953035905838603

Epoch: 83| Step: 0
Training loss: 2.5510820150137588
Validation loss: 2.5007267849207007

Epoch: 6| Step: 1
Training loss: 2.099929685777879
Validation loss: 2.505742273248175

Epoch: 6| Step: 2
Training loss: 3.144615257515274
Validation loss: 2.5039639200997312

Epoch: 6| Step: 3
Training loss: 2.5975724515090284
Validation loss: 2.503964491398423

Epoch: 6| Step: 4
Training loss: 2.6673567196978336
Validation loss: 2.5065438615953886

Epoch: 6| Step: 5
Training loss: 2.8003550781173443
Validation loss: 2.5093061805874886

Epoch: 6| Step: 6
Training loss: 2.77230674365928
Validation loss: 2.5094795905169565

Epoch: 6| Step: 7
Training loss: 2.3150396062705005
Validation loss: 2.5103891510992207

Epoch: 6| Step: 8
Training loss: 2.8497484263430737
Validation loss: 2.508995117975388

Epoch: 6| Step: 9
Training loss: 2.7913116020515005
Validation loss: 2.5060967649829418

Epoch: 6| Step: 10
Training loss: 2.207418168172321
Validation loss: 2.502060343191807

Epoch: 6| Step: 11
Training loss: 2.949749505997471
Validation loss: 2.495383450608764

Epoch: 6| Step: 12
Training loss: 2.8478692371481054
Validation loss: 2.4897530523146694

Epoch: 6| Step: 13
Training loss: 1.7811844127693461
Validation loss: 2.4883150251123407

Epoch: 84| Step: 0
Training loss: 2.646139943136668
Validation loss: 2.4946099509131736

Epoch: 6| Step: 1
Training loss: 2.7241536952336456
Validation loss: 2.488314130836315

Epoch: 6| Step: 2
Training loss: 2.3595080811818283
Validation loss: 2.4852396741861753

Epoch: 6| Step: 3
Training loss: 2.779185525428883
Validation loss: 2.4886368318301035

Epoch: 6| Step: 4
Training loss: 3.2184012511119833
Validation loss: 2.485384625987505

Epoch: 6| Step: 5
Training loss: 2.4643910229534742
Validation loss: 2.4888839590595255

Epoch: 6| Step: 6
Training loss: 2.1616402300549216
Validation loss: 2.484022919280362

Epoch: 6| Step: 7
Training loss: 3.028446434762804
Validation loss: 2.487289366757921

Epoch: 6| Step: 8
Training loss: 2.4811673359589315
Validation loss: 2.4823404934576963

Epoch: 6| Step: 9
Training loss: 2.4139158333973283
Validation loss: 2.486298110672873

Epoch: 6| Step: 10
Training loss: 2.70345379367778
Validation loss: 2.4874368189930083

Epoch: 6| Step: 11
Training loss: 2.528872091199929
Validation loss: 2.4870446055059827

Epoch: 6| Step: 12
Training loss: 2.2647671884292313
Validation loss: 2.486031817539757

Epoch: 6| Step: 13
Training loss: 2.468267852443541
Validation loss: 2.4911561304690837

Epoch: 85| Step: 0
Training loss: 2.797738224416874
Validation loss: 2.487019073538964

Epoch: 6| Step: 1
Training loss: 2.377137677716282
Validation loss: 2.484844059519059

Epoch: 6| Step: 2
Training loss: 3.0198086984940766
Validation loss: 2.487620419154623

Epoch: 6| Step: 3
Training loss: 3.0956960395226485
Validation loss: 2.4846972370496663

Epoch: 6| Step: 4
Training loss: 2.8420353006187975
Validation loss: 2.4803169103891385

Epoch: 6| Step: 5
Training loss: 2.522680115786235
Validation loss: 2.484455339264378

Epoch: 6| Step: 6
Training loss: 2.268714009149249
Validation loss: 2.4864166475745564

Epoch: 6| Step: 7
Training loss: 2.794741109551166
Validation loss: 2.486561147233928

Epoch: 6| Step: 8
Training loss: 2.4273278654847674
Validation loss: 2.4873992857999676

Epoch: 6| Step: 9
Training loss: 2.139861033196792
Validation loss: 2.488353510615344

Epoch: 6| Step: 10
Training loss: 2.598305803128228
Validation loss: 2.4867287448143287

Epoch: 6| Step: 11
Training loss: 2.604567524893478
Validation loss: 2.490404469783181

Epoch: 6| Step: 12
Training loss: 2.1741564726331624
Validation loss: 2.487438871760375

Epoch: 6| Step: 13
Training loss: 2.5289124421287528
Validation loss: 2.486363460891994

Epoch: 86| Step: 0
Training loss: 2.6481368082668713
Validation loss: 2.4835631125561273

Epoch: 6| Step: 1
Training loss: 2.422164998073638
Validation loss: 2.4795277970952028

Epoch: 6| Step: 2
Training loss: 2.714680574851141
Validation loss: 2.474261605931801

Epoch: 6| Step: 3
Training loss: 2.6426964935610897
Validation loss: 2.478985713050198

Epoch: 6| Step: 4
Training loss: 2.638049432738195
Validation loss: 2.479936741924549

Epoch: 6| Step: 5
Training loss: 2.3993497722677692
Validation loss: 2.4772010244821048

Epoch: 6| Step: 6
Training loss: 1.9344468209733314
Validation loss: 2.4790974989359635

Epoch: 6| Step: 7
Training loss: 2.586312350392254
Validation loss: 2.4840053707234695

Epoch: 6| Step: 8
Training loss: 2.8414399542289765
Validation loss: 2.4759908632151975

Epoch: 6| Step: 9
Training loss: 2.844346204028114
Validation loss: 2.4851666994423804

Epoch: 6| Step: 10
Training loss: 2.4952540171630737
Validation loss: 2.480506171797769

Epoch: 6| Step: 11
Training loss: 3.181885805278378
Validation loss: 2.489001446853407

Epoch: 6| Step: 12
Training loss: 2.7145521707178197
Validation loss: 2.4892953416148598

Epoch: 6| Step: 13
Training loss: 2.294929043373113
Validation loss: 2.490906875658833

Epoch: 87| Step: 0
Training loss: 2.775286163146697
Validation loss: 2.481379496464588

Epoch: 6| Step: 1
Training loss: 2.301265128115483
Validation loss: 2.481299313840701

Epoch: 6| Step: 2
Training loss: 1.963016092266519
Validation loss: 2.4781263770748643

Epoch: 6| Step: 3
Training loss: 2.900286226288187
Validation loss: 2.4856250904707666

Epoch: 6| Step: 4
Training loss: 2.895482945456035
Validation loss: 2.4854228530981595

Epoch: 6| Step: 5
Training loss: 2.8394293187542408
Validation loss: 2.483845092432638

Epoch: 6| Step: 6
Training loss: 2.624877563527629
Validation loss: 2.481338532707647

Epoch: 6| Step: 7
Training loss: 2.366515715804185
Validation loss: 2.4834106301005745

Epoch: 6| Step: 8
Training loss: 2.493558404967073
Validation loss: 2.485161534847111

Epoch: 6| Step: 9
Training loss: 2.539943507009325
Validation loss: 2.4841318711287355

Epoch: 6| Step: 10
Training loss: 2.689268284514844
Validation loss: 2.4814241106392876

Epoch: 6| Step: 11
Training loss: 2.5078588938952393
Validation loss: 2.48339419727711

Epoch: 6| Step: 12
Training loss: 2.810866496115455
Validation loss: 2.484241953872048

Epoch: 6| Step: 13
Training loss: 2.4987341537087624
Validation loss: 2.486665273833034

Epoch: 88| Step: 0
Training loss: 2.962856506271914
Validation loss: 2.481413029232148

Epoch: 6| Step: 1
Training loss: 2.383491094298517
Validation loss: 2.4824224832705624

Epoch: 6| Step: 2
Training loss: 2.281859329575222
Validation loss: 2.4807013294986873

Epoch: 6| Step: 3
Training loss: 2.2065503702126086
Validation loss: 2.475179420415558

Epoch: 6| Step: 4
Training loss: 2.594125100094949
Validation loss: 2.4774121773375315

Epoch: 6| Step: 5
Training loss: 3.2112907716531964
Validation loss: 2.470798704688418

Epoch: 6| Step: 6
Training loss: 2.4920564336004736
Validation loss: 2.4722478206847494

Epoch: 6| Step: 7
Training loss: 2.84936003610573
Validation loss: 2.473803325950222

Epoch: 6| Step: 8
Training loss: 2.6827855121585933
Validation loss: 2.476704173242619

Epoch: 6| Step: 9
Training loss: 2.865891166148585
Validation loss: 2.4756444278305603

Epoch: 6| Step: 10
Training loss: 2.5884159807256877
Validation loss: 2.471702226917595

Epoch: 6| Step: 11
Training loss: 2.5181875504871973
Validation loss: 2.477627514182595

Epoch: 6| Step: 12
Training loss: 1.989429674323058
Validation loss: 2.4784011032785433

Epoch: 6| Step: 13
Training loss: 2.4176439304367054
Validation loss: 2.4772910281012543

Epoch: 89| Step: 0
Training loss: 3.3938556521217818
Validation loss: 2.4783116049499205

Epoch: 6| Step: 1
Training loss: 2.031051039121579
Validation loss: 2.475903428364178

Epoch: 6| Step: 2
Training loss: 3.028153873459481
Validation loss: 2.478146853516964

Epoch: 6| Step: 3
Training loss: 1.8895019474468708
Validation loss: 2.4835828401898516

Epoch: 6| Step: 4
Training loss: 2.8969243873575463
Validation loss: 2.483754318405055

Epoch: 6| Step: 5
Training loss: 2.5227261417520723
Validation loss: 2.4843752239235193

Epoch: 6| Step: 6
Training loss: 2.7437239035232115
Validation loss: 2.480665168094191

Epoch: 6| Step: 7
Training loss: 2.5065043712724715
Validation loss: 2.4821317129482843

Epoch: 6| Step: 8
Training loss: 2.3247942556592487
Validation loss: 2.479941380625806

Epoch: 6| Step: 9
Training loss: 2.71684268388995
Validation loss: 2.4778857221050843

Epoch: 6| Step: 10
Training loss: 3.0007650671385755
Validation loss: 2.4801123495700077

Epoch: 6| Step: 11
Training loss: 2.5639044471765535
Validation loss: 2.4785511844970958

Epoch: 6| Step: 12
Training loss: 1.91603005935567
Validation loss: 2.4733456518872394

Epoch: 6| Step: 13
Training loss: 2.3341205381633627
Validation loss: 2.46829576780113

Epoch: 90| Step: 0
Training loss: 2.591582714164352
Validation loss: 2.471388601874505

Epoch: 6| Step: 1
Training loss: 2.749342406284126
Validation loss: 2.4760822909602282

Epoch: 6| Step: 2
Training loss: 2.3638670140215687
Validation loss: 2.483350018524168

Epoch: 6| Step: 3
Training loss: 2.9099401201727026
Validation loss: 2.478482550041371

Epoch: 6| Step: 4
Training loss: 2.85362892004298
Validation loss: 2.4789011730290778

Epoch: 6| Step: 5
Training loss: 3.196427652004198
Validation loss: 2.4739584564744352

Epoch: 6| Step: 6
Training loss: 2.6435518014622224
Validation loss: 2.4705828208935245

Epoch: 6| Step: 7
Training loss: 2.9947466949182253
Validation loss: 2.469283307895612

Epoch: 6| Step: 8
Training loss: 2.263199026966661
Validation loss: 2.4711317009815126

Epoch: 6| Step: 9
Training loss: 2.5565421462126
Validation loss: 2.476081745324581

Epoch: 6| Step: 10
Training loss: 1.9933732636491344
Validation loss: 2.4745173629117674

Epoch: 6| Step: 11
Training loss: 2.5451826780217472
Validation loss: 2.472852493220476

Epoch: 6| Step: 12
Training loss: 2.2168037582492257
Validation loss: 2.4753571153134093

Epoch: 6| Step: 13
Training loss: 2.27326235801151
Validation loss: 2.471490521918476

Epoch: 91| Step: 0
Training loss: 2.631798976433412
Validation loss: 2.4728071619698753

Epoch: 6| Step: 1
Training loss: 2.2922837438056134
Validation loss: 2.4716886261238673

Epoch: 6| Step: 2
Training loss: 2.3822623196156316
Validation loss: 2.473527526823622

Epoch: 6| Step: 3
Training loss: 2.761628274905905
Validation loss: 2.474242510619772

Epoch: 6| Step: 4
Training loss: 2.349601663147153
Validation loss: 2.4691067691335222

Epoch: 6| Step: 5
Training loss: 2.940813508918626
Validation loss: 2.475562438251387

Epoch: 6| Step: 6
Training loss: 2.822846434072609
Validation loss: 2.4772834330193025

Epoch: 6| Step: 7
Training loss: 2.7950875308502856
Validation loss: 2.4698255023116094

Epoch: 6| Step: 8
Training loss: 1.9098509874185674
Validation loss: 2.473256508845669

Epoch: 6| Step: 9
Training loss: 3.0293985592016717
Validation loss: 2.4680304947540024

Epoch: 6| Step: 10
Training loss: 2.356650389795419
Validation loss: 2.4668741141112225

Epoch: 6| Step: 11
Training loss: 2.3586298290019077
Validation loss: 2.4657519360620785

Epoch: 6| Step: 12
Training loss: 2.401509855111571
Validation loss: 2.4612363280663616

Epoch: 6| Step: 13
Training loss: 2.8613271251064805
Validation loss: 2.4691847567282386

Epoch: 92| Step: 0
Training loss: 3.1904074180907056
Validation loss: 2.4604078419198987

Epoch: 6| Step: 1
Training loss: 2.428506840319834
Validation loss: 2.4609162183376267

Epoch: 6| Step: 2
Training loss: 2.3552559777060367
Validation loss: 2.4693186785017276

Epoch: 6| Step: 3
Training loss: 2.406621929010017
Validation loss: 2.467402625695742

Epoch: 6| Step: 4
Training loss: 2.943691465277743
Validation loss: 2.4616634529349346

Epoch: 6| Step: 5
Training loss: 3.0143113511634674
Validation loss: 2.466374650844813

Epoch: 6| Step: 6
Training loss: 1.6487357064206698
Validation loss: 2.471680780714726

Epoch: 6| Step: 7
Training loss: 2.537824593064133
Validation loss: 2.4717445721720215

Epoch: 6| Step: 8
Training loss: 2.5588230641811482
Validation loss: 2.476764225490845

Epoch: 6| Step: 9
Training loss: 2.3479503377572146
Validation loss: 2.474750742578875

Epoch: 6| Step: 10
Training loss: 3.0175518935955337
Validation loss: 2.480704981651096

Epoch: 6| Step: 11
Training loss: 2.809261237398753
Validation loss: 2.477443518304331

Epoch: 6| Step: 12
Training loss: 2.6695275953902495
Validation loss: 2.477694985537039

Epoch: 6| Step: 13
Training loss: 1.8878411218462263
Validation loss: 2.470736352347799

Epoch: 93| Step: 0
Training loss: 2.587871646451636
Validation loss: 2.4761337246041846

Epoch: 6| Step: 1
Training loss: 2.543513039089261
Validation loss: 2.4753123275768973

Epoch: 6| Step: 2
Training loss: 2.520551324207922
Validation loss: 2.473226568851591

Epoch: 6| Step: 3
Training loss: 2.4311310138368127
Validation loss: 2.4687769763615464

Epoch: 6| Step: 4
Training loss: 2.616036233056101
Validation loss: 2.4705871635233447

Epoch: 6| Step: 5
Training loss: 2.8021960229915273
Validation loss: 2.4730095794200144

Epoch: 6| Step: 6
Training loss: 2.855182513333997
Validation loss: 2.4736106681811436

Epoch: 6| Step: 7
Training loss: 2.5983213103943785
Validation loss: 2.472566688365948

Epoch: 6| Step: 8
Training loss: 2.5973788694127724
Validation loss: 2.475126120696578

Epoch: 6| Step: 9
Training loss: 2.0295710740971877
Validation loss: 2.4759587174642386

Epoch: 6| Step: 10
Training loss: 2.9745029322715077
Validation loss: 2.4641162828547873

Epoch: 6| Step: 11
Training loss: 2.1371316737449924
Validation loss: 2.4675129072475936

Epoch: 6| Step: 12
Training loss: 2.477053139398025
Validation loss: 2.4689274494764315

Epoch: 6| Step: 13
Training loss: 2.8007099137206244
Validation loss: 2.4623550933958103

Epoch: 94| Step: 0
Training loss: 2.5551927166127335
Validation loss: 2.465809998947078

Epoch: 6| Step: 1
Training loss: 2.6599925882910243
Validation loss: 2.4664029098518734

Epoch: 6| Step: 2
Training loss: 2.8883321380466014
Validation loss: 2.471002557072641

Epoch: 6| Step: 3
Training loss: 2.8280473561456314
Validation loss: 2.466465726176985

Epoch: 6| Step: 4
Training loss: 2.7735402262830626
Validation loss: 2.4692537139919235

Epoch: 6| Step: 5
Training loss: 2.8343698251292166
Validation loss: 2.465582799771959

Epoch: 6| Step: 6
Training loss: 2.581058936633373
Validation loss: 2.4624793011461854

Epoch: 6| Step: 7
Training loss: 2.8144863319952864
Validation loss: 2.4765883483500497

Epoch: 6| Step: 8
Training loss: 2.537626359170578
Validation loss: 2.467040810261774

Epoch: 6| Step: 9
Training loss: 1.981980929639976
Validation loss: 2.4660161651283627

Epoch: 6| Step: 10
Training loss: 2.149132522522805
Validation loss: 2.4700920867227727

Epoch: 6| Step: 11
Training loss: 2.531446849562646
Validation loss: 2.471213017497134

Epoch: 6| Step: 12
Training loss: 2.4222720897374828
Validation loss: 2.464658864256678

Epoch: 6| Step: 13
Training loss: 2.478735322586596
Validation loss: 2.4708919648991876

Epoch: 95| Step: 0
Training loss: 2.6759241664616207
Validation loss: 2.474777814094863

Epoch: 6| Step: 1
Training loss: 2.936804344105034
Validation loss: 2.4660938315194243

Epoch: 6| Step: 2
Training loss: 2.3198321837535594
Validation loss: 2.4698607927546337

Epoch: 6| Step: 3
Training loss: 2.6972785303026714
Validation loss: 2.472465286795483

Epoch: 6| Step: 4
Training loss: 2.5323301294863967
Validation loss: 2.472496264576702

Epoch: 6| Step: 5
Training loss: 2.6861281331191518
Validation loss: 2.471004615452098

Epoch: 6| Step: 6
Training loss: 2.84881610038769
Validation loss: 2.4724283459871286

Epoch: 6| Step: 7
Training loss: 2.829148249690282
Validation loss: 2.472144983516163

Epoch: 6| Step: 8
Training loss: 2.133547478100404
Validation loss: 2.4728279395657724

Epoch: 6| Step: 9
Training loss: 2.6415090491829254
Validation loss: 2.4736744982207304

Epoch: 6| Step: 10
Training loss: 2.2562833577487784
Validation loss: 2.4657743362823923

Epoch: 6| Step: 11
Training loss: 2.3586322550048715
Validation loss: 2.4639424622364485

Epoch: 6| Step: 12
Training loss: 2.4241377565879048
Validation loss: 2.4652557431760074

Epoch: 6| Step: 13
Training loss: 2.615854590034785
Validation loss: 2.4726544340507663

Epoch: 96| Step: 0
Training loss: 2.7178697586124825
Validation loss: 2.470315284092054

Epoch: 6| Step: 1
Training loss: 2.4335057715713346
Validation loss: 2.471170695294147

Epoch: 6| Step: 2
Training loss: 2.1774135746759513
Validation loss: 2.470313900732632

Epoch: 6| Step: 3
Training loss: 2.4844051335264696
Validation loss: 2.47249200565703

Epoch: 6| Step: 4
Training loss: 3.1164582051890157
Validation loss: 2.476056228699724

Epoch: 6| Step: 5
Training loss: 3.278262567679179
Validation loss: 2.4794371374568995

Epoch: 6| Step: 6
Training loss: 2.329062253992192
Validation loss: 2.471316102474718

Epoch: 6| Step: 7
Training loss: 2.603769826534272
Validation loss: 2.4704295855093377

Epoch: 6| Step: 8
Training loss: 2.3953751388491638
Validation loss: 2.469619018578337

Epoch: 6| Step: 9
Training loss: 2.3289134079529803
Validation loss: 2.4724627715915415

Epoch: 6| Step: 10
Training loss: 2.440625656459979
Validation loss: 2.474585641668369

Epoch: 6| Step: 11
Training loss: 2.361726511123226
Validation loss: 2.473876555580281

Epoch: 6| Step: 12
Training loss: 3.006330962488672
Validation loss: 2.472563217044057

Epoch: 6| Step: 13
Training loss: 2.267696932786056
Validation loss: 2.468686984259907

Epoch: 97| Step: 0
Training loss: 2.7312361657951088
Validation loss: 2.4730322673958494

Epoch: 6| Step: 1
Training loss: 2.6015912761757805
Validation loss: 2.471007542207437

Epoch: 6| Step: 2
Training loss: 2.6155091327266407
Validation loss: 2.472536603414314

Epoch: 6| Step: 3
Training loss: 2.1674328940804135
Validation loss: 2.4770892091579277

Epoch: 6| Step: 4
Training loss: 2.8465311054169855
Validation loss: 2.4736999109050455

Epoch: 6| Step: 5
Training loss: 2.2853042945834483
Validation loss: 2.4727905542299795

Epoch: 6| Step: 6
Training loss: 2.528756125834461
Validation loss: 2.473389302449034

Epoch: 6| Step: 7
Training loss: 2.274949871810473
Validation loss: 2.472768418438082

Epoch: 6| Step: 8
Training loss: 2.7527787301474302
Validation loss: 2.4701029776137835

Epoch: 6| Step: 9
Training loss: 2.786933834586723
Validation loss: 2.470696241447097

Epoch: 6| Step: 10
Training loss: 2.6216085414501706
Validation loss: 2.4722209625621927

Epoch: 6| Step: 11
Training loss: 2.3132581756688086
Validation loss: 2.46603741083543

Epoch: 6| Step: 12
Training loss: 2.9472285749307234
Validation loss: 2.460320111694216

Epoch: 6| Step: 13
Training loss: 2.5835313003324276
Validation loss: 2.463477576768304

Epoch: 98| Step: 0
Training loss: 2.2861807849516045
Validation loss: 2.4650469019659664

Epoch: 6| Step: 1
Training loss: 2.8081813291923496
Validation loss: 2.464501890727003

Epoch: 6| Step: 2
Training loss: 2.3126556756484278
Validation loss: 2.461222951975161

Epoch: 6| Step: 3
Training loss: 2.6533578723303095
Validation loss: 2.4634015377480805

Epoch: 6| Step: 4
Training loss: 3.131734990918728
Validation loss: 2.459449584683081

Epoch: 6| Step: 5
Training loss: 2.1934737246182867
Validation loss: 2.4627610328052083

Epoch: 6| Step: 6
Training loss: 2.9226862959144575
Validation loss: 2.4643837025380946

Epoch: 6| Step: 7
Training loss: 2.6461791365716625
Validation loss: 2.4600667068823965

Epoch: 6| Step: 8
Training loss: 2.546240698339058
Validation loss: 2.4628008857126953

Epoch: 6| Step: 9
Training loss: 2.1053727221839855
Validation loss: 2.4671685831521675

Epoch: 6| Step: 10
Training loss: 2.0986425826465225
Validation loss: 2.469998619346902

Epoch: 6| Step: 11
Training loss: 2.531156184965762
Validation loss: 2.468781603840247

Epoch: 6| Step: 12
Training loss: 2.8247670845631236
Validation loss: 2.46820623308421

Epoch: 6| Step: 13
Training loss: 2.780901940672791
Validation loss: 2.4687658542816093

Epoch: 99| Step: 0
Training loss: 2.105120062043126
Validation loss: 2.466382658133394

Epoch: 6| Step: 1
Training loss: 2.4358172354577885
Validation loss: 2.459510623693609

Epoch: 6| Step: 2
Training loss: 2.8556384076650936
Validation loss: 2.4711351582340897

Epoch: 6| Step: 3
Training loss: 2.7337337068857996
Validation loss: 2.4679137716985347

Epoch: 6| Step: 4
Training loss: 2.653016759239317
Validation loss: 2.4676679984441274

Epoch: 6| Step: 5
Training loss: 2.1247904057079317
Validation loss: 2.471873838068339

Epoch: 6| Step: 6
Training loss: 2.399206976207984
Validation loss: 2.470470424544811

Epoch: 6| Step: 7
Training loss: 2.449350745919842
Validation loss: 2.470220393491122

Epoch: 6| Step: 8
Training loss: 2.472381817622799
Validation loss: 2.4703020295466733

Epoch: 6| Step: 9
Training loss: 2.3959534545860794
Validation loss: 2.469812172737946

Epoch: 6| Step: 10
Training loss: 2.6021214706602938
Validation loss: 2.474984630061761

Epoch: 6| Step: 11
Training loss: 2.8883818299598287
Validation loss: 2.468940148092801

Epoch: 6| Step: 12
Training loss: 2.7637036217257873
Validation loss: 2.471431901122585

Epoch: 6| Step: 13
Training loss: 2.9232942938581155
Validation loss: 2.46816880994258

Epoch: 100| Step: 0
Training loss: 2.7825105360847875
Validation loss: 2.4667291860991356

Epoch: 6| Step: 1
Training loss: 1.864235751469619
Validation loss: 2.462148943435891

Epoch: 6| Step: 2
Training loss: 2.5282854215557946
Validation loss: 2.46787371958145

Epoch: 6| Step: 3
Training loss: 2.9984552856999214
Validation loss: 2.464717033502389

Epoch: 6| Step: 4
Training loss: 2.733900977327637
Validation loss: 2.463775483878128

Epoch: 6| Step: 5
Training loss: 2.696162258483763
Validation loss: 2.4606413244213496

Epoch: 6| Step: 6
Training loss: 2.831562292799749
Validation loss: 2.4598326609846852

Epoch: 6| Step: 7
Training loss: 2.9695526644148607
Validation loss: 2.4652814360637714

Epoch: 6| Step: 8
Training loss: 2.161986088188363
Validation loss: 2.4645480035446083

Epoch: 6| Step: 9
Training loss: 2.0745571169397365
Validation loss: 2.468236394966737

Epoch: 6| Step: 10
Training loss: 3.0542816126601022
Validation loss: 2.4670923035487613

Epoch: 6| Step: 11
Training loss: 2.261050743319837
Validation loss: 2.462262574963854

Epoch: 6| Step: 12
Training loss: 2.580537718989672
Validation loss: 2.462548655950659

Epoch: 6| Step: 13
Training loss: 2.109814746371721
Validation loss: 2.455718303722467

Epoch: 101| Step: 0
Training loss: 2.7799353760816867
Validation loss: 2.459855050491907

Epoch: 6| Step: 1
Training loss: 2.5889900376948543
Validation loss: 2.4624170124767577

Epoch: 6| Step: 2
Training loss: 2.420022760709807
Validation loss: 2.4623877233479305

Epoch: 6| Step: 3
Training loss: 2.7069003691417
Validation loss: 2.455092222445893

Epoch: 6| Step: 4
Training loss: 2.952398624601665
Validation loss: 2.456747745235329

Epoch: 6| Step: 5
Training loss: 2.6832821594318483
Validation loss: 2.452579672553322

Epoch: 6| Step: 6
Training loss: 2.6823510814616998
Validation loss: 2.457996221370291

Epoch: 6| Step: 7
Training loss: 2.829564018230399
Validation loss: 2.46057702709327

Epoch: 6| Step: 8
Training loss: 2.3875564129141353
Validation loss: 2.4604792092492773

Epoch: 6| Step: 9
Training loss: 2.164287679366497
Validation loss: 2.4631290587596917

Epoch: 6| Step: 10
Training loss: 1.9574179505244347
Validation loss: 2.466341831967877

Epoch: 6| Step: 11
Training loss: 2.2781584183867367
Validation loss: 2.4658141888331553

Epoch: 6| Step: 12
Training loss: 2.5926380761511414
Validation loss: 2.468157540225417

Epoch: 6| Step: 13
Training loss: 2.7070688572592894
Validation loss: 2.4630516699408522

Epoch: 102| Step: 0
Training loss: 2.5246296714924212
Validation loss: 2.4643591612512377

Epoch: 6| Step: 1
Training loss: 2.941820579010861
Validation loss: 2.454948573612994

Epoch: 6| Step: 2
Training loss: 2.9595099961166302
Validation loss: 2.4624474631190036

Epoch: 6| Step: 3
Training loss: 2.372304692002437
Validation loss: 2.4582843829523977

Epoch: 6| Step: 4
Training loss: 2.716773180443493
Validation loss: 2.463487738784556

Epoch: 6| Step: 5
Training loss: 2.314765336108345
Validation loss: 2.4555336209243372

Epoch: 6| Step: 6
Training loss: 2.299654777160305
Validation loss: 2.4559061277241345

Epoch: 6| Step: 7
Training loss: 2.5258597921329997
Validation loss: 2.4605171934603436

Epoch: 6| Step: 8
Training loss: 2.910849919949451
Validation loss: 2.4616034197145398

Epoch: 6| Step: 9
Training loss: 2.434148391538365
Validation loss: 2.455294643779151

Epoch: 6| Step: 10
Training loss: 2.6448390223763463
Validation loss: 2.458630759355913

Epoch: 6| Step: 11
Training loss: 2.307456728941785
Validation loss: 2.457289107578611

Epoch: 6| Step: 12
Training loss: 1.9884349111599806
Validation loss: 2.4601883489720056

Epoch: 6| Step: 13
Training loss: 2.7565359992256324
Validation loss: 2.4651967323365747

Epoch: 103| Step: 0
Training loss: 2.5935159600617874
Validation loss: 2.4584897093956743

Epoch: 6| Step: 1
Training loss: 1.540622366076959
Validation loss: 2.471229370525044

Epoch: 6| Step: 2
Training loss: 2.224117609852513
Validation loss: 2.469449970147161

Epoch: 6| Step: 3
Training loss: 2.6120891047142316
Validation loss: 2.4608112605580117

Epoch: 6| Step: 4
Training loss: 2.834741093084047
Validation loss: 2.467540654005671

Epoch: 6| Step: 5
Training loss: 2.436760325564832
Validation loss: 2.4652726998672363

Epoch: 6| Step: 6
Training loss: 2.2015899288290903
Validation loss: 2.462779474939324

Epoch: 6| Step: 7
Training loss: 2.5482352901016583
Validation loss: 2.460133916859083

Epoch: 6| Step: 8
Training loss: 2.8517909128339793
Validation loss: 2.451120031044113

Epoch: 6| Step: 9
Training loss: 2.470672631358265
Validation loss: 2.462166518659266

Epoch: 6| Step: 10
Training loss: 3.12170556938451
Validation loss: 2.4568528766100193

Epoch: 6| Step: 11
Training loss: 3.0970322893311377
Validation loss: 2.4645972433420518

Epoch: 6| Step: 12
Training loss: 2.6526747034984455
Validation loss: 2.4615283640228767

Epoch: 6| Step: 13
Training loss: 2.425956682873574
Validation loss: 2.4669285585800447

Epoch: 104| Step: 0
Training loss: 2.94476361814045
Validation loss: 2.462951191523739

Epoch: 6| Step: 1
Training loss: 2.385550504924985
Validation loss: 2.4642845200535084

Epoch: 6| Step: 2
Training loss: 2.4203090404192715
Validation loss: 2.466215192443153

Epoch: 6| Step: 3
Training loss: 2.332831215192531
Validation loss: 2.4654920463993304

Epoch: 6| Step: 4
Training loss: 2.600271185157164
Validation loss: 2.4677089314898155

Epoch: 6| Step: 5
Training loss: 2.3818263280095207
Validation loss: 2.4639110059819465

Epoch: 6| Step: 6
Training loss: 2.786749471030421
Validation loss: 2.464408138773739

Epoch: 6| Step: 7
Training loss: 2.0052307391875908
Validation loss: 2.4655265124449235

Epoch: 6| Step: 8
Training loss: 2.364160900501117
Validation loss: 2.4645059216021163

Epoch: 6| Step: 9
Training loss: 2.8981160193808653
Validation loss: 2.4532073993167183

Epoch: 6| Step: 10
Training loss: 2.8622210570774644
Validation loss: 2.4583402299514843

Epoch: 6| Step: 11
Training loss: 2.582322558707702
Validation loss: 2.460811744988816

Epoch: 6| Step: 12
Training loss: 2.5473155009326
Validation loss: 2.457996730605171

Epoch: 6| Step: 13
Training loss: 2.5366388109192384
Validation loss: 2.4557564424771163

Epoch: 105| Step: 0
Training loss: 2.334453609016235
Validation loss: 2.4512145506042873

Epoch: 6| Step: 1
Training loss: 2.474558600166001
Validation loss: 2.458730792119412

Epoch: 6| Step: 2
Training loss: 2.04004408788724
Validation loss: 2.449546933938371

Epoch: 6| Step: 3
Training loss: 3.0230595946398644
Validation loss: 2.45751783347038

Epoch: 6| Step: 4
Training loss: 2.8127710847546648
Validation loss: 2.458162501159252

Epoch: 6| Step: 5
Training loss: 2.304741499963246
Validation loss: 2.473756245172632

Epoch: 6| Step: 6
Training loss: 2.61837195169034
Validation loss: 2.469673225547898

Epoch: 6| Step: 7
Training loss: 2.29528566764173
Validation loss: 2.4723862776334897

Epoch: 6| Step: 8
Training loss: 3.084745925506144
Validation loss: 2.4731787219481784

Epoch: 6| Step: 9
Training loss: 2.337083822318212
Validation loss: 2.46401038089543

Epoch: 6| Step: 10
Training loss: 2.093677348684144
Validation loss: 2.4560805413545634

Epoch: 6| Step: 11
Training loss: 2.7246688781584947
Validation loss: 2.4721400971172285

Epoch: 6| Step: 12
Training loss: 2.8282217778460406
Validation loss: 2.4804027398404815

Epoch: 6| Step: 13
Training loss: 2.5913933768310606
Validation loss: 2.471197130676124

Epoch: 106| Step: 0
Training loss: 2.387880832197121
Validation loss: 2.483342818000995

Epoch: 6| Step: 1
Training loss: 3.024286826059065
Validation loss: 2.4780076520666694

Epoch: 6| Step: 2
Training loss: 2.6482235982481463
Validation loss: 2.48164638488796

Epoch: 6| Step: 3
Training loss: 2.512836688053005
Validation loss: 2.4813960787470175

Epoch: 6| Step: 4
Training loss: 2.5751352256155986
Validation loss: 2.483449495615473

Epoch: 6| Step: 5
Training loss: 3.226052306250786
Validation loss: 2.4828414022253065

Epoch: 6| Step: 6
Training loss: 2.4674628076967937
Validation loss: 2.483750126785406

Epoch: 6| Step: 7
Training loss: 2.6206776591422765
Validation loss: 2.4775709471695184

Epoch: 6| Step: 8
Training loss: 2.30525143722822
Validation loss: 2.4818993395384634

Epoch: 6| Step: 9
Training loss: 2.8805077910461105
Validation loss: 2.473741732033047

Epoch: 6| Step: 10
Training loss: 2.815411565314118
Validation loss: 2.477805923566728

Epoch: 6| Step: 11
Training loss: 1.8822129430671006
Validation loss: 2.4738891806056067

Epoch: 6| Step: 12
Training loss: 2.616097020954474
Validation loss: 2.466968948189968

Epoch: 6| Step: 13
Training loss: 1.9246614926441195
Validation loss: 2.4708943450068044

Epoch: 107| Step: 0
Training loss: 2.7475391995355807
Validation loss: 2.4647388466155986

Epoch: 6| Step: 1
Training loss: 2.9438014517983144
Validation loss: 2.4703648593218785

Epoch: 6| Step: 2
Training loss: 2.5672791736879446
Validation loss: 2.472967304031593

Epoch: 6| Step: 3
Training loss: 2.125556760666758
Validation loss: 2.4696472082817866

Epoch: 6| Step: 4
Training loss: 2.373515920241302
Validation loss: 2.4712410764608674

Epoch: 6| Step: 5
Training loss: 2.5033365872188846
Validation loss: 2.4717932827861517

Epoch: 6| Step: 6
Training loss: 2.6390534187915007
Validation loss: 2.469338149820262

Epoch: 6| Step: 7
Training loss: 2.6621666927982064
Validation loss: 2.4659270874675054

Epoch: 6| Step: 8
Training loss: 2.5102212811382865
Validation loss: 2.464697364454302

Epoch: 6| Step: 9
Training loss: 2.7542759856796755
Validation loss: 2.4665312635357015

Epoch: 6| Step: 10
Training loss: 2.4333129524875448
Validation loss: 2.4647138413232876

Epoch: 6| Step: 11
Training loss: 2.607400844074829
Validation loss: 2.4620497032042583

Epoch: 6| Step: 12
Training loss: 2.5697017048300843
Validation loss: 2.4605188891703786

Epoch: 6| Step: 13
Training loss: 2.556085979543833
Validation loss: 2.463010094830911

Epoch: 108| Step: 0
Training loss: 2.28436035903017
Validation loss: 2.45313614439812

Epoch: 6| Step: 1
Training loss: 2.704765042802716
Validation loss: 2.4644234808328394

Epoch: 6| Step: 2
Training loss: 2.455371192792848
Validation loss: 2.455789863966291

Epoch: 6| Step: 3
Training loss: 2.641038580113272
Validation loss: 2.4630872429644186

Epoch: 6| Step: 4
Training loss: 2.250919895741445
Validation loss: 2.457861084487159

Epoch: 6| Step: 5
Training loss: 1.9299394080182481
Validation loss: 2.4555309670091305

Epoch: 6| Step: 6
Training loss: 2.645556658198475
Validation loss: 2.4570412850389807

Epoch: 6| Step: 7
Training loss: 2.661609583150789
Validation loss: 2.460946816724469

Epoch: 6| Step: 8
Training loss: 2.2867147755172903
Validation loss: 2.45657680819012

Epoch: 6| Step: 9
Training loss: 2.7316892676575426
Validation loss: 2.4543731332747063

Epoch: 6| Step: 10
Training loss: 2.5296119758778497
Validation loss: 2.4631081348181554

Epoch: 6| Step: 11
Training loss: 2.8459107291186756
Validation loss: 2.457216919886965

Epoch: 6| Step: 12
Training loss: 3.252704668693911
Validation loss: 2.4587921479515105

Epoch: 6| Step: 13
Training loss: 2.1844092195856617
Validation loss: 2.458868588081597

Epoch: 109| Step: 0
Training loss: 2.4244774402867666
Validation loss: 2.455258213378667

Epoch: 6| Step: 1
Training loss: 2.537713170610797
Validation loss: 2.453402250460469

Epoch: 6| Step: 2
Training loss: 2.9240668740198528
Validation loss: 2.4599085518656727

Epoch: 6| Step: 3
Training loss: 2.8257973718750167
Validation loss: 2.451885971471345

Epoch: 6| Step: 4
Training loss: 1.7533474650133805
Validation loss: 2.45613289538545

Epoch: 6| Step: 5
Training loss: 2.8370214655336037
Validation loss: 2.455505625210927

Epoch: 6| Step: 6
Training loss: 2.4932306193378126
Validation loss: 2.45178698032087

Epoch: 6| Step: 7
Training loss: 2.71167316403946
Validation loss: 2.4525518537477766

Epoch: 6| Step: 8
Training loss: 2.7939156161039773
Validation loss: 2.451954394256067

Epoch: 6| Step: 9
Training loss: 3.1394666366979367
Validation loss: 2.4552228991648675

Epoch: 6| Step: 10
Training loss: 2.2705132728428965
Validation loss: 2.456479558983758

Epoch: 6| Step: 11
Training loss: 2.1483388427277035
Validation loss: 2.4549205712277518

Epoch: 6| Step: 12
Training loss: 2.2691608067536198
Validation loss: 2.4584342617933115

Epoch: 6| Step: 13
Training loss: 2.083511828087559
Validation loss: 2.450293330064995

Epoch: 110| Step: 0
Training loss: 2.2341293520042247
Validation loss: 2.458641296967811

Epoch: 6| Step: 1
Training loss: 3.154497320933768
Validation loss: 2.455769387189201

Epoch: 6| Step: 2
Training loss: 2.0953937739483743
Validation loss: 2.454252206793669

Epoch: 6| Step: 3
Training loss: 2.7295678307385107
Validation loss: 2.4510911743334693

Epoch: 6| Step: 4
Training loss: 2.4470748644352667
Validation loss: 2.457947641494267

Epoch: 6| Step: 5
Training loss: 2.700201846454572
Validation loss: 2.4650775780376604

Epoch: 6| Step: 6
Training loss: 2.261344285710521
Validation loss: 2.4708038671407997

Epoch: 6| Step: 7
Training loss: 2.9555276451928214
Validation loss: 2.476168066598459

Epoch: 6| Step: 8
Training loss: 2.6871647292972476
Validation loss: 2.4771043122614067

Epoch: 6| Step: 9
Training loss: 2.584741321511148
Validation loss: 2.4697212047224655

Epoch: 6| Step: 10
Training loss: 2.6159597677117707
Validation loss: 2.475421839384761

Epoch: 6| Step: 11
Training loss: 2.2462761050295788
Validation loss: 2.469055317859144

Epoch: 6| Step: 12
Training loss: 2.7389745773244214
Validation loss: 2.470667549048052

Epoch: 6| Step: 13
Training loss: 2.395287647852464
Validation loss: 2.4652619407634644

Epoch: 111| Step: 0
Training loss: 2.4792575552385676
Validation loss: 2.463433944142758

Epoch: 6| Step: 1
Training loss: 3.112993904360236
Validation loss: 2.4584639940183473

Epoch: 6| Step: 2
Training loss: 2.928818556031642
Validation loss: 2.453081960766247

Epoch: 6| Step: 3
Training loss: 2.319362458729946
Validation loss: 2.44945369650168

Epoch: 6| Step: 4
Training loss: 2.46981035469758
Validation loss: 2.4519491434989216

Epoch: 6| Step: 5
Training loss: 2.5796437731710093
Validation loss: 2.454418562141555

Epoch: 6| Step: 6
Training loss: 2.623222566743827
Validation loss: 2.4556107935822604

Epoch: 6| Step: 7
Training loss: 2.6559584513712102
Validation loss: 2.4488080992077355

Epoch: 6| Step: 8
Training loss: 2.3241428394903987
Validation loss: 2.450046154158388

Epoch: 6| Step: 9
Training loss: 2.1337045892890205
Validation loss: 2.4506583153281776

Epoch: 6| Step: 10
Training loss: 2.440688468703744
Validation loss: 2.4481993708133527

Epoch: 6| Step: 11
Training loss: 2.054194402088333
Validation loss: 2.4568147710500012

Epoch: 6| Step: 12
Training loss: 2.5366120236393424
Validation loss: 2.4466563829089805

Epoch: 6| Step: 13
Training loss: 2.9053057705658794
Validation loss: 2.4486394153424906

Epoch: 112| Step: 0
Training loss: 2.651813976656502
Validation loss: 2.4458633468666675

Epoch: 6| Step: 1
Training loss: 2.161018406476702
Validation loss: 2.4407648571546465

Epoch: 6| Step: 2
Training loss: 2.5991990176094806
Validation loss: 2.448487955079467

Epoch: 6| Step: 3
Training loss: 2.016650153583775
Validation loss: 2.448016766605013

Epoch: 6| Step: 4
Training loss: 2.820173941719545
Validation loss: 2.4531744528805257

Epoch: 6| Step: 5
Training loss: 2.5406277101696992
Validation loss: 2.4509486690787017

Epoch: 6| Step: 6
Training loss: 2.605481743958884
Validation loss: 2.4554355212495973

Epoch: 6| Step: 7
Training loss: 2.9644699564682275
Validation loss: 2.457253030168952

Epoch: 6| Step: 8
Training loss: 2.5486331792067136
Validation loss: 2.459821110762389

Epoch: 6| Step: 9
Training loss: 2.5734148868755455
Validation loss: 2.460113548924994

Epoch: 6| Step: 10
Training loss: 2.616233902474795
Validation loss: 2.463105860115264

Epoch: 6| Step: 11
Training loss: 2.70661603817623
Validation loss: 2.453669072619219

Epoch: 6| Step: 12
Training loss: 2.71660898026456
Validation loss: 2.452771592651418

Epoch: 6| Step: 13
Training loss: 2.0274108993199667
Validation loss: 2.444724275245012

Epoch: 113| Step: 0
Training loss: 2.83935005272753
Validation loss: 2.451587835229199

Epoch: 6| Step: 1
Training loss: 2.3616287885637623
Validation loss: 2.4509977605615703

Epoch: 6| Step: 2
Training loss: 2.874224184927503
Validation loss: 2.4499535115041873

Epoch: 6| Step: 3
Training loss: 1.9239703905202472
Validation loss: 2.452649517913216

Epoch: 6| Step: 4
Training loss: 2.7982622680667784
Validation loss: 2.456349207951013

Epoch: 6| Step: 5
Training loss: 2.2073235512327276
Validation loss: 2.4507681829549837

Epoch: 6| Step: 6
Training loss: 2.0831057869305285
Validation loss: 2.4507465454536916

Epoch: 6| Step: 7
Training loss: 2.92315368416419
Validation loss: 2.455143642638773

Epoch: 6| Step: 8
Training loss: 2.120300256950997
Validation loss: 2.452910865460182

Epoch: 6| Step: 9
Training loss: 2.8255055135613394
Validation loss: 2.4512879120007

Epoch: 6| Step: 10
Training loss: 2.5107557666579017
Validation loss: 2.462546324253855

Epoch: 6| Step: 11
Training loss: 2.201007014331447
Validation loss: 2.4551062550699663

Epoch: 6| Step: 12
Training loss: 2.7467558538746535
Validation loss: 2.453332993422706

Epoch: 6| Step: 13
Training loss: 2.8688221774859377
Validation loss: 2.452097780957005

Epoch: 114| Step: 0
Training loss: 2.3812290621260015
Validation loss: 2.4466703096262172

Epoch: 6| Step: 1
Training loss: 2.722668159272734
Validation loss: 2.453438011982107

Epoch: 6| Step: 2
Training loss: 2.046435476389886
Validation loss: 2.4549061652519546

Epoch: 6| Step: 3
Training loss: 2.8692067698936095
Validation loss: 2.4587081418711088

Epoch: 6| Step: 4
Training loss: 2.4887724530803674
Validation loss: 2.4580953181072114

Epoch: 6| Step: 5
Training loss: 2.385802347468567
Validation loss: 2.459333124898914

Epoch: 6| Step: 6
Training loss: 3.0247249572811916
Validation loss: 2.46109442639442

Epoch: 6| Step: 7
Training loss: 2.7415778631729735
Validation loss: 2.463390697883283

Epoch: 6| Step: 8
Training loss: 2.4506905497292446
Validation loss: 2.4590775661772106

Epoch: 6| Step: 9
Training loss: 2.7355469726144137
Validation loss: 2.4555144123391583

Epoch: 6| Step: 10
Training loss: 2.133181920738152
Validation loss: 2.4495962076183524

Epoch: 6| Step: 11
Training loss: 2.430534386921086
Validation loss: 2.4488904328359653

Epoch: 6| Step: 12
Training loss: 2.531017528266755
Validation loss: 2.4497253121255396

Epoch: 6| Step: 13
Training loss: 2.6194810525172865
Validation loss: 2.4465125311166687

Epoch: 115| Step: 0
Training loss: 3.0199901237073674
Validation loss: 2.4515061595076117

Epoch: 6| Step: 1
Training loss: 2.0615653029708
Validation loss: 2.44650933142662

Epoch: 6| Step: 2
Training loss: 2.3614221243374303
Validation loss: 2.4501966910005506

Epoch: 6| Step: 3
Training loss: 2.0852360492528215
Validation loss: 2.450627450653955

Epoch: 6| Step: 4
Training loss: 2.3379572171293463
Validation loss: 2.4524215369938105

Epoch: 6| Step: 5
Training loss: 2.1825973066068824
Validation loss: 2.4439889821877543

Epoch: 6| Step: 6
Training loss: 2.8398387127061584
Validation loss: 2.4513611982568904

Epoch: 6| Step: 7
Training loss: 2.6974441723354
Validation loss: 2.4515663913609207

Epoch: 6| Step: 8
Training loss: 2.625244855814123
Validation loss: 2.451858793061351

Epoch: 6| Step: 9
Training loss: 2.74314824415829
Validation loss: 2.4486307171388697

Epoch: 6| Step: 10
Training loss: 2.6749821492963193
Validation loss: 2.447039367169963

Epoch: 6| Step: 11
Training loss: 2.778280751997567
Validation loss: 2.446380918076483

Epoch: 6| Step: 12
Training loss: 2.4834082299870834
Validation loss: 2.449139193713583

Epoch: 6| Step: 13
Training loss: 2.398721485535
Validation loss: 2.4513913485689103

Epoch: 116| Step: 0
Training loss: 2.257664975953306
Validation loss: 2.4494256880774055

Epoch: 6| Step: 1
Training loss: 2.5058941024788206
Validation loss: 2.4519009624153267

Epoch: 6| Step: 2
Training loss: 2.3971357260970967
Validation loss: 2.4529180905175054

Epoch: 6| Step: 3
Training loss: 2.0818006090737753
Validation loss: 2.4508821475777465

Epoch: 6| Step: 4
Training loss: 2.300013674819763
Validation loss: 2.4475502686863204

Epoch: 6| Step: 5
Training loss: 2.6668391370630498
Validation loss: 2.4467232953914553

Epoch: 6| Step: 6
Training loss: 2.8605499355076316
Validation loss: 2.442646706352069

Epoch: 6| Step: 7
Training loss: 2.887526217254914
Validation loss: 2.4456665708975036

Epoch: 6| Step: 8
Training loss: 2.0585885382627933
Validation loss: 2.4490502242211885

Epoch: 6| Step: 9
Training loss: 2.4136744313829217
Validation loss: 2.4438288110901354

Epoch: 6| Step: 10
Training loss: 2.520113524347295
Validation loss: 2.4508805749052556

Epoch: 6| Step: 11
Training loss: 2.5395944830316175
Validation loss: 2.4444105294673273

Epoch: 6| Step: 12
Training loss: 2.958395961761194
Validation loss: 2.4498901096014754

Epoch: 6| Step: 13
Training loss: 2.8229971073039875
Validation loss: 2.4489979621626388

Epoch: 117| Step: 0
Training loss: 2.4676917016910207
Validation loss: 2.4501339927674253

Epoch: 6| Step: 1
Training loss: 2.2977858832716658
Validation loss: 2.4535510428207035

Epoch: 6| Step: 2
Training loss: 2.4183247786339273
Validation loss: 2.4489536659091318

Epoch: 6| Step: 3
Training loss: 2.836417837947756
Validation loss: 2.4536088276027157

Epoch: 6| Step: 4
Training loss: 2.3956716289406064
Validation loss: 2.4544794024786136

Epoch: 6| Step: 5
Training loss: 2.1596995969556914
Validation loss: 2.4566863787812165

Epoch: 6| Step: 6
Training loss: 1.955258356374763
Validation loss: 2.445472720161257

Epoch: 6| Step: 7
Training loss: 2.2601015307820487
Validation loss: 2.4474259446045195

Epoch: 6| Step: 8
Training loss: 2.753466502041118
Validation loss: 2.449855934500586

Epoch: 6| Step: 9
Training loss: 2.6833224096924897
Validation loss: 2.4490739940837463

Epoch: 6| Step: 10
Training loss: 2.8755797755253036
Validation loss: 2.443768900727452

Epoch: 6| Step: 11
Training loss: 2.507198840965193
Validation loss: 2.4426822349168136

Epoch: 6| Step: 12
Training loss: 2.747976859365922
Validation loss: 2.4503898436953886

Epoch: 6| Step: 13
Training loss: 2.919049043876557
Validation loss: 2.44881306461732

Epoch: 118| Step: 0
Training loss: 2.580810165802196
Validation loss: 2.4588658569635506

Epoch: 6| Step: 1
Training loss: 2.400213224158083
Validation loss: 2.4562120229229625

Epoch: 6| Step: 2
Training loss: 2.7167787969496477
Validation loss: 2.4584862343604024

Epoch: 6| Step: 3
Training loss: 2.0932809104956176
Validation loss: 2.4553007774984343

Epoch: 6| Step: 4
Training loss: 2.5815359035775507
Validation loss: 2.4526772546047995

Epoch: 6| Step: 5
Training loss: 2.3797878392005734
Validation loss: 2.4540726760801594

Epoch: 6| Step: 6
Training loss: 2.2379143698829744
Validation loss: 2.447498323662729

Epoch: 6| Step: 7
Training loss: 3.316180218114461
Validation loss: 2.4546167652825828

Epoch: 6| Step: 8
Training loss: 2.0718098533825438
Validation loss: 2.4509283220893536

Epoch: 6| Step: 9
Training loss: 2.539836964969261
Validation loss: 2.4492465742154157

Epoch: 6| Step: 10
Training loss: 2.558018463921141
Validation loss: 2.453632958176697

Epoch: 6| Step: 11
Training loss: 2.1989576818289636
Validation loss: 2.456305820778808

Epoch: 6| Step: 12
Training loss: 2.632336038553388
Validation loss: 2.458974663005998

Epoch: 6| Step: 13
Training loss: 2.982986846352611
Validation loss: 2.4480564375129044

Epoch: 119| Step: 0
Training loss: 2.492723556793015
Validation loss: 2.452928312479294

Epoch: 6| Step: 1
Training loss: 1.9555962759110839
Validation loss: 2.45058148937714

Epoch: 6| Step: 2
Training loss: 2.0313694845416603
Validation loss: 2.450965222162161

Epoch: 6| Step: 3
Training loss: 2.795714068154844
Validation loss: 2.449510215277524

Epoch: 6| Step: 4
Training loss: 2.657168330599304
Validation loss: 2.4496411411060977

Epoch: 6| Step: 5
Training loss: 2.698568218800213
Validation loss: 2.455519315640138

Epoch: 6| Step: 6
Training loss: 2.6935277364778134
Validation loss: 2.4659161942476504

Epoch: 6| Step: 7
Training loss: 2.7801213063730534
Validation loss: 2.4634911986995713

Epoch: 6| Step: 8
Training loss: 1.9683084144059313
Validation loss: 2.4634354442791264

Epoch: 6| Step: 9
Training loss: 2.9047283167687614
Validation loss: 2.4635550489861955

Epoch: 6| Step: 10
Training loss: 2.2159323195371483
Validation loss: 2.4604039981353316

Epoch: 6| Step: 11
Training loss: 3.2303403300691538
Validation loss: 2.459337762068438

Epoch: 6| Step: 12
Training loss: 2.52776482919956
Validation loss: 2.4561588778430425

Epoch: 6| Step: 13
Training loss: 2.203040804505427
Validation loss: 2.456918152842841

Epoch: 120| Step: 0
Training loss: 2.870821362504145
Validation loss: 2.4515081207941742

Epoch: 6| Step: 1
Training loss: 2.5925262505757423
Validation loss: 2.454398122493506

Epoch: 6| Step: 2
Training loss: 2.8630982219490537
Validation loss: 2.4503840787688542

Epoch: 6| Step: 3
Training loss: 2.931156858090914
Validation loss: 2.4559693581412336

Epoch: 6| Step: 4
Training loss: 2.043913117878316
Validation loss: 2.451588686172484

Epoch: 6| Step: 5
Training loss: 2.445716897596383
Validation loss: 2.450487748077095

Epoch: 6| Step: 6
Training loss: 2.1627878780255987
Validation loss: 2.4602001397457856

Epoch: 6| Step: 7
Training loss: 1.9864637540500922
Validation loss: 2.45396721509233

Epoch: 6| Step: 8
Training loss: 2.2940629626066955
Validation loss: 2.453244864416674

Epoch: 6| Step: 9
Training loss: 2.659310048046415
Validation loss: 2.454889735861768

Epoch: 6| Step: 10
Training loss: 3.2136885466722203
Validation loss: 2.4582971527109603

Epoch: 6| Step: 11
Training loss: 2.809097945116686
Validation loss: 2.451989220752639

Epoch: 6| Step: 12
Training loss: 2.069429489980624
Validation loss: 2.459462542270416

Epoch: 6| Step: 13
Training loss: 1.9816710906090322
Validation loss: 2.451439734181672

Epoch: 121| Step: 0
Training loss: 2.3739485169816334
Validation loss: 2.455657040995489

Epoch: 6| Step: 1
Training loss: 2.2437912791075774
Validation loss: 2.4559942502219565

Epoch: 6| Step: 2
Training loss: 2.6191684798225183
Validation loss: 2.4553792035981985

Epoch: 6| Step: 3
Training loss: 2.498129526400957
Validation loss: 2.454066765980389

Epoch: 6| Step: 4
Training loss: 2.6345527851393578
Validation loss: 2.468008364570515

Epoch: 6| Step: 5
Training loss: 2.8575837408229052
Validation loss: 2.4637995793918175

Epoch: 6| Step: 6
Training loss: 2.328207334560261
Validation loss: 2.446893272477833

Epoch: 6| Step: 7
Training loss: 2.5294197906909526
Validation loss: 2.4382119076528768

Epoch: 6| Step: 8
Training loss: 2.4619008918479515
Validation loss: 2.445212332692001

Epoch: 6| Step: 9
Training loss: 2.0270804232360504
Validation loss: 2.4563786014349756

Epoch: 6| Step: 10
Training loss: 3.4868904921082735
Validation loss: 2.4663030352064417

Epoch: 6| Step: 11
Training loss: 2.7445969823213447
Validation loss: 2.473082254120874

Epoch: 6| Step: 12
Training loss: 2.2048180750320507
Validation loss: 2.477546151581715

Epoch: 6| Step: 13
Training loss: 2.358273684912169
Validation loss: 2.465040437858022

Epoch: 122| Step: 0
Training loss: 2.128394165045976
Validation loss: 2.47276618476096

Epoch: 6| Step: 1
Training loss: 2.109706485274672
Validation loss: 2.465397469804339

Epoch: 6| Step: 2
Training loss: 2.680410926971228
Validation loss: 2.4601545430566447

Epoch: 6| Step: 3
Training loss: 1.8858502839535138
Validation loss: 2.4534765910826457

Epoch: 6| Step: 4
Training loss: 2.5125047750095524
Validation loss: 2.4474196287888392

Epoch: 6| Step: 5
Training loss: 2.0321845619007957
Validation loss: 2.450654683256409

Epoch: 6| Step: 6
Training loss: 2.5560235778962834
Validation loss: 2.4485237964904236

Epoch: 6| Step: 7
Training loss: 2.817593264859721
Validation loss: 2.4564061018995083

Epoch: 6| Step: 8
Training loss: 2.424092710994483
Validation loss: 2.449318136969979

Epoch: 6| Step: 9
Training loss: 2.6850113102339037
Validation loss: 2.4579629672959324

Epoch: 6| Step: 10
Training loss: 2.6922581269868346
Validation loss: 2.4528228184889644

Epoch: 6| Step: 11
Training loss: 2.5806583788748623
Validation loss: 2.4443412858937776

Epoch: 6| Step: 12
Training loss: 3.5298078174525895
Validation loss: 2.449489710338519

Epoch: 6| Step: 13
Training loss: 2.6116629979980774
Validation loss: 2.4401584376295027

Epoch: 123| Step: 0
Training loss: 2.3046502579088433
Validation loss: 2.445476879895817

Epoch: 6| Step: 1
Training loss: 1.9934373712128501
Validation loss: 2.451328883518824

Epoch: 6| Step: 2
Training loss: 2.7519980887861046
Validation loss: 2.4498146463851853

Epoch: 6| Step: 3
Training loss: 3.0779954912079526
Validation loss: 2.4514344823221697

Epoch: 6| Step: 4
Training loss: 2.3426638311623336
Validation loss: 2.4502219660761124

Epoch: 6| Step: 5
Training loss: 2.0834257741128654
Validation loss: 2.4527891378642455

Epoch: 6| Step: 6
Training loss: 3.0986914426280348
Validation loss: 2.4505954343255483

Epoch: 6| Step: 7
Training loss: 2.288486759833419
Validation loss: 2.4571230274358187

Epoch: 6| Step: 8
Training loss: 1.7906543030263484
Validation loss: 2.4528580781568436

Epoch: 6| Step: 9
Training loss: 2.6682110923518794
Validation loss: 2.4564177814154173

Epoch: 6| Step: 10
Training loss: 2.812927128889084
Validation loss: 2.466562678318846

Epoch: 6| Step: 11
Training loss: 2.411084161872481
Validation loss: 2.4534569857843143

Epoch: 6| Step: 12
Training loss: 2.9358299865039466
Validation loss: 2.453309702146096

Epoch: 6| Step: 13
Training loss: 2.4012165681655344
Validation loss: 2.4507666426371157

Epoch: 124| Step: 0
Training loss: 2.7922172762537767
Validation loss: 2.45498084879836

Epoch: 6| Step: 1
Training loss: 2.5343801665341625
Validation loss: 2.4462460491893783

Epoch: 6| Step: 2
Training loss: 2.3047456378392734
Validation loss: 2.449937908527615

Epoch: 6| Step: 3
Training loss: 2.5162767786154054
Validation loss: 2.448897475039866

Epoch: 6| Step: 4
Training loss: 2.350725703091868
Validation loss: 2.447401184565432

Epoch: 6| Step: 5
Training loss: 3.0982300658627056
Validation loss: 2.4466387612347846

Epoch: 6| Step: 6
Training loss: 2.418731421268683
Validation loss: 2.446112098815905

Epoch: 6| Step: 7
Training loss: 2.7634939830666903
Validation loss: 2.446274329551651

Epoch: 6| Step: 8
Training loss: 2.2848142188610154
Validation loss: 2.441070305662601

Epoch: 6| Step: 9
Training loss: 1.8187006416046576
Validation loss: 2.4359944413376953

Epoch: 6| Step: 10
Training loss: 2.8716198497578747
Validation loss: 2.438616016226239

Epoch: 6| Step: 11
Training loss: 2.87925703584991
Validation loss: 2.4371482399679962

Epoch: 6| Step: 12
Training loss: 2.0350210543956284
Validation loss: 2.438993697302843

Epoch: 6| Step: 13
Training loss: 2.3638452282569338
Validation loss: 2.4410642664126554

Epoch: 125| Step: 0
Training loss: 2.431728278728901
Validation loss: 2.439869780192432

Epoch: 6| Step: 1
Training loss: 2.5082300141643863
Validation loss: 2.45672126759377

Epoch: 6| Step: 2
Training loss: 2.4219922437283774
Validation loss: 2.443602430175882

Epoch: 6| Step: 3
Training loss: 2.1959568584908555
Validation loss: 2.453971797630792

Epoch: 6| Step: 4
Training loss: 2.522048993354001
Validation loss: 2.4581874599389053

Epoch: 6| Step: 5
Training loss: 2.4535931183095667
Validation loss: 2.4567555898086053

Epoch: 6| Step: 6
Training loss: 1.9360506112442712
Validation loss: 2.454603968283018

Epoch: 6| Step: 7
Training loss: 2.1664456352563386
Validation loss: 2.4588678931820267

Epoch: 6| Step: 8
Training loss: 2.326472880300705
Validation loss: 2.4484798730406383

Epoch: 6| Step: 9
Training loss: 3.1840551872742267
Validation loss: 2.4492090317301627

Epoch: 6| Step: 10
Training loss: 2.6488292483130635
Validation loss: 2.441651940762463

Epoch: 6| Step: 11
Training loss: 2.9886349936151513
Validation loss: 2.4418563061738956

Epoch: 6| Step: 12
Training loss: 2.4859968925205
Validation loss: 2.4498485706527733

Epoch: 6| Step: 13
Training loss: 2.627302159375224
Validation loss: 2.4530102162325296

Epoch: 126| Step: 0
Training loss: 2.674395526790273
Validation loss: 2.458256022536161

Epoch: 6| Step: 1
Training loss: 2.164481112208518
Validation loss: 2.461850210005125

Epoch: 6| Step: 2
Training loss: 2.3937304901841916
Validation loss: 2.464455599684598

Epoch: 6| Step: 3
Training loss: 2.7313274730457806
Validation loss: 2.462823578993105

Epoch: 6| Step: 4
Training loss: 2.597122206323306
Validation loss: 2.471110925203693

Epoch: 6| Step: 5
Training loss: 2.6289913169395325
Validation loss: 2.470132191347195

Epoch: 6| Step: 6
Training loss: 2.795500859950395
Validation loss: 2.467834818088874

Epoch: 6| Step: 7
Training loss: 2.799771817310101
Validation loss: 2.4564522534577917

Epoch: 6| Step: 8
Training loss: 2.2341899661829734
Validation loss: 2.459240686674387

Epoch: 6| Step: 9
Training loss: 2.490631478754709
Validation loss: 2.450613546424958

Epoch: 6| Step: 10
Training loss: 2.223993043531886
Validation loss: 2.4602874704712017

Epoch: 6| Step: 11
Training loss: 2.9599912233480294
Validation loss: 2.447754295861978

Epoch: 6| Step: 12
Training loss: 2.361818778506277
Validation loss: 2.4490380877109277

Epoch: 6| Step: 13
Training loss: 2.3782187284227976
Validation loss: 2.450054782462561

Epoch: 127| Step: 0
Training loss: 2.427353796126268
Validation loss: 2.460133819946235

Epoch: 6| Step: 1
Training loss: 2.7365001158809235
Validation loss: 2.452640283080644

Epoch: 6| Step: 2
Training loss: 2.764832463905688
Validation loss: 2.444870597064741

Epoch: 6| Step: 3
Training loss: 2.313799003523174
Validation loss: 2.4467370512017403

Epoch: 6| Step: 4
Training loss: 2.0605804295994234
Validation loss: 2.4535936041655013

Epoch: 6| Step: 5
Training loss: 3.0578941431778417
Validation loss: 2.4493476635003746

Epoch: 6| Step: 6
Training loss: 2.3141791974301826
Validation loss: 2.4497911675648916

Epoch: 6| Step: 7
Training loss: 2.499932097466521
Validation loss: 2.449302400157273

Epoch: 6| Step: 8
Training loss: 2.6028871571851804
Validation loss: 2.4488987163479017

Epoch: 6| Step: 9
Training loss: 3.032273110049328
Validation loss: 2.445289619834385

Epoch: 6| Step: 10
Training loss: 2.307459725372538
Validation loss: 2.4495127297162993

Epoch: 6| Step: 11
Training loss: 1.9102055517905796
Validation loss: 2.4578448526880727

Epoch: 6| Step: 12
Training loss: 2.5031284784680983
Validation loss: 2.4569483320014847

Epoch: 6| Step: 13
Training loss: 2.4528859015893545
Validation loss: 2.445719895231482

Epoch: 128| Step: 0
Training loss: 2.8472151552024743
Validation loss: 2.446365714633046

Epoch: 6| Step: 1
Training loss: 1.120725245505104
Validation loss: 2.4490368708115278

Epoch: 6| Step: 2
Training loss: 2.8492842260629447
Validation loss: 2.446944158558415

Epoch: 6| Step: 3
Training loss: 2.655789773003483
Validation loss: 2.4437120946885895

Epoch: 6| Step: 4
Training loss: 2.1556258473072503
Validation loss: 2.4485342234267904

Epoch: 6| Step: 5
Training loss: 3.0638124417401307
Validation loss: 2.4484928724514843

Epoch: 6| Step: 6
Training loss: 2.7050028546048543
Validation loss: 2.4458967735688786

Epoch: 6| Step: 7
Training loss: 2.309169432868893
Validation loss: 2.4657523228301987

Epoch: 6| Step: 8
Training loss: 2.475802813478494
Validation loss: 2.4526840429178707

Epoch: 6| Step: 9
Training loss: 2.5860202925874956
Validation loss: 2.455235361158988

Epoch: 6| Step: 10
Training loss: 2.1347687521420373
Validation loss: 2.4538093794719478

Epoch: 6| Step: 11
Training loss: 2.567553677392452
Validation loss: 2.4490399373968574

Epoch: 6| Step: 12
Training loss: 2.329801941177302
Validation loss: 2.4466853325267786

Epoch: 6| Step: 13
Training loss: 2.8405278993971206
Validation loss: 2.4479091454789432

Epoch: 129| Step: 0
Training loss: 2.306976836506172
Validation loss: 2.4535894096060966

Epoch: 6| Step: 1
Training loss: 2.5691033855823218
Validation loss: 2.4613066219844946

Epoch: 6| Step: 2
Training loss: 2.591252422856083
Validation loss: 2.459175019654536

Epoch: 6| Step: 3
Training loss: 2.4878904793359395
Validation loss: 2.464198121132527

Epoch: 6| Step: 4
Training loss: 2.4317300435366325
Validation loss: 2.4645179980644922

Epoch: 6| Step: 5
Training loss: 2.6519065800030965
Validation loss: 2.4609994224548695

Epoch: 6| Step: 6
Training loss: 2.5467260586302367
Validation loss: 2.4624777681538026

Epoch: 6| Step: 7
Training loss: 2.9532567554933635
Validation loss: 2.4521569935882193

Epoch: 6| Step: 8
Training loss: 2.575317611365239
Validation loss: 2.4556330759471185

Epoch: 6| Step: 9
Training loss: 2.59760494324919
Validation loss: 2.450154135520089

Epoch: 6| Step: 10
Training loss: 2.720302796058941
Validation loss: 2.4528593174605535

Epoch: 6| Step: 11
Training loss: 2.0407013719646914
Validation loss: 2.4511642962537428

Epoch: 6| Step: 12
Training loss: 2.345911682157578
Validation loss: 2.4549104384940437

Epoch: 6| Step: 13
Training loss: 2.403831753027402
Validation loss: 2.46477317809788

Epoch: 130| Step: 0
Training loss: 2.4729419320242476
Validation loss: 2.465556803808956

Epoch: 6| Step: 1
Training loss: 2.4914857839124807
Validation loss: 2.4577032240761447

Epoch: 6| Step: 2
Training loss: 2.634587264192026
Validation loss: 2.4580962152943298

Epoch: 6| Step: 3
Training loss: 2.5820018864749605
Validation loss: 2.4536712103184364

Epoch: 6| Step: 4
Training loss: 2.494741058367225
Validation loss: 2.448062540672444

Epoch: 6| Step: 5
Training loss: 2.9412156001461316
Validation loss: 2.456548298654503

Epoch: 6| Step: 6
Training loss: 2.2532820605853283
Validation loss: 2.4497841441503994

Epoch: 6| Step: 7
Training loss: 2.36075021441482
Validation loss: 2.4497319869631324

Epoch: 6| Step: 8
Training loss: 2.9241242752488494
Validation loss: 2.4520555987824717

Epoch: 6| Step: 9
Training loss: 1.9363295803868787
Validation loss: 2.4555216135533993

Epoch: 6| Step: 10
Training loss: 2.816351563323525
Validation loss: 2.4629226186369877

Epoch: 6| Step: 11
Training loss: 2.051209497697001
Validation loss: 2.464722934186207

Epoch: 6| Step: 12
Training loss: 2.796111956460092
Validation loss: 2.471700153042536

Epoch: 6| Step: 13
Training loss: 2.289993981932349
Validation loss: 2.474517282620493

Epoch: 131| Step: 0
Training loss: 2.352178854026225
Validation loss: 2.4748476431091646

Epoch: 6| Step: 1
Training loss: 1.97897017323366
Validation loss: 2.4695975542847033

Epoch: 6| Step: 2
Training loss: 2.4198345818219367
Validation loss: 2.4623688022241117

Epoch: 6| Step: 3
Training loss: 2.5510436970173203
Validation loss: 2.461628618025942

Epoch: 6| Step: 4
Training loss: 2.905164290229153
Validation loss: 2.461212619157296

Epoch: 6| Step: 5
Training loss: 2.733364681513833
Validation loss: 2.464810273940145

Epoch: 6| Step: 6
Training loss: 2.5638649259388595
Validation loss: 2.4581134396069517

Epoch: 6| Step: 7
Training loss: 2.611186968826521
Validation loss: 2.4600793139405472

Epoch: 6| Step: 8
Training loss: 3.226102856277559
Validation loss: 2.4627032368761625

Epoch: 6| Step: 9
Training loss: 2.3880361863658135
Validation loss: 2.4672430565707

Epoch: 6| Step: 10
Training loss: 2.6215523376886303
Validation loss: 2.4742231100172662

Epoch: 6| Step: 11
Training loss: 2.059918493121323
Validation loss: 2.4702549624674233

Epoch: 6| Step: 12
Training loss: 2.5215717421686263
Validation loss: 2.463838899409465

Epoch: 6| Step: 13
Training loss: 2.2954892500100326
Validation loss: 2.4596703875054695

Epoch: 132| Step: 0
Training loss: 1.8887309525726672
Validation loss: 2.46304737855725

Epoch: 6| Step: 1
Training loss: 2.214115514234968
Validation loss: 2.4608972455320064

Epoch: 6| Step: 2
Training loss: 2.179845879382606
Validation loss: 2.4541244657565735

Epoch: 6| Step: 3
Training loss: 2.467030372955304
Validation loss: 2.4667242567539316

Epoch: 6| Step: 4
Training loss: 2.8668874640783257
Validation loss: 2.452358766015406

Epoch: 6| Step: 5
Training loss: 2.8851201608581802
Validation loss: 2.4641045914503734

Epoch: 6| Step: 6
Training loss: 2.493836625585627
Validation loss: 2.4572480413863955

Epoch: 6| Step: 7
Training loss: 2.285532445997331
Validation loss: 2.4547327365669007

Epoch: 6| Step: 8
Training loss: 2.535440531868833
Validation loss: 2.459622220350131

Epoch: 6| Step: 9
Training loss: 2.6557137340679047
Validation loss: 2.446716084522582

Epoch: 6| Step: 10
Training loss: 2.4323221622709066
Validation loss: 2.4504138843468906

Epoch: 6| Step: 11
Training loss: 2.8678287132114972
Validation loss: 2.4514183619609264

Epoch: 6| Step: 12
Training loss: 2.26798593565198
Validation loss: 2.44524925402019

Epoch: 6| Step: 13
Training loss: 2.699554731599522
Validation loss: 2.45475996409491

Epoch: 133| Step: 0
Training loss: 2.254572778057976
Validation loss: 2.450738787037459

Epoch: 6| Step: 1
Training loss: 2.0745322929805505
Validation loss: 2.4548241305110015

Epoch: 6| Step: 2
Training loss: 2.6007737805622217
Validation loss: 2.4504174843432027

Epoch: 6| Step: 3
Training loss: 2.5098241420707335
Validation loss: 2.4423362161105557

Epoch: 6| Step: 4
Training loss: 2.8143390153231658
Validation loss: 2.44726257242843

Epoch: 6| Step: 5
Training loss: 2.7643444307807457
Validation loss: 2.4463078399770013

Epoch: 6| Step: 6
Training loss: 2.4871864964741603
Validation loss: 2.452267426024836

Epoch: 6| Step: 7
Training loss: 1.9806121834424228
Validation loss: 2.452136267709455

Epoch: 6| Step: 8
Training loss: 2.3616707855310732
Validation loss: 2.459453260314853

Epoch: 6| Step: 9
Training loss: 2.8319633949306358
Validation loss: 2.4627199852497843

Epoch: 6| Step: 10
Training loss: 2.6924958923081825
Validation loss: 2.4664134142576977

Epoch: 6| Step: 11
Training loss: 2.850075697311865
Validation loss: 2.458957291207247

Epoch: 6| Step: 12
Training loss: 2.556992264032876
Validation loss: 2.4630557515882434

Epoch: 6| Step: 13
Training loss: 2.0886739433682133
Validation loss: 2.4633589361595556

Epoch: 134| Step: 0
Training loss: 2.3675947688791728
Validation loss: 2.462915842409684

Epoch: 6| Step: 1
Training loss: 2.527158656705128
Validation loss: 2.4631305752142367

Epoch: 6| Step: 2
Training loss: 2.711893841919124
Validation loss: 2.4591366592208654

Epoch: 6| Step: 3
Training loss: 3.028570190079839
Validation loss: 2.4622617035021284

Epoch: 6| Step: 4
Training loss: 3.064591452671881
Validation loss: 2.4474710478221335

Epoch: 6| Step: 5
Training loss: 2.1407406072654425
Validation loss: 2.4599796913828356

Epoch: 6| Step: 6
Training loss: 2.291706732197409
Validation loss: 2.4604467477878793

Epoch: 6| Step: 7
Training loss: 2.9732917176600187
Validation loss: 2.45316225578381

Epoch: 6| Step: 8
Training loss: 3.1135148136686426
Validation loss: 2.4569762304116542

Epoch: 6| Step: 9
Training loss: 1.7416063374317743
Validation loss: 2.459812839800651

Epoch: 6| Step: 10
Training loss: 2.443839314967658
Validation loss: 2.4512404636143734

Epoch: 6| Step: 11
Training loss: 2.1537534109521426
Validation loss: 2.458293531925397

Epoch: 6| Step: 12
Training loss: 2.098843428603708
Validation loss: 2.4501816653027046

Epoch: 6| Step: 13
Training loss: 1.8086974276987262
Validation loss: 2.440172702691257

Epoch: 135| Step: 0
Training loss: 1.8916364754215498
Validation loss: 2.45600611775824

Epoch: 6| Step: 1
Training loss: 2.432080626606858
Validation loss: 2.4485377775007904

Epoch: 6| Step: 2
Training loss: 2.7006698660466286
Validation loss: 2.4561147754515975

Epoch: 6| Step: 3
Training loss: 2.101545936490838
Validation loss: 2.456734061651681

Epoch: 6| Step: 4
Training loss: 3.155714990575924
Validation loss: 2.456840988903239

Epoch: 6| Step: 5
Training loss: 2.336845502154548
Validation loss: 2.452540139619348

Epoch: 6| Step: 6
Training loss: 1.814027865766764
Validation loss: 2.454565487845706

Epoch: 6| Step: 7
Training loss: 2.9048292727702383
Validation loss: 2.4467837099444054

Epoch: 6| Step: 8
Training loss: 2.59614378989682
Validation loss: 2.4491929859548347

Epoch: 6| Step: 9
Training loss: 2.717120416656586
Validation loss: 2.4504820239202894

Epoch: 6| Step: 10
Training loss: 2.8080888700251685
Validation loss: 2.451404300121341

Epoch: 6| Step: 11
Training loss: 1.8811838537608148
Validation loss: 2.4526362975105815

Epoch: 6| Step: 12
Training loss: 2.699951072532127
Validation loss: 2.4552474994041398

Epoch: 6| Step: 13
Training loss: 2.616239370296225
Validation loss: 2.4510284341329838

Epoch: 136| Step: 0
Training loss: 2.20668607730146
Validation loss: 2.455519882027409

Epoch: 6| Step: 1
Training loss: 2.0468493743923113
Validation loss: 2.4550769920215

Epoch: 6| Step: 2
Training loss: 2.6367396375040726
Validation loss: 2.45022810438524

Epoch: 6| Step: 3
Training loss: 1.800239796030426
Validation loss: 2.4580815773626896

Epoch: 6| Step: 4
Training loss: 2.705285416245319
Validation loss: 2.4517743873486695

Epoch: 6| Step: 5
Training loss: 2.3954380428014903
Validation loss: 2.4514560732281714

Epoch: 6| Step: 6
Training loss: 2.864070851115587
Validation loss: 2.452627176039278

Epoch: 6| Step: 7
Training loss: 2.205713253271594
Validation loss: 2.455561130852025

Epoch: 6| Step: 8
Training loss: 2.8578623955543816
Validation loss: 2.45686345419463

Epoch: 6| Step: 9
Training loss: 2.5440556185598475
Validation loss: 2.4607713269840965

Epoch: 6| Step: 10
Training loss: 3.1846062483598008
Validation loss: 2.460504483672684

Epoch: 6| Step: 11
Training loss: 1.6596267394297872
Validation loss: 2.4548909336732416

Epoch: 6| Step: 12
Training loss: 3.083290684035604
Validation loss: 2.4538305851248743

Epoch: 6| Step: 13
Training loss: 2.3575381777312643
Validation loss: 2.4583033193490973

Epoch: 137| Step: 0
Training loss: 2.2624708647985945
Validation loss: 2.452736453246676

Epoch: 6| Step: 1
Training loss: 2.798250424912188
Validation loss: 2.455112988111405

Epoch: 6| Step: 2
Training loss: 2.0383228114998406
Validation loss: 2.4507790300081345

Epoch: 6| Step: 3
Training loss: 2.0331858873323685
Validation loss: 2.4558005027617424

Epoch: 6| Step: 4
Training loss: 2.5682091730675713
Validation loss: 2.453398833005163

Epoch: 6| Step: 5
Training loss: 2.1013661119103926
Validation loss: 2.453914636733022

Epoch: 6| Step: 6
Training loss: 2.9203366396474206
Validation loss: 2.457841797088407

Epoch: 6| Step: 7
Training loss: 2.3881056731339774
Validation loss: 2.4612896460418363

Epoch: 6| Step: 8
Training loss: 2.5706107943360528
Validation loss: 2.461696705446576

Epoch: 6| Step: 9
Training loss: 2.712501448529819
Validation loss: 2.4557956890158974

Epoch: 6| Step: 10
Training loss: 3.0586386490957356
Validation loss: 2.457336924288288

Epoch: 6| Step: 11
Training loss: 2.4671034331733206
Validation loss: 2.4587066873350114

Epoch: 6| Step: 12
Training loss: 2.4870435669767685
Validation loss: 2.4542408974587424

Epoch: 6| Step: 13
Training loss: 2.1922542678768844
Validation loss: 2.4645963001528157

Epoch: 138| Step: 0
Training loss: 2.1173899648781513
Validation loss: 2.473021646492564

Epoch: 6| Step: 1
Training loss: 2.249859911478236
Validation loss: 2.4649539042270945

Epoch: 6| Step: 2
Training loss: 2.04309571785188
Validation loss: 2.4752698266367044

Epoch: 6| Step: 3
Training loss: 2.3882737908014446
Validation loss: 2.49504276570253

Epoch: 6| Step: 4
Training loss: 2.9578535380390685
Validation loss: 2.520787740457978

Epoch: 6| Step: 5
Training loss: 2.426579391705635
Validation loss: 2.4883637147629876

Epoch: 6| Step: 6
Training loss: 3.0360916640424844
Validation loss: 2.476445882239696

Epoch: 6| Step: 7
Training loss: 2.166668696280287
Validation loss: 2.464102253162834

Epoch: 6| Step: 8
Training loss: 2.5085835920263038
Validation loss: 2.453562703536542

Epoch: 6| Step: 9
Training loss: 2.943707015904164
Validation loss: 2.465440874271539

Epoch: 6| Step: 10
Training loss: 2.378855837834333
Validation loss: 2.477544443467727

Epoch: 6| Step: 11
Training loss: 3.0093837844863027
Validation loss: 2.4877602407531985

Epoch: 6| Step: 12
Training loss: 2.6627791997096284
Validation loss: 2.478713231868061

Epoch: 6| Step: 13
Training loss: 2.3241307346123676
Validation loss: 2.4891567157316152

Epoch: 139| Step: 0
Training loss: 2.548735892428446
Validation loss: 2.4794359915696544

Epoch: 6| Step: 1
Training loss: 2.7207497444184257
Validation loss: 2.4863377621112575

Epoch: 6| Step: 2
Training loss: 2.2783724259336715
Validation loss: 2.488016750264998

Epoch: 6| Step: 3
Training loss: 2.41892027736086
Validation loss: 2.486938976875172

Epoch: 6| Step: 4
Training loss: 2.982597420852826
Validation loss: 2.4826015804543373

Epoch: 6| Step: 5
Training loss: 2.925037651145728
Validation loss: 2.483669204741677

Epoch: 6| Step: 6
Training loss: 2.2301166209701773
Validation loss: 2.4832537538036723

Epoch: 6| Step: 7
Training loss: 2.9233897153781117
Validation loss: 2.4765074650599135

Epoch: 6| Step: 8
Training loss: 2.7606288804348047
Validation loss: 2.476442721225061

Epoch: 6| Step: 9
Training loss: 2.214199934673472
Validation loss: 2.4719565769114107

Epoch: 6| Step: 10
Training loss: 2.6737831842004844
Validation loss: 2.4746924719824968

Epoch: 6| Step: 11
Training loss: 2.1499683821371542
Validation loss: 2.469667610218048

Epoch: 6| Step: 12
Training loss: 2.7170610114342217
Validation loss: 2.458801230391581

Epoch: 6| Step: 13
Training loss: 2.324277835383431
Validation loss: 2.4642720715715747

Epoch: 140| Step: 0
Training loss: 2.897263939681996
Validation loss: 2.4601318978406317

Epoch: 6| Step: 1
Training loss: 3.107135829071966
Validation loss: 2.4654745754678635

Epoch: 6| Step: 2
Training loss: 2.3768173091205513
Validation loss: 2.456997910087896

Epoch: 6| Step: 3
Training loss: 2.4795872841710973
Validation loss: 2.460884311646201

Epoch: 6| Step: 4
Training loss: 1.9818266477674447
Validation loss: 2.4596403871441943

Epoch: 6| Step: 5
Training loss: 2.762445205904544
Validation loss: 2.456233604188769

Epoch: 6| Step: 6
Training loss: 2.539218369614726
Validation loss: 2.463878734882605

Epoch: 6| Step: 7
Training loss: 2.0265881374269825
Validation loss: 2.4615243686293997

Epoch: 6| Step: 8
Training loss: 2.918248174685905
Validation loss: 2.463035262618078

Epoch: 6| Step: 9
Training loss: 2.3149866704371664
Validation loss: 2.4684789323675913

Epoch: 6| Step: 10
Training loss: 2.810306456610367
Validation loss: 2.4668720361772167

Epoch: 6| Step: 11
Training loss: 2.6217458627245662
Validation loss: 2.4658625009282846

Epoch: 6| Step: 12
Training loss: 2.165769268916724
Validation loss: 2.4598241154408207

Epoch: 6| Step: 13
Training loss: 2.284008292054525
Validation loss: 2.4637054862032115

Epoch: 141| Step: 0
Training loss: 2.6362806168103705
Validation loss: 2.454177047716172

Epoch: 6| Step: 1
Training loss: 2.7010569516970637
Validation loss: 2.4602644549992

Epoch: 6| Step: 2
Training loss: 2.2279561282415092
Validation loss: 2.4605837209409276

Epoch: 6| Step: 3
Training loss: 2.275514054122772
Validation loss: 2.460156239016644

Epoch: 6| Step: 4
Training loss: 2.1787888509992817
Validation loss: 2.4653541693395797

Epoch: 6| Step: 5
Training loss: 2.7892232041849345
Validation loss: 2.466492268372662

Epoch: 6| Step: 6
Training loss: 2.478835545928234
Validation loss: 2.4683579725142892

Epoch: 6| Step: 7
Training loss: 2.672968679642059
Validation loss: 2.4638672762021674

Epoch: 6| Step: 8
Training loss: 2.3290110700449858
Validation loss: 2.465662591000583

Epoch: 6| Step: 9
Training loss: 3.017991476543669
Validation loss: 2.4613090436500813

Epoch: 6| Step: 10
Training loss: 2.305878722536039
Validation loss: 2.459592324413384

Epoch: 6| Step: 11
Training loss: 2.495664652206785
Validation loss: 2.4577593672163243

Epoch: 6| Step: 12
Training loss: 2.364162715746761
Validation loss: 2.459459028218253

Epoch: 6| Step: 13
Training loss: 2.4479617067346378
Validation loss: 2.4584210159268287

Epoch: 142| Step: 0
Training loss: 2.1388016334780007
Validation loss: 2.463278441181027

Epoch: 6| Step: 1
Training loss: 2.7167992444442848
Validation loss: 2.463471253714813

Epoch: 6| Step: 2
Training loss: 2.8988576414874796
Validation loss: 2.4576121958995407

Epoch: 6| Step: 3
Training loss: 2.6965585675477795
Validation loss: 2.458112235283058

Epoch: 6| Step: 4
Training loss: 2.5614163968651957
Validation loss: 2.457312838172238

Epoch: 6| Step: 5
Training loss: 2.0629011977736895
Validation loss: 2.4575229914829273

Epoch: 6| Step: 6
Training loss: 2.4020879841936207
Validation loss: 2.46108957456557

Epoch: 6| Step: 7
Training loss: 2.8613002944998933
Validation loss: 2.4530726627671076

Epoch: 6| Step: 8
Training loss: 1.7941326942658922
Validation loss: 2.458118515542785

Epoch: 6| Step: 9
Training loss: 2.9190678294796486
Validation loss: 2.459517732426419

Epoch: 6| Step: 10
Training loss: 1.8399409371723634
Validation loss: 2.4658098861423543

Epoch: 6| Step: 11
Training loss: 2.8123507989938883
Validation loss: 2.463365614382293

Epoch: 6| Step: 12
Training loss: 2.028018905145232
Validation loss: 2.4722639579202768

Epoch: 6| Step: 13
Training loss: 2.8014395351199544
Validation loss: 2.451254583131097

Epoch: 143| Step: 0
Training loss: 2.520573458136328
Validation loss: 2.4679984063257216

Epoch: 6| Step: 1
Training loss: 2.8254552221224882
Validation loss: 2.4682535243692283

Epoch: 6| Step: 2
Training loss: 2.8730568331319604
Validation loss: 2.4520082138685226

Epoch: 6| Step: 3
Training loss: 2.885049918286659
Validation loss: 2.465826774563521

Epoch: 6| Step: 4
Training loss: 2.6319216344466194
Validation loss: 2.4642799244425

Epoch: 6| Step: 5
Training loss: 2.207786444357044
Validation loss: 2.4593714499538835

Epoch: 6| Step: 6
Training loss: 2.4209177401912996
Validation loss: 2.4582212201647704

Epoch: 6| Step: 7
Training loss: 2.535542463088087
Validation loss: 2.458972384479387

Epoch: 6| Step: 8
Training loss: 2.185365125583526
Validation loss: 2.464020847120898

Epoch: 6| Step: 9
Training loss: 2.156512147752036
Validation loss: 2.4611845992430363

Epoch: 6| Step: 10
Training loss: 2.6254208545281106
Validation loss: 2.459966849592191

Epoch: 6| Step: 11
Training loss: 2.1261959076672032
Validation loss: 2.463496303879985

Epoch: 6| Step: 12
Training loss: 2.6356633087261603
Validation loss: 2.4638395283956247

Epoch: 6| Step: 13
Training loss: 2.09446965845223
Validation loss: 2.4601631682124925

Epoch: 144| Step: 0
Training loss: 1.791136360050968
Validation loss: 2.4588272573761056

Epoch: 6| Step: 1
Training loss: 1.968379515650642
Validation loss: 2.4612869902608527

Epoch: 6| Step: 2
Training loss: 2.508611724038302
Validation loss: 2.463198669514096

Epoch: 6| Step: 3
Training loss: 2.130243675728426
Validation loss: 2.46386307494145

Epoch: 6| Step: 4
Training loss: 2.7615879572823467
Validation loss: 2.4544402077456353

Epoch: 6| Step: 5
Training loss: 2.484768242573
Validation loss: 2.45711299273068

Epoch: 6| Step: 6
Training loss: 2.978779605361379
Validation loss: 2.4701414573050027

Epoch: 6| Step: 7
Training loss: 2.644249048770064
Validation loss: 2.471491325814405

Epoch: 6| Step: 8
Training loss: 2.996199743989674
Validation loss: 2.4605208594224752

Epoch: 6| Step: 9
Training loss: 2.8165284023169996
Validation loss: 2.47492163659315

Epoch: 6| Step: 10
Training loss: 2.5184444005454867
Validation loss: 2.4728320372148866

Epoch: 6| Step: 11
Training loss: 2.0724737438568024
Validation loss: 2.461355991202753

Epoch: 6| Step: 12
Training loss: 2.5726156843771233
Validation loss: 2.4635178052030247

Epoch: 6| Step: 13
Training loss: 2.262658116837943
Validation loss: 2.4621657762740394

Epoch: 145| Step: 0
Training loss: 2.907422229254815
Validation loss: 2.4586921096034895

Epoch: 6| Step: 1
Training loss: 2.673395270900863
Validation loss: 2.4638056435535947

Epoch: 6| Step: 2
Training loss: 2.609962260240161
Validation loss: 2.462122604574241

Epoch: 6| Step: 3
Training loss: 2.3189025088433577
Validation loss: 2.4620640512424634

Epoch: 6| Step: 4
Training loss: 2.508481705883063
Validation loss: 2.4605164182782238

Epoch: 6| Step: 5
Training loss: 2.392675878902262
Validation loss: 2.4649046715544336

Epoch: 6| Step: 6
Training loss: 2.610099646175193
Validation loss: 2.466324495948906

Epoch: 6| Step: 7
Training loss: 2.0555473820062753
Validation loss: 2.4612442229128706

Epoch: 6| Step: 8
Training loss: 2.6475470292162178
Validation loss: 2.4645708822761887

Epoch: 6| Step: 9
Training loss: 2.9529192817525334
Validation loss: 2.4595878654368

Epoch: 6| Step: 10
Training loss: 2.795499324792362
Validation loss: 2.45729718490009

Epoch: 6| Step: 11
Training loss: 2.0923721562462005
Validation loss: 2.460661033965328

Epoch: 6| Step: 12
Training loss: 2.38646760359026
Validation loss: 2.464295339861724

Epoch: 6| Step: 13
Training loss: 1.5156983033376803
Validation loss: 2.468290197633883

Epoch: 146| Step: 0
Training loss: 2.6347182080842617
Validation loss: 2.4813683668164552

Epoch: 6| Step: 1
Training loss: 2.6739966462712736
Validation loss: 2.485959537391641

Epoch: 6| Step: 2
Training loss: 2.53966911698855
Validation loss: 2.4763324522399497

Epoch: 6| Step: 3
Training loss: 2.0538161137921915
Validation loss: 2.463456817090529

Epoch: 6| Step: 4
Training loss: 3.100205746867875
Validation loss: 2.466432618515875

Epoch: 6| Step: 5
Training loss: 1.837382750111447
Validation loss: 2.467115593559544

Epoch: 6| Step: 6
Training loss: 2.8771337800756065
Validation loss: 2.460219311746343

Epoch: 6| Step: 7
Training loss: 2.529061866947775
Validation loss: 2.4554091346487534

Epoch: 6| Step: 8
Training loss: 2.2484626816326263
Validation loss: 2.45342375926422

Epoch: 6| Step: 9
Training loss: 2.250077988014735
Validation loss: 2.4579629834623398

Epoch: 6| Step: 10
Training loss: 2.811834807675717
Validation loss: 2.454883245008349

Epoch: 6| Step: 11
Training loss: 2.1806505051638574
Validation loss: 2.451414536500162

Epoch: 6| Step: 12
Training loss: 2.7123780394528803
Validation loss: 2.4569418951059294

Epoch: 6| Step: 13
Training loss: 2.103108344500995
Validation loss: 2.4525077026951356

Epoch: 147| Step: 0
Training loss: 2.1119156971781106
Validation loss: 2.456455415932057

Epoch: 6| Step: 1
Training loss: 2.543094754942723
Validation loss: 2.4495279622934403

Epoch: 6| Step: 2
Training loss: 1.720866962994043
Validation loss: 2.4563978598808296

Epoch: 6| Step: 3
Training loss: 2.5127176105148883
Validation loss: 2.4526893569064008

Epoch: 6| Step: 4
Training loss: 2.2689153521683387
Validation loss: 2.4586379837664833

Epoch: 6| Step: 5
Training loss: 2.8435767823167977
Validation loss: 2.4495125674945206

Epoch: 6| Step: 6
Training loss: 2.008837011763658
Validation loss: 2.4539812055716292

Epoch: 6| Step: 7
Training loss: 2.393472608624311
Validation loss: 2.459583842657511

Epoch: 6| Step: 8
Training loss: 2.6999897497477052
Validation loss: 2.454133622141865

Epoch: 6| Step: 9
Training loss: 2.9395197965341735
Validation loss: 2.455967966701261

Epoch: 6| Step: 10
Training loss: 2.5970175510029354
Validation loss: 2.4581274549839107

Epoch: 6| Step: 11
Training loss: 2.87294712580707
Validation loss: 2.4525522344965167

Epoch: 6| Step: 12
Training loss: 2.9425727385392255
Validation loss: 2.4614156430083645

Epoch: 6| Step: 13
Training loss: 1.885459210950273
Validation loss: 2.4707886772773473

Epoch: 148| Step: 0
Training loss: 2.6695707323271023
Validation loss: 2.4773208147132326

Epoch: 6| Step: 1
Training loss: 2.23170044356585
Validation loss: 2.4723444335771974

Epoch: 6| Step: 2
Training loss: 2.0813525383694733
Validation loss: 2.4879656900501543

Epoch: 6| Step: 3
Training loss: 2.2965963804492033
Validation loss: 2.5032500757661675

Epoch: 6| Step: 4
Training loss: 1.8981053568075146
Validation loss: 2.5133979606625

Epoch: 6| Step: 5
Training loss: 2.9443401482142364
Validation loss: 2.4947751601488743

Epoch: 6| Step: 6
Training loss: 2.5153877667703677
Validation loss: 2.495577046817097

Epoch: 6| Step: 7
Training loss: 2.494577630935284
Validation loss: 2.4917405703332287

Epoch: 6| Step: 8
Training loss: 1.9118264975853605
Validation loss: 2.4791212531880378

Epoch: 6| Step: 9
Training loss: 2.6249707538247087
Validation loss: 2.464733832679834

Epoch: 6| Step: 10
Training loss: 2.589093452042986
Validation loss: 2.4575781686043934

Epoch: 6| Step: 11
Training loss: 2.4056599872093436
Validation loss: 2.4574212359628334

Epoch: 6| Step: 12
Training loss: 3.2088848151970413
Validation loss: 2.4564119093111745

Epoch: 6| Step: 13
Training loss: 2.5856999867321653
Validation loss: 2.4620350484287523

Epoch: 149| Step: 0
Training loss: 2.914040736712884
Validation loss: 2.463498029799564

Epoch: 6| Step: 1
Training loss: 2.8800743766293593
Validation loss: 2.4630843229305923

Epoch: 6| Step: 2
Training loss: 2.6087458417390477
Validation loss: 2.471744234570356

Epoch: 6| Step: 3
Training loss: 2.0699146968200925
Validation loss: 2.4727793457503173

Epoch: 6| Step: 4
Training loss: 2.5664319831103812
Validation loss: 2.4740667754382035

Epoch: 6| Step: 5
Training loss: 2.837062475947902
Validation loss: 2.467779073242064

Epoch: 6| Step: 6
Training loss: 1.8141561373941126
Validation loss: 2.468414058442799

Epoch: 6| Step: 7
Training loss: 2.6531846254296383
Validation loss: 2.458466838724483

Epoch: 6| Step: 8
Training loss: 2.343969919695224
Validation loss: 2.448475393826906

Epoch: 6| Step: 9
Training loss: 2.348257384560011
Validation loss: 2.437019789905363

Epoch: 6| Step: 10
Training loss: 2.3857634735094724
Validation loss: 2.458611316373699

Epoch: 6| Step: 11
Training loss: 2.4233422541639986
Validation loss: 2.4496411411060977

Epoch: 6| Step: 12
Training loss: 2.5774712860846423
Validation loss: 2.453687728840497

Epoch: 6| Step: 13
Training loss: 2.445011108154776
Validation loss: 2.469474171203417

Epoch: 150| Step: 0
Training loss: 2.5551251611082035
Validation loss: 2.456031729437307

Epoch: 6| Step: 1
Training loss: 2.6709651178548026
Validation loss: 2.474697546026687

Epoch: 6| Step: 2
Training loss: 2.3384260617733066
Validation loss: 2.4748656901127566

Epoch: 6| Step: 3
Training loss: 2.9241676515664716
Validation loss: 2.4864410830217514

Epoch: 6| Step: 4
Training loss: 2.394113227238099
Validation loss: 2.478781555354536

Epoch: 6| Step: 5
Training loss: 2.42901484264175
Validation loss: 2.4617485042167297

Epoch: 6| Step: 6
Training loss: 2.319210831329802
Validation loss: 2.472656780321206

Epoch: 6| Step: 7
Training loss: 2.279500421034098
Validation loss: 2.462648650586592

Epoch: 6| Step: 8
Training loss: 1.7074510420431155
Validation loss: 2.457809624141782

Epoch: 6| Step: 9
Training loss: 2.105836967019299
Validation loss: 2.454171429312661

Epoch: 6| Step: 10
Training loss: 2.5531229717195223
Validation loss: 2.4503819219855396

Epoch: 6| Step: 11
Training loss: 2.728422213834769
Validation loss: 2.455608188296188

Epoch: 6| Step: 12
Training loss: 2.8243088239601852
Validation loss: 2.4602392992458126

Epoch: 6| Step: 13
Training loss: 2.6711413173674305
Validation loss: 2.4572567737706037

Testing loss: 1.9876497014063654
