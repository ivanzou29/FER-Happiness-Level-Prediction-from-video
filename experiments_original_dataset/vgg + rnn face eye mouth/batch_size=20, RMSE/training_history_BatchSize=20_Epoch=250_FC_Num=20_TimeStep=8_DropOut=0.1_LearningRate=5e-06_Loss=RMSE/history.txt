Epoch: 1| Step: 0
Training loss: 6.831105993485848
Validation loss: 5.869304906457495

Epoch: 5| Step: 1
Training loss: 6.210539491964446
Validation loss: 5.866644795694909

Epoch: 5| Step: 2
Training loss: 5.937048322663757
Validation loss: 5.864097584132345

Epoch: 5| Step: 3
Training loss: 6.239949805228993
Validation loss: 5.861455705595899

Epoch: 5| Step: 4
Training loss: 6.266153137322839
Validation loss: 5.858878871682403

Epoch: 5| Step: 5
Training loss: 6.108701234626373
Validation loss: 5.856485425735282

Epoch: 5| Step: 6
Training loss: 5.952058311074223
Validation loss: 5.853871886772202

Epoch: 5| Step: 7
Training loss: 4.998232338294045
Validation loss: 5.851344744132505

Epoch: 5| Step: 8
Training loss: 5.697592698766309
Validation loss: 5.8486357339794495

Epoch: 5| Step: 9
Training loss: 5.087167055074979
Validation loss: 5.846076712931226

Epoch: 5| Step: 10
Training loss: 5.98016958653276
Validation loss: 5.843258243752187

Epoch: 5| Step: 11
Training loss: 6.785686957512229
Validation loss: 5.840442966096165

Epoch: 2| Step: 0
Training loss: 4.445474685365181
Validation loss: 5.83742337118712

Epoch: 5| Step: 1
Training loss: 6.010192479052057
Validation loss: 5.834467085152653

Epoch: 5| Step: 2
Training loss: 6.241377108299723
Validation loss: 5.831045371905154

Epoch: 5| Step: 3
Training loss: 6.217539607199124
Validation loss: 5.827743695069225

Epoch: 5| Step: 4
Training loss: 6.402108393515703
Validation loss: 5.824288715545255

Epoch: 5| Step: 5
Training loss: 6.399137987258945
Validation loss: 5.820586776244704

Epoch: 5| Step: 6
Training loss: 5.304831681237376
Validation loss: 5.816625908196006

Epoch: 5| Step: 7
Training loss: 6.313431170684658
Validation loss: 5.812725801081271

Epoch: 5| Step: 8
Training loss: 5.744202386186162
Validation loss: 5.808409081854024

Epoch: 5| Step: 9
Training loss: 6.668735596374001
Validation loss: 5.80393758030975

Epoch: 5| Step: 10
Training loss: 5.003123070968456
Validation loss: 5.7993978201464484

Epoch: 5| Step: 11
Training loss: 6.601914399829475
Validation loss: 5.794550022442686

Epoch: 3| Step: 0
Training loss: 5.691954157630607
Validation loss: 5.789882085375828

Epoch: 5| Step: 1
Training loss: 5.576657227673308
Validation loss: 5.7849286584348425

Epoch: 5| Step: 2
Training loss: 6.886873292189699
Validation loss: 5.779251413015047

Epoch: 5| Step: 3
Training loss: 5.746432980936481
Validation loss: 5.773898507632467

Epoch: 5| Step: 4
Training loss: 6.342044995819874
Validation loss: 5.768485561439079

Epoch: 5| Step: 5
Training loss: 5.198246131908376
Validation loss: 5.762180419357012

Epoch: 5| Step: 6
Training loss: 5.66604322856082
Validation loss: 5.756108653445166

Epoch: 5| Step: 7
Training loss: 6.162165708934257
Validation loss: 5.749867099110648

Epoch: 5| Step: 8
Training loss: 5.895578583334751
Validation loss: 5.743232573128852

Epoch: 5| Step: 9
Training loss: 5.023999979140652
Validation loss: 5.736843184286526

Epoch: 5| Step: 10
Training loss: 6.300543007836985
Validation loss: 5.729646318182085

Epoch: 5| Step: 11
Training loss: 5.419959705667522
Validation loss: 5.722927492416395

Epoch: 4| Step: 0
Training loss: 6.14840554758613
Validation loss: 5.715938912529952

Epoch: 5| Step: 1
Training loss: 5.251405073789627
Validation loss: 5.7084952932432325

Epoch: 5| Step: 2
Training loss: 6.560798642459948
Validation loss: 5.7014250220474

Epoch: 5| Step: 3
Training loss: 5.620591534201354
Validation loss: 5.693814408977518

Epoch: 5| Step: 4
Training loss: 5.449305904880979
Validation loss: 5.6861438811256075

Epoch: 5| Step: 5
Training loss: 5.779188953770149
Validation loss: 5.678690938785902

Epoch: 5| Step: 6
Training loss: 6.460925101068816
Validation loss: 5.671086441303691

Epoch: 5| Step: 7
Training loss: 5.789228552780425
Validation loss: 5.663713690880539

Epoch: 5| Step: 8
Training loss: 4.876494349792142
Validation loss: 5.655953942238158

Epoch: 5| Step: 9
Training loss: 6.125980843618981
Validation loss: 5.64832211873883

Epoch: 5| Step: 10
Training loss: 5.624818587026865
Validation loss: 5.640564535139208

Epoch: 5| Step: 11
Training loss: 4.892729382641919
Validation loss: 5.632944445006012

Epoch: 5| Step: 0
Training loss: 4.635102244939686
Validation loss: 5.625657756636452

Epoch: 5| Step: 1
Training loss: 5.739371718736301
Validation loss: 5.618377997983647

Epoch: 5| Step: 2
Training loss: 6.890082997568237
Validation loss: 5.610744468536322

Epoch: 5| Step: 3
Training loss: 5.44489268103453
Validation loss: 5.60343088285612

Epoch: 5| Step: 4
Training loss: 5.651970862246686
Validation loss: 5.596542407302279

Epoch: 5| Step: 5
Training loss: 5.557623794007451
Validation loss: 5.58937309268801

Epoch: 5| Step: 6
Training loss: 5.0206281480241515
Validation loss: 5.582411471694344

Epoch: 5| Step: 7
Training loss: 5.74236852658953
Validation loss: 5.575371533716661

Epoch: 5| Step: 8
Training loss: 6.1372666821542685
Validation loss: 5.568350690346302

Epoch: 5| Step: 9
Training loss: 6.133543323294494
Validation loss: 5.561493414623931

Epoch: 5| Step: 10
Training loss: 5.234999889821923
Validation loss: 5.554599609251955

Epoch: 5| Step: 11
Training loss: 6.92854184353654
Validation loss: 5.548002316535626

Epoch: 6| Step: 0
Training loss: 5.803914281757634
Validation loss: 5.541144054790357

Epoch: 5| Step: 1
Training loss: 5.366671474920611
Validation loss: 5.534314802557896

Epoch: 5| Step: 2
Training loss: 5.303798056013231
Validation loss: 5.5276889221466305

Epoch: 5| Step: 3
Training loss: 6.022400683909914
Validation loss: 5.521214571571352

Epoch: 5| Step: 4
Training loss: 5.737337516528416
Validation loss: 5.514565392169463

Epoch: 5| Step: 5
Training loss: 5.47614124544496
Validation loss: 5.508711887092453

Epoch: 5| Step: 6
Training loss: 5.489969991522039
Validation loss: 5.5021388851174615

Epoch: 5| Step: 7
Training loss: 6.515108010252317
Validation loss: 5.496005153597137

Epoch: 5| Step: 8
Training loss: 5.452260295875865
Validation loss: 5.489488563467544

Epoch: 5| Step: 9
Training loss: 5.018573595417047
Validation loss: 5.483081146961184

Epoch: 5| Step: 10
Training loss: 5.556197635845858
Validation loss: 5.4769288728200305

Epoch: 5| Step: 11
Training loss: 5.735730252721306
Validation loss: 5.470499438255437

Epoch: 7| Step: 0
Training loss: 6.237765735783263
Validation loss: 5.463810591962808

Epoch: 5| Step: 1
Training loss: 5.995765781441784
Validation loss: 5.457306643986875

Epoch: 5| Step: 2
Training loss: 5.673816023007747
Validation loss: 5.450464206139551

Epoch: 5| Step: 3
Training loss: 4.932147637922615
Validation loss: 5.444067478375095

Epoch: 5| Step: 4
Training loss: 5.394884809195855
Validation loss: 5.438238619919658

Epoch: 5| Step: 5
Training loss: 5.959780999582811
Validation loss: 5.432564633156559

Epoch: 5| Step: 6
Training loss: 5.550013210521475
Validation loss: 5.426704776713671

Epoch: 5| Step: 7
Training loss: 5.5794443659179045
Validation loss: 5.420811368334303

Epoch: 5| Step: 8
Training loss: 5.178259651307322
Validation loss: 5.415391312135989

Epoch: 5| Step: 9
Training loss: 5.274593695590633
Validation loss: 5.409610314028541

Epoch: 5| Step: 10
Training loss: 5.525436708616148
Validation loss: 5.404034360836146

Epoch: 5| Step: 11
Training loss: 3.600648048140383
Validation loss: 5.3984182811050845

Epoch: 8| Step: 0
Training loss: 5.142298834634905
Validation loss: 5.3929362479224325

Epoch: 5| Step: 1
Training loss: 5.781161910752031
Validation loss: 5.3879738743098375

Epoch: 5| Step: 2
Training loss: 6.091361335724821
Validation loss: 5.3825993894811095

Epoch: 5| Step: 3
Training loss: 6.34753665752726
Validation loss: 5.377714853941035

Epoch: 5| Step: 4
Training loss: 4.715243824290507
Validation loss: 5.372230940220748

Epoch: 5| Step: 5
Training loss: 5.256719739247298
Validation loss: 5.367282731471352

Epoch: 5| Step: 6
Training loss: 5.553478168340572
Validation loss: 5.362114527733597

Epoch: 5| Step: 7
Training loss: 5.716384815500678
Validation loss: 5.356734415863033

Epoch: 5| Step: 8
Training loss: 4.792925373555759
Validation loss: 5.351252199258807

Epoch: 5| Step: 9
Training loss: 5.452552218810246
Validation loss: 5.345602521227292

Epoch: 5| Step: 10
Training loss: 5.323688169981518
Validation loss: 5.339637378424573

Epoch: 5| Step: 11
Training loss: 5.3783459562033915
Validation loss: 5.334141895971882

Epoch: 9| Step: 0
Training loss: 5.048544970601968
Validation loss: 5.328306543682401

Epoch: 5| Step: 1
Training loss: 5.191283718985217
Validation loss: 5.322264281106482

Epoch: 5| Step: 2
Training loss: 5.4139656179327735
Validation loss: 5.316517713108438

Epoch: 5| Step: 3
Training loss: 5.618402638799566
Validation loss: 5.310673590463953

Epoch: 5| Step: 4
Training loss: 5.55690715666792
Validation loss: 5.304428873326052

Epoch: 5| Step: 5
Training loss: 5.8371433712747205
Validation loss: 5.2986633297652626

Epoch: 5| Step: 6
Training loss: 5.983091371083709
Validation loss: 5.292546914946392

Epoch: 5| Step: 7
Training loss: 4.8620496055868765
Validation loss: 5.286084514862166

Epoch: 5| Step: 8
Training loss: 5.3415376422473075
Validation loss: 5.280097843272667

Epoch: 5| Step: 9
Training loss: 5.288880202787588
Validation loss: 5.274088049427388

Epoch: 5| Step: 10
Training loss: 5.517522987832915
Validation loss: 5.268051848457888

Epoch: 5| Step: 11
Training loss: 4.70669653244557
Validation loss: 5.261962144900865

Epoch: 10| Step: 0
Training loss: 5.425566985566409
Validation loss: 5.25538805328849

Epoch: 5| Step: 1
Training loss: 6.004148320795005
Validation loss: 5.24925948021839

Epoch: 5| Step: 2
Training loss: 5.213036979258745
Validation loss: 5.243082742290733

Epoch: 5| Step: 3
Training loss: 4.666030749635387
Validation loss: 5.236579552238892

Epoch: 5| Step: 4
Training loss: 5.096227873996725
Validation loss: 5.230403308112397

Epoch: 5| Step: 5
Training loss: 5.3841407587659775
Validation loss: 5.224841349077655

Epoch: 5| Step: 6
Training loss: 5.271954001404026
Validation loss: 5.2191710616329825

Epoch: 5| Step: 7
Training loss: 4.78278281381162
Validation loss: 5.213334782243285

Epoch: 5| Step: 8
Training loss: 5.545153197501819
Validation loss: 5.208051157619037

Epoch: 5| Step: 9
Training loss: 5.126733068194077
Validation loss: 5.2021817334632905

Epoch: 5| Step: 10
Training loss: 6.1706146112178955
Validation loss: 5.196881363788928

Epoch: 5| Step: 11
Training loss: 5.0882872326225765
Validation loss: 5.190558554484159

Epoch: 11| Step: 0
Training loss: 4.681997706514145
Validation loss: 5.184924669886484

Epoch: 5| Step: 1
Training loss: 5.607552489988704
Validation loss: 5.179849145514085

Epoch: 5| Step: 2
Training loss: 5.297037757916122
Validation loss: 5.174442487592115

Epoch: 5| Step: 3
Training loss: 5.116846996364471
Validation loss: 5.168785224865251

Epoch: 5| Step: 4
Training loss: 4.982846782156096
Validation loss: 5.162795380277126

Epoch: 5| Step: 5
Training loss: 5.017704327675228
Validation loss: 5.157055161930259

Epoch: 5| Step: 6
Training loss: 5.6406862038966565
Validation loss: 5.15140318750997

Epoch: 5| Step: 7
Training loss: 5.404664088140876
Validation loss: 5.1458202032418505

Epoch: 5| Step: 8
Training loss: 4.6877551200105945
Validation loss: 5.139754912573165

Epoch: 5| Step: 9
Training loss: 5.984176751978987
Validation loss: 5.134388666643623

Epoch: 5| Step: 10
Training loss: 5.605249104200597
Validation loss: 5.128774067438505

Epoch: 5| Step: 11
Training loss: 4.69976909963072
Validation loss: 5.123740770353833

Epoch: 12| Step: 0
Training loss: 6.096625173075393
Validation loss: 5.117497294514855

Epoch: 5| Step: 1
Training loss: 4.117220391679575
Validation loss: 5.112015884534427

Epoch: 5| Step: 2
Training loss: 4.747248806527745
Validation loss: 5.106521719679906

Epoch: 5| Step: 3
Training loss: 4.757305149532306
Validation loss: 5.101074226539816

Epoch: 5| Step: 4
Training loss: 4.749774726745889
Validation loss: 5.095582035800163

Epoch: 5| Step: 5
Training loss: 4.660890251224541
Validation loss: 5.089660531935564

Epoch: 5| Step: 6
Training loss: 5.901185139738186
Validation loss: 5.084774909912504

Epoch: 5| Step: 7
Training loss: 5.578114400046826
Validation loss: 5.078984051937675

Epoch: 5| Step: 8
Training loss: 4.876366448242875
Validation loss: 5.072883976616256

Epoch: 5| Step: 9
Training loss: 5.927983095585122
Validation loss: 5.066989117116003

Epoch: 5| Step: 10
Training loss: 5.666414517047258
Validation loss: 5.061510633015369

Epoch: 5| Step: 11
Training loss: 4.35799197336537
Validation loss: 5.055453580950386

Epoch: 13| Step: 0
Training loss: 5.389825291677337
Validation loss: 5.049535123119263

Epoch: 5| Step: 1
Training loss: 5.490290133621608
Validation loss: 5.043616495803919

Epoch: 5| Step: 2
Training loss: 5.617273406962176
Validation loss: 5.037274649212258

Epoch: 5| Step: 3
Training loss: 4.076324884077185
Validation loss: 5.031351392525952

Epoch: 5| Step: 4
Training loss: 5.485022873391766
Validation loss: 5.025010135191254

Epoch: 5| Step: 5
Training loss: 5.685477431622457
Validation loss: 5.020039549743971

Epoch: 5| Step: 6
Training loss: 5.358691291460793
Validation loss: 5.013608113026957

Epoch: 5| Step: 7
Training loss: 5.272383068772313
Validation loss: 5.007704163806281

Epoch: 5| Step: 8
Training loss: 4.650240508391869
Validation loss: 5.001102643818865

Epoch: 5| Step: 9
Training loss: 4.363685800893655
Validation loss: 4.995853294012405

Epoch: 5| Step: 10
Training loss: 4.868422937731968
Validation loss: 4.990907046175561

Epoch: 5| Step: 11
Training loss: 5.413782770325878
Validation loss: 4.984900954030025

Epoch: 14| Step: 0
Training loss: 5.366558099126369
Validation loss: 4.978487505807805

Epoch: 5| Step: 1
Training loss: 5.6111092184502125
Validation loss: 4.972286661122403

Epoch: 5| Step: 2
Training loss: 5.66145144558382
Validation loss: 4.966912207625096

Epoch: 5| Step: 3
Training loss: 4.34600749460795
Validation loss: 4.959941573811529

Epoch: 5| Step: 4
Training loss: 4.7528896576994715
Validation loss: 4.955569814130249

Epoch: 5| Step: 5
Training loss: 4.830588493115444
Validation loss: 4.9491023787878

Epoch: 5| Step: 6
Training loss: 4.567308791928796
Validation loss: 4.943835680283849

Epoch: 5| Step: 7
Training loss: 5.274587909818947
Validation loss: 4.937980234154713

Epoch: 5| Step: 8
Training loss: 5.503382596296636
Validation loss: 4.9317405524374855

Epoch: 5| Step: 9
Training loss: 5.000940806568867
Validation loss: 4.926680980596195

Epoch: 5| Step: 10
Training loss: 4.566080230221896
Validation loss: 4.920875068291611

Epoch: 5| Step: 11
Training loss: 5.678413930458487
Validation loss: 4.915567156594237

Epoch: 15| Step: 0
Training loss: 5.296837190476229
Validation loss: 4.910661686041719

Epoch: 5| Step: 1
Training loss: 4.961495724006617
Validation loss: 4.904707040349821

Epoch: 5| Step: 2
Training loss: 4.55064733742082
Validation loss: 4.899186567337583

Epoch: 5| Step: 3
Training loss: 4.983557176612742
Validation loss: 4.892915183390349

Epoch: 5| Step: 4
Training loss: 5.10546875
Validation loss: 4.887290166983118

Epoch: 5| Step: 5
Training loss: 4.741780849661939
Validation loss: 4.880788048748025

Epoch: 5| Step: 6
Training loss: 5.71128215871746
Validation loss: 4.876504087317269

Epoch: 5| Step: 7
Training loss: 5.441713301189594
Validation loss: 4.870572573902076

Epoch: 5| Step: 8
Training loss: 4.1151231371415715
Validation loss: 4.86526702008244

Epoch: 5| Step: 9
Training loss: 4.99167741488837
Validation loss: 4.859768686977616

Epoch: 5| Step: 10
Training loss: 4.9167492530912575
Validation loss: 4.854903474916135

Epoch: 5| Step: 11
Training loss: 5.355679230341428
Validation loss: 4.8493429974473745

Epoch: 16| Step: 0
Training loss: 5.547587776056963
Validation loss: 4.843229885274244

Epoch: 5| Step: 1
Training loss: 5.203484233563634
Validation loss: 4.8377992151398015

Epoch: 5| Step: 2
Training loss: 4.183172466533699
Validation loss: 4.832265401567227

Epoch: 5| Step: 3
Training loss: 4.6567826958420495
Validation loss: 4.826589823808405

Epoch: 5| Step: 4
Training loss: 4.942327915528205
Validation loss: 4.821224437576954

Epoch: 5| Step: 5
Training loss: 4.830323937651736
Validation loss: 4.816008721307819

Epoch: 5| Step: 6
Training loss: 4.810555597840244
Validation loss: 4.810569037261064

Epoch: 5| Step: 7
Training loss: 4.822896848875432
Validation loss: 4.805235255168941

Epoch: 5| Step: 8
Training loss: 5.356934461627459
Validation loss: 4.800089973361448

Epoch: 5| Step: 9
Training loss: 4.254067662226905
Validation loss: 4.795044780743527

Epoch: 5| Step: 10
Training loss: 5.630642752130881
Validation loss: 4.789276508239685

Epoch: 5| Step: 11
Training loss: 4.372629449846404
Validation loss: 4.783559137701246

Epoch: 17| Step: 0
Training loss: 4.498382065574882
Validation loss: 4.777371489391543

Epoch: 5| Step: 1
Training loss: 4.736815173089276
Validation loss: 4.772936530913443

Epoch: 5| Step: 2
Training loss: 4.932994670240986
Validation loss: 4.767908826894509

Epoch: 5| Step: 3
Training loss: 5.307634167262398
Validation loss: 4.762035806816858

Epoch: 5| Step: 4
Training loss: 4.582358424220801
Validation loss: 4.7578396851212394

Epoch: 5| Step: 5
Training loss: 5.301996236609149
Validation loss: 4.7518207256176686

Epoch: 5| Step: 6
Training loss: 4.513202373759004
Validation loss: 4.746141368067181

Epoch: 5| Step: 7
Training loss: 4.680358940444778
Validation loss: 4.741786271560637

Epoch: 5| Step: 8
Training loss: 5.050856398682051
Validation loss: 4.73591786708473

Epoch: 5| Step: 9
Training loss: 5.147798211980964
Validation loss: 4.730823515092908

Epoch: 5| Step: 10
Training loss: 4.804666261703568
Validation loss: 4.7255115107696595

Epoch: 5| Step: 11
Training loss: 4.92302581412122
Validation loss: 4.719671609912368

Epoch: 18| Step: 0
Training loss: 4.82724909568453
Validation loss: 4.713989458539245

Epoch: 5| Step: 1
Training loss: 5.013798936839484
Validation loss: 4.709544450849744

Epoch: 5| Step: 2
Training loss: 4.393657031099901
Validation loss: 4.703473565079075

Epoch: 5| Step: 3
Training loss: 5.194259835202288
Validation loss: 4.6975325901781595

Epoch: 5| Step: 4
Training loss: 4.34446282335466
Validation loss: 4.692670335802813

Epoch: 5| Step: 5
Training loss: 4.622656563582675
Validation loss: 4.687571385157941

Epoch: 5| Step: 6
Training loss: 5.113920750272092
Validation loss: 4.682418535810066

Epoch: 5| Step: 7
Training loss: 4.887374041170836
Validation loss: 4.677568417593647

Epoch: 5| Step: 8
Training loss: 4.790650544717446
Validation loss: 4.6725449522933635

Epoch: 5| Step: 9
Training loss: 5.017316586459316
Validation loss: 4.666981970262409

Epoch: 5| Step: 10
Training loss: 4.96728532424217
Validation loss: 4.661758705847177

Epoch: 5| Step: 11
Training loss: 3.009453343275819
Validation loss: 4.655987333189829

Epoch: 19| Step: 0
Training loss: 5.282307716404925
Validation loss: 4.6513565002485215

Epoch: 5| Step: 1
Training loss: 5.3012797627943655
Validation loss: 4.646275343916065

Epoch: 5| Step: 2
Training loss: 4.77189848668602
Validation loss: 4.640699589362131

Epoch: 5| Step: 3
Training loss: 4.268407787272925
Validation loss: 4.636182411752314

Epoch: 5| Step: 4
Training loss: 5.228739605774057
Validation loss: 4.630133426204803

Epoch: 5| Step: 5
Training loss: 5.395154382513741
Validation loss: 4.625854018122797

Epoch: 5| Step: 6
Training loss: 5.542910596395965
Validation loss: 4.620121255648551

Epoch: 5| Step: 7
Training loss: 4.396803665938092
Validation loss: 4.614657074946881

Epoch: 5| Step: 8
Training loss: 3.3579828260844815
Validation loss: 4.608678271552224

Epoch: 5| Step: 9
Training loss: 4.53389983470981
Validation loss: 4.604905952317488

Epoch: 5| Step: 10
Training loss: 3.7796940400160453
Validation loss: 4.600999548370001

Epoch: 5| Step: 11
Training loss: 4.282597907395204
Validation loss: 4.59478147002981

Epoch: 20| Step: 0
Training loss: 4.5237225325784305
Validation loss: 4.589632269133352

Epoch: 5| Step: 1
Training loss: 4.418608088824687
Validation loss: 4.585602357609261

Epoch: 5| Step: 2
Training loss: 5.256533417562023
Validation loss: 4.5804092818907725

Epoch: 5| Step: 3
Training loss: 4.121538964398929
Validation loss: 4.574464260932514

Epoch: 5| Step: 4
Training loss: 4.964762305095154
Validation loss: 4.571857775857587

Epoch: 5| Step: 5
Training loss: 4.627403459577516
Validation loss: 4.566463812733654

Epoch: 5| Step: 6
Training loss: 5.265858268664669
Validation loss: 4.561480595523542

Epoch: 5| Step: 7
Training loss: 4.888498837391568
Validation loss: 4.5553297982580165

Epoch: 5| Step: 8
Training loss: 3.592448388606952
Validation loss: 4.549737044830018

Epoch: 5| Step: 9
Training loss: 5.058543601947376
Validation loss: 4.545126619250382

Epoch: 5| Step: 10
Training loss: 4.480529625104107
Validation loss: 4.54121904471295

Epoch: 5| Step: 11
Training loss: 5.436778755147378
Validation loss: 4.535235627427369

Epoch: 21| Step: 0
Training loss: 4.649020118425327
Validation loss: 4.529511067626875

Epoch: 5| Step: 1
Training loss: 4.5506458704380375
Validation loss: 4.5246913931130575

Epoch: 5| Step: 2
Training loss: 3.683514008614621
Validation loss: 4.518864007886074

Epoch: 5| Step: 3
Training loss: 3.3819070004986793
Validation loss: 4.514535523909466

Epoch: 5| Step: 4
Training loss: 3.9127790893853875
Validation loss: 4.509451979563659

Epoch: 5| Step: 5
Training loss: 4.653257496460855
Validation loss: 4.504481036037019

Epoch: 5| Step: 6
Training loss: 5.3799327128573875
Validation loss: 4.500907126583792

Epoch: 5| Step: 7
Training loss: 5.503313800231046
Validation loss: 4.495143963506613

Epoch: 5| Step: 8
Training loss: 4.971427340108033
Validation loss: 4.489706863804447

Epoch: 5| Step: 9
Training loss: 4.589342143468326
Validation loss: 4.485370875418814

Epoch: 5| Step: 10
Training loss: 5.167284631176681
Validation loss: 4.479860862639022

Epoch: 5| Step: 11
Training loss: 4.596073108181273
Validation loss: 4.47516209399359

Epoch: 22| Step: 0
Training loss: 3.703026878891902
Validation loss: 4.470803844761129

Epoch: 5| Step: 1
Training loss: 4.404664965217053
Validation loss: 4.4652567194390524

Epoch: 5| Step: 2
Training loss: 5.122155307177314
Validation loss: 4.459671081251856

Epoch: 5| Step: 3
Training loss: 4.439965865888925
Validation loss: 4.453977964928279

Epoch: 5| Step: 4
Training loss: 4.412416512453252
Validation loss: 4.449138896293639

Epoch: 5| Step: 5
Training loss: 4.394180975623694
Validation loss: 4.445254534995439

Epoch: 5| Step: 6
Training loss: 4.258479914720983
Validation loss: 4.439653030998847

Epoch: 5| Step: 7
Training loss: 4.377758355482191
Validation loss: 4.434338235736305

Epoch: 5| Step: 8
Training loss: 4.634234719908886
Validation loss: 4.429548509178791

Epoch: 5| Step: 9
Training loss: 5.181317241310605
Validation loss: 4.423931250307043

Epoch: 5| Step: 10
Training loss: 5.2005418201749585
Validation loss: 4.4183561614483

Epoch: 5| Step: 11
Training loss: 4.2714084641174255
Validation loss: 4.414073014598465

Epoch: 23| Step: 0
Training loss: 4.218174647905121
Validation loss: 4.4082048106553

Epoch: 5| Step: 1
Training loss: 3.821135449849774
Validation loss: 4.4020803395863055

Epoch: 5| Step: 2
Training loss: 4.879635685313681
Validation loss: 4.398857056035047

Epoch: 5| Step: 3
Training loss: 4.2664626420434235
Validation loss: 4.394591371478207

Epoch: 5| Step: 4
Training loss: 5.133145999380122
Validation loss: 4.388056409863275

Epoch: 5| Step: 5
Training loss: 3.593007682760228
Validation loss: 4.3815219767523335

Epoch: 5| Step: 6
Training loss: 4.460500291553869
Validation loss: 4.378082016328406

Epoch: 5| Step: 7
Training loss: 5.019979232805922
Validation loss: 4.3729210046483455

Epoch: 5| Step: 8
Training loss: 4.632444215902891
Validation loss: 4.366569566314417

Epoch: 5| Step: 9
Training loss: 5.005540067362042
Validation loss: 4.3636356074399965

Epoch: 5| Step: 10
Training loss: 4.4019856480767885
Validation loss: 4.358151386041972

Epoch: 5| Step: 11
Training loss: 4.069944398017508
Validation loss: 4.352094913331521

Epoch: 24| Step: 0
Training loss: 4.311758889911569
Validation loss: 4.346769276111877

Epoch: 5| Step: 1
Training loss: 4.573500448979044
Validation loss: 4.343118022437883

Epoch: 5| Step: 2
Training loss: 3.7795907155230015
Validation loss: 4.337047450874639

Epoch: 5| Step: 3
Training loss: 5.626148360969401
Validation loss: 4.331647061876877

Epoch: 5| Step: 4
Training loss: 3.5493612440097606
Validation loss: 4.325971703530432

Epoch: 5| Step: 5
Training loss: 4.249296242283832
Validation loss: 4.321423038912989

Epoch: 5| Step: 6
Training loss: 4.455220689712572
Validation loss: 4.316039056823966

Epoch: 5| Step: 7
Training loss: 4.768541587985028
Validation loss: 4.3101792564052355

Epoch: 5| Step: 8
Training loss: 5.066008305858696
Validation loss: 4.304636212439764

Epoch: 5| Step: 9
Training loss: 4.381435130258027
Validation loss: 4.29985774695756

Epoch: 5| Step: 10
Training loss: 4.129633295437399
Validation loss: 4.295295674779195

Epoch: 5| Step: 11
Training loss: 2.654156926095796
Validation loss: 4.290472974165384

Epoch: 25| Step: 0
Training loss: 4.359942436888189
Validation loss: 4.285919010290746

Epoch: 5| Step: 1
Training loss: 5.113723817327958
Validation loss: 4.2801524887966185

Epoch: 5| Step: 2
Training loss: 3.6343287431392346
Validation loss: 4.274883729903972

Epoch: 5| Step: 3
Training loss: 4.070481426811884
Validation loss: 4.269215755084868

Epoch: 5| Step: 4
Training loss: 3.8977139399684924
Validation loss: 4.2646828194278985

Epoch: 5| Step: 5
Training loss: 4.599656647846246
Validation loss: 4.260129646886519

Epoch: 5| Step: 6
Training loss: 5.450554621762308
Validation loss: 4.255687292902418

Epoch: 5| Step: 7
Training loss: 4.500582763236361
Validation loss: 4.2497801069332475

Epoch: 5| Step: 8
Training loss: 4.162347665926168
Validation loss: 4.244401137596798

Epoch: 5| Step: 9
Training loss: 4.48613871804408
Validation loss: 4.240461186745069

Epoch: 5| Step: 10
Training loss: 3.4088071970937293
Validation loss: 4.2356793129703325

Epoch: 5| Step: 11
Training loss: 5.318094337295183
Validation loss: 4.2290757252478794

Epoch: 26| Step: 0
Training loss: 4.321918540840078
Validation loss: 4.225006620977507

Epoch: 5| Step: 1
Training loss: 4.899990097347296
Validation loss: 4.23278148457169

Epoch: 5| Step: 2
Training loss: 4.055984906907751
Validation loss: 4.221006374006679

Epoch: 5| Step: 3
Training loss: 4.135645221893095
Validation loss: 4.211961884657917

Epoch: 5| Step: 4
Training loss: 4.245476053995456
Validation loss: 4.206137828833302

Epoch: 5| Step: 5
Training loss: 4.0713615603178726
Validation loss: 4.20225219929423

Epoch: 5| Step: 6
Training loss: 4.251135730458309
Validation loss: 4.19792061072733

Epoch: 5| Step: 7
Training loss: 4.309427023415248
Validation loss: 4.192476409120862

Epoch: 5| Step: 8
Training loss: 4.679677310480351
Validation loss: 4.186323982899496

Epoch: 5| Step: 9
Training loss: 4.5188890955451555
Validation loss: 4.179702064750227

Epoch: 5| Step: 10
Training loss: 4.269889739710175
Validation loss: 4.173716992124613

Epoch: 5| Step: 11
Training loss: 3.386665106219836
Validation loss: 4.167715978420765

Epoch: 27| Step: 0
Training loss: 4.483633797561934
Validation loss: 4.162579499593833

Epoch: 5| Step: 1
Training loss: 4.142461635708931
Validation loss: 4.158978568047625

Epoch: 5| Step: 2
Training loss: 3.5405768718630144
Validation loss: 4.1540560847607155

Epoch: 5| Step: 3
Training loss: 4.422800135803082
Validation loss: 4.149239452408336

Epoch: 5| Step: 4
Training loss: 4.170210717089336
Validation loss: 4.143571230108903

Epoch: 5| Step: 5
Training loss: 4.6541354094946685
Validation loss: 4.13945413985262

Epoch: 5| Step: 6
Training loss: 4.0824001309851745
Validation loss: 4.1350616892064975

Epoch: 5| Step: 7
Training loss: 4.530994487003904
Validation loss: 4.127895138790517

Epoch: 5| Step: 8
Training loss: 4.386407856442061
Validation loss: 4.122621182684196

Epoch: 5| Step: 9
Training loss: 4.2351346056015124
Validation loss: 4.118994724565119

Epoch: 5| Step: 10
Training loss: 4.084260614686183
Validation loss: 4.114195883491802

Epoch: 5| Step: 11
Training loss: 4.857659432645955
Validation loss: 4.108357718178044

Epoch: 28| Step: 0
Training loss: 4.283034349587462
Validation loss: 4.102930084386845

Epoch: 5| Step: 1
Training loss: 4.240372917762004
Validation loss: 4.0983064352029075

Epoch: 5| Step: 2
Training loss: 4.4740087338303915
Validation loss: 4.091732887125844

Epoch: 5| Step: 3
Training loss: 4.509771546119976
Validation loss: 4.087119189925126

Epoch: 5| Step: 4
Training loss: 3.8572805798884873
Validation loss: 4.0817938971377945

Epoch: 5| Step: 5
Training loss: 3.5584074907519034
Validation loss: 4.07631553563686

Epoch: 5| Step: 6
Training loss: 4.022026925822479
Validation loss: 4.071477985520412

Epoch: 5| Step: 7
Training loss: 5.0238139484603845
Validation loss: 4.067301866230409

Epoch: 5| Step: 8
Training loss: 3.765909271273716
Validation loss: 4.061979681097236

Epoch: 5| Step: 9
Training loss: 4.151271965246719
Validation loss: 4.057428965695936

Epoch: 5| Step: 10
Training loss: 4.196003265626871
Validation loss: 4.0512131080960385

Epoch: 5| Step: 11
Training loss: 4.345447236146
Validation loss: 4.046082790998521

Epoch: 29| Step: 0
Training loss: 4.114743283538927
Validation loss: 4.04116316572562

Epoch: 5| Step: 1
Training loss: 4.66017139365205
Validation loss: 4.036332241262866

Epoch: 5| Step: 2
Training loss: 3.891671281331258
Validation loss: 4.031408336398311

Epoch: 5| Step: 3
Training loss: 4.9033445271447
Validation loss: 4.025775178460181

Epoch: 5| Step: 4
Training loss: 4.124375498344298
Validation loss: 4.020325646772459

Epoch: 5| Step: 5
Training loss: 4.594345780747916
Validation loss: 4.015669959740597

Epoch: 5| Step: 6
Training loss: 4.025502210289289
Validation loss: 4.010508398352803

Epoch: 5| Step: 7
Training loss: 4.098606170429552
Validation loss: 4.006007297958364

Epoch: 5| Step: 8
Training loss: 4.205667967296926
Validation loss: 4.000126906209686

Epoch: 5| Step: 9
Training loss: 3.3189321004617716
Validation loss: 3.99425116326196

Epoch: 5| Step: 10
Training loss: 3.45135452659348
Validation loss: 3.9899533335108646

Epoch: 5| Step: 11
Training loss: 4.102463861151694
Validation loss: 3.9850828103061113

Epoch: 30| Step: 0
Training loss: 4.515633025376736
Validation loss: 3.9802920595834075

Epoch: 5| Step: 1
Training loss: 3.158865722903472
Validation loss: 3.9757517479658806

Epoch: 5| Step: 2
Training loss: 4.265554574238345
Validation loss: 3.971167441392376

Epoch: 5| Step: 3
Training loss: 3.91268476348538
Validation loss: 3.96641951693939

Epoch: 5| Step: 4
Training loss: 3.7164480313255366
Validation loss: 3.9616640366377154

Epoch: 5| Step: 5
Training loss: 4.181419170703641
Validation loss: 3.9566810907381105

Epoch: 5| Step: 6
Training loss: 4.037007796103542
Validation loss: 3.953051092690816

Epoch: 5| Step: 7
Training loss: 3.792722087032976
Validation loss: 3.9485872432249622

Epoch: 5| Step: 8
Training loss: 4.661950021169031
Validation loss: 3.9434299925573892

Epoch: 5| Step: 9
Training loss: 3.9051568294590804
Validation loss: 3.9385515958305546

Epoch: 5| Step: 10
Training loss: 4.623246143915178
Validation loss: 3.933835019361714

Epoch: 5| Step: 11
Training loss: 3.9674348829919377
Validation loss: 3.92944676980847

Epoch: 31| Step: 0
Training loss: 4.176039999072391
Validation loss: 3.924347173052751

Epoch: 5| Step: 1
Training loss: 3.7316028728430295
Validation loss: 3.919691437956977

Epoch: 5| Step: 2
Training loss: 3.9535565649588347
Validation loss: 3.9151343719966873

Epoch: 5| Step: 3
Training loss: 3.643269507525867
Validation loss: 3.9106886682565074

Epoch: 5| Step: 4
Training loss: 4.342601157653455
Validation loss: 3.9056084016954

Epoch: 5| Step: 5
Training loss: 4.15775518481787
Validation loss: 3.901231655015382

Epoch: 5| Step: 6
Training loss: 4.047950631138402
Validation loss: 3.8961849750930053

Epoch: 5| Step: 7
Training loss: 4.265962580363375
Validation loss: 3.8922233719757044

Epoch: 5| Step: 8
Training loss: 4.775589727763975
Validation loss: 3.8878819090987826

Epoch: 5| Step: 9
Training loss: 3.7434268563585227
Validation loss: 3.88263749585966

Epoch: 5| Step: 10
Training loss: 3.4936123187893333
Validation loss: 3.878172268145244

Epoch: 5| Step: 11
Training loss: 3.463957353853596
Validation loss: 3.873693789525331

Epoch: 32| Step: 0
Training loss: 3.8800338535208394
Validation loss: 3.8688864061982553

Epoch: 5| Step: 1
Training loss: 4.042877933385193
Validation loss: 3.8639528560546474

Epoch: 5| Step: 2
Training loss: 4.052201819301525
Validation loss: 3.8592911632662403

Epoch: 5| Step: 3
Training loss: 4.384150717253762
Validation loss: 3.8546009987458723

Epoch: 5| Step: 4
Training loss: 3.8356617752706588
Validation loss: 3.8496186133560455

Epoch: 5| Step: 5
Training loss: 4.008734940826802
Validation loss: 3.8446112445812983

Epoch: 5| Step: 6
Training loss: 4.167587305720861
Validation loss: 3.839865993928172

Epoch: 5| Step: 7
Training loss: 4.471347294133599
Validation loss: 3.835363652023328

Epoch: 5| Step: 8
Training loss: 3.415315236723944
Validation loss: 3.8308837603561816

Epoch: 5| Step: 9
Training loss: 3.7368781347496105
Validation loss: 3.8263933534051904

Epoch: 5| Step: 10
Training loss: 4.017880055195707
Validation loss: 3.8217255021158096

Epoch: 5| Step: 11
Training loss: 1.55871168565198
Validation loss: 3.8171269215646015

Epoch: 33| Step: 0
Training loss: 3.8608388248247834
Validation loss: 3.8128400088173695

Epoch: 5| Step: 1
Training loss: 4.378536865553128
Validation loss: 3.8083568010226228

Epoch: 5| Step: 2
Training loss: 4.608711220743922
Validation loss: 3.8035721864151624

Epoch: 5| Step: 3
Training loss: 3.533014447439386
Validation loss: 3.7993981307209848

Epoch: 5| Step: 4
Training loss: 3.4183613055823883
Validation loss: 3.795086924965089

Epoch: 5| Step: 5
Training loss: 3.9835984613989592
Validation loss: 3.7906038118605214

Epoch: 5| Step: 6
Training loss: 4.0638700082519525
Validation loss: 3.7861195727124954

Epoch: 5| Step: 7
Training loss: 3.6522532732359614
Validation loss: 3.7811947442843636

Epoch: 5| Step: 8
Training loss: 4.671850504220898
Validation loss: 3.7769829105311756

Epoch: 5| Step: 9
Training loss: 3.3848577575999514
Validation loss: 3.772989208269024

Epoch: 5| Step: 10
Training loss: 3.4867030008974504
Validation loss: 3.768080073291432

Epoch: 5| Step: 11
Training loss: 3.184324889682546
Validation loss: 3.763775837097035

Epoch: 34| Step: 0
Training loss: 4.266743384108653
Validation loss: 3.7592469066466685

Epoch: 5| Step: 1
Training loss: 4.015628324870948
Validation loss: 3.7556002813998477

Epoch: 5| Step: 2
Training loss: 3.7559966143104315
Validation loss: 3.7513061315092493

Epoch: 5| Step: 3
Training loss: 3.8762999784365437
Validation loss: 3.745874148532962

Epoch: 5| Step: 4
Training loss: 3.9756050081294623
Validation loss: 3.741670061731533

Epoch: 5| Step: 5
Training loss: 3.4424865620447087
Validation loss: 3.7374510552424014

Epoch: 5| Step: 6
Training loss: 3.1868936298526824
Validation loss: 3.7326227490374344

Epoch: 5| Step: 7
Training loss: 4.240809207926844
Validation loss: 3.728493803828686

Epoch: 5| Step: 8
Training loss: 4.133741652921792
Validation loss: 3.7245349766582634

Epoch: 5| Step: 9
Training loss: 3.769135797343136
Validation loss: 3.7191810838894424

Epoch: 5| Step: 10
Training loss: 3.9179519546468278
Validation loss: 3.71519279778919

Epoch: 5| Step: 11
Training loss: 3.2244706658347972
Validation loss: 3.710986852485011

Epoch: 35| Step: 0
Training loss: 3.0454414320809637
Validation loss: 3.706569448580928

Epoch: 5| Step: 1
Training loss: 3.673723380559249
Validation loss: 3.702959617645228

Epoch: 5| Step: 2
Training loss: 4.490597969456965
Validation loss: 3.6982279400265234

Epoch: 5| Step: 3
Training loss: 2.972573959675309
Validation loss: 3.6935635514813856

Epoch: 5| Step: 4
Training loss: 4.715411287170795
Validation loss: 3.6896378952348816

Epoch: 5| Step: 5
Training loss: 4.03407342494248
Validation loss: 3.685239955977692

Epoch: 5| Step: 6
Training loss: 3.9395792481824707
Validation loss: 3.680916561360029

Epoch: 5| Step: 7
Training loss: 3.0164604018141676
Validation loss: 3.6760542008462007

Epoch: 5| Step: 8
Training loss: 4.283200453145541
Validation loss: 3.671927160880068

Epoch: 5| Step: 9
Training loss: 4.016636821166362
Validation loss: 3.668298941400041

Epoch: 5| Step: 10
Training loss: 3.341271596054573
Validation loss: 3.6634315538530307

Epoch: 5| Step: 11
Training loss: 3.904071291827592
Validation loss: 3.6592891049966165

Epoch: 36| Step: 0
Training loss: 3.1666930013531998
Validation loss: 3.654477007456548

Epoch: 5| Step: 1
Training loss: 4.117400133118127
Validation loss: 3.650495467458643

Epoch: 5| Step: 2
Training loss: 3.249805151160268
Validation loss: 3.6456384697563973

Epoch: 5| Step: 3
Training loss: 3.8705038011850332
Validation loss: 3.6415949935901577

Epoch: 5| Step: 4
Training loss: 4.130796579014424
Validation loss: 3.6365108683249883

Epoch: 5| Step: 5
Training loss: 3.6500170145552704
Validation loss: 3.6324268532879653

Epoch: 5| Step: 6
Training loss: 3.3054181096185897
Validation loss: 3.6280494283405957

Epoch: 5| Step: 7
Training loss: 3.9889452285353433
Validation loss: 3.6236460886831154

Epoch: 5| Step: 8
Training loss: 3.820036146781824
Validation loss: 3.6191038983165007

Epoch: 5| Step: 9
Training loss: 4.263614613965012
Validation loss: 3.6144075140209906

Epoch: 5| Step: 10
Training loss: 3.8279847411326924
Validation loss: 3.6097993147167196

Epoch: 5| Step: 11
Training loss: 3.057825062550044
Validation loss: 3.6054752634967064

Epoch: 37| Step: 0
Training loss: 3.3459146213435145
Validation loss: 3.6011024892958097

Epoch: 5| Step: 1
Training loss: 3.983368869979441
Validation loss: 3.5968851926180263

Epoch: 5| Step: 2
Training loss: 3.2524334527024243
Validation loss: 3.5929529660713144

Epoch: 5| Step: 3
Training loss: 3.9696579743075344
Validation loss: 3.588269873496604

Epoch: 5| Step: 4
Training loss: 2.6851382856791965
Validation loss: 3.584248097043205

Epoch: 5| Step: 5
Training loss: 4.350259856431733
Validation loss: 3.5803816729616824

Epoch: 5| Step: 6
Training loss: 3.844428522031687
Validation loss: 3.5757632061113624

Epoch: 5| Step: 7
Training loss: 3.9560991641152623
Validation loss: 3.5719765389228377

Epoch: 5| Step: 8
Training loss: 3.593824700947465
Validation loss: 3.567261090983674

Epoch: 5| Step: 9
Training loss: 3.744214490501166
Validation loss: 3.562992140032628

Epoch: 5| Step: 10
Training loss: 4.034408869405419
Validation loss: 3.558617657030842

Epoch: 5| Step: 11
Training loss: 2.7658656818382745
Validation loss: 3.5541487736193798

Epoch: 38| Step: 0
Training loss: 3.3758952048520503
Validation loss: 3.5501878534232256

Epoch: 5| Step: 1
Training loss: 3.459887480918308
Validation loss: 3.545505892423282

Epoch: 5| Step: 2
Training loss: 3.5684718890478604
Validation loss: 3.5419907402916984

Epoch: 5| Step: 3
Training loss: 3.496098250913653
Validation loss: 3.5377788222639928

Epoch: 5| Step: 4
Training loss: 3.7808719162250677
Validation loss: 3.533363778654922

Epoch: 5| Step: 5
Training loss: 3.578429896261898
Validation loss: 3.529593509606414

Epoch: 5| Step: 6
Training loss: 3.6435762812195147
Validation loss: 3.5249092090358585

Epoch: 5| Step: 7
Training loss: 3.829574621895749
Validation loss: 3.5213274167034134

Epoch: 5| Step: 8
Training loss: 3.799000965099207
Validation loss: 3.5165997658523422

Epoch: 5| Step: 9
Training loss: 4.104038501164794
Validation loss: 3.512356483450759

Epoch: 5| Step: 10
Training loss: 3.5827589387878658
Validation loss: 3.5075748252636467

Epoch: 5| Step: 11
Training loss: 3.8793024358266837
Validation loss: 3.50368983615043

Epoch: 39| Step: 0
Training loss: 3.1933965558328605
Validation loss: 3.498782661451809

Epoch: 5| Step: 1
Training loss: 3.5205339533963595
Validation loss: 3.495130654204536

Epoch: 5| Step: 2
Training loss: 4.024723417837292
Validation loss: 3.490550175806574

Epoch: 5| Step: 3
Training loss: 3.474649996249341
Validation loss: 3.4865800754037695

Epoch: 5| Step: 4
Training loss: 3.254410172329724
Validation loss: 3.482060979805092

Epoch: 5| Step: 5
Training loss: 3.6238948847534456
Validation loss: 3.4774012264683005

Epoch: 5| Step: 6
Training loss: 3.6228540580009194
Validation loss: 3.4732708152945917

Epoch: 5| Step: 7
Training loss: 3.912538882906329
Validation loss: 3.4695889601087857

Epoch: 5| Step: 8
Training loss: 3.409618566888015
Validation loss: 3.4653882986080795

Epoch: 5| Step: 9
Training loss: 3.643062708635119
Validation loss: 3.460179960012146

Epoch: 5| Step: 10
Training loss: 4.09714675805088
Validation loss: 3.455905318591693

Epoch: 5| Step: 11
Training loss: 2.8659407480188395
Validation loss: 3.451714534010101

Epoch: 40| Step: 0
Training loss: 3.342722369424403
Validation loss: 3.4472230730321263

Epoch: 5| Step: 1
Training loss: 4.088005170023835
Validation loss: 3.4438293794043937

Epoch: 5| Step: 2
Training loss: 3.984034385333604
Validation loss: 3.438753405275442

Epoch: 5| Step: 3
Training loss: 3.3609049307337115
Validation loss: 3.435288550210905

Epoch: 5| Step: 4
Training loss: 3.116917342714349
Validation loss: 3.4303472777877

Epoch: 5| Step: 5
Training loss: 3.6491455436653304
Validation loss: 3.426410099716073

Epoch: 5| Step: 6
Training loss: 3.8838274912842956
Validation loss: 3.4220377100983446

Epoch: 5| Step: 7
Training loss: 3.7316759642711927
Validation loss: 3.417726867836354

Epoch: 5| Step: 8
Training loss: 2.9887492293385174
Validation loss: 3.4131167314456388

Epoch: 5| Step: 9
Training loss: 3.464923294341297
Validation loss: 3.4092255349501634

Epoch: 5| Step: 10
Training loss: 3.675853116410237
Validation loss: 3.405041769082409

Epoch: 5| Step: 11
Training loss: 2.0902379885153777
Validation loss: 3.4009684349849016

Epoch: 41| Step: 0
Training loss: 4.09878370340398
Validation loss: 3.396943096284322

Epoch: 5| Step: 1
Training loss: 3.0293535415396255
Validation loss: 3.3928262564560687

Epoch: 5| Step: 2
Training loss: 4.251557457474729
Validation loss: 3.3885035756117468

Epoch: 5| Step: 3
Training loss: 3.7958223115919427
Validation loss: 3.3853765641796096

Epoch: 5| Step: 4
Training loss: 2.856347988459522
Validation loss: 3.3800007482580527

Epoch: 5| Step: 5
Training loss: 3.3851316048354256
Validation loss: 3.376089408856302

Epoch: 5| Step: 6
Training loss: 3.6843399473274916
Validation loss: 3.372628164450581

Epoch: 5| Step: 7
Training loss: 2.906408654261125
Validation loss: 3.3684749811851566

Epoch: 5| Step: 8
Training loss: 2.8670296690529695
Validation loss: 3.3641514791322686

Epoch: 5| Step: 9
Training loss: 4.17024524873182
Validation loss: 3.360470910924412

Epoch: 5| Step: 10
Training loss: 3.3603105528684027
Validation loss: 3.3561722443925106

Epoch: 5| Step: 11
Training loss: 2.792961750155127
Validation loss: 3.35245560111492

Epoch: 42| Step: 0
Training loss: 3.4111089085817907
Validation loss: 3.3487361678041543

Epoch: 5| Step: 1
Training loss: 3.985713240334744
Validation loss: 3.3451950064487477

Epoch: 5| Step: 2
Training loss: 3.8318066390197
Validation loss: 3.3405180847073552

Epoch: 5| Step: 3
Training loss: 2.351126696990252
Validation loss: 3.337032150428235

Epoch: 5| Step: 4
Training loss: 3.475109285241625
Validation loss: 3.3331350009247673

Epoch: 5| Step: 5
Training loss: 3.045274049800956
Validation loss: 3.3291307490770206

Epoch: 5| Step: 6
Training loss: 3.6834353011388408
Validation loss: 3.3252802587293533

Epoch: 5| Step: 7
Training loss: 3.476019587611945
Validation loss: 3.3215153987266675

Epoch: 5| Step: 8
Training loss: 3.675444730461173
Validation loss: 3.3183692032382397

Epoch: 5| Step: 9
Training loss: 3.789829829278314
Validation loss: 3.313574292860648

Epoch: 5| Step: 10
Training loss: 3.312149317190461
Validation loss: 3.310360121359097

Epoch: 5| Step: 11
Training loss: 2.479730162707243
Validation loss: 3.305880283964363

Epoch: 43| Step: 0
Training loss: 3.1272486416613026
Validation loss: 3.3022193138611904

Epoch: 5| Step: 1
Training loss: 3.2518736500235943
Validation loss: 3.2982076328979684

Epoch: 5| Step: 2
Training loss: 3.2261560659763706
Validation loss: 3.294392915456382

Epoch: 5| Step: 3
Training loss: 3.8074945829757456
Validation loss: 3.2912676585479885

Epoch: 5| Step: 4
Training loss: 3.3671077709981474
Validation loss: 3.2867277713038563

Epoch: 5| Step: 5
Training loss: 3.6551088035660118
Validation loss: 3.2832186711972215

Epoch: 5| Step: 6
Training loss: 3.5956425203254243
Validation loss: 3.279247956841653

Epoch: 5| Step: 7
Training loss: 3.0727284174440417
Validation loss: 3.2754462640594015

Epoch: 5| Step: 8
Training loss: 3.8511005612073723
Validation loss: 3.2709820019086786

Epoch: 5| Step: 9
Training loss: 3.055817768135997
Validation loss: 3.267851215206292

Epoch: 5| Step: 10
Training loss: 3.4721960872090425
Validation loss: 3.2634830720821992

Epoch: 5| Step: 11
Training loss: 3.623923306224144
Validation loss: 3.2590412960227773

Epoch: 44| Step: 0
Training loss: 3.1158404582832238
Validation loss: 3.255286364828089

Epoch: 5| Step: 1
Training loss: 3.825813187069959
Validation loss: 3.2510533154266796

Epoch: 5| Step: 2
Training loss: 3.337676762961211
Validation loss: 3.2471351529103267

Epoch: 5| Step: 3
Training loss: 2.816444174501944
Validation loss: 3.2434054006062647

Epoch: 5| Step: 4
Training loss: 3.7973730443510374
Validation loss: 3.2396064136005958

Epoch: 5| Step: 5
Training loss: 3.6974625572800317
Validation loss: 3.2350583606174483

Epoch: 5| Step: 6
Training loss: 2.9266121554095474
Validation loss: 3.2314103156237395

Epoch: 5| Step: 7
Training loss: 3.5895533729641627
Validation loss: 3.22707228062516

Epoch: 5| Step: 8
Training loss: 3.715607669876532
Validation loss: 3.2230609709020315

Epoch: 5| Step: 9
Training loss: 3.549609772631897
Validation loss: 3.2198498090720733

Epoch: 5| Step: 10
Training loss: 2.611626573054843
Validation loss: 3.2153189034895178

Epoch: 5| Step: 11
Training loss: 2.761994041955752
Validation loss: 3.211727710273088

Epoch: 45| Step: 0
Training loss: 2.6317632831460402
Validation loss: 3.2082196603594526

Epoch: 5| Step: 1
Training loss: 3.471133813448669
Validation loss: 3.204343356273942

Epoch: 5| Step: 2
Training loss: 3.1884198824881738
Validation loss: 3.201126051755762

Epoch: 5| Step: 3
Training loss: 3.6500347815123626
Validation loss: 3.1970377075513907

Epoch: 5| Step: 4
Training loss: 3.0246544884962105
Validation loss: 3.1936363667816323

Epoch: 5| Step: 5
Training loss: 3.071476916949724
Validation loss: 3.19055359250179

Epoch: 5| Step: 6
Training loss: 3.569671239380902
Validation loss: 3.1869738462432493

Epoch: 5| Step: 7
Training loss: 2.5859888538436064
Validation loss: 3.1829440025264017

Epoch: 5| Step: 8
Training loss: 3.589624574630611
Validation loss: 3.1796705103364857

Epoch: 5| Step: 9
Training loss: 3.5919337451406284
Validation loss: 3.175986727127491

Epoch: 5| Step: 10
Training loss: 3.9454929423851013
Validation loss: 3.1728488416846967

Epoch: 5| Step: 11
Training loss: 3.482132399546811
Validation loss: 3.168655333650471

Epoch: 46| Step: 0
Training loss: 3.7263921862695977
Validation loss: 3.1652664594088495

Epoch: 5| Step: 1
Training loss: 3.8684154063838148
Validation loss: 3.1616589180391066

Epoch: 5| Step: 2
Training loss: 2.902066901699704
Validation loss: 3.158216210225933

Epoch: 5| Step: 3
Training loss: 3.267446931438683
Validation loss: 3.1533470085733306

Epoch: 5| Step: 4
Training loss: 2.942212808574101
Validation loss: 3.1497837403655615

Epoch: 5| Step: 5
Training loss: 2.9070992818333594
Validation loss: 3.1458941300098333

Epoch: 5| Step: 6
Training loss: 3.2235325217283193
Validation loss: 3.142773015451722

Epoch: 5| Step: 7
Training loss: 3.3495735010834076
Validation loss: 3.13895843343485

Epoch: 5| Step: 8
Training loss: 2.841290762491844
Validation loss: 3.134827727497881

Epoch: 5| Step: 9
Training loss: 3.953350075809049
Validation loss: 3.1318093625749097

Epoch: 5| Step: 10
Training loss: 2.98390297876696
Validation loss: 3.128265226297153

Epoch: 5| Step: 11
Training loss: 3.1242380357677906
Validation loss: 3.1252494712434276

Epoch: 47| Step: 0
Training loss: 2.965754553775849
Validation loss: 3.1223553084076006

Epoch: 5| Step: 1
Training loss: 3.563127964288201
Validation loss: 3.1185512029603237

Epoch: 5| Step: 2
Training loss: 2.559569567316755
Validation loss: 3.1149669345072306

Epoch: 5| Step: 3
Training loss: 3.4280778240063117
Validation loss: 3.1115219525190065

Epoch: 5| Step: 4
Training loss: 3.688725671898024
Validation loss: 3.107765650280208

Epoch: 5| Step: 5
Training loss: 2.6635532283917427
Validation loss: 3.1044977297457934

Epoch: 5| Step: 6
Training loss: 3.351366868789687
Validation loss: 3.1014131979315405

Epoch: 5| Step: 7
Training loss: 3.53202865252856
Validation loss: 3.0982539148362647

Epoch: 5| Step: 8
Training loss: 3.3496230411528796
Validation loss: 3.0947777392881735

Epoch: 5| Step: 9
Training loss: 3.3560936804371413
Validation loss: 3.091062881569357

Epoch: 5| Step: 10
Training loss: 3.22040789230151
Validation loss: 3.087481554261988

Epoch: 5| Step: 11
Training loss: 2.2681572804554486
Validation loss: 3.0844636512082615

Epoch: 48| Step: 0
Training loss: 3.7082179333736636
Validation loss: 3.0808184727128154

Epoch: 5| Step: 1
Training loss: 3.01861803228383
Validation loss: 3.0783473933349237

Epoch: 5| Step: 2
Training loss: 2.8905969566840706
Validation loss: 3.074446143433362

Epoch: 5| Step: 3
Training loss: 3.4343027678261904
Validation loss: 3.071806650057822

Epoch: 5| Step: 4
Training loss: 3.50568799633349
Validation loss: 3.0681355194597364

Epoch: 5| Step: 5
Training loss: 2.6670715700150454
Validation loss: 3.064966635696171

Epoch: 5| Step: 6
Training loss: 3.2616975520924196
Validation loss: 3.061044502822108

Epoch: 5| Step: 7
Training loss: 2.9716820944062716
Validation loss: 3.058042617063452

Epoch: 5| Step: 8
Training loss: 3.0349685041373915
Validation loss: 3.053869572085218

Epoch: 5| Step: 9
Training loss: 3.3465530197888413
Validation loss: 3.0513396718747887

Epoch: 5| Step: 10
Training loss: 3.387996656882338
Validation loss: 3.0479978627940403

Epoch: 5| Step: 11
Training loss: 2.7512401905430885
Validation loss: 3.0445897000896505

Epoch: 49| Step: 0
Training loss: 3.2643495834269687
Validation loss: 3.0416941423786414

Epoch: 5| Step: 1
Training loss: 3.020559908013405
Validation loss: 3.03914693210081

Epoch: 5| Step: 2
Training loss: 3.3611820062844138
Validation loss: 3.0363242325307347

Epoch: 5| Step: 3
Training loss: 3.2090785824767116
Validation loss: 3.033976593603518

Epoch: 5| Step: 4
Training loss: 2.9740123487779258
Validation loss: 3.03122190416562

Epoch: 5| Step: 5
Training loss: 3.866103018314149
Validation loss: 3.028500647220602

Epoch: 5| Step: 6
Training loss: 3.2990352549777984
Validation loss: 3.025155143857779

Epoch: 5| Step: 7
Training loss: 2.850244839507933
Validation loss: 3.022107113375991

Epoch: 5| Step: 8
Training loss: 2.472481334218538
Validation loss: 3.0199320248770554

Epoch: 5| Step: 9
Training loss: 2.8655713591136345
Validation loss: 3.016711610824576

Epoch: 5| Step: 10
Training loss: 3.5583887302872013
Validation loss: 3.014575835040472

Epoch: 5| Step: 11
Training loss: 2.64688487946199
Validation loss: 3.0117014856829094

Epoch: 50| Step: 0
Training loss: 3.449180317682971
Validation loss: 3.00879830063183

Epoch: 5| Step: 1
Training loss: 3.0047012685856047
Validation loss: 3.0053755561057955

Epoch: 5| Step: 2
Training loss: 3.326063493720138
Validation loss: 3.0018049843479413

Epoch: 5| Step: 3
Training loss: 2.479977536561197
Validation loss: 2.999391583497993

Epoch: 5| Step: 4
Training loss: 3.4489685175192406
Validation loss: 2.9960647840231154

Epoch: 5| Step: 5
Training loss: 3.0531863843824407
Validation loss: 2.993916014764949

Epoch: 5| Step: 6
Training loss: 3.334958792779325
Validation loss: 2.99051198702635

Epoch: 5| Step: 7
Training loss: 2.9385469883966695
Validation loss: 2.987696016470373

Epoch: 5| Step: 8
Training loss: 3.0339046534101706
Validation loss: 2.984879572556751

Epoch: 5| Step: 9
Training loss: 3.156135934713699
Validation loss: 2.9819675608319693

Epoch: 5| Step: 10
Training loss: 3.085918648577705
Validation loss: 2.979766863049584

Epoch: 5| Step: 11
Training loss: 3.4454198980568074
Validation loss: 2.976818721153024

Epoch: 51| Step: 0
Training loss: 3.2837414683103
Validation loss: 2.973594186716758

Epoch: 5| Step: 1
Training loss: 2.9014156700867595
Validation loss: 2.9706499277635756

Epoch: 5| Step: 2
Training loss: 3.733029174903233
Validation loss: 2.968465650894647

Epoch: 5| Step: 3
Training loss: 3.12493743833861
Validation loss: 2.9645701044627004

Epoch: 5| Step: 4
Training loss: 2.8263304691593367
Validation loss: 2.9617339768182243

Epoch: 5| Step: 5
Training loss: 2.5121899959183107
Validation loss: 2.9582664332190625

Epoch: 5| Step: 6
Training loss: 2.5446585155186945
Validation loss: 2.9559925527756277

Epoch: 5| Step: 7
Training loss: 3.412132992414329
Validation loss: 2.9527415004697577

Epoch: 5| Step: 8
Training loss: 3.3231080258237085
Validation loss: 2.950703076859003

Epoch: 5| Step: 9
Training loss: 3.6501737788388455
Validation loss: 2.9476904068959677

Epoch: 5| Step: 10
Training loss: 2.6114819637568987
Validation loss: 2.9449846775010378

Epoch: 5| Step: 11
Training loss: 2.4978693465798023
Validation loss: 2.942700166043901

Epoch: 52| Step: 0
Training loss: 3.103336317045237
Validation loss: 2.9392003285472557

Epoch: 5| Step: 1
Training loss: 2.849118374101637
Validation loss: 2.9367958503216602

Epoch: 5| Step: 2
Training loss: 3.0460044203968497
Validation loss: 2.9338809100128063

Epoch: 5| Step: 3
Training loss: 3.3427132398538233
Validation loss: 2.930903176596368

Epoch: 5| Step: 4
Training loss: 3.8001802602476604
Validation loss: 2.927947104718219

Epoch: 5| Step: 5
Training loss: 3.076983864807332
Validation loss: 2.9243040035212178

Epoch: 5| Step: 6
Training loss: 2.7903825643900255
Validation loss: 2.9216969005683655

Epoch: 5| Step: 7
Training loss: 2.9553559772092375
Validation loss: 2.918705395746412

Epoch: 5| Step: 8
Training loss: 2.3638318137742025
Validation loss: 2.9160012519279497

Epoch: 5| Step: 9
Training loss: 3.1752583916717447
Validation loss: 2.9126596559852134

Epoch: 5| Step: 10
Training loss: 3.134030531023073
Validation loss: 2.9105130653190763

Epoch: 5| Step: 11
Training loss: 2.6121978110438375
Validation loss: 2.908089479472291

Epoch: 53| Step: 0
Training loss: 2.8582691493117345
Validation loss: 2.9052832065279124

Epoch: 5| Step: 1
Training loss: 2.7310228126715677
Validation loss: 2.903041801861919

Epoch: 5| Step: 2
Training loss: 3.089966743808781
Validation loss: 2.9008175314173603

Epoch: 5| Step: 3
Training loss: 2.8644304454347287
Validation loss: 2.898546201410427

Epoch: 5| Step: 4
Training loss: 2.9262305450770443
Validation loss: 2.8961099394188077

Epoch: 5| Step: 5
Training loss: 2.7628177684452813
Validation loss: 2.894120328343499

Epoch: 5| Step: 6
Training loss: 2.5155634902163224
Validation loss: 2.8929310235003274

Epoch: 5| Step: 7
Training loss: 2.9690668840439196
Validation loss: 2.890127503481949

Epoch: 5| Step: 8
Training loss: 3.5944936231746825
Validation loss: 2.8876540028732065

Epoch: 5| Step: 9
Training loss: 3.3371451199910207
Validation loss: 2.884677349264602

Epoch: 5| Step: 10
Training loss: 3.5275301625282225
Validation loss: 2.882470452641635

Epoch: 5| Step: 11
Training loss: 3.0983519572627993
Validation loss: 2.8801093725457063

Epoch: 54| Step: 0
Training loss: 3.079766315165856
Validation loss: 2.8764547765405952

Epoch: 5| Step: 1
Training loss: 3.470607775578966
Validation loss: 2.874405861705671

Epoch: 5| Step: 2
Training loss: 2.539624055239173
Validation loss: 2.8723042676112525

Epoch: 5| Step: 3
Training loss: 3.67040388790081
Validation loss: 2.8693185175069433

Epoch: 5| Step: 4
Training loss: 2.6708316662129055
Validation loss: 2.866354063274141

Epoch: 5| Step: 5
Training loss: 3.07660308237661
Validation loss: 2.8644570802551788

Epoch: 5| Step: 6
Training loss: 2.652316603149459
Validation loss: 2.8618030626972732

Epoch: 5| Step: 7
Training loss: 3.0664357955383936
Validation loss: 2.8594534051981735

Epoch: 5| Step: 8
Training loss: 3.040091293871492
Validation loss: 2.856741799294238

Epoch: 5| Step: 9
Training loss: 3.0308636291293123
Validation loss: 2.853953441720848

Epoch: 5| Step: 10
Training loss: 2.5770537954214014
Validation loss: 2.8512081884150082

Epoch: 5| Step: 11
Training loss: 2.942173587970793
Validation loss: 2.8495833648686846

Epoch: 55| Step: 0
Training loss: 2.7822928884359057
Validation loss: 2.846912630560378

Epoch: 5| Step: 1
Training loss: 3.1118989601599583
Validation loss: 2.8448546433482487

Epoch: 5| Step: 2
Training loss: 3.0435066580188033
Validation loss: 2.8432568971467576

Epoch: 5| Step: 3
Training loss: 3.05119104111971
Validation loss: 2.8404652030546784

Epoch: 5| Step: 4
Training loss: 3.052704384449613
Validation loss: 2.8382630284357377

Epoch: 5| Step: 5
Training loss: 3.119176397434975
Validation loss: 2.8361003152928466

Epoch: 5| Step: 6
Training loss: 2.695390517722763
Validation loss: 2.83379517091687

Epoch: 5| Step: 7
Training loss: 2.789238675748152
Validation loss: 2.8320705718018173

Epoch: 5| Step: 8
Training loss: 3.4008304984104187
Validation loss: 2.830421397098845

Epoch: 5| Step: 9
Training loss: 3.206124292478506
Validation loss: 2.8277468911561585

Epoch: 5| Step: 10
Training loss: 2.494602289093296
Validation loss: 2.825683657031654

Epoch: 5| Step: 11
Training loss: 2.416249886012975
Validation loss: 2.8240195485938746

Epoch: 56| Step: 0
Training loss: 2.9040742338586525
Validation loss: 2.821016380554136

Epoch: 5| Step: 1
Training loss: 2.6639811483810174
Validation loss: 2.8211525029801034

Epoch: 5| Step: 2
Training loss: 3.063841234122642
Validation loss: 2.818969230556553

Epoch: 5| Step: 3
Training loss: 2.756286544730536
Validation loss: 2.8167445931480217

Epoch: 5| Step: 4
Training loss: 2.948993841020602
Validation loss: 2.8147553090418906

Epoch: 5| Step: 5
Training loss: 2.9923729901301654
Validation loss: 2.8128125900055507

Epoch: 5| Step: 6
Training loss: 2.9208683993147866
Validation loss: 2.810768512808159

Epoch: 5| Step: 7
Training loss: 3.3284376114001892
Validation loss: 2.8079885432907603

Epoch: 5| Step: 8
Training loss: 2.918515972418552
Validation loss: 2.8068892108481336

Epoch: 5| Step: 9
Training loss: 3.093662145118573
Validation loss: 2.8065001245282626

Epoch: 5| Step: 10
Training loss: 2.826213042849781
Validation loss: 2.8050564741942248

Epoch: 5| Step: 11
Training loss: 3.0589639919489944
Validation loss: 2.800521991103528

Epoch: 57| Step: 0
Training loss: 3.0363175025242755
Validation loss: 2.7995488369574475

Epoch: 5| Step: 1
Training loss: 2.6993787086003826
Validation loss: 2.7977621742158414

Epoch: 5| Step: 2
Training loss: 2.9725327334514637
Validation loss: 2.7966320600081085

Epoch: 5| Step: 3
Training loss: 3.2817600398796047
Validation loss: 2.794159766434332

Epoch: 5| Step: 4
Training loss: 2.7522315594483926
Validation loss: 2.7924169960196714

Epoch: 5| Step: 5
Training loss: 2.8260351225714744
Validation loss: 2.790446505261482

Epoch: 5| Step: 6
Training loss: 3.016143279924576
Validation loss: 2.7879906989386676

Epoch: 5| Step: 7
Training loss: 3.2006197925205697
Validation loss: 2.7845858274676325

Epoch: 5| Step: 8
Training loss: 2.517168507424421
Validation loss: 2.783323668607809

Epoch: 5| Step: 9
Training loss: 3.104210479905035
Validation loss: 2.7802887373372527

Epoch: 5| Step: 10
Training loss: 2.885312038319544
Validation loss: 2.7792709717534207

Epoch: 5| Step: 11
Training loss: 2.125011444060981
Validation loss: 2.7769295785574344

Epoch: 58| Step: 0
Training loss: 2.882434851248488
Validation loss: 2.774409221504855

Epoch: 5| Step: 1
Training loss: 3.125618530095877
Validation loss: 2.7723498866929512

Epoch: 5| Step: 2
Training loss: 3.2272697209382066
Validation loss: 2.7712539781396486

Epoch: 5| Step: 3
Training loss: 2.9826687234124822
Validation loss: 2.76898898262265

Epoch: 5| Step: 4
Training loss: 2.8595634356668045
Validation loss: 2.766880034401996

Epoch: 5| Step: 5
Training loss: 3.2753462222597762
Validation loss: 2.7648142903341095

Epoch: 5| Step: 6
Training loss: 3.1282805961454634
Validation loss: 2.762459198404435

Epoch: 5| Step: 7
Training loss: 2.4109908132041857
Validation loss: 2.760783838048543

Epoch: 5| Step: 8
Training loss: 2.6676438945081284
Validation loss: 2.7585632988030406

Epoch: 5| Step: 9
Training loss: 2.8441741962335056
Validation loss: 2.757286389015219

Epoch: 5| Step: 10
Training loss: 2.588567312767248
Validation loss: 2.7553915829403435

Epoch: 5| Step: 11
Training loss: 2.039899632284918
Validation loss: 2.7547420342684443

Epoch: 59| Step: 0
Training loss: 2.7740713335476506
Validation loss: 2.7537584269644753

Epoch: 5| Step: 1
Training loss: 3.000534327924238
Validation loss: 2.7517360207243113

Epoch: 5| Step: 2
Training loss: 2.7363885060087227
Validation loss: 2.7487509050898313

Epoch: 5| Step: 3
Training loss: 2.382001294741851
Validation loss: 2.748189687915358

Epoch: 5| Step: 4
Training loss: 2.8597920431545947
Validation loss: 2.7459090140414175

Epoch: 5| Step: 5
Training loss: 3.194599547744095
Validation loss: 2.7436015548752906

Epoch: 5| Step: 6
Training loss: 2.722055639848882
Validation loss: 2.742348860931749

Epoch: 5| Step: 7
Training loss: 3.028705748306801
Validation loss: 2.7404142806943863

Epoch: 5| Step: 8
Training loss: 2.9445560202261394
Validation loss: 2.7371163568252954

Epoch: 5| Step: 9
Training loss: 3.3064225784575667
Validation loss: 2.7360871141019323

Epoch: 5| Step: 10
Training loss: 2.882653374144014
Validation loss: 2.7351880345281514

Epoch: 5| Step: 11
Training loss: 1.2621830419625542
Validation loss: 2.7326873294059673

Epoch: 60| Step: 0
Training loss: 2.931432748396938
Validation loss: 2.7312021502996053

Epoch: 5| Step: 1
Training loss: 2.642902453045185
Validation loss: 2.728650649745414

Epoch: 5| Step: 2
Training loss: 2.9329630126701915
Validation loss: 2.72724454960331

Epoch: 5| Step: 3
Training loss: 2.9297430007763725
Validation loss: 2.72476437217804

Epoch: 5| Step: 4
Training loss: 3.2806727310286887
Validation loss: 2.7243852274767573

Epoch: 5| Step: 5
Training loss: 2.9583106957944025
Validation loss: 2.721664758994218

Epoch: 5| Step: 6
Training loss: 3.139327507168633
Validation loss: 2.7204877152418256

Epoch: 5| Step: 7
Training loss: 2.9796293384014554
Validation loss: 2.7184946517587694

Epoch: 5| Step: 8
Training loss: 2.6177927712239772
Validation loss: 2.71601167434675

Epoch: 5| Step: 9
Training loss: 2.304294565616426
Validation loss: 2.7145126104229997

Epoch: 5| Step: 10
Training loss: 2.4767801568207357
Validation loss: 2.7126627296059964

Epoch: 5| Step: 11
Training loss: 3.5337914967537767
Validation loss: 2.7115461378991284

Epoch: 61| Step: 0
Training loss: 2.71857267656506
Validation loss: 2.709047884702009

Epoch: 5| Step: 1
Training loss: 2.9835229426250307
Validation loss: 2.708940369483064

Epoch: 5| Step: 2
Training loss: 2.7480346419137365
Validation loss: 2.707565276960817

Epoch: 5| Step: 3
Training loss: 2.953213806431736
Validation loss: 2.7095790687921286

Epoch: 5| Step: 4
Training loss: 3.224926254257289
Validation loss: 2.708179092905844

Epoch: 5| Step: 5
Training loss: 2.943275131508412
Validation loss: 2.7016751658780334

Epoch: 5| Step: 6
Training loss: 2.4042846778541653
Validation loss: 2.699734374949839

Epoch: 5| Step: 7
Training loss: 2.700526228592479
Validation loss: 2.699260339632753

Epoch: 5| Step: 8
Training loss: 3.0981968219213063
Validation loss: 2.6976363405873363

Epoch: 5| Step: 9
Training loss: 2.5637757451900423
Validation loss: 2.698941968757568

Epoch: 5| Step: 10
Training loss: 2.8172409788822224
Validation loss: 2.700213663453879

Epoch: 5| Step: 11
Training loss: 3.0286227766861153
Validation loss: 2.702412491168832

Epoch: 62| Step: 0
Training loss: 2.64476618434614
Validation loss: 2.6968132042905015

Epoch: 5| Step: 1
Training loss: 2.767296496096569
Validation loss: 2.692226807109382

Epoch: 5| Step: 2
Training loss: 2.8451056969288113
Validation loss: 2.688965493964043

Epoch: 5| Step: 3
Training loss: 2.803992565205032
Validation loss: 2.6872519925739113

Epoch: 5| Step: 4
Training loss: 3.1672386522871925
Validation loss: 2.6860541993879443

Epoch: 5| Step: 5
Training loss: 3.115568500645485
Validation loss: 2.6865477242499236

Epoch: 5| Step: 6
Training loss: 2.588025497664677
Validation loss: 2.6832497610875574

Epoch: 5| Step: 7
Training loss: 2.3399192530402178
Validation loss: 2.680799451882086

Epoch: 5| Step: 8
Training loss: 2.9565469604767642
Validation loss: 2.6806800531444264

Epoch: 5| Step: 9
Training loss: 2.9224475972720656
Validation loss: 2.6775078727554185

Epoch: 5| Step: 10
Training loss: 2.75014703530926
Validation loss: 2.6768165608838514

Epoch: 5| Step: 11
Training loss: 3.167699310848521
Validation loss: 2.676343508860653

Epoch: 63| Step: 0
Training loss: 3.223412553299613
Validation loss: 2.672783427635446

Epoch: 5| Step: 1
Training loss: 2.4801744181303347
Validation loss: 2.6728318008920677

Epoch: 5| Step: 2
Training loss: 3.1612006914630624
Validation loss: 2.6752191848917026

Epoch: 5| Step: 3
Training loss: 2.974889249903992
Validation loss: 2.684086021053501

Epoch: 5| Step: 4
Training loss: 2.6789507061508857
Validation loss: 2.667435737563935

Epoch: 5| Step: 5
Training loss: 2.2649611980491438
Validation loss: 2.6669896806844586

Epoch: 5| Step: 6
Training loss: 2.722429526041303
Validation loss: 2.66390583923851

Epoch: 5| Step: 7
Training loss: 2.6492088792415087
Validation loss: 2.663561888612902

Epoch: 5| Step: 8
Training loss: 2.7217949663871255
Validation loss: 2.664356584621772

Epoch: 5| Step: 9
Training loss: 2.986272079111506
Validation loss: 2.665805075206405

Epoch: 5| Step: 10
Training loss: 2.6460076722706396
Validation loss: 2.663495145999903

Epoch: 5| Step: 11
Training loss: 3.9075617914567564
Validation loss: 2.662480232153446

Epoch: 64| Step: 0
Training loss: 3.1601355779511606
Validation loss: 2.659752455213898

Epoch: 5| Step: 1
Training loss: 2.481444928177853
Validation loss: 2.658269417501605

Epoch: 5| Step: 2
Training loss: 2.5230421577405973
Validation loss: 2.6562480290723482

Epoch: 5| Step: 3
Training loss: 2.430773820310938
Validation loss: 2.6522358238948125

Epoch: 5| Step: 4
Training loss: 2.826415752019752
Validation loss: 2.6507486932195983

Epoch: 5| Step: 5
Training loss: 2.814362142602539
Validation loss: 2.6487945120964205

Epoch: 5| Step: 6
Training loss: 2.626129089215741
Validation loss: 2.6450109605495986

Epoch: 5| Step: 7
Training loss: 2.9195322038272793
Validation loss: 2.645053291727396

Epoch: 5| Step: 8
Training loss: 3.211531164230427
Validation loss: 2.642562888722504

Epoch: 5| Step: 9
Training loss: 2.534561534183525
Validation loss: 2.6414407451986905

Epoch: 5| Step: 10
Training loss: 2.757873188680239
Validation loss: 2.639105387780178

Epoch: 5| Step: 11
Training loss: 3.8708552682595223
Validation loss: 2.637495255277684

Epoch: 65| Step: 0
Training loss: 2.7719050942285004
Validation loss: 2.6379160632723937

Epoch: 5| Step: 1
Training loss: 2.577148807550182
Validation loss: 2.656620601905228

Epoch: 5| Step: 2
Training loss: 2.976677359219691
Validation loss: 2.6413283380125483

Epoch: 5| Step: 3
Training loss: 2.431940830803416
Validation loss: 2.635985808051375

Epoch: 5| Step: 4
Training loss: 2.862947660532026
Validation loss: 2.631320817557689

Epoch: 5| Step: 5
Training loss: 2.3475894252006597
Validation loss: 2.630401095638256

Epoch: 5| Step: 6
Training loss: 3.0382016097695765
Validation loss: 2.630770367667479

Epoch: 5| Step: 7
Training loss: 3.0051267051960098
Validation loss: 2.631594307210501

Epoch: 5| Step: 8
Training loss: 2.378257825954252
Validation loss: 2.6311167832009055

Epoch: 5| Step: 9
Training loss: 2.940288437688003
Validation loss: 2.6334063900599713

Epoch: 5| Step: 10
Training loss: 3.073916273735277
Validation loss: 2.6320555341141354

Epoch: 5| Step: 11
Training loss: 2.7432186437699158
Validation loss: 2.6319675636757913

Epoch: 66| Step: 0
Training loss: 3.1224724275274145
Validation loss: 2.6310542958830156

Epoch: 5| Step: 1
Training loss: 2.939836911718894
Validation loss: 2.627836587013483

Epoch: 5| Step: 2
Training loss: 2.6068601996276732
Validation loss: 2.628312820938303

Epoch: 5| Step: 3
Training loss: 3.106168080406756
Validation loss: 2.62601666593069

Epoch: 5| Step: 4
Training loss: 2.928370960698025
Validation loss: 2.6232637953377775

Epoch: 5| Step: 5
Training loss: 2.374021629794149
Validation loss: 2.620860230096086

Epoch: 5| Step: 6
Training loss: 2.920303166733263
Validation loss: 2.6198942582738693

Epoch: 5| Step: 7
Training loss: 2.4197024537641396
Validation loss: 2.6160801153164304

Epoch: 5| Step: 8
Training loss: 2.8220975093202956
Validation loss: 2.614087416185626

Epoch: 5| Step: 9
Training loss: 2.4637955796173694
Validation loss: 2.614473725613964

Epoch: 5| Step: 10
Training loss: 2.4163678960164416
Validation loss: 2.6132911678139314

Epoch: 5| Step: 11
Training loss: 3.095279816286935
Validation loss: 2.6119142424760398

Epoch: 67| Step: 0
Training loss: 2.6660237630084125
Validation loss: 2.610091326188806

Epoch: 5| Step: 1
Training loss: 2.2760051896047844
Validation loss: 2.607552720119366

Epoch: 5| Step: 2
Training loss: 2.904656085931528
Validation loss: 2.605893708078515

Epoch: 5| Step: 3
Training loss: 2.8212368367115794
Validation loss: 2.6068749853180035

Epoch: 5| Step: 4
Training loss: 2.74550972991592
Validation loss: 2.60689495729904

Epoch: 5| Step: 5
Training loss: 2.806697879385136
Validation loss: 2.604430575667712

Epoch: 5| Step: 6
Training loss: 2.8809264094425484
Validation loss: 2.6012070444493274

Epoch: 5| Step: 7
Training loss: 3.189947497614439
Validation loss: 2.6027099018911035

Epoch: 5| Step: 8
Training loss: 2.4524888106624587
Validation loss: 2.602535447719943

Epoch: 5| Step: 9
Training loss: 2.2342104551109436
Validation loss: 2.602181984248232

Epoch: 5| Step: 10
Training loss: 2.9636464471959285
Validation loss: 2.5999103298374338

Epoch: 5| Step: 11
Training loss: 2.8353200192952484
Validation loss: 2.608589663316226

Epoch: 68| Step: 0
Training loss: 2.942123021793312
Validation loss: 2.594541731417623

Epoch: 5| Step: 1
Training loss: 3.208775741658165
Validation loss: 2.594557690009487

Epoch: 5| Step: 2
Training loss: 2.925649235068222
Validation loss: 2.5954395291426926

Epoch: 5| Step: 3
Training loss: 2.7831144619923602
Validation loss: 2.597262539581824

Epoch: 5| Step: 4
Training loss: 2.289497724696485
Validation loss: 2.5997964976521835

Epoch: 5| Step: 5
Training loss: 2.758986355638934
Validation loss: 2.6046527803025796

Epoch: 5| Step: 6
Training loss: 3.0211052783147316
Validation loss: 2.6037136955495574

Epoch: 5| Step: 7
Training loss: 2.356360726828336
Validation loss: 2.6012373903449486

Epoch: 5| Step: 8
Training loss: 2.4704002948676806
Validation loss: 2.598393756699353

Epoch: 5| Step: 9
Training loss: 2.575241047956118
Validation loss: 2.59445381956451

Epoch: 5| Step: 10
Training loss: 2.7089341206416973
Validation loss: 2.5867163415895873

Epoch: 5| Step: 11
Training loss: 2.238995449768595
Validation loss: 2.590153437338285

Epoch: 69| Step: 0
Training loss: 3.234824034254842
Validation loss: 2.5890789868680324

Epoch: 5| Step: 1
Training loss: 2.8188085376556615
Validation loss: 2.5888354571592505

Epoch: 5| Step: 2
Training loss: 2.7818908810253298
Validation loss: 2.590883973402707

Epoch: 5| Step: 3
Training loss: 2.787175499199177
Validation loss: 2.5901739639726156

Epoch: 5| Step: 4
Training loss: 2.4585431758308247
Validation loss: 2.5908179198655557

Epoch: 5| Step: 5
Training loss: 2.4467557602788563
Validation loss: 2.59026970676009

Epoch: 5| Step: 6
Training loss: 2.768812422554609
Validation loss: 2.592150919117498

Epoch: 5| Step: 7
Training loss: 2.4473660654705394
Validation loss: 2.5892616641990074

Epoch: 5| Step: 8
Training loss: 2.9516038963440008
Validation loss: 2.5873423330212244

Epoch: 5| Step: 9
Training loss: 2.462469393157517
Validation loss: 2.5842035555756597

Epoch: 5| Step: 10
Training loss: 2.713913924345672
Validation loss: 2.581387549731032

Epoch: 5| Step: 11
Training loss: 2.908961354156006
Validation loss: 2.5777813692063307

Epoch: 70| Step: 0
Training loss: 2.514259583860704
Validation loss: 2.5752924492263016

Epoch: 5| Step: 1
Training loss: 3.1296161889166534
Validation loss: 2.573770807295451

Epoch: 5| Step: 2
Training loss: 2.742791611947325
Validation loss: 2.5797287817335435

Epoch: 5| Step: 3
Training loss: 2.9685434369955077
Validation loss: 2.5711362421231163

Epoch: 5| Step: 4
Training loss: 2.4911887340984276
Validation loss: 2.5780715089123127

Epoch: 5| Step: 5
Training loss: 2.7784759746046173
Validation loss: 2.569843210745351

Epoch: 5| Step: 6
Training loss: 2.979425770267188
Validation loss: 2.571521683314651

Epoch: 5| Step: 7
Training loss: 2.2431572601387937
Validation loss: 2.5697838723742654

Epoch: 5| Step: 8
Training loss: 2.7403246864015687
Validation loss: 2.569415943886947

Epoch: 5| Step: 9
Training loss: 2.8377556975516436
Validation loss: 2.568847973355905

Epoch: 5| Step: 10
Training loss: 2.4411294764990887
Validation loss: 2.5660854237773334

Epoch: 5| Step: 11
Training loss: 1.7429915826345834
Validation loss: 2.567388419184724

Epoch: 71| Step: 0
Training loss: 2.4444693674878453
Validation loss: 2.564165574256318

Epoch: 5| Step: 1
Training loss: 2.672971533918099
Validation loss: 2.5675809969224126

Epoch: 5| Step: 2
Training loss: 2.1576920262321773
Validation loss: 2.563954921110654

Epoch: 5| Step: 3
Training loss: 2.535175529136295
Validation loss: 2.5640798714975466

Epoch: 5| Step: 4
Training loss: 2.863544030510593
Validation loss: 2.5647329006899846

Epoch: 5| Step: 5
Training loss: 2.858741731819369
Validation loss: 2.563588891853148

Epoch: 5| Step: 6
Training loss: 2.572821879217482
Validation loss: 2.566424702152707

Epoch: 5| Step: 7
Training loss: 2.9475429194644414
Validation loss: 2.565016793765539

Epoch: 5| Step: 8
Training loss: 3.1503753377942023
Validation loss: 2.5617347753236235

Epoch: 5| Step: 9
Training loss: 2.378713214728157
Validation loss: 2.5624511217867596

Epoch: 5| Step: 10
Training loss: 3.0342295052938724
Validation loss: 2.5596299885538216

Epoch: 5| Step: 11
Training loss: 2.070970308416097
Validation loss: 2.557862050503382

Epoch: 72| Step: 0
Training loss: 2.8488284865410094
Validation loss: 2.557253160724159

Epoch: 5| Step: 1
Training loss: 2.8565723462671144
Validation loss: 2.5612419032844986

Epoch: 5| Step: 2
Training loss: 2.9442834650175054
Validation loss: 2.555785095979383

Epoch: 5| Step: 3
Training loss: 2.5091003723745096
Validation loss: 2.5581894261479814

Epoch: 5| Step: 4
Training loss: 2.7617281599302648
Validation loss: 2.5533245078756863

Epoch: 5| Step: 5
Training loss: 2.447965407731729
Validation loss: 2.555440097742675

Epoch: 5| Step: 6
Training loss: 2.7558792729946964
Validation loss: 2.5517966453263203

Epoch: 5| Step: 7
Training loss: 2.6739997669353968
Validation loss: 2.5549633993163705

Epoch: 5| Step: 8
Training loss: 2.2727346480856783
Validation loss: 2.550125181796811

Epoch: 5| Step: 9
Training loss: 2.669688797148575
Validation loss: 2.5536404796287213

Epoch: 5| Step: 10
Training loss: 2.849754952051696
Validation loss: 2.547920262190454

Epoch: 5| Step: 11
Training loss: 2.306388718483042
Validation loss: 2.5469601544769493

Epoch: 73| Step: 0
Training loss: 2.487835758878201
Validation loss: 2.547175953251964

Epoch: 5| Step: 1
Training loss: 2.867087879581078
Validation loss: 2.5491415988113144

Epoch: 5| Step: 2
Training loss: 2.808539929888974
Validation loss: 2.5470221892342497

Epoch: 5| Step: 3
Training loss: 2.676517758326746
Validation loss: 2.547482053495714

Epoch: 5| Step: 4
Training loss: 2.431908870746442
Validation loss: 2.548356645222584

Epoch: 5| Step: 5
Training loss: 2.520519258043802
Validation loss: 2.548020154161907

Epoch: 5| Step: 6
Training loss: 2.5879196453266715
Validation loss: 2.5447401448823594

Epoch: 5| Step: 7
Training loss: 2.366324188633174
Validation loss: 2.5467683383629285

Epoch: 5| Step: 8
Training loss: 3.318588275884254
Validation loss: 2.543212542979851

Epoch: 5| Step: 9
Training loss: 2.3908608513470937
Validation loss: 2.5473486298065473

Epoch: 5| Step: 10
Training loss: 2.759861689985852
Validation loss: 2.5452160883551147

Epoch: 5| Step: 11
Training loss: 3.084907301834706
Validation loss: 2.5471089924545836

Epoch: 74| Step: 0
Training loss: 2.3673150056548318
Validation loss: 2.544706615089036

Epoch: 5| Step: 1
Training loss: 2.914206820843936
Validation loss: 2.542199178058082

Epoch: 5| Step: 2
Training loss: 2.758912383167393
Validation loss: 2.543727587695664

Epoch: 5| Step: 3
Training loss: 2.557904099564399
Validation loss: 2.5464400113052688

Epoch: 5| Step: 4
Training loss: 2.623077233338375
Validation loss: 2.5421227230985877

Epoch: 5| Step: 5
Training loss: 2.9343722309916047
Validation loss: 2.542022886614788

Epoch: 5| Step: 6
Training loss: 2.770338793531366
Validation loss: 2.5431018175349904

Epoch: 5| Step: 7
Training loss: 2.955081352237167
Validation loss: 2.544177559607392

Epoch: 5| Step: 8
Training loss: 2.4343101953149193
Validation loss: 2.542349396661591

Epoch: 5| Step: 9
Training loss: 2.3696676927493563
Validation loss: 2.5387537294100917

Epoch: 5| Step: 10
Training loss: 2.8544028154307965
Validation loss: 2.534868652143678

Epoch: 5| Step: 11
Training loss: 1.1699004768363437
Validation loss: 2.5381427527117357

Epoch: 75| Step: 0
Training loss: 2.523604349106182
Validation loss: 2.5356271949967306

Epoch: 5| Step: 1
Training loss: 2.504620859231699
Validation loss: 2.5346207016307694

Epoch: 5| Step: 2
Training loss: 2.4511744039454086
Validation loss: 2.5411038804909327

Epoch: 5| Step: 3
Training loss: 2.8064342786609338
Validation loss: 2.5415992076447287

Epoch: 5| Step: 4
Training loss: 3.0317050552943576
Validation loss: 2.5377649444544907

Epoch: 5| Step: 5
Training loss: 2.8844082352034657
Validation loss: 2.533636232095025

Epoch: 5| Step: 6
Training loss: 2.72163553684588
Validation loss: 2.5307231598132667

Epoch: 5| Step: 7
Training loss: 2.5760902467047773
Validation loss: 2.5299826223859703

Epoch: 5| Step: 8
Training loss: 2.301133030162242
Validation loss: 2.532686606841111

Epoch: 5| Step: 9
Training loss: 2.7633318688542525
Validation loss: 2.533954827458001

Epoch: 5| Step: 10
Training loss: 2.6528102369025826
Validation loss: 2.537418498373076

Epoch: 5| Step: 11
Training loss: 3.0032339149755023
Validation loss: 2.5411934503273144

Epoch: 76| Step: 0
Training loss: 2.908670381473556
Validation loss: 2.540664605601881

Epoch: 5| Step: 1
Training loss: 2.6353492175330486
Validation loss: 2.540071875626574

Epoch: 5| Step: 2
Training loss: 2.745014700372519
Validation loss: 2.53928960322493

Epoch: 5| Step: 3
Training loss: 2.380489329996215
Validation loss: 2.537368608464896

Epoch: 5| Step: 4
Training loss: 2.984997749263867
Validation loss: 2.536692486450719

Epoch: 5| Step: 5
Training loss: 2.451014686194956
Validation loss: 2.534366353338114

Epoch: 5| Step: 6
Training loss: 2.323666700949874
Validation loss: 2.5349473009958294

Epoch: 5| Step: 7
Training loss: 3.01498738401693
Validation loss: 2.5344039670744585

Epoch: 5| Step: 8
Training loss: 2.63306369205781
Validation loss: 2.531695169776433

Epoch: 5| Step: 9
Training loss: 2.340269836452555
Validation loss: 2.5307303746931

Epoch: 5| Step: 10
Training loss: 2.60818381160243
Validation loss: 2.5271597337822866

Epoch: 5| Step: 11
Training loss: 3.358466588887601
Validation loss: 2.5231125841897533

Epoch: 77| Step: 0
Training loss: 2.8416706909270517
Validation loss: 2.5244343995997376

Epoch: 5| Step: 1
Training loss: 2.8677843184726832
Validation loss: 2.5242995412639164

Epoch: 5| Step: 2
Training loss: 2.7919569196738507
Validation loss: 2.5236610376575483

Epoch: 5| Step: 3
Training loss: 2.6801250311879654
Validation loss: 2.5234773355180105

Epoch: 5| Step: 4
Training loss: 2.20136748208897
Validation loss: 2.5229040946195704

Epoch: 5| Step: 5
Training loss: 2.0802264380077067
Validation loss: 2.5206571246791922

Epoch: 5| Step: 6
Training loss: 2.960085139725516
Validation loss: 2.517265957462666

Epoch: 5| Step: 7
Training loss: 2.7203378534861025
Validation loss: 2.5175244523180114

Epoch: 5| Step: 8
Training loss: 2.8140521534883622
Validation loss: 2.5172830018535253

Epoch: 5| Step: 9
Training loss: 2.48998045580444
Validation loss: 2.5211103828290518

Epoch: 5| Step: 10
Training loss: 2.5176966885628986
Validation loss: 2.5204845507697615

Epoch: 5| Step: 11
Training loss: 3.0251496270115474
Validation loss: 2.520974322125336

Epoch: 78| Step: 0
Training loss: 2.8315863740017924
Validation loss: 2.51844932727251

Epoch: 5| Step: 1
Training loss: 2.543612490974587
Validation loss: 2.5156463874871275

Epoch: 5| Step: 2
Training loss: 2.572199352108721
Validation loss: 2.5207335016223396

Epoch: 5| Step: 3
Training loss: 2.3606695198545293
Validation loss: 2.5170435213302973

Epoch: 5| Step: 4
Training loss: 2.3898962568168454
Validation loss: 2.517239058740251

Epoch: 5| Step: 5
Training loss: 3.037561825723515
Validation loss: 2.518021506288365

Epoch: 5| Step: 6
Training loss: 2.518149300025079
Validation loss: 2.517032517804967

Epoch: 5| Step: 7
Training loss: 2.423107399708073
Validation loss: 2.512466776092027

Epoch: 5| Step: 8
Training loss: 3.0499660364980303
Validation loss: 2.51603571380301

Epoch: 5| Step: 9
Training loss: 2.444342472617862
Validation loss: 2.5117441930515487

Epoch: 5| Step: 10
Training loss: 2.932392956535342
Validation loss: 2.5121747478539964

Epoch: 5| Step: 11
Training loss: 1.8557131957606068
Validation loss: 2.514374380640252

Epoch: 79| Step: 0
Training loss: 2.645502134804954
Validation loss: 2.5127937662322695

Epoch: 5| Step: 1
Training loss: 2.7033200055823556
Validation loss: 2.5081928673782836

Epoch: 5| Step: 2
Training loss: 2.755239869906549
Validation loss: 2.506021333348173

Epoch: 5| Step: 3
Training loss: 2.708445874345702
Validation loss: 2.5108369987170684

Epoch: 5| Step: 4
Training loss: 2.7260988382289915
Validation loss: 2.5076367484013473

Epoch: 5| Step: 5
Training loss: 2.8722736866429432
Validation loss: 2.512027418946704

Epoch: 5| Step: 6
Training loss: 2.2263237005304184
Validation loss: 2.51266274280989

Epoch: 5| Step: 7
Training loss: 2.753877160750622
Validation loss: 2.51079651951719

Epoch: 5| Step: 8
Training loss: 2.8525955628177164
Validation loss: 2.5063249963652243

Epoch: 5| Step: 9
Training loss: 2.3296781134208433
Validation loss: 2.506893591718733

Epoch: 5| Step: 10
Training loss: 2.3795433757216777
Validation loss: 2.5109942960141365

Epoch: 5| Step: 11
Training loss: 2.665388387037368
Validation loss: 2.5099961388952137

Epoch: 80| Step: 0
Training loss: 3.1416798808041704
Validation loss: 2.512042134035131

Epoch: 5| Step: 1
Training loss: 2.6003799270930146
Validation loss: 2.5072302276021117

Epoch: 5| Step: 2
Training loss: 2.6364149130495376
Validation loss: 2.5089635297081663

Epoch: 5| Step: 3
Training loss: 2.6493800463744255
Validation loss: 2.509000273104841

Epoch: 5| Step: 4
Training loss: 2.6297445561910857
Validation loss: 2.5070388765299323

Epoch: 5| Step: 5
Training loss: 2.750567984446221
Validation loss: 2.506832993132533

Epoch: 5| Step: 6
Training loss: 2.8865195323046016
Validation loss: 2.5082688357107523

Epoch: 5| Step: 7
Training loss: 2.174081025060435
Validation loss: 2.5059711117212164

Epoch: 5| Step: 8
Training loss: 2.737401366525391
Validation loss: 2.5002478953481293

Epoch: 5| Step: 9
Training loss: 2.3671864928189894
Validation loss: 2.505045004508286

Epoch: 5| Step: 10
Training loss: 2.329652221330702
Validation loss: 2.5028978639212545

Epoch: 5| Step: 11
Training loss: 2.3161423325360273
Validation loss: 2.5012805361252397

Epoch: 81| Step: 0
Training loss: 2.54509228057536
Validation loss: 2.5023763885735564

Epoch: 5| Step: 1
Training loss: 2.8174632042798184
Validation loss: 2.5046781043568354

Epoch: 5| Step: 2
Training loss: 2.7982329582977554
Validation loss: 2.5069435293689675

Epoch: 5| Step: 3
Training loss: 2.709132756334187
Validation loss: 2.5011521902982357

Epoch: 5| Step: 4
Training loss: 2.5171256002704
Validation loss: 2.4975331692661613

Epoch: 5| Step: 5
Training loss: 3.088098469542831
Validation loss: 2.5011739755947655

Epoch: 5| Step: 6
Training loss: 2.861772876324483
Validation loss: 2.5020048407620368

Epoch: 5| Step: 7
Training loss: 2.3448636270329932
Validation loss: 2.4977595740949248

Epoch: 5| Step: 8
Training loss: 2.4303045439911823
Validation loss: 2.502365872367408

Epoch: 5| Step: 9
Training loss: 2.353185252194616
Validation loss: 2.498327383159841

Epoch: 5| Step: 10
Training loss: 2.416737478687653
Validation loss: 2.495165732471992

Epoch: 5| Step: 11
Training loss: 1.9249913450764875
Validation loss: 2.4952215383150045

Epoch: 82| Step: 0
Training loss: 2.675058888295203
Validation loss: 2.495982538252103

Epoch: 5| Step: 1
Training loss: 2.6899667109588727
Validation loss: 2.497061997828579

Epoch: 5| Step: 2
Training loss: 2.5773826686375583
Validation loss: 2.494114245596609

Epoch: 5| Step: 3
Training loss: 3.0553883092557834
Validation loss: 2.494250596583609

Epoch: 5| Step: 4
Training loss: 2.2222554628217286
Validation loss: 2.495456811294626

Epoch: 5| Step: 5
Training loss: 2.5753252953543733
Validation loss: 2.4923768066289247

Epoch: 5| Step: 6
Training loss: 2.172175983458245
Validation loss: 2.4930555492095334

Epoch: 5| Step: 7
Training loss: 2.6344489832724203
Validation loss: 2.493765579500029

Epoch: 5| Step: 8
Training loss: 2.6140426644110235
Validation loss: 2.4890721859117884

Epoch: 5| Step: 9
Training loss: 2.924548552797662
Validation loss: 2.495249239717457

Epoch: 5| Step: 10
Training loss: 2.540924234821269
Validation loss: 2.490970529689757

Epoch: 5| Step: 11
Training loss: 2.3229234179297444
Validation loss: 2.491527095179346

Epoch: 83| Step: 0
Training loss: 2.707924083209052
Validation loss: 2.4922382465166653

Epoch: 5| Step: 1
Training loss: 2.6671713311767347
Validation loss: 2.499839074200613

Epoch: 5| Step: 2
Training loss: 2.4281933474157453
Validation loss: 2.5070633645763127

Epoch: 5| Step: 3
Training loss: 2.5883930452741777
Validation loss: 2.4999409787840428

Epoch: 5| Step: 4
Training loss: 2.147471817773142
Validation loss: 2.489853741845505

Epoch: 5| Step: 5
Training loss: 2.608001713091048
Validation loss: 2.4936216606571486

Epoch: 5| Step: 6
Training loss: 2.93104981346841
Validation loss: 2.4851564142122586

Epoch: 5| Step: 7
Training loss: 2.515887608060102
Validation loss: 2.494062714740218

Epoch: 5| Step: 8
Training loss: 2.7359554410005256
Validation loss: 2.496984347804516

Epoch: 5| Step: 9
Training loss: 2.456052648949204
Validation loss: 2.4958874851544426

Epoch: 5| Step: 10
Training loss: 2.886104203445283
Validation loss: 2.497417224451658

Epoch: 5| Step: 11
Training loss: 2.750295969901804
Validation loss: 2.4977226056800483

Epoch: 84| Step: 0
Training loss: 2.1890900418865407
Validation loss: 2.501825333844894

Epoch: 5| Step: 1
Training loss: 3.0013095858377397
Validation loss: 2.5032486788594674

Epoch: 5| Step: 2
Training loss: 3.0261694421016103
Validation loss: 2.5039290706330544

Epoch: 5| Step: 3
Training loss: 2.058818073826462
Validation loss: 2.5026101870800144

Epoch: 5| Step: 4
Training loss: 2.178459450481596
Validation loss: 2.497848813076834

Epoch: 5| Step: 5
Training loss: 2.7980168744792455
Validation loss: 2.501761411994407

Epoch: 5| Step: 6
Training loss: 2.3461179850797254
Validation loss: 2.49908973096098

Epoch: 5| Step: 7
Training loss: 2.457084812860128
Validation loss: 2.4975723599340087

Epoch: 5| Step: 8
Training loss: 3.109709141858841
Validation loss: 2.495492575240333

Epoch: 5| Step: 9
Training loss: 2.6190944727302568
Validation loss: 2.492851001585158

Epoch: 5| Step: 10
Training loss: 2.712708787749354
Validation loss: 2.4912970256498217

Epoch: 5| Step: 11
Training loss: 2.917831478949869
Validation loss: 2.491126277994909

Epoch: 85| Step: 0
Training loss: 2.3886014065520276
Validation loss: 2.4878904753429554

Epoch: 5| Step: 1
Training loss: 2.5213618289353295
Validation loss: 2.487733400359812

Epoch: 5| Step: 2
Training loss: 2.252797189428462
Validation loss: 2.4855862909477344

Epoch: 5| Step: 3
Training loss: 2.6891018728846
Validation loss: 2.505320664793362

Epoch: 5| Step: 4
Training loss: 2.4484257486593295
Validation loss: 2.504439691384448

Epoch: 5| Step: 5
Training loss: 3.0953214103189204
Validation loss: 2.5099040150368865

Epoch: 5| Step: 6
Training loss: 2.9660326919657463
Validation loss: 2.4979917645930767

Epoch: 5| Step: 7
Training loss: 3.0287037015958735
Validation loss: 2.4885242728744137

Epoch: 5| Step: 8
Training loss: 2.5764160040576436
Validation loss: 2.482048320701554

Epoch: 5| Step: 9
Training loss: 2.2561301328989662
Validation loss: 2.4851164161346224

Epoch: 5| Step: 10
Training loss: 2.4907577383550445
Validation loss: 2.485587533916711

Epoch: 5| Step: 11
Training loss: 2.435216763539707
Validation loss: 2.49085095719575

Epoch: 86| Step: 0
Training loss: 2.8816686495731285
Validation loss: 2.484802537194242

Epoch: 5| Step: 1
Training loss: 2.979978028542852
Validation loss: 2.486878862738296

Epoch: 5| Step: 2
Training loss: 2.6338946102437535
Validation loss: 2.4861728872465294

Epoch: 5| Step: 3
Training loss: 2.3687565705301354
Validation loss: 2.488250456758693

Epoch: 5| Step: 4
Training loss: 2.8982608052400027
Validation loss: 2.487061241886008

Epoch: 5| Step: 5
Training loss: 2.365672920578198
Validation loss: 2.4888295278738726

Epoch: 5| Step: 6
Training loss: 2.0040862539844495
Validation loss: 2.4892369206218907

Epoch: 5| Step: 7
Training loss: 2.5484702140350257
Validation loss: 2.4858574073304407

Epoch: 5| Step: 8
Training loss: 2.5440191627956317
Validation loss: 2.482634304430685

Epoch: 5| Step: 9
Training loss: 2.826266526414754
Validation loss: 2.4808902572578098

Epoch: 5| Step: 10
Training loss: 2.7020882619451565
Validation loss: 2.47954089014361

Epoch: 5| Step: 11
Training loss: 1.4693136554018817
Validation loss: 2.4797842848569966

Epoch: 87| Step: 0
Training loss: 2.7159986934630633
Validation loss: 2.481804393502705

Epoch: 5| Step: 1
Training loss: 2.749681194205846
Validation loss: 2.4833767122815225

Epoch: 5| Step: 2
Training loss: 2.6328644789819813
Validation loss: 2.4795055972489535

Epoch: 5| Step: 3
Training loss: 2.098415130927754
Validation loss: 2.4830314274032044

Epoch: 5| Step: 4
Training loss: 2.8849424851632994
Validation loss: 2.483236895892604

Epoch: 5| Step: 5
Training loss: 2.6981439286081206
Validation loss: 2.4796815318865266

Epoch: 5| Step: 6
Training loss: 2.3091463050600773
Validation loss: 2.482719909721219

Epoch: 5| Step: 7
Training loss: 2.1840136402388866
Validation loss: 2.479720556002369

Epoch: 5| Step: 8
Training loss: 3.1799970096598065
Validation loss: 2.4797044472615046

Epoch: 5| Step: 9
Training loss: 1.9659087250749785
Validation loss: 2.4821490306163256

Epoch: 5| Step: 10
Training loss: 2.8625400723646743
Validation loss: 2.4758852605297177

Epoch: 5| Step: 11
Training loss: 3.2440813898584415
Validation loss: 2.479672854435759

Epoch: 88| Step: 0
Training loss: 2.9098455685671976
Validation loss: 2.484344766140954

Epoch: 5| Step: 1
Training loss: 2.7618163009313874
Validation loss: 2.4831525246084993

Epoch: 5| Step: 2
Training loss: 1.961791806093119
Validation loss: 2.4887207377725407

Epoch: 5| Step: 3
Training loss: 2.5359011644544327
Validation loss: 2.487401985588875

Epoch: 5| Step: 4
Training loss: 3.0861819399826067
Validation loss: 2.489709062208005

Epoch: 5| Step: 5
Training loss: 2.7325644466132943
Validation loss: 2.492847909193287

Epoch: 5| Step: 6
Training loss: 3.2035230435798443
Validation loss: 2.493188300328095

Epoch: 5| Step: 7
Training loss: 2.383765558473075
Validation loss: 2.493296566789227

Epoch: 5| Step: 8
Training loss: 2.2568810465458866
Validation loss: 2.4907280246896377

Epoch: 5| Step: 9
Training loss: 2.566016505823842
Validation loss: 2.4889107331621068

Epoch: 5| Step: 10
Training loss: 2.055598184069091
Validation loss: 2.4842998205361995

Epoch: 5| Step: 11
Training loss: 2.3448166518120845
Validation loss: 2.485490492539405

Epoch: 89| Step: 0
Training loss: 2.834385302607981
Validation loss: 2.4810008982540546

Epoch: 5| Step: 1
Training loss: 2.601625000715542
Validation loss: 2.477898555221382

Epoch: 5| Step: 2
Training loss: 2.154999964950809
Validation loss: 2.4802060526314387

Epoch: 5| Step: 3
Training loss: 2.3791604994534152
Validation loss: 2.471889334732332

Epoch: 5| Step: 4
Training loss: 2.718691244257796
Validation loss: 2.4771015892179555

Epoch: 5| Step: 5
Training loss: 2.7840543174816093
Validation loss: 2.4741281083060693

Epoch: 5| Step: 6
Training loss: 2.836407919295734
Validation loss: 2.4724871440510796

Epoch: 5| Step: 7
Training loss: 2.448283769933816
Validation loss: 2.4761707304902587

Epoch: 5| Step: 8
Training loss: 2.6272658605086834
Validation loss: 2.475574948338503

Epoch: 5| Step: 9
Training loss: 2.736747192269862
Validation loss: 2.4788036574870476

Epoch: 5| Step: 10
Training loss: 2.346966888213666
Validation loss: 2.475171983407707

Epoch: 5| Step: 11
Training loss: 2.5837741803798866
Validation loss: 2.4684455901198206

Epoch: 90| Step: 0
Training loss: 2.6415944323205527
Validation loss: 2.4722614083565806

Epoch: 5| Step: 1
Training loss: 2.2444477452147904
Validation loss: 2.473616696242602

Epoch: 5| Step: 2
Training loss: 2.7626187639900923
Validation loss: 2.4770385773970536

Epoch: 5| Step: 3
Training loss: 2.8331631628058553
Validation loss: 2.4805229321266684

Epoch: 5| Step: 4
Training loss: 2.5426429270253044
Validation loss: 2.4724449641958826

Epoch: 5| Step: 5
Training loss: 2.6469313578364937
Validation loss: 2.4735231692751514

Epoch: 5| Step: 6
Training loss: 3.166151774524742
Validation loss: 2.4655582341581255

Epoch: 5| Step: 7
Training loss: 2.6311437372420063
Validation loss: 2.470653299223793

Epoch: 5| Step: 8
Training loss: 2.1661617962401225
Validation loss: 2.475944209210294

Epoch: 5| Step: 9
Training loss: 2.606317613488496
Validation loss: 2.482612656556251

Epoch: 5| Step: 10
Training loss: 2.3055316995308273
Validation loss: 2.4812771178332316

Epoch: 5| Step: 11
Training loss: 1.5044514250033805
Validation loss: 2.47402611221358

Epoch: 91| Step: 0
Training loss: 2.677202234460299
Validation loss: 2.4797689857547067

Epoch: 5| Step: 1
Training loss: 2.5884521796392717
Validation loss: 2.479063546149128

Epoch: 5| Step: 2
Training loss: 2.5815806031663104
Validation loss: 2.4801353731175753

Epoch: 5| Step: 3
Training loss: 2.5299142209314125
Validation loss: 2.4762722571340516

Epoch: 5| Step: 4
Training loss: 2.866117106108921
Validation loss: 2.4668311899214226

Epoch: 5| Step: 5
Training loss: 2.2799346476106477
Validation loss: 2.471698734285922

Epoch: 5| Step: 6
Training loss: 2.1975954613548825
Validation loss: 2.4774459482552564

Epoch: 5| Step: 7
Training loss: 2.395931164499417
Validation loss: 2.468249032742292

Epoch: 5| Step: 8
Training loss: 2.59514479304859
Validation loss: 2.467083118752039

Epoch: 5| Step: 9
Training loss: 3.007327825956292
Validation loss: 2.4710526491795957

Epoch: 5| Step: 10
Training loss: 2.8012787657677447
Validation loss: 2.465911291477301

Epoch: 5| Step: 11
Training loss: 1.616848011595242
Validation loss: 2.469692694071146

Epoch: 92| Step: 0
Training loss: 2.6159460966757115
Validation loss: 2.474053922446157

Epoch: 5| Step: 1
Training loss: 2.1895792207639952
Validation loss: 2.4714167673739693

Epoch: 5| Step: 2
Training loss: 2.2015283087843005
Validation loss: 2.473249833230412

Epoch: 5| Step: 3
Training loss: 2.8473719074217905
Validation loss: 2.475046538226899

Epoch: 5| Step: 4
Training loss: 2.5211316607367102
Validation loss: 2.4797248786235544

Epoch: 5| Step: 5
Training loss: 2.9691479867894857
Validation loss: 2.47611366480773

Epoch: 5| Step: 6
Training loss: 2.8374096961082897
Validation loss: 2.4771136483876557

Epoch: 5| Step: 7
Training loss: 2.4924813698212973
Validation loss: 2.477334466790697

Epoch: 5| Step: 8
Training loss: 2.7344363832395837
Validation loss: 2.47828020280874

Epoch: 5| Step: 9
Training loss: 2.3662679667730306
Validation loss: 2.480128952341093

Epoch: 5| Step: 10
Training loss: 2.7034419761429285
Validation loss: 2.471971799785288

Epoch: 5| Step: 11
Training loss: 1.9257879972823293
Validation loss: 2.468827161910976

Epoch: 93| Step: 0
Training loss: 2.0650258636702237
Validation loss: 2.462695391079112

Epoch: 5| Step: 1
Training loss: 2.6511916522233636
Validation loss: 2.4656224378500786

Epoch: 5| Step: 2
Training loss: 2.456325702616904
Validation loss: 2.46265325327566

Epoch: 5| Step: 3
Training loss: 2.457788008211967
Validation loss: 2.462322935041446

Epoch: 5| Step: 4
Training loss: 2.8148175333894834
Validation loss: 2.4670604002258805

Epoch: 5| Step: 5
Training loss: 2.3780199225692433
Validation loss: 2.4700495924842407

Epoch: 5| Step: 6
Training loss: 2.94059120020966
Validation loss: 2.4629211907906416

Epoch: 5| Step: 7
Training loss: 2.7545714961405254
Validation loss: 2.4669943212248704

Epoch: 5| Step: 8
Training loss: 2.34290440882213
Validation loss: 2.4641606008368786

Epoch: 5| Step: 9
Training loss: 2.564500725472166
Validation loss: 2.464309654669114

Epoch: 5| Step: 10
Training loss: 2.8167992686672934
Validation loss: 2.4703360585185794

Epoch: 5| Step: 11
Training loss: 2.565077625014704
Validation loss: 2.4627236681018285

Epoch: 94| Step: 0
Training loss: 2.148826314248919
Validation loss: 2.4641528644977213

Epoch: 5| Step: 1
Training loss: 2.728170450887231
Validation loss: 2.469895943931826

Epoch: 5| Step: 2
Training loss: 2.567472332263956
Validation loss: 2.460902505454262

Epoch: 5| Step: 3
Training loss: 2.9037330146782137
Validation loss: 2.459499015411885

Epoch: 5| Step: 4
Training loss: 2.568999630569782
Validation loss: 2.4694885002409643

Epoch: 5| Step: 5
Training loss: 2.6732374142049333
Validation loss: 2.465701011063027

Epoch: 5| Step: 6
Training loss: 2.5166420154332627
Validation loss: 2.4649338380821266

Epoch: 5| Step: 7
Training loss: 2.3231802022521264
Validation loss: 2.469064736725155

Epoch: 5| Step: 8
Training loss: 2.820633043158957
Validation loss: 2.470876486102838

Epoch: 5| Step: 9
Training loss: 2.659274634362373
Validation loss: 2.4726555107641897

Epoch: 5| Step: 10
Training loss: 2.5245154000755283
Validation loss: 2.4715512876746253

Epoch: 5| Step: 11
Training loss: 1.7008190818437505
Validation loss: 2.470804458168538

Epoch: 95| Step: 0
Training loss: 2.9690334787045525
Validation loss: 2.4732057905879175

Epoch: 5| Step: 1
Training loss: 2.8020240654521156
Validation loss: 2.473223447905671

Epoch: 5| Step: 2
Training loss: 1.8995331165492508
Validation loss: 2.4762156912557773

Epoch: 5| Step: 3
Training loss: 2.0693921616654025
Validation loss: 2.4764339241161384

Epoch: 5| Step: 4
Training loss: 2.43990969756575
Validation loss: 2.4755724543518425

Epoch: 5| Step: 5
Training loss: 2.297016995770258
Validation loss: 2.4702554691752048

Epoch: 5| Step: 6
Training loss: 2.159963533658807
Validation loss: 2.4699995041665264

Epoch: 5| Step: 7
Training loss: 2.5548127403241434
Validation loss: 2.4654599209033514

Epoch: 5| Step: 8
Training loss: 2.899737372509588
Validation loss: 2.4651870004897964

Epoch: 5| Step: 9
Training loss: 2.920286675058866
Validation loss: 2.464834657582774

Epoch: 5| Step: 10
Training loss: 2.9724696899100724
Validation loss: 2.4601739738425956

Epoch: 5| Step: 11
Training loss: 2.5569552467675627
Validation loss: 2.4651587517231532

Epoch: 96| Step: 0
Training loss: 2.185352906593116
Validation loss: 2.4677440911779653

Epoch: 5| Step: 1
Training loss: 2.9834761139642487
Validation loss: 2.4605557019396898

Epoch: 5| Step: 2
Training loss: 2.4226171525434745
Validation loss: 2.462717423788653

Epoch: 5| Step: 3
Training loss: 2.4229429782041225
Validation loss: 2.454510477742144

Epoch: 5| Step: 4
Training loss: 2.851535577516316
Validation loss: 2.4595408518221906

Epoch: 5| Step: 5
Training loss: 2.4415778260022813
Validation loss: 2.462776227810679

Epoch: 5| Step: 6
Training loss: 2.5997451070406945
Validation loss: 2.4647361502157197

Epoch: 5| Step: 7
Training loss: 2.707098625632725
Validation loss: 2.4669341277948744

Epoch: 5| Step: 8
Training loss: 2.582174738649654
Validation loss: 2.473670506381549

Epoch: 5| Step: 9
Training loss: 2.5782208973937935
Validation loss: 2.4705600460877024

Epoch: 5| Step: 10
Training loss: 2.488754826248371
Validation loss: 2.4708330766078395

Epoch: 5| Step: 11
Training loss: 2.3497076989051617
Validation loss: 2.469736960255818

Epoch: 97| Step: 0
Training loss: 2.6359275252374528
Validation loss: 2.473743386551323

Epoch: 5| Step: 1
Training loss: 2.364304401453919
Validation loss: 2.469810205875633

Epoch: 5| Step: 2
Training loss: 2.6380622662186686
Validation loss: 2.4678882672296005

Epoch: 5| Step: 3
Training loss: 2.630126035302941
Validation loss: 2.4712520024869247

Epoch: 5| Step: 4
Training loss: 2.5641660159158444
Validation loss: 2.4699989732747896

Epoch: 5| Step: 5
Training loss: 2.622253707069921
Validation loss: 2.471202569672648

Epoch: 5| Step: 6
Training loss: 2.8223446950428857
Validation loss: 2.467543512403243

Epoch: 5| Step: 7
Training loss: 2.3146068151766737
Validation loss: 2.4657509409396567

Epoch: 5| Step: 8
Training loss: 2.5243940400559923
Validation loss: 2.4658595398656273

Epoch: 5| Step: 9
Training loss: 2.597510312218706
Validation loss: 2.4642387772171337

Epoch: 5| Step: 10
Training loss: 2.3653018100742407
Validation loss: 2.4576487126698554

Epoch: 5| Step: 11
Training loss: 3.4459203067183526
Validation loss: 2.45876313482544

Epoch: 98| Step: 0
Training loss: 2.3544001393182357
Validation loss: 2.461826975098116

Epoch: 5| Step: 1
Training loss: 2.5835855627492554
Validation loss: 2.464893769785931

Epoch: 5| Step: 2
Training loss: 2.83545052206628
Validation loss: 2.4651658320792293

Epoch: 5| Step: 3
Training loss: 2.6708221145687854
Validation loss: 2.4656639084769827

Epoch: 5| Step: 4
Training loss: 2.444314478781157
Validation loss: 2.4603231440273143

Epoch: 5| Step: 5
Training loss: 2.6813888264886834
Validation loss: 2.4633160394385003

Epoch: 5| Step: 6
Training loss: 2.6500953729129577
Validation loss: 2.4617354739182096

Epoch: 5| Step: 7
Training loss: 2.3314530312332957
Validation loss: 2.4661659124430426

Epoch: 5| Step: 8
Training loss: 2.652024712005829
Validation loss: 2.466676791166027

Epoch: 5| Step: 9
Training loss: 2.8409247144789673
Validation loss: 2.4666274599769844

Epoch: 5| Step: 10
Training loss: 2.4372971279131903
Validation loss: 2.465636192976474

Epoch: 5| Step: 11
Training loss: 1.6135332774302729
Validation loss: 2.4663353188913972

Epoch: 99| Step: 0
Training loss: 2.840773649281589
Validation loss: 2.4700908198693345

Epoch: 5| Step: 1
Training loss: 2.7332533797533936
Validation loss: 2.47317550855682

Epoch: 5| Step: 2
Training loss: 2.1608417658035073
Validation loss: 2.467401276938602

Epoch: 5| Step: 3
Training loss: 3.2465767070779963
Validation loss: 2.4624857719771995

Epoch: 5| Step: 4
Training loss: 1.9291004106364258
Validation loss: 2.4610385530906838

Epoch: 5| Step: 5
Training loss: 2.715057057295728
Validation loss: 2.4664221826634236

Epoch: 5| Step: 6
Training loss: 2.7115837448218127
Validation loss: 2.464347676586764

Epoch: 5| Step: 7
Training loss: 2.3510432382921187
Validation loss: 2.4641738924478065

Epoch: 5| Step: 8
Training loss: 2.32832468699782
Validation loss: 2.4618136223925546

Epoch: 5| Step: 9
Training loss: 2.413603112419987
Validation loss: 2.465960467796441

Epoch: 5| Step: 10
Training loss: 2.6091697749222216
Validation loss: 2.46370242577562

Epoch: 5| Step: 11
Training loss: 2.99766481431618
Validation loss: 2.4656029633768948

Epoch: 100| Step: 0
Training loss: 2.534446675784002
Validation loss: 2.462939547023377

Epoch: 5| Step: 1
Training loss: 2.710811732999918
Validation loss: 2.472428763854482

Epoch: 5| Step: 2
Training loss: 2.2860290425575847
Validation loss: 2.4758491431368874

Epoch: 5| Step: 3
Training loss: 2.511615662068493
Validation loss: 2.4727458124076134

Epoch: 5| Step: 4
Training loss: 2.3392701122466675
Validation loss: 2.465559835745295

Epoch: 5| Step: 5
Training loss: 2.541592226866548
Validation loss: 2.4710663017157963

Epoch: 5| Step: 6
Training loss: 2.5494598190513846
Validation loss: 2.470240119100498

Epoch: 5| Step: 7
Training loss: 2.907932409799681
Validation loss: 2.4650561306193794

Epoch: 5| Step: 8
Training loss: 3.2881279929371683
Validation loss: 2.457920849403107

Epoch: 5| Step: 9
Training loss: 2.062673156867803
Validation loss: 2.4528329436464804

Epoch: 5| Step: 10
Training loss: 2.3268452653770444
Validation loss: 2.4622378713251165

Epoch: 5| Step: 11
Training loss: 2.52599155861357
Validation loss: 2.4623989024766404

Epoch: 101| Step: 0
Training loss: 2.2052824670736673
Validation loss: 2.4540262692700203

Epoch: 5| Step: 1
Training loss: 3.051381070495445
Validation loss: 2.458733272886694

Epoch: 5| Step: 2
Training loss: 2.5695765406930815
Validation loss: 2.4627162378514162

Epoch: 5| Step: 3
Training loss: 2.357401243307605
Validation loss: 2.464924218042668

Epoch: 5| Step: 4
Training loss: 2.7622819943950034
Validation loss: 2.4734866258084733

Epoch: 5| Step: 5
Training loss: 2.489019886138178
Validation loss: 2.460718312669834

Epoch: 5| Step: 6
Training loss: 2.2656689869787088
Validation loss: 2.4609842245520404

Epoch: 5| Step: 7
Training loss: 2.9948856947138824
Validation loss: 2.45987270268158

Epoch: 5| Step: 8
Training loss: 2.1845887566624715
Validation loss: 2.4533779556511353

Epoch: 5| Step: 9
Training loss: 2.3122680135300153
Validation loss: 2.4597880025169556

Epoch: 5| Step: 10
Training loss: 2.7394310119598027
Validation loss: 2.44908463771534

Epoch: 5| Step: 11
Training loss: 2.9715171365848754
Validation loss: 2.4561989470750243

Epoch: 102| Step: 0
Training loss: 2.397013287987638
Validation loss: 2.455740593202341

Epoch: 5| Step: 1
Training loss: 2.2337650987214097
Validation loss: 2.4622705330896455

Epoch: 5| Step: 2
Training loss: 2.59757162544254
Validation loss: 2.4663606621942864

Epoch: 5| Step: 3
Training loss: 2.9743860653108123
Validation loss: 2.468963786819723

Epoch: 5| Step: 4
Training loss: 2.622153055316911
Validation loss: 2.4574654159686595

Epoch: 5| Step: 5
Training loss: 2.576826843803591
Validation loss: 2.458559229272749

Epoch: 5| Step: 6
Training loss: 2.4046001971225297
Validation loss: 2.461478725843404

Epoch: 5| Step: 7
Training loss: 2.681459691666732
Validation loss: 2.452991619655115

Epoch: 5| Step: 8
Training loss: 2.6675100085741956
Validation loss: 2.4651767971209875

Epoch: 5| Step: 9
Training loss: 2.6396946820079763
Validation loss: 2.4675384276740013

Epoch: 5| Step: 10
Training loss: 2.4953209004413037
Validation loss: 2.4659880749127163

Epoch: 5| Step: 11
Training loss: 2.1152227653262305
Validation loss: 2.4626806796380376

Epoch: 103| Step: 0
Training loss: 2.450515038986463
Validation loss: 2.4719878986359753

Epoch: 5| Step: 1
Training loss: 2.5539708430120274
Validation loss: 2.4718118544597827

Epoch: 5| Step: 2
Training loss: 2.6903914045597537
Validation loss: 2.471585862152251

Epoch: 5| Step: 3
Training loss: 2.396277234515189
Validation loss: 2.4645876663268806

Epoch: 5| Step: 4
Training loss: 2.7529414658093194
Validation loss: 2.4677612280232255

Epoch: 5| Step: 5
Training loss: 3.052527871594353
Validation loss: 2.4703783588288473

Epoch: 5| Step: 6
Training loss: 2.6210279840214756
Validation loss: 2.462721675409292

Epoch: 5| Step: 7
Training loss: 2.3364313426494676
Validation loss: 2.4674724097868936

Epoch: 5| Step: 8
Training loss: 2.479941484776167
Validation loss: 2.4600589576688514

Epoch: 5| Step: 9
Training loss: 2.650345106865489
Validation loss: 2.4538409368823904

Epoch: 5| Step: 10
Training loss: 2.1859806779110467
Validation loss: 2.450488068337598

Epoch: 5| Step: 11
Training loss: 2.260088027995173
Validation loss: 2.460305789825464

Epoch: 104| Step: 0
Training loss: 2.761976346057591
Validation loss: 2.457718749460118

Epoch: 5| Step: 1
Training loss: 2.571234726032888
Validation loss: 2.4593002928422845

Epoch: 5| Step: 2
Training loss: 2.8927083523816357
Validation loss: 2.459623880327324

Epoch: 5| Step: 3
Training loss: 2.535401507300699
Validation loss: 2.4530954824886884

Epoch: 5| Step: 4
Training loss: 2.5663187369140323
Validation loss: 2.4493860109559824

Epoch: 5| Step: 5
Training loss: 2.484261948034594
Validation loss: 2.4509145006317214

Epoch: 5| Step: 6
Training loss: 2.6657077932972335
Validation loss: 2.44984841656321

Epoch: 5| Step: 7
Training loss: 2.6344861786574456
Validation loss: 2.4499253384898076

Epoch: 5| Step: 8
Training loss: 3.0287526648395953
Validation loss: 2.457716801213722

Epoch: 5| Step: 9
Training loss: 1.8948842771720655
Validation loss: 2.462073371773662

Epoch: 5| Step: 10
Training loss: 2.219092436678381
Validation loss: 2.4682006305162005

Epoch: 5| Step: 11
Training loss: 2.400018823073006
Validation loss: 2.4633481364349556

Epoch: 105| Step: 0
Training loss: 2.136644658507473
Validation loss: 2.4624370063431327

Epoch: 5| Step: 1
Training loss: 2.272360110535816
Validation loss: 2.46046029363634

Epoch: 5| Step: 2
Training loss: 2.5059508071357715
Validation loss: 2.4651722313818523

Epoch: 5| Step: 3
Training loss: 2.656022634312116
Validation loss: 2.4602670149763775

Epoch: 5| Step: 4
Training loss: 3.103257952989169
Validation loss: 2.470600561292427

Epoch: 5| Step: 5
Training loss: 2.4704184386998223
Validation loss: 2.4669929158691866

Epoch: 5| Step: 6
Training loss: 2.575013381034379
Validation loss: 2.4699974288618165

Epoch: 5| Step: 7
Training loss: 2.373171755169632
Validation loss: 2.4633228911882696

Epoch: 5| Step: 8
Training loss: 2.544511412091411
Validation loss: 2.4629395792908597

Epoch: 5| Step: 9
Training loss: 2.504256630126244
Validation loss: 2.45745415780304

Epoch: 5| Step: 10
Training loss: 2.8945877543299825
Validation loss: 2.4560907461099193

Epoch: 5| Step: 11
Training loss: 2.7143303035716206
Validation loss: 2.4568722769004774

Epoch: 106| Step: 0
Training loss: 2.661775474291006
Validation loss: 2.447456386932209

Epoch: 5| Step: 1
Training loss: 2.428705243823744
Validation loss: 2.4497672586765784

Epoch: 5| Step: 2
Training loss: 2.830252674266966
Validation loss: 2.4519815999666186

Epoch: 5| Step: 3
Training loss: 3.041014527386202
Validation loss: 2.459556333294693

Epoch: 5| Step: 4
Training loss: 2.622552366361183
Validation loss: 2.4517147967539046

Epoch: 5| Step: 5
Training loss: 2.2433617471120795
Validation loss: 2.4571555368497893

Epoch: 5| Step: 6
Training loss: 1.9613647603387685
Validation loss: 2.4571657937414075

Epoch: 5| Step: 7
Training loss: 2.5952041410439
Validation loss: 2.4649198533454375

Epoch: 5| Step: 8
Training loss: 2.256394307179092
Validation loss: 2.463477830819221

Epoch: 5| Step: 9
Training loss: 2.61515952723247
Validation loss: 2.468108633081621

Epoch: 5| Step: 10
Training loss: 2.9231267685443387
Validation loss: 2.4682285184605144

Epoch: 5| Step: 11
Training loss: 1.8416870990615124
Validation loss: 2.473191736140484

Epoch: 107| Step: 0
Training loss: 2.7237600882887407
Validation loss: 2.4646256839556293

Epoch: 5| Step: 1
Training loss: 2.394964430988883
Validation loss: 2.4666946683939583

Epoch: 5| Step: 2
Training loss: 2.5471868031612788
Validation loss: 2.4736995053000923

Epoch: 5| Step: 3
Training loss: 2.6317140002480444
Validation loss: 2.470555494318145

Epoch: 5| Step: 4
Training loss: 2.0920995783547096
Validation loss: 2.4637315944395084

Epoch: 5| Step: 5
Training loss: 2.775989658424397
Validation loss: 2.4630085783021873

Epoch: 5| Step: 6
Training loss: 2.425780955144155
Validation loss: 2.4664463409300694

Epoch: 5| Step: 7
Training loss: 2.4902468213537
Validation loss: 2.4611886395874345

Epoch: 5| Step: 8
Training loss: 2.6483683619294256
Validation loss: 2.454055727009341

Epoch: 5| Step: 9
Training loss: 2.502255661932761
Validation loss: 2.4546079911294134

Epoch: 5| Step: 10
Training loss: 2.9293583799508855
Validation loss: 2.45459135333864

Epoch: 5| Step: 11
Training loss: 2.10312342197308
Validation loss: 2.4530416907805623

Epoch: 108| Step: 0
Training loss: 2.8149198506465445
Validation loss: 2.4487289839461477

Epoch: 5| Step: 1
Training loss: 2.513685343483245
Validation loss: 2.4463382799752003

Epoch: 5| Step: 2
Training loss: 2.3294495776422877
Validation loss: 2.451680132489423

Epoch: 5| Step: 3
Training loss: 2.8056231030011407
Validation loss: 2.4405106470896607

Epoch: 5| Step: 4
Training loss: 2.5557469962004546
Validation loss: 2.4454134309879105

Epoch: 5| Step: 5
Training loss: 2.6016619322507872
Validation loss: 2.4500738676120197

Epoch: 5| Step: 6
Training loss: 2.843857815553627
Validation loss: 2.453337775557667

Epoch: 5| Step: 7
Training loss: 2.407462074876315
Validation loss: 2.457853712288909

Epoch: 5| Step: 8
Training loss: 2.1124992686614625
Validation loss: 2.451968205800458

Epoch: 5| Step: 9
Training loss: 2.52431338199858
Validation loss: 2.455461745738147

Epoch: 5| Step: 10
Training loss: 2.5914976152765665
Validation loss: 2.4498723124946373

Epoch: 5| Step: 11
Training loss: 1.9974389964732235
Validation loss: 2.456008212975118

Epoch: 109| Step: 0
Training loss: 2.690614714032404
Validation loss: 2.4545595263188558

Epoch: 5| Step: 1
Training loss: 2.0357997704246924
Validation loss: 2.433585198041933

Epoch: 5| Step: 2
Training loss: 2.4547364597306482
Validation loss: 2.4504678026569784

Epoch: 5| Step: 3
Training loss: 2.89674611879989
Validation loss: 2.453478670239235

Epoch: 5| Step: 4
Training loss: 2.7403701019932396
Validation loss: 2.474773306210245

Epoch: 5| Step: 5
Training loss: 2.2865340814809487
Validation loss: 2.461987645765638

Epoch: 5| Step: 6
Training loss: 2.5185493862633233
Validation loss: 2.4520565224874957

Epoch: 5| Step: 7
Training loss: 2.2669349829492123
Validation loss: 2.4499901748641872

Epoch: 5| Step: 8
Training loss: 2.5624163544191596
Validation loss: 2.4548353643174785

Epoch: 5| Step: 9
Training loss: 2.5663988180067427
Validation loss: 2.4546921820447185

Epoch: 5| Step: 10
Training loss: 2.993783072207313
Validation loss: 2.463564295325413

Epoch: 5| Step: 11
Training loss: 2.970978071441923
Validation loss: 2.4661828427355816

Epoch: 110| Step: 0
Training loss: 2.454053666557834
Validation loss: 2.4706940541458984

Epoch: 5| Step: 1
Training loss: 2.1855549475526743
Validation loss: 2.473754213177584

Epoch: 5| Step: 2
Training loss: 2.2119243023700617
Validation loss: 2.47788914988867

Epoch: 5| Step: 3
Training loss: 3.084326523976725
Validation loss: 2.4851127664678647

Epoch: 5| Step: 4
Training loss: 2.4875586881375704
Validation loss: 2.4833656875905024

Epoch: 5| Step: 5
Training loss: 2.598358105371544
Validation loss: 2.48582525329564

Epoch: 5| Step: 6
Training loss: 2.322714746933807
Validation loss: 2.4893048515080687

Epoch: 5| Step: 7
Training loss: 3.064115137312407
Validation loss: 2.4914656643079542

Epoch: 5| Step: 8
Training loss: 2.5038630203585894
Validation loss: 2.4817949049036767

Epoch: 5| Step: 9
Training loss: 2.933943848221469
Validation loss: 2.4701786736100284

Epoch: 5| Step: 10
Training loss: 2.356650895637428
Validation loss: 2.46483972370768

Epoch: 5| Step: 11
Training loss: 2.846602801009278
Validation loss: 2.4642059057059527

Epoch: 111| Step: 0
Training loss: 2.443164406002654
Validation loss: 2.4644990288016704

Epoch: 5| Step: 1
Training loss: 2.5822585751740776
Validation loss: 2.458500061739081

Epoch: 5| Step: 2
Training loss: 2.699381534950947
Validation loss: 2.455240782915905

Epoch: 5| Step: 3
Training loss: 2.611325659854156
Validation loss: 2.455409421900918

Epoch: 5| Step: 4
Training loss: 2.850070008873634
Validation loss: 2.4552272022014807

Epoch: 5| Step: 5
Training loss: 2.237365002528871
Validation loss: 2.448693818984105

Epoch: 5| Step: 6
Training loss: 2.681103301759067
Validation loss: 2.4512019182165012

Epoch: 5| Step: 7
Training loss: 2.6603677584325482
Validation loss: 2.4511395253431583

Epoch: 5| Step: 8
Training loss: 2.384369788407896
Validation loss: 2.4493701691290686

Epoch: 5| Step: 9
Training loss: 2.435800987269888
Validation loss: 2.4495467048033053

Epoch: 5| Step: 10
Training loss: 2.533989636418829
Validation loss: 2.453746765453288

Epoch: 5| Step: 11
Training loss: 2.47228634735647
Validation loss: 2.4490970457625263

Epoch: 112| Step: 0
Training loss: 2.1693559487181373
Validation loss: 2.4609303186705427

Epoch: 5| Step: 1
Training loss: 2.38223549782595
Validation loss: 2.453836823713729

Epoch: 5| Step: 2
Training loss: 2.983208713024261
Validation loss: 2.451030051293974

Epoch: 5| Step: 3
Training loss: 2.537644398155837
Validation loss: 2.454745290081218

Epoch: 5| Step: 4
Training loss: 2.5233734406173394
Validation loss: 2.4552491299705

Epoch: 5| Step: 5
Training loss: 2.414834599645748
Validation loss: 2.4539273685071645

Epoch: 5| Step: 6
Training loss: 1.8388686785334833
Validation loss: 2.4492544995973597

Epoch: 5| Step: 7
Training loss: 3.2254209554197177
Validation loss: 2.4534390120986904

Epoch: 5| Step: 8
Training loss: 2.725490064038459
Validation loss: 2.4458953032909743

Epoch: 5| Step: 9
Training loss: 2.6602944493630796
Validation loss: 2.454409973462654

Epoch: 5| Step: 10
Training loss: 2.352056204338387
Validation loss: 2.45487661655055

Epoch: 5| Step: 11
Training loss: 1.8112545338238928
Validation loss: 2.4597326245678213

Epoch: 113| Step: 0
Training loss: 2.6091440064298985
Validation loss: 2.4687913979709077

Epoch: 5| Step: 1
Training loss: 2.257254878156416
Validation loss: 2.4809967600416774

Epoch: 5| Step: 2
Training loss: 2.661707847131737
Validation loss: 2.481685634296742

Epoch: 5| Step: 3
Training loss: 2.4758153323821617
Validation loss: 2.4824509637720555

Epoch: 5| Step: 4
Training loss: 2.552737363712864
Validation loss: 2.4876579490112563

Epoch: 5| Step: 5
Training loss: 2.994837133090104
Validation loss: 2.4856027352571095

Epoch: 5| Step: 6
Training loss: 2.835686790796982
Validation loss: 2.479801266389465

Epoch: 5| Step: 7
Training loss: 2.371229692612454
Validation loss: 2.477008602906915

Epoch: 5| Step: 8
Training loss: 2.474462057664857
Validation loss: 2.4726416299637823

Epoch: 5| Step: 9
Training loss: 2.815532236550477
Validation loss: 2.4734941000134527

Epoch: 5| Step: 10
Training loss: 2.2433019121566526
Validation loss: 2.46712544664972

Epoch: 5| Step: 11
Training loss: 2.5675282341018484
Validation loss: 2.471654881041765

Epoch: 114| Step: 0
Training loss: 2.2687483732359546
Validation loss: 2.4697588215454895

Epoch: 5| Step: 1
Training loss: 2.5479500028894053
Validation loss: 2.469607127961958

Epoch: 5| Step: 2
Training loss: 2.529537799215725
Validation loss: 2.4669008290991035

Epoch: 5| Step: 3
Training loss: 2.6363304473916465
Validation loss: 2.4635626541329785

Epoch: 5| Step: 4
Training loss: 2.8425998248149678
Validation loss: 2.4585195944962517

Epoch: 5| Step: 5
Training loss: 2.2820209611336226
Validation loss: 2.451505296378937

Epoch: 5| Step: 6
Training loss: 2.4750983787019316
Validation loss: 2.4481538995811607

Epoch: 5| Step: 7
Training loss: 2.143356362728827
Validation loss: 2.449278429714754

Epoch: 5| Step: 8
Training loss: 2.8902714693545555
Validation loss: 2.4523829534483235

Epoch: 5| Step: 9
Training loss: 2.806503770394497
Validation loss: 2.4491467341087523

Epoch: 5| Step: 10
Training loss: 2.582110474448818
Validation loss: 2.452157427063485

Epoch: 5| Step: 11
Training loss: 2.2250847446719146
Validation loss: 2.4439540823349746

Epoch: 115| Step: 0
Training loss: 2.3972219561707706
Validation loss: 2.446887998680383

Epoch: 5| Step: 1
Training loss: 3.1040250673363357
Validation loss: 2.450728985617575

Epoch: 5| Step: 2
Training loss: 2.1648465605669007
Validation loss: 2.4480462276721044

Epoch: 5| Step: 3
Training loss: 2.531620139857427
Validation loss: 2.456485689744368

Epoch: 5| Step: 4
Training loss: 2.3908222590824115
Validation loss: 2.44808264771608

Epoch: 5| Step: 5
Training loss: 2.9906146743899105
Validation loss: 2.446160726930891

Epoch: 5| Step: 6
Training loss: 2.475967576444755
Validation loss: 2.4440722626204683

Epoch: 5| Step: 7
Training loss: 2.4949957353329952
Validation loss: 2.4493780089399864

Epoch: 5| Step: 8
Training loss: 2.0238419647715484
Validation loss: 2.4427185132940386

Epoch: 5| Step: 9
Training loss: 2.4514480982309848
Validation loss: 2.451591721201127

Epoch: 5| Step: 10
Training loss: 2.812553998640697
Validation loss: 2.4568150015289554

Epoch: 5| Step: 11
Training loss: 1.6952586363220976
Validation loss: 2.4549140157099214

Epoch: 116| Step: 0
Training loss: 2.2978644283532716
Validation loss: 2.462537126535586

Epoch: 5| Step: 1
Training loss: 2.5138418381738967
Validation loss: 2.4619024090590087

Epoch: 5| Step: 2
Training loss: 2.5410761433812215
Validation loss: 2.46613928617087

Epoch: 5| Step: 3
Training loss: 2.532631861877409
Validation loss: 2.4668168172586458

Epoch: 5| Step: 4
Training loss: 2.02969054000897
Validation loss: 2.469769641505036

Epoch: 5| Step: 5
Training loss: 2.245769868802096
Validation loss: 2.4640759230856664

Epoch: 5| Step: 6
Training loss: 2.2883126654899026
Validation loss: 2.466646290036614

Epoch: 5| Step: 7
Training loss: 2.8025445003192244
Validation loss: 2.465245689189224

Epoch: 5| Step: 8
Training loss: 2.489747482272485
Validation loss: 2.4667202133947925

Epoch: 5| Step: 9
Training loss: 2.8901983822642303
Validation loss: 2.45464736934811

Epoch: 5| Step: 10
Training loss: 3.0258163044319963
Validation loss: 2.44911142100894

Epoch: 5| Step: 11
Training loss: 3.42986934935751
Validation loss: 2.4562471247390083

Epoch: 117| Step: 0
Training loss: 2.4782555025044046
Validation loss: 2.447354971920779

Epoch: 5| Step: 1
Training loss: 2.098605887558492
Validation loss: 2.4520689560094096

Epoch: 5| Step: 2
Training loss: 2.700795752210802
Validation loss: 2.4534900863363736

Epoch: 5| Step: 3
Training loss: 2.7117799884428297
Validation loss: 2.4524733250820288

Epoch: 5| Step: 4
Training loss: 2.51258353478787
Validation loss: 2.4580906341385167

Epoch: 5| Step: 5
Training loss: 2.83603031227258
Validation loss: 2.449513037937649

Epoch: 5| Step: 6
Training loss: 2.543630768702052
Validation loss: 2.4564444847537246

Epoch: 5| Step: 7
Training loss: 2.2829873771970175
Validation loss: 2.4524919863487957

Epoch: 5| Step: 8
Training loss: 2.7286480029794644
Validation loss: 2.4559070702058396

Epoch: 5| Step: 9
Training loss: 2.28786085440604
Validation loss: 2.4608590491975346

Epoch: 5| Step: 10
Training loss: 2.7898520839954455
Validation loss: 2.4626346407710433

Epoch: 5| Step: 11
Training loss: 2.445199202085265
Validation loss: 2.465512321550201

Epoch: 118| Step: 0
Training loss: 2.2329308170820052
Validation loss: 2.4720176848501167

Epoch: 5| Step: 1
Training loss: 2.806572156056366
Validation loss: 2.477754193865746

Epoch: 5| Step: 2
Training loss: 2.794230228258216
Validation loss: 2.47602913104008

Epoch: 5| Step: 3
Training loss: 2.301900749963626
Validation loss: 2.475003783868537

Epoch: 5| Step: 4
Training loss: 2.5225376851468124
Validation loss: 2.4781798608006085

Epoch: 5| Step: 5
Training loss: 2.440362374490589
Validation loss: 2.4818019458038756

Epoch: 5| Step: 6
Training loss: 2.6413886416327
Validation loss: 2.4829230434167053

Epoch: 5| Step: 7
Training loss: 2.9072687147914076
Validation loss: 2.4809486345473006

Epoch: 5| Step: 8
Training loss: 2.3099770056831015
Validation loss: 2.4776919824833774

Epoch: 5| Step: 9
Training loss: 2.9491961143584984
Validation loss: 2.4806542474866746

Epoch: 5| Step: 10
Training loss: 2.2475409315411
Validation loss: 2.4784247639993033

Epoch: 5| Step: 11
Training loss: 3.150576335922385
Validation loss: 2.4706633231634823

Epoch: 119| Step: 0
Training loss: 2.6728158822289667
Validation loss: 2.4695964078544765

Epoch: 5| Step: 1
Training loss: 2.36882883710691
Validation loss: 2.4568620349571386

Epoch: 5| Step: 2
Training loss: 2.5802338269457454
Validation loss: 2.4569622246406966

Epoch: 5| Step: 3
Training loss: 2.0796405743951656
Validation loss: 2.4491791912090464

Epoch: 5| Step: 4
Training loss: 2.766781064238365
Validation loss: 2.447566114174967

Epoch: 5| Step: 5
Training loss: 2.7605932982932386
Validation loss: 2.4455849208353704

Epoch: 5| Step: 6
Training loss: 2.496219160245707
Validation loss: 2.453328640497512

Epoch: 5| Step: 7
Training loss: 2.576331237074814
Validation loss: 2.447950678785237

Epoch: 5| Step: 8
Training loss: 2.467164315035635
Validation loss: 2.4471027820393894

Epoch: 5| Step: 9
Training loss: 2.4817856064016848
Validation loss: 2.4508976229454977

Epoch: 5| Step: 10
Training loss: 2.5193035643851904
Validation loss: 2.4553648488638036

Epoch: 5| Step: 11
Training loss: 3.2469783821572906
Validation loss: 2.4547453103157153

Epoch: 120| Step: 0
Training loss: 2.5185597993962276
Validation loss: 2.4463856772546366

Epoch: 5| Step: 1
Training loss: 2.796492395923684
Validation loss: 2.4447183344185133

Epoch: 5| Step: 2
Training loss: 2.2295409509286155
Validation loss: 2.444216335254551

Epoch: 5| Step: 3
Training loss: 2.484955533894345
Validation loss: 2.4523239326142177

Epoch: 5| Step: 4
Training loss: 2.3108882958137027
Validation loss: 2.447922103280598

Epoch: 5| Step: 5
Training loss: 2.097712169732992
Validation loss: 2.4493099197705974

Epoch: 5| Step: 6
Training loss: 2.2761738358334185
Validation loss: 2.451597706153142

Epoch: 5| Step: 7
Training loss: 2.8651982612648257
Validation loss: 2.4518026606688172

Epoch: 5| Step: 8
Training loss: 2.5483571052149387
Validation loss: 2.4544627941714308

Epoch: 5| Step: 9
Training loss: 2.9454645173281846
Validation loss: 2.4621738920656

Epoch: 5| Step: 10
Training loss: 2.5653011549750944
Validation loss: 2.453683866431329

Epoch: 5| Step: 11
Training loss: 3.3561382935757385
Validation loss: 2.453166864122964

Epoch: 121| Step: 0
Training loss: 2.783276451884934
Validation loss: 2.4481210271604907

Epoch: 5| Step: 1
Training loss: 2.0166318286167013
Validation loss: 2.4400773360746033

Epoch: 5| Step: 2
Training loss: 2.6685985084436323
Validation loss: 2.439436888812531

Epoch: 5| Step: 3
Training loss: 2.790768398176083
Validation loss: 2.4410946497113515

Epoch: 5| Step: 4
Training loss: 2.3183073377031658
Validation loss: 2.4432460068449173

Epoch: 5| Step: 5
Training loss: 2.2615359533885897
Validation loss: 2.445461865820569

Epoch: 5| Step: 6
Training loss: 2.9470939611517197
Validation loss: 2.455093654845452

Epoch: 5| Step: 7
Training loss: 2.78600504863361
Validation loss: 2.4479819606973927

Epoch: 5| Step: 8
Training loss: 2.6073040996340935
Validation loss: 2.448621081732649

Epoch: 5| Step: 9
Training loss: 2.272540882443687
Validation loss: 2.452219512488726

Epoch: 5| Step: 10
Training loss: 2.4240429434922417
Validation loss: 2.4552090047760666

Epoch: 5| Step: 11
Training loss: 1.7169778878149489
Validation loss: 2.4544179874052623

Epoch: 122| Step: 0
Training loss: 2.364947880499278
Validation loss: 2.4534687805643522

Epoch: 5| Step: 1
Training loss: 2.7953440136143284
Validation loss: 2.454133822513309

Epoch: 5| Step: 2
Training loss: 2.8455204744703355
Validation loss: 2.451097322624597

Epoch: 5| Step: 3
Training loss: 2.9235459715854706
Validation loss: 2.459982364728307

Epoch: 5| Step: 4
Training loss: 1.803595736985912
Validation loss: 2.457057425112402

Epoch: 5| Step: 5
Training loss: 2.5867892703596955
Validation loss: 2.457476763015535

Epoch: 5| Step: 6
Training loss: 2.0801686728384543
Validation loss: 2.4612151902570454

Epoch: 5| Step: 7
Training loss: 2.8282141908523086
Validation loss: 2.4610755276194594

Epoch: 5| Step: 8
Training loss: 2.7987695170067455
Validation loss: 2.452202192087254

Epoch: 5| Step: 9
Training loss: 2.258950128350125
Validation loss: 2.456364110992825

Epoch: 5| Step: 10
Training loss: 2.3937627607757435
Validation loss: 2.4535682828455605

Epoch: 5| Step: 11
Training loss: 3.0631929508900226
Validation loss: 2.4606027607602754

Epoch: 123| Step: 0
Training loss: 2.1208252007928694
Validation loss: 2.4680748108762853

Epoch: 5| Step: 1
Training loss: 2.446801363054999
Validation loss: 2.4651243208343336

Epoch: 5| Step: 2
Training loss: 2.3111839673691428
Validation loss: 2.4695631611463953

Epoch: 5| Step: 3
Training loss: 2.9049814388450366
Validation loss: 2.4669106226429323

Epoch: 5| Step: 4
Training loss: 2.7289012071250016
Validation loss: 2.4591954155597406

Epoch: 5| Step: 5
Training loss: 2.443424751510958
Validation loss: 2.4534984514938865

Epoch: 5| Step: 6
Training loss: 2.4826360410542074
Validation loss: 2.4575035316516933

Epoch: 5| Step: 7
Training loss: 2.2570641145198387
Validation loss: 2.4417585927390832

Epoch: 5| Step: 8
Training loss: 2.5530098822611986
Validation loss: 2.4419175774759903

Epoch: 5| Step: 9
Training loss: 2.70143497975791
Validation loss: 2.4416427335011006

Epoch: 5| Step: 10
Training loss: 2.5565983803029613
Validation loss: 2.4395399686464985

Epoch: 5| Step: 11
Training loss: 4.078283314171468
Validation loss: 2.4368970443108116

Epoch: 124| Step: 0
Training loss: 2.855131074532094
Validation loss: 2.4429617684556018

Epoch: 5| Step: 1
Training loss: 2.1147461501204967
Validation loss: 2.4352943964586795

Epoch: 5| Step: 2
Training loss: 2.8533887893718566
Validation loss: 2.4352084579639617

Epoch: 5| Step: 3
Training loss: 2.1797921760609773
Validation loss: 2.4378037752470427

Epoch: 5| Step: 4
Training loss: 2.432748516125825
Validation loss: 2.441683256583331

Epoch: 5| Step: 5
Training loss: 1.9449053725143746
Validation loss: 2.439006722834999

Epoch: 5| Step: 6
Training loss: 3.0022237800890896
Validation loss: 2.441043031249403

Epoch: 5| Step: 7
Training loss: 2.170284210086612
Validation loss: 2.441807254664845

Epoch: 5| Step: 8
Training loss: 2.7021204675040935
Validation loss: 2.4441652135479424

Epoch: 5| Step: 9
Training loss: 2.8404021625802267
Validation loss: 2.4505160159726818

Epoch: 5| Step: 10
Training loss: 2.456704316577511
Validation loss: 2.449637523747518

Epoch: 5| Step: 11
Training loss: 2.693589785030971
Validation loss: 2.449039170750885

Epoch: 125| Step: 0
Training loss: 2.1375448523383214
Validation loss: 2.447774644884696

Epoch: 5| Step: 1
Training loss: 2.571843395757414
Validation loss: 2.444199289385338

Epoch: 5| Step: 2
Training loss: 2.547291353046347
Validation loss: 2.4368400454666053

Epoch: 5| Step: 3
Training loss: 2.741809612439693
Validation loss: 2.440575342816938

Epoch: 5| Step: 4
Training loss: 2.583360569307871
Validation loss: 2.4456426948019665

Epoch: 5| Step: 5
Training loss: 2.4018700109306415
Validation loss: 2.4424285497987945

Epoch: 5| Step: 6
Training loss: 2.276892170701268
Validation loss: 2.4466519572008987

Epoch: 5| Step: 7
Training loss: 2.9135749961375073
Validation loss: 2.4464453489287172

Epoch: 5| Step: 8
Training loss: 2.4126253757609923
Validation loss: 2.442874208740997

Epoch: 5| Step: 9
Training loss: 2.495831160844251
Validation loss: 2.448181881977842

Epoch: 5| Step: 10
Training loss: 2.5944906808770694
Validation loss: 2.4504597757957525

Epoch: 5| Step: 11
Training loss: 2.9275677552758634
Validation loss: 2.450438151787259

Epoch: 126| Step: 0
Training loss: 2.138947769554593
Validation loss: 2.449095382706565

Epoch: 5| Step: 1
Training loss: 2.895933483413672
Validation loss: 2.4517005745375298

Epoch: 5| Step: 2
Training loss: 2.440501199432435
Validation loss: 2.4548127064540712

Epoch: 5| Step: 3
Training loss: 2.26102649062783
Validation loss: 2.4442797806908843

Epoch: 5| Step: 4
Training loss: 2.3011755095469195
Validation loss: 2.4503937112967273

Epoch: 5| Step: 5
Training loss: 2.8202141826537326
Validation loss: 2.4453887765056264

Epoch: 5| Step: 6
Training loss: 2.358095137717694
Validation loss: 2.4561651914093017

Epoch: 5| Step: 7
Training loss: 2.793746733183519
Validation loss: 2.4538626685488256

Epoch: 5| Step: 8
Training loss: 2.6013232971746016
Validation loss: 2.445186737694082

Epoch: 5| Step: 9
Training loss: 2.864194716478153
Validation loss: 2.4509722543515884

Epoch: 5| Step: 10
Training loss: 2.129029884598081
Validation loss: 2.4492216460045055

Epoch: 5| Step: 11
Training loss: 2.3729309304880113
Validation loss: 2.443588394502938

Epoch: 127| Step: 0
Training loss: 2.185337087262979
Validation loss: 2.4442218830618794

Epoch: 5| Step: 1
Training loss: 2.00422829462522
Validation loss: 2.442831903895986

Epoch: 5| Step: 2
Training loss: 2.6845076114108255
Validation loss: 2.4395980364331726

Epoch: 5| Step: 3
Training loss: 2.55291593295631
Validation loss: 2.438193293953618

Epoch: 5| Step: 4
Training loss: 2.5336711277704356
Validation loss: 2.4421615856290226

Epoch: 5| Step: 5
Training loss: 2.312238317581577
Validation loss: 2.4466177165667964

Epoch: 5| Step: 6
Training loss: 2.731124340806824
Validation loss: 2.444642813146257

Epoch: 5| Step: 7
Training loss: 2.5740687973503023
Validation loss: 2.4465000409323068

Epoch: 5| Step: 8
Training loss: 2.61851991357346
Validation loss: 2.4460205499285386

Epoch: 5| Step: 9
Training loss: 2.5995342607773653
Validation loss: 2.4464726118413753

Epoch: 5| Step: 10
Training loss: 2.808419212892156
Validation loss: 2.449065759840069

Epoch: 5| Step: 11
Training loss: 2.418586220728628
Validation loss: 2.443715570407296

Epoch: 128| Step: 0
Training loss: 2.742781441642971
Validation loss: 2.445707315700198

Epoch: 5| Step: 1
Training loss: 2.589775993646096
Validation loss: 2.4454943149562705

Epoch: 5| Step: 2
Training loss: 2.1111865141715045
Validation loss: 2.4595933179885865

Epoch: 5| Step: 3
Training loss: 2.490145812610238
Validation loss: 2.452480992947704

Epoch: 5| Step: 4
Training loss: 2.5386404772470805
Validation loss: 2.4585891599948684

Epoch: 5| Step: 5
Training loss: 2.6927323085128307
Validation loss: 2.4643394853156604

Epoch: 5| Step: 6
Training loss: 2.834410032751904
Validation loss: 2.4571633033057543

Epoch: 5| Step: 7
Training loss: 2.531816018951772
Validation loss: 2.4579090598204716

Epoch: 5| Step: 8
Training loss: 2.288976049255418
Validation loss: 2.4597907285725404

Epoch: 5| Step: 9
Training loss: 2.5173206182855137
Validation loss: 2.4501682937326392

Epoch: 5| Step: 10
Training loss: 2.52197875384972
Validation loss: 2.4504802604556897

Epoch: 5| Step: 11
Training loss: 1.6963321414587764
Validation loss: 2.4518088841589623

Epoch: 129| Step: 0
Training loss: 2.8162525150916005
Validation loss: 2.4502982559766346

Epoch: 5| Step: 1
Training loss: 2.6164010303863283
Validation loss: 2.442523255213095

Epoch: 5| Step: 2
Training loss: 2.208675130148363
Validation loss: 2.4445545902928045

Epoch: 5| Step: 3
Training loss: 2.2278655940458028
Validation loss: 2.446765922723243

Epoch: 5| Step: 4
Training loss: 2.1983645255551316
Validation loss: 2.447569702124853

Epoch: 5| Step: 5
Training loss: 2.6862195535374855
Validation loss: 2.45298321227114

Epoch: 5| Step: 6
Training loss: 2.8427710891865945
Validation loss: 2.4491235693243674

Epoch: 5| Step: 7
Training loss: 2.7318146844234765
Validation loss: 2.447984387428232

Epoch: 5| Step: 8
Training loss: 2.852878214764235
Validation loss: 2.4424777230490125

Epoch: 5| Step: 9
Training loss: 2.5039654753014196
Validation loss: 2.4412915948012266

Epoch: 5| Step: 10
Training loss: 1.912617850568331
Validation loss: 2.435279352239985

Epoch: 5| Step: 11
Training loss: 2.452262192141939
Validation loss: 2.4433149561921677

Epoch: 130| Step: 0
Training loss: 2.8167098010069087
Validation loss: 2.4483985683556946

Epoch: 5| Step: 1
Training loss: 2.234406797809688
Validation loss: 2.448316506271065

Epoch: 5| Step: 2
Training loss: 2.816890934098609
Validation loss: 2.450061273943932

Epoch: 5| Step: 3
Training loss: 2.2540450293063414
Validation loss: 2.4428027988107983

Epoch: 5| Step: 4
Training loss: 2.7287518911665316
Validation loss: 2.4503603824269704

Epoch: 5| Step: 5
Training loss: 2.339660025947749
Validation loss: 2.4372869137603157

Epoch: 5| Step: 6
Training loss: 2.213077008713565
Validation loss: 2.440354438548702

Epoch: 5| Step: 7
Training loss: 2.051412430770713
Validation loss: 2.445146524567331

Epoch: 5| Step: 8
Training loss: 2.386895056173562
Validation loss: 2.4384082422550826

Epoch: 5| Step: 9
Training loss: 2.9943328417487747
Validation loss: 2.4435035811411607

Epoch: 5| Step: 10
Training loss: 2.710128003718516
Validation loss: 2.4435785095193596

Epoch: 5| Step: 11
Training loss: 2.4084149814303846
Validation loss: 2.43777949613664

Epoch: 131| Step: 0
Training loss: 2.3656773550067944
Validation loss: 2.4399798791445315

Epoch: 5| Step: 1
Training loss: 2.4529023282013407
Validation loss: 2.4487577143351755

Epoch: 5| Step: 2
Training loss: 2.2205926470086705
Validation loss: 2.444627249419527

Epoch: 5| Step: 3
Training loss: 2.323924223887337
Validation loss: 2.4501930055370496

Epoch: 5| Step: 4
Training loss: 2.5476597238170124
Validation loss: 2.4435639838262735

Epoch: 5| Step: 5
Training loss: 2.406966263817133
Validation loss: 2.450115637904766

Epoch: 5| Step: 6
Training loss: 3.0989727287064985
Validation loss: 2.446585899511066

Epoch: 5| Step: 7
Training loss: 2.501704302645938
Validation loss: 2.4491006598631735

Epoch: 5| Step: 8
Training loss: 2.8267366995622965
Validation loss: 2.4582245864630443

Epoch: 5| Step: 9
Training loss: 2.4716105246089373
Validation loss: 2.4579424843728517

Epoch: 5| Step: 10
Training loss: 2.4882530797684246
Validation loss: 2.4559105630479743

Epoch: 5| Step: 11
Training loss: 2.2094987157475643
Validation loss: 2.456702323046205

Epoch: 132| Step: 0
Training loss: 2.359964562327815
Validation loss: 2.44507715557241

Epoch: 5| Step: 1
Training loss: 2.4102128329814683
Validation loss: 2.4513069956545293

Epoch: 5| Step: 2
Training loss: 2.4415466756489743
Validation loss: 2.4654483567505374

Epoch: 5| Step: 3
Training loss: 2.6085488844786564
Validation loss: 2.498185759126716

Epoch: 5| Step: 4
Training loss: 3.0570330968081567
Validation loss: 2.5018725574553593

Epoch: 5| Step: 5
Training loss: 2.506225083529315
Validation loss: 2.467365391675626

Epoch: 5| Step: 6
Training loss: 2.8072289133695714
Validation loss: 2.4519477214169263

Epoch: 5| Step: 7
Training loss: 1.995999627031127
Validation loss: 2.4620347498448645

Epoch: 5| Step: 8
Training loss: 2.6415744857669603
Validation loss: 2.4679833642281968

Epoch: 5| Step: 9
Training loss: 2.511684387826284
Validation loss: 2.4714101028677646

Epoch: 5| Step: 10
Training loss: 2.5825723839925168
Validation loss: 2.470408015663603

Epoch: 5| Step: 11
Training loss: 4.759750197130824
Validation loss: 2.476343391906467

Epoch: 133| Step: 0
Training loss: 2.4978063495912957
Validation loss: 2.4905612147646052

Epoch: 5| Step: 1
Training loss: 2.9156208524848246
Validation loss: 2.4777998335305242

Epoch: 5| Step: 2
Training loss: 2.1650841019573774
Validation loss: 2.4793765529508787

Epoch: 5| Step: 3
Training loss: 2.974895340817616
Validation loss: 2.473873580016266

Epoch: 5| Step: 4
Training loss: 2.0759108371219654
Validation loss: 2.4655781703187554

Epoch: 5| Step: 5
Training loss: 2.5377991335586945
Validation loss: 2.4595723760848585

Epoch: 5| Step: 6
Training loss: 2.875708451265477
Validation loss: 2.4655666671576277

Epoch: 5| Step: 7
Training loss: 2.513369289346742
Validation loss: 2.459973452219339

Epoch: 5| Step: 8
Training loss: 2.540221621689451
Validation loss: 2.460757734403657

Epoch: 5| Step: 9
Training loss: 2.2671283864071046
Validation loss: 2.458222820470407

Epoch: 5| Step: 10
Training loss: 2.406757053604639
Validation loss: 2.455064484713386

Epoch: 5| Step: 11
Training loss: 3.138295994430294
Validation loss: 2.450306433373516

Epoch: 134| Step: 0
Training loss: 2.4613791417639215
Validation loss: 2.458582781943088

Epoch: 5| Step: 1
Training loss: 2.6915836801717576
Validation loss: 2.4597296117002307

Epoch: 5| Step: 2
Training loss: 2.2438511010134534
Validation loss: 2.479027320781795

Epoch: 5| Step: 3
Training loss: 2.9908372506744616
Validation loss: 2.4750623361206285

Epoch: 5| Step: 4
Training loss: 2.441321385243775
Validation loss: 2.4709288844523685

Epoch: 5| Step: 5
Training loss: 2.0792143985057465
Validation loss: 2.457836441696232

Epoch: 5| Step: 6
Training loss: 2.1834924227384556
Validation loss: 2.4536502907462223

Epoch: 5| Step: 7
Training loss: 2.9079819307566086
Validation loss: 2.4433933055462127

Epoch: 5| Step: 8
Training loss: 2.802928064545337
Validation loss: 2.45475448461964

Epoch: 5| Step: 9
Training loss: 2.0674972106102945
Validation loss: 2.4583867896997584

Epoch: 5| Step: 10
Training loss: 2.582870554747525
Validation loss: 2.455375149648454

Epoch: 5| Step: 11
Training loss: 3.010949181225719
Validation loss: 2.4666025221599233

Epoch: 135| Step: 0
Training loss: 2.024228328091786
Validation loss: 2.4618566259967314

Epoch: 5| Step: 1
Training loss: 2.485057041426918
Validation loss: 2.466659457501195

Epoch: 5| Step: 2
Training loss: 2.6396393149525585
Validation loss: 2.4646206617282824

Epoch: 5| Step: 3
Training loss: 2.27233199150035
Validation loss: 2.466405588318498

Epoch: 5| Step: 4
Training loss: 2.8320753633417777
Validation loss: 2.464417978502607

Epoch: 5| Step: 5
Training loss: 2.8458187417530802
Validation loss: 2.4647493218391565

Epoch: 5| Step: 6
Training loss: 2.7524515841710215
Validation loss: 2.464232613338273

Epoch: 5| Step: 7
Training loss: 2.499996376034971
Validation loss: 2.461790431528723

Epoch: 5| Step: 8
Training loss: 2.071485424670911
Validation loss: 2.460393399433543

Epoch: 5| Step: 9
Training loss: 2.8138953244519698
Validation loss: 2.455902313298776

Epoch: 5| Step: 10
Training loss: 2.366476424276501
Validation loss: 2.4439586877132964

Epoch: 5| Step: 11
Training loss: 2.3108908751080643
Validation loss: 2.438138906587044

Epoch: 136| Step: 0
Training loss: 2.293578084796938
Validation loss: 2.439707160226483

Epoch: 5| Step: 1
Training loss: 2.267167927442598
Validation loss: 2.464777135981625

Epoch: 5| Step: 2
Training loss: 2.5166978147823342
Validation loss: 2.46979441662049

Epoch: 5| Step: 3
Training loss: 2.711040220045994
Validation loss: 2.4781535419970715

Epoch: 5| Step: 4
Training loss: 2.382971286173276
Validation loss: 2.4849169198072127

Epoch: 5| Step: 5
Training loss: 3.3206518381284598
Validation loss: 2.4690359288031423

Epoch: 5| Step: 6
Training loss: 2.1800404471398624
Validation loss: 2.4597990521102306

Epoch: 5| Step: 7
Training loss: 2.8376938606619246
Validation loss: 2.4537051298495878

Epoch: 5| Step: 8
Training loss: 2.3445645760567246
Validation loss: 2.445223301894809

Epoch: 5| Step: 9
Training loss: 2.364986189303892
Validation loss: 2.4469453886779475

Epoch: 5| Step: 10
Training loss: 2.696495968383288
Validation loss: 2.4552757084540913

Epoch: 5| Step: 11
Training loss: 2.8149022333706473
Validation loss: 2.4566906610578334

Epoch: 137| Step: 0
Training loss: 2.1097414051707606
Validation loss: 2.4639519409649817

Epoch: 5| Step: 1
Training loss: 2.2011772907126144
Validation loss: 2.4691174310167048

Epoch: 5| Step: 2
Training loss: 2.8946732500383017
Validation loss: 2.475428617495977

Epoch: 5| Step: 3
Training loss: 3.1044014110175153
Validation loss: 2.4755418360968426

Epoch: 5| Step: 4
Training loss: 2.6646192757511513
Validation loss: 2.4772652592651156

Epoch: 5| Step: 5
Training loss: 3.1806459224325363
Validation loss: 2.4792495093943145

Epoch: 5| Step: 6
Training loss: 2.121769188109268
Validation loss: 2.4730071330589136

Epoch: 5| Step: 7
Training loss: 2.5001630729895457
Validation loss: 2.4644428174959234

Epoch: 5| Step: 8
Training loss: 2.5542411764290627
Validation loss: 2.4602331899526

Epoch: 5| Step: 9
Training loss: 2.0823953678731733
Validation loss: 2.4531834265358023

Epoch: 5| Step: 10
Training loss: 2.3795587055221232
Validation loss: 2.441438708280329

Epoch: 5| Step: 11
Training loss: 2.419848572588337
Validation loss: 2.4386502938489603

Epoch: 138| Step: 0
Training loss: 1.8033197677910608
Validation loss: 2.439707384177904

Epoch: 5| Step: 1
Training loss: 2.491180694886992
Validation loss: 2.4480454323091094

Epoch: 5| Step: 2
Training loss: 2.4240405829529204
Validation loss: 2.4439014958597047

Epoch: 5| Step: 3
Training loss: 2.729638493255751
Validation loss: 2.487949399113625

Epoch: 5| Step: 4
Training loss: 2.5234387282613593
Validation loss: 2.467890229585647

Epoch: 5| Step: 5
Training loss: 2.496007974550762
Validation loss: 2.4609982679826765

Epoch: 5| Step: 6
Training loss: 2.882039946131669
Validation loss: 2.458953214876693

Epoch: 5| Step: 7
Training loss: 2.9785045786168114
Validation loss: 2.4480687899024822

Epoch: 5| Step: 8
Training loss: 2.6907581717290774
Validation loss: 2.443460256565948

Epoch: 5| Step: 9
Training loss: 2.47578702030972
Validation loss: 2.435190682060171

Epoch: 5| Step: 10
Training loss: 2.3192890620263062
Validation loss: 2.4502440825669405

Epoch: 5| Step: 11
Training loss: 1.5290132651792117
Validation loss: 2.4442167233982572

Epoch: 139| Step: 0
Training loss: 2.2022456585385197
Validation loss: 2.455740504206635

Epoch: 5| Step: 1
Training loss: 2.630601265642292
Validation loss: 2.458004486320184

Epoch: 5| Step: 2
Training loss: 2.6081086700827742
Validation loss: 2.454776139402185

Epoch: 5| Step: 3
Training loss: 2.2519680528898656
Validation loss: 2.457885246065246

Epoch: 5| Step: 4
Training loss: 3.1133275046556084
Validation loss: 2.457544076161452

Epoch: 5| Step: 5
Training loss: 2.756678880466894
Validation loss: 2.456200941014887

Epoch: 5| Step: 6
Training loss: 1.9531710199656462
Validation loss: 2.456426334765284

Epoch: 5| Step: 7
Training loss: 2.7042255256097585
Validation loss: 2.4521650067914953

Epoch: 5| Step: 8
Training loss: 2.2277445549943846
Validation loss: 2.444861625404012

Epoch: 5| Step: 9
Training loss: 2.739610640434447
Validation loss: 2.4473458713568657

Epoch: 5| Step: 10
Training loss: 2.5693981086287505
Validation loss: 2.4544428466506547

Epoch: 5| Step: 11
Training loss: 1.8692898586095439
Validation loss: 2.448288740464372

Epoch: 140| Step: 0
Training loss: 2.5254070520419907
Validation loss: 2.4475877310875376

Epoch: 5| Step: 1
Training loss: 2.3378867497487725
Validation loss: 2.4484383284245435

Epoch: 5| Step: 2
Training loss: 2.546250061874127
Validation loss: 2.447836224607269

Epoch: 5| Step: 3
Training loss: 3.2397903588842047
Validation loss: 2.4508692175858133

Epoch: 5| Step: 4
Training loss: 2.7253090674439187
Validation loss: 2.4468701980075998

Epoch: 5| Step: 5
Training loss: 2.174602086291562
Validation loss: 2.446102071735949

Epoch: 5| Step: 6
Training loss: 2.286305925739549
Validation loss: 2.450035887734324

Epoch: 5| Step: 7
Training loss: 2.1398906701226874
Validation loss: 2.4449582599972364

Epoch: 5| Step: 8
Training loss: 2.5158642009481165
Validation loss: 2.452178493058819

Epoch: 5| Step: 9
Training loss: 2.28894480119497
Validation loss: 2.4423169932139217

Epoch: 5| Step: 10
Training loss: 2.760803934438373
Validation loss: 2.4487872050270987

Epoch: 5| Step: 11
Training loss: 1.5258489059550822
Validation loss: 2.445831024476434

Epoch: 141| Step: 0
Training loss: 2.903122726784464
Validation loss: 2.450702864520538

Epoch: 5| Step: 1
Training loss: 2.364361073359415
Validation loss: 2.4489295703578575

Epoch: 5| Step: 2
Training loss: 2.7111269310279478
Validation loss: 2.4554147502201857

Epoch: 5| Step: 3
Training loss: 2.680633555865803
Validation loss: 2.4556842299577597

Epoch: 5| Step: 4
Training loss: 2.228530174963457
Validation loss: 2.454698697685215

Epoch: 5| Step: 5
Training loss: 2.5420765051265195
Validation loss: 2.4601732550839204

Epoch: 5| Step: 6
Training loss: 1.8926091777194818
Validation loss: 2.4508299468770565

Epoch: 5| Step: 7
Training loss: 2.6368362061512407
Validation loss: 2.4511855004731067

Epoch: 5| Step: 8
Training loss: 2.318963374682247
Validation loss: 2.450123844292873

Epoch: 5| Step: 9
Training loss: 2.9349318295933813
Validation loss: 2.44090604006559

Epoch: 5| Step: 10
Training loss: 2.1165277220210217
Validation loss: 2.4486738021546524

Epoch: 5| Step: 11
Training loss: 2.8264398770702033
Validation loss: 2.4418806200114944

Epoch: 142| Step: 0
Training loss: 2.7625213277002105
Validation loss: 2.4541146211875047

Epoch: 5| Step: 1
Training loss: 2.0786942010800926
Validation loss: 2.45293481255566

Epoch: 5| Step: 2
Training loss: 2.298074629591874
Validation loss: 2.4514806585872213

Epoch: 5| Step: 3
Training loss: 2.7942031800019147
Validation loss: 2.4581268689908002

Epoch: 5| Step: 4
Training loss: 2.6425913875949063
Validation loss: 2.4529584435292744

Epoch: 5| Step: 5
Training loss: 2.239234175559395
Validation loss: 2.4534115674560266

Epoch: 5| Step: 6
Training loss: 2.099722698613266
Validation loss: 2.446066284187937

Epoch: 5| Step: 7
Training loss: 2.56110865339307
Validation loss: 2.4548422822285634

Epoch: 5| Step: 8
Training loss: 2.8837773225611865
Validation loss: 2.4483026173207563

Epoch: 5| Step: 9
Training loss: 2.7439628570645245
Validation loss: 2.4492282248703625

Epoch: 5| Step: 10
Training loss: 2.346744303105414
Validation loss: 2.448506577748105

Epoch: 5| Step: 11
Training loss: 2.219082767086202
Validation loss: 2.4456512898982563

Epoch: 143| Step: 0
Training loss: 2.4291970104418352
Validation loss: 2.447753658684024

Epoch: 5| Step: 1
Training loss: 2.1558755743043996
Validation loss: 2.4484340580873654

Epoch: 5| Step: 2
Training loss: 2.7016391088016443
Validation loss: 2.44811924170592

Epoch: 5| Step: 3
Training loss: 2.1108472419377926
Validation loss: 2.4541993350028117

Epoch: 5| Step: 4
Training loss: 2.864462906589139
Validation loss: 2.4544031292111548

Epoch: 5| Step: 5
Training loss: 2.6641438491348506
Validation loss: 2.457319726874045

Epoch: 5| Step: 6
Training loss: 2.8932041518500258
Validation loss: 2.4578309933305578

Epoch: 5| Step: 7
Training loss: 2.3054974700576314
Validation loss: 2.4568405400805298

Epoch: 5| Step: 8
Training loss: 2.521578171667513
Validation loss: 2.4587979901298898

Epoch: 5| Step: 9
Training loss: 2.3749135654180735
Validation loss: 2.456528002089865

Epoch: 5| Step: 10
Training loss: 2.629326479287077
Validation loss: 2.460902105813595

Epoch: 5| Step: 11
Training loss: 2.1972251515369634
Validation loss: 2.450515519371852

Epoch: 144| Step: 0
Training loss: 2.274567627953612
Validation loss: 2.45254884421044

Epoch: 5| Step: 1
Training loss: 2.5149764652554056
Validation loss: 2.4475148554342336

Epoch: 5| Step: 2
Training loss: 2.363920368124937
Validation loss: 2.4482556588576156

Epoch: 5| Step: 3
Training loss: 2.7214668992829627
Validation loss: 2.4516804991916885

Epoch: 5| Step: 4
Training loss: 2.113709806469558
Validation loss: 2.4501172110682523

Epoch: 5| Step: 5
Training loss: 2.508311949815144
Validation loss: 2.452229848766389

Epoch: 5| Step: 6
Training loss: 2.685863440148888
Validation loss: 2.461153483121735

Epoch: 5| Step: 7
Training loss: 2.4582743449057465
Validation loss: 2.453825994225866

Epoch: 5| Step: 8
Training loss: 2.500675205602926
Validation loss: 2.453541021848753

Epoch: 5| Step: 9
Training loss: 2.616150061115178
Validation loss: 2.448462098141507

Epoch: 5| Step: 10
Training loss: 2.3730014623998357
Validation loss: 2.4614597432480525

Epoch: 5| Step: 11
Training loss: 3.775743494648164
Validation loss: 2.4578222387354924

Epoch: 145| Step: 0
Training loss: 2.60178555285583
Validation loss: 2.4510209157389293

Epoch: 5| Step: 1
Training loss: 2.2576879975201907
Validation loss: 2.4502139992252845

Epoch: 5| Step: 2
Training loss: 1.7416164676909285
Validation loss: 2.4520799026422044

Epoch: 5| Step: 3
Training loss: 2.258456339659231
Validation loss: 2.4495927807977806

Epoch: 5| Step: 4
Training loss: 2.425693479660876
Validation loss: 2.4541850300367933

Epoch: 5| Step: 5
Training loss: 3.1903415057066646
Validation loss: 2.4484281424915872

Epoch: 5| Step: 6
Training loss: 2.2496786947776184
Validation loss: 2.450928459898216

Epoch: 5| Step: 7
Training loss: 2.9838015020278106
Validation loss: 2.449647686402776

Epoch: 5| Step: 8
Training loss: 2.7289569473253374
Validation loss: 2.444105217947327

Epoch: 5| Step: 9
Training loss: 2.14582360521599
Validation loss: 2.4460303417862366

Epoch: 5| Step: 10
Training loss: 2.6236653340906186
Validation loss: 2.4435302446946023

Epoch: 5| Step: 11
Training loss: 2.0311237002501286
Validation loss: 2.4434386214332466

Epoch: 146| Step: 0
Training loss: 2.8225972650627553
Validation loss: 2.4465211312780646

Epoch: 5| Step: 1
Training loss: 2.7805389181073985
Validation loss: 2.4491071335924146

Epoch: 5| Step: 2
Training loss: 1.9593383834313443
Validation loss: 2.442540137892708

Epoch: 5| Step: 3
Training loss: 2.331079848065407
Validation loss: 2.438422525703667

Epoch: 5| Step: 4
Training loss: 2.0254181700905396
Validation loss: 2.4456150204989213

Epoch: 5| Step: 5
Training loss: 2.2244591130524496
Validation loss: 2.449080561177455

Epoch: 5| Step: 6
Training loss: 2.405976317063209
Validation loss: 2.4440306938900536

Epoch: 5| Step: 7
Training loss: 2.96803451750392
Validation loss: 2.4481260385998858

Epoch: 5| Step: 8
Training loss: 2.644651875076234
Validation loss: 2.449551926238643

Epoch: 5| Step: 9
Training loss: 2.177770612611899
Validation loss: 2.449773750919838

Epoch: 5| Step: 10
Training loss: 2.796941575264946
Validation loss: 2.457010908906852

Epoch: 5| Step: 11
Training loss: 3.234889040286592
Validation loss: 2.444596958791046

Epoch: 147| Step: 0
Training loss: 2.75594381071926
Validation loss: 2.4508040883008744

Epoch: 5| Step: 1
Training loss: 2.042207827828068
Validation loss: 2.4466688844759954

Epoch: 5| Step: 2
Training loss: 2.4798021757534574
Validation loss: 2.4453061299753958

Epoch: 5| Step: 3
Training loss: 2.1897512568123862
Validation loss: 2.440419962724836

Epoch: 5| Step: 4
Training loss: 2.5938560739911085
Validation loss: 2.4468491817198688

Epoch: 5| Step: 5
Training loss: 2.493799722505646
Validation loss: 2.452051438054214

Epoch: 5| Step: 6
Training loss: 2.1981529241441744
Validation loss: 2.450694903286628

Epoch: 5| Step: 7
Training loss: 2.5033110626828408
Validation loss: 2.4461082488119374

Epoch: 5| Step: 8
Training loss: 3.0965181547372183
Validation loss: 2.4481046881736774

Epoch: 5| Step: 9
Training loss: 2.5133820005742358
Validation loss: 2.440602830044537

Epoch: 5| Step: 10
Training loss: 2.5050746911157855
Validation loss: 2.447474883505585

Epoch: 5| Step: 11
Training loss: 1.5081068947341976
Validation loss: 2.4541649729901502

Epoch: 148| Step: 0
Training loss: 2.391929420189018
Validation loss: 2.45001673335894

Epoch: 5| Step: 1
Training loss: 2.929845210598821
Validation loss: 2.460140753243253

Epoch: 5| Step: 2
Training loss: 3.0990475083458104
Validation loss: 2.46332053199465

Epoch: 5| Step: 3
Training loss: 2.1359081788132968
Validation loss: 2.4635161438171616

Epoch: 5| Step: 4
Training loss: 2.4303063098327824
Validation loss: 2.4636767406142392

Epoch: 5| Step: 5
Training loss: 2.073951373494948
Validation loss: 2.4567349269869467

Epoch: 5| Step: 6
Training loss: 2.3642235256704254
Validation loss: 2.460655184098717

Epoch: 5| Step: 7
Training loss: 1.847914695810373
Validation loss: 2.461507224685591

Epoch: 5| Step: 8
Training loss: 2.3943648661670602
Validation loss: 2.4617544543874015

Epoch: 5| Step: 9
Training loss: 2.1911120429734487
Validation loss: 2.452759166741485

Epoch: 5| Step: 10
Training loss: 3.048013797098006
Validation loss: 2.4495520965687736

Epoch: 5| Step: 11
Training loss: 3.5077136733103265
Validation loss: 2.442920014102973

Epoch: 149| Step: 0
Training loss: 1.6360110844747262
Validation loss: 2.456507207945965

Epoch: 5| Step: 1
Training loss: 2.1583586623817914
Validation loss: 2.4521825401398916

Epoch: 5| Step: 2
Training loss: 2.6574773309122968
Validation loss: 2.4543911932118103

Epoch: 5| Step: 3
Training loss: 2.5364251627440484
Validation loss: 2.4538021084575057

Epoch: 5| Step: 4
Training loss: 2.426762528290187
Validation loss: 2.458756569351137

Epoch: 5| Step: 5
Training loss: 2.4715590129137492
Validation loss: 2.4667535064742965

Epoch: 5| Step: 6
Training loss: 2.8174830903135657
Validation loss: 2.457023078811878

Epoch: 5| Step: 7
Training loss: 2.300124898919331
Validation loss: 2.4498758159681313

Epoch: 5| Step: 8
Training loss: 2.575362326305829
Validation loss: 2.457854253887559

Epoch: 5| Step: 9
Training loss: 2.667542899733334
Validation loss: 2.4567638993679264

Epoch: 5| Step: 10
Training loss: 2.8601014928882473
Validation loss: 2.4548574736419977

Epoch: 5| Step: 11
Training loss: 2.538722746198937
Validation loss: 2.460973386149662

Epoch: 150| Step: 0
Training loss: 2.864539147238524
Validation loss: 2.4663989948548233

Epoch: 5| Step: 1
Training loss: 2.121669178392113
Validation loss: 2.4658165617558625

Epoch: 5| Step: 2
Training loss: 2.2320616156916224
Validation loss: 2.4693135330594673

Epoch: 5| Step: 3
Training loss: 2.084857103679106
Validation loss: 2.469236440659769

Epoch: 5| Step: 4
Training loss: 2.357775215273771
Validation loss: 2.470361843336156

Epoch: 5| Step: 5
Training loss: 2.266118489156508
Validation loss: 2.469456366393532

Epoch: 5| Step: 6
Training loss: 2.156906801894065
Validation loss: 2.4696059976263656

Epoch: 5| Step: 7
Training loss: 2.592855644000452
Validation loss: 2.47320465587199

Epoch: 5| Step: 8
Training loss: 3.176781378399757
Validation loss: 2.46630017134324

Epoch: 5| Step: 9
Training loss: 2.2886247965027997
Validation loss: 2.4706440753941825

Epoch: 5| Step: 10
Training loss: 3.2245517034704982
Validation loss: 2.4672087675099625

Epoch: 5| Step: 11
Training loss: 3.3414532625799
Validation loss: 2.46212395622305

Epoch: 151| Step: 0
Training loss: 2.8329446937448997
Validation loss: 2.462699420877223

Epoch: 5| Step: 1
Training loss: 2.1162285128481066
Validation loss: 2.455268073592612

Epoch: 5| Step: 2
Training loss: 2.5718666642008747
Validation loss: 2.4638382220395756

Epoch: 5| Step: 3
Training loss: 2.5094593380713692
Validation loss: 2.4587068691520706

Epoch: 5| Step: 4
Training loss: 2.4509369635006846
Validation loss: 2.4499754357890606

Epoch: 5| Step: 5
Training loss: 2.3162229314252767
Validation loss: 2.4682326358197386

Epoch: 5| Step: 6
Training loss: 2.027952598920704
Validation loss: 2.4708915950173926

Epoch: 5| Step: 7
Training loss: 2.8205551085380858
Validation loss: 2.458479724717157

Epoch: 5| Step: 8
Training loss: 2.6891233287716183
Validation loss: 2.4691808541884113

Epoch: 5| Step: 9
Training loss: 2.3292137518839553
Validation loss: 2.4539002673588186

Epoch: 5| Step: 10
Training loss: 2.761230166542313
Validation loss: 2.4530951666182146

Epoch: 5| Step: 11
Training loss: 2.6741271760837457
Validation loss: 2.4534974149609123

Epoch: 152| Step: 0
Training loss: 2.6252487609703423
Validation loss: 2.45580093559389

Epoch: 5| Step: 1
Training loss: 2.4650134044847607
Validation loss: 2.45534826070657

Epoch: 5| Step: 2
Training loss: 2.9067461144091706
Validation loss: 2.4525695564764285

Epoch: 5| Step: 3
Training loss: 2.4102746572729905
Validation loss: 2.4555959951969912

Epoch: 5| Step: 4
Training loss: 2.675119671863123
Validation loss: 2.4577137757699408

Epoch: 5| Step: 5
Training loss: 2.062370527422949
Validation loss: 2.451628402608665

Epoch: 5| Step: 6
Training loss: 2.244599112079971
Validation loss: 2.454954546334759

Epoch: 5| Step: 7
Training loss: 2.6523015913611454
Validation loss: 2.4456376579640158

Epoch: 5| Step: 8
Training loss: 1.893186237280506
Validation loss: 2.4562156750882824

Epoch: 5| Step: 9
Training loss: 2.1573168561696767
Validation loss: 2.4549749327918797

Epoch: 5| Step: 10
Training loss: 2.6559410364316194
Validation loss: 2.450937109415436

Epoch: 5| Step: 11
Training loss: 3.8604339505896528
Validation loss: 2.4535032454531973

Epoch: 153| Step: 0
Training loss: 2.393183915655124
Validation loss: 2.460776756728685

Epoch: 5| Step: 1
Training loss: 2.390960570076879
Validation loss: 2.471586714249057

Epoch: 5| Step: 2
Training loss: 1.8628676493262344
Validation loss: 2.4804135974749912

Epoch: 5| Step: 3
Training loss: 2.1332217092914725
Validation loss: 2.512627519784449

Epoch: 5| Step: 4
Training loss: 2.7396728636371455
Validation loss: 2.5194079622765115

Epoch: 5| Step: 5
Training loss: 3.4120893909063468
Validation loss: 2.516975964135524

Epoch: 5| Step: 6
Training loss: 2.1295854797332563
Validation loss: 2.4722506133662634

Epoch: 5| Step: 7
Training loss: 2.3495228181466854
Validation loss: 2.449001726495963

Epoch: 5| Step: 8
Training loss: 2.8463535337921493
Validation loss: 2.4562939344687944

Epoch: 5| Step: 9
Training loss: 2.6176454058085366
Validation loss: 2.4604941821558937

Epoch: 5| Step: 10
Training loss: 2.749272336922692
Validation loss: 2.4610580091892644

Epoch: 5| Step: 11
Training loss: 2.2628641077928022
Validation loss: 2.4626330554341753

Epoch: 154| Step: 0
Training loss: 2.662580598139586
Validation loss: 2.47793796421963

Epoch: 5| Step: 1
Training loss: 2.443195730899611
Validation loss: 2.4680358843775894

Epoch: 5| Step: 2
Training loss: 2.2433414480431964
Validation loss: 2.4802685554196606

Epoch: 5| Step: 3
Training loss: 2.5261127475031957
Validation loss: 2.4753602496219775

Epoch: 5| Step: 4
Training loss: 2.3128663881124334
Validation loss: 2.481342732404614

Epoch: 5| Step: 5
Training loss: 2.3833321426851013
Validation loss: 2.4731229007298468

Epoch: 5| Step: 6
Training loss: 2.5236184259044014
Validation loss: 2.4810589506199805

Epoch: 5| Step: 7
Training loss: 2.3575055124131414
Validation loss: 2.482297412504418

Epoch: 5| Step: 8
Training loss: 3.1887014779975393
Validation loss: 2.48048395667834

Epoch: 5| Step: 9
Training loss: 3.146942010675552
Validation loss: 2.4818568833528154

Epoch: 5| Step: 10
Training loss: 1.912185495983058
Validation loss: 2.469860913418607

Epoch: 5| Step: 11
Training loss: 2.91593026446981
Validation loss: 2.479811035024421

Epoch: 155| Step: 0
Training loss: 2.696418778429681
Validation loss: 2.466119866132061

Epoch: 5| Step: 1
Training loss: 1.7352954381004018
Validation loss: 2.4794502389971993

Epoch: 5| Step: 2
Training loss: 2.414356695229712
Validation loss: 2.481757810757959

Epoch: 5| Step: 3
Training loss: 2.2876914022446946
Validation loss: 2.5081840033981346

Epoch: 5| Step: 4
Training loss: 2.8147594277284744
Validation loss: 2.5180845853583165

Epoch: 5| Step: 5
Training loss: 2.545778939706092
Validation loss: 2.5091428030921743

Epoch: 5| Step: 6
Training loss: 2.8562676894560437
Validation loss: 2.5150177461606025

Epoch: 5| Step: 7
Training loss: 3.2589432837346406
Validation loss: 2.504948187477506

Epoch: 5| Step: 8
Training loss: 2.0726898938326723
Validation loss: 2.4951934822695656

Epoch: 5| Step: 9
Training loss: 2.8403286316621608
Validation loss: 2.4703295117379

Epoch: 5| Step: 10
Training loss: 2.408167186756629
Validation loss: 2.4576003644142546

Epoch: 5| Step: 11
Training loss: 2.305072713437344
Validation loss: 2.4577534538560113

Epoch: 156| Step: 0
Training loss: 2.2654055785113063
Validation loss: 2.4598063457838597

Epoch: 5| Step: 1
Training loss: 2.152226107336785
Validation loss: 2.4510596666324953

Epoch: 5| Step: 2
Training loss: 3.0977675428758085
Validation loss: 2.452863784618729

Epoch: 5| Step: 3
Training loss: 2.4504155059675057
Validation loss: 2.460783722528455

Epoch: 5| Step: 4
Training loss: 2.1858148896281153
Validation loss: 2.450546038853047

Epoch: 5| Step: 5
Training loss: 2.339209469017558
Validation loss: 2.455690700489988

Epoch: 5| Step: 6
Training loss: 2.5698853111652133
Validation loss: 2.455104972391108

Epoch: 5| Step: 7
Training loss: 2.449636907336106
Validation loss: 2.4588275078673223

Epoch: 5| Step: 8
Training loss: 2.397247019001397
Validation loss: 2.459730249814586

Epoch: 5| Step: 9
Training loss: 2.768569843984086
Validation loss: 2.4507838049662385

Epoch: 5| Step: 10
Training loss: 2.2940583897470543
Validation loss: 2.4570760798647755

Epoch: 5| Step: 11
Training loss: 3.350804383226278
Validation loss: 2.445226060438439

Epoch: 157| Step: 0
Training loss: 2.427539526070537
Validation loss: 2.4510759089150853

Epoch: 5| Step: 1
Training loss: 2.0636312676788093
Validation loss: 2.4486334880718283

Epoch: 5| Step: 2
Training loss: 2.621222821168882
Validation loss: 2.4544886951487963

Epoch: 5| Step: 3
Training loss: 2.177835860688839
Validation loss: 2.4482631593690303

Epoch: 5| Step: 4
Training loss: 2.343394341504417
Validation loss: 2.4480344432878143

Epoch: 5| Step: 5
Training loss: 2.793797510071679
Validation loss: 2.4490842888775375

Epoch: 5| Step: 6
Training loss: 3.075927724686111
Validation loss: 2.4570031419691762

Epoch: 5| Step: 7
Training loss: 2.704649126209265
Validation loss: 2.4576999055681763

Epoch: 5| Step: 8
Training loss: 2.109995884823515
Validation loss: 2.4501520636785723

Epoch: 5| Step: 9
Training loss: 2.57169033792034
Validation loss: 2.451762787008485

Epoch: 5| Step: 10
Training loss: 2.111107460933452
Validation loss: 2.4480716953832236

Epoch: 5| Step: 11
Training loss: 2.50415456793259
Validation loss: 2.4506684575357975

Epoch: 158| Step: 0
Training loss: 3.1076241169062806
Validation loss: 2.4442460941146797

Epoch: 5| Step: 1
Training loss: 2.50930561050495
Validation loss: 2.445037243334496

Epoch: 5| Step: 2
Training loss: 2.468027999181215
Validation loss: 2.4472095293302107

Epoch: 5| Step: 3
Training loss: 2.4286524294319762
Validation loss: 2.4539883991406133

Epoch: 5| Step: 4
Training loss: 2.122298599231342
Validation loss: 2.4499164745469533

Epoch: 5| Step: 5
Training loss: 2.2629871665870525
Validation loss: 2.446684453486624

Epoch: 5| Step: 6
Training loss: 2.3247674887282703
Validation loss: 2.449513173798363

Epoch: 5| Step: 7
Training loss: 2.9341973751692634
Validation loss: 2.4561062594409724

Epoch: 5| Step: 8
Training loss: 2.4228763602116716
Validation loss: 2.452703208865063

Epoch: 5| Step: 9
Training loss: 2.2405864036566356
Validation loss: 2.460263699926559

Epoch: 5| Step: 10
Training loss: 2.4109592676570695
Validation loss: 2.462536154318621

Epoch: 5| Step: 11
Training loss: 1.9785640669199314
Validation loss: 2.4470358109196724

Epoch: 159| Step: 0
Training loss: 2.6292102292215738
Validation loss: 2.4551030989504357

Epoch: 5| Step: 1
Training loss: 2.3515509418190828
Validation loss: 2.4550876743694388

Epoch: 5| Step: 2
Training loss: 2.6971479717562907
Validation loss: 2.455605336232955

Epoch: 5| Step: 3
Training loss: 2.9619728230962457
Validation loss: 2.4528664738197277

Epoch: 5| Step: 4
Training loss: 2.0675120865123753
Validation loss: 2.4569616464561728

Epoch: 5| Step: 5
Training loss: 2.429051453970034
Validation loss: 2.4525785100673287

Epoch: 5| Step: 6
Training loss: 2.2911601691734442
Validation loss: 2.4702647065202736

Epoch: 5| Step: 7
Training loss: 2.518314700694132
Validation loss: 2.4645337183374103

Epoch: 5| Step: 8
Training loss: 1.9806613565119322
Validation loss: 2.4676037594070257

Epoch: 5| Step: 9
Training loss: 2.006344626028224
Validation loss: 2.464694216585929

Epoch: 5| Step: 10
Training loss: 2.704038079902174
Validation loss: 2.4633957548797154

Epoch: 5| Step: 11
Training loss: 4.158234316170005
Validation loss: 2.460941754695706

Epoch: 160| Step: 0
Training loss: 2.5959566220742993
Validation loss: 2.456549807039642

Epoch: 5| Step: 1
Training loss: 2.152216691214805
Validation loss: 2.4552071819915033

Epoch: 5| Step: 2
Training loss: 2.448947045740887
Validation loss: 2.45862138940924

Epoch: 5| Step: 3
Training loss: 2.625907377819097
Validation loss: 2.45959157317333

Epoch: 5| Step: 4
Training loss: 3.066025553597442
Validation loss: 2.46210673172345

Epoch: 5| Step: 5
Training loss: 2.2013033647366904
Validation loss: 2.4515418149660197

Epoch: 5| Step: 6
Training loss: 2.118028987307931
Validation loss: 2.457936623994472

Epoch: 5| Step: 7
Training loss: 2.2859531154346926
Validation loss: 2.4567021693865234

Epoch: 5| Step: 8
Training loss: 2.411505174834164
Validation loss: 2.463320221468142

Epoch: 5| Step: 9
Training loss: 2.336028438571373
Validation loss: 2.45875726428217

Epoch: 5| Step: 10
Training loss: 2.600968576630847
Validation loss: 2.448315921987276

Epoch: 5| Step: 11
Training loss: 2.7195705184139767
Validation loss: 2.4533244940760053

Epoch: 161| Step: 0
Training loss: 2.329350296270266
Validation loss: 2.471805558754416

Epoch: 5| Step: 1
Training loss: 2.219898410225385
Validation loss: 2.4655610062127447

Epoch: 5| Step: 2
Training loss: 2.3444726465687404
Validation loss: 2.4720465504515765

Epoch: 5| Step: 3
Training loss: 2.3244950843475154
Validation loss: 2.475487773687088

Epoch: 5| Step: 4
Training loss: 2.871490990801452
Validation loss: 2.4609264312979624

Epoch: 5| Step: 5
Training loss: 2.570312314482801
Validation loss: 2.450678133535677

Epoch: 5| Step: 6
Training loss: 2.7673991057243206
Validation loss: 2.460704465459329

Epoch: 5| Step: 7
Training loss: 2.1918417214031103
Validation loss: 2.4586504405722125

Epoch: 5| Step: 8
Training loss: 2.481893775886211
Validation loss: 2.4592795867701662

Epoch: 5| Step: 9
Training loss: 2.5442395763110595
Validation loss: 2.4585850608307678

Epoch: 5| Step: 10
Training loss: 2.7572811144281126
Validation loss: 2.465618803647454

Epoch: 5| Step: 11
Training loss: 2.5766992499136596
Validation loss: 2.4627689388988627

Epoch: 162| Step: 0
Training loss: 2.8070181935763445
Validation loss: 2.4559388190885327

Epoch: 5| Step: 1
Training loss: 2.638984576938743
Validation loss: 2.48350494072386

Epoch: 5| Step: 2
Training loss: 2.9599939619466697
Validation loss: 2.523151475976764

Epoch: 5| Step: 3
Training loss: 2.4361548013030423
Validation loss: 2.5616837767780583

Epoch: 5| Step: 4
Training loss: 2.3705448728255685
Validation loss: 2.590446965780434

Epoch: 5| Step: 5
Training loss: 2.8593239701517175
Validation loss: 2.566989520799899

Epoch: 5| Step: 6
Training loss: 3.2950636963772935
Validation loss: 2.5700125514427774

Epoch: 5| Step: 7
Training loss: 2.2019230154163685
Validation loss: 2.536172789389691

Epoch: 5| Step: 8
Training loss: 1.9856388542789427
Validation loss: 2.4941425328457756

Epoch: 5| Step: 9
Training loss: 2.063656569364025
Validation loss: 2.4735107753211283

Epoch: 5| Step: 10
Training loss: 2.3847661248783774
Validation loss: 2.46324625455189

Epoch: 5| Step: 11
Training loss: 1.7508165634250288
Validation loss: 2.4510733737886095

Epoch: 163| Step: 0
Training loss: 2.47441147251522
Validation loss: 2.44870192465812

Epoch: 5| Step: 1
Training loss: 2.349946642330791
Validation loss: 2.455702907277577

Epoch: 5| Step: 2
Training loss: 2.8662405503155086
Validation loss: 2.4585802808210215

Epoch: 5| Step: 3
Training loss: 1.892004723387744
Validation loss: 2.462016213363409

Epoch: 5| Step: 4
Training loss: 2.84418492606876
Validation loss: 2.4669466313008073

Epoch: 5| Step: 5
Training loss: 2.7414275852611376
Validation loss: 2.462613430250767

Epoch: 5| Step: 6
Training loss: 2.50835358198575
Validation loss: 2.4673352513555358

Epoch: 5| Step: 7
Training loss: 2.4780282577738464
Validation loss: 2.4676270606936686

Epoch: 5| Step: 8
Training loss: 2.8922165896510306
Validation loss: 2.4659487005367824

Epoch: 5| Step: 9
Training loss: 2.009899316609898
Validation loss: 2.4672737093635466

Epoch: 5| Step: 10
Training loss: 2.6263168301764854
Validation loss: 2.460625595429891

Epoch: 5| Step: 11
Training loss: 1.2002319628316274
Validation loss: 2.458264836202979

Epoch: 164| Step: 0
Training loss: 2.459453413802654
Validation loss: 2.454562909780542

Epoch: 5| Step: 1
Training loss: 2.0473369048093755
Validation loss: 2.455994598078301

Epoch: 5| Step: 2
Training loss: 2.795412501704802
Validation loss: 2.456513464001158

Epoch: 5| Step: 3
Training loss: 1.790798028438455
Validation loss: 2.449370519954046

Epoch: 5| Step: 4
Training loss: 2.4930447147550456
Validation loss: 2.4471119464299367

Epoch: 5| Step: 5
Training loss: 2.8604657536846916
Validation loss: 2.4453666242270704

Epoch: 5| Step: 6
Training loss: 2.549514806626261
Validation loss: 2.448533728452605

Epoch: 5| Step: 7
Training loss: 2.067119280669095
Validation loss: 2.44299963669404

Epoch: 5| Step: 8
Training loss: 2.709187407197611
Validation loss: 2.451103114243992

Epoch: 5| Step: 9
Training loss: 2.7502349406366595
Validation loss: 2.448730541773117

Epoch: 5| Step: 10
Training loss: 2.651441822441701
Validation loss: 2.449434862027491

Epoch: 5| Step: 11
Training loss: 1.9195296079871575
Validation loss: 2.4511926941411777

Epoch: 165| Step: 0
Training loss: 2.4257401664068294
Validation loss: 2.46347810503288

Epoch: 5| Step: 1
Training loss: 2.697974794760704
Validation loss: 2.474609844686438

Epoch: 5| Step: 2
Training loss: 2.1105841667782244
Validation loss: 2.4598322530931434

Epoch: 5| Step: 3
Training loss: 1.757551385771326
Validation loss: 2.454939569990729

Epoch: 5| Step: 4
Training loss: 2.1267793722791395
Validation loss: 2.454576261457639

Epoch: 5| Step: 5
Training loss: 2.9437920569394014
Validation loss: 2.443541790612072

Epoch: 5| Step: 6
Training loss: 2.210557669104124
Validation loss: 2.4468242453243594

Epoch: 5| Step: 7
Training loss: 2.6709916288586726
Validation loss: 2.4445086570696213

Epoch: 5| Step: 8
Training loss: 2.6122236406820125
Validation loss: 2.463353451615265

Epoch: 5| Step: 9
Training loss: 2.582606449204402
Validation loss: 2.4582996015874587

Epoch: 5| Step: 10
Training loss: 3.020875303481117
Validation loss: 2.4624895479654962

Epoch: 5| Step: 11
Training loss: 2.4015620750967925
Validation loss: 2.4443914529325865

Epoch: 166| Step: 0
Training loss: 2.4807251805197303
Validation loss: 2.456372312682554

Epoch: 5| Step: 1
Training loss: 2.155762327027802
Validation loss: 2.4543368065756064

Epoch: 5| Step: 2
Training loss: 2.5363985612055138
Validation loss: 2.452359746317945

Epoch: 5| Step: 3
Training loss: 2.1597921054187483
Validation loss: 2.4540644667048515

Epoch: 5| Step: 4
Training loss: 2.5096766118395424
Validation loss: 2.4622819164933123

Epoch: 5| Step: 5
Training loss: 2.405344012236027
Validation loss: 2.4602640310279593

Epoch: 5| Step: 6
Training loss: 2.609360106648412
Validation loss: 2.4622761390644645

Epoch: 5| Step: 7
Training loss: 2.8267909323020457
Validation loss: 2.4638115706121853

Epoch: 5| Step: 8
Training loss: 1.8486277826546074
Validation loss: 2.462063254355583

Epoch: 5| Step: 9
Training loss: 2.8323875045321887
Validation loss: 2.4563618947524386

Epoch: 5| Step: 10
Training loss: 2.5747831012521525
Validation loss: 2.4580987209503125

Epoch: 5| Step: 11
Training loss: 3.364022380414217
Validation loss: 2.4550330360984156

Epoch: 167| Step: 0
Training loss: 1.993986446985006
Validation loss: 2.452930163281608

Epoch: 5| Step: 1
Training loss: 2.3992966098008304
Validation loss: 2.462208051528369

Epoch: 5| Step: 2
Training loss: 2.482538083985811
Validation loss: 2.4555247893630816

Epoch: 5| Step: 3
Training loss: 2.4210101152261516
Validation loss: 2.4589844073193836

Epoch: 5| Step: 4
Training loss: 2.66185474367444
Validation loss: 2.450285874283602

Epoch: 5| Step: 5
Training loss: 2.3573944671731635
Validation loss: 2.447962542705961

Epoch: 5| Step: 6
Training loss: 2.841908959344603
Validation loss: 2.4505210914300886

Epoch: 5| Step: 7
Training loss: 3.2819063529277015
Validation loss: 2.447867650021512

Epoch: 5| Step: 8
Training loss: 1.909455652609462
Validation loss: 2.45330967785049

Epoch: 5| Step: 9
Training loss: 2.613373029206262
Validation loss: 2.4481607978235043

Epoch: 5| Step: 10
Training loss: 2.313718320195862
Validation loss: 2.4487858115344845

Epoch: 5| Step: 11
Training loss: 0.9996650850216305
Validation loss: 2.4538336578646507

Epoch: 168| Step: 0
Training loss: 2.318434960692594
Validation loss: 2.4525671484591838

Epoch: 5| Step: 1
Training loss: 2.5848605860999068
Validation loss: 2.4601945068318

Epoch: 5| Step: 2
Training loss: 2.097755586058665
Validation loss: 2.4557539546574456

Epoch: 5| Step: 3
Training loss: 2.650565493724582
Validation loss: 2.4572547240887643

Epoch: 5| Step: 4
Training loss: 2.643346253355889
Validation loss: 2.4603856472113246

Epoch: 5| Step: 5
Training loss: 2.385134906592087
Validation loss: 2.4682437039556486

Epoch: 5| Step: 6
Training loss: 2.5462651370932416
Validation loss: 2.4640858649301336

Epoch: 5| Step: 7
Training loss: 2.9870456110585164
Validation loss: 2.462176665913156

Epoch: 5| Step: 8
Training loss: 2.1553403621873226
Validation loss: 2.4611135187728084

Epoch: 5| Step: 9
Training loss: 2.343512968157289
Validation loss: 2.464203613875264

Epoch: 5| Step: 10
Training loss: 2.3246654433865395
Validation loss: 2.444635803386038

Epoch: 5| Step: 11
Training loss: 2.2093888645195725
Validation loss: 2.4544482377790837

Epoch: 169| Step: 0
Training loss: 2.7620752689897756
Validation loss: 2.454627162289718

Epoch: 5| Step: 1
Training loss: 2.6587934097885566
Validation loss: 2.448494426371446

Epoch: 5| Step: 2
Training loss: 2.2394825639158817
Validation loss: 2.4512023234914224

Epoch: 5| Step: 3
Training loss: 2.247860208909537
Validation loss: 2.461157095663462

Epoch: 5| Step: 4
Training loss: 2.5101761656563855
Validation loss: 2.4542677135314666

Epoch: 5| Step: 5
Training loss: 3.032153122852605
Validation loss: 2.452119799504581

Epoch: 5| Step: 6
Training loss: 2.662293504041235
Validation loss: 2.468840615504777

Epoch: 5| Step: 7
Training loss: 2.180334835935906
Validation loss: 2.46140434237134

Epoch: 5| Step: 8
Training loss: 2.3503372193923235
Validation loss: 2.4641018540411186

Epoch: 5| Step: 9
Training loss: 2.49709971995785
Validation loss: 2.4518414518790532

Epoch: 5| Step: 10
Training loss: 1.9605248613598063
Validation loss: 2.4585555805887602

Epoch: 5| Step: 11
Training loss: 0.9016543310194762
Validation loss: 2.4501355557828424

Epoch: 170| Step: 0
Training loss: 2.316289220108358
Validation loss: 2.4454951152111875

Epoch: 5| Step: 1
Training loss: 2.8441567601648825
Validation loss: 2.457199313304231

Epoch: 5| Step: 2
Training loss: 2.760605043905241
Validation loss: 2.4563821158497343

Epoch: 5| Step: 3
Training loss: 2.1929008296699353
Validation loss: 2.46194124288761

Epoch: 5| Step: 4
Training loss: 2.359077687509584
Validation loss: 2.4595935158957944

Epoch: 5| Step: 5
Training loss: 2.596292651234308
Validation loss: 2.4634670477461365

Epoch: 5| Step: 6
Training loss: 2.265242024642466
Validation loss: 2.4664202694861466

Epoch: 5| Step: 7
Training loss: 2.442505319017536
Validation loss: 2.474343827312944

Epoch: 5| Step: 8
Training loss: 2.4163852615505603
Validation loss: 2.4582672608650618

Epoch: 5| Step: 9
Training loss: 2.519103778386861
Validation loss: 2.476865663635179

Epoch: 5| Step: 10
Training loss: 2.2827861264772618
Validation loss: 2.4668904556319875

Epoch: 5| Step: 11
Training loss: 2.05544739802372
Validation loss: 2.472608607005438

Epoch: 171| Step: 0
Training loss: 2.650094383286363
Validation loss: 2.4644532456062653

Epoch: 5| Step: 1
Training loss: 2.5337629677544653
Validation loss: 2.4716809133473623

Epoch: 5| Step: 2
Training loss: 2.0829291778186674
Validation loss: 2.4942717690717324

Epoch: 5| Step: 3
Training loss: 2.3819222209797015
Validation loss: 2.4743270692922894

Epoch: 5| Step: 4
Training loss: 2.0603605791820905
Validation loss: 2.4854920073412488

Epoch: 5| Step: 5
Training loss: 2.3549958065829837
Validation loss: 2.4785875771421666

Epoch: 5| Step: 6
Training loss: 2.334311439231001
Validation loss: 2.4877483090630803

Epoch: 5| Step: 7
Training loss: 2.723687259954612
Validation loss: 2.4656843997776963

Epoch: 5| Step: 8
Training loss: 1.9303496302028342
Validation loss: 2.464584078967341

Epoch: 5| Step: 9
Training loss: 3.1153889680489675
Validation loss: 2.4673822291881393

Epoch: 5| Step: 10
Training loss: 2.6724317539447453
Validation loss: 2.462516165291386

Epoch: 5| Step: 11
Training loss: 2.3820835687053252
Validation loss: 2.472834166382824

Epoch: 172| Step: 0
Training loss: 2.4232854858180386
Validation loss: 2.461810022920095

Epoch: 5| Step: 1
Training loss: 2.2655147131023456
Validation loss: 2.4617034123914547

Epoch: 5| Step: 2
Training loss: 2.0171731134281345
Validation loss: 2.4589257792590784

Epoch: 5| Step: 3
Training loss: 2.117834463896384
Validation loss: 2.4636547043871704

Epoch: 5| Step: 4
Training loss: 2.5014424930834633
Validation loss: 2.4599844020417487

Epoch: 5| Step: 5
Training loss: 2.74950525861932
Validation loss: 2.4540870262289283

Epoch: 5| Step: 6
Training loss: 2.565645845539935
Validation loss: 2.4581036271789847

Epoch: 5| Step: 7
Training loss: 2.0513019009846296
Validation loss: 2.459890197245608

Epoch: 5| Step: 8
Training loss: 2.7723522373240037
Validation loss: 2.4514552506051697

Epoch: 5| Step: 9
Training loss: 2.5077746617204832
Validation loss: 2.4494008022466827

Epoch: 5| Step: 10
Training loss: 3.1016928695837316
Validation loss: 2.453639917940769

Epoch: 5| Step: 11
Training loss: 2.2364451815024937
Validation loss: 2.4670008567223043

Epoch: 173| Step: 0
Training loss: 2.6315054436507213
Validation loss: 2.457175961646495

Epoch: 5| Step: 1
Training loss: 2.436366086477241
Validation loss: 2.442043605770501

Epoch: 5| Step: 2
Training loss: 2.3698625714660118
Validation loss: 2.4464787595577766

Epoch: 5| Step: 3
Training loss: 2.397609008442983
Validation loss: 2.4608054070115886

Epoch: 5| Step: 4
Training loss: 2.322590849283151
Validation loss: 2.4660217404321183

Epoch: 5| Step: 5
Training loss: 2.291221980096834
Validation loss: 2.4627745699582544

Epoch: 5| Step: 6
Training loss: 2.7030332693069963
Validation loss: 2.4589239935699254

Epoch: 5| Step: 7
Training loss: 2.414810904134788
Validation loss: 2.463046944981893

Epoch: 5| Step: 8
Training loss: 2.430388223852341
Validation loss: 2.4606583330969647

Epoch: 5| Step: 9
Training loss: 1.8465806600646384
Validation loss: 2.464180888958515

Epoch: 5| Step: 10
Training loss: 3.0076441333761923
Validation loss: 2.458091442416755

Epoch: 5| Step: 11
Training loss: 1.835172713048761
Validation loss: 2.4712000170039294

Epoch: 174| Step: 0
Training loss: 2.291620589284346
Validation loss: 2.465030638898973

Epoch: 5| Step: 1
Training loss: 2.84195157708211
Validation loss: 2.4807858322007372

Epoch: 5| Step: 2
Training loss: 2.7960799808168497
Validation loss: 2.4702435373858034

Epoch: 5| Step: 3
Training loss: 1.9284667814211054
Validation loss: 2.472462068458992

Epoch: 5| Step: 4
Training loss: 2.9787035673286795
Validation loss: 2.4789447057293694

Epoch: 5| Step: 5
Training loss: 2.4271644174895917
Validation loss: 2.4803664819656084

Epoch: 5| Step: 6
Training loss: 2.6125442537638968
Validation loss: 2.4779616494075736

Epoch: 5| Step: 7
Training loss: 2.0857454704446727
Validation loss: 2.481267389001137

Epoch: 5| Step: 8
Training loss: 2.585353820020545
Validation loss: 2.4762107085824483

Epoch: 5| Step: 9
Training loss: 2.137076897044043
Validation loss: 2.4679893899336096

Epoch: 5| Step: 10
Training loss: 2.0840591946357008
Validation loss: 2.468040774877231

Epoch: 5| Step: 11
Training loss: 1.358834433226505
Validation loss: 2.4637227640399715

Epoch: 175| Step: 0
Training loss: 2.5611656250281207
Validation loss: 2.467077086806436

Epoch: 5| Step: 1
Training loss: 2.9084336475753805
Validation loss: 2.465108995226697

Epoch: 5| Step: 2
Training loss: 2.191494373854792
Validation loss: 2.4591376711586923

Epoch: 5| Step: 3
Training loss: 2.1157671115764294
Validation loss: 2.465126212853176

Epoch: 5| Step: 4
Training loss: 1.999593395386159
Validation loss: 2.462962476996669

Epoch: 5| Step: 5
Training loss: 2.1838264136655168
Validation loss: 2.456963465917502

Epoch: 5| Step: 6
Training loss: 2.516881972275562
Validation loss: 2.464491039578435

Epoch: 5| Step: 7
Training loss: 3.0036881346568456
Validation loss: 2.4531490887635594

Epoch: 5| Step: 8
Training loss: 2.561720752860703
Validation loss: 2.458341785728881

Epoch: 5| Step: 9
Training loss: 2.363774120544631
Validation loss: 2.4601228728078994

Epoch: 5| Step: 10
Training loss: 2.2577065835680625
Validation loss: 2.466133972966571

Epoch: 5| Step: 11
Training loss: 3.2820661710476307
Validation loss: 2.472058855301313

Epoch: 176| Step: 0
Training loss: 2.4022904552968
Validation loss: 2.470010290896642

Epoch: 5| Step: 1
Training loss: 2.3596002332282127
Validation loss: 2.4959818278150676

Epoch: 5| Step: 2
Training loss: 2.652652952798063
Validation loss: 2.502869975290248

Epoch: 5| Step: 3
Training loss: 2.2531277850976417
Validation loss: 2.5231207657675263

Epoch: 5| Step: 4
Training loss: 2.1943921097686245
Validation loss: 2.54563964340028

Epoch: 5| Step: 5
Training loss: 2.4175855490095453
Validation loss: 2.5369129530686703

Epoch: 5| Step: 6
Training loss: 2.539369441333107
Validation loss: 2.520805876295976

Epoch: 5| Step: 7
Training loss: 2.5467127648853207
Validation loss: 2.500091471588105

Epoch: 5| Step: 8
Training loss: 2.3586293235843097
Validation loss: 2.476614697825859

Epoch: 5| Step: 9
Training loss: 2.284197744858349
Validation loss: 2.4682460101464465

Epoch: 5| Step: 10
Training loss: 2.9974311320559908
Validation loss: 2.4691176241371835

Epoch: 5| Step: 11
Training loss: 2.6156326457906567
Validation loss: 2.478028085392182

Epoch: 177| Step: 0
Training loss: 2.535401037121517
Validation loss: 2.479051464406798

Epoch: 5| Step: 1
Training loss: 2.8029485640608884
Validation loss: 2.4857186936255617

Epoch: 5| Step: 2
Training loss: 2.6220362144256364
Validation loss: 2.4868470574619757

Epoch: 5| Step: 3
Training loss: 2.368818369661301
Validation loss: 2.488013488160305

Epoch: 5| Step: 4
Training loss: 2.274659028543943
Validation loss: 2.4927842114434977

Epoch: 5| Step: 5
Training loss: 2.905485975681661
Validation loss: 2.4882647495331516

Epoch: 5| Step: 6
Training loss: 2.2288671512162845
Validation loss: 2.4907322404621337

Epoch: 5| Step: 7
Training loss: 2.565293255079837
Validation loss: 2.4892682723410116

Epoch: 5| Step: 8
Training loss: 3.1966646872929667
Validation loss: 2.4853004315405953

Epoch: 5| Step: 9
Training loss: 1.8331218149526234
Validation loss: 2.477212042521935

Epoch: 5| Step: 10
Training loss: 2.2605581517627944
Validation loss: 2.490054167167261

Epoch: 5| Step: 11
Training loss: 3.5211375780342387
Validation loss: 2.4831586815288977

Epoch: 178| Step: 0
Training loss: 2.953380270930115
Validation loss: 2.4829248318508848

Epoch: 5| Step: 1
Training loss: 2.181355593511016
Validation loss: 2.4715186179260695

Epoch: 5| Step: 2
Training loss: 2.738339237137891
Validation loss: 2.4855013679168607

Epoch: 5| Step: 3
Training loss: 1.9982128503200869
Validation loss: 2.4815626480723147

Epoch: 5| Step: 4
Training loss: 2.447006272732357
Validation loss: 2.472659793507717

Epoch: 5| Step: 5
Training loss: 2.4496218214295205
Validation loss: 2.4716183822989026

Epoch: 5| Step: 6
Training loss: 2.78302288341812
Validation loss: 2.4755428152448036

Epoch: 5| Step: 7
Training loss: 2.6156830520294916
Validation loss: 2.4668304529670886

Epoch: 5| Step: 8
Training loss: 2.136545903050881
Validation loss: 2.4636136999479974

Epoch: 5| Step: 9
Training loss: 2.7908381091312684
Validation loss: 2.4624673599171274

Epoch: 5| Step: 10
Training loss: 2.4829133730467117
Validation loss: 2.4601744987785743

Epoch: 5| Step: 11
Training loss: 2.333656141113089
Validation loss: 2.4615230892949658

Epoch: 179| Step: 0
Training loss: 3.0288874277509543
Validation loss: 2.4630894793692

Epoch: 5| Step: 1
Training loss: 2.3945617176003156
Validation loss: 2.472783845217791

Epoch: 5| Step: 2
Training loss: 2.6107084784518646
Validation loss: 2.4982532578018932

Epoch: 5| Step: 3
Training loss: 2.291600509613401
Validation loss: 2.5332721866476984

Epoch: 5| Step: 4
Training loss: 2.11507634270866
Validation loss: 2.5450956588278375

Epoch: 5| Step: 5
Training loss: 2.63456536416361
Validation loss: 2.561726243967052

Epoch: 5| Step: 6
Training loss: 2.5881247130271534
Validation loss: 2.5157197259163477

Epoch: 5| Step: 7
Training loss: 2.781108724027754
Validation loss: 2.472018741747776

Epoch: 5| Step: 8
Training loss: 1.9989799640141848
Validation loss: 2.4618750870113804

Epoch: 5| Step: 9
Training loss: 2.521499598285039
Validation loss: 2.4533201532834816

Epoch: 5| Step: 10
Training loss: 2.6948416920665847
Validation loss: 2.4568962541215784

Epoch: 5| Step: 11
Training loss: 2.111426479084889
Validation loss: 2.4585578049532315

Epoch: 180| Step: 0
Training loss: 1.9877637628158724
Validation loss: 2.4645721237516724

Epoch: 5| Step: 1
Training loss: 2.542451351754365
Validation loss: 2.4713876693164423

Epoch: 5| Step: 2
Training loss: 2.784618438114319
Validation loss: 2.4808479519845705

Epoch: 5| Step: 3
Training loss: 2.033058417866182
Validation loss: 2.4782441143064897

Epoch: 5| Step: 4
Training loss: 2.3537658305149862
Validation loss: 2.480409864793018

Epoch: 5| Step: 5
Training loss: 2.7414485446540557
Validation loss: 2.489375917155341

Epoch: 5| Step: 6
Training loss: 2.105539635648685
Validation loss: 2.4765075152016323

Epoch: 5| Step: 7
Training loss: 2.056526318567891
Validation loss: 2.4848138113776317

Epoch: 5| Step: 8
Training loss: 2.481607683282268
Validation loss: 2.486262522129383

Epoch: 5| Step: 9
Training loss: 3.599825028299987
Validation loss: 2.480271903810388

Epoch: 5| Step: 10
Training loss: 2.7924280029960493
Validation loss: 2.473468231376548

Epoch: 5| Step: 11
Training loss: 0.7040330321760834
Validation loss: 2.4692294182422527

Epoch: 181| Step: 0
Training loss: 2.774010483560369
Validation loss: 2.4668411810674744

Epoch: 5| Step: 1
Training loss: 2.187053852906113
Validation loss: 2.4689593970749506

Epoch: 5| Step: 2
Training loss: 2.2667711187119144
Validation loss: 2.4552551302835375

Epoch: 5| Step: 3
Training loss: 2.4213325139028923
Validation loss: 2.4562992730023536

Epoch: 5| Step: 4
Training loss: 2.443060279549094
Validation loss: 2.4574422689624584

Epoch: 5| Step: 5
Training loss: 2.8211493690266773
Validation loss: 2.4654040860935034

Epoch: 5| Step: 6
Training loss: 2.6507563609228866
Validation loss: 2.468357533834883

Epoch: 5| Step: 7
Training loss: 2.2765727758339316
Validation loss: 2.4715368580530046

Epoch: 5| Step: 8
Training loss: 1.9627056888742964
Validation loss: 2.485907391921892

Epoch: 5| Step: 9
Training loss: 3.0206866700096557
Validation loss: 2.4824860627294396

Epoch: 5| Step: 10
Training loss: 2.127637012341772
Validation loss: 2.4918729808854367

Epoch: 5| Step: 11
Training loss: 1.9818968429973742
Validation loss: 2.474417354095668

Epoch: 182| Step: 0
Training loss: 2.2860446865690265
Validation loss: 2.4842693698267784

Epoch: 5| Step: 1
Training loss: 2.890604214980171
Validation loss: 2.4837213332069425

Epoch: 5| Step: 2
Training loss: 2.84967931984498
Validation loss: 2.4710967683889256

Epoch: 5| Step: 3
Training loss: 2.551234907435511
Validation loss: 2.4604549802811233

Epoch: 5| Step: 4
Training loss: 2.0185164183600204
Validation loss: 2.4714089813960154

Epoch: 5| Step: 5
Training loss: 2.689194522079388
Validation loss: 2.4724267990737165

Epoch: 5| Step: 6
Training loss: 2.2480636317658496
Validation loss: 2.474185107361462

Epoch: 5| Step: 7
Training loss: 2.7350201526854794
Validation loss: 2.471945308387896

Epoch: 5| Step: 8
Training loss: 1.5476406784083028
Validation loss: 2.471192921777027

Epoch: 5| Step: 9
Training loss: 2.6570442358662563
Validation loss: 2.465956399013934

Epoch: 5| Step: 10
Training loss: 1.6724468928688148
Validation loss: 2.4709038131486936

Epoch: 5| Step: 11
Training loss: 4.091675676904354
Validation loss: 2.469340615908122

Epoch: 183| Step: 0
Training loss: 2.459307030558942
Validation loss: 2.4794470377403797

Epoch: 5| Step: 1
Training loss: 2.3227358920200913
Validation loss: 2.469923110890013

Epoch: 5| Step: 2
Training loss: 2.6551841841495314
Validation loss: 2.4808967921869463

Epoch: 5| Step: 3
Training loss: 2.059140908998598
Validation loss: 2.4829536226632074

Epoch: 5| Step: 4
Training loss: 2.466964848855922
Validation loss: 2.4729788410584006

Epoch: 5| Step: 5
Training loss: 2.450367829873398
Validation loss: 2.4878871411988794

Epoch: 5| Step: 6
Training loss: 2.2603288507470074
Validation loss: 2.4841912879436054

Epoch: 5| Step: 7
Training loss: 2.509787949043468
Validation loss: 2.4785038371866697

Epoch: 5| Step: 8
Training loss: 2.4671706930485566
Validation loss: 2.4766603845612476

Epoch: 5| Step: 9
Training loss: 2.756304363657466
Validation loss: 2.4786269270904024

Epoch: 5| Step: 10
Training loss: 2.662027874130721
Validation loss: 2.4769114500192617

Epoch: 5| Step: 11
Training loss: 0.8698571840992434
Validation loss: 2.485010221832559

Epoch: 184| Step: 0
Training loss: 2.53905949519053
Validation loss: 2.4907733388845754

Epoch: 5| Step: 1
Training loss: 2.850985868495893
Validation loss: 2.490954437868273

Epoch: 5| Step: 2
Training loss: 2.1206569046152386
Validation loss: 2.489994267874558

Epoch: 5| Step: 3
Training loss: 2.601212028288598
Validation loss: 2.48849911137747

Epoch: 5| Step: 4
Training loss: 2.6365002803010174
Validation loss: 2.5008386794629187

Epoch: 5| Step: 5
Training loss: 2.621515959207085
Validation loss: 2.4822847962267702

Epoch: 5| Step: 6
Training loss: 1.8201279444314737
Validation loss: 2.4789875644347825

Epoch: 5| Step: 7
Training loss: 2.4914835829648467
Validation loss: 2.483565016527609

Epoch: 5| Step: 8
Training loss: 2.457606892555476
Validation loss: 2.4803084354207923

Epoch: 5| Step: 9
Training loss: 2.4840719170103336
Validation loss: 2.4796472465646766

Epoch: 5| Step: 10
Training loss: 2.105426172169207
Validation loss: 2.4769162748666087

Epoch: 5| Step: 11
Training loss: 2.883874216963628
Validation loss: 2.4792679490843734

Epoch: 185| Step: 0
Training loss: 1.9990217677539437
Validation loss: 2.469924627195256

Epoch: 5| Step: 1
Training loss: 2.208986533625161
Validation loss: 2.478334284472032

Epoch: 5| Step: 2
Training loss: 2.3024205324788363
Validation loss: 2.4846418705241935

Epoch: 5| Step: 3
Training loss: 2.070225321535675
Validation loss: 2.4848945322368485

Epoch: 5| Step: 4
Training loss: 2.983198483223605
Validation loss: 2.4720058539952916

Epoch: 5| Step: 5
Training loss: 2.3920630823193023
Validation loss: 2.4857856736093953

Epoch: 5| Step: 6
Training loss: 2.6564673839701416
Validation loss: 2.470328538566318

Epoch: 5| Step: 7
Training loss: 2.233122894943787
Validation loss: 2.485025288787693

Epoch: 5| Step: 8
Training loss: 2.437945789751505
Validation loss: 2.484390134785294

Epoch: 5| Step: 9
Training loss: 2.7896690243433646
Validation loss: 2.4706098576609303

Epoch: 5| Step: 10
Training loss: 2.5458798014577315
Validation loss: 2.47753852119485

Epoch: 5| Step: 11
Training loss: 2.1033080838960494
Validation loss: 2.4711331361439255

Epoch: 186| Step: 0
Training loss: 2.520557850899325
Validation loss: 2.476956782358106

Epoch: 5| Step: 1
Training loss: 2.272400294971363
Validation loss: 2.473391872940249

Epoch: 5| Step: 2
Training loss: 2.572758493439282
Validation loss: 2.4736616833499596

Epoch: 5| Step: 3
Training loss: 2.1822764563808077
Validation loss: 2.4784592987065164

Epoch: 5| Step: 4
Training loss: 2.023224926243459
Validation loss: 2.4871019915597024

Epoch: 5| Step: 5
Training loss: 2.47105994983849
Validation loss: 2.4886942769698255

Epoch: 5| Step: 6
Training loss: 2.8578008268773867
Validation loss: 2.48065602554266

Epoch: 5| Step: 7
Training loss: 2.204168194468016
Validation loss: 2.491695255787458

Epoch: 5| Step: 8
Training loss: 1.9264381634638954
Validation loss: 2.4862227975691105

Epoch: 5| Step: 9
Training loss: 2.2975198268761288
Validation loss: 2.4696612446872153

Epoch: 5| Step: 10
Training loss: 2.8785559183573044
Validation loss: 2.4812682577913976

Epoch: 5| Step: 11
Training loss: 3.410415482253838
Validation loss: 2.4812528036888035

Epoch: 187| Step: 0
Training loss: 2.4723522125911286
Validation loss: 2.4756393878290424

Epoch: 5| Step: 1
Training loss: 2.674015459362642
Validation loss: 2.471139250650075

Epoch: 5| Step: 2
Training loss: 2.5203868270859124
Validation loss: 2.469738919131801

Epoch: 5| Step: 3
Training loss: 2.4897041983108497
Validation loss: 2.4721734859779954

Epoch: 5| Step: 4
Training loss: 2.293389406886378
Validation loss: 2.479202628208781

Epoch: 5| Step: 5
Training loss: 2.4462777569599035
Validation loss: 2.472415894311189

Epoch: 5| Step: 6
Training loss: 2.5989289571953176
Validation loss: 2.472462168906511

Epoch: 5| Step: 7
Training loss: 2.7086452500140332
Validation loss: 2.4822820308421973

Epoch: 5| Step: 8
Training loss: 2.109486894818648
Validation loss: 2.471625186917651

Epoch: 5| Step: 9
Training loss: 2.054012173097488
Validation loss: 2.4760858074988503

Epoch: 5| Step: 10
Training loss: 2.4159968752430294
Validation loss: 2.4757286818141617

Epoch: 5| Step: 11
Training loss: 2.9504865536069023
Validation loss: 2.481899567687966

Epoch: 188| Step: 0
Training loss: 2.9369356952572474
Validation loss: 2.480701525721925

Epoch: 5| Step: 1
Training loss: 2.5782483620462253
Validation loss: 2.4863941756208026

Epoch: 5| Step: 2
Training loss: 2.3488930793940566
Validation loss: 2.4913888167685156

Epoch: 5| Step: 3
Training loss: 2.2527987769115443
Validation loss: 2.4862763948095914

Epoch: 5| Step: 4
Training loss: 1.9683272498238935
Validation loss: 2.4903950997139366

Epoch: 5| Step: 5
Training loss: 3.0469379125115426
Validation loss: 2.49367864438159

Epoch: 5| Step: 6
Training loss: 2.3191872896444226
Validation loss: 2.487209973767944

Epoch: 5| Step: 7
Training loss: 2.164554911755167
Validation loss: 2.493708908488236

Epoch: 5| Step: 8
Training loss: 2.0326076958571146
Validation loss: 2.4961792638196396

Epoch: 5| Step: 9
Training loss: 2.8539037838645074
Validation loss: 2.5072547831171317

Epoch: 5| Step: 10
Training loss: 1.924990416168532
Validation loss: 2.5015946190205858

Epoch: 5| Step: 11
Training loss: 1.6865344640816435
Validation loss: 2.5097321939777526

Epoch: 189| Step: 0
Training loss: 2.21225119878284
Validation loss: 2.487903847811241

Epoch: 5| Step: 1
Training loss: 2.5999383295521388
Validation loss: 2.499687266657579

Epoch: 5| Step: 2
Training loss: 1.8097846639690989
Validation loss: 2.490383132779857

Epoch: 5| Step: 3
Training loss: 2.2273839673305416
Validation loss: 2.483530556817895

Epoch: 5| Step: 4
Training loss: 2.902227263339956
Validation loss: 2.475811309888767

Epoch: 5| Step: 5
Training loss: 2.523986000941126
Validation loss: 2.4735540856143583

Epoch: 5| Step: 6
Training loss: 2.502855386870254
Validation loss: 2.4805143817699222

Epoch: 5| Step: 7
Training loss: 2.8519713226310435
Validation loss: 2.4816388031356245

Epoch: 5| Step: 8
Training loss: 2.078035395705387
Validation loss: 2.489900015530496

Epoch: 5| Step: 9
Training loss: 1.917730250553646
Validation loss: 2.480986225286999

Epoch: 5| Step: 10
Training loss: 2.5742021713533387
Validation loss: 2.478931224820217

Epoch: 5| Step: 11
Training loss: 2.932297502763721
Validation loss: 2.478493267787163

Epoch: 190| Step: 0
Training loss: 2.2703798056994087
Validation loss: 2.4828928919029103

Epoch: 5| Step: 1
Training loss: 2.8142531970540436
Validation loss: 2.486125972787443

Epoch: 5| Step: 2
Training loss: 2.2316115569911323
Validation loss: 2.4791741664890576

Epoch: 5| Step: 3
Training loss: 2.107868249833178
Validation loss: 2.4790864231576313

Epoch: 5| Step: 4
Training loss: 2.137472239531561
Validation loss: 2.4825322016368694

Epoch: 5| Step: 5
Training loss: 2.6213202343118986
Validation loss: 2.483465132053375

Epoch: 5| Step: 6
Training loss: 2.4412801725258455
Validation loss: 2.4811075464348704

Epoch: 5| Step: 7
Training loss: 2.2434297635956897
Validation loss: 2.4816646386422847

Epoch: 5| Step: 8
Training loss: 2.847893850202118
Validation loss: 2.488424232163621

Epoch: 5| Step: 9
Training loss: 2.121640523053734
Validation loss: 2.4878310270833084

Epoch: 5| Step: 10
Training loss: 2.5589174488104653
Validation loss: 2.4899565936968897

Epoch: 5| Step: 11
Training loss: 2.7415561220866036
Validation loss: 2.4918734911705256

Epoch: 191| Step: 0
Training loss: 2.2077315848196655
Validation loss: 2.4978463472952246

Epoch: 5| Step: 1
Training loss: 2.011312202928458
Validation loss: 2.485923356568044

Epoch: 5| Step: 2
Training loss: 2.3867035660830433
Validation loss: 2.482507911789891

Epoch: 5| Step: 3
Training loss: 2.531604694899619
Validation loss: 2.494441477037018

Epoch: 5| Step: 4
Training loss: 2.5101646729514084
Validation loss: 2.4826781437993026

Epoch: 5| Step: 5
Training loss: 2.2780604600594514
Validation loss: 2.487975380711064

Epoch: 5| Step: 6
Training loss: 2.297292450837571
Validation loss: 2.4831419389903733

Epoch: 5| Step: 7
Training loss: 2.216628013598896
Validation loss: 2.4863394921525654

Epoch: 5| Step: 8
Training loss: 2.66322344770116
Validation loss: 2.4824107120081846

Epoch: 5| Step: 9
Training loss: 2.8460298558784936
Validation loss: 2.4814314928787176

Epoch: 5| Step: 10
Training loss: 2.3194521969217066
Validation loss: 2.4804814896544256

Epoch: 5| Step: 11
Training loss: 3.7086822402776147
Validation loss: 2.492809098552111

Epoch: 192| Step: 0
Training loss: 2.5375526046937695
Validation loss: 2.4858788670998773

Epoch: 5| Step: 1
Training loss: 2.110409857188841
Validation loss: 2.5088189027881835

Epoch: 5| Step: 2
Training loss: 2.423259708417758
Validation loss: 2.519168502362342

Epoch: 5| Step: 3
Training loss: 2.4797547762132828
Validation loss: 2.4993012723408765

Epoch: 5| Step: 4
Training loss: 2.6035822912038546
Validation loss: 2.5013027333476017

Epoch: 5| Step: 5
Training loss: 2.15701490463038
Validation loss: 2.5092210131754027

Epoch: 5| Step: 6
Training loss: 2.61277339545147
Validation loss: 2.4979297529953692

Epoch: 5| Step: 7
Training loss: 2.1448920941721266
Validation loss: 2.495599553511646

Epoch: 5| Step: 8
Training loss: 2.635951313373798
Validation loss: 2.5083187539024405

Epoch: 5| Step: 9
Training loss: 2.39857407966934
Validation loss: 2.4985627374200847

Epoch: 5| Step: 10
Training loss: 2.4950402652954433
Validation loss: 2.4920816528579546

Epoch: 5| Step: 11
Training loss: 1.2208328056117317
Validation loss: 2.483818101744425

Epoch: 193| Step: 0
Training loss: 1.9250026157906335
Validation loss: 2.487860463892382

Epoch: 5| Step: 1
Training loss: 2.35225446791969
Validation loss: 2.4849999039737574

Epoch: 5| Step: 2
Training loss: 2.4451671228064082
Validation loss: 2.4795771961481288

Epoch: 5| Step: 3
Training loss: 1.9363111109291025
Validation loss: 2.4796766363016918

Epoch: 5| Step: 4
Training loss: 2.4325087870393065
Validation loss: 2.4837198933192726

Epoch: 5| Step: 5
Training loss: 2.0818017543252103
Validation loss: 2.4828606274571356

Epoch: 5| Step: 6
Training loss: 3.042320877858307
Validation loss: 2.4891027095697424

Epoch: 5| Step: 7
Training loss: 2.696177998776495
Validation loss: 2.498219591204126

Epoch: 5| Step: 8
Training loss: 2.264101660727416
Validation loss: 2.4921751350885337

Epoch: 5| Step: 9
Training loss: 2.3210886674977487
Validation loss: 2.496061222379868

Epoch: 5| Step: 10
Training loss: 2.5578195579958076
Validation loss: 2.4978940358752735

Epoch: 5| Step: 11
Training loss: 3.5663268298762407
Validation loss: 2.505439320712495

Epoch: 194| Step: 0
Training loss: 2.5204722458503785
Validation loss: 2.491616019135032

Epoch: 5| Step: 1
Training loss: 2.8304785951237315
Validation loss: 2.503584632313325

Epoch: 5| Step: 2
Training loss: 2.2611614588267024
Validation loss: 2.4921227051095705

Epoch: 5| Step: 3
Training loss: 1.9090042228751938
Validation loss: 2.502811531793543

Epoch: 5| Step: 4
Training loss: 2.7921291556557324
Validation loss: 2.5085347998199072

Epoch: 5| Step: 5
Training loss: 2.5523543129647797
Validation loss: 2.515725305583325

Epoch: 5| Step: 6
Training loss: 1.9702609485776528
Validation loss: 2.5126801782026975

Epoch: 5| Step: 7
Training loss: 2.0019661060935845
Validation loss: 2.490940702907928

Epoch: 5| Step: 8
Training loss: 1.9314464629651367
Validation loss: 2.504982534980296

Epoch: 5| Step: 9
Training loss: 2.7849619237190555
Validation loss: 2.5149072290478958

Epoch: 5| Step: 10
Training loss: 2.731426545816162
Validation loss: 2.4973450152676717

Epoch: 5| Step: 11
Training loss: 2.148135521213403
Validation loss: 2.5010092962909023

Epoch: 195| Step: 0
Training loss: 2.279912373548771
Validation loss: 2.494221818678272

Epoch: 5| Step: 1
Training loss: 2.702221493410687
Validation loss: 2.4892997154519176

Epoch: 5| Step: 2
Training loss: 3.0426098828624073
Validation loss: 2.4826603976713284

Epoch: 5| Step: 3
Training loss: 2.678808485167896
Validation loss: 2.4907152935717694

Epoch: 5| Step: 4
Training loss: 2.5258274157924756
Validation loss: 2.4957037508116855

Epoch: 5| Step: 5
Training loss: 2.4079884776096376
Validation loss: 2.487083849609427

Epoch: 5| Step: 6
Training loss: 2.4765023305424876
Validation loss: 2.5027677950258354

Epoch: 5| Step: 7
Training loss: 2.0704313424027165
Validation loss: 2.493649929591486

Epoch: 5| Step: 8
Training loss: 2.449405352771125
Validation loss: 2.49097470517143

Epoch: 5| Step: 9
Training loss: 2.535483035052457
Validation loss: 2.4879734182255095

Epoch: 5| Step: 10
Training loss: 2.26322588999379
Validation loss: 2.488734405151945

Epoch: 5| Step: 11
Training loss: 1.8857027402334456
Validation loss: 2.478143452146317

Epoch: 196| Step: 0
Training loss: 2.5218107572217345
Validation loss: 2.4901493711237515

Epoch: 5| Step: 1
Training loss: 2.5197011018026596
Validation loss: 2.483921823415372

Epoch: 5| Step: 2
Training loss: 2.8936238996742674
Validation loss: 2.480325669695083

Epoch: 5| Step: 3
Training loss: 2.5185920798346273
Validation loss: 2.4895770513117443

Epoch: 5| Step: 4
Training loss: 1.9728681696000296
Validation loss: 2.4817658925015613

Epoch: 5| Step: 5
Training loss: 2.336498282492537
Validation loss: 2.4960512088977116

Epoch: 5| Step: 6
Training loss: 2.3646553017395413
Validation loss: 2.508125158925118

Epoch: 5| Step: 7
Training loss: 1.8204932389148196
Validation loss: 2.5125402290767473

Epoch: 5| Step: 8
Training loss: 1.9419620570278064
Validation loss: 2.5414024721217814

Epoch: 5| Step: 9
Training loss: 3.203617709342409
Validation loss: 2.5361048643393413

Epoch: 5| Step: 10
Training loss: 2.5187729751637082
Validation loss: 2.4981550323001973

Epoch: 5| Step: 11
Training loss: 1.2051972712100054
Validation loss: 2.5036452142947336

Epoch: 197| Step: 0
Training loss: 2.2057102267110085
Validation loss: 2.500443888039683

Epoch: 5| Step: 1
Training loss: 2.042962681485968
Validation loss: 2.481028163835904

Epoch: 5| Step: 2
Training loss: 2.2256625314197724
Validation loss: 2.50019464927124

Epoch: 5| Step: 3
Training loss: 2.903201237099437
Validation loss: 2.4963709558412766

Epoch: 5| Step: 4
Training loss: 2.225460167779694
Validation loss: 2.500355579996946

Epoch: 5| Step: 5
Training loss: 2.3838693745112516
Validation loss: 2.4989118850534116

Epoch: 5| Step: 6
Training loss: 2.2834086199226604
Validation loss: 2.4999623573966097

Epoch: 5| Step: 7
Training loss: 2.578406671106962
Validation loss: 2.4908859776710455

Epoch: 5| Step: 8
Training loss: 2.484267514380811
Validation loss: 2.4852817568066077

Epoch: 5| Step: 9
Training loss: 2.215978476409497
Validation loss: 2.492333092019324

Epoch: 5| Step: 10
Training loss: 2.7545393845004575
Validation loss: 2.4935002033747846

Epoch: 5| Step: 11
Training loss: 2.2051846230994685
Validation loss: 2.4915947044680666

Epoch: 198| Step: 0
Training loss: 2.2090882024809084
Validation loss: 2.479903938287797

Epoch: 5| Step: 1
Training loss: 2.4926354654397653
Validation loss: 2.484358125705313

Epoch: 5| Step: 2
Training loss: 1.8360542422574215
Validation loss: 2.4812697151163134

Epoch: 5| Step: 3
Training loss: 1.9908543333359425
Validation loss: 2.4824018340023377

Epoch: 5| Step: 4
Training loss: 2.856716566981643
Validation loss: 2.488715784127303

Epoch: 5| Step: 5
Training loss: 2.6781793470888653
Validation loss: 2.5111333541590635

Epoch: 5| Step: 6
Training loss: 2.341274123589451
Validation loss: 2.495037191543171

Epoch: 5| Step: 7
Training loss: 2.9283724261999735
Validation loss: 2.4988689645675213

Epoch: 5| Step: 8
Training loss: 2.3791895605300772
Validation loss: 2.504841086949167

Epoch: 5| Step: 9
Training loss: 2.3748962982024238
Validation loss: 2.509087326675125

Epoch: 5| Step: 10
Training loss: 2.2836155580098563
Validation loss: 2.521175256244392

Epoch: 5| Step: 11
Training loss: 2.3423707082399567
Validation loss: 2.5057871910475624

Epoch: 199| Step: 0
Training loss: 2.260398677162508
Validation loss: 2.5045197083036728

Epoch: 5| Step: 1
Training loss: 2.4741198891877123
Validation loss: 2.4872324802884513

Epoch: 5| Step: 2
Training loss: 1.8860123538101137
Validation loss: 2.4920012903753586

Epoch: 5| Step: 3
Training loss: 2.434617612450415
Validation loss: 2.4785237092992767

Epoch: 5| Step: 4
Training loss: 2.4558733469336724
Validation loss: 2.497995486910255

Epoch: 5| Step: 5
Training loss: 2.591499363281831
Validation loss: 2.4925851255564764

Epoch: 5| Step: 6
Training loss: 1.823249771927851
Validation loss: 2.492043773050327

Epoch: 5| Step: 7
Training loss: 2.9213434235598634
Validation loss: 2.4807620017851137

Epoch: 5| Step: 8
Training loss: 2.7439694605759977
Validation loss: 2.4987751463616603

Epoch: 5| Step: 9
Training loss: 2.443469440716385
Validation loss: 2.491881440441929

Epoch: 5| Step: 10
Training loss: 2.2477410951153085
Validation loss: 2.485311067922039

Epoch: 5| Step: 11
Training loss: 1.3338632821880427
Validation loss: 2.4942433518553755

Epoch: 200| Step: 0
Training loss: 2.4166520436162404
Validation loss: 2.485225523904857

Epoch: 5| Step: 1
Training loss: 1.8354809781894135
Validation loss: 2.5050016438218012

Epoch: 5| Step: 2
Training loss: 2.3612146342402243
Validation loss: 2.4930301584976755

Epoch: 5| Step: 3
Training loss: 2.744143231482303
Validation loss: 2.4894793234663246

Epoch: 5| Step: 4
Training loss: 2.3835452094522833
Validation loss: 2.498239503322759

Epoch: 5| Step: 5
Training loss: 2.5945301031783825
Validation loss: 2.5025468132335478

Epoch: 5| Step: 6
Training loss: 2.6354367905000475
Validation loss: 2.4872064709601913

Epoch: 5| Step: 7
Training loss: 2.4859304297326883
Validation loss: 2.480039852838606

Epoch: 5| Step: 8
Training loss: 1.6794700304351617
Validation loss: 2.489459548783086

Epoch: 5| Step: 9
Training loss: 2.6513612525831367
Validation loss: 2.4867769701717166

Epoch: 5| Step: 10
Training loss: 2.4715595917028046
Validation loss: 2.5023599195161386

Epoch: 5| Step: 11
Training loss: 2.0962038606264364
Validation loss: 2.4912373556214003

Epoch: 201| Step: 0
Training loss: 2.7770246491428594
Validation loss: 2.490139146367761

Epoch: 5| Step: 1
Training loss: 1.8873134015543485
Validation loss: 2.493391772444252

Epoch: 5| Step: 2
Training loss: 2.1847134962296337
Validation loss: 2.483418282446935

Epoch: 5| Step: 3
Training loss: 2.564422444539912
Validation loss: 2.4949476150850054

Epoch: 5| Step: 4
Training loss: 2.399139003490387
Validation loss: 2.4826884112868957

Epoch: 5| Step: 5
Training loss: 2.709893369090079
Validation loss: 2.491516913955435

Epoch: 5| Step: 6
Training loss: 2.8118768637490525
Validation loss: 2.4973407231449984

Epoch: 5| Step: 7
Training loss: 2.274750739894352
Validation loss: 2.4829226113116096

Epoch: 5| Step: 8
Training loss: 1.8264128010985028
Validation loss: 2.496951835764634

Epoch: 5| Step: 9
Training loss: 2.3563090228471992
Validation loss: 2.491336398153774

Epoch: 5| Step: 10
Training loss: 2.0363894659887487
Validation loss: 2.4997927420853046

Epoch: 5| Step: 11
Training loss: 3.2105783971753716
Validation loss: 2.510545645496318

Epoch: 202| Step: 0
Training loss: 2.013592663898828
Validation loss: 2.514422917299396

Epoch: 5| Step: 1
Training loss: 2.145006359953444
Validation loss: 2.518987481633209

Epoch: 5| Step: 2
Training loss: 2.2155245049287307
Validation loss: 2.5086532403558084

Epoch: 5| Step: 3
Training loss: 2.1118424289401023
Validation loss: 2.529433175321208

Epoch: 5| Step: 4
Training loss: 2.3008049800147754
Validation loss: 2.518585490856461

Epoch: 5| Step: 5
Training loss: 2.728132784942671
Validation loss: 2.538510063912824

Epoch: 5| Step: 6
Training loss: 2.4060678784696043
Validation loss: 2.5474217574919877

Epoch: 5| Step: 7
Training loss: 2.7894497129779756
Validation loss: 2.512664011920796

Epoch: 5| Step: 8
Training loss: 2.507279479046435
Validation loss: 2.51044869831169

Epoch: 5| Step: 9
Training loss: 2.7388261587539207
Validation loss: 2.498920839565614

Epoch: 5| Step: 10
Training loss: 1.978967101091104
Validation loss: 2.4949515629273153

Epoch: 5| Step: 11
Training loss: 3.3409227914712094
Validation loss: 2.483573348385643

Epoch: 203| Step: 0
Training loss: 2.428718987157448
Validation loss: 2.4832683633673054

Epoch: 5| Step: 1
Training loss: 2.681177998178461
Validation loss: 2.4775562919806506

Epoch: 5| Step: 2
Training loss: 2.381485566429659
Validation loss: 2.4729876584921144

Epoch: 5| Step: 3
Training loss: 2.559904132776528
Validation loss: 2.48717846829121

Epoch: 5| Step: 4
Training loss: 2.2918992935944544
Validation loss: 2.478073990606727

Epoch: 5| Step: 5
Training loss: 1.9502289931015941
Validation loss: 2.477377616003634

Epoch: 5| Step: 6
Training loss: 2.2001551096596073
Validation loss: 2.4820293733491448

Epoch: 5| Step: 7
Training loss: 3.0722924756952064
Validation loss: 2.4798144180838197

Epoch: 5| Step: 8
Training loss: 2.1347473087903626
Validation loss: 2.479282313676186

Epoch: 5| Step: 9
Training loss: 2.3926859430426073
Validation loss: 2.496573615474979

Epoch: 5| Step: 10
Training loss: 2.556101463124815
Validation loss: 2.5016207944553526

Epoch: 5| Step: 11
Training loss: 1.596455988247753
Validation loss: 2.4870367845714676

Epoch: 204| Step: 0
Training loss: 1.954297011636763
Validation loss: 2.51340479445831

Epoch: 5| Step: 1
Training loss: 2.511903177612535
Validation loss: 2.563015788977148

Epoch: 5| Step: 2
Training loss: 3.027947740907607
Validation loss: 2.629546583921551

Epoch: 5| Step: 3
Training loss: 2.260826659632712
Validation loss: 2.593755668419462

Epoch: 5| Step: 4
Training loss: 3.0339233565183448
Validation loss: 2.5445595046822906

Epoch: 5| Step: 5
Training loss: 1.8299007431586616
Validation loss: 2.5034741977631536

Epoch: 5| Step: 6
Training loss: 2.3284949706360947
Validation loss: 2.490896853420539

Epoch: 5| Step: 7
Training loss: 2.7021204675040935
Validation loss: 2.482097569533087

Epoch: 5| Step: 8
Training loss: 2.768204342912324
Validation loss: 2.4870257481445073

Epoch: 5| Step: 9
Training loss: 2.209127703130861
Validation loss: 2.4833319531720655

Epoch: 5| Step: 10
Training loss: 2.1739884666129923
Validation loss: 2.4772024721691155

Epoch: 5| Step: 11
Training loss: 1.618103799751054
Validation loss: 2.485242304370829

Epoch: 205| Step: 0
Training loss: 2.183204902870709
Validation loss: 2.4836769842836213

Epoch: 5| Step: 1
Training loss: 2.8749384666160447
Validation loss: 2.481635924945858

Epoch: 5| Step: 2
Training loss: 2.624776739889535
Validation loss: 2.4891544448783223

Epoch: 5| Step: 3
Training loss: 2.774761217171109
Validation loss: 2.4772212759825396

Epoch: 5| Step: 4
Training loss: 2.121027430837641
Validation loss: 2.4903875445962464

Epoch: 5| Step: 5
Training loss: 2.5151561987360798
Validation loss: 2.4858009756448047

Epoch: 5| Step: 6
Training loss: 2.119934102239821
Validation loss: 2.484524488450092

Epoch: 5| Step: 7
Training loss: 2.7055228298156733
Validation loss: 2.492698381890023

Epoch: 5| Step: 8
Training loss: 2.2623121573519085
Validation loss: 2.506111443543131

Epoch: 5| Step: 9
Training loss: 2.2381152878726067
Validation loss: 2.501984285611722

Epoch: 5| Step: 10
Training loss: 2.1560903296577245
Validation loss: 2.51475285878082

Epoch: 5| Step: 11
Training loss: 2.6891269638429565
Validation loss: 2.5141037394869614

Epoch: 206| Step: 0
Training loss: 2.1126721644925373
Validation loss: 2.530725440471193

Epoch: 5| Step: 1
Training loss: 2.3214584243867056
Validation loss: 2.5300130451253073

Epoch: 5| Step: 2
Training loss: 2.4871965616221448
Validation loss: 2.5259693895729374

Epoch: 5| Step: 3
Training loss: 2.9319935585565315
Validation loss: 2.526281700658932

Epoch: 5| Step: 4
Training loss: 2.412387995516448
Validation loss: 2.514582332989089

Epoch: 5| Step: 5
Training loss: 2.7465429250688227
Validation loss: 2.5131361340308778

Epoch: 5| Step: 6
Training loss: 1.987517624303061
Validation loss: 2.498369032601776

Epoch: 5| Step: 7
Training loss: 2.126919608644615
Validation loss: 2.488890872138043

Epoch: 5| Step: 8
Training loss: 1.9778338177322141
Validation loss: 2.5107076695197468

Epoch: 5| Step: 9
Training loss: 2.712299719241642
Validation loss: 2.4969602622003397

Epoch: 5| Step: 10
Training loss: 2.514386174127117
Validation loss: 2.4931855032078976

Epoch: 5| Step: 11
Training loss: 2.8090971812531453
Validation loss: 2.4907690294549574

Epoch: 207| Step: 0
Training loss: 2.326098898152092
Validation loss: 2.4918087319686353

Epoch: 5| Step: 1
Training loss: 2.3905066167903013
Validation loss: 2.4808310136558887

Epoch: 5| Step: 2
Training loss: 1.7931247219485695
Validation loss: 2.4903196592001047

Epoch: 5| Step: 3
Training loss: 2.4817906979662814
Validation loss: 2.4888509260936256

Epoch: 5| Step: 4
Training loss: 2.779007682847326
Validation loss: 2.485542450914448

Epoch: 5| Step: 5
Training loss: 2.057629701551884
Validation loss: 2.495804222162177

Epoch: 5| Step: 6
Training loss: 2.7810931215082477
Validation loss: 2.4892406819710544

Epoch: 5| Step: 7
Training loss: 2.5509048128212677
Validation loss: 2.4992745737763733

Epoch: 5| Step: 8
Training loss: 2.35198555116043
Validation loss: 2.4977288957184753

Epoch: 5| Step: 9
Training loss: 2.8237169170763563
Validation loss: 2.4963769209841007

Epoch: 5| Step: 10
Training loss: 1.8703225603207527
Validation loss: 2.50180560314109

Epoch: 5| Step: 11
Training loss: 0.8863255641558972
Validation loss: 2.506177823017547

Epoch: 208| Step: 0
Training loss: 2.4625705689518567
Validation loss: 2.4959415395352242

Epoch: 5| Step: 1
Training loss: 2.4706084583827863
Validation loss: 2.4970906495126575

Epoch: 5| Step: 2
Training loss: 2.522170749798216
Validation loss: 2.497206693029816

Epoch: 5| Step: 3
Training loss: 2.22156271154961
Validation loss: 2.4956550550923957

Epoch: 5| Step: 4
Training loss: 2.568997774449116
Validation loss: 2.4837793739839613

Epoch: 5| Step: 5
Training loss: 2.5914787551447724
Validation loss: 2.4828713663147552

Epoch: 5| Step: 6
Training loss: 2.3755066983645006
Validation loss: 2.4688531958664472

Epoch: 5| Step: 7
Training loss: 2.624564452595214
Validation loss: 2.480757969292542

Epoch: 5| Step: 8
Training loss: 2.1288335665273106
Validation loss: 2.4834037617696216

Epoch: 5| Step: 9
Training loss: 2.0272938863689656
Validation loss: 2.483293713876576

Epoch: 5| Step: 10
Training loss: 2.6765331687589446
Validation loss: 2.490419488147577

Epoch: 5| Step: 11
Training loss: 2.8983155916390113
Validation loss: 2.487665436545251

Epoch: 209| Step: 0
Training loss: 1.8676662070833034
Validation loss: 2.4954764449044102

Epoch: 5| Step: 1
Training loss: 2.1043033240732694
Validation loss: 2.487867958802925

Epoch: 5| Step: 2
Training loss: 2.019253562267619
Validation loss: 2.480019251828174

Epoch: 5| Step: 3
Training loss: 2.3632449312808457
Validation loss: 2.4909927230722544

Epoch: 5| Step: 4
Training loss: 2.5102272648149824
Validation loss: 2.4878273774058255

Epoch: 5| Step: 5
Training loss: 2.2986658082762768
Validation loss: 2.4934168646478447

Epoch: 5| Step: 6
Training loss: 2.521170811617598
Validation loss: 2.4847118581163947

Epoch: 5| Step: 7
Training loss: 2.1275165466669237
Validation loss: 2.4983631815621345

Epoch: 5| Step: 8
Training loss: 2.183430401146414
Validation loss: 2.4960797010493025

Epoch: 5| Step: 9
Training loss: 2.9898709326097257
Validation loss: 2.501292705104602

Epoch: 5| Step: 10
Training loss: 2.9069821655755166
Validation loss: 2.4924050558035464

Epoch: 5| Step: 11
Training loss: 2.1107205090927796
Validation loss: 2.4990392627043563

Epoch: 210| Step: 0
Training loss: 2.6334248631501103
Validation loss: 2.5199265399133366

Epoch: 5| Step: 1
Training loss: 2.3282355979917195
Validation loss: 2.5129548230503076

Epoch: 5| Step: 2
Training loss: 2.6405868978967986
Validation loss: 2.541209356930863

Epoch: 5| Step: 3
Training loss: 2.7378948989379808
Validation loss: 2.5421742977212953

Epoch: 5| Step: 4
Training loss: 2.3690735004724672
Validation loss: 2.519395297224305

Epoch: 5| Step: 5
Training loss: 2.0698141397895378
Validation loss: 2.499803159832348

Epoch: 5| Step: 6
Training loss: 1.880539404409832
Validation loss: 2.499794597929745

Epoch: 5| Step: 7
Training loss: 2.2955341187976197
Validation loss: 2.4917441425164695

Epoch: 5| Step: 8
Training loss: 2.4017663773595457
Validation loss: 2.492098413068972

Epoch: 5| Step: 9
Training loss: 2.5234331538396204
Validation loss: 2.480104206360838

Epoch: 5| Step: 10
Training loss: 2.1326066920433306
Validation loss: 2.485012356556618

Epoch: 5| Step: 11
Training loss: 3.61468023487257
Validation loss: 2.4801241297382193

Epoch: 211| Step: 0
Training loss: 2.6032945520473163
Validation loss: 2.4886781424880224

Epoch: 5| Step: 1
Training loss: 2.1448788665144387
Validation loss: 2.4920931233201706

Epoch: 5| Step: 2
Training loss: 1.9485285880693564
Validation loss: 2.4963100500816116

Epoch: 5| Step: 3
Training loss: 2.661456581508311
Validation loss: 2.4970547413654414

Epoch: 5| Step: 4
Training loss: 2.923245847894331
Validation loss: 2.515246119903523

Epoch: 5| Step: 5
Training loss: 2.2023829299348376
Validation loss: 2.5619077967374473

Epoch: 5| Step: 6
Training loss: 2.6150141104031204
Validation loss: 2.5562689782816186

Epoch: 5| Step: 7
Training loss: 2.087183662247674
Validation loss: 2.5477835939912787

Epoch: 5| Step: 8
Training loss: 2.299251961346688
Validation loss: 2.5316058524899163

Epoch: 5| Step: 9
Training loss: 3.0970781708097
Validation loss: 2.5164872502378466

Epoch: 5| Step: 10
Training loss: 1.5691286245641674
Validation loss: 2.5048203329779923

Epoch: 5| Step: 11
Training loss: 2.4193286923051884
Validation loss: 2.4751099981081928

Epoch: 212| Step: 0
Training loss: 2.3052156522082776
Validation loss: 2.482886834349202

Epoch: 5| Step: 1
Training loss: 2.67712671464932
Validation loss: 2.483046702403436

Epoch: 5| Step: 2
Training loss: 2.7592059281287433
Validation loss: 2.4885045105619445

Epoch: 5| Step: 3
Training loss: 1.7182178020149637
Validation loss: 2.4885175903122216

Epoch: 5| Step: 4
Training loss: 2.5724186486077327
Validation loss: 2.486052268827833

Epoch: 5| Step: 5
Training loss: 2.1841766180020126
Validation loss: 2.4936089482965627

Epoch: 5| Step: 6
Training loss: 2.8098536439025765
Validation loss: 2.492947077021866

Epoch: 5| Step: 7
Training loss: 2.85243291242712
Validation loss: 2.4868215913766587

Epoch: 5| Step: 8
Training loss: 2.6921152805907993
Validation loss: 2.4839117909905752

Epoch: 5| Step: 9
Training loss: 2.3514500587930423
Validation loss: 2.4823557547010493

Epoch: 5| Step: 10
Training loss: 1.6813973174377654
Validation loss: 2.4861913435141076

Epoch: 5| Step: 11
Training loss: 2.2141912128129753
Validation loss: 2.4866830433143474

Epoch: 213| Step: 0
Training loss: 2.2411448749454785
Validation loss: 2.4993901860038976

Epoch: 5| Step: 1
Training loss: 2.1916043605094764
Validation loss: 2.5110606492707923

Epoch: 5| Step: 2
Training loss: 2.932367589226277
Validation loss: 2.5176490515244168

Epoch: 5| Step: 3
Training loss: 2.0013242152389883
Validation loss: 2.5363001464040047

Epoch: 5| Step: 4
Training loss: 2.6398606858919598
Validation loss: 2.5561947396110565

Epoch: 5| Step: 5
Training loss: 2.0478040610549497
Validation loss: 2.5744634617141178

Epoch: 5| Step: 6
Training loss: 2.3897318449379314
Validation loss: 2.5757135962596496

Epoch: 5| Step: 7
Training loss: 2.3256538128112396
Validation loss: 2.5469027519664333

Epoch: 5| Step: 8
Training loss: 2.799921518315831
Validation loss: 2.533387484541626

Epoch: 5| Step: 9
Training loss: 2.1259826183451875
Validation loss: 2.510974653183187

Epoch: 5| Step: 10
Training loss: 2.373217666822032
Validation loss: 2.5043558559157257

Epoch: 5| Step: 11
Training loss: 3.6273951017223123
Validation loss: 2.5003252274842054

Epoch: 214| Step: 0
Training loss: 1.9171975133210006
Validation loss: 2.5006585128078007

Epoch: 5| Step: 1
Training loss: 1.6752702694241473
Validation loss: 2.490513154425833

Epoch: 5| Step: 2
Training loss: 3.1438503120450725
Validation loss: 2.4915615898215826

Epoch: 5| Step: 3
Training loss: 2.653750870821752
Validation loss: 2.4841720130254608

Epoch: 5| Step: 4
Training loss: 2.8566063990368984
Validation loss: 2.483636512400207

Epoch: 5| Step: 5
Training loss: 2.0413795840262297
Validation loss: 2.4874278291299747

Epoch: 5| Step: 6
Training loss: 2.4309282967692
Validation loss: 2.483729318568827

Epoch: 5| Step: 7
Training loss: 1.9772721173994026
Validation loss: 2.4986713256269186

Epoch: 5| Step: 8
Training loss: 2.729827237933273
Validation loss: 2.4985612305426277

Epoch: 5| Step: 9
Training loss: 2.333585646021091
Validation loss: 2.4973712431990154

Epoch: 5| Step: 10
Training loss: 2.4003354990428085
Validation loss: 2.5085619106784827

Epoch: 5| Step: 11
Training loss: 2.081872758683779
Validation loss: 2.498212767563903

Epoch: 215| Step: 0
Training loss: 2.209150906735266
Validation loss: 2.496797795667707

Epoch: 5| Step: 1
Training loss: 2.24794198329223
Validation loss: 2.497330273247368

Epoch: 5| Step: 2
Training loss: 2.010443007011673
Validation loss: 2.4976303870857026

Epoch: 5| Step: 3
Training loss: 2.7125659635759067
Validation loss: 2.4993008629411917

Epoch: 5| Step: 4
Training loss: 2.7733284082582954
Validation loss: 2.4982416486129395

Epoch: 5| Step: 5
Training loss: 2.1925450594196345
Validation loss: 2.4954466719794532

Epoch: 5| Step: 6
Training loss: 2.3141525137714303
Validation loss: 2.485766574906539

Epoch: 5| Step: 7
Training loss: 2.7590159095064877
Validation loss: 2.494390671796385

Epoch: 5| Step: 8
Training loss: 2.3158841501622347
Validation loss: 2.495408315775702

Epoch: 5| Step: 9
Training loss: 1.9543749662325485
Validation loss: 2.4984116833442256

Epoch: 5| Step: 10
Training loss: 2.405144177276857
Validation loss: 2.5076066286191714

Epoch: 5| Step: 11
Training loss: 2.074264612068018
Validation loss: 2.5055042152919973

Epoch: 216| Step: 0
Training loss: 2.4779066415338806
Validation loss: 2.5216570262468325

Epoch: 5| Step: 1
Training loss: 3.0394181776421525
Validation loss: 2.5479515156477195

Epoch: 5| Step: 2
Training loss: 2.462064648403096
Validation loss: 2.5658340009651504

Epoch: 5| Step: 3
Training loss: 2.3132931148246683
Validation loss: 2.5581348560943975

Epoch: 5| Step: 4
Training loss: 2.5880095602091835
Validation loss: 2.5681592624000635

Epoch: 5| Step: 5
Training loss: 2.342596253297425
Validation loss: 2.556449333166578

Epoch: 5| Step: 6
Training loss: 1.958234649227913
Validation loss: 2.5498284960087765

Epoch: 5| Step: 7
Training loss: 2.1439198106957273
Validation loss: 2.5332854136736658

Epoch: 5| Step: 8
Training loss: 2.4237850409773807
Validation loss: 2.504518308138642

Epoch: 5| Step: 9
Training loss: 1.972467575870414
Validation loss: 2.500413669693934

Epoch: 5| Step: 10
Training loss: 2.383639432906319
Validation loss: 2.500637585081432

Epoch: 5| Step: 11
Training loss: 2.8617043934554913
Validation loss: 2.486594909754631

Epoch: 217| Step: 0
Training loss: 1.924139781823009
Validation loss: 2.4913113527834843

Epoch: 5| Step: 1
Training loss: 2.6363814526736196
Validation loss: 2.4863868101135904

Epoch: 5| Step: 2
Training loss: 2.237349337827859
Validation loss: 2.490430126599509

Epoch: 5| Step: 3
Training loss: 2.8660532191487085
Validation loss: 2.48979614790039

Epoch: 5| Step: 4
Training loss: 2.2785127495548565
Validation loss: 2.4909678776371127

Epoch: 5| Step: 5
Training loss: 1.9968051426567588
Validation loss: 2.476414380221965

Epoch: 5| Step: 6
Training loss: 2.043912417989604
Validation loss: 2.495739608739195

Epoch: 5| Step: 7
Training loss: 2.8330039412568344
Validation loss: 2.501509020279567

Epoch: 5| Step: 8
Training loss: 2.9273610554599236
Validation loss: 2.5121118960642

Epoch: 5| Step: 9
Training loss: 2.409776951452045
Validation loss: 2.502628942890293

Epoch: 5| Step: 10
Training loss: 2.089119530800224
Validation loss: 2.51489713852522

Epoch: 5| Step: 11
Training loss: 1.7048210308528455
Validation loss: 2.523273631976565

Epoch: 218| Step: 0
Training loss: 2.350314090922481
Validation loss: 2.533452347471594

Epoch: 5| Step: 1
Training loss: 2.421162752815795
Validation loss: 2.5649351125606423

Epoch: 5| Step: 2
Training loss: 1.660996814433057
Validation loss: 2.562636813721589

Epoch: 5| Step: 3
Training loss: 2.0220953418881593
Validation loss: 2.5448338456053943

Epoch: 5| Step: 4
Training loss: 2.374051958899014
Validation loss: 2.553124345229153

Epoch: 5| Step: 5
Training loss: 2.489135308167666
Validation loss: 2.5273113690856355

Epoch: 5| Step: 6
Training loss: 2.5324920621033935
Validation loss: 2.526758298126612

Epoch: 5| Step: 7
Training loss: 2.6945594509614414
Validation loss: 2.489751994965213

Epoch: 5| Step: 8
Training loss: 1.7890541043147028
Validation loss: 2.4908852996799555

Epoch: 5| Step: 9
Training loss: 2.653430564367233
Validation loss: 2.49462509130093

Epoch: 5| Step: 10
Training loss: 2.902882747993138
Validation loss: 2.485291086196821

Epoch: 5| Step: 11
Training loss: 1.1153140599097462
Validation loss: 2.4860115099395212

Epoch: 219| Step: 0
Training loss: 2.2920720753280284
Validation loss: 2.483746243131497

Epoch: 5| Step: 1
Training loss: 2.3875974545386485
Validation loss: 2.4745131797329054

Epoch: 5| Step: 2
Training loss: 2.2790026111127517
Validation loss: 2.480055514779476

Epoch: 5| Step: 3
Training loss: 2.752540801782694
Validation loss: 2.473665896080393

Epoch: 5| Step: 4
Training loss: 2.0448887630139168
Validation loss: 2.4808807671646274

Epoch: 5| Step: 5
Training loss: 1.930334808877785
Validation loss: 2.4810219976243606

Epoch: 5| Step: 6
Training loss: 2.3053752325643524
Validation loss: 2.4859096817259987

Epoch: 5| Step: 7
Training loss: 2.1963937072113544
Validation loss: 2.481750713692468

Epoch: 5| Step: 8
Training loss: 1.9423137056035367
Validation loss: 2.479951242844378

Epoch: 5| Step: 9
Training loss: 3.0593726870223157
Validation loss: 2.493254565658171

Epoch: 5| Step: 10
Training loss: 2.8458519178670794
Validation loss: 2.5020825017334265

Epoch: 5| Step: 11
Training loss: 2.136360766115603
Validation loss: 2.4966027005117986

Epoch: 220| Step: 0
Training loss: 2.0054140720262144
Validation loss: 2.483413998255929

Epoch: 5| Step: 1
Training loss: 2.4890122230753815
Validation loss: 2.4923760034907434

Epoch: 5| Step: 2
Training loss: 1.894312769296539
Validation loss: 2.490904925453268

Epoch: 5| Step: 3
Training loss: 2.646702741221731
Validation loss: 2.48771893082579

Epoch: 5| Step: 4
Training loss: 2.624834509582986
Validation loss: 2.491222549545

Epoch: 5| Step: 5
Training loss: 3.1740057041667407
Validation loss: 2.490898153561965

Epoch: 5| Step: 6
Training loss: 2.289754925569796
Validation loss: 2.4949849013404917

Epoch: 5| Step: 7
Training loss: 2.187755133872928
Validation loss: 2.4923471062872204

Epoch: 5| Step: 8
Training loss: 2.1159041340317954
Validation loss: 2.5052025108243305

Epoch: 5| Step: 9
Training loss: 2.0120683384811415
Validation loss: 2.4931178175206807

Epoch: 5| Step: 10
Training loss: 2.4830622053523776
Validation loss: 2.4970848710649314

Epoch: 5| Step: 11
Training loss: 2.381987482046038
Validation loss: 2.514614585475774

Epoch: 221| Step: 0
Training loss: 2.2608142157464726
Validation loss: 2.514673957571758

Epoch: 5| Step: 1
Training loss: 2.55752200910508
Validation loss: 2.522619427801792

Epoch: 5| Step: 2
Training loss: 2.6703635061893705
Validation loss: 2.522745389870696

Epoch: 5| Step: 3
Training loss: 1.9694433656458492
Validation loss: 2.5270735976075405

Epoch: 5| Step: 4
Training loss: 2.342980016749336
Validation loss: 2.5295966089832658

Epoch: 5| Step: 5
Training loss: 1.9774606948206448
Validation loss: 2.5422102524064147

Epoch: 5| Step: 6
Training loss: 2.158104140829635
Validation loss: 2.528266734271006

Epoch: 5| Step: 7
Training loss: 2.455977124303343
Validation loss: 2.5295844426406875

Epoch: 5| Step: 8
Training loss: 2.6183311582669995
Validation loss: 2.528471501027927

Epoch: 5| Step: 9
Training loss: 2.809363078091014
Validation loss: 2.530794919082202

Epoch: 5| Step: 10
Training loss: 2.237399741542532
Validation loss: 2.520782877414479

Epoch: 5| Step: 11
Training loss: 1.4310770421698513
Validation loss: 2.514013141268462

Epoch: 222| Step: 0
Training loss: 2.222419605496016
Validation loss: 2.5070427558011206

Epoch: 5| Step: 1
Training loss: 1.7819565158209483
Validation loss: 2.511198611906982

Epoch: 5| Step: 2
Training loss: 2.24345197478196
Validation loss: 2.5153288064659463

Epoch: 5| Step: 3
Training loss: 2.8146760787384855
Validation loss: 2.5061579244225705

Epoch: 5| Step: 4
Training loss: 1.9977283690036596
Validation loss: 2.5037780784458326

Epoch: 5| Step: 5
Training loss: 2.3542676808338507
Validation loss: 2.5056051064317897

Epoch: 5| Step: 6
Training loss: 2.582945599735195
Validation loss: 2.497194555854464

Epoch: 5| Step: 7
Training loss: 2.2940921663362315
Validation loss: 2.499321010890766

Epoch: 5| Step: 8
Training loss: 2.5887215831307624
Validation loss: 2.492195647574154

Epoch: 5| Step: 9
Training loss: 2.8004439615051684
Validation loss: 2.511634534548223

Epoch: 5| Step: 10
Training loss: 2.2743264259629696
Validation loss: 2.527542051449088

Epoch: 5| Step: 11
Training loss: 0.8767693885723942
Validation loss: 2.5131743916190574

Epoch: 223| Step: 0
Training loss: 2.643004840420618
Validation loss: 2.517740398787279

Epoch: 5| Step: 1
Training loss: 2.5111850390996966
Validation loss: 2.5162053554356234

Epoch: 5| Step: 2
Training loss: 2.651660499717435
Validation loss: 2.51537123875156

Epoch: 5| Step: 3
Training loss: 2.5976790118833577
Validation loss: 2.5250252923863266

Epoch: 5| Step: 4
Training loss: 2.5338353270365803
Validation loss: 2.533068898217639

Epoch: 5| Step: 5
Training loss: 2.4577234018015908
Validation loss: 2.5200375031084983

Epoch: 5| Step: 6
Training loss: 2.3614435286044513
Validation loss: 2.5065549349443796

Epoch: 5| Step: 7
Training loss: 2.040319179734899
Validation loss: 2.511164096244674

Epoch: 5| Step: 8
Training loss: 1.8327061562935183
Validation loss: 2.5076451072403314

Epoch: 5| Step: 9
Training loss: 2.332367174755814
Validation loss: 2.4989791176490685

Epoch: 5| Step: 10
Training loss: 2.0092705208533914
Validation loss: 2.497946070311636

Epoch: 5| Step: 11
Training loss: 2.5858618964354076
Validation loss: 2.4992998772018704

Epoch: 224| Step: 0
Training loss: 2.971436579924051
Validation loss: 2.5064052820656646

Epoch: 5| Step: 1
Training loss: 2.167887258286817
Validation loss: 2.496793148495904

Epoch: 5| Step: 2
Training loss: 2.9303440019643823
Validation loss: 2.5123259313266906

Epoch: 5| Step: 3
Training loss: 2.250657091619062
Validation loss: 2.517080738780059

Epoch: 5| Step: 4
Training loss: 1.8282070956585004
Validation loss: 2.5123944122750332

Epoch: 5| Step: 5
Training loss: 2.5541506328566967
Validation loss: 2.534960170504431

Epoch: 5| Step: 6
Training loss: 2.616999468525303
Validation loss: 2.508526713234807

Epoch: 5| Step: 7
Training loss: 2.0191210804305335
Validation loss: 2.5320964897026976

Epoch: 5| Step: 8
Training loss: 1.5597135493572478
Validation loss: 2.5284105277195383

Epoch: 5| Step: 9
Training loss: 2.302008568655815
Validation loss: 2.5360079110164575

Epoch: 5| Step: 10
Training loss: 2.462708626056982
Validation loss: 2.5274498439180393

Epoch: 5| Step: 11
Training loss: 1.1188143109638893
Validation loss: 2.538609081766813

Epoch: 225| Step: 0
Training loss: 2.6156308227620095
Validation loss: 2.5360464953653885

Epoch: 5| Step: 1
Training loss: 2.1744810427964087
Validation loss: 2.532414866884016

Epoch: 5| Step: 2
Training loss: 2.0143806105679674
Validation loss: 2.531764978840069

Epoch: 5| Step: 3
Training loss: 1.4673704608106446
Validation loss: 2.5406201343403763

Epoch: 5| Step: 4
Training loss: 2.0466230397539764
Validation loss: 2.5401297297288754

Epoch: 5| Step: 5
Training loss: 2.136236439723798
Validation loss: 2.5119714130300665

Epoch: 5| Step: 6
Training loss: 2.6398725171086754
Validation loss: 2.5148983630574353

Epoch: 5| Step: 7
Training loss: 2.4646261998820966
Validation loss: 2.5133190208713914

Epoch: 5| Step: 8
Training loss: 2.0557308666401664
Validation loss: 2.5102683270157735

Epoch: 5| Step: 9
Training loss: 2.980157398445061
Validation loss: 2.5062287064152717

Epoch: 5| Step: 10
Training loss: 2.714030762938721
Validation loss: 2.4978960243710557

Epoch: 5| Step: 11
Training loss: 3.157583578155858
Validation loss: 2.5071710893275454

Epoch: 226| Step: 0
Training loss: 2.2162597005409133
Validation loss: 2.4867877100935356

Epoch: 5| Step: 1
Training loss: 2.3834330766876137
Validation loss: 2.484656463929458

Epoch: 5| Step: 2
Training loss: 2.473760807115909
Validation loss: 2.492488033785038

Epoch: 5| Step: 3
Training loss: 2.7490990636800032
Validation loss: 2.4844062811203727

Epoch: 5| Step: 4
Training loss: 1.8604547266753215
Validation loss: 2.4900514263692206

Epoch: 5| Step: 5
Training loss: 2.3405603702927347
Validation loss: 2.489348852748319

Epoch: 5| Step: 6
Training loss: 2.728041108579579
Validation loss: 2.493934154801712

Epoch: 5| Step: 7
Training loss: 2.469509345985981
Validation loss: 2.4891888546686434

Epoch: 5| Step: 8
Training loss: 2.221512055832465
Validation loss: 2.4921245268037597

Epoch: 5| Step: 9
Training loss: 1.9781511880548297
Validation loss: 2.5082134746248275

Epoch: 5| Step: 10
Training loss: 2.4068885055159117
Validation loss: 2.5270503648670934

Epoch: 5| Step: 11
Training loss: 2.2573277570171544
Validation loss: 2.543868121185982

Epoch: 227| Step: 0
Training loss: 1.984640749460452
Validation loss: 2.564426461686694

Epoch: 5| Step: 1
Training loss: 2.1316641486269603
Validation loss: 2.5472553803830147

Epoch: 5| Step: 2
Training loss: 2.3836455342967016
Validation loss: 2.540678040473575

Epoch: 5| Step: 3
Training loss: 2.1224038590043492
Validation loss: 2.5228944357457728

Epoch: 5| Step: 4
Training loss: 2.702975847837061
Validation loss: 2.5077955100810025

Epoch: 5| Step: 5
Training loss: 2.3527182340187025
Validation loss: 2.5144946834631647

Epoch: 5| Step: 6
Training loss: 2.0944229866342994
Validation loss: 2.511632527265124

Epoch: 5| Step: 7
Training loss: 2.656423944499936
Validation loss: 2.5026745000688524

Epoch: 5| Step: 8
Training loss: 2.6116471134988313
Validation loss: 2.518307663260538

Epoch: 5| Step: 9
Training loss: 1.9877143456379078
Validation loss: 2.521981018781261

Epoch: 5| Step: 10
Training loss: 2.7746392024103326
Validation loss: 2.5082049038052

Epoch: 5| Step: 11
Training loss: 2.270170820925787
Validation loss: 2.506262346682812

Epoch: 228| Step: 0
Training loss: 2.234592987310935
Validation loss: 2.5007471716466703

Epoch: 5| Step: 1
Training loss: 2.8023675445916205
Validation loss: 2.5048220105937453

Epoch: 5| Step: 2
Training loss: 2.643082147026724
Validation loss: 2.5039119274057184

Epoch: 5| Step: 3
Training loss: 2.2730353874811757
Validation loss: 2.5065868508050575

Epoch: 5| Step: 4
Training loss: 2.4423781268697558
Validation loss: 2.511654520276482

Epoch: 5| Step: 5
Training loss: 2.1955719383858043
Validation loss: 2.498594520792491

Epoch: 5| Step: 6
Training loss: 1.9139389309602626
Validation loss: 2.4969028799181845

Epoch: 5| Step: 7
Training loss: 2.1742611956659577
Validation loss: 2.4870601154887595

Epoch: 5| Step: 8
Training loss: 2.2531427052049566
Validation loss: 2.4995452427514637

Epoch: 5| Step: 9
Training loss: 2.779244889545881
Validation loss: 2.4884784306959618

Epoch: 5| Step: 10
Training loss: 2.115571365916231
Validation loss: 2.5003463306545193

Epoch: 5| Step: 11
Training loss: 1.7258515426114724
Validation loss: 2.5079299962613306

Epoch: 229| Step: 0
Training loss: 2.691767475929192
Validation loss: 2.510133697000029

Epoch: 5| Step: 1
Training loss: 1.7861169279381834
Validation loss: 2.528626330241857

Epoch: 5| Step: 2
Training loss: 2.649088911667588
Validation loss: 2.533683717541642

Epoch: 5| Step: 3
Training loss: 2.8275190515660533
Validation loss: 2.5651019540122055

Epoch: 5| Step: 4
Training loss: 1.9878526986466385
Validation loss: 2.5624644075418437

Epoch: 5| Step: 5
Training loss: 3.0078605350770706
Validation loss: 2.538842580025385

Epoch: 5| Step: 6
Training loss: 1.7422180173108444
Validation loss: 2.5463871361844

Epoch: 5| Step: 7
Training loss: 2.2581299027411617
Validation loss: 2.518758397999434

Epoch: 5| Step: 8
Training loss: 2.3622986319165875
Validation loss: 2.5225911920923747

Epoch: 5| Step: 9
Training loss: 1.994645700185574
Validation loss: 2.505734431382107

Epoch: 5| Step: 10
Training loss: 2.419083691035893
Validation loss: 2.512643389777559

Epoch: 5| Step: 11
Training loss: 1.0512141927637741
Validation loss: 2.4994071058720175

Epoch: 230| Step: 0
Training loss: 2.485169289730703
Validation loss: 2.5020647185366633

Epoch: 5| Step: 1
Training loss: 1.798949661042545
Validation loss: 2.4946668742325646

Epoch: 5| Step: 2
Training loss: 2.4013040417175504
Validation loss: 2.4869578648532027

Epoch: 5| Step: 3
Training loss: 2.8546244864354975
Validation loss: 2.487213412665626

Epoch: 5| Step: 4
Training loss: 1.9776860236673637
Validation loss: 2.486485130944468

Epoch: 5| Step: 5
Training loss: 1.8604392844516537
Validation loss: 2.496236813962007

Epoch: 5| Step: 6
Training loss: 2.213043396163578
Validation loss: 2.4978897804889817

Epoch: 5| Step: 7
Training loss: 2.2773465766692897
Validation loss: 2.4836990308531446

Epoch: 5| Step: 8
Training loss: 2.8264418171876926
Validation loss: 2.494295721327523

Epoch: 5| Step: 9
Training loss: 2.278554499657657
Validation loss: 2.4970670622226496

Epoch: 5| Step: 10
Training loss: 2.1861616127463903
Validation loss: 2.5055785087394957

Epoch: 5| Step: 11
Training loss: 4.629350008396874
Validation loss: 2.4963535975527154

Epoch: 231| Step: 0
Training loss: 1.8905767639564355
Validation loss: 2.5224476576517203

Epoch: 5| Step: 1
Training loss: 2.121313038093321
Validation loss: 2.5435867496190046

Epoch: 5| Step: 2
Training loss: 2.665204740178111
Validation loss: 2.541242573225781

Epoch: 5| Step: 3
Training loss: 1.9995811142948547
Validation loss: 2.52838356682529

Epoch: 5| Step: 4
Training loss: 2.448272765751901
Validation loss: 2.5319382689408783

Epoch: 5| Step: 5
Training loss: 2.5752930779934613
Validation loss: 2.514949557845744

Epoch: 5| Step: 6
Training loss: 2.2037497642374158
Validation loss: 2.4864594973457677

Epoch: 5| Step: 7
Training loss: 1.8883767750527742
Validation loss: 2.487932373373803

Epoch: 5| Step: 8
Training loss: 3.034112738640212
Validation loss: 2.476939596834946

Epoch: 5| Step: 9
Training loss: 2.4142593254169173
Validation loss: 2.4862847015991973

Epoch: 5| Step: 10
Training loss: 2.695070913793772
Validation loss: 2.4846702096393702

Epoch: 5| Step: 11
Training loss: 1.267857971805171
Validation loss: 2.490082632191256

Epoch: 232| Step: 0
Training loss: 2.657916813888422
Validation loss: 2.4977126863586827

Epoch: 5| Step: 1
Training loss: 2.2023292348869847
Validation loss: 2.507719699731074

Epoch: 5| Step: 2
Training loss: 2.147571625053541
Validation loss: 2.495527441011229

Epoch: 5| Step: 3
Training loss: 2.581544677318212
Validation loss: 2.498178430373503

Epoch: 5| Step: 4
Training loss: 2.1226601902121716
Validation loss: 2.5067227016900437

Epoch: 5| Step: 5
Training loss: 2.41224755265915
Validation loss: 2.508013161685546

Epoch: 5| Step: 6
Training loss: 2.322386562833372
Validation loss: 2.511932704073217

Epoch: 5| Step: 7
Training loss: 2.454624665231299
Validation loss: 2.527523779217968

Epoch: 5| Step: 8
Training loss: 2.3197426658174853
Validation loss: 2.5275182059450163

Epoch: 5| Step: 9
Training loss: 2.5099444967569577
Validation loss: 2.5142418808655678

Epoch: 5| Step: 10
Training loss: 1.944323920495888
Validation loss: 2.525882925702288

Epoch: 5| Step: 11
Training loss: 2.941636439988524
Validation loss: 2.5428595570737267

Epoch: 233| Step: 0
Training loss: 1.9892662021945076
Validation loss: 2.5515274506416086

Epoch: 5| Step: 1
Training loss: 1.9623776804714168
Validation loss: 2.5551171986474626

Epoch: 5| Step: 2
Training loss: 2.4183642136407237
Validation loss: 2.5518493168771936

Epoch: 5| Step: 3
Training loss: 2.4708852105272503
Validation loss: 2.520784709923868

Epoch: 5| Step: 4
Training loss: 2.5806539443081937
Validation loss: 2.5066965696228607

Epoch: 5| Step: 5
Training loss: 2.0291753884923756
Validation loss: 2.4999170965118056

Epoch: 5| Step: 6
Training loss: 2.7490334112552195
Validation loss: 2.480191262811401

Epoch: 5| Step: 7
Training loss: 2.4226525811958273
Validation loss: 2.485558601754204

Epoch: 5| Step: 8
Training loss: 2.5457226539273665
Validation loss: 2.4818286321953837

Epoch: 5| Step: 9
Training loss: 2.356220789558816
Validation loss: 2.4822862829698797

Epoch: 5| Step: 10
Training loss: 2.4864695614413552
Validation loss: 2.4850223145803847

Epoch: 5| Step: 11
Training loss: 1.1691831061652351
Validation loss: 2.4913941000379687

Epoch: 234| Step: 0
Training loss: 2.5593483314475485
Validation loss: 2.498290407241662

Epoch: 5| Step: 1
Training loss: 2.0153793066932617
Validation loss: 2.510568259372531

Epoch: 5| Step: 2
Training loss: 2.039234957947367
Validation loss: 2.539587046897203

Epoch: 5| Step: 3
Training loss: 1.9427000221163293
Validation loss: 2.552030116454114

Epoch: 5| Step: 4
Training loss: 2.2752751529847
Validation loss: 2.5579695816291896

Epoch: 5| Step: 5
Training loss: 2.2513927811370578
Validation loss: 2.539156954059944

Epoch: 5| Step: 6
Training loss: 1.6778189268111656
Validation loss: 2.5302700610514344

Epoch: 5| Step: 7
Training loss: 2.9989499797662744
Validation loss: 2.510865431888594

Epoch: 5| Step: 8
Training loss: 2.392710654811594
Validation loss: 2.508494730970924

Epoch: 5| Step: 9
Training loss: 2.8558850278499244
Validation loss: 2.5285206157089557

Epoch: 5| Step: 10
Training loss: 2.513707822410746
Validation loss: 2.5109313434619516

Epoch: 5| Step: 11
Training loss: 2.2349107006760556
Validation loss: 2.499800070079743

Epoch: 235| Step: 0
Training loss: 2.3288544401786986
Validation loss: 2.507995222491967

Epoch: 5| Step: 1
Training loss: 2.6078068024039953
Validation loss: 2.5001586386892876

Epoch: 5| Step: 2
Training loss: 2.604671693787102
Validation loss: 2.506930202984946

Epoch: 5| Step: 3
Training loss: 2.066668603752623
Validation loss: 2.5085267171949432

Epoch: 5| Step: 4
Training loss: 1.9698610349719672
Validation loss: 2.5118200104721455

Epoch: 5| Step: 5
Training loss: 2.27555585924327
Validation loss: 2.5143584820632063

Epoch: 5| Step: 6
Training loss: 2.6483177675622387
Validation loss: 2.499451545318415

Epoch: 5| Step: 7
Training loss: 2.570003502542803
Validation loss: 2.5144754749059604

Epoch: 5| Step: 8
Training loss: 2.6143719003810832
Validation loss: 2.5165821094918184

Epoch: 5| Step: 9
Training loss: 1.8414661033591024
Validation loss: 2.5198334150468438

Epoch: 5| Step: 10
Training loss: 2.310366393752854
Validation loss: 2.5176281861151124

Epoch: 5| Step: 11
Training loss: 2.0517156307018665
Validation loss: 2.519501552357479

Epoch: 236| Step: 0
Training loss: 2.155741977277247
Validation loss: 2.5317888353549156

Epoch: 5| Step: 1
Training loss: 1.7021614638862568
Validation loss: 2.5375375520968646

Epoch: 5| Step: 2
Training loss: 2.1183234401484867
Validation loss: 2.5434965161237884

Epoch: 5| Step: 3
Training loss: 2.205027414960258
Validation loss: 2.5393337398315743

Epoch: 5| Step: 4
Training loss: 2.5781186190439502
Validation loss: 2.5414601513079322

Epoch: 5| Step: 5
Training loss: 2.9110378082241812
Validation loss: 2.520102061192987

Epoch: 5| Step: 6
Training loss: 2.6516446749935927
Validation loss: 2.5264677900886685

Epoch: 5| Step: 7
Training loss: 2.3930142499512974
Validation loss: 2.5127987910131053

Epoch: 5| Step: 8
Training loss: 2.702599799671616
Validation loss: 2.527786416579309

Epoch: 5| Step: 9
Training loss: 1.9497914055982626
Validation loss: 2.513546082679441

Epoch: 5| Step: 10
Training loss: 2.001930497204438
Validation loss: 2.5101311760069684

Epoch: 5| Step: 11
Training loss: 2.700901064809603
Validation loss: 2.5146118003373754

Epoch: 237| Step: 0
Training loss: 2.7835574061793826
Validation loss: 2.5092441081315227

Epoch: 5| Step: 1
Training loss: 2.2419751428932746
Validation loss: 2.524974768106522

Epoch: 5| Step: 2
Training loss: 2.64051403286511
Validation loss: 2.527568970225637

Epoch: 5| Step: 3
Training loss: 1.949401357655411
Validation loss: 2.528699394363351

Epoch: 5| Step: 4
Training loss: 1.7389654634587821
Validation loss: 2.534268545603153

Epoch: 5| Step: 5
Training loss: 2.622767089101569
Validation loss: 2.538766053329167

Epoch: 5| Step: 6
Training loss: 2.677182286038024
Validation loss: 2.523680062146053

Epoch: 5| Step: 7
Training loss: 1.8825462437961857
Validation loss: 2.5127565999370574

Epoch: 5| Step: 8
Training loss: 2.2453435822673553
Validation loss: 2.5165066131850016

Epoch: 5| Step: 9
Training loss: 2.5385591448178397
Validation loss: 2.513925677382163

Epoch: 5| Step: 10
Training loss: 2.357311634940547
Validation loss: 2.5147212914835793

Epoch: 5| Step: 11
Training loss: 0.6616984754967102
Validation loss: 2.5114030614904777

Epoch: 238| Step: 0
Training loss: 1.8577155393510827
Validation loss: 2.5236780388573807

Epoch: 5| Step: 1
Training loss: 2.0651327726893127
Validation loss: 2.4959841302671335

Epoch: 5| Step: 2
Training loss: 2.001536375257945
Validation loss: 2.5204556762868306

Epoch: 5| Step: 3
Training loss: 2.6417696125497043
Validation loss: 2.5296331037328192

Epoch: 5| Step: 4
Training loss: 2.429857254231191
Validation loss: 2.5164461197646046

Epoch: 5| Step: 5
Training loss: 2.351865628497784
Validation loss: 2.5400987202816245

Epoch: 5| Step: 6
Training loss: 2.35266675400655
Validation loss: 2.5398240693244207

Epoch: 5| Step: 7
Training loss: 2.317598033094905
Validation loss: 2.5560305697859658

Epoch: 5| Step: 8
Training loss: 2.474460323333989
Validation loss: 2.5651763918756756

Epoch: 5| Step: 9
Training loss: 2.6445107846616263
Validation loss: 2.5311401170655343

Epoch: 5| Step: 10
Training loss: 2.322434505036016
Validation loss: 2.5136168818965494

Epoch: 5| Step: 11
Training loss: 3.0369124860818952
Validation loss: 2.5051088009345075

Epoch: 239| Step: 0
Training loss: 2.129736054413435
Validation loss: 2.5114123334011738

Epoch: 5| Step: 1
Training loss: 1.885115927918303
Validation loss: 2.499804103646691

Epoch: 5| Step: 2
Training loss: 2.316978654047764
Validation loss: 2.501706605787708

Epoch: 5| Step: 3
Training loss: 2.582074371300998
Validation loss: 2.4890490774019045

Epoch: 5| Step: 4
Training loss: 2.5475900968392997
Validation loss: 2.495093625349955

Epoch: 5| Step: 5
Training loss: 2.2634932387453035
Validation loss: 2.4812274643573664

Epoch: 5| Step: 6
Training loss: 2.2359955786113668
Validation loss: 2.4924892214991927

Epoch: 5| Step: 7
Training loss: 2.915280003390574
Validation loss: 2.47912594951457

Epoch: 5| Step: 8
Training loss: 1.714158879424516
Validation loss: 2.4874771032445717

Epoch: 5| Step: 9
Training loss: 2.3587089760613624
Validation loss: 2.4938610600317443

Epoch: 5| Step: 10
Training loss: 2.6418110367788668
Validation loss: 2.512166451539463

Epoch: 5| Step: 11
Training loss: 2.508930848221941
Validation loss: 2.5360330829638573

Epoch: 240| Step: 0
Training loss: 2.007051553768274
Validation loss: 2.570460569373991

Epoch: 5| Step: 1
Training loss: 2.3043281921648684
Validation loss: 2.6253916811504605

Epoch: 5| Step: 2
Training loss: 2.8380767908225226
Validation loss: 2.660675998874331

Epoch: 5| Step: 3
Training loss: 2.0504281457544664
Validation loss: 2.6286376959549616

Epoch: 5| Step: 4
Training loss: 2.7367137389446166
Validation loss: 2.5763003433197498

Epoch: 5| Step: 5
Training loss: 2.9659608287012382
Validation loss: 2.5215835374499904

Epoch: 5| Step: 6
Training loss: 2.681013485451646
Validation loss: 2.5047222242131713

Epoch: 5| Step: 7
Training loss: 2.06610566749185
Validation loss: 2.489675238175201

Epoch: 5| Step: 8
Training loss: 2.596041574794738
Validation loss: 2.484031357580581

Epoch: 5| Step: 9
Training loss: 2.050495934393758
Validation loss: 2.48833173683645

Epoch: 5| Step: 10
Training loss: 1.8237933494012393
Validation loss: 2.481446665633752

Epoch: 5| Step: 11
Training loss: 2.4760346918217806
Validation loss: 2.4859032958447127

Epoch: 241| Step: 0
Training loss: 2.897977149783784
Validation loss: 2.481829464764554

Epoch: 5| Step: 1
Training loss: 1.7578855372196287
Validation loss: 2.4812725977345047

Epoch: 5| Step: 2
Training loss: 2.210019517527568
Validation loss: 2.475918241791314

Epoch: 5| Step: 3
Training loss: 2.834544110116268
Validation loss: 2.4826672680588078

Epoch: 5| Step: 4
Training loss: 2.492818339994834
Validation loss: 2.5019157976656117

Epoch: 5| Step: 5
Training loss: 2.432673248049335
Validation loss: 2.5049570291987084

Epoch: 5| Step: 6
Training loss: 1.9091954223296606
Validation loss: 2.512495594115688

Epoch: 5| Step: 7
Training loss: 2.3603875217058135
Validation loss: 2.525660214020131

Epoch: 5| Step: 8
Training loss: 1.8749324786426294
Validation loss: 2.523557421941794

Epoch: 5| Step: 9
Training loss: 2.418860645375592
Validation loss: 2.531677386619251

Epoch: 5| Step: 10
Training loss: 2.2191078004992946
Validation loss: 2.5623997730720203

Epoch: 5| Step: 11
Training loss: 3.0160152202596544
Validation loss: 2.542668603703655

Epoch: 242| Step: 0
Training loss: 2.2657132887902502
Validation loss: 2.5602173873311243

Epoch: 5| Step: 1
Training loss: 2.898992192331875
Validation loss: 2.5612045983578215

Epoch: 5| Step: 2
Training loss: 2.4273225614557896
Validation loss: 2.5433643343945525

Epoch: 5| Step: 3
Training loss: 1.903563184983586
Validation loss: 2.544043989946298

Epoch: 5| Step: 4
Training loss: 2.5907415384509465
Validation loss: 2.534368054513316

Epoch: 5| Step: 5
Training loss: 2.1615977659791348
Validation loss: 2.5333244512322803

Epoch: 5| Step: 6
Training loss: 1.545674947077394
Validation loss: 2.5346898696669484

Epoch: 5| Step: 7
Training loss: 2.6612632565506376
Validation loss: 2.531960152272558

Epoch: 5| Step: 8
Training loss: 1.9371938155874828
Validation loss: 2.5071532114679647

Epoch: 5| Step: 9
Training loss: 2.3435862166080628
Validation loss: 2.4923629898260726

Epoch: 5| Step: 10
Training loss: 2.680338166096089
Validation loss: 2.4775973503484674

Epoch: 5| Step: 11
Training loss: 1.0894677392000602
Validation loss: 2.474929628270839

Epoch: 243| Step: 0
Training loss: 2.57096988886171
Validation loss: 2.476249265868046

Epoch: 5| Step: 1
Training loss: 2.50999265601311
Validation loss: 2.485139365340237

Epoch: 5| Step: 2
Training loss: 2.1878080968508735
Validation loss: 2.476707959641648

Epoch: 5| Step: 3
Training loss: 2.0768486061221374
Validation loss: 2.4814888205849384

Epoch: 5| Step: 4
Training loss: 2.044303618409145
Validation loss: 2.4751190447515

Epoch: 5| Step: 5
Training loss: 1.978268034526063
Validation loss: 2.487254798887087

Epoch: 5| Step: 6
Training loss: 2.5700787377077727
Validation loss: 2.485028250998692

Epoch: 5| Step: 7
Training loss: 2.851603134074785
Validation loss: 2.4905354516026357

Epoch: 5| Step: 8
Training loss: 2.0795496596148406
Validation loss: 2.499180876132968

Epoch: 5| Step: 9
Training loss: 2.6924164624302698
Validation loss: 2.5096028395132257

Epoch: 5| Step: 10
Training loss: 2.216557346124491
Validation loss: 2.531197311889105

Epoch: 5| Step: 11
Training loss: 1.8834017389528255
Validation loss: 2.5452576164758876

Epoch: 244| Step: 0
Training loss: 2.178495128823141
Validation loss: 2.555219248844122

Epoch: 5| Step: 1
Training loss: 2.4868172211704684
Validation loss: 2.5505681477082156

Epoch: 5| Step: 2
Training loss: 2.280404861877804
Validation loss: 2.529926493670665

Epoch: 5| Step: 3
Training loss: 2.7790731419083183
Validation loss: 2.530345847495958

Epoch: 5| Step: 4
Training loss: 2.1353580249704986
Validation loss: 2.524546467145206

Epoch: 5| Step: 5
Training loss: 2.213867618273006
Validation loss: 2.5390235506640484

Epoch: 5| Step: 6
Training loss: 2.541101194754436
Validation loss: 2.534104354806917

Epoch: 5| Step: 7
Training loss: 2.592159840882895
Validation loss: 2.512919592259249

Epoch: 5| Step: 8
Training loss: 2.0936304314477012
Validation loss: 2.5155773711187632

Epoch: 5| Step: 9
Training loss: 2.147493578154051
Validation loss: 2.5309338902076672

Epoch: 5| Step: 10
Training loss: 1.7959680673398453
Validation loss: 2.5178635472181115

Epoch: 5| Step: 11
Training loss: 2.9606023513220765
Validation loss: 2.5009219575635986

Epoch: 245| Step: 0
Training loss: 2.72817420871396
Validation loss: 2.5036866145776817

Epoch: 5| Step: 1
Training loss: 1.7124217662900874
Validation loss: 2.494182414056034

Epoch: 5| Step: 2
Training loss: 2.213143693639776
Validation loss: 2.4962465361875323

Epoch: 5| Step: 3
Training loss: 2.434400788979805
Validation loss: 2.48669420510436

Epoch: 5| Step: 4
Training loss: 2.7897751696384687
Validation loss: 2.4906503965645714

Epoch: 5| Step: 5
Training loss: 1.9319784796604158
Validation loss: 2.4937553894889803

Epoch: 5| Step: 6
Training loss: 1.8588041823801231
Validation loss: 2.4856778293539894

Epoch: 5| Step: 7
Training loss: 2.6890719939468246
Validation loss: 2.4997883746857776

Epoch: 5| Step: 8
Training loss: 2.090735813733617
Validation loss: 2.5196576582078123

Epoch: 5| Step: 9
Training loss: 2.457987540111823
Validation loss: 2.5177779373650737

Epoch: 5| Step: 10
Training loss: 2.472328971910721
Validation loss: 2.54196487238176

Epoch: 5| Step: 11
Training loss: 2.765669827717558
Validation loss: 2.530920250532373

Epoch: 246| Step: 0
Training loss: 2.3520034934167153
Validation loss: 2.530960356855665

Epoch: 5| Step: 1
Training loss: 2.7490168461288653
Validation loss: 2.545462694570473

Epoch: 5| Step: 2
Training loss: 1.9001250125515359
Validation loss: 2.5393671214940476

Epoch: 5| Step: 3
Training loss: 2.7341829068965886
Validation loss: 2.5315154254352197

Epoch: 5| Step: 4
Training loss: 2.5127583157423876
Validation loss: 2.54353156358644

Epoch: 5| Step: 5
Training loss: 2.431957791031164
Validation loss: 2.559207794043651

Epoch: 5| Step: 6
Training loss: 2.063331898620468
Validation loss: 2.552041210423792

Epoch: 5| Step: 7
Training loss: 2.139306100665866
Validation loss: 2.5338302420375003

Epoch: 5| Step: 8
Training loss: 1.7782278021139297
Validation loss: 2.507202811120106

Epoch: 5| Step: 9
Training loss: 2.6455100655502126
Validation loss: 2.5116445669844345

Epoch: 5| Step: 10
Training loss: 2.3620224808181094
Validation loss: 2.4882388428208873

Epoch: 5| Step: 11
Training loss: 2.239525680391347
Validation loss: 2.4797539870144876

Epoch: 247| Step: 0
Training loss: 2.2296006205152423
Validation loss: 2.474880794743467

Epoch: 5| Step: 1
Training loss: 2.495039405282236
Validation loss: 2.47166238490107

Epoch: 5| Step: 2
Training loss: 2.0373503413555634
Validation loss: 2.4754606537527093

Epoch: 5| Step: 3
Training loss: 2.175288201015398
Validation loss: 2.46024021987824

Epoch: 5| Step: 4
Training loss: 2.556835892741196
Validation loss: 2.4588767652571355

Epoch: 5| Step: 5
Training loss: 2.569895887381191
Validation loss: 2.470566330893546

Epoch: 5| Step: 6
Training loss: 2.7256772590845966
Validation loss: 2.462178856746181

Epoch: 5| Step: 7
Training loss: 2.6728544169011066
Validation loss: 2.468329659422107

Epoch: 5| Step: 8
Training loss: 2.355077404199902
Validation loss: 2.4710241418297523

Epoch: 5| Step: 9
Training loss: 2.489826961923958
Validation loss: 2.4734448003671226

Epoch: 5| Step: 10
Training loss: 2.5029409276596035
Validation loss: 2.4839349792883354

Epoch: 5| Step: 11
Training loss: 2.066501434960687
Validation loss: 2.4826628065105707

Epoch: 248| Step: 0
Training loss: 2.4336231407484856
Validation loss: 2.483446447518644

Epoch: 5| Step: 1
Training loss: 2.3067119435550576
Validation loss: 2.481423446076526

Epoch: 5| Step: 2
Training loss: 1.9810240679900717
Validation loss: 2.478926960926437

Epoch: 5| Step: 3
Training loss: 1.9805698707542365
Validation loss: 2.471501153421001

Epoch: 5| Step: 4
Training loss: 2.7983178194610736
Validation loss: 2.4790435701685616

Epoch: 5| Step: 5
Training loss: 2.161198783519176
Validation loss: 2.4859360083274433

Epoch: 5| Step: 6
Training loss: 2.3631128676778266
Validation loss: 2.4837784860740793

Epoch: 5| Step: 7
Training loss: 2.7957278834855397
Validation loss: 2.4874271002747066

Epoch: 5| Step: 8
Training loss: 2.422229568614182
Validation loss: 2.4746808104728344

Epoch: 5| Step: 9
Training loss: 2.798732886387721
Validation loss: 2.4799903228017213

Epoch: 5| Step: 10
Training loss: 1.9231423022087257
Validation loss: 2.4856288313074777

Epoch: 5| Step: 11
Training loss: 1.7678196863166948
Validation loss: 2.4947718013591045

Epoch: 249| Step: 0
Training loss: 1.62256344275908
Validation loss: 2.532919411713969

Epoch: 5| Step: 1
Training loss: 2.8128557615976293
Validation loss: 2.546041375622614

Epoch: 5| Step: 2
Training loss: 2.8876802858820225
Validation loss: 2.580185423282026

Epoch: 5| Step: 3
Training loss: 2.3482091573133936
Validation loss: 2.5760861590520725

Epoch: 5| Step: 4
Training loss: 1.7442048030036974
Validation loss: 2.5450793315418037

Epoch: 5| Step: 5
Training loss: 2.625672481319118
Validation loss: 2.523779657903507

Epoch: 5| Step: 6
Training loss: 2.3923368620385603
Validation loss: 2.4997023246291525

Epoch: 5| Step: 7
Training loss: 1.9234525207379258
Validation loss: 2.489197939939263

Epoch: 5| Step: 8
Training loss: 2.5819219199621917
Validation loss: 2.486291266300739

Epoch: 5| Step: 9
Training loss: 2.205661260707288
Validation loss: 2.4716156572307364

Epoch: 5| Step: 10
Training loss: 2.5241482799519863
Validation loss: 2.4797936749898186

Epoch: 5| Step: 11
Training loss: 2.5302294333844877
Validation loss: 2.4864058201495287

Epoch: 250| Step: 0
Training loss: 2.6937188343626093
Validation loss: 2.4754863209843134

Epoch: 5| Step: 1
Training loss: 2.149280729408933
Validation loss: 2.4819712135995595

Epoch: 5| Step: 2
Training loss: 2.9445286524825205
Validation loss: 2.4763007481956167

Epoch: 5| Step: 3
Training loss: 2.2643647997102834
Validation loss: 2.481517612045051

Epoch: 5| Step: 4
Training loss: 2.658796727640139
Validation loss: 2.4820324431982743

Epoch: 5| Step: 5
Training loss: 2.4012713760306212
Validation loss: 2.497328998332997

Epoch: 5| Step: 6
Training loss: 2.125841535101062
Validation loss: 2.497258200779359

Epoch: 5| Step: 7
Training loss: 2.3600411390501295
Validation loss: 2.5017805474245685

Epoch: 5| Step: 8
Training loss: 2.241971739911602
Validation loss: 2.50810646005916

Epoch: 5| Step: 9
Training loss: 1.9806648473321466
Validation loss: 2.53658932472286

Epoch: 5| Step: 10
Training loss: 2.0795185894659194
Validation loss: 2.525992443483426

Epoch: 5| Step: 11
Training loss: 1.7195640023564325
Validation loss: 2.5225849108839173

Testing loss: 2.026816512182487
