Epoch: 1| Step: 0
Training loss: 6.118986642253452
Validation loss: 5.861938329549044

Epoch: 5| Step: 1
Training loss: 5.175932522848332
Validation loss: 5.860236054625376

Epoch: 5| Step: 2
Training loss: 6.5797253471958275
Validation loss: 5.858543832107342

Epoch: 5| Step: 3
Training loss: 6.025945831389608
Validation loss: 5.856869893630689

Epoch: 5| Step: 4
Training loss: 5.883704048270674
Validation loss: 5.8551479164331415

Epoch: 5| Step: 5
Training loss: 5.739055334637679
Validation loss: 5.8535372869756666

Epoch: 5| Step: 6
Training loss: 4.822712948192549
Validation loss: 5.851893457646194

Epoch: 5| Step: 7
Training loss: 5.8466508978381295
Validation loss: 5.850403240086932

Epoch: 5| Step: 8
Training loss: 6.667116849322467
Validation loss: 5.848698314436472

Epoch: 5| Step: 9
Training loss: 6.019521427332187
Validation loss: 5.847078894970027

Epoch: 5| Step: 10
Training loss: 6.531888647659261
Validation loss: 5.845359866091337

Epoch: 5| Step: 11
Training loss: 5.959016702940005
Validation loss: 5.843559085222896

Epoch: 2| Step: 0
Training loss: 5.846545524835551
Validation loss: 5.841641710457527

Epoch: 5| Step: 1
Training loss: 5.4014084144885235
Validation loss: 5.83970253049621

Epoch: 5| Step: 2
Training loss: 5.801409241049015
Validation loss: 5.837752537026398

Epoch: 5| Step: 3
Training loss: 6.2468180376655065
Validation loss: 5.83562042723149

Epoch: 5| Step: 4
Training loss: 5.399061064859341
Validation loss: 5.833410223953663

Epoch: 5| Step: 5
Training loss: 5.9800324383624535
Validation loss: 5.831178787249087

Epoch: 5| Step: 6
Training loss: 5.991589691700476
Validation loss: 5.828899696822591

Epoch: 5| Step: 7
Training loss: 5.843215673161155
Validation loss: 5.826324000532122

Epoch: 5| Step: 8
Training loss: 6.326212879035066
Validation loss: 5.823668909588428

Epoch: 5| Step: 9
Training loss: 6.598999826189927
Validation loss: 5.8211467375472825

Epoch: 5| Step: 10
Training loss: 5.908124676648608
Validation loss: 5.818054853710307

Epoch: 5| Step: 11
Training loss: 5.7725242955888945
Validation loss: 5.815110075202077

Epoch: 3| Step: 0
Training loss: 6.2082160409519265
Validation loss: 5.811908349993272

Epoch: 5| Step: 1
Training loss: 6.0503386599752105
Validation loss: 5.808360666550951

Epoch: 5| Step: 2
Training loss: 6.173963130740748
Validation loss: 5.805000046897886

Epoch: 5| Step: 3
Training loss: 6.244744799907102
Validation loss: 5.8013187180860095

Epoch: 5| Step: 4
Training loss: 5.834035050102143
Validation loss: 5.797440685491346

Epoch: 5| Step: 5
Training loss: 6.549943227740306
Validation loss: 5.793273993192976

Epoch: 5| Step: 6
Training loss: 5.902305618051875
Validation loss: 5.789055251555854

Epoch: 5| Step: 7
Training loss: 6.0120303028025734
Validation loss: 5.784468193272087

Epoch: 5| Step: 8
Training loss: 4.852086725338899
Validation loss: 5.779576239709977

Epoch: 5| Step: 9
Training loss: 5.6740523433536625
Validation loss: 5.7746625331023305

Epoch: 5| Step: 10
Training loss: 5.384572575996342
Validation loss: 5.769563000315516

Epoch: 5| Step: 11
Training loss: 5.5680688991668505
Validation loss: 5.764002053810846

Epoch: 4| Step: 0
Training loss: 5.859104160407118
Validation loss: 5.75853477306024

Epoch: 5| Step: 1
Training loss: 4.911774264786876
Validation loss: 5.7524984639859404

Epoch: 5| Step: 2
Training loss: 5.218720761519891
Validation loss: 5.746581865294946

Epoch: 5| Step: 3
Training loss: 7.037665530167085
Validation loss: 5.740115300869133

Epoch: 5| Step: 4
Training loss: 5.183622082745666
Validation loss: 5.733535628945304

Epoch: 5| Step: 5
Training loss: 5.956387004097209
Validation loss: 5.726611037870466

Epoch: 5| Step: 6
Training loss: 4.75025798699325
Validation loss: 5.719786857455215

Epoch: 5| Step: 7
Training loss: 6.458092502492663
Validation loss: 5.71264067100317

Epoch: 5| Step: 8
Training loss: 6.273112477473148
Validation loss: 5.705134597737372

Epoch: 5| Step: 9
Training loss: 6.473280347665521
Validation loss: 5.697297743169613

Epoch: 5| Step: 10
Training loss: 5.5589157729653405
Validation loss: 5.689431927832785

Epoch: 5| Step: 11
Training loss: 6.34058319875175
Validation loss: 5.681549683497954

Epoch: 5| Step: 0
Training loss: 5.178434792956963
Validation loss: 5.672983458825422

Epoch: 5| Step: 1
Training loss: 5.511652826446207
Validation loss: 5.6650556022561736

Epoch: 5| Step: 2
Training loss: 6.23384508830312
Validation loss: 5.656825217263731

Epoch: 5| Step: 3
Training loss: 5.697784180527646
Validation loss: 5.648603043827803

Epoch: 5| Step: 4
Training loss: 6.348864668629062
Validation loss: 5.63970378986184

Epoch: 5| Step: 5
Training loss: 5.024743463600903
Validation loss: 5.631182811814664

Epoch: 5| Step: 6
Training loss: 6.173832141231689
Validation loss: 5.622851222720871

Epoch: 5| Step: 7
Training loss: 6.368766579498783
Validation loss: 5.614275358266326

Epoch: 5| Step: 8
Training loss: 6.0088165991821905
Validation loss: 5.605863656943547

Epoch: 5| Step: 9
Training loss: 4.8038396816136055
Validation loss: 5.597389351479661

Epoch: 5| Step: 10
Training loss: 5.770403280197431
Validation loss: 5.589007265498585

Epoch: 5| Step: 11
Training loss: 4.979027250032619
Validation loss: 5.580722869950192

Epoch: 6| Step: 0
Training loss: 6.144180161715568
Validation loss: 5.572770320598873

Epoch: 5| Step: 1
Training loss: 6.124188739222776
Validation loss: 5.564543080966838

Epoch: 5| Step: 2
Training loss: 5.471847964600723
Validation loss: 5.556571301216106

Epoch: 5| Step: 3
Training loss: 5.936707775067168
Validation loss: 5.548672050976404

Epoch: 5| Step: 4
Training loss: 5.775429594897269
Validation loss: 5.540849642171891

Epoch: 5| Step: 5
Training loss: 6.0344915820278064
Validation loss: 5.533009085959783

Epoch: 5| Step: 6
Training loss: 5.824336971155125
Validation loss: 5.5252107240586295

Epoch: 5| Step: 7
Training loss: 4.855553599419529
Validation loss: 5.517530708221772

Epoch: 5| Step: 8
Training loss: 5.484099030683593
Validation loss: 5.509677219594396

Epoch: 5| Step: 9
Training loss: 5.37810799098941
Validation loss: 5.5020483060870395

Epoch: 5| Step: 10
Training loss: 5.234964730363464
Validation loss: 5.494728596643244

Epoch: 5| Step: 11
Training loss: 4.472517439508101
Validation loss: 5.487031016371105

Epoch: 7| Step: 0
Training loss: 6.239851073908779
Validation loss: 5.479834326133142

Epoch: 5| Step: 1
Training loss: 5.773100847022558
Validation loss: 5.472357985732124

Epoch: 5| Step: 2
Training loss: 5.36993932906389
Validation loss: 5.464540754475458

Epoch: 5| Step: 3
Training loss: 5.4661639393335
Validation loss: 5.456988688334585

Epoch: 5| Step: 4
Training loss: 5.455182318643317
Validation loss: 5.4493834768028755

Epoch: 5| Step: 5
Training loss: 5.214521876770709
Validation loss: 5.442085933841911

Epoch: 5| Step: 6
Training loss: 5.55609928437321
Validation loss: 5.434492689996718

Epoch: 5| Step: 7
Training loss: 5.512394550724878
Validation loss: 5.427067845103396

Epoch: 5| Step: 8
Training loss: 5.839587682513023
Validation loss: 5.419860252969419

Epoch: 5| Step: 9
Training loss: 6.199386738626539
Validation loss: 5.4125917904113265

Epoch: 5| Step: 10
Training loss: 4.742859140812622
Validation loss: 5.405212802655993

Epoch: 5| Step: 11
Training loss: 3.5594204090092094
Validation loss: 5.398488377111921

Epoch: 8| Step: 0
Training loss: 5.759128787593645
Validation loss: 5.391568183392551

Epoch: 5| Step: 1
Training loss: 5.08996460098518
Validation loss: 5.384600139035661

Epoch: 5| Step: 2
Training loss: 5.1205832825652315
Validation loss: 5.377951388352519

Epoch: 5| Step: 3
Training loss: 5.452061590438749
Validation loss: 5.371235741790272

Epoch: 5| Step: 4
Training loss: 5.960801189258965
Validation loss: 5.3643910000096655

Epoch: 5| Step: 5
Training loss: 5.593145241892026
Validation loss: 5.357943307476271

Epoch: 5| Step: 6
Training loss: 5.1597559251650065
Validation loss: 5.351120815938054

Epoch: 5| Step: 7
Training loss: 4.51753991519455
Validation loss: 5.343891588086491

Epoch: 5| Step: 8
Training loss: 6.388514536334486
Validation loss: 5.3377366539860045

Epoch: 5| Step: 9
Training loss: 5.526851823571165
Validation loss: 5.330901316621283

Epoch: 5| Step: 10
Training loss: 5.226710843431529
Validation loss: 5.324654135717514

Epoch: 5| Step: 11
Training loss: 6.59555882235912
Validation loss: 5.318026461847814

Epoch: 9| Step: 0
Training loss: 5.053221689029343
Validation loss: 5.311376310698852

Epoch: 5| Step: 1
Training loss: 5.42003694979189
Validation loss: 5.305014606291533

Epoch: 5| Step: 2
Training loss: 5.1226116290759105
Validation loss: 5.298402286623642

Epoch: 5| Step: 3
Training loss: 4.931038213516417
Validation loss: 5.292192870982902

Epoch: 5| Step: 4
Training loss: 5.648519386130596
Validation loss: 5.2858996492271615

Epoch: 5| Step: 5
Training loss: 5.717329005064204
Validation loss: 5.279686058565808

Epoch: 5| Step: 6
Training loss: 4.970752624385168
Validation loss: 5.273245491959218

Epoch: 5| Step: 7
Training loss: 5.492334746425866
Validation loss: 5.266611431331149

Epoch: 5| Step: 8
Training loss: 5.843701041113428
Validation loss: 5.259683926855951

Epoch: 5| Step: 9
Training loss: 5.579220789712603
Validation loss: 5.2523522405647025

Epoch: 5| Step: 10
Training loss: 5.525771709419341
Validation loss: 5.244735303296235

Epoch: 5| Step: 11
Training loss: 5.445350679676948
Validation loss: 5.237036989393288

Epoch: 10| Step: 0
Training loss: 4.8801133164553985
Validation loss: 5.2303978533186015

Epoch: 5| Step: 1
Training loss: 4.802133467516677
Validation loss: 5.223813476785379

Epoch: 5| Step: 2
Training loss: 5.503101341460981
Validation loss: 5.216121041868591

Epoch: 5| Step: 3
Training loss: 5.72401294445011
Validation loss: 5.209292493875072

Epoch: 5| Step: 4
Training loss: 5.683687378416953
Validation loss: 5.202184002072443

Epoch: 5| Step: 5
Training loss: 5.861784009990914
Validation loss: 5.195455640001707

Epoch: 5| Step: 6
Training loss: 4.9409822184048355
Validation loss: 5.188826915979892

Epoch: 5| Step: 7
Training loss: 5.3208545291073195
Validation loss: 5.182761360493479

Epoch: 5| Step: 8
Training loss: 5.030834867991012
Validation loss: 5.176168137011796

Epoch: 5| Step: 9
Training loss: 5.053612336749475
Validation loss: 5.169736921563857

Epoch: 5| Step: 10
Training loss: 5.438996909167138
Validation loss: 5.163453205154558

Epoch: 5| Step: 11
Training loss: 5.956688002406019
Validation loss: 5.157208918020178

Epoch: 11| Step: 0
Training loss: 4.630188995195076
Validation loss: 5.151031326988136

Epoch: 5| Step: 1
Training loss: 4.972139557921445
Validation loss: 5.145031038925317

Epoch: 5| Step: 2
Training loss: 4.743001701430278
Validation loss: 5.137864535996908

Epoch: 5| Step: 3
Training loss: 5.923903145646788
Validation loss: 5.132703968683184

Epoch: 5| Step: 4
Training loss: 4.992348347491897
Validation loss: 5.126560787629664

Epoch: 5| Step: 5
Training loss: 4.28493858765224
Validation loss: 5.120806591170001

Epoch: 5| Step: 6
Training loss: 6.159963659204074
Validation loss: 5.114417796618827

Epoch: 5| Step: 7
Training loss: 6.268646805314157
Validation loss: 5.108201361668501

Epoch: 5| Step: 8
Training loss: 5.77128244940757
Validation loss: 5.101675969916784

Epoch: 5| Step: 9
Training loss: 4.762786920670395
Validation loss: 5.096176404261757

Epoch: 5| Step: 10
Training loss: 4.757779025757141
Validation loss: 5.0895570297071595

Epoch: 5| Step: 11
Training loss: 5.013268793752544
Validation loss: 5.083635581781297

Epoch: 12| Step: 0
Training loss: 4.925792092077679
Validation loss: 5.07794555347006

Epoch: 5| Step: 1
Training loss: 6.052625341870479
Validation loss: 5.072040625825669

Epoch: 5| Step: 2
Training loss: 5.065438442101312
Validation loss: 5.065434919866582

Epoch: 5| Step: 3
Training loss: 5.484798751936407
Validation loss: 5.060760674131175

Epoch: 5| Step: 4
Training loss: 4.793364691138768
Validation loss: 5.054301503147375

Epoch: 5| Step: 5
Training loss: 4.596743484161335
Validation loss: 5.048653910107282

Epoch: 5| Step: 6
Training loss: 5.20906895846681
Validation loss: 5.0428335977887455

Epoch: 5| Step: 7
Training loss: 4.3382843539657765
Validation loss: 5.037517206179985

Epoch: 5| Step: 8
Training loss: 5.178109735663229
Validation loss: 5.031575597174991

Epoch: 5| Step: 9
Training loss: 5.964375275787056
Validation loss: 5.025055952377438

Epoch: 5| Step: 10
Training loss: 4.845922758021323
Validation loss: 5.019623981415848

Epoch: 5| Step: 11
Training loss: 6.010133451227394
Validation loss: 5.013774043053837

Epoch: 13| Step: 0
Training loss: 4.781854927839543
Validation loss: 5.008402130598059

Epoch: 5| Step: 1
Training loss: 5.064680218708131
Validation loss: 5.002051735168752

Epoch: 5| Step: 2
Training loss: 5.157961659555576
Validation loss: 4.996259406720926

Epoch: 5| Step: 3
Training loss: 5.279136460520681
Validation loss: 4.989607293928216

Epoch: 5| Step: 4
Training loss: 4.574776424093787
Validation loss: 4.983047810904843

Epoch: 5| Step: 5
Training loss: 4.442602957593483
Validation loss: 4.977049911001449

Epoch: 5| Step: 6
Training loss: 5.80241454278882
Validation loss: 4.971766078290551

Epoch: 5| Step: 7
Training loss: 4.884427272055648
Validation loss: 4.9661847256232905

Epoch: 5| Step: 8
Training loss: 4.961538779998569
Validation loss: 4.959963308885697

Epoch: 5| Step: 9
Training loss: 5.499317993881346
Validation loss: 4.95458013136911

Epoch: 5| Step: 10
Training loss: 5.76952926646039
Validation loss: 4.949577119854788

Epoch: 5| Step: 11
Training loss: 3.386826316594829
Validation loss: 4.944420933518726

Epoch: 14| Step: 0
Training loss: 5.217703160350467
Validation loss: 4.940247547868774

Epoch: 5| Step: 1
Training loss: 5.1740037852989715
Validation loss: 4.934973452585865

Epoch: 5| Step: 2
Training loss: 5.387200636191312
Validation loss: 4.927879054177912

Epoch: 5| Step: 3
Training loss: 4.715154831934083
Validation loss: 4.923144044708909

Epoch: 5| Step: 4
Training loss: 5.037275414394558
Validation loss: 4.917611987621858

Epoch: 5| Step: 5
Training loss: 5.436676313780351
Validation loss: 4.912321136945764

Epoch: 5| Step: 6
Training loss: 4.220658612314446
Validation loss: 4.90547749943385

Epoch: 5| Step: 7
Training loss: 4.912235181043041
Validation loss: 4.900033223435271

Epoch: 5| Step: 8
Training loss: 4.770745200241258
Validation loss: 4.894771382295975

Epoch: 5| Step: 9
Training loss: 5.200858507446394
Validation loss: 4.890445498746356

Epoch: 5| Step: 10
Training loss: 4.85500323027357
Validation loss: 4.884388531458476

Epoch: 5| Step: 11
Training loss: 6.612194713330965
Validation loss: 4.8791936703702135

Epoch: 15| Step: 0
Training loss: 5.841288165329623
Validation loss: 4.87399324797438

Epoch: 5| Step: 1
Training loss: 4.774778686507569
Validation loss: 4.867613870183196

Epoch: 5| Step: 2
Training loss: 4.678429334140454
Validation loss: 4.861930804700833

Epoch: 5| Step: 3
Training loss: 5.172971856935006
Validation loss: 4.857431953439149

Epoch: 5| Step: 4
Training loss: 4.8160866587246645
Validation loss: 4.851885937870828

Epoch: 5| Step: 5
Training loss: 4.615620561828752
Validation loss: 4.845885054404415

Epoch: 5| Step: 6
Training loss: 4.792051791871261
Validation loss: 4.84081473884726

Epoch: 5| Step: 7
Training loss: 4.232399793003078
Validation loss: 4.835175289302094

Epoch: 5| Step: 8
Training loss: 5.047160893423792
Validation loss: 4.8309865329454444

Epoch: 5| Step: 9
Training loss: 5.262415601184947
Validation loss: 4.826511685511539

Epoch: 5| Step: 10
Training loss: 5.2498653939566
Validation loss: 4.82101723801826

Epoch: 5| Step: 11
Training loss: 5.191272329148775
Validation loss: 4.815620261290453

Epoch: 16| Step: 0
Training loss: 4.821555003774088
Validation loss: 4.809937864352986

Epoch: 5| Step: 1
Training loss: 5.066121630883555
Validation loss: 4.807000423824196

Epoch: 5| Step: 2
Training loss: 5.5294120881673745
Validation loss: 4.799917384933419

Epoch: 5| Step: 3
Training loss: 4.335056084750758
Validation loss: 4.7955249704917255

Epoch: 5| Step: 4
Training loss: 5.436733323340954
Validation loss: 4.789022946466644

Epoch: 5| Step: 5
Training loss: 5.099094325412418
Validation loss: 4.784190800644752

Epoch: 5| Step: 6
Training loss: 4.058070188499104
Validation loss: 4.779443079441641

Epoch: 5| Step: 7
Training loss: 4.615589775514076
Validation loss: 4.7738761304913755

Epoch: 5| Step: 8
Training loss: 6.06715261727836
Validation loss: 4.7694754632410055

Epoch: 5| Step: 9
Training loss: 4.078250108458719
Validation loss: 4.764568491074307

Epoch: 5| Step: 10
Training loss: 3.932925518899008
Validation loss: 4.758537266509344

Epoch: 5| Step: 11
Training loss: 6.982248959834458
Validation loss: 4.753704533807162

Epoch: 17| Step: 0
Training loss: 4.168584204355098
Validation loss: 4.748801389682079

Epoch: 5| Step: 1
Training loss: 4.421606264608883
Validation loss: 4.743943376917804

Epoch: 5| Step: 2
Training loss: 5.904564672536661
Validation loss: 4.738627455460224

Epoch: 5| Step: 3
Training loss: 4.886198240227043
Validation loss: 4.733695112537574

Epoch: 5| Step: 4
Training loss: 4.439676315262382
Validation loss: 4.7277181090163065

Epoch: 5| Step: 5
Training loss: 5.433450177268346
Validation loss: 4.722341185673208

Epoch: 5| Step: 6
Training loss: 5.071167672429068
Validation loss: 4.717520362016258

Epoch: 5| Step: 7
Training loss: 4.7781341971788525
Validation loss: 4.712332941124675

Epoch: 5| Step: 8
Training loss: 4.35523226656204
Validation loss: 4.70727611026218

Epoch: 5| Step: 9
Training loss: 4.465363186101334
Validation loss: 4.702270109055589

Epoch: 5| Step: 10
Training loss: 5.362598395167361
Validation loss: 4.697491792242281

Epoch: 5| Step: 11
Training loss: 3.410170792136806
Validation loss: 4.691691919036356

Epoch: 18| Step: 0
Training loss: 4.919304458021276
Validation loss: 4.687728028579084

Epoch: 5| Step: 1
Training loss: 5.246559468926883
Validation loss: 4.6813016897963

Epoch: 5| Step: 2
Training loss: 5.2100876968822805
Validation loss: 4.675800536967617

Epoch: 5| Step: 3
Training loss: 5.3652974761373935
Validation loss: 4.6719347759662675

Epoch: 5| Step: 4
Training loss: 4.309092184168279
Validation loss: 4.668015177348224

Epoch: 5| Step: 5
Training loss: 4.692422951994033
Validation loss: 4.66043672359802

Epoch: 5| Step: 6
Training loss: 4.902479144046663
Validation loss: 4.655671670486621

Epoch: 5| Step: 7
Training loss: 4.045033864562088
Validation loss: 4.650704685262121

Epoch: 5| Step: 8
Training loss: 4.385132309973846
Validation loss: 4.644979717824926

Epoch: 5| Step: 9
Training loss: 4.818242993628933
Validation loss: 4.6402713628046675

Epoch: 5| Step: 10
Training loss: 4.981433730045592
Validation loss: 4.634957008573945

Epoch: 5| Step: 11
Training loss: 2.2658335622619235
Validation loss: 4.629472674817524

Epoch: 19| Step: 0
Training loss: 5.1190199039084945
Validation loss: 4.624395313770841

Epoch: 5| Step: 1
Training loss: 4.100973264966586
Validation loss: 4.619107315771374

Epoch: 5| Step: 2
Training loss: 4.1962114504036885
Validation loss: 4.615652114144563

Epoch: 5| Step: 3
Training loss: 3.8225509232995525
Validation loss: 4.611434622922573

Epoch: 5| Step: 4
Training loss: 4.859895046655016
Validation loss: 4.606268134182794

Epoch: 5| Step: 5
Training loss: 4.317335430956074
Validation loss: 4.599449099848234

Epoch: 5| Step: 6
Training loss: 4.725966638254396
Validation loss: 4.595534654850985

Epoch: 5| Step: 7
Training loss: 5.19346000513638
Validation loss: 4.593287533341186

Epoch: 5| Step: 8
Training loss: 4.541395733419356
Validation loss: 4.584260424859626

Epoch: 5| Step: 9
Training loss: 5.775167698923001
Validation loss: 4.581790433183124

Epoch: 5| Step: 10
Training loss: 4.681792993974396
Validation loss: 4.576777349890041

Epoch: 5| Step: 11
Training loss: 6.135950381559562
Validation loss: 4.569367283295555

Epoch: 20| Step: 0
Training loss: 4.860463305708889
Validation loss: 4.565899753680403

Epoch: 5| Step: 1
Training loss: 4.9399838537655025
Validation loss: 4.563722921239057

Epoch: 5| Step: 2
Training loss: 4.851108597363399
Validation loss: 4.5540026961832245

Epoch: 5| Step: 3
Training loss: 4.891810264407632
Validation loss: 4.550717743306319

Epoch: 5| Step: 4
Training loss: 5.464530494115498
Validation loss: 4.548282069113851

Epoch: 5| Step: 5
Training loss: 4.310844656541457
Validation loss: 4.540851444024616

Epoch: 5| Step: 6
Training loss: 4.590840151155018
Validation loss: 4.5333858849247015

Epoch: 5| Step: 7
Training loss: 4.050101742820452
Validation loss: 4.52641137138236

Epoch: 5| Step: 8
Training loss: 4.832444514840669
Validation loss: 4.5211535954166155

Epoch: 5| Step: 9
Training loss: 3.8125056282377128
Validation loss: 4.516405533119281

Epoch: 5| Step: 10
Training loss: 4.592044435850995
Validation loss: 4.513055723847506

Epoch: 5| Step: 11
Training loss: 4.37699800916857
Validation loss: 4.505165146931249

Epoch: 21| Step: 0
Training loss: 4.449035908707388
Validation loss: 4.501590227021602

Epoch: 5| Step: 1
Training loss: 4.860580638218545
Validation loss: 4.497749587126376

Epoch: 5| Step: 2
Training loss: 4.873702830350292
Validation loss: 4.492154602814892

Epoch: 5| Step: 3
Training loss: 4.83310203437277
Validation loss: 4.485664456981352

Epoch: 5| Step: 4
Training loss: 4.115343987698351
Validation loss: 4.477724103248322

Epoch: 5| Step: 5
Training loss: 4.569780993733559
Validation loss: 4.474311213700529

Epoch: 5| Step: 6
Training loss: 5.086095007641699
Validation loss: 4.468689026672256

Epoch: 5| Step: 7
Training loss: 4.698738156014768
Validation loss: 4.462012647415081

Epoch: 5| Step: 8
Training loss: 4.747557966009999
Validation loss: 4.457090911777959

Epoch: 5| Step: 9
Training loss: 4.397795228834087
Validation loss: 4.451042125418286

Epoch: 5| Step: 10
Training loss: 3.9958849243609795
Validation loss: 4.446178814455156

Epoch: 5| Step: 11
Training loss: 4.0003609494431975
Validation loss: 4.439426917130078

Epoch: 22| Step: 0
Training loss: 4.336106855504545
Validation loss: 4.435915328209247

Epoch: 5| Step: 1
Training loss: 4.223550057895933
Validation loss: 4.429787860610323

Epoch: 5| Step: 2
Training loss: 4.355747696364514
Validation loss: 4.425007370046451

Epoch: 5| Step: 3
Training loss: 4.846470222812214
Validation loss: 4.419284362712315

Epoch: 5| Step: 4
Training loss: 4.5901691207811774
Validation loss: 4.413957991811656

Epoch: 5| Step: 5
Training loss: 4.505733440277939
Validation loss: 4.410042674852199

Epoch: 5| Step: 6
Training loss: 3.789023991025318
Validation loss: 4.405223704368611

Epoch: 5| Step: 7
Training loss: 4.940407198907356
Validation loss: 4.4000314429633525

Epoch: 5| Step: 8
Training loss: 4.449026477065284
Validation loss: 4.3933416675151875

Epoch: 5| Step: 9
Training loss: 4.424850702730554
Validation loss: 4.387554665394304

Epoch: 5| Step: 10
Training loss: 5.256158395665247
Validation loss: 4.384322723925336

Epoch: 5| Step: 11
Training loss: 4.702667518239981
Validation loss: 4.379959320114602

Epoch: 23| Step: 0
Training loss: 4.114253756043277
Validation loss: 4.373207824207665

Epoch: 5| Step: 1
Training loss: 5.091349404664345
Validation loss: 4.367552954089442

Epoch: 5| Step: 2
Training loss: 4.148489454270948
Validation loss: 4.36245150006286

Epoch: 5| Step: 3
Training loss: 4.131569457291009
Validation loss: 4.357016277373007

Epoch: 5| Step: 4
Training loss: 4.280269761185108
Validation loss: 4.35243048420856

Epoch: 5| Step: 5
Training loss: 4.914265687559516
Validation loss: 4.347658032248132

Epoch: 5| Step: 6
Training loss: 4.7944586318361
Validation loss: 4.342746984734221

Epoch: 5| Step: 7
Training loss: 4.457177389625947
Validation loss: 4.337366018873584

Epoch: 5| Step: 8
Training loss: 4.231270528318117
Validation loss: 4.331678765429139

Epoch: 5| Step: 9
Training loss: 4.249318236476707
Validation loss: 4.326773660911131

Epoch: 5| Step: 10
Training loss: 4.609842981407547
Validation loss: 4.320437304790564

Epoch: 5| Step: 11
Training loss: 4.875307513588326
Validation loss: 4.315715438775395

Epoch: 24| Step: 0
Training loss: 4.559937476013926
Validation loss: 4.311449392855839

Epoch: 5| Step: 1
Training loss: 4.070425899631945
Validation loss: 4.305960391437546

Epoch: 5| Step: 2
Training loss: 4.164066164398013
Validation loss: 4.300395776218477

Epoch: 5| Step: 3
Training loss: 4.521617463956503
Validation loss: 4.295163663448153

Epoch: 5| Step: 4
Training loss: 4.622106936027786
Validation loss: 4.290158834043871

Epoch: 5| Step: 5
Training loss: 4.95575228064461
Validation loss: 4.284748810298016

Epoch: 5| Step: 6
Training loss: 4.658548696563336
Validation loss: 4.280582691543672

Epoch: 5| Step: 7
Training loss: 4.446979337582067
Validation loss: 4.274766797774949

Epoch: 5| Step: 8
Training loss: 4.413223700030814
Validation loss: 4.2701074526099365

Epoch: 5| Step: 9
Training loss: 3.8499519741481283
Validation loss: 4.263700509888968

Epoch: 5| Step: 10
Training loss: 4.202679124744301
Validation loss: 4.259293772761864

Epoch: 5| Step: 11
Training loss: 4.435860559347819
Validation loss: 4.254878978831126

Epoch: 25| Step: 0
Training loss: 4.332699998398579
Validation loss: 4.249403472249921

Epoch: 5| Step: 1
Training loss: 3.617882021311557
Validation loss: 4.24407641073616

Epoch: 5| Step: 2
Training loss: 4.426100151242415
Validation loss: 4.239560919975001

Epoch: 5| Step: 3
Training loss: 4.506344243729408
Validation loss: 4.234930318756809

Epoch: 5| Step: 4
Training loss: 4.342873025090712
Validation loss: 4.22919175026256

Epoch: 5| Step: 5
Training loss: 4.556539325920727
Validation loss: 4.225317037601732

Epoch: 5| Step: 6
Training loss: 4.3217031713656135
Validation loss: 4.219784371997433

Epoch: 5| Step: 7
Training loss: 4.7325568910011535
Validation loss: 4.21522897321647

Epoch: 5| Step: 8
Training loss: 4.344080192036485
Validation loss: 4.2099090905692425

Epoch: 5| Step: 9
Training loss: 3.854410538389717
Validation loss: 4.206223032705726

Epoch: 5| Step: 10
Training loss: 4.818497128908435
Validation loss: 4.200173236097395

Epoch: 5| Step: 11
Training loss: 3.8823132568173913
Validation loss: 4.195040371366771

Epoch: 26| Step: 0
Training loss: 4.573373457470332
Validation loss: 4.190351630237816

Epoch: 5| Step: 1
Training loss: 4.501918807488508
Validation loss: 4.18478998581681

Epoch: 5| Step: 2
Training loss: 4.319342009272524
Validation loss: 4.180482459599797

Epoch: 5| Step: 3
Training loss: 3.5734343454924997
Validation loss: 4.174876263397147

Epoch: 5| Step: 4
Training loss: 3.9671928174350195
Validation loss: 4.169585081699666

Epoch: 5| Step: 5
Training loss: 4.9089078082350435
Validation loss: 4.1642392653592015

Epoch: 5| Step: 6
Training loss: 4.941033366612745
Validation loss: 4.160003406182447

Epoch: 5| Step: 7
Training loss: 3.8754081511122824
Validation loss: 4.155608211289693

Epoch: 5| Step: 8
Training loss: 4.104488121391931
Validation loss: 4.150354003744685

Epoch: 5| Step: 9
Training loss: 4.20629808418258
Validation loss: 4.144914336720902

Epoch: 5| Step: 10
Training loss: 4.255720440022235
Validation loss: 4.139003469742971

Epoch: 5| Step: 11
Training loss: 3.341879205453173
Validation loss: 4.1343409518845995

Epoch: 27| Step: 0
Training loss: 4.393708256269519
Validation loss: 4.129781749899266

Epoch: 5| Step: 1
Training loss: 4.252906030179609
Validation loss: 4.1250846401354915

Epoch: 5| Step: 2
Training loss: 3.1972533955745037
Validation loss: 4.119909193996518

Epoch: 5| Step: 3
Training loss: 4.636866836304143
Validation loss: 4.115308280852091

Epoch: 5| Step: 4
Training loss: 4.035048949595874
Validation loss: 4.109885315822606

Epoch: 5| Step: 5
Training loss: 4.391636416326835
Validation loss: 4.105226809035706

Epoch: 5| Step: 6
Training loss: 4.065810747177044
Validation loss: 4.100137197711111

Epoch: 5| Step: 7
Training loss: 4.1541807143198
Validation loss: 4.095647828191641

Epoch: 5| Step: 8
Training loss: 3.9225902133193085
Validation loss: 4.090752054742194

Epoch: 5| Step: 9
Training loss: 4.755596277373547
Validation loss: 4.085796161684553

Epoch: 5| Step: 10
Training loss: 4.280174175889592
Validation loss: 4.081053300005186

Epoch: 5| Step: 11
Training loss: 5.592452255679584
Validation loss: 4.075701216178245

Epoch: 28| Step: 0
Training loss: 4.097961123518993
Validation loss: 4.070595944347419

Epoch: 5| Step: 1
Training loss: 4.9073047840469695
Validation loss: 4.065563929395024

Epoch: 5| Step: 2
Training loss: 4.304561661613504
Validation loss: 4.0608081816117405

Epoch: 5| Step: 3
Training loss: 4.834314816673
Validation loss: 4.055631234966707

Epoch: 5| Step: 4
Training loss: 3.185695810771501
Validation loss: 4.050204165732403

Epoch: 5| Step: 5
Training loss: 3.9390023408114354
Validation loss: 4.0447488352063035

Epoch: 5| Step: 6
Training loss: 3.79100883282815
Validation loss: 4.039752997104004

Epoch: 5| Step: 7
Training loss: 4.288878167643568
Validation loss: 4.034562871386612

Epoch: 5| Step: 8
Training loss: 3.902084937691889
Validation loss: 4.029578663348598

Epoch: 5| Step: 9
Training loss: 4.1812551820548975
Validation loss: 4.024913075300228

Epoch: 5| Step: 10
Training loss: 4.1404623899378965
Validation loss: 4.020102467432986

Epoch: 5| Step: 11
Training loss: 4.741291093394267
Validation loss: 4.014495576982544

Epoch: 29| Step: 0
Training loss: 4.681164338126453
Validation loss: 4.010107606480945

Epoch: 5| Step: 1
Training loss: 3.941629212559725
Validation loss: 4.005057738424112

Epoch: 5| Step: 2
Training loss: 4.392386195228865
Validation loss: 3.9999295466894167

Epoch: 5| Step: 3
Training loss: 3.7652296436484693
Validation loss: 3.9945684053118145

Epoch: 5| Step: 4
Training loss: 4.162366911905553
Validation loss: 3.9896482888985494

Epoch: 5| Step: 5
Training loss: 4.413371074165558
Validation loss: 3.9846839037060673

Epoch: 5| Step: 6
Training loss: 4.16406547732363
Validation loss: 3.980046457957201

Epoch: 5| Step: 7
Training loss: 4.072813587233943
Validation loss: 3.974078623633045

Epoch: 5| Step: 8
Training loss: 3.6886390607821116
Validation loss: 3.969325321779398

Epoch: 5| Step: 9
Training loss: 3.854693581244253
Validation loss: 3.964693534523554

Epoch: 5| Step: 10
Training loss: 4.050372994283646
Validation loss: 3.9595641464581544

Epoch: 5| Step: 11
Training loss: 4.162220273628147
Validation loss: 3.9547194028582644

Epoch: 30| Step: 0
Training loss: 3.872948626543189
Validation loss: 3.9494333381849636

Epoch: 5| Step: 1
Training loss: 4.636870332729172
Validation loss: 3.9447785875486225

Epoch: 5| Step: 2
Training loss: 4.108884832933688
Validation loss: 3.94022812767034

Epoch: 5| Step: 3
Training loss: 3.5199338828726487
Validation loss: 3.9345476142441296

Epoch: 5| Step: 4
Training loss: 4.078413562138824
Validation loss: 3.9300352211943967

Epoch: 5| Step: 5
Training loss: 3.7126668976025456
Validation loss: 3.924636506907294

Epoch: 5| Step: 6
Training loss: 4.422546551396331
Validation loss: 3.920084986819668

Epoch: 5| Step: 7
Training loss: 4.476793000310262
Validation loss: 3.915164769457947

Epoch: 5| Step: 8
Training loss: 3.9005147105246305
Validation loss: 3.910330545895988

Epoch: 5| Step: 9
Training loss: 4.198194597129367
Validation loss: 3.905598731109041

Epoch: 5| Step: 10
Training loss: 3.1130185656608163
Validation loss: 3.9005642723177227

Epoch: 5| Step: 11
Training loss: 5.602128727810437
Validation loss: 3.8957877215946977

Epoch: 31| Step: 0
Training loss: 3.6410266834717673
Validation loss: 3.8906014172351235

Epoch: 5| Step: 1
Training loss: 3.467703309097997
Validation loss: 3.885587978251095

Epoch: 5| Step: 2
Training loss: 4.1723655383716105
Validation loss: 3.8809095410485277

Epoch: 5| Step: 3
Training loss: 4.329161812440257
Validation loss: 3.876309778498233

Epoch: 5| Step: 4
Training loss: 4.605688657679176
Validation loss: 3.8708154018193444

Epoch: 5| Step: 5
Training loss: 4.048348294876069
Validation loss: 3.86638151047729

Epoch: 5| Step: 6
Training loss: 4.398840118465023
Validation loss: 3.860998936875375

Epoch: 5| Step: 7
Training loss: 3.999713887472531
Validation loss: 3.8561368735035595

Epoch: 5| Step: 8
Training loss: 3.952135165686883
Validation loss: 3.851195900204944

Epoch: 5| Step: 9
Training loss: 4.145695644117791
Validation loss: 3.845964212694463

Epoch: 5| Step: 10
Training loss: 3.383130065248913
Validation loss: 3.8404921911963386

Epoch: 5| Step: 11
Training loss: 1.720067299701651
Validation loss: 3.8358944374459103

Epoch: 32| Step: 0
Training loss: 3.8403387051455837
Validation loss: 3.83117797456116

Epoch: 5| Step: 1
Training loss: 3.338987291959084
Validation loss: 3.826730461167585

Epoch: 5| Step: 2
Training loss: 4.577344391707691
Validation loss: 3.821908104026159

Epoch: 5| Step: 3
Training loss: 4.156266979670439
Validation loss: 3.8176127999059166

Epoch: 5| Step: 4
Training loss: 4.369672310630961
Validation loss: 3.812960753193105

Epoch: 5| Step: 5
Training loss: 4.002772324189433
Validation loss: 3.8080035725624892

Epoch: 5| Step: 6
Training loss: 3.841415813031492
Validation loss: 3.8033035393137737

Epoch: 5| Step: 7
Training loss: 4.165749156386585
Validation loss: 3.798381025322629

Epoch: 5| Step: 8
Training loss: 3.8326324706751413
Validation loss: 3.793417257499072

Epoch: 5| Step: 9
Training loss: 3.7062229766632475
Validation loss: 3.7886006444130778

Epoch: 5| Step: 10
Training loss: 3.0423743239112495
Validation loss: 3.7838079008182413

Epoch: 5| Step: 11
Training loss: 5.100844608754147
Validation loss: 3.7796146755343902

Epoch: 33| Step: 0
Training loss: 4.0333506707273346
Validation loss: 3.7743135308106655

Epoch: 5| Step: 1
Training loss: 3.7234157495987943
Validation loss: 3.7699577103485007

Epoch: 5| Step: 2
Training loss: 4.423155474523436
Validation loss: 3.7653107940731596

Epoch: 5| Step: 3
Training loss: 4.022091420003919
Validation loss: 3.7602203701841894

Epoch: 5| Step: 4
Training loss: 4.175140360225976
Validation loss: 3.7550895379367666

Epoch: 5| Step: 5
Training loss: 3.8040237004357063
Validation loss: 3.75048422336214

Epoch: 5| Step: 6
Training loss: 3.2587429702969763
Validation loss: 3.744962052601632

Epoch: 5| Step: 7
Training loss: 3.317279893807555
Validation loss: 3.740138730784219

Epoch: 5| Step: 8
Training loss: 3.250814775891318
Validation loss: 3.736200862564383

Epoch: 5| Step: 9
Training loss: 4.020073589960907
Validation loss: 3.7312642419352633

Epoch: 5| Step: 10
Training loss: 4.529366147661829
Validation loss: 3.7264905025583457

Epoch: 5| Step: 11
Training loss: 3.608382579887348
Validation loss: 3.721741731117007

Epoch: 34| Step: 0
Training loss: 4.140984055408032
Validation loss: 3.7169430614274024

Epoch: 5| Step: 1
Training loss: 4.457597166704317
Validation loss: 3.71249525067746

Epoch: 5| Step: 2
Training loss: 3.916807997297712
Validation loss: 3.7072253482921727

Epoch: 5| Step: 3
Training loss: 3.3928297056078254
Validation loss: 3.7021432103581593

Epoch: 5| Step: 4
Training loss: 3.4252355786910846
Validation loss: 3.6975343354345926

Epoch: 5| Step: 5
Training loss: 3.9811736765781287
Validation loss: 3.692649774486125

Epoch: 5| Step: 6
Training loss: 3.863246319712221
Validation loss: 3.688229860393402

Epoch: 5| Step: 7
Training loss: 3.9463360657850988
Validation loss: 3.6831866592587774

Epoch: 5| Step: 8
Training loss: 3.6467524359994297
Validation loss: 3.6784033508763807

Epoch: 5| Step: 9
Training loss: 4.03024681679632
Validation loss: 3.673628476315571

Epoch: 5| Step: 10
Training loss: 3.4838086681538227
Validation loss: 3.668981315538358

Epoch: 5| Step: 11
Training loss: 1.8253670780517024
Validation loss: 3.6642932886942834

Epoch: 35| Step: 0
Training loss: 3.367958918667511
Validation loss: 3.6590735952300486

Epoch: 5| Step: 1
Training loss: 3.6321757096879774
Validation loss: 3.654955164629585

Epoch: 5| Step: 2
Training loss: 3.517175086875238
Validation loss: 3.6505777587603077

Epoch: 5| Step: 3
Training loss: 4.190736118012613
Validation loss: 3.6459384285447807

Epoch: 5| Step: 4
Training loss: 4.025340398764772
Validation loss: 3.6416758601918624

Epoch: 5| Step: 5
Training loss: 3.3272870222183504
Validation loss: 3.636950044689721

Epoch: 5| Step: 6
Training loss: 4.295841051027535
Validation loss: 3.6325061190353

Epoch: 5| Step: 7
Training loss: 3.1518720725380827
Validation loss: 3.628067404185527

Epoch: 5| Step: 8
Training loss: 4.017026426631503
Validation loss: 3.623413785741973

Epoch: 5| Step: 9
Training loss: 4.024559916255596
Validation loss: 3.6182291166606544

Epoch: 5| Step: 10
Training loss: 4.004546919017347
Validation loss: 3.614101749772724

Epoch: 5| Step: 11
Training loss: 2.210153285618207
Validation loss: 3.6094838741115063

Epoch: 36| Step: 0
Training loss: 3.483221983764973
Validation loss: 3.605170549299229

Epoch: 5| Step: 1
Training loss: 3.4255245725891545
Validation loss: 3.600649808367688

Epoch: 5| Step: 2
Training loss: 3.8495144921874918
Validation loss: 3.5964398807786706

Epoch: 5| Step: 3
Training loss: 3.88854066712661
Validation loss: 3.591991121295655

Epoch: 5| Step: 4
Training loss: 3.606606350486646
Validation loss: 3.58742407054941

Epoch: 5| Step: 5
Training loss: 4.12391023979591
Validation loss: 3.5830959455828246

Epoch: 5| Step: 6
Training loss: 3.8770183106138356
Validation loss: 3.5785182531329327

Epoch: 5| Step: 7
Training loss: 3.563514163570804
Validation loss: 3.573795647931714

Epoch: 5| Step: 8
Training loss: 3.8012977241347734
Validation loss: 3.5692312382668554

Epoch: 5| Step: 9
Training loss: 3.063671121690826
Validation loss: 3.564706854999708

Epoch: 5| Step: 10
Training loss: 3.996680193367265
Validation loss: 3.5597734055841683

Epoch: 5| Step: 11
Training loss: 4.276359047613
Validation loss: 3.555624595897319

Epoch: 37| Step: 0
Training loss: 3.842053791215673
Validation loss: 3.5508637986975993

Epoch: 5| Step: 1
Training loss: 3.012615065533772
Validation loss: 3.5462833028634058

Epoch: 5| Step: 2
Training loss: 3.6960698777070697
Validation loss: 3.5421820695631

Epoch: 5| Step: 3
Training loss: 4.753375610727105
Validation loss: 3.5376565595294527

Epoch: 5| Step: 4
Training loss: 3.6141202045456753
Validation loss: 3.5332888031723613

Epoch: 5| Step: 5
Training loss: 3.7155364440683
Validation loss: 3.5279766992035952

Epoch: 5| Step: 6
Training loss: 3.798881220507803
Validation loss: 3.5239107669811576

Epoch: 5| Step: 7
Training loss: 2.8106462091278086
Validation loss: 3.518680471091339

Epoch: 5| Step: 8
Training loss: 3.7333046883664878
Validation loss: 3.514942198956855

Epoch: 5| Step: 9
Training loss: 3.2756133575319892
Validation loss: 3.5104655235052595

Epoch: 5| Step: 10
Training loss: 3.9038117390250777
Validation loss: 3.506450771084671

Epoch: 5| Step: 11
Training loss: 2.690658753434798
Validation loss: 3.502129207963425

Epoch: 38| Step: 0
Training loss: 3.346485765692194
Validation loss: 3.497439657103851

Epoch: 5| Step: 1
Training loss: 4.070241975081798
Validation loss: 3.4928808697366303

Epoch: 5| Step: 2
Training loss: 3.868819691857643
Validation loss: 3.4885135927814406

Epoch: 5| Step: 3
Training loss: 4.086843474039449
Validation loss: 3.4842778920781634

Epoch: 5| Step: 4
Training loss: 3.571236989468597
Validation loss: 3.479389587083054

Epoch: 5| Step: 5
Training loss: 3.633226596652693
Validation loss: 3.4756143598617166

Epoch: 5| Step: 6
Training loss: 3.3069065300277
Validation loss: 3.47063247760462

Epoch: 5| Step: 7
Training loss: 3.4935541742955403
Validation loss: 3.4661662012538814

Epoch: 5| Step: 8
Training loss: 3.3824971604881577
Validation loss: 3.461390004309673

Epoch: 5| Step: 9
Training loss: 2.9326277563391807
Validation loss: 3.457261514987169

Epoch: 5| Step: 10
Training loss: 3.839933159564353
Validation loss: 3.453369839648988

Epoch: 5| Step: 11
Training loss: 3.8614842137773855
Validation loss: 3.448517471397905

Epoch: 39| Step: 0
Training loss: 3.578039043343563
Validation loss: 3.4443903789754917

Epoch: 5| Step: 1
Training loss: 2.690578649035238
Validation loss: 3.440529854960616

Epoch: 5| Step: 2
Training loss: 3.617832595942043
Validation loss: 3.436000016982212

Epoch: 5| Step: 3
Training loss: 3.5832389700833005
Validation loss: 3.4320756017417158

Epoch: 5| Step: 4
Training loss: 3.4340551975459683
Validation loss: 3.427533016829525

Epoch: 5| Step: 5
Training loss: 3.728772929342004
Validation loss: 3.423223505567512

Epoch: 5| Step: 6
Training loss: 4.259144985736161
Validation loss: 3.4194293056854987

Epoch: 5| Step: 7
Training loss: 3.232678986894927
Validation loss: 3.4144146619049507

Epoch: 5| Step: 8
Training loss: 3.708923821459685
Validation loss: 3.4105065957067926

Epoch: 5| Step: 9
Training loss: 3.480484916401147
Validation loss: 3.405434601272622

Epoch: 5| Step: 10
Training loss: 3.9228167979851163
Validation loss: 3.401406855155198

Epoch: 5| Step: 11
Training loss: 1.6287352840435063
Validation loss: 3.39673507551974

Epoch: 40| Step: 0
Training loss: 3.4656197110162386
Validation loss: 3.3927396283079148

Epoch: 5| Step: 1
Training loss: 3.604063808024493
Validation loss: 3.3886540217300323

Epoch: 5| Step: 2
Training loss: 3.551541925749153
Validation loss: 3.3848730247438543

Epoch: 5| Step: 3
Training loss: 3.1616687149526514
Validation loss: 3.3805784699739494

Epoch: 5| Step: 4
Training loss: 3.379409311584948
Validation loss: 3.3767742508949214

Epoch: 5| Step: 5
Training loss: 3.8039669161299536
Validation loss: 3.372723942214959

Epoch: 5| Step: 6
Training loss: 3.547492691903521
Validation loss: 3.368830540342429

Epoch: 5| Step: 7
Training loss: 3.3075631258037625
Validation loss: 3.3646886452805513

Epoch: 5| Step: 8
Training loss: 3.783902081551339
Validation loss: 3.360448118812739

Epoch: 5| Step: 9
Training loss: 3.408693749383685
Validation loss: 3.356628306430732

Epoch: 5| Step: 10
Training loss: 3.8367421846445016
Validation loss: 3.352482981277117

Epoch: 5| Step: 11
Training loss: 1.5112646243868397
Validation loss: 3.348177263569887

Epoch: 41| Step: 0
Training loss: 3.5209299710045032
Validation loss: 3.3441688952583917

Epoch: 5| Step: 1
Training loss: 3.5958430290459806
Validation loss: 3.340501270673267

Epoch: 5| Step: 2
Training loss: 3.346182963027889
Validation loss: 3.3368414220735874

Epoch: 5| Step: 3
Training loss: 3.475785277851538
Validation loss: 3.333936330772783

Epoch: 5| Step: 4
Training loss: 3.416247334372817
Validation loss: 3.3296485064410337

Epoch: 5| Step: 5
Training loss: 3.4211126723793033
Validation loss: 3.3250112937314773

Epoch: 5| Step: 6
Training loss: 2.88820352942454
Validation loss: 3.3212622686582325

Epoch: 5| Step: 7
Training loss: 3.2319306060781816
Validation loss: 3.3174873989127502

Epoch: 5| Step: 8
Training loss: 3.9539058351394023
Validation loss: 3.3139277446231454

Epoch: 5| Step: 9
Training loss: 3.510022798773905
Validation loss: 3.3099717562431836

Epoch: 5| Step: 10
Training loss: 3.6346566062455894
Validation loss: 3.3061560696177255

Epoch: 5| Step: 11
Training loss: 3.5815622403303093
Validation loss: 3.3020212135528846

Epoch: 42| Step: 0
Training loss: 3.4943711112581903
Validation loss: 3.2980885916112306

Epoch: 5| Step: 1
Training loss: 3.518387179869939
Validation loss: 3.2944411413425643

Epoch: 5| Step: 2
Training loss: 3.8469030582201134
Validation loss: 3.290086588295025

Epoch: 5| Step: 3
Training loss: 2.750092071379068
Validation loss: 3.2859160050871035

Epoch: 5| Step: 4
Training loss: 3.931186033859565
Validation loss: 3.2816503462200757

Epoch: 5| Step: 5
Training loss: 2.8193003351958446
Validation loss: 3.2780685381152814

Epoch: 5| Step: 6
Training loss: 3.4363794060822777
Validation loss: 3.273921697065483

Epoch: 5| Step: 7
Training loss: 2.6625533765716813
Validation loss: 3.26953997624128

Epoch: 5| Step: 8
Training loss: 2.950508856124787
Validation loss: 3.2665476370229762

Epoch: 5| Step: 9
Training loss: 4.070968018681903
Validation loss: 3.262393922652467

Epoch: 5| Step: 10
Training loss: 3.8214782309265876
Validation loss: 3.258490253330108

Epoch: 5| Step: 11
Training loss: 2.9740867431139946
Validation loss: 3.254425355460503

Epoch: 43| Step: 0
Training loss: 3.2921816427054713
Validation loss: 3.2507532053908688

Epoch: 5| Step: 1
Training loss: 3.6933642810484337
Validation loss: 3.2473433591533474

Epoch: 5| Step: 2
Training loss: 3.375037016488989
Validation loss: 3.2434715577794524

Epoch: 5| Step: 3
Training loss: 3.2333720398254213
Validation loss: 3.239252997643878

Epoch: 5| Step: 4
Training loss: 3.387591151738995
Validation loss: 3.2359777340305667

Epoch: 5| Step: 5
Training loss: 3.2551131008205076
Validation loss: 3.23205010157586

Epoch: 5| Step: 6
Training loss: 3.824896747467071
Validation loss: 3.2284101533210046

Epoch: 5| Step: 7
Training loss: 3.238493283166909
Validation loss: 3.2245534964790985

Epoch: 5| Step: 8
Training loss: 3.484122776088676
Validation loss: 3.221017717674136

Epoch: 5| Step: 9
Training loss: 3.1453879001029836
Validation loss: 3.2172199242075568

Epoch: 5| Step: 10
Training loss: 3.1295660611463534
Validation loss: 3.21324516589612

Epoch: 5| Step: 11
Training loss: 3.207988489287314
Validation loss: 3.209835398584428

Epoch: 44| Step: 0
Training loss: 3.1931362809112422
Validation loss: 3.20570398729333

Epoch: 5| Step: 1
Training loss: 3.4208210754794433
Validation loss: 3.202043422052311

Epoch: 5| Step: 2
Training loss: 3.281765270647183
Validation loss: 3.198023413244405

Epoch: 5| Step: 3
Training loss: 2.937513635481983
Validation loss: 3.194694297574581

Epoch: 5| Step: 4
Training loss: 2.8021105135104034
Validation loss: 3.1905805250275665

Epoch: 5| Step: 5
Training loss: 3.9430625014008607
Validation loss: 3.1866211146992125

Epoch: 5| Step: 6
Training loss: 3.408022078375423
Validation loss: 3.1828507568577082

Epoch: 5| Step: 7
Training loss: 3.978666636953618
Validation loss: 3.1795669332854573

Epoch: 5| Step: 8
Training loss: 3.5222347261973703
Validation loss: 3.17553815736321

Epoch: 5| Step: 9
Training loss: 3.0033436261959303
Validation loss: 3.1717958174219323

Epoch: 5| Step: 10
Training loss: 2.55427711293658
Validation loss: 3.167998257714011

Epoch: 5| Step: 11
Training loss: 4.462761127087289
Validation loss: 3.1644895037832956

Epoch: 45| Step: 0
Training loss: 3.4376102776611464
Validation loss: 3.160609033287915

Epoch: 5| Step: 1
Training loss: 3.271730838430659
Validation loss: 3.1566807921864624

Epoch: 5| Step: 2
Training loss: 3.7743650445555725
Validation loss: 3.1527880828584443

Epoch: 5| Step: 3
Training loss: 4.097011984623482
Validation loss: 3.148987229080365

Epoch: 5| Step: 4
Training loss: 3.139435348280049
Validation loss: 3.145014685832528

Epoch: 5| Step: 5
Training loss: 2.8823595802532913
Validation loss: 3.141007547186693

Epoch: 5| Step: 6
Training loss: 3.051874216529985
Validation loss: 3.1367692448473683

Epoch: 5| Step: 7
Training loss: 3.1905637490486165
Validation loss: 3.1330316329002006

Epoch: 5| Step: 8
Training loss: 2.8520278341960146
Validation loss: 3.129034807260509

Epoch: 5| Step: 9
Training loss: 3.217408873031559
Validation loss: 3.1256949224280755

Epoch: 5| Step: 10
Training loss: 3.202820256320875
Validation loss: 3.1222927382976766

Epoch: 5| Step: 11
Training loss: 2.162554825104333
Validation loss: 3.11868921117461

Epoch: 46| Step: 0
Training loss: 3.0546041413858016
Validation loss: 3.115579166285665

Epoch: 5| Step: 1
Training loss: 3.3684839996460694
Validation loss: 3.1124460271830876

Epoch: 5| Step: 2
Training loss: 3.74374376401557
Validation loss: 3.1095355773561373

Epoch: 5| Step: 3
Training loss: 3.0072634505474465
Validation loss: 3.1058991587768037

Epoch: 5| Step: 4
Training loss: 3.1436450917996135
Validation loss: 3.1026349267506865

Epoch: 5| Step: 5
Training loss: 3.5067606073084336
Validation loss: 3.0996510551549172

Epoch: 5| Step: 6
Training loss: 3.8016178351285754
Validation loss: 3.0965344360765523

Epoch: 5| Step: 7
Training loss: 2.6259056527184597
Validation loss: 3.092936322108952

Epoch: 5| Step: 8
Training loss: 3.241514131410774
Validation loss: 3.0898281278669435

Epoch: 5| Step: 9
Training loss: 3.0819707557533453
Validation loss: 3.086793286733391

Epoch: 5| Step: 10
Training loss: 3.1717881063952107
Validation loss: 3.083230288605113

Epoch: 5| Step: 11
Training loss: 1.3927015594949193
Validation loss: 3.079632746446669

Epoch: 47| Step: 0
Training loss: 2.582829385230319
Validation loss: 3.0770529543841243

Epoch: 5| Step: 1
Training loss: 3.4809495998329463
Validation loss: 3.0744802484128613

Epoch: 5| Step: 2
Training loss: 2.893286557090471
Validation loss: 3.0713676406196506

Epoch: 5| Step: 3
Training loss: 3.536564027145985
Validation loss: 3.0689775348898465

Epoch: 5| Step: 4
Training loss: 3.4540035459304748
Validation loss: 3.0654579494275747

Epoch: 5| Step: 5
Training loss: 3.0480909219932717
Validation loss: 3.0626482700604436

Epoch: 5| Step: 6
Training loss: 3.5933097237947864
Validation loss: 3.0595156992171666

Epoch: 5| Step: 7
Training loss: 3.0135511471787892
Validation loss: 3.0561514206000298

Epoch: 5| Step: 8
Training loss: 2.9311932979215602
Validation loss: 3.05327915855375

Epoch: 5| Step: 9
Training loss: 3.3808284870501932
Validation loss: 3.050289161581643

Epoch: 5| Step: 10
Training loss: 3.093473942317814
Validation loss: 3.047182396926287

Epoch: 5| Step: 11
Training loss: 3.5560286789929454
Validation loss: 3.0437341330634937

Epoch: 48| Step: 0
Training loss: 3.1572026996082423
Validation loss: 3.0410186761029405

Epoch: 5| Step: 1
Training loss: 3.172495964414466
Validation loss: 3.0384890972337524

Epoch: 5| Step: 2
Training loss: 3.091607170526454
Validation loss: 3.034825818024678

Epoch: 5| Step: 3
Training loss: 3.254334566976161
Validation loss: 3.0318235988554685

Epoch: 5| Step: 4
Training loss: 3.021731504013656
Validation loss: 3.028524153089052

Epoch: 5| Step: 5
Training loss: 3.250915398427707
Validation loss: 3.02526708768928

Epoch: 5| Step: 6
Training loss: 3.3452388978047938
Validation loss: 3.022338473581919

Epoch: 5| Step: 7
Training loss: 2.6682730147981943
Validation loss: 3.0191080241747064

Epoch: 5| Step: 8
Training loss: 3.5520536956594766
Validation loss: 3.0161294070568183

Epoch: 5| Step: 9
Training loss: 3.026186617313952
Validation loss: 3.0127523044860887

Epoch: 5| Step: 10
Training loss: 3.155453269790188
Validation loss: 3.009916199043545

Epoch: 5| Step: 11
Training loss: 3.5587615089779763
Validation loss: 3.0068016929943693

Epoch: 49| Step: 0
Training loss: 3.1304676289148228
Validation loss: 3.003762051974473

Epoch: 5| Step: 1
Training loss: 3.3631425888772717
Validation loss: 3.001508849904137

Epoch: 5| Step: 2
Training loss: 3.183190667781874
Validation loss: 2.9982320092577877

Epoch: 5| Step: 3
Training loss: 3.0675034424903163
Validation loss: 2.995803351422475

Epoch: 5| Step: 4
Training loss: 3.1062491342094334
Validation loss: 2.9928009161396862

Epoch: 5| Step: 5
Training loss: 3.1326392832217658
Validation loss: 2.992202645870219

Epoch: 5| Step: 6
Training loss: 3.0432135075868056
Validation loss: 2.9888234164012952

Epoch: 5| Step: 7
Training loss: 2.8463206985800173
Validation loss: 2.984536101701429

Epoch: 5| Step: 8
Training loss: 3.3390118550024166
Validation loss: 2.9813246191830913

Epoch: 5| Step: 9
Training loss: 2.7779647626461466
Validation loss: 2.9789526913678803

Epoch: 5| Step: 10
Training loss: 3.2037878327623317
Validation loss: 2.976607231411442

Epoch: 5| Step: 11
Training loss: 4.043053667586467
Validation loss: 2.9737715464834023

Epoch: 50| Step: 0
Training loss: 3.2254119373387553
Validation loss: 2.971270612143133

Epoch: 5| Step: 1
Training loss: 3.342157430277234
Validation loss: 2.9682646973792597

Epoch: 5| Step: 2
Training loss: 3.1566177002903175
Validation loss: 2.965174764148653

Epoch: 5| Step: 3
Training loss: 3.4407776898311586
Validation loss: 2.9623572938888025

Epoch: 5| Step: 4
Training loss: 2.9845766328932326
Validation loss: 2.958563635597049

Epoch: 5| Step: 5
Training loss: 2.983186335289764
Validation loss: 2.956012283187402

Epoch: 5| Step: 6
Training loss: 2.6576220390885017
Validation loss: 2.953172370490347

Epoch: 5| Step: 7
Training loss: 3.31571602799762
Validation loss: 2.9502781529409323

Epoch: 5| Step: 8
Training loss: 3.1173982859692884
Validation loss: 2.9472269704958047

Epoch: 5| Step: 9
Training loss: 2.856959088410109
Validation loss: 2.9446930946519068

Epoch: 5| Step: 10
Training loss: 2.8530545446381104
Validation loss: 2.942555125926611

Epoch: 5| Step: 11
Training loss: 3.40054361261065
Validation loss: 2.9396011974261422

Epoch: 51| Step: 0
Training loss: 3.1924247843963873
Validation loss: 2.9370788549633593

Epoch: 5| Step: 1
Training loss: 3.0666234808106263
Validation loss: 2.9340168816679526

Epoch: 5| Step: 2
Training loss: 3.1019915613075644
Validation loss: 2.9314044481973456

Epoch: 5| Step: 3
Training loss: 3.2160726726823388
Validation loss: 2.928887959203812

Epoch: 5| Step: 4
Training loss: 2.910902667489865
Validation loss: 2.926861165168969

Epoch: 5| Step: 5
Training loss: 2.763517535857153
Validation loss: 2.9244043550691354

Epoch: 5| Step: 6
Training loss: 2.926897760303147
Validation loss: 2.9216230083198687

Epoch: 5| Step: 7
Training loss: 3.1252654916519567
Validation loss: 2.919466127277201

Epoch: 5| Step: 8
Training loss: 3.001418414174912
Validation loss: 2.9161434839676033

Epoch: 5| Step: 9
Training loss: 3.255676447461295
Validation loss: 2.913894481434368

Epoch: 5| Step: 10
Training loss: 3.071968544421482
Validation loss: 2.911220146130955

Epoch: 5| Step: 11
Training loss: 3.448525520034483
Validation loss: 2.9082953355396475

Epoch: 52| Step: 0
Training loss: 2.702244433265025
Validation loss: 2.9052925617860144

Epoch: 5| Step: 1
Training loss: 3.0879236710557794
Validation loss: 2.902498811846963

Epoch: 5| Step: 2
Training loss: 3.345141255086172
Validation loss: 2.9006408309477116

Epoch: 5| Step: 3
Training loss: 3.0680028561376136
Validation loss: 2.8980865300295973

Epoch: 5| Step: 4
Training loss: 2.9080429289218954
Validation loss: 2.8962584064643178

Epoch: 5| Step: 5
Training loss: 2.5138861291447543
Validation loss: 2.8944851678156454

Epoch: 5| Step: 6
Training loss: 2.93558683387225
Validation loss: 2.8915277188435944

Epoch: 5| Step: 7
Training loss: 3.4012787265538837
Validation loss: 2.8884835567652356

Epoch: 5| Step: 8
Training loss: 2.985598647824029
Validation loss: 2.886011665959527

Epoch: 5| Step: 9
Training loss: 3.418701930292197
Validation loss: 2.883675071460506

Epoch: 5| Step: 10
Training loss: 2.920216625225709
Validation loss: 2.8809019958446807

Epoch: 5| Step: 11
Training loss: 2.8342988295240685
Validation loss: 2.8784862679533916

Epoch: 53| Step: 0
Training loss: 3.10665130172117
Validation loss: 2.876008257774909

Epoch: 5| Step: 1
Training loss: 3.1067856017937086
Validation loss: 2.873604390820876

Epoch: 5| Step: 2
Training loss: 2.52400224820383
Validation loss: 2.871314748272852

Epoch: 5| Step: 3
Training loss: 3.287438650972993
Validation loss: 2.869074565143408

Epoch: 5| Step: 4
Training loss: 3.2947797580680267
Validation loss: 2.866702205877535

Epoch: 5| Step: 5
Training loss: 2.928336602608845
Validation loss: 2.8641749258498517

Epoch: 5| Step: 6
Training loss: 3.159893388036198
Validation loss: 2.8613480707195973

Epoch: 5| Step: 7
Training loss: 3.1109435759197166
Validation loss: 2.858839353130479

Epoch: 5| Step: 8
Training loss: 3.0567075484387
Validation loss: 2.8567963630604245

Epoch: 5| Step: 9
Training loss: 2.565718699520343
Validation loss: 2.8538377368109358

Epoch: 5| Step: 10
Training loss: 2.7101799073977815
Validation loss: 2.85177074002975

Epoch: 5| Step: 11
Training loss: 3.4674890649206436
Validation loss: 2.8495723799530177

Epoch: 54| Step: 0
Training loss: 3.2895179849954306
Validation loss: 2.846795620528692

Epoch: 5| Step: 1
Training loss: 2.351348258869997
Validation loss: 2.844469405621871

Epoch: 5| Step: 2
Training loss: 2.9714194091980497
Validation loss: 2.8421270958603775

Epoch: 5| Step: 3
Training loss: 3.160200913235062
Validation loss: 2.839564687948008

Epoch: 5| Step: 4
Training loss: 2.7996467197163475
Validation loss: 2.8381688191001393

Epoch: 5| Step: 5
Training loss: 2.496662009540012
Validation loss: 2.836407551548435

Epoch: 5| Step: 6
Training loss: 3.2000151633857046
Validation loss: 2.838477780850996

Epoch: 5| Step: 7
Training loss: 3.137471147989695
Validation loss: 2.831421102809001

Epoch: 5| Step: 8
Training loss: 3.287788778755554
Validation loss: 2.8300078782375206

Epoch: 5| Step: 9
Training loss: 3.1036434543372393
Validation loss: 2.8285971716315546

Epoch: 5| Step: 10
Training loss: 2.6648218409549935
Validation loss: 2.8272261095550193

Epoch: 5| Step: 11
Training loss: 3.5173863046757887
Validation loss: 2.8254428741435245

Epoch: 55| Step: 0
Training loss: 3.296379594508392
Validation loss: 2.8238178951830797

Epoch: 5| Step: 1
Training loss: 2.9042863672472996
Validation loss: 2.821489854469561

Epoch: 5| Step: 2
Training loss: 2.982691105030379
Validation loss: 2.817996982778157

Epoch: 5| Step: 3
Training loss: 2.9977616860998055
Validation loss: 2.8155740256992896

Epoch: 5| Step: 4
Training loss: 2.8686659324811132
Validation loss: 2.8125816404008224

Epoch: 5| Step: 5
Training loss: 3.10234525013342
Validation loss: 2.81219003523448

Epoch: 5| Step: 6
Training loss: 3.004332592773798
Validation loss: 2.8067112690125575

Epoch: 5| Step: 7
Training loss: 2.424520512005367
Validation loss: 2.8056449530986725

Epoch: 5| Step: 8
Training loss: 3.0983307189547333
Validation loss: 2.8038377670041092

Epoch: 5| Step: 9
Training loss: 2.5359162071777255
Validation loss: 2.801877043739837

Epoch: 5| Step: 10
Training loss: 3.164451141978378
Validation loss: 2.8004120743467023

Epoch: 5| Step: 11
Training loss: 3.019077360675147
Validation loss: 2.797930569778708

Epoch: 56| Step: 0
Training loss: 2.758010295226292
Validation loss: 2.7968618829515486

Epoch: 5| Step: 1
Training loss: 2.6632868289189697
Validation loss: 2.795284223760003

Epoch: 5| Step: 2
Training loss: 3.1751866083048714
Validation loss: 2.794023128929425

Epoch: 5| Step: 3
Training loss: 2.5819823106060804
Validation loss: 2.792526010843532

Epoch: 5| Step: 4
Training loss: 3.262941416844363
Validation loss: 2.7907488343720708

Epoch: 5| Step: 5
Training loss: 2.7883812849805327
Validation loss: 2.787294074721669

Epoch: 5| Step: 6
Training loss: 3.193455984538241
Validation loss: 2.787073410932029

Epoch: 5| Step: 7
Training loss: 2.736154554853741
Validation loss: 2.7864231618402475

Epoch: 5| Step: 8
Training loss: 3.184194309248079
Validation loss: 2.784081789041891

Epoch: 5| Step: 9
Training loss: 2.6310007443921766
Validation loss: 2.7804362646100405

Epoch: 5| Step: 10
Training loss: 2.890936262538498
Validation loss: 2.777807487620312

Epoch: 5| Step: 11
Training loss: 3.942451391410275
Validation loss: 2.776507452464004

Epoch: 57| Step: 0
Training loss: 2.5764077680866584
Validation loss: 2.7752415265546526

Epoch: 5| Step: 1
Training loss: 3.2054964544561972
Validation loss: 2.7740800748939227

Epoch: 5| Step: 2
Training loss: 2.782957602931521
Validation loss: 2.7720833817246953

Epoch: 5| Step: 3
Training loss: 2.9769716156877197
Validation loss: 2.7711399788267634

Epoch: 5| Step: 4
Training loss: 2.475797420700484
Validation loss: 2.77009854696289

Epoch: 5| Step: 5
Training loss: 2.778794050807029
Validation loss: 2.7679715555542717

Epoch: 5| Step: 6
Training loss: 3.131831217596615
Validation loss: 2.768052119098586

Epoch: 5| Step: 7
Training loss: 2.810967600111562
Validation loss: 2.764476643673797

Epoch: 5| Step: 8
Training loss: 3.2922255287092295
Validation loss: 2.7616703221644734

Epoch: 5| Step: 9
Training loss: 2.8441653105580444
Validation loss: 2.7599020112306802

Epoch: 5| Step: 10
Training loss: 2.8247175396169055
Validation loss: 2.7579357274579186

Epoch: 5| Step: 11
Training loss: 3.7106334682198985
Validation loss: 2.7553827642788185

Epoch: 58| Step: 0
Training loss: 2.8828808122516834
Validation loss: 2.753430596435584

Epoch: 5| Step: 1
Training loss: 2.8703456189399854
Validation loss: 2.750844681223433

Epoch: 5| Step: 2
Training loss: 2.8820856103193675
Validation loss: 2.7502064193935847

Epoch: 5| Step: 3
Training loss: 3.1940970872372922
Validation loss: 2.748166607433402

Epoch: 5| Step: 4
Training loss: 2.8335167507567074
Validation loss: 2.7493622105277784

Epoch: 5| Step: 5
Training loss: 2.766277602618681
Validation loss: 2.7450553772186437

Epoch: 5| Step: 6
Training loss: 2.3797162059873482
Validation loss: 2.742422233308899

Epoch: 5| Step: 7
Training loss: 3.064283668982312
Validation loss: 2.7404011036475078

Epoch: 5| Step: 8
Training loss: 3.254952545288874
Validation loss: 2.7385728638154827

Epoch: 5| Step: 9
Training loss: 3.053554158811246
Validation loss: 2.735988685743462

Epoch: 5| Step: 10
Training loss: 2.500277122396983
Validation loss: 2.734075475363943

Epoch: 5| Step: 11
Training loss: 2.4971140416463373
Validation loss: 2.7330923796105075

Epoch: 59| Step: 0
Training loss: 3.1650893817351444
Validation loss: 2.730627652894083

Epoch: 5| Step: 1
Training loss: 2.656798003271605
Validation loss: 2.7295623824863933

Epoch: 5| Step: 2
Training loss: 2.7720140699659797
Validation loss: 2.7282760212723276

Epoch: 5| Step: 3
Training loss: 2.1834192632795593
Validation loss: 2.7257665221017855

Epoch: 5| Step: 4
Training loss: 2.872883888668067
Validation loss: 2.724610144319961

Epoch: 5| Step: 5
Training loss: 2.8223841447594618
Validation loss: 2.723140434511489

Epoch: 5| Step: 6
Training loss: 3.1413189325385753
Validation loss: 2.720969445201073

Epoch: 5| Step: 7
Training loss: 2.9541299714543077
Validation loss: 2.719786450076546

Epoch: 5| Step: 8
Training loss: 2.5566965771665813
Validation loss: 2.718520662712511

Epoch: 5| Step: 9
Training loss: 2.747596123552441
Validation loss: 2.716487677700153

Epoch: 5| Step: 10
Training loss: 3.316468219155648
Validation loss: 2.7146488403317086

Epoch: 5| Step: 11
Training loss: 3.4990276620910166
Validation loss: 2.7138244069138535

Epoch: 60| Step: 0
Training loss: 2.580353299872063
Validation loss: 2.7107648363927885

Epoch: 5| Step: 1
Training loss: 2.8599961236780747
Validation loss: 2.709017870053512

Epoch: 5| Step: 2
Training loss: 2.605257451813212
Validation loss: 2.706906292385897

Epoch: 5| Step: 3
Training loss: 2.8899622801856766
Validation loss: 2.7049897915112213

Epoch: 5| Step: 4
Training loss: 2.8828538514353017
Validation loss: 2.703744479217983

Epoch: 5| Step: 5
Training loss: 3.133623964615303
Validation loss: 2.7014665128042217

Epoch: 5| Step: 6
Training loss: 3.1909415421494387
Validation loss: 2.7060292358743365

Epoch: 5| Step: 7
Training loss: 2.795660852909771
Validation loss: 2.71057261302526

Epoch: 5| Step: 8
Training loss: 2.9289520561277076
Validation loss: 2.703210156813792

Epoch: 5| Step: 9
Training loss: 2.5429497174606985
Validation loss: 2.6967076362728455

Epoch: 5| Step: 10
Training loss: 2.795051960880115
Validation loss: 2.694635319066491

Epoch: 5| Step: 11
Training loss: 2.9848153153990977
Validation loss: 2.6945118880652346

Epoch: 61| Step: 0
Training loss: 3.2063759286403335
Validation loss: 2.6977047904536295

Epoch: 5| Step: 1
Training loss: 2.549770651582488
Validation loss: 2.6937820917977877

Epoch: 5| Step: 2
Training loss: 2.448449216229147
Validation loss: 2.688829824875648

Epoch: 5| Step: 3
Training loss: 3.1666911944058485
Validation loss: 2.6885526835469467

Epoch: 5| Step: 4
Training loss: 2.736898946750969
Validation loss: 2.6866073678487497

Epoch: 5| Step: 5
Training loss: 3.16582645178202
Validation loss: 2.686327734044812

Epoch: 5| Step: 6
Training loss: 3.09333783111026
Validation loss: 2.683886497703069

Epoch: 5| Step: 7
Training loss: 2.7461926373275887
Validation loss: 2.6835721499532994

Epoch: 5| Step: 8
Training loss: 2.4125513575330113
Validation loss: 2.681572720861922

Epoch: 5| Step: 9
Training loss: 2.8505742280934565
Validation loss: 2.6785403206699163

Epoch: 5| Step: 10
Training loss: 2.63874054430447
Validation loss: 2.679123395557511

Epoch: 5| Step: 11
Training loss: 2.458943846158755
Validation loss: 2.6764450252337997

Epoch: 62| Step: 0
Training loss: 2.5084935864767077
Validation loss: 2.6782206458539437

Epoch: 5| Step: 1
Training loss: 2.7520296236428776
Validation loss: 2.675911677910598

Epoch: 5| Step: 2
Training loss: 2.330144121845376
Validation loss: 2.672322843619631

Epoch: 5| Step: 3
Training loss: 2.5764126726568204
Validation loss: 2.674698503384496

Epoch: 5| Step: 4
Training loss: 2.5589159580635172
Validation loss: 2.6733373837626617

Epoch: 5| Step: 5
Training loss: 2.500186627097786
Validation loss: 2.6749867505788223

Epoch: 5| Step: 6
Training loss: 3.0035528761386474
Validation loss: 2.693302208337799

Epoch: 5| Step: 7
Training loss: 3.1270374522612037
Validation loss: 2.6919914535842144

Epoch: 5| Step: 8
Training loss: 3.0517154684562318
Validation loss: 2.6728352016681822

Epoch: 5| Step: 9
Training loss: 3.2683368720840007
Validation loss: 2.664246467957875

Epoch: 5| Step: 10
Training loss: 3.056282739132385
Validation loss: 2.6643091723365

Epoch: 5| Step: 11
Training loss: 3.0886769943223826
Validation loss: 2.666688283196891

Epoch: 63| Step: 0
Training loss: 2.6359806186154535
Validation loss: 2.6663532942185184

Epoch: 5| Step: 1
Training loss: 2.536382017351794
Validation loss: 2.667943716978981

Epoch: 5| Step: 2
Training loss: 2.388043774099755
Validation loss: 2.6758252068317683

Epoch: 5| Step: 3
Training loss: 2.8612844626574825
Validation loss: 2.670688414001939

Epoch: 5| Step: 4
Training loss: 2.863132863278553
Validation loss: 2.6711808096648384

Epoch: 5| Step: 5
Training loss: 2.5720477985906216
Validation loss: 2.6638082157315153

Epoch: 5| Step: 6
Training loss: 3.190493356228804
Validation loss: 2.6631633102429584

Epoch: 5| Step: 7
Training loss: 3.3680394769833186
Validation loss: 2.6664054054685877

Epoch: 5| Step: 8
Training loss: 2.874742081724548
Validation loss: 2.6558425366406095

Epoch: 5| Step: 9
Training loss: 2.99164594326085
Validation loss: 2.6519453660588588

Epoch: 5| Step: 10
Training loss: 2.603554269628329
Validation loss: 2.6512249481657855

Epoch: 5| Step: 11
Training loss: 1.6027031534953304
Validation loss: 2.6503900477821736

Epoch: 64| Step: 0
Training loss: 2.9098858803726295
Validation loss: 2.65112943197989

Epoch: 5| Step: 1
Training loss: 2.714878351004773
Validation loss: 2.649209587961034

Epoch: 5| Step: 2
Training loss: 2.9632517444319353
Validation loss: 2.6461685161091166

Epoch: 5| Step: 3
Training loss: 2.83817810156767
Validation loss: 2.64642480686992

Epoch: 5| Step: 4
Training loss: 2.7737726573182027
Validation loss: 2.6456442199664942

Epoch: 5| Step: 5
Training loss: 3.060920152133076
Validation loss: 2.6432213894333447

Epoch: 5| Step: 6
Training loss: 2.655244255396601
Validation loss: 2.639460502517474

Epoch: 5| Step: 7
Training loss: 2.6753831998922823
Validation loss: 2.63867328680468

Epoch: 5| Step: 8
Training loss: 2.6703937730201175
Validation loss: 2.636414276251302

Epoch: 5| Step: 9
Training loss: 2.875501008539184
Validation loss: 2.636136753229785

Epoch: 5| Step: 10
Training loss: 2.414239870734137
Validation loss: 2.6321601738723364

Epoch: 5| Step: 11
Training loss: 2.886261652166703
Validation loss: 2.630159677238001

Epoch: 65| Step: 0
Training loss: 2.6065280939750863
Validation loss: 2.631247431647345

Epoch: 5| Step: 1
Training loss: 2.71854496325224
Validation loss: 2.6333196587348344

Epoch: 5| Step: 2
Training loss: 2.7420456026321047
Validation loss: 2.63465562142592

Epoch: 5| Step: 3
Training loss: 2.7554895922070237
Validation loss: 2.6259410397534

Epoch: 5| Step: 4
Training loss: 2.8666858702023785
Validation loss: 2.634448681604539

Epoch: 5| Step: 5
Training loss: 3.238897727385716
Validation loss: 2.6326945134108812

Epoch: 5| Step: 6
Training loss: 3.0508090712759923
Validation loss: 2.629379271472133

Epoch: 5| Step: 7
Training loss: 2.698044959200583
Validation loss: 2.624871470317111

Epoch: 5| Step: 8
Training loss: 2.8560165944298523
Validation loss: 2.6241108357230414

Epoch: 5| Step: 9
Training loss: 2.586441405834083
Validation loss: 2.6236755950710227

Epoch: 5| Step: 10
Training loss: 2.280192718057387
Validation loss: 2.625436549746846

Epoch: 5| Step: 11
Training loss: 2.4980955499435864
Validation loss: 2.625966609369938

Epoch: 66| Step: 0
Training loss: 3.1491481840289994
Validation loss: 2.6276807304446166

Epoch: 5| Step: 1
Training loss: 2.326761140663279
Validation loss: 2.628014075394924

Epoch: 5| Step: 2
Training loss: 2.9467366870771317
Validation loss: 2.627012064484114

Epoch: 5| Step: 3
Training loss: 2.5874894662541283
Validation loss: 2.6264670790949833

Epoch: 5| Step: 4
Training loss: 2.8283374348305177
Validation loss: 2.625942806444485

Epoch: 5| Step: 5
Training loss: 2.4884797740173337
Validation loss: 2.6233428878945446

Epoch: 5| Step: 6
Training loss: 2.8377067994704355
Validation loss: 2.620630696189895

Epoch: 5| Step: 7
Training loss: 2.6970529437895734
Validation loss: 2.6167673409486514

Epoch: 5| Step: 8
Training loss: 3.2342523376498855
Validation loss: 2.6156252169409586

Epoch: 5| Step: 9
Training loss: 2.6409377415117183
Validation loss: 2.613706112296599

Epoch: 5| Step: 10
Training loss: 2.4867176071485555
Validation loss: 2.6094525300955276

Epoch: 5| Step: 11
Training loss: 2.7303726987084636
Validation loss: 2.610807246564798

Epoch: 67| Step: 0
Training loss: 3.2794001133056963
Validation loss: 2.609020936285878

Epoch: 5| Step: 1
Training loss: 2.7936361302461266
Validation loss: 2.616333631462835

Epoch: 5| Step: 2
Training loss: 2.7009570297670322
Validation loss: 2.6156835457566836

Epoch: 5| Step: 3
Training loss: 2.658701763710886
Validation loss: 2.6161584909385907

Epoch: 5| Step: 4
Training loss: 2.5347672503462197
Validation loss: 2.6092453065876096

Epoch: 5| Step: 5
Training loss: 2.540715920485964
Validation loss: 2.606813018233921

Epoch: 5| Step: 6
Training loss: 3.1770188288576473
Validation loss: 2.6012788375460985

Epoch: 5| Step: 7
Training loss: 3.0927947139700738
Validation loss: 2.601035216454231

Epoch: 5| Step: 8
Training loss: 2.1484825545701973
Validation loss: 2.6046292097666646

Epoch: 5| Step: 9
Training loss: 2.2107177193793492
Validation loss: 2.607492445468169

Epoch: 5| Step: 10
Training loss: 2.9164299641791356
Validation loss: 2.6074278908801833

Epoch: 5| Step: 11
Training loss: 2.584720936216371
Validation loss: 2.6094864157153603

Epoch: 68| Step: 0
Training loss: 2.9625115953693335
Validation loss: 2.604625861055099

Epoch: 5| Step: 1
Training loss: 2.7336717845749607
Validation loss: 2.6037481976296983

Epoch: 5| Step: 2
Training loss: 2.6286017821170584
Validation loss: 2.5958303588270493

Epoch: 5| Step: 3
Training loss: 2.835432191498405
Validation loss: 2.5972203015565714

Epoch: 5| Step: 4
Training loss: 2.664301886668334
Validation loss: 2.5947014239491732

Epoch: 5| Step: 5
Training loss: 2.847503532427572
Validation loss: 2.5968935886640447

Epoch: 5| Step: 6
Training loss: 2.9615935149968315
Validation loss: 2.598573844820739

Epoch: 5| Step: 7
Training loss: 2.7799082745026746
Validation loss: 2.604183369900859

Epoch: 5| Step: 8
Training loss: 2.5668732147173436
Validation loss: 2.6030930073311214

Epoch: 5| Step: 9
Training loss: 2.5488737723402894
Validation loss: 2.6033247629477194

Epoch: 5| Step: 10
Training loss: 2.704504994846724
Validation loss: 2.597537817681248

Epoch: 5| Step: 11
Training loss: 1.8040252395183765
Validation loss: 2.5937363804225995

Epoch: 69| Step: 0
Training loss: 2.7850258731153863
Validation loss: 2.5916064455225585

Epoch: 5| Step: 1
Training loss: 2.605183690160592
Validation loss: 2.5921891276649727

Epoch: 5| Step: 2
Training loss: 2.89896390098579
Validation loss: 2.583511436127013

Epoch: 5| Step: 3
Training loss: 2.661174383276219
Validation loss: 2.5885293846427446

Epoch: 5| Step: 4
Training loss: 2.5733522568963876
Validation loss: 2.5872835111736516

Epoch: 5| Step: 5
Training loss: 2.3145830206494558
Validation loss: 2.5867369185408453

Epoch: 5| Step: 6
Training loss: 3.3061006739450276
Validation loss: 2.58696675633945

Epoch: 5| Step: 7
Training loss: 2.2963485633491603
Validation loss: 2.5882478940015536

Epoch: 5| Step: 8
Training loss: 2.696146252810969
Validation loss: 2.5873259690096457

Epoch: 5| Step: 9
Training loss: 2.7711183979754717
Validation loss: 2.5855775142701773

Epoch: 5| Step: 10
Training loss: 2.9160635369996393
Validation loss: 2.58649061420733

Epoch: 5| Step: 11
Training loss: 2.6012211939450864
Validation loss: 2.5854138500086594

Epoch: 70| Step: 0
Training loss: 2.6805498609553733
Validation loss: 2.5828650624395526

Epoch: 5| Step: 1
Training loss: 2.765289631138046
Validation loss: 2.582050029091925

Epoch: 5| Step: 2
Training loss: 2.7001819796517577
Validation loss: 2.5792995898290108

Epoch: 5| Step: 3
Training loss: 2.569516136841766
Validation loss: 2.578995578855512

Epoch: 5| Step: 4
Training loss: 3.0489863978376843
Validation loss: 2.5759278500704883

Epoch: 5| Step: 5
Training loss: 2.8822166426673332
Validation loss: 2.5757880282811816

Epoch: 5| Step: 6
Training loss: 2.5643113410145824
Validation loss: 2.571032298677141

Epoch: 5| Step: 7
Training loss: 2.460354787472087
Validation loss: 2.57217162589777

Epoch: 5| Step: 8
Training loss: 2.9138633516798937
Validation loss: 2.5693619776428007

Epoch: 5| Step: 9
Training loss: 2.5382237384136053
Validation loss: 2.5710616831603965

Epoch: 5| Step: 10
Training loss: 2.7956321981274703
Validation loss: 2.57050537653402

Epoch: 5| Step: 11
Training loss: 2.010125753539799
Validation loss: 2.565072725881119

Epoch: 71| Step: 0
Training loss: 2.7024520300913886
Validation loss: 2.567021950731541

Epoch: 5| Step: 1
Training loss: 2.3741228592020964
Validation loss: 2.5656453421835974

Epoch: 5| Step: 2
Training loss: 2.703425131656944
Validation loss: 2.5672912155687952

Epoch: 5| Step: 3
Training loss: 3.19289525010217
Validation loss: 2.566241765666373

Epoch: 5| Step: 4
Training loss: 2.513278506546966
Validation loss: 2.5666925550265773

Epoch: 5| Step: 5
Training loss: 2.4967465211281223
Validation loss: 2.5663558165357356

Epoch: 5| Step: 6
Training loss: 2.6229390727917483
Validation loss: 2.5651225455669735

Epoch: 5| Step: 7
Training loss: 2.4241938165285415
Validation loss: 2.5653574177901994

Epoch: 5| Step: 8
Training loss: 3.1135419212350564
Validation loss: 2.5628686035028796

Epoch: 5| Step: 9
Training loss: 2.7362009981454576
Validation loss: 2.5623509472242034

Epoch: 5| Step: 10
Training loss: 2.75618905759117
Validation loss: 2.563558999325531

Epoch: 5| Step: 11
Training loss: 2.446924817587832
Validation loss: 2.560444344592641

Epoch: 72| Step: 0
Training loss: 2.782631691612196
Validation loss: 2.560099415463048

Epoch: 5| Step: 1
Training loss: 2.8184421075110118
Validation loss: 2.5604932378354226

Epoch: 5| Step: 2
Training loss: 2.9448173774610678
Validation loss: 2.559951553954241

Epoch: 5| Step: 3
Training loss: 2.238544761498183
Validation loss: 2.559897974167967

Epoch: 5| Step: 4
Training loss: 2.884076428071306
Validation loss: 2.55905278482789

Epoch: 5| Step: 5
Training loss: 2.523096398131696
Validation loss: 2.558345062361514

Epoch: 5| Step: 6
Training loss: 2.9705345813258157
Validation loss: 2.559712948997656

Epoch: 5| Step: 7
Training loss: 2.7059605890802922
Validation loss: 2.559045684736848

Epoch: 5| Step: 8
Training loss: 2.705887898454081
Validation loss: 2.5575879243271706

Epoch: 5| Step: 9
Training loss: 2.3396126405324575
Validation loss: 2.5590420473397653

Epoch: 5| Step: 10
Training loss: 2.6219883854461115
Validation loss: 2.556467437512392

Epoch: 5| Step: 11
Training loss: 2.8601576770986266
Validation loss: 2.5572326145747795

Epoch: 73| Step: 0
Training loss: 2.7804497414025184
Validation loss: 2.5560966245158334

Epoch: 5| Step: 1
Training loss: 3.2476744033933795
Validation loss: 2.554437630942367

Epoch: 5| Step: 2
Training loss: 2.2839571423225764
Validation loss: 2.5555847373335183

Epoch: 5| Step: 3
Training loss: 2.341114953459415
Validation loss: 2.5530400539478166

Epoch: 5| Step: 4
Training loss: 2.87625244060945
Validation loss: 2.5528110336004994

Epoch: 5| Step: 5
Training loss: 2.235158182814668
Validation loss: 2.552461309404399

Epoch: 5| Step: 6
Training loss: 2.9423312775523414
Validation loss: 2.5516163742629017

Epoch: 5| Step: 7
Training loss: 2.412074088019979
Validation loss: 2.551122851862799

Epoch: 5| Step: 8
Training loss: 2.540867278499021
Validation loss: 2.5504000945150858

Epoch: 5| Step: 9
Training loss: 3.1153496317334746
Validation loss: 2.5531838023131166

Epoch: 5| Step: 10
Training loss: 2.6861828969861286
Validation loss: 2.55614724485125

Epoch: 5| Step: 11
Training loss: 2.0242403418664012
Validation loss: 2.552680110573537

Epoch: 74| Step: 0
Training loss: 3.2050134069962763
Validation loss: 2.557530674898032

Epoch: 5| Step: 1
Training loss: 2.6518966904795365
Validation loss: 2.567953196077019

Epoch: 5| Step: 2
Training loss: 2.6257485730159065
Validation loss: 2.566913517831012

Epoch: 5| Step: 3
Training loss: 2.46290630725826
Validation loss: 2.569875519622365

Epoch: 5| Step: 4
Training loss: 2.7298525659343365
Validation loss: 2.573602578528196

Epoch: 5| Step: 5
Training loss: 2.7327587473551955
Validation loss: 2.562132250751606

Epoch: 5| Step: 6
Training loss: 2.649602493126475
Validation loss: 2.55807546554439

Epoch: 5| Step: 7
Training loss: 2.5698317800008703
Validation loss: 2.5456163966895717

Epoch: 5| Step: 8
Training loss: 2.367475032654604
Validation loss: 2.5432020784480054

Epoch: 5| Step: 9
Training loss: 2.7585201058055207
Validation loss: 2.5450558006274826

Epoch: 5| Step: 10
Training loss: 2.6462275193907843
Validation loss: 2.5481060695872872

Epoch: 5| Step: 11
Training loss: 3.049156860380276
Validation loss: 2.5488045332049443

Epoch: 75| Step: 0
Training loss: 2.2988965746234498
Validation loss: 2.555449396470451

Epoch: 5| Step: 1
Training loss: 2.791240707088159
Validation loss: 2.5606405210501784

Epoch: 5| Step: 2
Training loss: 3.109518843347599
Validation loss: 2.5644806673731004

Epoch: 5| Step: 3
Training loss: 2.8114823937608513
Validation loss: 2.563982383596839

Epoch: 5| Step: 4
Training loss: 2.799849308591066
Validation loss: 2.5620940127180933

Epoch: 5| Step: 5
Training loss: 2.6375246525918548
Validation loss: 2.5585984829380823

Epoch: 5| Step: 6
Training loss: 2.4517901245020366
Validation loss: 2.560822558117074

Epoch: 5| Step: 7
Training loss: 2.5098478904926975
Validation loss: 2.5553444689380234

Epoch: 5| Step: 8
Training loss: 3.3166012116943016
Validation loss: 2.5531239327872455

Epoch: 5| Step: 9
Training loss: 2.556827407203754
Validation loss: 2.5499665311100443

Epoch: 5| Step: 10
Training loss: 2.119821859108795
Validation loss: 2.543743591706673

Epoch: 5| Step: 11
Training loss: 2.6587508153802064
Validation loss: 2.5401635076555205

Epoch: 76| Step: 0
Training loss: 2.984452651047219
Validation loss: 2.536840994845782

Epoch: 5| Step: 1
Training loss: 2.524598412635278
Validation loss: 2.5341352808007165

Epoch: 5| Step: 2
Training loss: 2.7722447369140513
Validation loss: 2.53373715769909

Epoch: 5| Step: 3
Training loss: 2.4130072895418953
Validation loss: 2.532740640689676

Epoch: 5| Step: 4
Training loss: 2.633277557683728
Validation loss: 2.5324312365938133

Epoch: 5| Step: 5
Training loss: 2.876745937783133
Validation loss: 2.5330675373639258

Epoch: 5| Step: 6
Training loss: 2.40557832136925
Validation loss: 2.528919827158954

Epoch: 5| Step: 7
Training loss: 2.564041232451504
Validation loss: 2.5347127266855503

Epoch: 5| Step: 8
Training loss: 2.7170399516639407
Validation loss: 2.5318420016146415

Epoch: 5| Step: 9
Training loss: 2.8363146150238605
Validation loss: 2.5302939238087627

Epoch: 5| Step: 10
Training loss: 2.356888427048712
Validation loss: 2.530533163191676

Epoch: 5| Step: 11
Training loss: 3.4700496403993903
Validation loss: 2.5316773787714046

Epoch: 77| Step: 0
Training loss: 2.8493836321975072
Validation loss: 2.5305034572650813

Epoch: 5| Step: 1
Training loss: 2.342929645655927
Validation loss: 2.5315310749934676

Epoch: 5| Step: 2
Training loss: 2.888498544812476
Validation loss: 2.5338342527970696

Epoch: 5| Step: 3
Training loss: 3.2327941864512693
Validation loss: 2.545137214284233

Epoch: 5| Step: 4
Training loss: 2.323541212300481
Validation loss: 2.5381934962783297

Epoch: 5| Step: 5
Training loss: 2.592243814345301
Validation loss: 2.5310583395276267

Epoch: 5| Step: 6
Training loss: 2.5435351606742977
Validation loss: 2.5296053390245317

Epoch: 5| Step: 7
Training loss: 2.954699868388642
Validation loss: 2.527499454031614

Epoch: 5| Step: 8
Training loss: 2.4410291700983913
Validation loss: 2.5292891375841875

Epoch: 5| Step: 9
Training loss: 2.2583482364101806
Validation loss: 2.5243817109052378

Epoch: 5| Step: 10
Training loss: 2.836484073480563
Validation loss: 2.5293142114386353

Epoch: 5| Step: 11
Training loss: 2.398452311417265
Validation loss: 2.5277109719508966

Epoch: 78| Step: 0
Training loss: 2.463642486595369
Validation loss: 2.5294258428462104

Epoch: 5| Step: 1
Training loss: 2.596470612440254
Validation loss: 2.527705941442921

Epoch: 5| Step: 2
Training loss: 2.601632148795537
Validation loss: 2.5302467869903826

Epoch: 5| Step: 3
Training loss: 2.932984798127976
Validation loss: 2.5280188514231936

Epoch: 5| Step: 4
Training loss: 2.3557892892842927
Validation loss: 2.527968017583049

Epoch: 5| Step: 5
Training loss: 2.5376754023621513
Validation loss: 2.528048614052128

Epoch: 5| Step: 6
Training loss: 2.596793813159363
Validation loss: 2.5249001247180107

Epoch: 5| Step: 7
Training loss: 2.6330687627393945
Validation loss: 2.52613312598285

Epoch: 5| Step: 8
Training loss: 2.8969543446165114
Validation loss: 2.527082206639864

Epoch: 5| Step: 9
Training loss: 2.7291518543414135
Validation loss: 2.526485733772176

Epoch: 5| Step: 10
Training loss: 2.7108004752496577
Validation loss: 2.523900390150915

Epoch: 5| Step: 11
Training loss: 3.4659290011838904
Validation loss: 2.5239636371686442

Epoch: 79| Step: 0
Training loss: 2.615943362459926
Validation loss: 2.5223101370100975

Epoch: 5| Step: 1
Training loss: 2.6556709107102168
Validation loss: 2.519758619354854

Epoch: 5| Step: 2
Training loss: 2.5987021728342135
Validation loss: 2.5190786147326807

Epoch: 5| Step: 3
Training loss: 3.0858270166634454
Validation loss: 2.5189680115570603

Epoch: 5| Step: 4
Training loss: 2.5480035259156555
Validation loss: 2.5197781779409323

Epoch: 5| Step: 5
Training loss: 2.1879934571776816
Validation loss: 2.520175632608272

Epoch: 5| Step: 6
Training loss: 2.705128891671641
Validation loss: 2.5138484336578895

Epoch: 5| Step: 7
Training loss: 2.5984867460592906
Validation loss: 2.5194589964292056

Epoch: 5| Step: 8
Training loss: 2.6911527074085346
Validation loss: 2.520113622895507

Epoch: 5| Step: 9
Training loss: 2.644427929977155
Validation loss: 2.520025960767074

Epoch: 5| Step: 10
Training loss: 2.787516531446215
Validation loss: 2.514026975410362

Epoch: 5| Step: 11
Training loss: 2.455393137482209
Validation loss: 2.514609884318388

Epoch: 80| Step: 0
Training loss: 2.926856216543084
Validation loss: 2.5127944145916516

Epoch: 5| Step: 1
Training loss: 2.6788882295275536
Validation loss: 2.5117518619077237

Epoch: 5| Step: 2
Training loss: 2.438303692685986
Validation loss: 2.5141600653709544

Epoch: 5| Step: 3
Training loss: 2.7417182194772365
Validation loss: 2.511600873286229

Epoch: 5| Step: 4
Training loss: 2.7318435722294026
Validation loss: 2.509010872366144

Epoch: 5| Step: 5
Training loss: 2.7163720967798324
Validation loss: 2.5113335487590778

Epoch: 5| Step: 6
Training loss: 2.475149527762704
Validation loss: 2.512900055402568

Epoch: 5| Step: 7
Training loss: 2.366366102269102
Validation loss: 2.5134931795734565

Epoch: 5| Step: 8
Training loss: 2.3453925925346604
Validation loss: 2.5116627807076646

Epoch: 5| Step: 9
Training loss: 2.5473001511399396
Validation loss: 2.5094656165053277

Epoch: 5| Step: 10
Training loss: 2.8972478106124497
Validation loss: 2.5113389087405324

Epoch: 5| Step: 11
Training loss: 3.121857245378536
Validation loss: 2.510546326091891

Epoch: 81| Step: 0
Training loss: 2.85090592023659
Validation loss: 2.5106868136875233

Epoch: 5| Step: 1
Training loss: 2.8074319741898233
Validation loss: 2.5115442170866835

Epoch: 5| Step: 2
Training loss: 2.306146502563135
Validation loss: 2.512904506751547

Epoch: 5| Step: 3
Training loss: 2.416554766289513
Validation loss: 2.5136271297144757

Epoch: 5| Step: 4
Training loss: 2.7597149130879037
Validation loss: 2.516931230226203

Epoch: 5| Step: 5
Training loss: 2.435042291544212
Validation loss: 2.518202024443089

Epoch: 5| Step: 6
Training loss: 2.9530962584373506
Validation loss: 2.5150187810382385

Epoch: 5| Step: 7
Training loss: 2.6318217147980723
Validation loss: 2.512283364567551

Epoch: 5| Step: 8
Training loss: 2.6790989710520017
Validation loss: 2.5137011238062246

Epoch: 5| Step: 9
Training loss: 2.278673676820213
Validation loss: 2.509032098469793

Epoch: 5| Step: 10
Training loss: 2.753276173904249
Validation loss: 2.5109614827075584

Epoch: 5| Step: 11
Training loss: 3.227788881453126
Validation loss: 2.511694596067168

Epoch: 82| Step: 0
Training loss: 2.6929014174828247
Validation loss: 2.5092530871365306

Epoch: 5| Step: 1
Training loss: 2.9909445469344487
Validation loss: 2.510288830162796

Epoch: 5| Step: 2
Training loss: 2.7182479043989507
Validation loss: 2.5140949082009545

Epoch: 5| Step: 3
Training loss: 2.5246325046023386
Validation loss: 2.508360768138571

Epoch: 5| Step: 4
Training loss: 2.8787240497381847
Validation loss: 2.5177964973296256

Epoch: 5| Step: 5
Training loss: 2.324287375070131
Validation loss: 2.5169251243450805

Epoch: 5| Step: 6
Training loss: 2.8934836609047667
Validation loss: 2.515928901654828

Epoch: 5| Step: 7
Training loss: 2.285555395496103
Validation loss: 2.5093816995432325

Epoch: 5| Step: 8
Training loss: 2.6783525795315306
Validation loss: 2.505903981486467

Epoch: 5| Step: 9
Training loss: 2.5827305203239446
Validation loss: 2.5007347815265155

Epoch: 5| Step: 10
Training loss: 2.608224398092162
Validation loss: 2.5062478909757115

Epoch: 5| Step: 11
Training loss: 1.575071421018102
Validation loss: 2.5015852074721296

Epoch: 83| Step: 0
Training loss: 2.294928627815863
Validation loss: 2.5044872940841896

Epoch: 5| Step: 1
Training loss: 2.476220718048904
Validation loss: 2.504744537681347

Epoch: 5| Step: 2
Training loss: 2.801413577749607
Validation loss: 2.500491334396452

Epoch: 5| Step: 3
Training loss: 3.0395963930438166
Validation loss: 2.502346519097892

Epoch: 5| Step: 4
Training loss: 2.6193592682905096
Validation loss: 2.502402764246874

Epoch: 5| Step: 5
Training loss: 2.4896217460275882
Validation loss: 2.5024544151402215

Epoch: 5| Step: 6
Training loss: 2.7349226920797656
Validation loss: 2.5020599937991475

Epoch: 5| Step: 7
Training loss: 2.7027404158770474
Validation loss: 2.501582260895672

Epoch: 5| Step: 8
Training loss: 2.485324510228509
Validation loss: 2.500415787294353

Epoch: 5| Step: 9
Training loss: 2.7681408662011866
Validation loss: 2.5008427232716235

Epoch: 5| Step: 10
Training loss: 2.504362591416892
Validation loss: 2.4980176815089803

Epoch: 5| Step: 11
Training loss: 2.335436304731832
Validation loss: 2.497352422045891

Epoch: 84| Step: 0
Training loss: 2.263723483085674
Validation loss: 2.4985459509924435

Epoch: 5| Step: 1
Training loss: 2.5952023955339976
Validation loss: 2.4959319952270484

Epoch: 5| Step: 2
Training loss: 2.2715638295231546
Validation loss: 2.5025295216003287

Epoch: 5| Step: 3
Training loss: 2.6536972345397203
Validation loss: 2.506518892876631

Epoch: 5| Step: 4
Training loss: 3.2809020811640393
Validation loss: 2.5023459355200557

Epoch: 5| Step: 5
Training loss: 2.660786244634512
Validation loss: 2.499238911649057

Epoch: 5| Step: 6
Training loss: 2.096937002979372
Validation loss: 2.5018459617739564

Epoch: 5| Step: 7
Training loss: 2.7336420439242413
Validation loss: 2.4961593133776017

Epoch: 5| Step: 8
Training loss: 2.7118963035631167
Validation loss: 2.4931263007454434

Epoch: 5| Step: 9
Training loss: 2.6985836800109126
Validation loss: 2.495798371080206

Epoch: 5| Step: 10
Training loss: 2.8080284175739014
Validation loss: 2.491184846090184

Epoch: 5| Step: 11
Training loss: 2.4780296047557417
Validation loss: 2.491471282343087

Epoch: 85| Step: 0
Training loss: 2.5946912781050306
Validation loss: 2.4959794019795214

Epoch: 5| Step: 1
Training loss: 2.873906300705006
Validation loss: 2.4972378770653205

Epoch: 5| Step: 2
Training loss: 2.6942941704582544
Validation loss: 2.4959123811213653

Epoch: 5| Step: 3
Training loss: 2.4557420899478246
Validation loss: 2.497270751355938

Epoch: 5| Step: 4
Training loss: 2.5191316982731626
Validation loss: 2.498816015100785

Epoch: 5| Step: 5
Training loss: 2.4760144707375518
Validation loss: 2.494693803294646

Epoch: 5| Step: 6
Training loss: 2.572184799650812
Validation loss: 2.498881451398172

Epoch: 5| Step: 7
Training loss: 2.512720931478899
Validation loss: 2.4974389587964256

Epoch: 5| Step: 8
Training loss: 2.7791504382375045
Validation loss: 2.493106441427135

Epoch: 5| Step: 9
Training loss: 2.629667945467254
Validation loss: 2.495477316709535

Epoch: 5| Step: 10
Training loss: 2.7518143304136315
Validation loss: 2.493534692633471

Epoch: 5| Step: 11
Training loss: 2.2284385941989147
Validation loss: 2.4940147358174265

Epoch: 86| Step: 0
Training loss: 2.507643078936939
Validation loss: 2.496253321426874

Epoch: 5| Step: 1
Training loss: 2.459532903039773
Validation loss: 2.49721047221036

Epoch: 5| Step: 2
Training loss: 2.593874549173372
Validation loss: 2.4961394582910383

Epoch: 5| Step: 3
Training loss: 2.360446913801184
Validation loss: 2.4898355800469485

Epoch: 5| Step: 4
Training loss: 2.262076183267272
Validation loss: 2.492315422609635

Epoch: 5| Step: 5
Training loss: 2.5645463727513182
Validation loss: 2.492455933403557

Epoch: 5| Step: 6
Training loss: 3.0776270739600777
Validation loss: 2.491353946909131

Epoch: 5| Step: 7
Training loss: 2.840012494180624
Validation loss: 2.4953508062414222

Epoch: 5| Step: 8
Training loss: 2.591108516763065
Validation loss: 2.4913328812104285

Epoch: 5| Step: 9
Training loss: 2.788760470751534
Validation loss: 2.4903031084136726

Epoch: 5| Step: 10
Training loss: 2.6638156631088283
Validation loss: 2.4964801168925246

Epoch: 5| Step: 11
Training loss: 2.171588576936075
Validation loss: 2.495705452467778

Epoch: 87| Step: 0
Training loss: 2.3650332679586192
Validation loss: 2.5012040298573934

Epoch: 5| Step: 1
Training loss: 2.844419128169542
Validation loss: 2.502379159540866

Epoch: 5| Step: 2
Training loss: 2.149613381156259
Validation loss: 2.502766397849953

Epoch: 5| Step: 3
Training loss: 2.3132746661916084
Validation loss: 2.5013941652398946

Epoch: 5| Step: 4
Training loss: 3.0058328826906777
Validation loss: 2.498896494348478

Epoch: 5| Step: 5
Training loss: 2.91458951464514
Validation loss: 2.4960479732130536

Epoch: 5| Step: 6
Training loss: 2.8759190292950745
Validation loss: 2.4897541615336167

Epoch: 5| Step: 7
Training loss: 2.5201895866528257
Validation loss: 2.4978639338327646

Epoch: 5| Step: 8
Training loss: 2.1446644336916885
Validation loss: 2.4952253284646875

Epoch: 5| Step: 9
Training loss: 2.8485245080864137
Validation loss: 2.4993659407500846

Epoch: 5| Step: 10
Training loss: 2.784469798108715
Validation loss: 2.4993152713848827

Epoch: 5| Step: 11
Training loss: 2.224160916990488
Validation loss: 2.498548229213894

Epoch: 88| Step: 0
Training loss: 2.382665010484071
Validation loss: 2.4976494268889544

Epoch: 5| Step: 1
Training loss: 2.494977674671045
Validation loss: 2.4985581293143952

Epoch: 5| Step: 2
Training loss: 3.0290746060059335
Validation loss: 2.498717376384064

Epoch: 5| Step: 3
Training loss: 2.2682697512955405
Validation loss: 2.4966515747069575

Epoch: 5| Step: 4
Training loss: 2.7428562837695867
Validation loss: 2.4925397665817357

Epoch: 5| Step: 5
Training loss: 2.450367927172494
Validation loss: 2.4923112334305193

Epoch: 5| Step: 6
Training loss: 3.124288096401157
Validation loss: 2.4909219747447238

Epoch: 5| Step: 7
Training loss: 2.7572112468140895
Validation loss: 2.4909421306454282

Epoch: 5| Step: 8
Training loss: 2.506156017795913
Validation loss: 2.491750967923779

Epoch: 5| Step: 9
Training loss: 2.5605294629282596
Validation loss: 2.4903016643533364

Epoch: 5| Step: 10
Training loss: 2.2266844598931037
Validation loss: 2.4881118245635583

Epoch: 5| Step: 11
Training loss: 2.8479968208766726
Validation loss: 2.486707200496825

Epoch: 89| Step: 0
Training loss: 2.531587554653206
Validation loss: 2.495698339338576

Epoch: 5| Step: 1
Training loss: 2.3695573180865472
Validation loss: 2.49473523664797

Epoch: 5| Step: 2
Training loss: 3.0262052105532096
Validation loss: 2.5059844075281332

Epoch: 5| Step: 3
Training loss: 3.0509834955169772
Validation loss: 2.510493215340915

Epoch: 5| Step: 4
Training loss: 2.9083142896609866
Validation loss: 2.5130910471593007

Epoch: 5| Step: 5
Training loss: 2.269867076090875
Validation loss: 2.5071001595956424

Epoch: 5| Step: 6
Training loss: 2.844285683953164
Validation loss: 2.50784638838485

Epoch: 5| Step: 7
Training loss: 2.47696834090895
Validation loss: 2.4877354948114

Epoch: 5| Step: 8
Training loss: 2.4557712156242832
Validation loss: 2.4894890960244638

Epoch: 5| Step: 9
Training loss: 2.49148788916492
Validation loss: 2.492248797484988

Epoch: 5| Step: 10
Training loss: 2.4006259141764827
Validation loss: 2.4920526386312356

Epoch: 5| Step: 11
Training loss: 2.1165209632446365
Validation loss: 2.490000631295294

Epoch: 90| Step: 0
Training loss: 2.6291328774612004
Validation loss: 2.4916747870254454

Epoch: 5| Step: 1
Training loss: 2.3265143846156917
Validation loss: 2.493427374771774

Epoch: 5| Step: 2
Training loss: 2.4440616418709937
Validation loss: 2.4947473340220134

Epoch: 5| Step: 3
Training loss: 2.7609155935768768
Validation loss: 2.493085645554877

Epoch: 5| Step: 4
Training loss: 2.8566678265361887
Validation loss: 2.4948229552173813

Epoch: 5| Step: 5
Training loss: 2.652602170509912
Validation loss: 2.4949654947989717

Epoch: 5| Step: 6
Training loss: 2.606348532591112
Validation loss: 2.4908073494152436

Epoch: 5| Step: 7
Training loss: 2.953899947923719
Validation loss: 2.489899195634353

Epoch: 5| Step: 8
Training loss: 2.3193791114402686
Validation loss: 2.4852972218306775

Epoch: 5| Step: 9
Training loss: 2.4159097363050193
Validation loss: 2.4855310281586798

Epoch: 5| Step: 10
Training loss: 2.7416502162667857
Validation loss: 2.484438237599003

Epoch: 5| Step: 11
Training loss: 2.47332417173651
Validation loss: 2.483950680658523

Epoch: 91| Step: 0
Training loss: 2.693668295203127
Validation loss: 2.4832952340188204

Epoch: 5| Step: 1
Training loss: 2.1638269399519943
Validation loss: 2.483405637861907

Epoch: 5| Step: 2
Training loss: 2.8693658105449225
Validation loss: 2.484620236142941

Epoch: 5| Step: 3
Training loss: 2.74836031841712
Validation loss: 2.488210935612232

Epoch: 5| Step: 4
Training loss: 2.7613877417771326
Validation loss: 2.4866424625546584

Epoch: 5| Step: 5
Training loss: 2.5681509651362444
Validation loss: 2.483773812543184

Epoch: 5| Step: 6
Training loss: 2.6806548127117282
Validation loss: 2.4894086239110127

Epoch: 5| Step: 7
Training loss: 2.6723113122030924
Validation loss: 2.4855844444782034

Epoch: 5| Step: 8
Training loss: 2.304820945885023
Validation loss: 2.490998541574142

Epoch: 5| Step: 9
Training loss: 2.4201294545944956
Validation loss: 2.4844390572980655

Epoch: 5| Step: 10
Training loss: 2.5360373918622696
Validation loss: 2.4833126755843016

Epoch: 5| Step: 11
Training loss: 2.908153935740824
Validation loss: 2.483691659353218

Epoch: 92| Step: 0
Training loss: 2.4891145230189013
Validation loss: 2.4845076191691224

Epoch: 5| Step: 1
Training loss: 2.207835903165173
Validation loss: 2.485578285573162

Epoch: 5| Step: 2
Training loss: 2.0414553811912657
Validation loss: 2.479909117838237

Epoch: 5| Step: 3
Training loss: 3.033874948236675
Validation loss: 2.489004520077022

Epoch: 5| Step: 4
Training loss: 2.872623124500929
Validation loss: 2.4871308418610876

Epoch: 5| Step: 5
Training loss: 2.713766682985141
Validation loss: 2.4895970385399

Epoch: 5| Step: 6
Training loss: 2.756702664458159
Validation loss: 2.4899872301915584

Epoch: 5| Step: 7
Training loss: 2.628192957885123
Validation loss: 2.4861693150498825

Epoch: 5| Step: 8
Training loss: 1.954379174960282
Validation loss: 2.485218372785714

Epoch: 5| Step: 9
Training loss: 2.583973487375494
Validation loss: 2.486117649484155

Epoch: 5| Step: 10
Training loss: 2.7999058503262066
Validation loss: 2.483057436455553

Epoch: 5| Step: 11
Training loss: 3.811339404945771
Validation loss: 2.483733496224758

Epoch: 93| Step: 0
Training loss: 2.331303826495617
Validation loss: 2.4788552630951965

Epoch: 5| Step: 1
Training loss: 2.0060705799910226
Validation loss: 2.481960250708337

Epoch: 5| Step: 2
Training loss: 2.7580785866122812
Validation loss: 2.480222987217546

Epoch: 5| Step: 3
Training loss: 2.6713604347917563
Validation loss: 2.4723548484498012

Epoch: 5| Step: 4
Training loss: 2.971323764833834
Validation loss: 2.4843679743893365

Epoch: 5| Step: 5
Training loss: 2.446560672141004
Validation loss: 2.4803218447619066

Epoch: 5| Step: 6
Training loss: 2.7314828454808664
Validation loss: 2.4814725111474485

Epoch: 5| Step: 7
Training loss: 2.3391521877506167
Validation loss: 2.478360811793931

Epoch: 5| Step: 8
Training loss: 2.5581397199731484
Validation loss: 2.483834637750244

Epoch: 5| Step: 9
Training loss: 2.6895004633973847
Validation loss: 2.4798342276166765

Epoch: 5| Step: 10
Training loss: 3.0085483195941873
Validation loss: 2.4806282813166716

Epoch: 5| Step: 11
Training loss: 2.112469698897422
Validation loss: 2.483839645124655

Epoch: 94| Step: 0
Training loss: 3.2349026014709343
Validation loss: 2.480443334574416

Epoch: 5| Step: 1
Training loss: 2.4037516120512463
Validation loss: 2.4830925108375386

Epoch: 5| Step: 2
Training loss: 2.4523135258421425
Validation loss: 2.4802982301747325

Epoch: 5| Step: 3
Training loss: 2.29392379809116
Validation loss: 2.4815159707166203

Epoch: 5| Step: 4
Training loss: 2.201584189249254
Validation loss: 2.477636828289792

Epoch: 5| Step: 5
Training loss: 2.5505337324875046
Validation loss: 2.478090508819472

Epoch: 5| Step: 6
Training loss: 2.5002427936912017
Validation loss: 2.4788121776762546

Epoch: 5| Step: 7
Training loss: 3.1698782512979515
Validation loss: 2.4801376041632786

Epoch: 5| Step: 8
Training loss: 2.6472405623709863
Validation loss: 2.481386698681506

Epoch: 5| Step: 9
Training loss: 2.468722862384222
Validation loss: 2.474459825516571

Epoch: 5| Step: 10
Training loss: 2.4348629111173916
Validation loss: 2.476927001395054

Epoch: 5| Step: 11
Training loss: 2.4720285592204063
Validation loss: 2.4756568632681217

Epoch: 95| Step: 0
Training loss: 2.6710030543953622
Validation loss: 2.4770446893572116

Epoch: 5| Step: 1
Training loss: 3.086776735171005
Validation loss: 2.477125707498649

Epoch: 5| Step: 2
Training loss: 2.768037767273902
Validation loss: 2.479979331125248

Epoch: 5| Step: 3
Training loss: 2.5668100535812486
Validation loss: 2.481673513280913

Epoch: 5| Step: 4
Training loss: 2.6510140368227773
Validation loss: 2.4790476575437816

Epoch: 5| Step: 5
Training loss: 2.8098844446064
Validation loss: 2.4818055002700667

Epoch: 5| Step: 6
Training loss: 2.335905553286719
Validation loss: 2.4799372666830712

Epoch: 5| Step: 7
Training loss: 2.445756085901878
Validation loss: 2.4831542168629954

Epoch: 5| Step: 8
Training loss: 2.5638166627070595
Validation loss: 2.48273674313374

Epoch: 5| Step: 9
Training loss: 2.2816646669359084
Validation loss: 2.4787383925075894

Epoch: 5| Step: 10
Training loss: 2.375927392691493
Validation loss: 2.4750520931888307

Epoch: 5| Step: 11
Training loss: 1.8580606768034977
Validation loss: 2.4720763259126985

Epoch: 96| Step: 0
Training loss: 2.616361846501476
Validation loss: 2.4713621243240556

Epoch: 5| Step: 1
Training loss: 2.397744044352479
Validation loss: 2.473229858493027

Epoch: 5| Step: 2
Training loss: 2.5926146262862417
Validation loss: 2.4758914796576694

Epoch: 5| Step: 3
Training loss: 2.421890455627347
Validation loss: 2.478683125332339

Epoch: 5| Step: 4
Training loss: 2.8923582087442816
Validation loss: 2.481096043202396

Epoch: 5| Step: 5
Training loss: 3.0400138091727373
Validation loss: 2.4702153665522317

Epoch: 5| Step: 6
Training loss: 2.6737216568809328
Validation loss: 2.472924497656781

Epoch: 5| Step: 7
Training loss: 2.0568940241121374
Validation loss: 2.47147800924463

Epoch: 5| Step: 8
Training loss: 2.6723737641541376
Validation loss: 2.4751462868283935

Epoch: 5| Step: 9
Training loss: 2.8914485273798003
Validation loss: 2.4742343721819036

Epoch: 5| Step: 10
Training loss: 2.1523467408313497
Validation loss: 2.472341303481525

Epoch: 5| Step: 11
Training loss: 2.2564534779779546
Validation loss: 2.4761465547647865

Epoch: 97| Step: 0
Training loss: 2.461581869384526
Validation loss: 2.476500651793661

Epoch: 5| Step: 1
Training loss: 2.739684437867215
Validation loss: 2.4733910254817215

Epoch: 5| Step: 2
Training loss: 2.577190900411591
Validation loss: 2.473911647690755

Epoch: 5| Step: 3
Training loss: 2.6907194504237473
Validation loss: 2.4765463145596587

Epoch: 5| Step: 4
Training loss: 2.5307624253116177
Validation loss: 2.4786778991339373

Epoch: 5| Step: 5
Training loss: 2.3834177718065668
Validation loss: 2.4750855872579365

Epoch: 5| Step: 6
Training loss: 2.4994519586679327
Validation loss: 2.4764312765532996

Epoch: 5| Step: 7
Training loss: 2.847850149327113
Validation loss: 2.469638105391891

Epoch: 5| Step: 8
Training loss: 2.418483106294296
Validation loss: 2.4746259424326915

Epoch: 5| Step: 9
Training loss: 2.2649960401218316
Validation loss: 2.4755747577281872

Epoch: 5| Step: 10
Training loss: 2.9084733231599706
Validation loss: 2.4726594580398005

Epoch: 5| Step: 11
Training loss: 2.5695055590627156
Validation loss: 2.4743693254634924

Epoch: 98| Step: 0
Training loss: 2.3745841615935035
Validation loss: 2.4699206534278138

Epoch: 5| Step: 1
Training loss: 2.2441932134218527
Validation loss: 2.473883994474661

Epoch: 5| Step: 2
Training loss: 2.444561827856355
Validation loss: 2.4692539352635903

Epoch: 5| Step: 3
Training loss: 2.6820751707734978
Validation loss: 2.470476347676942

Epoch: 5| Step: 4
Training loss: 2.7184698903274063
Validation loss: 2.471166116509321

Epoch: 5| Step: 5
Training loss: 2.6331713513962987
Validation loss: 2.4692634740651545

Epoch: 5| Step: 6
Training loss: 2.9282480187563666
Validation loss: 2.4675221226520816

Epoch: 5| Step: 7
Training loss: 2.5325071250762576
Validation loss: 2.461937244129102

Epoch: 5| Step: 8
Training loss: 2.778569762390175
Validation loss: 2.4658391507376525

Epoch: 5| Step: 9
Training loss: 2.3505273105614646
Validation loss: 2.4660917529279507

Epoch: 5| Step: 10
Training loss: 2.503798841056248
Validation loss: 2.466943486302543

Epoch: 5| Step: 11
Training loss: 3.059309874358698
Validation loss: 2.471337722680736

Epoch: 99| Step: 0
Training loss: 2.4659026904556445
Validation loss: 2.4801464602333403

Epoch: 5| Step: 1
Training loss: 2.434345453790631
Validation loss: 2.477050697030386

Epoch: 5| Step: 2
Training loss: 2.93371679299427
Validation loss: 2.4832263266360766

Epoch: 5| Step: 3
Training loss: 2.5519193531734734
Validation loss: 2.48103722493584

Epoch: 5| Step: 4
Training loss: 2.1680030613838905
Validation loss: 2.487588076254255

Epoch: 5| Step: 5
Training loss: 2.8226852791373314
Validation loss: 2.4840750003317336

Epoch: 5| Step: 6
Training loss: 2.6320536167805675
Validation loss: 2.490794375414767

Epoch: 5| Step: 7
Training loss: 2.487254459396661
Validation loss: 2.481609204457313

Epoch: 5| Step: 8
Training loss: 2.5225535636787613
Validation loss: 2.4830381847420315

Epoch: 5| Step: 9
Training loss: 2.616657442534239
Validation loss: 2.482266052782009

Epoch: 5| Step: 10
Training loss: 2.858537728552247
Validation loss: 2.483098139815636

Epoch: 5| Step: 11
Training loss: 2.412719649361441
Validation loss: 2.4824483186247286

Epoch: 100| Step: 0
Training loss: 2.7816566427182408
Validation loss: 2.4776740603117458

Epoch: 5| Step: 1
Training loss: 2.548030474146684
Validation loss: 2.478854317315972

Epoch: 5| Step: 2
Training loss: 2.738730487623397
Validation loss: 2.4798235757560882

Epoch: 5| Step: 3
Training loss: 2.5869126800498856
Validation loss: 2.4774534425938426

Epoch: 5| Step: 4
Training loss: 2.7112439776609163
Validation loss: 2.476954893360109

Epoch: 5| Step: 5
Training loss: 2.776073481870681
Validation loss: 2.4821695739285774

Epoch: 5| Step: 6
Training loss: 2.1034772014030745
Validation loss: 2.479158190437594

Epoch: 5| Step: 7
Training loss: 2.5730836533529375
Validation loss: 2.4751015454470764

Epoch: 5| Step: 8
Training loss: 2.1900230026778944
Validation loss: 2.474976490050377

Epoch: 5| Step: 9
Training loss: 2.608105744821685
Validation loss: 2.4719587590767538

Epoch: 5| Step: 10
Training loss: 2.7795941856636373
Validation loss: 2.474586171576093

Epoch: 5| Step: 11
Training loss: 2.147782215408308
Validation loss: 2.4653440593411706

Epoch: 101| Step: 0
Training loss: 2.581091266766902
Validation loss: 2.4690929247100897

Epoch: 5| Step: 1
Training loss: 2.5636529887205732
Validation loss: 2.4720426685039074

Epoch: 5| Step: 2
Training loss: 3.0197864340747467
Validation loss: 2.4701626795956257

Epoch: 5| Step: 3
Training loss: 2.2494399115377357
Validation loss: 2.4682158403317915

Epoch: 5| Step: 4
Training loss: 2.0700220444099773
Validation loss: 2.4731159315247466

Epoch: 5| Step: 5
Training loss: 2.2916197569698746
Validation loss: 2.472721964769916

Epoch: 5| Step: 6
Training loss: 2.691549931249589
Validation loss: 2.4679722023449004

Epoch: 5| Step: 7
Training loss: 2.5596456680353894
Validation loss: 2.467131695912512

Epoch: 5| Step: 8
Training loss: 2.479106763441917
Validation loss: 2.4673643287584985

Epoch: 5| Step: 9
Training loss: 2.529633653525946
Validation loss: 2.465610270099614

Epoch: 5| Step: 10
Training loss: 3.24396673812465
Validation loss: 2.471423021864048

Epoch: 5| Step: 11
Training loss: 0.7617499711900837
Validation loss: 2.4667453876275816

Epoch: 102| Step: 0
Training loss: 2.7612348291715128
Validation loss: 2.4690075993442195

Epoch: 5| Step: 1
Training loss: 2.348224387077225
Validation loss: 2.4703618352935224

Epoch: 5| Step: 2
Training loss: 2.675638860547655
Validation loss: 2.473722251201872

Epoch: 5| Step: 3
Training loss: 2.512628986596686
Validation loss: 2.473035782246006

Epoch: 5| Step: 4
Training loss: 2.4914384152622913
Validation loss: 2.4694584421529444

Epoch: 5| Step: 5
Training loss: 2.6818127448404505
Validation loss: 2.4740140661018617

Epoch: 5| Step: 6
Training loss: 2.725455335319322
Validation loss: 2.4700779864062867

Epoch: 5| Step: 7
Training loss: 2.3708389371549843
Validation loss: 2.479117089798971

Epoch: 5| Step: 8
Training loss: 2.6259451481595306
Validation loss: 2.474146722681289

Epoch: 5| Step: 9
Training loss: 2.546594335151303
Validation loss: 2.4779483896590415

Epoch: 5| Step: 10
Training loss: 2.372419360672621
Validation loss: 2.473058289219512

Epoch: 5| Step: 11
Training loss: 3.3876332387023447
Validation loss: 2.4732061641403034

Epoch: 103| Step: 0
Training loss: 3.1240335114326476
Validation loss: 2.4720499139975773

Epoch: 5| Step: 1
Training loss: 2.5265152529873793
Validation loss: 2.469708103861623

Epoch: 5| Step: 2
Training loss: 2.4549430379066752
Validation loss: 2.475190060154263

Epoch: 5| Step: 3
Training loss: 2.8101840338395334
Validation loss: 2.4769784876839354

Epoch: 5| Step: 4
Training loss: 2.5251650727956267
Validation loss: 2.4720844453348034

Epoch: 5| Step: 5
Training loss: 2.147452499699203
Validation loss: 2.467014084709411

Epoch: 5| Step: 6
Training loss: 2.7843156699079263
Validation loss: 2.4760320518562677

Epoch: 5| Step: 7
Training loss: 2.11190632711377
Validation loss: 2.4680848130880957

Epoch: 5| Step: 8
Training loss: 2.7687048708163404
Validation loss: 2.4630009351445397

Epoch: 5| Step: 9
Training loss: 2.5416690534570043
Validation loss: 2.470354834171115

Epoch: 5| Step: 10
Training loss: 2.28790264233948
Validation loss: 2.4675450019893974

Epoch: 5| Step: 11
Training loss: 2.785049415026711
Validation loss: 2.4673865512809607

Epoch: 104| Step: 0
Training loss: 2.832745734225963
Validation loss: 2.4681877067278424

Epoch: 5| Step: 1
Training loss: 3.033615447818279
Validation loss: 2.463096245035864

Epoch: 5| Step: 2
Training loss: 2.1376492498392095
Validation loss: 2.467698968011023

Epoch: 5| Step: 3
Training loss: 2.5123034044470214
Validation loss: 2.4702153424229003

Epoch: 5| Step: 4
Training loss: 2.445655579311193
Validation loss: 2.4685283171035524

Epoch: 5| Step: 5
Training loss: 2.7070335399183136
Validation loss: 2.4655879731454107

Epoch: 5| Step: 6
Training loss: 2.2745164755616343
Validation loss: 2.464247573517231

Epoch: 5| Step: 7
Training loss: 2.072695185140683
Validation loss: 2.4626700181247223

Epoch: 5| Step: 8
Training loss: 2.286085673371331
Validation loss: 2.471248207728383

Epoch: 5| Step: 9
Training loss: 2.828894916080841
Validation loss: 2.4698389565005487

Epoch: 5| Step: 10
Training loss: 2.8617013941682954
Validation loss: 2.455819994290796

Epoch: 5| Step: 11
Training loss: 2.668871881708015
Validation loss: 2.4675424052778157

Epoch: 105| Step: 0
Training loss: 2.007770819917881
Validation loss: 2.46194070218805

Epoch: 5| Step: 1
Training loss: 2.9054692357866294
Validation loss: 2.4647321277781304

Epoch: 5| Step: 2
Training loss: 2.3186876149795115
Validation loss: 2.4664836492387656

Epoch: 5| Step: 3
Training loss: 2.436815703757338
Validation loss: 2.4674640638213963

Epoch: 5| Step: 4
Training loss: 2.5005963567891967
Validation loss: 2.4689596505618

Epoch: 5| Step: 5
Training loss: 2.2998777730226245
Validation loss: 2.4675888397046974

Epoch: 5| Step: 6
Training loss: 2.831153386301268
Validation loss: 2.466444629156711

Epoch: 5| Step: 7
Training loss: 2.675723332801568
Validation loss: 2.4665861102645237

Epoch: 5| Step: 8
Training loss: 2.1516360246095205
Validation loss: 2.4649128004942438

Epoch: 5| Step: 9
Training loss: 3.2645707322303283
Validation loss: 2.4730468128176017

Epoch: 5| Step: 10
Training loss: 2.6404539876785136
Validation loss: 2.4636063207700514

Epoch: 5| Step: 11
Training loss: 2.157467816091801
Validation loss: 2.4662646285504715

Epoch: 106| Step: 0
Training loss: 2.575471379364899
Validation loss: 2.4585647770399106

Epoch: 5| Step: 1
Training loss: 2.4413153303382944
Validation loss: 2.4598532089383984

Epoch: 5| Step: 2
Training loss: 2.648400320506685
Validation loss: 2.4569755551930035

Epoch: 5| Step: 3
Training loss: 2.2077013466966164
Validation loss: 2.4603481253030415

Epoch: 5| Step: 4
Training loss: 2.6895048957889363
Validation loss: 2.456483809268631

Epoch: 5| Step: 5
Training loss: 2.33248615780042
Validation loss: 2.455870430457649

Epoch: 5| Step: 6
Training loss: 2.7786010814853825
Validation loss: 2.4569613533206103

Epoch: 5| Step: 7
Training loss: 2.4912790777382345
Validation loss: 2.4557645612467045

Epoch: 5| Step: 8
Training loss: 3.0987873104999206
Validation loss: 2.4606880445044785

Epoch: 5| Step: 9
Training loss: 2.404603072500594
Validation loss: 2.4492712953194706

Epoch: 5| Step: 10
Training loss: 2.3304095228433424
Validation loss: 2.4587186670302805

Epoch: 5| Step: 11
Training loss: 2.7195492150716856
Validation loss: 2.4506517970526827

Epoch: 107| Step: 0
Training loss: 2.626295405870963
Validation loss: 2.4543832682266378

Epoch: 5| Step: 1
Training loss: 2.572234203520358
Validation loss: 2.4562683336125377

Epoch: 5| Step: 2
Training loss: 2.3329422032554663
Validation loss: 2.4580639608075683

Epoch: 5| Step: 3
Training loss: 2.7143404048056317
Validation loss: 2.4531639930234004

Epoch: 5| Step: 4
Training loss: 2.8271523167611554
Validation loss: 2.4533014659219945

Epoch: 5| Step: 5
Training loss: 2.322046421957123
Validation loss: 2.4560278949830883

Epoch: 5| Step: 6
Training loss: 2.502551683926847
Validation loss: 2.4557819111332

Epoch: 5| Step: 7
Training loss: 2.7313440581652664
Validation loss: 2.4578368054590887

Epoch: 5| Step: 8
Training loss: 2.9494153494074573
Validation loss: 2.4601423644143106

Epoch: 5| Step: 9
Training loss: 2.6825743492324974
Validation loss: 2.4491419356781488

Epoch: 5| Step: 10
Training loss: 1.8276566777730634
Validation loss: 2.4549030898079693

Epoch: 5| Step: 11
Training loss: 1.4227563830125072
Validation loss: 2.4579303473116494

Epoch: 108| Step: 0
Training loss: 2.514918542077439
Validation loss: 2.4616970060892016

Epoch: 5| Step: 1
Training loss: 2.2988026114371145
Validation loss: 2.454345551341557

Epoch: 5| Step: 2
Training loss: 2.460709043525302
Validation loss: 2.4593514836765182

Epoch: 5| Step: 3
Training loss: 2.5747130965608673
Validation loss: 2.4604193490121697

Epoch: 5| Step: 4
Training loss: 2.399559131501812
Validation loss: 2.4592247305900607

Epoch: 5| Step: 5
Training loss: 1.979038542230985
Validation loss: 2.462342316440917

Epoch: 5| Step: 6
Training loss: 2.6172514494869055
Validation loss: 2.4609020089309994

Epoch: 5| Step: 7
Training loss: 2.6575264051817586
Validation loss: 2.4619045557496517

Epoch: 5| Step: 8
Training loss: 2.4039072298947364
Validation loss: 2.4603609287646635

Epoch: 5| Step: 9
Training loss: 3.1626050064687052
Validation loss: 2.4637959747566667

Epoch: 5| Step: 10
Training loss: 2.9842152178267227
Validation loss: 2.4635610976202242

Epoch: 5| Step: 11
Training loss: 1.9055017972851107
Validation loss: 2.4611746497153177

Epoch: 109| Step: 0
Training loss: 2.6139434294821604
Validation loss: 2.460561503594813

Epoch: 5| Step: 1
Training loss: 2.5119407638745384
Validation loss: 2.456199925844895

Epoch: 5| Step: 2
Training loss: 2.437889948244128
Validation loss: 2.456911796734839

Epoch: 5| Step: 3
Training loss: 3.1063760835475995
Validation loss: 2.454048132880882

Epoch: 5| Step: 4
Training loss: 2.0716210026924293
Validation loss: 2.4524830304166962

Epoch: 5| Step: 5
Training loss: 2.371977036685017
Validation loss: 2.461827838643217

Epoch: 5| Step: 6
Training loss: 2.708457141882903
Validation loss: 2.452271691712154

Epoch: 5| Step: 7
Training loss: 2.484266554666836
Validation loss: 2.453500411187845

Epoch: 5| Step: 8
Training loss: 2.5595267189152975
Validation loss: 2.456897673339303

Epoch: 5| Step: 9
Training loss: 2.8464600780963516
Validation loss: 2.4563495941775257

Epoch: 5| Step: 10
Training loss: 2.079945276164053
Validation loss: 2.454972069876648

Epoch: 5| Step: 11
Training loss: 2.549682099965125
Validation loss: 2.457667100198375

Epoch: 110| Step: 0
Training loss: 2.9261490675944195
Validation loss: 2.455733946832324

Epoch: 5| Step: 1
Training loss: 2.805002348927757
Validation loss: 2.4583717170779145

Epoch: 5| Step: 2
Training loss: 2.399901201280883
Validation loss: 2.4663936056820517

Epoch: 5| Step: 3
Training loss: 2.915439311142169
Validation loss: 2.459310940688202

Epoch: 5| Step: 4
Training loss: 2.381568258649218
Validation loss: 2.4567669603517945

Epoch: 5| Step: 5
Training loss: 2.53967784761003
Validation loss: 2.451030878112715

Epoch: 5| Step: 6
Training loss: 2.1332352327599913
Validation loss: 2.4530303596658154

Epoch: 5| Step: 7
Training loss: 2.946651083730975
Validation loss: 2.4554624335102266

Epoch: 5| Step: 8
Training loss: 2.3403468538448036
Validation loss: 2.4558948624105197

Epoch: 5| Step: 9
Training loss: 2.6603512685490074
Validation loss: 2.4575934866046056

Epoch: 5| Step: 10
Training loss: 1.968386661971014
Validation loss: 2.465219411621717

Epoch: 5| Step: 11
Training loss: 2.904008226346221
Validation loss: 2.4544900752854004

Epoch: 111| Step: 0
Training loss: 2.82575746356971
Validation loss: 2.4587165721029582

Epoch: 5| Step: 1
Training loss: 2.298723579823278
Validation loss: 2.455113760953321

Epoch: 5| Step: 2
Training loss: 2.4484233142512433
Validation loss: 2.452271436500301

Epoch: 5| Step: 3
Training loss: 2.2803859380706357
Validation loss: 2.4594750070172533

Epoch: 5| Step: 4
Training loss: 2.162874963258268
Validation loss: 2.460102662267754

Epoch: 5| Step: 5
Training loss: 2.6371891760614545
Validation loss: 2.4677057029245275

Epoch: 5| Step: 6
Training loss: 2.342327449147177
Validation loss: 2.4667851318659766

Epoch: 5| Step: 7
Training loss: 2.749275632303966
Validation loss: 2.4735968810939517

Epoch: 5| Step: 8
Training loss: 2.855628054828642
Validation loss: 2.474923478976182

Epoch: 5| Step: 9
Training loss: 2.5567801301224677
Validation loss: 2.4751821375466903

Epoch: 5| Step: 10
Training loss: 2.698088788957499
Validation loss: 2.468172774455847

Epoch: 5| Step: 11
Training loss: 3.621305622046303
Validation loss: 2.467280868203434

Epoch: 112| Step: 0
Training loss: 2.5090204579875097
Validation loss: 2.4572546068485286

Epoch: 5| Step: 1
Training loss: 2.1960897461248408
Validation loss: 2.4576025189048845

Epoch: 5| Step: 2
Training loss: 2.450650662027814
Validation loss: 2.451747041575948

Epoch: 5| Step: 3
Training loss: 2.5500206740794127
Validation loss: 2.455971283504546

Epoch: 5| Step: 4
Training loss: 2.2291803329856954
Validation loss: 2.465608505367905

Epoch: 5| Step: 5
Training loss: 2.7035198474548463
Validation loss: 2.4707159029463095

Epoch: 5| Step: 6
Training loss: 3.06042488015676
Validation loss: 2.4796626225365146

Epoch: 5| Step: 7
Training loss: 2.6583748789284263
Validation loss: 2.4758258610521375

Epoch: 5| Step: 8
Training loss: 2.096754395247101
Validation loss: 2.4751043509631545

Epoch: 5| Step: 9
Training loss: 2.6146941649109343
Validation loss: 2.4768039092325687

Epoch: 5| Step: 10
Training loss: 3.072401272931187
Validation loss: 2.471486864188697

Epoch: 5| Step: 11
Training loss: 2.5498585456060296
Validation loss: 2.4642673630620173

Epoch: 113| Step: 0
Training loss: 2.1938860728782257
Validation loss: 2.459236938013753

Epoch: 5| Step: 1
Training loss: 2.8771995754823405
Validation loss: 2.453638549472138

Epoch: 5| Step: 2
Training loss: 2.600283838331207
Validation loss: 2.4561046678679133

Epoch: 5| Step: 3
Training loss: 2.249954011235194
Validation loss: 2.457281317263924

Epoch: 5| Step: 4
Training loss: 2.6093972028141756
Validation loss: 2.458396588874846

Epoch: 5| Step: 5
Training loss: 2.7166342559784553
Validation loss: 2.4563491553756718

Epoch: 5| Step: 6
Training loss: 2.194138725596416
Validation loss: 2.457974388835979

Epoch: 5| Step: 7
Training loss: 2.5355969062209796
Validation loss: 2.4570472890616433

Epoch: 5| Step: 8
Training loss: 3.301259384286377
Validation loss: 2.458522400751573

Epoch: 5| Step: 9
Training loss: 2.4312569311675682
Validation loss: 2.4597220997086655

Epoch: 5| Step: 10
Training loss: 2.3588132884354596
Validation loss: 2.464122217229183

Epoch: 5| Step: 11
Training loss: 2.4422529781689284
Validation loss: 2.460753782166149

Epoch: 114| Step: 0
Training loss: 2.278546651952356
Validation loss: 2.4575871585176623

Epoch: 5| Step: 1
Training loss: 2.272222764632521
Validation loss: 2.454893050075193

Epoch: 5| Step: 2
Training loss: 2.7179877429374213
Validation loss: 2.4541694620588235

Epoch: 5| Step: 3
Training loss: 2.835921358425137
Validation loss: 2.4514668260605914

Epoch: 5| Step: 4
Training loss: 2.26103081395285
Validation loss: 2.451945412051245

Epoch: 5| Step: 5
Training loss: 3.08202274065088
Validation loss: 2.4534789192520283

Epoch: 5| Step: 6
Training loss: 2.1228770703137907
Validation loss: 2.456536999890259

Epoch: 5| Step: 7
Training loss: 2.3644366001753525
Validation loss: 2.4474605696784457

Epoch: 5| Step: 8
Training loss: 1.8911392521373807
Validation loss: 2.4591784290828276

Epoch: 5| Step: 9
Training loss: 3.146643191212301
Validation loss: 2.4533542477344272

Epoch: 5| Step: 10
Training loss: 2.8391137529448596
Validation loss: 2.4545959832776334

Epoch: 5| Step: 11
Training loss: 1.5583472953347715
Validation loss: 2.4583962090312608

Epoch: 115| Step: 0
Training loss: 2.5679868246613964
Validation loss: 2.451652206228708

Epoch: 5| Step: 1
Training loss: 2.8457376429572605
Validation loss: 2.4555975446220457

Epoch: 5| Step: 2
Training loss: 2.6210474501953485
Validation loss: 2.4585115009874405

Epoch: 5| Step: 3
Training loss: 2.77315165161504
Validation loss: 2.455121920287821

Epoch: 5| Step: 4
Training loss: 2.1096514485369293
Validation loss: 2.4564973001336505

Epoch: 5| Step: 5
Training loss: 2.60922149389415
Validation loss: 2.4532081201163005

Epoch: 5| Step: 6
Training loss: 2.3422132413033654
Validation loss: 2.449263996637186

Epoch: 5| Step: 7
Training loss: 3.0754854144781714
Validation loss: 2.4558817970090048

Epoch: 5| Step: 8
Training loss: 1.9867469248572063
Validation loss: 2.450416689749877

Epoch: 5| Step: 9
Training loss: 2.210008513662933
Validation loss: 2.454863367674667

Epoch: 5| Step: 10
Training loss: 2.629212133515225
Validation loss: 2.4547815561031037

Epoch: 5| Step: 11
Training loss: 2.2770206490486307
Validation loss: 2.4531754085601762

Epoch: 116| Step: 0
Training loss: 2.6376247177648144
Validation loss: 2.4541946112159536

Epoch: 5| Step: 1
Training loss: 3.2189902799233816
Validation loss: 2.444936550762896

Epoch: 5| Step: 2
Training loss: 2.212616515459112
Validation loss: 2.448254751977886

Epoch: 5| Step: 3
Training loss: 2.4669998339160855
Validation loss: 2.4517023249686125

Epoch: 5| Step: 4
Training loss: 2.39247129863556
Validation loss: 2.448232116394469

Epoch: 5| Step: 5
Training loss: 2.4027369231742504
Validation loss: 2.4536432945731192

Epoch: 5| Step: 6
Training loss: 2.5205422435656817
Validation loss: 2.4534463003853713

Epoch: 5| Step: 7
Training loss: 2.399206976207984
Validation loss: 2.4537010002587847

Epoch: 5| Step: 8
Training loss: 2.539249824069476
Validation loss: 2.4523103944847975

Epoch: 5| Step: 9
Training loss: 2.485910097327216
Validation loss: 2.454413826634285

Epoch: 5| Step: 10
Training loss: 2.4000863735233184
Validation loss: 2.4602560482415314

Epoch: 5| Step: 11
Training loss: 2.9354880727435644
Validation loss: 2.4525751319690148

Epoch: 117| Step: 0
Training loss: 2.822628686909172
Validation loss: 2.456485962716533

Epoch: 5| Step: 1
Training loss: 2.26546725019914
Validation loss: 2.4461292003953106

Epoch: 5| Step: 2
Training loss: 2.891271240578559
Validation loss: 2.4512167026022613

Epoch: 5| Step: 3
Training loss: 2.914835400391753
Validation loss: 2.456045113577109

Epoch: 5| Step: 4
Training loss: 2.5182054446870716
Validation loss: 2.4556077938621086

Epoch: 5| Step: 5
Training loss: 2.2064550677301056
Validation loss: 2.4556761999206262

Epoch: 5| Step: 6
Training loss: 2.454593097661087
Validation loss: 2.4545117404952506

Epoch: 5| Step: 7
Training loss: 2.4206990986658665
Validation loss: 2.448618116048409

Epoch: 5| Step: 8
Training loss: 2.6516291199173208
Validation loss: 2.4542581650193127

Epoch: 5| Step: 9
Training loss: 2.3110012662084354
Validation loss: 2.4565249125004662

Epoch: 5| Step: 10
Training loss: 2.292003942003572
Validation loss: 2.4529498416382385

Epoch: 5| Step: 11
Training loss: 3.1291916773000166
Validation loss: 2.458226158478306

Epoch: 118| Step: 0
Training loss: 2.851738075181253
Validation loss: 2.4528407156890357

Epoch: 5| Step: 1
Training loss: 2.3608860457119487
Validation loss: 2.462109531872838

Epoch: 5| Step: 2
Training loss: 3.0280997040029596
Validation loss: 2.4524466797712696

Epoch: 5| Step: 3
Training loss: 2.1604270834259354
Validation loss: 2.4610811544804867

Epoch: 5| Step: 4
Training loss: 2.111733255678768
Validation loss: 2.4649701133938366

Epoch: 5| Step: 5
Training loss: 2.8361738962897034
Validation loss: 2.4648884901690677

Epoch: 5| Step: 6
Training loss: 2.928474032546944
Validation loss: 2.4583540096598804

Epoch: 5| Step: 7
Training loss: 2.328636369292781
Validation loss: 2.455956398303529

Epoch: 5| Step: 8
Training loss: 2.5597253990418105
Validation loss: 2.4637783789004275

Epoch: 5| Step: 9
Training loss: 2.3016347548776803
Validation loss: 2.456637756828

Epoch: 5| Step: 10
Training loss: 2.468706830769965
Validation loss: 2.461660391986377

Epoch: 5| Step: 11
Training loss: 1.4631044361440686
Validation loss: 2.4535014801111625

Epoch: 119| Step: 0
Training loss: 1.8905270133359842
Validation loss: 2.453154723681845

Epoch: 5| Step: 1
Training loss: 2.5188420735608905
Validation loss: 2.449107417527516

Epoch: 5| Step: 2
Training loss: 2.121636814687542
Validation loss: 2.458114074099504

Epoch: 5| Step: 3
Training loss: 2.499670197667471
Validation loss: 2.4536757934097233

Epoch: 5| Step: 4
Training loss: 2.6139988847597366
Validation loss: 2.450786005983692

Epoch: 5| Step: 5
Training loss: 2.281312915509233
Validation loss: 2.4525755532189386

Epoch: 5| Step: 6
Training loss: 2.410608876663736
Validation loss: 2.4521393830843574

Epoch: 5| Step: 7
Training loss: 2.4402585192823683
Validation loss: 2.4546739057831815

Epoch: 5| Step: 8
Training loss: 3.164637986582447
Validation loss: 2.4540923412274736

Epoch: 5| Step: 9
Training loss: 2.830484828329472
Validation loss: 2.4526049028191497

Epoch: 5| Step: 10
Training loss: 2.9925280344836223
Validation loss: 2.44843222823039

Epoch: 5| Step: 11
Training loss: 1.9008244708282604
Validation loss: 2.452046912697159

Epoch: 120| Step: 0
Training loss: 2.3017184513499185
Validation loss: 2.4505028245989147

Epoch: 5| Step: 1
Training loss: 2.8295817127390723
Validation loss: 2.4569583289682146

Epoch: 5| Step: 2
Training loss: 2.8145552013769244
Validation loss: 2.4615870027386806

Epoch: 5| Step: 3
Training loss: 2.3879979478133952
Validation loss: 2.453927530437094

Epoch: 5| Step: 4
Training loss: 2.7287032241062423
Validation loss: 2.4573881075116706

Epoch: 5| Step: 5
Training loss: 2.375101689621154
Validation loss: 2.4537842142210735

Epoch: 5| Step: 6
Training loss: 2.566390828589987
Validation loss: 2.4445996001943

Epoch: 5| Step: 7
Training loss: 2.764816338370094
Validation loss: 2.443962354124785

Epoch: 5| Step: 8
Training loss: 2.409647339149915
Validation loss: 2.4510409255593397

Epoch: 5| Step: 9
Training loss: 2.4960313768309796
Validation loss: 2.448228111475156

Epoch: 5| Step: 10
Training loss: 2.091184040130678
Validation loss: 2.450238992345536

Epoch: 5| Step: 11
Training loss: 2.2324406713994347
Validation loss: 2.4506933345475685

Epoch: 121| Step: 0
Training loss: 1.7154460709449764
Validation loss: 2.4527765257364056

Epoch: 5| Step: 1
Training loss: 2.5858332218223823
Validation loss: 2.4537375468959772

Epoch: 5| Step: 2
Training loss: 2.744054262153017
Validation loss: 2.4501400907518924

Epoch: 5| Step: 3
Training loss: 2.764859885723525
Validation loss: 2.4437377945643126

Epoch: 5| Step: 4
Training loss: 2.8290017807955916
Validation loss: 2.446452162655055

Epoch: 5| Step: 5
Training loss: 2.4305726429172116
Validation loss: 2.453358001334455

Epoch: 5| Step: 6
Training loss: 2.553260334588238
Validation loss: 2.453122618850233

Epoch: 5| Step: 7
Training loss: 2.4869979351726896
Validation loss: 2.44969960409844

Epoch: 5| Step: 8
Training loss: 2.5198696175406172
Validation loss: 2.4551521599652437

Epoch: 5| Step: 9
Training loss: 2.436494375296366
Validation loss: 2.445720309538483

Epoch: 5| Step: 10
Training loss: 2.509439576340639
Validation loss: 2.4488048578932697

Epoch: 5| Step: 11
Training loss: 2.6360393185671533
Validation loss: 2.4460796903654733

Epoch: 122| Step: 0
Training loss: 2.42100893347824
Validation loss: 2.4466176597219915

Epoch: 5| Step: 1
Training loss: 2.2409589106321977
Validation loss: 2.4497261758813678

Epoch: 5| Step: 2
Training loss: 2.4393098421066437
Validation loss: 2.4507620946402886

Epoch: 5| Step: 3
Training loss: 1.926921390911661
Validation loss: 2.4527532980287594

Epoch: 5| Step: 4
Training loss: 2.71345179159409
Validation loss: 2.454429441631341

Epoch: 5| Step: 5
Training loss: 2.8182439007171545
Validation loss: 2.455818281178276

Epoch: 5| Step: 6
Training loss: 2.8478449587571744
Validation loss: 2.453203038069785

Epoch: 5| Step: 7
Training loss: 2.616161179363047
Validation loss: 2.4496428524554927

Epoch: 5| Step: 8
Training loss: 2.716117636856407
Validation loss: 2.4548037994567533

Epoch: 5| Step: 9
Training loss: 2.8923870592809324
Validation loss: 2.4604014665638547

Epoch: 5| Step: 10
Training loss: 2.1652037988465547
Validation loss: 2.45913669557792

Epoch: 5| Step: 11
Training loss: 1.422351799135126
Validation loss: 2.4553435634055876

Epoch: 123| Step: 0
Training loss: 2.3896363651296504
Validation loss: 2.4551906312075866

Epoch: 5| Step: 1
Training loss: 1.882340748042698
Validation loss: 2.4572213386949286

Epoch: 5| Step: 2
Training loss: 2.1707320464869135
Validation loss: 2.4539077991965286

Epoch: 5| Step: 3
Training loss: 2.7250814268212973
Validation loss: 2.4530476600458377

Epoch: 5| Step: 4
Training loss: 2.7141694692945273
Validation loss: 2.4490511531160535

Epoch: 5| Step: 5
Training loss: 2.686387652477722
Validation loss: 2.448016482543412

Epoch: 5| Step: 6
Training loss: 2.817189270459051
Validation loss: 2.451107442751161

Epoch: 5| Step: 7
Training loss: 2.7792097173175025
Validation loss: 2.447049751716003

Epoch: 5| Step: 8
Training loss: 2.77601164514699
Validation loss: 2.4446849728743154

Epoch: 5| Step: 9
Training loss: 2.3076820703426115
Validation loss: 2.4480238498732843

Epoch: 5| Step: 10
Training loss: 2.3882294663894545
Validation loss: 2.443742599541141

Epoch: 5| Step: 11
Training loss: 2.5548035948152754
Validation loss: 2.4492520213972657

Epoch: 124| Step: 0
Training loss: 2.403869442166714
Validation loss: 2.442443151388344

Epoch: 5| Step: 1
Training loss: 2.4327390097394455
Validation loss: 2.4428474587280675

Epoch: 5| Step: 2
Training loss: 2.537721062412651
Validation loss: 2.4444806204332146

Epoch: 5| Step: 3
Training loss: 2.4345526849542343
Validation loss: 2.4441965256185196

Epoch: 5| Step: 4
Training loss: 2.5000785815286606
Validation loss: 2.450916381327312

Epoch: 5| Step: 5
Training loss: 3.005351379974438
Validation loss: 2.4478912873000858

Epoch: 5| Step: 6
Training loss: 2.183658824080665
Validation loss: 2.445394528834155

Epoch: 5| Step: 7
Training loss: 2.762128009174919
Validation loss: 2.45150162503949

Epoch: 5| Step: 8
Training loss: 2.821318639783089
Validation loss: 2.451543832954638

Epoch: 5| Step: 9
Training loss: 2.4146835367795485
Validation loss: 2.4490538181094097

Epoch: 5| Step: 10
Training loss: 2.166778402626269
Validation loss: 2.4459960437138593

Epoch: 5| Step: 11
Training loss: 2.087138883684456
Validation loss: 2.455959209510088

Epoch: 125| Step: 0
Training loss: 2.775150941060054
Validation loss: 2.4514404514486476

Epoch: 5| Step: 1
Training loss: 2.3420621770982177
Validation loss: 2.4509673885650316

Epoch: 5| Step: 2
Training loss: 2.426310163692394
Validation loss: 2.448295666729715

Epoch: 5| Step: 3
Training loss: 2.4665001383405762
Validation loss: 2.445535497277917

Epoch: 5| Step: 4
Training loss: 3.0962116966912228
Validation loss: 2.448159931486489

Epoch: 5| Step: 5
Training loss: 2.2516136740720123
Validation loss: 2.446177799742817

Epoch: 5| Step: 6
Training loss: 2.088753046641933
Validation loss: 2.441740606173589

Epoch: 5| Step: 7
Training loss: 2.5211565320189164
Validation loss: 2.445523822659811

Epoch: 5| Step: 8
Training loss: 1.889436395463428
Validation loss: 2.4542025793121693

Epoch: 5| Step: 9
Training loss: 2.6726869832813955
Validation loss: 2.451196746902625

Epoch: 5| Step: 10
Training loss: 2.8174230932995696
Validation loss: 2.459009050725699

Epoch: 5| Step: 11
Training loss: 3.1832505866142826
Validation loss: 2.454973609579177

Epoch: 126| Step: 0
Training loss: 2.751748829413437
Validation loss: 2.452832439414625

Epoch: 5| Step: 1
Training loss: 2.2327886965893
Validation loss: 2.4673268344664807

Epoch: 5| Step: 2
Training loss: 2.7296769245119714
Validation loss: 2.463090723607951

Epoch: 5| Step: 3
Training loss: 2.5466220472664443
Validation loss: 2.4646963487532942

Epoch: 5| Step: 4
Training loss: 3.154192263164662
Validation loss: 2.4664868814175063

Epoch: 5| Step: 5
Training loss: 2.2689531808043393
Validation loss: 2.4643355468847727

Epoch: 5| Step: 6
Training loss: 2.3185849935629896
Validation loss: 2.4629711810537644

Epoch: 5| Step: 7
Training loss: 1.968733711780804
Validation loss: 2.4610419478276753

Epoch: 5| Step: 8
Training loss: 2.6422508696858658
Validation loss: 2.456213408157956

Epoch: 5| Step: 9
Training loss: 2.512400770362963
Validation loss: 2.4506977124215052

Epoch: 5| Step: 10
Training loss: 2.750607076741223
Validation loss: 2.451653472480003

Epoch: 5| Step: 11
Training loss: 1.976610024826997
Validation loss: 2.4457617195753505

Epoch: 127| Step: 0
Training loss: 2.0244373811518788
Validation loss: 2.453527397310126

Epoch: 5| Step: 1
Training loss: 2.577239560752846
Validation loss: 2.4576160965988088

Epoch: 5| Step: 2
Training loss: 2.1455220363945893
Validation loss: 2.4660333703785

Epoch: 5| Step: 3
Training loss: 2.859760862903254
Validation loss: 2.467520719609976

Epoch: 5| Step: 4
Training loss: 3.2103132768866023
Validation loss: 2.4634281653831023

Epoch: 5| Step: 5
Training loss: 2.266447352102739
Validation loss: 2.466738048022174

Epoch: 5| Step: 6
Training loss: 2.41637588812435
Validation loss: 2.462989032744692

Epoch: 5| Step: 7
Training loss: 2.271589334150727
Validation loss: 2.4649292033799104

Epoch: 5| Step: 8
Training loss: 2.653052885515531
Validation loss: 2.455179386888101

Epoch: 5| Step: 9
Training loss: 2.717377151618259
Validation loss: 2.460420267558444

Epoch: 5| Step: 10
Training loss: 2.528585845099509
Validation loss: 2.4533593294677174

Epoch: 5| Step: 11
Training loss: 2.2399984167297764
Validation loss: 2.4561737092378717

Epoch: 128| Step: 0
Training loss: 2.673367089258994
Validation loss: 2.4553726088462007

Epoch: 5| Step: 1
Training loss: 2.9171306422719625
Validation loss: 2.4540772118696794

Epoch: 5| Step: 2
Training loss: 2.414104078607601
Validation loss: 2.45531652846331

Epoch: 5| Step: 3
Training loss: 2.3780262388958615
Validation loss: 2.4547151202601203

Epoch: 5| Step: 4
Training loss: 2.484707983961891
Validation loss: 2.460936579628424

Epoch: 5| Step: 5
Training loss: 2.3636884858646727
Validation loss: 2.4505171997064994

Epoch: 5| Step: 6
Training loss: 2.537157770389805
Validation loss: 2.4454766158503767

Epoch: 5| Step: 7
Training loss: 2.316107127543397
Validation loss: 2.447519478465505

Epoch: 5| Step: 8
Training loss: 2.496560878354428
Validation loss: 2.4445621367019363

Epoch: 5| Step: 9
Training loss: 2.6509583665592467
Validation loss: 2.4480444543369098

Epoch: 5| Step: 10
Training loss: 2.5269329792610735
Validation loss: 2.458339615722215

Epoch: 5| Step: 11
Training loss: 2.434811699105563
Validation loss: 2.4602300646374506

Epoch: 129| Step: 0
Training loss: 2.493565767218325
Validation loss: 2.466748514755981

Epoch: 5| Step: 1
Training loss: 2.8294381312461674
Validation loss: 2.4645051718598445

Epoch: 5| Step: 2
Training loss: 2.402790307200355
Validation loss: 2.466446679256898

Epoch: 5| Step: 3
Training loss: 2.203134631413178
Validation loss: 2.460676054211311

Epoch: 5| Step: 4
Training loss: 2.331184578558
Validation loss: 2.4630050572092888

Epoch: 5| Step: 5
Training loss: 2.002950756570378
Validation loss: 2.4620761033685437

Epoch: 5| Step: 6
Training loss: 2.5823543190648945
Validation loss: 2.4595509614407636

Epoch: 5| Step: 7
Training loss: 2.961062788514356
Validation loss: 2.4556643793345616

Epoch: 5| Step: 8
Training loss: 2.7802167537633635
Validation loss: 2.454825101735494

Epoch: 5| Step: 9
Training loss: 2.3583265589784124
Validation loss: 2.462032006099335

Epoch: 5| Step: 10
Training loss: 2.777477835250027
Validation loss: 2.447674521515922

Epoch: 5| Step: 11
Training loss: 2.5772778593106755
Validation loss: 2.4479325855359777

Epoch: 130| Step: 0
Training loss: 2.6841883104839934
Validation loss: 2.4506223227186235

Epoch: 5| Step: 1
Training loss: 2.2524552194968543
Validation loss: 2.463834750515969

Epoch: 5| Step: 2
Training loss: 2.680258731736373
Validation loss: 2.4713596502041586

Epoch: 5| Step: 3
Training loss: 2.3507195162566945
Validation loss: 2.474693969308328

Epoch: 5| Step: 4
Training loss: 2.2340012884725406
Validation loss: 2.465467927133471

Epoch: 5| Step: 5
Training loss: 2.6258944849342862
Validation loss: 2.463233333000204

Epoch: 5| Step: 6
Training loss: 2.445774802482937
Validation loss: 2.45013701743449

Epoch: 5| Step: 7
Training loss: 2.4610925050390478
Validation loss: 2.4499152864680034

Epoch: 5| Step: 8
Training loss: 2.5688041736988243
Validation loss: 2.44700955296647

Epoch: 5| Step: 9
Training loss: 3.5212528197060893
Validation loss: 2.450224581143638

Epoch: 5| Step: 10
Training loss: 1.881918413921415
Validation loss: 2.4501548247820444

Epoch: 5| Step: 11
Training loss: 3.276302131200239
Validation loss: 2.4577512388684446

Epoch: 131| Step: 0
Training loss: 2.4981679879565797
Validation loss: 2.459508014460389

Epoch: 5| Step: 1
Training loss: 2.0395038463259803
Validation loss: 2.466069359619166

Epoch: 5| Step: 2
Training loss: 2.635088290738622
Validation loss: 2.4673186732172905

Epoch: 5| Step: 3
Training loss: 2.478012863643038
Validation loss: 2.4741263737411074

Epoch: 5| Step: 4
Training loss: 2.0407013719646914
Validation loss: 2.4657251723665676

Epoch: 5| Step: 5
Training loss: 2.4091287212447
Validation loss: 2.466983807212076

Epoch: 5| Step: 6
Training loss: 2.6943449633434358
Validation loss: 2.4677833684739805

Epoch: 5| Step: 7
Training loss: 3.033561375887565
Validation loss: 2.462538590911452

Epoch: 5| Step: 8
Training loss: 2.823296994047112
Validation loss: 2.465950875933076

Epoch: 5| Step: 9
Training loss: 2.7779524038314407
Validation loss: 2.4618955533558675

Epoch: 5| Step: 10
Training loss: 2.5098044782072857
Validation loss: 2.4602517479437225

Epoch: 5| Step: 11
Training loss: 1.730556924954453
Validation loss: 2.460736899298702

Epoch: 132| Step: 0
Training loss: 2.7647167373892914
Validation loss: 2.4496434161461456

Epoch: 5| Step: 1
Training loss: 2.1674826137105008
Validation loss: 2.453550443587976

Epoch: 5| Step: 2
Training loss: 2.3328602402050556
Validation loss: 2.453576489832214

Epoch: 5| Step: 3
Training loss: 2.2994302043835866
Validation loss: 2.4564278472694427

Epoch: 5| Step: 4
Training loss: 2.429694761406452
Validation loss: 2.4702180991974814

Epoch: 5| Step: 5
Training loss: 2.753754307227937
Validation loss: 2.4786116569157715

Epoch: 5| Step: 6
Training loss: 2.656366054019204
Validation loss: 2.461688553780185

Epoch: 5| Step: 7
Training loss: 2.669506339251959
Validation loss: 2.4611460562036513

Epoch: 5| Step: 8
Training loss: 2.647123748008027
Validation loss: 2.450601754117607

Epoch: 5| Step: 9
Training loss: 2.6478996518416524
Validation loss: 2.45692307153727

Epoch: 5| Step: 10
Training loss: 2.3247980501800782
Validation loss: 2.455064614197329

Epoch: 5| Step: 11
Training loss: 3.4111498666550495
Validation loss: 2.4641591293620464

Epoch: 133| Step: 0
Training loss: 2.64001051394941
Validation loss: 2.4704941652413464

Epoch: 5| Step: 1
Training loss: 2.529865404250401
Validation loss: 2.475776844576472

Epoch: 5| Step: 2
Training loss: 1.9499042047298865
Validation loss: 2.4790367378253273

Epoch: 5| Step: 3
Training loss: 2.475745514611487
Validation loss: 2.482754160613954

Epoch: 5| Step: 4
Training loss: 2.8414651264156365
Validation loss: 2.4846857544343472

Epoch: 5| Step: 5
Training loss: 1.859932054693771
Validation loss: 2.4834364351742555

Epoch: 5| Step: 6
Training loss: 2.497913157185138
Validation loss: 2.4871993814539186

Epoch: 5| Step: 7
Training loss: 2.7170989186093872
Validation loss: 2.4822817687107936

Epoch: 5| Step: 8
Training loss: 3.2888031266030806
Validation loss: 2.484613962896809

Epoch: 5| Step: 9
Training loss: 2.5793513300229973
Validation loss: 2.4767538411927057

Epoch: 5| Step: 10
Training loss: 2.8615162654123143
Validation loss: 2.471383500938387

Epoch: 5| Step: 11
Training loss: 1.780868623294902
Validation loss: 2.4723062413174643

Epoch: 134| Step: 0
Training loss: 2.0921403761350694
Validation loss: 2.472909232441484

Epoch: 5| Step: 1
Training loss: 3.2298265992851993
Validation loss: 2.4727286498451924

Epoch: 5| Step: 2
Training loss: 2.1568558436128624
Validation loss: 2.465594895134344

Epoch: 5| Step: 3
Training loss: 2.7573479539414727
Validation loss: 2.4599103651089345

Epoch: 5| Step: 4
Training loss: 2.3927067687035444
Validation loss: 2.453800088277619

Epoch: 5| Step: 5
Training loss: 2.3706634482965123
Validation loss: 2.4577754035473425

Epoch: 5| Step: 6
Training loss: 2.358158227285555
Validation loss: 2.448729480909286

Epoch: 5| Step: 7
Training loss: 2.3633155505000496
Validation loss: 2.4546767629756463

Epoch: 5| Step: 8
Training loss: 2.861144472028516
Validation loss: 2.459504847833072

Epoch: 5| Step: 9
Training loss: 2.337976490760781
Validation loss: 2.4497045616181556

Epoch: 5| Step: 10
Training loss: 2.6883782127340954
Validation loss: 2.4615252686024354

Epoch: 5| Step: 11
Training loss: 1.842087205999112
Validation loss: 2.4504129397523875

Epoch: 135| Step: 0
Training loss: 2.860247036061711
Validation loss: 2.461077709341492

Epoch: 5| Step: 1
Training loss: 2.8202869699437456
Validation loss: 2.4517979241608483

Epoch: 5| Step: 2
Training loss: 2.6180471346512024
Validation loss: 2.467135170850115

Epoch: 5| Step: 3
Training loss: 2.1154989004941465
Validation loss: 2.449245057276541

Epoch: 5| Step: 4
Training loss: 2.569541838807661
Validation loss: 2.447301849641076

Epoch: 5| Step: 5
Training loss: 2.583421387761188
Validation loss: 2.4476540499020927

Epoch: 5| Step: 6
Training loss: 2.157466047954728
Validation loss: 2.450232568231824

Epoch: 5| Step: 7
Training loss: 2.8121339347817127
Validation loss: 2.454293628710516

Epoch: 5| Step: 8
Training loss: 2.583636132819225
Validation loss: 2.449996739502119

Epoch: 5| Step: 9
Training loss: 1.8172719553692915
Validation loss: 2.453464274017602

Epoch: 5| Step: 10
Training loss: 2.5360568523231755
Validation loss: 2.450785085853248

Epoch: 5| Step: 11
Training loss: 2.702518108353127
Validation loss: 2.4629515020967743

Epoch: 136| Step: 0
Training loss: 2.460515352402411
Validation loss: 2.454418995217405

Epoch: 5| Step: 1
Training loss: 2.799254699697635
Validation loss: 2.4610082908822943

Epoch: 5| Step: 2
Training loss: 2.487871121273056
Validation loss: 2.455027986154614

Epoch: 5| Step: 3
Training loss: 2.2628584182688876
Validation loss: 2.457024886098281

Epoch: 5| Step: 4
Training loss: 2.2705014070810186
Validation loss: 2.454243577055337

Epoch: 5| Step: 5
Training loss: 1.958265330439324
Validation loss: 2.455617658740551

Epoch: 5| Step: 6
Training loss: 2.6463539232147433
Validation loss: 2.4509588060316694

Epoch: 5| Step: 7
Training loss: 2.32283371120064
Validation loss: 2.4511127804222297

Epoch: 5| Step: 8
Training loss: 2.7437077408232136
Validation loss: 2.4469702710620633

Epoch: 5| Step: 9
Training loss: 2.6083701934484984
Validation loss: 2.457516944156778

Epoch: 5| Step: 10
Training loss: 2.886278338253957
Validation loss: 2.4536595825077847

Epoch: 5| Step: 11
Training loss: 3.0892956967432728
Validation loss: 2.4519677398798705

Epoch: 137| Step: 0
Training loss: 2.6382355120949783
Validation loss: 2.4531619561199802

Epoch: 5| Step: 1
Training loss: 2.5242198758726406
Validation loss: 2.45582654941279

Epoch: 5| Step: 2
Training loss: 2.6337080431376667
Validation loss: 2.44860046792153

Epoch: 5| Step: 3
Training loss: 3.1062271823467147
Validation loss: 2.449797278567932

Epoch: 5| Step: 4
Training loss: 2.7824538122355458
Validation loss: 2.4565420952592363

Epoch: 5| Step: 5
Training loss: 2.6019493021677085
Validation loss: 2.4532697153027794

Epoch: 5| Step: 6
Training loss: 2.764406269749611
Validation loss: 2.4567285218813084

Epoch: 5| Step: 7
Training loss: 2.09120342195927
Validation loss: 2.4586127952094197

Epoch: 5| Step: 8
Training loss: 2.1952061746174025
Validation loss: 2.4523344203596915

Epoch: 5| Step: 9
Training loss: 2.0518191662947096
Validation loss: 2.450394996441733

Epoch: 5| Step: 10
Training loss: 2.1258837040469367
Validation loss: 2.454133581662783

Epoch: 5| Step: 11
Training loss: 1.4763190659170728
Validation loss: 2.4520786710471723

Epoch: 138| Step: 0
Training loss: 2.753695259398636
Validation loss: 2.4514136328152323

Epoch: 5| Step: 1
Training loss: 2.5877869783194893
Validation loss: 2.4548780612159544

Epoch: 5| Step: 2
Training loss: 2.464096318740358
Validation loss: 2.4436808658456695

Epoch: 5| Step: 3
Training loss: 2.027130527345548
Validation loss: 2.4499042450104773

Epoch: 5| Step: 4
Training loss: 2.368347286726428
Validation loss: 2.448162798310148

Epoch: 5| Step: 5
Training loss: 2.480869338962041
Validation loss: 2.4546371707333825

Epoch: 5| Step: 6
Training loss: 2.187999341375332
Validation loss: 2.4552110359350734

Epoch: 5| Step: 7
Training loss: 2.372663653792058
Validation loss: 2.4498660192055928

Epoch: 5| Step: 8
Training loss: 2.8815792929922575
Validation loss: 2.448369184562191

Epoch: 5| Step: 9
Training loss: 2.3264544337008153
Validation loss: 2.452588312196769

Epoch: 5| Step: 10
Training loss: 2.8519099611726424
Validation loss: 2.4477395149141197

Epoch: 5| Step: 11
Training loss: 2.6813047105591523
Validation loss: 2.4498847003327358

Epoch: 139| Step: 0
Training loss: 2.444639070546345
Validation loss: 2.4526416845092283

Epoch: 5| Step: 1
Training loss: 2.615204746115536
Validation loss: 2.4502768170395792

Epoch: 5| Step: 2
Training loss: 2.6609892808195825
Validation loss: 2.458326769405158

Epoch: 5| Step: 3
Training loss: 2.68998142392009
Validation loss: 2.457650588212149

Epoch: 5| Step: 4
Training loss: 2.604876724079308
Validation loss: 2.456885660504684

Epoch: 5| Step: 5
Training loss: 2.415228404741529
Validation loss: 2.451700829808807

Epoch: 5| Step: 6
Training loss: 2.4310855093965333
Validation loss: 2.459176595101846

Epoch: 5| Step: 7
Training loss: 2.7419856070510114
Validation loss: 2.4565051859466975

Epoch: 5| Step: 8
Training loss: 2.999127261054944
Validation loss: 2.4554205923428287

Epoch: 5| Step: 9
Training loss: 1.8932448591572786
Validation loss: 2.4549116565285423

Epoch: 5| Step: 10
Training loss: 2.0409170318591143
Validation loss: 2.448772821792257

Epoch: 5| Step: 11
Training loss: 1.1794203904256042
Validation loss: 2.4500110932507733

Epoch: 140| Step: 0
Training loss: 2.6420228407144655
Validation loss: 2.4508015508665193

Epoch: 5| Step: 1
Training loss: 2.3358129767969955
Validation loss: 2.4520233377610863

Epoch: 5| Step: 2
Training loss: 1.867904844511142
Validation loss: 2.4640600124226433

Epoch: 5| Step: 3
Training loss: 2.5376902466662283
Validation loss: 2.4631740236602457

Epoch: 5| Step: 4
Training loss: 2.7504933521583603
Validation loss: 2.4495084308355373

Epoch: 5| Step: 5
Training loss: 2.7950167316625203
Validation loss: 2.44474300785237

Epoch: 5| Step: 6
Training loss: 2.862145754287615
Validation loss: 2.452795901566976

Epoch: 5| Step: 7
Training loss: 2.1765453154466763
Validation loss: 2.449009741910575

Epoch: 5| Step: 8
Training loss: 2.733977893876712
Validation loss: 2.45596191352372

Epoch: 5| Step: 9
Training loss: 2.469109327989685
Validation loss: 2.450321774534299

Epoch: 5| Step: 10
Training loss: 2.2920101833084
Validation loss: 2.4532259821102067

Epoch: 5| Step: 11
Training loss: 1.6020823309621994
Validation loss: 2.4544699316897014

Epoch: 141| Step: 0
Training loss: 2.9481467616636907
Validation loss: 2.4529554790391597

Epoch: 5| Step: 1
Training loss: 2.096428026750261
Validation loss: 2.4659346288992157

Epoch: 5| Step: 2
Training loss: 2.479808136686262
Validation loss: 2.4653883270466683

Epoch: 5| Step: 3
Training loss: 2.8200760422592785
Validation loss: 2.459897644109071

Epoch: 5| Step: 4
Training loss: 2.6773188941320503
Validation loss: 2.465338002993052

Epoch: 5| Step: 5
Training loss: 2.8786412276250775
Validation loss: 2.4713018362911603

Epoch: 5| Step: 6
Training loss: 2.376744984499598
Validation loss: 2.469103232596819

Epoch: 5| Step: 7
Training loss: 2.5262238322114987
Validation loss: 2.462460493684198

Epoch: 5| Step: 8
Training loss: 2.414286186447162
Validation loss: 2.4671541359505538

Epoch: 5| Step: 9
Training loss: 1.833976704964326
Validation loss: 2.4632363859447173

Epoch: 5| Step: 10
Training loss: 2.3491485473576357
Validation loss: 2.4621301657284924

Epoch: 5| Step: 11
Training loss: 2.3185285395646167
Validation loss: 2.4600595714688347

Epoch: 142| Step: 0
Training loss: 2.7422297547826178
Validation loss: 2.4527063802235407

Epoch: 5| Step: 1
Training loss: 2.6461068760400193
Validation loss: 2.4580568923263524

Epoch: 5| Step: 2
Training loss: 2.16505998559184
Validation loss: 2.4629946915343064

Epoch: 5| Step: 3
Training loss: 2.4367006409447023
Validation loss: 2.4577216273648306

Epoch: 5| Step: 4
Training loss: 2.676838597689871
Validation loss: 2.4569741238905802

Epoch: 5| Step: 5
Training loss: 2.3273345834398516
Validation loss: 2.4528908263445337

Epoch: 5| Step: 6
Training loss: 2.5126644744937705
Validation loss: 2.455976436675397

Epoch: 5| Step: 7
Training loss: 2.721360367519974
Validation loss: 2.461205422485475

Epoch: 5| Step: 8
Training loss: 2.406291713600744
Validation loss: 2.4620143371118615

Epoch: 5| Step: 9
Training loss: 2.7066752322144425
Validation loss: 2.4616552729096512

Epoch: 5| Step: 10
Training loss: 2.0672019767686822
Validation loss: 2.464410980649487

Epoch: 5| Step: 11
Training loss: 2.2945595832714525
Validation loss: 2.460037926850606

Epoch: 143| Step: 0
Training loss: 2.2409294400424624
Validation loss: 2.4602871878263604

Epoch: 5| Step: 1
Training loss: 2.15075891097246
Validation loss: 2.4581499853027453

Epoch: 5| Step: 2
Training loss: 2.3156324255202616
Validation loss: 2.46361465964274

Epoch: 5| Step: 3
Training loss: 2.5706132985263075
Validation loss: 2.4643717503814466

Epoch: 5| Step: 4
Training loss: 2.4724975342154862
Validation loss: 2.4571025092097027

Epoch: 5| Step: 5
Training loss: 2.26604757643178
Validation loss: 2.448518055570708

Epoch: 5| Step: 6
Training loss: 2.317369746361447
Validation loss: 2.4674476012914988

Epoch: 5| Step: 7
Training loss: 2.9877970783213486
Validation loss: 2.4572616372100207

Epoch: 5| Step: 8
Training loss: 2.53686277910528
Validation loss: 2.4588416807804006

Epoch: 5| Step: 9
Training loss: 2.9842109035894313
Validation loss: 2.459551908584282

Epoch: 5| Step: 10
Training loss: 2.297336142822573
Validation loss: 2.461295506508883

Epoch: 5| Step: 11
Training loss: 3.278515211941845
Validation loss: 2.4578293078915494

Epoch: 144| Step: 0
Training loss: 2.5128432347818896
Validation loss: 2.4621612896802976

Epoch: 5| Step: 1
Training loss: 2.5344147854279786
Validation loss: 2.4599090687814824

Epoch: 5| Step: 2
Training loss: 2.5461220593676828
Validation loss: 2.4605289685274574

Epoch: 5| Step: 3
Training loss: 2.0315210014908267
Validation loss: 2.4692065585357112

Epoch: 5| Step: 4
Training loss: 2.454493535741802
Validation loss: 2.4599606790475583

Epoch: 5| Step: 5
Training loss: 2.492666551234748
Validation loss: 2.452587186169015

Epoch: 5| Step: 6
Training loss: 2.872447331861179
Validation loss: 2.4576074180397733

Epoch: 5| Step: 7
Training loss: 2.698480397442846
Validation loss: 2.4562483987325767

Epoch: 5| Step: 8
Training loss: 2.2321644765624344
Validation loss: 2.4549410368752596

Epoch: 5| Step: 9
Training loss: 2.3118373849432805
Validation loss: 2.455667320327582

Epoch: 5| Step: 10
Training loss: 2.588481838422715
Validation loss: 2.4534396680453785

Epoch: 5| Step: 11
Training loss: 2.7164582864924354
Validation loss: 2.4558824361231415

Epoch: 145| Step: 0
Training loss: 2.782436846267458
Validation loss: 2.45927805380296

Epoch: 5| Step: 1
Training loss: 2.4424465557018267
Validation loss: 2.45615090193729

Epoch: 5| Step: 2
Training loss: 2.0943744923754073
Validation loss: 2.4533271868212383

Epoch: 5| Step: 3
Training loss: 2.7478499243678036
Validation loss: 2.4573459797659862

Epoch: 5| Step: 4
Training loss: 2.1548523727088464
Validation loss: 2.459482596506501

Epoch: 5| Step: 5
Training loss: 2.4060016850745436
Validation loss: 2.460586647979567

Epoch: 5| Step: 6
Training loss: 2.6847322983368214
Validation loss: 2.4590213965754173

Epoch: 5| Step: 7
Training loss: 3.001866078154033
Validation loss: 2.4452793821909555

Epoch: 5| Step: 8
Training loss: 1.8777408911613975
Validation loss: 2.454661851712921

Epoch: 5| Step: 9
Training loss: 2.4192637486896458
Validation loss: 2.4476791117769663

Epoch: 5| Step: 10
Training loss: 2.7380998798986544
Validation loss: 2.4611208125873554

Epoch: 5| Step: 11
Training loss: 2.591275425007359
Validation loss: 2.4537759714927

Epoch: 146| Step: 0
Training loss: 2.494610221704714
Validation loss: 2.461131670522484

Epoch: 5| Step: 1
Training loss: 2.2796470549605763
Validation loss: 2.454901811069599

Epoch: 5| Step: 2
Training loss: 2.46269332978844
Validation loss: 2.4561821926583804

Epoch: 5| Step: 3
Training loss: 2.4796096876082854
Validation loss: 2.4543603269097787

Epoch: 5| Step: 4
Training loss: 2.6291948134602854
Validation loss: 2.451985740556114

Epoch: 5| Step: 5
Training loss: 2.3991783563510856
Validation loss: 2.4557270152519783

Epoch: 5| Step: 6
Training loss: 2.617420425298499
Validation loss: 2.4561525035918415

Epoch: 5| Step: 7
Training loss: 2.9561688918102664
Validation loss: 2.4523716942300036

Epoch: 5| Step: 8
Training loss: 2.735529890039017
Validation loss: 2.459445396071826

Epoch: 5| Step: 9
Training loss: 2.1410865007767885
Validation loss: 2.4525080631977745

Epoch: 5| Step: 10
Training loss: 2.2350678336753833
Validation loss: 2.4609066269971525

Epoch: 5| Step: 11
Training loss: 1.076602801051669
Validation loss: 2.454933904773277

Epoch: 147| Step: 0
Training loss: 2.4911645206806194
Validation loss: 2.456152260916977

Epoch: 5| Step: 1
Training loss: 2.531401264710136
Validation loss: 2.4588442644597133

Epoch: 5| Step: 2
Training loss: 2.128252345460818
Validation loss: 2.4548913626191

Epoch: 5| Step: 3
Training loss: 2.4025785501998413
Validation loss: 2.4589087020384426

Epoch: 5| Step: 4
Training loss: 2.8560182640175564
Validation loss: 2.4688062540719256

Epoch: 5| Step: 5
Training loss: 3.233660927789221
Validation loss: 2.4579975025403833

Epoch: 5| Step: 6
Training loss: 2.360489638823152
Validation loss: 2.457082310213244

Epoch: 5| Step: 7
Training loss: 2.647430948828448
Validation loss: 2.4580101161698953

Epoch: 5| Step: 8
Training loss: 2.5691219459656227
Validation loss: 2.4585861639086204

Epoch: 5| Step: 9
Training loss: 2.1333030723372626
Validation loss: 2.462559654833237

Epoch: 5| Step: 10
Training loss: 1.9738231267059896
Validation loss: 2.458327626097784

Epoch: 5| Step: 11
Training loss: 1.2707432991194878
Validation loss: 2.4683930102708507

Epoch: 148| Step: 0
Training loss: 2.0252015661068943
Validation loss: 2.454182605389411

Epoch: 5| Step: 1
Training loss: 2.807821324100544
Validation loss: 2.4647287099101707

Epoch: 5| Step: 2
Training loss: 2.228809173534435
Validation loss: 2.4589899662470356

Epoch: 5| Step: 3
Training loss: 2.327475540409573
Validation loss: 2.4637916846694794

Epoch: 5| Step: 4
Training loss: 2.342976048157033
Validation loss: 2.4600602074785236

Epoch: 5| Step: 5
Training loss: 2.9104868861042084
Validation loss: 2.4605573168763804

Epoch: 5| Step: 6
Training loss: 2.2671762351788765
Validation loss: 2.4592253647958944

Epoch: 5| Step: 7
Training loss: 2.5249628234241532
Validation loss: 2.4580774955384896

Epoch: 5| Step: 8
Training loss: 2.7472448418996067
Validation loss: 2.4594162048481416

Epoch: 5| Step: 9
Training loss: 2.66668187574182
Validation loss: 2.4539036294639156

Epoch: 5| Step: 10
Training loss: 2.402186343610993
Validation loss: 2.4562861935745235

Epoch: 5| Step: 11
Training loss: 1.4269461275770294
Validation loss: 2.4600160437864522

Epoch: 149| Step: 0
Training loss: 2.760748405436047
Validation loss: 2.465016169091998

Epoch: 5| Step: 1
Training loss: 2.4469559969108294
Validation loss: 2.469283114788092

Epoch: 5| Step: 2
Training loss: 2.5338503820241414
Validation loss: 2.470456032842803

Epoch: 5| Step: 3
Training loss: 2.7582580379416335
Validation loss: 2.4672308525220923

Epoch: 5| Step: 4
Training loss: 2.1107656910155055
Validation loss: 2.4751971519501708

Epoch: 5| Step: 5
Training loss: 2.2482409488746478
Validation loss: 2.4705616585058254

Epoch: 5| Step: 6
Training loss: 2.3273932824013213
Validation loss: 2.463398702773165

Epoch: 5| Step: 7
Training loss: 2.4690708000257002
Validation loss: 2.4677328557515916

Epoch: 5| Step: 8
Training loss: 2.5398674730585222
Validation loss: 2.4634322101130217

Epoch: 5| Step: 9
Training loss: 2.216787625600197
Validation loss: 2.4675182537162503

Epoch: 5| Step: 10
Training loss: 2.767631018758399
Validation loss: 2.465150873443059

Epoch: 5| Step: 11
Training loss: 3.233172206862182
Validation loss: 2.4623737927350646

Epoch: 150| Step: 0
Training loss: 2.6334622540684944
Validation loss: 2.4669328754273425

Epoch: 5| Step: 1
Training loss: 2.4190119401905954
Validation loss: 2.4586764610721055

Epoch: 5| Step: 2
Training loss: 2.5823134182999614
Validation loss: 2.4539935848123213

Epoch: 5| Step: 3
Training loss: 2.550638612553363
Validation loss: 2.4643842668880716

Epoch: 5| Step: 4
Training loss: 2.467702715894028
Validation loss: 2.4586734832741928

Epoch: 5| Step: 5
Training loss: 2.276286329537769
Validation loss: 2.4634870290577986

Epoch: 5| Step: 6
Training loss: 2.4552589416682897
Validation loss: 2.462914628333656

Epoch: 5| Step: 7
Training loss: 2.5410706076512017
Validation loss: 2.468601793757816

Epoch: 5| Step: 8
Training loss: 1.9893254683857267
Validation loss: 2.462279875029081

Epoch: 5| Step: 9
Training loss: 2.6448007105436946
Validation loss: 2.4519309703633683

Epoch: 5| Step: 10
Training loss: 2.7463488182239093
Validation loss: 2.4651770973391955

Epoch: 5| Step: 11
Training loss: 1.246474252801368
Validation loss: 2.4610197346182954

Epoch: 151| Step: 0
Training loss: 2.5438263790276574
Validation loss: 2.467066456372412

Epoch: 5| Step: 1
Training loss: 3.184519552407095
Validation loss: 2.4649212760038326

Epoch: 5| Step: 2
Training loss: 2.7105127710950354
Validation loss: 2.4624115540746163

Epoch: 5| Step: 3
Training loss: 1.5952773162219995
Validation loss: 2.463091739971068

Epoch: 5| Step: 4
Training loss: 1.9884442035922356
Validation loss: 2.4582366170015524

Epoch: 5| Step: 5
Training loss: 2.2567891372324573
Validation loss: 2.4594293989040814

Epoch: 5| Step: 6
Training loss: 2.5673304364189633
Validation loss: 2.461020223044644

Epoch: 5| Step: 7
Training loss: 2.3726035626301485
Validation loss: 2.4691547633384228

Epoch: 5| Step: 8
Training loss: 2.1301895053718547
Validation loss: 2.463198447698478

Epoch: 5| Step: 9
Training loss: 2.6785109358723265
Validation loss: 2.4578193690322627

Epoch: 5| Step: 10
Training loss: 2.4552692348051894
Validation loss: 2.459273172134226

Epoch: 5| Step: 11
Training loss: 3.787340791585363
Validation loss: 2.458994971695121

Epoch: 152| Step: 0
Training loss: 2.6828861997386864
Validation loss: 2.45508064182894

Epoch: 5| Step: 1
Training loss: 2.6865225500384757
Validation loss: 2.452044866763072

Epoch: 5| Step: 2
Training loss: 2.7959032981369294
Validation loss: 2.4575206752294156

Epoch: 5| Step: 3
Training loss: 2.5780744143060463
Validation loss: 2.469747579195301

Epoch: 5| Step: 4
Training loss: 2.3581536776135756
Validation loss: 2.462402973103107

Epoch: 5| Step: 5
Training loss: 2.2730479742409053
Validation loss: 2.467285727988979

Epoch: 5| Step: 6
Training loss: 2.5423856145733867
Validation loss: 2.464573617149112

Epoch: 5| Step: 7
Training loss: 2.489519371158083
Validation loss: 2.463033088679943

Epoch: 5| Step: 8
Training loss: 2.4921670273086423
Validation loss: 2.468101174767714

Epoch: 5| Step: 9
Training loss: 2.417551229539662
Validation loss: 2.460063799415871

Epoch: 5| Step: 10
Training loss: 2.1534155307745766
Validation loss: 2.4634407229775257

Epoch: 5| Step: 11
Training loss: 2.2916942479178894
Validation loss: 2.4635745053727094

Epoch: 153| Step: 0
Training loss: 2.6462376102955725
Validation loss: 2.4645976343220997

Epoch: 5| Step: 1
Training loss: 2.669699424512511
Validation loss: 2.4583625360683286

Epoch: 5| Step: 2
Training loss: 2.433002528692986
Validation loss: 2.4614105698359467

Epoch: 5| Step: 3
Training loss: 2.5006603322563734
Validation loss: 2.4626705667319064

Epoch: 5| Step: 4
Training loss: 2.525412999737743
Validation loss: 2.459312140385706

Epoch: 5| Step: 5
Training loss: 2.6728868854991488
Validation loss: 2.462279342472916

Epoch: 5| Step: 6
Training loss: 2.257677331594077
Validation loss: 2.4638144776880915

Epoch: 5| Step: 7
Training loss: 1.9219336772117892
Validation loss: 2.4595813708260104

Epoch: 5| Step: 8
Training loss: 2.3861356981417234
Validation loss: 2.4640418802292405

Epoch: 5| Step: 9
Training loss: 2.282857772514001
Validation loss: 2.4628365369802463

Epoch: 5| Step: 10
Training loss: 2.5992752422205228
Validation loss: 2.4710986920159694

Epoch: 5| Step: 11
Training loss: 3.397190891376817
Validation loss: 2.4769259806823447

Epoch: 154| Step: 0
Training loss: 2.177630037964409
Validation loss: 2.4573261243747133

Epoch: 5| Step: 1
Training loss: 2.2220215653850284
Validation loss: 2.475237286235703

Epoch: 5| Step: 2
Training loss: 2.896724719251226
Validation loss: 2.473658299907787

Epoch: 5| Step: 3
Training loss: 2.146029478818103
Validation loss: 2.4624420047843607

Epoch: 5| Step: 4
Training loss: 2.118481792927216
Validation loss: 2.4648902372801746

Epoch: 5| Step: 5
Training loss: 2.301708610957225
Validation loss: 2.466448157422381

Epoch: 5| Step: 6
Training loss: 3.0895607067539186
Validation loss: 2.465536210718097

Epoch: 5| Step: 7
Training loss: 2.7315984961906223
Validation loss: 2.4685533823514447

Epoch: 5| Step: 8
Training loss: 2.118081329967106
Validation loss: 2.463769528508188

Epoch: 5| Step: 9
Training loss: 2.7759638925122454
Validation loss: 2.464030869820565

Epoch: 5| Step: 10
Training loss: 2.31122151680659
Validation loss: 2.4572235945883363

Epoch: 5| Step: 11
Training loss: 2.1751738818588278
Validation loss: 2.465427931987157

Epoch: 155| Step: 0
Training loss: 2.2871142744863726
Validation loss: 2.459155912226041

Epoch: 5| Step: 1
Training loss: 2.719717094911708
Validation loss: 2.4682944436801417

Epoch: 5| Step: 2
Training loss: 2.3269284649039017
Validation loss: 2.4648625553983536

Epoch: 5| Step: 3
Training loss: 2.4471016575470226
Validation loss: 2.464867423982177

Epoch: 5| Step: 4
Training loss: 2.202532208279716
Validation loss: 2.4659327354863714

Epoch: 5| Step: 5
Training loss: 2.4521285055878006
Validation loss: 2.4691012933333596

Epoch: 5| Step: 6
Training loss: 2.2692288904791544
Validation loss: 2.4636124015368686

Epoch: 5| Step: 7
Training loss: 2.5433458086793577
Validation loss: 2.4695217559995606

Epoch: 5| Step: 8
Training loss: 2.3249471596896822
Validation loss: 2.4645454238293447

Epoch: 5| Step: 9
Training loss: 2.8333679832882885
Validation loss: 2.461914457941282

Epoch: 5| Step: 10
Training loss: 2.5776452745258416
Validation loss: 2.4610805449717716

Epoch: 5| Step: 11
Training loss: 2.9982135539985904
Validation loss: 2.4673032907795527

Epoch: 156| Step: 0
Training loss: 2.25038122550274
Validation loss: 2.4678877479597396

Epoch: 5| Step: 1
Training loss: 1.677937221143859
Validation loss: 2.464269229535632

Epoch: 5| Step: 2
Training loss: 2.493521688999954
Validation loss: 2.4705100163720792

Epoch: 5| Step: 3
Training loss: 2.6795743245506394
Validation loss: 2.4681477476043994

Epoch: 5| Step: 4
Training loss: 2.5363364271964843
Validation loss: 2.4689828465101344

Epoch: 5| Step: 5
Training loss: 2.2423489077220795
Validation loss: 2.4676968666176315

Epoch: 5| Step: 6
Training loss: 2.704276749104701
Validation loss: 2.4653394435429385

Epoch: 5| Step: 7
Training loss: 2.554145965575256
Validation loss: 2.4722627203073375

Epoch: 5| Step: 8
Training loss: 2.609561936312431
Validation loss: 2.46555460791918

Epoch: 5| Step: 9
Training loss: 2.3725176436930897
Validation loss: 2.4651188724567334

Epoch: 5| Step: 10
Training loss: 3.047528944996792
Validation loss: 2.4626283478247877

Epoch: 5| Step: 11
Training loss: 1.5535896297071403
Validation loss: 2.4705495794177903

Epoch: 157| Step: 0
Training loss: 2.4598947404811504
Validation loss: 2.467908341555122

Epoch: 5| Step: 1
Training loss: 2.6952973738536157
Validation loss: 2.482126582060643

Epoch: 5| Step: 2
Training loss: 2.2882374392997944
Validation loss: 2.4714745886472107

Epoch: 5| Step: 3
Training loss: 2.413250437817978
Validation loss: 2.463746852005035

Epoch: 5| Step: 4
Training loss: 2.1473623463896105
Validation loss: 2.466574909838371

Epoch: 5| Step: 5
Training loss: 2.7208902988828285
Validation loss: 2.469302562248808

Epoch: 5| Step: 6
Training loss: 2.877382369433503
Validation loss: 2.469302835815636

Epoch: 5| Step: 7
Training loss: 1.8841023439239601
Validation loss: 2.472318528802171

Epoch: 5| Step: 8
Training loss: 3.067132210293903
Validation loss: 2.463418319684259

Epoch: 5| Step: 9
Training loss: 2.3985789502708417
Validation loss: 2.4751848386209154

Epoch: 5| Step: 10
Training loss: 2.113659047539216
Validation loss: 2.4711397893369393

Epoch: 5| Step: 11
Training loss: 2.9467536779937227
Validation loss: 2.468280719466359

Epoch: 158| Step: 0
Training loss: 1.9188830649493633
Validation loss: 2.470229928560704

Epoch: 5| Step: 1
Training loss: 2.9400239206495753
Validation loss: 2.4640236531583812

Epoch: 5| Step: 2
Training loss: 2.502896157232489
Validation loss: 2.457797369210146

Epoch: 5| Step: 3
Training loss: 2.422199252172315
Validation loss: 2.4609314045502595

Epoch: 5| Step: 4
Training loss: 2.6848554685255106
Validation loss: 2.4692036256224577

Epoch: 5| Step: 5
Training loss: 2.343269604087196
Validation loss: 2.4565150856392384

Epoch: 5| Step: 6
Training loss: 2.0130994484484024
Validation loss: 2.4566899008430774

Epoch: 5| Step: 7
Training loss: 2.4774950840782872
Validation loss: 2.4658167108188422

Epoch: 5| Step: 8
Training loss: 2.5752849310107635
Validation loss: 2.4700435718047205

Epoch: 5| Step: 9
Training loss: 2.6917595928988782
Validation loss: 2.467436332306387

Epoch: 5| Step: 10
Training loss: 2.2605744993830093
Validation loss: 2.4742412539214445

Epoch: 5| Step: 11
Training loss: 2.5184621035837527
Validation loss: 2.4832367278729808

Epoch: 159| Step: 0
Training loss: 2.3934694210383807
Validation loss: 2.4603746446665022

Epoch: 5| Step: 1
Training loss: 2.6992778412772553
Validation loss: 2.4657098625802316

Epoch: 5| Step: 2
Training loss: 2.711901226844399
Validation loss: 2.469735721376571

Epoch: 5| Step: 3
Training loss: 2.9263082724810148
Validation loss: 2.4681387357827864

Epoch: 5| Step: 4
Training loss: 2.0634165952375465
Validation loss: 2.4654437753969476

Epoch: 5| Step: 5
Training loss: 2.5803854540536575
Validation loss: 2.46599089482548

Epoch: 5| Step: 6
Training loss: 2.7186623043956373
Validation loss: 2.472345176924111

Epoch: 5| Step: 7
Training loss: 2.7636773961958983
Validation loss: 2.462434799602736

Epoch: 5| Step: 8
Training loss: 1.934824418965856
Validation loss: 2.4743356851934624

Epoch: 5| Step: 9
Training loss: 2.4021031701183397
Validation loss: 2.4742407159098243

Epoch: 5| Step: 10
Training loss: 1.9315657027384188
Validation loss: 2.4589216584359987

Epoch: 5| Step: 11
Training loss: 2.022473433311832
Validation loss: 2.467783923995463

Epoch: 160| Step: 0
Training loss: 2.062781112471401
Validation loss: 2.4684509265195

Epoch: 5| Step: 1
Training loss: 2.322699144610798
Validation loss: 2.459005907695159

Epoch: 5| Step: 2
Training loss: 2.6953020620835026
Validation loss: 2.471263696255997

Epoch: 5| Step: 3
Training loss: 2.6103420635582872
Validation loss: 2.466285485432714

Epoch: 5| Step: 4
Training loss: 2.754842482700633
Validation loss: 2.465490811430958

Epoch: 5| Step: 5
Training loss: 2.6607238791302867
Validation loss: 2.463090711508388

Epoch: 5| Step: 6
Training loss: 2.22345717871101
Validation loss: 2.4672966876359097

Epoch: 5| Step: 7
Training loss: 2.515406533937475
Validation loss: 2.470968887048061

Epoch: 5| Step: 8
Training loss: 2.411938075110496
Validation loss: 2.46131538840262

Epoch: 5| Step: 9
Training loss: 2.6310543902758536
Validation loss: 2.472439178371854

Epoch: 5| Step: 10
Training loss: 2.146755933722077
Validation loss: 2.464328141650185

Epoch: 5| Step: 11
Training loss: 2.3306100370909357
Validation loss: 2.4719065674230185

Epoch: 161| Step: 0
Training loss: 2.0137551084201455
Validation loss: 2.4612844474891404

Epoch: 5| Step: 1
Training loss: 2.5711113983911726
Validation loss: 2.462442613956085

Epoch: 5| Step: 2
Training loss: 2.384978163837141
Validation loss: 2.4603247308525993

Epoch: 5| Step: 3
Training loss: 2.1944909781607125
Validation loss: 2.4601771577794835

Epoch: 5| Step: 4
Training loss: 2.2731085994906017
Validation loss: 2.4651463681032797

Epoch: 5| Step: 5
Training loss: 2.3807094611269894
Validation loss: 2.460471057586741

Epoch: 5| Step: 6
Training loss: 2.4644231422282568
Validation loss: 2.468162877247888

Epoch: 5| Step: 7
Training loss: 2.7667108333080352
Validation loss: 2.4635269710325587

Epoch: 5| Step: 8
Training loss: 2.8068185005286086
Validation loss: 2.4652699033106975

Epoch: 5| Step: 9
Training loss: 2.23708451318689
Validation loss: 2.4656359190028247

Epoch: 5| Step: 10
Training loss: 2.9546325710764645
Validation loss: 2.467370577416258

Epoch: 5| Step: 11
Training loss: 1.9334370250957196
Validation loss: 2.4677217168889216

Epoch: 162| Step: 0
Training loss: 2.623007335918725
Validation loss: 2.4638709734669497

Epoch: 5| Step: 1
Training loss: 2.8381949023366775
Validation loss: 2.47188617592852

Epoch: 5| Step: 2
Training loss: 2.272518640825723
Validation loss: 2.465484600316371

Epoch: 5| Step: 3
Training loss: 2.2985939289025787
Validation loss: 2.4842619720274928

Epoch: 5| Step: 4
Training loss: 2.1109643670439926
Validation loss: 2.470445605944017

Epoch: 5| Step: 5
Training loss: 2.300420606550249
Validation loss: 2.4760833260628172

Epoch: 5| Step: 6
Training loss: 2.3401369856816867
Validation loss: 2.4718531931137475

Epoch: 5| Step: 7
Training loss: 2.750624672426613
Validation loss: 2.480161032024708

Epoch: 5| Step: 8
Training loss: 2.1519124729196535
Validation loss: 2.4701088252141807

Epoch: 5| Step: 9
Training loss: 2.7588602728641383
Validation loss: 2.4642420546690067

Epoch: 5| Step: 10
Training loss: 2.643265707330298
Validation loss: 2.472120153597739

Epoch: 5| Step: 11
Training loss: 1.2777669129854192
Validation loss: 2.4723383381240747

Epoch: 163| Step: 0
Training loss: 2.3653625907134987
Validation loss: 2.469031555280566

Epoch: 5| Step: 1
Training loss: 1.9205910340225092
Validation loss: 2.4672219782766196

Epoch: 5| Step: 2
Training loss: 2.4067626010798286
Validation loss: 2.465636144628185

Epoch: 5| Step: 3
Training loss: 3.081517862124886
Validation loss: 2.4718913441474153

Epoch: 5| Step: 4
Training loss: 2.3800139455627143
Validation loss: 2.4681803895233654

Epoch: 5| Step: 5
Training loss: 3.030461159539508
Validation loss: 2.4659054178086173

Epoch: 5| Step: 6
Training loss: 2.6696319980828798
Validation loss: 2.467144053460955

Epoch: 5| Step: 7
Training loss: 2.3655866491315765
Validation loss: 2.4661576949857804

Epoch: 5| Step: 8
Training loss: 2.65349867203361
Validation loss: 2.466225274702085

Epoch: 5| Step: 9
Training loss: 1.9236653370411694
Validation loss: 2.4735935497719597

Epoch: 5| Step: 10
Training loss: 2.0312940152607957
Validation loss: 2.479308219816798

Epoch: 5| Step: 11
Training loss: 2.145707049558069
Validation loss: 2.472628050407805

Epoch: 164| Step: 0
Training loss: 2.726406060133051
Validation loss: 2.4853137180167577

Epoch: 5| Step: 1
Training loss: 2.227211947841496
Validation loss: 2.4830548319618937

Epoch: 5| Step: 2
Training loss: 2.4827113309189492
Validation loss: 2.4791721549627854

Epoch: 5| Step: 3
Training loss: 2.6340232351809085
Validation loss: 2.476013451654729

Epoch: 5| Step: 4
Training loss: 1.7932633966094162
Validation loss: 2.471710216947098

Epoch: 5| Step: 5
Training loss: 2.1593952183529095
Validation loss: 2.4819712796409266

Epoch: 5| Step: 6
Training loss: 2.526755498852761
Validation loss: 2.4741979436116996

Epoch: 5| Step: 7
Training loss: 2.097755586058665
Validation loss: 2.4722614425115093

Epoch: 5| Step: 8
Training loss: 2.8457322809719505
Validation loss: 2.4737266124155

Epoch: 5| Step: 9
Training loss: 2.455296812430992
Validation loss: 2.4705426793529814

Epoch: 5| Step: 10
Training loss: 2.527603348336807
Validation loss: 2.463976929798899

Epoch: 5| Step: 11
Training loss: 3.7132193847742
Validation loss: 2.4770360507949447

Epoch: 165| Step: 0
Training loss: 2.6783602349719144
Validation loss: 2.4711352145149057

Epoch: 5| Step: 1
Training loss: 1.8708917114506471
Validation loss: 2.467532131130158

Epoch: 5| Step: 2
Training loss: 2.4910646019532967
Validation loss: 2.464706509775078

Epoch: 5| Step: 3
Training loss: 2.552710932162107
Validation loss: 2.4631908494932486

Epoch: 5| Step: 4
Training loss: 2.4483563183908097
Validation loss: 2.4669070024188837

Epoch: 5| Step: 5
Training loss: 2.2414402796600927
Validation loss: 2.4700758226883046

Epoch: 5| Step: 6
Training loss: 2.490788560424284
Validation loss: 2.467307691523399

Epoch: 5| Step: 7
Training loss: 3.111954122572911
Validation loss: 2.465023084626552

Epoch: 5| Step: 8
Training loss: 2.218906235902731
Validation loss: 2.472460336743116

Epoch: 5| Step: 9
Training loss: 2.412059459092582
Validation loss: 2.458616758969628

Epoch: 5| Step: 10
Training loss: 2.620938928980567
Validation loss: 2.4694005374654826

Epoch: 5| Step: 11
Training loss: 2.3685275776090884
Validation loss: 2.4748395748999545

Epoch: 166| Step: 0
Training loss: 2.7154207563249964
Validation loss: 2.4824856865717697

Epoch: 5| Step: 1
Training loss: 1.5428283627540476
Validation loss: 2.47684171528655

Epoch: 5| Step: 2
Training loss: 2.6587049023274307
Validation loss: 2.4969950537690515

Epoch: 5| Step: 3
Training loss: 2.895284001415498
Validation loss: 2.489718841844485

Epoch: 5| Step: 4
Training loss: 2.074537579589345
Validation loss: 2.4819357231151513

Epoch: 5| Step: 5
Training loss: 3.0169440828628384
Validation loss: 2.4850991910995583

Epoch: 5| Step: 6
Training loss: 2.9793971223772084
Validation loss: 2.4700635843741527

Epoch: 5| Step: 7
Training loss: 2.0824884481670645
Validation loss: 2.4688625430759084

Epoch: 5| Step: 8
Training loss: 2.078642587094475
Validation loss: 2.464268564377811

Epoch: 5| Step: 9
Training loss: 2.0144270064706227
Validation loss: 2.467771847413304

Epoch: 5| Step: 10
Training loss: 2.4784274134408433
Validation loss: 2.4700943670573245

Epoch: 5| Step: 11
Training loss: 3.97728862016153
Validation loss: 2.4622271070293698

Epoch: 167| Step: 0
Training loss: 2.0784037697039124
Validation loss: 2.4641949101400007

Epoch: 5| Step: 1
Training loss: 2.954756674519111
Validation loss: 2.467372183866308

Epoch: 5| Step: 2
Training loss: 2.5857958798078493
Validation loss: 2.4702309017711346

Epoch: 5| Step: 3
Training loss: 2.3486328125
Validation loss: 2.470138847236203

Epoch: 5| Step: 4
Training loss: 3.0512671480552584
Validation loss: 2.4669218577871863

Epoch: 5| Step: 5
Training loss: 2.312202434468363
Validation loss: 2.475396628982288

Epoch: 5| Step: 6
Training loss: 2.547705111346504
Validation loss: 2.493183801824134

Epoch: 5| Step: 7
Training loss: 1.9625542651406678
Validation loss: 2.4857654039622514

Epoch: 5| Step: 8
Training loss: 2.2501969781059388
Validation loss: 2.495216581650482

Epoch: 5| Step: 9
Training loss: 2.261766924040331
Validation loss: 2.486123415462466

Epoch: 5| Step: 10
Training loss: 2.5972420957443014
Validation loss: 2.4956692338108017

Epoch: 5| Step: 11
Training loss: 2.6342561199475187
Validation loss: 2.480806394810273

Epoch: 168| Step: 0
Training loss: 2.397384064290719
Validation loss: 2.478340272985652

Epoch: 5| Step: 1
Training loss: 2.9653525738858058
Validation loss: 2.4709120349240026

Epoch: 5| Step: 2
Training loss: 2.3992188016741793
Validation loss: 2.4712208040925034

Epoch: 5| Step: 3
Training loss: 2.159238209787527
Validation loss: 2.4767619352534758

Epoch: 5| Step: 4
Training loss: 2.113657355553878
Validation loss: 2.477207677419023

Epoch: 5| Step: 5
Training loss: 2.6519254599002107
Validation loss: 2.4776696779802547

Epoch: 5| Step: 6
Training loss: 2.2035788210696037
Validation loss: 2.4684448637085645

Epoch: 5| Step: 7
Training loss: 2.108408275473516
Validation loss: 2.4766066835074256

Epoch: 5| Step: 8
Training loss: 2.444609909767077
Validation loss: 2.479748354451327

Epoch: 5| Step: 9
Training loss: 3.0129278108727187
Validation loss: 2.4771937379116458

Epoch: 5| Step: 10
Training loss: 2.7487612448510452
Validation loss: 2.466666118733457

Epoch: 5| Step: 11
Training loss: 1.6622317994122893
Validation loss: 2.4758540482961444

Epoch: 169| Step: 0
Training loss: 2.724299412532245
Validation loss: 2.4740556570619145

Epoch: 5| Step: 1
Training loss: 2.2015446615477847
Validation loss: 2.470596307146731

Epoch: 5| Step: 2
Training loss: 2.572340979373897
Validation loss: 2.474921524203727

Epoch: 5| Step: 3
Training loss: 2.8388787772273743
Validation loss: 2.472505718548587

Epoch: 5| Step: 4
Training loss: 2.6681365690608243
Validation loss: 2.4701952928778685

Epoch: 5| Step: 5
Training loss: 2.560847330978906
Validation loss: 2.473017099253763

Epoch: 5| Step: 6
Training loss: 1.6330205611402109
Validation loss: 2.48257075277757

Epoch: 5| Step: 7
Training loss: 2.540211297355238
Validation loss: 2.482846847722316

Epoch: 5| Step: 8
Training loss: 2.5516484934605876
Validation loss: 2.4978136913675817

Epoch: 5| Step: 9
Training loss: 1.9657110950433778
Validation loss: 2.4848961933215414

Epoch: 5| Step: 10
Training loss: 2.828984419767991
Validation loss: 2.490383705199513

Epoch: 5| Step: 11
Training loss: 1.6315343499362718
Validation loss: 2.484373172623384

Epoch: 170| Step: 0
Training loss: 2.1462917640635015
Validation loss: 2.4802534996212837

Epoch: 5| Step: 1
Training loss: 2.453484284155673
Validation loss: 2.4799332328494397

Epoch: 5| Step: 2
Training loss: 2.5584496843386386
Validation loss: 2.4787522511897633

Epoch: 5| Step: 3
Training loss: 2.627548252464788
Validation loss: 2.476458442018133

Epoch: 5| Step: 4
Training loss: 2.215065919743382
Validation loss: 2.4751462206049237

Epoch: 5| Step: 5
Training loss: 2.7469512338659734
Validation loss: 2.471673674810364

Epoch: 5| Step: 6
Training loss: 2.268665667351028
Validation loss: 2.4812654852684193

Epoch: 5| Step: 7
Training loss: 2.021059620041539
Validation loss: 2.476783213121552

Epoch: 5| Step: 8
Training loss: 2.728563858512472
Validation loss: 2.471926496590638

Epoch: 5| Step: 9
Training loss: 2.094424352653501
Validation loss: 2.4888081494277023

Epoch: 5| Step: 10
Training loss: 2.8549623888414395
Validation loss: 2.4769552142091276

Epoch: 5| Step: 11
Training loss: 2.9534700383852144
Validation loss: 2.482938015011636

Epoch: 171| Step: 0
Training loss: 2.2662282206461417
Validation loss: 2.4840880674133454

Epoch: 5| Step: 1
Training loss: 2.529408291163323
Validation loss: 2.4861621906199907

Epoch: 5| Step: 2
Training loss: 2.6017303870847335
Validation loss: 2.4790671806783346

Epoch: 5| Step: 3
Training loss: 2.393536558670126
Validation loss: 2.4864207827594957

Epoch: 5| Step: 4
Training loss: 2.477091831955208
Validation loss: 2.4987010720560896

Epoch: 5| Step: 5
Training loss: 2.409169890187061
Validation loss: 2.4923142866293144

Epoch: 5| Step: 6
Training loss: 2.405034935076917
Validation loss: 2.4895047224607443

Epoch: 5| Step: 7
Training loss: 2.3944135577851973
Validation loss: 2.4956042864995793

Epoch: 5| Step: 8
Training loss: 2.4305202614779984
Validation loss: 2.4824606639553797

Epoch: 5| Step: 9
Training loss: 1.925272969299974
Validation loss: 2.4897084078368326

Epoch: 5| Step: 10
Training loss: 3.1553104626328907
Validation loss: 2.4865303247004977

Epoch: 5| Step: 11
Training loss: 1.5527124175432543
Validation loss: 2.4827633714626645

Epoch: 172| Step: 0
Training loss: 2.4213334985612542
Validation loss: 2.474905552812008

Epoch: 5| Step: 1
Training loss: 2.896617225280634
Validation loss: 2.4773267735966553

Epoch: 5| Step: 2
Training loss: 2.3989209610455595
Validation loss: 2.480280142594644

Epoch: 5| Step: 3
Training loss: 1.9026405056012783
Validation loss: 2.477351402961413

Epoch: 5| Step: 4
Training loss: 2.6495117889389665
Validation loss: 2.467966595220395

Epoch: 5| Step: 5
Training loss: 2.8310439079003125
Validation loss: 2.479330459494676

Epoch: 5| Step: 6
Training loss: 2.653406663373357
Validation loss: 2.482279899773113

Epoch: 5| Step: 7
Training loss: 2.188513493768875
Validation loss: 2.4834901525492796

Epoch: 5| Step: 8
Training loss: 2.2696275805516275
Validation loss: 2.496942597684881

Epoch: 5| Step: 9
Training loss: 2.2867796258672355
Validation loss: 2.487516979498237

Epoch: 5| Step: 10
Training loss: 2.5186152722695607
Validation loss: 2.4719698828657273

Epoch: 5| Step: 11
Training loss: 2.0949957258959304
Validation loss: 2.4789815414188268

Epoch: 173| Step: 0
Training loss: 1.9905123979708919
Validation loss: 2.483410090075241

Epoch: 5| Step: 1
Training loss: 2.6559343038212746
Validation loss: 2.479651381019837

Epoch: 5| Step: 2
Training loss: 2.4907204067666524
Validation loss: 2.4720929284045914

Epoch: 5| Step: 3
Training loss: 2.4810867140537045
Validation loss: 2.4749968801664988

Epoch: 5| Step: 4
Training loss: 2.2631661588291485
Validation loss: 2.476997497735462

Epoch: 5| Step: 5
Training loss: 2.522353278922321
Validation loss: 2.481161954840651

Epoch: 5| Step: 6
Training loss: 2.8040173083164333
Validation loss: 2.4824609520790575

Epoch: 5| Step: 7
Training loss: 2.1811478074408557
Validation loss: 2.4747229040488934

Epoch: 5| Step: 8
Training loss: 1.9354206124858513
Validation loss: 2.4816473816424844

Epoch: 5| Step: 9
Training loss: 2.4119055534457967
Validation loss: 2.482759578293659

Epoch: 5| Step: 10
Training loss: 3.1676619789238445
Validation loss: 2.4793536786194044

Epoch: 5| Step: 11
Training loss: 2.262817221474486
Validation loss: 2.470423714540898

Epoch: 174| Step: 0
Training loss: 2.6917695131130475
Validation loss: 2.4867620336736724

Epoch: 5| Step: 1
Training loss: 3.0749216209284937
Validation loss: 2.4816848176911948

Epoch: 5| Step: 2
Training loss: 2.334549098946485
Validation loss: 2.4833458222218128

Epoch: 5| Step: 3
Training loss: 2.1646146104429684
Validation loss: 2.48633538879628

Epoch: 5| Step: 4
Training loss: 2.5850432079843455
Validation loss: 2.4837253488892563

Epoch: 5| Step: 5
Training loss: 2.715767024181671
Validation loss: 2.480241984417189

Epoch: 5| Step: 6
Training loss: 2.0836368975410946
Validation loss: 2.479794968934515

Epoch: 5| Step: 7
Training loss: 1.603878003525287
Validation loss: 2.475264416644085

Epoch: 5| Step: 8
Training loss: 2.785152654658882
Validation loss: 2.4781353686108973

Epoch: 5| Step: 9
Training loss: 2.153829127810328
Validation loss: 2.475685766691456

Epoch: 5| Step: 10
Training loss: 2.390184648635233
Validation loss: 2.47615726657403

Epoch: 5| Step: 11
Training loss: 1.9318402595074429
Validation loss: 2.4761226636525184

Epoch: 175| Step: 0
Training loss: 2.802419441419677
Validation loss: 2.4804154918489942

Epoch: 5| Step: 1
Training loss: 2.670200023659523
Validation loss: 2.483807183000833

Epoch: 5| Step: 2
Training loss: 2.1560562710186457
Validation loss: 2.486357128116988

Epoch: 5| Step: 3
Training loss: 2.4250418354633716
Validation loss: 2.4846211077590596

Epoch: 5| Step: 4
Training loss: 2.5121271682367734
Validation loss: 2.4918616469482893

Epoch: 5| Step: 5
Training loss: 2.5982301006481907
Validation loss: 2.497482637733898

Epoch: 5| Step: 6
Training loss: 2.417231877319689
Validation loss: 2.4866819207407107

Epoch: 5| Step: 7
Training loss: 2.526929771326039
Validation loss: 2.4820780342134707

Epoch: 5| Step: 8
Training loss: 2.0878045231164735
Validation loss: 2.4920576294929435

Epoch: 5| Step: 9
Training loss: 2.1112301051194526
Validation loss: 2.4922103840924295

Epoch: 5| Step: 10
Training loss: 2.288071766254664
Validation loss: 2.4939492753924224

Epoch: 5| Step: 11
Training loss: 2.4200865017587434
Validation loss: 2.4953068710260475

Epoch: 176| Step: 0
Training loss: 2.3935307813218643
Validation loss: 2.488569940561019

Epoch: 5| Step: 1
Training loss: 2.4435848677860563
Validation loss: 2.4777617153371496

Epoch: 5| Step: 2
Training loss: 2.0212340858790783
Validation loss: 2.497823940387554

Epoch: 5| Step: 3
Training loss: 3.085138531361344
Validation loss: 2.4792648798190973

Epoch: 5| Step: 4
Training loss: 2.680953191232611
Validation loss: 2.4730664194769107

Epoch: 5| Step: 5
Training loss: 2.5864947775952665
Validation loss: 2.46917530613406

Epoch: 5| Step: 6
Training loss: 2.7811633321567175
Validation loss: 2.477771055000272

Epoch: 5| Step: 7
Training loss: 2.770661159892969
Validation loss: 2.48096612063863

Epoch: 5| Step: 8
Training loss: 1.8715105010748792
Validation loss: 2.4762088390744097

Epoch: 5| Step: 9
Training loss: 2.146578896882379
Validation loss: 2.4681628973723853

Epoch: 5| Step: 10
Training loss: 1.9008176349335604
Validation loss: 2.4812007234550375

Epoch: 5| Step: 11
Training loss: 2.3551528238005726
Validation loss: 2.4854289044710156

Epoch: 177| Step: 0
Training loss: 2.6158518557233528
Validation loss: 2.480077221024533

Epoch: 5| Step: 1
Training loss: 2.102680121835745
Validation loss: 2.4792787475788716

Epoch: 5| Step: 2
Training loss: 2.5801880875862087
Validation loss: 2.4737604858525732

Epoch: 5| Step: 3
Training loss: 2.7089505788266774
Validation loss: 2.4741616590502096

Epoch: 5| Step: 4
Training loss: 2.3634594054104143
Validation loss: 2.481027879549865

Epoch: 5| Step: 5
Training loss: 2.95614050245029
Validation loss: 2.4853524418537654

Epoch: 5| Step: 6
Training loss: 1.8945159596878145
Validation loss: 2.486371200040558

Epoch: 5| Step: 7
Training loss: 2.4347109365724564
Validation loss: 2.494975504675306

Epoch: 5| Step: 8
Training loss: 2.075511464887956
Validation loss: 2.4961996160512254

Epoch: 5| Step: 9
Training loss: 2.6207413415173546
Validation loss: 2.509316054079795

Epoch: 5| Step: 10
Training loss: 2.2887019892292026
Validation loss: 2.492921045624563

Epoch: 5| Step: 11
Training loss: 3.4047765782307153
Validation loss: 2.4867193988460037

Epoch: 178| Step: 0
Training loss: 2.3915427447213027
Validation loss: 2.4726192598152363

Epoch: 5| Step: 1
Training loss: 2.5222419292204745
Validation loss: 2.4823390807824643

Epoch: 5| Step: 2
Training loss: 2.046561530184782
Validation loss: 2.4818847339240393

Epoch: 5| Step: 3
Training loss: 2.563630203729112
Validation loss: 2.4879572571080915

Epoch: 5| Step: 4
Training loss: 2.799915131917602
Validation loss: 2.482302583058684

Epoch: 5| Step: 5
Training loss: 2.5323286230878606
Validation loss: 2.4833257926809362

Epoch: 5| Step: 6
Training loss: 2.6133817872920715
Validation loss: 2.4896990870190217

Epoch: 5| Step: 7
Training loss: 2.473080470619619
Validation loss: 2.4929126135055526

Epoch: 5| Step: 8
Training loss: 2.49962555942223
Validation loss: 2.492969063528008

Epoch: 5| Step: 9
Training loss: 3.030779615263034
Validation loss: 2.4989210264074804

Epoch: 5| Step: 10
Training loss: 2.4072743006802986
Validation loss: 2.4946265288763687

Epoch: 5| Step: 11
Training loss: 1.7005349159144427
Validation loss: 2.488776779937616

Epoch: 179| Step: 0
Training loss: 2.9115539061953912
Validation loss: 2.4821460849803705

Epoch: 5| Step: 1
Training loss: 2.592269474915487
Validation loss: 2.4805057853276784

Epoch: 5| Step: 2
Training loss: 2.3724904102577815
Validation loss: 2.483166622693483

Epoch: 5| Step: 3
Training loss: 2.3399488014749745
Validation loss: 2.4728998041153827

Epoch: 5| Step: 4
Training loss: 2.451074897701881
Validation loss: 2.4702431573531416

Epoch: 5| Step: 5
Training loss: 2.620382880560561
Validation loss: 2.462958334693634

Epoch: 5| Step: 6
Training loss: 2.686332715280041
Validation loss: 2.4726309953296797

Epoch: 5| Step: 7
Training loss: 2.5685685105264024
Validation loss: 2.4677414544200102

Epoch: 5| Step: 8
Training loss: 2.72882161373681
Validation loss: 2.475713999669363

Epoch: 5| Step: 9
Training loss: 2.0227058884890123
Validation loss: 2.4727810892949353

Epoch: 5| Step: 10
Training loss: 2.2057387626886586
Validation loss: 2.482852693316026

Epoch: 5| Step: 11
Training loss: 1.658457023314488
Validation loss: 2.474454441855676

Epoch: 180| Step: 0
Training loss: 2.72752088082465
Validation loss: 2.47559870228182

Epoch: 5| Step: 1
Training loss: 2.453772392617732
Validation loss: 2.4739237424874965

Epoch: 5| Step: 2
Training loss: 2.2270296376401215
Validation loss: 2.486712925159385

Epoch: 5| Step: 3
Training loss: 1.9171237676919595
Validation loss: 2.4865921331831378

Epoch: 5| Step: 4
Training loss: 2.9447273462371277
Validation loss: 2.483207692311173

Epoch: 5| Step: 5
Training loss: 2.774452818801593
Validation loss: 2.4778580029885173

Epoch: 5| Step: 6
Training loss: 2.4002897087716635
Validation loss: 2.464371484329408

Epoch: 5| Step: 7
Training loss: 2.8266373404595044
Validation loss: 2.4728420161672684

Epoch: 5| Step: 8
Training loss: 2.132138100221927
Validation loss: 2.4666129854413863

Epoch: 5| Step: 9
Training loss: 2.2563452787702527
Validation loss: 2.4657687725056583

Epoch: 5| Step: 10
Training loss: 2.2359190187683433
Validation loss: 2.4677586838714327

Epoch: 5| Step: 11
Training loss: 2.2302145470703834
Validation loss: 2.472378900530374

Epoch: 181| Step: 0
Training loss: 2.3848673980766084
Validation loss: 2.4751613837264883

Epoch: 5| Step: 1
Training loss: 2.5337092380039548
Validation loss: 2.466469423574325

Epoch: 5| Step: 2
Training loss: 2.2325839887414465
Validation loss: 2.475499052169542

Epoch: 5| Step: 3
Training loss: 2.13753871771118
Validation loss: 2.4639792843323023

Epoch: 5| Step: 4
Training loss: 2.4856662873236335
Validation loss: 2.4697852438836883

Epoch: 5| Step: 5
Training loss: 2.061391821725259
Validation loss: 2.4704032746152165

Epoch: 5| Step: 6
Training loss: 2.490107418638775
Validation loss: 2.468562634114207

Epoch: 5| Step: 7
Training loss: 2.621348975500015
Validation loss: 2.4656622565951465

Epoch: 5| Step: 8
Training loss: 2.3166521273186462
Validation loss: 2.47097592663382

Epoch: 5| Step: 9
Training loss: 2.233979090047189
Validation loss: 2.47254729872084

Epoch: 5| Step: 10
Training loss: 2.8547820010357183
Validation loss: 2.4700972707607085

Epoch: 5| Step: 11
Training loss: 3.7776013891018
Validation loss: 2.477029056505189

Epoch: 182| Step: 0
Training loss: 2.108575174787637
Validation loss: 2.4781807667509437

Epoch: 5| Step: 1
Training loss: 2.4055669236104213
Validation loss: 2.5008386993244707

Epoch: 5| Step: 2
Training loss: 3.1783640963808093
Validation loss: 2.494078959770905

Epoch: 5| Step: 3
Training loss: 2.022738538521711
Validation loss: 2.4959146776672747

Epoch: 5| Step: 4
Training loss: 2.2255734036985264
Validation loss: 2.497012952638824

Epoch: 5| Step: 5
Training loss: 2.1210478888343176
Validation loss: 2.4902339800666047

Epoch: 5| Step: 6
Training loss: 2.789083956253909
Validation loss: 2.48768901314509

Epoch: 5| Step: 7
Training loss: 2.2973648898274126
Validation loss: 2.4776073341651434

Epoch: 5| Step: 8
Training loss: 2.1988419909640635
Validation loss: 2.47356937697082

Epoch: 5| Step: 9
Training loss: 2.1809679871054524
Validation loss: 2.4744597693113723

Epoch: 5| Step: 10
Training loss: 2.8191684928194274
Validation loss: 2.481795113048824

Epoch: 5| Step: 11
Training loss: 3.062539080934873
Validation loss: 2.47990477550898

Epoch: 183| Step: 0
Training loss: 2.006421152580439
Validation loss: 2.479289025137558

Epoch: 5| Step: 1
Training loss: 2.438563872742334
Validation loss: 2.4823528873472887

Epoch: 5| Step: 2
Training loss: 2.9749052785972827
Validation loss: 2.473254333850258

Epoch: 5| Step: 3
Training loss: 2.3878319075192236
Validation loss: 2.479946682274174

Epoch: 5| Step: 4
Training loss: 2.7367701911937616
Validation loss: 2.4744013914939638

Epoch: 5| Step: 5
Training loss: 3.1018653548807644
Validation loss: 2.474318738418032

Epoch: 5| Step: 6
Training loss: 2.775149910116678
Validation loss: 2.480499051126746

Epoch: 5| Step: 7
Training loss: 2.075594056360274
Validation loss: 2.4890761570417124

Epoch: 5| Step: 8
Training loss: 1.9540719140132734
Validation loss: 2.478138483370787

Epoch: 5| Step: 9
Training loss: 2.1800452591633808
Validation loss: 2.4720475510768507

Epoch: 5| Step: 10
Training loss: 1.9729848455822505
Validation loss: 2.4811338399093823

Epoch: 5| Step: 11
Training loss: 2.36288504313716
Validation loss: 2.478732108383257

Epoch: 184| Step: 0
Training loss: 2.5011489135508
Validation loss: 2.4928391739625377

Epoch: 5| Step: 1
Training loss: 2.557861596104101
Validation loss: 2.4945404162478946

Epoch: 5| Step: 2
Training loss: 2.476063578798501
Validation loss: 2.48377840008279

Epoch: 5| Step: 3
Training loss: 1.8833415447607482
Validation loss: 2.497486794372868

Epoch: 5| Step: 4
Training loss: 2.605205196565318
Validation loss: 2.494917009638664

Epoch: 5| Step: 5
Training loss: 2.4139104998984067
Validation loss: 2.5038268998655955

Epoch: 5| Step: 6
Training loss: 2.4366734399279566
Validation loss: 2.496207469962471

Epoch: 5| Step: 7
Training loss: 2.193282631323811
Validation loss: 2.496472341434559

Epoch: 5| Step: 8
Training loss: 2.750133424469888
Validation loss: 2.4948833995564104

Epoch: 5| Step: 9
Training loss: 2.4225538717446775
Validation loss: 2.4850350069053033

Epoch: 5| Step: 10
Training loss: 2.563273057398425
Validation loss: 2.4865175041719425

Epoch: 5| Step: 11
Training loss: 1.4014090395536123
Validation loss: 2.488708746820621

Epoch: 185| Step: 0
Training loss: 2.0838096709881073
Validation loss: 2.4713354334441138

Epoch: 5| Step: 1
Training loss: 2.7526767881131438
Validation loss: 2.482372084347634

Epoch: 5| Step: 2
Training loss: 2.8984595449591235
Validation loss: 2.481300683068426

Epoch: 5| Step: 3
Training loss: 1.8337391129725054
Validation loss: 2.483234735639439

Epoch: 5| Step: 4
Training loss: 2.8080990585123975
Validation loss: 2.4786356041949618

Epoch: 5| Step: 5
Training loss: 2.6259829179567014
Validation loss: 2.474522601911788

Epoch: 5| Step: 6
Training loss: 1.9651123227346943
Validation loss: 2.4852033789526136

Epoch: 5| Step: 7
Training loss: 2.5077966232034905
Validation loss: 2.483273707917852

Epoch: 5| Step: 8
Training loss: 2.0700959866148305
Validation loss: 2.480267053448667

Epoch: 5| Step: 9
Training loss: 2.6608575689078435
Validation loss: 2.4722397158631257

Epoch: 5| Step: 10
Training loss: 2.2600971001889976
Validation loss: 2.478351412223834

Epoch: 5| Step: 11
Training loss: 2.0075816455927025
Validation loss: 2.4854259667191907

Epoch: 186| Step: 0
Training loss: 2.5405657734366405
Validation loss: 2.4723860686962316

Epoch: 5| Step: 1
Training loss: 2.458827685635267
Validation loss: 2.4796402656496923

Epoch: 5| Step: 2
Training loss: 2.1463370858388866
Validation loss: 2.4731888400869475

Epoch: 5| Step: 3
Training loss: 2.1493619282494976
Validation loss: 2.4826239526887717

Epoch: 5| Step: 4
Training loss: 1.9246006687680466
Validation loss: 2.4878509005613805

Epoch: 5| Step: 5
Training loss: 2.3796934632435134
Validation loss: 2.487194904070814

Epoch: 5| Step: 6
Training loss: 2.603789421731751
Validation loss: 2.4760999398013617

Epoch: 5| Step: 7
Training loss: 2.2195556682249187
Validation loss: 2.4853071667216544

Epoch: 5| Step: 8
Training loss: 2.32813892744366
Validation loss: 2.489573978794884

Epoch: 5| Step: 9
Training loss: 2.396298725426764
Validation loss: 2.4885286520586622

Epoch: 5| Step: 10
Training loss: 2.7813801252806405
Validation loss: 2.4815478082912183

Epoch: 5| Step: 11
Training loss: 4.7059741340831
Validation loss: 2.4849419096944025

Epoch: 187| Step: 0
Training loss: 2.751674055863211
Validation loss: 2.484655460385704

Epoch: 5| Step: 1
Training loss: 2.1811836604220067
Validation loss: 2.489374624200094

Epoch: 5| Step: 2
Training loss: 2.549588121547983
Validation loss: 2.482776111346526

Epoch: 5| Step: 3
Training loss: 1.9702172034721
Validation loss: 2.491726221746492

Epoch: 5| Step: 4
Training loss: 2.464690335149865
Validation loss: 2.4967579482758526

Epoch: 5| Step: 5
Training loss: 2.720129868688802
Validation loss: 2.485543394148757

Epoch: 5| Step: 6
Training loss: 2.4803075542787543
Validation loss: 2.496443885598637

Epoch: 5| Step: 7
Training loss: 2.513246632184313
Validation loss: 2.487153760496902

Epoch: 5| Step: 8
Training loss: 2.119819834629024
Validation loss: 2.4876604728118994

Epoch: 5| Step: 9
Training loss: 2.4059687858833536
Validation loss: 2.488759380656915

Epoch: 5| Step: 10
Training loss: 2.394410271878933
Validation loss: 2.497930651782807

Epoch: 5| Step: 11
Training loss: 1.2140675116279684
Validation loss: 2.491058173456067

Epoch: 188| Step: 0
Training loss: 2.1922781938429297
Validation loss: 2.494107797078542

Epoch: 5| Step: 1
Training loss: 2.6319594090644967
Validation loss: 2.4907197885572203

Epoch: 5| Step: 2
Training loss: 2.286439923072563
Validation loss: 2.499282801591282

Epoch: 5| Step: 3
Training loss: 2.6401971775171327
Validation loss: 2.5022022362523604

Epoch: 5| Step: 4
Training loss: 2.5129404849053367
Validation loss: 2.4953053621824215

Epoch: 5| Step: 5
Training loss: 2.6787757323324586
Validation loss: 2.5055057536779595

Epoch: 5| Step: 6
Training loss: 2.167040596997584
Validation loss: 2.496827429142007

Epoch: 5| Step: 7
Training loss: 2.4691322127363224
Validation loss: 2.4941644430952508

Epoch: 5| Step: 8
Training loss: 2.470328200771134
Validation loss: 2.5066758825339

Epoch: 5| Step: 9
Training loss: 2.1260299430597445
Validation loss: 2.494058490656428

Epoch: 5| Step: 10
Training loss: 2.312632479610258
Validation loss: 2.4869130044228496

Epoch: 5| Step: 11
Training loss: 2.1809150766580156
Validation loss: 2.4852801779217657

Epoch: 189| Step: 0
Training loss: 2.1299897122918208
Validation loss: 2.4797840444947683

Epoch: 5| Step: 1
Training loss: 2.127837138375767
Validation loss: 2.4920253561402532

Epoch: 5| Step: 2
Training loss: 2.2450374341872563
Validation loss: 2.4786529502972217

Epoch: 5| Step: 3
Training loss: 1.8405655338026985
Validation loss: 2.4773311445047232

Epoch: 5| Step: 4
Training loss: 2.932853920369219
Validation loss: 2.477964303353255

Epoch: 5| Step: 5
Training loss: 2.23408538435254
Validation loss: 2.483346692285086

Epoch: 5| Step: 6
Training loss: 2.5201350944880345
Validation loss: 2.488989784533947

Epoch: 5| Step: 7
Training loss: 2.87239039199512
Validation loss: 2.4758523971945428

Epoch: 5| Step: 8
Training loss: 2.24583664459192
Validation loss: 2.494560869461011

Epoch: 5| Step: 9
Training loss: 2.8664178880781215
Validation loss: 2.4892093279089966

Epoch: 5| Step: 10
Training loss: 2.260189507902667
Validation loss: 2.4805177218191097

Epoch: 5| Step: 11
Training loss: 2.0216065595622306
Validation loss: 2.4820238259980627

Epoch: 190| Step: 0
Training loss: 2.5591030400212103
Validation loss: 2.4927217116251286

Epoch: 5| Step: 1
Training loss: 1.4756390948917024
Validation loss: 2.4888598549363694

Epoch: 5| Step: 2
Training loss: 2.449890531313079
Validation loss: 2.477622983416113

Epoch: 5| Step: 3
Training loss: 2.9024242528581348
Validation loss: 2.4868309109954696

Epoch: 5| Step: 4
Training loss: 2.4894363381205746
Validation loss: 2.48522895755397

Epoch: 5| Step: 5
Training loss: 2.1041281542385266
Validation loss: 2.4861077777625904

Epoch: 5| Step: 6
Training loss: 2.7354010700401963
Validation loss: 2.4845887338120183

Epoch: 5| Step: 7
Training loss: 2.345889323115776
Validation loss: 2.483935195252837

Epoch: 5| Step: 8
Training loss: 2.594360555462934
Validation loss: 2.4850977680001174

Epoch: 5| Step: 9
Training loss: 2.1833375838531976
Validation loss: 2.4817450936668175

Epoch: 5| Step: 10
Training loss: 2.471694928155798
Validation loss: 2.487002624614125

Epoch: 5| Step: 11
Training loss: 1.8705131251066616
Validation loss: 2.4839937489354655

Epoch: 191| Step: 0
Training loss: 1.5422012931415616
Validation loss: 2.4880744412972566

Epoch: 5| Step: 1
Training loss: 2.502734214957756
Validation loss: 2.4948421876659204

Epoch: 5| Step: 2
Training loss: 2.5343934308944687
Validation loss: 2.506716808722645

Epoch: 5| Step: 3
Training loss: 2.8645649487454556
Validation loss: 2.5083251183608706

Epoch: 5| Step: 4
Training loss: 2.6466623844653383
Validation loss: 2.513001090385614

Epoch: 5| Step: 5
Training loss: 2.8989089623506756
Validation loss: 2.518988163891605

Epoch: 5| Step: 6
Training loss: 2.10395398969347
Validation loss: 2.507385958388432

Epoch: 5| Step: 7
Training loss: 2.53575458724848
Validation loss: 2.497263248863544

Epoch: 5| Step: 8
Training loss: 2.4246509025438163
Validation loss: 2.4777395778494933

Epoch: 5| Step: 9
Training loss: 1.8658865382707361
Validation loss: 2.4836094474476402

Epoch: 5| Step: 10
Training loss: 2.426034223109142
Validation loss: 2.4780088988370905

Epoch: 5| Step: 11
Training loss: 1.865062829562407
Validation loss: 2.4792489764764176

Epoch: 192| Step: 0
Training loss: 2.0401332572347792
Validation loss: 2.4909897539959722

Epoch: 5| Step: 1
Training loss: 2.1327398378619504
Validation loss: 2.4790322056271394

Epoch: 5| Step: 2
Training loss: 2.648508076585435
Validation loss: 2.4837057843757884

Epoch: 5| Step: 3
Training loss: 2.8922289548074107
Validation loss: 2.4905455470923474

Epoch: 5| Step: 4
Training loss: 2.796278735487671
Validation loss: 2.4886719153963126

Epoch: 5| Step: 5
Training loss: 2.1549198636690527
Validation loss: 2.483667328848482

Epoch: 5| Step: 6
Training loss: 2.564256949667575
Validation loss: 2.491552828151945

Epoch: 5| Step: 7
Training loss: 1.929654387525873
Validation loss: 2.488279724919098

Epoch: 5| Step: 8
Training loss: 2.3757979407785745
Validation loss: 2.5000637086062216

Epoch: 5| Step: 9
Training loss: 2.5763476169384525
Validation loss: 2.501319866656676

Epoch: 5| Step: 10
Training loss: 2.1924530629752623
Validation loss: 2.510753606342239

Epoch: 5| Step: 11
Training loss: 2.6458676453615815
Validation loss: 2.5116427950451357

Epoch: 193| Step: 0
Training loss: 1.9481595205871667
Validation loss: 2.512168100523132

Epoch: 5| Step: 1
Training loss: 2.4953878774705744
Validation loss: 2.5017859000773215

Epoch: 5| Step: 2
Training loss: 2.45571917750625
Validation loss: 2.5052864170925337

Epoch: 5| Step: 3
Training loss: 2.4528847351985217
Validation loss: 2.5094737436099437

Epoch: 5| Step: 4
Training loss: 2.562002273230992
Validation loss: 2.494676278033449

Epoch: 5| Step: 5
Training loss: 2.252482739889422
Validation loss: 2.4938215560972368

Epoch: 5| Step: 6
Training loss: 2.0240107722089986
Validation loss: 2.4838678574113104

Epoch: 5| Step: 7
Training loss: 2.3853501112091813
Validation loss: 2.490456102261198

Epoch: 5| Step: 8
Training loss: 2.8915069059566196
Validation loss: 2.494030106858348

Epoch: 5| Step: 9
Training loss: 2.113007871534613
Validation loss: 2.490725559835431

Epoch: 5| Step: 10
Training loss: 2.6987692959737455
Validation loss: 2.497109381139224

Epoch: 5| Step: 11
Training loss: 2.255824708878662
Validation loss: 2.4911746953692915

Epoch: 194| Step: 0
Training loss: 1.6240949311063566
Validation loss: 2.495459765103861

Epoch: 5| Step: 1
Training loss: 2.102073522216565
Validation loss: 2.496546048141874

Epoch: 5| Step: 2
Training loss: 2.1731857625712943
Validation loss: 2.4991073246489197

Epoch: 5| Step: 3
Training loss: 2.43051849579184
Validation loss: 2.4921586285137525

Epoch: 5| Step: 4
Training loss: 2.8332930917313064
Validation loss: 2.4915681166972106

Epoch: 5| Step: 5
Training loss: 2.3901825539048707
Validation loss: 2.4914218200726586

Epoch: 5| Step: 6
Training loss: 2.9227433979631043
Validation loss: 2.492143937530383

Epoch: 5| Step: 7
Training loss: 2.1907874336914483
Validation loss: 2.4998141100437885

Epoch: 5| Step: 8
Training loss: 2.2764571543179892
Validation loss: 2.520302024262981

Epoch: 5| Step: 9
Training loss: 2.6760136190161954
Validation loss: 2.524270049266237

Epoch: 5| Step: 10
Training loss: 2.4973250383374075
Validation loss: 2.5295041896541313

Epoch: 5| Step: 11
Training loss: 2.2436155231098645
Validation loss: 2.5202024093267767

Epoch: 195| Step: 0
Training loss: 2.0512673809981887
Validation loss: 2.5305345999965168

Epoch: 5| Step: 1
Training loss: 2.248660960700928
Validation loss: 2.501091381110086

Epoch: 5| Step: 2
Training loss: 2.5964381065051145
Validation loss: 2.5034697117897977

Epoch: 5| Step: 3
Training loss: 1.9500359482997371
Validation loss: 2.4866470128421314

Epoch: 5| Step: 4
Training loss: 2.3520314708991665
Validation loss: 2.4919252008465618

Epoch: 5| Step: 5
Training loss: 3.028237960172981
Validation loss: 2.49668265625562

Epoch: 5| Step: 6
Training loss: 2.4927736746968665
Validation loss: 2.4867756159435785

Epoch: 5| Step: 7
Training loss: 2.4351206194633255
Validation loss: 2.491167024977826

Epoch: 5| Step: 8
Training loss: 2.2643140485932465
Validation loss: 2.486456516863433

Epoch: 5| Step: 9
Training loss: 1.785361513987075
Validation loss: 2.4904435931311584

Epoch: 5| Step: 10
Training loss: 2.854107784211466
Validation loss: 2.492079872988278

Epoch: 5| Step: 11
Training loss: 2.6939299202507416
Validation loss: 2.499027953318344

Epoch: 196| Step: 0
Training loss: 2.476017937220862
Validation loss: 2.5214455756943392

Epoch: 5| Step: 1
Training loss: 2.7900894796044122
Validation loss: 2.547140298767268

Epoch: 5| Step: 2
Training loss: 2.452778396903978
Validation loss: 2.517487426891833

Epoch: 5| Step: 3
Training loss: 2.7765001177287134
Validation loss: 2.5049908412073028

Epoch: 5| Step: 4
Training loss: 2.201749981274328
Validation loss: 2.499052603341359

Epoch: 5| Step: 5
Training loss: 2.5806936703629635
Validation loss: 2.489199917422939

Epoch: 5| Step: 6
Training loss: 2.611659894138003
Validation loss: 2.4812816819635377

Epoch: 5| Step: 7
Training loss: 2.5442377958362057
Validation loss: 2.477574231042632

Epoch: 5| Step: 8
Training loss: 2.23821009444598
Validation loss: 2.471184491897394

Epoch: 5| Step: 9
Training loss: 2.0210352007005477
Validation loss: 2.481667060457057

Epoch: 5| Step: 10
Training loss: 1.716694243990424
Validation loss: 2.481667340666878

Epoch: 5| Step: 11
Training loss: 2.161857721282294
Validation loss: 2.475306291604922

Epoch: 197| Step: 0
Training loss: 2.2786008528856563
Validation loss: 2.486665181949145

Epoch: 5| Step: 1
Training loss: 2.3653216672707846
Validation loss: 2.4845504099022726

Epoch: 5| Step: 2
Training loss: 2.6460092040555674
Validation loss: 2.482954530872673

Epoch: 5| Step: 3
Training loss: 2.1781183973346394
Validation loss: 2.4842199201185418

Epoch: 5| Step: 4
Training loss: 2.085589662046165
Validation loss: 2.477070624915383

Epoch: 5| Step: 5
Training loss: 2.643942470172809
Validation loss: 2.4850979758686256

Epoch: 5| Step: 6
Training loss: 2.2060343693730116
Validation loss: 2.475985270237594

Epoch: 5| Step: 7
Training loss: 2.2890436477665985
Validation loss: 2.480050575871204

Epoch: 5| Step: 8
Training loss: 2.676864248927061
Validation loss: 2.4931308232607043

Epoch: 5| Step: 9
Training loss: 2.7608758700389235
Validation loss: 2.490854694172337

Epoch: 5| Step: 10
Training loss: 2.42814660964835
Validation loss: 2.491262018927921

Epoch: 5| Step: 11
Training loss: 1.49716705786043
Validation loss: 2.509364391667107

Epoch: 198| Step: 0
Training loss: 2.831977033425003
Validation loss: 2.5157362595432207

Epoch: 5| Step: 1
Training loss: 2.204636616596162
Validation loss: 2.514071780753288

Epoch: 5| Step: 2
Training loss: 2.0336661420812194
Validation loss: 2.514220783695186

Epoch: 5| Step: 3
Training loss: 1.9753190302005363
Validation loss: 2.520470042624968

Epoch: 5| Step: 4
Training loss: 2.636521079106657
Validation loss: 2.5096168998459225

Epoch: 5| Step: 5
Training loss: 2.538793555467864
Validation loss: 2.4988458472680875

Epoch: 5| Step: 6
Training loss: 2.6689605879948424
Validation loss: 2.4978742701411307

Epoch: 5| Step: 7
Training loss: 1.9596172614962226
Validation loss: 2.4987358592646096

Epoch: 5| Step: 8
Training loss: 2.0648051009672725
Validation loss: 2.5021261512232926

Epoch: 5| Step: 9
Training loss: 2.2868188271161705
Validation loss: 2.5046525102004944

Epoch: 5| Step: 10
Training loss: 2.925074330225013
Validation loss: 2.4966916704888753

Epoch: 5| Step: 11
Training loss: 2.066283483770495
Validation loss: 2.495328526215514

Epoch: 199| Step: 0
Training loss: 2.587846863574571
Validation loss: 2.5011451284056916

Epoch: 5| Step: 1
Training loss: 2.100555178507073
Validation loss: 2.4905149733085565

Epoch: 5| Step: 2
Training loss: 1.8799552923324594
Validation loss: 2.510722815707065

Epoch: 5| Step: 3
Training loss: 3.188739909444326
Validation loss: 2.499490511158972

Epoch: 5| Step: 4
Training loss: 2.252157554379745
Validation loss: 2.49461055621187

Epoch: 5| Step: 5
Training loss: 2.7459504916290873
Validation loss: 2.5053845592754733

Epoch: 5| Step: 6
Training loss: 2.2746564081653124
Validation loss: 2.5123146145308723

Epoch: 5| Step: 7
Training loss: 1.7664103828931845
Validation loss: 2.5098843953371435

Epoch: 5| Step: 8
Training loss: 2.233192290886513
Validation loss: 2.510837853319278

Epoch: 5| Step: 9
Training loss: 2.2190401129378325
Validation loss: 2.5046705010992043

Epoch: 5| Step: 10
Training loss: 2.7548149611681505
Validation loss: 2.515587097577452

Epoch: 5| Step: 11
Training loss: 2.339910999790051
Validation loss: 2.5018196636163053

Epoch: 200| Step: 0
Training loss: 2.330725734146972
Validation loss: 2.4943921095069252

Epoch: 5| Step: 1
Training loss: 1.7597979374331225
Validation loss: 2.483746463112056

Epoch: 5| Step: 2
Training loss: 2.0716567947303886
Validation loss: 2.4881344746448635

Epoch: 5| Step: 3
Training loss: 2.6377260445729123
Validation loss: 2.48501983007518

Epoch: 5| Step: 4
Training loss: 2.8066179437855716
Validation loss: 2.4804618855378893

Epoch: 5| Step: 5
Training loss: 2.532684767253821
Validation loss: 2.486495578477862

Epoch: 5| Step: 6
Training loss: 1.816751886113013
Validation loss: 2.4819583134855767

Epoch: 5| Step: 7
Training loss: 2.8908160172317086
Validation loss: 2.488275964113507

Epoch: 5| Step: 8
Training loss: 2.6591615763820444
Validation loss: 2.4802835911004935

Epoch: 5| Step: 9
Training loss: 2.453773364258511
Validation loss: 2.481210008133978

Epoch: 5| Step: 10
Training loss: 2.4729665166837904
Validation loss: 2.4924635619647413

Epoch: 5| Step: 11
Training loss: 1.18547176016288
Validation loss: 2.49959089985032

Epoch: 201| Step: 0
Training loss: 2.474827010919808
Validation loss: 2.516215758528914

Epoch: 5| Step: 1
Training loss: 2.1746494493034865
Validation loss: 2.5369501531345446

Epoch: 5| Step: 2
Training loss: 2.444858691728823
Validation loss: 2.5442727452364986

Epoch: 5| Step: 3
Training loss: 1.7064393717437651
Validation loss: 2.5486059099283485

Epoch: 5| Step: 4
Training loss: 2.5843606157375354
Validation loss: 2.528526728948622

Epoch: 5| Step: 5
Training loss: 2.3724842801794255
Validation loss: 2.524654504379624

Epoch: 5| Step: 6
Training loss: 2.585596989919544
Validation loss: 2.514607810275571

Epoch: 5| Step: 7
Training loss: 2.551619527802028
Validation loss: 2.4963317144763657

Epoch: 5| Step: 8
Training loss: 2.249951468050265
Validation loss: 2.4933858559383717

Epoch: 5| Step: 9
Training loss: 2.2301923109533512
Validation loss: 2.503688927799289

Epoch: 5| Step: 10
Training loss: 2.764549089194283
Validation loss: 2.5037851567179903

Epoch: 5| Step: 11
Training loss: 2.653069780222154
Validation loss: 2.4899266630056096

Epoch: 202| Step: 0
Training loss: 2.02520380289684
Validation loss: 2.491290805104126

Epoch: 5| Step: 1
Training loss: 2.2793844250336934
Validation loss: 2.488128389926196

Epoch: 5| Step: 2
Training loss: 2.3115866635905724
Validation loss: 2.50201237271129

Epoch: 5| Step: 3
Training loss: 2.5122686706632695
Validation loss: 2.490887732470656

Epoch: 5| Step: 4
Training loss: 2.6165706989483803
Validation loss: 2.5035995914534164

Epoch: 5| Step: 5
Training loss: 2.734960613211212
Validation loss: 2.4983453679150136

Epoch: 5| Step: 6
Training loss: 2.6003853365646803
Validation loss: 2.4912005456308677

Epoch: 5| Step: 7
Training loss: 2.203648714625519
Validation loss: 2.5017712795254363

Epoch: 5| Step: 8
Training loss: 1.9656630641241615
Validation loss: 2.5086689810539022

Epoch: 5| Step: 9
Training loss: 2.5299014042878194
Validation loss: 2.5168469819677974

Epoch: 5| Step: 10
Training loss: 2.3886573023753153
Validation loss: 2.541461879005297

Epoch: 5| Step: 11
Training loss: 1.5486333852096463
Validation loss: 2.510354153394271

Epoch: 203| Step: 0
Training loss: 2.2507348450071363
Validation loss: 2.5103670975367103

Epoch: 5| Step: 1
Training loss: 2.3909943737823776
Validation loss: 2.4999731300817367

Epoch: 5| Step: 2
Training loss: 2.5334483831615837
Validation loss: 2.495168849860622

Epoch: 5| Step: 3
Training loss: 2.299183626000615
Validation loss: 2.4899425220877243

Epoch: 5| Step: 4
Training loss: 2.3457135939543132
Validation loss: 2.487210552909002

Epoch: 5| Step: 5
Training loss: 2.231619142401906
Validation loss: 2.4889858332223525

Epoch: 5| Step: 6
Training loss: 2.5882684165574252
Validation loss: 2.493549323632082

Epoch: 5| Step: 7
Training loss: 2.74519622156994
Validation loss: 2.49242305539282

Epoch: 5| Step: 8
Training loss: 2.598313510893386
Validation loss: 2.4906865486060945

Epoch: 5| Step: 9
Training loss: 2.1678768104097395
Validation loss: 2.4914334710078396

Epoch: 5| Step: 10
Training loss: 2.13256521503149
Validation loss: 2.497899997380887

Epoch: 5| Step: 11
Training loss: 2.053109146591131
Validation loss: 2.501231871530804

Epoch: 204| Step: 0
Training loss: 1.916267277390241
Validation loss: 2.500214392688055

Epoch: 5| Step: 1
Training loss: 2.3567614700946313
Validation loss: 2.494648323374268

Epoch: 5| Step: 2
Training loss: 2.3649398154087073
Validation loss: 2.496588250549198

Epoch: 5| Step: 3
Training loss: 2.3313262231551275
Validation loss: 2.496089622880193

Epoch: 5| Step: 4
Training loss: 2.515957259514092
Validation loss: 2.4878408420537426

Epoch: 5| Step: 5
Training loss: 2.7230359199948193
Validation loss: 2.4773132999232583

Epoch: 5| Step: 6
Training loss: 2.7781270528127084
Validation loss: 2.481129571793131

Epoch: 5| Step: 7
Training loss: 2.26601411832231
Validation loss: 2.481241713509227

Epoch: 5| Step: 8
Training loss: 2.527391766382408
Validation loss: 2.4820940875267143

Epoch: 5| Step: 9
Training loss: 2.2210287293246784
Validation loss: 2.4989432604898196

Epoch: 5| Step: 10
Training loss: 2.667974737336574
Validation loss: 2.4805175015522156

Epoch: 5| Step: 11
Training loss: 1.8202048339437535
Validation loss: 2.479828362889768

Epoch: 205| Step: 0
Training loss: 2.2386734171196268
Validation loss: 2.4722547400999346

Epoch: 5| Step: 1
Training loss: 1.8870026747983282
Validation loss: 2.493399274633205

Epoch: 5| Step: 2
Training loss: 3.033730347471079
Validation loss: 2.4875333171958305

Epoch: 5| Step: 3
Training loss: 2.306614164221639
Validation loss: 2.498171809424958

Epoch: 5| Step: 4
Training loss: 2.5070727436724747
Validation loss: 2.479486995059057

Epoch: 5| Step: 5
Training loss: 2.001819498208008
Validation loss: 2.4956064997356

Epoch: 5| Step: 6
Training loss: 2.324898141249956
Validation loss: 2.477213359871188

Epoch: 5| Step: 7
Training loss: 1.9587685798002392
Validation loss: 2.4890671411707683

Epoch: 5| Step: 8
Training loss: 2.907291184829313
Validation loss: 2.4956023220519348

Epoch: 5| Step: 9
Training loss: 2.5131330764819086
Validation loss: 2.4901491297673344

Epoch: 5| Step: 10
Training loss: 2.371915621403378
Validation loss: 2.4956438179430767

Epoch: 5| Step: 11
Training loss: 2.8531765485036416
Validation loss: 2.485164305022224

Epoch: 206| Step: 0
Training loss: 2.2373716093766864
Validation loss: 2.504910077894119

Epoch: 5| Step: 1
Training loss: 2.1750008024016907
Validation loss: 2.50045527842575

Epoch: 5| Step: 2
Training loss: 2.7420291691904306
Validation loss: 2.50117457930493

Epoch: 5| Step: 3
Training loss: 2.393599311727027
Validation loss: 2.501575204188349

Epoch: 5| Step: 4
Training loss: 2.2997402044436606
Validation loss: 2.4938106811521394

Epoch: 5| Step: 5
Training loss: 2.0177073995824046
Validation loss: 2.5050646204713054

Epoch: 5| Step: 6
Training loss: 2.7587690126483815
Validation loss: 2.5010961473963906

Epoch: 5| Step: 7
Training loss: 2.4694958296603704
Validation loss: 2.4974601161879164

Epoch: 5| Step: 8
Training loss: 2.7775914850284655
Validation loss: 2.4939829538285903

Epoch: 5| Step: 9
Training loss: 2.3640679177211448
Validation loss: 2.4973196880571495

Epoch: 5| Step: 10
Training loss: 2.1597140585638415
Validation loss: 2.4833292089551775

Epoch: 5| Step: 11
Training loss: 2.964707684316007
Validation loss: 2.4964027114075544

Epoch: 207| Step: 0
Training loss: 2.128138972613248
Validation loss: 2.495600644209409

Epoch: 5| Step: 1
Training loss: 2.298807693429542
Validation loss: 2.520489642986602

Epoch: 5| Step: 2
Training loss: 2.424196963714846
Validation loss: 2.526781714402688

Epoch: 5| Step: 3
Training loss: 2.4717330293841573
Validation loss: 2.5626556884177023

Epoch: 5| Step: 4
Training loss: 3.037657896105882
Validation loss: 2.584194533302292

Epoch: 5| Step: 5
Training loss: 2.496221452529719
Validation loss: 2.5646885620724817

Epoch: 5| Step: 6
Training loss: 2.5732799896416894
Validation loss: 2.547273717769018

Epoch: 5| Step: 7
Training loss: 2.0838769457798096
Validation loss: 2.545029422012864

Epoch: 5| Step: 8
Training loss: 2.3209269830607475
Validation loss: 2.53329141345811

Epoch: 5| Step: 9
Training loss: 2.5799896895032575
Validation loss: 2.5051185938147285

Epoch: 5| Step: 10
Training loss: 2.4120965254591957
Validation loss: 2.50145610683945

Epoch: 5| Step: 11
Training loss: 1.9764479652964648
Validation loss: 2.4890048792847295

Epoch: 208| Step: 0
Training loss: 2.304871736048453
Validation loss: 2.49666397514334

Epoch: 5| Step: 1
Training loss: 2.3344072413739427
Validation loss: 2.5022652019710114

Epoch: 5| Step: 2
Training loss: 2.594978684942359
Validation loss: 2.5011271002330084

Epoch: 5| Step: 3
Training loss: 2.0492179216157065
Validation loss: 2.50435972347603

Epoch: 5| Step: 4
Training loss: 2.1380260868604255
Validation loss: 2.5016600660287422

Epoch: 5| Step: 5
Training loss: 2.4937508681063947
Validation loss: 2.501618457480466

Epoch: 5| Step: 6
Training loss: 3.0866684446336583
Validation loss: 2.5037345053678512

Epoch: 5| Step: 7
Training loss: 2.2834898521443425
Validation loss: 2.4993868652129523

Epoch: 5| Step: 8
Training loss: 1.9294034308639396
Validation loss: 2.501954236751233

Epoch: 5| Step: 9
Training loss: 2.499173313787952
Validation loss: 2.50277674566533

Epoch: 5| Step: 10
Training loss: 2.6336304613676265
Validation loss: 2.4962230881685863

Epoch: 5| Step: 11
Training loss: 2.6353550980403635
Validation loss: 2.4967724231184034

Epoch: 209| Step: 0
Training loss: 2.6561676012610294
Validation loss: 2.5070127992712847

Epoch: 5| Step: 1
Training loss: 2.5228541972592593
Validation loss: 2.507818065569793

Epoch: 5| Step: 2
Training loss: 2.6244082919301
Validation loss: 2.5004601333286307

Epoch: 5| Step: 3
Training loss: 2.0512883022714394
Validation loss: 2.521412859000251

Epoch: 5| Step: 4
Training loss: 2.315039812244142
Validation loss: 2.5328480224816823

Epoch: 5| Step: 5
Training loss: 2.2078398986973737
Validation loss: 2.530150787078118

Epoch: 5| Step: 6
Training loss: 2.549570821660835
Validation loss: 2.5192984658277444

Epoch: 5| Step: 7
Training loss: 2.213971001370539
Validation loss: 2.517554212742214

Epoch: 5| Step: 8
Training loss: 2.2281781675782053
Validation loss: 2.507712511741193

Epoch: 5| Step: 9
Training loss: 2.4916511365051415
Validation loss: 2.509700781235631

Epoch: 5| Step: 10
Training loss: 2.366214464085022
Validation loss: 2.5072172256616416

Epoch: 5| Step: 11
Training loss: 3.2834651191198243
Validation loss: 2.493334443500938

Epoch: 210| Step: 0
Training loss: 2.078992504809118
Validation loss: 2.4989546855429743

Epoch: 5| Step: 1
Training loss: 2.3088982860486955
Validation loss: 2.487458133345185

Epoch: 5| Step: 2
Training loss: 1.996551102948883
Validation loss: 2.508072773230982

Epoch: 5| Step: 3
Training loss: 1.9956006301362004
Validation loss: 2.5069599465207597

Epoch: 5| Step: 4
Training loss: 2.86042274498531
Validation loss: 2.5175817315485425

Epoch: 5| Step: 5
Training loss: 2.14244125054199
Validation loss: 2.512936247092208

Epoch: 5| Step: 6
Training loss: 2.4234486051461186
Validation loss: 2.516155281804566

Epoch: 5| Step: 7
Training loss: 2.5142179546576604
Validation loss: 2.490818528618138

Epoch: 5| Step: 8
Training loss: 2.356589384452986
Validation loss: 2.4982968310464875

Epoch: 5| Step: 9
Training loss: 2.7464713085321115
Validation loss: 2.4763846549148103

Epoch: 5| Step: 10
Training loss: 2.6697273769568586
Validation loss: 2.4798703991349758

Epoch: 5| Step: 11
Training loss: 1.9101676082468415
Validation loss: 2.470745495419074

Epoch: 211| Step: 0
Training loss: 2.2792351590964515
Validation loss: 2.4864456976026275

Epoch: 5| Step: 1
Training loss: 2.7867090035223447
Validation loss: 2.4833131396242787

Epoch: 5| Step: 2
Training loss: 2.177305389712431
Validation loss: 2.4704149201257684

Epoch: 5| Step: 3
Training loss: 2.4324573294336287
Validation loss: 2.481721120351788

Epoch: 5| Step: 4
Training loss: 1.709732537127004
Validation loss: 2.472752083623202

Epoch: 5| Step: 5
Training loss: 2.7274568943495088
Validation loss: 2.4700470748204415

Epoch: 5| Step: 6
Training loss: 2.391523105242543
Validation loss: 2.4727764411790196

Epoch: 5| Step: 7
Training loss: 2.437452853798355
Validation loss: 2.4757510920804706

Epoch: 5| Step: 8
Training loss: 2.249455810011085
Validation loss: 2.4591446718988013

Epoch: 5| Step: 9
Training loss: 2.8833725134625947
Validation loss: 2.4827046187057378

Epoch: 5| Step: 10
Training loss: 2.229784431302027
Validation loss: 2.4821786148531477

Epoch: 5| Step: 11
Training loss: 1.654314025285584
Validation loss: 2.478080877718641

Epoch: 212| Step: 0
Training loss: 1.943184052039672
Validation loss: 2.470801824676505

Epoch: 5| Step: 1
Training loss: 1.927970833078946
Validation loss: 2.4765987935099405

Epoch: 5| Step: 2
Training loss: 2.3196319712391076
Validation loss: 2.4764966103566324

Epoch: 5| Step: 3
Training loss: 2.770416591730536
Validation loss: 2.4763726282991416

Epoch: 5| Step: 4
Training loss: 1.7128274312209817
Validation loss: 2.482795077007308

Epoch: 5| Step: 5
Training loss: 3.2397241265386563
Validation loss: 2.4798186724397095

Epoch: 5| Step: 6
Training loss: 2.572875255503714
Validation loss: 2.487729417103356

Epoch: 5| Step: 7
Training loss: 2.3770572385656767
Validation loss: 2.4856603724119606

Epoch: 5| Step: 8
Training loss: 2.4376574734413996
Validation loss: 2.4880764935385584

Epoch: 5| Step: 9
Training loss: 2.326538876938131
Validation loss: 2.4777892330631417

Epoch: 5| Step: 10
Training loss: 2.324054308291216
Validation loss: 2.477051370787217

Epoch: 5| Step: 11
Training loss: 1.691656926632858
Validation loss: 2.4906579628505736

Epoch: 213| Step: 0
Training loss: 2.064134123813496
Validation loss: 2.4892028746660295

Epoch: 5| Step: 1
Training loss: 2.470661630395133
Validation loss: 2.4893800593963324

Epoch: 5| Step: 2
Training loss: 2.558273738038561
Validation loss: 2.4956578494447323

Epoch: 5| Step: 3
Training loss: 2.807933066469699
Validation loss: 2.496445682253443

Epoch: 5| Step: 4
Training loss: 2.7090343643999795
Validation loss: 2.4986142529980357

Epoch: 5| Step: 5
Training loss: 2.6502267200723875
Validation loss: 2.497739365823189

Epoch: 5| Step: 6
Training loss: 1.6634227973765514
Validation loss: 2.493859705667017

Epoch: 5| Step: 7
Training loss: 1.879382099002463
Validation loss: 2.497506988777817

Epoch: 5| Step: 8
Training loss: 2.1570457427613228
Validation loss: 2.5049965915034917

Epoch: 5| Step: 9
Training loss: 2.518412970245824
Validation loss: 2.5197381065283

Epoch: 5| Step: 10
Training loss: 2.401337898389144
Validation loss: 2.531611091069898

Epoch: 5| Step: 11
Training loss: 2.3857341927055975
Validation loss: 2.5508709434641146

Epoch: 214| Step: 0
Training loss: 2.773462515704744
Validation loss: 2.5413413595254304

Epoch: 5| Step: 1
Training loss: 2.428853078746676
Validation loss: 2.5242085691101295

Epoch: 5| Step: 2
Training loss: 2.581961349487595
Validation loss: 2.4975123028584223

Epoch: 5| Step: 3
Training loss: 2.430440510040404
Validation loss: 2.4926377650048006

Epoch: 5| Step: 4
Training loss: 2.146923072421097
Validation loss: 2.4879274860385974

Epoch: 5| Step: 5
Training loss: 2.437789019542604
Validation loss: 2.4849168078698627

Epoch: 5| Step: 6
Training loss: 1.4131292140109952
Validation loss: 2.480819929599485

Epoch: 5| Step: 7
Training loss: 2.2256729222799594
Validation loss: 2.487716323225915

Epoch: 5| Step: 8
Training loss: 2.390168888237929
Validation loss: 2.488392298928752

Epoch: 5| Step: 9
Training loss: 2.504743748424133
Validation loss: 2.4846829877238368

Epoch: 5| Step: 10
Training loss: 2.83444603407233
Validation loss: 2.4937853817831854

Epoch: 5| Step: 11
Training loss: 1.8018374045555399
Validation loss: 2.4918525973026493

Epoch: 215| Step: 0
Training loss: 2.561162366880543
Validation loss: 2.4995777568276956

Epoch: 5| Step: 1
Training loss: 2.057184594824645
Validation loss: 2.4918578875620425

Epoch: 5| Step: 2
Training loss: 2.685532847974731
Validation loss: 2.4971911346799907

Epoch: 5| Step: 3
Training loss: 2.6469254129736455
Validation loss: 2.506801908643749

Epoch: 5| Step: 4
Training loss: 2.4446364373130063
Validation loss: 2.5252542717065456

Epoch: 5| Step: 5
Training loss: 2.8379951347540566
Validation loss: 2.503650757385537

Epoch: 5| Step: 6
Training loss: 2.7439575568661874
Validation loss: 2.5264155173498883

Epoch: 5| Step: 7
Training loss: 2.255416813494569
Validation loss: 2.5249319109848103

Epoch: 5| Step: 8
Training loss: 2.186958245903138
Validation loss: 2.509345816841991

Epoch: 5| Step: 9
Training loss: 2.0482718091539525
Validation loss: 2.4933229329301114

Epoch: 5| Step: 10
Training loss: 2.315762769793818
Validation loss: 2.4758036841863422

Epoch: 5| Step: 11
Training loss: 1.487810516003554
Validation loss: 2.489535579994864

Epoch: 216| Step: 0
Training loss: 2.48098331430737
Validation loss: 2.4909075935255274

Epoch: 5| Step: 1
Training loss: 1.645279014369822
Validation loss: 2.495346363389632

Epoch: 5| Step: 2
Training loss: 2.6740259803702484
Validation loss: 2.5059588861763955

Epoch: 5| Step: 3
Training loss: 1.890892136041782
Validation loss: 2.510339424453975

Epoch: 5| Step: 4
Training loss: 2.6856503886300485
Validation loss: 2.5235693142283218

Epoch: 5| Step: 5
Training loss: 2.907191954519826
Validation loss: 2.517729195106028

Epoch: 5| Step: 6
Training loss: 2.738922522929206
Validation loss: 2.5125292849059733

Epoch: 5| Step: 7
Training loss: 2.2538924985363646
Validation loss: 2.4982768199751826

Epoch: 5| Step: 8
Training loss: 2.534863565298483
Validation loss: 2.510698339612803

Epoch: 5| Step: 9
Training loss: 2.1158584984265296
Validation loss: 2.504600956199618

Epoch: 5| Step: 10
Training loss: 2.7209480432823305
Validation loss: 2.509702222050451

Epoch: 5| Step: 11
Training loss: 1.9770035082101447
Validation loss: 2.5315392646811015

Epoch: 217| Step: 0
Training loss: 2.6713702522597282
Validation loss: 2.534545413401535

Epoch: 5| Step: 1
Training loss: 2.310334299841988
Validation loss: 2.5453116371460873

Epoch: 5| Step: 2
Training loss: 2.91242030611822
Validation loss: 2.544180300665954

Epoch: 5| Step: 3
Training loss: 2.3633420826042
Validation loss: 2.562477476129553

Epoch: 5| Step: 4
Training loss: 2.9926934275182346
Validation loss: 2.5547507547524937

Epoch: 5| Step: 5
Training loss: 1.9889900428058607
Validation loss: 2.5506755228607556

Epoch: 5| Step: 6
Training loss: 2.553998288386286
Validation loss: 2.53442638766884

Epoch: 5| Step: 7
Training loss: 1.839994582292625
Validation loss: 2.516829251780694

Epoch: 5| Step: 8
Training loss: 2.291934662378609
Validation loss: 2.5076893452384494

Epoch: 5| Step: 9
Training loss: 1.8694920065077145
Validation loss: 2.4918907172175655

Epoch: 5| Step: 10
Training loss: 2.277013947830738
Validation loss: 2.485089956928562

Epoch: 5| Step: 11
Training loss: 2.268770546728155
Validation loss: 2.4909501068175244

Epoch: 218| Step: 0
Training loss: 2.3674048396384704
Validation loss: 2.4836797881125587

Epoch: 5| Step: 1
Training loss: 2.251004948302583
Validation loss: 2.4898818181613542

Epoch: 5| Step: 2
Training loss: 2.3679737761823927
Validation loss: 2.4917353436139233

Epoch: 5| Step: 3
Training loss: 2.1634747640091376
Validation loss: 2.4909811857284567

Epoch: 5| Step: 4
Training loss: 2.8046551120768797
Validation loss: 2.4893274089252446

Epoch: 5| Step: 5
Training loss: 2.939481999961998
Validation loss: 2.5006662196332954

Epoch: 5| Step: 6
Training loss: 2.3090276681490485
Validation loss: 2.4990110110070463

Epoch: 5| Step: 7
Training loss: 1.9666991072204398
Validation loss: 2.503082649755331

Epoch: 5| Step: 8
Training loss: 2.3900534750729943
Validation loss: 2.4984100173287955

Epoch: 5| Step: 9
Training loss: 2.749421752476681
Validation loss: 2.5091952099966672

Epoch: 5| Step: 10
Training loss: 2.0627737152655947
Validation loss: 2.49457890128239

Epoch: 5| Step: 11
Training loss: 1.665026748029975
Validation loss: 2.5037157776782797

Epoch: 219| Step: 0
Training loss: 2.480334853515788
Validation loss: 2.5102184871679607

Epoch: 5| Step: 1
Training loss: 2.027209327078049
Validation loss: 2.5129016604191836

Epoch: 5| Step: 2
Training loss: 2.567953401107109
Validation loss: 2.5176464828156235

Epoch: 5| Step: 3
Training loss: 2.924672302408776
Validation loss: 2.5111397114839176

Epoch: 5| Step: 4
Training loss: 1.9333877607883743
Validation loss: 2.487537139027471

Epoch: 5| Step: 5
Training loss: 2.9714317657118174
Validation loss: 2.500951605725297

Epoch: 5| Step: 6
Training loss: 1.8721527097395674
Validation loss: 2.4968568593537124

Epoch: 5| Step: 7
Training loss: 2.0178227234809296
Validation loss: 2.505824282314479

Epoch: 5| Step: 8
Training loss: 2.3511311588542343
Validation loss: 2.512539149686301

Epoch: 5| Step: 9
Training loss: 2.134494886480208
Validation loss: 2.4979480746736242

Epoch: 5| Step: 10
Training loss: 2.190990823410505
Validation loss: 2.5053488017227785

Epoch: 5| Step: 11
Training loss: 3.0997265972045005
Validation loss: 2.5006931099121106

Epoch: 220| Step: 0
Training loss: 2.3692449812458074
Validation loss: 2.5040718059588243

Epoch: 5| Step: 1
Training loss: 1.9257761121453079
Validation loss: 2.5032355907582584

Epoch: 5| Step: 2
Training loss: 2.2811477847257677
Validation loss: 2.504382639144139

Epoch: 5| Step: 3
Training loss: 2.8075474685637154
Validation loss: 2.5006578573292786

Epoch: 5| Step: 4
Training loss: 2.7629710248987287
Validation loss: 2.506356205675774

Epoch: 5| Step: 5
Training loss: 2.3400310256727024
Validation loss: 2.5038096884895653

Epoch: 5| Step: 6
Training loss: 2.6508144638539575
Validation loss: 2.50926568065159

Epoch: 5| Step: 7
Training loss: 1.853116120032509
Validation loss: 2.503767393549791

Epoch: 5| Step: 8
Training loss: 2.933166716640884
Validation loss: 2.4956325767625627

Epoch: 5| Step: 9
Training loss: 2.288127929718968
Validation loss: 2.5001887170771036

Epoch: 5| Step: 10
Training loss: 1.8869387417438845
Validation loss: 2.5157946456351317

Epoch: 5| Step: 11
Training loss: 1.4821922717499172
Validation loss: 2.5204842531979486

Epoch: 221| Step: 0
Training loss: 2.9328262808409415
Validation loss: 2.55934743482117

Epoch: 5| Step: 1
Training loss: 1.5594798081519656
Validation loss: 2.5804862990106465

Epoch: 5| Step: 2
Training loss: 2.299083141355057
Validation loss: 2.6276453630578325

Epoch: 5| Step: 3
Training loss: 2.8930780672892626
Validation loss: 2.6192998304346693

Epoch: 5| Step: 4
Training loss: 2.176464473491382
Validation loss: 2.593797641148101

Epoch: 5| Step: 5
Training loss: 2.1608451862159685
Validation loss: 2.5555820901386954

Epoch: 5| Step: 6
Training loss: 1.8758864532546073
Validation loss: 2.5309482441693065

Epoch: 5| Step: 7
Training loss: 1.8473911216151642
Validation loss: 2.5118477344765378

Epoch: 5| Step: 8
Training loss: 2.5568081980808968
Validation loss: 2.5144431376677407

Epoch: 5| Step: 9
Training loss: 2.797861191764625
Validation loss: 2.5103161298371885

Epoch: 5| Step: 10
Training loss: 2.4495029801683272
Validation loss: 2.5010288743964715

Epoch: 5| Step: 11
Training loss: 3.6922871179496526
Validation loss: 2.4923588246418618

Epoch: 222| Step: 0
Training loss: 2.44282468560693
Validation loss: 2.4936896473808496

Epoch: 5| Step: 1
Training loss: 2.874100751805817
Validation loss: 2.4985695302851485

Epoch: 5| Step: 2
Training loss: 2.225169498973914
Validation loss: 2.4979732563225276

Epoch: 5| Step: 3
Training loss: 1.9132834581305525
Validation loss: 2.493801138647515

Epoch: 5| Step: 4
Training loss: 2.9826186839021194
Validation loss: 2.502944426307738

Epoch: 5| Step: 5
Training loss: 2.3110166380088146
Validation loss: 2.4965080192065816

Epoch: 5| Step: 6
Training loss: 2.1736248843319
Validation loss: 2.5043940155828053

Epoch: 5| Step: 7
Training loss: 2.0859785325947255
Validation loss: 2.513362111585405

Epoch: 5| Step: 8
Training loss: 2.4080332303970162
Validation loss: 2.506094541191412

Epoch: 5| Step: 9
Training loss: 2.6160870871965693
Validation loss: 2.5089847839282284

Epoch: 5| Step: 10
Training loss: 2.2897646090868937
Validation loss: 2.512464809013121

Epoch: 5| Step: 11
Training loss: 1.0704396861447094
Validation loss: 2.5188508369322093

Epoch: 223| Step: 0
Training loss: 2.2456972518581337
Validation loss: 2.538878562329125

Epoch: 5| Step: 1
Training loss: 1.9392427789460969
Validation loss: 2.5283641101692353

Epoch: 5| Step: 2
Training loss: 2.1974949967085435
Validation loss: 2.5527150183296223

Epoch: 5| Step: 3
Training loss: 2.3115706767326567
Validation loss: 2.5556884111433256

Epoch: 5| Step: 4
Training loss: 2.5558957850145183
Validation loss: 2.5447391767445615

Epoch: 5| Step: 5
Training loss: 2.733410561641341
Validation loss: 2.530708498391804

Epoch: 5| Step: 6
Training loss: 2.3243161990469057
Validation loss: 2.525087417530834

Epoch: 5| Step: 7
Training loss: 2.3356503721619433
Validation loss: 2.506956336579394

Epoch: 5| Step: 8
Training loss: 2.245303125965829
Validation loss: 2.5124861522311925

Epoch: 5| Step: 9
Training loss: 2.638264882333741
Validation loss: 2.5051351775804633

Epoch: 5| Step: 10
Training loss: 2.21236974472852
Validation loss: 2.4987134682849073

Epoch: 5| Step: 11
Training loss: 3.1726068864376473
Validation loss: 2.505344019735925

Epoch: 224| Step: 0
Training loss: 2.3588728212402397
Validation loss: 2.5103536587375497

Epoch: 5| Step: 1
Training loss: 2.1089913478509246
Validation loss: 2.520575513476121

Epoch: 5| Step: 2
Training loss: 1.997558713104983
Validation loss: 2.5227029122905957

Epoch: 5| Step: 3
Training loss: 1.9084316964043273
Validation loss: 2.5148116429769862

Epoch: 5| Step: 4
Training loss: 2.5453697390176706
Validation loss: 2.5136378556928083

Epoch: 5| Step: 5
Training loss: 2.042421811123555
Validation loss: 2.5186947244616458

Epoch: 5| Step: 6
Training loss: 2.810522698357403
Validation loss: 2.518570610864797

Epoch: 5| Step: 7
Training loss: 2.452676525548579
Validation loss: 2.5263839542209534

Epoch: 5| Step: 8
Training loss: 2.534558241836673
Validation loss: 2.5240071640822315

Epoch: 5| Step: 9
Training loss: 2.087112610100665
Validation loss: 2.543127477861386

Epoch: 5| Step: 10
Training loss: 2.7999068721542892
Validation loss: 2.5249467161114842

Epoch: 5| Step: 11
Training loss: 1.625269500685846
Validation loss: 2.537919355451677

Epoch: 225| Step: 0
Training loss: 2.9429412119493223
Validation loss: 2.5239608229875325

Epoch: 5| Step: 1
Training loss: 2.092720006135166
Validation loss: 2.530445858101127

Epoch: 5| Step: 2
Training loss: 2.47259772112429
Validation loss: 2.5116109078345343

Epoch: 5| Step: 3
Training loss: 2.297393532694689
Validation loss: 2.5051959758514566

Epoch: 5| Step: 4
Training loss: 2.696967371555478
Validation loss: 2.4837937664789256

Epoch: 5| Step: 5
Training loss: 2.8912201139931555
Validation loss: 2.4905332458264215

Epoch: 5| Step: 6
Training loss: 1.6886216427287286
Validation loss: 2.484921980969274

Epoch: 5| Step: 7
Training loss: 1.841096876501598
Validation loss: 2.4886061906865877

Epoch: 5| Step: 8
Training loss: 2.3341141030238988
Validation loss: 2.48068137872033

Epoch: 5| Step: 9
Training loss: 2.0885524860460163
Validation loss: 2.495156376301377

Epoch: 5| Step: 10
Training loss: 2.459731421036706
Validation loss: 2.5016295367473154

Epoch: 5| Step: 11
Training loss: 1.0404799122518813
Validation loss: 2.4948649677718557

Epoch: 226| Step: 0
Training loss: 2.934368980978418
Validation loss: 2.4973386904504076

Epoch: 5| Step: 1
Training loss: 2.2626120692364595
Validation loss: 2.5029715401688515

Epoch: 5| Step: 2
Training loss: 1.825584994579401
Validation loss: 2.5227330546315434

Epoch: 5| Step: 3
Training loss: 2.0397620627075446
Validation loss: 2.530187477998517

Epoch: 5| Step: 4
Training loss: 2.4884896423173344
Validation loss: 2.5239225104530885

Epoch: 5| Step: 5
Training loss: 2.372707565601799
Validation loss: 2.543585363148065

Epoch: 5| Step: 6
Training loss: 2.5106676432620656
Validation loss: 2.5517549452708996

Epoch: 5| Step: 7
Training loss: 2.199192514483277
Validation loss: 2.5505498417975625

Epoch: 5| Step: 8
Training loss: 2.0642141674840677
Validation loss: 2.5477736473232553

Epoch: 5| Step: 9
Training loss: 2.5614477648884812
Validation loss: 2.5356006164293574

Epoch: 5| Step: 10
Training loss: 2.338328487022346
Validation loss: 2.537547155233368

Epoch: 5| Step: 11
Training loss: 1.8086277606312138
Validation loss: 2.5408830385756414

Epoch: 227| Step: 0
Training loss: 1.8381239188618157
Validation loss: 2.5370940691785058

Epoch: 5| Step: 1
Training loss: 2.235084261063268
Validation loss: 2.533139402773848

Epoch: 5| Step: 2
Training loss: 2.3036356966636706
Validation loss: 2.534130392409774

Epoch: 5| Step: 3
Training loss: 2.2191168253514966
Validation loss: 2.53482672651553

Epoch: 5| Step: 4
Training loss: 1.7511741241638048
Validation loss: 2.5256889582050452

Epoch: 5| Step: 5
Training loss: 2.746494920493595
Validation loss: 2.52969217439392

Epoch: 5| Step: 6
Training loss: 2.27515118693932
Validation loss: 2.525289432694232

Epoch: 5| Step: 7
Training loss: 2.5270649728215484
Validation loss: 2.5090873702268897

Epoch: 5| Step: 8
Training loss: 2.5118513532077436
Validation loss: 2.51286789357891

Epoch: 5| Step: 9
Training loss: 2.7876588511001823
Validation loss: 2.5103476872339177

Epoch: 5| Step: 10
Training loss: 2.020902835660141
Validation loss: 2.522093104747895

Epoch: 5| Step: 11
Training loss: 3.109047570552672
Validation loss: 2.518619311202381

Epoch: 228| Step: 0
Training loss: 2.4703161366271265
Validation loss: 2.526926476898321

Epoch: 5| Step: 1
Training loss: 2.7672656521566035
Validation loss: 2.534639330311276

Epoch: 5| Step: 2
Training loss: 2.6477189341103844
Validation loss: 2.528990172418737

Epoch: 5| Step: 3
Training loss: 2.2509418211798424
Validation loss: 2.518984243861077

Epoch: 5| Step: 4
Training loss: 1.8700765182017134
Validation loss: 2.518510772491822

Epoch: 5| Step: 5
Training loss: 1.9727840571027693
Validation loss: 2.5193512016843616

Epoch: 5| Step: 6
Training loss: 2.2352844734840085
Validation loss: 2.5065276993324965

Epoch: 5| Step: 7
Training loss: 2.9344256931918973
Validation loss: 2.504319326018178

Epoch: 5| Step: 8
Training loss: 2.0925195978812456
Validation loss: 2.50139474903978

Epoch: 5| Step: 9
Training loss: 2.36130762840696
Validation loss: 2.4998501931446886

Epoch: 5| Step: 10
Training loss: 1.9640297388517298
Validation loss: 2.496033040454111

Epoch: 5| Step: 11
Training loss: 2.2630801937510716
Validation loss: 2.5102410723319744

Epoch: 229| Step: 0
Training loss: 2.494050862990536
Validation loss: 2.5001644279130555

Epoch: 5| Step: 1
Training loss: 2.6664181136485725
Validation loss: 2.5097145837326167

Epoch: 5| Step: 2
Training loss: 2.1200687186781764
Validation loss: 2.5219109743397303

Epoch: 5| Step: 3
Training loss: 2.61451735292951
Validation loss: 2.5298050810497963

Epoch: 5| Step: 4
Training loss: 2.262817537565278
Validation loss: 2.5383416546426165

Epoch: 5| Step: 5
Training loss: 1.7673359236039317
Validation loss: 2.527746931931184

Epoch: 5| Step: 6
Training loss: 1.812827245175229
Validation loss: 2.54036558311882

Epoch: 5| Step: 7
Training loss: 2.6901215475480424
Validation loss: 2.5350151042312694

Epoch: 5| Step: 8
Training loss: 2.398847016901671
Validation loss: 2.5503328171621784

Epoch: 5| Step: 9
Training loss: 1.8881087780343668
Validation loss: 2.553187907178163

Epoch: 5| Step: 10
Training loss: 2.5715941969952754
Validation loss: 2.5359081569814372

Epoch: 5| Step: 11
Training loss: 2.268391150476491
Validation loss: 2.5424931790033125

Epoch: 230| Step: 0
Training loss: 2.475635824509676
Validation loss: 2.5094427809026985

Epoch: 5| Step: 1
Training loss: 1.7018190328898595
Validation loss: 2.5088973664807934

Epoch: 5| Step: 2
Training loss: 2.253862139238798
Validation loss: 2.489726103728402

Epoch: 5| Step: 3
Training loss: 2.228735362126264
Validation loss: 2.508380948266406

Epoch: 5| Step: 4
Training loss: 2.7945542750211203
Validation loss: 2.493815389650673

Epoch: 5| Step: 5
Training loss: 2.5956205494119398
Validation loss: 2.4895956938262507

Epoch: 5| Step: 6
Training loss: 2.7755048756502485
Validation loss: 2.5013478043425432

Epoch: 5| Step: 7
Training loss: 2.298459810295198
Validation loss: 2.5028157331661953

Epoch: 5| Step: 8
Training loss: 2.3525074425801544
Validation loss: 2.4965102117454263

Epoch: 5| Step: 9
Training loss: 2.217336930017236
Validation loss: 2.519955909289048

Epoch: 5| Step: 10
Training loss: 1.759972766535475
Validation loss: 2.5353144482204244

Epoch: 5| Step: 11
Training loss: 1.8129808511538092
Validation loss: 2.521354524207502

Epoch: 231| Step: 0
Training loss: 1.8400072158796377
Validation loss: 2.5348621035144236

Epoch: 5| Step: 1
Training loss: 2.645085376738913
Validation loss: 2.556752489254305

Epoch: 5| Step: 2
Training loss: 2.154258582431094
Validation loss: 2.5594400806715027

Epoch: 5| Step: 3
Training loss: 2.689569253291224
Validation loss: 2.575686902952554

Epoch: 5| Step: 4
Training loss: 2.1389098709970877
Validation loss: 2.5838387934396523

Epoch: 5| Step: 5
Training loss: 2.8514737050066303
Validation loss: 2.5955290916623706

Epoch: 5| Step: 6
Training loss: 2.8519153115430806
Validation loss: 2.5773271694075928

Epoch: 5| Step: 7
Training loss: 2.2161594365050212
Validation loss: 2.528552085377469

Epoch: 5| Step: 8
Training loss: 2.1211912016848515
Validation loss: 2.5134832315862616

Epoch: 5| Step: 9
Training loss: 1.7550788476952246
Validation loss: 2.5029148156434577

Epoch: 5| Step: 10
Training loss: 2.41519957987329
Validation loss: 2.503730228166347

Epoch: 5| Step: 11
Training loss: 1.6109087404038964
Validation loss: 2.493279368384783

Epoch: 232| Step: 0
Training loss: 1.4217561106180743
Validation loss: 2.498850858353471

Epoch: 5| Step: 1
Training loss: 2.1591493215370936
Validation loss: 2.4861073861695084

Epoch: 5| Step: 2
Training loss: 2.233591862798149
Validation loss: 2.5102782639990826

Epoch: 5| Step: 3
Training loss: 2.3518246729502104
Validation loss: 2.507581420900075

Epoch: 5| Step: 4
Training loss: 2.8390398527427236
Validation loss: 2.502837748084826

Epoch: 5| Step: 5
Training loss: 1.9260698144842345
Validation loss: 2.498402971542426

Epoch: 5| Step: 6
Training loss: 3.2289638496612865
Validation loss: 2.5146788284786212

Epoch: 5| Step: 7
Training loss: 2.279858726675544
Validation loss: 2.5426579064215127

Epoch: 5| Step: 8
Training loss: 2.389749902863495
Validation loss: 2.5463267245224586

Epoch: 5| Step: 9
Training loss: 2.6950730369451947
Validation loss: 2.54488253129988

Epoch: 5| Step: 10
Training loss: 1.992550207292846
Validation loss: 2.5389580846982374

Epoch: 5| Step: 11
Training loss: 2.215371043900344
Validation loss: 2.5256465183314636

Epoch: 233| Step: 0
Training loss: 2.546291541920343
Validation loss: 2.50743179362908

Epoch: 5| Step: 1
Training loss: 2.6295784576891448
Validation loss: 2.501592597724768

Epoch: 5| Step: 2
Training loss: 2.0475249678099
Validation loss: 2.482083605457355

Epoch: 5| Step: 3
Training loss: 2.113666379460029
Validation loss: 2.478660585269099

Epoch: 5| Step: 4
Training loss: 2.471904525869854
Validation loss: 2.4709829460979944

Epoch: 5| Step: 5
Training loss: 2.3683909765642777
Validation loss: 2.4776617552826066

Epoch: 5| Step: 6
Training loss: 2.3099369588729655
Validation loss: 2.4794085341899814

Epoch: 5| Step: 7
Training loss: 2.4442485408117265
Validation loss: 2.4795094835385014

Epoch: 5| Step: 8
Training loss: 2.5352079741810285
Validation loss: 2.4692205632490434

Epoch: 5| Step: 9
Training loss: 2.4897956491593347
Validation loss: 2.4726273854897616

Epoch: 5| Step: 10
Training loss: 2.372422576541403
Validation loss: 2.4693590813164477

Epoch: 5| Step: 11
Training loss: 1.4833560859706798
Validation loss: 2.4755353592641

Epoch: 234| Step: 0
Training loss: 2.4236353229623755
Validation loss: 2.49445757424081

Epoch: 5| Step: 1
Training loss: 2.1500781643875357
Validation loss: 2.4791432641364657

Epoch: 5| Step: 2
Training loss: 2.3347575291733698
Validation loss: 2.488402107693206

Epoch: 5| Step: 3
Training loss: 3.0449431726323803
Validation loss: 2.4833353054328957

Epoch: 5| Step: 4
Training loss: 2.0906437848762516
Validation loss: 2.492961030057715

Epoch: 5| Step: 5
Training loss: 2.354793723886588
Validation loss: 2.508339890812596

Epoch: 5| Step: 6
Training loss: 2.3571247207472314
Validation loss: 2.5014910860687545

Epoch: 5| Step: 7
Training loss: 2.1408703517225236
Validation loss: 2.512378382546607

Epoch: 5| Step: 8
Training loss: 2.6604172274699227
Validation loss: 2.5309908777421963

Epoch: 5| Step: 9
Training loss: 2.316168272714506
Validation loss: 2.53107444327072

Epoch: 5| Step: 10
Training loss: 2.1496807038723387
Validation loss: 2.5402026741575705

Epoch: 5| Step: 11
Training loss: 1.1311361603335433
Validation loss: 2.522580728653688

Epoch: 235| Step: 0
Training loss: 2.1574198548602594
Validation loss: 2.506515246630222

Epoch: 5| Step: 1
Training loss: 2.0802113091898495
Validation loss: 2.5136028399864014

Epoch: 5| Step: 2
Training loss: 2.0476792480853905
Validation loss: 2.4873651627716162

Epoch: 5| Step: 3
Training loss: 2.683563720890486
Validation loss: 2.490348587907557

Epoch: 5| Step: 4
Training loss: 2.0382375400311625
Validation loss: 2.4963998383015116

Epoch: 5| Step: 5
Training loss: 2.302020272014057
Validation loss: 2.495683770695057

Epoch: 5| Step: 6
Training loss: 2.6987181446338604
Validation loss: 2.493169577094779

Epoch: 5| Step: 7
Training loss: 2.194254881750063
Validation loss: 2.4962755832497723

Epoch: 5| Step: 8
Training loss: 2.3375280572359936
Validation loss: 2.493802184321375

Epoch: 5| Step: 9
Training loss: 2.308361784097488
Validation loss: 2.4997908345778055

Epoch: 5| Step: 10
Training loss: 2.7340867244804032
Validation loss: 2.48452800303581

Epoch: 5| Step: 11
Training loss: 2.4113452025228534
Validation loss: 2.526543456638642

Epoch: 236| Step: 0
Training loss: 2.2262872893922894
Validation loss: 2.507092559720975

Epoch: 5| Step: 1
Training loss: 1.894447309069862
Validation loss: 2.5234407202480624

Epoch: 5| Step: 2
Training loss: 2.3436537659279666
Validation loss: 2.508022117370952

Epoch: 5| Step: 3
Training loss: 1.7547834959462274
Validation loss: 2.5089796406452147

Epoch: 5| Step: 4
Training loss: 2.2823616350232765
Validation loss: 2.5261237193411143

Epoch: 5| Step: 5
Training loss: 2.514371476707863
Validation loss: 2.5320453846242783

Epoch: 5| Step: 6
Training loss: 2.6653769374325673
Validation loss: 2.544688403646952

Epoch: 5| Step: 7
Training loss: 2.509863184357489
Validation loss: 2.5356560808507984

Epoch: 5| Step: 8
Training loss: 2.87847110353046
Validation loss: 2.5451000909477712

Epoch: 5| Step: 9
Training loss: 1.9044679535532885
Validation loss: 2.5251841764351806

Epoch: 5| Step: 10
Training loss: 2.420283034301048
Validation loss: 2.5507962283385486

Epoch: 5| Step: 11
Training loss: 1.5250318742766704
Validation loss: 2.547815297517988

Epoch: 237| Step: 0
Training loss: 2.5013329766963928
Validation loss: 2.5500381228458275

Epoch: 5| Step: 1
Training loss: 2.0003251765069545
Validation loss: 2.5318652806299125

Epoch: 5| Step: 2
Training loss: 2.493374054758114
Validation loss: 2.5326963656528343

Epoch: 5| Step: 3
Training loss: 2.511879448622167
Validation loss: 2.533106958685987

Epoch: 5| Step: 4
Training loss: 2.27506085408743
Validation loss: 2.5387198662045574

Epoch: 5| Step: 5
Training loss: 2.5450218339144595
Validation loss: 2.540838827227538

Epoch: 5| Step: 6
Training loss: 2.373695215895737
Validation loss: 2.5321563110728182

Epoch: 5| Step: 7
Training loss: 2.132108579178885
Validation loss: 2.5572681322329154

Epoch: 5| Step: 8
Training loss: 1.721921803137766
Validation loss: 2.541578996167724

Epoch: 5| Step: 9
Training loss: 2.3106171443311423
Validation loss: 2.531759405093966

Epoch: 5| Step: 10
Training loss: 2.2786461588541433
Validation loss: 2.519930742317477

Epoch: 5| Step: 11
Training loss: 2.8339022644893266
Validation loss: 2.525328749242606

Epoch: 238| Step: 0
Training loss: 2.8800420914329172
Validation loss: 2.534787237880894

Epoch: 5| Step: 1
Training loss: 2.366640537637097
Validation loss: 2.5332880724034275

Epoch: 5| Step: 2
Training loss: 2.485769012706871
Validation loss: 2.500157422831391

Epoch: 5| Step: 3
Training loss: 2.4993331019673715
Validation loss: 2.5037852082972547

Epoch: 5| Step: 4
Training loss: 2.5927305860983405
Validation loss: 2.4997320786599375

Epoch: 5| Step: 5
Training loss: 1.4013044921461082
Validation loss: 2.5043106228670187

Epoch: 5| Step: 6
Training loss: 1.7261491513747438
Validation loss: 2.498398915832458

Epoch: 5| Step: 7
Training loss: 2.1633497916811772
Validation loss: 2.4903297535700752

Epoch: 5| Step: 8
Training loss: 2.282366544701477
Validation loss: 2.4897243321498834

Epoch: 5| Step: 9
Training loss: 2.4518526507313685
Validation loss: 2.5150262661138054

Epoch: 5| Step: 10
Training loss: 2.3465161085959734
Validation loss: 2.5301880394498806

Epoch: 5| Step: 11
Training loss: 2.3679516254587414
Validation loss: 2.5441491258314124

Epoch: 239| Step: 0
Training loss: 1.572925954963931
Validation loss: 2.5535107506794046

Epoch: 5| Step: 1
Training loss: 2.0084055458899415
Validation loss: 2.555101036486544

Epoch: 5| Step: 2
Training loss: 2.628311702161112
Validation loss: 2.562600812247028

Epoch: 5| Step: 3
Training loss: 2.602559399838455
Validation loss: 2.529536895949869

Epoch: 5| Step: 4
Training loss: 2.6745680237408327
Validation loss: 2.5243553917250705

Epoch: 5| Step: 5
Training loss: 2.688642835481025
Validation loss: 2.522025643426302

Epoch: 5| Step: 6
Training loss: 1.7373682260285874
Validation loss: 2.5196226670193727

Epoch: 5| Step: 7
Training loss: 2.2182498421876926
Validation loss: 2.520010413212681

Epoch: 5| Step: 8
Training loss: 2.6545102873642543
Validation loss: 2.5342371332006834

Epoch: 5| Step: 9
Training loss: 2.4198122161329865
Validation loss: 2.532121398444649

Epoch: 5| Step: 10
Training loss: 2.2652236056741977
Validation loss: 2.53617707846594

Epoch: 5| Step: 11
Training loss: 1.3604918090646645
Validation loss: 2.5530380675458306

Epoch: 240| Step: 0
Training loss: 2.3751070098862166
Validation loss: 2.524489129510299

Epoch: 5| Step: 1
Training loss: 2.2166336066665626
Validation loss: 2.530093054241239

Epoch: 5| Step: 2
Training loss: 2.6148767091413716
Validation loss: 2.531196440612802

Epoch: 5| Step: 3
Training loss: 1.9758667456371881
Validation loss: 2.521667458062847

Epoch: 5| Step: 4
Training loss: 1.56800680603769
Validation loss: 2.545563635195359

Epoch: 5| Step: 5
Training loss: 2.455436055290109
Validation loss: 2.539026713974951

Epoch: 5| Step: 6
Training loss: 2.364754008268683
Validation loss: 2.549053286452028

Epoch: 5| Step: 7
Training loss: 3.016212682829094
Validation loss: 2.5305333437737496

Epoch: 5| Step: 8
Training loss: 2.550297970285757
Validation loss: 2.5504587309364646

Epoch: 5| Step: 9
Training loss: 1.8147381742380875
Validation loss: 2.52991532432202

Epoch: 5| Step: 10
Training loss: 2.1148568588769354
Validation loss: 2.542778601815642

Epoch: 5| Step: 11
Training loss: 2.237156237402318
Validation loss: 2.556903923664909

Epoch: 241| Step: 0
Training loss: 2.176477837815818
Validation loss: 2.56343125269977

Epoch: 5| Step: 1
Training loss: 2.456436060878708
Validation loss: 2.556121789068916

Epoch: 5| Step: 2
Training loss: 2.3481733162127605
Validation loss: 2.5769053685800314

Epoch: 5| Step: 3
Training loss: 2.575576077065801
Validation loss: 2.572633767630688

Epoch: 5| Step: 4
Training loss: 2.640471324173345
Validation loss: 2.5753680853424146

Epoch: 5| Step: 5
Training loss: 2.215129746367785
Validation loss: 2.5634756208145593

Epoch: 5| Step: 6
Training loss: 2.5087886823666508
Validation loss: 2.561800663584536

Epoch: 5| Step: 7
Training loss: 2.134235508215719
Validation loss: 2.541433688466235

Epoch: 5| Step: 8
Training loss: 2.279674351675853
Validation loss: 2.5147090531731506

Epoch: 5| Step: 9
Training loss: 2.4066904829049727
Validation loss: 2.5070522815855987

Epoch: 5| Step: 10
Training loss: 2.240899011517872
Validation loss: 2.49851513317147

Epoch: 5| Step: 11
Training loss: 1.7221113454683457
Validation loss: 2.514519667800534

Epoch: 242| Step: 0
Training loss: 2.4719166787126547
Validation loss: 2.517389034394072

Epoch: 5| Step: 1
Training loss: 2.3494521902626224
Validation loss: 2.526194134597386

Epoch: 5| Step: 2
Training loss: 2.24253911574323
Validation loss: 2.515284766020096

Epoch: 5| Step: 3
Training loss: 3.011845884101249
Validation loss: 2.505444768638813

Epoch: 5| Step: 4
Training loss: 2.3645288626380805
Validation loss: 2.5198569508664064

Epoch: 5| Step: 5
Training loss: 2.3956227638479017
Validation loss: 2.503422286167121

Epoch: 5| Step: 6
Training loss: 2.261710633047557
Validation loss: 2.5009957198233868

Epoch: 5| Step: 7
Training loss: 2.5490584112323735
Validation loss: 2.4977638575434495

Epoch: 5| Step: 8
Training loss: 2.1597788586265416
Validation loss: 2.492785215699929

Epoch: 5| Step: 9
Training loss: 2.557193938108169
Validation loss: 2.481222940164471

Epoch: 5| Step: 10
Training loss: 1.9770783365693643
Validation loss: 2.484763305036092

Epoch: 5| Step: 11
Training loss: 1.308755118825497
Validation loss: 2.473842378542442

Epoch: 243| Step: 0
Training loss: 2.2560752864409466
Validation loss: 2.4873816811874288

Epoch: 5| Step: 1
Training loss: 2.7096540507540934
Validation loss: 2.4753129857538028

Epoch: 5| Step: 2
Training loss: 2.1714768079010645
Validation loss: 2.5107968518678865

Epoch: 5| Step: 3
Training loss: 2.284127497800527
Validation loss: 2.5057392522693096

Epoch: 5| Step: 4
Training loss: 1.7332045583695406
Validation loss: 2.498917559892283

Epoch: 5| Step: 5
Training loss: 2.633262075192427
Validation loss: 2.494458219401192

Epoch: 5| Step: 6
Training loss: 2.3628755583797525
Validation loss: 2.4941504948001785

Epoch: 5| Step: 7
Training loss: 2.6103253489903873
Validation loss: 2.4879759317240238

Epoch: 5| Step: 8
Training loss: 1.511220529551322
Validation loss: 2.495458702210644

Epoch: 5| Step: 9
Training loss: 1.8463833640246603
Validation loss: 2.5168342448224212

Epoch: 5| Step: 10
Training loss: 2.589470147390403
Validation loss: 2.513469119763345

Epoch: 5| Step: 11
Training loss: 3.9725893928355878
Validation loss: 2.5065596650805135

Epoch: 244| Step: 0
Training loss: 1.649157037126989
Validation loss: 2.4959327594098646

Epoch: 5| Step: 1
Training loss: 2.203231376081848
Validation loss: 2.501586686715741

Epoch: 5| Step: 2
Training loss: 2.5358826429788075
Validation loss: 2.5126557409434915

Epoch: 5| Step: 3
Training loss: 2.5459791608918
Validation loss: 2.520016018858208

Epoch: 5| Step: 4
Training loss: 2.6247248732482045
Validation loss: 2.522358934498978

Epoch: 5| Step: 5
Training loss: 2.253947080774553
Validation loss: 2.519356233102155

Epoch: 5| Step: 6
Training loss: 2.397878674941664
Validation loss: 2.514665641849268

Epoch: 5| Step: 7
Training loss: 2.6746435266573267
Validation loss: 2.5284213206404886

Epoch: 5| Step: 8
Training loss: 2.230095880611134
Validation loss: 2.5463885972042597

Epoch: 5| Step: 9
Training loss: 2.051687044196907
Validation loss: 2.5526709729906596

Epoch: 5| Step: 10
Training loss: 2.2201889100331376
Validation loss: 2.5766089519063335

Epoch: 5| Step: 11
Training loss: 3.3092579360731884
Validation loss: 2.577059469726731

Epoch: 245| Step: 0
Training loss: 2.0574908840121187
Validation loss: 2.5794012667605877

Epoch: 5| Step: 1
Training loss: 2.2025803778852024
Validation loss: 2.5882137341592646

Epoch: 5| Step: 2
Training loss: 2.6589605526216347
Validation loss: 2.5522890488112915

Epoch: 5| Step: 3
Training loss: 2.1157140355272386
Validation loss: 2.538573790247713

Epoch: 5| Step: 4
Training loss: 2.704961604834784
Validation loss: 2.527660289125355

Epoch: 5| Step: 5
Training loss: 2.8285950328067715
Validation loss: 2.535859506613849

Epoch: 5| Step: 6
Training loss: 2.409927728289505
Validation loss: 2.5244829651746485

Epoch: 5| Step: 7
Training loss: 2.0164637040499827
Validation loss: 2.519355862449463

Epoch: 5| Step: 8
Training loss: 2.0740572476776737
Validation loss: 2.5123905412671013

Epoch: 5| Step: 9
Training loss: 1.6661881316161014
Validation loss: 2.510122920429554

Epoch: 5| Step: 10
Training loss: 2.431643174258202
Validation loss: 2.509178700573951

Epoch: 5| Step: 11
Training loss: 1.9869754602906808
Validation loss: 2.5050831536776372

Epoch: 246| Step: 0
Training loss: 2.2082311018786505
Validation loss: 2.5060005336536633

Epoch: 5| Step: 1
Training loss: 2.047512275556532
Validation loss: 2.5180333418712912

Epoch: 5| Step: 2
Training loss: 2.1848646365557802
Validation loss: 2.5082942622701974

Epoch: 5| Step: 3
Training loss: 2.651823956395924
Validation loss: 2.4890225961427594

Epoch: 5| Step: 4
Training loss: 2.5446840000889774
Validation loss: 2.5113903165129976

Epoch: 5| Step: 5
Training loss: 1.7851182528736167
Validation loss: 2.50316112062044

Epoch: 5| Step: 6
Training loss: 2.1778251321124915
Validation loss: 2.524012949771528

Epoch: 5| Step: 7
Training loss: 2.6731469768470757
Validation loss: 2.5346243544777134

Epoch: 5| Step: 8
Training loss: 2.559182787933137
Validation loss: 2.570219175428171

Epoch: 5| Step: 9
Training loss: 2.0276971115835973
Validation loss: 2.5959763795699424

Epoch: 5| Step: 10
Training loss: 2.253352211171514
Validation loss: 2.6286543432110188

Epoch: 5| Step: 11
Training loss: 2.2631115882389743
Validation loss: 2.6150832071979457

Epoch: 247| Step: 0
Training loss: 3.082227422662021
Validation loss: 2.559901897517667

Epoch: 5| Step: 1
Training loss: 1.8688731226342357
Validation loss: 2.5586498729966562

Epoch: 5| Step: 2
Training loss: 2.5461523985099532
Validation loss: 2.5294184200191263

Epoch: 5| Step: 3
Training loss: 2.2343516315225216
Validation loss: 2.528042817951047

Epoch: 5| Step: 4
Training loss: 2.475006095801659
Validation loss: 2.5225723169153924

Epoch: 5| Step: 5
Training loss: 2.0554637530449877
Validation loss: 2.525349014069226

Epoch: 5| Step: 6
Training loss: 2.581139484099407
Validation loss: 2.530823298779707

Epoch: 5| Step: 7
Training loss: 2.245709354845192
Validation loss: 2.5235872804893673

Epoch: 5| Step: 8
Training loss: 2.0219964157510413
Validation loss: 2.525769709993275

Epoch: 5| Step: 9
Training loss: 2.0332707843644555
Validation loss: 2.540098133644468

Epoch: 5| Step: 10
Training loss: 2.190888532385966
Validation loss: 2.533537486491961

Epoch: 5| Step: 11
Training loss: 2.2730247935710515
Validation loss: 2.5241960383402646

Epoch: 248| Step: 0
Training loss: 2.6167317007774717
Validation loss: 2.5238146898614358

Epoch: 5| Step: 1
Training loss: 2.1286675835613535
Validation loss: 2.5215541673334205

Epoch: 5| Step: 2
Training loss: 2.3999508733489785
Validation loss: 2.5162073847330992

Epoch: 5| Step: 3
Training loss: 2.557723827840761
Validation loss: 2.5017303319954434

Epoch: 5| Step: 4
Training loss: 2.0819683816947627
Validation loss: 2.5118535363086383

Epoch: 5| Step: 5
Training loss: 2.7514469501553256
Validation loss: 2.5083566730834934

Epoch: 5| Step: 6
Training loss: 2.196194400333262
Validation loss: 2.4937010686180123

Epoch: 5| Step: 7
Training loss: 2.6723051561460376
Validation loss: 2.504263599940085

Epoch: 5| Step: 8
Training loss: 1.895925736184106
Validation loss: 2.4913831766167993

Epoch: 5| Step: 9
Training loss: 1.930646218047119
Validation loss: 2.5101937647482844

Epoch: 5| Step: 10
Training loss: 2.34316134371977
Validation loss: 2.5206204960299874

Epoch: 5| Step: 11
Training loss: 2.2271043620054978
Validation loss: 2.521068709132577

Epoch: 249| Step: 0
Training loss: 2.525651368076926
Validation loss: 2.5186729605530305

Epoch: 5| Step: 1
Training loss: 2.5782816521417895
Validation loss: 2.506087778633209

Epoch: 5| Step: 2
Training loss: 2.445909713600934
Validation loss: 2.52155799275631

Epoch: 5| Step: 3
Training loss: 1.7561463322027733
Validation loss: 2.516637116747123

Epoch: 5| Step: 4
Training loss: 2.3016136231089193
Validation loss: 2.5171879637938974

Epoch: 5| Step: 5
Training loss: 2.5640289583400855
Validation loss: 2.5144019184446385

Epoch: 5| Step: 6
Training loss: 2.4263070192471416
Validation loss: 2.4965290094041563

Epoch: 5| Step: 7
Training loss: 1.9426702609861308
Validation loss: 2.4751334735573827

Epoch: 5| Step: 8
Training loss: 2.5603581292765645
Validation loss: 2.475290944758825

Epoch: 5| Step: 9
Training loss: 2.153565214248002
Validation loss: 2.481022061688975

Epoch: 5| Step: 10
Training loss: 2.0272457856193165
Validation loss: 2.4594357545644234

Epoch: 5| Step: 11
Training loss: 1.7634869348633104
Validation loss: 2.473993310513777

Epoch: 250| Step: 0
Training loss: 2.0122937019712515
Validation loss: 2.486410274981402

Epoch: 5| Step: 1
Training loss: 1.733526692548305
Validation loss: 2.4915408508299275

Epoch: 5| Step: 2
Training loss: 2.6619698368258065
Validation loss: 2.5239214516743593

Epoch: 5| Step: 3
Training loss: 2.3393209698099318
Validation loss: 2.577612099539286

Epoch: 5| Step: 4
Training loss: 2.490600080377413
Validation loss: 2.5631857628957944

Epoch: 5| Step: 5
Training loss: 2.695051628425086
Validation loss: 2.5544686879934235

Epoch: 5| Step: 6
Training loss: 1.9610545818741505
Validation loss: 2.5366138682111057

Epoch: 5| Step: 7
Training loss: 1.6814328374321241
Validation loss: 2.5218652998411932

Epoch: 5| Step: 8
Training loss: 2.7089296320284397
Validation loss: 2.5238557238679413

Epoch: 5| Step: 9
Training loss: 2.24269571426274
Validation loss: 2.5108956965519624

Epoch: 5| Step: 10
Training loss: 2.4882211722842023
Validation loss: 2.519276829375195

Epoch: 5| Step: 11
Training loss: 1.4261444883242929
Validation loss: 2.542885575347934

Epoch: 251| Step: 0
Training loss: 2.2786908361441434
Validation loss: 2.5330886481621375

Epoch: 5| Step: 1
Training loss: 1.7814441374340015
Validation loss: 2.5450637828563587

Epoch: 5| Step: 2
Training loss: 2.57130862705598
Validation loss: 2.5354914274663183

Epoch: 5| Step: 3
Training loss: 2.338937421472871
Validation loss: 2.5238182678171865

Epoch: 5| Step: 4
Training loss: 2.369519586279713
Validation loss: 2.5620744921796983

Epoch: 5| Step: 5
Training loss: 2.700920661503919
Validation loss: 2.556471129088955

Epoch: 5| Step: 6
Training loss: 1.6996639676927672
Validation loss: 2.5499241992180894

Epoch: 5| Step: 7
Training loss: 2.7010960544142297
Validation loss: 2.5683252136511396

Epoch: 5| Step: 8
Training loss: 1.704460390453745
Validation loss: 2.5420656255899274

Epoch: 5| Step: 9
Training loss: 1.8087855457749125
Validation loss: 2.5261720774437992

Epoch: 5| Step: 10
Training loss: 2.5484361602948082
Validation loss: 2.525788400020247

Epoch: 5| Step: 11
Training loss: 3.1954174071161163
Validation loss: 2.514609923823949

Epoch: 252| Step: 0
Training loss: 2.4614536289122237
Validation loss: 2.5272093024205105

Epoch: 5| Step: 1
Training loss: 2.0835485601512973
Validation loss: 2.52778842085972

Epoch: 5| Step: 2
Training loss: 2.359385408290111
Validation loss: 2.522372994617192

Epoch: 5| Step: 3
Training loss: 2.369022577148394
Validation loss: 2.5323149046203683

Epoch: 5| Step: 4
Training loss: 1.8359044498147192
Validation loss: 2.5244507541609353

Epoch: 5| Step: 5
Training loss: 2.2419478125508765
Validation loss: 2.529060723904988

Epoch: 5| Step: 6
Training loss: 1.7563056421119885
Validation loss: 2.5205195378756615

Epoch: 5| Step: 7
Training loss: 2.6926246398866036
Validation loss: 2.517939109363452

Epoch: 5| Step: 8
Training loss: 2.4714063043323633
Validation loss: 2.515943068779025

Epoch: 5| Step: 9
Training loss: 2.9952329271837836
Validation loss: 2.5298876373182964

Epoch: 5| Step: 10
Training loss: 2.10846300543068
Validation loss: 2.528591543702412

Epoch: 5| Step: 11
Training loss: 1.7366629965237566
Validation loss: 2.5506363107532843

Epoch: 253| Step: 0
Training loss: 2.1320299662260815
Validation loss: 2.569210179420626

Epoch: 5| Step: 1
Training loss: 2.700902124094012
Validation loss: 2.5691855413288196

Epoch: 5| Step: 2
Training loss: 2.0249480864852325
Validation loss: 2.5638724350208997

Epoch: 5| Step: 3
Training loss: 2.556140917849941
Validation loss: 2.5749665960287147

Epoch: 5| Step: 4
Training loss: 1.6957418012481276
Validation loss: 2.5493917414502154

Epoch: 5| Step: 5
Training loss: 2.1345509580854642
Validation loss: 2.5270621660252277

Epoch: 5| Step: 6
Training loss: 1.8661602179054246
Validation loss: 2.5259274381523458

Epoch: 5| Step: 7
Training loss: 2.485124103202714
Validation loss: 2.5145261350846084

Epoch: 5| Step: 8
Training loss: 2.4492948724090526
Validation loss: 2.5051032511560756

Epoch: 5| Step: 9
Training loss: 2.219336741060479
Validation loss: 2.5135649821631696

Epoch: 5| Step: 10
Training loss: 2.529653351749423
Validation loss: 2.5175894931075864

Epoch: 5| Step: 11
Training loss: 1.4935719723135918
Validation loss: 2.5144263071263016

Epoch: 254| Step: 0
Training loss: 2.9713775250483243
Validation loss: 2.505755312575795

Epoch: 5| Step: 1
Training loss: 2.185435383452593
Validation loss: 2.4933605442903977

Epoch: 5| Step: 2
Training loss: 1.7146339375045432
Validation loss: 2.5087039230707404

Epoch: 5| Step: 3
Training loss: 2.134862787630455
Validation loss: 2.512210147263819

Epoch: 5| Step: 4
Training loss: 2.486148129500748
Validation loss: 2.530194604102733

Epoch: 5| Step: 5
Training loss: 2.1649968853370867
Validation loss: 2.525849932181115

Epoch: 5| Step: 6
Training loss: 2.563542316865018
Validation loss: 2.5317066746121046

Epoch: 5| Step: 7
Training loss: 1.7475813091173522
Validation loss: 2.5354942837016745

Epoch: 5| Step: 8
Training loss: 2.362288135535233
Validation loss: 2.537263927690738

Epoch: 5| Step: 9
Training loss: 1.590196724963447
Validation loss: 2.5441934124123544

Epoch: 5| Step: 10
Training loss: 2.5934683405523318
Validation loss: 2.528784438059179

Epoch: 5| Step: 11
Training loss: 2.990634126559595
Validation loss: 2.520859029864866

Epoch: 255| Step: 0
Training loss: 2.3151945962540967
Validation loss: 2.5328385035038745

Epoch: 5| Step: 1
Training loss: 2.2648397202865476
Validation loss: 2.539964584124956

Epoch: 5| Step: 2
Training loss: 2.50067739846064
Validation loss: 2.534604322545253

Epoch: 5| Step: 3
Training loss: 2.788816467888294
Validation loss: 2.541566158219969

Epoch: 5| Step: 4
Training loss: 2.419338349932195
Validation loss: 2.5229569047343574

Epoch: 5| Step: 5
Training loss: 2.1839565460227846
Validation loss: 2.5412518046751558

Epoch: 5| Step: 6
Training loss: 2.081553334535385
Validation loss: 2.5453239624876884

Epoch: 5| Step: 7
Training loss: 1.902582674473353
Validation loss: 2.531611212714698

Epoch: 5| Step: 8
Training loss: 1.9541766577860393
Validation loss: 2.5304160176697237

Epoch: 5| Step: 9
Training loss: 2.0956142723111544
Validation loss: 2.5301238604333314

Epoch: 5| Step: 10
Training loss: 1.9441751732648989
Validation loss: 2.5297718893249472

Epoch: 5| Step: 11
Training loss: 2.694870445378907
Validation loss: 2.527103304541646

Epoch: 256| Step: 0
Training loss: 2.358319178921804
Validation loss: 2.5606683372012746

Epoch: 5| Step: 1
Training loss: 2.43596238765274
Validation loss: 2.562475545502874

Epoch: 5| Step: 2
Training loss: 1.8141841956036335
Validation loss: 2.5452400802947563

Epoch: 5| Step: 3
Training loss: 2.2421267830207365
Validation loss: 2.5413033012007933

Epoch: 5| Step: 4
Training loss: 2.0347284903518363
Validation loss: 2.535687332678477

Epoch: 5| Step: 5
Training loss: 2.152715356666978
Validation loss: 2.5176842023245203

Epoch: 5| Step: 6
Training loss: 2.2480568442301756
Validation loss: 2.5165516230728158

Epoch: 5| Step: 7
Training loss: 1.8367841351162886
Validation loss: 2.5224253786982125

Epoch: 5| Step: 8
Training loss: 2.888215746664329
Validation loss: 2.5243130396213562

Epoch: 5| Step: 9
Training loss: 2.7499911568239384
Validation loss: 2.5555263040487906

Epoch: 5| Step: 10
Training loss: 2.2969541990158855
Validation loss: 2.539940753556177

Epoch: 5| Step: 11
Training loss: 1.3341453086546093
Validation loss: 2.530671151618815

Epoch: 257| Step: 0
Training loss: 2.272513290215334
Validation loss: 2.5410755608791247

Epoch: 5| Step: 1
Training loss: 2.363411992767785
Validation loss: 2.541978177278579

Epoch: 5| Step: 2
Training loss: 2.240210216228988
Validation loss: 2.541880842211059

Epoch: 5| Step: 3
Training loss: 2.17084967472225
Validation loss: 2.551273134949982

Epoch: 5| Step: 4
Training loss: 1.9324220131834902
Validation loss: 2.5602480638601812

Epoch: 5| Step: 5
Training loss: 2.566950956511395
Validation loss: 2.53869628221462

Epoch: 5| Step: 6
Training loss: 2.2656312087401456
Validation loss: 2.5218229965211734

Epoch: 5| Step: 7
Training loss: 2.8230393349058707
Validation loss: 2.536271389306554

Epoch: 5| Step: 8
Training loss: 2.094597488374715
Validation loss: 2.525745529172358

Epoch: 5| Step: 9
Training loss: 1.871167525905594
Validation loss: 2.5134399749719645

Epoch: 5| Step: 10
Training loss: 2.293834308457296
Validation loss: 2.5216079433429512

Epoch: 5| Step: 11
Training loss: 1.522708738077061
Validation loss: 2.515923095400974

Epoch: 258| Step: 0
Training loss: 2.3148695687776626
Validation loss: 2.5146722786276277

Epoch: 5| Step: 1
Training loss: 2.569797731002458
Validation loss: 2.5135588483437923

Epoch: 5| Step: 2
Training loss: 2.1962547587916883
Validation loss: 2.5161057520296675

Epoch: 5| Step: 3
Training loss: 1.450765272965631
Validation loss: 2.5213124802412277

Epoch: 5| Step: 4
Training loss: 2.1228557314626926
Validation loss: 2.5177495171542024

Epoch: 5| Step: 5
Training loss: 1.805363119907034
Validation loss: 2.5046320283410424

Epoch: 5| Step: 6
Training loss: 1.6653368731100449
Validation loss: 2.498291345662958

Epoch: 5| Step: 7
Training loss: 2.4465581384264974
Validation loss: 2.522627874824992

Epoch: 5| Step: 8
Training loss: 1.8673967060697
Validation loss: 2.509727566797866

Epoch: 5| Step: 9
Training loss: 2.784339988479811
Validation loss: 2.5211317356031056

Epoch: 5| Step: 10
Training loss: 2.7948411760602525
Validation loss: 2.4999785819725644

Epoch: 5| Step: 11
Training loss: 2.407094237615596
Validation loss: 2.5138502909809963

Epoch: 259| Step: 0
Training loss: 2.4137277710580993
Validation loss: 2.54246994845692

Epoch: 5| Step: 1
Training loss: 2.2487783294301265
Validation loss: 2.6014101539429926

Epoch: 5| Step: 2
Training loss: 2.3866887816500295
Validation loss: 2.6087276965499204

Epoch: 5| Step: 3
Training loss: 2.1701941263586404
Validation loss: 2.62687689045425

Epoch: 5| Step: 4
Training loss: 2.5343890094487467
Validation loss: 2.59023367514975

Epoch: 5| Step: 5
Training loss: 2.1688237334368026
Validation loss: 2.5554424379775176

Epoch: 5| Step: 6
Training loss: 2.17512280347687
Validation loss: 2.522781523012646

Epoch: 5| Step: 7
Training loss: 1.8640410275753403
Validation loss: 2.4980077951738253

Epoch: 5| Step: 8
Training loss: 2.596507617289159
Validation loss: 2.4902401713384847

Epoch: 5| Step: 9
Training loss: 2.135317941259829
Validation loss: 2.5020063495359754

Epoch: 5| Step: 10
Training loss: 2.8304196316876533
Validation loss: 2.5023686274668355

Epoch: 5| Step: 11
Training loss: 1.745342869780394
Validation loss: 2.5065421712606106

Epoch: 260| Step: 0
Training loss: 2.5297377978974107
Validation loss: 2.5042572965634657

Epoch: 5| Step: 1
Training loss: 2.4400241204930015
Validation loss: 2.5064269840507

Epoch: 5| Step: 2
Training loss: 2.3848773951976048
Validation loss: 2.4961091420669663

Epoch: 5| Step: 3
Training loss: 2.4421740980018547
Validation loss: 2.4977568735697484

Epoch: 5| Step: 4
Training loss: 1.8810628145185122
Validation loss: 2.4951743799312522

Epoch: 5| Step: 5
Training loss: 2.2551374064532883
Validation loss: 2.4861418481225495

Epoch: 5| Step: 6
Training loss: 2.2197142104322514
Validation loss: 2.487272220674759

Epoch: 5| Step: 7
Training loss: 2.438879649647577
Validation loss: 2.480729016844554

Epoch: 5| Step: 8
Training loss: 1.4939231165721882
Validation loss: 2.492826079029178

Epoch: 5| Step: 9
Training loss: 2.686275291838586
Validation loss: 2.516500601015727

Epoch: 5| Step: 10
Training loss: 2.360952393177453
Validation loss: 2.537875339077832

Epoch: 5| Step: 11
Training loss: 1.0857023354998434
Validation loss: 2.5818279280565837

Epoch: 261| Step: 0
Training loss: 2.565669170189921
Validation loss: 2.614091638226714

Epoch: 5| Step: 1
Training loss: 2.467696532487866
Validation loss: 2.657007431047639

Epoch: 5| Step: 2
Training loss: 2.6527035543589017
Validation loss: 2.591576408509291

Epoch: 5| Step: 3
Training loss: 2.3015536451201757
Validation loss: 2.5699463808679393

Epoch: 5| Step: 4
Training loss: 2.023584662428742
Validation loss: 2.5742918282971727

Epoch: 5| Step: 5
Training loss: 1.9396405854535332
Validation loss: 2.518453224468484

Epoch: 5| Step: 6
Training loss: 2.3696958641277903
Validation loss: 2.5358258006343055

Epoch: 5| Step: 7
Training loss: 2.199594360582136
Validation loss: 2.5250136705538377

Epoch: 5| Step: 8
Training loss: 2.1178015912774004
Validation loss: 2.5206968110267187

Epoch: 5| Step: 9
Training loss: 2.1574322320543424
Validation loss: 2.525777997023563

Epoch: 5| Step: 10
Training loss: 2.423481365424201
Validation loss: 2.5139448684064556

Epoch: 5| Step: 11
Training loss: 2.2837490868109853
Validation loss: 2.523928733229133

Epoch: 262| Step: 0
Training loss: 2.3521580749836293
Validation loss: 2.5118228936246623

Epoch: 5| Step: 1
Training loss: 2.176149183082081
Validation loss: 2.5203166693605454

Epoch: 5| Step: 2
Training loss: 1.8068130988196212
Validation loss: 2.5211585533908627

Epoch: 5| Step: 3
Training loss: 2.2825402569432702
Validation loss: 2.520210828975142

Epoch: 5| Step: 4
Training loss: 2.401365201808858
Validation loss: 2.4993630631010673

Epoch: 5| Step: 5
Training loss: 2.07689888714563
Validation loss: 2.5076639066031756

Epoch: 5| Step: 6
Training loss: 2.5357424582867836
Validation loss: 2.5240534374179373

Epoch: 5| Step: 7
Training loss: 2.0380513106485876
Validation loss: 2.499525295329248

Epoch: 5| Step: 8
Training loss: 2.3726388337140154
Validation loss: 2.5097710952006493

Epoch: 5| Step: 9
Training loss: 2.206209228830519
Validation loss: 2.511327235437836

Epoch: 5| Step: 10
Training loss: 2.7626990233659683
Validation loss: 2.514897606612605

Epoch: 5| Step: 11
Training loss: 2.3023721735260887
Validation loss: 2.5287364127648453

Epoch: 263| Step: 0
Training loss: 1.8540559228407194
Validation loss: 2.5276150683085317

Epoch: 5| Step: 1
Training loss: 1.9852373547220343
Validation loss: 2.5510054952711063

Epoch: 5| Step: 2
Training loss: 2.420164328583878
Validation loss: 2.5355149629064

Epoch: 5| Step: 3
Training loss: 1.7184971710128518
Validation loss: 2.5303408124113234

Epoch: 5| Step: 4
Training loss: 2.534966648341379
Validation loss: 2.552214924021293

Epoch: 5| Step: 5
Training loss: 1.8863963607924465
Validation loss: 2.558774461261241

Epoch: 5| Step: 6
Training loss: 2.023372221965253
Validation loss: 2.57181069056905

Epoch: 5| Step: 7
Training loss: 2.415906084887932
Validation loss: 2.572628496740308

Epoch: 5| Step: 8
Training loss: 2.2135505466657053
Validation loss: 2.586440714482801

Epoch: 5| Step: 9
Training loss: 2.5584741928471915
Validation loss: 2.591211490022913

Epoch: 5| Step: 10
Training loss: 2.6454688794892656
Validation loss: 2.60036316377178

Epoch: 5| Step: 11
Training loss: 3.3963908730480967
Validation loss: 2.5273746722460597

Epoch: 264| Step: 0
Training loss: 2.2198078696132297
Validation loss: 2.5376452554742097

Epoch: 5| Step: 1
Training loss: 2.581742217122265
Validation loss: 2.5185431580848476

Epoch: 5| Step: 2
Training loss: 2.4959248708030777
Validation loss: 2.5153482948379033

Epoch: 5| Step: 3
Training loss: 1.8773507958262887
Validation loss: 2.505524626583503

Epoch: 5| Step: 4
Training loss: 1.8311488257050827
Validation loss: 2.5005838586584628

Epoch: 5| Step: 5
Training loss: 2.0737951388513727
Validation loss: 2.5064055079844754

Epoch: 5| Step: 6
Training loss: 2.1629814449930627
Validation loss: 2.501475689390599

Epoch: 5| Step: 7
Training loss: 1.9800818552571702
Validation loss: 2.5082471635239028

Epoch: 5| Step: 8
Training loss: 2.078035510438068
Validation loss: 2.5001564731903354

Epoch: 5| Step: 9
Training loss: 2.3489210939239653
Validation loss: 2.4960713751182584

Epoch: 5| Step: 10
Training loss: 2.6035553685193253
Validation loss: 2.523568522985576

Epoch: 5| Step: 11
Training loss: 3.842201479234431
Validation loss: 2.5348779753873782

Epoch: 265| Step: 0
Training loss: 2.5455324343741297
Validation loss: 2.5535425348231886

Epoch: 5| Step: 1
Training loss: 2.8186456293038593
Validation loss: 2.581077411044977

Epoch: 5| Step: 2
Training loss: 2.458511270667529
Validation loss: 2.6126807434735895

Epoch: 5| Step: 3
Training loss: 1.948969823197532
Validation loss: 2.5683901438060612

Epoch: 5| Step: 4
Training loss: 1.6542207054068254
Validation loss: 2.571109269469228

Epoch: 5| Step: 5
Training loss: 2.4945588026427696
Validation loss: 2.5368876371329714

Epoch: 5| Step: 6
Training loss: 1.7302803987594897
Validation loss: 2.539352998987948

Epoch: 5| Step: 7
Training loss: 2.1528723979651385
Validation loss: 2.521351915933862

Epoch: 5| Step: 8
Training loss: 2.119617151923323
Validation loss: 2.5119550879522223

Epoch: 5| Step: 9
Training loss: 2.5566352162256574
Validation loss: 2.524663168878888

Epoch: 5| Step: 10
Training loss: 2.5677334446997775
Validation loss: 2.503014787191471

Epoch: 5| Step: 11
Training loss: 1.7651111226316707
Validation loss: 2.5303026750004856

Epoch: 266| Step: 0
Training loss: 1.9925350110509155
Validation loss: 2.5376895146311167

Epoch: 5| Step: 1
Training loss: 2.272666039942443
Validation loss: 2.5515593685046056

Epoch: 5| Step: 2
Training loss: 2.1274317123265774
Validation loss: 2.5404237355446777

Epoch: 5| Step: 3
Training loss: 2.0043849559188156
Validation loss: 2.551813696546054

Epoch: 5| Step: 4
Training loss: 2.70395846003728
Validation loss: 2.5640144408729872

Epoch: 5| Step: 5
Training loss: 2.8743962192934154
Validation loss: 2.599136076348967

Epoch: 5| Step: 6
Training loss: 2.5193445417436315
Validation loss: 2.651711195142881

Epoch: 5| Step: 7
Training loss: 1.7669644971431737
Validation loss: 2.638158899417961

Epoch: 5| Step: 8
Training loss: 2.6315680486051845
Validation loss: 2.656445948535226

Epoch: 5| Step: 9
Training loss: 2.2678083751399676
Validation loss: 2.639190807276287

Epoch: 5| Step: 10
Training loss: 2.3508300654476386
Validation loss: 2.5766209077740436

Epoch: 5| Step: 11
Training loss: 1.9382459988630867
Validation loss: 2.5351097913814127

Epoch: 267| Step: 0
Training loss: 2.1331236895231105
Validation loss: 2.5120333310928324

Epoch: 5| Step: 1
Training loss: 2.0210331952343124
Validation loss: 2.4997240311575015

Epoch: 5| Step: 2
Training loss: 2.608242771498087
Validation loss: 2.5257983506726345

Epoch: 5| Step: 3
Training loss: 2.305101467389967
Validation loss: 2.546307557126072

Epoch: 5| Step: 4
Training loss: 2.40649710042887
Validation loss: 2.549894423106836

Epoch: 5| Step: 5
Training loss: 2.4886439851016293
Validation loss: 2.554791968462095

Epoch: 5| Step: 6
Training loss: 2.6824971141959644
Validation loss: 2.5690805831945274

Epoch: 5| Step: 7
Training loss: 2.7436330088219103
Validation loss: 2.5468193079314245

Epoch: 5| Step: 8
Training loss: 2.067569513409293
Validation loss: 2.554434476993322

Epoch: 5| Step: 9
Training loss: 2.115297607153044
Validation loss: 2.550579742681956

Epoch: 5| Step: 10
Training loss: 2.6461513858776904
Validation loss: 2.5357411321677827

Epoch: 5| Step: 11
Training loss: 0.9584556722643989
Validation loss: 2.5273315138523085

Epoch: 268| Step: 0
Training loss: 2.6615248421099618
Validation loss: 2.5080013936840992

Epoch: 5| Step: 1
Training loss: 2.3512239434250004
Validation loss: 2.465062264229304

Epoch: 5| Step: 2
Training loss: 2.002505283039187
Validation loss: 2.4899351690717713

Epoch: 5| Step: 3
Training loss: 2.286513331511418
Validation loss: 2.473398295140218

Epoch: 5| Step: 4
Training loss: 1.7993290604414256
Validation loss: 2.4859962411682264

Epoch: 5| Step: 5
Training loss: 2.272671600006708
Validation loss: 2.496247610684141

Epoch: 5| Step: 6
Training loss: 2.0287802133055584
Validation loss: 2.4777166242553523

Epoch: 5| Step: 7
Training loss: 2.600665513474594
Validation loss: 2.4905908147491242

Epoch: 5| Step: 8
Training loss: 2.510663654845557
Validation loss: 2.4757711708647725

Epoch: 5| Step: 9
Training loss: 2.5516864286322325
Validation loss: 2.488951003536233

Epoch: 5| Step: 10
Training loss: 2.1922840665401373
Validation loss: 2.4940923687621246

Epoch: 5| Step: 11
Training loss: 1.3257427616860535
Validation loss: 2.4870053527944687

Epoch: 269| Step: 0
Training loss: 2.04606297816864
Validation loss: 2.488459925521959

Epoch: 5| Step: 1
Training loss: 2.09466760370115
Validation loss: 2.4759506007164935

Epoch: 5| Step: 2
Training loss: 1.934730765762081
Validation loss: 2.472330044747769

Epoch: 5| Step: 3
Training loss: 2.495005864535914
Validation loss: 2.4816905659480617

Epoch: 5| Step: 4
Training loss: 2.0719908622923153
Validation loss: 2.468652485881259

Epoch: 5| Step: 5
Training loss: 2.421128287104421
Validation loss: 2.47337239738635

Epoch: 5| Step: 6
Training loss: 2.3611633394735376
Validation loss: 2.4924749130930226

Epoch: 5| Step: 7
Training loss: 2.112512360485866
Validation loss: 2.4962216634515797

Epoch: 5| Step: 8
Training loss: 2.6945410467529936
Validation loss: 2.4795746921646638

Epoch: 5| Step: 9
Training loss: 2.057781254582572
Validation loss: 2.4829115285904004

Epoch: 5| Step: 10
Training loss: 2.388155390873775
Validation loss: 2.4935417999829332

Epoch: 5| Step: 11
Training loss: 1.634463629863198
Validation loss: 2.5096169988063184

Epoch: 270| Step: 0
Training loss: 2.4219875186500914
Validation loss: 2.5080829922107957

Epoch: 5| Step: 1
Training loss: 2.211456022352705
Validation loss: 2.5091943469168276

Epoch: 5| Step: 2
Training loss: 2.4238382565196694
Validation loss: 2.5071849731092777

Epoch: 5| Step: 3
Training loss: 2.1824947314291654
Validation loss: 2.5244690368293803

Epoch: 5| Step: 4
Training loss: 2.224932800306865
Validation loss: 2.5050927880355367

Epoch: 5| Step: 5
Training loss: 2.303687754890773
Validation loss: 2.530577079587428

Epoch: 5| Step: 6
Training loss: 2.556728842359324
Validation loss: 2.518077941793151

Epoch: 5| Step: 7
Training loss: 1.9058175143558507
Validation loss: 2.525392658717651

Epoch: 5| Step: 8
Training loss: 1.5925798795539299
Validation loss: 2.5094874879763647

Epoch: 5| Step: 9
Training loss: 2.5344412196453487
Validation loss: 2.5447945864256387

Epoch: 5| Step: 10
Training loss: 2.0375809823073165
Validation loss: 2.546706870834781

Epoch: 5| Step: 11
Training loss: 1.6533572288037446
Validation loss: 2.5509207756979997

Epoch: 271| Step: 0
Training loss: 1.9543082353382584
Validation loss: 2.560640032228085

Epoch: 5| Step: 1
Training loss: 2.321669467541862
Validation loss: 2.556232906554881

Epoch: 5| Step: 2
Training loss: 2.3414475384833997
Validation loss: 2.55125464524789

Epoch: 5| Step: 3
Training loss: 1.8886476375125247
Validation loss: 2.5211915649629937

Epoch: 5| Step: 4
Training loss: 1.5115502236439324
Validation loss: 2.5563278104012213

Epoch: 5| Step: 5
Training loss: 2.2720875091020005
Validation loss: 2.550080959275291

Epoch: 5| Step: 6
Training loss: 3.031804614110159
Validation loss: 2.52710271095673

Epoch: 5| Step: 7
Training loss: 2.6578132068738496
Validation loss: 2.523096957223732

Epoch: 5| Step: 8
Training loss: 1.9322157139687115
Validation loss: 2.527588881053305

Epoch: 5| Step: 9
Training loss: 2.130938031137369
Validation loss: 2.5722442680134607

Epoch: 5| Step: 10
Training loss: 1.9767276860747434
Validation loss: 2.5636752116421695

Epoch: 5| Step: 11
Training loss: 2.175943200814623
Validation loss: 2.5810282264803135

Epoch: 272| Step: 0
Training loss: 2.856264517515588
Validation loss: 2.5751625688708835

Epoch: 5| Step: 1
Training loss: 1.715007174618675
Validation loss: 2.5820676826988476

Epoch: 5| Step: 2
Training loss: 2.699248958258513
Validation loss: 2.605389191091023

Epoch: 5| Step: 3
Training loss: 1.9104550991817053
Validation loss: 2.6098573033377663

Epoch: 5| Step: 4
Training loss: 2.2538098822078894
Validation loss: 2.582142133539306

Epoch: 5| Step: 5
Training loss: 2.252526771818166
Validation loss: 2.563583606241016

Epoch: 5| Step: 6
Training loss: 1.440108627487181
Validation loss: 2.5718776455661274

Epoch: 5| Step: 7
Training loss: 2.3372342902135106
Validation loss: 2.5409418985283945

Epoch: 5| Step: 8
Training loss: 1.8415605508718593
Validation loss: 2.533538413818277

Epoch: 5| Step: 9
Training loss: 2.000095722768797
Validation loss: 2.5311695957364906

Epoch: 5| Step: 10
Training loss: 2.8165613308985287
Validation loss: 2.5440739126277077

Epoch: 5| Step: 11
Training loss: 2.4704522167557577
Validation loss: 2.5348823567906065

Epoch: 273| Step: 0
Training loss: 2.50387254237013
Validation loss: 2.5305387376758457

Epoch: 5| Step: 1
Training loss: 2.4200379326109496
Validation loss: 2.53797699245699

Epoch: 5| Step: 2
Training loss: 2.1470807594635772
Validation loss: 2.535270535518955

Epoch: 5| Step: 3
Training loss: 1.9565438826777564
Validation loss: 2.553424032808616

Epoch: 5| Step: 4
Training loss: 2.479630456279127
Validation loss: 2.544002613830523

Epoch: 5| Step: 5
Training loss: 2.0573746547780964
Validation loss: 2.5501074258765235

Epoch: 5| Step: 6
Training loss: 2.418824471206988
Validation loss: 2.547096862958805

Epoch: 5| Step: 7
Training loss: 2.5931391168974605
Validation loss: 2.561887733847855

Epoch: 5| Step: 8
Training loss: 1.8124703371975015
Validation loss: 2.58486364911963

Epoch: 5| Step: 9
Training loss: 1.956613766422484
Validation loss: 2.562377876379993

Epoch: 5| Step: 10
Training loss: 1.1525243585292129
Validation loss: 2.5846707794050796

Epoch: 5| Step: 11
Training loss: 3.0061820230709517
Validation loss: 2.597171315602623

Epoch: 274| Step: 0
Training loss: 1.798107288579657
Validation loss: 2.5571356290046974

Epoch: 5| Step: 1
Training loss: 2.1989595250268477
Validation loss: 2.5297185872747634

Epoch: 5| Step: 2
Training loss: 2.301112101006317
Validation loss: 2.523356098795064

Epoch: 5| Step: 3
Training loss: 2.100624186984685
Validation loss: 2.517202563865289

Epoch: 5| Step: 4
Training loss: 2.571873524179881
Validation loss: 2.515987978193413

Epoch: 5| Step: 5
Training loss: 2.206976263660993
Validation loss: 2.5110995852987488

Epoch: 5| Step: 6
Training loss: 2.4138221991481355
Validation loss: 2.516981369330391

Epoch: 5| Step: 7
Training loss: 2.4837943304182555
Validation loss: 2.512149704605633

Epoch: 5| Step: 8
Training loss: 1.9955613234313174
Validation loss: 2.529592159517444

Epoch: 5| Step: 9
Training loss: 2.3325456470467283
Validation loss: 2.5440841236670773

Epoch: 5| Step: 10
Training loss: 1.8565979422766112
Validation loss: 2.6090888591736556

Epoch: 5| Step: 11
Training loss: 2.232648062073284
Validation loss: 2.608085983987653

Epoch: 275| Step: 0
Training loss: 2.2956815979853595
Validation loss: 2.542535177479478

Epoch: 5| Step: 1
Training loss: 2.3539581769146474
Validation loss: 2.5267599297244066

Epoch: 5| Step: 2
Training loss: 1.7876606742298002
Validation loss: 2.50631949089788

Epoch: 5| Step: 3
Training loss: 2.453989544766141
Validation loss: 2.4964378848020057

Epoch: 5| Step: 4
Training loss: 2.0974460830396917
Validation loss: 2.506186484010035

Epoch: 5| Step: 5
Training loss: 1.728146960927757
Validation loss: 2.5068175698214112

Epoch: 5| Step: 6
Training loss: 2.4617942650779243
Validation loss: 2.5009695140139017

Epoch: 5| Step: 7
Training loss: 1.6683036950318162
Validation loss: 2.472894091665123

Epoch: 5| Step: 8
Training loss: 2.2440975971927597
Validation loss: 2.49310523009923

Epoch: 5| Step: 9
Training loss: 2.541760416855435
Validation loss: 2.4737964751182986

Epoch: 5| Step: 10
Training loss: 2.3070580656286857
Validation loss: 2.4886564593680185

Epoch: 5| Step: 11
Training loss: 1.0824345687402739
Validation loss: 2.5033554764778683

Epoch: 276| Step: 0
Training loss: 2.103325313647539
Validation loss: 2.4971102464068875

Epoch: 5| Step: 1
Training loss: 2.2983470533301253
Validation loss: 2.51006233252553

Epoch: 5| Step: 2
Training loss: 2.3150996468109764
Validation loss: 2.535760592943504

Epoch: 5| Step: 3
Training loss: 2.1454741414987035
Validation loss: 2.5453807137100837

Epoch: 5| Step: 4
Training loss: 1.9954024160941926
Validation loss: 2.5302791578217634

Epoch: 5| Step: 5
Training loss: 2.107475273014416
Validation loss: 2.532233333713449

Epoch: 5| Step: 6
Training loss: 2.5766214321191163
Validation loss: 2.5383404335925395

Epoch: 5| Step: 7
Training loss: 2.549597846838404
Validation loss: 2.5465518574795185

Epoch: 5| Step: 8
Training loss: 2.0440330286063606
Validation loss: 2.5410904439612882

Epoch: 5| Step: 9
Training loss: 1.9505184022474906
Validation loss: 2.5323913144008325

Epoch: 5| Step: 10
Training loss: 1.8146228854587567
Validation loss: 2.5292532702287183

Epoch: 5| Step: 11
Training loss: 2.209302857339391
Validation loss: 2.572505529402069

Epoch: 277| Step: 0
Training loss: 2.419189342252779
Validation loss: 2.5388746886606337

Epoch: 5| Step: 1
Training loss: 2.3052474036843864
Validation loss: 2.5603131290129117

Epoch: 5| Step: 2
Training loss: 2.578833465334889
Validation loss: 2.563724310634792

Epoch: 5| Step: 3
Training loss: 2.1309873715567567
Validation loss: 2.5504801573939653

Epoch: 5| Step: 4
Training loss: 2.5123654685370833
Validation loss: 2.5945124711916683

Epoch: 5| Step: 5
Training loss: 1.5974161205448358
Validation loss: 2.5828267774977687

Epoch: 5| Step: 6
Training loss: 1.596199845472299
Validation loss: 2.6070498502313764

Epoch: 5| Step: 7
Training loss: 2.5426704946721506
Validation loss: 2.589444796681684

Epoch: 5| Step: 8
Training loss: 1.9736116720555679
Validation loss: 2.584499981436222

Epoch: 5| Step: 9
Training loss: 2.163619123409118
Validation loss: 2.587238729649892

Epoch: 5| Step: 10
Training loss: 1.7208754142560674
Validation loss: 2.5415456865524457

Epoch: 5| Step: 11
Training loss: 1.8733683798465497
Validation loss: 2.570969170166305

Epoch: 278| Step: 0
Training loss: 2.142625528261509
Validation loss: 2.5721307370120527

Epoch: 5| Step: 1
Training loss: 1.9145824738155701
Validation loss: 2.5861838877410763

Epoch: 5| Step: 2
Training loss: 1.8637950516698198
Validation loss: 2.563944332011939

Epoch: 5| Step: 3
Training loss: 2.0861437977706156
Validation loss: 2.5784201250795817

Epoch: 5| Step: 4
Training loss: 2.30260484636894
Validation loss: 2.563770192601663

Epoch: 5| Step: 5
Training loss: 2.2320734721707653
Validation loss: 2.575534848804094

Epoch: 5| Step: 6
Training loss: 2.766966499795838
Validation loss: 2.5752439758308827

Epoch: 5| Step: 7
Training loss: 2.463344595663559
Validation loss: 2.5876750582756687

Epoch: 5| Step: 8
Training loss: 1.55011210190026
Validation loss: 2.5778800000232867

Epoch: 5| Step: 9
Training loss: 2.065998116410201
Validation loss: 2.55751022420103

Epoch: 5| Step: 10
Training loss: 2.328919243224458
Validation loss: 2.556865253882155

Epoch: 5| Step: 11
Training loss: 1.309609545547428
Validation loss: 2.5491828408548605

Epoch: 279| Step: 0
Training loss: 1.9309489339578554
Validation loss: 2.5430237372997224

Epoch: 5| Step: 1
Training loss: 2.3369862935452277
Validation loss: 2.545103742415506

Epoch: 5| Step: 2
Training loss: 2.5029530250631167
Validation loss: 2.542260746759378

Epoch: 5| Step: 3
Training loss: 1.9419581897057376
Validation loss: 2.5408029391517584

Epoch: 5| Step: 4
Training loss: 2.019439281974163
Validation loss: 2.5546422093038816

Epoch: 5| Step: 5
Training loss: 2.6882332089961443
Validation loss: 2.5679811283745924

Epoch: 5| Step: 6
Training loss: 2.0005176589518214
Validation loss: 2.552692279697221

Epoch: 5| Step: 7
Training loss: 2.4919797996143127
Validation loss: 2.583842420919755

Epoch: 5| Step: 8
Training loss: 1.5324841411074934
Validation loss: 2.6043052229578936

Epoch: 5| Step: 9
Training loss: 2.1992412992849304
Validation loss: 2.592400973687089

Epoch: 5| Step: 10
Training loss: 1.853979344138721
Validation loss: 2.5788587046357043

Epoch: 5| Step: 11
Training loss: 1.8414921270777553
Validation loss: 2.598859776836857

Epoch: 280| Step: 0
Training loss: 1.7549639870407416
Validation loss: 2.5534891123370556

Epoch: 5| Step: 1
Training loss: 2.1793586729032675
Validation loss: 2.5638668400206837

Epoch: 5| Step: 2
Training loss: 2.1660337868729664
Validation loss: 2.549921339666826

Epoch: 5| Step: 3
Training loss: 2.1998324850636486
Validation loss: 2.5590369736086247

Epoch: 5| Step: 4
Training loss: 2.3518832675485415
Validation loss: 2.5393865525257273

Epoch: 5| Step: 5
Training loss: 1.6611766596349682
Validation loss: 2.5624282795863547

Epoch: 5| Step: 6
Training loss: 1.7709311364784701
Validation loss: 2.542732591108302

Epoch: 5| Step: 7
Training loss: 2.7067014815373067
Validation loss: 2.5653088108797855

Epoch: 5| Step: 8
Training loss: 1.8067628891272551
Validation loss: 2.5712433494737783

Epoch: 5| Step: 9
Training loss: 2.4652789860634385
Validation loss: 2.5608383544324798

Epoch: 5| Step: 10
Training loss: 2.4268512423853332
Validation loss: 2.552452237201987

Epoch: 5| Step: 11
Training loss: 3.082082769739308
Validation loss: 2.5463862037841043

Epoch: 281| Step: 0
Training loss: 2.054517383567811
Validation loss: 2.5436329909210733

Epoch: 5| Step: 1
Training loss: 1.8373094991947598
Validation loss: 2.527035127847229

Epoch: 5| Step: 2
Training loss: 1.9287176127257903
Validation loss: 2.5207338917772537

Epoch: 5| Step: 3
Training loss: 2.001519341342244
Validation loss: 2.5381748623722427

Epoch: 5| Step: 4
Training loss: 1.4714631526946773
Validation loss: 2.5331800582804167

Epoch: 5| Step: 5
Training loss: 2.214313531076824
Validation loss: 2.5350228535608292

Epoch: 5| Step: 6
Training loss: 3.265537242531593
Validation loss: 2.54518408313806

Epoch: 5| Step: 7
Training loss: 2.0176909748434224
Validation loss: 2.540606732398593

Epoch: 5| Step: 8
Training loss: 2.664703649966498
Validation loss: 2.5813354539619486

Epoch: 5| Step: 9
Training loss: 1.7443673903799193
Validation loss: 2.5927456324463947

Epoch: 5| Step: 10
Training loss: 2.1963784016053176
Validation loss: 2.6102930422282644

Epoch: 5| Step: 11
Training loss: 2.0553273412242
Validation loss: 2.5978674284106327

Epoch: 282| Step: 0
Training loss: 2.0471746793161194
Validation loss: 2.6074139884229393

Epoch: 5| Step: 1
Training loss: 1.820079673972418
Validation loss: 2.574501807357466

Epoch: 5| Step: 2
Training loss: 1.4413404992466827
Validation loss: 2.537425341862409

Epoch: 5| Step: 3
Training loss: 2.253229472665409
Validation loss: 2.532305872045792

Epoch: 5| Step: 4
Training loss: 3.023474404752964
Validation loss: 2.526603114600431

Epoch: 5| Step: 5
Training loss: 1.7706603769847507
Validation loss: 2.507787286427669

Epoch: 5| Step: 6
Training loss: 2.298669127327265
Validation loss: 2.5152518191075552

Epoch: 5| Step: 7
Training loss: 1.8514756451930556
Validation loss: 2.5010664632146073

Epoch: 5| Step: 8
Training loss: 2.321801732012421
Validation loss: 2.518457606834486

Epoch: 5| Step: 9
Training loss: 2.363827375883458
Validation loss: 2.5384507757942787

Epoch: 5| Step: 10
Training loss: 2.1968822365176313
Validation loss: 2.5491192920552135

Epoch: 5| Step: 11
Training loss: 2.720824053418943
Validation loss: 2.543515550430012

Epoch: 283| Step: 0
Training loss: 2.729097341185993
Validation loss: 2.561056556284965

Epoch: 5| Step: 1
Training loss: 2.4476710635947554
Validation loss: 2.5941358723534917

Epoch: 5| Step: 2
Training loss: 1.5103812991857566
Validation loss: 2.593645480551054

Epoch: 5| Step: 3
Training loss: 2.2889725078300005
Validation loss: 2.554970670165936

Epoch: 5| Step: 4
Training loss: 2.2650743538818503
Validation loss: 2.5779785133899997

Epoch: 5| Step: 5
Training loss: 1.3853371198184488
Validation loss: 2.5762305977245132

Epoch: 5| Step: 6
Training loss: 1.9947152052551997
Validation loss: 2.5534698197445116

Epoch: 5| Step: 7
Training loss: 2.025486913468784
Validation loss: 2.5491217472108847

Epoch: 5| Step: 8
Training loss: 1.7204169079715814
Validation loss: 2.5495285884027137

Epoch: 5| Step: 9
Training loss: 2.3854549577019073
Validation loss: 2.5516507125902232

Epoch: 5| Step: 10
Training loss: 2.559493184883358
Validation loss: 2.558238022708407

Epoch: 5| Step: 11
Training loss: 1.364984535856297
Validation loss: 2.5509825544776383

Epoch: 284| Step: 0
Training loss: 1.993571799036548
Validation loss: 2.520329323870325

Epoch: 5| Step: 1
Training loss: 1.3911054402776786
Validation loss: 2.528817432577416

Epoch: 5| Step: 2
Training loss: 1.9710823049677944
Validation loss: 2.5407684463976925

Epoch: 5| Step: 3
Training loss: 2.4432534027903414
Validation loss: 2.5441418201504837

Epoch: 5| Step: 4
Training loss: 2.7396670329914468
Validation loss: 2.5453795858011317

Epoch: 5| Step: 5
Training loss: 2.427288379657687
Validation loss: 2.5649978125093784

Epoch: 5| Step: 6
Training loss: 1.9129249773763828
Validation loss: 2.5658813744962283

Epoch: 5| Step: 7
Training loss: 2.243492145651256
Validation loss: 2.572561989918735

Epoch: 5| Step: 8
Training loss: 1.85518636060408
Validation loss: 2.546874414923665

Epoch: 5| Step: 9
Training loss: 2.115710204083625
Validation loss: 2.5787611321057837

Epoch: 5| Step: 10
Training loss: 1.9504304533027514
Validation loss: 2.57576983989934

Epoch: 5| Step: 11
Training loss: 1.4641613807792686
Validation loss: 2.596273424174209

Epoch: 285| Step: 0
Training loss: 1.9812661997617174
Validation loss: 2.5971083749263273

Epoch: 5| Step: 1
Training loss: 2.4681572504320117
Validation loss: 2.5861444515306986

Epoch: 5| Step: 2
Training loss: 2.132787236214268
Validation loss: 2.5963597133402496

Epoch: 5| Step: 3
Training loss: 1.8348314565438237
Validation loss: 2.601334471155182

Epoch: 5| Step: 4
Training loss: 2.1437175158828254
Validation loss: 2.5768967236085767

Epoch: 5| Step: 5
Training loss: 1.892351544401697
Validation loss: 2.5601666534588063

Epoch: 5| Step: 6
Training loss: 1.807045325238025
Validation loss: 2.5345909064315277

Epoch: 5| Step: 7
Training loss: 2.523244183106456
Validation loss: 2.5318567270978525

Epoch: 5| Step: 8
Training loss: 2.4453873790452403
Validation loss: 2.5529213885232567

Epoch: 5| Step: 9
Training loss: 2.138313772102651
Validation loss: 2.544212478598417

Epoch: 5| Step: 10
Training loss: 2.073131671534819
Validation loss: 2.55273491981771

Epoch: 5| Step: 11
Training loss: 1.400196524859114
Validation loss: 2.556995873265274

Epoch: 286| Step: 0
Training loss: 2.017144391982862
Validation loss: 2.5676795398162975

Epoch: 5| Step: 1
Training loss: 2.09925448944822
Validation loss: 2.5912473470205346

Epoch: 5| Step: 2
Training loss: 2.475609629139593
Validation loss: 2.5920703305771324

Epoch: 5| Step: 3
Training loss: 1.6956083681195695
Validation loss: 2.607350224380805

Epoch: 5| Step: 4
Training loss: 2.184843030131615
Validation loss: 2.60870656952641

Epoch: 5| Step: 5
Training loss: 2.1757823457834986
Validation loss: 2.5929586053450406

Epoch: 5| Step: 6
Training loss: 1.7338763370702643
Validation loss: 2.6098733985640545

Epoch: 5| Step: 7
Training loss: 2.364238652274179
Validation loss: 2.5731437920054114

Epoch: 5| Step: 8
Training loss: 1.9723919077604917
Validation loss: 2.5730378988536144

Epoch: 5| Step: 9
Training loss: 2.327608499261889
Validation loss: 2.5797014214124454

Epoch: 5| Step: 10
Training loss: 1.9119045003639599
Validation loss: 2.5747922722504293

Epoch: 5| Step: 11
Training loss: 3.465343005004553
Validation loss: 2.5892738762476863

Epoch: 287| Step: 0
Training loss: 2.45899077422966
Validation loss: 2.6019949262478166

Epoch: 5| Step: 1
Training loss: 2.024772527657693
Validation loss: 2.622543188132824

Epoch: 5| Step: 2
Training loss: 1.8055009206021038
Validation loss: 2.6118547759224344

Epoch: 5| Step: 3
Training loss: 1.9886319613717633
Validation loss: 2.5787470096121465

Epoch: 5| Step: 4
Training loss: 1.9254475704911327
Validation loss: 2.5904192910700865

Epoch: 5| Step: 5
Training loss: 2.5619690507840436
Validation loss: 2.5614234244527645

Epoch: 5| Step: 6
Training loss: 2.0100273058350817
Validation loss: 2.5578512652952514

Epoch: 5| Step: 7
Training loss: 2.1906739233542623
Validation loss: 2.536151167634591

Epoch: 5| Step: 8
Training loss: 2.233061290892356
Validation loss: 2.530901702418571

Epoch: 5| Step: 9
Training loss: 1.6623033708440107
Validation loss: 2.579676275076764

Epoch: 5| Step: 10
Training loss: 2.6661026378028043
Validation loss: 2.590627905426421

Epoch: 5| Step: 11
Training loss: 1.345260480878545
Validation loss: 2.576606441976721

Epoch: 288| Step: 0
Training loss: 2.247261712296155
Validation loss: 2.6009225640598936

Epoch: 5| Step: 1
Training loss: 1.6925113582934297
Validation loss: 2.574089691523595

Epoch: 5| Step: 2
Training loss: 1.7496900965267155
Validation loss: 2.580184441492942

Epoch: 5| Step: 3
Training loss: 3.0746365836404084
Validation loss: 2.546583763586476

Epoch: 5| Step: 4
Training loss: 1.9721955922915329
Validation loss: 2.5653713042033353

Epoch: 5| Step: 5
Training loss: 1.8102030175514008
Validation loss: 2.551409314477081

Epoch: 5| Step: 6
Training loss: 2.4361760382975604
Validation loss: 2.5519444285108874

Epoch: 5| Step: 7
Training loss: 2.221983903450609
Validation loss: 2.5304855401083826

Epoch: 5| Step: 8
Training loss: 2.329846865488369
Validation loss: 2.566888416503837

Epoch: 5| Step: 9
Training loss: 1.7567573601886244
Validation loss: 2.581446925387865

Epoch: 5| Step: 10
Training loss: 1.8520941634946777
Validation loss: 2.5649895050188576

Epoch: 5| Step: 11
Training loss: 1.2701201965493487
Validation loss: 2.5968551815545227

Epoch: 289| Step: 0
Training loss: 2.5553588918211707
Validation loss: 2.588401757392312

Epoch: 5| Step: 1
Training loss: 1.779064376832745
Validation loss: 2.61058995330595

Epoch: 5| Step: 2
Training loss: 2.2578885286723427
Validation loss: 2.598771787432529

Epoch: 5| Step: 3
Training loss: 2.1437882489498468
Validation loss: 2.663088492753757

Epoch: 5| Step: 4
Training loss: 1.8790952464513888
Validation loss: 2.6489933972145008

Epoch: 5| Step: 5
Training loss: 2.700622899999952
Validation loss: 2.5947526809130164

Epoch: 5| Step: 6
Training loss: 2.178613870015245
Validation loss: 2.566522166955007

Epoch: 5| Step: 7
Training loss: 1.268536926568073
Validation loss: 2.5730289532539348

Epoch: 5| Step: 8
Training loss: 1.4673044923850718
Validation loss: 2.555151641554778

Epoch: 5| Step: 9
Training loss: 1.8534269964897832
Validation loss: 2.5188064400065913

Epoch: 5| Step: 10
Training loss: 1.9780858016386471
Validation loss: 2.514674913581797

Epoch: 5| Step: 11
Training loss: 3.5370594950065257
Validation loss: 2.5141207618513914

Epoch: 290| Step: 0
Training loss: 2.7538785459599406
Validation loss: 2.5073514655198097

Epoch: 5| Step: 1
Training loss: 1.9116366214048481
Validation loss: 2.5120048972993745

Epoch: 5| Step: 2
Training loss: 2.3446622980312286
Validation loss: 2.5038102122122963

Epoch: 5| Step: 3
Training loss: 2.3416714415948405
Validation loss: 2.5078360694102506

Epoch: 5| Step: 4
Training loss: 1.6094683277513318
Validation loss: 2.5158514509299454

Epoch: 5| Step: 5
Training loss: 2.1210031507613447
Validation loss: 2.520432646619762

Epoch: 5| Step: 6
Training loss: 1.4961449039170123
Validation loss: 2.538384968274612

Epoch: 5| Step: 7
Training loss: 2.029092082611831
Validation loss: 2.5410655019460155

Epoch: 5| Step: 8
Training loss: 2.1480355181465782
Validation loss: 2.5512995911307272

Epoch: 5| Step: 9
Training loss: 2.4328045736488773
Validation loss: 2.5801875293146064

Epoch: 5| Step: 10
Training loss: 2.356487604197262
Validation loss: 2.5954848389780136

Epoch: 5| Step: 11
Training loss: 1.668736015575548
Validation loss: 2.6180116371217195

Epoch: 291| Step: 0
Training loss: 2.270271430067431
Validation loss: 2.6143930994158597

Epoch: 5| Step: 1
Training loss: 2.13371431058279
Validation loss: 2.584648687038738

Epoch: 5| Step: 2
Training loss: 2.150872643382624
Validation loss: 2.578523816944862

Epoch: 5| Step: 3
Training loss: 1.4663033906105654
Validation loss: 2.5940164980654163

Epoch: 5| Step: 4
Training loss: 1.4957910136804058
Validation loss: 2.5686422678128342

Epoch: 5| Step: 5
Training loss: 1.9648794849703004
Validation loss: 2.590838399057803

Epoch: 5| Step: 6
Training loss: 2.373493720789451
Validation loss: 2.5880914228739753

Epoch: 5| Step: 7
Training loss: 1.9456069294512788
Validation loss: 2.5921322132029916

Epoch: 5| Step: 8
Training loss: 1.4754978762087505
Validation loss: 2.575721734172834

Epoch: 5| Step: 9
Training loss: 2.5028614834152476
Validation loss: 2.567732593558469

Epoch: 5| Step: 10
Training loss: 2.6457176083064557
Validation loss: 2.5671827630842716

Epoch: 5| Step: 11
Training loss: 3.4614707932012165
Validation loss: 2.562446237015602

Epoch: 292| Step: 0
Training loss: 1.6620424573182806
Validation loss: 2.560348382778542

Epoch: 5| Step: 1
Training loss: 2.3762777806262974
Validation loss: 2.6158614447890765

Epoch: 5| Step: 2
Training loss: 2.3885588849247426
Validation loss: 2.6993601642815395

Epoch: 5| Step: 3
Training loss: 2.417911954098709
Validation loss: 2.7060015299309432

Epoch: 5| Step: 4
Training loss: 2.528823820084132
Validation loss: 2.7427607242396705

Epoch: 5| Step: 5
Training loss: 2.2233397601071436
Validation loss: 2.677798963454592

Epoch: 5| Step: 6
Training loss: 2.6467661577385337
Validation loss: 2.573115801859252

Epoch: 5| Step: 7
Training loss: 2.324896090246688
Validation loss: 2.5018894168585453

Epoch: 5| Step: 8
Training loss: 1.7975619785834243
Validation loss: 2.5135523232398667

Epoch: 5| Step: 9
Training loss: 1.4317143981994016
Validation loss: 2.4990017805394626

Epoch: 5| Step: 10
Training loss: 2.1090439148079927
Validation loss: 2.5026560780317806

Epoch: 5| Step: 11
Training loss: 2.618009341433815
Validation loss: 2.5244500615733894

Epoch: 293| Step: 0
Training loss: 1.9060053433866744
Validation loss: 2.525826593793006

Epoch: 5| Step: 1
Training loss: 1.3613009347485239
Validation loss: 2.5597916262046514

Epoch: 5| Step: 2
Training loss: 2.587043917353581
Validation loss: 2.55797975273361

Epoch: 5| Step: 3
Training loss: 1.6878891955252422
Validation loss: 2.5493654934274974

Epoch: 5| Step: 4
Training loss: 2.072789046098629
Validation loss: 2.5480481938568214

Epoch: 5| Step: 5
Training loss: 2.3704753741819955
Validation loss: 2.5389313492770853

Epoch: 5| Step: 6
Training loss: 2.1170864855327336
Validation loss: 2.5375262185482024

Epoch: 5| Step: 7
Training loss: 2.485687101306314
Validation loss: 2.553194926287559

Epoch: 5| Step: 8
Training loss: 1.1955824403820416
Validation loss: 2.547039186611049

Epoch: 5| Step: 9
Training loss: 2.2573121252278523
Validation loss: 2.5799323518950383

Epoch: 5| Step: 10
Training loss: 2.7455482863648983
Validation loss: 2.5774283575713572

Epoch: 5| Step: 11
Training loss: 2.6963519317360283
Validation loss: 2.611398445348566

Epoch: 294| Step: 0
Training loss: 1.9563448800670102
Validation loss: 2.6767393044508374

Epoch: 5| Step: 1
Training loss: 2.505216687057007
Validation loss: 2.717428869312591

Epoch: 5| Step: 2
Training loss: 2.256437100501427
Validation loss: 2.6851595660579397

Epoch: 5| Step: 3
Training loss: 2.2580861912403414
Validation loss: 2.6358455012528355

Epoch: 5| Step: 4
Training loss: 1.922724838304485
Validation loss: 2.581026071098034

Epoch: 5| Step: 5
Training loss: 2.3879350475570558
Validation loss: 2.5513293196929263

Epoch: 5| Step: 6
Training loss: 1.3999219293624685
Validation loss: 2.5269243972394713

Epoch: 5| Step: 7
Training loss: 2.780631864628857
Validation loss: 2.5512632972847977

Epoch: 5| Step: 8
Training loss: 2.361241290923052
Validation loss: 2.5390263677129106

Epoch: 5| Step: 9
Training loss: 1.804250755141815
Validation loss: 2.545017118664959

Epoch: 5| Step: 10
Training loss: 1.7051295112129035
Validation loss: 2.542683149278427

Epoch: 5| Step: 11
Training loss: 2.538847553251499
Validation loss: 2.5523984960984722

Epoch: 295| Step: 0
Training loss: 2.689375378295957
Validation loss: 2.564987475585848

Epoch: 5| Step: 1
Training loss: 2.0148955215364195
Validation loss: 2.53901270108416

Epoch: 5| Step: 2
Training loss: 1.8058186738751651
Validation loss: 2.5467491547867196

Epoch: 5| Step: 3
Training loss: 1.8678290888876317
Validation loss: 2.547318741692548

Epoch: 5| Step: 4
Training loss: 1.9260694431291565
Validation loss: 2.5553356791032766

Epoch: 5| Step: 5
Training loss: 2.491619559600774
Validation loss: 2.5647400973636674

Epoch: 5| Step: 6
Training loss: 2.9211207757655084
Validation loss: 2.5732919609762153

Epoch: 5| Step: 7
Training loss: 1.6802163644383106
Validation loss: 2.579910295963713

Epoch: 5| Step: 8
Training loss: 1.7322093054788936
Validation loss: 2.5526256776494995

Epoch: 5| Step: 9
Training loss: 2.078524214180712
Validation loss: 2.591332929492262

Epoch: 5| Step: 10
Training loss: 1.996859648023165
Validation loss: 2.595551876027358

Epoch: 5| Step: 11
Training loss: 1.9536409230697243
Validation loss: 2.6099136085998627

Epoch: 296| Step: 0
Training loss: 2.304572047558439
Validation loss: 2.6214141611961868

Epoch: 5| Step: 1
Training loss: 2.426916867115336
Validation loss: 2.63997952248598

Epoch: 5| Step: 2
Training loss: 1.7180547521834815
Validation loss: 2.597765590880979

Epoch: 5| Step: 3
Training loss: 1.7475196426881188
Validation loss: 2.602591485789147

Epoch: 5| Step: 4
Training loss: 2.3751960472706184
Validation loss: 2.58889326334028

Epoch: 5| Step: 5
Training loss: 1.84103866617769
Validation loss: 2.5672527912464123

Epoch: 5| Step: 6
Training loss: 2.502178863895435
Validation loss: 2.5743649276730225

Epoch: 5| Step: 7
Training loss: 1.9508754745661738
Validation loss: 2.559492723011101

Epoch: 5| Step: 8
Training loss: 1.9266907438117926
Validation loss: 2.5335870322970546

Epoch: 5| Step: 9
Training loss: 1.8225344738623597
Validation loss: 2.559860428455009

Epoch: 5| Step: 10
Training loss: 2.1010425023569144
Validation loss: 2.5343823184696745

Epoch: 5| Step: 11
Training loss: 1.725696605507896
Validation loss: 2.529198388105512

Epoch: 297| Step: 0
Training loss: 1.7019219305240993
Validation loss: 2.549390280203085

Epoch: 5| Step: 1
Training loss: 1.9100126434826419
Validation loss: 2.5388546198329824

Epoch: 5| Step: 2
Training loss: 2.1497205197748075
Validation loss: 2.5528366080070497

Epoch: 5| Step: 3
Training loss: 1.7846872059924204
Validation loss: 2.5369226329698935

Epoch: 5| Step: 4
Training loss: 2.133923140095367
Validation loss: 2.5528081500428486

Epoch: 5| Step: 5
Training loss: 1.846662064361805
Validation loss: 2.5787121229461083

Epoch: 5| Step: 6
Training loss: 2.3579408442589083
Validation loss: 2.5516047256006367

Epoch: 5| Step: 7
Training loss: 2.737770109045482
Validation loss: 2.5933629593611576

Epoch: 5| Step: 8
Training loss: 1.79564233045915
Validation loss: 2.625391158978102

Epoch: 5| Step: 9
Training loss: 2.2658197779622355
Validation loss: 2.6018084160676183

Epoch: 5| Step: 10
Training loss: 1.8517483002356279
Validation loss: 2.644188998232544

Epoch: 5| Step: 11
Training loss: 2.4687828351505097
Validation loss: 2.6216812801822793

Epoch: 298| Step: 0
Training loss: 1.2901408453501344
Validation loss: 2.606518765945369

Epoch: 5| Step: 1
Training loss: 1.9985792955286381
Validation loss: 2.609703793245484

Epoch: 5| Step: 2
Training loss: 2.3346958496532655
Validation loss: 2.649822870518621

Epoch: 5| Step: 3
Training loss: 2.094356505956364
Validation loss: 2.6069140564821787

Epoch: 5| Step: 4
Training loss: 2.3316367884428773
Validation loss: 2.6277961370979623

Epoch: 5| Step: 5
Training loss: 2.100818715128516
Validation loss: 2.648952066551853

Epoch: 5| Step: 6
Training loss: 2.0655675098077144
Validation loss: 2.624200439919224

Epoch: 5| Step: 7
Training loss: 2.753552483095364
Validation loss: 2.6312384574195997

Epoch: 5| Step: 8
Training loss: 1.5549030250411453
Validation loss: 2.6229668569774813

Epoch: 5| Step: 9
Training loss: 2.2387005744389774
Validation loss: 2.6194377923076204

Epoch: 5| Step: 10
Training loss: 1.5642085842693514
Validation loss: 2.6226270296576732

Epoch: 5| Step: 11
Training loss: 1.2190742550390485
Validation loss: 2.6023449565938477

Epoch: 299| Step: 0
Training loss: 1.7048446652753722
Validation loss: 2.6385136953849893

Epoch: 5| Step: 1
Training loss: 1.8300445781552095
Validation loss: 2.6225375876174035

Epoch: 5| Step: 2
Training loss: 2.052424239550449
Validation loss: 2.6054231409964155

Epoch: 5| Step: 3
Training loss: 2.5018539230369896
Validation loss: 2.6066906002373593

Epoch: 5| Step: 4
Training loss: 1.580823724758056
Validation loss: 2.6466168059637787

Epoch: 5| Step: 5
Training loss: 2.0640837628571016
Validation loss: 2.6479914917016845

Epoch: 5| Step: 6
Training loss: 2.3995693654906134
Validation loss: 2.637299051358576

Epoch: 5| Step: 7
Training loss: 1.8267855831871205
Validation loss: 2.6334424345336087

Epoch: 5| Step: 8
Training loss: 1.4903907543841595
Validation loss: 2.6169580273591286

Epoch: 5| Step: 9
Training loss: 2.7387815010351955
Validation loss: 2.623671149913221

Epoch: 5| Step: 10
Training loss: 2.366091937364394
Validation loss: 2.6326788388215827

Epoch: 5| Step: 11
Training loss: 1.6326911552641494
Validation loss: 2.6063382262643287

Epoch: 300| Step: 0
Training loss: 1.4170696676407224
Validation loss: 2.6186400410912465

Epoch: 5| Step: 1
Training loss: 2.296582054089196
Validation loss: 2.623888393457873

Epoch: 5| Step: 2
Training loss: 2.0012085362653584
Validation loss: 2.6181247987593066

Epoch: 5| Step: 3
Training loss: 2.0521003477162534
Validation loss: 2.6118605457778314

Epoch: 5| Step: 4
Training loss: 2.124937056562911
Validation loss: 2.639795300905668

Epoch: 5| Step: 5
Training loss: 2.9126969888892447
Validation loss: 2.6271790209977057

Epoch: 5| Step: 6
Training loss: 1.839752000598465
Validation loss: 2.6507127079345465

Epoch: 5| Step: 7
Training loss: 2.372399060400322
Validation loss: 2.6105017599214246

Epoch: 5| Step: 8
Training loss: 1.3873774293939616
Validation loss: 2.5864495291978065

Epoch: 5| Step: 9
Training loss: 1.667978612794684
Validation loss: 2.5791360086540642

Epoch: 5| Step: 10
Training loss: 2.0020367265318395
Validation loss: 2.568865294239733

Epoch: 5| Step: 11
Training loss: 1.801387262878756
Validation loss: 2.5700810916701573

Epoch: 301| Step: 0
Training loss: 2.826801222066803
Validation loss: 2.5774825056563366

Epoch: 5| Step: 1
Training loss: 2.1609359906702292
Validation loss: 2.565971991940908

Epoch: 5| Step: 2
Training loss: 1.7373660303514598
Validation loss: 2.549747493184741

Epoch: 5| Step: 3
Training loss: 1.2904194943022713
Validation loss: 2.5831240612809476

Epoch: 5| Step: 4
Training loss: 2.1081542827383104
Validation loss: 2.5688651086180205

Epoch: 5| Step: 5
Training loss: 2.055068644284406
Validation loss: 2.5906201019363513

Epoch: 5| Step: 6
Training loss: 1.4597099164949592
Validation loss: 2.578643862213037

Epoch: 5| Step: 7
Training loss: 1.7461962232453414
Validation loss: 2.605677053502409

Epoch: 5| Step: 8
Training loss: 1.9659829449073936
Validation loss: 2.602448867084215

Epoch: 5| Step: 9
Training loss: 2.2581360265070356
Validation loss: 2.602151905150941

Epoch: 5| Step: 10
Training loss: 2.1825654094110036
Validation loss: 2.6271575507849008

Epoch: 5| Step: 11
Training loss: 3.619552860570132
Validation loss: 2.659217089855664

Epoch: 302| Step: 0
Training loss: 2.354827034302246
Validation loss: 2.68033261406964

Epoch: 5| Step: 1
Training loss: 2.7669484048657664
Validation loss: 2.754152807286451

Epoch: 5| Step: 2
Training loss: 2.198927106203386
Validation loss: 2.6794643216482603

Epoch: 5| Step: 3
Training loss: 1.9848574554995992
Validation loss: 2.659109584684228

Epoch: 5| Step: 4
Training loss: 2.2743125883063247
Validation loss: 2.6248375183863515

Epoch: 5| Step: 5
Training loss: 1.890667560192932
Validation loss: 2.575582896308649

Epoch: 5| Step: 6
Training loss: 1.3221908841217163
Validation loss: 2.55065792656051

Epoch: 5| Step: 7
Training loss: 2.105051540731424
Validation loss: 2.4966487317296293

Epoch: 5| Step: 8
Training loss: 2.065343803622207
Validation loss: 2.5303578040641983

Epoch: 5| Step: 9
Training loss: 2.1902324504377804
Validation loss: 2.5299671831377393

Epoch: 5| Step: 10
Training loss: 1.640769370856756
Validation loss: 2.503092514062228

Epoch: 5| Step: 11
Training loss: 3.365337810819683
Validation loss: 2.5358583548827496

Epoch: 303| Step: 0
Training loss: 1.7014183102440492
Validation loss: 2.542456005338455

Epoch: 5| Step: 1
Training loss: 2.4927553110017326
Validation loss: 2.5339093426103756

Epoch: 5| Step: 2
Training loss: 1.1342132852425038
Validation loss: 2.5555402516572543

Epoch: 5| Step: 3
Training loss: 1.9348175183581793
Validation loss: 2.586923655147391

Epoch: 5| Step: 4
Training loss: 2.0400629037620757
Validation loss: 2.6095703036682285

Epoch: 5| Step: 5
Training loss: 1.8941971002436713
Validation loss: 2.620630324698177

Epoch: 5| Step: 6
Training loss: 2.2392494011848676
Validation loss: 2.636511580252191

Epoch: 5| Step: 7
Training loss: 2.2350755140276046
Validation loss: 2.6562212923779964

Epoch: 5| Step: 8
Training loss: 2.2516280747764674
Validation loss: 2.591709272508715

Epoch: 5| Step: 9
Training loss: 2.340025218110442
Validation loss: 2.6071257614793306

Epoch: 5| Step: 10
Training loss: 1.7936223320270879
Validation loss: 2.59575955932595

Epoch: 5| Step: 11
Training loss: 2.296220647284761
Validation loss: 2.6185137600433097

Epoch: 304| Step: 0
Training loss: 1.7887234428988126
Validation loss: 2.64112253787515

Epoch: 5| Step: 1
Training loss: 2.1582064391235867
Validation loss: 2.7024653443882545

Epoch: 5| Step: 2
Training loss: 2.5824627998974163
Validation loss: 2.654712119614183

Epoch: 5| Step: 3
Training loss: 1.5398630296805629
Validation loss: 2.6619862159233123

Epoch: 5| Step: 4
Training loss: 2.1617306702412353
Validation loss: 2.630990753631699

Epoch: 5| Step: 5
Training loss: 2.004549336002062
Validation loss: 2.603617890074418

Epoch: 5| Step: 6
Training loss: 1.8142637681652838
Validation loss: 2.5613702012442303

Epoch: 5| Step: 7
Training loss: 1.911436623043768
Validation loss: 2.58228889753453

Epoch: 5| Step: 8
Training loss: 2.02176057706981
Validation loss: 2.5553611155037284

Epoch: 5| Step: 9
Training loss: 2.456031972124081
Validation loss: 2.550395712504389

Epoch: 5| Step: 10
Training loss: 1.9468688866778014
Validation loss: 2.545887929379875

Epoch: 5| Step: 11
Training loss: 2.519167378491011
Validation loss: 2.536526404269624

Epoch: 305| Step: 0
Training loss: 2.319641427249734
Validation loss: 2.5771994499582314

Epoch: 5| Step: 1
Training loss: 1.6201314620848692
Validation loss: 2.5750133347397495

Epoch: 5| Step: 2
Training loss: 1.7206222047516344
Validation loss: 2.6009003194571236

Epoch: 5| Step: 3
Training loss: 1.8845331710806903
Validation loss: 2.6011450378160923

Epoch: 5| Step: 4
Training loss: 1.8786692003856185
Validation loss: 2.6328071835668903

Epoch: 5| Step: 5
Training loss: 2.481908665632609
Validation loss: 2.640617201302654

Epoch: 5| Step: 6
Training loss: 2.181061998370258
Validation loss: 2.6400679615874836

Epoch: 5| Step: 7
Training loss: 1.9104303268670848
Validation loss: 2.5946453839363115

Epoch: 5| Step: 8
Training loss: 2.6757524697642463
Validation loss: 2.5856151860141314

Epoch: 5| Step: 9
Training loss: 1.726391123555992
Validation loss: 2.56679444495561

Epoch: 5| Step: 10
Training loss: 2.1009226679416697
Validation loss: 2.579271485464024

Epoch: 5| Step: 11
Training loss: 0.7438867491337672
Validation loss: 2.585494603763404

Epoch: 306| Step: 0
Training loss: 2.1925250510651733
Validation loss: 2.568354733539057

Epoch: 5| Step: 1
Training loss: 1.7754185572610186
Validation loss: 2.5887668493764164

Epoch: 5| Step: 2
Training loss: 2.050020901643218
Validation loss: 2.586153764699637

Epoch: 5| Step: 3
Training loss: 2.1564782063342376
Validation loss: 2.589027870819927

Epoch: 5| Step: 4
Training loss: 1.9140073184408586
Validation loss: 2.575277516925511

Epoch: 5| Step: 5
Training loss: 1.7860494503467317
Validation loss: 2.6519626199399946

Epoch: 5| Step: 6
Training loss: 2.07794567280926
Validation loss: 2.66247851582487

Epoch: 5| Step: 7
Training loss: 2.115341000674194
Validation loss: 2.6433985137559874

Epoch: 5| Step: 8
Training loss: 1.95303478795568
Validation loss: 2.6155333496468414

Epoch: 5| Step: 9
Training loss: 1.9970897720246916
Validation loss: 2.595203375469526

Epoch: 5| Step: 10
Training loss: 2.4158858539635317
Validation loss: 2.543401311209252

Epoch: 5| Step: 11
Training loss: 2.4234309950839017
Validation loss: 2.5355424787598535

Epoch: 307| Step: 0
Training loss: 2.0248808554931994
Validation loss: 2.5513596475312577

Epoch: 5| Step: 1
Training loss: 2.4288887109181503
Validation loss: 2.5314895826542663

Epoch: 5| Step: 2
Training loss: 2.3705780624864046
Validation loss: 2.53875853063921

Epoch: 5| Step: 3
Training loss: 1.7178138264065765
Validation loss: 2.55256454186908

Epoch: 5| Step: 4
Training loss: 2.443457829407542
Validation loss: 2.5494048536703198

Epoch: 5| Step: 5
Training loss: 1.7932693794550945
Validation loss: 2.5442168693064637

Epoch: 5| Step: 6
Training loss: 1.8528126548269037
Validation loss: 2.5670568105162013

Epoch: 5| Step: 7
Training loss: 2.1172656505842724
Validation loss: 2.5425576865642174

Epoch: 5| Step: 8
Training loss: 1.7318827963371
Validation loss: 2.5632053815517097

Epoch: 5| Step: 9
Training loss: 1.8665383459444662
Validation loss: 2.5646506797775497

Epoch: 5| Step: 10
Training loss: 2.065596250486923
Validation loss: 2.5702507452227645

Epoch: 5| Step: 11
Training loss: 1.2705433728389655
Validation loss: 2.5710740009740585

Epoch: 308| Step: 0
Training loss: 1.5594201824851415
Validation loss: 2.588961344008827

Epoch: 5| Step: 1
Training loss: 1.9886811159721334
Validation loss: 2.548865575990274

Epoch: 5| Step: 2
Training loss: 1.8658816827140834
Validation loss: 2.568192246176268

Epoch: 5| Step: 3
Training loss: 2.221995706404719
Validation loss: 2.5617083202699242

Epoch: 5| Step: 4
Training loss: 1.7722597622790193
Validation loss: 2.5831069783030434

Epoch: 5| Step: 5
Training loss: 1.9184054559273722
Validation loss: 2.565636111385246

Epoch: 5| Step: 6
Training loss: 1.6912535847402448
Validation loss: 2.552510188210355

Epoch: 5| Step: 7
Training loss: 2.1229498454138236
Validation loss: 2.577642765605328

Epoch: 5| Step: 8
Training loss: 2.626693633355813
Validation loss: 2.571758617117837

Epoch: 5| Step: 9
Training loss: 1.9454131808902997
Validation loss: 2.562381695133132

Epoch: 5| Step: 10
Training loss: 2.009665617386951
Validation loss: 2.556875060280484

Epoch: 5| Step: 11
Training loss: 1.7234942069801513
Validation loss: 2.584025157050153

Epoch: 309| Step: 0
Training loss: 2.10083256066911
Validation loss: 2.56942551293716

Epoch: 5| Step: 1
Training loss: 1.7251440927888892
Validation loss: 2.582129422243743

Epoch: 5| Step: 2
Training loss: 2.228948552759437
Validation loss: 2.6010204128445547

Epoch: 5| Step: 3
Training loss: 1.4206631704926191
Validation loss: 2.6039683965863976

Epoch: 5| Step: 4
Training loss: 1.8065654677145786
Validation loss: 2.6149859833934324

Epoch: 5| Step: 5
Training loss: 1.714328001840455
Validation loss: 2.6383076418045257

Epoch: 5| Step: 6
Training loss: 2.2440168514264958
Validation loss: 2.634566336999315

Epoch: 5| Step: 7
Training loss: 2.383476990147175
Validation loss: 2.6569851624640815

Epoch: 5| Step: 8
Training loss: 1.7742827833505541
Validation loss: 2.6413046509576534

Epoch: 5| Step: 9
Training loss: 1.8820789221857668
Validation loss: 2.61167731146194

Epoch: 5| Step: 10
Training loss: 2.1341348538106177
Validation loss: 2.580903559674556

Epoch: 5| Step: 11
Training loss: 2.859802214179091
Validation loss: 2.615488075674007

Epoch: 310| Step: 0
Training loss: 2.0846457607212
Validation loss: 2.5788321209268634

Epoch: 5| Step: 1
Training loss: 1.9009388586663742
Validation loss: 2.624612109726033

Epoch: 5| Step: 2
Training loss: 2.4197568429211076
Validation loss: 2.647990955228091

Epoch: 5| Step: 3
Training loss: 2.063595798584132
Validation loss: 2.6348651049973015

Epoch: 5| Step: 4
Training loss: 2.1744202992281214
Validation loss: 2.625474292807016

Epoch: 5| Step: 5
Training loss: 1.7151060142781298
Validation loss: 2.5902477426864263

Epoch: 5| Step: 6
Training loss: 1.781525841486184
Validation loss: 2.5665422090992984

Epoch: 5| Step: 7
Training loss: 1.862685582176634
Validation loss: 2.531590364280305

Epoch: 5| Step: 8
Training loss: 1.936285992183805
Validation loss: 2.5236821956510287

Epoch: 5| Step: 9
Training loss: 1.8866560710344358
Validation loss: 2.5057446717917933

Epoch: 5| Step: 10
Training loss: 2.033586420140519
Validation loss: 2.501107860506396

Epoch: 5| Step: 11
Training loss: 2.945764805393718
Validation loss: 2.5110619290817544

Epoch: 311| Step: 0
Training loss: 2.5297816220751947
Validation loss: 2.5282024396832936

Epoch: 5| Step: 1
Training loss: 1.8856950909083512
Validation loss: 2.532970110887962

Epoch: 5| Step: 2
Training loss: 2.092623621161371
Validation loss: 2.5155295636257

Epoch: 5| Step: 3
Training loss: 2.1743849926198378
Validation loss: 2.525606347291837

Epoch: 5| Step: 4
Training loss: 1.537397461860222
Validation loss: 2.5527274635881

Epoch: 5| Step: 5
Training loss: 1.7156268093745795
Validation loss: 2.553724474898392

Epoch: 5| Step: 6
Training loss: 1.6575923733985014
Validation loss: 2.5456692097720564

Epoch: 5| Step: 7
Training loss: 2.169670468109281
Validation loss: 2.5189012000907627

Epoch: 5| Step: 8
Training loss: 2.142129299895196
Validation loss: 2.506147063369816

Epoch: 5| Step: 9
Training loss: 2.4193048437141704
Validation loss: 2.517037857757091

Epoch: 5| Step: 10
Training loss: 1.6420499880171044
Validation loss: 2.5354074472235193

Epoch: 5| Step: 11
Training loss: 2.9184756164316425
Validation loss: 2.5046772674840168

Epoch: 312| Step: 0
Training loss: 2.083595361126111
Validation loss: 2.537567089553172

Epoch: 5| Step: 1
Training loss: 1.8807584709758616
Validation loss: 2.522864754066868

Epoch: 5| Step: 2
Training loss: 1.7007537573229394
Validation loss: 2.579735112496973

Epoch: 5| Step: 3
Training loss: 2.3059142904771757
Validation loss: 2.6149808624520365

Epoch: 5| Step: 4
Training loss: 2.361741249918666
Validation loss: 2.63182092967853

Epoch: 5| Step: 5
Training loss: 2.0860707672638323
Validation loss: 2.661346423240506

Epoch: 5| Step: 6
Training loss: 1.9475101788001394
Validation loss: 2.6191291249378557

Epoch: 5| Step: 7
Training loss: 1.817198156192725
Validation loss: 2.6000200802687856

Epoch: 5| Step: 8
Training loss: 1.8002301943134107
Validation loss: 2.6006106753765756

Epoch: 5| Step: 9
Training loss: 1.8414157380032397
Validation loss: 2.582049128806677

Epoch: 5| Step: 10
Training loss: 1.6723647781699504
Validation loss: 2.624410494959306

Epoch: 5| Step: 11
Training loss: 2.326032171530391
Validation loss: 2.590807988875252

Epoch: 313| Step: 0
Training loss: 1.715683160292847
Validation loss: 2.565950942621593

Epoch: 5| Step: 1
Training loss: 1.3910442963162477
Validation loss: 2.535375678661817

Epoch: 5| Step: 2
Training loss: 2.2588461651410032
Validation loss: 2.5408626220051813

Epoch: 5| Step: 3
Training loss: 1.6981219380182284
Validation loss: 2.53934896564838

Epoch: 5| Step: 4
Training loss: 2.2759831913493316
Validation loss: 2.574283705158618

Epoch: 5| Step: 5
Training loss: 2.2468811247295153
Validation loss: 2.571502251726866

Epoch: 5| Step: 6
Training loss: 2.055311217119867
Validation loss: 2.595487123969032

Epoch: 5| Step: 7
Training loss: 2.175340371519848
Validation loss: 2.5894986090964798

Epoch: 5| Step: 8
Training loss: 2.103353538395985
Validation loss: 2.617142019303694

Epoch: 5| Step: 9
Training loss: 2.115821087764097
Validation loss: 2.592860938904751

Epoch: 5| Step: 10
Training loss: 1.5248977314161354
Validation loss: 2.6528384721568843

Epoch: 5| Step: 11
Training loss: 2.9196223586976497
Validation loss: 2.67317566621535

Epoch: 314| Step: 0
Training loss: 2.414652928119308
Validation loss: 2.694626710785507

Epoch: 5| Step: 1
Training loss: 1.9774163252806245
Validation loss: 2.6914904673059885

Epoch: 5| Step: 2
Training loss: 1.9397843338358634
Validation loss: 2.6708998545864326

Epoch: 5| Step: 3
Training loss: 1.868522135133117
Validation loss: 2.625222681076608

Epoch: 5| Step: 4
Training loss: 1.5552893005811483
Validation loss: 2.5879212153324196

Epoch: 5| Step: 5
Training loss: 2.1117460135486286
Validation loss: 2.569247489904093

Epoch: 5| Step: 6
Training loss: 2.307070776797459
Validation loss: 2.545361375271162

Epoch: 5| Step: 7
Training loss: 2.3388827839054622
Validation loss: 2.5059388807909544

Epoch: 5| Step: 8
Training loss: 2.178992266511258
Validation loss: 2.529977188032638

Epoch: 5| Step: 9
Training loss: 1.8081978350150125
Validation loss: 2.502017343705967

Epoch: 5| Step: 10
Training loss: 1.794583792077118
Validation loss: 2.496699037426911

Epoch: 5| Step: 11
Training loss: 1.5486286896001131
Validation loss: 2.5295744165564877

Epoch: 315| Step: 0
Training loss: 2.1667155724899176
Validation loss: 2.527704530540839

Epoch: 5| Step: 1
Training loss: 1.588403597808967
Validation loss: 2.5419656520361746

Epoch: 5| Step: 2
Training loss: 1.807808757174746
Validation loss: 2.5312365661076233

Epoch: 5| Step: 3
Training loss: 2.4143584727354357
Validation loss: 2.5428369334600593

Epoch: 5| Step: 4
Training loss: 2.3611567760863625
Validation loss: 2.5653332383683036

Epoch: 5| Step: 5
Training loss: 1.7167758354486173
Validation loss: 2.604576766466003

Epoch: 5| Step: 6
Training loss: 1.9952582534908028
Validation loss: 2.611401074003268

Epoch: 5| Step: 7
Training loss: 2.154700676294749
Validation loss: 2.6399768131615398

Epoch: 5| Step: 8
Training loss: 1.5344587687760562
Validation loss: 2.5997183700705353

Epoch: 5| Step: 9
Training loss: 1.9180823018631346
Validation loss: 2.570880197214322

Epoch: 5| Step: 10
Training loss: 2.1228177702394833
Validation loss: 2.5966810073648334

Epoch: 5| Step: 11
Training loss: 1.5012055956318726
Validation loss: 2.5644722923536754

Epoch: 316| Step: 0
Training loss: 2.1435786009130235
Validation loss: 2.556881109612836

Epoch: 5| Step: 1
Training loss: 1.9558241237406755
Validation loss: 2.585903666909772

Epoch: 5| Step: 2
Training loss: 1.4747189108479533
Validation loss: 2.565205870546908

Epoch: 5| Step: 3
Training loss: 1.5327093216042207
Validation loss: 2.5789928170210508

Epoch: 5| Step: 4
Training loss: 1.868217535295553
Validation loss: 2.6143819698490405

Epoch: 5| Step: 5
Training loss: 2.2343602746865083
Validation loss: 2.5833171272282227

Epoch: 5| Step: 6
Training loss: 2.4917238575507517
Validation loss: 2.5971535064721087

Epoch: 5| Step: 7
Training loss: 1.855788032767939
Validation loss: 2.6116391864281088

Epoch: 5| Step: 8
Training loss: 2.064667227766638
Validation loss: 2.6133825361374563

Epoch: 5| Step: 9
Training loss: 1.7313044405203208
Validation loss: 2.628870838639091

Epoch: 5| Step: 10
Training loss: 2.1251325005005777
Validation loss: 2.634165924421731

Epoch: 5| Step: 11
Training loss: 1.7771821000922858
Validation loss: 2.587310038763808

Epoch: 317| Step: 0
Training loss: 2.0878068070319076
Validation loss: 2.5667287042374114

Epoch: 5| Step: 1
Training loss: 2.4595355203246254
Validation loss: 2.5713146501584707

Epoch: 5| Step: 2
Training loss: 1.6161479465160595
Validation loss: 2.5566818878986073

Epoch: 5| Step: 3
Training loss: 2.0445140005571303
Validation loss: 2.580432587386663

Epoch: 5| Step: 4
Training loss: 2.1587668946913268
Validation loss: 2.5926209562379934

Epoch: 5| Step: 5
Training loss: 1.8596891891069263
Validation loss: 2.573797057309683

Epoch: 5| Step: 6
Training loss: 1.4097520243600923
Validation loss: 2.6066897923044543

Epoch: 5| Step: 7
Training loss: 1.9276887372304854
Validation loss: 2.590717714811061

Epoch: 5| Step: 8
Training loss: 1.3541738167598445
Validation loss: 2.6198420674586775

Epoch: 5| Step: 9
Training loss: 2.0097620660956097
Validation loss: 2.6372699980766336

Epoch: 5| Step: 10
Training loss: 2.2128178987732143
Validation loss: 2.6035658079606585

Epoch: 5| Step: 11
Training loss: 2.2717700624433297
Validation loss: 2.5840067882916165

Epoch: 318| Step: 0
Training loss: 1.940431100492534
Validation loss: 2.5861774959391153

Epoch: 5| Step: 1
Training loss: 1.196148349504959
Validation loss: 2.5797383163810603

Epoch: 5| Step: 2
Training loss: 1.9733236562431462
Validation loss: 2.588326517498559

Epoch: 5| Step: 3
Training loss: 1.752981507111847
Validation loss: 2.585522790329718

Epoch: 5| Step: 4
Training loss: 1.967429429646316
Validation loss: 2.5822726342219373

Epoch: 5| Step: 5
Training loss: 1.1292763601608347
Validation loss: 2.6048394948894735

Epoch: 5| Step: 6
Training loss: 2.3630015814635046
Validation loss: 2.6351606536173997

Epoch: 5| Step: 7
Training loss: 1.8778857594478715
Validation loss: 2.655909523927862

Epoch: 5| Step: 8
Training loss: 2.634372690364961
Validation loss: 2.6209076020816613

Epoch: 5| Step: 9
Training loss: 1.6901869398478029
Validation loss: 2.6353450333179302

Epoch: 5| Step: 10
Training loss: 2.3846206558491114
Validation loss: 2.597337210813222

Epoch: 5| Step: 11
Training loss: 1.5249180568504797
Validation loss: 2.613819429930958

Epoch: 319| Step: 0
Training loss: 1.9886006696395875
Validation loss: 2.5893468979558127

Epoch: 5| Step: 1
Training loss: 1.6683141989409367
Validation loss: 2.602952747973204

Epoch: 5| Step: 2
Training loss: 1.8807922541445459
Validation loss: 2.6124089585644357

Epoch: 5| Step: 3
Training loss: 1.3101548178385742
Validation loss: 2.6073352737427666

Epoch: 5| Step: 4
Training loss: 1.6903961901152862
Validation loss: 2.6475414496993293

Epoch: 5| Step: 5
Training loss: 1.9516633324576982
Validation loss: 2.626380833491786

Epoch: 5| Step: 6
Training loss: 2.119346390679859
Validation loss: 2.606879611545125

Epoch: 5| Step: 7
Training loss: 1.720969760773189
Validation loss: 2.6264107788368847

Epoch: 5| Step: 8
Training loss: 2.3103550422597747
Validation loss: 2.64398104617755

Epoch: 5| Step: 9
Training loss: 2.0697267099473855
Validation loss: 2.62947538128175

Epoch: 5| Step: 10
Training loss: 2.3915876058698524
Validation loss: 2.629466011872713

Epoch: 5| Step: 11
Training loss: 1.242756455356528
Validation loss: 2.615270160926869

Epoch: 320| Step: 0
Training loss: 2.5302465828310052
Validation loss: 2.612375738300701

Epoch: 5| Step: 1
Training loss: 1.823025037178203
Validation loss: 2.6167154370357166

Epoch: 5| Step: 2
Training loss: 2.08814114529837
Validation loss: 2.606614737294237

Epoch: 5| Step: 3
Training loss: 1.4026267103594925
Validation loss: 2.6237620128946024

Epoch: 5| Step: 4
Training loss: 1.4922337549839668
Validation loss: 2.6061759629470944

Epoch: 5| Step: 5
Training loss: 2.149770427246142
Validation loss: 2.610076041094378

Epoch: 5| Step: 6
Training loss: 1.856447945261317
Validation loss: 2.5917878025014005

Epoch: 5| Step: 7
Training loss: 1.4064214813794342
Validation loss: 2.6095345804296657

Epoch: 5| Step: 8
Training loss: 1.9660253896305915
Validation loss: 2.588873281031627

Epoch: 5| Step: 9
Training loss: 1.714174248556982
Validation loss: 2.576668869484786

Epoch: 5| Step: 10
Training loss: 2.4448775126974165
Validation loss: 2.586888099195469

Epoch: 5| Step: 11
Training loss: 1.831630573501391
Validation loss: 2.6046970755514156

Epoch: 321| Step: 0
Training loss: 1.9158432131470076
Validation loss: 2.60981728846601

Epoch: 5| Step: 1
Training loss: 1.8104199279591897
Validation loss: 2.6551404281100206

Epoch: 5| Step: 2
Training loss: 1.621466536344524
Validation loss: 2.624019341228408

Epoch: 5| Step: 3
Training loss: 2.276194994291696
Validation loss: 2.6028081605694706

Epoch: 5| Step: 4
Training loss: 1.8019742179279443
Validation loss: 2.5983623415013035

Epoch: 5| Step: 5
Training loss: 1.9645709536645455
Validation loss: 2.557346853578818

Epoch: 5| Step: 6
Training loss: 2.144627970197675
Validation loss: 2.546083413113148

Epoch: 5| Step: 7
Training loss: 1.962824669484258
Validation loss: 2.5223710136024784

Epoch: 5| Step: 8
Training loss: 2.310590832276814
Validation loss: 2.5452812216319796

Epoch: 5| Step: 9
Training loss: 1.9912924756861723
Validation loss: 2.561580966114875

Epoch: 5| Step: 10
Training loss: 2.0517638550006216
Validation loss: 2.5477195774767827

Epoch: 5| Step: 11
Training loss: 1.5887989857202693
Validation loss: 2.556426211954696

Epoch: 322| Step: 0
Training loss: 1.586572905035427
Validation loss: 2.597902516711708

Epoch: 5| Step: 1
Training loss: 2.131137511565287
Validation loss: 2.6266634378397247

Epoch: 5| Step: 2
Training loss: 2.393287323143756
Validation loss: 2.5922757405627235

Epoch: 5| Step: 3
Training loss: 2.119761123874584
Validation loss: 2.6239270144162523

Epoch: 5| Step: 4
Training loss: 1.7266550859163579
Validation loss: 2.596980346856503

Epoch: 5| Step: 5
Training loss: 2.1521819065952412
Validation loss: 2.5769809881954036

Epoch: 5| Step: 6
Training loss: 1.9959701231056346
Validation loss: 2.5718217185253853

Epoch: 5| Step: 7
Training loss: 1.404332612793909
Validation loss: 2.5350837951870737

Epoch: 5| Step: 8
Training loss: 2.324593957700198
Validation loss: 2.5597145945181867

Epoch: 5| Step: 9
Training loss: 1.6331758961737763
Validation loss: 2.581307144702457

Epoch: 5| Step: 10
Training loss: 2.1249288659250922
Validation loss: 2.5780871417415976

Epoch: 5| Step: 11
Training loss: 1.9175806837750613
Validation loss: 2.5971500142464126

Epoch: 323| Step: 0
Training loss: 1.3400085169962759
Validation loss: 2.5991510817939187

Epoch: 5| Step: 1
Training loss: 1.9988885413770294
Validation loss: 2.5982473518316245

Epoch: 5| Step: 2
Training loss: 2.263540532380575
Validation loss: 2.6209622315537398

Epoch: 5| Step: 3
Training loss: 2.684316923603469
Validation loss: 2.6549680196772103

Epoch: 5| Step: 4
Training loss: 2.062777413871814
Validation loss: 2.6681638341933884

Epoch: 5| Step: 5
Training loss: 1.7289254430092529
Validation loss: 2.6769682467371365

Epoch: 5| Step: 6
Training loss: 2.305561171630801
Validation loss: 2.6823726024576975

Epoch: 5| Step: 7
Training loss: 1.5188877341526432
Validation loss: 2.6236760872941662

Epoch: 5| Step: 8
Training loss: 2.1655149577753168
Validation loss: 2.599252754205319

Epoch: 5| Step: 9
Training loss: 1.3144163492168073
Validation loss: 2.5942635085324084

Epoch: 5| Step: 10
Training loss: 1.7519046772495772
Validation loss: 2.575039020415515

Epoch: 5| Step: 11
Training loss: 1.4631723863439412
Validation loss: 2.561592579106133

Epoch: 324| Step: 0
Training loss: 2.1088583984734517
Validation loss: 2.5651168138737663

Epoch: 5| Step: 1
Training loss: 1.546359043578332
Validation loss: 2.5673162549159154

Epoch: 5| Step: 2
Training loss: 2.3389446588161067
Validation loss: 2.568827102289835

Epoch: 5| Step: 3
Training loss: 1.9296940482951268
Validation loss: 2.556631487972601

Epoch: 5| Step: 4
Training loss: 1.552786964149727
Validation loss: 2.560465458580151

Epoch: 5| Step: 5
Training loss: 2.37848026865196
Validation loss: 2.615142596540547

Epoch: 5| Step: 6
Training loss: 2.001412846303245
Validation loss: 2.634658283434673

Epoch: 5| Step: 7
Training loss: 1.6644361192953137
Validation loss: 2.697118491345312

Epoch: 5| Step: 8
Training loss: 2.1196286250467735
Validation loss: 2.712396615632078

Epoch: 5| Step: 9
Training loss: 2.2283241129503484
Validation loss: 2.702286831044134

Epoch: 5| Step: 10
Training loss: 1.9513293747822122
Validation loss: 2.670284355466144

Epoch: 5| Step: 11
Training loss: 1.8589242340703174
Validation loss: 2.6173362461920995

Epoch: 325| Step: 0
Training loss: 1.762990420674109
Validation loss: 2.5926655068595603

Epoch: 5| Step: 1
Training loss: 2.096060545520057
Validation loss: 2.5736283825027564

Epoch: 5| Step: 2
Training loss: 2.0318004155851463
Validation loss: 2.5683065198674084

Epoch: 5| Step: 3
Training loss: 2.0778477992987794
Validation loss: 2.5888800038534057

Epoch: 5| Step: 4
Training loss: 2.2213407622659997
Validation loss: 2.5696638229870827

Epoch: 5| Step: 5
Training loss: 1.5106785075915226
Validation loss: 2.556791184054835

Epoch: 5| Step: 6
Training loss: 1.510461407579764
Validation loss: 2.5460125919878696

Epoch: 5| Step: 7
Training loss: 2.089205007892342
Validation loss: 2.550820202844027

Epoch: 5| Step: 8
Training loss: 2.03650958556896
Validation loss: 2.5869238625140754

Epoch: 5| Step: 9
Training loss: 1.9194823467280533
Validation loss: 2.6076771357598947

Epoch: 5| Step: 10
Training loss: 2.2458275147918836
Validation loss: 2.657586801025853

Epoch: 5| Step: 11
Training loss: 2.403641116274376
Validation loss: 2.666985832922885

Epoch: 326| Step: 0
Training loss: 1.7589956413245402
Validation loss: 2.7196240098156634

Epoch: 5| Step: 1
Training loss: 1.896959647940437
Validation loss: 2.775029208341736

Epoch: 5| Step: 2
Training loss: 2.2416807658757776
Validation loss: 2.822693109751183

Epoch: 5| Step: 3
Training loss: 2.379248082448674
Validation loss: 2.860813473885248

Epoch: 5| Step: 4
Training loss: 2.0389401921681687
Validation loss: 2.808911467838387

Epoch: 5| Step: 5
Training loss: 1.9038404651370122
Validation loss: 2.70411040512555

Epoch: 5| Step: 6
Training loss: 1.852112700405089
Validation loss: 2.6269902752562087

Epoch: 5| Step: 7
Training loss: 2.016524476432233
Validation loss: 2.605773412306072

Epoch: 5| Step: 8
Training loss: 1.8554732473218523
Validation loss: 2.5806069920962385

Epoch: 5| Step: 9
Training loss: 1.6080251421504845
Validation loss: 2.5652972863529566

Epoch: 5| Step: 10
Training loss: 2.4347113282716206
Validation loss: 2.564127261939984

Epoch: 5| Step: 11
Training loss: 1.1638574611656225
Validation loss: 2.5803050485985155

Epoch: 327| Step: 0
Training loss: 2.2447187112398588
Validation loss: 2.579362972771596

Epoch: 5| Step: 1
Training loss: 2.064798750226464
Validation loss: 2.550925867519223

Epoch: 5| Step: 2
Training loss: 2.40030778659695
Validation loss: 2.5685393566507244

Epoch: 5| Step: 3
Training loss: 2.2662713542927384
Validation loss: 2.575726350787982

Epoch: 5| Step: 4
Training loss: 1.5905488721095908
Validation loss: 2.565208240598773

Epoch: 5| Step: 5
Training loss: 1.7152364711275196
Validation loss: 2.551412343677834

Epoch: 5| Step: 6
Training loss: 1.8725162585867914
Validation loss: 2.5966123735038873

Epoch: 5| Step: 7
Training loss: 1.386991189333236
Validation loss: 2.5999412869279794

Epoch: 5| Step: 8
Training loss: 2.0055865703073787
Validation loss: 2.6326973283368695

Epoch: 5| Step: 9
Training loss: 1.9731207876610584
Validation loss: 2.6420370235414246

Epoch: 5| Step: 10
Training loss: 1.726441392060126
Validation loss: 2.6175453624601994

Epoch: 5| Step: 11
Training loss: 2.9960676488025384
Validation loss: 2.59405470785602

Epoch: 328| Step: 0
Training loss: 1.8206748110671545
Validation loss: 2.578028655901099

Epoch: 5| Step: 1
Training loss: 1.1889901097803108
Validation loss: 2.591379553191864

Epoch: 5| Step: 2
Training loss: 2.1049254783432745
Validation loss: 2.585221528571852

Epoch: 5| Step: 3
Training loss: 2.58271815040542
Validation loss: 2.6178803053589346

Epoch: 5| Step: 4
Training loss: 1.938810705025288
Validation loss: 2.584711331550612

Epoch: 5| Step: 5
Training loss: 1.5384754281150603
Validation loss: 2.6149605419410755

Epoch: 5| Step: 6
Training loss: 1.5977756297085723
Validation loss: 2.6070718556519754

Epoch: 5| Step: 7
Training loss: 1.6070983486975756
Validation loss: 2.596546446562029

Epoch: 5| Step: 8
Training loss: 2.2428070169493184
Validation loss: 2.5850361581428056

Epoch: 5| Step: 9
Training loss: 1.7902312479942823
Validation loss: 2.5978913317936088

Epoch: 5| Step: 10
Training loss: 1.8345792900327955
Validation loss: 2.600693237673371

Epoch: 5| Step: 11
Training loss: 1.5328188274847898
Validation loss: 2.625496700009217

Epoch: 329| Step: 0
Training loss: 2.0608207339857905
Validation loss: 2.655211971385724

Epoch: 5| Step: 1
Training loss: 2.1568794990167643
Validation loss: 2.6617445944205125

Epoch: 5| Step: 2
Training loss: 1.8165714311864154
Validation loss: 2.712445472720042

Epoch: 5| Step: 3
Training loss: 2.1362574217049666
Validation loss: 2.6669325112410927

Epoch: 5| Step: 4
Training loss: 2.036464395213231
Validation loss: 2.6203913422598877

Epoch: 5| Step: 5
Training loss: 1.981629883360893
Validation loss: 2.5800713599917913

Epoch: 5| Step: 6
Training loss: 1.6418293483444262
Validation loss: 2.5726148927733266

Epoch: 5| Step: 7
Training loss: 2.0493859185442456
Validation loss: 2.563125394473712

Epoch: 5| Step: 8
Training loss: 1.594629830243279
Validation loss: 2.552134249951298

Epoch: 5| Step: 9
Training loss: 1.8695152808088016
Validation loss: 2.5500132216004823

Epoch: 5| Step: 10
Training loss: 1.8093917108004567
Validation loss: 2.558405042682938

Epoch: 5| Step: 11
Training loss: 2.6461044432945195
Validation loss: 2.5429458773395424

Epoch: 330| Step: 0
Training loss: 2.0430398202937474
Validation loss: 2.5560299790322687

Epoch: 5| Step: 1
Training loss: 1.6471694480385914
Validation loss: 2.5483376958043356

Epoch: 5| Step: 2
Training loss: 1.895802179716362
Validation loss: 2.558616385711636

Epoch: 5| Step: 3
Training loss: 1.9231467032610368
Validation loss: 2.549453385832869

Epoch: 5| Step: 4
Training loss: 2.412511135727872
Validation loss: 2.5636939198215885

Epoch: 5| Step: 5
Training loss: 1.6344450313815726
Validation loss: 2.552911407395139

Epoch: 5| Step: 6
Training loss: 1.885988587807101
Validation loss: 2.553675347026082

Epoch: 5| Step: 7
Training loss: 1.9001354897024276
Validation loss: 2.563990562618481

Epoch: 5| Step: 8
Training loss: 1.3067633737974798
Validation loss: 2.56557657890766

Epoch: 5| Step: 9
Training loss: 1.816854967046891
Validation loss: 2.574500894786022

Epoch: 5| Step: 10
Training loss: 1.626972468559978
Validation loss: 2.592002496369974

Epoch: 5| Step: 11
Training loss: 3.1100854110028733
Validation loss: 2.578505852051863

Epoch: 331| Step: 0
Training loss: 1.9187535935160136
Validation loss: 2.657793531550126

Epoch: 5| Step: 1
Training loss: 2.0457793353607956
Validation loss: 2.688740780233918

Epoch: 5| Step: 2
Training loss: 1.8794210446460557
Validation loss: 2.6972815982493876

Epoch: 5| Step: 3
Training loss: 1.6424020498208152
Validation loss: 2.644754540291891

Epoch: 5| Step: 4
Training loss: 1.8650278026973175
Validation loss: 2.6290364906278665

Epoch: 5| Step: 5
Training loss: 2.078696036220432
Validation loss: 2.58129908597394

Epoch: 5| Step: 6
Training loss: 1.5077436362239611
Validation loss: 2.5596549650687663

Epoch: 5| Step: 7
Training loss: 2.282812654572259
Validation loss: 2.553913283005338

Epoch: 5| Step: 8
Training loss: 2.0657450261643033
Validation loss: 2.5828294275386425

Epoch: 5| Step: 9
Training loss: 1.8431836567700541
Validation loss: 2.568259674573909

Epoch: 5| Step: 10
Training loss: 2.0253655515790707
Validation loss: 2.567218975045227

Epoch: 5| Step: 11
Training loss: 1.8229621954182353
Validation loss: 2.5674571881041564

Epoch: 332| Step: 0
Training loss: 2.6824785383491165
Validation loss: 2.540406138622644

Epoch: 5| Step: 1
Training loss: 1.9480446622142535
Validation loss: 2.570578995158585

Epoch: 5| Step: 2
Training loss: 1.9073875035101684
Validation loss: 2.599605404578276

Epoch: 5| Step: 3
Training loss: 1.5157973987807178
Validation loss: 2.601901762552323

Epoch: 5| Step: 4
Training loss: 1.4561323814208273
Validation loss: 2.6123864429075474

Epoch: 5| Step: 5
Training loss: 1.68386109391296
Validation loss: 2.6123627063808703

Epoch: 5| Step: 6
Training loss: 2.2208080149549914
Validation loss: 2.650214753281231

Epoch: 5| Step: 7
Training loss: 1.9334290097119426
Validation loss: 2.6484670421711876

Epoch: 5| Step: 8
Training loss: 1.9930700404238573
Validation loss: 2.6019995611514424

Epoch: 5| Step: 9
Training loss: 1.865562977231104
Validation loss: 2.6167330257136987

Epoch: 5| Step: 10
Training loss: 1.4408219142893022
Validation loss: 2.557249299350391

Epoch: 5| Step: 11
Training loss: 1.529347230123645
Validation loss: 2.553724863903032

Epoch: 333| Step: 0
Training loss: 2.006199288841428
Validation loss: 2.559318404916879

Epoch: 5| Step: 1
Training loss: 1.7779215449905548
Validation loss: 2.5659694948355414

Epoch: 5| Step: 2
Training loss: 1.7920952956968117
Validation loss: 2.586442819262796

Epoch: 5| Step: 3
Training loss: 1.6836656878119924
Validation loss: 2.5692425001247203

Epoch: 5| Step: 4
Training loss: 2.559446702262505
Validation loss: 2.5826389638300067

Epoch: 5| Step: 5
Training loss: 2.1320829715794303
Validation loss: 2.599516918774716

Epoch: 5| Step: 6
Training loss: 1.2080738293210618
Validation loss: 2.5817960823450257

Epoch: 5| Step: 7
Training loss: 1.7324165077513392
Validation loss: 2.6399365793663643

Epoch: 5| Step: 8
Training loss: 1.915378787474064
Validation loss: 2.6038301873583545

Epoch: 5| Step: 9
Training loss: 2.003975374394101
Validation loss: 2.643486567900672

Epoch: 5| Step: 10
Training loss: 2.2010125387719395
Validation loss: 2.6837701383219206

Epoch: 5| Step: 11
Training loss: 2.9415795425898823
Validation loss: 2.664834195085132

Epoch: 334| Step: 0
Training loss: 2.3572029068964357
Validation loss: 2.6121163311608933

Epoch: 5| Step: 1
Training loss: 2.160860743507557
Validation loss: 2.5894030679846094

Epoch: 5| Step: 2
Training loss: 1.434646510936887
Validation loss: 2.5591187537861186

Epoch: 5| Step: 3
Training loss: 1.5345317939156835
Validation loss: 2.586961176726309

Epoch: 5| Step: 4
Training loss: 2.6788237934210475
Validation loss: 2.5753128667219447

Epoch: 5| Step: 5
Training loss: 1.4605242302754444
Validation loss: 2.5942334525026722

Epoch: 5| Step: 6
Training loss: 2.349290022230339
Validation loss: 2.5805687891414713

Epoch: 5| Step: 7
Training loss: 1.566837622398693
Validation loss: 2.560112938482061

Epoch: 5| Step: 8
Training loss: 2.0463136092397027
Validation loss: 2.5747270675565392

Epoch: 5| Step: 9
Training loss: 1.9180239418930112
Validation loss: 2.516431240939494

Epoch: 5| Step: 10
Training loss: 1.6451650381347172
Validation loss: 2.5825533586684655

Epoch: 5| Step: 11
Training loss: 1.9019712361468253
Validation loss: 2.6226311356795886

Epoch: 335| Step: 0
Training loss: 1.5471404647380937
Validation loss: 2.609468587845522

Epoch: 5| Step: 1
Training loss: 2.02914789440498
Validation loss: 2.622381255113424

Epoch: 5| Step: 2
Training loss: 1.486060620972345
Validation loss: 2.598894723688413

Epoch: 5| Step: 3
Training loss: 2.013849940599337
Validation loss: 2.613605439244394

Epoch: 5| Step: 4
Training loss: 1.5945659867296669
Validation loss: 2.570638471686037

Epoch: 5| Step: 5
Training loss: 1.9157035176799586
Validation loss: 2.572054364549909

Epoch: 5| Step: 6
Training loss: 1.4320750494635897
Validation loss: 2.560772833224838

Epoch: 5| Step: 7
Training loss: 2.5914985352794844
Validation loss: 2.574614471753072

Epoch: 5| Step: 8
Training loss: 1.5720168396676317
Validation loss: 2.5710418308007523

Epoch: 5| Step: 9
Training loss: 1.8769578884036526
Validation loss: 2.5439926133301

Epoch: 5| Step: 10
Training loss: 2.454926624949658
Validation loss: 2.559200954458065

Epoch: 5| Step: 11
Training loss: 1.4591626488619218
Validation loss: 2.5652109746754927

Epoch: 336| Step: 0
Training loss: 1.8094081157493462
Validation loss: 2.526363617086327

Epoch: 5| Step: 1
Training loss: 1.5450161641087052
Validation loss: 2.5803335074497085

Epoch: 5| Step: 2
Training loss: 2.351967203287877
Validation loss: 2.6245825602115507

Epoch: 5| Step: 3
Training loss: 1.775441050469093
Validation loss: 2.6429471841117014

Epoch: 5| Step: 4
Training loss: 1.2873102474193865
Validation loss: 2.6121860617444934

Epoch: 5| Step: 5
Training loss: 1.8283322208694417
Validation loss: 2.5937589698850885

Epoch: 5| Step: 6
Training loss: 1.2584359655567454
Validation loss: 2.6034055525836144

Epoch: 5| Step: 7
Training loss: 1.909983184400903
Validation loss: 2.550530815195861

Epoch: 5| Step: 8
Training loss: 2.3067115301205128
Validation loss: 2.5731698592442673

Epoch: 5| Step: 9
Training loss: 1.6511184802874248
Validation loss: 2.5823831631012126

Epoch: 5| Step: 10
Training loss: 2.0710907247169414
Validation loss: 2.549455154872165

Epoch: 5| Step: 11
Training loss: 2.246183443351799
Validation loss: 2.532182341244787

Epoch: 337| Step: 0
Training loss: 1.5826389228865805
Validation loss: 2.542243275873617

Epoch: 5| Step: 1
Training loss: 1.7981232661085418
Validation loss: 2.5924326527234136

Epoch: 5| Step: 2
Training loss: 1.6784379436440486
Validation loss: 2.592198581989951

Epoch: 5| Step: 3
Training loss: 1.8067262701405724
Validation loss: 2.586725700704733

Epoch: 5| Step: 4
Training loss: 2.0502467448907957
Validation loss: 2.5943642926774393

Epoch: 5| Step: 5
Training loss: 2.765448957971915
Validation loss: 2.633008321390357

Epoch: 5| Step: 6
Training loss: 1.6269831660360525
Validation loss: 2.5843461817311257

Epoch: 5| Step: 7
Training loss: 1.4518028725464944
Validation loss: 2.5830545249325487

Epoch: 5| Step: 8
Training loss: 1.9308149619361064
Validation loss: 2.541528992493967

Epoch: 5| Step: 9
Training loss: 2.2089716390686127
Validation loss: 2.5610489749444723

Epoch: 5| Step: 10
Training loss: 1.6041098828194587
Validation loss: 2.5659700097427387

Epoch: 5| Step: 11
Training loss: 1.4997346961322722
Validation loss: 2.54455074591347

Epoch: 338| Step: 0
Training loss: 1.465897651477184
Validation loss: 2.5622066042962093

Epoch: 5| Step: 1
Training loss: 1.550473122529547
Validation loss: 2.551412791438566

Epoch: 5| Step: 2
Training loss: 2.1737351170579315
Validation loss: 2.554243603326009

Epoch: 5| Step: 3
Training loss: 1.5777619199149908
Validation loss: 2.546116815528673

Epoch: 5| Step: 4
Training loss: 2.237318327790152
Validation loss: 2.5765192984804517

Epoch: 5| Step: 5
Training loss: 1.7440458231383076
Validation loss: 2.6046785627157245

Epoch: 5| Step: 6
Training loss: 2.3706426301316195
Validation loss: 2.5838624786589794

Epoch: 5| Step: 7
Training loss: 1.7064262382958089
Validation loss: 2.6199091865365385

Epoch: 5| Step: 8
Training loss: 1.9596825341593804
Validation loss: 2.6085412183820673

Epoch: 5| Step: 9
Training loss: 1.7561427344964191
Validation loss: 2.612032380454191

Epoch: 5| Step: 10
Training loss: 1.9287467856636877
Validation loss: 2.5534558763886595

Epoch: 5| Step: 11
Training loss: 0.9242643975459037
Validation loss: 2.5764707903312676

Epoch: 339| Step: 0
Training loss: 1.329645430978572
Validation loss: 2.584269270757989

Epoch: 5| Step: 1
Training loss: 1.2358241688771587
Validation loss: 2.5981688870805444

Epoch: 5| Step: 2
Training loss: 1.8278977342501497
Validation loss: 2.5785364304363756

Epoch: 5| Step: 3
Training loss: 2.1167325027119297
Validation loss: 2.6157763458243046

Epoch: 5| Step: 4
Training loss: 2.2313716951409552
Validation loss: 2.5753977250832034

Epoch: 5| Step: 5
Training loss: 1.8625302510717046
Validation loss: 2.5929770332856186

Epoch: 5| Step: 6
Training loss: 1.5000298814976127
Validation loss: 2.604685027348825

Epoch: 5| Step: 7
Training loss: 1.5531810573846285
Validation loss: 2.5927557284318516

Epoch: 5| Step: 8
Training loss: 1.5975126094648806
Validation loss: 2.572196849462586

Epoch: 5| Step: 9
Training loss: 2.069783269068118
Validation loss: 2.5807265593781503

Epoch: 5| Step: 10
Training loss: 2.201011780516222
Validation loss: 2.6413739363115334

Epoch: 5| Step: 11
Training loss: 2.6031319864277775
Validation loss: 2.6312533175461876

Epoch: 340| Step: 0
Training loss: 1.3111877238973808
Validation loss: 2.648894076531175

Epoch: 5| Step: 1
Training loss: 1.945456993527683
Validation loss: 2.6376084303149456

Epoch: 5| Step: 2
Training loss: 2.246604901076949
Validation loss: 2.655305241886165

Epoch: 5| Step: 3
Training loss: 1.5335359442956984
Validation loss: 2.6481036685687367

Epoch: 5| Step: 4
Training loss: 2.2080054369596906
Validation loss: 2.6223260566547753

Epoch: 5| Step: 5
Training loss: 1.248266782773477
Validation loss: 2.5822673272240837

Epoch: 5| Step: 6
Training loss: 1.894985750089428
Validation loss: 2.5735866829966927

Epoch: 5| Step: 7
Training loss: 2.1076794626882296
Validation loss: 2.575374727698157

Epoch: 5| Step: 8
Training loss: 1.722829797008529
Validation loss: 2.5902822630544855

Epoch: 5| Step: 9
Training loss: 1.868570940503848
Validation loss: 2.6074591320866887

Epoch: 5| Step: 10
Training loss: 1.5935368114824209
Validation loss: 2.6233160203227506

Epoch: 5| Step: 11
Training loss: 1.9780627200189111
Validation loss: 2.639442498851548

Epoch: 341| Step: 0
Training loss: 1.798795055702579
Validation loss: 2.577109146348668

Epoch: 5| Step: 1
Training loss: 1.5939370587844217
Validation loss: 2.5977815220200062

Epoch: 5| Step: 2
Training loss: 1.773096329057536
Validation loss: 2.5772503187888787

Epoch: 5| Step: 3
Training loss: 1.5454114675892936
Validation loss: 2.5866395971042757

Epoch: 5| Step: 4
Training loss: 1.81570480092519
Validation loss: 2.545456522486304

Epoch: 5| Step: 5
Training loss: 2.1269127707948705
Validation loss: 2.567203697823712

Epoch: 5| Step: 6
Training loss: 2.2925472879472664
Validation loss: 2.570602041244468

Epoch: 5| Step: 7
Training loss: 1.319313438782766
Validation loss: 2.5799176312760466

Epoch: 5| Step: 8
Training loss: 1.7526466247343264
Validation loss: 2.5369127651090575

Epoch: 5| Step: 9
Training loss: 1.98959852549027
Validation loss: 2.5873412809973146

Epoch: 5| Step: 10
Training loss: 1.8549550841206977
Validation loss: 2.551337706705978

Epoch: 5| Step: 11
Training loss: 1.3599415179609249
Validation loss: 2.5644538687641725

Epoch: 342| Step: 0
Training loss: 2.0649354600403567
Validation loss: 2.540063658696282

Epoch: 5| Step: 1
Training loss: 1.8681015267401782
Validation loss: 2.573720745873316

Epoch: 5| Step: 2
Training loss: 1.2947665620530102
Validation loss: 2.5541204742892876

Epoch: 5| Step: 3
Training loss: 2.031893584190763
Validation loss: 2.551616646791128

Epoch: 5| Step: 4
Training loss: 1.7267225372573927
Validation loss: 2.553008858892349

Epoch: 5| Step: 5
Training loss: 1.5632963058760871
Validation loss: 2.5446706878682637

Epoch: 5| Step: 6
Training loss: 1.8787738967563543
Validation loss: 2.5430088889708817

Epoch: 5| Step: 7
Training loss: 2.4862128603363502
Validation loss: 2.570904693483846

Epoch: 5| Step: 8
Training loss: 1.496157174222691
Validation loss: 2.6171755814162307

Epoch: 5| Step: 9
Training loss: 1.4782146112162993
Validation loss: 2.570865919369309

Epoch: 5| Step: 10
Training loss: 1.530057949140578
Validation loss: 2.581360445592336

Epoch: 5| Step: 11
Training loss: 2.6052914034353174
Validation loss: 2.5412074453290647

Epoch: 343| Step: 0
Training loss: 1.3346557268287575
Validation loss: 2.574686786435289

Epoch: 5| Step: 1
Training loss: 1.2292368701779006
Validation loss: 2.601388572247725

Epoch: 5| Step: 2
Training loss: 2.2772044013233628
Validation loss: 2.558156643480798

Epoch: 5| Step: 3
Training loss: 1.862217757582086
Validation loss: 2.5999199165640934

Epoch: 5| Step: 4
Training loss: 1.9033743633896256
Validation loss: 2.647286238957609

Epoch: 5| Step: 5
Training loss: 2.1660222293350624
Validation loss: 2.657519949470014

Epoch: 5| Step: 6
Training loss: 2.0654195293780937
Validation loss: 2.6343824081045226

Epoch: 5| Step: 7
Training loss: 1.8728566316764161
Validation loss: 2.6075588842773336

Epoch: 5| Step: 8
Training loss: 1.4407419053842703
Validation loss: 2.5451306452378404

Epoch: 5| Step: 9
Training loss: 1.9279093097749487
Validation loss: 2.5337545108049286

Epoch: 5| Step: 10
Training loss: 1.6241268599857803
Validation loss: 2.5472942857475873

Epoch: 5| Step: 11
Training loss: 1.3359238473294979
Validation loss: 2.5493801956267212

Epoch: 344| Step: 0
Training loss: 1.4455066447413707
Validation loss: 2.528115101257737

Epoch: 5| Step: 1
Training loss: 1.5961387534572569
Validation loss: 2.5638057281845374

Epoch: 5| Step: 2
Training loss: 1.9678802991300313
Validation loss: 2.541321814442228

Epoch: 5| Step: 3
Training loss: 1.7410381272034154
Validation loss: 2.537192652869729

Epoch: 5| Step: 4
Training loss: 1.887596036981463
Validation loss: 2.551386700484292

Epoch: 5| Step: 5
Training loss: 1.8626709264371126
Validation loss: 2.59520581765099

Epoch: 5| Step: 6
Training loss: 1.9496081618785046
Validation loss: 2.585392417199708

Epoch: 5| Step: 7
Training loss: 2.152868964885755
Validation loss: 2.6306115222264506

Epoch: 5| Step: 8
Training loss: 1.5302253720464711
Validation loss: 2.6565773444334426

Epoch: 5| Step: 9
Training loss: 2.1473294816802255
Validation loss: 2.6410001416808764

Epoch: 5| Step: 10
Training loss: 1.4709544581320524
Validation loss: 2.59781170525675

Epoch: 5| Step: 11
Training loss: 1.3202950741673178
Validation loss: 2.6074304511492365

Epoch: 345| Step: 0
Training loss: 1.6543630251218688
Validation loss: 2.581231139963137

Epoch: 5| Step: 1
Training loss: 1.5124569059175506
Validation loss: 2.537068414394172

Epoch: 5| Step: 2
Training loss: 1.593949398955903
Validation loss: 2.57329808752929

Epoch: 5| Step: 3
Training loss: 1.7107214246897289
Validation loss: 2.5771866410461652

Epoch: 5| Step: 4
Training loss: 1.9493627705240877
Validation loss: 2.5888116236532244

Epoch: 5| Step: 5
Training loss: 1.90466930953392
Validation loss: 2.610462240129295

Epoch: 5| Step: 6
Training loss: 1.418451988749643
Validation loss: 2.599867515825981

Epoch: 5| Step: 7
Training loss: 1.52462331153155
Validation loss: 2.6325650688442566

Epoch: 5| Step: 8
Training loss: 1.9405352904981716
Validation loss: 2.6205181848622527

Epoch: 5| Step: 9
Training loss: 2.3559393721002686
Validation loss: 2.626245201426617

Epoch: 5| Step: 10
Training loss: 1.6479822768674985
Validation loss: 2.6497624457995266

Epoch: 5| Step: 11
Training loss: 1.9839590642959042
Validation loss: 2.5928500540716626

Epoch: 346| Step: 0
Training loss: 1.895240194855116
Validation loss: 2.6129165683864533

Epoch: 5| Step: 1
Training loss: 1.8155298887674796
Validation loss: 2.6035467261869902

Epoch: 5| Step: 2
Training loss: 2.0624509863375957
Validation loss: 2.612098034441939

Epoch: 5| Step: 3
Training loss: 1.6786789106029045
Validation loss: 2.632727192403177

Epoch: 5| Step: 4
Training loss: 1.6260946694858356
Validation loss: 2.632743510050791

Epoch: 5| Step: 5
Training loss: 1.374792126634643
Validation loss: 2.6135992817453295

Epoch: 5| Step: 6
Training loss: 2.04001463660431
Validation loss: 2.608210796965561

Epoch: 5| Step: 7
Training loss: 1.7749985869496054
Validation loss: 2.590785887492249

Epoch: 5| Step: 8
Training loss: 2.162038579675979
Validation loss: 2.5956566784685595

Epoch: 5| Step: 9
Training loss: 1.7407046452215125
Validation loss: 2.5951921061886116

Epoch: 5| Step: 10
Training loss: 1.3611724633167035
Validation loss: 2.598758916651487

Epoch: 5| Step: 11
Training loss: 2.349403784581393
Validation loss: 2.603975931176249

Epoch: 347| Step: 0
Training loss: 1.4856576296986748
Validation loss: 2.6817579954522515

Epoch: 5| Step: 1
Training loss: 1.3826430480926832
Validation loss: 2.666675505524133

Epoch: 5| Step: 2
Training loss: 1.442187420647682
Validation loss: 2.7466570989452155

Epoch: 5| Step: 3
Training loss: 2.397197489821458
Validation loss: 2.722336365832561

Epoch: 5| Step: 4
Training loss: 1.8634017169644368
Validation loss: 2.684027050561602

Epoch: 5| Step: 5
Training loss: 1.9007395534747606
Validation loss: 2.671266423271459

Epoch: 5| Step: 6
Training loss: 1.6912304652538586
Validation loss: 2.5640706583095136

Epoch: 5| Step: 7
Training loss: 2.154346233781219
Validation loss: 2.523382428397975

Epoch: 5| Step: 8
Training loss: 2.1493093490224737
Validation loss: 2.5350045705913344

Epoch: 5| Step: 9
Training loss: 2.3455406977615967
Validation loss: 2.5460301462590227

Epoch: 5| Step: 10
Training loss: 2.177865090317473
Validation loss: 2.5374630942581384

Epoch: 5| Step: 11
Training loss: 1.2394544176442992
Validation loss: 2.487595915422809

Epoch: 348| Step: 0
Training loss: 2.0932245306827575
Validation loss: 2.4847916747500167

Epoch: 5| Step: 1
Training loss: 2.0106743629284662
Validation loss: 2.504211651154175

Epoch: 5| Step: 2
Training loss: 1.5631308235874468
Validation loss: 2.501145497785267

Epoch: 5| Step: 3
Training loss: 2.2428375258902515
Validation loss: 2.5450224584501617

Epoch: 5| Step: 4
Training loss: 1.5819256029057316
Validation loss: 2.6158320242846194

Epoch: 5| Step: 5
Training loss: 2.05223755490952
Validation loss: 2.6698333159993495

Epoch: 5| Step: 6
Training loss: 1.7984073241989145
Validation loss: 2.7481097928354385

Epoch: 5| Step: 7
Training loss: 2.195416974062659
Validation loss: 2.717253386342335

Epoch: 5| Step: 8
Training loss: 1.8686760750632503
Validation loss: 2.7171563779757073

Epoch: 5| Step: 9
Training loss: 1.7795166147929664
Validation loss: 2.669710304865094

Epoch: 5| Step: 10
Training loss: 1.715493741599141
Validation loss: 2.665065938111192

Epoch: 5| Step: 11
Training loss: 0.7536677245093706
Validation loss: 2.611459548522845

Epoch: 349| Step: 0
Training loss: 1.6541496490576846
Validation loss: 2.599558076225791

Epoch: 5| Step: 1
Training loss: 1.5397533279880953
Validation loss: 2.593399514413753

Epoch: 5| Step: 2
Training loss: 1.7455196247467333
Validation loss: 2.6121784462535897

Epoch: 5| Step: 3
Training loss: 1.3616131302212795
Validation loss: 2.6096743946814516

Epoch: 5| Step: 4
Training loss: 1.8320484282576825
Validation loss: 2.6006794978449217

Epoch: 5| Step: 5
Training loss: 1.7312375808435632
Validation loss: 2.633360359550165

Epoch: 5| Step: 6
Training loss: 1.6344518873170741
Validation loss: 2.617178952027591

Epoch: 5| Step: 7
Training loss: 2.154609166437202
Validation loss: 2.6076558135547705

Epoch: 5| Step: 8
Training loss: 1.5533664016860165
Validation loss: 2.611452706940449

Epoch: 5| Step: 9
Training loss: 2.1311555231805945
Validation loss: 2.644660713636809

Epoch: 5| Step: 10
Training loss: 2.020069397404656
Validation loss: 2.6692415276135972

Epoch: 5| Step: 11
Training loss: 2.379611707796634
Validation loss: 2.6510521989074816

Epoch: 350| Step: 0
Training loss: 1.629975112303785
Validation loss: 2.6730967920096553

Epoch: 5| Step: 1
Training loss: 1.3516928108327249
Validation loss: 2.7234076580922957

Epoch: 5| Step: 2
Training loss: 2.293461761242328
Validation loss: 2.736364817730681

Epoch: 5| Step: 3
Training loss: 2.309095815422618
Validation loss: 2.760580948073778

Epoch: 5| Step: 4
Training loss: 2.0922374670943493
Validation loss: 2.6803179296825697

Epoch: 5| Step: 5
Training loss: 1.4297400292924178
Validation loss: 2.623762542963602

Epoch: 5| Step: 6
Training loss: 1.203250729815644
Validation loss: 2.5955745300632924

Epoch: 5| Step: 7
Training loss: 1.4468683889415141
Validation loss: 2.5452644232761643

Epoch: 5| Step: 8
Training loss: 1.8473218812884662
Validation loss: 2.5396891441760774

Epoch: 5| Step: 9
Training loss: 1.7142707023644508
Validation loss: 2.5254063439820396

Epoch: 5| Step: 10
Training loss: 2.4690244497986678
Validation loss: 2.515644278758478

Epoch: 5| Step: 11
Training loss: 1.1455987632398483
Validation loss: 2.5236463509534945

Epoch: 351| Step: 0
Training loss: 1.9841319258189347
Validation loss: 2.5246334489716045

Epoch: 5| Step: 1
Training loss: 2.2323401729020804
Validation loss: 2.474537271052837

Epoch: 5| Step: 2
Training loss: 1.6258253789042687
Validation loss: 2.519972663477567

Epoch: 5| Step: 3
Training loss: 1.6579966422163182
Validation loss: 2.557528367648093

Epoch: 5| Step: 4
Training loss: 1.886454372166632
Validation loss: 2.570662392528959

Epoch: 5| Step: 5
Training loss: 2.372559950365557
Validation loss: 2.5643508669940016

Epoch: 5| Step: 6
Training loss: 1.675748953697018
Validation loss: 2.551512908765096

Epoch: 5| Step: 7
Training loss: 1.5568358946199499
Validation loss: 2.539761561481105

Epoch: 5| Step: 8
Training loss: 2.0616691534242717
Validation loss: 2.531428217010346

Epoch: 5| Step: 9
Training loss: 1.373560759098609
Validation loss: 2.5357925545195243

Epoch: 5| Step: 10
Training loss: 1.6228829311378905
Validation loss: 2.55853208899514

Epoch: 5| Step: 11
Training loss: 1.416430939902623
Validation loss: 2.582654861344275

Epoch: 352| Step: 0
Training loss: 1.5968494570008704
Validation loss: 2.618037815410525

Epoch: 5| Step: 1
Training loss: 1.5148442410512033
Validation loss: 2.6082997609883622

Epoch: 5| Step: 2
Training loss: 1.908845104353879
Validation loss: 2.6449469235436536

Epoch: 5| Step: 3
Training loss: 1.7677999957867858
Validation loss: 2.6954023337021202

Epoch: 5| Step: 4
Training loss: 1.7639714152470254
Validation loss: 2.6699012173251373

Epoch: 5| Step: 5
Training loss: 1.6163339619907051
Validation loss: 2.6259328267049344

Epoch: 5| Step: 6
Training loss: 1.682868889985776
Validation loss: 2.668197342782556

Epoch: 5| Step: 7
Training loss: 1.8916584689709108
Validation loss: 2.6237227363769233

Epoch: 5| Step: 8
Training loss: 1.7186302143317194
Validation loss: 2.5834793593040675

Epoch: 5| Step: 9
Training loss: 1.8901005167193126
Validation loss: 2.594816348707455

Epoch: 5| Step: 10
Training loss: 2.031300236007398
Validation loss: 2.5666993823897624

Epoch: 5| Step: 11
Training loss: 1.4274275798432023
Validation loss: 2.5690242511101573

Epoch: 353| Step: 0
Training loss: 1.8852439154908804
Validation loss: 2.5665157842462247

Epoch: 5| Step: 1
Training loss: 2.258896933559677
Validation loss: 2.5621665916019363

Epoch: 5| Step: 2
Training loss: 1.9799409121549563
Validation loss: 2.5494524233814584

Epoch: 5| Step: 3
Training loss: 1.6816146086520123
Validation loss: 2.554480677485241

Epoch: 5| Step: 4
Training loss: 1.6336622445457172
Validation loss: 2.5940718814943837

Epoch: 5| Step: 5
Training loss: 1.7598050501531917
Validation loss: 2.6204198434278396

Epoch: 5| Step: 6
Training loss: 1.448228770404176
Validation loss: 2.6654579147499384

Epoch: 5| Step: 7
Training loss: 1.9291212355315526
Validation loss: 2.66756433165062

Epoch: 5| Step: 8
Training loss: 1.468593832601039
Validation loss: 2.6386278376091683

Epoch: 5| Step: 9
Training loss: 1.8974598694629972
Validation loss: 2.602478526677575

Epoch: 5| Step: 10
Training loss: 1.3864251914052992
Validation loss: 2.58404261647639

Epoch: 5| Step: 11
Training loss: 0.9168753747607754
Validation loss: 2.5746235623241533

Epoch: 354| Step: 0
Training loss: 1.4041896986086495
Validation loss: 2.5441333313211727

Epoch: 5| Step: 1
Training loss: 2.262801311514253
Validation loss: 2.543121856752511

Epoch: 5| Step: 2
Training loss: 1.7824403232252617
Validation loss: 2.548714063486789

Epoch: 5| Step: 3
Training loss: 1.8450716098854996
Validation loss: 2.5289440169100583

Epoch: 5| Step: 4
Training loss: 2.209658842725028
Validation loss: 2.5521198711245017

Epoch: 5| Step: 5
Training loss: 1.911284630251521
Validation loss: 2.592887815549629

Epoch: 5| Step: 6
Training loss: 1.7968489935278347
Validation loss: 2.5274983024214146

Epoch: 5| Step: 7
Training loss: 1.2646855293637498
Validation loss: 2.584925462157256

Epoch: 5| Step: 8
Training loss: 1.73967722869686
Validation loss: 2.6024331324754515

Epoch: 5| Step: 9
Training loss: 0.9775002821509693
Validation loss: 2.57580596392084

Epoch: 5| Step: 10
Training loss: 1.2753918400944155
Validation loss: 2.557492441866618

Epoch: 5| Step: 11
Training loss: 1.5276607564941809
Validation loss: 2.5657892051495863

Epoch: 355| Step: 0
Training loss: 1.5483442322696794
Validation loss: 2.5785783157236533

Epoch: 5| Step: 1
Training loss: 1.646592830104223
Validation loss: 2.6047515415800113

Epoch: 5| Step: 2
Training loss: 1.811587926328539
Validation loss: 2.5695323861741

Epoch: 5| Step: 3
Training loss: 1.684785637846119
Validation loss: 2.541699707619034

Epoch: 5| Step: 4
Training loss: 1.826734943587308
Validation loss: 2.5678873728349587

Epoch: 5| Step: 5
Training loss: 1.4877605979309916
Validation loss: 2.5847128573842513

Epoch: 5| Step: 6
Training loss: 2.2628308133386645
Validation loss: 2.545994101149934

Epoch: 5| Step: 7
Training loss: 1.5636792120093137
Validation loss: 2.5369462980583166

Epoch: 5| Step: 8
Training loss: 1.3349512932853902
Validation loss: 2.5376091734728976

Epoch: 5| Step: 9
Training loss: 1.8946977365233921
Validation loss: 2.5593371022469023

Epoch: 5| Step: 10
Training loss: 1.4324500071538255
Validation loss: 2.536147207543168

Epoch: 5| Step: 11
Training loss: 1.8789523747546315
Validation loss: 2.5467927096437837

Epoch: 356| Step: 0
Training loss: 1.6926545432909765
Validation loss: 2.552395728836916

Epoch: 5| Step: 1
Training loss: 1.5900326178461934
Validation loss: 2.5576907789769265

Epoch: 5| Step: 2
Training loss: 1.649479902544531
Validation loss: 2.6014763604949342

Epoch: 5| Step: 3
Training loss: 1.7828924403543476
Validation loss: 2.573984713376103

Epoch: 5| Step: 4
Training loss: 1.8850961345979216
Validation loss: 2.5664981997820706

Epoch: 5| Step: 5
Training loss: 1.3817041988053071
Validation loss: 2.6046241142311843

Epoch: 5| Step: 6
Training loss: 1.5987576370116505
Validation loss: 2.6307307955089163

Epoch: 5| Step: 7
Training loss: 1.5785330820758512
Validation loss: 2.590847589910216

Epoch: 5| Step: 8
Training loss: 2.0068423528638335
Validation loss: 2.607022346052314

Epoch: 5| Step: 9
Training loss: 1.6757205694278474
Validation loss: 2.6390928906229907

Epoch: 5| Step: 10
Training loss: 1.5594606211669266
Validation loss: 2.5921342597078976

Epoch: 5| Step: 11
Training loss: 1.125960469854645
Validation loss: 2.595097075188914

Epoch: 357| Step: 0
Training loss: 1.3333242634623717
Validation loss: 2.573585467088711

Epoch: 5| Step: 1
Training loss: 1.8471049157598545
Validation loss: 2.5545092879264817

Epoch: 5| Step: 2
Training loss: 1.4437558425851156
Validation loss: 2.586713369093736

Epoch: 5| Step: 3
Training loss: 1.5334959880277617
Validation loss: 2.576330577713716

Epoch: 5| Step: 4
Training loss: 1.6772394127414245
Validation loss: 2.618062995497579

Epoch: 5| Step: 5
Training loss: 1.5204116114647959
Validation loss: 2.5849286557650886

Epoch: 5| Step: 6
Training loss: 1.7636737675619691
Validation loss: 2.6166641736980476

Epoch: 5| Step: 7
Training loss: 1.4264043413212768
Validation loss: 2.6300643969642654

Epoch: 5| Step: 8
Training loss: 1.954159577064695
Validation loss: 2.6004415737740616

Epoch: 5| Step: 9
Training loss: 2.2061489265783205
Validation loss: 2.6122057744489178

Epoch: 5| Step: 10
Training loss: 1.328874309319654
Validation loss: 2.6454416076404517

Epoch: 5| Step: 11
Training loss: 2.1373178594072324
Validation loss: 2.6200863398820045

Epoch: 358| Step: 0
Training loss: 1.3961602962027215
Validation loss: 2.6719818391316004

Epoch: 5| Step: 1
Training loss: 1.8726050658346842
Validation loss: 2.7638232977084782

Epoch: 5| Step: 2
Training loss: 2.8485526308028963
Validation loss: 2.7441608541338085

Epoch: 5| Step: 3
Training loss: 1.6702841204095955
Validation loss: 2.6452231241664776

Epoch: 5| Step: 4
Training loss: 1.438261825372336
Validation loss: 2.5847799605045587

Epoch: 5| Step: 5
Training loss: 1.38390255653084
Validation loss: 2.5790630560622856

Epoch: 5| Step: 6
Training loss: 1.7588780543187152
Validation loss: 2.534486932081909

Epoch: 5| Step: 7
Training loss: 1.80560160684138
Validation loss: 2.5312982013021914

Epoch: 5| Step: 8
Training loss: 1.796774488208707
Validation loss: 2.5174104068942658

Epoch: 5| Step: 9
Training loss: 1.338892696479846
Validation loss: 2.5269856383478255

Epoch: 5| Step: 10
Training loss: 1.7477220286718953
Validation loss: 2.5480636561038668

Epoch: 5| Step: 11
Training loss: 2.5010664572566843
Validation loss: 2.549273346544166

Epoch: 359| Step: 0
Training loss: 2.2646561228106443
Validation loss: 2.54155815914316

Epoch: 5| Step: 1
Training loss: 1.6704666052331663
Validation loss: 2.550220149329441

Epoch: 5| Step: 2
Training loss: 2.211577306042687
Validation loss: 2.5306647530728705

Epoch: 5| Step: 3
Training loss: 1.2060614581825386
Validation loss: 2.532040252873557

Epoch: 5| Step: 4
Training loss: 1.5516335093680462
Validation loss: 2.5188486125690193

Epoch: 5| Step: 5
Training loss: 1.29438878934801
Validation loss: 2.5502397430765114

Epoch: 5| Step: 6
Training loss: 1.3470745655737693
Validation loss: 2.5841586783920305

Epoch: 5| Step: 7
Training loss: 1.790832643303162
Validation loss: 2.5898230941662193

Epoch: 5| Step: 8
Training loss: 1.3895378578137876
Validation loss: 2.5909689812554886

Epoch: 5| Step: 9
Training loss: 1.930693576492607
Validation loss: 2.579459243925674

Epoch: 5| Step: 10
Training loss: 1.8703562133065832
Validation loss: 2.592132604108548

Epoch: 5| Step: 11
Training loss: 2.070619956164977
Validation loss: 2.553922303340788

Epoch: 360| Step: 0
Training loss: 1.9096895673637955
Validation loss: 2.536884872531344

Epoch: 5| Step: 1
Training loss: 1.8378762255762302
Validation loss: 2.5334617465082254

Epoch: 5| Step: 2
Training loss: 1.4820474948505522
Validation loss: 2.5418573383561562

Epoch: 5| Step: 3
Training loss: 1.5983818663520253
Validation loss: 2.557804325613461

Epoch: 5| Step: 4
Training loss: 1.597609614878467
Validation loss: 2.5389523682795896

Epoch: 5| Step: 5
Training loss: 1.3028591845431858
Validation loss: 2.5233326546665156

Epoch: 5| Step: 6
Training loss: 2.142566329659305
Validation loss: 2.526742611144661

Epoch: 5| Step: 7
Training loss: 1.3135850145456298
Validation loss: 2.56037661725706

Epoch: 5| Step: 8
Training loss: 1.931854513918053
Validation loss: 2.577357538222423

Epoch: 5| Step: 9
Training loss: 1.69733958198424
Validation loss: 2.5563739805615744

Epoch: 5| Step: 10
Training loss: 1.5023553951960673
Validation loss: 2.584367511743032

Epoch: 5| Step: 11
Training loss: 0.7222501283739926
Validation loss: 2.6068705915378563

Epoch: 361| Step: 0
Training loss: 1.3426064349273306
Validation loss: 2.6044866378032774

Epoch: 5| Step: 1
Training loss: 1.6038064263185212
Validation loss: 2.5742037805981615

Epoch: 5| Step: 2
Training loss: 1.6153445592567053
Validation loss: 2.583217734908872

Epoch: 5| Step: 3
Training loss: 1.4912590613653445
Validation loss: 2.576561235836622

Epoch: 5| Step: 4
Training loss: 1.4887580808585166
Validation loss: 2.587379664235118

Epoch: 5| Step: 5
Training loss: 1.373294683154825
Validation loss: 2.55842832074185

Epoch: 5| Step: 6
Training loss: 1.667786206300297
Validation loss: 2.5866428769281846

Epoch: 5| Step: 7
Training loss: 2.251368848002988
Validation loss: 2.575146139034894

Epoch: 5| Step: 8
Training loss: 1.8247250624192732
Validation loss: 2.5501487068373385

Epoch: 5| Step: 9
Training loss: 1.6233067126640384
Validation loss: 2.5825578976788464

Epoch: 5| Step: 10
Training loss: 1.603937091335769
Validation loss: 2.5838119630007568

Epoch: 5| Step: 11
Training loss: 1.5210663952202128
Validation loss: 2.5797179656806986

Epoch: 362| Step: 0
Training loss: 1.2896398927346886
Validation loss: 2.544433683547772

Epoch: 5| Step: 1
Training loss: 1.5435707173510065
Validation loss: 2.607618048785412

Epoch: 5| Step: 2
Training loss: 1.9690670787453521
Validation loss: 2.57408361702524

Epoch: 5| Step: 3
Training loss: 1.8295601973970843
Validation loss: 2.5500723499742914

Epoch: 5| Step: 4
Training loss: 1.261150456518228
Validation loss: 2.575684665962948

Epoch: 5| Step: 5
Training loss: 1.7382793983706781
Validation loss: 2.5876910860880007

Epoch: 5| Step: 6
Training loss: 1.384676996362132
Validation loss: 2.573430235311464

Epoch: 5| Step: 7
Training loss: 1.66532520509105
Validation loss: 2.571416700773491

Epoch: 5| Step: 8
Training loss: 1.6150212176083618
Validation loss: 2.614204080338458

Epoch: 5| Step: 9
Training loss: 2.1104173133700987
Validation loss: 2.5914570159892407

Epoch: 5| Step: 10
Training loss: 1.3433513493587954
Validation loss: 2.562025662071557

Epoch: 5| Step: 11
Training loss: 1.4193787513323872
Validation loss: 2.582482933746305

Epoch: 363| Step: 0
Training loss: 1.3720563243003592
Validation loss: 2.5642230862098945

Epoch: 5| Step: 1
Training loss: 1.3859225714222498
Validation loss: 2.560092725713604

Epoch: 5| Step: 2
Training loss: 1.7368794822017328
Validation loss: 2.580896333014419

Epoch: 5| Step: 3
Training loss: 1.5492508492965302
Validation loss: 2.55042943236965

Epoch: 5| Step: 4
Training loss: 1.6910182869146293
Validation loss: 2.556023177581843

Epoch: 5| Step: 5
Training loss: 1.2750319346000232
Validation loss: 2.5754720003739777

Epoch: 5| Step: 6
Training loss: 2.1493368589894524
Validation loss: 2.5742413216403506

Epoch: 5| Step: 7
Training loss: 1.5968649847086096
Validation loss: 2.608966323311086

Epoch: 5| Step: 8
Training loss: 1.7123917622017661
Validation loss: 2.6433591513156585

Epoch: 5| Step: 9
Training loss: 1.9142681400614814
Validation loss: 2.7080180803854708

Epoch: 5| Step: 10
Training loss: 1.9125965966656817
Validation loss: 2.6788818846275273

Epoch: 5| Step: 11
Training loss: 0.985568881762481
Validation loss: 2.6911618620523923

Epoch: 364| Step: 0
Training loss: 1.6465951468242477
Validation loss: 2.681561684887847

Epoch: 5| Step: 1
Training loss: 1.9375935193533844
Validation loss: 2.6795225843391433

Epoch: 5| Step: 2
Training loss: 1.8558644726040283
Validation loss: 2.6293933864863743

Epoch: 5| Step: 3
Training loss: 1.333593621279102
Validation loss: 2.618486034834152

Epoch: 5| Step: 4
Training loss: 1.7779849729728965
Validation loss: 2.6038742295417685

Epoch: 5| Step: 5
Training loss: 1.1037269052441656
Validation loss: 2.5741655752336734

Epoch: 5| Step: 6
Training loss: 1.6037863573694062
Validation loss: 2.574985241461869

Epoch: 5| Step: 7
Training loss: 1.5814671393715354
Validation loss: 2.5592559229374907

Epoch: 5| Step: 8
Training loss: 1.509786312065176
Validation loss: 2.577105472770786

Epoch: 5| Step: 9
Training loss: 1.3315567111015045
Validation loss: 2.567926445312632

Epoch: 5| Step: 10
Training loss: 2.1441144138595916
Validation loss: 2.554643986415962

Epoch: 5| Step: 11
Training loss: 1.759545993118166
Validation loss: 2.5462992081641556

Epoch: 365| Step: 0
Training loss: 1.2877036128101353
Validation loss: 2.550990689506772

Epoch: 5| Step: 1
Training loss: 2.1003308852959983
Validation loss: 2.53765086131141

Epoch: 5| Step: 2
Training loss: 1.4611583685555367
Validation loss: 2.5612580150592406

Epoch: 5| Step: 3
Training loss: 2.105985390542737
Validation loss: 2.5522708214120917

Epoch: 5| Step: 4
Training loss: 1.5256183371267509
Validation loss: 2.6514465582426197

Epoch: 5| Step: 5
Training loss: 1.3798310633929172
Validation loss: 2.616845164518039

Epoch: 5| Step: 6
Training loss: 1.4460666647774967
Validation loss: 2.625447185966379

Epoch: 5| Step: 7
Training loss: 1.644515737428692
Validation loss: 2.6051909218996534

Epoch: 5| Step: 8
Training loss: 1.6345007532584204
Validation loss: 2.5939510068411336

Epoch: 5| Step: 9
Training loss: 1.5011739905027541
Validation loss: 2.574043738783963

Epoch: 5| Step: 10
Training loss: 1.785962546666047
Validation loss: 2.569746811290635

Epoch: 5| Step: 11
Training loss: 1.0900782397826572
Validation loss: 2.580167115741746

Epoch: 366| Step: 0
Training loss: 1.3429805859393127
Validation loss: 2.5755419072959462

Epoch: 5| Step: 1
Training loss: 2.0548024888733294
Validation loss: 2.5744030953498234

Epoch: 5| Step: 2
Training loss: 1.7917309313345302
Validation loss: 2.5723422383509402

Epoch: 5| Step: 3
Training loss: 1.2260110186319726
Validation loss: 2.6072183327160743

Epoch: 5| Step: 4
Training loss: 1.7569175646120005
Validation loss: 2.597380636408008

Epoch: 5| Step: 5
Training loss: 1.387436415100292
Validation loss: 2.6006262452968216

Epoch: 5| Step: 6
Training loss: 1.8034809918101258
Validation loss: 2.619372242645679

Epoch: 5| Step: 7
Training loss: 1.5684118962787006
Validation loss: 2.630342602214049

Epoch: 5| Step: 8
Training loss: 1.5058316674757193
Validation loss: 2.6243688982760673

Epoch: 5| Step: 9
Training loss: 1.809941557894388
Validation loss: 2.620997412437123

Epoch: 5| Step: 10
Training loss: 1.2705188372497984
Validation loss: 2.623813947789146

Epoch: 5| Step: 11
Training loss: 2.194375486403726
Validation loss: 2.613360401393718

Epoch: 367| Step: 0
Training loss: 1.3962730834746706
Validation loss: 2.596185100309328

Epoch: 5| Step: 1
Training loss: 2.0027444605966793
Validation loss: 2.569781413764638

Epoch: 5| Step: 2
Training loss: 1.8536222565893221
Validation loss: 2.6011806814993026

Epoch: 5| Step: 3
Training loss: 1.855050836982126
Validation loss: 2.59930140282956

Epoch: 5| Step: 4
Training loss: 2.292967814196732
Validation loss: 2.5816475164192854

Epoch: 5| Step: 5
Training loss: 1.378091976955182
Validation loss: 2.5725702111709636

Epoch: 5| Step: 6
Training loss: 1.5729898431526432
Validation loss: 2.6193220704845386

Epoch: 5| Step: 7
Training loss: 1.4149387237167441
Validation loss: 2.5980419819048324

Epoch: 5| Step: 8
Training loss: 1.5172210626789027
Validation loss: 2.6607948279907534

Epoch: 5| Step: 9
Training loss: 1.172871636338804
Validation loss: 2.669284471926698

Epoch: 5| Step: 10
Training loss: 1.4383990751840592
Validation loss: 2.6581729062222195

Epoch: 5| Step: 11
Training loss: 1.3239272255273065
Validation loss: 2.67237511726359

Epoch: 368| Step: 0
Training loss: 1.592104043167795
Validation loss: 2.561948263270568

Epoch: 5| Step: 1
Training loss: 1.0373714137536478
Validation loss: 2.5906684755267304

Epoch: 5| Step: 2
Training loss: 1.1694931747772301
Validation loss: 2.56026784083058

Epoch: 5| Step: 3
Training loss: 1.7989345523195257
Validation loss: 2.5931632860565688

Epoch: 5| Step: 4
Training loss: 1.3241833707421249
Validation loss: 2.5899975339283734

Epoch: 5| Step: 5
Training loss: 1.3196215204017945
Validation loss: 2.573917844066136

Epoch: 5| Step: 6
Training loss: 2.3226579827162013
Validation loss: 2.579197011459962

Epoch: 5| Step: 7
Training loss: 1.5924458122915326
Validation loss: 2.5593422763022664

Epoch: 5| Step: 8
Training loss: 1.2764090288187786
Validation loss: 2.542940681642481

Epoch: 5| Step: 9
Training loss: 1.3621711911657997
Validation loss: 2.5759407539413455

Epoch: 5| Step: 10
Training loss: 2.465972593534196
Validation loss: 2.599993193293489

Epoch: 5| Step: 11
Training loss: 0.8613072952900497
Validation loss: 2.6122283639186152

Epoch: 369| Step: 0
Training loss: 1.6361088674832505
Validation loss: 2.6736600538345674

Epoch: 5| Step: 1
Training loss: 1.9424160762219003
Validation loss: 2.740404909953664

Epoch: 5| Step: 2
Training loss: 1.4753716727916313
Validation loss: 2.774864581816239

Epoch: 5| Step: 3
Training loss: 1.6828424675981863
Validation loss: 2.8108871144445216

Epoch: 5| Step: 4
Training loss: 1.3095588882710354
Validation loss: 2.740776477862702

Epoch: 5| Step: 5
Training loss: 1.4993430129372416
Validation loss: 2.6154347827979394

Epoch: 5| Step: 6
Training loss: 1.5377661187833087
Validation loss: 2.601792792130998

Epoch: 5| Step: 7
Training loss: 2.016960470482688
Validation loss: 2.5594073994145754

Epoch: 5| Step: 8
Training loss: 1.5440915428754673
Validation loss: 2.550770458220027

Epoch: 5| Step: 9
Training loss: 2.1602016119996956
Validation loss: 2.5845803793837447

Epoch: 5| Step: 10
Training loss: 1.2786383644812997
Validation loss: 2.611623495778116

Epoch: 5| Step: 11
Training loss: 2.3772718706399645
Validation loss: 2.5696497626079133

Epoch: 370| Step: 0
Training loss: 1.6652464617210678
Validation loss: 2.578669762132776

Epoch: 5| Step: 1
Training loss: 1.6378311346573786
Validation loss: 2.5718347666031893

Epoch: 5| Step: 2
Training loss: 1.4553366617003642
Validation loss: 2.554878161642679

Epoch: 5| Step: 3
Training loss: 2.020661795765187
Validation loss: 2.6097285569867346

Epoch: 5| Step: 4
Training loss: 1.1504016610152148
Validation loss: 2.610606194324081

Epoch: 5| Step: 5
Training loss: 1.8396740488889318
Validation loss: 2.6020731801816606

Epoch: 5| Step: 6
Training loss: 1.3194601704959754
Validation loss: 2.5926014184013133

Epoch: 5| Step: 7
Training loss: 1.7386259615853854
Validation loss: 2.618552376809728

Epoch: 5| Step: 8
Training loss: 1.030109757714161
Validation loss: 2.6126490551956114

Epoch: 5| Step: 9
Training loss: 1.7360402953222087
Validation loss: 2.5968669179705692

Epoch: 5| Step: 10
Training loss: 1.4840414375164837
Validation loss: 2.6202880978040413

Epoch: 5| Step: 11
Training loss: 2.7558477821890293
Validation loss: 2.587614382029342

Epoch: 371| Step: 0
Training loss: 1.3993294710945332
Validation loss: 2.547740625354677

Epoch: 5| Step: 1
Training loss: 1.1686883961154768
Validation loss: 2.559281894851892

Epoch: 5| Step: 2
Training loss: 1.4897573765090197
Validation loss: 2.587986981979226

Epoch: 5| Step: 3
Training loss: 1.673572213585749
Validation loss: 2.542037148651402

Epoch: 5| Step: 4
Training loss: 1.4878146824443141
Validation loss: 2.558151781575881

Epoch: 5| Step: 5
Training loss: 2.104223559022766
Validation loss: 2.569711435181703

Epoch: 5| Step: 6
Training loss: 1.7764714039015672
Validation loss: 2.578853816273928

Epoch: 5| Step: 7
Training loss: 1.8037797370516095
Validation loss: 2.591284746571025

Epoch: 5| Step: 8
Training loss: 1.6449777173791225
Validation loss: 2.6130009354965495

Epoch: 5| Step: 9
Training loss: 1.4022692817318538
Validation loss: 2.602530390073105

Epoch: 5| Step: 10
Training loss: 1.5117536831548004
Validation loss: 2.6200830981311487

Epoch: 5| Step: 11
Training loss: 1.13361551170572
Validation loss: 2.600496621722395

Epoch: 372| Step: 0
Training loss: 1.6283231647581322
Validation loss: 2.592207392454706

Epoch: 5| Step: 1
Training loss: 1.362891811065289
Validation loss: 2.589735781651975

Epoch: 5| Step: 2
Training loss: 1.0778205552301985
Validation loss: 2.534332764693429

Epoch: 5| Step: 3
Training loss: 1.3530732019390537
Validation loss: 2.5123585963273674

Epoch: 5| Step: 4
Training loss: 1.2037807510583696
Validation loss: 2.5107858684453874

Epoch: 5| Step: 5
Training loss: 2.202311264074547
Validation loss: 2.537509920855642

Epoch: 5| Step: 6
Training loss: 1.3577184558955628
Validation loss: 2.544217035251261

Epoch: 5| Step: 7
Training loss: 1.7378106669687428
Validation loss: 2.5616075853630007

Epoch: 5| Step: 8
Training loss: 1.220141570053865
Validation loss: 2.5386125958259056

Epoch: 5| Step: 9
Training loss: 1.9898650151386903
Validation loss: 2.574435354718297

Epoch: 5| Step: 10
Training loss: 2.019134187309879
Validation loss: 2.5940796899189595

Epoch: 5| Step: 11
Training loss: 2.094204525932352
Validation loss: 2.574291178061135

Epoch: 373| Step: 0
Training loss: 1.2643095645009614
Validation loss: 2.625107316442291

Epoch: 5| Step: 1
Training loss: 1.330968080139314
Validation loss: 2.573173719891078

Epoch: 5| Step: 2
Training loss: 1.9480061094043344
Validation loss: 2.604122668212502

Epoch: 5| Step: 3
Training loss: 1.5143506700023117
Validation loss: 2.5968249068648537

Epoch: 5| Step: 4
Training loss: 2.024917826927934
Validation loss: 2.592430763564689

Epoch: 5| Step: 5
Training loss: 1.3564206169851942
Validation loss: 2.590863996861904

Epoch: 5| Step: 6
Training loss: 2.1688884811822233
Validation loss: 2.5444479925870334

Epoch: 5| Step: 7
Training loss: 1.1171857393691054
Validation loss: 2.5631006475056193

Epoch: 5| Step: 8
Training loss: 1.5882224173844541
Validation loss: 2.5646220933808745

Epoch: 5| Step: 9
Training loss: 1.193263023470034
Validation loss: 2.562084776879553

Epoch: 5| Step: 10
Training loss: 1.5449704863065667
Validation loss: 2.525079718360576

Epoch: 5| Step: 11
Training loss: 1.8103222753971047
Validation loss: 2.5348244456286024

Epoch: 374| Step: 0
Training loss: 1.4272663899354443
Validation loss: 2.52323892125009

Epoch: 5| Step: 1
Training loss: 1.295852211858645
Validation loss: 2.5531632156344597

Epoch: 5| Step: 2
Training loss: 1.7413323874059643
Validation loss: 2.5890529340015926

Epoch: 5| Step: 3
Training loss: 1.3184653458567266
Validation loss: 2.596584661207618

Epoch: 5| Step: 4
Training loss: 1.6714541181770868
Validation loss: 2.5808094921885165

Epoch: 5| Step: 5
Training loss: 1.8834793366184046
Validation loss: 2.569597861861956

Epoch: 5| Step: 6
Training loss: 1.2971337301624575
Validation loss: 2.5913088122666608

Epoch: 5| Step: 7
Training loss: 1.547531065867839
Validation loss: 2.6156167512168844

Epoch: 5| Step: 8
Training loss: 2.0653853607832118
Validation loss: 2.629360445038366

Epoch: 5| Step: 9
Training loss: 1.2868252847340178
Validation loss: 2.6125132863073453

Epoch: 5| Step: 10
Training loss: 1.5582646761098602
Validation loss: 2.5682681494153567

Epoch: 5| Step: 11
Training loss: 1.65767680196133
Validation loss: 2.5840861520789256

Epoch: 375| Step: 0
Training loss: 1.4883179347205324
Validation loss: 2.5929874348616133

Epoch: 5| Step: 1
Training loss: 1.0635157386142493
Validation loss: 2.6135391313386744

Epoch: 5| Step: 2
Training loss: 1.3638481120229105
Validation loss: 2.5784630062592564

Epoch: 5| Step: 3
Training loss: 1.3512885637453054
Validation loss: 2.5901331981937092

Epoch: 5| Step: 4
Training loss: 1.9981275376252166
Validation loss: 2.5768968180576968

Epoch: 5| Step: 5
Training loss: 1.9952945789079022
Validation loss: 2.578498967338485

Epoch: 5| Step: 6
Training loss: 1.2894092902516139
Validation loss: 2.5558042214500474

Epoch: 5| Step: 7
Training loss: 1.462501952993279
Validation loss: 2.563514958169797

Epoch: 5| Step: 8
Training loss: 1.6466641401485154
Validation loss: 2.5592551427279435

Epoch: 5| Step: 9
Training loss: 1.4083714906989557
Validation loss: 2.6100491092709523

Epoch: 5| Step: 10
Training loss: 1.9234150244533093
Validation loss: 2.5552259027556374

Epoch: 5| Step: 11
Training loss: 0.6655875701409647
Validation loss: 2.5344458409014776

Epoch: 376| Step: 0
Training loss: 1.7044884360053465
Validation loss: 2.574108061583872

Epoch: 5| Step: 1
Training loss: 1.4322831402149145
Validation loss: 2.5727286958693076

Epoch: 5| Step: 2
Training loss: 1.4628098673105132
Validation loss: 2.555602787552876

Epoch: 5| Step: 3
Training loss: 0.9618504227242848
Validation loss: 2.5576309897045637

Epoch: 5| Step: 4
Training loss: 2.0878804619651508
Validation loss: 2.5501800965931833

Epoch: 5| Step: 5
Training loss: 1.5723975463871334
Validation loss: 2.5735352167763943

Epoch: 5| Step: 6
Training loss: 1.636129268566354
Validation loss: 2.584942525431305

Epoch: 5| Step: 7
Training loss: 1.7360494280559648
Validation loss: 2.583618122728352

Epoch: 5| Step: 8
Training loss: 1.3774394590086156
Validation loss: 2.5713709687679547

Epoch: 5| Step: 9
Training loss: 1.2005132094311486
Validation loss: 2.5494864947194555

Epoch: 5| Step: 10
Training loss: 1.469182944911731
Validation loss: 2.56539985127277

Epoch: 5| Step: 11
Training loss: 1.7931396137013018
Validation loss: 2.549706758985203

Epoch: 377| Step: 0
Training loss: 1.4073747587297794
Validation loss: 2.5276435505216925

Epoch: 5| Step: 1
Training loss: 1.4273851544200808
Validation loss: 2.566075273187239

Epoch: 5| Step: 2
Training loss: 1.5154485698142564
Validation loss: 2.5926995045956196

Epoch: 5| Step: 3
Training loss: 1.1458815073232391
Validation loss: 2.5904607752218527

Epoch: 5| Step: 4
Training loss: 1.2877373097053093
Validation loss: 2.6048512830463815

Epoch: 5| Step: 5
Training loss: 1.1919289864854188
Validation loss: 2.5741650117967825

Epoch: 5| Step: 6
Training loss: 1.9778584088213844
Validation loss: 2.5954189867393165

Epoch: 5| Step: 7
Training loss: 1.3728299356174385
Validation loss: 2.574619667195865

Epoch: 5| Step: 8
Training loss: 1.4395460411942431
Validation loss: 2.5737900191208425

Epoch: 5| Step: 9
Training loss: 1.1992883320356842
Validation loss: 2.6114267213173807

Epoch: 5| Step: 10
Training loss: 2.232444516098005
Validation loss: 2.6161434045732634

Epoch: 5| Step: 11
Training loss: 2.0661665952341486
Validation loss: 2.631765268635612

Epoch: 378| Step: 0
Training loss: 1.4165083665853164
Validation loss: 2.6199722638585192

Epoch: 5| Step: 1
Training loss: 1.3774903460127985
Validation loss: 2.635342083630758

Epoch: 5| Step: 2
Training loss: 1.138650622423076
Validation loss: 2.589257509096739

Epoch: 5| Step: 3
Training loss: 1.3750106637714594
Validation loss: 2.6024248070653724

Epoch: 5| Step: 4
Training loss: 1.9387866024494924
Validation loss: 2.583777740666711

Epoch: 5| Step: 5
Training loss: 1.3423108667025447
Validation loss: 2.5898236963906314

Epoch: 5| Step: 6
Training loss: 1.1959660557232636
Validation loss: 2.5574132083722474

Epoch: 5| Step: 7
Training loss: 2.1992226527773986
Validation loss: 2.529935118518028

Epoch: 5| Step: 8
Training loss: 1.730816326152694
Validation loss: 2.5822601447746796

Epoch: 5| Step: 9
Training loss: 1.5902497244206324
Validation loss: 2.5675498044260725

Epoch: 5| Step: 10
Training loss: 1.3980754191748046
Validation loss: 2.590641717737952

Epoch: 5| Step: 11
Training loss: 1.1022861890140645
Validation loss: 2.559629010523571

Epoch: 379| Step: 0
Training loss: 1.5696018565784249
Validation loss: 2.614407048355373

Epoch: 5| Step: 1
Training loss: 1.3413771149054579
Validation loss: 2.6098221568955546

Epoch: 5| Step: 2
Training loss: 1.3513609454742292
Validation loss: 2.634950956024514

Epoch: 5| Step: 3
Training loss: 1.8111402080528465
Validation loss: 2.610266116449565

Epoch: 5| Step: 4
Training loss: 1.5273565501581599
Validation loss: 2.627735423252363

Epoch: 5| Step: 5
Training loss: 1.8925413397805397
Validation loss: 2.5584928730498926

Epoch: 5| Step: 6
Training loss: 1.763332127220352
Validation loss: 2.5806879078132874

Epoch: 5| Step: 7
Training loss: 1.7298363763684612
Validation loss: 2.5711510593823963

Epoch: 5| Step: 8
Training loss: 1.1800144576140679
Validation loss: 2.554981448093106

Epoch: 5| Step: 9
Training loss: 1.161877007854629
Validation loss: 2.584969138533675

Epoch: 5| Step: 10
Training loss: 1.5553924649134918
Validation loss: 2.550387485989305

Epoch: 5| Step: 11
Training loss: 0.7465053441622254
Validation loss: 2.577416440137766

Epoch: 380| Step: 0
Training loss: 2.0386615227375953
Validation loss: 2.5815258406760004

Epoch: 5| Step: 1
Training loss: 1.4229658365015605
Validation loss: 2.612006256074604

Epoch: 5| Step: 2
Training loss: 1.4392956009572233
Validation loss: 2.6697800028160814

Epoch: 5| Step: 3
Training loss: 1.4893011968578278
Validation loss: 2.6147870646786204

Epoch: 5| Step: 4
Training loss: 1.102352481323528
Validation loss: 2.5935982349530944

Epoch: 5| Step: 5
Training loss: 0.8704068336521839
Validation loss: 2.6276981663344037

Epoch: 5| Step: 6
Training loss: 1.3678937994937401
Validation loss: 2.663707053149926

Epoch: 5| Step: 7
Training loss: 1.217285303145674
Validation loss: 2.5966483586853024

Epoch: 5| Step: 8
Training loss: 1.9516492227262858
Validation loss: 2.648048593629635

Epoch: 5| Step: 9
Training loss: 1.4064084281688378
Validation loss: 2.6209235972298828

Epoch: 5| Step: 10
Training loss: 2.3012295919214814
Validation loss: 2.6477828590525556

Epoch: 5| Step: 11
Training loss: 0.9199490229332479
Validation loss: 2.6338865954923683

Epoch: 381| Step: 0
Training loss: 1.1813104846142568
Validation loss: 2.607824931144608

Epoch: 5| Step: 1
Training loss: 1.204461383503006
Validation loss: 2.623763712901228

Epoch: 5| Step: 2
Training loss: 1.8494007351429649
Validation loss: 2.630000139564008

Epoch: 5| Step: 3
Training loss: 1.6190956394770384
Validation loss: 2.6845338221540387

Epoch: 5| Step: 4
Training loss: 1.9488547067364335
Validation loss: 2.703153562303

Epoch: 5| Step: 5
Training loss: 1.6512760834290654
Validation loss: 2.683501595992951

Epoch: 5| Step: 6
Training loss: 1.2445105177977813
Validation loss: 2.5962697203182157

Epoch: 5| Step: 7
Training loss: 1.9113562311522418
Validation loss: 2.5902857223527542

Epoch: 5| Step: 8
Training loss: 1.5753292587287848
Validation loss: 2.5818735787270706

Epoch: 5| Step: 9
Training loss: 1.385484990129832
Validation loss: 2.5594529085330087

Epoch: 5| Step: 10
Training loss: 1.2043825983303689
Validation loss: 2.589839810636429

Epoch: 5| Step: 11
Training loss: 1.9069587765635352
Validation loss: 2.5290569176866224

Epoch: 382| Step: 0
Training loss: 1.9138022732463151
Validation loss: 2.582806884796445

Epoch: 5| Step: 1
Training loss: 1.455222144456157
Validation loss: 2.565149277162932

Epoch: 5| Step: 2
Training loss: 1.4061285178375935
Validation loss: 2.525609533307733

Epoch: 5| Step: 3
Training loss: 1.6284656980917498
Validation loss: 2.56109001554263

Epoch: 5| Step: 4
Training loss: 1.181080784863396
Validation loss: 2.5555542108513802

Epoch: 5| Step: 5
Training loss: 1.7928305844862167
Validation loss: 2.5611286215368603

Epoch: 5| Step: 6
Training loss: 1.7779399165416911
Validation loss: 2.6217661874809197

Epoch: 5| Step: 7
Training loss: 1.5522284301251992
Validation loss: 2.638728244950224

Epoch: 5| Step: 8
Training loss: 1.4895479513736805
Validation loss: 2.6819051013396056

Epoch: 5| Step: 9
Training loss: 1.101955046275133
Validation loss: 2.670134771454382

Epoch: 5| Step: 10
Training loss: 1.2697328378111254
Validation loss: 2.6230901665806448

Epoch: 5| Step: 11
Training loss: 1.2149151845456738
Validation loss: 2.57824599627539

Epoch: 383| Step: 0
Training loss: 1.9863942003090944
Validation loss: 2.607540182222814

Epoch: 5| Step: 1
Training loss: 1.5612258293534855
Validation loss: 2.6029290017493736

Epoch: 5| Step: 2
Training loss: 1.4115447502379932
Validation loss: 2.597365938183781

Epoch: 5| Step: 3
Training loss: 1.232667587137231
Validation loss: 2.567962225122444

Epoch: 5| Step: 4
Training loss: 1.4592145255689684
Validation loss: 2.606907673590373

Epoch: 5| Step: 5
Training loss: 1.0905210516505481
Validation loss: 2.5629503234350968

Epoch: 5| Step: 6
Training loss: 1.7446965509556043
Validation loss: 2.5863294890184623

Epoch: 5| Step: 7
Training loss: 1.5083709631312858
Validation loss: 2.5504185456188675

Epoch: 5| Step: 8
Training loss: 1.2121785357134724
Validation loss: 2.561281798553045

Epoch: 5| Step: 9
Training loss: 1.254669337539046
Validation loss: 2.540643123735674

Epoch: 5| Step: 10
Training loss: 1.7540439475196516
Validation loss: 2.58467618716327

Epoch: 5| Step: 11
Training loss: 1.5699378178668044
Validation loss: 2.580124093473317

Epoch: 384| Step: 0
Training loss: 1.2956236351731028
Validation loss: 2.59680590945075

Epoch: 5| Step: 1
Training loss: 1.5118017839205498
Validation loss: 2.6411267919248314

Epoch: 5| Step: 2
Training loss: 1.7673201399048935
Validation loss: 2.711940239136753

Epoch: 5| Step: 3
Training loss: 1.4248465204405432
Validation loss: 2.7326770088017622

Epoch: 5| Step: 4
Training loss: 1.56184403955518
Validation loss: 2.7090047529793075

Epoch: 5| Step: 5
Training loss: 1.93796595231137
Validation loss: 2.6350712317345915

Epoch: 5| Step: 6
Training loss: 1.3534508011172486
Validation loss: 2.618561880111727

Epoch: 5| Step: 7
Training loss: 1.3011227179580658
Validation loss: 2.592088492727201

Epoch: 5| Step: 8
Training loss: 1.7174003850930906
Validation loss: 2.593115382326473

Epoch: 5| Step: 9
Training loss: 2.2040665150071317
Validation loss: 2.6119724449814137

Epoch: 5| Step: 10
Training loss: 1.5533623343258554
Validation loss: 2.589211081226295

Epoch: 5| Step: 11
Training loss: 1.1438157901707215
Validation loss: 2.5736200295316825

Epoch: 385| Step: 0
Training loss: 1.6699312979449057
Validation loss: 2.6142526787322837

Epoch: 5| Step: 1
Training loss: 1.9456030081030844
Validation loss: 2.564500555029343

Epoch: 5| Step: 2
Training loss: 1.6474334406974749
Validation loss: 2.6180412304455687

Epoch: 5| Step: 3
Training loss: 1.4799202982603086
Validation loss: 2.6702272379600007

Epoch: 5| Step: 4
Training loss: 1.1136860429443953
Validation loss: 2.696345627930677

Epoch: 5| Step: 5
Training loss: 1.3788758185381376
Validation loss: 2.7107728437243197

Epoch: 5| Step: 6
Training loss: 1.5543592096806698
Validation loss: 2.7287352174809056

Epoch: 5| Step: 7
Training loss: 1.7812297886822777
Validation loss: 2.669767634362628

Epoch: 5| Step: 8
Training loss: 1.477249550804319
Validation loss: 2.64517921086416

Epoch: 5| Step: 9
Training loss: 1.2635142774933834
Validation loss: 2.6412351945340857

Epoch: 5| Step: 10
Training loss: 1.3155996868389497
Validation loss: 2.5695036588466973

Epoch: 5| Step: 11
Training loss: 2.5760754385736004
Validation loss: 2.5175063934642745

Epoch: 386| Step: 0
Training loss: 1.7961460127492392
Validation loss: 2.5136754239207213

Epoch: 5| Step: 1
Training loss: 2.027851724655306
Validation loss: 2.5029519058176084

Epoch: 5| Step: 2
Training loss: 1.2727781589819596
Validation loss: 2.530318449840293

Epoch: 5| Step: 3
Training loss: 1.4507803921550624
Validation loss: 2.512474662184861

Epoch: 5| Step: 4
Training loss: 1.6337244143011223
Validation loss: 2.5258228574284063

Epoch: 5| Step: 5
Training loss: 1.952827919300754
Validation loss: 2.5207663256564135

Epoch: 5| Step: 6
Training loss: 1.9279067127681766
Validation loss: 2.5229730759374873

Epoch: 5| Step: 7
Training loss: 1.0690000520390355
Validation loss: 2.5685623146786827

Epoch: 5| Step: 8
Training loss: 1.6343912769331315
Validation loss: 2.580043957099233

Epoch: 5| Step: 9
Training loss: 1.158346646504544
Validation loss: 2.5770829262163915

Epoch: 5| Step: 10
Training loss: 1.4406279656965135
Validation loss: 2.569950410640306

Epoch: 5| Step: 11
Training loss: 1.7774374465558747
Validation loss: 2.565422411442315

Epoch: 387| Step: 0
Training loss: 1.0282089013646891
Validation loss: 2.5861185131508835

Epoch: 5| Step: 1
Training loss: 1.2319471409159015
Validation loss: 2.5382223764098257

Epoch: 5| Step: 2
Training loss: 1.3753868339159134
Validation loss: 2.5950213690645385

Epoch: 5| Step: 3
Training loss: 1.4479850185736287
Validation loss: 2.602613322789182

Epoch: 5| Step: 4
Training loss: 1.9885861026307847
Validation loss: 2.630571084769455

Epoch: 5| Step: 5
Training loss: 1.4802605072354682
Validation loss: 2.6098327730094875

Epoch: 5| Step: 6
Training loss: 1.5479559926325275
Validation loss: 2.6062453950678135

Epoch: 5| Step: 7
Training loss: 2.1439705204218047
Validation loss: 2.610351905009272

Epoch: 5| Step: 8
Training loss: 1.58578663376193
Validation loss: 2.596409663478033

Epoch: 5| Step: 9
Training loss: 1.8130231299673905
Validation loss: 2.5910703938810657

Epoch: 5| Step: 10
Training loss: 1.3312102889464579
Validation loss: 2.621636756557404

Epoch: 5| Step: 11
Training loss: 1.8704779453766958
Validation loss: 2.5797407732029414

Epoch: 388| Step: 0
Training loss: 1.7162279525196429
Validation loss: 2.62641892230796

Epoch: 5| Step: 1
Training loss: 1.594774926428098
Validation loss: 2.649306980719849

Epoch: 5| Step: 2
Training loss: 1.2358542644574237
Validation loss: 2.632381732236656

Epoch: 5| Step: 3
Training loss: 1.624561984376947
Validation loss: 2.6346184699097406

Epoch: 5| Step: 4
Training loss: 1.5292250030505106
Validation loss: 2.6139972658106565

Epoch: 5| Step: 5
Training loss: 1.810724506902881
Validation loss: 2.584952013946453

Epoch: 5| Step: 6
Training loss: 0.8611306723215283
Validation loss: 2.6028513269562352

Epoch: 5| Step: 7
Training loss: 1.346082481651499
Validation loss: 2.567297503482204

Epoch: 5| Step: 8
Training loss: 1.7649619959124845
Validation loss: 2.607580896831293

Epoch: 5| Step: 9
Training loss: 1.2310545480574648
Validation loss: 2.555424606266954

Epoch: 5| Step: 10
Training loss: 1.7904594331527723
Validation loss: 2.5724155823548776

Epoch: 5| Step: 11
Training loss: 1.7656044747839061
Validation loss: 2.591824253285507

Epoch: 389| Step: 0
Training loss: 1.039220812217216
Validation loss: 2.5862347219786272

Epoch: 5| Step: 1
Training loss: 1.4705639452891697
Validation loss: 2.5720525840178996

Epoch: 5| Step: 2
Training loss: 1.8135539312092208
Validation loss: 2.6228459769599084

Epoch: 5| Step: 3
Training loss: 1.3180150917647913
Validation loss: 2.627763814521648

Epoch: 5| Step: 4
Training loss: 1.3753081756641694
Validation loss: 2.6631553388131413

Epoch: 5| Step: 5
Training loss: 2.0169655533715862
Validation loss: 2.672765449583463

Epoch: 5| Step: 6
Training loss: 1.809869765132824
Validation loss: 2.6584811433120135

Epoch: 5| Step: 7
Training loss: 1.2751777319354298
Validation loss: 2.5907636133712586

Epoch: 5| Step: 8
Training loss: 1.0999541749945825
Validation loss: 2.5557826822069347

Epoch: 5| Step: 9
Training loss: 1.126274234964003
Validation loss: 2.5575111059343594

Epoch: 5| Step: 10
Training loss: 1.690813978425022
Validation loss: 2.594413928961565

Epoch: 5| Step: 11
Training loss: 3.356020792090806
Validation loss: 2.564103311124412

Epoch: 390| Step: 0
Training loss: 1.3860304292748606
Validation loss: 2.6074463880055796

Epoch: 5| Step: 1
Training loss: 1.2325669579569167
Validation loss: 2.5747095314562105

Epoch: 5| Step: 2
Training loss: 2.077327030110294
Validation loss: 2.5969101639871357

Epoch: 5| Step: 3
Training loss: 1.7925472387369985
Validation loss: 2.57780313120241

Epoch: 5| Step: 4
Training loss: 1.258835086617414
Validation loss: 2.5910993230022465

Epoch: 5| Step: 5
Training loss: 1.5708650594217535
Validation loss: 2.63644882515939

Epoch: 5| Step: 6
Training loss: 1.3311436176328872
Validation loss: 2.6167027911853316

Epoch: 5| Step: 7
Training loss: 1.6880556533958802
Validation loss: 2.6360295730185173

Epoch: 5| Step: 8
Training loss: 1.4137399632294112
Validation loss: 2.607170727239302

Epoch: 5| Step: 9
Training loss: 1.5074346988129546
Validation loss: 2.5820683540606164

Epoch: 5| Step: 10
Training loss: 1.5247082227896371
Validation loss: 2.5971434275823198

Epoch: 5| Step: 11
Training loss: 1.7930069131882806
Validation loss: 2.5942530201701994

Epoch: 391| Step: 0
Training loss: 1.7094240505845226
Validation loss: 2.589292783132466

Epoch: 5| Step: 1
Training loss: 1.0786653353286404
Validation loss: 2.563174228823331

Epoch: 5| Step: 2
Training loss: 1.7818448595958665
Validation loss: 2.5458452994465497

Epoch: 5| Step: 3
Training loss: 1.3746140545274586
Validation loss: 2.5685973430668514

Epoch: 5| Step: 4
Training loss: 1.219408590928508
Validation loss: 2.5801496859186512

Epoch: 5| Step: 5
Training loss: 1.8866628318698224
Validation loss: 2.545941550383993

Epoch: 5| Step: 6
Training loss: 1.792345458089663
Validation loss: 2.5807572076828573

Epoch: 5| Step: 7
Training loss: 0.9719328737353023
Validation loss: 2.621603861638722

Epoch: 5| Step: 8
Training loss: 1.3733771891365996
Validation loss: 2.6337607135503505

Epoch: 5| Step: 9
Training loss: 1.7656894098197062
Validation loss: 2.6750263792145517

Epoch: 5| Step: 10
Training loss: 1.267088855897375
Validation loss: 2.6582966605161147

Epoch: 5| Step: 11
Training loss: 1.1711652004847468
Validation loss: 2.6074463651461857

Epoch: 392| Step: 0
Training loss: 1.4676084749334242
Validation loss: 2.5599348052981967

Epoch: 5| Step: 1
Training loss: 1.2089698309940258
Validation loss: 2.5948980789437224

Epoch: 5| Step: 2
Training loss: 1.565274712214401
Validation loss: 2.5577953461553617

Epoch: 5| Step: 3
Training loss: 1.364043801300774
Validation loss: 2.584724502885885

Epoch: 5| Step: 4
Training loss: 1.1320822104704822
Validation loss: 2.5570494128517587

Epoch: 5| Step: 5
Training loss: 1.171020501450032
Validation loss: 2.5743522358593505

Epoch: 5| Step: 6
Training loss: 1.5594463263274068
Validation loss: 2.55452178666486

Epoch: 5| Step: 7
Training loss: 1.6604317470170447
Validation loss: 2.5644274340134645

Epoch: 5| Step: 8
Training loss: 1.3377836087160695
Validation loss: 2.5226018996461588

Epoch: 5| Step: 9
Training loss: 1.8046540756763398
Validation loss: 2.550754272411746

Epoch: 5| Step: 10
Training loss: 1.5940333843731804
Validation loss: 2.5975648142083805

Epoch: 5| Step: 11
Training loss: 1.873768338348452
Validation loss: 2.591172868341595

Epoch: 393| Step: 0
Training loss: 2.1779480696723357
Validation loss: 2.6301221676048216

Epoch: 5| Step: 1
Training loss: 1.4793704344755956
Validation loss: 2.62678181634474

Epoch: 5| Step: 2
Training loss: 1.2569003381361283
Validation loss: 2.622982097250987

Epoch: 5| Step: 3
Training loss: 1.1197582092018303
Validation loss: 2.594930410842451

Epoch: 5| Step: 4
Training loss: 1.1469448016386758
Validation loss: 2.5966872202847777

Epoch: 5| Step: 5
Training loss: 1.5460922110127273
Validation loss: 2.6249628026536875

Epoch: 5| Step: 6
Training loss: 1.1790194609364884
Validation loss: 2.6051811581892053

Epoch: 5| Step: 7
Training loss: 1.1567821309194795
Validation loss: 2.5990810913164655

Epoch: 5| Step: 8
Training loss: 1.6462963354357605
Validation loss: 2.5884155969346634

Epoch: 5| Step: 9
Training loss: 1.3824452057891037
Validation loss: 2.6042723379947987

Epoch: 5| Step: 10
Training loss: 1.2106359783220353
Validation loss: 2.575342979628813

Epoch: 5| Step: 11
Training loss: 1.6243081454014971
Validation loss: 2.5928304873103065

Epoch: 394| Step: 0
Training loss: 1.1763868831560875
Validation loss: 2.5797638587425373

Epoch: 5| Step: 1
Training loss: 1.4925355355586665
Validation loss: 2.6033981002911264

Epoch: 5| Step: 2
Training loss: 1.0974554237923762
Validation loss: 2.6014228760422107

Epoch: 5| Step: 3
Training loss: 1.7580683543182274
Validation loss: 2.624101038302232

Epoch: 5| Step: 4
Training loss: 1.65515517991099
Validation loss: 2.5893332974206853

Epoch: 5| Step: 5
Training loss: 1.8693916367505057
Validation loss: 2.600084429067001

Epoch: 5| Step: 6
Training loss: 1.3189426516428808
Validation loss: 2.6169308019361037

Epoch: 5| Step: 7
Training loss: 1.3736801748953031
Validation loss: 2.5850453100592956

Epoch: 5| Step: 8
Training loss: 0.9235201235500988
Validation loss: 2.5890024121804784

Epoch: 5| Step: 9
Training loss: 1.8782080862039188
Validation loss: 2.5575691520624484

Epoch: 5| Step: 10
Training loss: 1.2500077247380943
Validation loss: 2.597037843601333

Epoch: 5| Step: 11
Training loss: 1.0326281499885046
Validation loss: 2.5623587204979126

Epoch: 395| Step: 0
Training loss: 1.448897745203542
Validation loss: 2.5220753976550108

Epoch: 5| Step: 1
Training loss: 0.8999265852761095
Validation loss: 2.556690923722028

Epoch: 5| Step: 2
Training loss: 1.6484056804171252
Validation loss: 2.545300857301877

Epoch: 5| Step: 3
Training loss: 1.1252175226785688
Validation loss: 2.58165730179364

Epoch: 5| Step: 4
Training loss: 1.5014182379707792
Validation loss: 2.5589093816851047

Epoch: 5| Step: 5
Training loss: 1.412293481498768
Validation loss: 2.583906096111089

Epoch: 5| Step: 6
Training loss: 1.1957781514230197
Validation loss: 2.590723290168278

Epoch: 5| Step: 7
Training loss: 1.5384925522796007
Validation loss: 2.6260851970808794

Epoch: 5| Step: 8
Training loss: 2.1914290972655914
Validation loss: 2.6155051807440253

Epoch: 5| Step: 9
Training loss: 1.445379554636449
Validation loss: 2.636446131046613

Epoch: 5| Step: 10
Training loss: 1.283031899279391
Validation loss: 2.6552307342466324

Epoch: 5| Step: 11
Training loss: 1.1201017024492244
Validation loss: 2.6426269271114817

Epoch: 396| Step: 0
Training loss: 1.7277372342525232
Validation loss: 2.5601200627755443

Epoch: 5| Step: 1
Training loss: 1.4003652998630778
Validation loss: 2.5719274860061767

Epoch: 5| Step: 2
Training loss: 1.1129953653113973
Validation loss: 2.5810713645385697

Epoch: 5| Step: 3
Training loss: 1.5025787439515117
Validation loss: 2.6142809580292616

Epoch: 5| Step: 4
Training loss: 1.390632115035125
Validation loss: 2.5741765004821566

Epoch: 5| Step: 5
Training loss: 1.3457434306316554
Validation loss: 2.5542382167006594

Epoch: 5| Step: 6
Training loss: 1.6377506326375177
Validation loss: 2.5603569691658867

Epoch: 5| Step: 7
Training loss: 1.0051315489120247
Validation loss: 2.5918702893949845

Epoch: 5| Step: 8
Training loss: 1.6895617146957085
Validation loss: 2.5977414683654443

Epoch: 5| Step: 9
Training loss: 1.663473678788815
Validation loss: 2.6158871357166698

Epoch: 5| Step: 10
Training loss: 1.1936355496011362
Validation loss: 2.6086175317890286

Epoch: 5| Step: 11
Training loss: 0.7932843862655282
Validation loss: 2.6402970322911266

Epoch: 397| Step: 0
Training loss: 1.5046270055286097
Validation loss: 2.6465965819648254

Epoch: 5| Step: 1
Training loss: 1.245652171373096
Validation loss: 2.635965351740733

Epoch: 5| Step: 2
Training loss: 1.146578627291254
Validation loss: 2.6047364082161213

Epoch: 5| Step: 3
Training loss: 1.5208419207326138
Validation loss: 2.5866493885568875

Epoch: 5| Step: 4
Training loss: 0.9867895576641251
Validation loss: 2.5497167760352135

Epoch: 5| Step: 5
Training loss: 2.029377352869134
Validation loss: 2.5616639254234137

Epoch: 5| Step: 6
Training loss: 1.3812741273179534
Validation loss: 2.5716574878574145

Epoch: 5| Step: 7
Training loss: 1.361303955914396
Validation loss: 2.5377495838688926

Epoch: 5| Step: 8
Training loss: 1.3069961132701005
Validation loss: 2.5415848962470964

Epoch: 5| Step: 9
Training loss: 1.764289283197256
Validation loss: 2.553908731983123

Epoch: 5| Step: 10
Training loss: 1.369974967769619
Validation loss: 2.5579791468957622

Epoch: 5| Step: 11
Training loss: 1.1500368464828106
Validation loss: 2.5570640436764447

Epoch: 398| Step: 0
Training loss: 1.401833826719808
Validation loss: 2.5855104299280938

Epoch: 5| Step: 1
Training loss: 1.3344641251471043
Validation loss: 2.6071516718500805

Epoch: 5| Step: 2
Training loss: 0.916857139709886
Validation loss: 2.585247452895636

Epoch: 5| Step: 3
Training loss: 1.0178695524984134
Validation loss: 2.5659778881971143

Epoch: 5| Step: 4
Training loss: 1.2542402351490467
Validation loss: 2.5419623614630344

Epoch: 5| Step: 5
Training loss: 1.1410100626589537
Validation loss: 2.565564869723157

Epoch: 5| Step: 6
Training loss: 2.163386160034588
Validation loss: 2.5186146885170158

Epoch: 5| Step: 7
Training loss: 1.239315142857308
Validation loss: 2.582061809718682

Epoch: 5| Step: 8
Training loss: 1.2540620606015518
Validation loss: 2.5932921537886515

Epoch: 5| Step: 9
Training loss: 1.437888880663588
Validation loss: 2.536237829808064

Epoch: 5| Step: 10
Training loss: 1.8913461870239203
Validation loss: 2.551931315714783

Epoch: 5| Step: 11
Training loss: 1.6218526144081493
Validation loss: 2.577301564352687

Epoch: 399| Step: 0
Training loss: 1.300024872321832
Validation loss: 2.5796842503041026

Epoch: 5| Step: 1
Training loss: 1.3237909847034959
Validation loss: 2.6188379919341305

Epoch: 5| Step: 2
Training loss: 1.3561562325545526
Validation loss: 2.6767848376589534

Epoch: 5| Step: 3
Training loss: 1.4506385613908337
Validation loss: 2.649892392387892

Epoch: 5| Step: 4
Training loss: 1.401333500792847
Validation loss: 2.6849085415608154

Epoch: 5| Step: 5
Training loss: 1.0443635678992547
Validation loss: 2.6800484446635493

Epoch: 5| Step: 6
Training loss: 2.103370201021486
Validation loss: 2.6637323795847467

Epoch: 5| Step: 7
Training loss: 1.1254728700985288
Validation loss: 2.6567025640576025

Epoch: 5| Step: 8
Training loss: 1.238586580677537
Validation loss: 2.6170418732016207

Epoch: 5| Step: 9
Training loss: 1.2867326894351345
Validation loss: 2.6324404331905438

Epoch: 5| Step: 10
Training loss: 1.534553467729833
Validation loss: 2.667316816964659

Epoch: 5| Step: 11
Training loss: 1.3466297607904276
Validation loss: 2.629987580254339

Epoch: 400| Step: 0
Training loss: 1.3129908234332957
Validation loss: 2.639547741496193

Epoch: 5| Step: 1
Training loss: 1.2042246165515653
Validation loss: 2.5932581753144825

Epoch: 5| Step: 2
Training loss: 0.6988284977271684
Validation loss: 2.664020892253684

Epoch: 5| Step: 3
Training loss: 1.083721067048976
Validation loss: 2.570456743299464

Epoch: 5| Step: 4
Training loss: 1.2087923800308429
Validation loss: 2.641083453708115

Epoch: 5| Step: 5
Training loss: 1.3102050881333736
Validation loss: 2.6259569701947174

Epoch: 5| Step: 6
Training loss: 1.5285513316311614
Validation loss: 2.58591425828583

Epoch: 5| Step: 7
Training loss: 1.2452029688588062
Validation loss: 2.559847653085302

Epoch: 5| Step: 8
Training loss: 1.6646112960866648
Validation loss: 2.606464777054707

Epoch: 5| Step: 9
Training loss: 1.674317331833916
Validation loss: 2.6202092770054124

Epoch: 5| Step: 10
Training loss: 1.814245173073201
Validation loss: 2.5828425777012467

Epoch: 5| Step: 11
Training loss: 0.9084136390767393
Validation loss: 2.5796648647979654

Epoch: 401| Step: 0
Training loss: 1.1497939008048368
Validation loss: 2.5509314811673236

Epoch: 5| Step: 1
Training loss: 1.182874757042902
Validation loss: 2.5683962240343647

Epoch: 5| Step: 2
Training loss: 1.0665378140069226
Validation loss: 2.558024359092722

Epoch: 5| Step: 3
Training loss: 1.278480187568023
Validation loss: 2.581576662737802

Epoch: 5| Step: 4
Training loss: 1.3892809770064152
Validation loss: 2.591759963875906

Epoch: 5| Step: 5
Training loss: 1.2620842938541768
Validation loss: 2.5738086672879312

Epoch: 5| Step: 6
Training loss: 1.1740743724719218
Validation loss: 2.586203959970798

Epoch: 5| Step: 7
Training loss: 2.1233884647144805
Validation loss: 2.573788345931906

Epoch: 5| Step: 8
Training loss: 0.6954437089198736
Validation loss: 2.576694870219107

Epoch: 5| Step: 9
Training loss: 1.468143662634107
Validation loss: 2.567510049113734

Epoch: 5| Step: 10
Training loss: 1.395745867745447
Validation loss: 2.633751732798958

Epoch: 5| Step: 11
Training loss: 1.0417932179189773
Validation loss: 2.5584371814919398

Epoch: 402| Step: 0
Training loss: 1.2258509619141331
Validation loss: 2.5903225394316847

Epoch: 5| Step: 1
Training loss: 1.1603718053249215
Validation loss: 2.5993844920696914

Epoch: 5| Step: 2
Training loss: 1.5461443321739714
Validation loss: 2.5323678087728383

Epoch: 5| Step: 3
Training loss: 0.8436455132108238
Validation loss: 2.539163984569172

Epoch: 5| Step: 4
Training loss: 1.154233462791301
Validation loss: 2.5898230251213734

Epoch: 5| Step: 5
Training loss: 0.9616931332384595
Validation loss: 2.558345345822027

Epoch: 5| Step: 6
Training loss: 1.6947269395293894
Validation loss: 2.5490842181445763

Epoch: 5| Step: 7
Training loss: 1.5119950389477919
Validation loss: 2.570295977321959

Epoch: 5| Step: 8
Training loss: 1.4808925535388964
Validation loss: 2.5651971880832978

Epoch: 5| Step: 9
Training loss: 1.772358637608248
Validation loss: 2.5783682698774295

Epoch: 5| Step: 10
Training loss: 1.4375648483907977
Validation loss: 2.532761816968491

Epoch: 5| Step: 11
Training loss: 0.8234982346896236
Validation loss: 2.6006055452278733

Epoch: 403| Step: 0
Training loss: 1.7045015144464508
Validation loss: 2.5507274230605437

Epoch: 5| Step: 1
Training loss: 1.3211324278923777
Validation loss: 2.5455668196479126

Epoch: 5| Step: 2
Training loss: 1.0173166711596004
Validation loss: 2.58789619493185

Epoch: 5| Step: 3
Training loss: 1.2229412100222874
Validation loss: 2.5830090355104027

Epoch: 5| Step: 4
Training loss: 1.385139404125588
Validation loss: 2.611578758840057

Epoch: 5| Step: 5
Training loss: 1.6516052471536706
Validation loss: 2.5784473025065853

Epoch: 5| Step: 6
Training loss: 1.2282626281188493
Validation loss: 2.5658214837688877

Epoch: 5| Step: 7
Training loss: 1.020258793724504
Validation loss: 2.5530836221057047

Epoch: 5| Step: 8
Training loss: 1.1291171606174524
Validation loss: 2.565664771666572

Epoch: 5| Step: 9
Training loss: 1.6698611956720473
Validation loss: 2.5429472290003465

Epoch: 5| Step: 10
Training loss: 1.3296947402846633
Validation loss: 2.5363669617244633

Epoch: 5| Step: 11
Training loss: 1.2355468595627173
Validation loss: 2.5741601376766132

Epoch: 404| Step: 0
Training loss: 1.1839698722653405
Validation loss: 2.5891860464328658

Epoch: 5| Step: 1
Training loss: 1.016902061997948
Validation loss: 2.6063286745804115

Epoch: 5| Step: 2
Training loss: 1.7806434937276918
Validation loss: 2.5847672295129414

Epoch: 5| Step: 3
Training loss: 1.6351309929731985
Validation loss: 2.6268890864662944

Epoch: 5| Step: 4
Training loss: 1.035201737466088
Validation loss: 2.612561140455327

Epoch: 5| Step: 5
Training loss: 1.169350205795225
Validation loss: 2.623046808723303

Epoch: 5| Step: 6
Training loss: 0.8437244623346104
Validation loss: 2.60552641210466

Epoch: 5| Step: 7
Training loss: 1.6413921197630725
Validation loss: 2.587239317117238

Epoch: 5| Step: 8
Training loss: 1.081700353602383
Validation loss: 2.5870889364820733

Epoch: 5| Step: 9
Training loss: 1.3767536424651345
Validation loss: 2.5652748838567967

Epoch: 5| Step: 10
Training loss: 1.4787358834245032
Validation loss: 2.600167386309455

Epoch: 5| Step: 11
Training loss: 1.4850222330965748
Validation loss: 2.6379865730122045

Epoch: 405| Step: 0
Training loss: 1.6734900828701076
Validation loss: 2.6129686580135494

Epoch: 5| Step: 1
Training loss: 0.9473385183072549
Validation loss: 2.642147238657931

Epoch: 5| Step: 2
Training loss: 1.233870874143915
Validation loss: 2.6123613012721214

Epoch: 5| Step: 3
Training loss: 1.4091570159082338
Validation loss: 2.6618610769127016

Epoch: 5| Step: 4
Training loss: 1.9268527193665133
Validation loss: 2.6472310269275954

Epoch: 5| Step: 5
Training loss: 0.8598198172974779
Validation loss: 2.576516079026626

Epoch: 5| Step: 6
Training loss: 1.0812193651214406
Validation loss: 2.621069804279765

Epoch: 5| Step: 7
Training loss: 1.4189585864292238
Validation loss: 2.5804473243168053

Epoch: 5| Step: 8
Training loss: 1.20942692213946
Validation loss: 2.586466290516366

Epoch: 5| Step: 9
Training loss: 1.7469543793851499
Validation loss: 2.5840768872013267

Epoch: 5| Step: 10
Training loss: 0.9672463961465348
Validation loss: 2.597387949154728

Epoch: 5| Step: 11
Training loss: 0.6179780846046283
Validation loss: 2.593927507569429

Epoch: 406| Step: 0
Training loss: 1.3522532467498987
Validation loss: 2.5436161465305873

Epoch: 5| Step: 1
Training loss: 0.9887647689893032
Validation loss: 2.556202753123158

Epoch: 5| Step: 2
Training loss: 1.2755425495600765
Validation loss: 2.5720299390965593

Epoch: 5| Step: 3
Training loss: 1.4105788678090887
Validation loss: 2.5797249732558454

Epoch: 5| Step: 4
Training loss: 1.3208693735077393
Validation loss: 2.566762464973152

Epoch: 5| Step: 5
Training loss: 1.2780620643398213
Validation loss: 2.6019724082871734

Epoch: 5| Step: 6
Training loss: 1.6801930930795868
Validation loss: 2.613628134444378

Epoch: 5| Step: 7
Training loss: 1.5591493156578158
Validation loss: 2.5922651636815286

Epoch: 5| Step: 8
Training loss: 1.1542845852838253
Validation loss: 2.609179849236991

Epoch: 5| Step: 9
Training loss: 1.2328704162840427
Validation loss: 2.615395075461923

Epoch: 5| Step: 10
Training loss: 1.3120151259928543
Validation loss: 2.6172516620419493

Epoch: 5| Step: 11
Training loss: 0.6725401136779281
Validation loss: 2.595820921556447

Epoch: 407| Step: 0
Training loss: 1.10622280540015
Validation loss: 2.5642225670777874

Epoch: 5| Step: 1
Training loss: 1.3017455870962171
Validation loss: 2.569826831945557

Epoch: 5| Step: 2
Training loss: 1.4607594427443042
Validation loss: 2.5788868481679423

Epoch: 5| Step: 3
Training loss: 1.1670675724213282
Validation loss: 2.559863890056964

Epoch: 5| Step: 4
Training loss: 1.4466815135270135
Validation loss: 2.553628602897892

Epoch: 5| Step: 5
Training loss: 1.5259165620353634
Validation loss: 2.58088377724573

Epoch: 5| Step: 6
Training loss: 0.8012930002442602
Validation loss: 2.6139305763983254

Epoch: 5| Step: 7
Training loss: 1.5354349208593825
Validation loss: 2.5833585581522134

Epoch: 5| Step: 8
Training loss: 1.5701544383195434
Validation loss: 2.6118499417094503

Epoch: 5| Step: 9
Training loss: 1.2000037987966807
Validation loss: 2.628534525966164

Epoch: 5| Step: 10
Training loss: 1.3221914250841442
Validation loss: 2.610923570268182

Epoch: 5| Step: 11
Training loss: 2.3331157264964584
Validation loss: 2.5869327408646807

Epoch: 408| Step: 0
Training loss: 1.782049501585656
Validation loss: 2.6082148837859083

Epoch: 5| Step: 1
Training loss: 1.2750648444646733
Validation loss: 2.589739207156677

Epoch: 5| Step: 2
Training loss: 1.4705606216755245
Validation loss: 2.5993971075212565

Epoch: 5| Step: 3
Training loss: 1.9192354016978028
Validation loss: 2.597928767620946

Epoch: 5| Step: 4
Training loss: 1.335054786358041
Validation loss: 2.580812113507047

Epoch: 5| Step: 5
Training loss: 1.0941231772173248
Validation loss: 2.6152095513356297

Epoch: 5| Step: 6
Training loss: 1.518162127716508
Validation loss: 2.627634293402723

Epoch: 5| Step: 7
Training loss: 1.4425658650294344
Validation loss: 2.6223545102775265

Epoch: 5| Step: 8
Training loss: 1.0880007456959244
Validation loss: 2.660468857556224

Epoch: 5| Step: 9
Training loss: 1.2368192495741843
Validation loss: 2.690879417719655

Epoch: 5| Step: 10
Training loss: 1.155478864706775
Validation loss: 2.715751968067028

Epoch: 5| Step: 11
Training loss: 1.4120524752432455
Validation loss: 2.7426706813995523

Epoch: 409| Step: 0
Training loss: 1.1942510442124294
Validation loss: 2.702914885805603

Epoch: 5| Step: 1
Training loss: 1.2642885852347006
Validation loss: 2.690837632098347

Epoch: 5| Step: 2
Training loss: 1.4955601948440516
Validation loss: 2.6739171832764352

Epoch: 5| Step: 3
Training loss: 1.1466142883000054
Validation loss: 2.681310371721093

Epoch: 5| Step: 4
Training loss: 1.3657709685295292
Validation loss: 2.664136693523554

Epoch: 5| Step: 5
Training loss: 1.7382321468661561
Validation loss: 2.6553936643834755

Epoch: 5| Step: 6
Training loss: 1.23896140303081
Validation loss: 2.700483453700979

Epoch: 5| Step: 7
Training loss: 1.5231112399788715
Validation loss: 2.684379995516835

Epoch: 5| Step: 8
Training loss: 0.9250558514100632
Validation loss: 2.6584679898823333

Epoch: 5| Step: 9
Training loss: 1.2168739257713714
Validation loss: 2.6463318352650793

Epoch: 5| Step: 10
Training loss: 1.3124887375121326
Validation loss: 2.68695520823007

Epoch: 5| Step: 11
Training loss: 0.6598708760500663
Validation loss: 2.66676867309815

Epoch: 410| Step: 0
Training loss: 1.0369080313950674
Validation loss: 2.666203925594139

Epoch: 5| Step: 1
Training loss: 1.55231497996624
Validation loss: 2.679817478301079

Epoch: 5| Step: 2
Training loss: 0.9907483454307122
Validation loss: 2.687382506973766

Epoch: 5| Step: 3
Training loss: 1.4837827605284017
Validation loss: 2.731941997207203

Epoch: 5| Step: 4
Training loss: 1.2092110909666618
Validation loss: 2.674382100608096

Epoch: 5| Step: 5
Training loss: 1.600198751264537
Validation loss: 2.627130200398824

Epoch: 5| Step: 6
Training loss: 1.1194907501199762
Validation loss: 2.6557160270881077

Epoch: 5| Step: 7
Training loss: 1.211499582092994
Validation loss: 2.621653243649122

Epoch: 5| Step: 8
Training loss: 1.3096433614885683
Validation loss: 2.6763205066084037

Epoch: 5| Step: 9
Training loss: 1.3009928396615824
Validation loss: 2.632758157925809

Epoch: 5| Step: 10
Training loss: 1.0049181636304931
Validation loss: 2.6159299913440712

Epoch: 5| Step: 11
Training loss: 2.517075683080318
Validation loss: 2.6384330884297253

Epoch: 411| Step: 0
Training loss: 1.2807666983527624
Validation loss: 2.612923157110615

Epoch: 5| Step: 1
Training loss: 1.702888052320158
Validation loss: 2.6411916926023538

Epoch: 5| Step: 2
Training loss: 0.9624205519348706
Validation loss: 2.6650354448953006

Epoch: 5| Step: 3
Training loss: 1.2021545360419792
Validation loss: 2.6332699220804865

Epoch: 5| Step: 4
Training loss: 1.7249501843100978
Validation loss: 2.6617146920338475

Epoch: 5| Step: 5
Training loss: 1.1150296586201915
Validation loss: 2.6630217084330488

Epoch: 5| Step: 6
Training loss: 1.5683421208820907
Validation loss: 2.6136024821262835

Epoch: 5| Step: 7
Training loss: 1.067057372351739
Validation loss: 2.619246948875647

Epoch: 5| Step: 8
Training loss: 1.1046185678344644
Validation loss: 2.569989440156589

Epoch: 5| Step: 9
Training loss: 1.1826656719068827
Validation loss: 2.557079964218502

Epoch: 5| Step: 10
Training loss: 1.1040061738076559
Validation loss: 2.57156879368187

Epoch: 5| Step: 11
Training loss: 0.7288031943718115
Validation loss: 2.5681517851933497

Epoch: 412| Step: 0
Training loss: 1.177783870131452
Validation loss: 2.565271555413924

Epoch: 5| Step: 1
Training loss: 1.0073552831833028
Validation loss: 2.562977544745464

Epoch: 5| Step: 2
Training loss: 1.107983966250037
Validation loss: 2.563428373337984

Epoch: 5| Step: 3
Training loss: 1.3111693585293305
Validation loss: 2.5446580353382204

Epoch: 5| Step: 4
Training loss: 1.4690780273343989
Validation loss: 2.6021815795818872

Epoch: 5| Step: 5
Training loss: 1.6479817705118376
Validation loss: 2.595940572585977

Epoch: 5| Step: 6
Training loss: 1.1503443036687027
Validation loss: 2.6233737275137217

Epoch: 5| Step: 7
Training loss: 1.4163344030994933
Validation loss: 2.664907379270513

Epoch: 5| Step: 8
Training loss: 1.2398109013437082
Validation loss: 2.62795061840018

Epoch: 5| Step: 9
Training loss: 1.051110425249467
Validation loss: 2.638978275380222

Epoch: 5| Step: 10
Training loss: 1.3152100876054686
Validation loss: 2.6705335480559342

Epoch: 5| Step: 11
Training loss: 2.401850158102357
Validation loss: 2.643211550097962

Epoch: 413| Step: 0
Training loss: 1.0816934657389434
Validation loss: 2.6246701934046457

Epoch: 5| Step: 1
Training loss: 0.8204440420132147
Validation loss: 2.5910379601392997

Epoch: 5| Step: 2
Training loss: 1.188631672951885
Validation loss: 2.629955870091317

Epoch: 5| Step: 3
Training loss: 1.1010397353767387
Validation loss: 2.593665129257336

Epoch: 5| Step: 4
Training loss: 1.1416497004192692
Validation loss: 2.611088188445024

Epoch: 5| Step: 5
Training loss: 1.509675767205867
Validation loss: 2.5884133939730845

Epoch: 5| Step: 6
Training loss: 1.5034424698342528
Validation loss: 2.622249645917708

Epoch: 5| Step: 7
Training loss: 1.2289859617345615
Validation loss: 2.614814019886602

Epoch: 5| Step: 8
Training loss: 0.8786181507524731
Validation loss: 2.622757025312726

Epoch: 5| Step: 9
Training loss: 1.2404523042260647
Validation loss: 2.6421974924877247

Epoch: 5| Step: 10
Training loss: 1.5802425115112484
Validation loss: 2.627105515608487

Epoch: 5| Step: 11
Training loss: 2.245366093069622
Validation loss: 2.5878892718617483

Epoch: 414| Step: 0
Training loss: 1.1573029440608755
Validation loss: 2.5991274422546478

Epoch: 5| Step: 1
Training loss: 1.2276127686143203
Validation loss: 2.5872970111362816

Epoch: 5| Step: 2
Training loss: 1.5105284901583544
Validation loss: 2.568158426872613

Epoch: 5| Step: 3
Training loss: 0.9996051008603426
Validation loss: 2.6360593710695515

Epoch: 5| Step: 4
Training loss: 1.2775226432749442
Validation loss: 2.6211650400941573

Epoch: 5| Step: 5
Training loss: 1.7131746898237736
Validation loss: 2.624308491253451

Epoch: 5| Step: 6
Training loss: 1.2311025773298516
Validation loss: 2.6280338602671685

Epoch: 5| Step: 7
Training loss: 1.3558666513698894
Validation loss: 2.610613131354217

Epoch: 5| Step: 8
Training loss: 0.8914551797555332
Validation loss: 2.6161066774727346

Epoch: 5| Step: 9
Training loss: 1.0704945875776677
Validation loss: 2.6369663225906304

Epoch: 5| Step: 10
Training loss: 1.1758062417045212
Validation loss: 2.6324360518916485

Epoch: 5| Step: 11
Training loss: 1.235974494775863
Validation loss: 2.6138884898973793

Epoch: 415| Step: 0
Training loss: 1.0445522902544446
Validation loss: 2.6049466694310826

Epoch: 5| Step: 1
Training loss: 1.4390842166881503
Validation loss: 2.6033789791297113

Epoch: 5| Step: 2
Training loss: 1.2334685075417573
Validation loss: 2.6222454464827085

Epoch: 5| Step: 3
Training loss: 1.2528045663180387
Validation loss: 2.66194040718937

Epoch: 5| Step: 4
Training loss: 1.434173965494637
Validation loss: 2.629835602187478

Epoch: 5| Step: 5
Training loss: 1.2452695985150524
Validation loss: 2.5915915842209407

Epoch: 5| Step: 6
Training loss: 1.6681225457857671
Validation loss: 2.678310277636253

Epoch: 5| Step: 7
Training loss: 1.3446448695370925
Validation loss: 2.636953984822881

Epoch: 5| Step: 8
Training loss: 1.015786730286925
Validation loss: 2.716381217629824

Epoch: 5| Step: 9
Training loss: 0.7907737079434816
Validation loss: 2.687578961594846

Epoch: 5| Step: 10
Training loss: 1.1437236553555874
Validation loss: 2.674008255866399

Epoch: 5| Step: 11
Training loss: 1.2367124999533616
Validation loss: 2.6623360417705166

Epoch: 416| Step: 0
Training loss: 1.0807284006629283
Validation loss: 2.598277353783188

Epoch: 5| Step: 1
Training loss: 0.9173392227209279
Validation loss: 2.5705027060584453

Epoch: 5| Step: 2
Training loss: 1.1854570785275729
Validation loss: 2.568258235666057

Epoch: 5| Step: 3
Training loss: 1.299330627065404
Validation loss: 2.587656097341467

Epoch: 5| Step: 4
Training loss: 1.539987663615964
Validation loss: 2.594636436259178

Epoch: 5| Step: 5
Training loss: 1.3086074600640245
Validation loss: 2.570157458992902

Epoch: 5| Step: 6
Training loss: 1.0587127731245962
Validation loss: 2.5850421742393643

Epoch: 5| Step: 7
Training loss: 1.3245941800208074
Validation loss: 2.5855721737133552

Epoch: 5| Step: 8
Training loss: 1.4053250131692527
Validation loss: 2.627745511450225

Epoch: 5| Step: 9
Training loss: 1.2053160100306703
Validation loss: 2.699414225454721

Epoch: 5| Step: 10
Training loss: 1.7834765923378053
Validation loss: 2.712024470806138

Epoch: 5| Step: 11
Training loss: 1.121740068487348
Validation loss: 2.7765210449295457

Epoch: 417| Step: 0
Training loss: 1.6263030769664781
Validation loss: 2.704522332155038

Epoch: 5| Step: 1
Training loss: 1.3752772745251252
Validation loss: 2.6503435101183173

Epoch: 5| Step: 2
Training loss: 1.1316875791700813
Validation loss: 2.5937732749109164

Epoch: 5| Step: 3
Training loss: 1.1580935550214897
Validation loss: 2.6220550707155645

Epoch: 5| Step: 4
Training loss: 1.255531612358304
Validation loss: 2.6177826959016066

Epoch: 5| Step: 5
Training loss: 1.4116116777104022
Validation loss: 2.607832580300152

Epoch: 5| Step: 6
Training loss: 1.4215266880531692
Validation loss: 2.601094055768504

Epoch: 5| Step: 7
Training loss: 1.2028811319086483
Validation loss: 2.5739257908215993

Epoch: 5| Step: 8
Training loss: 0.8762750531695059
Validation loss: 2.5738534663374124

Epoch: 5| Step: 9
Training loss: 1.8529802519954923
Validation loss: 2.6152698000692074

Epoch: 5| Step: 10
Training loss: 1.351597868175468
Validation loss: 2.7105692999103144

Epoch: 5| Step: 11
Training loss: 1.5059568222715631
Validation loss: 2.7218550091902447

Epoch: 418| Step: 0
Training loss: 1.6711023274291175
Validation loss: 2.7976393623058953

Epoch: 5| Step: 1
Training loss: 1.241787924168797
Validation loss: 2.819931645624584

Epoch: 5| Step: 2
Training loss: 1.5364287637569969
Validation loss: 2.7113051188136392

Epoch: 5| Step: 3
Training loss: 1.4996469400067574
Validation loss: 2.69124239389101

Epoch: 5| Step: 4
Training loss: 1.1824963710317917
Validation loss: 2.661027004926582

Epoch: 5| Step: 5
Training loss: 1.261095253153361
Validation loss: 2.6812698356114044

Epoch: 5| Step: 6
Training loss: 0.9529083506014606
Validation loss: 2.63543074055006

Epoch: 5| Step: 7
Training loss: 1.1187420146806333
Validation loss: 2.6561238352414436

Epoch: 5| Step: 8
Training loss: 1.6750317300097055
Validation loss: 2.679077368138468

Epoch: 5| Step: 9
Training loss: 0.8487920227659257
Validation loss: 2.6384988912093683

Epoch: 5| Step: 10
Training loss: 0.9770322966650087
Validation loss: 2.6271020896679693

Epoch: 5| Step: 11
Training loss: 1.4453303155574286
Validation loss: 2.660542867520565

Epoch: 419| Step: 0
Training loss: 0.9318734763713127
Validation loss: 2.6242809294723184

Epoch: 5| Step: 1
Training loss: 1.4620177818918179
Validation loss: 2.6850784873560736

Epoch: 5| Step: 2
Training loss: 1.3551173565426176
Validation loss: 2.6527893298886758

Epoch: 5| Step: 3
Training loss: 1.068998602346108
Validation loss: 2.66370382719152

Epoch: 5| Step: 4
Training loss: 1.280491534641917
Validation loss: 2.6412329039868143

Epoch: 5| Step: 5
Training loss: 1.705444366518424
Validation loss: 2.6774163923379666

Epoch: 5| Step: 6
Training loss: 1.0876317700761837
Validation loss: 2.627387686596579

Epoch: 5| Step: 7
Training loss: 0.7677032912221176
Validation loss: 2.5823655905124756

Epoch: 5| Step: 8
Training loss: 1.4048194390476998
Validation loss: 2.5682908661846766

Epoch: 5| Step: 9
Training loss: 1.1215322879560161
Validation loss: 2.570825825056326

Epoch: 5| Step: 10
Training loss: 1.124538909941145
Validation loss: 2.5408209516745512

Epoch: 5| Step: 11
Training loss: 1.1808238840274707
Validation loss: 2.5863504339401664

Epoch: 420| Step: 0
Training loss: 1.296809091386926
Validation loss: 2.560845018958721

Epoch: 5| Step: 1
Training loss: 1.5627313824040314
Validation loss: 2.571137853286868

Epoch: 5| Step: 2
Training loss: 1.2873377966323543
Validation loss: 2.605095477724933

Epoch: 5| Step: 3
Training loss: 1.3108633827472407
Validation loss: 2.6218474508299936

Epoch: 5| Step: 4
Training loss: 1.0071500034909697
Validation loss: 2.657845492927228

Epoch: 5| Step: 5
Training loss: 1.5829557755028647
Validation loss: 2.6714705668646292

Epoch: 5| Step: 6
Training loss: 0.992631137217404
Validation loss: 2.6571760246408607

Epoch: 5| Step: 7
Training loss: 1.2522794444041379
Validation loss: 2.6179100709275827

Epoch: 5| Step: 8
Training loss: 0.7276410127420148
Validation loss: 2.6231658105687847

Epoch: 5| Step: 9
Training loss: 0.9116636571770556
Validation loss: 2.669118355218446

Epoch: 5| Step: 10
Training loss: 1.015817242547875
Validation loss: 2.611796966364381

Epoch: 5| Step: 11
Training loss: 1.5050555704952993
Validation loss: 2.6776108809508576

Epoch: 421| Step: 0
Training loss: 1.119746285635291
Validation loss: 2.6408459159039324

Epoch: 5| Step: 1
Training loss: 1.6296488946601178
Validation loss: 2.6276783260066785

Epoch: 5| Step: 2
Training loss: 0.9251122612748134
Validation loss: 2.62421127610516

Epoch: 5| Step: 3
Training loss: 1.2640972099678387
Validation loss: 2.6894985980970896

Epoch: 5| Step: 4
Training loss: 0.9716200000315786
Validation loss: 2.690968795828877

Epoch: 5| Step: 5
Training loss: 1.1353405859885977
Validation loss: 2.7368624172602383

Epoch: 5| Step: 6
Training loss: 1.1449877248547489
Validation loss: 2.66137080163714

Epoch: 5| Step: 7
Training loss: 0.8864193381411238
Validation loss: 2.6960871776440642

Epoch: 5| Step: 8
Training loss: 1.4193483477315398
Validation loss: 2.6078590969450484

Epoch: 5| Step: 9
Training loss: 1.458202310761685
Validation loss: 2.6251773433724503

Epoch: 5| Step: 10
Training loss: 1.1825237914549003
Validation loss: 2.6335264307661763

Epoch: 5| Step: 11
Training loss: 1.4092480807451189
Validation loss: 2.605733584432589

Epoch: 422| Step: 0
Training loss: 1.1490874235527788
Validation loss: 2.6148297103871165

Epoch: 5| Step: 1
Training loss: 1.577276398277458
Validation loss: 2.6185643308578666

Epoch: 5| Step: 2
Training loss: 1.1690702825683372
Validation loss: 2.595234691104973

Epoch: 5| Step: 3
Training loss: 1.038978802744693
Validation loss: 2.580799953799938

Epoch: 5| Step: 4
Training loss: 1.3743534301897087
Validation loss: 2.6581295207846467

Epoch: 5| Step: 5
Training loss: 0.9200600684292995
Validation loss: 2.614512075286515

Epoch: 5| Step: 6
Training loss: 1.4592003107177254
Validation loss: 2.6214860678436023

Epoch: 5| Step: 7
Training loss: 1.104748494623958
Validation loss: 2.641689905932841

Epoch: 5| Step: 8
Training loss: 1.2001111316878883
Validation loss: 2.654033431676972

Epoch: 5| Step: 9
Training loss: 0.9724637495997388
Validation loss: 2.678734864895148

Epoch: 5| Step: 10
Training loss: 0.9951875641170022
Validation loss: 2.6626060696041107

Epoch: 5| Step: 11
Training loss: 1.027748753306812
Validation loss: 2.6698611256502525

Epoch: 423| Step: 0
Training loss: 1.0837156770368304
Validation loss: 2.6871917496081363

Epoch: 5| Step: 1
Training loss: 1.259580897308797
Validation loss: 2.6255314531182776

Epoch: 5| Step: 2
Training loss: 0.9004779036912363
Validation loss: 2.6594945763414732

Epoch: 5| Step: 3
Training loss: 1.0993338692037071
Validation loss: 2.636566312174588

Epoch: 5| Step: 4
Training loss: 0.8651182901943223
Validation loss: 2.6369963210199217

Epoch: 5| Step: 5
Training loss: 1.3532139385498945
Validation loss: 2.625546451487259

Epoch: 5| Step: 6
Training loss: 1.3906291147235472
Validation loss: 2.6312882702265057

Epoch: 5| Step: 7
Training loss: 1.5180258857470033
Validation loss: 2.6161111734564915

Epoch: 5| Step: 8
Training loss: 1.1740961006967294
Validation loss: 2.658562726753313

Epoch: 5| Step: 9
Training loss: 1.0525069690029634
Validation loss: 2.6330246995483835

Epoch: 5| Step: 10
Training loss: 1.1734154304227151
Validation loss: 2.6214959659849746

Epoch: 5| Step: 11
Training loss: 1.4339925019136026
Validation loss: 2.651846835855719

Epoch: 424| Step: 0
Training loss: 1.1093132109291841
Validation loss: 2.656774398052489

Epoch: 5| Step: 1
Training loss: 0.8625593317052587
Validation loss: 2.671062442595695

Epoch: 5| Step: 2
Training loss: 1.1081785815818486
Validation loss: 2.6972027954768683

Epoch: 5| Step: 3
Training loss: 1.2249532457109766
Validation loss: 2.6730644634671044

Epoch: 5| Step: 4
Training loss: 1.1953919826834183
Validation loss: 2.663025634664804

Epoch: 5| Step: 5
Training loss: 1.1093768804829738
Validation loss: 2.6514693341796667

Epoch: 5| Step: 6
Training loss: 1.6103665158587874
Validation loss: 2.6351429428969433

Epoch: 5| Step: 7
Training loss: 1.3967617373023686
Validation loss: 2.620214444598413

Epoch: 5| Step: 8
Training loss: 1.2950879388945813
Validation loss: 2.619212666126918

Epoch: 5| Step: 9
Training loss: 0.958383935476959
Validation loss: 2.647125181574564

Epoch: 5| Step: 10
Training loss: 1.4459835659691913
Validation loss: 2.6493484145853383

Epoch: 5| Step: 11
Training loss: 1.2620480701099743
Validation loss: 2.6704667155654405

Epoch: 425| Step: 0
Training loss: 0.9438712743181191
Validation loss: 2.686713243992621

Epoch: 5| Step: 1
Training loss: 1.1542449784594113
Validation loss: 2.740922971394184

Epoch: 5| Step: 2
Training loss: 1.1318400977834184
Validation loss: 2.7192146591135002

Epoch: 5| Step: 3
Training loss: 1.2625501037324478
Validation loss: 2.6888213642651366

Epoch: 5| Step: 4
Training loss: 1.1586524644971903
Validation loss: 2.683058769136693

Epoch: 5| Step: 5
Training loss: 1.4714277490991843
Validation loss: 2.658831419117333

Epoch: 5| Step: 6
Training loss: 1.1125306393122432
Validation loss: 2.6070610415827775

Epoch: 5| Step: 7
Training loss: 0.9413783279013653
Validation loss: 2.6379861267658717

Epoch: 5| Step: 8
Training loss: 1.5754335321456707
Validation loss: 2.648242125530042

Epoch: 5| Step: 9
Training loss: 1.255527197302836
Validation loss: 2.6145695550461814

Epoch: 5| Step: 10
Training loss: 1.1596769119720944
Validation loss: 2.6185433097549113

Epoch: 5| Step: 11
Training loss: 1.2828982381476888
Validation loss: 2.613504914356917

Epoch: 426| Step: 0
Training loss: 1.6742743272408098
Validation loss: 2.549823470176147

Epoch: 5| Step: 1
Training loss: 1.3898619369166043
Validation loss: 2.5994548183231534

Epoch: 5| Step: 2
Training loss: 0.9346592780073769
Validation loss: 2.5661841712061135

Epoch: 5| Step: 3
Training loss: 1.06867270608442
Validation loss: 2.645563856554268

Epoch: 5| Step: 4
Training loss: 1.4401047369166573
Validation loss: 2.62400541499292

Epoch: 5| Step: 5
Training loss: 0.9690314468579927
Validation loss: 2.5923626532999813

Epoch: 5| Step: 6
Training loss: 0.9379145341563939
Validation loss: 2.654585507540236

Epoch: 5| Step: 7
Training loss: 1.1417957202802438
Validation loss: 2.6714062902391023

Epoch: 5| Step: 8
Training loss: 1.494420801958135
Validation loss: 2.5913557545853507

Epoch: 5| Step: 9
Training loss: 0.7231034828090555
Validation loss: 2.654600311817373

Epoch: 5| Step: 10
Training loss: 0.9649528719704678
Validation loss: 2.6169610300341475

Epoch: 5| Step: 11
Training loss: 1.4700295576380735
Validation loss: 2.6269342357991596

Epoch: 427| Step: 0
Training loss: 1.067575393712346
Validation loss: 2.6109606213918455

Epoch: 5| Step: 1
Training loss: 1.5344587687760562
Validation loss: 2.6097214063402108

Epoch: 5| Step: 2
Training loss: 0.8944504880470617
Validation loss: 2.624579418639914

Epoch: 5| Step: 3
Training loss: 1.0513638154240985
Validation loss: 2.6030013121810325

Epoch: 5| Step: 4
Training loss: 1.4117342502099828
Validation loss: 2.7061992355648194

Epoch: 5| Step: 5
Training loss: 1.0582140702659888
Validation loss: 2.6477982228698327

Epoch: 5| Step: 6
Training loss: 1.0156506461793513
Validation loss: 2.6241792273642277

Epoch: 5| Step: 7
Training loss: 1.452048446404026
Validation loss: 2.6468904716222674

Epoch: 5| Step: 8
Training loss: 1.1803699060710084
Validation loss: 2.5885006743369976

Epoch: 5| Step: 9
Training loss: 0.9862366586708692
Validation loss: 2.608769097099113

Epoch: 5| Step: 10
Training loss: 0.8857715942480989
Validation loss: 2.5771303435231663

Epoch: 5| Step: 11
Training loss: 1.5265012012305783
Validation loss: 2.5795026142603517

Epoch: 428| Step: 0
Training loss: 1.0002499506425262
Validation loss: 2.6005881645297193

Epoch: 5| Step: 1
Training loss: 1.0777414164740011
Validation loss: 2.5658115508868895

Epoch: 5| Step: 2
Training loss: 1.0789090498349974
Validation loss: 2.626273977608082

Epoch: 5| Step: 3
Training loss: 0.8979703932853811
Validation loss: 2.5654343691036403

Epoch: 5| Step: 4
Training loss: 1.0424541675546346
Validation loss: 2.5924081663606104

Epoch: 5| Step: 5
Training loss: 1.1312770566286448
Validation loss: 2.6187778670194666

Epoch: 5| Step: 6
Training loss: 0.9659654529467506
Validation loss: 2.6407512807653064

Epoch: 5| Step: 7
Training loss: 1.7307231363043554
Validation loss: 2.613784973376365

Epoch: 5| Step: 8
Training loss: 1.0847572114787827
Validation loss: 2.618754131523278

Epoch: 5| Step: 9
Training loss: 1.5069365650133124
Validation loss: 2.596837660991194

Epoch: 5| Step: 10
Training loss: 0.980747077009876
Validation loss: 2.622705150925234

Epoch: 5| Step: 11
Training loss: 0.5205490067375511
Validation loss: 2.59989006730124

Epoch: 429| Step: 0
Training loss: 1.1112116801259788
Validation loss: 2.585176701722761

Epoch: 5| Step: 1
Training loss: 1.3731956347085277
Validation loss: 2.6243989612102947

Epoch: 5| Step: 2
Training loss: 1.5312797387796968
Validation loss: 2.665209518615639

Epoch: 5| Step: 3
Training loss: 0.8402725899135991
Validation loss: 2.6106293170519734

Epoch: 5| Step: 4
Training loss: 0.9734559965136778
Validation loss: 2.6404624828761842

Epoch: 5| Step: 5
Training loss: 1.4607019081484025
Validation loss: 2.616172160864765

Epoch: 5| Step: 6
Training loss: 1.0835066558886948
Validation loss: 2.6718610908190876

Epoch: 5| Step: 7
Training loss: 0.9605260448826722
Validation loss: 2.608477695164988

Epoch: 5| Step: 8
Training loss: 1.0976198672309387
Validation loss: 2.6436027275411154

Epoch: 5| Step: 9
Training loss: 1.0227963718036663
Validation loss: 2.6580725419864044

Epoch: 5| Step: 10
Training loss: 1.2260751424198781
Validation loss: 2.6496026580948864

Epoch: 5| Step: 11
Training loss: 0.7244224204339527
Validation loss: 2.695136782313267

Epoch: 430| Step: 0
Training loss: 1.0381331338856614
Validation loss: 2.6635192399217735

Epoch: 5| Step: 1
Training loss: 0.8483985428270184
Validation loss: 2.684438573390163

Epoch: 5| Step: 2
Training loss: 0.8378244298294026
Validation loss: 2.648046807923452

Epoch: 5| Step: 3
Training loss: 1.2144482818340074
Validation loss: 2.662810466765432

Epoch: 5| Step: 4
Training loss: 0.7640797338121837
Validation loss: 2.613971700723592

Epoch: 5| Step: 5
Training loss: 1.1319785896305181
Validation loss: 2.653281404268231

Epoch: 5| Step: 6
Training loss: 1.203625760584393
Validation loss: 2.6503419433560724

Epoch: 5| Step: 7
Training loss: 1.3647532563541918
Validation loss: 2.616498220594139

Epoch: 5| Step: 8
Training loss: 1.3660022938933876
Validation loss: 2.6003644110919057

Epoch: 5| Step: 9
Training loss: 1.06282963968582
Validation loss: 2.610480563535328

Epoch: 5| Step: 10
Training loss: 1.617934418465546
Validation loss: 2.6274719331030507

Epoch: 5| Step: 11
Training loss: 1.0964873800042876
Validation loss: 2.659816852863764

Epoch: 431| Step: 0
Training loss: 1.0339720664392418
Validation loss: 2.60650764277416

Epoch: 5| Step: 1
Training loss: 0.6933504775645014
Validation loss: 2.637556629567316

Epoch: 5| Step: 2
Training loss: 1.2168832322730245
Validation loss: 2.6417349640073087

Epoch: 5| Step: 3
Training loss: 1.0920067109541034
Validation loss: 2.618660480999471

Epoch: 5| Step: 4
Training loss: 0.7438037740677809
Validation loss: 2.623731052893054

Epoch: 5| Step: 5
Training loss: 1.1935762748332883
Validation loss: 2.59363357635016

Epoch: 5| Step: 6
Training loss: 1.0150905083014223
Validation loss: 2.608808882438278

Epoch: 5| Step: 7
Training loss: 0.8956976869187636
Validation loss: 2.642796517027185

Epoch: 5| Step: 8
Training loss: 0.8181603310272951
Validation loss: 2.6144310664993244

Epoch: 5| Step: 9
Training loss: 1.5795136187172483
Validation loss: 2.665918332142312

Epoch: 5| Step: 10
Training loss: 1.5750391788756515
Validation loss: 2.6957643913305414

Epoch: 5| Step: 11
Training loss: 0.9545942769837914
Validation loss: 2.670788291133772

Epoch: 432| Step: 0
Training loss: 1.0789470579259521
Validation loss: 2.6626879631699722

Epoch: 5| Step: 1
Training loss: 0.88155450903169
Validation loss: 2.633448138229281

Epoch: 5| Step: 2
Training loss: 1.3821305139581195
Validation loss: 2.6090377734376395

Epoch: 5| Step: 3
Training loss: 1.394643057820899
Validation loss: 2.6353683291338466

Epoch: 5| Step: 4
Training loss: 0.5759476047401485
Validation loss: 2.631508376875585

Epoch: 5| Step: 5
Training loss: 1.4281401051196183
Validation loss: 2.642801044663767

Epoch: 5| Step: 6
Training loss: 1.192297080267259
Validation loss: 2.64140541913827

Epoch: 5| Step: 7
Training loss: 1.0094653629446557
Validation loss: 2.6212446431796654

Epoch: 5| Step: 8
Training loss: 1.2113218620406558
Validation loss: 2.654084613276286

Epoch: 5| Step: 9
Training loss: 1.0470513721895542
Validation loss: 2.6198636582925343

Epoch: 5| Step: 10
Training loss: 0.9600162587179806
Validation loss: 2.6704722657836273

Epoch: 5| Step: 11
Training loss: 0.9230937982966825
Validation loss: 2.631484778856773

Epoch: 433| Step: 0
Training loss: 0.9268437336685321
Validation loss: 2.7201958900274765

Epoch: 5| Step: 1
Training loss: 1.0350426953488772
Validation loss: 2.7018960794248232

Epoch: 5| Step: 2
Training loss: 1.0264081865101637
Validation loss: 2.6869306293877178

Epoch: 5| Step: 3
Training loss: 1.1642069374952517
Validation loss: 2.71912479009677

Epoch: 5| Step: 4
Training loss: 0.9484065156051574
Validation loss: 2.688356348119731

Epoch: 5| Step: 5
Training loss: 1.7708049173506126
Validation loss: 2.7316257170373075

Epoch: 5| Step: 6
Training loss: 0.9577532788835169
Validation loss: 2.68884469922941

Epoch: 5| Step: 7
Training loss: 1.1232078370553125
Validation loss: 2.6360236600984766

Epoch: 5| Step: 8
Training loss: 0.8947471791148585
Validation loss: 2.703277598283526

Epoch: 5| Step: 9
Training loss: 1.050735302455869
Validation loss: 2.643040953200653

Epoch: 5| Step: 10
Training loss: 1.4692177534967175
Validation loss: 2.625021665725913

Epoch: 5| Step: 11
Training loss: 0.9978743850149893
Validation loss: 2.616251767779569

Epoch: 434| Step: 0
Training loss: 1.0251892473386983
Validation loss: 2.6336330338841885

Epoch: 5| Step: 1
Training loss: 1.0488343194249399
Validation loss: 2.641234859790848

Epoch: 5| Step: 2
Training loss: 0.755580959251407
Validation loss: 2.5840594875945384

Epoch: 5| Step: 3
Training loss: 0.7741720776391067
Validation loss: 2.6607176626610105

Epoch: 5| Step: 4
Training loss: 1.0594547613044223
Validation loss: 2.625668387620178

Epoch: 5| Step: 5
Training loss: 1.1278225670352267
Validation loss: 2.658600425506321

Epoch: 5| Step: 6
Training loss: 0.9422714879193792
Validation loss: 2.6633652700396047

Epoch: 5| Step: 7
Training loss: 1.6316412416346917
Validation loss: 2.65431168088697

Epoch: 5| Step: 8
Training loss: 1.6636559074730113
Validation loss: 2.631923344280666

Epoch: 5| Step: 9
Training loss: 1.1614016645944791
Validation loss: 2.6489834480630163

Epoch: 5| Step: 10
Training loss: 1.0229242799764349
Validation loss: 2.6868709892674265

Epoch: 5| Step: 11
Training loss: 0.7026457530826639
Validation loss: 2.633977041960787

Epoch: 435| Step: 0
Training loss: 1.0029235661365345
Validation loss: 2.600598111651187

Epoch: 5| Step: 1
Training loss: 0.9322542932503075
Validation loss: 2.577287372189499

Epoch: 5| Step: 2
Training loss: 1.3041231682361516
Validation loss: 2.649022216916597

Epoch: 5| Step: 3
Training loss: 1.128477761018642
Validation loss: 2.610270706220313

Epoch: 5| Step: 4
Training loss: 0.818844089488915
Validation loss: 2.574900192036269

Epoch: 5| Step: 5
Training loss: 0.8538010248823665
Validation loss: 2.63964885147624

Epoch: 5| Step: 6
Training loss: 1.184051727221753
Validation loss: 2.626511070750993

Epoch: 5| Step: 7
Training loss: 1.3867530496143226
Validation loss: 2.6178404909152113

Epoch: 5| Step: 8
Training loss: 0.960497747765144
Validation loss: 2.6502246059744494

Epoch: 5| Step: 9
Training loss: 1.1392952993769587
Validation loss: 2.6249100295043406

Epoch: 5| Step: 10
Training loss: 1.0795493737291078
Validation loss: 2.6507155374554934

Epoch: 5| Step: 11
Training loss: 0.9630453360730858
Validation loss: 2.6684295606347996

Epoch: 436| Step: 0
Training loss: 1.0530029407253665
Validation loss: 2.7088064783014905

Epoch: 5| Step: 1
Training loss: 1.3127160121634813
Validation loss: 2.7059965224928595

Epoch: 5| Step: 2
Training loss: 0.9352021030029558
Validation loss: 2.6890283903462957

Epoch: 5| Step: 3
Training loss: 1.207156474213208
Validation loss: 2.714315965976555

Epoch: 5| Step: 4
Training loss: 1.0970373614963718
Validation loss: 2.7232697688189793

Epoch: 5| Step: 5
Training loss: 0.7176233666724824
Validation loss: 2.6783061123192438

Epoch: 5| Step: 6
Training loss: 1.1023616191840466
Validation loss: 2.67784364766266

Epoch: 5| Step: 7
Training loss: 1.4726835293861407
Validation loss: 2.683594827221428

Epoch: 5| Step: 8
Training loss: 0.7684459100350706
Validation loss: 2.665347921856398

Epoch: 5| Step: 9
Training loss: 1.2706385082722087
Validation loss: 2.663423687218257

Epoch: 5| Step: 10
Training loss: 0.8331319486152273
Validation loss: 2.6252651913217306

Epoch: 5| Step: 11
Training loss: 0.7198506925002595
Validation loss: 2.5794671042872928

Epoch: 437| Step: 0
Training loss: 1.0491962035619102
Validation loss: 2.678342594786676

Epoch: 5| Step: 1
Training loss: 1.1621956416575976
Validation loss: 2.655182171275294

Epoch: 5| Step: 2
Training loss: 1.0915128444207711
Validation loss: 2.6227052209982977

Epoch: 5| Step: 3
Training loss: 0.6477017652395959
Validation loss: 2.664619007324146

Epoch: 5| Step: 4
Training loss: 1.0232341069213529
Validation loss: 2.677551266980524

Epoch: 5| Step: 5
Training loss: 1.0421518848744942
Validation loss: 2.7192115428466423

Epoch: 5| Step: 6
Training loss: 0.8826230951539055
Validation loss: 2.7051143418881773

Epoch: 5| Step: 7
Training loss: 1.2735850242865272
Validation loss: 2.729760572492245

Epoch: 5| Step: 8
Training loss: 1.3060290811435025
Validation loss: 2.7366889644900017

Epoch: 5| Step: 9
Training loss: 1.3534780609951362
Validation loss: 2.691249892699456

Epoch: 5| Step: 10
Training loss: 1.123020443812609
Validation loss: 2.714090377234004

Epoch: 5| Step: 11
Training loss: 0.9367687234282482
Validation loss: 2.6536252685788244

Epoch: 438| Step: 0
Training loss: 1.15757067750887
Validation loss: 2.647623501557578

Epoch: 5| Step: 1
Training loss: 1.491744929485804
Validation loss: 2.67187977394436

Epoch: 5| Step: 2
Training loss: 1.1699925880523399
Validation loss: 2.650807470882843

Epoch: 5| Step: 3
Training loss: 0.8381030829264254
Validation loss: 2.6270470584681207

Epoch: 5| Step: 4
Training loss: 1.1319512085559742
Validation loss: 2.643691045435947

Epoch: 5| Step: 5
Training loss: 1.1400669770893972
Validation loss: 2.737433309047519

Epoch: 5| Step: 6
Training loss: 1.249391550753086
Validation loss: 2.7497800717409335

Epoch: 5| Step: 7
Training loss: 1.0220642777812778
Validation loss: 2.8141764342214124

Epoch: 5| Step: 8
Training loss: 1.3565663228116218
Validation loss: 2.7633686128438035

Epoch: 5| Step: 9
Training loss: 1.2307350476038752
Validation loss: 2.6890885884720483

Epoch: 5| Step: 10
Training loss: 1.1168229902268885
Validation loss: 2.67101420837964

Epoch: 5| Step: 11
Training loss: 0.6925323712188511
Validation loss: 2.6858408375156952

Epoch: 439| Step: 0
Training loss: 1.398900259161275
Validation loss: 2.7021439890841554

Epoch: 5| Step: 1
Training loss: 1.292023189112182
Validation loss: 2.7036452702287943

Epoch: 5| Step: 2
Training loss: 1.2870450503030981
Validation loss: 2.7128217783157234

Epoch: 5| Step: 3
Training loss: 0.9819141387909073
Validation loss: 2.706793058557499

Epoch: 5| Step: 4
Training loss: 1.3848574759900536
Validation loss: 2.73641250992129

Epoch: 5| Step: 5
Training loss: 0.8583646209964797
Validation loss: 2.7524917035810796

Epoch: 5| Step: 6
Training loss: 1.4465231284261504
Validation loss: 2.7157400906504425

Epoch: 5| Step: 7
Training loss: 1.5813250437182043
Validation loss: 2.766903935354306

Epoch: 5| Step: 8
Training loss: 1.2443566726108977
Validation loss: 2.7765901690471013

Epoch: 5| Step: 9
Training loss: 1.221106525141981
Validation loss: 2.7934108322013738

Epoch: 5| Step: 10
Training loss: 1.0671492562765101
Validation loss: 2.779590629589409

Epoch: 5| Step: 11
Training loss: 1.3377137004509165
Validation loss: 2.710450615158367

Epoch: 440| Step: 0
Training loss: 1.2446464815690985
Validation loss: 2.7194897679284122

Epoch: 5| Step: 1
Training loss: 1.2718718095219217
Validation loss: 2.686885183077985

Epoch: 5| Step: 2
Training loss: 1.0900978147732043
Validation loss: 2.668003783919879

Epoch: 5| Step: 3
Training loss: 1.0594943674179935
Validation loss: 2.6063883548791003

Epoch: 5| Step: 4
Training loss: 1.4318362072502218
Validation loss: 2.6441799927884726

Epoch: 5| Step: 5
Training loss: 1.2783133650110816
Validation loss: 2.643790527766592

Epoch: 5| Step: 6
Training loss: 1.0897075062023716
Validation loss: 2.6151125449572072

Epoch: 5| Step: 7
Training loss: 1.1930107943677228
Validation loss: 2.6202125868442154

Epoch: 5| Step: 8
Training loss: 1.049130529357527
Validation loss: 2.6493470703384245

Epoch: 5| Step: 9
Training loss: 1.0443233308732156
Validation loss: 2.621440873940687

Epoch: 5| Step: 10
Training loss: 1.1638407656043395
Validation loss: 2.6089876195753483

Epoch: 5| Step: 11
Training loss: 1.2522184712649873
Validation loss: 2.7161017487783474

Epoch: 441| Step: 0
Training loss: 2.0031040660698625
Validation loss: 2.701955755560716

Epoch: 5| Step: 1
Training loss: 0.9345550695310282
Validation loss: 2.711277748910936

Epoch: 5| Step: 2
Training loss: 1.36255366193457
Validation loss: 2.7158296766214565

Epoch: 5| Step: 3
Training loss: 1.038106090963677
Validation loss: 2.6461670857784547

Epoch: 5| Step: 4
Training loss: 0.7131502697652405
Validation loss: 2.6266978956458207

Epoch: 5| Step: 5
Training loss: 1.3255745128062266
Validation loss: 2.6269691665329797

Epoch: 5| Step: 6
Training loss: 1.2182076543458222
Validation loss: 2.6405835609269404

Epoch: 5| Step: 7
Training loss: 1.0696264699676388
Validation loss: 2.6113230349277825

Epoch: 5| Step: 8
Training loss: 1.1448570022242919
Validation loss: 2.62227652062711

Epoch: 5| Step: 9
Training loss: 1.189399855850619
Validation loss: 2.6066904211201805

Epoch: 5| Step: 10
Training loss: 1.0737777637094148
Validation loss: 2.6566087817064665

Epoch: 5| Step: 11
Training loss: 0.32880683855404597
Validation loss: 2.714343080162401

Epoch: 442| Step: 0
Training loss: 1.1782233644903073
Validation loss: 2.724623806093708

Epoch: 5| Step: 1
Training loss: 1.2309209083664996
Validation loss: 2.8055424002747094

Epoch: 5| Step: 2
Training loss: 1.080726525483485
Validation loss: 2.8028055782334014

Epoch: 5| Step: 3
Training loss: 0.9609788405046885
Validation loss: 2.7754549738927157

Epoch: 5| Step: 4
Training loss: 1.1302031884611021
Validation loss: 2.6582932729054365

Epoch: 5| Step: 5
Training loss: 0.8992964246197142
Validation loss: 2.6637750435100487

Epoch: 5| Step: 6
Training loss: 1.1245954633927568
Validation loss: 2.6538953797936884

Epoch: 5| Step: 7
Training loss: 1.889853075563494
Validation loss: 2.6776680672651128

Epoch: 5| Step: 8
Training loss: 1.0364567486672611
Validation loss: 2.642829264689539

Epoch: 5| Step: 9
Training loss: 1.0799804422585673
Validation loss: 2.62882175092476

Epoch: 5| Step: 10
Training loss: 1.0794074129982032
Validation loss: 2.627365734119151

Epoch: 5| Step: 11
Training loss: 0.5051234721326106
Validation loss: 2.6599615196621214

Epoch: 443| Step: 0
Training loss: 1.0580351647300281
Validation loss: 2.647069283162958

Epoch: 5| Step: 1
Training loss: 0.850061441052169
Validation loss: 2.68707075313542

Epoch: 5| Step: 2
Training loss: 1.0816478945293926
Validation loss: 2.6937398588752295

Epoch: 5| Step: 3
Training loss: 1.4351465614253467
Validation loss: 2.660886543847782

Epoch: 5| Step: 4
Training loss: 1.1926327255249891
Validation loss: 2.6961806037271274

Epoch: 5| Step: 5
Training loss: 0.8638962846202949
Validation loss: 2.704071037402148

Epoch: 5| Step: 6
Training loss: 0.8609525246529383
Validation loss: 2.69344777641515

Epoch: 5| Step: 7
Training loss: 0.9704044120367501
Validation loss: 2.652038489235044

Epoch: 5| Step: 8
Training loss: 1.0523692331152679
Validation loss: 2.6511014651815805

Epoch: 5| Step: 9
Training loss: 1.1625609474202523
Validation loss: 2.663469802390226

Epoch: 5| Step: 10
Training loss: 1.327615887168768
Validation loss: 2.6764197597088093

Epoch: 5| Step: 11
Training loss: 0.23573879975900613
Validation loss: 2.6799783280075204

Epoch: 444| Step: 0
Training loss: 1.4793857448044245
Validation loss: 2.702865066231795

Epoch: 5| Step: 1
Training loss: 1.3073154867770682
Validation loss: 2.727227068980054

Epoch: 5| Step: 2
Training loss: 1.0251433737431224
Validation loss: 2.777786784687275

Epoch: 5| Step: 3
Training loss: 0.834637709846064
Validation loss: 2.766261485507321

Epoch: 5| Step: 4
Training loss: 0.7851724955078511
Validation loss: 2.7023824726678227

Epoch: 5| Step: 5
Training loss: 0.9734363108913942
Validation loss: 2.69357133362826

Epoch: 5| Step: 6
Training loss: 0.7902899156437971
Validation loss: 2.684873121420218

Epoch: 5| Step: 7
Training loss: 1.1521245198306242
Validation loss: 2.7173395810042176

Epoch: 5| Step: 8
Training loss: 0.9092484887598006
Validation loss: 2.6511564073794784

Epoch: 5| Step: 9
Training loss: 0.984727493631314
Validation loss: 2.6778311866122793

Epoch: 5| Step: 10
Training loss: 1.2317343364359945
Validation loss: 2.6737657887576844

Epoch: 5| Step: 11
Training loss: 0.7190387394646137
Validation loss: 2.663678485567343

Epoch: 445| Step: 0
Training loss: 1.1506354649454829
Validation loss: 2.6100618520620658

Epoch: 5| Step: 1
Training loss: 0.9474267881487334
Validation loss: 2.617945349746289

Epoch: 5| Step: 2
Training loss: 1.1791500863211464
Validation loss: 2.675635933004579

Epoch: 5| Step: 3
Training loss: 0.7780497809519673
Validation loss: 2.714847142059622

Epoch: 5| Step: 4
Training loss: 1.2666597727956057
Validation loss: 2.669223972312396

Epoch: 5| Step: 5
Training loss: 0.8794988372300591
Validation loss: 2.660887215856561

Epoch: 5| Step: 6
Training loss: 0.8165634587979738
Validation loss: 2.698021630168652

Epoch: 5| Step: 7
Training loss: 1.5680086306606913
Validation loss: 2.671077705982986

Epoch: 5| Step: 8
Training loss: 1.105815819489254
Validation loss: 2.674778362848889

Epoch: 5| Step: 9
Training loss: 0.7006810417527568
Validation loss: 2.6496325097097375

Epoch: 5| Step: 10
Training loss: 0.7336983505604829
Validation loss: 2.6480553500406607

Epoch: 5| Step: 11
Training loss: 0.8141343478605186
Validation loss: 2.6679265441088114

Epoch: 446| Step: 0
Training loss: 1.1442877604859332
Validation loss: 2.6828718181459066

Epoch: 5| Step: 1
Training loss: 1.4706017204676152
Validation loss: 2.663917973868639

Epoch: 5| Step: 2
Training loss: 1.1438271501712984
Validation loss: 2.6901679140694683

Epoch: 5| Step: 3
Training loss: 0.6659344039121821
Validation loss: 2.673706416018127

Epoch: 5| Step: 4
Training loss: 0.8904731687994052
Validation loss: 2.654562200740472

Epoch: 5| Step: 5
Training loss: 0.9058815437292153
Validation loss: 2.678937237904188

Epoch: 5| Step: 6
Training loss: 0.8098954122037294
Validation loss: 2.6490884391664022

Epoch: 5| Step: 7
Training loss: 0.9250279190386508
Validation loss: 2.6393141455458324

Epoch: 5| Step: 8
Training loss: 1.1517703423894763
Validation loss: 2.6915634102005797

Epoch: 5| Step: 9
Training loss: 1.2243452989014487
Validation loss: 2.6682709075524165

Epoch: 5| Step: 10
Training loss: 0.7047701768101228
Validation loss: 2.6799138513876857

Epoch: 5| Step: 11
Training loss: 0.9009581326845512
Validation loss: 2.647584145649324

Epoch: 447| Step: 0
Training loss: 0.8913233512023684
Validation loss: 2.7232079605979034

Epoch: 5| Step: 1
Training loss: 0.994642299736084
Validation loss: 2.78751146374043

Epoch: 5| Step: 2
Training loss: 1.1441988413473636
Validation loss: 2.7804142860794188

Epoch: 5| Step: 3
Training loss: 0.957440876392831
Validation loss: 2.7481132920442137

Epoch: 5| Step: 4
Training loss: 0.91283376546848
Validation loss: 2.7865965455380284

Epoch: 5| Step: 5
Training loss: 1.180513105688898
Validation loss: 2.715549964438798

Epoch: 5| Step: 6
Training loss: 1.1737564750549663
Validation loss: 2.7572963256758145

Epoch: 5| Step: 7
Training loss: 1.1293900980781995
Validation loss: 2.6956643395516635

Epoch: 5| Step: 8
Training loss: 0.9973699734010496
Validation loss: 2.663469839687842

Epoch: 5| Step: 9
Training loss: 1.4250514840981439
Validation loss: 2.6950378572899023

Epoch: 5| Step: 10
Training loss: 1.3431620975162166
Validation loss: 2.6585385823063152

Epoch: 5| Step: 11
Training loss: 0.5787429084920102
Validation loss: 2.63330155461085

Epoch: 448| Step: 0
Training loss: 0.849336953170654
Validation loss: 2.6562364091712474

Epoch: 5| Step: 1
Training loss: 1.1243367889340639
Validation loss: 2.641571409531677

Epoch: 5| Step: 2
Training loss: 0.6475789004383468
Validation loss: 2.64967861370953

Epoch: 5| Step: 3
Training loss: 1.215549031215324
Validation loss: 2.683310377623022

Epoch: 5| Step: 4
Training loss: 0.9823298932617069
Validation loss: 2.7227754060566745

Epoch: 5| Step: 5
Training loss: 1.463093192281523
Validation loss: 2.7189200702543475

Epoch: 5| Step: 6
Training loss: 1.0097256030889408
Validation loss: 2.76060545413711

Epoch: 5| Step: 7
Training loss: 0.8574617415698924
Validation loss: 2.6843004698171247

Epoch: 5| Step: 8
Training loss: 1.2820231268309836
Validation loss: 2.681280717177305

Epoch: 5| Step: 9
Training loss: 1.0882930867249043
Validation loss: 2.702294437061074

Epoch: 5| Step: 10
Training loss: 1.0726343295753313
Validation loss: 2.667702862218698

Epoch: 5| Step: 11
Training loss: 1.0196745322382292
Validation loss: 2.6694578610778943

Epoch: 449| Step: 0
Training loss: 1.3257574633395985
Validation loss: 2.662593846913298

Epoch: 5| Step: 1
Training loss: 0.862031264713931
Validation loss: 2.6903589219734805

Epoch: 5| Step: 2
Training loss: 0.6419635372888912
Validation loss: 2.6581650992127828

Epoch: 5| Step: 3
Training loss: 0.9072275151472562
Validation loss: 2.7257168104113982

Epoch: 5| Step: 4
Training loss: 0.9473780614448848
Validation loss: 2.701525863802065

Epoch: 5| Step: 5
Training loss: 1.1785132013940214
Validation loss: 2.7316804888501456

Epoch: 5| Step: 6
Training loss: 0.8952551165926953
Validation loss: 2.73406004045441

Epoch: 5| Step: 7
Training loss: 1.0733482579167057
Validation loss: 2.7492191333125486

Epoch: 5| Step: 8
Training loss: 1.3457457780653086
Validation loss: 2.7509099726347093

Epoch: 5| Step: 9
Training loss: 1.1061248988736598
Validation loss: 2.7209257686057304

Epoch: 5| Step: 10
Training loss: 0.6596247322149927
Validation loss: 2.674573381591347

Epoch: 5| Step: 11
Training loss: 0.8742841789844756
Validation loss: 2.6710234320460255

Epoch: 450| Step: 0
Training loss: 0.8829010100429442
Validation loss: 2.683138020635871

Epoch: 5| Step: 1
Training loss: 1.043601940412461
Validation loss: 2.638762123565556

Epoch: 5| Step: 2
Training loss: 0.9469700932357421
Validation loss: 2.593226492955033

Epoch: 5| Step: 3
Training loss: 1.0260276922574925
Validation loss: 2.6462018940258556

Epoch: 5| Step: 4
Training loss: 0.8339698665169875
Validation loss: 2.6379083318844274

Epoch: 5| Step: 5
Training loss: 1.0871727045318351
Validation loss: 2.6842820396802773

Epoch: 5| Step: 6
Training loss: 1.2678320208695195
Validation loss: 2.6843751549859496

Epoch: 5| Step: 7
Training loss: 1.2679487018798334
Validation loss: 2.652593133707332

Epoch: 5| Step: 8
Training loss: 0.6977240500659525
Validation loss: 2.6559224843085003

Epoch: 5| Step: 9
Training loss: 1.1708671813814568
Validation loss: 2.6853139510436215

Epoch: 5| Step: 10
Training loss: 0.8587755366586086
Validation loss: 2.6988803524430516

Epoch: 5| Step: 11
Training loss: 1.2995291517451049
Validation loss: 2.653701580736102

Epoch: 451| Step: 0
Training loss: 0.8303806247408702
Validation loss: 2.6674554274224644

Epoch: 5| Step: 1
Training loss: 1.0491803535031243
Validation loss: 2.6879934035416113

Epoch: 5| Step: 2
Training loss: 1.1108688183034403
Validation loss: 2.685517230245946

Epoch: 5| Step: 3
Training loss: 1.325857133553831
Validation loss: 2.6886662606701623

Epoch: 5| Step: 4
Training loss: 0.8323653002756827
Validation loss: 2.7084575893557434

Epoch: 5| Step: 5
Training loss: 0.7906659142081597
Validation loss: 2.6501910350726714

Epoch: 5| Step: 6
Training loss: 0.9561515346021465
Validation loss: 2.707344991127737

Epoch: 5| Step: 7
Training loss: 0.7939213635350518
Validation loss: 2.7072465268802444

Epoch: 5| Step: 8
Training loss: 0.7152237846052971
Validation loss: 2.7066705710245107

Epoch: 5| Step: 9
Training loss: 1.3781330220860488
Validation loss: 2.6819899948003663

Epoch: 5| Step: 10
Training loss: 0.9979225573966477
Validation loss: 2.7092009120686646

Epoch: 5| Step: 11
Training loss: 1.297213636560956
Validation loss: 2.7217037663867756

Epoch: 452| Step: 0
Training loss: 0.8997559534433968
Validation loss: 2.698373970590072

Epoch: 5| Step: 1
Training loss: 1.0789189386968265
Validation loss: 2.649342677627228

Epoch: 5| Step: 2
Training loss: 0.9273031095679909
Validation loss: 2.676521911580574

Epoch: 5| Step: 3
Training loss: 1.0217844885075276
Validation loss: 2.7284758994310527

Epoch: 5| Step: 4
Training loss: 0.8059635599810918
Validation loss: 2.6569696797811364

Epoch: 5| Step: 5
Training loss: 1.2037830287248494
Validation loss: 2.669533597837031

Epoch: 5| Step: 6
Training loss: 0.7167530514160176
Validation loss: 2.659800699441322

Epoch: 5| Step: 7
Training loss: 0.7879666565506641
Validation loss: 2.7044390936951985

Epoch: 5| Step: 8
Training loss: 1.3773880941140921
Validation loss: 2.640583470636829

Epoch: 5| Step: 9
Training loss: 0.8944449903718166
Validation loss: 2.6421893863682526

Epoch: 5| Step: 10
Training loss: 0.9209121589811518
Validation loss: 2.679875040118347

Epoch: 5| Step: 11
Training loss: 0.7023371202879446
Validation loss: 2.6768923603521855

Epoch: 453| Step: 0
Training loss: 0.894370218633404
Validation loss: 2.699218367242119

Epoch: 5| Step: 1
Training loss: 0.7798859322722199
Validation loss: 2.7226146547049064

Epoch: 5| Step: 2
Training loss: 1.0097505726974385
Validation loss: 2.7004022060274524

Epoch: 5| Step: 3
Training loss: 1.0397240389980928
Validation loss: 2.7025037650671133

Epoch: 5| Step: 4
Training loss: 0.9694234291635887
Validation loss: 2.7286667013975294

Epoch: 5| Step: 5
Training loss: 1.3112715921724285
Validation loss: 2.7247917560894614

Epoch: 5| Step: 6
Training loss: 0.5928245912001503
Validation loss: 2.735098632246302

Epoch: 5| Step: 7
Training loss: 0.8217136587306919
Validation loss: 2.7589805910135925

Epoch: 5| Step: 8
Training loss: 0.9999610476059948
Validation loss: 2.719018153781927

Epoch: 5| Step: 9
Training loss: 0.8125318374264882
Validation loss: 2.689468553656281

Epoch: 5| Step: 10
Training loss: 1.3058319554486986
Validation loss: 2.6973352554471264

Epoch: 5| Step: 11
Training loss: 0.9646759196118652
Validation loss: 2.7108233150213406

Epoch: 454| Step: 0
Training loss: 1.063802033529043
Validation loss: 2.653220131632192

Epoch: 5| Step: 1
Training loss: 0.9718250875136831
Validation loss: 2.6965349530383733

Epoch: 5| Step: 2
Training loss: 1.046229661768916
Validation loss: 2.6896064915880142

Epoch: 5| Step: 3
Training loss: 0.9917008415445548
Validation loss: 2.676284616464129

Epoch: 5| Step: 4
Training loss: 0.8014644034816629
Validation loss: 2.691994523866137

Epoch: 5| Step: 5
Training loss: 0.6304134528999917
Validation loss: 2.7258223737809093

Epoch: 5| Step: 6
Training loss: 1.2142213656100684
Validation loss: 2.7128527853560285

Epoch: 5| Step: 7
Training loss: 1.1491167823267785
Validation loss: 2.6958851634373597

Epoch: 5| Step: 8
Training loss: 0.9213411434123644
Validation loss: 2.7380925075841205

Epoch: 5| Step: 9
Training loss: 0.8921655415039075
Validation loss: 2.7027051007844407

Epoch: 5| Step: 10
Training loss: 0.6269667436778396
Validation loss: 2.742445162906169

Epoch: 5| Step: 11
Training loss: 2.215070440407988
Validation loss: 2.689182435013019

Epoch: 455| Step: 0
Training loss: 0.6931499970987608
Validation loss: 2.6645836679271

Epoch: 5| Step: 1
Training loss: 0.7441292108576505
Validation loss: 2.7234706344821205

Epoch: 5| Step: 2
Training loss: 1.0362769627945874
Validation loss: 2.695484321756678

Epoch: 5| Step: 3
Training loss: 0.9976353403408008
Validation loss: 2.7052797171235445

Epoch: 5| Step: 4
Training loss: 1.0248035894016891
Validation loss: 2.6652822415010404

Epoch: 5| Step: 5
Training loss: 0.8465707042207834
Validation loss: 2.7114915638862227

Epoch: 5| Step: 6
Training loss: 1.2990399410224391
Validation loss: 2.708488244737102

Epoch: 5| Step: 7
Training loss: 0.9793202638210619
Validation loss: 2.6532473497370623

Epoch: 5| Step: 8
Training loss: 0.9290035520881933
Validation loss: 2.6608803613590517

Epoch: 5| Step: 9
Training loss: 1.148060899086176
Validation loss: 2.676257055446418

Epoch: 5| Step: 10
Training loss: 0.6962351731343057
Validation loss: 2.7141031732551357

Epoch: 5| Step: 11
Training loss: 0.7226292785560099
Validation loss: 2.6894040275234734

Epoch: 456| Step: 0
Training loss: 0.9922362187957441
Validation loss: 2.6836778830231993

Epoch: 5| Step: 1
Training loss: 1.3528385643266736
Validation loss: 2.6946408121307757

Epoch: 5| Step: 2
Training loss: 0.8565608330550007
Validation loss: 2.664355618934854

Epoch: 5| Step: 3
Training loss: 0.8803336864951236
Validation loss: 2.6986134168237967

Epoch: 5| Step: 4
Training loss: 0.896576321941746
Validation loss: 2.6968651137423105

Epoch: 5| Step: 5
Training loss: 1.2460727988846556
Validation loss: 2.7181339917999416

Epoch: 5| Step: 6
Training loss: 0.7962215961079193
Validation loss: 2.7014170636753785

Epoch: 5| Step: 7
Training loss: 0.5390420716326375
Validation loss: 2.658977820758822

Epoch: 5| Step: 8
Training loss: 0.9811980434196051
Validation loss: 2.6947364523271307

Epoch: 5| Step: 9
Training loss: 0.5477978685147452
Validation loss: 2.685710603289099

Epoch: 5| Step: 10
Training loss: 0.8361374090149001
Validation loss: 2.689087099697587

Epoch: 5| Step: 11
Training loss: 1.045024260736687
Validation loss: 2.670555246122026

Epoch: 457| Step: 0
Training loss: 1.045358042729858
Validation loss: 2.692485163065422

Epoch: 5| Step: 1
Training loss: 1.0466036088945045
Validation loss: 2.694019637807285

Epoch: 5| Step: 2
Training loss: 0.8415202949896248
Validation loss: 2.6894800521400173

Epoch: 5| Step: 3
Training loss: 0.9259489849097989
Validation loss: 2.7310470383433385

Epoch: 5| Step: 4
Training loss: 0.9721519664326809
Validation loss: 2.733118062633169

Epoch: 5| Step: 5
Training loss: 0.9847028277241401
Validation loss: 2.6711578113021712

Epoch: 5| Step: 6
Training loss: 0.7666021067623466
Validation loss: 2.6927989204167337

Epoch: 5| Step: 7
Training loss: 1.2648588616715446
Validation loss: 2.6834754325478243

Epoch: 5| Step: 8
Training loss: 0.7391909691285788
Validation loss: 2.7178094413511737

Epoch: 5| Step: 9
Training loss: 0.8318175278664381
Validation loss: 2.7110543312893434

Epoch: 5| Step: 10
Training loss: 0.7533222763198127
Validation loss: 2.740523080442216

Epoch: 5| Step: 11
Training loss: 1.4112971121101725
Validation loss: 2.7186424665268083

Epoch: 458| Step: 0
Training loss: 0.7612229127245863
Validation loss: 2.720447507280217

Epoch: 5| Step: 1
Training loss: 0.9413475873089036
Validation loss: 2.710740847238762

Epoch: 5| Step: 2
Training loss: 1.0176359368886803
Validation loss: 2.6836850790727467

Epoch: 5| Step: 3
Training loss: 0.6980931903350702
Validation loss: 2.6869968564320708

Epoch: 5| Step: 4
Training loss: 1.2945824087528643
Validation loss: 2.6643731615712074

Epoch: 5| Step: 5
Training loss: 0.8579514938061371
Validation loss: 2.7073159740120505

Epoch: 5| Step: 6
Training loss: 1.3538988680013697
Validation loss: 2.6881318957416185

Epoch: 5| Step: 7
Training loss: 0.7550881958914976
Validation loss: 2.7051881366123185

Epoch: 5| Step: 8
Training loss: 0.8991688944023284
Validation loss: 2.684906184672626

Epoch: 5| Step: 9
Training loss: 0.6767178258050611
Validation loss: 2.738893738803176

Epoch: 5| Step: 10
Training loss: 0.6475340282674589
Validation loss: 2.70623701590227

Epoch: 5| Step: 11
Training loss: 0.7586153634289462
Validation loss: 2.7437208657828744

Epoch: 459| Step: 0
Training loss: 1.0233333039568504
Validation loss: 2.763243484993967

Epoch: 5| Step: 1
Training loss: 0.8705200906546255
Validation loss: 2.7439799450659534

Epoch: 5| Step: 2
Training loss: 0.7939207629247641
Validation loss: 2.731374554882002

Epoch: 5| Step: 3
Training loss: 0.9709692730230799
Validation loss: 2.6896057307233923

Epoch: 5| Step: 4
Training loss: 0.9229355223877275
Validation loss: 2.7053000752714276

Epoch: 5| Step: 5
Training loss: 0.7088662041158945
Validation loss: 2.7288170941285785

Epoch: 5| Step: 6
Training loss: 0.844506066270613
Validation loss: 2.691768479759111

Epoch: 5| Step: 7
Training loss: 1.1229813797138224
Validation loss: 2.672302215657258

Epoch: 5| Step: 8
Training loss: 1.1730529967919057
Validation loss: 2.7289523096326564

Epoch: 5| Step: 9
Training loss: 1.053432254512269
Validation loss: 2.7432593327627184

Epoch: 5| Step: 10
Training loss: 0.8897625277377647
Validation loss: 2.7268852126706755

Epoch: 5| Step: 11
Training loss: 0.38162902923741
Validation loss: 2.7238033875451215

Epoch: 460| Step: 0
Training loss: 1.0168794953775013
Validation loss: 2.7291651839817668

Epoch: 5| Step: 1
Training loss: 0.7952696393348244
Validation loss: 2.7560824045564507

Epoch: 5| Step: 2
Training loss: 0.908300415078362
Validation loss: 2.7511184975351686

Epoch: 5| Step: 3
Training loss: 1.2994230127019188
Validation loss: 2.75192113081178

Epoch: 5| Step: 4
Training loss: 0.629688629262967
Validation loss: 2.7408539770985625

Epoch: 5| Step: 5
Training loss: 0.8367046864357934
Validation loss: 2.7550463613819742

Epoch: 5| Step: 6
Training loss: 0.9136536164597917
Validation loss: 2.7488249522455535

Epoch: 5| Step: 7
Training loss: 0.7286466015440622
Validation loss: 2.764963796567137

Epoch: 5| Step: 8
Training loss: 1.2706954547733844
Validation loss: 2.7475861481954342

Epoch: 5| Step: 9
Training loss: 1.0028558720629928
Validation loss: 2.767309297379455

Epoch: 5| Step: 10
Training loss: 1.1001789250940364
Validation loss: 2.6980900702602457

Epoch: 5| Step: 11
Training loss: 0.4133556378342885
Validation loss: 2.7841496478792487

Epoch: 461| Step: 0
Training loss: 0.5384185095574792
Validation loss: 2.7184006294766823

Epoch: 5| Step: 1
Training loss: 1.2961176303827289
Validation loss: 2.7630707822857605

Epoch: 5| Step: 2
Training loss: 1.2902977775681719
Validation loss: 2.7560732204522504

Epoch: 5| Step: 3
Training loss: 0.98956384472312
Validation loss: 2.7566690749162106

Epoch: 5| Step: 4
Training loss: 1.4105983474370205
Validation loss: 2.7423798293495114

Epoch: 5| Step: 5
Training loss: 0.7616262526471324
Validation loss: 2.727773617826304

Epoch: 5| Step: 6
Training loss: 0.639810486279369
Validation loss: 2.7047020385633522

Epoch: 5| Step: 7
Training loss: 1.0714017240248725
Validation loss: 2.7502983791140663

Epoch: 5| Step: 8
Training loss: 0.6800186183778801
Validation loss: 2.715588935287731

Epoch: 5| Step: 9
Training loss: 0.6692731736039584
Validation loss: 2.7651582313224843

Epoch: 5| Step: 10
Training loss: 0.883317414776101
Validation loss: 2.767521267389666

Epoch: 5| Step: 11
Training loss: 0.9366810082347907
Validation loss: 2.723700211489925

Epoch: 462| Step: 0
Training loss: 1.0708532707545215
Validation loss: 2.741041413109272

Epoch: 5| Step: 1
Training loss: 0.8880942343229282
Validation loss: 2.7005849712312435

Epoch: 5| Step: 2
Training loss: 1.1647259146678364
Validation loss: 2.789348633920992

Epoch: 5| Step: 3
Training loss: 1.0770558570785793
Validation loss: 2.736986010851713

Epoch: 5| Step: 4
Training loss: 0.9135371923971419
Validation loss: 2.738813572547238

Epoch: 5| Step: 5
Training loss: 0.9662308394196616
Validation loss: 2.699654896780629

Epoch: 5| Step: 6
Training loss: 1.1438817078680619
Validation loss: 2.730994319951071

Epoch: 5| Step: 7
Training loss: 0.8582790322086744
Validation loss: 2.769847412428306

Epoch: 5| Step: 8
Training loss: 1.0158568484427395
Validation loss: 2.762526527553594

Epoch: 5| Step: 9
Training loss: 0.7795555813483191
Validation loss: 2.755097173649013

Epoch: 5| Step: 10
Training loss: 0.9625806638431683
Validation loss: 2.8299426284833773

Epoch: 5| Step: 11
Training loss: 1.0517427377851318
Validation loss: 2.808254389450386

Epoch: 463| Step: 0
Training loss: 1.0128131382230157
Validation loss: 2.767078705466759

Epoch: 5| Step: 1
Training loss: 0.9384612559520157
Validation loss: 2.7499523700577457

Epoch: 5| Step: 2
Training loss: 0.5725102080971771
Validation loss: 2.749054804115383

Epoch: 5| Step: 3
Training loss: 0.7864043530934522
Validation loss: 2.7455117995889085

Epoch: 5| Step: 4
Training loss: 0.8649771762328458
Validation loss: 2.7221492512377328

Epoch: 5| Step: 5
Training loss: 1.3630843143259428
Validation loss: 2.74572073445589

Epoch: 5| Step: 6
Training loss: 0.7739143057853884
Validation loss: 2.7633721754138145

Epoch: 5| Step: 7
Training loss: 0.8050096848302141
Validation loss: 2.7421076111780733

Epoch: 5| Step: 8
Training loss: 0.95627402107137
Validation loss: 2.7943407863501015

Epoch: 5| Step: 9
Training loss: 0.852056867255306
Validation loss: 2.7254616155350404

Epoch: 5| Step: 10
Training loss: 1.036587053801094
Validation loss: 2.7842573843909992

Epoch: 5| Step: 11
Training loss: 1.5791558402033397
Validation loss: 2.7599507004543478

Epoch: 464| Step: 0
Training loss: 0.9392311325615076
Validation loss: 2.684544764499282

Epoch: 5| Step: 1
Training loss: 0.9281707379923178
Validation loss: 2.7026609305400258

Epoch: 5| Step: 2
Training loss: 0.8560960464182168
Validation loss: 2.7392554516025642

Epoch: 5| Step: 3
Training loss: 1.2655693324526913
Validation loss: 2.6967911538903158

Epoch: 5| Step: 4
Training loss: 0.9102373537265822
Validation loss: 2.784561464664387

Epoch: 5| Step: 5
Training loss: 0.7732351404434064
Validation loss: 2.7266779659273404

Epoch: 5| Step: 6
Training loss: 1.4954167121440078
Validation loss: 2.709124758822694

Epoch: 5| Step: 7
Training loss: 0.5474276066737671
Validation loss: 2.739144505261338

Epoch: 5| Step: 8
Training loss: 1.0177147127470194
Validation loss: 2.722140492755348

Epoch: 5| Step: 9
Training loss: 0.8883824474494354
Validation loss: 2.7294540193331

Epoch: 5| Step: 10
Training loss: 0.9542323386956743
Validation loss: 2.7595380116428774

Epoch: 5| Step: 11
Training loss: 1.2312145092491578
Validation loss: 2.7543488960653586

Epoch: 465| Step: 0
Training loss: 0.5036887949070022
Validation loss: 2.6768588641174156

Epoch: 5| Step: 1
Training loss: 1.204928198689402
Validation loss: 2.6876334075935797

Epoch: 5| Step: 2
Training loss: 0.8282736159071604
Validation loss: 2.694767599265011

Epoch: 5| Step: 3
Training loss: 1.181611317673101
Validation loss: 2.687061129820515

Epoch: 5| Step: 4
Training loss: 1.087656869207227
Validation loss: 2.6798087742298535

Epoch: 5| Step: 5
Training loss: 1.0230592217852823
Validation loss: 2.7195517976359587

Epoch: 5| Step: 6
Training loss: 0.7864736635511868
Validation loss: 2.7187984798391414

Epoch: 5| Step: 7
Training loss: 1.1701466849067699
Validation loss: 2.7707929745701083

Epoch: 5| Step: 8
Training loss: 1.147861985267519
Validation loss: 2.8111453113990557

Epoch: 5| Step: 9
Training loss: 0.6865841443934857
Validation loss: 2.7851359904775363

Epoch: 5| Step: 10
Training loss: 0.8388860165278065
Validation loss: 2.7123576172289354

Epoch: 5| Step: 11
Training loss: 1.1526097911910655
Validation loss: 2.7041788454080327

Epoch: 466| Step: 0
Training loss: 1.4474503660504443
Validation loss: 2.7142769128016173

Epoch: 5| Step: 1
Training loss: 0.7832667070488731
Validation loss: 2.710496106157694

Epoch: 5| Step: 2
Training loss: 0.8069216259545886
Validation loss: 2.7010313830981074

Epoch: 5| Step: 3
Training loss: 1.002672320274721
Validation loss: 2.7294601265668383

Epoch: 5| Step: 4
Training loss: 0.6037437723758712
Validation loss: 2.667311792768244

Epoch: 5| Step: 5
Training loss: 0.7604240173263263
Validation loss: 2.6943610977006505

Epoch: 5| Step: 6
Training loss: 1.0419842935136197
Validation loss: 2.7483201567710083

Epoch: 5| Step: 7
Training loss: 0.8104124026607207
Validation loss: 2.7436482595293503

Epoch: 5| Step: 8
Training loss: 0.7904256999200596
Validation loss: 2.779083426047248

Epoch: 5| Step: 9
Training loss: 0.7776652299156712
Validation loss: 2.863185497589365

Epoch: 5| Step: 10
Training loss: 1.0737484544025706
Validation loss: 2.8470328354587284

Epoch: 5| Step: 11
Training loss: 0.4063562657682521
Validation loss: 2.82268541287384

Epoch: 467| Step: 0
Training loss: 0.901131645663898
Validation loss: 2.7746930571220214

Epoch: 5| Step: 1
Training loss: 0.902858306683968
Validation loss: 2.7217150593368395

Epoch: 5| Step: 2
Training loss: 0.7050437601860705
Validation loss: 2.7132140722726437

Epoch: 5| Step: 3
Training loss: 0.916036642195423
Validation loss: 2.725429346809075

Epoch: 5| Step: 4
Training loss: 1.1363570958729567
Validation loss: 2.71098520345061

Epoch: 5| Step: 5
Training loss: 0.7717250014131273
Validation loss: 2.7310083899285886

Epoch: 5| Step: 6
Training loss: 0.7615632509799991
Validation loss: 2.705195293803927

Epoch: 5| Step: 7
Training loss: 1.2742682713393692
Validation loss: 2.6927715468718807

Epoch: 5| Step: 8
Training loss: 0.6662291690654603
Validation loss: 2.6860172557991366

Epoch: 5| Step: 9
Training loss: 0.6322813041587817
Validation loss: 2.711522954336111

Epoch: 5| Step: 10
Training loss: 0.8329404779121782
Validation loss: 2.7384448399384267

Epoch: 5| Step: 11
Training loss: 1.6228460561778502
Validation loss: 2.738596601915843

Epoch: 468| Step: 0
Training loss: 0.8238709063792171
Validation loss: 2.734508307704232

Epoch: 5| Step: 1
Training loss: 0.6965485205772833
Validation loss: 2.7427476924781873

Epoch: 5| Step: 2
Training loss: 0.7799719847636476
Validation loss: 2.741859952631583

Epoch: 5| Step: 3
Training loss: 1.0631190908582873
Validation loss: 2.703309802535227

Epoch: 5| Step: 4
Training loss: 0.8630734016524984
Validation loss: 2.744025625984582

Epoch: 5| Step: 5
Training loss: 1.5168581792765625
Validation loss: 2.7792757470906593

Epoch: 5| Step: 6
Training loss: 0.9831975828369977
Validation loss: 2.7399811486073706

Epoch: 5| Step: 7
Training loss: 0.6431722937600793
Validation loss: 2.785315460462583

Epoch: 5| Step: 8
Training loss: 0.9798956179984409
Validation loss: 2.7875124010172296

Epoch: 5| Step: 9
Training loss: 0.8080478613105279
Validation loss: 2.7819215092470344

Epoch: 5| Step: 10
Training loss: 0.9934179231023308
Validation loss: 2.7152350493633173

Epoch: 5| Step: 11
Training loss: 0.5078232690696305
Validation loss: 2.730751634168603

Epoch: 469| Step: 0
Training loss: 0.9172712882402954
Validation loss: 2.763984710996108

Epoch: 5| Step: 1
Training loss: 0.7504498801399606
Validation loss: 2.74559858695424

Epoch: 5| Step: 2
Training loss: 0.8371618342550298
Validation loss: 2.716724792445666

Epoch: 5| Step: 3
Training loss: 0.7313947469144527
Validation loss: 2.7634346724262815

Epoch: 5| Step: 4
Training loss: 0.7312504874333771
Validation loss: 2.7081470511024595

Epoch: 5| Step: 5
Training loss: 0.910559765345232
Validation loss: 2.7747979637578815

Epoch: 5| Step: 6
Training loss: 1.0733574205760181
Validation loss: 2.734387399554522

Epoch: 5| Step: 7
Training loss: 1.0561499734500102
Validation loss: 2.724083752902427

Epoch: 5| Step: 8
Training loss: 1.1356476656678356
Validation loss: 2.7412284992753078

Epoch: 5| Step: 9
Training loss: 1.0039600402433333
Validation loss: 2.7398208592552433

Epoch: 5| Step: 10
Training loss: 0.8899625690496987
Validation loss: 2.762180270022158

Epoch: 5| Step: 11
Training loss: 0.8852581817304883
Validation loss: 2.7142312216487294

Epoch: 470| Step: 0
Training loss: 0.9781556828473035
Validation loss: 2.7907491476218325

Epoch: 5| Step: 1
Training loss: 0.8292221502849298
Validation loss: 2.693425750098967

Epoch: 5| Step: 2
Training loss: 1.0431390401856426
Validation loss: 2.736086322593603

Epoch: 5| Step: 3
Training loss: 0.8202210148250931
Validation loss: 2.688697762424502

Epoch: 5| Step: 4
Training loss: 1.00763245386344
Validation loss: 2.6951601805470218

Epoch: 5| Step: 5
Training loss: 0.7664588746835121
Validation loss: 2.6980698233965454

Epoch: 5| Step: 6
Training loss: 0.744394454317482
Validation loss: 2.7379795185755316

Epoch: 5| Step: 7
Training loss: 0.8073677683410566
Validation loss: 2.6917604048225425

Epoch: 5| Step: 8
Training loss: 0.9085509915840272
Validation loss: 2.7555434534574506

Epoch: 5| Step: 9
Training loss: 0.605606703270256
Validation loss: 2.7596768965409613

Epoch: 5| Step: 10
Training loss: 0.9003366052802791
Validation loss: 2.761520342644456

Epoch: 5| Step: 11
Training loss: 0.2602531905459642
Validation loss: 2.716449469433811

Epoch: 471| Step: 0
Training loss: 1.0389280303907211
Validation loss: 2.7645185272298325

Epoch: 5| Step: 1
Training loss: 0.6106321864647185
Validation loss: 2.830506784827744

Epoch: 5| Step: 2
Training loss: 0.656926850541893
Validation loss: 2.7431381077691177

Epoch: 5| Step: 3
Training loss: 0.8137453512126371
Validation loss: 2.735151494899271

Epoch: 5| Step: 4
Training loss: 0.9299452608672909
Validation loss: 2.749408325932196

Epoch: 5| Step: 5
Training loss: 0.6097021936222937
Validation loss: 2.7315229855603227

Epoch: 5| Step: 6
Training loss: 0.9243102801442856
Validation loss: 2.7528718020066307

Epoch: 5| Step: 7
Training loss: 1.0741166499774544
Validation loss: 2.7247637268608718

Epoch: 5| Step: 8
Training loss: 0.7697667569959659
Validation loss: 2.7026433570732045

Epoch: 5| Step: 9
Training loss: 0.8830947087324309
Validation loss: 2.7120169799895777

Epoch: 5| Step: 10
Training loss: 0.7367215104926161
Validation loss: 2.7100346992237205

Epoch: 5| Step: 11
Training loss: 0.6727409991708042
Validation loss: 2.741492173305176

Epoch: 472| Step: 0
Training loss: 0.9262706251846795
Validation loss: 2.7376127202416245

Epoch: 5| Step: 1
Training loss: 0.7940686119591995
Validation loss: 2.786781286377985

Epoch: 5| Step: 2
Training loss: 0.863496365219798
Validation loss: 2.7750048797724896

Epoch: 5| Step: 3
Training loss: 0.8120601270311133
Validation loss: 2.7045717392009188

Epoch: 5| Step: 4
Training loss: 0.9279531441792769
Validation loss: 2.7253236005408508

Epoch: 5| Step: 5
Training loss: 0.6652080080426005
Validation loss: 2.7034769104785923

Epoch: 5| Step: 6
Training loss: 0.7926329479555994
Validation loss: 2.73166737877249

Epoch: 5| Step: 7
Training loss: 0.7877359854112239
Validation loss: 2.747586126501976

Epoch: 5| Step: 8
Training loss: 0.7498752967158572
Validation loss: 2.7532781764013787

Epoch: 5| Step: 9
Training loss: 0.9058196920673829
Validation loss: 2.7489766470956907

Epoch: 5| Step: 10
Training loss: 1.0590331794865049
Validation loss: 2.762439826091325

Epoch: 5| Step: 11
Training loss: 0.2914206994695518
Validation loss: 2.729066899104351

Epoch: 473| Step: 0
Training loss: 0.7432047247571197
Validation loss: 2.785563763253573

Epoch: 5| Step: 1
Training loss: 0.7315210932143412
Validation loss: 2.82991415583868

Epoch: 5| Step: 2
Training loss: 1.033871987651264
Validation loss: 2.770783299637323

Epoch: 5| Step: 3
Training loss: 0.8509517544362567
Validation loss: 2.8031740204867184

Epoch: 5| Step: 4
Training loss: 0.7813231624677968
Validation loss: 2.7394509712608577

Epoch: 5| Step: 5
Training loss: 0.7114997568726543
Validation loss: 2.7204505381435506

Epoch: 5| Step: 6
Training loss: 0.9037626595883349
Validation loss: 2.6904557260867534

Epoch: 5| Step: 7
Training loss: 0.8423473567386569
Validation loss: 2.735593291858505

Epoch: 5| Step: 8
Training loss: 0.9807476239823482
Validation loss: 2.721930819047454

Epoch: 5| Step: 9
Training loss: 0.9713420031947605
Validation loss: 2.7425977974154283

Epoch: 5| Step: 10
Training loss: 0.6591054238766012
Validation loss: 2.764843483686187

Epoch: 5| Step: 11
Training loss: 0.8839030998380192
Validation loss: 2.764138621534056

Epoch: 474| Step: 0
Training loss: 1.1329664454596506
Validation loss: 2.733234156625555

Epoch: 5| Step: 1
Training loss: 0.7977032564456116
Validation loss: 2.7433093276852705

Epoch: 5| Step: 2
Training loss: 0.6155419927878633
Validation loss: 2.7416321680300535

Epoch: 5| Step: 3
Training loss: 0.5936339164493188
Validation loss: 2.775247082006026

Epoch: 5| Step: 4
Training loss: 0.44920632718365433
Validation loss: 2.795749782492546

Epoch: 5| Step: 5
Training loss: 0.6294899121704074
Validation loss: 2.774107958565958

Epoch: 5| Step: 6
Training loss: 1.1274443139410046
Validation loss: 2.787565974950155

Epoch: 5| Step: 7
Training loss: 1.1250941449085636
Validation loss: 2.732495899302066

Epoch: 5| Step: 8
Training loss: 0.5005102236520038
Validation loss: 2.7108467849079516

Epoch: 5| Step: 9
Training loss: 0.7551598281191498
Validation loss: 2.6700687028556223

Epoch: 5| Step: 10
Training loss: 0.9269790947994078
Validation loss: 2.7351208605088977

Epoch: 5| Step: 11
Training loss: 0.5416221111263704
Validation loss: 2.750321376690711

Epoch: 475| Step: 0
Training loss: 0.8490387151066249
Validation loss: 2.7489093727492038

Epoch: 5| Step: 1
Training loss: 0.7273394624479227
Validation loss: 2.7536222018305403

Epoch: 5| Step: 2
Training loss: 1.0288835596871646
Validation loss: 2.736598496803832

Epoch: 5| Step: 3
Training loss: 0.8609715283656307
Validation loss: 2.834197909379154

Epoch: 5| Step: 4
Training loss: 0.6154431669986006
Validation loss: 2.758788309913015

Epoch: 5| Step: 5
Training loss: 0.8941845617669315
Validation loss: 2.7570482118927404

Epoch: 5| Step: 6
Training loss: 0.7596125902144933
Validation loss: 2.715756083267002

Epoch: 5| Step: 7
Training loss: 0.7675600316679148
Validation loss: 2.7394059030685773

Epoch: 5| Step: 8
Training loss: 0.6615541093426639
Validation loss: 2.7229643418901395

Epoch: 5| Step: 9
Training loss: 0.8351190071616076
Validation loss: 2.696900590028908

Epoch: 5| Step: 10
Training loss: 0.8979738448864525
Validation loss: 2.701002768930228

Epoch: 5| Step: 11
Training loss: 0.912093952710222
Validation loss: 2.7496486930711384

Epoch: 476| Step: 0
Training loss: 0.7639918912936599
Validation loss: 2.776801827698944

Epoch: 5| Step: 1
Training loss: 0.9468409894116548
Validation loss: 2.784963746482666

Epoch: 5| Step: 2
Training loss: 0.9556894354742962
Validation loss: 2.7721437436479412

Epoch: 5| Step: 3
Training loss: 0.9200791793419438
Validation loss: 2.7490010867613357

Epoch: 5| Step: 4
Training loss: 0.9095410736082983
Validation loss: 2.759475393978268

Epoch: 5| Step: 5
Training loss: 0.7258749138681115
Validation loss: 2.734655918041704

Epoch: 5| Step: 6
Training loss: 0.6215275143481311
Validation loss: 2.7633374590338664

Epoch: 5| Step: 7
Training loss: 0.791988349274955
Validation loss: 2.744762143019117

Epoch: 5| Step: 8
Training loss: 0.8929744983931952
Validation loss: 2.73329536558934

Epoch: 5| Step: 9
Training loss: 0.7276475249478583
Validation loss: 2.7432915945477836

Epoch: 5| Step: 10
Training loss: 0.6832614199859591
Validation loss: 2.7544769705765675

Epoch: 5| Step: 11
Training loss: 0.4677623038669233
Validation loss: 2.7161124834821555

Epoch: 477| Step: 0
Training loss: 1.0614705427900766
Validation loss: 2.8074158137984844

Epoch: 5| Step: 1
Training loss: 0.9131695550992535
Validation loss: 2.796319100031058

Epoch: 5| Step: 2
Training loss: 1.0303344129986405
Validation loss: 2.7878746295584294

Epoch: 5| Step: 3
Training loss: 0.5698649335500523
Validation loss: 2.74649006645804

Epoch: 5| Step: 4
Training loss: 1.0065293534419202
Validation loss: 2.741625982831045

Epoch: 5| Step: 5
Training loss: 0.9807509361980248
Validation loss: 2.728948869580796

Epoch: 5| Step: 6
Training loss: 0.6708507715253054
Validation loss: 2.7293520141348795

Epoch: 5| Step: 7
Training loss: 0.6276201164361028
Validation loss: 2.7391388657074636

Epoch: 5| Step: 8
Training loss: 0.7309814530588542
Validation loss: 2.8072662293385164

Epoch: 5| Step: 9
Training loss: 0.8194674544327625
Validation loss: 2.82061923711047

Epoch: 5| Step: 10
Training loss: 0.7186326055437792
Validation loss: 2.8074248334809697

Epoch: 5| Step: 11
Training loss: 0.9573265087330276
Validation loss: 2.7597634256313204

Epoch: 478| Step: 0
Training loss: 0.9572969651654996
Validation loss: 2.8796988284349943

Epoch: 5| Step: 1
Training loss: 0.940637646713658
Validation loss: 2.8342552134511414

Epoch: 5| Step: 2
Training loss: 0.5339125779613927
Validation loss: 2.8119584586510373

Epoch: 5| Step: 3
Training loss: 0.8741564090103902
Validation loss: 2.811483997926508

Epoch: 5| Step: 4
Training loss: 0.7077475023215475
Validation loss: 2.770412148944187

Epoch: 5| Step: 5
Training loss: 0.6517009880665431
Validation loss: 2.7707615546678808

Epoch: 5| Step: 6
Training loss: 0.8270533843747778
Validation loss: 2.7736122864283645

Epoch: 5| Step: 7
Training loss: 1.0874681183098907
Validation loss: 2.7807185526091116

Epoch: 5| Step: 8
Training loss: 0.7805844332902862
Validation loss: 2.78108225184414

Epoch: 5| Step: 9
Training loss: 0.5667579085391825
Validation loss: 2.7540471719528594

Epoch: 5| Step: 10
Training loss: 0.7642382304614607
Validation loss: 2.7891520103815663

Epoch: 5| Step: 11
Training loss: 0.3142858854264716
Validation loss: 2.7861751156962726

Epoch: 479| Step: 0
Training loss: 0.6532090666844826
Validation loss: 2.798108359951915

Epoch: 5| Step: 1
Training loss: 1.1301010830996807
Validation loss: 2.8324697957360225

Epoch: 5| Step: 2
Training loss: 0.8530901583868418
Validation loss: 2.779315679454834

Epoch: 5| Step: 3
Training loss: 0.8548942274064057
Validation loss: 2.8205407667553963

Epoch: 5| Step: 4
Training loss: 0.5747532335765353
Validation loss: 2.7450629045404464

Epoch: 5| Step: 5
Training loss: 0.7951515859361027
Validation loss: 2.7502561905042837

Epoch: 5| Step: 6
Training loss: 0.6222887598826977
Validation loss: 2.7742053621098526

Epoch: 5| Step: 7
Training loss: 0.5998203266853851
Validation loss: 2.774013176572969

Epoch: 5| Step: 8
Training loss: 0.8202532792285966
Validation loss: 2.6891567535107344

Epoch: 5| Step: 9
Training loss: 0.825364315626452
Validation loss: 2.7552143173777757

Epoch: 5| Step: 10
Training loss: 0.9521017053335435
Validation loss: 2.7453737721402147

Epoch: 5| Step: 11
Training loss: 0.3871947932383895
Validation loss: 2.7740275547808424

Epoch: 480| Step: 0
Training loss: 0.862874517812847
Validation loss: 2.7940377703784955

Epoch: 5| Step: 1
Training loss: 0.9940719730677728
Validation loss: 2.870976881213388

Epoch: 5| Step: 2
Training loss: 0.9371797014492645
Validation loss: 2.8659056969421486

Epoch: 5| Step: 3
Training loss: 0.7816974884197815
Validation loss: 2.8464814332441053

Epoch: 5| Step: 4
Training loss: 0.8324667637007023
Validation loss: 2.8213048617372953

Epoch: 5| Step: 5
Training loss: 0.6601341740455249
Validation loss: 2.7641535722224773

Epoch: 5| Step: 6
Training loss: 0.6346766013294853
Validation loss: 2.755769500600672

Epoch: 5| Step: 7
Training loss: 0.8281003480516892
Validation loss: 2.769748419177387

Epoch: 5| Step: 8
Training loss: 0.6888809207058921
Validation loss: 2.731320438887935

Epoch: 5| Step: 9
Training loss: 0.7322943411100413
Validation loss: 2.6865991812608265

Epoch: 5| Step: 10
Training loss: 0.928625766767698
Validation loss: 2.761211321669081

Epoch: 5| Step: 11
Training loss: 0.8382127760538555
Validation loss: 2.7821447669043144

Epoch: 481| Step: 0
Training loss: 0.5858099989451533
Validation loss: 2.762326520331698

Epoch: 5| Step: 1
Training loss: 0.8712908603057066
Validation loss: 2.774245163349474

Epoch: 5| Step: 2
Training loss: 0.6468045458918755
Validation loss: 2.776582136855761

Epoch: 5| Step: 3
Training loss: 0.7290860313153124
Validation loss: 2.7350205958123834

Epoch: 5| Step: 4
Training loss: 0.8088212729743857
Validation loss: 2.8188592366594616

Epoch: 5| Step: 5
Training loss: 0.6914841128542645
Validation loss: 2.7801308362518875

Epoch: 5| Step: 6
Training loss: 0.6275527320985314
Validation loss: 2.7534722890342094

Epoch: 5| Step: 7
Training loss: 1.0569661145043336
Validation loss: 2.704328651210309

Epoch: 5| Step: 8
Training loss: 0.45791605536593916
Validation loss: 2.7620951779525376

Epoch: 5| Step: 9
Training loss: 0.5144248925690521
Validation loss: 2.7380290620469867

Epoch: 5| Step: 10
Training loss: 1.086465062492113
Validation loss: 2.7567776907950803

Epoch: 5| Step: 11
Training loss: 1.0191277768899552
Validation loss: 2.7242715076895

Epoch: 482| Step: 0
Training loss: 0.5549714879281434
Validation loss: 2.757541034366655

Epoch: 5| Step: 1
Training loss: 0.9638123656106377
Validation loss: 2.734650094862593

Epoch: 5| Step: 2
Training loss: 0.7448759675945483
Validation loss: 2.796469014287186

Epoch: 5| Step: 3
Training loss: 0.9307807136753107
Validation loss: 2.860067467838508

Epoch: 5| Step: 4
Training loss: 0.8661672759637188
Validation loss: 2.872145880818649

Epoch: 5| Step: 5
Training loss: 0.885744610060772
Validation loss: 2.797310651382963

Epoch: 5| Step: 6
Training loss: 0.5863111194886718
Validation loss: 2.7974738042989573

Epoch: 5| Step: 7
Training loss: 0.9038125176656279
Validation loss: 2.725237527171883

Epoch: 5| Step: 8
Training loss: 0.7868938671634657
Validation loss: 2.803140038032127

Epoch: 5| Step: 9
Training loss: 0.9878087176860261
Validation loss: 2.7392251260385967

Epoch: 5| Step: 10
Training loss: 0.7782210570338224
Validation loss: 2.704521869338506

Epoch: 5| Step: 11
Training loss: 0.9741984324718904
Validation loss: 2.6949089688070695

Epoch: 483| Step: 0
Training loss: 0.8984107635500374
Validation loss: 2.8133373250319047

Epoch: 5| Step: 1
Training loss: 0.8450318242462544
Validation loss: 2.8078747971150904

Epoch: 5| Step: 2
Training loss: 0.7631431368735342
Validation loss: 2.8086518417384867

Epoch: 5| Step: 3
Training loss: 0.9460281941565479
Validation loss: 2.806454133111858

Epoch: 5| Step: 4
Training loss: 0.6830540297516493
Validation loss: 2.796296146809539

Epoch: 5| Step: 5
Training loss: 0.8249327834519278
Validation loss: 2.8048562341794425

Epoch: 5| Step: 6
Training loss: 0.5774205529692397
Validation loss: 2.7678251154023727

Epoch: 5| Step: 7
Training loss: 0.6320259009136091
Validation loss: 2.7702437086577545

Epoch: 5| Step: 8
Training loss: 0.6818061124932717
Validation loss: 2.7779627386079198

Epoch: 5| Step: 9
Training loss: 0.6989606455515002
Validation loss: 2.761638631202594

Epoch: 5| Step: 10
Training loss: 0.9618366655688506
Validation loss: 2.735872345531096

Epoch: 5| Step: 11
Training loss: 0.6155831211388033
Validation loss: 2.7699567273382995

Epoch: 484| Step: 0
Training loss: 0.6929021913029961
Validation loss: 2.7262908086064743

Epoch: 5| Step: 1
Training loss: 0.7345177531995533
Validation loss: 2.7516174201892705

Epoch: 5| Step: 2
Training loss: 0.8264598660125894
Validation loss: 2.7999577643978313

Epoch: 5| Step: 3
Training loss: 0.8377081043123243
Validation loss: 2.7797582712039826

Epoch: 5| Step: 4
Training loss: 0.8024858521613693
Validation loss: 2.7779356249359797

Epoch: 5| Step: 5
Training loss: 0.9119209895521434
Validation loss: 2.7696051110236457

Epoch: 5| Step: 6
Training loss: 0.7445821578563199
Validation loss: 2.753709162881012

Epoch: 5| Step: 7
Training loss: 0.8276864816114531
Validation loss: 2.7921769698217864

Epoch: 5| Step: 8
Training loss: 0.6598747149678399
Validation loss: 2.7525208399541254

Epoch: 5| Step: 9
Training loss: 0.8279046899216901
Validation loss: 2.7950074124792414

Epoch: 5| Step: 10
Training loss: 0.661415659411516
Validation loss: 2.8280867719788887

Epoch: 5| Step: 11
Training loss: 0.618523033977548
Validation loss: 2.8336983310053805

Epoch: 485| Step: 0
Training loss: 0.8253096461797423
Validation loss: 2.7309743679584666

Epoch: 5| Step: 1
Training loss: 0.7056228351137455
Validation loss: 2.7630814172045297

Epoch: 5| Step: 2
Training loss: 0.7133933189236452
Validation loss: 2.703582148033666

Epoch: 5| Step: 3
Training loss: 0.697370248847089
Validation loss: 2.732666070154756

Epoch: 5| Step: 4
Training loss: 0.6106243531019675
Validation loss: 2.7133983798767245

Epoch: 5| Step: 5
Training loss: 0.9831177387587798
Validation loss: 2.746997603109541

Epoch: 5| Step: 6
Training loss: 0.8408216593839024
Validation loss: 2.7434007292005185

Epoch: 5| Step: 7
Training loss: 0.8544271389861332
Validation loss: 2.752920897037779

Epoch: 5| Step: 8
Training loss: 0.6001059746534299
Validation loss: 2.763888850417102

Epoch: 5| Step: 9
Training loss: 0.5057868758281442
Validation loss: 2.7299594540606784

Epoch: 5| Step: 10
Training loss: 0.7337599674698106
Validation loss: 2.7606928897104455

Epoch: 5| Step: 11
Training loss: 0.575441680114088
Validation loss: 2.8201506542709884

Epoch: 486| Step: 0
Training loss: 0.7522556241434696
Validation loss: 2.827536165116884

Epoch: 5| Step: 1
Training loss: 0.6822983593406223
Validation loss: 2.7931204516775763

Epoch: 5| Step: 2
Training loss: 0.7452600824569183
Validation loss: 2.8077534111257427

Epoch: 5| Step: 3
Training loss: 0.7369426318347372
Validation loss: 2.8323645419731838

Epoch: 5| Step: 4
Training loss: 0.823870110561081
Validation loss: 2.7836632135249757

Epoch: 5| Step: 5
Training loss: 0.6155923437761555
Validation loss: 2.8164716087796138

Epoch: 5| Step: 6
Training loss: 0.7482953567752338
Validation loss: 2.798755801877631

Epoch: 5| Step: 7
Training loss: 0.8683317041900445
Validation loss: 2.773780296524676

Epoch: 5| Step: 8
Training loss: 0.8645223956100221
Validation loss: 2.8005226757196504

Epoch: 5| Step: 9
Training loss: 0.9640946356612367
Validation loss: 2.7982097367620575

Epoch: 5| Step: 10
Training loss: 0.6758855397450491
Validation loss: 2.7706227485446226

Epoch: 5| Step: 11
Training loss: 0.2774895029831967
Validation loss: 2.7382414593165927

Epoch: 487| Step: 0
Training loss: 0.6250169751723068
Validation loss: 2.796700889524262

Epoch: 5| Step: 1
Training loss: 0.6150936147337621
Validation loss: 2.7905665918028153

Epoch: 5| Step: 2
Training loss: 0.7962040039623
Validation loss: 2.8728762951384765

Epoch: 5| Step: 3
Training loss: 0.6879716469112193
Validation loss: 2.8290302450654026

Epoch: 5| Step: 4
Training loss: 0.8156224919423094
Validation loss: 2.7913938479179596

Epoch: 5| Step: 5
Training loss: 0.5544522821001534
Validation loss: 2.7251404421309773

Epoch: 5| Step: 6
Training loss: 0.6722318455722754
Validation loss: 2.725515680194641

Epoch: 5| Step: 7
Training loss: 0.7164098541934538
Validation loss: 2.7494402156748583

Epoch: 5| Step: 8
Training loss: 0.8732196201726539
Validation loss: 2.7232947820816458

Epoch: 5| Step: 9
Training loss: 0.7198851370583755
Validation loss: 2.774172951339871

Epoch: 5| Step: 10
Training loss: 1.0688929925037038
Validation loss: 2.7926915562510053

Epoch: 5| Step: 11
Training loss: 0.8467272752810281
Validation loss: 2.7722006426236545

Epoch: 488| Step: 0
Training loss: 0.9204812586511885
Validation loss: 2.82847214073441

Epoch: 5| Step: 1
Training loss: 0.8287632479982476
Validation loss: 2.847131761933354

Epoch: 5| Step: 2
Training loss: 0.7145310848994161
Validation loss: 2.9105359471935586

Epoch: 5| Step: 3
Training loss: 1.039173894661792
Validation loss: 2.91429357831214

Epoch: 5| Step: 4
Training loss: 0.9513074085091076
Validation loss: 2.875079178065364

Epoch: 5| Step: 5
Training loss: 0.7469029856270891
Validation loss: 2.8018071819683454

Epoch: 5| Step: 6
Training loss: 0.883934523272052
Validation loss: 2.7160419774643563

Epoch: 5| Step: 7
Training loss: 0.7398074083758096
Validation loss: 2.769140982738832

Epoch: 5| Step: 8
Training loss: 0.9398809081585795
Validation loss: 2.745216377788645

Epoch: 5| Step: 9
Training loss: 1.095654818036066
Validation loss: 2.773812998393908

Epoch: 5| Step: 10
Training loss: 0.7977803267354396
Validation loss: 2.7240192754187675

Epoch: 5| Step: 11
Training loss: 0.6932816797701776
Validation loss: 2.731758213408018

Epoch: 489| Step: 0
Training loss: 0.7908196100451854
Validation loss: 2.7787026015503624

Epoch: 5| Step: 1
Training loss: 1.0663105568901359
Validation loss: 2.873351920483369

Epoch: 5| Step: 2
Training loss: 0.4982578503918087
Validation loss: 2.833022361173621

Epoch: 5| Step: 3
Training loss: 0.7918409021950293
Validation loss: 2.7906963894588355

Epoch: 5| Step: 4
Training loss: 0.7288174655890067
Validation loss: 2.772779237956188

Epoch: 5| Step: 5
Training loss: 0.7969983697273878
Validation loss: 2.7231334412223376

Epoch: 5| Step: 6
Training loss: 0.7677235550495011
Validation loss: 2.7127650803806063

Epoch: 5| Step: 7
Training loss: 0.604886716608955
Validation loss: 2.7733761632879648

Epoch: 5| Step: 8
Training loss: 0.9842452614679623
Validation loss: 2.7241098837089917

Epoch: 5| Step: 9
Training loss: 0.859913223956428
Validation loss: 2.761908913575577

Epoch: 5| Step: 10
Training loss: 0.7133796582227813
Validation loss: 2.7626464882585355

Epoch: 5| Step: 11
Training loss: 0.9547572620831851
Validation loss: 2.8147099466220453

Epoch: 490| Step: 0
Training loss: 0.5335721984800459
Validation loss: 2.7565214973458847

Epoch: 5| Step: 1
Training loss: 0.6371013685292874
Validation loss: 2.7999641506988207

Epoch: 5| Step: 2
Training loss: 0.4677897790909409
Validation loss: 2.8223146181352963

Epoch: 5| Step: 3
Training loss: 0.5951645464530461
Validation loss: 2.8288557924442785

Epoch: 5| Step: 4
Training loss: 0.7949718487751634
Validation loss: 2.814428325387627

Epoch: 5| Step: 5
Training loss: 0.6962241721713269
Validation loss: 2.770829216277618

Epoch: 5| Step: 6
Training loss: 0.8638795876351508
Validation loss: 2.795620908830132

Epoch: 5| Step: 7
Training loss: 0.922035138720438
Validation loss: 2.766665925510338

Epoch: 5| Step: 8
Training loss: 1.0527252593203142
Validation loss: 2.7847687575198288

Epoch: 5| Step: 9
Training loss: 0.9009969990560703
Validation loss: 2.827330261603059

Epoch: 5| Step: 10
Training loss: 0.6316411043730304
Validation loss: 2.7872162058618346

Epoch: 5| Step: 11
Training loss: 0.6877542805762078
Validation loss: 2.8068354076027267

Epoch: 491| Step: 0
Training loss: 0.7443153796914251
Validation loss: 2.7212084547150286

Epoch: 5| Step: 1
Training loss: 0.5640185309943758
Validation loss: 2.759696720214296

Epoch: 5| Step: 2
Training loss: 0.9820330174444616
Validation loss: 2.7408511246493967

Epoch: 5| Step: 3
Training loss: 0.9028056560189603
Validation loss: 2.7675380914772347

Epoch: 5| Step: 4
Training loss: 0.6951334433438109
Validation loss: 2.7695583096479406

Epoch: 5| Step: 5
Training loss: 0.9023729129719038
Validation loss: 2.75889032138676

Epoch: 5| Step: 6
Training loss: 0.6749671265756422
Validation loss: 2.823370570937821

Epoch: 5| Step: 7
Training loss: 0.9269726004887548
Validation loss: 2.7311938245860956

Epoch: 5| Step: 8
Training loss: 0.883400712652353
Validation loss: 2.7751878220914845

Epoch: 5| Step: 9
Training loss: 0.7269639577576051
Validation loss: 2.7951034319875037

Epoch: 5| Step: 10
Training loss: 0.5783746025887091
Validation loss: 2.7706123648757757

Epoch: 5| Step: 11
Training loss: 0.5044412655888935
Validation loss: 2.761287459491672

Epoch: 492| Step: 0
Training loss: 0.9954982099243961
Validation loss: 2.7502914079243777

Epoch: 5| Step: 1
Training loss: 0.6302928447542999
Validation loss: 2.811316000770177

Epoch: 5| Step: 2
Training loss: 0.5811854111256193
Validation loss: 2.7794415026824177

Epoch: 5| Step: 3
Training loss: 0.5940581826941601
Validation loss: 2.7609923692082217

Epoch: 5| Step: 4
Training loss: 0.761274315707218
Validation loss: 2.760618228870943

Epoch: 5| Step: 5
Training loss: 0.636153315259694
Validation loss: 2.801287365473677

Epoch: 5| Step: 6
Training loss: 0.7848359778518932
Validation loss: 2.7827852205327708

Epoch: 5| Step: 7
Training loss: 0.5802069113238548
Validation loss: 2.780515516644729

Epoch: 5| Step: 8
Training loss: 0.8322498589535906
Validation loss: 2.7738717146693532

Epoch: 5| Step: 9
Training loss: 0.8340670613878424
Validation loss: 2.7547246451928875

Epoch: 5| Step: 10
Training loss: 0.9007347260343997
Validation loss: 2.7396335029117935

Epoch: 5| Step: 11
Training loss: 0.6745559962833977
Validation loss: 2.7324765799560833

Epoch: 493| Step: 0
Training loss: 0.7561688245602812
Validation loss: 2.705653028301126

Epoch: 5| Step: 1
Training loss: 0.7046664824808843
Validation loss: 2.7543547677651037

Epoch: 5| Step: 2
Training loss: 1.0876039849914354
Validation loss: 2.7297178299137244

Epoch: 5| Step: 3
Training loss: 0.7720552674112781
Validation loss: 2.733044440472635

Epoch: 5| Step: 4
Training loss: 0.9161360606586224
Validation loss: 2.7991348173103643

Epoch: 5| Step: 5
Training loss: 0.7812545013298058
Validation loss: 2.7917994792622385

Epoch: 5| Step: 6
Training loss: 0.6064192417702207
Validation loss: 2.8058096324220636

Epoch: 5| Step: 7
Training loss: 0.5755469602520309
Validation loss: 2.7969589895640827

Epoch: 5| Step: 8
Training loss: 0.7636497865101992
Validation loss: 2.7793884726911875

Epoch: 5| Step: 9
Training loss: 0.6138946235781093
Validation loss: 2.7564300768062284

Epoch: 5| Step: 10
Training loss: 0.6707054871310372
Validation loss: 2.783272540024356

Epoch: 5| Step: 11
Training loss: 0.42611362887916177
Validation loss: 2.8010256495265486

Epoch: 494| Step: 0
Training loss: 0.698359019502045
Validation loss: 2.785562943008464

Epoch: 5| Step: 1
Training loss: 0.724895287219481
Validation loss: 2.791628927478679

Epoch: 5| Step: 2
Training loss: 0.7234765423318038
Validation loss: 2.7713928350914783

Epoch: 5| Step: 3
Training loss: 0.7450635498259638
Validation loss: 2.8405404336033855

Epoch: 5| Step: 4
Training loss: 0.5251828601817877
Validation loss: 2.822320971446749

Epoch: 5| Step: 5
Training loss: 0.6727914326545849
Validation loss: 2.79837990166739

Epoch: 5| Step: 6
Training loss: 0.5584028758205861
Validation loss: 2.7867342387472034

Epoch: 5| Step: 7
Training loss: 0.9228648997155454
Validation loss: 2.8271616951341154

Epoch: 5| Step: 8
Training loss: 0.9508164699428686
Validation loss: 2.7864206483853584

Epoch: 5| Step: 9
Training loss: 0.718551898690629
Validation loss: 2.747012104638677

Epoch: 5| Step: 10
Training loss: 0.8924877363051599
Validation loss: 2.833906863638203

Epoch: 5| Step: 11
Training loss: 0.32983869412304656
Validation loss: 2.7817126078685064

Epoch: 495| Step: 0
Training loss: 0.6205096587290808
Validation loss: 2.737698506135727

Epoch: 5| Step: 1
Training loss: 0.6224892731014269
Validation loss: 2.796789398872447

Epoch: 5| Step: 2
Training loss: 0.6568626768152197
Validation loss: 2.820837579599074

Epoch: 5| Step: 3
Training loss: 0.9025051088267784
Validation loss: 2.744809012506002

Epoch: 5| Step: 4
Training loss: 0.549873252916173
Validation loss: 2.785407616327876

Epoch: 5| Step: 5
Training loss: 0.49295030248013416
Validation loss: 2.804248949084091

Epoch: 5| Step: 6
Training loss: 0.6287699486542662
Validation loss: 2.784999563010528

Epoch: 5| Step: 7
Training loss: 0.9488861380345387
Validation loss: 2.7980447202073564

Epoch: 5| Step: 8
Training loss: 0.6847410546881786
Validation loss: 2.7918125275800727

Epoch: 5| Step: 9
Training loss: 0.9058395640191991
Validation loss: 2.8358753817562192

Epoch: 5| Step: 10
Training loss: 1.0129025871609127
Validation loss: 2.82126592862319

Epoch: 5| Step: 11
Training loss: 0.4875472846696823
Validation loss: 2.8284090155923076

Epoch: 496| Step: 0
Training loss: 0.7881403907767515
Validation loss: 2.7751400481216235

Epoch: 5| Step: 1
Training loss: 0.7584727842016101
Validation loss: 2.783126465929606

Epoch: 5| Step: 2
Training loss: 0.7382745490198953
Validation loss: 2.793992875143345

Epoch: 5| Step: 3
Training loss: 0.8729298489712536
Validation loss: 2.7711959950495046

Epoch: 5| Step: 4
Training loss: 0.9883964984022829
Validation loss: 2.8015689176765006

Epoch: 5| Step: 5
Training loss: 0.7093966207696419
Validation loss: 2.79367110662271

Epoch: 5| Step: 6
Training loss: 0.5277801403472401
Validation loss: 2.822140169270211

Epoch: 5| Step: 7
Training loss: 0.6155106665851406
Validation loss: 2.839919710608235

Epoch: 5| Step: 8
Training loss: 1.0570706040865605
Validation loss: 2.868288630810104

Epoch: 5| Step: 9
Training loss: 0.6690395316716514
Validation loss: 2.8181729676938754

Epoch: 5| Step: 10
Training loss: 0.5697715231515494
Validation loss: 2.8332416377002363

Epoch: 5| Step: 11
Training loss: 0.4026623177654058
Validation loss: 2.8048890943695723

Epoch: 497| Step: 0
Training loss: 0.6141954156814458
Validation loss: 2.741839927534242

Epoch: 5| Step: 1
Training loss: 0.6220645155703947
Validation loss: 2.753599264290935

Epoch: 5| Step: 2
Training loss: 0.7161387402732304
Validation loss: 2.81330454233279

Epoch: 5| Step: 3
Training loss: 0.9061329206935369
Validation loss: 2.764793914089957

Epoch: 5| Step: 4
Training loss: 0.44024475004194985
Validation loss: 2.7314450997389

Epoch: 5| Step: 5
Training loss: 0.6563169581450119
Validation loss: 2.7421106434599998

Epoch: 5| Step: 6
Training loss: 0.7517119974718356
Validation loss: 2.759534314525767

Epoch: 5| Step: 7
Training loss: 0.5650820544673323
Validation loss: 2.7430640501515864

Epoch: 5| Step: 8
Training loss: 0.6547216829830808
Validation loss: 2.837290284449425

Epoch: 5| Step: 9
Training loss: 0.880565315102913
Validation loss: 2.831540744440966

Epoch: 5| Step: 10
Training loss: 0.8356970681930921
Validation loss: 2.8263249051576165

Epoch: 5| Step: 11
Training loss: 0.6890476320353782
Validation loss: 2.8491701794699646

Epoch: 498| Step: 0
Training loss: 0.36938926356187235
Validation loss: 2.8370014958523937

Epoch: 5| Step: 1
Training loss: 0.807259089315072
Validation loss: 2.8173614730335337

Epoch: 5| Step: 2
Training loss: 0.782990576615514
Validation loss: 2.7483962938763042

Epoch: 5| Step: 3
Training loss: 0.6454827654389732
Validation loss: 2.791641567364115

Epoch: 5| Step: 4
Training loss: 0.7095592259560246
Validation loss: 2.8241679009819167

Epoch: 5| Step: 5
Training loss: 0.7123363691793944
Validation loss: 2.836917410152034

Epoch: 5| Step: 6
Training loss: 0.9209381127331174
Validation loss: 2.7923332647363295

Epoch: 5| Step: 7
Training loss: 0.7243998756778258
Validation loss: 2.7903998166967727

Epoch: 5| Step: 8
Training loss: 0.7505614245678067
Validation loss: 2.805710704188729

Epoch: 5| Step: 9
Training loss: 0.6560453595392353
Validation loss: 2.8003902721045635

Epoch: 5| Step: 10
Training loss: 0.7512012239893081
Validation loss: 2.76409182823181

Epoch: 5| Step: 11
Training loss: 0.3730773513887535
Validation loss: 2.761518195035992

Epoch: 499| Step: 0
Training loss: 0.6420430561613184
Validation loss: 2.769631811270264

Epoch: 5| Step: 1
Training loss: 0.5241229565301058
Validation loss: 2.804835150045691

Epoch: 5| Step: 2
Training loss: 0.5944122335683207
Validation loss: 2.7540792532614393

Epoch: 5| Step: 3
Training loss: 0.6545776220356192
Validation loss: 2.7987270403521247

Epoch: 5| Step: 4
Training loss: 0.9682011126058166
Validation loss: 2.7612287886187508

Epoch: 5| Step: 5
Training loss: 0.7791547526164364
Validation loss: 2.808855450445573

Epoch: 5| Step: 6
Training loss: 0.8839540443493173
Validation loss: 2.792207410499813

Epoch: 5| Step: 7
Training loss: 0.5944362990642245
Validation loss: 2.7466431452980866

Epoch: 5| Step: 8
Training loss: 0.774335628737114
Validation loss: 2.840897551310829

Epoch: 5| Step: 9
Training loss: 0.6189321413621939
Validation loss: 2.7940735772513485

Epoch: 5| Step: 10
Training loss: 0.6270630404419548
Validation loss: 2.83093412348068

Epoch: 5| Step: 11
Training loss: 0.5705165759193528
Validation loss: 2.834044428021946

Epoch: 500| Step: 0
Training loss: 0.6874768296585475
Validation loss: 2.7792397138231317

Epoch: 5| Step: 1
Training loss: 0.6898995485992436
Validation loss: 2.7529692947517352

Epoch: 5| Step: 2
Training loss: 0.5686924800501725
Validation loss: 2.7888431801212246

Epoch: 5| Step: 3
Training loss: 0.8487475002740783
Validation loss: 2.7696558175994896

Epoch: 5| Step: 4
Training loss: 0.6289740342282928
Validation loss: 2.805961661262575

Epoch: 5| Step: 5
Training loss: 0.927442388261892
Validation loss: 2.740131632736037

Epoch: 5| Step: 6
Training loss: 0.6695709421506391
Validation loss: 2.7781624193249645

Epoch: 5| Step: 7
Training loss: 0.6346926133641504
Validation loss: 2.785113615661139

Epoch: 5| Step: 8
Training loss: 0.4166536766252592
Validation loss: 2.7996357943462487

Epoch: 5| Step: 9
Training loss: 0.5681986630717081
Validation loss: 2.783000441638785

Epoch: 5| Step: 10
Training loss: 0.7752532068510382
Validation loss: 2.826612405246798

Epoch: 5| Step: 11
Training loss: 0.9286568642968631
Validation loss: 2.8133900470312896

Epoch: 501| Step: 0
Training loss: 0.6826753823464676
Validation loss: 2.855122487390752

Epoch: 5| Step: 1
Training loss: 0.9527427970135487
Validation loss: 2.900089451215974

Epoch: 5| Step: 2
Training loss: 1.0510283679454782
Validation loss: 2.8889645249193654

Epoch: 5| Step: 3
Training loss: 0.7626434972846097
Validation loss: 2.8157826728436888

Epoch: 5| Step: 4
Training loss: 0.6492276031588259
Validation loss: 2.79118821091231

Epoch: 5| Step: 5
Training loss: 0.8186458914574287
Validation loss: 2.7495847085008123

Epoch: 5| Step: 6
Training loss: 0.8287809401270244
Validation loss: 2.7271369248834545

Epoch: 5| Step: 7
Training loss: 0.7850204274380739
Validation loss: 2.7369099846301395

Epoch: 5| Step: 8
Training loss: 1.1297910714058512
Validation loss: 2.745947781947983

Epoch: 5| Step: 9
Training loss: 0.7730491125412721
Validation loss: 2.733511804844423

Epoch: 5| Step: 10
Training loss: 0.6195499980153476
Validation loss: 2.7880086430459436

Epoch: 5| Step: 11
Training loss: 0.7296984686016895
Validation loss: 2.746850167756424

Epoch: 502| Step: 0
Training loss: 0.5854417865653665
Validation loss: 2.8220523810865874

Epoch: 5| Step: 1
Training loss: 0.8902223915140512
Validation loss: 2.856287187074058

Epoch: 5| Step: 2
Training loss: 0.8717410842706514
Validation loss: 2.8833661913147997

Epoch: 5| Step: 3
Training loss: 0.8174652823679377
Validation loss: 2.8774897879168813

Epoch: 5| Step: 4
Training loss: 0.7185935803915223
Validation loss: 2.777829077299929

Epoch: 5| Step: 5
Training loss: 0.5940219105956576
Validation loss: 2.768524097989032

Epoch: 5| Step: 6
Training loss: 0.8035616359416763
Validation loss: 2.8002204067470493

Epoch: 5| Step: 7
Training loss: 0.8190544290446954
Validation loss: 2.8438986190973807

Epoch: 5| Step: 8
Training loss: 0.9782916819746307
Validation loss: 2.8103553259574237

Epoch: 5| Step: 9
Training loss: 0.7117499017021988
Validation loss: 2.7683887070873276

Epoch: 5| Step: 10
Training loss: 0.7509002845232235
Validation loss: 2.8283613608490237

Epoch: 5| Step: 11
Training loss: 0.43472349060382726
Validation loss: 2.8481649983058324

Epoch: 503| Step: 0
Training loss: 0.7636914653167814
Validation loss: 2.8127685913121607

Epoch: 5| Step: 1
Training loss: 0.7365930621960541
Validation loss: 2.912858218155639

Epoch: 5| Step: 2
Training loss: 0.6478880657208516
Validation loss: 2.8366260235702963

Epoch: 5| Step: 3
Training loss: 0.9986118277887759
Validation loss: 2.835301162325385

Epoch: 5| Step: 4
Training loss: 0.7049807748134681
Validation loss: 2.802599144485493

Epoch: 5| Step: 5
Training loss: 0.7957361722889877
Validation loss: 2.809826873319631

Epoch: 5| Step: 6
Training loss: 0.573680443713376
Validation loss: 2.764452597759233

Epoch: 5| Step: 7
Training loss: 0.7661783982095786
Validation loss: 2.769439638359604

Epoch: 5| Step: 8
Training loss: 0.8086934788334976
Validation loss: 2.773552293147974

Epoch: 5| Step: 9
Training loss: 0.546826605699137
Validation loss: 2.804216598606558

Epoch: 5| Step: 10
Training loss: 0.8046934257215067
Validation loss: 2.8204333384261515

Epoch: 5| Step: 11
Training loss: 0.1915499284175559
Validation loss: 2.8308178286220937

Epoch: 504| Step: 0
Training loss: 0.6534036489116833
Validation loss: 2.8485565436886184

Epoch: 5| Step: 1
Training loss: 0.9570147143122653
Validation loss: 2.8505875754191043

Epoch: 5| Step: 2
Training loss: 0.6720085233150666
Validation loss: 2.933132018465578

Epoch: 5| Step: 3
Training loss: 0.6800060621860902
Validation loss: 2.8642529013819558

Epoch: 5| Step: 4
Training loss: 0.8610111267398773
Validation loss: 2.801105124077617

Epoch: 5| Step: 5
Training loss: 0.7776722429595823
Validation loss: 2.7839348260645025

Epoch: 5| Step: 6
Training loss: 0.7276926173025544
Validation loss: 2.821787261021328

Epoch: 5| Step: 7
Training loss: 0.5380619549123188
Validation loss: 2.778886794725604

Epoch: 5| Step: 8
Training loss: 0.6042480222143303
Validation loss: 2.7793786471810247

Epoch: 5| Step: 9
Training loss: 0.7116140981670354
Validation loss: 2.7505140835525643

Epoch: 5| Step: 10
Training loss: 0.6526768684737738
Validation loss: 2.8243977871148864

Epoch: 5| Step: 11
Training loss: 0.20017376295269423
Validation loss: 2.814735866077577

Epoch: 505| Step: 0
Training loss: 0.43183514798979444
Validation loss: 2.8283466722926534

Epoch: 5| Step: 1
Training loss: 0.6746237218200438
Validation loss: 2.875346732999758

Epoch: 5| Step: 2
Training loss: 0.8679528167113699
Validation loss: 2.8452111881324926

Epoch: 5| Step: 3
Training loss: 0.7100487068420759
Validation loss: 2.853325090916336

Epoch: 5| Step: 4
Training loss: 0.7323786201420133
Validation loss: 2.8534870672831354

Epoch: 5| Step: 5
Training loss: 0.6821760899930301
Validation loss: 2.7761634038936647

Epoch: 5| Step: 6
Training loss: 0.5724974022935461
Validation loss: 2.814569150115748

Epoch: 5| Step: 7
Training loss: 0.6336160667619016
Validation loss: 2.8027976707905218

Epoch: 5| Step: 8
Training loss: 0.6258802414223793
Validation loss: 2.7905342785027933

Epoch: 5| Step: 9
Training loss: 0.8003081249875651
Validation loss: 2.7771788171224885

Epoch: 5| Step: 10
Training loss: 0.9980437097667213
Validation loss: 2.8039832935676774

Epoch: 5| Step: 11
Training loss: 1.0577675385829968
Validation loss: 2.7830696404107838

Epoch: 506| Step: 0
Training loss: 0.4968384987241512
Validation loss: 2.778490941105037

Epoch: 5| Step: 1
Training loss: 0.8494877169093203
Validation loss: 2.816860220586593

Epoch: 5| Step: 2
Training loss: 0.500549788998689
Validation loss: 2.764958655190236

Epoch: 5| Step: 3
Training loss: 0.9109128827650508
Validation loss: 2.782823335489764

Epoch: 5| Step: 4
Training loss: 0.6546200082445478
Validation loss: 2.7913985847220566

Epoch: 5| Step: 5
Training loss: 0.7160746498565462
Validation loss: 2.828936002164533

Epoch: 5| Step: 6
Training loss: 0.86946915835829
Validation loss: 2.8613912634018863

Epoch: 5| Step: 7
Training loss: 0.7487736052802719
Validation loss: 2.823994333470903

Epoch: 5| Step: 8
Training loss: 0.6473300623200521
Validation loss: 2.839811588124473

Epoch: 5| Step: 9
Training loss: 0.6862386055644858
Validation loss: 2.818608291289308

Epoch: 5| Step: 10
Training loss: 0.7783236054813887
Validation loss: 2.748736672946645

Epoch: 5| Step: 11
Training loss: 0.6618469753582147
Validation loss: 2.7862724646256956

Epoch: 507| Step: 0
Training loss: 0.7432446630333126
Validation loss: 2.7785741778319375

Epoch: 5| Step: 1
Training loss: 0.5136202071860522
Validation loss: 2.759068794584639

Epoch: 5| Step: 2
Training loss: 0.5078577755038257
Validation loss: 2.8025404381195336

Epoch: 5| Step: 3
Training loss: 0.6441728231087335
Validation loss: 2.8338653448317093

Epoch: 5| Step: 4
Training loss: 0.7406354637855437
Validation loss: 2.7888746723717825

Epoch: 5| Step: 5
Training loss: 0.6803730324697982
Validation loss: 2.8305781422708947

Epoch: 5| Step: 6
Training loss: 0.5506606003665377
Validation loss: 2.809945161166698

Epoch: 5| Step: 7
Training loss: 0.5912386839511595
Validation loss: 2.8011888484984073

Epoch: 5| Step: 8
Training loss: 0.874763252382501
Validation loss: 2.8109942644122494

Epoch: 5| Step: 9
Training loss: 1.0165179508648836
Validation loss: 2.7982144123260175

Epoch: 5| Step: 10
Training loss: 0.6842062032158567
Validation loss: 2.8027536318446415

Epoch: 5| Step: 11
Training loss: 0.36767671339263897
Validation loss: 2.7833247857524106

Epoch: 508| Step: 0
Training loss: 0.5720971285811459
Validation loss: 2.825317352046597

Epoch: 5| Step: 1
Training loss: 0.653427662604344
Validation loss: 2.780187214446845

Epoch: 5| Step: 2
Training loss: 0.6051473195042232
Validation loss: 2.854946591445006

Epoch: 5| Step: 3
Training loss: 0.6684856311149754
Validation loss: 2.8240263799960754

Epoch: 5| Step: 4
Training loss: 0.8400206623487976
Validation loss: 2.8061294355597424

Epoch: 5| Step: 5
Training loss: 0.7492144762539815
Validation loss: 2.823644390593922

Epoch: 5| Step: 6
Training loss: 0.7256792914609926
Validation loss: 2.7761241704956245

Epoch: 5| Step: 7
Training loss: 0.5734705819298216
Validation loss: 2.7655596536793565

Epoch: 5| Step: 8
Training loss: 0.6052048877305014
Validation loss: 2.764305708848554

Epoch: 5| Step: 9
Training loss: 0.6357718137058163
Validation loss: 2.787750298762175

Epoch: 5| Step: 10
Training loss: 0.5194035710212386
Validation loss: 2.822683283647092

Epoch: 5| Step: 11
Training loss: 0.7445408102984823
Validation loss: 2.7592681018749055

Epoch: 509| Step: 0
Training loss: 0.8715890750546955
Validation loss: 2.7612767708941153

Epoch: 5| Step: 1
Training loss: 0.49542202866681484
Validation loss: 2.802326111516007

Epoch: 5| Step: 2
Training loss: 0.5003879353482981
Validation loss: 2.806954660281186

Epoch: 5| Step: 3
Training loss: 0.8136052903334375
Validation loss: 2.854900489688549

Epoch: 5| Step: 4
Training loss: 0.9325290818064412
Validation loss: 2.7947805650177533

Epoch: 5| Step: 5
Training loss: 0.7608003606333114
Validation loss: 2.8516882010846474

Epoch: 5| Step: 6
Training loss: 0.46350263224063154
Validation loss: 2.8496628552116574

Epoch: 5| Step: 7
Training loss: 0.45725908061939163
Validation loss: 2.813914296626616

Epoch: 5| Step: 8
Training loss: 0.4974535680553765
Validation loss: 2.783233478224471

Epoch: 5| Step: 9
Training loss: 0.5632151719698087
Validation loss: 2.778916662448883

Epoch: 5| Step: 10
Training loss: 0.6933237415882078
Validation loss: 2.766563999662959

Epoch: 5| Step: 11
Training loss: 0.39529620502646906
Validation loss: 2.7172138434389477

Epoch: 510| Step: 0
Training loss: 0.7085037914570413
Validation loss: 2.7583777341025404

Epoch: 5| Step: 1
Training loss: 0.81375025876652
Validation loss: 2.7809992473591674

Epoch: 5| Step: 2
Training loss: 0.6996508067954935
Validation loss: 2.752115956405966

Epoch: 5| Step: 3
Training loss: 0.6027998151378943
Validation loss: 2.7699929961254846

Epoch: 5| Step: 4
Training loss: 0.5585117946871736
Validation loss: 2.8076324409402225

Epoch: 5| Step: 5
Training loss: 0.6215742639624185
Validation loss: 2.83893154628164

Epoch: 5| Step: 6
Training loss: 0.8493820412451314
Validation loss: 2.8591548369372415

Epoch: 5| Step: 7
Training loss: 0.7047633052069295
Validation loss: 2.82615922082732

Epoch: 5| Step: 8
Training loss: 0.6278776203596758
Validation loss: 2.8194162207372067

Epoch: 5| Step: 9
Training loss: 0.5900579909742388
Validation loss: 2.8508173626568802

Epoch: 5| Step: 10
Training loss: 0.6054727123500009
Validation loss: 2.7867882126290358

Epoch: 5| Step: 11
Training loss: 0.7424366582959964
Validation loss: 2.7791823548746812

Epoch: 511| Step: 0
Training loss: 0.546750381439941
Validation loss: 2.7869602119791206

Epoch: 5| Step: 1
Training loss: 0.6119711665719545
Validation loss: 2.762045809000367

Epoch: 5| Step: 2
Training loss: 0.84917605519993
Validation loss: 2.8251283059479544

Epoch: 5| Step: 3
Training loss: 0.6042809679715553
Validation loss: 2.769598690587426

Epoch: 5| Step: 4
Training loss: 0.636931167461758
Validation loss: 2.834541898676258

Epoch: 5| Step: 5
Training loss: 0.7682256321367754
Validation loss: 2.7756142218601774

Epoch: 5| Step: 6
Training loss: 0.5729903491640482
Validation loss: 2.7742692944752734

Epoch: 5| Step: 7
Training loss: 0.7938902438163837
Validation loss: 2.766661807040654

Epoch: 5| Step: 8
Training loss: 0.5835652202695191
Validation loss: 2.750646273215711

Epoch: 5| Step: 9
Training loss: 0.5553136971309984
Validation loss: 2.775277869457315

Epoch: 5| Step: 10
Training loss: 0.619749257429262
Validation loss: 2.7757806989284703

Epoch: 5| Step: 11
Training loss: 0.357280265396351
Validation loss: 2.769918700728209

Epoch: 512| Step: 0
Training loss: 0.843203791675783
Validation loss: 2.8005403834526037

Epoch: 5| Step: 1
Training loss: 0.6726149543021966
Validation loss: 2.849539913022014

Epoch: 5| Step: 2
Training loss: 0.6082920085466083
Validation loss: 2.7807668952123406

Epoch: 5| Step: 3
Training loss: 0.7365513875428119
Validation loss: 2.8005270104354625

Epoch: 5| Step: 4
Training loss: 0.6626328730940326
Validation loss: 2.820641594422445

Epoch: 5| Step: 5
Training loss: 0.7032363803384106
Validation loss: 2.8338876221798195

Epoch: 5| Step: 6
Training loss: 0.3230377426609456
Validation loss: 2.849802475631818

Epoch: 5| Step: 7
Training loss: 0.7089860143721362
Validation loss: 2.8424675114099407

Epoch: 5| Step: 8
Training loss: 0.7546853106923068
Validation loss: 2.835724744706543

Epoch: 5| Step: 9
Training loss: 0.5162419471851581
Validation loss: 2.7711199179611974

Epoch: 5| Step: 10
Training loss: 0.7668765990000426
Validation loss: 2.8011507564669422

Epoch: 5| Step: 11
Training loss: 0.39283660426266365
Validation loss: 2.7372502205753633

Epoch: 513| Step: 0
Training loss: 0.6466707266437592
Validation loss: 2.786993596845119

Epoch: 5| Step: 1
Training loss: 0.5421499486666195
Validation loss: 2.7585917948634253

Epoch: 5| Step: 2
Training loss: 0.8095920315947812
Validation loss: 2.779379029622412

Epoch: 5| Step: 3
Training loss: 0.7074471615043032
Validation loss: 2.7702188539464214

Epoch: 5| Step: 4
Training loss: 0.8512392743032913
Validation loss: 2.80733892770216

Epoch: 5| Step: 5
Training loss: 0.6192982469998038
Validation loss: 2.7861745505644606

Epoch: 5| Step: 6
Training loss: 0.5322580030761471
Validation loss: 2.829281603810449

Epoch: 5| Step: 7
Training loss: 0.49170140073684176
Validation loss: 2.786658364837622

Epoch: 5| Step: 8
Training loss: 0.7237737726843425
Validation loss: 2.8288228454346727

Epoch: 5| Step: 9
Training loss: 0.6300910073351045
Validation loss: 2.8332777345101507

Epoch: 5| Step: 10
Training loss: 0.4965258541232936
Validation loss: 2.8058544695807455

Epoch: 5| Step: 11
Training loss: 0.21610854394049753
Validation loss: 2.854701675382628

Epoch: 514| Step: 0
Training loss: 0.9662703187984905
Validation loss: 2.862563420999362

Epoch: 5| Step: 1
Training loss: 0.5433596843441618
Validation loss: 2.868209067868178

Epoch: 5| Step: 2
Training loss: 0.6561276230922248
Validation loss: 2.844174629339619

Epoch: 5| Step: 3
Training loss: 0.3881637472201527
Validation loss: 2.834936296261968

Epoch: 5| Step: 4
Training loss: 0.611068987538524
Validation loss: 2.7966425246760385

Epoch: 5| Step: 5
Training loss: 0.6165194698733696
Validation loss: 2.7972954766091838

Epoch: 5| Step: 6
Training loss: 0.5884686540084257
Validation loss: 2.765795643170273

Epoch: 5| Step: 7
Training loss: 0.4738262292835023
Validation loss: 2.7816443824465913

Epoch: 5| Step: 8
Training loss: 0.3587863496315468
Validation loss: 2.7854049236323024

Epoch: 5| Step: 9
Training loss: 0.6873096505994323
Validation loss: 2.770465117681221

Epoch: 5| Step: 10
Training loss: 0.6523579350374036
Validation loss: 2.7404696018495995

Epoch: 5| Step: 11
Training loss: 0.5232822985224272
Validation loss: 2.768933965772702

Epoch: 515| Step: 0
Training loss: 0.5470204841014186
Validation loss: 2.7824404879612468

Epoch: 5| Step: 1
Training loss: 0.5332332504760928
Validation loss: 2.757053613036049

Epoch: 5| Step: 2
Training loss: 0.4794400219791913
Validation loss: 2.7788642516209787

Epoch: 5| Step: 3
Training loss: 0.6439947727728695
Validation loss: 2.810382070297806

Epoch: 5| Step: 4
Training loss: 0.6327960400736568
Validation loss: 2.8314140366338654

Epoch: 5| Step: 5
Training loss: 0.49186218955142563
Validation loss: 2.7823041211278774

Epoch: 5| Step: 6
Training loss: 0.9070381157719529
Validation loss: 2.7404927544057527

Epoch: 5| Step: 7
Training loss: 0.35829142290288873
Validation loss: 2.797199935436539

Epoch: 5| Step: 8
Training loss: 0.7851939405817676
Validation loss: 2.805419858136258

Epoch: 5| Step: 9
Training loss: 0.7322418398521279
Validation loss: 2.817812589219719

Epoch: 5| Step: 10
Training loss: 0.5885643124795021
Validation loss: 2.8086246246494286

Epoch: 5| Step: 11
Training loss: 0.49641903403021165
Validation loss: 2.8283445824511984

Epoch: 516| Step: 0
Training loss: 0.5197303218483389
Validation loss: 2.820581421574991

Epoch: 5| Step: 1
Training loss: 0.6559221720437998
Validation loss: 2.8424528013855217

Epoch: 5| Step: 2
Training loss: 0.8319300200440102
Validation loss: 2.8423469316988537

Epoch: 5| Step: 3
Training loss: 0.5760036416865835
Validation loss: 2.807587947085054

Epoch: 5| Step: 4
Training loss: 0.7057392898527955
Validation loss: 2.8380343774248438

Epoch: 5| Step: 5
Training loss: 0.6102533612406802
Validation loss: 2.854605468144865

Epoch: 5| Step: 6
Training loss: 0.5917600865779621
Validation loss: 2.8648663652642417

Epoch: 5| Step: 7
Training loss: 0.5044547060793575
Validation loss: 2.816892619823068

Epoch: 5| Step: 8
Training loss: 0.4460779604814794
Validation loss: 2.8178859426728198

Epoch: 5| Step: 9
Training loss: 0.533220227983773
Validation loss: 2.807157387055104

Epoch: 5| Step: 10
Training loss: 0.46912213494726757
Validation loss: 2.8320389916325133

Epoch: 5| Step: 11
Training loss: 0.4680075487665112
Validation loss: 2.8105986349373384

Epoch: 517| Step: 0
Training loss: 0.3747172879427619
Validation loss: 2.76549822486214

Epoch: 5| Step: 1
Training loss: 0.6750945643129732
Validation loss: 2.754504315161301

Epoch: 5| Step: 2
Training loss: 0.8116925702540659
Validation loss: 2.805274972691911

Epoch: 5| Step: 3
Training loss: 0.4647111142487821
Validation loss: 2.793928188754615

Epoch: 5| Step: 4
Training loss: 0.483016045882364
Validation loss: 2.7746300976313387

Epoch: 5| Step: 5
Training loss: 0.5511707524883647
Validation loss: 2.7715761950433326

Epoch: 5| Step: 6
Training loss: 0.8271191083984484
Validation loss: 2.8106286039436053

Epoch: 5| Step: 7
Training loss: 0.6135842856310362
Validation loss: 2.7996098947682

Epoch: 5| Step: 8
Training loss: 0.6332485203881942
Validation loss: 2.741812521862734

Epoch: 5| Step: 9
Training loss: 0.6845227713409197
Validation loss: 2.8155953575433994

Epoch: 5| Step: 10
Training loss: 0.5563977163250128
Validation loss: 2.7882638530450343

Epoch: 5| Step: 11
Training loss: 0.7572162288012811
Validation loss: 2.7816712885472152

Epoch: 518| Step: 0
Training loss: 0.4676575965237438
Validation loss: 2.766597031000396

Epoch: 5| Step: 1
Training loss: 0.6087630206679724
Validation loss: 2.7916459051944904

Epoch: 5| Step: 2
Training loss: 0.4163768972676002
Validation loss: 2.809099087375205

Epoch: 5| Step: 3
Training loss: 0.6108801909980006
Validation loss: 2.7713881823832276

Epoch: 5| Step: 4
Training loss: 0.5832912963525207
Validation loss: 2.8102498201274537

Epoch: 5| Step: 5
Training loss: 0.6766773743048476
Validation loss: 2.8475907662270754

Epoch: 5| Step: 6
Training loss: 0.5359764774484528
Validation loss: 2.834473476360508

Epoch: 5| Step: 7
Training loss: 0.7603734583314627
Validation loss: 2.8473146318284686

Epoch: 5| Step: 8
Training loss: 0.6829310665586901
Validation loss: 2.8030604120792364

Epoch: 5| Step: 9
Training loss: 0.6614376024817278
Validation loss: 2.8361885898431947

Epoch: 5| Step: 10
Training loss: 0.5361635515472131
Validation loss: 2.8428990379900267

Epoch: 5| Step: 11
Training loss: 0.9961595401354763
Validation loss: 2.805673172791337

Epoch: 519| Step: 0
Training loss: 0.6268430714258638
Validation loss: 2.835418758816663

Epoch: 5| Step: 1
Training loss: 0.8666785525154931
Validation loss: 2.832797014909865

Epoch: 5| Step: 2
Training loss: 0.6633244620581407
Validation loss: 2.7897510800530894

Epoch: 5| Step: 3
Training loss: 0.7956507385118152
Validation loss: 2.833469195941894

Epoch: 5| Step: 4
Training loss: 0.7959784906299109
Validation loss: 2.819418007132153

Epoch: 5| Step: 5
Training loss: 0.40014350522266523
Validation loss: 2.7679169312185605

Epoch: 5| Step: 6
Training loss: 0.4025370309510993
Validation loss: 2.868136558102104

Epoch: 5| Step: 7
Training loss: 0.9541068101346221
Validation loss: 2.8909337677878444

Epoch: 5| Step: 8
Training loss: 0.7685817534395908
Validation loss: 2.897565595714303

Epoch: 5| Step: 9
Training loss: 0.5697553342943606
Validation loss: 2.8966932197882134

Epoch: 5| Step: 10
Training loss: 0.6401498009038186
Validation loss: 2.88684738691599

Epoch: 5| Step: 11
Training loss: 0.8735026081092123
Validation loss: 2.8086724551035807

Epoch: 520| Step: 0
Training loss: 0.5791906381581522
Validation loss: 2.7919276575719425

Epoch: 5| Step: 1
Training loss: 0.6798352924891351
Validation loss: 2.8773440690825427

Epoch: 5| Step: 2
Training loss: 0.7654355651676521
Validation loss: 2.8285140126520556

Epoch: 5| Step: 3
Training loss: 0.7867017499797322
Validation loss: 2.8063589338301744

Epoch: 5| Step: 4
Training loss: 0.5960111228301804
Validation loss: 2.802358377470068

Epoch: 5| Step: 5
Training loss: 0.6315744321697276
Validation loss: 2.788058216783347

Epoch: 5| Step: 6
Training loss: 0.704231366640586
Validation loss: 2.7914118021779823

Epoch: 5| Step: 7
Training loss: 0.6980829871026046
Validation loss: 2.79373694039179

Epoch: 5| Step: 8
Training loss: 0.8778477376979221
Validation loss: 2.779466778871344

Epoch: 5| Step: 9
Training loss: 0.4865810701652213
Validation loss: 2.828543560043083

Epoch: 5| Step: 10
Training loss: 0.5477658236998045
Validation loss: 2.7983460810936873

Epoch: 5| Step: 11
Training loss: 1.1983851415145943
Validation loss: 2.7706746555487944

Epoch: 521| Step: 0
Training loss: 0.9447423934004446
Validation loss: 2.853990080631076

Epoch: 5| Step: 1
Training loss: 0.4420434690251682
Validation loss: 2.8631336023167733

Epoch: 5| Step: 2
Training loss: 0.41937902093315604
Validation loss: 2.8309956062277855

Epoch: 5| Step: 3
Training loss: 0.5547990552453439
Validation loss: 2.848615054987469

Epoch: 5| Step: 4
Training loss: 0.5756162129993733
Validation loss: 2.813448837728034

Epoch: 5| Step: 5
Training loss: 0.6224644488788309
Validation loss: 2.827515706840262

Epoch: 5| Step: 6
Training loss: 0.6090685244908672
Validation loss: 2.8415391488330473

Epoch: 5| Step: 7
Training loss: 0.8500644911815725
Validation loss: 2.8215739246226823

Epoch: 5| Step: 8
Training loss: 0.6292386805350187
Validation loss: 2.839637087683767

Epoch: 5| Step: 9
Training loss: 0.7003680964355535
Validation loss: 2.869836946512143

Epoch: 5| Step: 10
Training loss: 0.7027306616506385
Validation loss: 2.844444033011971

Epoch: 5| Step: 11
Training loss: 0.6214421572633017
Validation loss: 2.869881977568782

Epoch: 522| Step: 0
Training loss: 0.41609380999230566
Validation loss: 2.8541250550701074

Epoch: 5| Step: 1
Training loss: 0.586182403246198
Validation loss: 2.8410056744254426

Epoch: 5| Step: 2
Training loss: 0.5585130219713031
Validation loss: 2.8988128515034015

Epoch: 5| Step: 3
Training loss: 0.6269287389843409
Validation loss: 2.881156342281273

Epoch: 5| Step: 4
Training loss: 0.5766156572684467
Validation loss: 2.7951872402192435

Epoch: 5| Step: 5
Training loss: 0.3829545711101074
Validation loss: 2.810409560216954

Epoch: 5| Step: 6
Training loss: 0.6291807772041462
Validation loss: 2.7988017103817024

Epoch: 5| Step: 7
Training loss: 0.5255158002276524
Validation loss: 2.7643568486368033

Epoch: 5| Step: 8
Training loss: 0.9487059664151322
Validation loss: 2.772697224569074

Epoch: 5| Step: 9
Training loss: 0.6370342619663094
Validation loss: 2.8179272703525644

Epoch: 5| Step: 10
Training loss: 0.6378420417070886
Validation loss: 2.7875102271047787

Epoch: 5| Step: 11
Training loss: 0.5952188242903584
Validation loss: 2.7949967817482477

Epoch: 523| Step: 0
Training loss: 0.6202401587440871
Validation loss: 2.804846547468767

Epoch: 5| Step: 1
Training loss: 0.5701523647453005
Validation loss: 2.8125152728761025

Epoch: 5| Step: 2
Training loss: 0.6669712314692707
Validation loss: 2.836416363461073

Epoch: 5| Step: 3
Training loss: 0.8315473053528472
Validation loss: 2.8276178351340273

Epoch: 5| Step: 4
Training loss: 0.7727650888772298
Validation loss: 2.8238704531701133

Epoch: 5| Step: 5
Training loss: 0.5035303473262381
Validation loss: 2.842695718478436

Epoch: 5| Step: 6
Training loss: 0.43014017016158035
Validation loss: 2.7921044139315785

Epoch: 5| Step: 7
Training loss: 0.7528397522487226
Validation loss: 2.8119602321197594

Epoch: 5| Step: 8
Training loss: 0.6241370919949253
Validation loss: 2.8504501716437556

Epoch: 5| Step: 9
Training loss: 0.43434121597421427
Validation loss: 2.8411820942878006

Epoch: 5| Step: 10
Training loss: 0.4528707086705674
Validation loss: 2.8496768447526732

Epoch: 5| Step: 11
Training loss: 1.0528468140977054
Validation loss: 2.8251654804341193

Epoch: 524| Step: 0
Training loss: 0.5475059684010055
Validation loss: 2.8287097333446205

Epoch: 5| Step: 1
Training loss: 0.49863751861586764
Validation loss: 2.8229654485046582

Epoch: 5| Step: 2
Training loss: 0.6744236622559924
Validation loss: 2.8171800246221514

Epoch: 5| Step: 3
Training loss: 0.48283600117296743
Validation loss: 2.778785023991214

Epoch: 5| Step: 4
Training loss: 0.6490758029270572
Validation loss: 2.8418869825761703

Epoch: 5| Step: 5
Training loss: 0.5137909725771167
Validation loss: 2.8405908986119557

Epoch: 5| Step: 6
Training loss: 0.8069453737520202
Validation loss: 2.8173887573391028

Epoch: 5| Step: 7
Training loss: 0.6785835860174341
Validation loss: 2.8047950249394247

Epoch: 5| Step: 8
Training loss: 0.7489207370183785
Validation loss: 2.847012245116605

Epoch: 5| Step: 9
Training loss: 0.5452625208033179
Validation loss: 2.874814473261267

Epoch: 5| Step: 10
Training loss: 0.43042412819107995
Validation loss: 2.870404378257699

Epoch: 5| Step: 11
Training loss: 0.7597638990681714
Validation loss: 2.8511606987182194

Epoch: 525| Step: 0
Training loss: 0.4957346480065794
Validation loss: 2.8673344435010812

Epoch: 5| Step: 1
Training loss: 0.6412975920849839
Validation loss: 2.8529233428786336

Epoch: 5| Step: 2
Training loss: 0.4099511314844065
Validation loss: 2.7922123273710935

Epoch: 5| Step: 3
Training loss: 0.725966260178573
Validation loss: 2.78620645448255

Epoch: 5| Step: 4
Training loss: 0.7726533170360907
Validation loss: 2.7705523138065757

Epoch: 5| Step: 5
Training loss: 0.5932657626292862
Validation loss: 2.8067434562404543

Epoch: 5| Step: 6
Training loss: 0.6635781260663799
Validation loss: 2.789093373588131

Epoch: 5| Step: 7
Training loss: 0.7196539294835611
Validation loss: 2.798964822522899

Epoch: 5| Step: 8
Training loss: 0.7263231601075587
Validation loss: 2.8217857542461053

Epoch: 5| Step: 9
Training loss: 0.8033398574614303
Validation loss: 2.8317837030369617

Epoch: 5| Step: 10
Training loss: 0.5820307891639063
Validation loss: 2.824949564807081

Epoch: 5| Step: 11
Training loss: 0.5029580117555046
Validation loss: 2.806664920030112

Epoch: 526| Step: 0
Training loss: 0.5656382121866625
Validation loss: 2.8226042371670728

Epoch: 5| Step: 1
Training loss: 0.6702354075598064
Validation loss: 2.8893545537829337

Epoch: 5| Step: 2
Training loss: 0.8111376344540675
Validation loss: 2.910265708418022

Epoch: 5| Step: 3
Training loss: 0.6365062850602886
Validation loss: 2.880330693069971

Epoch: 5| Step: 4
Training loss: 0.7508484888681779
Validation loss: 2.8562807701952027

Epoch: 5| Step: 5
Training loss: 0.7343734578867203
Validation loss: 2.8213268861560254

Epoch: 5| Step: 6
Training loss: 0.5936918983139929
Validation loss: 2.8706323992573406

Epoch: 5| Step: 7
Training loss: 0.8069692316441269
Validation loss: 2.815604816749708

Epoch: 5| Step: 8
Training loss: 0.8660521076727113
Validation loss: 2.829279153008096

Epoch: 5| Step: 9
Training loss: 1.0274073940042965
Validation loss: 2.8951518894478188

Epoch: 5| Step: 10
Training loss: 0.5558092567866545
Validation loss: 2.782891956803548

Epoch: 5| Step: 11
Training loss: 0.7776639269387975
Validation loss: 2.8275826778966673

Epoch: 527| Step: 0
Training loss: 0.632538088416904
Validation loss: 2.7885053168915253

Epoch: 5| Step: 1
Training loss: 0.45629040264843646
Validation loss: 2.8076674782492046

Epoch: 5| Step: 2
Training loss: 0.5514736828062708
Validation loss: 2.815087230442045

Epoch: 5| Step: 3
Training loss: 0.6050264281025625
Validation loss: 2.860390456779483

Epoch: 5| Step: 4
Training loss: 0.6433634495562714
Validation loss: 2.8339167524840985

Epoch: 5| Step: 5
Training loss: 0.41975500650356734
Validation loss: 2.787352998846017

Epoch: 5| Step: 6
Training loss: 0.7774702189712327
Validation loss: 2.8371943131304915

Epoch: 5| Step: 7
Training loss: 0.6804286817979796
Validation loss: 2.791637845151545

Epoch: 5| Step: 8
Training loss: 0.7040745363590792
Validation loss: 2.8447825440174737

Epoch: 5| Step: 9
Training loss: 0.6739533681160882
Validation loss: 2.7837439617233666

Epoch: 5| Step: 10
Training loss: 0.33923328862251956
Validation loss: 2.792243749603053

Epoch: 5| Step: 11
Training loss: 1.0117136833623737
Validation loss: 2.7968258915573285

Epoch: 528| Step: 0
Training loss: 0.4464828437785594
Validation loss: 2.8480515835739277

Epoch: 5| Step: 1
Training loss: 0.8308443370295756
Validation loss: 2.8208575651028647

Epoch: 5| Step: 2
Training loss: 0.8606203592434316
Validation loss: 2.844168132740995

Epoch: 5| Step: 3
Training loss: 0.7850197061264166
Validation loss: 2.9238164642855735

Epoch: 5| Step: 4
Training loss: 0.7036802007234086
Validation loss: 2.8799766714091666

Epoch: 5| Step: 5
Training loss: 0.734456402751327
Validation loss: 2.827617459217043

Epoch: 5| Step: 6
Training loss: 0.4718076323110183
Validation loss: 2.826399390872582

Epoch: 5| Step: 7
Training loss: 0.5874509212609728
Validation loss: 2.8286921141552885

Epoch: 5| Step: 8
Training loss: 0.7425025672739773
Validation loss: 2.8177014889636913

Epoch: 5| Step: 9
Training loss: 0.6161250615320157
Validation loss: 2.7929781079969156

Epoch: 5| Step: 10
Training loss: 0.7690163840891152
Validation loss: 2.802151051072925

Epoch: 5| Step: 11
Training loss: 0.6308772317821556
Validation loss: 2.8285522489473167

Epoch: 529| Step: 0
Training loss: 0.8021765485490798
Validation loss: 2.795633367208537

Epoch: 5| Step: 1
Training loss: 0.6882978924439827
Validation loss: 2.809745757461722

Epoch: 5| Step: 2
Training loss: 0.5435939455265002
Validation loss: 2.863857636284794

Epoch: 5| Step: 3
Training loss: 0.5544397042413094
Validation loss: 2.898338199638448

Epoch: 5| Step: 4
Training loss: 0.5670911134311816
Validation loss: 2.8681984001981577

Epoch: 5| Step: 5
Training loss: 0.4456194940416802
Validation loss: 2.811714712643337

Epoch: 5| Step: 6
Training loss: 0.5536692501031192
Validation loss: 2.8109754633676833

Epoch: 5| Step: 7
Training loss: 0.7433949336228494
Validation loss: 2.798896719497284

Epoch: 5| Step: 8
Training loss: 0.7644357592559998
Validation loss: 2.78712954176388

Epoch: 5| Step: 9
Training loss: 0.7954544045708272
Validation loss: 2.8113803400898605

Epoch: 5| Step: 10
Training loss: 0.6062317992948888
Validation loss: 2.813972744524361

Epoch: 5| Step: 11
Training loss: 0.742939979164632
Validation loss: 2.7992525420019936

Epoch: 530| Step: 0
Training loss: 0.42615170942476366
Validation loss: 2.7633336124163104

Epoch: 5| Step: 1
Training loss: 0.5570288391917145
Validation loss: 2.8002253130960466

Epoch: 5| Step: 2
Training loss: 0.6087701681348482
Validation loss: 2.8115859100372353

Epoch: 5| Step: 3
Training loss: 0.62558471031676
Validation loss: 2.813530909604681

Epoch: 5| Step: 4
Training loss: 0.8119190780268166
Validation loss: 2.8602204315005997

Epoch: 5| Step: 5
Training loss: 0.6223450058702444
Validation loss: 2.8265966497340185

Epoch: 5| Step: 6
Training loss: 0.6435758503283704
Validation loss: 2.7805788501943405

Epoch: 5| Step: 7
Training loss: 0.5184674090771099
Validation loss: 2.7356316594318844

Epoch: 5| Step: 8
Training loss: 0.6656552903353029
Validation loss: 2.816576899183399

Epoch: 5| Step: 9
Training loss: 0.8120817061385608
Validation loss: 2.710128018380712

Epoch: 5| Step: 10
Training loss: 0.745392034993299
Validation loss: 2.7389876161571354

Epoch: 5| Step: 11
Training loss: 0.5262764762325312
Validation loss: 2.722813722570869

Epoch: 531| Step: 0
Training loss: 0.48081607205278803
Validation loss: 2.8012947736115583

Epoch: 5| Step: 1
Training loss: 0.5192298014610053
Validation loss: 2.7916028361828134

Epoch: 5| Step: 2
Training loss: 0.5562805617434117
Validation loss: 2.825501456245511

Epoch: 5| Step: 3
Training loss: 0.5990329917043794
Validation loss: 2.9137528044421055

Epoch: 5| Step: 4
Training loss: 0.5355304328737259
Validation loss: 2.8304699472299713

Epoch: 5| Step: 5
Training loss: 0.6596253873351526
Validation loss: 2.8537099930026275

Epoch: 5| Step: 6
Training loss: 0.45155844703096226
Validation loss: 2.8524576323737043

Epoch: 5| Step: 7
Training loss: 0.8396438005758143
Validation loss: 2.838525367246721

Epoch: 5| Step: 8
Training loss: 0.6429097905247625
Validation loss: 2.8211933989925333

Epoch: 5| Step: 9
Training loss: 0.5604028549997684
Validation loss: 2.785430933892729

Epoch: 5| Step: 10
Training loss: 0.5886938241614265
Validation loss: 2.7777010566659794

Epoch: 5| Step: 11
Training loss: 0.7628582378647989
Validation loss: 2.816191585294467

Epoch: 532| Step: 0
Training loss: 0.8322346040327794
Validation loss: 2.786497546600411

Epoch: 5| Step: 1
Training loss: 0.7269303815872122
Validation loss: 2.834225967453837

Epoch: 5| Step: 2
Training loss: 0.5401906081956206
Validation loss: 2.8235707504728693

Epoch: 5| Step: 3
Training loss: 0.564616856043137
Validation loss: 2.8147236334231036

Epoch: 5| Step: 4
Training loss: 0.6490367280768479
Validation loss: 2.802153130315535

Epoch: 5| Step: 5
Training loss: 0.5432284440803538
Validation loss: 2.7573339643261696

Epoch: 5| Step: 6
Training loss: 0.5212978072163682
Validation loss: 2.8385714199828285

Epoch: 5| Step: 7
Training loss: 0.6107355725570923
Validation loss: 2.860739453619298

Epoch: 5| Step: 8
Training loss: 0.5802709085723302
Validation loss: 2.882364329552754

Epoch: 5| Step: 9
Training loss: 0.5348737207563685
Validation loss: 2.8870147704717897

Epoch: 5| Step: 10
Training loss: 0.727912550945325
Validation loss: 2.8275985262867174

Epoch: 5| Step: 11
Training loss: 0.29847700396813287
Validation loss: 2.787443914832839

Epoch: 533| Step: 0
Training loss: 0.5024132604843662
Validation loss: 2.7796761492332505

Epoch: 5| Step: 1
Training loss: 0.7410923557642369
Validation loss: 2.8032451239582903

Epoch: 5| Step: 2
Training loss: 0.44774011155971283
Validation loss: 2.7684684439473926

Epoch: 5| Step: 3
Training loss: 0.45494010371235977
Validation loss: 2.764425692966376

Epoch: 5| Step: 4
Training loss: 0.6699432280671309
Validation loss: 2.812905861569119

Epoch: 5| Step: 5
Training loss: 0.6624928941885424
Validation loss: 2.763906742535621

Epoch: 5| Step: 6
Training loss: 0.5540899631172262
Validation loss: 2.7678326023349915

Epoch: 5| Step: 7
Training loss: 0.53595623728748
Validation loss: 2.786908615427435

Epoch: 5| Step: 8
Training loss: 0.5730625631503148
Validation loss: 2.794371747377841

Epoch: 5| Step: 9
Training loss: 0.5070131319215084
Validation loss: 2.7860239682673864

Epoch: 5| Step: 10
Training loss: 0.5059328062748087
Validation loss: 2.823652876446912

Epoch: 5| Step: 11
Training loss: 0.7052793559077237
Validation loss: 2.8186386368343386

Epoch: 534| Step: 0
Training loss: 0.756627562355481
Validation loss: 2.8697973702449624

Epoch: 5| Step: 1
Training loss: 0.4887434031146185
Validation loss: 2.8467794463015856

Epoch: 5| Step: 2
Training loss: 0.4861747009450221
Validation loss: 2.8138339305501145

Epoch: 5| Step: 3
Training loss: 0.7837515644502008
Validation loss: 2.803947003864581

Epoch: 5| Step: 4
Training loss: 0.5527447001972204
Validation loss: 2.781943409807869

Epoch: 5| Step: 5
Training loss: 0.5939379695700606
Validation loss: 2.8157651915033317

Epoch: 5| Step: 6
Training loss: 0.4155190777432732
Validation loss: 2.765374842247903

Epoch: 5| Step: 7
Training loss: 0.8530487250021438
Validation loss: 2.810289068461944

Epoch: 5| Step: 8
Training loss: 0.5391875688617592
Validation loss: 2.77213057766491

Epoch: 5| Step: 9
Training loss: 0.691697700409419
Validation loss: 2.7943356137026543

Epoch: 5| Step: 10
Training loss: 0.6802280731803028
Validation loss: 2.834847705878043

Epoch: 5| Step: 11
Training loss: 0.2774446330811007
Validation loss: 2.817782742451515

Epoch: 535| Step: 0
Training loss: 0.6794014471287962
Validation loss: 2.834215799281724

Epoch: 5| Step: 1
Training loss: 0.5469161426871632
Validation loss: 2.8295162495260366

Epoch: 5| Step: 2
Training loss: 0.6709294207885598
Validation loss: 2.8170240080086524

Epoch: 5| Step: 3
Training loss: 0.6921700391440009
Validation loss: 2.900150930516487

Epoch: 5| Step: 4
Training loss: 0.6348162586851654
Validation loss: 2.7925933301032098

Epoch: 5| Step: 5
Training loss: 0.49795028647506384
Validation loss: 2.7850953140476684

Epoch: 5| Step: 6
Training loss: 0.5212119601797943
Validation loss: 2.832731987211795

Epoch: 5| Step: 7
Training loss: 0.5054332750185596
Validation loss: 2.8317557224985848

Epoch: 5| Step: 8
Training loss: 0.46764074048121773
Validation loss: 2.842979833391387

Epoch: 5| Step: 9
Training loss: 0.419517606374854
Validation loss: 2.7970179373873254

Epoch: 5| Step: 10
Training loss: 0.5106854088114509
Validation loss: 2.7933305839427933

Epoch: 5| Step: 11
Training loss: 0.6001822254505673
Validation loss: 2.8274457653284655

Epoch: 536| Step: 0
Training loss: 0.5066888555365321
Validation loss: 2.8097479495263276

Epoch: 5| Step: 1
Training loss: 0.4565403086538897
Validation loss: 2.795700995406375

Epoch: 5| Step: 2
Training loss: 0.34345230303197805
Validation loss: 2.826733125478556

Epoch: 5| Step: 3
Training loss: 0.48743583733795637
Validation loss: 2.794530411484553

Epoch: 5| Step: 4
Training loss: 0.4470932474248846
Validation loss: 2.8056392985037863

Epoch: 5| Step: 5
Training loss: 0.6298252759574383
Validation loss: 2.786197601431486

Epoch: 5| Step: 6
Training loss: 0.5271196242291953
Validation loss: 2.7902644761439737

Epoch: 5| Step: 7
Training loss: 0.9166882613557268
Validation loss: 2.8089363303045736

Epoch: 5| Step: 8
Training loss: 0.5705938559699779
Validation loss: 2.7876960120971632

Epoch: 5| Step: 9
Training loss: 0.5516738152496994
Validation loss: 2.78950508730613

Epoch: 5| Step: 10
Training loss: 0.535667370263219
Validation loss: 2.7783564971373167

Epoch: 5| Step: 11
Training loss: 0.21155395322916176
Validation loss: 2.841509785521367

Epoch: 537| Step: 0
Training loss: 0.6077916286385943
Validation loss: 2.843943858263641

Epoch: 5| Step: 1
Training loss: 0.6476636888470256
Validation loss: 2.8566820182428603

Epoch: 5| Step: 2
Training loss: 0.4724137811360116
Validation loss: 2.8742840642576972

Epoch: 5| Step: 3
Training loss: 0.39380652839335867
Validation loss: 2.8373499874058545

Epoch: 5| Step: 4
Training loss: 0.5498452586624596
Validation loss: 2.8471964921538193

Epoch: 5| Step: 5
Training loss: 0.5254878978660502
Validation loss: 2.8383458807849533

Epoch: 5| Step: 6
Training loss: 0.49534249681200304
Validation loss: 2.8134655637216044

Epoch: 5| Step: 7
Training loss: 0.7193650640867033
Validation loss: 2.7723753457844524

Epoch: 5| Step: 8
Training loss: 0.4720541689680668
Validation loss: 2.825224124547479

Epoch: 5| Step: 9
Training loss: 0.6072746662706995
Validation loss: 2.7974039426487303

Epoch: 5| Step: 10
Training loss: 0.42633881066009827
Validation loss: 2.8153551691439116

Epoch: 5| Step: 11
Training loss: 0.3089014282004602
Validation loss: 2.8068321514858408

Epoch: 538| Step: 0
Training loss: 0.43805909195721426
Validation loss: 2.7876081013780323

Epoch: 5| Step: 1
Training loss: 0.48226575603325744
Validation loss: 2.8145844294115063

Epoch: 5| Step: 2
Training loss: 0.3868863484346665
Validation loss: 2.825658836451848

Epoch: 5| Step: 3
Training loss: 0.4123174494616426
Validation loss: 2.8453254946601003

Epoch: 5| Step: 4
Training loss: 0.45694252522318995
Validation loss: 2.8131007471277223

Epoch: 5| Step: 5
Training loss: 0.5963929731466759
Validation loss: 2.858602996308013

Epoch: 5| Step: 6
Training loss: 0.6370391975451624
Validation loss: 2.835348521742049

Epoch: 5| Step: 7
Training loss: 0.539074800876198
Validation loss: 2.8357894515529303

Epoch: 5| Step: 8
Training loss: 0.7915461138909103
Validation loss: 2.875834464862667

Epoch: 5| Step: 9
Training loss: 0.2940574634822011
Validation loss: 2.8254575004452835

Epoch: 5| Step: 10
Training loss: 0.6510608187083686
Validation loss: 2.814956648234745

Epoch: 5| Step: 11
Training loss: 0.6788316358646056
Validation loss: 2.800831576595268

Epoch: 539| Step: 0
Training loss: 0.4990257069037805
Validation loss: 2.839434048895616

Epoch: 5| Step: 1
Training loss: 0.4781397063044318
Validation loss: 2.7786505442004086

Epoch: 5| Step: 2
Training loss: 0.7819204886519667
Validation loss: 2.8246487280945503

Epoch: 5| Step: 3
Training loss: 0.5809337586297294
Validation loss: 2.7747425286384653

Epoch: 5| Step: 4
Training loss: 0.45971387962513716
Validation loss: 2.8104749382732646

Epoch: 5| Step: 5
Training loss: 0.4025997162441745
Validation loss: 2.821202835907947

Epoch: 5| Step: 6
Training loss: 0.6138472162700466
Validation loss: 2.8077904123135564

Epoch: 5| Step: 7
Training loss: 0.6131328476103208
Validation loss: 2.804809273685751

Epoch: 5| Step: 8
Training loss: 0.5466985417828912
Validation loss: 2.801801118973629

Epoch: 5| Step: 9
Training loss: 0.6281597137348084
Validation loss: 2.7902190466715258

Epoch: 5| Step: 10
Training loss: 0.6588305643751902
Validation loss: 2.774003446620156

Epoch: 5| Step: 11
Training loss: 0.6331721331797276
Validation loss: 2.811074810621933

Epoch: 540| Step: 0
Training loss: 0.6887190587870303
Validation loss: 2.8147405812469874

Epoch: 5| Step: 1
Training loss: 0.5105033301395221
Validation loss: 2.815638348868477

Epoch: 5| Step: 2
Training loss: 0.335161388242233
Validation loss: 2.810859993217185

Epoch: 5| Step: 3
Training loss: 0.4501512220393856
Validation loss: 2.7966124022402177

Epoch: 5| Step: 4
Training loss: 0.8192534376764331
Validation loss: 2.804114280502324

Epoch: 5| Step: 5
Training loss: 0.7515599399451672
Validation loss: 2.833757310355031

Epoch: 5| Step: 6
Training loss: 0.6799631984653599
Validation loss: 2.8707479221075474

Epoch: 5| Step: 7
Training loss: 0.6352689654759287
Validation loss: 2.904511622288477

Epoch: 5| Step: 8
Training loss: 0.6069531364701155
Validation loss: 2.8881942357576373

Epoch: 5| Step: 9
Training loss: 0.6686331584501857
Validation loss: 2.8999634502014984

Epoch: 5| Step: 10
Training loss: 0.7291857217387897
Validation loss: 2.9320229880974384

Epoch: 5| Step: 11
Training loss: 0.6658392082435789
Validation loss: 2.9192915288150187

Epoch: 541| Step: 0
Training loss: 0.3577429158211109
Validation loss: 2.8280944822572196

Epoch: 5| Step: 1
Training loss: 0.6031331946256063
Validation loss: 2.8590568685133904

Epoch: 5| Step: 2
Training loss: 0.6614138120150914
Validation loss: 2.846999948762644

Epoch: 5| Step: 3
Training loss: 0.8224971925403487
Validation loss: 2.841584313691828

Epoch: 5| Step: 4
Training loss: 0.4461661238342268
Validation loss: 2.7516872294697583

Epoch: 5| Step: 5
Training loss: 0.9116786944719288
Validation loss: 2.785363184734767

Epoch: 5| Step: 6
Training loss: 0.5404041842614885
Validation loss: 2.852890733012574

Epoch: 5| Step: 7
Training loss: 0.6819432851863969
Validation loss: 2.8295806981164664

Epoch: 5| Step: 8
Training loss: 0.6234885775644797
Validation loss: 2.8726774142815947

Epoch: 5| Step: 9
Training loss: 0.6276459238135007
Validation loss: 2.8581855954469484

Epoch: 5| Step: 10
Training loss: 0.6130737634029174
Validation loss: 2.888694792324083

Epoch: 5| Step: 11
Training loss: 0.5363238329621882
Validation loss: 2.855572898207429

Epoch: 542| Step: 0
Training loss: 0.6544282695872349
Validation loss: 2.8581602611823285

Epoch: 5| Step: 1
Training loss: 0.4820235302769107
Validation loss: 2.79265166396731

Epoch: 5| Step: 2
Training loss: 0.5662989547653832
Validation loss: 2.852745026950693

Epoch: 5| Step: 3
Training loss: 0.5532065757037241
Validation loss: 2.8585842477495094

Epoch: 5| Step: 4
Training loss: 0.6655217910053574
Validation loss: 2.8536723096278047

Epoch: 5| Step: 5
Training loss: 0.42084596665307705
Validation loss: 2.8225618147606464

Epoch: 5| Step: 6
Training loss: 0.82507124650976
Validation loss: 2.8454083229114286

Epoch: 5| Step: 7
Training loss: 0.3849410223684362
Validation loss: 2.8045062269535124

Epoch: 5| Step: 8
Training loss: 0.6448418302440421
Validation loss: 2.8609060451376362

Epoch: 5| Step: 9
Training loss: 0.5848179357418143
Validation loss: 2.853682143905248

Epoch: 5| Step: 10
Training loss: 0.46111652970800715
Validation loss: 2.8714639472606716

Epoch: 5| Step: 11
Training loss: 0.3020913462836716
Validation loss: 2.8288444496138947

Epoch: 543| Step: 0
Training loss: 0.5042802177059786
Validation loss: 2.892077783708332

Epoch: 5| Step: 1
Training loss: 0.4984081229757651
Validation loss: 2.8480826827362704

Epoch: 5| Step: 2
Training loss: 0.7388095479289382
Validation loss: 2.8881786338868904

Epoch: 5| Step: 3
Training loss: 0.45595346834641665
Validation loss: 2.7793938482920875

Epoch: 5| Step: 4
Training loss: 0.29723371617700844
Validation loss: 2.817981616227817

Epoch: 5| Step: 5
Training loss: 0.5246101453240051
Validation loss: 2.8172077232533463

Epoch: 5| Step: 6
Training loss: 0.6370354549296313
Validation loss: 2.840018041860108

Epoch: 5| Step: 7
Training loss: 0.521052978613488
Validation loss: 2.7912033904164915

Epoch: 5| Step: 8
Training loss: 0.4963535919933321
Validation loss: 2.8150039829115303

Epoch: 5| Step: 9
Training loss: 0.5750431189748012
Validation loss: 2.8580446848709604

Epoch: 5| Step: 10
Training loss: 0.7172187997807089
Validation loss: 2.8320886891119708

Epoch: 5| Step: 11
Training loss: 0.4814548143296478
Validation loss: 2.8353719401329665

Epoch: 544| Step: 0
Training loss: 0.5590369860230991
Validation loss: 2.8393027985428128

Epoch: 5| Step: 1
Training loss: 0.4898289679771582
Validation loss: 2.8716395510243684

Epoch: 5| Step: 2
Training loss: 0.5027264823382942
Validation loss: 2.8265736823056713

Epoch: 5| Step: 3
Training loss: 0.5432974005979089
Validation loss: 2.811637562516531

Epoch: 5| Step: 4
Training loss: 0.48208696114513966
Validation loss: 2.857895129444707

Epoch: 5| Step: 5
Training loss: 0.4421434913006075
Validation loss: 2.8596227812979294

Epoch: 5| Step: 6
Training loss: 0.3711613643686037
Validation loss: 2.803274143891024

Epoch: 5| Step: 7
Training loss: 0.5057638659950013
Validation loss: 2.829928501018434

Epoch: 5| Step: 8
Training loss: 0.39321373494501816
Validation loss: 2.83374574174913

Epoch: 5| Step: 9
Training loss: 0.6036816711144378
Validation loss: 2.779930923493358

Epoch: 5| Step: 10
Training loss: 0.8045573453362471
Validation loss: 2.8746846689533134

Epoch: 5| Step: 11
Training loss: 0.2686223031667934
Validation loss: 2.821574315427914

Epoch: 545| Step: 0
Training loss: 0.5850824602404268
Validation loss: 2.8037563361488753

Epoch: 5| Step: 1
Training loss: 0.6903881400420718
Validation loss: 2.8396748558589375

Epoch: 5| Step: 2
Training loss: 0.38586219176403347
Validation loss: 2.8962252863912212

Epoch: 5| Step: 3
Training loss: 0.3862558735089177
Validation loss: 2.862066385029517

Epoch: 5| Step: 4
Training loss: 0.7450630698293461
Validation loss: 2.885099518672078

Epoch: 5| Step: 5
Training loss: 0.5326142745013535
Validation loss: 2.8290301643011637

Epoch: 5| Step: 6
Training loss: 0.6525455779384323
Validation loss: 2.8457902115216616

Epoch: 5| Step: 7
Training loss: 0.5573459907745498
Validation loss: 2.850216329183368

Epoch: 5| Step: 8
Training loss: 0.4565579498607372
Validation loss: 2.8232655092655223

Epoch: 5| Step: 9
Training loss: 0.525910811310915
Validation loss: 2.8133098213477346

Epoch: 5| Step: 10
Training loss: 0.6763176525636377
Validation loss: 2.847102030618212

Epoch: 5| Step: 11
Training loss: 0.34184046876014157
Validation loss: 2.817102195476489

Epoch: 546| Step: 0
Training loss: 0.5462982951622773
Validation loss: 2.822998648622563

Epoch: 5| Step: 1
Training loss: 0.4766558727657311
Validation loss: 2.8331465531006295

Epoch: 5| Step: 2
Training loss: 0.3515274878127709
Validation loss: 2.849993172018338

Epoch: 5| Step: 3
Training loss: 0.44948422424311757
Validation loss: 2.8275134301759053

Epoch: 5| Step: 4
Training loss: 0.8013205224362981
Validation loss: 2.9009102746508573

Epoch: 5| Step: 5
Training loss: 0.43090024946182975
Validation loss: 2.822528401849399

Epoch: 5| Step: 6
Training loss: 0.756157946698254
Validation loss: 2.8143803174327746

Epoch: 5| Step: 7
Training loss: 0.5275889638936619
Validation loss: 2.853407391030123

Epoch: 5| Step: 8
Training loss: 0.4484548459037797
Validation loss: 2.8269813852802694

Epoch: 5| Step: 9
Training loss: 0.5891763056092933
Validation loss: 2.800168827479124

Epoch: 5| Step: 10
Training loss: 0.5221912293954444
Validation loss: 2.840742641456789

Epoch: 5| Step: 11
Training loss: 0.354097719587208
Validation loss: 2.787307742891474

Epoch: 547| Step: 0
Training loss: 0.5290846451948209
Validation loss: 2.7973570452661844

Epoch: 5| Step: 1
Training loss: 0.3932928534801472
Validation loss: 2.805507571898029

Epoch: 5| Step: 2
Training loss: 0.5705828613733177
Validation loss: 2.8263643098637754

Epoch: 5| Step: 3
Training loss: 0.8074799758979384
Validation loss: 2.854491898646184

Epoch: 5| Step: 4
Training loss: 0.4501298703769971
Validation loss: 2.8934848007498166

Epoch: 5| Step: 5
Training loss: 0.49928514221187087
Validation loss: 2.8660531706229158

Epoch: 5| Step: 6
Training loss: 0.6285012404157223
Validation loss: 2.892917826897386

Epoch: 5| Step: 7
Training loss: 0.4190509725147246
Validation loss: 2.856192827939409

Epoch: 5| Step: 8
Training loss: 0.5597360042766288
Validation loss: 2.86305786899047

Epoch: 5| Step: 9
Training loss: 0.3702381510078144
Validation loss: 2.8143256125683282

Epoch: 5| Step: 10
Training loss: 0.6077832192867585
Validation loss: 2.8572277595047617

Epoch: 5| Step: 11
Training loss: 0.5973764400333115
Validation loss: 2.857355033143128

Epoch: 548| Step: 0
Training loss: 0.4402905094132362
Validation loss: 2.878990686248964

Epoch: 5| Step: 1
Training loss: 0.5787124226937627
Validation loss: 2.8241042856576106

Epoch: 5| Step: 2
Training loss: 0.4696498181626504
Validation loss: 2.8640641186965055

Epoch: 5| Step: 3
Training loss: 0.49883484682768436
Validation loss: 2.8292824886268226

Epoch: 5| Step: 4
Training loss: 0.3976153324562495
Validation loss: 2.8678481634052937

Epoch: 5| Step: 5
Training loss: 0.6160435275360511
Validation loss: 2.8241181221565594

Epoch: 5| Step: 6
Training loss: 0.5259636799126726
Validation loss: 2.8594342453174404

Epoch: 5| Step: 7
Training loss: 0.7699869423539394
Validation loss: 2.8445635843958077

Epoch: 5| Step: 8
Training loss: 0.5292305429708495
Validation loss: 2.8336281424371235

Epoch: 5| Step: 9
Training loss: 0.6039379827100121
Validation loss: 2.861978405346941

Epoch: 5| Step: 10
Training loss: 0.4330589157596997
Validation loss: 2.799674879226542

Epoch: 5| Step: 11
Training loss: 0.6142219569380406
Validation loss: 2.8321193462130805

Epoch: 549| Step: 0
Training loss: 0.386750576366545
Validation loss: 2.8410339659786756

Epoch: 5| Step: 1
Training loss: 0.42824323859168867
Validation loss: 2.868978549022798

Epoch: 5| Step: 2
Training loss: 0.49667420558626857
Validation loss: 2.8062258957958317

Epoch: 5| Step: 3
Training loss: 0.6074787125566524
Validation loss: 2.8168032468227233

Epoch: 5| Step: 4
Training loss: 0.47885141852221413
Validation loss: 2.846725870044641

Epoch: 5| Step: 5
Training loss: 0.6417203238788157
Validation loss: 2.827100353897197

Epoch: 5| Step: 6
Training loss: 0.6576440400639433
Validation loss: 2.8221482794806656

Epoch: 5| Step: 7
Training loss: 0.6194062971643679
Validation loss: 2.8267186850096415

Epoch: 5| Step: 8
Training loss: 0.6993932666046462
Validation loss: 2.8275452049367655

Epoch: 5| Step: 9
Training loss: 0.6435929838371857
Validation loss: 2.817079309327941

Epoch: 5| Step: 10
Training loss: 0.536658579911539
Validation loss: 2.8409493946915605

Epoch: 5| Step: 11
Training loss: 0.6815492628894352
Validation loss: 2.8103439332011577

Epoch: 550| Step: 0
Training loss: 0.42067698518802993
Validation loss: 2.8506625423177048

Epoch: 5| Step: 1
Training loss: 0.6582697033814543
Validation loss: 2.824284286758691

Epoch: 5| Step: 2
Training loss: 0.5958531175232069
Validation loss: 2.8944220408619827

Epoch: 5| Step: 3
Training loss: 0.8498424692594904
Validation loss: 2.887142926248572

Epoch: 5| Step: 4
Training loss: 0.5493420132920375
Validation loss: 2.8526327972526193

Epoch: 5| Step: 5
Training loss: 0.5836493255013299
Validation loss: 2.818194664089649

Epoch: 5| Step: 6
Training loss: 0.538590985172923
Validation loss: 2.7910964487847174

Epoch: 5| Step: 7
Training loss: 0.6780595906086474
Validation loss: 2.7975783751187375

Epoch: 5| Step: 8
Training loss: 0.7583744285962373
Validation loss: 2.885343569071795

Epoch: 5| Step: 9
Training loss: 0.6982037300242978
Validation loss: 2.7781761127543008

Epoch: 5| Step: 10
Training loss: 0.667359793971898
Validation loss: 2.826701643825974

Epoch: 5| Step: 11
Training loss: 0.3578600672791909
Validation loss: 2.843570336755294

Testing loss: 2.5386128030004573
