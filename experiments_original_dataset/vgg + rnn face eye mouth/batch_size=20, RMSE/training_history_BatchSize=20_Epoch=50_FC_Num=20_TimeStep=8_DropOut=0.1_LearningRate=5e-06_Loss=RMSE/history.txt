Epoch: 1| Step: 0
Training loss: 5.6826009925497445
Validation loss: 5.901375637945833

Epoch: 5| Step: 1
Training loss: 5.862472488566511
Validation loss: 5.899991886219545

Epoch: 5| Step: 2
Training loss: 6.155247950451953
Validation loss: 5.89871816072671

Epoch: 5| Step: 3
Training loss: 5.602238357610154
Validation loss: 5.897439099965347

Epoch: 5| Step: 4
Training loss: 6.058912966082811
Validation loss: 5.8962268248719845

Epoch: 5| Step: 5
Training loss: 6.126484593677071
Validation loss: 5.895060730131409

Epoch: 5| Step: 6
Training loss: 6.424024978456118
Validation loss: 5.893816864831782

Epoch: 5| Step: 7
Training loss: 6.7834564697686455
Validation loss: 5.892574173324654

Epoch: 5| Step: 8
Training loss: 5.736125626852261
Validation loss: 5.891302783129842

Epoch: 5| Step: 9
Training loss: 6.1880227841017605
Validation loss: 5.889961515612865

Epoch: 5| Step: 10
Training loss: 5.685372761740553
Validation loss: 5.888529849303466

Epoch: 5| Step: 11
Training loss: 4.376064498007617
Validation loss: 5.887104915313216

Epoch: 2| Step: 0
Training loss: 5.566875836826397
Validation loss: 5.8856269011180995

Epoch: 5| Step: 1
Training loss: 6.103000603270934
Validation loss: 5.884086987562329

Epoch: 5| Step: 2
Training loss: 5.7238166752214354
Validation loss: 5.882468704505697

Epoch: 5| Step: 3
Training loss: 5.869417825712612
Validation loss: 5.880740154894521

Epoch: 5| Step: 4
Training loss: 5.670195023346481
Validation loss: 5.879041499106098

Epoch: 5| Step: 5
Training loss: 6.527987454701505
Validation loss: 5.877157680830474

Epoch: 5| Step: 6
Training loss: 6.529319952565409
Validation loss: 5.875259238130643

Epoch: 5| Step: 7
Training loss: 6.112508063125753
Validation loss: 5.873231296923098

Epoch: 5| Step: 8
Training loss: 5.517696348290957
Validation loss: 5.871107042627099

Epoch: 5| Step: 9
Training loss: 6.411207709125542
Validation loss: 5.868895761604687

Epoch: 5| Step: 10
Training loss: 5.903118938485341
Validation loss: 5.866643373305866

Epoch: 5| Step: 11
Training loss: 5.3406296928121755
Validation loss: 5.864144102715131

Epoch: 3| Step: 0
Training loss: 6.673372551761187
Validation loss: 5.86157737879051

Epoch: 5| Step: 1
Training loss: 5.835647269389607
Validation loss: 5.858959986930145

Epoch: 5| Step: 2
Training loss: 6.214569066545268
Validation loss: 5.856355158493752

Epoch: 5| Step: 3
Training loss: 5.657080489251079
Validation loss: 5.853308505039665

Epoch: 5| Step: 4
Training loss: 4.996339220782638
Validation loss: 5.850201926047596

Epoch: 5| Step: 5
Training loss: 6.106087895470146
Validation loss: 5.847041768601569

Epoch: 5| Step: 6
Training loss: 6.144014388921896
Validation loss: 5.843675194735796

Epoch: 5| Step: 7
Training loss: 6.480372505783961
Validation loss: 5.840106576301987

Epoch: 5| Step: 8
Training loss: 5.597851661311319
Validation loss: 5.836272564129007

Epoch: 5| Step: 9
Training loss: 5.5060284261472
Validation loss: 5.832266875828265

Epoch: 5| Step: 10
Training loss: 6.259138216900288
Validation loss: 5.828246884950728

Epoch: 5| Step: 11
Training loss: 5.532095117177401
Validation loss: 5.823915613115893

Epoch: 4| Step: 0
Training loss: 6.016042878140173
Validation loss: 5.819184496507785

Epoch: 5| Step: 1
Training loss: 5.4115250270969355
Validation loss: 5.814575815919204

Epoch: 5| Step: 2
Training loss: 5.719086850777691
Validation loss: 5.8096450165612525

Epoch: 5| Step: 3
Training loss: 5.82043014509878
Validation loss: 5.804512750349221

Epoch: 5| Step: 4
Training loss: 6.061020503467797
Validation loss: 5.799087540882062

Epoch: 5| Step: 5
Training loss: 5.996432833449751
Validation loss: 5.793594618067927

Epoch: 5| Step: 6
Training loss: 5.5438008990956265
Validation loss: 5.787670536151502

Epoch: 5| Step: 7
Training loss: 6.114244320605822
Validation loss: 5.78182948876848

Epoch: 5| Step: 8
Training loss: 6.62330980153056
Validation loss: 5.775556162686177

Epoch: 5| Step: 9
Training loss: 6.771952218749579
Validation loss: 5.769176219983888

Epoch: 5| Step: 10
Training loss: 4.852441876951176
Validation loss: 5.762612097498721

Epoch: 5| Step: 11
Training loss: 4.920027322460696
Validation loss: 5.755458756143831

Epoch: 5| Step: 0
Training loss: 5.578460939693715
Validation loss: 5.748598066062572

Epoch: 5| Step: 1
Training loss: 5.784452963560728
Validation loss: 5.741468035893688

Epoch: 5| Step: 2
Training loss: 5.870618444354006
Validation loss: 5.7342869667828245

Epoch: 5| Step: 3
Training loss: 5.671907955525815
Validation loss: 5.726901430766133

Epoch: 5| Step: 4
Training loss: 5.978912170877769
Validation loss: 5.719398350607351

Epoch: 5| Step: 5
Training loss: 6.057803822516838
Validation loss: 5.711967260615504

Epoch: 5| Step: 6
Training loss: 6.128234631979249
Validation loss: 5.704235007204328

Epoch: 5| Step: 7
Training loss: 6.2639026890743885
Validation loss: 5.696427391827705

Epoch: 5| Step: 8
Training loss: 5.943679324591311
Validation loss: 5.688539933928127

Epoch: 5| Step: 9
Training loss: 4.918843816422355
Validation loss: 5.680727311231935

Epoch: 5| Step: 10
Training loss: 5.771554435911478
Validation loss: 5.672967796735018

Epoch: 5| Step: 11
Training loss: 5.974153479459879
Validation loss: 5.66519264609659

Epoch: 6| Step: 0
Training loss: 5.8355021486713925
Validation loss: 5.65760291764073

Epoch: 5| Step: 1
Training loss: 5.803878789454992
Validation loss: 5.6496599562051415

Epoch: 5| Step: 2
Training loss: 5.164265823401326
Validation loss: 5.642048058326896

Epoch: 5| Step: 3
Training loss: 5.985591436114555
Validation loss: 5.63455506917002

Epoch: 5| Step: 4
Training loss: 5.525150880436381
Validation loss: 5.627267373483936

Epoch: 5| Step: 5
Training loss: 5.803202093759585
Validation loss: 5.620220301146458

Epoch: 5| Step: 6
Training loss: 5.691726623189575
Validation loss: 5.613182574922198

Epoch: 5| Step: 7
Training loss: 6.135720971359349
Validation loss: 5.6066629269769255

Epoch: 5| Step: 8
Training loss: 5.890385063809595
Validation loss: 5.599934269031135

Epoch: 5| Step: 9
Training loss: 5.887066401168546
Validation loss: 5.593472905461733

Epoch: 5| Step: 10
Training loss: 5.146095032414539
Validation loss: 5.587077062360861

Epoch: 5| Step: 11
Training loss: 6.61076783999606
Validation loss: 5.580919543454801

Epoch: 7| Step: 0
Training loss: 6.07245440111437
Validation loss: 5.575155327861194

Epoch: 5| Step: 1
Training loss: 4.4663674999275615
Validation loss: 5.569142122802048

Epoch: 5| Step: 2
Training loss: 5.516715917146545
Validation loss: 5.5637145627350995

Epoch: 5| Step: 3
Training loss: 5.926022649788033
Validation loss: 5.55803108003576

Epoch: 5| Step: 4
Training loss: 6.637643229920171
Validation loss: 5.552826130927721

Epoch: 5| Step: 5
Training loss: 6.1212950419598835
Validation loss: 5.547516054173476

Epoch: 5| Step: 6
Training loss: 5.880788345946844
Validation loss: 5.542422016072944

Epoch: 5| Step: 7
Training loss: 5.29163418657242
Validation loss: 5.537162286235384

Epoch: 5| Step: 8
Training loss: 5.463143401150404
Validation loss: 5.532077461605984

Epoch: 5| Step: 9
Training loss: 5.566907529512115
Validation loss: 5.5271436531503335

Epoch: 5| Step: 10
Training loss: 5.468013692061521
Validation loss: 5.5219975977271485

Epoch: 5| Step: 11
Training loss: 3.707311139328484
Validation loss: 5.517138373481135

Epoch: 8| Step: 0
Training loss: 5.6781085940487745
Validation loss: 5.5123211382554755

Epoch: 5| Step: 1
Training loss: 5.241943535621082
Validation loss: 5.507508614455874

Epoch: 5| Step: 2
Training loss: 5.010882170288154
Validation loss: 5.502591194634614

Epoch: 5| Step: 3
Training loss: 5.545413230310024
Validation loss: 5.49777479385013

Epoch: 5| Step: 4
Training loss: 6.068246536507234
Validation loss: 5.493118713643829

Epoch: 5| Step: 5
Training loss: 5.141184489405293
Validation loss: 5.4882700565898235

Epoch: 5| Step: 6
Training loss: 5.556765568674377
Validation loss: 5.483265024511432

Epoch: 5| Step: 7
Training loss: 6.412642401885738
Validation loss: 5.478318074971765

Epoch: 5| Step: 8
Training loss: 5.644816946435434
Validation loss: 5.473160961184431

Epoch: 5| Step: 9
Training loss: 4.940912540182869
Validation loss: 5.467888726124267

Epoch: 5| Step: 10
Training loss: 6.039053656607368
Validation loss: 5.463035977079803

Epoch: 5| Step: 11
Training loss: 6.649852848576038
Validation loss: 5.458024491849831

Epoch: 9| Step: 0
Training loss: 5.6441032696203965
Validation loss: 5.452536732478349

Epoch: 5| Step: 1
Training loss: 5.4540472699009905
Validation loss: 5.447531227593028

Epoch: 5| Step: 2
Training loss: 5.093276112985664
Validation loss: 5.442443763350081

Epoch: 5| Step: 3
Training loss: 6.566321432007231
Validation loss: 5.437452944555602

Epoch: 5| Step: 4
Training loss: 5.063781952730086
Validation loss: 5.4323548056961535

Epoch: 5| Step: 5
Training loss: 5.366210848640809
Validation loss: 5.427445129323335

Epoch: 5| Step: 6
Training loss: 5.441066580725573
Validation loss: 5.422829462445213

Epoch: 5| Step: 7
Training loss: 5.5302226518781055
Validation loss: 5.417438322513315

Epoch: 5| Step: 8
Training loss: 5.816697440662608
Validation loss: 5.412714487161896

Epoch: 5| Step: 9
Training loss: 5.913540332071237
Validation loss: 5.407901643923768

Epoch: 5| Step: 10
Training loss: 4.6319334280075894
Validation loss: 5.403144561926321

Epoch: 5| Step: 11
Training loss: 6.88401619369668
Validation loss: 5.3982320434514754

Epoch: 10| Step: 0
Training loss: 4.454006174810384
Validation loss: 5.393857618770748

Epoch: 5| Step: 1
Training loss: 6.412931800269074
Validation loss: 5.389065908635729

Epoch: 5| Step: 2
Training loss: 6.047530737519259
Validation loss: 5.384615318941109

Epoch: 5| Step: 3
Training loss: 5.081546323424532
Validation loss: 5.379883137489023

Epoch: 5| Step: 4
Training loss: 5.2952865874601125
Validation loss: 5.375502828986696

Epoch: 5| Step: 5
Training loss: 5.549808382042805
Validation loss: 5.370970361390479

Epoch: 5| Step: 6
Training loss: 5.112761981845802
Validation loss: 5.3662879556503835

Epoch: 5| Step: 7
Training loss: 5.378542597604222
Validation loss: 5.3620375830303

Epoch: 5| Step: 8
Training loss: 5.426667044324807
Validation loss: 5.357116304816187

Epoch: 5| Step: 9
Training loss: 6.061109875054276
Validation loss: 5.352418824527157

Epoch: 5| Step: 10
Training loss: 5.4181438877041845
Validation loss: 5.347542054931049

Epoch: 5| Step: 11
Training loss: 5.122642533128463
Validation loss: 5.343134214380137

Epoch: 11| Step: 0
Training loss: 5.729996758638167
Validation loss: 5.338096610025306

Epoch: 5| Step: 1
Training loss: 5.396089918401166
Validation loss: 5.333322348682694

Epoch: 5| Step: 2
Training loss: 4.9324440481083744
Validation loss: 5.3288951328387

Epoch: 5| Step: 3
Training loss: 5.427098640913313
Validation loss: 5.324765090357664

Epoch: 5| Step: 4
Training loss: 5.089149691262591
Validation loss: 5.320645262646271

Epoch: 5| Step: 5
Training loss: 4.874159129078181
Validation loss: 5.316433561032095

Epoch: 5| Step: 6
Training loss: 5.5289698496986714
Validation loss: 5.312121276819695

Epoch: 5| Step: 7
Training loss: 4.9817296963828
Validation loss: 5.307952774795038

Epoch: 5| Step: 8
Training loss: 5.562390787145478
Validation loss: 5.3038493539730265

Epoch: 5| Step: 9
Training loss: 5.810428701529401
Validation loss: 5.300164640616478

Epoch: 5| Step: 10
Training loss: 6.142008307731771
Validation loss: 5.295744333587339

Epoch: 5| Step: 11
Training loss: 6.434263137801006
Validation loss: 5.291352280216164

Epoch: 12| Step: 0
Training loss: 5.7381619206661645
Validation loss: 5.286780101085103

Epoch: 5| Step: 1
Training loss: 5.833604134223046
Validation loss: 5.28220751507358

Epoch: 5| Step: 2
Training loss: 5.526131195675804
Validation loss: 5.277233861479856

Epoch: 5| Step: 3
Training loss: 5.385831697607267
Validation loss: 5.272359132122407

Epoch: 5| Step: 4
Training loss: 4.736582427129212
Validation loss: 5.267773266417805

Epoch: 5| Step: 5
Training loss: 5.872360610574337
Validation loss: 5.262912183492961

Epoch: 5| Step: 6
Training loss: 5.50452445073241
Validation loss: 5.25828410315504

Epoch: 5| Step: 7
Training loss: 5.463553264691674
Validation loss: 5.252914096789991

Epoch: 5| Step: 8
Training loss: 4.867985496192207
Validation loss: 5.247667854269371

Epoch: 5| Step: 9
Training loss: 6.025189294650995
Validation loss: 5.243210368225204

Epoch: 5| Step: 10
Training loss: 4.130130005422872
Validation loss: 5.238221352367745

Epoch: 5| Step: 11
Training loss: 4.732207655141714
Validation loss: 5.2337563144332035

Epoch: 13| Step: 0
Training loss: 5.377657033985237
Validation loss: 5.228861061477343

Epoch: 5| Step: 1
Training loss: 5.9758367359579205
Validation loss: 5.224562159054562

Epoch: 5| Step: 2
Training loss: 4.377337240159469
Validation loss: 5.218580033814348

Epoch: 5| Step: 3
Training loss: 4.450993613422571
Validation loss: 5.214147361710285

Epoch: 5| Step: 4
Training loss: 5.562644356558203
Validation loss: 5.209323646492141

Epoch: 5| Step: 5
Training loss: 5.956154840755951
Validation loss: 5.204474257986357

Epoch: 5| Step: 6
Training loss: 4.7365822257869254
Validation loss: 5.199461295271561

Epoch: 5| Step: 7
Training loss: 5.068943397228523
Validation loss: 5.194535107878199

Epoch: 5| Step: 8
Training loss: 5.960907742287289
Validation loss: 5.189717757072765

Epoch: 5| Step: 9
Training loss: 5.5545122035784695
Validation loss: 5.185385828576577

Epoch: 5| Step: 10
Training loss: 5.05631415063552
Validation loss: 5.181296174043416

Epoch: 5| Step: 11
Training loss: 6.2987278940668725
Validation loss: 5.175986331739367

Epoch: 14| Step: 0
Training loss: 4.801672111772078
Validation loss: 5.171533778863452

Epoch: 5| Step: 1
Training loss: 5.524913887284947
Validation loss: 5.167272926980175

Epoch: 5| Step: 2
Training loss: 5.733863412763725
Validation loss: 5.16252538106743

Epoch: 5| Step: 3
Training loss: 5.406947096495108
Validation loss: 5.156907134134163

Epoch: 5| Step: 4
Training loss: 5.211223908979214
Validation loss: 5.152601018251929

Epoch: 5| Step: 5
Training loss: 4.711072929295576
Validation loss: 5.148302098656267

Epoch: 5| Step: 6
Training loss: 4.540481319372679
Validation loss: 5.143592519037368

Epoch: 5| Step: 7
Training loss: 5.507254584442355
Validation loss: 5.13906544505215

Epoch: 5| Step: 8
Training loss: 4.615813333211253
Validation loss: 5.134588862225798

Epoch: 5| Step: 9
Training loss: 5.702840719584339
Validation loss: 5.1299631308680125

Epoch: 5| Step: 10
Training loss: 5.711438116631172
Validation loss: 5.125046535993983

Epoch: 5| Step: 11
Training loss: 6.682249771268299
Validation loss: 5.120738785597451

Epoch: 15| Step: 0
Training loss: 4.902466888704975
Validation loss: 5.117520573383193

Epoch: 5| Step: 1
Training loss: 4.731749558877715
Validation loss: 5.11433273550943

Epoch: 5| Step: 2
Training loss: 5.021552745304678
Validation loss: 5.10870888166041

Epoch: 5| Step: 3
Training loss: 4.773133613166066
Validation loss: 5.102110034482825

Epoch: 5| Step: 4
Training loss: 4.967109265330827
Validation loss: 5.097487597641412

Epoch: 5| Step: 5
Training loss: 5.385556345246714
Validation loss: 5.09393135481254

Epoch: 5| Step: 6
Training loss: 5.096447750967798
Validation loss: 5.089598768129912

Epoch: 5| Step: 7
Training loss: 5.275955345097871
Validation loss: 5.083877091430505

Epoch: 5| Step: 8
Training loss: 6.10169222763419
Validation loss: 5.07898443529879

Epoch: 5| Step: 9
Training loss: 5.680752283165105
Validation loss: 5.075334762468984

Epoch: 5| Step: 10
Training loss: 5.220160562084782
Validation loss: 5.070996450445645

Epoch: 5| Step: 11
Training loss: 5.558964666669793
Validation loss: 5.06577653385647

Epoch: 16| Step: 0
Training loss: 5.448414164111107
Validation loss: 5.0598922810629565

Epoch: 5| Step: 1
Training loss: 5.02793424349981
Validation loss: 5.055499130092502

Epoch: 5| Step: 2
Training loss: 4.720407359114923
Validation loss: 5.051329018298021

Epoch: 5| Step: 3
Training loss: 4.875951429592998
Validation loss: 5.047646100450734

Epoch: 5| Step: 4
Training loss: 5.8824973458909495
Validation loss: 5.042861941285258

Epoch: 5| Step: 5
Training loss: 5.170475243099221
Validation loss: 5.036704240520366

Epoch: 5| Step: 6
Training loss: 5.172996929445799
Validation loss: 5.033153608199706

Epoch: 5| Step: 7
Training loss: 5.694374708456803
Validation loss: 5.029305400162172

Epoch: 5| Step: 8
Training loss: 4.108810095885758
Validation loss: 5.023618632561645

Epoch: 5| Step: 9
Training loss: 5.849159715083748
Validation loss: 5.018892002590816

Epoch: 5| Step: 10
Training loss: 4.6789087529604885
Validation loss: 5.013440417940975

Epoch: 5| Step: 11
Training loss: 4.48328389042437
Validation loss: 5.008127338512501

Epoch: 17| Step: 0
Training loss: 5.380120787842264
Validation loss: 5.004024594545593

Epoch: 5| Step: 1
Training loss: 5.063902295717335
Validation loss: 4.999021410545777

Epoch: 5| Step: 2
Training loss: 5.203492114430128
Validation loss: 4.993450985941286

Epoch: 5| Step: 3
Training loss: 5.5072107730372215
Validation loss: 4.988933125327873

Epoch: 5| Step: 4
Training loss: 4.861667104744371
Validation loss: 4.984198492386838

Epoch: 5| Step: 5
Training loss: 4.909392110016532
Validation loss: 4.979863348175006

Epoch: 5| Step: 6
Training loss: 5.582889861908892
Validation loss: 4.974657389730226

Epoch: 5| Step: 7
Training loss: 5.245397457631346
Validation loss: 4.9698418271373095

Epoch: 5| Step: 8
Training loss: 4.669843455270049
Validation loss: 4.965291729116809

Epoch: 5| Step: 9
Training loss: 4.884790029239818
Validation loss: 4.960257327893001

Epoch: 5| Step: 10
Training loss: 4.728017233195905
Validation loss: 4.955059688515272

Epoch: 5| Step: 11
Training loss: 5.226566149335422
Validation loss: 4.949938161059118

Epoch: 18| Step: 0
Training loss: 5.513228200965642
Validation loss: 4.946212268872137

Epoch: 5| Step: 1
Training loss: 5.229662057377609
Validation loss: 4.9413594843042405

Epoch: 5| Step: 2
Training loss: 4.727275901740016
Validation loss: 4.9365411141189455

Epoch: 5| Step: 3
Training loss: 5.007883151741764
Validation loss: 4.9314378068468905

Epoch: 5| Step: 4
Training loss: 5.066670148413282
Validation loss: 4.926605696105162

Epoch: 5| Step: 5
Training loss: 4.807731743284026
Validation loss: 4.921557812839587

Epoch: 5| Step: 6
Training loss: 5.640437495530929
Validation loss: 4.917259284312596

Epoch: 5| Step: 7
Training loss: 3.9140741953418083
Validation loss: 4.912351285060163

Epoch: 5| Step: 8
Training loss: 4.832581077878319
Validation loss: 4.90736472066605

Epoch: 5| Step: 9
Training loss: 5.773177495942612
Validation loss: 4.90285053445337

Epoch: 5| Step: 10
Training loss: 4.977540307870896
Validation loss: 4.897819037892987

Epoch: 5| Step: 11
Training loss: 3.7630066692081323
Validation loss: 4.8929975562090515

Epoch: 19| Step: 0
Training loss: 3.9234500473107436
Validation loss: 4.889362265627037

Epoch: 5| Step: 1
Training loss: 5.711734324754787
Validation loss: 4.884941267729664

Epoch: 5| Step: 2
Training loss: 4.955149721102776
Validation loss: 4.88053398172185

Epoch: 5| Step: 3
Training loss: 4.764972779715605
Validation loss: 4.875278709465193

Epoch: 5| Step: 4
Training loss: 5.163940243565114
Validation loss: 4.870724906508622

Epoch: 5| Step: 5
Training loss: 5.056842421258299
Validation loss: 4.866000737501288

Epoch: 5| Step: 6
Training loss: 5.46453712590245
Validation loss: 4.861727881889139

Epoch: 5| Step: 7
Training loss: 5.150003059164083
Validation loss: 4.856176503270484

Epoch: 5| Step: 8
Training loss: 5.081076365902486
Validation loss: 4.850532016873015

Epoch: 5| Step: 9
Training loss: 3.9616450593835495
Validation loss: 4.846157829110695

Epoch: 5| Step: 10
Training loss: 5.506000713200078
Validation loss: 4.841144328521555

Epoch: 5| Step: 11
Training loss: 4.063936185065432
Validation loss: 4.836146319866954

Epoch: 20| Step: 0
Training loss: 4.726557859308156
Validation loss: 4.831281344240934

Epoch: 5| Step: 1
Training loss: 4.679662229950553
Validation loss: 4.826663951521755

Epoch: 5| Step: 2
Training loss: 4.82283357201242
Validation loss: 4.821050330871988

Epoch: 5| Step: 3
Training loss: 5.035139014286346
Validation loss: 4.816231622595683

Epoch: 5| Step: 4
Training loss: 4.72108937057653
Validation loss: 4.811209930969297

Epoch: 5| Step: 5
Training loss: 5.208142310136296
Validation loss: 4.805827407215888

Epoch: 5| Step: 6
Training loss: 5.620797515973705
Validation loss: 4.8015660678309455

Epoch: 5| Step: 7
Training loss: 5.282404485616205
Validation loss: 4.796234717697255

Epoch: 5| Step: 8
Training loss: 4.963498969626605
Validation loss: 4.790958707450362

Epoch: 5| Step: 9
Training loss: 4.930134748431863
Validation loss: 4.785805943817155

Epoch: 5| Step: 10
Training loss: 4.104120296209861
Validation loss: 4.779898616654649

Epoch: 5| Step: 11
Training loss: 4.945687567542765
Validation loss: 4.774779685165601

Epoch: 21| Step: 0
Training loss: 4.086246515262643
Validation loss: 4.7713782847422

Epoch: 5| Step: 1
Training loss: 5.512246975098044
Validation loss: 4.765578689767091

Epoch: 5| Step: 2
Training loss: 4.633607844355566
Validation loss: 4.7594913512694115

Epoch: 5| Step: 3
Training loss: 4.811426414531979
Validation loss: 4.753783108180258

Epoch: 5| Step: 4
Training loss: 5.031786208870785
Validation loss: 4.748930727083607

Epoch: 5| Step: 5
Training loss: 5.510598288453269
Validation loss: 4.744428780584711

Epoch: 5| Step: 6
Training loss: 5.443379698114196
Validation loss: 4.738682712321055

Epoch: 5| Step: 7
Training loss: 4.450995327510194
Validation loss: 4.73311676326908

Epoch: 5| Step: 8
Training loss: 3.996475335749356
Validation loss: 4.727351292558078

Epoch: 5| Step: 9
Training loss: 4.959524166601716
Validation loss: 4.7219192186393615

Epoch: 5| Step: 10
Training loss: 4.821654295304944
Validation loss: 4.716456380049762

Epoch: 5| Step: 11
Training loss: 5.034538568530632
Validation loss: 4.7120664392055405

Epoch: 22| Step: 0
Training loss: 5.235859128160012
Validation loss: 4.706172390956896

Epoch: 5| Step: 1
Training loss: 5.614972650150531
Validation loss: 4.701919764540124

Epoch: 5| Step: 2
Training loss: 5.226369264049767
Validation loss: 4.694215685570818

Epoch: 5| Step: 3
Training loss: 4.088147238720614
Validation loss: 4.6889436745092095

Epoch: 5| Step: 4
Training loss: 5.129348956581507
Validation loss: 4.683978873298338

Epoch: 5| Step: 5
Training loss: 4.929877082576847
Validation loss: 4.678358917911552

Epoch: 5| Step: 6
Training loss: 4.4220074205823705
Validation loss: 4.672134664372556

Epoch: 5| Step: 7
Training loss: 3.792853466603794
Validation loss: 4.666265933110684

Epoch: 5| Step: 8
Training loss: 4.501847205912353
Validation loss: 4.660536915446051

Epoch: 5| Step: 9
Training loss: 5.165518643391446
Validation loss: 4.656347107354706

Epoch: 5| Step: 10
Training loss: 4.539876369187796
Validation loss: 4.649738888262894

Epoch: 5| Step: 11
Training loss: 4.271617885573517
Validation loss: 4.644153815981307

Epoch: 23| Step: 0
Training loss: 5.106099703384982
Validation loss: 4.6394708741696915

Epoch: 5| Step: 1
Training loss: 4.341251230895979
Validation loss: 4.633526130079529

Epoch: 5| Step: 2
Training loss: 5.093497989715932
Validation loss: 4.62815482134058

Epoch: 5| Step: 3
Training loss: 4.604240635526556
Validation loss: 4.623051868860953

Epoch: 5| Step: 4
Training loss: 5.501654982825516
Validation loss: 4.617342124970435

Epoch: 5| Step: 5
Training loss: 3.681456057832215
Validation loss: 4.611061580741752

Epoch: 5| Step: 6
Training loss: 4.195389560439265
Validation loss: 4.605777021578842

Epoch: 5| Step: 7
Training loss: 4.354964893431687
Validation loss: 4.600672369690084

Epoch: 5| Step: 8
Training loss: 4.840582618010678
Validation loss: 4.594996631345735

Epoch: 5| Step: 9
Training loss: 4.637204537657603
Validation loss: 4.590739502851848

Epoch: 5| Step: 10
Training loss: 5.202827880440714
Validation loss: 4.586070273804346

Epoch: 5| Step: 11
Training loss: 5.961858315796906
Validation loss: 4.579065566932614

Epoch: 24| Step: 0
Training loss: 4.858830166904408
Validation loss: 4.574773522974574

Epoch: 5| Step: 1
Training loss: 4.385842538966866
Validation loss: 4.572035627135634

Epoch: 5| Step: 2
Training loss: 4.498221787808971
Validation loss: 4.564684366732763

Epoch: 5| Step: 3
Training loss: 5.422785349997586
Validation loss: 4.556848649063138

Epoch: 5| Step: 4
Training loss: 4.812967649254817
Validation loss: 4.551460492655999

Epoch: 5| Step: 5
Training loss: 5.1812706738693395
Validation loss: 4.548230881203986

Epoch: 5| Step: 6
Training loss: 4.193644783530738
Validation loss: 4.540652015922463

Epoch: 5| Step: 7
Training loss: 4.418825857328784
Validation loss: 4.533391678775923

Epoch: 5| Step: 8
Training loss: 4.6396516235058
Validation loss: 4.528106142526503

Epoch: 5| Step: 9
Training loss: 4.913660369575727
Validation loss: 4.521344963105084

Epoch: 5| Step: 10
Training loss: 4.073723884585429
Validation loss: 4.51625699875162

Epoch: 5| Step: 11
Training loss: 3.810076083727718
Validation loss: 4.511132783255694

Epoch: 25| Step: 0
Training loss: 4.637348495435213
Validation loss: 4.508188955894411

Epoch: 5| Step: 1
Training loss: 4.8684025651518334
Validation loss: 4.5019418314959685

Epoch: 5| Step: 2
Training loss: 4.033523746335933
Validation loss: 4.495289412160629

Epoch: 5| Step: 3
Training loss: 5.015728435459923
Validation loss: 4.490433316706815

Epoch: 5| Step: 4
Training loss: 4.516099739858672
Validation loss: 4.484595445094803

Epoch: 5| Step: 5
Training loss: 4.431024258866794
Validation loss: 4.479041105181274

Epoch: 5| Step: 6
Training loss: 4.389949217135469
Validation loss: 4.472192625312462

Epoch: 5| Step: 7
Training loss: 4.970654776287455
Validation loss: 4.466662446181358

Epoch: 5| Step: 8
Training loss: 4.718979179425314
Validation loss: 4.462833186586181

Epoch: 5| Step: 9
Training loss: 4.814311293549802
Validation loss: 4.456012374227819

Epoch: 5| Step: 10
Training loss: 3.9335805368059487
Validation loss: 4.449399051914722

Epoch: 5| Step: 11
Training loss: 5.5663822642027085
Validation loss: 4.443492246324936

Epoch: 26| Step: 0
Training loss: 4.859223685407897
Validation loss: 4.438590430662008

Epoch: 5| Step: 1
Training loss: 3.6543343244924342
Validation loss: 4.432099759182992

Epoch: 5| Step: 2
Training loss: 4.064518823051439
Validation loss: 4.426302155032375

Epoch: 5| Step: 3
Training loss: 5.2091588497799926
Validation loss: 4.420329116892536

Epoch: 5| Step: 4
Training loss: 4.932909219571172
Validation loss: 4.415659423751537

Epoch: 5| Step: 5
Training loss: 4.647381420541374
Validation loss: 4.410578249982276

Epoch: 5| Step: 6
Training loss: 4.331468963592878
Validation loss: 4.404413945459968

Epoch: 5| Step: 7
Training loss: 4.696388464098012
Validation loss: 4.398242085589529

Epoch: 5| Step: 8
Training loss: 3.9633175172054407
Validation loss: 4.392471617496786

Epoch: 5| Step: 9
Training loss: 4.531195699432185
Validation loss: 4.386767293424247

Epoch: 5| Step: 10
Training loss: 4.512449844377493
Validation loss: 4.383062504003213

Epoch: 5| Step: 11
Training loss: 5.8265938473362295
Validation loss: 4.376440074606124

Epoch: 27| Step: 0
Training loss: 4.595646058201256
Validation loss: 4.370014524479348

Epoch: 5| Step: 1
Training loss: 4.3891568698970485
Validation loss: 4.36559375304843

Epoch: 5| Step: 2
Training loss: 3.816556179885048
Validation loss: 4.357434049184935

Epoch: 5| Step: 3
Training loss: 3.7386294594390272
Validation loss: 4.352494839061385

Epoch: 5| Step: 4
Training loss: 5.19538445673853
Validation loss: 4.347420420138598

Epoch: 5| Step: 5
Training loss: 4.987938064802496
Validation loss: 4.342793983803747

Epoch: 5| Step: 6
Training loss: 3.0567287639548852
Validation loss: 4.3358835532008495

Epoch: 5| Step: 7
Training loss: 4.519938484380942
Validation loss: 4.3310462650531125

Epoch: 5| Step: 8
Training loss: 5.105655541246332
Validation loss: 4.324533847905871

Epoch: 5| Step: 9
Training loss: 4.441183790877774
Validation loss: 4.318864378493335

Epoch: 5| Step: 10
Training loss: 4.965363506060201
Validation loss: 4.314720650917142

Epoch: 5| Step: 11
Training loss: 3.7919574807676453
Validation loss: 4.309213348779588

Epoch: 28| Step: 0
Training loss: 4.6649761998263495
Validation loss: 4.306119068076444

Epoch: 5| Step: 1
Training loss: 4.580762708699088
Validation loss: 4.2985127327705905

Epoch: 5| Step: 2
Training loss: 4.445118127203699
Validation loss: 4.291738674646109

Epoch: 5| Step: 3
Training loss: 4.660586801673959
Validation loss: 4.2873578230599785

Epoch: 5| Step: 4
Training loss: 4.12040801648211
Validation loss: 4.283023216410863

Epoch: 5| Step: 5
Training loss: 4.4049011763226815
Validation loss: 4.277118327385842

Epoch: 5| Step: 6
Training loss: 4.446374535027083
Validation loss: 4.270761013194035

Epoch: 5| Step: 7
Training loss: 4.565213376392944
Validation loss: 4.266434505350222

Epoch: 5| Step: 8
Training loss: 4.74184963273332
Validation loss: 4.261827546154933

Epoch: 5| Step: 9
Training loss: 4.2233524789554355
Validation loss: 4.255414272197987

Epoch: 5| Step: 10
Training loss: 3.660418229309918
Validation loss: 4.249480860923669

Epoch: 5| Step: 11
Training loss: 3.6544494107745757
Validation loss: 4.244012073782508

Epoch: 29| Step: 0
Training loss: 4.827030391125644
Validation loss: 4.239974009378715

Epoch: 5| Step: 1
Training loss: 3.709193669219936
Validation loss: 4.234742274198138

Epoch: 5| Step: 2
Training loss: 4.547959031335705
Validation loss: 4.229424636314293

Epoch: 5| Step: 3
Training loss: 4.147051506051939
Validation loss: 4.2239759596124875

Epoch: 5| Step: 4
Training loss: 4.302479698758327
Validation loss: 4.218019445766688

Epoch: 5| Step: 5
Training loss: 3.252845398891087
Validation loss: 4.213124020707509

Epoch: 5| Step: 6
Training loss: 4.529271186995935
Validation loss: 4.208740430284193

Epoch: 5| Step: 7
Training loss: 4.491300438911693
Validation loss: 4.203998715940401

Epoch: 5| Step: 8
Training loss: 4.628257429145913
Validation loss: 4.197450941706797

Epoch: 5| Step: 9
Training loss: 3.620821945705146
Validation loss: 4.19303836668763

Epoch: 5| Step: 10
Training loss: 5.093398567667389
Validation loss: 4.187610434978544

Epoch: 5| Step: 11
Training loss: 5.53215648744785
Validation loss: 4.186784521821186

Epoch: 30| Step: 0
Training loss: 4.624309385132953
Validation loss: 4.179820344424061

Epoch: 5| Step: 1
Training loss: 4.547817905883889
Validation loss: 4.172064139927972

Epoch: 5| Step: 2
Training loss: 4.690537142709115
Validation loss: 4.167273876132695

Epoch: 5| Step: 3
Training loss: 3.420020031786695
Validation loss: 4.164245219751569

Epoch: 5| Step: 4
Training loss: 4.257639806202534
Validation loss: 4.159070475316974

Epoch: 5| Step: 5
Training loss: 3.8603452628885484
Validation loss: 4.152593758856819

Epoch: 5| Step: 6
Training loss: 4.668837564609837
Validation loss: 4.1453368003028475

Epoch: 5| Step: 7
Training loss: 4.568084643299597
Validation loss: 4.140968764328176

Epoch: 5| Step: 8
Training loss: 4.1964025803894485
Validation loss: 4.137195385594214

Epoch: 5| Step: 9
Training loss: 3.492989876755123
Validation loss: 4.130373383439586

Epoch: 5| Step: 10
Training loss: 4.623724478027
Validation loss: 4.124024232416711

Epoch: 5| Step: 11
Training loss: 3.792423857375288
Validation loss: 4.118498350414103

Epoch: 31| Step: 0
Training loss: 5.231843524109508
Validation loss: 4.114240929887131

Epoch: 5| Step: 1
Training loss: 4.491875838373461
Validation loss: 4.109251883515452

Epoch: 5| Step: 2
Training loss: 3.981634296931288
Validation loss: 4.1037152650455155

Epoch: 5| Step: 3
Training loss: 3.7499813079368125
Validation loss: 4.0984827498452665

Epoch: 5| Step: 4
Training loss: 4.000555476720009
Validation loss: 4.0931163520700276

Epoch: 5| Step: 5
Training loss: 3.942542707155079
Validation loss: 4.088157167598277

Epoch: 5| Step: 6
Training loss: 4.124137325823544
Validation loss: 4.083796497598305

Epoch: 5| Step: 7
Training loss: 4.573502117152739
Validation loss: 4.078758102909308

Epoch: 5| Step: 8
Training loss: 4.434081789287035
Validation loss: 4.074085939314611

Epoch: 5| Step: 9
Training loss: 3.826278801865396
Validation loss: 4.068320530708878

Epoch: 5| Step: 10
Training loss: 3.6790677660346507
Validation loss: 4.062511404950688

Epoch: 5| Step: 11
Training loss: 4.92733258617631
Validation loss: 4.0577144949300985

Epoch: 32| Step: 0
Training loss: 4.483504260656196
Validation loss: 4.05237136379365

Epoch: 5| Step: 1
Training loss: 4.94076121345772
Validation loss: 4.047580844000297

Epoch: 5| Step: 2
Training loss: 3.9327744480212425
Validation loss: 4.042741852073958

Epoch: 5| Step: 3
Training loss: 4.312733077232926
Validation loss: 4.03739515036543

Epoch: 5| Step: 4
Training loss: 3.5854457277002787
Validation loss: 4.032481141082754

Epoch: 5| Step: 5
Training loss: 4.147160507757038
Validation loss: 4.026868602844901

Epoch: 5| Step: 6
Training loss: 3.753155461552199
Validation loss: 4.021939568543459

Epoch: 5| Step: 7
Training loss: 3.962139962864405
Validation loss: 4.01649141921929

Epoch: 5| Step: 8
Training loss: 3.863279028294988
Validation loss: 4.011603363962957

Epoch: 5| Step: 9
Training loss: 4.169620890776851
Validation loss: 4.006888091500768

Epoch: 5| Step: 10
Training loss: 4.502390544435703
Validation loss: 4.001637327345368

Epoch: 5| Step: 11
Training loss: 3.787959679635714
Validation loss: 3.9973532841144057

Epoch: 33| Step: 0
Training loss: 4.287979294926203
Validation loss: 3.991383560563176

Epoch: 5| Step: 1
Training loss: 4.238446407352351
Validation loss: 3.986612038514516

Epoch: 5| Step: 2
Training loss: 3.815169603569926
Validation loss: 3.9812080413028608

Epoch: 5| Step: 3
Training loss: 3.9842259996266622
Validation loss: 3.9775484033305237

Epoch: 5| Step: 4
Training loss: 4.627906710713958
Validation loss: 3.9712121289810614

Epoch: 5| Step: 5
Training loss: 3.867808898938899
Validation loss: 3.965562281151441

Epoch: 5| Step: 6
Training loss: 3.716580054353066
Validation loss: 3.960354548286022

Epoch: 5| Step: 7
Training loss: 4.014851417690066
Validation loss: 3.9545275897619394

Epoch: 5| Step: 8
Training loss: 3.9052582969667746
Validation loss: 3.948666386473289

Epoch: 5| Step: 9
Training loss: 4.226865746977156
Validation loss: 3.942810307556786

Epoch: 5| Step: 10
Training loss: 4.27713193325421
Validation loss: 3.9366522537412276

Epoch: 5| Step: 11
Training loss: 4.235880566491929
Validation loss: 3.931596791426846

Epoch: 34| Step: 0
Training loss: 4.152658387803049
Validation loss: 3.92658899199392

Epoch: 5| Step: 1
Training loss: 3.5993962258429946
Validation loss: 3.921312552721186

Epoch: 5| Step: 2
Training loss: 4.131519367710456
Validation loss: 3.9163513749962733

Epoch: 5| Step: 3
Training loss: 3.846466593131311
Validation loss: 3.9112820727393784

Epoch: 5| Step: 4
Training loss: 4.416371077716834
Validation loss: 3.9060224543100386

Epoch: 5| Step: 5
Training loss: 4.260656572347768
Validation loss: 3.900974195004661

Epoch: 5| Step: 6
Training loss: 3.8964215954763963
Validation loss: 3.8955337575828017

Epoch: 5| Step: 7
Training loss: 3.0154958114228076
Validation loss: 3.8896722559000496

Epoch: 5| Step: 8
Training loss: 4.097039684532692
Validation loss: 3.884708333156359

Epoch: 5| Step: 9
Training loss: 4.467655714808335
Validation loss: 3.8805853112254955

Epoch: 5| Step: 10
Training loss: 4.106413844075323
Validation loss: 3.875318447482017

Epoch: 5| Step: 11
Training loss: 4.861439159162869
Validation loss: 3.86966921619876

Epoch: 35| Step: 0
Training loss: 3.4905089711684765
Validation loss: 3.864190277853978

Epoch: 5| Step: 1
Training loss: 4.071733047458493
Validation loss: 3.859016360609109

Epoch: 5| Step: 2
Training loss: 3.5786366992194107
Validation loss: 3.8534519959172138

Epoch: 5| Step: 3
Training loss: 4.435905062458453
Validation loss: 3.8487263180701143

Epoch: 5| Step: 4
Training loss: 4.223275928744474
Validation loss: 3.843401854340707

Epoch: 5| Step: 5
Training loss: 4.387558052570114
Validation loss: 3.8384711916012533

Epoch: 5| Step: 6
Training loss: 3.3760144157373073
Validation loss: 3.83268598950856

Epoch: 5| Step: 7
Training loss: 4.265634613585206
Validation loss: 3.8278787858115053

Epoch: 5| Step: 8
Training loss: 4.234647509825429
Validation loss: 3.8227320565007616

Epoch: 5| Step: 9
Training loss: 4.00288930492408
Validation loss: 3.8176604871193316

Epoch: 5| Step: 10
Training loss: 3.210315653412209
Validation loss: 3.8117949349744666

Epoch: 5| Step: 11
Training loss: 4.809894203085245
Validation loss: 3.807022427885878

Epoch: 36| Step: 0
Training loss: 3.6184858789066965
Validation loss: 3.802212280107408

Epoch: 5| Step: 1
Training loss: 4.0314567572039115
Validation loss: 3.796568644949315

Epoch: 5| Step: 2
Training loss: 3.6467492978383063
Validation loss: 3.7912236765354224

Epoch: 5| Step: 3
Training loss: 3.8872361955338093
Validation loss: 3.7862082254047436

Epoch: 5| Step: 4
Training loss: 3.597780968971819
Validation loss: 3.781717933516313

Epoch: 5| Step: 5
Training loss: 4.075483263063982
Validation loss: 3.7763562021029125

Epoch: 5| Step: 6
Training loss: 4.225082505001797
Validation loss: 3.771949137559837

Epoch: 5| Step: 7
Training loss: 4.356614636959609
Validation loss: 3.767185067411123

Epoch: 5| Step: 8
Training loss: 4.0013628068614056
Validation loss: 3.762221157898189

Epoch: 5| Step: 9
Training loss: 3.657466718583559
Validation loss: 3.756692340044392

Epoch: 5| Step: 10
Training loss: 3.840492170502934
Validation loss: 3.7516294118307285

Epoch: 5| Step: 11
Training loss: 3.9359239118401312
Validation loss: 3.7463443315619864

Epoch: 37| Step: 0
Training loss: 3.797369277241071
Validation loss: 3.7418174852732213

Epoch: 5| Step: 1
Training loss: 3.9145807163026083
Validation loss: 3.7370050710739475

Epoch: 5| Step: 2
Training loss: 3.336754727822748
Validation loss: 3.732149714074449

Epoch: 5| Step: 3
Training loss: 4.081456252490184
Validation loss: 3.727195126239532

Epoch: 5| Step: 4
Training loss: 3.4225449276435045
Validation loss: 3.722078025612242

Epoch: 5| Step: 5
Training loss: 3.8399029840691274
Validation loss: 3.7176534387681577

Epoch: 5| Step: 6
Training loss: 4.190789595976412
Validation loss: 3.712828278289841

Epoch: 5| Step: 7
Training loss: 4.637769032203883
Validation loss: 3.7080132778510224

Epoch: 5| Step: 8
Training loss: 3.402951664709423
Validation loss: 3.703218499142064

Epoch: 5| Step: 9
Training loss: 4.361298823653249
Validation loss: 3.6981424325430363

Epoch: 5| Step: 10
Training loss: 3.1976342754787948
Validation loss: 3.6933546895024842

Epoch: 5| Step: 11
Training loss: 3.47384708956577
Validation loss: 3.688272993243768

Epoch: 38| Step: 0
Training loss: 3.878240399484205
Validation loss: 3.6836624381820338

Epoch: 5| Step: 1
Training loss: 3.4370646807988816
Validation loss: 3.679179405559002

Epoch: 5| Step: 2
Training loss: 3.7525215572218302
Validation loss: 3.6744400534202897

Epoch: 5| Step: 3
Training loss: 4.277537720345037
Validation loss: 3.6699143714685962

Epoch: 5| Step: 4
Training loss: 4.268569544807992
Validation loss: 3.6655165790416566

Epoch: 5| Step: 5
Training loss: 4.001667867075401
Validation loss: 3.660956171508881

Epoch: 5| Step: 6
Training loss: 3.8306042175177337
Validation loss: 3.655924394025766

Epoch: 5| Step: 7
Training loss: 4.006641120088689
Validation loss: 3.651124072630073

Epoch: 5| Step: 8
Training loss: 3.1080440567311047
Validation loss: 3.646520351892396

Epoch: 5| Step: 9
Training loss: 3.6836382801523695
Validation loss: 3.6421185296422283

Epoch: 5| Step: 10
Training loss: 3.341310984136676
Validation loss: 3.6372166561484667

Epoch: 5| Step: 11
Training loss: 3.8327640995370684
Validation loss: 3.6330134783973507

Epoch: 39| Step: 0
Training loss: 3.6580674308706214
Validation loss: 3.6277651818390897

Epoch: 5| Step: 1
Training loss: 4.4912377987278385
Validation loss: 3.6233329721682828

Epoch: 5| Step: 2
Training loss: 3.891446191612989
Validation loss: 3.6183790162791714

Epoch: 5| Step: 3
Training loss: 3.8455010124168507
Validation loss: 3.6135320737917964

Epoch: 5| Step: 4
Training loss: 3.468916330559567
Validation loss: 3.609343342828018

Epoch: 5| Step: 5
Training loss: 2.6730288863813647
Validation loss: 3.604532921470565

Epoch: 5| Step: 6
Training loss: 3.9560495045556645
Validation loss: 3.6001212435191574

Epoch: 5| Step: 7
Training loss: 3.268129401438367
Validation loss: 3.5956041003669212

Epoch: 5| Step: 8
Training loss: 4.044692699326171
Validation loss: 3.5913773900713926

Epoch: 5| Step: 9
Training loss: 3.5648327601771483
Validation loss: 3.5870407667871684

Epoch: 5| Step: 10
Training loss: 3.979644839863557
Validation loss: 3.5823205729112617

Epoch: 5| Step: 11
Training loss: 3.8130275173760024
Validation loss: 3.5773913757215285

Epoch: 40| Step: 0
Training loss: 4.37856343788017
Validation loss: 3.5728975783005934

Epoch: 5| Step: 1
Training loss: 3.6493752558898054
Validation loss: 3.568531012065523

Epoch: 5| Step: 2
Training loss: 3.7824631943711573
Validation loss: 3.564329196395502

Epoch: 5| Step: 3
Training loss: 3.3584327973307744
Validation loss: 3.559689249529378

Epoch: 5| Step: 4
Training loss: 3.607515194465007
Validation loss: 3.555293406733407

Epoch: 5| Step: 5
Training loss: 3.2088729272529375
Validation loss: 3.5502915473102354

Epoch: 5| Step: 6
Training loss: 3.866424176954424
Validation loss: 3.545565745831748

Epoch: 5| Step: 7
Training loss: 3.812142152095166
Validation loss: 3.5411772988259536

Epoch: 5| Step: 8
Training loss: 4.028104279245096
Validation loss: 3.536385484412352

Epoch: 5| Step: 9
Training loss: 2.9848894404858326
Validation loss: 3.5320748910146404

Epoch: 5| Step: 10
Training loss: 3.613981931640179
Validation loss: 3.5275290191649913

Epoch: 5| Step: 11
Training loss: 4.078883075045493
Validation loss: 3.5228593891946045

Epoch: 41| Step: 0
Training loss: 3.4711138944279574
Validation loss: 3.518656998529507

Epoch: 5| Step: 1
Training loss: 3.9072053275166523
Validation loss: 3.5144696463555234

Epoch: 5| Step: 2
Training loss: 4.036716510350526
Validation loss: 3.509590746033034

Epoch: 5| Step: 3
Training loss: 3.319906340047781
Validation loss: 3.5055386282321885

Epoch: 5| Step: 4
Training loss: 3.1036883162699795
Validation loss: 3.5009005614135575

Epoch: 5| Step: 5
Training loss: 3.835570525661628
Validation loss: 3.4964898195871768

Epoch: 5| Step: 6
Training loss: 3.7851820749006153
Validation loss: 3.4922209588026067

Epoch: 5| Step: 7
Training loss: 3.3136666600623528
Validation loss: 3.4879703988392614

Epoch: 5| Step: 8
Training loss: 3.9569238796899597
Validation loss: 3.483369933206817

Epoch: 5| Step: 9
Training loss: 3.608207612934648
Validation loss: 3.478616771908823

Epoch: 5| Step: 10
Training loss: 3.6493330515995086
Validation loss: 3.4746186097429597

Epoch: 5| Step: 11
Training loss: 2.881547355616196
Validation loss: 3.4699773020556215

Epoch: 42| Step: 0
Training loss: 3.4031147658068965
Validation loss: 3.4657043569483847

Epoch: 5| Step: 1
Training loss: 2.7065374631376664
Validation loss: 3.4614398783994336

Epoch: 5| Step: 2
Training loss: 3.3947409684659235
Validation loss: 3.457601019679241

Epoch: 5| Step: 3
Training loss: 3.645515791370521
Validation loss: 3.4534487450275955

Epoch: 5| Step: 4
Training loss: 3.0019161145144517
Validation loss: 3.4492849975076387

Epoch: 5| Step: 5
Training loss: 3.899406847719033
Validation loss: 3.4452155194001226

Epoch: 5| Step: 6
Training loss: 4.3200727675631825
Validation loss: 3.4411196580325023

Epoch: 5| Step: 7
Training loss: 3.759637274594909
Validation loss: 3.4367714138668553

Epoch: 5| Step: 8
Training loss: 4.1352935439581735
Validation loss: 3.4325621193981055

Epoch: 5| Step: 9
Training loss: 3.556384542967205
Validation loss: 3.428223977620455

Epoch: 5| Step: 10
Training loss: 3.2611697528714227
Validation loss: 3.4236130328599663

Epoch: 5| Step: 11
Training loss: 3.6247469057322106
Validation loss: 3.4194235475850063

Epoch: 43| Step: 0
Training loss: 3.286824894617664
Validation loss: 3.414985363241453

Epoch: 5| Step: 1
Training loss: 3.7055206919308437
Validation loss: 3.410828892925276

Epoch: 5| Step: 2
Training loss: 3.10809790680194
Validation loss: 3.406893129908772

Epoch: 5| Step: 3
Training loss: 3.405785065164156
Validation loss: 3.4027268332389524

Epoch: 5| Step: 4
Training loss: 3.475262688237869
Validation loss: 3.398452291054528

Epoch: 5| Step: 5
Training loss: 3.7488612671277792
Validation loss: 3.3942494891852966

Epoch: 5| Step: 6
Training loss: 3.8620886278063016
Validation loss: 3.390583624052624

Epoch: 5| Step: 7
Training loss: 4.163663519376643
Validation loss: 3.38620189754623

Epoch: 5| Step: 8
Training loss: 3.177212438409522
Validation loss: 3.3817461490048455

Epoch: 5| Step: 9
Training loss: 3.533588276668462
Validation loss: 3.378128426756225

Epoch: 5| Step: 10
Training loss: 3.2214128164607554
Validation loss: 3.3738194861740722

Epoch: 5| Step: 11
Training loss: 3.7075423922336963
Validation loss: 3.3696367718543483

Epoch: 44| Step: 0
Training loss: 3.792035696215756
Validation loss: 3.36595412675489

Epoch: 5| Step: 1
Training loss: 3.288233274190066
Validation loss: 3.3613550014038305

Epoch: 5| Step: 2
Training loss: 3.490110594737791
Validation loss: 3.357435467929039

Epoch: 5| Step: 3
Training loss: 2.5016765694757908
Validation loss: 3.3530199902514353

Epoch: 5| Step: 4
Training loss: 3.8832919095385425
Validation loss: 3.3493713264661107

Epoch: 5| Step: 5
Training loss: 4.25500059457275
Validation loss: 3.34536085810981

Epoch: 5| Step: 6
Training loss: 3.7106941223645715
Validation loss: 3.3414137988762995

Epoch: 5| Step: 7
Training loss: 3.301070883418888
Validation loss: 3.3373857878669915

Epoch: 5| Step: 8
Training loss: 3.537255371046535
Validation loss: 3.333116480608232

Epoch: 5| Step: 9
Training loss: 3.7655875176428104
Validation loss: 3.329001369518435

Epoch: 5| Step: 10
Training loss: 2.7111942928178725
Validation loss: 3.3249409567578954

Epoch: 5| Step: 11
Training loss: 1.6739605881257016
Validation loss: 3.3210919142306494

Epoch: 45| Step: 0
Training loss: 3.4569026944670678
Validation loss: 3.3176720745474797

Epoch: 5| Step: 1
Training loss: 3.427201536665856
Validation loss: 3.3138380886837346

Epoch: 5| Step: 2
Training loss: 2.9458128810174387
Validation loss: 3.3104460604310777

Epoch: 5| Step: 3
Training loss: 2.9696413007223708
Validation loss: 3.307188015412432

Epoch: 5| Step: 4
Training loss: 3.6744665212794385
Validation loss: 3.3033145490459366

Epoch: 5| Step: 5
Training loss: 3.3547683713179532
Validation loss: 3.299407570816603

Epoch: 5| Step: 6
Training loss: 3.9084434759457745
Validation loss: 3.2960060143516197

Epoch: 5| Step: 7
Training loss: 3.243588064631515
Validation loss: 3.29203279285931

Epoch: 5| Step: 8
Training loss: 4.000349506367625
Validation loss: 3.2880427213524714

Epoch: 5| Step: 9
Training loss: 3.404214373238325
Validation loss: 3.2843263857819083

Epoch: 5| Step: 10
Training loss: 3.479987833725281
Validation loss: 3.280385972356711

Epoch: 5| Step: 11
Training loss: 2.185489711746859
Validation loss: 3.27696426492173

Epoch: 46| Step: 0
Training loss: 3.26039646780239
Validation loss: 3.273150647689158

Epoch: 5| Step: 1
Training loss: 3.1450857491015505
Validation loss: 3.26939750346176

Epoch: 5| Step: 2
Training loss: 3.4338562119717637
Validation loss: 3.2655846564372917

Epoch: 5| Step: 3
Training loss: 3.7179159302956397
Validation loss: 3.262127519831995

Epoch: 5| Step: 4
Training loss: 3.8760938023573233
Validation loss: 3.258247846488482

Epoch: 5| Step: 5
Training loss: 3.655599291680565
Validation loss: 3.2546858996458936

Epoch: 5| Step: 6
Training loss: 3.08573615467557
Validation loss: 3.251332456146173

Epoch: 5| Step: 7
Training loss: 3.508658190356098
Validation loss: 3.24755983874092

Epoch: 5| Step: 8
Training loss: 2.7859582374986216
Validation loss: 3.2444415334729486

Epoch: 5| Step: 9
Training loss: 3.020403934521563
Validation loss: 3.2401612227362278

Epoch: 5| Step: 10
Training loss: 3.660292778603599
Validation loss: 3.2370032506258037

Epoch: 5| Step: 11
Training loss: 3.51623529858979
Validation loss: 3.2331453986869896

Epoch: 47| Step: 0
Training loss: 3.257215266749392
Validation loss: 3.2294380084240752

Epoch: 5| Step: 1
Training loss: 2.99277325267775
Validation loss: 3.225806368576582

Epoch: 5| Step: 2
Training loss: 3.1851332610561265
Validation loss: 3.2225545108032962

Epoch: 5| Step: 3
Training loss: 3.2571016629322123
Validation loss: 3.219010592531787

Epoch: 5| Step: 4
Training loss: 3.07629061030771
Validation loss: 3.2158535020098094

Epoch: 5| Step: 5
Training loss: 3.629028186864176
Validation loss: 3.2122400307265226

Epoch: 5| Step: 6
Training loss: 3.4653809828711926
Validation loss: 3.2091262857205756

Epoch: 5| Step: 7
Training loss: 3.118817890169841
Validation loss: 3.2053975208242416

Epoch: 5| Step: 8
Training loss: 3.376301549795481
Validation loss: 3.2025303048221954

Epoch: 5| Step: 9
Training loss: 4.248873393014115
Validation loss: 3.198703971313984

Epoch: 5| Step: 10
Training loss: 3.011926784826172
Validation loss: 3.1947649771901525

Epoch: 5| Step: 11
Training loss: 3.6208640872423326
Validation loss: 3.1915148713059587

Epoch: 48| Step: 0
Training loss: 3.8337924654673112
Validation loss: 3.187650701912134

Epoch: 5| Step: 1
Training loss: 3.4472226061851936
Validation loss: 3.1839184429699467

Epoch: 5| Step: 2
Training loss: 3.2268193399024008
Validation loss: 3.180409264404513

Epoch: 5| Step: 3
Training loss: 3.773247818691124
Validation loss: 3.176656085610822

Epoch: 5| Step: 4
Training loss: 3.0554613464936833
Validation loss: 3.1732616619389797

Epoch: 5| Step: 5
Training loss: 3.2974252829137654
Validation loss: 3.1694371669045682

Epoch: 5| Step: 6
Training loss: 2.9758344746159016
Validation loss: 3.1659231609732297

Epoch: 5| Step: 7
Training loss: 3.453480421736227
Validation loss: 3.1624332833069206

Epoch: 5| Step: 8
Training loss: 3.2778933840549858
Validation loss: 3.1589885074051804

Epoch: 5| Step: 9
Training loss: 2.7092636173501314
Validation loss: 3.155425174818696

Epoch: 5| Step: 10
Training loss: 3.243473395459445
Validation loss: 3.152427845541838

Epoch: 5| Step: 11
Training loss: 3.152742457553758
Validation loss: 3.1489444005929053

Epoch: 49| Step: 0
Training loss: 3.219250686369338
Validation loss: 3.145878587275177

Epoch: 5| Step: 1
Training loss: 3.0916663965874593
Validation loss: 3.14274704192518

Epoch: 5| Step: 2
Training loss: 3.110443698350824
Validation loss: 3.139284819038611

Epoch: 5| Step: 3
Training loss: 3.264576282668072
Validation loss: 3.1361777415845236

Epoch: 5| Step: 4
Training loss: 3.6417613077559676
Validation loss: 3.1329452600673915

Epoch: 5| Step: 5
Training loss: 3.119833986805165
Validation loss: 3.1297259644055373

Epoch: 5| Step: 6
Training loss: 3.9399273368989873
Validation loss: 3.126460007705455

Epoch: 5| Step: 7
Training loss: 3.060780100648187
Validation loss: 3.12316650644992

Epoch: 5| Step: 8
Training loss: 3.447044438946894
Validation loss: 3.1198103059817934

Epoch: 5| Step: 9
Training loss: 2.5259129337398445
Validation loss: 3.1165952605892024

Epoch: 5| Step: 10
Training loss: 3.5330338825033922
Validation loss: 3.1133775046038017

Epoch: 5| Step: 11
Training loss: 2.2010934539879212
Validation loss: 3.1102087829492078

Epoch: 50| Step: 0
Training loss: 3.1659246545767687
Validation loss: 3.10787530256707

Epoch: 5| Step: 1
Training loss: 3.1011200019869647
Validation loss: 3.104831001486317

Epoch: 5| Step: 2
Training loss: 3.2176299877926122
Validation loss: 3.101937457912457

Epoch: 5| Step: 3
Training loss: 3.3713135542658677
Validation loss: 3.099564255320121

Epoch: 5| Step: 4
Training loss: 3.2997591682177814
Validation loss: 3.096401796009373

Epoch: 5| Step: 5
Training loss: 3.650380044251319
Validation loss: 3.0939809186407032

Epoch: 5| Step: 6
Training loss: 2.635762449556242
Validation loss: 3.0905153145144504

Epoch: 5| Step: 7
Training loss: 3.3872548595283525
Validation loss: 3.087959888766405

Epoch: 5| Step: 8
Training loss: 3.3471026858718433
Validation loss: 3.0855985592157458

Epoch: 5| Step: 9
Training loss: 3.444871385496106
Validation loss: 3.083068795497711

Epoch: 5| Step: 10
Training loss: 3.148706164386184
Validation loss: 3.0795932759877283

Epoch: 5| Step: 11
Training loss: 1.2546856795852395
Validation loss: 3.0782757381702703

Testing loss: 2.656860817940466
