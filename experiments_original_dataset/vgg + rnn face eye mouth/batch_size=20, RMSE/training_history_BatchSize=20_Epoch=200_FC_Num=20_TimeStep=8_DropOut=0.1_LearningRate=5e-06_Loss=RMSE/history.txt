Epoch: 1| Step: 0
Training loss: 6.602852129951117
Validation loss: 5.917318565650352

Epoch: 5| Step: 1
Training loss: 5.7385092651685925
Validation loss: 5.915449415725617

Epoch: 5| Step: 2
Training loss: 5.134852916835989
Validation loss: 5.913551076648942

Epoch: 5| Step: 3
Training loss: 5.768914336305308
Validation loss: 5.911917179353899

Epoch: 5| Step: 4
Training loss: 6.382090496190296
Validation loss: 5.910204449961546

Epoch: 5| Step: 5
Training loss: 5.562253110742872
Validation loss: 5.908525267506822

Epoch: 5| Step: 6
Training loss: 6.8260335621717045
Validation loss: 5.906896713884797

Epoch: 5| Step: 7
Training loss: 6.351333069733889
Validation loss: 5.905255181766043

Epoch: 5| Step: 8
Training loss: 5.790125946098209
Validation loss: 5.903641126238463

Epoch: 5| Step: 9
Training loss: 5.693049144635274
Validation loss: 5.902021761581028

Epoch: 5| Step: 10
Training loss: 6.2249954530017595
Validation loss: 5.90040213432145

Epoch: 5| Step: 11
Training loss: 5.977618434599034
Validation loss: 5.898755507496584

Epoch: 2| Step: 0
Training loss: 5.475185422500922
Validation loss: 5.896939098695091

Epoch: 5| Step: 1
Training loss: 6.728239517194109
Validation loss: 5.895221754869179

Epoch: 5| Step: 2
Training loss: 5.898333375529627
Validation loss: 5.893474931659235

Epoch: 5| Step: 3
Training loss: 6.546917535101979
Validation loss: 5.891544192748436

Epoch: 5| Step: 4
Training loss: 5.476834495853486
Validation loss: 5.889578101424907

Epoch: 5| Step: 5
Training loss: 6.709652156995256
Validation loss: 5.887521690280103

Epoch: 5| Step: 6
Training loss: 5.83181670318695
Validation loss: 5.885404896232066

Epoch: 5| Step: 7
Training loss: 6.375510401021644
Validation loss: 5.883230558403652

Epoch: 5| Step: 8
Training loss: 5.7988406239339865
Validation loss: 5.880767493837789

Epoch: 5| Step: 9
Training loss: 5.214755419722426
Validation loss: 5.878486437504026

Epoch: 5| Step: 10
Training loss: 5.61049698258555
Validation loss: 5.875928000617758

Epoch: 5| Step: 11
Training loss: 6.6524974292289984
Validation loss: 5.873337334538777

Epoch: 3| Step: 0
Training loss: 5.856397681068809
Validation loss: 5.870414906145753

Epoch: 5| Step: 1
Training loss: 6.218657373093149
Validation loss: 5.867539701290906

Epoch: 5| Step: 2
Training loss: 4.800595906143022
Validation loss: 5.8644096208754055

Epoch: 5| Step: 3
Training loss: 6.181134581380247
Validation loss: 5.861247869626645

Epoch: 5| Step: 4
Training loss: 5.02772578615924
Validation loss: 5.857777804230141

Epoch: 5| Step: 5
Training loss: 6.533081965898218
Validation loss: 5.8541925798523655

Epoch: 5| Step: 6
Training loss: 6.046413196997714
Validation loss: 5.850455742660152

Epoch: 5| Step: 7
Training loss: 6.254152978131967
Validation loss: 5.846506709520897

Epoch: 5| Step: 8
Training loss: 5.732231550290217
Validation loss: 5.842343227354519

Epoch: 5| Step: 9
Training loss: 6.797179186799546
Validation loss: 5.837864269623792

Epoch: 5| Step: 10
Training loss: 5.95482701278528
Validation loss: 5.832992389342856

Epoch: 5| Step: 11
Training loss: 5.739795752423689
Validation loss: 5.827995107940195

Epoch: 4| Step: 0
Training loss: 6.142440566325395
Validation loss: 5.822949590800314

Epoch: 5| Step: 1
Training loss: 5.818191858846497
Validation loss: 5.817481958350104

Epoch: 5| Step: 2
Training loss: 4.810093067244308
Validation loss: 5.812019758996896

Epoch: 5| Step: 3
Training loss: 6.927166365123452
Validation loss: 5.806373033154206

Epoch: 5| Step: 4
Training loss: 6.181572126397736
Validation loss: 5.8002386419485585

Epoch: 5| Step: 5
Training loss: 6.1491977943797105
Validation loss: 5.793800786415447

Epoch: 5| Step: 6
Training loss: 6.1622006852386955
Validation loss: 5.787244139660106

Epoch: 5| Step: 7
Training loss: 5.759325509316661
Validation loss: 5.7803419482577185

Epoch: 5| Step: 8
Training loss: 5.518431730154499
Validation loss: 5.773477570528478

Epoch: 5| Step: 9
Training loss: 5.481542306759204
Validation loss: 5.7660574953262795

Epoch: 5| Step: 10
Training loss: 5.540991873517124
Validation loss: 5.758743983732669

Epoch: 5| Step: 11
Training loss: 7.051316310203576
Validation loss: 5.751496769796267

Epoch: 5| Step: 0
Training loss: 5.589699413427407
Validation loss: 5.7436249609707435

Epoch: 5| Step: 1
Training loss: 5.27675008081729
Validation loss: 5.736040668604075

Epoch: 5| Step: 2
Training loss: 4.769767386724631
Validation loss: 5.728072941736557

Epoch: 5| Step: 3
Training loss: 6.132490910159068
Validation loss: 5.7205748017812565

Epoch: 5| Step: 4
Training loss: 5.177301331912302
Validation loss: 5.712641804811123

Epoch: 5| Step: 5
Training loss: 6.926704874432032
Validation loss: 5.7047499967488395

Epoch: 5| Step: 6
Training loss: 5.910830381765488
Validation loss: 5.69662150762228

Epoch: 5| Step: 7
Training loss: 5.61274605192576
Validation loss: 5.688704150099012

Epoch: 5| Step: 8
Training loss: 6.192612818651632
Validation loss: 5.680412018891863

Epoch: 5| Step: 9
Training loss: 6.405798919427816
Validation loss: 5.672514403901993

Epoch: 5| Step: 10
Training loss: 5.034358989138394
Validation loss: 5.663780559669792

Epoch: 5| Step: 11
Training loss: 8.325208543336261
Validation loss: 5.655523116473181

Epoch: 6| Step: 0
Training loss: 5.314211580899136
Validation loss: 5.647043931211363

Epoch: 5| Step: 1
Training loss: 4.851395608731264
Validation loss: 5.638734826623054

Epoch: 5| Step: 2
Training loss: 6.310479171139444
Validation loss: 5.630312939524022

Epoch: 5| Step: 3
Training loss: 5.952277175725284
Validation loss: 5.621746740173344

Epoch: 5| Step: 4
Training loss: 6.032726364093866
Validation loss: 5.6132401774794545

Epoch: 5| Step: 5
Training loss: 5.178900335230538
Validation loss: 5.604818960845402

Epoch: 5| Step: 6
Training loss: 6.092532931345652
Validation loss: 5.5961989044999285

Epoch: 5| Step: 7
Training loss: 6.129853485995047
Validation loss: 5.5875856897893685

Epoch: 5| Step: 8
Training loss: 5.382627885418131
Validation loss: 5.579198881725305

Epoch: 5| Step: 9
Training loss: 6.217615685454652
Validation loss: 5.57053414394706

Epoch: 5| Step: 10
Training loss: 4.996623234134877
Validation loss: 5.561889643525717

Epoch: 5| Step: 11
Training loss: 6.781657263836077
Validation loss: 5.553585517262649

Epoch: 7| Step: 0
Training loss: 5.911703185893678
Validation loss: 5.544784581821675

Epoch: 5| Step: 1
Training loss: 5.634109919062471
Validation loss: 5.536385546182178

Epoch: 5| Step: 2
Training loss: 6.375718020226231
Validation loss: 5.528336945031249

Epoch: 5| Step: 3
Training loss: 5.1543212982558915
Validation loss: 5.5198045695765305

Epoch: 5| Step: 4
Training loss: 5.515536991098047
Validation loss: 5.511831259440918

Epoch: 5| Step: 5
Training loss: 4.799716170184551
Validation loss: 5.503989636647093

Epoch: 5| Step: 6
Training loss: 5.127077193439295
Validation loss: 5.496269116634843

Epoch: 5| Step: 7
Training loss: 5.345108662598941
Validation loss: 5.488202931851024

Epoch: 5| Step: 8
Training loss: 5.0605374523503555
Validation loss: 5.4799688233117525

Epoch: 5| Step: 9
Training loss: 6.307341327886484
Validation loss: 5.471294755596466

Epoch: 5| Step: 10
Training loss: 6.226205928074421
Validation loss: 5.461865536807094

Epoch: 5| Step: 11
Training loss: 6.266258150677923
Validation loss: 5.452316814530439

Epoch: 8| Step: 0
Training loss: 5.342669996913795
Validation loss: 5.442897981932199

Epoch: 5| Step: 1
Training loss: 6.553716394373566
Validation loss: 5.434723192539784

Epoch: 5| Step: 2
Training loss: 5.448803782642862
Validation loss: 5.4277149670009

Epoch: 5| Step: 3
Training loss: 6.041475630622883
Validation loss: 5.421072337076261

Epoch: 5| Step: 4
Training loss: 5.843025693017923
Validation loss: 5.414719975170958

Epoch: 5| Step: 5
Training loss: 5.292468553394708
Validation loss: 5.40860234058342

Epoch: 5| Step: 6
Training loss: 5.98414009768657
Validation loss: 5.401812089827878

Epoch: 5| Step: 7
Training loss: 5.692807917117982
Validation loss: 5.3947842460601425

Epoch: 5| Step: 8
Training loss: 4.4061355034852525
Validation loss: 5.388008780179402

Epoch: 5| Step: 9
Training loss: 5.35106742406637
Validation loss: 5.380794506755093

Epoch: 5| Step: 10
Training loss: 4.696055424923675
Validation loss: 5.374159089186269

Epoch: 5| Step: 11
Training loss: 4.737854940761406
Validation loss: 5.3672895130307685

Epoch: 9| Step: 0
Training loss: 6.078078242810998
Validation loss: 5.360122962117717

Epoch: 5| Step: 1
Training loss: 4.935389973267808
Validation loss: 5.35310372762022

Epoch: 5| Step: 2
Training loss: 4.945054275014271
Validation loss: 5.346815178256145

Epoch: 5| Step: 3
Training loss: 5.235308845685878
Validation loss: 5.340104151387538

Epoch: 5| Step: 4
Training loss: 5.117518104182032
Validation loss: 5.333552909841111

Epoch: 5| Step: 5
Training loss: 4.787242450210727
Validation loss: 5.327065258967659

Epoch: 5| Step: 6
Training loss: 5.832767059451648
Validation loss: 5.321243189791741

Epoch: 5| Step: 7
Training loss: 5.674772000879233
Validation loss: 5.315093368626463

Epoch: 5| Step: 8
Training loss: 6.177263211166357
Validation loss: 5.308667000664488

Epoch: 5| Step: 9
Training loss: 4.992589800031338
Validation loss: 5.302553911691925

Epoch: 5| Step: 10
Training loss: 6.16629185267794
Validation loss: 5.296473207491757

Epoch: 5| Step: 11
Training loss: 3.855206914511688
Validation loss: 5.2904108264381415

Epoch: 10| Step: 0
Training loss: 5.548698190136548
Validation loss: 5.284204157153002

Epoch: 5| Step: 1
Training loss: 5.172740299179806
Validation loss: 5.278298427878719

Epoch: 5| Step: 2
Training loss: 4.408708684525963
Validation loss: 5.27219030631646

Epoch: 5| Step: 3
Training loss: 4.8538620270624495
Validation loss: 5.266352617380884

Epoch: 5| Step: 4
Training loss: 6.18811895183903
Validation loss: 5.260050954160964

Epoch: 5| Step: 5
Training loss: 6.095632096169803
Validation loss: 5.254152184914404

Epoch: 5| Step: 6
Training loss: 6.21596629652315
Validation loss: 5.247729234224345

Epoch: 5| Step: 7
Training loss: 5.292077516641141
Validation loss: 5.241450485821419

Epoch: 5| Step: 8
Training loss: 4.558872191515061
Validation loss: 5.235034844101276

Epoch: 5| Step: 9
Training loss: 5.62127155078424
Validation loss: 5.228600523293481

Epoch: 5| Step: 10
Training loss: 4.495243101409699
Validation loss: 5.222166614315315

Epoch: 5| Step: 11
Training loss: 6.516369966873122
Validation loss: 5.21603754026072

Epoch: 11| Step: 0
Training loss: 5.525548205213637
Validation loss: 5.209600533506317

Epoch: 5| Step: 1
Training loss: 5.403883399490415
Validation loss: 5.203229702649259

Epoch: 5| Step: 2
Training loss: 4.702730586854214
Validation loss: 5.196772220686347

Epoch: 5| Step: 3
Training loss: 5.28729119215452
Validation loss: 5.1902002713929605

Epoch: 5| Step: 4
Training loss: 5.3460195975238785
Validation loss: 5.184146770154387

Epoch: 5| Step: 5
Training loss: 5.585641962516291
Validation loss: 5.177815532012315

Epoch: 5| Step: 6
Training loss: 4.961010549412964
Validation loss: 5.171555377653257

Epoch: 5| Step: 7
Training loss: 6.02800730762912
Validation loss: 5.165856761929501

Epoch: 5| Step: 8
Training loss: 5.168633958097424
Validation loss: 5.159891857657675

Epoch: 5| Step: 9
Training loss: 5.956479226471845
Validation loss: 5.153762679841965

Epoch: 5| Step: 10
Training loss: 4.230052585861125
Validation loss: 5.148818230142538

Epoch: 5| Step: 11
Training loss: 4.545706162857754
Validation loss: 5.143459246032235

Epoch: 12| Step: 0
Training loss: 6.170840869652548
Validation loss: 5.138129752451998

Epoch: 5| Step: 1
Training loss: 5.172926320520069
Validation loss: 5.133271234103686

Epoch: 5| Step: 2
Training loss: 5.420964848972813
Validation loss: 5.127805872163215

Epoch: 5| Step: 3
Training loss: 4.291460322385423
Validation loss: 5.1227408136025385

Epoch: 5| Step: 4
Training loss: 5.191734883374069
Validation loss: 5.1181853896290335

Epoch: 5| Step: 5
Training loss: 5.069245165851981
Validation loss: 5.113373804384009

Epoch: 5| Step: 6
Training loss: 5.335544823067272
Validation loss: 5.107970936269581

Epoch: 5| Step: 7
Training loss: 5.463392499906283
Validation loss: 5.103394433076666

Epoch: 5| Step: 8
Training loss: 4.208718360938306
Validation loss: 5.098399780146376

Epoch: 5| Step: 9
Training loss: 5.760750050983148
Validation loss: 5.09338881571411

Epoch: 5| Step: 10
Training loss: 5.03798021625967
Validation loss: 5.088303991550312

Epoch: 5| Step: 11
Training loss: 6.048142253555077
Validation loss: 5.083891363730514

Epoch: 13| Step: 0
Training loss: 5.869859110036602
Validation loss: 5.078819798596982

Epoch: 5| Step: 1
Training loss: 4.836733159441365
Validation loss: 5.0736223104730245

Epoch: 5| Step: 2
Training loss: 5.389089702958941
Validation loss: 5.068869433895034

Epoch: 5| Step: 3
Training loss: 5.366200007808478
Validation loss: 5.063689394346256

Epoch: 5| Step: 4
Training loss: 5.336694889855716
Validation loss: 5.058578440128759

Epoch: 5| Step: 5
Training loss: 5.032213201788251
Validation loss: 5.053405551989874

Epoch: 5| Step: 6
Training loss: 5.541339357887447
Validation loss: 5.04874596495096

Epoch: 5| Step: 7
Training loss: 5.176852225576281
Validation loss: 5.04418505935597

Epoch: 5| Step: 8
Training loss: 4.408654388870579
Validation loss: 5.038768600054786

Epoch: 5| Step: 9
Training loss: 4.82878587267549
Validation loss: 5.03442267772815

Epoch: 5| Step: 10
Training loss: 5.135548226900446
Validation loss: 5.029472945504647

Epoch: 5| Step: 11
Training loss: 4.6031949267802625
Validation loss: 5.025203412242297

Epoch: 14| Step: 0
Training loss: 5.050183230560199
Validation loss: 5.0203002973863935

Epoch: 5| Step: 1
Training loss: 5.648522256344568
Validation loss: 5.015570643240368

Epoch: 5| Step: 2
Training loss: 5.035200570135626
Validation loss: 5.01091349379607

Epoch: 5| Step: 3
Training loss: 5.096798224604735
Validation loss: 5.006801286903252

Epoch: 5| Step: 4
Training loss: 5.017413524572446
Validation loss: 5.001999010389236

Epoch: 5| Step: 5
Training loss: 4.673078809292791
Validation loss: 4.997572134571401

Epoch: 5| Step: 6
Training loss: 4.149692726249745
Validation loss: 4.992740495008981

Epoch: 5| Step: 7
Training loss: 4.8856267280668275
Validation loss: 4.988319781181228

Epoch: 5| Step: 8
Training loss: 5.830534817749254
Validation loss: 4.984292526918078

Epoch: 5| Step: 9
Training loss: 5.7625016020071325
Validation loss: 4.979121246556358

Epoch: 5| Step: 10
Training loss: 4.92120511779395
Validation loss: 4.974374894146424

Epoch: 5| Step: 11
Training loss: 5.267176187390514
Validation loss: 4.970039184436311

Epoch: 15| Step: 0
Training loss: 4.902168082323232
Validation loss: 4.965202024485149

Epoch: 5| Step: 1
Training loss: 4.725349712044924
Validation loss: 4.96094047966815

Epoch: 5| Step: 2
Training loss: 4.158171016198248
Validation loss: 4.956146938924878

Epoch: 5| Step: 3
Training loss: 5.2005161469396555
Validation loss: 4.951309585411785

Epoch: 5| Step: 4
Training loss: 5.68507216059668
Validation loss: 4.94694088867674

Epoch: 5| Step: 5
Training loss: 5.233132103778824
Validation loss: 4.942271972731931

Epoch: 5| Step: 6
Training loss: 5.547810220455229
Validation loss: 4.937390885575922

Epoch: 5| Step: 7
Training loss: 5.109329083437602
Validation loss: 4.932917436046053

Epoch: 5| Step: 8
Training loss: 5.13510104041902
Validation loss: 4.9280852279719225

Epoch: 5| Step: 9
Training loss: 4.642732597608911
Validation loss: 4.923744161601889

Epoch: 5| Step: 10
Training loss: 5.249637046256783
Validation loss: 4.918631115405321

Epoch: 5| Step: 11
Training loss: 4.852677320083375
Validation loss: 4.91347996301856

Epoch: 16| Step: 0
Training loss: 5.044204619574886
Validation loss: 4.90890518553215

Epoch: 5| Step: 1
Training loss: 4.555519302864868
Validation loss: 4.904219930235859

Epoch: 5| Step: 2
Training loss: 5.23711266735557
Validation loss: 4.899272233089847

Epoch: 5| Step: 3
Training loss: 5.583461228609171
Validation loss: 4.8945758124431435

Epoch: 5| Step: 4
Training loss: 5.822004853058197
Validation loss: 4.889098671665248

Epoch: 5| Step: 5
Training loss: 5.045022630442286
Validation loss: 4.883745418689962

Epoch: 5| Step: 6
Training loss: 4.746931992591126
Validation loss: 4.879607208044142

Epoch: 5| Step: 7
Training loss: 5.117553325127395
Validation loss: 4.874894613773402

Epoch: 5| Step: 8
Training loss: 4.931233739403046
Validation loss: 4.869514174553575

Epoch: 5| Step: 9
Training loss: 4.064467907154162
Validation loss: 4.864672146081071

Epoch: 5| Step: 10
Training loss: 5.081454174636495
Validation loss: 4.859128007407358

Epoch: 5| Step: 11
Training loss: 2.8130204460955075
Validation loss: 4.854730412351159

Epoch: 17| Step: 0
Training loss: 5.251349865990559
Validation loss: 4.850150942665726

Epoch: 5| Step: 1
Training loss: 5.253168875416303
Validation loss: 4.845051850959043

Epoch: 5| Step: 2
Training loss: 4.741021353862815
Validation loss: 4.840739629351552

Epoch: 5| Step: 3
Training loss: 3.915923568899288
Validation loss: 4.83581824661488

Epoch: 5| Step: 4
Training loss: 5.519272244066783
Validation loss: 4.831381792949716

Epoch: 5| Step: 5
Training loss: 5.2508756724720484
Validation loss: 4.826570048541909

Epoch: 5| Step: 6
Training loss: 4.786142675751161
Validation loss: 4.8223455377907145

Epoch: 5| Step: 7
Training loss: 5.336315850937041
Validation loss: 4.816447125560754

Epoch: 5| Step: 8
Training loss: 5.065236611747116
Validation loss: 4.812771067065622

Epoch: 5| Step: 9
Training loss: 4.451605929226114
Validation loss: 4.807811773674313

Epoch: 5| Step: 10
Training loss: 4.851004207510963
Validation loss: 4.803346822129811

Epoch: 5| Step: 11
Training loss: 4.048020366466688
Validation loss: 4.798792866737886

Epoch: 18| Step: 0
Training loss: 4.833811549940874
Validation loss: 4.793837282330331

Epoch: 5| Step: 1
Training loss: 5.254734810653898
Validation loss: 4.789190061445806

Epoch: 5| Step: 2
Training loss: 5.114975965337136
Validation loss: 4.784172801988543

Epoch: 5| Step: 3
Training loss: 4.7689277585797765
Validation loss: 4.779621561690282

Epoch: 5| Step: 4
Training loss: 4.993925409972221
Validation loss: 4.774567357447225

Epoch: 5| Step: 5
Training loss: 5.126795942531021
Validation loss: 4.769169799205536

Epoch: 5| Step: 6
Training loss: 4.943476862059513
Validation loss: 4.763721582065536

Epoch: 5| Step: 7
Training loss: 4.506257474895738
Validation loss: 4.758712324336173

Epoch: 5| Step: 8
Training loss: 4.721221478704061
Validation loss: 4.754900512537014

Epoch: 5| Step: 9
Training loss: 4.955969730644986
Validation loss: 4.749367207489267

Epoch: 5| Step: 10
Training loss: 4.566331064928522
Validation loss: 4.744655865408833

Epoch: 5| Step: 11
Training loss: 4.935309201712077
Validation loss: 4.7395336176462095

Epoch: 19| Step: 0
Training loss: 5.304820175646604
Validation loss: 4.735924545869445

Epoch: 5| Step: 1
Training loss: 5.12193243752114
Validation loss: 4.730202425603223

Epoch: 5| Step: 2
Training loss: 4.882474207031126
Validation loss: 4.7239585744681785

Epoch: 5| Step: 3
Training loss: 4.513824209418249
Validation loss: 4.719340474824172

Epoch: 5| Step: 4
Training loss: 4.712800171699838
Validation loss: 4.714425949973745

Epoch: 5| Step: 5
Training loss: 4.519074175380162
Validation loss: 4.709211734539647

Epoch: 5| Step: 6
Training loss: 5.344272164158522
Validation loss: 4.704721367869399

Epoch: 5| Step: 7
Training loss: 4.5632451115271
Validation loss: 4.699163261629267

Epoch: 5| Step: 8
Training loss: 4.394683374103095
Validation loss: 4.6941829175288

Epoch: 5| Step: 9
Training loss: 5.07473331746686
Validation loss: 4.6891110089021755

Epoch: 5| Step: 10
Training loss: 5.041897897173006
Validation loss: 4.684795710066467

Epoch: 5| Step: 11
Training loss: 2.1201977040215336
Validation loss: 4.679525556187557

Epoch: 20| Step: 0
Training loss: 4.677978203457289
Validation loss: 4.6744237303213785

Epoch: 5| Step: 1
Training loss: 5.001575603187889
Validation loss: 4.6697685911090785

Epoch: 5| Step: 2
Training loss: 5.531031027732201
Validation loss: 4.665740933162806

Epoch: 5| Step: 3
Training loss: 4.756809774133807
Validation loss: 4.660458525377445

Epoch: 5| Step: 4
Training loss: 4.5934846762504025
Validation loss: 4.655011398487224

Epoch: 5| Step: 5
Training loss: 5.254252754895704
Validation loss: 4.651143296837616

Epoch: 5| Step: 6
Training loss: 3.3733004776732978
Validation loss: 4.6460060834484915

Epoch: 5| Step: 7
Training loss: 4.746299506856796
Validation loss: 4.640981615537672

Epoch: 5| Step: 8
Training loss: 5.23755387526596
Validation loss: 4.636156098899413

Epoch: 5| Step: 9
Training loss: 3.621389366683648
Validation loss: 4.6315153685135675

Epoch: 5| Step: 10
Training loss: 5.199457932608817
Validation loss: 4.626328784347714

Epoch: 5| Step: 11
Training loss: 5.170422860123748
Validation loss: 4.621502094816818

Epoch: 21| Step: 0
Training loss: 4.501596379574652
Validation loss: 4.616340253952899

Epoch: 5| Step: 1
Training loss: 4.831806445925146
Validation loss: 4.611902360870732

Epoch: 5| Step: 2
Training loss: 5.233783745466708
Validation loss: 4.607455268707584

Epoch: 5| Step: 3
Training loss: 5.026712397224856
Validation loss: 4.602790776532843

Epoch: 5| Step: 4
Training loss: 4.300758188516736
Validation loss: 4.597938591588368

Epoch: 5| Step: 5
Training loss: 4.774067788725122
Validation loss: 4.593450601383768

Epoch: 5| Step: 6
Training loss: 5.005258084254021
Validation loss: 4.588056491772853

Epoch: 5| Step: 7
Training loss: 3.711547415955538
Validation loss: 4.5830378292652485

Epoch: 5| Step: 8
Training loss: 4.523847544899924
Validation loss: 4.577616931380844

Epoch: 5| Step: 9
Training loss: 4.552982384117898
Validation loss: 4.572746250508029

Epoch: 5| Step: 10
Training loss: 5.155972929937477
Validation loss: 4.567863186248834

Epoch: 5| Step: 11
Training loss: 5.163190390026511
Validation loss: 4.5634463909448915

Epoch: 22| Step: 0
Training loss: 5.541246594256511
Validation loss: 4.558496504146542

Epoch: 5| Step: 1
Training loss: 3.322191276817267
Validation loss: 4.55387552743669

Epoch: 5| Step: 2
Training loss: 4.652742229471373
Validation loss: 4.549813849096115

Epoch: 5| Step: 3
Training loss: 4.543296638129742
Validation loss: 4.544842098439195

Epoch: 5| Step: 4
Training loss: 5.059588501674263
Validation loss: 4.5396349923968815

Epoch: 5| Step: 5
Training loss: 4.502158812749693
Validation loss: 4.534720413859333

Epoch: 5| Step: 6
Training loss: 5.001671702352648
Validation loss: 4.528552732411867

Epoch: 5| Step: 7
Training loss: 3.680745549766246
Validation loss: 4.523527022614042

Epoch: 5| Step: 8
Training loss: 4.870505584227996
Validation loss: 4.518780640761598

Epoch: 5| Step: 9
Training loss: 5.387821430433209
Validation loss: 4.514782625713024

Epoch: 5| Step: 10
Training loss: 4.195208159273362
Validation loss: 4.509033734085773

Epoch: 5| Step: 11
Training loss: 4.796032959036566
Validation loss: 4.504053277215532

Epoch: 23| Step: 0
Training loss: 4.7025535464444985
Validation loss: 4.49954315798272

Epoch: 5| Step: 1
Training loss: 4.466879713377034
Validation loss: 4.494439358420861

Epoch: 5| Step: 2
Training loss: 4.600371072148946
Validation loss: 4.489618158168511

Epoch: 5| Step: 3
Training loss: 4.546862834901037
Validation loss: 4.484685871544933

Epoch: 5| Step: 4
Training loss: 5.165690709300199
Validation loss: 4.47977000172626

Epoch: 5| Step: 5
Training loss: 4.880397449630247
Validation loss: 4.47460884217451

Epoch: 5| Step: 6
Training loss: 4.30144088911311
Validation loss: 4.470098216523163

Epoch: 5| Step: 7
Training loss: 4.720594841279812
Validation loss: 4.464659408096828

Epoch: 5| Step: 8
Training loss: 4.5833701854727025
Validation loss: 4.459534138738413

Epoch: 5| Step: 9
Training loss: 4.547568566558806
Validation loss: 4.454421611991792

Epoch: 5| Step: 10
Training loss: 4.2075680077735
Validation loss: 4.449215650906264

Epoch: 5| Step: 11
Training loss: 3.7087703118766098
Validation loss: 4.445000322997714

Epoch: 24| Step: 0
Training loss: 4.613524350601582
Validation loss: 4.440239790320845

Epoch: 5| Step: 1
Training loss: 4.10850068861199
Validation loss: 4.435023032884449

Epoch: 5| Step: 2
Training loss: 4.8054111338959835
Validation loss: 4.429574927997027

Epoch: 5| Step: 3
Training loss: 4.726936565130897
Validation loss: 4.42497050711938

Epoch: 5| Step: 4
Training loss: 4.524780917264742
Validation loss: 4.421594644562177

Epoch: 5| Step: 5
Training loss: 5.431664679075199
Validation loss: 4.414827677703621

Epoch: 5| Step: 6
Training loss: 4.88929764647542
Validation loss: 4.409868035529777

Epoch: 5| Step: 7
Training loss: 4.814487987956937
Validation loss: 4.404777154441956

Epoch: 5| Step: 8
Training loss: 3.6990623884176057
Validation loss: 4.399505503639513

Epoch: 5| Step: 9
Training loss: 4.024666548475292
Validation loss: 4.39439984612568

Epoch: 5| Step: 10
Training loss: 3.9217974286557857
Validation loss: 4.389490739014468

Epoch: 5| Step: 11
Training loss: 5.213039540421692
Validation loss: 4.38500283554722

Epoch: 25| Step: 0
Training loss: 4.994926548934233
Validation loss: 4.380393600023346

Epoch: 5| Step: 1
Training loss: 4.6779767764046305
Validation loss: 4.375122132186071

Epoch: 5| Step: 2
Training loss: 4.183652562174149
Validation loss: 4.369907576153195

Epoch: 5| Step: 3
Training loss: 4.738954853126962
Validation loss: 4.3650253393771195

Epoch: 5| Step: 4
Training loss: 4.486395085141895
Validation loss: 4.359867701608499

Epoch: 5| Step: 5
Training loss: 4.647299337092463
Validation loss: 4.3549010404313755

Epoch: 5| Step: 6
Training loss: 4.869777327191733
Validation loss: 4.349424840458195

Epoch: 5| Step: 7
Training loss: 4.497570865702574
Validation loss: 4.344944769022117

Epoch: 5| Step: 8
Training loss: 4.3404069289595375
Validation loss: 4.339800917136221

Epoch: 5| Step: 9
Training loss: 3.485070266124725
Validation loss: 4.334152679132297

Epoch: 5| Step: 10
Training loss: 4.350075924967117
Validation loss: 4.328828853109657

Epoch: 5| Step: 11
Training loss: 3.825469672594776
Validation loss: 4.323949068568496

Epoch: 26| Step: 0
Training loss: 4.50704912567958
Validation loss: 4.319376770005921

Epoch: 5| Step: 1
Training loss: 4.070748040442278
Validation loss: 4.313922417141873

Epoch: 5| Step: 2
Training loss: 4.491975835706302
Validation loss: 4.309282752126939

Epoch: 5| Step: 3
Training loss: 4.480003219671455
Validation loss: 4.304664948687645

Epoch: 5| Step: 4
Training loss: 3.6388576949499796
Validation loss: 4.29896781586967

Epoch: 5| Step: 5
Training loss: 4.233699054890171
Validation loss: 4.29458406816183

Epoch: 5| Step: 6
Training loss: 5.295488654364296
Validation loss: 4.2899875720273135

Epoch: 5| Step: 7
Training loss: 4.044477658490561
Validation loss: 4.2850223869249335

Epoch: 5| Step: 8
Training loss: 4.21568492170974
Validation loss: 4.279523506007588

Epoch: 5| Step: 9
Training loss: 4.363825887841371
Validation loss: 4.274497789215553

Epoch: 5| Step: 10
Training loss: 4.8693270810168245
Validation loss: 4.269270041695544

Epoch: 5| Step: 11
Training loss: 5.458087750605568
Validation loss: 4.26498994303595

Epoch: 27| Step: 0
Training loss: 4.312433214637983
Validation loss: 4.25951843617272

Epoch: 5| Step: 1
Training loss: 4.1756293730419545
Validation loss: 4.254786918376113

Epoch: 5| Step: 2
Training loss: 4.308336985209606
Validation loss: 4.250195367847965

Epoch: 5| Step: 3
Training loss: 4.604691741599675
Validation loss: 4.244720676819232

Epoch: 5| Step: 4
Training loss: 4.433814008846003
Validation loss: 4.239335325455581

Epoch: 5| Step: 5
Training loss: 5.096506320850274
Validation loss: 4.233511715920335

Epoch: 5| Step: 6
Training loss: 4.452951314115594
Validation loss: 4.22815269692337

Epoch: 5| Step: 7
Training loss: 3.813036646360968
Validation loss: 4.222648660592391

Epoch: 5| Step: 8
Training loss: 4.161244080924044
Validation loss: 4.2179346026570235

Epoch: 5| Step: 9
Training loss: 4.326590916852666
Validation loss: 4.213293196335082

Epoch: 5| Step: 10
Training loss: 4.14212227866773
Validation loss: 4.207802954699652

Epoch: 5| Step: 11
Training loss: 4.658288701388986
Validation loss: 4.202890713388674

Epoch: 28| Step: 0
Training loss: 4.242529642769204
Validation loss: 4.197456962587472

Epoch: 5| Step: 1
Training loss: 4.382182954939413
Validation loss: 4.193060229522323

Epoch: 5| Step: 2
Training loss: 4.264887372192301
Validation loss: 4.189422488748948

Epoch: 5| Step: 3
Training loss: 3.834217066415272
Validation loss: 4.1849404478830365

Epoch: 5| Step: 4
Training loss: 5.318273481277103
Validation loss: 4.179349991430882

Epoch: 5| Step: 5
Training loss: 4.562048484721871
Validation loss: 4.172879539828641

Epoch: 5| Step: 6
Training loss: 3.6080373952496694
Validation loss: 4.16798204957937

Epoch: 5| Step: 7
Training loss: 5.0390653388436775
Validation loss: 4.162390756844134

Epoch: 5| Step: 8
Training loss: 3.555864814050959
Validation loss: 4.15702974562823

Epoch: 5| Step: 9
Training loss: 3.899157012407896
Validation loss: 4.1526838506044115

Epoch: 5| Step: 10
Training loss: 4.119247355554789
Validation loss: 4.147992126350692

Epoch: 5| Step: 11
Training loss: 5.056788483981559
Validation loss: 4.143274819701803

Epoch: 29| Step: 0
Training loss: 4.66651961685287
Validation loss: 4.138159333254537

Epoch: 5| Step: 1
Training loss: 3.638525623570474
Validation loss: 4.133324753011494

Epoch: 5| Step: 2
Training loss: 3.578605519641689
Validation loss: 4.128298413669673

Epoch: 5| Step: 3
Training loss: 4.0586287613534395
Validation loss: 4.12332984559249

Epoch: 5| Step: 4
Training loss: 4.316440937714127
Validation loss: 4.118534622967219

Epoch: 5| Step: 5
Training loss: 3.808552934476809
Validation loss: 4.113235966069989

Epoch: 5| Step: 6
Training loss: 4.3868096224169655
Validation loss: 4.108192167249053

Epoch: 5| Step: 7
Training loss: 4.39978548740789
Validation loss: 4.10295740053043

Epoch: 5| Step: 8
Training loss: 4.617005526963418
Validation loss: 4.098259647770146

Epoch: 5| Step: 9
Training loss: 4.283896414906918
Validation loss: 4.09314997112202

Epoch: 5| Step: 10
Training loss: 4.505695130025591
Validation loss: 4.088167509546042

Epoch: 5| Step: 11
Training loss: 5.358891323496028
Validation loss: 4.083172477096966

Epoch: 30| Step: 0
Training loss: 4.598544777938672
Validation loss: 4.077904131329496

Epoch: 5| Step: 1
Training loss: 4.214641916217034
Validation loss: 4.072856676614375

Epoch: 5| Step: 2
Training loss: 3.251481818793446
Validation loss: 4.067876788699976

Epoch: 5| Step: 3
Training loss: 4.035766909867473
Validation loss: 4.062889334778052

Epoch: 5| Step: 4
Training loss: 4.836379023349505
Validation loss: 4.057836824877167

Epoch: 5| Step: 5
Training loss: 4.197148381331319
Validation loss: 4.05244505312971

Epoch: 5| Step: 6
Training loss: 4.078721744534179
Validation loss: 4.047639953702208

Epoch: 5| Step: 7
Training loss: 3.804990282484922
Validation loss: 4.042402051440079

Epoch: 5| Step: 8
Training loss: 4.76193604822326
Validation loss: 4.03735664298198

Epoch: 5| Step: 9
Training loss: 4.2045954858301045
Validation loss: 4.032300215941761

Epoch: 5| Step: 10
Training loss: 3.7390084989277184
Validation loss: 4.027198085870163

Epoch: 5| Step: 11
Training loss: 4.473411849385069
Validation loss: 4.022364125696269

Epoch: 31| Step: 0
Training loss: 3.874818859173452
Validation loss: 4.017560603688207

Epoch: 5| Step: 1
Training loss: 3.831585872794468
Validation loss: 4.012492728301022

Epoch: 5| Step: 2
Training loss: 3.9404831742032855
Validation loss: 4.007939243109635

Epoch: 5| Step: 3
Training loss: 4.273220133440107
Validation loss: 4.003165820129788

Epoch: 5| Step: 4
Training loss: 3.7571319154106586
Validation loss: 3.9985437325162687

Epoch: 5| Step: 5
Training loss: 4.530349536740937
Validation loss: 3.9933705129203463

Epoch: 5| Step: 6
Training loss: 4.501831105992846
Validation loss: 3.9884385125579542

Epoch: 5| Step: 7
Training loss: 4.0937288007114505
Validation loss: 3.9832773329710145

Epoch: 5| Step: 8
Training loss: 3.7092537041414424
Validation loss: 3.97862946876942

Epoch: 5| Step: 9
Training loss: 4.864515719328467
Validation loss: 3.973749461086477

Epoch: 5| Step: 10
Training loss: 4.152362353336149
Validation loss: 3.9684401513844376

Epoch: 5| Step: 11
Training loss: 2.1065356324082125
Validation loss: 3.9636787694944564

Epoch: 32| Step: 0
Training loss: 4.123131299837326
Validation loss: 3.9593264772753285

Epoch: 5| Step: 1
Training loss: 3.902146281915729
Validation loss: 3.9547055719676845

Epoch: 5| Step: 2
Training loss: 3.7829346490146802
Validation loss: 3.949539186663085

Epoch: 5| Step: 3
Training loss: 4.210785079207483
Validation loss: 3.945127385898688

Epoch: 5| Step: 4
Training loss: 4.593478032579563
Validation loss: 3.9406321243919527

Epoch: 5| Step: 5
Training loss: 3.7030607451324795
Validation loss: 3.9354093238892656

Epoch: 5| Step: 6
Training loss: 4.71350715863433
Validation loss: 3.9311253449569445

Epoch: 5| Step: 7
Training loss: 3.718976438664646
Validation loss: 3.9262669201194527

Epoch: 5| Step: 8
Training loss: 4.10677774832302
Validation loss: 3.9212673471342936

Epoch: 5| Step: 9
Training loss: 4.520079214364055
Validation loss: 3.9168071958343056

Epoch: 5| Step: 10
Training loss: 3.446780076021105
Validation loss: 3.9120556781173352

Epoch: 5| Step: 11
Training loss: 2.4851123987026806
Validation loss: 3.9071013171452766

Epoch: 33| Step: 0
Training loss: 3.5484192297199315
Validation loss: 3.9023417389145036

Epoch: 5| Step: 1
Training loss: 3.8473710782249757
Validation loss: 3.898204238426312

Epoch: 5| Step: 2
Training loss: 4.291746762216533
Validation loss: 3.893779160383748

Epoch: 5| Step: 3
Training loss: 4.469155246526317
Validation loss: 3.888902218924489

Epoch: 5| Step: 4
Training loss: 3.2476184628958484
Validation loss: 3.8843619148195625

Epoch: 5| Step: 5
Training loss: 4.337034014645199
Validation loss: 3.879934148467234

Epoch: 5| Step: 6
Training loss: 4.023117023037571
Validation loss: 3.8754945306133597

Epoch: 5| Step: 7
Training loss: 4.202740619767179
Validation loss: 3.8706607056727442

Epoch: 5| Step: 8
Training loss: 4.031831211508093
Validation loss: 3.8654225544406473

Epoch: 5| Step: 9
Training loss: 3.9634503401244743
Validation loss: 3.860874152554747

Epoch: 5| Step: 10
Training loss: 3.951613306795141
Validation loss: 3.8561982118909777

Epoch: 5| Step: 11
Training loss: 4.376284819363387
Validation loss: 3.8515634749529304

Epoch: 34| Step: 0
Training loss: 4.542222201933574
Validation loss: 3.84721739149345

Epoch: 5| Step: 1
Training loss: 4.1722736525353445
Validation loss: 3.8457912411079063

Epoch: 5| Step: 2
Training loss: 3.922601883235513
Validation loss: 3.8435553886541776

Epoch: 5| Step: 3
Training loss: 3.45008861593796
Validation loss: 3.8366217122784763

Epoch: 5| Step: 4
Training loss: 3.0641931018686717
Validation loss: 3.831290134180307

Epoch: 5| Step: 5
Training loss: 4.3780798834164925
Validation loss: 3.824997814443791

Epoch: 5| Step: 6
Training loss: 4.1063221081770385
Validation loss: 3.820065074935577

Epoch: 5| Step: 7
Training loss: 4.433932307420481
Validation loss: 3.81511383402601

Epoch: 5| Step: 8
Training loss: 3.678779635839829
Validation loss: 3.810319443691704

Epoch: 5| Step: 9
Training loss: 4.049284346658403
Validation loss: 3.8049790977575615

Epoch: 5| Step: 10
Training loss: 3.698994711322206
Validation loss: 3.7997892103792568

Epoch: 5| Step: 11
Training loss: 2.9018107318847726
Validation loss: 3.7947772213310733

Epoch: 35| Step: 0
Training loss: 3.722368675564489
Validation loss: 3.7895368770682945

Epoch: 5| Step: 1
Training loss: 4.33770155204789
Validation loss: 3.7844302619912367

Epoch: 5| Step: 2
Training loss: 4.031034951794982
Validation loss: 3.779732901616025

Epoch: 5| Step: 3
Training loss: 4.096371808492022
Validation loss: 3.77476900248683

Epoch: 5| Step: 4
Training loss: 3.9547423420347276
Validation loss: 3.7692433723326837

Epoch: 5| Step: 5
Training loss: 3.916974901015209
Validation loss: 3.7638525214242815

Epoch: 5| Step: 6
Training loss: 4.421087080240485
Validation loss: 3.7591380783772097

Epoch: 5| Step: 7
Training loss: 3.522270601490537
Validation loss: 3.7542890339651316

Epoch: 5| Step: 8
Training loss: 3.2679459934231128
Validation loss: 3.7498368810568548

Epoch: 5| Step: 9
Training loss: 4.1050306207999325
Validation loss: 3.7446232184387087

Epoch: 5| Step: 10
Training loss: 3.3247213375945135
Validation loss: 3.7394016490923736

Epoch: 5| Step: 11
Training loss: 4.000538789701976
Validation loss: 3.734950304607203

Epoch: 36| Step: 0
Training loss: 4.149320174457046
Validation loss: 3.729964717880506

Epoch: 5| Step: 1
Training loss: 3.8738621917854568
Validation loss: 3.7246647660461276

Epoch: 5| Step: 2
Training loss: 3.6681525658647245
Validation loss: 3.7198929673096846

Epoch: 5| Step: 3
Training loss: 3.945761838196098
Validation loss: 3.7149269370128875

Epoch: 5| Step: 4
Training loss: 3.997298520505584
Validation loss: 3.7104577273039396

Epoch: 5| Step: 5
Training loss: 3.8747574514958174
Validation loss: 3.7052757171617947

Epoch: 5| Step: 6
Training loss: 4.350208558092516
Validation loss: 3.7002816638617966

Epoch: 5| Step: 7
Training loss: 3.8232803518210123
Validation loss: 3.695388809287206

Epoch: 5| Step: 8
Training loss: 3.5800814547942097
Validation loss: 3.690005340365549

Epoch: 5| Step: 9
Training loss: 3.7478130321300327
Validation loss: 3.6845847475908404

Epoch: 5| Step: 10
Training loss: 3.115072579801183
Validation loss: 3.6796284783577753

Epoch: 5| Step: 11
Training loss: 3.8306965812509115
Validation loss: 3.6745984630112476

Epoch: 37| Step: 0
Training loss: 3.7127706718031166
Validation loss: 3.669998555230767

Epoch: 5| Step: 1
Training loss: 3.9675525450757436
Validation loss: 3.6656564419030193

Epoch: 5| Step: 2
Training loss: 3.6921568092365336
Validation loss: 3.6608167694889935

Epoch: 5| Step: 3
Training loss: 4.037669666610918
Validation loss: 3.6557844577464422

Epoch: 5| Step: 4
Training loss: 3.7711106228258333
Validation loss: 3.650702030349044

Epoch: 5| Step: 5
Training loss: 3.159236590242947
Validation loss: 3.6457071809287314

Epoch: 5| Step: 6
Training loss: 3.8807967113241095
Validation loss: 3.6410876950130677

Epoch: 5| Step: 7
Training loss: 4.386454818000674
Validation loss: 3.6360442959661516

Epoch: 5| Step: 8
Training loss: 3.890644854759203
Validation loss: 3.6317968828864595

Epoch: 5| Step: 9
Training loss: 3.4852858922259613
Validation loss: 3.626283388300794

Epoch: 5| Step: 10
Training loss: 3.7962383474322494
Validation loss: 3.620965855934806

Epoch: 5| Step: 11
Training loss: 1.817867618201922
Validation loss: 3.6164545974142253

Epoch: 38| Step: 0
Training loss: 3.687326459518791
Validation loss: 3.6119553066236594

Epoch: 5| Step: 1
Training loss: 3.619187529209012
Validation loss: 3.607840135990833

Epoch: 5| Step: 2
Training loss: 3.654811608799144
Validation loss: 3.6033540298356876

Epoch: 5| Step: 3
Training loss: 4.115119660910044
Validation loss: 3.59878198805321

Epoch: 5| Step: 4
Training loss: 3.873752885529981
Validation loss: 3.59373890418952

Epoch: 5| Step: 5
Training loss: 3.328555800087244
Validation loss: 3.5891894220505156

Epoch: 5| Step: 6
Training loss: 3.5188632547097765
Validation loss: 3.584884444608513

Epoch: 5| Step: 7
Training loss: 3.897455921327579
Validation loss: 3.5805085196281605

Epoch: 5| Step: 8
Training loss: 4.403072428880184
Validation loss: 3.575660292574553

Epoch: 5| Step: 9
Training loss: 3.1496011935684542
Validation loss: 3.571360405770962

Epoch: 5| Step: 10
Training loss: 3.1877620813671688
Validation loss: 3.5664098655345313

Epoch: 5| Step: 11
Training loss: 5.232932549617629
Validation loss: 3.5618720309830882

Epoch: 39| Step: 0
Training loss: 3.7853682609210657
Validation loss: 3.556733729487872

Epoch: 5| Step: 1
Training loss: 3.7315001335200244
Validation loss: 3.551755065888937

Epoch: 5| Step: 2
Training loss: 4.064110774039875
Validation loss: 3.546895641877415

Epoch: 5| Step: 3
Training loss: 3.5531787395187795
Validation loss: 3.54190906181357

Epoch: 5| Step: 4
Training loss: 3.9722071931164904
Validation loss: 3.53682371264236

Epoch: 5| Step: 5
Training loss: 3.720430907856873
Validation loss: 3.532382980256851

Epoch: 5| Step: 6
Training loss: 3.6733710954344034
Validation loss: 3.5272165686011503

Epoch: 5| Step: 7
Training loss: 3.722039955256772
Validation loss: 3.522490329688547

Epoch: 5| Step: 8
Training loss: 3.172469059978905
Validation loss: 3.517763626090316

Epoch: 5| Step: 9
Training loss: 3.4116657844347262
Validation loss: 3.5124639131405035

Epoch: 5| Step: 10
Training loss: 3.32052001304667
Validation loss: 3.507677037399531

Epoch: 5| Step: 11
Training loss: 4.404780149483423
Validation loss: 3.5032861133179454

Epoch: 40| Step: 0
Training loss: 3.9372542773882424
Validation loss: 3.4986702345659317

Epoch: 5| Step: 1
Training loss: 3.783887463515247
Validation loss: 3.4935373916037173

Epoch: 5| Step: 2
Training loss: 3.8387262031714426
Validation loss: 3.4886004567804765

Epoch: 5| Step: 3
Training loss: 3.209574092049591
Validation loss: 3.4838794076402206

Epoch: 5| Step: 4
Training loss: 3.1170259591601295
Validation loss: 3.4794759022840784

Epoch: 5| Step: 5
Training loss: 3.6896628809401806
Validation loss: 3.4749978534316788

Epoch: 5| Step: 6
Training loss: 3.2511742744588195
Validation loss: 3.470292072215981

Epoch: 5| Step: 7
Training loss: 3.983092576629248
Validation loss: 3.4658311184631985

Epoch: 5| Step: 8
Training loss: 3.779379768349649
Validation loss: 3.460986576923557

Epoch: 5| Step: 9
Training loss: 3.6544911645387645
Validation loss: 3.456343421110352

Epoch: 5| Step: 10
Training loss: 3.2975703224856754
Validation loss: 3.4514222528306346

Epoch: 5| Step: 11
Training loss: 3.9841206787323395
Validation loss: 3.4469300305748316

Epoch: 41| Step: 0
Training loss: 3.799694505759268
Validation loss: 3.4423622769223465

Epoch: 5| Step: 1
Training loss: 3.1016215359620762
Validation loss: 3.437907599356793

Epoch: 5| Step: 2
Training loss: 4.010951309566702
Validation loss: 3.4333836039470773

Epoch: 5| Step: 3
Training loss: 3.7808885638047016
Validation loss: 3.429310539691434

Epoch: 5| Step: 4
Training loss: 3.6481014644248546
Validation loss: 3.4241753833858164

Epoch: 5| Step: 5
Training loss: 3.4016975989298976
Validation loss: 3.4190253784369897

Epoch: 5| Step: 6
Training loss: 3.352418021181893
Validation loss: 3.4145800200456544

Epoch: 5| Step: 7
Training loss: 2.5037137104819265
Validation loss: 3.4099720558856164

Epoch: 5| Step: 8
Training loss: 3.927527985160481
Validation loss: 3.4058713556688485

Epoch: 5| Step: 9
Training loss: 4.22397115245274
Validation loss: 3.4014620479761977

Epoch: 5| Step: 10
Training loss: 2.901841788955325
Validation loss: 3.3970587611977563

Epoch: 5| Step: 11
Training loss: 4.158841121352949
Validation loss: 3.392632389750989

Epoch: 42| Step: 0
Training loss: 3.456336689805184
Validation loss: 3.3879156817167875

Epoch: 5| Step: 1
Training loss: 3.0432241623995275
Validation loss: 3.3837471332310085

Epoch: 5| Step: 2
Training loss: 4.177980676981578
Validation loss: 3.3792001085629577

Epoch: 5| Step: 3
Training loss: 3.1159088648248434
Validation loss: 3.3749685992440255

Epoch: 5| Step: 4
Training loss: 3.270957426078079
Validation loss: 3.3708246034494214

Epoch: 5| Step: 5
Training loss: 3.197721659692446
Validation loss: 3.3664987218076203

Epoch: 5| Step: 6
Training loss: 3.8011790554522538
Validation loss: 3.3622204225920123

Epoch: 5| Step: 7
Training loss: 3.831966792350981
Validation loss: 3.3582593144541537

Epoch: 5| Step: 8
Training loss: 3.993674044416604
Validation loss: 3.3538509224232635

Epoch: 5| Step: 9
Training loss: 2.7796959982490685
Validation loss: 3.3492687945627186

Epoch: 5| Step: 10
Training loss: 3.6584107624685616
Validation loss: 3.345344365369208

Epoch: 5| Step: 11
Training loss: 3.2640955505596945
Validation loss: 3.3407207088718844

Epoch: 43| Step: 0
Training loss: 3.3236136507700413
Validation loss: 3.336523196689271

Epoch: 5| Step: 1
Training loss: 3.973726771629676
Validation loss: 3.332014595875593

Epoch: 5| Step: 2
Training loss: 3.0412724557369755
Validation loss: 3.3277553329169027

Epoch: 5| Step: 3
Training loss: 3.451561068754301
Validation loss: 3.3234445616959896

Epoch: 5| Step: 4
Training loss: 3.3246457535038982
Validation loss: 3.3191649005785266

Epoch: 5| Step: 5
Training loss: 3.6370242407439064
Validation loss: 3.315285704926917

Epoch: 5| Step: 6
Training loss: 3.2281543416465097
Validation loss: 3.310550601923372

Epoch: 5| Step: 7
Training loss: 3.3396445767091256
Validation loss: 3.3062279239583354

Epoch: 5| Step: 8
Training loss: 3.869764544399227
Validation loss: 3.3022850328009428

Epoch: 5| Step: 9
Training loss: 3.621043578358939
Validation loss: 3.2980407172604966

Epoch: 5| Step: 10
Training loss: 3.3051220763683244
Validation loss: 3.2936296987551086

Epoch: 5| Step: 11
Training loss: 2.131373999783502
Validation loss: 3.2893203730912237

Epoch: 44| Step: 0
Training loss: 3.4572886225698567
Validation loss: 3.2855923998529235

Epoch: 5| Step: 1
Training loss: 3.203668762201054
Validation loss: 3.281596604463562

Epoch: 5| Step: 2
Training loss: 3.804793401415327
Validation loss: 3.2779210657833984

Epoch: 5| Step: 3
Training loss: 3.2879990695664327
Validation loss: 3.274283091262521

Epoch: 5| Step: 4
Training loss: 3.4382136211058656
Validation loss: 3.270417263918569

Epoch: 5| Step: 5
Training loss: 3.4941606856868934
Validation loss: 3.2668095437418145

Epoch: 5| Step: 6
Training loss: 3.306261341674043
Validation loss: 3.2631829361812894

Epoch: 5| Step: 7
Training loss: 3.3912603248919897
Validation loss: 3.25927301566114

Epoch: 5| Step: 8
Training loss: 2.8724961365623156
Validation loss: 3.2556361881092424

Epoch: 5| Step: 9
Training loss: 3.5566317763996187
Validation loss: 3.251530549752284

Epoch: 5| Step: 10
Training loss: 3.725637261073417
Validation loss: 3.2476362900575206

Epoch: 5| Step: 11
Training loss: 2.4859874938502964
Validation loss: 3.2435929343062995

Epoch: 45| Step: 0
Training loss: 3.6834474698387547
Validation loss: 3.2397523306446656

Epoch: 5| Step: 1
Training loss: 2.826155846371703
Validation loss: 3.2355566584425253

Epoch: 5| Step: 2
Training loss: 3.4845921743821235
Validation loss: 3.2320904979664924

Epoch: 5| Step: 3
Training loss: 3.3709953001991626
Validation loss: 3.2283117649573647

Epoch: 5| Step: 4
Training loss: 3.8381974968758987
Validation loss: 3.224494499195147

Epoch: 5| Step: 5
Training loss: 3.571506425826396
Validation loss: 3.220559663895174

Epoch: 5| Step: 6
Training loss: 2.53193033753515
Validation loss: 3.21670957661867

Epoch: 5| Step: 7
Training loss: 3.3440771210278384
Validation loss: 3.212767346460653

Epoch: 5| Step: 8
Training loss: 3.404362987022992
Validation loss: 3.209069831129754

Epoch: 5| Step: 9
Training loss: 3.491460600775844
Validation loss: 3.205402649964883

Epoch: 5| Step: 10
Training loss: 3.326615971986133
Validation loss: 3.201498936968072

Epoch: 5| Step: 11
Training loss: 2.8149249325325636
Validation loss: 3.198085439786595

Epoch: 46| Step: 0
Training loss: 3.57872490663888
Validation loss: 3.193776919008244

Epoch: 5| Step: 1
Training loss: 3.4301049884265087
Validation loss: 3.189943741897249

Epoch: 5| Step: 2
Training loss: 3.6353167034640688
Validation loss: 3.186360700985678

Epoch: 5| Step: 3
Training loss: 3.4683054046264066
Validation loss: 3.182012559270939

Epoch: 5| Step: 4
Training loss: 3.4385809845955455
Validation loss: 3.17836990988185

Epoch: 5| Step: 5
Training loss: 3.1888839110964367
Validation loss: 3.174430109301635

Epoch: 5| Step: 6
Training loss: 3.364845682944723
Validation loss: 3.171203889928837

Epoch: 5| Step: 7
Training loss: 2.9122038531056607
Validation loss: 3.167253262163781

Epoch: 5| Step: 8
Training loss: 3.157649721294326
Validation loss: 3.1633695181059016

Epoch: 5| Step: 9
Training loss: 3.500879313502881
Validation loss: 3.159958753477584

Epoch: 5| Step: 10
Training loss: 2.554888049545269
Validation loss: 3.156397000908836

Epoch: 5| Step: 11
Training loss: 3.7572914444334877
Validation loss: 3.1526015632014057

Epoch: 47| Step: 0
Training loss: 3.1857118265654454
Validation loss: 3.148813047011332

Epoch: 5| Step: 1
Training loss: 3.1025719525326227
Validation loss: 3.1449829345810203

Epoch: 5| Step: 2
Training loss: 3.5018368396929995
Validation loss: 3.1413165670623724

Epoch: 5| Step: 3
Training loss: 3.5245214854438016
Validation loss: 3.1374723701729605

Epoch: 5| Step: 4
Training loss: 3.0651865483278184
Validation loss: 3.133761064945828

Epoch: 5| Step: 5
Training loss: 3.441157943652698
Validation loss: 3.1304588101290065

Epoch: 5| Step: 6
Training loss: 3.111277549318222
Validation loss: 3.127072425931697

Epoch: 5| Step: 7
Training loss: 3.4864417818920983
Validation loss: 3.1233337442359805

Epoch: 5| Step: 8
Training loss: 3.0619434707376887
Validation loss: 3.119825793903821

Epoch: 5| Step: 9
Training loss: 3.4992012747421697
Validation loss: 3.116183065737881

Epoch: 5| Step: 10
Training loss: 3.209862596417239
Validation loss: 3.112191076791501

Epoch: 5| Step: 11
Training loss: 1.6566256690884968
Validation loss: 3.108871131595476

Epoch: 48| Step: 0
Training loss: 3.3526103197987234
Validation loss: 3.1053870744181142

Epoch: 5| Step: 1
Training loss: 3.227337095373344
Validation loss: 3.1024894546290636

Epoch: 5| Step: 2
Training loss: 2.9257224144514016
Validation loss: 3.0991706786078876

Epoch: 5| Step: 3
Training loss: 3.3631109710724028
Validation loss: 3.096111070968071

Epoch: 5| Step: 4
Training loss: 3.4425342109880686
Validation loss: 3.093410190711316

Epoch: 5| Step: 5
Training loss: 3.3034124417139923
Validation loss: 3.08974119354589

Epoch: 5| Step: 6
Training loss: 3.419893431313755
Validation loss: 3.0870326742562937

Epoch: 5| Step: 7
Training loss: 2.7037642059446783
Validation loss: 3.083248963146777

Epoch: 5| Step: 8
Training loss: 3.3381097586604693
Validation loss: 3.0803678380755506

Epoch: 5| Step: 9
Training loss: 3.2152872069412584
Validation loss: 3.07692765574084

Epoch: 5| Step: 10
Training loss: 2.936934558745897
Validation loss: 3.07364323749541

Epoch: 5| Step: 11
Training loss: 4.200477191519388
Validation loss: 3.0709330357981424

Epoch: 49| Step: 0
Training loss: 2.9012174615839146
Validation loss: 3.066817756140883

Epoch: 5| Step: 1
Training loss: 3.7783282633106445
Validation loss: 3.0642470158186916

Epoch: 5| Step: 2
Training loss: 3.1857028457563272
Validation loss: 3.060240499144889

Epoch: 5| Step: 3
Training loss: 3.4079584159552727
Validation loss: 3.056872585542399

Epoch: 5| Step: 4
Training loss: 3.279519487632782
Validation loss: 3.053375131336233

Epoch: 5| Step: 5
Training loss: 2.6598886139572966
Validation loss: 3.0501874670668037

Epoch: 5| Step: 6
Training loss: 3.0158808308136025
Validation loss: 3.0468697735342207

Epoch: 5| Step: 7
Training loss: 3.629100453546128
Validation loss: 3.043929937815621

Epoch: 5| Step: 8
Training loss: 2.8702117187881706
Validation loss: 3.0406762572591486

Epoch: 5| Step: 9
Training loss: 3.30179926054471
Validation loss: 3.037226961891299

Epoch: 5| Step: 10
Training loss: 2.996607292557386
Validation loss: 3.0343316233212922

Epoch: 5| Step: 11
Training loss: 2.688292985184899
Validation loss: 3.0309534648822622

Epoch: 50| Step: 0
Training loss: 2.7512141928450626
Validation loss: 3.027655695768686

Epoch: 5| Step: 1
Training loss: 3.704175582777749
Validation loss: 3.024326295680569

Epoch: 5| Step: 2
Training loss: 3.341083497288275
Validation loss: 3.020934383850711

Epoch: 5| Step: 3
Training loss: 3.503266309054069
Validation loss: 3.0176772577654085

Epoch: 5| Step: 4
Training loss: 3.3196200737097694
Validation loss: 3.014228757811638

Epoch: 5| Step: 5
Training loss: 3.179383659373497
Validation loss: 3.0112073458348787

Epoch: 5| Step: 6
Training loss: 3.0433136300169545
Validation loss: 3.0081869841788493

Epoch: 5| Step: 7
Training loss: 3.0202522157355127
Validation loss: 3.0050619123854494

Epoch: 5| Step: 8
Training loss: 3.0443850001760415
Validation loss: 3.0020755700658044

Epoch: 5| Step: 9
Training loss: 2.6957022122584857
Validation loss: 2.998496778365039

Epoch: 5| Step: 10
Training loss: 3.083924846787341
Validation loss: 2.995452175555171

Epoch: 5| Step: 11
Training loss: 2.375328643547237
Validation loss: 2.992269745601922

Epoch: 51| Step: 0
Training loss: 3.0578121195048786
Validation loss: 2.9893120244936555

Epoch: 5| Step: 1
Training loss: 3.0601021858057686
Validation loss: 2.9859990532620824

Epoch: 5| Step: 2
Training loss: 3.2423725121346387
Validation loss: 2.983061916020775

Epoch: 5| Step: 3
Training loss: 3.2858822051078955
Validation loss: 2.9802866388882654

Epoch: 5| Step: 4
Training loss: 2.7096763997581426
Validation loss: 2.9770819176594223

Epoch: 5| Step: 5
Training loss: 3.6580311927779436
Validation loss: 2.9742164343933544

Epoch: 5| Step: 6
Training loss: 3.0380603540288136
Validation loss: 2.9704755319277765

Epoch: 5| Step: 7
Training loss: 2.677869263304562
Validation loss: 2.96873555430863

Epoch: 5| Step: 8
Training loss: 2.3537205523787623
Validation loss: 2.965552411599619

Epoch: 5| Step: 9
Training loss: 3.2228139757803818
Validation loss: 2.963513990428303

Epoch: 5| Step: 10
Training loss: 3.6091517259641877
Validation loss: 2.9596827523233

Epoch: 5| Step: 11
Training loss: 3.6457011316944485
Validation loss: 2.95726313956273

Epoch: 52| Step: 0
Training loss: 2.9981518456786165
Validation loss: 2.9542652498824222

Epoch: 5| Step: 1
Training loss: 2.8305176787815722
Validation loss: 2.9515007335688423

Epoch: 5| Step: 2
Training loss: 3.303851948614565
Validation loss: 2.9491615710915546

Epoch: 5| Step: 3
Training loss: 3.220708010769869
Validation loss: 2.945141936607456

Epoch: 5| Step: 4
Training loss: 3.062028342536301
Validation loss: 2.9426762278107947

Epoch: 5| Step: 5
Training loss: 2.992294429133363
Validation loss: 2.939317303431335

Epoch: 5| Step: 6
Training loss: 3.327075201672335
Validation loss: 2.9382383250615813

Epoch: 5| Step: 7
Training loss: 2.9672034803043545
Validation loss: 2.9360224951242646

Epoch: 5| Step: 8
Training loss: 3.207415726135106
Validation loss: 2.9314516274704876

Epoch: 5| Step: 9
Training loss: 3.4751829689212723
Validation loss: 2.929093586379487

Epoch: 5| Step: 10
Training loss: 2.703699480873112
Validation loss: 2.925018458973819

Epoch: 5| Step: 11
Training loss: 1.1428718385007026
Validation loss: 2.9219432149665843

Epoch: 53| Step: 0
Training loss: 2.50113165991531
Validation loss: 2.919703188120496

Epoch: 5| Step: 1
Training loss: 2.917556590599501
Validation loss: 2.9175850830049637

Epoch: 5| Step: 2
Training loss: 2.848162570728166
Validation loss: 2.915340180981376

Epoch: 5| Step: 3
Training loss: 3.0526943875340096
Validation loss: 2.9117522469502592

Epoch: 5| Step: 4
Training loss: 2.8686245427509243
Validation loss: 2.909380276378487

Epoch: 5| Step: 5
Training loss: 2.978325749583125
Validation loss: 2.9068187956870695

Epoch: 5| Step: 6
Training loss: 3.0250356624802532
Validation loss: 2.905486474868226

Epoch: 5| Step: 7
Training loss: 3.4236182384059983
Validation loss: 2.903042790809638

Epoch: 5| Step: 8
Training loss: 2.808700198728132
Validation loss: 2.9011822546013124

Epoch: 5| Step: 9
Training loss: 3.355015538687048
Validation loss: 2.898431238131687

Epoch: 5| Step: 10
Training loss: 3.62759411827096
Validation loss: 2.897336749106941

Epoch: 5| Step: 11
Training loss: 2.914656591324117
Validation loss: 2.8949159477233946

Epoch: 54| Step: 0
Training loss: 2.895480310524956
Validation loss: 2.8919044378093335

Epoch: 5| Step: 1
Training loss: 3.27648376166495
Validation loss: 2.8898715918964015

Epoch: 5| Step: 2
Training loss: 2.8352828518143443
Validation loss: 2.887517743654766

Epoch: 5| Step: 3
Training loss: 3.4256949506305125
Validation loss: 2.8850828843025558

Epoch: 5| Step: 4
Training loss: 3.190816761796396
Validation loss: 2.882457104755536

Epoch: 5| Step: 5
Training loss: 3.283552542660927
Validation loss: 2.8800069325802955

Epoch: 5| Step: 6
Training loss: 2.962220409736483
Validation loss: 2.876933031946454

Epoch: 5| Step: 7
Training loss: 3.2148802373954615
Validation loss: 2.8736912367615917

Epoch: 5| Step: 8
Training loss: 2.9045442887533306
Validation loss: 2.8718578299367836

Epoch: 5| Step: 9
Training loss: 2.6231546727779693
Validation loss: 2.867453851203758

Epoch: 5| Step: 10
Training loss: 2.7952489974696753
Validation loss: 2.867084806233343

Epoch: 5| Step: 11
Training loss: 1.2610395274429582
Validation loss: 2.8648409479073957

Epoch: 55| Step: 0
Training loss: 2.64410162496976
Validation loss: 2.862555112960629

Epoch: 5| Step: 1
Training loss: 3.038087977890266
Validation loss: 2.860835114276738

Epoch: 5| Step: 2
Training loss: 3.6216886457632698
Validation loss: 2.8595996414076024

Epoch: 5| Step: 3
Training loss: 2.523436271738043
Validation loss: 2.8572375154851377

Epoch: 5| Step: 4
Training loss: 2.7847674982624064
Validation loss: 2.856232766614882

Epoch: 5| Step: 5
Training loss: 2.9937308292929874
Validation loss: 2.8543105100782244

Epoch: 5| Step: 6
Training loss: 2.9851511001043316
Validation loss: 2.8534054588028757

Epoch: 5| Step: 7
Training loss: 2.9370464218258383
Validation loss: 2.8499378958845516

Epoch: 5| Step: 8
Training loss: 3.2698280263586414
Validation loss: 2.8481152255741833

Epoch: 5| Step: 9
Training loss: 2.694988905790067
Validation loss: 2.8461838776283868

Epoch: 5| Step: 10
Training loss: 3.0303456638689417
Validation loss: 2.8428778376399975

Epoch: 5| Step: 11
Training loss: 4.0839108169039156
Validation loss: 2.8411233320082356

Epoch: 56| Step: 0
Training loss: 3.488218095470434
Validation loss: 2.84089022196659

Epoch: 5| Step: 1
Training loss: 2.897383917391394
Validation loss: 2.845186684550236

Epoch: 5| Step: 2
Training loss: 3.0369297575503653
Validation loss: 2.8339254179031097

Epoch: 5| Step: 3
Training loss: 2.8596361384981295
Validation loss: 2.8298508065991057

Epoch: 5| Step: 4
Training loss: 2.7336394274292206
Validation loss: 2.82654041698483

Epoch: 5| Step: 5
Training loss: 3.0989441088609118
Validation loss: 2.8286594707787973

Epoch: 5| Step: 6
Training loss: 2.7427405861941696
Validation loss: 2.8273499341807318

Epoch: 5| Step: 7
Training loss: 3.0951639662588706
Validation loss: 2.829504052683657

Epoch: 5| Step: 8
Training loss: 2.9646285510462707
Validation loss: 2.828103140927417

Epoch: 5| Step: 9
Training loss: 2.6518492202530646
Validation loss: 2.8222904930207107

Epoch: 5| Step: 10
Training loss: 3.1414396074104043
Validation loss: 2.8167539955930843

Epoch: 5| Step: 11
Training loss: 2.331782802209959
Validation loss: 2.812407004620322

Epoch: 57| Step: 0
Training loss: 3.2692625967694524
Validation loss: 2.8094964732045966

Epoch: 5| Step: 1
Training loss: 2.941006130446887
Validation loss: 2.8062426719201685

Epoch: 5| Step: 2
Training loss: 3.753013544389052
Validation loss: 2.8069924470516523

Epoch: 5| Step: 3
Training loss: 2.368153491439035
Validation loss: 2.8051316486070936

Epoch: 5| Step: 4
Training loss: 2.945670918074993
Validation loss: 2.803381421832994

Epoch: 5| Step: 5
Training loss: 2.7409009387859666
Validation loss: 2.8022823593948947

Epoch: 5| Step: 6
Training loss: 2.8460740873299994
Validation loss: 2.798087366984445

Epoch: 5| Step: 7
Training loss: 2.85549864120598
Validation loss: 2.7962970953522195

Epoch: 5| Step: 8
Training loss: 2.4559121790166847
Validation loss: 2.7956393476368624

Epoch: 5| Step: 9
Training loss: 3.0916861383556684
Validation loss: 2.7916735226750995

Epoch: 5| Step: 10
Training loss: 2.83832544092353
Validation loss: 2.788637465459602

Epoch: 5| Step: 11
Training loss: 3.14820107455009
Validation loss: 2.7859843317368544

Epoch: 58| Step: 0
Training loss: 2.589227433323896
Validation loss: 2.7834135384244014

Epoch: 5| Step: 1
Training loss: 3.0832135117076884
Validation loss: 2.7808205776667

Epoch: 5| Step: 2
Training loss: 2.2561832872497933
Validation loss: 2.779650796323076

Epoch: 5| Step: 3
Training loss: 2.82208179548368
Validation loss: 2.776557066967024

Epoch: 5| Step: 4
Training loss: 2.7487200445925595
Validation loss: 2.774425574152015

Epoch: 5| Step: 5
Training loss: 3.036176630282474
Validation loss: 2.7731655363602576

Epoch: 5| Step: 6
Training loss: 3.2059114571169967
Validation loss: 2.7694255053621806

Epoch: 5| Step: 7
Training loss: 3.039485009642313
Validation loss: 2.7667899506937492

Epoch: 5| Step: 8
Training loss: 3.191024028997227
Validation loss: 2.7674462128374295

Epoch: 5| Step: 9
Training loss: 3.0307179406803786
Validation loss: 2.7642489186949777

Epoch: 5| Step: 10
Training loss: 2.9723808170997863
Validation loss: 2.7682534961701903

Epoch: 5| Step: 11
Training loss: 2.8818073122625263
Validation loss: 2.762282131055951

Epoch: 59| Step: 0
Training loss: 3.1723664001759526
Validation loss: 2.765919534980237

Epoch: 5| Step: 1
Training loss: 3.412927364655031
Validation loss: 2.769291656202532

Epoch: 5| Step: 2
Training loss: 2.759999043284817
Validation loss: 2.769705038352661

Epoch: 5| Step: 3
Training loss: 2.9490505953717547
Validation loss: 2.772982607505741

Epoch: 5| Step: 4
Training loss: 3.134104474184378
Validation loss: 2.7739051746905017

Epoch: 5| Step: 5
Training loss: 2.5699163902724
Validation loss: 2.7752939521047484

Epoch: 5| Step: 6
Training loss: 2.8725947394488793
Validation loss: 2.7759219042988263

Epoch: 5| Step: 7
Training loss: 2.6082047448032544
Validation loss: 2.7666918498256603

Epoch: 5| Step: 8
Training loss: 2.6350640424151734
Validation loss: 2.76022502425864

Epoch: 5| Step: 9
Training loss: 2.647518122163442
Validation loss: 2.7550384574878333

Epoch: 5| Step: 10
Training loss: 3.086135587491237
Validation loss: 2.7508679595227137

Epoch: 5| Step: 11
Training loss: 2.7471650856829855
Validation loss: 2.7474487854011405

Epoch: 60| Step: 0
Training loss: 2.3818691700223646
Validation loss: 2.7458593377911353

Epoch: 5| Step: 1
Training loss: 2.351089886289307
Validation loss: 2.743961912152866

Epoch: 5| Step: 2
Training loss: 3.039771617542411
Validation loss: 2.7465353945693347

Epoch: 5| Step: 3
Training loss: 2.5112416242855713
Validation loss: 2.749199725518217

Epoch: 5| Step: 4
Training loss: 3.0667570460173192
Validation loss: 2.752117201726422

Epoch: 5| Step: 5
Training loss: 2.828054606367759
Validation loss: 2.746176973893276

Epoch: 5| Step: 6
Training loss: 2.660546272803118
Validation loss: 2.7370075632080737

Epoch: 5| Step: 7
Training loss: 3.162288969334354
Validation loss: 2.731383792937705

Epoch: 5| Step: 8
Training loss: 3.063309698695127
Validation loss: 2.729470994351841

Epoch: 5| Step: 9
Training loss: 3.4253437454473232
Validation loss: 2.728988337089868

Epoch: 5| Step: 10
Training loss: 2.9508020054352615
Validation loss: 2.728394724361623

Epoch: 5| Step: 11
Training loss: 3.120727975965798
Validation loss: 2.7282205366118286

Epoch: 61| Step: 0
Training loss: 2.5565906400289418
Validation loss: 2.7285192694852425

Epoch: 5| Step: 1
Training loss: 3.214142102863136
Validation loss: 2.7281129576776664

Epoch: 5| Step: 2
Training loss: 3.424835318065904
Validation loss: 2.7271419517875084

Epoch: 5| Step: 3
Training loss: 3.1806192368559927
Validation loss: 2.7245670766520953

Epoch: 5| Step: 4
Training loss: 2.8698827564070384
Validation loss: 2.722621539864746

Epoch: 5| Step: 5
Training loss: 3.3507941372304053
Validation loss: 2.7209068198354798

Epoch: 5| Step: 6
Training loss: 2.9634757322318914
Validation loss: 2.71922843202038

Epoch: 5| Step: 7
Training loss: 2.5181990065768933
Validation loss: 2.717159255299404

Epoch: 5| Step: 8
Training loss: 2.1547155034027687
Validation loss: 2.7153874280556445

Epoch: 5| Step: 9
Training loss: 2.7460451298149615
Validation loss: 2.7132851606934514

Epoch: 5| Step: 10
Training loss: 2.1091118542459295
Validation loss: 2.711651249130333

Epoch: 5| Step: 11
Training loss: 3.0038503733424684
Validation loss: 2.709279083525297

Epoch: 62| Step: 0
Training loss: 2.5237736433791236
Validation loss: 2.7079734868853462

Epoch: 5| Step: 1
Training loss: 2.822390142419689
Validation loss: 2.708398338907116

Epoch: 5| Step: 2
Training loss: 2.6340543721524283
Validation loss: 2.7054180533035774

Epoch: 5| Step: 3
Training loss: 2.738617488662216
Validation loss: 2.7032998824098033

Epoch: 5| Step: 4
Training loss: 2.629969479633966
Validation loss: 2.70017166541232

Epoch: 5| Step: 5
Training loss: 3.1093348208184497
Validation loss: 2.700479009899751

Epoch: 5| Step: 6
Training loss: 3.1209397451053302
Validation loss: 2.696908612739849

Epoch: 5| Step: 7
Training loss: 2.825282908089416
Validation loss: 2.696360302400427

Epoch: 5| Step: 8
Training loss: 3.0775330259904625
Validation loss: 2.6960824594599337

Epoch: 5| Step: 9
Training loss: 2.6369854827469683
Validation loss: 2.694143498807133

Epoch: 5| Step: 10
Training loss: 3.082465505043441
Validation loss: 2.6932795611665763

Epoch: 5| Step: 11
Training loss: 2.6626751551078134
Validation loss: 2.69076240268462

Epoch: 63| Step: 0
Training loss: 3.16946695557324
Validation loss: 2.6918045915533537

Epoch: 5| Step: 1
Training loss: 3.0765206275519965
Validation loss: 2.6897309565395475

Epoch: 5| Step: 2
Training loss: 2.5886560999382593
Validation loss: 2.6880585733174054

Epoch: 5| Step: 3
Training loss: 2.562625230659946
Validation loss: 2.685246543043181

Epoch: 5| Step: 4
Training loss: 2.9303723157953305
Validation loss: 2.6863771798837366

Epoch: 5| Step: 5
Training loss: 2.968230513245348
Validation loss: 2.6830702913874904

Epoch: 5| Step: 6
Training loss: 3.2522683663833063
Validation loss: 2.682486730106046

Epoch: 5| Step: 7
Training loss: 2.758664007812787
Validation loss: 2.680789457722415

Epoch: 5| Step: 8
Training loss: 2.687652760976839
Validation loss: 2.680168512767356

Epoch: 5| Step: 9
Training loss: 2.3516274883630395
Validation loss: 2.6771283288185037

Epoch: 5| Step: 10
Training loss: 2.6647263759686397
Validation loss: 2.675069540745003

Epoch: 5| Step: 11
Training loss: 2.45761465354291
Validation loss: 2.672668632888245

Epoch: 64| Step: 0
Training loss: 2.6697689925138977
Validation loss: 2.670910086597654

Epoch: 5| Step: 1
Training loss: 2.6690684966026788
Validation loss: 2.6721276541188423

Epoch: 5| Step: 2
Training loss: 3.3020502483904615
Validation loss: 2.6684780314306424

Epoch: 5| Step: 3
Training loss: 2.4692500127174597
Validation loss: 2.6676581906203034

Epoch: 5| Step: 4
Training loss: 2.5360090940174023
Validation loss: 2.666960947120797

Epoch: 5| Step: 5
Training loss: 2.8185242454645887
Validation loss: 2.664406538867701

Epoch: 5| Step: 6
Training loss: 2.7818282308527316
Validation loss: 2.662831030222572

Epoch: 5| Step: 7
Training loss: 2.890928675190985
Validation loss: 2.662291712964038

Epoch: 5| Step: 8
Training loss: 3.385141887761983
Validation loss: 2.660633311391234

Epoch: 5| Step: 9
Training loss: 2.1797900979017784
Validation loss: 2.6587851001961527

Epoch: 5| Step: 10
Training loss: 2.936339940641968
Validation loss: 2.659961194744864

Epoch: 5| Step: 11
Training loss: 3.020715399884539
Validation loss: 2.656554716995027

Epoch: 65| Step: 0
Training loss: 3.225169178864855
Validation loss: 2.65484344416563

Epoch: 5| Step: 1
Training loss: 2.5781063194754097
Validation loss: 2.654755691870914

Epoch: 5| Step: 2
Training loss: 2.7669862317513725
Validation loss: 2.6521322758771646

Epoch: 5| Step: 3
Training loss: 2.386001204344069
Validation loss: 2.6531198795839823

Epoch: 5| Step: 4
Training loss: 2.8242354649725803
Validation loss: 2.651715529609229

Epoch: 5| Step: 5
Training loss: 2.9036977081910917
Validation loss: 2.6533013227183595

Epoch: 5| Step: 6
Training loss: 2.6189529158244094
Validation loss: 2.6506987851484087

Epoch: 5| Step: 7
Training loss: 2.670876567409318
Validation loss: 2.6451547057753646

Epoch: 5| Step: 8
Training loss: 2.7465986544635843
Validation loss: 2.645475473507853

Epoch: 5| Step: 9
Training loss: 2.977400854399407
Validation loss: 2.6504674125910435

Epoch: 5| Step: 10
Training loss: 2.7886755752378622
Validation loss: 2.64962262669539

Epoch: 5| Step: 11
Training loss: 3.3040687216199816
Validation loss: 2.6432581607124135

Epoch: 66| Step: 0
Training loss: 2.8474228165425295
Validation loss: 2.638578152068585

Epoch: 5| Step: 1
Training loss: 2.530779759561517
Validation loss: 2.638121989282431

Epoch: 5| Step: 2
Training loss: 3.1439382811450693
Validation loss: 2.6370376996822285

Epoch: 5| Step: 3
Training loss: 2.4941381396204334
Validation loss: 2.6387162015416785

Epoch: 5| Step: 4
Training loss: 2.816457464887367
Validation loss: 2.637286703847028

Epoch: 5| Step: 5
Training loss: 3.007607034378359
Validation loss: 2.637178530695318

Epoch: 5| Step: 6
Training loss: 2.809094635039841
Validation loss: 2.634364473435747

Epoch: 5| Step: 7
Training loss: 2.3791067856325046
Validation loss: 2.6330436808798185

Epoch: 5| Step: 8
Training loss: 2.9028697711618405
Validation loss: 2.6321708584049213

Epoch: 5| Step: 9
Training loss: 2.5637722113738466
Validation loss: 2.6301533469819764

Epoch: 5| Step: 10
Training loss: 2.838107705264141
Validation loss: 2.62894295510472

Epoch: 5| Step: 11
Training loss: 3.205015638673332
Validation loss: 2.6265406874507957

Epoch: 67| Step: 0
Training loss: 3.2931607553564883
Validation loss: 2.6232100810208596

Epoch: 5| Step: 1
Training loss: 2.688176446993102
Validation loss: 2.624421426801964

Epoch: 5| Step: 2
Training loss: 2.9700093057916934
Validation loss: 2.619746574989592

Epoch: 5| Step: 3
Training loss: 2.604376293646187
Validation loss: 2.6193057052547353

Epoch: 5| Step: 4
Training loss: 2.9609585965091947
Validation loss: 2.6146121283132273

Epoch: 5| Step: 5
Training loss: 2.6307687495990955
Validation loss: 2.6163635551133426

Epoch: 5| Step: 6
Training loss: 2.523560228699675
Validation loss: 2.6165749891180416

Epoch: 5| Step: 7
Training loss: 2.799828786383686
Validation loss: 2.6113045081984905

Epoch: 5| Step: 8
Training loss: 2.197105679942467
Validation loss: 2.611456084938334

Epoch: 5| Step: 9
Training loss: 2.758630993120913
Validation loss: 2.6079519849759487

Epoch: 5| Step: 10
Training loss: 2.9679789294705663
Validation loss: 2.611874858159103

Epoch: 5| Step: 11
Training loss: 1.7288532509245607
Validation loss: 2.609821167223357

Epoch: 68| Step: 0
Training loss: 2.713101273797405
Validation loss: 2.608894802687611

Epoch: 5| Step: 1
Training loss: 2.8193903971619267
Validation loss: 2.606178072753314

Epoch: 5| Step: 2
Training loss: 2.608171562402631
Validation loss: 2.6045588897337577

Epoch: 5| Step: 3
Training loss: 2.872608849012735
Validation loss: 2.6054825217642263

Epoch: 5| Step: 4
Training loss: 2.681324628311562
Validation loss: 2.603940760668687

Epoch: 5| Step: 5
Training loss: 2.7332592240808316
Validation loss: 2.6045944866986575

Epoch: 5| Step: 6
Training loss: 2.356007478005891
Validation loss: 2.6039575925187544

Epoch: 5| Step: 7
Training loss: 3.2268199309948224
Validation loss: 2.601310423742393

Epoch: 5| Step: 8
Training loss: 1.9551814125360627
Validation loss: 2.6010962136175735

Epoch: 5| Step: 9
Training loss: 2.9418074497614843
Validation loss: 2.5983176018110417

Epoch: 5| Step: 10
Training loss: 2.811839132018723
Validation loss: 2.5986875852986073

Epoch: 5| Step: 11
Training loss: 3.6998041771283896
Validation loss: 2.594110973165521

Epoch: 69| Step: 0
Training loss: 2.823199878482486
Validation loss: 2.5954406582620697

Epoch: 5| Step: 1
Training loss: 2.5202669710704755
Validation loss: 2.5976477257151314

Epoch: 5| Step: 2
Training loss: 2.463393762730845
Validation loss: 2.5948263217832848

Epoch: 5| Step: 3
Training loss: 2.968179105778405
Validation loss: 2.5870499767803703

Epoch: 5| Step: 4
Training loss: 2.669744880574913
Validation loss: 2.5876659866818432

Epoch: 5| Step: 5
Training loss: 2.896956978206881
Validation loss: 2.5901167099050206

Epoch: 5| Step: 6
Training loss: 2.3722704209735093
Validation loss: 2.595137661551464

Epoch: 5| Step: 7
Training loss: 2.935701834420539
Validation loss: 2.596062927338632

Epoch: 5| Step: 8
Training loss: 3.2788588757895254
Validation loss: 2.592022895300525

Epoch: 5| Step: 9
Training loss: 2.292342924271693
Validation loss: 2.587644280758646

Epoch: 5| Step: 10
Training loss: 2.5317975617607726
Validation loss: 2.587516037803741

Epoch: 5| Step: 11
Training loss: 3.461365684044614
Validation loss: 2.5853372974083375

Epoch: 70| Step: 0
Training loss: 2.6341533020060237
Validation loss: 2.581703642329375

Epoch: 5| Step: 1
Training loss: 3.1984729759287607
Validation loss: 2.5842291691268264

Epoch: 5| Step: 2
Training loss: 2.593779230527592
Validation loss: 2.581612757453845

Epoch: 5| Step: 3
Training loss: 2.7117167735223098
Validation loss: 2.5833637456231777

Epoch: 5| Step: 4
Training loss: 2.573084301963736
Validation loss: 2.581669957694691

Epoch: 5| Step: 5
Training loss: 2.8177991324771128
Validation loss: 2.582991736397476

Epoch: 5| Step: 6
Training loss: 2.631885580468725
Validation loss: 2.5804526754801196

Epoch: 5| Step: 7
Training loss: 2.217386820935776
Validation loss: 2.579993717065204

Epoch: 5| Step: 8
Training loss: 2.707919328786779
Validation loss: 2.5798141263571335

Epoch: 5| Step: 9
Training loss: 2.7446482341623986
Validation loss: 2.575531095838527

Epoch: 5| Step: 10
Training loss: 2.822201167759827
Validation loss: 2.5790422657365033

Epoch: 5| Step: 11
Training loss: 3.454130690831733
Validation loss: 2.574604395303689

Epoch: 71| Step: 0
Training loss: 2.5573882313279817
Validation loss: 2.5739237722940027

Epoch: 5| Step: 1
Training loss: 2.6180110717376124
Validation loss: 2.570816976092301

Epoch: 5| Step: 2
Training loss: 2.564690188906973
Validation loss: 2.5724958636822453

Epoch: 5| Step: 3
Training loss: 2.7720855426497613
Validation loss: 2.5650802624100164

Epoch: 5| Step: 4
Training loss: 2.3637732127727733
Validation loss: 2.5667018091182205

Epoch: 5| Step: 5
Training loss: 3.130300070909424
Validation loss: 2.567677678872458

Epoch: 5| Step: 6
Training loss: 2.467633344917995
Validation loss: 2.5631722134558803

Epoch: 5| Step: 7
Training loss: 2.851931529792144
Validation loss: 2.564198351772656

Epoch: 5| Step: 8
Training loss: 2.860266041152794
Validation loss: 2.561854397462195

Epoch: 5| Step: 9
Training loss: 3.0609323031277667
Validation loss: 2.563937384950496

Epoch: 5| Step: 10
Training loss: 2.2229031658626623
Validation loss: 2.5580673763465374

Epoch: 5| Step: 11
Training loss: 3.0688483943043066
Validation loss: 2.5594836990196046

Epoch: 72| Step: 0
Training loss: 3.1777016626888788
Validation loss: 2.56315768144694

Epoch: 5| Step: 1
Training loss: 3.00739235854216
Validation loss: 2.5594701765573045

Epoch: 5| Step: 2
Training loss: 2.649986691711405
Validation loss: 2.563540127405115

Epoch: 5| Step: 3
Training loss: 3.0683913881803884
Validation loss: 2.5636878245660304

Epoch: 5| Step: 4
Training loss: 2.504951437443244
Validation loss: 2.561239533441002

Epoch: 5| Step: 5
Training loss: 2.2780792985264484
Validation loss: 2.5568644107788

Epoch: 5| Step: 6
Training loss: 2.6955821026847713
Validation loss: 2.5581030260999005

Epoch: 5| Step: 7
Training loss: 2.340242023993561
Validation loss: 2.5590264767373614

Epoch: 5| Step: 8
Training loss: 2.554499161336914
Validation loss: 2.55568807685637

Epoch: 5| Step: 9
Training loss: 2.6570928694891047
Validation loss: 2.5573101250214774

Epoch: 5| Step: 10
Training loss: 2.51050278343133
Validation loss: 2.557031246581186

Epoch: 5| Step: 11
Training loss: 2.836000552146438
Validation loss: 2.551561579925066

Epoch: 73| Step: 0
Training loss: 2.549884819720599
Validation loss: 2.5511279218636633

Epoch: 5| Step: 1
Training loss: 2.997229250276151
Validation loss: 2.546062070609092

Epoch: 5| Step: 2
Training loss: 2.355549521508476
Validation loss: 2.5470671552005655

Epoch: 5| Step: 3
Training loss: 2.5029761719005736
Validation loss: 2.5520203498282594

Epoch: 5| Step: 4
Training loss: 2.4910709187731244
Validation loss: 2.5469809395067293

Epoch: 5| Step: 5
Training loss: 2.7091019542345576
Validation loss: 2.553360433940973

Epoch: 5| Step: 6
Training loss: 2.860546101537858
Validation loss: 2.5504722271718148

Epoch: 5| Step: 7
Training loss: 2.515501694589407
Validation loss: 2.544964551628822

Epoch: 5| Step: 8
Training loss: 2.466330102778783
Validation loss: 2.5417270470831608

Epoch: 5| Step: 9
Training loss: 2.5652122100434793
Validation loss: 2.548318278449301

Epoch: 5| Step: 10
Training loss: 3.2396233035910087
Validation loss: 2.5476526231690215

Epoch: 5| Step: 11
Training loss: 3.1343223377188942
Validation loss: 2.5428292059907283

Epoch: 74| Step: 0
Training loss: 2.3084460629182635
Validation loss: 2.5421710933881934

Epoch: 5| Step: 1
Training loss: 2.498551235031687
Validation loss: 2.548503974969079

Epoch: 5| Step: 2
Training loss: 2.2039553112477237
Validation loss: 2.548958633998598

Epoch: 5| Step: 3
Training loss: 3.0049996041854623
Validation loss: 2.5636148624957844

Epoch: 5| Step: 4
Training loss: 2.4662372984368166
Validation loss: 2.5548712443652266

Epoch: 5| Step: 5
Training loss: 3.118822476876962
Validation loss: 2.551881647250035

Epoch: 5| Step: 6
Training loss: 2.7376895542795885
Validation loss: 2.54063077373091

Epoch: 5| Step: 7
Training loss: 3.1674253324576314
Validation loss: 2.546077853154461

Epoch: 5| Step: 8
Training loss: 2.533321051400512
Validation loss: 2.553548588159947

Epoch: 5| Step: 9
Training loss: 2.8800511975506087
Validation loss: 2.5587279228769995

Epoch: 5| Step: 10
Training loss: 2.4043943507796883
Validation loss: 2.553242440948607

Epoch: 5| Step: 11
Training loss: 2.841238065225463
Validation loss: 2.5511627574035987

Epoch: 75| Step: 0
Training loss: 2.9271606941905763
Validation loss: 2.5515783290368153

Epoch: 5| Step: 1
Training loss: 2.7123940372425692
Validation loss: 2.5494777626186993

Epoch: 5| Step: 2
Training loss: 2.6427260848729612
Validation loss: 2.548564299939748

Epoch: 5| Step: 3
Training loss: 2.4812070213458366
Validation loss: 2.549564018564948

Epoch: 5| Step: 4
Training loss: 2.463216930920457
Validation loss: 2.546008830621293

Epoch: 5| Step: 5
Training loss: 2.7977070343342563
Validation loss: 2.5455403214471084

Epoch: 5| Step: 6
Training loss: 2.571929423056519
Validation loss: 2.5433918785987144

Epoch: 5| Step: 7
Training loss: 2.831466807975677
Validation loss: 2.543085672763992

Epoch: 5| Step: 8
Training loss: 2.397128664442696
Validation loss: 2.5409071808998744

Epoch: 5| Step: 9
Training loss: 2.387224858592541
Validation loss: 2.5436853784886786

Epoch: 5| Step: 10
Training loss: 3.019540567124613
Validation loss: 2.541356471680717

Epoch: 5| Step: 11
Training loss: 3.339583894313512
Validation loss: 2.5389380165297837

Epoch: 76| Step: 0
Training loss: 2.6343510600639224
Validation loss: 2.5360610906726757

Epoch: 5| Step: 1
Training loss: 2.800879313136825
Validation loss: 2.536129682791366

Epoch: 5| Step: 2
Training loss: 2.4678395197919123
Validation loss: 2.536254985629578

Epoch: 5| Step: 3
Training loss: 2.8026454791814674
Validation loss: 2.533040218169024

Epoch: 5| Step: 4
Training loss: 2.9987000191941084
Validation loss: 2.534334501169459

Epoch: 5| Step: 5
Training loss: 2.4363641293109826
Validation loss: 2.532325588712047

Epoch: 5| Step: 6
Training loss: 2.3290142434824213
Validation loss: 2.536778256856287

Epoch: 5| Step: 7
Training loss: 2.9067302020008876
Validation loss: 2.5321923609261696

Epoch: 5| Step: 8
Training loss: 2.0981019752382237
Validation loss: 2.529227618394792

Epoch: 5| Step: 9
Training loss: 2.8799803346386366
Validation loss: 2.528604581098946

Epoch: 5| Step: 10
Training loss: 2.8353082468427058
Validation loss: 2.5314575628256915

Epoch: 5| Step: 11
Training loss: 2.77475305437923
Validation loss: 2.529918084759758

Epoch: 77| Step: 0
Training loss: 2.6845220878546416
Validation loss: 2.527835862892022

Epoch: 5| Step: 1
Training loss: 2.8498988484953767
Validation loss: 2.5286914861914123

Epoch: 5| Step: 2
Training loss: 2.7130139228809442
Validation loss: 2.5285262496334497

Epoch: 5| Step: 3
Training loss: 2.430622178632963
Validation loss: 2.523003165833116

Epoch: 5| Step: 4
Training loss: 2.3736860756605775
Validation loss: 2.523538534308978

Epoch: 5| Step: 5
Training loss: 2.3532305406304665
Validation loss: 2.524921469049482

Epoch: 5| Step: 6
Training loss: 2.903195816999477
Validation loss: 2.5259735779909445

Epoch: 5| Step: 7
Training loss: 3.075514252623587
Validation loss: 2.5247149703170613

Epoch: 5| Step: 8
Training loss: 2.2617173796074757
Validation loss: 2.5204649011012905

Epoch: 5| Step: 9
Training loss: 2.853012259889208
Validation loss: 2.5257812575515195

Epoch: 5| Step: 10
Training loss: 2.666340410619532
Validation loss: 2.5212527877156736

Epoch: 5| Step: 11
Training loss: 2.018031967537475
Validation loss: 2.520313320959927

Epoch: 78| Step: 0
Training loss: 2.9146397404987345
Validation loss: 2.5229364336616515

Epoch: 5| Step: 1
Training loss: 2.4641771095148344
Validation loss: 2.5217493983192667

Epoch: 5| Step: 2
Training loss: 2.504574595742688
Validation loss: 2.5195389621823585

Epoch: 5| Step: 3
Training loss: 3.2936567897745697
Validation loss: 2.522985443471394

Epoch: 5| Step: 4
Training loss: 2.3194905376105637
Validation loss: 2.520438680941028

Epoch: 5| Step: 5
Training loss: 2.334073448875612
Validation loss: 2.520941768762579

Epoch: 5| Step: 6
Training loss: 2.647750180160607
Validation loss: 2.5227359745347835

Epoch: 5| Step: 7
Training loss: 2.601031183280998
Validation loss: 2.521288024207098

Epoch: 5| Step: 8
Training loss: 2.508539017347826
Validation loss: 2.5183579406371286

Epoch: 5| Step: 9
Training loss: 2.4843034074172543
Validation loss: 2.519431640075378

Epoch: 5| Step: 10
Training loss: 3.06282571111546
Validation loss: 2.5207053433127764

Epoch: 5| Step: 11
Training loss: 2.1462051168291016
Validation loss: 2.5182037917669726

Epoch: 79| Step: 0
Training loss: 2.703982884098936
Validation loss: 2.5161199378990275

Epoch: 5| Step: 1
Training loss: 2.955031975122947
Validation loss: 2.51753422649772

Epoch: 5| Step: 2
Training loss: 2.296935930546794
Validation loss: 2.5149280498809974

Epoch: 5| Step: 3
Training loss: 2.675916236758214
Validation loss: 2.5172826328687448

Epoch: 5| Step: 4
Training loss: 2.7118207828247796
Validation loss: 2.514361393912496

Epoch: 5| Step: 5
Training loss: 1.8320702912617801
Validation loss: 2.512109946502603

Epoch: 5| Step: 6
Training loss: 3.107745026114412
Validation loss: 2.514366490628374

Epoch: 5| Step: 7
Training loss: 2.3151096362523855
Validation loss: 2.507411916871192

Epoch: 5| Step: 8
Training loss: 3.1095654606594114
Validation loss: 2.511659280360684

Epoch: 5| Step: 9
Training loss: 2.73155878272533
Validation loss: 2.514920931869418

Epoch: 5| Step: 10
Training loss: 2.3530263811700407
Validation loss: 2.508654325378167

Epoch: 5| Step: 11
Training loss: 2.2412320005137696
Validation loss: 2.511208537297291

Epoch: 80| Step: 0
Training loss: 2.57923134849514
Validation loss: 2.525301576457083

Epoch: 5| Step: 1
Training loss: 2.9296787109243163
Validation loss: 2.5171835397523035

Epoch: 5| Step: 2
Training loss: 2.781697612275665
Validation loss: 2.5161670985290874

Epoch: 5| Step: 3
Training loss: 2.508349875039679
Validation loss: 2.519107572039296

Epoch: 5| Step: 4
Training loss: 2.8031633321295173
Validation loss: 2.5134230784267624

Epoch: 5| Step: 5
Training loss: 2.753654825623873
Validation loss: 2.510131955655014

Epoch: 5| Step: 6
Training loss: 2.4144871409238284
Validation loss: 2.513011554180401

Epoch: 5| Step: 7
Training loss: 2.5869324950976003
Validation loss: 2.5162017311220515

Epoch: 5| Step: 8
Training loss: 2.270548554741985
Validation loss: 2.518605707388173

Epoch: 5| Step: 9
Training loss: 2.7484853214443086
Validation loss: 2.52256864070916

Epoch: 5| Step: 10
Training loss: 2.5793700015308705
Validation loss: 2.5215210895933486

Epoch: 5| Step: 11
Training loss: 2.6572829986714015
Validation loss: 2.5172958274940993

Epoch: 81| Step: 0
Training loss: 2.602888164760117
Validation loss: 2.519516961108949

Epoch: 5| Step: 1
Training loss: 2.748380183955466
Validation loss: 2.5189769401259556

Epoch: 5| Step: 2
Training loss: 2.7603208033392446
Validation loss: 2.5172487945639626

Epoch: 5| Step: 3
Training loss: 2.7564252871181463
Validation loss: 2.516016114279345

Epoch: 5| Step: 4
Training loss: 2.856327955655441
Validation loss: 2.5112770052024773

Epoch: 5| Step: 5
Training loss: 2.34431633782578
Validation loss: 2.5095203324319093

Epoch: 5| Step: 6
Training loss: 2.740125614544685
Validation loss: 2.5099657822489143

Epoch: 5| Step: 7
Training loss: 2.7976730316349077
Validation loss: 2.503971981746989

Epoch: 5| Step: 8
Training loss: 2.398354494727406
Validation loss: 2.505981010246075

Epoch: 5| Step: 9
Training loss: 2.599007666558542
Validation loss: 2.5029269369871554

Epoch: 5| Step: 10
Training loss: 2.2077958394560584
Validation loss: 2.50430451794941

Epoch: 5| Step: 11
Training loss: 3.339791923254682
Validation loss: 2.501812337566642

Epoch: 82| Step: 0
Training loss: 2.7854449749813193
Validation loss: 2.500360713208306

Epoch: 5| Step: 1
Training loss: 2.3216969890307633
Validation loss: 2.4999137903290185

Epoch: 5| Step: 2
Training loss: 2.3807237819648845
Validation loss: 2.501617897559226

Epoch: 5| Step: 3
Training loss: 2.726491407981443
Validation loss: 2.5031298714732033

Epoch: 5| Step: 4
Training loss: 2.481997425880296
Validation loss: 2.4990186990621193

Epoch: 5| Step: 5
Training loss: 2.5331954073586176
Validation loss: 2.503433551892358

Epoch: 5| Step: 6
Training loss: 2.7270251212283143
Validation loss: 2.502954608675587

Epoch: 5| Step: 7
Training loss: 3.1011446039509765
Validation loss: 2.5048140349684003

Epoch: 5| Step: 8
Training loss: 2.4390079040086463
Validation loss: 2.5056796169251676

Epoch: 5| Step: 9
Training loss: 2.4284448911254706
Validation loss: 2.501039745759577

Epoch: 5| Step: 10
Training loss: 3.0507402991209633
Validation loss: 2.5108759659081796

Epoch: 5| Step: 11
Training loss: 1.0347961375200923
Validation loss: 2.503345686621309

Epoch: 83| Step: 0
Training loss: 2.341255182605716
Validation loss: 2.5053924220620916

Epoch: 5| Step: 1
Training loss: 2.7974511943579023
Validation loss: 2.5016540896573747

Epoch: 5| Step: 2
Training loss: 2.5093310740653614
Validation loss: 2.5052190424848186

Epoch: 5| Step: 3
Training loss: 2.824430296851034
Validation loss: 2.509195146651368

Epoch: 5| Step: 4
Training loss: 2.9066056884995546
Validation loss: 2.5017744958953494

Epoch: 5| Step: 5
Training loss: 2.28695487942907
Validation loss: 2.5046193123695892

Epoch: 5| Step: 6
Training loss: 2.805411412740147
Validation loss: 2.4992008839404196

Epoch: 5| Step: 7
Training loss: 2.217934794500287
Validation loss: 2.50603205223902

Epoch: 5| Step: 8
Training loss: 2.2401301817871566
Validation loss: 2.5097331439537482

Epoch: 5| Step: 9
Training loss: 2.7587594197799064
Validation loss: 2.510303393191951

Epoch: 5| Step: 10
Training loss: 3.021038513231053
Validation loss: 2.5155422165480594

Epoch: 5| Step: 11
Training loss: 2.594454198633337
Validation loss: 2.5159050447955087

Epoch: 84| Step: 0
Training loss: 2.263577608214356
Validation loss: 2.51497162257491

Epoch: 5| Step: 1
Training loss: 2.8074709540721847
Validation loss: 2.5166541160550544

Epoch: 5| Step: 2
Training loss: 2.6576476963804234
Validation loss: 2.5143265660774907

Epoch: 5| Step: 3
Training loss: 2.8160792992978876
Validation loss: 2.5118666309192905

Epoch: 5| Step: 4
Training loss: 2.9966015640276096
Validation loss: 2.5094424741041608

Epoch: 5| Step: 5
Training loss: 2.5467885944710797
Validation loss: 2.5074938396366773

Epoch: 5| Step: 6
Training loss: 2.9355640931173355
Validation loss: 2.500986957441557

Epoch: 5| Step: 7
Training loss: 2.0694435455297557
Validation loss: 2.500962453591597

Epoch: 5| Step: 8
Training loss: 2.560805341884353
Validation loss: 2.497500847341237

Epoch: 5| Step: 9
Training loss: 2.6905728892243386
Validation loss: 2.4955226660794425

Epoch: 5| Step: 10
Training loss: 2.449250873555784
Validation loss: 2.495185328559054

Epoch: 5| Step: 11
Training loss: 2.503075710387597
Validation loss: 2.4938081914602352

Epoch: 85| Step: 0
Training loss: 2.6063926236946915
Validation loss: 2.4970361585174765

Epoch: 5| Step: 1
Training loss: 2.763190539604607
Validation loss: 2.5246357902188863

Epoch: 5| Step: 2
Training loss: 2.883947133641862
Validation loss: 2.534185175562057

Epoch: 5| Step: 3
Training loss: 2.4540972878494407
Validation loss: 2.5467272288509375

Epoch: 5| Step: 4
Training loss: 2.8148217684490726
Validation loss: 2.531472478908732

Epoch: 5| Step: 5
Training loss: 2.2855967040131984
Validation loss: 2.503276140632302

Epoch: 5| Step: 6
Training loss: 2.5928291616540102
Validation loss: 2.4934458131990627

Epoch: 5| Step: 7
Training loss: 2.580024897728778
Validation loss: 2.4922646577345184

Epoch: 5| Step: 8
Training loss: 2.3151320865922838
Validation loss: 2.494321270412361

Epoch: 5| Step: 9
Training loss: 3.0220557710056988
Validation loss: 2.499772399237611

Epoch: 5| Step: 10
Training loss: 2.8719527639792113
Validation loss: 2.5024062973909094

Epoch: 5| Step: 11
Training loss: 1.883177915703884
Validation loss: 2.5024443518148316

Epoch: 86| Step: 0
Training loss: 3.000055948371526
Validation loss: 2.5052594769836007

Epoch: 5| Step: 1
Training loss: 2.8032227838274006
Validation loss: 2.5090299921008103

Epoch: 5| Step: 2
Training loss: 2.3694535793273945
Validation loss: 2.5164892714127913

Epoch: 5| Step: 3
Training loss: 3.0126202887741256
Validation loss: 2.5146387271631894

Epoch: 5| Step: 4
Training loss: 2.7469590453048314
Validation loss: 2.5170386036918515

Epoch: 5| Step: 5
Training loss: 2.429261001491338
Validation loss: 2.5260380551551616

Epoch: 5| Step: 6
Training loss: 2.188210508217042
Validation loss: 2.5248486929904383

Epoch: 5| Step: 7
Training loss: 2.5947603762616085
Validation loss: 2.5254270349854173

Epoch: 5| Step: 8
Training loss: 2.2864844480745155
Validation loss: 2.519158647768224

Epoch: 5| Step: 9
Training loss: 2.8155700034677684
Validation loss: 2.520118227063673

Epoch: 5| Step: 10
Training loss: 2.755748376158719
Validation loss: 2.517453739318291

Epoch: 5| Step: 11
Training loss: 2.354432037610464
Validation loss: 2.5102628697708513

Epoch: 87| Step: 0
Training loss: 2.1897392800568802
Validation loss: 2.5097554366205532

Epoch: 5| Step: 1
Training loss: 2.985589863628504
Validation loss: 2.506823886574387

Epoch: 5| Step: 2
Training loss: 2.656586569612077
Validation loss: 2.5049729676161783

Epoch: 5| Step: 3
Training loss: 2.778622189498359
Validation loss: 2.500974906137343

Epoch: 5| Step: 4
Training loss: 2.732483738382295
Validation loss: 2.4997960285583516

Epoch: 5| Step: 5
Training loss: 2.50433812456279
Validation loss: 2.4942394725914756

Epoch: 5| Step: 6
Training loss: 2.709486867317773
Validation loss: 2.4973880037112743

Epoch: 5| Step: 7
Training loss: 2.482067836243276
Validation loss: 2.4949784232195955

Epoch: 5| Step: 8
Training loss: 2.418972712867118
Validation loss: 2.4932312568468253

Epoch: 5| Step: 9
Training loss: 2.677551574922666
Validation loss: 2.490831015923874

Epoch: 5| Step: 10
Training loss: 2.7402469039271664
Validation loss: 2.4937567996806385

Epoch: 5| Step: 11
Training loss: 2.4742290683310757
Validation loss: 2.490413141752849

Epoch: 88| Step: 0
Training loss: 2.66053283087295
Validation loss: 2.4886301695291455

Epoch: 5| Step: 1
Training loss: 2.5817162672203025
Validation loss: 2.4835204088122445

Epoch: 5| Step: 2
Training loss: 1.7690039516424245
Validation loss: 2.4888890121546026

Epoch: 5| Step: 3
Training loss: 2.206603098162106
Validation loss: 2.4908944006979024

Epoch: 5| Step: 4
Training loss: 2.7568692331333766
Validation loss: 2.4842087991970536

Epoch: 5| Step: 5
Training loss: 2.385785758658615
Validation loss: 2.4936385559254597

Epoch: 5| Step: 6
Training loss: 3.036695328237676
Validation loss: 2.4951852787926727

Epoch: 5| Step: 7
Training loss: 2.0650169735781283
Validation loss: 2.493225917703809

Epoch: 5| Step: 8
Training loss: 2.8135518967970823
Validation loss: 2.496976120372856

Epoch: 5| Step: 9
Training loss: 3.26954145897077
Validation loss: 2.488843270493518

Epoch: 5| Step: 10
Training loss: 2.9180638554405745
Validation loss: 2.488602997215841

Epoch: 5| Step: 11
Training loss: 2.2682792112053956
Validation loss: 2.484586022969599

Epoch: 89| Step: 0
Training loss: 2.8617132246717576
Validation loss: 2.482191910035216

Epoch: 5| Step: 1
Training loss: 2.670410200890816
Validation loss: 2.489263279877549

Epoch: 5| Step: 2
Training loss: 2.4163971016159067
Validation loss: 2.492844721156415

Epoch: 5| Step: 3
Training loss: 2.723449591447314
Validation loss: 2.4912649019468427

Epoch: 5| Step: 4
Training loss: 2.2682080506934255
Validation loss: 2.4931605720420875

Epoch: 5| Step: 5
Training loss: 2.3680406298373655
Validation loss: 2.4922326860148196

Epoch: 5| Step: 6
Training loss: 2.4549746980936544
Validation loss: 2.4939812290894485

Epoch: 5| Step: 7
Training loss: 2.62550975754595
Validation loss: 2.4916103176987687

Epoch: 5| Step: 8
Training loss: 2.4474640664569316
Validation loss: 2.4939655151871363

Epoch: 5| Step: 9
Training loss: 2.980157238441039
Validation loss: 2.489984577091614

Epoch: 5| Step: 10
Training loss: 2.5703570237405127
Validation loss: 2.4885508791940754

Epoch: 5| Step: 11
Training loss: 3.862016646378456
Validation loss: 2.487998850560766

Epoch: 90| Step: 0
Training loss: 2.8715150692674043
Validation loss: 2.4869068647862838

Epoch: 5| Step: 1
Training loss: 2.3628854467430136
Validation loss: 2.4863770613208325

Epoch: 5| Step: 2
Training loss: 2.9041220144800723
Validation loss: 2.4842064238481476

Epoch: 5| Step: 3
Training loss: 2.4836154952391762
Validation loss: 2.4865904312831075

Epoch: 5| Step: 4
Training loss: 2.8969851245544302
Validation loss: 2.4871874750320018

Epoch: 5| Step: 5
Training loss: 2.4150378778302795
Validation loss: 2.4837692249951053

Epoch: 5| Step: 6
Training loss: 3.013762378137168
Validation loss: 2.482224055105935

Epoch: 5| Step: 7
Training loss: 2.3851317078633163
Validation loss: 2.482176461683307

Epoch: 5| Step: 8
Training loss: 2.1542406533064957
Validation loss: 2.483010503140882

Epoch: 5| Step: 9
Training loss: 2.5647221676154524
Validation loss: 2.4823157074938433

Epoch: 5| Step: 10
Training loss: 2.4268531089815144
Validation loss: 2.4850879421957845

Epoch: 5| Step: 11
Training loss: 2.880281489973995
Validation loss: 2.489907508291502

Epoch: 91| Step: 0
Training loss: 2.86253807342396
Validation loss: 2.486686722635775

Epoch: 5| Step: 1
Training loss: 2.8524150253330256
Validation loss: 2.4837743444902336

Epoch: 5| Step: 2
Training loss: 2.3445864392871214
Validation loss: 2.4761340455596073

Epoch: 5| Step: 3
Training loss: 2.560689146743509
Validation loss: 2.4856102149938666

Epoch: 5| Step: 4
Training loss: 2.817096260611755
Validation loss: 2.4784169679710826

Epoch: 5| Step: 5
Training loss: 2.3456338051138483
Validation loss: 2.475085462835031

Epoch: 5| Step: 6
Training loss: 2.6078344125895585
Validation loss: 2.480044166892035

Epoch: 5| Step: 7
Training loss: 2.343264618522247
Validation loss: 2.472182366559469

Epoch: 5| Step: 8
Training loss: 2.487204997143368
Validation loss: 2.4783534444580013

Epoch: 5| Step: 9
Training loss: 2.6514313017397715
Validation loss: 2.4806661251968487

Epoch: 5| Step: 10
Training loss: 2.5837456671498975
Validation loss: 2.4801628484858274

Epoch: 5| Step: 11
Training loss: 3.0142245030112176
Validation loss: 2.480547802083437

Epoch: 92| Step: 0
Training loss: 1.6746498681403306
Validation loss: 2.4797798621882645

Epoch: 5| Step: 1
Training loss: 2.6140467687157405
Validation loss: 2.4822729222599387

Epoch: 5| Step: 2
Training loss: 2.5036055314373025
Validation loss: 2.482164667242139

Epoch: 5| Step: 3
Training loss: 3.234418490942126
Validation loss: 2.48724662713996

Epoch: 5| Step: 4
Training loss: 2.6954909998071788
Validation loss: 2.4859500147010793

Epoch: 5| Step: 5
Training loss: 2.881917178677392
Validation loss: 2.4893672734973173

Epoch: 5| Step: 6
Training loss: 2.557169790270719
Validation loss: 2.48500920244121

Epoch: 5| Step: 7
Training loss: 2.714731337600751
Validation loss: 2.4789285879394027

Epoch: 5| Step: 8
Training loss: 2.6388508632217955
Validation loss: 2.4824320354999068

Epoch: 5| Step: 9
Training loss: 2.526622168049296
Validation loss: 2.477757535631046

Epoch: 5| Step: 10
Training loss: 2.3213598283084274
Validation loss: 2.4777126589753657

Epoch: 5| Step: 11
Training loss: 2.3912510270367267
Validation loss: 2.4767768538457307

Epoch: 93| Step: 0
Training loss: 2.2832973124686293
Validation loss: 2.4769510351474113

Epoch: 5| Step: 1
Training loss: 2.0763705311973357
Validation loss: 2.4716082054803215

Epoch: 5| Step: 2
Training loss: 2.679561333980978
Validation loss: 2.4779157741842868

Epoch: 5| Step: 3
Training loss: 2.8929439006895072
Validation loss: 2.470978525767639

Epoch: 5| Step: 4
Training loss: 2.670659552845437
Validation loss: 2.474121218221403

Epoch: 5| Step: 5
Training loss: 3.0540402402293965
Validation loss: 2.471980214924013

Epoch: 5| Step: 6
Training loss: 2.712023602678335
Validation loss: 2.476774601723636

Epoch: 5| Step: 7
Training loss: 2.5349167062592253
Validation loss: 2.4797116142819884

Epoch: 5| Step: 8
Training loss: 2.640426176813629
Validation loss: 2.475949946721325

Epoch: 5| Step: 9
Training loss: 2.653430654220187
Validation loss: 2.4823013904704974

Epoch: 5| Step: 10
Training loss: 2.2186035322818203
Validation loss: 2.4828037635516678

Epoch: 5| Step: 11
Training loss: 2.932694745634011
Validation loss: 2.4769527516918486

Epoch: 94| Step: 0
Training loss: 2.838182469777179
Validation loss: 2.4756848397647495

Epoch: 5| Step: 1
Training loss: 2.6325707933085116
Validation loss: 2.472371348620152

Epoch: 5| Step: 2
Training loss: 2.7811118959578263
Validation loss: 2.4647754472315984

Epoch: 5| Step: 3
Training loss: 2.175459942472789
Validation loss: 2.4743378090526553

Epoch: 5| Step: 4
Training loss: 2.4363925080678484
Validation loss: 2.476078194677909

Epoch: 5| Step: 5
Training loss: 2.2466924516271662
Validation loss: 2.465756335545868

Epoch: 5| Step: 6
Training loss: 2.5151308889438115
Validation loss: 2.473976202783129

Epoch: 5| Step: 7
Training loss: 2.4956507043353073
Validation loss: 2.4721823987063125

Epoch: 5| Step: 8
Training loss: 2.7219738317124476
Validation loss: 2.47397237004096

Epoch: 5| Step: 9
Training loss: 2.8996036784894534
Validation loss: 2.4758041616711615

Epoch: 5| Step: 10
Training loss: 2.6583286903205274
Validation loss: 2.478419681552839

Epoch: 5| Step: 11
Training loss: 2.2766503771994597
Validation loss: 2.4776482192790206

Epoch: 95| Step: 0
Training loss: 3.007252509762142
Validation loss: 2.466407396785295

Epoch: 5| Step: 1
Training loss: 2.170546200654016
Validation loss: 2.471892967753609

Epoch: 5| Step: 2
Training loss: 2.469926963992761
Validation loss: 2.474576717523519

Epoch: 5| Step: 3
Training loss: 2.3648983805722708
Validation loss: 2.471925094039028

Epoch: 5| Step: 4
Training loss: 2.3934239974776013
Validation loss: 2.473745362333834

Epoch: 5| Step: 5
Training loss: 2.9403070875927475
Validation loss: 2.469773643671372

Epoch: 5| Step: 6
Training loss: 2.823703576424446
Validation loss: 2.468189791603915

Epoch: 5| Step: 7
Training loss: 2.5337022746954454
Validation loss: 2.475760228669777

Epoch: 5| Step: 8
Training loss: 2.3275998950667818
Validation loss: 2.468936277355441

Epoch: 5| Step: 9
Training loss: 2.4565407850225087
Validation loss: 2.4731779346676817

Epoch: 5| Step: 10
Training loss: 2.615911098497833
Validation loss: 2.4760431854303304

Epoch: 5| Step: 11
Training loss: 3.284824712945181
Validation loss: 2.4712065293189074

Epoch: 96| Step: 0
Training loss: 2.1757461846366497
Validation loss: 2.469741501466965

Epoch: 5| Step: 1
Training loss: 2.4656067164604996
Validation loss: 2.466865627189506

Epoch: 5| Step: 2
Training loss: 2.8708701948467086
Validation loss: 2.460785258594658

Epoch: 5| Step: 3
Training loss: 2.2948361644566257
Validation loss: 2.467485095761425

Epoch: 5| Step: 4
Training loss: 2.407793516050801
Validation loss: 2.4659037318455774

Epoch: 5| Step: 5
Training loss: 2.6308512188417557
Validation loss: 2.476138089594365

Epoch: 5| Step: 6
Training loss: 2.6431975163912247
Validation loss: 2.4677578666828794

Epoch: 5| Step: 7
Training loss: 2.434210979141475
Validation loss: 2.4617890474142294

Epoch: 5| Step: 8
Training loss: 2.5521213347012623
Validation loss: 2.4621493852388423

Epoch: 5| Step: 9
Training loss: 2.4924974398279387
Validation loss: 2.463361440495204

Epoch: 5| Step: 10
Training loss: 3.032113964797501
Validation loss: 2.471350298370346

Epoch: 5| Step: 11
Training loss: 3.3095841439848184
Validation loss: 2.4789945531987607

Epoch: 97| Step: 0
Training loss: 2.4247087205385243
Validation loss: 2.4741271245830343

Epoch: 5| Step: 1
Training loss: 2.061315716678472
Validation loss: 2.4814917830142162

Epoch: 5| Step: 2
Training loss: 2.5873040682559463
Validation loss: 2.4821472376209432

Epoch: 5| Step: 3
Training loss: 2.366374464756665
Validation loss: 2.481286560368973

Epoch: 5| Step: 4
Training loss: 2.4936583193798336
Validation loss: 2.4787196242497083

Epoch: 5| Step: 5
Training loss: 2.7652383307719535
Validation loss: 2.481548028466661

Epoch: 5| Step: 6
Training loss: 3.0643582058873693
Validation loss: 2.4818770168094195

Epoch: 5| Step: 7
Training loss: 2.3147210461026946
Validation loss: 2.4846421943787744

Epoch: 5| Step: 8
Training loss: 3.091492416804411
Validation loss: 2.476854806490912

Epoch: 5| Step: 9
Training loss: 2.646924962604704
Validation loss: 2.4803174430775803

Epoch: 5| Step: 10
Training loss: 2.6094235170159723
Validation loss: 2.481643394621986

Epoch: 5| Step: 11
Training loss: 2.062482775991942
Validation loss: 2.4734657051436635

Epoch: 98| Step: 0
Training loss: 2.360892306891869
Validation loss: 2.477842214900672

Epoch: 5| Step: 1
Training loss: 2.30901600030813
Validation loss: 2.4741120233815566

Epoch: 5| Step: 2
Training loss: 2.9287703642582867
Validation loss: 2.4770185008653653

Epoch: 5| Step: 3
Training loss: 2.7082721898928694
Validation loss: 2.473687361216043

Epoch: 5| Step: 4
Training loss: 2.7351768843725908
Validation loss: 2.471189641483935

Epoch: 5| Step: 5
Training loss: 2.6369324096014286
Validation loss: 2.4786429546606943

Epoch: 5| Step: 6
Training loss: 2.373488196006724
Validation loss: 2.4772087962656104

Epoch: 5| Step: 7
Training loss: 2.577782625526313
Validation loss: 2.480013223306463

Epoch: 5| Step: 8
Training loss: 2.6317145438144527
Validation loss: 2.4783054640467923

Epoch: 5| Step: 9
Training loss: 2.6293838769950115
Validation loss: 2.479435622962456

Epoch: 5| Step: 10
Training loss: 2.7309051295940807
Validation loss: 2.484935665244465

Epoch: 5| Step: 11
Training loss: 1.625622776709022
Validation loss: 2.4721326630213776

Epoch: 99| Step: 0
Training loss: 2.2540412214515797
Validation loss: 2.467857762958963

Epoch: 5| Step: 1
Training loss: 2.6193224952585505
Validation loss: 2.4675683561671873

Epoch: 5| Step: 2
Training loss: 2.7054276553851793
Validation loss: 2.4658371081897563

Epoch: 5| Step: 3
Training loss: 2.717386978311827
Validation loss: 2.4659708290617774

Epoch: 5| Step: 4
Training loss: 2.6172443440655226
Validation loss: 2.466842731483529

Epoch: 5| Step: 5
Training loss: 2.559433008824446
Validation loss: 2.472878914641048

Epoch: 5| Step: 6
Training loss: 2.1275496053683973
Validation loss: 2.471974528479541

Epoch: 5| Step: 7
Training loss: 2.809175009393049
Validation loss: 2.4785927634513882

Epoch: 5| Step: 8
Training loss: 2.5728876727448675
Validation loss: 2.4706844364308838

Epoch: 5| Step: 9
Training loss: 1.999521973226147
Validation loss: 2.4694054735370066

Epoch: 5| Step: 10
Training loss: 3.086147639205967
Validation loss: 2.473733419266709

Epoch: 5| Step: 11
Training loss: 3.1136263054253037
Validation loss: 2.477086020891439

Epoch: 100| Step: 0
Training loss: 2.1456656035513046
Validation loss: 2.4729224850640517

Epoch: 5| Step: 1
Training loss: 2.451658551660623
Validation loss: 2.4769649198722825

Epoch: 5| Step: 2
Training loss: 2.4856898828852674
Validation loss: 2.4760142942035492

Epoch: 5| Step: 3
Training loss: 2.533651084380565
Validation loss: 2.478924095617756

Epoch: 5| Step: 4
Training loss: 2.7297053108878897
Validation loss: 2.4818007049417314

Epoch: 5| Step: 5
Training loss: 2.640347347672939
Validation loss: 2.479970830968856

Epoch: 5| Step: 6
Training loss: 2.3930139510580575
Validation loss: 2.477405597127688

Epoch: 5| Step: 7
Training loss: 2.688647535314518
Validation loss: 2.479416359153473

Epoch: 5| Step: 8
Training loss: 2.5324606178588165
Validation loss: 2.4738380536738966

Epoch: 5| Step: 9
Training loss: 2.7783347292024905
Validation loss: 2.479370042061759

Epoch: 5| Step: 10
Training loss: 2.91325240342131
Validation loss: 2.4762355456250504

Epoch: 5| Step: 11
Training loss: 2.553918378584691
Validation loss: 2.474849039990476

Epoch: 101| Step: 0
Training loss: 2.161473016037919
Validation loss: 2.4800220397641555

Epoch: 5| Step: 1
Training loss: 3.162860557297338
Validation loss: 2.4783067547600703

Epoch: 5| Step: 2
Training loss: 2.4828115858168744
Validation loss: 2.4766741184949974

Epoch: 5| Step: 3
Training loss: 1.9687762788502228
Validation loss: 2.4804199574394916

Epoch: 5| Step: 4
Training loss: 2.5467888753172008
Validation loss: 2.4794245286614585

Epoch: 5| Step: 5
Training loss: 2.7970322719235625
Validation loss: 2.481542133762853

Epoch: 5| Step: 6
Training loss: 2.8002082100157653
Validation loss: 2.4805147402046726

Epoch: 5| Step: 7
Training loss: 2.425902924119887
Validation loss: 2.482250228698179

Epoch: 5| Step: 8
Training loss: 2.7502723038844565
Validation loss: 2.483831434145186

Epoch: 5| Step: 9
Training loss: 2.9295268510641708
Validation loss: 2.4785325791520822

Epoch: 5| Step: 10
Training loss: 2.3254508206948206
Validation loss: 2.481944949008848

Epoch: 5| Step: 11
Training loss: 2.5680980476901674
Validation loss: 2.4730338018796174

Epoch: 102| Step: 0
Training loss: 2.295759072692218
Validation loss: 2.4708858618424916

Epoch: 5| Step: 1
Training loss: 2.9178991347745
Validation loss: 2.4702834022862397

Epoch: 5| Step: 2
Training loss: 2.390978419290662
Validation loss: 2.4690261678304233

Epoch: 5| Step: 3
Training loss: 2.41608953709825
Validation loss: 2.4683485268037866

Epoch: 5| Step: 4
Training loss: 2.56927060979758
Validation loss: 2.461257647322771

Epoch: 5| Step: 5
Training loss: 2.737087364973898
Validation loss: 2.458570765220278

Epoch: 5| Step: 6
Training loss: 2.21207272126893
Validation loss: 2.4621229677038445

Epoch: 5| Step: 7
Training loss: 2.878146730024086
Validation loss: 2.466585530308431

Epoch: 5| Step: 8
Training loss: 2.7016814682790566
Validation loss: 2.4685208379239296

Epoch: 5| Step: 9
Training loss: 2.594570351903012
Validation loss: 2.469066615665934

Epoch: 5| Step: 10
Training loss: 2.5295623050880294
Validation loss: 2.467403445015018

Epoch: 5| Step: 11
Training loss: 2.646516086064626
Validation loss: 2.4650502589430183

Epoch: 103| Step: 0
Training loss: 2.8213226960720204
Validation loss: 2.469058194620408

Epoch: 5| Step: 1
Training loss: 2.5601933029329187
Validation loss: 2.4691669035639046

Epoch: 5| Step: 2
Training loss: 2.7836610437439253
Validation loss: 2.4676067022734394

Epoch: 5| Step: 3
Training loss: 2.3945630119669077
Validation loss: 2.4729599005420972

Epoch: 5| Step: 4
Training loss: 2.5626140662136305
Validation loss: 2.4697204806975828

Epoch: 5| Step: 5
Training loss: 2.6224667269011466
Validation loss: 2.471035716070537

Epoch: 5| Step: 6
Training loss: 2.641567626283862
Validation loss: 2.4750658480878767

Epoch: 5| Step: 7
Training loss: 2.2935118673752304
Validation loss: 2.4709956301307403

Epoch: 5| Step: 8
Training loss: 2.584444196851738
Validation loss: 2.469925785539218

Epoch: 5| Step: 9
Training loss: 1.9049471170489358
Validation loss: 2.466748818810108

Epoch: 5| Step: 10
Training loss: 2.857086933814841
Validation loss: 2.4651705026046327

Epoch: 5| Step: 11
Training loss: 2.5486988487929247
Validation loss: 2.4606609895564553

Epoch: 104| Step: 0
Training loss: 2.526275928030166
Validation loss: 2.4648353266181635

Epoch: 5| Step: 1
Training loss: 2.4326532545750594
Validation loss: 2.4760737212570576

Epoch: 5| Step: 2
Training loss: 2.6093048269007397
Validation loss: 2.491082818597269

Epoch: 5| Step: 3
Training loss: 2.270487441104849
Validation loss: 2.4792376248973156

Epoch: 5| Step: 4
Training loss: 2.2453310525720993
Validation loss: 2.4712257365281936

Epoch: 5| Step: 5
Training loss: 2.9446013626734935
Validation loss: 2.464766443232215

Epoch: 5| Step: 6
Training loss: 2.6628725856792803
Validation loss: 2.4677589817627594

Epoch: 5| Step: 7
Training loss: 2.7979206709124176
Validation loss: 2.456225717503798

Epoch: 5| Step: 8
Training loss: 2.5130179976742153
Validation loss: 2.463834182008153

Epoch: 5| Step: 9
Training loss: 2.6530072333233314
Validation loss: 2.461820034444246

Epoch: 5| Step: 10
Training loss: 2.7052369439501223
Validation loss: 2.4694986616585295

Epoch: 5| Step: 11
Training loss: 2.8290135794914057
Validation loss: 2.465209994182695

Epoch: 105| Step: 0
Training loss: 2.6251162548661537
Validation loss: 2.4714110715938475

Epoch: 5| Step: 1
Training loss: 2.3057697406028397
Validation loss: 2.4731409763864196

Epoch: 5| Step: 2
Training loss: 2.9916657075021496
Validation loss: 2.47205956658566

Epoch: 5| Step: 3
Training loss: 2.4915473139659046
Validation loss: 2.473620716280753

Epoch: 5| Step: 4
Training loss: 2.6142926504145856
Validation loss: 2.4826585510263732

Epoch: 5| Step: 5
Training loss: 2.328286184581271
Validation loss: 2.4818656332210205

Epoch: 5| Step: 6
Training loss: 2.7966151622929454
Validation loss: 2.4816231311718107

Epoch: 5| Step: 7
Training loss: 2.8534598113338587
Validation loss: 2.4849836295731653

Epoch: 5| Step: 8
Training loss: 2.6571188908036696
Validation loss: 2.483438383244425

Epoch: 5| Step: 9
Training loss: 2.4708444909223917
Validation loss: 2.4819062200379203

Epoch: 5| Step: 10
Training loss: 2.358121728558651
Validation loss: 2.4837108460059794

Epoch: 5| Step: 11
Training loss: 1.6437104775206408
Validation loss: 2.481030366050599

Epoch: 106| Step: 0
Training loss: 3.0279982911360843
Validation loss: 2.4844558190849493

Epoch: 5| Step: 1
Training loss: 2.09223393452106
Validation loss: 2.483844852463375

Epoch: 5| Step: 2
Training loss: 2.525330391598485
Validation loss: 2.4832847210160507

Epoch: 5| Step: 3
Training loss: 2.0860465374854837
Validation loss: 2.4772916095611626

Epoch: 5| Step: 4
Training loss: 2.59791414515157
Validation loss: 2.4765126637479606

Epoch: 5| Step: 5
Training loss: 1.8348137845757575
Validation loss: 2.4790302300509777

Epoch: 5| Step: 6
Training loss: 2.7045706703345247
Validation loss: 2.4757270085596397

Epoch: 5| Step: 7
Training loss: 2.837674536357542
Validation loss: 2.468890069456626

Epoch: 5| Step: 8
Training loss: 2.242528696716482
Validation loss: 2.4633146884438006

Epoch: 5| Step: 9
Training loss: 3.2852090838126626
Validation loss: 2.472024817895893

Epoch: 5| Step: 10
Training loss: 2.9046344163300994
Validation loss: 2.474043894174968

Epoch: 5| Step: 11
Training loss: 2.747130197034354
Validation loss: 2.4710836326093713

Epoch: 107| Step: 0
Training loss: 2.7625382433699524
Validation loss: 2.468321827484538

Epoch: 5| Step: 1
Training loss: 2.3025998763002953
Validation loss: 2.4713013378374984

Epoch: 5| Step: 2
Training loss: 2.6188172689096607
Validation loss: 2.4778272205341616

Epoch: 5| Step: 3
Training loss: 2.5992391023105634
Validation loss: 2.4654806838611143

Epoch: 5| Step: 4
Training loss: 2.519296750533477
Validation loss: 2.470727548993682

Epoch: 5| Step: 5
Training loss: 2.8921198098676526
Validation loss: 2.46659042771115

Epoch: 5| Step: 6
Training loss: 2.6104997049830896
Validation loss: 2.4688134124917185

Epoch: 5| Step: 7
Training loss: 2.3918136932514407
Validation loss: 2.4690651953960554

Epoch: 5| Step: 8
Training loss: 2.5313000144255926
Validation loss: 2.4663751946001424

Epoch: 5| Step: 9
Training loss: 2.4327011798338467
Validation loss: 2.4702368134130324

Epoch: 5| Step: 10
Training loss: 2.4681049904648544
Validation loss: 2.468075193255349

Epoch: 5| Step: 11
Training loss: 3.2473090842661287
Validation loss: 2.4664310960360996

Epoch: 108| Step: 0
Training loss: 2.4494113876782
Validation loss: 2.4623161450604596

Epoch: 5| Step: 1
Training loss: 2.430445414878386
Validation loss: 2.4673484896285647

Epoch: 5| Step: 2
Training loss: 2.476577999415468
Validation loss: 2.461324764237912

Epoch: 5| Step: 3
Training loss: 2.791804998206403
Validation loss: 2.4614002660573955

Epoch: 5| Step: 4
Training loss: 2.326558347638116
Validation loss: 2.4650918480034507

Epoch: 5| Step: 5
Training loss: 2.895272143392009
Validation loss: 2.4661855778349873

Epoch: 5| Step: 6
Training loss: 2.375934818401276
Validation loss: 2.45732588181575

Epoch: 5| Step: 7
Training loss: 2.010133581704556
Validation loss: 2.46164568848432

Epoch: 5| Step: 8
Training loss: 3.1303599358447416
Validation loss: 2.467990440505993

Epoch: 5| Step: 9
Training loss: 2.47525972101776
Validation loss: 2.4657136537756505

Epoch: 5| Step: 10
Training loss: 2.794449846992638
Validation loss: 2.4585776301945366

Epoch: 5| Step: 11
Training loss: 1.3298895838085114
Validation loss: 2.45912561069095

Epoch: 109| Step: 0
Training loss: 2.1260946483698473
Validation loss: 2.4649703793812634

Epoch: 5| Step: 1
Training loss: 2.3615050143112524
Validation loss: 2.4554634247108265

Epoch: 5| Step: 2
Training loss: 2.6021419028864603
Validation loss: 2.4607819886496833

Epoch: 5| Step: 3
Training loss: 2.396859211975382
Validation loss: 2.4563110056023825

Epoch: 5| Step: 4
Training loss: 3.1999111520830676
Validation loss: 2.4656292670744446

Epoch: 5| Step: 5
Training loss: 2.517598012249322
Validation loss: 2.4634237496434537

Epoch: 5| Step: 6
Training loss: 2.8833589526969505
Validation loss: 2.462422257049827

Epoch: 5| Step: 7
Training loss: 2.3856881221808304
Validation loss: 2.457392776649274

Epoch: 5| Step: 8
Training loss: 2.391951149515027
Validation loss: 2.463502034089632

Epoch: 5| Step: 9
Training loss: 2.4108125111585803
Validation loss: 2.463454954033969

Epoch: 5| Step: 10
Training loss: 2.5930032229567157
Validation loss: 2.464240631618483

Epoch: 5| Step: 11
Training loss: 2.992678450105373
Validation loss: 2.465179807360964

Epoch: 110| Step: 0
Training loss: 2.7054457211595246
Validation loss: 2.4589861364057843

Epoch: 5| Step: 1
Training loss: 2.4798571696220884
Validation loss: 2.466328274115842

Epoch: 5| Step: 2
Training loss: 2.372819702828803
Validation loss: 2.468724745609184

Epoch: 5| Step: 3
Training loss: 2.868464796063372
Validation loss: 2.4706011242223105

Epoch: 5| Step: 4
Training loss: 2.1135707240945383
Validation loss: 2.467453165308756

Epoch: 5| Step: 5
Training loss: 2.4207133799088396
Validation loss: 2.4728344877665047

Epoch: 5| Step: 6
Training loss: 2.966714904335838
Validation loss: 2.479663952605679

Epoch: 5| Step: 7
Training loss: 2.6601387729154684
Validation loss: 2.479826051446459

Epoch: 5| Step: 8
Training loss: 2.44933108326174
Validation loss: 2.486421809562806

Epoch: 5| Step: 9
Training loss: 2.3632201131684054
Validation loss: 2.481798899686343

Epoch: 5| Step: 10
Training loss: 3.009624460562434
Validation loss: 2.48820071886058

Epoch: 5| Step: 11
Training loss: 1.3135461724990818
Validation loss: 2.4958918275384154

Epoch: 111| Step: 0
Training loss: 2.428147591543471
Validation loss: 2.494607685023987

Epoch: 5| Step: 1
Training loss: 2.82067378469585
Validation loss: 2.4850793715682564

Epoch: 5| Step: 2
Training loss: 2.4179353234071277
Validation loss: 2.483522820817344

Epoch: 5| Step: 3
Training loss: 2.753382596490406
Validation loss: 2.4882266100000012

Epoch: 5| Step: 4
Training loss: 2.5270639350148687
Validation loss: 2.4815822995368793

Epoch: 5| Step: 5
Training loss: 2.487199533229476
Validation loss: 2.481935082704772

Epoch: 5| Step: 6
Training loss: 2.9500327092313174
Validation loss: 2.485036006298213

Epoch: 5| Step: 7
Training loss: 2.341554045316369
Validation loss: 2.478296376925276

Epoch: 5| Step: 8
Training loss: 2.904309517089583
Validation loss: 2.4767053123717493

Epoch: 5| Step: 9
Training loss: 2.318274016765292
Validation loss: 2.4759881269106603

Epoch: 5| Step: 10
Training loss: 2.471039688044807
Validation loss: 2.4692717254407475

Epoch: 5| Step: 11
Training loss: 2.5837679056507756
Validation loss: 2.4698205067465646

Epoch: 112| Step: 0
Training loss: 2.3212725262018803
Validation loss: 2.4619019046671387

Epoch: 5| Step: 1
Training loss: 2.9930221150578866
Validation loss: 2.462552294684168

Epoch: 5| Step: 2
Training loss: 2.4338338620197186
Validation loss: 2.4563447188216485

Epoch: 5| Step: 3
Training loss: 2.2029721903731825
Validation loss: 2.455961434203645

Epoch: 5| Step: 4
Training loss: 3.025780531383048
Validation loss: 2.4584016763486938

Epoch: 5| Step: 5
Training loss: 2.288666257966951
Validation loss: 2.4609073859092927

Epoch: 5| Step: 6
Training loss: 2.781347208788828
Validation loss: 2.4663941856832743

Epoch: 5| Step: 7
Training loss: 2.6172186550734264
Validation loss: 2.469895913766261

Epoch: 5| Step: 8
Training loss: 2.7485974810147047
Validation loss: 2.4664293480026056

Epoch: 5| Step: 9
Training loss: 2.526230721756407
Validation loss: 2.4645517683117264

Epoch: 5| Step: 10
Training loss: 2.469940767543246
Validation loss: 2.462620223446032

Epoch: 5| Step: 11
Training loss: 2.41898020356094
Validation loss: 2.45588836005607

Epoch: 113| Step: 0
Training loss: 2.6861645241438663
Validation loss: 2.4542998924319797

Epoch: 5| Step: 1
Training loss: 2.538976861536546
Validation loss: 2.451362332952768

Epoch: 5| Step: 2
Training loss: 2.3890304732935994
Validation loss: 2.454472400574093

Epoch: 5| Step: 3
Training loss: 3.0091150411189793
Validation loss: 2.455575868764443

Epoch: 5| Step: 4
Training loss: 1.9440660888167813
Validation loss: 2.457472114249549

Epoch: 5| Step: 5
Training loss: 2.615342494789405
Validation loss: 2.4611975073330536

Epoch: 5| Step: 6
Training loss: 2.248104568655855
Validation loss: 2.4695365352990404

Epoch: 5| Step: 7
Training loss: 2.4841667423890246
Validation loss: 2.462884377076596

Epoch: 5| Step: 8
Training loss: 2.223612654992078
Validation loss: 2.4637290783836865

Epoch: 5| Step: 9
Training loss: 2.9691948808315773
Validation loss: 2.460050865186337

Epoch: 5| Step: 10
Training loss: 2.8674610641483413
Validation loss: 2.4565527510165475

Epoch: 5| Step: 11
Training loss: 2.2207237383607943
Validation loss: 2.461464053542994

Epoch: 114| Step: 0
Training loss: 2.396389363215639
Validation loss: 2.458685038887726

Epoch: 5| Step: 1
Training loss: 2.896616402187369
Validation loss: 2.4626294208539403

Epoch: 5| Step: 2
Training loss: 2.591644351613752
Validation loss: 2.453750712782785

Epoch: 5| Step: 3
Training loss: 2.3391922440153716
Validation loss: 2.4622184285842548

Epoch: 5| Step: 4
Training loss: 2.915495573812104
Validation loss: 2.4625145234004036

Epoch: 5| Step: 5
Training loss: 2.768568035544322
Validation loss: 2.459573963394511

Epoch: 5| Step: 6
Training loss: 2.173296346681245
Validation loss: 2.4574462750351933

Epoch: 5| Step: 7
Training loss: 2.158190199869385
Validation loss: 2.456343343771373

Epoch: 5| Step: 8
Training loss: 2.6122650770945532
Validation loss: 2.4584584985539912

Epoch: 5| Step: 9
Training loss: 2.5475017501929864
Validation loss: 2.4608595618768434

Epoch: 5| Step: 10
Training loss: 2.428159079686887
Validation loss: 2.4612487152145337

Epoch: 5| Step: 11
Training loss: 3.3129352787419215
Validation loss: 2.4600997386913575

Epoch: 115| Step: 0
Training loss: 2.4316886682628414
Validation loss: 2.45751742519463

Epoch: 5| Step: 1
Training loss: 2.351684769908383
Validation loss: 2.4702468953438217

Epoch: 5| Step: 2
Training loss: 2.5014924363016795
Validation loss: 2.4620731579263717

Epoch: 5| Step: 3
Training loss: 2.4725878858230494
Validation loss: 2.4707320220423408

Epoch: 5| Step: 4
Training loss: 2.2434416662683097
Validation loss: 2.468862019987205

Epoch: 5| Step: 5
Training loss: 2.917802716578195
Validation loss: 2.4703443344609726

Epoch: 5| Step: 6
Training loss: 2.1091171672211906
Validation loss: 2.4687024647124023

Epoch: 5| Step: 7
Training loss: 2.8940783518299504
Validation loss: 2.4620885105006534

Epoch: 5| Step: 8
Training loss: 2.5324229595670977
Validation loss: 2.460511472449055

Epoch: 5| Step: 9
Training loss: 2.588909734479217
Validation loss: 2.46164030706536

Epoch: 5| Step: 10
Training loss: 2.8576466490860475
Validation loss: 2.4561527300883608

Epoch: 5| Step: 11
Training loss: 3.1890323919718813
Validation loss: 2.4669981346071777

Epoch: 116| Step: 0
Training loss: 2.4714333160128046
Validation loss: 2.4527083121985345

Epoch: 5| Step: 1
Training loss: 2.8000892624931955
Validation loss: 2.4631257031973797

Epoch: 5| Step: 2
Training loss: 2.5385323778018263
Validation loss: 2.453449159007458

Epoch: 5| Step: 3
Training loss: 2.8998924366964336
Validation loss: 2.457831062041476

Epoch: 5| Step: 4
Training loss: 2.210307432514316
Validation loss: 2.4536876276244013

Epoch: 5| Step: 5
Training loss: 2.5537296097548716
Validation loss: 2.4581128778586314

Epoch: 5| Step: 6
Training loss: 2.5013007594748307
Validation loss: 2.4536343752332277

Epoch: 5| Step: 7
Training loss: 2.3769238359688916
Validation loss: 2.458789380386368

Epoch: 5| Step: 8
Training loss: 2.4888050240718855
Validation loss: 2.45929814791782

Epoch: 5| Step: 9
Training loss: 2.266439146889935
Validation loss: 2.4531607979594283

Epoch: 5| Step: 10
Training loss: 2.943845186091703
Validation loss: 2.4569232737028806

Epoch: 5| Step: 11
Training loss: 2.4262238864977217
Validation loss: 2.45226105381144

Epoch: 117| Step: 0
Training loss: 2.934424555708415
Validation loss: 2.4549404642845745

Epoch: 5| Step: 1
Training loss: 2.761640016116018
Validation loss: 2.4574837159360756

Epoch: 5| Step: 2
Training loss: 2.568398734251648
Validation loss: 2.456816879729451

Epoch: 5| Step: 3
Training loss: 2.3116788695035537
Validation loss: 2.4559564185280482

Epoch: 5| Step: 4
Training loss: 2.601599157493239
Validation loss: 2.457053434578063

Epoch: 5| Step: 5
Training loss: 2.3827747779736983
Validation loss: 2.4573017693139834

Epoch: 5| Step: 6
Training loss: 2.6339273780653794
Validation loss: 2.4572769834611496

Epoch: 5| Step: 7
Training loss: 2.274843914839773
Validation loss: 2.468672445342587

Epoch: 5| Step: 8
Training loss: 2.27688295600165
Validation loss: 2.4617384681892567

Epoch: 5| Step: 9
Training loss: 2.954905462673038
Validation loss: 2.4637477632625653

Epoch: 5| Step: 10
Training loss: 2.2776881590583358
Validation loss: 2.4655574686192363

Epoch: 5| Step: 11
Training loss: 2.977200176988417
Validation loss: 2.4691824795768826

Epoch: 118| Step: 0
Training loss: 2.203141665564737
Validation loss: 2.4660901537003728

Epoch: 5| Step: 1
Training loss: 2.9652303611980475
Validation loss: 2.4666214067800265

Epoch: 5| Step: 2
Training loss: 2.316836029375346
Validation loss: 2.4695193987051827

Epoch: 5| Step: 3
Training loss: 2.3143041635211876
Validation loss: 2.471332896991578

Epoch: 5| Step: 4
Training loss: 2.907933393667963
Validation loss: 2.4698908017032055

Epoch: 5| Step: 5
Training loss: 2.7997151025517835
Validation loss: 2.4697905452108446

Epoch: 5| Step: 6
Training loss: 1.8699306624098282
Validation loss: 2.4696831006134774

Epoch: 5| Step: 7
Training loss: 2.245770718109186
Validation loss: 2.464852161262134

Epoch: 5| Step: 8
Training loss: 2.589416008287786
Validation loss: 2.461395120205894

Epoch: 5| Step: 9
Training loss: 2.857752271781968
Validation loss: 2.4552911844518213

Epoch: 5| Step: 10
Training loss: 2.722060457167843
Validation loss: 2.463981001850112

Epoch: 5| Step: 11
Training loss: 2.088787631980545
Validation loss: 2.464716239488529

Epoch: 119| Step: 0
Training loss: 2.994142376823933
Validation loss: 2.4576606672064063

Epoch: 5| Step: 1
Training loss: 2.2667892095688287
Validation loss: 2.467639766001913

Epoch: 5| Step: 2
Training loss: 2.181631007980146
Validation loss: 2.468226622782551

Epoch: 5| Step: 3
Training loss: 2.8451658643700135
Validation loss: 2.4767411585725365

Epoch: 5| Step: 4
Training loss: 3.076928540371666
Validation loss: 2.4838949135490864

Epoch: 5| Step: 5
Training loss: 2.430765581290747
Validation loss: 2.4728138950227785

Epoch: 5| Step: 6
Training loss: 2.181268808890409
Validation loss: 2.481441809561563

Epoch: 5| Step: 7
Training loss: 2.9584578546098035
Validation loss: 2.4681675763135487

Epoch: 5| Step: 8
Training loss: 2.1578405291417027
Validation loss: 2.462558168282567

Epoch: 5| Step: 9
Training loss: 2.3185952764748117
Validation loss: 2.4708156756069775

Epoch: 5| Step: 10
Training loss: 2.5238007558600066
Validation loss: 2.4673517448317184

Epoch: 5| Step: 11
Training loss: 2.399516605333253
Validation loss: 2.4737858253700415

Epoch: 120| Step: 0
Training loss: 2.7268749156447405
Validation loss: 2.4702546568341077

Epoch: 5| Step: 1
Training loss: 2.430491029397544
Validation loss: 2.4681058236384454

Epoch: 5| Step: 2
Training loss: 2.3801088096685445
Validation loss: 2.476770458455377

Epoch: 5| Step: 3
Training loss: 2.3349078406499504
Validation loss: 2.4896690973701654

Epoch: 5| Step: 4
Training loss: 2.3425650080532594
Validation loss: 2.5050050582948886

Epoch: 5| Step: 5
Training loss: 2.702822982586043
Validation loss: 2.51811441411867

Epoch: 5| Step: 6
Training loss: 2.7270784518375715
Validation loss: 2.52863341753053

Epoch: 5| Step: 7
Training loss: 3.119808615169861
Validation loss: 2.5266378754377823

Epoch: 5| Step: 8
Training loss: 2.5481289076242994
Validation loss: 2.5386282211990276

Epoch: 5| Step: 9
Training loss: 2.9146631353077113
Validation loss: 2.53953593217415

Epoch: 5| Step: 10
Training loss: 2.492845884790346
Validation loss: 2.5397115846085443

Epoch: 5| Step: 11
Training loss: 2.037621116548833
Validation loss: 2.527432019098958

Epoch: 121| Step: 0
Training loss: 2.9048305859959203
Validation loss: 2.5230533594848503

Epoch: 5| Step: 1
Training loss: 2.5050427123671346
Validation loss: 2.527458530278253

Epoch: 5| Step: 2
Training loss: 3.1106374660101888
Validation loss: 2.5270689589386963

Epoch: 5| Step: 3
Training loss: 2.1909693862190034
Validation loss: 2.5264936390184003

Epoch: 5| Step: 4
Training loss: 3.2274411092832667
Validation loss: 2.5240025000985526

Epoch: 5| Step: 5
Training loss: 2.464761433383043
Validation loss: 2.5232211395196043

Epoch: 5| Step: 6
Training loss: 2.689662063671596
Validation loss: 2.5190352037821198

Epoch: 5| Step: 7
Training loss: 2.2264783341411394
Validation loss: 2.5143995281593674

Epoch: 5| Step: 8
Training loss: 2.3215150125360324
Validation loss: 2.5136038319730596

Epoch: 5| Step: 9
Training loss: 2.8000695083709948
Validation loss: 2.5026355957111295

Epoch: 5| Step: 10
Training loss: 2.4517629936514203
Validation loss: 2.4997468025417753

Epoch: 5| Step: 11
Training loss: 1.582723734438725
Validation loss: 2.499808610106894

Epoch: 122| Step: 0
Training loss: 1.959981495322243
Validation loss: 2.494428382550188

Epoch: 5| Step: 1
Training loss: 2.609613007980708
Validation loss: 2.4899767095365113

Epoch: 5| Step: 2
Training loss: 2.820148410408959
Validation loss: 2.482843568822351

Epoch: 5| Step: 3
Training loss: 2.8173260291342315
Validation loss: 2.480004178493579

Epoch: 5| Step: 4
Training loss: 2.4609601700964747
Validation loss: 2.4770887720247776

Epoch: 5| Step: 5
Training loss: 2.6329668039445213
Validation loss: 2.475682010830448

Epoch: 5| Step: 6
Training loss: 2.4520990449525737
Validation loss: 2.4731156664133866

Epoch: 5| Step: 7
Training loss: 2.7930568441089467
Validation loss: 2.4695964038319134

Epoch: 5| Step: 8
Training loss: 2.362896848579897
Validation loss: 2.4680000747571684

Epoch: 5| Step: 9
Training loss: 2.6243436083513956
Validation loss: 2.4701078640208434

Epoch: 5| Step: 10
Training loss: 2.803350698513295
Validation loss: 2.470223284981737

Epoch: 5| Step: 11
Training loss: 2.95588966415613
Validation loss: 2.4664748568856316

Epoch: 123| Step: 0
Training loss: 2.6772872807536556
Validation loss: 2.4653917157942105

Epoch: 5| Step: 1
Training loss: 2.4109299961846022
Validation loss: 2.4588701071636945

Epoch: 5| Step: 2
Training loss: 2.325667242472831
Validation loss: 2.4618937819262308

Epoch: 5| Step: 3
Training loss: 2.2969046869759846
Validation loss: 2.4573255887236374

Epoch: 5| Step: 4
Training loss: 2.5881740889860327
Validation loss: 2.4608469507422166

Epoch: 5| Step: 5
Training loss: 2.6954969260103234
Validation loss: 2.457924781945862

Epoch: 5| Step: 6
Training loss: 2.8041118573013555
Validation loss: 2.4598951241317675

Epoch: 5| Step: 7
Training loss: 2.322096116638682
Validation loss: 2.4549974030198025

Epoch: 5| Step: 8
Training loss: 2.692034599580651
Validation loss: 2.459286518436038

Epoch: 5| Step: 9
Training loss: 2.719627940172164
Validation loss: 2.4603114729564646

Epoch: 5| Step: 10
Training loss: 2.4381864510355697
Validation loss: 2.4488802589249827

Epoch: 5| Step: 11
Training loss: 2.9734046184507776
Validation loss: 2.4556734571613728

Epoch: 124| Step: 0
Training loss: 2.6850951324601757
Validation loss: 2.452137871986232

Epoch: 5| Step: 1
Training loss: 2.1426119527867407
Validation loss: 2.45149307476847

Epoch: 5| Step: 2
Training loss: 3.2227447312663897
Validation loss: 2.4545727485044737

Epoch: 5| Step: 3
Training loss: 2.3220822556257756
Validation loss: 2.4560560950698003

Epoch: 5| Step: 4
Training loss: 2.516403741133587
Validation loss: 2.4683695673059276

Epoch: 5| Step: 5
Training loss: 2.6900849441673653
Validation loss: 2.4672146380757773

Epoch: 5| Step: 6
Training loss: 2.3646146685390765
Validation loss: 2.4587351375008457

Epoch: 5| Step: 7
Training loss: 2.5466961944159796
Validation loss: 2.4609122865384347

Epoch: 5| Step: 8
Training loss: 2.6256110070610976
Validation loss: 2.4691010881414934

Epoch: 5| Step: 9
Training loss: 2.674390623613559
Validation loss: 2.4590161770679817

Epoch: 5| Step: 10
Training loss: 2.335369436539078
Validation loss: 2.4614027885296923

Epoch: 5| Step: 11
Training loss: 2.169364301324882
Validation loss: 2.454608497020093

Epoch: 125| Step: 0
Training loss: 2.199282060867126
Validation loss: 2.4515453201058297

Epoch: 5| Step: 1
Training loss: 2.0551392961427926
Validation loss: 2.4501844101550887

Epoch: 5| Step: 2
Training loss: 3.136567488618209
Validation loss: 2.4543393403550144

Epoch: 5| Step: 3
Training loss: 2.637713751786715
Validation loss: 2.4512628100221128

Epoch: 5| Step: 4
Training loss: 2.30693756440349
Validation loss: 2.457891809825293

Epoch: 5| Step: 5
Training loss: 2.6395057247307174
Validation loss: 2.461973954990058

Epoch: 5| Step: 6
Training loss: 2.6596775156308143
Validation loss: 2.459340682511307

Epoch: 5| Step: 7
Training loss: 2.679034006048898
Validation loss: 2.4622625305838657

Epoch: 5| Step: 8
Training loss: 2.2074514343518348
Validation loss: 2.455716459066792

Epoch: 5| Step: 9
Training loss: 2.4957865494645732
Validation loss: 2.456946164807377

Epoch: 5| Step: 10
Training loss: 2.5982367074979327
Validation loss: 2.4520485575458997

Epoch: 5| Step: 11
Training loss: 3.5521735723374634
Validation loss: 2.452005288743792

Epoch: 126| Step: 0
Training loss: 2.821685710316217
Validation loss: 2.4508680299687136

Epoch: 5| Step: 1
Training loss: 2.4949577982358795
Validation loss: 2.450980137675403

Epoch: 5| Step: 2
Training loss: 2.70268872218769
Validation loss: 2.4551503715314476

Epoch: 5| Step: 3
Training loss: 2.948279548299631
Validation loss: 2.4532057309483335

Epoch: 5| Step: 4
Training loss: 1.852500516966054
Validation loss: 2.4617014794050034

Epoch: 5| Step: 5
Training loss: 2.6466722034649464
Validation loss: 2.4497088763756154

Epoch: 5| Step: 6
Training loss: 2.4371105763328003
Validation loss: 2.456844304527921

Epoch: 5| Step: 7
Training loss: 2.214703698414585
Validation loss: 2.4552519885166046

Epoch: 5| Step: 8
Training loss: 2.8047668955836618
Validation loss: 2.4515943023907547

Epoch: 5| Step: 9
Training loss: 2.733586486475328
Validation loss: 2.4521259330629377

Epoch: 5| Step: 10
Training loss: 1.8959126578143812
Validation loss: 2.452682195980137

Epoch: 5| Step: 11
Training loss: 3.126293067437194
Validation loss: 2.4513680307391263

Epoch: 127| Step: 0
Training loss: 2.5573249291602433
Validation loss: 2.447343622595002

Epoch: 5| Step: 1
Training loss: 2.7988978055810514
Validation loss: 2.450682560080071

Epoch: 5| Step: 2
Training loss: 2.3992509984464196
Validation loss: 2.446668271376926

Epoch: 5| Step: 3
Training loss: 2.5304531208814676
Validation loss: 2.4519501685318708

Epoch: 5| Step: 4
Training loss: 2.189515520443716
Validation loss: 2.456321779646948

Epoch: 5| Step: 5
Training loss: 2.592641570622654
Validation loss: 2.4568339613814985

Epoch: 5| Step: 6
Training loss: 2.578841323751735
Validation loss: 2.453659141200515

Epoch: 5| Step: 7
Training loss: 1.9864221061146317
Validation loss: 2.4474948005504147

Epoch: 5| Step: 8
Training loss: 2.9493390393515235
Validation loss: 2.443530590259826

Epoch: 5| Step: 9
Training loss: 2.9576728155057217
Validation loss: 2.450196074729812

Epoch: 5| Step: 10
Training loss: 2.067780295656368
Validation loss: 2.4471308982401188

Epoch: 5| Step: 11
Training loss: 2.953149866070079
Validation loss: 2.4491139196323273

Epoch: 128| Step: 0
Training loss: 2.9086326758407894
Validation loss: 2.453906532084358

Epoch: 5| Step: 1
Training loss: 2.6075401936521
Validation loss: 2.453212242437932

Epoch: 5| Step: 2
Training loss: 2.2566068921796103
Validation loss: 2.456103329085202

Epoch: 5| Step: 3
Training loss: 2.2244083089282647
Validation loss: 2.4530585456156726

Epoch: 5| Step: 4
Training loss: 2.3654841473067765
Validation loss: 2.443902682797345

Epoch: 5| Step: 5
Training loss: 2.6523391656175863
Validation loss: 2.4573850230462058

Epoch: 5| Step: 6
Training loss: 2.425868525754858
Validation loss: 2.446820477641069

Epoch: 5| Step: 7
Training loss: 2.573736906902994
Validation loss: 2.451355468034686

Epoch: 5| Step: 8
Training loss: 2.638667086152899
Validation loss: 2.450719625995166

Epoch: 5| Step: 9
Training loss: 2.520396854244776
Validation loss: 2.4499282660979227

Epoch: 5| Step: 10
Training loss: 2.6474084345875206
Validation loss: 2.454350422573507

Epoch: 5| Step: 11
Training loss: 2.761817682158774
Validation loss: 2.4533050373853986

Epoch: 129| Step: 0
Training loss: 2.2163388758017435
Validation loss: 2.450616205665526

Epoch: 5| Step: 1
Training loss: 2.5785249342083603
Validation loss: 2.4617022683380703

Epoch: 5| Step: 2
Training loss: 2.745335698124721
Validation loss: 2.452380680949707

Epoch: 5| Step: 3
Training loss: 2.700516781977107
Validation loss: 2.4509383051054336

Epoch: 5| Step: 4
Training loss: 2.5862996288643108
Validation loss: 2.4560230270782064

Epoch: 5| Step: 5
Training loss: 2.756294502712138
Validation loss: 2.4478699916420914

Epoch: 5| Step: 6
Training loss: 2.1245637333647833
Validation loss: 2.4613130393930907

Epoch: 5| Step: 7
Training loss: 2.7795938425652165
Validation loss: 2.4486680372449654

Epoch: 5| Step: 8
Training loss: 1.9564056310202567
Validation loss: 2.4508427331824816

Epoch: 5| Step: 9
Training loss: 2.6068205064937193
Validation loss: 2.4468926777044784

Epoch: 5| Step: 10
Training loss: 2.783877214146634
Validation loss: 2.4523548529030186

Epoch: 5| Step: 11
Training loss: 2.064587894541157
Validation loss: 2.449291725024705

Epoch: 130| Step: 0
Training loss: 2.4667185863838665
Validation loss: 2.440671923255921

Epoch: 5| Step: 1
Training loss: 1.4711751193143028
Validation loss: 2.4459718337369876

Epoch: 5| Step: 2
Training loss: 2.536186772926625
Validation loss: 2.4526072075134295

Epoch: 5| Step: 3
Training loss: 2.455957320541431
Validation loss: 2.4546699356561197

Epoch: 5| Step: 4
Training loss: 2.8386778819213654
Validation loss: 2.4425565283372825

Epoch: 5| Step: 5
Training loss: 2.5525570073052655
Validation loss: 2.44967456086697

Epoch: 5| Step: 6
Training loss: 2.542298868901601
Validation loss: 2.448031797474728

Epoch: 5| Step: 7
Training loss: 2.916331698846644
Validation loss: 2.456889501706928

Epoch: 5| Step: 8
Training loss: 2.7639773358410906
Validation loss: 2.45552624173837

Epoch: 5| Step: 9
Training loss: 2.9719559876069748
Validation loss: 2.4512320826457747

Epoch: 5| Step: 10
Training loss: 1.9891479641637502
Validation loss: 2.4574409753755186

Epoch: 5| Step: 11
Training loss: 2.5419242811713523
Validation loss: 2.4547517691587513

Epoch: 131| Step: 0
Training loss: 2.6030020182158786
Validation loss: 2.4603792435343412

Epoch: 5| Step: 1
Training loss: 2.551726418793682
Validation loss: 2.4610355579680703

Epoch: 5| Step: 2
Training loss: 2.4910826909855155
Validation loss: 2.46610946118214

Epoch: 5| Step: 3
Training loss: 2.7817887202372695
Validation loss: 2.462225731229558

Epoch: 5| Step: 4
Training loss: 2.801702924997178
Validation loss: 2.4697456927279475

Epoch: 5| Step: 5
Training loss: 2.2587028252763526
Validation loss: 2.4666672745802707

Epoch: 5| Step: 6
Training loss: 2.7299110814519723
Validation loss: 2.4612597219243835

Epoch: 5| Step: 7
Training loss: 2.2938027108187984
Validation loss: 2.461730086642398

Epoch: 5| Step: 8
Training loss: 2.5534132833223016
Validation loss: 2.46654068398511

Epoch: 5| Step: 9
Training loss: 2.261023538108432
Validation loss: 2.4643442783412794

Epoch: 5| Step: 10
Training loss: 2.6613094838143376
Validation loss: 2.454537327294857

Epoch: 5| Step: 11
Training loss: 1.2886385133696914
Validation loss: 2.4587437716762186

Epoch: 132| Step: 0
Training loss: 2.693164444937967
Validation loss: 2.460129051021801

Epoch: 5| Step: 1
Training loss: 2.513878447040863
Validation loss: 2.4561139624782173

Epoch: 5| Step: 2
Training loss: 2.4506138869376306
Validation loss: 2.456371184345207

Epoch: 5| Step: 3
Training loss: 2.6082306139852705
Validation loss: 2.460389866522801

Epoch: 5| Step: 4
Training loss: 2.7491238672263414
Validation loss: 2.4531084209942895

Epoch: 5| Step: 5
Training loss: 2.4222909877749137
Validation loss: 2.455920018168956

Epoch: 5| Step: 6
Training loss: 2.737719773480381
Validation loss: 2.4554937673927335

Epoch: 5| Step: 7
Training loss: 2.658914553522883
Validation loss: 2.450072736374036

Epoch: 5| Step: 8
Training loss: 2.4616463745286365
Validation loss: 2.449439055590048

Epoch: 5| Step: 9
Training loss: 2.015935356435847
Validation loss: 2.4470606964439585

Epoch: 5| Step: 10
Training loss: 2.34795846120558
Validation loss: 2.4549303923318915

Epoch: 5| Step: 11
Training loss: 2.3214644838007623
Validation loss: 2.450104479767752

Epoch: 133| Step: 0
Training loss: 2.2690225316656822
Validation loss: 2.453911426453311

Epoch: 5| Step: 1
Training loss: 2.378390151291725
Validation loss: 2.4609501308540875

Epoch: 5| Step: 2
Training loss: 2.6957735855894804
Validation loss: 2.452980936278807

Epoch: 5| Step: 3
Training loss: 2.6591589762609256
Validation loss: 2.449430830684957

Epoch: 5| Step: 4
Training loss: 2.6452858325855604
Validation loss: 2.446490693554958

Epoch: 5| Step: 5
Training loss: 2.7995805494299644
Validation loss: 2.454600214564766

Epoch: 5| Step: 6
Training loss: 2.262833342048574
Validation loss: 2.4621049765849623

Epoch: 5| Step: 7
Training loss: 2.54501527628033
Validation loss: 2.462365122875686

Epoch: 5| Step: 8
Training loss: 2.298444873167824
Validation loss: 2.4651715906463805

Epoch: 5| Step: 9
Training loss: 2.846254859487936
Validation loss: 2.4579995273535835

Epoch: 5| Step: 10
Training loss: 2.539155459536275
Validation loss: 2.4655031187798104

Epoch: 5| Step: 11
Training loss: 2.010434587098995
Validation loss: 2.4632390033274234

Epoch: 134| Step: 0
Training loss: 2.739101401366695
Validation loss: 2.4575383623769635

Epoch: 5| Step: 1
Training loss: 2.393709275021249
Validation loss: 2.467120421457849

Epoch: 5| Step: 2
Training loss: 2.840843811672316
Validation loss: 2.4626128816308546

Epoch: 5| Step: 3
Training loss: 2.5031932464325632
Validation loss: 2.464198234011033

Epoch: 5| Step: 4
Training loss: 2.7692855489235937
Validation loss: 2.4646614478838234

Epoch: 5| Step: 5
Training loss: 2.4450684446962354
Validation loss: 2.46864107752796

Epoch: 5| Step: 6
Training loss: 2.529092599285945
Validation loss: 2.461423246693506

Epoch: 5| Step: 7
Training loss: 2.306883305793306
Validation loss: 2.4632838210376695

Epoch: 5| Step: 8
Training loss: 2.393649313778757
Validation loss: 2.4609706129641777

Epoch: 5| Step: 9
Training loss: 2.4475592386092444
Validation loss: 2.4609050768780114

Epoch: 5| Step: 10
Training loss: 2.379998418342642
Validation loss: 2.4525027852718235

Epoch: 5| Step: 11
Training loss: 2.3334072532752295
Validation loss: 2.453660270785019

Epoch: 135| Step: 0
Training loss: 2.6251672963918717
Validation loss: 2.4559998482762104

Epoch: 5| Step: 1
Training loss: 2.0838071538619123
Validation loss: 2.4545314102193845

Epoch: 5| Step: 2
Training loss: 2.7854394969323164
Validation loss: 2.4556995051599437

Epoch: 5| Step: 3
Training loss: 2.21419508919966
Validation loss: 2.4510920416609046

Epoch: 5| Step: 4
Training loss: 3.079247904021199
Validation loss: 2.455609270461158

Epoch: 5| Step: 5
Training loss: 2.669311453657515
Validation loss: 2.4735462943156183

Epoch: 5| Step: 6
Training loss: 2.09127672925103
Validation loss: 2.458166740451706

Epoch: 5| Step: 7
Training loss: 2.6718683967731818
Validation loss: 2.458904960951797

Epoch: 5| Step: 8
Training loss: 1.930853857996809
Validation loss: 2.460539609037666

Epoch: 5| Step: 9
Training loss: 2.62766149109892
Validation loss: 2.4579324732214705

Epoch: 5| Step: 10
Training loss: 2.8748548719845224
Validation loss: 2.463181420265421

Epoch: 5| Step: 11
Training loss: 1.8489301939063238
Validation loss: 2.4538570251353193

Epoch: 136| Step: 0
Training loss: 2.3140173393134
Validation loss: 2.455755022599857

Epoch: 5| Step: 1
Training loss: 2.550860323417847
Validation loss: 2.453313901232992

Epoch: 5| Step: 2
Training loss: 2.2897850172253866
Validation loss: 2.4555716978187916

Epoch: 5| Step: 3
Training loss: 3.210567852192617
Validation loss: 2.455540874674895

Epoch: 5| Step: 4
Training loss: 2.5995418731844757
Validation loss: 2.4577439188862096

Epoch: 5| Step: 5
Training loss: 2.395121615195084
Validation loss: 2.4521468696908255

Epoch: 5| Step: 6
Training loss: 2.0842455456294773
Validation loss: 2.453445672783759

Epoch: 5| Step: 7
Training loss: 2.579536190482276
Validation loss: 2.4567878938208856

Epoch: 5| Step: 8
Training loss: 2.5125266002556446
Validation loss: 2.4511771760556473

Epoch: 5| Step: 9
Training loss: 2.6836321299111408
Validation loss: 2.4559246698728705

Epoch: 5| Step: 10
Training loss: 2.2433236994921453
Validation loss: 2.4520532814157057

Epoch: 5| Step: 11
Training loss: 2.712439656794995
Validation loss: 2.4634853495047424

Epoch: 137| Step: 0
Training loss: 2.6916611859371105
Validation loss: 2.4556875855750695

Epoch: 5| Step: 1
Training loss: 2.6711101664250387
Validation loss: 2.45933898194956

Epoch: 5| Step: 2
Training loss: 2.8405384751373024
Validation loss: 2.4597872069120155

Epoch: 5| Step: 3
Training loss: 1.8161246789069072
Validation loss: 2.4568857211552926

Epoch: 5| Step: 4
Training loss: 2.9163467413417874
Validation loss: 2.4586019261501706

Epoch: 5| Step: 5
Training loss: 2.0869054941404004
Validation loss: 2.4621145471180332

Epoch: 5| Step: 6
Training loss: 2.8909440148077805
Validation loss: 2.467646384330485

Epoch: 5| Step: 7
Training loss: 2.6400631639842747
Validation loss: 2.462091710118403

Epoch: 5| Step: 8
Training loss: 1.7908719836159255
Validation loss: 2.452452828714832

Epoch: 5| Step: 9
Training loss: 2.4802361326703775
Validation loss: 2.4525343392418217

Epoch: 5| Step: 10
Training loss: 2.6579783482642045
Validation loss: 2.4575193210487773

Epoch: 5| Step: 11
Training loss: 1.948698597463159
Validation loss: 2.4457362724900795

Epoch: 138| Step: 0
Training loss: 2.8151677512940547
Validation loss: 2.4537031784163683

Epoch: 5| Step: 1
Training loss: 3.0039205364785433
Validation loss: 2.4508110844720856

Epoch: 5| Step: 2
Training loss: 1.9621642633439216
Validation loss: 2.4548900757812997

Epoch: 5| Step: 3
Training loss: 2.3318465014300767
Validation loss: 2.4453963609641995

Epoch: 5| Step: 4
Training loss: 2.3570191198131063
Validation loss: 2.443077703392066

Epoch: 5| Step: 5
Training loss: 2.4554166355604523
Validation loss: 2.4483354020959345

Epoch: 5| Step: 6
Training loss: 2.346340731216447
Validation loss: 2.456434572644305

Epoch: 5| Step: 7
Training loss: 2.893453832510825
Validation loss: 2.453759611457168

Epoch: 5| Step: 8
Training loss: 2.7036710860066897
Validation loss: 2.454809606612238

Epoch: 5| Step: 9
Training loss: 2.0885632165826022
Validation loss: 2.456949132568974

Epoch: 5| Step: 10
Training loss: 2.7501549243636636
Validation loss: 2.471593338085909

Epoch: 5| Step: 11
Training loss: 1.7376637937335548
Validation loss: 2.470355477583537

Epoch: 139| Step: 0
Training loss: 2.0517568828829402
Validation loss: 2.464748777725139

Epoch: 5| Step: 1
Training loss: 2.7215917358860535
Validation loss: 2.458532464049753

Epoch: 5| Step: 2
Training loss: 1.8614451320573577
Validation loss: 2.4638342303918015

Epoch: 5| Step: 3
Training loss: 2.740208185876946
Validation loss: 2.461024744011207

Epoch: 5| Step: 4
Training loss: 2.1855714198311755
Validation loss: 2.4565134174953123

Epoch: 5| Step: 5
Training loss: 2.731377839123495
Validation loss: 2.4539322587863195

Epoch: 5| Step: 6
Training loss: 2.9868452623590755
Validation loss: 2.4574817695245468

Epoch: 5| Step: 7
Training loss: 2.742743020152848
Validation loss: 2.457187087671765

Epoch: 5| Step: 8
Training loss: 2.4737952141776476
Validation loss: 2.455849655016443

Epoch: 5| Step: 9
Training loss: 2.373248207122952
Validation loss: 2.4518294304781283

Epoch: 5| Step: 10
Training loss: 2.425731517140657
Validation loss: 2.457414400098132

Epoch: 5| Step: 11
Training loss: 3.146053045486463
Validation loss: 2.4462429303700763

Epoch: 140| Step: 0
Training loss: 2.2602691485059347
Validation loss: 2.4526403397858623

Epoch: 5| Step: 1
Training loss: 2.5937980739320747
Validation loss: 2.455039103705455

Epoch: 5| Step: 2
Training loss: 2.382697531005871
Validation loss: 2.453943112094562

Epoch: 5| Step: 3
Training loss: 2.6925748771095583
Validation loss: 2.456685299112563

Epoch: 5| Step: 4
Training loss: 2.2771306927901875
Validation loss: 2.4539243910186843

Epoch: 5| Step: 5
Training loss: 2.376823728952819
Validation loss: 2.4608184624194727

Epoch: 5| Step: 6
Training loss: 2.826248389357083
Validation loss: 2.46815310678508

Epoch: 5| Step: 7
Training loss: 2.6591941225106277
Validation loss: 2.454489411524784

Epoch: 5| Step: 8
Training loss: 2.3443474580290538
Validation loss: 2.4560709311300157

Epoch: 5| Step: 9
Training loss: 2.931911102768734
Validation loss: 2.461820272525139

Epoch: 5| Step: 10
Training loss: 2.17446656975362
Validation loss: 2.461780956583614

Epoch: 5| Step: 11
Training loss: 2.6398316043552907
Validation loss: 2.469084910117368

Epoch: 141| Step: 0
Training loss: 2.928968824612054
Validation loss: 2.4647128215985368

Epoch: 5| Step: 1
Training loss: 2.6247885482635938
Validation loss: 2.462998878142917

Epoch: 5| Step: 2
Training loss: 2.4598880528355167
Validation loss: 2.4694850849332735

Epoch: 5| Step: 3
Training loss: 2.381407777059794
Validation loss: 2.4828257738626425

Epoch: 5| Step: 4
Training loss: 2.575031158110612
Validation loss: 2.484770341522965

Epoch: 5| Step: 5
Training loss: 2.3222329768652266
Validation loss: 2.4792161877812577

Epoch: 5| Step: 6
Training loss: 2.4452558516988225
Validation loss: 2.483179930588178

Epoch: 5| Step: 7
Training loss: 2.879833967403255
Validation loss: 2.477312826739349

Epoch: 5| Step: 8
Training loss: 2.354521451789568
Validation loss: 2.4784960093422175

Epoch: 5| Step: 9
Training loss: 2.2439138963605054
Validation loss: 2.4779626877340926

Epoch: 5| Step: 10
Training loss: 2.6595469938035983
Validation loss: 2.471527593307248

Epoch: 5| Step: 11
Training loss: 2.162410835677027
Validation loss: 2.468542961501017

Epoch: 142| Step: 0
Training loss: 2.2981321047667107
Validation loss: 2.4685817331198305

Epoch: 5| Step: 1
Training loss: 2.4092037352810247
Validation loss: 2.471582598457993

Epoch: 5| Step: 2
Training loss: 2.422662028748953
Validation loss: 2.4653869207755124

Epoch: 5| Step: 3
Training loss: 2.70527175595911
Validation loss: 2.4670901573454866

Epoch: 5| Step: 4
Training loss: 2.252847882502402
Validation loss: 2.467835220632293

Epoch: 5| Step: 5
Training loss: 2.6545392979055245
Validation loss: 2.463974647834583

Epoch: 5| Step: 6
Training loss: 2.3345868853269054
Validation loss: 2.468906526391914

Epoch: 5| Step: 7
Training loss: 2.594113979309021
Validation loss: 2.468583797542057

Epoch: 5| Step: 8
Training loss: 3.247204825691271
Validation loss: 2.4700375993726604

Epoch: 5| Step: 9
Training loss: 2.123652086790579
Validation loss: 2.467190056498135

Epoch: 5| Step: 10
Training loss: 2.4408971148807868
Validation loss: 2.4683175130663826

Epoch: 5| Step: 11
Training loss: 3.641144547616612
Validation loss: 2.4634554500426713

Epoch: 143| Step: 0
Training loss: 2.598263134728902
Validation loss: 2.465084872212929

Epoch: 5| Step: 1
Training loss: 2.3771578372264552
Validation loss: 2.464575304022055

Epoch: 5| Step: 2
Training loss: 2.8210994224945565
Validation loss: 2.467072798398222

Epoch: 5| Step: 3
Training loss: 2.772624065763783
Validation loss: 2.474123828104216

Epoch: 5| Step: 4
Training loss: 2.2988596535645907
Validation loss: 2.474296756819983

Epoch: 5| Step: 5
Training loss: 2.6349675897852616
Validation loss: 2.4621451265778704

Epoch: 5| Step: 6
Training loss: 2.4812924436691297
Validation loss: 2.4683618039127615

Epoch: 5| Step: 7
Training loss: 2.7726781530904376
Validation loss: 2.4751174995197367

Epoch: 5| Step: 8
Training loss: 1.9971681454299222
Validation loss: 2.468665829764817

Epoch: 5| Step: 9
Training loss: 2.1948027646858845
Validation loss: 2.4603558655304725

Epoch: 5| Step: 10
Training loss: 2.6365487503067606
Validation loss: 2.4546462867590724

Epoch: 5| Step: 11
Training loss: 2.3460954247569363
Validation loss: 2.4605307146966786

Epoch: 144| Step: 0
Training loss: 2.860877804260973
Validation loss: 2.4590543333509323

Epoch: 5| Step: 1
Training loss: 2.429005812416959
Validation loss: 2.465053628005427

Epoch: 5| Step: 2
Training loss: 2.0461374366294205
Validation loss: 2.460985867463989

Epoch: 5| Step: 3
Training loss: 3.118847244978857
Validation loss: 2.4447463033135683

Epoch: 5| Step: 4
Training loss: 2.3801670084787605
Validation loss: 2.4636926819778697

Epoch: 5| Step: 5
Training loss: 2.1626800638545105
Validation loss: 2.4620272408516706

Epoch: 5| Step: 6
Training loss: 3.0327467221924813
Validation loss: 2.4573486964027884

Epoch: 5| Step: 7
Training loss: 2.2309424436797376
Validation loss: 2.4616048685033665

Epoch: 5| Step: 8
Training loss: 2.7272778641045483
Validation loss: 2.4624153664853683

Epoch: 5| Step: 9
Training loss: 2.1783861219941203
Validation loss: 2.46048747393355

Epoch: 5| Step: 10
Training loss: 2.1768644913434265
Validation loss: 2.4705437248185853

Epoch: 5| Step: 11
Training loss: 2.579374808035775
Validation loss: 2.463760113591339

Epoch: 145| Step: 0
Training loss: 2.123529037287833
Validation loss: 2.4579513961628483

Epoch: 5| Step: 1
Training loss: 3.090616353855054
Validation loss: 2.4661139808754196

Epoch: 5| Step: 2
Training loss: 2.617069708607452
Validation loss: 2.4639229563417775

Epoch: 5| Step: 3
Training loss: 2.6286012379069645
Validation loss: 2.465144204086523

Epoch: 5| Step: 4
Training loss: 2.4277163049910775
Validation loss: 2.472802602284616

Epoch: 5| Step: 5
Training loss: 2.4554781955752145
Validation loss: 2.4704481191804915

Epoch: 5| Step: 6
Training loss: 2.3157418699026064
Validation loss: 2.459923215271213

Epoch: 5| Step: 7
Training loss: 2.570413604881263
Validation loss: 2.464624313525426

Epoch: 5| Step: 8
Training loss: 2.3425294877092484
Validation loss: 2.469638644406191

Epoch: 5| Step: 9
Training loss: 1.8475785027370948
Validation loss: 2.4682395383175946

Epoch: 5| Step: 10
Training loss: 2.7149240166304214
Validation loss: 2.4624264325288605

Epoch: 5| Step: 11
Training loss: 3.67461731144334
Validation loss: 2.4624669645646344

Epoch: 146| Step: 0
Training loss: 2.3438905800938397
Validation loss: 2.464598295360389

Epoch: 5| Step: 1
Training loss: 2.6327413215410855
Validation loss: 2.4683563747549764

Epoch: 5| Step: 2
Training loss: 2.1880472860997533
Validation loss: 2.4772889789552495

Epoch: 5| Step: 3
Training loss: 2.3692281758735327
Validation loss: 2.4729954997552754

Epoch: 5| Step: 4
Training loss: 2.1759968895609445
Validation loss: 2.4806007610446184

Epoch: 5| Step: 5
Training loss: 2.7954496022735444
Validation loss: 2.4791105301429153

Epoch: 5| Step: 6
Training loss: 2.8225780908072027
Validation loss: 2.486158746272475

Epoch: 5| Step: 7
Training loss: 2.573506790831066
Validation loss: 2.4809840790905193

Epoch: 5| Step: 8
Training loss: 2.7216323832003226
Validation loss: 2.487037827097867

Epoch: 5| Step: 9
Training loss: 2.5010596890470786
Validation loss: 2.47969602628643

Epoch: 5| Step: 10
Training loss: 2.640141279168315
Validation loss: 2.4778079281836654

Epoch: 5| Step: 11
Training loss: 2.020983293874814
Validation loss: 2.4877403865170105

Epoch: 147| Step: 0
Training loss: 2.1694579362415816
Validation loss: 2.4808149681868055

Epoch: 5| Step: 1
Training loss: 2.0470341045481155
Validation loss: 2.4719936533669498

Epoch: 5| Step: 2
Training loss: 2.6919112264667975
Validation loss: 2.4755148130654403

Epoch: 5| Step: 3
Training loss: 2.3995515801811194
Validation loss: 2.467575765768339

Epoch: 5| Step: 4
Training loss: 2.7941699026081275
Validation loss: 2.4690383710520285

Epoch: 5| Step: 5
Training loss: 2.2838211202169862
Validation loss: 2.4740405032248227

Epoch: 5| Step: 6
Training loss: 2.3046857413592337
Validation loss: 2.4779774186941474

Epoch: 5| Step: 7
Training loss: 2.700133945533447
Validation loss: 2.4739456109506173

Epoch: 5| Step: 8
Training loss: 2.5782689834616406
Validation loss: 2.485889041443517

Epoch: 5| Step: 9
Training loss: 2.606223939175291
Validation loss: 2.4782091116049974

Epoch: 5| Step: 10
Training loss: 3.1028043245116983
Validation loss: 2.4786740275718815

Epoch: 5| Step: 11
Training loss: 2.5179419421107254
Validation loss: 2.473875696240974

Epoch: 148| Step: 0
Training loss: 2.3446627047739117
Validation loss: 2.479683100314485

Epoch: 5| Step: 1
Training loss: 2.5400639363749886
Validation loss: 2.4689300326603387

Epoch: 5| Step: 2
Training loss: 2.498062336555454
Validation loss: 2.4661844821843375

Epoch: 5| Step: 3
Training loss: 2.4472302604001555
Validation loss: 2.463232796617224

Epoch: 5| Step: 4
Training loss: 2.7769655809862277
Validation loss: 2.4685325888981575

Epoch: 5| Step: 5
Training loss: 2.879450463212169
Validation loss: 2.465440696980431

Epoch: 5| Step: 6
Training loss: 2.3650980877848915
Validation loss: 2.4654508952277525

Epoch: 5| Step: 7
Training loss: 2.0739909188817593
Validation loss: 2.470423738668194

Epoch: 5| Step: 8
Training loss: 2.8434790178238853
Validation loss: 2.460146103619266

Epoch: 5| Step: 9
Training loss: 2.1499973252745557
Validation loss: 2.4637364571939595

Epoch: 5| Step: 10
Training loss: 2.5752603047472755
Validation loss: 2.460289263246298

Epoch: 5| Step: 11
Training loss: 3.179557328992451
Validation loss: 2.4653815213315284

Epoch: 149| Step: 0
Training loss: 2.8686805600341034
Validation loss: 2.4647772327119015

Epoch: 5| Step: 1
Training loss: 2.426694934421823
Validation loss: 2.4735052168977276

Epoch: 5| Step: 2
Training loss: 2.6114841548666123
Validation loss: 2.4781842141695463

Epoch: 5| Step: 3
Training loss: 2.3022524626270604
Validation loss: 2.4797993795582665

Epoch: 5| Step: 4
Training loss: 2.449372355193715
Validation loss: 2.4874628778304295

Epoch: 5| Step: 5
Training loss: 2.5120708877256024
Validation loss: 2.4893676565963694

Epoch: 5| Step: 6
Training loss: 2.1715447703082535
Validation loss: 2.4781572199519193

Epoch: 5| Step: 7
Training loss: 2.529396226028953
Validation loss: 2.475124485163708

Epoch: 5| Step: 8
Training loss: 2.695757577608997
Validation loss: 2.481304242256259

Epoch: 5| Step: 9
Training loss: 2.395415747918761
Validation loss: 2.475116423877316

Epoch: 5| Step: 10
Training loss: 2.9922330768191743
Validation loss: 2.478775810370869

Epoch: 5| Step: 11
Training loss: 2.175433749214832
Validation loss: 2.476338194868865

Epoch: 150| Step: 0
Training loss: 2.751834344297158
Validation loss: 2.4637284171121787

Epoch: 5| Step: 1
Training loss: 2.4558357763089482
Validation loss: 2.4596485536761996

Epoch: 5| Step: 2
Training loss: 2.5622647805533414
Validation loss: 2.46049692156012

Epoch: 5| Step: 3
Training loss: 2.5599426906846654
Validation loss: 2.4607829615596915

Epoch: 5| Step: 4
Training loss: 2.198367996038948
Validation loss: 2.4598215873110947

Epoch: 5| Step: 5
Training loss: 3.696255908247941
Validation loss: 2.460115285293912

Epoch: 5| Step: 6
Training loss: 1.8178365347028964
Validation loss: 2.465960481896171

Epoch: 5| Step: 7
Training loss: 2.2101948168057186
Validation loss: 2.463831250763642

Epoch: 5| Step: 8
Training loss: 2.5366211407453076
Validation loss: 2.462887567593368

Epoch: 5| Step: 9
Training loss: 2.507568727808396
Validation loss: 2.466460421731252

Epoch: 5| Step: 10
Training loss: 2.109845822382781
Validation loss: 2.4580969871983

Epoch: 5| Step: 11
Training loss: 1.8291093181521039
Validation loss: 2.4580790211715953

Epoch: 151| Step: 0
Training loss: 2.445943440217729
Validation loss: 2.4658737730771327

Epoch: 5| Step: 1
Training loss: 2.4008996111923717
Validation loss: 2.4600858950657534

Epoch: 5| Step: 2
Training loss: 2.5869406053989366
Validation loss: 2.458918297132059

Epoch: 5| Step: 3
Training loss: 1.8089162979710216
Validation loss: 2.4619256876401554

Epoch: 5| Step: 4
Training loss: 2.889906015418858
Validation loss: 2.4628582961612437

Epoch: 5| Step: 5
Training loss: 1.8653756133126258
Validation loss: 2.4589168346402084

Epoch: 5| Step: 6
Training loss: 2.356574411092739
Validation loss: 2.4580233723336513

Epoch: 5| Step: 7
Training loss: 2.8112304365224534
Validation loss: 2.463370852903038

Epoch: 5| Step: 8
Training loss: 2.9323890538866926
Validation loss: 2.4636207040980937

Epoch: 5| Step: 9
Training loss: 2.6431052393432797
Validation loss: 2.465393923917332

Epoch: 5| Step: 10
Training loss: 2.723369488548108
Validation loss: 2.469464882627923

Epoch: 5| Step: 11
Training loss: 1.7048429171784178
Validation loss: 2.464081418116581

Epoch: 152| Step: 0
Training loss: 2.9202762248407454
Validation loss: 2.4630952609400496

Epoch: 5| Step: 1
Training loss: 2.5398103052927667
Validation loss: 2.4678672024970907

Epoch: 5| Step: 2
Training loss: 2.540330775492352
Validation loss: 2.4678500301590343

Epoch: 5| Step: 3
Training loss: 2.0651125689251817
Validation loss: 2.4644398244951455

Epoch: 5| Step: 4
Training loss: 2.1985306688207933
Validation loss: 2.469417944415403

Epoch: 5| Step: 5
Training loss: 2.336642768055612
Validation loss: 2.4676833202360573

Epoch: 5| Step: 6
Training loss: 2.3201326756522773
Validation loss: 2.4549548700591006

Epoch: 5| Step: 7
Training loss: 2.389081469124333
Validation loss: 2.4614704786128287

Epoch: 5| Step: 8
Training loss: 2.6892994024355006
Validation loss: 2.4639844973580134

Epoch: 5| Step: 9
Training loss: 2.711889446120722
Validation loss: 2.459431145853985

Epoch: 5| Step: 10
Training loss: 2.700419223876207
Validation loss: 2.459785151261512

Epoch: 5| Step: 11
Training loss: 2.648184705164278
Validation loss: 2.4649455336136734

Epoch: 153| Step: 0
Training loss: 2.3292436408447115
Validation loss: 2.4626872164984235

Epoch: 5| Step: 1
Training loss: 2.362329111528865
Validation loss: 2.459994495703579

Epoch: 5| Step: 2
Training loss: 2.3844768777383334
Validation loss: 2.4625943535351227

Epoch: 5| Step: 3
Training loss: 2.110871751779278
Validation loss: 2.4684078888920626

Epoch: 5| Step: 4
Training loss: 2.2252349643728593
Validation loss: 2.4542463295080066

Epoch: 5| Step: 5
Training loss: 2.8288499103320324
Validation loss: 2.4635059496580167

Epoch: 5| Step: 6
Training loss: 2.3142660459728845
Validation loss: 2.4621357054494997

Epoch: 5| Step: 7
Training loss: 2.6645169136253584
Validation loss: 2.4551395842538186

Epoch: 5| Step: 8
Training loss: 2.364062572612875
Validation loss: 2.463080636584603

Epoch: 5| Step: 9
Training loss: 2.5611585501881096
Validation loss: 2.4608921087206412

Epoch: 5| Step: 10
Training loss: 3.0275374812003966
Validation loss: 2.4604129333101694

Epoch: 5| Step: 11
Training loss: 3.046874530498762
Validation loss: 2.4652658817440036

Epoch: 154| Step: 0
Training loss: 2.8880220808204773
Validation loss: 2.4630049765427255

Epoch: 5| Step: 1
Training loss: 2.87042353066971
Validation loss: 2.451435738555019

Epoch: 5| Step: 2
Training loss: 2.453004481762891
Validation loss: 2.463338784432047

Epoch: 5| Step: 3
Training loss: 1.885073874768886
Validation loss: 2.4692442354997093

Epoch: 5| Step: 4
Training loss: 2.1804553357828715
Validation loss: 2.4634376904493465

Epoch: 5| Step: 5
Training loss: 2.460085766855628
Validation loss: 2.4687453000309625

Epoch: 5| Step: 6
Training loss: 2.306099772535584
Validation loss: 2.46678869991604

Epoch: 5| Step: 7
Training loss: 2.3585998070087224
Validation loss: 2.476220188490971

Epoch: 5| Step: 8
Training loss: 2.072041376260451
Validation loss: 2.4655348005020996

Epoch: 5| Step: 9
Training loss: 2.6917915677439153
Validation loss: 2.46646545229548

Epoch: 5| Step: 10
Training loss: 2.8480165774259407
Validation loss: 2.468270935383489

Epoch: 5| Step: 11
Training loss: 2.732367252570101
Validation loss: 2.456723572470059

Epoch: 155| Step: 0
Training loss: 2.575456845395375
Validation loss: 2.457466066798201

Epoch: 5| Step: 1
Training loss: 2.3409123854180476
Validation loss: 2.4634651887298884

Epoch: 5| Step: 2
Training loss: 2.3571289689616814
Validation loss: 2.4603283203849

Epoch: 5| Step: 3
Training loss: 2.792983517907854
Validation loss: 2.4662759270572425

Epoch: 5| Step: 4
Training loss: 2.2874608604543054
Validation loss: 2.464804196128526

Epoch: 5| Step: 5
Training loss: 2.3458688948958324
Validation loss: 2.4567849662999115

Epoch: 5| Step: 6
Training loss: 2.451591255208989
Validation loss: 2.468645832020936

Epoch: 5| Step: 7
Training loss: 2.316877294703403
Validation loss: 2.4559066495273547

Epoch: 5| Step: 8
Training loss: 2.6052335664446633
Validation loss: 2.4619953808386077

Epoch: 5| Step: 9
Training loss: 2.289168111298222
Validation loss: 2.4651364748640487

Epoch: 5| Step: 10
Training loss: 2.9294729739165075
Validation loss: 2.470438508550407

Epoch: 5| Step: 11
Training loss: 2.4939045028819025
Validation loss: 2.4726848389718956

Epoch: 156| Step: 0
Training loss: 2.10138256337901
Validation loss: 2.470704837843712

Epoch: 5| Step: 1
Training loss: 3.101534211536612
Validation loss: 2.4632457464022615

Epoch: 5| Step: 2
Training loss: 2.212077894732851
Validation loss: 2.467810894815574

Epoch: 5| Step: 3
Training loss: 2.6771797034189158
Validation loss: 2.4641006647386536

Epoch: 5| Step: 4
Training loss: 2.705270081467668
Validation loss: 2.469745334741443

Epoch: 5| Step: 5
Training loss: 2.242686571676224
Validation loss: 2.47506014465054

Epoch: 5| Step: 6
Training loss: 2.2770802261968868
Validation loss: 2.4723926703014487

Epoch: 5| Step: 7
Training loss: 2.63316981214325
Validation loss: 2.4817905398557456

Epoch: 5| Step: 8
Training loss: 2.317200497200463
Validation loss: 2.487990577444048

Epoch: 5| Step: 9
Training loss: 2.481468756038412
Validation loss: 2.4950612280257047

Epoch: 5| Step: 10
Training loss: 2.5255389365466985
Validation loss: 2.477631154827889

Epoch: 5| Step: 11
Training loss: 2.5990796771163573
Validation loss: 2.477612289972456

Epoch: 157| Step: 0
Training loss: 2.8632612657044754
Validation loss: 2.4677433021636666

Epoch: 5| Step: 1
Training loss: 2.5733527201414734
Validation loss: 2.458389234446066

Epoch: 5| Step: 2
Training loss: 2.613339456272089
Validation loss: 2.46773640632898

Epoch: 5| Step: 3
Training loss: 2.1246232091415065
Validation loss: 2.4705667530968203

Epoch: 5| Step: 4
Training loss: 2.0628687211101604
Validation loss: 2.471955885691048

Epoch: 5| Step: 5
Training loss: 2.6790186100021844
Validation loss: 2.465187750024703

Epoch: 5| Step: 6
Training loss: 2.2783223007854057
Validation loss: 2.470966390422594

Epoch: 5| Step: 7
Training loss: 2.051519700567759
Validation loss: 2.4715329753047803

Epoch: 5| Step: 8
Training loss: 2.778545050087803
Validation loss: 2.457656172388327

Epoch: 5| Step: 9
Training loss: 2.391454016860517
Validation loss: 2.462667851931926

Epoch: 5| Step: 10
Training loss: 2.556067044675754
Validation loss: 2.4719645219129838

Epoch: 5| Step: 11
Training loss: 3.36346201128465
Validation loss: 2.4631542838110354

Epoch: 158| Step: 0
Training loss: 2.7990484051159474
Validation loss: 2.459807197922612

Epoch: 5| Step: 1
Training loss: 2.267233021421771
Validation loss: 2.4647577616367564

Epoch: 5| Step: 2
Training loss: 2.6982404202853423
Validation loss: 2.4638574383059324

Epoch: 5| Step: 3
Training loss: 2.4167863114654686
Validation loss: 2.4655875138276464

Epoch: 5| Step: 4
Training loss: 2.4175259827220534
Validation loss: 2.4672636112571196

Epoch: 5| Step: 5
Training loss: 3.260026869867907
Validation loss: 2.4689890448008027

Epoch: 5| Step: 6
Training loss: 2.2960381053660073
Validation loss: 2.478979605875662

Epoch: 5| Step: 7
Training loss: 1.9959683910802617
Validation loss: 2.467580494132995

Epoch: 5| Step: 8
Training loss: 2.729032430672071
Validation loss: 2.4691360710965853

Epoch: 5| Step: 9
Training loss: 1.9621595852818403
Validation loss: 2.4639084820456345

Epoch: 5| Step: 10
Training loss: 2.5041848442784658
Validation loss: 2.458434576977795

Epoch: 5| Step: 11
Training loss: 2.5907984106099313
Validation loss: 2.4643541183251307

Epoch: 159| Step: 0
Training loss: 2.718358241828017
Validation loss: 2.458644747541032

Epoch: 5| Step: 1
Training loss: 2.6420764432788286
Validation loss: 2.4697069293260316

Epoch: 5| Step: 2
Training loss: 2.385525119320622
Validation loss: 2.463820360373503

Epoch: 5| Step: 3
Training loss: 2.9662069571708165
Validation loss: 2.4692194085974295

Epoch: 5| Step: 4
Training loss: 2.2216553269612245
Validation loss: 2.4690672071095237

Epoch: 5| Step: 5
Training loss: 2.388188036296599
Validation loss: 2.4738074219836927

Epoch: 5| Step: 6
Training loss: 2.3245622653511315
Validation loss: 2.477611548205811

Epoch: 5| Step: 7
Training loss: 2.0713742394674117
Validation loss: 2.477089365563348

Epoch: 5| Step: 8
Training loss: 2.42184773091377
Validation loss: 2.4728688916479276

Epoch: 5| Step: 9
Training loss: 2.595818671301943
Validation loss: 2.479884902445676

Epoch: 5| Step: 10
Training loss: 2.8180532943526835
Validation loss: 2.4745754328936305

Epoch: 5| Step: 11
Training loss: 1.8558836141877002
Validation loss: 2.4660201733863105

Epoch: 160| Step: 0
Training loss: 2.6846667591919404
Validation loss: 2.4742507172858086

Epoch: 5| Step: 1
Training loss: 2.492289956596681
Validation loss: 2.4667793005495713

Epoch: 5| Step: 2
Training loss: 2.446197057276822
Validation loss: 2.462264551889772

Epoch: 5| Step: 3
Training loss: 3.0993496858763447
Validation loss: 2.4585171822050995

Epoch: 5| Step: 4
Training loss: 2.363506413602187
Validation loss: 2.464320385681119

Epoch: 5| Step: 5
Training loss: 2.29717154113183
Validation loss: 2.4668134546314224

Epoch: 5| Step: 6
Training loss: 2.594608762204092
Validation loss: 2.463142521294256

Epoch: 5| Step: 7
Training loss: 2.4032071182645884
Validation loss: 2.4653983119517533

Epoch: 5| Step: 8
Training loss: 2.446073955893193
Validation loss: 2.465467963397162

Epoch: 5| Step: 9
Training loss: 2.593810023337158
Validation loss: 2.4582038107118933

Epoch: 5| Step: 10
Training loss: 2.2306991965838083
Validation loss: 2.4613331027682634

Epoch: 5| Step: 11
Training loss: 1.4953926375867663
Validation loss: 2.454280237043022

Epoch: 161| Step: 0
Training loss: 2.258078483569108
Validation loss: 2.460735538813905

Epoch: 5| Step: 1
Training loss: 3.0187865766437856
Validation loss: 2.4632601802306735

Epoch: 5| Step: 2
Training loss: 2.1335930705898773
Validation loss: 2.4626611819017303

Epoch: 5| Step: 3
Training loss: 2.4082039170213623
Validation loss: 2.464946275161701

Epoch: 5| Step: 4
Training loss: 2.170774551542718
Validation loss: 2.463954329792345

Epoch: 5| Step: 5
Training loss: 2.565690636114686
Validation loss: 2.4712064810796006

Epoch: 5| Step: 6
Training loss: 3.1192528328870095
Validation loss: 2.469297682294264

Epoch: 5| Step: 7
Training loss: 2.944954524053415
Validation loss: 2.4760533921655945

Epoch: 5| Step: 8
Training loss: 2.4071093919569613
Validation loss: 2.4655428427516566

Epoch: 5| Step: 9
Training loss: 2.073614862326059
Validation loss: 2.469137599955084

Epoch: 5| Step: 10
Training loss: 2.407416618226301
Validation loss: 2.4650713396872135

Epoch: 5| Step: 11
Training loss: 1.780456031395686
Validation loss: 2.465299436238268

Epoch: 162| Step: 0
Training loss: 1.8020484421132463
Validation loss: 2.464290845051486

Epoch: 5| Step: 1
Training loss: 2.5304044088184736
Validation loss: 2.4655484997090755

Epoch: 5| Step: 2
Training loss: 2.815776611717184
Validation loss: 2.481368767164376

Epoch: 5| Step: 3
Training loss: 2.7545015597973483
Validation loss: 2.4868594348839324

Epoch: 5| Step: 4
Training loss: 2.737662208663424
Validation loss: 2.483457931863961

Epoch: 5| Step: 5
Training loss: 2.6600277235264294
Validation loss: 2.4908344099396205

Epoch: 5| Step: 6
Training loss: 2.4221716914413447
Validation loss: 2.4838700731061043

Epoch: 5| Step: 7
Training loss: 2.6281936836112783
Validation loss: 2.4710067180527813

Epoch: 5| Step: 8
Training loss: 2.5306265734373
Validation loss: 2.4681653646345088

Epoch: 5| Step: 9
Training loss: 2.080426426054835
Validation loss: 2.4665615083267243

Epoch: 5| Step: 10
Training loss: 2.6583100352766125
Validation loss: 2.463977691797113

Epoch: 5| Step: 11
Training loss: 2.4009887843952433
Validation loss: 2.459325979278236

Epoch: 163| Step: 0
Training loss: 2.262813323017756
Validation loss: 2.4637217277763983

Epoch: 5| Step: 1
Training loss: 2.839492797154586
Validation loss: 2.461250107705298

Epoch: 5| Step: 2
Training loss: 2.9734987526225978
Validation loss: 2.469849824374844

Epoch: 5| Step: 3
Training loss: 2.7929305067311803
Validation loss: 2.470520901399657

Epoch: 5| Step: 4
Training loss: 2.6918876671387864
Validation loss: 2.4730622981145935

Epoch: 5| Step: 5
Training loss: 2.602397612830544
Validation loss: 2.468911757179667

Epoch: 5| Step: 6
Training loss: 2.2640491135058665
Validation loss: 2.4623551539117003

Epoch: 5| Step: 7
Training loss: 2.557479592518756
Validation loss: 2.4628814729363704

Epoch: 5| Step: 8
Training loss: 1.893904749524539
Validation loss: 2.462269970272469

Epoch: 5| Step: 9
Training loss: 1.972768708602144
Validation loss: 2.462321982912145

Epoch: 5| Step: 10
Training loss: 2.237036553661883
Validation loss: 2.4571665861522223

Epoch: 5| Step: 11
Training loss: 2.280522687796204
Validation loss: 2.4645514377863638

Epoch: 164| Step: 0
Training loss: 2.2224806463130524
Validation loss: 2.4764876529843556

Epoch: 5| Step: 1
Training loss: 2.419271829780781
Validation loss: 2.4610642375302305

Epoch: 5| Step: 2
Training loss: 2.472996692814141
Validation loss: 2.462492291201226

Epoch: 5| Step: 3
Training loss: 2.3443343387780415
Validation loss: 2.478826841470478

Epoch: 5| Step: 4
Training loss: 2.6928490036916943
Validation loss: 2.4816877999013287

Epoch: 5| Step: 5
Training loss: 2.349368164669565
Validation loss: 2.476013515848935

Epoch: 5| Step: 6
Training loss: 2.4677265798318984
Validation loss: 2.4909720890156324

Epoch: 5| Step: 7
Training loss: 2.62245036235486
Validation loss: 2.480515971697974

Epoch: 5| Step: 8
Training loss: 2.9806525697430946
Validation loss: 2.49144914107088

Epoch: 5| Step: 9
Training loss: 2.7257579064456148
Validation loss: 2.4830536837433907

Epoch: 5| Step: 10
Training loss: 1.9907912803201409
Validation loss: 2.474890865784045

Epoch: 5| Step: 11
Training loss: 2.417967665368547
Validation loss: 2.485125192501911

Epoch: 165| Step: 0
Training loss: 2.244547064274366
Validation loss: 2.4838017816046185

Epoch: 5| Step: 1
Training loss: 2.367872686649488
Validation loss: 2.4733997530857312

Epoch: 5| Step: 2
Training loss: 2.952164751185077
Validation loss: 2.472579723859329

Epoch: 5| Step: 3
Training loss: 2.012017622292248
Validation loss: 2.4772128585968214

Epoch: 5| Step: 4
Training loss: 2.1320661978759583
Validation loss: 2.4794940104608694

Epoch: 5| Step: 5
Training loss: 2.459065333723616
Validation loss: 2.474439635724145

Epoch: 5| Step: 6
Training loss: 2.7463974330326733
Validation loss: 2.476957055079566

Epoch: 5| Step: 7
Training loss: 2.3964817883416156
Validation loss: 2.480712191833131

Epoch: 5| Step: 8
Training loss: 2.6340006063369366
Validation loss: 2.4710562191080054

Epoch: 5| Step: 9
Training loss: 2.2270986881803263
Validation loss: 2.484279070907483

Epoch: 5| Step: 10
Training loss: 2.348540331631658
Validation loss: 2.478466729858456

Epoch: 5| Step: 11
Training loss: 3.751723974042438
Validation loss: 2.4813732510566746

Epoch: 166| Step: 0
Training loss: 2.458478880199793
Validation loss: 2.482395979343291

Epoch: 5| Step: 1
Training loss: 2.5460882551444715
Validation loss: 2.4852699631121773

Epoch: 5| Step: 2
Training loss: 2.3179493182338207
Validation loss: 2.486914586265599

Epoch: 5| Step: 3
Training loss: 3.0421006576768606
Validation loss: 2.468108608931693

Epoch: 5| Step: 4
Training loss: 2.547929510384162
Validation loss: 2.4726600425976377

Epoch: 5| Step: 5
Training loss: 2.928292636693485
Validation loss: 2.466168119872975

Epoch: 5| Step: 6
Training loss: 2.2102541457198708
Validation loss: 2.4638932980547303

Epoch: 5| Step: 7
Training loss: 2.0903609446909774
Validation loss: 2.464695998094516

Epoch: 5| Step: 8
Training loss: 2.1518281571793287
Validation loss: 2.4729011137188572

Epoch: 5| Step: 9
Training loss: 2.4893819389658383
Validation loss: 2.460641584820901

Epoch: 5| Step: 10
Training loss: 2.473533535006896
Validation loss: 2.4691352221773784

Epoch: 5| Step: 11
Training loss: 1.3689021666088927
Validation loss: 2.4639929800924403

Epoch: 167| Step: 0
Training loss: 2.8291531374743153
Validation loss: 2.4653172710699893

Epoch: 5| Step: 1
Training loss: 2.438132570788401
Validation loss: 2.466037406807062

Epoch: 5| Step: 2
Training loss: 2.026835295140962
Validation loss: 2.4624124779291923

Epoch: 5| Step: 3
Training loss: 2.6740997154229125
Validation loss: 2.4587823341918553

Epoch: 5| Step: 4
Training loss: 2.579974441697439
Validation loss: 2.469234793179481

Epoch: 5| Step: 5
Training loss: 2.336571444731149
Validation loss: 2.4691085555050853

Epoch: 5| Step: 6
Training loss: 2.1575284844172455
Validation loss: 2.473425777067742

Epoch: 5| Step: 7
Training loss: 2.237557978385034
Validation loss: 2.472839931196246

Epoch: 5| Step: 8
Training loss: 2.0878549970650573
Validation loss: 2.458257242954084

Epoch: 5| Step: 9
Training loss: 2.460860187587666
Validation loss: 2.4630150114428795

Epoch: 5| Step: 10
Training loss: 2.93580513615692
Validation loss: 2.4666983855845768

Epoch: 5| Step: 11
Training loss: 3.548039451052937
Validation loss: 2.472017873725397

Epoch: 168| Step: 0
Training loss: 2.7668214785300433
Validation loss: 2.4671639687541584

Epoch: 5| Step: 1
Training loss: 1.8819730161380315
Validation loss: 2.4733291863321445

Epoch: 5| Step: 2
Training loss: 3.02300691125946
Validation loss: 2.471861363504752

Epoch: 5| Step: 3
Training loss: 2.2042254141446342
Validation loss: 2.4768373715904026

Epoch: 5| Step: 4
Training loss: 2.441395507788867
Validation loss: 2.47304671641078

Epoch: 5| Step: 5
Training loss: 2.3115791343099734
Validation loss: 2.467915736046952

Epoch: 5| Step: 6
Training loss: 2.1170224058526927
Validation loss: 2.482402998529593

Epoch: 5| Step: 7
Training loss: 2.405603297138904
Validation loss: 2.4616517539165597

Epoch: 5| Step: 8
Training loss: 2.256552057309428
Validation loss: 2.4729296114828347

Epoch: 5| Step: 9
Training loss: 2.8430614266590926
Validation loss: 2.4671399262318814

Epoch: 5| Step: 10
Training loss: 2.6684696738178326
Validation loss: 2.475827399823134

Epoch: 5| Step: 11
Training loss: 2.220265475371792
Validation loss: 2.4682034881494612

Epoch: 169| Step: 0
Training loss: 2.4949019904753045
Validation loss: 2.4761220417984915

Epoch: 5| Step: 1
Training loss: 2.1861378379565664
Validation loss: 2.473240418252636

Epoch: 5| Step: 2
Training loss: 2.441709746760814
Validation loss: 2.470302492009254

Epoch: 5| Step: 3
Training loss: 2.7144086530278235
Validation loss: 2.471845798344057

Epoch: 5| Step: 4
Training loss: 2.080580558451193
Validation loss: 2.4717702860300226

Epoch: 5| Step: 5
Training loss: 2.6043443441177354
Validation loss: 2.476513425900384

Epoch: 5| Step: 6
Training loss: 2.3487832510940887
Validation loss: 2.470973357649679

Epoch: 5| Step: 7
Training loss: 2.3911588982687912
Validation loss: 2.478083240899605

Epoch: 5| Step: 8
Training loss: 2.503088950136883
Validation loss: 2.4838559550170047

Epoch: 5| Step: 9
Training loss: 3.0249599990091554
Validation loss: 2.4852746298323907

Epoch: 5| Step: 10
Training loss: 2.510284251497314
Validation loss: 2.4754181312805406

Epoch: 5| Step: 11
Training loss: 2.2301376818590386
Validation loss: 2.499947412255642

Epoch: 170| Step: 0
Training loss: 2.8034394869246144
Validation loss: 2.496372921673775

Epoch: 5| Step: 1
Training loss: 2.012135997574616
Validation loss: 2.4749331364125124

Epoch: 5| Step: 2
Training loss: 2.183082916614252
Validation loss: 2.4812330335073827

Epoch: 5| Step: 3
Training loss: 2.2657310724091837
Validation loss: 2.479381328927596

Epoch: 5| Step: 4
Training loss: 2.673462424058963
Validation loss: 2.4721228700728846

Epoch: 5| Step: 5
Training loss: 2.8165563366140143
Validation loss: 2.4832218340883565

Epoch: 5| Step: 6
Training loss: 2.1707322661534243
Validation loss: 2.482339805128788

Epoch: 5| Step: 7
Training loss: 1.9743627437586693
Validation loss: 2.485195312384877

Epoch: 5| Step: 8
Training loss: 2.5585554513176065
Validation loss: 2.487160734302699

Epoch: 5| Step: 9
Training loss: 2.6661499436745415
Validation loss: 2.4880036938349583

Epoch: 5| Step: 10
Training loss: 2.5878839917367817
Validation loss: 2.494230188620211

Epoch: 5| Step: 11
Training loss: 3.806681210500678
Validation loss: 2.480928557623633

Epoch: 171| Step: 0
Training loss: 2.3843800875908205
Validation loss: 2.4822084868903525

Epoch: 5| Step: 1
Training loss: 2.1307396509818166
Validation loss: 2.477839043639813

Epoch: 5| Step: 2
Training loss: 2.7827137727696876
Validation loss: 2.4755736441623646

Epoch: 5| Step: 3
Training loss: 2.3523266333366175
Validation loss: 2.470804027964688

Epoch: 5| Step: 4
Training loss: 2.033588882188397
Validation loss: 2.4839394465502203

Epoch: 5| Step: 5
Training loss: 2.300963830099099
Validation loss: 2.4757467464708256

Epoch: 5| Step: 6
Training loss: 2.812169203908024
Validation loss: 2.471750038097329

Epoch: 5| Step: 7
Training loss: 2.9459758790602617
Validation loss: 2.4710002976775907

Epoch: 5| Step: 8
Training loss: 2.5717175941921275
Validation loss: 2.4717555964486837

Epoch: 5| Step: 9
Training loss: 2.441352636130063
Validation loss: 2.477272325069765

Epoch: 5| Step: 10
Training loss: 2.455606165556648
Validation loss: 2.468644178110326

Epoch: 5| Step: 11
Training loss: 3.3960433770185134
Validation loss: 2.471511202058095

Epoch: 172| Step: 0
Training loss: 2.1688090027799936
Validation loss: 2.472302600867169

Epoch: 5| Step: 1
Training loss: 2.553758831559724
Validation loss: 2.4631554594546614

Epoch: 5| Step: 2
Training loss: 2.7450347638317396
Validation loss: 2.480508911128084

Epoch: 5| Step: 3
Training loss: 2.195972818460029
Validation loss: 2.480182256699042

Epoch: 5| Step: 4
Training loss: 2.4534594070997744
Validation loss: 2.4817120417342307

Epoch: 5| Step: 5
Training loss: 2.5005536420042116
Validation loss: 2.4824001652458345

Epoch: 5| Step: 6
Training loss: 2.4168771674020944
Validation loss: 2.4860913288020834

Epoch: 5| Step: 7
Training loss: 2.370954581737514
Validation loss: 2.479012690231713

Epoch: 5| Step: 8
Training loss: 2.262786665822838
Validation loss: 2.4859532075837674

Epoch: 5| Step: 9
Training loss: 3.0877837633707346
Validation loss: 2.4746579328799414

Epoch: 5| Step: 10
Training loss: 2.3406802610181656
Validation loss: 2.4654196758057414

Epoch: 5| Step: 11
Training loss: 2.142259850591439
Validation loss: 2.4686285584594887

Epoch: 173| Step: 0
Training loss: 2.5741300205805464
Validation loss: 2.471040319218268

Epoch: 5| Step: 1
Training loss: 2.1622565821541837
Validation loss: 2.470810185501445

Epoch: 5| Step: 2
Training loss: 2.5926936192987102
Validation loss: 2.4726711230561405

Epoch: 5| Step: 3
Training loss: 2.3191809158719017
Validation loss: 2.478387054242938

Epoch: 5| Step: 4
Training loss: 2.063910955371297
Validation loss: 2.472347925296705

Epoch: 5| Step: 5
Training loss: 2.5462895756128674
Validation loss: 2.4691986931706387

Epoch: 5| Step: 6
Training loss: 2.6682937446467445
Validation loss: 2.472861540088069

Epoch: 5| Step: 7
Training loss: 2.581904005646329
Validation loss: 2.4746352397366875

Epoch: 5| Step: 8
Training loss: 2.6174860086586293
Validation loss: 2.4561085224255415

Epoch: 5| Step: 9
Training loss: 2.442352453361146
Validation loss: 2.476258264220054

Epoch: 5| Step: 10
Training loss: 2.4974497184999636
Validation loss: 2.4660040073774727

Epoch: 5| Step: 11
Training loss: 2.2738639719931935
Validation loss: 2.468850314842535

Epoch: 174| Step: 0
Training loss: 2.0989904156702774
Validation loss: 2.4752611497733796

Epoch: 5| Step: 1
Training loss: 2.3527770090333338
Validation loss: 2.4962204615947012

Epoch: 5| Step: 2
Training loss: 2.7848557661912707
Validation loss: 2.502427055503821

Epoch: 5| Step: 3
Training loss: 2.182678904503545
Validation loss: 2.4887277391205487

Epoch: 5| Step: 4
Training loss: 2.5857247901859695
Validation loss: 2.507253610321883

Epoch: 5| Step: 5
Training loss: 2.708566557794759
Validation loss: 2.4929896053444853

Epoch: 5| Step: 6
Training loss: 1.9660145966307165
Validation loss: 2.4861819775448257

Epoch: 5| Step: 7
Training loss: 2.4750266141134865
Validation loss: 2.493244108595314

Epoch: 5| Step: 8
Training loss: 2.3528657767893235
Validation loss: 2.476170369420755

Epoch: 5| Step: 9
Training loss: 2.8269224191821585
Validation loss: 2.478253494240991

Epoch: 5| Step: 10
Training loss: 2.673838646744729
Validation loss: 2.4857726853884303

Epoch: 5| Step: 11
Training loss: 2.3604641857116975
Validation loss: 2.473591467442432

Epoch: 175| Step: 0
Training loss: 2.9359318220033903
Validation loss: 2.484356890118568

Epoch: 5| Step: 1
Training loss: 2.400387446600825
Validation loss: 2.4776747419179603

Epoch: 5| Step: 2
Training loss: 2.3178584932411086
Validation loss: 2.4837998338194662

Epoch: 5| Step: 3
Training loss: 2.776379896866795
Validation loss: 2.4762217370464263

Epoch: 5| Step: 4
Training loss: 2.08624516764836
Validation loss: 2.486789817325868

Epoch: 5| Step: 5
Training loss: 2.4329182527718456
Validation loss: 2.477913352712217

Epoch: 5| Step: 6
Training loss: 2.527423462355041
Validation loss: 2.4929518289927226

Epoch: 5| Step: 7
Training loss: 2.187553841064524
Validation loss: 2.4850937505380286

Epoch: 5| Step: 8
Training loss: 2.494389723942445
Validation loss: 2.487356188624969

Epoch: 5| Step: 9
Training loss: 2.108345628282887
Validation loss: 2.4932234194590834

Epoch: 5| Step: 10
Training loss: 2.3800403916914443
Validation loss: 2.5008751847289377

Epoch: 5| Step: 11
Training loss: 2.7177160642861686
Validation loss: 2.489873407668235

Epoch: 176| Step: 0
Training loss: 1.7703509926714553
Validation loss: 2.511252680875652

Epoch: 5| Step: 1
Training loss: 2.2635286300665296
Validation loss: 2.4977748743643162

Epoch: 5| Step: 2
Training loss: 3.410627998852648
Validation loss: 2.488248903712054

Epoch: 5| Step: 3
Training loss: 1.9447004588690109
Validation loss: 2.4864562411886126

Epoch: 5| Step: 4
Training loss: 2.7690871814850015
Validation loss: 2.4911877611000106

Epoch: 5| Step: 5
Training loss: 2.5104821751912767
Validation loss: 2.4912004459388974

Epoch: 5| Step: 6
Training loss: 2.2156718218204783
Validation loss: 2.486344628330466

Epoch: 5| Step: 7
Training loss: 2.5512995755557513
Validation loss: 2.49256674851575

Epoch: 5| Step: 8
Training loss: 2.440840364105042
Validation loss: 2.4879833264658475

Epoch: 5| Step: 9
Training loss: 2.4858698156554704
Validation loss: 2.485086161314559

Epoch: 5| Step: 10
Training loss: 2.200757316808596
Validation loss: 2.4922601854652755

Epoch: 5| Step: 11
Training loss: 1.6820067960712968
Validation loss: 2.486653388823564

Epoch: 177| Step: 0
Training loss: 3.1421905714842335
Validation loss: 2.4941900194136744

Epoch: 5| Step: 1
Training loss: 2.2672002117660304
Validation loss: 2.4968052796650753

Epoch: 5| Step: 2
Training loss: 1.7212743081763688
Validation loss: 2.4836986548791797

Epoch: 5| Step: 3
Training loss: 2.7098433955364505
Validation loss: 2.5071424201051644

Epoch: 5| Step: 4
Training loss: 2.413030409936299
Validation loss: 2.5128213767056327

Epoch: 5| Step: 5
Training loss: 2.0165087514583844
Validation loss: 2.5047165089825376

Epoch: 5| Step: 6
Training loss: 1.8450547467097889
Validation loss: 2.493293229913591

Epoch: 5| Step: 7
Training loss: 2.775749339063336
Validation loss: 2.495898864492918

Epoch: 5| Step: 8
Training loss: 2.1408219072871764
Validation loss: 2.487492466760216

Epoch: 5| Step: 9
Training loss: 2.515563016329254
Validation loss: 2.4788190988055727

Epoch: 5| Step: 10
Training loss: 2.7025825970614124
Validation loss: 2.483308955260658

Epoch: 5| Step: 11
Training loss: 3.43303265288881
Validation loss: 2.4799580686623734

Epoch: 178| Step: 0
Training loss: 2.416567197484584
Validation loss: 2.488824402811279

Epoch: 5| Step: 1
Training loss: 2.385501132674579
Validation loss: 2.4839424860434183

Epoch: 5| Step: 2
Training loss: 1.9736140277163008
Validation loss: 2.4857632558974903

Epoch: 5| Step: 3
Training loss: 2.8529403910916313
Validation loss: 2.480158764951191

Epoch: 5| Step: 4
Training loss: 2.3127367053158547
Validation loss: 2.4802611216556674

Epoch: 5| Step: 5
Training loss: 2.351663378202472
Validation loss: 2.4861175615758584

Epoch: 5| Step: 6
Training loss: 2.141969022176014
Validation loss: 2.487198586629139

Epoch: 5| Step: 7
Training loss: 2.397815835016527
Validation loss: 2.4872428607782617

Epoch: 5| Step: 8
Training loss: 2.6730673287899775
Validation loss: 2.484138621475127

Epoch: 5| Step: 9
Training loss: 2.379645973289077
Validation loss: 2.4877747080503663

Epoch: 5| Step: 10
Training loss: 2.847716865888637
Validation loss: 2.4976334616240257

Epoch: 5| Step: 11
Training loss: 2.296907385772957
Validation loss: 2.4870896472990296

Epoch: 179| Step: 0
Training loss: 2.369093627966719
Validation loss: 2.4813746082331924

Epoch: 5| Step: 1
Training loss: 2.29655672320497
Validation loss: 2.5006882236811423

Epoch: 5| Step: 2
Training loss: 1.8199242435660161
Validation loss: 2.4896464712258326

Epoch: 5| Step: 3
Training loss: 2.5936438297465356
Validation loss: 2.4701386521847257

Epoch: 5| Step: 4
Training loss: 2.945547888782714
Validation loss: 2.4834044378030393

Epoch: 5| Step: 5
Training loss: 2.437072129476274
Validation loss: 2.483875312376544

Epoch: 5| Step: 6
Training loss: 2.4037698622114543
Validation loss: 2.487061461573355

Epoch: 5| Step: 7
Training loss: 2.718499709260696
Validation loss: 2.50136895845776

Epoch: 5| Step: 8
Training loss: 2.636811340966881
Validation loss: 2.4918448572382434

Epoch: 5| Step: 9
Training loss: 1.6638971524182868
Validation loss: 2.4929285412602864

Epoch: 5| Step: 10
Training loss: 2.734829238219315
Validation loss: 2.490373706784294

Epoch: 5| Step: 11
Training loss: 2.2535978797187624
Validation loss: 2.4881998085735204

Epoch: 180| Step: 0
Training loss: 2.5188197351083286
Validation loss: 2.4938636492563817

Epoch: 5| Step: 1
Training loss: 1.7578639044133106
Validation loss: 2.4955435570849445

Epoch: 5| Step: 2
Training loss: 2.401286169968204
Validation loss: 2.5013478619293195

Epoch: 5| Step: 3
Training loss: 2.707657382438071
Validation loss: 2.4835179608046736

Epoch: 5| Step: 4
Training loss: 2.0703090451769524
Validation loss: 2.485537842650156

Epoch: 5| Step: 5
Training loss: 2.1309686872239477
Validation loss: 2.483954903934228

Epoch: 5| Step: 6
Training loss: 2.342675331418133
Validation loss: 2.475212583659962

Epoch: 5| Step: 7
Training loss: 2.9874287105976807
Validation loss: 2.483134309796192

Epoch: 5| Step: 8
Training loss: 2.7002753965011537
Validation loss: 2.4801500391020705

Epoch: 5| Step: 9
Training loss: 2.26858621641887
Validation loss: 2.4978591176313807

Epoch: 5| Step: 10
Training loss: 2.761844443303045
Validation loss: 2.489445735741457

Epoch: 5| Step: 11
Training loss: 2.1744216149912625
Validation loss: 2.503422107597627

Epoch: 181| Step: 0
Training loss: 2.4011700996478003
Validation loss: 2.5132889968551884

Epoch: 5| Step: 1
Training loss: 2.0805085932217935
Validation loss: 2.5107075231219835

Epoch: 5| Step: 2
Training loss: 2.573357167290059
Validation loss: 2.5259310799738564

Epoch: 5| Step: 3
Training loss: 2.739649889080718
Validation loss: 2.526168726973241

Epoch: 5| Step: 4
Training loss: 2.06073546789493
Validation loss: 2.517023475775945

Epoch: 5| Step: 5
Training loss: 2.5739868244820956
Validation loss: 2.497290907728388

Epoch: 5| Step: 6
Training loss: 2.2887294904622246
Validation loss: 2.4869082668776876

Epoch: 5| Step: 7
Training loss: 2.0608597215114006
Validation loss: 2.4801704207311337

Epoch: 5| Step: 8
Training loss: 3.124878079897069
Validation loss: 2.4825689320759654

Epoch: 5| Step: 9
Training loss: 2.4073977024610915
Validation loss: 2.4766315125678338

Epoch: 5| Step: 10
Training loss: 2.6574467375362008
Validation loss: 2.4859042149650574

Epoch: 5| Step: 11
Training loss: 2.3483433788979036
Validation loss: 2.487319125495646

Epoch: 182| Step: 0
Training loss: 2.4865038885304407
Validation loss: 2.4940276213686468

Epoch: 5| Step: 1
Training loss: 2.049496435329355
Validation loss: 2.478817171150767

Epoch: 5| Step: 2
Training loss: 2.0336737623972025
Validation loss: 2.484546187638819

Epoch: 5| Step: 3
Training loss: 2.1762173282421062
Validation loss: 2.4877890235238183

Epoch: 5| Step: 4
Training loss: 2.8548728644662313
Validation loss: 2.4863929869928265

Epoch: 5| Step: 5
Training loss: 2.610196469684143
Validation loss: 2.4931625364213996

Epoch: 5| Step: 6
Training loss: 2.041207073669018
Validation loss: 2.4943042144856986

Epoch: 5| Step: 7
Training loss: 2.58992963967801
Validation loss: 2.487790688665591

Epoch: 5| Step: 8
Training loss: 2.425137789242905
Validation loss: 2.4986607620209527

Epoch: 5| Step: 9
Training loss: 2.628718603275889
Validation loss: 2.505416942061191

Epoch: 5| Step: 10
Training loss: 2.741926479686741
Validation loss: 2.5149659227359202

Epoch: 5| Step: 11
Training loss: 2.1041475301445196
Validation loss: 2.5129802654464

Epoch: 183| Step: 0
Training loss: 2.4572624740602214
Validation loss: 2.524468883359404

Epoch: 5| Step: 1
Training loss: 2.478840451189304
Validation loss: 2.5355107158080132

Epoch: 5| Step: 2
Training loss: 2.6836409252301374
Validation loss: 2.5406214931036852

Epoch: 5| Step: 3
Training loss: 2.8447024249104693
Validation loss: 2.5082742774914153

Epoch: 5| Step: 4
Training loss: 1.9177760009872813
Validation loss: 2.522028247064239

Epoch: 5| Step: 5
Training loss: 2.880699313614912
Validation loss: 2.510149642123546

Epoch: 5| Step: 6
Training loss: 2.772280255510614
Validation loss: 2.507682903898532

Epoch: 5| Step: 7
Training loss: 1.883769571649427
Validation loss: 2.4934160279795177

Epoch: 5| Step: 8
Training loss: 2.5816867154128724
Validation loss: 2.4853881633389303

Epoch: 5| Step: 9
Training loss: 2.424894063149724
Validation loss: 2.483284877031257

Epoch: 5| Step: 10
Training loss: 2.120375481768572
Validation loss: 2.48990016115679

Epoch: 5| Step: 11
Training loss: 2.7211972326753298
Validation loss: 2.485968085004348

Epoch: 184| Step: 0
Training loss: 2.400161968170004
Validation loss: 2.487842355424502

Epoch: 5| Step: 1
Training loss: 1.6534828966823247
Validation loss: 2.4871735714862986

Epoch: 5| Step: 2
Training loss: 2.526110859870362
Validation loss: 2.4911363072857546

Epoch: 5| Step: 3
Training loss: 2.907400416262087
Validation loss: 2.4859473413080395

Epoch: 5| Step: 4
Training loss: 2.3277452402362213
Validation loss: 2.4870929086183127

Epoch: 5| Step: 5
Training loss: 2.1027272906920182
Validation loss: 2.4789651353384055

Epoch: 5| Step: 6
Training loss: 2.6583640269198616
Validation loss: 2.4902983015245015

Epoch: 5| Step: 7
Training loss: 2.8435276489523442
Validation loss: 2.494962831066165

Epoch: 5| Step: 8
Training loss: 2.5163365654947567
Validation loss: 2.4953744336402295

Epoch: 5| Step: 9
Training loss: 2.6462821179343248
Validation loss: 2.508035719177844

Epoch: 5| Step: 10
Training loss: 2.2282486805021167
Validation loss: 2.496275822024058

Epoch: 5| Step: 11
Training loss: 2.564483712123615
Validation loss: 2.5152003638715983

Epoch: 185| Step: 0
Training loss: 2.050176389595439
Validation loss: 2.5313910731496847

Epoch: 5| Step: 1
Training loss: 2.328472137173067
Validation loss: 2.5321208236906463

Epoch: 5| Step: 2
Training loss: 2.530749330337588
Validation loss: 2.5266324181634405

Epoch: 5| Step: 3
Training loss: 1.73172034474442
Validation loss: 2.510835143121455

Epoch: 5| Step: 4
Training loss: 2.4179480433155174
Validation loss: 2.5095058954920444

Epoch: 5| Step: 5
Training loss: 2.2619362102320517
Validation loss: 2.4875131895843423

Epoch: 5| Step: 6
Training loss: 2.4863820156301255
Validation loss: 2.485626681126381

Epoch: 5| Step: 7
Training loss: 2.490741178514373
Validation loss: 2.4834345671055327

Epoch: 5| Step: 8
Training loss: 3.0286602480220886
Validation loss: 2.481066876483373

Epoch: 5| Step: 9
Training loss: 2.6939354958801696
Validation loss: 2.483753426486581

Epoch: 5| Step: 10
Training loss: 2.562626719249113
Validation loss: 2.481480501744355

Epoch: 5| Step: 11
Training loss: 3.595207515876428
Validation loss: 2.4834114981410496

Epoch: 186| Step: 0
Training loss: 2.647890287598542
Validation loss: 2.4736032184246683

Epoch: 5| Step: 1
Training loss: 2.9554826317142764
Validation loss: 2.4915258870707535

Epoch: 5| Step: 2
Training loss: 1.8979510402253608
Validation loss: 2.476894336374371

Epoch: 5| Step: 3
Training loss: 2.7359409752719666
Validation loss: 2.49222990775226

Epoch: 5| Step: 4
Training loss: 2.3357966453927297
Validation loss: 2.491388998194181

Epoch: 5| Step: 5
Training loss: 2.7395848804851464
Validation loss: 2.488536416409238

Epoch: 5| Step: 6
Training loss: 2.137160567610222
Validation loss: 2.489247157065452

Epoch: 5| Step: 7
Training loss: 2.2803755874135363
Validation loss: 2.486065299543213

Epoch: 5| Step: 8
Training loss: 1.9358475929793695
Validation loss: 2.484103101970484

Epoch: 5| Step: 9
Training loss: 2.575311130874653
Validation loss: 2.4894463622482546

Epoch: 5| Step: 10
Training loss: 2.4733844185083664
Validation loss: 2.4815842730813524

Epoch: 5| Step: 11
Training loss: 2.2509515657505785
Validation loss: 2.486695980839061

Epoch: 187| Step: 0
Training loss: 2.94240371792897
Validation loss: 2.484671353112685

Epoch: 5| Step: 1
Training loss: 2.7257457482651954
Validation loss: 2.4835970798280913

Epoch: 5| Step: 2
Training loss: 2.3938833732400777
Validation loss: 2.475180901392867

Epoch: 5| Step: 3
Training loss: 2.395404699931232
Validation loss: 2.490275248273123

Epoch: 5| Step: 4
Training loss: 2.192829723728139
Validation loss: 2.482373120829357

Epoch: 5| Step: 5
Training loss: 2.165862178612851
Validation loss: 2.485996632778816

Epoch: 5| Step: 6
Training loss: 2.7660465242523693
Validation loss: 2.4832095085439243

Epoch: 5| Step: 7
Training loss: 2.7588872355319904
Validation loss: 2.492261660278658

Epoch: 5| Step: 8
Training loss: 2.3015454614737614
Validation loss: 2.478297326925865

Epoch: 5| Step: 9
Training loss: 2.5913216127104888
Validation loss: 2.473645964862502

Epoch: 5| Step: 10
Training loss: 2.0542395505942306
Validation loss: 2.4826562002033428

Epoch: 5| Step: 11
Training loss: 2.934293092147163
Validation loss: 2.489202707049106

Epoch: 188| Step: 0
Training loss: 1.992748166643495
Validation loss: 2.472812746066361

Epoch: 5| Step: 1
Training loss: 2.0984920491778487
Validation loss: 2.4866928588209634

Epoch: 5| Step: 2
Training loss: 2.5422476641212555
Validation loss: 2.4863324720929527

Epoch: 5| Step: 3
Training loss: 2.252107904413676
Validation loss: 2.503132510640294

Epoch: 5| Step: 4
Training loss: 2.629517074747133
Validation loss: 2.5142863445628243

Epoch: 5| Step: 5
Training loss: 2.4748288413311084
Validation loss: 2.5039952619881536

Epoch: 5| Step: 6
Training loss: 2.340192714645721
Validation loss: 2.4898746165786245

Epoch: 5| Step: 7
Training loss: 2.822727173548493
Validation loss: 2.4776451379835107

Epoch: 5| Step: 8
Training loss: 2.9607007578715434
Validation loss: 2.4970673048995624

Epoch: 5| Step: 9
Training loss: 2.2498360680094582
Validation loss: 2.483394721305048

Epoch: 5| Step: 10
Training loss: 2.51005249758833
Validation loss: 2.476975780544477

Epoch: 5| Step: 11
Training loss: 2.378500917977811
Validation loss: 2.483671432612991

Epoch: 189| Step: 0
Training loss: 2.4127507766281266
Validation loss: 2.4869229628252043

Epoch: 5| Step: 1
Training loss: 2.349140732500143
Validation loss: 2.47814152997899

Epoch: 5| Step: 2
Training loss: 2.494904283969514
Validation loss: 2.477781555313553

Epoch: 5| Step: 3
Training loss: 2.652918083470536
Validation loss: 2.485855728904908

Epoch: 5| Step: 4
Training loss: 2.4500695899889404
Validation loss: 2.4856071295802025

Epoch: 5| Step: 5
Training loss: 2.4937694156818284
Validation loss: 2.484835392100893

Epoch: 5| Step: 6
Training loss: 2.7348564378066715
Validation loss: 2.475241323708802

Epoch: 5| Step: 7
Training loss: 2.4331685241208554
Validation loss: 2.482799760382881

Epoch: 5| Step: 8
Training loss: 1.8194541380852949
Validation loss: 2.4804700516024

Epoch: 5| Step: 9
Training loss: 2.923574351253049
Validation loss: 2.4912929304589855

Epoch: 5| Step: 10
Training loss: 1.9846521619540727
Validation loss: 2.4873383241058247

Epoch: 5| Step: 11
Training loss: 1.2821802623376222
Validation loss: 2.4863140967833113

Epoch: 190| Step: 0
Training loss: 1.9072921905711309
Validation loss: 2.4984612060401936

Epoch: 5| Step: 1
Training loss: 2.6485827020771753
Validation loss: 2.488173985028211

Epoch: 5| Step: 2
Training loss: 1.9714010040752792
Validation loss: 2.4867597925920077

Epoch: 5| Step: 3
Training loss: 1.9587766740707495
Validation loss: 2.5016003413835826

Epoch: 5| Step: 4
Training loss: 2.4102074912882525
Validation loss: 2.486685318421996

Epoch: 5| Step: 5
Training loss: 2.944258847975054
Validation loss: 2.4820831071677323

Epoch: 5| Step: 6
Training loss: 2.4220299455853165
Validation loss: 2.491397808288327

Epoch: 5| Step: 7
Training loss: 2.449025610407063
Validation loss: 2.4960145853191618

Epoch: 5| Step: 8
Training loss: 2.2990910226624477
Validation loss: 2.4859517050512485

Epoch: 5| Step: 9
Training loss: 2.371496728781033
Validation loss: 2.4854237763931213

Epoch: 5| Step: 10
Training loss: 3.057090809000861
Validation loss: 2.4973149066073983

Epoch: 5| Step: 11
Training loss: 2.1555097110806503
Validation loss: 2.4979843199420797

Epoch: 191| Step: 0
Training loss: 2.6268234277636924
Validation loss: 2.4789653397137927

Epoch: 5| Step: 1
Training loss: 2.028458070370081
Validation loss: 2.4947243099371215

Epoch: 5| Step: 2
Training loss: 2.3187748087663733
Validation loss: 2.4888422646464985

Epoch: 5| Step: 3
Training loss: 2.920875255884272
Validation loss: 2.4908682461492586

Epoch: 5| Step: 4
Training loss: 1.5504096904878932
Validation loss: 2.491931403862594

Epoch: 5| Step: 5
Training loss: 2.468649463779398
Validation loss: 2.4929761047477945

Epoch: 5| Step: 6
Training loss: 1.7526177854041902
Validation loss: 2.500804743785034

Epoch: 5| Step: 7
Training loss: 2.4300380834099102
Validation loss: 2.4967693077319453

Epoch: 5| Step: 8
Training loss: 2.313886690641196
Validation loss: 2.518312890055866

Epoch: 5| Step: 9
Training loss: 2.768687648372508
Validation loss: 2.5048560346197015

Epoch: 5| Step: 10
Training loss: 2.8670314985446987
Validation loss: 2.520035606982952

Epoch: 5| Step: 11
Training loss: 3.6289745771958217
Validation loss: 2.5150922839105943

Epoch: 192| Step: 0
Training loss: 2.074223002916132
Validation loss: 2.505398789989195

Epoch: 5| Step: 1
Training loss: 2.893305015542583
Validation loss: 2.5064429428464723

Epoch: 5| Step: 2
Training loss: 2.5071569043341584
Validation loss: 2.489039502673203

Epoch: 5| Step: 3
Training loss: 2.443140399735018
Validation loss: 2.4969142068864953

Epoch: 5| Step: 4
Training loss: 2.7747323465573643
Validation loss: 2.498341860838272

Epoch: 5| Step: 5
Training loss: 2.535298441938792
Validation loss: 2.5031402376292946

Epoch: 5| Step: 6
Training loss: 2.2309441535830183
Validation loss: 2.4977112664686403

Epoch: 5| Step: 7
Training loss: 2.20225843336708
Validation loss: 2.4998891249547768

Epoch: 5| Step: 8
Training loss: 2.209589031379264
Validation loss: 2.5051011216558354

Epoch: 5| Step: 9
Training loss: 2.4129242914292677
Validation loss: 2.507881868696374

Epoch: 5| Step: 10
Training loss: 2.2825440172545077
Validation loss: 2.5028444916405572

Epoch: 5| Step: 11
Training loss: 1.762838612487992
Validation loss: 2.509299256451224

Epoch: 193| Step: 0
Training loss: 2.044039210583563
Validation loss: 2.501730065945491

Epoch: 5| Step: 1
Training loss: 2.420946693939679
Validation loss: 2.5080449045147373

Epoch: 5| Step: 2
Training loss: 2.605413113161591
Validation loss: 2.5205133421545454

Epoch: 5| Step: 3
Training loss: 2.4214341285342798
Validation loss: 2.5286853576357915

Epoch: 5| Step: 4
Training loss: 2.6431810095899197
Validation loss: 2.524138039428378

Epoch: 5| Step: 5
Training loss: 2.2968519559988794
Validation loss: 2.5197444618558613

Epoch: 5| Step: 6
Training loss: 2.436123288002256
Validation loss: 2.5118238942241446

Epoch: 5| Step: 7
Training loss: 2.2415286701180475
Validation loss: 2.5167411121090084

Epoch: 5| Step: 8
Training loss: 2.375072478142135
Validation loss: 2.505350625695459

Epoch: 5| Step: 9
Training loss: 2.308653338545947
Validation loss: 2.4999050738273567

Epoch: 5| Step: 10
Training loss: 2.9880323119350582
Validation loss: 2.5010969695798595

Epoch: 5| Step: 11
Training loss: 2.4130453293894485
Validation loss: 2.5035591539541087

Epoch: 194| Step: 0
Training loss: 2.6044593239689386
Validation loss: 2.5050042294627084

Epoch: 5| Step: 1
Training loss: 2.480766410689551
Validation loss: 2.4994166567829383

Epoch: 5| Step: 2
Training loss: 2.069104111896426
Validation loss: 2.5084738725808724

Epoch: 5| Step: 3
Training loss: 2.592772977724771
Validation loss: 2.50929061807948

Epoch: 5| Step: 4
Training loss: 2.3313369612032413
Validation loss: 2.517782482675165

Epoch: 5| Step: 5
Training loss: 2.853047023681162
Validation loss: 2.517897734319664

Epoch: 5| Step: 6
Training loss: 2.358682290759541
Validation loss: 2.516556841672875

Epoch: 5| Step: 7
Training loss: 2.443172993553306
Validation loss: 2.521960287688491

Epoch: 5| Step: 8
Training loss: 2.844752376084392
Validation loss: 2.5188981317924455

Epoch: 5| Step: 9
Training loss: 1.9331565285549572
Validation loss: 2.519813517843317

Epoch: 5| Step: 10
Training loss: 1.9917867818495498
Validation loss: 2.509404975123014

Epoch: 5| Step: 11
Training loss: 1.7456989567404504
Validation loss: 2.507887937177673

Epoch: 195| Step: 0
Training loss: 2.195939052674068
Validation loss: 2.4987256060337146

Epoch: 5| Step: 1
Training loss: 2.701794070660521
Validation loss: 2.4980396850259767

Epoch: 5| Step: 2
Training loss: 2.2499188302551754
Validation loss: 2.49180850871312

Epoch: 5| Step: 3
Training loss: 2.7018025421232275
Validation loss: 2.4966436306761186

Epoch: 5| Step: 4
Training loss: 2.2986283649003196
Validation loss: 2.5040922447947445

Epoch: 5| Step: 5
Training loss: 2.01498201745578
Validation loss: 2.4959487037125445

Epoch: 5| Step: 6
Training loss: 2.7544032304501656
Validation loss: 2.49921125446836

Epoch: 5| Step: 7
Training loss: 2.0839922689415276
Validation loss: 2.486434574650269

Epoch: 5| Step: 8
Training loss: 2.6768103632314197
Validation loss: 2.5028421359626183

Epoch: 5| Step: 9
Training loss: 2.4090858691704247
Validation loss: 2.498882683778585

Epoch: 5| Step: 10
Training loss: 2.117649605070092
Validation loss: 2.4845352021233436

Epoch: 5| Step: 11
Training loss: 2.9692766224424925
Validation loss: 2.4955237846762035

Epoch: 196| Step: 0
Training loss: 2.1130179137135388
Validation loss: 2.49582608598178

Epoch: 5| Step: 1
Training loss: 1.7074358218462786
Validation loss: 2.5004432166131436

Epoch: 5| Step: 2
Training loss: 2.811752559101402
Validation loss: 2.493326463003519

Epoch: 5| Step: 3
Training loss: 2.560151582491883
Validation loss: 2.4956964087991724

Epoch: 5| Step: 4
Training loss: 2.334214203184896
Validation loss: 2.511909347113314

Epoch: 5| Step: 5
Training loss: 2.409006595771979
Validation loss: 2.5253824311074555

Epoch: 5| Step: 6
Training loss: 2.585239650456601
Validation loss: 2.4996356340958434

Epoch: 5| Step: 7
Training loss: 2.381220952054568
Validation loss: 2.505224078493081

Epoch: 5| Step: 8
Training loss: 2.8486679645157147
Validation loss: 2.5028098667223166

Epoch: 5| Step: 9
Training loss: 2.0852527423141334
Validation loss: 2.504612748110776

Epoch: 5| Step: 10
Training loss: 2.401911502811893
Validation loss: 2.5105753461989053

Epoch: 5| Step: 11
Training loss: 2.096133000492959
Validation loss: 2.512086804734974

Epoch: 197| Step: 0
Training loss: 2.7108192967746163
Validation loss: 2.5035746290825087

Epoch: 5| Step: 1
Training loss: 2.420857566497725
Validation loss: 2.5073883712074534

Epoch: 5| Step: 2
Training loss: 2.5645529734108
Validation loss: 2.5164041714371996

Epoch: 5| Step: 3
Training loss: 2.469452094185529
Validation loss: 2.5162669403319526

Epoch: 5| Step: 4
Training loss: 1.9503461677225906
Validation loss: 2.525679919633719

Epoch: 5| Step: 5
Training loss: 2.4165676907846563
Validation loss: 2.520203792894521

Epoch: 5| Step: 6
Training loss: 2.7261481639761773
Validation loss: 2.5150041544647994

Epoch: 5| Step: 7
Training loss: 2.072318663354305
Validation loss: 2.519424246948085

Epoch: 5| Step: 8
Training loss: 1.95320995908968
Validation loss: 2.5021766485324575

Epoch: 5| Step: 9
Training loss: 2.576009911571413
Validation loss: 2.5275688955499125

Epoch: 5| Step: 10
Training loss: 2.2444559245975264
Validation loss: 2.507613030539227

Epoch: 5| Step: 11
Training loss: 3.174964189702932
Validation loss: 2.5048228513841964

Epoch: 198| Step: 0
Training loss: 2.7292772129956306
Validation loss: 2.4856753834711456

Epoch: 5| Step: 1
Training loss: 1.8399396413771656
Validation loss: 2.496424721200249

Epoch: 5| Step: 2
Training loss: 2.4248757753310484
Validation loss: 2.481113358089474

Epoch: 5| Step: 3
Training loss: 3.04340152821452
Validation loss: 2.4868923564892262

Epoch: 5| Step: 4
Training loss: 2.6793066705062225
Validation loss: 2.4899465397058242

Epoch: 5| Step: 5
Training loss: 2.067124470898169
Validation loss: 2.481493000011165

Epoch: 5| Step: 6
Training loss: 2.1708776805055234
Validation loss: 2.4885179096704406

Epoch: 5| Step: 7
Training loss: 2.416584758905149
Validation loss: 2.4810713809410547

Epoch: 5| Step: 8
Training loss: 2.711017442563411
Validation loss: 2.490321137157245

Epoch: 5| Step: 9
Training loss: 2.1486143836985794
Validation loss: 2.489709884161795

Epoch: 5| Step: 10
Training loss: 2.675787665366397
Validation loss: 2.49825460382014

Epoch: 5| Step: 11
Training loss: 1.8227958275843288
Validation loss: 2.48933212390842

Epoch: 199| Step: 0
Training loss: 2.5067410185453176
Validation loss: 2.5035635227115858

Epoch: 5| Step: 1
Training loss: 2.2390771219823615
Validation loss: 2.505877630772325

Epoch: 5| Step: 2
Training loss: 1.876188156054111
Validation loss: 2.5094249607938437

Epoch: 5| Step: 3
Training loss: 2.5450614604011506
Validation loss: 2.520128736203677

Epoch: 5| Step: 4
Training loss: 2.6663545386114222
Validation loss: 2.5111030073044507

Epoch: 5| Step: 5
Training loss: 2.386766299009785
Validation loss: 2.5232407775665515

Epoch: 5| Step: 6
Training loss: 2.3595843695907117
Validation loss: 2.5202155748694084

Epoch: 5| Step: 7
Training loss: 2.892379146019521
Validation loss: 2.504465087404472

Epoch: 5| Step: 8
Training loss: 2.652244959299046
Validation loss: 2.507092817277063

Epoch: 5| Step: 9
Training loss: 1.994516664146108
Validation loss: 2.516660011411124

Epoch: 5| Step: 10
Training loss: 2.6074408941253915
Validation loss: 2.504974887040552

Epoch: 5| Step: 11
Training loss: 1.6156525629817227
Validation loss: 2.5179232115952175

Epoch: 200| Step: 0
Training loss: 2.051662989390239
Validation loss: 2.511669417510354

Epoch: 5| Step: 1
Training loss: 2.286282775210157
Validation loss: 2.5062352069852585

Epoch: 5| Step: 2
Training loss: 2.416013552665593
Validation loss: 2.4930462169974095

Epoch: 5| Step: 3
Training loss: 2.9076496978559665
Validation loss: 2.4964520073435184

Epoch: 5| Step: 4
Training loss: 2.8370970990328863
Validation loss: 2.4978458780010295

Epoch: 5| Step: 5
Training loss: 2.023582777309175
Validation loss: 2.5030223022106943

Epoch: 5| Step: 6
Training loss: 2.4733885634323154
Validation loss: 2.495384983291125

Epoch: 5| Step: 7
Training loss: 2.171679371318216
Validation loss: 2.497010704843819

Epoch: 5| Step: 8
Training loss: 2.7336022729296525
Validation loss: 2.4924078418423643

Epoch: 5| Step: 9
Training loss: 1.9512805011132197
Validation loss: 2.4949026992289487

Epoch: 5| Step: 10
Training loss: 2.415683732793079
Validation loss: 2.502795916993878

Epoch: 5| Step: 11
Training loss: 2.810936047912528
Validation loss: 2.5020561028321415

Testing loss: 1.9917680774268154
