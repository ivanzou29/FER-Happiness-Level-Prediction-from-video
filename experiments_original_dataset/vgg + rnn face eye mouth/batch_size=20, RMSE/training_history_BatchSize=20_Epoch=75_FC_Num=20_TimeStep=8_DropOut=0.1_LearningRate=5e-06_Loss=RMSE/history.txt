Epoch: 1| Step: 0
Training loss: 5.9716578884771785
Validation loss: 5.9459954636872245

Epoch: 5| Step: 1
Training loss: 6.474695688998574
Validation loss: 5.944344781424391

Epoch: 5| Step: 2
Training loss: 5.274256844623849
Validation loss: 5.94268739536708

Epoch: 5| Step: 3
Training loss: 5.581557470654385
Validation loss: 5.941172404372095

Epoch: 5| Step: 4
Training loss: 7.066358204473206
Validation loss: 5.939473463327011

Epoch: 5| Step: 5
Training loss: 5.830884510292009
Validation loss: 5.9376885434381235

Epoch: 5| Step: 6
Training loss: 5.818963835461448
Validation loss: 5.935833345700885

Epoch: 5| Step: 7
Training loss: 5.323970304697224
Validation loss: 5.933940837955611

Epoch: 5| Step: 8
Training loss: 7.152229345668182
Validation loss: 5.932102976257823

Epoch: 5| Step: 9
Training loss: 5.840398633232868
Validation loss: 5.930192130977016

Epoch: 5| Step: 10
Training loss: 5.807218387523465
Validation loss: 5.928063794806944

Epoch: 5| Step: 11
Training loss: 6.632357560406558
Validation loss: 5.925983456518912

Epoch: 2| Step: 0
Training loss: 5.971017776199583
Validation loss: 5.923694099698616

Epoch: 5| Step: 1
Training loss: 5.8613323553591865
Validation loss: 5.921421406064653

Epoch: 5| Step: 2
Training loss: 6.3530247730580935
Validation loss: 5.918990533997218

Epoch: 5| Step: 3
Training loss: 5.7742154599968645
Validation loss: 5.916493422250845

Epoch: 5| Step: 4
Training loss: 6.512169816036021
Validation loss: 5.913933480861472

Epoch: 5| Step: 5
Training loss: 5.582606633658857
Validation loss: 5.911091295406682

Epoch: 5| Step: 6
Training loss: 5.922130086029804
Validation loss: 5.908481842276531

Epoch: 5| Step: 7
Training loss: 6.8032446469188566
Validation loss: 5.905633292050891

Epoch: 5| Step: 8
Training loss: 6.088048840480998
Validation loss: 5.902415482366873

Epoch: 5| Step: 9
Training loss: 5.868225737241424
Validation loss: 5.899335234579035

Epoch: 5| Step: 10
Training loss: 5.392361656964595
Validation loss: 5.895925011163558

Epoch: 5| Step: 11
Training loss: 6.175104228387187
Validation loss: 5.892621856247325

Epoch: 3| Step: 0
Training loss: 5.365559293492377
Validation loss: 5.889164811943687

Epoch: 5| Step: 1
Training loss: 6.596153363648949
Validation loss: 5.885570526362464

Epoch: 5| Step: 2
Training loss: 5.989318877200726
Validation loss: 5.881669344192952

Epoch: 5| Step: 3
Training loss: 5.90773274212229
Validation loss: 5.877717701687638

Epoch: 5| Step: 4
Training loss: 5.8292160035727445
Validation loss: 5.873368077173569

Epoch: 5| Step: 5
Training loss: 5.82280285700729
Validation loss: 5.869129386125193

Epoch: 5| Step: 6
Training loss: 6.146246358495273
Validation loss: 5.864368016935623

Epoch: 5| Step: 7
Training loss: 5.973769708486367
Validation loss: 5.859735842296106

Epoch: 5| Step: 8
Training loss: 6.0324930283798235
Validation loss: 5.854925210574452

Epoch: 5| Step: 9
Training loss: 6.506284170216767
Validation loss: 5.849736063184501

Epoch: 5| Step: 10
Training loss: 4.9986597172147915
Validation loss: 5.844154384717442

Epoch: 5| Step: 11
Training loss: 7.9980287507425905
Validation loss: 5.838319713537802

Epoch: 4| Step: 0
Training loss: 7.224193815772234
Validation loss: 5.832621819381766

Epoch: 5| Step: 1
Training loss: 5.389891289798406
Validation loss: 5.826592728882586

Epoch: 5| Step: 2
Training loss: 5.92032524504187
Validation loss: 5.820394808125373

Epoch: 5| Step: 3
Training loss: 5.919963759749551
Validation loss: 5.813863614829294

Epoch: 5| Step: 4
Training loss: 5.886089491293156
Validation loss: 5.807162086398227

Epoch: 5| Step: 5
Training loss: 5.315175717769508
Validation loss: 5.80068064044739

Epoch: 5| Step: 6
Training loss: 5.940925653947575
Validation loss: 5.7937351713570315

Epoch: 5| Step: 7
Training loss: 5.951518004579831
Validation loss: 5.786679139775722

Epoch: 5| Step: 8
Training loss: 5.179134747914998
Validation loss: 5.779744716944433

Epoch: 5| Step: 9
Training loss: 6.464771761306137
Validation loss: 5.772138718778281

Epoch: 5| Step: 10
Training loss: 6.031568133408527
Validation loss: 5.764751530123469

Epoch: 5| Step: 11
Training loss: 3.169042816778081
Validation loss: 5.756832569090053

Epoch: 5| Step: 0
Training loss: 5.68047997824155
Validation loss: 5.7494021671600315

Epoch: 5| Step: 1
Training loss: 6.1745312346782715
Validation loss: 5.741445272834477

Epoch: 5| Step: 2
Training loss: 5.379545906501426
Validation loss: 5.733154180780931

Epoch: 5| Step: 3
Training loss: 5.417596981657463
Validation loss: 5.724901611615435

Epoch: 5| Step: 4
Training loss: 5.5770912387902545
Validation loss: 5.716403410255999

Epoch: 5| Step: 5
Training loss: 5.904673855501568
Validation loss: 5.707735575636143

Epoch: 5| Step: 6
Training loss: 5.941743639232951
Validation loss: 5.698686727853242

Epoch: 5| Step: 7
Training loss: 5.886409637496371
Validation loss: 5.689785431781209

Epoch: 5| Step: 8
Training loss: 5.637810086605599
Validation loss: 5.680435145448393

Epoch: 5| Step: 9
Training loss: 5.925629324024764
Validation loss: 5.671024297245242

Epoch: 5| Step: 10
Training loss: 6.267819750328452
Validation loss: 5.661504731840641

Epoch: 5| Step: 11
Training loss: 6.627427717956514
Validation loss: 5.651921444336847

Epoch: 6| Step: 0
Training loss: 6.21577942408488
Validation loss: 5.641800339700875

Epoch: 5| Step: 1
Training loss: 6.032170517006315
Validation loss: 5.63179801309454

Epoch: 5| Step: 2
Training loss: 6.1599134979119485
Validation loss: 5.6218189781667425

Epoch: 5| Step: 3
Training loss: 6.317339864134617
Validation loss: 5.611095111601694

Epoch: 5| Step: 4
Training loss: 6.198827681919135
Validation loss: 5.60113390387291

Epoch: 5| Step: 5
Training loss: 5.537627428366808
Validation loss: 5.590330119180842

Epoch: 5| Step: 6
Training loss: 5.490600356609556
Validation loss: 5.5791682488589025

Epoch: 5| Step: 7
Training loss: 5.39394287613213
Validation loss: 5.568290611011095

Epoch: 5| Step: 8
Training loss: 4.72807754321338
Validation loss: 5.556933071170707

Epoch: 5| Step: 9
Training loss: 5.8231939569369855
Validation loss: 5.545649433406752

Epoch: 5| Step: 10
Training loss: 4.766323951369589
Validation loss: 5.534204674484795

Epoch: 5| Step: 11
Training loss: 5.040454098665313
Validation loss: 5.523750976127336

Epoch: 7| Step: 0
Training loss: 6.204817764348082
Validation loss: 5.513884711991316

Epoch: 5| Step: 1
Training loss: 5.47843920540507
Validation loss: 5.50357682068186

Epoch: 5| Step: 2
Training loss: 5.826511026627188
Validation loss: 5.494322403912161

Epoch: 5| Step: 3
Training loss: 5.519427579971213
Validation loss: 5.485115863430597

Epoch: 5| Step: 4
Training loss: 5.5746329353502375
Validation loss: 5.476518102040542

Epoch: 5| Step: 5
Training loss: 4.461015102693552
Validation loss: 5.46766576282249

Epoch: 5| Step: 6
Training loss: 6.110986365384083
Validation loss: 5.458880261205758

Epoch: 5| Step: 7
Training loss: 5.719877871830162
Validation loss: 5.45019315441485

Epoch: 5| Step: 8
Training loss: 6.039357482891068
Validation loss: 5.442019582971371

Epoch: 5| Step: 9
Training loss: 4.862315965322581
Validation loss: 5.4331264299459345

Epoch: 5| Step: 10
Training loss: 5.318067438278324
Validation loss: 5.424603269576383

Epoch: 5| Step: 11
Training loss: 6.118817069725461
Validation loss: 5.416570577013695

Epoch: 8| Step: 0
Training loss: 5.190760679268825
Validation loss: 5.4082058655931755

Epoch: 5| Step: 1
Training loss: 5.0716518989988995
Validation loss: 5.400332768218275

Epoch: 5| Step: 2
Training loss: 5.396468116605982
Validation loss: 5.3922958217231916

Epoch: 5| Step: 3
Training loss: 6.063914340498738
Validation loss: 5.384685860293165

Epoch: 5| Step: 4
Training loss: 6.839730811371269
Validation loss: 5.376771257998883

Epoch: 5| Step: 5
Training loss: 5.926826279289199
Validation loss: 5.369636691274744

Epoch: 5| Step: 6
Training loss: 5.336253479388799
Validation loss: 5.362626456464336

Epoch: 5| Step: 7
Training loss: 5.205628305526418
Validation loss: 5.354706728325322

Epoch: 5| Step: 8
Training loss: 5.46349025104526
Validation loss: 5.348084816433437

Epoch: 5| Step: 9
Training loss: 4.661494840624617
Validation loss: 5.341254917805821

Epoch: 5| Step: 10
Training loss: 4.831609264996458
Validation loss: 5.334735591644022

Epoch: 5| Step: 11
Training loss: 5.897425927331295
Validation loss: 5.328183790014945

Epoch: 9| Step: 0
Training loss: 6.0751192559989615
Validation loss: 5.321624653801017

Epoch: 5| Step: 1
Training loss: 5.440073215609007
Validation loss: 5.315079567637534

Epoch: 5| Step: 2
Training loss: 5.7323080802163515
Validation loss: 5.3079833408876205

Epoch: 5| Step: 3
Training loss: 4.641989767356682
Validation loss: 5.302109359147725

Epoch: 5| Step: 4
Training loss: 5.232688335997061
Validation loss: 5.295260428056967

Epoch: 5| Step: 5
Training loss: 5.9905833418486685
Validation loss: 5.289058285236792

Epoch: 5| Step: 6
Training loss: 5.292102024862402
Validation loss: 5.283067341656132

Epoch: 5| Step: 7
Training loss: 5.869019081520186
Validation loss: 5.276726450136631

Epoch: 5| Step: 8
Training loss: 4.94917751376369
Validation loss: 5.270110561989344

Epoch: 5| Step: 9
Training loss: 5.0682481698421595
Validation loss: 5.264253809460589

Epoch: 5| Step: 10
Training loss: 5.089783417116518
Validation loss: 5.257954747173232

Epoch: 5| Step: 11
Training loss: 5.2177492198635536
Validation loss: 5.2521668685368965

Epoch: 10| Step: 0
Training loss: 5.329235509328857
Validation loss: 5.245537927969144

Epoch: 5| Step: 1
Training loss: 4.8724988732451635
Validation loss: 5.239980923967364

Epoch: 5| Step: 2
Training loss: 5.819273580725022
Validation loss: 5.233695256521124

Epoch: 5| Step: 3
Training loss: 4.689151117084258
Validation loss: 5.227582671346239

Epoch: 5| Step: 4
Training loss: 5.124810564215208
Validation loss: 5.221900582835859

Epoch: 5| Step: 5
Training loss: 4.924389974699892
Validation loss: 5.215694858090043

Epoch: 5| Step: 6
Training loss: 5.704129566919999
Validation loss: 5.21000214607795

Epoch: 5| Step: 7
Training loss: 5.42994006550627
Validation loss: 5.2040836951689435

Epoch: 5| Step: 8
Training loss: 5.234526583626021
Validation loss: 5.19863617019305

Epoch: 5| Step: 9
Training loss: 5.6005640563271335
Validation loss: 5.193327759350849

Epoch: 5| Step: 10
Training loss: 5.835471424452824
Validation loss: 5.187522106812953

Epoch: 5| Step: 11
Training loss: 5.421735338506533
Validation loss: 5.182044565517358

Epoch: 11| Step: 0
Training loss: 5.685714273664991
Validation loss: 5.176619651594855

Epoch: 5| Step: 1
Training loss: 5.8534517587023025
Validation loss: 5.1714189603031775

Epoch: 5| Step: 2
Training loss: 5.171021174918459
Validation loss: 5.165777924711212

Epoch: 5| Step: 3
Training loss: 4.956862907467066
Validation loss: 5.161051493244376

Epoch: 5| Step: 4
Training loss: 4.6118707656685825
Validation loss: 5.1558274067031356

Epoch: 5| Step: 5
Training loss: 4.900259454825772
Validation loss: 5.150617740827964

Epoch: 5| Step: 6
Training loss: 5.295451735407589
Validation loss: 5.145729746014016

Epoch: 5| Step: 7
Training loss: 6.039583605629988
Validation loss: 5.140127828532415

Epoch: 5| Step: 8
Training loss: 5.064585691718501
Validation loss: 5.135195298546737

Epoch: 5| Step: 9
Training loss: 5.307167518468943
Validation loss: 5.129853540019062

Epoch: 5| Step: 10
Training loss: 5.136512665186288
Validation loss: 5.124406400279512

Epoch: 5| Step: 11
Training loss: 4.325544669192617
Validation loss: 5.11884016765691

Epoch: 12| Step: 0
Training loss: 5.1944454530838495
Validation loss: 5.11323657306516

Epoch: 5| Step: 1
Training loss: 4.540782714121031
Validation loss: 5.108464376667818

Epoch: 5| Step: 2
Training loss: 5.633983135930755
Validation loss: 5.102997231971787

Epoch: 5| Step: 3
Training loss: 5.037626407826319
Validation loss: 5.097464457249702

Epoch: 5| Step: 4
Training loss: 4.213379556989824
Validation loss: 5.091846547276514

Epoch: 5| Step: 5
Training loss: 5.4862446871992745
Validation loss: 5.086764212285902

Epoch: 5| Step: 6
Training loss: 5.309990503334993
Validation loss: 5.081741985481435

Epoch: 5| Step: 7
Training loss: 6.213366147610918
Validation loss: 5.0767852424371025

Epoch: 5| Step: 8
Training loss: 5.543062345051949
Validation loss: 5.071932321828983

Epoch: 5| Step: 9
Training loss: 5.16543667006301
Validation loss: 5.0669431771986435

Epoch: 5| Step: 10
Training loss: 4.598406241929949
Validation loss: 5.062023493628994

Epoch: 5| Step: 11
Training loss: 5.575105592557334
Validation loss: 5.056859025085636

Epoch: 13| Step: 0
Training loss: 5.562554519900478
Validation loss: 5.051297701546127

Epoch: 5| Step: 1
Training loss: 5.071521209392635
Validation loss: 5.045817867773009

Epoch: 5| Step: 2
Training loss: 5.717113490015293
Validation loss: 5.040066152370603

Epoch: 5| Step: 3
Training loss: 4.771786168438888
Validation loss: 5.035221656786845

Epoch: 5| Step: 4
Training loss: 5.379674076857981
Validation loss: 5.028956188526621

Epoch: 5| Step: 5
Training loss: 4.880872466156413
Validation loss: 5.023358682080366

Epoch: 5| Step: 6
Training loss: 4.517396572767804
Validation loss: 5.017376357264016

Epoch: 5| Step: 7
Training loss: 5.438286209268587
Validation loss: 5.011551744944643

Epoch: 5| Step: 8
Training loss: 5.22931428779455
Validation loss: 5.005212887680199

Epoch: 5| Step: 9
Training loss: 5.696169774300644
Validation loss: 4.998653214587567

Epoch: 5| Step: 10
Training loss: 4.3654770888200405
Validation loss: 4.992963345554121

Epoch: 5| Step: 11
Training loss: 3.932440155796202
Validation loss: 4.986036775023648

Epoch: 14| Step: 0
Training loss: 4.512547483749154
Validation loss: 4.980472914750097

Epoch: 5| Step: 1
Training loss: 5.42424218998113
Validation loss: 4.975280436881773

Epoch: 5| Step: 2
Training loss: 4.945917993392459
Validation loss: 4.969141003081136

Epoch: 5| Step: 3
Training loss: 4.830027183945888
Validation loss: 4.962514775764254

Epoch: 5| Step: 4
Training loss: 5.592180767199164
Validation loss: 4.956492373427754

Epoch: 5| Step: 5
Training loss: 5.249459375066041
Validation loss: 4.950821542478085

Epoch: 5| Step: 6
Training loss: 5.32863133505286
Validation loss: 4.944520200846713

Epoch: 5| Step: 7
Training loss: 4.447609574424634
Validation loss: 4.938417880535832

Epoch: 5| Step: 8
Training loss: 6.08260950807582
Validation loss: 4.932341452175776

Epoch: 5| Step: 9
Training loss: 4.454368230376459
Validation loss: 4.926348281237467

Epoch: 5| Step: 10
Training loss: 4.789461750856252
Validation loss: 4.920475594321173

Epoch: 5| Step: 11
Training loss: 4.528329894890929
Validation loss: 4.914446485726313

Epoch: 15| Step: 0
Training loss: 4.697573404677566
Validation loss: 4.909232470221868

Epoch: 5| Step: 1
Training loss: 5.1486823757441895
Validation loss: 4.903446684399583

Epoch: 5| Step: 2
Training loss: 4.931513960316436
Validation loss: 4.897163229426104

Epoch: 5| Step: 3
Training loss: 4.518641114670799
Validation loss: 4.892004182187859

Epoch: 5| Step: 4
Training loss: 5.413094658374042
Validation loss: 4.886345255214322

Epoch: 5| Step: 5
Training loss: 4.458735201302821
Validation loss: 4.880688852967269

Epoch: 5| Step: 6
Training loss: 4.945035760979708
Validation loss: 4.8760139111948115

Epoch: 5| Step: 7
Training loss: 5.151421708094186
Validation loss: 4.870506130853106

Epoch: 5| Step: 8
Training loss: 5.354565834375202
Validation loss: 4.865006302518771

Epoch: 5| Step: 9
Training loss: 5.050731024378078
Validation loss: 4.859437236816644

Epoch: 5| Step: 10
Training loss: 5.299939734638111
Validation loss: 4.854612717442826

Epoch: 5| Step: 11
Training loss: 4.957189775341469
Validation loss: 4.849056667665189

Epoch: 16| Step: 0
Training loss: 4.48823939105535
Validation loss: 4.844014929632652

Epoch: 5| Step: 1
Training loss: 4.434086305926871
Validation loss: 4.839238089657411

Epoch: 5| Step: 2
Training loss: 4.810246125584042
Validation loss: 4.833428951939951

Epoch: 5| Step: 3
Training loss: 5.544344644576291
Validation loss: 4.829036038233526

Epoch: 5| Step: 4
Training loss: 4.211925949691955
Validation loss: 4.82389156246193

Epoch: 5| Step: 5
Training loss: 5.119599264674861
Validation loss: 4.818616967647044

Epoch: 5| Step: 6
Training loss: 4.6577142039013735
Validation loss: 4.8135681453203025

Epoch: 5| Step: 7
Training loss: 4.890213531637424
Validation loss: 4.808744732376491

Epoch: 5| Step: 8
Training loss: 5.771529650308879
Validation loss: 4.8036249324582805

Epoch: 5| Step: 9
Training loss: 5.280772351215891
Validation loss: 4.798861577879092

Epoch: 5| Step: 10
Training loss: 4.9764505849857175
Validation loss: 4.793058187805257

Epoch: 5| Step: 11
Training loss: 4.748152524148537
Validation loss: 4.78870966795504

Epoch: 17| Step: 0
Training loss: 5.111642316957797
Validation loss: 4.783908603492081

Epoch: 5| Step: 1
Training loss: 4.613749248594493
Validation loss: 4.7783819501674625

Epoch: 5| Step: 2
Training loss: 5.399960779118273
Validation loss: 4.773591625432951

Epoch: 5| Step: 3
Training loss: 5.19730581033647
Validation loss: 4.7677179378818115

Epoch: 5| Step: 4
Training loss: 5.4175228713767005
Validation loss: 4.763546299579346

Epoch: 5| Step: 5
Training loss: 5.539107092501656
Validation loss: 4.757997455979477

Epoch: 5| Step: 6
Training loss: 4.897316349591735
Validation loss: 4.753414140075072

Epoch: 5| Step: 7
Training loss: 5.034732537386913
Validation loss: 4.748654292033246

Epoch: 5| Step: 8
Training loss: 4.196066676712838
Validation loss: 4.742992209251504

Epoch: 5| Step: 9
Training loss: 3.8698036053329186
Validation loss: 4.7380271061446235

Epoch: 5| Step: 10
Training loss: 4.353436325124563
Validation loss: 4.733618248784144

Epoch: 5| Step: 11
Training loss: 3.7752424705394416
Validation loss: 4.728409133714109

Epoch: 18| Step: 0
Training loss: 3.8467850526633334
Validation loss: 4.7235094198509415

Epoch: 5| Step: 1
Training loss: 4.064202524110041
Validation loss: 4.7194086335168

Epoch: 5| Step: 2
Training loss: 5.277943676577555
Validation loss: 4.7151651259748535

Epoch: 5| Step: 3
Training loss: 5.146219009999181
Validation loss: 4.7092077602298446

Epoch: 5| Step: 4
Training loss: 5.1996213555027815
Validation loss: 4.704888428268175

Epoch: 5| Step: 5
Training loss: 4.5646027200560795
Validation loss: 4.6994156092006

Epoch: 5| Step: 6
Training loss: 4.587639513934639
Validation loss: 4.695409899657169

Epoch: 5| Step: 7
Training loss: 5.411460878911917
Validation loss: 4.690194576167962

Epoch: 5| Step: 8
Training loss: 5.000860903057444
Validation loss: 4.685326326561398

Epoch: 5| Step: 9
Training loss: 4.6800471758298725
Validation loss: 4.680086992350541

Epoch: 5| Step: 10
Training loss: 4.990904546180674
Validation loss: 4.675075391681691

Epoch: 5| Step: 11
Training loss: 5.082555158909678
Validation loss: 4.670379748114984

Epoch: 19| Step: 0
Training loss: 4.94711121545208
Validation loss: 4.665196453971946

Epoch: 5| Step: 1
Training loss: 5.28891482351304
Validation loss: 4.660122006064809

Epoch: 5| Step: 2
Training loss: 4.860686784420012
Validation loss: 4.655717294418038

Epoch: 5| Step: 3
Training loss: 4.03352350989891
Validation loss: 4.650034021779504

Epoch: 5| Step: 4
Training loss: 4.8615866776613235
Validation loss: 4.645374872768558

Epoch: 5| Step: 5
Training loss: 5.383708552618819
Validation loss: 4.640376674117489

Epoch: 5| Step: 6
Training loss: 4.5402284263920425
Validation loss: 4.635449770119866

Epoch: 5| Step: 7
Training loss: 4.9514931478606075
Validation loss: 4.631054455142013

Epoch: 5| Step: 8
Training loss: 4.629065093200242
Validation loss: 4.626022638208632

Epoch: 5| Step: 9
Training loss: 3.705402559143227
Validation loss: 4.621185826351364

Epoch: 5| Step: 10
Training loss: 4.757759983418085
Validation loss: 4.616544890719945

Epoch: 5| Step: 11
Training loss: 5.8064662010255725
Validation loss: 4.611749561122233

Epoch: 20| Step: 0
Training loss: 4.762588283891988
Validation loss: 4.60687111989249

Epoch: 5| Step: 1
Training loss: 4.555993234858795
Validation loss: 4.602180840958925

Epoch: 5| Step: 2
Training loss: 3.848832530579852
Validation loss: 4.597458119148916

Epoch: 5| Step: 3
Training loss: 4.8415345078167995
Validation loss: 4.592560845603449

Epoch: 5| Step: 4
Training loss: 5.405536406063719
Validation loss: 4.587941578289387

Epoch: 5| Step: 5
Training loss: 4.776988804654551
Validation loss: 4.583656051140382

Epoch: 5| Step: 6
Training loss: 4.27533195946788
Validation loss: 4.579141089611225

Epoch: 5| Step: 7
Training loss: 5.250125338556846
Validation loss: 4.574123947329548

Epoch: 5| Step: 8
Training loss: 4.5849803855085405
Validation loss: 4.569070004842585

Epoch: 5| Step: 9
Training loss: 5.2064656482011324
Validation loss: 4.565022933710156

Epoch: 5| Step: 10
Training loss: 4.207557808200689
Validation loss: 4.56002255678872

Epoch: 5| Step: 11
Training loss: 3.9669596320777174
Validation loss: 4.554911883297826

Epoch: 21| Step: 0
Training loss: 4.867760001567593
Validation loss: 4.550924300536325

Epoch: 5| Step: 1
Training loss: 4.649096222693848
Validation loss: 4.546211705543438

Epoch: 5| Step: 2
Training loss: 4.8324218197422395
Validation loss: 4.541727829734222

Epoch: 5| Step: 3
Training loss: 4.429830020717631
Validation loss: 4.537168605602291

Epoch: 5| Step: 4
Training loss: 4.9000395325603545
Validation loss: 4.532856255326371

Epoch: 5| Step: 5
Training loss: 4.47848453502619
Validation loss: 4.528291117672965

Epoch: 5| Step: 6
Training loss: 3.7592591734790286
Validation loss: 4.523716273966049

Epoch: 5| Step: 7
Training loss: 4.685794570946149
Validation loss: 4.519297108785031

Epoch: 5| Step: 8
Training loss: 4.512949642699225
Validation loss: 4.514967785872073

Epoch: 5| Step: 9
Training loss: 4.727614205371363
Validation loss: 4.510170393189849

Epoch: 5| Step: 10
Training loss: 5.049888443422847
Validation loss: 4.505444782498269

Epoch: 5| Step: 11
Training loss: 5.554885109606914
Validation loss: 4.500743067285377

Epoch: 22| Step: 0
Training loss: 4.6925113592889325
Validation loss: 4.496049360978059

Epoch: 5| Step: 1
Training loss: 4.434346112512716
Validation loss: 4.491473791950848

Epoch: 5| Step: 2
Training loss: 4.644877633411898
Validation loss: 4.4870297397177445

Epoch: 5| Step: 3
Training loss: 4.517569469768514
Validation loss: 4.482867507003185

Epoch: 5| Step: 4
Training loss: 5.1999250773387615
Validation loss: 4.476920880789953

Epoch: 5| Step: 5
Training loss: 4.516788741898433
Validation loss: 4.471915148953125

Epoch: 5| Step: 6
Training loss: 4.5859456102861635
Validation loss: 4.467441402805982

Epoch: 5| Step: 7
Training loss: 5.383999587049086
Validation loss: 4.46309527283399

Epoch: 5| Step: 8
Training loss: 4.112887313831296
Validation loss: 4.457356108166723

Epoch: 5| Step: 9
Training loss: 4.23077081533549
Validation loss: 4.45354808559878

Epoch: 5| Step: 10
Training loss: 4.346801564126275
Validation loss: 4.44900522900285

Epoch: 5| Step: 11
Training loss: 3.4038420399056997
Validation loss: 4.4443265584702685

Epoch: 23| Step: 0
Training loss: 4.575176239788154
Validation loss: 4.4401976664105725

Epoch: 5| Step: 1
Training loss: 3.969780855640407
Validation loss: 4.43631559334742

Epoch: 5| Step: 2
Training loss: 3.861718088158071
Validation loss: 4.431449198942156

Epoch: 5| Step: 3
Training loss: 5.0249450225100025
Validation loss: 4.426817671340745

Epoch: 5| Step: 4
Training loss: 4.379758590246486
Validation loss: 4.422339784528112

Epoch: 5| Step: 5
Training loss: 4.725857466141272
Validation loss: 4.418009718736764

Epoch: 5| Step: 6
Training loss: 4.963251874642529
Validation loss: 4.413179828083689

Epoch: 5| Step: 7
Training loss: 4.186015534964002
Validation loss: 4.408803411898755

Epoch: 5| Step: 8
Training loss: 4.647523626685044
Validation loss: 4.404482556902713

Epoch: 5| Step: 9
Training loss: 4.429976627124585
Validation loss: 4.399857535187173

Epoch: 5| Step: 10
Training loss: 5.0554230757648355
Validation loss: 4.395450813439746

Epoch: 5| Step: 11
Training loss: 4.572096047888557
Validation loss: 4.390758358524085

Epoch: 24| Step: 0
Training loss: 4.520763601770261
Validation loss: 4.386317120648469

Epoch: 5| Step: 1
Training loss: 4.455559316133058
Validation loss: 4.382120894990202

Epoch: 5| Step: 2
Training loss: 5.03789238170668
Validation loss: 4.377238309580814

Epoch: 5| Step: 3
Training loss: 4.24811287664244
Validation loss: 4.373091067791799

Epoch: 5| Step: 4
Training loss: 3.347626622535173
Validation loss: 4.368322926586164

Epoch: 5| Step: 5
Training loss: 4.439980686592505
Validation loss: 4.364589216217714

Epoch: 5| Step: 6
Training loss: 4.864974643997969
Validation loss: 4.359501133852076

Epoch: 5| Step: 7
Training loss: 5.185641587823841
Validation loss: 4.355362188064876

Epoch: 5| Step: 8
Training loss: 5.027186678053252
Validation loss: 4.35020930711108

Epoch: 5| Step: 9
Training loss: 3.672439466877353
Validation loss: 4.3461557902629755

Epoch: 5| Step: 10
Training loss: 4.420410345025471
Validation loss: 4.34147281555653

Epoch: 5| Step: 11
Training loss: 3.6819172641424514
Validation loss: 4.3372641564341805

Epoch: 25| Step: 0
Training loss: 4.661678963950591
Validation loss: 4.33290370620935

Epoch: 5| Step: 1
Training loss: 4.811238903925829
Validation loss: 4.328526474824033

Epoch: 5| Step: 2
Training loss: 3.4238779833613067
Validation loss: 4.324106331558282

Epoch: 5| Step: 3
Training loss: 5.330168838260224
Validation loss: 4.319778823312188

Epoch: 5| Step: 4
Training loss: 4.473202707815728
Validation loss: 4.315519952473861

Epoch: 5| Step: 5
Training loss: 4.711495184587335
Validation loss: 4.3112714049369325

Epoch: 5| Step: 6
Training loss: 4.155336207846982
Validation loss: 4.306775486132776

Epoch: 5| Step: 7
Training loss: 4.417970476900635
Validation loss: 4.3023293065404244

Epoch: 5| Step: 8
Training loss: 4.233970707247407
Validation loss: 4.29803781207685

Epoch: 5| Step: 9
Training loss: 3.807610675407999
Validation loss: 4.293817049305346

Epoch: 5| Step: 10
Training loss: 4.444952066890387
Validation loss: 4.289746399618188

Epoch: 5| Step: 11
Training loss: 4.89784716588335
Validation loss: 4.285368921919243

Epoch: 26| Step: 0
Training loss: 5.194759941832874
Validation loss: 4.28100345764876

Epoch: 5| Step: 1
Training loss: 4.0779900656406545
Validation loss: 4.27653408893611

Epoch: 5| Step: 2
Training loss: 4.632014342541141
Validation loss: 4.272100589342438

Epoch: 5| Step: 3
Training loss: 4.118053482738457
Validation loss: 4.267477217935433

Epoch: 5| Step: 4
Training loss: 4.561715463570811
Validation loss: 4.2631049531417675

Epoch: 5| Step: 5
Training loss: 5.309487060657559
Validation loss: 4.258674053787277

Epoch: 5| Step: 6
Training loss: 3.8657028893508296
Validation loss: 4.254191823107211

Epoch: 5| Step: 7
Training loss: 3.942195696071915
Validation loss: 4.249437725047253

Epoch: 5| Step: 8
Training loss: 4.0220615441513825
Validation loss: 4.245146242400186

Epoch: 5| Step: 9
Training loss: 3.9193939020683177
Validation loss: 4.240943759153428

Epoch: 5| Step: 10
Training loss: 4.329929017152487
Validation loss: 4.236522838338127

Epoch: 5| Step: 11
Training loss: 4.511457057480891
Validation loss: 4.232034343633612

Epoch: 27| Step: 0
Training loss: 4.299667505228466
Validation loss: 4.227756606558748

Epoch: 5| Step: 1
Training loss: 4.39929255953887
Validation loss: 4.223955921904616

Epoch: 5| Step: 2
Training loss: 3.399804693110171
Validation loss: 4.2195286255967055

Epoch: 5| Step: 3
Training loss: 4.829768916381459
Validation loss: 4.215991995417809

Epoch: 5| Step: 4
Training loss: 4.433860898476746
Validation loss: 4.211416001460565

Epoch: 5| Step: 5
Training loss: 4.5701361728138385
Validation loss: 4.206761976412763

Epoch: 5| Step: 6
Training loss: 4.466638666511189
Validation loss: 4.202872815892166

Epoch: 5| Step: 7
Training loss: 4.552173581599959
Validation loss: 4.198339207526369

Epoch: 5| Step: 8
Training loss: 4.023124608586085
Validation loss: 4.194080140999755

Epoch: 5| Step: 9
Training loss: 4.7756488379193165
Validation loss: 4.189915989676193

Epoch: 5| Step: 10
Training loss: 3.8167227200941016
Validation loss: 4.185276579929527

Epoch: 5| Step: 11
Training loss: 4.042146136496545
Validation loss: 4.18077645540215

Epoch: 28| Step: 0
Training loss: 3.8579145749424923
Validation loss: 4.176705681843654

Epoch: 5| Step: 1
Training loss: 4.380613159390096
Validation loss: 4.1725288954965265

Epoch: 5| Step: 2
Training loss: 3.8253451472122477
Validation loss: 4.168359377669203

Epoch: 5| Step: 3
Training loss: 4.133197845781526
Validation loss: 4.164100556143035

Epoch: 5| Step: 4
Training loss: 4.55312397786
Validation loss: 4.159820490557154

Epoch: 5| Step: 5
Training loss: 4.00690293726734
Validation loss: 4.155617280951862

Epoch: 5| Step: 6
Training loss: 4.191180760841024
Validation loss: 4.151133416221653

Epoch: 5| Step: 7
Training loss: 3.806784050217805
Validation loss: 4.147149843423404

Epoch: 5| Step: 8
Training loss: 4.1861406084076265
Validation loss: 4.1430972030535065

Epoch: 5| Step: 9
Training loss: 4.486561312031322
Validation loss: 4.138958769655671

Epoch: 5| Step: 10
Training loss: 5.162125263052546
Validation loss: 4.135099142585819

Epoch: 5| Step: 11
Training loss: 5.848324214521974
Validation loss: 4.130481940206862

Epoch: 29| Step: 0
Training loss: 4.471063188591384
Validation loss: 4.125454116639491

Epoch: 5| Step: 1
Training loss: 4.07811377512823
Validation loss: 4.120815717288564

Epoch: 5| Step: 2
Training loss: 3.777058319384898
Validation loss: 4.1163471674520755

Epoch: 5| Step: 3
Training loss: 4.888194104637648
Validation loss: 4.111963595392445

Epoch: 5| Step: 4
Training loss: 4.617496073524445
Validation loss: 4.107298013074504

Epoch: 5| Step: 5
Training loss: 4.329510738931755
Validation loss: 4.102770808423551

Epoch: 5| Step: 6
Training loss: 3.9194499873617694
Validation loss: 4.098355447265567

Epoch: 5| Step: 7
Training loss: 3.9669447269805693
Validation loss: 4.093486782279861

Epoch: 5| Step: 8
Training loss: 4.002244319719445
Validation loss: 4.089168158800998

Epoch: 5| Step: 9
Training loss: 4.493791748192504
Validation loss: 4.084471503404089

Epoch: 5| Step: 10
Training loss: 4.040155082218863
Validation loss: 4.080240925994775

Epoch: 5| Step: 11
Training loss: 3.480826311336488
Validation loss: 4.075707007432635

Epoch: 30| Step: 0
Training loss: 4.2025556781445825
Validation loss: 4.070980088052738

Epoch: 5| Step: 1
Training loss: 4.839390127677384
Validation loss: 4.066708590468594

Epoch: 5| Step: 2
Training loss: 4.305367362445434
Validation loss: 4.062213427877634

Epoch: 5| Step: 3
Training loss: 3.899851571217404
Validation loss: 4.057719175890904

Epoch: 5| Step: 4
Training loss: 4.056880879530865
Validation loss: 4.052939325382184

Epoch: 5| Step: 5
Training loss: 4.332529189005423
Validation loss: 4.048521185731053

Epoch: 5| Step: 6
Training loss: 4.2184215276494745
Validation loss: 4.044106045534625

Epoch: 5| Step: 7
Training loss: 4.103840977999157
Validation loss: 4.039718805802015

Epoch: 5| Step: 8
Training loss: 4.12951390063552
Validation loss: 4.035226496934061

Epoch: 5| Step: 9
Training loss: 3.634816263164862
Validation loss: 4.030726766020786

Epoch: 5| Step: 10
Training loss: 4.366329211137119
Validation loss: 4.026696928654779

Epoch: 5| Step: 11
Training loss: 3.1011456802824457
Validation loss: 4.0221935830727125

Epoch: 31| Step: 0
Training loss: 4.252327674276062
Validation loss: 4.017932748234586

Epoch: 5| Step: 1
Training loss: 3.865454206340243
Validation loss: 4.013868073728826

Epoch: 5| Step: 2
Training loss: 4.295098398700151
Validation loss: 4.009674348704315

Epoch: 5| Step: 3
Training loss: 3.791345911117716
Validation loss: 4.00534392558514

Epoch: 5| Step: 4
Training loss: 4.3492995564193695
Validation loss: 4.001260330407725

Epoch: 5| Step: 5
Training loss: 3.739587186990238
Validation loss: 3.9968054750712207

Epoch: 5| Step: 6
Training loss: 3.8012910757758918
Validation loss: 3.99261337964872

Epoch: 5| Step: 7
Training loss: 4.40494469321059
Validation loss: 3.9885623495316684

Epoch: 5| Step: 8
Training loss: 4.482758233907668
Validation loss: 3.9842119171077206

Epoch: 5| Step: 9
Training loss: 4.5457114077731315
Validation loss: 3.9800271789782515

Epoch: 5| Step: 10
Training loss: 3.6648921718582192
Validation loss: 3.9755109984355657

Epoch: 5| Step: 11
Training loss: 4.611764475993028
Validation loss: 3.971139949169866

Epoch: 32| Step: 0
Training loss: 3.4065800778108954
Validation loss: 3.966921768213297

Epoch: 5| Step: 1
Training loss: 4.190786410074281
Validation loss: 3.9627141736189784

Epoch: 5| Step: 2
Training loss: 4.882203086970254
Validation loss: 3.9582365258408614

Epoch: 5| Step: 3
Training loss: 3.732334233746686
Validation loss: 3.9540205030422637

Epoch: 5| Step: 4
Training loss: 3.9361221082401094
Validation loss: 3.9495681069861948

Epoch: 5| Step: 5
Training loss: 4.2383546040599125
Validation loss: 3.9450598053534818

Epoch: 5| Step: 6
Training loss: 3.9450336622148487
Validation loss: 3.9408780598792865

Epoch: 5| Step: 7
Training loss: 4.505865301253147
Validation loss: 3.936618484236662

Epoch: 5| Step: 8
Training loss: 3.8228806053075375
Validation loss: 3.932331578471095

Epoch: 5| Step: 9
Training loss: 4.0093779304475845
Validation loss: 3.9277450128882623

Epoch: 5| Step: 10
Training loss: 4.116082233122791
Validation loss: 3.9236431923213946

Epoch: 5| Step: 11
Training loss: 3.501453642746779
Validation loss: 3.919192086713988

Epoch: 33| Step: 0
Training loss: 4.1113274291121735
Validation loss: 3.9148897374241542

Epoch: 5| Step: 1
Training loss: 4.256461896957263
Validation loss: 3.910529257010956

Epoch: 5| Step: 2
Training loss: 3.552817320104452
Validation loss: 3.905958464869628

Epoch: 5| Step: 3
Training loss: 4.624418067406774
Validation loss: 3.9016079850219616

Epoch: 5| Step: 4
Training loss: 3.5764132073984
Validation loss: 3.897299137196343

Epoch: 5| Step: 5
Training loss: 3.944039621010987
Validation loss: 3.892589303023103

Epoch: 5| Step: 6
Training loss: 4.137638958674832
Validation loss: 3.8882347894638944

Epoch: 5| Step: 7
Training loss: 3.503394932687767
Validation loss: 3.883937317139415

Epoch: 5| Step: 8
Training loss: 4.011848544181981
Validation loss: 3.87975627476151

Epoch: 5| Step: 9
Training loss: 4.125404106922152
Validation loss: 3.875342389844003

Epoch: 5| Step: 10
Training loss: 4.447579126109822
Validation loss: 3.8711991383988

Epoch: 5| Step: 11
Training loss: 3.2118477006959436
Validation loss: 3.866992239084505

Epoch: 34| Step: 0
Training loss: 3.912751791167524
Validation loss: 3.862694726950901

Epoch: 5| Step: 1
Training loss: 3.4633817631037314
Validation loss: 3.8584181697298736

Epoch: 5| Step: 2
Training loss: 3.7933979204128816
Validation loss: 3.854307639490786

Epoch: 5| Step: 3
Training loss: 3.6269523361772165
Validation loss: 3.8503932712800357

Epoch: 5| Step: 4
Training loss: 3.7559820146221465
Validation loss: 3.846317854985162

Epoch: 5| Step: 5
Training loss: 4.406013861206249
Validation loss: 3.8423074946334057

Epoch: 5| Step: 6
Training loss: 3.7141536228041327
Validation loss: 3.8383847708795384

Epoch: 5| Step: 7
Training loss: 4.593554849436889
Validation loss: 3.834185203284133

Epoch: 5| Step: 8
Training loss: 4.108454960279415
Validation loss: 3.830056716467463

Epoch: 5| Step: 9
Training loss: 4.017742860167844
Validation loss: 3.825504625812819

Epoch: 5| Step: 10
Training loss: 4.253714789223255
Validation loss: 3.821258687783247

Epoch: 5| Step: 11
Training loss: 3.6327170738894905
Validation loss: 3.8168012713277277

Epoch: 35| Step: 0
Training loss: 3.7797388257014712
Validation loss: 3.8127074419712628

Epoch: 5| Step: 1
Training loss: 3.753075546459741
Validation loss: 3.8082530751247323

Epoch: 5| Step: 2
Training loss: 4.3647261833661135
Validation loss: 3.8041990672915165

Epoch: 5| Step: 3
Training loss: 3.6767539218106906
Validation loss: 3.7998449434049792

Epoch: 5| Step: 4
Training loss: 3.7012803517249853
Validation loss: 3.7956734104713554

Epoch: 5| Step: 5
Training loss: 3.9240574330628846
Validation loss: 3.7914208482699308

Epoch: 5| Step: 6
Training loss: 4.158275598241143
Validation loss: 3.787247144905807

Epoch: 5| Step: 7
Training loss: 3.961204865891562
Validation loss: 3.783174860291857

Epoch: 5| Step: 8
Training loss: 3.9724616769198877
Validation loss: 3.7787101401867154

Epoch: 5| Step: 9
Training loss: 4.0493924474068
Validation loss: 3.7742495666690306

Epoch: 5| Step: 10
Training loss: 3.8863084739489606
Validation loss: 3.769882486216864

Epoch: 5| Step: 11
Training loss: 3.449944321556274
Validation loss: 3.765558418962149

Epoch: 36| Step: 0
Training loss: 3.7251102968822263
Validation loss: 3.76126888195609

Epoch: 5| Step: 1
Training loss: 3.3521069349015606
Validation loss: 3.757216545745093

Epoch: 5| Step: 2
Training loss: 4.105531004225903
Validation loss: 3.753064392303493

Epoch: 5| Step: 3
Training loss: 3.6730464284171003
Validation loss: 3.748843274263617

Epoch: 5| Step: 4
Training loss: 3.5917011557307545
Validation loss: 3.7447579726753517

Epoch: 5| Step: 5
Training loss: 4.137297362006981
Validation loss: 3.7404945063954136

Epoch: 5| Step: 6
Training loss: 3.7157863058972795
Validation loss: 3.736437638906714

Epoch: 5| Step: 7
Training loss: 4.253617934587833
Validation loss: 3.7321530226475366

Epoch: 5| Step: 8
Training loss: 4.030581396680096
Validation loss: 3.7282695259417333

Epoch: 5| Step: 9
Training loss: 3.617770648525419
Validation loss: 3.7238865914358965

Epoch: 5| Step: 10
Training loss: 4.138900916119765
Validation loss: 3.71983150174915

Epoch: 5| Step: 11
Training loss: 4.702737684555277
Validation loss: 3.715588462570807

Epoch: 37| Step: 0
Training loss: 3.6789181951919048
Validation loss: 3.711072990219469

Epoch: 5| Step: 1
Training loss: 3.9264104993600535
Validation loss: 3.7067905745847805

Epoch: 5| Step: 2
Training loss: 3.5685636882617318
Validation loss: 3.7024466567969485

Epoch: 5| Step: 3
Training loss: 4.403850145373395
Validation loss: 3.6981504751444083

Epoch: 5| Step: 4
Training loss: 3.6940175019300368
Validation loss: 3.693859618529595

Epoch: 5| Step: 5
Training loss: 3.775467668073837
Validation loss: 3.689344392072548

Epoch: 5| Step: 6
Training loss: 3.9779446041801263
Validation loss: 3.6849370713729064

Epoch: 5| Step: 7
Training loss: 3.3746699419049673
Validation loss: 3.6805251262214633

Epoch: 5| Step: 8
Training loss: 3.0119570230910924
Validation loss: 3.6762380339803795

Epoch: 5| Step: 9
Training loss: 3.861061252909394
Validation loss: 3.672168081504535

Epoch: 5| Step: 10
Training loss: 4.499195026878984
Validation loss: 3.6680424540315144

Epoch: 5| Step: 11
Training loss: 4.20062862414814
Validation loss: 3.663863181391227

Epoch: 38| Step: 0
Training loss: 3.422395292119609
Validation loss: 3.659312647356983

Epoch: 5| Step: 1
Training loss: 3.972523014681331
Validation loss: 3.6551846530712906

Epoch: 5| Step: 2
Training loss: 4.045901148208421
Validation loss: 3.650817089638226

Epoch: 5| Step: 3
Training loss: 3.8995726620247932
Validation loss: 3.6467278100791742

Epoch: 5| Step: 4
Training loss: 3.7864786363535727
Validation loss: 3.6426057679846435

Epoch: 5| Step: 5
Training loss: 3.5761566745137086
Validation loss: 3.638369859115127

Epoch: 5| Step: 6
Training loss: 4.198549410681106
Validation loss: 3.6346548843527504

Epoch: 5| Step: 7
Training loss: 3.796737605619178
Validation loss: 3.629855811554291

Epoch: 5| Step: 8
Training loss: 3.7717819847135865
Validation loss: 3.6254783512069397

Epoch: 5| Step: 9
Training loss: 3.5458291818405456
Validation loss: 3.6213980625403095

Epoch: 5| Step: 10
Training loss: 3.526876255963332
Validation loss: 3.617037177481113

Epoch: 5| Step: 11
Training loss: 3.278154493404695
Validation loss: 3.6129320295503846

Epoch: 39| Step: 0
Training loss: 3.635995696699997
Validation loss: 3.609172017168301

Epoch: 5| Step: 1
Training loss: 3.994099437249432
Validation loss: 3.6049154400530905

Epoch: 5| Step: 2
Training loss: 4.225366447854238
Validation loss: 3.6009069964704756

Epoch: 5| Step: 3
Training loss: 2.7055016802315683
Validation loss: 3.5966161245322006

Epoch: 5| Step: 4
Training loss: 4.1897057943911395
Validation loss: 3.5926275573627926

Epoch: 5| Step: 5
Training loss: 3.235451929048037
Validation loss: 3.5886894310074435

Epoch: 5| Step: 6
Training loss: 3.5659274294791827
Validation loss: 3.584614716828155

Epoch: 5| Step: 7
Training loss: 4.035543358579438
Validation loss: 3.580484597841577

Epoch: 5| Step: 8
Training loss: 3.741725439163724
Validation loss: 3.57657511986511

Epoch: 5| Step: 9
Training loss: 3.6391040424548904
Validation loss: 3.5727716625954624

Epoch: 5| Step: 10
Training loss: 3.7773310001319853
Validation loss: 3.5685731308416817

Epoch: 5| Step: 11
Training loss: 3.635278402211373
Validation loss: 3.564662600419414

Epoch: 40| Step: 0
Training loss: 4.084100197126169
Validation loss: 3.5605944673723315

Epoch: 5| Step: 1
Training loss: 3.7262461785953023
Validation loss: 3.556533920807423

Epoch: 5| Step: 2
Training loss: 3.658266212583347
Validation loss: 3.5524564959076796

Epoch: 5| Step: 3
Training loss: 3.4043649479532214
Validation loss: 3.548219378391361

Epoch: 5| Step: 4
Training loss: 3.618071149490214
Validation loss: 3.5443645280855853

Epoch: 5| Step: 5
Training loss: 3.0561362340928864
Validation loss: 3.540300176702689

Epoch: 5| Step: 6
Training loss: 3.2974526138892015
Validation loss: 3.536481419948154

Epoch: 5| Step: 7
Training loss: 3.599935499249241
Validation loss: 3.532456425422578

Epoch: 5| Step: 8
Training loss: 3.948761473008383
Validation loss: 3.528873561065612

Epoch: 5| Step: 9
Training loss: 4.220377290320885
Validation loss: 3.524766957355574

Epoch: 5| Step: 10
Training loss: 3.749302099771578
Validation loss: 3.52084322181231

Epoch: 5| Step: 11
Training loss: 3.3910730303249252
Validation loss: 3.516718613811898

Epoch: 41| Step: 0
Training loss: 3.5674485754785703
Validation loss: 3.512931899897877

Epoch: 5| Step: 1
Training loss: 3.883395299021452
Validation loss: 3.508950748995204

Epoch: 5| Step: 2
Training loss: 3.424326397445944
Validation loss: 3.505062931591443

Epoch: 5| Step: 3
Training loss: 3.4899820280295484
Validation loss: 3.501144034877118

Epoch: 5| Step: 4
Training loss: 3.9544728510618397
Validation loss: 3.4971585376685446

Epoch: 5| Step: 5
Training loss: 3.7238608749903883
Validation loss: 3.493434936384182

Epoch: 5| Step: 6
Training loss: 2.924369196240935
Validation loss: 3.489550016253639

Epoch: 5| Step: 7
Training loss: 3.657521866206985
Validation loss: 3.4858292024080146

Epoch: 5| Step: 8
Training loss: 3.6210973054442497
Validation loss: 3.481833108113473

Epoch: 5| Step: 9
Training loss: 3.7664428076149874
Validation loss: 3.4779030833320497

Epoch: 5| Step: 10
Training loss: 3.8125510290514266
Validation loss: 3.4739926158732852

Epoch: 5| Step: 11
Training loss: 3.6792899076932652
Validation loss: 3.469880025962639

Epoch: 42| Step: 0
Training loss: 2.8954875565796545
Validation loss: 3.465976058428592

Epoch: 5| Step: 1
Training loss: 3.7734229677919573
Validation loss: 3.462382649936059

Epoch: 5| Step: 2
Training loss: 3.6480947982952188
Validation loss: 3.4588762492952303

Epoch: 5| Step: 3
Training loss: 3.237783211946636
Validation loss: 3.454873811622845

Epoch: 5| Step: 4
Training loss: 3.890392005408904
Validation loss: 3.4512082011468634

Epoch: 5| Step: 5
Training loss: 3.7053796527855085
Validation loss: 3.447703897570656

Epoch: 5| Step: 6
Training loss: 3.4583441186453308
Validation loss: 3.4438210197921144

Epoch: 5| Step: 7
Training loss: 3.248034249543261
Validation loss: 3.4398568425682763

Epoch: 5| Step: 8
Training loss: 3.949157533256067
Validation loss: 3.4360223484130374

Epoch: 5| Step: 9
Training loss: 3.8269728814752364
Validation loss: 3.4324538270253173

Epoch: 5| Step: 10
Training loss: 3.8778457036911282
Validation loss: 3.4284475832570567

Epoch: 5| Step: 11
Training loss: 2.1807552443291165
Validation loss: 3.424374046694558

Epoch: 43| Step: 0
Training loss: 3.9952080156122904
Validation loss: 3.4212547796901496

Epoch: 5| Step: 1
Training loss: 2.8070732319530105
Validation loss: 3.4177917957821085

Epoch: 5| Step: 2
Training loss: 3.6286055950534393
Validation loss: 3.414508455831418

Epoch: 5| Step: 3
Training loss: 3.0427495169842538
Validation loss: 3.4111379438991998

Epoch: 5| Step: 4
Training loss: 3.119711100578741
Validation loss: 3.407944517334695

Epoch: 5| Step: 5
Training loss: 3.555053289687384
Validation loss: 3.404565499629041

Epoch: 5| Step: 6
Training loss: 3.448788228281098
Validation loss: 3.401401165845349

Epoch: 5| Step: 7
Training loss: 4.1331775410322455
Validation loss: 3.3981325034598417

Epoch: 5| Step: 8
Training loss: 3.4640524733711877
Validation loss: 3.394483331094053

Epoch: 5| Step: 9
Training loss: 3.950013032722702
Validation loss: 3.3910067207176455

Epoch: 5| Step: 10
Training loss: 3.3040083960733577
Validation loss: 3.387443901901921

Epoch: 5| Step: 11
Training loss: 4.726668629361181
Validation loss: 3.3838347196595087

Epoch: 44| Step: 0
Training loss: 4.022839192468055
Validation loss: 3.3799884099592323

Epoch: 5| Step: 1
Training loss: 3.3859458314153237
Validation loss: 3.375814728062145

Epoch: 5| Step: 2
Training loss: 3.30203176432072
Validation loss: 3.3718941078434206

Epoch: 5| Step: 3
Training loss: 3.924182228375617
Validation loss: 3.368102548977098

Epoch: 5| Step: 4
Training loss: 3.1552259842454573
Validation loss: 3.3641528847271696

Epoch: 5| Step: 5
Training loss: 3.6176451688056432
Validation loss: 3.3604131173960385

Epoch: 5| Step: 6
Training loss: 3.229869560938378
Validation loss: 3.356364061535503

Epoch: 5| Step: 7
Training loss: 2.4770698869969614
Validation loss: 3.3526154044682355

Epoch: 5| Step: 8
Training loss: 3.44487429230306
Validation loss: 3.349064682398617

Epoch: 5| Step: 9
Training loss: 3.7505865274142898
Validation loss: 3.345350726100909

Epoch: 5| Step: 10
Training loss: 4.046607284822451
Validation loss: 3.341902587930853

Epoch: 5| Step: 11
Training loss: 2.6776154183551606
Validation loss: 3.338140476459718

Epoch: 45| Step: 0
Training loss: 3.470154349112592
Validation loss: 3.3346579760833888

Epoch: 5| Step: 1
Training loss: 3.6013477451733316
Validation loss: 3.3312204588677052

Epoch: 5| Step: 2
Training loss: 3.4981199392146145
Validation loss: 3.3277511685216288

Epoch: 5| Step: 3
Training loss: 3.6753258904484887
Validation loss: 3.3243947503625066

Epoch: 5| Step: 4
Training loss: 3.2740204139590374
Validation loss: 3.3206448497115515

Epoch: 5| Step: 5
Training loss: 3.2010658158147476
Validation loss: 3.317019552278821

Epoch: 5| Step: 6
Training loss: 3.1972105922168916
Validation loss: 3.313762202394501

Epoch: 5| Step: 7
Training loss: 3.6326423851298917
Validation loss: 3.310337362345811

Epoch: 5| Step: 8
Training loss: 2.788457724773521
Validation loss: 3.307182443372142

Epoch: 5| Step: 9
Training loss: 3.554516597454167
Validation loss: 3.303434598880137

Epoch: 5| Step: 10
Training loss: 3.815496923998049
Validation loss: 3.300176248275045

Epoch: 5| Step: 11
Training loss: 4.373429806815983
Validation loss: 3.296571946641202

Epoch: 46| Step: 0
Training loss: 3.7955043500810763
Validation loss: 3.293041453194335

Epoch: 5| Step: 1
Training loss: 3.796014884573854
Validation loss: 3.2892081318295303

Epoch: 5| Step: 2
Training loss: 2.963956154708793
Validation loss: 3.28587202574371

Epoch: 5| Step: 3
Training loss: 3.524322330996589
Validation loss: 3.2823412700275743

Epoch: 5| Step: 4
Training loss: 3.4828849309181322
Validation loss: 3.2786056156534884

Epoch: 5| Step: 5
Training loss: 3.4293657642905466
Validation loss: 3.275196310037079

Epoch: 5| Step: 6
Training loss: 3.4176784195889645
Validation loss: 3.271615352001473

Epoch: 5| Step: 7
Training loss: 2.731625116981487
Validation loss: 3.2679948071754095

Epoch: 5| Step: 8
Training loss: 3.83872558208365
Validation loss: 3.2647989922825658

Epoch: 5| Step: 9
Training loss: 3.4243169284386634
Validation loss: 3.261204229345347

Epoch: 5| Step: 10
Training loss: 2.7943983993966897
Validation loss: 3.257798771939829

Epoch: 5| Step: 11
Training loss: 4.15287379760192
Validation loss: 3.2545333874653757

Epoch: 47| Step: 0
Training loss: 3.679167044536244
Validation loss: 3.251024958795657

Epoch: 5| Step: 1
Training loss: 3.4760423592641154
Validation loss: 3.247456435571359

Epoch: 5| Step: 2
Training loss: 3.462028796362159
Validation loss: 3.2441225765246022

Epoch: 5| Step: 3
Training loss: 2.5388526242887095
Validation loss: 3.24051141886246

Epoch: 5| Step: 4
Training loss: 2.8196439928200756
Validation loss: 3.2370071941869702

Epoch: 5| Step: 5
Training loss: 3.3118639641250542
Validation loss: 3.23381478376835

Epoch: 5| Step: 6
Training loss: 3.8328651197563834
Validation loss: 3.230584674125229

Epoch: 5| Step: 7
Training loss: 3.5835780274582882
Validation loss: 3.2274100458210415

Epoch: 5| Step: 8
Training loss: 3.423920320617651
Validation loss: 3.2241139022605982

Epoch: 5| Step: 9
Training loss: 2.567381605261936
Validation loss: 3.2208182285607707

Epoch: 5| Step: 10
Training loss: 3.968877835355059
Validation loss: 3.217521186013905

Epoch: 5| Step: 11
Training loss: 3.860158987378229
Validation loss: 3.214282815417239

Epoch: 48| Step: 0
Training loss: 2.815411904047634
Validation loss: 3.210781864004881

Epoch: 5| Step: 1
Training loss: 4.054743242707511
Validation loss: 3.207506064897107

Epoch: 5| Step: 2
Training loss: 3.4078399027440205
Validation loss: 3.2040713951289725

Epoch: 5| Step: 3
Training loss: 3.6747485016383052
Validation loss: 3.200609711338191

Epoch: 5| Step: 4
Training loss: 3.360260318935237
Validation loss: 3.1970638148537565

Epoch: 5| Step: 5
Training loss: 2.9351016053998875
Validation loss: 3.193463437934755

Epoch: 5| Step: 6
Training loss: 3.5690719485994933
Validation loss: 3.1903192855030924

Epoch: 5| Step: 7
Training loss: 2.830037687340502
Validation loss: 3.187035732491497

Epoch: 5| Step: 8
Training loss: 3.089741740128278
Validation loss: 3.1837502719962405

Epoch: 5| Step: 9
Training loss: 3.633490386391643
Validation loss: 3.180769034240405

Epoch: 5| Step: 10
Training loss: 3.1172789749070358
Validation loss: 3.177453702173659

Epoch: 5| Step: 11
Training loss: 3.1924609305695335
Validation loss: 3.174316856901791

Epoch: 49| Step: 0
Training loss: 2.7996757592066714
Validation loss: 3.170939688124935

Epoch: 5| Step: 1
Training loss: 3.074305144166044
Validation loss: 3.1679368901404783

Epoch: 5| Step: 2
Training loss: 2.9650068275926276
Validation loss: 3.164954379246595

Epoch: 5| Step: 3
Training loss: 3.900574245724741
Validation loss: 3.1620009374060176

Epoch: 5| Step: 4
Training loss: 3.7920516660526524
Validation loss: 3.1588341800637103

Epoch: 5| Step: 5
Training loss: 3.1120186307099353
Validation loss: 3.1556884152709386

Epoch: 5| Step: 6
Training loss: 3.296051067067795
Validation loss: 3.152658704412737

Epoch: 5| Step: 7
Training loss: 2.977404858200549
Validation loss: 3.1494318935471086

Epoch: 5| Step: 8
Training loss: 3.51785153560731
Validation loss: 3.1465984018361146

Epoch: 5| Step: 9
Training loss: 3.427660784243864
Validation loss: 3.143381683433522

Epoch: 5| Step: 10
Training loss: 3.3175391968033567
Validation loss: 3.140387290448394

Epoch: 5| Step: 11
Training loss: 2.7876044557441375
Validation loss: 3.1371726930473227

Epoch: 50| Step: 0
Training loss: 2.9258902800633586
Validation loss: 3.1343554520559995

Epoch: 5| Step: 1
Training loss: 3.141685648354038
Validation loss: 3.1314008549526915

Epoch: 5| Step: 2
Training loss: 3.5280708248010004
Validation loss: 3.1285824459321137

Epoch: 5| Step: 3
Training loss: 2.9720950906566355
Validation loss: 3.125675147557626

Epoch: 5| Step: 4
Training loss: 3.6416167516946567
Validation loss: 3.1228079800888153

Epoch: 5| Step: 5
Training loss: 3.001704844207825
Validation loss: 3.1200139322642277

Epoch: 5| Step: 6
Training loss: 3.342121333697398
Validation loss: 3.1172417816815345

Epoch: 5| Step: 7
Training loss: 3.6437097668266833
Validation loss: 3.1142985725147803

Epoch: 5| Step: 8
Training loss: 3.4857168308177293
Validation loss: 3.1113100787715227

Epoch: 5| Step: 9
Training loss: 2.9773212577152415
Validation loss: 3.1084010549349106

Epoch: 5| Step: 10
Training loss: 2.989895971523462
Validation loss: 3.1054465942872036

Epoch: 5| Step: 11
Training loss: 3.7266681904070293
Validation loss: 3.1025746229113227

Epoch: 51| Step: 0
Training loss: 3.468167917711646
Validation loss: 3.0995320961702615

Epoch: 5| Step: 1
Training loss: 3.0365475640945903
Validation loss: 3.0963154537175313

Epoch: 5| Step: 2
Training loss: 3.4160851394620875
Validation loss: 3.0933676396685965

Epoch: 5| Step: 3
Training loss: 2.878139440311817
Validation loss: 3.0903956695576418

Epoch: 5| Step: 4
Training loss: 2.820633043158957
Validation loss: 3.0875536907536754

Epoch: 5| Step: 5
Training loss: 3.3345241009196886
Validation loss: 3.084836964794524

Epoch: 5| Step: 6
Training loss: 3.5123621740485436
Validation loss: 3.082112661365438

Epoch: 5| Step: 7
Training loss: 3.4462313648559912
Validation loss: 3.0792313119006804

Epoch: 5| Step: 8
Training loss: 3.168211526658049
Validation loss: 3.0762577589852493

Epoch: 5| Step: 9
Training loss: 3.137108195488354
Validation loss: 3.073325486655848

Epoch: 5| Step: 10
Training loss: 3.24914935790705
Validation loss: 3.070532997114933

Epoch: 5| Step: 11
Training loss: 2.893355281266089
Validation loss: 3.067552767675149

Epoch: 52| Step: 0
Training loss: 2.9842855230369314
Validation loss: 3.064714176298765

Epoch: 5| Step: 1
Training loss: 2.7638257742043457
Validation loss: 3.0619521137532058

Epoch: 5| Step: 2
Training loss: 2.5180837805568186
Validation loss: 3.059265485186045

Epoch: 5| Step: 3
Training loss: 3.1178776256729313
Validation loss: 3.0566198638763455

Epoch: 5| Step: 4
Training loss: 3.1776938597025377
Validation loss: 3.054204800217222

Epoch: 5| Step: 5
Training loss: 3.4047520694851023
Validation loss: 3.0515708829468697

Epoch: 5| Step: 6
Training loss: 3.482286314751456
Validation loss: 3.0491963501613353

Epoch: 5| Step: 7
Training loss: 3.1641450847632826
Validation loss: 3.046571615389843

Epoch: 5| Step: 8
Training loss: 3.767775811703868
Validation loss: 3.044010548794627

Epoch: 5| Step: 9
Training loss: 3.233459637983556
Validation loss: 3.0413267694712105

Epoch: 5| Step: 10
Training loss: 3.012264929499589
Validation loss: 3.0386318565238044

Epoch: 5| Step: 11
Training loss: 4.474348069765479
Validation loss: 3.0359017411091163

Epoch: 53| Step: 0
Training loss: 3.0152872321364605
Validation loss: 3.0327789082043375

Epoch: 5| Step: 1
Training loss: 3.1267286478608143
Validation loss: 3.0297908482688944

Epoch: 5| Step: 2
Training loss: 2.6301973751834433
Validation loss: 3.026780218362407

Epoch: 5| Step: 3
Training loss: 3.071157868074314
Validation loss: 3.024014656908099

Epoch: 5| Step: 4
Training loss: 3.6469224156923192
Validation loss: 3.0213384052600474

Epoch: 5| Step: 5
Training loss: 3.09192673102617
Validation loss: 3.0183529777684512

Epoch: 5| Step: 6
Training loss: 2.926775082323089
Validation loss: 3.015662049772531

Epoch: 5| Step: 7
Training loss: 2.6026707943325977
Validation loss: 3.0128360692739653

Epoch: 5| Step: 8
Training loss: 3.2051905973181563
Validation loss: 3.0100835574075644

Epoch: 5| Step: 9
Training loss: 3.3402576212408115
Validation loss: 3.007555989478622

Epoch: 5| Step: 10
Training loss: 3.874238216215085
Validation loss: 3.0048423304004075

Epoch: 5| Step: 11
Training loss: 3.1521203246701623
Validation loss: 3.0017288478314583

Epoch: 54| Step: 0
Training loss: 2.913769418331788
Validation loss: 2.998708658976272

Epoch: 5| Step: 1
Training loss: 3.064516765840526
Validation loss: 2.99560369125185

Epoch: 5| Step: 2
Training loss: 2.6271065933040836
Validation loss: 2.992751205372713

Epoch: 5| Step: 3
Training loss: 2.9172896855115185
Validation loss: 2.9901791398660875

Epoch: 5| Step: 4
Training loss: 2.841361079933358
Validation loss: 2.987680834453973

Epoch: 5| Step: 5
Training loss: 3.3992735086570653
Validation loss: 2.9854586299938277

Epoch: 5| Step: 6
Training loss: 2.9752144551918143
Validation loss: 2.9828796035468272

Epoch: 5| Step: 7
Training loss: 3.4790699349545546
Validation loss: 2.9804761427374764

Epoch: 5| Step: 8
Training loss: 3.2607201058233297
Validation loss: 2.9776596223423377

Epoch: 5| Step: 9
Training loss: 3.3825721567243434
Validation loss: 2.9753491255587323

Epoch: 5| Step: 10
Training loss: 3.1494219355521746
Validation loss: 2.9726236436002185

Epoch: 5| Step: 11
Training loss: 4.263590904092575
Validation loss: 2.97024699832373

Epoch: 55| Step: 0
Training loss: 3.528842206419842
Validation loss: 2.9676746361585593

Epoch: 5| Step: 1
Training loss: 2.6255725054633916
Validation loss: 2.96524235823117

Epoch: 5| Step: 2
Training loss: 2.991436976237389
Validation loss: 2.962619971141107

Epoch: 5| Step: 3
Training loss: 3.234332835341859
Validation loss: 2.9601123133016554

Epoch: 5| Step: 4
Training loss: 2.7796230057797864
Validation loss: 2.957688873684502

Epoch: 5| Step: 5
Training loss: 3.0655710820269624
Validation loss: 2.95541022956463

Epoch: 5| Step: 6
Training loss: 3.2191277439714683
Validation loss: 2.9530339437235407

Epoch: 5| Step: 7
Training loss: 2.936674935556202
Validation loss: 2.9504173790397012

Epoch: 5| Step: 8
Training loss: 3.626285982581327
Validation loss: 2.9482619124977614

Epoch: 5| Step: 9
Training loss: 2.942057219632846
Validation loss: 2.945792377480381

Epoch: 5| Step: 10
Training loss: 2.990709542381963
Validation loss: 2.94339409773743

Epoch: 5| Step: 11
Training loss: 3.0408310635126923
Validation loss: 2.941053625199009

Epoch: 56| Step: 0
Training loss: 2.8060839903395345
Validation loss: 2.938486200859648

Epoch: 5| Step: 1
Training loss: 2.947022606883666
Validation loss: 2.936322950363928

Epoch: 5| Step: 2
Training loss: 3.441460841738538
Validation loss: 2.934171397113174

Epoch: 5| Step: 3
Training loss: 2.923498182212352
Validation loss: 2.9318634260289755

Epoch: 5| Step: 4
Training loss: 2.731669106178831
Validation loss: 2.929636864118619

Epoch: 5| Step: 5
Training loss: 3.4280223236425402
Validation loss: 2.927396161387597

Epoch: 5| Step: 6
Training loss: 2.90514639953345
Validation loss: 2.924820117771754

Epoch: 5| Step: 7
Training loss: 2.5864953306647465
Validation loss: 2.9220734051203436

Epoch: 5| Step: 8
Training loss: 2.613251325267754
Validation loss: 2.9198782893131194

Epoch: 5| Step: 9
Training loss: 3.764990028884876
Validation loss: 2.9171247883182123

Epoch: 5| Step: 10
Training loss: 3.2457564599887334
Validation loss: 2.9148446500134892

Epoch: 5| Step: 11
Training loss: 3.599207043737407
Validation loss: 2.912942741098003

Epoch: 57| Step: 0
Training loss: 2.6940823166355914
Validation loss: 2.910291531211222

Epoch: 5| Step: 1
Training loss: 2.9266932941462263
Validation loss: 2.907588971603417

Epoch: 5| Step: 2
Training loss: 2.8195261189156953
Validation loss: 2.904965667237213

Epoch: 5| Step: 3
Training loss: 3.3287997569176904
Validation loss: 2.9026030248811643

Epoch: 5| Step: 4
Training loss: 3.2766442808497076
Validation loss: 2.9001317928774992

Epoch: 5| Step: 5
Training loss: 3.325984642686101
Validation loss: 2.8979210406301705

Epoch: 5| Step: 6
Training loss: 3.409695064300993
Validation loss: 2.89613151158646

Epoch: 5| Step: 7
Training loss: 3.1397141991071726
Validation loss: 2.893698081202359

Epoch: 5| Step: 8
Training loss: 2.3969887200425517
Validation loss: 2.891499089919599

Epoch: 5| Step: 9
Training loss: 3.0796525137436714
Validation loss: 2.8891961492664984

Epoch: 5| Step: 10
Training loss: 2.8546498764390043
Validation loss: 2.8869765686614404

Epoch: 5| Step: 11
Training loss: 3.2285250774967493
Validation loss: 2.8848693284920395

Epoch: 58| Step: 0
Training loss: 3.4840008316652202
Validation loss: 2.8830371586513976

Epoch: 5| Step: 1
Training loss: 2.8037847484624154
Validation loss: 2.881094040445768

Epoch: 5| Step: 2
Training loss: 3.2456594973148007
Validation loss: 2.878945504364758

Epoch: 5| Step: 3
Training loss: 2.6816043504010514
Validation loss: 2.8770634978980474

Epoch: 5| Step: 4
Training loss: 2.8310934263475827
Validation loss: 2.874882526347327

Epoch: 5| Step: 5
Training loss: 3.31070963141587
Validation loss: 2.8729923052071196

Epoch: 5| Step: 6
Training loss: 3.0153169622871556
Validation loss: 2.871025465241908

Epoch: 5| Step: 7
Training loss: 2.646018304641855
Validation loss: 2.8689974962737472

Epoch: 5| Step: 8
Training loss: 3.1480379442693462
Validation loss: 2.8668798408054386

Epoch: 5| Step: 9
Training loss: 3.153774990688862
Validation loss: 2.864965632966515

Epoch: 5| Step: 10
Training loss: 2.760860584960092
Validation loss: 2.8630960776702916

Epoch: 5| Step: 11
Training loss: 2.941171502501836
Validation loss: 2.861183299976924

Epoch: 59| Step: 0
Training loss: 3.0754051003684166
Validation loss: 2.859715220877293

Epoch: 5| Step: 1
Training loss: 3.31784159553894
Validation loss: 2.8581591750258895

Epoch: 5| Step: 2
Training loss: 2.8580370831976807
Validation loss: 2.8566530296681965

Epoch: 5| Step: 3
Training loss: 3.2326428479039393
Validation loss: 2.8550575889217313

Epoch: 5| Step: 4
Training loss: 2.788712850927682
Validation loss: 2.8534176457385967

Epoch: 5| Step: 5
Training loss: 3.434995536523665
Validation loss: 2.8520117209903897

Epoch: 5| Step: 6
Training loss: 2.6147087543289786
Validation loss: 2.850135522821448

Epoch: 5| Step: 7
Training loss: 3.3410158476466516
Validation loss: 2.8483145902994287

Epoch: 5| Step: 8
Training loss: 2.8195979938339217
Validation loss: 2.846497535875814

Epoch: 5| Step: 9
Training loss: 2.6581299356199035
Validation loss: 2.844568637768778

Epoch: 5| Step: 10
Training loss: 2.6688632163839596
Validation loss: 2.8428573185417925

Epoch: 5| Step: 11
Training loss: 2.858453487469554
Validation loss: 2.8411233075324405

Epoch: 60| Step: 0
Training loss: 3.0872551145233977
Validation loss: 2.839434055892861

Epoch: 5| Step: 1
Training loss: 3.1005356479681523
Validation loss: 2.837699216831695

Epoch: 5| Step: 2
Training loss: 2.8377575459161934
Validation loss: 2.8360610248436773

Epoch: 5| Step: 3
Training loss: 3.4429468177147053
Validation loss: 2.834482805977019

Epoch: 5| Step: 4
Training loss: 2.4175846614431853
Validation loss: 2.832618438531748

Epoch: 5| Step: 5
Training loss: 3.4373877767103944
Validation loss: 2.8308841776350184

Epoch: 5| Step: 6
Training loss: 2.682248951593415
Validation loss: 2.8291172162782647

Epoch: 5| Step: 7
Training loss: 2.4208845512850536
Validation loss: 2.827429483924561

Epoch: 5| Step: 8
Training loss: 2.806312876381399
Validation loss: 2.8259865173421828

Epoch: 5| Step: 9
Training loss: 2.802115448456882
Validation loss: 2.8242647722151766

Epoch: 5| Step: 10
Training loss: 3.530975871290782
Validation loss: 2.822739582677596

Epoch: 5| Step: 11
Training loss: 2.30735815453297
Validation loss: 2.821038688939999

Epoch: 61| Step: 0
Training loss: 2.5475192513080076
Validation loss: 2.8193868666179056

Epoch: 5| Step: 1
Training loss: 2.69697117285904
Validation loss: 2.8177041331675325

Epoch: 5| Step: 2
Training loss: 2.968124645021875
Validation loss: 2.8161194541113796

Epoch: 5| Step: 3
Training loss: 2.927972479789936
Validation loss: 2.8144505200979553

Epoch: 5| Step: 4
Training loss: 2.700753114005888
Validation loss: 2.8128747549105073

Epoch: 5| Step: 5
Training loss: 2.842520814951943
Validation loss: 2.811309046607905

Epoch: 5| Step: 6
Training loss: 2.8800349720844864
Validation loss: 2.809715496188645

Epoch: 5| Step: 7
Training loss: 3.076550385939044
Validation loss: 2.8080518763078

Epoch: 5| Step: 8
Training loss: 3.373505438031735
Validation loss: 2.8065334857975275

Epoch: 5| Step: 9
Training loss: 3.067811214015039
Validation loss: 2.8051532121397273

Epoch: 5| Step: 10
Training loss: 3.3354862095486704
Validation loss: 2.8033079191848342

Epoch: 5| Step: 11
Training loss: 2.7802947043224213
Validation loss: 2.8017081797775196

Epoch: 62| Step: 0
Training loss: 3.2962676297853015
Validation loss: 2.800194601267427

Epoch: 5| Step: 1
Training loss: 3.334361648890357
Validation loss: 2.7988246501538114

Epoch: 5| Step: 2
Training loss: 2.7275053214100815
Validation loss: 2.796847973769335

Epoch: 5| Step: 3
Training loss: 2.7640281420653796
Validation loss: 2.79520012345513

Epoch: 5| Step: 4
Training loss: 3.226475896896928
Validation loss: 2.7934464230686333

Epoch: 5| Step: 5
Training loss: 2.743488839826346
Validation loss: 2.7919769980520113

Epoch: 5| Step: 6
Training loss: 3.0876296413864415
Validation loss: 2.7904389739819333

Epoch: 5| Step: 7
Training loss: 3.2081137908198696
Validation loss: 2.7888088876801116

Epoch: 5| Step: 8
Training loss: 2.775108156588085
Validation loss: 2.787120035815417

Epoch: 5| Step: 9
Training loss: 2.9764072648066247
Validation loss: 2.7855689272259303

Epoch: 5| Step: 10
Training loss: 1.605426425793619
Validation loss: 2.78421209239087

Epoch: 5| Step: 11
Training loss: 3.611216418043141
Validation loss: 2.7828905182114636

Epoch: 63| Step: 0
Training loss: 2.657060746273447
Validation loss: 2.7811103778611144

Epoch: 5| Step: 1
Training loss: 2.9210879647951873
Validation loss: 2.779513967385504

Epoch: 5| Step: 2
Training loss: 3.042224484509312
Validation loss: 2.7780516071587344

Epoch: 5| Step: 3
Training loss: 2.686783539838576
Validation loss: 2.7762940502608133

Epoch: 5| Step: 4
Training loss: 3.2200174151121432
Validation loss: 2.7750373452626333

Epoch: 5| Step: 5
Training loss: 3.0832181513811747
Validation loss: 2.7731730805193004

Epoch: 5| Step: 6
Training loss: 3.0923128739703007
Validation loss: 2.7718731511399084

Epoch: 5| Step: 7
Training loss: 2.696496675726597
Validation loss: 2.7703861088376764

Epoch: 5| Step: 8
Training loss: 3.1900146139641254
Validation loss: 2.7687612592182616

Epoch: 5| Step: 9
Training loss: 2.4903701326353023
Validation loss: 2.7675509418955393

Epoch: 5| Step: 10
Training loss: 2.9595415755282564
Validation loss: 2.7660134827493703

Epoch: 5| Step: 11
Training loss: 2.5711831702345638
Validation loss: 2.764384629142746

Epoch: 64| Step: 0
Training loss: 2.7364805997289423
Validation loss: 2.762727692514207

Epoch: 5| Step: 1
Training loss: 2.444308431290002
Validation loss: 2.7617541341929375

Epoch: 5| Step: 2
Training loss: 2.772212829990144
Validation loss: 2.7600923971533304

Epoch: 5| Step: 3
Training loss: 3.146204002386652
Validation loss: 2.759593885387083

Epoch: 5| Step: 4
Training loss: 2.4410939253349366
Validation loss: 2.7580286469014896

Epoch: 5| Step: 5
Training loss: 2.917805004504503
Validation loss: 2.756686386860844

Epoch: 5| Step: 6
Training loss: 3.21331149883951
Validation loss: 2.755279613406918

Epoch: 5| Step: 7
Training loss: 2.703497535745363
Validation loss: 2.754032776002453

Epoch: 5| Step: 8
Training loss: 3.670021400908976
Validation loss: 2.752633957474579

Epoch: 5| Step: 9
Training loss: 2.5385753927284984
Validation loss: 2.7515419480702366

Epoch: 5| Step: 10
Training loss: 2.8338164497328275
Validation loss: 2.750116800948896

Epoch: 5| Step: 11
Training loss: 3.894283428361392
Validation loss: 2.7487666803478095

Epoch: 65| Step: 0
Training loss: 3.2513334033187267
Validation loss: 2.7473160802947727

Epoch: 5| Step: 1
Training loss: 2.6147517014558215
Validation loss: 2.7464204017836074

Epoch: 5| Step: 2
Training loss: 3.366682470555242
Validation loss: 2.744964494035501

Epoch: 5| Step: 3
Training loss: 2.624359234305783
Validation loss: 2.7435135564977235

Epoch: 5| Step: 4
Training loss: 2.801139946903087
Validation loss: 2.7425026961527497

Epoch: 5| Step: 5
Training loss: 2.960654534580542
Validation loss: 2.7406461501021306

Epoch: 5| Step: 6
Training loss: 2.8415441656323517
Validation loss: 2.7396436341373387

Epoch: 5| Step: 7
Training loss: 2.5865569971700557
Validation loss: 2.7369114873172515

Epoch: 5| Step: 8
Training loss: 2.8913814070509685
Validation loss: 2.734319940648462

Epoch: 5| Step: 9
Training loss: 2.7767663025429394
Validation loss: 2.7340277533067847

Epoch: 5| Step: 10
Training loss: 2.7595373708575988
Validation loss: 2.733217114113847

Epoch: 5| Step: 11
Training loss: 3.4659130420463313
Validation loss: 2.7318902851725273

Epoch: 66| Step: 0
Training loss: 2.764434644489901
Validation loss: 2.730968176809159

Epoch: 5| Step: 1
Training loss: 2.702868410842782
Validation loss: 2.7302159895941776

Epoch: 5| Step: 2
Training loss: 3.3626607750103146
Validation loss: 2.728489887732376

Epoch: 5| Step: 3
Training loss: 2.5131705494822496
Validation loss: 2.726403578796775

Epoch: 5| Step: 4
Training loss: 2.8459048648034106
Validation loss: 2.724350769093903

Epoch: 5| Step: 5
Training loss: 3.1931828721290607
Validation loss: 2.7229001899654635

Epoch: 5| Step: 6
Training loss: 2.8932598580495967
Validation loss: 2.721476820717198

Epoch: 5| Step: 7
Training loss: 2.510514654460561
Validation loss: 2.7206425601875384

Epoch: 5| Step: 8
Training loss: 2.524435879227535
Validation loss: 2.7184793878393285

Epoch: 5| Step: 9
Training loss: 2.9457165671106242
Validation loss: 2.7160090701282296

Epoch: 5| Step: 10
Training loss: 3.0936764795063936
Validation loss: 2.7156617978978956

Epoch: 5| Step: 11
Training loss: 3.030527402345134
Validation loss: 2.713786955502298

Epoch: 67| Step: 0
Training loss: 2.4670081452110364
Validation loss: 2.712931336769589

Epoch: 5| Step: 1
Training loss: 2.8384316146001685
Validation loss: 2.7108841303574893

Epoch: 5| Step: 2
Training loss: 3.147063530556135
Validation loss: 2.7105134014799215

Epoch: 5| Step: 3
Training loss: 2.8587734235797218
Validation loss: 2.710298160500531

Epoch: 5| Step: 4
Training loss: 2.6041545613325416
Validation loss: 2.708430924246771

Epoch: 5| Step: 5
Training loss: 2.488905991436841
Validation loss: 2.709461902572549

Epoch: 5| Step: 6
Training loss: 2.7506087236328076
Validation loss: 2.7071683334276253

Epoch: 5| Step: 7
Training loss: 2.8832812251268423
Validation loss: 2.706375688566365

Epoch: 5| Step: 8
Training loss: 3.214557324393062
Validation loss: 2.7040311180335466

Epoch: 5| Step: 9
Training loss: 3.051377320030143
Validation loss: 2.702619490644662

Epoch: 5| Step: 10
Training loss: 2.811810642107084
Validation loss: 2.7003170415976

Epoch: 5| Step: 11
Training loss: 3.4575327364019297
Validation loss: 2.6986576901271326

Epoch: 68| Step: 0
Training loss: 2.1588726955549724
Validation loss: 2.69600794200666

Epoch: 5| Step: 1
Training loss: 2.790216116516367
Validation loss: 2.7042355323412255

Epoch: 5| Step: 2
Training loss: 3.08045182171436
Validation loss: 2.695969347689224

Epoch: 5| Step: 3
Training loss: 2.680700705578335
Validation loss: 2.692558971864314

Epoch: 5| Step: 4
Training loss: 2.891449681769861
Validation loss: 2.6950730037709665

Epoch: 5| Step: 5
Training loss: 2.731215389914079
Validation loss: 2.6979967250262105

Epoch: 5| Step: 6
Training loss: 2.6771874512687672
Validation loss: 2.7037877903820893

Epoch: 5| Step: 7
Training loss: 2.9257393644260667
Validation loss: 2.715114391567916

Epoch: 5| Step: 8
Training loss: 3.219602897752123
Validation loss: 2.7142447490038766

Epoch: 5| Step: 9
Training loss: 2.9437350392214543
Validation loss: 2.7098110911321105

Epoch: 5| Step: 10
Training loss: 2.9448746980652145
Validation loss: 2.6955198456994753

Epoch: 5| Step: 11
Training loss: 3.401877159946365
Validation loss: 2.6916093791164175

Epoch: 69| Step: 0
Training loss: 3.025259331550326
Validation loss: 2.6885387793585434

Epoch: 5| Step: 1
Training loss: 2.787956210724311
Validation loss: 2.686992771128783

Epoch: 5| Step: 2
Training loss: 3.0190404021727124
Validation loss: 2.6883986027955986

Epoch: 5| Step: 3
Training loss: 2.468086250022237
Validation loss: 2.6849135106291353

Epoch: 5| Step: 4
Training loss: 2.8413337251450215
Validation loss: 2.6846564649012796

Epoch: 5| Step: 5
Training loss: 2.800870885970853
Validation loss: 2.6821931703624533

Epoch: 5| Step: 6
Training loss: 2.3754522997178587
Validation loss: 2.6823749393511895

Epoch: 5| Step: 7
Training loss: 3.290913330661681
Validation loss: 2.681507037809185

Epoch: 5| Step: 8
Training loss: 2.5463812413801348
Validation loss: 2.680684111010051

Epoch: 5| Step: 9
Training loss: 2.808921232483284
Validation loss: 2.6775556820512194

Epoch: 5| Step: 10
Training loss: 3.0884475736560866
Validation loss: 2.6764018023712266

Epoch: 5| Step: 11
Training loss: 2.234758890958981
Validation loss: 2.6739535770193155

Epoch: 70| Step: 0
Training loss: 2.8314819645119487
Validation loss: 2.6736709700870285

Epoch: 5| Step: 1
Training loss: 2.946282912448006
Validation loss: 2.6724327408754838

Epoch: 5| Step: 2
Training loss: 3.059950097867681
Validation loss: 2.6727704635282516

Epoch: 5| Step: 3
Training loss: 2.5614162107036735
Validation loss: 2.6716269699589406

Epoch: 5| Step: 4
Training loss: 2.6642221531614974
Validation loss: 2.6710565030912474

Epoch: 5| Step: 5
Training loss: 2.864509017442735
Validation loss: 2.6701723775153936

Epoch: 5| Step: 6
Training loss: 3.177936343554811
Validation loss: 2.6681062207752926

Epoch: 5| Step: 7
Training loss: 2.462518384061244
Validation loss: 2.666887707539558

Epoch: 5| Step: 8
Training loss: 3.1762789515737513
Validation loss: 2.6653855730928298

Epoch: 5| Step: 9
Training loss: 2.4998534159601924
Validation loss: 2.66298344928642

Epoch: 5| Step: 10
Training loss: 2.6906180812556224
Validation loss: 2.662996005927316

Epoch: 5| Step: 11
Training loss: 2.1501859451437793
Validation loss: 2.660360641208213

Epoch: 71| Step: 0
Training loss: 2.882802244752254
Validation loss: 2.6602728431159943

Epoch: 5| Step: 1
Training loss: 3.0279006544216203
Validation loss: 2.658440668281989

Epoch: 5| Step: 2
Training loss: 2.8028795796173074
Validation loss: 2.6602223183171207

Epoch: 5| Step: 3
Training loss: 2.9052064724425306
Validation loss: 2.65829575615715

Epoch: 5| Step: 4
Training loss: 2.6609663437037714
Validation loss: 2.655771765947376

Epoch: 5| Step: 5
Training loss: 2.8337738779186874
Validation loss: 2.656870477798623

Epoch: 5| Step: 6
Training loss: 2.8016500788040073
Validation loss: 2.6564864670458856

Epoch: 5| Step: 7
Training loss: 2.564912265370227
Validation loss: 2.6550872090187863

Epoch: 5| Step: 8
Training loss: 2.942581975243897
Validation loss: 2.651361507365194

Epoch: 5| Step: 9
Training loss: 2.4438002910463674
Validation loss: 2.649226109696874

Epoch: 5| Step: 10
Training loss: 2.9022929827638513
Validation loss: 2.6469929336702847

Epoch: 5| Step: 11
Training loss: 2.559880196778101
Validation loss: 2.6520457299306783

Epoch: 72| Step: 0
Training loss: 2.746030022653602
Validation loss: 2.6560608441189646

Epoch: 5| Step: 1
Training loss: 2.712142280863589
Validation loss: 2.6719454705833146

Epoch: 5| Step: 2
Training loss: 2.10661678120343
Validation loss: 2.6819346452651756

Epoch: 5| Step: 3
Training loss: 3.177769487839966
Validation loss: 2.6858340319073233

Epoch: 5| Step: 4
Training loss: 2.997462630114528
Validation loss: 2.6550017397097188

Epoch: 5| Step: 5
Training loss: 2.980763112102126
Validation loss: 2.641277988662861

Epoch: 5| Step: 6
Training loss: 2.469441184332686
Validation loss: 2.642081932817886

Epoch: 5| Step: 7
Training loss: 3.310777756283479
Validation loss: 2.6471945772754526

Epoch: 5| Step: 8
Training loss: 2.7792816054460197
Validation loss: 2.656480128473321

Epoch: 5| Step: 9
Training loss: 2.4902019184465765
Validation loss: 2.654146011926918

Epoch: 5| Step: 10
Training loss: 2.692733282469242
Validation loss: 2.6568204940305553

Epoch: 5| Step: 11
Training loss: 2.944938494261867
Validation loss: 2.655675713783668

Epoch: 73| Step: 0
Training loss: 3.093956372092158
Validation loss: 2.65418666660393

Epoch: 5| Step: 1
Training loss: 2.737226645003245
Validation loss: 2.6507026415613666

Epoch: 5| Step: 2
Training loss: 2.736842235814219
Validation loss: 2.6464458505001316

Epoch: 5| Step: 3
Training loss: 2.993900137622766
Validation loss: 2.6449195204896014

Epoch: 5| Step: 4
Training loss: 2.391063475445522
Validation loss: 2.6417396006358573

Epoch: 5| Step: 5
Training loss: 2.692497397645562
Validation loss: 2.6389458827227474

Epoch: 5| Step: 6
Training loss: 2.9335375093435547
Validation loss: 2.634678572679303

Epoch: 5| Step: 7
Training loss: 2.64003065293752
Validation loss: 2.6335441259527532

Epoch: 5| Step: 8
Training loss: 2.5037552286627687
Validation loss: 2.6298954856313177

Epoch: 5| Step: 9
Training loss: 2.7418046559061575
Validation loss: 2.6316901247377436

Epoch: 5| Step: 10
Training loss: 3.138034492346872
Validation loss: 2.629536258959383

Epoch: 5| Step: 11
Training loss: 2.240468073713851
Validation loss: 2.6299271360851124

Epoch: 74| Step: 0
Training loss: 2.9263592748758405
Validation loss: 2.6257762139743193

Epoch: 5| Step: 1
Training loss: 2.6835266726799305
Validation loss: 2.6249353688472996

Epoch: 5| Step: 2
Training loss: 2.623741665736497
Validation loss: 2.626320809389128

Epoch: 5| Step: 3
Training loss: 2.969842328340041
Validation loss: 2.6252789046454494

Epoch: 5| Step: 4
Training loss: 2.898622738247688
Validation loss: 2.6281591584793893

Epoch: 5| Step: 5
Training loss: 2.791115397971736
Validation loss: 2.628456753699676

Epoch: 5| Step: 6
Training loss: 2.8695869903592848
Validation loss: 2.62905154079431

Epoch: 5| Step: 7
Training loss: 2.349271856277963
Validation loss: 2.627723144216909

Epoch: 5| Step: 8
Training loss: 2.9900248308968744
Validation loss: 2.627086362804226

Epoch: 5| Step: 9
Training loss: 2.7278114234763993
Validation loss: 2.626139465401378

Epoch: 5| Step: 10
Training loss: 2.571810485846471
Validation loss: 2.623926450306747

Epoch: 5| Step: 11
Training loss: 2.6019235537981453
Validation loss: 2.621478617686509

Epoch: 75| Step: 0
Training loss: 2.7818963660621883
Validation loss: 2.615145491138229

Epoch: 5| Step: 1
Training loss: 2.4834480715707006
Validation loss: 2.6140455602266877

Epoch: 5| Step: 2
Training loss: 2.6114552138109195
Validation loss: 2.6161559468055575

Epoch: 5| Step: 3
Training loss: 3.066507792158317
Validation loss: 2.6202383715964777

Epoch: 5| Step: 4
Training loss: 2.9718922900349765
Validation loss: 2.6246966345648874

Epoch: 5| Step: 5
Training loss: 2.2200747551231155
Validation loss: 2.62007466197708

Epoch: 5| Step: 6
Training loss: 2.9943460591827984
Validation loss: 2.61238367834721

Epoch: 5| Step: 7
Training loss: 2.4505164983848204
Validation loss: 2.6078732027303224

Epoch: 5| Step: 8
Training loss: 2.4933706124046666
Validation loss: 2.604783028458583

Epoch: 5| Step: 9
Training loss: 3.011990269000582
Validation loss: 2.6081897914458625

Epoch: 5| Step: 10
Training loss: 3.18874110574652
Validation loss: 2.610195518212732

Epoch: 5| Step: 11
Training loss: 2.050599764105031
Validation loss: 2.611070226936544

Testing loss: 2.158811461559574
