Epoch: 1| Step: 0
Training loss: 7.06761267945665
Validation loss: 5.9351743058380295

Epoch: 5| Step: 1
Training loss: 5.649093399904513
Validation loss: 5.933867337095536

Epoch: 5| Step: 2
Training loss: 6.64386926725173
Validation loss: 5.932593161870504

Epoch: 5| Step: 3
Training loss: 6.239946442887745
Validation loss: 5.9312623302892975

Epoch: 5| Step: 4
Training loss: 4.530255649249675
Validation loss: 5.929970380613688

Epoch: 5| Step: 5
Training loss: 6.846309653498155
Validation loss: 5.928633336921968

Epoch: 5| Step: 6
Training loss: 5.340009127262616
Validation loss: 5.92725693415502

Epoch: 5| Step: 7
Training loss: 6.292737486536594
Validation loss: 5.92589727064772

Epoch: 5| Step: 8
Training loss: 5.168349986528772
Validation loss: 5.9244165862973714

Epoch: 5| Step: 9
Training loss: 5.769953728396098
Validation loss: 5.922865154924806

Epoch: 5| Step: 10
Training loss: 6.291537083518702
Validation loss: 5.921351997678639

Epoch: 5| Step: 11
Training loss: 6.805048235540811
Validation loss: 5.919582644595211

Epoch: 2| Step: 0
Training loss: 4.69968671363303
Validation loss: 5.9179730741613055

Epoch: 5| Step: 1
Training loss: 6.177282663595461
Validation loss: 5.916157951334734

Epoch: 5| Step: 2
Training loss: 5.929965086861514
Validation loss: 5.9142660478026245

Epoch: 5| Step: 3
Training loss: 5.774670955647265
Validation loss: 5.912258556724055

Epoch: 5| Step: 4
Training loss: 5.556971170418935
Validation loss: 5.910203501967765

Epoch: 5| Step: 5
Training loss: 6.323943689972683
Validation loss: 5.908075706432065

Epoch: 5| Step: 6
Training loss: 6.014123189158583
Validation loss: 5.905785207608398

Epoch: 5| Step: 7
Training loss: 5.919509455487297
Validation loss: 5.903490010344814

Epoch: 5| Step: 8
Training loss: 5.8833351257724935
Validation loss: 5.900875303566942

Epoch: 5| Step: 9
Training loss: 6.954448171151639
Validation loss: 5.8983819685252445

Epoch: 5| Step: 10
Training loss: 6.454849123680015
Validation loss: 5.895481357469821

Epoch: 5| Step: 11
Training loss: 7.359773855881497
Validation loss: 5.892568333471936

Epoch: 3| Step: 0
Training loss: 4.939034718402469
Validation loss: 5.88943847255002

Epoch: 5| Step: 1
Training loss: 6.419484828350775
Validation loss: 5.886189997905856

Epoch: 5| Step: 2
Training loss: 5.213051614458633
Validation loss: 5.882826157917516

Epoch: 5| Step: 3
Training loss: 5.530827392985699
Validation loss: 5.879183193033062

Epoch: 5| Step: 4
Training loss: 6.449125588458709
Validation loss: 5.875623899839204

Epoch: 5| Step: 5
Training loss: 5.628464712579439
Validation loss: 5.871728229566316

Epoch: 5| Step: 6
Training loss: 6.722083112189814
Validation loss: 5.8673467364758265

Epoch: 5| Step: 7
Training loss: 5.236479834208965
Validation loss: 5.863069188643567

Epoch: 5| Step: 8
Training loss: 6.578272004648232
Validation loss: 5.858246296995318

Epoch: 5| Step: 9
Training loss: 6.601720828352848
Validation loss: 5.85357242387384

Epoch: 5| Step: 10
Training loss: 6.150601191715428
Validation loss: 5.848422842629923

Epoch: 5| Step: 11
Training loss: 6.007101942091193
Validation loss: 5.842662138837618

Epoch: 4| Step: 0
Training loss: 5.6760131200486885
Validation loss: 5.836998403483513

Epoch: 5| Step: 1
Training loss: 6.908111735594963
Validation loss: 5.830750611166274

Epoch: 5| Step: 2
Training loss: 5.970237027419784
Validation loss: 5.824283414430981

Epoch: 5| Step: 3
Training loss: 6.621453829626172
Validation loss: 5.8175464722586305

Epoch: 5| Step: 4
Training loss: 5.739181956837699
Validation loss: 5.810460652371477

Epoch: 5| Step: 5
Training loss: 5.873218347388723
Validation loss: 5.803132435470855

Epoch: 5| Step: 6
Training loss: 6.476926491957938
Validation loss: 5.795576198568096

Epoch: 5| Step: 7
Training loss: 6.019620603854986
Validation loss: 5.787451770106389

Epoch: 5| Step: 8
Training loss: 5.07962605519301
Validation loss: 5.77930485074996

Epoch: 5| Step: 9
Training loss: 5.118372656173145
Validation loss: 5.770783774189507

Epoch: 5| Step: 10
Training loss: 5.795447160848717
Validation loss: 5.762539997086144

Epoch: 5| Step: 11
Training loss: 2.898747265655294
Validation loss: 5.75334271418417

Epoch: 5| Step: 0
Training loss: 5.0473946224131545
Validation loss: 5.7447611328678505

Epoch: 5| Step: 1
Training loss: 6.326934928606451
Validation loss: 5.7359162493292795

Epoch: 5| Step: 2
Training loss: 5.687715966452532
Validation loss: 5.726639202830695

Epoch: 5| Step: 3
Training loss: 6.107797248218199
Validation loss: 5.7171886167814465

Epoch: 5| Step: 4
Training loss: 5.456286544065675
Validation loss: 5.707317124939091

Epoch: 5| Step: 5
Training loss: 5.2388739993676126
Validation loss: 5.697315395880191

Epoch: 5| Step: 6
Training loss: 6.703104797190563
Validation loss: 5.687201830974475

Epoch: 5| Step: 7
Training loss: 5.897776181366842
Validation loss: 5.676780288960661

Epoch: 5| Step: 8
Training loss: 5.654484594519919
Validation loss: 5.665855281839875

Epoch: 5| Step: 9
Training loss: 5.491727329472877
Validation loss: 5.6549668235266575

Epoch: 5| Step: 10
Training loss: 5.730869479427565
Validation loss: 5.643481798301435

Epoch: 5| Step: 11
Training loss: 7.475334808098167
Validation loss: 5.632772726834739

Epoch: 6| Step: 0
Training loss: 5.156986808151939
Validation loss: 5.6214756203013945

Epoch: 5| Step: 1
Training loss: 5.016345961617941
Validation loss: 5.61036986416365

Epoch: 5| Step: 2
Training loss: 6.016594191913397
Validation loss: 5.599381671840086

Epoch: 5| Step: 3
Training loss: 5.011853853279329
Validation loss: 5.588561331461651

Epoch: 5| Step: 4
Training loss: 5.520120922643846
Validation loss: 5.578217691743073

Epoch: 5| Step: 5
Training loss: 5.510399436803561
Validation loss: 5.567787265009932

Epoch: 5| Step: 6
Training loss: 5.99604285401852
Validation loss: 5.557686870028398

Epoch: 5| Step: 7
Training loss: 6.177706896575784
Validation loss: 5.548055045101642

Epoch: 5| Step: 8
Training loss: 5.707288586130115
Validation loss: 5.537852360900697

Epoch: 5| Step: 9
Training loss: 5.851829125476027
Validation loss: 5.5285081623154335

Epoch: 5| Step: 10
Training loss: 6.118233816566647
Validation loss: 5.518835421196675

Epoch: 5| Step: 11
Training loss: 6.966492154553332
Validation loss: 5.50920569292605

Epoch: 7| Step: 0
Training loss: 4.74222208981413
Validation loss: 5.499132535901465

Epoch: 5| Step: 1
Training loss: 6.095628341318743
Validation loss: 5.489547775220952

Epoch: 5| Step: 2
Training loss: 5.589863711147536
Validation loss: 5.480250888299836

Epoch: 5| Step: 3
Training loss: 6.407327105525909
Validation loss: 5.47028446286573

Epoch: 5| Step: 4
Training loss: 4.4508481278298895
Validation loss: 5.460200058493925

Epoch: 5| Step: 5
Training loss: 5.521586797389714
Validation loss: 5.451154343674689

Epoch: 5| Step: 6
Training loss: 5.677035923564462
Validation loss: 5.441553548812331

Epoch: 5| Step: 7
Training loss: 5.2285552053624205
Validation loss: 5.432591213941613

Epoch: 5| Step: 8
Training loss: 5.883003789013141
Validation loss: 5.423595371730932

Epoch: 5| Step: 9
Training loss: 5.662649675626858
Validation loss: 5.414513309090057

Epoch: 5| Step: 10
Training loss: 5.82181516361662
Validation loss: 5.405734814919842

Epoch: 5| Step: 11
Training loss: 5.192566936357181
Validation loss: 5.396613586255844

Epoch: 8| Step: 0
Training loss: 6.311075484185706
Validation loss: 5.387908427960555

Epoch: 5| Step: 1
Training loss: 5.7761660104707495
Validation loss: 5.3790017172385225

Epoch: 5| Step: 2
Training loss: 5.322024077087552
Validation loss: 5.370892796311789

Epoch: 5| Step: 3
Training loss: 5.61208675366952
Validation loss: 5.361848325338791

Epoch: 5| Step: 4
Training loss: 4.329244200397996
Validation loss: 5.353711552950593

Epoch: 5| Step: 5
Training loss: 4.41521110781658
Validation loss: 5.345852971604575

Epoch: 5| Step: 6
Training loss: 5.395755349949512
Validation loss: 5.337839520188018

Epoch: 5| Step: 7
Training loss: 5.580129396859302
Validation loss: 5.33025707495687

Epoch: 5| Step: 8
Training loss: 5.026321745927046
Validation loss: 5.322779624453871

Epoch: 5| Step: 9
Training loss: 5.424531401335258
Validation loss: 5.315705368328495

Epoch: 5| Step: 10
Training loss: 6.388943252700752
Validation loss: 5.308104068869495

Epoch: 5| Step: 11
Training loss: 6.3259276542856435
Validation loss: 5.301210435262282

Epoch: 9| Step: 0
Training loss: 4.706461891784354
Validation loss: 5.293509517883678

Epoch: 5| Step: 1
Training loss: 5.009495111787656
Validation loss: 5.2859978786940065

Epoch: 5| Step: 2
Training loss: 5.6321145735053895
Validation loss: 5.278827999706105

Epoch: 5| Step: 3
Training loss: 4.966975633027297
Validation loss: 5.271971683938446

Epoch: 5| Step: 4
Training loss: 6.0195578661806115
Validation loss: 5.264817120224846

Epoch: 5| Step: 5
Training loss: 5.9275162130364984
Validation loss: 5.25787997379625

Epoch: 5| Step: 6
Training loss: 4.843093138425167
Validation loss: 5.250547024823278

Epoch: 5| Step: 7
Training loss: 5.009471315063628
Validation loss: 5.243544977459298

Epoch: 5| Step: 8
Training loss: 5.416813579425458
Validation loss: 5.23648796136398

Epoch: 5| Step: 9
Training loss: 5.546083205756194
Validation loss: 5.229144961348798

Epoch: 5| Step: 10
Training loss: 5.918687430577738
Validation loss: 5.22273614594532

Epoch: 5| Step: 11
Training loss: 5.1975854476356265
Validation loss: 5.215932675705786

Epoch: 10| Step: 0
Training loss: 5.694456436434062
Validation loss: 5.209392953531671

Epoch: 5| Step: 1
Training loss: 5.202750710894843
Validation loss: 5.202534356640046

Epoch: 5| Step: 2
Training loss: 5.76994083632048
Validation loss: 5.195715974136471

Epoch: 5| Step: 3
Training loss: 5.235394643283623
Validation loss: 5.188469233221402

Epoch: 5| Step: 4
Training loss: 5.033892772649533
Validation loss: 5.181843442718407

Epoch: 5| Step: 5
Training loss: 5.056979147791326
Validation loss: 5.174369617589449

Epoch: 5| Step: 6
Training loss: 5.535192603918637
Validation loss: 5.16827977542791

Epoch: 5| Step: 7
Training loss: 5.938428625469445
Validation loss: 5.160418942445457

Epoch: 5| Step: 8
Training loss: 4.80029493061608
Validation loss: 5.153228969076484

Epoch: 5| Step: 9
Training loss: 5.0629053777705355
Validation loss: 5.146202987902155

Epoch: 5| Step: 10
Training loss: 5.0338276012000565
Validation loss: 5.138899431418295

Epoch: 5| Step: 11
Training loss: 4.173011196447802
Validation loss: 5.13234780200041

Epoch: 11| Step: 0
Training loss: 5.432205955387557
Validation loss: 5.126385703037489

Epoch: 5| Step: 1
Training loss: 4.800969764974999
Validation loss: 5.120689052145643

Epoch: 5| Step: 2
Training loss: 5.371499984637525
Validation loss: 5.114036906382583

Epoch: 5| Step: 3
Training loss: 5.593072434631363
Validation loss: 5.108305341800502

Epoch: 5| Step: 4
Training loss: 5.0394898226029925
Validation loss: 5.1018582112792625

Epoch: 5| Step: 5
Training loss: 5.634149527626881
Validation loss: 5.09616795197866

Epoch: 5| Step: 6
Training loss: 5.312227129940712
Validation loss: 5.08994666869148

Epoch: 5| Step: 7
Training loss: 5.742046660687775
Validation loss: 5.084169939122723

Epoch: 5| Step: 8
Training loss: 5.333621593473628
Validation loss: 5.077723991015034

Epoch: 5| Step: 9
Training loss: 3.646322482764714
Validation loss: 5.071461199170008

Epoch: 5| Step: 10
Training loss: 5.0890906619217136
Validation loss: 5.0659977952420485

Epoch: 5| Step: 11
Training loss: 5.760171269943458
Validation loss: 5.060323757649972

Epoch: 12| Step: 0
Training loss: 5.662693463319508
Validation loss: 5.054960342739667

Epoch: 5| Step: 1
Training loss: 4.377556626036967
Validation loss: 5.049574910266578

Epoch: 5| Step: 2
Training loss: 5.2605832920186355
Validation loss: 5.043371025448016

Epoch: 5| Step: 3
Training loss: 5.294111132773587
Validation loss: 5.038410856315346

Epoch: 5| Step: 4
Training loss: 5.279361183940539
Validation loss: 5.032767720473795

Epoch: 5| Step: 5
Training loss: 4.449062059974099
Validation loss: 5.026519407451859

Epoch: 5| Step: 6
Training loss: 5.277562044430411
Validation loss: 5.02104876941132

Epoch: 5| Step: 7
Training loss: 5.634363984548387
Validation loss: 5.015988488261688

Epoch: 5| Step: 8
Training loss: 5.063354796782041
Validation loss: 5.01022962933535

Epoch: 5| Step: 9
Training loss: 4.845707848395521
Validation loss: 5.004689338231968

Epoch: 5| Step: 10
Training loss: 5.45094846119342
Validation loss: 4.999055304291887

Epoch: 5| Step: 11
Training loss: 4.529328879522545
Validation loss: 4.994085103465939

Epoch: 13| Step: 0
Training loss: 5.426036282196957
Validation loss: 4.988629517412626

Epoch: 5| Step: 1
Training loss: 4.9445275622369325
Validation loss: 4.983066741910294

Epoch: 5| Step: 2
Training loss: 5.074763573462126
Validation loss: 4.977897149678864

Epoch: 5| Step: 3
Training loss: 5.447077067091038
Validation loss: 4.97283331912122

Epoch: 5| Step: 4
Training loss: 5.274854591137238
Validation loss: 4.966653001476323

Epoch: 5| Step: 5
Training loss: 5.4098750843568215
Validation loss: 4.961290586226575

Epoch: 5| Step: 6
Training loss: 4.5627203065122215
Validation loss: 4.955902419984897

Epoch: 5| Step: 7
Training loss: 5.16611328032699
Validation loss: 4.949964981404777

Epoch: 5| Step: 8
Training loss: 5.560364045224889
Validation loss: 4.944588349542506

Epoch: 5| Step: 9
Training loss: 4.706566245508955
Validation loss: 4.938939114181621

Epoch: 5| Step: 10
Training loss: 3.951349394916938
Validation loss: 4.934063621007217

Epoch: 5| Step: 11
Training loss: 6.026728541188801
Validation loss: 4.927983033161866

Epoch: 14| Step: 0
Training loss: 5.0156230985929025
Validation loss: 4.92288054029092

Epoch: 5| Step: 1
Training loss: 3.7660200616157353
Validation loss: 4.917055464851652

Epoch: 5| Step: 2
Training loss: 5.323858527398242
Validation loss: 4.912254344502286

Epoch: 5| Step: 3
Training loss: 5.710599166512755
Validation loss: 4.907285852279679

Epoch: 5| Step: 4
Training loss: 4.284183583063251
Validation loss: 4.901869800854591

Epoch: 5| Step: 5
Training loss: 4.6057971581647195
Validation loss: 4.8970358595955155

Epoch: 5| Step: 6
Training loss: 5.734107902605313
Validation loss: 4.892091517002824

Epoch: 5| Step: 7
Training loss: 5.3550979853195075
Validation loss: 4.886778182886258

Epoch: 5| Step: 8
Training loss: 5.062715879005379
Validation loss: 4.881438665777623

Epoch: 5| Step: 9
Training loss: 4.695370792782383
Validation loss: 4.875902756628299

Epoch: 5| Step: 10
Training loss: 5.631372529622136
Validation loss: 4.871945385998473

Epoch: 5| Step: 11
Training loss: 2.8707525971847807
Validation loss: 4.866246303384159

Epoch: 15| Step: 0
Training loss: 5.1589254200723005
Validation loss: 4.861728977113127

Epoch: 5| Step: 1
Training loss: 4.687990696972674
Validation loss: 4.856909172262858

Epoch: 5| Step: 2
Training loss: 5.098333625074322
Validation loss: 4.8514412472162585

Epoch: 5| Step: 3
Training loss: 4.559129070632946
Validation loss: 4.847100499849438

Epoch: 5| Step: 4
Training loss: 5.08908035514119
Validation loss: 4.841925345036365

Epoch: 5| Step: 5
Training loss: 5.010708214200996
Validation loss: 4.836616127495877

Epoch: 5| Step: 6
Training loss: 3.993397031179446
Validation loss: 4.831838264199038

Epoch: 5| Step: 7
Training loss: 5.218347591030186
Validation loss: 4.827032819584325

Epoch: 5| Step: 8
Training loss: 5.343953268189456
Validation loss: 4.821760548493956

Epoch: 5| Step: 9
Training loss: 4.839778133067603
Validation loss: 4.81692601905942

Epoch: 5| Step: 10
Training loss: 5.449764757591463
Validation loss: 4.811787887004699

Epoch: 5| Step: 11
Training loss: 4.763853450503697
Validation loss: 4.806270770626221

Epoch: 16| Step: 0
Training loss: 4.861015999484183
Validation loss: 4.801866930583645

Epoch: 5| Step: 1
Training loss: 5.007346287775904
Validation loss: 4.796074650335944

Epoch: 5| Step: 2
Training loss: 5.185608852325012
Validation loss: 4.790890384762801

Epoch: 5| Step: 3
Training loss: 4.653150922448151
Validation loss: 4.787360174529251

Epoch: 5| Step: 4
Training loss: 5.2950940584324355
Validation loss: 4.7821961507673505

Epoch: 5| Step: 5
Training loss: 4.303966094837158
Validation loss: 4.777205716060104

Epoch: 5| Step: 6
Training loss: 5.246069026840478
Validation loss: 4.771788866506064

Epoch: 5| Step: 7
Training loss: 4.766414389347767
Validation loss: 4.766857025484713

Epoch: 5| Step: 8
Training loss: 5.663206427763077
Validation loss: 4.761416969406174

Epoch: 5| Step: 9
Training loss: 4.204276795672924
Validation loss: 4.7562769440845605

Epoch: 5| Step: 10
Training loss: 4.5187711216603095
Validation loss: 4.751985528127017

Epoch: 5| Step: 11
Training loss: 5.031392539712229
Validation loss: 4.747093633288264

Epoch: 17| Step: 0
Training loss: 5.290665939902697
Validation loss: 4.7423829023228885

Epoch: 5| Step: 1
Training loss: 5.1212045525174625
Validation loss: 4.737756149157833

Epoch: 5| Step: 2
Training loss: 4.942274079241338
Validation loss: 4.733965420605667

Epoch: 5| Step: 3
Training loss: 4.365641584753975
Validation loss: 4.729115900391771

Epoch: 5| Step: 4
Training loss: 4.26512215693171
Validation loss: 4.723822774347532

Epoch: 5| Step: 5
Training loss: 4.833899738842404
Validation loss: 4.719647581109337

Epoch: 5| Step: 6
Training loss: 5.213847341605094
Validation loss: 4.714538741339853

Epoch: 5| Step: 7
Training loss: 5.525787932538727
Validation loss: 4.709600618455523

Epoch: 5| Step: 8
Training loss: 4.6119356962884055
Validation loss: 4.705098233536943

Epoch: 5| Step: 9
Training loss: 4.291871198699988
Validation loss: 4.700509933783098

Epoch: 5| Step: 10
Training loss: 4.9697391317204485
Validation loss: 4.696443376063672

Epoch: 5| Step: 11
Training loss: 2.939286358433795
Validation loss: 4.692002799808635

Epoch: 18| Step: 0
Training loss: 4.723791195885895
Validation loss: 4.689182827134546

Epoch: 5| Step: 1
Training loss: 4.3148695475815355
Validation loss: 4.68284818618511

Epoch: 5| Step: 2
Training loss: 5.285259823795733
Validation loss: 4.678894060617636

Epoch: 5| Step: 3
Training loss: 5.156534452972972
Validation loss: 4.674430862503041

Epoch: 5| Step: 4
Training loss: 5.227117534640604
Validation loss: 4.669545412544727

Epoch: 5| Step: 5
Training loss: 5.545370924215421
Validation loss: 4.663980233016964

Epoch: 5| Step: 6
Training loss: 4.107321570636897
Validation loss: 4.6598420678064185

Epoch: 5| Step: 7
Training loss: 4.67863358234816
Validation loss: 4.655539379468587

Epoch: 5| Step: 8
Training loss: 4.764329677958216
Validation loss: 4.6515254003727975

Epoch: 5| Step: 9
Training loss: 3.884048971179748
Validation loss: 4.645616905519778

Epoch: 5| Step: 10
Training loss: 4.627478888910199
Validation loss: 4.641693377574905

Epoch: 5| Step: 11
Training loss: 5.355923177747932
Validation loss: 4.6364654840354085

Epoch: 19| Step: 0
Training loss: 4.763518721592465
Validation loss: 4.632525061470777

Epoch: 5| Step: 1
Training loss: 4.843209119561704
Validation loss: 4.6283998708689404

Epoch: 5| Step: 2
Training loss: 5.164525459994239
Validation loss: 4.6228086933708346

Epoch: 5| Step: 3
Training loss: 4.416866417932223
Validation loss: 4.618316142379354

Epoch: 5| Step: 4
Training loss: 4.6340248104216615
Validation loss: 4.61360930014766

Epoch: 5| Step: 5
Training loss: 3.9460743385733212
Validation loss: 4.608735414086521

Epoch: 5| Step: 6
Training loss: 4.816560295716788
Validation loss: 4.604164169564009

Epoch: 5| Step: 7
Training loss: 4.779497610848798
Validation loss: 4.599750388670757

Epoch: 5| Step: 8
Training loss: 5.271866447111653
Validation loss: 4.595145543366684

Epoch: 5| Step: 9
Training loss: 4.949413943035741
Validation loss: 4.590342245965348

Epoch: 5| Step: 10
Training loss: 4.354213051191457
Validation loss: 4.586491799851559

Epoch: 5| Step: 11
Training loss: 4.7998528696399045
Validation loss: 4.581263632621796

Epoch: 20| Step: 0
Training loss: 4.583989576118161
Validation loss: 4.5767900909794985

Epoch: 5| Step: 1
Training loss: 4.904345488981478
Validation loss: 4.572275654117623

Epoch: 5| Step: 2
Training loss: 4.852503195461378
Validation loss: 4.568036948040139

Epoch: 5| Step: 3
Training loss: 4.946164604647185
Validation loss: 4.563227068655545

Epoch: 5| Step: 4
Training loss: 5.169133776586183
Validation loss: 4.559122769109521

Epoch: 5| Step: 5
Training loss: 3.947194351239873
Validation loss: 4.554894710340013

Epoch: 5| Step: 6
Training loss: 4.59021482874955
Validation loss: 4.549710284430919

Epoch: 5| Step: 7
Training loss: 3.589765379738261
Validation loss: 4.544817219616527

Epoch: 5| Step: 8
Training loss: 4.955719758541166
Validation loss: 4.540698187339531

Epoch: 5| Step: 9
Training loss: 4.930246747633805
Validation loss: 4.5364674576478885

Epoch: 5| Step: 10
Training loss: 4.995509992650392
Validation loss: 4.531498509750506

Epoch: 5| Step: 11
Training loss: 3.4750416375828608
Validation loss: 4.527259077630363

Epoch: 21| Step: 0
Training loss: 4.3489914700583885
Validation loss: 4.524127826272166

Epoch: 5| Step: 1
Training loss: 4.76282856926686
Validation loss: 4.520073649599726

Epoch: 5| Step: 2
Training loss: 3.981360278556008
Validation loss: 4.5153603393715445

Epoch: 5| Step: 3
Training loss: 5.215419780334793
Validation loss: 4.510642403584046

Epoch: 5| Step: 4
Training loss: 4.737387929109157
Validation loss: 4.506629810737445

Epoch: 5| Step: 5
Training loss: 4.908791242309179
Validation loss: 4.501857374252902

Epoch: 5| Step: 6
Training loss: 4.418815929563071
Validation loss: 4.498180984262459

Epoch: 5| Step: 7
Training loss: 4.4893921754623465
Validation loss: 4.493771383829751

Epoch: 5| Step: 8
Training loss: 5.11987532285047
Validation loss: 4.489485753614964

Epoch: 5| Step: 9
Training loss: 4.129558472019512
Validation loss: 4.48466155834615

Epoch: 5| Step: 10
Training loss: 4.945868823923853
Validation loss: 4.480202438302128

Epoch: 5| Step: 11
Training loss: 2.762446932045603
Validation loss: 4.476107820029852

Epoch: 22| Step: 0
Training loss: 5.050636425139924
Validation loss: 4.4715130229170095

Epoch: 5| Step: 1
Training loss: 4.4269800271341335
Validation loss: 4.467359188588139

Epoch: 5| Step: 2
Training loss: 4.138196240071015
Validation loss: 4.463152636649139

Epoch: 5| Step: 3
Training loss: 4.581419504732646
Validation loss: 4.459598605335832

Epoch: 5| Step: 4
Training loss: 4.651881684259146
Validation loss: 4.454804577778044

Epoch: 5| Step: 5
Training loss: 3.464074084822194
Validation loss: 4.450412937178577

Epoch: 5| Step: 6
Training loss: 4.845200844332857
Validation loss: 4.446859822322191

Epoch: 5| Step: 7
Training loss: 4.213672662623339
Validation loss: 4.442127206173802

Epoch: 5| Step: 8
Training loss: 5.3249634790735225
Validation loss: 4.437354327215128

Epoch: 5| Step: 9
Training loss: 4.69187885479904
Validation loss: 4.433209480740237

Epoch: 5| Step: 10
Training loss: 4.751776513621026
Validation loss: 4.428869859338788

Epoch: 5| Step: 11
Training loss: 4.368850746139197
Validation loss: 4.4246718387365656

Epoch: 23| Step: 0
Training loss: 4.324985067529203
Validation loss: 4.420408277484159

Epoch: 5| Step: 1
Training loss: 4.63980084945544
Validation loss: 4.41650779306421

Epoch: 5| Step: 2
Training loss: 4.44410793831919
Validation loss: 4.41148613654889

Epoch: 5| Step: 3
Training loss: 4.740160538735307
Validation loss: 4.4077601403885005

Epoch: 5| Step: 4
Training loss: 4.738812372013008
Validation loss: 4.4033400122779325

Epoch: 5| Step: 5
Training loss: 4.474435670528983
Validation loss: 4.399297839008011

Epoch: 5| Step: 6
Training loss: 4.533967985345582
Validation loss: 4.395179128855254

Epoch: 5| Step: 7
Training loss: 4.5741322262445525
Validation loss: 4.390522006490984

Epoch: 5| Step: 8
Training loss: 4.862022537285916
Validation loss: 4.386779531101393

Epoch: 5| Step: 9
Training loss: 3.769405003148214
Validation loss: 4.382548604762052

Epoch: 5| Step: 10
Training loss: 4.629152238321466
Validation loss: 4.378184603626416

Epoch: 5| Step: 11
Training loss: 4.487225945480238
Validation loss: 4.374432976626429

Epoch: 24| Step: 0
Training loss: 4.064640361647172
Validation loss: 4.37034566896463

Epoch: 5| Step: 1
Training loss: 4.577091868616456
Validation loss: 4.365444379131564

Epoch: 5| Step: 2
Training loss: 3.6759514439876226
Validation loss: 4.361824318334052

Epoch: 5| Step: 3
Training loss: 4.116590308177492
Validation loss: 4.357761444489366

Epoch: 5| Step: 4
Training loss: 4.8158482385340795
Validation loss: 4.354240611542076

Epoch: 5| Step: 5
Training loss: 4.942218312720103
Validation loss: 4.349720586192342

Epoch: 5| Step: 6
Training loss: 4.235279845232383
Validation loss: 4.345575365338752

Epoch: 5| Step: 7
Training loss: 5.191061245237494
Validation loss: 4.341425303353916

Epoch: 5| Step: 8
Training loss: 4.528311572499383
Validation loss: 4.33712557991457

Epoch: 5| Step: 9
Training loss: 4.584067592182435
Validation loss: 4.333081158611955

Epoch: 5| Step: 10
Training loss: 4.209555999104268
Validation loss: 4.328687440796688

Epoch: 5| Step: 11
Training loss: 4.968169748265754
Validation loss: 4.324542113047444

Epoch: 25| Step: 0
Training loss: 4.402815975393883
Validation loss: 4.320204528231994

Epoch: 5| Step: 1
Training loss: 4.090435287704172
Validation loss: 4.315709592085453

Epoch: 5| Step: 2
Training loss: 5.275326086876144
Validation loss: 4.311396582045185

Epoch: 5| Step: 3
Training loss: 4.134217800343701
Validation loss: 4.30681776632513

Epoch: 5| Step: 4
Training loss: 3.917177708069196
Validation loss: 4.302704065106163

Epoch: 5| Step: 5
Training loss: 3.9706731026748683
Validation loss: 4.298420728611233

Epoch: 5| Step: 6
Training loss: 4.184917507657521
Validation loss: 4.294048762396547

Epoch: 5| Step: 7
Training loss: 4.654191964040027
Validation loss: 4.289633161129726

Epoch: 5| Step: 8
Training loss: 5.486161943460386
Validation loss: 4.285856585562242

Epoch: 5| Step: 9
Training loss: 4.192114948749649
Validation loss: 4.281346136716906

Epoch: 5| Step: 10
Training loss: 4.010317133209185
Validation loss: 4.2770525271419135

Epoch: 5| Step: 11
Training loss: 4.820346924892269
Validation loss: 4.27281683785514

Epoch: 26| Step: 0
Training loss: 5.050131299417612
Validation loss: 4.268643504760338

Epoch: 5| Step: 1
Training loss: 4.233645893683196
Validation loss: 4.2642398397103936

Epoch: 5| Step: 2
Training loss: 4.129374871777209
Validation loss: 4.259891788573871

Epoch: 5| Step: 3
Training loss: 5.179296786616637
Validation loss: 4.255405065065682

Epoch: 5| Step: 4
Training loss: 4.434339445481032
Validation loss: 4.251083114460601

Epoch: 5| Step: 5
Training loss: 4.0589678154134825
Validation loss: 4.24647554882027

Epoch: 5| Step: 6
Training loss: 4.3264639521183454
Validation loss: 4.242112877401949

Epoch: 5| Step: 7
Training loss: 4.087456677875114
Validation loss: 4.237796269340181

Epoch: 5| Step: 8
Training loss: 4.184701924162795
Validation loss: 4.233690626480627

Epoch: 5| Step: 9
Training loss: 3.9067737685962443
Validation loss: 4.229151057072037

Epoch: 5| Step: 10
Training loss: 4.4506029984903055
Validation loss: 4.225075606510454

Epoch: 5| Step: 11
Training loss: 4.029438410171719
Validation loss: 4.221022636609539

Epoch: 27| Step: 0
Training loss: 3.8847069522498603
Validation loss: 4.216147347588019

Epoch: 5| Step: 1
Training loss: 4.583047869491202
Validation loss: 4.211623013950365

Epoch: 5| Step: 2
Training loss: 4.566495217402142
Validation loss: 4.2076286475010125

Epoch: 5| Step: 3
Training loss: 3.72576025558767
Validation loss: 4.20302144883805

Epoch: 5| Step: 4
Training loss: 4.7183744773746215
Validation loss: 4.198458301382397

Epoch: 5| Step: 5
Training loss: 4.388009266220227
Validation loss: 4.19424137812684

Epoch: 5| Step: 6
Training loss: 4.560489159163698
Validation loss: 4.189876100518526

Epoch: 5| Step: 7
Training loss: 4.193787366811454
Validation loss: 4.185144055863656

Epoch: 5| Step: 8
Training loss: 3.8440431312499173
Validation loss: 4.180954315154014

Epoch: 5| Step: 9
Training loss: 4.979537673386338
Validation loss: 4.1769033030132725

Epoch: 5| Step: 10
Training loss: 4.124930410087123
Validation loss: 4.172597901079715

Epoch: 5| Step: 11
Training loss: 3.3198618145415884
Validation loss: 4.1682104906398365

Epoch: 28| Step: 0
Training loss: 4.760604665481671
Validation loss: 4.164434224344564

Epoch: 5| Step: 1
Training loss: 3.983505932142385
Validation loss: 4.160409757862777

Epoch: 5| Step: 2
Training loss: 4.080569882703512
Validation loss: 4.155688059016612

Epoch: 5| Step: 3
Training loss: 4.164810428403797
Validation loss: 4.151353480530966

Epoch: 5| Step: 4
Training loss: 4.401058953907739
Validation loss: 4.147391331640005

Epoch: 5| Step: 5
Training loss: 4.028348603120356
Validation loss: 4.142792342020561

Epoch: 5| Step: 6
Training loss: 3.369530378271247
Validation loss: 4.138982727848833

Epoch: 5| Step: 7
Training loss: 4.5619533681664475
Validation loss: 4.134894093791293

Epoch: 5| Step: 8
Training loss: 4.104193259732346
Validation loss: 4.130573591683049

Epoch: 5| Step: 9
Training loss: 4.623468918869251
Validation loss: 4.126918067428174

Epoch: 5| Step: 10
Training loss: 4.359559195397377
Validation loss: 4.122225097796342

Epoch: 5| Step: 11
Training loss: 5.9507664291039015
Validation loss: 4.118396805827696

Epoch: 29| Step: 0
Training loss: 3.959370500641805
Validation loss: 4.113527885305091

Epoch: 5| Step: 1
Training loss: 4.343084929343567
Validation loss: 4.109070799268922

Epoch: 5| Step: 2
Training loss: 4.187209845212179
Validation loss: 4.10532538359978

Epoch: 5| Step: 3
Training loss: 5.016911516941797
Validation loss: 4.100514576572545

Epoch: 5| Step: 4
Training loss: 3.9388809204618784
Validation loss: 4.0964768478864215

Epoch: 5| Step: 5
Training loss: 4.1392195709597495
Validation loss: 4.092072096910435

Epoch: 5| Step: 6
Training loss: 3.7464053409255684
Validation loss: 4.0870782488768205

Epoch: 5| Step: 7
Training loss: 4.171104102756866
Validation loss: 4.0831956872641495

Epoch: 5| Step: 8
Training loss: 4.295765570554124
Validation loss: 4.07838487832364

Epoch: 5| Step: 9
Training loss: 4.179582997379335
Validation loss: 4.073712935340042

Epoch: 5| Step: 10
Training loss: 4.1785010819807455
Validation loss: 4.06934980355459

Epoch: 5| Step: 11
Training loss: 5.091125561087623
Validation loss: 4.065158951964654

Epoch: 30| Step: 0
Training loss: 4.7175064974741625
Validation loss: 4.0608517897904255

Epoch: 5| Step: 1
Training loss: 4.2969611141939055
Validation loss: 4.055739284117553

Epoch: 5| Step: 2
Training loss: 3.45171082136081
Validation loss: 4.051548089745813

Epoch: 5| Step: 3
Training loss: 4.274048254244945
Validation loss: 4.0470485380023975

Epoch: 5| Step: 4
Training loss: 3.8859831914297707
Validation loss: 4.042748968321035

Epoch: 5| Step: 5
Training loss: 4.403800554074668
Validation loss: 4.03845053291102

Epoch: 5| Step: 6
Training loss: 3.998637921168829
Validation loss: 4.034002724512795

Epoch: 5| Step: 7
Training loss: 3.7155273321997297
Validation loss: 4.0296015067241795

Epoch: 5| Step: 8
Training loss: 4.43583046037255
Validation loss: 4.0254626365610955

Epoch: 5| Step: 9
Training loss: 3.9790597205578133
Validation loss: 4.021052679031625

Epoch: 5| Step: 10
Training loss: 4.393382228257002
Validation loss: 4.016315366227112

Epoch: 5| Step: 11
Training loss: 4.938802812815769
Validation loss: 4.011859795982868

Epoch: 31| Step: 0
Training loss: 4.0584945886887684
Validation loss: 4.007674935541097

Epoch: 5| Step: 1
Training loss: 4.124330177254331
Validation loss: 4.002907237895557

Epoch: 5| Step: 2
Training loss: 4.179085319135547
Validation loss: 3.9991413277625276

Epoch: 5| Step: 3
Training loss: 3.938620392783456
Validation loss: 3.9947032081462077

Epoch: 5| Step: 4
Training loss: 4.358648205403459
Validation loss: 3.990126503936356

Epoch: 5| Step: 5
Training loss: 4.149575747210302
Validation loss: 3.985871167480229

Epoch: 5| Step: 6
Training loss: 4.364832371030675
Validation loss: 3.9811521772646192

Epoch: 5| Step: 7
Training loss: 5.085243470731387
Validation loss: 3.976823129962636

Epoch: 5| Step: 8
Training loss: 4.017243649102563
Validation loss: 3.9724501834864303

Epoch: 5| Step: 9
Training loss: 3.3462848502771454
Validation loss: 3.968048123750428

Epoch: 5| Step: 10
Training loss: 3.805825566522703
Validation loss: 3.9638706460069755

Epoch: 5| Step: 11
Training loss: 1.8611059386464577
Validation loss: 3.9598501745773795

Epoch: 32| Step: 0
Training loss: 3.54560701669281
Validation loss: 3.9558813766048964

Epoch: 5| Step: 1
Training loss: 3.5143335301494667
Validation loss: 3.9523601922988085

Epoch: 5| Step: 2
Training loss: 4.622271170927545
Validation loss: 3.948348842843735

Epoch: 5| Step: 3
Training loss: 4.4382525598384
Validation loss: 3.944299820963409

Epoch: 5| Step: 4
Training loss: 4.530265964338253
Validation loss: 3.940374016791981

Epoch: 5| Step: 5
Training loss: 3.8905762205934318
Validation loss: 3.936345622473107

Epoch: 5| Step: 6
Training loss: 3.547700895033994
Validation loss: 3.9323122272417086

Epoch: 5| Step: 7
Training loss: 3.866213527523444
Validation loss: 3.9282418101404666

Epoch: 5| Step: 8
Training loss: 4.529822604851199
Validation loss: 3.9242691645370074

Epoch: 5| Step: 9
Training loss: 3.757011724791357
Validation loss: 3.9201793069767192

Epoch: 5| Step: 10
Training loss: 4.256472203396392
Validation loss: 3.916255192075929

Epoch: 5| Step: 11
Training loss: 4.230077836423021
Validation loss: 3.9121819887930687

Epoch: 33| Step: 0
Training loss: 4.275319244778732
Validation loss: 3.908279913853747

Epoch: 5| Step: 1
Training loss: 3.6290825841005163
Validation loss: 3.904263293815388

Epoch: 5| Step: 2
Training loss: 4.178274211630113
Validation loss: 3.8999432985552893

Epoch: 5| Step: 3
Training loss: 3.3255810394851464
Validation loss: 3.8962188094808714

Epoch: 5| Step: 4
Training loss: 3.712194739741788
Validation loss: 3.8916835953359925

Epoch: 5| Step: 5
Training loss: 4.55509745354359
Validation loss: 3.887745599869441

Epoch: 5| Step: 6
Training loss: 3.9502649628825584
Validation loss: 3.8837982042061316

Epoch: 5| Step: 7
Training loss: 4.469593315313696
Validation loss: 3.879696686398767

Epoch: 5| Step: 8
Training loss: 4.466841923895593
Validation loss: 3.8756796435669876

Epoch: 5| Step: 9
Training loss: 3.8845527786242
Validation loss: 3.8712622397022676

Epoch: 5| Step: 10
Training loss: 3.6599704691211468
Validation loss: 3.8671372124584455

Epoch: 5| Step: 11
Training loss: 3.644094099544556
Validation loss: 3.8630620150432358

Epoch: 34| Step: 0
Training loss: 4.29551247928775
Validation loss: 3.8592321752975245

Epoch: 5| Step: 1
Training loss: 4.357016961380551
Validation loss: 3.8554932691109434

Epoch: 5| Step: 2
Training loss: 3.753130813835526
Validation loss: 3.8505259905928115

Epoch: 5| Step: 3
Training loss: 3.4427820025635216
Validation loss: 3.846452863697234

Epoch: 5| Step: 4
Training loss: 3.8100444202386794
Validation loss: 3.8420731264651815

Epoch: 5| Step: 5
Training loss: 3.8420263628156954
Validation loss: 3.8381606921816314

Epoch: 5| Step: 6
Training loss: 3.9536788612741347
Validation loss: 3.834175409554259

Epoch: 5| Step: 7
Training loss: 4.252819696661787
Validation loss: 3.8303412062264415

Epoch: 5| Step: 8
Training loss: 4.058274874308582
Validation loss: 3.8261264748352

Epoch: 5| Step: 9
Training loss: 3.7501536019974195
Validation loss: 3.821872561670515

Epoch: 5| Step: 10
Training loss: 4.084645871299114
Validation loss: 3.8179204013657295

Epoch: 5| Step: 11
Training loss: 4.019483797703382
Validation loss: 3.8139400420324447

Epoch: 35| Step: 0
Training loss: 3.6633055338153317
Validation loss: 3.8098739063660165

Epoch: 5| Step: 1
Training loss: 4.380946015221056
Validation loss: 3.805629924216123

Epoch: 5| Step: 2
Training loss: 4.690519047302278
Validation loss: 3.8016231345449727

Epoch: 5| Step: 3
Training loss: 3.645619384300894
Validation loss: 3.7972418368484924

Epoch: 5| Step: 4
Training loss: 2.8540132207530853
Validation loss: 3.793350258159815

Epoch: 5| Step: 5
Training loss: 4.1138402082671215
Validation loss: 3.789025941652727

Epoch: 5| Step: 6
Training loss: 4.572534265655721
Validation loss: 3.785168327887037

Epoch: 5| Step: 7
Training loss: 3.464112764853308
Validation loss: 3.7807947993499145

Epoch: 5| Step: 8
Training loss: 3.8195741404081565
Validation loss: 3.7766468834646454

Epoch: 5| Step: 9
Training loss: 3.68361575624723
Validation loss: 3.772697202357926

Epoch: 5| Step: 10
Training loss: 3.8516393812449183
Validation loss: 3.768655393898628

Epoch: 5| Step: 11
Training loss: 4.265337476716608
Validation loss: 3.7646293062415834

Epoch: 36| Step: 0
Training loss: 3.986251449034443
Validation loss: 3.7603581107838506

Epoch: 5| Step: 1
Training loss: 3.667902189225684
Validation loss: 3.7561146951384448

Epoch: 5| Step: 2
Training loss: 3.173052038526437
Validation loss: 3.752080144391919

Epoch: 5| Step: 3
Training loss: 4.496334278291448
Validation loss: 3.7479521245941925

Epoch: 5| Step: 4
Training loss: 3.977361272841851
Validation loss: 3.744037890098535

Epoch: 5| Step: 5
Training loss: 4.642157407577701
Validation loss: 3.7398751746220698

Epoch: 5| Step: 6
Training loss: 3.9046356527451413
Validation loss: 3.7353597749773555

Epoch: 5| Step: 7
Training loss: 3.5985729197017315
Validation loss: 3.7312271119591993

Epoch: 5| Step: 8
Training loss: 3.601217985742457
Validation loss: 3.727011663530716

Epoch: 5| Step: 9
Training loss: 4.007935520239743
Validation loss: 3.7230280783529675

Epoch: 5| Step: 10
Training loss: 3.4964719429259628
Validation loss: 3.7189626125389217

Epoch: 5| Step: 11
Training loss: 3.010858910271864
Validation loss: 3.7148808084024036

Epoch: 37| Step: 0
Training loss: 3.614132078880592
Validation loss: 3.710795207725473

Epoch: 5| Step: 1
Training loss: 3.897589398252541
Validation loss: 3.7068535588309577

Epoch: 5| Step: 2
Training loss: 3.638398762730746
Validation loss: 3.703001135620333

Epoch: 5| Step: 3
Training loss: 3.61423300915226
Validation loss: 3.6991612511489413

Epoch: 5| Step: 4
Training loss: 3.502224215446697
Validation loss: 3.6951783406567302

Epoch: 5| Step: 5
Training loss: 3.967746397466624
Validation loss: 3.6913271510347037

Epoch: 5| Step: 6
Training loss: 3.476517923476509
Validation loss: 3.687759271763445

Epoch: 5| Step: 7
Training loss: 4.345153801306329
Validation loss: 3.6837758908862934

Epoch: 5| Step: 8
Training loss: 3.974537871746263
Validation loss: 3.67962366738537

Epoch: 5| Step: 9
Training loss: 4.362035452256568
Validation loss: 3.6757700234490684

Epoch: 5| Step: 10
Training loss: 3.7114089184530914
Validation loss: 3.671796952087743

Epoch: 5| Step: 11
Training loss: 3.113272826064905
Validation loss: 3.6677510417317656

Epoch: 38| Step: 0
Training loss: 3.5704513956844885
Validation loss: 3.663767669246413

Epoch: 5| Step: 1
Training loss: 3.5691028106580056
Validation loss: 3.660137451948696

Epoch: 5| Step: 2
Training loss: 4.48148649009329
Validation loss: 3.656200082552293

Epoch: 5| Step: 3
Training loss: 4.197678223961888
Validation loss: 3.6521879220723297

Epoch: 5| Step: 4
Training loss: 3.4081426839196562
Validation loss: 3.6479723223338962

Epoch: 5| Step: 5
Training loss: 3.4913262109465903
Validation loss: 3.6439715490933384

Epoch: 5| Step: 6
Training loss: 3.952785914658367
Validation loss: 3.6401437542286836

Epoch: 5| Step: 7
Training loss: 4.423578911302644
Validation loss: 3.6359834620848406

Epoch: 5| Step: 8
Training loss: 3.2812712169142917
Validation loss: 3.631910785075773

Epoch: 5| Step: 9
Training loss: 2.753438274040109
Validation loss: 3.6280653916619996

Epoch: 5| Step: 10
Training loss: 4.084632796518857
Validation loss: 3.624214871105638

Epoch: 5| Step: 11
Training loss: 3.842793539496342
Validation loss: 3.620245018249039

Epoch: 39| Step: 0
Training loss: 4.549239864362601
Validation loss: 3.6163686837584037

Epoch: 5| Step: 1
Training loss: 4.084754670525978
Validation loss: 3.61242361526955

Epoch: 5| Step: 2
Training loss: 3.4518148431020412
Validation loss: 3.6084162524535914

Epoch: 5| Step: 3
Training loss: 3.2279171074454593
Validation loss: 3.6044698194486524

Epoch: 5| Step: 4
Training loss: 2.3582971397111776
Validation loss: 3.6004356778503808

Epoch: 5| Step: 5
Training loss: 3.399390356720346
Validation loss: 3.5968838420663127

Epoch: 5| Step: 6
Training loss: 3.8441862773636246
Validation loss: 3.5930923910669064

Epoch: 5| Step: 7
Training loss: 3.70234678436947
Validation loss: 3.589544810293001

Epoch: 5| Step: 8
Training loss: 4.063002569950314
Validation loss: 3.5859278870608176

Epoch: 5| Step: 9
Training loss: 4.055484759498115
Validation loss: 3.582179009271839

Epoch: 5| Step: 10
Training loss: 3.725083031465016
Validation loss: 3.578276413069648

Epoch: 5| Step: 11
Training loss: 4.503428107073119
Validation loss: 3.5743185227440133

Epoch: 40| Step: 0
Training loss: 3.1718530513210736
Validation loss: 3.5702692998920016

Epoch: 5| Step: 1
Training loss: 4.031826953852984
Validation loss: 3.5664165060753095

Epoch: 5| Step: 2
Training loss: 4.105716599841954
Validation loss: 3.562222062807826

Epoch: 5| Step: 3
Training loss: 3.531531398667636
Validation loss: 3.558149603865778

Epoch: 5| Step: 4
Training loss: 3.5364580486823725
Validation loss: 3.5540460196377683

Epoch: 5| Step: 5
Training loss: 3.6968123958700945
Validation loss: 3.549920923847756

Epoch: 5| Step: 6
Training loss: 3.2159033474134113
Validation loss: 3.546108039692137

Epoch: 5| Step: 7
Training loss: 3.468653634597176
Validation loss: 3.5421382515289173

Epoch: 5| Step: 8
Training loss: 3.607517838040753
Validation loss: 3.5382802041096375

Epoch: 5| Step: 9
Training loss: 3.9722231588532972
Validation loss: 3.5342878255034913

Epoch: 5| Step: 10
Training loss: 4.106165107302401
Validation loss: 3.5307213097733583

Epoch: 5| Step: 11
Training loss: 3.530031922495933
Validation loss: 3.5266082661545997

Epoch: 41| Step: 0
Training loss: 3.5539166295840676
Validation loss: 3.5224986379714185

Epoch: 5| Step: 1
Training loss: 3.6749720721578467
Validation loss: 3.51838143690021

Epoch: 5| Step: 2
Training loss: 3.385095543914627
Validation loss: 3.514272650120928

Epoch: 5| Step: 3
Training loss: 4.200564146754692
Validation loss: 3.5103417859264723

Epoch: 5| Step: 4
Training loss: 4.104276678221341
Validation loss: 3.505756055749286

Epoch: 5| Step: 5
Training loss: 3.487248762371859
Validation loss: 3.501442004787037

Epoch: 5| Step: 6
Training loss: 3.3569324218747956
Validation loss: 3.496910377757566

Epoch: 5| Step: 7
Training loss: 3.7889650941893556
Validation loss: 3.4927148043948666

Epoch: 5| Step: 8
Training loss: 2.776012675770339
Validation loss: 3.4886715433193682

Epoch: 5| Step: 9
Training loss: 3.448728498479633
Validation loss: 3.485242584511406

Epoch: 5| Step: 10
Training loss: 3.904002038720646
Validation loss: 3.4816316773199665

Epoch: 5| Step: 11
Training loss: 4.3232901660780785
Validation loss: 3.47717626632979

Epoch: 42| Step: 0
Training loss: 3.363982266019872
Validation loss: 3.4733999776822673

Epoch: 5| Step: 1
Training loss: 3.607955058813912
Validation loss: 3.469450533353948

Epoch: 5| Step: 2
Training loss: 3.5977803062894513
Validation loss: 3.4654281106233733

Epoch: 5| Step: 3
Training loss: 4.151143084363674
Validation loss: 3.4619431423154983

Epoch: 5| Step: 4
Training loss: 4.047965944742486
Validation loss: 3.4580061462852227

Epoch: 5| Step: 5
Training loss: 3.330438087674797
Validation loss: 3.4539760674293762

Epoch: 5| Step: 6
Training loss: 3.6770260007601405
Validation loss: 3.450694735001515

Epoch: 5| Step: 7
Training loss: 3.0892713091236437
Validation loss: 3.446709387896926

Epoch: 5| Step: 8
Training loss: 3.7131387385865597
Validation loss: 3.443002995025768

Epoch: 5| Step: 9
Training loss: 3.6334729322394033
Validation loss: 3.43934789753321

Epoch: 5| Step: 10
Training loss: 3.4262366519571943
Validation loss: 3.4355762213689194

Epoch: 5| Step: 11
Training loss: 2.0557317944601614
Validation loss: 3.431863921182378

Epoch: 43| Step: 0
Training loss: 3.3587501122120087
Validation loss: 3.4283344841156027

Epoch: 5| Step: 1
Training loss: 3.0128268369284696
Validation loss: 3.42486032412308

Epoch: 5| Step: 2
Training loss: 3.5571534040101005
Validation loss: 3.4213673695548437

Epoch: 5| Step: 3
Training loss: 3.5260161375908745
Validation loss: 3.417861152045243

Epoch: 5| Step: 4
Training loss: 3.7364184801868796
Validation loss: 3.4143995763145694

Epoch: 5| Step: 5
Training loss: 3.0469817314038474
Validation loss: 3.410753760731146

Epoch: 5| Step: 6
Training loss: 3.9918102825240878
Validation loss: 3.4074537092718344

Epoch: 5| Step: 7
Training loss: 3.5625436345155337
Validation loss: 3.4037308141153875

Epoch: 5| Step: 8
Training loss: 3.571167424054756
Validation loss: 3.4000825547031788

Epoch: 5| Step: 9
Training loss: 4.229476065506966
Validation loss: 3.3964578760220063

Epoch: 5| Step: 10
Training loss: 3.0354885081471257
Validation loss: 3.392860683401072

Epoch: 5| Step: 11
Training loss: 4.424488602737265
Validation loss: 3.3892262000833195

Epoch: 44| Step: 0
Training loss: 3.217538846484638
Validation loss: 3.3853933225951716

Epoch: 5| Step: 1
Training loss: 3.742057017558157
Validation loss: 3.3819295657433535

Epoch: 5| Step: 2
Training loss: 3.0379514256725852
Validation loss: 3.3783163919260883

Epoch: 5| Step: 3
Training loss: 3.078653357998958
Validation loss: 3.374682037658067

Epoch: 5| Step: 4
Training loss: 3.527957022277567
Validation loss: 3.3711607076596914

Epoch: 5| Step: 5
Training loss: 3.878205726883784
Validation loss: 3.367471100325171

Epoch: 5| Step: 6
Training loss: 3.776881823851566
Validation loss: 3.3637485570867875

Epoch: 5| Step: 7
Training loss: 3.5226493681406637
Validation loss: 3.3601897087166774

Epoch: 5| Step: 8
Training loss: 3.4897165453332253
Validation loss: 3.356492114080686

Epoch: 5| Step: 9
Training loss: 3.973440087332954
Validation loss: 3.352965694742345

Epoch: 5| Step: 10
Training loss: 3.0205439637244136
Validation loss: 3.3493186772641117

Epoch: 5| Step: 11
Training loss: 4.162109604132444
Validation loss: 3.345626117557173

Epoch: 45| Step: 0
Training loss: 3.283701244467139
Validation loss: 3.3423731990834895

Epoch: 5| Step: 1
Training loss: 3.5373640216263555
Validation loss: 3.338802087459153

Epoch: 5| Step: 2
Training loss: 3.9492257530384247
Validation loss: 3.3351260470639152

Epoch: 5| Step: 3
Training loss: 4.199292786411285
Validation loss: 3.331483307684933

Epoch: 5| Step: 4
Training loss: 3.1001811374534185
Validation loss: 3.3277835670808953

Epoch: 5| Step: 5
Training loss: 3.77634104977863
Validation loss: 3.3241323212543317

Epoch: 5| Step: 6
Training loss: 3.018512193620743
Validation loss: 3.3205276718729007

Epoch: 5| Step: 7
Training loss: 3.308727203163787
Validation loss: 3.3170966518214424

Epoch: 5| Step: 8
Training loss: 3.091584497749669
Validation loss: 3.313627890734471

Epoch: 5| Step: 9
Training loss: 3.4573353779094442
Validation loss: 3.31019498892288

Epoch: 5| Step: 10
Training loss: 3.280605434505457
Validation loss: 3.3068437267942703

Epoch: 5| Step: 11
Training loss: 3.0271046402547364
Validation loss: 3.3034998215213935

Epoch: 46| Step: 0
Training loss: 3.4853794719917857
Validation loss: 3.300476686169266

Epoch: 5| Step: 1
Training loss: 4.271700490360449
Validation loss: 3.2972163133685215

Epoch: 5| Step: 2
Training loss: 3.0707718600189398
Validation loss: 3.2939603495883705

Epoch: 5| Step: 3
Training loss: 3.241332159623007
Validation loss: 3.2907626967014796

Epoch: 5| Step: 4
Training loss: 2.989644296979314
Validation loss: 3.287558784974604

Epoch: 5| Step: 5
Training loss: 2.9748506203982883
Validation loss: 3.284455825338647

Epoch: 5| Step: 6
Training loss: 2.989269776244027
Validation loss: 3.281628014724527

Epoch: 5| Step: 7
Training loss: 3.2566407655631493
Validation loss: 3.278644629436067

Epoch: 5| Step: 8
Training loss: 3.728658602467499
Validation loss: 3.2757203268470327

Epoch: 5| Step: 9
Training loss: 3.7739846285055654
Validation loss: 3.272708732795501

Epoch: 5| Step: 10
Training loss: 3.4658947439792187
Validation loss: 3.2695434065713944

Epoch: 5| Step: 11
Training loss: 4.219367540161066
Validation loss: 3.2663029722893273

Epoch: 47| Step: 0
Training loss: 3.429594903273785
Validation loss: 3.2629578968178077

Epoch: 5| Step: 1
Training loss: 3.3013726240766776
Validation loss: 3.259528478883941

Epoch: 5| Step: 2
Training loss: 3.346292830126505
Validation loss: 3.256337912331335

Epoch: 5| Step: 3
Training loss: 4.04094411677004
Validation loss: 3.2528221611147985

Epoch: 5| Step: 4
Training loss: 3.996185033208687
Validation loss: 3.2494926178846333

Epoch: 5| Step: 5
Training loss: 3.189626395850301
Validation loss: 3.2459875365629287

Epoch: 5| Step: 6
Training loss: 2.7978081877909653
Validation loss: 3.242404958027659

Epoch: 5| Step: 7
Training loss: 2.7835987760170298
Validation loss: 3.239167543490793

Epoch: 5| Step: 8
Training loss: 3.346212175773223
Validation loss: 3.235925158605

Epoch: 5| Step: 9
Training loss: 3.4503455389828575
Validation loss: 3.2327855023768195

Epoch: 5| Step: 10
Training loss: 3.251642105763205
Validation loss: 3.229342023128512

Epoch: 5| Step: 11
Training loss: 3.8303968266817363
Validation loss: 3.2262197132307397

Epoch: 48| Step: 0
Training loss: 2.972537385466431
Validation loss: 3.2228177610056203

Epoch: 5| Step: 1
Training loss: 3.1321609847008234
Validation loss: 3.219522648884473

Epoch: 5| Step: 2
Training loss: 3.3509212138249693
Validation loss: 3.21641855460664

Epoch: 5| Step: 3
Training loss: 3.1192282208759097
Validation loss: 3.2132359837952236

Epoch: 5| Step: 4
Training loss: 3.0616126818631253
Validation loss: 3.2102093950051542

Epoch: 5| Step: 5
Training loss: 3.8272367731496604
Validation loss: 3.2072558183061473

Epoch: 5| Step: 6
Training loss: 3.769177798762818
Validation loss: 3.203921130726471

Epoch: 5| Step: 7
Training loss: 3.076908548944361
Validation loss: 3.2008305403136013

Epoch: 5| Step: 8
Training loss: 3.590195730925062
Validation loss: 3.1975096568860772

Epoch: 5| Step: 9
Training loss: 3.5279340450756456
Validation loss: 3.1943236222200313

Epoch: 5| Step: 10
Training loss: 3.1851748793662797
Validation loss: 3.191349441477175

Epoch: 5| Step: 11
Training loss: 3.7246995023836003
Validation loss: 3.188088032455113

Epoch: 49| Step: 0
Training loss: 3.12670500972421
Validation loss: 3.1849111503093437

Epoch: 5| Step: 1
Training loss: 3.4211079334314345
Validation loss: 3.181860222838039

Epoch: 5| Step: 2
Training loss: 4.31682911178127
Validation loss: 3.1787995419358683

Epoch: 5| Step: 3
Training loss: 3.5706252747810536
Validation loss: 3.175317327656339

Epoch: 5| Step: 4
Training loss: 3.2815287153762447
Validation loss: 3.1720020788634113

Epoch: 5| Step: 5
Training loss: 3.534870418563826
Validation loss: 3.1685442419420187

Epoch: 5| Step: 6
Training loss: 2.2104974854771453
Validation loss: 3.16528223334142

Epoch: 5| Step: 7
Training loss: 3.131479640923139
Validation loss: 3.162052794137392

Epoch: 5| Step: 8
Training loss: 3.00834559881047
Validation loss: 3.158886346655725

Epoch: 5| Step: 9
Training loss: 2.993912879160469
Validation loss: 3.155876763940383

Epoch: 5| Step: 10
Training loss: 3.5490256355845236
Validation loss: 3.152992537872666

Epoch: 5| Step: 11
Training loss: 2.745170340333862
Validation loss: 3.150118260081134

Epoch: 50| Step: 0
Training loss: 3.31340417577688
Validation loss: 3.1473863675504723

Epoch: 5| Step: 1
Training loss: 3.0587198711325354
Validation loss: 3.144970517644478

Epoch: 5| Step: 2
Training loss: 3.137822965132076
Validation loss: 3.142376024106621

Epoch: 5| Step: 3
Training loss: 3.065499685605714
Validation loss: 3.1398740411508888

Epoch: 5| Step: 4
Training loss: 3.776934722877655
Validation loss: 3.1372484968836756

Epoch: 5| Step: 5
Training loss: 3.3105621427560914
Validation loss: 3.134523179927601

Epoch: 5| Step: 6
Training loss: 3.474990043351434
Validation loss: 3.1317391463380657

Epoch: 5| Step: 7
Training loss: 3.23227745263657
Validation loss: 3.129152466876798

Epoch: 5| Step: 8
Training loss: 2.700493739159878
Validation loss: 3.1263269849508655

Epoch: 5| Step: 9
Training loss: 3.8811063337534786
Validation loss: 3.123606733629382

Epoch: 5| Step: 10
Training loss: 3.138034796255026
Validation loss: 3.120480199798599

Epoch: 5| Step: 11
Training loss: 1.8029414726486233
Validation loss: 3.117693217086131

Epoch: 51| Step: 0
Training loss: 3.264025136570349
Validation loss: 3.1148586321633815

Epoch: 5| Step: 1
Training loss: 3.159147990567418
Validation loss: 3.1120303651223917

Epoch: 5| Step: 2
Training loss: 3.8002530365068443
Validation loss: 3.1091408601461983

Epoch: 5| Step: 3
Training loss: 2.8420748964624507
Validation loss: 3.1061215304410674

Epoch: 5| Step: 4
Training loss: 3.3440497433371243
Validation loss: 3.1031602320314886

Epoch: 5| Step: 5
Training loss: 3.2674229978960754
Validation loss: 3.1004564441463036

Epoch: 5| Step: 6
Training loss: 2.962642611519538
Validation loss: 3.097617775676916

Epoch: 5| Step: 7
Training loss: 2.6342130382703774
Validation loss: 3.0947775178010435

Epoch: 5| Step: 8
Training loss: 3.6515659422035953
Validation loss: 3.0920183171140554

Epoch: 5| Step: 9
Training loss: 3.8195441785949757
Validation loss: 3.0893219331565427

Epoch: 5| Step: 10
Training loss: 2.744404214709156
Validation loss: 3.0864602302101702

Epoch: 5| Step: 11
Training loss: 2.8826484116579976
Validation loss: 3.0837232089776316

Epoch: 52| Step: 0
Training loss: 3.207283855716568
Validation loss: 3.0810860593461107

Epoch: 5| Step: 1
Training loss: 3.2355811777107606
Validation loss: 3.078559676975997

Epoch: 5| Step: 2
Training loss: 3.2503629628487323
Validation loss: 3.075921497953792

Epoch: 5| Step: 3
Training loss: 3.2655070160355413
Validation loss: 3.0734626134180307

Epoch: 5| Step: 4
Training loss: 3.1089170492498206
Validation loss: 3.0707868738598005

Epoch: 5| Step: 5
Training loss: 3.3651700448182393
Validation loss: 3.0681315595886063

Epoch: 5| Step: 6
Training loss: 3.2669578643033934
Validation loss: 3.0653791679666447

Epoch: 5| Step: 7
Training loss: 3.5310293483157276
Validation loss: 3.062565566029286

Epoch: 5| Step: 8
Training loss: 2.478003146048728
Validation loss: 3.0599120974277563

Epoch: 5| Step: 9
Training loss: 3.1150442609505027
Validation loss: 3.0575467360161435

Epoch: 5| Step: 10
Training loss: 3.440594892517354
Validation loss: 3.054916438298596

Epoch: 5| Step: 11
Training loss: 2.873815707218397
Validation loss: 3.0524347686671

Epoch: 53| Step: 0
Training loss: 3.5330502132731256
Validation loss: 3.0498662953175613

Epoch: 5| Step: 1
Training loss: 3.228271622849979
Validation loss: 3.047260338307159

Epoch: 5| Step: 2
Training loss: 3.317579585301545
Validation loss: 3.0444374571864685

Epoch: 5| Step: 3
Training loss: 3.519669982004927
Validation loss: 3.0418601410006922

Epoch: 5| Step: 4
Training loss: 3.0063450788344683
Validation loss: 3.039014895997105

Epoch: 5| Step: 5
Training loss: 3.244264971183314
Validation loss: 3.0362742560694964

Epoch: 5| Step: 6
Training loss: 3.533030643333482
Validation loss: 3.0334734152492526

Epoch: 5| Step: 7
Training loss: 3.13001824858102
Validation loss: 3.030882334615035

Epoch: 5| Step: 8
Training loss: 2.575521460759029
Validation loss: 3.028357029814971

Epoch: 5| Step: 9
Training loss: 2.756492060890161
Validation loss: 3.025764660568586

Epoch: 5| Step: 10
Training loss: 2.75895507313014
Validation loss: 3.023367756935343

Epoch: 5| Step: 11
Training loss: 4.085275512518537
Validation loss: 3.0210076687372536

Epoch: 54| Step: 0
Training loss: 3.0696009619513727
Validation loss: 3.018434128646687

Epoch: 5| Step: 1
Training loss: 2.6924291253214356
Validation loss: 3.015810619828078

Epoch: 5| Step: 2
Training loss: 3.019050668468772
Validation loss: 3.0131450134026263

Epoch: 5| Step: 3
Training loss: 2.9764742300006413
Validation loss: 3.0105188653795465

Epoch: 5| Step: 4
Training loss: 3.328676992855587
Validation loss: 3.008024781237478

Epoch: 5| Step: 5
Training loss: 3.9198116634824243
Validation loss: 3.005638859728056

Epoch: 5| Step: 6
Training loss: 3.2119747816072066
Validation loss: 3.0031649266346667

Epoch: 5| Step: 7
Training loss: 3.59132768015195
Validation loss: 3.000725453136189

Epoch: 5| Step: 8
Training loss: 3.0233375079355014
Validation loss: 2.9980436045476613

Epoch: 5| Step: 9
Training loss: 2.4906668014560367
Validation loss: 2.99545920299136

Epoch: 5| Step: 10
Training loss: 2.9662313920637833
Validation loss: 2.9929321199195456

Epoch: 5| Step: 11
Training loss: 3.596304077123724
Validation loss: 2.9904373834236186

Epoch: 55| Step: 0
Training loss: 2.5985479444932937
Validation loss: 2.988081137079842

Epoch: 5| Step: 1
Training loss: 2.8147217346393103
Validation loss: 2.9856004578974717

Epoch: 5| Step: 2
Training loss: 3.6371229625239567
Validation loss: 2.9834613466679976

Epoch: 5| Step: 3
Training loss: 2.898277422245218
Validation loss: 2.9809647093727896

Epoch: 5| Step: 4
Training loss: 2.927988765319783
Validation loss: 2.9786811590837514

Epoch: 5| Step: 5
Training loss: 3.4841365989245916
Validation loss: 2.976269311224098

Epoch: 5| Step: 6
Training loss: 3.0738720631728307
Validation loss: 2.9737509651284073

Epoch: 5| Step: 7
Training loss: 3.1510333773080963
Validation loss: 2.971344383060932

Epoch: 5| Step: 8
Training loss: 3.099573992098772
Validation loss: 2.968880489894707

Epoch: 5| Step: 9
Training loss: 3.041448210792534
Validation loss: 2.9664689687066765

Epoch: 5| Step: 10
Training loss: 3.0905427588155745
Validation loss: 2.964041144321415

Epoch: 5| Step: 11
Training loss: 4.536848726639252
Validation loss: 2.961743603220294

Epoch: 56| Step: 0
Training loss: 3.1537542768125078
Validation loss: 2.9590579083562467

Epoch: 5| Step: 1
Training loss: 2.8324117470685013
Validation loss: 2.956357374385223

Epoch: 5| Step: 2
Training loss: 2.91853868262735
Validation loss: 2.953924266024076

Epoch: 5| Step: 3
Training loss: 2.9924274876221744
Validation loss: 2.951642143503764

Epoch: 5| Step: 4
Training loss: 2.5963668491330534
Validation loss: 2.9494200816706804

Epoch: 5| Step: 5
Training loss: 3.5988097024452492
Validation loss: 2.9472703910504285

Epoch: 5| Step: 6
Training loss: 3.023322524612548
Validation loss: 2.945240906942291

Epoch: 5| Step: 7
Training loss: 3.1275933758086034
Validation loss: 2.9429663497203453

Epoch: 5| Step: 8
Training loss: 2.728918243827422
Validation loss: 2.9406990832443434

Epoch: 5| Step: 9
Training loss: 3.066792185605732
Validation loss: 2.938471312268343

Epoch: 5| Step: 10
Training loss: 3.7105681868038616
Validation loss: 2.9362308249423297

Epoch: 5| Step: 11
Training loss: 3.2712902227836174
Validation loss: 2.9337065192913383

Epoch: 57| Step: 0
Training loss: 2.804567807334581
Validation loss: 2.9313232602506027

Epoch: 5| Step: 1
Training loss: 2.851641426561831
Validation loss: 2.928960671016365

Epoch: 5| Step: 2
Training loss: 2.8001635094993365
Validation loss: 2.926422076124353

Epoch: 5| Step: 3
Training loss: 2.8835582233845956
Validation loss: 2.924142209504558

Epoch: 5| Step: 4
Training loss: 2.9133118181576263
Validation loss: 2.9218905749390363

Epoch: 5| Step: 5
Training loss: 3.274890804654358
Validation loss: 2.9197240449875532

Epoch: 5| Step: 6
Training loss: 3.3353069343759927
Validation loss: 2.9175155267245088

Epoch: 5| Step: 7
Training loss: 3.3512874748300296
Validation loss: 2.9152784665626736

Epoch: 5| Step: 8
Training loss: 3.3446125094605414
Validation loss: 2.912973539660897

Epoch: 5| Step: 9
Training loss: 2.9620896968718644
Validation loss: 2.910788567651388

Epoch: 5| Step: 10
Training loss: 2.952371168047137
Validation loss: 2.9086071832773412

Epoch: 5| Step: 11
Training loss: 3.62741994652464
Validation loss: 2.906363498700152

Epoch: 58| Step: 0
Training loss: 2.7794898817931903
Validation loss: 2.9040093346937024

Epoch: 5| Step: 1
Training loss: 2.94469949429383
Validation loss: 2.9018354317314974

Epoch: 5| Step: 2
Training loss: 2.8920132989010456
Validation loss: 2.8996725235944303

Epoch: 5| Step: 3
Training loss: 2.9499580315659557
Validation loss: 2.8976685565636755

Epoch: 5| Step: 4
Training loss: 2.9913260312904835
Validation loss: 2.8954775349243898

Epoch: 5| Step: 5
Training loss: 3.2913705877748463
Validation loss: 2.8934417575544336

Epoch: 5| Step: 6
Training loss: 2.9569232069305706
Validation loss: 2.891474432331601

Epoch: 5| Step: 7
Training loss: 3.2559381668818004
Validation loss: 2.8893532575905545

Epoch: 5| Step: 8
Training loss: 3.09223515578408
Validation loss: 2.887526616335753

Epoch: 5| Step: 9
Training loss: 3.2496810169670702
Validation loss: 2.885352203989488

Epoch: 5| Step: 10
Training loss: 3.102311281770652
Validation loss: 2.8834108629350648

Epoch: 5| Step: 11
Training loss: 2.0458956406603797
Validation loss: 2.8812864515049554

Epoch: 59| Step: 0
Training loss: 3.2344276313369504
Validation loss: 2.879059948348848

Epoch: 5| Step: 1
Training loss: 2.8751238920634976
Validation loss: 2.8770500938508192

Epoch: 5| Step: 2
Training loss: 3.1958340170278072
Validation loss: 2.8750489030355353

Epoch: 5| Step: 3
Training loss: 2.898940543968748
Validation loss: 2.8731125876602746

Epoch: 5| Step: 4
Training loss: 2.8287720335246824
Validation loss: 2.87119941084496

Epoch: 5| Step: 5
Training loss: 2.8417921767572847
Validation loss: 2.8692923398174672

Epoch: 5| Step: 6
Training loss: 3.303956728820456
Validation loss: 2.8676307190131807

Epoch: 5| Step: 7
Training loss: 2.706305160136509
Validation loss: 2.8655538071025988

Epoch: 5| Step: 8
Training loss: 3.509727040515513
Validation loss: 2.8636419494949656

Epoch: 5| Step: 9
Training loss: 3.19349585191927
Validation loss: 2.8617733970212846

Epoch: 5| Step: 10
Training loss: 2.526675954145743
Validation loss: 2.8596257723434997

Epoch: 5| Step: 11
Training loss: 2.2535827510342896
Validation loss: 2.8576659182885678

Epoch: 60| Step: 0
Training loss: 2.845001448377834
Validation loss: 2.8557526516451643

Epoch: 5| Step: 1
Training loss: 3.1352806357512866
Validation loss: 2.853968906976596

Epoch: 5| Step: 2
Training loss: 3.181372643525536
Validation loss: 2.8520978869189224

Epoch: 5| Step: 3
Training loss: 2.5327013352583414
Validation loss: 2.8503051877444685

Epoch: 5| Step: 4
Training loss: 3.2685908670876342
Validation loss: 2.8485444283726027

Epoch: 5| Step: 5
Training loss: 2.9406134156212773
Validation loss: 2.846626503710952

Epoch: 5| Step: 6
Training loss: 3.208347733370349
Validation loss: 2.8449590334599333

Epoch: 5| Step: 7
Training loss: 3.188738414065952
Validation loss: 2.843200944987673

Epoch: 5| Step: 8
Training loss: 2.9241881980186637
Validation loss: 2.8413793967258316

Epoch: 5| Step: 9
Training loss: 2.4111513034363363
Validation loss: 2.839838376886251

Epoch: 5| Step: 10
Training loss: 3.218772221460764
Validation loss: 2.8380265051316655

Epoch: 5| Step: 11
Training loss: 2.4049871524459703
Validation loss: 2.83631641529298

Epoch: 61| Step: 0
Training loss: 3.448671532982987
Validation loss: 2.834836856598382

Epoch: 5| Step: 1
Training loss: 3.2397462041376204
Validation loss: 2.833054866616973

Epoch: 5| Step: 2
Training loss: 3.071029928704383
Validation loss: 2.83128582845422

Epoch: 5| Step: 3
Training loss: 2.6721803367999644
Validation loss: 2.8295396003288866

Epoch: 5| Step: 4
Training loss: 3.023106125604505
Validation loss: 2.8278399652260284

Epoch: 5| Step: 5
Training loss: 2.985679301502165
Validation loss: 2.8259911610108963

Epoch: 5| Step: 6
Training loss: 3.180679204129986
Validation loss: 2.8242012118352946

Epoch: 5| Step: 7
Training loss: 2.783188990506872
Validation loss: 2.82258615048629

Epoch: 5| Step: 8
Training loss: 3.046673264305044
Validation loss: 2.821235864863312

Epoch: 5| Step: 9
Training loss: 2.9290816430838156
Validation loss: 2.819560421801298

Epoch: 5| Step: 10
Training loss: 2.133305978102934
Validation loss: 2.818017154112551

Epoch: 5| Step: 11
Training loss: 2.7856147035678496
Validation loss: 2.8166512758823927

Epoch: 62| Step: 0
Training loss: 2.9973756119448947
Validation loss: 2.814979135216901

Epoch: 5| Step: 1
Training loss: 2.893058453641496
Validation loss: 2.813372840368548

Epoch: 5| Step: 2
Training loss: 3.1761084056100812
Validation loss: 2.8117972343664843

Epoch: 5| Step: 3
Training loss: 2.886277512212303
Validation loss: 2.8100709739785747

Epoch: 5| Step: 4
Training loss: 2.961049261475033
Validation loss: 2.808393118407801

Epoch: 5| Step: 5
Training loss: 2.9306141112766566
Validation loss: 2.8068984693476002

Epoch: 5| Step: 6
Training loss: 2.7720119197363493
Validation loss: 2.805343781374363

Epoch: 5| Step: 7
Training loss: 3.4699091993429123
Validation loss: 2.8036315935087317

Epoch: 5| Step: 8
Training loss: 2.932188710945576
Validation loss: 2.8019597027436087

Epoch: 5| Step: 9
Training loss: 2.559120275469691
Validation loss: 2.8003502181125755

Epoch: 5| Step: 10
Training loss: 2.890805295528018
Validation loss: 2.7987346362915693

Epoch: 5| Step: 11
Training loss: 2.3922970976537137
Validation loss: 2.797337580810431

Epoch: 63| Step: 0
Training loss: 3.013779149399063
Validation loss: 2.79591941137216

Epoch: 5| Step: 1
Training loss: 2.3291472168612484
Validation loss: 2.7946873496927624

Epoch: 5| Step: 2
Training loss: 2.8624786042992185
Validation loss: 2.7932410723188097

Epoch: 5| Step: 3
Training loss: 2.8673381713859483
Validation loss: 2.7918710859146163

Epoch: 5| Step: 4
Training loss: 2.7052446995757187
Validation loss: 2.7905954801529544

Epoch: 5| Step: 5
Training loss: 3.163783685149934
Validation loss: 2.7892073443189216

Epoch: 5| Step: 6
Training loss: 2.926046728661897
Validation loss: 2.7878671857594957

Epoch: 5| Step: 7
Training loss: 3.609637890774454
Validation loss: 2.7864387630357705

Epoch: 5| Step: 8
Training loss: 3.1406726738646853
Validation loss: 2.7849576218495216

Epoch: 5| Step: 9
Training loss: 2.871220301738995
Validation loss: 2.7835606431272573

Epoch: 5| Step: 10
Training loss: 2.5696861176346153
Validation loss: 2.781942627775484

Epoch: 5| Step: 11
Training loss: 2.906900968761664
Validation loss: 2.7806224793719747

Epoch: 64| Step: 0
Training loss: 2.917501348317022
Validation loss: 2.77916675226382

Epoch: 5| Step: 1
Training loss: 2.98439992524768
Validation loss: 2.7777066036218883

Epoch: 5| Step: 2
Training loss: 3.3145631806731815
Validation loss: 2.776211983261416

Epoch: 5| Step: 3
Training loss: 3.1698483160654223
Validation loss: 2.774683175601848

Epoch: 5| Step: 4
Training loss: 2.4296172398653613
Validation loss: 2.773194810161854

Epoch: 5| Step: 5
Training loss: 2.9966510517985103
Validation loss: 2.7717913295671344

Epoch: 5| Step: 6
Training loss: 2.9316269622016735
Validation loss: 2.7702646616050384

Epoch: 5| Step: 7
Training loss: 2.351113514160838
Validation loss: 2.768887859841879

Epoch: 5| Step: 8
Training loss: 2.978851159379456
Validation loss: 2.7676811477269734

Epoch: 5| Step: 9
Training loss: 2.776131881956112
Validation loss: 2.7661739099181757

Epoch: 5| Step: 10
Training loss: 3.063978188778209
Validation loss: 2.7648908211742484

Epoch: 5| Step: 11
Training loss: 2.9690776443376263
Validation loss: 2.7634292298320857

Epoch: 65| Step: 0
Training loss: 3.336303119143645
Validation loss: 2.7623386757409514

Epoch: 5| Step: 1
Training loss: 2.9405785519441254
Validation loss: 2.7610641128071682

Epoch: 5| Step: 2
Training loss: 2.8231086712580984
Validation loss: 2.7596606040890608

Epoch: 5| Step: 3
Training loss: 2.325855147085082
Validation loss: 2.758433152368194

Epoch: 5| Step: 4
Training loss: 2.9855908219056353
Validation loss: 2.757164757496535

Epoch: 5| Step: 5
Training loss: 3.1265802584043243
Validation loss: 2.755794709129809

Epoch: 5| Step: 6
Training loss: 3.0416429248736745
Validation loss: 2.7544801479288274

Epoch: 5| Step: 7
Training loss: 2.7737698208142403
Validation loss: 2.7533569617812375

Epoch: 5| Step: 8
Training loss: 2.5628060879142787
Validation loss: 2.7522398648348716

Epoch: 5| Step: 9
Training loss: 3.2595096256765266
Validation loss: 2.751220854778592

Epoch: 5| Step: 10
Training loss: 2.7046917029953623
Validation loss: 2.7500239573504417

Epoch: 5| Step: 11
Training loss: 2.0239417430952304
Validation loss: 2.748849678759151

Epoch: 66| Step: 0
Training loss: 3.096410666876139
Validation loss: 2.7476399076740647

Epoch: 5| Step: 1
Training loss: 3.575507526785069
Validation loss: 2.746621646849717

Epoch: 5| Step: 2
Training loss: 2.7264662236483086
Validation loss: 2.7453683407813947

Epoch: 5| Step: 3
Training loss: 2.7065788650678613
Validation loss: 2.744375824719297

Epoch: 5| Step: 4
Training loss: 2.852069799160292
Validation loss: 2.743353259889889

Epoch: 5| Step: 5
Training loss: 3.1773971819506097
Validation loss: 2.7421627423943042

Epoch: 5| Step: 6
Training loss: 2.507093665230766
Validation loss: 2.7409968241010154

Epoch: 5| Step: 7
Training loss: 2.9316838901079625
Validation loss: 2.7396905114176304

Epoch: 5| Step: 8
Training loss: 2.6184396965071364
Validation loss: 2.738587925054608

Epoch: 5| Step: 9
Training loss: 2.905535210108068
Validation loss: 2.737374954328846

Epoch: 5| Step: 10
Training loss: 2.589602175761933
Validation loss: 2.736159510730368

Epoch: 5| Step: 11
Training loss: 2.1086235685950263
Validation loss: 2.7347290754407267

Epoch: 67| Step: 0
Training loss: 3.2093475192044
Validation loss: 2.7337149777150964

Epoch: 5| Step: 1
Training loss: 2.712657371913198
Validation loss: 2.73252852083837

Epoch: 5| Step: 2
Training loss: 2.835366940441869
Validation loss: 2.7314244400116157

Epoch: 5| Step: 3
Training loss: 2.7328218245088207
Validation loss: 2.7301899772666394

Epoch: 5| Step: 4
Training loss: 2.3174860015413445
Validation loss: 2.7289110669474765

Epoch: 5| Step: 5
Training loss: 2.7573604051077556
Validation loss: 2.727873537083804

Epoch: 5| Step: 6
Training loss: 2.8321778989509383
Validation loss: 2.726627764426271

Epoch: 5| Step: 7
Training loss: 3.2516057375920746
Validation loss: 2.725572885582058

Epoch: 5| Step: 8
Training loss: 2.777268463702477
Validation loss: 2.7244968805823224

Epoch: 5| Step: 9
Training loss: 2.913385143765006
Validation loss: 2.723337731254728

Epoch: 5| Step: 10
Training loss: 3.1103072566016285
Validation loss: 2.7223350412049614

Epoch: 5| Step: 11
Training loss: 2.8607627961148343
Validation loss: 2.721283521450137

Epoch: 68| Step: 0
Training loss: 2.7267949133685785
Validation loss: 2.7200909628979986

Epoch: 5| Step: 1
Training loss: 2.9087716924483886
Validation loss: 2.7189641115495826

Epoch: 5| Step: 2
Training loss: 3.1085877308448104
Validation loss: 2.7178617100527775

Epoch: 5| Step: 3
Training loss: 3.0058542986474355
Validation loss: 2.7166671008907355

Epoch: 5| Step: 4
Training loss: 2.8337319785522292
Validation loss: 2.7156358546723056

Epoch: 5| Step: 5
Training loss: 3.030486335123154
Validation loss: 2.71439586210655

Epoch: 5| Step: 6
Training loss: 2.6068093484071424
Validation loss: 2.7132337704249885

Epoch: 5| Step: 7
Training loss: 2.8693013311761724
Validation loss: 2.7119298908603713

Epoch: 5| Step: 8
Training loss: 2.960433232589714
Validation loss: 2.710757521665601

Epoch: 5| Step: 9
Training loss: 2.4694117371441253
Validation loss: 2.709492410933909

Epoch: 5| Step: 10
Training loss: 2.997186294951568
Validation loss: 2.7086694997841043

Epoch: 5| Step: 11
Training loss: 1.856008928873519
Validation loss: 2.7073203332040614

Epoch: 69| Step: 0
Training loss: 3.0542997226294437
Validation loss: 2.706346572961837

Epoch: 5| Step: 1
Training loss: 2.6103781410859286
Validation loss: 2.7057408187855185

Epoch: 5| Step: 2
Training loss: 2.9764155954869786
Validation loss: 2.7047767002992598

Epoch: 5| Step: 3
Training loss: 2.5898452229445286
Validation loss: 2.704323372515225

Epoch: 5| Step: 4
Training loss: 2.943108257473714
Validation loss: 2.7030291935401136

Epoch: 5| Step: 5
Training loss: 2.2744658461392437
Validation loss: 2.702329459754088

Epoch: 5| Step: 6
Training loss: 2.718360346791077
Validation loss: 2.7016565931976833

Epoch: 5| Step: 7
Training loss: 3.125143276744781
Validation loss: 2.700374045041294

Epoch: 5| Step: 8
Training loss: 2.952686418531714
Validation loss: 2.699548519911167

Epoch: 5| Step: 9
Training loss: 2.935881473154879
Validation loss: 2.698477238824685

Epoch: 5| Step: 10
Training loss: 2.8696828684228897
Validation loss: 2.6976167715899386

Epoch: 5| Step: 11
Training loss: 3.3746029655606744
Validation loss: 2.6968267416586946

Epoch: 70| Step: 0
Training loss: 2.701766802959586
Validation loss: 2.6957618375688868

Epoch: 5| Step: 1
Training loss: 2.3310235943935935
Validation loss: 2.694819415411263

Epoch: 5| Step: 2
Training loss: 2.9766278597646942
Validation loss: 2.693842076751055

Epoch: 5| Step: 3
Training loss: 2.8559314441627137
Validation loss: 2.6928207231354513

Epoch: 5| Step: 4
Training loss: 2.9380619242084394
Validation loss: 2.691980172482224

Epoch: 5| Step: 5
Training loss: 3.46259235575653
Validation loss: 2.6909302067638436

Epoch: 5| Step: 6
Training loss: 3.0352561669123244
Validation loss: 2.6901022673185033

Epoch: 5| Step: 7
Training loss: 3.1035952116722694
Validation loss: 2.6890882707683863

Epoch: 5| Step: 8
Training loss: 2.2136069852877998
Validation loss: 2.6877631088217235

Epoch: 5| Step: 9
Training loss: 2.5370933996201237
Validation loss: 2.6867142792908836

Epoch: 5| Step: 10
Training loss: 2.797265052236012
Validation loss: 2.6854604922186684

Epoch: 5| Step: 11
Training loss: 2.678705152170885
Validation loss: 2.684922039053326

Epoch: 71| Step: 0
Training loss: 2.7692896814274675
Validation loss: 2.6838129426966133

Epoch: 5| Step: 1
Training loss: 2.9342480779301727
Validation loss: 2.6822494997333455

Epoch: 5| Step: 2
Training loss: 3.034722295936178
Validation loss: 2.681038585410789

Epoch: 5| Step: 3
Training loss: 2.5240509893644427
Validation loss: 2.6802861292954896

Epoch: 5| Step: 4
Training loss: 2.825063323264904
Validation loss: 2.6791565816777463

Epoch: 5| Step: 5
Training loss: 3.2760298121752847
Validation loss: 2.6779810455400272

Epoch: 5| Step: 6
Training loss: 2.5009905759991526
Validation loss: 2.6772368841008802

Epoch: 5| Step: 7
Training loss: 2.721616702519543
Validation loss: 2.675655003746045

Epoch: 5| Step: 8
Training loss: 2.6769917889292048
Validation loss: 2.676420687637407

Epoch: 5| Step: 9
Training loss: 3.210745033009035
Validation loss: 2.6747679710769723

Epoch: 5| Step: 10
Training loss: 2.6369352124688805
Validation loss: 2.673104573991516

Epoch: 5| Step: 11
Training loss: 1.39322214095106
Validation loss: 2.672694989469759

Epoch: 72| Step: 0
Training loss: 2.6725109748864777
Validation loss: 2.671377280652138

Epoch: 5| Step: 1
Training loss: 3.0178197276358807
Validation loss: 2.6708614442112673

Epoch: 5| Step: 2
Training loss: 2.991978092684586
Validation loss: 2.6702645041741464

Epoch: 5| Step: 3
Training loss: 2.0993531820441707
Validation loss: 2.6695041808811126

Epoch: 5| Step: 4
Training loss: 3.328910913936389
Validation loss: 2.6692818779445506

Epoch: 5| Step: 5
Training loss: 3.0946197828395325
Validation loss: 2.6685186278367468

Epoch: 5| Step: 6
Training loss: 2.4502793833972607
Validation loss: 2.668096677990691

Epoch: 5| Step: 7
Training loss: 2.5154704170830495
Validation loss: 2.667040993574377

Epoch: 5| Step: 8
Training loss: 2.7192127228637037
Validation loss: 2.666266580212072

Epoch: 5| Step: 9
Training loss: 2.9812887321211377
Validation loss: 2.6657959788182577

Epoch: 5| Step: 10
Training loss: 2.6605943047453438
Validation loss: 2.6651348107530435

Epoch: 5| Step: 11
Training loss: 3.4271778839580262
Validation loss: 2.6643496085512632

Epoch: 73| Step: 0
Training loss: 2.15328167039449
Validation loss: 2.6628819718476087

Epoch: 5| Step: 1
Training loss: 3.0075807160084107
Validation loss: 2.6619944296911604

Epoch: 5| Step: 2
Training loss: 2.69372033901657
Validation loss: 2.6605738770873293

Epoch: 5| Step: 3
Training loss: 2.7573882470956
Validation loss: 2.659825532720066

Epoch: 5| Step: 4
Training loss: 3.0756882060237882
Validation loss: 2.6586378191967506

Epoch: 5| Step: 5
Training loss: 2.6338603031649446
Validation loss: 2.6574745459726654

Epoch: 5| Step: 6
Training loss: 3.3955125871766834
Validation loss: 2.6562525244308146

Epoch: 5| Step: 7
Training loss: 2.713673291275316
Validation loss: 2.6556789195685133

Epoch: 5| Step: 8
Training loss: 2.5475978644593424
Validation loss: 2.6540992032574273

Epoch: 5| Step: 9
Training loss: 2.912651313485738
Validation loss: 2.652833903608265

Epoch: 5| Step: 10
Training loss: 2.8977591242544136
Validation loss: 2.651950494286665

Epoch: 5| Step: 11
Training loss: 1.5065869504522702
Validation loss: 2.651280470449219

Epoch: 74| Step: 0
Training loss: 3.132062788985551
Validation loss: 2.6503558230381654

Epoch: 5| Step: 1
Training loss: 2.9528706758977203
Validation loss: 2.6521238967198726

Epoch: 5| Step: 2
Training loss: 2.693599698504756
Validation loss: 2.648657726782677

Epoch: 5| Step: 3
Training loss: 2.5403797664739334
Validation loss: 2.648118501579757

Epoch: 5| Step: 4
Training loss: 2.572708080243443
Validation loss: 2.645987514949599

Epoch: 5| Step: 5
Training loss: 2.915837869508901
Validation loss: 2.6460759259443836

Epoch: 5| Step: 6
Training loss: 2.8772431620391377
Validation loss: 2.645097905674387

Epoch: 5| Step: 7
Training loss: 2.6056747240723808
Validation loss: 2.64470001914299

Epoch: 5| Step: 8
Training loss: 2.9973849979384863
Validation loss: 2.644144432819165

Epoch: 5| Step: 9
Training loss: 2.5848335606544186
Validation loss: 2.6438542057660235

Epoch: 5| Step: 10
Training loss: 2.627574294153291
Validation loss: 2.6429893209446367

Epoch: 5| Step: 11
Training loss: 3.174516001178107
Validation loss: 2.642408442118602

Epoch: 75| Step: 0
Training loss: 2.9087331684643587
Validation loss: 2.6410649288671944

Epoch: 5| Step: 1
Training loss: 3.056563871839867
Validation loss: 2.640248838037876

Epoch: 5| Step: 2
Training loss: 2.5714582770766183
Validation loss: 2.6386594887345565

Epoch: 5| Step: 3
Training loss: 2.6991496760450038
Validation loss: 2.638341356382945

Epoch: 5| Step: 4
Training loss: 2.917178535958459
Validation loss: 2.6357701269352996

Epoch: 5| Step: 5
Training loss: 2.5958172935941413
Validation loss: 2.635897043547439

Epoch: 5| Step: 6
Training loss: 2.9010075693278297
Validation loss: 2.63574873047269

Epoch: 5| Step: 7
Training loss: 2.7185596092470625
Validation loss: 2.632870821585128

Epoch: 5| Step: 8
Training loss: 3.0652238838110573
Validation loss: 2.632697603791932

Epoch: 5| Step: 9
Training loss: 2.4337969307863743
Validation loss: 2.633385359173716

Epoch: 5| Step: 10
Training loss: 2.664651486795514
Validation loss: 2.6336833181571397

Epoch: 5| Step: 11
Training loss: 2.4598943527920447
Validation loss: 2.6333630341854795

Epoch: 76| Step: 0
Training loss: 3.0208558881948027
Validation loss: 2.63209026101051

Epoch: 5| Step: 1
Training loss: 2.7196690551595215
Validation loss: 2.6317867012584855

Epoch: 5| Step: 2
Training loss: 2.7334357692163085
Validation loss: 2.6322988165599925

Epoch: 5| Step: 3
Training loss: 2.6217049399183323
Validation loss: 2.6308159318380064

Epoch: 5| Step: 4
Training loss: 2.5208885144796276
Validation loss: 2.627652213517758

Epoch: 5| Step: 5
Training loss: 2.1824621772766006
Validation loss: 2.6255421267897567

Epoch: 5| Step: 6
Training loss: 3.1052852552412085
Validation loss: 2.624691212748343

Epoch: 5| Step: 7
Training loss: 2.897056229898608
Validation loss: 2.6231857077489207

Epoch: 5| Step: 8
Training loss: 2.9306482799579197
Validation loss: 2.622903565719242

Epoch: 5| Step: 9
Training loss: 2.620945842452649
Validation loss: 2.621611538798702

Epoch: 5| Step: 10
Training loss: 2.9020386403282945
Validation loss: 2.62113390350285

Epoch: 5| Step: 11
Training loss: 3.099411379398139
Validation loss: 2.6211031796569544

Epoch: 77| Step: 0
Training loss: 2.8718871804395194
Validation loss: 2.6191492613920984

Epoch: 5| Step: 1
Training loss: 2.664849755093919
Validation loss: 2.619499513832237

Epoch: 5| Step: 2
Training loss: 3.0639467520008696
Validation loss: 2.6166834749200305

Epoch: 5| Step: 3
Training loss: 2.8310961212042165
Validation loss: 2.6150894523732897

Epoch: 5| Step: 4
Training loss: 2.690628891785894
Validation loss: 2.6159855298255517

Epoch: 5| Step: 5
Training loss: 2.4497703405680906
Validation loss: 2.6161493054675184

Epoch: 5| Step: 6
Training loss: 2.563195390085892
Validation loss: 2.6142147318582456

Epoch: 5| Step: 7
Training loss: 2.9242451076761786
Validation loss: 2.6119964817090606

Epoch: 5| Step: 8
Training loss: 2.527033366699691
Validation loss: 2.6148484932740863

Epoch: 5| Step: 9
Training loss: 3.1516366612300315
Validation loss: 2.6136042419540453

Epoch: 5| Step: 10
Training loss: 2.6128734047987083
Validation loss: 2.6097938178643245

Epoch: 5| Step: 11
Training loss: 2.1825146132566577
Validation loss: 2.609814243313906

Epoch: 78| Step: 0
Training loss: 2.6160671284313377
Validation loss: 2.61123875436755

Epoch: 5| Step: 1
Training loss: 2.514367114876585
Validation loss: 2.6130953362919325

Epoch: 5| Step: 2
Training loss: 2.523369661251926
Validation loss: 2.613538694221648

Epoch: 5| Step: 3
Training loss: 3.0337173016282732
Validation loss: 2.614880322057284

Epoch: 5| Step: 4
Training loss: 2.807444967544079
Validation loss: 2.6148327496983645

Epoch: 5| Step: 5
Training loss: 2.393124339755414
Validation loss: 2.6151580229618334

Epoch: 5| Step: 6
Training loss: 2.771870602988075
Validation loss: 2.6137073665518735

Epoch: 5| Step: 7
Training loss: 2.873128198734318
Validation loss: 2.6172253923851967

Epoch: 5| Step: 8
Training loss: 2.92359147678124
Validation loss: 2.6160007234296763

Epoch: 5| Step: 9
Training loss: 2.6573288465705405
Validation loss: 2.615052664884724

Epoch: 5| Step: 10
Training loss: 2.946322563873587
Validation loss: 2.6123696539575434

Epoch: 5| Step: 11
Training loss: 3.3948321280458487
Validation loss: 2.610798959273416

Epoch: 79| Step: 0
Training loss: 2.595119804012943
Validation loss: 2.6087999147965926

Epoch: 5| Step: 1
Training loss: 2.9575048190905533
Validation loss: 2.607203587075437

Epoch: 5| Step: 2
Training loss: 2.4661057229625443
Validation loss: 2.604771312455206

Epoch: 5| Step: 3
Training loss: 2.637216659440742
Validation loss: 2.603328265969949

Epoch: 5| Step: 4
Training loss: 2.7384788017462407
Validation loss: 2.6003098971046663

Epoch: 5| Step: 5
Training loss: 2.7811996798302947
Validation loss: 2.597726194735512

Epoch: 5| Step: 6
Training loss: 2.6423943364753972
Validation loss: 2.5964479241362346

Epoch: 5| Step: 7
Training loss: 3.149704898150709
Validation loss: 2.596551657422326

Epoch: 5| Step: 8
Training loss: 2.661639770375103
Validation loss: 2.593804891227616

Epoch: 5| Step: 9
Training loss: 2.766276654555906
Validation loss: 2.594935004768497

Epoch: 5| Step: 10
Training loss: 2.6197177783008527
Validation loss: 2.5940457217604433

Epoch: 5| Step: 11
Training loss: 2.958721368261933
Validation loss: 2.5912879649274974

Epoch: 80| Step: 0
Training loss: 2.5490683256070796
Validation loss: 2.6128612460199765

Epoch: 5| Step: 1
Training loss: 2.0638878516697607
Validation loss: 2.611959513738955

Epoch: 5| Step: 2
Training loss: 2.3641900451099467
Validation loss: 2.617591561018865

Epoch: 5| Step: 3
Training loss: 2.947788321101593
Validation loss: 2.5963118590208296

Epoch: 5| Step: 4
Training loss: 2.6944123907465785
Validation loss: 2.5872458790800263

Epoch: 5| Step: 5
Training loss: 3.273847094563823
Validation loss: 2.5916636398477655

Epoch: 5| Step: 6
Training loss: 2.7375126738233124
Validation loss: 2.595541611031638

Epoch: 5| Step: 7
Training loss: 2.55015352946332
Validation loss: 2.6105558689100827

Epoch: 5| Step: 8
Training loss: 3.4763234259879723
Validation loss: 2.6280954970897317

Epoch: 5| Step: 9
Training loss: 2.312350500274689
Validation loss: 2.6130247536662083

Epoch: 5| Step: 10
Training loss: 2.842004428900342
Validation loss: 2.608344976919184

Epoch: 5| Step: 11
Training loss: 2.9687997914204463
Validation loss: 2.609060455064379

Epoch: 81| Step: 0
Training loss: 2.5601632233083245
Validation loss: 2.597147017354572

Epoch: 5| Step: 1
Training loss: 2.905127195636561
Validation loss: 2.5949564697801706

Epoch: 5| Step: 2
Training loss: 2.7582673732404395
Validation loss: 2.5916236832990607

Epoch: 5| Step: 3
Training loss: 2.5313921288041743
Validation loss: 2.591221691663351

Epoch: 5| Step: 4
Training loss: 3.0926311280706473
Validation loss: 2.5899390447162385

Epoch: 5| Step: 5
Training loss: 2.3211557416620674
Validation loss: 2.5851351750470584

Epoch: 5| Step: 6
Training loss: 2.6568885484492224
Validation loss: 2.586478001098172

Epoch: 5| Step: 7
Training loss: 2.6091359651461516
Validation loss: 2.5862899071472434

Epoch: 5| Step: 8
Training loss: 2.8686915306498992
Validation loss: 2.584750338032556

Epoch: 5| Step: 9
Training loss: 2.911155416509023
Validation loss: 2.582863412437187

Epoch: 5| Step: 10
Training loss: 2.788045232846474
Validation loss: 2.5828370661027833

Epoch: 5| Step: 11
Training loss: 2.1581190550297205
Validation loss: 2.5845665961775297

Epoch: 82| Step: 0
Training loss: 2.7628226872810675
Validation loss: 2.5971511043721343

Epoch: 5| Step: 1
Training loss: 2.7859531027741538
Validation loss: 2.605284551374714

Epoch: 5| Step: 2
Training loss: 3.162670139968063
Validation loss: 2.5956948851642854

Epoch: 5| Step: 3
Training loss: 2.5309693922696326
Validation loss: 2.5828143041919422

Epoch: 5| Step: 4
Training loss: 2.522624070714548
Validation loss: 2.5778993334407647

Epoch: 5| Step: 5
Training loss: 2.4916528588702342
Validation loss: 2.573234844740176

Epoch: 5| Step: 6
Training loss: 2.512829856665549
Validation loss: 2.5752529947443508

Epoch: 5| Step: 7
Training loss: 2.787239654426012
Validation loss: 2.5767647092675787

Epoch: 5| Step: 8
Training loss: 2.8204682114325736
Validation loss: 2.5765688081613605

Epoch: 5| Step: 9
Training loss: 2.8849854588927237
Validation loss: 2.579514527832487

Epoch: 5| Step: 10
Training loss: 2.725791756633475
Validation loss: 2.5793417631336744

Epoch: 5| Step: 11
Training loss: 2.5665260879198453
Validation loss: 2.5804521519135513

Epoch: 83| Step: 0
Training loss: 2.563701999015935
Validation loss: 2.5792698100536713

Epoch: 5| Step: 1
Training loss: 3.1286177484327014
Validation loss: 2.577109335231335

Epoch: 5| Step: 2
Training loss: 2.685609196720052
Validation loss: 2.576527279624086

Epoch: 5| Step: 3
Training loss: 2.695325503110618
Validation loss: 2.57647922659673

Epoch: 5| Step: 4
Training loss: 2.2186588752194067
Validation loss: 2.574397307142851

Epoch: 5| Step: 5
Training loss: 2.8194101850394007
Validation loss: 2.572805642938544

Epoch: 5| Step: 6
Training loss: 2.577011145215697
Validation loss: 2.5694997018308032

Epoch: 5| Step: 7
Training loss: 2.8851666026545577
Validation loss: 2.5678202983181775

Epoch: 5| Step: 8
Training loss: 2.7979925043579654
Validation loss: 2.566561558251568

Epoch: 5| Step: 9
Training loss: 2.5138867930291737
Validation loss: 2.564645121336484

Epoch: 5| Step: 10
Training loss: 2.8182752865032787
Validation loss: 2.5665106517472362

Epoch: 5| Step: 11
Training loss: 2.924203689295891
Validation loss: 2.565662491091198

Epoch: 84| Step: 0
Training loss: 3.1642852328047004
Validation loss: 2.566338343232363

Epoch: 5| Step: 1
Training loss: 2.7296541278548174
Validation loss: 2.564004262711864

Epoch: 5| Step: 2
Training loss: 2.761350356247376
Validation loss: 2.5638794016315263

Epoch: 5| Step: 3
Training loss: 2.6298530766746304
Validation loss: 2.562259492209738

Epoch: 5| Step: 4
Training loss: 2.4795660343719494
Validation loss: 2.564026284993632

Epoch: 5| Step: 5
Training loss: 2.744331065455874
Validation loss: 2.5614978606245966

Epoch: 5| Step: 6
Training loss: 2.5845473318520393
Validation loss: 2.561264290634012

Epoch: 5| Step: 7
Training loss: 2.566544481151743
Validation loss: 2.5615766497684205

Epoch: 5| Step: 8
Training loss: 2.6357103468111966
Validation loss: 2.5575704882265446

Epoch: 5| Step: 9
Training loss: 2.6749917752148398
Validation loss: 2.558455603755151

Epoch: 5| Step: 10
Training loss: 2.541570275985584
Validation loss: 2.5589144828443287

Epoch: 5| Step: 11
Training loss: 3.4506316007672955
Validation loss: 2.5593929993458815

Epoch: 85| Step: 0
Training loss: 3.194379525745868
Validation loss: 2.5553705194825196

Epoch: 5| Step: 1
Training loss: 2.7330804866827085
Validation loss: 2.5565259386591164

Epoch: 5| Step: 2
Training loss: 2.320510701663413
Validation loss: 2.5586060230067544

Epoch: 5| Step: 3
Training loss: 2.6241800753397353
Validation loss: 2.5603347329629753

Epoch: 5| Step: 4
Training loss: 2.925427566969478
Validation loss: 2.5598383004807856

Epoch: 5| Step: 5
Training loss: 2.5045256659376305
Validation loss: 2.55871436536084

Epoch: 5| Step: 6
Training loss: 2.708094972734091
Validation loss: 2.5568894978412717

Epoch: 5| Step: 7
Training loss: 2.6678448895457345
Validation loss: 2.5568799090721006

Epoch: 5| Step: 8
Training loss: 2.661710265616064
Validation loss: 2.5541356508530186

Epoch: 5| Step: 9
Training loss: 2.6690356242438327
Validation loss: 2.5531953970807915

Epoch: 5| Step: 10
Training loss: 2.755497898589004
Validation loss: 2.5506420282494826

Epoch: 5| Step: 11
Training loss: 1.577666112070465
Validation loss: 2.5478353308553827

Epoch: 86| Step: 0
Training loss: 2.559129871371784
Validation loss: 2.5477298479894976

Epoch: 5| Step: 1
Training loss: 2.6926695318519265
Validation loss: 2.5472751451312554

Epoch: 5| Step: 2
Training loss: 2.5502933894403013
Validation loss: 2.5477483476753156

Epoch: 5| Step: 3
Training loss: 3.142413488880038
Validation loss: 2.546694052885591

Epoch: 5| Step: 4
Training loss: 2.8628412301518953
Validation loss: 2.553842169439185

Epoch: 5| Step: 5
Training loss: 2.4401428371582807
Validation loss: 2.5477452614792924

Epoch: 5| Step: 6
Training loss: 3.083411464904069
Validation loss: 2.546692371646447

Epoch: 5| Step: 7
Training loss: 2.3046211879694765
Validation loss: 2.543842153965366

Epoch: 5| Step: 8
Training loss: 2.564082238715871
Validation loss: 2.5427058836536935

Epoch: 5| Step: 9
Training loss: 2.31735194748725
Validation loss: 2.541483473168867

Epoch: 5| Step: 10
Training loss: 2.8946465637877186
Validation loss: 2.5420383288464903

Epoch: 5| Step: 11
Training loss: 2.96846793993137
Validation loss: 2.5447657613623753

Epoch: 87| Step: 0
Training loss: 2.5352972194230423
Validation loss: 2.545347809005131

Epoch: 5| Step: 1
Training loss: 3.177794396713419
Validation loss: 2.547311269609254

Epoch: 5| Step: 2
Training loss: 2.5585594582625677
Validation loss: 2.5457043326847524

Epoch: 5| Step: 3
Training loss: 2.648625730053994
Validation loss: 2.547038691278359

Epoch: 5| Step: 4
Training loss: 2.6555830174209487
Validation loss: 2.5453926172169936

Epoch: 5| Step: 5
Training loss: 2.804960189781624
Validation loss: 2.543256591976073

Epoch: 5| Step: 6
Training loss: 2.530948573873786
Validation loss: 2.5422420488822723

Epoch: 5| Step: 7
Training loss: 2.6474333803550127
Validation loss: 2.5425790272274145

Epoch: 5| Step: 8
Training loss: 2.7097066674067642
Validation loss: 2.540708425074162

Epoch: 5| Step: 9
Training loss: 2.812758370293866
Validation loss: 2.5408466584942717

Epoch: 5| Step: 10
Training loss: 2.3792977848655603
Validation loss: 2.5370865865598726

Epoch: 5| Step: 11
Training loss: 2.632070646277073
Validation loss: 2.5409035370852306

Epoch: 88| Step: 0
Training loss: 2.9378983247846513
Validation loss: 2.541727453557607

Epoch: 5| Step: 1
Training loss: 2.065738101234778
Validation loss: 2.5383442376312293

Epoch: 5| Step: 2
Training loss: 2.6818765757335408
Validation loss: 2.5435442685873646

Epoch: 5| Step: 3
Training loss: 2.5304132656269487
Validation loss: 2.534601680873786

Epoch: 5| Step: 4
Training loss: 2.72194159828111
Validation loss: 2.534743308207511

Epoch: 5| Step: 5
Training loss: 2.908985942063077
Validation loss: 2.53312497102976

Epoch: 5| Step: 6
Training loss: 2.780118733621762
Validation loss: 2.5384064594671916

Epoch: 5| Step: 7
Training loss: 2.6632230000883257
Validation loss: 2.542214289021739

Epoch: 5| Step: 8
Training loss: 2.456731586952883
Validation loss: 2.539572495324466

Epoch: 5| Step: 9
Training loss: 2.755155672220306
Validation loss: 2.5392621084149094

Epoch: 5| Step: 10
Training loss: 2.707517902177711
Validation loss: 2.539336783437404

Epoch: 5| Step: 11
Training loss: 3.4473566405300797
Validation loss: 2.5396373900016007

Epoch: 89| Step: 0
Training loss: 2.1639732590325846
Validation loss: 2.534424427834585

Epoch: 5| Step: 1
Training loss: 2.7499221443946253
Validation loss: 2.5382730557650035

Epoch: 5| Step: 2
Training loss: 2.4663854937062157
Validation loss: 2.5405650539606675

Epoch: 5| Step: 3
Training loss: 2.481488164046079
Validation loss: 2.550559598474805

Epoch: 5| Step: 4
Training loss: 2.757886069724034
Validation loss: 2.5504071524578196

Epoch: 5| Step: 5
Training loss: 2.375957898161895
Validation loss: 2.549176629065602

Epoch: 5| Step: 6
Training loss: 2.6660868988011677
Validation loss: 2.543994296353422

Epoch: 5| Step: 7
Training loss: 3.0794303178938263
Validation loss: 2.5418902960614775

Epoch: 5| Step: 8
Training loss: 2.961742442687069
Validation loss: 2.534199322947222

Epoch: 5| Step: 9
Training loss: 2.631779680376239
Validation loss: 2.5330831341939217

Epoch: 5| Step: 10
Training loss: 3.043095988795208
Validation loss: 2.531283802230629

Epoch: 5| Step: 11
Training loss: 2.6721674887307474
Validation loss: 2.533342250277068

Epoch: 90| Step: 0
Training loss: 2.46412805483353
Validation loss: 2.5354456136383736

Epoch: 5| Step: 1
Training loss: 3.0176117830343765
Validation loss: 2.5334760234095466

Epoch: 5| Step: 2
Training loss: 2.5368271598054934
Validation loss: 2.529177688677263

Epoch: 5| Step: 3
Training loss: 2.661881793251514
Validation loss: 2.529063819153677

Epoch: 5| Step: 4
Training loss: 2.3671307950420024
Validation loss: 2.5259253065437988

Epoch: 5| Step: 5
Training loss: 2.7763058725752288
Validation loss: 2.527374047280043

Epoch: 5| Step: 6
Training loss: 2.9646298377829976
Validation loss: 2.5258248789989914

Epoch: 5| Step: 7
Training loss: 2.3134157584216193
Validation loss: 2.525381754510243

Epoch: 5| Step: 8
Training loss: 2.296028136788732
Validation loss: 2.524402933692628

Epoch: 5| Step: 9
Training loss: 2.8783448705863517
Validation loss: 2.5268152147118244

Epoch: 5| Step: 10
Training loss: 3.000513032915098
Validation loss: 2.53165989370949

Epoch: 5| Step: 11
Training loss: 1.7990018779327108
Validation loss: 2.5269965474279115

Epoch: 91| Step: 0
Training loss: 2.1966737484082155
Validation loss: 2.530161823857157

Epoch: 5| Step: 1
Training loss: 2.4606125389987015
Validation loss: 2.5291297651193307

Epoch: 5| Step: 2
Training loss: 2.4397852040160912
Validation loss: 2.5287559490539295

Epoch: 5| Step: 3
Training loss: 2.5430057833504924
Validation loss: 2.5243379503946946

Epoch: 5| Step: 4
Training loss: 2.7127512380386043
Validation loss: 2.523131376580802

Epoch: 5| Step: 5
Training loss: 2.9302175627254687
Validation loss: 2.5209026182652354

Epoch: 5| Step: 6
Training loss: 3.035478611621457
Validation loss: 2.5219680554673265

Epoch: 5| Step: 7
Training loss: 2.8465532173342925
Validation loss: 2.5227286029047247

Epoch: 5| Step: 8
Training loss: 2.6946220066340425
Validation loss: 2.521133721531932

Epoch: 5| Step: 9
Training loss: 2.5759850145757066
Validation loss: 2.522678127136856

Epoch: 5| Step: 10
Training loss: 2.8113579868661627
Validation loss: 2.524920147083226

Epoch: 5| Step: 11
Training loss: 1.4461443182760934
Validation loss: 2.519417792237344

Epoch: 92| Step: 0
Training loss: 2.706088519839932
Validation loss: 2.5203417713840683

Epoch: 5| Step: 1
Training loss: 2.5944705559748242
Validation loss: 2.52025795641264

Epoch: 5| Step: 2
Training loss: 2.218162136374307
Validation loss: 2.520154389989287

Epoch: 5| Step: 3
Training loss: 2.68617091471195
Validation loss: 2.519198180270868

Epoch: 5| Step: 4
Training loss: 2.5912674202818793
Validation loss: 2.517906433906154

Epoch: 5| Step: 5
Training loss: 2.773543664753925
Validation loss: 2.5131096279025487

Epoch: 5| Step: 6
Training loss: 2.361388705023156
Validation loss: 2.53019304931807

Epoch: 5| Step: 7
Training loss: 2.6112998213336156
Validation loss: 2.5338383694058617

Epoch: 5| Step: 8
Training loss: 2.974082574515069
Validation loss: 2.5240103009507955

Epoch: 5| Step: 9
Training loss: 2.5072536142840303
Validation loss: 2.5209503199226653

Epoch: 5| Step: 10
Training loss: 3.1098776559591825
Validation loss: 2.521011816489623

Epoch: 5| Step: 11
Training loss: 3.044794712506673
Validation loss: 2.519863152143747

Epoch: 93| Step: 0
Training loss: 2.779435069226592
Validation loss: 2.52484879135383

Epoch: 5| Step: 1
Training loss: 2.6409160747026865
Validation loss: 2.5297009315943106

Epoch: 5| Step: 2
Training loss: 2.9616326394288297
Validation loss: 2.541695924236146

Epoch: 5| Step: 3
Training loss: 2.5002252477262275
Validation loss: 2.5490404335355414

Epoch: 5| Step: 4
Training loss: 2.8745324127763894
Validation loss: 2.547551359770124

Epoch: 5| Step: 5
Training loss: 3.0542900431764304
Validation loss: 2.546563970066279

Epoch: 5| Step: 6
Training loss: 2.8376402563981653
Validation loss: 2.5399879607843947

Epoch: 5| Step: 7
Training loss: 2.5486066115429407
Validation loss: 2.5380638153885133

Epoch: 5| Step: 8
Training loss: 2.4536522948546335
Validation loss: 2.5360495350820442

Epoch: 5| Step: 9
Training loss: 2.359008255300918
Validation loss: 2.530555496385641

Epoch: 5| Step: 10
Training loss: 2.150468234152421
Validation loss: 2.527259518665709

Epoch: 5| Step: 11
Training loss: 3.0489645028755126
Validation loss: 2.5255313095554146

Epoch: 94| Step: 0
Training loss: 2.8099853293962442
Validation loss: 2.526073582765495

Epoch: 5| Step: 1
Training loss: 2.3982420602502206
Validation loss: 2.522188722082945

Epoch: 5| Step: 2
Training loss: 2.8699473888612563
Validation loss: 2.522366291455763

Epoch: 5| Step: 3
Training loss: 2.8332893891760125
Validation loss: 2.521281960397798

Epoch: 5| Step: 4
Training loss: 2.4075203056707117
Validation loss: 2.517856717633022

Epoch: 5| Step: 5
Training loss: 3.2150478367783952
Validation loss: 2.5214509811573644

Epoch: 5| Step: 6
Training loss: 2.4567259582169223
Validation loss: 2.516156797885924

Epoch: 5| Step: 7
Training loss: 2.3680948967025834
Validation loss: 2.5144116731555175

Epoch: 5| Step: 8
Training loss: 2.3594164307853465
Validation loss: 2.5144784458812084

Epoch: 5| Step: 9
Training loss: 2.5978245730826797
Validation loss: 2.512579122407741

Epoch: 5| Step: 10
Training loss: 2.807701765030428
Validation loss: 2.517995203478716

Epoch: 5| Step: 11
Training loss: 2.257157491426124
Validation loss: 2.520764635006436

Epoch: 95| Step: 0
Training loss: 2.914370768505332
Validation loss: 2.522421081992128

Epoch: 5| Step: 1
Training loss: 2.997881618256885
Validation loss: 2.5226717201310658

Epoch: 5| Step: 2
Training loss: 2.5922095078815417
Validation loss: 2.5216792528964955

Epoch: 5| Step: 3
Training loss: 2.577268330978698
Validation loss: 2.5235200362589496

Epoch: 5| Step: 4
Training loss: 2.4703941182135694
Validation loss: 2.5222973644364166

Epoch: 5| Step: 5
Training loss: 2.539707888228829
Validation loss: 2.5207166421432166

Epoch: 5| Step: 6
Training loss: 2.73971855110298
Validation loss: 2.5197326461379097

Epoch: 5| Step: 7
Training loss: 2.8612817962332993
Validation loss: 2.5225311714542507

Epoch: 5| Step: 8
Training loss: 2.5724514580568547
Validation loss: 2.521715929197732

Epoch: 5| Step: 9
Training loss: 2.539377797430602
Validation loss: 2.521365449771537

Epoch: 5| Step: 10
Training loss: 2.469670763814607
Validation loss: 2.5185845738018626

Epoch: 5| Step: 11
Training loss: 1.6597407999244822
Validation loss: 2.5188132118010866

Epoch: 96| Step: 0
Training loss: 2.6976952676743653
Validation loss: 2.520923689071473

Epoch: 5| Step: 1
Training loss: 2.4968253005408485
Validation loss: 2.5187662308692955

Epoch: 5| Step: 2
Training loss: 1.8644619765472172
Validation loss: 2.521652929147169

Epoch: 5| Step: 3
Training loss: 2.9889116407692087
Validation loss: 2.5226121720028707

Epoch: 5| Step: 4
Training loss: 2.3129100951432013
Validation loss: 2.519224427143916

Epoch: 5| Step: 5
Training loss: 2.9696160910273197
Validation loss: 2.516952073785079

Epoch: 5| Step: 6
Training loss: 2.527079313379305
Validation loss: 2.521180449512935

Epoch: 5| Step: 7
Training loss: 2.9149216109085505
Validation loss: 2.513865224599251

Epoch: 5| Step: 8
Training loss: 2.4664838022890696
Validation loss: 2.513746053514587

Epoch: 5| Step: 9
Training loss: 2.317568096818804
Validation loss: 2.5168371972250436

Epoch: 5| Step: 10
Training loss: 3.0763563312752864
Validation loss: 2.5123689837164895

Epoch: 5| Step: 11
Training loss: 3.473451744252872
Validation loss: 2.514651507033169

Epoch: 97| Step: 0
Training loss: 2.482939107270373
Validation loss: 2.5149553683222012

Epoch: 5| Step: 1
Training loss: 2.818052363708537
Validation loss: 2.5124621994186276

Epoch: 5| Step: 2
Training loss: 2.7665609726383997
Validation loss: 2.512489216498266

Epoch: 5| Step: 3
Training loss: 2.7212951848453972
Validation loss: 2.5145394370148964

Epoch: 5| Step: 4
Training loss: 2.8773121036857647
Validation loss: 2.5188471099395824

Epoch: 5| Step: 5
Training loss: 2.3000509919858003
Validation loss: 2.512453172573135

Epoch: 5| Step: 6
Training loss: 2.42483615125076
Validation loss: 2.513452622603981

Epoch: 5| Step: 7
Training loss: 2.592345075548905
Validation loss: 2.5169610016115005

Epoch: 5| Step: 8
Training loss: 2.2855149207703644
Validation loss: 2.5116371430250455

Epoch: 5| Step: 9
Training loss: 3.125918596678276
Validation loss: 2.5115023371922103

Epoch: 5| Step: 10
Training loss: 2.3520104878185277
Validation loss: 2.514565546836199

Epoch: 5| Step: 11
Training loss: 3.182378057044987
Validation loss: 2.5131776447817415

Epoch: 98| Step: 0
Training loss: 2.7864557474189713
Validation loss: 2.50420532979543

Epoch: 5| Step: 1
Training loss: 3.0075301396991403
Validation loss: 2.503928447749969

Epoch: 5| Step: 2
Training loss: 2.6088501179616053
Validation loss: 2.5002076976648064

Epoch: 5| Step: 3
Training loss: 2.654982051034375
Validation loss: 2.5014349276473657

Epoch: 5| Step: 4
Training loss: 2.5901513931036497
Validation loss: 2.5039820548022376

Epoch: 5| Step: 5
Training loss: 1.9556318141176052
Validation loss: 2.503005359154193

Epoch: 5| Step: 6
Training loss: 2.9705971843782417
Validation loss: 2.5030407275056303

Epoch: 5| Step: 7
Training loss: 2.40180538937233
Validation loss: 2.5034474087839165

Epoch: 5| Step: 8
Training loss: 2.684777588680968
Validation loss: 2.501270893040801

Epoch: 5| Step: 9
Training loss: 2.8451718978036737
Validation loss: 2.503345833449599

Epoch: 5| Step: 10
Training loss: 2.0828848801189483
Validation loss: 2.49927988409866

Epoch: 5| Step: 11
Training loss: 3.1351323468808294
Validation loss: 2.49834743955327

Epoch: 99| Step: 0
Training loss: 2.5986233624698993
Validation loss: 2.4978387789213086

Epoch: 5| Step: 1
Training loss: 2.5207567649961637
Validation loss: 2.5011262423127616

Epoch: 5| Step: 2
Training loss: 2.502955120670382
Validation loss: 2.4994994218666267

Epoch: 5| Step: 3
Training loss: 2.9069649421984605
Validation loss: 2.499675622399896

Epoch: 5| Step: 4
Training loss: 2.7062718590961428
Validation loss: 2.4979030576679353

Epoch: 5| Step: 5
Training loss: 2.729842260086398
Validation loss: 2.497891910171532

Epoch: 5| Step: 6
Training loss: 2.588163034748719
Validation loss: 2.4980142296474104

Epoch: 5| Step: 7
Training loss: 2.467826960428184
Validation loss: 2.4996228927069537

Epoch: 5| Step: 8
Training loss: 2.783834221212069
Validation loss: 2.496401545452177

Epoch: 5| Step: 9
Training loss: 2.380984346084373
Validation loss: 2.4976863009311825

Epoch: 5| Step: 10
Training loss: 2.587481541959376
Validation loss: 2.497282203950651

Epoch: 5| Step: 11
Training loss: 2.509057802363873
Validation loss: 2.4950681638038543

Epoch: 100| Step: 0
Training loss: 2.267579281565973
Validation loss: 2.49984199104062

Epoch: 5| Step: 1
Training loss: 2.6817562914614768
Validation loss: 2.4942961912896697

Epoch: 5| Step: 2
Training loss: 2.8911749239359246
Validation loss: 2.4982205376049693

Epoch: 5| Step: 3
Training loss: 2.5482503535763423
Validation loss: 2.497612242061883

Epoch: 5| Step: 4
Training loss: 2.881757341513371
Validation loss: 2.491031454338198

Epoch: 5| Step: 5
Training loss: 2.663718640461945
Validation loss: 2.4908611870062662

Epoch: 5| Step: 6
Training loss: 2.6790432614332413
Validation loss: 2.4966080065695953

Epoch: 5| Step: 7
Training loss: 2.5117473215047292
Validation loss: 2.4954087815473582

Epoch: 5| Step: 8
Training loss: 2.885410699023377
Validation loss: 2.4972329323590454

Epoch: 5| Step: 9
Training loss: 2.1198819177958828
Validation loss: 2.4940651304907213

Epoch: 5| Step: 10
Training loss: 2.6263254543179317
Validation loss: 2.4940653117217035

Epoch: 5| Step: 11
Training loss: 2.7197589975063234
Validation loss: 2.4895396860571477

Epoch: 101| Step: 0
Training loss: 2.729168889479181
Validation loss: 2.487826421061661

Epoch: 5| Step: 1
Training loss: 2.382487590713447
Validation loss: 2.4887102716386185

Epoch: 5| Step: 2
Training loss: 3.0043608441782172
Validation loss: 2.4901979929940357

Epoch: 5| Step: 3
Training loss: 2.023570052706164
Validation loss: 2.494380273261407

Epoch: 5| Step: 4
Training loss: 2.7122758095907686
Validation loss: 2.4934987372619624

Epoch: 5| Step: 5
Training loss: 2.3342676222284022
Validation loss: 2.4921899076029628

Epoch: 5| Step: 6
Training loss: 2.9181553629040895
Validation loss: 2.499455758300681

Epoch: 5| Step: 7
Training loss: 2.7153758014786122
Validation loss: 2.49225260411352

Epoch: 5| Step: 8
Training loss: 2.7532181549766124
Validation loss: 2.4908679869155477

Epoch: 5| Step: 9
Training loss: 2.9170258618745937
Validation loss: 2.4940285016465324

Epoch: 5| Step: 10
Training loss: 2.4881131820570532
Validation loss: 2.4944702623643558

Epoch: 5| Step: 11
Training loss: 0.9054925318072432
Validation loss: 2.4976568287870733

Epoch: 102| Step: 0
Training loss: 2.7940879873349083
Validation loss: 2.503518037263634

Epoch: 5| Step: 1
Training loss: 2.2460603131003025
Validation loss: 2.5101072086372205

Epoch: 5| Step: 2
Training loss: 2.251241235625953
Validation loss: 2.512512188497557

Epoch: 5| Step: 3
Training loss: 2.7605557292722285
Validation loss: 2.511437625290694

Epoch: 5| Step: 4
Training loss: 2.449467647870673
Validation loss: 2.510685413005047

Epoch: 5| Step: 5
Training loss: 2.360213478099159
Validation loss: 2.510614095867884

Epoch: 5| Step: 6
Training loss: 3.037121778260445
Validation loss: 2.5135032796846564

Epoch: 5| Step: 7
Training loss: 2.561878687271253
Validation loss: 2.514057200038801

Epoch: 5| Step: 8
Training loss: 3.0835367255958124
Validation loss: 2.507564037211442

Epoch: 5| Step: 9
Training loss: 2.6135296667884504
Validation loss: 2.5017738367383955

Epoch: 5| Step: 10
Training loss: 2.6916354099816964
Validation loss: 2.502751830657217

Epoch: 5| Step: 11
Training loss: 2.8210967180885627
Validation loss: 2.502924373014307

Epoch: 103| Step: 0
Training loss: 2.836677055504225
Validation loss: 2.4976037621414586

Epoch: 5| Step: 1
Training loss: 3.026180944777537
Validation loss: 2.4930283613737756

Epoch: 5| Step: 2
Training loss: 2.5683776622744867
Validation loss: 2.4919362713855713

Epoch: 5| Step: 3
Training loss: 2.673704000953882
Validation loss: 2.4912010959304736

Epoch: 5| Step: 4
Training loss: 2.4505584313930133
Validation loss: 2.490277342581464

Epoch: 5| Step: 5
Training loss: 2.7923163232186954
Validation loss: 2.4873302025566533

Epoch: 5| Step: 6
Training loss: 2.224439820483713
Validation loss: 2.489136377752039

Epoch: 5| Step: 7
Training loss: 2.619905887689778
Validation loss: 2.4933609865392463

Epoch: 5| Step: 8
Training loss: 2.158008797989129
Validation loss: 2.494392826370597

Epoch: 5| Step: 9
Training loss: 2.3328144541053226
Validation loss: 2.495413347697369

Epoch: 5| Step: 10
Training loss: 2.825317506755135
Validation loss: 2.4930803021153496

Epoch: 5| Step: 11
Training loss: 2.7490700102904384
Validation loss: 2.50051923763831

Epoch: 104| Step: 0
Training loss: 3.0645038510580167
Validation loss: 2.4945428255622812

Epoch: 5| Step: 1
Training loss: 2.523016643564527
Validation loss: 2.4937238113443168

Epoch: 5| Step: 2
Training loss: 2.526580459445968
Validation loss: 2.4875429097025727

Epoch: 5| Step: 3
Training loss: 2.6431347358760635
Validation loss: 2.4914529249975383

Epoch: 5| Step: 4
Training loss: 2.3647523951205276
Validation loss: 2.48655935342489

Epoch: 5| Step: 5
Training loss: 2.7350517961245506
Validation loss: 2.4894626553601094

Epoch: 5| Step: 6
Training loss: 2.9345266024718937
Validation loss: 2.4899006778308332

Epoch: 5| Step: 7
Training loss: 2.776744321795849
Validation loss: 2.4869661873417175

Epoch: 5| Step: 8
Training loss: 1.9460031286922133
Validation loss: 2.490001895998293

Epoch: 5| Step: 9
Training loss: 2.513154137325553
Validation loss: 2.484827004506005

Epoch: 5| Step: 10
Training loss: 2.32591624100449
Validation loss: 2.4863956918697827

Epoch: 5| Step: 11
Training loss: 3.3142233630126627
Validation loss: 2.486639694026248

Epoch: 105| Step: 0
Training loss: 2.872878577348933
Validation loss: 2.4871418418740303

Epoch: 5| Step: 1
Training loss: 2.36835040745586
Validation loss: 2.485113382074682

Epoch: 5| Step: 2
Training loss: 2.6030901298614553
Validation loss: 2.4843962406554

Epoch: 5| Step: 3
Training loss: 2.6388065916468557
Validation loss: 2.485693791478019

Epoch: 5| Step: 4
Training loss: 2.774848084973993
Validation loss: 2.483712397890531

Epoch: 5| Step: 5
Training loss: 2.5222562972001614
Validation loss: 2.4804862434791604

Epoch: 5| Step: 6
Training loss: 2.3540096286845764
Validation loss: 2.481668507540293

Epoch: 5| Step: 7
Training loss: 2.6246449366625924
Validation loss: 2.477898657453063

Epoch: 5| Step: 8
Training loss: 2.7188771536020884
Validation loss: 2.4787918870740095

Epoch: 5| Step: 9
Training loss: 2.853554226028696
Validation loss: 2.4834313969856945

Epoch: 5| Step: 10
Training loss: 2.3531105800961933
Validation loss: 2.4849334405054684

Epoch: 5| Step: 11
Training loss: 1.9058557321521856
Validation loss: 2.4826722937932284

Epoch: 106| Step: 0
Training loss: 2.5779768467729802
Validation loss: 2.4835049767241775

Epoch: 5| Step: 1
Training loss: 2.436443686852393
Validation loss: 2.48390912740198

Epoch: 5| Step: 2
Training loss: 2.5428319563161748
Validation loss: 2.48353011681851

Epoch: 5| Step: 3
Training loss: 2.346461037852673
Validation loss: 2.4766264625416254

Epoch: 5| Step: 4
Training loss: 2.451615567724014
Validation loss: 2.479679404591849

Epoch: 5| Step: 5
Training loss: 2.3488579592577654
Validation loss: 2.4882143332018654

Epoch: 5| Step: 6
Training loss: 2.6526323703594987
Validation loss: 2.485347713325083

Epoch: 5| Step: 7
Training loss: 2.958828056411394
Validation loss: 2.486751183783589

Epoch: 5| Step: 8
Training loss: 3.17782995904378
Validation loss: 2.4848896309311383

Epoch: 5| Step: 9
Training loss: 2.3840190896799665
Validation loss: 2.4813730308657242

Epoch: 5| Step: 10
Training loss: 2.7395296176145556
Validation loss: 2.4809546968333605

Epoch: 5| Step: 11
Training loss: 2.34590131571924
Validation loss: 2.488001597612743

Epoch: 107| Step: 0
Training loss: 2.2429141684720277
Validation loss: 2.487145692266485

Epoch: 5| Step: 1
Training loss: 2.5760716439762854
Validation loss: 2.4862997208756052

Epoch: 5| Step: 2
Training loss: 2.249841260608626
Validation loss: 2.486220368205059

Epoch: 5| Step: 3
Training loss: 2.9051874330757506
Validation loss: 2.490698709518003

Epoch: 5| Step: 4
Training loss: 2.5829897211086665
Validation loss: 2.4872703355170103

Epoch: 5| Step: 5
Training loss: 2.0382780122566753
Validation loss: 2.4879031769934037

Epoch: 5| Step: 6
Training loss: 2.931421687256971
Validation loss: 2.4898490059059704

Epoch: 5| Step: 7
Training loss: 2.8535665916157704
Validation loss: 2.488245314533722

Epoch: 5| Step: 8
Training loss: 2.41217648802763
Validation loss: 2.493476231525155

Epoch: 5| Step: 9
Training loss: 2.6349037083326325
Validation loss: 2.48671672827754

Epoch: 5| Step: 10
Training loss: 3.0036970246747656
Validation loss: 2.491767114402856

Epoch: 5| Step: 11
Training loss: 2.8348606892153096
Validation loss: 2.486179500192101

Epoch: 108| Step: 0
Training loss: 2.539279118614223
Validation loss: 2.4858606283057885

Epoch: 5| Step: 1
Training loss: 2.3939097657435244
Validation loss: 2.4881468556439255

Epoch: 5| Step: 2
Training loss: 2.759144231838895
Validation loss: 2.4928746925270544

Epoch: 5| Step: 3
Training loss: 2.277361442798178
Validation loss: 2.489915403993423

Epoch: 5| Step: 4
Training loss: 2.619975048849091
Validation loss: 2.491444611515711

Epoch: 5| Step: 5
Training loss: 2.8491821387124596
Validation loss: 2.4884960455137146

Epoch: 5| Step: 6
Training loss: 2.757627140548385
Validation loss: 2.4892898862799484

Epoch: 5| Step: 7
Training loss: 2.791130004845524
Validation loss: 2.4881250241600688

Epoch: 5| Step: 8
Training loss: 2.543375712233708
Validation loss: 2.4863914207998024

Epoch: 5| Step: 9
Training loss: 2.7219351165124084
Validation loss: 2.481906988539293

Epoch: 5| Step: 10
Training loss: 2.365562661885309
Validation loss: 2.4789146140272353

Epoch: 5| Step: 11
Training loss: 2.1832045752533653
Validation loss: 2.4752597952649125

Epoch: 109| Step: 0
Training loss: 2.805979056755318
Validation loss: 2.4712909908815255

Epoch: 5| Step: 1
Training loss: 3.0119956516371262
Validation loss: 2.47805445563858

Epoch: 5| Step: 2
Training loss: 2.3118773988338504
Validation loss: 2.4760706199479925

Epoch: 5| Step: 3
Training loss: 2.6265880685590903
Validation loss: 2.4801118929421637

Epoch: 5| Step: 4
Training loss: 2.5043614490010087
Validation loss: 2.480008584739583

Epoch: 5| Step: 5
Training loss: 2.4827251594214212
Validation loss: 2.485909861553457

Epoch: 5| Step: 6
Training loss: 2.255572412247248
Validation loss: 2.4798693836396666

Epoch: 5| Step: 7
Training loss: 2.627316134305135
Validation loss: 2.484607425749666

Epoch: 5| Step: 8
Training loss: 2.6058836096230116
Validation loss: 2.4777396660550344

Epoch: 5| Step: 9
Training loss: 2.5306363715973625
Validation loss: 2.4836682527960536

Epoch: 5| Step: 10
Training loss: 2.5652966938607626
Validation loss: 2.479006066182696

Epoch: 5| Step: 11
Training loss: 2.8137234040286656
Validation loss: 2.4764922098961097

Epoch: 110| Step: 0
Training loss: 2.6795980811144524
Validation loss: 2.4770514870904607

Epoch: 5| Step: 1
Training loss: 2.3760838294284645
Validation loss: 2.4767483381789006

Epoch: 5| Step: 2
Training loss: 2.0925745155256346
Validation loss: 2.4769074112578555

Epoch: 5| Step: 3
Training loss: 2.614415400204539
Validation loss: 2.476851000262464

Epoch: 5| Step: 4
Training loss: 2.436890843886092
Validation loss: 2.4792499822085934

Epoch: 5| Step: 5
Training loss: 1.9965101431100063
Validation loss: 2.4787550886431857

Epoch: 5| Step: 6
Training loss: 2.716017478965281
Validation loss: 2.4766913700369217

Epoch: 5| Step: 7
Training loss: 2.9833816552821766
Validation loss: 2.478131873019847

Epoch: 5| Step: 8
Training loss: 2.505584773109227
Validation loss: 2.4752965272653698

Epoch: 5| Step: 9
Training loss: 3.00211768111929
Validation loss: 2.4751386470364185

Epoch: 5| Step: 10
Training loss: 2.6567865166459534
Validation loss: 2.473778327951895

Epoch: 5| Step: 11
Training loss: 3.240920074183579
Validation loss: 2.4761241721493805

Epoch: 111| Step: 0
Training loss: 2.9451230744581887
Validation loss: 2.474767040116562

Epoch: 5| Step: 1
Training loss: 2.7165406117906303
Validation loss: 2.4740284732446023

Epoch: 5| Step: 2
Training loss: 2.545017618294459
Validation loss: 2.4755845370216596

Epoch: 5| Step: 3
Training loss: 2.3042321741358873
Validation loss: 2.471272065567918

Epoch: 5| Step: 4
Training loss: 2.7057981999353156
Validation loss: 2.4791254566411283

Epoch: 5| Step: 5
Training loss: 2.5615092897769802
Validation loss: 2.4763183112352727

Epoch: 5| Step: 6
Training loss: 2.751620248841662
Validation loss: 2.473116341242247

Epoch: 5| Step: 7
Training loss: 2.831377045936716
Validation loss: 2.46976402237211

Epoch: 5| Step: 8
Training loss: 2.4707657515839982
Validation loss: 2.4772252661101315

Epoch: 5| Step: 9
Training loss: 2.450724210552661
Validation loss: 2.4737372463553577

Epoch: 5| Step: 10
Training loss: 2.231567112376093
Validation loss: 2.4752236928260722

Epoch: 5| Step: 11
Training loss: 1.2785248035505872
Validation loss: 2.4730828044351907

Epoch: 112| Step: 0
Training loss: 2.4661802607022847
Validation loss: 2.477690104069457

Epoch: 5| Step: 1
Training loss: 2.9439992228175256
Validation loss: 2.477908104844924

Epoch: 5| Step: 2
Training loss: 2.577258525085707
Validation loss: 2.4798454622955752

Epoch: 5| Step: 3
Training loss: 2.775303172828302
Validation loss: 2.479083664223239

Epoch: 5| Step: 4
Training loss: 2.131555543179884
Validation loss: 2.480593884933629

Epoch: 5| Step: 5
Training loss: 2.8208737647024757
Validation loss: 2.4821810601794567

Epoch: 5| Step: 6
Training loss: 2.346082213656389
Validation loss: 2.481293020187755

Epoch: 5| Step: 7
Training loss: 2.6732606919646593
Validation loss: 2.474780198493558

Epoch: 5| Step: 8
Training loss: 1.9881367509117496
Validation loss: 2.4732138038767255

Epoch: 5| Step: 9
Training loss: 3.071419009323697
Validation loss: 2.4747761241408615

Epoch: 5| Step: 10
Training loss: 2.293873908830439
Validation loss: 2.4730983136080242

Epoch: 5| Step: 11
Training loss: 2.20552462575617
Validation loss: 2.481020920537785

Epoch: 113| Step: 0
Training loss: 2.4367085663636794
Validation loss: 2.514238149016404

Epoch: 5| Step: 1
Training loss: 2.8179232550053332
Validation loss: 2.513799135058932

Epoch: 5| Step: 2
Training loss: 2.8024843536402986
Validation loss: 2.5156905756078283

Epoch: 5| Step: 3
Training loss: 2.732246224222673
Validation loss: 2.511758273037696

Epoch: 5| Step: 4
Training loss: 2.4948392052524544
Validation loss: 2.4882473626416806

Epoch: 5| Step: 5
Training loss: 2.2135672414461607
Validation loss: 2.477222968278645

Epoch: 5| Step: 6
Training loss: 2.754523718038842
Validation loss: 2.4721677035369822

Epoch: 5| Step: 7
Training loss: 2.744212215480747
Validation loss: 2.4722773687025787

Epoch: 5| Step: 8
Training loss: 2.4557821862061884
Validation loss: 2.4716699007951597

Epoch: 5| Step: 9
Training loss: 2.6505018982548547
Validation loss: 2.4752644848710688

Epoch: 5| Step: 10
Training loss: 2.808539675217227
Validation loss: 2.481813745971583

Epoch: 5| Step: 11
Training loss: 2.442368365111208
Validation loss: 2.4804792188688816

Epoch: 114| Step: 0
Training loss: 2.2351134887146293
Validation loss: 2.4812135594444205

Epoch: 5| Step: 1
Training loss: 3.2011785780607824
Validation loss: 2.4806492577101427

Epoch: 5| Step: 2
Training loss: 2.606992627647403
Validation loss: 2.4818589127165787

Epoch: 5| Step: 3
Training loss: 2.915897885683984
Validation loss: 2.481338412601814

Epoch: 5| Step: 4
Training loss: 2.447177650958913
Validation loss: 2.4800060311206935

Epoch: 5| Step: 5
Training loss: 2.243110812214868
Validation loss: 2.4763442784706498

Epoch: 5| Step: 6
Training loss: 2.9865621970275233
Validation loss: 2.475031308175196

Epoch: 5| Step: 7
Training loss: 2.5744813081852174
Validation loss: 2.4729553893436527

Epoch: 5| Step: 8
Training loss: 2.220253877986669
Validation loss: 2.4775227711680348

Epoch: 5| Step: 9
Training loss: 2.097192808987783
Validation loss: 2.475498400061567

Epoch: 5| Step: 10
Training loss: 2.551087248646647
Validation loss: 2.477366071392171

Epoch: 5| Step: 11
Training loss: 3.4501962799407786
Validation loss: 2.473742081409571

Epoch: 115| Step: 0
Training loss: 2.4929318646768883
Validation loss: 2.469595410258618

Epoch: 5| Step: 1
Training loss: 2.2595480613856007
Validation loss: 2.4713486985258997

Epoch: 5| Step: 2
Training loss: 3.0605048083619857
Validation loss: 2.47784494113938

Epoch: 5| Step: 3
Training loss: 2.7166681320872965
Validation loss: 2.482466712544731

Epoch: 5| Step: 4
Training loss: 2.911660193654642
Validation loss: 2.4790086869519365

Epoch: 5| Step: 5
Training loss: 2.62893799171727
Validation loss: 2.485653026711519

Epoch: 5| Step: 6
Training loss: 2.2918207521366756
Validation loss: 2.4844497293553225

Epoch: 5| Step: 7
Training loss: 2.567490532995969
Validation loss: 2.475691906067372

Epoch: 5| Step: 8
Training loss: 2.4228948599265094
Validation loss: 2.474507185971981

Epoch: 5| Step: 9
Training loss: 2.6431470034502706
Validation loss: 2.474119776761869

Epoch: 5| Step: 10
Training loss: 2.559201233942057
Validation loss: 2.4750357895007067

Epoch: 5| Step: 11
Training loss: 1.858211056858958
Validation loss: 2.4767055490217493

Epoch: 116| Step: 0
Training loss: 2.6737032875806417
Validation loss: 2.47516416108014

Epoch: 5| Step: 1
Training loss: 2.4888211178162316
Validation loss: 2.476190364568222

Epoch: 5| Step: 2
Training loss: 2.5273990300779117
Validation loss: 2.4745047772227107

Epoch: 5| Step: 3
Training loss: 2.263233474790786
Validation loss: 2.4745774923155985

Epoch: 5| Step: 4
Training loss: 2.5690952189711895
Validation loss: 2.478540927927147

Epoch: 5| Step: 5
Training loss: 2.6865641716684214
Validation loss: 2.4749756029962366

Epoch: 5| Step: 6
Training loss: 2.456999131130737
Validation loss: 2.4776070655248197

Epoch: 5| Step: 7
Training loss: 2.67337654262767
Validation loss: 2.474527455504208

Epoch: 5| Step: 8
Training loss: 2.7167408853077673
Validation loss: 2.4783253297332366

Epoch: 5| Step: 9
Training loss: 2.785362203936267
Validation loss: 2.4781804981727813

Epoch: 5| Step: 10
Training loss: 2.235208315944562
Validation loss: 2.469933467598273

Epoch: 5| Step: 11
Training loss: 3.537405135429512
Validation loss: 2.4752207269083515

Epoch: 117| Step: 0
Training loss: 2.725722393910383
Validation loss: 2.4692082965567357

Epoch: 5| Step: 1
Training loss: 2.7073564870740254
Validation loss: 2.471113566406501

Epoch: 5| Step: 2
Training loss: 2.636977435950331
Validation loss: 2.4656250889612528

Epoch: 5| Step: 3
Training loss: 2.586063808341354
Validation loss: 2.465833683795996

Epoch: 5| Step: 4
Training loss: 2.1882417783544597
Validation loss: 2.4716686025969046

Epoch: 5| Step: 5
Training loss: 2.264616537918121
Validation loss: 2.469296942052996

Epoch: 5| Step: 6
Training loss: 2.822072502313324
Validation loss: 2.4710123102382426

Epoch: 5| Step: 7
Training loss: 2.4773538089428886
Validation loss: 2.471662075422588

Epoch: 5| Step: 8
Training loss: 2.8217977485770507
Validation loss: 2.469350049777776

Epoch: 5| Step: 9
Training loss: 2.112616979305814
Validation loss: 2.4740302500394216

Epoch: 5| Step: 10
Training loss: 2.5835015847164526
Validation loss: 2.472710241739707

Epoch: 5| Step: 11
Training loss: 3.3619755105437776
Validation loss: 2.4704695841264064

Epoch: 118| Step: 0
Training loss: 2.7514845568975494
Validation loss: 2.470188538611782

Epoch: 5| Step: 1
Training loss: 2.5732744305380333
Validation loss: 2.4719916319790345

Epoch: 5| Step: 2
Training loss: 2.66694838307353
Validation loss: 2.4666113986340426

Epoch: 5| Step: 3
Training loss: 2.3513718841452595
Validation loss: 2.4636321356992603

Epoch: 5| Step: 4
Training loss: 3.060528334590061
Validation loss: 2.4708433249680573

Epoch: 5| Step: 5
Training loss: 2.7601514197014945
Validation loss: 2.465357948993543

Epoch: 5| Step: 6
Training loss: 2.8821182035180812
Validation loss: 2.467545783015292

Epoch: 5| Step: 7
Training loss: 2.4029180072983314
Validation loss: 2.4684864861250624

Epoch: 5| Step: 8
Training loss: 2.3442176860849373
Validation loss: 2.470380381536822

Epoch: 5| Step: 9
Training loss: 2.6333103331837004
Validation loss: 2.471976057591867

Epoch: 5| Step: 10
Training loss: 1.6659895793135524
Validation loss: 2.4733721082039444

Epoch: 5| Step: 11
Training loss: 2.3196913790140425
Validation loss: 2.4693755713323537

Epoch: 119| Step: 0
Training loss: 2.4887149738201737
Validation loss: 2.469416222633359

Epoch: 5| Step: 1
Training loss: 2.4644936677213285
Validation loss: 2.4619362615875464

Epoch: 5| Step: 2
Training loss: 2.3814836642746022
Validation loss: 2.4691508808676357

Epoch: 5| Step: 3
Training loss: 2.645970008103448
Validation loss: 2.4657148866179637

Epoch: 5| Step: 4
Training loss: 3.2200730946934195
Validation loss: 2.468154537642092

Epoch: 5| Step: 5
Training loss: 2.318986507394614
Validation loss: 2.461929331329502

Epoch: 5| Step: 6
Training loss: 2.1043893173813837
Validation loss: 2.465913640135143

Epoch: 5| Step: 7
Training loss: 2.8329098515896844
Validation loss: 2.4621333733616217

Epoch: 5| Step: 8
Training loss: 2.3272711705072573
Validation loss: 2.461234166666084

Epoch: 5| Step: 9
Training loss: 2.3413498859921074
Validation loss: 2.4628225403343746

Epoch: 5| Step: 10
Training loss: 2.7331619623782912
Validation loss: 2.461785209821577

Epoch: 5| Step: 11
Training loss: 3.3182768920921553
Validation loss: 2.4684407004222026

Epoch: 120| Step: 0
Training loss: 3.0369826704378067
Validation loss: 2.480014040462424

Epoch: 5| Step: 1
Training loss: 2.870734658134916
Validation loss: 2.480124013579064

Epoch: 5| Step: 2
Training loss: 2.4224634255560473
Validation loss: 2.4796383606677566

Epoch: 5| Step: 3
Training loss: 2.5268822179290695
Validation loss: 2.4851253663899953

Epoch: 5| Step: 4
Training loss: 2.3579299240247424
Validation loss: 2.4864296883663153

Epoch: 5| Step: 5
Training loss: 2.802094432331401
Validation loss: 2.4926431253344714

Epoch: 5| Step: 6
Training loss: 2.2323275702207823
Validation loss: 2.4957095085743464

Epoch: 5| Step: 7
Training loss: 2.4080379828565586
Validation loss: 2.4938640157310363

Epoch: 5| Step: 8
Training loss: 2.5748418074227306
Validation loss: 2.493144912735835

Epoch: 5| Step: 9
Training loss: 2.4944203099718965
Validation loss: 2.4923572940843837

Epoch: 5| Step: 10
Training loss: 2.880968284487975
Validation loss: 2.492238748754931

Epoch: 5| Step: 11
Training loss: 1.908822496957257
Validation loss: 2.492976136626503

Epoch: 121| Step: 0
Training loss: 2.836033338708592
Validation loss: 2.4889646716468343

Epoch: 5| Step: 1
Training loss: 2.5801650789957966
Validation loss: 2.4844433317244037

Epoch: 5| Step: 2
Training loss: 2.6263617661817977
Validation loss: 2.4830146159926003

Epoch: 5| Step: 3
Training loss: 2.7682612726186493
Validation loss: 2.4853284193958705

Epoch: 5| Step: 4
Training loss: 2.640527305827346
Validation loss: 2.484804836012383

Epoch: 5| Step: 5
Training loss: 2.849767501449354
Validation loss: 2.4812647085610653

Epoch: 5| Step: 6
Training loss: 2.7504390019357166
Validation loss: 2.479504102828774

Epoch: 5| Step: 7
Training loss: 2.513444227745332
Validation loss: 2.4742520542792135

Epoch: 5| Step: 8
Training loss: 2.052621244875574
Validation loss: 2.4759741123298977

Epoch: 5| Step: 9
Training loss: 2.7256602021244447
Validation loss: 2.4731010972954173

Epoch: 5| Step: 10
Training loss: 2.290440896248262
Validation loss: 2.4745355809345595

Epoch: 5| Step: 11
Training loss: 2.0770595945827464
Validation loss: 2.470732014000912

Epoch: 122| Step: 0
Training loss: 2.4536950487774596
Validation loss: 2.4757522075727594

Epoch: 5| Step: 1
Training loss: 2.6858070719120835
Validation loss: 2.471071278681669

Epoch: 5| Step: 2
Training loss: 2.6705451913055005
Validation loss: 2.4687915468542707

Epoch: 5| Step: 3
Training loss: 2.5227938087930553
Validation loss: 2.466590355216773

Epoch: 5| Step: 4
Training loss: 2.6863500219497993
Validation loss: 2.4671488007724927

Epoch: 5| Step: 5
Training loss: 2.3977598543924157
Validation loss: 2.4737525185085003

Epoch: 5| Step: 6
Training loss: 2.7312353801554243
Validation loss: 2.4694356931827652

Epoch: 5| Step: 7
Training loss: 2.5284466702685444
Validation loss: 2.4707824091196042

Epoch: 5| Step: 8
Training loss: 2.510411422111974
Validation loss: 2.470316454317007

Epoch: 5| Step: 9
Training loss: 2.5075495216598735
Validation loss: 2.4679132765858793

Epoch: 5| Step: 10
Training loss: 2.669485082944414
Validation loss: 2.4692417974775775

Epoch: 5| Step: 11
Training loss: 2.063970792755946
Validation loss: 2.4684114264249972

Epoch: 123| Step: 0
Training loss: 2.6844335405319155
Validation loss: 2.465574761681859

Epoch: 5| Step: 1
Training loss: 2.4012911343563648
Validation loss: 2.4663432135273435

Epoch: 5| Step: 2
Training loss: 3.091886787769926
Validation loss: 2.4655410215631726

Epoch: 5| Step: 3
Training loss: 2.4906732150093163
Validation loss: 2.465479382403927

Epoch: 5| Step: 4
Training loss: 2.332357054783799
Validation loss: 2.4665631978676656

Epoch: 5| Step: 5
Training loss: 2.1150614631686135
Validation loss: 2.465686043586812

Epoch: 5| Step: 6
Training loss: 2.6926638650573427
Validation loss: 2.4687287474574586

Epoch: 5| Step: 7
Training loss: 2.271376262004204
Validation loss: 2.464019591256822

Epoch: 5| Step: 8
Training loss: 2.6522315651900805
Validation loss: 2.472241086090165

Epoch: 5| Step: 9
Training loss: 2.7253450227749263
Validation loss: 2.455949695888723

Epoch: 5| Step: 10
Training loss: 2.684490026423144
Validation loss: 2.4624263962203776

Epoch: 5| Step: 11
Training loss: 1.8729813199310854
Validation loss: 2.4612775577754427

Epoch: 124| Step: 0
Training loss: 2.165863719735344
Validation loss: 2.4625793349045435

Epoch: 5| Step: 1
Training loss: 2.738494647060008
Validation loss: 2.464749269442997

Epoch: 5| Step: 2
Training loss: 2.4956059941944515
Validation loss: 2.469790211364326

Epoch: 5| Step: 3
Training loss: 1.9341206150689372
Validation loss: 2.4726389361554273

Epoch: 5| Step: 4
Training loss: 2.4336998489298955
Validation loss: 2.4698559139030447

Epoch: 5| Step: 5
Training loss: 2.5144487557248043
Validation loss: 2.4670586727717843

Epoch: 5| Step: 6
Training loss: 2.9127582157259138
Validation loss: 2.4680032002957932

Epoch: 5| Step: 7
Training loss: 3.043496787565719
Validation loss: 2.468331559045563

Epoch: 5| Step: 8
Training loss: 2.902601679845311
Validation loss: 2.468328705585202

Epoch: 5| Step: 9
Training loss: 2.609694409951111
Validation loss: 2.469574408358717

Epoch: 5| Step: 10
Training loss: 2.2331224678851553
Validation loss: 2.4718192613878585

Epoch: 5| Step: 11
Training loss: 1.8928078904646077
Validation loss: 2.4706022138933634

Epoch: 125| Step: 0
Training loss: 2.54197155317211
Validation loss: 2.465122769337501

Epoch: 5| Step: 1
Training loss: 2.51996527193754
Validation loss: 2.46888537981354

Epoch: 5| Step: 2
Training loss: 3.09599068927597
Validation loss: 2.4684364626764324

Epoch: 5| Step: 3
Training loss: 2.6046469792244507
Validation loss: 2.4702048380982706

Epoch: 5| Step: 4
Training loss: 2.7852692440701117
Validation loss: 2.463382850243064

Epoch: 5| Step: 5
Training loss: 2.626240301028049
Validation loss: 2.4598432621025217

Epoch: 5| Step: 6
Training loss: 2.220190520831828
Validation loss: 2.464454297686072

Epoch: 5| Step: 7
Training loss: 2.165313469303953
Validation loss: 2.4597206861593013

Epoch: 5| Step: 8
Training loss: 2.370974089919753
Validation loss: 2.457242826197693

Epoch: 5| Step: 9
Training loss: 2.6276709274314873
Validation loss: 2.466339834142907

Epoch: 5| Step: 10
Training loss: 2.37289817563947
Validation loss: 2.4672035975350846

Epoch: 5| Step: 11
Training loss: 2.4586351069343926
Validation loss: 2.455402125280945

Epoch: 126| Step: 0
Training loss: 2.022477912923689
Validation loss: 2.456252989148367

Epoch: 5| Step: 1
Training loss: 2.9078951865384615
Validation loss: 2.457175791844847

Epoch: 5| Step: 2
Training loss: 2.9779075327006765
Validation loss: 2.461144155070474

Epoch: 5| Step: 3
Training loss: 2.30081430615446
Validation loss: 2.4621181138670485

Epoch: 5| Step: 4
Training loss: 2.9225613201094354
Validation loss: 2.461861314905808

Epoch: 5| Step: 5
Training loss: 2.9300724031010823
Validation loss: 2.4649743853096417

Epoch: 5| Step: 6
Training loss: 2.6254488243414382
Validation loss: 2.4657768945679877

Epoch: 5| Step: 7
Training loss: 2.2874452261281846
Validation loss: 2.468614433686919

Epoch: 5| Step: 8
Training loss: 2.6356747064930577
Validation loss: 2.464472408705971

Epoch: 5| Step: 9
Training loss: 2.3218665265304774
Validation loss: 2.467785481870258

Epoch: 5| Step: 10
Training loss: 1.7357404677733548
Validation loss: 2.462225481084055

Epoch: 5| Step: 11
Training loss: 2.785001817356797
Validation loss: 2.464572623566301

Epoch: 127| Step: 0
Training loss: 2.5162432367013166
Validation loss: 2.4620381835573886

Epoch: 5| Step: 1
Training loss: 2.2987222314913325
Validation loss: 2.459251052014456

Epoch: 5| Step: 2
Training loss: 2.557136132093691
Validation loss: 2.4600737897795213

Epoch: 5| Step: 3
Training loss: 2.1133896664152108
Validation loss: 2.4551541952175038

Epoch: 5| Step: 4
Training loss: 1.9814867642326617
Validation loss: 2.46348089555838

Epoch: 5| Step: 5
Training loss: 2.862151751927562
Validation loss: 2.460648163432988

Epoch: 5| Step: 6
Training loss: 2.8259449348997316
Validation loss: 2.4748895010380214

Epoch: 5| Step: 7
Training loss: 2.907666261204654
Validation loss: 2.463366767745015

Epoch: 5| Step: 8
Training loss: 2.278978863312213
Validation loss: 2.469824810494831

Epoch: 5| Step: 9
Training loss: 3.3587103607598534
Validation loss: 2.4622971184899307

Epoch: 5| Step: 10
Training loss: 2.0887182324389055
Validation loss: 2.4643139660260966

Epoch: 5| Step: 11
Training loss: 2.292824111873718
Validation loss: 2.4635723399752187

Epoch: 128| Step: 0
Training loss: 2.1587286814137845
Validation loss: 2.4692203500207373

Epoch: 5| Step: 1
Training loss: 2.5828138772599645
Validation loss: 2.467920115572222

Epoch: 5| Step: 2
Training loss: 1.7200631413957406
Validation loss: 2.4696652611077896

Epoch: 5| Step: 3
Training loss: 2.395762190937344
Validation loss: 2.468314027719343

Epoch: 5| Step: 4
Training loss: 2.9609935423044003
Validation loss: 2.472810255319846

Epoch: 5| Step: 5
Training loss: 2.407423055494701
Validation loss: 2.471919660651065

Epoch: 5| Step: 6
Training loss: 2.8925083932449835
Validation loss: 2.4697788846894397

Epoch: 5| Step: 7
Training loss: 2.740120915995742
Validation loss: 2.468606216331902

Epoch: 5| Step: 8
Training loss: 2.853317932758779
Validation loss: 2.4736752291201647

Epoch: 5| Step: 9
Training loss: 2.8145852729645733
Validation loss: 2.466875136969567

Epoch: 5| Step: 10
Training loss: 2.3315709361051686
Validation loss: 2.4680732692843

Epoch: 5| Step: 11
Training loss: 2.4193793451442147
Validation loss: 2.4694635591338114

Epoch: 129| Step: 0
Training loss: 2.067195056719819
Validation loss: 2.46797194875663

Epoch: 5| Step: 1
Training loss: 2.5147756718418246
Validation loss: 2.462903374909432

Epoch: 5| Step: 2
Training loss: 2.576289315254553
Validation loss: 2.4715459217945304

Epoch: 5| Step: 3
Training loss: 3.127340889595166
Validation loss: 2.474480673542553

Epoch: 5| Step: 4
Training loss: 2.8930782321092687
Validation loss: 2.486945072492938

Epoch: 5| Step: 5
Training loss: 2.4210132665510957
Validation loss: 2.4703190320270614

Epoch: 5| Step: 6
Training loss: 2.78215869246369
Validation loss: 2.47287626327207

Epoch: 5| Step: 7
Training loss: 2.2208677044678486
Validation loss: 2.4679109580082206

Epoch: 5| Step: 8
Training loss: 2.3585990994150476
Validation loss: 2.4601712482116755

Epoch: 5| Step: 9
Training loss: 2.6644016620501945
Validation loss: 2.46510323651332

Epoch: 5| Step: 10
Training loss: 2.631578014524194
Validation loss: 2.461659893598216

Epoch: 5| Step: 11
Training loss: 1.8723402868387033
Validation loss: 2.4648975904481807

Epoch: 130| Step: 0
Training loss: 2.286932048226791
Validation loss: 2.471792044937548

Epoch: 5| Step: 1
Training loss: 2.4783268849901026
Validation loss: 2.474201862328563

Epoch: 5| Step: 2
Training loss: 2.576494383273007
Validation loss: 2.468359147691764

Epoch: 5| Step: 3
Training loss: 2.315146916055204
Validation loss: 2.4687377510893636

Epoch: 5| Step: 4
Training loss: 2.375140336558488
Validation loss: 2.470521645295247

Epoch: 5| Step: 5
Training loss: 2.94869469034895
Validation loss: 2.4671998046027004

Epoch: 5| Step: 6
Training loss: 2.605770339554121
Validation loss: 2.466290282732358

Epoch: 5| Step: 7
Training loss: 2.083034366772843
Validation loss: 2.4605241700884295

Epoch: 5| Step: 8
Training loss: 2.762587695218596
Validation loss: 2.4621179242323326

Epoch: 5| Step: 9
Training loss: 3.0266767788464626
Validation loss: 2.454271534544999

Epoch: 5| Step: 10
Training loss: 2.433942791199855
Validation loss: 2.4596618212037704

Epoch: 5| Step: 11
Training loss: 2.7805634411998423
Validation loss: 2.4543391582144096

Epoch: 131| Step: 0
Training loss: 2.7812598581889456
Validation loss: 2.450774895486811

Epoch: 5| Step: 1
Training loss: 2.7144308750515918
Validation loss: 2.457744614103571

Epoch: 5| Step: 2
Training loss: 2.419153074444694
Validation loss: 2.449794206848004

Epoch: 5| Step: 3
Training loss: 2.734983365637704
Validation loss: 2.4613543424838062

Epoch: 5| Step: 4
Training loss: 2.3677573950121076
Validation loss: 2.456351695167805

Epoch: 5| Step: 5
Training loss: 2.073294625897131
Validation loss: 2.459480859690911

Epoch: 5| Step: 6
Training loss: 2.2777260513428343
Validation loss: 2.4633350218438888

Epoch: 5| Step: 7
Training loss: 2.594083373924748
Validation loss: 2.4534448103374102

Epoch: 5| Step: 8
Training loss: 2.831814545857717
Validation loss: 2.4590344452955355

Epoch: 5| Step: 9
Training loss: 2.6338221937223727
Validation loss: 2.453143194661628

Epoch: 5| Step: 10
Training loss: 2.3537220717934306
Validation loss: 2.451040962036481

Epoch: 5| Step: 11
Training loss: 2.753843828941285
Validation loss: 2.4534212690791604

Epoch: 132| Step: 0
Training loss: 2.7394237882815755
Validation loss: 2.461116812495834

Epoch: 5| Step: 1
Training loss: 3.005598566292448
Validation loss: 2.4701005122870465

Epoch: 5| Step: 2
Training loss: 2.6593724467066915
Validation loss: 2.4776952942619754

Epoch: 5| Step: 3
Training loss: 2.2638684007254537
Validation loss: 2.4810570607412625

Epoch: 5| Step: 4
Training loss: 2.7774984367634024
Validation loss: 2.48369298726475

Epoch: 5| Step: 5
Training loss: 2.6914523138746724
Validation loss: 2.4855928255204467

Epoch: 5| Step: 6
Training loss: 2.4193095740319057
Validation loss: 2.4911719298838513

Epoch: 5| Step: 7
Training loss: 1.7287513356675996
Validation loss: 2.4945397711087716

Epoch: 5| Step: 8
Training loss: 2.944029672867052
Validation loss: 2.496773409855577

Epoch: 5| Step: 9
Training loss: 2.50158622010879
Validation loss: 2.5030640818929593

Epoch: 5| Step: 10
Training loss: 2.693418860383714
Validation loss: 2.498989194928812

Epoch: 5| Step: 11
Training loss: 2.3079013980384055
Validation loss: 2.508209470423924

Epoch: 133| Step: 0
Training loss: 2.608008478022176
Validation loss: 2.5092829892085784

Epoch: 5| Step: 1
Training loss: 2.29669261389896
Validation loss: 2.501732428626913

Epoch: 5| Step: 2
Training loss: 2.7641164684903194
Validation loss: 2.5057936531183813

Epoch: 5| Step: 3
Training loss: 2.403733758499574
Validation loss: 2.502961336040703

Epoch: 5| Step: 4
Training loss: 2.327797168973618
Validation loss: 2.502659777533839

Epoch: 5| Step: 5
Training loss: 2.935301424629194
Validation loss: 2.500249683309542

Epoch: 5| Step: 6
Training loss: 2.684216556158468
Validation loss: 2.4959595176012535

Epoch: 5| Step: 7
Training loss: 2.5159830348014456
Validation loss: 2.4936208758470433

Epoch: 5| Step: 8
Training loss: 3.0831165409339407
Validation loss: 2.495446494829686

Epoch: 5| Step: 9
Training loss: 2.8425634235160744
Validation loss: 2.4920705530676246

Epoch: 5| Step: 10
Training loss: 2.452927308104587
Validation loss: 2.4927657402262655

Epoch: 5| Step: 11
Training loss: 1.9940220781709095
Validation loss: 2.4922907338540172

Epoch: 134| Step: 0
Training loss: 2.703423015064895
Validation loss: 2.486099388466682

Epoch: 5| Step: 1
Training loss: 2.946164926070237
Validation loss: 2.4879095537485094

Epoch: 5| Step: 2
Training loss: 2.5890123232374713
Validation loss: 2.4876216371467295

Epoch: 5| Step: 3
Training loss: 2.289852279496226
Validation loss: 2.4875282333918727

Epoch: 5| Step: 4
Training loss: 2.3345951573988573
Validation loss: 2.4866513793524834

Epoch: 5| Step: 5
Training loss: 2.9885076698841755
Validation loss: 2.4798150950957445

Epoch: 5| Step: 6
Training loss: 2.5550159861443382
Validation loss: 2.4824282218157663

Epoch: 5| Step: 7
Training loss: 2.2113860521140074
Validation loss: 2.481788112157265

Epoch: 5| Step: 8
Training loss: 2.797098246780462
Validation loss: 2.478172015898233

Epoch: 5| Step: 9
Training loss: 2.4651750199896374
Validation loss: 2.475156573519186

Epoch: 5| Step: 10
Training loss: 2.71059466126228
Validation loss: 2.475522048396647

Epoch: 5| Step: 11
Training loss: 2.42111893204096
Validation loss: 2.47704443669774

Epoch: 135| Step: 0
Training loss: 2.5642019992890495
Validation loss: 2.476002783357014

Epoch: 5| Step: 1
Training loss: 2.484722377075092
Validation loss: 2.4760275522733024

Epoch: 5| Step: 2
Training loss: 2.351280423605855
Validation loss: 2.4702223238329375

Epoch: 5| Step: 3
Training loss: 2.2264585236481804
Validation loss: 2.4750697774716115

Epoch: 5| Step: 4
Training loss: 2.515961808113401
Validation loss: 2.469957414554691

Epoch: 5| Step: 5
Training loss: 2.474536921788584
Validation loss: 2.4718759801181887

Epoch: 5| Step: 6
Training loss: 2.7640474637120165
Validation loss: 2.4691271996752966

Epoch: 5| Step: 7
Training loss: 2.8468507064302035
Validation loss: 2.472575398791088

Epoch: 5| Step: 8
Training loss: 3.1769730512312364
Validation loss: 2.464335317109184

Epoch: 5| Step: 9
Training loss: 2.5309146611880844
Validation loss: 2.4689218203793977

Epoch: 5| Step: 10
Training loss: 2.066190019626605
Validation loss: 2.46496247631836

Epoch: 5| Step: 11
Training loss: 2.9078256581135324
Validation loss: 2.4622461623828986

Epoch: 136| Step: 0
Training loss: 2.641373928789609
Validation loss: 2.4634837022108966

Epoch: 5| Step: 1
Training loss: 2.9343420057300404
Validation loss: 2.459967645139031

Epoch: 5| Step: 2
Training loss: 2.4828718904530405
Validation loss: 2.46093075060045

Epoch: 5| Step: 3
Training loss: 2.4018508529541185
Validation loss: 2.4624215833245273

Epoch: 5| Step: 4
Training loss: 2.5589900285020457
Validation loss: 2.46502136380479

Epoch: 5| Step: 5
Training loss: 2.1298174386746203
Validation loss: 2.4594460544557455

Epoch: 5| Step: 6
Training loss: 2.9856801000425413
Validation loss: 2.462101292807469

Epoch: 5| Step: 7
Training loss: 2.112342386178271
Validation loss: 2.463196991780926

Epoch: 5| Step: 8
Training loss: 2.324323994794159
Validation loss: 2.4591031175888975

Epoch: 5| Step: 9
Training loss: 2.671572841044639
Validation loss: 2.4608268107392286

Epoch: 5| Step: 10
Training loss: 2.6116655541153686
Validation loss: 2.462692918336866

Epoch: 5| Step: 11
Training loss: 2.4921797510104353
Validation loss: 2.4585001748792052

Epoch: 137| Step: 0
Training loss: 2.628736017165496
Validation loss: 2.459661288080755

Epoch: 5| Step: 1
Training loss: 2.049522260498006
Validation loss: 2.4566149780985698

Epoch: 5| Step: 2
Training loss: 2.023166122796373
Validation loss: 2.4590392708805306

Epoch: 5| Step: 3
Training loss: 2.7734878750376675
Validation loss: 2.4561608718154337

Epoch: 5| Step: 4
Training loss: 2.5007302171480874
Validation loss: 2.4527152583853633

Epoch: 5| Step: 5
Training loss: 2.7151947453240624
Validation loss: 2.4569452267675436

Epoch: 5| Step: 6
Training loss: 2.4679858799720584
Validation loss: 2.45828047523138

Epoch: 5| Step: 7
Training loss: 2.9227579180204226
Validation loss: 2.460516545456557

Epoch: 5| Step: 8
Training loss: 2.589385439450938
Validation loss: 2.4512189356527756

Epoch: 5| Step: 9
Training loss: 2.7141666583431228
Validation loss: 2.4598895753264896

Epoch: 5| Step: 10
Training loss: 2.326907460377958
Validation loss: 2.449792789597709

Epoch: 5| Step: 11
Training loss: 2.5291067398068967
Validation loss: 2.4553558629515644

Epoch: 138| Step: 0
Training loss: 2.4533064465327943
Validation loss: 2.4560746846228665

Epoch: 5| Step: 1
Training loss: 2.7238914719806937
Validation loss: 2.456344945300444

Epoch: 5| Step: 2
Training loss: 1.8505353694237134
Validation loss: 2.4589940465565734

Epoch: 5| Step: 3
Training loss: 2.5725960370850367
Validation loss: 2.4535605839626284

Epoch: 5| Step: 4
Training loss: 2.8111411308759715
Validation loss: 2.4564698451747353

Epoch: 5| Step: 5
Training loss: 2.043752487134441
Validation loss: 2.4556841207332494

Epoch: 5| Step: 6
Training loss: 2.9836429676792
Validation loss: 2.4513756291178237

Epoch: 5| Step: 7
Training loss: 2.9355121135874325
Validation loss: 2.4584364519205524

Epoch: 5| Step: 8
Training loss: 2.6765402949403643
Validation loss: 2.453494094813281

Epoch: 5| Step: 9
Training loss: 2.2239820016022898
Validation loss: 2.448554387454037

Epoch: 5| Step: 10
Training loss: 2.405688926380602
Validation loss: 2.450700776928608

Epoch: 5| Step: 11
Training loss: 1.5459110069125372
Validation loss: 2.451627993352133

Epoch: 139| Step: 0
Training loss: 2.0429560294402616
Validation loss: 2.447948708561263

Epoch: 5| Step: 1
Training loss: 2.121537248250742
Validation loss: 2.4541075980024583

Epoch: 5| Step: 2
Training loss: 2.1073711908872723
Validation loss: 2.454176744128415

Epoch: 5| Step: 3
Training loss: 2.587755008238998
Validation loss: 2.4513173783317965

Epoch: 5| Step: 4
Training loss: 2.2174156367307565
Validation loss: 2.446826376823651

Epoch: 5| Step: 5
Training loss: 2.6862629549575914
Validation loss: 2.4544335659491265

Epoch: 5| Step: 6
Training loss: 2.9266020536422954
Validation loss: 2.457584345131074

Epoch: 5| Step: 7
Training loss: 2.8292224082642927
Validation loss: 2.4515638952370815

Epoch: 5| Step: 8
Training loss: 2.8237093179785635
Validation loss: 2.457287935192406

Epoch: 5| Step: 9
Training loss: 2.5848655668678973
Validation loss: 2.4611773419444343

Epoch: 5| Step: 10
Training loss: 2.7717612775420246
Validation loss: 2.4592047065676277

Epoch: 5| Step: 11
Training loss: 1.9787781250353174
Validation loss: 2.461450367926905

Epoch: 140| Step: 0
Training loss: 2.7362390758284136
Validation loss: 2.4616248286102604

Epoch: 5| Step: 1
Training loss: 2.060771911771162
Validation loss: 2.4591450738449017

Epoch: 5| Step: 2
Training loss: 2.6533041382466167
Validation loss: 2.4553859156619526

Epoch: 5| Step: 3
Training loss: 2.4478187270896754
Validation loss: 2.452105798405037

Epoch: 5| Step: 4
Training loss: 2.0975375861163723
Validation loss: 2.456783623844376

Epoch: 5| Step: 5
Training loss: 2.6822299295869696
Validation loss: 2.4581949079194256

Epoch: 5| Step: 6
Training loss: 2.8792648195648973
Validation loss: 2.455593145142348

Epoch: 5| Step: 7
Training loss: 2.6224253607675148
Validation loss: 2.4554972790282448

Epoch: 5| Step: 8
Training loss: 2.2467942182214204
Validation loss: 2.4594976421251062

Epoch: 5| Step: 9
Training loss: 2.8125191581921274
Validation loss: 2.4595968237710544

Epoch: 5| Step: 10
Training loss: 2.5116137635402045
Validation loss: 2.4579247859875264

Epoch: 5| Step: 11
Training loss: 2.057536423686381
Validation loss: 2.4529166487476766

Epoch: 141| Step: 0
Training loss: 2.3980192633675173
Validation loss: 2.458983013545582

Epoch: 5| Step: 1
Training loss: 2.8221492122941756
Validation loss: 2.4611175249243153

Epoch: 5| Step: 2
Training loss: 2.451480192573972
Validation loss: 2.46550100342712

Epoch: 5| Step: 3
Training loss: 2.209967194740921
Validation loss: 2.4680050277177017

Epoch: 5| Step: 4
Training loss: 2.5873503268531666
Validation loss: 2.4686886864303457

Epoch: 5| Step: 5
Training loss: 2.5192001243470137
Validation loss: 2.469302880069091

Epoch: 5| Step: 6
Training loss: 2.3011030869052655
Validation loss: 2.471799982430015

Epoch: 5| Step: 7
Training loss: 2.5164503556146203
Validation loss: 2.461039320035241

Epoch: 5| Step: 8
Training loss: 3.014414648166629
Validation loss: 2.4655501597254563

Epoch: 5| Step: 9
Training loss: 2.415283783060712
Validation loss: 2.465853984338477

Epoch: 5| Step: 10
Training loss: 2.6396376891487145
Validation loss: 2.4577360451316714

Epoch: 5| Step: 11
Training loss: 2.7243993534645767
Validation loss: 2.4534186979098207

Epoch: 142| Step: 0
Training loss: 2.571318548361606
Validation loss: 2.4542811234817865

Epoch: 5| Step: 1
Training loss: 2.1998424560317638
Validation loss: 2.455049205560134

Epoch: 5| Step: 2
Training loss: 2.5590936303489995
Validation loss: 2.4534563743815374

Epoch: 5| Step: 3
Training loss: 2.379435162556454
Validation loss: 2.467636996282498

Epoch: 5| Step: 4
Training loss: 2.36383403271645
Validation loss: 2.4603977358221933

Epoch: 5| Step: 5
Training loss: 2.3924022376356966
Validation loss: 2.4638207071249125

Epoch: 5| Step: 6
Training loss: 2.979945065548854
Validation loss: 2.459913684673314

Epoch: 5| Step: 7
Training loss: 2.4652473614984856
Validation loss: 2.456924715143201

Epoch: 5| Step: 8
Training loss: 2.5553551597621795
Validation loss: 2.456679217374653

Epoch: 5| Step: 9
Training loss: 2.4387238193438208
Validation loss: 2.4592743193373483

Epoch: 5| Step: 10
Training loss: 2.6653833778413194
Validation loss: 2.4543428536422622

Epoch: 5| Step: 11
Training loss: 3.094798209124497
Validation loss: 2.4574867881505136

Epoch: 143| Step: 0
Training loss: 2.731581999898222
Validation loss: 2.4675514031737182

Epoch: 5| Step: 1
Training loss: 2.2664080088890324
Validation loss: 2.4690432354252323

Epoch: 5| Step: 2
Training loss: 2.5750101404082986
Validation loss: 2.472145759070369

Epoch: 5| Step: 3
Training loss: 2.66011206412344
Validation loss: 2.482170682534203

Epoch: 5| Step: 4
Training loss: 2.509287272780876
Validation loss: 2.478112230272011

Epoch: 5| Step: 5
Training loss: 2.680150117228307
Validation loss: 2.479294738880802

Epoch: 5| Step: 6
Training loss: 2.0945602671097654
Validation loss: 2.4741843725975468

Epoch: 5| Step: 7
Training loss: 2.492895713317263
Validation loss: 2.473021441625978

Epoch: 5| Step: 8
Training loss: 2.5937536768140355
Validation loss: 2.4704886241574497

Epoch: 5| Step: 9
Training loss: 2.8818572821452
Validation loss: 2.4734587409207296

Epoch: 5| Step: 10
Training loss: 2.4541562579397853
Validation loss: 2.472114387105841

Epoch: 5| Step: 11
Training loss: 3.5825293474399555
Validation loss: 2.4760167716966333

Epoch: 144| Step: 0
Training loss: 2.95236567670559
Validation loss: 2.467987989169736

Epoch: 5| Step: 1
Training loss: 2.5110224920106354
Validation loss: 2.476121933475516

Epoch: 5| Step: 2
Training loss: 2.398930700830112
Validation loss: 2.476086922840348

Epoch: 5| Step: 3
Training loss: 2.521401165358246
Validation loss: 2.474688477771089

Epoch: 5| Step: 4
Training loss: 2.4816186357217784
Validation loss: 2.4631973103889955

Epoch: 5| Step: 5
Training loss: 2.1657091617056303
Validation loss: 2.473524402241258

Epoch: 5| Step: 6
Training loss: 2.50230282581223
Validation loss: 2.4633424784572746

Epoch: 5| Step: 7
Training loss: 2.994473930863254
Validation loss: 2.469064921802897

Epoch: 5| Step: 8
Training loss: 2.2743406828544863
Validation loss: 2.472940047993687

Epoch: 5| Step: 9
Training loss: 2.5920981237123106
Validation loss: 2.4744473077843794

Epoch: 5| Step: 10
Training loss: 2.670862820403515
Validation loss: 2.466783476707818

Epoch: 5| Step: 11
Training loss: 1.982129907013407
Validation loss: 2.470766889430337

Epoch: 145| Step: 0
Training loss: 2.5115785455802286
Validation loss: 2.467839038753357

Epoch: 5| Step: 1
Training loss: 2.552886047760762
Validation loss: 2.461260089217483

Epoch: 5| Step: 2
Training loss: 2.478341122760174
Validation loss: 2.4595222036472686

Epoch: 5| Step: 3
Training loss: 2.801971906032397
Validation loss: 2.4574422669412295

Epoch: 5| Step: 4
Training loss: 2.488398335096069
Validation loss: 2.461230104197121

Epoch: 5| Step: 5
Training loss: 2.8755413043405844
Validation loss: 2.4564148756961672

Epoch: 5| Step: 6
Training loss: 2.3358981023929926
Validation loss: 2.457522732774092

Epoch: 5| Step: 7
Training loss: 2.358078151776411
Validation loss: 2.456136333304241

Epoch: 5| Step: 8
Training loss: 2.3018672951065198
Validation loss: 2.456189317091156

Epoch: 5| Step: 9
Training loss: 2.1941021063386157
Validation loss: 2.454700899239337

Epoch: 5| Step: 10
Training loss: 2.9587938908366276
Validation loss: 2.456463952974609

Epoch: 5| Step: 11
Training loss: 1.7282279427134917
Validation loss: 2.4569637206419803

Epoch: 146| Step: 0
Training loss: 2.165469707078954
Validation loss: 2.4567863330159385

Epoch: 5| Step: 1
Training loss: 2.3474766921246224
Validation loss: 2.4555516318706543

Epoch: 5| Step: 2
Training loss: 2.5101560296427503
Validation loss: 2.456064047015073

Epoch: 5| Step: 3
Training loss: 2.55513038645958
Validation loss: 2.4592271583452647

Epoch: 5| Step: 4
Training loss: 2.2744876494241097
Validation loss: 2.4576012011491137

Epoch: 5| Step: 5
Training loss: 2.7500528850672135
Validation loss: 2.4568526906123287

Epoch: 5| Step: 6
Training loss: 2.6922052578774918
Validation loss: 2.4573878043206103

Epoch: 5| Step: 7
Training loss: 2.1285373193087174
Validation loss: 2.451577538792046

Epoch: 5| Step: 8
Training loss: 2.857681690223591
Validation loss: 2.4591568413433342

Epoch: 5| Step: 9
Training loss: 3.050462224986859
Validation loss: 2.4538118814084604

Epoch: 5| Step: 10
Training loss: 2.3389239660709964
Validation loss: 2.4653566595600065

Epoch: 5| Step: 11
Training loss: 2.008020412500895
Validation loss: 2.4587718254663096

Epoch: 147| Step: 0
Training loss: 2.493520637232514
Validation loss: 2.456405952265461

Epoch: 5| Step: 1
Training loss: 3.0009525694106762
Validation loss: 2.458522475504191

Epoch: 5| Step: 2
Training loss: 2.010121958055004
Validation loss: 2.4568300109188517

Epoch: 5| Step: 3
Training loss: 2.576327165228143
Validation loss: 2.4533813731355223

Epoch: 5| Step: 4
Training loss: 2.776648840906168
Validation loss: 2.457475449234735

Epoch: 5| Step: 5
Training loss: 1.8714733017554244
Validation loss: 2.4563192014029718

Epoch: 5| Step: 6
Training loss: 2.484146203595884
Validation loss: 2.460300254059662

Epoch: 5| Step: 7
Training loss: 2.6592830619653873
Validation loss: 2.4586066091447867

Epoch: 5| Step: 8
Training loss: 2.681039719238649
Validation loss: 2.4581496498752977

Epoch: 5| Step: 9
Training loss: 1.9925279513400402
Validation loss: 2.4554400686817544

Epoch: 5| Step: 10
Training loss: 2.999378139894038
Validation loss: 2.4597185496788625

Epoch: 5| Step: 11
Training loss: 0.8925150508840368
Validation loss: 2.4627503161757534

Epoch: 148| Step: 0
Training loss: 2.264042057974432
Validation loss: 2.4643158546359194

Epoch: 5| Step: 1
Training loss: 1.6407884788808027
Validation loss: 2.463281082716304

Epoch: 5| Step: 2
Training loss: 2.931103824313675
Validation loss: 2.458579036319918

Epoch: 5| Step: 3
Training loss: 1.941616300276182
Validation loss: 2.4553135506364425

Epoch: 5| Step: 4
Training loss: 2.5714001426941815
Validation loss: 2.4588732503678203

Epoch: 5| Step: 5
Training loss: 2.8429592835807806
Validation loss: 2.458038289473902

Epoch: 5| Step: 6
Training loss: 2.868650972406587
Validation loss: 2.456111762190705

Epoch: 5| Step: 7
Training loss: 2.777620325924296
Validation loss: 2.4531980410512326

Epoch: 5| Step: 8
Training loss: 2.6161281890142503
Validation loss: 2.4565520271544212

Epoch: 5| Step: 9
Training loss: 2.6149605913274403
Validation loss: 2.4557517277533103

Epoch: 5| Step: 10
Training loss: 2.367253771568724
Validation loss: 2.4658835666714145

Epoch: 5| Step: 11
Training loss: 2.8072371515891654
Validation loss: 2.4614176367582266

Epoch: 149| Step: 0
Training loss: 2.972582621922027
Validation loss: 2.4633449142525374

Epoch: 5| Step: 1
Training loss: 2.3988480107896852
Validation loss: 2.4644836186874355

Epoch: 5| Step: 2
Training loss: 2.658537743421564
Validation loss: 2.4631947897544064

Epoch: 5| Step: 3
Training loss: 2.6636426488545943
Validation loss: 2.458638884796067

Epoch: 5| Step: 4
Training loss: 2.571768026804013
Validation loss: 2.4649523324722886

Epoch: 5| Step: 5
Training loss: 2.2309824123262127
Validation loss: 2.456655310822806

Epoch: 5| Step: 6
Training loss: 2.46911840466563
Validation loss: 2.454599233133441

Epoch: 5| Step: 7
Training loss: 2.8832610486916277
Validation loss: 2.4580623664606644

Epoch: 5| Step: 8
Training loss: 2.0605257006095106
Validation loss: 2.466380998677333

Epoch: 5| Step: 9
Training loss: 2.4036682943422276
Validation loss: 2.4610223906876842

Epoch: 5| Step: 10
Training loss: 2.204224440665392
Validation loss: 2.4615468638208693

Epoch: 5| Step: 11
Training loss: 2.6897935174023613
Validation loss: 2.4614423244137065

Epoch: 150| Step: 0
Training loss: 2.4028940950535995
Validation loss: 2.458637797903838

Epoch: 5| Step: 1
Training loss: 2.404673468615151
Validation loss: 2.457270511041841

Epoch: 5| Step: 2
Training loss: 2.231786869544894
Validation loss: 2.4581442951538204

Epoch: 5| Step: 3
Training loss: 2.860711791022288
Validation loss: 2.45629622761304

Epoch: 5| Step: 4
Training loss: 2.5533076768421092
Validation loss: 2.4661816463803965

Epoch: 5| Step: 5
Training loss: 2.3517676989478473
Validation loss: 2.4631911761681597

Epoch: 5| Step: 6
Training loss: 2.046296598524887
Validation loss: 2.4630540697244756

Epoch: 5| Step: 7
Training loss: 2.8637451795240216
Validation loss: 2.475643304264232

Epoch: 5| Step: 8
Training loss: 2.784921772678318
Validation loss: 2.467633401278679

Epoch: 5| Step: 9
Training loss: 2.5871547818824987
Validation loss: 2.4702586863650438

Epoch: 5| Step: 10
Training loss: 2.347685497945929
Validation loss: 2.4762847295357564

Epoch: 5| Step: 11
Training loss: 2.166701597763573
Validation loss: 2.4684366236545623

Epoch: 151| Step: 0
Training loss: 2.7158498093732564
Validation loss: 2.478160611282015

Epoch: 5| Step: 1
Training loss: 2.30105666890628
Validation loss: 2.4760209262563944

Epoch: 5| Step: 2
Training loss: 2.974999044722716
Validation loss: 2.4746171027356176

Epoch: 5| Step: 3
Training loss: 2.5952781863301126
Validation loss: 2.4734980258697297

Epoch: 5| Step: 4
Training loss: 1.9560801008747593
Validation loss: 2.4686446549678784

Epoch: 5| Step: 5
Training loss: 2.235622031338123
Validation loss: 2.4706389930252275

Epoch: 5| Step: 6
Training loss: 2.911655116838047
Validation loss: 2.4698001985846347

Epoch: 5| Step: 7
Training loss: 2.6389366937512366
Validation loss: 2.4697949455450767

Epoch: 5| Step: 8
Training loss: 2.0927303735215785
Validation loss: 2.4723181068980513

Epoch: 5| Step: 9
Training loss: 2.315985552971669
Validation loss: 2.4636366276789943

Epoch: 5| Step: 10
Training loss: 2.7085379498777074
Validation loss: 2.461063224366312

Epoch: 5| Step: 11
Training loss: 2.3817415425957367
Validation loss: 2.462393216094705

Epoch: 152| Step: 0
Training loss: 2.6993031026243877
Validation loss: 2.4673460618119134

Epoch: 5| Step: 1
Training loss: 3.1537857255639605
Validation loss: 2.4610117744661184

Epoch: 5| Step: 2
Training loss: 2.5218608643089544
Validation loss: 2.465843308344711

Epoch: 5| Step: 3
Training loss: 2.4139370685076553
Validation loss: 2.4632981175261452

Epoch: 5| Step: 4
Training loss: 2.4881377126354107
Validation loss: 2.4687844366577107

Epoch: 5| Step: 5
Training loss: 2.3496643719535
Validation loss: 2.4703360022195566

Epoch: 5| Step: 6
Training loss: 2.6630880861514985
Validation loss: 2.460021555962492

Epoch: 5| Step: 7
Training loss: 2.0083750370913838
Validation loss: 2.4667123481562867

Epoch: 5| Step: 8
Training loss: 2.6656056518568043
Validation loss: 2.469511377451144

Epoch: 5| Step: 9
Training loss: 2.2924022072137933
Validation loss: 2.4590033302455225

Epoch: 5| Step: 10
Training loss: 2.421777046437716
Validation loss: 2.461587696870654

Epoch: 5| Step: 11
Training loss: 1.6872246129009207
Validation loss: 2.459400690179644

Epoch: 153| Step: 0
Training loss: 2.094143047733396
Validation loss: 2.4555924917936562

Epoch: 5| Step: 1
Training loss: 2.6855632101775924
Validation loss: 2.467799152481317

Epoch: 5| Step: 2
Training loss: 2.1820791379247133
Validation loss: 2.4700807373015046

Epoch: 5| Step: 3
Training loss: 2.708777190786228
Validation loss: 2.497309480724878

Epoch: 5| Step: 4
Training loss: 2.755593074095383
Validation loss: 2.5064712891270124

Epoch: 5| Step: 5
Training loss: 2.896392676766205
Validation loss: 2.494203664789048

Epoch: 5| Step: 6
Training loss: 2.7128032673007523
Validation loss: 2.473518128967576

Epoch: 5| Step: 7
Training loss: 2.4829618645519087
Validation loss: 2.465561264078132

Epoch: 5| Step: 8
Training loss: 2.5033470636322273
Validation loss: 2.4566874685586466

Epoch: 5| Step: 9
Training loss: 2.262267894325471
Validation loss: 2.4563621697604785

Epoch: 5| Step: 10
Training loss: 2.2200602571368653
Validation loss: 2.464705530352748

Epoch: 5| Step: 11
Training loss: 2.684114497271018
Validation loss: 2.4601731945143595

Epoch: 154| Step: 0
Training loss: 2.6610575534082814
Validation loss: 2.464944886774043

Epoch: 5| Step: 1
Training loss: 2.699366431605772
Validation loss: 2.4613828266222066

Epoch: 5| Step: 2
Training loss: 2.3043156727995555
Validation loss: 2.467904763047854

Epoch: 5| Step: 3
Training loss: 2.5708071339991547
Validation loss: 2.4718346217507072

Epoch: 5| Step: 4
Training loss: 2.826283482349447
Validation loss: 2.464968513438559

Epoch: 5| Step: 5
Training loss: 2.1437425396402965
Validation loss: 2.465147230485592

Epoch: 5| Step: 6
Training loss: 2.874464731559766
Validation loss: 2.47056513264005

Epoch: 5| Step: 7
Training loss: 2.572934931845962
Validation loss: 2.46563178924928

Epoch: 5| Step: 8
Training loss: 1.9693010558081216
Validation loss: 2.4615834796123353

Epoch: 5| Step: 9
Training loss: 2.3222976566861537
Validation loss: 2.4627268870632886

Epoch: 5| Step: 10
Training loss: 2.7939060585760482
Validation loss: 2.461597616479439

Epoch: 5| Step: 11
Training loss: 2.006549126022486
Validation loss: 2.4626747740608823

Epoch: 155| Step: 0
Training loss: 2.0548408944196614
Validation loss: 2.4520395189669006

Epoch: 5| Step: 1
Training loss: 2.5440064172123997
Validation loss: 2.484859051522465

Epoch: 5| Step: 2
Training loss: 2.700909892166984
Validation loss: 2.5368637345853258

Epoch: 5| Step: 3
Training loss: 2.643336602393779
Validation loss: 2.5746424456064876

Epoch: 5| Step: 4
Training loss: 2.8706419712580735
Validation loss: 2.566569365219694

Epoch: 5| Step: 5
Training loss: 2.4014601160089537
Validation loss: 2.5216945065207277

Epoch: 5| Step: 6
Training loss: 2.7389537730945155
Validation loss: 2.4721920588137922

Epoch: 5| Step: 7
Training loss: 2.8559005556932107
Validation loss: 2.473694091873165

Epoch: 5| Step: 8
Training loss: 2.2626036393681144
Validation loss: 2.462958709800233

Epoch: 5| Step: 9
Training loss: 2.2378523650372104
Validation loss: 2.458144016303854

Epoch: 5| Step: 10
Training loss: 3.0945721699417557
Validation loss: 2.462865806654203

Epoch: 5| Step: 11
Training loss: 2.0812435986302997
Validation loss: 2.46167425197947

Epoch: 156| Step: 0
Training loss: 2.9137204866947966
Validation loss: 2.4620678077032214

Epoch: 5| Step: 1
Training loss: 2.336975581454939
Validation loss: 2.46000409867687

Epoch: 5| Step: 2
Training loss: 3.213153306605978
Validation loss: 2.46280315464678

Epoch: 5| Step: 3
Training loss: 2.4779327164044602
Validation loss: 2.460885950588051

Epoch: 5| Step: 4
Training loss: 2.2828596524088893
Validation loss: 2.4596250354446125

Epoch: 5| Step: 5
Training loss: 2.0480403931329816
Validation loss: 2.455654233488413

Epoch: 5| Step: 6
Training loss: 2.428402870804119
Validation loss: 2.460239149844904

Epoch: 5| Step: 7
Training loss: 2.3521571627287727
Validation loss: 2.4600037029285007

Epoch: 5| Step: 8
Training loss: 1.872227144313471
Validation loss: 2.462699779887946

Epoch: 5| Step: 9
Training loss: 2.5890458432791554
Validation loss: 2.454421771757954

Epoch: 5| Step: 10
Training loss: 2.7136676683416634
Validation loss: 2.4554598887525687

Epoch: 5| Step: 11
Training loss: 2.9511738139057164
Validation loss: 2.464539716199727

Epoch: 157| Step: 0
Training loss: 2.168145799710266
Validation loss: 2.4688098795586306

Epoch: 5| Step: 1
Training loss: 2.3620555883547762
Validation loss: 2.475336511449968

Epoch: 5| Step: 2
Training loss: 2.4855109922464886
Validation loss: 2.4723404355723955

Epoch: 5| Step: 3
Training loss: 2.9808275799210966
Validation loss: 2.4728232513647805

Epoch: 5| Step: 4
Training loss: 2.9886230273300285
Validation loss: 2.469235802990484

Epoch: 5| Step: 5
Training loss: 2.9535761090016015
Validation loss: 2.4701048014713765

Epoch: 5| Step: 6
Training loss: 1.6381965466142165
Validation loss: 2.463599022217117

Epoch: 5| Step: 7
Training loss: 2.2576792324558856
Validation loss: 2.4587043418937427

Epoch: 5| Step: 8
Training loss: 2.3468467090999328
Validation loss: 2.457708472645069

Epoch: 5| Step: 9
Training loss: 2.9187942011424934
Validation loss: 2.458212083046218

Epoch: 5| Step: 10
Training loss: 2.4302268456905196
Validation loss: 2.459721760456892

Epoch: 5| Step: 11
Training loss: 1.5419609545008195
Validation loss: 2.4616686506872463

Epoch: 158| Step: 0
Training loss: 2.560357477441867
Validation loss: 2.462724866136848

Epoch: 5| Step: 1
Training loss: 2.1042687671427713
Validation loss: 2.458795691238394

Epoch: 5| Step: 2
Training loss: 3.0586938366646303
Validation loss: 2.463883706207683

Epoch: 5| Step: 3
Training loss: 2.391272264009035
Validation loss: 2.4592112870037184

Epoch: 5| Step: 4
Training loss: 2.25929554737574
Validation loss: 2.4561804959766227

Epoch: 5| Step: 5
Training loss: 2.3334097055016394
Validation loss: 2.463697379489148

Epoch: 5| Step: 6
Training loss: 2.3225166307065375
Validation loss: 2.465285800120833

Epoch: 5| Step: 7
Training loss: 2.856426949727302
Validation loss: 2.4532485493448

Epoch: 5| Step: 8
Training loss: 2.3564734395985036
Validation loss: 2.4594419425827354

Epoch: 5| Step: 9
Training loss: 2.2256896332523306
Validation loss: 2.459976804004932

Epoch: 5| Step: 10
Training loss: 2.892774782572606
Validation loss: 2.452635649449797

Epoch: 5| Step: 11
Training loss: 2.7678191538370363
Validation loss: 2.4662054122500785

Epoch: 159| Step: 0
Training loss: 2.524329816050715
Validation loss: 2.4581873669905523

Epoch: 5| Step: 1
Training loss: 2.5775804349112947
Validation loss: 2.466255710548148

Epoch: 5| Step: 2
Training loss: 2.144002658201819
Validation loss: 2.45743709865308

Epoch: 5| Step: 3
Training loss: 2.8590206072539313
Validation loss: 2.4605970520597604

Epoch: 5| Step: 4
Training loss: 2.7297703800818875
Validation loss: 2.4624222368784134

Epoch: 5| Step: 5
Training loss: 2.16471197525006
Validation loss: 2.4600325641247123

Epoch: 5| Step: 6
Training loss: 2.336755003499643
Validation loss: 2.4587366708065477

Epoch: 5| Step: 7
Training loss: 2.5719254369413656
Validation loss: 2.452663621217614

Epoch: 5| Step: 8
Training loss: 2.79153068173325
Validation loss: 2.4582584855975385

Epoch: 5| Step: 9
Training loss: 2.2371810685784816
Validation loss: 2.4622518188452287

Epoch: 5| Step: 10
Training loss: 2.291911256626651
Validation loss: 2.4647747016017436

Epoch: 5| Step: 11
Training loss: 2.6704526986091763
Validation loss: 2.470264911615484

Epoch: 160| Step: 0
Training loss: 2.319840097342916
Validation loss: 2.463820388597457

Epoch: 5| Step: 1
Training loss: 2.0679656924753678
Validation loss: 2.468385782214763

Epoch: 5| Step: 2
Training loss: 2.3289320398212476
Validation loss: 2.472968561377309

Epoch: 5| Step: 3
Training loss: 2.683827130471272
Validation loss: 2.4769500445242625

Epoch: 5| Step: 4
Training loss: 2.6019721181256763
Validation loss: 2.4796155929154944

Epoch: 5| Step: 5
Training loss: 2.3500143131875344
Validation loss: 2.468361324988278

Epoch: 5| Step: 6
Training loss: 2.371797209055827
Validation loss: 2.472565659826637

Epoch: 5| Step: 7
Training loss: 2.276643360720524
Validation loss: 2.4675644148380855

Epoch: 5| Step: 8
Training loss: 2.8636664200453605
Validation loss: 2.469164020894393

Epoch: 5| Step: 9
Training loss: 2.769064106572138
Validation loss: 2.4617898343015736

Epoch: 5| Step: 10
Training loss: 2.6206470910525677
Validation loss: 2.4631902526056453

Epoch: 5| Step: 11
Training loss: 2.3145027766957895
Validation loss: 2.463052944448076

Epoch: 161| Step: 0
Training loss: 2.1687372168788093
Validation loss: 2.462918230225242

Epoch: 5| Step: 1
Training loss: 1.9348344617705557
Validation loss: 2.466576295294776

Epoch: 5| Step: 2
Training loss: 2.4740329664249665
Validation loss: 2.469908655668091

Epoch: 5| Step: 3
Training loss: 2.5501363269043322
Validation loss: 2.465694889114356

Epoch: 5| Step: 4
Training loss: 2.0840484409084006
Validation loss: 2.4661765346744304

Epoch: 5| Step: 5
Training loss: 2.7606407122589127
Validation loss: 2.466049085019754

Epoch: 5| Step: 6
Training loss: 3.3308475444516943
Validation loss: 2.466155938702147

Epoch: 5| Step: 7
Training loss: 2.2668741925924127
Validation loss: 2.4663783443508747

Epoch: 5| Step: 8
Training loss: 2.29956913934405
Validation loss: 2.4670192329342293

Epoch: 5| Step: 9
Training loss: 2.7357408872290674
Validation loss: 2.4668685608689507

Epoch: 5| Step: 10
Training loss: 2.7354367184006936
Validation loss: 2.462368907117736

Epoch: 5| Step: 11
Training loss: 1.7228890951488256
Validation loss: 2.4658064173945853

Epoch: 162| Step: 0
Training loss: 2.008163243394715
Validation loss: 2.465142608274066

Epoch: 5| Step: 1
Training loss: 2.392516540980385
Validation loss: 2.469824050300589

Epoch: 5| Step: 2
Training loss: 2.8019947099438327
Validation loss: 2.4631283368302053

Epoch: 5| Step: 3
Training loss: 2.8379363274881544
Validation loss: 2.4605837754444377

Epoch: 5| Step: 4
Training loss: 2.754070217581008
Validation loss: 2.4688343403891704

Epoch: 5| Step: 5
Training loss: 2.054744589124908
Validation loss: 2.467151732101942

Epoch: 5| Step: 6
Training loss: 1.9792725451073059
Validation loss: 2.47464732296818

Epoch: 5| Step: 7
Training loss: 2.737824972015665
Validation loss: 2.4635134904364455

Epoch: 5| Step: 8
Training loss: 2.8512549665609317
Validation loss: 2.4705091116299114

Epoch: 5| Step: 9
Training loss: 2.236244433307063
Validation loss: 2.462445345141366

Epoch: 5| Step: 10
Training loss: 2.648883523208438
Validation loss: 2.458884138428168

Epoch: 5| Step: 11
Training loss: 1.354451262083377
Validation loss: 2.468679547813586

Epoch: 163| Step: 0
Training loss: 2.275454226411272
Validation loss: 2.470551493418367

Epoch: 5| Step: 1
Training loss: 2.64773109039853
Validation loss: 2.465432666485744

Epoch: 5| Step: 2
Training loss: 2.752874086271161
Validation loss: 2.464328177930648

Epoch: 5| Step: 3
Training loss: 2.4783907619134222
Validation loss: 2.4698504478080774

Epoch: 5| Step: 4
Training loss: 2.6924685304408946
Validation loss: 2.4678591396443847

Epoch: 5| Step: 5
Training loss: 2.5405489751835915
Validation loss: 2.4697921420423636

Epoch: 5| Step: 6
Training loss: 2.4903005314435362
Validation loss: 2.4704380199755356

Epoch: 5| Step: 7
Training loss: 2.39454698168517
Validation loss: 2.4644107589429862

Epoch: 5| Step: 8
Training loss: 2.2317126224601695
Validation loss: 2.467687519018447

Epoch: 5| Step: 9
Training loss: 2.8427039936983545
Validation loss: 2.47253244500879

Epoch: 5| Step: 10
Training loss: 2.1540646743486733
Validation loss: 2.476358952866995

Epoch: 5| Step: 11
Training loss: 1.2826566185603923
Validation loss: 2.4714360412820247

Epoch: 164| Step: 0
Training loss: 2.6601983737831314
Validation loss: 2.479128081291255

Epoch: 5| Step: 1
Training loss: 2.051852863621121
Validation loss: 2.474135492239141

Epoch: 5| Step: 2
Training loss: 1.9542724900646746
Validation loss: 2.464143104339517

Epoch: 5| Step: 3
Training loss: 2.911666744372653
Validation loss: 2.4739714063332467

Epoch: 5| Step: 4
Training loss: 2.122933673384969
Validation loss: 2.467290358264562

Epoch: 5| Step: 5
Training loss: 2.4681230545712474
Validation loss: 2.470748627536414

Epoch: 5| Step: 6
Training loss: 2.256737476216509
Validation loss: 2.4712223155815853

Epoch: 5| Step: 7
Training loss: 2.599486109493041
Validation loss: 2.468953466279975

Epoch: 5| Step: 8
Training loss: 2.790577025818124
Validation loss: 2.471185717990401

Epoch: 5| Step: 9
Training loss: 2.910908892291827
Validation loss: 2.466211925669632

Epoch: 5| Step: 10
Training loss: 2.5761440180153743
Validation loss: 2.470474262719967

Epoch: 5| Step: 11
Training loss: 2.053724520171739
Validation loss: 2.476453022587853

Epoch: 165| Step: 0
Training loss: 2.2282557423715676
Validation loss: 2.4729656690794983

Epoch: 5| Step: 1
Training loss: 2.497293628647197
Validation loss: 2.476594417298159

Epoch: 5| Step: 2
Training loss: 2.570003780852034
Validation loss: 2.4846176292892377

Epoch: 5| Step: 3
Training loss: 2.2009739757214257
Validation loss: 2.48418757293471

Epoch: 5| Step: 4
Training loss: 2.635389114255961
Validation loss: 2.4833718679839127

Epoch: 5| Step: 5
Training loss: 2.4906667057312357
Validation loss: 2.475361060287568

Epoch: 5| Step: 6
Training loss: 2.1018240953736034
Validation loss: 2.470897895061709

Epoch: 5| Step: 7
Training loss: 3.094099237015674
Validation loss: 2.470734173123531

Epoch: 5| Step: 8
Training loss: 2.357360282794968
Validation loss: 2.4614247238398055

Epoch: 5| Step: 9
Training loss: 2.495946267894563
Validation loss: 2.460644622813633

Epoch: 5| Step: 10
Training loss: 2.1111385179157223
Validation loss: 2.4648735983643864

Epoch: 5| Step: 11
Training loss: 4.020941750970445
Validation loss: 2.4700345286923744

Epoch: 166| Step: 0
Training loss: 2.0432367969545173
Validation loss: 2.470934239611266

Epoch: 5| Step: 1
Training loss: 2.7188288359338153
Validation loss: 2.465571203962436

Epoch: 5| Step: 2
Training loss: 3.0903020583971705
Validation loss: 2.468983361526116

Epoch: 5| Step: 3
Training loss: 2.3703963182550134
Validation loss: 2.472303605406969

Epoch: 5| Step: 4
Training loss: 2.079999379561405
Validation loss: 2.472590742403544

Epoch: 5| Step: 5
Training loss: 2.427635675757927
Validation loss: 2.4670036513166615

Epoch: 5| Step: 6
Training loss: 2.115190528422227
Validation loss: 2.473856879044668

Epoch: 5| Step: 7
Training loss: 2.531900487134459
Validation loss: 2.471583583193784

Epoch: 5| Step: 8
Training loss: 2.922483003565278
Validation loss: 2.4753024268092854

Epoch: 5| Step: 9
Training loss: 3.2202507890454966
Validation loss: 2.470142080664632

Epoch: 5| Step: 10
Training loss: 2.082848021883302
Validation loss: 2.4722484153855375

Epoch: 5| Step: 11
Training loss: 2.218985424177821
Validation loss: 2.470394134298626

Epoch: 167| Step: 0
Training loss: 2.4322776603431597
Validation loss: 2.472013826968895

Epoch: 5| Step: 1
Training loss: 2.716951498846183
Validation loss: 2.4674051541101263

Epoch: 5| Step: 2
Training loss: 2.605162183578324
Validation loss: 2.46631284723574

Epoch: 5| Step: 3
Training loss: 2.432217571646586
Validation loss: 2.4620343927546267

Epoch: 5| Step: 4
Training loss: 2.8226336704494495
Validation loss: 2.4783195856961964

Epoch: 5| Step: 5
Training loss: 2.507125522722832
Validation loss: 2.4772109136513176

Epoch: 5| Step: 6
Training loss: 2.3280724641133577
Validation loss: 2.477235207314641

Epoch: 5| Step: 7
Training loss: 1.909931380252589
Validation loss: 2.4835841701595203

Epoch: 5| Step: 8
Training loss: 2.380144871061165
Validation loss: 2.4814659937477535

Epoch: 5| Step: 9
Training loss: 2.4907924849460996
Validation loss: 2.475647561775375

Epoch: 5| Step: 10
Training loss: 2.5365633358589195
Validation loss: 2.4715068007600762

Epoch: 5| Step: 11
Training loss: 3.443786006123092
Validation loss: 2.470298844584637

Epoch: 168| Step: 0
Training loss: 2.3776600647643975
Validation loss: 2.4750821034142296

Epoch: 5| Step: 1
Training loss: 2.41070293242188
Validation loss: 2.4678471922435605

Epoch: 5| Step: 2
Training loss: 2.6590374850083793
Validation loss: 2.4664890543253195

Epoch: 5| Step: 3
Training loss: 1.939173621621615
Validation loss: 2.467609971226271

Epoch: 5| Step: 4
Training loss: 2.7084853985473667
Validation loss: 2.4765111434537426

Epoch: 5| Step: 5
Training loss: 2.578209153160186
Validation loss: 2.4677430606286266

Epoch: 5| Step: 6
Training loss: 2.162086769268398
Validation loss: 2.4659580708412223

Epoch: 5| Step: 7
Training loss: 2.486302617639682
Validation loss: 2.470239041334268

Epoch: 5| Step: 8
Training loss: 2.3538841370595716
Validation loss: 2.4654753853546465

Epoch: 5| Step: 9
Training loss: 2.7045496896137973
Validation loss: 2.4681680512507365

Epoch: 5| Step: 10
Training loss: 2.788191972042353
Validation loss: 2.4711225432588697

Epoch: 5| Step: 11
Training loss: 2.9444360213089267
Validation loss: 2.468083549229364

Epoch: 169| Step: 0
Training loss: 2.647234077822901
Validation loss: 2.4701503130186526

Epoch: 5| Step: 1
Training loss: 2.879202383641483
Validation loss: 2.471010175480225

Epoch: 5| Step: 2
Training loss: 2.7301881834293504
Validation loss: 2.4660311910265995

Epoch: 5| Step: 3
Training loss: 2.351438398666784
Validation loss: 2.4699138481351177

Epoch: 5| Step: 4
Training loss: 2.51096485742598
Validation loss: 2.4697779394567654

Epoch: 5| Step: 5
Training loss: 2.860534432902581
Validation loss: 2.471796260854442

Epoch: 5| Step: 6
Training loss: 2.1920653523288522
Validation loss: 2.465832656476941

Epoch: 5| Step: 7
Training loss: 1.9219919184654775
Validation loss: 2.4766691367439524

Epoch: 5| Step: 8
Training loss: 2.3422072355674426
Validation loss: 2.4769526594476683

Epoch: 5| Step: 9
Training loss: 2.329441696698299
Validation loss: 2.4732922001868864

Epoch: 5| Step: 10
Training loss: 2.323093686963973
Validation loss: 2.4807800257854913

Epoch: 5| Step: 11
Training loss: 2.1341587610581185
Validation loss: 2.4702755202425553

Epoch: 170| Step: 0
Training loss: 2.681453289870636
Validation loss: 2.471927019030862

Epoch: 5| Step: 1
Training loss: 2.6059770217022984
Validation loss: 2.467087028636805

Epoch: 5| Step: 2
Training loss: 2.2756923753779894
Validation loss: 2.4646173001354

Epoch: 5| Step: 3
Training loss: 2.174659206832886
Validation loss: 2.467331446546771

Epoch: 5| Step: 4
Training loss: 2.626333170631011
Validation loss: 2.4670923277086376

Epoch: 5| Step: 5
Training loss: 2.3819332314076895
Validation loss: 2.4662199193883

Epoch: 5| Step: 6
Training loss: 1.8917488982130743
Validation loss: 2.468625037334288

Epoch: 5| Step: 7
Training loss: 2.498889390302628
Validation loss: 2.46999329835675

Epoch: 5| Step: 8
Training loss: 2.259949408783575
Validation loss: 2.471451922547743

Epoch: 5| Step: 9
Training loss: 2.523702601629631
Validation loss: 2.4666842296228544

Epoch: 5| Step: 10
Training loss: 3.121368434310497
Validation loss: 2.466581337705122

Epoch: 5| Step: 11
Training loss: 2.9677078827286003
Validation loss: 2.4724723221207157

Epoch: 171| Step: 0
Training loss: 2.3567397198107374
Validation loss: 2.4709752753423184

Epoch: 5| Step: 1
Training loss: 1.7759375070883694
Validation loss: 2.4682685487214377

Epoch: 5| Step: 2
Training loss: 2.7211340612929766
Validation loss: 2.474075263756853

Epoch: 5| Step: 3
Training loss: 2.8162644518580056
Validation loss: 2.4724575001014975

Epoch: 5| Step: 4
Training loss: 2.5180984563084188
Validation loss: 2.4811490785459633

Epoch: 5| Step: 5
Training loss: 2.8785637039681324
Validation loss: 2.472102870155632

Epoch: 5| Step: 6
Training loss: 2.7986527232906684
Validation loss: 2.471919945984606

Epoch: 5| Step: 7
Training loss: 2.8252973383161355
Validation loss: 2.4679558921383227

Epoch: 5| Step: 8
Training loss: 2.2943468777671825
Validation loss: 2.464023004060914

Epoch: 5| Step: 9
Training loss: 2.2178394437144684
Validation loss: 2.4681688300670293

Epoch: 5| Step: 10
Training loss: 1.950802207653931
Validation loss: 2.4719774179183314

Epoch: 5| Step: 11
Training loss: 1.9540452543931603
Validation loss: 2.466801498138936

Epoch: 172| Step: 0
Training loss: 2.2525717554719105
Validation loss: 2.473071802142499

Epoch: 5| Step: 1
Training loss: 2.5614514880704897
Validation loss: 2.476575793241651

Epoch: 5| Step: 2
Training loss: 2.427867146158235
Validation loss: 2.465510685683719

Epoch: 5| Step: 3
Training loss: 2.3897646683586853
Validation loss: 2.4777764073992

Epoch: 5| Step: 4
Training loss: 2.223837379424249
Validation loss: 2.4715422118945893

Epoch: 5| Step: 5
Training loss: 2.074191852977092
Validation loss: 2.4678565955935303

Epoch: 5| Step: 6
Training loss: 2.269217543333421
Validation loss: 2.46922593418238

Epoch: 5| Step: 7
Training loss: 2.841840333376897
Validation loss: 2.4703625892903007

Epoch: 5| Step: 8
Training loss: 2.9027262008278796
Validation loss: 2.4624245122128126

Epoch: 5| Step: 9
Training loss: 2.4500844785177875
Validation loss: 2.4732909791546875

Epoch: 5| Step: 10
Training loss: 2.6665385533393873
Validation loss: 2.471602289079957

Epoch: 5| Step: 11
Training loss: 1.953128601070899
Validation loss: 2.4750233549563827

Epoch: 173| Step: 0
Training loss: 2.7575311706385945
Validation loss: 2.4850551625838193

Epoch: 5| Step: 1
Training loss: 2.4988000851182477
Validation loss: 2.487050525114222

Epoch: 5| Step: 2
Training loss: 2.066427364133328
Validation loss: 2.500525969569096

Epoch: 5| Step: 3
Training loss: 2.606928243594084
Validation loss: 2.4964396894197507

Epoch: 5| Step: 4
Training loss: 2.4692158319902235
Validation loss: 2.4887014061261383

Epoch: 5| Step: 5
Training loss: 2.689040164090034
Validation loss: 2.4977613757691546

Epoch: 5| Step: 6
Training loss: 2.7370390203424124
Validation loss: 2.483138266418439

Epoch: 5| Step: 7
Training loss: 1.9816700078017953
Validation loss: 2.4813761535719228

Epoch: 5| Step: 8
Training loss: 2.8602550382207164
Validation loss: 2.4846321908511184

Epoch: 5| Step: 9
Training loss: 2.308392666032372
Validation loss: 2.474959314859624

Epoch: 5| Step: 10
Training loss: 2.3066013471729945
Validation loss: 2.4736018409200695

Epoch: 5| Step: 11
Training loss: 1.643841161484489
Validation loss: 2.47293779438595

Epoch: 174| Step: 0
Training loss: 2.3518526525598977
Validation loss: 2.4686200916539534

Epoch: 5| Step: 1
Training loss: 2.201519536722045
Validation loss: 2.477136864229468

Epoch: 5| Step: 2
Training loss: 2.468741018544531
Validation loss: 2.4728976750039595

Epoch: 5| Step: 3
Training loss: 2.8239719815958044
Validation loss: 2.4675545192159256

Epoch: 5| Step: 4
Training loss: 2.7039185169628377
Validation loss: 2.476282892177212

Epoch: 5| Step: 5
Training loss: 2.082217896989754
Validation loss: 2.468540750158301

Epoch: 5| Step: 6
Training loss: 2.026098320830005
Validation loss: 2.478204966726481

Epoch: 5| Step: 7
Training loss: 2.79046185434144
Validation loss: 2.4662559844529452

Epoch: 5| Step: 8
Training loss: 2.8348418502157866
Validation loss: 2.482545242825686

Epoch: 5| Step: 9
Training loss: 2.5174828534266847
Validation loss: 2.486194935657641

Epoch: 5| Step: 10
Training loss: 2.232140764507948
Validation loss: 2.4910222301940936

Epoch: 5| Step: 11
Training loss: 1.7102592900769267
Validation loss: 2.49002192370148

Epoch: 175| Step: 0
Training loss: 2.347625579887535
Validation loss: 2.4887865991613993

Epoch: 5| Step: 1
Training loss: 2.35116614363061
Validation loss: 2.4981913700024636

Epoch: 5| Step: 2
Training loss: 2.621364710257493
Validation loss: 2.489334131215517

Epoch: 5| Step: 3
Training loss: 2.5730728122625273
Validation loss: 2.487494619322154

Epoch: 5| Step: 4
Training loss: 2.0582321399519423
Validation loss: 2.4880937259104097

Epoch: 5| Step: 5
Training loss: 2.1134500206984397
Validation loss: 2.4795850325984405

Epoch: 5| Step: 6
Training loss: 2.3257058907608728
Validation loss: 2.4774770401892563

Epoch: 5| Step: 7
Training loss: 2.577558513017892
Validation loss: 2.4686413189751364

Epoch: 5| Step: 8
Training loss: 2.144600844513402
Validation loss: 2.4668979820377435

Epoch: 5| Step: 9
Training loss: 2.939043653996595
Validation loss: 2.470506719087915

Epoch: 5| Step: 10
Training loss: 2.77906902395255
Validation loss: 2.46285360108312

Epoch: 5| Step: 11
Training loss: 3.5809719969744576
Validation loss: 2.4678764890351887

Epoch: 176| Step: 0
Training loss: 2.398829723184311
Validation loss: 2.464413931359562

Epoch: 5| Step: 1
Training loss: 2.9610022384289825
Validation loss: 2.4647729564239587

Epoch: 5| Step: 2
Training loss: 2.2426504262017892
Validation loss: 2.468562408756326

Epoch: 5| Step: 3
Training loss: 2.110621218419549
Validation loss: 2.466034079372418

Epoch: 5| Step: 4
Training loss: 2.612135380757668
Validation loss: 2.46665385544732

Epoch: 5| Step: 5
Training loss: 2.9555429722064748
Validation loss: 2.4694974266824588

Epoch: 5| Step: 6
Training loss: 2.5671899258026905
Validation loss: 2.4685510603507366

Epoch: 5| Step: 7
Training loss: 2.5935571437973155
Validation loss: 2.478419942088598

Epoch: 5| Step: 8
Training loss: 2.385343014664227
Validation loss: 2.472236754402092

Epoch: 5| Step: 9
Training loss: 2.3377115408905964
Validation loss: 2.481848809910919

Epoch: 5| Step: 10
Training loss: 1.976088455710698
Validation loss: 2.4812047312055774

Epoch: 5| Step: 11
Training loss: 2.7282167679251748
Validation loss: 2.4757665363876478

Epoch: 177| Step: 0
Training loss: 2.1558024729832628
Validation loss: 2.4796878095985995

Epoch: 5| Step: 1
Training loss: 2.949901941253759
Validation loss: 2.4897638133135973

Epoch: 5| Step: 2
Training loss: 2.2972989891209763
Validation loss: 2.4896166704784237

Epoch: 5| Step: 3
Training loss: 2.0992082647381887
Validation loss: 2.4930846732967846

Epoch: 5| Step: 4
Training loss: 2.5231630158318485
Validation loss: 2.5017796142828943

Epoch: 5| Step: 5
Training loss: 2.096525715192373
Validation loss: 2.5201365648143716

Epoch: 5| Step: 6
Training loss: 2.6331208272086437
Validation loss: 2.507196824187485

Epoch: 5| Step: 7
Training loss: 2.8473444429128896
Validation loss: 2.5099915517801614

Epoch: 5| Step: 8
Training loss: 2.701391910354071
Validation loss: 2.508156452775479

Epoch: 5| Step: 9
Training loss: 2.1151998839379766
Validation loss: 2.4908336282395767

Epoch: 5| Step: 10
Training loss: 2.4758979555588176
Validation loss: 2.478614416375553

Epoch: 5| Step: 11
Training loss: 2.196364832716449
Validation loss: 2.4815993528308162

Epoch: 178| Step: 0
Training loss: 2.207764630294806
Validation loss: 2.4683520704586828

Epoch: 5| Step: 1
Training loss: 2.080023679781884
Validation loss: 2.4702335640225024

Epoch: 5| Step: 2
Training loss: 3.234346841145916
Validation loss: 2.468705832814631

Epoch: 5| Step: 3
Training loss: 2.390215869874947
Validation loss: 2.46575214153265

Epoch: 5| Step: 4
Training loss: 2.2466705908396754
Validation loss: 2.470721194235124

Epoch: 5| Step: 5
Training loss: 2.720599542906631
Validation loss: 2.478192121166773

Epoch: 5| Step: 6
Training loss: 2.2571958339917035
Validation loss: 2.480340809163285

Epoch: 5| Step: 7
Training loss: 2.765609827377166
Validation loss: 2.4798462094029214

Epoch: 5| Step: 8
Training loss: 2.48665797105075
Validation loss: 2.484660725987262

Epoch: 5| Step: 9
Training loss: 2.1263989724118724
Validation loss: 2.4810235111504313

Epoch: 5| Step: 10
Training loss: 2.4370656726927935
Validation loss: 2.484406453059483

Epoch: 5| Step: 11
Training loss: 2.401032873263086
Validation loss: 2.5054374809443085

Epoch: 179| Step: 0
Training loss: 2.7789262643800625
Validation loss: 2.511261237337532

Epoch: 5| Step: 1
Training loss: 1.9927532514689907
Validation loss: 2.520333888228608

Epoch: 5| Step: 2
Training loss: 2.062503121113583
Validation loss: 2.550734032217748

Epoch: 5| Step: 3
Training loss: 3.201676948553359
Validation loss: 2.5541053520879102

Epoch: 5| Step: 4
Training loss: 1.8739479928387826
Validation loss: 2.5420684470834147

Epoch: 5| Step: 5
Training loss: 2.734195463553449
Validation loss: 2.5172512571254853

Epoch: 5| Step: 6
Training loss: 2.552229045419075
Validation loss: 2.4999311397923667

Epoch: 5| Step: 7
Training loss: 2.2108758169675107
Validation loss: 2.4860412719857528

Epoch: 5| Step: 8
Training loss: 2.7706060866096074
Validation loss: 2.4791459328454932

Epoch: 5| Step: 9
Training loss: 2.51466483990403
Validation loss: 2.4724157416281

Epoch: 5| Step: 10
Training loss: 2.0120801878737544
Validation loss: 2.4728780027311292

Epoch: 5| Step: 11
Training loss: 2.2051881909670583
Validation loss: 2.4709104468570646

Epoch: 180| Step: 0
Training loss: 2.595033351117921
Validation loss: 2.469279868165643

Epoch: 5| Step: 1
Training loss: 2.5776218732553415
Validation loss: 2.4667675412231795

Epoch: 5| Step: 2
Training loss: 2.3430144109343827
Validation loss: 2.467842100089174

Epoch: 5| Step: 3
Training loss: 2.296403797628787
Validation loss: 2.4661019041720205

Epoch: 5| Step: 4
Training loss: 2.4968571935598836
Validation loss: 2.465374635008573

Epoch: 5| Step: 5
Training loss: 2.613948537254285
Validation loss: 2.4665075894129527

Epoch: 5| Step: 6
Training loss: 2.3378753279183133
Validation loss: 2.471151023343337

Epoch: 5| Step: 7
Training loss: 2.395701584441509
Validation loss: 2.467833678890642

Epoch: 5| Step: 8
Training loss: 2.057567825775378
Validation loss: 2.475346267605359

Epoch: 5| Step: 9
Training loss: 2.4082205494097937
Validation loss: 2.472010644212355

Epoch: 5| Step: 10
Training loss: 2.8939808104642726
Validation loss: 2.4781071271408184

Epoch: 5| Step: 11
Training loss: 2.7571899748869657
Validation loss: 2.4917285022164806

Epoch: 181| Step: 0
Training loss: 1.9220772613533126
Validation loss: 2.5046592171401434

Epoch: 5| Step: 1
Training loss: 1.8399544781775845
Validation loss: 2.517982156520388

Epoch: 5| Step: 2
Training loss: 2.3853121294550816
Validation loss: 2.517712976411687

Epoch: 5| Step: 3
Training loss: 2.1307489382257696
Validation loss: 2.5492806063446407

Epoch: 5| Step: 4
Training loss: 2.803199649697112
Validation loss: 2.519636178604039

Epoch: 5| Step: 5
Training loss: 2.837659076819286
Validation loss: 2.5220249580506646

Epoch: 5| Step: 6
Training loss: 2.1040382975584766
Validation loss: 2.5046613906448223

Epoch: 5| Step: 7
Training loss: 2.454213186534478
Validation loss: 2.483634306496617

Epoch: 5| Step: 8
Training loss: 2.0513465320252218
Validation loss: 2.481393740739981

Epoch: 5| Step: 9
Training loss: 3.072567642994433
Validation loss: 2.483795730267104

Epoch: 5| Step: 10
Training loss: 2.6738785041649518
Validation loss: 2.4778104840679087

Epoch: 5| Step: 11
Training loss: 3.347342584397261
Validation loss: 2.474116817551225

Epoch: 182| Step: 0
Training loss: 2.4880236817241737
Validation loss: 2.467188063386511

Epoch: 5| Step: 1
Training loss: 2.8327716569854546
Validation loss: 2.4756737166172043

Epoch: 5| Step: 2
Training loss: 2.8519434008232043
Validation loss: 2.471865804360153

Epoch: 5| Step: 3
Training loss: 1.845240297770321
Validation loss: 2.4672811097837206

Epoch: 5| Step: 4
Training loss: 1.8819152466908649
Validation loss: 2.471805130734286

Epoch: 5| Step: 5
Training loss: 2.181003733726639
Validation loss: 2.463270706104184

Epoch: 5| Step: 6
Training loss: 2.2083318338449054
Validation loss: 2.4726581503171285

Epoch: 5| Step: 7
Training loss: 2.658511108226
Validation loss: 2.4712428512399094

Epoch: 5| Step: 8
Training loss: 2.628266255214791
Validation loss: 2.463818840311518

Epoch: 5| Step: 9
Training loss: 2.581048868023377
Validation loss: 2.47699569700055

Epoch: 5| Step: 10
Training loss: 2.439168310222413
Validation loss: 2.479791896315512

Epoch: 5| Step: 11
Training loss: 3.8797871952099054
Validation loss: 2.4848552215739304

Epoch: 183| Step: 0
Training loss: 1.996078461291743
Validation loss: 2.50108792951875

Epoch: 5| Step: 1
Training loss: 2.372313636559015
Validation loss: 2.515484436720481

Epoch: 5| Step: 2
Training loss: 2.3889339674410124
Validation loss: 2.534615586852329

Epoch: 5| Step: 3
Training loss: 2.8800122893918942
Validation loss: 2.5255457099564698

Epoch: 5| Step: 4
Training loss: 2.9806844050830135
Validation loss: 2.5458194714078806

Epoch: 5| Step: 5
Training loss: 2.457403351909953
Validation loss: 2.531777538852304

Epoch: 5| Step: 6
Training loss: 2.616026845893417
Validation loss: 2.502699213409595

Epoch: 5| Step: 7
Training loss: 2.315158964923884
Validation loss: 2.4867318168518144

Epoch: 5| Step: 8
Training loss: 2.086871563090887
Validation loss: 2.4912828858484786

Epoch: 5| Step: 9
Training loss: 2.210632087452414
Validation loss: 2.475843170666055

Epoch: 5| Step: 10
Training loss: 2.695664711758533
Validation loss: 2.474693487595023

Epoch: 5| Step: 11
Training loss: 2.402888836312257
Validation loss: 2.4693723731066006

Epoch: 184| Step: 0
Training loss: 2.3568972277952462
Validation loss: 2.470426770663197

Epoch: 5| Step: 1
Training loss: 2.4319027924058614
Validation loss: 2.4726451212636076

Epoch: 5| Step: 2
Training loss: 2.9030925046746687
Validation loss: 2.4687241822514396

Epoch: 5| Step: 3
Training loss: 2.1931048930940436
Validation loss: 2.4684867517335882

Epoch: 5| Step: 4
Training loss: 2.6354409519529116
Validation loss: 2.474448371673638

Epoch: 5| Step: 5
Training loss: 2.8789264569550337
Validation loss: 2.4730787011762247

Epoch: 5| Step: 6
Training loss: 2.642714717517961
Validation loss: 2.4731301229746983

Epoch: 5| Step: 7
Training loss: 2.7275272619072064
Validation loss: 2.4762987543936115

Epoch: 5| Step: 8
Training loss: 1.7772201998180635
Validation loss: 2.4763127671370766

Epoch: 5| Step: 9
Training loss: 2.530751402927919
Validation loss: 2.481160905841532

Epoch: 5| Step: 10
Training loss: 1.724908994955472
Validation loss: 2.4850658080100896

Epoch: 5| Step: 11
Training loss: 2.838065029805223
Validation loss: 2.4905699300640722

Epoch: 185| Step: 0
Training loss: 2.954621919562812
Validation loss: 2.5008625251284866

Epoch: 5| Step: 1
Training loss: 2.2697940746456244
Validation loss: 2.506596188089174

Epoch: 5| Step: 2
Training loss: 2.1453749034276792
Validation loss: 2.511194292035735

Epoch: 5| Step: 3
Training loss: 2.096271647533178
Validation loss: 2.502027555654464

Epoch: 5| Step: 4
Training loss: 2.2266707544612863
Validation loss: 2.513998062322715

Epoch: 5| Step: 5
Training loss: 2.4602499349520652
Validation loss: 2.5063251311281323

Epoch: 5| Step: 6
Training loss: 2.52393045718335
Validation loss: 2.509949919073085

Epoch: 5| Step: 7
Training loss: 2.655777474055238
Validation loss: 2.4941111268898295

Epoch: 5| Step: 8
Training loss: 2.40523091323935
Validation loss: 2.49868825831426

Epoch: 5| Step: 9
Training loss: 2.478181424166024
Validation loss: 2.4894195180863483

Epoch: 5| Step: 10
Training loss: 2.557214542839363
Validation loss: 2.4884298211362124

Epoch: 5| Step: 11
Training loss: 2.393591542390171
Validation loss: 2.4830887301734443

Epoch: 186| Step: 0
Training loss: 2.435700559317718
Validation loss: 2.488062087886811

Epoch: 5| Step: 1
Training loss: 2.939243043001466
Validation loss: 2.4843839329333024

Epoch: 5| Step: 2
Training loss: 1.8102190200268362
Validation loss: 2.4917926973877083

Epoch: 5| Step: 3
Training loss: 2.753331767013264
Validation loss: 2.489253350791759

Epoch: 5| Step: 4
Training loss: 1.7951225027504338
Validation loss: 2.4858082050145103

Epoch: 5| Step: 5
Training loss: 2.9824962194503524
Validation loss: 2.488100505434555

Epoch: 5| Step: 6
Training loss: 1.825411355676205
Validation loss: 2.4884285117209024

Epoch: 5| Step: 7
Training loss: 2.3012835694226235
Validation loss: 2.4828023511400295

Epoch: 5| Step: 8
Training loss: 2.5207359568386214
Validation loss: 2.477287579439685

Epoch: 5| Step: 9
Training loss: 2.4894340395887937
Validation loss: 2.490763377928831

Epoch: 5| Step: 10
Training loss: 2.6842073186121023
Validation loss: 2.4789639090857274

Epoch: 5| Step: 11
Training loss: 1.4627096270445157
Validation loss: 2.49398294984536

Epoch: 187| Step: 0
Training loss: 2.398753987160411
Validation loss: 2.487858343591269

Epoch: 5| Step: 1
Training loss: 2.0992014501985334
Validation loss: 2.5078387788879217

Epoch: 5| Step: 2
Training loss: 2.429242353966899
Validation loss: 2.5080312076956153

Epoch: 5| Step: 3
Training loss: 2.389656419198971
Validation loss: 2.4978761671811522

Epoch: 5| Step: 4
Training loss: 2.732864136859615
Validation loss: 2.5234943182722374

Epoch: 5| Step: 5
Training loss: 1.776351349829755
Validation loss: 2.537766189268517

Epoch: 5| Step: 6
Training loss: 2.39709574293424
Validation loss: 2.532450775761419

Epoch: 5| Step: 7
Training loss: 2.595803332780503
Validation loss: 2.5307112147847346

Epoch: 5| Step: 8
Training loss: 2.725948931455668
Validation loss: 2.522494619245307

Epoch: 5| Step: 9
Training loss: 2.2846672904365577
Validation loss: 2.5142457747054556

Epoch: 5| Step: 10
Training loss: 2.8884044469262675
Validation loss: 2.502938792350681

Epoch: 5| Step: 11
Training loss: 2.1303931966715246
Validation loss: 2.490118744602762

Epoch: 188| Step: 0
Training loss: 2.355039541637418
Validation loss: 2.472151983587281

Epoch: 5| Step: 1
Training loss: 2.1456051553930235
Validation loss: 2.472014807514276

Epoch: 5| Step: 2
Training loss: 1.9529495770829983
Validation loss: 2.469270454143331

Epoch: 5| Step: 3
Training loss: 2.5263659606623907
Validation loss: 2.4660983955523075

Epoch: 5| Step: 4
Training loss: 2.18100854362483
Validation loss: 2.4713725393166404

Epoch: 5| Step: 5
Training loss: 2.5767796560816163
Validation loss: 2.46899577015993

Epoch: 5| Step: 6
Training loss: 2.4989563670964925
Validation loss: 2.463918747112336

Epoch: 5| Step: 7
Training loss: 2.9736432355626032
Validation loss: 2.470030082533604

Epoch: 5| Step: 8
Training loss: 2.6452081397212415
Validation loss: 2.469389341758945

Epoch: 5| Step: 9
Training loss: 2.3692805035865407
Validation loss: 2.469972629640004

Epoch: 5| Step: 10
Training loss: 2.9748716182416226
Validation loss: 2.4679522170941715

Epoch: 5| Step: 11
Training loss: 2.590871845628647
Validation loss: 2.477239670617767

Epoch: 189| Step: 0
Training loss: 1.9934953772130315
Validation loss: 2.4808006915563445

Epoch: 5| Step: 1
Training loss: 2.193336982646716
Validation loss: 2.491531261753989

Epoch: 5| Step: 2
Training loss: 2.4095670947572643
Validation loss: 2.500849563569694

Epoch: 5| Step: 3
Training loss: 3.013232769624343
Validation loss: 2.513683806151218

Epoch: 5| Step: 4
Training loss: 1.9246800738930145
Validation loss: 2.51954545995367

Epoch: 5| Step: 5
Training loss: 2.289632160012088
Validation loss: 2.530502228507072

Epoch: 5| Step: 6
Training loss: 2.7352351116545415
Validation loss: 2.523104760875703

Epoch: 5| Step: 7
Training loss: 2.4003671842071483
Validation loss: 2.5198002240426094

Epoch: 5| Step: 8
Training loss: 2.389018896789033
Validation loss: 2.5031910835588365

Epoch: 5| Step: 9
Training loss: 2.8577432614673266
Validation loss: 2.4931174589055645

Epoch: 5| Step: 10
Training loss: 2.5549269631056384
Validation loss: 2.491988761096836

Epoch: 5| Step: 11
Training loss: 1.5873058410617809
Validation loss: 2.486771549259958

Epoch: 190| Step: 0
Training loss: 2.705781898804655
Validation loss: 2.4817693809726515

Epoch: 5| Step: 1
Training loss: 2.500647556362423
Validation loss: 2.484446222655915

Epoch: 5| Step: 2
Training loss: 2.2215753752984218
Validation loss: 2.475154954060556

Epoch: 5| Step: 3
Training loss: 2.121702328202694
Validation loss: 2.48346176396737

Epoch: 5| Step: 4
Training loss: 2.464655220571982
Validation loss: 2.480884459095488

Epoch: 5| Step: 5
Training loss: 2.301137485354029
Validation loss: 2.4808101268956184

Epoch: 5| Step: 6
Training loss: 2.858178060186326
Validation loss: 2.4842005294540135

Epoch: 5| Step: 7
Training loss: 2.355007044139783
Validation loss: 2.486000309120122

Epoch: 5| Step: 8
Training loss: 2.594689348475843
Validation loss: 2.4872151940207434

Epoch: 5| Step: 9
Training loss: 1.4703864862391776
Validation loss: 2.5024228753124853

Epoch: 5| Step: 10
Training loss: 2.978860923888463
Validation loss: 2.5089610748499878

Epoch: 5| Step: 11
Training loss: 2.7845156067903853
Validation loss: 2.5127204965910046

Epoch: 191| Step: 0
Training loss: 2.787631054863748
Validation loss: 2.51585602341215

Epoch: 5| Step: 1
Training loss: 2.6939653208765417
Validation loss: 2.5124212205217504

Epoch: 5| Step: 2
Training loss: 1.8525257421807948
Validation loss: 2.496199659827845

Epoch: 5| Step: 3
Training loss: 2.639525144959836
Validation loss: 2.500600190437249

Epoch: 5| Step: 4
Training loss: 2.3118334660198547
Validation loss: 2.498198718600257

Epoch: 5| Step: 5
Training loss: 1.9950624552728802
Validation loss: 2.49341413153027

Epoch: 5| Step: 6
Training loss: 2.7115996593722165
Validation loss: 2.483743879339173

Epoch: 5| Step: 7
Training loss: 2.461554071601559
Validation loss: 2.4924695683441866

Epoch: 5| Step: 8
Training loss: 2.3011664956942517
Validation loss: 2.4877589809004013

Epoch: 5| Step: 9
Training loss: 2.5656867332326323
Validation loss: 2.5035895684426417

Epoch: 5| Step: 10
Training loss: 2.498733390382691
Validation loss: 2.492019067651151

Epoch: 5| Step: 11
Training loss: 1.4990377518656943
Validation loss: 2.490155989466639

Epoch: 192| Step: 0
Training loss: 2.591444806561645
Validation loss: 2.4982897392127286

Epoch: 5| Step: 1
Training loss: 2.5891578191731477
Validation loss: 2.5008690317023956

Epoch: 5| Step: 2
Training loss: 2.027277186482529
Validation loss: 2.5011553796616166

Epoch: 5| Step: 3
Training loss: 2.6125544747691816
Validation loss: 2.5023043423464646

Epoch: 5| Step: 4
Training loss: 2.712209265813112
Validation loss: 2.5089425722690546

Epoch: 5| Step: 5
Training loss: 2.2429750767282766
Validation loss: 2.4940569691082275

Epoch: 5| Step: 6
Training loss: 2.81614846836816
Validation loss: 2.495736468180904

Epoch: 5| Step: 7
Training loss: 2.7102262679793028
Validation loss: 2.5005412429795566

Epoch: 5| Step: 8
Training loss: 1.8887982331131552
Validation loss: 2.500798753452509

Epoch: 5| Step: 9
Training loss: 2.0946652134445722
Validation loss: 2.4942737206276187

Epoch: 5| Step: 10
Training loss: 2.4296484450362947
Validation loss: 2.504002986314829

Epoch: 5| Step: 11
Training loss: 0.8024434028703711
Validation loss: 2.5221034087180327

Epoch: 193| Step: 0
Training loss: 2.127056473111875
Validation loss: 2.4982053792424606

Epoch: 5| Step: 1
Training loss: 1.723962543709061
Validation loss: 2.4980851350170314

Epoch: 5| Step: 2
Training loss: 2.443868777615396
Validation loss: 2.496620528582543

Epoch: 5| Step: 3
Training loss: 2.272405855685846
Validation loss: 2.4964307936563586

Epoch: 5| Step: 4
Training loss: 2.3636569142281862
Validation loss: 2.48424077021258

Epoch: 5| Step: 5
Training loss: 2.490880928627088
Validation loss: 2.4940357111505564

Epoch: 5| Step: 6
Training loss: 2.746866261334889
Validation loss: 2.489022572195751

Epoch: 5| Step: 7
Training loss: 2.4016381196604946
Validation loss: 2.497096139522894

Epoch: 5| Step: 8
Training loss: 2.678277626273273
Validation loss: 2.497122690315106

Epoch: 5| Step: 9
Training loss: 2.517425461454518
Validation loss: 2.5004960203830064

Epoch: 5| Step: 10
Training loss: 2.3827173432908064
Validation loss: 2.4939452243896234

Epoch: 5| Step: 11
Training loss: 3.9165926310799275
Validation loss: 2.4934985340777804

Epoch: 194| Step: 0
Training loss: 2.4250532400048272
Validation loss: 2.498967156044154

Epoch: 5| Step: 1
Training loss: 2.2938265130277173
Validation loss: 2.49982606362213

Epoch: 5| Step: 2
Training loss: 2.331784540414019
Validation loss: 2.504311618534431

Epoch: 5| Step: 3
Training loss: 2.531747745507262
Validation loss: 2.509824846610486

Epoch: 5| Step: 4
Training loss: 2.4968270193366915
Validation loss: 2.5216591929795404

Epoch: 5| Step: 5
Training loss: 2.4517744683847336
Validation loss: 2.520848919817656

Epoch: 5| Step: 6
Training loss: 2.282547673106716
Validation loss: 2.5154776125236267

Epoch: 5| Step: 7
Training loss: 2.6390289358711536
Validation loss: 2.5254246708698456

Epoch: 5| Step: 8
Training loss: 2.4485185464908708
Validation loss: 2.515500043841848

Epoch: 5| Step: 9
Training loss: 2.6286039589563073
Validation loss: 2.5060570059881457

Epoch: 5| Step: 10
Training loss: 1.8915663338267372
Validation loss: 2.4965656294154286

Epoch: 5| Step: 11
Training loss: 3.0616754472828482
Validation loss: 2.49586330339039

Epoch: 195| Step: 0
Training loss: 2.3386708473826454
Validation loss: 2.490260795502971

Epoch: 5| Step: 1
Training loss: 2.817043872457759
Validation loss: 2.507354048737527

Epoch: 5| Step: 2
Training loss: 2.0809952267798733
Validation loss: 2.494186839066626

Epoch: 5| Step: 3
Training loss: 2.468791140442908
Validation loss: 2.504016308441161

Epoch: 5| Step: 4
Training loss: 2.1494812805397085
Validation loss: 2.5086512999861865

Epoch: 5| Step: 5
Training loss: 2.7195346620752527
Validation loss: 2.5193222195758795

Epoch: 5| Step: 6
Training loss: 2.2088096272958904
Validation loss: 2.5332964054247955

Epoch: 5| Step: 7
Training loss: 2.431327438101888
Validation loss: 2.5293486718725036

Epoch: 5| Step: 8
Training loss: 2.0701927294364935
Validation loss: 2.5199794715595205

Epoch: 5| Step: 9
Training loss: 2.9426111435946183
Validation loss: 2.5184557371311116

Epoch: 5| Step: 10
Training loss: 2.0964135834860693
Validation loss: 2.516712066391418

Epoch: 5| Step: 11
Training loss: 1.8632771553938239
Validation loss: 2.515865871199659

Epoch: 196| Step: 0
Training loss: 2.845167372729628
Validation loss: 2.5171937533174047

Epoch: 5| Step: 1
Training loss: 2.5337828220674905
Validation loss: 2.5286872551324846

Epoch: 5| Step: 2
Training loss: 2.1645336533378003
Validation loss: 2.5355491118263775

Epoch: 5| Step: 3
Training loss: 2.630339505289372
Validation loss: 2.5229633110159275

Epoch: 5| Step: 4
Training loss: 2.0025482632920397
Validation loss: 2.5067528439818223

Epoch: 5| Step: 5
Training loss: 2.020375176893568
Validation loss: 2.503019305730952

Epoch: 5| Step: 6
Training loss: 2.2558570498499924
Validation loss: 2.4900865578256552

Epoch: 5| Step: 7
Training loss: 2.3671303921599987
Validation loss: 2.4853075044795117

Epoch: 5| Step: 8
Training loss: 2.4994956461469227
Validation loss: 2.4848665714773097

Epoch: 5| Step: 9
Training loss: 2.35617748118546
Validation loss: 2.482195704071704

Epoch: 5| Step: 10
Training loss: 2.7403684489485043
Validation loss: 2.4847353827803973

Epoch: 5| Step: 11
Training loss: 3.265504971721359
Validation loss: 2.4775546961436334

Epoch: 197| Step: 0
Training loss: 1.5603050837158128
Validation loss: 2.4961181145933047

Epoch: 5| Step: 1
Training loss: 2.4371577291557163
Validation loss: 2.485562610471497

Epoch: 5| Step: 2
Training loss: 1.939306278566331
Validation loss: 2.5124303601705664

Epoch: 5| Step: 3
Training loss: 2.1262486099337297
Validation loss: 2.518738500191788

Epoch: 5| Step: 4
Training loss: 2.7132585686576736
Validation loss: 2.537894440986121

Epoch: 5| Step: 5
Training loss: 2.3265599872685705
Validation loss: 2.5323744423091115

Epoch: 5| Step: 6
Training loss: 2.9204897937462437
Validation loss: 2.513930565545363

Epoch: 5| Step: 7
Training loss: 2.691814862197966
Validation loss: 2.50246231095181

Epoch: 5| Step: 8
Training loss: 2.6536155651538813
Validation loss: 2.4920347519704724

Epoch: 5| Step: 9
Training loss: 2.8457185408384778
Validation loss: 2.498543394451763

Epoch: 5| Step: 10
Training loss: 2.1984433692577237
Validation loss: 2.4853951580868143

Epoch: 5| Step: 11
Training loss: 2.505749385617107
Validation loss: 2.493016279567055

Epoch: 198| Step: 0
Training loss: 2.20210924473161
Validation loss: 2.4927364649595356

Epoch: 5| Step: 1
Training loss: 2.728422126451452
Validation loss: 2.4833204762448133

Epoch: 5| Step: 2
Training loss: 2.48695834219371
Validation loss: 2.4892728577362813

Epoch: 5| Step: 3
Training loss: 2.4914612862987635
Validation loss: 2.488003430309977

Epoch: 5| Step: 4
Training loss: 2.1663146711184362
Validation loss: 2.4924755348527694

Epoch: 5| Step: 5
Training loss: 2.845348202493434
Validation loss: 2.4965131921626553

Epoch: 5| Step: 6
Training loss: 2.2164352592584082
Validation loss: 2.492504047950409

Epoch: 5| Step: 7
Training loss: 2.067027584473208
Validation loss: 2.4830507911905935

Epoch: 5| Step: 8
Training loss: 2.8784757419059
Validation loss: 2.496067474815961

Epoch: 5| Step: 9
Training loss: 1.9121800722294937
Validation loss: 2.4926308922083686

Epoch: 5| Step: 10
Training loss: 2.208994952243134
Validation loss: 2.496458668666731

Epoch: 5| Step: 11
Training loss: 3.421668616912281
Validation loss: 2.5072599655976755

Epoch: 199| Step: 0
Training loss: 1.9845808628260984
Validation loss: 2.5118360042147354

Epoch: 5| Step: 1
Training loss: 2.2438519510468047
Validation loss: 2.51770433534224

Epoch: 5| Step: 2
Training loss: 2.2149552682187426
Validation loss: 2.5156470627537932

Epoch: 5| Step: 3
Training loss: 2.505016443803918
Validation loss: 2.5068490068040252

Epoch: 5| Step: 4
Training loss: 2.2650695119805935
Validation loss: 2.498877249373938

Epoch: 5| Step: 5
Training loss: 2.791557670477201
Validation loss: 2.5059335944903287

Epoch: 5| Step: 6
Training loss: 2.2388527558310933
Validation loss: 2.5004635023555313

Epoch: 5| Step: 7
Training loss: 2.5639314142596694
Validation loss: 2.498340886649415

Epoch: 5| Step: 8
Training loss: 2.094885105633348
Validation loss: 2.5026532200436136

Epoch: 5| Step: 9
Training loss: 2.6726868048702395
Validation loss: 2.492941109649406

Epoch: 5| Step: 10
Training loss: 2.680268961377247
Validation loss: 2.5066105545980375

Epoch: 5| Step: 11
Training loss: 3.1712020385627855
Validation loss: 2.495427850243954

Epoch: 200| Step: 0
Training loss: 2.2100013934860323
Validation loss: 2.488421429688353

Epoch: 5| Step: 1
Training loss: 2.55595893601816
Validation loss: 2.4792610051667756

Epoch: 5| Step: 2
Training loss: 2.650135407497147
Validation loss: 2.4738273519007503

Epoch: 5| Step: 3
Training loss: 2.69301961037925
Validation loss: 2.4922722231057515

Epoch: 5| Step: 4
Training loss: 2.4744331519916916
Validation loss: 2.492888775479845

Epoch: 5| Step: 5
Training loss: 2.2425968447795808
Validation loss: 2.4904955718243555

Epoch: 5| Step: 6
Training loss: 2.5854430864097484
Validation loss: 2.490569758550464

Epoch: 5| Step: 7
Training loss: 2.2320397184249354
Validation loss: 2.4912152361960453

Epoch: 5| Step: 8
Training loss: 2.414757193449107
Validation loss: 2.5007456422507417

Epoch: 5| Step: 9
Training loss: 2.096798627346598
Validation loss: 2.4998033446212893

Epoch: 5| Step: 10
Training loss: 2.3974351807743215
Validation loss: 2.5063000809572107

Epoch: 5| Step: 11
Training loss: 1.668657147399557
Validation loss: 2.497833779725331

Epoch: 201| Step: 0
Training loss: 2.0766447144272164
Validation loss: 2.513533502705913

Epoch: 5| Step: 1
Training loss: 2.4486040381275753
Validation loss: 2.5136938837604976

Epoch: 5| Step: 2
Training loss: 2.107349129341361
Validation loss: 2.539538412241857

Epoch: 5| Step: 3
Training loss: 2.291827722149707
Validation loss: 2.529307772147762

Epoch: 5| Step: 4
Training loss: 3.2949632643184366
Validation loss: 2.531870220477696

Epoch: 5| Step: 5
Training loss: 2.539694745501827
Validation loss: 2.5251988561621466

Epoch: 5| Step: 6
Training loss: 1.9720013730622747
Validation loss: 2.525562080921799

Epoch: 5| Step: 7
Training loss: 2.7083159421704748
Validation loss: 2.515194810687561

Epoch: 5| Step: 8
Training loss: 1.7834040684204309
Validation loss: 2.505152189507282

Epoch: 5| Step: 9
Training loss: 2.4646384853491914
Validation loss: 2.505772141890435

Epoch: 5| Step: 10
Training loss: 2.46354396785013
Validation loss: 2.4889457210677715

Epoch: 5| Step: 11
Training loss: 3.2219526042897577
Validation loss: 2.493432805117917

Epoch: 202| Step: 0
Training loss: 2.384099493946025
Validation loss: 2.477583228592085

Epoch: 5| Step: 1
Training loss: 2.5610627586542796
Validation loss: 2.4783469148476223

Epoch: 5| Step: 2
Training loss: 2.777190428202487
Validation loss: 2.4764506759026683

Epoch: 5| Step: 3
Training loss: 2.1947342189035046
Validation loss: 2.4742711896672205

Epoch: 5| Step: 4
Training loss: 2.4779409910292847
Validation loss: 2.470760050282438

Epoch: 5| Step: 5
Training loss: 2.4977763777389916
Validation loss: 2.4753208718232336

Epoch: 5| Step: 6
Training loss: 2.1910949594733324
Validation loss: 2.4826741624355178

Epoch: 5| Step: 7
Training loss: 2.7200281931313586
Validation loss: 2.479049693214417

Epoch: 5| Step: 8
Training loss: 2.733778359850808
Validation loss: 2.4805449426518185

Epoch: 5| Step: 9
Training loss: 2.1083888256424608
Validation loss: 2.4841796510295864

Epoch: 5| Step: 10
Training loss: 2.2043640764623933
Validation loss: 2.489343062315742

Epoch: 5| Step: 11
Training loss: 1.8277458384595227
Validation loss: 2.4986910969831797

Epoch: 203| Step: 0
Training loss: 2.361753262978419
Validation loss: 2.49606454560533

Epoch: 5| Step: 1
Training loss: 2.099843055673322
Validation loss: 2.5132912893809216

Epoch: 5| Step: 2
Training loss: 1.8429339914573437
Validation loss: 2.5328743749987783

Epoch: 5| Step: 3
Training loss: 2.446682092460351
Validation loss: 2.533685297629966

Epoch: 5| Step: 4
Training loss: 2.857149185446134
Validation loss: 2.529822033106123

Epoch: 5| Step: 5
Training loss: 2.33233211244307
Validation loss: 2.5294853896263083

Epoch: 5| Step: 6
Training loss: 2.332299502996922
Validation loss: 2.5138375702661055

Epoch: 5| Step: 7
Training loss: 2.2535788366028875
Validation loss: 2.5068189488880366

Epoch: 5| Step: 8
Training loss: 2.5220367984794594
Validation loss: 2.4955553161601256

Epoch: 5| Step: 9
Training loss: 2.63432924857634
Validation loss: 2.5016795516799446

Epoch: 5| Step: 10
Training loss: 2.8320911900984407
Validation loss: 2.4830127075982436

Epoch: 5| Step: 11
Training loss: 2.5433727125199836
Validation loss: 2.48387607626925

Epoch: 204| Step: 0
Training loss: 2.7952443915780747
Validation loss: 2.484399923363513

Epoch: 5| Step: 1
Training loss: 1.9525650442428035
Validation loss: 2.486518974401072

Epoch: 5| Step: 2
Training loss: 2.468771922340116
Validation loss: 2.487536607885076

Epoch: 5| Step: 3
Training loss: 2.4863296592689688
Validation loss: 2.4898487784848897

Epoch: 5| Step: 4
Training loss: 2.520153637093029
Validation loss: 2.491059848376298

Epoch: 5| Step: 5
Training loss: 2.81081560346627
Validation loss: 2.4951282319324015

Epoch: 5| Step: 6
Training loss: 2.8286722401961057
Validation loss: 2.495475286477951

Epoch: 5| Step: 7
Training loss: 2.257261321165006
Validation loss: 2.5001588135184787

Epoch: 5| Step: 8
Training loss: 2.004561229841116
Validation loss: 2.50282181591571

Epoch: 5| Step: 9
Training loss: 2.3839317819768637
Validation loss: 2.5057214514143715

Epoch: 5| Step: 10
Training loss: 2.093903607100006
Validation loss: 2.5104832475520267

Epoch: 5| Step: 11
Training loss: 1.2742421235186683
Validation loss: 2.5152614085915013

Epoch: 205| Step: 0
Training loss: 2.789087973940477
Validation loss: 2.528156277652079

Epoch: 5| Step: 1
Training loss: 1.712857914854794
Validation loss: 2.5263482972805154

Epoch: 5| Step: 2
Training loss: 2.186668019798294
Validation loss: 2.5436011883996184

Epoch: 5| Step: 3
Training loss: 2.472878974899401
Validation loss: 2.5538652907064927

Epoch: 5| Step: 4
Training loss: 1.9742239284409726
Validation loss: 2.5382601208647397

Epoch: 5| Step: 5
Training loss: 2.142656462218778
Validation loss: 2.5320100114279454

Epoch: 5| Step: 6
Training loss: 2.7436837572864623
Validation loss: 2.5171353759988735

Epoch: 5| Step: 7
Training loss: 2.8177813639786793
Validation loss: 2.516331054296694

Epoch: 5| Step: 8
Training loss: 2.7143613098487926
Validation loss: 2.502366336844037

Epoch: 5| Step: 9
Training loss: 2.5333040168805954
Validation loss: 2.501833045017493

Epoch: 5| Step: 10
Training loss: 2.0546704425756444
Validation loss: 2.499096850337648

Epoch: 5| Step: 11
Training loss: 2.398354594136636
Validation loss: 2.492247523957181

Epoch: 206| Step: 0
Training loss: 3.03836467350797
Validation loss: 2.5056715449133926

Epoch: 5| Step: 1
Training loss: 1.7458265129933326
Validation loss: 2.5111136768113687

Epoch: 5| Step: 2
Training loss: 2.2430843460340166
Validation loss: 2.499124288169973

Epoch: 5| Step: 3
Training loss: 1.751581363082981
Validation loss: 2.504588831058506

Epoch: 5| Step: 4
Training loss: 2.6737363700644132
Validation loss: 2.5010580089077017

Epoch: 5| Step: 5
Training loss: 2.1366909659913786
Validation loss: 2.50781809329858

Epoch: 5| Step: 6
Training loss: 2.257003269570095
Validation loss: 2.5069714935430882

Epoch: 5| Step: 7
Training loss: 2.6200018028078356
Validation loss: 2.5091449410397386

Epoch: 5| Step: 8
Training loss: 2.3184237515414274
Validation loss: 2.5264347137679155

Epoch: 5| Step: 9
Training loss: 2.431287428854627
Validation loss: 2.516927113593046

Epoch: 5| Step: 10
Training loss: 2.5210295251420964
Validation loss: 2.516986289054073

Epoch: 5| Step: 11
Training loss: 3.2221956050986553
Validation loss: 2.540061754054195

Epoch: 207| Step: 0
Training loss: 2.5620387522843573
Validation loss: 2.5454239056121537

Epoch: 5| Step: 1
Training loss: 2.669871689074328
Validation loss: 2.5294573287441158

Epoch: 5| Step: 2
Training loss: 2.4276435325610106
Validation loss: 2.5219385559002174

Epoch: 5| Step: 3
Training loss: 2.1536254389826253
Validation loss: 2.5213600047253464

Epoch: 5| Step: 4
Training loss: 2.3250170963438133
Validation loss: 2.509961246530731

Epoch: 5| Step: 5
Training loss: 2.139824376431158
Validation loss: 2.5048246440119524

Epoch: 5| Step: 6
Training loss: 2.1491487192817376
Validation loss: 2.5094335432812604

Epoch: 5| Step: 7
Training loss: 2.403567515730178
Validation loss: 2.5133982985978944

Epoch: 5| Step: 8
Training loss: 2.470299053698432
Validation loss: 2.5158467520837893

Epoch: 5| Step: 9
Training loss: 2.5552379703371053
Validation loss: 2.501423017499763

Epoch: 5| Step: 10
Training loss: 2.602697726167291
Validation loss: 2.5148524525667506

Epoch: 5| Step: 11
Training loss: 1.6431392477817295
Validation loss: 2.5091578755836537

Epoch: 208| Step: 0
Training loss: 2.5812357313302092
Validation loss: 2.514791611234363

Epoch: 5| Step: 1
Training loss: 2.63323790059415
Validation loss: 2.510620980766409

Epoch: 5| Step: 2
Training loss: 1.6780240360625462
Validation loss: 2.5128479985443004

Epoch: 5| Step: 3
Training loss: 2.5294986835814877
Validation loss: 2.514051462563737

Epoch: 5| Step: 4
Training loss: 2.4347297380612702
Validation loss: 2.518707440366158

Epoch: 5| Step: 5
Training loss: 2.4106597127237426
Validation loss: 2.5104478237914765

Epoch: 5| Step: 6
Training loss: 2.216937332072871
Validation loss: 2.51511551256768

Epoch: 5| Step: 7
Training loss: 2.180238496875807
Validation loss: 2.513880541443943

Epoch: 5| Step: 8
Training loss: 2.984309490343666
Validation loss: 2.515020973239458

Epoch: 5| Step: 9
Training loss: 1.8552105211962209
Validation loss: 2.524544822311836

Epoch: 5| Step: 10
Training loss: 2.559413632950182
Validation loss: 2.527162640709041

Epoch: 5| Step: 11
Training loss: 1.3947366515124435
Validation loss: 2.5398551838184376

Epoch: 209| Step: 0
Training loss: 1.8263645662042733
Validation loss: 2.551022497260607

Epoch: 5| Step: 1
Training loss: 2.684932014130285
Validation loss: 2.555615481132455

Epoch: 5| Step: 2
Training loss: 1.9309392413631403
Validation loss: 2.5278987717287205

Epoch: 5| Step: 3
Training loss: 2.4458683832398513
Validation loss: 2.53042130189753

Epoch: 5| Step: 4
Training loss: 2.5125529800826425
Validation loss: 2.5225074006656683

Epoch: 5| Step: 5
Training loss: 2.5447354369184807
Validation loss: 2.521146330567349

Epoch: 5| Step: 6
Training loss: 2.683057528788622
Validation loss: 2.518144396381122

Epoch: 5| Step: 7
Training loss: 2.4896367810841995
Validation loss: 2.5047078032453025

Epoch: 5| Step: 8
Training loss: 2.4771055955798156
Validation loss: 2.4967677918145235

Epoch: 5| Step: 9
Training loss: 2.081077142358911
Validation loss: 2.4973587269391504

Epoch: 5| Step: 10
Training loss: 2.647624113147303
Validation loss: 2.500240028302722

Epoch: 5| Step: 11
Training loss: 1.4853969870499142
Validation loss: 2.499654074418895

Epoch: 210| Step: 0
Training loss: 2.4837711968019005
Validation loss: 2.5025761166422016

Epoch: 5| Step: 1
Training loss: 2.485052724083211
Validation loss: 2.4994959402558203

Epoch: 5| Step: 2
Training loss: 2.469334786603485
Validation loss: 2.5114501959849393

Epoch: 5| Step: 3
Training loss: 2.3137011115104174
Validation loss: 2.5149009681489867

Epoch: 5| Step: 4
Training loss: 2.388951033392587
Validation loss: 2.526556345362609

Epoch: 5| Step: 5
Training loss: 2.3418467614187066
Validation loss: 2.5258743361800393

Epoch: 5| Step: 6
Training loss: 2.0994336999543832
Validation loss: 2.5316846458666395

Epoch: 5| Step: 7
Training loss: 2.9447971368681967
Validation loss: 2.534737229556825

Epoch: 5| Step: 8
Training loss: 2.197139210773258
Validation loss: 2.5307090989818217

Epoch: 5| Step: 9
Training loss: 2.7433149405597135
Validation loss: 2.5324723585012987

Epoch: 5| Step: 10
Training loss: 1.6199336669433817
Validation loss: 2.5192889350859606

Epoch: 5| Step: 11
Training loss: 2.332626190206503
Validation loss: 2.524721230487244

Epoch: 211| Step: 0
Training loss: 1.7543928325250961
Validation loss: 2.5246097570009103

Epoch: 5| Step: 1
Training loss: 2.5417746745022782
Validation loss: 2.519814582290519

Epoch: 5| Step: 2
Training loss: 2.234232971372375
Validation loss: 2.5267219151878932

Epoch: 5| Step: 3
Training loss: 2.8088307499535756
Validation loss: 2.5169658878266996

Epoch: 5| Step: 4
Training loss: 2.925628535890551
Validation loss: 2.521438799149979

Epoch: 5| Step: 5
Training loss: 2.336160604482081
Validation loss: 2.50659040183062

Epoch: 5| Step: 6
Training loss: 2.5716360099318343
Validation loss: 2.5091478470618407

Epoch: 5| Step: 7
Training loss: 2.5373171397501095
Validation loss: 2.5137437772112663

Epoch: 5| Step: 8
Training loss: 2.2390914968355293
Validation loss: 2.5125587545866597

Epoch: 5| Step: 9
Training loss: 2.149168243979558
Validation loss: 2.508863318069384

Epoch: 5| Step: 10
Training loss: 2.1276477698749408
Validation loss: 2.509418563496306

Epoch: 5| Step: 11
Training loss: 1.1248748497757788
Validation loss: 2.52670670764049

Epoch: 212| Step: 0
Training loss: 1.9050655750192147
Validation loss: 2.533976028873206

Epoch: 5| Step: 1
Training loss: 3.0519870226422907
Validation loss: 2.5501400627054256

Epoch: 5| Step: 2
Training loss: 2.1839009787081114
Validation loss: 2.5410771989215934

Epoch: 5| Step: 3
Training loss: 2.6235022131894348
Validation loss: 2.537022127839631

Epoch: 5| Step: 4
Training loss: 2.4641614353441326
Validation loss: 2.537284169625427

Epoch: 5| Step: 5
Training loss: 2.648899274420949
Validation loss: 2.5345613499689925

Epoch: 5| Step: 6
Training loss: 2.345362197786549
Validation loss: 2.529479922786062

Epoch: 5| Step: 7
Training loss: 2.044965712579309
Validation loss: 2.52443005515566

Epoch: 5| Step: 8
Training loss: 2.33171634049455
Validation loss: 2.516622760107599

Epoch: 5| Step: 9
Training loss: 2.1577148989979342
Validation loss: 2.5199507470054545

Epoch: 5| Step: 10
Training loss: 2.191063077171009
Validation loss: 2.526109556223113

Epoch: 5| Step: 11
Training loss: 2.9848788969435502
Validation loss: 2.5157668506126596

Epoch: 213| Step: 0
Training loss: 2.971074368907418
Validation loss: 2.516882445914293

Epoch: 5| Step: 1
Training loss: 2.3888781778948087
Validation loss: 2.5094197629908366

Epoch: 5| Step: 2
Training loss: 2.651040387606109
Validation loss: 2.5008969446329368

Epoch: 5| Step: 3
Training loss: 1.4612428070752814
Validation loss: 2.500196425350738

Epoch: 5| Step: 4
Training loss: 2.3569713753089747
Validation loss: 2.50702090460843

Epoch: 5| Step: 5
Training loss: 2.3942604098460656
Validation loss: 2.5146712752110707

Epoch: 5| Step: 6
Training loss: 2.121214018445178
Validation loss: 2.5244870950647678

Epoch: 5| Step: 7
Training loss: 2.8173848434784707
Validation loss: 2.531901487646491

Epoch: 5| Step: 8
Training loss: 2.401663533494835
Validation loss: 2.5304056140686124

Epoch: 5| Step: 9
Training loss: 2.121443858327829
Validation loss: 2.5402155444159833

Epoch: 5| Step: 10
Training loss: 2.4145679129985003
Validation loss: 2.5200614548750986

Epoch: 5| Step: 11
Training loss: 1.5217833317088842
Validation loss: 2.533714119365909

Epoch: 214| Step: 0
Training loss: 2.354342620035552
Validation loss: 2.549177303244215

Epoch: 5| Step: 1
Training loss: 2.2984388567974303
Validation loss: 2.5385865963693224

Epoch: 5| Step: 2
Training loss: 1.8069885908567802
Validation loss: 2.5325817090077467

Epoch: 5| Step: 3
Training loss: 2.3497990177324897
Validation loss: 2.5380634357256815

Epoch: 5| Step: 4
Training loss: 2.215255887339614
Validation loss: 2.5281742623979326

Epoch: 5| Step: 5
Training loss: 2.4164933986593384
Validation loss: 2.514532979641726

Epoch: 5| Step: 6
Training loss: 2.4275636866157977
Validation loss: 2.4984884778949836

Epoch: 5| Step: 7
Training loss: 2.741368011007888
Validation loss: 2.5027215052210714

Epoch: 5| Step: 8
Training loss: 2.8257630322042866
Validation loss: 2.5119481829818464

Epoch: 5| Step: 9
Training loss: 2.6210291665501813
Validation loss: 2.5036671802575414

Epoch: 5| Step: 10
Training loss: 1.8986734000369665
Validation loss: 2.5077710965265254

Epoch: 5| Step: 11
Training loss: 3.169921423723397
Validation loss: 2.5231279315164485

Epoch: 215| Step: 0
Training loss: 1.7803767556715686
Validation loss: 2.53159811820707

Epoch: 5| Step: 1
Training loss: 2.526801073161494
Validation loss: 2.559521661669864

Epoch: 5| Step: 2
Training loss: 2.5809490111501114
Validation loss: 2.5613564288850372

Epoch: 5| Step: 3
Training loss: 2.4510019433439125
Validation loss: 2.58655998904893

Epoch: 5| Step: 4
Training loss: 2.3628383252937666
Validation loss: 2.6004058588364978

Epoch: 5| Step: 5
Training loss: 3.0839127863860942
Validation loss: 2.5841212006950336

Epoch: 5| Step: 6
Training loss: 2.01173036442339
Validation loss: 2.559634405209584

Epoch: 5| Step: 7
Training loss: 1.6669135228766438
Validation loss: 2.5314031366249417

Epoch: 5| Step: 8
Training loss: 2.8673368409889313
Validation loss: 2.522308490718385

Epoch: 5| Step: 9
Training loss: 2.547335249615151
Validation loss: 2.514931518028064

Epoch: 5| Step: 10
Training loss: 2.385756178325739
Validation loss: 2.497720676705242

Epoch: 5| Step: 11
Training loss: 2.220341930690985
Validation loss: 2.504574571944377

Epoch: 216| Step: 0
Training loss: 2.149460649483772
Validation loss: 2.4990594127630077

Epoch: 5| Step: 1
Training loss: 2.8047828764358487
Validation loss: 2.492716475007316

Epoch: 5| Step: 2
Training loss: 2.520120525202684
Validation loss: 2.496560868406636

Epoch: 5| Step: 3
Training loss: 2.3327726530643766
Validation loss: 2.4956602059331603

Epoch: 5| Step: 4
Training loss: 2.3063137717592013
Validation loss: 2.499333908832006

Epoch: 5| Step: 5
Training loss: 1.9953025847497072
Validation loss: 2.4948630843694817

Epoch: 5| Step: 6
Training loss: 1.9374550229666434
Validation loss: 2.51094341423764

Epoch: 5| Step: 7
Training loss: 2.4609836150193187
Validation loss: 2.5216978412690034

Epoch: 5| Step: 8
Training loss: 2.9450034224744512
Validation loss: 2.552752178804265

Epoch: 5| Step: 9
Training loss: 2.359735019323076
Validation loss: 2.5505701964040846

Epoch: 5| Step: 10
Training loss: 2.4993227041219788
Validation loss: 2.5566670314667537

Epoch: 5| Step: 11
Training loss: 2.1406300120051385
Validation loss: 2.532437595371792

Epoch: 217| Step: 0
Training loss: 2.230531387652115
Validation loss: 2.533624732100297

Epoch: 5| Step: 1
Training loss: 2.1757856331306837
Validation loss: 2.552359744433343

Epoch: 5| Step: 2
Training loss: 2.1932593685460104
Validation loss: 2.533219479812223

Epoch: 5| Step: 3
Training loss: 2.7895548409983806
Validation loss: 2.546585604836347

Epoch: 5| Step: 4
Training loss: 2.1171490993043696
Validation loss: 2.5292164322127286

Epoch: 5| Step: 5
Training loss: 2.407923426167834
Validation loss: 2.53354703029076

Epoch: 5| Step: 6
Training loss: 3.0842476769230096
Validation loss: 2.5181414376210984

Epoch: 5| Step: 7
Training loss: 2.06046877166107
Validation loss: 2.519559847252971

Epoch: 5| Step: 8
Training loss: 2.6748318735212546
Validation loss: 2.513828125518474

Epoch: 5| Step: 9
Training loss: 2.0416021790992085
Validation loss: 2.519327578333715

Epoch: 5| Step: 10
Training loss: 2.0092733686739233
Validation loss: 2.517148044528748

Epoch: 5| Step: 11
Training loss: 2.2904665029525013
Validation loss: 2.5096636760107973

Epoch: 218| Step: 0
Training loss: 2.346396312836105
Validation loss: 2.5130363239871634

Epoch: 5| Step: 1
Training loss: 2.1702856382131652
Validation loss: 2.523366503902731

Epoch: 5| Step: 2
Training loss: 1.8336603855528697
Validation loss: 2.514425066560808

Epoch: 5| Step: 3
Training loss: 2.3941032686834136
Validation loss: 2.5236031484807757

Epoch: 5| Step: 4
Training loss: 2.6349518457750274
Validation loss: 2.534939326100068

Epoch: 5| Step: 5
Training loss: 2.8823092882072427
Validation loss: 2.520233170864507

Epoch: 5| Step: 6
Training loss: 2.0415358469046723
Validation loss: 2.549314944959688

Epoch: 5| Step: 7
Training loss: 2.0064652372039515
Validation loss: 2.556203510946717

Epoch: 5| Step: 8
Training loss: 2.3315089677658247
Validation loss: 2.579213184395286

Epoch: 5| Step: 9
Training loss: 2.587619845061274
Validation loss: 2.5874442198940604

Epoch: 5| Step: 10
Training loss: 2.7729263049463784
Validation loss: 2.557387734115293

Epoch: 5| Step: 11
Training loss: 2.958978412483679
Validation loss: 2.5099599839689755

Epoch: 219| Step: 0
Training loss: 1.9948334718578231
Validation loss: 2.4975166782157023

Epoch: 5| Step: 1
Training loss: 2.1142388675536896
Validation loss: 2.501298507589908

Epoch: 5| Step: 2
Training loss: 2.0073196459332796
Validation loss: 2.4971551205671267

Epoch: 5| Step: 3
Training loss: 2.518872930589017
Validation loss: 2.483639506266224

Epoch: 5| Step: 4
Training loss: 2.532548924356695
Validation loss: 2.4819628163254097

Epoch: 5| Step: 5
Training loss: 2.894723821455588
Validation loss: 2.495754616891261

Epoch: 5| Step: 6
Training loss: 3.0736013565640334
Validation loss: 2.4883268742393403

Epoch: 5| Step: 7
Training loss: 2.27507342964134
Validation loss: 2.4868900795736892

Epoch: 5| Step: 8
Training loss: 2.5386954174250276
Validation loss: 2.493901057277277

Epoch: 5| Step: 9
Training loss: 1.9977396470595141
Validation loss: 2.500616530054697

Epoch: 5| Step: 10
Training loss: 2.2476105187795365
Validation loss: 2.4949538922110737

Epoch: 5| Step: 11
Training loss: 2.6322210989035826
Validation loss: 2.499888230845291

Epoch: 220| Step: 0
Training loss: 2.4870167248404726
Validation loss: 2.5306227067651372

Epoch: 5| Step: 1
Training loss: 2.0364536243068825
Validation loss: 2.524822099323207

Epoch: 5| Step: 2
Training loss: 2.291051319621497
Validation loss: 2.541998518453387

Epoch: 5| Step: 3
Training loss: 2.37539007095609
Validation loss: 2.549160016157095

Epoch: 5| Step: 4
Training loss: 2.732061660942054
Validation loss: 2.5525282154149043

Epoch: 5| Step: 5
Training loss: 2.5464582979962262
Validation loss: 2.543479903219537

Epoch: 5| Step: 6
Training loss: 2.088729761140891
Validation loss: 2.5224512375465293

Epoch: 5| Step: 7
Training loss: 1.9728194669675723
Validation loss: 2.517818738331428

Epoch: 5| Step: 8
Training loss: 2.5275849547102442
Validation loss: 2.5087827665339817

Epoch: 5| Step: 9
Training loss: 2.326900492981133
Validation loss: 2.5165106673448805

Epoch: 5| Step: 10
Training loss: 2.7743737588094644
Validation loss: 2.506505060892039

Epoch: 5| Step: 11
Training loss: 1.8633726085602202
Validation loss: 2.5094415358942066

Epoch: 221| Step: 0
Training loss: 2.8222838721295935
Validation loss: 2.508921274136751

Epoch: 5| Step: 1
Training loss: 2.604219746366601
Validation loss: 2.52311417483544

Epoch: 5| Step: 2
Training loss: 2.257938685075461
Validation loss: 2.5206462512203087

Epoch: 5| Step: 3
Training loss: 2.439210829296451
Validation loss: 2.526743106524528

Epoch: 5| Step: 4
Training loss: 2.876530447247244
Validation loss: 2.525301228313092

Epoch: 5| Step: 5
Training loss: 2.055255767795612
Validation loss: 2.5342305574597352

Epoch: 5| Step: 6
Training loss: 2.0272066220633747
Validation loss: 2.5336784009096727

Epoch: 5| Step: 7
Training loss: 2.4921243593833426
Validation loss: 2.5289113618698678

Epoch: 5| Step: 8
Training loss: 2.5061010302175024
Validation loss: 2.5436117411162966

Epoch: 5| Step: 9
Training loss: 2.092673864946303
Validation loss: 2.5422702578106597

Epoch: 5| Step: 10
Training loss: 2.0299859442012855
Validation loss: 2.5319577157872537

Epoch: 5| Step: 11
Training loss: 1.2388241898293213
Validation loss: 2.510818112329643

Epoch: 222| Step: 0
Training loss: 2.237921614323314
Validation loss: 2.5006408108547724

Epoch: 5| Step: 1
Training loss: 2.85607436159708
Validation loss: 2.5010911864865353

Epoch: 5| Step: 2
Training loss: 2.497732373826505
Validation loss: 2.5040083381841036

Epoch: 5| Step: 3
Training loss: 2.0216665876891184
Validation loss: 2.5031524015364277

Epoch: 5| Step: 4
Training loss: 2.453387592620959
Validation loss: 2.4991102304178163

Epoch: 5| Step: 5
Training loss: 2.2703477766180304
Validation loss: 2.500667093601697

Epoch: 5| Step: 6
Training loss: 2.5072851844728103
Validation loss: 2.4993174853094198

Epoch: 5| Step: 7
Training loss: 2.4835466647417173
Validation loss: 2.5131698023994105

Epoch: 5| Step: 8
Training loss: 2.326904284067287
Validation loss: 2.519273185820891

Epoch: 5| Step: 9
Training loss: 2.2195870338420076
Validation loss: 2.5204502470115226

Epoch: 5| Step: 10
Training loss: 2.310329346401238
Validation loss: 2.54585570238674

Epoch: 5| Step: 11
Training loss: 2.3971735205135176
Validation loss: 2.5482329510448074

Epoch: 223| Step: 0
Training loss: 2.632926961069034
Validation loss: 2.5458618871603655

Epoch: 5| Step: 1
Training loss: 2.041529657347008
Validation loss: 2.521155294765113

Epoch: 5| Step: 2
Training loss: 2.916928107033837
Validation loss: 2.523448833837734

Epoch: 5| Step: 3
Training loss: 1.9443049138581578
Validation loss: 2.5175831639071977

Epoch: 5| Step: 4
Training loss: 2.2569766493887857
Validation loss: 2.5169724119748547

Epoch: 5| Step: 5
Training loss: 2.129998331203613
Validation loss: 2.511526785674082

Epoch: 5| Step: 6
Training loss: 2.5146929986949793
Validation loss: 2.5025519578286337

Epoch: 5| Step: 7
Training loss: 1.7823643461294651
Validation loss: 2.5250629036373207

Epoch: 5| Step: 8
Training loss: 2.0759628635679124
Validation loss: 2.5159682243093826

Epoch: 5| Step: 9
Training loss: 2.5071963685302143
Validation loss: 2.5258181496011414

Epoch: 5| Step: 10
Training loss: 2.5388578831314144
Validation loss: 2.519639857117459

Epoch: 5| Step: 11
Training loss: 3.978138789222714
Validation loss: 2.5219483366067856

Epoch: 224| Step: 0
Training loss: 2.591248558474635
Validation loss: 2.5590621403032303

Epoch: 5| Step: 1
Training loss: 2.3449667251926503
Validation loss: 2.598784314116039

Epoch: 5| Step: 2
Training loss: 2.4154600770620522
Validation loss: 2.6260507312352397

Epoch: 5| Step: 3
Training loss: 2.6757040861934938
Validation loss: 2.6205956506423784

Epoch: 5| Step: 4
Training loss: 3.0355700354403745
Validation loss: 2.6138424463219248

Epoch: 5| Step: 5
Training loss: 2.4089834367587257
Validation loss: 2.5832521031026974

Epoch: 5| Step: 6
Training loss: 2.4741605548862386
Validation loss: 2.5446741701333115

Epoch: 5| Step: 7
Training loss: 2.1013418315765633
Validation loss: 2.535034811582187

Epoch: 5| Step: 8
Training loss: 2.077660185953689
Validation loss: 2.5206799059801996

Epoch: 5| Step: 9
Training loss: 2.6167283295900066
Validation loss: 2.506624536599875

Epoch: 5| Step: 10
Training loss: 1.963795376550236
Validation loss: 2.4883050762734533

Epoch: 5| Step: 11
Training loss: 1.8069261150064113
Validation loss: 2.4925591162848666

Epoch: 225| Step: 0
Training loss: 2.9199973208271435
Validation loss: 2.485614243611124

Epoch: 5| Step: 1
Training loss: 2.7098437474661066
Validation loss: 2.4942565429006236

Epoch: 5| Step: 2
Training loss: 2.5106016436500127
Validation loss: 2.4844268097663464

Epoch: 5| Step: 3
Training loss: 2.325898097508026
Validation loss: 2.49808583889087

Epoch: 5| Step: 4
Training loss: 2.653207809539808
Validation loss: 2.4849654121921314

Epoch: 5| Step: 5
Training loss: 2.297896696426432
Validation loss: 2.4860540070596833

Epoch: 5| Step: 6
Training loss: 2.0245924786836564
Validation loss: 2.490743559596507

Epoch: 5| Step: 7
Training loss: 2.475587382118661
Validation loss: 2.4916917592850916

Epoch: 5| Step: 8
Training loss: 2.376759730474717
Validation loss: 2.500064769541637

Epoch: 5| Step: 9
Training loss: 1.6583317323737667
Validation loss: 2.511874485280001

Epoch: 5| Step: 10
Training loss: 2.043314158778538
Validation loss: 2.4985268742852305

Epoch: 5| Step: 11
Training loss: 3.67038518022507
Validation loss: 2.519358809925481

Epoch: 226| Step: 0
Training loss: 2.6173906389797916
Validation loss: 2.530116031314276

Epoch: 5| Step: 1
Training loss: 2.5994871183862416
Validation loss: 2.539770283961962

Epoch: 5| Step: 2
Training loss: 2.001140031146089
Validation loss: 2.5566629671578167

Epoch: 5| Step: 3
Training loss: 2.2679837280577795
Validation loss: 2.545949069408461

Epoch: 5| Step: 4
Training loss: 2.7210872732211895
Validation loss: 2.5671390124103235

Epoch: 5| Step: 5
Training loss: 2.112013911013595
Validation loss: 2.5760309673929878

Epoch: 5| Step: 6
Training loss: 2.4744465449955726
Validation loss: 2.5824243012640338

Epoch: 5| Step: 7
Training loss: 2.259105272667833
Validation loss: 2.5695170086560433

Epoch: 5| Step: 8
Training loss: 2.640176407671095
Validation loss: 2.5618604195260453

Epoch: 5| Step: 9
Training loss: 2.2384618982510904
Validation loss: 2.533555103673425

Epoch: 5| Step: 10
Training loss: 2.3460886159682524
Validation loss: 2.5284742080374283

Epoch: 5| Step: 11
Training loss: 1.464403823914025
Validation loss: 2.5102941290573666

Epoch: 227| Step: 0
Training loss: 2.1366564865385556
Validation loss: 2.510910149239173

Epoch: 5| Step: 1
Training loss: 2.079026793805889
Validation loss: 2.5267066938797416

Epoch: 5| Step: 2
Training loss: 2.655120699306712
Validation loss: 2.5265419507218208

Epoch: 5| Step: 3
Training loss: 2.8106211002349095
Validation loss: 2.526294641838023

Epoch: 5| Step: 4
Training loss: 2.2964777181197635
Validation loss: 2.5205551235641517

Epoch: 5| Step: 5
Training loss: 2.1522580110673566
Validation loss: 2.527423482007679

Epoch: 5| Step: 6
Training loss: 2.1087283803468093
Validation loss: 2.519751266611894

Epoch: 5| Step: 7
Training loss: 2.089970722084676
Validation loss: 2.5406679134959744

Epoch: 5| Step: 8
Training loss: 2.084418268626814
Validation loss: 2.54711172255821

Epoch: 5| Step: 9
Training loss: 2.647067365445585
Validation loss: 2.5618037890758534

Epoch: 5| Step: 10
Training loss: 2.8070827446494766
Validation loss: 2.5755968278730967

Epoch: 5| Step: 11
Training loss: 1.7442713023204368
Validation loss: 2.5661896295347804

Epoch: 228| Step: 0
Training loss: 2.065813235479688
Validation loss: 2.562475250868956

Epoch: 5| Step: 1
Training loss: 2.3904976405706773
Validation loss: 2.5508287628873973

Epoch: 5| Step: 2
Training loss: 3.008949124475055
Validation loss: 2.534772780246583

Epoch: 5| Step: 3
Training loss: 2.3227076643133255
Validation loss: 2.5267086302129385

Epoch: 5| Step: 4
Training loss: 2.3699992888888164
Validation loss: 2.518675232401503

Epoch: 5| Step: 5
Training loss: 2.3668858301294198
Validation loss: 2.5162830992579543

Epoch: 5| Step: 6
Training loss: 2.2189101040523753
Validation loss: 2.504097287036259

Epoch: 5| Step: 7
Training loss: 2.414198393222052
Validation loss: 2.513414351464897

Epoch: 5| Step: 8
Training loss: 2.0093482411740085
Validation loss: 2.5019350669143647

Epoch: 5| Step: 9
Training loss: 2.4140317847016948
Validation loss: 2.501314250884016

Epoch: 5| Step: 10
Training loss: 2.4996240333142827
Validation loss: 2.5122902369830586

Epoch: 5| Step: 11
Training loss: 1.9579551480409638
Validation loss: 2.516584150327862

Epoch: 229| Step: 0
Training loss: 2.1778347659385715
Validation loss: 2.5109934295964336

Epoch: 5| Step: 1
Training loss: 2.9142251467888953
Validation loss: 2.512096370710223

Epoch: 5| Step: 2
Training loss: 2.335218337998978
Validation loss: 2.507495911640195

Epoch: 5| Step: 3
Training loss: 2.648694321324868
Validation loss: 2.512353560780869

Epoch: 5| Step: 4
Training loss: 2.274103860105477
Validation loss: 2.514631011803751

Epoch: 5| Step: 5
Training loss: 1.7285867967339024
Validation loss: 2.5076935047665043

Epoch: 5| Step: 6
Training loss: 2.149274850138811
Validation loss: 2.5215521974944473

Epoch: 5| Step: 7
Training loss: 2.645030843630623
Validation loss: 2.508728264190378

Epoch: 5| Step: 8
Training loss: 2.0445875825508057
Validation loss: 2.5234847600741372

Epoch: 5| Step: 9
Training loss: 2.4805677499313563
Validation loss: 2.522043652195277

Epoch: 5| Step: 10
Training loss: 2.4280564699849028
Validation loss: 2.511442328430678

Epoch: 5| Step: 11
Training loss: 2.007067115258323
Validation loss: 2.5252700702149258

Epoch: 230| Step: 0
Training loss: 1.959551560813985
Validation loss: 2.5069066092071477

Epoch: 5| Step: 1
Training loss: 2.6321396689590695
Validation loss: 2.510701354624691

Epoch: 5| Step: 2
Training loss: 1.9459149144106935
Validation loss: 2.5137919190065396

Epoch: 5| Step: 3
Training loss: 2.155095662164405
Validation loss: 2.496542267955548

Epoch: 5| Step: 4
Training loss: 2.766401278931127
Validation loss: 2.497935778046569

Epoch: 5| Step: 5
Training loss: 2.125699545212953
Validation loss: 2.509152265475917

Epoch: 5| Step: 6
Training loss: 2.5170175240429122
Validation loss: 2.503154096144574

Epoch: 5| Step: 7
Training loss: 2.7366879517273053
Validation loss: 2.516201423173599

Epoch: 5| Step: 8
Training loss: 1.9939217592115543
Validation loss: 2.505357045275701

Epoch: 5| Step: 9
Training loss: 2.254336311128913
Validation loss: 2.506816989265838

Epoch: 5| Step: 10
Training loss: 2.3642077938998542
Validation loss: 2.5085196483418657

Epoch: 5| Step: 11
Training loss: 3.4559520351560606
Validation loss: 2.5222078246339628

Epoch: 231| Step: 0
Training loss: 2.71607199129923
Validation loss: 2.5321157411333632

Epoch: 5| Step: 1
Training loss: 1.8587944342529688
Validation loss: 2.544181185066697

Epoch: 5| Step: 2
Training loss: 2.8016213150786506
Validation loss: 2.5563402147548246

Epoch: 5| Step: 3
Training loss: 2.3623866382023357
Validation loss: 2.5677055890195675

Epoch: 5| Step: 4
Training loss: 2.5188575967756637
Validation loss: 2.574551396350628

Epoch: 5| Step: 5
Training loss: 2.379613912024447
Validation loss: 2.5607194781717877

Epoch: 5| Step: 6
Training loss: 2.469487430192184
Validation loss: 2.558632203412534

Epoch: 5| Step: 7
Training loss: 2.0703335742957463
Validation loss: 2.544213716353253

Epoch: 5| Step: 8
Training loss: 1.9320917017480363
Validation loss: 2.5522731022767724

Epoch: 5| Step: 9
Training loss: 1.8773297141475542
Validation loss: 2.5438495678984614

Epoch: 5| Step: 10
Training loss: 2.453275347919336
Validation loss: 2.5426123545617445

Epoch: 5| Step: 11
Training loss: 3.371350045478872
Validation loss: 2.532774701504174

Epoch: 232| Step: 0
Training loss: 2.479595072513416
Validation loss: 2.517453317086267

Epoch: 5| Step: 1
Training loss: 2.299356586188671
Validation loss: 2.5014229202008913

Epoch: 5| Step: 2
Training loss: 2.2711940327258593
Validation loss: 2.5123948234951374

Epoch: 5| Step: 3
Training loss: 1.596043376529151
Validation loss: 2.512939733800919

Epoch: 5| Step: 4
Training loss: 1.8727846409561797
Validation loss: 2.51974118563131

Epoch: 5| Step: 5
Training loss: 1.9493454641616146
Validation loss: 2.522171651763399

Epoch: 5| Step: 6
Training loss: 2.4703793520872446
Validation loss: 2.535931833495529

Epoch: 5| Step: 7
Training loss: 2.6557168762158048
Validation loss: 2.5433938158996336

Epoch: 5| Step: 8
Training loss: 2.771887375590019
Validation loss: 2.548569827188602

Epoch: 5| Step: 9
Training loss: 3.1644636488568683
Validation loss: 2.5494854816258545

Epoch: 5| Step: 10
Training loss: 1.9192059599541766
Validation loss: 2.574565854401921

Epoch: 5| Step: 11
Training loss: 2.0109058107904025
Validation loss: 2.568911880998372

Epoch: 233| Step: 0
Training loss: 2.4909217992672303
Validation loss: 2.5702119515800583

Epoch: 5| Step: 1
Training loss: 2.502460985060604
Validation loss: 2.576674934033023

Epoch: 5| Step: 2
Training loss: 2.0793923550458544
Validation loss: 2.5833366391458177

Epoch: 5| Step: 3
Training loss: 2.818717611257889
Validation loss: 2.597589209893748

Epoch: 5| Step: 4
Training loss: 2.17439617676276
Validation loss: 2.5754704671370052

Epoch: 5| Step: 5
Training loss: 2.3348341157136603
Validation loss: 2.555638061593302

Epoch: 5| Step: 6
Training loss: 2.545567838203587
Validation loss: 2.5515924851041114

Epoch: 5| Step: 7
Training loss: 2.7020025844660442
Validation loss: 2.5303935144304237

Epoch: 5| Step: 8
Training loss: 1.8471649355438684
Validation loss: 2.5300909811116044

Epoch: 5| Step: 9
Training loss: 2.138599300459538
Validation loss: 2.5372270219605393

Epoch: 5| Step: 10
Training loss: 2.218130213177
Validation loss: 2.5319813390024564

Epoch: 5| Step: 11
Training loss: 1.6782647783255813
Validation loss: 2.5221079974373635

Epoch: 234| Step: 0
Training loss: 2.57569382218052
Validation loss: 2.5404097870611615

Epoch: 5| Step: 1
Training loss: 2.901972586514783
Validation loss: 2.5394129623728903

Epoch: 5| Step: 2
Training loss: 2.1224199227368215
Validation loss: 2.5272256115084955

Epoch: 5| Step: 3
Training loss: 2.6631900555771915
Validation loss: 2.5328069890390035

Epoch: 5| Step: 4
Training loss: 2.2761079500674186
Validation loss: 2.5344758573031814

Epoch: 5| Step: 5
Training loss: 2.750273777598442
Validation loss: 2.5475930252972274

Epoch: 5| Step: 6
Training loss: 2.018500827020906
Validation loss: 2.53006527494829

Epoch: 5| Step: 7
Training loss: 2.091838590489158
Validation loss: 2.52669269915945

Epoch: 5| Step: 8
Training loss: 2.1994575655399866
Validation loss: 2.5453213436503086

Epoch: 5| Step: 9
Training loss: 2.531511646452666
Validation loss: 2.546429889687276

Epoch: 5| Step: 10
Training loss: 1.4331494716147029
Validation loss: 2.553630007257086

Epoch: 5| Step: 11
Training loss: 0.8773408640052294
Validation loss: 2.563997005855907

Epoch: 235| Step: 0
Training loss: 2.61286884241182
Validation loss: 2.569252058221306

Epoch: 5| Step: 1
Training loss: 2.4629349610031013
Validation loss: 2.592317285061383

Epoch: 5| Step: 2
Training loss: 2.6067149600590405
Validation loss: 2.575546763372824

Epoch: 5| Step: 3
Training loss: 2.629175226244971
Validation loss: 2.584727235535598

Epoch: 5| Step: 4
Training loss: 2.2526346252381404
Validation loss: 2.56938736797781

Epoch: 5| Step: 5
Training loss: 2.214324621219122
Validation loss: 2.555863416022281

Epoch: 5| Step: 6
Training loss: 2.4630884851877037
Validation loss: 2.557844185171706

Epoch: 5| Step: 7
Training loss: 2.2140789023298577
Validation loss: 2.5431047472550095

Epoch: 5| Step: 8
Training loss: 1.8424324241678776
Validation loss: 2.5314384201941365

Epoch: 5| Step: 9
Training loss: 2.193386767276637
Validation loss: 2.5191783017104235

Epoch: 5| Step: 10
Training loss: 2.3391624821742236
Validation loss: 2.535066043638013

Epoch: 5| Step: 11
Training loss: 2.0846132797091985
Validation loss: 2.5338882896161774

Epoch: 236| Step: 0
Training loss: 1.6125136944093197
Validation loss: 2.5231870914769554

Epoch: 5| Step: 1
Training loss: 2.566899500438052
Validation loss: 2.5223531213851857

Epoch: 5| Step: 2
Training loss: 2.43428825645007
Validation loss: 2.528789721767975

Epoch: 5| Step: 3
Training loss: 2.7163104808690415
Validation loss: 2.5270994796509663

Epoch: 5| Step: 4
Training loss: 1.9529034298149157
Validation loss: 2.535548833653233

Epoch: 5| Step: 5
Training loss: 2.495281821715033
Validation loss: 2.541964651577333

Epoch: 5| Step: 6
Training loss: 2.7325130553775656
Validation loss: 2.539110212611351

Epoch: 5| Step: 7
Training loss: 2.1952653655833023
Validation loss: 2.5250868903528323

Epoch: 5| Step: 8
Training loss: 2.124750234847814
Validation loss: 2.5414425381089543

Epoch: 5| Step: 9
Training loss: 2.1124844838311807
Validation loss: 2.5592957307761037

Epoch: 5| Step: 10
Training loss: 2.7801612694707365
Validation loss: 2.56492619292398

Epoch: 5| Step: 11
Training loss: 1.1814144201744132
Validation loss: 2.568450597344516

Epoch: 237| Step: 0
Training loss: 2.624745856198529
Validation loss: 2.581580229903321

Epoch: 5| Step: 1
Training loss: 2.1022552142714255
Validation loss: 2.569632448944861

Epoch: 5| Step: 2
Training loss: 2.0793812332082826
Validation loss: 2.564837211750058

Epoch: 5| Step: 3
Training loss: 2.1408276984038044
Validation loss: 2.5667794477364323

Epoch: 5| Step: 4
Training loss: 2.5117978191833723
Validation loss: 2.559004869506613

Epoch: 5| Step: 5
Training loss: 1.4929556741745713
Validation loss: 2.5513702460309142

Epoch: 5| Step: 6
Training loss: 1.8415148489791278
Validation loss: 2.544236550283977

Epoch: 5| Step: 7
Training loss: 2.768631674690163
Validation loss: 2.5346082850472915

Epoch: 5| Step: 8
Training loss: 2.3290061563268774
Validation loss: 2.5375246760855075

Epoch: 5| Step: 9
Training loss: 2.434489812334877
Validation loss: 2.520537265751822

Epoch: 5| Step: 10
Training loss: 3.101137223382266
Validation loss: 2.519951935573405

Epoch: 5| Step: 11
Training loss: 3.0019537603691586
Validation loss: 2.5123273983150085

Epoch: 238| Step: 0
Training loss: 2.244939517457483
Validation loss: 2.5172640671422384

Epoch: 5| Step: 1
Training loss: 2.418950536334943
Validation loss: 2.516633485160591

Epoch: 5| Step: 2
Training loss: 2.180897694640004
Validation loss: 2.541581442972756

Epoch: 5| Step: 3
Training loss: 2.202667513483884
Validation loss: 2.5503861889085107

Epoch: 5| Step: 4
Training loss: 2.176407071689306
Validation loss: 2.5613519259940016

Epoch: 5| Step: 5
Training loss: 2.2041556470435664
Validation loss: 2.557330775431271

Epoch: 5| Step: 6
Training loss: 2.6364476495468803
Validation loss: 2.567530687130812

Epoch: 5| Step: 7
Training loss: 2.749023264043067
Validation loss: 2.5931246283190656

Epoch: 5| Step: 8
Training loss: 2.2179895091655766
Validation loss: 2.587166078493182

Epoch: 5| Step: 9
Training loss: 2.024870376205793
Validation loss: 2.5959279058954254

Epoch: 5| Step: 10
Training loss: 2.4844659752653038
Validation loss: 2.582900731463772

Epoch: 5| Step: 11
Training loss: 3.184475978938609
Validation loss: 2.5695527759832215

Epoch: 239| Step: 0
Training loss: 2.689776232888884
Validation loss: 2.54412928994124

Epoch: 5| Step: 1
Training loss: 2.7524786962365546
Validation loss: 2.537201873604519

Epoch: 5| Step: 2
Training loss: 2.285990557833818
Validation loss: 2.537125694843024

Epoch: 5| Step: 3
Training loss: 2.0133512224998404
Validation loss: 2.531992567897423

Epoch: 5| Step: 4
Training loss: 1.8603946871026928
Validation loss: 2.523233921196837

Epoch: 5| Step: 5
Training loss: 2.2222666206163177
Validation loss: 2.527727690457823

Epoch: 5| Step: 6
Training loss: 1.770415499890234
Validation loss: 2.546908711871432

Epoch: 5| Step: 7
Training loss: 2.502124074773088
Validation loss: 2.5518516565121434

Epoch: 5| Step: 8
Training loss: 2.376172529198856
Validation loss: 2.5510914737070314

Epoch: 5| Step: 9
Training loss: 2.4081145159653796
Validation loss: 2.5408884887009484

Epoch: 5| Step: 10
Training loss: 2.6534133125436448
Validation loss: 2.5495315535984826

Epoch: 5| Step: 11
Training loss: 1.7085657969535535
Validation loss: 2.531636247874881

Epoch: 240| Step: 0
Training loss: 2.352921305600576
Validation loss: 2.537893928211363

Epoch: 5| Step: 1
Training loss: 2.101754899417761
Validation loss: 2.4984343235487922

Epoch: 5| Step: 2
Training loss: 2.5347207845977002
Validation loss: 2.5171968197467516

Epoch: 5| Step: 3
Training loss: 2.0435092422578762
Validation loss: 2.5214115942929327

Epoch: 5| Step: 4
Training loss: 2.3394290002434732
Validation loss: 2.508939828348045

Epoch: 5| Step: 5
Training loss: 2.4136255356451546
Validation loss: 2.5107599408889443

Epoch: 5| Step: 6
Training loss: 1.876713414917082
Validation loss: 2.5300662879653206

Epoch: 5| Step: 7
Training loss: 2.4952908987353606
Validation loss: 2.50882719433391

Epoch: 5| Step: 8
Training loss: 2.2825666834438105
Validation loss: 2.52276921748351

Epoch: 5| Step: 9
Training loss: 2.62487647356306
Validation loss: 2.5377328883257357

Epoch: 5| Step: 10
Training loss: 2.5475521942571855
Validation loss: 2.552414083781571

Epoch: 5| Step: 11
Training loss: 1.7114201391891664
Validation loss: 2.5516220078047516

Epoch: 241| Step: 0
Training loss: 2.5618190325774903
Validation loss: 2.56512947780043

Epoch: 5| Step: 1
Training loss: 3.088788301978379
Validation loss: 2.5709945330374366

Epoch: 5| Step: 2
Training loss: 2.230662749984565
Validation loss: 2.576078024218264

Epoch: 5| Step: 3
Training loss: 2.515449659977779
Validation loss: 2.5697600438636434

Epoch: 5| Step: 4
Training loss: 2.0479521501583915
Validation loss: 2.5741209205480637

Epoch: 5| Step: 5
Training loss: 2.5022545185549494
Validation loss: 2.582786084220991

Epoch: 5| Step: 6
Training loss: 2.9902321424918186
Validation loss: 2.5657352826495727

Epoch: 5| Step: 7
Training loss: 2.2773725399860623
Validation loss: 2.549118598375881

Epoch: 5| Step: 8
Training loss: 1.9499505452462762
Validation loss: 2.5498061095493947

Epoch: 5| Step: 9
Training loss: 1.6160412840526988
Validation loss: 2.536779862429324

Epoch: 5| Step: 10
Training loss: 1.5115651291656185
Validation loss: 2.5353332540028672

Epoch: 5| Step: 11
Training loss: 1.2565116552896933
Validation loss: 2.519135531318142

Epoch: 242| Step: 0
Training loss: 2.101216227426253
Validation loss: 2.5118707044326944

Epoch: 5| Step: 1
Training loss: 2.4146406845465704
Validation loss: 2.504043182580365

Epoch: 5| Step: 2
Training loss: 2.296082340405526
Validation loss: 2.503992111947734

Epoch: 5| Step: 3
Training loss: 2.3259900435991474
Validation loss: 2.5148721757135335

Epoch: 5| Step: 4
Training loss: 2.769167856068279
Validation loss: 2.495127646666302

Epoch: 5| Step: 5
Training loss: 2.2470665989281025
Validation loss: 2.5073688150245257

Epoch: 5| Step: 6
Training loss: 2.5091573846502384
Validation loss: 2.5134457691762813

Epoch: 5| Step: 7
Training loss: 1.6355411052943745
Validation loss: 2.537673813014322

Epoch: 5| Step: 8
Training loss: 1.8675072049125783
Validation loss: 2.551024613739459

Epoch: 5| Step: 9
Training loss: 2.681217568652656
Validation loss: 2.567562146826046

Epoch: 5| Step: 10
Training loss: 2.6636968009287076
Validation loss: 2.5931981123881735

Epoch: 5| Step: 11
Training loss: 2.315667225894153
Validation loss: 2.5969260506445453

Epoch: 243| Step: 0
Training loss: 2.4973483328069266
Validation loss: 2.6049421541780187

Epoch: 5| Step: 1
Training loss: 3.0958189548519632
Validation loss: 2.5947063322263277

Epoch: 5| Step: 2
Training loss: 2.4429715685070286
Validation loss: 2.601668812944145

Epoch: 5| Step: 3
Training loss: 2.5232213166879123
Validation loss: 2.629379226134706

Epoch: 5| Step: 4
Training loss: 2.240715686872878
Validation loss: 2.6064631305579593

Epoch: 5| Step: 5
Training loss: 1.9932840358842945
Validation loss: 2.583173436682098

Epoch: 5| Step: 6
Training loss: 1.6560040417267132
Validation loss: 2.5524763440472222

Epoch: 5| Step: 7
Training loss: 2.7280943319338213
Validation loss: 2.55094913399479

Epoch: 5| Step: 8
Training loss: 2.1209786455877064
Validation loss: 2.5340683007919726

Epoch: 5| Step: 9
Training loss: 2.269189805627198
Validation loss: 2.507737018958519

Epoch: 5| Step: 10
Training loss: 2.0878270195746036
Validation loss: 2.507759874055124

Epoch: 5| Step: 11
Training loss: 1.5591616253318548
Validation loss: 2.5138498128192213

Epoch: 244| Step: 0
Training loss: 2.285260059574506
Validation loss: 2.5210802033553663

Epoch: 5| Step: 1
Training loss: 2.929307266992168
Validation loss: 2.5094716059425033

Epoch: 5| Step: 2
Training loss: 2.51868342839337
Validation loss: 2.5170994578047483

Epoch: 5| Step: 3
Training loss: 2.3505791417187285
Validation loss: 2.556690181585079

Epoch: 5| Step: 4
Training loss: 1.7579489421872874
Validation loss: 2.563989047699814

Epoch: 5| Step: 5
Training loss: 2.5929895228340865
Validation loss: 2.589075276556818

Epoch: 5| Step: 6
Training loss: 2.2840967053185
Validation loss: 2.5843168022248313

Epoch: 5| Step: 7
Training loss: 2.3442900989020234
Validation loss: 2.6180318922114028

Epoch: 5| Step: 8
Training loss: 2.3733889486283
Validation loss: 2.5923021979055334

Epoch: 5| Step: 9
Training loss: 1.8872003986987267
Validation loss: 2.565214622688334

Epoch: 5| Step: 10
Training loss: 2.4585001183091437
Validation loss: 2.5629778780816603

Epoch: 5| Step: 11
Training loss: 1.2261074704272361
Validation loss: 2.530141426783815

Epoch: 245| Step: 0
Training loss: 2.14935172309928
Validation loss: 2.5323883330582286

Epoch: 5| Step: 1
Training loss: 1.9095094049726054
Validation loss: 2.5267434053250355

Epoch: 5| Step: 2
Training loss: 2.518417135729773
Validation loss: 2.531695876077537

Epoch: 5| Step: 3
Training loss: 2.4976126716255664
Validation loss: 2.5139823589429287

Epoch: 5| Step: 4
Training loss: 2.6911742355376638
Validation loss: 2.5220748343976522

Epoch: 5| Step: 5
Training loss: 2.6388157170730726
Validation loss: 2.517247563282298

Epoch: 5| Step: 6
Training loss: 1.9613093901200782
Validation loss: 2.526879446312113

Epoch: 5| Step: 7
Training loss: 1.564320305033113
Validation loss: 2.5317888981349213

Epoch: 5| Step: 8
Training loss: 2.716242455982418
Validation loss: 2.549701822524846

Epoch: 5| Step: 9
Training loss: 1.9652058019439442
Validation loss: 2.583114066098899

Epoch: 5| Step: 10
Training loss: 2.7434473865790183
Validation loss: 2.590093099137197

Epoch: 5| Step: 11
Training loss: 1.9928083462168626
Validation loss: 2.602965082795367

Epoch: 246| Step: 0
Training loss: 2.5775264160696993
Validation loss: 2.584541358805756

Epoch: 5| Step: 1
Training loss: 2.0437503873025604
Validation loss: 2.5625073231228033

Epoch: 5| Step: 2
Training loss: 2.2197362292876837
Validation loss: 2.563476574125744

Epoch: 5| Step: 3
Training loss: 2.46426205791547
Validation loss: 2.533961931206377

Epoch: 5| Step: 4
Training loss: 2.2128669218997525
Validation loss: 2.531910366683009

Epoch: 5| Step: 5
Training loss: 2.505605516783778
Validation loss: 2.5168983088133094

Epoch: 5| Step: 6
Training loss: 2.7600701360498627
Validation loss: 2.5052443195753566

Epoch: 5| Step: 7
Training loss: 2.1792230145358045
Validation loss: 2.5045162059063895

Epoch: 5| Step: 8
Training loss: 2.993389953751794
Validation loss: 2.499363075025034

Epoch: 5| Step: 9
Training loss: 1.650332333590588
Validation loss: 2.5102932287605344

Epoch: 5| Step: 10
Training loss: 1.698936491575785
Validation loss: 2.4944634005905524

Epoch: 5| Step: 11
Training loss: 3.15585007352765
Validation loss: 2.4998391139396

Epoch: 247| Step: 0
Training loss: 1.8110916322247008
Validation loss: 2.5287052203877605

Epoch: 5| Step: 1
Training loss: 2.2443991994336607
Validation loss: 2.5544226117321327

Epoch: 5| Step: 2
Training loss: 2.709620966850637
Validation loss: 2.5675777391775547

Epoch: 5| Step: 3
Training loss: 2.7085527380079406
Validation loss: 2.568677449806774

Epoch: 5| Step: 4
Training loss: 2.6764795436351756
Validation loss: 2.5972904607463483

Epoch: 5| Step: 5
Training loss: 3.099798743575361
Validation loss: 2.6006573161004596

Epoch: 5| Step: 6
Training loss: 2.036709300883696
Validation loss: 2.625893887199241

Epoch: 5| Step: 7
Training loss: 1.803014334682494
Validation loss: 2.6104085820634313

Epoch: 5| Step: 8
Training loss: 1.7363746731228968
Validation loss: 2.624703882560436

Epoch: 5| Step: 9
Training loss: 2.599040690756309
Validation loss: 2.5845036983157263

Epoch: 5| Step: 10
Training loss: 2.022264884608168
Validation loss: 2.573269056726417

Epoch: 5| Step: 11
Training loss: 1.3437019162113772
Validation loss: 2.544565050390397

Epoch: 248| Step: 0
Training loss: 2.630483621725762
Validation loss: 2.527043045133723

Epoch: 5| Step: 1
Training loss: 2.8981364214624588
Validation loss: 2.510654182330956

Epoch: 5| Step: 2
Training loss: 2.3390685056559612
Validation loss: 2.4945879529845767

Epoch: 5| Step: 3
Training loss: 2.5158768995703076
Validation loss: 2.4941941078563645

Epoch: 5| Step: 4
Training loss: 2.209466343654656
Validation loss: 2.499096925864148

Epoch: 5| Step: 5
Training loss: 2.1598747856439835
Validation loss: 2.5059727053189684

Epoch: 5| Step: 6
Training loss: 2.1045257211655466
Validation loss: 2.5033720441454657

Epoch: 5| Step: 7
Training loss: 2.0863020789044233
Validation loss: 2.495804667958336

Epoch: 5| Step: 8
Training loss: 2.21521057643494
Validation loss: 2.502754236036031

Epoch: 5| Step: 9
Training loss: 2.549521726747244
Validation loss: 2.499922266387424

Epoch: 5| Step: 10
Training loss: 2.182728822997968
Validation loss: 2.5216552416455857

Epoch: 5| Step: 11
Training loss: 1.9177692255163672
Validation loss: 2.5289880826726354

Epoch: 249| Step: 0
Training loss: 1.8006117734784093
Validation loss: 2.545931089265268

Epoch: 5| Step: 1
Training loss: 3.099373840344122
Validation loss: 2.590255301846469

Epoch: 5| Step: 2
Training loss: 2.09572735689771
Validation loss: 2.6145708772785605

Epoch: 5| Step: 3
Training loss: 2.4097951559804045
Validation loss: 2.625865331951372

Epoch: 5| Step: 4
Training loss: 2.635905998145759
Validation loss: 2.612681562861809

Epoch: 5| Step: 5
Training loss: 2.399722472675083
Validation loss: 2.6126537434423884

Epoch: 5| Step: 6
Training loss: 2.149303580758936
Validation loss: 2.56598528269494

Epoch: 5| Step: 7
Training loss: 2.233166881545421
Validation loss: 2.51753627445386

Epoch: 5| Step: 8
Training loss: 2.7737912234543276
Validation loss: 2.5263648006711543

Epoch: 5| Step: 9
Training loss: 1.5340953004819138
Validation loss: 2.4910844177315026

Epoch: 5| Step: 10
Training loss: 2.1678208309264813
Validation loss: 2.50237421705405

Epoch: 5| Step: 11
Training loss: 3.6348535198097918
Validation loss: 2.490757901878934

Epoch: 250| Step: 0
Training loss: 2.8851986652379114
Validation loss: 2.4952289394527796

Epoch: 5| Step: 1
Training loss: 2.452432133691232
Validation loss: 2.505372584636242

Epoch: 5| Step: 2
Training loss: 2.1381764016528106
Validation loss: 2.511314118235939

Epoch: 5| Step: 3
Training loss: 2.197599041543702
Validation loss: 2.513221726104473

Epoch: 5| Step: 4
Training loss: 2.243028967994713
Validation loss: 2.4983420238657583

Epoch: 5| Step: 5
Training loss: 2.900438959508873
Validation loss: 2.519547044965732

Epoch: 5| Step: 6
Training loss: 2.3621730759896016
Validation loss: 2.518890551738679

Epoch: 5| Step: 7
Training loss: 2.1318260958029813
Validation loss: 2.5447843352961845

Epoch: 5| Step: 8
Training loss: 2.129518753273714
Validation loss: 2.579043858479756

Epoch: 5| Step: 9
Training loss: 2.040187130928269
Validation loss: 2.5926503221073975

Epoch: 5| Step: 10
Training loss: 1.8685022298316216
Validation loss: 2.6274148027195308

Epoch: 5| Step: 11
Training loss: 3.2105925066051655
Validation loss: 2.6318638844324393

Epoch: 251| Step: 0
Training loss: 1.9724736195239767
Validation loss: 2.6559281098046843

Epoch: 5| Step: 1
Training loss: 2.655226566396262
Validation loss: 2.6741272318072027

Epoch: 5| Step: 2
Training loss: 2.530153201745736
Validation loss: 2.6920614603080284

Epoch: 5| Step: 3
Training loss: 2.4921094350038393
Validation loss: 2.6804620681749087

Epoch: 5| Step: 4
Training loss: 2.0698948852829715
Validation loss: 2.635704182533026

Epoch: 5| Step: 5
Training loss: 2.0371152268761827
Validation loss: 2.6035267895714096

Epoch: 5| Step: 6
Training loss: 2.7782650477807573
Validation loss: 2.586940785883573

Epoch: 5| Step: 7
Training loss: 1.772354265686441
Validation loss: 2.541206303840189

Epoch: 5| Step: 8
Training loss: 2.1038696784500144
Validation loss: 2.5415589565113406

Epoch: 5| Step: 9
Training loss: 2.4420944342572173
Validation loss: 2.5217710312845307

Epoch: 5| Step: 10
Training loss: 2.6289024409681727
Validation loss: 2.527480611579

Epoch: 5| Step: 11
Training loss: 3.2126767536624268
Validation loss: 2.5198419108328607

Epoch: 252| Step: 0
Training loss: 1.8103531586716854
Validation loss: 2.520956916512056

Epoch: 5| Step: 1
Training loss: 3.065315042705261
Validation loss: 2.520876972093995

Epoch: 5| Step: 2
Training loss: 2.3132257096085005
Validation loss: 2.5267140440747338

Epoch: 5| Step: 3
Training loss: 2.2794095283656577
Validation loss: 2.520569532688845

Epoch: 5| Step: 4
Training loss: 2.3382551758316428
Validation loss: 2.53394089041036

Epoch: 5| Step: 5
Training loss: 1.4064584365654076
Validation loss: 2.5447517195658094

Epoch: 5| Step: 6
Training loss: 2.6737284338724723
Validation loss: 2.5371697672918727

Epoch: 5| Step: 7
Training loss: 2.0772259136864433
Validation loss: 2.555138652134951

Epoch: 5| Step: 8
Training loss: 2.715052930059542
Validation loss: 2.574331799168047

Epoch: 5| Step: 9
Training loss: 2.0944167257015587
Validation loss: 2.5915268079599123

Epoch: 5| Step: 10
Training loss: 2.4162435709339385
Validation loss: 2.5915035837896827

Epoch: 5| Step: 11
Training loss: 2.7580262012191485
Validation loss: 2.5871560029325305

Epoch: 253| Step: 0
Training loss: 2.2220639477102417
Validation loss: 2.5967811047242244

Epoch: 5| Step: 1
Training loss: 2.874609547514093
Validation loss: 2.5936029844481427

Epoch: 5| Step: 2
Training loss: 1.9158292751703454
Validation loss: 2.5836654547011504

Epoch: 5| Step: 3
Training loss: 2.423756317870162
Validation loss: 2.5823240513301355

Epoch: 5| Step: 4
Training loss: 2.5963668491330534
Validation loss: 2.5648289114857596

Epoch: 5| Step: 5
Training loss: 2.0764266797060444
Validation loss: 2.5586392464123495

Epoch: 5| Step: 6
Training loss: 2.475253460168804
Validation loss: 2.542244897533244

Epoch: 5| Step: 7
Training loss: 1.9247827630267709
Validation loss: 2.5539234780436204

Epoch: 5| Step: 8
Training loss: 2.893630656012112
Validation loss: 2.551233532908662

Epoch: 5| Step: 9
Training loss: 1.674817926560283
Validation loss: 2.5511200987935925

Epoch: 5| Step: 10
Training loss: 2.3250699063528155
Validation loss: 2.5365148194673015

Epoch: 5| Step: 11
Training loss: 2.453975942958566
Validation loss: 2.547933011588703

Epoch: 254| Step: 0
Training loss: 2.363459304533461
Validation loss: 2.516689024177508

Epoch: 5| Step: 1
Training loss: 2.4257879333895453
Validation loss: 2.5137316843153115

Epoch: 5| Step: 2
Training loss: 2.037235069603113
Validation loss: 2.501831000089897

Epoch: 5| Step: 3
Training loss: 3.0184311534492205
Validation loss: 2.5089327844158693

Epoch: 5| Step: 4
Training loss: 2.5214244265118952
Validation loss: 2.4960059248508024

Epoch: 5| Step: 5
Training loss: 2.138258914182759
Validation loss: 2.5155579733755045

Epoch: 5| Step: 6
Training loss: 2.394852534235894
Validation loss: 2.5316275287609833

Epoch: 5| Step: 7
Training loss: 2.281910317366282
Validation loss: 2.5288229912019453

Epoch: 5| Step: 8
Training loss: 2.3263163870020094
Validation loss: 2.546894198230241

Epoch: 5| Step: 9
Training loss: 2.434181987275001
Validation loss: 2.568157372792456

Epoch: 5| Step: 10
Training loss: 1.832053113209096
Validation loss: 2.568159703372775

Epoch: 5| Step: 11
Training loss: 2.006128933780228
Validation loss: 2.6009412564069443

Epoch: 255| Step: 0
Training loss: 2.787704692903103
Validation loss: 2.591117675986088

Epoch: 5| Step: 1
Training loss: 2.3957217867771443
Validation loss: 2.5771821157036015

Epoch: 5| Step: 2
Training loss: 1.9604209432308672
Validation loss: 2.583388586889056

Epoch: 5| Step: 3
Training loss: 2.3573998274005254
Validation loss: 2.5539600491509553

Epoch: 5| Step: 4
Training loss: 2.2905541464970147
Validation loss: 2.5689214963970786

Epoch: 5| Step: 5
Training loss: 2.5473198063456386
Validation loss: 2.586439247281134

Epoch: 5| Step: 6
Training loss: 2.1860831985835194
Validation loss: 2.589757297428869

Epoch: 5| Step: 7
Training loss: 2.420548697287696
Validation loss: 2.5748686483825125

Epoch: 5| Step: 8
Training loss: 2.0894554847052134
Validation loss: 2.585844524206479

Epoch: 5| Step: 9
Training loss: 1.7618564458859962
Validation loss: 2.5845106977195984

Epoch: 5| Step: 10
Training loss: 2.500899534517628
Validation loss: 2.5916703324327783

Epoch: 5| Step: 11
Training loss: 2.2282020288022464
Validation loss: 2.5671497934257426

Epoch: 256| Step: 0
Training loss: 2.6090104082513297
Validation loss: 2.5515001071730814

Epoch: 5| Step: 1
Training loss: 1.7615135733140765
Validation loss: 2.538036111594801

Epoch: 5| Step: 2
Training loss: 2.5383034848090276
Validation loss: 2.511050778682107

Epoch: 5| Step: 3
Training loss: 2.65913647165811
Validation loss: 2.5058862373020294

Epoch: 5| Step: 4
Training loss: 2.445235863602917
Validation loss: 2.4964150951730435

Epoch: 5| Step: 5
Training loss: 1.9437496541013748
Validation loss: 2.4978530526246856

Epoch: 5| Step: 6
Training loss: 2.0030090822193913
Validation loss: 2.510245552140602

Epoch: 5| Step: 7
Training loss: 3.012387133498188
Validation loss: 2.504085401453081

Epoch: 5| Step: 8
Training loss: 2.0243914502174176
Validation loss: 2.513036849740071

Epoch: 5| Step: 9
Training loss: 2.2667345158388996
Validation loss: 2.530348232532551

Epoch: 5| Step: 10
Training loss: 1.7981517070846065
Validation loss: 2.5279009016731777

Epoch: 5| Step: 11
Training loss: 3.3336355231318295
Validation loss: 2.5633282931606494

Epoch: 257| Step: 0
Training loss: 2.727375772725837
Validation loss: 2.5555472021093073

Epoch: 5| Step: 1
Training loss: 2.125166942546257
Validation loss: 2.5698422134081547

Epoch: 5| Step: 2
Training loss: 2.802777503343041
Validation loss: 2.555368361896398

Epoch: 5| Step: 3
Training loss: 2.248318997906039
Validation loss: 2.573897280419897

Epoch: 5| Step: 4
Training loss: 1.9932290738991811
Validation loss: 2.5596000730784865

Epoch: 5| Step: 5
Training loss: 2.463129720192108
Validation loss: 2.5610078522299777

Epoch: 5| Step: 6
Training loss: 2.2260407489018443
Validation loss: 2.573914343472045

Epoch: 5| Step: 7
Training loss: 1.974057928976492
Validation loss: 2.5856530358627445

Epoch: 5| Step: 8
Training loss: 2.1899153317671525
Validation loss: 2.590827409868983

Epoch: 5| Step: 9
Training loss: 2.4269953590351836
Validation loss: 2.602218031750126

Epoch: 5| Step: 10
Training loss: 2.1086251515512755
Validation loss: 2.598674442684615

Epoch: 5| Step: 11
Training loss: 1.4370237473746907
Validation loss: 2.5790922065323465

Epoch: 258| Step: 0
Training loss: 2.2787614600499726
Validation loss: 2.56043679829798

Epoch: 5| Step: 1
Training loss: 2.762557575437113
Validation loss: 2.5472481850093995

Epoch: 5| Step: 2
Training loss: 2.6141340520703227
Validation loss: 2.542095206175171

Epoch: 5| Step: 3
Training loss: 2.037679853867906
Validation loss: 2.5265560779949943

Epoch: 5| Step: 4
Training loss: 2.3778259129370904
Validation loss: 2.5263065920201893

Epoch: 5| Step: 5
Training loss: 2.13916043488571
Validation loss: 2.5136853039631535

Epoch: 5| Step: 6
Training loss: 2.4840137530942785
Validation loss: 2.53785734479214

Epoch: 5| Step: 7
Training loss: 2.001983374390369
Validation loss: 2.538809905570171

Epoch: 5| Step: 8
Training loss: 2.2112266971444945
Validation loss: 2.5624845434513537

Epoch: 5| Step: 9
Training loss: 2.364679197365134
Validation loss: 2.5582007264014237

Epoch: 5| Step: 10
Training loss: 2.120002030065752
Validation loss: 2.5757684938922716

Epoch: 5| Step: 11
Training loss: 2.459573616044395
Validation loss: 2.581677257223881

Epoch: 259| Step: 0
Training loss: 2.1691887799177696
Validation loss: 2.5793033565686487

Epoch: 5| Step: 1
Training loss: 2.3506326959996717
Validation loss: 2.5512982867261558

Epoch: 5| Step: 2
Training loss: 1.3773535180137668
Validation loss: 2.5697736900039976

Epoch: 5| Step: 3
Training loss: 2.109989670099943
Validation loss: 2.5654451340489985

Epoch: 5| Step: 4
Training loss: 2.7287579198801857
Validation loss: 2.5564926372737644

Epoch: 5| Step: 5
Training loss: 2.877888596690876
Validation loss: 2.5682543057415796

Epoch: 5| Step: 6
Training loss: 2.204852245509896
Validation loss: 2.556989839744746

Epoch: 5| Step: 7
Training loss: 1.8458005849144783
Validation loss: 2.5850951790765158

Epoch: 5| Step: 8
Training loss: 2.223781093232078
Validation loss: 2.588235757713714

Epoch: 5| Step: 9
Training loss: 2.4187536983806712
Validation loss: 2.5846863031382634

Epoch: 5| Step: 10
Training loss: 2.343662412914195
Validation loss: 2.6001975991587583

Epoch: 5| Step: 11
Training loss: 2.9502353962230607
Validation loss: 2.598804753466635

Epoch: 260| Step: 0
Training loss: 2.973203350555983
Validation loss: 2.6545102050325458

Epoch: 5| Step: 1
Training loss: 2.609636944626123
Validation loss: 2.686530762744135

Epoch: 5| Step: 2
Training loss: 1.9550791005866697
Validation loss: 2.672647713955418

Epoch: 5| Step: 3
Training loss: 2.5412748587199805
Validation loss: 2.673701437267912

Epoch: 5| Step: 4
Training loss: 2.761801107384543
Validation loss: 2.6496173327438632

Epoch: 5| Step: 5
Training loss: 1.7770668568654167
Validation loss: 2.620074684726296

Epoch: 5| Step: 6
Training loss: 2.6029407413110848
Validation loss: 2.6018710979609874

Epoch: 5| Step: 7
Training loss: 2.0102982033200876
Validation loss: 2.5717826511494146

Epoch: 5| Step: 8
Training loss: 2.3208620595837828
Validation loss: 2.550464094383999

Epoch: 5| Step: 9
Training loss: 2.4273645022573036
Validation loss: 2.522437193617632

Epoch: 5| Step: 10
Training loss: 1.6468044345511548
Validation loss: 2.5141072996520992

Epoch: 5| Step: 11
Training loss: 1.204528633854121
Validation loss: 2.496463131424998

Epoch: 261| Step: 0
Training loss: 2.270712776367004
Validation loss: 2.5075124004484626

Epoch: 5| Step: 1
Training loss: 2.1947682204862757
Validation loss: 2.507832484497429

Epoch: 5| Step: 2
Training loss: 2.6733206245741794
Validation loss: 2.5036864558660006

Epoch: 5| Step: 3
Training loss: 2.493565575991295
Validation loss: 2.50317847535681

Epoch: 5| Step: 4
Training loss: 2.551056220523373
Validation loss: 2.521081732236725

Epoch: 5| Step: 5
Training loss: 2.282136405238091
Validation loss: 2.5369020983782224

Epoch: 5| Step: 6
Training loss: 2.6792957253070595
Validation loss: 2.5728447604202285

Epoch: 5| Step: 7
Training loss: 2.2527020442330037
Validation loss: 2.59277854483102

Epoch: 5| Step: 8
Training loss: 2.085305221684401
Validation loss: 2.60757826051583

Epoch: 5| Step: 9
Training loss: 2.128970867891185
Validation loss: 2.6268083799586535

Epoch: 5| Step: 10
Training loss: 2.3493635979751457
Validation loss: 2.617697181227569

Epoch: 5| Step: 11
Training loss: 2.030905826460732
Validation loss: 2.6068538661439438

Epoch: 262| Step: 0
Training loss: 2.9581229085812084
Validation loss: 2.5871515948624064

Epoch: 5| Step: 1
Training loss: 1.4030390213959454
Validation loss: 2.556834979692503

Epoch: 5| Step: 2
Training loss: 2.2205485186946383
Validation loss: 2.568919286386043

Epoch: 5| Step: 3
Training loss: 2.351074370862534
Validation loss: 2.5493443576498396

Epoch: 5| Step: 4
Training loss: 2.7354408148817972
Validation loss: 2.5454649464115557

Epoch: 5| Step: 5
Training loss: 2.4435904292231574
Validation loss: 2.5434043948646123

Epoch: 5| Step: 6
Training loss: 1.8474714577913012
Validation loss: 2.543925369584788

Epoch: 5| Step: 7
Training loss: 2.140528433076477
Validation loss: 2.5367690698261454

Epoch: 5| Step: 8
Training loss: 2.455701410508212
Validation loss: 2.5342713326584296

Epoch: 5| Step: 9
Training loss: 1.8494080833783972
Validation loss: 2.580082029214081

Epoch: 5| Step: 10
Training loss: 2.1338950962284353
Validation loss: 2.573327666183352

Epoch: 5| Step: 11
Training loss: 3.0541317329299735
Validation loss: 2.5721877619014393

Epoch: 263| Step: 0
Training loss: 2.059067036549475
Validation loss: 2.583148435672014

Epoch: 5| Step: 1
Training loss: 1.6245279360054294
Validation loss: 2.5841328603958056

Epoch: 5| Step: 2
Training loss: 2.6767700150499407
Validation loss: 2.612821594625169

Epoch: 5| Step: 3
Training loss: 1.9345852246159874
Validation loss: 2.615728987248839

Epoch: 5| Step: 4
Training loss: 1.8253933965921942
Validation loss: 2.6274244753009635

Epoch: 5| Step: 5
Training loss: 2.0810238689573377
Validation loss: 2.6411578188226597

Epoch: 5| Step: 6
Training loss: 2.6234704965830375
Validation loss: 2.6010781563758347

Epoch: 5| Step: 7
Training loss: 3.185195089500596
Validation loss: 2.592460951619865

Epoch: 5| Step: 8
Training loss: 3.0181199263298786
Validation loss: 2.572586244274929

Epoch: 5| Step: 9
Training loss: 2.000196804854011
Validation loss: 2.549364047752123

Epoch: 5| Step: 10
Training loss: 1.6288094983537793
Validation loss: 2.5443637418361225

Epoch: 5| Step: 11
Training loss: 2.0158447618963473
Validation loss: 2.5137671052707065

Epoch: 264| Step: 0
Training loss: 2.434951232171141
Validation loss: 2.5124460554578976

Epoch: 5| Step: 1
Training loss: 2.4553453638363973
Validation loss: 2.519354813580911

Epoch: 5| Step: 2
Training loss: 1.9979240252929777
Validation loss: 2.5043879108684814

Epoch: 5| Step: 3
Training loss: 2.2481814558774
Validation loss: 2.4938131808003106

Epoch: 5| Step: 4
Training loss: 2.3534707472705194
Validation loss: 2.488784315995749

Epoch: 5| Step: 5
Training loss: 1.8382159440761208
Validation loss: 2.490237753872044

Epoch: 5| Step: 6
Training loss: 3.0094097701903264
Validation loss: 2.4873231094091524

Epoch: 5| Step: 7
Training loss: 2.7828656765003235
Validation loss: 2.5013539065477106

Epoch: 5| Step: 8
Training loss: 1.8649672711443424
Validation loss: 2.508830334343834

Epoch: 5| Step: 9
Training loss: 2.383635532009201
Validation loss: 2.5185432251394158

Epoch: 5| Step: 10
Training loss: 1.9899830907553737
Validation loss: 2.5249818695789727

Epoch: 5| Step: 11
Training loss: 3.4045515112921985
Validation loss: 2.5544613340476343

Epoch: 265| Step: 0
Training loss: 2.668969253002762
Validation loss: 2.563847160556581

Epoch: 5| Step: 1
Training loss: 2.1288754522213265
Validation loss: 2.5747405214649763

Epoch: 5| Step: 2
Training loss: 2.076270172002776
Validation loss: 2.577657938563541

Epoch: 5| Step: 3
Training loss: 2.097459723503059
Validation loss: 2.5813802686244705

Epoch: 5| Step: 4
Training loss: 1.83056686210067
Validation loss: 2.581168003026837

Epoch: 5| Step: 5
Training loss: 1.6391579744735256
Validation loss: 2.592858222489931

Epoch: 5| Step: 6
Training loss: 2.21716176529534
Validation loss: 2.6113067717381733

Epoch: 5| Step: 7
Training loss: 2.702896549515955
Validation loss: 2.6118136905321574

Epoch: 5| Step: 8
Training loss: 2.5247994635991153
Validation loss: 2.594988347310956

Epoch: 5| Step: 9
Training loss: 2.8056854767717407
Validation loss: 2.603421590394173

Epoch: 5| Step: 10
Training loss: 1.9213150573318343
Validation loss: 2.5881090333530996

Epoch: 5| Step: 11
Training loss: 2.7942982317081064
Validation loss: 2.585514533418928

Epoch: 266| Step: 0
Training loss: 3.1341180150269867
Validation loss: 2.586228910316851

Epoch: 5| Step: 1
Training loss: 2.400175974275431
Validation loss: 2.5917919535471596

Epoch: 5| Step: 2
Training loss: 1.787347029429436
Validation loss: 2.6202463105648324

Epoch: 5| Step: 3
Training loss: 1.6234583510968095
Validation loss: 2.6227589002029235

Epoch: 5| Step: 4
Training loss: 2.2431377032354187
Validation loss: 2.6285037091036543

Epoch: 5| Step: 5
Training loss: 2.289052188576658
Validation loss: 2.621391775941617

Epoch: 5| Step: 6
Training loss: 2.5790387008384275
Validation loss: 2.5764511107454084

Epoch: 5| Step: 7
Training loss: 2.551535805856327
Validation loss: 2.5563029063034284

Epoch: 5| Step: 8
Training loss: 2.154813094209747
Validation loss: 2.554707580549704

Epoch: 5| Step: 9
Training loss: 1.8173575586596755
Validation loss: 2.51772793052116

Epoch: 5| Step: 10
Training loss: 2.0924236594508967
Validation loss: 2.5048643829084147

Epoch: 5| Step: 11
Training loss: 3.332801363139943
Validation loss: 2.5119822686735347

Epoch: 267| Step: 0
Training loss: 1.7344176828441937
Validation loss: 2.4969739680277017

Epoch: 5| Step: 1
Training loss: 2.1679161821470267
Validation loss: 2.5127057479165296

Epoch: 5| Step: 2
Training loss: 2.3117695247518273
Validation loss: 2.503020734516442

Epoch: 5| Step: 3
Training loss: 2.345281380403081
Validation loss: 2.504495096223569

Epoch: 5| Step: 4
Training loss: 2.371081482605725
Validation loss: 2.5151624392512124

Epoch: 5| Step: 5
Training loss: 2.7126161506501103
Validation loss: 2.5184753886697737

Epoch: 5| Step: 6
Training loss: 2.127647321645478
Validation loss: 2.5284405450484733

Epoch: 5| Step: 7
Training loss: 2.3292942055420305
Validation loss: 2.5449358104637527

Epoch: 5| Step: 8
Training loss: 2.09962345562139
Validation loss: 2.571083532943061

Epoch: 5| Step: 9
Training loss: 2.064207583922684
Validation loss: 2.574272610569299

Epoch: 5| Step: 10
Training loss: 2.764565302529619
Validation loss: 2.5946873154721106

Epoch: 5| Step: 11
Training loss: 2.7586385122085204
Validation loss: 2.598519035217764

Epoch: 268| Step: 0
Training loss: 1.9906679828500624
Validation loss: 2.618408582519883

Epoch: 5| Step: 1
Training loss: 2.7476930478614445
Validation loss: 2.635901076135464

Epoch: 5| Step: 2
Training loss: 2.3806241351882433
Validation loss: 2.631617266288145

Epoch: 5| Step: 3
Training loss: 2.263656602993943
Validation loss: 2.644820538864409

Epoch: 5| Step: 4
Training loss: 2.483883791172469
Validation loss: 2.6333223635911818

Epoch: 5| Step: 5
Training loss: 2.0450377627292777
Validation loss: 2.6255306017955715

Epoch: 5| Step: 6
Training loss: 1.6462111783790652
Validation loss: 2.6213834501091506

Epoch: 5| Step: 7
Training loss: 1.8009963827652855
Validation loss: 2.6188790657509937

Epoch: 5| Step: 8
Training loss: 1.9742919183719956
Validation loss: 2.6048313106508103

Epoch: 5| Step: 9
Training loss: 2.7219640215781005
Validation loss: 2.5914703293748693

Epoch: 5| Step: 10
Training loss: 2.4916052063301333
Validation loss: 2.570934118065635

Epoch: 5| Step: 11
Training loss: 2.661914395687713
Validation loss: 2.5621029538466087

Epoch: 269| Step: 0
Training loss: 2.1703863736921125
Validation loss: 2.547790569502842

Epoch: 5| Step: 1
Training loss: 2.3651156281478665
Validation loss: 2.562244290099635

Epoch: 5| Step: 2
Training loss: 3.0302377170691153
Validation loss: 2.5593769806298

Epoch: 5| Step: 3
Training loss: 1.805930828155429
Validation loss: 2.605107157950554

Epoch: 5| Step: 4
Training loss: 2.1173515678544628
Validation loss: 2.5999889063292807

Epoch: 5| Step: 5
Training loss: 2.364333443454188
Validation loss: 2.5971499109713205

Epoch: 5| Step: 6
Training loss: 2.1477440287058878
Validation loss: 2.617650570872868

Epoch: 5| Step: 7
Training loss: 1.653655917720133
Validation loss: 2.611362998195049

Epoch: 5| Step: 8
Training loss: 1.979012640598015
Validation loss: 2.5959088674753885

Epoch: 5| Step: 9
Training loss: 2.8873247431954128
Validation loss: 2.571969156407357

Epoch: 5| Step: 10
Training loss: 2.3144033692238812
Validation loss: 2.581248951188953

Epoch: 5| Step: 11
Training loss: 1.4387747047086363
Validation loss: 2.568734504949981

Epoch: 270| Step: 0
Training loss: 2.250389489264815
Validation loss: 2.573909152394865

Epoch: 5| Step: 1
Training loss: 2.118692686492919
Validation loss: 2.5500694438416907

Epoch: 5| Step: 2
Training loss: 1.9793842062270797
Validation loss: 2.561423354642387

Epoch: 5| Step: 3
Training loss: 2.4527807297862245
Validation loss: 2.582368871917832

Epoch: 5| Step: 4
Training loss: 2.825872377714428
Validation loss: 2.5529868855466398

Epoch: 5| Step: 5
Training loss: 2.5287801678715875
Validation loss: 2.5889113000473656

Epoch: 5| Step: 6
Training loss: 2.2048240224634115
Validation loss: 2.574037638126564

Epoch: 5| Step: 7
Training loss: 2.5047854399020024
Validation loss: 2.580851119259043

Epoch: 5| Step: 8
Training loss: 1.6692359273973487
Validation loss: 2.5638953883427487

Epoch: 5| Step: 9
Training loss: 1.5918623273065735
Validation loss: 2.543609934816122

Epoch: 5| Step: 10
Training loss: 2.596977891042768
Validation loss: 2.5461494840015657

Epoch: 5| Step: 11
Training loss: 2.119250429182874
Validation loss: 2.5589769459861498

Epoch: 271| Step: 0
Training loss: 1.6090173416483422
Validation loss: 2.575823577403493

Epoch: 5| Step: 1
Training loss: 2.092423431563403
Validation loss: 2.57888116247499

Epoch: 5| Step: 2
Training loss: 2.3019343079076697
Validation loss: 2.5851400707449876

Epoch: 5| Step: 3
Training loss: 1.5816824069243172
Validation loss: 2.593773462580075

Epoch: 5| Step: 4
Training loss: 2.4203784872064507
Validation loss: 2.6074773203923214

Epoch: 5| Step: 5
Training loss: 1.4237187766116977
Validation loss: 2.6004916212316957

Epoch: 5| Step: 6
Training loss: 2.752735078285661
Validation loss: 2.6052496807036087

Epoch: 5| Step: 7
Training loss: 3.005054031368706
Validation loss: 2.601668167641268

Epoch: 5| Step: 8
Training loss: 2.801056788469785
Validation loss: 2.6194520367406384

Epoch: 5| Step: 9
Training loss: 2.52437543415199
Validation loss: 2.591170564210785

Epoch: 5| Step: 10
Training loss: 1.7484685463829281
Validation loss: 2.584527306333546

Epoch: 5| Step: 11
Training loss: 1.5041674102330505
Validation loss: 2.577605775123619

Epoch: 272| Step: 0
Training loss: 2.558119309095385
Validation loss: 2.604675683183721

Epoch: 5| Step: 1
Training loss: 1.8403823614892403
Validation loss: 2.6198784047222086

Epoch: 5| Step: 2
Training loss: 1.9976065738783688
Validation loss: 2.601245070328594

Epoch: 5| Step: 3
Training loss: 2.1923431188987426
Validation loss: 2.600715953877732

Epoch: 5| Step: 4
Training loss: 2.008297160391369
Validation loss: 2.6082385685548113

Epoch: 5| Step: 5
Training loss: 2.483256922150072
Validation loss: 2.606832556258987

Epoch: 5| Step: 6
Training loss: 2.00558193408999
Validation loss: 2.6089660339274316

Epoch: 5| Step: 7
Training loss: 2.212406708210631
Validation loss: 2.6016269213821284

Epoch: 5| Step: 8
Training loss: 1.6797315724823034
Validation loss: 2.5911443100098905

Epoch: 5| Step: 9
Training loss: 1.983654942870117
Validation loss: 2.5773575189505387

Epoch: 5| Step: 10
Training loss: 3.0946510621115313
Validation loss: 2.5821645051136284

Epoch: 5| Step: 11
Training loss: 3.126664900735168
Validation loss: 2.5657016013229694

Epoch: 273| Step: 0
Training loss: 2.3192853612906643
Validation loss: 2.582973150682953

Epoch: 5| Step: 1
Training loss: 1.7021950799063463
Validation loss: 2.5740250672340226

Epoch: 5| Step: 2
Training loss: 2.324689442392372
Validation loss: 2.583381922839162

Epoch: 5| Step: 3
Training loss: 2.4307797053082627
Validation loss: 2.5883926461279745

Epoch: 5| Step: 4
Training loss: 2.3252658568939633
Validation loss: 2.562072446866889

Epoch: 5| Step: 5
Training loss: 2.71986690686481
Validation loss: 2.571896861876856

Epoch: 5| Step: 6
Training loss: 1.7249899214298106
Validation loss: 2.5783512594178926

Epoch: 5| Step: 7
Training loss: 2.2688787838873457
Validation loss: 2.578681696888499

Epoch: 5| Step: 8
Training loss: 2.269613504150307
Validation loss: 2.5575066817274967

Epoch: 5| Step: 9
Training loss: 2.634665994195556
Validation loss: 2.5472378969547993

Epoch: 5| Step: 10
Training loss: 2.1793100994260657
Validation loss: 2.5345474240954764

Epoch: 5| Step: 11
Training loss: 1.0050915203840094
Validation loss: 2.535105465231897

Epoch: 274| Step: 0
Training loss: 2.05969324735344
Validation loss: 2.5355067743062825

Epoch: 5| Step: 1
Training loss: 2.595061097206785
Validation loss: 2.5398031044724036

Epoch: 5| Step: 2
Training loss: 1.7302467083182438
Validation loss: 2.5245733785131326

Epoch: 5| Step: 3
Training loss: 2.5103747626852844
Validation loss: 2.528555566268056

Epoch: 5| Step: 4
Training loss: 2.5313099983545624
Validation loss: 2.551383274104263

Epoch: 5| Step: 5
Training loss: 2.275716157474044
Validation loss: 2.554817414164249

Epoch: 5| Step: 6
Training loss: 2.9247691462782144
Validation loss: 2.6133925181879274

Epoch: 5| Step: 7
Training loss: 1.9649666658636533
Validation loss: 2.66439117015108

Epoch: 5| Step: 8
Training loss: 2.228481068456055
Validation loss: 2.680806826117651

Epoch: 5| Step: 9
Training loss: 2.007152641904764
Validation loss: 2.6652641494879195

Epoch: 5| Step: 10
Training loss: 2.624330707784055
Validation loss: 2.639264442813611

Epoch: 5| Step: 11
Training loss: 1.290970055588182
Validation loss: 2.5898336158120716

Epoch: 275| Step: 0
Training loss: 2.2772859595476223
Validation loss: 2.5608793343995964

Epoch: 5| Step: 1
Training loss: 2.20618977667119
Validation loss: 2.532940986538719

Epoch: 5| Step: 2
Training loss: 1.9106329886606686
Validation loss: 2.5299887438726008

Epoch: 5| Step: 3
Training loss: 2.650166265202116
Validation loss: 2.533680475024799

Epoch: 5| Step: 4
Training loss: 2.7997222558278585
Validation loss: 2.5281080164454814

Epoch: 5| Step: 5
Training loss: 2.2712630002495287
Validation loss: 2.5254081023305526

Epoch: 5| Step: 6
Training loss: 1.7931600231793696
Validation loss: 2.5617700521814113

Epoch: 5| Step: 7
Training loss: 1.8073921578765124
Validation loss: 2.5698070860174504

Epoch: 5| Step: 8
Training loss: 2.123174444189404
Validation loss: 2.587478416770567

Epoch: 5| Step: 9
Training loss: 2.2154892076811854
Validation loss: 2.590376368127323

Epoch: 5| Step: 10
Training loss: 2.7586226961728726
Validation loss: 2.586550629334177

Epoch: 5| Step: 11
Training loss: 2.3888103105006984
Validation loss: 2.5862074765802148

Epoch: 276| Step: 0
Training loss: 1.5334710342661675
Validation loss: 2.5850242315886898

Epoch: 5| Step: 1
Training loss: 2.3030507628278865
Validation loss: 2.565889756531244

Epoch: 5| Step: 2
Training loss: 2.5726222643329133
Validation loss: 2.5373799388024407

Epoch: 5| Step: 3
Training loss: 1.9720378246277872
Validation loss: 2.5289465387902457

Epoch: 5| Step: 4
Training loss: 2.8932890292114224
Validation loss: 2.529039512707982

Epoch: 5| Step: 5
Training loss: 2.332146876550122
Validation loss: 2.521846186817169

Epoch: 5| Step: 6
Training loss: 2.197608588685374
Validation loss: 2.522433420726045

Epoch: 5| Step: 7
Training loss: 1.701270537466158
Validation loss: 2.520831972442344

Epoch: 5| Step: 8
Training loss: 2.2191053294024097
Validation loss: 2.5215929295116584

Epoch: 5| Step: 9
Training loss: 2.205274358621996
Validation loss: 2.5337006240434943

Epoch: 5| Step: 10
Training loss: 2.6691938187568627
Validation loss: 2.5702150165967454

Epoch: 5| Step: 11
Training loss: 2.2766190646860838
Validation loss: 2.5819089728799556

Epoch: 277| Step: 0
Training loss: 2.2451168689171697
Validation loss: 2.602634136665339

Epoch: 5| Step: 1
Training loss: 2.398563145629945
Validation loss: 2.6181185911793303

Epoch: 5| Step: 2
Training loss: 1.8855986814650472
Validation loss: 2.635905466749991

Epoch: 5| Step: 3
Training loss: 1.9565505848015918
Validation loss: 2.6200248710529284

Epoch: 5| Step: 4
Training loss: 2.754763379190596
Validation loss: 2.5945712057266896

Epoch: 5| Step: 5
Training loss: 2.620169145351163
Validation loss: 2.607547847452663

Epoch: 5| Step: 6
Training loss: 2.3102387378402844
Validation loss: 2.583635290761839

Epoch: 5| Step: 7
Training loss: 1.8573100701185359
Validation loss: 2.5736582391347538

Epoch: 5| Step: 8
Training loss: 2.0908618194151862
Validation loss: 2.5715151932579245

Epoch: 5| Step: 9
Training loss: 1.93379694323778
Validation loss: 2.552675716910214

Epoch: 5| Step: 10
Training loss: 2.474376399537741
Validation loss: 2.5543953809243205

Epoch: 5| Step: 11
Training loss: 2.608206481611495
Validation loss: 2.5587501264546333

Epoch: 278| Step: 0
Training loss: 2.1298219163979057
Validation loss: 2.5427556102399373

Epoch: 5| Step: 1
Training loss: 2.590479247775264
Validation loss: 2.531595132006305

Epoch: 5| Step: 2
Training loss: 2.3171965873473193
Validation loss: 2.5311196729287575

Epoch: 5| Step: 3
Training loss: 2.185117241269507
Validation loss: 2.526064832653251

Epoch: 5| Step: 4
Training loss: 2.6803254460825694
Validation loss: 2.5425514507745492

Epoch: 5| Step: 5
Training loss: 2.505286444849341
Validation loss: 2.546128563429783

Epoch: 5| Step: 6
Training loss: 2.0729910167861965
Validation loss: 2.55429813400341

Epoch: 5| Step: 7
Training loss: 2.333874253743675
Validation loss: 2.556918667992521

Epoch: 5| Step: 8
Training loss: 2.1801640252867536
Validation loss: 2.581734613797223

Epoch: 5| Step: 9
Training loss: 1.493697595674646
Validation loss: 2.588035270439277

Epoch: 5| Step: 10
Training loss: 2.339581864974483
Validation loss: 2.615082392361012

Epoch: 5| Step: 11
Training loss: 2.680764918696976
Validation loss: 2.597739625132946

Epoch: 279| Step: 0
Training loss: 2.3826713144968243
Validation loss: 2.602258178745483

Epoch: 5| Step: 1
Training loss: 1.7756206501924594
Validation loss: 2.5917796690388184

Epoch: 5| Step: 2
Training loss: 2.628045177721692
Validation loss: 2.5847895053442387

Epoch: 5| Step: 3
Training loss: 2.6952386376031994
Validation loss: 2.584846566108849

Epoch: 5| Step: 4
Training loss: 2.5215489551361467
Validation loss: 2.5754131349906495

Epoch: 5| Step: 5
Training loss: 1.6623068847928582
Validation loss: 2.56973114898536

Epoch: 5| Step: 6
Training loss: 2.228710115924176
Validation loss: 2.5546449585774083

Epoch: 5| Step: 7
Training loss: 2.1265136713144144
Validation loss: 2.5509393164987175

Epoch: 5| Step: 8
Training loss: 2.083200552205776
Validation loss: 2.535671485460354

Epoch: 5| Step: 9
Training loss: 2.2145675137069345
Validation loss: 2.5403006835805333

Epoch: 5| Step: 10
Training loss: 2.1341943980000018
Validation loss: 2.5678362953123726

Epoch: 5| Step: 11
Training loss: 2.241457085815767
Validation loss: 2.5728926844129107

Epoch: 280| Step: 0
Training loss: 2.5273595983370947
Validation loss: 2.5778060137763883

Epoch: 5| Step: 1
Training loss: 2.2826000033779774
Validation loss: 2.5877001345600066

Epoch: 5| Step: 2
Training loss: 2.466756861128853
Validation loss: 2.5984513330387675

Epoch: 5| Step: 3
Training loss: 2.6135753699864117
Validation loss: 2.610742876677704

Epoch: 5| Step: 4
Training loss: 1.7405802065223897
Validation loss: 2.5963811436166417

Epoch: 5| Step: 5
Training loss: 2.5889463869439657
Validation loss: 2.628271845413

Epoch: 5| Step: 6
Training loss: 1.9259046781962732
Validation loss: 2.6386135912787156

Epoch: 5| Step: 7
Training loss: 1.7476991787149772
Validation loss: 2.695257409311356

Epoch: 5| Step: 8
Training loss: 2.5403202638942703
Validation loss: 2.6884280568864947

Epoch: 5| Step: 9
Training loss: 2.2622767470000413
Validation loss: 2.660893140726618

Epoch: 5| Step: 10
Training loss: 1.982863083022114
Validation loss: 2.578189163180222

Epoch: 5| Step: 11
Training loss: 2.6641056359342254
Validation loss: 2.5500101556762718

Epoch: 281| Step: 0
Training loss: 1.2991590035395846
Validation loss: 2.5340481860588078

Epoch: 5| Step: 1
Training loss: 2.1076764084731967
Validation loss: 2.533018954015238

Epoch: 5| Step: 2
Training loss: 2.1976950535228514
Validation loss: 2.521259883911045

Epoch: 5| Step: 3
Training loss: 2.2787428364769293
Validation loss: 2.534531260109187

Epoch: 5| Step: 4
Training loss: 2.4221818298895563
Validation loss: 2.523551412792581

Epoch: 5| Step: 5
Training loss: 2.0411693460353395
Validation loss: 2.5511322325246755

Epoch: 5| Step: 6
Training loss: 2.571293605940963
Validation loss: 2.567654596866489

Epoch: 5| Step: 7
Training loss: 1.9110357525972868
Validation loss: 2.5872095154600703

Epoch: 5| Step: 8
Training loss: 2.7213872636793197
Validation loss: 2.5837540796620186

Epoch: 5| Step: 9
Training loss: 2.984776175332666
Validation loss: 2.6086554191819538

Epoch: 5| Step: 10
Training loss: 2.0171781957812147
Validation loss: 2.5966264906502365

Epoch: 5| Step: 11
Training loss: 1.8255813378190089
Validation loss: 2.5990478994547948

Epoch: 282| Step: 0
Training loss: 2.193921609018831
Validation loss: 2.588919081827937

Epoch: 5| Step: 1
Training loss: 2.2370668215706844
Validation loss: 2.5840509645892937

Epoch: 5| Step: 2
Training loss: 1.529984710467368
Validation loss: 2.5887703068623034

Epoch: 5| Step: 3
Training loss: 2.19526503976584
Validation loss: 2.581053936972998

Epoch: 5| Step: 4
Training loss: 2.122238721278545
Validation loss: 2.582975860186548

Epoch: 5| Step: 5
Training loss: 2.314899333965
Validation loss: 2.572646382970623

Epoch: 5| Step: 6
Training loss: 2.2727248920081413
Validation loss: 2.564234239776578

Epoch: 5| Step: 7
Training loss: 2.6538142087538343
Validation loss: 2.566839052940446

Epoch: 5| Step: 8
Training loss: 2.4691738296011794
Validation loss: 2.570773882361402

Epoch: 5| Step: 9
Training loss: 1.577991064450066
Validation loss: 2.550767151743478

Epoch: 5| Step: 10
Training loss: 2.248701356591776
Validation loss: 2.5638678551809093

Epoch: 5| Step: 11
Training loss: 3.5556857876636485
Validation loss: 2.573058233858113

Epoch: 283| Step: 0
Training loss: 2.387537739240749
Validation loss: 2.5628273529985526

Epoch: 5| Step: 1
Training loss: 2.4514057914095932
Validation loss: 2.5646551265217283

Epoch: 5| Step: 2
Training loss: 1.855155388320958
Validation loss: 2.561808097284061

Epoch: 5| Step: 3
Training loss: 1.768522804684833
Validation loss: 2.57127228724282

Epoch: 5| Step: 4
Training loss: 1.9261591851909738
Validation loss: 2.5630749933486405

Epoch: 5| Step: 5
Training loss: 2.013661574181037
Validation loss: 2.561046676682561

Epoch: 5| Step: 6
Training loss: 2.4408205352096903
Validation loss: 2.5496953158892524

Epoch: 5| Step: 7
Training loss: 2.3136250620145407
Validation loss: 2.5679906466790077

Epoch: 5| Step: 8
Training loss: 2.30860676253471
Validation loss: 2.571660979934836

Epoch: 5| Step: 9
Training loss: 1.973977067870227
Validation loss: 2.5603389738031765

Epoch: 5| Step: 10
Training loss: 2.5999452071651876
Validation loss: 2.606063164921614

Epoch: 5| Step: 11
Training loss: 3.6415755050271135
Validation loss: 2.6313298802245213

Epoch: 284| Step: 0
Training loss: 1.5742775880026763
Validation loss: 2.651984593565308

Epoch: 5| Step: 1
Training loss: 2.0370664217142824
Validation loss: 2.662496958836832

Epoch: 5| Step: 2
Training loss: 2.1409089951182927
Validation loss: 2.6379068782453867

Epoch: 5| Step: 3
Training loss: 2.176215137112608
Validation loss: 2.6111875223726666

Epoch: 5| Step: 4
Training loss: 1.628202656890947
Validation loss: 2.5840178603090456

Epoch: 5| Step: 5
Training loss: 2.531777691879248
Validation loss: 2.576934994494096

Epoch: 5| Step: 6
Training loss: 2.502928925453454
Validation loss: 2.551757376478946

Epoch: 5| Step: 7
Training loss: 2.4829679139207697
Validation loss: 2.5629691725663126

Epoch: 5| Step: 8
Training loss: 2.1578401976733748
Validation loss: 2.5793549695911397

Epoch: 5| Step: 9
Training loss: 2.17238374967529
Validation loss: 2.577020393092287

Epoch: 5| Step: 10
Training loss: 2.702690133632611
Validation loss: 2.582221750839148

Epoch: 5| Step: 11
Training loss: 3.5344801451189727
Validation loss: 2.620533306696004

Epoch: 285| Step: 0
Training loss: 2.457887145677407
Validation loss: 2.6433441262387625

Epoch: 5| Step: 1
Training loss: 1.7030882525198074
Validation loss: 2.6466252250773987

Epoch: 5| Step: 2
Training loss: 1.8736557274248942
Validation loss: 2.6650184974422104

Epoch: 5| Step: 3
Training loss: 2.0651661373299173
Validation loss: 2.6713950412057916

Epoch: 5| Step: 4
Training loss: 1.8197053215913774
Validation loss: 2.661916429594779

Epoch: 5| Step: 5
Training loss: 2.1833593143732437
Validation loss: 2.6433305667663887

Epoch: 5| Step: 6
Training loss: 2.3404406771640196
Validation loss: 2.635186359962205

Epoch: 5| Step: 7
Training loss: 2.902702709811222
Validation loss: 2.5842844855353486

Epoch: 5| Step: 8
Training loss: 1.949816228080986
Validation loss: 2.5879785333253618

Epoch: 5| Step: 9
Training loss: 2.722383548428365
Validation loss: 2.5807324758149814

Epoch: 5| Step: 10
Training loss: 2.2277837248501102
Validation loss: 2.5713556061085754

Epoch: 5| Step: 11
Training loss: 1.4134549263540503
Validation loss: 2.5819431468804637

Epoch: 286| Step: 0
Training loss: 1.6898016597675087
Validation loss: 2.568680802841835

Epoch: 5| Step: 1
Training loss: 2.6261928209691985
Validation loss: 2.568817053412389

Epoch: 5| Step: 2
Training loss: 2.4407223651528502
Validation loss: 2.581144193015554

Epoch: 5| Step: 3
Training loss: 2.3900295338741167
Validation loss: 2.559632018353506

Epoch: 5| Step: 4
Training loss: 1.535856829646525
Validation loss: 2.5808244964104254

Epoch: 5| Step: 5
Training loss: 1.3058752261519726
Validation loss: 2.586907108000406

Epoch: 5| Step: 6
Training loss: 1.9665970913923998
Validation loss: 2.5923911254016843

Epoch: 5| Step: 7
Training loss: 2.4903042652569845
Validation loss: 2.613661996335021

Epoch: 5| Step: 8
Training loss: 2.391586010821221
Validation loss: 2.6143722081653955

Epoch: 5| Step: 9
Training loss: 2.491914740198431
Validation loss: 2.608745483786904

Epoch: 5| Step: 10
Training loss: 2.523240970481652
Validation loss: 2.606138270123043

Epoch: 5| Step: 11
Training loss: 2.1486086135693023
Validation loss: 2.579982550769025

Epoch: 287| Step: 0
Training loss: 1.6367215177016425
Validation loss: 2.5997251756624165

Epoch: 5| Step: 1
Training loss: 1.938455961103532
Validation loss: 2.615932368605109

Epoch: 5| Step: 2
Training loss: 1.8597844418345157
Validation loss: 2.6227364506720434

Epoch: 5| Step: 3
Training loss: 2.9469892752730233
Validation loss: 2.621677767579944

Epoch: 5| Step: 4
Training loss: 2.3894988754854114
Validation loss: 2.6245641119406997

Epoch: 5| Step: 5
Training loss: 1.794140667523949
Validation loss: 2.5952860485415425

Epoch: 5| Step: 6
Training loss: 2.5820152755450914
Validation loss: 2.5857093303164254

Epoch: 5| Step: 7
Training loss: 2.3554406109041643
Validation loss: 2.585271747707045

Epoch: 5| Step: 8
Training loss: 2.5808732614537684
Validation loss: 2.5574727677330755

Epoch: 5| Step: 9
Training loss: 2.691096981533697
Validation loss: 2.5632302786578354

Epoch: 5| Step: 10
Training loss: 1.4256068292820279
Validation loss: 2.564495356517804

Epoch: 5| Step: 11
Training loss: 1.181666198958146
Validation loss: 2.557033515429559

Epoch: 288| Step: 0
Training loss: 2.274802830294865
Validation loss: 2.543810375537493

Epoch: 5| Step: 1
Training loss: 1.571852958024118
Validation loss: 2.5394573159020175

Epoch: 5| Step: 2
Training loss: 2.5433938041820925
Validation loss: 2.5536593585765184

Epoch: 5| Step: 3
Training loss: 2.3791914645192613
Validation loss: 2.5484220744028083

Epoch: 5| Step: 4
Training loss: 2.3843798876071096
Validation loss: 2.5311006062380996

Epoch: 5| Step: 5
Training loss: 2.3983301393418275
Validation loss: 2.538432231830141

Epoch: 5| Step: 6
Training loss: 2.1449436701422946
Validation loss: 2.55955781512731

Epoch: 5| Step: 7
Training loss: 2.26478919035563
Validation loss: 2.5491804169338765

Epoch: 5| Step: 8
Training loss: 2.4137712321441542
Validation loss: 2.5899452277814916

Epoch: 5| Step: 9
Training loss: 2.013575613568161
Validation loss: 2.5955081863626956

Epoch: 5| Step: 10
Training loss: 2.0724158776378
Validation loss: 2.6057881164795798

Epoch: 5| Step: 11
Training loss: 1.170290778942756
Validation loss: 2.6432082089249422

Epoch: 289| Step: 0
Training loss: 2.381823825531679
Validation loss: 2.6539609769969754

Epoch: 5| Step: 1
Training loss: 1.912676998749185
Validation loss: 2.628250588233534

Epoch: 5| Step: 2
Training loss: 1.9494903925590226
Validation loss: 2.585503056691776

Epoch: 5| Step: 3
Training loss: 2.1975597676383067
Validation loss: 2.571204624897626

Epoch: 5| Step: 4
Training loss: 2.2217099499999344
Validation loss: 2.5568672392534744

Epoch: 5| Step: 5
Training loss: 2.700699175270885
Validation loss: 2.515817769090798

Epoch: 5| Step: 6
Training loss: 1.9474222164266235
Validation loss: 2.5091896751951124

Epoch: 5| Step: 7
Training loss: 2.16281576772861
Validation loss: 2.5028764984754313

Epoch: 5| Step: 8
Training loss: 2.0262357591037987
Validation loss: 2.491680061714715

Epoch: 5| Step: 9
Training loss: 3.167777736563764
Validation loss: 2.4933754213392407

Epoch: 5| Step: 10
Training loss: 1.789945759191199
Validation loss: 2.4969656291646314

Epoch: 5| Step: 11
Training loss: 1.7638546330420504
Validation loss: 2.5143298809653736

Epoch: 290| Step: 0
Training loss: 2.33791367241407
Validation loss: 2.547019065105614

Epoch: 5| Step: 1
Training loss: 1.8383392856578775
Validation loss: 2.598009663874914

Epoch: 5| Step: 2
Training loss: 2.3334609973133613
Validation loss: 2.6397631704121896

Epoch: 5| Step: 3
Training loss: 2.6946746513717765
Validation loss: 2.6552991324506494

Epoch: 5| Step: 4
Training loss: 2.291253925492857
Validation loss: 2.669340580595011

Epoch: 5| Step: 5
Training loss: 1.4751739431717588
Validation loss: 2.652016860676251

Epoch: 5| Step: 6
Training loss: 2.3405972447296723
Validation loss: 2.6186925821071627

Epoch: 5| Step: 7
Training loss: 2.0102403263636837
Validation loss: 2.5997382823950135

Epoch: 5| Step: 8
Training loss: 2.401504593339062
Validation loss: 2.615890921926647

Epoch: 5| Step: 9
Training loss: 2.7218359610454725
Validation loss: 2.5812073940366176

Epoch: 5| Step: 10
Training loss: 1.856106104555558
Validation loss: 2.578106637369132

Epoch: 5| Step: 11
Training loss: 1.1372245371197143
Validation loss: 2.5597524567219803

Epoch: 291| Step: 0
Training loss: 2.462585285084746
Validation loss: 2.5398785262835037

Epoch: 5| Step: 1
Training loss: 1.6101282079365735
Validation loss: 2.5495476224837694

Epoch: 5| Step: 2
Training loss: 2.3341270754297314
Validation loss: 2.538427752846665

Epoch: 5| Step: 3
Training loss: 2.9971742037121336
Validation loss: 2.541101562235289

Epoch: 5| Step: 4
Training loss: 1.809241358115576
Validation loss: 2.538795699749575

Epoch: 5| Step: 5
Training loss: 1.8396756688666274
Validation loss: 2.5675048683031205

Epoch: 5| Step: 6
Training loss: 2.115658929685168
Validation loss: 2.5535244136303286

Epoch: 5| Step: 7
Training loss: 2.2445896585886507
Validation loss: 2.5642043663946286

Epoch: 5| Step: 8
Training loss: 2.249354163834124
Validation loss: 2.5743843646649784

Epoch: 5| Step: 9
Training loss: 2.3045993594109717
Validation loss: 2.5818585036486517

Epoch: 5| Step: 10
Training loss: 2.1907943986596474
Validation loss: 2.606030344073291

Epoch: 5| Step: 11
Training loss: 1.7637150654621232
Validation loss: 2.609776715328955

Epoch: 292| Step: 0
Training loss: 1.8813001328185361
Validation loss: 2.6167158090832263

Epoch: 5| Step: 1
Training loss: 1.9192227306229963
Validation loss: 2.6388010840001677

Epoch: 5| Step: 2
Training loss: 2.3069671218903736
Validation loss: 2.6650583749464865

Epoch: 5| Step: 3
Training loss: 1.824554347141742
Validation loss: 2.6524757386121816

Epoch: 5| Step: 4
Training loss: 2.405207618745213
Validation loss: 2.627367688902827

Epoch: 5| Step: 5
Training loss: 2.6015520525198443
Validation loss: 2.5958621108193327

Epoch: 5| Step: 6
Training loss: 1.9450140421539444
Validation loss: 2.579601150382975

Epoch: 5| Step: 7
Training loss: 1.966141562215111
Validation loss: 2.559643913801134

Epoch: 5| Step: 8
Training loss: 2.01944471280835
Validation loss: 2.5608709243273005

Epoch: 5| Step: 9
Training loss: 2.8962617918522766
Validation loss: 2.546874173092074

Epoch: 5| Step: 10
Training loss: 2.309137528821997
Validation loss: 2.534938781376543

Epoch: 5| Step: 11
Training loss: 1.8189797167871355
Validation loss: 2.5132541897334475

Epoch: 293| Step: 0
Training loss: 2.1347623861694895
Validation loss: 2.5160027096018127

Epoch: 5| Step: 1
Training loss: 1.8785185542790765
Validation loss: 2.503036165347768

Epoch: 5| Step: 2
Training loss: 2.3676723071903005
Validation loss: 2.505804791231391

Epoch: 5| Step: 3
Training loss: 2.5279993919601194
Validation loss: 2.52492024150941

Epoch: 5| Step: 4
Training loss: 2.3694277193950746
Validation loss: 2.542637214983999

Epoch: 5| Step: 5
Training loss: 2.9042885016376436
Validation loss: 2.5772635860720863

Epoch: 5| Step: 6
Training loss: 1.9170421840621121
Validation loss: 2.591744631997978

Epoch: 5| Step: 7
Training loss: 2.351766786541563
Validation loss: 2.6018294120165066

Epoch: 5| Step: 8
Training loss: 2.2893826517929603
Validation loss: 2.588760199171378

Epoch: 5| Step: 9
Training loss: 1.8782154486738103
Validation loss: 2.6122351407214324

Epoch: 5| Step: 10
Training loss: 1.607818295067074
Validation loss: 2.5781855470117403

Epoch: 5| Step: 11
Training loss: 2.6218209771466197
Validation loss: 2.5969941215568566

Epoch: 294| Step: 0
Training loss: 2.5256773276266613
Validation loss: 2.5797150958329853

Epoch: 5| Step: 1
Training loss: 1.9551612310438315
Validation loss: 2.5975441624066415

Epoch: 5| Step: 2
Training loss: 2.227236354651203
Validation loss: 2.6252176330811783

Epoch: 5| Step: 3
Training loss: 2.3051465627947296
Validation loss: 2.6174507198534434

Epoch: 5| Step: 4
Training loss: 1.6961823091093344
Validation loss: 2.579493082592789

Epoch: 5| Step: 5
Training loss: 2.2359325608812717
Validation loss: 2.5769082174628215

Epoch: 5| Step: 6
Training loss: 2.157058011572546
Validation loss: 2.587569314455187

Epoch: 5| Step: 7
Training loss: 1.845957130029398
Validation loss: 2.5691918284726287

Epoch: 5| Step: 8
Training loss: 2.0495550649727536
Validation loss: 2.5777265144417516

Epoch: 5| Step: 9
Training loss: 2.16001221105868
Validation loss: 2.6051780580461896

Epoch: 5| Step: 10
Training loss: 2.80124480642359
Validation loss: 2.6177752465893604

Epoch: 5| Step: 11
Training loss: 1.8391604440385334
Validation loss: 2.6233170011170324

Epoch: 295| Step: 0
Training loss: 2.206198854366887
Validation loss: 2.5917344477479323

Epoch: 5| Step: 1
Training loss: 1.1605982596706954
Validation loss: 2.5703749644255933

Epoch: 5| Step: 2
Training loss: 2.340927051566194
Validation loss: 2.568644507068096

Epoch: 5| Step: 3
Training loss: 2.3065183447226767
Validation loss: 2.548714626703507

Epoch: 5| Step: 4
Training loss: 2.5232805610725246
Validation loss: 2.5558584020567006

Epoch: 5| Step: 5
Training loss: 2.170503251747098
Validation loss: 2.5628398770660628

Epoch: 5| Step: 6
Training loss: 2.4127333849349757
Validation loss: 2.5647630274271638

Epoch: 5| Step: 7
Training loss: 1.9278793203170304
Validation loss: 2.573294620836273

Epoch: 5| Step: 8
Training loss: 2.0142947990034825
Validation loss: 2.5855442566374993

Epoch: 5| Step: 9
Training loss: 2.4567457557828667
Validation loss: 2.584497286983519

Epoch: 5| Step: 10
Training loss: 2.37552195384986
Validation loss: 2.579244913712737

Epoch: 5| Step: 11
Training loss: 1.4772653672895288
Validation loss: 2.5925634918175433

Epoch: 296| Step: 0
Training loss: 1.761404546559022
Validation loss: 2.594523988472566

Epoch: 5| Step: 1
Training loss: 2.4369112917752944
Validation loss: 2.5486987591454264

Epoch: 5| Step: 2
Training loss: 1.6647505076668694
Validation loss: 2.5613435368658184

Epoch: 5| Step: 3
Training loss: 2.5551602454053066
Validation loss: 2.574819279628185

Epoch: 5| Step: 4
Training loss: 2.0190267320046953
Validation loss: 2.5586104414300794

Epoch: 5| Step: 5
Training loss: 1.8340975367985086
Validation loss: 2.548089707009848

Epoch: 5| Step: 6
Training loss: 2.9812452272260996
Validation loss: 2.553039112303973

Epoch: 5| Step: 7
Training loss: 2.2929286140945373
Validation loss: 2.579581610210198

Epoch: 5| Step: 8
Training loss: 1.9317518304456014
Validation loss: 2.6017625138049127

Epoch: 5| Step: 9
Training loss: 2.3277950181021674
Validation loss: 2.626701341023372

Epoch: 5| Step: 10
Training loss: 1.9184422423233745
Validation loss: 2.643104333544951

Epoch: 5| Step: 11
Training loss: 1.4555142357148736
Validation loss: 2.6497963464204095

Epoch: 297| Step: 0
Training loss: 1.7572461381436444
Validation loss: 2.665467042107526

Epoch: 5| Step: 1
Training loss: 2.6864339799037213
Validation loss: 2.6746052146163533

Epoch: 5| Step: 2
Training loss: 2.240086757648733
Validation loss: 2.617033028670038

Epoch: 5| Step: 3
Training loss: 1.9088860093219508
Validation loss: 2.621629740701934

Epoch: 5| Step: 4
Training loss: 2.314544392649325
Validation loss: 2.58832729278305

Epoch: 5| Step: 5
Training loss: 2.2152012127832665
Validation loss: 2.5764651455751495

Epoch: 5| Step: 6
Training loss: 2.4088698158099504
Validation loss: 2.560823159402966

Epoch: 5| Step: 7
Training loss: 1.5160121619861489
Validation loss: 2.567366955847108

Epoch: 5| Step: 8
Training loss: 2.629535208704831
Validation loss: 2.5602391822163497

Epoch: 5| Step: 9
Training loss: 1.7219353030076772
Validation loss: 2.5608169797289717

Epoch: 5| Step: 10
Training loss: 1.9522906543095522
Validation loss: 2.576905509289472

Epoch: 5| Step: 11
Training loss: 3.1969206477660332
Validation loss: 2.574257714802009

Epoch: 298| Step: 0
Training loss: 2.5503349906940267
Validation loss: 2.6043632750998293

Epoch: 5| Step: 1
Training loss: 2.4667899161125124
Validation loss: 2.6322665190819503

Epoch: 5| Step: 2
Training loss: 2.6460170431763173
Validation loss: 2.647891765770529

Epoch: 5| Step: 3
Training loss: 2.0849046757631493
Validation loss: 2.676763249470272

Epoch: 5| Step: 4
Training loss: 2.9266445785882307
Validation loss: 2.6630755821691623

Epoch: 5| Step: 5
Training loss: 2.055546686078889
Validation loss: 2.615696511758964

Epoch: 5| Step: 6
Training loss: 1.7881180048368737
Validation loss: 2.6306435341430214

Epoch: 5| Step: 7
Training loss: 2.046501882776382
Validation loss: 2.6026811838857444

Epoch: 5| Step: 8
Training loss: 1.5320368710754702
Validation loss: 2.5546099060904846

Epoch: 5| Step: 9
Training loss: 1.9100061525375576
Validation loss: 2.543583222904117

Epoch: 5| Step: 10
Training loss: 1.7764635526534875
Validation loss: 2.517936974937566

Epoch: 5| Step: 11
Training loss: 1.6072591557885016
Validation loss: 2.532369632898974

Epoch: 299| Step: 0
Training loss: 2.7197419910917855
Validation loss: 2.5282578738721893

Epoch: 5| Step: 1
Training loss: 1.704740615422825
Validation loss: 2.518331308012711

Epoch: 5| Step: 2
Training loss: 2.5832319137189663
Validation loss: 2.5366645052942833

Epoch: 5| Step: 3
Training loss: 1.6637797227321098
Validation loss: 2.529168061617907

Epoch: 5| Step: 4
Training loss: 2.205232734767409
Validation loss: 2.548403322328633

Epoch: 5| Step: 5
Training loss: 1.843011417194175
Validation loss: 2.5915870342000265

Epoch: 5| Step: 6
Training loss: 2.848987995297817
Validation loss: 2.6054964459656778

Epoch: 5| Step: 7
Training loss: 2.138409547089323
Validation loss: 2.674299430317351

Epoch: 5| Step: 8
Training loss: 2.2324485743837563
Validation loss: 2.7119901007914224

Epoch: 5| Step: 9
Training loss: 2.240719304567525
Validation loss: 2.719016811096741

Epoch: 5| Step: 10
Training loss: 2.044096597102229
Validation loss: 2.6842697861598213

Epoch: 5| Step: 11
Training loss: 2.4317733789690594
Validation loss: 2.6261077882118347

Epoch: 300| Step: 0
Training loss: 2.529005209112327
Validation loss: 2.5667378420890006

Epoch: 5| Step: 1
Training loss: 1.891450370768733
Validation loss: 2.53661650778705

Epoch: 5| Step: 2
Training loss: 2.3358348198717085
Validation loss: 2.5084952220340266

Epoch: 5| Step: 3
Training loss: 2.8852507248591572
Validation loss: 2.488605795494805

Epoch: 5| Step: 4
Training loss: 2.4919596122420224
Validation loss: 2.4854011695572664

Epoch: 5| Step: 5
Training loss: 2.2604792596497947
Validation loss: 2.4774244615520997

Epoch: 5| Step: 6
Training loss: 2.1115157955300616
Validation loss: 2.4723733315261867

Epoch: 5| Step: 7
Training loss: 2.3443954596240704
Validation loss: 2.456854498024071

Epoch: 5| Step: 8
Training loss: 2.3327639657124686
Validation loss: 2.473569844846684

Epoch: 5| Step: 9
Training loss: 2.0034367120931953
Validation loss: 2.4944551847564616

Epoch: 5| Step: 10
Training loss: 2.051917816561285
Validation loss: 2.4932179767035323

Epoch: 5| Step: 11
Training loss: 0.8191830807344948
Validation loss: 2.515476246102356

Epoch: 301| Step: 0
Training loss: 2.6568964452064248
Validation loss: 2.544551647753774

Epoch: 5| Step: 1
Training loss: 2.0670267770672535
Validation loss: 2.540689332592505

Epoch: 5| Step: 2
Training loss: 2.219446851877311
Validation loss: 2.5896341901702247

Epoch: 5| Step: 3
Training loss: 2.4681347430402267
Validation loss: 2.5917432751224134

Epoch: 5| Step: 4
Training loss: 2.2388859809034134
Validation loss: 2.5947261068994334

Epoch: 5| Step: 5
Training loss: 2.364689683133047
Validation loss: 2.6104331355223622

Epoch: 5| Step: 6
Training loss: 1.92569229508595
Validation loss: 2.61125546308877

Epoch: 5| Step: 7
Training loss: 2.2440547810495985
Validation loss: 2.575197831520196

Epoch: 5| Step: 8
Training loss: 2.4121240036246694
Validation loss: 2.545746834253708

Epoch: 5| Step: 9
Training loss: 1.945562323649193
Validation loss: 2.5446143814794566

Epoch: 5| Step: 10
Training loss: 1.9120836265942245
Validation loss: 2.530246684910696

Epoch: 5| Step: 11
Training loss: 1.4578774784240092
Validation loss: 2.517166845930322

Epoch: 302| Step: 0
Training loss: 2.499119221982247
Validation loss: 2.525082665056514

Epoch: 5| Step: 1
Training loss: 2.026960568240694
Validation loss: 2.5296651093479894

Epoch: 5| Step: 2
Training loss: 2.179364799210896
Validation loss: 2.506533121113518

Epoch: 5| Step: 3
Training loss: 1.3986712638641847
Validation loss: 2.5294544656918885

Epoch: 5| Step: 4
Training loss: 2.0276158615102973
Validation loss: 2.5356782318036366

Epoch: 5| Step: 5
Training loss: 2.7163281231743346
Validation loss: 2.535230861794336

Epoch: 5| Step: 6
Training loss: 2.2022423024271998
Validation loss: 2.542488404362886

Epoch: 5| Step: 7
Training loss: 2.140658190393353
Validation loss: 2.566368660150744

Epoch: 5| Step: 8
Training loss: 2.2367423794131485
Validation loss: 2.5578618097106105

Epoch: 5| Step: 9
Training loss: 2.5728261419476937
Validation loss: 2.598818377062693

Epoch: 5| Step: 10
Training loss: 2.3194064545201067
Validation loss: 2.590023730714256

Epoch: 5| Step: 11
Training loss: 1.7600800532861651
Validation loss: 2.558563096345726

Epoch: 303| Step: 0
Training loss: 2.333968235103714
Validation loss: 2.5760040421340653

Epoch: 5| Step: 1
Training loss: 2.322977712424959
Validation loss: 2.547632295943744

Epoch: 5| Step: 2
Training loss: 1.9831526588509254
Validation loss: 2.5703356083813818

Epoch: 5| Step: 3
Training loss: 2.3680934871893475
Validation loss: 2.5615849450585335

Epoch: 5| Step: 4
Training loss: 2.4189001702110953
Validation loss: 2.5538864338019387

Epoch: 5| Step: 5
Training loss: 2.5434850118895507
Validation loss: 2.5622960897276665

Epoch: 5| Step: 6
Training loss: 2.1677732087350092
Validation loss: 2.5663631983319637

Epoch: 5| Step: 7
Training loss: 2.393950200486311
Validation loss: 2.5770018443009226

Epoch: 5| Step: 8
Training loss: 1.9181670107797957
Validation loss: 2.5808368369134023

Epoch: 5| Step: 9
Training loss: 1.4029581323305367
Validation loss: 2.6039802764310664

Epoch: 5| Step: 10
Training loss: 1.8650148911687021
Validation loss: 2.5876989176057066

Epoch: 5| Step: 11
Training loss: 0.820846601724291
Validation loss: 2.604994450930557

Epoch: 304| Step: 0
Training loss: 2.423655095713855
Validation loss: 2.6000936139811106

Epoch: 5| Step: 1
Training loss: 1.744020190892013
Validation loss: 2.60152302770292

Epoch: 5| Step: 2
Training loss: 1.615428834439194
Validation loss: 2.621174795429908

Epoch: 5| Step: 3
Training loss: 1.6602053646227528
Validation loss: 2.60639037113305

Epoch: 5| Step: 4
Training loss: 2.379542473965635
Validation loss: 2.611723039467412

Epoch: 5| Step: 5
Training loss: 2.0189965017892084
Validation loss: 2.616978677797848

Epoch: 5| Step: 6
Training loss: 2.225789896451813
Validation loss: 2.595932084762101

Epoch: 5| Step: 7
Training loss: 2.702511227114186
Validation loss: 2.6279180557898916

Epoch: 5| Step: 8
Training loss: 2.073213207816774
Validation loss: 2.632796124295133

Epoch: 5| Step: 9
Training loss: 2.434412149677176
Validation loss: 2.620044625256538

Epoch: 5| Step: 10
Training loss: 2.2260624909724793
Validation loss: 2.6441076212663406

Epoch: 5| Step: 11
Training loss: 1.9293667298866628
Validation loss: 2.6528101545181118

Epoch: 305| Step: 0
Training loss: 2.3728478367853394
Validation loss: 2.5893133511188027

Epoch: 5| Step: 1
Training loss: 1.8958570108576982
Validation loss: 2.589208771512961

Epoch: 5| Step: 2
Training loss: 1.925928013530779
Validation loss: 2.5603629908717807

Epoch: 5| Step: 3
Training loss: 1.8958263257354784
Validation loss: 2.535417125036302

Epoch: 5| Step: 4
Training loss: 2.7524960201002515
Validation loss: 2.515835688043305

Epoch: 5| Step: 5
Training loss: 1.987066711123755
Validation loss: 2.5232539430040264

Epoch: 5| Step: 6
Training loss: 2.0134553099097237
Validation loss: 2.515514825497318

Epoch: 5| Step: 7
Training loss: 2.548542810599519
Validation loss: 2.5237855149658324

Epoch: 5| Step: 8
Training loss: 1.9511951525333526
Validation loss: 2.538734367882193

Epoch: 5| Step: 9
Training loss: 2.1477985333560676
Validation loss: 2.5636233798172627

Epoch: 5| Step: 10
Training loss: 2.2400972944655497
Validation loss: 2.576651219370615

Epoch: 5| Step: 11
Training loss: 2.4434009429542636
Validation loss: 2.5935584116270123

Epoch: 306| Step: 0
Training loss: 2.5382768090262973
Validation loss: 2.625216883827656

Epoch: 5| Step: 1
Training loss: 1.9141478227554996
Validation loss: 2.666287254869662

Epoch: 5| Step: 2
Training loss: 2.0371330164765498
Validation loss: 2.6706498034398427

Epoch: 5| Step: 3
Training loss: 2.8374752362888973
Validation loss: 2.677730787531265

Epoch: 5| Step: 4
Training loss: 1.8267241107071406
Validation loss: 2.5991722406236035

Epoch: 5| Step: 5
Training loss: 2.7978718435674184
Validation loss: 2.5359415798189695

Epoch: 5| Step: 6
Training loss: 1.7608398816621371
Validation loss: 2.514011086490821

Epoch: 5| Step: 7
Training loss: 2.0028496944350405
Validation loss: 2.4966627734993843

Epoch: 5| Step: 8
Training loss: 2.27662943242215
Validation loss: 2.4867171157797987

Epoch: 5| Step: 9
Training loss: 2.3393858905837353
Validation loss: 2.494535350706587

Epoch: 5| Step: 10
Training loss: 2.23132617724232
Validation loss: 2.480682560073578

Epoch: 5| Step: 11
Training loss: 1.9102392510165493
Validation loss: 2.4972337558144306

Epoch: 307| Step: 0
Training loss: 2.481742183577309
Validation loss: 2.4914886427491676

Epoch: 5| Step: 1
Training loss: 2.173945147028512
Validation loss: 2.517942731176251

Epoch: 5| Step: 2
Training loss: 1.6795698967505577
Validation loss: 2.5751788635847284

Epoch: 5| Step: 3
Training loss: 1.864006365229008
Validation loss: 2.601268301090874

Epoch: 5| Step: 4
Training loss: 2.355374209402999
Validation loss: 2.642731445255543

Epoch: 5| Step: 5
Training loss: 2.6145628564850902
Validation loss: 2.703380708598797

Epoch: 5| Step: 6
Training loss: 1.8411515886431735
Validation loss: 2.7006844728797517

Epoch: 5| Step: 7
Training loss: 2.0757240824495873
Validation loss: 2.7282543598863676

Epoch: 5| Step: 8
Training loss: 2.2438169931595366
Validation loss: 2.732616992934346

Epoch: 5| Step: 9
Training loss: 1.8816804133685427
Validation loss: 2.6810401527609393

Epoch: 5| Step: 10
Training loss: 2.5788978111963377
Validation loss: 2.6285354254472812

Epoch: 5| Step: 11
Training loss: 2.0781323425622165
Validation loss: 2.614645472138968

Epoch: 308| Step: 0
Training loss: 1.9439367615496272
Validation loss: 2.600975986232485

Epoch: 5| Step: 1
Training loss: 1.4870749563528287
Validation loss: 2.5732064193372644

Epoch: 5| Step: 2
Training loss: 1.8896478066455664
Validation loss: 2.5502950176669246

Epoch: 5| Step: 3
Training loss: 2.571552012523331
Validation loss: 2.5569417381295323

Epoch: 5| Step: 4
Training loss: 2.142691624016364
Validation loss: 2.5179167313370314

Epoch: 5| Step: 5
Training loss: 1.7813236823653333
Validation loss: 2.5220732450658967

Epoch: 5| Step: 6
Training loss: 2.24009814592333
Validation loss: 2.513295253864453

Epoch: 5| Step: 7
Training loss: 1.908123284097669
Validation loss: 2.5201133035992864

Epoch: 5| Step: 8
Training loss: 3.164153373261012
Validation loss: 2.5399670637741196

Epoch: 5| Step: 9
Training loss: 2.393961852736162
Validation loss: 2.550261927067679

Epoch: 5| Step: 10
Training loss: 2.138751247100199
Validation loss: 2.5573452803410093

Epoch: 5| Step: 11
Training loss: 1.4608397425619575
Validation loss: 2.5630919501589156

Epoch: 309| Step: 0
Training loss: 1.9112030468619048
Validation loss: 2.5825861047569023

Epoch: 5| Step: 1
Training loss: 2.5016536965267977
Validation loss: 2.593673049980267

Epoch: 5| Step: 2
Training loss: 2.018140657186392
Validation loss: 2.60141723196685

Epoch: 5| Step: 3
Training loss: 2.1761658361156337
Validation loss: 2.6199043482265347

Epoch: 5| Step: 4
Training loss: 1.9392403200612904
Validation loss: 2.626557875611582

Epoch: 5| Step: 5
Training loss: 2.3045597364281685
Validation loss: 2.615825302372571

Epoch: 5| Step: 6
Training loss: 2.1395742245944236
Validation loss: 2.601573142181716

Epoch: 5| Step: 7
Training loss: 2.575856175719907
Validation loss: 2.610379122935724

Epoch: 5| Step: 8
Training loss: 1.9474623111118978
Validation loss: 2.590088370054027

Epoch: 5| Step: 9
Training loss: 2.3263923290727018
Validation loss: 2.578314456336323

Epoch: 5| Step: 10
Training loss: 1.6125718743917574
Validation loss: 2.579411095318196

Epoch: 5| Step: 11
Training loss: 1.54321704267086
Validation loss: 2.574792380280505

Epoch: 310| Step: 0
Training loss: 2.3857664715237172
Validation loss: 2.5761182932261923

Epoch: 5| Step: 1
Training loss: 1.798403811035666
Validation loss: 2.601667350511952

Epoch: 5| Step: 2
Training loss: 2.5046817810412136
Validation loss: 2.6228995264042227

Epoch: 5| Step: 3
Training loss: 2.040030063519824
Validation loss: 2.657898167166402

Epoch: 5| Step: 4
Training loss: 2.1943189877516267
Validation loss: 2.6792840718836013

Epoch: 5| Step: 5
Training loss: 2.2620670136121666
Validation loss: 2.6221906486379885

Epoch: 5| Step: 6
Training loss: 1.9427139513958924
Validation loss: 2.62574245155981

Epoch: 5| Step: 7
Training loss: 1.8272365791432312
Validation loss: 2.5884480155618546

Epoch: 5| Step: 8
Training loss: 1.8458404328473075
Validation loss: 2.5496222183467463

Epoch: 5| Step: 9
Training loss: 2.2015074073932
Validation loss: 2.5356690133637514

Epoch: 5| Step: 10
Training loss: 2.2339273284389396
Validation loss: 2.519925652913443

Epoch: 5| Step: 11
Training loss: 3.5609937461705985
Validation loss: 2.514019068502247

Epoch: 311| Step: 0
Training loss: 1.9865265243606804
Validation loss: 2.5283195463188957

Epoch: 5| Step: 1
Training loss: 1.8033775430408743
Validation loss: 2.521239694572069

Epoch: 5| Step: 2
Training loss: 1.840185955643852
Validation loss: 2.5789075453711745

Epoch: 5| Step: 3
Training loss: 2.1228701071333247
Validation loss: 2.580536775830905

Epoch: 5| Step: 4
Training loss: 1.7157809883175144
Validation loss: 2.6051346480300412

Epoch: 5| Step: 5
Training loss: 2.1731684284407367
Validation loss: 2.644086063089003

Epoch: 5| Step: 6
Training loss: 1.809055409512287
Validation loss: 2.643845875521907

Epoch: 5| Step: 7
Training loss: 2.2684846917338586
Validation loss: 2.641636111256234

Epoch: 5| Step: 8
Training loss: 2.020007433358292
Validation loss: 2.6232925038712915

Epoch: 5| Step: 9
Training loss: 2.9640513933181802
Validation loss: 2.6237445508474146

Epoch: 5| Step: 10
Training loss: 2.5332553596375886
Validation loss: 2.6213480962911273

Epoch: 5| Step: 11
Training loss: 1.0965857665147556
Validation loss: 2.6118178896240996

Epoch: 312| Step: 0
Training loss: 2.5092121152162385
Validation loss: 2.6435933518350714

Epoch: 5| Step: 1
Training loss: 1.789429073176265
Validation loss: 2.6382988497367594

Epoch: 5| Step: 2
Training loss: 2.17373281374472
Validation loss: 2.6636388615247495

Epoch: 5| Step: 3
Training loss: 2.1044199070388974
Validation loss: 2.6221937665522352

Epoch: 5| Step: 4
Training loss: 2.463270552854241
Validation loss: 2.613551100714756

Epoch: 5| Step: 5
Training loss: 2.457520549917209
Validation loss: 2.5958429303203605

Epoch: 5| Step: 6
Training loss: 1.85241557239057
Validation loss: 2.5904652620281294

Epoch: 5| Step: 7
Training loss: 1.7777709447543966
Validation loss: 2.605753241110152

Epoch: 5| Step: 8
Training loss: 2.3577359803298363
Validation loss: 2.5625169741835956

Epoch: 5| Step: 9
Training loss: 1.841916158298485
Validation loss: 2.5487660445524787

Epoch: 5| Step: 10
Training loss: 2.07376731658383
Validation loss: 2.54566031043369

Epoch: 5| Step: 11
Training loss: 1.6520137231824836
Validation loss: 2.525248941261224

Epoch: 313| Step: 0
Training loss: 2.15159668739434
Validation loss: 2.5204897395494386

Epoch: 5| Step: 1
Training loss: 2.251158733816082
Validation loss: 2.508163558298551

Epoch: 5| Step: 2
Training loss: 1.8289060961736707
Validation loss: 2.5153955587950905

Epoch: 5| Step: 3
Training loss: 2.306420660553433
Validation loss: 2.5353031243253934

Epoch: 5| Step: 4
Training loss: 2.050471167963752
Validation loss: 2.569959142758459

Epoch: 5| Step: 5
Training loss: 2.4073814605336223
Validation loss: 2.5705938136976543

Epoch: 5| Step: 6
Training loss: 1.6780356157817484
Validation loss: 2.6044677573031962

Epoch: 5| Step: 7
Training loss: 2.415906479635991
Validation loss: 2.6114382895354873

Epoch: 5| Step: 8
Training loss: 1.915263208074604
Validation loss: 2.6438985393570973

Epoch: 5| Step: 9
Training loss: 2.2234671509642854
Validation loss: 2.6095755037493507

Epoch: 5| Step: 10
Training loss: 2.40367682462133
Validation loss: 2.6257869244837373

Epoch: 5| Step: 11
Training loss: 1.415251005845217
Validation loss: 2.6143074890668467

Epoch: 314| Step: 0
Training loss: 2.6719158682569812
Validation loss: 2.6019144860658128

Epoch: 5| Step: 1
Training loss: 1.985816732196622
Validation loss: 2.5810840579519714

Epoch: 5| Step: 2
Training loss: 1.960467825643331
Validation loss: 2.598403257265559

Epoch: 5| Step: 3
Training loss: 2.502891299116702
Validation loss: 2.593913674456619

Epoch: 5| Step: 4
Training loss: 2.299326308725889
Validation loss: 2.6210480869369115

Epoch: 5| Step: 5
Training loss: 2.0871809207305954
Validation loss: 2.5856950844104714

Epoch: 5| Step: 6
Training loss: 1.5448589095101755
Validation loss: 2.5803548475322233

Epoch: 5| Step: 7
Training loss: 1.52129553821521
Validation loss: 2.5847468136756304

Epoch: 5| Step: 8
Training loss: 1.8648573249671194
Validation loss: 2.5771820116283384

Epoch: 5| Step: 9
Training loss: 2.292954608932119
Validation loss: 2.5675670721622006

Epoch: 5| Step: 10
Training loss: 2.223361206890354
Validation loss: 2.5841065250819413

Epoch: 5| Step: 11
Training loss: 1.3865762986637233
Validation loss: 2.5831007019532013

Epoch: 315| Step: 0
Training loss: 1.8097332192971056
Validation loss: 2.5811197381176023

Epoch: 5| Step: 1
Training loss: 2.514787048667637
Validation loss: 2.5779325124379895

Epoch: 5| Step: 2
Training loss: 1.802515547707812
Validation loss: 2.6011588210147694

Epoch: 5| Step: 3
Training loss: 1.7477596792925132
Validation loss: 2.636908110424049

Epoch: 5| Step: 4
Training loss: 1.6762192516081151
Validation loss: 2.6518893444875955

Epoch: 5| Step: 5
Training loss: 2.064063433315577
Validation loss: 2.6397700684534193

Epoch: 5| Step: 6
Training loss: 2.7505800329067935
Validation loss: 2.6232479356412073

Epoch: 5| Step: 7
Training loss: 2.390700195725571
Validation loss: 2.602354286223671

Epoch: 5| Step: 8
Training loss: 1.849011301347557
Validation loss: 2.6291740247096516

Epoch: 5| Step: 9
Training loss: 2.1707644470570577
Validation loss: 2.595064025688095

Epoch: 5| Step: 10
Training loss: 2.248713019312402
Validation loss: 2.5945015856295144

Epoch: 5| Step: 11
Training loss: 1.1248849174129305
Validation loss: 2.5893048454072756

Epoch: 316| Step: 0
Training loss: 2.420559236523058
Validation loss: 2.603058721729745

Epoch: 5| Step: 1
Training loss: 2.4281310956527413
Validation loss: 2.6286096391377334

Epoch: 5| Step: 2
Training loss: 2.076390166124556
Validation loss: 2.6266100426644394

Epoch: 5| Step: 3
Training loss: 2.3311621805376377
Validation loss: 2.622324223126225

Epoch: 5| Step: 4
Training loss: 2.334448400362248
Validation loss: 2.670952985486647

Epoch: 5| Step: 5
Training loss: 1.9663412102304776
Validation loss: 2.6276831462220267

Epoch: 5| Step: 6
Training loss: 1.5646503148003967
Validation loss: 2.611797038631882

Epoch: 5| Step: 7
Training loss: 2.3126174278343563
Validation loss: 2.564589776424327

Epoch: 5| Step: 8
Training loss: 1.7893669835483006
Validation loss: 2.5647351937119938

Epoch: 5| Step: 9
Training loss: 1.4948436803330278
Validation loss: 2.5435777863639473

Epoch: 5| Step: 10
Training loss: 2.238794823756393
Validation loss: 2.530798078939785

Epoch: 5| Step: 11
Training loss: 2.1836987847194615
Validation loss: 2.521344756957453

Epoch: 317| Step: 0
Training loss: 2.3377326523160926
Validation loss: 2.5192699957349287

Epoch: 5| Step: 1
Training loss: 1.5751356005954096
Validation loss: 2.4904347457557146

Epoch: 5| Step: 2
Training loss: 1.94874839229652
Validation loss: 2.5282307423913397

Epoch: 5| Step: 3
Training loss: 2.3025773037702004
Validation loss: 2.5259457455280683

Epoch: 5| Step: 4
Training loss: 2.6213445188174385
Validation loss: 2.5270475148123137

Epoch: 5| Step: 5
Training loss: 1.935012882298212
Validation loss: 2.519396835014239

Epoch: 5| Step: 6
Training loss: 1.4120783927758263
Validation loss: 2.5391108620757263

Epoch: 5| Step: 7
Training loss: 1.4408621239125319
Validation loss: 2.5662765605640243

Epoch: 5| Step: 8
Training loss: 2.4701543748930397
Validation loss: 2.6094010974241413

Epoch: 5| Step: 9
Training loss: 2.579412982458592
Validation loss: 2.6406323848523288

Epoch: 5| Step: 10
Training loss: 2.1544033380453524
Validation loss: 2.6403725144102603

Epoch: 5| Step: 11
Training loss: 2.0384181382053463
Validation loss: 2.5945353831788864

Epoch: 318| Step: 0
Training loss: 1.9813159582669178
Validation loss: 2.587322670854001

Epoch: 5| Step: 1
Training loss: 2.802857973782744
Validation loss: 2.5815944600355953

Epoch: 5| Step: 2
Training loss: 1.8078619050946496
Validation loss: 2.5630669935710864

Epoch: 5| Step: 3
Training loss: 1.5580340075864123
Validation loss: 2.5461832932642285

Epoch: 5| Step: 4
Training loss: 1.7077207242243067
Validation loss: 2.5483359181927616

Epoch: 5| Step: 5
Training loss: 2.22405714996239
Validation loss: 2.5458290550104414

Epoch: 5| Step: 6
Training loss: 2.095892649646048
Validation loss: 2.5628905463920013

Epoch: 5| Step: 7
Training loss: 2.5432567521244414
Validation loss: 2.566015750898363

Epoch: 5| Step: 8
Training loss: 2.196571830570138
Validation loss: 2.5593949944006646

Epoch: 5| Step: 9
Training loss: 2.14465843059811
Validation loss: 2.5687078938123196

Epoch: 5| Step: 10
Training loss: 1.6814493564553095
Validation loss: 2.5748158805723675

Epoch: 5| Step: 11
Training loss: 2.9929426151768594
Validation loss: 2.555947415973585

Epoch: 319| Step: 0
Training loss: 1.5164426190959215
Validation loss: 2.604982775919833

Epoch: 5| Step: 1
Training loss: 2.193433615972784
Validation loss: 2.5936554734497115

Epoch: 5| Step: 2
Training loss: 2.151376164054412
Validation loss: 2.5893345174433966

Epoch: 5| Step: 3
Training loss: 1.8230116319897338
Validation loss: 2.5768066349193024

Epoch: 5| Step: 4
Training loss: 2.289541044761634
Validation loss: 2.559701581681888

Epoch: 5| Step: 5
Training loss: 1.7579713198651752
Validation loss: 2.5528365107220568

Epoch: 5| Step: 6
Training loss: 2.205087964126355
Validation loss: 2.5819369542711668

Epoch: 5| Step: 7
Training loss: 2.6689725582045565
Validation loss: 2.530387668737644

Epoch: 5| Step: 8
Training loss: 2.121588043450198
Validation loss: 2.5913003514414368

Epoch: 5| Step: 9
Training loss: 1.5309639488375881
Validation loss: 2.6314419009679386

Epoch: 5| Step: 10
Training loss: 2.2378785734805975
Validation loss: 2.605226576958715

Epoch: 5| Step: 11
Training loss: 2.3061167277877797
Validation loss: 2.6147594975146644

Epoch: 320| Step: 0
Training loss: 2.5304056336980887
Validation loss: 2.6996882904813426

Epoch: 5| Step: 1
Training loss: 2.0426955323026506
Validation loss: 2.751175105565901

Epoch: 5| Step: 2
Training loss: 2.4074455362816316
Validation loss: 2.7300167737464136

Epoch: 5| Step: 3
Training loss: 2.088907363597976
Validation loss: 2.671518803996714

Epoch: 5| Step: 4
Training loss: 2.7779656208951264
Validation loss: 2.6284928169154758

Epoch: 5| Step: 5
Training loss: 1.2989372494395437
Validation loss: 2.5900914307268454

Epoch: 5| Step: 6
Training loss: 2.0711406850658904
Validation loss: 2.5416776716796594

Epoch: 5| Step: 7
Training loss: 2.0753730392644387
Validation loss: 2.5341532701549876

Epoch: 5| Step: 8
Training loss: 2.8198666206903984
Validation loss: 2.5294227833873157

Epoch: 5| Step: 9
Training loss: 1.8262939412328825
Validation loss: 2.5102121354249824

Epoch: 5| Step: 10
Training loss: 1.7778821192691854
Validation loss: 2.511576081412028

Epoch: 5| Step: 11
Training loss: 1.0868464994724543
Validation loss: 2.5176638087253855

Epoch: 321| Step: 0
Training loss: 1.400343762495515
Validation loss: 2.517153281625119

Epoch: 5| Step: 1
Training loss: 1.7592402784353498
Validation loss: 2.5370699062316837

Epoch: 5| Step: 2
Training loss: 1.9412925886504449
Validation loss: 2.526663353046754

Epoch: 5| Step: 3
Training loss: 2.40838676798147
Validation loss: 2.5562641710791727

Epoch: 5| Step: 4
Training loss: 2.2350085233999466
Validation loss: 2.5743466018934296

Epoch: 5| Step: 5
Training loss: 2.1411713508552146
Validation loss: 2.5750767151660803

Epoch: 5| Step: 6
Training loss: 2.161665266924277
Validation loss: 2.5916296476886918

Epoch: 5| Step: 7
Training loss: 2.922838184900893
Validation loss: 2.599757755132857

Epoch: 5| Step: 8
Training loss: 1.8782487063678261
Validation loss: 2.615492318243162

Epoch: 5| Step: 9
Training loss: 2.008132730914947
Validation loss: 2.6369551300715393

Epoch: 5| Step: 10
Training loss: 2.2950047774254765
Validation loss: 2.6405331183705845

Epoch: 5| Step: 11
Training loss: 0.8256724766863216
Validation loss: 2.6189460236436064

Epoch: 322| Step: 0
Training loss: 2.131422882675153
Validation loss: 2.584637367894792

Epoch: 5| Step: 1
Training loss: 2.094841971252601
Validation loss: 2.5674581051138183

Epoch: 5| Step: 2
Training loss: 1.7929469420991289
Validation loss: 2.568492349293553

Epoch: 5| Step: 3
Training loss: 2.1568467793239234
Validation loss: 2.5492125590299204

Epoch: 5| Step: 4
Training loss: 2.7956158238342863
Validation loss: 2.5251556802509842

Epoch: 5| Step: 5
Training loss: 1.742011022824123
Validation loss: 2.526540226583574

Epoch: 5| Step: 6
Training loss: 1.7814773949819815
Validation loss: 2.5266959014979866

Epoch: 5| Step: 7
Training loss: 2.72862187740506
Validation loss: 2.5461992720861617

Epoch: 5| Step: 8
Training loss: 1.8152569816401507
Validation loss: 2.5728582396160355

Epoch: 5| Step: 9
Training loss: 1.946457981372393
Validation loss: 2.59710254169617

Epoch: 5| Step: 10
Training loss: 1.6397181593229826
Validation loss: 2.607103847963319

Epoch: 5| Step: 11
Training loss: 2.710058416039619
Validation loss: 2.617542424973957

Epoch: 323| Step: 0
Training loss: 1.9721727439631778
Validation loss: 2.6220267047724857

Epoch: 5| Step: 1
Training loss: 1.563875508444088
Validation loss: 2.6072673166021665

Epoch: 5| Step: 2
Training loss: 1.9249842853647838
Validation loss: 2.5851464920113405

Epoch: 5| Step: 3
Training loss: 2.2458498084243104
Validation loss: 2.5580681802189997

Epoch: 5| Step: 4
Training loss: 2.2885879180869315
Validation loss: 2.561267583559246

Epoch: 5| Step: 5
Training loss: 2.9656494010990677
Validation loss: 2.534223528943988

Epoch: 5| Step: 6
Training loss: 1.9805993633350518
Validation loss: 2.534195336285579

Epoch: 5| Step: 7
Training loss: 1.9279051669291514
Validation loss: 2.5092381181513197

Epoch: 5| Step: 8
Training loss: 1.9162905434576434
Validation loss: 2.545029066809174

Epoch: 5| Step: 9
Training loss: 1.6989917121132727
Validation loss: 2.5534680379248207

Epoch: 5| Step: 10
Training loss: 2.422806788211084
Validation loss: 2.5623264137647896

Epoch: 5| Step: 11
Training loss: 0.8270660683649976
Validation loss: 2.588862225942559

Epoch: 324| Step: 0
Training loss: 1.5387634141648738
Validation loss: 2.606437118058123

Epoch: 5| Step: 1
Training loss: 2.3571429273266804
Validation loss: 2.6328631583904687

Epoch: 5| Step: 2
Training loss: 1.567259368313531
Validation loss: 2.6620038002967696

Epoch: 5| Step: 3
Training loss: 1.9191896860539628
Validation loss: 2.634332514277366

Epoch: 5| Step: 4
Training loss: 2.485533917825089
Validation loss: 2.6292541371972784

Epoch: 5| Step: 5
Training loss: 2.398777940675855
Validation loss: 2.6109260700370585

Epoch: 5| Step: 6
Training loss: 2.1601648589198934
Validation loss: 2.5811014776165946

Epoch: 5| Step: 7
Training loss: 1.9200836765413778
Validation loss: 2.5547138799924936

Epoch: 5| Step: 8
Training loss: 2.1210506989832822
Validation loss: 2.5032932267032386

Epoch: 5| Step: 9
Training loss: 2.375224253457224
Validation loss: 2.4902981978072884

Epoch: 5| Step: 10
Training loss: 2.1038663920562493
Validation loss: 2.4943073468905466

Epoch: 5| Step: 11
Training loss: 1.6716316259913624
Validation loss: 2.5295846115089806

Epoch: 325| Step: 0
Training loss: 1.9655031345355052
Validation loss: 2.535385246886697

Epoch: 5| Step: 1
Training loss: 1.9015021685242606
Validation loss: 2.577515316167515

Epoch: 5| Step: 2
Training loss: 2.0142323022116764
Validation loss: 2.592322753510974

Epoch: 5| Step: 3
Training loss: 1.9263597590560348
Validation loss: 2.6148417004494697

Epoch: 5| Step: 4
Training loss: 1.7954831911222842
Validation loss: 2.643656779059322

Epoch: 5| Step: 5
Training loss: 2.6971309995650374
Validation loss: 2.6362341466083037

Epoch: 5| Step: 6
Training loss: 2.301672252930923
Validation loss: 2.674007980951769

Epoch: 5| Step: 7
Training loss: 1.4473285532666984
Validation loss: 2.679335683224655

Epoch: 5| Step: 8
Training loss: 2.1952824166296754
Validation loss: 2.6340404518294767

Epoch: 5| Step: 9
Training loss: 2.2431020964789523
Validation loss: 2.5957866087903185

Epoch: 5| Step: 10
Training loss: 2.2988216947791336
Validation loss: 2.5546839458351416

Epoch: 5| Step: 11
Training loss: 1.8166992607459143
Validation loss: 2.525200148477585

Epoch: 326| Step: 0
Training loss: 2.343529550993154
Validation loss: 2.519539687662511

Epoch: 5| Step: 1
Training loss: 2.155299986384966
Validation loss: 2.5170271067997954

Epoch: 5| Step: 2
Training loss: 2.1706795455533374
Validation loss: 2.522390091142742

Epoch: 5| Step: 3
Training loss: 2.5006193347533987
Validation loss: 2.5208620425762183

Epoch: 5| Step: 4
Training loss: 1.7360505267274648
Validation loss: 2.5505427764598845

Epoch: 5| Step: 5
Training loss: 2.357159009688219
Validation loss: 2.5418027205610323

Epoch: 5| Step: 6
Training loss: 2.4425049285682765
Validation loss: 2.563728402497971

Epoch: 5| Step: 7
Training loss: 2.0224327626975804
Validation loss: 2.592038670107903

Epoch: 5| Step: 8
Training loss: 1.6927977865987056
Validation loss: 2.6355498108132025

Epoch: 5| Step: 9
Training loss: 1.5898869389096901
Validation loss: 2.653375143234118

Epoch: 5| Step: 10
Training loss: 2.018316911000044
Validation loss: 2.666789422090691

Epoch: 5| Step: 11
Training loss: 1.7195721133973498
Validation loss: 2.649819995056777

Epoch: 327| Step: 0
Training loss: 1.579573995283709
Validation loss: 2.6163215001556708

Epoch: 5| Step: 1
Training loss: 1.6545418622095094
Validation loss: 2.587964468808141

Epoch: 5| Step: 2
Training loss: 3.056812064631079
Validation loss: 2.5553523918149073

Epoch: 5| Step: 3
Training loss: 2.1188824052427533
Validation loss: 2.557547637393869

Epoch: 5| Step: 4
Training loss: 2.5021681920213377
Validation loss: 2.562329685940145

Epoch: 5| Step: 5
Training loss: 2.0849045614084796
Validation loss: 2.5390544245664852

Epoch: 5| Step: 6
Training loss: 1.4643425249250788
Validation loss: 2.5738794337589184

Epoch: 5| Step: 7
Training loss: 1.8881765858214599
Validation loss: 2.5771451995586423

Epoch: 5| Step: 8
Training loss: 2.430038672088463
Validation loss: 2.599631626827809

Epoch: 5| Step: 9
Training loss: 2.1216297350613593
Validation loss: 2.617976146700071

Epoch: 5| Step: 10
Training loss: 1.3979993592016582
Validation loss: 2.636845127420837

Epoch: 5| Step: 11
Training loss: 1.8031445136906825
Validation loss: 2.6320504237377063

Epoch: 328| Step: 0
Training loss: 2.3083425730532965
Validation loss: 2.66440526373738

Epoch: 5| Step: 1
Training loss: 2.478308510449724
Validation loss: 2.6596679911605583

Epoch: 5| Step: 2
Training loss: 2.5903241616721884
Validation loss: 2.6350281369940713

Epoch: 5| Step: 3
Training loss: 1.563081175484554
Validation loss: 2.658717430601559

Epoch: 5| Step: 4
Training loss: 2.3577759231147017
Validation loss: 2.5901298422467383

Epoch: 5| Step: 5
Training loss: 1.4546829403847799
Validation loss: 2.5989248060817247

Epoch: 5| Step: 6
Training loss: 1.7355340744669534
Validation loss: 2.6127849310923175

Epoch: 5| Step: 7
Training loss: 1.6544726209729776
Validation loss: 2.598154938902857

Epoch: 5| Step: 8
Training loss: 1.868705483611251
Validation loss: 2.5853658315090886

Epoch: 5| Step: 9
Training loss: 1.9185623524514757
Validation loss: 2.596472858303747

Epoch: 5| Step: 10
Training loss: 2.2872572931658524
Validation loss: 2.609678692381622

Epoch: 5| Step: 11
Training loss: 2.295774858102745
Validation loss: 2.584589696266779

Epoch: 329| Step: 0
Training loss: 1.5800841606034293
Validation loss: 2.568501914049321

Epoch: 5| Step: 1
Training loss: 2.4596484486665635
Validation loss: 2.5508094462792825

Epoch: 5| Step: 2
Training loss: 2.0647169971278774
Validation loss: 2.5373206125313206

Epoch: 5| Step: 3
Training loss: 1.6886212191549637
Validation loss: 2.539736446044925

Epoch: 5| Step: 4
Training loss: 1.6851819683264715
Validation loss: 2.5591328332064656

Epoch: 5| Step: 5
Training loss: 2.34000402548028
Validation loss: 2.568339830524842

Epoch: 5| Step: 6
Training loss: 2.0199588050040957
Validation loss: 2.586744545566305

Epoch: 5| Step: 7
Training loss: 1.664039504201255
Validation loss: 2.599588154764214

Epoch: 5| Step: 8
Training loss: 2.3649063449889187
Validation loss: 2.6290494625690717

Epoch: 5| Step: 9
Training loss: 2.294298660392455
Validation loss: 2.655473625565449

Epoch: 5| Step: 10
Training loss: 2.220416450617398
Validation loss: 2.6486914521389964

Epoch: 5| Step: 11
Training loss: 2.3299554375246814
Validation loss: 2.6161544582967253

Epoch: 330| Step: 0
Training loss: 2.155066344972449
Validation loss: 2.6150431184392717

Epoch: 5| Step: 1
Training loss: 1.776214777619396
Validation loss: 2.645537255959886

Epoch: 5| Step: 2
Training loss: 2.572091828820466
Validation loss: 2.675829238646907

Epoch: 5| Step: 3
Training loss: 2.423142427623341
Validation loss: 2.624144206493546

Epoch: 5| Step: 4
Training loss: 2.1443188949534524
Validation loss: 2.604643977609591

Epoch: 5| Step: 5
Training loss: 1.431216063784267
Validation loss: 2.5841361626226336

Epoch: 5| Step: 6
Training loss: 2.3209852277358776
Validation loss: 2.5432197888324017

Epoch: 5| Step: 7
Training loss: 1.5735504018967967
Validation loss: 2.5312001729699904

Epoch: 5| Step: 8
Training loss: 2.4449565981891803
Validation loss: 2.510533343303833

Epoch: 5| Step: 9
Training loss: 1.5843889164360467
Validation loss: 2.5179407190586724

Epoch: 5| Step: 10
Training loss: 1.8611013268297396
Validation loss: 2.537322861810414

Epoch: 5| Step: 11
Training loss: 1.243730558310527
Validation loss: 2.5338955582115985

Epoch: 331| Step: 0
Training loss: 1.898958487902154
Validation loss: 2.5660966776455023

Epoch: 5| Step: 1
Training loss: 1.866973162363671
Validation loss: 2.5653898412472844

Epoch: 5| Step: 2
Training loss: 1.7916255399138534
Validation loss: 2.6083683577269072

Epoch: 5| Step: 3
Training loss: 1.9653041292662223
Validation loss: 2.6384603404751883

Epoch: 5| Step: 4
Training loss: 1.8347309449564695
Validation loss: 2.635794493137509

Epoch: 5| Step: 5
Training loss: 1.3759378356032144
Validation loss: 2.646552796552677

Epoch: 5| Step: 6
Training loss: 1.793807687396674
Validation loss: 2.638609229642345

Epoch: 5| Step: 7
Training loss: 2.7625973610960597
Validation loss: 2.6103914854586203

Epoch: 5| Step: 8
Training loss: 2.3465045255580383
Validation loss: 2.6188401996492026

Epoch: 5| Step: 9
Training loss: 2.5981589841879766
Validation loss: 2.5913719398083375

Epoch: 5| Step: 10
Training loss: 2.1668954752880847
Validation loss: 2.559714078352662

Epoch: 5| Step: 11
Training loss: 1.0815191606437111
Validation loss: 2.5429852236572086

Epoch: 332| Step: 0
Training loss: 2.053486171871836
Validation loss: 2.5344391833894435

Epoch: 5| Step: 1
Training loss: 3.0558261944143275
Validation loss: 2.5427323020004353

Epoch: 5| Step: 2
Training loss: 2.219769525678589
Validation loss: 2.546521963914982

Epoch: 5| Step: 3
Training loss: 2.027431008403356
Validation loss: 2.57561527203768

Epoch: 5| Step: 4
Training loss: 2.164735324530127
Validation loss: 2.5583900195830074

Epoch: 5| Step: 5
Training loss: 1.6984943819040135
Validation loss: 2.5659039846342298

Epoch: 5| Step: 6
Training loss: 1.6274619892328377
Validation loss: 2.5981581047787037

Epoch: 5| Step: 7
Training loss: 1.7524799078035813
Validation loss: 2.6238733363926277

Epoch: 5| Step: 8
Training loss: 1.8475359823106605
Validation loss: 2.627411661698669

Epoch: 5| Step: 9
Training loss: 1.79242626618454
Validation loss: 2.6265885110687055

Epoch: 5| Step: 10
Training loss: 2.1920761199737746
Validation loss: 2.639802424655015

Epoch: 5| Step: 11
Training loss: 1.4978216566462137
Validation loss: 2.6238787542201214

Epoch: 333| Step: 0
Training loss: 1.8234717332360846
Validation loss: 2.629363966268014

Epoch: 5| Step: 1
Training loss: 2.3913647872086994
Validation loss: 2.591544546508792

Epoch: 5| Step: 2
Training loss: 2.0715921154198473
Validation loss: 2.6058018617759693

Epoch: 5| Step: 3
Training loss: 1.8207343926452868
Validation loss: 2.5559654500284816

Epoch: 5| Step: 4
Training loss: 1.9030601202267652
Validation loss: 2.5758382037916965

Epoch: 5| Step: 5
Training loss: 1.416500287477065
Validation loss: 2.577381209769698

Epoch: 5| Step: 6
Training loss: 1.933859388812023
Validation loss: 2.577192072217677

Epoch: 5| Step: 7
Training loss: 2.778291478870592
Validation loss: 2.571448873983444

Epoch: 5| Step: 8
Training loss: 2.205931911285796
Validation loss: 2.584019375018852

Epoch: 5| Step: 9
Training loss: 2.296799950444013
Validation loss: 2.5906252096779636

Epoch: 5| Step: 10
Training loss: 1.8175516434459345
Validation loss: 2.590026889269296

Epoch: 5| Step: 11
Training loss: 1.5417883111886483
Validation loss: 2.6473175351451137

Epoch: 334| Step: 0
Training loss: 1.803039591070527
Validation loss: 2.629778814968629

Epoch: 5| Step: 1
Training loss: 1.591354514598049
Validation loss: 2.6080949617020126

Epoch: 5| Step: 2
Training loss: 2.151452629480983
Validation loss: 2.602274948946772

Epoch: 5| Step: 3
Training loss: 2.010998050516133
Validation loss: 2.6344870949604853

Epoch: 5| Step: 4
Training loss: 2.406414472235117
Validation loss: 2.600870699159307

Epoch: 5| Step: 5
Training loss: 2.104890252013739
Validation loss: 2.5980301475569516

Epoch: 5| Step: 6
Training loss: 1.6342070980150836
Validation loss: 2.5925588783621487

Epoch: 5| Step: 7
Training loss: 2.0843065150504234
Validation loss: 2.6012745927995167

Epoch: 5| Step: 8
Training loss: 1.7569909104278747
Validation loss: 2.603606016207275

Epoch: 5| Step: 9
Training loss: 2.0159292065436967
Validation loss: 2.5905074759753854

Epoch: 5| Step: 10
Training loss: 2.504098298657055
Validation loss: 2.5894190812646003

Epoch: 5| Step: 11
Training loss: 1.868512692901152
Validation loss: 2.5929967904976388

Epoch: 335| Step: 0
Training loss: 1.900715971616404
Validation loss: 2.5522786253860446

Epoch: 5| Step: 1
Training loss: 2.4491282177122606
Validation loss: 2.5591515241286937

Epoch: 5| Step: 2
Training loss: 1.4218108613356375
Validation loss: 2.5297148213158955

Epoch: 5| Step: 3
Training loss: 2.393472608624311
Validation loss: 2.5443269742292096

Epoch: 5| Step: 4
Training loss: 1.8189812896588315
Validation loss: 2.566055699701061

Epoch: 5| Step: 5
Training loss: 2.6467321075817627
Validation loss: 2.540647080729409

Epoch: 5| Step: 6
Training loss: 1.8062791287406474
Validation loss: 2.567223185165268

Epoch: 5| Step: 7
Training loss: 2.008215006696882
Validation loss: 2.585101719582122

Epoch: 5| Step: 8
Training loss: 1.5388039308791777
Validation loss: 2.620363314671772

Epoch: 5| Step: 9
Training loss: 2.493802112618039
Validation loss: 2.651319318120278

Epoch: 5| Step: 10
Training loss: 1.6236902974512577
Validation loss: 2.6321862907034013

Epoch: 5| Step: 11
Training loss: 1.8140908855941256
Validation loss: 2.6429227804872717

Epoch: 336| Step: 0
Training loss: 2.697372136095106
Validation loss: 2.636502081363502

Epoch: 5| Step: 1
Training loss: 1.5823671337594816
Validation loss: 2.649074798470835

Epoch: 5| Step: 2
Training loss: 2.264267402891199
Validation loss: 2.6159103541738613

Epoch: 5| Step: 3
Training loss: 1.730510427003235
Validation loss: 2.573312027602948

Epoch: 5| Step: 4
Training loss: 2.0730672682554605
Validation loss: 2.6004702057288376

Epoch: 5| Step: 5
Training loss: 2.0551264188914833
Validation loss: 2.5689070549170068

Epoch: 5| Step: 6
Training loss: 1.7422688555004366
Validation loss: 2.5432349874781526

Epoch: 5| Step: 7
Training loss: 1.7451975867435505
Validation loss: 2.5494517765515616

Epoch: 5| Step: 8
Training loss: 2.2288366649848768
Validation loss: 2.561035536386312

Epoch: 5| Step: 9
Training loss: 2.1325419607204448
Validation loss: 2.5478068287261997

Epoch: 5| Step: 10
Training loss: 1.9884696226689256
Validation loss: 2.549259376338545

Epoch: 5| Step: 11
Training loss: 1.8810317613109426
Validation loss: 2.5827193793225507

Epoch: 337| Step: 0
Training loss: 1.6048758866995276
Validation loss: 2.5654399064732614

Epoch: 5| Step: 1
Training loss: 2.111910504135539
Validation loss: 2.6120712071357013

Epoch: 5| Step: 2
Training loss: 2.0634988620201247
Validation loss: 2.6134300322629134

Epoch: 5| Step: 3
Training loss: 1.7143915575140896
Validation loss: 2.645576758722524

Epoch: 5| Step: 4
Training loss: 1.478506433415534
Validation loss: 2.629866932281435

Epoch: 5| Step: 5
Training loss: 2.2173520909538857
Validation loss: 2.6149207362275395

Epoch: 5| Step: 6
Training loss: 2.4756093402185244
Validation loss: 2.6163575028253954

Epoch: 5| Step: 7
Training loss: 2.183684045224697
Validation loss: 2.586451726150421

Epoch: 5| Step: 8
Training loss: 2.4406699084889314
Validation loss: 2.5863685709607136

Epoch: 5| Step: 9
Training loss: 1.7587995004635437
Validation loss: 2.581977231936605

Epoch: 5| Step: 10
Training loss: 2.1772770285948515
Validation loss: 2.5826648121460183

Epoch: 5| Step: 11
Training loss: 1.2583032918127117
Validation loss: 2.578106365714499

Epoch: 338| Step: 0
Training loss: 1.8202962588130078
Validation loss: 2.593546449571709

Epoch: 5| Step: 1
Training loss: 2.1829958730143995
Validation loss: 2.5703822960309974

Epoch: 5| Step: 2
Training loss: 1.7457581609354653
Validation loss: 2.5624342111345455

Epoch: 5| Step: 3
Training loss: 2.356474856062211
Validation loss: 2.5639493611612383

Epoch: 5| Step: 4
Training loss: 1.9344210001416922
Validation loss: 2.5621767111505087

Epoch: 5| Step: 5
Training loss: 1.338316689471309
Validation loss: 2.56495396259826

Epoch: 5| Step: 6
Training loss: 1.8969521696931089
Validation loss: 2.575425941151466

Epoch: 5| Step: 7
Training loss: 1.7466513065701363
Validation loss: 2.563487037273986

Epoch: 5| Step: 8
Training loss: 1.957186694643725
Validation loss: 2.624969947733741

Epoch: 5| Step: 9
Training loss: 2.692404153688769
Validation loss: 2.6421042480527293

Epoch: 5| Step: 10
Training loss: 1.6258937138709073
Validation loss: 2.6694407481875735

Epoch: 5| Step: 11
Training loss: 3.52891341692805
Validation loss: 2.7132780358254927

Epoch: 339| Step: 0
Training loss: 2.5788371634163876
Validation loss: 2.7041633757780374

Epoch: 5| Step: 1
Training loss: 2.4783981692211956
Validation loss: 2.732164537601723

Epoch: 5| Step: 2
Training loss: 1.3365094483081181
Validation loss: 2.6574054299385472

Epoch: 5| Step: 3
Training loss: 2.0476993909917343
Validation loss: 2.6015383993260124

Epoch: 5| Step: 4
Training loss: 1.8070340444738646
Validation loss: 2.543256480653421

Epoch: 5| Step: 5
Training loss: 2.1537955868989203
Validation loss: 2.5296506676006056

Epoch: 5| Step: 6
Training loss: 2.0349700901167265
Validation loss: 2.5020049023041495

Epoch: 5| Step: 7
Training loss: 1.7532248755851965
Validation loss: 2.4998394954338488

Epoch: 5| Step: 8
Training loss: 2.2311171676461505
Validation loss: 2.4820432076522834

Epoch: 5| Step: 9
Training loss: 2.234967133282507
Validation loss: 2.4792089772554218

Epoch: 5| Step: 10
Training loss: 2.514868391472648
Validation loss: 2.465964377446971

Epoch: 5| Step: 11
Training loss: 2.168818017074398
Validation loss: 2.477631373346627

Epoch: 340| Step: 0
Training loss: 2.2333225359110043
Validation loss: 2.5107144671145942

Epoch: 5| Step: 1
Training loss: 1.8165014098477215
Validation loss: 2.59578113615686

Epoch: 5| Step: 2
Training loss: 2.1895545030819745
Validation loss: 2.6814661379043025

Epoch: 5| Step: 3
Training loss: 1.9846401488010752
Validation loss: 2.71878279377536

Epoch: 5| Step: 4
Training loss: 1.6354198172310126
Validation loss: 2.7697955724127468

Epoch: 5| Step: 5
Training loss: 2.037041843132489
Validation loss: 2.832939251439716

Epoch: 5| Step: 6
Training loss: 2.164690387955748
Validation loss: 2.8397127074904898

Epoch: 5| Step: 7
Training loss: 1.9958936736582618
Validation loss: 2.7957813284159445

Epoch: 5| Step: 8
Training loss: 2.2893896292287526
Validation loss: 2.731608355368963

Epoch: 5| Step: 9
Training loss: 2.3443874255272865
Validation loss: 2.6394704518095957

Epoch: 5| Step: 10
Training loss: 2.232636742585058
Validation loss: 2.5668356916942585

Epoch: 5| Step: 11
Training loss: 2.8099451965200832
Validation loss: 2.5235298698848907

Epoch: 341| Step: 0
Training loss: 2.2003652182787827
Validation loss: 2.5333583512660347

Epoch: 5| Step: 1
Training loss: 2.282234084149993
Validation loss: 2.5175192219127585

Epoch: 5| Step: 2
Training loss: 2.1768441198120847
Validation loss: 2.5028404709117518

Epoch: 5| Step: 3
Training loss: 2.611195186406729
Validation loss: 2.513897336122524

Epoch: 5| Step: 4
Training loss: 2.289344744158245
Validation loss: 2.506508762639809

Epoch: 5| Step: 5
Training loss: 2.4152429157607664
Validation loss: 2.5127513418166534

Epoch: 5| Step: 6
Training loss: 2.184374729314741
Validation loss: 2.500955693044781

Epoch: 5| Step: 7
Training loss: 2.262401523870686
Validation loss: 2.5075196424952875

Epoch: 5| Step: 8
Training loss: 1.969182042747818
Validation loss: 2.501040397166023

Epoch: 5| Step: 9
Training loss: 1.8423028212569132
Validation loss: 2.5434144152540332

Epoch: 5| Step: 10
Training loss: 1.466728442509438
Validation loss: 2.5564234568249162

Epoch: 5| Step: 11
Training loss: 1.180240223726727
Validation loss: 2.6218331398424204

Epoch: 342| Step: 0
Training loss: 2.5131679880544477
Validation loss: 2.634266467892478

Epoch: 5| Step: 1
Training loss: 2.078411914264751
Validation loss: 2.652973780012493

Epoch: 5| Step: 2
Training loss: 1.9042270745420744
Validation loss: 2.654516140393725

Epoch: 5| Step: 3
Training loss: 1.9222681527294585
Validation loss: 2.6244180692775716

Epoch: 5| Step: 4
Training loss: 1.646772945361758
Validation loss: 2.5884015846854096

Epoch: 5| Step: 5
Training loss: 2.152422839475325
Validation loss: 2.5860681414377744

Epoch: 5| Step: 6
Training loss: 2.290801965973565
Validation loss: 2.58480769175015

Epoch: 5| Step: 7
Training loss: 2.452882888411902
Validation loss: 2.5617906084730793

Epoch: 5| Step: 8
Training loss: 1.8186697034381634
Validation loss: 2.5397190008208272

Epoch: 5| Step: 9
Training loss: 1.9238038347134065
Validation loss: 2.5316237931098358

Epoch: 5| Step: 10
Training loss: 1.8259316352673016
Validation loss: 2.538621404431496

Epoch: 5| Step: 11
Training loss: 1.2787006415632445
Validation loss: 2.540400007044286

Epoch: 343| Step: 0
Training loss: 1.2878285368467235
Validation loss: 2.525482081669735

Epoch: 5| Step: 1
Training loss: 1.5522129934885036
Validation loss: 2.5618455485313567

Epoch: 5| Step: 2
Training loss: 1.3456117906289733
Validation loss: 2.552761821993291

Epoch: 5| Step: 3
Training loss: 2.18102351983081
Validation loss: 2.5699148479225857

Epoch: 5| Step: 4
Training loss: 1.7925311450034822
Validation loss: 2.597848534219601

Epoch: 5| Step: 5
Training loss: 1.9130664335681067
Validation loss: 2.6324105904005153

Epoch: 5| Step: 6
Training loss: 2.3712480925299455
Validation loss: 2.6159447789359604

Epoch: 5| Step: 7
Training loss: 2.692472780846288
Validation loss: 2.6289342431915688

Epoch: 5| Step: 8
Training loss: 2.398187381985864
Validation loss: 2.5877101696124494

Epoch: 5| Step: 9
Training loss: 1.7048609574527849
Validation loss: 2.584527721451435

Epoch: 5| Step: 10
Training loss: 2.296547483591591
Validation loss: 2.5803838486640074

Epoch: 5| Step: 11
Training loss: 2.7657269820036747
Validation loss: 2.58657696472747

Epoch: 344| Step: 0
Training loss: 1.8079788118319315
Validation loss: 2.556626314259638

Epoch: 5| Step: 1
Training loss: 2.025044160526209
Validation loss: 2.5555882610915353

Epoch: 5| Step: 2
Training loss: 2.1793792397250265
Validation loss: 2.557137146041091

Epoch: 5| Step: 3
Training loss: 2.2523712802227274
Validation loss: 2.551607676703927

Epoch: 5| Step: 4
Training loss: 1.7596481571937836
Validation loss: 2.5282411156493887

Epoch: 5| Step: 5
Training loss: 1.2353146513600026
Validation loss: 2.5553768056284567

Epoch: 5| Step: 6
Training loss: 1.8901862273732744
Validation loss: 2.5532093496408126

Epoch: 5| Step: 7
Training loss: 2.409451819158801
Validation loss: 2.539652477091917

Epoch: 5| Step: 8
Training loss: 2.2069839337433494
Validation loss: 2.5353278213226735

Epoch: 5| Step: 9
Training loss: 1.7869624843576624
Validation loss: 2.5379201891915426

Epoch: 5| Step: 10
Training loss: 2.1340758665590442
Validation loss: 2.5719181058723675

Epoch: 5| Step: 11
Training loss: 1.1727533736089952
Validation loss: 2.57070149431929

Epoch: 345| Step: 0
Training loss: 2.1941827330947024
Validation loss: 2.565006631200645

Epoch: 5| Step: 1
Training loss: 1.801413865587421
Validation loss: 2.5869656734423145

Epoch: 5| Step: 2
Training loss: 1.48856701447795
Validation loss: 2.5669722491786473

Epoch: 5| Step: 3
Training loss: 2.3129046318095234
Validation loss: 2.6133628494151258

Epoch: 5| Step: 4
Training loss: 2.3236028800960953
Validation loss: 2.5975471875234195

Epoch: 5| Step: 5
Training loss: 2.0821002998854206
Validation loss: 2.557988354838849

Epoch: 5| Step: 6
Training loss: 1.9592794878737396
Validation loss: 2.5633043096889265

Epoch: 5| Step: 7
Training loss: 2.1336760955866017
Validation loss: 2.5484664796841714

Epoch: 5| Step: 8
Training loss: 1.5890335905583013
Validation loss: 2.5234321302862677

Epoch: 5| Step: 9
Training loss: 1.7400335159581597
Validation loss: 2.540253595573444

Epoch: 5| Step: 10
Training loss: 2.255300953103289
Validation loss: 2.5369541080568374

Epoch: 5| Step: 11
Training loss: 2.6434856922966685
Validation loss: 2.5243972433428863

Epoch: 346| Step: 0
Training loss: 2.454745783802906
Validation loss: 2.61190260029797

Epoch: 5| Step: 1
Training loss: 1.737018323587544
Validation loss: 2.6621863208751275

Epoch: 5| Step: 2
Training loss: 2.169612556887329
Validation loss: 2.7831991202342348

Epoch: 5| Step: 3
Training loss: 1.8544555467598698
Validation loss: 2.805320409770924

Epoch: 5| Step: 4
Training loss: 2.881780506869062
Validation loss: 2.8516060429562495

Epoch: 5| Step: 5
Training loss: 2.025096551924549
Validation loss: 2.7800864775503906

Epoch: 5| Step: 6
Training loss: 1.6761080905545842
Validation loss: 2.7338193601365792

Epoch: 5| Step: 7
Training loss: 2.193107176061708
Validation loss: 2.6124159820711337

Epoch: 5| Step: 8
Training loss: 1.8479843654796901
Validation loss: 2.550062478459456

Epoch: 5| Step: 9
Training loss: 2.0936193852464067
Validation loss: 2.501603698947173

Epoch: 5| Step: 10
Training loss: 2.1795297654480703
Validation loss: 2.497864363353164

Epoch: 5| Step: 11
Training loss: 1.5349930926487487
Validation loss: 2.4716450500271825

Epoch: 347| Step: 0
Training loss: 2.147371228657158
Validation loss: 2.4768177265980134

Epoch: 5| Step: 1
Training loss: 2.2802016057007726
Validation loss: 2.4839491649167225

Epoch: 5| Step: 2
Training loss: 2.1954977697206037
Validation loss: 2.483785491354454

Epoch: 5| Step: 3
Training loss: 1.6294394519204989
Validation loss: 2.465281947823402

Epoch: 5| Step: 4
Training loss: 2.449585030893576
Validation loss: 2.493920898318

Epoch: 5| Step: 5
Training loss: 2.0791193368706526
Validation loss: 2.4840119174534716

Epoch: 5| Step: 6
Training loss: 2.333804378192694
Validation loss: 2.5289714274916055

Epoch: 5| Step: 7
Training loss: 2.049984848152549
Validation loss: 2.523954092555643

Epoch: 5| Step: 8
Training loss: 2.4433668885088813
Validation loss: 2.5868188771638057

Epoch: 5| Step: 9
Training loss: 1.6187520590515003
Validation loss: 2.601830702542117

Epoch: 5| Step: 10
Training loss: 1.6579904588394903
Validation loss: 2.6450697868445516

Epoch: 5| Step: 11
Training loss: 2.6224150873188923
Validation loss: 2.701849796513817

Epoch: 348| Step: 0
Training loss: 1.8897220567660216
Validation loss: 2.710149846638013

Epoch: 5| Step: 1
Training loss: 1.9723718419280911
Validation loss: 2.7467592824749727

Epoch: 5| Step: 2
Training loss: 2.2458006559789014
Validation loss: 2.760117368247004

Epoch: 5| Step: 3
Training loss: 2.131131582242471
Validation loss: 2.7752197664031706

Epoch: 5| Step: 4
Training loss: 2.2337991465929377
Validation loss: 2.760084435725147

Epoch: 5| Step: 5
Training loss: 2.2734271177074463
Validation loss: 2.659122634072047

Epoch: 5| Step: 6
Training loss: 2.681825724504441
Validation loss: 2.6430028182707614

Epoch: 5| Step: 7
Training loss: 1.8320470618112636
Validation loss: 2.6397291503488933

Epoch: 5| Step: 8
Training loss: 2.0756256447193464
Validation loss: 2.6086380235712268

Epoch: 5| Step: 9
Training loss: 1.7264122530780779
Validation loss: 2.5720329092502543

Epoch: 5| Step: 10
Training loss: 1.5649789600359567
Validation loss: 2.5570544361369043

Epoch: 5| Step: 11
Training loss: 2.5623797876957277
Validation loss: 2.5793737335054074

Epoch: 349| Step: 0
Training loss: 2.3557521466125273
Validation loss: 2.5547262766283754

Epoch: 5| Step: 1
Training loss: 2.2750733248453447
Validation loss: 2.574505679512192

Epoch: 5| Step: 2
Training loss: 2.058061389745204
Validation loss: 2.582156887643188

Epoch: 5| Step: 3
Training loss: 2.166188651931506
Validation loss: 2.568910655143628

Epoch: 5| Step: 4
Training loss: 2.089166891703868
Validation loss: 2.5517558036880965

Epoch: 5| Step: 5
Training loss: 1.8802112639202693
Validation loss: 2.5895337110528547

Epoch: 5| Step: 6
Training loss: 2.1072592968669466
Validation loss: 2.597971208260388

Epoch: 5| Step: 7
Training loss: 2.4716645432109634
Validation loss: 2.608290406920995

Epoch: 5| Step: 8
Training loss: 1.7357522805578192
Validation loss: 2.605822694024973

Epoch: 5| Step: 9
Training loss: 1.448486554447827
Validation loss: 2.5952356710283064

Epoch: 5| Step: 10
Training loss: 1.7834293351522077
Validation loss: 2.5465659595677748

Epoch: 5| Step: 11
Training loss: 1.0003218728853547
Validation loss: 2.577274579132405

Epoch: 350| Step: 0
Training loss: 2.10750581788044
Validation loss: 2.5757719148314937

Epoch: 5| Step: 1
Training loss: 1.3731593035795964
Validation loss: 2.568884575622075

Epoch: 5| Step: 2
Training loss: 1.8393749765648226
Validation loss: 2.5600812281509517

Epoch: 5| Step: 3
Training loss: 1.6385928693055853
Validation loss: 2.562337513555944

Epoch: 5| Step: 4
Training loss: 2.447724441664498
Validation loss: 2.5772471368663807

Epoch: 5| Step: 5
Training loss: 1.7251154847118646
Validation loss: 2.575200805735356

Epoch: 5| Step: 6
Training loss: 2.0227806173894454
Validation loss: 2.6195437703988653

Epoch: 5| Step: 7
Training loss: 1.9430425184332254
Validation loss: 2.6129188685488245

Epoch: 5| Step: 8
Training loss: 2.585027436603322
Validation loss: 2.589243190632303

Epoch: 5| Step: 9
Training loss: 1.9194635288463198
Validation loss: 2.6125735401833396

Epoch: 5| Step: 10
Training loss: 2.1967111930714474
Validation loss: 2.61665550252837

Epoch: 5| Step: 11
Training loss: 1.2838896565306865
Validation loss: 2.642856178212941

Epoch: 351| Step: 0
Training loss: 2.1639468165576843
Validation loss: 2.649189410004532

Epoch: 5| Step: 1
Training loss: 1.9476394524062235
Validation loss: 2.6702612489350814

Epoch: 5| Step: 2
Training loss: 1.8919479533490773
Validation loss: 2.6537181755789465

Epoch: 5| Step: 3
Training loss: 1.8667172274667545
Validation loss: 2.680490421677122

Epoch: 5| Step: 4
Training loss: 1.3929379548045413
Validation loss: 2.6560314200730253

Epoch: 5| Step: 5
Training loss: 2.076659295184838
Validation loss: 2.664826858662313

Epoch: 5| Step: 6
Training loss: 1.9658805280806475
Validation loss: 2.635435226184092

Epoch: 5| Step: 7
Training loss: 2.2690561555627413
Validation loss: 2.626323856206139

Epoch: 5| Step: 8
Training loss: 1.1701986911986078
Validation loss: 2.56026134940707

Epoch: 5| Step: 9
Training loss: 2.164952174444751
Validation loss: 2.533440878011697

Epoch: 5| Step: 10
Training loss: 2.3108418680229006
Validation loss: 2.570980908832767

Epoch: 5| Step: 11
Training loss: 3.182290551184892
Validation loss: 2.5398959899680347

Epoch: 352| Step: 0
Training loss: 2.3440401024886914
Validation loss: 2.537230763065533

Epoch: 5| Step: 1
Training loss: 2.1320377941038147
Validation loss: 2.543984541831546

Epoch: 5| Step: 2
Training loss: 2.0936740462917047
Validation loss: 2.5710760990148573

Epoch: 5| Step: 3
Training loss: 2.3587963076656555
Validation loss: 2.601085439631188

Epoch: 5| Step: 4
Training loss: 1.6835499910478386
Validation loss: 2.6024606813385494

Epoch: 5| Step: 5
Training loss: 1.2880886213782217
Validation loss: 2.634326816267518

Epoch: 5| Step: 6
Training loss: 1.825893376783696
Validation loss: 2.6437115020894892

Epoch: 5| Step: 7
Training loss: 2.274469724623469
Validation loss: 2.6565815961715558

Epoch: 5| Step: 8
Training loss: 2.2865707844835272
Validation loss: 2.6410575452243332

Epoch: 5| Step: 9
Training loss: 1.5093107537601445
Validation loss: 2.6239289604038176

Epoch: 5| Step: 10
Training loss: 1.9796824201535248
Validation loss: 2.572933962734224

Epoch: 5| Step: 11
Training loss: 1.2181423824473434
Validation loss: 2.5510643397411825

Epoch: 353| Step: 0
Training loss: 1.7188874623208406
Validation loss: 2.5578917455155685

Epoch: 5| Step: 1
Training loss: 1.9375497134814152
Validation loss: 2.5416542050311497

Epoch: 5| Step: 2
Training loss: 2.2523649290784733
Validation loss: 2.5209961725609693

Epoch: 5| Step: 3
Training loss: 2.179363814626903
Validation loss: 2.528672475834882

Epoch: 5| Step: 4
Training loss: 1.8089787709860428
Validation loss: 2.532552109483786

Epoch: 5| Step: 5
Training loss: 1.8966255489019974
Validation loss: 2.5350999948366133

Epoch: 5| Step: 6
Training loss: 2.01232355896288
Validation loss: 2.5881855999281123

Epoch: 5| Step: 7
Training loss: 2.170548287663647
Validation loss: 2.595030296273783

Epoch: 5| Step: 8
Training loss: 1.8936437041914913
Validation loss: 2.563316228787394

Epoch: 5| Step: 9
Training loss: 2.0890160178104087
Validation loss: 2.577996915467683

Epoch: 5| Step: 10
Training loss: 1.9054959165819148
Validation loss: 2.5603166637233925

Epoch: 5| Step: 11
Training loss: 1.6865145313621965
Validation loss: 2.5874952558882462

Epoch: 354| Step: 0
Training loss: 2.6919608243781283
Validation loss: 2.535668876242633

Epoch: 5| Step: 1
Training loss: 1.6572324609960585
Validation loss: 2.537415593408064

Epoch: 5| Step: 2
Training loss: 1.8102973840162422
Validation loss: 2.53110200739749

Epoch: 5| Step: 3
Training loss: 1.5834977499605893
Validation loss: 2.533224567998064

Epoch: 5| Step: 4
Training loss: 1.9552709768262848
Validation loss: 2.534957662444543

Epoch: 5| Step: 5
Training loss: 1.6138937020827346
Validation loss: 2.541472788488004

Epoch: 5| Step: 6
Training loss: 2.851340758180736
Validation loss: 2.5569597457459223

Epoch: 5| Step: 7
Training loss: 1.975293803996338
Validation loss: 2.5681255935231304

Epoch: 5| Step: 8
Training loss: 1.649949379346754
Validation loss: 2.555339352876895

Epoch: 5| Step: 9
Training loss: 1.4090584579210137
Validation loss: 2.5471010088347597

Epoch: 5| Step: 10
Training loss: 2.0258230632405017
Validation loss: 2.5620838753947885

Epoch: 5| Step: 11
Training loss: 2.3616831018077464
Validation loss: 2.552017192891781

Epoch: 355| Step: 0
Training loss: 1.8186280147373592
Validation loss: 2.6471890645643046

Epoch: 5| Step: 1
Training loss: 1.862002463739652
Validation loss: 2.7255842208173506

Epoch: 5| Step: 2
Training loss: 2.0127663856628755
Validation loss: 2.8010884554979216

Epoch: 5| Step: 3
Training loss: 2.5513201344413368
Validation loss: 2.8337816077792986

Epoch: 5| Step: 4
Training loss: 2.1493258772303427
Validation loss: 2.85244271266826

Epoch: 5| Step: 5
Training loss: 1.9745346945687083
Validation loss: 2.7985701547459736

Epoch: 5| Step: 6
Training loss: 1.951640426997946
Validation loss: 2.7094866949961904

Epoch: 5| Step: 7
Training loss: 2.2954594408630307
Validation loss: 2.6436985757875124

Epoch: 5| Step: 8
Training loss: 2.721275296809904
Validation loss: 2.597804191028773

Epoch: 5| Step: 9
Training loss: 1.4606739969323514
Validation loss: 2.5395497993986136

Epoch: 5| Step: 10
Training loss: 1.8010104151482333
Validation loss: 2.531291360870395

Epoch: 5| Step: 11
Training loss: 0.914432483360281
Validation loss: 2.5323459662313605

Epoch: 356| Step: 0
Training loss: 2.428677560586901
Validation loss: 2.549936724326508

Epoch: 5| Step: 1
Training loss: 1.9608340901012504
Validation loss: 2.521020871797417

Epoch: 5| Step: 2
Training loss: 1.4457349829885793
Validation loss: 2.540449090539771

Epoch: 5| Step: 3
Training loss: 1.353670185726739
Validation loss: 2.565544800583229

Epoch: 5| Step: 4
Training loss: 1.5976407299826858
Validation loss: 2.548984784881649

Epoch: 5| Step: 5
Training loss: 2.3129318452681895
Validation loss: 2.575572258590484

Epoch: 5| Step: 6
Training loss: 2.3918023295809925
Validation loss: 2.5632758284192394

Epoch: 5| Step: 7
Training loss: 2.3613734591970093
Validation loss: 2.6326645112446223

Epoch: 5| Step: 8
Training loss: 2.0502713977453917
Validation loss: 2.625451336766795

Epoch: 5| Step: 9
Training loss: 1.7386806757782836
Validation loss: 2.6353190420310737

Epoch: 5| Step: 10
Training loss: 2.0468039463901997
Validation loss: 2.6655440177705763

Epoch: 5| Step: 11
Training loss: 2.2402771577350062
Validation loss: 2.6552271425626817

Epoch: 357| Step: 0
Training loss: 1.4045528767438185
Validation loss: 2.6207454770276084

Epoch: 5| Step: 1
Training loss: 1.8289789666895164
Validation loss: 2.5968197003783575

Epoch: 5| Step: 2
Training loss: 2.3068913671532503
Validation loss: 2.5608712075082285

Epoch: 5| Step: 3
Training loss: 1.8412555048614896
Validation loss: 2.543460728039749

Epoch: 5| Step: 4
Training loss: 1.5231975659915966
Validation loss: 2.5615241355764153

Epoch: 5| Step: 5
Training loss: 1.454667370059726
Validation loss: 2.5315871857913166

Epoch: 5| Step: 6
Training loss: 2.676056384121249
Validation loss: 2.5374747295405413

Epoch: 5| Step: 7
Training loss: 2.0526315824866455
Validation loss: 2.5618762831177904

Epoch: 5| Step: 8
Training loss: 2.1774528834679523
Validation loss: 2.566265231999479

Epoch: 5| Step: 9
Training loss: 1.9075914884452962
Validation loss: 2.5865303888832187

Epoch: 5| Step: 10
Training loss: 2.1242618400690017
Validation loss: 2.5995708054782143

Epoch: 5| Step: 11
Training loss: 2.9528267523108425
Validation loss: 2.6040862465203034

Epoch: 358| Step: 0
Training loss: 1.9690598138119784
Validation loss: 2.6078575046587966

Epoch: 5| Step: 1
Training loss: 2.0136719933999117
Validation loss: 2.595970991524838

Epoch: 5| Step: 2
Training loss: 2.190336731406439
Validation loss: 2.559601819580559

Epoch: 5| Step: 3
Training loss: 1.8500793568885845
Validation loss: 2.5339838303848197

Epoch: 5| Step: 4
Training loss: 1.4850593194127575
Validation loss: 2.535523927238312

Epoch: 5| Step: 5
Training loss: 1.7169973280257695
Validation loss: 2.5248680547666584

Epoch: 5| Step: 6
Training loss: 1.7602585113930744
Validation loss: 2.517585188148205

Epoch: 5| Step: 7
Training loss: 1.5341225752468275
Validation loss: 2.511249460821883

Epoch: 5| Step: 8
Training loss: 2.187691489421432
Validation loss: 2.5095001238597234

Epoch: 5| Step: 9
Training loss: 2.2739106305358754
Validation loss: 2.5200279771327834

Epoch: 5| Step: 10
Training loss: 2.6606540746267413
Validation loss: 2.497623573768015

Epoch: 5| Step: 11
Training loss: 1.7038732162554684
Validation loss: 2.5387516711786913

Epoch: 359| Step: 0
Training loss: 2.0424554300289604
Validation loss: 2.569248555136637

Epoch: 5| Step: 1
Training loss: 2.202545414433678
Validation loss: 2.5728845221072634

Epoch: 5| Step: 2
Training loss: 1.6796737315478576
Validation loss: 2.6018494685448585

Epoch: 5| Step: 3
Training loss: 2.238820488702376
Validation loss: 2.646429679277246

Epoch: 5| Step: 4
Training loss: 2.1970862556996096
Validation loss: 2.6434095211542386

Epoch: 5| Step: 5
Training loss: 2.366637817618897
Validation loss: 2.635493919436468

Epoch: 5| Step: 6
Training loss: 1.2514451732719367
Validation loss: 2.5775937737217935

Epoch: 5| Step: 7
Training loss: 1.9563822326818943
Validation loss: 2.5682947767133206

Epoch: 5| Step: 8
Training loss: 2.303541926789652
Validation loss: 2.536344076529755

Epoch: 5| Step: 9
Training loss: 1.9992258242459222
Validation loss: 2.5061146543428383

Epoch: 5| Step: 10
Training loss: 1.8185695440689065
Validation loss: 2.4915075660122175

Epoch: 5| Step: 11
Training loss: 1.8157163560899883
Validation loss: 2.4827599484079785

Epoch: 360| Step: 0
Training loss: 2.0411555630107343
Validation loss: 2.4796772692829268

Epoch: 5| Step: 1
Training loss: 2.694744636313011
Validation loss: 2.499384863992101

Epoch: 5| Step: 2
Training loss: 2.000722635372076
Validation loss: 2.4808970284371257

Epoch: 5| Step: 3
Training loss: 1.5684291496290184
Validation loss: 2.5083907937177927

Epoch: 5| Step: 4
Training loss: 1.642344128138038
Validation loss: 2.501942456133586

Epoch: 5| Step: 5
Training loss: 1.8001164928463331
Validation loss: 2.52719863011146

Epoch: 5| Step: 6
Training loss: 1.1889677012446411
Validation loss: 2.532175246234991

Epoch: 5| Step: 7
Training loss: 2.080539075613291
Validation loss: 2.517331754725205

Epoch: 5| Step: 8
Training loss: 1.8256288098351343
Validation loss: 2.5426955225235144

Epoch: 5| Step: 9
Training loss: 2.071214472224838
Validation loss: 2.5670534940583964

Epoch: 5| Step: 10
Training loss: 1.7378450339251992
Validation loss: 2.5763137388850974

Epoch: 5| Step: 11
Training loss: 3.195696147840675
Validation loss: 2.593952021716879

Epoch: 361| Step: 0
Training loss: 1.7604986393670563
Validation loss: 2.6018429510491763

Epoch: 5| Step: 1
Training loss: 2.1717210893503793
Validation loss: 2.6386838922572853

Epoch: 5| Step: 2
Training loss: 2.1288513736476635
Validation loss: 2.634293133273222

Epoch: 5| Step: 3
Training loss: 1.7539260285415634
Validation loss: 2.6154133073344483

Epoch: 5| Step: 4
Training loss: 2.1880186283566894
Validation loss: 2.628288408053511

Epoch: 5| Step: 5
Training loss: 1.7099170167207076
Validation loss: 2.590447065487856

Epoch: 5| Step: 6
Training loss: 1.5044238500267053
Validation loss: 2.5503110836894383

Epoch: 5| Step: 7
Training loss: 1.6092029961084233
Validation loss: 2.557149771789225

Epoch: 5| Step: 8
Training loss: 1.8289707542362958
Validation loss: 2.5208748480370744

Epoch: 5| Step: 9
Training loss: 2.138364503276008
Validation loss: 2.503466297206725

Epoch: 5| Step: 10
Training loss: 2.4133655319735485
Validation loss: 2.5164835236922873

Epoch: 5| Step: 11
Training loss: 1.1189091361469004
Validation loss: 2.499811407764167

Epoch: 362| Step: 0
Training loss: 1.6791811157564092
Validation loss: 2.5037651954630338

Epoch: 5| Step: 1
Training loss: 1.5955217274687008
Validation loss: 2.5265635721412387

Epoch: 5| Step: 2
Training loss: 1.7939767435027238
Validation loss: 2.5383228261416657

Epoch: 5| Step: 3
Training loss: 2.0789454855329006
Validation loss: 2.524247640784633

Epoch: 5| Step: 4
Training loss: 1.8493204183152736
Validation loss: 2.5675366765355316

Epoch: 5| Step: 5
Training loss: 2.4718527309412903
Validation loss: 2.561594888512545

Epoch: 5| Step: 6
Training loss: 1.5449599925666657
Validation loss: 2.586412922008221

Epoch: 5| Step: 7
Training loss: 1.885663861110399
Validation loss: 2.6119703455605205

Epoch: 5| Step: 8
Training loss: 1.8910770979142382
Validation loss: 2.6148026489638294

Epoch: 5| Step: 9
Training loss: 1.678782090415069
Validation loss: 2.6304933047378296

Epoch: 5| Step: 10
Training loss: 2.151246499075914
Validation loss: 2.6099209509372785

Epoch: 5| Step: 11
Training loss: 3.137661270921002
Validation loss: 2.5737964397561814

Epoch: 363| Step: 0
Training loss: 1.6097609418297794
Validation loss: 2.6013426282070746

Epoch: 5| Step: 1
Training loss: 2.2038052638195196
Validation loss: 2.5584325686249954

Epoch: 5| Step: 2
Training loss: 1.586720465955459
Validation loss: 2.554071107049645

Epoch: 5| Step: 3
Training loss: 2.133166161583482
Validation loss: 2.5371438568097844

Epoch: 5| Step: 4
Training loss: 1.8986631659616566
Validation loss: 2.5201993899141906

Epoch: 5| Step: 5
Training loss: 2.2571507312368286
Validation loss: 2.504963626264371

Epoch: 5| Step: 6
Training loss: 1.77633014323661
Validation loss: 2.50746686777885

Epoch: 5| Step: 7
Training loss: 2.0915850933729243
Validation loss: 2.4958266113797856

Epoch: 5| Step: 8
Training loss: 1.7587726598607014
Validation loss: 2.509616191289375

Epoch: 5| Step: 9
Training loss: 2.1787794402470304
Validation loss: 2.512292324801768

Epoch: 5| Step: 10
Training loss: 2.399541246756399
Validation loss: 2.5151486311032856

Epoch: 5| Step: 11
Training loss: 1.11194870822951
Validation loss: 2.5669290618770177

Epoch: 364| Step: 0
Training loss: 2.4836130953236624
Validation loss: 2.5758084919855846

Epoch: 5| Step: 1
Training loss: 1.5937002585633528
Validation loss: 2.595996756841106

Epoch: 5| Step: 2
Training loss: 1.418387191024838
Validation loss: 2.5929173584653666

Epoch: 5| Step: 3
Training loss: 1.5662324956477482
Validation loss: 2.5852038138840383

Epoch: 5| Step: 4
Training loss: 2.1895857540253947
Validation loss: 2.5761695053941898

Epoch: 5| Step: 5
Training loss: 1.8392426952669665
Validation loss: 2.5561105690123007

Epoch: 5| Step: 6
Training loss: 2.128004418540612
Validation loss: 2.565694060811359

Epoch: 5| Step: 7
Training loss: 2.3188659063196604
Validation loss: 2.5450958754573927

Epoch: 5| Step: 8
Training loss: 1.628509692764366
Validation loss: 2.5646534861078525

Epoch: 5| Step: 9
Training loss: 2.3454793018085667
Validation loss: 2.554715762045227

Epoch: 5| Step: 10
Training loss: 1.61625268427013
Validation loss: 2.5394732881465436

Epoch: 5| Step: 11
Training loss: 1.3655585039303717
Validation loss: 2.5557374031447777

Epoch: 365| Step: 0
Training loss: 2.4220449080394975
Validation loss: 2.5554635388686515

Epoch: 5| Step: 1
Training loss: 1.323654459674553
Validation loss: 2.5792116553080997

Epoch: 5| Step: 2
Training loss: 2.0272466088691297
Validation loss: 2.601407624026907

Epoch: 5| Step: 3
Training loss: 1.5212123955848766
Validation loss: 2.567267859221436

Epoch: 5| Step: 4
Training loss: 2.0698505390038906
Validation loss: 2.584370917455792

Epoch: 5| Step: 5
Training loss: 1.5712515077909945
Validation loss: 2.5991904066562466

Epoch: 5| Step: 6
Training loss: 2.38393968280552
Validation loss: 2.6160504770238164

Epoch: 5| Step: 7
Training loss: 1.9171608895815546
Validation loss: 2.5955995032392165

Epoch: 5| Step: 8
Training loss: 1.2818247738674224
Validation loss: 2.6210163709548158

Epoch: 5| Step: 9
Training loss: 1.8102144761284396
Validation loss: 2.5756238653841876

Epoch: 5| Step: 10
Training loss: 1.7552030055779289
Validation loss: 2.5932356542743764

Epoch: 5| Step: 11
Training loss: 3.771009971457777
Validation loss: 2.5665286967322234

Epoch: 366| Step: 0
Training loss: 1.9572191586005618
Validation loss: 2.528057604859239

Epoch: 5| Step: 1
Training loss: 1.307223020577573
Validation loss: 2.553330304946631

Epoch: 5| Step: 2
Training loss: 2.238353468443897
Validation loss: 2.5508900454162484

Epoch: 5| Step: 3
Training loss: 1.3972540168397327
Validation loss: 2.5107368578978524

Epoch: 5| Step: 4
Training loss: 1.908319381873871
Validation loss: 2.5360484500289653

Epoch: 5| Step: 5
Training loss: 1.4837768152476405
Validation loss: 2.552910434573547

Epoch: 5| Step: 6
Training loss: 1.971565473780715
Validation loss: 2.574160357648981

Epoch: 5| Step: 7
Training loss: 2.5023756184187733
Validation loss: 2.566806473629628

Epoch: 5| Step: 8
Training loss: 1.8324711968837184
Validation loss: 2.6031896296946697

Epoch: 5| Step: 9
Training loss: 2.3347885725538045
Validation loss: 2.6268106603930566

Epoch: 5| Step: 10
Training loss: 1.494056848907475
Validation loss: 2.6100443897029

Epoch: 5| Step: 11
Training loss: 2.2447008673646818
Validation loss: 2.616290155938865

Epoch: 367| Step: 0
Training loss: 2.3797798244027275
Validation loss: 2.6250926864246042

Epoch: 5| Step: 1
Training loss: 1.9261767617672116
Validation loss: 2.6594231183920685

Epoch: 5| Step: 2
Training loss: 1.8028453325735885
Validation loss: 2.6256103525083856

Epoch: 5| Step: 3
Training loss: 1.5456066904553047
Validation loss: 2.573031192552414

Epoch: 5| Step: 4
Training loss: 1.6248851148635484
Validation loss: 2.5700386852291786

Epoch: 5| Step: 5
Training loss: 1.684798727720818
Validation loss: 2.5488066183963545

Epoch: 5| Step: 6
Training loss: 1.8580081307322602
Validation loss: 2.509164827823968

Epoch: 5| Step: 7
Training loss: 2.45277295350344
Validation loss: 2.5064114670811843

Epoch: 5| Step: 8
Training loss: 1.6412107602706898
Validation loss: 2.5230594544727825

Epoch: 5| Step: 9
Training loss: 2.1911086698088202
Validation loss: 2.52140209911804

Epoch: 5| Step: 10
Training loss: 1.775932942602246
Validation loss: 2.5140901586553386

Epoch: 5| Step: 11
Training loss: 0.8122790843233393
Validation loss: 2.532984010136161

Epoch: 368| Step: 0
Training loss: 1.353975908586303
Validation loss: 2.533866742459984

Epoch: 5| Step: 1
Training loss: 1.9291148088816688
Validation loss: 2.534920899488205

Epoch: 5| Step: 2
Training loss: 1.4158101952278535
Validation loss: 2.536410064290204

Epoch: 5| Step: 3
Training loss: 2.241338057226906
Validation loss: 2.594792202602736

Epoch: 5| Step: 4
Training loss: 1.8741756534431628
Validation loss: 2.578781680080327

Epoch: 5| Step: 5
Training loss: 1.555826354676042
Validation loss: 2.5572378336775237

Epoch: 5| Step: 6
Training loss: 2.0003966891750498
Validation loss: 2.611962989967484

Epoch: 5| Step: 7
Training loss: 1.6490255454995484
Validation loss: 2.609861419934001

Epoch: 5| Step: 8
Training loss: 2.2050264418350847
Validation loss: 2.628178643651727

Epoch: 5| Step: 9
Training loss: 2.0017507757874053
Validation loss: 2.615429890631458

Epoch: 5| Step: 10
Training loss: 2.1444608749766036
Validation loss: 2.600249380063758

Epoch: 5| Step: 11
Training loss: 1.691830059986457
Validation loss: 2.608370067766356

Epoch: 369| Step: 0
Training loss: 1.5045575205594897
Validation loss: 2.5879077570126223

Epoch: 5| Step: 1
Training loss: 1.7736972164932487
Validation loss: 2.5505939276604397

Epoch: 5| Step: 2
Training loss: 1.9098764538377737
Validation loss: 2.581409908603261

Epoch: 5| Step: 3
Training loss: 1.7937968550354328
Validation loss: 2.555241274916163

Epoch: 5| Step: 4
Training loss: 1.6969798103125082
Validation loss: 2.567980987176151

Epoch: 5| Step: 5
Training loss: 1.7243097721163865
Validation loss: 2.570244825915815

Epoch: 5| Step: 6
Training loss: 2.6481854254117634
Validation loss: 2.590720410463263

Epoch: 5| Step: 7
Training loss: 1.9085363216246878
Validation loss: 2.584665513844299

Epoch: 5| Step: 8
Training loss: 2.455572765840467
Validation loss: 2.5950118905703374

Epoch: 5| Step: 9
Training loss: 1.7411154968497526
Validation loss: 2.5924692400533242

Epoch: 5| Step: 10
Training loss: 1.3926071014171735
Validation loss: 2.5997708273108793

Epoch: 5| Step: 11
Training loss: 0.8599108325952456
Validation loss: 2.605482685713362

Epoch: 370| Step: 0
Training loss: 1.6773794240582625
Validation loss: 2.575032357904522

Epoch: 5| Step: 1
Training loss: 2.2951946729484534
Validation loss: 2.591208637696868

Epoch: 5| Step: 2
Training loss: 1.3308373075715314
Validation loss: 2.5877353184960135

Epoch: 5| Step: 3
Training loss: 1.830837096446422
Validation loss: 2.591479345484312

Epoch: 5| Step: 4
Training loss: 1.965424529558533
Validation loss: 2.577106673526357

Epoch: 5| Step: 5
Training loss: 2.2158944465135515
Validation loss: 2.5858133945091812

Epoch: 5| Step: 6
Training loss: 1.830840221815154
Validation loss: 2.5534236943347097

Epoch: 5| Step: 7
Training loss: 1.5272216748089806
Validation loss: 2.5304160687061517

Epoch: 5| Step: 8
Training loss: 2.0559267433489294
Validation loss: 2.5210801166661896

Epoch: 5| Step: 9
Training loss: 2.14818657536806
Validation loss: 2.5398724990355053

Epoch: 5| Step: 10
Training loss: 1.6181592003076468
Validation loss: 2.5288622587060656

Epoch: 5| Step: 11
Training loss: 1.4319446860131397
Validation loss: 2.5299853631175435

Epoch: 371| Step: 0
Training loss: 1.5995447613867546
Validation loss: 2.533268171076787

Epoch: 5| Step: 1
Training loss: 2.6292230151667746
Validation loss: 2.5361910012666593

Epoch: 5| Step: 2
Training loss: 2.0754331205653083
Validation loss: 2.5542484454452383

Epoch: 5| Step: 3
Training loss: 2.080417601772806
Validation loss: 2.587952776468447

Epoch: 5| Step: 4
Training loss: 1.5973285068402956
Validation loss: 2.5865446801174943

Epoch: 5| Step: 5
Training loss: 1.496897827484065
Validation loss: 2.577230780065286

Epoch: 5| Step: 6
Training loss: 1.9211465338878213
Validation loss: 2.5735719801216494

Epoch: 5| Step: 7
Training loss: 1.576585831105626
Validation loss: 2.588831232301618

Epoch: 5| Step: 8
Training loss: 2.09812015681749
Validation loss: 2.579324447127819

Epoch: 5| Step: 9
Training loss: 1.2863927765280478
Validation loss: 2.590114638793648

Epoch: 5| Step: 10
Training loss: 1.8544881377695712
Validation loss: 2.572876877161744

Epoch: 5| Step: 11
Training loss: 1.3320022982586115
Validation loss: 2.5773244173485605

Epoch: 372| Step: 0
Training loss: 1.4797282518456902
Validation loss: 2.5642046879489

Epoch: 5| Step: 1
Training loss: 1.894104459216306
Validation loss: 2.5750898586260593

Epoch: 5| Step: 2
Training loss: 1.6695727602448804
Validation loss: 2.558446597461361

Epoch: 5| Step: 3
Training loss: 1.5203004277878145
Validation loss: 2.5649565613906073

Epoch: 5| Step: 4
Training loss: 1.8122005873048186
Validation loss: 2.5397215667626503

Epoch: 5| Step: 5
Training loss: 1.706489180125135
Validation loss: 2.5630933454571654

Epoch: 5| Step: 6
Training loss: 2.7634409238472073
Validation loss: 2.5859855059636474

Epoch: 5| Step: 7
Training loss: 1.8493068814277869
Validation loss: 2.600729945616313

Epoch: 5| Step: 8
Training loss: 2.0595284064756374
Validation loss: 2.5589622756313544

Epoch: 5| Step: 9
Training loss: 1.4200336144726644
Validation loss: 2.6130445912034928

Epoch: 5| Step: 10
Training loss: 1.8933275941417014
Validation loss: 2.5875691685668847

Epoch: 5| Step: 11
Training loss: 1.192069847531101
Validation loss: 2.5783616853210143

Epoch: 373| Step: 0
Training loss: 2.0744418439126306
Validation loss: 2.565071188364539

Epoch: 5| Step: 1
Training loss: 1.8923333386668764
Validation loss: 2.559740026213953

Epoch: 5| Step: 2
Training loss: 1.621713248770131
Validation loss: 2.547981536696535

Epoch: 5| Step: 3
Training loss: 2.310686070174545
Validation loss: 2.549853379578345

Epoch: 5| Step: 4
Training loss: 1.249674659352059
Validation loss: 2.5583485434874227

Epoch: 5| Step: 5
Training loss: 1.679704674921277
Validation loss: 2.577074596006795

Epoch: 5| Step: 6
Training loss: 1.7790973438393418
Validation loss: 2.565555909682785

Epoch: 5| Step: 7
Training loss: 1.901143911738793
Validation loss: 2.5654899610417043

Epoch: 5| Step: 8
Training loss: 1.5221040807869917
Validation loss: 2.576164540590571

Epoch: 5| Step: 9
Training loss: 2.0175404282008946
Validation loss: 2.581164654667068

Epoch: 5| Step: 10
Training loss: 1.9804849417060308
Validation loss: 2.557559367746531

Epoch: 5| Step: 11
Training loss: 1.8540653744007733
Validation loss: 2.565268443829043

Epoch: 374| Step: 0
Training loss: 2.241134555819895
Validation loss: 2.5793792852408193

Epoch: 5| Step: 1
Training loss: 1.4230603318228685
Validation loss: 2.6221492895146485

Epoch: 5| Step: 2
Training loss: 1.7335460159448302
Validation loss: 2.601854859688879

Epoch: 5| Step: 3
Training loss: 1.57392233052745
Validation loss: 2.622739908828936

Epoch: 5| Step: 4
Training loss: 1.481849771105481
Validation loss: 2.6507500573678464

Epoch: 5| Step: 5
Training loss: 1.698610253835056
Validation loss: 2.602012060842141

Epoch: 5| Step: 6
Training loss: 2.1684080486438857
Validation loss: 2.5802776751378658

Epoch: 5| Step: 7
Training loss: 1.7841077267020355
Validation loss: 2.5618338920929014

Epoch: 5| Step: 8
Training loss: 1.896898815627691
Validation loss: 2.583644826372818

Epoch: 5| Step: 9
Training loss: 2.448998935697674
Validation loss: 2.5373339319930857

Epoch: 5| Step: 10
Training loss: 1.9440091834263469
Validation loss: 2.524480259787987

Epoch: 5| Step: 11
Training loss: 1.86325322735905
Validation loss: 2.523412607894967

Epoch: 375| Step: 0
Training loss: 1.4724036690721962
Validation loss: 2.5200077917215697

Epoch: 5| Step: 1
Training loss: 1.9083591737066588
Validation loss: 2.51901853011861

Epoch: 5| Step: 2
Training loss: 2.6212683902326392
Validation loss: 2.527145798569732

Epoch: 5| Step: 3
Training loss: 1.8777325745445588
Validation loss: 2.536925622689201

Epoch: 5| Step: 4
Training loss: 1.8838768953895109
Validation loss: 2.542801522861837

Epoch: 5| Step: 5
Training loss: 1.9244113715743518
Validation loss: 2.5585714247023166

Epoch: 5| Step: 6
Training loss: 1.7872909370287773
Validation loss: 2.5345635801397712

Epoch: 5| Step: 7
Training loss: 2.369712766794097
Validation loss: 2.5341619178575274

Epoch: 5| Step: 8
Training loss: 1.4921461169511099
Validation loss: 2.5445424458444132

Epoch: 5| Step: 9
Training loss: 1.9495651151432705
Validation loss: 2.516608640231294

Epoch: 5| Step: 10
Training loss: 1.4090090071320553
Validation loss: 2.5206279132364915

Epoch: 5| Step: 11
Training loss: 1.6545302621627915
Validation loss: 2.5330029410719033

Epoch: 376| Step: 0
Training loss: 1.9181063538580683
Validation loss: 2.535274618448763

Epoch: 5| Step: 1
Training loss: 1.9894157725238826
Validation loss: 2.5383498458383658

Epoch: 5| Step: 2
Training loss: 1.5531799828604298
Validation loss: 2.531642290807489

Epoch: 5| Step: 3
Training loss: 1.7024411569697016
Validation loss: 2.5140142318805276

Epoch: 5| Step: 4
Training loss: 1.5803540793967246
Validation loss: 2.515080896616047

Epoch: 5| Step: 5
Training loss: 2.216402880908448
Validation loss: 2.5540620736263704

Epoch: 5| Step: 6
Training loss: 1.2843274629803443
Validation loss: 2.55562548668405

Epoch: 5| Step: 7
Training loss: 1.877531948808269
Validation loss: 2.5878901758733397

Epoch: 5| Step: 8
Training loss: 1.81763880759755
Validation loss: 2.6125346677326466

Epoch: 5| Step: 9
Training loss: 2.2234050649179147
Validation loss: 2.6207691073065766

Epoch: 5| Step: 10
Training loss: 2.2775274762067546
Validation loss: 2.6275086223268453

Epoch: 5| Step: 11
Training loss: 2.8020851579586927
Validation loss: 2.631160228946657

Epoch: 377| Step: 0
Training loss: 1.748908179152655
Validation loss: 2.6268754458376

Epoch: 5| Step: 1
Training loss: 1.6304514483277335
Validation loss: 2.6078923975988575

Epoch: 5| Step: 2
Training loss: 1.8965286265434613
Validation loss: 2.605945057490321

Epoch: 5| Step: 3
Training loss: 2.03002963453188
Validation loss: 2.5888366045081344

Epoch: 5| Step: 4
Training loss: 1.7673275596100326
Validation loss: 2.597398757601455

Epoch: 5| Step: 5
Training loss: 1.7985495684031207
Validation loss: 2.55352651441926

Epoch: 5| Step: 6
Training loss: 1.7867178399434376
Validation loss: 2.531996652189636

Epoch: 5| Step: 7
Training loss: 1.977086054401783
Validation loss: 2.5453635842708104

Epoch: 5| Step: 8
Training loss: 1.882693275064157
Validation loss: 2.546017375626547

Epoch: 5| Step: 9
Training loss: 1.745011645062347
Validation loss: 2.555688858154883

Epoch: 5| Step: 10
Training loss: 2.264021207170943
Validation loss: 2.551195312588594

Epoch: 5| Step: 11
Training loss: 1.3704796527102243
Validation loss: 2.5540712995808157

Epoch: 378| Step: 0
Training loss: 1.4164933023775799
Validation loss: 2.6013168280060115

Epoch: 5| Step: 1
Training loss: 1.6174634615089165
Validation loss: 2.6301269644561347

Epoch: 5| Step: 2
Training loss: 1.9763955509409792
Validation loss: 2.660006391474567

Epoch: 5| Step: 3
Training loss: 1.9700941311184927
Validation loss: 2.7013453613823417

Epoch: 5| Step: 4
Training loss: 1.6760204651295523
Validation loss: 2.639182868833909

Epoch: 5| Step: 5
Training loss: 1.7571234814974548
Validation loss: 2.6263512849651347

Epoch: 5| Step: 6
Training loss: 1.7957958131958238
Validation loss: 2.585029381130647

Epoch: 5| Step: 7
Training loss: 2.279244782703249
Validation loss: 2.562003913403663

Epoch: 5| Step: 8
Training loss: 1.9476661997088416
Validation loss: 2.506216569330325

Epoch: 5| Step: 9
Training loss: 2.3400580255535894
Validation loss: 2.486305516398148

Epoch: 5| Step: 10
Training loss: 1.4472581294350855
Validation loss: 2.455751066356325

Epoch: 5| Step: 11
Training loss: 1.9820591185959553
Validation loss: 2.4691611321866076

Epoch: 379| Step: 0
Training loss: 1.8875523970449049
Validation loss: 2.477672131766089

Epoch: 5| Step: 1
Training loss: 1.8141880067555267
Validation loss: 2.4874968597417846

Epoch: 5| Step: 2
Training loss: 2.3297712406942583
Validation loss: 2.504641638653428

Epoch: 5| Step: 3
Training loss: 1.6563293150138259
Validation loss: 2.527900410449984

Epoch: 5| Step: 4
Training loss: 2.196221431574596
Validation loss: 2.543114307884527

Epoch: 5| Step: 5
Training loss: 1.4143577815350834
Validation loss: 2.5934328743280157

Epoch: 5| Step: 6
Training loss: 1.4468227434711518
Validation loss: 2.5794489611038554

Epoch: 5| Step: 7
Training loss: 1.4290088648003905
Validation loss: 2.5722430398847926

Epoch: 5| Step: 8
Training loss: 2.0984790971145295
Validation loss: 2.5951019272114295

Epoch: 5| Step: 9
Training loss: 1.8346980029861195
Validation loss: 2.554089669710429

Epoch: 5| Step: 10
Training loss: 1.694651672671116
Validation loss: 2.562572691436881

Epoch: 5| Step: 11
Training loss: 3.3537361547957056
Validation loss: 2.5630127308549557

Epoch: 380| Step: 0
Training loss: 2.061010342945427
Validation loss: 2.5214062320844524

Epoch: 5| Step: 1
Training loss: 2.139839306618185
Validation loss: 2.535673379688053

Epoch: 5| Step: 2
Training loss: 1.7285935551376805
Validation loss: 2.515597515074524

Epoch: 5| Step: 3
Training loss: 1.4328320217986652
Validation loss: 2.5023591950100994

Epoch: 5| Step: 4
Training loss: 1.8179499147732046
Validation loss: 2.4773519803971804

Epoch: 5| Step: 5
Training loss: 2.033447368217408
Validation loss: 2.52653523896152

Epoch: 5| Step: 6
Training loss: 2.1176454393686073
Validation loss: 2.5489888263578213

Epoch: 5| Step: 7
Training loss: 1.315989533072591
Validation loss: 2.550166980568207

Epoch: 5| Step: 8
Training loss: 1.9821689387978045
Validation loss: 2.5324238068848195

Epoch: 5| Step: 9
Training loss: 2.023955643344989
Validation loss: 2.559664929603679

Epoch: 5| Step: 10
Training loss: 1.354692352180635
Validation loss: 2.618705176620047

Epoch: 5| Step: 11
Training loss: 1.9307344507749324
Validation loss: 2.6190713811184523

Epoch: 381| Step: 0
Training loss: 1.4403686924320973
Validation loss: 2.6247966929829483

Epoch: 5| Step: 1
Training loss: 1.4466827495548211
Validation loss: 2.611735781698619

Epoch: 5| Step: 2
Training loss: 2.009123615303101
Validation loss: 2.619135019105302

Epoch: 5| Step: 3
Training loss: 1.378930802167218
Validation loss: 2.5784479960011164

Epoch: 5| Step: 4
Training loss: 2.328180504463678
Validation loss: 2.622343448594273

Epoch: 5| Step: 5
Training loss: 2.2050009241772575
Validation loss: 2.585856433531239

Epoch: 5| Step: 6
Training loss: 1.3153063426708587
Validation loss: 2.6077638285189826

Epoch: 5| Step: 7
Training loss: 1.2963287398022416
Validation loss: 2.5876106465834403

Epoch: 5| Step: 8
Training loss: 1.8479504340984814
Validation loss: 2.5657775162942884

Epoch: 5| Step: 9
Training loss: 2.077683825020474
Validation loss: 2.5430060646143824

Epoch: 5| Step: 10
Training loss: 2.0404860398091444
Validation loss: 2.5312639597127142

Epoch: 5| Step: 11
Training loss: 1.3916871375826407
Validation loss: 2.5096101151118826

Epoch: 382| Step: 0
Training loss: 2.1188249062769375
Validation loss: 2.495665647343038

Epoch: 5| Step: 1
Training loss: 1.8648307323600752
Validation loss: 2.530591678960583

Epoch: 5| Step: 2
Training loss: 1.9484340028341398
Validation loss: 2.557561170021112

Epoch: 5| Step: 3
Training loss: 1.9122885443779734
Validation loss: 2.5676942300054546

Epoch: 5| Step: 4
Training loss: 1.8738204424686489
Validation loss: 2.623941885662031

Epoch: 5| Step: 5
Training loss: 1.5843908726726645
Validation loss: 2.60609765305059

Epoch: 5| Step: 6
Training loss: 1.8126732315939775
Validation loss: 2.621274908696622

Epoch: 5| Step: 7
Training loss: 1.2794553702211802
Validation loss: 2.5973405918702697

Epoch: 5| Step: 8
Training loss: 1.577552616070135
Validation loss: 2.5738768053799244

Epoch: 5| Step: 9
Training loss: 2.6489053948668286
Validation loss: 2.5348276043821167

Epoch: 5| Step: 10
Training loss: 1.923837357707065
Validation loss: 2.499588662322169

Epoch: 5| Step: 11
Training loss: 0.6844860901223849
Validation loss: 2.52099530169962

Epoch: 383| Step: 0
Training loss: 1.8083921118235367
Validation loss: 2.5191216345306033

Epoch: 5| Step: 1
Training loss: 1.7073465226371611
Validation loss: 2.529552813017904

Epoch: 5| Step: 2
Training loss: 2.3853644041863453
Validation loss: 2.513493503662961

Epoch: 5| Step: 3
Training loss: 2.2872273767327935
Validation loss: 2.5103221746260096

Epoch: 5| Step: 4
Training loss: 2.3534047967292127
Validation loss: 2.5253561066217816

Epoch: 5| Step: 5
Training loss: 1.530929999098552
Validation loss: 2.504689269244703

Epoch: 5| Step: 6
Training loss: 1.7745056968462085
Validation loss: 2.557136528349045

Epoch: 5| Step: 7
Training loss: 1.9446343768166474
Validation loss: 2.579456786835648

Epoch: 5| Step: 8
Training loss: 1.366891273014442
Validation loss: 2.5966874039176533

Epoch: 5| Step: 9
Training loss: 1.7016277906714
Validation loss: 2.5949312990021207

Epoch: 5| Step: 10
Training loss: 1.5449832175864893
Validation loss: 2.608862569598308

Epoch: 5| Step: 11
Training loss: 2.133351911026809
Validation loss: 2.6137298594276066

Epoch: 384| Step: 0
Training loss: 1.7334177623262572
Validation loss: 2.5642828360636405

Epoch: 5| Step: 1
Training loss: 1.8428406493398317
Validation loss: 2.5383587610228098

Epoch: 5| Step: 2
Training loss: 1.6668416487708202
Validation loss: 2.5310897697943204

Epoch: 5| Step: 3
Training loss: 1.9923637760936839
Validation loss: 2.5419718814468197

Epoch: 5| Step: 4
Training loss: 2.054230381697751
Validation loss: 2.5370419253222027

Epoch: 5| Step: 5
Training loss: 1.9944601821042374
Validation loss: 2.551928536268272

Epoch: 5| Step: 6
Training loss: 2.2206556705984024
Validation loss: 2.560387356908251

Epoch: 5| Step: 7
Training loss: 1.5775145303628297
Validation loss: 2.56383596462157

Epoch: 5| Step: 8
Training loss: 1.484300310363922
Validation loss: 2.562236813078701

Epoch: 5| Step: 9
Training loss: 1.6396677766969237
Validation loss: 2.5429406699228516

Epoch: 5| Step: 10
Training loss: 1.7539768672057077
Validation loss: 2.555912808887727

Epoch: 5| Step: 11
Training loss: 1.899059994212411
Validation loss: 2.5164056992118176

Epoch: 385| Step: 0
Training loss: 1.5853641770337885
Validation loss: 2.5589784502847785

Epoch: 5| Step: 1
Training loss: 1.6578484505252757
Validation loss: 2.5619049583173057

Epoch: 5| Step: 2
Training loss: 1.9835712877814444
Validation loss: 2.564443568385946

Epoch: 5| Step: 3
Training loss: 1.139967951240449
Validation loss: 2.542855916056763

Epoch: 5| Step: 4
Training loss: 1.6970099463994637
Validation loss: 2.551534349730474

Epoch: 5| Step: 5
Training loss: 1.7382819357881372
Validation loss: 2.572061162231276

Epoch: 5| Step: 6
Training loss: 2.1056964588353444
Validation loss: 2.5542316749497607

Epoch: 5| Step: 7
Training loss: 1.7302194247807976
Validation loss: 2.563150189649644

Epoch: 5| Step: 8
Training loss: 1.8178622409257645
Validation loss: 2.5786962935821074

Epoch: 5| Step: 9
Training loss: 1.5180522713136566
Validation loss: 2.6008146392918827

Epoch: 5| Step: 10
Training loss: 2.5836272739003774
Validation loss: 2.597960723395297

Epoch: 5| Step: 11
Training loss: 2.267560881582801
Validation loss: 2.6085622743876598

Epoch: 386| Step: 0
Training loss: 2.1145541434943307
Validation loss: 2.611868780256042

Epoch: 5| Step: 1
Training loss: 1.7883105967635562
Validation loss: 2.5717827515804483

Epoch: 5| Step: 2
Training loss: 1.7984405331954765
Validation loss: 2.540382147955903

Epoch: 5| Step: 3
Training loss: 1.1940085585429614
Validation loss: 2.5653585214258947

Epoch: 5| Step: 4
Training loss: 1.9172544061975987
Validation loss: 2.56641039177857

Epoch: 5| Step: 5
Training loss: 1.6362862026793654
Validation loss: 2.518038940082635

Epoch: 5| Step: 6
Training loss: 2.2318602595594292
Validation loss: 2.556556935369782

Epoch: 5| Step: 7
Training loss: 1.32565292969255
Validation loss: 2.5686689531112497

Epoch: 5| Step: 8
Training loss: 1.610569704917736
Validation loss: 2.5554858874301565

Epoch: 5| Step: 9
Training loss: 1.806856313666218
Validation loss: 2.5612664005889485

Epoch: 5| Step: 10
Training loss: 2.3235071455285574
Validation loss: 2.5526751954297424

Epoch: 5| Step: 11
Training loss: 0.9354518770474222
Validation loss: 2.5416165852433115

Epoch: 387| Step: 0
Training loss: 1.206857316901532
Validation loss: 2.5565693463831183

Epoch: 5| Step: 1
Training loss: 1.869850589882814
Validation loss: 2.518591389580315

Epoch: 5| Step: 2
Training loss: 2.37966450851064
Validation loss: 2.5162053435914697

Epoch: 5| Step: 3
Training loss: 1.4724980681686812
Validation loss: 2.5235083838743617

Epoch: 5| Step: 4
Training loss: 1.766783207822166
Validation loss: 2.5236052033212872

Epoch: 5| Step: 5
Training loss: 2.086800728818954
Validation loss: 2.5134318883588893

Epoch: 5| Step: 6
Training loss: 1.9249878771511666
Validation loss: 2.5079958007943137

Epoch: 5| Step: 7
Training loss: 1.6941266812873694
Validation loss: 2.5027913325591062

Epoch: 5| Step: 8
Training loss: 1.5289543226166677
Validation loss: 2.5344174664910586

Epoch: 5| Step: 9
Training loss: 0.9935819183811345
Validation loss: 2.5361710659232193

Epoch: 5| Step: 10
Training loss: 2.101027409951656
Validation loss: 2.520767358174023

Epoch: 5| Step: 11
Training loss: 1.804489983653203
Validation loss: 2.541099118877557

Epoch: 388| Step: 0
Training loss: 1.219070588031019
Validation loss: 2.537247291596823

Epoch: 5| Step: 1
Training loss: 1.7609065651397702
Validation loss: 2.507912369400283

Epoch: 5| Step: 2
Training loss: 1.4750898172220126
Validation loss: 2.5087695984105762

Epoch: 5| Step: 3
Training loss: 1.8847563906428575
Validation loss: 2.506773411548482

Epoch: 5| Step: 4
Training loss: 1.4175945870733144
Validation loss: 2.4934723709880213

Epoch: 5| Step: 5
Training loss: 1.585780168819181
Validation loss: 2.5003762041591946

Epoch: 5| Step: 6
Training loss: 2.628742547344358
Validation loss: 2.519464737361686

Epoch: 5| Step: 7
Training loss: 1.8499134301215534
Validation loss: 2.549078857639386

Epoch: 5| Step: 8
Training loss: 1.7321985008279945
Validation loss: 2.5802568002727067

Epoch: 5| Step: 9
Training loss: 1.5517631900374884
Validation loss: 2.562527346271271

Epoch: 5| Step: 10
Training loss: 1.9736160209654943
Validation loss: 2.5599270518285664

Epoch: 5| Step: 11
Training loss: 2.421045862827834
Validation loss: 2.5540422836082994

Epoch: 389| Step: 0
Training loss: 1.54835285528966
Validation loss: 2.586965160794044

Epoch: 5| Step: 1
Training loss: 2.1542184077037314
Validation loss: 2.5475399888818004

Epoch: 5| Step: 2
Training loss: 2.5205164203105146
Validation loss: 2.5417106805700933

Epoch: 5| Step: 3
Training loss: 1.036055091869625
Validation loss: 2.5498192975587393

Epoch: 5| Step: 4
Training loss: 1.8699590312325454
Validation loss: 2.5671926616385408

Epoch: 5| Step: 5
Training loss: 1.5761384452290519
Validation loss: 2.5322960666151175

Epoch: 5| Step: 6
Training loss: 1.9262235493363231
Validation loss: 2.563735086635424

Epoch: 5| Step: 7
Training loss: 1.6988735506041592
Validation loss: 2.526600323018265

Epoch: 5| Step: 8
Training loss: 1.636192510307431
Validation loss: 2.488637027427645

Epoch: 5| Step: 9
Training loss: 1.6602795364378795
Validation loss: 2.53266521812425

Epoch: 5| Step: 10
Training loss: 1.6502707172602264
Validation loss: 2.503276708119517

Epoch: 5| Step: 11
Training loss: 0.5692660516210577
Validation loss: 2.5200773608352622

Epoch: 390| Step: 0
Training loss: 1.55433643153634
Validation loss: 2.509716717234841

Epoch: 5| Step: 1
Training loss: 1.922647336515236
Validation loss: 2.497688054930414

Epoch: 5| Step: 2
Training loss: 1.490147739356898
Validation loss: 2.520155044338731

Epoch: 5| Step: 3
Training loss: 1.6210593346309206
Validation loss: 2.5682373636754825

Epoch: 5| Step: 4
Training loss: 1.8701254742391467
Validation loss: 2.516612587646682

Epoch: 5| Step: 5
Training loss: 1.5653197213598649
Validation loss: 2.507992616168778

Epoch: 5| Step: 6
Training loss: 2.201485856010128
Validation loss: 2.53260756221827

Epoch: 5| Step: 7
Training loss: 1.9911332875331411
Validation loss: 2.5118646732575862

Epoch: 5| Step: 8
Training loss: 1.3681204963843474
Validation loss: 2.5195695425667286

Epoch: 5| Step: 9
Training loss: 1.2852580485274645
Validation loss: 2.538160788026929

Epoch: 5| Step: 10
Training loss: 2.4755702392561934
Validation loss: 2.534040792452755

Epoch: 5| Step: 11
Training loss: 1.5475995457297314
Validation loss: 2.5530999293316228

Epoch: 391| Step: 0
Training loss: 2.264875827442403
Validation loss: 2.6181314312918187

Epoch: 5| Step: 1
Training loss: 2.2607577955724714
Validation loss: 2.6294287265831517

Epoch: 5| Step: 2
Training loss: 1.4450579444856675
Validation loss: 2.6454813502816377

Epoch: 5| Step: 3
Training loss: 1.9081577697798833
Validation loss: 2.598917214801597

Epoch: 5| Step: 4
Training loss: 1.5481031532270761
Validation loss: 2.570293198409651

Epoch: 5| Step: 5
Training loss: 2.1194938681680937
Validation loss: 2.5766729947670846

Epoch: 5| Step: 6
Training loss: 1.6655682838617505
Validation loss: 2.5450900557272584

Epoch: 5| Step: 7
Training loss: 1.6722298361448968
Validation loss: 2.5424137613448976

Epoch: 5| Step: 8
Training loss: 1.5527306898541176
Validation loss: 2.564000857067659

Epoch: 5| Step: 9
Training loss: 1.7172496142273805
Validation loss: 2.527107149081634

Epoch: 5| Step: 10
Training loss: 1.537198249545107
Validation loss: 2.5928354987447473

Epoch: 5| Step: 11
Training loss: 0.8744204850053636
Validation loss: 2.568844999519719

Epoch: 392| Step: 0
Training loss: 1.661932284718932
Validation loss: 2.6015773005250677

Epoch: 5| Step: 1
Training loss: 1.052972770125106
Validation loss: 2.6442708422996626

Epoch: 5| Step: 2
Training loss: 2.0447710012543703
Validation loss: 2.6380020635501347

Epoch: 5| Step: 3
Training loss: 1.7684073342033806
Validation loss: 2.5938641856234064

Epoch: 5| Step: 4
Training loss: 1.7575100786942977
Validation loss: 2.6213759882914482

Epoch: 5| Step: 5
Training loss: 2.297467628890196
Validation loss: 2.586163544547271

Epoch: 5| Step: 6
Training loss: 2.006355439739861
Validation loss: 2.5888886721235282

Epoch: 5| Step: 7
Training loss: 2.0099891115719246
Validation loss: 2.602072237193198

Epoch: 5| Step: 8
Training loss: 1.462008405048095
Validation loss: 2.59127763320314

Epoch: 5| Step: 9
Training loss: 1.468412076344784
Validation loss: 2.601132087118697

Epoch: 5| Step: 10
Training loss: 1.6069523622754978
Validation loss: 2.5769470336589184

Epoch: 5| Step: 11
Training loss: 1.6357085176105615
Validation loss: 2.5556607429192275

Epoch: 393| Step: 0
Training loss: 2.3171921630318577
Validation loss: 2.5332434226276668

Epoch: 5| Step: 1
Training loss: 1.5962147820395636
Validation loss: 2.5477775971415877

Epoch: 5| Step: 2
Training loss: 1.93334318136579
Validation loss: 2.5372728584365682

Epoch: 5| Step: 3
Training loss: 1.577665885388855
Validation loss: 2.5616478278357353

Epoch: 5| Step: 4
Training loss: 1.8903840597175625
Validation loss: 2.5351844789944544

Epoch: 5| Step: 5
Training loss: 1.479076203638005
Validation loss: 2.538198928695686

Epoch: 5| Step: 6
Training loss: 1.5780393369483217
Validation loss: 2.6024508482181674

Epoch: 5| Step: 7
Training loss: 2.480743441052441
Validation loss: 2.57822102069255

Epoch: 5| Step: 8
Training loss: 1.538212962884659
Validation loss: 2.539549611634162

Epoch: 5| Step: 9
Training loss: 1.7360028712121451
Validation loss: 2.5657728101501984

Epoch: 5| Step: 10
Training loss: 0.981045314068892
Validation loss: 2.5498092107831325

Epoch: 5| Step: 11
Training loss: 1.4163695005014347
Validation loss: 2.548569846678175

Epoch: 394| Step: 0
Training loss: 2.3494606129522504
Validation loss: 2.5658167825450833

Epoch: 5| Step: 1
Training loss: 1.3674189344434555
Validation loss: 2.541024726306001

Epoch: 5| Step: 2
Training loss: 1.9350951251716633
Validation loss: 2.563289590465646

Epoch: 5| Step: 3
Training loss: 1.6831197757406142
Validation loss: 2.551936664389046

Epoch: 5| Step: 4
Training loss: 1.250579461255657
Validation loss: 2.5757527004330103

Epoch: 5| Step: 5
Training loss: 1.313483097102704
Validation loss: 2.593013091904004

Epoch: 5| Step: 6
Training loss: 1.887132050479257
Validation loss: 2.5883821301385317

Epoch: 5| Step: 7
Training loss: 2.380327974369071
Validation loss: 2.5863599211311157

Epoch: 5| Step: 8
Training loss: 2.05089483037408
Validation loss: 2.5712292475056864

Epoch: 5| Step: 9
Training loss: 1.6851099537594438
Validation loss: 2.586445308124522

Epoch: 5| Step: 10
Training loss: 1.4611259787656827
Validation loss: 2.598941119996417

Epoch: 5| Step: 11
Training loss: 1.1329538717517464
Validation loss: 2.560599314183947

Epoch: 395| Step: 0
Training loss: 1.2794551372914056
Validation loss: 2.5955103373734723

Epoch: 5| Step: 1
Training loss: 1.766152834693248
Validation loss: 2.6125488889643287

Epoch: 5| Step: 2
Training loss: 1.5733552367630792
Validation loss: 2.6159409890064067

Epoch: 5| Step: 3
Training loss: 1.5493894235817482
Validation loss: 2.6504691704299943

Epoch: 5| Step: 4
Training loss: 1.279638346751602
Validation loss: 2.6358637424258204

Epoch: 5| Step: 5
Training loss: 1.4544823982377535
Validation loss: 2.6341828610667526

Epoch: 5| Step: 6
Training loss: 1.9493299311118089
Validation loss: 2.655636267724556

Epoch: 5| Step: 7
Training loss: 1.7102201168425597
Validation loss: 2.676854986008653

Epoch: 5| Step: 8
Training loss: 2.148358374785839
Validation loss: 2.6245538392937884

Epoch: 5| Step: 9
Training loss: 1.8125438027186216
Validation loss: 2.5896199294123474

Epoch: 5| Step: 10
Training loss: 2.3487871083672376
Validation loss: 2.587215461228141

Epoch: 5| Step: 11
Training loss: 2.057142871996713
Validation loss: 2.570504012311678

Epoch: 396| Step: 0
Training loss: 1.7601878753001794
Validation loss: 2.543300233986367

Epoch: 5| Step: 1
Training loss: 1.087703777820746
Validation loss: 2.571299605897893

Epoch: 5| Step: 2
Training loss: 1.3941703350720402
Validation loss: 2.5832142238435236

Epoch: 5| Step: 3
Training loss: 1.4690101068563213
Validation loss: 2.5509019193201095

Epoch: 5| Step: 4
Training loss: 1.6350558990582078
Validation loss: 2.545257604766926

Epoch: 5| Step: 5
Training loss: 2.387818627790824
Validation loss: 2.5772632545835643

Epoch: 5| Step: 6
Training loss: 1.5880210231715417
Validation loss: 2.5649008320159616

Epoch: 5| Step: 7
Training loss: 2.093168946673643
Validation loss: 2.584166393755673

Epoch: 5| Step: 8
Training loss: 1.3334351242469809
Validation loss: 2.6210410941416216

Epoch: 5| Step: 9
Training loss: 2.3927400495270263
Validation loss: 2.5572549904072788

Epoch: 5| Step: 10
Training loss: 1.30725429932381
Validation loss: 2.5676483020896628

Epoch: 5| Step: 11
Training loss: 1.8502162111081208
Validation loss: 2.5770271159963283

Epoch: 397| Step: 0
Training loss: 1.2900118019983553
Validation loss: 2.5453216910074334

Epoch: 5| Step: 1
Training loss: 2.024236455064769
Validation loss: 2.5362447117348794

Epoch: 5| Step: 2
Training loss: 2.065023439103448
Validation loss: 2.513290518618193

Epoch: 5| Step: 3
Training loss: 2.3071458022694813
Validation loss: 2.5307557875499764

Epoch: 5| Step: 4
Training loss: 1.926793573263235
Validation loss: 2.5260950744855726

Epoch: 5| Step: 5
Training loss: 1.2718076983366873
Validation loss: 2.595179332491394

Epoch: 5| Step: 6
Training loss: 1.6015445615182509
Validation loss: 2.582927319450911

Epoch: 5| Step: 7
Training loss: 1.7762429653729084
Validation loss: 2.599924555166853

Epoch: 5| Step: 8
Training loss: 2.1442122647768986
Validation loss: 2.6440713464699934

Epoch: 5| Step: 9
Training loss: 1.577546419648639
Validation loss: 2.6528503466017828

Epoch: 5| Step: 10
Training loss: 1.1807324663387322
Validation loss: 2.6388201969531075

Epoch: 5| Step: 11
Training loss: 1.7409999888648526
Validation loss: 2.580950527660966

Epoch: 398| Step: 0
Training loss: 1.725040783607345
Validation loss: 2.5830497637336447

Epoch: 5| Step: 1
Training loss: 1.6453631328968295
Validation loss: 2.5712486772931

Epoch: 5| Step: 2
Training loss: 1.7600746349202077
Validation loss: 2.548606354284279

Epoch: 5| Step: 3
Training loss: 1.574694843097212
Validation loss: 2.562928807426187

Epoch: 5| Step: 4
Training loss: 1.9349701269441184
Validation loss: 2.5631535130957923

Epoch: 5| Step: 5
Training loss: 1.7039987265264203
Validation loss: 2.575793034306062

Epoch: 5| Step: 6
Training loss: 1.5089979502447224
Validation loss: 2.5535081869227794

Epoch: 5| Step: 7
Training loss: 1.6987749594454074
Validation loss: 2.584064473751014

Epoch: 5| Step: 8
Training loss: 2.132044391864155
Validation loss: 2.5518543581844417

Epoch: 5| Step: 9
Training loss: 1.5052783602184492
Validation loss: 2.5617326541208025

Epoch: 5| Step: 10
Training loss: 1.6080346312707978
Validation loss: 2.536268639700479

Epoch: 5| Step: 11
Training loss: 1.6234090793387213
Validation loss: 2.572015644459732

Epoch: 399| Step: 0
Training loss: 2.1537427838116603
Validation loss: 2.564596923143424

Epoch: 5| Step: 1
Training loss: 1.4354423225372648
Validation loss: 2.5381089909460472

Epoch: 5| Step: 2
Training loss: 1.430670728440102
Validation loss: 2.529593200214035

Epoch: 5| Step: 3
Training loss: 1.7825038579227597
Validation loss: 2.5424671606207982

Epoch: 5| Step: 4
Training loss: 1.8903652044192683
Validation loss: 2.565583126579798

Epoch: 5| Step: 5
Training loss: 1.6030750854336062
Validation loss: 2.5387307992093584

Epoch: 5| Step: 6
Training loss: 1.6387565509074524
Validation loss: 2.5415751148890946

Epoch: 5| Step: 7
Training loss: 1.654623852767368
Validation loss: 2.559320710553084

Epoch: 5| Step: 8
Training loss: 1.8190309654901056
Validation loss: 2.564806322856325

Epoch: 5| Step: 9
Training loss: 1.651098842011931
Validation loss: 2.5647575234559588

Epoch: 5| Step: 10
Training loss: 1.7531936659259637
Validation loss: 2.545606558627034

Epoch: 5| Step: 11
Training loss: 2.016221423954675
Validation loss: 2.5265660963974557

Epoch: 400| Step: 0
Training loss: 1.8396637457973994
Validation loss: 2.53690769802592

Epoch: 5| Step: 1
Training loss: 1.2178686329603627
Validation loss: 2.539185580669436

Epoch: 5| Step: 2
Training loss: 1.7510199299434612
Validation loss: 2.576483070717672

Epoch: 5| Step: 3
Training loss: 1.725426623897506
Validation loss: 2.568625544884525

Epoch: 5| Step: 4
Training loss: 2.0052541620211084
Validation loss: 2.5870000302450293

Epoch: 5| Step: 5
Training loss: 1.737497079970287
Validation loss: 2.547343669277451

Epoch: 5| Step: 6
Training loss: 1.3310061898635706
Validation loss: 2.5682461828471235

Epoch: 5| Step: 7
Training loss: 1.5839023404215677
Validation loss: 2.586240648861489

Epoch: 5| Step: 8
Training loss: 1.9041813115976494
Validation loss: 2.5505097786589355

Epoch: 5| Step: 9
Training loss: 1.7199716561222076
Validation loss: 2.5428300537476107

Epoch: 5| Step: 10
Training loss: 1.9387312637692866
Validation loss: 2.585358707619546

Epoch: 5| Step: 11
Training loss: 1.3423968754662672
Validation loss: 2.565963176567389

Epoch: 401| Step: 0
Training loss: 1.36068986463856
Validation loss: 2.5729786689072753

Epoch: 5| Step: 1
Training loss: 1.4826157434321037
Validation loss: 2.5512652948031014

Epoch: 5| Step: 2
Training loss: 1.9665913933826242
Validation loss: 2.5600433126029043

Epoch: 5| Step: 3
Training loss: 1.7014928574054844
Validation loss: 2.5665856506258504

Epoch: 5| Step: 4
Training loss: 1.565680813889033
Validation loss: 2.5999042430691595

Epoch: 5| Step: 5
Training loss: 2.0054987181091395
Validation loss: 2.6247965567332043

Epoch: 5| Step: 6
Training loss: 1.5739611848022295
Validation loss: 2.6028574640820104

Epoch: 5| Step: 7
Training loss: 1.8507456204812012
Validation loss: 2.6384437588551926

Epoch: 5| Step: 8
Training loss: 1.446717522704373
Validation loss: 2.5973889531259315

Epoch: 5| Step: 9
Training loss: 2.2507571959608788
Validation loss: 2.571818570444599

Epoch: 5| Step: 10
Training loss: 1.481539537806653
Validation loss: 2.570187272844661

Epoch: 5| Step: 11
Training loss: 0.8156087895678859
Validation loss: 2.5804188012742

Epoch: 402| Step: 0
Training loss: 2.1395789047636153
Validation loss: 2.508897627811156

Epoch: 5| Step: 1
Training loss: 2.149722294282543
Validation loss: 2.494090423038923

Epoch: 5| Step: 2
Training loss: 1.5925670047958436
Validation loss: 2.4810739694990356

Epoch: 5| Step: 3
Training loss: 1.3973508480915051
Validation loss: 2.522382919359333

Epoch: 5| Step: 4
Training loss: 1.5927774790625455
Validation loss: 2.4900704243861984

Epoch: 5| Step: 5
Training loss: 2.101926750750663
Validation loss: 2.4970475525130196

Epoch: 5| Step: 6
Training loss: 1.528254244902856
Validation loss: 2.520781285297713

Epoch: 5| Step: 7
Training loss: 1.536796799788154
Validation loss: 2.5083497522667986

Epoch: 5| Step: 8
Training loss: 1.1480102263237717
Validation loss: 2.521556249451542

Epoch: 5| Step: 9
Training loss: 1.6068674941538617
Validation loss: 2.5062161293499825

Epoch: 5| Step: 10
Training loss: 1.7189965504760927
Validation loss: 2.537585900172854

Epoch: 5| Step: 11
Training loss: 1.8634656898813866
Validation loss: 2.487076308398733

Epoch: 403| Step: 0
Training loss: 1.5390568457175244
Validation loss: 2.462119772161494

Epoch: 5| Step: 1
Training loss: 1.9410979181518364
Validation loss: 2.513106062371149

Epoch: 5| Step: 2
Training loss: 1.0499778995004572
Validation loss: 2.569993114242656

Epoch: 5| Step: 3
Training loss: 1.929299999048392
Validation loss: 2.5499735512951283

Epoch: 5| Step: 4
Training loss: 1.8264060130442663
Validation loss: 2.534884269243309

Epoch: 5| Step: 5
Training loss: 1.8694125528750147
Validation loss: 2.5528715914501294

Epoch: 5| Step: 6
Training loss: 2.1541197938326553
Validation loss: 2.5597376899081716

Epoch: 5| Step: 7
Training loss: 1.942797034099122
Validation loss: 2.5793308212493664

Epoch: 5| Step: 8
Training loss: 2.109429252774536
Validation loss: 2.5698214663873093

Epoch: 5| Step: 9
Training loss: 1.6344230776073865
Validation loss: 2.6671438324207943

Epoch: 5| Step: 10
Training loss: 1.7353822000232313
Validation loss: 2.6824266837992483

Epoch: 5| Step: 11
Training loss: 1.443763273764358
Validation loss: 2.690882745848103

Epoch: 404| Step: 0
Training loss: 2.2245838676242884
Validation loss: 2.71760908208537

Epoch: 5| Step: 1
Training loss: 1.7337856494233543
Validation loss: 2.6474396561597833

Epoch: 5| Step: 2
Training loss: 1.8349412528256623
Validation loss: 2.5803348433756215

Epoch: 5| Step: 3
Training loss: 1.6626940907926764
Validation loss: 2.5701447753909843

Epoch: 5| Step: 4
Training loss: 1.9112346701945926
Validation loss: 2.504068711555305

Epoch: 5| Step: 5
Training loss: 1.6952279065381124
Validation loss: 2.5301247517106447

Epoch: 5| Step: 6
Training loss: 1.6006019503040914
Validation loss: 2.5293133277308857

Epoch: 5| Step: 7
Training loss: 1.7688083814280056
Validation loss: 2.52970167772209

Epoch: 5| Step: 8
Training loss: 1.74917235557839
Validation loss: 2.5442284678456097

Epoch: 5| Step: 9
Training loss: 1.2182349070195906
Validation loss: 2.5349055059930463

Epoch: 5| Step: 10
Training loss: 1.842804359132129
Validation loss: 2.5700314879312924

Epoch: 5| Step: 11
Training loss: 1.3971599945248212
Validation loss: 2.5905339206994538

Epoch: 405| Step: 0
Training loss: 1.3048100214095633
Validation loss: 2.6185939217292784

Epoch: 5| Step: 1
Training loss: 1.5817667422107204
Validation loss: 2.6135236003358244

Epoch: 5| Step: 2
Training loss: 2.141330797549433
Validation loss: 2.5829025468247027

Epoch: 5| Step: 3
Training loss: 1.8214064818466627
Validation loss: 2.5572701949845165

Epoch: 5| Step: 4
Training loss: 1.2844509519966194
Validation loss: 2.5740664508939464

Epoch: 5| Step: 5
Training loss: 1.1797499987486435
Validation loss: 2.5415139399955535

Epoch: 5| Step: 6
Training loss: 1.667253756435531
Validation loss: 2.5662088613407135

Epoch: 5| Step: 7
Training loss: 2.253995209364721
Validation loss: 2.5695659940912026

Epoch: 5| Step: 8
Training loss: 1.9056964132978715
Validation loss: 2.6078549562369107

Epoch: 5| Step: 9
Training loss: 1.7464316636374912
Validation loss: 2.5863234778368582

Epoch: 5| Step: 10
Training loss: 1.9882229120056174
Validation loss: 2.5630321609152698

Epoch: 5| Step: 11
Training loss: 0.7525339236803035
Validation loss: 2.5683355255373397

Epoch: 406| Step: 0
Training loss: 1.8620505437085857
Validation loss: 2.5014850695808333

Epoch: 5| Step: 1
Training loss: 1.9241037239142955
Validation loss: 2.604520811160364

Epoch: 5| Step: 2
Training loss: 1.6135861014085786
Validation loss: 2.587202667346687

Epoch: 5| Step: 3
Training loss: 2.1183004797011793
Validation loss: 2.5970106465105887

Epoch: 5| Step: 4
Training loss: 1.5464851581738197
Validation loss: 2.587079217731063

Epoch: 5| Step: 5
Training loss: 1.8533696236705133
Validation loss: 2.6399989091264033

Epoch: 5| Step: 6
Training loss: 1.5525634671566766
Validation loss: 2.6142950519640187

Epoch: 5| Step: 7
Training loss: 1.6177283225837698
Validation loss: 2.5880462100685597

Epoch: 5| Step: 8
Training loss: 1.723829497011124
Validation loss: 2.5647805928016605

Epoch: 5| Step: 9
Training loss: 1.174423193884185
Validation loss: 2.509529846832616

Epoch: 5| Step: 10
Training loss: 1.7015022456322177
Validation loss: 2.5223868045701745

Epoch: 5| Step: 11
Training loss: 1.458846692147038
Validation loss: 2.5177878723291016

Epoch: 407| Step: 0
Training loss: 1.6154973878027654
Validation loss: 2.5254791865760278

Epoch: 5| Step: 1
Training loss: 1.6360005917629674
Validation loss: 2.5264524709145375

Epoch: 5| Step: 2
Training loss: 1.762650879698814
Validation loss: 2.554280006503503

Epoch: 5| Step: 3
Training loss: 1.6434635130264656
Validation loss: 2.560341899319221

Epoch: 5| Step: 4
Training loss: 1.5316913513640749
Validation loss: 2.5835890425493164

Epoch: 5| Step: 5
Training loss: 1.3138431760664537
Validation loss: 2.5643327950619557

Epoch: 5| Step: 6
Training loss: 1.238499907914406
Validation loss: 2.620994243827029

Epoch: 5| Step: 7
Training loss: 2.3302739613453856
Validation loss: 2.622525066435338

Epoch: 5| Step: 8
Training loss: 1.700778779994869
Validation loss: 2.6124122136408134

Epoch: 5| Step: 9
Training loss: 1.924749070694136
Validation loss: 2.622894316758086

Epoch: 5| Step: 10
Training loss: 1.7522732411390463
Validation loss: 2.623236196071484

Epoch: 5| Step: 11
Training loss: 2.467267327590567
Validation loss: 2.6604286312072216

Epoch: 408| Step: 0
Training loss: 1.9049758404979469
Validation loss: 2.6143957516579777

Epoch: 5| Step: 1
Training loss: 1.7357568133491197
Validation loss: 2.6290034918067238

Epoch: 5| Step: 2
Training loss: 1.9267805188054803
Validation loss: 2.6243270056729138

Epoch: 5| Step: 3
Training loss: 1.7685549571196646
Validation loss: 2.606844674562569

Epoch: 5| Step: 4
Training loss: 1.9461723173951893
Validation loss: 2.6217581280745734

Epoch: 5| Step: 5
Training loss: 1.3266343222002748
Validation loss: 2.627688854857787

Epoch: 5| Step: 6
Training loss: 1.2718815571383972
Validation loss: 2.607408867849989

Epoch: 5| Step: 7
Training loss: 1.912682483419334
Validation loss: 2.6153104399259215

Epoch: 5| Step: 8
Training loss: 1.7903131503028906
Validation loss: 2.5310550857976546

Epoch: 5| Step: 9
Training loss: 1.389642818651347
Validation loss: 2.5451874046738143

Epoch: 5| Step: 10
Training loss: 1.407440359908447
Validation loss: 2.5430084436368703

Epoch: 5| Step: 11
Training loss: 2.3703574933865688
Validation loss: 2.526335183358571

Epoch: 409| Step: 0
Training loss: 1.715717970477835
Validation loss: 2.545053646006889

Epoch: 5| Step: 1
Training loss: 2.0395721149493236
Validation loss: 2.5336877422559896

Epoch: 5| Step: 2
Training loss: 1.6889330818782804
Validation loss: 2.5536293070226814

Epoch: 5| Step: 3
Training loss: 2.139648771786544
Validation loss: 2.5208595106378806

Epoch: 5| Step: 4
Training loss: 1.6673185345281372
Validation loss: 2.530325791506717

Epoch: 5| Step: 5
Training loss: 1.6883025203778885
Validation loss: 2.5809263442103583

Epoch: 5| Step: 6
Training loss: 1.4164473513464426
Validation loss: 2.5849478058000472

Epoch: 5| Step: 7
Training loss: 1.2413990709542555
Validation loss: 2.5935304751815957

Epoch: 5| Step: 8
Training loss: 1.7889434241767947
Validation loss: 2.570014368176651

Epoch: 5| Step: 9
Training loss: 1.7977543545064016
Validation loss: 2.599557632936382

Epoch: 5| Step: 10
Training loss: 1.8463545684024891
Validation loss: 2.585557880945867

Epoch: 5| Step: 11
Training loss: 1.3431686208252955
Validation loss: 2.632347511108728

Epoch: 410| Step: 0
Training loss: 1.7013078146927065
Validation loss: 2.589882801925642

Epoch: 5| Step: 1
Training loss: 1.834192168760277
Validation loss: 2.5615115333287304

Epoch: 5| Step: 2
Training loss: 1.3706948767930534
Validation loss: 2.5189805387561934

Epoch: 5| Step: 3
Training loss: 1.7610816226393087
Validation loss: 2.573086147414995

Epoch: 5| Step: 4
Training loss: 1.8399334215475132
Validation loss: 2.5644476203636635

Epoch: 5| Step: 5
Training loss: 1.1914645321457913
Validation loss: 2.5664500634853193

Epoch: 5| Step: 6
Training loss: 1.6452993742010784
Validation loss: 2.59422867544205

Epoch: 5| Step: 7
Training loss: 1.360531851822181
Validation loss: 2.568101293170184

Epoch: 5| Step: 8
Training loss: 1.3444966747885456
Validation loss: 2.5644342402905376

Epoch: 5| Step: 9
Training loss: 1.9366144186819245
Validation loss: 2.5218722012932493

Epoch: 5| Step: 10
Training loss: 2.2302858508157373
Validation loss: 2.5467352409475614

Epoch: 5| Step: 11
Training loss: 0.6909041871762106
Validation loss: 2.5724718478991453

Epoch: 411| Step: 0
Training loss: 1.7934408127414638
Validation loss: 2.5462060802706334

Epoch: 5| Step: 1
Training loss: 2.2131893700387657
Validation loss: 2.6035789907480056

Epoch: 5| Step: 2
Training loss: 1.2672863170321271
Validation loss: 2.6016540931256906

Epoch: 5| Step: 3
Training loss: 1.2106078652905812
Validation loss: 2.56606980687266

Epoch: 5| Step: 4
Training loss: 1.3074241307640617
Validation loss: 2.5719687817494843

Epoch: 5| Step: 5
Training loss: 2.0424713054308254
Validation loss: 2.541199001426617

Epoch: 5| Step: 6
Training loss: 1.3529239038184355
Validation loss: 2.569705485638546

Epoch: 5| Step: 7
Training loss: 1.4752532159731135
Validation loss: 2.552038983848483

Epoch: 5| Step: 8
Training loss: 1.997605917441602
Validation loss: 2.582729062553666

Epoch: 5| Step: 9
Training loss: 1.841468887008265
Validation loss: 2.5660011169144243

Epoch: 5| Step: 10
Training loss: 1.117234129032638
Validation loss: 2.5717208698697456

Epoch: 5| Step: 11
Training loss: 1.1627517079037524
Validation loss: 2.5449071743692553

Epoch: 412| Step: 0
Training loss: 1.2766462282249595
Validation loss: 2.5426976986769074

Epoch: 5| Step: 1
Training loss: 1.4101915434333159
Validation loss: 2.53896751617397

Epoch: 5| Step: 2
Training loss: 1.552661975636213
Validation loss: 2.521422090162492

Epoch: 5| Step: 3
Training loss: 1.3836526850636728
Validation loss: 2.505807556425294

Epoch: 5| Step: 4
Training loss: 1.3679412072163233
Validation loss: 2.534047560778537

Epoch: 5| Step: 5
Training loss: 1.6781386220368473
Validation loss: 2.509735621806111

Epoch: 5| Step: 6
Training loss: 1.6102316345010885
Validation loss: 2.537842724585719

Epoch: 5| Step: 7
Training loss: 1.3840348611614142
Validation loss: 2.523467324536326

Epoch: 5| Step: 8
Training loss: 1.8558516257928617
Validation loss: 2.5577307529393325

Epoch: 5| Step: 9
Training loss: 1.9558436279394358
Validation loss: 2.5440045467614483

Epoch: 5| Step: 10
Training loss: 2.1403578988383294
Validation loss: 2.538731781377492

Epoch: 5| Step: 11
Training loss: 1.129429151612155
Validation loss: 2.5445554151784253

Epoch: 413| Step: 0
Training loss: 1.5128615837747275
Validation loss: 2.5597791124486555

Epoch: 5| Step: 1
Training loss: 1.8710529745035114
Validation loss: 2.5641288581364994

Epoch: 5| Step: 2
Training loss: 1.3898702137546723
Validation loss: 2.5752649530496887

Epoch: 5| Step: 3
Training loss: 1.7385041169015512
Validation loss: 2.5542911568174302

Epoch: 5| Step: 4
Training loss: 1.7824538328978827
Validation loss: 2.581526602610263

Epoch: 5| Step: 5
Training loss: 1.7096266929092052
Validation loss: 2.5283773392971867

Epoch: 5| Step: 6
Training loss: 1.551863208838109
Validation loss: 2.519079789909714

Epoch: 5| Step: 7
Training loss: 1.6737248534634712
Validation loss: 2.5220092770778697

Epoch: 5| Step: 8
Training loss: 1.1337810716503505
Validation loss: 2.484538638725671

Epoch: 5| Step: 9
Training loss: 1.4627978877376988
Validation loss: 2.4930133507561467

Epoch: 5| Step: 10
Training loss: 1.7385050768817876
Validation loss: 2.537962545164869

Epoch: 5| Step: 11
Training loss: 1.113250892626809
Validation loss: 2.497019061459098

Epoch: 414| Step: 0
Training loss: 1.3851608766843204
Validation loss: 2.5292254660012445

Epoch: 5| Step: 1
Training loss: 1.3387675509117127
Validation loss: 2.5169372611013556

Epoch: 5| Step: 2
Training loss: 1.9457797672759574
Validation loss: 2.5604073229175124

Epoch: 5| Step: 3
Training loss: 2.2004405230853177
Validation loss: 2.56753089606377

Epoch: 5| Step: 4
Training loss: 1.3910635781639396
Validation loss: 2.5654907800132944

Epoch: 5| Step: 5
Training loss: 1.1894905071930042
Validation loss: 2.530048889930446

Epoch: 5| Step: 6
Training loss: 1.9603662760707732
Validation loss: 2.5524134104579015

Epoch: 5| Step: 7
Training loss: 1.922404890746183
Validation loss: 2.5532806364610843

Epoch: 5| Step: 8
Training loss: 1.2886106681800127
Validation loss: 2.5408944822614083

Epoch: 5| Step: 9
Training loss: 1.3530581363077407
Validation loss: 2.593889657822253

Epoch: 5| Step: 10
Training loss: 1.7026521918882165
Validation loss: 2.5879540777524634

Epoch: 5| Step: 11
Training loss: 2.4897108058669355
Validation loss: 2.6311862518761373

Epoch: 415| Step: 0
Training loss: 1.6724294295768276
Validation loss: 2.5971039416726027

Epoch: 5| Step: 1
Training loss: 1.7608570774401369
Validation loss: 2.5476652257332857

Epoch: 5| Step: 2
Training loss: 1.5950037195048716
Validation loss: 2.579290735273166

Epoch: 5| Step: 3
Training loss: 1.0141429945586942
Validation loss: 2.533411351265777

Epoch: 5| Step: 4
Training loss: 1.6209924137660425
Validation loss: 2.5476721957200095

Epoch: 5| Step: 5
Training loss: 1.328331426398146
Validation loss: 2.5276051601803866

Epoch: 5| Step: 6
Training loss: 1.8912243484199642
Validation loss: 2.518181964441088

Epoch: 5| Step: 7
Training loss: 1.858233574326476
Validation loss: 2.5060405710289664

Epoch: 5| Step: 8
Training loss: 1.3376351439748457
Validation loss: 2.500736163947581

Epoch: 5| Step: 9
Training loss: 1.611810859270787
Validation loss: 2.501353020904799

Epoch: 5| Step: 10
Training loss: 2.007685082099655
Validation loss: 2.492236349171193

Epoch: 5| Step: 11
Training loss: 1.37362853925136
Validation loss: 2.4971702813267864

Epoch: 416| Step: 0
Training loss: 0.857826849812203
Validation loss: 2.5461105338323082

Epoch: 5| Step: 1
Training loss: 2.129660712428399
Validation loss: 2.5785993081949274

Epoch: 5| Step: 2
Training loss: 1.2863849922721018
Validation loss: 2.585633259035376

Epoch: 5| Step: 3
Training loss: 1.5539173921748515
Validation loss: 2.5597040810209237

Epoch: 5| Step: 4
Training loss: 1.831382913290269
Validation loss: 2.576072318828859

Epoch: 5| Step: 5
Training loss: 1.6260627792457276
Validation loss: 2.5270676498890836

Epoch: 5| Step: 6
Training loss: 1.5892355315489106
Validation loss: 2.5432559591946173

Epoch: 5| Step: 7
Training loss: 1.191290027390239
Validation loss: 2.4957634274962404

Epoch: 5| Step: 8
Training loss: 1.4489390470901864
Validation loss: 2.523715455658186

Epoch: 5| Step: 9
Training loss: 1.5591974069380985
Validation loss: 2.503377036249918

Epoch: 5| Step: 10
Training loss: 2.284716963319095
Validation loss: 2.523282980346149

Epoch: 5| Step: 11
Training loss: 1.679241174349551
Validation loss: 2.53107840737407

Epoch: 417| Step: 0
Training loss: 1.7376939788775512
Validation loss: 2.5517749087489334

Epoch: 5| Step: 1
Training loss: 1.6039367940440576
Validation loss: 2.536358599624375

Epoch: 5| Step: 2
Training loss: 1.5725413584159982
Validation loss: 2.5735280253970263

Epoch: 5| Step: 3
Training loss: 1.2198898169525212
Validation loss: 2.5900512965043108

Epoch: 5| Step: 4
Training loss: 1.8547714690022412
Validation loss: 2.5759558096611395

Epoch: 5| Step: 5
Training loss: 1.6089697762845996
Validation loss: 2.632008143861688

Epoch: 5| Step: 6
Training loss: 1.3179301149395917
Validation loss: 2.627604743849077

Epoch: 5| Step: 7
Training loss: 2.2151475055567995
Validation loss: 2.606173025987265

Epoch: 5| Step: 8
Training loss: 1.3917987884499765
Validation loss: 2.601145018720449

Epoch: 5| Step: 9
Training loss: 1.6701387320360026
Validation loss: 2.591913994387783

Epoch: 5| Step: 10
Training loss: 1.3136703178131104
Validation loss: 2.551337504234307

Epoch: 5| Step: 11
Training loss: 1.5618589993771994
Validation loss: 2.5367648052471385

Epoch: 418| Step: 0
Training loss: 1.1903542298332856
Validation loss: 2.4713193202936923

Epoch: 5| Step: 1
Training loss: 1.8186322754188629
Validation loss: 2.484667139051082

Epoch: 5| Step: 2
Training loss: 1.6757856604600323
Validation loss: 2.487372048120747

Epoch: 5| Step: 3
Training loss: 1.6681386963791909
Validation loss: 2.4827700094944793

Epoch: 5| Step: 4
Training loss: 1.6614020486543735
Validation loss: 2.518454056763604

Epoch: 5| Step: 5
Training loss: 1.211819874855898
Validation loss: 2.502618276904946

Epoch: 5| Step: 6
Training loss: 1.4144271464728904
Validation loss: 2.463197411214326

Epoch: 5| Step: 7
Training loss: 1.6988405705687055
Validation loss: 2.4700937436856543

Epoch: 5| Step: 8
Training loss: 1.5106249260103384
Validation loss: 2.5195353308356303

Epoch: 5| Step: 9
Training loss: 1.8718294039412637
Validation loss: 2.4571538590333293

Epoch: 5| Step: 10
Training loss: 1.7381376400034962
Validation loss: 2.4677985929377693

Epoch: 5| Step: 11
Training loss: 1.3343099305772619
Validation loss: 2.511223110816437

Epoch: 419| Step: 0
Training loss: 1.5273108125144932
Validation loss: 2.499500697661153

Epoch: 5| Step: 1
Training loss: 1.2256490622750016
Validation loss: 2.486550532180324

Epoch: 5| Step: 2
Training loss: 1.6449028555758594
Validation loss: 2.451405534081386

Epoch: 5| Step: 3
Training loss: 2.261318770966035
Validation loss: 2.4897601824292805

Epoch: 5| Step: 4
Training loss: 1.4576767215278745
Validation loss: 2.4621027776165847

Epoch: 5| Step: 5
Training loss: 1.7972993432579651
Validation loss: 2.4781508341369074

Epoch: 5| Step: 6
Training loss: 1.7187917530883778
Validation loss: 2.481143000719472

Epoch: 5| Step: 7
Training loss: 1.7882725333371754
Validation loss: 2.4898216753291207

Epoch: 5| Step: 8
Training loss: 1.4098222078006972
Validation loss: 2.5390894453135044

Epoch: 5| Step: 9
Training loss: 1.7261660021345133
Validation loss: 2.551030797663928

Epoch: 5| Step: 10
Training loss: 1.5592240132412076
Validation loss: 2.5083301798165945

Epoch: 5| Step: 11
Training loss: 0.9843855963242613
Validation loss: 2.538060200761206

Epoch: 420| Step: 0
Training loss: 1.5242582799965967
Validation loss: 2.56391290347991

Epoch: 5| Step: 1
Training loss: 2.1541414870580455
Validation loss: 2.551907740929557

Epoch: 5| Step: 2
Training loss: 1.8724276381237717
Validation loss: 2.5493483167247737

Epoch: 5| Step: 3
Training loss: 1.4913381186300374
Validation loss: 2.5495242477551194

Epoch: 5| Step: 4
Training loss: 1.396321277831061
Validation loss: 2.556081206975363

Epoch: 5| Step: 5
Training loss: 1.681272956095818
Validation loss: 2.521766349377437

Epoch: 5| Step: 6
Training loss: 0.9674627303798696
Validation loss: 2.52783835050881

Epoch: 5| Step: 7
Training loss: 1.6832741701789335
Validation loss: 2.5394863811655246

Epoch: 5| Step: 8
Training loss: 1.593929355477427
Validation loss: 2.5519226348003774

Epoch: 5| Step: 9
Training loss: 1.1688909557837555
Validation loss: 2.5653146815529837

Epoch: 5| Step: 10
Training loss: 1.8299653660774815
Validation loss: 2.517491767532692

Epoch: 5| Step: 11
Training loss: 1.2348273691767975
Validation loss: 2.478186968092356

Epoch: 421| Step: 0
Training loss: 1.7233192050485058
Validation loss: 2.4742902847579193

Epoch: 5| Step: 1
Training loss: 1.1022270849229168
Validation loss: 2.4848557732787806

Epoch: 5| Step: 2
Training loss: 1.1133354843046535
Validation loss: 2.5033272893653202

Epoch: 5| Step: 3
Training loss: 1.7274655013221123
Validation loss: 2.469643825373463

Epoch: 5| Step: 4
Training loss: 1.251496515903965
Validation loss: 2.491261743784862

Epoch: 5| Step: 5
Training loss: 1.7470355129027875
Validation loss: 2.5305030803936788

Epoch: 5| Step: 6
Training loss: 1.2232470562695
Validation loss: 2.5301931671048203

Epoch: 5| Step: 7
Training loss: 1.5458716018477776
Validation loss: 2.473886371703668

Epoch: 5| Step: 8
Training loss: 1.9060947167357898
Validation loss: 2.4744341456298105

Epoch: 5| Step: 9
Training loss: 1.5591535972945914
Validation loss: 2.462197369812606

Epoch: 5| Step: 10
Training loss: 1.908693842033653
Validation loss: 2.4597214696696206

Epoch: 5| Step: 11
Training loss: 2.0075227402174636
Validation loss: 2.4934897772222033

Epoch: 422| Step: 0
Training loss: 1.4577599715309026
Validation loss: 2.5485466266954795

Epoch: 5| Step: 1
Training loss: 1.5181521553761232
Validation loss: 2.621417765101988

Epoch: 5| Step: 2
Training loss: 2.1514719116377425
Validation loss: 2.556688716738219

Epoch: 5| Step: 3
Training loss: 1.4238076123511687
Validation loss: 2.5293323646912893

Epoch: 5| Step: 4
Training loss: 1.5734697173834733
Validation loss: 2.5496995218271516

Epoch: 5| Step: 5
Training loss: 2.009996228570389
Validation loss: 2.5322206896542063

Epoch: 5| Step: 6
Training loss: 1.7844544080712355
Validation loss: 2.5348970959635886

Epoch: 5| Step: 7
Training loss: 1.2454155298974234
Validation loss: 2.5605188790620868

Epoch: 5| Step: 8
Training loss: 1.5524909062510832
Validation loss: 2.5219429243316402

Epoch: 5| Step: 9
Training loss: 1.685655504176273
Validation loss: 2.4899873179632377

Epoch: 5| Step: 10
Training loss: 0.9139164212867915
Validation loss: 2.542799213967445

Epoch: 5| Step: 11
Training loss: 1.0137447852813146
Validation loss: 2.5541461367090594

Epoch: 423| Step: 0
Training loss: 1.9624350251539666
Validation loss: 2.5626978952860817

Epoch: 5| Step: 1
Training loss: 1.4070387006072038
Validation loss: 2.5589988950712326

Epoch: 5| Step: 2
Training loss: 2.1448385160966863
Validation loss: 2.578237384697096

Epoch: 5| Step: 3
Training loss: 1.4031058873019688
Validation loss: 2.5945199758086948

Epoch: 5| Step: 4
Training loss: 2.291493137609872
Validation loss: 2.5914411916400204

Epoch: 5| Step: 5
Training loss: 1.226376075912904
Validation loss: 2.578179823167297

Epoch: 5| Step: 6
Training loss: 1.8675184395529572
Validation loss: 2.5895737957542204

Epoch: 5| Step: 7
Training loss: 1.2472925906636936
Validation loss: 2.64043263293337

Epoch: 5| Step: 8
Training loss: 1.8883087850637732
Validation loss: 2.6658039498048836

Epoch: 5| Step: 9
Training loss: 1.5964459822751629
Validation loss: 2.703938705336259

Epoch: 5| Step: 10
Training loss: 1.207683695529283
Validation loss: 2.645926580262748

Epoch: 5| Step: 11
Training loss: 1.3905047246804019
Validation loss: 2.6280856200241507

Epoch: 424| Step: 0
Training loss: 1.8367584341054672
Validation loss: 2.5339851633039996

Epoch: 5| Step: 1
Training loss: 1.7948243090789737
Validation loss: 2.5274999178198736

Epoch: 5| Step: 2
Training loss: 1.8852127414527753
Validation loss: 2.4765221264553703

Epoch: 5| Step: 3
Training loss: 1.656181118090591
Validation loss: 2.520155008861958

Epoch: 5| Step: 4
Training loss: 1.6574007750855404
Validation loss: 2.4927096183689588

Epoch: 5| Step: 5
Training loss: 1.8276727883287833
Validation loss: 2.5157806237776774

Epoch: 5| Step: 6
Training loss: 1.2827494616242496
Validation loss: 2.4793424056513214

Epoch: 5| Step: 7
Training loss: 1.8537207792400867
Validation loss: 2.4789736209101667

Epoch: 5| Step: 8
Training loss: 1.1181810136201478
Validation loss: 2.506056060564689

Epoch: 5| Step: 9
Training loss: 1.6613239086464469
Validation loss: 2.557875620304536

Epoch: 5| Step: 10
Training loss: 0.994089001587427
Validation loss: 2.5530284273457813

Epoch: 5| Step: 11
Training loss: 0.5903411183000982
Validation loss: 2.524171197007065

Epoch: 425| Step: 0
Training loss: 1.0175572135079904
Validation loss: 2.5211952845496595

Epoch: 5| Step: 1
Training loss: 1.2593040389522152
Validation loss: 2.558599857390979

Epoch: 5| Step: 2
Training loss: 2.023984268134876
Validation loss: 2.5225664688504694

Epoch: 5| Step: 3
Training loss: 1.4104073847695826
Validation loss: 2.5411489785475885

Epoch: 5| Step: 4
Training loss: 1.3903277647415573
Validation loss: 2.5411677040138345

Epoch: 5| Step: 5
Training loss: 1.2505912336207259
Validation loss: 2.5195265540737184

Epoch: 5| Step: 6
Training loss: 1.8425168585038374
Validation loss: 2.5335378982013608

Epoch: 5| Step: 7
Training loss: 1.9162420825334336
Validation loss: 2.5296267104154

Epoch: 5| Step: 8
Training loss: 1.7345969255757716
Validation loss: 2.601583138995931

Epoch: 5| Step: 9
Training loss: 1.3258048042538328
Validation loss: 2.5819306115925666

Epoch: 5| Step: 10
Training loss: 2.0525961556254506
Validation loss: 2.6068970112681877

Epoch: 5| Step: 11
Training loss: 1.9624194134731292
Validation loss: 2.6578687036586786

Epoch: 426| Step: 0
Training loss: 1.0808973189222668
Validation loss: 2.6392091081368725

Epoch: 5| Step: 1
Training loss: 1.6712213825066786
Validation loss: 2.6238531528990743

Epoch: 5| Step: 2
Training loss: 1.8038483357209056
Validation loss: 2.6377543810346253

Epoch: 5| Step: 3
Training loss: 1.2695980113155123
Validation loss: 2.6694613517442365

Epoch: 5| Step: 4
Training loss: 2.0157993448248246
Validation loss: 2.6475513780043474

Epoch: 5| Step: 5
Training loss: 1.5409998439662491
Validation loss: 2.6490715453186326

Epoch: 5| Step: 6
Training loss: 2.191470548125062
Validation loss: 2.6588520320294684

Epoch: 5| Step: 7
Training loss: 1.4191217280000459
Validation loss: 2.664756289295424

Epoch: 5| Step: 8
Training loss: 1.8912520196453841
Validation loss: 2.6386805528808175

Epoch: 5| Step: 9
Training loss: 1.7438464285053707
Validation loss: 2.6411061873657773

Epoch: 5| Step: 10
Training loss: 2.1480912363008833
Validation loss: 2.6565043121966796

Epoch: 5| Step: 11
Training loss: 1.192193943471232
Validation loss: 2.6571390571471847

Epoch: 427| Step: 0
Training loss: 1.9672059558975266
Validation loss: 2.624017652744911

Epoch: 5| Step: 1
Training loss: 1.1989417237634596
Validation loss: 2.5671800156289

Epoch: 5| Step: 2
Training loss: 1.7229072232277813
Validation loss: 2.58576739271296

Epoch: 5| Step: 3
Training loss: 2.4849769294941972
Validation loss: 2.53635766353745

Epoch: 5| Step: 4
Training loss: 1.0081012519172499
Validation loss: 2.533514842371919

Epoch: 5| Step: 5
Training loss: 1.8058326687860726
Validation loss: 2.5791342214557758

Epoch: 5| Step: 6
Training loss: 1.2487075799986438
Validation loss: 2.578559345687033

Epoch: 5| Step: 7
Training loss: 1.90914746815844
Validation loss: 2.591154808080009

Epoch: 5| Step: 8
Training loss: 1.7641798874052277
Validation loss: 2.5626224666887043

Epoch: 5| Step: 9
Training loss: 1.3850122832018696
Validation loss: 2.5534289659634437

Epoch: 5| Step: 10
Training loss: 1.989171876020233
Validation loss: 2.5775583126059107

Epoch: 5| Step: 11
Training loss: 1.40944858874865
Validation loss: 2.6045981749023928

Epoch: 428| Step: 0
Training loss: 1.4309639157558063
Validation loss: 2.6095032346361515

Epoch: 5| Step: 1
Training loss: 1.807270068242043
Validation loss: 2.6511343369590596

Epoch: 5| Step: 2
Training loss: 1.7243985385262974
Validation loss: 2.6597960233340183

Epoch: 5| Step: 3
Training loss: 1.6113084456658118
Validation loss: 2.672403591880522

Epoch: 5| Step: 4
Training loss: 1.7239063251252973
Validation loss: 2.703357172056171

Epoch: 5| Step: 5
Training loss: 2.003946225843952
Validation loss: 2.699804585649632

Epoch: 5| Step: 6
Training loss: 2.2517669944896928
Validation loss: 2.720453123503822

Epoch: 5| Step: 7
Training loss: 1.2569781077017916
Validation loss: 2.628471176021832

Epoch: 5| Step: 8
Training loss: 1.3516717767364075
Validation loss: 2.564832579408013

Epoch: 5| Step: 9
Training loss: 1.3027784348662201
Validation loss: 2.548086428243905

Epoch: 5| Step: 10
Training loss: 1.1554979507646006
Validation loss: 2.53931910074074

Epoch: 5| Step: 11
Training loss: 0.21244452923556084
Validation loss: 2.516139741917978

Epoch: 429| Step: 0
Training loss: 1.3479150938155575
Validation loss: 2.534043826734837

Epoch: 5| Step: 1
Training loss: 1.8306608300367213
Validation loss: 2.477297632675765

Epoch: 5| Step: 2
Training loss: 2.141429332342933
Validation loss: 2.508846960888261

Epoch: 5| Step: 3
Training loss: 1.2265903931380076
Validation loss: 2.47930320529381

Epoch: 5| Step: 4
Training loss: 1.7172081707447013
Validation loss: 2.5033409285864

Epoch: 5| Step: 5
Training loss: 1.4620163142159006
Validation loss: 2.5334337139842455

Epoch: 5| Step: 6
Training loss: 0.8852746774853046
Validation loss: 2.503970716165303

Epoch: 5| Step: 7
Training loss: 1.068318144789001
Validation loss: 2.4957503598473507

Epoch: 5| Step: 8
Training loss: 2.163892388113139
Validation loss: 2.531332709291599

Epoch: 5| Step: 9
Training loss: 1.8882670555480856
Validation loss: 2.560438439473467

Epoch: 5| Step: 10
Training loss: 1.332025790832609
Validation loss: 2.5619784033651984

Epoch: 5| Step: 11
Training loss: 1.1993765960094334
Validation loss: 2.517240897775908

Epoch: 430| Step: 0
Training loss: 1.5202024884621501
Validation loss: 2.56180755827371

Epoch: 5| Step: 1
Training loss: 1.094315791246743
Validation loss: 2.553437029005527

Epoch: 5| Step: 2
Training loss: 1.0012298412412932
Validation loss: 2.567915481867515

Epoch: 5| Step: 3
Training loss: 1.2553649688535677
Validation loss: 2.5691478490764155

Epoch: 5| Step: 4
Training loss: 1.799101668940793
Validation loss: 2.5226706568894404

Epoch: 5| Step: 5
Training loss: 2.447105359844851
Validation loss: 2.4991052496655057

Epoch: 5| Step: 6
Training loss: 1.3853261052794572
Validation loss: 2.4453377768090676

Epoch: 5| Step: 7
Training loss: 1.35852225731401
Validation loss: 2.517438629681506

Epoch: 5| Step: 8
Training loss: 1.4144011876964329
Validation loss: 2.470724467108704

Epoch: 5| Step: 9
Training loss: 1.630654181631977
Validation loss: 2.4652440974721257

Epoch: 5| Step: 10
Training loss: 1.3492123230922992
Validation loss: 2.4601270057520543

Epoch: 5| Step: 11
Training loss: 1.1441948301864302
Validation loss: 2.4643531710117212

Epoch: 431| Step: 0
Training loss: 2.067101749132313
Validation loss: 2.5015174671053537

Epoch: 5| Step: 1
Training loss: 1.863284832773023
Validation loss: 2.5129074044727107

Epoch: 5| Step: 2
Training loss: 1.8003197862755451
Validation loss: 2.4864320975492196

Epoch: 5| Step: 3
Training loss: 1.410358108063678
Validation loss: 2.5098490779078975

Epoch: 5| Step: 4
Training loss: 1.5375549368619021
Validation loss: 2.568445035523699

Epoch: 5| Step: 5
Training loss: 1.5617993118857139
Validation loss: 2.593363798259999

Epoch: 5| Step: 6
Training loss: 1.3364279220502584
Validation loss: 2.5813364737976134

Epoch: 5| Step: 7
Training loss: 1.3424360371559534
Validation loss: 2.572575126918904

Epoch: 5| Step: 8
Training loss: 1.1863450406815133
Validation loss: 2.440922317353478

Epoch: 5| Step: 9
Training loss: 1.4415853745725213
Validation loss: 2.452233462300957

Epoch: 5| Step: 10
Training loss: 0.95463567365209
Validation loss: 2.4912098688063256

Epoch: 5| Step: 11
Training loss: 0.9371875878181684
Validation loss: 2.4877390827286594

Epoch: 432| Step: 0
Training loss: 1.4991361991892138
Validation loss: 2.532832922314835

Epoch: 5| Step: 1
Training loss: 2.178853412040863
Validation loss: 2.4800789153774287

Epoch: 5| Step: 2
Training loss: 1.1905417385675154
Validation loss: 2.505228745713747

Epoch: 5| Step: 3
Training loss: 1.4708486132958256
Validation loss: 2.50165718704764

Epoch: 5| Step: 4
Training loss: 1.2731788232107037
Validation loss: 2.516803552260603

Epoch: 5| Step: 5
Training loss: 1.3270078560741068
Validation loss: 2.50577665743996

Epoch: 5| Step: 6
Training loss: 1.375943510417993
Validation loss: 2.569918740517956

Epoch: 5| Step: 7
Training loss: 1.220204781089711
Validation loss: 2.5496748413078407

Epoch: 5| Step: 8
Training loss: 1.4821854353811323
Validation loss: 2.5583476678672414

Epoch: 5| Step: 9
Training loss: 2.1299421397485796
Validation loss: 2.552920816506442

Epoch: 5| Step: 10
Training loss: 1.1612259271629295
Validation loss: 2.5139959324538537

Epoch: 5| Step: 11
Training loss: 1.033075450948279
Validation loss: 2.5884925113567445

Epoch: 433| Step: 0
Training loss: 1.8002699252237597
Validation loss: 2.577041232495788

Epoch: 5| Step: 1
Training loss: 1.2487991763981579
Validation loss: 2.538455716523713

Epoch: 5| Step: 2
Training loss: 1.5958453597104498
Validation loss: 2.563660079926596

Epoch: 5| Step: 3
Training loss: 1.125973068721542
Validation loss: 2.5562008022122438

Epoch: 5| Step: 4
Training loss: 1.905034224735913
Validation loss: 2.5717486125286806

Epoch: 5| Step: 5
Training loss: 1.7543901825109616
Validation loss: 2.5540210717903253

Epoch: 5| Step: 6
Training loss: 1.2248349020115605
Validation loss: 2.542311201034339

Epoch: 5| Step: 7
Training loss: 1.3060414946391632
Validation loss: 2.5327662608659804

Epoch: 5| Step: 8
Training loss: 1.5801562088391405
Validation loss: 2.4841811806270666

Epoch: 5| Step: 9
Training loss: 1.1767392738749776
Validation loss: 2.4802390084792285

Epoch: 5| Step: 10
Training loss: 1.399764427733427
Validation loss: 2.5070186836178956

Epoch: 5| Step: 11
Training loss: 1.6919277171393623
Validation loss: 2.4867373097572343

Epoch: 434| Step: 0
Training loss: 1.5558413723596776
Validation loss: 2.543367662212713

Epoch: 5| Step: 1
Training loss: 1.5063797067852462
Validation loss: 2.618908436852454

Epoch: 5| Step: 2
Training loss: 1.3365895425675391
Validation loss: 2.7076765706848085

Epoch: 5| Step: 3
Training loss: 1.8048483376440145
Validation loss: 2.774955323435302

Epoch: 5| Step: 4
Training loss: 1.4358707815118117
Validation loss: 2.7306510053138338

Epoch: 5| Step: 5
Training loss: 1.7260932802607323
Validation loss: 2.651485924260367

Epoch: 5| Step: 6
Training loss: 1.2876680171925567
Validation loss: 2.5581610044307808

Epoch: 5| Step: 7
Training loss: 1.4296263801559372
Validation loss: 2.52730185480391

Epoch: 5| Step: 8
Training loss: 1.8555677528069294
Validation loss: 2.485902556552015

Epoch: 5| Step: 9
Training loss: 1.9441570236069374
Validation loss: 2.492204739820908

Epoch: 5| Step: 10
Training loss: 1.960335019634637
Validation loss: 2.444018501968843

Epoch: 5| Step: 11
Training loss: 0.8796540194656631
Validation loss: 2.5123517873645635

Epoch: 435| Step: 0
Training loss: 1.4545684536286025
Validation loss: 2.510257095921574

Epoch: 5| Step: 1
Training loss: 1.3985736290510682
Validation loss: 2.5331613247495466

Epoch: 5| Step: 2
Training loss: 2.2508483982629506
Validation loss: 2.5548622254360027

Epoch: 5| Step: 3
Training loss: 1.6884428145575454
Validation loss: 2.5555496705259295

Epoch: 5| Step: 4
Training loss: 1.1379967809909821
Validation loss: 2.534989024771182

Epoch: 5| Step: 5
Training loss: 1.8333667044058852
Validation loss: 2.559930431847494

Epoch: 5| Step: 6
Training loss: 1.3787330756441298
Validation loss: 2.5791817551162777

Epoch: 5| Step: 7
Training loss: 1.7366325875280386
Validation loss: 2.5223616362532666

Epoch: 5| Step: 8
Training loss: 1.0959204799873987
Validation loss: 2.5320326846992707

Epoch: 5| Step: 9
Training loss: 1.417363229305901
Validation loss: 2.5759074837279674

Epoch: 5| Step: 10
Training loss: 0.962226406449399
Validation loss: 2.5596345294036604

Epoch: 5| Step: 11
Training loss: 1.655708224378221
Validation loss: 2.52465549989354

Epoch: 436| Step: 0
Training loss: 1.3565301614565544
Validation loss: 2.5350961349875663

Epoch: 5| Step: 1
Training loss: 1.492463650540342
Validation loss: 2.49846663140957

Epoch: 5| Step: 2
Training loss: 1.9453677740249014
Validation loss: 2.547561880526256

Epoch: 5| Step: 3
Training loss: 1.912931956958034
Validation loss: 2.505834381621099

Epoch: 5| Step: 4
Training loss: 1.087940262872564
Validation loss: 2.513690390193856

Epoch: 5| Step: 5
Training loss: 1.2144382695528433
Validation loss: 2.513602523815273

Epoch: 5| Step: 6
Training loss: 1.464180025413565
Validation loss: 2.524179835616282

Epoch: 5| Step: 7
Training loss: 1.5222954014701477
Validation loss: 2.503758093328373

Epoch: 5| Step: 8
Training loss: 1.4036802336016705
Validation loss: 2.483466048075976

Epoch: 5| Step: 9
Training loss: 1.3545108455591284
Validation loss: 2.524040287958027

Epoch: 5| Step: 10
Training loss: 1.4146942076493478
Validation loss: 2.4861372329776907

Epoch: 5| Step: 11
Training loss: 1.5734043333768541
Validation loss: 2.4802954986221564

Epoch: 437| Step: 0
Training loss: 1.2485019290039903
Validation loss: 2.4918465974093382

Epoch: 5| Step: 1
Training loss: 1.1505911220057505
Validation loss: 2.5027190680561935

Epoch: 5| Step: 2
Training loss: 1.6187161946540998
Validation loss: 2.4890318596265666

Epoch: 5| Step: 3
Training loss: 1.1507804482140633
Validation loss: 2.494399684355977

Epoch: 5| Step: 4
Training loss: 1.41081759090094
Validation loss: 2.5016746038399504

Epoch: 5| Step: 5
Training loss: 1.5229978269284752
Validation loss: 2.4912869890309066

Epoch: 5| Step: 6
Training loss: 1.8671015635869355
Validation loss: 2.477600072847044

Epoch: 5| Step: 7
Training loss: 1.554819532759176
Validation loss: 2.4841453917981964

Epoch: 5| Step: 8
Training loss: 1.197370863702951
Validation loss: 2.5784134404828314

Epoch: 5| Step: 9
Training loss: 1.042071696057191
Validation loss: 2.6139526037026357

Epoch: 5| Step: 10
Training loss: 2.1734119712707005
Validation loss: 2.6050360194929714

Epoch: 5| Step: 11
Training loss: 0.7858887477186202
Validation loss: 2.6327219116443588

Epoch: 438| Step: 0
Training loss: 1.3959493399092966
Validation loss: 2.692618098613207

Epoch: 5| Step: 1
Training loss: 1.9402416888829332
Validation loss: 2.6557901059121787

Epoch: 5| Step: 2
Training loss: 1.5878169757049432
Validation loss: 2.6439448635772274

Epoch: 5| Step: 3
Training loss: 1.5464414509180597
Validation loss: 2.5827657950367606

Epoch: 5| Step: 4
Training loss: 1.4615849167085708
Validation loss: 2.547623031073657

Epoch: 5| Step: 5
Training loss: 1.4584674046967057
Validation loss: 2.511084170390967

Epoch: 5| Step: 6
Training loss: 1.4255671092132014
Validation loss: 2.5514006045314837

Epoch: 5| Step: 7
Training loss: 1.4121640776489637
Validation loss: 2.4785439540004592

Epoch: 5| Step: 8
Training loss: 1.2510039112874582
Validation loss: 2.487590188798798

Epoch: 5| Step: 9
Training loss: 1.7791286351280622
Validation loss: 2.4944062476135263

Epoch: 5| Step: 10
Training loss: 1.1448906864641408
Validation loss: 2.51172416453077

Epoch: 5| Step: 11
Training loss: 0.28058484684390833
Validation loss: 2.4597869726729487

Epoch: 439| Step: 0
Training loss: 1.4847547346567282
Validation loss: 2.493837661285952

Epoch: 5| Step: 1
Training loss: 0.9272926965686499
Validation loss: 2.5157081756109885

Epoch: 5| Step: 2
Training loss: 2.0517603689447426
Validation loss: 2.5420557190748343

Epoch: 5| Step: 3
Training loss: 1.203004112610799
Validation loss: 2.5269737857263515

Epoch: 5| Step: 4
Training loss: 1.8874124392984901
Validation loss: 2.5440182451470115

Epoch: 5| Step: 5
Training loss: 1.3083786517189142
Validation loss: 2.5360978371009457

Epoch: 5| Step: 6
Training loss: 1.0662186565912877
Validation loss: 2.5423720832249184

Epoch: 5| Step: 7
Training loss: 1.3851592845420926
Validation loss: 2.5400015771884727

Epoch: 5| Step: 8
Training loss: 1.075346365287017
Validation loss: 2.5192816460354854

Epoch: 5| Step: 9
Training loss: 1.5746320082661531
Validation loss: 2.526426900741146

Epoch: 5| Step: 10
Training loss: 1.5468803945119793
Validation loss: 2.496725608357421

Epoch: 5| Step: 11
Training loss: 1.4210837541577825
Validation loss: 2.497025219994139

Epoch: 440| Step: 0
Training loss: 1.1830265209324053
Validation loss: 2.5040492722662453

Epoch: 5| Step: 1
Training loss: 1.412834097585996
Validation loss: 2.5032447778346403

Epoch: 5| Step: 2
Training loss: 1.4638733765087648
Validation loss: 2.4943895208308398

Epoch: 5| Step: 3
Training loss: 1.108924559363704
Validation loss: 2.4988127034856245

Epoch: 5| Step: 4
Training loss: 1.8888638703553102
Validation loss: 2.4768866438186485

Epoch: 5| Step: 5
Training loss: 1.1201268721995774
Validation loss: 2.5430381363066625

Epoch: 5| Step: 6
Training loss: 1.6014030563258628
Validation loss: 2.542478233801871

Epoch: 5| Step: 7
Training loss: 1.9589960586640618
Validation loss: 2.5339853279586735

Epoch: 5| Step: 8
Training loss: 1.0519490046089353
Validation loss: 2.5618706760027217

Epoch: 5| Step: 9
Training loss: 0.7568399146190865
Validation loss: 2.5543111043625983

Epoch: 5| Step: 10
Training loss: 1.5157140332056516
Validation loss: 2.5737997205074605

Epoch: 5| Step: 11
Training loss: 1.7360709206909437
Validation loss: 2.568409521582743

Epoch: 441| Step: 0
Training loss: 1.5515166491968384
Validation loss: 2.5284803999669885

Epoch: 5| Step: 1
Training loss: 1.2518042893991577
Validation loss: 2.481572631948479

Epoch: 5| Step: 2
Training loss: 2.0054005188103265
Validation loss: 2.5039429327171696

Epoch: 5| Step: 3
Training loss: 1.4744898867669383
Validation loss: 2.49759277240813

Epoch: 5| Step: 4
Training loss: 1.040108004152073
Validation loss: 2.473120570968944

Epoch: 5| Step: 5
Training loss: 1.0022439813354675
Validation loss: 2.4837921266546132

Epoch: 5| Step: 6
Training loss: 1.0224928245199392
Validation loss: 2.4119733352497286

Epoch: 5| Step: 7
Training loss: 1.7181161578725546
Validation loss: 2.4445544805710133

Epoch: 5| Step: 8
Training loss: 1.4420826883139164
Validation loss: 2.4615056749446733

Epoch: 5| Step: 9
Training loss: 1.6139813767437678
Validation loss: 2.484431733977101

Epoch: 5| Step: 10
Training loss: 1.4850597207747498
Validation loss: 2.577473355792885

Epoch: 5| Step: 11
Training loss: 0.7786059076966486
Validation loss: 2.6081153776026516

Epoch: 442| Step: 0
Training loss: 1.5855062866278782
Validation loss: 2.6490540813543126

Epoch: 5| Step: 1
Training loss: 1.1444245897399978
Validation loss: 2.6714220908673827

Epoch: 5| Step: 2
Training loss: 1.6872670048116638
Validation loss: 2.6265652546290457

Epoch: 5| Step: 3
Training loss: 1.5818654668152217
Validation loss: 2.588153277809751

Epoch: 5| Step: 4
Training loss: 1.687133325370127
Validation loss: 2.5528975582720337

Epoch: 5| Step: 5
Training loss: 1.0054747207096786
Validation loss: 2.504082918009684

Epoch: 5| Step: 6
Training loss: 1.3929439026846366
Validation loss: 2.512775631868849

Epoch: 5| Step: 7
Training loss: 1.9457302640727374
Validation loss: 2.489291632227865

Epoch: 5| Step: 8
Training loss: 1.3104783337289148
Validation loss: 2.5038686780248125

Epoch: 5| Step: 9
Training loss: 1.4229573751782225
Validation loss: 2.485951425324349

Epoch: 5| Step: 10
Training loss: 1.277728194965565
Validation loss: 2.484428749062855

Epoch: 5| Step: 11
Training loss: 2.0260104166348674
Validation loss: 2.4582172678903254

Epoch: 443| Step: 0
Training loss: 1.7693246885077474
Validation loss: 2.5199981670808183

Epoch: 5| Step: 1
Training loss: 1.6373305895582522
Validation loss: 2.580371837083855

Epoch: 5| Step: 2
Training loss: 1.6849089616581447
Validation loss: 2.653708068197735

Epoch: 5| Step: 3
Training loss: 1.2342141927926433
Validation loss: 2.7520288114515807

Epoch: 5| Step: 4
Training loss: 2.02613891786564
Validation loss: 2.8001946402915654

Epoch: 5| Step: 5
Training loss: 1.6428782657189422
Validation loss: 2.710317003840232

Epoch: 5| Step: 6
Training loss: 1.6258363772151472
Validation loss: 2.6613700327001575

Epoch: 5| Step: 7
Training loss: 1.6970185164709786
Validation loss: 2.592454218924638

Epoch: 5| Step: 8
Training loss: 1.245985403103997
Validation loss: 2.5472019079365067

Epoch: 5| Step: 9
Training loss: 1.006950423708881
Validation loss: 2.51992197481722

Epoch: 5| Step: 10
Training loss: 1.50605078048506
Validation loss: 2.4619567213709184

Epoch: 5| Step: 11
Training loss: 1.410273412344109
Validation loss: 2.5071489361364683

Epoch: 444| Step: 0
Training loss: 1.710603585602227
Validation loss: 2.5386879317000903

Epoch: 5| Step: 1
Training loss: 1.281677267893058
Validation loss: 2.514144896426812

Epoch: 5| Step: 2
Training loss: 1.5932931432217445
Validation loss: 2.516448105443552

Epoch: 5| Step: 3
Training loss: 1.082418489536923
Validation loss: 2.515713988284109

Epoch: 5| Step: 4
Training loss: 1.2481506495545558
Validation loss: 2.52849747484139

Epoch: 5| Step: 5
Training loss: 1.5764046536113405
Validation loss: 2.5302371129587002

Epoch: 5| Step: 6
Training loss: 1.1048388084804992
Validation loss: 2.5587850639898835

Epoch: 5| Step: 7
Training loss: 1.472462041783352
Validation loss: 2.568230582949675

Epoch: 5| Step: 8
Training loss: 1.6371793622307789
Validation loss: 2.618317017764423

Epoch: 5| Step: 9
Training loss: 1.484630843751408
Validation loss: 2.613411550879954

Epoch: 5| Step: 10
Training loss: 1.6087563816468613
Validation loss: 2.6491447299646214

Epoch: 5| Step: 11
Training loss: 3.4676313916363313
Validation loss: 2.6107778185707473

Epoch: 445| Step: 0
Training loss: 1.5562293300251784
Validation loss: 2.63673091555956

Epoch: 5| Step: 1
Training loss: 1.079964768046985
Validation loss: 2.6090010681547366

Epoch: 5| Step: 2
Training loss: 1.7156363287101777
Validation loss: 2.6253919762913127

Epoch: 5| Step: 3
Training loss: 1.9416473054807393
Validation loss: 2.5709194946895053

Epoch: 5| Step: 4
Training loss: 1.4765317398984732
Validation loss: 2.555188445848303

Epoch: 5| Step: 5
Training loss: 1.1917221400991826
Validation loss: 2.5110228045504246

Epoch: 5| Step: 6
Training loss: 1.3228945342287577
Validation loss: 2.4866906176769565

Epoch: 5| Step: 7
Training loss: 1.3765734426386067
Validation loss: 2.505497122051723

Epoch: 5| Step: 8
Training loss: 0.8822196725403588
Validation loss: 2.5179758440881006

Epoch: 5| Step: 9
Training loss: 1.7463020354090817
Validation loss: 2.4639642842227025

Epoch: 5| Step: 10
Training loss: 1.3228221719389583
Validation loss: 2.4771091768367337

Epoch: 5| Step: 11
Training loss: 0.890910454228832
Validation loss: 2.502148404467677

Epoch: 446| Step: 0
Training loss: 1.1214918964788814
Validation loss: 2.483879659762787

Epoch: 5| Step: 1
Training loss: 1.3442333594085567
Validation loss: 2.586143854211439

Epoch: 5| Step: 2
Training loss: 0.906811770253299
Validation loss: 2.5380148227577948

Epoch: 5| Step: 3
Training loss: 1.7677299307869607
Validation loss: 2.509935646878614

Epoch: 5| Step: 4
Training loss: 1.4918930801811037
Validation loss: 2.520244726052972

Epoch: 5| Step: 5
Training loss: 1.1767288900912782
Validation loss: 2.462703523277536

Epoch: 5| Step: 6
Training loss: 1.538411191428268
Validation loss: 2.4861824470428457

Epoch: 5| Step: 7
Training loss: 1.304143780922903
Validation loss: 2.4721348148930433

Epoch: 5| Step: 8
Training loss: 1.6514984205043814
Validation loss: 2.4588974989617585

Epoch: 5| Step: 9
Training loss: 1.3539796064241243
Validation loss: 2.451259300425677

Epoch: 5| Step: 10
Training loss: 2.04276929651226
Validation loss: 2.475813623074046

Epoch: 5| Step: 11
Training loss: 1.3578439618889413
Validation loss: 2.5071245796834827

Epoch: 447| Step: 0
Training loss: 1.6599528827644618
Validation loss: 2.4832535317792463

Epoch: 5| Step: 1
Training loss: 1.022444090025806
Validation loss: 2.5304136935482044

Epoch: 5| Step: 2
Training loss: 1.4529126740249343
Validation loss: 2.5523549940883075

Epoch: 5| Step: 3
Training loss: 1.3771332751445577
Validation loss: 2.4935973274451815

Epoch: 5| Step: 4
Training loss: 2.025577312168262
Validation loss: 2.4984487966314295

Epoch: 5| Step: 5
Training loss: 1.3237679763596377
Validation loss: 2.5372557134127645

Epoch: 5| Step: 6
Training loss: 0.6192455984951736
Validation loss: 2.52072504825104

Epoch: 5| Step: 7
Training loss: 1.06976850287083
Validation loss: 2.5325473043336206

Epoch: 5| Step: 8
Training loss: 1.4793313521282676
Validation loss: 2.533712562820187

Epoch: 5| Step: 9
Training loss: 1.4939890267251288
Validation loss: 2.518945634783777

Epoch: 5| Step: 10
Training loss: 1.0448839412470479
Validation loss: 2.524698660749875

Epoch: 5| Step: 11
Training loss: 0.784908616219871
Validation loss: 2.531869286654946

Epoch: 448| Step: 0
Training loss: 1.457037958942748
Validation loss: 2.50236004059795

Epoch: 5| Step: 1
Training loss: 1.454346994114806
Validation loss: 2.4643701782553475

Epoch: 5| Step: 2
Training loss: 1.3294117248225863
Validation loss: 2.4970368229034205

Epoch: 5| Step: 3
Training loss: 0.9665774317912944
Validation loss: 2.499660806692593

Epoch: 5| Step: 4
Training loss: 1.32453496077678
Validation loss: 2.533257630172859

Epoch: 5| Step: 5
Training loss: 1.326743810190354
Validation loss: 2.4835304808180068

Epoch: 5| Step: 6
Training loss: 1.618434333216281
Validation loss: 2.482118189314391

Epoch: 5| Step: 7
Training loss: 1.7985540092106913
Validation loss: 2.5201027313238002

Epoch: 5| Step: 8
Training loss: 1.621271183460816
Validation loss: 2.5390848305527203

Epoch: 5| Step: 9
Training loss: 1.114435714976118
Validation loss: 2.549519965547064

Epoch: 5| Step: 10
Training loss: 1.1611601727649337
Validation loss: 2.596253603891569

Epoch: 5| Step: 11
Training loss: 1.1016060029225734
Validation loss: 2.6233175085548566

Epoch: 449| Step: 0
Training loss: 1.8290069278608778
Validation loss: 2.6472958417480124

Epoch: 5| Step: 1
Training loss: 1.2970602064136767
Validation loss: 2.6765240308881313

Epoch: 5| Step: 2
Training loss: 1.6887660751876536
Validation loss: 2.6704010457878415

Epoch: 5| Step: 3
Training loss: 1.129741531282927
Validation loss: 2.6334273528766707

Epoch: 5| Step: 4
Training loss: 1.6721462849638729
Validation loss: 2.628149918563952

Epoch: 5| Step: 5
Training loss: 1.6292514938293792
Validation loss: 2.531698454074895

Epoch: 5| Step: 6
Training loss: 1.184493424828485
Validation loss: 2.5033115904782766

Epoch: 5| Step: 7
Training loss: 1.2060545886576377
Validation loss: 2.5065161423390703

Epoch: 5| Step: 8
Training loss: 0.7773684013713531
Validation loss: 2.4914130060760837

Epoch: 5| Step: 9
Training loss: 1.0596604269355385
Validation loss: 2.477072164918337

Epoch: 5| Step: 10
Training loss: 1.4148511004875755
Validation loss: 2.476679064136485

Epoch: 5| Step: 11
Training loss: 0.5426095281951097
Validation loss: 2.4670856716538143

Epoch: 450| Step: 0
Training loss: 1.0027994667506768
Validation loss: 2.520385774704898

Epoch: 5| Step: 1
Training loss: 1.795254117250469
Validation loss: 2.475441565683484

Epoch: 5| Step: 2
Training loss: 1.6294452315259709
Validation loss: 2.469485278025

Epoch: 5| Step: 3
Training loss: 1.324450267256952
Validation loss: 2.5601963915843737

Epoch: 5| Step: 4
Training loss: 1.1594475016583836
Validation loss: 2.594418925850307

Epoch: 5| Step: 5
Training loss: 1.4421984142084732
Validation loss: 2.614616148136092

Epoch: 5| Step: 6
Training loss: 1.7695379867593892
Validation loss: 2.63635768349094

Epoch: 5| Step: 7
Training loss: 1.31472997598148
Validation loss: 2.629169569955987

Epoch: 5| Step: 8
Training loss: 0.874244363663536
Validation loss: 2.584647072766571

Epoch: 5| Step: 9
Training loss: 1.516932758981022
Validation loss: 2.5849469180532183

Epoch: 5| Step: 10
Training loss: 1.4455467240531863
Validation loss: 2.643694122962457

Epoch: 5| Step: 11
Training loss: 1.552992467003488
Validation loss: 2.616782484457738

Epoch: 451| Step: 0
Training loss: 0.7451471845155773
Validation loss: 2.5942063485503026

Epoch: 5| Step: 1
Training loss: 1.3392864436193024
Validation loss: 2.5959493435632788

Epoch: 5| Step: 2
Training loss: 1.546964854703633
Validation loss: 2.5531846777588223

Epoch: 5| Step: 3
Training loss: 1.4500729082127872
Validation loss: 2.5633927976455753

Epoch: 5| Step: 4
Training loss: 1.3997909560128177
Validation loss: 2.552697825249213

Epoch: 5| Step: 5
Training loss: 1.3536823384713934
Validation loss: 2.50697477456787

Epoch: 5| Step: 6
Training loss: 1.3857759091210573
Validation loss: 2.567980364355537

Epoch: 5| Step: 7
Training loss: 1.400374195635625
Validation loss: 2.559826724159906

Epoch: 5| Step: 8
Training loss: 1.8716501193222348
Validation loss: 2.5601479699477525

Epoch: 5| Step: 9
Training loss: 1.1722663226025447
Validation loss: 2.520845713992231

Epoch: 5| Step: 10
Training loss: 0.908915775400645
Validation loss: 2.5043151370850234

Epoch: 5| Step: 11
Training loss: 0.7705915862401552
Validation loss: 2.508880760068295

Epoch: 452| Step: 0
Training loss: 0.8762844399446897
Validation loss: 2.464189227902547

Epoch: 5| Step: 1
Training loss: 1.2374506429982617
Validation loss: 2.518295627783405

Epoch: 5| Step: 2
Training loss: 1.119351831448785
Validation loss: 2.4904427933584303

Epoch: 5| Step: 3
Training loss: 1.1721712373781543
Validation loss: 2.5321627529277833

Epoch: 5| Step: 4
Training loss: 1.4957933248767523
Validation loss: 2.5121323960280124

Epoch: 5| Step: 5
Training loss: 0.8844949674619496
Validation loss: 2.529137436249029

Epoch: 5| Step: 6
Training loss: 0.8720463902181494
Validation loss: 2.53675631131222

Epoch: 5| Step: 7
Training loss: 1.5145743749774248
Validation loss: 2.52250245823534

Epoch: 5| Step: 8
Training loss: 1.6588168137525416
Validation loss: 2.5154284781546807

Epoch: 5| Step: 9
Training loss: 1.3464046692614813
Validation loss: 2.5784019706761545

Epoch: 5| Step: 10
Training loss: 1.986377396624181
Validation loss: 2.5664216984129533

Epoch: 5| Step: 11
Training loss: 1.071756933621864
Validation loss: 2.547466979628578

Epoch: 453| Step: 0
Training loss: 1.3344795793562414
Validation loss: 2.562154126279311

Epoch: 5| Step: 1
Training loss: 0.936588257265819
Validation loss: 2.575530146989224

Epoch: 5| Step: 2
Training loss: 1.5055933617180999
Validation loss: 2.5598212212173084

Epoch: 5| Step: 3
Training loss: 1.3873926808548427
Validation loss: 2.5675986320063187

Epoch: 5| Step: 4
Training loss: 1.0439211607977121
Validation loss: 2.546400478444118

Epoch: 5| Step: 5
Training loss: 1.1579900999189565
Validation loss: 2.5666668864555597

Epoch: 5| Step: 6
Training loss: 1.7952978095374064
Validation loss: 2.5461293125468463

Epoch: 5| Step: 7
Training loss: 1.4198363224581245
Validation loss: 2.53018847133546

Epoch: 5| Step: 8
Training loss: 1.2586741842642117
Validation loss: 2.545329083068044

Epoch: 5| Step: 9
Training loss: 1.2972710246060184
Validation loss: 2.5303695289448274

Epoch: 5| Step: 10
Training loss: 0.945918684874054
Validation loss: 2.5635030574337647

Epoch: 5| Step: 11
Training loss: 1.041625797741565
Validation loss: 2.5906194270388085

Epoch: 454| Step: 0
Training loss: 0.9902674201101458
Validation loss: 2.5202562575382257

Epoch: 5| Step: 1
Training loss: 1.4104543777600727
Validation loss: 2.574937811659177

Epoch: 5| Step: 2
Training loss: 1.6782323877509164
Validation loss: 2.5030353874583424

Epoch: 5| Step: 3
Training loss: 1.2093287949520726
Validation loss: 2.536737130343954

Epoch: 5| Step: 4
Training loss: 1.5634994362200925
Validation loss: 2.5538997621668758

Epoch: 5| Step: 5
Training loss: 1.4666536670166508
Validation loss: 2.549212064119535

Epoch: 5| Step: 6
Training loss: 1.5454968565233511
Validation loss: 2.5184307878973384

Epoch: 5| Step: 7
Training loss: 0.9401824087339701
Validation loss: 2.4951048570142875

Epoch: 5| Step: 8
Training loss: 1.0164342150700474
Validation loss: 2.51459562474565

Epoch: 5| Step: 9
Training loss: 1.222424274899832
Validation loss: 2.4840294099754447

Epoch: 5| Step: 10
Training loss: 1.1075510962175636
Validation loss: 2.472677426601564

Epoch: 5| Step: 11
Training loss: 1.4435066282241065
Validation loss: 2.5019180728185137

Epoch: 455| Step: 0
Training loss: 0.9816850511764805
Validation loss: 2.5349463565500243

Epoch: 5| Step: 1
Training loss: 1.271364080360993
Validation loss: 2.6210216809828686

Epoch: 5| Step: 2
Training loss: 1.3871042494812107
Validation loss: 2.685295043235105

Epoch: 5| Step: 3
Training loss: 1.5107443969158052
Validation loss: 2.6892892588603696

Epoch: 5| Step: 4
Training loss: 1.4496370519012243
Validation loss: 2.6858676085404207

Epoch: 5| Step: 5
Training loss: 1.8020889928945705
Validation loss: 2.6898729841091584

Epoch: 5| Step: 6
Training loss: 1.3965992273438081
Validation loss: 2.6858728717265223

Epoch: 5| Step: 7
Training loss: 1.0055373778260366
Validation loss: 2.6199395091897264

Epoch: 5| Step: 8
Training loss: 0.8942379533117847
Validation loss: 2.5204107715913815

Epoch: 5| Step: 9
Training loss: 0.9229861529666169
Validation loss: 2.4939484867021275

Epoch: 5| Step: 10
Training loss: 1.5613588362081516
Validation loss: 2.4915060588549416

Epoch: 5| Step: 11
Training loss: 2.187789788805968
Validation loss: 2.4746371706490695

Epoch: 456| Step: 0
Training loss: 1.377963816587106
Validation loss: 2.4779381205714777

Epoch: 5| Step: 1
Training loss: 1.1735698396748104
Validation loss: 2.497305246221129

Epoch: 5| Step: 2
Training loss: 1.2773262046052258
Validation loss: 2.4917563700290426

Epoch: 5| Step: 3
Training loss: 1.4553236376610816
Validation loss: 2.5153173491521708

Epoch: 5| Step: 4
Training loss: 1.47015719267468
Validation loss: 2.562658322490856

Epoch: 5| Step: 5
Training loss: 1.1629862578474768
Validation loss: 2.5525011901279804

Epoch: 5| Step: 6
Training loss: 1.6558312660489796
Validation loss: 2.5562424705475313

Epoch: 5| Step: 7
Training loss: 1.4765784853115367
Validation loss: 2.5577220062609607

Epoch: 5| Step: 8
Training loss: 1.1439480386017329
Validation loss: 2.6044939801830127

Epoch: 5| Step: 9
Training loss: 1.343146476946666
Validation loss: 2.5564603049827865

Epoch: 5| Step: 10
Training loss: 1.3695327262631092
Validation loss: 2.556552742656296

Epoch: 5| Step: 11
Training loss: 2.0414039935899915
Validation loss: 2.5625371813984175

Epoch: 457| Step: 0
Training loss: 1.1193724919668586
Validation loss: 2.5111720714816856

Epoch: 5| Step: 1
Training loss: 1.2853582159732968
Validation loss: 2.5516981002803334

Epoch: 5| Step: 2
Training loss: 1.6731429951283951
Validation loss: 2.49658969097329

Epoch: 5| Step: 3
Training loss: 1.7111720094261436
Validation loss: 2.5455707845979756

Epoch: 5| Step: 4
Training loss: 1.2516635315843543
Validation loss: 2.5551522091843095

Epoch: 5| Step: 5
Training loss: 1.302074625621925
Validation loss: 2.5377447102691706

Epoch: 5| Step: 6
Training loss: 1.6120089855322288
Validation loss: 2.5515920918810804

Epoch: 5| Step: 7
Training loss: 1.2323751546525148
Validation loss: 2.5044847356752884

Epoch: 5| Step: 8
Training loss: 1.3341893140612804
Validation loss: 2.449499833051379

Epoch: 5| Step: 9
Training loss: 0.711265488306766
Validation loss: 2.469508702353106

Epoch: 5| Step: 10
Training loss: 1.5085596002697135
Validation loss: 2.4747685614822137

Epoch: 5| Step: 11
Training loss: 1.7071496848216676
Validation loss: 2.5356860045717866

Epoch: 458| Step: 0
Training loss: 1.375090032577648
Validation loss: 2.5115706823833617

Epoch: 5| Step: 1
Training loss: 1.259266457246225
Validation loss: 2.5416552368803416

Epoch: 5| Step: 2
Training loss: 1.3572166232805858
Validation loss: 2.52101741596795

Epoch: 5| Step: 3
Training loss: 1.145233147384534
Validation loss: 2.546707202399866

Epoch: 5| Step: 4
Training loss: 1.6332031950714527
Validation loss: 2.538237925909516

Epoch: 5| Step: 5
Training loss: 1.1036949889664893
Validation loss: 2.5615890131923944

Epoch: 5| Step: 6
Training loss: 1.2960262508647744
Validation loss: 2.6240546363421084

Epoch: 5| Step: 7
Training loss: 1.0828323978946313
Validation loss: 2.6251442222485424

Epoch: 5| Step: 8
Training loss: 1.5901728858763498
Validation loss: 2.6890533231364007

Epoch: 5| Step: 9
Training loss: 1.2539850608325196
Validation loss: 2.6454866712853624

Epoch: 5| Step: 10
Training loss: 1.4603582855759631
Validation loss: 2.617288805770697

Epoch: 5| Step: 11
Training loss: 1.1841681569032108
Validation loss: 2.5699673839335033

Epoch: 459| Step: 0
Training loss: 1.1110726919419696
Validation loss: 2.5913003821105405

Epoch: 5| Step: 1
Training loss: 1.0787985535941154
Validation loss: 2.5554346436654476

Epoch: 5| Step: 2
Training loss: 0.9750967087834186
Validation loss: 2.5199806817956727

Epoch: 5| Step: 3
Training loss: 1.2226394798420575
Validation loss: 2.5713738643475663

Epoch: 5| Step: 4
Training loss: 1.362885819500722
Validation loss: 2.5907876858248726

Epoch: 5| Step: 5
Training loss: 1.228746013537874
Validation loss: 2.6152578461562186

Epoch: 5| Step: 6
Training loss: 1.38206461709274
Validation loss: 2.6502732597870273

Epoch: 5| Step: 7
Training loss: 1.4227341791351504
Validation loss: 2.6629893545708416

Epoch: 5| Step: 8
Training loss: 1.6241959269774706
Validation loss: 2.5864567153767877

Epoch: 5| Step: 9
Training loss: 1.7148183069101262
Validation loss: 2.646456507387102

Epoch: 5| Step: 10
Training loss: 1.2669170048604566
Validation loss: 2.6194805272704937

Epoch: 5| Step: 11
Training loss: 1.0253241235875827
Validation loss: 2.573786277120091

Epoch: 460| Step: 0
Training loss: 1.4670895869822298
Validation loss: 2.4998026452050084

Epoch: 5| Step: 1
Training loss: 0.8312247222269364
Validation loss: 2.532514338796379

Epoch: 5| Step: 2
Training loss: 1.2664346342300516
Validation loss: 2.4689895658508183

Epoch: 5| Step: 3
Training loss: 0.9822329572741383
Validation loss: 2.495303825470034

Epoch: 5| Step: 4
Training loss: 0.9490340253259357
Validation loss: 2.500875820289241

Epoch: 5| Step: 5
Training loss: 1.3470728841687656
Validation loss: 2.5104083750945323

Epoch: 5| Step: 6
Training loss: 1.6191706637367367
Validation loss: 2.4715973071544006

Epoch: 5| Step: 7
Training loss: 1.2993264525841175
Validation loss: 2.4817844055594556

Epoch: 5| Step: 8
Training loss: 1.045825147153471
Validation loss: 2.445574647869453

Epoch: 5| Step: 9
Training loss: 1.2204237961661248
Validation loss: 2.522774553168314

Epoch: 5| Step: 10
Training loss: 1.2910727807116857
Validation loss: 2.536723839077526

Epoch: 5| Step: 11
Training loss: 1.5321993317867884
Validation loss: 2.510667231759068

Epoch: 461| Step: 0
Training loss: 1.6171348673783432
Validation loss: 2.4973501666007145

Epoch: 5| Step: 1
Training loss: 1.707962724756877
Validation loss: 2.498685566744252

Epoch: 5| Step: 2
Training loss: 1.1124192497864878
Validation loss: 2.489346051313978

Epoch: 5| Step: 3
Training loss: 0.8478683698491395
Validation loss: 2.513348072204411

Epoch: 5| Step: 4
Training loss: 1.1194012989083681
Validation loss: 2.5367800073224505

Epoch: 5| Step: 5
Training loss: 0.9580346277743992
Validation loss: 2.55222240120995

Epoch: 5| Step: 6
Training loss: 0.80969218957589
Validation loss: 2.589599350434473

Epoch: 5| Step: 7
Training loss: 1.1233106751142456
Validation loss: 2.590823985803068

Epoch: 5| Step: 8
Training loss: 1.4884262214600146
Validation loss: 2.5453753317455705

Epoch: 5| Step: 9
Training loss: 1.0204667516597397
Validation loss: 2.5388954459768143

Epoch: 5| Step: 10
Training loss: 1.318798393337855
Validation loss: 2.554550147763179

Epoch: 5| Step: 11
Training loss: 1.7358050937098322
Validation loss: 2.545195854859806

Epoch: 462| Step: 0
Training loss: 0.7773037617428349
Validation loss: 2.5419299987228072

Epoch: 5| Step: 1
Training loss: 1.3755963506146047
Validation loss: 2.4874500780830973

Epoch: 5| Step: 2
Training loss: 1.004080731261711
Validation loss: 2.5210351245810902

Epoch: 5| Step: 3
Training loss: 1.606124558356028
Validation loss: 2.547955753705534

Epoch: 5| Step: 4
Training loss: 1.1676746623311525
Validation loss: 2.528016929847176

Epoch: 5| Step: 5
Training loss: 1.24228403927879
Validation loss: 2.540657192149831

Epoch: 5| Step: 6
Training loss: 0.9974176920727428
Validation loss: 2.5351658543197613

Epoch: 5| Step: 7
Training loss: 1.4197655425137028
Validation loss: 2.5366232359518843

Epoch: 5| Step: 8
Training loss: 1.3614505838622601
Validation loss: 2.570780113453518

Epoch: 5| Step: 9
Training loss: 1.0749182071175452
Validation loss: 2.568205074805107

Epoch: 5| Step: 10
Training loss: 1.2400757215052771
Validation loss: 2.5544279279670845

Epoch: 5| Step: 11
Training loss: 1.3972378492060786
Validation loss: 2.551023279988041

Epoch: 463| Step: 0
Training loss: 0.871352768779271
Validation loss: 2.5903355249973985

Epoch: 5| Step: 1
Training loss: 1.339082863295634
Validation loss: 2.5788612971201044

Epoch: 5| Step: 2
Training loss: 1.3155658427731574
Validation loss: 2.5819977543168826

Epoch: 5| Step: 3
Training loss: 0.8433405271105221
Validation loss: 2.5668581057242497

Epoch: 5| Step: 4
Training loss: 1.0614831771164386
Validation loss: 2.592272373976779

Epoch: 5| Step: 5
Training loss: 1.4136442967571108
Validation loss: 2.562369219226167

Epoch: 5| Step: 6
Training loss: 1.5621662546396942
Validation loss: 2.515017734310856

Epoch: 5| Step: 7
Training loss: 1.4283953387861383
Validation loss: 2.562350927839452

Epoch: 5| Step: 8
Training loss: 1.2736294373571528
Validation loss: 2.5099969423321036

Epoch: 5| Step: 9
Training loss: 1.2245452231315357
Validation loss: 2.4839130487953076

Epoch: 5| Step: 10
Training loss: 1.0199447319540627
Validation loss: 2.550786540720634

Epoch: 5| Step: 11
Training loss: 0.4738432112113789
Validation loss: 2.5224109604832394

Epoch: 464| Step: 0
Training loss: 1.4401527474770424
Validation loss: 2.5596598299400246

Epoch: 5| Step: 1
Training loss: 1.2595344272162217
Validation loss: 2.56669127392636

Epoch: 5| Step: 2
Training loss: 0.8129496430617557
Validation loss: 2.5730268761098105

Epoch: 5| Step: 3
Training loss: 0.7846431289092946
Validation loss: 2.5610984714416363

Epoch: 5| Step: 4
Training loss: 1.3578825463948536
Validation loss: 2.578585697203028

Epoch: 5| Step: 5
Training loss: 1.281523605534107
Validation loss: 2.615326163533183

Epoch: 5| Step: 6
Training loss: 0.758412978597541
Validation loss: 2.5208302621323555

Epoch: 5| Step: 7
Training loss: 1.5462604419352592
Validation loss: 2.525066161154455

Epoch: 5| Step: 8
Training loss: 1.0089804217666882
Validation loss: 2.534611428392672

Epoch: 5| Step: 9
Training loss: 1.199193053327472
Validation loss: 2.521310667815711

Epoch: 5| Step: 10
Training loss: 1.2311943215885548
Validation loss: 2.55521433275288

Epoch: 5| Step: 11
Training loss: 0.8505017034120002
Validation loss: 2.5093293400811065

Epoch: 465| Step: 0
Training loss: 1.5427985375112339
Validation loss: 2.518619413753325

Epoch: 5| Step: 1
Training loss: 1.1382844504662883
Validation loss: 2.514136033674969

Epoch: 5| Step: 2
Training loss: 0.967064406245218
Validation loss: 2.531413626386073

Epoch: 5| Step: 3
Training loss: 1.1579366187570335
Validation loss: 2.507947401179646

Epoch: 5| Step: 4
Training loss: 0.936876566543949
Validation loss: 2.5200937515560966

Epoch: 5| Step: 5
Training loss: 1.2757951874681224
Validation loss: 2.5261341523743313

Epoch: 5| Step: 6
Training loss: 1.4614836136182834
Validation loss: 2.5532628519047345

Epoch: 5| Step: 7
Training loss: 1.0460283642163424
Validation loss: 2.564873542035515

Epoch: 5| Step: 8
Training loss: 1.2293113472483326
Validation loss: 2.578241445820824

Epoch: 5| Step: 9
Training loss: 0.9980324522047562
Validation loss: 2.562838202542475

Epoch: 5| Step: 10
Training loss: 1.267279026851219
Validation loss: 2.608221613885237

Epoch: 5| Step: 11
Training loss: 0.6657495050890433
Validation loss: 2.59141368663642

Epoch: 466| Step: 0
Training loss: 1.1727276052866995
Validation loss: 2.5228250191315422

Epoch: 5| Step: 1
Training loss: 0.9759811196670265
Validation loss: 2.584529566419025

Epoch: 5| Step: 2
Training loss: 0.8829975103103428
Validation loss: 2.5831425170772135

Epoch: 5| Step: 3
Training loss: 1.1652635356490941
Validation loss: 2.5910358667601407

Epoch: 5| Step: 4
Training loss: 1.3704646914448877
Validation loss: 2.575402272847707

Epoch: 5| Step: 5
Training loss: 1.4698510608347322
Validation loss: 2.560452732787135

Epoch: 5| Step: 6
Training loss: 1.4263804391629054
Validation loss: 2.5755817816259565

Epoch: 5| Step: 7
Training loss: 1.0980018804634821
Validation loss: 2.5294620258707914

Epoch: 5| Step: 8
Training loss: 1.1994784692101625
Validation loss: 2.570100128150453

Epoch: 5| Step: 9
Training loss: 1.221441329524526
Validation loss: 2.5638029771102246

Epoch: 5| Step: 10
Training loss: 0.948402681921373
Validation loss: 2.5874776373924258

Epoch: 5| Step: 11
Training loss: 1.9295733336989476
Validation loss: 2.5574648281188486

Epoch: 467| Step: 0
Training loss: 1.2738080100044997
Validation loss: 2.5741893745409548

Epoch: 5| Step: 1
Training loss: 1.1707420976507725
Validation loss: 2.5797094581758504

Epoch: 5| Step: 2
Training loss: 1.8872805562569421
Validation loss: 2.5865085082782824

Epoch: 5| Step: 3
Training loss: 1.2097409150676623
Validation loss: 2.627296317560251

Epoch: 5| Step: 4
Training loss: 0.6795733125728636
Validation loss: 2.6271779773633805

Epoch: 5| Step: 5
Training loss: 1.0162322356488456
Validation loss: 2.6195788451877804

Epoch: 5| Step: 6
Training loss: 1.4980373257925763
Validation loss: 2.579907598642831

Epoch: 5| Step: 7
Training loss: 1.2651223020273235
Validation loss: 2.5904885396077435

Epoch: 5| Step: 8
Training loss: 0.8512030376526223
Validation loss: 2.551785207709147

Epoch: 5| Step: 9
Training loss: 1.2552605086545612
Validation loss: 2.5152724001172992

Epoch: 5| Step: 10
Training loss: 0.890273911726782
Validation loss: 2.4757691244733455

Epoch: 5| Step: 11
Training loss: 2.1169746545311416
Validation loss: 2.514597467689854

Epoch: 468| Step: 0
Training loss: 1.3808865254496903
Validation loss: 2.573372489047816

Epoch: 5| Step: 1
Training loss: 1.1461657937672294
Validation loss: 2.5815013740006876

Epoch: 5| Step: 2
Training loss: 1.483233364179746
Validation loss: 2.6228507454556707

Epoch: 5| Step: 3
Training loss: 1.3287361534021611
Validation loss: 2.6261140941743437

Epoch: 5| Step: 4
Training loss: 1.464507611172565
Validation loss: 2.611650890640669

Epoch: 5| Step: 5
Training loss: 1.2729418673520703
Validation loss: 2.520333147210727

Epoch: 5| Step: 6
Training loss: 1.20779236928491
Validation loss: 2.5130737766888624

Epoch: 5| Step: 7
Training loss: 1.071858646724058
Validation loss: 2.487387949450211

Epoch: 5| Step: 8
Training loss: 1.054889122799817
Validation loss: 2.4787692057272217

Epoch: 5| Step: 9
Training loss: 1.3921960678436334
Validation loss: 2.5234936293588404

Epoch: 5| Step: 10
Training loss: 1.318050591370471
Validation loss: 2.561660303378056

Epoch: 5| Step: 11
Training loss: 1.4315140526415226
Validation loss: 2.58921331036628

Epoch: 469| Step: 0
Training loss: 0.9437100092518051
Validation loss: 2.6063578783817927

Epoch: 5| Step: 1
Training loss: 1.3870367840631475
Validation loss: 2.536249415875589

Epoch: 5| Step: 2
Training loss: 1.3601530632669716
Validation loss: 2.5924255099334936

Epoch: 5| Step: 3
Training loss: 1.231561375472033
Validation loss: 2.544470137277158

Epoch: 5| Step: 4
Training loss: 1.3843895491616964
Validation loss: 2.636999436497161

Epoch: 5| Step: 5
Training loss: 1.2291555026996765
Validation loss: 2.6147022232948713

Epoch: 5| Step: 6
Training loss: 1.2964952671275052
Validation loss: 2.562214769600656

Epoch: 5| Step: 7
Training loss: 1.2208352955790471
Validation loss: 2.500884662505212

Epoch: 5| Step: 8
Training loss: 1.0296918483983841
Validation loss: 2.4959019670352784

Epoch: 5| Step: 9
Training loss: 1.1690801735495238
Validation loss: 2.500479278717094

Epoch: 5| Step: 10
Training loss: 1.102691180376072
Validation loss: 2.4908108232292934

Epoch: 5| Step: 11
Training loss: 0.5600029569360458
Validation loss: 2.531411495472908

Epoch: 470| Step: 0
Training loss: 0.9126451376885194
Validation loss: 2.478783911856019

Epoch: 5| Step: 1
Training loss: 1.33976038014469
Validation loss: 2.5453579720029333

Epoch: 5| Step: 2
Training loss: 1.0840568449522232
Validation loss: 2.527346012088917

Epoch: 5| Step: 3
Training loss: 0.952485260686699
Validation loss: 2.53434633504553

Epoch: 5| Step: 4
Training loss: 0.7229619384866863
Validation loss: 2.608614473811816

Epoch: 5| Step: 5
Training loss: 1.2551819678527854
Validation loss: 2.587394165786342

Epoch: 5| Step: 6
Training loss: 1.2830104828433782
Validation loss: 2.6204863866478996

Epoch: 5| Step: 7
Training loss: 1.2970273491410507
Validation loss: 2.599452655289919

Epoch: 5| Step: 8
Training loss: 1.5466750815316095
Validation loss: 2.6330699587246245

Epoch: 5| Step: 9
Training loss: 1.2505368987034813
Validation loss: 2.58567888094172

Epoch: 5| Step: 10
Training loss: 1.6437832179901253
Validation loss: 2.5354007079960383

Epoch: 5| Step: 11
Training loss: 0.5789100368854665
Validation loss: 2.5114758751308135

Epoch: 471| Step: 0
Training loss: 1.4641350824853574
Validation loss: 2.5225122721990725

Epoch: 5| Step: 1
Training loss: 1.1472860779333771
Validation loss: 2.5166820532494723

Epoch: 5| Step: 2
Training loss: 1.0516243994350751
Validation loss: 2.5194401805890205

Epoch: 5| Step: 3
Training loss: 0.6692907624796569
Validation loss: 2.5434717129221167

Epoch: 5| Step: 4
Training loss: 0.8146454289046279
Validation loss: 2.5440538848142547

Epoch: 5| Step: 5
Training loss: 1.479919492748538
Validation loss: 2.498327900079219

Epoch: 5| Step: 6
Training loss: 1.2997961581413895
Validation loss: 2.550609261525659

Epoch: 5| Step: 7
Training loss: 1.0069302386162402
Validation loss: 2.5456933086573406

Epoch: 5| Step: 8
Training loss: 0.9940897810549365
Validation loss: 2.570776247280002

Epoch: 5| Step: 9
Training loss: 1.0364336301584924
Validation loss: 2.581243771013652

Epoch: 5| Step: 10
Training loss: 1.4597060781679656
Validation loss: 2.5945253324072657

Epoch: 5| Step: 11
Training loss: 1.2123942810847497
Validation loss: 2.566932446221127

Epoch: 472| Step: 0
Training loss: 0.876717754629274
Validation loss: 2.580149462606701

Epoch: 5| Step: 1
Training loss: 1.3694725776982557
Validation loss: 2.5948280101197754

Epoch: 5| Step: 2
Training loss: 1.001191561799681
Validation loss: 2.539052628718041

Epoch: 5| Step: 3
Training loss: 1.4057471329891975
Validation loss: 2.5374017106048217

Epoch: 5| Step: 4
Training loss: 0.9729030556444835
Validation loss: 2.556376735744677

Epoch: 5| Step: 5
Training loss: 1.2590327060381146
Validation loss: 2.5430399059022695

Epoch: 5| Step: 6
Training loss: 1.4913693726717765
Validation loss: 2.5414626470875716

Epoch: 5| Step: 7
Training loss: 1.366716489038792
Validation loss: 2.5632675037211157

Epoch: 5| Step: 8
Training loss: 1.0934276650796781
Validation loss: 2.5438999535634768

Epoch: 5| Step: 9
Training loss: 0.8935559548957883
Validation loss: 2.5655154148662946

Epoch: 5| Step: 10
Training loss: 0.7522314572139136
Validation loss: 2.547109721782553

Epoch: 5| Step: 11
Training loss: 0.515516067326636
Validation loss: 2.5713265224673516

Epoch: 473| Step: 0
Training loss: 0.9942664645728315
Validation loss: 2.613478717271387

Epoch: 5| Step: 1
Training loss: 1.0575368750345306
Validation loss: 2.607199201469586

Epoch: 5| Step: 2
Training loss: 1.1727664354417267
Validation loss: 2.6413823984628704

Epoch: 5| Step: 3
Training loss: 1.4269920746891294
Validation loss: 2.5980692102595095

Epoch: 5| Step: 4
Training loss: 0.7077893571249116
Validation loss: 2.600550732605308

Epoch: 5| Step: 5
Training loss: 1.1674584642328494
Validation loss: 2.6013715748420916

Epoch: 5| Step: 6
Training loss: 1.4796085324509851
Validation loss: 2.5870875234063595

Epoch: 5| Step: 7
Training loss: 1.176798586317078
Validation loss: 2.559462864151258

Epoch: 5| Step: 8
Training loss: 0.7075039458417549
Validation loss: 2.569391131850339

Epoch: 5| Step: 9
Training loss: 1.1352122703218417
Validation loss: 2.56318713295102

Epoch: 5| Step: 10
Training loss: 0.9584333775310085
Validation loss: 2.562932040071735

Epoch: 5| Step: 11
Training loss: 0.8582366339523081
Validation loss: 2.549325583134011

Epoch: 474| Step: 0
Training loss: 1.044105224922639
Validation loss: 2.53311227651733

Epoch: 5| Step: 1
Training loss: 0.8690780788590403
Validation loss: 2.5566590349521983

Epoch: 5| Step: 2
Training loss: 1.095761384282123
Validation loss: 2.58916367797589

Epoch: 5| Step: 3
Training loss: 0.9201300642602039
Validation loss: 2.637918944178335

Epoch: 5| Step: 4
Training loss: 0.8502059771103113
Validation loss: 2.5699262744320674

Epoch: 5| Step: 5
Training loss: 1.1983526625066918
Validation loss: 2.5932059081204795

Epoch: 5| Step: 6
Training loss: 1.0189969939392494
Validation loss: 2.6083321724199466

Epoch: 5| Step: 7
Training loss: 1.0373673917291664
Validation loss: 2.60032883835681

Epoch: 5| Step: 8
Training loss: 1.8163491516983303
Validation loss: 2.582739924653329

Epoch: 5| Step: 9
Training loss: 0.9440500009941124
Validation loss: 2.59063101914661

Epoch: 5| Step: 10
Training loss: 1.2549973253776348
Validation loss: 2.630235688221509

Epoch: 5| Step: 11
Training loss: 0.6611649971682786
Validation loss: 2.5684076882424685

Epoch: 475| Step: 0
Training loss: 1.2417160195051455
Validation loss: 2.6047322129635906

Epoch: 5| Step: 1
Training loss: 1.2970541864721608
Validation loss: 2.6604404643066584

Epoch: 5| Step: 2
Training loss: 1.2120966132153272
Validation loss: 2.6313567433637144

Epoch: 5| Step: 3
Training loss: 0.9545816640674166
Validation loss: 2.624687662540586

Epoch: 5| Step: 4
Training loss: 1.0791375201694355
Validation loss: 2.6043069471087525

Epoch: 5| Step: 5
Training loss: 1.0761073486036088
Validation loss: 2.5442469285657365

Epoch: 5| Step: 6
Training loss: 1.4850893409903885
Validation loss: 2.560169497686433

Epoch: 5| Step: 7
Training loss: 1.1440008711711527
Validation loss: 2.503180281067953

Epoch: 5| Step: 8
Training loss: 1.0953212895496454
Validation loss: 2.503971525502881

Epoch: 5| Step: 9
Training loss: 1.0951097483048056
Validation loss: 2.524216977363514

Epoch: 5| Step: 10
Training loss: 0.9331825659664057
Validation loss: 2.552992006321989

Epoch: 5| Step: 11
Training loss: 0.415237558806622
Validation loss: 2.5591956364929636

Epoch: 476| Step: 0
Training loss: 0.9462108914395334
Validation loss: 2.5433403013249745

Epoch: 5| Step: 1
Training loss: 1.101590798738209
Validation loss: 2.5702278138715693

Epoch: 5| Step: 2
Training loss: 0.9175998027477036
Validation loss: 2.5680884814302134

Epoch: 5| Step: 3
Training loss: 1.1485698390148527
Validation loss: 2.5773607489164148

Epoch: 5| Step: 4
Training loss: 1.3681780033640214
Validation loss: 2.549757233451684

Epoch: 5| Step: 5
Training loss: 1.059385053198721
Validation loss: 2.5620474144322407

Epoch: 5| Step: 6
Training loss: 0.996854663509901
Validation loss: 2.56861781764822

Epoch: 5| Step: 7
Training loss: 1.3617145531699661
Validation loss: 2.521224950421047

Epoch: 5| Step: 8
Training loss: 1.136739566782785
Validation loss: 2.5354830232983563

Epoch: 5| Step: 9
Training loss: 1.077939777772861
Validation loss: 2.5763626355778366

Epoch: 5| Step: 10
Training loss: 0.9122141220426487
Validation loss: 2.5551041623971833

Epoch: 5| Step: 11
Training loss: 0.7144147909568382
Validation loss: 2.5664349558718507

Epoch: 477| Step: 0
Training loss: 1.316028167130401
Validation loss: 2.6274283091609707

Epoch: 5| Step: 1
Training loss: 1.1684380038378421
Validation loss: 2.5489115461434264

Epoch: 5| Step: 2
Training loss: 0.918123792176202
Validation loss: 2.571533572051675

Epoch: 5| Step: 3
Training loss: 1.2662016885170457
Validation loss: 2.537393649461144

Epoch: 5| Step: 4
Training loss: 1.0257292270179366
Validation loss: 2.571728116519085

Epoch: 5| Step: 5
Training loss: 1.0463885415435594
Validation loss: 2.5924397993256063

Epoch: 5| Step: 6
Training loss: 0.9261505742320523
Validation loss: 2.6097826344252115

Epoch: 5| Step: 7
Training loss: 1.2374712584269338
Validation loss: 2.570754267364455

Epoch: 5| Step: 8
Training loss: 1.1345867600367634
Validation loss: 2.577772189573647

Epoch: 5| Step: 9
Training loss: 1.0322235598200178
Validation loss: 2.5960350675912034

Epoch: 5| Step: 10
Training loss: 0.926519140094206
Validation loss: 2.579874658755817

Epoch: 5| Step: 11
Training loss: 0.6112479257840963
Validation loss: 2.5380146622786612

Epoch: 478| Step: 0
Training loss: 1.1633302574517832
Validation loss: 2.578502168905862

Epoch: 5| Step: 1
Training loss: 1.1424446745317012
Validation loss: 2.582266242356199

Epoch: 5| Step: 2
Training loss: 1.0949747040844546
Validation loss: 2.6258109860834784

Epoch: 5| Step: 3
Training loss: 0.968849115531137
Validation loss: 2.6282897649607846

Epoch: 5| Step: 4
Training loss: 0.9258423797126544
Validation loss: 2.630067248699408

Epoch: 5| Step: 5
Training loss: 1.0986819650462973
Validation loss: 2.6549842025025834

Epoch: 5| Step: 6
Training loss: 1.0169775539610597
Validation loss: 2.6350603629237086

Epoch: 5| Step: 7
Training loss: 1.1078372021760545
Validation loss: 2.613006440497431

Epoch: 5| Step: 8
Training loss: 0.9263021556878172
Validation loss: 2.570227245706385

Epoch: 5| Step: 9
Training loss: 1.5203001141411177
Validation loss: 2.6281669355562824

Epoch: 5| Step: 10
Training loss: 1.3389753190886227
Validation loss: 2.6005255319339096

Epoch: 5| Step: 11
Training loss: 0.8096259711152107
Validation loss: 2.541219599026435

Epoch: 479| Step: 0
Training loss: 1.221482270876076
Validation loss: 2.613195546203168

Epoch: 5| Step: 1
Training loss: 1.0822191867050361
Validation loss: 2.616553876100181

Epoch: 5| Step: 2
Training loss: 1.029529002469855
Validation loss: 2.666219995511355

Epoch: 5| Step: 3
Training loss: 0.8541049973780583
Validation loss: 2.652066009766565

Epoch: 5| Step: 4
Training loss: 0.9001852864695962
Validation loss: 2.6712579181894736

Epoch: 5| Step: 5
Training loss: 0.8674691919798182
Validation loss: 2.7039114115012803

Epoch: 5| Step: 6
Training loss: 0.7117588622328994
Validation loss: 2.6949383572728105

Epoch: 5| Step: 7
Training loss: 1.2246752756204162
Validation loss: 2.6758827654290975

Epoch: 5| Step: 8
Training loss: 1.504754003399988
Validation loss: 2.666551558920925

Epoch: 5| Step: 9
Training loss: 1.2541407665903004
Validation loss: 2.6029159511569047

Epoch: 5| Step: 10
Training loss: 1.4863549128560902
Validation loss: 2.6140978135670587

Epoch: 5| Step: 11
Training loss: 1.1023211741146448
Validation loss: 2.5675822698405986

Epoch: 480| Step: 0
Training loss: 0.8587097714370274
Validation loss: 2.5451191718092523

Epoch: 5| Step: 1
Training loss: 0.9802475942004762
Validation loss: 2.5284391463431564

Epoch: 5| Step: 2
Training loss: 1.3293945079353144
Validation loss: 2.5264487983882495

Epoch: 5| Step: 3
Training loss: 1.113240826860007
Validation loss: 2.5691614714017397

Epoch: 5| Step: 4
Training loss: 1.225323774407024
Validation loss: 2.593867431418176

Epoch: 5| Step: 5
Training loss: 1.11277513209364
Validation loss: 2.5658570799906215

Epoch: 5| Step: 6
Training loss: 1.5978015936142236
Validation loss: 2.591191446998684

Epoch: 5| Step: 7
Training loss: 1.2752202199103448
Validation loss: 2.604173459362072

Epoch: 5| Step: 8
Training loss: 0.9258252225967522
Validation loss: 2.6056237772774553

Epoch: 5| Step: 9
Training loss: 1.2341250395897028
Validation loss: 2.6355692300375644

Epoch: 5| Step: 10
Training loss: 1.1113021659836144
Validation loss: 2.592121654898265

Epoch: 5| Step: 11
Training loss: 1.023724523001401
Validation loss: 2.639333642461983

Epoch: 481| Step: 0
Training loss: 1.3701499886097257
Validation loss: 2.6633923229250303

Epoch: 5| Step: 1
Training loss: 1.0745502861969365
Validation loss: 2.6096081581946944

Epoch: 5| Step: 2
Training loss: 1.1418325224827912
Validation loss: 2.7039396642343227

Epoch: 5| Step: 3
Training loss: 1.495450910103715
Validation loss: 2.664143090320285

Epoch: 5| Step: 4
Training loss: 1.4291220625579684
Validation loss: 2.65557656446652

Epoch: 5| Step: 5
Training loss: 0.8458764160784783
Validation loss: 2.6202929354054607

Epoch: 5| Step: 6
Training loss: 0.939948318257865
Validation loss: 2.6022697380945257

Epoch: 5| Step: 7
Training loss: 0.9180274457630972
Validation loss: 2.6189435542887787

Epoch: 5| Step: 8
Training loss: 0.9206743665564722
Validation loss: 2.62061241721861

Epoch: 5| Step: 9
Training loss: 1.0899146272315645
Validation loss: 2.5749499720432616

Epoch: 5| Step: 10
Training loss: 1.0493575310403265
Validation loss: 2.5760396673305563

Epoch: 5| Step: 11
Training loss: 1.0280641995803872
Validation loss: 2.597344688145027

Epoch: 482| Step: 0
Training loss: 0.8689607241175512
Validation loss: 2.5366301794932724

Epoch: 5| Step: 1
Training loss: 1.0321315696408357
Validation loss: 2.5781197133636216

Epoch: 5| Step: 2
Training loss: 1.420365255150354
Validation loss: 2.6102323437091663

Epoch: 5| Step: 3
Training loss: 1.2618959379230394
Validation loss: 2.608309693935226

Epoch: 5| Step: 4
Training loss: 1.1037166986161522
Validation loss: 2.6341961055905916

Epoch: 5| Step: 5
Training loss: 0.940071711239762
Validation loss: 2.669269142460481

Epoch: 5| Step: 6
Training loss: 0.6787399176029657
Validation loss: 2.613419856495006

Epoch: 5| Step: 7
Training loss: 0.8362898752373482
Validation loss: 2.6637287396937497

Epoch: 5| Step: 8
Training loss: 1.2661657708671052
Validation loss: 2.6251707172890115

Epoch: 5| Step: 9
Training loss: 1.186874074106925
Validation loss: 2.6135661450290457

Epoch: 5| Step: 10
Training loss: 0.9600496920499958
Validation loss: 2.6192750832267886

Epoch: 5| Step: 11
Training loss: 1.1326582704984662
Validation loss: 2.5801838062174522

Epoch: 483| Step: 0
Training loss: 1.0721413239798216
Validation loss: 2.5146319717806387

Epoch: 5| Step: 1
Training loss: 0.8969713604564163
Validation loss: 2.5570787365765213

Epoch: 5| Step: 2
Training loss: 1.1583506601167488
Validation loss: 2.523150779095392

Epoch: 5| Step: 3
Training loss: 1.0522344814288191
Validation loss: 2.553230601274233

Epoch: 5| Step: 4
Training loss: 0.842654541398687
Validation loss: 2.5684262729920313

Epoch: 5| Step: 5
Training loss: 0.8338235168415475
Validation loss: 2.5492249941089353

Epoch: 5| Step: 6
Training loss: 1.1960129524314225
Validation loss: 2.585292005697098

Epoch: 5| Step: 7
Training loss: 1.282818833961601
Validation loss: 2.625639118621842

Epoch: 5| Step: 8
Training loss: 1.146117949539085
Validation loss: 2.583020365635848

Epoch: 5| Step: 9
Training loss: 1.198461933707542
Validation loss: 2.646890295225446

Epoch: 5| Step: 10
Training loss: 0.8044928157810426
Validation loss: 2.6659619839480433

Epoch: 5| Step: 11
Training loss: 2.3005651816187926
Validation loss: 2.6196173779938166

Epoch: 484| Step: 0
Training loss: 1.3762654636772007
Validation loss: 2.6412891252529174

Epoch: 5| Step: 1
Training loss: 1.057011903979091
Validation loss: 2.6832713785384033

Epoch: 5| Step: 2
Training loss: 1.0866214053161345
Validation loss: 2.6661625450183335

Epoch: 5| Step: 3
Training loss: 1.2052515235927648
Validation loss: 2.701712590305195

Epoch: 5| Step: 4
Training loss: 0.9208008278565452
Validation loss: 2.681767452581372

Epoch: 5| Step: 5
Training loss: 0.9440829895887193
Validation loss: 2.6909032055334396

Epoch: 5| Step: 6
Training loss: 1.3456893056483825
Validation loss: 2.6508133096027615

Epoch: 5| Step: 7
Training loss: 1.286486369250927
Validation loss: 2.653471402221365

Epoch: 5| Step: 8
Training loss: 0.8035966831356236
Validation loss: 2.666394820860838

Epoch: 5| Step: 9
Training loss: 1.0251737819452205
Validation loss: 2.585420531875299

Epoch: 5| Step: 10
Training loss: 0.9579018817162721
Validation loss: 2.5562459525936703

Epoch: 5| Step: 11
Training loss: 0.957058746565695
Validation loss: 2.56497974513548

Epoch: 485| Step: 0
Training loss: 1.077167804782539
Validation loss: 2.605417467458108

Epoch: 5| Step: 1
Training loss: 0.9702258404596666
Validation loss: 2.609153842881313

Epoch: 5| Step: 2
Training loss: 1.1068879847139188
Validation loss: 2.5852361037109537

Epoch: 5| Step: 3
Training loss: 0.9160268168792567
Validation loss: 2.5870174580743015

Epoch: 5| Step: 4
Training loss: 1.1191924983546901
Validation loss: 2.6244239477813784

Epoch: 5| Step: 5
Training loss: 0.9878508644655135
Validation loss: 2.6622019933801666

Epoch: 5| Step: 6
Training loss: 1.1816161097986388
Validation loss: 2.6219490425770147

Epoch: 5| Step: 7
Training loss: 0.9321204015744484
Validation loss: 2.636967610989308

Epoch: 5| Step: 8
Training loss: 0.9486156792730054
Validation loss: 2.651930483278768

Epoch: 5| Step: 9
Training loss: 1.0984654277870542
Validation loss: 2.556236182644162

Epoch: 5| Step: 10
Training loss: 1.1360935445068407
Validation loss: 2.5807384268821973

Epoch: 5| Step: 11
Training loss: 0.6222694593216843
Validation loss: 2.5729677964868944

Epoch: 486| Step: 0
Training loss: 1.1536323196388896
Validation loss: 2.584443662562361

Epoch: 5| Step: 1
Training loss: 1.126420607605635
Validation loss: 2.620176227675483

Epoch: 5| Step: 2
Training loss: 1.1683219452183686
Validation loss: 2.6107415677269628

Epoch: 5| Step: 3
Training loss: 0.860800168253127
Validation loss: 2.5991524539125552

Epoch: 5| Step: 4
Training loss: 1.0221113975602278
Validation loss: 2.6288663304676776

Epoch: 5| Step: 5
Training loss: 0.8520574968395808
Validation loss: 2.602887975839846

Epoch: 5| Step: 6
Training loss: 0.8556730122327836
Validation loss: 2.654971013039628

Epoch: 5| Step: 7
Training loss: 1.1044820419101886
Validation loss: 2.6154616933482413

Epoch: 5| Step: 8
Training loss: 0.9691499991772707
Validation loss: 2.610857095323104

Epoch: 5| Step: 9
Training loss: 1.025049468916894
Validation loss: 2.572853888133157

Epoch: 5| Step: 10
Training loss: 0.8373301661222942
Validation loss: 2.579688386167963

Epoch: 5| Step: 11
Training loss: 0.985245456029775
Validation loss: 2.5582434572178245

Epoch: 487| Step: 0
Training loss: 1.5014230018306052
Validation loss: 2.6107035013259026

Epoch: 5| Step: 1
Training loss: 1.0117367775978914
Validation loss: 2.5908248964593383

Epoch: 5| Step: 2
Training loss: 0.8125819751760883
Validation loss: 2.5778985473130036

Epoch: 5| Step: 3
Training loss: 1.1768857514411457
Validation loss: 2.563513346090261

Epoch: 5| Step: 4
Training loss: 0.9533845204225211
Validation loss: 2.647137967302501

Epoch: 5| Step: 5
Training loss: 1.039321522945552
Validation loss: 2.6112867802400044

Epoch: 5| Step: 6
Training loss: 0.8701057476143662
Validation loss: 2.6352505926846814

Epoch: 5| Step: 7
Training loss: 0.9137645790199913
Validation loss: 2.65465702834967

Epoch: 5| Step: 8
Training loss: 0.5634436110145552
Validation loss: 2.646269082183943

Epoch: 5| Step: 9
Training loss: 1.0536713968376161
Validation loss: 2.676684295412952

Epoch: 5| Step: 10
Training loss: 0.7190049589991495
Validation loss: 2.644830302727137

Epoch: 5| Step: 11
Training loss: 1.3409275309348354
Validation loss: 2.60966537481738

Epoch: 488| Step: 0
Training loss: 1.0705646301458571
Validation loss: 2.6248515707770292

Epoch: 5| Step: 1
Training loss: 0.8933581860546479
Validation loss: 2.6051478686377387

Epoch: 5| Step: 2
Training loss: 0.9416530491398497
Validation loss: 2.5790978763529426

Epoch: 5| Step: 3
Training loss: 1.183277452967259
Validation loss: 2.5965820424214527

Epoch: 5| Step: 4
Training loss: 0.8014994308317357
Validation loss: 2.597954142610437

Epoch: 5| Step: 5
Training loss: 1.0577215000605635
Validation loss: 2.5885583325674015

Epoch: 5| Step: 6
Training loss: 0.7957442245393657
Validation loss: 2.588878735651204

Epoch: 5| Step: 7
Training loss: 0.7392816375964896
Validation loss: 2.509687639699647

Epoch: 5| Step: 8
Training loss: 1.238043199635915
Validation loss: 2.5598924364524698

Epoch: 5| Step: 9
Training loss: 1.1091698470286213
Validation loss: 2.5698045327202497

Epoch: 5| Step: 10
Training loss: 1.0644286546606738
Validation loss: 2.603683845902353

Epoch: 5| Step: 11
Training loss: 0.6507446196323043
Validation loss: 2.576736727611671

Epoch: 489| Step: 0
Training loss: 1.01497382783267
Validation loss: 2.638968698789359

Epoch: 5| Step: 1
Training loss: 0.6747432741520382
Validation loss: 2.632492744053003

Epoch: 5| Step: 2
Training loss: 0.9663857558844349
Validation loss: 2.6684119069203796

Epoch: 5| Step: 3
Training loss: 0.9198170012933973
Validation loss: 2.6459106837002127

Epoch: 5| Step: 4
Training loss: 0.9168677037318663
Validation loss: 2.6400065026901576

Epoch: 5| Step: 5
Training loss: 1.0568281701810125
Validation loss: 2.6475329509506054

Epoch: 5| Step: 6
Training loss: 1.3284366017735436
Validation loss: 2.5552039134851343

Epoch: 5| Step: 7
Training loss: 1.0691131220309054
Validation loss: 2.6114976932971437

Epoch: 5| Step: 8
Training loss: 0.9181839386347261
Validation loss: 2.537501922694388

Epoch: 5| Step: 9
Training loss: 1.0255802814746853
Validation loss: 2.599244628814111

Epoch: 5| Step: 10
Training loss: 1.0224857709869255
Validation loss: 2.576260302734504

Epoch: 5| Step: 11
Training loss: 0.5561097407580825
Validation loss: 2.582953161035242

Epoch: 490| Step: 0
Training loss: 0.8442668038487198
Validation loss: 2.5704555027225613

Epoch: 5| Step: 1
Training loss: 1.0488588694465346
Validation loss: 2.632766281763657

Epoch: 5| Step: 2
Training loss: 0.9631912659679196
Validation loss: 2.6921035092256145

Epoch: 5| Step: 3
Training loss: 1.0118152469289277
Validation loss: 2.6575718862919353

Epoch: 5| Step: 4
Training loss: 0.9027311145916721
Validation loss: 2.639945098807013

Epoch: 5| Step: 5
Training loss: 1.0205788911587965
Validation loss: 2.6424337076487006

Epoch: 5| Step: 6
Training loss: 0.8967919580381462
Validation loss: 2.603368664862799

Epoch: 5| Step: 7
Training loss: 1.0861839728267135
Validation loss: 2.596330194289262

Epoch: 5| Step: 8
Training loss: 1.2888572760702497
Validation loss: 2.5825763882937767

Epoch: 5| Step: 9
Training loss: 0.8564094353254518
Validation loss: 2.573361182070375

Epoch: 5| Step: 10
Training loss: 1.0236135433299824
Validation loss: 2.6056552116781857

Epoch: 5| Step: 11
Training loss: 0.8640806889473452
Validation loss: 2.7052254536855327

Epoch: 491| Step: 0
Training loss: 0.8993633309800899
Validation loss: 2.6595872596338417

Epoch: 5| Step: 1
Training loss: 0.9801491144164719
Validation loss: 2.674067443585118

Epoch: 5| Step: 2
Training loss: 0.9204422112911147
Validation loss: 2.6438774604222606

Epoch: 5| Step: 3
Training loss: 0.8004839833865424
Validation loss: 2.6163851252929717

Epoch: 5| Step: 4
Training loss: 0.9550859571888565
Validation loss: 2.5459057654541284

Epoch: 5| Step: 5
Training loss: 0.8200229678775344
Validation loss: 2.5799736985571253

Epoch: 5| Step: 6
Training loss: 1.2699513840569023
Validation loss: 2.5461836541592504

Epoch: 5| Step: 7
Training loss: 0.7624322923710237
Validation loss: 2.5610918036960775

Epoch: 5| Step: 8
Training loss: 1.3390779225052192
Validation loss: 2.633103555500999

Epoch: 5| Step: 9
Training loss: 1.1303989349298122
Validation loss: 2.6657456183265302

Epoch: 5| Step: 10
Training loss: 1.0206673091381433
Validation loss: 2.685939058277861

Epoch: 5| Step: 11
Training loss: 0.3135506135460373
Validation loss: 2.6377272798742397

Epoch: 492| Step: 0
Training loss: 0.7162047806957085
Validation loss: 2.7060893788586817

Epoch: 5| Step: 1
Training loss: 1.1651570339540431
Validation loss: 2.6687884358505243

Epoch: 5| Step: 2
Training loss: 0.5910359138994961
Validation loss: 2.6614142163546255

Epoch: 5| Step: 3
Training loss: 1.1821520494656028
Validation loss: 2.672158956775651

Epoch: 5| Step: 4
Training loss: 1.1758260116421289
Validation loss: 2.606667375877492

Epoch: 5| Step: 5
Training loss: 1.0817816821775534
Validation loss: 2.6462124749365445

Epoch: 5| Step: 6
Training loss: 0.8252851629153246
Validation loss: 2.617164885010443

Epoch: 5| Step: 7
Training loss: 1.016155984431246
Validation loss: 2.6504611533256126

Epoch: 5| Step: 8
Training loss: 1.035122277044228
Validation loss: 2.660903280549239

Epoch: 5| Step: 9
Training loss: 0.8678370268518267
Validation loss: 2.6426260136308444

Epoch: 5| Step: 10
Training loss: 1.1820399594789737
Validation loss: 2.6419327373766883

Epoch: 5| Step: 11
Training loss: 0.6025696287640542
Validation loss: 2.6098339225466627

Epoch: 493| Step: 0
Training loss: 0.9559213235514592
Validation loss: 2.566814299203888

Epoch: 5| Step: 1
Training loss: 1.0956214153537984
Validation loss: 2.555146999429085

Epoch: 5| Step: 2
Training loss: 1.2332144484484933
Validation loss: 2.5827336935677487

Epoch: 5| Step: 3
Training loss: 0.8936139196556552
Validation loss: 2.597481448762335

Epoch: 5| Step: 4
Training loss: 0.8410962368699665
Validation loss: 2.5613743007465906

Epoch: 5| Step: 5
Training loss: 0.821167600089084
Validation loss: 2.613880729245909

Epoch: 5| Step: 6
Training loss: 0.9330245321754924
Validation loss: 2.6017528575029782

Epoch: 5| Step: 7
Training loss: 1.1071365769379569
Validation loss: 2.595753183449071

Epoch: 5| Step: 8
Training loss: 0.8356837662980108
Validation loss: 2.58043421969446

Epoch: 5| Step: 9
Training loss: 1.0761647302075383
Validation loss: 2.624796371282152

Epoch: 5| Step: 10
Training loss: 0.8717678181933453
Validation loss: 2.615556449705875

Epoch: 5| Step: 11
Training loss: 1.416394244909566
Validation loss: 2.6280302616541817

Epoch: 494| Step: 0
Training loss: 0.9879629353779438
Validation loss: 2.603666995113171

Epoch: 5| Step: 1
Training loss: 1.1683211289410973
Validation loss: 2.5471595300985768

Epoch: 5| Step: 2
Training loss: 1.1126558387561665
Validation loss: 2.566556348432161

Epoch: 5| Step: 3
Training loss: 0.9162782727676441
Validation loss: 2.5405518296431766

Epoch: 5| Step: 4
Training loss: 1.2367801653420154
Validation loss: 2.5592718880686776

Epoch: 5| Step: 5
Training loss: 1.1368420196497384
Validation loss: 2.5809220525191

Epoch: 5| Step: 6
Training loss: 1.3054640052476332
Validation loss: 2.7139468570860052

Epoch: 5| Step: 7
Training loss: 1.0980175143305928
Validation loss: 2.6829277704025607

Epoch: 5| Step: 8
Training loss: 0.9480258368761878
Validation loss: 2.7063038662049266

Epoch: 5| Step: 9
Training loss: 1.0904314650941818
Validation loss: 2.6698565192549872

Epoch: 5| Step: 10
Training loss: 0.9302519679470309
Validation loss: 2.656169418907842

Epoch: 5| Step: 11
Training loss: 0.572417307466215
Validation loss: 2.6065921982650906

Epoch: 495| Step: 0
Training loss: 0.8806408190203237
Validation loss: 2.5751456452509265

Epoch: 5| Step: 1
Training loss: 1.0769343228198363
Validation loss: 2.661389483751375

Epoch: 5| Step: 2
Training loss: 1.1719642605165745
Validation loss: 2.728230673806906

Epoch: 5| Step: 3
Training loss: 1.1698481006319779
Validation loss: 2.6650714399365953

Epoch: 5| Step: 4
Training loss: 1.3503028865402253
Validation loss: 2.7119616828375874

Epoch: 5| Step: 5
Training loss: 0.7303840873736596
Validation loss: 2.7450375612684996

Epoch: 5| Step: 6
Training loss: 1.06810912386645
Validation loss: 2.787598265639302

Epoch: 5| Step: 7
Training loss: 1.198201297724541
Validation loss: 2.7623840027185196

Epoch: 5| Step: 8
Training loss: 1.4189341387797751
Validation loss: 2.7203558092871165

Epoch: 5| Step: 9
Training loss: 1.0752615566098258
Validation loss: 2.726863984688937

Epoch: 5| Step: 10
Training loss: 0.8058876790758845
Validation loss: 2.665635089475045

Epoch: 5| Step: 11
Training loss: 1.1235494268738697
Validation loss: 2.593765641743632

Epoch: 496| Step: 0
Training loss: 1.2179956791649207
Validation loss: 2.581359075561583

Epoch: 5| Step: 1
Training loss: 1.197314860341258
Validation loss: 2.5287692625575833

Epoch: 5| Step: 2
Training loss: 0.7293819155197683
Validation loss: 2.5060490342932344

Epoch: 5| Step: 3
Training loss: 0.7909771191679189
Validation loss: 2.5441618004156865

Epoch: 5| Step: 4
Training loss: 0.7728686697384618
Validation loss: 2.5465645825208267

Epoch: 5| Step: 5
Training loss: 0.8116956911308928
Validation loss: 2.5924605550159354

Epoch: 5| Step: 6
Training loss: 0.984753551053542
Validation loss: 2.663751783550876

Epoch: 5| Step: 7
Training loss: 1.3303586689180453
Validation loss: 2.69525493615642

Epoch: 5| Step: 8
Training loss: 1.2247885735677062
Validation loss: 2.758748577349742

Epoch: 5| Step: 9
Training loss: 1.2916179873409857
Validation loss: 2.6710092896977495

Epoch: 5| Step: 10
Training loss: 1.059150690057783
Validation loss: 2.7196026009617937

Epoch: 5| Step: 11
Training loss: 0.8774574036326018
Validation loss: 2.6705377329358235

Epoch: 497| Step: 0
Training loss: 1.009538399901737
Validation loss: 2.6456859965614545

Epoch: 5| Step: 1
Training loss: 0.8274471819867499
Validation loss: 2.6098002165361502

Epoch: 5| Step: 2
Training loss: 1.123787332324153
Validation loss: 2.6327663044032072

Epoch: 5| Step: 3
Training loss: 1.2034223114854086
Validation loss: 2.6471943258450374

Epoch: 5| Step: 4
Training loss: 1.1924422465640363
Validation loss: 2.632878198002051

Epoch: 5| Step: 5
Training loss: 0.9864071653818964
Validation loss: 2.5838641972274385

Epoch: 5| Step: 6
Training loss: 0.936250680737318
Validation loss: 2.626455637588342

Epoch: 5| Step: 7
Training loss: 0.8222701917507909
Validation loss: 2.5852843167480164

Epoch: 5| Step: 8
Training loss: 0.9395219932263816
Validation loss: 2.621653213335098

Epoch: 5| Step: 9
Training loss: 1.0157906030477504
Validation loss: 2.5943007210066305

Epoch: 5| Step: 10
Training loss: 0.7574433282860394
Validation loss: 2.627937720418915

Epoch: 5| Step: 11
Training loss: 1.4378722165065945
Validation loss: 2.612686925950979

Epoch: 498| Step: 0
Training loss: 0.6552975873291783
Validation loss: 2.6253642972324105

Epoch: 5| Step: 1
Training loss: 0.8774907900117704
Validation loss: 2.682740517748314

Epoch: 5| Step: 2
Training loss: 1.0630711535004538
Validation loss: 2.6923239923711226

Epoch: 5| Step: 3
Training loss: 0.9218729310093308
Validation loss: 2.6440169915789724

Epoch: 5| Step: 4
Training loss: 0.7330379489036898
Validation loss: 2.6513346108624223

Epoch: 5| Step: 5
Training loss: 0.9175829137398654
Validation loss: 2.6677443604058015

Epoch: 5| Step: 6
Training loss: 1.2897613018447984
Validation loss: 2.6432675150577776

Epoch: 5| Step: 7
Training loss: 0.9132867112987642
Validation loss: 2.62794799873912

Epoch: 5| Step: 8
Training loss: 0.7497561376205321
Validation loss: 2.635757945634213

Epoch: 5| Step: 9
Training loss: 1.0852444310127791
Validation loss: 2.5647071253547535

Epoch: 5| Step: 10
Training loss: 0.8275552265028238
Validation loss: 2.562414675741948

Epoch: 5| Step: 11
Training loss: 1.3056427433895474
Validation loss: 2.5864368429122058

Epoch: 499| Step: 0
Training loss: 0.9899520622072021
Validation loss: 2.6294680104309096

Epoch: 5| Step: 1
Training loss: 0.5806271815592636
Validation loss: 2.5852738073278503

Epoch: 5| Step: 2
Training loss: 1.3301991591091133
Validation loss: 2.5635415650860764

Epoch: 5| Step: 3
Training loss: 0.9596386637259647
Validation loss: 2.625192794077718

Epoch: 5| Step: 4
Training loss: 1.243330759287838
Validation loss: 2.535928049342169

Epoch: 5| Step: 5
Training loss: 0.7069638046215109
Validation loss: 2.6267943418180275

Epoch: 5| Step: 6
Training loss: 0.6190366928521447
Validation loss: 2.6047506796518682

Epoch: 5| Step: 7
Training loss: 0.8904275173287157
Validation loss: 2.610383845704191

Epoch: 5| Step: 8
Training loss: 1.0223694681171156
Validation loss: 2.5830470293093053

Epoch: 5| Step: 9
Training loss: 0.9402344561435362
Validation loss: 2.616948127238073

Epoch: 5| Step: 10
Training loss: 0.8751976947883953
Validation loss: 2.5821807364062415

Epoch: 5| Step: 11
Training loss: 0.9651921681802119
Validation loss: 2.6080403407641906

Epoch: 500| Step: 0
Training loss: 0.7904376897461018
Validation loss: 2.623411017445744

Epoch: 5| Step: 1
Training loss: 0.8766506157579339
Validation loss: 2.5870766373216583

Epoch: 5| Step: 2
Training loss: 0.8019059633266608
Validation loss: 2.606304395002819

Epoch: 5| Step: 3
Training loss: 1.0126162050225724
Validation loss: 2.5897792196313523

Epoch: 5| Step: 4
Training loss: 0.599764477677892
Validation loss: 2.6283748745301345

Epoch: 5| Step: 5
Training loss: 1.047873291472924
Validation loss: 2.637619520254451

Epoch: 5| Step: 6
Training loss: 0.9898150457180975
Validation loss: 2.6265676449572695

Epoch: 5| Step: 7
Training loss: 0.920389918906745
Validation loss: 2.6529996039536092

Epoch: 5| Step: 8
Training loss: 1.0303515363986022
Validation loss: 2.7424510311135224

Epoch: 5| Step: 9
Training loss: 0.9671583328409529
Validation loss: 2.726836107912065

Epoch: 5| Step: 10
Training loss: 0.8777589557704736
Validation loss: 2.7535849814452233

Epoch: 5| Step: 11
Training loss: 1.2276447162666573
Validation loss: 2.7327138941492732

Testing loss: 2.3414874082399058
