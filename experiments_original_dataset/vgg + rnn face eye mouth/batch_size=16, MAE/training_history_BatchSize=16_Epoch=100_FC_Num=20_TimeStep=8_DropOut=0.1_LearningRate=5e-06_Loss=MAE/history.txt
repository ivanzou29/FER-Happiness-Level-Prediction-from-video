Epoch: 1| Step: 0
Training loss: 5.112118721008301
Validation loss: 5.336144367853801

Epoch: 6| Step: 1
Training loss: 5.710727691650391
Validation loss: 5.334635019302368

Epoch: 6| Step: 2
Training loss: 5.765478134155273
Validation loss: 5.3332293430964155

Epoch: 6| Step: 3
Training loss: 5.095303058624268
Validation loss: 5.331788937250773

Epoch: 6| Step: 4
Training loss: 5.587193965911865
Validation loss: 5.330418984095256

Epoch: 6| Step: 5
Training loss: 6.324060440063477
Validation loss: 5.3290330568949384

Epoch: 6| Step: 6
Training loss: 5.066349029541016
Validation loss: 5.327676057815552

Epoch: 6| Step: 7
Training loss: 4.540450096130371
Validation loss: 5.326287666956584

Epoch: 6| Step: 8
Training loss: 5.399382591247559
Validation loss: 5.324807961781819

Epoch: 6| Step: 9
Training loss: 5.393857479095459
Validation loss: 5.323397239049275

Epoch: 6| Step: 10
Training loss: 5.809323787689209
Validation loss: 5.3218503793080645

Epoch: 6| Step: 11
Training loss: 4.035857677459717
Validation loss: 5.320314009984334

Epoch: 6| Step: 12
Training loss: 5.587801933288574
Validation loss: 5.318719228108724

Epoch: 6| Step: 13
Training loss: 6.1112565994262695
Validation loss: 5.31706182161967

Epoch: 2| Step: 0
Training loss: 5.690506935119629
Validation loss: 5.315288702646892

Epoch: 6| Step: 1
Training loss: 5.5411481857299805
Validation loss: 5.313501358032227

Epoch: 6| Step: 2
Training loss: 5.113032341003418
Validation loss: 5.311748504638672

Epoch: 6| Step: 3
Training loss: 4.607565402984619
Validation loss: 5.30976676940918

Epoch: 6| Step: 4
Training loss: 4.080979347229004
Validation loss: 5.307868878046672

Epoch: 6| Step: 5
Training loss: 4.4047346115112305
Validation loss: 5.305755217870076

Epoch: 6| Step: 6
Training loss: 5.529468536376953
Validation loss: 5.303546667098999

Epoch: 6| Step: 7
Training loss: 5.220700263977051
Validation loss: 5.301332155863444

Epoch: 6| Step: 8
Training loss: 6.466879844665527
Validation loss: 5.2989395459493

Epoch: 6| Step: 9
Training loss: 5.190411567687988
Validation loss: 5.296310265858968

Epoch: 6| Step: 10
Training loss: 6.508519172668457
Validation loss: 5.29373041788737

Epoch: 6| Step: 11
Training loss: 5.353943824768066
Validation loss: 5.290983438491821

Epoch: 6| Step: 12
Training loss: 5.965163230895996
Validation loss: 5.288145383199056

Epoch: 6| Step: 13
Training loss: 5.509863376617432
Validation loss: 5.285105228424072

Epoch: 3| Step: 0
Training loss: 5.226077079772949
Validation loss: 5.281857490539551

Epoch: 6| Step: 1
Training loss: 5.843983173370361
Validation loss: 5.278385321299235

Epoch: 6| Step: 2
Training loss: 5.295568466186523
Validation loss: 5.2749307950337725

Epoch: 6| Step: 3
Training loss: 5.520904064178467
Validation loss: 5.271122217178345

Epoch: 6| Step: 4
Training loss: 5.835680961608887
Validation loss: 5.267143805821736

Epoch: 6| Step: 5
Training loss: 5.364927291870117
Validation loss: 5.262946049372355

Epoch: 6| Step: 6
Training loss: 5.142512798309326
Validation loss: 5.258483250935872

Epoch: 6| Step: 7
Training loss: 5.641654014587402
Validation loss: 5.253891070683797

Epoch: 6| Step: 8
Training loss: 4.976914882659912
Validation loss: 5.249220609664917

Epoch: 6| Step: 9
Training loss: 4.785933017730713
Validation loss: 5.244209845860799

Epoch: 6| Step: 10
Training loss: 5.321307182312012
Validation loss: 5.238903919855754

Epoch: 6| Step: 11
Training loss: 5.265429496765137
Validation loss: 5.233508110046387

Epoch: 6| Step: 12
Training loss: 4.57048225402832
Validation loss: 5.227861722310384

Epoch: 6| Step: 13
Training loss: 5.749516487121582
Validation loss: 5.2220330238342285

Epoch: 4| Step: 0
Training loss: 4.568685531616211
Validation loss: 5.215957562128703

Epoch: 6| Step: 1
Training loss: 5.029743194580078
Validation loss: 5.209735155105591

Epoch: 6| Step: 2
Training loss: 5.283914566040039
Validation loss: 5.203341801961263

Epoch: 6| Step: 3
Training loss: 4.850680351257324
Validation loss: 5.196713288625081

Epoch: 6| Step: 4
Training loss: 4.343223571777344
Validation loss: 5.189848820368449

Epoch: 6| Step: 5
Training loss: 6.704318046569824
Validation loss: 5.182858387629191

Epoch: 6| Step: 6
Training loss: 5.615257263183594
Validation loss: 5.175850550333659

Epoch: 6| Step: 7
Training loss: 4.5044941902160645
Validation loss: 5.16835876305898

Epoch: 6| Step: 8
Training loss: 4.9043779373168945
Validation loss: 5.161182006200154

Epoch: 6| Step: 9
Training loss: 5.003244400024414
Validation loss: 5.153821309407552

Epoch: 6| Step: 10
Training loss: 5.720737457275391
Validation loss: 5.1459864775339765

Epoch: 6| Step: 11
Training loss: 6.242966651916504
Validation loss: 5.138460795084636

Epoch: 6| Step: 12
Training loss: 4.908021926879883
Validation loss: 5.130484898885091

Epoch: 6| Step: 13
Training loss: 5.711794853210449
Validation loss: 5.1225268840789795

Epoch: 5| Step: 0
Training loss: 5.704919815063477
Validation loss: 5.1144758860270185

Epoch: 6| Step: 1
Training loss: 4.678614616394043
Validation loss: 5.1060779094696045

Epoch: 6| Step: 2
Training loss: 5.266200542449951
Validation loss: 5.097809553146362

Epoch: 6| Step: 3
Training loss: 6.2115325927734375
Validation loss: 5.0892899831136065

Epoch: 6| Step: 4
Training loss: 5.0724101066589355
Validation loss: 5.080062071482341

Epoch: 6| Step: 5
Training loss: 4.755634307861328
Validation loss: 5.071271975835164

Epoch: 6| Step: 6
Training loss: 5.142279624938965
Validation loss: 5.062102754910787

Epoch: 6| Step: 7
Training loss: 5.095736980438232
Validation loss: 5.052667458852132

Epoch: 6| Step: 8
Training loss: 4.652739524841309
Validation loss: 5.042613585789998

Epoch: 6| Step: 9
Training loss: 5.672250270843506
Validation loss: 5.032972653706868

Epoch: 6| Step: 10
Training loss: 4.891840934753418
Validation loss: 5.023055950800578

Epoch: 6| Step: 11
Training loss: 4.476138114929199
Validation loss: 5.012496789296468

Epoch: 6| Step: 12
Training loss: 5.05827522277832
Validation loss: 5.0025144418080645

Epoch: 6| Step: 13
Training loss: 5.216218948364258
Validation loss: 4.992891629536946

Epoch: 6| Step: 0
Training loss: 4.051340103149414
Validation loss: 4.98261817296346

Epoch: 6| Step: 1
Training loss: 4.539494514465332
Validation loss: 4.9725643793741865

Epoch: 6| Step: 2
Training loss: 4.843542098999023
Validation loss: 4.963284174601237

Epoch: 6| Step: 3
Training loss: 6.33808708190918
Validation loss: 4.9534071286519366

Epoch: 6| Step: 4
Training loss: 5.234933853149414
Validation loss: 4.943897088368733

Epoch: 6| Step: 5
Training loss: 5.223243236541748
Validation loss: 4.93448003133138

Epoch: 6| Step: 6
Training loss: 6.129717826843262
Validation loss: 4.924921870231628

Epoch: 6| Step: 7
Training loss: 4.788295745849609
Validation loss: 4.915514389673869

Epoch: 6| Step: 8
Training loss: 4.576993942260742
Validation loss: 4.90603240331014

Epoch: 6| Step: 9
Training loss: 5.6488752365112305
Validation loss: 4.896685361862183

Epoch: 6| Step: 10
Training loss: 4.792758941650391
Validation loss: 4.88735564549764

Epoch: 6| Step: 11
Training loss: 3.903470039367676
Validation loss: 4.877985954284668

Epoch: 6| Step: 12
Training loss: 4.281519889831543
Validation loss: 4.86813489596049

Epoch: 6| Step: 13
Training loss: 5.71382999420166
Validation loss: 4.858435948689778

Epoch: 7| Step: 0
Training loss: 6.012394905090332
Validation loss: 4.848893245061238

Epoch: 6| Step: 1
Training loss: 5.420065879821777
Validation loss: 4.839017470677693

Epoch: 6| Step: 2
Training loss: 4.877513885498047
Validation loss: 4.829715967178345

Epoch: 6| Step: 3
Training loss: 5.457306861877441
Validation loss: 4.8205757935841875

Epoch: 6| Step: 4
Training loss: 4.03223991394043
Validation loss: 4.8113893667856855

Epoch: 6| Step: 5
Training loss: 3.9551987648010254
Validation loss: 4.8018561999003095

Epoch: 6| Step: 6
Training loss: 4.223053932189941
Validation loss: 4.7930616935094195

Epoch: 6| Step: 7
Training loss: 4.457066059112549
Validation loss: 4.78382666905721

Epoch: 6| Step: 8
Training loss: 4.929446220397949
Validation loss: 4.77536674340566

Epoch: 6| Step: 9
Training loss: 5.216060638427734
Validation loss: 4.766842762629191

Epoch: 6| Step: 10
Training loss: 5.36148738861084
Validation loss: 4.758628845214844

Epoch: 6| Step: 11
Training loss: 4.573948860168457
Validation loss: 4.7501223882039385

Epoch: 6| Step: 12
Training loss: 4.113813400268555
Validation loss: 4.741943359375

Epoch: 6| Step: 13
Training loss: 5.6877641677856445
Validation loss: 4.734138409296672

Epoch: 8| Step: 0
Training loss: 6.620850563049316
Validation loss: 4.72705062230428

Epoch: 6| Step: 1
Training loss: 5.981826305389404
Validation loss: 4.719972252845764

Epoch: 6| Step: 2
Training loss: 4.21668815612793
Validation loss: 4.713062206904094

Epoch: 6| Step: 3
Training loss: 4.463068008422852
Validation loss: 4.706542571385701

Epoch: 6| Step: 4
Training loss: 5.55277156829834
Validation loss: 4.700012127558391

Epoch: 6| Step: 5
Training loss: 4.927020072937012
Validation loss: 4.693709055582683

Epoch: 6| Step: 6
Training loss: 4.598385810852051
Validation loss: 4.687493483225505

Epoch: 6| Step: 7
Training loss: 4.21082878112793
Validation loss: 4.680628101030986

Epoch: 6| Step: 8
Training loss: 4.411874294281006
Validation loss: 4.67512305577596

Epoch: 6| Step: 9
Training loss: 3.836111545562744
Validation loss: 4.669322689374288

Epoch: 6| Step: 10
Training loss: 4.186656951904297
Validation loss: 4.663089156150818

Epoch: 6| Step: 11
Training loss: 4.98109245300293
Validation loss: 4.657304286956787

Epoch: 6| Step: 12
Training loss: 3.6231820583343506
Validation loss: 4.651180346806844

Epoch: 6| Step: 13
Training loss: 5.314358234405518
Validation loss: 4.644884824752808

Epoch: 9| Step: 0
Training loss: 3.8236215114593506
Validation loss: 4.639007806777954

Epoch: 6| Step: 1
Training loss: 4.36046028137207
Validation loss: 4.633070985476176

Epoch: 6| Step: 2
Training loss: 5.649478912353516
Validation loss: 4.627239465713501

Epoch: 6| Step: 3
Training loss: 4.549182891845703
Validation loss: 4.620386242866516

Epoch: 6| Step: 4
Training loss: 5.0956268310546875
Validation loss: 4.61411174138387

Epoch: 6| Step: 5
Training loss: 4.8909912109375
Validation loss: 4.607529004414876

Epoch: 6| Step: 6
Training loss: 5.2758636474609375
Validation loss: 4.600959817568461

Epoch: 6| Step: 7
Training loss: 3.995915412902832
Validation loss: 4.594570477803548

Epoch: 6| Step: 8
Training loss: 5.0873894691467285
Validation loss: 4.58780837059021

Epoch: 6| Step: 9
Training loss: 4.971824645996094
Validation loss: 4.581424236297607

Epoch: 6| Step: 10
Training loss: 5.325095176696777
Validation loss: 4.5745987097422285

Epoch: 6| Step: 11
Training loss: 5.374209880828857
Validation loss: 4.568055272102356

Epoch: 6| Step: 12
Training loss: 3.5390403270721436
Validation loss: 4.561835368474324

Epoch: 6| Step: 13
Training loss: 3.8288016319274902
Validation loss: 4.555030266443889

Epoch: 10| Step: 0
Training loss: 3.907583475112915
Validation loss: 4.549262444178264

Epoch: 6| Step: 1
Training loss: 3.493396759033203
Validation loss: 4.543699860572815

Epoch: 6| Step: 2
Training loss: 5.5643720626831055
Validation loss: 4.538014968236287

Epoch: 6| Step: 3
Training loss: 5.140077590942383
Validation loss: 4.5324457089106245

Epoch: 6| Step: 4
Training loss: 5.497717380523682
Validation loss: 4.527738889058431

Epoch: 6| Step: 5
Training loss: 4.467122554779053
Validation loss: 4.522761106491089

Epoch: 6| Step: 6
Training loss: 4.51673698425293
Validation loss: 4.517846663792928

Epoch: 6| Step: 7
Training loss: 3.8423409461975098
Validation loss: 4.512811660766602

Epoch: 6| Step: 8
Training loss: 4.669147968292236
Validation loss: 4.508511066436768

Epoch: 6| Step: 9
Training loss: 4.6516852378845215
Validation loss: 4.503756721814473

Epoch: 6| Step: 10
Training loss: 4.360477447509766
Validation loss: 4.499376535415649

Epoch: 6| Step: 11
Training loss: 5.192409038543701
Validation loss: 4.494805057843526

Epoch: 6| Step: 12
Training loss: 5.050682067871094
Validation loss: 4.489760001500447

Epoch: 6| Step: 13
Training loss: 4.3340630531311035
Validation loss: 4.485104600588481

Epoch: 11| Step: 0
Training loss: 5.037412643432617
Validation loss: 4.48038371404012

Epoch: 6| Step: 1
Training loss: 5.187860488891602
Validation loss: 4.475900808970134

Epoch: 6| Step: 2
Training loss: 5.495024681091309
Validation loss: 4.471088767051697

Epoch: 6| Step: 3
Training loss: 4.070135116577148
Validation loss: 4.466336647669475

Epoch: 6| Step: 4
Training loss: 4.741933822631836
Validation loss: 4.460979104042053

Epoch: 6| Step: 5
Training loss: 3.897390604019165
Validation loss: 4.456475615501404

Epoch: 6| Step: 6
Training loss: 5.263034820556641
Validation loss: 4.452042738596599

Epoch: 6| Step: 7
Training loss: 2.751156806945801
Validation loss: 4.447381178538005

Epoch: 6| Step: 8
Training loss: 4.518525123596191
Validation loss: 4.443483034769694

Epoch: 6| Step: 9
Training loss: 4.892912864685059
Validation loss: 4.438804308573405

Epoch: 6| Step: 10
Training loss: 3.868825912475586
Validation loss: 4.434135715166728

Epoch: 6| Step: 11
Training loss: 5.2335734367370605
Validation loss: 4.43017303943634

Epoch: 6| Step: 12
Training loss: 4.420289039611816
Validation loss: 4.4250714381535845

Epoch: 6| Step: 13
Training loss: 4.494230270385742
Validation loss: 4.4213502407073975

Epoch: 12| Step: 0
Training loss: 4.892091751098633
Validation loss: 4.417882323265076

Epoch: 6| Step: 1
Training loss: 4.125897407531738
Validation loss: 4.413029472033183

Epoch: 6| Step: 2
Training loss: 3.6707091331481934
Validation loss: 4.40910283724467

Epoch: 6| Step: 3
Training loss: 5.988141059875488
Validation loss: 4.405015309651692

Epoch: 6| Step: 4
Training loss: 4.206047058105469
Validation loss: 4.400131622950236

Epoch: 6| Step: 5
Training loss: 5.155094146728516
Validation loss: 4.396501302719116

Epoch: 6| Step: 6
Training loss: 4.688962936401367
Validation loss: 4.392658352851868

Epoch: 6| Step: 7
Training loss: 3.000847339630127
Validation loss: 4.387990832328796

Epoch: 6| Step: 8
Training loss: 4.79585075378418
Validation loss: 4.3831837972005205

Epoch: 6| Step: 9
Training loss: 5.502459526062012
Validation loss: 4.379321654637654

Epoch: 6| Step: 10
Training loss: 2.8933112621307373
Validation loss: 4.37428347269694

Epoch: 6| Step: 11
Training loss: 4.722245693206787
Validation loss: 4.369799693425496

Epoch: 6| Step: 12
Training loss: 4.026225566864014
Validation loss: 4.365923364957173

Epoch: 6| Step: 13
Training loss: 5.438748359680176
Validation loss: 4.362444321314494

Epoch: 13| Step: 0
Training loss: 4.257664680480957
Validation loss: 4.358412146568298

Epoch: 6| Step: 1
Training loss: 3.9646286964416504
Validation loss: 4.354246258735657

Epoch: 6| Step: 2
Training loss: 4.651333332061768
Validation loss: 4.349611282348633

Epoch: 6| Step: 3
Training loss: 4.34615421295166
Validation loss: 4.345446348190308

Epoch: 6| Step: 4
Training loss: 4.298547267913818
Validation loss: 4.341818173726399

Epoch: 6| Step: 5
Training loss: 3.779223918914795
Validation loss: 4.337173620859782

Epoch: 6| Step: 6
Training loss: 5.146868705749512
Validation loss: 4.333201050758362

Epoch: 6| Step: 7
Training loss: 4.530739784240723
Validation loss: 4.329183340072632

Epoch: 6| Step: 8
Training loss: 4.656269073486328
Validation loss: 4.325564940770467

Epoch: 6| Step: 9
Training loss: 4.883380889892578
Validation loss: 4.321580211321513

Epoch: 6| Step: 10
Training loss: 4.844047546386719
Validation loss: 4.316550254821777

Epoch: 6| Step: 11
Training loss: 3.652308940887451
Validation loss: 4.312633593877156

Epoch: 6| Step: 12
Training loss: 5.471554756164551
Validation loss: 4.309058785438538

Epoch: 6| Step: 13
Training loss: 3.8656954765319824
Validation loss: 4.304155707359314

Epoch: 14| Step: 0
Training loss: 4.1482157707214355
Validation loss: 4.299737453460693

Epoch: 6| Step: 1
Training loss: 4.6453351974487305
Validation loss: 4.296037038167317

Epoch: 6| Step: 2
Training loss: 5.263222694396973
Validation loss: 4.291739662488301

Epoch: 6| Step: 3
Training loss: 4.535467147827148
Validation loss: 4.287123799324036

Epoch: 6| Step: 4
Training loss: 4.163371562957764
Validation loss: 4.283327420552571

Epoch: 6| Step: 5
Training loss: 2.841440200805664
Validation loss: 4.2790136734644575

Epoch: 6| Step: 6
Training loss: 4.511021137237549
Validation loss: 4.274103919665019

Epoch: 6| Step: 7
Training loss: 4.416570663452148
Validation loss: 4.269076744715373

Epoch: 6| Step: 8
Training loss: 3.710508346557617
Validation loss: 4.264647285143535

Epoch: 6| Step: 9
Training loss: 5.2423858642578125
Validation loss: 4.261035482088725

Epoch: 6| Step: 10
Training loss: 4.860950946807861
Validation loss: 4.256898919741313

Epoch: 6| Step: 11
Training loss: 4.275239944458008
Validation loss: 4.251980026563008

Epoch: 6| Step: 12
Training loss: 5.069659233093262
Validation loss: 4.248295704523723

Epoch: 6| Step: 13
Training loss: 3.8830440044403076
Validation loss: 4.245161533355713

Epoch: 15| Step: 0
Training loss: 3.5608954429626465
Validation loss: 4.238673408826192

Epoch: 6| Step: 1
Training loss: 4.226635932922363
Validation loss: 4.234489281972249

Epoch: 6| Step: 2
Training loss: 5.2032365798950195
Validation loss: 4.23075258731842

Epoch: 6| Step: 3
Training loss: 4.523515224456787
Validation loss: 4.226588249206543

Epoch: 6| Step: 4
Training loss: 4.599928379058838
Validation loss: 4.2221382061640425

Epoch: 6| Step: 5
Training loss: 4.376611709594727
Validation loss: 4.216603755950928

Epoch: 6| Step: 6
Training loss: 2.814875602722168
Validation loss: 4.211228410402934

Epoch: 6| Step: 7
Training loss: 4.8746819496154785
Validation loss: 4.206987539927165

Epoch: 6| Step: 8
Training loss: 4.061417102813721
Validation loss: 4.202497482299805

Epoch: 6| Step: 9
Training loss: 4.530393600463867
Validation loss: 4.197763641675313

Epoch: 6| Step: 10
Training loss: 4.146933555603027
Validation loss: 4.192622582117717

Epoch: 6| Step: 11
Training loss: 4.989129066467285
Validation loss: 4.187549829483032

Epoch: 6| Step: 12
Training loss: 5.280942916870117
Validation loss: 4.183221936225891

Epoch: 6| Step: 13
Training loss: 3.59421443939209
Validation loss: 4.178258339564006

Epoch: 16| Step: 0
Training loss: 4.339715957641602
Validation loss: 4.173863569895427

Epoch: 6| Step: 1
Training loss: 4.3171796798706055
Validation loss: 4.170300563176473

Epoch: 6| Step: 2
Training loss: 4.3245344161987305
Validation loss: 4.16465695699056

Epoch: 6| Step: 3
Training loss: 2.5919601917266846
Validation loss: 4.159706354141235

Epoch: 6| Step: 4
Training loss: 4.059897422790527
Validation loss: 4.1555449565251665

Epoch: 6| Step: 5
Training loss: 4.962747573852539
Validation loss: 4.15164069334666

Epoch: 6| Step: 6
Training loss: 4.703398704528809
Validation loss: 4.146346966425578

Epoch: 6| Step: 7
Training loss: 4.6374406814575195
Validation loss: 4.1427585283915205

Epoch: 6| Step: 8
Training loss: 4.5679802894592285
Validation loss: 4.139583468437195

Epoch: 6| Step: 9
Training loss: 4.968651294708252
Validation loss: 4.13306450843811

Epoch: 6| Step: 10
Training loss: 4.821042060852051
Validation loss: 4.129095077514648

Epoch: 6| Step: 11
Training loss: 4.59547233581543
Validation loss: 4.124618212381999

Epoch: 6| Step: 12
Training loss: 3.1122093200683594
Validation loss: 4.121041138966878

Epoch: 6| Step: 13
Training loss: 3.9451651573181152
Validation loss: 4.115752776463826

Epoch: 17| Step: 0
Training loss: 4.555365085601807
Validation loss: 4.111343304316203

Epoch: 6| Step: 1
Training loss: 4.68820858001709
Validation loss: 4.107301553090413

Epoch: 6| Step: 2
Training loss: 4.106647968292236
Validation loss: 4.1025402545928955

Epoch: 6| Step: 3
Training loss: 3.633180618286133
Validation loss: 4.097758213678996

Epoch: 6| Step: 4
Training loss: 4.545035362243652
Validation loss: 4.095436731974284

Epoch: 6| Step: 5
Training loss: 4.552080154418945
Validation loss: 4.0934319496154785

Epoch: 6| Step: 6
Training loss: 3.764068126678467
Validation loss: 4.085996627807617

Epoch: 6| Step: 7
Training loss: 4.1166229248046875
Validation loss: 4.081950863202413

Epoch: 6| Step: 8
Training loss: 4.552424430847168
Validation loss: 4.078012903531392

Epoch: 6| Step: 9
Training loss: 3.597092628479004
Validation loss: 4.0740119616190595

Epoch: 6| Step: 10
Training loss: 4.796189308166504
Validation loss: 4.0695496797561646

Epoch: 6| Step: 11
Training loss: 4.016364097595215
Validation loss: 4.065023581186931

Epoch: 6| Step: 12
Training loss: 3.4776806831359863
Validation loss: 4.061314423878987

Epoch: 6| Step: 13
Training loss: 4.753484725952148
Validation loss: 4.058276693026225

Epoch: 18| Step: 0
Training loss: 3.8972320556640625
Validation loss: 4.054253101348877

Epoch: 6| Step: 1
Training loss: 4.760265350341797
Validation loss: 4.049396395683289

Epoch: 6| Step: 2
Training loss: 4.526479244232178
Validation loss: 4.043598095575969

Epoch: 6| Step: 3
Training loss: 4.028910160064697
Validation loss: 4.038134376207988

Epoch: 6| Step: 4
Training loss: 4.473755836486816
Validation loss: 4.03479818503062

Epoch: 6| Step: 5
Training loss: 3.3940820693969727
Validation loss: 4.030514756838481

Epoch: 6| Step: 6
Training loss: 5.729239463806152
Validation loss: 4.027339180310567

Epoch: 6| Step: 7
Training loss: 4.029688835144043
Validation loss: 4.022565245628357

Epoch: 6| Step: 8
Training loss: 3.9014530181884766
Validation loss: 4.018397053082784

Epoch: 6| Step: 9
Training loss: 3.103299856185913
Validation loss: 4.014729460080464

Epoch: 6| Step: 10
Training loss: 4.098416328430176
Validation loss: 4.010292371114095

Epoch: 6| Step: 11
Training loss: 3.4999046325683594
Validation loss: 4.006747921307881

Epoch: 6| Step: 12
Training loss: 4.47336483001709
Validation loss: 3.999512712160746

Epoch: 6| Step: 13
Training loss: 4.442955493927002
Validation loss: 3.9953229824701944

Epoch: 19| Step: 0
Training loss: 3.2577269077301025
Validation loss: 3.991180896759033

Epoch: 6| Step: 1
Training loss: 4.295934677124023
Validation loss: 3.987656752268473

Epoch: 6| Step: 2
Training loss: 5.103139877319336
Validation loss: 3.983187715212504

Epoch: 6| Step: 3
Training loss: 5.482371807098389
Validation loss: 3.978882312774658

Epoch: 6| Step: 4
Training loss: 3.763317108154297
Validation loss: 3.974125941594442

Epoch: 6| Step: 5
Training loss: 4.03790807723999
Validation loss: 3.977868676185608

Epoch: 6| Step: 6
Training loss: 4.6324992179870605
Validation loss: 3.966140945752462

Epoch: 6| Step: 7
Training loss: 4.338827133178711
Validation loss: 3.9607067902882895

Epoch: 6| Step: 8
Training loss: 3.585763692855835
Validation loss: 3.957259257634481

Epoch: 6| Step: 9
Training loss: 3.5478413105010986
Validation loss: 3.952565828959147

Epoch: 6| Step: 10
Training loss: 3.676358699798584
Validation loss: 3.9482000271479287

Epoch: 6| Step: 11
Training loss: 3.7504515647888184
Validation loss: 3.9434844652811685

Epoch: 6| Step: 12
Training loss: 4.216737747192383
Validation loss: 3.939569036165873

Epoch: 6| Step: 13
Training loss: 3.856140375137329
Validation loss: 3.9356292883555093

Epoch: 20| Step: 0
Training loss: 2.8863954544067383
Validation loss: 3.9311806360880532

Epoch: 6| Step: 1
Training loss: 3.5953445434570312
Validation loss: 3.9269069035847983

Epoch: 6| Step: 2
Training loss: 3.5529251098632812
Validation loss: 3.922825296719869

Epoch: 6| Step: 3
Training loss: 4.165272235870361
Validation loss: 3.9179091850916543

Epoch: 6| Step: 4
Training loss: 5.594220161437988
Validation loss: 3.912785609563192

Epoch: 6| Step: 5
Training loss: 3.989872694015503
Validation loss: 3.9077837467193604

Epoch: 6| Step: 6
Training loss: 4.601723670959473
Validation loss: 3.9022196928660073

Epoch: 6| Step: 7
Training loss: 3.372068405151367
Validation loss: 3.898498058319092

Epoch: 6| Step: 8
Training loss: 4.599600791931152
Validation loss: 3.8940102656682334

Epoch: 6| Step: 9
Training loss: 3.5831546783447266
Validation loss: 3.88900625705719

Epoch: 6| Step: 10
Training loss: 4.217268943786621
Validation loss: 3.884899616241455

Epoch: 6| Step: 11
Training loss: 4.099849700927734
Validation loss: 3.879852056503296

Epoch: 6| Step: 12
Training loss: 3.834758996963501
Validation loss: 3.87494957447052

Epoch: 6| Step: 13
Training loss: 4.613162994384766
Validation loss: 3.8699297110239663

Epoch: 21| Step: 0
Training loss: 5.013327598571777
Validation loss: 3.8657145897547402

Epoch: 6| Step: 1
Training loss: 4.365319728851318
Validation loss: 3.8618167638778687

Epoch: 6| Step: 2
Training loss: 4.6990580558776855
Validation loss: 3.8566654920578003

Epoch: 6| Step: 3
Training loss: 4.610347747802734
Validation loss: 3.8514289458592734

Epoch: 6| Step: 4
Training loss: 4.17031192779541
Validation loss: 3.848049600919088

Epoch: 6| Step: 5
Training loss: 3.029966354370117
Validation loss: 3.8494284550348916

Epoch: 6| Step: 6
Training loss: 3.9305531978607178
Validation loss: 3.8404225508371987

Epoch: 6| Step: 7
Training loss: 4.136289596557617
Validation loss: 3.8341286182403564

Epoch: 6| Step: 8
Training loss: 3.798301935195923
Validation loss: 3.8284741242726645

Epoch: 6| Step: 9
Training loss: 4.003357887268066
Validation loss: 3.8244044383366904

Epoch: 6| Step: 10
Training loss: 3.82472562789917
Validation loss: 3.820549408594767

Epoch: 6| Step: 11
Training loss: 3.713498592376709
Validation loss: 3.8172057469685874

Epoch: 6| Step: 12
Training loss: 3.6256117820739746
Validation loss: 3.812163829803467

Epoch: 6| Step: 13
Training loss: 2.9468212127685547
Validation loss: 3.8079487482706704

Epoch: 22| Step: 0
Training loss: 3.335911989212036
Validation loss: 3.803276697794596

Epoch: 6| Step: 1
Training loss: 3.2302496433258057
Validation loss: 3.798464059829712

Epoch: 6| Step: 2
Training loss: 3.824307680130005
Validation loss: 3.7927219470342

Epoch: 6| Step: 3
Training loss: 4.978737831115723
Validation loss: 3.788436532020569

Epoch: 6| Step: 4
Training loss: 4.208279609680176
Validation loss: 3.7846142848332724

Epoch: 6| Step: 5
Training loss: 3.328808307647705
Validation loss: 3.780725081761678

Epoch: 6| Step: 6
Training loss: 4.3906731605529785
Validation loss: 3.7754563093185425

Epoch: 6| Step: 7
Training loss: 4.106395721435547
Validation loss: 3.7702256441116333

Epoch: 6| Step: 8
Training loss: 3.924558639526367
Validation loss: 3.766488472620646

Epoch: 6| Step: 9
Training loss: 3.3876428604125977
Validation loss: 3.761906703313192

Epoch: 6| Step: 10
Training loss: 4.154166221618652
Validation loss: 3.757780909538269

Epoch: 6| Step: 11
Training loss: 4.360976219177246
Validation loss: 3.7532880703608194

Epoch: 6| Step: 12
Training loss: 3.54738187789917
Validation loss: 3.749652544657389

Epoch: 6| Step: 13
Training loss: 4.252280235290527
Validation loss: 3.7445799112319946

Epoch: 23| Step: 0
Training loss: 3.803673505783081
Validation loss: 3.7401676972707114

Epoch: 6| Step: 1
Training loss: 4.145958423614502
Validation loss: 3.7358742554982505

Epoch: 6| Step: 2
Training loss: 3.8666129112243652
Validation loss: 3.7322179873784385

Epoch: 6| Step: 3
Training loss: 4.237522125244141
Validation loss: 3.7282392183939614

Epoch: 6| Step: 4
Training loss: 3.781763792037964
Validation loss: 3.723958969116211

Epoch: 6| Step: 5
Training loss: 3.1292965412139893
Validation loss: 3.7193932135899863

Epoch: 6| Step: 6
Training loss: 4.077486038208008
Validation loss: 3.7143918673197427

Epoch: 6| Step: 7
Training loss: 4.317032814025879
Validation loss: 3.7110427220662436

Epoch: 6| Step: 8
Training loss: 3.222235918045044
Validation loss: 3.7064355611801147

Epoch: 6| Step: 9
Training loss: 4.724867820739746
Validation loss: 3.701756159464518

Epoch: 6| Step: 10
Training loss: 3.45635986328125
Validation loss: 3.697482466697693

Epoch: 6| Step: 11
Training loss: 3.9509425163269043
Validation loss: 3.6925957202911377

Epoch: 6| Step: 12
Training loss: 3.5373592376708984
Validation loss: 3.688196579615275

Epoch: 6| Step: 13
Training loss: 3.9645633697509766
Validation loss: 3.6842018763224282

Epoch: 24| Step: 0
Training loss: 4.499903678894043
Validation loss: 3.6793275276819863

Epoch: 6| Step: 1
Training loss: 3.747629404067993
Validation loss: 3.675109386444092

Epoch: 6| Step: 2
Training loss: 3.973130464553833
Validation loss: 3.670141657193502

Epoch: 6| Step: 3
Training loss: 3.8546674251556396
Validation loss: 3.6663246949513755

Epoch: 6| Step: 4
Training loss: 3.8039793968200684
Validation loss: 3.6611209313074746

Epoch: 6| Step: 5
Training loss: 3.6743640899658203
Validation loss: 3.6575637261072793

Epoch: 6| Step: 6
Training loss: 4.184008598327637
Validation loss: 3.652299483617147

Epoch: 6| Step: 7
Training loss: 3.6380181312561035
Validation loss: 3.64739720026652

Epoch: 6| Step: 8
Training loss: 4.220797538757324
Validation loss: 3.6436325311660767

Epoch: 6| Step: 9
Training loss: 3.9426379203796387
Validation loss: 3.638667027155558

Epoch: 6| Step: 10
Training loss: 3.915679454803467
Validation loss: 3.634105602900187

Epoch: 6| Step: 11
Training loss: 3.5064706802368164
Validation loss: 3.628963589668274

Epoch: 6| Step: 12
Training loss: 3.479602813720703
Validation loss: 3.624051292737325

Epoch: 6| Step: 13
Training loss: 2.9361062049865723
Validation loss: 3.619936188062032

Epoch: 25| Step: 0
Training loss: 4.070771217346191
Validation loss: 3.615598678588867

Epoch: 6| Step: 1
Training loss: 3.592658519744873
Validation loss: 3.6101072629292807

Epoch: 6| Step: 2
Training loss: 3.607656955718994
Validation loss: 3.604891022046407

Epoch: 6| Step: 3
Training loss: 3.4183974266052246
Validation loss: 3.599868377049764

Epoch: 6| Step: 4
Training loss: 4.148071765899658
Validation loss: 3.5952837069829306

Epoch: 6| Step: 5
Training loss: 3.577315330505371
Validation loss: 3.5905848344167075

Epoch: 6| Step: 6
Training loss: 2.5533900260925293
Validation loss: 3.5860480070114136

Epoch: 6| Step: 7
Training loss: 3.750664472579956
Validation loss: 3.5813226302464805

Epoch: 6| Step: 8
Training loss: 3.5063259601593018
Validation loss: 3.576238473256429

Epoch: 6| Step: 9
Training loss: 4.339422225952148
Validation loss: 3.571930170059204

Epoch: 6| Step: 10
Training loss: 3.8998825550079346
Validation loss: 3.5670860608418784

Epoch: 6| Step: 11
Training loss: 3.9471616744995117
Validation loss: 3.5630265871683755

Epoch: 6| Step: 12
Training loss: 4.348187446594238
Validation loss: 3.5580281019210815

Epoch: 6| Step: 13
Training loss: 3.7343616485595703
Validation loss: 3.5539159774780273

Epoch: 26| Step: 0
Training loss: 3.4728293418884277
Validation loss: 3.548917055130005

Epoch: 6| Step: 1
Training loss: 3.5038669109344482
Validation loss: 3.5442774295806885

Epoch: 6| Step: 2
Training loss: 3.413919687271118
Validation loss: 3.539854049682617

Epoch: 6| Step: 3
Training loss: 3.3862109184265137
Validation loss: 3.5355326334635415

Epoch: 6| Step: 4
Training loss: 4.749039173126221
Validation loss: 3.5312069853146872

Epoch: 6| Step: 5
Training loss: 3.4045376777648926
Validation loss: 3.525767962137858

Epoch: 6| Step: 6
Training loss: 4.217170715332031
Validation loss: 3.5210214058558145

Epoch: 6| Step: 7
Training loss: 3.0895543098449707
Validation loss: 3.516128142674764

Epoch: 6| Step: 8
Training loss: 4.0649800300598145
Validation loss: 3.5115203857421875

Epoch: 6| Step: 9
Training loss: 3.6413824558258057
Validation loss: 3.5069815715154014

Epoch: 6| Step: 10
Training loss: 4.4978108406066895
Validation loss: 3.5019481976826987

Epoch: 6| Step: 11
Training loss: 3.977980375289917
Validation loss: 3.4975481033325195

Epoch: 6| Step: 12
Training loss: 2.9638571739196777
Validation loss: 3.492498437563578

Epoch: 6| Step: 13
Training loss: 3.2107698917388916
Validation loss: 3.4874401489893594

Epoch: 27| Step: 0
Training loss: 2.7957534790039062
Validation loss: 3.4827508131663003

Epoch: 6| Step: 1
Training loss: 3.5287399291992188
Validation loss: 3.478363513946533

Epoch: 6| Step: 2
Training loss: 3.9346249103546143
Validation loss: 3.474416136741638

Epoch: 6| Step: 3
Training loss: 3.928433895111084
Validation loss: 3.4694743156433105

Epoch: 6| Step: 4
Training loss: 3.2291512489318848
Validation loss: 3.4647719065348306

Epoch: 6| Step: 5
Training loss: 3.859790325164795
Validation loss: 3.460145115852356

Epoch: 6| Step: 6
Training loss: 3.389892101287842
Validation loss: 3.454998771349589

Epoch: 6| Step: 7
Training loss: 3.2161483764648438
Validation loss: 3.4504785935084024

Epoch: 6| Step: 8
Training loss: 3.494467258453369
Validation loss: 3.4460370937983194

Epoch: 6| Step: 9
Training loss: 3.820025682449341
Validation loss: 3.4430054426193237

Epoch: 6| Step: 10
Training loss: 2.968348264694214
Validation loss: 3.439637859662374

Epoch: 6| Step: 11
Training loss: 4.78968620300293
Validation loss: 3.4342973629633584

Epoch: 6| Step: 12
Training loss: 4.57330846786499
Validation loss: 3.4288766781489053

Epoch: 6| Step: 13
Training loss: 3.152214527130127
Validation loss: 3.422530929247538

Epoch: 28| Step: 0
Training loss: 2.918980121612549
Validation loss: 3.4189321200052896

Epoch: 6| Step: 1
Training loss: 4.551817417144775
Validation loss: 3.414637049039205

Epoch: 6| Step: 2
Training loss: 3.3944320678710938
Validation loss: 3.409082214037577

Epoch: 6| Step: 3
Training loss: 3.3048107624053955
Validation loss: 3.4046665827433267

Epoch: 6| Step: 4
Training loss: 4.085799217224121
Validation loss: 3.400580883026123

Epoch: 6| Step: 5
Training loss: 3.2792022228240967
Validation loss: 3.3968034187952676

Epoch: 6| Step: 6
Training loss: 3.974036455154419
Validation loss: 3.3908619483311973

Epoch: 6| Step: 7
Training loss: 3.457085609436035
Validation loss: 3.3863418896993003

Epoch: 6| Step: 8
Training loss: 2.8637771606445312
Validation loss: 3.3817259867986045

Epoch: 6| Step: 9
Training loss: 3.9993646144866943
Validation loss: 3.3765921592712402

Epoch: 6| Step: 10
Training loss: 3.3655552864074707
Validation loss: 3.3713560899098716

Epoch: 6| Step: 11
Training loss: 3.741560935974121
Validation loss: 3.3670239448547363

Epoch: 6| Step: 12
Training loss: 2.969907522201538
Validation loss: 3.362204114596049

Epoch: 6| Step: 13
Training loss: 3.8886446952819824
Validation loss: 3.358154018719991

Epoch: 29| Step: 0
Training loss: 3.130831241607666
Validation loss: 3.354735334714254

Epoch: 6| Step: 1
Training loss: 4.108028411865234
Validation loss: 3.349594076474508

Epoch: 6| Step: 2
Training loss: 4.0657806396484375
Validation loss: 3.345296065012614

Epoch: 6| Step: 3
Training loss: 2.9697632789611816
Validation loss: 3.341969092686971

Epoch: 6| Step: 4
Training loss: 2.672914505004883
Validation loss: 3.3407828410466514

Epoch: 6| Step: 5
Training loss: 3.5213685035705566
Validation loss: 3.334434231122335

Epoch: 6| Step: 6
Training loss: 3.1841726303100586
Validation loss: 3.326219399770101

Epoch: 6| Step: 7
Training loss: 4.045091152191162
Validation loss: 3.3223114808400473

Epoch: 6| Step: 8
Training loss: 3.395087957382202
Validation loss: 3.3198297023773193

Epoch: 6| Step: 9
Training loss: 3.921555280685425
Validation loss: 3.317457993825277

Epoch: 6| Step: 10
Training loss: 3.892293930053711
Validation loss: 3.3123835722605386

Epoch: 6| Step: 11
Training loss: 2.904965400695801
Validation loss: 3.3054041862487793

Epoch: 6| Step: 12
Training loss: 4.273397445678711
Validation loss: 3.3022473057111106

Epoch: 6| Step: 13
Training loss: 2.8700177669525146
Validation loss: 3.296692212422689

Epoch: 30| Step: 0
Training loss: 2.7020998001098633
Validation loss: 3.2919623454411826

Epoch: 6| Step: 1
Training loss: 2.8471317291259766
Validation loss: 3.288392265637716

Epoch: 6| Step: 2
Training loss: 3.6364586353302
Validation loss: 3.285030722618103

Epoch: 6| Step: 3
Training loss: 3.8105456829071045
Validation loss: 3.2805541356404624

Epoch: 6| Step: 4
Training loss: 3.254729747772217
Validation loss: 3.274715304374695

Epoch: 6| Step: 5
Training loss: 4.026734352111816
Validation loss: 3.270435412724813

Epoch: 6| Step: 6
Training loss: 3.4812777042388916
Validation loss: 3.2676016092300415

Epoch: 6| Step: 7
Training loss: 3.4737234115600586
Validation loss: 3.2621031602223716

Epoch: 6| Step: 8
Training loss: 3.291571617126465
Validation loss: 3.2573867241541543

Epoch: 6| Step: 9
Training loss: 3.115492820739746
Validation loss: 3.252889553705851

Epoch: 6| Step: 10
Training loss: 3.1717381477355957
Validation loss: 3.2487539052963257

Epoch: 6| Step: 11
Training loss: 3.322242021560669
Validation loss: 3.2441423734029136

Epoch: 6| Step: 12
Training loss: 3.766329765319824
Validation loss: 3.2398742039998374

Epoch: 6| Step: 13
Training loss: 4.224740982055664
Validation loss: 3.2357584635416665

Epoch: 31| Step: 0
Training loss: 3.158512592315674
Validation loss: 3.230898936589559

Epoch: 6| Step: 1
Training loss: 3.645383358001709
Validation loss: 3.226112882296244

Epoch: 6| Step: 2
Training loss: 4.079375267028809
Validation loss: 3.2212392489115396

Epoch: 6| Step: 3
Training loss: 3.356213092803955
Validation loss: 3.2163429260253906

Epoch: 6| Step: 4
Training loss: 2.155561923980713
Validation loss: 3.2113753954569497

Epoch: 6| Step: 5
Training loss: 3.665412425994873
Validation loss: 3.2075581153233848

Epoch: 6| Step: 6
Training loss: 3.7610840797424316
Validation loss: 3.203533331553141

Epoch: 6| Step: 7
Training loss: 3.30477237701416
Validation loss: 3.1998294989267984

Epoch: 6| Step: 8
Training loss: 3.09263277053833
Validation loss: 3.195802370707194

Epoch: 6| Step: 9
Training loss: 4.044809341430664
Validation loss: 3.194173514842987

Epoch: 6| Step: 10
Training loss: 2.8346340656280518
Validation loss: 3.1848096450169883

Epoch: 6| Step: 11
Training loss: 3.779280185699463
Validation loss: 3.180421551068624

Epoch: 6| Step: 12
Training loss: 3.239743232727051
Validation loss: 3.1763433615366616

Epoch: 6| Step: 13
Training loss: 3.245408535003662
Validation loss: 3.172337452570597

Epoch: 32| Step: 0
Training loss: 3.2837884426116943
Validation loss: 3.168431878089905

Epoch: 6| Step: 1
Training loss: 4.104706287384033
Validation loss: 3.1641034682591758

Epoch: 6| Step: 2
Training loss: 3.362163543701172
Validation loss: 3.159687876701355

Epoch: 6| Step: 3
Training loss: 3.9289755821228027
Validation loss: 3.155639131863912

Epoch: 6| Step: 4
Training loss: 3.7551989555358887
Validation loss: 3.152135173479716

Epoch: 6| Step: 5
Training loss: 2.6003527641296387
Validation loss: 3.147225101788839

Epoch: 6| Step: 6
Training loss: 3.4969468116760254
Validation loss: 3.1434577306111655

Epoch: 6| Step: 7
Training loss: 2.957190990447998
Validation loss: 3.1381861368815103

Epoch: 6| Step: 8
Training loss: 2.7709710597991943
Validation loss: 3.135079503059387

Epoch: 6| Step: 9
Training loss: 3.0522172451019287
Validation loss: 3.131827155749003

Epoch: 6| Step: 10
Training loss: 3.2828025817871094
Validation loss: 3.128113587697347

Epoch: 6| Step: 11
Training loss: 2.976088047027588
Validation loss: 3.1234989960988364

Epoch: 6| Step: 12
Training loss: 3.1155824661254883
Validation loss: 3.1189854939778647

Epoch: 6| Step: 13
Training loss: 3.9029836654663086
Validation loss: 3.1141233444213867

Epoch: 33| Step: 0
Training loss: 4.102132797241211
Validation loss: 3.109238862991333

Epoch: 6| Step: 1
Training loss: 3.3154313564300537
Validation loss: 3.1057161490122476

Epoch: 6| Step: 2
Training loss: 4.198712348937988
Validation loss: 3.10140597820282

Epoch: 6| Step: 3
Training loss: 3.274101972579956
Validation loss: 3.097191095352173

Epoch: 6| Step: 4
Training loss: 2.883230686187744
Validation loss: 3.093589266141256

Epoch: 6| Step: 5
Training loss: 3.5142760276794434
Validation loss: 3.0895080963770547

Epoch: 6| Step: 6
Training loss: 2.7889773845672607
Validation loss: 3.085666219393412

Epoch: 6| Step: 7
Training loss: 3.563021659851074
Validation loss: 3.081239660580953

Epoch: 6| Step: 8
Training loss: 2.3330514430999756
Validation loss: 3.077322483062744

Epoch: 6| Step: 9
Training loss: 3.1529674530029297
Validation loss: 3.0731970071792603

Epoch: 6| Step: 10
Training loss: 3.164973497390747
Validation loss: 3.070220629374186

Epoch: 6| Step: 11
Training loss: 3.1956186294555664
Validation loss: 3.0653574069341025

Epoch: 6| Step: 12
Training loss: 3.673145294189453
Validation loss: 3.0613828897476196

Epoch: 6| Step: 13
Training loss: 2.6848390102386475
Validation loss: 3.058952808380127

Epoch: 34| Step: 0
Training loss: 2.8834240436553955
Validation loss: 3.056794762611389

Epoch: 6| Step: 1
Training loss: 3.8077468872070312
Validation loss: 3.0509305795033774

Epoch: 6| Step: 2
Training loss: 3.322376251220703
Validation loss: 3.0484205881754556

Epoch: 6| Step: 3
Training loss: 2.660273551940918
Validation loss: 3.0470023949941

Epoch: 6| Step: 4
Training loss: 3.2931385040283203
Validation loss: 3.0417587757110596

Epoch: 6| Step: 5
Training loss: 3.6695034503936768
Validation loss: 3.051048517227173

Epoch: 6| Step: 6
Training loss: 2.8062119483947754
Validation loss: 3.0343945026397705

Epoch: 6| Step: 7
Training loss: 3.6751389503479004
Validation loss: 3.0297216176986694

Epoch: 6| Step: 8
Training loss: 2.835645914077759
Validation loss: 3.0274604956309

Epoch: 6| Step: 9
Training loss: 3.599435329437256
Validation loss: 3.0249157746632895

Epoch: 6| Step: 10
Training loss: 2.783270835876465
Validation loss: 3.024439493815104

Epoch: 6| Step: 11
Training loss: 3.3709166049957275
Validation loss: 3.022068738937378

Epoch: 6| Step: 12
Training loss: 3.118741035461426
Validation loss: 3.0206912755966187

Epoch: 6| Step: 13
Training loss: 3.361494541168213
Validation loss: 3.016088366508484

Epoch: 35| Step: 0
Training loss: 3.5669310092926025
Validation loss: 3.011279344558716

Epoch: 6| Step: 1
Training loss: 2.778120517730713
Validation loss: 3.007170796394348

Epoch: 6| Step: 2
Training loss: 3.2032008171081543
Validation loss: 3.001956820487976

Epoch: 6| Step: 3
Training loss: 2.297713279724121
Validation loss: 2.9970097144444785

Epoch: 6| Step: 4
Training loss: 2.643965721130371
Validation loss: 2.9937971433003745

Epoch: 6| Step: 5
Training loss: 2.458583354949951
Validation loss: 2.9907756249109902

Epoch: 6| Step: 6
Training loss: 3.4016175270080566
Validation loss: 2.9878045519193015

Epoch: 6| Step: 7
Training loss: 3.383131980895996
Validation loss: 2.9830352067947388

Epoch: 6| Step: 8
Training loss: 3.612072706222534
Validation loss: 2.9800426165262857

Epoch: 6| Step: 9
Training loss: 3.7000584602355957
Validation loss: 2.976539214452108

Epoch: 6| Step: 10
Training loss: 3.393186330795288
Validation loss: 2.9724457263946533

Epoch: 6| Step: 11
Training loss: 2.7551016807556152
Validation loss: 2.9686231215794883

Epoch: 6| Step: 12
Training loss: 4.242246627807617
Validation loss: 2.964383920033773

Epoch: 6| Step: 13
Training loss: 3.0775468349456787
Validation loss: 2.961408019065857

Epoch: 36| Step: 0
Training loss: 2.6460680961608887
Validation loss: 2.957432230313619

Epoch: 6| Step: 1
Training loss: 2.942091226577759
Validation loss: 2.9539628426233926

Epoch: 6| Step: 2
Training loss: 2.893813133239746
Validation loss: 2.9503386815389

Epoch: 6| Step: 3
Training loss: 3.7146401405334473
Validation loss: 2.9463492234547934

Epoch: 6| Step: 4
Training loss: 2.9697556495666504
Validation loss: 2.943207542101542

Epoch: 6| Step: 5
Training loss: 3.7370400428771973
Validation loss: 2.9402449131011963

Epoch: 6| Step: 6
Training loss: 3.815427780151367
Validation loss: 2.935186743736267

Epoch: 6| Step: 7
Training loss: 3.245840549468994
Validation loss: 2.9313546419143677

Epoch: 6| Step: 8
Training loss: 2.9494340419769287
Validation loss: 2.928731362024943

Epoch: 6| Step: 9
Training loss: 2.868898868560791
Validation loss: 2.9259770711263022

Epoch: 6| Step: 10
Training loss: 3.2893011569976807
Validation loss: 2.922166426976522

Epoch: 6| Step: 11
Training loss: 3.009669303894043
Validation loss: 2.918696324030558

Epoch: 6| Step: 12
Training loss: 3.1055514812469482
Validation loss: 2.9156548182169595

Epoch: 6| Step: 13
Training loss: 2.6838390827178955
Validation loss: 2.9151108463605246

Epoch: 37| Step: 0
Training loss: 2.7162415981292725
Validation loss: 2.9163925647735596

Epoch: 6| Step: 1
Training loss: 3.026728868484497
Validation loss: 2.906754453976949

Epoch: 6| Step: 2
Training loss: 2.363471746444702
Validation loss: 2.9000314474105835

Epoch: 6| Step: 3
Training loss: 3.5250349044799805
Validation loss: 2.895787537097931

Epoch: 6| Step: 4
Training loss: 2.6536436080932617
Validation loss: 2.8931442499160767

Epoch: 6| Step: 5
Training loss: 2.9018783569335938
Validation loss: 2.8901292085647583

Epoch: 6| Step: 6
Training loss: 3.3737759590148926
Validation loss: 2.8864867289861045

Epoch: 6| Step: 7
Training loss: 3.250972032546997
Validation loss: 2.883243223031362

Epoch: 6| Step: 8
Training loss: 3.1036534309387207
Validation loss: 2.879729469617208

Epoch: 6| Step: 9
Training loss: 3.824941396713257
Validation loss: 2.876344323158264

Epoch: 6| Step: 10
Training loss: 3.192868709564209
Validation loss: 2.8737565676371255

Epoch: 6| Step: 11
Training loss: 3.6526026725769043
Validation loss: 2.869665582974752

Epoch: 6| Step: 12
Training loss: 2.8067831993103027
Validation loss: 2.865882953008016

Epoch: 6| Step: 13
Training loss: 2.856924295425415
Validation loss: 2.8617414633433023

Epoch: 38| Step: 0
Training loss: 2.3183369636535645
Validation loss: 2.8589210907618203

Epoch: 6| Step: 1
Training loss: 2.848822832107544
Validation loss: 2.8561748266220093

Epoch: 6| Step: 2
Training loss: 2.875291347503662
Validation loss: 2.851808468500773

Epoch: 6| Step: 3
Training loss: 3.054246425628662
Validation loss: 2.848761240641276

Epoch: 6| Step: 4
Training loss: 3.831484317779541
Validation loss: 2.84670090675354

Epoch: 6| Step: 5
Training loss: 3.428839683532715
Validation loss: 2.842853546142578

Epoch: 6| Step: 6
Training loss: 3.1545751094818115
Validation loss: 2.8397559324900308

Epoch: 6| Step: 7
Training loss: 3.353686809539795
Validation loss: 2.836665391921997

Epoch: 6| Step: 8
Training loss: 3.4064383506774902
Validation loss: 2.835329453150431

Epoch: 6| Step: 9
Training loss: 3.239596366882324
Validation loss: 2.8330813447634378

Epoch: 6| Step: 10
Training loss: 2.5426597595214844
Validation loss: 2.828391671180725

Epoch: 6| Step: 11
Training loss: 2.71427321434021
Validation loss: 2.826566974322001

Epoch: 6| Step: 12
Training loss: 2.715005397796631
Validation loss: 2.8209315141042075

Epoch: 6| Step: 13
Training loss: 3.1700854301452637
Validation loss: 2.817139824231466

Epoch: 39| Step: 0
Training loss: 3.1996965408325195
Validation loss: 2.8140029112497964

Epoch: 6| Step: 1
Training loss: 2.50393009185791
Validation loss: 2.811434268951416

Epoch: 6| Step: 2
Training loss: 3.7762298583984375
Validation loss: 2.808151443799337

Epoch: 6| Step: 3
Training loss: 2.666391134262085
Validation loss: 2.8040096759796143

Epoch: 6| Step: 4
Training loss: 2.5253472328186035
Validation loss: 2.8004069328308105

Epoch: 6| Step: 5
Training loss: 2.5556697845458984
Validation loss: 2.7982969681421914

Epoch: 6| Step: 6
Training loss: 3.182723045349121
Validation loss: 2.7949508825937905

Epoch: 6| Step: 7
Training loss: 3.4186060428619385
Validation loss: 2.7917822202046714

Epoch: 6| Step: 8
Training loss: 3.761496067047119
Validation loss: 2.7904239098230996

Epoch: 6| Step: 9
Training loss: 3.325984239578247
Validation loss: 2.7862113316853843

Epoch: 6| Step: 10
Training loss: 2.805558681488037
Validation loss: 2.785425146420797

Epoch: 6| Step: 11
Training loss: 2.2737598419189453
Validation loss: 2.780692219734192

Epoch: 6| Step: 12
Training loss: 2.9313621520996094
Validation loss: 2.785780588785807

Epoch: 6| Step: 13
Training loss: 3.143237590789795
Validation loss: 2.7767520745595298

Epoch: 40| Step: 0
Training loss: 2.592339515686035
Validation loss: 2.7716246048609414

Epoch: 6| Step: 1
Training loss: 2.7996256351470947
Validation loss: 2.7684231201807656

Epoch: 6| Step: 2
Training loss: 3.2442333698272705
Validation loss: 2.7650074561436973

Epoch: 6| Step: 3
Training loss: 2.707540988922119
Validation loss: 2.763316591580709

Epoch: 6| Step: 4
Training loss: 3.845684766769409
Validation loss: 2.7599351008733115

Epoch: 6| Step: 5
Training loss: 3.3964788913726807
Validation loss: 2.7581382592519126

Epoch: 6| Step: 6
Training loss: 3.3565683364868164
Validation loss: 2.7564514875411987

Epoch: 6| Step: 7
Training loss: 2.6749794483184814
Validation loss: 2.7544522682825723

Epoch: 6| Step: 8
Training loss: 2.4777064323425293
Validation loss: 2.751477758089701

Epoch: 6| Step: 9
Training loss: 2.810190439224243
Validation loss: 2.7501611709594727

Epoch: 6| Step: 10
Training loss: 2.7657432556152344
Validation loss: 2.747323671976725

Epoch: 6| Step: 11
Training loss: 3.3403687477111816
Validation loss: 2.745128591855367

Epoch: 6| Step: 12
Training loss: 2.140038251876831
Validation loss: 2.740630110104879

Epoch: 6| Step: 13
Training loss: 3.348381519317627
Validation loss: 2.737318833669027

Epoch: 41| Step: 0
Training loss: 2.9749536514282227
Validation loss: 2.733296354611715

Epoch: 6| Step: 1
Training loss: 2.154543876647949
Validation loss: 2.7304535706837973

Epoch: 6| Step: 2
Training loss: 2.7072253227233887
Validation loss: 2.726555506388346

Epoch: 6| Step: 3
Training loss: 2.8742384910583496
Validation loss: 2.7238770723342896

Epoch: 6| Step: 4
Training loss: 3.486915111541748
Validation loss: 2.7208423614501953

Epoch: 6| Step: 5
Training loss: 3.15788197517395
Validation loss: 2.7178024848302207

Epoch: 6| Step: 6
Training loss: 2.4649033546447754
Validation loss: 2.7148584922154746

Epoch: 6| Step: 7
Training loss: 2.469921112060547
Validation loss: 2.7121590773264566

Epoch: 6| Step: 8
Training loss: 3.4011080265045166
Validation loss: 2.7086567481358848

Epoch: 6| Step: 9
Training loss: 3.3307788372039795
Validation loss: 2.7057503859202066

Epoch: 6| Step: 10
Training loss: 3.3438644409179688
Validation loss: 2.701911687850952

Epoch: 6| Step: 11
Training loss: 2.99929141998291
Validation loss: 2.6997635761896768

Epoch: 6| Step: 12
Training loss: 2.544623374938965
Validation loss: 2.6967833240826926

Epoch: 6| Step: 13
Training loss: 2.9798929691314697
Validation loss: 2.694400151570638

Epoch: 42| Step: 0
Training loss: 2.594127655029297
Validation loss: 2.690228263537089

Epoch: 6| Step: 1
Training loss: 2.845411777496338
Validation loss: 2.686170478661855

Epoch: 6| Step: 2
Training loss: 2.218097686767578
Validation loss: 2.6842886209487915

Epoch: 6| Step: 3
Training loss: 3.2027740478515625
Validation loss: 2.6809579531351724

Epoch: 6| Step: 4
Training loss: 3.023775100708008
Validation loss: 2.6800752878189087

Epoch: 6| Step: 5
Training loss: 2.580671787261963
Validation loss: 2.6761627991994223

Epoch: 6| Step: 6
Training loss: 3.214750051498413
Validation loss: 2.671854833761851

Epoch: 6| Step: 7
Training loss: 2.799898147583008
Validation loss: 2.669655998547872

Epoch: 6| Step: 8
Training loss: 3.1814844608306885
Validation loss: 2.6657447814941406

Epoch: 6| Step: 9
Training loss: 2.3552234172821045
Validation loss: 2.6632014910380044

Epoch: 6| Step: 10
Training loss: 3.593327760696411
Validation loss: 2.657585342725118

Epoch: 6| Step: 11
Training loss: 2.621575117111206
Validation loss: 2.6563685735066733

Epoch: 6| Step: 12
Training loss: 3.0136454105377197
Validation loss: 2.6546557346979776

Epoch: 6| Step: 13
Training loss: 3.0361311435699463
Validation loss: 2.6541848182678223

Epoch: 43| Step: 0
Training loss: 3.025669574737549
Validation loss: 2.648185749848684

Epoch: 6| Step: 1
Training loss: 3.2786612510681152
Validation loss: 2.644180874029795

Epoch: 6| Step: 2
Training loss: 2.5314393043518066
Validation loss: 2.6426265239715576

Epoch: 6| Step: 3
Training loss: 2.81048583984375
Validation loss: 2.6398739417394004

Epoch: 6| Step: 4
Training loss: 2.7321410179138184
Validation loss: 2.6362427870432534

Epoch: 6| Step: 5
Training loss: 2.8699731826782227
Validation loss: 2.636510729789734

Epoch: 6| Step: 6
Training loss: 2.538839340209961
Validation loss: 2.6335731744766235

Epoch: 6| Step: 7
Training loss: 3.793768882751465
Validation loss: 2.6305285692214966

Epoch: 6| Step: 8
Training loss: 2.8688507080078125
Validation loss: 2.6290361881256104

Epoch: 6| Step: 9
Training loss: 3.0078322887420654
Validation loss: 2.6250418027242026

Epoch: 6| Step: 10
Training loss: 2.671900510787964
Validation loss: 2.6221675078074136

Epoch: 6| Step: 11
Training loss: 3.109105348587036
Validation loss: 2.6207003196080527

Epoch: 6| Step: 12
Training loss: 2.40866756439209
Validation loss: 2.6172014474868774

Epoch: 6| Step: 13
Training loss: 2.055478572845459
Validation loss: 2.612538913885752

Epoch: 44| Step: 0
Training loss: 3.026254177093506
Validation loss: 2.6095737417538962

Epoch: 6| Step: 1
Training loss: 1.9888768196105957
Validation loss: 2.6073045134544373

Epoch: 6| Step: 2
Training loss: 2.634133815765381
Validation loss: 2.6039788524309793

Epoch: 6| Step: 3
Training loss: 3.5251853466033936
Validation loss: 2.60036967198054

Epoch: 6| Step: 4
Training loss: 2.042619466781616
Validation loss: 2.5984434684117637

Epoch: 6| Step: 5
Training loss: 4.003701210021973
Validation loss: 2.5948765675226846

Epoch: 6| Step: 6
Training loss: 2.6271464824676514
Validation loss: 2.591092268625895

Epoch: 6| Step: 7
Training loss: 2.4339706897735596
Validation loss: 2.588358441988627

Epoch: 6| Step: 8
Training loss: 3.0203425884246826
Validation loss: 2.5849937995274863

Epoch: 6| Step: 9
Training loss: 3.1585750579833984
Validation loss: 2.5820858081181846

Epoch: 6| Step: 10
Training loss: 2.492753028869629
Validation loss: 2.580949902534485

Epoch: 6| Step: 11
Training loss: 2.430166244506836
Validation loss: 2.5757030248641968

Epoch: 6| Step: 12
Training loss: 3.0914764404296875
Validation loss: 2.57246603568395

Epoch: 6| Step: 13
Training loss: 2.634202241897583
Validation loss: 2.5704742670059204

Epoch: 45| Step: 0
Training loss: 2.8532211780548096
Validation loss: 2.5648484230041504

Epoch: 6| Step: 1
Training loss: 2.038011074066162
Validation loss: 2.562440276145935

Epoch: 6| Step: 2
Training loss: 3.0760908126831055
Validation loss: 2.561660647392273

Epoch: 6| Step: 3
Training loss: 2.641068696975708
Validation loss: 2.560422420501709

Epoch: 6| Step: 4
Training loss: 2.528782367706299
Validation loss: 2.5583077669143677

Epoch: 6| Step: 5
Training loss: 3.0779612064361572
Validation loss: 2.5558727979660034

Epoch: 6| Step: 6
Training loss: 2.641521692276001
Validation loss: 2.5539493958155313

Epoch: 6| Step: 7
Training loss: 2.827129364013672
Validation loss: 2.5523438453674316

Epoch: 6| Step: 8
Training loss: 2.4670305252075195
Validation loss: 2.5501951376597085

Epoch: 6| Step: 9
Training loss: 3.522894859313965
Validation loss: 2.5457750956217446

Epoch: 6| Step: 10
Training loss: 2.5394768714904785
Validation loss: 2.5437750021616616

Epoch: 6| Step: 11
Training loss: 1.8173084259033203
Validation loss: 2.5416897535324097

Epoch: 6| Step: 12
Training loss: 3.3450798988342285
Validation loss: 2.539467175801595

Epoch: 6| Step: 13
Training loss: 3.180142402648926
Validation loss: 2.536969304084778

Epoch: 46| Step: 0
Training loss: 3.0523154735565186
Validation loss: 2.5333996216456094

Epoch: 6| Step: 1
Training loss: 2.604848623275757
Validation loss: 2.5314775307973227

Epoch: 6| Step: 2
Training loss: 3.1402153968811035
Validation loss: 2.5289804538091025

Epoch: 6| Step: 3
Training loss: 2.8379764556884766
Validation loss: 2.5265182654062905

Epoch: 6| Step: 4
Training loss: 2.9897379875183105
Validation loss: 2.524087150891622

Epoch: 6| Step: 5
Training loss: 2.0672645568847656
Validation loss: 2.5212620894114175

Epoch: 6| Step: 6
Training loss: 3.1645874977111816
Validation loss: 2.518824577331543

Epoch: 6| Step: 7
Training loss: 2.567939281463623
Validation loss: 2.5163639783859253

Epoch: 6| Step: 8
Training loss: 2.8325839042663574
Validation loss: 2.5127742489178977

Epoch: 6| Step: 9
Training loss: 2.860877275466919
Validation loss: 2.5079245964686074

Epoch: 6| Step: 10
Training loss: 2.4476919174194336
Validation loss: 2.5062522490819297

Epoch: 6| Step: 11
Training loss: 2.201550006866455
Validation loss: 2.5049057006835938

Epoch: 6| Step: 12
Training loss: 2.615262508392334
Validation loss: 2.5029839078585305

Epoch: 6| Step: 13
Training loss: 2.6059155464172363
Validation loss: 2.498562971750895

Epoch: 47| Step: 0
Training loss: 2.7362186908721924
Validation loss: 2.4953008691469827

Epoch: 6| Step: 1
Training loss: 3.132661819458008
Validation loss: 2.494809905687968

Epoch: 6| Step: 2
Training loss: 2.455066680908203
Validation loss: 2.4938774506251016

Epoch: 6| Step: 3
Training loss: 2.7523956298828125
Validation loss: 2.48787252108256

Epoch: 6| Step: 4
Training loss: 2.9264678955078125
Validation loss: 2.4848559896151223

Epoch: 6| Step: 5
Training loss: 2.3843817710876465
Validation loss: 2.4824607372283936

Epoch: 6| Step: 6
Training loss: 2.530625104904175
Validation loss: 2.481414516766866

Epoch: 6| Step: 7
Training loss: 3.3870460987091064
Validation loss: 2.4809410572052

Epoch: 6| Step: 8
Training loss: 2.8587403297424316
Validation loss: 2.477512081464132

Epoch: 6| Step: 9
Training loss: 2.5646920204162598
Validation loss: 2.4773396253585815

Epoch: 6| Step: 10
Training loss: 2.4243063926696777
Validation loss: 2.4715497692426047

Epoch: 6| Step: 11
Training loss: 2.557487964630127
Validation loss: 2.465491692225138

Epoch: 6| Step: 12
Training loss: 2.7167325019836426
Validation loss: 2.4675594369570413

Epoch: 6| Step: 13
Training loss: 2.03865122795105
Validation loss: 2.4981353282928467

Epoch: 48| Step: 0
Training loss: 2.976262331008911
Validation loss: 2.4937037229537964

Epoch: 6| Step: 1
Training loss: 2.585470199584961
Validation loss: 2.490736722946167

Epoch: 6| Step: 2
Training loss: 2.3884921073913574
Validation loss: 2.4662108421325684

Epoch: 6| Step: 3
Training loss: 2.52154278755188
Validation loss: 2.4533301989237466

Epoch: 6| Step: 4
Training loss: 2.3838977813720703
Validation loss: 2.4491087396939597

Epoch: 6| Step: 5
Training loss: 2.7713871002197266
Validation loss: 2.4488025506337485

Epoch: 6| Step: 6
Training loss: 3.2066431045532227
Validation loss: 2.449048399925232

Epoch: 6| Step: 7
Training loss: 2.7841639518737793
Validation loss: 2.4494084318478904

Epoch: 6| Step: 8
Training loss: 2.5449206829071045
Validation loss: 2.453059116999308

Epoch: 6| Step: 9
Training loss: 2.210832118988037
Validation loss: 2.4569749236106873

Epoch: 6| Step: 10
Training loss: 2.63474702835083
Validation loss: 2.447552045186361

Epoch: 6| Step: 11
Training loss: 2.3775155544281006
Validation loss: 2.4461099108060202

Epoch: 6| Step: 12
Training loss: 2.4879965782165527
Validation loss: 2.4495736757914224

Epoch: 6| Step: 13
Training loss: 3.1920700073242188
Validation loss: 2.4499143759409585

Epoch: 49| Step: 0
Training loss: 2.572385787963867
Validation loss: 2.4381112853686013

Epoch: 6| Step: 1
Training loss: 2.198683500289917
Validation loss: 2.4337539672851562

Epoch: 6| Step: 2
Training loss: 2.9388484954833984
Validation loss: 2.4321573774019876

Epoch: 6| Step: 3
Training loss: 2.402052402496338
Validation loss: 2.429167111714681

Epoch: 6| Step: 4
Training loss: 2.8265042304992676
Validation loss: 2.4245231548945108

Epoch: 6| Step: 5
Training loss: 2.854602098464966
Validation loss: 2.4225411415100098

Epoch: 6| Step: 6
Training loss: 2.7590620517730713
Validation loss: 2.4195611079533896

Epoch: 6| Step: 7
Training loss: 2.347228527069092
Validation loss: 2.4154947797457376

Epoch: 6| Step: 8
Training loss: 2.565983295440674
Validation loss: 2.4132199883461

Epoch: 6| Step: 9
Training loss: 2.8041367530822754
Validation loss: 2.4126681089401245

Epoch: 6| Step: 10
Training loss: 3.3206465244293213
Validation loss: 2.4081053733825684

Epoch: 6| Step: 11
Training loss: 2.4098024368286133
Validation loss: 2.406243403752645

Epoch: 6| Step: 12
Training loss: 2.355459690093994
Validation loss: 2.401896278063456

Epoch: 6| Step: 13
Training loss: 2.087421417236328
Validation loss: 2.3998483618100486

Epoch: 50| Step: 0
Training loss: 2.9183216094970703
Validation loss: 2.3976765473683677

Epoch: 6| Step: 1
Training loss: 2.6177892684936523
Validation loss: 2.3939021627108255

Epoch: 6| Step: 2
Training loss: 3.015742778778076
Validation loss: 2.3925419648488364

Epoch: 6| Step: 3
Training loss: 2.4796581268310547
Validation loss: 2.3865942557652793

Epoch: 6| Step: 4
Training loss: 2.894932270050049
Validation loss: 2.388895869255066

Epoch: 6| Step: 5
Training loss: 2.8092074394226074
Validation loss: 2.3862704833348594

Epoch: 6| Step: 6
Training loss: 2.4333667755126953
Validation loss: 2.381603797276815

Epoch: 6| Step: 7
Training loss: 2.3333613872528076
Validation loss: 2.3807676235834756

Epoch: 6| Step: 8
Training loss: 1.8918744325637817
Validation loss: 2.3777344624201455

Epoch: 6| Step: 9
Training loss: 2.6138994693756104
Validation loss: 2.3794108430544534

Epoch: 6| Step: 10
Training loss: 1.9587465524673462
Validation loss: 2.3700788021087646

Epoch: 6| Step: 11
Training loss: 2.523205280303955
Validation loss: 2.3657108147939048

Epoch: 6| Step: 12
Training loss: 2.9741933345794678
Validation loss: 2.3649579683939614

Epoch: 6| Step: 13
Training loss: 2.4364471435546875
Validation loss: 2.3627479871114097

Epoch: 51| Step: 0
Training loss: 2.2394461631774902
Validation loss: 2.362383246421814

Epoch: 6| Step: 1
Training loss: 2.726438045501709
Validation loss: 2.373184939225515

Epoch: 6| Step: 2
Training loss: 2.941084384918213
Validation loss: 2.3929171562194824

Epoch: 6| Step: 3
Training loss: 2.5638060569763184
Validation loss: 2.378739873568217

Epoch: 6| Step: 4
Training loss: 3.2464420795440674
Validation loss: 2.35187296072642

Epoch: 6| Step: 5
Training loss: 2.821967363357544
Validation loss: 2.3506593704223633

Epoch: 6| Step: 6
Training loss: 2.94216251373291
Validation loss: 2.3547587394714355

Epoch: 6| Step: 7
Training loss: 1.6127452850341797
Validation loss: 2.3594191471735635

Epoch: 6| Step: 8
Training loss: 2.4014077186584473
Validation loss: 2.3712013562520347

Epoch: 6| Step: 9
Training loss: 2.460822105407715
Validation loss: 2.38137153784434

Epoch: 6| Step: 10
Training loss: 2.247380018234253
Validation loss: 2.3848954836527505

Epoch: 6| Step: 11
Training loss: 2.5574231147766113
Validation loss: 2.379069526990255

Epoch: 6| Step: 12
Training loss: 2.6008427143096924
Validation loss: 2.3739200631777444

Epoch: 6| Step: 13
Training loss: 2.4351234436035156
Validation loss: 2.3743156592051187

Epoch: 52| Step: 0
Training loss: 2.2465312480926514
Validation loss: 2.363528529802958

Epoch: 6| Step: 1
Training loss: 3.3565993309020996
Validation loss: 2.363176941871643

Epoch: 6| Step: 2
Training loss: 2.1142642498016357
Validation loss: 2.3516579071680703

Epoch: 6| Step: 3
Training loss: 2.680372953414917
Validation loss: 2.346232990423838

Epoch: 6| Step: 4
Training loss: 1.9730638265609741
Validation loss: 2.340439518292745

Epoch: 6| Step: 5
Training loss: 2.349498748779297
Validation loss: 2.338711977005005

Epoch: 6| Step: 6
Training loss: 3.0310473442077637
Validation loss: 2.3332290649414062

Epoch: 6| Step: 7
Training loss: 2.360936164855957
Validation loss: 2.335429549217224

Epoch: 6| Step: 8
Training loss: 2.2666900157928467
Validation loss: 2.3293529748916626

Epoch: 6| Step: 9
Training loss: 2.7085185050964355
Validation loss: 2.3267077604929605

Epoch: 6| Step: 10
Training loss: 2.18841552734375
Validation loss: 2.324103275934855

Epoch: 6| Step: 11
Training loss: 2.6023709774017334
Validation loss: 2.321124037106832

Epoch: 6| Step: 12
Training loss: 2.4490933418273926
Validation loss: 2.318329632282257

Epoch: 6| Step: 13
Training loss: 2.7484183311462402
Validation loss: 2.315051237742106

Epoch: 53| Step: 0
Training loss: 2.337973117828369
Validation loss: 2.308984875679016

Epoch: 6| Step: 1
Training loss: 2.019031524658203
Validation loss: 2.305342435836792

Epoch: 6| Step: 2
Training loss: 2.6407039165496826
Validation loss: 2.3019783894220986

Epoch: 6| Step: 3
Training loss: 2.2449564933776855
Validation loss: 2.302570939064026

Epoch: 6| Step: 4
Training loss: 3.550532341003418
Validation loss: 2.299783945083618

Epoch: 6| Step: 5
Training loss: 2.5041725635528564
Validation loss: 2.296952486038208

Epoch: 6| Step: 6
Training loss: 2.1750612258911133
Validation loss: 2.2998085220654807

Epoch: 6| Step: 7
Training loss: 2.0886967182159424
Validation loss: 2.2945899168650308

Epoch: 6| Step: 8
Training loss: 2.581545829772949
Validation loss: 2.295663913091024

Epoch: 6| Step: 9
Training loss: 2.2943248748779297
Validation loss: 2.2921311457951865

Epoch: 6| Step: 10
Training loss: 2.274386167526245
Validation loss: 2.2914539178212485

Epoch: 6| Step: 11
Training loss: 2.400045871734619
Validation loss: 2.2913665771484375

Epoch: 6| Step: 12
Training loss: 3.2191832065582275
Validation loss: 2.285565356413523

Epoch: 6| Step: 13
Training loss: 2.229571580886841
Validation loss: 2.2869608998298645

Epoch: 54| Step: 0
Training loss: 2.3049333095550537
Validation loss: 2.2819456656773887

Epoch: 6| Step: 1
Training loss: 2.5459184646606445
Validation loss: 2.2720803022384644

Epoch: 6| Step: 2
Training loss: 2.181476593017578
Validation loss: 2.268553892771403

Epoch: 6| Step: 3
Training loss: 2.147825241088867
Validation loss: 2.269144852956136

Epoch: 6| Step: 4
Training loss: 2.9774367809295654
Validation loss: 2.266818106174469

Epoch: 6| Step: 5
Training loss: 2.0620431900024414
Validation loss: 2.261754333972931

Epoch: 6| Step: 6
Training loss: 2.4193971157073975
Validation loss: 2.26431796948115

Epoch: 6| Step: 7
Training loss: 2.5775089263916016
Validation loss: 2.264445940653483

Epoch: 6| Step: 8
Training loss: 2.059823751449585
Validation loss: 2.25984921058019

Epoch: 6| Step: 9
Training loss: 2.50551176071167
Validation loss: 2.254770835240682

Epoch: 6| Step: 10
Training loss: 2.5681095123291016
Validation loss: 2.2515297333399453

Epoch: 6| Step: 11
Training loss: 2.4782469272613525
Validation loss: 2.252070585886637

Epoch: 6| Step: 12
Training loss: 2.459026575088501
Validation loss: 2.2472594380378723

Epoch: 6| Step: 13
Training loss: 2.729907274246216
Validation loss: 2.247120181719462

Epoch: 55| Step: 0
Training loss: 2.785648822784424
Validation loss: 2.2384953697522483

Epoch: 6| Step: 1
Training loss: 3.101259708404541
Validation loss: 2.2442610462506614

Epoch: 6| Step: 2
Training loss: 2.2246782779693604
Validation loss: 2.2419251600901284

Epoch: 6| Step: 3
Training loss: 2.4537739753723145
Validation loss: 2.240450859069824

Epoch: 6| Step: 4
Training loss: 1.5793384313583374
Validation loss: 2.2426602443059287

Epoch: 6| Step: 5
Training loss: 2.870225667953491
Validation loss: 2.242448707421621

Epoch: 6| Step: 6
Training loss: 2.193053722381592
Validation loss: 2.2363977829615274

Epoch: 6| Step: 7
Training loss: 2.2335963249206543
Validation loss: 2.2346354126930237

Epoch: 6| Step: 8
Training loss: 2.044206142425537
Validation loss: 2.232251505057017

Epoch: 6| Step: 9
Training loss: 2.6815948486328125
Validation loss: 2.234064757823944

Epoch: 6| Step: 10
Training loss: 1.9206271171569824
Validation loss: 2.2338534593582153

Epoch: 6| Step: 11
Training loss: 2.8186821937561035
Validation loss: 2.2294267217318215

Epoch: 6| Step: 12
Training loss: 1.8383173942565918
Validation loss: 2.2295921643575034

Epoch: 6| Step: 13
Training loss: 2.8935747146606445
Validation loss: 2.2268834511439004

Epoch: 56| Step: 0
Training loss: 2.524678945541382
Validation loss: 2.221051494280497

Epoch: 6| Step: 1
Training loss: 2.143028497695923
Validation loss: 2.2218921383221946

Epoch: 6| Step: 2
Training loss: 2.1866211891174316
Validation loss: 2.213786462942759

Epoch: 6| Step: 3
Training loss: 2.13051700592041
Validation loss: 2.2162545323371887

Epoch: 6| Step: 4
Training loss: 2.6237335205078125
Validation loss: 2.211248298486074

Epoch: 6| Step: 5
Training loss: 2.5350570678710938
Validation loss: 2.211624344189962

Epoch: 6| Step: 6
Training loss: 2.030877113342285
Validation loss: 2.2073848644892373

Epoch: 6| Step: 7
Training loss: 2.428863048553467
Validation loss: 2.202624758084615

Epoch: 6| Step: 8
Training loss: 2.254343032836914
Validation loss: 2.206468105316162

Epoch: 6| Step: 9
Training loss: 2.467423439025879
Validation loss: 2.2055532336235046

Epoch: 6| Step: 10
Training loss: 2.4412074089050293
Validation loss: 2.2006336053212485

Epoch: 6| Step: 11
Training loss: 1.879347801208496
Validation loss: 2.204973022143046

Epoch: 6| Step: 12
Training loss: 2.874019145965576
Validation loss: 2.2041340271631875

Epoch: 6| Step: 13
Training loss: 2.712029218673706
Validation loss: 2.202665646870931

Epoch: 57| Step: 0
Training loss: 1.3915808200836182
Validation loss: 2.2004360357920327

Epoch: 6| Step: 1
Training loss: 2.714567184448242
Validation loss: 2.1988644003868103

Epoch: 6| Step: 2
Training loss: 1.9067693948745728
Validation loss: 2.2001407146453857

Epoch: 6| Step: 3
Training loss: 2.1306936740875244
Validation loss: 2.196787436803182

Epoch: 6| Step: 4
Training loss: 3.3433938026428223
Validation loss: 2.1990752617518106

Epoch: 6| Step: 5
Training loss: 2.2345314025878906
Validation loss: 2.197274327278137

Epoch: 6| Step: 6
Training loss: 2.683417558670044
Validation loss: 2.1901338497797647

Epoch: 6| Step: 7
Training loss: 2.5246567726135254
Validation loss: 2.194484810034434

Epoch: 6| Step: 8
Training loss: 2.236978769302368
Validation loss: 2.193967600663503

Epoch: 6| Step: 9
Training loss: 2.2179479598999023
Validation loss: 2.188031872113546

Epoch: 6| Step: 10
Training loss: 2.045701026916504
Validation loss: 2.1864904165267944

Epoch: 6| Step: 11
Training loss: 2.468111991882324
Validation loss: 2.18584136168162

Epoch: 6| Step: 12
Training loss: 2.272390365600586
Validation loss: 2.190021197001139

Epoch: 6| Step: 13
Training loss: 2.7873358726501465
Validation loss: 2.1798957784970603

Epoch: 58| Step: 0
Training loss: 2.2374372482299805
Validation loss: 2.1829034884770713

Epoch: 6| Step: 1
Training loss: 1.568772554397583
Validation loss: 2.1773127714792886

Epoch: 6| Step: 2
Training loss: 2.8616838455200195
Validation loss: 2.1759119431177774

Epoch: 6| Step: 3
Training loss: 1.9204317331314087
Validation loss: 2.181158701578776

Epoch: 6| Step: 4
Training loss: 1.3449721336364746
Validation loss: 2.1823719342549643

Epoch: 6| Step: 5
Training loss: 2.6756200790405273
Validation loss: 2.1840396920839944

Epoch: 6| Step: 6
Training loss: 2.622392177581787
Validation loss: 2.174840490023295

Epoch: 6| Step: 7
Training loss: 2.5236525535583496
Validation loss: 2.171152194341024

Epoch: 6| Step: 8
Training loss: 1.9263575077056885
Validation loss: 2.172623852888743

Epoch: 6| Step: 9
Training loss: 2.6131155490875244
Validation loss: 2.171393076578776

Epoch: 6| Step: 10
Training loss: 2.2378299236297607
Validation loss: 2.15836364030838

Epoch: 6| Step: 11
Training loss: 2.442340850830078
Validation loss: 2.161739389101664

Epoch: 6| Step: 12
Training loss: 3.1752986907958984
Validation loss: 2.1706979672114053

Epoch: 6| Step: 13
Training loss: 2.7047460079193115
Validation loss: 2.1677900552749634

Epoch: 59| Step: 0
Training loss: 2.717197895050049
Validation loss: 2.1708730657895408

Epoch: 6| Step: 1
Training loss: 1.500060796737671
Validation loss: 2.170033574104309

Epoch: 6| Step: 2
Training loss: 2.4399070739746094
Validation loss: 2.1736876169840493

Epoch: 6| Step: 3
Training loss: 2.4522042274475098
Validation loss: 2.170994818210602

Epoch: 6| Step: 4
Training loss: 1.466174840927124
Validation loss: 2.1677764455477395

Epoch: 6| Step: 5
Training loss: 1.952117681503296
Validation loss: 2.168607215086619

Epoch: 6| Step: 6
Training loss: 2.436570405960083
Validation loss: 2.168915112813314

Epoch: 6| Step: 7
Training loss: 2.2286179065704346
Validation loss: 2.166510045528412

Epoch: 6| Step: 8
Training loss: 2.5046677589416504
Validation loss: 2.1668384273846946

Epoch: 6| Step: 9
Training loss: 1.994217038154602
Validation loss: 2.164133906364441

Epoch: 6| Step: 10
Training loss: 2.798152446746826
Validation loss: 2.1616178353627524

Epoch: 6| Step: 11
Training loss: 2.598454475402832
Validation loss: 2.163537859916687

Epoch: 6| Step: 12
Training loss: 2.591749668121338
Validation loss: 2.1580764849980674

Epoch: 6| Step: 13
Training loss: 2.9654221534729004
Validation loss: 2.157587766647339

Epoch: 60| Step: 0
Training loss: 2.762540102005005
Validation loss: 2.1601180831591287

Epoch: 6| Step: 1
Training loss: 2.7709834575653076
Validation loss: 2.1585864226023355

Epoch: 6| Step: 2
Training loss: 1.5661249160766602
Validation loss: 2.1609893639882407

Epoch: 6| Step: 3
Training loss: 2.2336578369140625
Validation loss: 2.1585469245910645

Epoch: 6| Step: 4
Training loss: 1.9851080179214478
Validation loss: 2.1578457951545715

Epoch: 6| Step: 5
Training loss: 1.6578693389892578
Validation loss: 2.154613475004832

Epoch: 6| Step: 6
Training loss: 2.1072287559509277
Validation loss: 2.1541651089986167

Epoch: 6| Step: 7
Training loss: 2.1454806327819824
Validation loss: 2.144848585128784

Epoch: 6| Step: 8
Training loss: 2.259934663772583
Validation loss: 2.1405269503593445

Epoch: 6| Step: 9
Training loss: 2.5702130794525146
Validation loss: 2.136425276597341

Epoch: 6| Step: 10
Training loss: 2.1554384231567383
Validation loss: 2.1379566391309104

Epoch: 6| Step: 11
Training loss: 2.6733286380767822
Validation loss: 2.1386444568634033

Epoch: 6| Step: 12
Training loss: 2.941638469696045
Validation loss: 2.1370745102564492

Epoch: 6| Step: 13
Training loss: 2.614182472229004
Validation loss: 2.138371527194977

Epoch: 61| Step: 0
Training loss: 2.7574877738952637
Validation loss: 2.1341439485549927

Epoch: 6| Step: 1
Training loss: 2.686161994934082
Validation loss: 2.1390784780184426

Epoch: 6| Step: 2
Training loss: 2.569892406463623
Validation loss: 2.1394308606783548

Epoch: 6| Step: 3
Training loss: 2.1405811309814453
Validation loss: 2.1379872957865396

Epoch: 6| Step: 4
Training loss: 1.6059536933898926
Validation loss: 2.134977698326111

Epoch: 6| Step: 5
Training loss: 2.2260348796844482
Validation loss: 2.1341414054234824

Epoch: 6| Step: 6
Training loss: 1.3742833137512207
Validation loss: 2.132356286048889

Epoch: 6| Step: 7
Training loss: 2.425285816192627
Validation loss: 2.128854592641195

Epoch: 6| Step: 8
Training loss: 1.9190378189086914
Validation loss: 2.1282063523928323

Epoch: 6| Step: 9
Training loss: 2.6393918991088867
Validation loss: 2.1267818212509155

Epoch: 6| Step: 10
Training loss: 2.226409435272217
Validation loss: 2.1280292669932046

Epoch: 6| Step: 11
Training loss: 1.9265737533569336
Validation loss: 2.1265761057535806

Epoch: 6| Step: 12
Training loss: 3.2426223754882812
Validation loss: 2.1284321546554565

Epoch: 6| Step: 13
Training loss: 2.4337828159332275
Validation loss: 2.1215686202049255

Epoch: 62| Step: 0
Training loss: 2.399146795272827
Validation loss: 2.120666027069092

Epoch: 6| Step: 1
Training loss: 2.5502266883850098
Validation loss: 2.116303543249766

Epoch: 6| Step: 2
Training loss: 2.7450125217437744
Validation loss: 2.117881178855896

Epoch: 6| Step: 3
Training loss: 2.114394187927246
Validation loss: 2.1122698982556662

Epoch: 6| Step: 4
Training loss: 2.549893856048584
Validation loss: 2.1108399033546448

Epoch: 6| Step: 5
Training loss: 2.5202126502990723
Validation loss: 2.1071375409762063

Epoch: 6| Step: 6
Training loss: 2.3400845527648926
Validation loss: 2.1108715335528054

Epoch: 6| Step: 7
Training loss: 1.6347830295562744
Validation loss: 2.1104155580202737

Epoch: 6| Step: 8
Training loss: 2.4739255905151367
Validation loss: 2.108516812324524

Epoch: 6| Step: 9
Training loss: 2.4448087215423584
Validation loss: 2.114490727583567

Epoch: 6| Step: 10
Training loss: 1.9623994827270508
Validation loss: 2.116283675034841

Epoch: 6| Step: 11
Training loss: 1.7068326473236084
Validation loss: 2.114709655443827

Epoch: 6| Step: 12
Training loss: 2.335874319076538
Validation loss: 2.118431786696116

Epoch: 6| Step: 13
Training loss: 2.145921468734741
Validation loss: 2.1150476932525635

Epoch: 63| Step: 0
Training loss: 1.371509075164795
Validation loss: 2.1153849363327026

Epoch: 6| Step: 1
Training loss: 2.775155544281006
Validation loss: 2.1150659918785095

Epoch: 6| Step: 2
Training loss: 2.5999202728271484
Validation loss: 2.117855489253998

Epoch: 6| Step: 3
Training loss: 1.8109838962554932
Validation loss: 2.1147648096084595

Epoch: 6| Step: 4
Training loss: 2.949439525604248
Validation loss: 2.1094851891199746

Epoch: 6| Step: 5
Training loss: 2.2229833602905273
Validation loss: 2.10795921087265

Epoch: 6| Step: 6
Training loss: 2.2218120098114014
Validation loss: 2.0964027444521585

Epoch: 6| Step: 7
Training loss: 2.5261783599853516
Validation loss: 2.094003359476725

Epoch: 6| Step: 8
Training loss: 1.6157982349395752
Validation loss: 2.102428356806437

Epoch: 6| Step: 9
Training loss: 2.645453929901123
Validation loss: 2.1021779576937356

Epoch: 6| Step: 10
Training loss: 2.5768892765045166
Validation loss: 2.1126485069592795

Epoch: 6| Step: 11
Training loss: 1.7422823905944824
Validation loss: 2.124087909857432

Epoch: 6| Step: 12
Training loss: 2.6116783618927
Validation loss: 2.117647091547648

Epoch: 6| Step: 13
Training loss: 2.1293158531188965
Validation loss: 2.1144045988718667

Epoch: 64| Step: 0
Training loss: 2.2043349742889404
Validation loss: 2.09022980928421

Epoch: 6| Step: 1
Training loss: 1.9509296417236328
Validation loss: 2.093749165534973

Epoch: 6| Step: 2
Training loss: 2.125869035720825
Validation loss: 2.0982855757077536

Epoch: 6| Step: 3
Training loss: 2.1564016342163086
Validation loss: 2.0978469451268515

Epoch: 6| Step: 4
Training loss: 2.7987871170043945
Validation loss: 2.0992384354273477

Epoch: 6| Step: 5
Training loss: 2.4871268272399902
Validation loss: 2.0888851284980774

Epoch: 6| Step: 6
Training loss: 2.0098915100097656
Validation loss: 2.0887187918027244

Epoch: 6| Step: 7
Training loss: 2.3677916526794434
Validation loss: 2.086932977040609

Epoch: 6| Step: 8
Training loss: 1.6728579998016357
Validation loss: 2.0849475264549255

Epoch: 6| Step: 9
Training loss: 2.610699415206909
Validation loss: 2.0815146764119468

Epoch: 6| Step: 10
Training loss: 2.3510217666625977
Validation loss: 2.0874945918718972

Epoch: 6| Step: 11
Training loss: 1.9494402408599854
Validation loss: 2.085262437661489

Epoch: 6| Step: 12
Training loss: 2.72914457321167
Validation loss: 2.081276516119639

Epoch: 6| Step: 13
Training loss: 2.214646816253662
Validation loss: 2.084023972352346

Epoch: 65| Step: 0
Training loss: 2.1690101623535156
Validation loss: 2.0816996494928994

Epoch: 6| Step: 1
Training loss: 2.3620705604553223
Validation loss: 2.083551267782847

Epoch: 6| Step: 2
Training loss: 1.696999192237854
Validation loss: 2.0781255960464478

Epoch: 6| Step: 3
Training loss: 2.274223804473877
Validation loss: 2.0758443474769592

Epoch: 6| Step: 4
Training loss: 2.6183090209960938
Validation loss: 2.0731550057729087

Epoch: 6| Step: 5
Training loss: 2.5524754524230957
Validation loss: 2.0718364318211875

Epoch: 6| Step: 6
Training loss: 1.9629541635513306
Validation loss: 2.0826268394788108

Epoch: 6| Step: 7
Training loss: 2.1248297691345215
Validation loss: 2.0814385612805686

Epoch: 6| Step: 8
Training loss: 2.456120491027832
Validation loss: 2.0796338518460593

Epoch: 6| Step: 9
Training loss: 1.8769516944885254
Validation loss: 2.0707602500915527

Epoch: 6| Step: 10
Training loss: 2.6597297191619873
Validation loss: 2.0708434780438743

Epoch: 6| Step: 11
Training loss: 2.0054287910461426
Validation loss: 2.0801926056543985

Epoch: 6| Step: 12
Training loss: 2.522977352142334
Validation loss: 2.073582112789154

Epoch: 6| Step: 13
Training loss: 2.2969770431518555
Validation loss: 2.0722488164901733

Epoch: 66| Step: 0
Training loss: 1.8721206188201904
Validation loss: 2.072219133377075

Epoch: 6| Step: 1
Training loss: 2.84918212890625
Validation loss: 2.0764286120732627

Epoch: 6| Step: 2
Training loss: 2.2427356243133545
Validation loss: 2.072977364063263

Epoch: 6| Step: 3
Training loss: 2.3341760635375977
Validation loss: 2.0827263394991555

Epoch: 6| Step: 4
Training loss: 2.1695051193237305
Validation loss: 2.0846073031425476

Epoch: 6| Step: 5
Training loss: 2.502572774887085
Validation loss: 2.0854299664497375

Epoch: 6| Step: 6
Training loss: 1.9091264009475708
Validation loss: 2.0764545798301697

Epoch: 6| Step: 7
Training loss: 2.1495604515075684
Validation loss: 2.084886888662974

Epoch: 6| Step: 8
Training loss: 2.1159751415252686
Validation loss: 2.0750529766082764

Epoch: 6| Step: 9
Training loss: 2.553131103515625
Validation loss: 2.0745411117871604

Epoch: 6| Step: 10
Training loss: 2.243259906768799
Validation loss: 2.067288041114807

Epoch: 6| Step: 11
Training loss: 2.1093637943267822
Validation loss: 2.0696645776430764

Epoch: 6| Step: 12
Training loss: 2.2776763439178467
Validation loss: 2.0633299152056375

Epoch: 6| Step: 13
Training loss: 2.050410270690918
Validation loss: 2.061209221680959

Epoch: 67| Step: 0
Training loss: 2.578115463256836
Validation loss: 2.066705604394277

Epoch: 6| Step: 1
Training loss: 1.6679723262786865
Validation loss: 2.095066408316294

Epoch: 6| Step: 2
Training loss: 1.7021377086639404
Validation loss: 2.1224623223145804

Epoch: 6| Step: 3
Training loss: 2.4598419666290283
Validation loss: 2.1332859794298806

Epoch: 6| Step: 4
Training loss: 3.355672836303711
Validation loss: 2.1420684258143106

Epoch: 6| Step: 5
Training loss: 2.566584587097168
Validation loss: 2.117471774419149

Epoch: 6| Step: 6
Training loss: 2.4009957313537598
Validation loss: 2.080639580885569

Epoch: 6| Step: 7
Training loss: 1.5335861444473267
Validation loss: 2.068174878756205

Epoch: 6| Step: 8
Training loss: 2.2633461952209473
Validation loss: 2.070608615875244

Epoch: 6| Step: 9
Training loss: 2.596446990966797
Validation loss: 2.063750902811686

Epoch: 6| Step: 10
Training loss: 1.7542617321014404
Validation loss: 2.064745227495829

Epoch: 6| Step: 11
Training loss: 2.220445156097412
Validation loss: 2.0769503116607666

Epoch: 6| Step: 12
Training loss: 2.195162534713745
Validation loss: 2.076988379160563

Epoch: 6| Step: 13
Training loss: 2.6497621536254883
Validation loss: 2.0786982576052346

Epoch: 68| Step: 0
Training loss: 1.93601655960083
Validation loss: 2.079621116320292

Epoch: 6| Step: 1
Training loss: 2.203474521636963
Validation loss: 2.079235096772512

Epoch: 6| Step: 2
Training loss: 2.2225518226623535
Validation loss: 2.0829855600992837

Epoch: 6| Step: 3
Training loss: 2.0901565551757812
Validation loss: 2.0830051501592

Epoch: 6| Step: 4
Training loss: 2.2052369117736816
Validation loss: 2.07651424407959

Epoch: 6| Step: 5
Training loss: 2.2308101654052734
Validation loss: 2.083214441935221

Epoch: 6| Step: 6
Training loss: 2.2290642261505127
Validation loss: 2.0719736218452454

Epoch: 6| Step: 7
Training loss: 2.420229196548462
Validation loss: 2.070010324319204

Epoch: 6| Step: 8
Training loss: 2.9742815494537354
Validation loss: 2.0672772924105325

Epoch: 6| Step: 9
Training loss: 1.7633624076843262
Validation loss: 2.062010725339254

Epoch: 6| Step: 10
Training loss: 1.840475082397461
Validation loss: 2.061478396256765

Epoch: 6| Step: 11
Training loss: 2.2856998443603516
Validation loss: 2.059487005074819

Epoch: 6| Step: 12
Training loss: 2.951138973236084
Validation loss: 2.0604090889294944

Epoch: 6| Step: 13
Training loss: 2.2780845165252686
Validation loss: 2.056321084499359

Epoch: 69| Step: 0
Training loss: 2.4053456783294678
Validation loss: 2.0553455352783203

Epoch: 6| Step: 1
Training loss: 2.414371967315674
Validation loss: 2.0522231260935464

Epoch: 6| Step: 2
Training loss: 2.1161394119262695
Validation loss: 2.0542505184809365

Epoch: 6| Step: 3
Training loss: 2.14041805267334
Validation loss: 2.051796277364095

Epoch: 6| Step: 4
Training loss: 2.9164910316467285
Validation loss: 2.0472766160964966

Epoch: 6| Step: 5
Training loss: 1.8844883441925049
Validation loss: 2.0531484285990396

Epoch: 6| Step: 6
Training loss: 2.7582406997680664
Validation loss: 2.050303558508555

Epoch: 6| Step: 7
Training loss: 1.978487491607666
Validation loss: 2.0461341937383017

Epoch: 6| Step: 8
Training loss: 1.8034247159957886
Validation loss: 2.041901091734568

Epoch: 6| Step: 9
Training loss: 1.8601562976837158
Validation loss: 2.0413417418797812

Epoch: 6| Step: 10
Training loss: 2.0014777183532715
Validation loss: 2.0492204229036965

Epoch: 6| Step: 11
Training loss: 1.7541906833648682
Validation loss: 2.0450786352157593

Epoch: 6| Step: 12
Training loss: 2.3746581077575684
Validation loss: 2.038169542948405

Epoch: 6| Step: 13
Training loss: 2.8556432723999023
Validation loss: 2.0405139525731406

Epoch: 70| Step: 0
Training loss: 2.2238521575927734
Validation loss: 2.041431407133738

Epoch: 6| Step: 1
Training loss: 1.8263373374938965
Validation loss: 2.043083131313324

Epoch: 6| Step: 2
Training loss: 2.398069143295288
Validation loss: 2.0506137013435364

Epoch: 6| Step: 3
Training loss: 2.265913963317871
Validation loss: 2.0452210108439126

Epoch: 6| Step: 4
Training loss: 2.14261531829834
Validation loss: 2.04793910185496

Epoch: 6| Step: 5
Training loss: 1.8258570432662964
Validation loss: 2.040164033571879

Epoch: 6| Step: 6
Training loss: 2.1758956909179688
Validation loss: 2.039759933948517

Epoch: 6| Step: 7
Training loss: 2.408398151397705
Validation loss: 2.045168658097585

Epoch: 6| Step: 8
Training loss: 2.2117252349853516
Validation loss: 2.0470380783081055

Epoch: 6| Step: 9
Training loss: 2.5392627716064453
Validation loss: 2.051052709420522

Epoch: 6| Step: 10
Training loss: 2.884732961654663
Validation loss: 2.0474207202593484

Epoch: 6| Step: 11
Training loss: 1.712766170501709
Validation loss: 2.0474787751833596

Epoch: 6| Step: 12
Training loss: 1.8530100584030151
Validation loss: 2.0465538104375205

Epoch: 6| Step: 13
Training loss: 2.5233049392700195
Validation loss: 2.0505380829175315

Epoch: 71| Step: 0
Training loss: 1.9303874969482422
Validation loss: 2.0447846055030823

Epoch: 6| Step: 1
Training loss: 2.1473584175109863
Validation loss: 2.0510504841804504

Epoch: 6| Step: 2
Training loss: 2.217802047729492
Validation loss: 2.0396570364634194

Epoch: 6| Step: 3
Training loss: 1.4536218643188477
Validation loss: 2.040242910385132

Epoch: 6| Step: 4
Training loss: 1.8306366205215454
Validation loss: 2.044209877649943

Epoch: 6| Step: 5
Training loss: 2.4943947792053223
Validation loss: 2.0473291873931885

Epoch: 6| Step: 6
Training loss: 2.7372970581054688
Validation loss: 2.045366585254669

Epoch: 6| Step: 7
Training loss: 2.4104580879211426
Validation loss: 2.0477489233016968

Epoch: 6| Step: 8
Training loss: 2.105029821395874
Validation loss: 2.0601896047592163

Epoch: 6| Step: 9
Training loss: 2.459113836288452
Validation loss: 2.064152956008911

Epoch: 6| Step: 10
Training loss: 2.4776852130889893
Validation loss: 2.0584394534428916

Epoch: 6| Step: 11
Training loss: 2.663482189178467
Validation loss: 2.052893122037252

Epoch: 6| Step: 12
Training loss: 1.6629269123077393
Validation loss: 2.05073211590449

Epoch: 6| Step: 13
Training loss: 2.371647357940674
Validation loss: 2.0589187343915305

Epoch: 72| Step: 0
Training loss: 2.795654773712158
Validation loss: 2.05768221616745

Epoch: 6| Step: 1
Training loss: 2.1186845302581787
Validation loss: 2.0517649054527283

Epoch: 6| Step: 2
Training loss: 2.683089017868042
Validation loss: 2.05466490983963

Epoch: 6| Step: 3
Training loss: 2.127338409423828
Validation loss: 2.054668684800466

Epoch: 6| Step: 4
Training loss: 2.322849750518799
Validation loss: 2.050434410572052

Epoch: 6| Step: 5
Training loss: 1.6967582702636719
Validation loss: 2.040058135986328

Epoch: 6| Step: 6
Training loss: 1.9669138193130493
Validation loss: 2.039782146612803

Epoch: 6| Step: 7
Training loss: 1.7386507987976074
Validation loss: 2.0443649888038635

Epoch: 6| Step: 8
Training loss: 1.6843323707580566
Validation loss: 2.0396090745925903

Epoch: 6| Step: 9
Training loss: 2.114525556564331
Validation loss: 2.0443444649378457

Epoch: 6| Step: 10
Training loss: 2.018983840942383
Validation loss: 2.040845274925232

Epoch: 6| Step: 11
Training loss: 2.727494955062866
Validation loss: 2.044646422068278

Epoch: 6| Step: 12
Training loss: 2.400036096572876
Validation loss: 2.0398127834002175

Epoch: 6| Step: 13
Training loss: 2.735975980758667
Validation loss: 2.0364407300949097

Epoch: 73| Step: 0
Training loss: 2.3769431114196777
Validation loss: 2.041453182697296

Epoch: 6| Step: 1
Training loss: 2.6105422973632812
Validation loss: 2.037629226843516

Epoch: 6| Step: 2
Training loss: 2.262181282043457
Validation loss: 2.040686786174774

Epoch: 6| Step: 3
Training loss: 2.3782994747161865
Validation loss: 2.0355363488197327

Epoch: 6| Step: 4
Training loss: 2.1158900260925293
Validation loss: 2.040866573651632

Epoch: 6| Step: 5
Training loss: 1.9564167261123657
Validation loss: 2.0433172384897866

Epoch: 6| Step: 6
Training loss: 1.917590618133545
Validation loss: 2.046798845132192

Epoch: 6| Step: 7
Training loss: 2.346083641052246
Validation loss: 2.0462076663970947

Epoch: 6| Step: 8
Training loss: 2.5571818351745605
Validation loss: 2.0362042586008706

Epoch: 6| Step: 9
Training loss: 2.545194625854492
Validation loss: 2.041635493437449

Epoch: 6| Step: 10
Training loss: 1.6496044397354126
Validation loss: 2.0346932808558145

Epoch: 6| Step: 11
Training loss: 1.96433424949646
Validation loss: 2.0500553448994956

Epoch: 6| Step: 12
Training loss: 1.731811761856079
Validation loss: 2.0556436578432717

Epoch: 6| Step: 13
Training loss: 2.592893123626709
Validation loss: 2.0592291355133057

Epoch: 74| Step: 0
Training loss: 2.517021894454956
Validation loss: 2.0651862223943076

Epoch: 6| Step: 1
Training loss: 2.0956881046295166
Validation loss: 2.0459588368733725

Epoch: 6| Step: 2
Training loss: 2.3053393363952637
Validation loss: 2.061510701974233

Epoch: 6| Step: 3
Training loss: 1.5284984111785889
Validation loss: 2.0531727075576782

Epoch: 6| Step: 4
Training loss: 2.1539011001586914
Validation loss: 2.0442957282066345

Epoch: 6| Step: 5
Training loss: 2.7494924068450928
Validation loss: 2.03784716129303

Epoch: 6| Step: 6
Training loss: 1.6775403022766113
Validation loss: 2.033308426539103

Epoch: 6| Step: 7
Training loss: 2.701443672180176
Validation loss: 2.0417794386545816

Epoch: 6| Step: 8
Training loss: 2.2273263931274414
Validation loss: 2.045118570327759

Epoch: 6| Step: 9
Training loss: 1.643080711364746
Validation loss: 2.038582364718119

Epoch: 6| Step: 10
Training loss: 1.3922665119171143
Validation loss: 2.037209212779999

Epoch: 6| Step: 11
Training loss: 2.661670446395874
Validation loss: 2.0366244316101074

Epoch: 6| Step: 12
Training loss: 2.4875190258026123
Validation loss: 2.04298734664917

Epoch: 6| Step: 13
Training loss: 2.7468161582946777
Validation loss: 2.040355145931244

Epoch: 75| Step: 0
Training loss: 2.694761276245117
Validation loss: 2.0405452450116477

Epoch: 6| Step: 1
Training loss: 2.000318765640259
Validation loss: 2.049002925554911

Epoch: 6| Step: 2
Training loss: 1.2105329036712646
Validation loss: 2.0402740240097046

Epoch: 6| Step: 3
Training loss: 2.354616641998291
Validation loss: 2.0398071805636087

Epoch: 6| Step: 4
Training loss: 2.1452879905700684
Validation loss: 2.0384908318519592

Epoch: 6| Step: 5
Training loss: 2.1328928470611572
Validation loss: 2.0418394207954407

Epoch: 6| Step: 6
Training loss: 2.477588176727295
Validation loss: 2.04350209236145

Epoch: 6| Step: 7
Training loss: 2.1173553466796875
Validation loss: 2.0406213998794556

Epoch: 6| Step: 8
Training loss: 2.6933212280273438
Validation loss: 2.0461339553197226

Epoch: 6| Step: 9
Training loss: 2.209433078765869
Validation loss: 2.036778191725413

Epoch: 6| Step: 10
Training loss: 2.4314310550689697
Validation loss: 2.0434879461924234

Epoch: 6| Step: 11
Training loss: 1.7433412075042725
Validation loss: 2.0435561339060464

Epoch: 6| Step: 12
Training loss: 2.287393093109131
Validation loss: 2.0420873959859214

Epoch: 6| Step: 13
Training loss: 2.61338472366333
Validation loss: 2.0242633620897927

Epoch: 76| Step: 0
Training loss: 1.9690978527069092
Validation loss: 2.0412242809931436

Epoch: 6| Step: 1
Training loss: 2.3811912536621094
Validation loss: 2.0351786017417908

Epoch: 6| Step: 2
Training loss: 2.3343100547790527
Validation loss: 2.037153402964274

Epoch: 6| Step: 3
Training loss: 1.8677189350128174
Validation loss: 2.0405121644337973

Epoch: 6| Step: 4
Training loss: 2.2938756942749023
Validation loss: 2.044559101263682

Epoch: 6| Step: 5
Training loss: 2.297022819519043
Validation loss: 2.0573692520459494

Epoch: 6| Step: 6
Training loss: 1.5205659866333008
Validation loss: 2.0596367915471396

Epoch: 6| Step: 7
Training loss: 2.9096648693084717
Validation loss: 2.0556209087371826

Epoch: 6| Step: 8
Training loss: 2.2705326080322266
Validation loss: 2.040830433368683

Epoch: 6| Step: 9
Training loss: 2.507847547531128
Validation loss: 2.029388427734375

Epoch: 6| Step: 10
Training loss: 2.036872148513794
Validation loss: 2.0232327580451965

Epoch: 6| Step: 11
Training loss: 1.7866286039352417
Validation loss: 2.0282517870267234

Epoch: 6| Step: 12
Training loss: 2.1610803604125977
Validation loss: 2.0275990962982178

Epoch: 6| Step: 13
Training loss: 2.3650879859924316
Validation loss: 2.0317765871683755

Epoch: 77| Step: 0
Training loss: 1.885859489440918
Validation loss: 2.0365686217943826

Epoch: 6| Step: 1
Training loss: 2.6707825660705566
Validation loss: 2.03794535001119

Epoch: 6| Step: 2
Training loss: 2.1474461555480957
Validation loss: 2.0429371198018393

Epoch: 6| Step: 3
Training loss: 1.9538192749023438
Validation loss: 2.043406347433726

Epoch: 6| Step: 4
Training loss: 1.8627510070800781
Validation loss: 2.0446162621180215

Epoch: 6| Step: 5
Training loss: 1.8321914672851562
Validation loss: 2.0391523241996765

Epoch: 6| Step: 6
Training loss: 2.3206300735473633
Validation loss: 2.0411484440167746

Epoch: 6| Step: 7
Training loss: 2.9586174488067627
Validation loss: 2.033780594666799

Epoch: 6| Step: 8
Training loss: 2.550304412841797
Validation loss: 2.0392896135648093

Epoch: 6| Step: 9
Training loss: 1.998892903327942
Validation loss: 2.035077472527822

Epoch: 6| Step: 10
Training loss: 1.982723355293274
Validation loss: 2.037779529889425

Epoch: 6| Step: 11
Training loss: 2.2244229316711426
Validation loss: 2.038291017214457

Epoch: 6| Step: 12
Training loss: 2.1683497428894043
Validation loss: 2.0271867712338767

Epoch: 6| Step: 13
Training loss: 2.2811450958251953
Validation loss: 2.022266964117686

Epoch: 78| Step: 0
Training loss: 2.0543885231018066
Validation loss: 2.0251076420148215

Epoch: 6| Step: 1
Training loss: 2.6703453063964844
Validation loss: 2.026499172051748

Epoch: 6| Step: 2
Training loss: 2.175827980041504
Validation loss: 2.02317221959432

Epoch: 6| Step: 3
Training loss: 1.355539321899414
Validation loss: 2.0416253407796225

Epoch: 6| Step: 4
Training loss: 2.3128790855407715
Validation loss: 2.0518105824788413

Epoch: 6| Step: 5
Training loss: 1.9555792808532715
Validation loss: 2.0718109607696533

Epoch: 6| Step: 6
Training loss: 2.663456439971924
Validation loss: 2.085575799147288

Epoch: 6| Step: 7
Training loss: 2.599036693572998
Validation loss: 2.084462602933248

Epoch: 6| Step: 8
Training loss: 2.5924651622772217
Validation loss: 2.0792866547902427

Epoch: 6| Step: 9
Training loss: 1.6763362884521484
Validation loss: 2.065061171849569

Epoch: 6| Step: 10
Training loss: 2.1769962310791016
Validation loss: 2.064886232217153

Epoch: 6| Step: 11
Training loss: 2.4419915676116943
Validation loss: 2.0423901677131653

Epoch: 6| Step: 12
Training loss: 1.7875871658325195
Validation loss: 2.0340581138928733

Epoch: 6| Step: 13
Training loss: 2.347811698913574
Validation loss: 2.037515183289846

Epoch: 79| Step: 0
Training loss: 1.8405522108078003
Validation loss: 2.0285932620366416

Epoch: 6| Step: 1
Training loss: 2.2517714500427246
Validation loss: 2.0338197350502014

Epoch: 6| Step: 2
Training loss: 2.5984864234924316
Validation loss: 2.038924237092336

Epoch: 6| Step: 3
Training loss: 1.934720516204834
Validation loss: 2.036571820576986

Epoch: 6| Step: 4
Training loss: 2.7907097339630127
Validation loss: 2.04898335536321

Epoch: 6| Step: 5
Training loss: 1.7879345417022705
Validation loss: 2.0441818634668985

Epoch: 6| Step: 6
Training loss: 2.838202476501465
Validation loss: 2.0483322143554688

Epoch: 6| Step: 7
Training loss: 2.1331863403320312
Validation loss: 2.0502560138702393

Epoch: 6| Step: 8
Training loss: 2.077949285507202
Validation loss: 2.044366459051768

Epoch: 6| Step: 9
Training loss: 2.310023307800293
Validation loss: 2.039419253667196

Epoch: 6| Step: 10
Training loss: 1.9395179748535156
Validation loss: 2.0339825550715127

Epoch: 6| Step: 11
Training loss: 2.0008039474487305
Validation loss: 2.0274657209714255

Epoch: 6| Step: 12
Training loss: 1.8094286918640137
Validation loss: 2.0179888804753623

Epoch: 6| Step: 13
Training loss: 2.5213217735290527
Validation loss: 2.0258372028668723

Epoch: 80| Step: 0
Training loss: 2.2453699111938477
Validation loss: 2.022473414738973

Epoch: 6| Step: 1
Training loss: 2.008901357650757
Validation loss: 2.026328126589457

Epoch: 6| Step: 2
Training loss: 2.498850107192993
Validation loss: 2.0372604727745056

Epoch: 6| Step: 3
Training loss: 1.8530735969543457
Validation loss: 2.0441572666168213

Epoch: 6| Step: 4
Training loss: 2.320746660232544
Validation loss: 2.0520887772242227

Epoch: 6| Step: 5
Training loss: 1.4905598163604736
Validation loss: 2.064982612927755

Epoch: 6| Step: 6
Training loss: 2.6195945739746094
Validation loss: 2.061802347501119

Epoch: 6| Step: 7
Training loss: 2.5881857872009277
Validation loss: 2.056925594806671

Epoch: 6| Step: 8
Training loss: 2.059265613555908
Validation loss: 2.0441186825434365

Epoch: 6| Step: 9
Training loss: 1.4857488870620728
Validation loss: 2.060891409715017

Epoch: 6| Step: 10
Training loss: 1.9134814739227295
Validation loss: 2.05318949619929

Epoch: 6| Step: 11
Training loss: 2.2549362182617188
Validation loss: 2.063956061999003

Epoch: 6| Step: 12
Training loss: 2.4623570442199707
Validation loss: 2.054583569367727

Epoch: 6| Step: 13
Training loss: 2.642796754837036
Validation loss: 2.0453661680221558

Epoch: 81| Step: 0
Training loss: 2.0768799781799316
Validation loss: 2.037616729736328

Epoch: 6| Step: 1
Training loss: 2.1051716804504395
Validation loss: 2.033682405948639

Epoch: 6| Step: 2
Training loss: 2.0498056411743164
Validation loss: 2.0289303064346313

Epoch: 6| Step: 3
Training loss: 2.5872926712036133
Validation loss: 2.029706358909607

Epoch: 6| Step: 4
Training loss: 1.5287821292877197
Validation loss: 2.037415027618408

Epoch: 6| Step: 5
Training loss: 2.0036683082580566
Validation loss: 2.0322088599205017

Epoch: 6| Step: 6
Training loss: 2.558168411254883
Validation loss: 2.034239093462626

Epoch: 6| Step: 7
Training loss: 2.7859749794006348
Validation loss: 2.034099837144216

Epoch: 6| Step: 8
Training loss: 2.114525079727173
Validation loss: 2.038872758547465

Epoch: 6| Step: 9
Training loss: 1.972602128982544
Validation loss: 2.0393675764401755

Epoch: 6| Step: 10
Training loss: 2.458075523376465
Validation loss: 2.0472209056218467

Epoch: 6| Step: 11
Training loss: 2.48590087890625
Validation loss: 2.045735458532969

Epoch: 6| Step: 12
Training loss: 2.1171538829803467
Validation loss: 2.046898365020752

Epoch: 6| Step: 13
Training loss: 2.047933578491211
Validation loss: 2.0434423287709556

Epoch: 82| Step: 0
Training loss: 2.3852438926696777
Validation loss: 2.043255945046743

Epoch: 6| Step: 1
Training loss: 2.0375876426696777
Validation loss: 2.0389110247294107

Epoch: 6| Step: 2
Training loss: 1.7185670137405396
Validation loss: 2.0380069812138877

Epoch: 6| Step: 3
Training loss: 2.1555099487304688
Validation loss: 2.0361286401748657

Epoch: 6| Step: 4
Training loss: 2.3868472576141357
Validation loss: 2.0328330993652344

Epoch: 6| Step: 5
Training loss: 2.0000648498535156
Validation loss: 2.0315181016921997

Epoch: 6| Step: 6
Training loss: 2.6471314430236816
Validation loss: 2.0377238988876343

Epoch: 6| Step: 7
Training loss: 1.2472187280654907
Validation loss: 2.036882758140564

Epoch: 6| Step: 8
Training loss: 2.571138858795166
Validation loss: 2.0345985492070517

Epoch: 6| Step: 9
Training loss: 2.554192304611206
Validation loss: 2.0324349800745645

Epoch: 6| Step: 10
Training loss: 1.9108715057373047
Validation loss: 2.020528793334961

Epoch: 6| Step: 11
Training loss: 2.444809675216675
Validation loss: 2.02280455827713

Epoch: 6| Step: 12
Training loss: 2.7677547931671143
Validation loss: 2.0266964435577393

Epoch: 6| Step: 13
Training loss: 2.1136903762817383
Validation loss: 2.0357205073038735

Epoch: 83| Step: 0
Training loss: 1.9305408000946045
Validation loss: 2.0340640544891357

Epoch: 6| Step: 1
Training loss: 1.6931569576263428
Validation loss: 2.0308048526446023

Epoch: 6| Step: 2
Training loss: 1.7225803136825562
Validation loss: 2.028724789619446

Epoch: 6| Step: 3
Training loss: 2.4523563385009766
Validation loss: 2.0377076864242554

Epoch: 6| Step: 4
Training loss: 2.224994659423828
Validation loss: 2.0510882139205933

Epoch: 6| Step: 5
Training loss: 2.4176647663116455
Validation loss: 2.0641616384188333

Epoch: 6| Step: 6
Training loss: 2.9789602756500244
Validation loss: 2.064699133237203

Epoch: 6| Step: 7
Training loss: 2.091817855834961
Validation loss: 2.075013041496277

Epoch: 6| Step: 8
Training loss: 1.7636466026306152
Validation loss: 2.0852197408676147

Epoch: 6| Step: 9
Training loss: 2.0344810485839844
Validation loss: 2.081701656182607

Epoch: 6| Step: 10
Training loss: 2.141702651977539
Validation loss: 2.0744080543518066

Epoch: 6| Step: 11
Training loss: 2.380446434020996
Validation loss: 2.0719189445177713

Epoch: 6| Step: 12
Training loss: 2.2373948097229004
Validation loss: 2.0671497583389282

Epoch: 6| Step: 13
Training loss: 2.465622901916504
Validation loss: 2.063428978125254

Epoch: 84| Step: 0
Training loss: 1.8946425914764404
Validation loss: 2.0442298452059426

Epoch: 6| Step: 1
Training loss: 1.9132038354873657
Validation loss: 2.0285568038622537

Epoch: 6| Step: 2
Training loss: 2.545264720916748
Validation loss: 2.0365091959635415

Epoch: 6| Step: 3
Training loss: 1.4011564254760742
Validation loss: 2.026200612386068

Epoch: 6| Step: 4
Training loss: 2.520514488220215
Validation loss: 2.0256117582321167

Epoch: 6| Step: 5
Training loss: 2.0776617527008057
Validation loss: 2.037891447544098

Epoch: 6| Step: 6
Training loss: 1.7493171691894531
Validation loss: 2.0359337528546653

Epoch: 6| Step: 7
Training loss: 1.969620943069458
Validation loss: 2.0437050660451255

Epoch: 6| Step: 8
Training loss: 2.330137014389038
Validation loss: 2.0368431011835733

Epoch: 6| Step: 9
Training loss: 1.905240535736084
Validation loss: 2.036453048388163

Epoch: 6| Step: 10
Training loss: 1.938857078552246
Validation loss: 2.0273576577504477

Epoch: 6| Step: 11
Training loss: 2.9296677112579346
Validation loss: 2.023539145787557

Epoch: 6| Step: 12
Training loss: 2.527031183242798
Validation loss: 2.017622788747152

Epoch: 6| Step: 13
Training loss: 2.6802408695220947
Validation loss: 2.0222179889678955

Epoch: 85| Step: 0
Training loss: 2.484377861022949
Validation loss: 2.019884546597799

Epoch: 6| Step: 1
Training loss: 1.85651433467865
Validation loss: 2.0205878218015036

Epoch: 6| Step: 2
Training loss: 1.4414291381835938
Validation loss: 2.0389384428660073

Epoch: 6| Step: 3
Training loss: 2.5684597492218018
Validation loss: 2.0447651147842407

Epoch: 6| Step: 4
Training loss: 1.8997082710266113
Validation loss: 2.049673636754354

Epoch: 6| Step: 5
Training loss: 1.7010855674743652
Validation loss: 2.072958985964457

Epoch: 6| Step: 6
Training loss: 2.45430850982666
Validation loss: 2.073061545689901

Epoch: 6| Step: 7
Training loss: 2.498563289642334
Validation loss: 2.0794615944226584

Epoch: 6| Step: 8
Training loss: 2.586050271987915
Validation loss: 2.0820064544677734

Epoch: 6| Step: 9
Training loss: 1.9491560459136963
Validation loss: 2.0772902965545654

Epoch: 6| Step: 10
Training loss: 2.1457698345184326
Validation loss: 2.084060529867808

Epoch: 6| Step: 11
Training loss: 2.3282642364501953
Validation loss: 2.061720550060272

Epoch: 6| Step: 12
Training loss: 2.4111266136169434
Validation loss: 2.0622252027193704

Epoch: 6| Step: 13
Training loss: 2.36456036567688
Validation loss: 2.024888734022776

Epoch: 86| Step: 0
Training loss: 2.5573806762695312
Validation loss: 2.0188379685084024

Epoch: 6| Step: 1
Training loss: 2.0687389373779297
Validation loss: 2.0201668540636697

Epoch: 6| Step: 2
Training loss: 2.5767221450805664
Validation loss: 2.0231979886690774

Epoch: 6| Step: 3
Training loss: 2.3671531677246094
Validation loss: 2.0227611462275186

Epoch: 6| Step: 4
Training loss: 1.9693870544433594
Validation loss: 2.024328966935476

Epoch: 6| Step: 5
Training loss: 2.6120333671569824
Validation loss: 2.0293941299120584

Epoch: 6| Step: 6
Training loss: 1.8532155752182007
Validation loss: 2.0244548122088113

Epoch: 6| Step: 7
Training loss: 2.450143337249756
Validation loss: 2.024603009223938

Epoch: 6| Step: 8
Training loss: 2.199280023574829
Validation loss: 2.029439707597097

Epoch: 6| Step: 9
Training loss: 1.571939468383789
Validation loss: 2.028712968031565

Epoch: 6| Step: 10
Training loss: 2.354397773742676
Validation loss: 2.0260321895281472

Epoch: 6| Step: 11
Training loss: 1.6349055767059326
Validation loss: 2.0271408359209695

Epoch: 6| Step: 12
Training loss: 1.7106285095214844
Validation loss: 2.0286330580711365

Epoch: 6| Step: 13
Training loss: 2.5872700214385986
Validation loss: 2.0251020789146423

Epoch: 87| Step: 0
Training loss: 1.4907749891281128
Validation loss: 2.0269771814346313

Epoch: 6| Step: 1
Training loss: 2.544825553894043
Validation loss: 2.026408076286316

Epoch: 6| Step: 2
Training loss: 2.4982166290283203
Validation loss: 2.022910177707672

Epoch: 6| Step: 3
Training loss: 2.0834848880767822
Validation loss: 2.025198678175608

Epoch: 6| Step: 4
Training loss: 2.409085988998413
Validation loss: 2.027273694674174

Epoch: 6| Step: 5
Training loss: 2.5637941360473633
Validation loss: 2.0262763102849326

Epoch: 6| Step: 6
Training loss: 2.2397894859313965
Validation loss: 2.016555825869242

Epoch: 6| Step: 7
Training loss: 1.9507408142089844
Validation loss: 2.029894471168518

Epoch: 6| Step: 8
Training loss: 2.1255831718444824
Validation loss: 2.02913232644399

Epoch: 6| Step: 9
Training loss: 1.4781720638275146
Validation loss: 2.0279293060302734

Epoch: 6| Step: 10
Training loss: 2.337297201156616
Validation loss: 2.0342476765314736

Epoch: 6| Step: 11
Training loss: 2.513404369354248
Validation loss: 2.0389329393704734

Epoch: 6| Step: 12
Training loss: 2.082425832748413
Validation loss: 2.0476300716400146

Epoch: 6| Step: 13
Training loss: 2.0496761798858643
Validation loss: 2.067448357741038

Epoch: 88| Step: 0
Training loss: 2.1306824684143066
Validation loss: 2.0740413665771484

Epoch: 6| Step: 1
Training loss: 2.3761701583862305
Validation loss: 2.0793575843175254

Epoch: 6| Step: 2
Training loss: 1.963546872138977
Validation loss: 2.0581719477971396

Epoch: 6| Step: 3
Training loss: 2.452648639678955
Validation loss: 2.0476446946461997

Epoch: 6| Step: 4
Training loss: 2.4766592979431152
Validation loss: 2.0269137620925903

Epoch: 6| Step: 5
Training loss: 1.5796592235565186
Validation loss: 2.0156134366989136

Epoch: 6| Step: 6
Training loss: 2.3321917057037354
Validation loss: 2.018102467060089

Epoch: 6| Step: 7
Training loss: 2.651750087738037
Validation loss: 2.019874413808187

Epoch: 6| Step: 8
Training loss: 2.2682766914367676
Validation loss: 2.030831972757975

Epoch: 6| Step: 9
Training loss: 1.9077528715133667
Validation loss: 2.029824356238047

Epoch: 6| Step: 10
Training loss: 2.212634563446045
Validation loss: 2.024938225746155

Epoch: 6| Step: 11
Training loss: 2.0659384727478027
Validation loss: 2.023597498734792

Epoch: 6| Step: 12
Training loss: 2.0620172023773193
Validation loss: 2.0214648842811584

Epoch: 6| Step: 13
Training loss: 2.1247644424438477
Validation loss: 2.020929992198944

Epoch: 89| Step: 0
Training loss: 1.9712908267974854
Validation loss: 2.024613857269287

Epoch: 6| Step: 1
Training loss: 2.4000325202941895
Validation loss: 2.016906479994456

Epoch: 6| Step: 2
Training loss: 1.6122353076934814
Validation loss: 2.01175457239151

Epoch: 6| Step: 3
Training loss: 2.512483596801758
Validation loss: 2.0147805412610373

Epoch: 6| Step: 4
Training loss: 1.7130236625671387
Validation loss: 2.019152820110321

Epoch: 6| Step: 5
Training loss: 1.7628828287124634
Validation loss: 2.0291923880577087

Epoch: 6| Step: 6
Training loss: 2.8542537689208984
Validation loss: 2.049080232779185

Epoch: 6| Step: 7
Training loss: 1.3415377140045166
Validation loss: 2.0550573269526162

Epoch: 6| Step: 8
Training loss: 2.5390377044677734
Validation loss: 2.0497818986574807

Epoch: 6| Step: 9
Training loss: 2.2847023010253906
Validation loss: 2.0528305967648826

Epoch: 6| Step: 10
Training loss: 2.2603793144226074
Validation loss: 2.0537241299947104

Epoch: 6| Step: 11
Training loss: 2.161377429962158
Validation loss: 2.0431196888287864

Epoch: 6| Step: 12
Training loss: 2.6321516036987305
Validation loss: 2.045871833960215

Epoch: 6| Step: 13
Training loss: 2.208096504211426
Validation loss: 2.0390892823537192

Epoch: 90| Step: 0
Training loss: 2.080733299255371
Validation loss: 2.0312620997428894

Epoch: 6| Step: 1
Training loss: 2.1831753253936768
Validation loss: 2.0300451119740806

Epoch: 6| Step: 2
Training loss: 1.7387762069702148
Validation loss: 2.0261764327685037

Epoch: 6| Step: 3
Training loss: 2.556983232498169
Validation loss: 2.0375749667485556

Epoch: 6| Step: 4
Training loss: 2.411787986755371
Validation loss: 2.0335187315940857

Epoch: 6| Step: 5
Training loss: 2.0345468521118164
Validation loss: 2.0361885825792947

Epoch: 6| Step: 6
Training loss: 1.9219433069229126
Validation loss: 2.03700723250707

Epoch: 6| Step: 7
Training loss: 2.3191468715667725
Validation loss: 2.0396098494529724

Epoch: 6| Step: 8
Training loss: 2.2206950187683105
Validation loss: 2.0351597468058267

Epoch: 6| Step: 9
Training loss: 2.057755470275879
Validation loss: 2.0367289384206138

Epoch: 6| Step: 10
Training loss: 2.3043978214263916
Validation loss: 2.029120703538259

Epoch: 6| Step: 11
Training loss: 1.7044661045074463
Validation loss: 2.0227726101875305

Epoch: 6| Step: 12
Training loss: 2.163947582244873
Validation loss: 2.0226375659306846

Epoch: 6| Step: 13
Training loss: 2.527884006500244
Validation loss: 2.0229039390881858

Epoch: 91| Step: 0
Training loss: 2.449174404144287
Validation loss: 2.0304882923762

Epoch: 6| Step: 1
Training loss: 2.5045719146728516
Validation loss: 2.022394816080729

Epoch: 6| Step: 2
Training loss: 1.9024803638458252
Validation loss: 2.022165377934774

Epoch: 6| Step: 3
Training loss: 2.0009193420410156
Validation loss: 2.0186866323153176

Epoch: 6| Step: 4
Training loss: 1.7822362184524536
Validation loss: 2.019838194052378

Epoch: 6| Step: 5
Training loss: 2.9350368976593018
Validation loss: 2.0161200364430747

Epoch: 6| Step: 6
Training loss: 1.8392618894577026
Validation loss: 2.0211369395256042

Epoch: 6| Step: 7
Training loss: 1.9818861484527588
Validation loss: 2.0165483355522156

Epoch: 6| Step: 8
Training loss: 2.4599123001098633
Validation loss: 2.0205726424853006

Epoch: 6| Step: 9
Training loss: 2.036141872406006
Validation loss: 2.019284645716349

Epoch: 6| Step: 10
Training loss: 2.323516607284546
Validation loss: 2.013805349667867

Epoch: 6| Step: 11
Training loss: 2.2928457260131836
Validation loss: 2.0228841304779053

Epoch: 6| Step: 12
Training loss: 1.8463308811187744
Validation loss: 2.017366051673889

Epoch: 6| Step: 13
Training loss: 1.853013515472412
Validation loss: 2.017311235268911

Epoch: 92| Step: 0
Training loss: 1.932508111000061
Validation loss: 2.026514788468679

Epoch: 6| Step: 1
Training loss: 2.579509735107422
Validation loss: 2.0256277322769165

Epoch: 6| Step: 2
Training loss: 2.3494882583618164
Validation loss: 2.029907743136088

Epoch: 6| Step: 3
Training loss: 2.0409741401672363
Validation loss: 2.037674307823181

Epoch: 6| Step: 4
Training loss: 2.2315046787261963
Validation loss: 2.0414369702339172

Epoch: 6| Step: 5
Training loss: 1.3350074291229248
Validation loss: 2.03524382909139

Epoch: 6| Step: 6
Training loss: 1.4819722175598145
Validation loss: 2.0315900444984436

Epoch: 6| Step: 7
Training loss: 1.8245031833648682
Validation loss: 2.031257748603821

Epoch: 6| Step: 8
Training loss: 2.6310596466064453
Validation loss: 2.040617267290751

Epoch: 6| Step: 9
Training loss: 1.587996244430542
Validation loss: 2.030706226825714

Epoch: 6| Step: 10
Training loss: 2.4214682579040527
Validation loss: 2.031904617945353

Epoch: 6| Step: 11
Training loss: 2.5347208976745605
Validation loss: 2.0346256693204245

Epoch: 6| Step: 12
Training loss: 2.6437253952026367
Validation loss: 2.0365465879440308

Epoch: 6| Step: 13
Training loss: 2.2797091007232666
Validation loss: 2.026145656903585

Epoch: 93| Step: 0
Training loss: 2.151548147201538
Validation loss: 2.023659348487854

Epoch: 6| Step: 1
Training loss: 2.4447927474975586
Validation loss: 2.0190173387527466

Epoch: 6| Step: 2
Training loss: 1.8718328475952148
Validation loss: 2.019180198510488

Epoch: 6| Step: 3
Training loss: 2.37666654586792
Validation loss: 2.0126770734786987

Epoch: 6| Step: 4
Training loss: 2.379976749420166
Validation loss: 2.0166998704274497

Epoch: 6| Step: 5
Training loss: 2.182779312133789
Validation loss: 2.027969320615133

Epoch: 6| Step: 6
Training loss: 2.7539124488830566
Validation loss: 2.020129998524984

Epoch: 6| Step: 7
Training loss: 1.6189887523651123
Validation loss: 2.0318257411321006

Epoch: 6| Step: 8
Training loss: 1.5215177536010742
Validation loss: 2.038587987422943

Epoch: 6| Step: 9
Training loss: 2.2105751037597656
Validation loss: 2.0378719369570413

Epoch: 6| Step: 10
Training loss: 1.9735658168792725
Validation loss: 2.0308284163475037

Epoch: 6| Step: 11
Training loss: 1.7996430397033691
Validation loss: 2.029193937778473

Epoch: 6| Step: 12
Training loss: 2.1221861839294434
Validation loss: 2.0348533193270364

Epoch: 6| Step: 13
Training loss: 2.6291236877441406
Validation loss: 2.02753347158432

Epoch: 94| Step: 0
Training loss: 2.2574806213378906
Validation loss: 2.0186837315559387

Epoch: 6| Step: 1
Training loss: 1.4828062057495117
Validation loss: 2.0298513372739158

Epoch: 6| Step: 2
Training loss: 1.7869367599487305
Validation loss: 2.0284541050593057

Epoch: 6| Step: 3
Training loss: 2.296865463256836
Validation loss: 2.0304823915163674

Epoch: 6| Step: 4
Training loss: 2.3589744567871094
Validation loss: 2.027839263280233

Epoch: 6| Step: 5
Training loss: 1.9116582870483398
Validation loss: 2.017464339733124

Epoch: 6| Step: 6
Training loss: 2.909005641937256
Validation loss: 2.0247366229693093

Epoch: 6| Step: 7
Training loss: 2.468967914581299
Validation loss: 2.018664538860321

Epoch: 6| Step: 8
Training loss: 2.4013705253601074
Validation loss: 2.0221904714902244

Epoch: 6| Step: 9
Training loss: 2.113118886947632
Validation loss: 2.0244574348131814

Epoch: 6| Step: 10
Training loss: 2.221745491027832
Validation loss: 2.0198652346928916

Epoch: 6| Step: 11
Training loss: 1.7750658988952637
Validation loss: 2.0241719285647073

Epoch: 6| Step: 12
Training loss: 2.2087411880493164
Validation loss: 2.0158055424690247

Epoch: 6| Step: 13
Training loss: 2.186903953552246
Validation loss: 2.0213591853777566

Epoch: 95| Step: 0
Training loss: 2.0055980682373047
Validation loss: 2.0217217803001404

Epoch: 6| Step: 1
Training loss: 2.587406635284424
Validation loss: 2.022664944330851

Epoch: 6| Step: 2
Training loss: 1.8643834590911865
Validation loss: 2.025277098019918

Epoch: 6| Step: 3
Training loss: 2.1750056743621826
Validation loss: 2.0248690843582153

Epoch: 6| Step: 4
Training loss: 1.8599289655685425
Validation loss: 2.0285314122835794

Epoch: 6| Step: 5
Training loss: 2.8299622535705566
Validation loss: 2.026269336541494

Epoch: 6| Step: 6
Training loss: 1.834190011024475
Validation loss: 2.023987074693044

Epoch: 6| Step: 7
Training loss: 1.8142824172973633
Validation loss: 2.007860004901886

Epoch: 6| Step: 8
Training loss: 1.8069665431976318
Validation loss: 2.0136786897977195

Epoch: 6| Step: 9
Training loss: 2.094815969467163
Validation loss: 2.0179425875345864

Epoch: 6| Step: 10
Training loss: 2.546450138092041
Validation loss: 2.0221303502718606

Epoch: 6| Step: 11
Training loss: 2.241805076599121
Validation loss: 2.021995266278585

Epoch: 6| Step: 12
Training loss: 2.648796796798706
Validation loss: 2.023812492688497

Epoch: 6| Step: 13
Training loss: 2.042921543121338
Validation loss: 2.020351747671763

Epoch: 96| Step: 0
Training loss: 1.9156008958816528
Validation loss: 2.029889404773712

Epoch: 6| Step: 1
Training loss: 2.2530059814453125
Validation loss: 2.016947646935781

Epoch: 6| Step: 2
Training loss: 1.6756303310394287
Validation loss: 2.0160953799883523

Epoch: 6| Step: 3
Training loss: 2.735525608062744
Validation loss: 2.037593106428782

Epoch: 6| Step: 4
Training loss: 2.0173330307006836
Validation loss: 2.0504096349080405

Epoch: 6| Step: 5
Training loss: 1.481276035308838
Validation loss: 2.04641725619634

Epoch: 6| Step: 6
Training loss: 1.938908338546753
Validation loss: 2.0425453980763755

Epoch: 6| Step: 7
Training loss: 2.4320054054260254
Validation loss: 2.050183872381846

Epoch: 6| Step: 8
Training loss: 2.444356918334961
Validation loss: 2.0386762619018555

Epoch: 6| Step: 9
Training loss: 1.7116737365722656
Validation loss: 2.050265351931254

Epoch: 6| Step: 10
Training loss: 2.1143999099731445
Validation loss: 2.05390864610672

Epoch: 6| Step: 11
Training loss: 2.2622597217559814
Validation loss: 2.055557131767273

Epoch: 6| Step: 12
Training loss: 2.547987937927246
Validation loss: 2.0515053272247314

Epoch: 6| Step: 13
Training loss: 2.335038661956787
Validation loss: 2.04387774070104

Epoch: 97| Step: 0
Training loss: 2.0606212615966797
Validation loss: 2.0476252237955728

Epoch: 6| Step: 1
Training loss: 1.3759887218475342
Validation loss: 2.0554427901903787

Epoch: 6| Step: 2
Training loss: 2.334120750427246
Validation loss: 2.042986432711283

Epoch: 6| Step: 3
Training loss: 2.1309962272644043
Validation loss: 2.040987948576609

Epoch: 6| Step: 4
Training loss: 2.7857556343078613
Validation loss: 2.049541393915812

Epoch: 6| Step: 5
Training loss: 2.2130532264709473
Validation loss: 2.048093398412069

Epoch: 6| Step: 6
Training loss: 2.0684237480163574
Validation loss: 2.03252120812734

Epoch: 6| Step: 7
Training loss: 1.6236366033554077
Validation loss: 2.0378918250401816

Epoch: 6| Step: 8
Training loss: 1.954904317855835
Validation loss: 2.036444385846456

Epoch: 6| Step: 9
Training loss: 2.4295763969421387
Validation loss: 2.0379613041877747

Epoch: 6| Step: 10
Training loss: 2.638016939163208
Validation loss: 2.026338835557302

Epoch: 6| Step: 11
Training loss: 1.6030033826828003
Validation loss: 2.030637184778849

Epoch: 6| Step: 12
Training loss: 2.2381606101989746
Validation loss: 2.0334390997886658

Epoch: 6| Step: 13
Training loss: 2.360502243041992
Validation loss: 2.0372812350591025

Epoch: 98| Step: 0
Training loss: 2.3612656593322754
Validation loss: 2.030994494756063

Epoch: 6| Step: 1
Training loss: 2.191993474960327
Validation loss: 2.0379870732625327

Epoch: 6| Step: 2
Training loss: 1.982108235359192
Validation loss: 2.035414934158325

Epoch: 6| Step: 3
Training loss: 2.1061758995056152
Validation loss: 2.037328521410624

Epoch: 6| Step: 4
Training loss: 2.3029701709747314
Validation loss: 2.0338945388793945

Epoch: 6| Step: 5
Training loss: 2.1616392135620117
Validation loss: 2.049818297227224

Epoch: 6| Step: 6
Training loss: 2.067107915878296
Validation loss: 2.0474277337392173

Epoch: 6| Step: 7
Training loss: 1.70499587059021
Validation loss: 2.0640806357065835

Epoch: 6| Step: 8
Training loss: 2.082411527633667
Validation loss: 2.0606208046277366

Epoch: 6| Step: 9
Training loss: 1.7472621202468872
Validation loss: 2.0592177907625833

Epoch: 6| Step: 10
Training loss: 1.6084628105163574
Validation loss: 2.050179739793142

Epoch: 6| Step: 11
Training loss: 2.860396385192871
Validation loss: 2.047616640726725

Epoch: 6| Step: 12
Training loss: 2.5697317123413086
Validation loss: 2.0347382624944053

Epoch: 6| Step: 13
Training loss: 2.3304202556610107
Validation loss: 2.0327879985173545

Epoch: 99| Step: 0
Training loss: 2.216132164001465
Validation loss: 2.031516373157501

Epoch: 6| Step: 1
Training loss: 1.366098165512085
Validation loss: 2.019108315308889

Epoch: 6| Step: 2
Training loss: 2.0420656204223633
Validation loss: 2.0323309302330017

Epoch: 6| Step: 3
Training loss: 2.0226829051971436
Validation loss: 2.0365646878878274

Epoch: 6| Step: 4
Training loss: 2.8295371532440186
Validation loss: 2.0417787233988443

Epoch: 6| Step: 5
Training loss: 2.3136096000671387
Validation loss: 2.041596531867981

Epoch: 6| Step: 6
Training loss: 1.6714303493499756
Validation loss: 2.0460428992907205

Epoch: 6| Step: 7
Training loss: 2.2506299018859863
Validation loss: 2.0459914604822793

Epoch: 6| Step: 8
Training loss: 2.122650146484375
Validation loss: 2.0393075942993164

Epoch: 6| Step: 9
Training loss: 2.4714388847351074
Validation loss: 2.037524422009786

Epoch: 6| Step: 10
Training loss: 1.9050737619400024
Validation loss: 2.0317010482152305

Epoch: 6| Step: 11
Training loss: 2.0440456867218018
Validation loss: 2.0363488594690957

Epoch: 6| Step: 12
Training loss: 2.1176650524139404
Validation loss: 2.0328402717908225

Epoch: 6| Step: 13
Training loss: 2.70670485496521
Validation loss: 2.0312519470850625

Epoch: 100| Step: 0
Training loss: 2.3742146492004395
Validation loss: 2.0245872139930725

Epoch: 6| Step: 1
Training loss: 1.8679988384246826
Validation loss: 2.0255601604779563

Epoch: 6| Step: 2
Training loss: 1.783557415008545
Validation loss: 2.030722439289093

Epoch: 6| Step: 3
Training loss: 2.4981818199157715
Validation loss: 2.0252556602160134

Epoch: 6| Step: 4
Training loss: 2.2536721229553223
Validation loss: 2.026310940583547

Epoch: 6| Step: 5
Training loss: 1.99855637550354
Validation loss: 2.0297850171724954

Epoch: 6| Step: 6
Training loss: 2.499633550643921
Validation loss: 2.0322704116503396

Epoch: 6| Step: 7
Training loss: 2.135298252105713
Validation loss: 2.0376272201538086

Epoch: 6| Step: 8
Training loss: 1.9517749547958374
Validation loss: 2.0372326175371804

Epoch: 6| Step: 9
Training loss: 2.819643497467041
Validation loss: 2.0402190685272217

Epoch: 6| Step: 10
Training loss: 1.7100787162780762
Validation loss: 2.038020590941111

Epoch: 6| Step: 11
Training loss: 1.4456740617752075
Validation loss: 2.031640370686849

Epoch: 6| Step: 12
Training loss: 2.460994243621826
Validation loss: 2.0363304813702903

Epoch: 6| Step: 13
Training loss: 2.3074588775634766
Validation loss: 2.0330008467038474

Testing loss: 1.672829849256886
