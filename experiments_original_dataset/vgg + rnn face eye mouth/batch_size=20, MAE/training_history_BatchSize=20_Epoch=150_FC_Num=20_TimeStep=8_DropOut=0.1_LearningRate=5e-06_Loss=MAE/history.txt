Epoch: 1| Step: 0
Training loss: 5.903707981109619
Validation loss: 5.38986982901891

Epoch: 5| Step: 1
Training loss: 5.061513900756836
Validation loss: 5.3874737819035845

Epoch: 5| Step: 2
Training loss: 4.988375663757324
Validation loss: 5.385121762752533

Epoch: 5| Step: 3
Training loss: 6.02742862701416
Validation loss: 5.382695555686951

Epoch: 5| Step: 4
Training loss: 5.01428747177124
Validation loss: 5.380488653977712

Epoch: 5| Step: 5
Training loss: 5.301161289215088
Validation loss: 5.37802392244339

Epoch: 5| Step: 6
Training loss: 5.473280906677246
Validation loss: 5.375639100869496

Epoch: 5| Step: 7
Training loss: 5.350282192230225
Validation loss: 5.373130698998769

Epoch: 5| Step: 8
Training loss: 5.314528942108154
Validation loss: 5.370663126309712

Epoch: 5| Step: 9
Training loss: 6.156338691711426
Validation loss: 5.367935419082642

Epoch: 5| Step: 10
Training loss: 4.934789180755615
Validation loss: 5.365223050117493

Epoch: 5| Step: 11
Training loss: 7.380011081695557
Validation loss: 5.3625368475914

Epoch: 2| Step: 0
Training loss: 6.0612335205078125
Validation loss: 5.3595011830329895

Epoch: 5| Step: 1
Training loss: 5.593535900115967
Validation loss: 5.356565276781718

Epoch: 5| Step: 2
Training loss: 4.664244174957275
Validation loss: 5.35331396261851

Epoch: 5| Step: 3
Training loss: 5.252862453460693
Validation loss: 5.350150267283122

Epoch: 5| Step: 4
Training loss: 6.223298072814941
Validation loss: 5.346642931302388

Epoch: 5| Step: 5
Training loss: 5.433804988861084
Validation loss: 5.343076745669047

Epoch: 5| Step: 6
Training loss: 5.002053260803223
Validation loss: 5.339328348636627

Epoch: 5| Step: 7
Training loss: 4.653553485870361
Validation loss: 5.335464835166931

Epoch: 5| Step: 8
Training loss: 5.224984169006348
Validation loss: 5.331230918566386

Epoch: 5| Step: 9
Training loss: 6.176291465759277
Validation loss: 5.327106595039368

Epoch: 5| Step: 10
Training loss: 5.148777484893799
Validation loss: 5.3226631085077925

Epoch: 5| Step: 11
Training loss: 5.843166828155518
Validation loss: 5.3179861307144165

Epoch: 3| Step: 0
Training loss: 6.498333930969238
Validation loss: 5.313185393810272

Epoch: 5| Step: 1
Training loss: 4.2388200759887695
Validation loss: 5.3080113530159

Epoch: 5| Step: 2
Training loss: 5.5957818031311035
Validation loss: 5.30297056833903

Epoch: 5| Step: 3
Training loss: 5.378085136413574
Validation loss: 5.297417521476746

Epoch: 5| Step: 4
Training loss: 4.830573081970215
Validation loss: 5.291819294293721

Epoch: 5| Step: 5
Training loss: 6.135368824005127
Validation loss: 5.285834848880768

Epoch: 5| Step: 6
Training loss: 5.8118414878845215
Validation loss: 5.279754996299744

Epoch: 5| Step: 7
Training loss: 5.663272857666016
Validation loss: 5.273476421833038

Epoch: 5| Step: 8
Training loss: 4.07003116607666
Validation loss: 5.267045358816783

Epoch: 5| Step: 9
Training loss: 5.299597263336182
Validation loss: 5.260398864746094

Epoch: 5| Step: 10
Training loss: 5.423253059387207
Validation loss: 5.253463466962178

Epoch: 5| Step: 11
Training loss: 5.095149993896484
Validation loss: 5.246603012084961

Epoch: 4| Step: 0
Training loss: 6.604588508605957
Validation loss: 5.239556988080342

Epoch: 5| Step: 1
Training loss: 5.040040493011475
Validation loss: 5.23224139213562

Epoch: 5| Step: 2
Training loss: 4.433676242828369
Validation loss: 5.224405427773793

Epoch: 5| Step: 3
Training loss: 5.268823623657227
Validation loss: 5.217134515444438

Epoch: 5| Step: 4
Training loss: 5.2213358879089355
Validation loss: 5.209102749824524

Epoch: 5| Step: 5
Training loss: 4.757667541503906
Validation loss: 5.201292097568512

Epoch: 5| Step: 6
Training loss: 5.805544376373291
Validation loss: 5.193343897660573

Epoch: 5| Step: 7
Training loss: 4.85723876953125
Validation loss: 5.184578498204549

Epoch: 5| Step: 8
Training loss: 5.7799601554870605
Validation loss: 5.176269988218944

Epoch: 5| Step: 9
Training loss: 5.426323890686035
Validation loss: 5.167864123980205

Epoch: 5| Step: 10
Training loss: 4.642376899719238
Validation loss: 5.159105539321899

Epoch: 5| Step: 11
Training loss: 6.003147602081299
Validation loss: 5.149945318698883

Epoch: 5| Step: 0
Training loss: 4.371251106262207
Validation loss: 5.141063729921977

Epoch: 5| Step: 1
Training loss: 4.674498558044434
Validation loss: 5.131988088289897

Epoch: 5| Step: 2
Training loss: 5.156035423278809
Validation loss: 5.123327950636546

Epoch: 5| Step: 3
Training loss: 5.443140506744385
Validation loss: 5.114250004291534

Epoch: 5| Step: 4
Training loss: 4.384342670440674
Validation loss: 5.105403860410054

Epoch: 5| Step: 5
Training loss: 4.952508926391602
Validation loss: 5.096287806828816

Epoch: 5| Step: 6
Training loss: 7.054818153381348
Validation loss: 5.0869571169217425

Epoch: 5| Step: 7
Training loss: 6.184636116027832
Validation loss: 5.077967047691345

Epoch: 5| Step: 8
Training loss: 4.266003608703613
Validation loss: 5.069092353185018

Epoch: 5| Step: 9
Training loss: 5.610366344451904
Validation loss: 5.059914410114288

Epoch: 5| Step: 10
Training loss: 5.377554893493652
Validation loss: 5.051024417082469

Epoch: 5| Step: 11
Training loss: 2.2054553031921387
Validation loss: 5.042116850614548

Epoch: 6| Step: 0
Training loss: 5.519550800323486
Validation loss: 5.033406396706899

Epoch: 5| Step: 1
Training loss: 5.003340244293213
Validation loss: 5.024953345457713

Epoch: 5| Step: 2
Training loss: 4.803493499755859
Validation loss: 5.016071538130443

Epoch: 5| Step: 3
Training loss: 6.452530860900879
Validation loss: 5.007716457049052

Epoch: 5| Step: 4
Training loss: 4.464929103851318
Validation loss: 4.998870372772217

Epoch: 5| Step: 5
Training loss: 4.581150531768799
Validation loss: 4.990685184796651

Epoch: 5| Step: 6
Training loss: 4.9469475746154785
Validation loss: 4.982273320357005

Epoch: 5| Step: 7
Training loss: 5.779998779296875
Validation loss: 4.973920822143555

Epoch: 5| Step: 8
Training loss: 5.853084564208984
Validation loss: 4.965674519538879

Epoch: 5| Step: 9
Training loss: 4.315905570983887
Validation loss: 4.95755656560262

Epoch: 5| Step: 10
Training loss: 3.7472853660583496
Validation loss: 4.949546953042348

Epoch: 5| Step: 11
Training loss: 6.621697425842285
Validation loss: 4.941973507404327

Epoch: 7| Step: 0
Training loss: 4.880105495452881
Validation loss: 4.9342835744222

Epoch: 5| Step: 1
Training loss: 4.582455635070801
Validation loss: 4.926451841990153

Epoch: 5| Step: 2
Training loss: 4.659444332122803
Validation loss: 4.919232149918874

Epoch: 5| Step: 3
Training loss: 4.501328945159912
Validation loss: 4.912266115347545

Epoch: 5| Step: 4
Training loss: 5.726243019104004
Validation loss: 4.905557304620743

Epoch: 5| Step: 5
Training loss: 5.454878807067871
Validation loss: 4.898995379606883

Epoch: 5| Step: 6
Training loss: 4.9384446144104
Validation loss: 4.892577290534973

Epoch: 5| Step: 7
Training loss: 5.342739582061768
Validation loss: 4.886204838752747

Epoch: 5| Step: 8
Training loss: 5.007273197174072
Validation loss: 4.8799635370572405

Epoch: 5| Step: 9
Training loss: 4.975720405578613
Validation loss: 4.873756607373555

Epoch: 5| Step: 10
Training loss: 4.398743629455566
Validation loss: 4.867935240268707

Epoch: 5| Step: 11
Training loss: 6.7858195304870605
Validation loss: 4.861498475074768

Epoch: 8| Step: 0
Training loss: 4.800809383392334
Validation loss: 4.855715850989024

Epoch: 5| Step: 1
Training loss: 4.455501556396484
Validation loss: 4.849690357844035

Epoch: 5| Step: 2
Training loss: 5.752924919128418
Validation loss: 4.843850165605545

Epoch: 5| Step: 3
Training loss: 4.170735836029053
Validation loss: 4.838242669900258

Epoch: 5| Step: 4
Training loss: 4.966538429260254
Validation loss: 4.831840713818868

Epoch: 5| Step: 5
Training loss: 4.670763969421387
Validation loss: 4.825806061426799

Epoch: 5| Step: 6
Training loss: 4.596499919891357
Validation loss: 4.820372641086578

Epoch: 5| Step: 7
Training loss: 6.211810111999512
Validation loss: 4.814725985129674

Epoch: 5| Step: 8
Training loss: 4.562501430511475
Validation loss: 4.808783411979675

Epoch: 5| Step: 9
Training loss: 4.801570892333984
Validation loss: 4.803187628587087

Epoch: 5| Step: 10
Training loss: 5.0098371505737305
Validation loss: 4.797586619853973

Epoch: 5| Step: 11
Training loss: 5.182511329650879
Validation loss: 4.791768113772075

Epoch: 9| Step: 0
Training loss: 4.851880073547363
Validation loss: 4.786599338054657

Epoch: 5| Step: 1
Training loss: 5.3458733558654785
Validation loss: 4.781478583812714

Epoch: 5| Step: 2
Training loss: 4.226813316345215
Validation loss: 4.776318808396657

Epoch: 5| Step: 3
Training loss: 4.608388900756836
Validation loss: 4.77128545443217

Epoch: 5| Step: 4
Training loss: 4.626332759857178
Validation loss: 4.766259729862213

Epoch: 5| Step: 5
Training loss: 4.903517723083496
Validation loss: 4.76130810379982

Epoch: 5| Step: 6
Training loss: 4.713473320007324
Validation loss: 4.7561729947725935

Epoch: 5| Step: 7
Training loss: 5.140942096710205
Validation loss: 4.751189152399699

Epoch: 5| Step: 8
Training loss: 4.836315155029297
Validation loss: 4.746000607808431

Epoch: 5| Step: 9
Training loss: 4.467984199523926
Validation loss: 4.740986714760463

Epoch: 5| Step: 10
Training loss: 5.564510345458984
Validation loss: 4.736204365889232

Epoch: 5| Step: 11
Training loss: 5.26348352432251
Validation loss: 4.7305536071459455

Epoch: 10| Step: 0
Training loss: 4.883945465087891
Validation loss: 4.725713868935903

Epoch: 5| Step: 1
Training loss: 5.547761917114258
Validation loss: 4.720342993736267

Epoch: 5| Step: 2
Training loss: 4.4417643547058105
Validation loss: 4.714889466762543

Epoch: 5| Step: 3
Training loss: 5.1031646728515625
Validation loss: 4.710233787695567

Epoch: 5| Step: 4
Training loss: 4.515394687652588
Validation loss: 4.70416937271754

Epoch: 5| Step: 5
Training loss: 4.509804725646973
Validation loss: 4.6996792157491045

Epoch: 5| Step: 6
Training loss: 4.481095314025879
Validation loss: 4.6943754851818085

Epoch: 5| Step: 7
Training loss: 5.099135398864746
Validation loss: 4.68893176317215

Epoch: 5| Step: 8
Training loss: 4.694741725921631
Validation loss: 4.6838934024175005

Epoch: 5| Step: 9
Training loss: 4.45798397064209
Validation loss: 4.678697357575099

Epoch: 5| Step: 10
Training loss: 4.75448751449585
Validation loss: 4.673793733119965

Epoch: 5| Step: 11
Training loss: 6.026246070861816
Validation loss: 4.6687707006931305

Epoch: 11| Step: 0
Training loss: 4.938377380371094
Validation loss: 4.663869023323059

Epoch: 5| Step: 1
Training loss: 5.305876731872559
Validation loss: 4.659107754627864

Epoch: 5| Step: 2
Training loss: 4.093419075012207
Validation loss: 4.654219547907512

Epoch: 5| Step: 3
Training loss: 5.024278163909912
Validation loss: 4.649635016918182

Epoch: 5| Step: 4
Training loss: 4.217379570007324
Validation loss: 4.644949654738109

Epoch: 5| Step: 5
Training loss: 4.580828666687012
Validation loss: 4.640360713005066

Epoch: 5| Step: 6
Training loss: 5.431223392486572
Validation loss: 4.635950227578481

Epoch: 5| Step: 7
Training loss: 4.596203804016113
Validation loss: 4.631119887034099

Epoch: 5| Step: 8
Training loss: 5.179951190948486
Validation loss: 4.62655504544576

Epoch: 5| Step: 9
Training loss: 5.085202217102051
Validation loss: 4.621632516384125

Epoch: 5| Step: 10
Training loss: 3.962873935699463
Validation loss: 4.616941034793854

Epoch: 5| Step: 11
Training loss: 3.21978759765625
Validation loss: 4.6122669378916425

Epoch: 12| Step: 0
Training loss: 5.022674560546875
Validation loss: 4.607808430989583

Epoch: 5| Step: 1
Training loss: 5.155093193054199
Validation loss: 4.602928817272186

Epoch: 5| Step: 2
Training loss: 4.091458320617676
Validation loss: 4.598412215709686

Epoch: 5| Step: 3
Training loss: 4.599559783935547
Validation loss: 4.593860228856404

Epoch: 5| Step: 4
Training loss: 5.468599796295166
Validation loss: 4.589163998762767

Epoch: 5| Step: 5
Training loss: 3.8330562114715576
Validation loss: 4.584957838058472

Epoch: 5| Step: 6
Training loss: 3.688048839569092
Validation loss: 4.580753564834595

Epoch: 5| Step: 7
Training loss: 4.575315952301025
Validation loss: 4.575927913188934

Epoch: 5| Step: 8
Training loss: 4.270163059234619
Validation loss: 4.571018834908803

Epoch: 5| Step: 9
Training loss: 6.080445766448975
Validation loss: 4.56650639573733

Epoch: 5| Step: 10
Training loss: 4.639862060546875
Validation loss: 4.562022904555003

Epoch: 5| Step: 11
Training loss: 5.248462200164795
Validation loss: 4.557252009709676

Epoch: 13| Step: 0
Training loss: 5.0556135177612305
Validation loss: 4.552405695120494

Epoch: 5| Step: 1
Training loss: 4.957395076751709
Validation loss: 4.54763134320577

Epoch: 5| Step: 2
Training loss: 4.5391998291015625
Validation loss: 4.543057759602864

Epoch: 5| Step: 3
Training loss: 4.424993991851807
Validation loss: 4.5383983453114825

Epoch: 5| Step: 4
Training loss: 4.654438018798828
Validation loss: 4.53316871325175

Epoch: 5| Step: 5
Training loss: 5.00540828704834
Validation loss: 4.528442889451981

Epoch: 5| Step: 6
Training loss: 4.868889808654785
Validation loss: 4.523710012435913

Epoch: 5| Step: 7
Training loss: 4.3837127685546875
Validation loss: 4.518592019875844

Epoch: 5| Step: 8
Training loss: 3.955918788909912
Validation loss: 4.514157732327779

Epoch: 5| Step: 9
Training loss: 4.82344388961792
Validation loss: 4.509230136871338

Epoch: 5| Step: 10
Training loss: 4.162482261657715
Validation loss: 4.504893670479457

Epoch: 5| Step: 11
Training loss: 5.296229362487793
Validation loss: 4.500126371781032

Epoch: 14| Step: 0
Training loss: 4.462684631347656
Validation loss: 4.495450258255005

Epoch: 5| Step: 1
Training loss: 4.962218284606934
Validation loss: 4.490620841582616

Epoch: 5| Step: 2
Training loss: 3.783390760421753
Validation loss: 4.486084123452504

Epoch: 5| Step: 3
Training loss: 4.328090190887451
Validation loss: 4.480582485596339

Epoch: 5| Step: 4
Training loss: 4.047575950622559
Validation loss: 4.475542942682902

Epoch: 5| Step: 5
Training loss: 5.278765678405762
Validation loss: 4.470935006936391

Epoch: 5| Step: 6
Training loss: 5.306271553039551
Validation loss: 4.465901672840118

Epoch: 5| Step: 7
Training loss: 4.583560943603516
Validation loss: 4.461046367883682

Epoch: 5| Step: 8
Training loss: 4.114573001861572
Validation loss: 4.455639878908793

Epoch: 5| Step: 9
Training loss: 4.696686744689941
Validation loss: 4.450412323077519

Epoch: 5| Step: 10
Training loss: 4.774322509765625
Validation loss: 4.445412258307139

Epoch: 5| Step: 11
Training loss: 4.80026912689209
Validation loss: 4.440099219481151

Epoch: 15| Step: 0
Training loss: 4.4830451011657715
Validation loss: 4.435324668884277

Epoch: 5| Step: 1
Training loss: 5.018497467041016
Validation loss: 4.430431514978409

Epoch: 5| Step: 2
Training loss: 4.847777843475342
Validation loss: 4.425434162219365

Epoch: 5| Step: 3
Training loss: 4.963432312011719
Validation loss: 4.420697192351024

Epoch: 5| Step: 4
Training loss: 4.0607194900512695
Validation loss: 4.415511627991994

Epoch: 5| Step: 5
Training loss: 3.8821189403533936
Validation loss: 4.409806410471599

Epoch: 5| Step: 6
Training loss: 4.760867118835449
Validation loss: 4.404806514581044

Epoch: 5| Step: 7
Training loss: 3.8590164184570312
Validation loss: 4.399921735127767

Epoch: 5| Step: 8
Training loss: 4.334503173828125
Validation loss: 4.394075791041057

Epoch: 5| Step: 9
Training loss: 5.531742095947266
Validation loss: 4.388986388842265

Epoch: 5| Step: 10
Training loss: 4.255673408508301
Validation loss: 4.383837739626567

Epoch: 5| Step: 11
Training loss: 3.315666913986206
Validation loss: 4.379317035277684

Epoch: 16| Step: 0
Training loss: 5.103606700897217
Validation loss: 4.376878470182419

Epoch: 5| Step: 1
Training loss: 4.476578235626221
Validation loss: 4.368469536304474

Epoch: 5| Step: 2
Training loss: 4.03285026550293
Validation loss: 4.362670302391052

Epoch: 5| Step: 3
Training loss: 5.491421699523926
Validation loss: 4.35962238907814

Epoch: 5| Step: 4
Training loss: 3.9259238243103027
Validation loss: 4.355801383654277

Epoch: 5| Step: 5
Training loss: 4.027360916137695
Validation loss: 4.351294378439586

Epoch: 5| Step: 6
Training loss: 4.738918304443359
Validation loss: 4.344183226426442

Epoch: 5| Step: 7
Training loss: 5.376555919647217
Validation loss: 4.337955762942632

Epoch: 5| Step: 8
Training loss: 4.695991039276123
Validation loss: 4.332017223040263

Epoch: 5| Step: 9
Training loss: 3.5675957202911377
Validation loss: 4.32955006758372

Epoch: 5| Step: 10
Training loss: 3.818436861038208
Validation loss: 4.322087585926056

Epoch: 5| Step: 11
Training loss: 3.973982810974121
Validation loss: 4.318353672822316

Epoch: 17| Step: 0
Training loss: 3.850698947906494
Validation loss: 4.315528492132823

Epoch: 5| Step: 1
Training loss: 4.920435428619385
Validation loss: 4.3110666672388716

Epoch: 5| Step: 2
Training loss: 3.905406951904297
Validation loss: 4.3054052491982775

Epoch: 5| Step: 3
Training loss: 4.558953285217285
Validation loss: 4.299100657304128

Epoch: 5| Step: 4
Training loss: 5.406503677368164
Validation loss: 4.293589115142822

Epoch: 5| Step: 5
Training loss: 4.621058464050293
Validation loss: 4.287254552046458

Epoch: 5| Step: 6
Training loss: 3.9493331909179688
Validation loss: 4.281814108292262

Epoch: 5| Step: 7
Training loss: 4.678181171417236
Validation loss: 4.27686192591985

Epoch: 5| Step: 8
Training loss: 3.614327907562256
Validation loss: 4.271792312463124

Epoch: 5| Step: 9
Training loss: 5.233588695526123
Validation loss: 4.265347023804982

Epoch: 5| Step: 10
Training loss: 3.681452989578247
Validation loss: 4.260186632474263

Epoch: 5| Step: 11
Training loss: 5.029951095581055
Validation loss: 4.256873309612274

Epoch: 18| Step: 0
Training loss: 4.224111557006836
Validation loss: 4.252404699722926

Epoch: 5| Step: 1
Training loss: 3.668104648590088
Validation loss: 4.246191918849945

Epoch: 5| Step: 2
Training loss: 5.020400047302246
Validation loss: 4.2394433716932935

Epoch: 5| Step: 3
Training loss: 4.630772590637207
Validation loss: 4.235179781913757

Epoch: 5| Step: 4
Training loss: 4.382636070251465
Validation loss: 4.2308381994565325

Epoch: 5| Step: 5
Training loss: 3.2555675506591797
Validation loss: 4.227307905753453

Epoch: 5| Step: 6
Training loss: 5.119917869567871
Validation loss: 4.220791945854823

Epoch: 5| Step: 7
Training loss: 5.248248100280762
Validation loss: 4.213937819004059

Epoch: 5| Step: 8
Training loss: 4.3875837326049805
Validation loss: 4.209034661451976

Epoch: 5| Step: 9
Training loss: 3.9830288887023926
Validation loss: 4.204850842555364

Epoch: 5| Step: 10
Training loss: 4.115496635437012
Validation loss: 4.200141916672389

Epoch: 5| Step: 11
Training loss: 3.7342073917388916
Validation loss: 4.193686266740163

Epoch: 19| Step: 0
Training loss: 4.360995769500732
Validation loss: 4.187531749407451

Epoch: 5| Step: 1
Training loss: 4.407726287841797
Validation loss: 4.183267533779144

Epoch: 5| Step: 2
Training loss: 2.510744333267212
Validation loss: 4.179658989111583

Epoch: 5| Step: 3
Training loss: 4.494372367858887
Validation loss: 4.174294998248418

Epoch: 5| Step: 4
Training loss: 4.010653972625732
Validation loss: 4.169362743695577

Epoch: 5| Step: 5
Training loss: 4.621214866638184
Validation loss: 4.163064638773601

Epoch: 5| Step: 6
Training loss: 4.744168281555176
Validation loss: 4.158375044663747

Epoch: 5| Step: 7
Training loss: 4.649611473083496
Validation loss: 4.154285430908203

Epoch: 5| Step: 8
Training loss: 4.925971508026123
Validation loss: 4.150027354558309

Epoch: 5| Step: 9
Training loss: 4.034634113311768
Validation loss: 4.143902470668157

Epoch: 5| Step: 10
Training loss: 4.963123321533203
Validation loss: 4.138476530710856

Epoch: 5| Step: 11
Training loss: 2.1118621826171875
Validation loss: 4.133501023054123

Epoch: 20| Step: 0
Training loss: 3.5291073322296143
Validation loss: 4.129851390918096

Epoch: 5| Step: 1
Training loss: 4.23349666595459
Validation loss: 4.124623169501622

Epoch: 5| Step: 2
Training loss: 4.8365936279296875
Validation loss: 4.119116187095642

Epoch: 5| Step: 3
Training loss: 4.871020317077637
Validation loss: 4.113399217526118

Epoch: 5| Step: 4
Training loss: 3.7145285606384277
Validation loss: 4.109335611263911

Epoch: 5| Step: 5
Training loss: 3.865051746368408
Validation loss: 4.104804823795955

Epoch: 5| Step: 6
Training loss: 4.42746114730835
Validation loss: 4.099221815665563

Epoch: 5| Step: 7
Training loss: 4.125008583068848
Validation loss: 4.09538729985555

Epoch: 5| Step: 8
Training loss: 5.196796417236328
Validation loss: 4.089413334925969

Epoch: 5| Step: 9
Training loss: 3.8469974994659424
Validation loss: 4.0844608545303345

Epoch: 5| Step: 10
Training loss: 3.849944591522217
Validation loss: 4.080891340970993

Epoch: 5| Step: 11
Training loss: 5.2115068435668945
Validation loss: 4.076637953519821

Epoch: 21| Step: 0
Training loss: 4.939127445220947
Validation loss: 4.069849491119385

Epoch: 5| Step: 1
Training loss: 4.202641487121582
Validation loss: 4.065969347953796

Epoch: 5| Step: 2
Training loss: 4.09161376953125
Validation loss: 4.063919802506764

Epoch: 5| Step: 3
Training loss: 4.690652370452881
Validation loss: 4.059972157080968

Epoch: 5| Step: 4
Training loss: 4.090216159820557
Validation loss: 4.0524517099062605

Epoch: 5| Step: 5
Training loss: 3.803459644317627
Validation loss: 4.046927163998286

Epoch: 5| Step: 6
Training loss: 4.570008277893066
Validation loss: 4.041725029548009

Epoch: 5| Step: 7
Training loss: 3.471914291381836
Validation loss: 4.038060088952382

Epoch: 5| Step: 8
Training loss: 3.980461835861206
Validation loss: 4.034288197755814

Epoch: 5| Step: 9
Training loss: 4.140455722808838
Validation loss: 4.028821070988973

Epoch: 5| Step: 10
Training loss: 4.186039924621582
Validation loss: 4.0239807069301605

Epoch: 5| Step: 11
Training loss: 3.838841438293457
Validation loss: 4.018602112929027

Epoch: 22| Step: 0
Training loss: 3.4020564556121826
Validation loss: 4.013723770777385

Epoch: 5| Step: 1
Training loss: 4.947731018066406
Validation loss: 4.0095787445704145

Epoch: 5| Step: 2
Training loss: 4.268077850341797
Validation loss: 4.004482915004094

Epoch: 5| Step: 3
Training loss: 4.5217132568359375
Validation loss: 3.999492178360621

Epoch: 5| Step: 4
Training loss: 3.1467723846435547
Validation loss: 3.994344582160314

Epoch: 5| Step: 5
Training loss: 3.927255153656006
Validation loss: 3.9896878401438394

Epoch: 5| Step: 6
Training loss: 3.8655686378479004
Validation loss: 3.9858104487260184

Epoch: 5| Step: 7
Training loss: 4.316857814788818
Validation loss: 3.981367210547129

Epoch: 5| Step: 8
Training loss: 4.033663749694824
Validation loss: 3.9756522675355277

Epoch: 5| Step: 9
Training loss: 4.6517438888549805
Validation loss: 3.9711636503537497

Epoch: 5| Step: 10
Training loss: 4.559531211853027
Validation loss: 3.96713525056839

Epoch: 5| Step: 11
Training loss: 3.4117679595947266
Validation loss: 3.963090936342875

Epoch: 23| Step: 0
Training loss: 3.7621371746063232
Validation loss: 3.9580012361208596

Epoch: 5| Step: 1
Training loss: 3.25462007522583
Validation loss: 3.9533638457457223

Epoch: 5| Step: 2
Training loss: 4.50484561920166
Validation loss: 3.94920019308726

Epoch: 5| Step: 3
Training loss: 4.6979522705078125
Validation loss: 3.9436845580736795

Epoch: 5| Step: 4
Training loss: 4.210391044616699
Validation loss: 3.939896066983541

Epoch: 5| Step: 5
Training loss: 4.3154683113098145
Validation loss: 3.9349862039089203

Epoch: 5| Step: 6
Training loss: 4.625929832458496
Validation loss: 3.9305791656176248

Epoch: 5| Step: 7
Training loss: 3.1713366508483887
Validation loss: 3.9251730839411416

Epoch: 5| Step: 8
Training loss: 4.007872581481934
Validation loss: 3.920526921749115

Epoch: 5| Step: 9
Training loss: 4.332741737365723
Validation loss: 3.915956715742747

Epoch: 5| Step: 10
Training loss: 4.1370744705200195
Validation loss: 3.911770443121592

Epoch: 5| Step: 11
Training loss: 3.5026912689208984
Validation loss: 3.907024393479029

Epoch: 24| Step: 0
Training loss: 4.665026664733887
Validation loss: 3.902252674102783

Epoch: 5| Step: 1
Training loss: 3.6068718433380127
Validation loss: 3.897922178109487

Epoch: 5| Step: 2
Training loss: 3.665743350982666
Validation loss: 3.8931082785129547

Epoch: 5| Step: 3
Training loss: 4.674109935760498
Validation loss: 3.88861945271492

Epoch: 5| Step: 4
Training loss: 3.97367787361145
Validation loss: 3.8844651679197946

Epoch: 5| Step: 5
Training loss: 4.75943660736084
Validation loss: 3.879179984331131

Epoch: 5| Step: 6
Training loss: 2.817476749420166
Validation loss: 3.874332368373871

Epoch: 5| Step: 7
Training loss: 3.6642818450927734
Validation loss: 3.869827091693878

Epoch: 5| Step: 8
Training loss: 3.786144733428955
Validation loss: 3.865809977054596

Epoch: 5| Step: 9
Training loss: 4.129435062408447
Validation loss: 3.861129770676295

Epoch: 5| Step: 10
Training loss: 4.539604663848877
Validation loss: 3.856864978869756

Epoch: 5| Step: 11
Training loss: 4.3402557373046875
Validation loss: 3.8525337874889374

Epoch: 25| Step: 0
Training loss: 3.816486358642578
Validation loss: 3.848108450571696

Epoch: 5| Step: 1
Training loss: 4.564394474029541
Validation loss: 3.843818167845408

Epoch: 5| Step: 2
Training loss: 3.3338229656219482
Validation loss: 3.8386007249355316

Epoch: 5| Step: 3
Training loss: 4.24124813079834
Validation loss: 3.834079305330912

Epoch: 5| Step: 4
Training loss: 3.6227450370788574
Validation loss: 3.8301057517528534

Epoch: 5| Step: 5
Training loss: 4.295106410980225
Validation loss: 3.82474751273791

Epoch: 5| Step: 6
Training loss: 3.981505870819092
Validation loss: 3.8206056356430054

Epoch: 5| Step: 7
Training loss: 4.513866424560547
Validation loss: 3.8159606059392295

Epoch: 5| Step: 8
Training loss: 3.5725834369659424
Validation loss: 3.8115630944569907

Epoch: 5| Step: 9
Training loss: 3.724430799484253
Validation loss: 3.8070944945017495

Epoch: 5| Step: 10
Training loss: 3.9737422466278076
Validation loss: 3.8017561038335166

Epoch: 5| Step: 11
Training loss: 4.5880818367004395
Validation loss: 3.7970400551954904

Epoch: 26| Step: 0
Training loss: 4.047441005706787
Validation loss: 3.7924793561299643

Epoch: 5| Step: 1
Training loss: 2.9805996417999268
Validation loss: 3.7879712879657745

Epoch: 5| Step: 2
Training loss: 3.9656596183776855
Validation loss: 3.7836622297763824

Epoch: 5| Step: 3
Training loss: 4.877255916595459
Validation loss: 3.7793220380942025

Epoch: 5| Step: 4
Training loss: 4.200009346008301
Validation loss: 3.774899939695994

Epoch: 5| Step: 5
Training loss: 3.9871582984924316
Validation loss: 3.7701480984687805

Epoch: 5| Step: 6
Training loss: 3.621075391769409
Validation loss: 3.7657087047894797

Epoch: 5| Step: 7
Training loss: 4.517510414123535
Validation loss: 3.7616460422674813

Epoch: 5| Step: 8
Training loss: 3.183126449584961
Validation loss: 3.757140725851059

Epoch: 5| Step: 9
Training loss: 3.7642734050750732
Validation loss: 3.752572695414225

Epoch: 5| Step: 10
Training loss: 4.046486854553223
Validation loss: 3.7466621696949005

Epoch: 5| Step: 11
Training loss: 4.023111820220947
Validation loss: 3.7423945566018424

Epoch: 27| Step: 0
Training loss: 3.515923261642456
Validation loss: 3.73770672082901

Epoch: 5| Step: 1
Training loss: 3.634547710418701
Validation loss: 3.733849803606669

Epoch: 5| Step: 2
Training loss: 3.5103821754455566
Validation loss: 3.7293298045794168

Epoch: 5| Step: 3
Training loss: 4.651949405670166
Validation loss: 3.72452845176061

Epoch: 5| Step: 4
Training loss: 4.23319149017334
Validation loss: 3.7206419507662454

Epoch: 5| Step: 5
Training loss: 3.6346702575683594
Validation loss: 3.715583622455597

Epoch: 5| Step: 6
Training loss: 4.075408935546875
Validation loss: 3.7110829949378967

Epoch: 5| Step: 7
Training loss: 4.122122287750244
Validation loss: 3.7061330378055573

Epoch: 5| Step: 8
Training loss: 4.060655117034912
Validation loss: 3.7016651928424835

Epoch: 5| Step: 9
Training loss: 3.739215135574341
Validation loss: 3.697420448064804

Epoch: 5| Step: 10
Training loss: 3.329787492752075
Validation loss: 3.6923336187998452

Epoch: 5| Step: 11
Training loss: 4.478543758392334
Validation loss: 3.688484956820806

Epoch: 28| Step: 0
Training loss: 4.3295698165893555
Validation loss: 3.6835153102874756

Epoch: 5| Step: 1
Training loss: 4.383951663970947
Validation loss: 3.6787365774313607

Epoch: 5| Step: 2
Training loss: 4.097586631774902
Validation loss: 3.6741612454255423

Epoch: 5| Step: 3
Training loss: 4.611668109893799
Validation loss: 3.669291843970617

Epoch: 5| Step: 4
Training loss: 3.896709442138672
Validation loss: 3.663851330677668

Epoch: 5| Step: 5
Training loss: 3.166229009628296
Validation loss: 3.6588399509588876

Epoch: 5| Step: 6
Training loss: 2.934583902359009
Validation loss: 3.6547317504882812

Epoch: 5| Step: 7
Training loss: 3.855527400970459
Validation loss: 3.6504271229108176

Epoch: 5| Step: 8
Training loss: 3.2236666679382324
Validation loss: 3.645448386669159

Epoch: 5| Step: 9
Training loss: 3.6840038299560547
Validation loss: 3.6406301458676658

Epoch: 5| Step: 10
Training loss: 3.8504562377929688
Validation loss: 3.636137475570043

Epoch: 5| Step: 11
Training loss: 3.9299564361572266
Validation loss: 3.6316020290056863

Epoch: 29| Step: 0
Training loss: 3.8649818897247314
Validation loss: 3.626875340938568

Epoch: 5| Step: 1
Training loss: 4.171384334564209
Validation loss: 3.622610479593277

Epoch: 5| Step: 2
Training loss: 4.218262672424316
Validation loss: 3.6174146234989166

Epoch: 5| Step: 3
Training loss: 3.5329742431640625
Validation loss: 3.6127608120441437

Epoch: 5| Step: 4
Training loss: 3.9447569847106934
Validation loss: 3.607765326897303

Epoch: 5| Step: 5
Training loss: 3.4647884368896484
Validation loss: 3.6033005913098655

Epoch: 5| Step: 6
Training loss: 3.296844959259033
Validation loss: 3.598636527856191

Epoch: 5| Step: 7
Training loss: 3.850572109222412
Validation loss: 3.593295137087504

Epoch: 5| Step: 8
Training loss: 4.0158538818359375
Validation loss: 3.5881490409374237

Epoch: 5| Step: 9
Training loss: 3.213313341140747
Validation loss: 3.583640933036804

Epoch: 5| Step: 10
Training loss: 4.17412805557251
Validation loss: 3.5785453816254935

Epoch: 5| Step: 11
Training loss: 2.219729423522949
Validation loss: 3.57342129945755

Epoch: 30| Step: 0
Training loss: 3.7789597511291504
Validation loss: 3.5695170561472573

Epoch: 5| Step: 1
Training loss: 3.18628191947937
Validation loss: 3.565106878678004

Epoch: 5| Step: 2
Training loss: 3.591736316680908
Validation loss: 3.5615114669005075

Epoch: 5| Step: 3
Training loss: 4.243142604827881
Validation loss: 3.556203931570053

Epoch: 5| Step: 4
Training loss: 3.342921495437622
Validation loss: 3.552276154359182

Epoch: 5| Step: 5
Training loss: 3.915858745574951
Validation loss: 3.547579199075699

Epoch: 5| Step: 6
Training loss: 3.5733349323272705
Validation loss: 3.543242613474528

Epoch: 5| Step: 7
Training loss: 3.704777479171753
Validation loss: 3.538479665915171

Epoch: 5| Step: 8
Training loss: 3.831784725189209
Validation loss: 3.534046699603399

Epoch: 5| Step: 9
Training loss: 3.305990219116211
Validation loss: 3.5292232036590576

Epoch: 5| Step: 10
Training loss: 4.376160621643066
Validation loss: 3.5243618885676065

Epoch: 5| Step: 11
Training loss: 3.5773894786834717
Validation loss: 3.5197664300600686

Epoch: 31| Step: 0
Training loss: 4.074216365814209
Validation loss: 3.5147224764029183

Epoch: 5| Step: 1
Training loss: 3.2916553020477295
Validation loss: 3.5098161896069846

Epoch: 5| Step: 2
Training loss: 4.382693290710449
Validation loss: 3.5050679743289948

Epoch: 5| Step: 3
Training loss: 3.3110268115997314
Validation loss: 3.500193436940511

Epoch: 5| Step: 4
Training loss: 2.99324631690979
Validation loss: 3.4951663116614022

Epoch: 5| Step: 5
Training loss: 3.8424861431121826
Validation loss: 3.4900918006896973

Epoch: 5| Step: 6
Training loss: 4.242239952087402
Validation loss: 3.4858062863349915

Epoch: 5| Step: 7
Training loss: 2.877807855606079
Validation loss: 3.4809913436571756

Epoch: 5| Step: 8
Training loss: 3.4232215881347656
Validation loss: 3.4760150611400604

Epoch: 5| Step: 9
Training loss: 3.973047971725464
Validation loss: 3.471021354198456

Epoch: 5| Step: 10
Training loss: 3.946892499923706
Validation loss: 3.4661761124928794

Epoch: 5| Step: 11
Training loss: 2.989048480987549
Validation loss: 3.461767385403315

Epoch: 32| Step: 0
Training loss: 3.748145580291748
Validation loss: 3.457165241241455

Epoch: 5| Step: 1
Training loss: 2.9682884216308594
Validation loss: 3.4540361861387887

Epoch: 5| Step: 2
Training loss: 4.059905052185059
Validation loss: 3.4494316577911377

Epoch: 5| Step: 3
Training loss: 2.870884418487549
Validation loss: 3.4447034895420074

Epoch: 5| Step: 4
Training loss: 5.1114888191223145
Validation loss: 3.4399052361647287

Epoch: 5| Step: 5
Training loss: 3.751642942428589
Validation loss: 3.4348984758059182

Epoch: 5| Step: 6
Training loss: 2.7570624351501465
Validation loss: 3.429740379254023

Epoch: 5| Step: 7
Training loss: 3.2539830207824707
Validation loss: 3.425205171108246

Epoch: 5| Step: 8
Training loss: 3.5656776428222656
Validation loss: 3.4208245873451233

Epoch: 5| Step: 9
Training loss: 3.726191759109497
Validation loss: 3.416945536931356

Epoch: 5| Step: 10
Training loss: 3.837027072906494
Validation loss: 3.411906679471334

Epoch: 5| Step: 11
Training loss: 3.39927339553833
Validation loss: 3.406552016735077

Epoch: 33| Step: 0
Training loss: 3.5398170948028564
Validation loss: 3.401266853014628

Epoch: 5| Step: 1
Training loss: 4.041446208953857
Validation loss: 3.3962020377318063

Epoch: 5| Step: 2
Training loss: 3.887378692626953
Validation loss: 3.3912795980771384

Epoch: 5| Step: 3
Training loss: 2.899517059326172
Validation loss: 3.3865133225917816

Epoch: 5| Step: 4
Training loss: 3.419509172439575
Validation loss: 3.381272037823995

Epoch: 5| Step: 5
Training loss: 3.9011757373809814
Validation loss: 3.376692086458206

Epoch: 5| Step: 6
Training loss: 3.5758602619171143
Validation loss: 3.3720907072226205

Epoch: 5| Step: 7
Training loss: 4.07940673828125
Validation loss: 3.3670499324798584

Epoch: 5| Step: 8
Training loss: 3.225586414337158
Validation loss: 3.361592084169388

Epoch: 5| Step: 9
Training loss: 3.6463236808776855
Validation loss: 3.3573655088742576

Epoch: 5| Step: 10
Training loss: 3.0618882179260254
Validation loss: 3.3521734277407327

Epoch: 5| Step: 11
Training loss: 2.2317938804626465
Validation loss: 3.3471640845139823

Epoch: 34| Step: 0
Training loss: 3.7708611488342285
Validation loss: 3.3440975149472556

Epoch: 5| Step: 1
Training loss: 3.342491865158081
Validation loss: 3.339109400908152

Epoch: 5| Step: 2
Training loss: 2.4136626720428467
Validation loss: 3.3352018197377524

Epoch: 5| Step: 3
Training loss: 3.2932677268981934
Validation loss: 3.3301453590393066

Epoch: 5| Step: 4
Training loss: 4.156026363372803
Validation loss: 3.3257111807664237

Epoch: 5| Step: 5
Training loss: 4.114745140075684
Validation loss: 3.3221482733885446

Epoch: 5| Step: 6
Training loss: 3.4791672229766846
Validation loss: 3.317336469888687

Epoch: 5| Step: 7
Training loss: 3.4226887226104736
Validation loss: 3.3134054144223533

Epoch: 5| Step: 8
Training loss: 4.004638671875
Validation loss: 3.309349298477173

Epoch: 5| Step: 9
Training loss: 3.0693914890289307
Validation loss: 3.304090678691864

Epoch: 5| Step: 10
Training loss: 3.548205852508545
Validation loss: 3.2995150089263916

Epoch: 5| Step: 11
Training loss: 2.5174009799957275
Validation loss: 3.295338918765386

Epoch: 35| Step: 0
Training loss: 4.454251289367676
Validation loss: 3.29034556945165

Epoch: 5| Step: 1
Training loss: 4.179580211639404
Validation loss: 3.2855973740418754

Epoch: 5| Step: 2
Training loss: 2.6825976371765137
Validation loss: 3.2810067534446716

Epoch: 5| Step: 3
Training loss: 3.6801764965057373
Validation loss: 3.2762105564276376

Epoch: 5| Step: 4
Training loss: 3.482205867767334
Validation loss: 3.2718628545602164

Epoch: 5| Step: 5
Training loss: 3.638599395751953
Validation loss: 3.266652594010035

Epoch: 5| Step: 6
Training loss: 2.799790859222412
Validation loss: 3.2621052960554757

Epoch: 5| Step: 7
Training loss: 1.9366915225982666
Validation loss: 3.2573717832565308

Epoch: 5| Step: 8
Training loss: 4.008389472961426
Validation loss: 3.252904166777929

Epoch: 5| Step: 9
Training loss: 3.2498786449432373
Validation loss: 3.248709410429001

Epoch: 5| Step: 10
Training loss: 3.6076972484588623
Validation loss: 3.243707090616226

Epoch: 5| Step: 11
Training loss: 4.309120178222656
Validation loss: 3.239314377307892

Epoch: 36| Step: 0
Training loss: 3.3525567054748535
Validation loss: 3.234859049320221

Epoch: 5| Step: 1
Training loss: 3.0800256729125977
Validation loss: 3.2300084829330444

Epoch: 5| Step: 2
Training loss: 2.9072530269622803
Validation loss: 3.2259374956289926

Epoch: 5| Step: 3
Training loss: 2.999980926513672
Validation loss: 3.2212756176789603

Epoch: 5| Step: 4
Training loss: 3.5875930786132812
Validation loss: 3.2163423895835876

Epoch: 5| Step: 5
Training loss: 3.0442333221435547
Validation loss: 3.2119942605495453

Epoch: 5| Step: 6
Training loss: 3.5844719409942627
Validation loss: 3.207309047381083

Epoch: 5| Step: 7
Training loss: 3.717512845993042
Validation loss: 3.202823797861735

Epoch: 5| Step: 8
Training loss: 3.2436325550079346
Validation loss: 3.1979448894659677

Epoch: 5| Step: 9
Training loss: 3.263596296310425
Validation loss: 3.1929916540781655

Epoch: 5| Step: 10
Training loss: 4.132961273193359
Validation loss: 3.189261188109716

Epoch: 5| Step: 11
Training loss: 5.399096488952637
Validation loss: 3.185073435306549

Epoch: 37| Step: 0
Training loss: 3.3343727588653564
Validation loss: 3.179634471734365

Epoch: 5| Step: 1
Training loss: 3.215681552886963
Validation loss: 3.1757337351640067

Epoch: 5| Step: 2
Training loss: 3.5077500343322754
Validation loss: 3.1710583368937173

Epoch: 5| Step: 3
Training loss: 3.2665297985076904
Validation loss: 3.1657660802205405

Epoch: 5| Step: 4
Training loss: 3.239593505859375
Validation loss: 3.161644369363785

Epoch: 5| Step: 5
Training loss: 3.4621212482452393
Validation loss: 3.1564921736717224

Epoch: 5| Step: 6
Training loss: 2.4819395542144775
Validation loss: 3.1520903209845224

Epoch: 5| Step: 7
Training loss: 2.760969877243042
Validation loss: 3.1475928525129953

Epoch: 5| Step: 8
Training loss: 4.398825168609619
Validation loss: 3.1432386140028634

Epoch: 5| Step: 9
Training loss: 3.5119571685791016
Validation loss: 3.138664980729421

Epoch: 5| Step: 10
Training loss: 3.7201831340789795
Validation loss: 3.1345229844252267

Epoch: 5| Step: 11
Training loss: 2.641916275024414
Validation loss: 3.130676140387853

Epoch: 38| Step: 0
Training loss: 3.3105902671813965
Validation loss: 3.126261055469513

Epoch: 5| Step: 1
Training loss: 2.8592653274536133
Validation loss: 3.12077389160792

Epoch: 5| Step: 2
Training loss: 3.1027514934539795
Validation loss: 3.1167710224787393

Epoch: 5| Step: 3
Training loss: 3.8211848735809326
Validation loss: 3.1126751403013864

Epoch: 5| Step: 4
Training loss: 2.9696850776672363
Validation loss: 3.1089422702789307

Epoch: 5| Step: 5
Training loss: 3.214524030685425
Validation loss: 3.104390472173691

Epoch: 5| Step: 6
Training loss: 2.8070361614227295
Validation loss: 3.100763807694117

Epoch: 5| Step: 7
Training loss: 2.924347162246704
Validation loss: 3.096476823091507

Epoch: 5| Step: 8
Training loss: 3.6612753868103027
Validation loss: 3.0930473605791726

Epoch: 5| Step: 9
Training loss: 3.9231338500976562
Validation loss: 3.088855425516764

Epoch: 5| Step: 10
Training loss: 3.245408296585083
Validation loss: 3.084709276755651

Epoch: 5| Step: 11
Training loss: 5.188412666320801
Validation loss: 3.0811372995376587

Epoch: 39| Step: 0
Training loss: 2.714500665664673
Validation loss: 3.0764142870903015

Epoch: 5| Step: 1
Training loss: 2.3317694664001465
Validation loss: 3.0730884671211243

Epoch: 5| Step: 2
Training loss: 4.04923152923584
Validation loss: 3.070354680220286

Epoch: 5| Step: 3
Training loss: 3.6576437950134277
Validation loss: 3.065633088350296

Epoch: 5| Step: 4
Training loss: 3.51318621635437
Validation loss: 3.06108092268308

Epoch: 5| Step: 5
Training loss: 2.5674195289611816
Validation loss: 3.056226243575414

Epoch: 5| Step: 6
Training loss: 2.955479383468628
Validation loss: 3.0522768000761666

Epoch: 5| Step: 7
Training loss: 3.872610092163086
Validation loss: 3.0488270223140717

Epoch: 5| Step: 8
Training loss: 2.9550700187683105
Validation loss: 3.045145114262899

Epoch: 5| Step: 9
Training loss: 3.4198741912841797
Validation loss: 3.041004161039988

Epoch: 5| Step: 10
Training loss: 3.688256025314331
Validation loss: 3.0372394919395447

Epoch: 5| Step: 11
Training loss: 3.1381287574768066
Validation loss: 3.0330541332562766

Epoch: 40| Step: 0
Training loss: 3.430995225906372
Validation loss: 3.0288250148296356

Epoch: 5| Step: 1
Training loss: 2.87690806388855
Validation loss: 3.024155557155609

Epoch: 5| Step: 2
Training loss: 3.4377872943878174
Validation loss: 3.020608901977539

Epoch: 5| Step: 3
Training loss: 2.7936177253723145
Validation loss: 3.016306827465693

Epoch: 5| Step: 4
Training loss: 3.4558939933776855
Validation loss: 3.0122850139935813

Epoch: 5| Step: 5
Training loss: 3.879786729812622
Validation loss: 3.008117894331614

Epoch: 5| Step: 6
Training loss: 2.6733994483947754
Validation loss: 3.0040359795093536

Epoch: 5| Step: 7
Training loss: 2.622312545776367
Validation loss: 3.0002161661783853

Epoch: 5| Step: 8
Training loss: 3.3069472312927246
Validation loss: 2.9961974720160165

Epoch: 5| Step: 9
Training loss: 3.531079053878784
Validation loss: 2.992202570041021

Epoch: 5| Step: 10
Training loss: 3.1559245586395264
Validation loss: 2.988065004348755

Epoch: 5| Step: 11
Training loss: 3.5509982109069824
Validation loss: 2.984164277712504

Epoch: 41| Step: 0
Training loss: 3.050067186355591
Validation loss: 2.9807708859443665

Epoch: 5| Step: 1
Training loss: 2.2623703479766846
Validation loss: 2.9779839515686035

Epoch: 5| Step: 2
Training loss: 3.953641176223755
Validation loss: 2.97397052248319

Epoch: 5| Step: 3
Training loss: 3.4910824298858643
Validation loss: 2.969514091809591

Epoch: 5| Step: 4
Training loss: 3.1505041122436523
Validation loss: 2.9645023345947266

Epoch: 5| Step: 5
Training loss: 3.3748443126678467
Validation loss: 2.9606295128663382

Epoch: 5| Step: 6
Training loss: 3.1297645568847656
Validation loss: 2.956957827011744

Epoch: 5| Step: 7
Training loss: 2.6747283935546875
Validation loss: 2.9528125623861947

Epoch: 5| Step: 8
Training loss: 3.44205904006958
Validation loss: 2.9494894246260324

Epoch: 5| Step: 9
Training loss: 3.314054012298584
Validation loss: 2.946680615345637

Epoch: 5| Step: 10
Training loss: 2.9841740131378174
Validation loss: 2.9453108410040536

Epoch: 5| Step: 11
Training loss: 2.881542205810547
Validation loss: 2.9387810130914054

Epoch: 42| Step: 0
Training loss: 2.8995096683502197
Validation loss: 2.9339866737524667

Epoch: 5| Step: 1
Training loss: 3.7034430503845215
Validation loss: 2.9311042030652366

Epoch: 5| Step: 2
Training loss: 2.9080069065093994
Validation loss: 2.92728453874588

Epoch: 5| Step: 3
Training loss: 3.27374267578125
Validation loss: 2.923632472753525

Epoch: 5| Step: 4
Training loss: 2.7117838859558105
Validation loss: 2.9195835292339325

Epoch: 5| Step: 5
Training loss: 3.476438045501709
Validation loss: 2.9166749517122903

Epoch: 5| Step: 6
Training loss: 3.041278839111328
Validation loss: 2.912861317396164

Epoch: 5| Step: 7
Training loss: 2.878976821899414
Validation loss: 2.9093350072701774

Epoch: 5| Step: 8
Training loss: 2.656643867492676
Validation loss: 2.9059268136819205

Epoch: 5| Step: 9
Training loss: 3.021496534347534
Validation loss: 2.905628591775894

Epoch: 5| Step: 10
Training loss: 3.4790244102478027
Validation loss: 2.90684566895167

Epoch: 5| Step: 11
Training loss: 4.4383063316345215
Validation loss: 2.8951026995976767

Epoch: 43| Step: 0
Training loss: 3.267749786376953
Validation loss: 2.8909820914268494

Epoch: 5| Step: 1
Training loss: 2.5183804035186768
Validation loss: 2.8879982630411782

Epoch: 5| Step: 2
Training loss: 3.3032069206237793
Validation loss: 2.8845317363739014

Epoch: 5| Step: 3
Training loss: 2.700674057006836
Validation loss: 2.8839756548404694

Epoch: 5| Step: 4
Training loss: 2.706505298614502
Validation loss: 2.8789070546627045

Epoch: 5| Step: 5
Training loss: 2.4091598987579346
Validation loss: 2.873365114132563

Epoch: 5| Step: 6
Training loss: 3.233818769454956
Validation loss: 2.870517502228419

Epoch: 5| Step: 7
Training loss: 3.4371604919433594
Validation loss: 2.8658146063486734

Epoch: 5| Step: 8
Training loss: 3.8151984214782715
Validation loss: 2.8629726568857827

Epoch: 5| Step: 9
Training loss: 3.5335350036621094
Validation loss: 2.8593876361846924

Epoch: 5| Step: 10
Training loss: 3.312490940093994
Validation loss: 2.853798578182856

Epoch: 5| Step: 11
Training loss: 1.4371459484100342
Validation loss: 2.850837548573812

Epoch: 44| Step: 0
Training loss: 2.6901612281799316
Validation loss: 2.847457637389501

Epoch: 5| Step: 1
Training loss: 2.663703441619873
Validation loss: 2.844589332739512

Epoch: 5| Step: 2
Training loss: 3.3796253204345703
Validation loss: 2.842354198296865

Epoch: 5| Step: 3
Training loss: 3.7384800910949707
Validation loss: 2.8386644423007965

Epoch: 5| Step: 4
Training loss: 3.0907018184661865
Validation loss: 2.8351989686489105

Epoch: 5| Step: 5
Training loss: 3.25768780708313
Validation loss: 2.8310336073239646

Epoch: 5| Step: 6
Training loss: 2.906647205352783
Validation loss: 2.826231449842453

Epoch: 5| Step: 7
Training loss: 3.452897548675537
Validation loss: 2.8226213455200195

Epoch: 5| Step: 8
Training loss: 3.1925320625305176
Validation loss: 2.8182918628056846

Epoch: 5| Step: 9
Training loss: 2.2267885208129883
Validation loss: 2.81571027636528

Epoch: 5| Step: 10
Training loss: 2.5517191886901855
Validation loss: 2.811024526755015

Epoch: 5| Step: 11
Training loss: 4.339922904968262
Validation loss: 2.8097356855869293

Epoch: 45| Step: 0
Training loss: 2.6924984455108643
Validation loss: 2.805506487687429

Epoch: 5| Step: 1
Training loss: 2.988503932952881
Validation loss: 2.8031193912029266

Epoch: 5| Step: 2
Training loss: 3.3637824058532715
Validation loss: 2.797573894262314

Epoch: 5| Step: 3
Training loss: 3.0176327228546143
Validation loss: 2.793880343437195

Epoch: 5| Step: 4
Training loss: 2.5663411617279053
Validation loss: 2.7900640964508057

Epoch: 5| Step: 5
Training loss: 3.059980869293213
Validation loss: 2.7866347829500833

Epoch: 5| Step: 6
Training loss: 3.1441898345947266
Validation loss: 2.7829566299915314

Epoch: 5| Step: 7
Training loss: 3.717992067337036
Validation loss: 2.778190662463506

Epoch: 5| Step: 8
Training loss: 2.9620614051818848
Validation loss: 2.775826464096705

Epoch: 5| Step: 9
Training loss: 2.5886292457580566
Validation loss: 2.7715376019477844

Epoch: 5| Step: 10
Training loss: 2.7813937664031982
Validation loss: 2.7706396182378135

Epoch: 5| Step: 11
Training loss: 3.494309425354004
Validation loss: 2.766170879205068

Epoch: 46| Step: 0
Training loss: 2.972942590713501
Validation loss: 2.7639619410037994

Epoch: 5| Step: 1
Training loss: 3.101583480834961
Validation loss: 2.758714775244395

Epoch: 5| Step: 2
Training loss: 3.6596457958221436
Validation loss: 2.7549345990022025

Epoch: 5| Step: 3
Training loss: 3.5178885459899902
Validation loss: 2.751555383205414

Epoch: 5| Step: 4
Training loss: 2.625344753265381
Validation loss: 2.7481569051742554

Epoch: 5| Step: 5
Training loss: 2.601724147796631
Validation loss: 2.744829833507538

Epoch: 5| Step: 6
Training loss: 2.0981500148773193
Validation loss: 2.7416505813598633

Epoch: 5| Step: 7
Training loss: 3.4257736206054688
Validation loss: 2.7391360898812613

Epoch: 5| Step: 8
Training loss: 2.4974889755249023
Validation loss: 2.7364456752936044

Epoch: 5| Step: 9
Training loss: 3.098700761795044
Validation loss: 2.7343428134918213

Epoch: 5| Step: 10
Training loss: 3.2443032264709473
Validation loss: 2.728540003299713

Epoch: 5| Step: 11
Training loss: 1.4079983234405518
Validation loss: 2.7248663008213043

Epoch: 47| Step: 0
Training loss: 2.7245185375213623
Validation loss: 2.721993257602056

Epoch: 5| Step: 1
Training loss: 2.8203201293945312
Validation loss: 2.7205901940663657

Epoch: 5| Step: 2
Training loss: 2.674589157104492
Validation loss: 2.7186248997847238

Epoch: 5| Step: 3
Training loss: 3.234213352203369
Validation loss: 2.715881442030271

Epoch: 5| Step: 4
Training loss: 3.2640907764434814
Validation loss: 2.712985893090566

Epoch: 5| Step: 5
Training loss: 2.701817750930786
Validation loss: 2.7098861634731293

Epoch: 5| Step: 6
Training loss: 2.614213228225708
Validation loss: 2.7082443038622537

Epoch: 5| Step: 7
Training loss: 3.1911613941192627
Validation loss: 2.7047654887040458

Epoch: 5| Step: 8
Training loss: 3.2491061687469482
Validation loss: 2.700642536083857

Epoch: 5| Step: 9
Training loss: 2.8665237426757812
Validation loss: 2.69403467575709

Epoch: 5| Step: 10
Training loss: 2.785407543182373
Validation loss: 2.6921664774417877

Epoch: 5| Step: 11
Training loss: 2.5683891773223877
Validation loss: 2.6911592980225882

Epoch: 48| Step: 0
Training loss: 2.612790584564209
Validation loss: 2.687037388483683

Epoch: 5| Step: 1
Training loss: 3.711357831954956
Validation loss: 2.685724208752314

Epoch: 5| Step: 2
Training loss: 2.712310314178467
Validation loss: 2.680210908253988

Epoch: 5| Step: 3
Training loss: 3.2397284507751465
Validation loss: 2.6762727002302804

Epoch: 5| Step: 4
Training loss: 2.8648457527160645
Validation loss: 2.6723942706982293

Epoch: 5| Step: 5
Training loss: 2.6519384384155273
Validation loss: 2.670984427134196

Epoch: 5| Step: 6
Training loss: 2.607708692550659
Validation loss: 2.66890342036883

Epoch: 5| Step: 7
Training loss: 2.731889009475708
Validation loss: 2.6664908031622567

Epoch: 5| Step: 8
Training loss: 2.748605251312256
Validation loss: 2.662431448698044

Epoch: 5| Step: 9
Training loss: 2.7949349880218506
Validation loss: 2.659986754258474

Epoch: 5| Step: 10
Training loss: 3.2425217628479004
Validation loss: 2.656152755022049

Epoch: 5| Step: 11
Training loss: 1.5894179344177246
Validation loss: 2.6511188447475433

Epoch: 49| Step: 0
Training loss: 2.898311138153076
Validation loss: 2.648740222056707

Epoch: 5| Step: 1
Training loss: 2.7229058742523193
Validation loss: 2.644837439060211

Epoch: 5| Step: 2
Training loss: 2.3395590782165527
Validation loss: 2.6439662675062814

Epoch: 5| Step: 3
Training loss: 3.111076593399048
Validation loss: 2.6384565035502114

Epoch: 5| Step: 4
Training loss: 2.5457537174224854
Validation loss: 2.636145909627279

Epoch: 5| Step: 5
Training loss: 3.6517410278320312
Validation loss: 2.637249449888865

Epoch: 5| Step: 6
Training loss: 3.276276111602783
Validation loss: 2.6314929326375327

Epoch: 5| Step: 7
Training loss: 2.6591811180114746
Validation loss: 2.6316107511520386

Epoch: 5| Step: 8
Training loss: 3.1292800903320312
Validation loss: 2.6269259452819824

Epoch: 5| Step: 9
Training loss: 2.562424421310425
Validation loss: 2.6216489473978677

Epoch: 5| Step: 10
Training loss: 2.3438944816589355
Validation loss: 2.618731359640757

Epoch: 5| Step: 11
Training loss: 2.7319395542144775
Validation loss: 2.6167737940947213

Epoch: 50| Step: 0
Training loss: 2.4531285762786865
Validation loss: 2.6146209041277566

Epoch: 5| Step: 1
Training loss: 2.5999276638031006
Validation loss: 2.6095164120197296

Epoch: 5| Step: 2
Training loss: 2.6850132942199707
Validation loss: 2.607323557138443

Epoch: 5| Step: 3
Training loss: 2.6670498847961426
Validation loss: 2.603306621313095

Epoch: 5| Step: 4
Training loss: 3.74469256401062
Validation loss: 2.5993252098560333

Epoch: 5| Step: 5
Training loss: 2.7562851905822754
Validation loss: 2.5956786274909973

Epoch: 5| Step: 6
Training loss: 2.8000330924987793
Validation loss: 2.591043377916018

Epoch: 5| Step: 7
Training loss: 2.262943744659424
Validation loss: 2.5872532526652017

Epoch: 5| Step: 8
Training loss: 3.0456771850585938
Validation loss: 2.58717813094457

Epoch: 5| Step: 9
Training loss: 3.107656240463257
Validation loss: 2.585393706957499

Epoch: 5| Step: 10
Training loss: 2.4459214210510254
Validation loss: 2.5809295177459717

Epoch: 5| Step: 11
Training loss: 3.79341459274292
Validation loss: 2.5772912800312042

Epoch: 51| Step: 0
Training loss: 2.754398822784424
Validation loss: 2.582785020271937

Epoch: 5| Step: 1
Training loss: 2.3978729248046875
Validation loss: 2.575154652198156

Epoch: 5| Step: 2
Training loss: 2.2753500938415527
Validation loss: 2.572128117084503

Epoch: 5| Step: 3
Training loss: 3.24232816696167
Validation loss: 2.5702241907517114

Epoch: 5| Step: 4
Training loss: 2.609588861465454
Validation loss: 2.563892434040705

Epoch: 5| Step: 5
Training loss: 2.380551815032959
Validation loss: 2.558174043893814

Epoch: 5| Step: 6
Training loss: 3.2278430461883545
Validation loss: 2.5546098550160727

Epoch: 5| Step: 7
Training loss: 2.568459987640381
Validation loss: 2.5528301894664764

Epoch: 5| Step: 8
Training loss: 2.501540184020996
Validation loss: 2.551988979180654

Epoch: 5| Step: 9
Training loss: 2.9877407550811768
Validation loss: 2.547838419675827

Epoch: 5| Step: 10
Training loss: 3.2540817260742188
Validation loss: 2.5442024966080985

Epoch: 5| Step: 11
Training loss: 3.4594922065734863
Validation loss: 2.5412273506323495

Epoch: 52| Step: 0
Training loss: 2.971735715866089
Validation loss: 2.5395824710528054

Epoch: 5| Step: 1
Training loss: 2.4691336154937744
Validation loss: 2.537708103656769

Epoch: 5| Step: 2
Training loss: 3.1345152854919434
Validation loss: 2.53306312362353

Epoch: 5| Step: 3
Training loss: 2.657118558883667
Validation loss: 2.5292959113915763

Epoch: 5| Step: 4
Training loss: 2.662339687347412
Validation loss: 2.525067061185837

Epoch: 5| Step: 5
Training loss: 2.5208308696746826
Validation loss: 2.5231863856315613

Epoch: 5| Step: 6
Training loss: 2.521299123764038
Validation loss: 2.520455777645111

Epoch: 5| Step: 7
Training loss: 2.5899341106414795
Validation loss: 2.5178887943426767

Epoch: 5| Step: 8
Training loss: 2.648481845855713
Validation loss: 2.5158845086892447

Epoch: 5| Step: 9
Training loss: 2.689893960952759
Validation loss: 2.512784550587336

Epoch: 5| Step: 10
Training loss: 3.2591500282287598
Validation loss: 2.51182026664416

Epoch: 5| Step: 11
Training loss: 1.625380039215088
Validation loss: 2.5065587162971497

Epoch: 53| Step: 0
Training loss: 2.278169631958008
Validation loss: 2.5024109184741974

Epoch: 5| Step: 1
Training loss: 2.6829888820648193
Validation loss: 2.501388212045034

Epoch: 5| Step: 2
Training loss: 2.584956407546997
Validation loss: 2.500355233748754

Epoch: 5| Step: 3
Training loss: 1.9147287607192993
Validation loss: 2.49857563773791

Epoch: 5| Step: 4
Training loss: 2.8388655185699463
Validation loss: 2.4979108969370523

Epoch: 5| Step: 5
Training loss: 3.321115016937256
Validation loss: 2.49642206231753

Epoch: 5| Step: 6
Training loss: 2.869987964630127
Validation loss: 2.4897994001706443

Epoch: 5| Step: 7
Training loss: 2.9885973930358887
Validation loss: 2.4826170851786933

Epoch: 5| Step: 8
Training loss: 2.9408562183380127
Validation loss: 2.4852972428003945

Epoch: 5| Step: 9
Training loss: 2.424482583999634
Validation loss: 2.479796419541041

Epoch: 5| Step: 10
Training loss: 2.637995719909668
Validation loss: 2.476388603448868

Epoch: 5| Step: 11
Training loss: 2.680405616760254
Validation loss: 2.472426245609919

Epoch: 54| Step: 0
Training loss: 2.5428924560546875
Validation loss: 2.4709293991327286

Epoch: 5| Step: 1
Training loss: 2.4551148414611816
Validation loss: 2.4817582170168557

Epoch: 5| Step: 2
Training loss: 2.7385880947113037
Validation loss: 2.4947870671749115

Epoch: 5| Step: 3
Training loss: 2.01775860786438
Validation loss: 2.4769873519738517

Epoch: 5| Step: 4
Training loss: 2.402052402496338
Validation loss: 2.4623333712418876

Epoch: 5| Step: 5
Training loss: 2.9375503063201904
Validation loss: 2.4632348716259003

Epoch: 5| Step: 6
Training loss: 3.172612428665161
Validation loss: 2.463621368010839

Epoch: 5| Step: 7
Training loss: 3.2619941234588623
Validation loss: 2.4523647824923196

Epoch: 5| Step: 8
Training loss: 2.6197893619537354
Validation loss: 2.451023042201996

Epoch: 5| Step: 9
Training loss: 2.0875513553619385
Validation loss: 2.451018671194712

Epoch: 5| Step: 10
Training loss: 2.868666410446167
Validation loss: 2.4495704074700675

Epoch: 5| Step: 11
Training loss: 2.4318952560424805
Validation loss: 2.44495482246081

Epoch: 55| Step: 0
Training loss: 2.8107738494873047
Validation loss: 2.4414218763510385

Epoch: 5| Step: 1
Training loss: 2.7344906330108643
Validation loss: 2.4414480278889337

Epoch: 5| Step: 2
Training loss: 2.762765407562256
Validation loss: 2.436651587486267

Epoch: 5| Step: 3
Training loss: 2.493166208267212
Validation loss: 2.430521974960963

Epoch: 5| Step: 4
Training loss: 2.4664783477783203
Validation loss: 2.4257798890272775

Epoch: 5| Step: 5
Training loss: 2.2058067321777344
Validation loss: 2.423090154925982

Epoch: 5| Step: 6
Training loss: 2.8617944717407227
Validation loss: 2.4211628437042236

Epoch: 5| Step: 7
Training loss: 2.749842643737793
Validation loss: 2.416572997967402

Epoch: 5| Step: 8
Training loss: 2.3034751415252686
Validation loss: 2.4164288341999054

Epoch: 5| Step: 9
Training loss: 2.607687473297119
Validation loss: 2.4168997506300607

Epoch: 5| Step: 10
Training loss: 2.6064205169677734
Validation loss: 2.4134687582651773

Epoch: 5| Step: 11
Training loss: 3.308997392654419
Validation loss: 2.4077472736438117

Epoch: 56| Step: 0
Training loss: 2.9329304695129395
Validation loss: 2.4055990278720856

Epoch: 5| Step: 1
Training loss: 2.4752724170684814
Validation loss: 2.4040644814570746

Epoch: 5| Step: 2
Training loss: 2.5916600227355957
Validation loss: 2.4009292920430503

Epoch: 5| Step: 3
Training loss: 2.541257858276367
Validation loss: 2.398595074812571

Epoch: 5| Step: 4
Training loss: 2.539898633956909
Validation loss: 2.3954651852448783

Epoch: 5| Step: 5
Training loss: 2.104736328125
Validation loss: 2.3942103385925293

Epoch: 5| Step: 6
Training loss: 2.635514497756958
Validation loss: 2.394585500160853

Epoch: 5| Step: 7
Training loss: 2.8282856941223145
Validation loss: 2.3933075666427612

Epoch: 5| Step: 8
Training loss: 2.493162155151367
Validation loss: 2.3879566540320716

Epoch: 5| Step: 9
Training loss: 3.2112197875976562
Validation loss: 2.3831431766351066

Epoch: 5| Step: 10
Training loss: 1.9314171075820923
Validation loss: 2.3789863884449005

Epoch: 5| Step: 11
Training loss: 2.6632134914398193
Validation loss: 2.380280445019404

Epoch: 57| Step: 0
Training loss: 2.8786046504974365
Validation loss: 2.376566012700399

Epoch: 5| Step: 1
Training loss: 2.6283655166625977
Validation loss: 2.37368776400884

Epoch: 5| Step: 2
Training loss: 2.902963399887085
Validation loss: 2.367997576793035

Epoch: 5| Step: 3
Training loss: 2.001237154006958
Validation loss: 2.367718289295832

Epoch: 5| Step: 4
Training loss: 2.7842917442321777
Validation loss: 2.366832067569097

Epoch: 5| Step: 5
Training loss: 2.419675588607788
Validation loss: 2.365946352481842

Epoch: 5| Step: 6
Training loss: 2.6501107215881348
Validation loss: 2.362176607052485

Epoch: 5| Step: 7
Training loss: 2.6239230632781982
Validation loss: 2.3600082844495773

Epoch: 5| Step: 8
Training loss: 2.733661413192749
Validation loss: 2.354635010162989

Epoch: 5| Step: 9
Training loss: 2.8353562355041504
Validation loss: 2.3573688864707947

Epoch: 5| Step: 10
Training loss: 1.408203125
Validation loss: 2.349416340390841

Epoch: 5| Step: 11
Training loss: 2.850252151489258
Validation loss: 2.3555625478426614

Epoch: 58| Step: 0
Training loss: 2.3470404148101807
Validation loss: 2.351142237583796

Epoch: 5| Step: 1
Training loss: 2.7708325386047363
Validation loss: 2.353123366832733

Epoch: 5| Step: 2
Training loss: 1.883470892906189
Validation loss: 2.3450410465399423

Epoch: 5| Step: 3
Training loss: 2.419649124145508
Validation loss: 2.338828225930532

Epoch: 5| Step: 4
Training loss: 2.7451770305633545
Validation loss: 2.341557949781418

Epoch: 5| Step: 5
Training loss: 2.408109188079834
Validation loss: 2.3447608153025308

Epoch: 5| Step: 6
Training loss: 2.209275484085083
Validation loss: 2.3478451669216156

Epoch: 5| Step: 7
Training loss: 2.8851094245910645
Validation loss: 2.3412284503380456

Epoch: 5| Step: 8
Training loss: 2.725428581237793
Validation loss: 2.3353131711483

Epoch: 5| Step: 9
Training loss: 2.066565990447998
Validation loss: 2.330217401186625

Epoch: 5| Step: 10
Training loss: 3.177138566970825
Validation loss: 2.329214334487915

Epoch: 5| Step: 11
Training loss: 2.9951024055480957
Validation loss: 2.324629565080007

Epoch: 59| Step: 0
Training loss: 2.6081833839416504
Validation loss: 2.3226610819498696

Epoch: 5| Step: 1
Training loss: 2.1857664585113525
Validation loss: 2.3202719539403915

Epoch: 5| Step: 2
Training loss: 2.6242611408233643
Validation loss: 2.318328768014908

Epoch: 5| Step: 3
Training loss: 2.808432102203369
Validation loss: 2.3146909375985465

Epoch: 5| Step: 4
Training loss: 2.432858943939209
Validation loss: 2.3098690112431846

Epoch: 5| Step: 5
Training loss: 2.7969610691070557
Validation loss: 2.3049405167500177

Epoch: 5| Step: 6
Training loss: 2.4327504634857178
Validation loss: 2.3024146258831024

Epoch: 5| Step: 7
Training loss: 2.06065034866333
Validation loss: 2.2985852559407554

Epoch: 5| Step: 8
Training loss: 2.5980191230773926
Validation loss: 2.2991445461908975

Epoch: 5| Step: 9
Training loss: 1.9242525100708008
Validation loss: 2.2934338251749673

Epoch: 5| Step: 10
Training loss: 2.563840866088867
Validation loss: 2.2924340267976127

Epoch: 5| Step: 11
Training loss: 3.578230381011963
Validation loss: 2.2913957039515176

Epoch: 60| Step: 0
Training loss: 1.8639609813690186
Validation loss: 2.285157471895218

Epoch: 5| Step: 1
Training loss: 2.549408197402954
Validation loss: 2.2862520615259805

Epoch: 5| Step: 2
Training loss: 2.3567683696746826
Validation loss: 2.288318400581678

Epoch: 5| Step: 3
Training loss: 3.009610652923584
Validation loss: 2.284255027770996

Epoch: 5| Step: 4
Training loss: 2.254889726638794
Validation loss: 2.2847941319147744

Epoch: 5| Step: 5
Training loss: 2.7325997352600098
Validation loss: 2.282710259159406

Epoch: 5| Step: 6
Training loss: 2.2402148246765137
Validation loss: 2.280854528148969

Epoch: 5| Step: 7
Training loss: 2.3875815868377686
Validation loss: 2.276298855741819

Epoch: 5| Step: 8
Training loss: 2.6388425827026367
Validation loss: 2.2736424108346305

Epoch: 5| Step: 9
Training loss: 2.898172378540039
Validation loss: 2.2654847502708435

Epoch: 5| Step: 10
Training loss: 2.2392818927764893
Validation loss: 2.2663930555184684

Epoch: 5| Step: 11
Training loss: 1.1811431646347046
Validation loss: 2.2620213280121484

Epoch: 61| Step: 0
Training loss: 2.5328969955444336
Validation loss: 2.258289188146591

Epoch: 5| Step: 1
Training loss: 2.134204387664795
Validation loss: 2.2562695940335593

Epoch: 5| Step: 2
Training loss: 2.5113015174865723
Validation loss: 2.253329892953237

Epoch: 5| Step: 3
Training loss: 2.231081008911133
Validation loss: 2.2523725628852844

Epoch: 5| Step: 4
Training loss: 2.2138965129852295
Validation loss: 2.247970695296923

Epoch: 5| Step: 5
Training loss: 2.2312989234924316
Validation loss: 2.243554641803106

Epoch: 5| Step: 6
Training loss: 2.4567863941192627
Validation loss: 2.2451162338256836

Epoch: 5| Step: 7
Training loss: 2.5763230323791504
Validation loss: 2.239955112338066

Epoch: 5| Step: 8
Training loss: 2.5398640632629395
Validation loss: 2.238194098075231

Epoch: 5| Step: 9
Training loss: 2.6846609115600586
Validation loss: 2.2360260685284934

Epoch: 5| Step: 10
Training loss: 2.3779311180114746
Validation loss: 2.2360390722751617

Epoch: 5| Step: 11
Training loss: 2.0857338905334473
Validation loss: 2.2295238773028054

Epoch: 62| Step: 0
Training loss: 1.9436365365982056
Validation loss: 2.231079081694285

Epoch: 5| Step: 1
Training loss: 2.081815242767334
Validation loss: 2.230009004473686

Epoch: 5| Step: 2
Training loss: 2.6432929039001465
Validation loss: 2.232879867156347

Epoch: 5| Step: 3
Training loss: 2.147149085998535
Validation loss: 2.2303879410028458

Epoch: 5| Step: 4
Training loss: 1.9636681079864502
Validation loss: 2.2226068874200187

Epoch: 5| Step: 5
Training loss: 2.642563581466675
Validation loss: 2.224104235569636

Epoch: 5| Step: 6
Training loss: 3.168174982070923
Validation loss: 2.2217970291773477

Epoch: 5| Step: 7
Training loss: 2.370784282684326
Validation loss: 2.215764502684275

Epoch: 5| Step: 8
Training loss: 2.7804067134857178
Validation loss: 2.2090673744678497

Epoch: 5| Step: 9
Training loss: 2.431260108947754
Validation loss: 2.208638161420822

Epoch: 5| Step: 10
Training loss: 2.2853245735168457
Validation loss: 2.2087811827659607

Epoch: 5| Step: 11
Training loss: 0.7465163469314575
Validation loss: 2.208487590154012

Epoch: 63| Step: 0
Training loss: 2.452603578567505
Validation loss: 2.2156952619552612

Epoch: 5| Step: 1
Training loss: 2.3599300384521484
Validation loss: 2.233791301647822

Epoch: 5| Step: 2
Training loss: 2.3362460136413574
Validation loss: 2.207493936022123

Epoch: 5| Step: 3
Training loss: 2.6782469749450684
Validation loss: 2.199243019024531

Epoch: 5| Step: 4
Training loss: 2.395415782928467
Validation loss: 2.194543262322744

Epoch: 5| Step: 5
Training loss: 1.8953368663787842
Validation loss: 2.1932721684376397

Epoch: 5| Step: 6
Training loss: 2.844022274017334
Validation loss: 2.19347017010053

Epoch: 5| Step: 7
Training loss: 2.481334686279297
Validation loss: 2.1943629533052444

Epoch: 5| Step: 8
Training loss: 2.204035520553589
Validation loss: 2.1935243159532547

Epoch: 5| Step: 9
Training loss: 2.1916489601135254
Validation loss: 2.1960431188344955

Epoch: 5| Step: 10
Training loss: 1.9387061595916748
Validation loss: 2.1955303500096

Epoch: 5| Step: 11
Training loss: 3.339355945587158
Validation loss: 2.1925873508056006

Epoch: 64| Step: 0
Training loss: 2.3617844581604004
Validation loss: 2.1869357327620187

Epoch: 5| Step: 1
Training loss: 2.3509883880615234
Validation loss: 2.18422136704127

Epoch: 5| Step: 2
Training loss: 2.637411594390869
Validation loss: 2.18733803431193

Epoch: 5| Step: 3
Training loss: 1.8053619861602783
Validation loss: 2.1966240604718528

Epoch: 5| Step: 4
Training loss: 2.399918794631958
Validation loss: 2.20637916525205

Epoch: 5| Step: 5
Training loss: 2.194934844970703
Validation loss: 2.1962576607863107

Epoch: 5| Step: 6
Training loss: 2.4574689865112305
Validation loss: 2.185945232709249

Epoch: 5| Step: 7
Training loss: 2.17867374420166
Validation loss: 2.1767054746548333

Epoch: 5| Step: 8
Training loss: 2.5642447471618652
Validation loss: 2.174459785223007

Epoch: 5| Step: 9
Training loss: 2.3845231533050537
Validation loss: 2.175695617993673

Epoch: 5| Step: 10
Training loss: 2.3011746406555176
Validation loss: 2.1774223844210305

Epoch: 5| Step: 11
Training loss: 3.12424373626709
Validation loss: 2.1805105954408646

Epoch: 65| Step: 0
Training loss: 1.9973394870758057
Validation loss: 2.1856237997611365

Epoch: 5| Step: 1
Training loss: 2.546144962310791
Validation loss: 2.1911773482958474

Epoch: 5| Step: 2
Training loss: 2.175837755203247
Validation loss: 2.1912828038136163

Epoch: 5| Step: 3
Training loss: 2.43974232673645
Validation loss: 2.184287895758947

Epoch: 5| Step: 4
Training loss: 2.250519275665283
Validation loss: 2.182378133138021

Epoch: 5| Step: 5
Training loss: 2.673492908477783
Validation loss: 2.1782183150450387

Epoch: 5| Step: 6
Training loss: 2.483109712600708
Validation loss: 2.1697501689195633

Epoch: 5| Step: 7
Training loss: 2.8980977535247803
Validation loss: 2.1668332517147064

Epoch: 5| Step: 8
Training loss: 2.399144411087036
Validation loss: 2.1648108462492623

Epoch: 5| Step: 9
Training loss: 1.2391149997711182
Validation loss: 2.1646936237812042

Epoch: 5| Step: 10
Training loss: 2.536712646484375
Validation loss: 2.1625694185495377

Epoch: 5| Step: 11
Training loss: 2.1095330715179443
Validation loss: 2.167458931605021

Epoch: 66| Step: 0
Training loss: 2.9137609004974365
Validation loss: 2.1835434238115945

Epoch: 5| Step: 1
Training loss: 2.761664867401123
Validation loss: 2.18339641392231

Epoch: 5| Step: 2
Training loss: 2.3090672492980957
Validation loss: 2.178682287534078

Epoch: 5| Step: 3
Training loss: 2.5784671306610107
Validation loss: 2.1676483750343323

Epoch: 5| Step: 4
Training loss: 1.8813692331314087
Validation loss: 2.1547435522079468

Epoch: 5| Step: 5
Training loss: 2.170773983001709
Validation loss: 2.1510607103506723

Epoch: 5| Step: 6
Training loss: 2.6730873584747314
Validation loss: 2.1474124689896903

Epoch: 5| Step: 7
Training loss: 2.0404751300811768
Validation loss: 2.146167407433192

Epoch: 5| Step: 8
Training loss: 2.550647497177124
Validation loss: 2.151758536696434

Epoch: 5| Step: 9
Training loss: 2.3160903453826904
Validation loss: 2.1561136891444526

Epoch: 5| Step: 10
Training loss: 1.6545403003692627
Validation loss: 2.154847875237465

Epoch: 5| Step: 11
Training loss: 1.4335191249847412
Validation loss: 2.152401273449262

Epoch: 67| Step: 0
Training loss: 2.2764203548431396
Validation loss: 2.150213435292244

Epoch: 5| Step: 1
Training loss: 2.1002020835876465
Validation loss: 2.146385351816813

Epoch: 5| Step: 2
Training loss: 2.5009987354278564
Validation loss: 2.1414306362469993

Epoch: 5| Step: 3
Training loss: 1.9687455892562866
Validation loss: 2.141521433989207

Epoch: 5| Step: 4
Training loss: 1.9179303646087646
Validation loss: 2.1367779125769935

Epoch: 5| Step: 5
Training loss: 2.6597445011138916
Validation loss: 2.1317489544550576

Epoch: 5| Step: 6
Training loss: 1.9512197971343994
Validation loss: 2.132160191734632

Epoch: 5| Step: 7
Training loss: 3.0152242183685303
Validation loss: 2.1300594359636307

Epoch: 5| Step: 8
Training loss: 2.3834850788116455
Validation loss: 2.122778539856275

Epoch: 5| Step: 9
Training loss: 2.027040481567383
Validation loss: 2.1236331264177957

Epoch: 5| Step: 10
Training loss: 2.3962624073028564
Validation loss: 2.1301024655501046

Epoch: 5| Step: 11
Training loss: 2.6035685539245605
Validation loss: 2.1310689647992453

Epoch: 68| Step: 0
Training loss: 2.3644587993621826
Validation loss: 2.138751372694969

Epoch: 5| Step: 1
Training loss: 2.069037675857544
Validation loss: 2.14144374926885

Epoch: 5| Step: 2
Training loss: 2.2983944416046143
Validation loss: 2.1561325937509537

Epoch: 5| Step: 3
Training loss: 2.370039463043213
Validation loss: 2.150712405641874

Epoch: 5| Step: 4
Training loss: 2.788172483444214
Validation loss: 2.146139696240425

Epoch: 5| Step: 5
Training loss: 2.1156463623046875
Validation loss: 2.134826973080635

Epoch: 5| Step: 6
Training loss: 2.7364401817321777
Validation loss: 2.1228755116462708

Epoch: 5| Step: 7
Training loss: 2.1626269817352295
Validation loss: 2.119091952840487

Epoch: 5| Step: 8
Training loss: 2.131260395050049
Validation loss: 2.1215784500042596

Epoch: 5| Step: 9
Training loss: 1.7707641124725342
Validation loss: 2.123751292626063

Epoch: 5| Step: 10
Training loss: 2.402557849884033
Validation loss: 2.125138357281685

Epoch: 5| Step: 11
Training loss: 2.6965742111206055
Validation loss: 2.129240870475769

Epoch: 69| Step: 0
Training loss: 1.885563611984253
Validation loss: 2.1272291938463845

Epoch: 5| Step: 1
Training loss: 1.726771593093872
Validation loss: 2.1277947276830673

Epoch: 5| Step: 2
Training loss: 2.8269829750061035
Validation loss: 2.1270320117473602

Epoch: 5| Step: 3
Training loss: 2.5214784145355225
Validation loss: 2.1265510668357215

Epoch: 5| Step: 4
Training loss: 1.937351942062378
Validation loss: 2.1240061322848

Epoch: 5| Step: 5
Training loss: 1.9842720031738281
Validation loss: 2.12486931681633

Epoch: 5| Step: 6
Training loss: 2.751044750213623
Validation loss: 2.1197235733270645

Epoch: 5| Step: 7
Training loss: 2.6806511878967285
Validation loss: 2.119798332452774

Epoch: 5| Step: 8
Training loss: 2.3833632469177246
Validation loss: 2.1143787999947867

Epoch: 5| Step: 9
Training loss: 2.627009868621826
Validation loss: 2.1155534783999124

Epoch: 5| Step: 10
Training loss: 1.9561485052108765
Validation loss: 2.11374065776666

Epoch: 5| Step: 11
Training loss: 1.7995948791503906
Validation loss: 2.1072859317064285

Epoch: 70| Step: 0
Training loss: 2.124361038208008
Validation loss: 2.093859687447548

Epoch: 5| Step: 1
Training loss: 1.6898612976074219
Validation loss: 2.1044346690177917

Epoch: 5| Step: 2
Training loss: 2.3809616565704346
Validation loss: 2.1077093333005905

Epoch: 5| Step: 3
Training loss: 2.694657802581787
Validation loss: 2.113706355293592

Epoch: 5| Step: 4
Training loss: 1.8576905727386475
Validation loss: 2.104980160792669

Epoch: 5| Step: 5
Training loss: 2.115230083465576
Validation loss: 2.1057366927464805

Epoch: 5| Step: 6
Training loss: 2.451270341873169
Validation loss: 2.0997678140799203

Epoch: 5| Step: 7
Training loss: 2.249427318572998
Validation loss: 2.0903393526872

Epoch: 5| Step: 8
Training loss: 2.6669039726257324
Validation loss: 2.089941839377085

Epoch: 5| Step: 9
Training loss: 2.212737560272217
Validation loss: 2.089658409357071

Epoch: 5| Step: 10
Training loss: 2.4507484436035156
Validation loss: 2.098174820343653

Epoch: 5| Step: 11
Training loss: 2.989797830581665
Validation loss: 2.098918800552686

Epoch: 71| Step: 0
Training loss: 2.069563388824463
Validation loss: 2.0899040549993515

Epoch: 5| Step: 1
Training loss: 2.4383227825164795
Validation loss: 2.0880379577477775

Epoch: 5| Step: 2
Training loss: 1.8851019144058228
Validation loss: 2.098764250675837

Epoch: 5| Step: 3
Training loss: 2.405442714691162
Validation loss: 2.0921277850866318

Epoch: 5| Step: 4
Training loss: 2.2609469890594482
Validation loss: 2.0929545809825263

Epoch: 5| Step: 5
Training loss: 2.157613754272461
Validation loss: 2.092669889330864

Epoch: 5| Step: 6
Training loss: 2.6024389266967773
Validation loss: 2.0892821649710336

Epoch: 5| Step: 7
Training loss: 2.6615042686462402
Validation loss: 2.0914516150951385

Epoch: 5| Step: 8
Training loss: 2.4076573848724365
Validation loss: 2.0863262762626014

Epoch: 5| Step: 9
Training loss: 1.9840809106826782
Validation loss: 2.0861489325761795

Epoch: 5| Step: 10
Training loss: 2.0850560665130615
Validation loss: 2.08243058125178

Epoch: 5| Step: 11
Training loss: 2.101113796234131
Validation loss: 2.076058735450109

Epoch: 72| Step: 0
Training loss: 2.4119338989257812
Validation loss: 2.0756499965985618

Epoch: 5| Step: 1
Training loss: 2.3608031272888184
Validation loss: 2.0721938461065292

Epoch: 5| Step: 2
Training loss: 1.9248015880584717
Validation loss: 2.0714002599318824

Epoch: 5| Step: 3
Training loss: 2.1579060554504395
Validation loss: 2.070509081085523

Epoch: 5| Step: 4
Training loss: 1.869371771812439
Validation loss: 2.0681891987721124

Epoch: 5| Step: 5
Training loss: 1.7082170248031616
Validation loss: 2.06563238799572

Epoch: 5| Step: 6
Training loss: 2.3906090259552
Validation loss: 2.068628177046776

Epoch: 5| Step: 7
Training loss: 2.9854979515075684
Validation loss: 2.0658465921878815

Epoch: 5| Step: 8
Training loss: 1.8931996822357178
Validation loss: 2.067630057533582

Epoch: 5| Step: 9
Training loss: 2.3520102500915527
Validation loss: 2.0653088142474494

Epoch: 5| Step: 10
Training loss: 2.575605869293213
Validation loss: 2.072222337126732

Epoch: 5| Step: 11
Training loss: 2.7246012687683105
Validation loss: 2.0660302887360253

Epoch: 73| Step: 0
Training loss: 1.6488535404205322
Validation loss: 2.060609151919683

Epoch: 5| Step: 1
Training loss: 2.2752223014831543
Validation loss: 2.074588899811109

Epoch: 5| Step: 2
Training loss: 2.2347970008850098
Validation loss: 2.0768015533685684

Epoch: 5| Step: 3
Training loss: 1.9502182006835938
Validation loss: 2.0835793018341064

Epoch: 5| Step: 4
Training loss: 2.438149929046631
Validation loss: 2.098156953851382

Epoch: 5| Step: 5
Training loss: 2.566680431365967
Validation loss: 2.1014704356590905

Epoch: 5| Step: 6
Training loss: 2.485679864883423
Validation loss: 2.0910204450289407

Epoch: 5| Step: 7
Training loss: 2.1202497482299805
Validation loss: 2.086306616663933

Epoch: 5| Step: 8
Training loss: 1.7437217235565186
Validation loss: 2.084236443042755

Epoch: 5| Step: 9
Training loss: 2.783784866333008
Validation loss: 2.081347862879435

Epoch: 5| Step: 10
Training loss: 2.763134002685547
Validation loss: 2.0712656577428183

Epoch: 5| Step: 11
Training loss: 1.718368649482727
Validation loss: 2.068865180015564

Epoch: 74| Step: 0
Training loss: 2.578781843185425
Validation loss: 2.0703626573085785

Epoch: 5| Step: 1
Training loss: 1.9274723529815674
Validation loss: 2.0615240236123404

Epoch: 5| Step: 2
Training loss: 2.333292245864868
Validation loss: 2.0643123388290405

Epoch: 5| Step: 3
Training loss: 2.130692720413208
Validation loss: 2.0576305290063224

Epoch: 5| Step: 4
Training loss: 2.6138699054718018
Validation loss: 2.0545319567124047

Epoch: 5| Step: 5
Training loss: 2.137305498123169
Validation loss: 2.0488283981879554

Epoch: 5| Step: 6
Training loss: 2.3340466022491455
Validation loss: 2.051474546392759

Epoch: 5| Step: 7
Training loss: 1.6870176792144775
Validation loss: 2.047181357940038

Epoch: 5| Step: 8
Training loss: 1.8976070880889893
Validation loss: 2.0518792122602463

Epoch: 5| Step: 9
Training loss: 2.594489097595215
Validation loss: 2.0414852599302926

Epoch: 5| Step: 10
Training loss: 2.084548234939575
Validation loss: 2.047675977150599

Epoch: 5| Step: 11
Training loss: 3.2897281646728516
Validation loss: 2.0649229139089584

Epoch: 75| Step: 0
Training loss: 2.18853497505188
Validation loss: 2.0592764019966125

Epoch: 5| Step: 1
Training loss: 2.2095441818237305
Validation loss: 2.0585435231526694

Epoch: 5| Step: 2
Training loss: 2.07881760597229
Validation loss: 2.0510999113321304

Epoch: 5| Step: 3
Training loss: 2.648190498352051
Validation loss: 2.051772346099218

Epoch: 5| Step: 4
Training loss: 1.9955803155899048
Validation loss: 2.049692859252294

Epoch: 5| Step: 5
Training loss: 2.49052095413208
Validation loss: 2.0409460117419562

Epoch: 5| Step: 6
Training loss: 2.064809560775757
Validation loss: 2.0435346414645514

Epoch: 5| Step: 7
Training loss: 2.0760703086853027
Validation loss: 2.055364042520523

Epoch: 5| Step: 8
Training loss: 2.226454496383667
Validation loss: 2.0602371444304786

Epoch: 5| Step: 9
Training loss: 2.668301582336426
Validation loss: 2.0648511399825416

Epoch: 5| Step: 10
Training loss: 1.861769676208496
Validation loss: 2.072548414270083

Epoch: 5| Step: 11
Training loss: 1.7910386323928833
Validation loss: 2.0720092554887137

Epoch: 76| Step: 0
Training loss: 2.5078325271606445
Validation loss: 2.0709263583024344

Epoch: 5| Step: 1
Training loss: 2.2163779735565186
Validation loss: 2.071466585000356

Epoch: 5| Step: 2
Training loss: 2.343665361404419
Validation loss: 2.0726516793171563

Epoch: 5| Step: 3
Training loss: 2.541255235671997
Validation loss: 2.0705097764730453

Epoch: 5| Step: 4
Training loss: 1.6543264389038086
Validation loss: 2.0693111022313437

Epoch: 5| Step: 5
Training loss: 2.6236014366149902
Validation loss: 2.0690441727638245

Epoch: 5| Step: 6
Training loss: 2.0356388092041016
Validation loss: 2.064161871870359

Epoch: 5| Step: 7
Training loss: 2.3984341621398926
Validation loss: 2.0635179926951728

Epoch: 5| Step: 8
Training loss: 2.6325676441192627
Validation loss: 2.05726321041584

Epoch: 5| Step: 9
Training loss: 1.6377156972885132
Validation loss: 2.0594143768151603

Epoch: 5| Step: 10
Training loss: 2.332711696624756
Validation loss: 2.0514251788457236

Epoch: 5| Step: 11
Training loss: 1.1172127723693848
Validation loss: 2.049764225880305

Epoch: 77| Step: 0
Training loss: 2.473172664642334
Validation loss: 2.0323425928751626

Epoch: 5| Step: 1
Training loss: 1.9323017597198486
Validation loss: 2.026453490058581

Epoch: 5| Step: 2
Training loss: 2.571732997894287
Validation loss: 2.0244947224855423

Epoch: 5| Step: 3
Training loss: 1.904531478881836
Validation loss: 2.0310409317413964

Epoch: 5| Step: 4
Training loss: 2.579704523086548
Validation loss: 2.039716492096583

Epoch: 5| Step: 5
Training loss: 1.862206220626831
Validation loss: 2.046134740114212

Epoch: 5| Step: 6
Training loss: 2.3880863189697266
Validation loss: 2.042712007959684

Epoch: 5| Step: 7
Training loss: 2.4422006607055664
Validation loss: 2.0425422191619873

Epoch: 5| Step: 8
Training loss: 1.9422801733016968
Validation loss: 2.027367815375328

Epoch: 5| Step: 9
Training loss: 2.2006258964538574
Validation loss: 2.0349483639001846

Epoch: 5| Step: 10
Training loss: 2.121706962585449
Validation loss: 2.029405618707339

Epoch: 5| Step: 11
Training loss: 1.7344515323638916
Validation loss: 2.042847047249476

Epoch: 78| Step: 0
Training loss: 2.3579049110412598
Validation loss: 2.0434279094139733

Epoch: 5| Step: 1
Training loss: 2.118197202682495
Validation loss: 2.0423999031384787

Epoch: 5| Step: 2
Training loss: 2.3485331535339355
Validation loss: 2.040311167637507

Epoch: 5| Step: 3
Training loss: 2.2276663780212402
Validation loss: 2.0295617332061133

Epoch: 5| Step: 4
Training loss: 1.9897441864013672
Validation loss: 2.0314133018255234

Epoch: 5| Step: 5
Training loss: 2.528428554534912
Validation loss: 2.031928166747093

Epoch: 5| Step: 6
Training loss: 2.3448262214660645
Validation loss: 2.0243014295895896

Epoch: 5| Step: 7
Training loss: 2.5924057960510254
Validation loss: 2.0284895449876785

Epoch: 5| Step: 8
Training loss: 1.6624549627304077
Validation loss: 2.027564197778702

Epoch: 5| Step: 9
Training loss: 2.3966217041015625
Validation loss: 2.04439285894235

Epoch: 5| Step: 10
Training loss: 1.8829078674316406
Validation loss: 2.0379351129134498

Epoch: 5| Step: 11
Training loss: 2.345794677734375
Validation loss: 2.038082246979078

Epoch: 79| Step: 0
Training loss: 2.4909751415252686
Validation loss: 2.0303808053334556

Epoch: 5| Step: 1
Training loss: 1.3522089719772339
Validation loss: 2.042877584695816

Epoch: 5| Step: 2
Training loss: 2.362244129180908
Validation loss: 2.0532520761092505

Epoch: 5| Step: 3
Training loss: 2.5007617473602295
Validation loss: 2.0464118868112564

Epoch: 5| Step: 4
Training loss: 1.5676268339157104
Validation loss: 2.0411613235870996

Epoch: 5| Step: 5
Training loss: 1.8265187740325928
Validation loss: 2.0442164540290833

Epoch: 5| Step: 6
Training loss: 2.7297184467315674
Validation loss: 2.0406232873598733

Epoch: 5| Step: 7
Training loss: 2.3138632774353027
Validation loss: 2.028867930173874

Epoch: 5| Step: 8
Training loss: 2.605976104736328
Validation loss: 2.031246388951937

Epoch: 5| Step: 9
Training loss: 2.163928270339966
Validation loss: 2.0377213756243386

Epoch: 5| Step: 10
Training loss: 2.239335060119629
Validation loss: 2.0299483835697174

Epoch: 5| Step: 11
Training loss: 2.5099620819091797
Validation loss: 2.024195834994316

Epoch: 80| Step: 0
Training loss: 2.307072162628174
Validation loss: 2.025508999824524

Epoch: 5| Step: 1
Training loss: 1.8166660070419312
Validation loss: 2.023465653260549

Epoch: 5| Step: 2
Training loss: 2.1418650150299072
Validation loss: 2.0261635035276413

Epoch: 5| Step: 3
Training loss: 1.8747920989990234
Validation loss: 2.0274522503217063

Epoch: 5| Step: 4
Training loss: 2.167182445526123
Validation loss: 2.0201881478230157

Epoch: 5| Step: 5
Training loss: 2.3527159690856934
Validation loss: 2.02186452349027

Epoch: 5| Step: 6
Training loss: 2.133880376815796
Validation loss: 2.0285815000534058

Epoch: 5| Step: 7
Training loss: 1.876164436340332
Validation loss: 2.032213499148687

Epoch: 5| Step: 8
Training loss: 3.2130463123321533
Validation loss: 2.021430010596911

Epoch: 5| Step: 9
Training loss: 2.386000871658325
Validation loss: 2.026327297091484

Epoch: 5| Step: 10
Training loss: 2.2448127269744873
Validation loss: 2.0181477814912796

Epoch: 5| Step: 11
Training loss: 0.8069952726364136
Validation loss: 2.0227004339297614

Epoch: 81| Step: 0
Training loss: 1.885901689529419
Validation loss: 2.015663350621859

Epoch: 5| Step: 1
Training loss: 1.675328016281128
Validation loss: 2.0230770806471505

Epoch: 5| Step: 2
Training loss: 2.677083969116211
Validation loss: 2.02937359114488

Epoch: 5| Step: 3
Training loss: 2.150639772415161
Validation loss: 2.0272829780975976

Epoch: 5| Step: 4
Training loss: 1.8514773845672607
Validation loss: 2.0274765690167746

Epoch: 5| Step: 5
Training loss: 2.6520798206329346
Validation loss: 2.038879007101059

Epoch: 5| Step: 6
Training loss: 1.8845323324203491
Validation loss: 2.0238950550556183

Epoch: 5| Step: 7
Training loss: 2.9764022827148438
Validation loss: 2.0174659540255866

Epoch: 5| Step: 8
Training loss: 2.3035225868225098
Validation loss: 2.023931990067164

Epoch: 5| Step: 9
Training loss: 2.4321908950805664
Validation loss: 2.0311264197031655

Epoch: 5| Step: 10
Training loss: 1.9194148778915405
Validation loss: 2.02510034541289

Epoch: 5| Step: 11
Training loss: 0.45204591751098633
Validation loss: 2.024709482987722

Epoch: 82| Step: 0
Training loss: 2.6435303688049316
Validation loss: 2.022687936822573

Epoch: 5| Step: 1
Training loss: 1.8939330577850342
Validation loss: 2.023158386349678

Epoch: 5| Step: 2
Training loss: 2.2985281944274902
Validation loss: 2.0297247618436813

Epoch: 5| Step: 3
Training loss: 2.518019199371338
Validation loss: 2.0367286801338196

Epoch: 5| Step: 4
Training loss: 1.7538821697235107
Validation loss: 2.04789470632871

Epoch: 5| Step: 5
Training loss: 2.0743653774261475
Validation loss: 2.0691604564587274

Epoch: 5| Step: 6
Training loss: 1.4960458278656006
Validation loss: 2.0705379446347556

Epoch: 5| Step: 7
Training loss: 2.382819652557373
Validation loss: 2.0712588926156363

Epoch: 5| Step: 8
Training loss: 2.122300863265991
Validation loss: 2.0617260386546454

Epoch: 5| Step: 9
Training loss: 2.6365981101989746
Validation loss: 2.061751519640287

Epoch: 5| Step: 10
Training loss: 2.3590638637542725
Validation loss: 2.063785672187805

Epoch: 5| Step: 11
Training loss: 2.816096067428589
Validation loss: 2.044729674855868

Epoch: 83| Step: 0
Training loss: 1.9106709957122803
Validation loss: 2.021754036347071

Epoch: 5| Step: 1
Training loss: 2.349496841430664
Validation loss: 2.0288840929667153

Epoch: 5| Step: 2
Training loss: 2.111215591430664
Validation loss: 2.0327403843402863

Epoch: 5| Step: 3
Training loss: 1.781783103942871
Validation loss: 2.042874867717425

Epoch: 5| Step: 4
Training loss: 2.533076286315918
Validation loss: 2.0500412384668985

Epoch: 5| Step: 5
Training loss: 2.079125165939331
Validation loss: 2.0511199285586676

Epoch: 5| Step: 6
Training loss: 2.487083911895752
Validation loss: 2.052558978398641

Epoch: 5| Step: 7
Training loss: 2.225069761276245
Validation loss: 2.0480774541695914

Epoch: 5| Step: 8
Training loss: 2.6370208263397217
Validation loss: 2.044640382130941

Epoch: 5| Step: 9
Training loss: 2.4484264850616455
Validation loss: 2.036295856038729

Epoch: 5| Step: 10
Training loss: 1.6469218730926514
Validation loss: 2.0348539501428604

Epoch: 5| Step: 11
Training loss: 2.7040536403656006
Validation loss: 2.026836742957433

Epoch: 84| Step: 0
Training loss: 2.384455442428589
Validation loss: 2.019503985842069

Epoch: 5| Step: 1
Training loss: 1.952379822731018
Validation loss: 2.0207831809918084

Epoch: 5| Step: 2
Training loss: 2.1346702575683594
Validation loss: 2.0254463305075965

Epoch: 5| Step: 3
Training loss: 1.6520735025405884
Validation loss: 2.034429356455803

Epoch: 5| Step: 4
Training loss: 2.6616692543029785
Validation loss: 2.0424077610174813

Epoch: 5| Step: 5
Training loss: 2.0904223918914795
Validation loss: 2.045249958833059

Epoch: 5| Step: 6
Training loss: 2.5465917587280273
Validation loss: 2.046520466605822

Epoch: 5| Step: 7
Training loss: 1.9955781698226929
Validation loss: 2.0569115976492562

Epoch: 5| Step: 8
Training loss: 2.24372935295105
Validation loss: 2.045682355761528

Epoch: 5| Step: 9
Training loss: 2.3014419078826904
Validation loss: 2.053010726968447

Epoch: 5| Step: 10
Training loss: 1.9438855648040771
Validation loss: 2.036280925075213

Epoch: 5| Step: 11
Training loss: 3.1268510818481445
Validation loss: 2.0414431740840278

Epoch: 85| Step: 0
Training loss: 1.8595740795135498
Validation loss: 2.0381061335404715

Epoch: 5| Step: 1
Training loss: 2.2711024284362793
Validation loss: 2.0316577404737473

Epoch: 5| Step: 2
Training loss: 2.4119930267333984
Validation loss: 2.023314192891121

Epoch: 5| Step: 3
Training loss: 2.033273220062256
Validation loss: 2.0139569441477456

Epoch: 5| Step: 4
Training loss: 2.5904440879821777
Validation loss: 2.0167870223522186

Epoch: 5| Step: 5
Training loss: 2.2643513679504395
Validation loss: 2.0159237583478293

Epoch: 5| Step: 6
Training loss: 2.4058220386505127
Validation loss: 2.013489539424578

Epoch: 5| Step: 7
Training loss: 2.095423936843872
Validation loss: 2.017093708117803

Epoch: 5| Step: 8
Training loss: 2.049334764480591
Validation loss: 2.022859752178192

Epoch: 5| Step: 9
Training loss: 1.7095859050750732
Validation loss: 2.025480628013611

Epoch: 5| Step: 10
Training loss: 2.1271910667419434
Validation loss: 2.014386077721914

Epoch: 5| Step: 11
Training loss: 3.043290853500366
Validation loss: 2.0154616783062616

Epoch: 86| Step: 0
Training loss: 2.5181727409362793
Validation loss: 2.023040438691775

Epoch: 5| Step: 1
Training loss: 2.263554096221924
Validation loss: 2.0268651793400445

Epoch: 5| Step: 2
Training loss: 2.5999507904052734
Validation loss: 2.030557870864868

Epoch: 5| Step: 3
Training loss: 1.943355917930603
Validation loss: 2.019583856066068

Epoch: 5| Step: 4
Training loss: 2.730875015258789
Validation loss: 2.033336748679479

Epoch: 5| Step: 5
Training loss: 1.9686387777328491
Validation loss: 2.0444546043872833

Epoch: 5| Step: 6
Training loss: 1.9092319011688232
Validation loss: 2.0481203397115073

Epoch: 5| Step: 7
Training loss: 1.7369102239608765
Validation loss: 2.0639235973358154

Epoch: 5| Step: 8
Training loss: 2.013774871826172
Validation loss: 2.053883155186971

Epoch: 5| Step: 9
Training loss: 2.5306153297424316
Validation loss: 2.043071433901787

Epoch: 5| Step: 10
Training loss: 1.9502519369125366
Validation loss: 2.0362573315699897

Epoch: 5| Step: 11
Training loss: 1.2696388959884644
Validation loss: 2.015312393506368

Epoch: 87| Step: 0
Training loss: 2.0795061588287354
Validation loss: 2.033076902230581

Epoch: 5| Step: 1
Training loss: 2.3389828205108643
Validation loss: 2.0402610152959824

Epoch: 5| Step: 2
Training loss: 1.9148626327514648
Validation loss: 2.0437643925348916

Epoch: 5| Step: 3
Training loss: 2.2081620693206787
Validation loss: 2.0425227085749307

Epoch: 5| Step: 4
Training loss: 3.002140522003174
Validation loss: 2.0533690253893533

Epoch: 5| Step: 5
Training loss: 2.7838234901428223
Validation loss: 2.049519250790278

Epoch: 5| Step: 6
Training loss: 2.0249991416931152
Validation loss: 2.048743635416031

Epoch: 5| Step: 7
Training loss: 2.440701961517334
Validation loss: 2.042868971824646

Epoch: 5| Step: 8
Training loss: 1.7421033382415771
Validation loss: 2.0429991334676743

Epoch: 5| Step: 9
Training loss: 2.067718029022217
Validation loss: 2.0445157090822854

Epoch: 5| Step: 10
Training loss: 1.8222520351409912
Validation loss: 2.04176864027977

Epoch: 5| Step: 11
Training loss: 1.9859107732772827
Validation loss: 2.040494824449221

Epoch: 88| Step: 0
Training loss: 2.0473597049713135
Validation loss: 2.0389375388622284

Epoch: 5| Step: 1
Training loss: 2.437671661376953
Validation loss: 2.0399106641610465

Epoch: 5| Step: 2
Training loss: 2.2606863975524902
Validation loss: 2.0316874235868454

Epoch: 5| Step: 3
Training loss: 2.489992618560791
Validation loss: 2.0286819835503898

Epoch: 5| Step: 4
Training loss: 2.436352491378784
Validation loss: 2.0360160122315087

Epoch: 5| Step: 5
Training loss: 2.395183563232422
Validation loss: 2.0320358872413635

Epoch: 5| Step: 6
Training loss: 1.455186367034912
Validation loss: 2.036304235458374

Epoch: 5| Step: 7
Training loss: 1.9706894159317017
Validation loss: 2.024085765083631

Epoch: 5| Step: 8
Training loss: 2.017815351486206
Validation loss: 2.0161100775003433

Epoch: 5| Step: 9
Training loss: 2.1602742671966553
Validation loss: 2.030051996310552

Epoch: 5| Step: 10
Training loss: 1.9444522857666016
Validation loss: 2.041228249669075

Epoch: 5| Step: 11
Training loss: 3.4330945014953613
Validation loss: 2.084885170062383

Epoch: 89| Step: 0
Training loss: 2.454798460006714
Validation loss: 2.0694486896197

Epoch: 5| Step: 1
Training loss: 2.362541913986206
Validation loss: 2.0502315560976663

Epoch: 5| Step: 2
Training loss: 1.6369507312774658
Validation loss: 2.038790042201678

Epoch: 5| Step: 3
Training loss: 2.0286128520965576
Validation loss: 2.0236538300911584

Epoch: 5| Step: 4
Training loss: 1.9754469394683838
Validation loss: 2.0193056066830954

Epoch: 5| Step: 5
Training loss: 2.1690638065338135
Validation loss: 2.0204421132802963

Epoch: 5| Step: 6
Training loss: 2.4459004402160645
Validation loss: 2.016063541173935

Epoch: 5| Step: 7
Training loss: 2.084324598312378
Validation loss: 2.0189146945873895

Epoch: 5| Step: 8
Training loss: 2.096024990081787
Validation loss: 2.017986625432968

Epoch: 5| Step: 9
Training loss: 2.7889726161956787
Validation loss: 2.0170413305362067

Epoch: 5| Step: 10
Training loss: 1.940431833267212
Validation loss: 2.0153792103131614

Epoch: 5| Step: 11
Training loss: 2.507032871246338
Validation loss: 2.0146842350562415

Epoch: 90| Step: 0
Training loss: 2.445034980773926
Validation loss: 2.008326694369316

Epoch: 5| Step: 1
Training loss: 1.9582836627960205
Validation loss: 2.014240195353826

Epoch: 5| Step: 2
Training loss: 2.517974615097046
Validation loss: 2.0094780872265496

Epoch: 5| Step: 3
Training loss: 2.149012327194214
Validation loss: 2.0119443833827972

Epoch: 5| Step: 4
Training loss: 2.8979713916778564
Validation loss: 2.0053592969973884

Epoch: 5| Step: 5
Training loss: 2.497110366821289
Validation loss: 2.0232888708511987

Epoch: 5| Step: 6
Training loss: 2.0624773502349854
Validation loss: 2.0105230460564294

Epoch: 5| Step: 7
Training loss: 2.046034336090088
Validation loss: 2.0105014741420746

Epoch: 5| Step: 8
Training loss: 1.7695720195770264
Validation loss: 2.013047362367312

Epoch: 5| Step: 9
Training loss: 1.751932144165039
Validation loss: 2.01423646012942

Epoch: 5| Step: 10
Training loss: 1.953887701034546
Validation loss: 2.0097397714853287

Epoch: 5| Step: 11
Training loss: 2.651303291320801
Validation loss: 2.0099824418624244

Epoch: 91| Step: 0
Training loss: 2.0119729042053223
Validation loss: 2.005724176764488

Epoch: 5| Step: 1
Training loss: 2.0113108158111572
Validation loss: 2.009505718946457

Epoch: 5| Step: 2
Training loss: 2.126296281814575
Validation loss: 2.0102412154277167

Epoch: 5| Step: 3
Training loss: 2.6082277297973633
Validation loss: 2.015126203497251

Epoch: 5| Step: 4
Training loss: 1.4974514245986938
Validation loss: 2.0176502416531243

Epoch: 5| Step: 5
Training loss: 2.8856940269470215
Validation loss: 2.0181652208169303

Epoch: 5| Step: 6
Training loss: 2.2531466484069824
Validation loss: 2.0172300140062966

Epoch: 5| Step: 7
Training loss: 2.342991828918457
Validation loss: 2.0176554173231125

Epoch: 5| Step: 8
Training loss: 2.0615179538726807
Validation loss: 2.015411118666331

Epoch: 5| Step: 9
Training loss: 2.1080195903778076
Validation loss: 2.0146023432413735

Epoch: 5| Step: 10
Training loss: 1.8510500192642212
Validation loss: 2.015135924021403

Epoch: 5| Step: 11
Training loss: 2.8389010429382324
Validation loss: 2.0146738290786743

Epoch: 92| Step: 0
Training loss: 2.151956796646118
Validation loss: 2.0099143336216607

Epoch: 5| Step: 1
Training loss: 1.805593490600586
Validation loss: 2.0196317235628762

Epoch: 5| Step: 2
Training loss: 2.221057653427124
Validation loss: 2.034246494372686

Epoch: 5| Step: 3
Training loss: 1.974357008934021
Validation loss: 2.0481925308704376

Epoch: 5| Step: 4
Training loss: 1.9818605184555054
Validation loss: 2.05521888534228

Epoch: 5| Step: 5
Training loss: 2.3522162437438965
Validation loss: 2.065855915347735

Epoch: 5| Step: 6
Training loss: 1.8808084726333618
Validation loss: 2.0570045908292136

Epoch: 5| Step: 7
Training loss: 2.3253324031829834
Validation loss: 2.0414120654265084

Epoch: 5| Step: 8
Training loss: 2.282762050628662
Validation loss: 2.0224739809830985

Epoch: 5| Step: 9
Training loss: 2.2699790000915527
Validation loss: 2.0157224287589393

Epoch: 5| Step: 10
Training loss: 2.5409183502197266
Validation loss: 2.0141106198231378

Epoch: 5| Step: 11
Training loss: 3.220492362976074
Validation loss: 2.0201202829678855

Epoch: 93| Step: 0
Training loss: 1.537947654724121
Validation loss: 2.0109329173962274

Epoch: 5| Step: 1
Training loss: 2.344933032989502
Validation loss: 2.013662243882815

Epoch: 5| Step: 2
Training loss: 1.8136106729507446
Validation loss: 2.0225313206513724

Epoch: 5| Step: 3
Training loss: 2.4510867595672607
Validation loss: 2.0354207952817283

Epoch: 5| Step: 4
Training loss: 1.5196683406829834
Validation loss: 2.058974872032801

Epoch: 5| Step: 5
Training loss: 2.7632789611816406
Validation loss: 2.067684849103292

Epoch: 5| Step: 6
Training loss: 2.051955223083496
Validation loss: 2.0741728444894156

Epoch: 5| Step: 7
Training loss: 2.5418782234191895
Validation loss: 2.0768921176592507

Epoch: 5| Step: 8
Training loss: 2.5818686485290527
Validation loss: 2.0624861419200897

Epoch: 5| Step: 9
Training loss: 2.4171154499053955
Validation loss: 2.046151280403137

Epoch: 5| Step: 10
Training loss: 2.1970789432525635
Validation loss: 2.0298608591159186

Epoch: 5| Step: 11
Training loss: 2.4352927207946777
Validation loss: 2.033344636360804

Epoch: 94| Step: 0
Training loss: 2.2342019081115723
Validation loss: 2.025030185778936

Epoch: 5| Step: 1
Training loss: 2.0332627296447754
Validation loss: 2.047331457336744

Epoch: 5| Step: 2
Training loss: 1.8804019689559937
Validation loss: 2.041672627131144

Epoch: 5| Step: 3
Training loss: 2.6853103637695312
Validation loss: 2.0447453757127128

Epoch: 5| Step: 4
Training loss: 2.4180264472961426
Validation loss: 2.044486870368322

Epoch: 5| Step: 5
Training loss: 1.6101446151733398
Validation loss: 2.0371701220671334

Epoch: 5| Step: 6
Training loss: 2.4856715202331543
Validation loss: 2.0420557955900827

Epoch: 5| Step: 7
Training loss: 2.2556865215301514
Validation loss: 2.0276870280504227

Epoch: 5| Step: 8
Training loss: 2.10119891166687
Validation loss: 2.040855750441551

Epoch: 5| Step: 9
Training loss: 1.9823812246322632
Validation loss: 2.0341833184162774

Epoch: 5| Step: 10
Training loss: 2.4212899208068848
Validation loss: 2.0374837468067803

Epoch: 5| Step: 11
Training loss: 1.4099845886230469
Validation loss: 2.0323293606440225

Epoch: 95| Step: 0
Training loss: 2.406369686126709
Validation loss: 2.045833557844162

Epoch: 5| Step: 1
Training loss: 2.5132484436035156
Validation loss: 2.0550532191991806

Epoch: 5| Step: 2
Training loss: 2.1138455867767334
Validation loss: 2.0464815547068915

Epoch: 5| Step: 3
Training loss: 1.6120555400848389
Validation loss: 2.0441274295250573

Epoch: 5| Step: 4
Training loss: 2.1224420070648193
Validation loss: 2.0398095647493997

Epoch: 5| Step: 5
Training loss: 2.1904489994049072
Validation loss: 2.027745092908541

Epoch: 5| Step: 6
Training loss: 1.5281336307525635
Validation loss: 2.0198317915201187

Epoch: 5| Step: 7
Training loss: 2.0032193660736084
Validation loss: 2.006805802385012

Epoch: 5| Step: 8
Training loss: 2.416287899017334
Validation loss: 2.0060039858023324

Epoch: 5| Step: 9
Training loss: 2.013368606567383
Validation loss: 2.0030374030272164

Epoch: 5| Step: 10
Training loss: 3.10330867767334
Validation loss: 2.009902238845825

Epoch: 5| Step: 11
Training loss: 1.355759620666504
Validation loss: 2.015180617570877

Epoch: 96| Step: 0
Training loss: 2.10392165184021
Validation loss: 2.010013625025749

Epoch: 5| Step: 1
Training loss: 1.9099533557891846
Validation loss: 2.0114575624465942

Epoch: 5| Step: 2
Training loss: 2.4663760662078857
Validation loss: 2.0184378027915955

Epoch: 5| Step: 3
Training loss: 2.027804136276245
Validation loss: 2.026541749636332

Epoch: 5| Step: 4
Training loss: 2.189384937286377
Validation loss: 2.027104765176773

Epoch: 5| Step: 5
Training loss: 1.700990915298462
Validation loss: 2.0358475546042123

Epoch: 5| Step: 6
Training loss: 2.1605870723724365
Validation loss: 2.046675756573677

Epoch: 5| Step: 7
Training loss: 1.887316107749939
Validation loss: 2.042432188987732

Epoch: 5| Step: 8
Training loss: 1.9333785772323608
Validation loss: 2.0514182647069297

Epoch: 5| Step: 9
Training loss: 2.480485439300537
Validation loss: 2.050908495982488

Epoch: 5| Step: 10
Training loss: 2.9477860927581787
Validation loss: 2.044385850429535

Epoch: 5| Step: 11
Training loss: 2.571197509765625
Validation loss: 2.0301478604475656

Epoch: 97| Step: 0
Training loss: 1.8449773788452148
Validation loss: 2.018955926100413

Epoch: 5| Step: 1
Training loss: 2.1816744804382324
Validation loss: 2.015864223241806

Epoch: 5| Step: 2
Training loss: 1.9721097946166992
Validation loss: 2.01748255888621

Epoch: 5| Step: 3
Training loss: 2.5537867546081543
Validation loss: 2.009518881638845

Epoch: 5| Step: 4
Training loss: 2.376972198486328
Validation loss: 2.0173790603876114

Epoch: 5| Step: 5
Training loss: 1.9822126626968384
Validation loss: 2.0220536092917123

Epoch: 5| Step: 6
Training loss: 2.5021941661834717
Validation loss: 2.0254889676968255

Epoch: 5| Step: 7
Training loss: 2.040156602859497
Validation loss: 2.0304824709892273

Epoch: 5| Step: 8
Training loss: 1.7194712162017822
Validation loss: 2.0352852592865625

Epoch: 5| Step: 9
Training loss: 1.4748752117156982
Validation loss: 2.0338352769613266

Epoch: 5| Step: 10
Training loss: 3.1334056854248047
Validation loss: 2.031684493025144

Epoch: 5| Step: 11
Training loss: 2.5831375122070312
Validation loss: 2.0347484797239304

Epoch: 98| Step: 0
Training loss: 2.322309970855713
Validation loss: 2.0303433934847512

Epoch: 5| Step: 1
Training loss: 2.236466407775879
Validation loss: 2.0270546774069467

Epoch: 5| Step: 2
Training loss: 2.0897974967956543
Validation loss: 2.032354782025019

Epoch: 5| Step: 3
Training loss: 1.657348871231079
Validation loss: 2.032192647457123

Epoch: 5| Step: 4
Training loss: 2.474430799484253
Validation loss: 2.031666561961174

Epoch: 5| Step: 5
Training loss: 2.6881747245788574
Validation loss: 2.0246436297893524

Epoch: 5| Step: 6
Training loss: 2.185584783554077
Validation loss: 2.021317278345426

Epoch: 5| Step: 7
Training loss: 1.6789696216583252
Validation loss: 2.0119182020425797

Epoch: 5| Step: 8
Training loss: 1.8606884479522705
Validation loss: 2.009498725334803

Epoch: 5| Step: 9
Training loss: 2.440991163253784
Validation loss: 2.02042056620121

Epoch: 5| Step: 10
Training loss: 2.4712138175964355
Validation loss: 2.0319856107234955

Epoch: 5| Step: 11
Training loss: 1.5533525943756104
Validation loss: 2.029693618416786

Epoch: 99| Step: 0
Training loss: 2.075376510620117
Validation loss: 2.0403876304626465

Epoch: 5| Step: 1
Training loss: 2.4374465942382812
Validation loss: 2.0345167020956674

Epoch: 5| Step: 2
Training loss: 2.3544962406158447
Validation loss: 2.037365441521009

Epoch: 5| Step: 3
Training loss: 2.226712942123413
Validation loss: 2.043769265214602

Epoch: 5| Step: 4
Training loss: 2.530268907546997
Validation loss: 2.0292482674121857

Epoch: 5| Step: 5
Training loss: 1.7632259130477905
Validation loss: 2.0229368209838867

Epoch: 5| Step: 6
Training loss: 1.8981819152832031
Validation loss: 2.012620414296786

Epoch: 5| Step: 7
Training loss: 1.7286217212677002
Validation loss: 2.008558432261149

Epoch: 5| Step: 8
Training loss: 2.444626569747925
Validation loss: 2.016575038433075

Epoch: 5| Step: 9
Training loss: 2.0036697387695312
Validation loss: 2.0091474056243896

Epoch: 5| Step: 10
Training loss: 2.3225584030151367
Validation loss: 2.0118830303351083

Epoch: 5| Step: 11
Training loss: 1.2751377820968628
Validation loss: 2.013254334529241

Epoch: 100| Step: 0
Training loss: 2.4085888862609863
Validation loss: 2.013559808333715

Epoch: 5| Step: 1
Training loss: 2.3714919090270996
Validation loss: 2.0164533952871957

Epoch: 5| Step: 2
Training loss: 1.9281055927276611
Validation loss: 2.007337893048922

Epoch: 5| Step: 3
Training loss: 2.7909951210021973
Validation loss: 2.0084345042705536

Epoch: 5| Step: 4
Training loss: 2.204559803009033
Validation loss: 2.0133637388547263

Epoch: 5| Step: 5
Training loss: 1.9616378545761108
Validation loss: 2.0128819197416306

Epoch: 5| Step: 6
Training loss: 1.9987083673477173
Validation loss: 2.0146548748016357

Epoch: 5| Step: 7
Training loss: 1.3668676614761353
Validation loss: 2.02042023340861

Epoch: 5| Step: 8
Training loss: 2.0600342750549316
Validation loss: 2.02380308508873

Epoch: 5| Step: 9
Training loss: 2.3457603454589844
Validation loss: 2.019658704598745

Epoch: 5| Step: 10
Training loss: 2.1793370246887207
Validation loss: 2.0379582246144614

Epoch: 5| Step: 11
Training loss: 1.6738334894180298
Validation loss: 2.035720909635226

Epoch: 101| Step: 0
Training loss: 1.962196707725525
Validation loss: 2.0367794881264367

Epoch: 5| Step: 1
Training loss: 1.9677836894989014
Validation loss: 2.025170629223188

Epoch: 5| Step: 2
Training loss: 1.7515977621078491
Validation loss: 2.014060234030088

Epoch: 5| Step: 3
Training loss: 2.740880012512207
Validation loss: 2.020947058995565

Epoch: 5| Step: 4
Training loss: 2.234952449798584
Validation loss: 2.0211898535490036

Epoch: 5| Step: 5
Training loss: 2.0038914680480957
Validation loss: 2.0126576274633408

Epoch: 5| Step: 6
Training loss: 2.2922303676605225
Validation loss: 2.0138311882813773

Epoch: 5| Step: 7
Training loss: 1.8695141077041626
Validation loss: 2.0145387947559357

Epoch: 5| Step: 8
Training loss: 2.274597644805908
Validation loss: 2.018859480818113

Epoch: 5| Step: 9
Training loss: 2.043003559112549
Validation loss: 2.0081659952799478

Epoch: 5| Step: 10
Training loss: 2.4700052738189697
Validation loss: 2.02302148938179

Epoch: 5| Step: 11
Training loss: 1.5507335662841797
Validation loss: 2.0219291150569916

Epoch: 102| Step: 0
Training loss: 2.5197460651397705
Validation loss: 2.0280779004096985

Epoch: 5| Step: 1
Training loss: 2.557199716567993
Validation loss: 2.034586956103643

Epoch: 5| Step: 2
Training loss: 2.6508138179779053
Validation loss: 2.043269917368889

Epoch: 5| Step: 3
Training loss: 1.8843162059783936
Validation loss: 2.0322964986165366

Epoch: 5| Step: 4
Training loss: 1.8976147174835205
Validation loss: 2.037661631902059

Epoch: 5| Step: 5
Training loss: 1.6260154247283936
Validation loss: 2.04009348154068

Epoch: 5| Step: 6
Training loss: 2.199227809906006
Validation loss: 2.0450335294008255

Epoch: 5| Step: 7
Training loss: 1.9152891635894775
Validation loss: 2.0398367842038474

Epoch: 5| Step: 8
Training loss: 2.3021154403686523
Validation loss: 2.0400423208872476

Epoch: 5| Step: 9
Training loss: 2.128296136856079
Validation loss: 2.0129181842009225

Epoch: 5| Step: 10
Training loss: 1.5393357276916504
Validation loss: 2.026524598399798

Epoch: 5| Step: 11
Training loss: 3.669665813446045
Validation loss: 2.012174849708875

Epoch: 103| Step: 0
Training loss: 2.360869884490967
Validation loss: 2.0070549100637436

Epoch: 5| Step: 1
Training loss: 2.189375162124634
Validation loss: 2.012353857358297

Epoch: 5| Step: 2
Training loss: 1.976958990097046
Validation loss: 2.0203184336423874

Epoch: 5| Step: 3
Training loss: 2.0577356815338135
Validation loss: 2.024267723162969

Epoch: 5| Step: 4
Training loss: 2.0889108180999756
Validation loss: 2.0273876190185547

Epoch: 5| Step: 5
Training loss: 2.4589996337890625
Validation loss: 2.0256443669398627

Epoch: 5| Step: 6
Training loss: 2.2464921474456787
Validation loss: 2.028098021944364

Epoch: 5| Step: 7
Training loss: 2.317999839782715
Validation loss: 2.0308182587226233

Epoch: 5| Step: 8
Training loss: 2.0400824546813965
Validation loss: 2.0206255366404853

Epoch: 5| Step: 9
Training loss: 1.9199138879776
Validation loss: 2.0244963318109512

Epoch: 5| Step: 10
Training loss: 2.2266242504119873
Validation loss: 2.021537557244301

Epoch: 5| Step: 11
Training loss: 1.842113733291626
Validation loss: 2.0120489448308945

Epoch: 104| Step: 0
Training loss: 2.5332770347595215
Validation loss: 2.013345609108607

Epoch: 5| Step: 1
Training loss: 1.2492120265960693
Validation loss: 2.0147309054931006

Epoch: 5| Step: 2
Training loss: 1.9411176443099976
Validation loss: 2.0174311250448227

Epoch: 5| Step: 3
Training loss: 2.4214606285095215
Validation loss: 2.0212922543287277

Epoch: 5| Step: 4
Training loss: 2.1872856616973877
Validation loss: 2.0233770608901978

Epoch: 5| Step: 5
Training loss: 2.1349563598632812
Validation loss: 2.03078256547451

Epoch: 5| Step: 6
Training loss: 2.446577787399292
Validation loss: 2.0428441017866135

Epoch: 5| Step: 7
Training loss: 2.429651975631714
Validation loss: 2.0525826116402945

Epoch: 5| Step: 8
Training loss: 2.752143621444702
Validation loss: 2.0450371901194253

Epoch: 5| Step: 9
Training loss: 1.6492795944213867
Validation loss: 2.0427432854970298

Epoch: 5| Step: 10
Training loss: 1.8238385915756226
Validation loss: 2.050210654735565

Epoch: 5| Step: 11
Training loss: 1.6726268529891968
Validation loss: 2.047685131430626

Epoch: 105| Step: 0
Training loss: 2.175816535949707
Validation loss: 2.0460354139407477

Epoch: 5| Step: 1
Training loss: 2.2194836139678955
Validation loss: 2.0273627688487372

Epoch: 5| Step: 2
Training loss: 2.3482418060302734
Validation loss: 2.017349198460579

Epoch: 5| Step: 3
Training loss: 2.4030466079711914
Validation loss: 2.0102078219254813

Epoch: 5| Step: 4
Training loss: 2.4713892936706543
Validation loss: 2.014285405476888

Epoch: 5| Step: 5
Training loss: 2.377882719039917
Validation loss: 2.022205243508021

Epoch: 5| Step: 6
Training loss: 2.09175443649292
Validation loss: 2.0271031707525253

Epoch: 5| Step: 7
Training loss: 1.786635160446167
Validation loss: 2.028804436326027

Epoch: 5| Step: 8
Training loss: 1.9847255945205688
Validation loss: 2.0364990482727685

Epoch: 5| Step: 9
Training loss: 1.9203662872314453
Validation loss: 2.033600484331449

Epoch: 5| Step: 10
Training loss: 2.127455234527588
Validation loss: 2.0343060940504074

Epoch: 5| Step: 11
Training loss: 2.5580122470855713
Validation loss: 2.035143797596296

Epoch: 106| Step: 0
Training loss: 2.311457395553589
Validation loss: 2.0361148367325463

Epoch: 5| Step: 1
Training loss: 2.534783124923706
Validation loss: 2.034408837556839

Epoch: 5| Step: 2
Training loss: 1.4850337505340576
Validation loss: 2.0293602347373962

Epoch: 5| Step: 3
Training loss: 2.3415133953094482
Validation loss: 2.030433257420858

Epoch: 5| Step: 4
Training loss: 2.2758233547210693
Validation loss: 2.0302469631036124

Epoch: 5| Step: 5
Training loss: 1.9981731176376343
Validation loss: 2.0300243298212686

Epoch: 5| Step: 6
Training loss: 2.545051097869873
Validation loss: 2.0297612150510154

Epoch: 5| Step: 7
Training loss: 1.8523406982421875
Validation loss: 2.0235882302125296

Epoch: 5| Step: 8
Training loss: 2.1753995418548584
Validation loss: 2.0142398476600647

Epoch: 5| Step: 9
Training loss: 2.19088077545166
Validation loss: 2.015616143743197

Epoch: 5| Step: 10
Training loss: 2.1284339427948
Validation loss: 2.015642767151197

Epoch: 5| Step: 11
Training loss: 1.6918760538101196
Validation loss: 2.0118158956368766

Epoch: 107| Step: 0
Training loss: 2.576486110687256
Validation loss: 2.0148210475842157

Epoch: 5| Step: 1
Training loss: 2.166050910949707
Validation loss: 2.015334894259771

Epoch: 5| Step: 2
Training loss: 2.33960223197937
Validation loss: 2.0182541012763977

Epoch: 5| Step: 3
Training loss: 1.8405290842056274
Validation loss: 2.0243319074312844

Epoch: 5| Step: 4
Training loss: 2.40346097946167
Validation loss: 2.0213066736857095

Epoch: 5| Step: 5
Training loss: 1.7794075012207031
Validation loss: 2.0299775302410126

Epoch: 5| Step: 6
Training loss: 2.0768303871154785
Validation loss: 2.0232605636119843

Epoch: 5| Step: 7
Training loss: 2.088871717453003
Validation loss: 2.0333621402581534

Epoch: 5| Step: 8
Training loss: 2.2860217094421387
Validation loss: 2.045797179142634

Epoch: 5| Step: 9
Training loss: 1.7298614978790283
Validation loss: 2.0363977203766503

Epoch: 5| Step: 10
Training loss: 2.1521506309509277
Validation loss: 2.043569187323252

Epoch: 5| Step: 11
Training loss: 0.8593227863311768
Validation loss: 2.038712203502655

Epoch: 108| Step: 0
Training loss: 2.205336809158325
Validation loss: 2.0611659983793893

Epoch: 5| Step: 1
Training loss: 1.8564910888671875
Validation loss: 2.0629585733016333

Epoch: 5| Step: 2
Training loss: 2.6959738731384277
Validation loss: 2.056625932455063

Epoch: 5| Step: 3
Training loss: 2.0640857219696045
Validation loss: 2.041227400302887

Epoch: 5| Step: 4
Training loss: 2.3783860206604004
Validation loss: 2.049162512024244

Epoch: 5| Step: 5
Training loss: 2.106442928314209
Validation loss: 2.0382977426052094

Epoch: 5| Step: 6
Training loss: 2.2950351238250732
Validation loss: 2.0397996803124747

Epoch: 5| Step: 7
Training loss: 2.079927921295166
Validation loss: 2.0288507292668023

Epoch: 5| Step: 8
Training loss: 2.0324389934539795
Validation loss: 2.02997391919295

Epoch: 5| Step: 9
Training loss: 2.3195266723632812
Validation loss: 2.0220527400573096

Epoch: 5| Step: 10
Training loss: 1.60186767578125
Validation loss: 2.017603799700737

Epoch: 5| Step: 11
Training loss: 2.7662582397460938
Validation loss: 2.015729675690333

Epoch: 109| Step: 0
Training loss: 2.140209197998047
Validation loss: 2.0174954384565353

Epoch: 5| Step: 1
Training loss: 2.20786190032959
Validation loss: 2.01790027320385

Epoch: 5| Step: 2
Training loss: 2.1806788444519043
Validation loss: 2.0136292974154153

Epoch: 5| Step: 3
Training loss: 1.5851396322250366
Validation loss: 2.0174523293972015

Epoch: 5| Step: 4
Training loss: 2.1993565559387207
Validation loss: 2.0126461734374366

Epoch: 5| Step: 5
Training loss: 2.351797580718994
Validation loss: 2.0101625422636666

Epoch: 5| Step: 6
Training loss: 1.7902246713638306
Validation loss: 2.011937032143275

Epoch: 5| Step: 7
Training loss: 1.8626312017440796
Validation loss: 2.01720621685187

Epoch: 5| Step: 8
Training loss: 2.2797904014587402
Validation loss: 2.020745560526848

Epoch: 5| Step: 9
Training loss: 2.6641600131988525
Validation loss: 2.0202610989411673

Epoch: 5| Step: 10
Training loss: 2.197376012802124
Validation loss: 2.0176161428292594

Epoch: 5| Step: 11
Training loss: 2.1775383949279785
Validation loss: 2.036032423377037

Epoch: 110| Step: 0
Training loss: 2.1917805671691895
Validation loss: 2.033604542414347

Epoch: 5| Step: 1
Training loss: 1.949716567993164
Validation loss: 2.014695336421331

Epoch: 5| Step: 2
Training loss: 2.4553940296173096
Validation loss: 2.020441025495529

Epoch: 5| Step: 3
Training loss: 2.1962571144104004
Validation loss: 2.0118610163529715

Epoch: 5| Step: 4
Training loss: 1.6616615056991577
Validation loss: 2.0120545774698257

Epoch: 5| Step: 5
Training loss: 2.4001545906066895
Validation loss: 2.017110526561737

Epoch: 5| Step: 6
Training loss: 2.406763792037964
Validation loss: 2.016670361161232

Epoch: 5| Step: 7
Training loss: 1.725610375404358
Validation loss: 2.014400745431582

Epoch: 5| Step: 8
Training loss: 1.9450929164886475
Validation loss: 2.022313177585602

Epoch: 5| Step: 9
Training loss: 2.491039752960205
Validation loss: 2.0191636234521866

Epoch: 5| Step: 10
Training loss: 2.017972946166992
Validation loss: 2.015581796566645

Epoch: 5| Step: 11
Training loss: 2.0830349922180176
Validation loss: 2.0138379534085593

Epoch: 111| Step: 0
Training loss: 2.3564865589141846
Validation loss: 2.0319787561893463

Epoch: 5| Step: 1
Training loss: 1.8125932216644287
Validation loss: 2.05440454185009

Epoch: 5| Step: 2
Training loss: 2.3136839866638184
Validation loss: 2.0632895479599633

Epoch: 5| Step: 3
Training loss: 1.6150814294815063
Validation loss: 2.075710579752922

Epoch: 5| Step: 4
Training loss: 2.3679113388061523
Validation loss: 2.07662762204806

Epoch: 5| Step: 5
Training loss: 1.1206496953964233
Validation loss: 2.0672069837649665

Epoch: 5| Step: 6
Training loss: 2.3592910766601562
Validation loss: 2.072265386581421

Epoch: 5| Step: 7
Training loss: 2.340886116027832
Validation loss: 2.075908730427424

Epoch: 5| Step: 8
Training loss: 2.2072691917419434
Validation loss: 2.0522714157899222

Epoch: 5| Step: 9
Training loss: 2.382577419281006
Validation loss: 2.0574738184611

Epoch: 5| Step: 10
Training loss: 2.4780001640319824
Validation loss: 2.0260525047779083

Epoch: 5| Step: 11
Training loss: 3.325469493865967
Validation loss: 2.0234791884819665

Epoch: 112| Step: 0
Training loss: 2.0158960819244385
Validation loss: 2.013146127263705

Epoch: 5| Step: 1
Training loss: 1.7976925373077393
Validation loss: 2.0122836331526437

Epoch: 5| Step: 2
Training loss: 2.489226818084717
Validation loss: 2.0183541774749756

Epoch: 5| Step: 3
Training loss: 2.202171802520752
Validation loss: 2.0209536850452423

Epoch: 5| Step: 4
Training loss: 1.7475913763046265
Validation loss: 2.0245281954606376

Epoch: 5| Step: 5
Training loss: 2.2936482429504395
Validation loss: 2.0245984146992364

Epoch: 5| Step: 6
Training loss: 2.18275785446167
Validation loss: 2.028205012281736

Epoch: 5| Step: 7
Training loss: 2.241361141204834
Validation loss: 2.0236540138721466

Epoch: 5| Step: 8
Training loss: 2.120527505874634
Validation loss: 2.0267541706562042

Epoch: 5| Step: 9
Training loss: 2.0787081718444824
Validation loss: 2.0250044713417688

Epoch: 5| Step: 10
Training loss: 2.5901198387145996
Validation loss: 2.0322267611821494

Epoch: 5| Step: 11
Training loss: 2.5913801193237305
Validation loss: 2.024418741464615

Epoch: 113| Step: 0
Training loss: 2.234708070755005
Validation loss: 2.0190696169932685

Epoch: 5| Step: 1
Training loss: 1.7721614837646484
Validation loss: 2.018613467613856

Epoch: 5| Step: 2
Training loss: 2.31284761428833
Validation loss: 2.0190306107203164

Epoch: 5| Step: 3
Training loss: 2.2627923488616943
Validation loss: 2.01224514345328

Epoch: 5| Step: 4
Training loss: 2.290431499481201
Validation loss: 2.006495321790377

Epoch: 5| Step: 5
Training loss: 2.2780921459198
Validation loss: 2.0164236376682916

Epoch: 5| Step: 6
Training loss: 2.064711332321167
Validation loss: 2.028861790895462

Epoch: 5| Step: 7
Training loss: 1.982397437095642
Validation loss: 2.024572084347407

Epoch: 5| Step: 8
Training loss: 1.8528047800064087
Validation loss: 2.0315364251534143

Epoch: 5| Step: 9
Training loss: 2.0801920890808105
Validation loss: 2.037548919518789

Epoch: 5| Step: 10
Training loss: 2.2524313926696777
Validation loss: 2.0437070230642953

Epoch: 5| Step: 11
Training loss: 3.109318733215332
Validation loss: 2.0397396236658096

Epoch: 114| Step: 0
Training loss: 2.158088207244873
Validation loss: 2.0395333667596183

Epoch: 5| Step: 1
Training loss: 2.3479621410369873
Validation loss: 2.0548077722390494

Epoch: 5| Step: 2
Training loss: 2.413051128387451
Validation loss: 2.0532412379980087

Epoch: 5| Step: 3
Training loss: 2.1613364219665527
Validation loss: 2.056774069865545

Epoch: 5| Step: 4
Training loss: 2.6505298614501953
Validation loss: 2.042362858851751

Epoch: 5| Step: 5
Training loss: 1.6293449401855469
Validation loss: 2.0376509626706443

Epoch: 5| Step: 6
Training loss: 2.067974805831909
Validation loss: 2.0302225401004157

Epoch: 5| Step: 7
Training loss: 1.654301404953003
Validation loss: 2.023359850049019

Epoch: 5| Step: 8
Training loss: 1.6529630422592163
Validation loss: 2.01774633427461

Epoch: 5| Step: 9
Training loss: 2.6759369373321533
Validation loss: 2.0089602321386337

Epoch: 5| Step: 10
Training loss: 2.448446273803711
Validation loss: 2.012872780362765

Epoch: 5| Step: 11
Training loss: 0.47487539052963257
Validation loss: 2.0160089631875358

Epoch: 115| Step: 0
Training loss: 2.1288108825683594
Validation loss: 2.0137815276781716

Epoch: 5| Step: 1
Training loss: 1.578148603439331
Validation loss: 2.022954066594442

Epoch: 5| Step: 2
Training loss: 2.2979469299316406
Validation loss: 2.0364267279704413

Epoch: 5| Step: 3
Training loss: 1.6152527332305908
Validation loss: 2.0351491471131644

Epoch: 5| Step: 4
Training loss: 2.178295135498047
Validation loss: 2.056159034371376

Epoch: 5| Step: 5
Training loss: 2.3000247478485107
Validation loss: 2.0662202586730323

Epoch: 5| Step: 6
Training loss: 2.22914457321167
Validation loss: 2.049918090303739

Epoch: 5| Step: 7
Training loss: 2.6485581398010254
Validation loss: 2.055324837565422

Epoch: 5| Step: 8
Training loss: 2.3888988494873047
Validation loss: 2.044100801150004

Epoch: 5| Step: 9
Training loss: 2.133528232574463
Validation loss: 2.0277751882870994

Epoch: 5| Step: 10
Training loss: 2.146523952484131
Validation loss: 2.02201942106088

Epoch: 5| Step: 11
Training loss: 1.9597113132476807
Validation loss: 2.0264865954717

Epoch: 116| Step: 0
Training loss: 1.8859198093414307
Validation loss: 2.0204605559508004

Epoch: 5| Step: 1
Training loss: 2.082598924636841
Validation loss: 2.0209654172261557

Epoch: 5| Step: 2
Training loss: 2.128568649291992
Validation loss: 2.0168532033761344

Epoch: 5| Step: 3
Training loss: 1.6522605419158936
Validation loss: 2.0244173854589462

Epoch: 5| Step: 4
Training loss: 2.6198983192443848
Validation loss: 2.025005802512169

Epoch: 5| Step: 5
Training loss: 3.07720947265625
Validation loss: 2.0255208065112433

Epoch: 5| Step: 6
Training loss: 1.930821180343628
Validation loss: 2.0150925368070602

Epoch: 5| Step: 7
Training loss: 2.4200451374053955
Validation loss: 2.0197272350390754

Epoch: 5| Step: 8
Training loss: 1.683136224746704
Validation loss: 2.021012465159098

Epoch: 5| Step: 9
Training loss: 2.1955676078796387
Validation loss: 2.026737704873085

Epoch: 5| Step: 10
Training loss: 1.804826021194458
Validation loss: 2.0313561956087747

Epoch: 5| Step: 11
Training loss: 0.8788095116615295
Validation loss: 2.0208544184764228

Epoch: 117| Step: 0
Training loss: 2.2106785774230957
Validation loss: 2.018285115559896

Epoch: 5| Step: 1
Training loss: 1.6091028451919556
Validation loss: 2.018269712726275

Epoch: 5| Step: 2
Training loss: 2.2639403343200684
Validation loss: 2.0120958536863327

Epoch: 5| Step: 3
Training loss: 2.2566940784454346
Validation loss: 2.005881736675898

Epoch: 5| Step: 4
Training loss: 2.049962282180786
Validation loss: 2.016329124569893

Epoch: 5| Step: 5
Training loss: 1.9346530437469482
Validation loss: 2.0177001605431237

Epoch: 5| Step: 6
Training loss: 2.404881477355957
Validation loss: 2.0280496031045914

Epoch: 5| Step: 7
Training loss: 2.0691866874694824
Validation loss: 2.024484932422638

Epoch: 5| Step: 8
Training loss: 2.400590658187866
Validation loss: 2.019985089699427

Epoch: 5| Step: 9
Training loss: 2.2390873432159424
Validation loss: 2.0170917312304177

Epoch: 5| Step: 10
Training loss: 2.2521934509277344
Validation loss: 2.0221064488093057

Epoch: 5| Step: 11
Training loss: 1.300834059715271
Validation loss: 2.021868402759234

Epoch: 118| Step: 0
Training loss: 1.8098478317260742
Validation loss: 2.0251023968060813

Epoch: 5| Step: 1
Training loss: 1.7663415670394897
Validation loss: 2.0221924632787704

Epoch: 5| Step: 2
Training loss: 1.538968563079834
Validation loss: 2.0250971664985022

Epoch: 5| Step: 3
Training loss: 2.2457399368286133
Validation loss: 2.030663013458252

Epoch: 5| Step: 4
Training loss: 1.9367082118988037
Validation loss: 2.0165166656176248

Epoch: 5| Step: 5
Training loss: 2.152791976928711
Validation loss: 2.022003635764122

Epoch: 5| Step: 6
Training loss: 1.981715440750122
Validation loss: 2.020278498530388

Epoch: 5| Step: 7
Training loss: 2.100677728652954
Validation loss: 2.023286854227384

Epoch: 5| Step: 8
Training loss: 2.7036819458007812
Validation loss: 2.0261459052562714

Epoch: 5| Step: 9
Training loss: 2.6211814880371094
Validation loss: 2.0249185959498086

Epoch: 5| Step: 10
Training loss: 2.3437983989715576
Validation loss: 2.0337886959314346

Epoch: 5| Step: 11
Training loss: 2.209749698638916
Validation loss: 2.0288852552572885

Epoch: 119| Step: 0
Training loss: 1.8762741088867188
Validation loss: 2.0372021595637

Epoch: 5| Step: 1
Training loss: 2.335874319076538
Validation loss: 2.0275754233201346

Epoch: 5| Step: 2
Training loss: 2.2111849784851074
Validation loss: 2.020195464293162

Epoch: 5| Step: 3
Training loss: 2.1047399044036865
Validation loss: 2.0255131920178733

Epoch: 5| Step: 4
Training loss: 1.6780316829681396
Validation loss: 2.018622169891993

Epoch: 5| Step: 5
Training loss: 1.626786231994629
Validation loss: 2.020090435942014

Epoch: 5| Step: 6
Training loss: 2.703670024871826
Validation loss: 2.0138644675413766

Epoch: 5| Step: 7
Training loss: 2.211134433746338
Validation loss: 2.0207937260468802

Epoch: 5| Step: 8
Training loss: 1.64714777469635
Validation loss: 2.0258512645959854

Epoch: 5| Step: 9
Training loss: 2.448246479034424
Validation loss: 2.0231416076421738

Epoch: 5| Step: 10
Training loss: 2.28619384765625
Validation loss: 2.038225387533506

Epoch: 5| Step: 11
Training loss: 2.537383556365967
Validation loss: 2.03713728984197

Epoch: 120| Step: 0
Training loss: 2.496124744415283
Validation loss: 2.033133546511332

Epoch: 5| Step: 1
Training loss: 1.9107551574707031
Validation loss: 2.0355437994003296

Epoch: 5| Step: 2
Training loss: 1.9526296854019165
Validation loss: 2.0278718372186026

Epoch: 5| Step: 3
Training loss: 2.4372684955596924
Validation loss: 2.0281047572692237

Epoch: 5| Step: 4
Training loss: 2.2306175231933594
Validation loss: 2.024514908591906

Epoch: 5| Step: 5
Training loss: 2.179492235183716
Validation loss: 2.0128933240969977

Epoch: 5| Step: 6
Training loss: 2.1210334300994873
Validation loss: 2.0089602917432785

Epoch: 5| Step: 7
Training loss: 1.815058946609497
Validation loss: 2.0116956333319345

Epoch: 5| Step: 8
Training loss: 1.711336374282837
Validation loss: 2.018316686153412

Epoch: 5| Step: 9
Training loss: 1.963396430015564
Validation loss: 2.0131144473950067

Epoch: 5| Step: 10
Training loss: 2.372218608856201
Validation loss: 2.0144505153099694

Epoch: 5| Step: 11
Training loss: 2.753340244293213
Validation loss: 2.0127591590086618

Epoch: 121| Step: 0
Training loss: 1.7960284948349
Validation loss: 2.0105003118515015

Epoch: 5| Step: 1
Training loss: 2.472914218902588
Validation loss: 2.0207356363534927

Epoch: 5| Step: 2
Training loss: 2.2419791221618652
Validation loss: 2.0095278869072595

Epoch: 5| Step: 3
Training loss: 2.146056890487671
Validation loss: 2.0133927961190543

Epoch: 5| Step: 4
Training loss: 1.9282217025756836
Validation loss: 2.0193767299254737

Epoch: 5| Step: 5
Training loss: 2.6160950660705566
Validation loss: 2.025044098496437

Epoch: 5| Step: 6
Training loss: 1.5744415521621704
Validation loss: 2.0210132400194802

Epoch: 5| Step: 7
Training loss: 2.0023772716522217
Validation loss: 2.039459392428398

Epoch: 5| Step: 8
Training loss: 2.311082363128662
Validation loss: 2.030872493982315

Epoch: 5| Step: 9
Training loss: 1.8741166591644287
Validation loss: 2.0406897366046906

Epoch: 5| Step: 10
Training loss: 2.039811611175537
Validation loss: 2.0455456326405206

Epoch: 5| Step: 11
Training loss: 3.2693233489990234
Validation loss: 2.0402393539746604

Epoch: 122| Step: 0
Training loss: 1.9708532094955444
Validation loss: 2.0390781859556832

Epoch: 5| Step: 1
Training loss: 2.3595056533813477
Validation loss: 2.0290643721818924

Epoch: 5| Step: 2
Training loss: 2.2968525886535645
Validation loss: 2.0306744823853173

Epoch: 5| Step: 3
Training loss: 1.7941392660140991
Validation loss: 2.022603611151377

Epoch: 5| Step: 4
Training loss: 2.390512228012085
Validation loss: 2.0037408967812858

Epoch: 5| Step: 5
Training loss: 2.2694900035858154
Validation loss: 2.006144846479098

Epoch: 5| Step: 6
Training loss: 2.02807879447937
Validation loss: 2.011234144369761

Epoch: 5| Step: 7
Training loss: 2.1946330070495605
Validation loss: 2.013726383447647

Epoch: 5| Step: 8
Training loss: 2.10876202583313
Validation loss: 2.012212703625361

Epoch: 5| Step: 9
Training loss: 2.0380258560180664
Validation loss: 2.0158662100632987

Epoch: 5| Step: 10
Training loss: 2.530944585800171
Validation loss: 2.0121363500754037

Epoch: 5| Step: 11
Training loss: 1.2211862802505493
Validation loss: 2.0111754139264426

Epoch: 123| Step: 0
Training loss: 1.9699058532714844
Validation loss: 2.006606787443161

Epoch: 5| Step: 1
Training loss: 1.9064964056015015
Validation loss: 2.0081748962402344

Epoch: 5| Step: 2
Training loss: 2.1651549339294434
Validation loss: 2.007308458288511

Epoch: 5| Step: 3
Training loss: 1.8622729778289795
Validation loss: 2.0118049532175064

Epoch: 5| Step: 4
Training loss: 1.9911892414093018
Validation loss: 2.0169090777635574

Epoch: 5| Step: 5
Training loss: 2.3103084564208984
Validation loss: 2.026259650786718

Epoch: 5| Step: 6
Training loss: 2.041477918624878
Validation loss: 2.0301085313161216

Epoch: 5| Step: 7
Training loss: 2.3513882160186768
Validation loss: 2.039206936955452

Epoch: 5| Step: 8
Training loss: 2.0837912559509277
Validation loss: 2.0382441778977713

Epoch: 5| Step: 9
Training loss: 2.7411584854125977
Validation loss: 2.047528564929962

Epoch: 5| Step: 10
Training loss: 2.2031991481781006
Validation loss: 2.0670697589715323

Epoch: 5| Step: 11
Training loss: 1.3852338790893555
Validation loss: 2.060565640528997

Epoch: 124| Step: 0
Training loss: 2.426421880722046
Validation loss: 2.0843330522378287

Epoch: 5| Step: 1
Training loss: 2.057483196258545
Validation loss: 2.102233404914538

Epoch: 5| Step: 2
Training loss: 2.2119617462158203
Validation loss: 2.1212956060965857

Epoch: 5| Step: 3
Training loss: 2.2897114753723145
Validation loss: 2.136249989271164

Epoch: 5| Step: 4
Training loss: 2.5852084159851074
Validation loss: 2.1100457906723022

Epoch: 5| Step: 5
Training loss: 2.1574249267578125
Validation loss: 2.099038685361544

Epoch: 5| Step: 6
Training loss: 2.6754038333892822
Validation loss: 2.079877585172653

Epoch: 5| Step: 7
Training loss: 1.6269006729125977
Validation loss: 2.0530795603990555

Epoch: 5| Step: 8
Training loss: 1.9504886865615845
Validation loss: 2.0345614552497864

Epoch: 5| Step: 9
Training loss: 2.1442689895629883
Validation loss: 2.0208199620246887

Epoch: 5| Step: 10
Training loss: 1.9013245105743408
Validation loss: 2.0160793364048004

Epoch: 5| Step: 11
Training loss: 1.9095178842544556
Validation loss: 2.0077356894810996

Epoch: 125| Step: 0
Training loss: 2.346290349960327
Validation loss: 2.0082721610864005

Epoch: 5| Step: 1
Training loss: 2.2238097190856934
Validation loss: 2.0101710508267083

Epoch: 5| Step: 2
Training loss: 2.394617795944214
Validation loss: 2.0170925060908

Epoch: 5| Step: 3
Training loss: 2.3081483840942383
Validation loss: 2.020183583100637

Epoch: 5| Step: 4
Training loss: 1.7179409265518188
Validation loss: 2.009699374437332

Epoch: 5| Step: 5
Training loss: 2.2182230949401855
Validation loss: 2.014715696374575

Epoch: 5| Step: 6
Training loss: 2.1875030994415283
Validation loss: 2.022096966703733

Epoch: 5| Step: 7
Training loss: 2.0137877464294434
Validation loss: 2.022642210125923

Epoch: 5| Step: 8
Training loss: 2.2529876232147217
Validation loss: 2.0386882424354553

Epoch: 5| Step: 9
Training loss: 1.846548318862915
Validation loss: 2.031040827433268

Epoch: 5| Step: 10
Training loss: 1.6670398712158203
Validation loss: 2.030865505337715

Epoch: 5| Step: 11
Training loss: 2.4389820098876953
Validation loss: 2.036854311823845

Epoch: 126| Step: 0
Training loss: 2.1741981506347656
Validation loss: 2.0378883282343545

Epoch: 5| Step: 1
Training loss: 1.808793067932129
Validation loss: 2.0394050230582557

Epoch: 5| Step: 2
Training loss: 2.4311258792877197
Validation loss: 2.04379033545653

Epoch: 5| Step: 3
Training loss: 2.492340564727783
Validation loss: 2.0401201198498407

Epoch: 5| Step: 4
Training loss: 2.6351563930511475
Validation loss: 2.0424865235884986

Epoch: 5| Step: 5
Training loss: 1.8726263046264648
Validation loss: 2.0285831292470298

Epoch: 5| Step: 6
Training loss: 1.936335563659668
Validation loss: 2.0225235521793365

Epoch: 5| Step: 7
Training loss: 2.0989747047424316
Validation loss: 2.0370784252882004

Epoch: 5| Step: 8
Training loss: 1.8772456645965576
Validation loss: 2.0284271240234375

Epoch: 5| Step: 9
Training loss: 2.341587781906128
Validation loss: 2.0294825583696365

Epoch: 5| Step: 10
Training loss: 1.9600927829742432
Validation loss: 2.031450087825457

Epoch: 5| Step: 11
Training loss: 0.7968512773513794
Validation loss: 2.0307200650374093

Epoch: 127| Step: 0
Training loss: 2.083483934402466
Validation loss: 2.0300117880105972

Epoch: 5| Step: 1
Training loss: 1.6381866931915283
Validation loss: 2.029109666744868

Epoch: 5| Step: 2
Training loss: 2.340726137161255
Validation loss: 2.0328643123308816

Epoch: 5| Step: 3
Training loss: 2.588449001312256
Validation loss: 2.0238955865303674

Epoch: 5| Step: 4
Training loss: 1.5959410667419434
Validation loss: 2.0262171725432077

Epoch: 5| Step: 5
Training loss: 2.584764242172241
Validation loss: 2.0284857948621116

Epoch: 5| Step: 6
Training loss: 2.0626344680786133
Validation loss: 2.025505075852076

Epoch: 5| Step: 7
Training loss: 2.0473010540008545
Validation loss: 2.0269841055075326

Epoch: 5| Step: 8
Training loss: 2.492570161819458
Validation loss: 2.0254336148500443

Epoch: 5| Step: 9
Training loss: 2.230827569961548
Validation loss: 2.0208439330259957

Epoch: 5| Step: 10
Training loss: 1.849453330039978
Validation loss: 2.019856502612432

Epoch: 5| Step: 11
Training loss: 1.0214412212371826
Validation loss: 2.0150101085503898

Epoch: 128| Step: 0
Training loss: 2.3555729389190674
Validation loss: 2.0174549221992493

Epoch: 5| Step: 1
Training loss: 1.7738618850708008
Validation loss: 2.0215207437674203

Epoch: 5| Step: 2
Training loss: 1.7426183223724365
Validation loss: 2.026377166310946

Epoch: 5| Step: 3
Training loss: 2.146292209625244
Validation loss: 2.023118793964386

Epoch: 5| Step: 4
Training loss: 1.9488286972045898
Validation loss: 2.015139768520991

Epoch: 5| Step: 5
Training loss: 1.7323901653289795
Validation loss: 2.0228807826836905

Epoch: 5| Step: 6
Training loss: 2.3151004314422607
Validation loss: 2.026623929540316

Epoch: 5| Step: 7
Training loss: 1.953879952430725
Validation loss: 2.028060923020045

Epoch: 5| Step: 8
Training loss: 2.200115919113159
Validation loss: 2.030303647120794

Epoch: 5| Step: 9
Training loss: 2.4721274375915527
Validation loss: 2.0361665884653726

Epoch: 5| Step: 10
Training loss: 2.4717013835906982
Validation loss: 2.0462314089139304

Epoch: 5| Step: 11
Training loss: 2.3472256660461426
Validation loss: 2.038411637147268

Epoch: 129| Step: 0
Training loss: 2.330531597137451
Validation loss: 2.025843933224678

Epoch: 5| Step: 1
Training loss: 2.0132622718811035
Validation loss: 2.024968852599462

Epoch: 5| Step: 2
Training loss: 2.0406413078308105
Validation loss: 2.027879779537519

Epoch: 5| Step: 3
Training loss: 1.8197765350341797
Validation loss: 2.0217763682206473

Epoch: 5| Step: 4
Training loss: 2.2412028312683105
Validation loss: 2.021865119536718

Epoch: 5| Step: 5
Training loss: 1.864450216293335
Validation loss: 2.0315820425748825

Epoch: 5| Step: 6
Training loss: 1.8121178150177002
Validation loss: 2.0241040090719857

Epoch: 5| Step: 7
Training loss: 2.1239118576049805
Validation loss: 2.0179478377103806

Epoch: 5| Step: 8
Training loss: 2.6349024772644043
Validation loss: 2.0263062566518784

Epoch: 5| Step: 9
Training loss: 1.890920639038086
Validation loss: 2.0228905578454337

Epoch: 5| Step: 10
Training loss: 2.0860111713409424
Validation loss: 2.0126016587018967

Epoch: 5| Step: 11
Training loss: 2.6832940578460693
Validation loss: 2.0178941090901694

Epoch: 130| Step: 0
Training loss: 2.299417018890381
Validation loss: 2.0119694968064628

Epoch: 5| Step: 1
Training loss: 1.9764350652694702
Validation loss: 2.012899398803711

Epoch: 5| Step: 2
Training loss: 2.59706711769104
Validation loss: 2.011890242497126

Epoch: 5| Step: 3
Training loss: 2.4256367683410645
Validation loss: 2.0157008369763694

Epoch: 5| Step: 4
Training loss: 1.969683051109314
Validation loss: 2.0168745468060174

Epoch: 5| Step: 5
Training loss: 1.296822428703308
Validation loss: 2.018639385700226

Epoch: 5| Step: 6
Training loss: 1.8273277282714844
Validation loss: 2.0182517021894455

Epoch: 5| Step: 7
Training loss: 2.4249625205993652
Validation loss: 2.0213860472043357

Epoch: 5| Step: 8
Training loss: 2.1883463859558105
Validation loss: 2.0321462055047355

Epoch: 5| Step: 9
Training loss: 2.261829376220703
Validation loss: 2.026973287264506

Epoch: 5| Step: 10
Training loss: 1.5972323417663574
Validation loss: 2.031731903553009

Epoch: 5| Step: 11
Training loss: 2.3976049423217773
Validation loss: 2.0331755727529526

Epoch: 131| Step: 0
Training loss: 1.7799947261810303
Validation loss: 2.048320626219114

Epoch: 5| Step: 1
Training loss: 2.18599009513855
Validation loss: 2.042508507768313

Epoch: 5| Step: 2
Training loss: 2.315587282180786
Validation loss: 2.0388429015874863

Epoch: 5| Step: 3
Training loss: 2.006850481033325
Validation loss: 2.041357030471166

Epoch: 5| Step: 4
Training loss: 1.6823619604110718
Validation loss: 2.0286450932423272

Epoch: 5| Step: 5
Training loss: 2.0639822483062744
Validation loss: 2.0246091534694037

Epoch: 5| Step: 6
Training loss: 2.6054866313934326
Validation loss: 2.0203513354063034

Epoch: 5| Step: 7
Training loss: 2.107776641845703
Validation loss: 2.018247420589129

Epoch: 5| Step: 8
Training loss: 1.7948843240737915
Validation loss: 2.016739303867022

Epoch: 5| Step: 9
Training loss: 2.571810245513916
Validation loss: 2.0198635856310525

Epoch: 5| Step: 10
Training loss: 2.2461090087890625
Validation loss: 2.0189134379227958

Epoch: 5| Step: 11
Training loss: 1.7066720724105835
Validation loss: 2.021714448928833

Epoch: 132| Step: 0
Training loss: 2.687678813934326
Validation loss: 2.0291346659262977

Epoch: 5| Step: 1
Training loss: 1.8089697360992432
Validation loss: 2.024896259109179

Epoch: 5| Step: 2
Training loss: 2.088395595550537
Validation loss: 2.028004288673401

Epoch: 5| Step: 3
Training loss: 2.670842409133911
Validation loss: 2.032561575373014

Epoch: 5| Step: 4
Training loss: 2.3028905391693115
Validation loss: 2.0268677175045013

Epoch: 5| Step: 5
Training loss: 2.423408031463623
Validation loss: 2.0349086920420327

Epoch: 5| Step: 6
Training loss: 1.4487063884735107
Validation loss: 2.029024307926496

Epoch: 5| Step: 7
Training loss: 2.3102850914001465
Validation loss: 2.022521590193113

Epoch: 5| Step: 8
Training loss: 2.1130242347717285
Validation loss: 2.033392757177353

Epoch: 5| Step: 9
Training loss: 1.1619529724121094
Validation loss: 2.024701699614525

Epoch: 5| Step: 10
Training loss: 1.8572450876235962
Validation loss: 2.0202067295710244

Epoch: 5| Step: 11
Training loss: 2.3103957176208496
Validation loss: 2.031553735335668

Epoch: 133| Step: 0
Training loss: 1.8872478008270264
Validation loss: 2.0234451045592627

Epoch: 5| Step: 1
Training loss: 2.0708556175231934
Validation loss: 2.0341819326082864

Epoch: 5| Step: 2
Training loss: 2.3787918090820312
Validation loss: 2.03020249803861

Epoch: 5| Step: 3
Training loss: 1.8414547443389893
Validation loss: 2.021773725748062

Epoch: 5| Step: 4
Training loss: 2.161888837814331
Validation loss: 2.023627599080404

Epoch: 5| Step: 5
Training loss: 1.9632774591445923
Validation loss: 2.0261122385660806

Epoch: 5| Step: 6
Training loss: 2.222215175628662
Validation loss: 2.033472533027331

Epoch: 5| Step: 7
Training loss: 1.742269515991211
Validation loss: 2.0317098051309586

Epoch: 5| Step: 8
Training loss: 2.6909663677215576
Validation loss: 2.0296259373426437

Epoch: 5| Step: 9
Training loss: 1.7832019329071045
Validation loss: 2.033038318157196

Epoch: 5| Step: 10
Training loss: 1.948162317276001
Validation loss: 2.043992112080256

Epoch: 5| Step: 11
Training loss: 2.894735336303711
Validation loss: 2.0335906346639

Epoch: 134| Step: 0
Training loss: 2.1216635704040527
Validation loss: 2.0279586811860404

Epoch: 5| Step: 1
Training loss: 2.4524121284484863
Validation loss: 2.0362504522005715

Epoch: 5| Step: 2
Training loss: 1.8400828838348389
Validation loss: 2.0421183705329895

Epoch: 5| Step: 3
Training loss: 2.1450448036193848
Validation loss: 2.037329395612081

Epoch: 5| Step: 4
Training loss: 2.5533223152160645
Validation loss: 2.0370591481526694

Epoch: 5| Step: 5
Training loss: 2.0354561805725098
Validation loss: 2.0297393947839737

Epoch: 5| Step: 6
Training loss: 2.184161424636841
Validation loss: 2.029774953921636

Epoch: 5| Step: 7
Training loss: 2.2096543312072754
Validation loss: 2.0273993412653604

Epoch: 5| Step: 8
Training loss: 1.799590826034546
Validation loss: 2.0217490245898566

Epoch: 5| Step: 9
Training loss: 2.2825417518615723
Validation loss: 2.0203544795513153

Epoch: 5| Step: 10
Training loss: 1.5794636011123657
Validation loss: 2.0290010372797647

Epoch: 5| Step: 11
Training loss: 0.9816914796829224
Validation loss: 2.0413141598304114

Epoch: 135| Step: 0
Training loss: 1.5202162265777588
Validation loss: 2.0300947477420173

Epoch: 5| Step: 1
Training loss: 2.406571865081787
Validation loss: 2.0398021390040717

Epoch: 5| Step: 2
Training loss: 2.116654872894287
Validation loss: 2.053685262799263

Epoch: 5| Step: 3
Training loss: 2.4090144634246826
Validation loss: 2.0771889785925546

Epoch: 5| Step: 4
Training loss: 1.991965889930725
Validation loss: 2.0816070387760797

Epoch: 5| Step: 5
Training loss: 1.8207874298095703
Validation loss: 2.0702545742193856

Epoch: 5| Step: 6
Training loss: 1.5730679035186768
Validation loss: 2.0842399249474206

Epoch: 5| Step: 7
Training loss: 2.0236544609069824
Validation loss: 2.0846420923868814

Epoch: 5| Step: 8
Training loss: 2.440948724746704
Validation loss: 2.066710119446119

Epoch: 5| Step: 9
Training loss: 2.4505715370178223
Validation loss: 2.0660457015037537

Epoch: 5| Step: 10
Training loss: 2.262754440307617
Validation loss: 2.051105792323748

Epoch: 5| Step: 11
Training loss: 2.5297653675079346
Validation loss: 2.0333255579074225

Epoch: 136| Step: 0
Training loss: 2.1197733879089355
Validation loss: 2.024344896276792

Epoch: 5| Step: 1
Training loss: 2.3632826805114746
Validation loss: 2.023233041167259

Epoch: 5| Step: 2
Training loss: 1.8729865550994873
Validation loss: 2.0148169100284576

Epoch: 5| Step: 3
Training loss: 2.251600742340088
Validation loss: 2.0149925549825034

Epoch: 5| Step: 4
Training loss: 2.1807174682617188
Validation loss: 2.022395516435305

Epoch: 5| Step: 5
Training loss: 1.945556402206421
Validation loss: 2.016864021619161

Epoch: 5| Step: 6
Training loss: 1.7888323068618774
Validation loss: 2.023522232969602

Epoch: 5| Step: 7
Training loss: 1.6978607177734375
Validation loss: 2.0309190253416696

Epoch: 5| Step: 8
Training loss: 2.651381731033325
Validation loss: 2.031073143084844

Epoch: 5| Step: 9
Training loss: 2.2356772422790527
Validation loss: 2.028433248400688

Epoch: 5| Step: 10
Training loss: 1.942954659461975
Validation loss: 2.032934680581093

Epoch: 5| Step: 11
Training loss: 1.9301037788391113
Validation loss: 2.04752616584301

Epoch: 137| Step: 0
Training loss: 1.7012088298797607
Validation loss: 2.05599337319533

Epoch: 5| Step: 1
Training loss: 2.022526264190674
Validation loss: 2.0585950165987015

Epoch: 5| Step: 2
Training loss: 2.8751583099365234
Validation loss: 2.0500560998916626

Epoch: 5| Step: 3
Training loss: 2.071784496307373
Validation loss: 2.0557416876157126

Epoch: 5| Step: 4
Training loss: 1.7543178796768188
Validation loss: 2.0593771586815515

Epoch: 5| Step: 5
Training loss: 1.8861984014511108
Validation loss: 2.0375395814577737

Epoch: 5| Step: 6
Training loss: 2.074606418609619
Validation loss: 2.050944318373998

Epoch: 5| Step: 7
Training loss: 1.7851921319961548
Validation loss: 2.0419290512800217

Epoch: 5| Step: 8
Training loss: 2.1538965702056885
Validation loss: 2.050515984495481

Epoch: 5| Step: 9
Training loss: 2.1960196495056152
Validation loss: 2.0355129142602286

Epoch: 5| Step: 10
Training loss: 2.1090776920318604
Validation loss: 2.037887225548426

Epoch: 5| Step: 11
Training loss: 3.456451892852783
Validation loss: 2.0342387557029724

Epoch: 138| Step: 0
Training loss: 1.952508568763733
Validation loss: 2.0348757952451706

Epoch: 5| Step: 1
Training loss: 2.206104278564453
Validation loss: 2.0245195726553598

Epoch: 5| Step: 2
Training loss: 1.9795652627944946
Validation loss: 2.0463666518529258

Epoch: 5| Step: 3
Training loss: 2.242981433868408
Validation loss: 2.043401852250099

Epoch: 5| Step: 4
Training loss: 2.1934924125671387
Validation loss: 2.0551032026608786

Epoch: 5| Step: 5
Training loss: 2.606982707977295
Validation loss: 2.0585795491933823

Epoch: 5| Step: 6
Training loss: 1.9354522228240967
Validation loss: 2.0394798070192337

Epoch: 5| Step: 7
Training loss: 1.7835667133331299
Validation loss: 2.0267996738354364

Epoch: 5| Step: 8
Training loss: 1.9832563400268555
Validation loss: 2.025413691997528

Epoch: 5| Step: 9
Training loss: 2.083721399307251
Validation loss: 2.0182597984870276

Epoch: 5| Step: 10
Training loss: 2.0111560821533203
Validation loss: 2.0204405089219413

Epoch: 5| Step: 11
Training loss: 2.424423933029175
Validation loss: 2.0082260916630426

Epoch: 139| Step: 0
Training loss: 1.6399662494659424
Validation loss: 2.032396838068962

Epoch: 5| Step: 1
Training loss: 2.7020108699798584
Validation loss: 2.058952977259954

Epoch: 5| Step: 2
Training loss: 1.7825229167938232
Validation loss: 2.0547902683417

Epoch: 5| Step: 3
Training loss: 2.6636481285095215
Validation loss: 2.068372825781504

Epoch: 5| Step: 4
Training loss: 2.3774561882019043
Validation loss: 2.0547909438610077

Epoch: 5| Step: 5
Training loss: 2.463756561279297
Validation loss: 2.0519807587067285

Epoch: 5| Step: 6
Training loss: 1.4440419673919678
Validation loss: 2.0739370783170066

Epoch: 5| Step: 7
Training loss: 2.3239903450012207
Validation loss: 2.0398125102122626

Epoch: 5| Step: 8
Training loss: 1.5832659006118774
Validation loss: 2.0221266647179923

Epoch: 5| Step: 9
Training loss: 2.490074634552002
Validation loss: 2.0238616913557053

Epoch: 5| Step: 10
Training loss: 1.6221446990966797
Validation loss: 2.0221679409344993

Epoch: 5| Step: 11
Training loss: 2.9351096153259277
Validation loss: 2.025921473900477

Epoch: 140| Step: 0
Training loss: 2.0693438053131104
Validation loss: 2.0288485884666443

Epoch: 5| Step: 1
Training loss: 2.37725567817688
Validation loss: 2.0252134005228677

Epoch: 5| Step: 2
Training loss: 1.5901435613632202
Validation loss: 2.025570993622144

Epoch: 5| Step: 3
Training loss: 1.803101897239685
Validation loss: 2.041082724928856

Epoch: 5| Step: 4
Training loss: 1.5146383047103882
Validation loss: 2.062160794933637

Epoch: 5| Step: 5
Training loss: 2.472745418548584
Validation loss: 2.0483981321255365

Epoch: 5| Step: 6
Training loss: 2.5315418243408203
Validation loss: 2.061265990138054

Epoch: 5| Step: 7
Training loss: 2.5406641960144043
Validation loss: 2.061917617917061

Epoch: 5| Step: 8
Training loss: 1.9139258861541748
Validation loss: 2.0659186293681464

Epoch: 5| Step: 9
Training loss: 2.2280988693237305
Validation loss: 2.056043157974879

Epoch: 5| Step: 10
Training loss: 1.9525794982910156
Validation loss: 2.058204005161921

Epoch: 5| Step: 11
Training loss: 1.874847173690796
Validation loss: 2.054965595404307

Epoch: 141| Step: 0
Training loss: 2.3877921104431152
Validation loss: 2.061218579610189

Epoch: 5| Step: 1
Training loss: 2.143583059310913
Validation loss: 2.0503289997577667

Epoch: 5| Step: 2
Training loss: 2.1022934913635254
Validation loss: 2.0513480504353843

Epoch: 5| Step: 3
Training loss: 2.0168747901916504
Validation loss: 2.043535386522611

Epoch: 5| Step: 4
Training loss: 1.7764005661010742
Validation loss: 2.0510971198479333

Epoch: 5| Step: 5
Training loss: 2.406017303466797
Validation loss: 2.0552925219138465

Epoch: 5| Step: 6
Training loss: 1.665026068687439
Validation loss: 2.0557053834199905

Epoch: 5| Step: 7
Training loss: 2.1026415824890137
Validation loss: 2.046316067377726

Epoch: 5| Step: 8
Training loss: 1.738838791847229
Validation loss: 2.0418705344200134

Epoch: 5| Step: 9
Training loss: 2.190955638885498
Validation loss: 2.0425978352626166

Epoch: 5| Step: 10
Training loss: 2.478137493133545
Validation loss: 2.0372579395771027

Epoch: 5| Step: 11
Training loss: 1.4186173677444458
Validation loss: 2.040916825334231

Epoch: 142| Step: 0
Training loss: 2.6367745399475098
Validation loss: 2.0360423078139624

Epoch: 5| Step: 1
Training loss: 1.8175798654556274
Validation loss: 2.032986809810003

Epoch: 5| Step: 2
Training loss: 2.3543777465820312
Validation loss: 2.0401851584513984

Epoch: 5| Step: 3
Training loss: 1.9818042516708374
Validation loss: 2.031366358200709

Epoch: 5| Step: 4
Training loss: 1.6866508722305298
Validation loss: 2.0444533129533133

Epoch: 5| Step: 5
Training loss: 1.804610252380371
Validation loss: 2.0556777069965997

Epoch: 5| Step: 6
Training loss: 2.14495849609375
Validation loss: 2.047896405061086

Epoch: 5| Step: 7
Training loss: 2.3543701171875
Validation loss: 2.0492185254891715

Epoch: 5| Step: 8
Training loss: 2.070265769958496
Validation loss: 2.0522897094488144

Epoch: 5| Step: 9
Training loss: 1.923723578453064
Validation loss: 2.0448262095451355

Epoch: 5| Step: 10
Training loss: 2.036076545715332
Validation loss: 2.0429431150356927

Epoch: 5| Step: 11
Training loss: 1.8339718580245972
Validation loss: 2.062139039238294

Epoch: 143| Step: 0
Training loss: 2.0658721923828125
Validation loss: 2.0548297315835953

Epoch: 5| Step: 1
Training loss: 2.0669333934783936
Validation loss: 2.0553019295136132

Epoch: 5| Step: 2
Training loss: 2.772305727005005
Validation loss: 2.049126903216044

Epoch: 5| Step: 3
Training loss: 1.7427856922149658
Validation loss: 2.044911806782087

Epoch: 5| Step: 4
Training loss: 1.7923980951309204
Validation loss: 2.037825713555018

Epoch: 5| Step: 5
Training loss: 1.5772483348846436
Validation loss: 2.0418704549471536

Epoch: 5| Step: 6
Training loss: 2.1502761840820312
Validation loss: 2.0312116543451944

Epoch: 5| Step: 7
Training loss: 2.4869656562805176
Validation loss: 2.034710948665937

Epoch: 5| Step: 8
Training loss: 2.4686522483825684
Validation loss: 2.0363365709781647

Epoch: 5| Step: 9
Training loss: 2.1783032417297363
Validation loss: 2.042828619480133

Epoch: 5| Step: 10
Training loss: 1.5253937244415283
Validation loss: 2.0388829757769904

Epoch: 5| Step: 11
Training loss: 1.925418496131897
Validation loss: 2.040094961722692

Epoch: 144| Step: 0
Training loss: 2.1733322143554688
Validation loss: 2.04669751226902

Epoch: 5| Step: 1
Training loss: 1.9494138956069946
Validation loss: 2.044542501370112

Epoch: 5| Step: 2
Training loss: 2.040245532989502
Validation loss: 2.053574542204539

Epoch: 5| Step: 3
Training loss: 1.8516013622283936
Validation loss: 2.055370807647705

Epoch: 5| Step: 4
Training loss: 2.005155086517334
Validation loss: 2.0628122438987098

Epoch: 5| Step: 5
Training loss: 2.0396296977996826
Validation loss: 2.0734373728434243

Epoch: 5| Step: 6
Training loss: 2.07637357711792
Validation loss: 2.0787462890148163

Epoch: 5| Step: 7
Training loss: 2.0954442024230957
Validation loss: 2.0683848609526954

Epoch: 5| Step: 8
Training loss: 2.0197556018829346
Validation loss: 2.0563625494639077

Epoch: 5| Step: 9
Training loss: 1.912624716758728
Validation loss: 2.065532128016154

Epoch: 5| Step: 10
Training loss: 2.582946300506592
Validation loss: 2.0625451803207397

Epoch: 5| Step: 11
Training loss: 2.798191547393799
Validation loss: 2.0375225991010666

Epoch: 145| Step: 0
Training loss: 2.665917158126831
Validation loss: 2.032134453455607

Epoch: 5| Step: 1
Training loss: 1.8416942358016968
Validation loss: 2.0313129226366677

Epoch: 5| Step: 2
Training loss: 1.8692800998687744
Validation loss: 2.0212110926707587

Epoch: 5| Step: 3
Training loss: 1.900740385055542
Validation loss: 2.0249112298091254

Epoch: 5| Step: 4
Training loss: 1.7952384948730469
Validation loss: 2.034621184070905

Epoch: 5| Step: 5
Training loss: 2.481461763381958
Validation loss: 2.0302352805932364

Epoch: 5| Step: 6
Training loss: 2.213921070098877
Validation loss: 2.0298204123973846

Epoch: 5| Step: 7
Training loss: 2.115935802459717
Validation loss: 2.0286154051621756

Epoch: 5| Step: 8
Training loss: 1.8073419332504272
Validation loss: 2.0247448533773422

Epoch: 5| Step: 9
Training loss: 2.017185688018799
Validation loss: 2.0317258487145105

Epoch: 5| Step: 10
Training loss: 2.330268383026123
Validation loss: 2.035722369949023

Epoch: 5| Step: 11
Training loss: 1.540776252746582
Validation loss: 2.0378156950076423

Epoch: 146| Step: 0
Training loss: 1.9805667400360107
Validation loss: 2.0367758522431054

Epoch: 5| Step: 1
Training loss: 1.6656787395477295
Validation loss: 2.044990206758181

Epoch: 5| Step: 2
Training loss: 2.120159864425659
Validation loss: 2.048972258965174

Epoch: 5| Step: 3
Training loss: 2.4772086143493652
Validation loss: 2.037266398469607

Epoch: 5| Step: 4
Training loss: 2.022437810897827
Validation loss: 2.0488479882478714

Epoch: 5| Step: 5
Training loss: 2.234949827194214
Validation loss: 2.0445460975170135

Epoch: 5| Step: 6
Training loss: 1.8803523778915405
Validation loss: 2.0514110972483954

Epoch: 5| Step: 7
Training loss: 2.7706704139709473
Validation loss: 2.0507069329420724

Epoch: 5| Step: 8
Training loss: 1.7410160303115845
Validation loss: 2.055442447463671

Epoch: 5| Step: 9
Training loss: 2.162475109100342
Validation loss: 2.0622072567542395

Epoch: 5| Step: 10
Training loss: 1.7020905017852783
Validation loss: 2.050342336297035

Epoch: 5| Step: 11
Training loss: 1.959144115447998
Validation loss: 2.048074573278427

Epoch: 147| Step: 0
Training loss: 2.608889579772949
Validation loss: 2.0547720243533454

Epoch: 5| Step: 1
Training loss: 1.9146753549575806
Validation loss: 2.0470613092184067

Epoch: 5| Step: 2
Training loss: 2.2477779388427734
Validation loss: 2.047081912557284

Epoch: 5| Step: 3
Training loss: 1.9480470418930054
Validation loss: 2.0522002478440604

Epoch: 5| Step: 4
Training loss: 1.931264877319336
Validation loss: 2.051690479119619

Epoch: 5| Step: 5
Training loss: 1.7844444513320923
Validation loss: 2.038384273648262

Epoch: 5| Step: 6
Training loss: 1.8410943746566772
Validation loss: 2.0486065497001014

Epoch: 5| Step: 7
Training loss: 2.3174052238464355
Validation loss: 2.0465775380531945

Epoch: 5| Step: 8
Training loss: 2.328045606613159
Validation loss: 2.0461623022953668

Epoch: 5| Step: 9
Training loss: 1.9178470373153687
Validation loss: 2.045982857545217

Epoch: 5| Step: 10
Training loss: 1.8799911737442017
Validation loss: 2.045303006966909

Epoch: 5| Step: 11
Training loss: 1.9042787551879883
Validation loss: 2.0429862439632416

Epoch: 148| Step: 0
Training loss: 2.6231935024261475
Validation loss: 2.0483748664458594

Epoch: 5| Step: 1
Training loss: 1.4570814371109009
Validation loss: 2.0520225018262863

Epoch: 5| Step: 2
Training loss: 2.2338593006134033
Validation loss: 2.055639366308848

Epoch: 5| Step: 3
Training loss: 2.284400463104248
Validation loss: 2.055888906121254

Epoch: 5| Step: 4
Training loss: 2.1517810821533203
Validation loss: 2.0388789673646293

Epoch: 5| Step: 5
Training loss: 1.9043201208114624
Validation loss: 2.0428821047147117

Epoch: 5| Step: 6
Training loss: 2.060106039047241
Validation loss: 2.0363304366668067

Epoch: 5| Step: 7
Training loss: 2.005540370941162
Validation loss: 2.040661017100016

Epoch: 5| Step: 8
Training loss: 2.4721903800964355
Validation loss: 2.037954658269882

Epoch: 5| Step: 9
Training loss: 1.997122049331665
Validation loss: 2.0421789288520813

Epoch: 5| Step: 10
Training loss: 1.4046021699905396
Validation loss: 2.041684707005819

Epoch: 5| Step: 11
Training loss: 3.230283737182617
Validation loss: 2.0696014811595282

Epoch: 149| Step: 0
Training loss: 2.3881685733795166
Validation loss: 2.0931828121344247

Epoch: 5| Step: 1
Training loss: 2.4395878314971924
Validation loss: 2.094684208432833

Epoch: 5| Step: 2
Training loss: 1.9004762172698975
Validation loss: 2.0860330959161124

Epoch: 5| Step: 3
Training loss: 1.9369806051254272
Validation loss: 2.085347672303518

Epoch: 5| Step: 4
Training loss: 1.824380874633789
Validation loss: 2.0711106409629187

Epoch: 5| Step: 5
Training loss: 2.5386734008789062
Validation loss: 2.0571863700946174

Epoch: 5| Step: 6
Training loss: 2.0140304565429688
Validation loss: 2.0569261014461517

Epoch: 5| Step: 7
Training loss: 1.8867709636688232
Validation loss: 2.037245665987333

Epoch: 5| Step: 8
Training loss: 2.2019779682159424
Validation loss: 2.036989430586497

Epoch: 5| Step: 9
Training loss: 2.0723328590393066
Validation loss: 2.034081603089968

Epoch: 5| Step: 10
Training loss: 1.5977206230163574
Validation loss: 2.034745087226232

Epoch: 5| Step: 11
Training loss: 2.271432638168335
Validation loss: 2.036509801944097

Epoch: 150| Step: 0
Training loss: 2.0968105792999268
Validation loss: 2.042468786239624

Epoch: 5| Step: 1
Training loss: 2.1330721378326416
Validation loss: 2.033793181180954

Epoch: 5| Step: 2
Training loss: 2.440526247024536
Validation loss: 2.03451798359553

Epoch: 5| Step: 3
Training loss: 2.365975856781006
Validation loss: 2.039805288116137

Epoch: 5| Step: 4
Training loss: 1.6578342914581299
Validation loss: 2.0372765262921653

Epoch: 5| Step: 5
Training loss: 2.20127534866333
Validation loss: 2.039094095428785

Epoch: 5| Step: 6
Training loss: 2.2019248008728027
Validation loss: 2.0445470064878464

Epoch: 5| Step: 7
Training loss: 1.8565715551376343
Validation loss: 2.0459106812874475

Epoch: 5| Step: 8
Training loss: 1.0053677558898926
Validation loss: 2.070292502641678

Epoch: 5| Step: 9
Training loss: 2.1972689628601074
Validation loss: 2.085092822710673

Epoch: 5| Step: 10
Training loss: 2.5933871269226074
Validation loss: 2.099167933066686

Epoch: 5| Step: 11
Training loss: 2.2507410049438477
Validation loss: 2.062589854001999

Testing loss: 1.6469264836620083
