Epoch: 1| Step: 0
Training loss: 6.187422752380371
Validation loss: 5.333829959233602

Epoch: 5| Step: 1
Training loss: 4.695742130279541
Validation loss: 5.332094470659892

Epoch: 5| Step: 2
Training loss: 5.533780097961426
Validation loss: 5.330330570538838

Epoch: 5| Step: 3
Training loss: 5.767544746398926
Validation loss: 5.328593850135803

Epoch: 5| Step: 4
Training loss: 5.770623207092285
Validation loss: 5.326854805151622

Epoch: 5| Step: 5
Training loss: 4.649040699005127
Validation loss: 5.325067142645518

Epoch: 5| Step: 6
Training loss: 4.646556854248047
Validation loss: 5.323255856831868

Epoch: 5| Step: 7
Training loss: 5.5005083084106445
Validation loss: 5.321349859237671

Epoch: 5| Step: 8
Training loss: 5.1026458740234375
Validation loss: 5.31942484776179

Epoch: 5| Step: 9
Training loss: 5.635080814361572
Validation loss: 5.31739201148351

Epoch: 5| Step: 10
Training loss: 5.997642517089844
Validation loss: 5.315380334854126

Epoch: 5| Step: 11
Training loss: 4.603718280792236
Validation loss: 5.3132267991701765

Epoch: 2| Step: 0
Training loss: 4.7566704750061035
Validation loss: 5.310990512371063

Epoch: 5| Step: 1
Training loss: 5.9789323806762695
Validation loss: 5.308745165665944

Epoch: 5| Step: 2
Training loss: 5.64306116104126
Validation loss: 5.30642428000768

Epoch: 5| Step: 3
Training loss: 5.856027126312256
Validation loss: 5.304013590017955

Epoch: 5| Step: 4
Training loss: 5.555505275726318
Validation loss: 5.30148462454478

Epoch: 5| Step: 5
Training loss: 5.880633354187012
Validation loss: 5.298869887987773

Epoch: 5| Step: 6
Training loss: 5.5977983474731445
Validation loss: 5.2961456179618835

Epoch: 5| Step: 7
Training loss: 4.4066057205200195
Validation loss: 5.293279151121776

Epoch: 5| Step: 8
Training loss: 4.770457744598389
Validation loss: 5.290283262729645

Epoch: 5| Step: 9
Training loss: 5.615714073181152
Validation loss: 5.287106374899547

Epoch: 5| Step: 10
Training loss: 4.973755359649658
Validation loss: 5.283892035484314

Epoch: 5| Step: 11
Training loss: 5.371444225311279
Validation loss: 5.28050023317337

Epoch: 3| Step: 0
Training loss: 5.363430500030518
Validation loss: 5.2769849101702375

Epoch: 5| Step: 1
Training loss: 4.261735439300537
Validation loss: 5.273274739583333

Epoch: 5| Step: 2
Training loss: 5.6995954513549805
Validation loss: 5.269367039203644

Epoch: 5| Step: 3
Training loss: 5.050395488739014
Validation loss: 5.265356043974559

Epoch: 5| Step: 4
Training loss: 4.681519508361816
Validation loss: 5.260997553666432

Epoch: 5| Step: 5
Training loss: 5.406702995300293
Validation loss: 5.256592969099681

Epoch: 5| Step: 6
Training loss: 5.186145782470703
Validation loss: 5.252024471759796

Epoch: 5| Step: 7
Training loss: 6.836977481842041
Validation loss: 5.2472134828567505

Epoch: 5| Step: 8
Training loss: 5.475822448730469
Validation loss: 5.242193500200908

Epoch: 5| Step: 9
Training loss: 5.077327728271484
Validation loss: 5.2369630336761475

Epoch: 5| Step: 10
Training loss: 5.514956474304199
Validation loss: 5.231535752614339

Epoch: 5| Step: 11
Training loss: 5.403834342956543
Validation loss: 5.2258404692014055

Epoch: 4| Step: 0
Training loss: 6.049742698669434
Validation loss: 5.219987610975902

Epoch: 5| Step: 1
Training loss: 4.9484429359436035
Validation loss: 5.213726162910461

Epoch: 5| Step: 2
Training loss: 4.816957950592041
Validation loss: 5.207551737626393

Epoch: 5| Step: 3
Training loss: 5.199176788330078
Validation loss: 5.200966437657674

Epoch: 5| Step: 4
Training loss: 5.644801616668701
Validation loss: 5.193922718365987

Epoch: 5| Step: 5
Training loss: 5.4985246658325195
Validation loss: 5.1868069767951965

Epoch: 5| Step: 6
Training loss: 5.4719977378845215
Validation loss: 5.179616789023082

Epoch: 5| Step: 7
Training loss: 4.73920202255249
Validation loss: 5.172033707300822

Epoch: 5| Step: 8
Training loss: 5.51112174987793
Validation loss: 5.1640706062316895

Epoch: 5| Step: 9
Training loss: 5.554642677307129
Validation loss: 5.156285425027211

Epoch: 5| Step: 10
Training loss: 4.161364555358887
Validation loss: 5.148202617963155

Epoch: 5| Step: 11
Training loss: 6.403660297393799
Validation loss: 5.139567931493123

Epoch: 5| Step: 0
Training loss: 5.704718589782715
Validation loss: 5.131028056144714

Epoch: 5| Step: 1
Training loss: 5.499590873718262
Validation loss: 5.121991773446401

Epoch: 5| Step: 2
Training loss: 4.508440017700195
Validation loss: 5.112651427586873

Epoch: 5| Step: 3
Training loss: 4.999268054962158
Validation loss: 5.103384772936503

Epoch: 5| Step: 4
Training loss: 5.149783611297607
Validation loss: 5.093644579251607

Epoch: 5| Step: 5
Training loss: 4.775906085968018
Validation loss: 5.083570798238118

Epoch: 5| Step: 6
Training loss: 5.401793956756592
Validation loss: 5.0736356774965925

Epoch: 5| Step: 7
Training loss: 5.3606648445129395
Validation loss: 5.063000738620758

Epoch: 5| Step: 8
Training loss: 4.703379154205322
Validation loss: 5.052436113357544

Epoch: 5| Step: 9
Training loss: 5.36608362197876
Validation loss: 5.041573345661163

Epoch: 5| Step: 10
Training loss: 5.427537441253662
Validation loss: 5.030994872252147

Epoch: 5| Step: 11
Training loss: 4.305907249450684
Validation loss: 5.020102560520172

Epoch: 6| Step: 0
Training loss: 5.971083164215088
Validation loss: 5.009074668089549

Epoch: 5| Step: 1
Training loss: 6.179755210876465
Validation loss: 4.998097221056621

Epoch: 5| Step: 2
Training loss: 5.489853382110596
Validation loss: 4.987593154112498

Epoch: 5| Step: 3
Training loss: 4.723254203796387
Validation loss: 4.976845761140187

Epoch: 5| Step: 4
Training loss: 5.075699806213379
Validation loss: 4.96571542819341

Epoch: 5| Step: 5
Training loss: 4.625612258911133
Validation loss: 4.955166379610698

Epoch: 5| Step: 6
Training loss: 4.484475612640381
Validation loss: 4.944259226322174

Epoch: 5| Step: 7
Training loss: 5.07062292098999
Validation loss: 4.93411252895991

Epoch: 5| Step: 8
Training loss: 4.480203628540039
Validation loss: 4.924130916595459

Epoch: 5| Step: 9
Training loss: 4.861544609069824
Validation loss: 4.914157589276631

Epoch: 5| Step: 10
Training loss: 4.5702691078186035
Validation loss: 4.904750764369965

Epoch: 5| Step: 11
Training loss: 4.386641502380371
Validation loss: 4.895447512467702

Epoch: 7| Step: 0
Training loss: 4.348799705505371
Validation loss: 4.886406759421031

Epoch: 5| Step: 1
Training loss: 5.249682903289795
Validation loss: 4.877623836199443

Epoch: 5| Step: 2
Training loss: 5.040102481842041
Validation loss: 4.869025806585948

Epoch: 5| Step: 3
Training loss: 4.19677734375
Validation loss: 4.860798021157582

Epoch: 5| Step: 4
Training loss: 4.489901542663574
Validation loss: 4.852862298488617

Epoch: 5| Step: 5
Training loss: 4.894282817840576
Validation loss: 4.844809055328369

Epoch: 5| Step: 6
Training loss: 6.048953056335449
Validation loss: 4.837136507034302

Epoch: 5| Step: 7
Training loss: 5.47238826751709
Validation loss: 4.82926760117213

Epoch: 5| Step: 8
Training loss: 3.937575578689575
Validation loss: 4.821753064791362

Epoch: 5| Step: 9
Training loss: 5.544083595275879
Validation loss: 4.814602255821228

Epoch: 5| Step: 10
Training loss: 4.974673271179199
Validation loss: 4.807443777720134

Epoch: 5| Step: 11
Training loss: 5.138126373291016
Validation loss: 4.800012588500977

Epoch: 8| Step: 0
Training loss: 4.699029445648193
Validation loss: 4.793245335419972

Epoch: 5| Step: 1
Training loss: 4.621447563171387
Validation loss: 4.78618719180425

Epoch: 5| Step: 2
Training loss: 5.534956932067871
Validation loss: 4.779206424951553

Epoch: 5| Step: 3
Training loss: 4.6824259757995605
Validation loss: 4.772441327571869

Epoch: 5| Step: 4
Training loss: 5.807225227355957
Validation loss: 4.765876491864522

Epoch: 5| Step: 5
Training loss: 4.425233364105225
Validation loss: 4.7595884799957275

Epoch: 5| Step: 6
Training loss: 4.9725565910339355
Validation loss: 4.752846002578735

Epoch: 5| Step: 7
Training loss: 5.17545747756958
Validation loss: 4.746956030527751

Epoch: 5| Step: 8
Training loss: 3.870358943939209
Validation loss: 4.740409195423126

Epoch: 5| Step: 9
Training loss: 5.879314422607422
Validation loss: 4.734199523925781

Epoch: 5| Step: 10
Training loss: 3.9514553546905518
Validation loss: 4.728215297063191

Epoch: 5| Step: 11
Training loss: 3.6047134399414062
Validation loss: 4.722703675429027

Epoch: 9| Step: 0
Training loss: 4.687693119049072
Validation loss: 4.716969758272171

Epoch: 5| Step: 1
Training loss: 4.975164890289307
Validation loss: 4.710930009682973

Epoch: 5| Step: 2
Training loss: 5.268797397613525
Validation loss: 4.705162554979324

Epoch: 5| Step: 3
Training loss: 4.842266082763672
Validation loss: 4.699718077977498

Epoch: 5| Step: 4
Training loss: 3.599548816680908
Validation loss: 4.694149613380432

Epoch: 5| Step: 5
Training loss: 5.434532165527344
Validation loss: 4.688396394252777

Epoch: 5| Step: 6
Training loss: 4.834681510925293
Validation loss: 4.682816286881764

Epoch: 5| Step: 7
Training loss: 4.712285041809082
Validation loss: 4.6774524847666425

Epoch: 5| Step: 8
Training loss: 4.91140604019165
Validation loss: 4.67202349503835

Epoch: 5| Step: 9
Training loss: 4.287434101104736
Validation loss: 4.666833062966664

Epoch: 5| Step: 10
Training loss: 5.078303337097168
Validation loss: 4.66094450155894

Epoch: 5| Step: 11
Training loss: 4.676119327545166
Validation loss: 4.655681331952413

Epoch: 10| Step: 0
Training loss: 5.756471157073975
Validation loss: 4.6501437822977705

Epoch: 5| Step: 1
Training loss: 5.320588111877441
Validation loss: 4.6451906363169355

Epoch: 5| Step: 2
Training loss: 5.1670241355896
Validation loss: 4.639352798461914

Epoch: 5| Step: 3
Training loss: 3.5215556621551514
Validation loss: 4.6335987250010175

Epoch: 5| Step: 4
Training loss: 4.666376113891602
Validation loss: 4.628434369961421

Epoch: 5| Step: 5
Training loss: 4.572524070739746
Validation loss: 4.622904519240062

Epoch: 5| Step: 6
Training loss: 4.647385597229004
Validation loss: 4.617978751659393

Epoch: 5| Step: 7
Training loss: 4.722851753234863
Validation loss: 4.612556368112564

Epoch: 5| Step: 8
Training loss: 4.116243362426758
Validation loss: 4.607557495435079

Epoch: 5| Step: 9
Training loss: 4.403502941131592
Validation loss: 4.602601687113444

Epoch: 5| Step: 10
Training loss: 4.882803916931152
Validation loss: 4.597608665625255

Epoch: 5| Step: 11
Training loss: 5.458281517028809
Validation loss: 4.592638313770294

Epoch: 11| Step: 0
Training loss: 4.351629734039307
Validation loss: 4.587340354919434

Epoch: 5| Step: 1
Training loss: 4.12654447555542
Validation loss: 4.582536419232686

Epoch: 5| Step: 2
Training loss: 5.131322860717773
Validation loss: 4.577563494443893

Epoch: 5| Step: 3
Training loss: 4.790188789367676
Validation loss: 4.572554588317871

Epoch: 5| Step: 4
Training loss: 4.562326431274414
Validation loss: 4.5673633217811584

Epoch: 5| Step: 5
Training loss: 3.9629979133605957
Validation loss: 4.562436282634735

Epoch: 5| Step: 6
Training loss: 4.54400634765625
Validation loss: 4.557609458764394

Epoch: 5| Step: 7
Training loss: 5.192452430725098
Validation loss: 4.552504946788152

Epoch: 5| Step: 8
Training loss: 5.280241012573242
Validation loss: 4.547515094280243

Epoch: 5| Step: 9
Training loss: 5.054637908935547
Validation loss: 4.542294045289357

Epoch: 5| Step: 10
Training loss: 4.370520114898682
Validation loss: 4.537532200415929

Epoch: 5| Step: 11
Training loss: 4.284558296203613
Validation loss: 4.532237261533737

Epoch: 12| Step: 0
Training loss: 4.573922157287598
Validation loss: 4.527736792961757

Epoch: 5| Step: 1
Training loss: 4.756674766540527
Validation loss: 4.522521158059438

Epoch: 5| Step: 2
Training loss: 5.11464786529541
Validation loss: 4.517623384793599

Epoch: 5| Step: 3
Training loss: 4.269898414611816
Validation loss: 4.513070662816365

Epoch: 5| Step: 4
Training loss: 4.542579650878906
Validation loss: 4.507533152898152

Epoch: 5| Step: 5
Training loss: 3.951831340789795
Validation loss: 4.502533733844757

Epoch: 5| Step: 6
Training loss: 4.785916805267334
Validation loss: 4.498287002245585

Epoch: 5| Step: 7
Training loss: 4.948180675506592
Validation loss: 4.493250211079915

Epoch: 5| Step: 8
Training loss: 3.940042018890381
Validation loss: 4.488423387209575

Epoch: 5| Step: 9
Training loss: 5.256332874298096
Validation loss: 4.483097831408183

Epoch: 5| Step: 10
Training loss: 4.881352424621582
Validation loss: 4.478553255399068

Epoch: 5| Step: 11
Training loss: 3.0430078506469727
Validation loss: 4.473455607891083

Epoch: 13| Step: 0
Training loss: 5.309264183044434
Validation loss: 4.469043513139089

Epoch: 5| Step: 1
Training loss: 4.330775260925293
Validation loss: 4.46407675743103

Epoch: 5| Step: 2
Training loss: 4.338222503662109
Validation loss: 4.459363281726837

Epoch: 5| Step: 3
Training loss: 5.042961597442627
Validation loss: 4.454525917768478

Epoch: 5| Step: 4
Training loss: 4.5952677726745605
Validation loss: 4.449312180280685

Epoch: 5| Step: 5
Training loss: 4.301018238067627
Validation loss: 4.443735182285309

Epoch: 5| Step: 6
Training loss: 4.71025276184082
Validation loss: 4.439127534627914

Epoch: 5| Step: 7
Training loss: 4.161706447601318
Validation loss: 4.434057245651881

Epoch: 5| Step: 8
Training loss: 4.11613130569458
Validation loss: 4.429337054491043

Epoch: 5| Step: 9
Training loss: 4.488229274749756
Validation loss: 4.424180706342061

Epoch: 5| Step: 10
Training loss: 4.4236741065979
Validation loss: 4.4189602335294085

Epoch: 5| Step: 11
Training loss: 6.0226287841796875
Validation loss: 4.414367417494456

Epoch: 14| Step: 0
Training loss: 4.580609321594238
Validation loss: 4.4092859625816345

Epoch: 5| Step: 1
Training loss: 4.408404350280762
Validation loss: 4.4042365948359175

Epoch: 5| Step: 2
Training loss: 4.407717704772949
Validation loss: 4.399551212787628

Epoch: 5| Step: 3
Training loss: 4.959177494049072
Validation loss: 4.394541452328364

Epoch: 5| Step: 4
Training loss: 3.679882526397705
Validation loss: 4.388914465904236

Epoch: 5| Step: 5
Training loss: 4.529054164886475
Validation loss: 4.384275575478871

Epoch: 5| Step: 6
Training loss: 4.113055229187012
Validation loss: 4.379414717356364

Epoch: 5| Step: 7
Training loss: 4.350553035736084
Validation loss: 4.373992383480072

Epoch: 5| Step: 8
Training loss: 4.818656921386719
Validation loss: 4.368368625640869

Epoch: 5| Step: 9
Training loss: 4.820862293243408
Validation loss: 4.362840672334035

Epoch: 5| Step: 10
Training loss: 4.716419696807861
Validation loss: 4.358461360136668

Epoch: 5| Step: 11
Training loss: 5.091540336608887
Validation loss: 4.353274534145991

Epoch: 15| Step: 0
Training loss: 4.118683815002441
Validation loss: 4.347760031620662

Epoch: 5| Step: 1
Training loss: 4.917654991149902
Validation loss: 4.342862586180369

Epoch: 5| Step: 2
Training loss: 5.010725498199463
Validation loss: 4.336864988009135

Epoch: 5| Step: 3
Training loss: 4.6026177406311035
Validation loss: 4.3320991198221845

Epoch: 5| Step: 4
Training loss: 4.430264949798584
Validation loss: 4.326606680949529

Epoch: 5| Step: 5
Training loss: 3.9739956855773926
Validation loss: 4.322068413098653

Epoch: 5| Step: 6
Training loss: 5.182276248931885
Validation loss: 4.316367814938228

Epoch: 5| Step: 7
Training loss: 4.1365461349487305
Validation loss: 4.310459733009338

Epoch: 5| Step: 8
Training loss: 4.931844234466553
Validation loss: 4.305269181728363

Epoch: 5| Step: 9
Training loss: 3.6140410900115967
Validation loss: 4.300346593062083

Epoch: 5| Step: 10
Training loss: 4.164178848266602
Validation loss: 4.295784533023834

Epoch: 5| Step: 11
Training loss: 3.4775390625
Validation loss: 4.290373305479686

Epoch: 16| Step: 0
Training loss: 4.7985358238220215
Validation loss: 4.285414089759191

Epoch: 5| Step: 1
Training loss: 4.210434436798096
Validation loss: 4.279801567395528

Epoch: 5| Step: 2
Training loss: 4.341477394104004
Validation loss: 4.275037368138631

Epoch: 5| Step: 3
Training loss: 4.554947853088379
Validation loss: 4.26945502559344

Epoch: 5| Step: 4
Training loss: 3.888098955154419
Validation loss: 4.2637118101119995

Epoch: 5| Step: 5
Training loss: 4.746993064880371
Validation loss: 4.258612136046092

Epoch: 5| Step: 6
Training loss: 5.276711463928223
Validation loss: 4.25339937210083

Epoch: 5| Step: 7
Training loss: 4.353325843811035
Validation loss: 4.248309840758641

Epoch: 5| Step: 8
Training loss: 4.047506332397461
Validation loss: 4.243776649236679

Epoch: 5| Step: 9
Training loss: 3.9267678260803223
Validation loss: 4.238465815782547

Epoch: 5| Step: 10
Training loss: 4.190911293029785
Validation loss: 4.232763270537059

Epoch: 5| Step: 11
Training loss: 3.961627960205078
Validation loss: 4.228271047274272

Epoch: 17| Step: 0
Training loss: 4.774584770202637
Validation loss: 4.223151216904323

Epoch: 5| Step: 1
Training loss: 3.6251931190490723
Validation loss: 4.217904806137085

Epoch: 5| Step: 2
Training loss: 5.409345626831055
Validation loss: 4.211981654167175

Epoch: 5| Step: 3
Training loss: 5.240108966827393
Validation loss: 4.207891821861267

Epoch: 5| Step: 4
Training loss: 3.842899799346924
Validation loss: 4.2027391990025835

Epoch: 5| Step: 5
Training loss: 4.747477054595947
Validation loss: 4.197649339834849

Epoch: 5| Step: 6
Training loss: 4.905353546142578
Validation loss: 4.192092150449753

Epoch: 5| Step: 7
Training loss: 4.519228935241699
Validation loss: 4.186033666133881

Epoch: 5| Step: 8
Training loss: 2.914102554321289
Validation loss: 4.180547883113225

Epoch: 5| Step: 9
Training loss: 3.885777711868286
Validation loss: 4.176213214794795

Epoch: 5| Step: 10
Training loss: 3.8537964820861816
Validation loss: 4.170501361290614

Epoch: 5| Step: 11
Training loss: 3.873664617538452
Validation loss: 4.1659643948078156

Epoch: 18| Step: 0
Training loss: 4.2896294593811035
Validation loss: 4.160609692335129

Epoch: 5| Step: 1
Training loss: 4.336464881896973
Validation loss: 4.155539284149806

Epoch: 5| Step: 2
Training loss: 5.279514312744141
Validation loss: 4.150197843710582

Epoch: 5| Step: 3
Training loss: 4.937870025634766
Validation loss: 4.144800513982773

Epoch: 5| Step: 4
Training loss: 3.862736225128174
Validation loss: 4.139859179655711

Epoch: 5| Step: 5
Training loss: 3.8518173694610596
Validation loss: 4.134818732738495

Epoch: 5| Step: 6
Training loss: 4.477173805236816
Validation loss: 4.129809190829595

Epoch: 5| Step: 7
Training loss: 3.9998366832733154
Validation loss: 4.124984701474507

Epoch: 5| Step: 8
Training loss: 3.4854226112365723
Validation loss: 4.119510968526204

Epoch: 5| Step: 9
Training loss: 4.423495292663574
Validation loss: 4.114218443632126

Epoch: 5| Step: 10
Training loss: 4.369185924530029
Validation loss: 4.110437502463658

Epoch: 5| Step: 11
Training loss: 2.7441492080688477
Validation loss: 4.104953775803248

Epoch: 19| Step: 0
Training loss: 5.316407680511475
Validation loss: 4.100429425636928

Epoch: 5| Step: 1
Training loss: 4.139991760253906
Validation loss: 4.097289055585861

Epoch: 5| Step: 2
Training loss: 4.656370639801025
Validation loss: 4.092618723710378

Epoch: 5| Step: 3
Training loss: 3.8552520275115967
Validation loss: 4.086463809013367

Epoch: 5| Step: 4
Training loss: 4.652251720428467
Validation loss: 4.081814626852672

Epoch: 5| Step: 5
Training loss: 4.132879734039307
Validation loss: 4.077774087587993

Epoch: 5| Step: 6
Training loss: 3.4475300312042236
Validation loss: 4.072359095017116

Epoch: 5| Step: 7
Training loss: 3.965639591217041
Validation loss: 4.0677288969357805

Epoch: 5| Step: 8
Training loss: 3.8288357257843018
Validation loss: 4.0634491840998335

Epoch: 5| Step: 9
Training loss: 4.099634170532227
Validation loss: 4.058949152628581

Epoch: 5| Step: 10
Training loss: 4.229940891265869
Validation loss: 4.0549636880556745

Epoch: 5| Step: 11
Training loss: 4.603998184204102
Validation loss: 4.050727119048436

Epoch: 20| Step: 0
Training loss: 4.1569132804870605
Validation loss: 4.045409083366394

Epoch: 5| Step: 1
Training loss: 3.3546531200408936
Validation loss: 4.040923068920772

Epoch: 5| Step: 2
Training loss: 3.9960861206054688
Validation loss: 4.035875012477239

Epoch: 5| Step: 3
Training loss: 3.158501148223877
Validation loss: 4.0323591729005175

Epoch: 5| Step: 4
Training loss: 4.604618072509766
Validation loss: 4.0275738934675855

Epoch: 5| Step: 5
Training loss: 3.983753204345703
Validation loss: 4.022504955530167

Epoch: 5| Step: 6
Training loss: 4.0699968338012695
Validation loss: 4.018136302630107

Epoch: 5| Step: 7
Training loss: 4.414435863494873
Validation loss: 4.014563202857971

Epoch: 5| Step: 8
Training loss: 5.4414472579956055
Validation loss: 4.010127514600754

Epoch: 5| Step: 9
Training loss: 4.275651454925537
Validation loss: 4.00439515709877

Epoch: 5| Step: 10
Training loss: 4.165892601013184
Validation loss: 3.9993953506151834

Epoch: 5| Step: 11
Training loss: 5.0852251052856445
Validation loss: 3.9952010114987693

Epoch: 21| Step: 0
Training loss: 4.22047758102417
Validation loss: 3.9903028508027396

Epoch: 5| Step: 1
Training loss: 4.070661544799805
Validation loss: 3.9854744573434195

Epoch: 5| Step: 2
Training loss: 4.549688816070557
Validation loss: 3.9809434612592063

Epoch: 5| Step: 3
Training loss: 4.716076850891113
Validation loss: 3.976012537876765

Epoch: 5| Step: 4
Training loss: 4.879531383514404
Validation loss: 3.970465471347173

Epoch: 5| Step: 5
Training loss: 2.572364568710327
Validation loss: 3.9665079911549888

Epoch: 5| Step: 6
Training loss: 3.8948798179626465
Validation loss: 3.96200438340505

Epoch: 5| Step: 7
Training loss: 3.7389063835144043
Validation loss: 3.957226792971293

Epoch: 5| Step: 8
Training loss: 3.684474229812622
Validation loss: 3.9519187013308206

Epoch: 5| Step: 9
Training loss: 4.504789352416992
Validation loss: 3.9472009738286338

Epoch: 5| Step: 10
Training loss: 3.960660934448242
Validation loss: 3.942407806714376

Epoch: 5| Step: 11
Training loss: 6.314610481262207
Validation loss: 3.938132186730703

Epoch: 22| Step: 0
Training loss: 4.223555564880371
Validation loss: 3.932948350906372

Epoch: 5| Step: 1
Training loss: 5.33984375
Validation loss: 3.927827556927999

Epoch: 5| Step: 2
Training loss: 3.867689609527588
Validation loss: 3.9234077533086142

Epoch: 5| Step: 3
Training loss: 3.6879642009735107
Validation loss: 3.919251322746277

Epoch: 5| Step: 4
Training loss: 3.4471123218536377
Validation loss: 3.9146789014339447

Epoch: 5| Step: 5
Training loss: 3.7994415760040283
Validation loss: 3.9104619721571603

Epoch: 5| Step: 6
Training loss: 3.8410701751708984
Validation loss: 3.907715459664663

Epoch: 5| Step: 7
Training loss: 3.748441696166992
Validation loss: 3.902844727039337

Epoch: 5| Step: 8
Training loss: 3.5777580738067627
Validation loss: 3.897464652856191

Epoch: 5| Step: 9
Training loss: 4.785731315612793
Validation loss: 3.891738345225652

Epoch: 5| Step: 10
Training loss: 4.228093147277832
Validation loss: 3.887152989705404

Epoch: 5| Step: 11
Training loss: 4.468033790588379
Validation loss: 3.8837350606918335

Epoch: 23| Step: 0
Training loss: 4.324187755584717
Validation loss: 3.878359615802765

Epoch: 5| Step: 1
Training loss: 4.630308628082275
Validation loss: 3.874328056971232

Epoch: 5| Step: 2
Training loss: 4.165648937225342
Validation loss: 3.868591785430908

Epoch: 5| Step: 3
Training loss: 4.353187561035156
Validation loss: 3.864517241716385

Epoch: 5| Step: 4
Training loss: 4.063455104827881
Validation loss: 3.8601533571879068

Epoch: 5| Step: 5
Training loss: 3.252470016479492
Validation loss: 3.85451606909434

Epoch: 5| Step: 6
Training loss: 3.6153266429901123
Validation loss: 3.8488763769467673

Epoch: 5| Step: 7
Training loss: 3.8822808265686035
Validation loss: 3.843601177136103

Epoch: 5| Step: 8
Training loss: 3.2844040393829346
Validation loss: 3.8388024667898812

Epoch: 5| Step: 9
Training loss: 3.7847237586975098
Validation loss: 3.8354082107543945

Epoch: 5| Step: 10
Training loss: 4.509693145751953
Validation loss: 3.8319663405418396

Epoch: 5| Step: 11
Training loss: 5.0860595703125
Validation loss: 3.8271746238072715

Epoch: 24| Step: 0
Training loss: 4.378155708312988
Validation loss: 3.82252836227417

Epoch: 5| Step: 1
Training loss: 3.902613401412964
Validation loss: 3.816947321097056

Epoch: 5| Step: 2
Training loss: 3.3246071338653564
Validation loss: 3.8117311795552573

Epoch: 5| Step: 3
Training loss: 4.393441200256348
Validation loss: 3.8075276215871177

Epoch: 5| Step: 4
Training loss: 3.910353899002075
Validation loss: 3.8021372656027475

Epoch: 5| Step: 5
Training loss: 4.260952472686768
Validation loss: 3.7976825733979545

Epoch: 5| Step: 6
Training loss: 3.98124623298645
Validation loss: 3.792215903600057

Epoch: 5| Step: 7
Training loss: 3.948345899581909
Validation loss: 3.7886613408724465

Epoch: 5| Step: 8
Training loss: 3.7185120582580566
Validation loss: 3.783723364273707

Epoch: 5| Step: 9
Training loss: 3.661400318145752
Validation loss: 3.7793662448724112

Epoch: 5| Step: 10
Training loss: 4.262635707855225
Validation loss: 3.7745814621448517

Epoch: 5| Step: 11
Training loss: 2.6793103218078613
Validation loss: 3.7691846092542014

Epoch: 25| Step: 0
Training loss: 3.777198076248169
Validation loss: 3.765398214260737

Epoch: 5| Step: 1
Training loss: 4.586576461791992
Validation loss: 3.7611491282780967

Epoch: 5| Step: 2
Training loss: 4.713396072387695
Validation loss: 3.7575557231903076

Epoch: 5| Step: 3
Training loss: 2.9581542015075684
Validation loss: 3.7522566318511963

Epoch: 5| Step: 4
Training loss: 3.823668956756592
Validation loss: 3.7483138740062714

Epoch: 5| Step: 5
Training loss: 3.6133646965026855
Validation loss: 3.7437405586242676

Epoch: 5| Step: 6
Training loss: 3.6758651733398438
Validation loss: 3.7395758032798767

Epoch: 5| Step: 7
Training loss: 4.563878059387207
Validation loss: 3.7347314159075418

Epoch: 5| Step: 8
Training loss: 3.917463779449463
Validation loss: 3.7314319709936776

Epoch: 5| Step: 9
Training loss: 3.7225239276885986
Validation loss: 3.7272066275278726

Epoch: 5| Step: 10
Training loss: 3.7965660095214844
Validation loss: 3.7222744623819985

Epoch: 5| Step: 11
Training loss: 2.8098483085632324
Validation loss: 3.718207816282908

Epoch: 26| Step: 0
Training loss: 3.6185574531555176
Validation loss: 3.7137824396292367

Epoch: 5| Step: 1
Training loss: 3.595363140106201
Validation loss: 3.7101223369439444

Epoch: 5| Step: 2
Training loss: 3.9008164405822754
Validation loss: 3.7049446602662406

Epoch: 5| Step: 3
Training loss: 3.6386146545410156
Validation loss: 3.7012819647789

Epoch: 5| Step: 4
Training loss: 4.169679641723633
Validation loss: 3.69679989417394

Epoch: 5| Step: 5
Training loss: 4.125479698181152
Validation loss: 3.691829025745392

Epoch: 5| Step: 6
Training loss: 3.5831069946289062
Validation loss: 3.6884984374046326

Epoch: 5| Step: 7
Training loss: 4.473541736602783
Validation loss: 3.683954735596975

Epoch: 5| Step: 8
Training loss: 3.5002474784851074
Validation loss: 3.6792941093444824

Epoch: 5| Step: 9
Training loss: 3.952225923538208
Validation loss: 3.674912969271342

Epoch: 5| Step: 10
Training loss: 3.719148635864258
Validation loss: 3.670374095439911

Epoch: 5| Step: 11
Training loss: 4.357130527496338
Validation loss: 3.6672027806440988

Epoch: 27| Step: 0
Training loss: 3.404076099395752
Validation loss: 3.6621960004170737

Epoch: 5| Step: 1
Training loss: 3.9673309326171875
Validation loss: 3.65786204735438

Epoch: 5| Step: 2
Training loss: 3.3646507263183594
Validation loss: 3.6528995037078857

Epoch: 5| Step: 3
Training loss: 4.20770788192749
Validation loss: 3.648390084505081

Epoch: 5| Step: 4
Training loss: 3.579115390777588
Validation loss: 3.6446170111497245

Epoch: 5| Step: 5
Training loss: 3.5957627296447754
Validation loss: 3.6403798361619315

Epoch: 5| Step: 6
Training loss: 3.686312437057495
Validation loss: 3.6344555616378784

Epoch: 5| Step: 7
Training loss: 3.4607224464416504
Validation loss: 3.6307914157708487

Epoch: 5| Step: 8
Training loss: 3.7696852684020996
Validation loss: 3.6262052257855735

Epoch: 5| Step: 9
Training loss: 4.865548610687256
Validation loss: 3.621410916248957

Epoch: 5| Step: 10
Training loss: 4.126812934875488
Validation loss: 3.6178921858469644

Epoch: 5| Step: 11
Training loss: 2.710029125213623
Validation loss: 3.6129402915636697

Epoch: 28| Step: 0
Training loss: 4.250561714172363
Validation loss: 3.6084214647610984

Epoch: 5| Step: 1
Training loss: 3.7255330085754395
Validation loss: 3.603517403205236

Epoch: 5| Step: 2
Training loss: 3.719547986984253
Validation loss: 3.5997999707857766

Epoch: 5| Step: 3
Training loss: 3.7820632457733154
Validation loss: 3.595475892225901

Epoch: 5| Step: 4
Training loss: 3.8660290241241455
Validation loss: 3.5921435058116913

Epoch: 5| Step: 5
Training loss: 3.9829697608947754
Validation loss: 3.5860606332619986

Epoch: 5| Step: 6
Training loss: 4.210149765014648
Validation loss: 3.5802372694015503

Epoch: 5| Step: 7
Training loss: 3.047722339630127
Validation loss: 3.5758053263028464

Epoch: 5| Step: 8
Training loss: 2.7190182209014893
Validation loss: 3.572609712680181

Epoch: 5| Step: 9
Training loss: 4.0457587242126465
Validation loss: 3.5692070027192435

Epoch: 5| Step: 10
Training loss: 4.161383152008057
Validation loss: 3.564872066179911

Epoch: 5| Step: 11
Training loss: 2.452441453933716
Validation loss: 3.5595816175142923

Epoch: 29| Step: 0
Training loss: 3.7173423767089844
Validation loss: 3.5551847418149314

Epoch: 5| Step: 1
Training loss: 3.5978591442108154
Validation loss: 3.5498007933298745

Epoch: 5| Step: 2
Training loss: 4.454841613769531
Validation loss: 3.5468787848949432

Epoch: 5| Step: 3
Training loss: 4.216829776763916
Validation loss: 3.5416594644387565

Epoch: 5| Step: 4
Training loss: 4.312459468841553
Validation loss: 3.5367573897043862

Epoch: 5| Step: 5
Training loss: 3.8132519721984863
Validation loss: 3.531898727019628

Epoch: 5| Step: 6
Training loss: 3.554567813873291
Validation loss: 3.5274265507857003

Epoch: 5| Step: 7
Training loss: 3.4971377849578857
Validation loss: 3.5229322612285614

Epoch: 5| Step: 8
Training loss: 2.7827975749969482
Validation loss: 3.517804811398188

Epoch: 5| Step: 9
Training loss: 3.4466171264648438
Validation loss: 3.513905664285024

Epoch: 5| Step: 10
Training loss: 3.36610746383667
Validation loss: 3.509456773598989

Epoch: 5| Step: 11
Training loss: 3.317641496658325
Validation loss: 3.5056769649187722

Epoch: 30| Step: 0
Training loss: 2.9142568111419678
Validation loss: 3.500651220480601

Epoch: 5| Step: 1
Training loss: 2.995884418487549
Validation loss: 3.4973046084245047

Epoch: 5| Step: 2
Training loss: 4.628288269042969
Validation loss: 3.4932070473829904

Epoch: 5| Step: 3
Training loss: 4.177578926086426
Validation loss: 3.4889364341894784

Epoch: 5| Step: 4
Training loss: 3.661540985107422
Validation loss: 3.48386683066686

Epoch: 5| Step: 5
Training loss: 3.8904037475585938
Validation loss: 3.4794299403826394

Epoch: 5| Step: 6
Training loss: 4.434536933898926
Validation loss: 3.4751610457897186

Epoch: 5| Step: 7
Training loss: 3.6095376014709473
Validation loss: 3.4712777535120645

Epoch: 5| Step: 8
Training loss: 3.9331061840057373
Validation loss: 3.466462582349777

Epoch: 5| Step: 9
Training loss: 2.3318705558776855
Validation loss: 3.4618107676506042

Epoch: 5| Step: 10
Training loss: 3.540510654449463
Validation loss: 3.4572196702162423

Epoch: 5| Step: 11
Training loss: 3.612823963165283
Validation loss: 3.453053464492162

Epoch: 31| Step: 0
Training loss: 3.8362362384796143
Validation loss: 3.4487494031588235

Epoch: 5| Step: 1
Training loss: 3.6656761169433594
Validation loss: 3.4444870253403983

Epoch: 5| Step: 2
Training loss: 3.345111846923828
Validation loss: 3.4400586783885956

Epoch: 5| Step: 3
Training loss: 3.782679796218872
Validation loss: 3.435887893040975

Epoch: 5| Step: 4
Training loss: 3.6083247661590576
Validation loss: 3.4307457208633423

Epoch: 5| Step: 5
Training loss: 3.9707398414611816
Validation loss: 3.425911913315455

Epoch: 5| Step: 6
Training loss: 2.7550294399261475
Validation loss: 3.421857923269272

Epoch: 5| Step: 7
Training loss: 3.3512473106384277
Validation loss: 3.4171931743621826

Epoch: 5| Step: 8
Training loss: 3.68339204788208
Validation loss: 3.4122194945812225

Epoch: 5| Step: 9
Training loss: 3.850954055786133
Validation loss: 3.4085414111614227

Epoch: 5| Step: 10
Training loss: 3.711350917816162
Validation loss: 3.4045707285404205

Epoch: 5| Step: 11
Training loss: 3.4643714427948
Validation loss: 3.399687240521113

Epoch: 32| Step: 0
Training loss: 3.5922999382019043
Validation loss: 3.3958189388116202

Epoch: 5| Step: 1
Training loss: 3.8686726093292236
Validation loss: 3.3915942311286926

Epoch: 5| Step: 2
Training loss: 3.8482117652893066
Validation loss: 3.3874579668045044

Epoch: 5| Step: 3
Training loss: 3.3828346729278564
Validation loss: 3.3833045760790506

Epoch: 5| Step: 4
Training loss: 3.3093883991241455
Validation loss: 3.378964046637217

Epoch: 5| Step: 5
Training loss: 3.805300235748291
Validation loss: 3.3748991191387177

Epoch: 5| Step: 6
Training loss: 3.7718448638916016
Validation loss: 3.3708213369051614

Epoch: 5| Step: 7
Training loss: 3.368264675140381
Validation loss: 3.366524656613668

Epoch: 5| Step: 8
Training loss: 3.1113739013671875
Validation loss: 3.361761659383774

Epoch: 5| Step: 9
Training loss: 3.3584060668945312
Validation loss: 3.358248233795166

Epoch: 5| Step: 10
Training loss: 3.531459093093872
Validation loss: 3.353348046541214

Epoch: 5| Step: 11
Training loss: 3.697624444961548
Validation loss: 3.350264678398768

Epoch: 33| Step: 0
Training loss: 3.314547061920166
Validation loss: 3.345386286576589

Epoch: 5| Step: 1
Training loss: 4.47491455078125
Validation loss: 3.340268552303314

Epoch: 5| Step: 2
Training loss: 4.110973358154297
Validation loss: 3.3358864188194275

Epoch: 5| Step: 3
Training loss: 3.7921767234802246
Validation loss: 3.331496367851893

Epoch: 5| Step: 4
Training loss: 3.2641093730926514
Validation loss: 3.3266224463780723

Epoch: 5| Step: 5
Training loss: 3.221675395965576
Validation loss: 3.322627067565918

Epoch: 5| Step: 6
Training loss: 3.678748369216919
Validation loss: 3.3182923992474875

Epoch: 5| Step: 7
Training loss: 3.287388563156128
Validation loss: 3.314256022373835

Epoch: 5| Step: 8
Training loss: 3.1794674396514893
Validation loss: 3.3090820709864297

Epoch: 5| Step: 9
Training loss: 2.7784688472747803
Validation loss: 3.305382410685221

Epoch: 5| Step: 10
Training loss: 3.3072211742401123
Validation loss: 3.3000155488650003

Epoch: 5| Step: 11
Training loss: 3.7511298656463623
Validation loss: 3.298435151576996

Epoch: 34| Step: 0
Training loss: 3.303429365158081
Validation loss: 3.2969570557276406

Epoch: 5| Step: 1
Training loss: 2.682638645172119
Validation loss: 3.289963742097219

Epoch: 5| Step: 2
Training loss: 3.1999073028564453
Validation loss: 3.2875129779179892

Epoch: 5| Step: 3
Training loss: 3.381762742996216
Validation loss: 3.2804804742336273

Epoch: 5| Step: 4
Training loss: 3.583141326904297
Validation loss: 3.2766080796718597

Epoch: 5| Step: 5
Training loss: 2.8207545280456543
Validation loss: 3.2735049625237784

Epoch: 5| Step: 6
Training loss: 2.819533109664917
Validation loss: 3.2703905403614044

Epoch: 5| Step: 7
Training loss: 3.5147547721862793
Validation loss: 3.2666871746381125

Epoch: 5| Step: 8
Training loss: 4.112575054168701
Validation loss: 3.26319553454717

Epoch: 5| Step: 9
Training loss: 4.188805103302002
Validation loss: 3.2588720122973123

Epoch: 5| Step: 10
Training loss: 4.280211448669434
Validation loss: 3.2540232141812644

Epoch: 5| Step: 11
Training loss: 3.7754459381103516
Validation loss: 3.2497266928354898

Epoch: 35| Step: 0
Training loss: 4.358922004699707
Validation loss: 3.247859408458074

Epoch: 5| Step: 1
Training loss: 3.008911609649658
Validation loss: 3.2453403870264688

Epoch: 5| Step: 2
Training loss: 3.0383574962615967
Validation loss: 3.2380224565664926

Epoch: 5| Step: 3
Training loss: 2.8660590648651123
Validation loss: 3.2335795958836875

Epoch: 5| Step: 4
Training loss: 3.4558627605438232
Validation loss: 3.2298631966114044

Epoch: 5| Step: 5
Training loss: 3.7654426097869873
Validation loss: 3.2255802551905313

Epoch: 5| Step: 6
Training loss: 2.7794344425201416
Validation loss: 3.2217025756835938

Epoch: 5| Step: 7
Training loss: 3.4537525177001953
Validation loss: 3.2190179427464805

Epoch: 5| Step: 8
Training loss: 3.097019672393799
Validation loss: 3.21576327085495

Epoch: 5| Step: 9
Training loss: 3.7497735023498535
Validation loss: 3.212599734465281

Epoch: 5| Step: 10
Training loss: 3.6784043312072754
Validation loss: 3.2075900534788766

Epoch: 5| Step: 11
Training loss: 4.376331329345703
Validation loss: 3.20304669936498

Epoch: 36| Step: 0
Training loss: 3.3261070251464844
Validation loss: 3.198616017897924

Epoch: 5| Step: 1
Training loss: 3.498486280441284
Validation loss: 3.19418665766716

Epoch: 5| Step: 2
Training loss: 3.163822889328003
Validation loss: 3.188958058754603

Epoch: 5| Step: 3
Training loss: 3.140381336212158
Validation loss: 3.1845129231611886

Epoch: 5| Step: 4
Training loss: 4.085275650024414
Validation loss: 3.1809493402640023

Epoch: 5| Step: 5
Training loss: 3.565288543701172
Validation loss: 3.1775357723236084

Epoch: 5| Step: 6
Training loss: 2.9856209754943848
Validation loss: 3.172664612531662

Epoch: 5| Step: 7
Training loss: 2.9712347984313965
Validation loss: 3.168452183405558

Epoch: 5| Step: 8
Training loss: 3.5259957313537598
Validation loss: 3.163381884495417

Epoch: 5| Step: 9
Training loss: 3.472074031829834
Validation loss: 3.1598858336607614

Epoch: 5| Step: 10
Training loss: 3.2586276531219482
Validation loss: 3.154939462741216

Epoch: 5| Step: 11
Training loss: 3.1249303817749023
Validation loss: 3.152474880218506

Epoch: 37| Step: 0
Training loss: 3.426180362701416
Validation loss: 3.147532711426417

Epoch: 5| Step: 1
Training loss: 3.0471198558807373
Validation loss: 3.142902592817942

Epoch: 5| Step: 2
Training loss: 3.168480396270752
Validation loss: 3.138134350379308

Epoch: 5| Step: 3
Training loss: 3.4998936653137207
Validation loss: 3.134004086256027

Epoch: 5| Step: 4
Training loss: 4.246695041656494
Validation loss: 3.129398832718531

Epoch: 5| Step: 5
Training loss: 3.2146549224853516
Validation loss: 3.1250874400138855

Epoch: 5| Step: 6
Training loss: 3.3319950103759766
Validation loss: 3.122282087802887

Epoch: 5| Step: 7
Training loss: 2.936248779296875
Validation loss: 3.1179938316345215

Epoch: 5| Step: 8
Training loss: 2.9072511196136475
Validation loss: 3.1134834587574005

Epoch: 5| Step: 9
Training loss: 3.7230048179626465
Validation loss: 3.109338939189911

Epoch: 5| Step: 10
Training loss: 3.0360054969787598
Validation loss: 3.1062214076519012

Epoch: 5| Step: 11
Training loss: 2.877460479736328
Validation loss: 3.102240910132726

Epoch: 38| Step: 0
Training loss: 3.228485107421875
Validation loss: 3.0980739096800485

Epoch: 5| Step: 1
Training loss: 4.417930603027344
Validation loss: 3.0951273341973624

Epoch: 5| Step: 2
Training loss: 2.5766806602478027
Validation loss: 3.091739902893702

Epoch: 5| Step: 3
Training loss: 2.6421151161193848
Validation loss: 3.0882110595703125

Epoch: 5| Step: 4
Training loss: 2.8575727939605713
Validation loss: 3.0844033559163413

Epoch: 5| Step: 5
Training loss: 2.676665782928467
Validation loss: 3.0811011294523873

Epoch: 5| Step: 6
Training loss: 3.451900005340576
Validation loss: 3.0770195921262107

Epoch: 5| Step: 7
Training loss: 3.195802688598633
Validation loss: 3.0743831197420755

Epoch: 5| Step: 8
Training loss: 3.401419162750244
Validation loss: 3.0715427696704865

Epoch: 5| Step: 9
Training loss: 3.6981024742126465
Validation loss: 3.0707128743330636

Epoch: 5| Step: 10
Training loss: 3.659727096557617
Validation loss: 3.065365711847941

Epoch: 5| Step: 11
Training loss: 4.0976715087890625
Validation loss: 3.065506319204966

Epoch: 39| Step: 0
Training loss: 4.071223735809326
Validation loss: 3.0568582018216452

Epoch: 5| Step: 1
Training loss: 3.400061845779419
Validation loss: 3.0535914997259774

Epoch: 5| Step: 2
Training loss: 2.54828143119812
Validation loss: 3.05201663573583

Epoch: 5| Step: 3
Training loss: 3.1418519020080566
Validation loss: 3.0519767800966897

Epoch: 5| Step: 4
Training loss: 3.8192195892333984
Validation loss: 3.0504409670829773

Epoch: 5| Step: 5
Training loss: 2.7788965702056885
Validation loss: 3.045359124739965

Epoch: 5| Step: 6
Training loss: 3.076829433441162
Validation loss: 3.040373216072718

Epoch: 5| Step: 7
Training loss: 2.9046273231506348
Validation loss: 3.0340077380339303

Epoch: 5| Step: 8
Training loss: 3.560769557952881
Validation loss: 3.029096633195877

Epoch: 5| Step: 9
Training loss: 2.8260340690612793
Validation loss: 3.025473713874817

Epoch: 5| Step: 10
Training loss: 3.4973556995391846
Validation loss: 3.0215603411197662

Epoch: 5| Step: 11
Training loss: 2.9500019550323486
Validation loss: 3.0199387272198996

Epoch: 40| Step: 0
Training loss: 4.038346767425537
Validation loss: 3.017486502726873

Epoch: 5| Step: 1
Training loss: 3.251023530960083
Validation loss: 3.013241241375605

Epoch: 5| Step: 2
Training loss: 3.0009427070617676
Validation loss: 3.0124645431836448

Epoch: 5| Step: 3
Training loss: 3.56829571723938
Validation loss: 3.0090639094511666

Epoch: 5| Step: 4
Training loss: 3.224853992462158
Validation loss: 3.003717025121053

Epoch: 5| Step: 5
Training loss: 3.878103733062744
Validation loss: 2.9997182389100394

Epoch: 5| Step: 6
Training loss: 3.3193860054016113
Validation loss: 2.9946295022964478

Epoch: 5| Step: 7
Training loss: 2.4305834770202637
Validation loss: 2.9917735358079276

Epoch: 5| Step: 8
Training loss: 3.167257070541382
Validation loss: 2.988380958636602

Epoch: 5| Step: 9
Training loss: 2.0497782230377197
Validation loss: 2.985746850570043

Epoch: 5| Step: 10
Training loss: 2.877734422683716
Validation loss: 2.9830962220827737

Epoch: 5| Step: 11
Training loss: 4.887334823608398
Validation loss: 2.981032361586889

Epoch: 41| Step: 0
Training loss: 3.4676613807678223
Validation loss: 2.976461331049601

Epoch: 5| Step: 1
Training loss: 2.642059087753296
Validation loss: 2.9728708465894065

Epoch: 5| Step: 2
Training loss: 3.0816988945007324
Validation loss: 2.968351811170578

Epoch: 5| Step: 3
Training loss: 2.854078769683838
Validation loss: 2.964075654745102

Epoch: 5| Step: 4
Training loss: 2.7786593437194824
Validation loss: 2.9614271322886148

Epoch: 5| Step: 5
Training loss: 4.261425971984863
Validation loss: 2.9577669699986777

Epoch: 5| Step: 6
Training loss: 2.8333487510681152
Validation loss: 2.9533218443393707

Epoch: 5| Step: 7
Training loss: 3.0003228187561035
Validation loss: 2.9501999715964

Epoch: 5| Step: 8
Training loss: 3.4524528980255127
Validation loss: 2.948520521322886

Epoch: 5| Step: 9
Training loss: 2.5173087120056152
Validation loss: 2.9458738366762796

Epoch: 5| Step: 10
Training loss: 3.466888427734375
Validation loss: 2.941843092441559

Epoch: 5| Step: 11
Training loss: 4.942203998565674
Validation loss: 2.938236435254415

Epoch: 42| Step: 0
Training loss: 3.0262539386749268
Validation loss: 2.9337248305479684

Epoch: 5| Step: 1
Training loss: 2.633922576904297
Validation loss: 2.930131584405899

Epoch: 5| Step: 2
Training loss: 3.4415061473846436
Validation loss: 2.9270669321219125

Epoch: 5| Step: 3
Training loss: 2.9651081562042236
Validation loss: 2.922731796900431

Epoch: 5| Step: 4
Training loss: 3.861095428466797
Validation loss: 2.9195705552895865

Epoch: 5| Step: 5
Training loss: 2.955974817276001
Validation loss: 2.915595789750417

Epoch: 5| Step: 6
Training loss: 3.1765151023864746
Validation loss: 2.913041591644287

Epoch: 5| Step: 7
Training loss: 3.1552815437316895
Validation loss: 2.9081183473269143

Epoch: 5| Step: 8
Training loss: 2.8760857582092285
Validation loss: 2.906115412712097

Epoch: 5| Step: 9
Training loss: 2.9238548278808594
Validation loss: 2.9027119576931

Epoch: 5| Step: 10
Training loss: 3.205662488937378
Validation loss: 2.899628152449926

Epoch: 5| Step: 11
Training loss: 3.5537338256835938
Validation loss: 2.8957550326983132

Epoch: 43| Step: 0
Training loss: 3.651789426803589
Validation loss: 2.8967774709065757

Epoch: 5| Step: 1
Training loss: 3.3754501342773438
Validation loss: 2.914259612560272

Epoch: 5| Step: 2
Training loss: 3.2626166343688965
Validation loss: 2.8896932105223336

Epoch: 5| Step: 3
Training loss: 2.5625290870666504
Validation loss: 2.8818141917387643

Epoch: 5| Step: 4
Training loss: 3.544909954071045
Validation loss: 2.8800410330295563

Epoch: 5| Step: 5
Training loss: 3.5474987030029297
Validation loss: 2.8771361211935678

Epoch: 5| Step: 6
Training loss: 3.0075602531433105
Validation loss: 2.877498875061671

Epoch: 5| Step: 7
Training loss: 2.740933418273926
Validation loss: 2.875142047802607

Epoch: 5| Step: 8
Training loss: 2.9653208255767822
Validation loss: 2.8733525971571603

Epoch: 5| Step: 9
Training loss: 2.2680931091308594
Validation loss: 2.86966410279274

Epoch: 5| Step: 10
Training loss: 2.9077067375183105
Validation loss: 2.866168797016144

Epoch: 5| Step: 11
Training loss: 3.870654344558716
Validation loss: 2.862229605515798

Epoch: 44| Step: 0
Training loss: 3.09352445602417
Validation loss: 2.856935133536657

Epoch: 5| Step: 1
Training loss: 3.049668788909912
Validation loss: 2.852004031340281

Epoch: 5| Step: 2
Training loss: 2.9176454544067383
Validation loss: 2.849131236473719

Epoch: 5| Step: 3
Training loss: 3.65580415725708
Validation loss: 2.8459437489509583

Epoch: 5| Step: 4
Training loss: 2.5359995365142822
Validation loss: 2.843057870864868

Epoch: 5| Step: 5
Training loss: 2.624788761138916
Validation loss: 2.8398892680803933

Epoch: 5| Step: 6
Training loss: 3.7919769287109375
Validation loss: 2.837397734324137

Epoch: 5| Step: 7
Training loss: 2.871311664581299
Validation loss: 2.8338860968748727

Epoch: 5| Step: 8
Training loss: 2.9912867546081543
Validation loss: 2.831013629833857

Epoch: 5| Step: 9
Training loss: 3.2381808757781982
Validation loss: 2.8274201403061547

Epoch: 5| Step: 10
Training loss: 2.884106159210205
Validation loss: 2.8228321075439453

Epoch: 5| Step: 11
Training loss: 2.568180561065674
Validation loss: 2.821350574493408

Epoch: 45| Step: 0
Training loss: 3.747962236404419
Validation loss: 2.819858451684316

Epoch: 5| Step: 1
Training loss: 3.0711960792541504
Validation loss: 2.817637413740158

Epoch: 5| Step: 2
Training loss: 3.217705249786377
Validation loss: 2.815480957428614

Epoch: 5| Step: 3
Training loss: 2.56913685798645
Validation loss: 2.813216278950373

Epoch: 5| Step: 4
Training loss: 3.352583408355713
Validation loss: 2.807549695173899

Epoch: 5| Step: 5
Training loss: 3.2537612915039062
Validation loss: 2.8043443659941354

Epoch: 5| Step: 6
Training loss: 2.547433376312256
Validation loss: 2.8025649189949036

Epoch: 5| Step: 7
Training loss: 2.664562225341797
Validation loss: 2.799952268600464

Epoch: 5| Step: 8
Training loss: 2.856489419937134
Validation loss: 2.797773758570353

Epoch: 5| Step: 9
Training loss: 2.8935348987579346
Validation loss: 2.7936313251654306

Epoch: 5| Step: 10
Training loss: 3.0102293491363525
Validation loss: 2.7936453024546304

Epoch: 5| Step: 11
Training loss: 3.0255627632141113
Validation loss: 2.790251135826111

Epoch: 46| Step: 0
Training loss: 2.973987579345703
Validation loss: 2.7873733043670654

Epoch: 5| Step: 1
Training loss: 3.0559463500976562
Validation loss: 2.7860922714074454

Epoch: 5| Step: 2
Training loss: 2.697878360748291
Validation loss: 2.783984969059626

Epoch: 5| Step: 3
Training loss: 2.4372031688690186
Validation loss: 2.7814758121967316

Epoch: 5| Step: 4
Training loss: 3.498539686203003
Validation loss: 2.7779331505298615

Epoch: 5| Step: 5
Training loss: 3.1593289375305176
Validation loss: 2.7746275762716928

Epoch: 5| Step: 6
Training loss: 2.817797899246216
Validation loss: 2.773031363884608

Epoch: 5| Step: 7
Training loss: 3.1738998889923096
Validation loss: 2.7706658939520517

Epoch: 5| Step: 8
Training loss: 2.6425681114196777
Validation loss: 2.768856187661489

Epoch: 5| Step: 9
Training loss: 3.002988338470459
Validation loss: 2.76386296749115

Epoch: 5| Step: 10
Training loss: 3.1616671085357666
Validation loss: 2.7608061830202737

Epoch: 5| Step: 11
Training loss: 4.079380035400391
Validation loss: 2.7573617100715637

Epoch: 47| Step: 0
Training loss: 3.5138542652130127
Validation loss: 2.7545370360215506

Epoch: 5| Step: 1
Training loss: 3.271484375
Validation loss: 2.7523282865683236

Epoch: 5| Step: 2
Training loss: 3.044264554977417
Validation loss: 2.7483124136924744

Epoch: 5| Step: 3
Training loss: 2.7725203037261963
Validation loss: 2.746013323465983

Epoch: 5| Step: 4
Training loss: 2.6354916095733643
Validation loss: 2.743767261505127

Epoch: 5| Step: 5
Training loss: 2.318690776824951
Validation loss: 2.740164796511332

Epoch: 5| Step: 6
Training loss: 3.2186248302459717
Validation loss: 2.7367526094118753

Epoch: 5| Step: 7
Training loss: 2.435580015182495
Validation loss: 2.7338757117589316

Epoch: 5| Step: 8
Training loss: 2.4365055561065674
Validation loss: 2.731567154328028

Epoch: 5| Step: 9
Training loss: 3.1741676330566406
Validation loss: 2.7267364462216697

Epoch: 5| Step: 10
Training loss: 3.3502705097198486
Validation loss: 2.723802854617437

Epoch: 5| Step: 11
Training loss: 4.251152515411377
Validation loss: 2.7219478686650596

Epoch: 48| Step: 0
Training loss: 2.620607852935791
Validation loss: 2.7199179033438363

Epoch: 5| Step: 1
Training loss: 2.718315601348877
Validation loss: 2.7151976227760315

Epoch: 5| Step: 2
Training loss: 3.3944523334503174
Validation loss: 2.7107610007127128

Epoch: 5| Step: 3
Training loss: 2.704777240753174
Validation loss: 2.7091187040011087

Epoch: 5| Step: 4
Training loss: 2.6998610496520996
Validation loss: 2.705493668715159

Epoch: 5| Step: 5
Training loss: 2.9722888469696045
Validation loss: 2.701521545648575

Epoch: 5| Step: 6
Training loss: 3.4984326362609863
Validation loss: 2.6998672485351562

Epoch: 5| Step: 7
Training loss: 3.080063581466675
Validation loss: 2.6951112747192383

Epoch: 5| Step: 8
Training loss: 2.758265972137451
Validation loss: 2.692122201124827

Epoch: 5| Step: 9
Training loss: 2.863903522491455
Validation loss: 2.690245678027471

Epoch: 5| Step: 10
Training loss: 2.674067497253418
Validation loss: 2.6865202287832894

Epoch: 5| Step: 11
Training loss: 3.0140163898468018
Validation loss: 2.6859157383441925

Epoch: 49| Step: 0
Training loss: 3.101858615875244
Validation loss: 2.6822816034158072

Epoch: 5| Step: 1
Training loss: 3.3320746421813965
Validation loss: 2.677588472763697

Epoch: 5| Step: 2
Training loss: 2.91660737991333
Validation loss: 2.674741725126902

Epoch: 5| Step: 3
Training loss: 2.5311896800994873
Validation loss: 2.672013978163401

Epoch: 5| Step: 4
Training loss: 2.5726096630096436
Validation loss: 2.6715654035409293

Epoch: 5| Step: 5
Training loss: 2.7870326042175293
Validation loss: 2.670674522717794

Epoch: 5| Step: 6
Training loss: 3.6604907512664795
Validation loss: 2.668626089890798

Epoch: 5| Step: 7
Training loss: 2.3379712104797363
Validation loss: 2.6651349663734436

Epoch: 5| Step: 8
Training loss: 2.6564393043518066
Validation loss: 2.66229318579038

Epoch: 5| Step: 9
Training loss: 3.1027615070343018
Validation loss: 2.6591190795103707

Epoch: 5| Step: 10
Training loss: 2.3754937648773193
Validation loss: 2.6558300256729126

Epoch: 5| Step: 11
Training loss: 4.027860641479492
Validation loss: 2.6521314283212027

Epoch: 50| Step: 0
Training loss: 3.329550266265869
Validation loss: 2.6470908174912133

Epoch: 5| Step: 1
Training loss: 2.7735648155212402
Validation loss: 2.6425862113634744

Epoch: 5| Step: 2
Training loss: 2.745260238647461
Validation loss: 2.639513889948527

Epoch: 5| Step: 3
Training loss: 2.680701971054077
Validation loss: 2.6354347467422485

Epoch: 5| Step: 4
Training loss: 2.609711170196533
Validation loss: 2.632494737704595

Epoch: 5| Step: 5
Training loss: 2.7952308654785156
Validation loss: 2.6331160167853036

Epoch: 5| Step: 6
Training loss: 2.9741971492767334
Validation loss: 2.6290106972058616

Epoch: 5| Step: 7
Training loss: 2.757194995880127
Validation loss: 2.6263767580191293

Epoch: 5| Step: 8
Training loss: 2.7781167030334473
Validation loss: 2.624067117770513

Epoch: 5| Step: 9
Training loss: 2.987126588821411
Validation loss: 2.6210924784342446

Epoch: 5| Step: 10
Training loss: 2.9517464637756348
Validation loss: 2.615921755631765

Epoch: 5| Step: 11
Training loss: 1.8753894567489624
Validation loss: 2.6128171384334564

Epoch: 51| Step: 0
Training loss: 2.8527355194091797
Validation loss: 2.6103835652271905

Epoch: 5| Step: 1
Training loss: 2.7003376483917236
Validation loss: 2.6060845255851746

Epoch: 5| Step: 2
Training loss: 2.990485668182373
Validation loss: 2.6048463881015778

Epoch: 5| Step: 3
Training loss: 3.1295666694641113
Validation loss: 2.598301817973455

Epoch: 5| Step: 4
Training loss: 2.6674389839172363
Validation loss: 2.595188687245051

Epoch: 5| Step: 5
Training loss: 2.751417636871338
Validation loss: 2.594017436107

Epoch: 5| Step: 6
Training loss: 2.59629487991333
Validation loss: 2.591665198405584

Epoch: 5| Step: 7
Training loss: 2.430737018585205
Validation loss: 2.5881061355272927

Epoch: 5| Step: 8
Training loss: 2.7343900203704834
Validation loss: 2.5850822428862252

Epoch: 5| Step: 9
Training loss: 2.4274725914001465
Validation loss: 2.5786824822425842

Epoch: 5| Step: 10
Training loss: 3.352982997894287
Validation loss: 2.576587508122126

Epoch: 5| Step: 11
Training loss: 3.4536521434783936
Validation loss: 2.5757263898849487

Epoch: 52| Step: 0
Training loss: 2.8018670082092285
Validation loss: 2.5699836909770966

Epoch: 5| Step: 1
Training loss: 2.8472156524658203
Validation loss: 2.569789484143257

Epoch: 5| Step: 2
Training loss: 3.606555938720703
Validation loss: 2.5643249849478402

Epoch: 5| Step: 3
Training loss: 2.7587389945983887
Validation loss: 2.564514622092247

Epoch: 5| Step: 4
Training loss: 2.967963695526123
Validation loss: 2.560914158821106

Epoch: 5| Step: 5
Training loss: 3.0474534034729004
Validation loss: 2.5576930046081543

Epoch: 5| Step: 6
Training loss: 2.6775598526000977
Validation loss: 2.5530776927868524

Epoch: 5| Step: 7
Training loss: 2.3883395195007324
Validation loss: 2.5517015109459558

Epoch: 5| Step: 8
Training loss: 2.1799874305725098
Validation loss: 2.550713116923968

Epoch: 5| Step: 9
Training loss: 2.5556507110595703
Validation loss: 2.5437165598074594

Epoch: 5| Step: 10
Training loss: 2.5146212577819824
Validation loss: 2.543454726537069

Epoch: 5| Step: 11
Training loss: 2.7556300163269043
Validation loss: 2.5417200922966003

Epoch: 53| Step: 0
Training loss: 2.583547353744507
Validation loss: 2.5386463602383933

Epoch: 5| Step: 1
Training loss: 2.7038650512695312
Validation loss: 2.5374264220396676

Epoch: 5| Step: 2
Training loss: 2.146449089050293
Validation loss: 2.5352489749590554

Epoch: 5| Step: 3
Training loss: 3.2132256031036377
Validation loss: 2.5326680690050125

Epoch: 5| Step: 4
Training loss: 2.9783787727355957
Validation loss: 2.5298228760560355

Epoch: 5| Step: 5
Training loss: 2.7825446128845215
Validation loss: 2.526977449655533

Epoch: 5| Step: 6
Training loss: 3.0642457008361816
Validation loss: 2.5241307417551675

Epoch: 5| Step: 7
Training loss: 2.9951107501983643
Validation loss: 2.522860566775004

Epoch: 5| Step: 8
Training loss: 2.529853105545044
Validation loss: 2.518262734015783

Epoch: 5| Step: 9
Training loss: 2.641288995742798
Validation loss: 2.5185967783133187

Epoch: 5| Step: 10
Training loss: 2.217061996459961
Validation loss: 2.5157147149244943

Epoch: 5| Step: 11
Training loss: 3.274618625640869
Validation loss: 2.509384661912918

Epoch: 54| Step: 0
Training loss: 2.368821382522583
Validation loss: 2.5082125266393027

Epoch: 5| Step: 1
Training loss: 2.567577600479126
Validation loss: 2.5064806938171387

Epoch: 5| Step: 2
Training loss: 2.4870352745056152
Validation loss: 2.504845827817917

Epoch: 5| Step: 3
Training loss: 2.995525360107422
Validation loss: 2.5009272595246634

Epoch: 5| Step: 4
Training loss: 2.668912649154663
Validation loss: 2.4987339874108634

Epoch: 5| Step: 5
Training loss: 2.5885443687438965
Validation loss: 2.4967608650525412

Epoch: 5| Step: 6
Training loss: 2.234243869781494
Validation loss: 2.4961334268252053

Epoch: 5| Step: 7
Training loss: 2.5876717567443848
Validation loss: 2.492744634548823

Epoch: 5| Step: 8
Training loss: 3.0529544353485107
Validation loss: 2.49193874001503

Epoch: 5| Step: 9
Training loss: 3.3906219005584717
Validation loss: 2.4885123670101166

Epoch: 5| Step: 10
Training loss: 2.524723768234253
Validation loss: 2.485174556573232

Epoch: 5| Step: 11
Training loss: 3.5418591499328613
Validation loss: 2.482736657063166

Epoch: 55| Step: 0
Training loss: 2.732671022415161
Validation loss: 2.477377245823542

Epoch: 5| Step: 1
Training loss: 2.618232250213623
Validation loss: 2.478745440642039

Epoch: 5| Step: 2
Training loss: 3.1405324935913086
Validation loss: 2.4730152686436973

Epoch: 5| Step: 3
Training loss: 2.7535853385925293
Validation loss: 2.4744112690289817

Epoch: 5| Step: 4
Training loss: 2.6841986179351807
Validation loss: 2.4713688294092813

Epoch: 5| Step: 5
Training loss: 2.5601449012756348
Validation loss: 2.469429781039556

Epoch: 5| Step: 6
Training loss: 2.046208381652832
Validation loss: 2.4645689924558005

Epoch: 5| Step: 7
Training loss: 2.6833317279815674
Validation loss: 2.4653505384922028

Epoch: 5| Step: 8
Training loss: 2.862321376800537
Validation loss: 2.460897068182627

Epoch: 5| Step: 9
Training loss: 2.415227174758911
Validation loss: 2.4580108324686685

Epoch: 5| Step: 10
Training loss: 2.5357747077941895
Validation loss: 2.4530178109804788

Epoch: 5| Step: 11
Training loss: 3.710646390914917
Validation loss: 2.4558980812629065

Epoch: 56| Step: 0
Training loss: 3.3400821685791016
Validation loss: 2.4524157593647637

Epoch: 5| Step: 1
Training loss: 2.6583404541015625
Validation loss: 2.4466855426629386

Epoch: 5| Step: 2
Training loss: 2.5792126655578613
Validation loss: 2.444637656211853

Epoch: 5| Step: 3
Training loss: 2.647489070892334
Validation loss: 2.440775861342748

Epoch: 5| Step: 4
Training loss: 2.4058289527893066
Validation loss: 2.4407664140065513

Epoch: 5| Step: 5
Training loss: 2.2445290088653564
Validation loss: 2.4347192148367562

Epoch: 5| Step: 6
Training loss: 2.356945514678955
Validation loss: 2.435204734404882

Epoch: 5| Step: 7
Training loss: 2.7409377098083496
Validation loss: 2.4313159187634787

Epoch: 5| Step: 8
Training loss: 2.647087574005127
Validation loss: 2.4304032574097314

Epoch: 5| Step: 9
Training loss: 2.8126866817474365
Validation loss: 2.425127243002256

Epoch: 5| Step: 10
Training loss: 2.374953031539917
Validation loss: 2.4239167223374047

Epoch: 5| Step: 11
Training loss: 3.072930335998535
Validation loss: 2.4197152902682624

Epoch: 57| Step: 0
Training loss: 2.2824196815490723
Validation loss: 2.417627682288488

Epoch: 5| Step: 1
Training loss: 2.2118916511535645
Validation loss: 2.417086213827133

Epoch: 5| Step: 2
Training loss: 2.790386915206909
Validation loss: 2.4125299950440726

Epoch: 5| Step: 3
Training loss: 2.8341712951660156
Validation loss: 2.4135528604189553

Epoch: 5| Step: 4
Training loss: 2.4089062213897705
Validation loss: 2.4129018584887185

Epoch: 5| Step: 5
Training loss: 2.2670083045959473
Validation loss: 2.412406543890635

Epoch: 5| Step: 6
Training loss: 2.7932586669921875
Validation loss: 2.4040242234865823

Epoch: 5| Step: 7
Training loss: 2.6634633541107178
Validation loss: 2.398424963156382

Epoch: 5| Step: 8
Training loss: 3.154991626739502
Validation loss: 2.3984083930651345

Epoch: 5| Step: 9
Training loss: 2.6010732650756836
Validation loss: 2.3991848031679788

Epoch: 5| Step: 10
Training loss: 2.8086137771606445
Validation loss: 2.3961221476395926

Epoch: 5| Step: 11
Training loss: 1.3448865413665771
Validation loss: 2.3924280206362405

Epoch: 58| Step: 0
Training loss: 2.6944146156311035
Validation loss: 2.3897827863693237

Epoch: 5| Step: 1
Training loss: 2.737502336502075
Validation loss: 2.391262630621592

Epoch: 5| Step: 2
Training loss: 2.213961124420166
Validation loss: 2.38619726896286

Epoch: 5| Step: 3
Training loss: 2.1049890518188477
Validation loss: 2.383554140726725

Epoch: 5| Step: 4
Training loss: 2.2638049125671387
Validation loss: 2.379786411921183

Epoch: 5| Step: 5
Training loss: 3.0436863899230957
Validation loss: 2.3791458308696747

Epoch: 5| Step: 6
Training loss: 2.8821640014648438
Validation loss: 2.376505583524704

Epoch: 5| Step: 7
Training loss: 2.682290554046631
Validation loss: 2.373640169699987

Epoch: 5| Step: 8
Training loss: 2.5232887268066406
Validation loss: 2.368445962667465

Epoch: 5| Step: 9
Training loss: 2.3447399139404297
Validation loss: 2.3698709905147552

Epoch: 5| Step: 10
Training loss: 2.7394261360168457
Validation loss: 2.3682215909163156

Epoch: 5| Step: 11
Training loss: 2.4245057106018066
Validation loss: 2.3651766628026962

Epoch: 59| Step: 0
Training loss: 2.808685779571533
Validation loss: 2.3604257901509604

Epoch: 5| Step: 1
Training loss: 2.4878017902374268
Validation loss: 2.361909568309784

Epoch: 5| Step: 2
Training loss: 2.734682559967041
Validation loss: 2.359143058458964

Epoch: 5| Step: 3
Training loss: 2.5997917652130127
Validation loss: 2.357135454813639

Epoch: 5| Step: 4
Training loss: 2.3675358295440674
Validation loss: 2.355059007803599

Epoch: 5| Step: 5
Training loss: 1.9198309183120728
Validation loss: 2.3554792205492654

Epoch: 5| Step: 6
Training loss: 2.5759198665618896
Validation loss: 2.3502681056658425

Epoch: 5| Step: 7
Training loss: 2.383833408355713
Validation loss: 2.348828395207723

Epoch: 5| Step: 8
Training loss: 2.4435415267944336
Validation loss: 2.347365806500117

Epoch: 5| Step: 9
Training loss: 2.9465222358703613
Validation loss: 2.3422059466441474

Epoch: 5| Step: 10
Training loss: 2.909224271774292
Validation loss: 2.339491148789724

Epoch: 5| Step: 11
Training loss: 1.0943398475646973
Validation loss: 2.3338687817255654

Epoch: 60| Step: 0
Training loss: 2.104566812515259
Validation loss: 2.3351440181334815

Epoch: 5| Step: 1
Training loss: 3.1510682106018066
Validation loss: 2.3343695600827536

Epoch: 5| Step: 2
Training loss: 2.6321873664855957
Validation loss: 2.3303307741880417

Epoch: 5| Step: 3
Training loss: 1.9639995098114014
Validation loss: 2.324719468752543

Epoch: 5| Step: 4
Training loss: 2.402505874633789
Validation loss: 2.319569999972979

Epoch: 5| Step: 5
Training loss: 2.265981674194336
Validation loss: 2.3277925898631415

Epoch: 5| Step: 6
Training loss: 2.521696090698242
Validation loss: 2.3326029032468796

Epoch: 5| Step: 7
Training loss: 2.52308988571167
Validation loss: 2.3228148221969604

Epoch: 5| Step: 8
Training loss: 2.586648941040039
Validation loss: 2.3189013997713723

Epoch: 5| Step: 9
Training loss: 2.516531467437744
Validation loss: 2.3169307112693787

Epoch: 5| Step: 10
Training loss: 3.0059092044830322
Validation loss: 2.320616066455841

Epoch: 5| Step: 11
Training loss: 2.068366527557373
Validation loss: 2.3252132882674537

Epoch: 61| Step: 0
Training loss: 2.9630112648010254
Validation loss: 2.3283272137244544

Epoch: 5| Step: 1
Training loss: 3.4836857318878174
Validation loss: 2.329169139266014

Epoch: 5| Step: 2
Training loss: 2.2738192081451416
Validation loss: 2.3228536595900855

Epoch: 5| Step: 3
Training loss: 2.6453118324279785
Validation loss: 2.32267918686072

Epoch: 5| Step: 4
Training loss: 2.2453677654266357
Validation loss: 2.315446972846985

Epoch: 5| Step: 5
Training loss: 2.231736421585083
Validation loss: 2.309263586997986

Epoch: 5| Step: 6
Training loss: 2.5043444633483887
Validation loss: 2.3039351205031076

Epoch: 5| Step: 7
Training loss: 2.648820400238037
Validation loss: 2.2994833985964456

Epoch: 5| Step: 8
Training loss: 2.1069393157958984
Validation loss: 2.2955604096253714

Epoch: 5| Step: 9
Training loss: 2.3638672828674316
Validation loss: 2.2955219546953836

Epoch: 5| Step: 10
Training loss: 2.004089593887329
Validation loss: 2.2879530787467957

Epoch: 5| Step: 11
Training loss: 1.8425955772399902
Validation loss: 2.2862243354320526

Epoch: 62| Step: 0
Training loss: 2.2150869369506836
Validation loss: 2.2848033756017685

Epoch: 5| Step: 1
Training loss: 2.637406826019287
Validation loss: 2.283547282218933

Epoch: 5| Step: 2
Training loss: 2.250588893890381
Validation loss: 2.287951489289602

Epoch: 5| Step: 3
Training loss: 2.0946242809295654
Validation loss: 2.2872942835092545

Epoch: 5| Step: 4
Training loss: 2.47973895072937
Validation loss: 2.2774947186311087

Epoch: 5| Step: 5
Training loss: 2.3750014305114746
Validation loss: 2.275923808415731

Epoch: 5| Step: 6
Training loss: 2.246561050415039
Validation loss: 2.2712981353203454

Epoch: 5| Step: 7
Training loss: 2.8086318969726562
Validation loss: 2.266267071167628

Epoch: 5| Step: 8
Training loss: 2.605006456375122
Validation loss: 2.266670286655426

Epoch: 5| Step: 9
Training loss: 2.9030776023864746
Validation loss: 2.2664026270310083

Epoch: 5| Step: 10
Training loss: 2.346710443496704
Validation loss: 2.2650040884812674

Epoch: 5| Step: 11
Training loss: 2.425370216369629
Validation loss: 2.2615327338377633

Epoch: 63| Step: 0
Training loss: 1.9708009958267212
Validation loss: 2.2579326083262763

Epoch: 5| Step: 1
Training loss: 3.0709927082061768
Validation loss: 2.2570013304551444

Epoch: 5| Step: 2
Training loss: 2.5744259357452393
Validation loss: 2.2555464456478753

Epoch: 5| Step: 3
Training loss: 2.447233200073242
Validation loss: 2.2564473847548165

Epoch: 5| Step: 4
Training loss: 2.0234460830688477
Validation loss: 2.2553789019584656

Epoch: 5| Step: 5
Training loss: 2.3957881927490234
Validation loss: 2.2503098249435425

Epoch: 5| Step: 6
Training loss: 2.306486129760742
Validation loss: 2.242280120650927

Epoch: 5| Step: 7
Training loss: 2.1535916328430176
Validation loss: 2.239660605788231

Epoch: 5| Step: 8
Training loss: 2.6139118671417236
Validation loss: 2.2416678766409555

Epoch: 5| Step: 9
Training loss: 2.472102642059326
Validation loss: 2.2381043285131454

Epoch: 5| Step: 10
Training loss: 2.4707775115966797
Validation loss: 2.238362744450569

Epoch: 5| Step: 11
Training loss: 2.779665946960449
Validation loss: 2.2327441374460855

Epoch: 64| Step: 0
Training loss: 2.3636727333068848
Validation loss: 2.232964744170507

Epoch: 5| Step: 1
Training loss: 2.3576464653015137
Validation loss: 2.2305565079053244

Epoch: 5| Step: 2
Training loss: 2.7457752227783203
Validation loss: 2.231055667002996

Epoch: 5| Step: 3
Training loss: 1.2315469980239868
Validation loss: 2.223832676808039

Epoch: 5| Step: 4
Training loss: 2.633155345916748
Validation loss: 2.226224273443222

Epoch: 5| Step: 5
Training loss: 2.71825909614563
Validation loss: 2.2242115139961243

Epoch: 5| Step: 6
Training loss: 2.934450387954712
Validation loss: 2.2176064948240914

Epoch: 5| Step: 7
Training loss: 1.8089011907577515
Validation loss: 2.2181285669406257

Epoch: 5| Step: 8
Training loss: 2.0314884185791016
Validation loss: 2.212347755829493

Epoch: 5| Step: 9
Training loss: 2.965681791305542
Validation loss: 2.2138191113869348

Epoch: 5| Step: 10
Training loss: 2.491210460662842
Validation loss: 2.209706907471021

Epoch: 5| Step: 11
Training loss: 2.263892889022827
Validation loss: 2.207094207406044

Epoch: 65| Step: 0
Training loss: 2.037755012512207
Validation loss: 2.207689886291822

Epoch: 5| Step: 1
Training loss: 2.292280673980713
Validation loss: 2.2100841253995895

Epoch: 5| Step: 2
Training loss: 2.007324695587158
Validation loss: 2.206565946340561

Epoch: 5| Step: 3
Training loss: 2.1148552894592285
Validation loss: 2.2056247293949127

Epoch: 5| Step: 4
Training loss: 2.567931890487671
Validation loss: 2.1999240666627884

Epoch: 5| Step: 5
Training loss: 2.683481216430664
Validation loss: 2.1990640610456467

Epoch: 5| Step: 6
Training loss: 2.182497978210449
Validation loss: 2.1945195446411767

Epoch: 5| Step: 7
Training loss: 2.2795512676239014
Validation loss: 2.1930289963881173

Epoch: 5| Step: 8
Training loss: 1.8890390396118164
Validation loss: 2.1926545898119607

Epoch: 5| Step: 9
Training loss: 2.8615305423736572
Validation loss: 2.1920671463012695

Epoch: 5| Step: 10
Training loss: 3.0852530002593994
Validation loss: 2.1960482398668923

Epoch: 5| Step: 11
Training loss: 2.6541900634765625
Validation loss: 2.1912974566221237

Epoch: 66| Step: 0
Training loss: 2.029275417327881
Validation loss: 2.193120062351227

Epoch: 5| Step: 1
Training loss: 2.535357713699341
Validation loss: 2.190908511479696

Epoch: 5| Step: 2
Training loss: 2.36607027053833
Validation loss: 2.1922945280869803

Epoch: 5| Step: 3
Training loss: 2.5363609790802
Validation loss: 2.1876722077528634

Epoch: 5| Step: 4
Training loss: 2.5671463012695312
Validation loss: 2.18374095360438

Epoch: 5| Step: 5
Training loss: 2.1464500427246094
Validation loss: 2.178936039408048

Epoch: 5| Step: 6
Training loss: 2.809830904006958
Validation loss: 2.1775929729143777

Epoch: 5| Step: 7
Training loss: 2.0703585147857666
Validation loss: 2.1711500386397042

Epoch: 5| Step: 8
Training loss: 2.0224645137786865
Validation loss: 2.1743082404136658

Epoch: 5| Step: 9
Training loss: 2.578589916229248
Validation loss: 2.1683988720178604

Epoch: 5| Step: 10
Training loss: 2.121201992034912
Validation loss: 2.172365978360176

Epoch: 5| Step: 11
Training loss: 2.5226292610168457
Validation loss: 2.1717768708864846

Epoch: 67| Step: 0
Training loss: 2.333556890487671
Validation loss: 2.1757941842079163

Epoch: 5| Step: 1
Training loss: 2.274341106414795
Validation loss: 2.1776121457417807

Epoch: 5| Step: 2
Training loss: 2.7423298358917236
Validation loss: 2.17851585149765

Epoch: 5| Step: 3
Training loss: 2.275632858276367
Validation loss: 2.1809434394041696

Epoch: 5| Step: 4
Training loss: 2.223073959350586
Validation loss: 2.18405020236969

Epoch: 5| Step: 5
Training loss: 2.6182475090026855
Validation loss: 2.1828774412473044

Epoch: 5| Step: 6
Training loss: 2.5046792030334473
Validation loss: 2.177543506026268

Epoch: 5| Step: 7
Training loss: 2.4025204181671143
Validation loss: 2.170339892307917

Epoch: 5| Step: 8
Training loss: 2.1613972187042236
Validation loss: 2.1694706082344055

Epoch: 5| Step: 9
Training loss: 1.6392379999160767
Validation loss: 2.1608823388814926

Epoch: 5| Step: 10
Training loss: 2.643517017364502
Validation loss: 2.1570899734894433

Epoch: 5| Step: 11
Training loss: 2.0519487857818604
Validation loss: 2.1559988061587014

Epoch: 68| Step: 0
Training loss: 2.468031644821167
Validation loss: 2.1509923934936523

Epoch: 5| Step: 1
Training loss: 2.125669479370117
Validation loss: 2.146996592481931

Epoch: 5| Step: 2
Training loss: 2.14784574508667
Validation loss: 2.1469970842202506

Epoch: 5| Step: 3
Training loss: 2.855581283569336
Validation loss: 2.1546449611584344

Epoch: 5| Step: 4
Training loss: 1.8230555057525635
Validation loss: 2.1561480462551117

Epoch: 5| Step: 5
Training loss: 1.9918533563613892
Validation loss: 2.1622004012266793

Epoch: 5| Step: 6
Training loss: 2.334603786468506
Validation loss: 2.170290539662043

Epoch: 5| Step: 7
Training loss: 2.920558214187622
Validation loss: 2.1663380761941275

Epoch: 5| Step: 8
Training loss: 2.51383113861084
Validation loss: 2.17204358180364

Epoch: 5| Step: 9
Training loss: 2.0239052772521973
Validation loss: 2.151745726664861

Epoch: 5| Step: 10
Training loss: 2.2682509422302246
Validation loss: 2.1433795988559723

Epoch: 5| Step: 11
Training loss: 3.6519112586975098
Validation loss: 2.1433841586112976

Epoch: 69| Step: 0
Training loss: 2.3246352672576904
Validation loss: 2.1478336254755654

Epoch: 5| Step: 1
Training loss: 2.1827173233032227
Validation loss: 2.155701145529747

Epoch: 5| Step: 2
Training loss: 2.507241725921631
Validation loss: 2.161919410030047

Epoch: 5| Step: 3
Training loss: 2.449716091156006
Validation loss: 2.1755654166142144

Epoch: 5| Step: 4
Training loss: 2.3698763847351074
Validation loss: 2.1869864563147225

Epoch: 5| Step: 5
Training loss: 2.2327449321746826
Validation loss: 2.18998791774114

Epoch: 5| Step: 6
Training loss: 2.0782673358917236
Validation loss: 2.1900116155544915

Epoch: 5| Step: 7
Training loss: 2.526630163192749
Validation loss: 2.173385962843895

Epoch: 5| Step: 8
Training loss: 2.0110573768615723
Validation loss: 2.169525235891342

Epoch: 5| Step: 9
Training loss: 2.0072531700134277
Validation loss: 2.1635202169418335

Epoch: 5| Step: 10
Training loss: 2.9069762229919434
Validation loss: 2.1537173787752786

Epoch: 5| Step: 11
Training loss: 2.78932785987854
Validation loss: 2.1451901396115622

Epoch: 70| Step: 0
Training loss: 2.211430072784424
Validation loss: 2.138051708539327

Epoch: 5| Step: 1
Training loss: 2.313636541366577
Validation loss: 2.1340299546718597

Epoch: 5| Step: 2
Training loss: 2.636258363723755
Validation loss: 2.12896192073822

Epoch: 5| Step: 3
Training loss: 2.2043275833129883
Validation loss: 2.1273934145768485

Epoch: 5| Step: 4
Training loss: 2.4167239665985107
Validation loss: 2.122450148065885

Epoch: 5| Step: 5
Training loss: 2.4423184394836426
Validation loss: 2.1216479490200677

Epoch: 5| Step: 6
Training loss: 2.2997469902038574
Validation loss: 2.117557391524315

Epoch: 5| Step: 7
Training loss: 2.089043378829956
Validation loss: 2.1146439413229623

Epoch: 5| Step: 8
Training loss: 1.4930317401885986
Validation loss: 2.1117266515890756

Epoch: 5| Step: 9
Training loss: 2.510986089706421
Validation loss: 2.1175535867611566

Epoch: 5| Step: 10
Training loss: 2.7110848426818848
Validation loss: 2.1190986980994544

Epoch: 5| Step: 11
Training loss: 2.335115909576416
Validation loss: 2.1177789072195687

Epoch: 71| Step: 0
Training loss: 2.5454747676849365
Validation loss: 2.1142351627349854

Epoch: 5| Step: 1
Training loss: 2.3919408321380615
Validation loss: 2.1156737258036933

Epoch: 5| Step: 2
Training loss: 1.919363021850586
Validation loss: 2.113510469595591

Epoch: 5| Step: 3
Training loss: 2.8497166633605957
Validation loss: 2.113886614640554

Epoch: 5| Step: 4
Training loss: 1.9943554401397705
Validation loss: 2.113834008574486

Epoch: 5| Step: 5
Training loss: 2.2893147468566895
Validation loss: 2.117330660422643

Epoch: 5| Step: 6
Training loss: 2.9306302070617676
Validation loss: 2.1082337299982705

Epoch: 5| Step: 7
Training loss: 2.0181899070739746
Validation loss: 2.109676460425059

Epoch: 5| Step: 8
Training loss: 1.77512526512146
Validation loss: 2.1054141422112784

Epoch: 5| Step: 9
Training loss: 2.32407808303833
Validation loss: 2.1038809021313987

Epoch: 5| Step: 10
Training loss: 2.3331587314605713
Validation loss: 2.1064266860485077

Epoch: 5| Step: 11
Training loss: 1.5608071088790894
Validation loss: 2.1031673749287925

Epoch: 72| Step: 0
Training loss: 2.644310474395752
Validation loss: 2.100051000714302

Epoch: 5| Step: 1
Training loss: 2.0720293521881104
Validation loss: 2.0998174597819648

Epoch: 5| Step: 2
Training loss: 2.470534086227417
Validation loss: 2.101467380921046

Epoch: 5| Step: 3
Training loss: 2.144134044647217
Validation loss: 2.099359482526779

Epoch: 5| Step: 4
Training loss: 2.870960235595703
Validation loss: 2.096882149577141

Epoch: 5| Step: 5
Training loss: 2.03208327293396
Validation loss: 2.0918545722961426

Epoch: 5| Step: 6
Training loss: 2.220397472381592
Validation loss: 2.088915745417277

Epoch: 5| Step: 7
Training loss: 2.3413617610931396
Validation loss: 2.092244183023771

Epoch: 5| Step: 8
Training loss: 2.243971824645996
Validation loss: 2.088719363013903

Epoch: 5| Step: 9
Training loss: 2.186122417449951
Validation loss: 2.0887375672658286

Epoch: 5| Step: 10
Training loss: 1.8066352605819702
Validation loss: 2.0923744092384973

Epoch: 5| Step: 11
Training loss: 2.490528106689453
Validation loss: 2.0856326818466187

Epoch: 73| Step: 0
Training loss: 2.0548512935638428
Validation loss: 2.093684116999308

Epoch: 5| Step: 1
Training loss: 1.8968315124511719
Validation loss: 2.0944285144408545

Epoch: 5| Step: 2
Training loss: 2.196715831756592
Validation loss: 2.0999347269535065

Epoch: 5| Step: 3
Training loss: 1.829602837562561
Validation loss: 2.1008831411600113

Epoch: 5| Step: 4
Training loss: 2.765488862991333
Validation loss: 2.100654552380244

Epoch: 5| Step: 5
Training loss: 2.5005931854248047
Validation loss: 2.1022097865740457

Epoch: 5| Step: 6
Training loss: 2.3445942401885986
Validation loss: 2.1018854826688766

Epoch: 5| Step: 7
Training loss: 2.4126534461975098
Validation loss: 2.1037940680980682

Epoch: 5| Step: 8
Training loss: 2.283006191253662
Validation loss: 2.1018731941779456

Epoch: 5| Step: 9
Training loss: 2.3461086750030518
Validation loss: 2.1040115306774774

Epoch: 5| Step: 10
Training loss: 2.492121458053589
Validation loss: 2.0979813834031424

Epoch: 5| Step: 11
Training loss: 2.504183292388916
Validation loss: 2.0964848498503366

Epoch: 74| Step: 0
Training loss: 2.7343850135803223
Validation loss: 2.0939663350582123

Epoch: 5| Step: 1
Training loss: 1.8909600973129272
Validation loss: 2.089760864774386

Epoch: 5| Step: 2
Training loss: 2.5767548084259033
Validation loss: 2.088551332553228

Epoch: 5| Step: 3
Training loss: 2.307776927947998
Validation loss: 2.082343821724256

Epoch: 5| Step: 4
Training loss: 2.48909330368042
Validation loss: 2.0827074398597083

Epoch: 5| Step: 5
Training loss: 2.0250680446624756
Validation loss: 2.0730642080307007

Epoch: 5| Step: 6
Training loss: 2.213588237762451
Validation loss: 2.073393945892652

Epoch: 5| Step: 7
Training loss: 2.6760075092315674
Validation loss: 2.071441814303398

Epoch: 5| Step: 8
Training loss: 2.3770594596862793
Validation loss: 2.0686186403036118

Epoch: 5| Step: 9
Training loss: 1.5904676914215088
Validation loss: 2.0742654154698053

Epoch: 5| Step: 10
Training loss: 2.0651638507843018
Validation loss: 2.0653495838244758

Epoch: 5| Step: 11
Training loss: 2.6159234046936035
Validation loss: 2.061293989419937

Epoch: 75| Step: 0
Training loss: 2.3470871448516846
Validation loss: 2.0634433726469674

Epoch: 5| Step: 1
Training loss: 2.5325398445129395
Validation loss: 2.063307151198387

Epoch: 5| Step: 2
Training loss: 2.235896348953247
Validation loss: 2.0623512218395867

Epoch: 5| Step: 3
Training loss: 2.684476137161255
Validation loss: 2.065856471657753

Epoch: 5| Step: 4
Training loss: 2.1224005222320557
Validation loss: 2.0631287594636283

Epoch: 5| Step: 5
Training loss: 1.9950497150421143
Validation loss: 2.078889404733976

Epoch: 5| Step: 6
Training loss: 2.005276918411255
Validation loss: 2.079510197043419

Epoch: 5| Step: 7
Training loss: 2.57320237159729
Validation loss: 2.0755657305320105

Epoch: 5| Step: 8
Training loss: 2.5137290954589844
Validation loss: 2.0636332035064697

Epoch: 5| Step: 9
Training loss: 1.9922759532928467
Validation loss: 2.060056279102961

Epoch: 5| Step: 10
Training loss: 1.8925098180770874
Validation loss: 2.063636635740598

Epoch: 5| Step: 11
Training loss: 1.897883415222168
Validation loss: 2.0566331247488656

Epoch: 76| Step: 0
Training loss: 2.2503116130828857
Validation loss: 2.0550838808218637

Epoch: 5| Step: 1
Training loss: 2.297311782836914
Validation loss: 2.058732802669207

Epoch: 5| Step: 2
Training loss: 2.677863597869873
Validation loss: 2.0636019309361777

Epoch: 5| Step: 3
Training loss: 2.243048667907715
Validation loss: 2.0637259731690087

Epoch: 5| Step: 4
Training loss: 2.1927082538604736
Validation loss: 2.065601627031962

Epoch: 5| Step: 5
Training loss: 2.3957066535949707
Validation loss: 2.0606566617886224

Epoch: 5| Step: 6
Training loss: 2.2911505699157715
Validation loss: 2.0589570005734763

Epoch: 5| Step: 7
Training loss: 2.321058988571167
Validation loss: 2.060225342710813

Epoch: 5| Step: 8
Training loss: 2.0934224128723145
Validation loss: 2.0536926637093225

Epoch: 5| Step: 9
Training loss: 2.098588228225708
Validation loss: 2.051840826869011

Epoch: 5| Step: 10
Training loss: 1.9454638957977295
Validation loss: 2.0514120161533356

Epoch: 5| Step: 11
Training loss: 1.91627836227417
Validation loss: 2.0571331779162088

Epoch: 77| Step: 0
Training loss: 1.8737252950668335
Validation loss: 2.0635585337877274

Epoch: 5| Step: 1
Training loss: 2.4586939811706543
Validation loss: 2.088524967432022

Epoch: 5| Step: 2
Training loss: 2.3639633655548096
Validation loss: 2.09207791586717

Epoch: 5| Step: 3
Training loss: 2.428626775741577
Validation loss: 2.079596057534218

Epoch: 5| Step: 4
Training loss: 2.0966005325317383
Validation loss: 2.0806897232929864

Epoch: 5| Step: 5
Training loss: 1.8985233306884766
Validation loss: 2.080764646331469

Epoch: 5| Step: 6
Training loss: 1.8654285669326782
Validation loss: 2.070910250147184

Epoch: 5| Step: 7
Training loss: 1.968327283859253
Validation loss: 2.0631951093673706

Epoch: 5| Step: 8
Training loss: 2.7784008979797363
Validation loss: 2.0684823940197625

Epoch: 5| Step: 9
Training loss: 2.2429051399230957
Validation loss: 2.0625706166028976

Epoch: 5| Step: 10
Training loss: 2.700935125350952
Validation loss: 2.064647192756335

Epoch: 5| Step: 11
Training loss: 3.4759879112243652
Validation loss: 2.0589407483736673

Epoch: 78| Step: 0
Training loss: 1.8912200927734375
Validation loss: 2.065352459748586

Epoch: 5| Step: 1
Training loss: 2.154000997543335
Validation loss: 2.069560786088308

Epoch: 5| Step: 2
Training loss: 1.9552074670791626
Validation loss: 2.077684501806895

Epoch: 5| Step: 3
Training loss: 1.8870586156845093
Validation loss: 2.0782950470844903

Epoch: 5| Step: 4
Training loss: 2.2490639686584473
Validation loss: 2.0789203147093454

Epoch: 5| Step: 5
Training loss: 2.730440616607666
Validation loss: 2.0911992390950522

Epoch: 5| Step: 6
Training loss: 2.267267942428589
Validation loss: 2.0862236072619758

Epoch: 5| Step: 7
Training loss: 2.515017032623291
Validation loss: 2.076759616533915

Epoch: 5| Step: 8
Training loss: 1.8193089962005615
Validation loss: 2.063882663846016

Epoch: 5| Step: 9
Training loss: 2.842014789581299
Validation loss: 2.060773382584254

Epoch: 5| Step: 10
Training loss: 2.360128879547119
Validation loss: 2.047365759809812

Epoch: 5| Step: 11
Training loss: 3.3132481575012207
Validation loss: 2.0519102861483893

Epoch: 79| Step: 0
Training loss: 1.8403688669204712
Validation loss: 2.045480082432429

Epoch: 5| Step: 1
Training loss: 2.0032334327697754
Validation loss: 2.0452587654193244

Epoch: 5| Step: 2
Training loss: 2.441615343093872
Validation loss: 2.0492755472660065

Epoch: 5| Step: 3
Training loss: 2.4946043491363525
Validation loss: 2.0388047943512597

Epoch: 5| Step: 4
Training loss: 2.8677287101745605
Validation loss: 2.0401357462008796

Epoch: 5| Step: 5
Training loss: 1.662383794784546
Validation loss: 2.039764389395714

Epoch: 5| Step: 6
Training loss: 2.154581308364868
Validation loss: 2.044079750776291

Epoch: 5| Step: 7
Training loss: 2.1384670734405518
Validation loss: 2.0518563191095986

Epoch: 5| Step: 8
Training loss: 1.9502910375595093
Validation loss: 2.059212476015091

Epoch: 5| Step: 9
Training loss: 1.883204698562622
Validation loss: 2.0495444486538568

Epoch: 5| Step: 10
Training loss: 3.0569076538085938
Validation loss: 2.0483671128749847

Epoch: 5| Step: 11
Training loss: 3.3250951766967773
Validation loss: 2.044546032945315

Epoch: 80| Step: 0
Training loss: 2.0057568550109863
Validation loss: 2.0415550669034324

Epoch: 5| Step: 1
Training loss: 1.8807265758514404
Validation loss: 2.0409400264422097

Epoch: 5| Step: 2
Training loss: 2.2180838584899902
Validation loss: 2.034149537483851

Epoch: 5| Step: 3
Training loss: 2.3492298126220703
Validation loss: 2.0411521593729653

Epoch: 5| Step: 4
Training loss: 2.29182767868042
Validation loss: 2.0418446362018585

Epoch: 5| Step: 5
Training loss: 2.4211227893829346
Validation loss: 2.0375287930170694

Epoch: 5| Step: 6
Training loss: 2.589968204498291
Validation loss: 2.039436712861061

Epoch: 5| Step: 7
Training loss: 2.140956401824951
Validation loss: 2.043098891774813

Epoch: 5| Step: 8
Training loss: 2.111269474029541
Validation loss: 2.033506607015928

Epoch: 5| Step: 9
Training loss: 1.8752597570419312
Validation loss: 2.0348063111305237

Epoch: 5| Step: 10
Training loss: 2.5597355365753174
Validation loss: 2.0402597784996033

Epoch: 5| Step: 11
Training loss: 2.5418853759765625
Validation loss: 2.041809245944023

Epoch: 81| Step: 0
Training loss: 2.043550968170166
Validation loss: 2.0353235801060996

Epoch: 5| Step: 1
Training loss: 1.7602485418319702
Validation loss: 2.034985134998957

Epoch: 5| Step: 2
Training loss: 2.4935059547424316
Validation loss: 2.0302108377218246

Epoch: 5| Step: 3
Training loss: 2.631657600402832
Validation loss: 2.030491774280866

Epoch: 5| Step: 4
Training loss: 2.154465913772583
Validation loss: 2.0235136250654855

Epoch: 5| Step: 5
Training loss: 1.9269077777862549
Validation loss: 2.0250397423903146

Epoch: 5| Step: 6
Training loss: 2.534327983856201
Validation loss: 2.0222055663665137

Epoch: 5| Step: 7
Training loss: 2.106812000274658
Validation loss: 2.020195593436559

Epoch: 5| Step: 8
Training loss: 2.5922884941101074
Validation loss: 2.0282109677791595

Epoch: 5| Step: 9
Training loss: 2.2339961528778076
Validation loss: 2.028244207302729

Epoch: 5| Step: 10
Training loss: 1.8080103397369385
Validation loss: 2.0335252483685813

Epoch: 5| Step: 11
Training loss: 2.8784594535827637
Validation loss: 2.0358033776283264

Epoch: 82| Step: 0
Training loss: 2.0482897758483887
Validation loss: 2.0326247811317444

Epoch: 5| Step: 1
Training loss: 2.203399181365967
Validation loss: 2.02890079220136

Epoch: 5| Step: 2
Training loss: 2.3511061668395996
Validation loss: 2.0250368267297745

Epoch: 5| Step: 3
Training loss: 2.061767101287842
Validation loss: 2.027645935614904

Epoch: 5| Step: 4
Training loss: 2.7066588401794434
Validation loss: 2.0324888080358505

Epoch: 5| Step: 5
Training loss: 2.118286371231079
Validation loss: 2.0273486574490867

Epoch: 5| Step: 6
Training loss: 1.7414395809173584
Validation loss: 2.0252710580825806

Epoch: 5| Step: 7
Training loss: 2.1855130195617676
Validation loss: 2.021977961063385

Epoch: 5| Step: 8
Training loss: 2.1055045127868652
Validation loss: 2.020440032084783

Epoch: 5| Step: 9
Training loss: 2.225147247314453
Validation loss: 2.0241156071424484

Epoch: 5| Step: 10
Training loss: 2.6730377674102783
Validation loss: 2.024715711673101

Epoch: 5| Step: 11
Training loss: 1.6246864795684814
Validation loss: 2.030634010831515

Epoch: 83| Step: 0
Training loss: 1.6578041315078735
Validation loss: 2.0357261250416436

Epoch: 5| Step: 1
Training loss: 2.408670425415039
Validation loss: 2.0506012390057244

Epoch: 5| Step: 2
Training loss: 2.145735263824463
Validation loss: 2.045043468475342

Epoch: 5| Step: 3
Training loss: 2.1069092750549316
Validation loss: 2.04715758562088

Epoch: 5| Step: 4
Training loss: 1.9229854345321655
Validation loss: 2.039001593987147

Epoch: 5| Step: 5
Training loss: 2.284242630004883
Validation loss: 2.034865985314051

Epoch: 5| Step: 6
Training loss: 2.091787576675415
Validation loss: 2.0213946849107742

Epoch: 5| Step: 7
Training loss: 2.820338487625122
Validation loss: 2.0188345462083817

Epoch: 5| Step: 8
Training loss: 2.1583809852600098
Validation loss: 2.024659509460131

Epoch: 5| Step: 9
Training loss: 2.4033265113830566
Validation loss: 2.0292290101448693

Epoch: 5| Step: 10
Training loss: 2.584909439086914
Validation loss: 2.0336132645606995

Epoch: 5| Step: 11
Training loss: 1.4786193370819092
Validation loss: 2.0292070657014847

Epoch: 84| Step: 0
Training loss: 2.1500308513641357
Validation loss: 2.02940571308136

Epoch: 5| Step: 1
Training loss: 2.0442376136779785
Validation loss: 2.036537562807401

Epoch: 5| Step: 2
Training loss: 2.6965150833129883
Validation loss: 2.03529192507267

Epoch: 5| Step: 3
Training loss: 2.0729856491088867
Validation loss: 2.034618909160296

Epoch: 5| Step: 4
Training loss: 2.395481824874878
Validation loss: 2.030941257874171

Epoch: 5| Step: 5
Training loss: 1.9592063426971436
Validation loss: 2.0282469938198724

Epoch: 5| Step: 6
Training loss: 2.060389757156372
Validation loss: 2.023292322953542

Epoch: 5| Step: 7
Training loss: 2.391104221343994
Validation loss: 2.0138714214166007

Epoch: 5| Step: 8
Training loss: 2.3217782974243164
Validation loss: 2.0169057796398797

Epoch: 5| Step: 9
Training loss: 2.0843117237091064
Validation loss: 2.011262501279513

Epoch: 5| Step: 10
Training loss: 2.0472373962402344
Validation loss: 2.021759087840716

Epoch: 5| Step: 11
Training loss: 2.7402443885803223
Validation loss: 2.0138007452090583

Epoch: 85| Step: 0
Training loss: 2.1349730491638184
Validation loss: 2.011746739347776

Epoch: 5| Step: 1
Training loss: 2.5331127643585205
Validation loss: 2.0139096677303314

Epoch: 5| Step: 2
Training loss: 1.9730167388916016
Validation loss: 2.014212111632029

Epoch: 5| Step: 3
Training loss: 2.0554134845733643
Validation loss: 2.0094180405139923

Epoch: 5| Step: 4
Training loss: 1.9428889751434326
Validation loss: 2.0100792348384857

Epoch: 5| Step: 5
Training loss: 2.3337769508361816
Validation loss: 2.0110450387001038

Epoch: 5| Step: 6
Training loss: 2.169955015182495
Validation loss: 2.015255252520243

Epoch: 5| Step: 7
Training loss: 2.505143404006958
Validation loss: 2.0089751879374185

Epoch: 5| Step: 8
Training loss: 2.4587700366973877
Validation loss: 2.007042239109675

Epoch: 5| Step: 9
Training loss: 2.0890815258026123
Validation loss: 2.018879155317942

Epoch: 5| Step: 10
Training loss: 2.319209575653076
Validation loss: 2.017029603322347

Epoch: 5| Step: 11
Training loss: 0.47998714447021484
Validation loss: 2.0151762664318085

Epoch: 86| Step: 0
Training loss: 2.1346139907836914
Validation loss: 2.010510101914406

Epoch: 5| Step: 1
Training loss: 2.0272204875946045
Validation loss: 2.006383846203486

Epoch: 5| Step: 2
Training loss: 2.233616352081299
Validation loss: 2.016948784391085

Epoch: 5| Step: 3
Training loss: 1.9807409048080444
Validation loss: 2.005305990576744

Epoch: 5| Step: 4
Training loss: 2.095719337463379
Validation loss: 2.012727369864782

Epoch: 5| Step: 5
Training loss: 2.5515084266662598
Validation loss: 2.0114164501428604

Epoch: 5| Step: 6
Training loss: 2.0766849517822266
Validation loss: 2.0162985026836395

Epoch: 5| Step: 7
Training loss: 2.243812084197998
Validation loss: 2.0198199301958084

Epoch: 5| Step: 8
Training loss: 2.299539089202881
Validation loss: 2.011258065700531

Epoch: 5| Step: 9
Training loss: 2.181938886642456
Validation loss: 2.018055255214373

Epoch: 5| Step: 10
Training loss: 2.3471295833587646
Validation loss: 2.010230372349421

Epoch: 5| Step: 11
Training loss: 1.9928524494171143
Validation loss: 2.0195865680774054

Epoch: 87| Step: 0
Training loss: 2.205183267593384
Validation loss: 2.0158423582712808

Epoch: 5| Step: 1
Training loss: 2.5259127616882324
Validation loss: 2.0178366353114447

Epoch: 5| Step: 2
Training loss: 1.776055932044983
Validation loss: 2.0144903312126794

Epoch: 5| Step: 3
Training loss: 2.2824196815490723
Validation loss: 2.019771695137024

Epoch: 5| Step: 4
Training loss: 1.7542225122451782
Validation loss: 2.0239896178245544

Epoch: 5| Step: 5
Training loss: 2.2367029190063477
Validation loss: 2.0296621173620224

Epoch: 5| Step: 6
Training loss: 1.586279273033142
Validation loss: 2.0477117002010345

Epoch: 5| Step: 7
Training loss: 2.248183012008667
Validation loss: 2.042069678505262

Epoch: 5| Step: 8
Training loss: 2.228511333465576
Validation loss: 2.0576863884925842

Epoch: 5| Step: 9
Training loss: 2.535651206970215
Validation loss: 2.0515433798233667

Epoch: 5| Step: 10
Training loss: 2.5993897914886475
Validation loss: 2.05854802330335

Epoch: 5| Step: 11
Training loss: 3.2520699501037598
Validation loss: 2.0347349544366202

Epoch: 88| Step: 0
Training loss: 1.765291452407837
Validation loss: 2.009760727485021

Epoch: 5| Step: 1
Training loss: 1.9486459493637085
Validation loss: 2.0296140760183334

Epoch: 5| Step: 2
Training loss: 2.5169055461883545
Validation loss: 2.0541097819805145

Epoch: 5| Step: 3
Training loss: 1.6081641912460327
Validation loss: 2.0838644007841745

Epoch: 5| Step: 4
Training loss: 2.442610740661621
Validation loss: 2.1180740346511207

Epoch: 5| Step: 5
Training loss: 2.349365234375
Validation loss: 2.1368782768646875

Epoch: 5| Step: 6
Training loss: 2.4701926708221436
Validation loss: 2.152665068705877

Epoch: 5| Step: 7
Training loss: 2.8907370567321777
Validation loss: 2.1491381029287973

Epoch: 5| Step: 8
Training loss: 2.6639158725738525
Validation loss: 2.148325299223264

Epoch: 5| Step: 9
Training loss: 2.4647183418273926
Validation loss: 2.129705016811689

Epoch: 5| Step: 10
Training loss: 1.9652068614959717
Validation loss: 2.1081706980864205

Epoch: 5| Step: 11
Training loss: 2.0161471366882324
Validation loss: 2.095297704140345

Epoch: 89| Step: 0
Training loss: 2.526932954788208
Validation loss: 2.0820426841576896

Epoch: 5| Step: 1
Training loss: 2.1256890296936035
Validation loss: 2.0710610697666803

Epoch: 5| Step: 2
Training loss: 1.988370656967163
Validation loss: 2.0559256772200265

Epoch: 5| Step: 3
Training loss: 1.6189686059951782
Validation loss: 2.052094375093778

Epoch: 5| Step: 4
Training loss: 2.1714489459991455
Validation loss: 2.046060328682264

Epoch: 5| Step: 5
Training loss: 2.3313679695129395
Validation loss: 2.041460245847702

Epoch: 5| Step: 6
Training loss: 2.2481789588928223
Validation loss: 2.0379212448994317

Epoch: 5| Step: 7
Training loss: 2.5307536125183105
Validation loss: 2.034506142139435

Epoch: 5| Step: 8
Training loss: 2.068319797515869
Validation loss: 2.0325956443945565

Epoch: 5| Step: 9
Training loss: 2.896289348602295
Validation loss: 2.0357007582982383

Epoch: 5| Step: 10
Training loss: 2.2622148990631104
Validation loss: 2.031542102495829

Epoch: 5| Step: 11
Training loss: 1.703603982925415
Validation loss: 2.0237557788689933

Epoch: 90| Step: 0
Training loss: 2.481253147125244
Validation loss: 2.014301612973213

Epoch: 5| Step: 1
Training loss: 2.3531126976013184
Validation loss: 2.021372283498446

Epoch: 5| Step: 2
Training loss: 2.4138975143432617
Validation loss: 2.024455949664116

Epoch: 5| Step: 3
Training loss: 2.1563706398010254
Validation loss: 2.043361912171046

Epoch: 5| Step: 4
Training loss: 2.2999699115753174
Validation loss: 2.0543427069981894

Epoch: 5| Step: 5
Training loss: 2.5734732151031494
Validation loss: 2.0891808519760766

Epoch: 5| Step: 6
Training loss: 1.8307597637176514
Validation loss: 2.104170029362043

Epoch: 5| Step: 7
Training loss: 2.312140941619873
Validation loss: 2.072433332602183

Epoch: 5| Step: 8
Training loss: 2.4055275917053223
Validation loss: 2.071003794670105

Epoch: 5| Step: 9
Training loss: 2.072636365890503
Validation loss: 2.028500556945801

Epoch: 5| Step: 10
Training loss: 1.6121246814727783
Validation loss: 2.0209872474273047

Epoch: 5| Step: 11
Training loss: 2.941272735595703
Validation loss: 2.0148163934548697

Epoch: 91| Step: 0
Training loss: 2.9036242961883545
Validation loss: 2.0127676278352737

Epoch: 5| Step: 1
Training loss: 1.389341950416565
Validation loss: 2.024605467915535

Epoch: 5| Step: 2
Training loss: 2.395613431930542
Validation loss: 2.0269489884376526

Epoch: 5| Step: 3
Training loss: 1.873064637184143
Validation loss: 2.0317824383576712

Epoch: 5| Step: 4
Training loss: 2.206862211227417
Validation loss: 2.033151542147001

Epoch: 5| Step: 5
Training loss: 1.8019087314605713
Validation loss: 2.0337045838435492

Epoch: 5| Step: 6
Training loss: 2.082631826400757
Validation loss: 2.0324019342660904

Epoch: 5| Step: 7
Training loss: 2.4751365184783936
Validation loss: 2.0337277998526893

Epoch: 5| Step: 8
Training loss: 2.2094016075134277
Validation loss: 2.0345508257548013

Epoch: 5| Step: 9
Training loss: 2.8907971382141113
Validation loss: 2.030338873465856

Epoch: 5| Step: 10
Training loss: 2.1142377853393555
Validation loss: 2.0327775379021964

Epoch: 5| Step: 11
Training loss: 2.4023170471191406
Validation loss: 2.0288291573524475

Epoch: 92| Step: 0
Training loss: 2.67928147315979
Validation loss: 2.027219141523043

Epoch: 5| Step: 1
Training loss: 2.401240587234497
Validation loss: 2.0288377702236176

Epoch: 5| Step: 2
Training loss: 2.1217575073242188
Validation loss: 2.0245855301618576

Epoch: 5| Step: 3
Training loss: 2.2657272815704346
Validation loss: 2.028324360648791

Epoch: 5| Step: 4
Training loss: 1.848686933517456
Validation loss: 2.023189435402552

Epoch: 5| Step: 5
Training loss: 1.8871854543685913
Validation loss: 2.0193998217582703

Epoch: 5| Step: 6
Training loss: 1.8866872787475586
Validation loss: 2.0090049107869468

Epoch: 5| Step: 7
Training loss: 2.245729684829712
Validation loss: 2.0090320656696954

Epoch: 5| Step: 8
Training loss: 2.2014479637145996
Validation loss: 2.0051359037558236

Epoch: 5| Step: 9
Training loss: 2.6896920204162598
Validation loss: 2.014350473880768

Epoch: 5| Step: 10
Training loss: 1.8106762170791626
Validation loss: 2.0045103083054223

Epoch: 5| Step: 11
Training loss: 3.3611316680908203
Validation loss: 2.0123833417892456

Epoch: 93| Step: 0
Training loss: 2.734910249710083
Validation loss: 2.01968344549338

Epoch: 5| Step: 1
Training loss: 1.8683481216430664
Validation loss: 2.0117794622977576

Epoch: 5| Step: 2
Training loss: 2.50437593460083
Validation loss: 2.0143573631842933

Epoch: 5| Step: 3
Training loss: 2.174119710922241
Validation loss: 2.0242007275422416

Epoch: 5| Step: 4
Training loss: 2.1828389167785645
Validation loss: 2.0114604433377585

Epoch: 5| Step: 5
Training loss: 2.337831735610962
Validation loss: 2.0108733723560968

Epoch: 5| Step: 6
Training loss: 2.2120330333709717
Validation loss: 2.007713650663694

Epoch: 5| Step: 7
Training loss: 1.762873888015747
Validation loss: 2.018545930584272

Epoch: 5| Step: 8
Training loss: 1.9999847412109375
Validation loss: 2.0088306019703546

Epoch: 5| Step: 9
Training loss: 1.969504952430725
Validation loss: 2.00748610496521

Epoch: 5| Step: 10
Training loss: 2.33744215965271
Validation loss: 2.0075407177209854

Epoch: 5| Step: 11
Training loss: 2.0068838596343994
Validation loss: 2.0046871105829873

Epoch: 94| Step: 0
Training loss: 2.577077627182007
Validation loss: 2.0017136385043464

Epoch: 5| Step: 1
Training loss: 2.264693260192871
Validation loss: 2.0037028888861337

Epoch: 5| Step: 2
Training loss: 1.828282356262207
Validation loss: 2.0070739487806954

Epoch: 5| Step: 3
Training loss: 2.0482585430145264
Validation loss: 2.008281553785006

Epoch: 5| Step: 4
Training loss: 2.2493252754211426
Validation loss: 2.013850659132004

Epoch: 5| Step: 5
Training loss: 2.0447051525115967
Validation loss: 2.012913386027018

Epoch: 5| Step: 6
Training loss: 2.1443800926208496
Validation loss: 2.0123912493387857

Epoch: 5| Step: 7
Training loss: 2.277233362197876
Validation loss: 2.0133362660805383

Epoch: 5| Step: 8
Training loss: 2.611912488937378
Validation loss: 2.0143070419629416

Epoch: 5| Step: 9
Training loss: 2.125863552093506
Validation loss: 2.0106728971004486

Epoch: 5| Step: 10
Training loss: 1.8129169940948486
Validation loss: 2.0074366281429925

Epoch: 5| Step: 11
Training loss: 2.000120162963867
Validation loss: 2.0074209620555243

Epoch: 95| Step: 0
Training loss: 2.4057188034057617
Validation loss: 2.0094664295514426

Epoch: 5| Step: 1
Training loss: 2.125378131866455
Validation loss: 2.0190316836039224

Epoch: 5| Step: 2
Training loss: 1.949028730392456
Validation loss: 2.0166407426198325

Epoch: 5| Step: 3
Training loss: 2.344200611114502
Validation loss: 2.0216771761576333

Epoch: 5| Step: 4
Training loss: 2.409935235977173
Validation loss: 2.0264333933591843

Epoch: 5| Step: 5
Training loss: 1.8895041942596436
Validation loss: 2.0130333403746286

Epoch: 5| Step: 6
Training loss: 1.9181652069091797
Validation loss: 2.0068360368410745

Epoch: 5| Step: 7
Training loss: 2.078562021255493
Validation loss: 2.0088578512271247

Epoch: 5| Step: 8
Training loss: 2.40163254737854
Validation loss: 2.008392716447512

Epoch: 5| Step: 9
Training loss: 2.188825845718384
Validation loss: 2.005132426818212

Epoch: 5| Step: 10
Training loss: 2.3181731700897217
Validation loss: 2.0111902952194214

Epoch: 5| Step: 11
Training loss: 1.5633490085601807
Validation loss: 2.0041121592124305

Epoch: 96| Step: 0
Training loss: 1.9541409015655518
Validation loss: 2.006986310084661

Epoch: 5| Step: 1
Training loss: 1.6148170232772827
Validation loss: 2.005531926949819

Epoch: 5| Step: 2
Training loss: 1.816676139831543
Validation loss: 2.0035173495610556

Epoch: 5| Step: 3
Training loss: 1.8658031225204468
Validation loss: 2.002415736516317

Epoch: 5| Step: 4
Training loss: 2.87479567527771
Validation loss: 1.9996732970078785

Epoch: 5| Step: 5
Training loss: 2.3803658485412598
Validation loss: 2.0017916013797126

Epoch: 5| Step: 6
Training loss: 1.9566634893417358
Validation loss: 2.0058120091756186

Epoch: 5| Step: 7
Training loss: 1.8734614849090576
Validation loss: 2.0056875944137573

Epoch: 5| Step: 8
Training loss: 2.4556477069854736
Validation loss: 2.0029627829790115

Epoch: 5| Step: 9
Training loss: 2.5937070846557617
Validation loss: 2.00194650888443

Epoch: 5| Step: 10
Training loss: 2.467608690261841
Validation loss: 2.006380468606949

Epoch: 5| Step: 11
Training loss: 1.8277904987335205
Validation loss: 2.006718640526136

Epoch: 97| Step: 0
Training loss: 1.9567458629608154
Validation loss: 2.004745031396548

Epoch: 5| Step: 1
Training loss: 1.983214020729065
Validation loss: 2.0091198732455573

Epoch: 5| Step: 2
Training loss: 2.122128963470459
Validation loss: 2.007078061501185

Epoch: 5| Step: 3
Training loss: 2.1309523582458496
Validation loss: 2.0054403245449066

Epoch: 5| Step: 4
Training loss: 2.1162571907043457
Validation loss: 2.0140224546194077

Epoch: 5| Step: 5
Training loss: 1.7345521450042725
Validation loss: 2.0085165898005166

Epoch: 5| Step: 6
Training loss: 2.907802104949951
Validation loss: 2.016402135292689

Epoch: 5| Step: 7
Training loss: 2.4760143756866455
Validation loss: 2.0203857322533927

Epoch: 5| Step: 8
Training loss: 2.3471298217773438
Validation loss: 2.018124500910441

Epoch: 5| Step: 9
Training loss: 2.109619617462158
Validation loss: 2.0170827557643256

Epoch: 5| Step: 10
Training loss: 2.0148167610168457
Validation loss: 2.0087178548177085

Epoch: 5| Step: 11
Training loss: 2.360821008682251
Validation loss: 2.0121822456518808

Epoch: 98| Step: 0
Training loss: 2.5043821334838867
Validation loss: 2.010993907848994

Epoch: 5| Step: 1
Training loss: 2.3256163597106934
Validation loss: 2.017519180973371

Epoch: 5| Step: 2
Training loss: 2.344007730484009
Validation loss: 2.008906697233518

Epoch: 5| Step: 3
Training loss: 1.977445363998413
Validation loss: 2.0205635726451874

Epoch: 5| Step: 4
Training loss: 2.086638927459717
Validation loss: 2.0179840326309204

Epoch: 5| Step: 5
Training loss: 1.8802608251571655
Validation loss: 2.016456112265587

Epoch: 5| Step: 6
Training loss: 2.0688557624816895
Validation loss: 2.0092464238405228

Epoch: 5| Step: 7
Training loss: 2.313894510269165
Validation loss: 2.0206486930449805

Epoch: 5| Step: 8
Training loss: 1.9534515142440796
Validation loss: 2.0069832454125085

Epoch: 5| Step: 9
Training loss: 1.6234865188598633
Validation loss: 2.0090905725955963

Epoch: 5| Step: 10
Training loss: 2.576956272125244
Validation loss: 2.0062536746263504

Epoch: 5| Step: 11
Training loss: 2.5516135692596436
Validation loss: 2.0052465349435806

Epoch: 99| Step: 0
Training loss: 2.0892720222473145
Validation loss: 1.998531773686409

Epoch: 5| Step: 1
Training loss: 2.197518825531006
Validation loss: 1.9968891541163127

Epoch: 5| Step: 2
Training loss: 1.9224399328231812
Validation loss: 1.9964596231778462

Epoch: 5| Step: 3
Training loss: 2.131248712539673
Validation loss: 1.9990042795737584

Epoch: 5| Step: 4
Training loss: 2.223602771759033
Validation loss: 1.9903713862101238

Epoch: 5| Step: 5
Training loss: 1.977320671081543
Validation loss: 1.9895334492127101

Epoch: 5| Step: 6
Training loss: 2.4317402839660645
Validation loss: 1.9895585228999455

Epoch: 5| Step: 7
Training loss: 2.5079922676086426
Validation loss: 2.001283749938011

Epoch: 5| Step: 8
Training loss: 2.018160581588745
Validation loss: 1.9957102338473003

Epoch: 5| Step: 9
Training loss: 2.5696005821228027
Validation loss: 1.999921053647995

Epoch: 5| Step: 10
Training loss: 1.8263461589813232
Validation loss: 2.002204259236654

Epoch: 5| Step: 11
Training loss: 1.091428518295288
Validation loss: 2.008265266815821

Epoch: 100| Step: 0
Training loss: 1.9840017557144165
Validation loss: 2.0169040064016976

Epoch: 5| Step: 1
Training loss: 2.1329219341278076
Validation loss: 2.016262342532476

Epoch: 5| Step: 2
Training loss: 2.2249932289123535
Validation loss: 2.0348679969708123

Epoch: 5| Step: 3
Training loss: 2.686812162399292
Validation loss: 2.0365207493305206

Epoch: 5| Step: 4
Training loss: 2.0093791484832764
Validation loss: 2.036217212677002

Epoch: 5| Step: 5
Training loss: 2.477721691131592
Validation loss: 2.0283368130524955

Epoch: 5| Step: 6
Training loss: 2.1031508445739746
Validation loss: 2.017173076669375

Epoch: 5| Step: 7
Training loss: 1.4524486064910889
Validation loss: 2.000439132253329

Epoch: 5| Step: 8
Training loss: 2.4350197315216064
Validation loss: 1.9956950346628826

Epoch: 5| Step: 9
Training loss: 2.1427159309387207
Validation loss: 2.0047531376282373

Epoch: 5| Step: 10
Training loss: 2.506211757659912
Validation loss: 2.0025572578112283

Epoch: 5| Step: 11
Training loss: 1.1128978729248047
Validation loss: 1.997140218814214

Epoch: 101| Step: 0
Training loss: 2.1313412189483643
Validation loss: 2.0037905474503837

Epoch: 5| Step: 1
Training loss: 2.0827903747558594
Validation loss: 2.0016209383805594

Epoch: 5| Step: 2
Training loss: 2.822404384613037
Validation loss: 2.0025538504123688

Epoch: 5| Step: 3
Training loss: 2.0421364307403564
Validation loss: 2.0058826009432473

Epoch: 5| Step: 4
Training loss: 1.8033857345581055
Validation loss: 2.009362821777662

Epoch: 5| Step: 5
Training loss: 2.1166951656341553
Validation loss: 2.006417602300644

Epoch: 5| Step: 6
Training loss: 2.0499281883239746
Validation loss: 2.010389526685079

Epoch: 5| Step: 7
Training loss: 2.3449740409851074
Validation loss: 2.0121441185474396

Epoch: 5| Step: 8
Training loss: 1.8815685510635376
Validation loss: 2.006358007589976

Epoch: 5| Step: 9
Training loss: 2.268202304840088
Validation loss: 2.009775867064794

Epoch: 5| Step: 10
Training loss: 2.218777894973755
Validation loss: 2.0169277290503183

Epoch: 5| Step: 11
Training loss: 1.9995735883712769
Validation loss: 2.0219119985898337

Epoch: 102| Step: 0
Training loss: 2.6683077812194824
Validation loss: 2.0324529111385345

Epoch: 5| Step: 1
Training loss: 2.4163241386413574
Validation loss: 2.034024342894554

Epoch: 5| Step: 2
Training loss: 2.0417582988739014
Validation loss: 2.047060896952947

Epoch: 5| Step: 3
Training loss: 2.1361007690429688
Validation loss: 2.0598599513371787

Epoch: 5| Step: 4
Training loss: 2.476155996322632
Validation loss: 2.081129267811775

Epoch: 5| Step: 5
Training loss: 2.0767922401428223
Validation loss: 2.0567237039407096

Epoch: 5| Step: 6
Training loss: 2.181964635848999
Validation loss: 2.053112268447876

Epoch: 5| Step: 7
Training loss: 1.4605445861816406
Validation loss: 2.047802319129308

Epoch: 5| Step: 8
Training loss: 2.2891414165496826
Validation loss: 2.0319247941176095

Epoch: 5| Step: 9
Training loss: 2.088923931121826
Validation loss: 2.0298244108756385

Epoch: 5| Step: 10
Training loss: 2.1287059783935547
Validation loss: 2.008699119091034

Epoch: 5| Step: 11
Training loss: 2.365480899810791
Validation loss: 2.010668178399404

Epoch: 103| Step: 0
Training loss: 2.0288949012756348
Validation loss: 2.005905717611313

Epoch: 5| Step: 1
Training loss: 2.0662713050842285
Validation loss: 2.0152010023593903

Epoch: 5| Step: 2
Training loss: 2.0750415325164795
Validation loss: 2.015705739458402

Epoch: 5| Step: 3
Training loss: 1.7246125936508179
Validation loss: 2.019233042995135

Epoch: 5| Step: 4
Training loss: 2.5846543312072754
Validation loss: 2.0222724825143814

Epoch: 5| Step: 5
Training loss: 1.5355585813522339
Validation loss: 2.024857982993126

Epoch: 5| Step: 6
Training loss: 2.3791069984436035
Validation loss: 2.01688814163208

Epoch: 5| Step: 7
Training loss: 2.498924732208252
Validation loss: 2.0265328884124756

Epoch: 5| Step: 8
Training loss: 2.352620840072632
Validation loss: 2.0215538839499154

Epoch: 5| Step: 9
Training loss: 2.547712564468384
Validation loss: 2.021762231985728

Epoch: 5| Step: 10
Training loss: 2.248253583908081
Validation loss: 2.0210959166288376

Epoch: 5| Step: 11
Training loss: 2.749732255935669
Validation loss: 2.0236491511265435

Epoch: 104| Step: 0
Training loss: 1.9317833185195923
Validation loss: 2.015472228328387

Epoch: 5| Step: 1
Training loss: 2.287781000137329
Validation loss: 2.0125835984945297

Epoch: 5| Step: 2
Training loss: 1.9213975667953491
Validation loss: 2.0104968696832657

Epoch: 5| Step: 3
Training loss: 2.079360246658325
Validation loss: 2.011782387892405

Epoch: 5| Step: 4
Training loss: 2.0489916801452637
Validation loss: 2.006914565960566

Epoch: 5| Step: 5
Training loss: 2.466066360473633
Validation loss: 2.0014529625574746

Epoch: 5| Step: 6
Training loss: 2.223100185394287
Validation loss: 2.002840037147204

Epoch: 5| Step: 7
Training loss: 2.311570405960083
Validation loss: 2.0067444940408072

Epoch: 5| Step: 8
Training loss: 2.1522960662841797
Validation loss: 2.0152265230814614

Epoch: 5| Step: 9
Training loss: 2.109926700592041
Validation loss: 2.0232862532138824

Epoch: 5| Step: 10
Training loss: 2.440427303314209
Validation loss: 2.023615926504135

Epoch: 5| Step: 11
Training loss: 0.9762376546859741
Validation loss: 2.0276995251576104

Epoch: 105| Step: 0
Training loss: 2.612668752670288
Validation loss: 2.029509906967481

Epoch: 5| Step: 1
Training loss: 2.0395560264587402
Validation loss: 2.0300345569849014

Epoch: 5| Step: 2
Training loss: 2.011274814605713
Validation loss: 2.0399180253346763

Epoch: 5| Step: 3
Training loss: 2.534135341644287
Validation loss: 2.042372857530912

Epoch: 5| Step: 4
Training loss: 2.0107903480529785
Validation loss: 2.0446043014526367

Epoch: 5| Step: 5
Training loss: 1.9496711492538452
Validation loss: 2.043230245510737

Epoch: 5| Step: 6
Training loss: 2.078258514404297
Validation loss: 2.032593463857969

Epoch: 5| Step: 7
Training loss: 1.7933647632598877
Validation loss: 2.0310784727334976

Epoch: 5| Step: 8
Training loss: 1.9812462329864502
Validation loss: 2.0335664252440133

Epoch: 5| Step: 9
Training loss: 2.4190897941589355
Validation loss: 2.0175648977359137

Epoch: 5| Step: 10
Training loss: 2.191784143447876
Validation loss: 2.015367408593496

Epoch: 5| Step: 11
Training loss: 2.627800703048706
Validation loss: 2.0083528459072113

Epoch: 106| Step: 0
Training loss: 1.9286928176879883
Validation loss: 2.0111535489559174

Epoch: 5| Step: 1
Training loss: 2.137937068939209
Validation loss: 2.002750794092814

Epoch: 5| Step: 2
Training loss: 2.230642318725586
Validation loss: 2.0076134900252023

Epoch: 5| Step: 3
Training loss: 2.302938938140869
Validation loss: 2.00276680290699

Epoch: 5| Step: 4
Training loss: 1.7464256286621094
Validation loss: 2.005621944864591

Epoch: 5| Step: 5
Training loss: 2.740772247314453
Validation loss: 2.0055726766586304

Epoch: 5| Step: 6
Training loss: 2.487060070037842
Validation loss: 2.001774246493975

Epoch: 5| Step: 7
Training loss: 2.373385190963745
Validation loss: 2.011600981156031

Epoch: 5| Step: 8
Training loss: 1.8012129068374634
Validation loss: 2.008537858724594

Epoch: 5| Step: 9
Training loss: 2.1040546894073486
Validation loss: 2.010242318113645

Epoch: 5| Step: 10
Training loss: 1.8511860370635986
Validation loss: 2.003168448805809

Epoch: 5| Step: 11
Training loss: 2.5332882404327393
Validation loss: 2.00079553325971

Epoch: 107| Step: 0
Training loss: 2.250770092010498
Validation loss: 2.0041113446156182

Epoch: 5| Step: 1
Training loss: 2.015263080596924
Validation loss: 2.0086845457553864

Epoch: 5| Step: 2
Training loss: 2.0585415363311768
Validation loss: 2.0147412767012916

Epoch: 5| Step: 3
Training loss: 2.7578861713409424
Validation loss: 2.011318395535151

Epoch: 5| Step: 4
Training loss: 2.7669835090637207
Validation loss: 2.0181650072336197

Epoch: 5| Step: 5
Training loss: 1.9844166040420532
Validation loss: 2.0249239752689996

Epoch: 5| Step: 6
Training loss: 1.5621004104614258
Validation loss: 2.017953152457873

Epoch: 5| Step: 7
Training loss: 2.255160331726074
Validation loss: 2.0272254943847656

Epoch: 5| Step: 8
Training loss: 2.2605059146881104
Validation loss: 2.0294979910055795

Epoch: 5| Step: 9
Training loss: 2.2432303428649902
Validation loss: 2.0152716686328254

Epoch: 5| Step: 10
Training loss: 1.3938167095184326
Validation loss: 2.023095135887464

Epoch: 5| Step: 11
Training loss: 2.159518241882324
Validation loss: 2.0123057762781777

Epoch: 108| Step: 0
Training loss: 2.360114812850952
Validation loss: 2.011722147464752

Epoch: 5| Step: 1
Training loss: 2.2852325439453125
Validation loss: 2.0181029736995697

Epoch: 5| Step: 2
Training loss: 2.565056562423706
Validation loss: 2.0083045214414597

Epoch: 5| Step: 3
Training loss: 2.4813356399536133
Validation loss: 2.010238140821457

Epoch: 5| Step: 4
Training loss: 2.2761919498443604
Validation loss: 2.0164064913988113

Epoch: 5| Step: 5
Training loss: 2.1998467445373535
Validation loss: 2.0055154909690223

Epoch: 5| Step: 6
Training loss: 1.2396408319473267
Validation loss: 2.0041337062915168

Epoch: 5| Step: 7
Training loss: 1.674891471862793
Validation loss: 1.99681560198466

Epoch: 5| Step: 8
Training loss: 2.222961902618408
Validation loss: 2.0025505224863687

Epoch: 5| Step: 9
Training loss: 2.4762892723083496
Validation loss: 2.002372538050016

Epoch: 5| Step: 10
Training loss: 1.8641643524169922
Validation loss: 2.002530127763748

Epoch: 5| Step: 11
Training loss: 1.7970783710479736
Validation loss: 2.000835860768954

Epoch: 109| Step: 0
Training loss: 2.28641939163208
Validation loss: 1.9981930355230968

Epoch: 5| Step: 1
Training loss: 2.1243996620178223
Validation loss: 2.001490741968155

Epoch: 5| Step: 2
Training loss: 2.111654758453369
Validation loss: 2.004127562046051

Epoch: 5| Step: 3
Training loss: 2.1286447048187256
Validation loss: 2.011346767346064

Epoch: 5| Step: 4
Training loss: 2.4911577701568604
Validation loss: 2.0114674468835196

Epoch: 5| Step: 5
Training loss: 2.017526626586914
Validation loss: 2.0114027659098306

Epoch: 5| Step: 6
Training loss: 2.117048740386963
Validation loss: 2.022260159254074

Epoch: 5| Step: 7
Training loss: 1.8085472583770752
Validation loss: 2.0302366415659585

Epoch: 5| Step: 8
Training loss: 1.9949222803115845
Validation loss: 2.028033514817556

Epoch: 5| Step: 9
Training loss: 2.4619193077087402
Validation loss: 2.033659189939499

Epoch: 5| Step: 10
Training loss: 1.9285805225372314
Validation loss: 2.041755119959513

Epoch: 5| Step: 11
Training loss: 2.7967562675476074
Validation loss: 2.038014511267344

Epoch: 110| Step: 0
Training loss: 2.4100208282470703
Validation loss: 2.0242022772630057

Epoch: 5| Step: 1
Training loss: 2.1824300289154053
Validation loss: 2.0089224676291146

Epoch: 5| Step: 2
Training loss: 2.5292561054229736
Validation loss: 2.006581569711367

Epoch: 5| Step: 3
Training loss: 2.7257943153381348
Validation loss: 1.9997085183858871

Epoch: 5| Step: 4
Training loss: 2.1973695755004883
Validation loss: 1.9965839435656865

Epoch: 5| Step: 5
Training loss: 2.480637311935425
Validation loss: 2.005291839440664

Epoch: 5| Step: 6
Training loss: 1.9009592533111572
Validation loss: 2.0065316359202066

Epoch: 5| Step: 7
Training loss: 1.4811655282974243
Validation loss: 2.006938710808754

Epoch: 5| Step: 8
Training loss: 1.7957661151885986
Validation loss: 2.0057002902030945

Epoch: 5| Step: 9
Training loss: 2.096527099609375
Validation loss: 2.0005192259947457

Epoch: 5| Step: 10
Training loss: 1.9618648290634155
Validation loss: 1.993858923514684

Epoch: 5| Step: 11
Training loss: 1.607499361038208
Validation loss: 1.9968849023183186

Epoch: 111| Step: 0
Training loss: 2.4395017623901367
Validation loss: 1.997714435060819

Epoch: 5| Step: 1
Training loss: 2.0240659713745117
Validation loss: 2.008274386326472

Epoch: 5| Step: 2
Training loss: 1.980433702468872
Validation loss: 1.9969856590032578

Epoch: 5| Step: 3
Training loss: 1.9195533990859985
Validation loss: 2.0024417340755463

Epoch: 5| Step: 4
Training loss: 2.265695333480835
Validation loss: 2.009610950946808

Epoch: 5| Step: 5
Training loss: 2.385636806488037
Validation loss: 2.013684242963791

Epoch: 5| Step: 6
Training loss: 2.251589298248291
Validation loss: 2.028101831674576

Epoch: 5| Step: 7
Training loss: 1.8040605783462524
Validation loss: 2.0156832138697305

Epoch: 5| Step: 8
Training loss: 2.165670156478882
Validation loss: 2.020534028609594

Epoch: 5| Step: 9
Training loss: 2.092583417892456
Validation loss: 2.0330729484558105

Epoch: 5| Step: 10
Training loss: 2.1146225929260254
Validation loss: 2.044967989126841

Epoch: 5| Step: 11
Training loss: 2.6641955375671387
Validation loss: 2.034952456752459

Epoch: 112| Step: 0
Training loss: 2.5181167125701904
Validation loss: 2.0351347972949347

Epoch: 5| Step: 1
Training loss: 2.1942811012268066
Validation loss: 2.0260414530833564

Epoch: 5| Step: 2
Training loss: 1.927991509437561
Validation loss: 2.0337065060933432

Epoch: 5| Step: 3
Training loss: 2.123114824295044
Validation loss: 2.023269400000572

Epoch: 5| Step: 4
Training loss: 1.9373308420181274
Validation loss: 2.019740641117096

Epoch: 5| Step: 5
Training loss: 1.8078315258026123
Validation loss: 2.017459442218145

Epoch: 5| Step: 6
Training loss: 1.922597885131836
Validation loss: 2.0229108780622482

Epoch: 5| Step: 7
Training loss: 2.413938283920288
Validation loss: 2.0198649168014526

Epoch: 5| Step: 8
Training loss: 2.0910019874572754
Validation loss: 2.03092885017395

Epoch: 5| Step: 9
Training loss: 2.0898373126983643
Validation loss: 2.024413744608561

Epoch: 5| Step: 10
Training loss: 2.5622498989105225
Validation loss: 2.019174267848333

Epoch: 5| Step: 11
Training loss: 1.3774551153182983
Validation loss: 2.0269013146559396

Epoch: 113| Step: 0
Training loss: 2.040318012237549
Validation loss: 2.0302454978227615

Epoch: 5| Step: 1
Training loss: 1.9203007221221924
Validation loss: 2.0181471506754556

Epoch: 5| Step: 2
Training loss: 2.3795971870422363
Validation loss: 2.0196661800146103

Epoch: 5| Step: 3
Training loss: 2.432034969329834
Validation loss: 2.0229153583447137

Epoch: 5| Step: 4
Training loss: 2.1216752529144287
Validation loss: 2.025450810790062

Epoch: 5| Step: 5
Training loss: 1.895586609840393
Validation loss: 2.027053231994311

Epoch: 5| Step: 6
Training loss: 1.7993557453155518
Validation loss: 2.0278733720382056

Epoch: 5| Step: 7
Training loss: 2.102672815322876
Validation loss: 2.0352999617656073

Epoch: 5| Step: 8
Training loss: 1.7368793487548828
Validation loss: 2.0215987811485925

Epoch: 5| Step: 9
Training loss: 2.686741590499878
Validation loss: 2.018068095048269

Epoch: 5| Step: 10
Training loss: 2.0375983715057373
Validation loss: 2.0195744882027307

Epoch: 5| Step: 11
Training loss: 3.6203413009643555
Validation loss: 2.0240750710169473

Epoch: 114| Step: 0
Training loss: 2.2914700508117676
Validation loss: 2.0152305712302527

Epoch: 5| Step: 1
Training loss: 2.8721179962158203
Validation loss: 2.007536306977272

Epoch: 5| Step: 2
Training loss: 2.1463918685913086
Validation loss: 2.0068851013978324

Epoch: 5| Step: 3
Training loss: 1.871180772781372
Validation loss: 2.010785003503164

Epoch: 5| Step: 4
Training loss: 1.2208764553070068
Validation loss: 2.010363588730494

Epoch: 5| Step: 5
Training loss: 2.158052444458008
Validation loss: 2.0115737318992615

Epoch: 5| Step: 6
Training loss: 2.686558723449707
Validation loss: 2.001220559080442

Epoch: 5| Step: 7
Training loss: 2.0379748344421387
Validation loss: 2.0109228690465293

Epoch: 5| Step: 8
Training loss: 1.5491859912872314
Validation loss: 2.0029612630605698

Epoch: 5| Step: 9
Training loss: 2.159066915512085
Validation loss: 2.0052594741185508

Epoch: 5| Step: 10
Training loss: 2.5025837421417236
Validation loss: 2.006616805990537

Epoch: 5| Step: 11
Training loss: 2.2355470657348633
Validation loss: 2.011582146088282

Epoch: 115| Step: 0
Training loss: 2.0109143257141113
Validation loss: 2.0150600224733353

Epoch: 5| Step: 1
Training loss: 3.015777111053467
Validation loss: 2.016957630713781

Epoch: 5| Step: 2
Training loss: 1.9774386882781982
Validation loss: 2.0130384465058646

Epoch: 5| Step: 3
Training loss: 2.4842231273651123
Validation loss: 2.0167428304751716

Epoch: 5| Step: 4
Training loss: 1.7059173583984375
Validation loss: 2.0141531924406686

Epoch: 5| Step: 5
Training loss: 1.7709057331085205
Validation loss: 2.0169628461201987

Epoch: 5| Step: 6
Training loss: 1.6599953174591064
Validation loss: 2.02123931547006

Epoch: 5| Step: 7
Training loss: 2.235365629196167
Validation loss: 2.0186927169561386

Epoch: 5| Step: 8
Training loss: 2.4798519611358643
Validation loss: 2.017053097486496

Epoch: 5| Step: 9
Training loss: 1.9119682312011719
Validation loss: 2.0320437053839364

Epoch: 5| Step: 10
Training loss: 2.1446645259857178
Validation loss: 2.0282278706630072

Epoch: 5| Step: 11
Training loss: 1.9651449918746948
Validation loss: 2.0349209010601044

Epoch: 116| Step: 0
Training loss: 1.7792819738388062
Validation loss: 2.028187572956085

Epoch: 5| Step: 1
Training loss: 2.1025729179382324
Validation loss: 2.0323163121938705

Epoch: 5| Step: 2
Training loss: 2.2908473014831543
Validation loss: 2.0171509832143784

Epoch: 5| Step: 3
Training loss: 2.193894147872925
Validation loss: 2.025378038485845

Epoch: 5| Step: 4
Training loss: 1.9515907764434814
Validation loss: 2.0239685575167337

Epoch: 5| Step: 5
Training loss: 2.4324564933776855
Validation loss: 2.017566750446955

Epoch: 5| Step: 6
Training loss: 2.4955008029937744
Validation loss: 2.0241496215264

Epoch: 5| Step: 7
Training loss: 2.444887638092041
Validation loss: 2.018404091397921

Epoch: 5| Step: 8
Training loss: 1.976788878440857
Validation loss: 2.013977920015653

Epoch: 5| Step: 9
Training loss: 1.8768384456634521
Validation loss: 2.015328968564669

Epoch: 5| Step: 10
Training loss: 1.9377362728118896
Validation loss: 2.0167688926060996

Epoch: 5| Step: 11
Training loss: 1.6362816095352173
Validation loss: 2.0182980597019196

Epoch: 117| Step: 0
Training loss: 2.202252149581909
Validation loss: 2.0153758029143014

Epoch: 5| Step: 1
Training loss: 2.567277431488037
Validation loss: 2.0239204267660775

Epoch: 5| Step: 2
Training loss: 2.388895034790039
Validation loss: 2.015285144249598

Epoch: 5| Step: 3
Training loss: 2.1704940795898438
Validation loss: 2.0174401303132377

Epoch: 5| Step: 4
Training loss: 2.104602336883545
Validation loss: 2.020646944642067

Epoch: 5| Step: 5
Training loss: 1.9932429790496826
Validation loss: 2.018549238642057

Epoch: 5| Step: 6
Training loss: 1.7463691234588623
Validation loss: 2.006771316130956

Epoch: 5| Step: 7
Training loss: 1.934878945350647
Validation loss: 2.0082907378673553

Epoch: 5| Step: 8
Training loss: 2.203956127166748
Validation loss: 2.027016927798589

Epoch: 5| Step: 9
Training loss: 2.512378454208374
Validation loss: 2.014129345615705

Epoch: 5| Step: 10
Training loss: 1.7099968194961548
Validation loss: 2.017212986946106

Epoch: 5| Step: 11
Training loss: 1.1336085796356201
Validation loss: 2.0208444197972617

Epoch: 118| Step: 0
Training loss: 2.1115715503692627
Validation loss: 2.034884343544642

Epoch: 5| Step: 1
Training loss: 1.996631383895874
Validation loss: 2.023590922355652

Epoch: 5| Step: 2
Training loss: 2.027517795562744
Validation loss: 2.027605285247167

Epoch: 5| Step: 3
Training loss: 2.3127856254577637
Validation loss: 2.0250490605831146

Epoch: 5| Step: 4
Training loss: 1.9829031229019165
Validation loss: 2.015092839797338

Epoch: 5| Step: 5
Training loss: 2.262998104095459
Validation loss: 2.0208045095205307

Epoch: 5| Step: 6
Training loss: 2.575836658477783
Validation loss: 2.028981407483419

Epoch: 5| Step: 7
Training loss: 2.222968339920044
Validation loss: 2.020801211396853

Epoch: 5| Step: 8
Training loss: 1.9367496967315674
Validation loss: 2.021855945388476

Epoch: 5| Step: 9
Training loss: 1.8646844625473022
Validation loss: 2.0189821223417916

Epoch: 5| Step: 10
Training loss: 2.0765061378479004
Validation loss: 2.0250288943449655

Epoch: 5| Step: 11
Training loss: 1.3935905694961548
Validation loss: 2.0322401920954385

Epoch: 119| Step: 0
Training loss: 2.1418023109436035
Validation loss: 2.030859112739563

Epoch: 5| Step: 1
Training loss: 1.8048464059829712
Validation loss: 2.0241270313660302

Epoch: 5| Step: 2
Training loss: 2.069528579711914
Validation loss: 2.0276106695334115

Epoch: 5| Step: 3
Training loss: 1.3935006856918335
Validation loss: 2.012928600112597

Epoch: 5| Step: 4
Training loss: 2.400216579437256
Validation loss: 2.0136278172334037

Epoch: 5| Step: 5
Training loss: 1.8183521032333374
Validation loss: 2.012733444571495

Epoch: 5| Step: 6
Training loss: 2.5321133136749268
Validation loss: 2.0056041131416955

Epoch: 5| Step: 7
Training loss: 2.2177486419677734
Validation loss: 2.012448623776436

Epoch: 5| Step: 8
Training loss: 2.3834266662597656
Validation loss: 2.0065070539712906

Epoch: 5| Step: 9
Training loss: 2.271045207977295
Validation loss: 2.0189893742402396

Epoch: 5| Step: 10
Training loss: 2.1089224815368652
Validation loss: 2.015176663796107

Epoch: 5| Step: 11
Training loss: 3.024088144302368
Validation loss: 2.025187502304713

Epoch: 120| Step: 0
Training loss: 1.9229930639266968
Validation loss: 2.0300219605366387

Epoch: 5| Step: 1
Training loss: 2.668762683868408
Validation loss: 2.026281793912252

Epoch: 5| Step: 2
Training loss: 2.2527413368225098
Validation loss: 2.0572939763466516

Epoch: 5| Step: 3
Training loss: 2.541234254837036
Validation loss: 2.0648976067701974

Epoch: 5| Step: 4
Training loss: 1.7820110321044922
Validation loss: 2.0704691211382547

Epoch: 5| Step: 5
Training loss: 1.8812183141708374
Validation loss: 2.0528017729520798

Epoch: 5| Step: 6
Training loss: 2.0529396533966064
Validation loss: 2.038323392470678

Epoch: 5| Step: 7
Training loss: 2.1537511348724365
Validation loss: 2.0412646681070328

Epoch: 5| Step: 8
Training loss: 1.8040885925292969
Validation loss: 2.04474213719368

Epoch: 5| Step: 9
Training loss: 2.345689535140991
Validation loss: 2.0269102404514947

Epoch: 5| Step: 10
Training loss: 2.1290087699890137
Validation loss: 2.0261356433232627

Epoch: 5| Step: 11
Training loss: 2.899061918258667
Validation loss: 2.028148129582405

Epoch: 121| Step: 0
Training loss: 1.8761272430419922
Validation loss: 2.0226642241080603

Epoch: 5| Step: 1
Training loss: 2.083378553390503
Validation loss: 2.022700011730194

Epoch: 5| Step: 2
Training loss: 2.1638343334198
Validation loss: 2.010389799873034

Epoch: 5| Step: 3
Training loss: 2.235719919204712
Validation loss: 2.0159102181593576

Epoch: 5| Step: 4
Training loss: 2.2801880836486816
Validation loss: 2.009138827522596

Epoch: 5| Step: 5
Training loss: 2.0025129318237305
Validation loss: 2.0039320091406503

Epoch: 5| Step: 6
Training loss: 2.0771632194519043
Validation loss: 2.0047839134931564

Epoch: 5| Step: 7
Training loss: 2.4079113006591797
Validation loss: 2.008556758364042

Epoch: 5| Step: 8
Training loss: 2.1715641021728516
Validation loss: 2.0102944672107697

Epoch: 5| Step: 9
Training loss: 1.9499626159667969
Validation loss: 2.006345565120379

Epoch: 5| Step: 10
Training loss: 2.151870012283325
Validation loss: 2.015166774392128

Epoch: 5| Step: 11
Training loss: 2.5369386672973633
Validation loss: 2.0186970978975296

Epoch: 122| Step: 0
Training loss: 2.037888526916504
Validation loss: 2.02288747827212

Epoch: 5| Step: 1
Training loss: 2.1336073875427246
Validation loss: 2.031329095363617

Epoch: 5| Step: 2
Training loss: 1.5337750911712646
Validation loss: 2.033155972758929

Epoch: 5| Step: 3
Training loss: 2.21549654006958
Validation loss: 2.0318431854248047

Epoch: 5| Step: 4
Training loss: 1.7537529468536377
Validation loss: 2.042897199591001

Epoch: 5| Step: 5
Training loss: 1.7276294231414795
Validation loss: 2.0397786597410836

Epoch: 5| Step: 6
Training loss: 2.723405361175537
Validation loss: 2.0361788123846054

Epoch: 5| Step: 7
Training loss: 2.061847448348999
Validation loss: 2.042102878292402

Epoch: 5| Step: 8
Training loss: 2.030228614807129
Validation loss: 2.03567864994208

Epoch: 5| Step: 9
Training loss: 2.623335123062134
Validation loss: 2.045857757329941

Epoch: 5| Step: 10
Training loss: 2.432734727859497
Validation loss: 2.03104900320371

Epoch: 5| Step: 11
Training loss: 2.107301950454712
Validation loss: 2.035413066546122

Epoch: 123| Step: 0
Training loss: 2.0121450424194336
Validation loss: 2.0373953878879547

Epoch: 5| Step: 1
Training loss: 2.3704543113708496
Validation loss: 2.027584195137024

Epoch: 5| Step: 2
Training loss: 1.736262321472168
Validation loss: 2.0307182669639587

Epoch: 5| Step: 3
Training loss: 1.9558591842651367
Validation loss: 2.0248227268457413

Epoch: 5| Step: 4
Training loss: 2.4499728679656982
Validation loss: 2.030015985171

Epoch: 5| Step: 5
Training loss: 2.8178720474243164
Validation loss: 2.0226411869128547

Epoch: 5| Step: 6
Training loss: 2.0931665897369385
Validation loss: 2.016093681255976

Epoch: 5| Step: 7
Training loss: 2.4910197257995605
Validation loss: 2.01466511686643

Epoch: 5| Step: 8
Training loss: 2.213557481765747
Validation loss: 2.0088264594475427

Epoch: 5| Step: 9
Training loss: 1.5348161458969116
Validation loss: 2.007532015442848

Epoch: 5| Step: 10
Training loss: 1.8745721578598022
Validation loss: 2.0099549094835916

Epoch: 5| Step: 11
Training loss: 0.8218568563461304
Validation loss: 2.0079291462898254

Epoch: 124| Step: 0
Training loss: 2.2493999004364014
Validation loss: 2.0270607272783914

Epoch: 5| Step: 1
Training loss: 2.0374200344085693
Validation loss: 2.026266038417816

Epoch: 5| Step: 2
Training loss: 2.4475135803222656
Validation loss: 2.0310812493165336

Epoch: 5| Step: 3
Training loss: 1.9645748138427734
Validation loss: 2.045338044563929

Epoch: 5| Step: 4
Training loss: 2.312812089920044
Validation loss: 2.0542377134164176

Epoch: 5| Step: 5
Training loss: 1.7943851947784424
Validation loss: 2.0527454167604446

Epoch: 5| Step: 6
Training loss: 1.828989028930664
Validation loss: 2.025339831908544

Epoch: 5| Step: 7
Training loss: 1.715873122215271
Validation loss: 2.018590042988459

Epoch: 5| Step: 8
Training loss: 2.1936497688293457
Validation loss: 2.023383860786756

Epoch: 5| Step: 9
Training loss: 1.689781904220581
Validation loss: 2.014835317929586

Epoch: 5| Step: 10
Training loss: 2.7294204235076904
Validation loss: 1.999759207169215

Epoch: 5| Step: 11
Training loss: 3.5025553703308105
Validation loss: 2.007140894730886

Epoch: 125| Step: 0
Training loss: 2.207073926925659
Validation loss: 2.003883143266042

Epoch: 5| Step: 1
Training loss: 2.0069258213043213
Validation loss: 2.0059037705262504

Epoch: 5| Step: 2
Training loss: 1.7688524723052979
Validation loss: 2.0080977578957877

Epoch: 5| Step: 3
Training loss: 2.0399246215820312
Validation loss: 2.0210487047831216

Epoch: 5| Step: 4
Training loss: 2.3780696392059326
Validation loss: 2.020399123430252

Epoch: 5| Step: 5
Training loss: 2.1055099964141846
Validation loss: 2.0232875645160675

Epoch: 5| Step: 6
Training loss: 2.2293174266815186
Validation loss: 2.0304683595895767

Epoch: 5| Step: 7
Training loss: 1.9163320064544678
Validation loss: 2.0237525552511215

Epoch: 5| Step: 8
Training loss: 2.639146089553833
Validation loss: 2.0256668080886207

Epoch: 5| Step: 9
Training loss: 2.3422446250915527
Validation loss: 2.022749364376068

Epoch: 5| Step: 10
Training loss: 2.0674421787261963
Validation loss: 2.0130858222643533

Epoch: 5| Step: 11
Training loss: 1.9012953042984009
Validation loss: 2.0220840175946555

Epoch: 126| Step: 0
Training loss: 2.358588933944702
Validation loss: 2.0190394272406897

Epoch: 5| Step: 1
Training loss: 1.723658800125122
Validation loss: 2.01463475326697

Epoch: 5| Step: 2
Training loss: 2.0008327960968018
Validation loss: 2.0170387079318366

Epoch: 5| Step: 3
Training loss: 2.3442344665527344
Validation loss: 2.0127841383218765

Epoch: 5| Step: 4
Training loss: 1.6803102493286133
Validation loss: 2.01042041182518

Epoch: 5| Step: 5
Training loss: 2.2756614685058594
Validation loss: 2.0245215197404227

Epoch: 5| Step: 6
Training loss: 1.9691194295883179
Validation loss: 2.0220022151867547

Epoch: 5| Step: 7
Training loss: 2.5283148288726807
Validation loss: 2.0312657356262207

Epoch: 5| Step: 8
Training loss: 2.164442539215088
Validation loss: 2.024944916367531

Epoch: 5| Step: 9
Training loss: 2.037381887435913
Validation loss: 2.035662829875946

Epoch: 5| Step: 10
Training loss: 2.444749355316162
Validation loss: 2.034939924875895

Epoch: 5| Step: 11
Training loss: 1.4498116970062256
Validation loss: 2.02917151649793

Epoch: 127| Step: 0
Training loss: 1.892338514328003
Validation loss: 2.0293324689070382

Epoch: 5| Step: 1
Training loss: 2.1207082271575928
Validation loss: 2.0233713885148368

Epoch: 5| Step: 2
Training loss: 2.045628309249878
Validation loss: 2.040799766778946

Epoch: 5| Step: 3
Training loss: 2.0588269233703613
Validation loss: 2.0250411679347358

Epoch: 5| Step: 4
Training loss: 2.3132846355438232
Validation loss: 2.021398365497589

Epoch: 5| Step: 5
Training loss: 2.264603614807129
Validation loss: 2.0192626118659973

Epoch: 5| Step: 6
Training loss: 2.4022529125213623
Validation loss: 2.015465185046196

Epoch: 5| Step: 7
Training loss: 1.8400113582611084
Validation loss: 2.021254206697146

Epoch: 5| Step: 8
Training loss: 2.539108991622925
Validation loss: 2.0141149759292603

Epoch: 5| Step: 9
Training loss: 2.0959134101867676
Validation loss: 2.0158516069253287

Epoch: 5| Step: 10
Training loss: 1.6444965600967407
Validation loss: 2.0152510503927865

Epoch: 5| Step: 11
Training loss: 1.6661773920059204
Validation loss: 2.025005504488945

Epoch: 128| Step: 0
Training loss: 1.9545116424560547
Validation loss: 2.0149487107992172

Epoch: 5| Step: 1
Training loss: 1.6855432987213135
Validation loss: 2.01692862311999

Epoch: 5| Step: 2
Training loss: 1.9021384716033936
Validation loss: 2.0272321154673896

Epoch: 5| Step: 3
Training loss: 2.260713577270508
Validation loss: 2.0324308574199677

Epoch: 5| Step: 4
Training loss: 2.716747283935547
Validation loss: 2.040246973435084

Epoch: 5| Step: 5
Training loss: 1.634866714477539
Validation loss: 2.047238141298294

Epoch: 5| Step: 6
Training loss: 2.0913171768188477
Validation loss: 2.0331621170043945

Epoch: 5| Step: 7
Training loss: 2.123854875564575
Validation loss: 2.0277506758769355

Epoch: 5| Step: 8
Training loss: 2.354839324951172
Validation loss: 2.0399714012940726

Epoch: 5| Step: 9
Training loss: 2.6528255939483643
Validation loss: 2.052054906884829

Epoch: 5| Step: 10
Training loss: 1.7983343601226807
Validation loss: 2.0430265764395394

Epoch: 5| Step: 11
Training loss: 2.1675429344177246
Validation loss: 2.036761020620664

Epoch: 129| Step: 0
Training loss: 1.9270111322402954
Validation loss: 2.0385035475095115

Epoch: 5| Step: 1
Training loss: 2.270533323287964
Validation loss: 2.041407788793246

Epoch: 5| Step: 2
Training loss: 2.593264579772949
Validation loss: 2.0421701073646545

Epoch: 5| Step: 3
Training loss: 2.3065249919891357
Validation loss: 2.033054788907369

Epoch: 5| Step: 4
Training loss: 2.3068017959594727
Validation loss: 2.0283603072166443

Epoch: 5| Step: 5
Training loss: 1.8960659503936768
Validation loss: 2.0121066868305206

Epoch: 5| Step: 6
Training loss: 1.8459218740463257
Validation loss: 2.0215122401714325

Epoch: 5| Step: 7
Training loss: 1.7926931381225586
Validation loss: 2.008264402548472

Epoch: 5| Step: 8
Training loss: 2.042515993118286
Validation loss: 2.0149369885524115

Epoch: 5| Step: 9
Training loss: 2.5278189182281494
Validation loss: 2.022886276245117

Epoch: 5| Step: 10
Training loss: 1.7678329944610596
Validation loss: 2.0143973728020987

Epoch: 5| Step: 11
Training loss: 1.8723639249801636
Validation loss: 2.029864509900411

Epoch: 130| Step: 0
Training loss: 2.2122533321380615
Validation loss: 2.027890612681707

Epoch: 5| Step: 1
Training loss: 2.1837964057922363
Validation loss: 2.0171962728103003

Epoch: 5| Step: 2
Training loss: 2.1435964107513428
Validation loss: 2.0242926627397537

Epoch: 5| Step: 3
Training loss: 2.121244430541992
Validation loss: 2.025844211379687

Epoch: 5| Step: 4
Training loss: 2.0260822772979736
Validation loss: 2.018547162413597

Epoch: 5| Step: 5
Training loss: 2.523296356201172
Validation loss: 2.0301098426183066

Epoch: 5| Step: 6
Training loss: 2.1123037338256836
Validation loss: 2.029765486717224

Epoch: 5| Step: 7
Training loss: 2.3407626152038574
Validation loss: 2.0258188198010125

Epoch: 5| Step: 8
Training loss: 1.9912220239639282
Validation loss: 2.0219155301650367

Epoch: 5| Step: 9
Training loss: 1.317960500717163
Validation loss: 2.028304715951284

Epoch: 5| Step: 10
Training loss: 1.9184181690216064
Validation loss: 2.029017607371012

Epoch: 5| Step: 11
Training loss: 2.438786029815674
Validation loss: 2.018611470858256

Epoch: 131| Step: 0
Training loss: 2.0800371170043945
Validation loss: 2.015446424484253

Epoch: 5| Step: 1
Training loss: 2.1181893348693848
Validation loss: 2.02544766664505

Epoch: 5| Step: 2
Training loss: 2.1222622394561768
Validation loss: 2.022483299175898

Epoch: 5| Step: 3
Training loss: 2.195460796356201
Validation loss: 2.0206584433714547

Epoch: 5| Step: 4
Training loss: 1.9054811000823975
Validation loss: 2.021207610766093

Epoch: 5| Step: 5
Training loss: 2.166123867034912
Validation loss: 2.0255498637755713

Epoch: 5| Step: 6
Training loss: 2.208110809326172
Validation loss: 2.02075166006883

Epoch: 5| Step: 7
Training loss: 2.2484054565429688
Validation loss: 2.024764120578766

Epoch: 5| Step: 8
Training loss: 2.072570562362671
Validation loss: 2.0165709604819617

Epoch: 5| Step: 9
Training loss: 2.249502182006836
Validation loss: 2.0307904183864594

Epoch: 5| Step: 10
Training loss: 1.889113426208496
Validation loss: 2.0332102527221045

Epoch: 5| Step: 11
Training loss: 0.9022914171218872
Validation loss: 2.029955650369326

Epoch: 132| Step: 0
Training loss: 1.9288053512573242
Validation loss: 2.0435466120640435

Epoch: 5| Step: 1
Training loss: 2.311295986175537
Validation loss: 2.043883979320526

Epoch: 5| Step: 2
Training loss: 1.898813009262085
Validation loss: 2.0651184221108756

Epoch: 5| Step: 3
Training loss: 1.955519676208496
Validation loss: 2.0642649034659066

Epoch: 5| Step: 4
Training loss: 2.307429313659668
Validation loss: 2.045220618446668

Epoch: 5| Step: 5
Training loss: 2.492020845413208
Validation loss: 2.060728053251902

Epoch: 5| Step: 6
Training loss: 1.8074073791503906
Validation loss: 2.035279189546903

Epoch: 5| Step: 7
Training loss: 2.3805699348449707
Validation loss: 2.0343870321909585

Epoch: 5| Step: 8
Training loss: 1.9970672130584717
Validation loss: 2.019072179992994

Epoch: 5| Step: 9
Training loss: 1.6064732074737549
Validation loss: 2.0274184892574945

Epoch: 5| Step: 10
Training loss: 2.5167672634124756
Validation loss: 2.0179640303055444

Epoch: 5| Step: 11
Training loss: 2.835611343383789
Validation loss: 2.0255257735649743

Epoch: 133| Step: 0
Training loss: 1.65191650390625
Validation loss: 2.021062488357226

Epoch: 5| Step: 1
Training loss: 2.3227362632751465
Validation loss: 2.0117110709349313

Epoch: 5| Step: 2
Training loss: 2.2074921131134033
Validation loss: 2.010562246044477

Epoch: 5| Step: 3
Training loss: 2.4316635131835938
Validation loss: 2.0183377216259637

Epoch: 5| Step: 4
Training loss: 2.112407922744751
Validation loss: 2.0106738259394965

Epoch: 5| Step: 5
Training loss: 1.7947683334350586
Validation loss: 2.0076048771540322

Epoch: 5| Step: 6
Training loss: 2.121253490447998
Validation loss: 2.010852466026942

Epoch: 5| Step: 7
Training loss: 2.222938060760498
Validation loss: 2.018144205212593

Epoch: 5| Step: 8
Training loss: 2.308912754058838
Validation loss: 2.0165802041689553

Epoch: 5| Step: 9
Training loss: 1.9327850341796875
Validation loss: 2.02385006348292

Epoch: 5| Step: 10
Training loss: 2.017998218536377
Validation loss: 2.016130715608597

Epoch: 5| Step: 11
Training loss: 2.297206401824951
Validation loss: 2.0240286588668823

Epoch: 134| Step: 0
Training loss: 1.7983314990997314
Validation loss: 2.0356101791063943

Epoch: 5| Step: 1
Training loss: 1.9174768924713135
Validation loss: 2.031094084183375

Epoch: 5| Step: 2
Training loss: 2.193906784057617
Validation loss: 2.0377774387598038

Epoch: 5| Step: 3
Training loss: 2.1965274810791016
Validation loss: 2.0440092782179513

Epoch: 5| Step: 4
Training loss: 2.346479654312134
Validation loss: 2.0413108120361962

Epoch: 5| Step: 5
Training loss: 1.9433958530426025
Validation loss: 2.039008244872093

Epoch: 5| Step: 6
Training loss: 2.315985679626465
Validation loss: 2.0518098026514053

Epoch: 5| Step: 7
Training loss: 1.746272325515747
Validation loss: 2.0386404941479364

Epoch: 5| Step: 8
Training loss: 2.430493116378784
Validation loss: 2.0472562313079834

Epoch: 5| Step: 9
Training loss: 1.9301128387451172
Validation loss: 2.039173811674118

Epoch: 5| Step: 10
Training loss: 2.2099525928497314
Validation loss: 2.0199855069319406

Epoch: 5| Step: 11
Training loss: 2.183854579925537
Validation loss: 2.035702496767044

Epoch: 135| Step: 0
Training loss: 1.7918962240219116
Validation loss: 2.0344760020573935

Epoch: 5| Step: 1
Training loss: 1.8232530355453491
Validation loss: 2.035810778538386

Epoch: 5| Step: 2
Training loss: 1.9512755870819092
Validation loss: 2.0293374011913934

Epoch: 5| Step: 3
Training loss: 1.7715518474578857
Validation loss: 2.028324991464615

Epoch: 5| Step: 4
Training loss: 1.7690627574920654
Validation loss: 2.0276001344124475

Epoch: 5| Step: 5
Training loss: 2.51226806640625
Validation loss: 2.0277012834946313

Epoch: 5| Step: 6
Training loss: 1.8643615245819092
Validation loss: 2.0394763400157294

Epoch: 5| Step: 7
Training loss: 1.8628454208374023
Validation loss: 2.036813884973526

Epoch: 5| Step: 8
Training loss: 2.4097774028778076
Validation loss: 2.0477565179268518

Epoch: 5| Step: 9
Training loss: 3.0506739616394043
Validation loss: 2.0356131196022034

Epoch: 5| Step: 10
Training loss: 2.1311545372009277
Validation loss: 2.046974256634712

Epoch: 5| Step: 11
Training loss: 2.4507570266723633
Validation loss: 2.042284071445465

Epoch: 136| Step: 0
Training loss: 2.7025625705718994
Validation loss: 2.037312055627505

Epoch: 5| Step: 1
Training loss: 2.3308472633361816
Validation loss: 2.0254856646060944

Epoch: 5| Step: 2
Training loss: 1.8857656717300415
Validation loss: 2.028240198890368

Epoch: 5| Step: 3
Training loss: 2.291625499725342
Validation loss: 2.030976707736651

Epoch: 5| Step: 4
Training loss: 2.1066575050354004
Validation loss: 2.0242945651213327

Epoch: 5| Step: 5
Training loss: 2.205174684524536
Validation loss: 2.0261866052945456

Epoch: 5| Step: 6
Training loss: 1.7228000164031982
Validation loss: 2.0220279842615128

Epoch: 5| Step: 7
Training loss: 2.04746675491333
Validation loss: 2.0216146359841027

Epoch: 5| Step: 8
Training loss: 1.9837825298309326
Validation loss: 2.02780848244826

Epoch: 5| Step: 9
Training loss: 2.1217942237854004
Validation loss: 2.01892581085364

Epoch: 5| Step: 10
Training loss: 1.9250924587249756
Validation loss: 2.031118780374527

Epoch: 5| Step: 11
Training loss: 0.5248665809631348
Validation loss: 2.0287100225687027

Epoch: 137| Step: 0
Training loss: 2.245877504348755
Validation loss: 2.0448891321818032

Epoch: 5| Step: 1
Training loss: 2.096017837524414
Validation loss: 2.033162867029508

Epoch: 5| Step: 2
Training loss: 1.4669312238693237
Validation loss: 2.0207639733950296

Epoch: 5| Step: 3
Training loss: 1.7541784048080444
Validation loss: 2.0291826526323953

Epoch: 5| Step: 4
Training loss: 2.107111692428589
Validation loss: 2.026331275701523

Epoch: 5| Step: 5
Training loss: 1.8958429098129272
Validation loss: 2.0337476283311844

Epoch: 5| Step: 6
Training loss: 2.2026915550231934
Validation loss: 2.039731348554293

Epoch: 5| Step: 7
Training loss: 2.191040515899658
Validation loss: 2.0357193599144616

Epoch: 5| Step: 8
Training loss: 2.539651870727539
Validation loss: 2.048398956656456

Epoch: 5| Step: 9
Training loss: 2.2204678058624268
Validation loss: 2.0494491159915924

Epoch: 5| Step: 10
Training loss: 2.3366141319274902
Validation loss: 2.054505005478859

Epoch: 5| Step: 11
Training loss: 0.8094813823699951
Validation loss: 2.0557873845100403

Epoch: 138| Step: 0
Training loss: 2.1125824451446533
Validation loss: 2.0619753996531167

Epoch: 5| Step: 1
Training loss: 2.2469592094421387
Validation loss: 2.0609547197818756

Epoch: 5| Step: 2
Training loss: 2.3340535163879395
Validation loss: 2.0648421744505563

Epoch: 5| Step: 3
Training loss: 1.82975172996521
Validation loss: 2.0588501195112863

Epoch: 5| Step: 4
Training loss: 1.5798522233963013
Validation loss: 2.0483631740013757

Epoch: 5| Step: 5
Training loss: 2.024242877960205
Validation loss: 2.053429360191027

Epoch: 5| Step: 6
Training loss: 2.456873893737793
Validation loss: 2.038051332036654

Epoch: 5| Step: 7
Training loss: 1.972036361694336
Validation loss: 2.025123804807663

Epoch: 5| Step: 8
Training loss: 2.065577983856201
Validation loss: 2.018593485156695

Epoch: 5| Step: 9
Training loss: 2.3614134788513184
Validation loss: 2.0076594054698944

Epoch: 5| Step: 10
Training loss: 1.889623999595642
Validation loss: 2.0119362572828927

Epoch: 5| Step: 11
Training loss: 3.3149149417877197
Validation loss: 2.0051556130250296

Epoch: 139| Step: 0
Training loss: 2.454002857208252
Validation loss: 2.0094010780255

Epoch: 5| Step: 1
Training loss: 2.2707557678222656
Validation loss: 2.009882082541784

Epoch: 5| Step: 2
Training loss: 1.7709572315216064
Validation loss: 2.0087847113609314

Epoch: 5| Step: 3
Training loss: 2.404453754425049
Validation loss: 2.0110829919576645

Epoch: 5| Step: 4
Training loss: 1.695669174194336
Validation loss: 2.0100273936986923

Epoch: 5| Step: 5
Training loss: 1.857287049293518
Validation loss: 2.0059022307395935

Epoch: 5| Step: 6
Training loss: 2.073911190032959
Validation loss: 2.0080745170513787

Epoch: 5| Step: 7
Training loss: 1.9749778509140015
Validation loss: 2.0148542722066245

Epoch: 5| Step: 8
Training loss: 2.4256482124328613
Validation loss: 2.0111657281716666

Epoch: 5| Step: 9
Training loss: 2.532830238342285
Validation loss: 2.017894223332405

Epoch: 5| Step: 10
Training loss: 1.8796265125274658
Validation loss: 2.0281293590863547

Epoch: 5| Step: 11
Training loss: 1.4955880641937256
Validation loss: 2.0232826520999274

Epoch: 140| Step: 0
Training loss: 1.8874009847640991
Validation loss: 2.0262158711751304

Epoch: 5| Step: 1
Training loss: 1.8625357151031494
Validation loss: 2.0172502795855203

Epoch: 5| Step: 2
Training loss: 2.297194242477417
Validation loss: 2.0256732255220413

Epoch: 5| Step: 3
Training loss: 2.189354419708252
Validation loss: 2.034681811928749

Epoch: 5| Step: 4
Training loss: 1.8596162796020508
Validation loss: 2.030533572038015

Epoch: 5| Step: 5
Training loss: 1.852855920791626
Validation loss: 2.0294204453627267

Epoch: 5| Step: 6
Training loss: 2.1557223796844482
Validation loss: 2.042064373691877

Epoch: 5| Step: 7
Training loss: 2.398714065551758
Validation loss: 2.040042296051979

Epoch: 5| Step: 8
Training loss: 2.154630184173584
Validation loss: 2.033402835329374

Epoch: 5| Step: 9
Training loss: 2.017033576965332
Validation loss: 2.031173437833786

Epoch: 5| Step: 10
Training loss: 2.2714645862579346
Validation loss: 2.0355072965224585

Epoch: 5| Step: 11
Training loss: 2.106004476547241
Validation loss: 2.0375395864248276

Epoch: 141| Step: 0
Training loss: 1.8029234409332275
Validation loss: 2.042806347211202

Epoch: 5| Step: 1
Training loss: 2.0031180381774902
Validation loss: 2.051822076241175

Epoch: 5| Step: 2
Training loss: 2.0449671745300293
Validation loss: 2.0469401131073632

Epoch: 5| Step: 3
Training loss: 1.7769060134887695
Validation loss: 2.04149038096269

Epoch: 5| Step: 4
Training loss: 2.4222488403320312
Validation loss: 2.037167097131411

Epoch: 5| Step: 5
Training loss: 2.5720977783203125
Validation loss: 2.043542444705963

Epoch: 5| Step: 6
Training loss: 2.013698101043701
Validation loss: 2.049117753903071

Epoch: 5| Step: 7
Training loss: 2.0534980297088623
Validation loss: 2.053602715333303

Epoch: 5| Step: 8
Training loss: 1.6642940044403076
Validation loss: 2.0416681518157325

Epoch: 5| Step: 9
Training loss: 1.9294332265853882
Validation loss: 2.026244913538297

Epoch: 5| Step: 10
Training loss: 2.46409273147583
Validation loss: 2.0264201362927756

Epoch: 5| Step: 11
Training loss: 3.075133800506592
Validation loss: 2.0142758737007775

Epoch: 142| Step: 0
Training loss: 1.8716005086898804
Validation loss: 2.0140867680311203

Epoch: 5| Step: 1
Training loss: 1.240214467048645
Validation loss: 2.0166668941577277

Epoch: 5| Step: 2
Training loss: 2.2337374687194824
Validation loss: 2.015161340435346

Epoch: 5| Step: 3
Training loss: 2.2596046924591064
Validation loss: 2.0189288854599

Epoch: 5| Step: 4
Training loss: 1.7097580432891846
Validation loss: 2.0203619649012885

Epoch: 5| Step: 5
Training loss: 2.3849010467529297
Validation loss: 2.013666346669197

Epoch: 5| Step: 6
Training loss: 2.2820961475372314
Validation loss: 2.012775947650274

Epoch: 5| Step: 7
Training loss: 2.1198973655700684
Validation loss: 2.0165083507696786

Epoch: 5| Step: 8
Training loss: 2.0082242488861084
Validation loss: 2.011193424463272

Epoch: 5| Step: 9
Training loss: 2.346496105194092
Validation loss: 2.0108604431152344

Epoch: 5| Step: 10
Training loss: 2.529740810394287
Validation loss: 2.0021829903125763

Epoch: 5| Step: 11
Training loss: 3.4519991874694824
Validation loss: 2.011628141005834

Epoch: 143| Step: 0
Training loss: 1.5090968608856201
Validation loss: 2.004379774133364

Epoch: 5| Step: 1
Training loss: 2.130316972732544
Validation loss: 2.0077137798070908

Epoch: 5| Step: 2
Training loss: 2.3712587356567383
Validation loss: 2.0081163495779037

Epoch: 5| Step: 3
Training loss: 1.9473062753677368
Validation loss: 2.0112955272197723

Epoch: 5| Step: 4
Training loss: 2.4833133220672607
Validation loss: 2.0158256640036902

Epoch: 5| Step: 5
Training loss: 1.7528833150863647
Validation loss: 2.009350369373957

Epoch: 5| Step: 6
Training loss: 2.121807336807251
Validation loss: 2.0090237905581794

Epoch: 5| Step: 7
Training loss: 2.038722038269043
Validation loss: 2.01602769891421

Epoch: 5| Step: 8
Training loss: 2.478818893432617
Validation loss: 2.0166906466086707

Epoch: 5| Step: 9
Training loss: 1.964813470840454
Validation loss: 2.027868906656901

Epoch: 5| Step: 10
Training loss: 2.256192684173584
Validation loss: 2.025306517879168

Epoch: 5| Step: 11
Training loss: 1.4280261993408203
Validation loss: 2.0323668817679086

Epoch: 144| Step: 0
Training loss: 1.9512345790863037
Validation loss: 2.0288685262203217

Epoch: 5| Step: 1
Training loss: 1.8498455286026
Validation loss: 2.0395471354325614

Epoch: 5| Step: 2
Training loss: 2.458024501800537
Validation loss: 2.0481068938970566

Epoch: 5| Step: 3
Training loss: 1.4123119115829468
Validation loss: 2.0438792010148368

Epoch: 5| Step: 4
Training loss: 1.7465126514434814
Validation loss: 2.0515998949607215

Epoch: 5| Step: 5
Training loss: 2.5548620223999023
Validation loss: 2.046439468860626

Epoch: 5| Step: 6
Training loss: 2.1519484519958496
Validation loss: 2.0403401205937066

Epoch: 5| Step: 7
Training loss: 2.088918685913086
Validation loss: 2.0491304099559784

Epoch: 5| Step: 8
Training loss: 1.793686866760254
Validation loss: 2.058735489845276

Epoch: 5| Step: 9
Training loss: 2.3353493213653564
Validation loss: 2.0564245680967965

Epoch: 5| Step: 10
Training loss: 2.4794704914093018
Validation loss: 2.053853675723076

Epoch: 5| Step: 11
Training loss: 1.325854778289795
Validation loss: 2.0658083309729895

Epoch: 145| Step: 0
Training loss: 2.248654842376709
Validation loss: 2.0715163946151733

Epoch: 5| Step: 1
Training loss: 1.5133321285247803
Validation loss: 2.075585330526034

Epoch: 5| Step: 2
Training loss: 2.4056334495544434
Validation loss: 2.0982957035303116

Epoch: 5| Step: 3
Training loss: 1.8738189935684204
Validation loss: 2.10061381260554

Epoch: 5| Step: 4
Training loss: 2.1029064655303955
Validation loss: 2.0714013377825418

Epoch: 5| Step: 5
Training loss: 1.7160145044326782
Validation loss: 2.0554976413647332

Epoch: 5| Step: 6
Training loss: 1.9216527938842773
Validation loss: 2.046347513794899

Epoch: 5| Step: 7
Training loss: 2.3133747577667236
Validation loss: 2.047021374106407

Epoch: 5| Step: 8
Training loss: 2.383817195892334
Validation loss: 2.041695366303126

Epoch: 5| Step: 9
Training loss: 2.106987714767456
Validation loss: 2.0409453163544335

Epoch: 5| Step: 10
Training loss: 2.3099474906921387
Validation loss: 2.028108840187391

Epoch: 5| Step: 11
Training loss: 2.8942270278930664
Validation loss: 2.033926303188006

Epoch: 146| Step: 0
Training loss: 1.858496069908142
Validation loss: 2.0399945924679437

Epoch: 5| Step: 1
Training loss: 2.0089027881622314
Validation loss: 2.033801704645157

Epoch: 5| Step: 2
Training loss: 1.8940290212631226
Validation loss: 2.0336051136255264

Epoch: 5| Step: 3
Training loss: 2.109206438064575
Validation loss: 2.0442287723223367

Epoch: 5| Step: 4
Training loss: 2.0063750743865967
Validation loss: 2.0538962284723916

Epoch: 5| Step: 5
Training loss: 2.1630382537841797
Validation loss: 2.048589160044988

Epoch: 5| Step: 6
Training loss: 2.2609331607818604
Validation loss: 2.05536679426829

Epoch: 5| Step: 7
Training loss: 2.1190757751464844
Validation loss: 2.067898914217949

Epoch: 5| Step: 8
Training loss: 2.0951130390167236
Validation loss: 2.0599288692077002

Epoch: 5| Step: 9
Training loss: 2.405219316482544
Validation loss: 2.0733147213856378

Epoch: 5| Step: 10
Training loss: 2.059476375579834
Validation loss: 2.074581523736318

Epoch: 5| Step: 11
Training loss: 1.8083465099334717
Validation loss: 2.0713376055161157

Epoch: 147| Step: 0
Training loss: 1.6595367193222046
Validation loss: 2.0579129507144294

Epoch: 5| Step: 1
Training loss: 1.6363325119018555
Validation loss: 2.0704167932271957

Epoch: 5| Step: 2
Training loss: 2.2103586196899414
Validation loss: 2.06947327653567

Epoch: 5| Step: 3
Training loss: 1.9021310806274414
Validation loss: 2.065355141957601

Epoch: 5| Step: 4
Training loss: 2.059556484222412
Validation loss: 2.0585264762242637

Epoch: 5| Step: 5
Training loss: 2.575568675994873
Validation loss: 2.054257780313492

Epoch: 5| Step: 6
Training loss: 2.0468826293945312
Validation loss: 2.0478739639123282

Epoch: 5| Step: 7
Training loss: 1.911110281944275
Validation loss: 2.0447147637605667

Epoch: 5| Step: 8
Training loss: 2.3407578468322754
Validation loss: 2.042552093664805

Epoch: 5| Step: 9
Training loss: 2.064209461212158
Validation loss: 2.0323040982087455

Epoch: 5| Step: 10
Training loss: 2.5269932746887207
Validation loss: 2.0317597140868506

Epoch: 5| Step: 11
Training loss: 1.4155360460281372
Validation loss: 2.0261116524537406

Epoch: 148| Step: 0
Training loss: 2.4601359367370605
Validation loss: 2.03160892923673

Epoch: 5| Step: 1
Training loss: 2.1687686443328857
Validation loss: 2.026700899004936

Epoch: 5| Step: 2
Training loss: 2.156615734100342
Validation loss: 2.031078562140465

Epoch: 5| Step: 3
Training loss: 2.3890979290008545
Validation loss: 2.0375690509875617

Epoch: 5| Step: 4
Training loss: 2.56829571723938
Validation loss: 2.0331582923730216

Epoch: 5| Step: 5
Training loss: 2.0470385551452637
Validation loss: 2.026639074087143

Epoch: 5| Step: 6
Training loss: 1.8627218008041382
Validation loss: 2.0209018538395562

Epoch: 5| Step: 7
Training loss: 2.1075966358184814
Validation loss: 2.0324969788392386

Epoch: 5| Step: 8
Training loss: 1.4677467346191406
Validation loss: 2.0281117657820382

Epoch: 5| Step: 9
Training loss: 1.76251220703125
Validation loss: 2.03008001546065

Epoch: 5| Step: 10
Training loss: 1.8460391759872437
Validation loss: 2.019980529944102

Epoch: 5| Step: 11
Training loss: 2.388119697570801
Validation loss: 2.024614612261454

Epoch: 149| Step: 0
Training loss: 1.8443081378936768
Validation loss: 2.0342338581879935

Epoch: 5| Step: 1
Training loss: 2.0278546810150146
Validation loss: 2.032890642682711

Epoch: 5| Step: 2
Training loss: 1.9729198217391968
Validation loss: 2.0523803333441415

Epoch: 5| Step: 3
Training loss: 1.7744563817977905
Validation loss: 2.054341420531273

Epoch: 5| Step: 4
Training loss: 1.7511742115020752
Validation loss: 2.0563799838225045

Epoch: 5| Step: 5
Training loss: 2.1816039085388184
Validation loss: 2.0577804346879325

Epoch: 5| Step: 6
Training loss: 2.0725553035736084
Validation loss: 2.0625000596046448

Epoch: 5| Step: 7
Training loss: 2.086277484893799
Validation loss: 2.067663937807083

Epoch: 5| Step: 8
Training loss: 2.5300259590148926
Validation loss: 2.0694602678219476

Epoch: 5| Step: 9
Training loss: 2.6569876670837402
Validation loss: 2.064204211036364

Epoch: 5| Step: 10
Training loss: 1.9823181629180908
Validation loss: 2.064039175709089

Epoch: 5| Step: 11
Training loss: 2.608755350112915
Validation loss: 2.064009169737498

Epoch: 150| Step: 0
Training loss: 1.9254251718521118
Validation loss: 2.069007491072019

Epoch: 5| Step: 1
Training loss: 2.231147050857544
Validation loss: 2.078063815832138

Epoch: 5| Step: 2
Training loss: 1.7218729257583618
Validation loss: 2.081725060939789

Epoch: 5| Step: 3
Training loss: 2.030022382736206
Validation loss: 2.0708584586779275

Epoch: 5| Step: 4
Training loss: 2.2910447120666504
Validation loss: 2.0745606869459152

Epoch: 5| Step: 5
Training loss: 2.0820670127868652
Validation loss: 2.08606610695521

Epoch: 5| Step: 6
Training loss: 1.8792297840118408
Validation loss: 2.076284646987915

Epoch: 5| Step: 7
Training loss: 1.797895073890686
Validation loss: 2.0636056512594223

Epoch: 5| Step: 8
Training loss: 2.1975817680358887
Validation loss: 2.064094305038452

Epoch: 5| Step: 9
Training loss: 2.008169174194336
Validation loss: 2.058198163906733

Epoch: 5| Step: 10
Training loss: 2.6191883087158203
Validation loss: 2.048969184358915

Epoch: 5| Step: 11
Training loss: 1.6312611103057861
Validation loss: 2.052357092499733

Epoch: 151| Step: 0
Training loss: 2.2039871215820312
Validation loss: 2.0341659684975943

Epoch: 5| Step: 1
Training loss: 1.8781623840332031
Validation loss: 2.0270405064026513

Epoch: 5| Step: 2
Training loss: 2.145298719406128
Validation loss: 2.030936742822329

Epoch: 5| Step: 3
Training loss: 2.364581823348999
Validation loss: 2.0319014439980188

Epoch: 5| Step: 4
Training loss: 2.2539398670196533
Validation loss: 2.0315989057223

Epoch: 5| Step: 5
Training loss: 2.0575034618377686
Validation loss: 2.026251897215843

Epoch: 5| Step: 6
Training loss: 2.3487367630004883
Validation loss: 2.0315819084644318

Epoch: 5| Step: 7
Training loss: 2.1827309131622314
Validation loss: 2.0278425564368567

Epoch: 5| Step: 8
Training loss: 2.033494472503662
Validation loss: 2.03818608323733

Epoch: 5| Step: 9
Training loss: 2.0551705360412598
Validation loss: 2.032507007320722

Epoch: 5| Step: 10
Training loss: 1.9264037609100342
Validation loss: 2.037786448995272

Epoch: 5| Step: 11
Training loss: 1.6073076725006104
Validation loss: 2.0310890128215155

Epoch: 152| Step: 0
Training loss: 2.019618511199951
Validation loss: 2.023914640148481

Epoch: 5| Step: 1
Training loss: 2.1254796981811523
Validation loss: 2.0254771411418915

Epoch: 5| Step: 2
Training loss: 2.194373607635498
Validation loss: 2.013841604193052

Epoch: 5| Step: 3
Training loss: 2.2628281116485596
Validation loss: 2.019318441549937

Epoch: 5| Step: 4
Training loss: 2.5374197959899902
Validation loss: 2.0224748700857162

Epoch: 5| Step: 5
Training loss: 2.2648110389709473
Validation loss: 2.019277741511663

Epoch: 5| Step: 6
Training loss: 2.3357505798339844
Validation loss: 2.0220141410827637

Epoch: 5| Step: 7
Training loss: 1.5101191997528076
Validation loss: 2.028680125872294

Epoch: 5| Step: 8
Training loss: 2.375884771347046
Validation loss: 2.039100334048271

Epoch: 5| Step: 9
Training loss: 1.624695062637329
Validation loss: 2.0511296639839807

Epoch: 5| Step: 10
Training loss: 1.9181663990020752
Validation loss: 2.0414986113707223

Epoch: 5| Step: 11
Training loss: 2.767643690109253
Validation loss: 2.037139435609182

Epoch: 153| Step: 0
Training loss: 2.3626010417938232
Validation loss: 2.034773881236712

Epoch: 5| Step: 1
Training loss: 2.486394166946411
Validation loss: 2.036105295022329

Epoch: 5| Step: 2
Training loss: 2.09993052482605
Validation loss: 2.035528391599655

Epoch: 5| Step: 3
Training loss: 1.9863121509552002
Validation loss: 2.0345358153184256

Epoch: 5| Step: 4
Training loss: 1.9694187641143799
Validation loss: 2.0449416438738504

Epoch: 5| Step: 5
Training loss: 2.3962693214416504
Validation loss: 2.0337269008159637

Epoch: 5| Step: 6
Training loss: 2.33671498298645
Validation loss: 2.0345113376776376

Epoch: 5| Step: 7
Training loss: 1.7186428308486938
Validation loss: 2.025225132703781

Epoch: 5| Step: 8
Training loss: 2.1806092262268066
Validation loss: 2.030096466342608

Epoch: 5| Step: 9
Training loss: 1.811505913734436
Validation loss: 2.0324816902478537

Epoch: 5| Step: 10
Training loss: 1.8037420511245728
Validation loss: 2.0280680060386658

Epoch: 5| Step: 11
Training loss: 2.496717691421509
Validation loss: 2.026496097445488

Epoch: 154| Step: 0
Training loss: 2.032684803009033
Validation loss: 2.0412294814984002

Epoch: 5| Step: 1
Training loss: 2.043192148208618
Validation loss: 2.0353435377279916

Epoch: 5| Step: 2
Training loss: 1.9816583395004272
Validation loss: 2.0268198748429618

Epoch: 5| Step: 3
Training loss: 2.3228487968444824
Validation loss: 2.029883086681366

Epoch: 5| Step: 4
Training loss: 1.9941326379776
Validation loss: 2.0393207172552743

Epoch: 5| Step: 5
Training loss: 2.117617607116699
Validation loss: 2.036742721994718

Epoch: 5| Step: 6
Training loss: 1.650779366493225
Validation loss: 2.0447235107421875

Epoch: 5| Step: 7
Training loss: 2.522681713104248
Validation loss: 2.051021700104078

Epoch: 5| Step: 8
Training loss: 2.397296905517578
Validation loss: 2.054632236560186

Epoch: 5| Step: 9
Training loss: 2.1836299896240234
Validation loss: 2.0378853430350623

Epoch: 5| Step: 10
Training loss: 1.589759111404419
Validation loss: 2.0547801653544107

Epoch: 5| Step: 11
Training loss: 1.8111804723739624
Validation loss: 2.048631946245829

Epoch: 155| Step: 0
Training loss: 2.1409404277801514
Validation loss: 2.042383427421252

Epoch: 5| Step: 1
Training loss: 2.244668960571289
Validation loss: 2.0328393826882043

Epoch: 5| Step: 2
Training loss: 1.4105737209320068
Validation loss: 2.0287950883309045

Epoch: 5| Step: 3
Training loss: 2.5674612522125244
Validation loss: 2.0334450205167136

Epoch: 5| Step: 4
Training loss: 1.8533433675765991
Validation loss: 2.0402856866518655

Epoch: 5| Step: 5
Training loss: 2.457096815109253
Validation loss: 2.0403770903746286

Epoch: 5| Step: 6
Training loss: 2.1753692626953125
Validation loss: 2.054989526669184

Epoch: 5| Step: 7
Training loss: 1.8823219537734985
Validation loss: 2.0558256010214486

Epoch: 5| Step: 8
Training loss: 1.531714677810669
Validation loss: 2.0632280757029853

Epoch: 5| Step: 9
Training loss: 2.3362298011779785
Validation loss: 2.058075482646624

Epoch: 5| Step: 10
Training loss: 2.013352870941162
Validation loss: 2.052469184001287

Epoch: 5| Step: 11
Training loss: 2.1235249042510986
Validation loss: 2.0664808054765067

Epoch: 156| Step: 0
Training loss: 2.5015957355499268
Validation loss: 2.0498985201120377

Epoch: 5| Step: 1
Training loss: 2.207045316696167
Validation loss: 2.0566239853700004

Epoch: 5| Step: 2
Training loss: 1.6302411556243896
Validation loss: 2.0574125250180564

Epoch: 5| Step: 3
Training loss: 2.3513576984405518
Validation loss: 2.0588672161102295

Epoch: 5| Step: 4
Training loss: 1.5800096988677979
Validation loss: 2.057368367910385

Epoch: 5| Step: 5
Training loss: 1.9839057922363281
Validation loss: 2.054558292031288

Epoch: 5| Step: 6
Training loss: 1.9040123224258423
Validation loss: 2.0575899680455527

Epoch: 5| Step: 7
Training loss: 1.713334321975708
Validation loss: 2.059919779499372

Epoch: 5| Step: 8
Training loss: 2.2091565132141113
Validation loss: 2.049783612291018

Epoch: 5| Step: 9
Training loss: 2.320390224456787
Validation loss: 2.053092767794927

Epoch: 5| Step: 10
Training loss: 2.102339506149292
Validation loss: 2.0490069140990577

Epoch: 5| Step: 11
Training loss: 2.76776385307312
Validation loss: 2.0552990088860192

Epoch: 157| Step: 0
Training loss: 2.3429648876190186
Validation loss: 2.0504183918237686

Epoch: 5| Step: 1
Training loss: 1.781869888305664
Validation loss: 2.0485691527525582

Epoch: 5| Step: 2
Training loss: 1.8671703338623047
Validation loss: 2.052877798676491

Epoch: 5| Step: 3
Training loss: 1.4606220722198486
Validation loss: 2.0395455906788507

Epoch: 5| Step: 4
Training loss: 2.2129273414611816
Validation loss: 2.037250116467476

Epoch: 5| Step: 5
Training loss: 2.535526990890503
Validation loss: 2.043356036146482

Epoch: 5| Step: 6
Training loss: 1.683938980102539
Validation loss: 2.0424820383389792

Epoch: 5| Step: 7
Training loss: 2.204659938812256
Validation loss: 2.0582566310962043

Epoch: 5| Step: 8
Training loss: 1.6807924509048462
Validation loss: 2.0478635181983313

Epoch: 5| Step: 9
Training loss: 2.7043685913085938
Validation loss: 2.05387348930041

Epoch: 5| Step: 10
Training loss: 1.8820836544036865
Validation loss: 2.05121744175752

Epoch: 5| Step: 11
Training loss: 2.5252904891967773
Validation loss: 2.0589750905831656

Epoch: 158| Step: 0
Training loss: 1.8864834308624268
Validation loss: 2.0622836649417877

Epoch: 5| Step: 1
Training loss: 1.5359697341918945
Validation loss: 2.0736448764801025

Epoch: 5| Step: 2
Training loss: 2.17559552192688
Validation loss: 2.0736469477415085

Epoch: 5| Step: 3
Training loss: 2.3336122035980225
Validation loss: 2.0615709672371545

Epoch: 5| Step: 4
Training loss: 2.149700880050659
Validation loss: 2.0698995689551034

Epoch: 5| Step: 5
Training loss: 2.2311038970947266
Validation loss: 2.064471960067749

Epoch: 5| Step: 6
Training loss: 2.005089282989502
Validation loss: 2.0602754453818

Epoch: 5| Step: 7
Training loss: 1.6599104404449463
Validation loss: 2.0622890988985696

Epoch: 5| Step: 8
Training loss: 2.274120330810547
Validation loss: 2.0445668399333954

Epoch: 5| Step: 9
Training loss: 2.0983123779296875
Validation loss: 2.0520006169875464

Epoch: 5| Step: 10
Training loss: 2.2478489875793457
Validation loss: 2.059040829539299

Epoch: 5| Step: 11
Training loss: 1.6019279956817627
Validation loss: 2.045113434394201

Epoch: 159| Step: 0
Training loss: 2.1308798789978027
Validation loss: 2.054466883341471

Epoch: 5| Step: 1
Training loss: 1.7313541173934937
Validation loss: 2.0537162025769553

Epoch: 5| Step: 2
Training loss: 2.166565418243408
Validation loss: 2.054706498980522

Epoch: 5| Step: 3
Training loss: 1.5769020318984985
Validation loss: 2.0562597513198853

Epoch: 5| Step: 4
Training loss: 2.2691335678100586
Validation loss: 2.05869814256827

Epoch: 5| Step: 5
Training loss: 1.85700261592865
Validation loss: 2.0637546380360923

Epoch: 5| Step: 6
Training loss: 2.515232563018799
Validation loss: 2.0622135549783707

Epoch: 5| Step: 7
Training loss: 2.1823134422302246
Validation loss: 2.066966488957405

Epoch: 5| Step: 8
Training loss: 1.6231906414031982
Validation loss: 2.065883239110311

Epoch: 5| Step: 9
Training loss: 1.9548346996307373
Validation loss: 2.0517224272092185

Epoch: 5| Step: 10
Training loss: 2.3845152854919434
Validation loss: 2.0587737560272217

Epoch: 5| Step: 11
Training loss: 1.567654013633728
Validation loss: 2.0580988178650537

Epoch: 160| Step: 0
Training loss: 1.619576096534729
Validation loss: 2.0574806729952493

Epoch: 5| Step: 1
Training loss: 2.0079147815704346
Validation loss: 2.0682620207468667

Epoch: 5| Step: 2
Training loss: 2.210366725921631
Validation loss: 2.054190302888552

Epoch: 5| Step: 3
Training loss: 2.028078317642212
Validation loss: 2.0599705477555594

Epoch: 5| Step: 4
Training loss: 1.8644399642944336
Validation loss: 2.053379143277804

Epoch: 5| Step: 5
Training loss: 1.7639331817626953
Validation loss: 2.062979072332382

Epoch: 5| Step: 6
Training loss: 2.2108840942382812
Validation loss: 2.0582836071650186

Epoch: 5| Step: 7
Training loss: 2.3327651023864746
Validation loss: 2.0533982117970786

Epoch: 5| Step: 8
Training loss: 2.1512460708618164
Validation loss: 2.063054844737053

Epoch: 5| Step: 9
Training loss: 2.165104627609253
Validation loss: 2.0672647853692374

Epoch: 5| Step: 10
Training loss: 2.010988712310791
Validation loss: 2.063438192009926

Epoch: 5| Step: 11
Training loss: 1.499419927597046
Validation loss: 2.0518198808034263

Epoch: 161| Step: 0
Training loss: 1.8998867273330688
Validation loss: 2.069606011112531

Epoch: 5| Step: 1
Training loss: 1.963440179824829
Validation loss: 2.0648483633995056

Epoch: 5| Step: 2
Training loss: 2.5384652614593506
Validation loss: 2.0722888857126236

Epoch: 5| Step: 3
Training loss: 2.4072012901306152
Validation loss: 2.0742741028467813

Epoch: 5| Step: 4
Training loss: 2.203577995300293
Validation loss: 2.0754534304142

Epoch: 5| Step: 5
Training loss: 1.7232348918914795
Validation loss: 2.065231586496035

Epoch: 5| Step: 6
Training loss: 2.0498805046081543
Validation loss: 2.063379163543383

Epoch: 5| Step: 7
Training loss: 2.081423282623291
Validation loss: 2.0577449649572372

Epoch: 5| Step: 8
Training loss: 1.9203284978866577
Validation loss: 2.051506072282791

Epoch: 5| Step: 9
Training loss: 2.072146415710449
Validation loss: 2.055098449190458

Epoch: 5| Step: 10
Training loss: 1.702549695968628
Validation loss: 2.0630223055680594

Epoch: 5| Step: 11
Training loss: 1.8672877550125122
Validation loss: 2.05616124967734

Epoch: 162| Step: 0
Training loss: 1.8820788860321045
Validation loss: 2.0671595136324563

Epoch: 5| Step: 1
Training loss: 1.4335670471191406
Validation loss: 2.068748806913694

Epoch: 5| Step: 2
Training loss: 1.7375335693359375
Validation loss: 2.0642427057027817

Epoch: 5| Step: 3
Training loss: 2.361876964569092
Validation loss: 2.060038755337397

Epoch: 5| Step: 4
Training loss: 2.630425214767456
Validation loss: 2.0758614043394723

Epoch: 5| Step: 5
Training loss: 2.518228769302368
Validation loss: 2.0766241202751794

Epoch: 5| Step: 6
Training loss: 2.1429667472839355
Validation loss: 2.079147865374883

Epoch: 5| Step: 7
Training loss: 2.1326427459716797
Validation loss: 2.0729287962118783

Epoch: 5| Step: 8
Training loss: 1.9710174798965454
Validation loss: 2.0781772484381995

Epoch: 5| Step: 9
Training loss: 1.70890212059021
Validation loss: 2.0640360663334527

Epoch: 5| Step: 10
Training loss: 2.1393814086914062
Validation loss: 2.063578928510348

Epoch: 5| Step: 11
Training loss: 0.563174307346344
Validation loss: 2.066418925921122

Epoch: 163| Step: 0
Training loss: 1.8452894687652588
Validation loss: 2.0771505385637283

Epoch: 5| Step: 1
Training loss: 1.86038076877594
Validation loss: 2.053387075662613

Epoch: 5| Step: 2
Training loss: 1.9635086059570312
Validation loss: 2.053336580594381

Epoch: 5| Step: 3
Training loss: 1.761054277420044
Validation loss: 2.0473593970139823

Epoch: 5| Step: 4
Training loss: 2.449979066848755
Validation loss: 2.050391341249148

Epoch: 5| Step: 5
Training loss: 2.1553750038146973
Validation loss: 2.057120700677236

Epoch: 5| Step: 6
Training loss: 2.426995277404785
Validation loss: 2.0482284178336463

Epoch: 5| Step: 7
Training loss: 1.3079841136932373
Validation loss: 2.0539555797974267

Epoch: 5| Step: 8
Training loss: 1.930053472518921
Validation loss: 2.0582547932863235

Epoch: 5| Step: 9
Training loss: 2.3292155265808105
Validation loss: 2.052927941083908

Epoch: 5| Step: 10
Training loss: 2.2788619995117188
Validation loss: 2.054555987318357

Epoch: 5| Step: 11
Training loss: 2.820610284805298
Validation loss: 2.0574066092570624

Epoch: 164| Step: 0
Training loss: 2.540607213973999
Validation loss: 2.069212739666303

Epoch: 5| Step: 1
Training loss: 2.0400240421295166
Validation loss: 2.0643224914868674

Epoch: 5| Step: 2
Training loss: 1.9533439874649048
Validation loss: 2.0722164511680603

Epoch: 5| Step: 3
Training loss: 2.223069667816162
Validation loss: 2.0758029222488403

Epoch: 5| Step: 4
Training loss: 2.002779960632324
Validation loss: 2.0747948636611304

Epoch: 5| Step: 5
Training loss: 2.102823257446289
Validation loss: 2.074950233101845

Epoch: 5| Step: 6
Training loss: 1.9772895574569702
Validation loss: 2.0707335472106934

Epoch: 5| Step: 7
Training loss: 2.649305820465088
Validation loss: 2.0659485111633935

Epoch: 5| Step: 8
Training loss: 2.543893337249756
Validation loss: 2.0579624275366464

Epoch: 5| Step: 9
Training loss: 1.241532325744629
Validation loss: 2.0572177519400916

Epoch: 5| Step: 10
Training loss: 1.2935913801193237
Validation loss: 2.0619030694166818

Epoch: 5| Step: 11
Training loss: 1.213256597518921
Validation loss: 2.0579852362473807

Epoch: 165| Step: 0
Training loss: 2.3616690635681152
Validation loss: 2.0722315857807794

Epoch: 5| Step: 1
Training loss: 1.8316084146499634
Validation loss: 2.07704891761144

Epoch: 5| Step: 2
Training loss: 1.9531385898590088
Validation loss: 2.0900980085134506

Epoch: 5| Step: 3
Training loss: 2.2920055389404297
Validation loss: 2.073910027742386

Epoch: 5| Step: 4
Training loss: 1.9662567377090454
Validation loss: 2.0708893040815988

Epoch: 5| Step: 5
Training loss: 1.8243610858917236
Validation loss: 2.0719199180603027

Epoch: 5| Step: 6
Training loss: 2.1131060123443604
Validation loss: 2.064279392361641

Epoch: 5| Step: 7
Training loss: 1.7077662944793701
Validation loss: 2.074412693579992

Epoch: 5| Step: 8
Training loss: 2.4344065189361572
Validation loss: 2.0591090619564056

Epoch: 5| Step: 9
Training loss: 1.9722808599472046
Validation loss: 2.0568953305482864

Epoch: 5| Step: 10
Training loss: 1.9508174657821655
Validation loss: 2.055627296368281

Epoch: 5| Step: 11
Training loss: 1.6168313026428223
Validation loss: 2.052572324872017

Epoch: 166| Step: 0
Training loss: 1.1928962469100952
Validation loss: 2.0596573104461036

Epoch: 5| Step: 1
Training loss: 1.8191207647323608
Validation loss: 2.0615392923355103

Epoch: 5| Step: 2
Training loss: 1.544905424118042
Validation loss: 2.067270870010058

Epoch: 5| Step: 3
Training loss: 2.198061466217041
Validation loss: 2.064672276377678

Epoch: 5| Step: 4
Training loss: 2.295743227005005
Validation loss: 2.074057623744011

Epoch: 5| Step: 5
Training loss: 1.9451358318328857
Validation loss: 2.07141974568367

Epoch: 5| Step: 6
Training loss: 2.314304828643799
Validation loss: 2.0988563944896064

Epoch: 5| Step: 7
Training loss: 2.664987325668335
Validation loss: 2.086549073457718

Epoch: 5| Step: 8
Training loss: 2.303217887878418
Validation loss: 2.0866805712381997

Epoch: 5| Step: 9
Training loss: 2.2159502506256104
Validation loss: 2.10594542324543

Epoch: 5| Step: 10
Training loss: 2.1135621070861816
Validation loss: 2.081569641828537

Epoch: 5| Step: 11
Training loss: 2.982954263687134
Validation loss: 2.072574188311895

Epoch: 167| Step: 0
Training loss: 2.0575063228607178
Validation loss: 2.0668251613775888

Epoch: 5| Step: 1
Training loss: 1.3528064489364624
Validation loss: 2.0442760040362677

Epoch: 5| Step: 2
Training loss: 2.836925983428955
Validation loss: 2.0386371513207755

Epoch: 5| Step: 3
Training loss: 2.1649184226989746
Validation loss: 2.0391927858193717

Epoch: 5| Step: 4
Training loss: 2.319235324859619
Validation loss: 2.021969104806582

Epoch: 5| Step: 5
Training loss: 1.7483097314834595
Validation loss: 2.0318044821421304

Epoch: 5| Step: 6
Training loss: 2.321887254714966
Validation loss: 2.035035952925682

Epoch: 5| Step: 7
Training loss: 1.6604019403457642
Validation loss: 2.0295538008213043

Epoch: 5| Step: 8
Training loss: 2.1084225177764893
Validation loss: 2.0274657706419625

Epoch: 5| Step: 9
Training loss: 1.791691780090332
Validation loss: 2.0275680273771286

Epoch: 5| Step: 10
Training loss: 1.9807684421539307
Validation loss: 2.0284611036380134

Epoch: 5| Step: 11
Training loss: 3.418797016143799
Validation loss: 2.027933900554975

Epoch: 168| Step: 0
Training loss: 2.3320422172546387
Validation loss: 2.0306074917316437

Epoch: 5| Step: 1
Training loss: 2.3789710998535156
Validation loss: 2.036577175060908

Epoch: 5| Step: 2
Training loss: 2.717878818511963
Validation loss: 2.046255479256312

Epoch: 5| Step: 3
Training loss: 1.6513316631317139
Validation loss: 2.047803262869517

Epoch: 5| Step: 4
Training loss: 1.3661085367202759
Validation loss: 2.05216421186924

Epoch: 5| Step: 5
Training loss: 1.618581771850586
Validation loss: 2.050983597834905

Epoch: 5| Step: 6
Training loss: 2.241985321044922
Validation loss: 2.0616686890522637

Epoch: 5| Step: 7
Training loss: 2.1158432960510254
Validation loss: 2.0598663687705994

Epoch: 5| Step: 8
Training loss: 1.9640676975250244
Validation loss: 2.0647762417793274

Epoch: 5| Step: 9
Training loss: 2.173605442047119
Validation loss: 2.078528712193171

Epoch: 5| Step: 10
Training loss: 1.610821008682251
Validation loss: 2.0833740631739297

Epoch: 5| Step: 11
Training loss: 3.133134126663208
Validation loss: 2.086753770709038

Epoch: 169| Step: 0
Training loss: 2.023169994354248
Validation loss: 2.072101334730784

Epoch: 5| Step: 1
Training loss: 1.5929386615753174
Validation loss: 2.054277370373408

Epoch: 5| Step: 2
Training loss: 1.9215309619903564
Validation loss: 2.059361586968104

Epoch: 5| Step: 3
Training loss: 1.963597059249878
Validation loss: 2.0558219999074936

Epoch: 5| Step: 4
Training loss: 1.8735902309417725
Validation loss: 2.0460731238126755

Epoch: 5| Step: 5
Training loss: 2.6889548301696777
Validation loss: 2.029770572980245

Epoch: 5| Step: 6
Training loss: 2.136476993560791
Validation loss: 2.037759547432264

Epoch: 5| Step: 7
Training loss: 1.9559202194213867
Validation loss: 2.031334415078163

Epoch: 5| Step: 8
Training loss: 1.9606506824493408
Validation loss: 2.0299318681160607

Epoch: 5| Step: 9
Training loss: 2.4867186546325684
Validation loss: 2.0399232556422553

Epoch: 5| Step: 10
Training loss: 2.369692802429199
Validation loss: 2.0423730611801147

Epoch: 5| Step: 11
Training loss: 1.2084238529205322
Validation loss: 2.034553810954094

Epoch: 170| Step: 0
Training loss: 2.49530029296875
Validation loss: 2.0453015565872192

Epoch: 5| Step: 1
Training loss: 2.215897560119629
Validation loss: 2.045893539985021

Epoch: 5| Step: 2
Training loss: 2.1069493293762207
Validation loss: 2.05900306502978

Epoch: 5| Step: 3
Training loss: 1.8346633911132812
Validation loss: 2.0647104481856027

Epoch: 5| Step: 4
Training loss: 2.606675624847412
Validation loss: 2.062381496032079

Epoch: 5| Step: 5
Training loss: 1.99098801612854
Validation loss: 2.0562553256750107

Epoch: 5| Step: 6
Training loss: 1.7364521026611328
Validation loss: 2.0683414041996

Epoch: 5| Step: 7
Training loss: 1.9764124155044556
Validation loss: 2.0579548478126526

Epoch: 5| Step: 8
Training loss: 1.618661642074585
Validation loss: 2.0693151652812958

Epoch: 5| Step: 9
Training loss: 1.8335720300674438
Validation loss: 2.0617957413196564

Epoch: 5| Step: 10
Training loss: 1.6587775945663452
Validation loss: 2.0715347478787103

Epoch: 5| Step: 11
Training loss: 2.2163047790527344
Validation loss: 2.056152512629827

Epoch: 171| Step: 0
Training loss: 1.8085438013076782
Validation loss: 2.057728831966718

Epoch: 5| Step: 1
Training loss: 1.9007320404052734
Validation loss: 2.0637386441230774

Epoch: 5| Step: 2
Training loss: 2.0476369857788086
Validation loss: 2.0714300523201623

Epoch: 5| Step: 3
Training loss: 2.699388027191162
Validation loss: 2.076493273178736

Epoch: 5| Step: 4
Training loss: 1.965091347694397
Validation loss: 2.0655298779408136

Epoch: 5| Step: 5
Training loss: 2.166346311569214
Validation loss: 2.07428507010142

Epoch: 5| Step: 6
Training loss: 1.9402611255645752
Validation loss: 2.084412897626559

Epoch: 5| Step: 7
Training loss: 2.0039825439453125
Validation loss: 2.0937460561593375

Epoch: 5| Step: 8
Training loss: 1.5714079141616821
Validation loss: 2.084109445412954

Epoch: 5| Step: 9
Training loss: 1.8646490573883057
Validation loss: 2.0902802844842276

Epoch: 5| Step: 10
Training loss: 1.9003654718399048
Validation loss: 2.0902012437582016

Epoch: 5| Step: 11
Training loss: 4.009352207183838
Validation loss: 2.077157308657964

Epoch: 172| Step: 0
Training loss: 1.8357617855072021
Validation loss: 2.082092210650444

Epoch: 5| Step: 1
Training loss: 1.974355697631836
Validation loss: 2.055676062901815

Epoch: 5| Step: 2
Training loss: 1.9101879596710205
Validation loss: 2.062755599617958

Epoch: 5| Step: 3
Training loss: 2.303774356842041
Validation loss: 2.0474768380324044

Epoch: 5| Step: 4
Training loss: 1.9514116048812866
Validation loss: 2.0462570240100226

Epoch: 5| Step: 5
Training loss: 2.503706693649292
Validation loss: 2.03959359228611

Epoch: 5| Step: 6
Training loss: 2.4562442302703857
Validation loss: 2.0470220148563385

Epoch: 5| Step: 7
Training loss: 1.5130040645599365
Validation loss: 2.05290994544824

Epoch: 5| Step: 8
Training loss: 1.9392789602279663
Validation loss: 2.0514650692542395

Epoch: 5| Step: 9
Training loss: 2.2211856842041016
Validation loss: 2.0709574967622757

Epoch: 5| Step: 10
Training loss: 1.6392490863800049
Validation loss: 2.0841091771920524

Epoch: 5| Step: 11
Training loss: 2.153465986251831
Validation loss: 2.0854827811320624

Epoch: 173| Step: 0
Training loss: 1.393386721611023
Validation loss: 2.1105951964855194

Epoch: 5| Step: 1
Training loss: 2.109600067138672
Validation loss: 2.1078893740971885

Epoch: 5| Step: 2
Training loss: 1.7707113027572632
Validation loss: 2.101196527481079

Epoch: 5| Step: 3
Training loss: 2.4125585556030273
Validation loss: 2.107490132252375

Epoch: 5| Step: 4
Training loss: 2.1653921604156494
Validation loss: 2.116471682985624

Epoch: 5| Step: 5
Training loss: 2.396561622619629
Validation loss: 2.089549640814463

Epoch: 5| Step: 6
Training loss: 2.481301784515381
Validation loss: 2.091284602880478

Epoch: 5| Step: 7
Training loss: 2.127638339996338
Validation loss: 2.0873451282580695

Epoch: 5| Step: 8
Training loss: 1.807962417602539
Validation loss: 2.077906767527262

Epoch: 5| Step: 9
Training loss: 1.3584139347076416
Validation loss: 2.0607056568066278

Epoch: 5| Step: 10
Training loss: 1.9918594360351562
Validation loss: 2.0486533492803574

Epoch: 5| Step: 11
Training loss: 3.304084300994873
Validation loss: 2.044209132591883

Epoch: 174| Step: 0
Training loss: 1.7491270303726196
Validation loss: 2.0402450462182364

Epoch: 5| Step: 1
Training loss: 2.085427761077881
Validation loss: 2.0351758748292923

Epoch: 5| Step: 2
Training loss: 2.268040895462036
Validation loss: 2.0391137848297753

Epoch: 5| Step: 3
Training loss: 2.5400428771972656
Validation loss: 2.0350043177604675

Epoch: 5| Step: 4
Training loss: 2.086336612701416
Validation loss: 2.037178084254265

Epoch: 5| Step: 5
Training loss: 2.3244900703430176
Validation loss: 2.0327389538288116

Epoch: 5| Step: 6
Training loss: 1.433250904083252
Validation loss: 2.041080037752787

Epoch: 5| Step: 7
Training loss: 1.783376693725586
Validation loss: 2.0469821790854135

Epoch: 5| Step: 8
Training loss: 1.9821134805679321
Validation loss: 2.047432820002238

Epoch: 5| Step: 9
Training loss: 2.101156234741211
Validation loss: 2.064180617531141

Epoch: 5| Step: 10
Training loss: 2.2907233238220215
Validation loss: 2.0697940587997437

Epoch: 5| Step: 11
Training loss: 1.9876627922058105
Validation loss: 2.0707860440015793

Epoch: 175| Step: 0
Training loss: 1.9679571390151978
Validation loss: 2.0914294719696045

Epoch: 5| Step: 1
Training loss: 2.408754825592041
Validation loss: 2.100908617178599

Epoch: 5| Step: 2
Training loss: 2.3222482204437256
Validation loss: 2.1023588329553604

Epoch: 5| Step: 3
Training loss: 2.116698741912842
Validation loss: 2.126635402441025

Epoch: 5| Step: 4
Training loss: 2.096219062805176
Validation loss: 2.1323705315589905

Epoch: 5| Step: 5
Training loss: 2.1867053508758545
Validation loss: 2.120250036319097

Epoch: 5| Step: 6
Training loss: 1.6237220764160156
Validation loss: 2.1207978973786035

Epoch: 5| Step: 7
Training loss: 1.8107179403305054
Validation loss: 2.0997991363207498

Epoch: 5| Step: 8
Training loss: 1.6376978158950806
Validation loss: 2.0641232381264367

Epoch: 5| Step: 9
Training loss: 1.9574693441390991
Validation loss: 2.0670823951562247

Epoch: 5| Step: 10
Training loss: 2.0693061351776123
Validation loss: 2.0734919855992

Epoch: 5| Step: 11
Training loss: 2.6679625511169434
Validation loss: 2.0583177506923676

Epoch: 176| Step: 0
Training loss: 2.1112899780273438
Validation loss: 2.057429770628611

Epoch: 5| Step: 1
Training loss: 2.3182754516601562
Validation loss: 2.050557772318522

Epoch: 5| Step: 2
Training loss: 2.2251293659210205
Validation loss: 2.0561679800351462

Epoch: 5| Step: 3
Training loss: 1.8426551818847656
Validation loss: 2.0574138859907785

Epoch: 5| Step: 4
Training loss: 1.7355880737304688
Validation loss: 2.0481559137503305

Epoch: 5| Step: 5
Training loss: 1.7656641006469727
Validation loss: 2.0528343518575034

Epoch: 5| Step: 6
Training loss: 1.6101350784301758
Validation loss: 2.056407113869985

Epoch: 5| Step: 7
Training loss: 2.3613078594207764
Validation loss: 2.0670313239097595

Epoch: 5| Step: 8
Training loss: 2.1796317100524902
Validation loss: 2.0703708777825036

Epoch: 5| Step: 9
Training loss: 1.8768783807754517
Validation loss: 2.0739527444044747

Epoch: 5| Step: 10
Training loss: 2.237654685974121
Validation loss: 2.081960449616114

Epoch: 5| Step: 11
Training loss: 1.4726654291152954
Validation loss: 2.0804930329322815

Epoch: 177| Step: 0
Training loss: 1.2853337526321411
Validation loss: 2.086806903282801

Epoch: 5| Step: 1
Training loss: 2.186258316040039
Validation loss: 2.094230219721794

Epoch: 5| Step: 2
Training loss: 2.140345335006714
Validation loss: 2.1092872619628906

Epoch: 5| Step: 3
Training loss: 2.0791196823120117
Validation loss: 2.1112748086452484

Epoch: 5| Step: 4
Training loss: 1.768457055091858
Validation loss: 2.102884297569593

Epoch: 5| Step: 5
Training loss: 2.4874331951141357
Validation loss: 2.1019395689169564

Epoch: 5| Step: 6
Training loss: 1.9955021142959595
Validation loss: 2.1112954318523407

Epoch: 5| Step: 7
Training loss: 2.37221622467041
Validation loss: 2.1012442807356515

Epoch: 5| Step: 8
Training loss: 2.028409481048584
Validation loss: 2.0917722582817078

Epoch: 5| Step: 9
Training loss: 1.456920862197876
Validation loss: 2.097330411275228

Epoch: 5| Step: 10
Training loss: 2.1634185314178467
Validation loss: 2.08927683532238

Epoch: 5| Step: 11
Training loss: 3.055258274078369
Validation loss: 2.078021148840586

Epoch: 178| Step: 0
Training loss: 1.591054916381836
Validation loss: 2.062698389093081

Epoch: 5| Step: 1
Training loss: 2.0016543865203857
Validation loss: 2.063734153906504

Epoch: 5| Step: 2
Training loss: 2.31968355178833
Validation loss: 2.0589800079663596

Epoch: 5| Step: 3
Training loss: 2.0816729068756104
Validation loss: 2.062422772248586

Epoch: 5| Step: 4
Training loss: 1.9719622135162354
Validation loss: 2.0678958793481192

Epoch: 5| Step: 5
Training loss: 2.236485719680786
Validation loss: 2.054427906870842

Epoch: 5| Step: 6
Training loss: 2.1435112953186035
Validation loss: 2.0686945666869483

Epoch: 5| Step: 7
Training loss: 2.2909605503082275
Validation loss: 2.0684910217920938

Epoch: 5| Step: 8
Training loss: 1.7870614528656006
Validation loss: 2.0604839672644935

Epoch: 5| Step: 9
Training loss: 2.247926712036133
Validation loss: 2.0669141560792923

Epoch: 5| Step: 10
Training loss: 1.9060957431793213
Validation loss: 2.0721448759237924

Epoch: 5| Step: 11
Training loss: 3.0646591186523438
Validation loss: 2.0586429834365845

Epoch: 179| Step: 0
Training loss: 2.372903823852539
Validation loss: 2.06709415713946

Epoch: 5| Step: 1
Training loss: 2.104952573776245
Validation loss: 2.063676178455353

Epoch: 5| Step: 2
Training loss: 2.0374488830566406
Validation loss: 2.069535101453463

Epoch: 5| Step: 3
Training loss: 1.4954246282577515
Validation loss: 2.080615982413292

Epoch: 5| Step: 4
Training loss: 2.0394060611724854
Validation loss: 2.1089277962843576

Epoch: 5| Step: 5
Training loss: 1.8455612659454346
Validation loss: 2.1076725721359253

Epoch: 5| Step: 6
Training loss: 2.059718370437622
Validation loss: 2.1269264618555703

Epoch: 5| Step: 7
Training loss: 1.6869007349014282
Validation loss: 2.120952586332957

Epoch: 5| Step: 8
Training loss: 2.773073434829712
Validation loss: 2.1083597590525947

Epoch: 5| Step: 9
Training loss: 1.7214784622192383
Validation loss: 2.1004410088062286

Epoch: 5| Step: 10
Training loss: 1.9848442077636719
Validation loss: 2.093979373574257

Epoch: 5| Step: 11
Training loss: 2.9744887351989746
Validation loss: 2.0924279193083444

Epoch: 180| Step: 0
Training loss: 1.7060260772705078
Validation loss: 2.0826257169246674

Epoch: 5| Step: 1
Training loss: 2.3664157390594482
Validation loss: 2.0900610834360123

Epoch: 5| Step: 2
Training loss: 1.7362569570541382
Validation loss: 2.0753801812728248

Epoch: 5| Step: 3
Training loss: 1.756990671157837
Validation loss: 2.087054431438446

Epoch: 5| Step: 4
Training loss: 2.511369228363037
Validation loss: 2.0933389017979303

Epoch: 5| Step: 5
Training loss: 2.3670871257781982
Validation loss: 2.0841887295246124

Epoch: 5| Step: 6
Training loss: 1.1895831823349
Validation loss: 2.0821687132120132

Epoch: 5| Step: 7
Training loss: 2.064314365386963
Validation loss: 2.070903634031614

Epoch: 5| Step: 8
Training loss: 2.712526321411133
Validation loss: 2.0740787982940674

Epoch: 5| Step: 9
Training loss: 1.9402660131454468
Validation loss: 2.0757580399513245

Epoch: 5| Step: 10
Training loss: 1.8141300678253174
Validation loss: 2.0699812869230905

Epoch: 5| Step: 11
Training loss: 0.8000161647796631
Validation loss: 2.0708237091700235

Epoch: 181| Step: 0
Training loss: 2.1622700691223145
Validation loss: 2.0716391652822495

Epoch: 5| Step: 1
Training loss: 2.603022813796997
Validation loss: 2.079003324111303

Epoch: 5| Step: 2
Training loss: 1.6595245599746704
Validation loss: 2.0769045998652778

Epoch: 5| Step: 3
Training loss: 2.0295560359954834
Validation loss: 2.0895595103502274

Epoch: 5| Step: 4
Training loss: 2.1887218952178955
Validation loss: 2.0819265991449356

Epoch: 5| Step: 5
Training loss: 2.0986270904541016
Validation loss: 2.0871915072202682

Epoch: 5| Step: 6
Training loss: 1.9375696182250977
Validation loss: 2.097547098994255

Epoch: 5| Step: 7
Training loss: 2.046229600906372
Validation loss: 2.108624001344045

Epoch: 5| Step: 8
Training loss: 1.5174180269241333
Validation loss: 2.1158238699038825

Epoch: 5| Step: 9
Training loss: 1.8274281024932861
Validation loss: 2.124912033478419

Epoch: 5| Step: 10
Training loss: 2.2543160915374756
Validation loss: 2.115842660268148

Epoch: 5| Step: 11
Training loss: 2.3315846920013428
Validation loss: 2.0811890910069146

Epoch: 182| Step: 0
Training loss: 1.8967012166976929
Validation loss: 2.0831419974565506

Epoch: 5| Step: 1
Training loss: 1.9858763217926025
Validation loss: 2.0751023838917413

Epoch: 5| Step: 2
Training loss: 2.0409095287323
Validation loss: 2.0660576770702996

Epoch: 5| Step: 3
Training loss: 1.5826914310455322
Validation loss: 2.060273438692093

Epoch: 5| Step: 4
Training loss: 1.9472182989120483
Validation loss: 2.066775252421697

Epoch: 5| Step: 5
Training loss: 2.683739423751831
Validation loss: 2.067994033296903

Epoch: 5| Step: 6
Training loss: 2.7199902534484863
Validation loss: 2.067510495583216

Epoch: 5| Step: 7
Training loss: 2.387420177459717
Validation loss: 2.0706203430891037

Epoch: 5| Step: 8
Training loss: 1.8252544403076172
Validation loss: 2.0576269924640656

Epoch: 5| Step: 9
Training loss: 2.35451078414917
Validation loss: 2.0649763544400535

Epoch: 5| Step: 10
Training loss: 1.5032261610031128
Validation loss: 2.0642563551664352

Epoch: 5| Step: 11
Training loss: 2.035670518875122
Validation loss: 2.0587878922621408

Epoch: 183| Step: 0
Training loss: 2.1433072090148926
Validation loss: 2.0638767878214517

Epoch: 5| Step: 1
Training loss: 2.211519718170166
Validation loss: 2.0677908857663474

Epoch: 5| Step: 2
Training loss: 2.682163715362549
Validation loss: 2.0541704098383584

Epoch: 5| Step: 3
Training loss: 2.502857208251953
Validation loss: 2.0695757418870926

Epoch: 5| Step: 4
Training loss: 1.7919937372207642
Validation loss: 2.0622063875198364

Epoch: 5| Step: 5
Training loss: 2.4457485675811768
Validation loss: 2.0627049803733826

Epoch: 5| Step: 6
Training loss: 1.6581342220306396
Validation loss: 2.0689240396022797

Epoch: 5| Step: 7
Training loss: 2.207503080368042
Validation loss: 2.0609144220749536

Epoch: 5| Step: 8
Training loss: 2.2714271545410156
Validation loss: 2.062442203362783

Epoch: 5| Step: 9
Training loss: 1.2308741807937622
Validation loss: 2.054571747779846

Epoch: 5| Step: 10
Training loss: 1.5149213075637817
Validation loss: 2.05487097799778

Epoch: 5| Step: 11
Training loss: 2.8377604484558105
Validation loss: 2.064477930466334

Epoch: 184| Step: 0
Training loss: 1.869667410850525
Validation loss: 2.0527894298235574

Epoch: 5| Step: 1
Training loss: 2.1326491832733154
Validation loss: 2.0585948675870895

Epoch: 5| Step: 2
Training loss: 2.2222588062286377
Validation loss: 2.0676810493071875

Epoch: 5| Step: 3
Training loss: 1.6266368627548218
Validation loss: 2.080103943745295

Epoch: 5| Step: 4
Training loss: 1.7838256359100342
Validation loss: 2.0814253191153207

Epoch: 5| Step: 5
Training loss: 2.220554828643799
Validation loss: 2.0844551821549735

Epoch: 5| Step: 6
Training loss: 2.447878360748291
Validation loss: 2.084719479084015

Epoch: 5| Step: 7
Training loss: 1.556328296661377
Validation loss: 2.0823421676953635

Epoch: 5| Step: 8
Training loss: 2.2465336322784424
Validation loss: 2.0942049523194632

Epoch: 5| Step: 9
Training loss: 2.2717442512512207
Validation loss: 2.065608208378156

Epoch: 5| Step: 10
Training loss: 2.3937034606933594
Validation loss: 2.080634266138077

Epoch: 5| Step: 11
Training loss: 2.612039089202881
Validation loss: 2.077411691347758

Epoch: 185| Step: 0
Training loss: 1.9995838403701782
Validation loss: 2.082130253314972

Epoch: 5| Step: 1
Training loss: 2.144256591796875
Validation loss: 2.0850185801585517

Epoch: 5| Step: 2
Training loss: 1.6948881149291992
Validation loss: 2.0649114002784095

Epoch: 5| Step: 3
Training loss: 2.0561137199401855
Validation loss: 2.0649071435133615

Epoch: 5| Step: 4
Training loss: 1.9811617136001587
Validation loss: 2.05996465186278

Epoch: 5| Step: 5
Training loss: 2.0928955078125
Validation loss: 2.0681903262933097

Epoch: 5| Step: 6
Training loss: 2.4391744136810303
Validation loss: 2.0655639618635178

Epoch: 5| Step: 7
Training loss: 1.969268560409546
Validation loss: 2.0708431800206504

Epoch: 5| Step: 8
Training loss: 1.7999929189682007
Validation loss: 2.0642834504445395

Epoch: 5| Step: 9
Training loss: 2.3928682804107666
Validation loss: 2.063807507356008

Epoch: 5| Step: 10
Training loss: 1.8237167596817017
Validation loss: 2.0713993509610495

Epoch: 5| Step: 11
Training loss: 1.0613113641738892
Validation loss: 2.063255031903585

Epoch: 186| Step: 0
Training loss: 2.158210277557373
Validation loss: 2.071798841158549

Epoch: 5| Step: 1
Training loss: 2.0360193252563477
Validation loss: 2.0746988405783973

Epoch: 5| Step: 2
Training loss: 2.0853209495544434
Validation loss: 2.079294428229332

Epoch: 5| Step: 3
Training loss: 1.9805481433868408
Validation loss: 2.076487968365351

Epoch: 5| Step: 4
Training loss: 1.848522424697876
Validation loss: 2.0802798916896186

Epoch: 5| Step: 5
Training loss: 1.6706291437149048
Validation loss: 2.080674191315969

Epoch: 5| Step: 6
Training loss: 1.6874405145645142
Validation loss: 2.0860597689946494

Epoch: 5| Step: 7
Training loss: 2.446936845779419
Validation loss: 2.090552488962809

Epoch: 5| Step: 8
Training loss: 2.0168137550354004
Validation loss: 2.074215888977051

Epoch: 5| Step: 9
Training loss: 1.934505820274353
Validation loss: 2.0776804834604263

Epoch: 5| Step: 10
Training loss: 2.2063469886779785
Validation loss: 2.0725844701131186

Epoch: 5| Step: 11
Training loss: 1.8010380268096924
Validation loss: 2.075144042571386

Epoch: 187| Step: 0
Training loss: 1.939662218093872
Validation loss: 2.0704324692487717

Epoch: 5| Step: 1
Training loss: 2.227473497390747
Validation loss: 2.082574943701426

Epoch: 5| Step: 2
Training loss: 2.1778311729431152
Validation loss: 2.0833810716867447

Epoch: 5| Step: 3
Training loss: 1.79495370388031
Validation loss: 2.0791947692632675

Epoch: 5| Step: 4
Training loss: 1.9165655374526978
Validation loss: 2.068833738565445

Epoch: 5| Step: 5
Training loss: 2.1494717597961426
Validation loss: 2.0719243784745536

Epoch: 5| Step: 6
Training loss: 2.1105904579162598
Validation loss: 2.072230488061905

Epoch: 5| Step: 7
Training loss: 1.673596739768982
Validation loss: 2.0684183686971664

Epoch: 5| Step: 8
Training loss: 2.3078365325927734
Validation loss: 2.0786807934443154

Epoch: 5| Step: 9
Training loss: 1.8558826446533203
Validation loss: 2.0910926908254623

Epoch: 5| Step: 10
Training loss: 1.9073963165283203
Validation loss: 2.0934899350007377

Epoch: 5| Step: 11
Training loss: 1.1640856266021729
Validation loss: 2.110516677300135

Epoch: 188| Step: 0
Training loss: 1.7129161357879639
Validation loss: 2.1295692970355353

Epoch: 5| Step: 1
Training loss: 1.8740513324737549
Validation loss: 2.1366263230641684

Epoch: 5| Step: 2
Training loss: 1.6945469379425049
Validation loss: 2.1411445091168084

Epoch: 5| Step: 3
Training loss: 2.5562543869018555
Validation loss: 2.1288125862677894

Epoch: 5| Step: 4
Training loss: 1.7806422710418701
Validation loss: 2.1317782253026962

Epoch: 5| Step: 5
Training loss: 2.431490659713745
Validation loss: 2.1247776796420417

Epoch: 5| Step: 6
Training loss: 2.1019768714904785
Validation loss: 2.1058612863222756

Epoch: 5| Step: 7
Training loss: 2.0103700160980225
Validation loss: 2.101939380168915

Epoch: 5| Step: 8
Training loss: 1.7926965951919556
Validation loss: 2.0850106676419577

Epoch: 5| Step: 9
Training loss: 2.31402325630188
Validation loss: 2.0690928449233374

Epoch: 5| Step: 10
Training loss: 1.801177740097046
Validation loss: 2.078550154964129

Epoch: 5| Step: 11
Training loss: 2.1492743492126465
Validation loss: 2.0695238361756005

Epoch: 189| Step: 0
Training loss: 1.6274200677871704
Validation loss: 2.07342599829038

Epoch: 5| Step: 1
Training loss: 1.9234631061553955
Validation loss: 2.069175432125727

Epoch: 5| Step: 2
Training loss: 2.151729106903076
Validation loss: 2.0775823394457498

Epoch: 5| Step: 3
Training loss: 2.2760345935821533
Validation loss: 2.079203277826309

Epoch: 5| Step: 4
Training loss: 1.7865116596221924
Validation loss: 2.0744081487258277

Epoch: 5| Step: 5
Training loss: 1.9333229064941406
Validation loss: 2.078881377975146

Epoch: 5| Step: 6
Training loss: 1.9127776622772217
Validation loss: 2.0884771992762885

Epoch: 5| Step: 7
Training loss: 2.213197946548462
Validation loss: 2.083126947283745

Epoch: 5| Step: 8
Training loss: 2.2765839099884033
Validation loss: 2.084697350859642

Epoch: 5| Step: 9
Training loss: 1.850996971130371
Validation loss: 2.0751969814300537

Epoch: 5| Step: 10
Training loss: 2.0455410480499268
Validation loss: 2.0758041739463806

Epoch: 5| Step: 11
Training loss: 1.1588371992111206
Validation loss: 2.090745896100998

Epoch: 190| Step: 0
Training loss: 2.53544282913208
Validation loss: 2.10315103828907

Epoch: 5| Step: 1
Training loss: 1.6577945947647095
Validation loss: 2.08508508404096

Epoch: 5| Step: 2
Training loss: 1.989179253578186
Validation loss: 2.0782223492860794

Epoch: 5| Step: 3
Training loss: 1.4340702295303345
Validation loss: 2.0946291337410607

Epoch: 5| Step: 4
Training loss: 1.7530765533447266
Validation loss: 2.096296007434527

Epoch: 5| Step: 5
Training loss: 1.7207609415054321
Validation loss: 2.0957548369963965

Epoch: 5| Step: 6
Training loss: 1.9711272716522217
Validation loss: 2.0908895432949066

Epoch: 5| Step: 7
Training loss: 1.6885063648223877
Validation loss: 2.07797472178936

Epoch: 5| Step: 8
Training loss: 2.0966665744781494
Validation loss: 2.0936793933312097

Epoch: 5| Step: 9
Training loss: 2.602057933807373
Validation loss: 2.0851178417603173

Epoch: 5| Step: 10
Training loss: 1.9920848608016968
Validation loss: 2.0830087860425315

Epoch: 5| Step: 11
Training loss: 3.3750901222229004
Validation loss: 2.0770264913638434

Epoch: 191| Step: 0
Training loss: 2.204439640045166
Validation loss: 2.0763744910558066

Epoch: 5| Step: 1
Training loss: 2.2116525173187256
Validation loss: 2.081969733039538

Epoch: 5| Step: 2
Training loss: 1.9828245639801025
Validation loss: 2.073041891058286

Epoch: 5| Step: 3
Training loss: 1.9708623886108398
Validation loss: 2.0731001744667688

Epoch: 5| Step: 4
Training loss: 2.0208487510681152
Validation loss: 2.0685658007860184

Epoch: 5| Step: 5
Training loss: 2.376767158508301
Validation loss: 2.0799318651358285

Epoch: 5| Step: 6
Training loss: 2.3659720420837402
Validation loss: 2.074093113342921

Epoch: 5| Step: 7
Training loss: 1.8458350896835327
Validation loss: 2.0760634938875833

Epoch: 5| Step: 8
Training loss: 1.9709413051605225
Validation loss: 2.0774425119161606

Epoch: 5| Step: 9
Training loss: 1.7800925970077515
Validation loss: 2.0678893824418387

Epoch: 5| Step: 10
Training loss: 1.2824671268463135
Validation loss: 2.0818902601798377

Epoch: 5| Step: 11
Training loss: 1.1892845630645752
Validation loss: 2.079942653576533

Epoch: 192| Step: 0
Training loss: 1.804160714149475
Validation loss: 2.091789409518242

Epoch: 5| Step: 1
Training loss: 1.7015924453735352
Validation loss: 2.1073475728432336

Epoch: 5| Step: 2
Training loss: 1.6658637523651123
Validation loss: 2.111911197503408

Epoch: 5| Step: 3
Training loss: 1.9268547296524048
Validation loss: 2.1027884036302567

Epoch: 5| Step: 4
Training loss: 2.5676965713500977
Validation loss: 2.105820745229721

Epoch: 5| Step: 5
Training loss: 2.1973390579223633
Validation loss: 2.107294743259748

Epoch: 5| Step: 6
Training loss: 2.667473077774048
Validation loss: 2.084169993797938

Epoch: 5| Step: 7
Training loss: 1.3234350681304932
Validation loss: 2.064496566851934

Epoch: 5| Step: 8
Training loss: 1.5561840534210205
Validation loss: 2.082999820510546

Epoch: 5| Step: 9
Training loss: 2.060194969177246
Validation loss: 2.0877221524715424

Epoch: 5| Step: 10
Training loss: 2.3318731784820557
Validation loss: 2.079155743122101

Epoch: 5| Step: 11
Training loss: 1.7250046730041504
Validation loss: 2.076924522717794

Epoch: 193| Step: 0
Training loss: 1.8397929668426514
Validation loss: 2.0829507062832513

Epoch: 5| Step: 1
Training loss: 2.257350206375122
Validation loss: 2.081921180089315

Epoch: 5| Step: 2
Training loss: 1.3962445259094238
Validation loss: 2.0822432537873587

Epoch: 5| Step: 3
Training loss: 2.0838522911071777
Validation loss: 2.0754769096771875

Epoch: 5| Step: 4
Training loss: 2.0752158164978027
Validation loss: 2.0734963367382684

Epoch: 5| Step: 5
Training loss: 2.230180263519287
Validation loss: 2.079956606030464

Epoch: 5| Step: 6
Training loss: 2.324256420135498
Validation loss: 2.07868999739488

Epoch: 5| Step: 7
Training loss: 2.0537800788879395
Validation loss: 2.079288880030314

Epoch: 5| Step: 8
Training loss: 2.1128153800964355
Validation loss: 2.0745461930831275

Epoch: 5| Step: 9
Training loss: 1.897504448890686
Validation loss: 2.080970197916031

Epoch: 5| Step: 10
Training loss: 1.4306482076644897
Validation loss: 2.08300344645977

Epoch: 5| Step: 11
Training loss: 1.4726003408432007
Validation loss: 2.071930711468061

Epoch: 194| Step: 0
Training loss: 2.2930405139923096
Validation loss: 2.0973775883515677

Epoch: 5| Step: 1
Training loss: 2.2259457111358643
Validation loss: 2.0928453703721366

Epoch: 5| Step: 2
Training loss: 2.0369763374328613
Validation loss: 2.1090794006983438

Epoch: 5| Step: 3
Training loss: 2.147063732147217
Validation loss: 2.109903876980146

Epoch: 5| Step: 4
Training loss: 2.4109950065612793
Validation loss: 2.1051714619000754

Epoch: 5| Step: 5
Training loss: 2.1603119373321533
Validation loss: 2.102547918756803

Epoch: 5| Step: 6
Training loss: 1.617868423461914
Validation loss: 2.093320364753405

Epoch: 5| Step: 7
Training loss: 1.7447456121444702
Validation loss: 2.094943642616272

Epoch: 5| Step: 8
Training loss: 1.725879430770874
Validation loss: 2.0749902923901877

Epoch: 5| Step: 9
Training loss: 1.7458984851837158
Validation loss: 2.077475885550181

Epoch: 5| Step: 10
Training loss: 1.979095458984375
Validation loss: 2.0774759401877723

Epoch: 5| Step: 11
Training loss: 1.7542665004730225
Validation loss: 2.06586646536986

Epoch: 195| Step: 0
Training loss: 1.4558168649673462
Validation loss: 2.0728184282779694

Epoch: 5| Step: 1
Training loss: 2.074620246887207
Validation loss: 2.07315323750178

Epoch: 5| Step: 2
Training loss: 2.101330280303955
Validation loss: 2.080932984749476

Epoch: 5| Step: 3
Training loss: 1.7049283981323242
Validation loss: 2.063218648235003

Epoch: 5| Step: 4
Training loss: 1.8068063259124756
Validation loss: 2.07260529200236

Epoch: 5| Step: 5
Training loss: 2.254577398300171
Validation loss: 2.0663342426220574

Epoch: 5| Step: 6
Training loss: 2.1927878856658936
Validation loss: 2.0726967255274453

Epoch: 5| Step: 7
Training loss: 1.9226856231689453
Validation loss: 2.0672583927710853

Epoch: 5| Step: 8
Training loss: 3.136183261871338
Validation loss: 2.072715232769648

Epoch: 5| Step: 9
Training loss: 1.8726059198379517
Validation loss: 2.0746800949176154

Epoch: 5| Step: 10
Training loss: 1.7094453573226929
Validation loss: 2.077878291408221

Epoch: 5| Step: 11
Training loss: 1.4417533874511719
Validation loss: 2.0857196201880774

Epoch: 196| Step: 0
Training loss: 1.6947402954101562
Validation loss: 2.085216080149015

Epoch: 5| Step: 1
Training loss: 2.142918825149536
Validation loss: 2.098509887854258

Epoch: 5| Step: 2
Training loss: 2.4984230995178223
Validation loss: 2.103948583205541

Epoch: 5| Step: 3
Training loss: 2.0431630611419678
Validation loss: 2.1127726236979165

Epoch: 5| Step: 4
Training loss: 1.836832046508789
Validation loss: 2.1076749861240387

Epoch: 5| Step: 5
Training loss: 2.1063179969787598
Validation loss: 2.1207228203614554

Epoch: 5| Step: 6
Training loss: 1.7247428894042969
Validation loss: 2.1267387717962265

Epoch: 5| Step: 7
Training loss: 1.342182993888855
Validation loss: 2.1063082814216614

Epoch: 5| Step: 8
Training loss: 2.480445384979248
Validation loss: 2.108955735961596

Epoch: 5| Step: 9
Training loss: 2.3576860427856445
Validation loss: 2.097995176911354

Epoch: 5| Step: 10
Training loss: 2.1007778644561768
Validation loss: 2.0863647212584815

Epoch: 5| Step: 11
Training loss: 2.2019333839416504
Validation loss: 2.089336852232615

Epoch: 197| Step: 0
Training loss: 2.152491807937622
Validation loss: 2.074217369159063

Epoch: 5| Step: 1
Training loss: 1.9256671667099
Validation loss: 2.0884645183881125

Epoch: 5| Step: 2
Training loss: 2.0072293281555176
Validation loss: 2.0939428905646005

Epoch: 5| Step: 3
Training loss: 1.538262963294983
Validation loss: 2.087195118268331

Epoch: 5| Step: 4
Training loss: 2.542325258255005
Validation loss: 2.0843497961759567

Epoch: 5| Step: 5
Training loss: 1.9803838729858398
Validation loss: 2.1205593844254813

Epoch: 5| Step: 6
Training loss: 1.640024185180664
Validation loss: 2.107416495680809

Epoch: 5| Step: 7
Training loss: 1.7024571895599365
Validation loss: 2.1193774243195853

Epoch: 5| Step: 8
Training loss: 2.4219961166381836
Validation loss: 2.133365198969841

Epoch: 5| Step: 9
Training loss: 1.9830787181854248
Validation loss: 2.1258950730164847

Epoch: 5| Step: 10
Training loss: 1.852399468421936
Validation loss: 2.125661477446556

Epoch: 5| Step: 11
Training loss: 2.4760093688964844
Validation loss: 2.1210469007492065

Epoch: 198| Step: 0
Training loss: 1.19938063621521
Validation loss: 2.1146733462810516

Epoch: 5| Step: 1
Training loss: 1.4939898252487183
Validation loss: 2.1082693934440613

Epoch: 5| Step: 2
Training loss: 2.702873706817627
Validation loss: 2.088079189260801

Epoch: 5| Step: 3
Training loss: 1.8217204809188843
Validation loss: 2.0808525880177817

Epoch: 5| Step: 4
Training loss: 1.5347280502319336
Validation loss: 2.0830277651548386

Epoch: 5| Step: 5
Training loss: 2.4570107460021973
Validation loss: 2.0933315406243005

Epoch: 5| Step: 6
Training loss: 1.9929771423339844
Validation loss: 2.090224494536718

Epoch: 5| Step: 7
Training loss: 1.9859111309051514
Validation loss: 2.084184467792511

Epoch: 5| Step: 8
Training loss: 2.1026861667633057
Validation loss: 2.098766033848127

Epoch: 5| Step: 9
Training loss: 1.9810549020767212
Validation loss: 2.079358478387197

Epoch: 5| Step: 10
Training loss: 2.3916211128234863
Validation loss: 2.0997706949710846

Epoch: 5| Step: 11
Training loss: 2.2201855182647705
Validation loss: 2.0951871822277703

Epoch: 199| Step: 0
Training loss: 1.7127625942230225
Validation loss: 2.095735435684522

Epoch: 5| Step: 1
Training loss: 2.150778293609619
Validation loss: 2.097062513232231

Epoch: 5| Step: 2
Training loss: 2.185863733291626
Validation loss: 2.0997208754221597

Epoch: 5| Step: 3
Training loss: 2.1638684272766113
Validation loss: 2.0925000309944153

Epoch: 5| Step: 4
Training loss: 2.0433876514434814
Validation loss: 2.089501624306043

Epoch: 5| Step: 5
Training loss: 1.9944852590560913
Validation loss: 2.0994662940502167

Epoch: 5| Step: 6
Training loss: 1.3223507404327393
Validation loss: 2.0994718869527182

Epoch: 5| Step: 7
Training loss: 2.244361400604248
Validation loss: 2.1050207068522773

Epoch: 5| Step: 8
Training loss: 1.8234920501708984
Validation loss: 2.093557447195053

Epoch: 5| Step: 9
Training loss: 2.092777967453003
Validation loss: 2.1147450506687164

Epoch: 5| Step: 10
Training loss: 2.018589496612549
Validation loss: 2.0954692165056863

Epoch: 5| Step: 11
Training loss: 1.145652174949646
Validation loss: 2.099337865908941

Epoch: 200| Step: 0
Training loss: 1.909436583518982
Validation loss: 2.0985607306162515

Epoch: 5| Step: 1
Training loss: 2.151904821395874
Validation loss: 2.1010357240835824

Epoch: 5| Step: 2
Training loss: 1.9434680938720703
Validation loss: 2.102935492992401

Epoch: 5| Step: 3
Training loss: 1.9279817342758179
Validation loss: 2.0985151330629983

Epoch: 5| Step: 4
Training loss: 1.869787573814392
Validation loss: 2.0910720775524774

Epoch: 5| Step: 5
Training loss: 1.5054985284805298
Validation loss: 2.0938817461331687

Epoch: 5| Step: 6
Training loss: 2.0676980018615723
Validation loss: 2.093923697868983

Epoch: 5| Step: 7
Training loss: 2.340197801589966
Validation loss: 2.1127049922943115

Epoch: 5| Step: 8
Training loss: 1.6191661357879639
Validation loss: 2.1206479916969934

Epoch: 5| Step: 9
Training loss: 2.0148353576660156
Validation loss: 2.123483548561732

Epoch: 5| Step: 10
Training loss: 2.3636112213134766
Validation loss: 2.1136128306388855

Epoch: 5| Step: 11
Training loss: 1.5946733951568604
Validation loss: 2.103090504805247

Epoch: 201| Step: 0
Training loss: 2.334967851638794
Validation loss: 2.0911066631476083

Epoch: 5| Step: 1
Training loss: 2.007371187210083
Validation loss: 2.095567802588145

Epoch: 5| Step: 2
Training loss: 1.4016320705413818
Validation loss: 2.0779310961564383

Epoch: 5| Step: 3
Training loss: 2.514486789703369
Validation loss: 2.0738665709892907

Epoch: 5| Step: 4
Training loss: 2.0288288593292236
Validation loss: 2.0645951330661774

Epoch: 5| Step: 5
Training loss: 2.5433950424194336
Validation loss: 2.064290940761566

Epoch: 5| Step: 6
Training loss: 2.056331157684326
Validation loss: 2.079263692100843

Epoch: 5| Step: 7
Training loss: 2.290449857711792
Validation loss: 2.0630664924780526

Epoch: 5| Step: 8
Training loss: 2.364772319793701
Validation loss: 2.072095349431038

Epoch: 5| Step: 9
Training loss: 2.106980085372925
Validation loss: 2.0755446553230286

Epoch: 5| Step: 10
Training loss: 1.5275604724884033
Validation loss: 2.0682745575904846

Epoch: 5| Step: 11
Training loss: 0.8924908638000488
Validation loss: 2.087105840444565

Epoch: 202| Step: 0
Training loss: 2.065375804901123
Validation loss: 2.084915136297544

Epoch: 5| Step: 1
Training loss: 2.0255987644195557
Validation loss: 2.0805775821208954

Epoch: 5| Step: 2
Training loss: 1.7692463397979736
Validation loss: 2.086749573548635

Epoch: 5| Step: 3
Training loss: 1.9165706634521484
Validation loss: 2.088210314512253

Epoch: 5| Step: 4
Training loss: 1.946010947227478
Validation loss: 2.0575990627209344

Epoch: 5| Step: 5
Training loss: 2.472513437271118
Validation loss: 2.091800813873609

Epoch: 5| Step: 6
Training loss: 1.8861488103866577
Validation loss: 2.084569518764814

Epoch: 5| Step: 7
Training loss: 2.2581236362457275
Validation loss: 2.0809120684862137

Epoch: 5| Step: 8
Training loss: 2.116219997406006
Validation loss: 2.106864114602407

Epoch: 5| Step: 9
Training loss: 1.8856397867202759
Validation loss: 2.1003802865743637

Epoch: 5| Step: 10
Training loss: 1.8006417751312256
Validation loss: 2.108068640033404

Epoch: 5| Step: 11
Training loss: 2.8529105186462402
Validation loss: 2.093523914615313

Epoch: 203| Step: 0
Training loss: 1.2352654933929443
Validation loss: 2.08909339706103

Epoch: 5| Step: 1
Training loss: 2.6664016246795654
Validation loss: 2.09339206914107

Epoch: 5| Step: 2
Training loss: 1.9259202480316162
Validation loss: 2.081452334920565

Epoch: 5| Step: 3
Training loss: 2.011336088180542
Validation loss: 2.086282958587011

Epoch: 5| Step: 4
Training loss: 1.9499918222427368
Validation loss: 2.09504234790802

Epoch: 5| Step: 5
Training loss: 1.9288547039031982
Validation loss: 2.078426649173101

Epoch: 5| Step: 6
Training loss: 1.7565730810165405
Validation loss: 2.0752874662478766

Epoch: 5| Step: 7
Training loss: 1.5023555755615234
Validation loss: 2.070920377969742

Epoch: 5| Step: 8
Training loss: 1.872930884361267
Validation loss: 2.0751319924990335

Epoch: 5| Step: 9
Training loss: 2.4640040397644043
Validation loss: 2.0810523678859076

Epoch: 5| Step: 10
Training loss: 2.0866012573242188
Validation loss: 2.0651428600152335

Epoch: 5| Step: 11
Training loss: 3.6428442001342773
Validation loss: 2.0744223992029824

Epoch: 204| Step: 0
Training loss: 1.7842117547988892
Validation loss: 2.0810137887795768

Epoch: 5| Step: 1
Training loss: 2.336272954940796
Validation loss: 2.0938617636760077

Epoch: 5| Step: 2
Training loss: 1.4850397109985352
Validation loss: 2.0832727501789727

Epoch: 5| Step: 3
Training loss: 1.8037402629852295
Validation loss: 2.076185405254364

Epoch: 5| Step: 4
Training loss: 1.665013074874878
Validation loss: 2.0864383429288864

Epoch: 5| Step: 5
Training loss: 2.02724027633667
Validation loss: 2.0777723838885627

Epoch: 5| Step: 6
Training loss: 2.115025043487549
Validation loss: 2.0703241328398385

Epoch: 5| Step: 7
Training loss: 2.254706859588623
Validation loss: 2.0988306552171707

Epoch: 5| Step: 8
Training loss: 2.2836391925811768
Validation loss: 2.071129704515139

Epoch: 5| Step: 9
Training loss: 1.5036356449127197
Validation loss: 2.0730478117863336

Epoch: 5| Step: 10
Training loss: 2.395594358444214
Validation loss: 2.0682559510072074

Epoch: 5| Step: 11
Training loss: 2.4491090774536133
Validation loss: 2.0884313384691873

Epoch: 205| Step: 0
Training loss: 1.6788108348846436
Validation loss: 2.0897460132837296

Epoch: 5| Step: 1
Training loss: 2.56767201423645
Validation loss: 2.0909860680500665

Epoch: 5| Step: 2
Training loss: 1.7706890106201172
Validation loss: 2.0888252556324005

Epoch: 5| Step: 3
Training loss: 2.004434585571289
Validation loss: 2.0827231258153915

Epoch: 5| Step: 4
Training loss: 1.6358343362808228
Validation loss: 2.0814043084780374

Epoch: 5| Step: 5
Training loss: 2.055077314376831
Validation loss: 2.0952559212843576

Epoch: 5| Step: 6
Training loss: 1.523958683013916
Validation loss: 2.0884518772363663

Epoch: 5| Step: 7
Training loss: 1.7039682865142822
Validation loss: 2.089470903078715

Epoch: 5| Step: 8
Training loss: 2.510603666305542
Validation loss: 2.0817892650763192

Epoch: 5| Step: 9
Training loss: 2.019432544708252
Validation loss: 2.095491295059522

Epoch: 5| Step: 10
Training loss: 1.6368061304092407
Validation loss: 2.082921579480171

Epoch: 5| Step: 11
Training loss: 3.594061851501465
Validation loss: 2.092728445927302

Epoch: 206| Step: 0
Training loss: 1.7875499725341797
Validation loss: 2.101471334695816

Epoch: 5| Step: 1
Training loss: 1.9183934926986694
Validation loss: 2.1062377591927848

Epoch: 5| Step: 2
Training loss: 2.2826473712921143
Validation loss: 2.1030463874340057

Epoch: 5| Step: 3
Training loss: 2.002720594406128
Validation loss: 2.102161784966787

Epoch: 5| Step: 4
Training loss: 1.4448328018188477
Validation loss: 2.1129399041334787

Epoch: 5| Step: 5
Training loss: 1.9049060344696045
Validation loss: 2.1138924012581506

Epoch: 5| Step: 6
Training loss: 1.6716934442520142
Validation loss: 2.1170353988806405

Epoch: 5| Step: 7
Training loss: 1.9104015827178955
Validation loss: 2.111369381348292

Epoch: 5| Step: 8
Training loss: 2.4308063983917236
Validation loss: 2.0969198644161224

Epoch: 5| Step: 9
Training loss: 1.982141137123108
Validation loss: 2.10272970298926

Epoch: 5| Step: 10
Training loss: 2.034247636795044
Validation loss: 2.0878467659155526

Epoch: 5| Step: 11
Training loss: 2.137734889984131
Validation loss: 2.090968737999598

Epoch: 207| Step: 0
Training loss: 2.3307385444641113
Validation loss: 2.0855067670345306

Epoch: 5| Step: 1
Training loss: 1.9155676364898682
Validation loss: 2.0977476239204407

Epoch: 5| Step: 2
Training loss: 1.7405000925064087
Validation loss: 2.092634325226148

Epoch: 5| Step: 3
Training loss: 1.853467583656311
Validation loss: 2.0949625869592032

Epoch: 5| Step: 4
Training loss: 1.6560804843902588
Validation loss: 2.0988238950570426

Epoch: 5| Step: 5
Training loss: 1.995599389076233
Validation loss: 2.1046187579631805

Epoch: 5| Step: 6
Training loss: 1.912899374961853
Validation loss: 2.0910607179005942

Epoch: 5| Step: 7
Training loss: 1.8958899974822998
Validation loss: 2.097492208083471

Epoch: 5| Step: 8
Training loss: 1.434704065322876
Validation loss: 2.102929577231407

Epoch: 5| Step: 9
Training loss: 2.038475751876831
Validation loss: 2.1216197411219277

Epoch: 5| Step: 10
Training loss: 2.399552583694458
Validation loss: 2.123124529918035

Epoch: 5| Step: 11
Training loss: 2.0448808670043945
Validation loss: 2.1305445382992425

Epoch: 208| Step: 0
Training loss: 1.7060941457748413
Validation loss: 2.1464134951432547

Epoch: 5| Step: 1
Training loss: 2.2379207611083984
Validation loss: 2.143989016612371

Epoch: 5| Step: 2
Training loss: 1.967241644859314
Validation loss: 2.1282238165537515

Epoch: 5| Step: 3
Training loss: 2.2109553813934326
Validation loss: 2.132271945476532

Epoch: 5| Step: 4
Training loss: 1.976218819618225
Validation loss: 2.1106363783280053

Epoch: 5| Step: 5
Training loss: 2.2269020080566406
Validation loss: 2.1097632398207984

Epoch: 5| Step: 6
Training loss: 1.8653974533081055
Validation loss: 2.1050333877404532

Epoch: 5| Step: 7
Training loss: 1.6160141229629517
Validation loss: 2.0900985300540924

Epoch: 5| Step: 8
Training loss: 1.9790350198745728
Validation loss: 2.0865295877059302

Epoch: 5| Step: 9
Training loss: 2.178616762161255
Validation loss: 2.094765692949295

Epoch: 5| Step: 10
Training loss: 1.7036008834838867
Validation loss: 2.1075343439976373

Epoch: 5| Step: 11
Training loss: 1.3099569082260132
Validation loss: 2.108079100648562

Epoch: 209| Step: 0
Training loss: 1.6819570064544678
Validation loss: 2.0904502322276435

Epoch: 5| Step: 1
Training loss: 2.692178249359131
Validation loss: 2.1156176775693893

Epoch: 5| Step: 2
Training loss: 1.912553071975708
Validation loss: 2.0835734953482947

Epoch: 5| Step: 3
Training loss: 1.653888463973999
Validation loss: 2.1014539301395416

Epoch: 5| Step: 4
Training loss: 1.5332121849060059
Validation loss: 2.0886029104391732

Epoch: 5| Step: 5
Training loss: 2.044808864593506
Validation loss: 2.1025403936704

Epoch: 5| Step: 6
Training loss: 2.189718723297119
Validation loss: 2.098634531100591

Epoch: 5| Step: 7
Training loss: 1.9243783950805664
Validation loss: 2.111899087826411

Epoch: 5| Step: 8
Training loss: 1.5409389734268188
Validation loss: 2.0916461596886315

Epoch: 5| Step: 9
Training loss: 2.268803358078003
Validation loss: 2.1029950280984244

Epoch: 5| Step: 10
Training loss: 1.8237966299057007
Validation loss: 2.1006086518367133

Epoch: 5| Step: 11
Training loss: 2.09340500831604
Validation loss: 2.09235110382239

Epoch: 210| Step: 0
Training loss: 2.4898414611816406
Validation loss: 2.107490047812462

Epoch: 5| Step: 1
Training loss: 1.5209661722183228
Validation loss: 2.1141982277234397

Epoch: 5| Step: 2
Training loss: 1.557155728340149
Validation loss: 2.117840071519216

Epoch: 5| Step: 3
Training loss: 2.1765244007110596
Validation loss: 2.1407705595095954

Epoch: 5| Step: 4
Training loss: 2.325530529022217
Validation loss: 2.1167014439900718

Epoch: 5| Step: 5
Training loss: 1.2479051351547241
Validation loss: 2.1253653516372046

Epoch: 5| Step: 6
Training loss: 2.1015124320983887
Validation loss: 2.122882599631945

Epoch: 5| Step: 7
Training loss: 2.1022465229034424
Validation loss: 2.105418140689532

Epoch: 5| Step: 8
Training loss: 1.508545160293579
Validation loss: 2.1122311105330787

Epoch: 5| Step: 9
Training loss: 2.200016498565674
Validation loss: 2.0892153829336166

Epoch: 5| Step: 10
Training loss: 2.038173198699951
Validation loss: 2.080253377556801

Epoch: 5| Step: 11
Training loss: 1.866253137588501
Validation loss: 2.0829255084196725

Epoch: 211| Step: 0
Training loss: 2.3992760181427
Validation loss: 2.075878217816353

Epoch: 5| Step: 1
Training loss: 2.6349263191223145
Validation loss: 2.0755572567383447

Epoch: 5| Step: 2
Training loss: 2.1669559478759766
Validation loss: 2.0700861116250358

Epoch: 5| Step: 3
Training loss: 1.9065392017364502
Validation loss: 2.070715377728144

Epoch: 5| Step: 4
Training loss: 1.6207420825958252
Validation loss: 2.071711699167887

Epoch: 5| Step: 5
Training loss: 1.9654735326766968
Validation loss: 2.076298321286837

Epoch: 5| Step: 6
Training loss: 1.9779651165008545
Validation loss: 2.0746212551991143

Epoch: 5| Step: 7
Training loss: 2.5692601203918457
Validation loss: 2.0751833319664

Epoch: 5| Step: 8
Training loss: 1.7137638330459595
Validation loss: 2.084171950817108

Epoch: 5| Step: 9
Training loss: 1.8175718784332275
Validation loss: 2.0753570795059204

Epoch: 5| Step: 10
Training loss: 1.686073899269104
Validation loss: 2.074491952856382

Epoch: 5| Step: 11
Training loss: 1.4968185424804688
Validation loss: 2.0790592283010483

Epoch: 212| Step: 0
Training loss: 1.7405803203582764
Validation loss: 2.075063645839691

Epoch: 5| Step: 1
Training loss: 1.9844629764556885
Validation loss: 2.094341362516085

Epoch: 5| Step: 2
Training loss: 1.6724255084991455
Validation loss: 2.0820072442293167

Epoch: 5| Step: 3
Training loss: 1.7017247676849365
Validation loss: 2.0910438348849616

Epoch: 5| Step: 4
Training loss: 2.0252890586853027
Validation loss: 2.1138558387756348

Epoch: 5| Step: 5
Training loss: 1.4936918020248413
Validation loss: 2.091920996705691

Epoch: 5| Step: 6
Training loss: 1.9338375329971313
Validation loss: 2.094978481531143

Epoch: 5| Step: 7
Training loss: 2.157071352005005
Validation loss: 2.1169936060905457

Epoch: 5| Step: 8
Training loss: 2.658329486846924
Validation loss: 2.1363526632388434

Epoch: 5| Step: 9
Training loss: 2.0805320739746094
Validation loss: 2.1366484264532724

Epoch: 5| Step: 10
Training loss: 2.2964541912078857
Validation loss: 2.1300178368886313

Epoch: 5| Step: 11
Training loss: 1.1628730297088623
Validation loss: 2.101390451192856

Epoch: 213| Step: 0
Training loss: 1.7338558435440063
Validation loss: 2.118684117992719

Epoch: 5| Step: 1
Training loss: 2.3192832469940186
Validation loss: 2.1064604371786118

Epoch: 5| Step: 2
Training loss: 2.225987672805786
Validation loss: 2.088264753421148

Epoch: 5| Step: 3
Training loss: 1.5773828029632568
Validation loss: 2.0892621278762817

Epoch: 5| Step: 4
Training loss: 1.8808294534683228
Validation loss: 2.08165043592453

Epoch: 5| Step: 5
Training loss: 2.210793972015381
Validation loss: 2.080235247810682

Epoch: 5| Step: 6
Training loss: 1.748978614807129
Validation loss: 2.1014230201641717

Epoch: 5| Step: 7
Training loss: 2.098780870437622
Validation loss: 2.0938987831274667

Epoch: 5| Step: 8
Training loss: 1.7629019021987915
Validation loss: 2.0803541243076324

Epoch: 5| Step: 9
Training loss: 1.5785105228424072
Validation loss: 2.0872497260570526

Epoch: 5| Step: 10
Training loss: 2.079902410507202
Validation loss: 2.094187170267105

Epoch: 5| Step: 11
Training loss: 2.4901041984558105
Validation loss: 2.090929533044497

Epoch: 214| Step: 0
Training loss: 2.2398717403411865
Validation loss: 2.1112424035867057

Epoch: 5| Step: 1
Training loss: 1.6409753561019897
Validation loss: 2.1014704753955207

Epoch: 5| Step: 2
Training loss: 2.3773839473724365
Validation loss: 2.1086206436157227

Epoch: 5| Step: 3
Training loss: 1.8299963474273682
Validation loss: 2.1071245769659677

Epoch: 5| Step: 4
Training loss: 2.020167112350464
Validation loss: 2.1055027643839517

Epoch: 5| Step: 5
Training loss: 1.1964647769927979
Validation loss: 2.1149905820687613

Epoch: 5| Step: 6
Training loss: 2.042849063873291
Validation loss: 2.101556474963824

Epoch: 5| Step: 7
Training loss: 1.8512258529663086
Validation loss: 2.1038965632518134

Epoch: 5| Step: 8
Training loss: 2.1955535411834717
Validation loss: 2.111959755420685

Epoch: 5| Step: 9
Training loss: 1.5729230642318726
Validation loss: 2.1087632973988852

Epoch: 5| Step: 10
Training loss: 2.2888941764831543
Validation loss: 2.128754824399948

Epoch: 5| Step: 11
Training loss: 1.5766496658325195
Validation loss: 2.123621493577957

Epoch: 215| Step: 0
Training loss: 1.764868140220642
Validation loss: 2.104837015271187

Epoch: 5| Step: 1
Training loss: 2.1167047023773193
Validation loss: 2.0939384003480277

Epoch: 5| Step: 2
Training loss: 1.9434289932250977
Validation loss: 2.0866499543190002

Epoch: 5| Step: 3
Training loss: 1.4278786182403564
Validation loss: 2.0858456840117774

Epoch: 5| Step: 4
Training loss: 2.1253464221954346
Validation loss: 2.0793539037307105

Epoch: 5| Step: 5
Training loss: 2.041595935821533
Validation loss: 2.081162706017494

Epoch: 5| Step: 6
Training loss: 2.1211581230163574
Validation loss: 2.08486644923687

Epoch: 5| Step: 7
Training loss: 1.6987025737762451
Validation loss: 2.0890115151802697

Epoch: 5| Step: 8
Training loss: 2.67510986328125
Validation loss: 2.090601230661074

Epoch: 5| Step: 9
Training loss: 2.1162109375
Validation loss: 2.0868373413880668

Epoch: 5| Step: 10
Training loss: 1.4385693073272705
Validation loss: 2.0960170924663544

Epoch: 5| Step: 11
Training loss: 3.5576767921447754
Validation loss: 2.0835459480683007

Epoch: 216| Step: 0
Training loss: 1.997605562210083
Validation loss: 2.094520688056946

Epoch: 5| Step: 1
Training loss: 2.026383876800537
Validation loss: 2.0915029098590217

Epoch: 5| Step: 2
Training loss: 1.748508095741272
Validation loss: 2.092531899611155

Epoch: 5| Step: 3
Training loss: 1.6475130319595337
Validation loss: 2.1065762291351953

Epoch: 5| Step: 4
Training loss: 1.7267459630966187
Validation loss: 2.100276450316111

Epoch: 5| Step: 5
Training loss: 2.02512788772583
Validation loss: 2.112413078546524

Epoch: 5| Step: 6
Training loss: 2.268659830093384
Validation loss: 2.1175301720698676

Epoch: 5| Step: 7
Training loss: 1.6137845516204834
Validation loss: 2.1175244549910226

Epoch: 5| Step: 8
Training loss: 2.2329230308532715
Validation loss: 2.1049101501703262

Epoch: 5| Step: 9
Training loss: 2.2731728553771973
Validation loss: 2.1123811652263007

Epoch: 5| Step: 10
Training loss: 1.8682883977890015
Validation loss: 2.132058540980021

Epoch: 5| Step: 11
Training loss: 2.3332083225250244
Validation loss: 2.119652435183525

Epoch: 217| Step: 0
Training loss: 1.7740110158920288
Validation loss: 2.108987723787626

Epoch: 5| Step: 1
Training loss: 2.016252040863037
Validation loss: 2.117490584651629

Epoch: 5| Step: 2
Training loss: 2.212857484817505
Validation loss: 2.090419332186381

Epoch: 5| Step: 3
Training loss: 2.3665857315063477
Validation loss: 2.09164231022199

Epoch: 5| Step: 4
Training loss: 1.9182227849960327
Validation loss: 2.0910456677277884

Epoch: 5| Step: 5
Training loss: 2.129451274871826
Validation loss: 2.0966286957263947

Epoch: 5| Step: 6
Training loss: 1.7915055751800537
Validation loss: 2.085306609670321

Epoch: 5| Step: 7
Training loss: 1.8432689905166626
Validation loss: 2.094096933801969

Epoch: 5| Step: 8
Training loss: 1.5842046737670898
Validation loss: 2.0949431359767914

Epoch: 5| Step: 9
Training loss: 1.7487390041351318
Validation loss: 2.115500728289286

Epoch: 5| Step: 10
Training loss: 2.2795581817626953
Validation loss: 2.1201495279868445

Epoch: 5| Step: 11
Training loss: 2.02221941947937
Validation loss: 2.143021121621132

Epoch: 218| Step: 0
Training loss: 2.305685520172119
Validation loss: 2.1417385985453925

Epoch: 5| Step: 1
Training loss: 2.1509556770324707
Validation loss: 2.160135249296824

Epoch: 5| Step: 2
Training loss: 1.7446844577789307
Validation loss: 2.1641375919183097

Epoch: 5| Step: 3
Training loss: 1.636239767074585
Validation loss: 2.160343661904335

Epoch: 5| Step: 4
Training loss: 2.010415554046631
Validation loss: 2.1537257532278695

Epoch: 5| Step: 5
Training loss: 2.1064887046813965
Validation loss: 2.1593820601701736

Epoch: 5| Step: 6
Training loss: 1.3336248397827148
Validation loss: 2.141430586576462

Epoch: 5| Step: 7
Training loss: 2.080350875854492
Validation loss: 2.1272976050774255

Epoch: 5| Step: 8
Training loss: 1.819345474243164
Validation loss: 2.1197780619064965

Epoch: 5| Step: 9
Training loss: 1.9468624591827393
Validation loss: 2.123877386252085

Epoch: 5| Step: 10
Training loss: 2.273569107055664
Validation loss: 2.1335633446772895

Epoch: 5| Step: 11
Training loss: 2.3394882678985596
Validation loss: 2.1244690219561257

Epoch: 219| Step: 0
Training loss: 2.0732951164245605
Validation loss: 2.110179215669632

Epoch: 5| Step: 1
Training loss: 1.852020263671875
Validation loss: 2.107220634818077

Epoch: 5| Step: 2
Training loss: 1.7562662363052368
Validation loss: 2.099022716283798

Epoch: 5| Step: 3
Training loss: 2.1133904457092285
Validation loss: 2.1025360922018685

Epoch: 5| Step: 4
Training loss: 2.3405795097351074
Validation loss: 2.1155953109264374

Epoch: 5| Step: 5
Training loss: 1.5188792943954468
Validation loss: 2.1155152320861816

Epoch: 5| Step: 6
Training loss: 2.021498918533325
Validation loss: 2.1235610097646713

Epoch: 5| Step: 7
Training loss: 1.5805712938308716
Validation loss: 2.118213882048925

Epoch: 5| Step: 8
Training loss: 2.214960813522339
Validation loss: 2.1170114278793335

Epoch: 5| Step: 9
Training loss: 2.196138381958008
Validation loss: 2.1312879025936127

Epoch: 5| Step: 10
Training loss: 1.467759132385254
Validation loss: 2.1229129334290824

Epoch: 5| Step: 11
Training loss: 1.9408457279205322
Validation loss: 2.1354778756697974

Epoch: 220| Step: 0
Training loss: 2.2319209575653076
Validation loss: 2.1322198609511056

Epoch: 5| Step: 1
Training loss: 1.616398572921753
Validation loss: 2.1222323924303055

Epoch: 5| Step: 2
Training loss: 1.9404205083847046
Validation loss: 2.1226840118567147

Epoch: 5| Step: 3
Training loss: 2.18955659866333
Validation loss: 2.132595881819725

Epoch: 5| Step: 4
Training loss: 2.6690590381622314
Validation loss: 2.126931369304657

Epoch: 5| Step: 5
Training loss: 1.7586807012557983
Validation loss: 2.139239728450775

Epoch: 5| Step: 6
Training loss: 2.1815524101257324
Validation loss: 2.1174755146106086

Epoch: 5| Step: 7
Training loss: 1.4111807346343994
Validation loss: 2.124857177337011

Epoch: 5| Step: 8
Training loss: 1.9078346490859985
Validation loss: 2.124934201439222

Epoch: 5| Step: 9
Training loss: 1.6885792016983032
Validation loss: 2.1120649774869285

Epoch: 5| Step: 10
Training loss: 1.683811902999878
Validation loss: 2.124069799979528

Epoch: 5| Step: 11
Training loss: 2.1149168014526367
Validation loss: 2.1296312560637793

Epoch: 221| Step: 0
Training loss: 1.9197953939437866
Validation loss: 2.1334724376598992

Epoch: 5| Step: 1
Training loss: 2.0749878883361816
Validation loss: 2.129992817838987

Epoch: 5| Step: 2
Training loss: 1.7717037200927734
Validation loss: 2.102041224638621

Epoch: 5| Step: 3
Training loss: 1.7864395380020142
Validation loss: 2.1158439417680106

Epoch: 5| Step: 4
Training loss: 2.025834560394287
Validation loss: 2.1280453403790793

Epoch: 5| Step: 5
Training loss: 1.4678152799606323
Validation loss: 2.1374213496843972

Epoch: 5| Step: 6
Training loss: 2.2663521766662598
Validation loss: 2.1515049089988074

Epoch: 5| Step: 7
Training loss: 1.7387468814849854
Validation loss: 2.1430904269218445

Epoch: 5| Step: 8
Training loss: 1.9530277252197266
Validation loss: 2.139021654923757

Epoch: 5| Step: 9
Training loss: 2.1295909881591797
Validation loss: 2.1339428226153054

Epoch: 5| Step: 10
Training loss: 2.058666706085205
Validation loss: 2.1310057987769446

Epoch: 5| Step: 11
Training loss: 1.6098651885986328
Validation loss: 2.121840705474218

Epoch: 222| Step: 0
Training loss: 1.9495433568954468
Validation loss: 2.111847092707952

Epoch: 5| Step: 1
Training loss: 1.8029683828353882
Validation loss: 2.1126481195290885

Epoch: 5| Step: 2
Training loss: 1.809557557106018
Validation loss: 2.112173020839691

Epoch: 5| Step: 3
Training loss: 1.805070161819458
Validation loss: 2.1042694995800653

Epoch: 5| Step: 4
Training loss: 1.81633722782135
Validation loss: 2.1119924634695053

Epoch: 5| Step: 5
Training loss: 1.7408649921417236
Validation loss: 2.1026682456334433

Epoch: 5| Step: 6
Training loss: 2.0584912300109863
Validation loss: 2.102350637316704

Epoch: 5| Step: 7
Training loss: 1.9310657978057861
Validation loss: 2.105996072292328

Epoch: 5| Step: 8
Training loss: 2.031499147415161
Validation loss: 2.1300248305002847

Epoch: 5| Step: 9
Training loss: 1.979021430015564
Validation loss: 2.1279474397500358

Epoch: 5| Step: 10
Training loss: 2.2420058250427246
Validation loss: 2.137782941261927

Epoch: 5| Step: 11
Training loss: 2.3907251358032227
Validation loss: 2.142856001853943

Epoch: 223| Step: 0
Training loss: 2.3939859867095947
Validation loss: 2.136737436056137

Epoch: 5| Step: 1
Training loss: 1.7795110940933228
Validation loss: 2.137346069018046

Epoch: 5| Step: 2
Training loss: 1.752740502357483
Validation loss: 2.1254095236460366

Epoch: 5| Step: 3
Training loss: 1.9214633703231812
Validation loss: 2.1078613102436066

Epoch: 5| Step: 4
Training loss: 1.9041563272476196
Validation loss: 2.1088312913974128

Epoch: 5| Step: 5
Training loss: 2.0823826789855957
Validation loss: 2.105862299601237

Epoch: 5| Step: 6
Training loss: 1.7431634664535522
Validation loss: 2.092458282907804

Epoch: 5| Step: 7
Training loss: 1.7927608489990234
Validation loss: 2.096637407938639

Epoch: 5| Step: 8
Training loss: 1.8731582164764404
Validation loss: 2.095030983289083

Epoch: 5| Step: 9
Training loss: 1.818050742149353
Validation loss: 2.103522111972173

Epoch: 5| Step: 10
Training loss: 1.9448678493499756
Validation loss: 2.111848145723343

Epoch: 5| Step: 11
Training loss: 3.8317482471466064
Validation loss: 2.1135218838850656

Epoch: 224| Step: 0
Training loss: 2.1248621940612793
Validation loss: 2.1506440540154776

Epoch: 5| Step: 1
Training loss: 2.3345229625701904
Validation loss: 2.183691749970118

Epoch: 5| Step: 2
Training loss: 1.779320478439331
Validation loss: 2.1955207735300064

Epoch: 5| Step: 3
Training loss: 1.9144834280014038
Validation loss: 2.1838980118433633

Epoch: 5| Step: 4
Training loss: 1.335839867591858
Validation loss: 2.1838857730229697

Epoch: 5| Step: 5
Training loss: 2.2644009590148926
Validation loss: 2.1764679898818335

Epoch: 5| Step: 6
Training loss: 2.4584691524505615
Validation loss: 2.1772843251625695

Epoch: 5| Step: 7
Training loss: 1.9993451833724976
Validation loss: 2.1613524556159973

Epoch: 5| Step: 8
Training loss: 2.226112127304077
Validation loss: 2.163436676065127

Epoch: 5| Step: 9
Training loss: 1.4740813970565796
Validation loss: 2.1359039147694907

Epoch: 5| Step: 10
Training loss: 1.7118759155273438
Validation loss: 2.1104867408672967

Epoch: 5| Step: 11
Training loss: 1.3290940523147583
Validation loss: 2.1195347805817923

Epoch: 225| Step: 0
Training loss: 1.7586820125579834
Validation loss: 2.107342710097631

Epoch: 5| Step: 1
Training loss: 2.4111225605010986
Validation loss: 2.097365995248159

Epoch: 5| Step: 2
Training loss: 2.1174421310424805
Validation loss: 2.1044699251651764

Epoch: 5| Step: 3
Training loss: 1.6043775081634521
Validation loss: 2.110635201136271

Epoch: 5| Step: 4
Training loss: 2.012441635131836
Validation loss: 2.101863458752632

Epoch: 5| Step: 5
Training loss: 2.043381452560425
Validation loss: 2.1076127539078393

Epoch: 5| Step: 6
Training loss: 1.9951763153076172
Validation loss: 2.102546696861585

Epoch: 5| Step: 7
Training loss: 2.2895326614379883
Validation loss: 2.1003509759902954

Epoch: 5| Step: 8
Training loss: 1.7500202655792236
Validation loss: 2.0960601419210434

Epoch: 5| Step: 9
Training loss: 1.9498552083969116
Validation loss: 2.118520791331927

Epoch: 5| Step: 10
Training loss: 1.9048227071762085
Validation loss: 2.1174115737279258

Epoch: 5| Step: 11
Training loss: 1.4903016090393066
Validation loss: 2.13113601009051

Epoch: 226| Step: 0
Training loss: 2.2778663635253906
Validation loss: 2.1394127955039344

Epoch: 5| Step: 1
Training loss: 2.110515594482422
Validation loss: 2.125822057326635

Epoch: 5| Step: 2
Training loss: 2.112064838409424
Validation loss: 2.1518950859705606

Epoch: 5| Step: 3
Training loss: 1.5061767101287842
Validation loss: 2.1533335000276566

Epoch: 5| Step: 4
Training loss: 1.330597996711731
Validation loss: 2.134696811437607

Epoch: 5| Step: 5
Training loss: 1.8581554889678955
Validation loss: 2.140645464261373

Epoch: 5| Step: 6
Training loss: 1.5527622699737549
Validation loss: 2.145553191502889

Epoch: 5| Step: 7
Training loss: 2.0940918922424316
Validation loss: 2.154061550895373

Epoch: 5| Step: 8
Training loss: 1.8219016790390015
Validation loss: 2.1528012106815972

Epoch: 5| Step: 9
Training loss: 2.369554042816162
Validation loss: 2.146656036376953

Epoch: 5| Step: 10
Training loss: 2.013141632080078
Validation loss: 2.1394939919312796

Epoch: 5| Step: 11
Training loss: 2.2279133796691895
Validation loss: 2.136026009917259

Epoch: 227| Step: 0
Training loss: 1.524721622467041
Validation loss: 2.127891793847084

Epoch: 5| Step: 1
Training loss: 2.3673274517059326
Validation loss: 2.121162528793017

Epoch: 5| Step: 2
Training loss: 1.6306133270263672
Validation loss: 2.13200506567955

Epoch: 5| Step: 3
Training loss: 2.393599033355713
Validation loss: 2.126851439476013

Epoch: 5| Step: 4
Training loss: 1.6853653192520142
Validation loss: 2.1210273007551828

Epoch: 5| Step: 5
Training loss: 1.8038536310195923
Validation loss: 2.1059101670980453

Epoch: 5| Step: 6
Training loss: 1.8736026287078857
Validation loss: 2.126390020052592

Epoch: 5| Step: 7
Training loss: 2.2117867469787598
Validation loss: 2.115132754047712

Epoch: 5| Step: 8
Training loss: 2.206505537033081
Validation loss: 2.1183293710152307

Epoch: 5| Step: 9
Training loss: 1.553113341331482
Validation loss: 2.1198122948408127

Epoch: 5| Step: 10
Training loss: 1.9325813055038452
Validation loss: 2.13311334947745

Epoch: 5| Step: 11
Training loss: 1.4454902410507202
Validation loss: 2.121901402870814

Epoch: 228| Step: 0
Training loss: 1.655388593673706
Validation loss: 2.1415438652038574

Epoch: 5| Step: 1
Training loss: 1.8471977710723877
Validation loss: 2.1376681476831436

Epoch: 5| Step: 2
Training loss: 1.7910845279693604
Validation loss: 2.140668109059334

Epoch: 5| Step: 3
Training loss: 1.6560213565826416
Validation loss: 2.131094311674436

Epoch: 5| Step: 4
Training loss: 2.420891284942627
Validation loss: 2.1170301785071692

Epoch: 5| Step: 5
Training loss: 1.7948381900787354
Validation loss: 2.1184211721022925

Epoch: 5| Step: 6
Training loss: 2.324937343597412
Validation loss: 2.125403583049774

Epoch: 5| Step: 7
Training loss: 1.9911829233169556
Validation loss: 2.122236981987953

Epoch: 5| Step: 8
Training loss: 1.6918056011199951
Validation loss: 2.1246247788270316

Epoch: 5| Step: 9
Training loss: 2.006275177001953
Validation loss: 2.1265079577763877

Epoch: 5| Step: 10
Training loss: 1.9131923913955688
Validation loss: 2.1448866724967957

Epoch: 5| Step: 11
Training loss: 1.508310317993164
Validation loss: 2.143147826194763

Epoch: 229| Step: 0
Training loss: 1.9204480648040771
Validation loss: 2.1344022701183953

Epoch: 5| Step: 1
Training loss: 1.5862579345703125
Validation loss: 2.1460653940836587

Epoch: 5| Step: 2
Training loss: 2.149028778076172
Validation loss: 2.153579627474149

Epoch: 5| Step: 3
Training loss: 2.4991555213928223
Validation loss: 2.1493435154358544

Epoch: 5| Step: 4
Training loss: 2.128380060195923
Validation loss: 2.14363032579422

Epoch: 5| Step: 5
Training loss: 1.3886247873306274
Validation loss: 2.1290624886751175

Epoch: 5| Step: 6
Training loss: 1.8137905597686768
Validation loss: 2.1298961440722146

Epoch: 5| Step: 7
Training loss: 1.560668706893921
Validation loss: 2.1103853483994803

Epoch: 5| Step: 8
Training loss: 2.0209174156188965
Validation loss: 2.094704066713651

Epoch: 5| Step: 9
Training loss: 1.9341704845428467
Validation loss: 2.0872978965441384

Epoch: 5| Step: 10
Training loss: 2.3127341270446777
Validation loss: 2.100613663593928

Epoch: 5| Step: 11
Training loss: 2.0200047492980957
Validation loss: 2.0969094733397164

Epoch: 230| Step: 0
Training loss: 1.5783170461654663
Validation loss: 2.099815239508947

Epoch: 5| Step: 1
Training loss: 2.252645492553711
Validation loss: 2.1060028771559396

Epoch: 5| Step: 2
Training loss: 1.7004375457763672
Validation loss: 2.109767665465673

Epoch: 5| Step: 3
Training loss: 1.9479577541351318
Validation loss: 2.1373692949612937

Epoch: 5| Step: 4
Training loss: 2.321565628051758
Validation loss: 2.1520306766033173

Epoch: 5| Step: 5
Training loss: 1.821068525314331
Validation loss: 2.1351126531759896

Epoch: 5| Step: 6
Training loss: 1.4473021030426025
Validation loss: 2.1354931543270745

Epoch: 5| Step: 7
Training loss: 1.9781169891357422
Validation loss: 2.150902589162191

Epoch: 5| Step: 8
Training loss: 2.1245203018188477
Validation loss: 2.128304382165273

Epoch: 5| Step: 9
Training loss: 1.8226600885391235
Validation loss: 2.13689290980498

Epoch: 5| Step: 10
Training loss: 1.98615300655365
Validation loss: 2.133983939886093

Epoch: 5| Step: 11
Training loss: 2.5475478172302246
Validation loss: 2.156979958216349

Epoch: 231| Step: 0
Training loss: 1.7847652435302734
Validation loss: 2.138526290655136

Epoch: 5| Step: 1
Training loss: 1.4994021654129028
Validation loss: 2.1359584430853524

Epoch: 5| Step: 2
Training loss: 2.0417816638946533
Validation loss: 2.1343923459450402

Epoch: 5| Step: 3
Training loss: 1.8714545965194702
Validation loss: 2.134302814801534

Epoch: 5| Step: 4
Training loss: 1.6912460327148438
Validation loss: 2.1245840191841125

Epoch: 5| Step: 5
Training loss: 2.1334362030029297
Validation loss: 2.124193921685219

Epoch: 5| Step: 6
Training loss: 2.3264999389648438
Validation loss: 2.1183631221453347

Epoch: 5| Step: 7
Training loss: 2.0193090438842773
Validation loss: 2.1199700136979422

Epoch: 5| Step: 8
Training loss: 1.8630149364471436
Validation loss: 2.11418824394544

Epoch: 5| Step: 9
Training loss: 2.3177273273468018
Validation loss: 2.0943966011206308

Epoch: 5| Step: 10
Training loss: 1.6015474796295166
Validation loss: 2.109865128993988

Epoch: 5| Step: 11
Training loss: 1.0580278635025024
Validation loss: 2.117347856362661

Epoch: 232| Step: 0
Training loss: 1.349909782409668
Validation loss: 2.10081052283446

Epoch: 5| Step: 1
Training loss: 1.4598257541656494
Validation loss: 2.1113690634568534

Epoch: 5| Step: 2
Training loss: 2.358696460723877
Validation loss: 2.1074200520912805

Epoch: 5| Step: 3
Training loss: 2.34409761428833
Validation loss: 2.105331629514694

Epoch: 5| Step: 4
Training loss: 2.1398797035217285
Validation loss: 2.101407284537951

Epoch: 5| Step: 5
Training loss: 2.0696702003479004
Validation loss: 2.118705595533053

Epoch: 5| Step: 6
Training loss: 1.8345825672149658
Validation loss: 2.1303809781869254

Epoch: 5| Step: 7
Training loss: 2.0820577144622803
Validation loss: 2.1357579429944358

Epoch: 5| Step: 8
Training loss: 1.7362550497055054
Validation loss: 2.1520329316457114

Epoch: 5| Step: 9
Training loss: 1.7345340251922607
Validation loss: 2.167180875937144

Epoch: 5| Step: 10
Training loss: 1.9122533798217773
Validation loss: 2.1570675869782767

Epoch: 5| Step: 11
Training loss: 2.752833127975464
Validation loss: 2.1351287364959717

Epoch: 233| Step: 0
Training loss: 1.7407505512237549
Validation loss: 2.136028617620468

Epoch: 5| Step: 1
Training loss: 1.6400457620620728
Validation loss: 2.1308545966943107

Epoch: 5| Step: 2
Training loss: 1.7219364643096924
Validation loss: 2.1118471870819726

Epoch: 5| Step: 3
Training loss: 2.1395227909088135
Validation loss: 2.1138893167177835

Epoch: 5| Step: 4
Training loss: 2.291463613510132
Validation loss: 2.1140288412570953

Epoch: 5| Step: 5
Training loss: 1.8948341608047485
Validation loss: 2.1074302146832147

Epoch: 5| Step: 6
Training loss: 1.7822126150131226
Validation loss: 2.1165589094161987

Epoch: 5| Step: 7
Training loss: 2.035414457321167
Validation loss: 2.119949072599411

Epoch: 5| Step: 8
Training loss: 1.6432654857635498
Validation loss: 2.128320425748825

Epoch: 5| Step: 9
Training loss: 2.3332650661468506
Validation loss: 2.1432509273290634

Epoch: 5| Step: 10
Training loss: 1.6367053985595703
Validation loss: 2.12843165298303

Epoch: 5| Step: 11
Training loss: 2.5457420349121094
Validation loss: 2.1486205955346427

Epoch: 234| Step: 0
Training loss: 2.3732831478118896
Validation loss: 2.1397101829449334

Epoch: 5| Step: 1
Training loss: 1.0489788055419922
Validation loss: 2.1390789101521173

Epoch: 5| Step: 2
Training loss: 1.8886207342147827
Validation loss: 2.1317474047342935

Epoch: 5| Step: 3
Training loss: 2.434471607208252
Validation loss: 2.128965899348259

Epoch: 5| Step: 4
Training loss: 1.3889434337615967
Validation loss: 2.1451304455598197

Epoch: 5| Step: 5
Training loss: 1.8900747299194336
Validation loss: 2.135786011815071

Epoch: 5| Step: 6
Training loss: 2.266775608062744
Validation loss: 2.131888965765635

Epoch: 5| Step: 7
Training loss: 1.6367435455322266
Validation loss: 2.1413533637921014

Epoch: 5| Step: 8
Training loss: 1.714352011680603
Validation loss: 2.1106780618429184

Epoch: 5| Step: 9
Training loss: 2.1910228729248047
Validation loss: 2.110132709145546

Epoch: 5| Step: 10
Training loss: 1.9778215885162354
Validation loss: 2.1336677024761834

Epoch: 5| Step: 11
Training loss: 3.056492805480957
Validation loss: 2.1310211519400277

Epoch: 235| Step: 0
Training loss: 1.9992988109588623
Validation loss: 2.1437564939260483

Epoch: 5| Step: 1
Training loss: 1.8221368789672852
Validation loss: 2.145427703857422

Epoch: 5| Step: 2
Training loss: 2.105374574661255
Validation loss: 2.1447827021280923

Epoch: 5| Step: 3
Training loss: 1.9390310049057007
Validation loss: 2.170303995410601

Epoch: 5| Step: 4
Training loss: 1.6618635654449463
Validation loss: 2.1626962622006736

Epoch: 5| Step: 5
Training loss: 1.733802080154419
Validation loss: 2.1615308076143265

Epoch: 5| Step: 6
Training loss: 1.7519738674163818
Validation loss: 2.1537075440088906

Epoch: 5| Step: 7
Training loss: 1.7746093273162842
Validation loss: 2.1527878642082214

Epoch: 5| Step: 8
Training loss: 2.0766546726226807
Validation loss: 2.1512586126724877

Epoch: 5| Step: 9
Training loss: 1.7489134073257446
Validation loss: 2.1302678982416787

Epoch: 5| Step: 10
Training loss: 2.0438718795776367
Validation loss: 2.1044102708498635

Epoch: 5| Step: 11
Training loss: 2.0084612369537354
Validation loss: 2.0978054205576577

Epoch: 236| Step: 0
Training loss: 1.396404504776001
Validation loss: 2.114525616168976

Epoch: 5| Step: 1
Training loss: 2.1210575103759766
Validation loss: 2.097657173871994

Epoch: 5| Step: 2
Training loss: 1.7599468231201172
Validation loss: 2.1058191508054733

Epoch: 5| Step: 3
Training loss: 1.8423748016357422
Validation loss: 2.0946403543154397

Epoch: 5| Step: 4
Training loss: 1.5887556076049805
Validation loss: 2.099092960357666

Epoch: 5| Step: 5
Training loss: 1.375436782836914
Validation loss: 2.1104586074749627

Epoch: 5| Step: 6
Training loss: 2.3453047275543213
Validation loss: 2.124335209528605

Epoch: 5| Step: 7
Training loss: 1.4666144847869873
Validation loss: 2.1502515276273093

Epoch: 5| Step: 8
Training loss: 2.2129337787628174
Validation loss: 2.133753021558126

Epoch: 5| Step: 9
Training loss: 2.361356258392334
Validation loss: 2.16281358897686

Epoch: 5| Step: 10
Training loss: 2.3128857612609863
Validation loss: 2.161808505654335

Epoch: 5| Step: 11
Training loss: 2.0788888931274414
Validation loss: 2.154703830679258

Epoch: 237| Step: 0
Training loss: 1.391711950302124
Validation loss: 2.149824102719625

Epoch: 5| Step: 1
Training loss: 1.5963544845581055
Validation loss: 2.151318992177645

Epoch: 5| Step: 2
Training loss: 1.7627151012420654
Validation loss: 2.1529558251301446

Epoch: 5| Step: 3
Training loss: 1.8365987539291382
Validation loss: 2.1382055431604385

Epoch: 5| Step: 4
Training loss: 2.3873772621154785
Validation loss: 2.1287772754828134

Epoch: 5| Step: 5
Training loss: 1.8873653411865234
Validation loss: 2.129194254676501

Epoch: 5| Step: 6
Training loss: 2.0382184982299805
Validation loss: 2.1169219464063644

Epoch: 5| Step: 7
Training loss: 2.522174835205078
Validation loss: 2.1228644947210946

Epoch: 5| Step: 8
Training loss: 1.4617608785629272
Validation loss: 2.1156465957562127

Epoch: 5| Step: 9
Training loss: 1.4245893955230713
Validation loss: 2.107998346288999

Epoch: 5| Step: 10
Training loss: 2.1419777870178223
Validation loss: 2.125773698091507

Epoch: 5| Step: 11
Training loss: 3.126955509185791
Validation loss: 2.110672414302826

Epoch: 238| Step: 0
Training loss: 1.852026343345642
Validation loss: 2.1149906118710837

Epoch: 5| Step: 1
Training loss: 1.8839231729507446
Validation loss: 2.1174227794011435

Epoch: 5| Step: 2
Training loss: 1.6299502849578857
Validation loss: 2.131952424844106

Epoch: 5| Step: 3
Training loss: 1.3333154916763306
Validation loss: 2.1479026277860007

Epoch: 5| Step: 4
Training loss: 1.8643062114715576
Validation loss: 2.1653753171364465

Epoch: 5| Step: 5
Training loss: 2.033188581466675
Validation loss: 2.1732021371523538

Epoch: 5| Step: 6
Training loss: 2.28924298286438
Validation loss: 2.179407849907875

Epoch: 5| Step: 7
Training loss: 1.8053953647613525
Validation loss: 2.174354687333107

Epoch: 5| Step: 8
Training loss: 2.306392192840576
Validation loss: 2.162584140896797

Epoch: 5| Step: 9
Training loss: 1.9163084030151367
Validation loss: 2.182479421297709

Epoch: 5| Step: 10
Training loss: 1.964342474937439
Validation loss: 2.1789753784736

Epoch: 5| Step: 11
Training loss: 2.23388409614563
Validation loss: 2.1480662574370704

Epoch: 239| Step: 0
Training loss: 1.9031013250350952
Validation loss: 2.147031416495641

Epoch: 5| Step: 1
Training loss: 2.147843837738037
Validation loss: 2.1368355651696525

Epoch: 5| Step: 2
Training loss: 1.849278450012207
Validation loss: 2.1315592428048453

Epoch: 5| Step: 3
Training loss: 1.4336525201797485
Validation loss: 2.1464436650276184

Epoch: 5| Step: 4
Training loss: 2.333632230758667
Validation loss: 2.1343262791633606

Epoch: 5| Step: 5
Training loss: 1.9629409313201904
Validation loss: 2.130034868915876

Epoch: 5| Step: 6
Training loss: 1.6632664203643799
Validation loss: 2.1351673106352487

Epoch: 5| Step: 7
Training loss: 2.191843271255493
Validation loss: 2.1376633445421853

Epoch: 5| Step: 8
Training loss: 1.1275910139083862
Validation loss: 2.134494791428248

Epoch: 5| Step: 9
Training loss: 1.9947906732559204
Validation loss: 2.1256050864855447

Epoch: 5| Step: 10
Training loss: 1.8756892681121826
Validation loss: 2.1223505437374115

Epoch: 5| Step: 11
Training loss: 2.7677712440490723
Validation loss: 2.14875919620196

Epoch: 240| Step: 0
Training loss: 2.1453115940093994
Validation loss: 2.160578896601995

Epoch: 5| Step: 1
Training loss: 1.7821012735366821
Validation loss: 2.1340975860754647

Epoch: 5| Step: 2
Training loss: 2.2642223834991455
Validation loss: 2.1563261399666467

Epoch: 5| Step: 3
Training loss: 1.7651557922363281
Validation loss: 2.1542078455289206

Epoch: 5| Step: 4
Training loss: 1.703466773033142
Validation loss: 2.154342765609423

Epoch: 5| Step: 5
Training loss: 1.9170610904693604
Validation loss: 2.1519360641638436

Epoch: 5| Step: 6
Training loss: 1.9416793584823608
Validation loss: 2.154506281018257

Epoch: 5| Step: 7
Training loss: 2.1232805252075195
Validation loss: 2.1727013885974884

Epoch: 5| Step: 8
Training loss: 1.3551980257034302
Validation loss: 2.172067642211914

Epoch: 5| Step: 9
Training loss: 2.0651843547821045
Validation loss: 2.168398121992747

Epoch: 5| Step: 10
Training loss: 1.8407847881317139
Validation loss: 2.170486922065417

Epoch: 5| Step: 11
Training loss: 1.0336072444915771
Validation loss: 2.146556794643402

Epoch: 241| Step: 0
Training loss: 1.6660068035125732
Validation loss: 2.1308327416578927

Epoch: 5| Step: 1
Training loss: 1.5352659225463867
Validation loss: 2.1336691478888192

Epoch: 5| Step: 2
Training loss: 2.0822815895080566
Validation loss: 2.1285608609517417

Epoch: 5| Step: 3
Training loss: 2.2029001712799072
Validation loss: 2.114757612347603

Epoch: 5| Step: 4
Training loss: 1.8704900741577148
Validation loss: 2.1011303265889487

Epoch: 5| Step: 5
Training loss: 2.4928841590881348
Validation loss: 2.1047647148370743

Epoch: 5| Step: 6
Training loss: 2.01385760307312
Validation loss: 2.102966840068499

Epoch: 5| Step: 7
Training loss: 1.6957008838653564
Validation loss: 2.1116007020076117

Epoch: 5| Step: 8
Training loss: 1.7036139965057373
Validation loss: 2.1019164820512137

Epoch: 5| Step: 9
Training loss: 1.4979674816131592
Validation loss: 2.1069564620653787

Epoch: 5| Step: 10
Training loss: 2.3273606300354004
Validation loss: 2.1239722768465676

Epoch: 5| Step: 11
Training loss: 1.9334708452224731
Validation loss: 2.1364393581946692

Epoch: 242| Step: 0
Training loss: 2.220722198486328
Validation loss: 2.170339817802111

Epoch: 5| Step: 1
Training loss: 1.8120307922363281
Validation loss: 2.2002727588017783

Epoch: 5| Step: 2
Training loss: 1.8560020923614502
Validation loss: 2.2290122359991074

Epoch: 5| Step: 3
Training loss: 1.829214334487915
Validation loss: 2.2417660305897393

Epoch: 5| Step: 4
Training loss: 2.0751218795776367
Validation loss: 2.2651263574759164

Epoch: 5| Step: 5
Training loss: 2.1669135093688965
Validation loss: 2.2556498597065606

Epoch: 5| Step: 6
Training loss: 2.4639625549316406
Validation loss: 2.2600713074207306

Epoch: 5| Step: 7
Training loss: 1.3704451322555542
Validation loss: 2.241992582877477

Epoch: 5| Step: 8
Training loss: 2.194277286529541
Validation loss: 2.2063978066047034

Epoch: 5| Step: 9
Training loss: 1.7352336645126343
Validation loss: 2.1613338639338813

Epoch: 5| Step: 10
Training loss: 1.9287189245224
Validation loss: 2.1350159297386804

Epoch: 5| Step: 11
Training loss: 2.855369806289673
Validation loss: 2.113299230734507

Epoch: 243| Step: 0
Training loss: 2.4990906715393066
Validation loss: 2.101675113042196

Epoch: 5| Step: 1
Training loss: 2.221259593963623
Validation loss: 2.0983708600203195

Epoch: 5| Step: 2
Training loss: 1.7368762493133545
Validation loss: 2.08469195663929

Epoch: 5| Step: 3
Training loss: 2.0713000297546387
Validation loss: 2.0845545729001365

Epoch: 5| Step: 4
Training loss: 1.8616472482681274
Validation loss: 2.079376498858134

Epoch: 5| Step: 5
Training loss: 1.9486147165298462
Validation loss: 2.078361759583155

Epoch: 5| Step: 6
Training loss: 1.9192616939544678
Validation loss: 2.0818632592757544

Epoch: 5| Step: 7
Training loss: 1.7667287588119507
Validation loss: 2.0947132607301078

Epoch: 5| Step: 8
Training loss: 1.7898032665252686
Validation loss: 2.089549963672956

Epoch: 5| Step: 9
Training loss: 2.1546828746795654
Validation loss: 2.1028319547573724

Epoch: 5| Step: 10
Training loss: 1.4206355810165405
Validation loss: 2.132233197490374

Epoch: 5| Step: 11
Training loss: 2.1324238777160645
Validation loss: 2.1488009691238403

Epoch: 244| Step: 0
Training loss: 1.9545392990112305
Validation loss: 2.1790408541758857

Epoch: 5| Step: 1
Training loss: 2.156324863433838
Validation loss: 2.1807506481806436

Epoch: 5| Step: 2
Training loss: 1.9049049615859985
Validation loss: 2.2000764906406403

Epoch: 5| Step: 3
Training loss: 1.9272139072418213
Validation loss: 2.1634830981492996

Epoch: 5| Step: 4
Training loss: 1.812628149986267
Validation loss: 2.1762365897496543

Epoch: 5| Step: 5
Training loss: 2.2756876945495605
Validation loss: 2.164210428794225

Epoch: 5| Step: 6
Training loss: 1.5340514183044434
Validation loss: 2.151740218202273

Epoch: 5| Step: 7
Training loss: 1.9750936031341553
Validation loss: 2.1378620068232217

Epoch: 5| Step: 8
Training loss: 2.1406848430633545
Validation loss: 2.138152321179708

Epoch: 5| Step: 9
Training loss: 1.8061119318008423
Validation loss: 2.1192936152219772

Epoch: 5| Step: 10
Training loss: 2.0900418758392334
Validation loss: 2.1296506375074387

Epoch: 5| Step: 11
Training loss: 2.1064231395721436
Validation loss: 2.1219269831975303

Epoch: 245| Step: 0
Training loss: 2.1891040802001953
Validation loss: 2.1326677401860556

Epoch: 5| Step: 1
Training loss: 2.3567728996276855
Validation loss: 2.11962861319383

Epoch: 5| Step: 2
Training loss: 1.3893760442733765
Validation loss: 2.137906084458033

Epoch: 5| Step: 3
Training loss: 1.6865386962890625
Validation loss: 2.1653080781300864

Epoch: 5| Step: 4
Training loss: 1.951280951499939
Validation loss: 2.1692816019058228

Epoch: 5| Step: 5
Training loss: 1.3501088619232178
Validation loss: 2.1641222834587097

Epoch: 5| Step: 6
Training loss: 2.136657953262329
Validation loss: 2.1897773693005242

Epoch: 5| Step: 7
Training loss: 1.692330002784729
Validation loss: 2.173776537179947

Epoch: 5| Step: 8
Training loss: 2.205591917037964
Validation loss: 2.145575831333796

Epoch: 5| Step: 9
Training loss: 1.853050947189331
Validation loss: 2.1495556086301804

Epoch: 5| Step: 10
Training loss: 2.030641555786133
Validation loss: 2.131126011411349

Epoch: 5| Step: 11
Training loss: 2.5288138389587402
Validation loss: 2.1368131736914315

Epoch: 246| Step: 0
Training loss: 1.7276191711425781
Validation loss: 2.1266418049732843

Epoch: 5| Step: 1
Training loss: 1.6684166193008423
Validation loss: 2.1176162511110306

Epoch: 5| Step: 2
Training loss: 2.2690823078155518
Validation loss: 2.1147937128941217

Epoch: 5| Step: 3
Training loss: 2.1300418376922607
Validation loss: 2.1200143744548163

Epoch: 5| Step: 4
Training loss: 1.5288981199264526
Validation loss: 2.116355761885643

Epoch: 5| Step: 5
Training loss: 1.7615123987197876
Validation loss: 2.1163700918356576

Epoch: 5| Step: 6
Training loss: 1.8846855163574219
Validation loss: 2.1203019320964813

Epoch: 5| Step: 7
Training loss: 1.741999626159668
Validation loss: 2.1393637359142303

Epoch: 5| Step: 8
Training loss: 2.6191482543945312
Validation loss: 2.1248199144999185

Epoch: 5| Step: 9
Training loss: 1.6720664501190186
Validation loss: 2.128189822038015

Epoch: 5| Step: 10
Training loss: 1.8615548610687256
Validation loss: 2.1343200504779816

Epoch: 5| Step: 11
Training loss: 1.564745545387268
Validation loss: 2.1438250044981637

Epoch: 247| Step: 0
Training loss: 1.5145760774612427
Validation loss: 2.1446048617362976

Epoch: 5| Step: 1
Training loss: 2.065342426300049
Validation loss: 2.1372578839461007

Epoch: 5| Step: 2
Training loss: 2.050612688064575
Validation loss: 2.133458733558655

Epoch: 5| Step: 3
Training loss: 1.6947448253631592
Validation loss: 2.182930519183477

Epoch: 5| Step: 4
Training loss: 1.4685137271881104
Validation loss: 2.1683705846468606

Epoch: 5| Step: 5
Training loss: 1.842567801475525
Validation loss: 2.1614562571048737

Epoch: 5| Step: 6
Training loss: 2.4757256507873535
Validation loss: 2.1776252835989

Epoch: 5| Step: 7
Training loss: 2.4844982624053955
Validation loss: 2.1720651040474572

Epoch: 5| Step: 8
Training loss: 1.7769352197647095
Validation loss: 2.1999505112568536

Epoch: 5| Step: 9
Training loss: 1.626848816871643
Validation loss: 2.1797547141710916

Epoch: 5| Step: 10
Training loss: 1.885711669921875
Validation loss: 2.158486316601435

Epoch: 5| Step: 11
Training loss: 0.8233655691146851
Validation loss: 2.146190678079923

Epoch: 248| Step: 0
Training loss: 2.526843547821045
Validation loss: 2.1154786298672357

Epoch: 5| Step: 1
Training loss: 1.803280234336853
Validation loss: 2.1056412756443024

Epoch: 5| Step: 2
Training loss: 2.419102907180786
Validation loss: 2.0851584722598395

Epoch: 5| Step: 3
Training loss: 1.6622226238250732
Validation loss: 2.084510490298271

Epoch: 5| Step: 4
Training loss: 2.4575185775756836
Validation loss: 2.0896240770816803

Epoch: 5| Step: 5
Training loss: 1.5455235242843628
Validation loss: 2.0936101973056793

Epoch: 5| Step: 6
Training loss: 2.4342055320739746
Validation loss: 2.0821730891863504

Epoch: 5| Step: 7
Training loss: 1.9922187328338623
Validation loss: 2.0920566618442535

Epoch: 5| Step: 8
Training loss: 1.5288124084472656
Validation loss: 2.1089916229248047

Epoch: 5| Step: 9
Training loss: 1.4623792171478271
Validation loss: 2.1116180568933487

Epoch: 5| Step: 10
Training loss: 1.3670623302459717
Validation loss: 2.0997059444586434

Epoch: 5| Step: 11
Training loss: 1.7511496543884277
Validation loss: 2.128327419360479

Epoch: 249| Step: 0
Training loss: 1.9491252899169922
Validation loss: 2.1473123033841452

Epoch: 5| Step: 1
Training loss: 2.2946929931640625
Validation loss: 2.1499179750680923

Epoch: 5| Step: 2
Training loss: 1.613975167274475
Validation loss: 2.1873119374116263

Epoch: 5| Step: 3
Training loss: 1.8417003154754639
Validation loss: 2.1771512031555176

Epoch: 5| Step: 4
Training loss: 2.330927610397339
Validation loss: 2.1641511817773185

Epoch: 5| Step: 5
Training loss: 1.7225433588027954
Validation loss: 2.1896929691235223

Epoch: 5| Step: 6
Training loss: 1.9335148334503174
Validation loss: 2.190995146830877

Epoch: 5| Step: 7
Training loss: 1.5294891595840454
Validation loss: 2.1698648929595947

Epoch: 5| Step: 8
Training loss: 2.086648464202881
Validation loss: 2.166523983081182

Epoch: 5| Step: 9
Training loss: 1.343617558479309
Validation loss: 2.1804328511158624

Epoch: 5| Step: 10
Training loss: 2.321033000946045
Validation loss: 2.1410010556379953

Epoch: 5| Step: 11
Training loss: 0.5953813791275024
Validation loss: 2.1370201905568442

Epoch: 250| Step: 0
Training loss: 1.6599795818328857
Validation loss: 2.1225475569566092

Epoch: 5| Step: 1
Training loss: 1.877478837966919
Validation loss: 2.124688367048899

Epoch: 5| Step: 2
Training loss: 2.0612196922302246
Validation loss: 2.1308545668919883

Epoch: 5| Step: 3
Training loss: 1.2871558666229248
Validation loss: 2.108170837163925

Epoch: 5| Step: 4
Training loss: 2.088107109069824
Validation loss: 2.1199520577987037

Epoch: 5| Step: 5
Training loss: 1.754178762435913
Validation loss: 2.12695903579394

Epoch: 5| Step: 6
Training loss: 1.540651559829712
Validation loss: 2.116501897573471

Epoch: 5| Step: 7
Training loss: 2.6916911602020264
Validation loss: 2.136493444442749

Epoch: 5| Step: 8
Training loss: 2.0447335243225098
Validation loss: 2.1296721696853638

Epoch: 5| Step: 9
Training loss: 1.4586713314056396
Validation loss: 2.137080043554306

Epoch: 5| Step: 10
Training loss: 2.112457275390625
Validation loss: 2.149939944346746

Epoch: 5| Step: 11
Training loss: 1.5405254364013672
Validation loss: 2.1653837263584137

Epoch: 251| Step: 0
Training loss: 2.1346325874328613
Validation loss: 2.178252935409546

Epoch: 5| Step: 1
Training loss: 2.260624885559082
Validation loss: 2.1788716117540994

Epoch: 5| Step: 2
Training loss: 1.2397000789642334
Validation loss: 2.1509103079636893

Epoch: 5| Step: 3
Training loss: 2.007506847381592
Validation loss: 2.171750803788503

Epoch: 5| Step: 4
Training loss: 1.9711183309555054
Validation loss: 2.151069308320681

Epoch: 5| Step: 5
Training loss: 1.4626126289367676
Validation loss: 2.1295946836471558

Epoch: 5| Step: 6
Training loss: 1.913884162902832
Validation loss: 2.147621045509974

Epoch: 5| Step: 7
Training loss: 2.414928674697876
Validation loss: 2.150469104448954

Epoch: 5| Step: 8
Training loss: 2.153782606124878
Validation loss: 2.127255360285441

Epoch: 5| Step: 9
Training loss: 1.3344885110855103
Validation loss: 2.128495082259178

Epoch: 5| Step: 10
Training loss: 1.870080590248108
Validation loss: 2.1252500861883163

Epoch: 5| Step: 11
Training loss: 1.1415358781814575
Validation loss: 2.1121866106987

Epoch: 252| Step: 0
Training loss: 1.4621028900146484
Validation loss: 2.120526264111201

Epoch: 5| Step: 1
Training loss: 2.5052649974823
Validation loss: 2.141303300857544

Epoch: 5| Step: 2
Training loss: 1.8328030109405518
Validation loss: 2.1342007418473563

Epoch: 5| Step: 3
Training loss: 2.1064696311950684
Validation loss: 2.1298051277796426

Epoch: 5| Step: 4
Training loss: 1.5545809268951416
Validation loss: 2.151065637667974

Epoch: 5| Step: 5
Training loss: 1.3603800535202026
Validation loss: 2.1475322792927423

Epoch: 5| Step: 6
Training loss: 1.9557456970214844
Validation loss: 2.146186207731565

Epoch: 5| Step: 7
Training loss: 2.10235595703125
Validation loss: 2.1607810159524283

Epoch: 5| Step: 8
Training loss: 1.6772792339324951
Validation loss: 2.1360626816749573

Epoch: 5| Step: 9
Training loss: 1.8116047382354736
Validation loss: 2.148636738459269

Epoch: 5| Step: 10
Training loss: 2.0429999828338623
Validation loss: 2.138369550307592

Epoch: 5| Step: 11
Training loss: 1.5420637130737305
Validation loss: 2.134122063716253

Epoch: 253| Step: 0
Training loss: 1.9716403484344482
Validation loss: 2.130856846769651

Epoch: 5| Step: 1
Training loss: 1.9833484888076782
Validation loss: 2.1532378842433295

Epoch: 5| Step: 2
Training loss: 1.2821146249771118
Validation loss: 2.1570156862338385

Epoch: 5| Step: 3
Training loss: 2.689262628555298
Validation loss: 2.1505198776721954

Epoch: 5| Step: 4
Training loss: 1.8978595733642578
Validation loss: 2.148916239539782

Epoch: 5| Step: 5
Training loss: 1.7251522541046143
Validation loss: 2.117304712533951

Epoch: 5| Step: 6
Training loss: 1.9923919439315796
Validation loss: 2.1216075966755548

Epoch: 5| Step: 7
Training loss: 1.9204740524291992
Validation loss: 2.1276877522468567

Epoch: 5| Step: 8
Training loss: 1.4189873933792114
Validation loss: 2.1272797534863153

Epoch: 5| Step: 9
Training loss: 1.966393232345581
Validation loss: 2.1150447875261307

Epoch: 5| Step: 10
Training loss: 1.7698109149932861
Validation loss: 2.1179477671782174

Epoch: 5| Step: 11
Training loss: 1.4250214099884033
Validation loss: 2.123461276292801

Epoch: 254| Step: 0
Training loss: 1.969232201576233
Validation loss: 2.1379924515883126

Epoch: 5| Step: 1
Training loss: 1.6717703342437744
Validation loss: 2.1249257971843085

Epoch: 5| Step: 2
Training loss: 1.9809398651123047
Validation loss: 2.1510991851488748

Epoch: 5| Step: 3
Training loss: 1.6635280847549438
Validation loss: 2.1469254046678543

Epoch: 5| Step: 4
Training loss: 1.8108984231948853
Validation loss: 2.1513177255789437

Epoch: 5| Step: 5
Training loss: 1.7430331707000732
Validation loss: 2.1254035035769143

Epoch: 5| Step: 6
Training loss: 1.7615442276000977
Validation loss: 2.1324698527654014

Epoch: 5| Step: 7
Training loss: 2.8894190788269043
Validation loss: 2.1132145623366037

Epoch: 5| Step: 8
Training loss: 2.0681896209716797
Validation loss: 2.126767635345459

Epoch: 5| Step: 9
Training loss: 1.5064127445220947
Validation loss: 2.10453595717748

Epoch: 5| Step: 10
Training loss: 1.5242929458618164
Validation loss: 2.1328763564427695

Epoch: 5| Step: 11
Training loss: 1.5576248168945312
Validation loss: 2.1232912490765252

Epoch: 255| Step: 0
Training loss: 2.274242877960205
Validation loss: 2.125182723005613

Epoch: 5| Step: 1
Training loss: 1.6302669048309326
Validation loss: 2.1244543492794037

Epoch: 5| Step: 2
Training loss: 1.6143646240234375
Validation loss: 2.1428500413894653

Epoch: 5| Step: 3
Training loss: 1.6936941146850586
Validation loss: 2.1366177995999656

Epoch: 5| Step: 4
Training loss: 1.9806684255599976
Validation loss: 2.144100253780683

Epoch: 5| Step: 5
Training loss: 1.841007947921753
Validation loss: 2.150210162003835

Epoch: 5| Step: 6
Training loss: 2.2018344402313232
Validation loss: 2.1391541659832

Epoch: 5| Step: 7
Training loss: 1.8117659091949463
Validation loss: 2.134338249762853

Epoch: 5| Step: 8
Training loss: 1.958406686782837
Validation loss: 2.1481731484333673

Epoch: 5| Step: 9
Training loss: 1.645835518836975
Validation loss: 2.1548262586196265

Epoch: 5| Step: 10
Training loss: 1.5077029466629028
Validation loss: 2.132744073867798

Epoch: 5| Step: 11
Training loss: 2.246163845062256
Validation loss: 2.1529265542825065

Epoch: 256| Step: 0
Training loss: 1.9765636920928955
Validation loss: 2.1410116901000342

Epoch: 5| Step: 1
Training loss: 1.5786445140838623
Validation loss: 2.1589109947284064

Epoch: 5| Step: 2
Training loss: 1.6462535858154297
Validation loss: 2.1429783205191293

Epoch: 5| Step: 3
Training loss: 1.757338285446167
Validation loss: 2.1293992896874747

Epoch: 5| Step: 4
Training loss: 1.9518101215362549
Validation loss: 2.1363235811392465

Epoch: 5| Step: 5
Training loss: 1.6632194519042969
Validation loss: 2.1272381047407785

Epoch: 5| Step: 6
Training loss: 2.4944751262664795
Validation loss: 2.11962561806043

Epoch: 5| Step: 7
Training loss: 1.714303731918335
Validation loss: 2.1396147509415946

Epoch: 5| Step: 8
Training loss: 1.621891736984253
Validation loss: 2.11773145198822

Epoch: 5| Step: 9
Training loss: 1.7081495523452759
Validation loss: 2.1287655234336853

Epoch: 5| Step: 10
Training loss: 2.2468647956848145
Validation loss: 2.135229547818502

Epoch: 5| Step: 11
Training loss: 0.9550249576568604
Validation loss: 2.1205925047397614

Epoch: 257| Step: 0
Training loss: 1.9628082513809204
Validation loss: 2.1315501034259796

Epoch: 5| Step: 1
Training loss: 1.3703750371932983
Validation loss: 2.13484958310922

Epoch: 5| Step: 2
Training loss: 2.0767292976379395
Validation loss: 2.124825825293859

Epoch: 5| Step: 3
Training loss: 1.749301552772522
Validation loss: 2.134382590651512

Epoch: 5| Step: 4
Training loss: 1.2493751049041748
Validation loss: 2.129796331127485

Epoch: 5| Step: 5
Training loss: 2.9460384845733643
Validation loss: 2.1376320322354636

Epoch: 5| Step: 6
Training loss: 1.59116530418396
Validation loss: 2.1567504902680716

Epoch: 5| Step: 7
Training loss: 1.9078967571258545
Validation loss: 2.143019219239553

Epoch: 5| Step: 8
Training loss: 1.485339879989624
Validation loss: 2.155033906300863

Epoch: 5| Step: 9
Training loss: 1.865037202835083
Validation loss: 2.151230509082476

Epoch: 5| Step: 10
Training loss: 1.6522903442382812
Validation loss: 2.1516456504662833

Epoch: 5| Step: 11
Training loss: 2.697230339050293
Validation loss: 2.1437634428342185

Epoch: 258| Step: 0
Training loss: 2.291358470916748
Validation loss: 2.1491724054018655

Epoch: 5| Step: 1
Training loss: 1.5020372867584229
Validation loss: 2.1488462388515472

Epoch: 5| Step: 2
Training loss: 2.0085020065307617
Validation loss: 2.1465276877085366

Epoch: 5| Step: 3
Training loss: 1.5179321765899658
Validation loss: 2.1538774271806083

Epoch: 5| Step: 4
Training loss: 2.3435072898864746
Validation loss: 2.158991520603498

Epoch: 5| Step: 5
Training loss: 1.7841228246688843
Validation loss: 2.172815571228663

Epoch: 5| Step: 6
Training loss: 1.7638517618179321
Validation loss: 2.171647618214289

Epoch: 5| Step: 7
Training loss: 1.7775599956512451
Validation loss: 2.1499899129072824

Epoch: 5| Step: 8
Training loss: 1.5498809814453125
Validation loss: 2.157361884911855

Epoch: 5| Step: 9
Training loss: 1.7440626621246338
Validation loss: 2.1422735452651978

Epoch: 5| Step: 10
Training loss: 2.0858187675476074
Validation loss: 2.151784598827362

Epoch: 5| Step: 11
Training loss: 0.9876911044120789
Validation loss: 2.1753641068935394

Epoch: 259| Step: 0
Training loss: 2.089719295501709
Validation loss: 2.141542966167132

Epoch: 5| Step: 1
Training loss: 1.6603095531463623
Validation loss: 2.147490451733271

Epoch: 5| Step: 2
Training loss: 1.647709608078003
Validation loss: 2.1503570129474006

Epoch: 5| Step: 3
Training loss: 1.681884765625
Validation loss: 2.154232377807299

Epoch: 5| Step: 4
Training loss: 2.020615816116333
Validation loss: 2.129776751001676

Epoch: 5| Step: 5
Training loss: 1.297104835510254
Validation loss: 2.1506460259358087

Epoch: 5| Step: 6
Training loss: 1.5876926183700562
Validation loss: 2.1663189828395844

Epoch: 5| Step: 7
Training loss: 2.5705127716064453
Validation loss: 2.160906419157982

Epoch: 5| Step: 8
Training loss: 2.5536205768585205
Validation loss: 2.165483772754669

Epoch: 5| Step: 9
Training loss: 1.7891616821289062
Validation loss: 2.1298747956752777

Epoch: 5| Step: 10
Training loss: 1.3541195392608643
Validation loss: 2.1436248819033303

Epoch: 5| Step: 11
Training loss: 1.9190152883529663
Validation loss: 2.141903574268023

Epoch: 260| Step: 0
Training loss: 1.591967225074768
Validation loss: 2.152425224582354

Epoch: 5| Step: 1
Training loss: 2.18741512298584
Validation loss: 2.151056836048762

Epoch: 5| Step: 2
Training loss: 1.3805372714996338
Validation loss: 2.1287474731604257

Epoch: 5| Step: 3
Training loss: 1.7842738628387451
Validation loss: 2.1216488083203635

Epoch: 5| Step: 4
Training loss: 2.088042736053467
Validation loss: 2.1373225847880044

Epoch: 5| Step: 5
Training loss: 2.402303695678711
Validation loss: 2.134185880422592

Epoch: 5| Step: 6
Training loss: 2.0950591564178467
Validation loss: 2.1259888261556625

Epoch: 5| Step: 7
Training loss: 1.6524555683135986
Validation loss: 2.1249995678663254

Epoch: 5| Step: 8
Training loss: 1.9193637371063232
Validation loss: 2.143288572629293

Epoch: 5| Step: 9
Training loss: 2.24812650680542
Validation loss: 2.1560496985912323

Epoch: 5| Step: 10
Training loss: 1.186311960220337
Validation loss: 2.1607188433408737

Epoch: 5| Step: 11
Training loss: 1.2541582584381104
Validation loss: 2.1634378135204315

Epoch: 261| Step: 0
Training loss: 1.782107949256897
Validation loss: 2.1830492118994393

Epoch: 5| Step: 1
Training loss: 2.6070539951324463
Validation loss: 2.1691516240437827

Epoch: 5| Step: 2
Training loss: 2.2032997608184814
Validation loss: 2.177664170662562

Epoch: 5| Step: 3
Training loss: 1.6614761352539062
Validation loss: 2.1881399154663086

Epoch: 5| Step: 4
Training loss: 1.4910047054290771
Validation loss: 2.1724313298861184

Epoch: 5| Step: 5
Training loss: 1.7142003774642944
Validation loss: 2.1635132133960724

Epoch: 5| Step: 6
Training loss: 1.371671438217163
Validation loss: 2.1828728318214417

Epoch: 5| Step: 7
Training loss: 1.982561707496643
Validation loss: 2.1497461199760437

Epoch: 5| Step: 8
Training loss: 1.614519476890564
Validation loss: 2.1459510872761407

Epoch: 5| Step: 9
Training loss: 2.1896719932556152
Validation loss: 2.125887463490168

Epoch: 5| Step: 10
Training loss: 1.4564402103424072
Validation loss: 2.120584080616633

Epoch: 5| Step: 11
Training loss: 1.7950100898742676
Validation loss: 2.116856276988983

Epoch: 262| Step: 0
Training loss: 1.8845252990722656
Validation loss: 2.109852304061254

Epoch: 5| Step: 1
Training loss: 1.6352113485336304
Validation loss: 2.1206058015426

Epoch: 5| Step: 2
Training loss: 1.702873945236206
Validation loss: 2.115701670447985

Epoch: 5| Step: 3
Training loss: 2.3794479370117188
Validation loss: 2.1238430539766946

Epoch: 5| Step: 4
Training loss: 1.9369518756866455
Validation loss: 2.116396129131317

Epoch: 5| Step: 5
Training loss: 1.7149772644042969
Validation loss: 2.1155702273050943

Epoch: 5| Step: 6
Training loss: 1.6952028274536133
Validation loss: 2.1385368953148522

Epoch: 5| Step: 7
Training loss: 1.676719069480896
Validation loss: 2.149823228518168

Epoch: 5| Step: 8
Training loss: 1.634365439414978
Validation loss: 2.1421855290730796

Epoch: 5| Step: 9
Training loss: 2.0543644428253174
Validation loss: 2.153744916121165

Epoch: 5| Step: 10
Training loss: 2.224625825881958
Validation loss: 2.1646857857704163

Epoch: 5| Step: 11
Training loss: 1.3124346733093262
Validation loss: 2.156066050132116

Epoch: 263| Step: 0
Training loss: 1.6869838237762451
Validation loss: 2.185882488886515

Epoch: 5| Step: 1
Training loss: 1.8622350692749023
Validation loss: 2.145401025811831

Epoch: 5| Step: 2
Training loss: 1.6680513620376587
Validation loss: 2.1548550029595694

Epoch: 5| Step: 3
Training loss: 2.216160535812378
Validation loss: 2.1630010902881622

Epoch: 5| Step: 4
Training loss: 1.4990379810333252
Validation loss: 2.1636289606491723

Epoch: 5| Step: 5
Training loss: 2.004060745239258
Validation loss: 2.170705368121465

Epoch: 5| Step: 6
Training loss: 2.0126473903656006
Validation loss: 2.140981689095497

Epoch: 5| Step: 7
Training loss: 1.3469429016113281
Validation loss: 2.136239151159922

Epoch: 5| Step: 8
Training loss: 2.06103253364563
Validation loss: 2.15827610095342

Epoch: 5| Step: 9
Training loss: 1.6081445217132568
Validation loss: 2.156240498026212

Epoch: 5| Step: 10
Training loss: 1.9547045230865479
Validation loss: 2.152636076013247

Epoch: 5| Step: 11
Training loss: 2.277667284011841
Validation loss: 2.1510182271401086

Epoch: 264| Step: 0
Training loss: 1.5466169118881226
Validation loss: 2.1518028577168784

Epoch: 5| Step: 1
Training loss: 1.568856954574585
Validation loss: 2.1203768948713937

Epoch: 5| Step: 2
Training loss: 2.0894789695739746
Validation loss: 2.1220671832561493

Epoch: 5| Step: 3
Training loss: 1.8489784002304077
Validation loss: 2.109067976474762

Epoch: 5| Step: 4
Training loss: 1.9108041524887085
Validation loss: 2.113536352912585

Epoch: 5| Step: 5
Training loss: 2.2147340774536133
Validation loss: 2.106537068883578

Epoch: 5| Step: 6
Training loss: 2.305527448654175
Validation loss: 2.0987208584944406

Epoch: 5| Step: 7
Training loss: 2.041015148162842
Validation loss: 2.1033694247404733

Epoch: 5| Step: 8
Training loss: 1.1937220096588135
Validation loss: 2.0993141333262124

Epoch: 5| Step: 9
Training loss: 2.5108418464660645
Validation loss: 2.1066162437200546

Epoch: 5| Step: 10
Training loss: 2.136134624481201
Validation loss: 2.1162328769763312

Epoch: 5| Step: 11
Training loss: 2.8854780197143555
Validation loss: 2.11178886393706

Epoch: 265| Step: 0
Training loss: 2.2664194107055664
Validation loss: 2.0966312686602273

Epoch: 5| Step: 1
Training loss: 1.2854799032211304
Validation loss: 2.105584422747294

Epoch: 5| Step: 2
Training loss: 1.5224422216415405
Validation loss: 2.1040263175964355

Epoch: 5| Step: 3
Training loss: 2.3373312950134277
Validation loss: 2.09951713681221

Epoch: 5| Step: 4
Training loss: 1.8942493200302124
Validation loss: 2.122473329305649

Epoch: 5| Step: 5
Training loss: 1.2788654565811157
Validation loss: 2.107143610715866

Epoch: 5| Step: 6
Training loss: 2.049704074859619
Validation loss: 2.1225215097268424

Epoch: 5| Step: 7
Training loss: 1.6534512042999268
Validation loss: 2.1249652206897736

Epoch: 5| Step: 8
Training loss: 1.782109022140503
Validation loss: 2.1416640281677246

Epoch: 5| Step: 9
Training loss: 2.025991916656494
Validation loss: 2.128122250239054

Epoch: 5| Step: 10
Training loss: 2.277406692504883
Validation loss: 2.127597148219744

Epoch: 5| Step: 11
Training loss: 2.1384716033935547
Validation loss: 2.125559647878011

Epoch: 266| Step: 0
Training loss: 2.1217143535614014
Validation loss: 2.1130697627862296

Epoch: 5| Step: 1
Training loss: 1.729998230934143
Validation loss: 2.1203283816576004

Epoch: 5| Step: 2
Training loss: 2.0704126358032227
Validation loss: 2.1310793310403824

Epoch: 5| Step: 3
Training loss: 1.5360478162765503
Validation loss: 2.1272239983081818

Epoch: 5| Step: 4
Training loss: 2.249929428100586
Validation loss: 2.122659424940745

Epoch: 5| Step: 5
Training loss: 1.709985375404358
Validation loss: 2.136444096763929

Epoch: 5| Step: 6
Training loss: 1.72879958152771
Validation loss: 2.1347188651561737

Epoch: 5| Step: 7
Training loss: 1.5120971202850342
Validation loss: 2.1398450483878455

Epoch: 5| Step: 8
Training loss: 1.7421867847442627
Validation loss: 2.1379100730021796

Epoch: 5| Step: 9
Training loss: 1.7661851644515991
Validation loss: 2.162616034348806

Epoch: 5| Step: 10
Training loss: 1.9405978918075562
Validation loss: 2.1826931883891425

Epoch: 5| Step: 11
Training loss: 0.9672139883041382
Validation loss: 2.163864344358444

Epoch: 267| Step: 0
Training loss: 2.196450710296631
Validation loss: 2.1661685705184937

Epoch: 5| Step: 1
Training loss: 1.7902590036392212
Validation loss: 2.173765609661738

Epoch: 5| Step: 2
Training loss: 2.2432913780212402
Validation loss: 2.1840810229380927

Epoch: 5| Step: 3
Training loss: 2.3805174827575684
Validation loss: 2.1563352843125663

Epoch: 5| Step: 4
Training loss: 1.2184116840362549
Validation loss: 2.174289961655935

Epoch: 5| Step: 5
Training loss: 1.63675057888031
Validation loss: 2.1507075826327005

Epoch: 5| Step: 6
Training loss: 1.3934876918792725
Validation loss: 2.203136737147967

Epoch: 5| Step: 7
Training loss: 2.2523953914642334
Validation loss: 2.1950553009907403

Epoch: 5| Step: 8
Training loss: 1.485087513923645
Validation loss: 2.2380619049072266

Epoch: 5| Step: 9
Training loss: 1.6200271844863892
Validation loss: 2.2148676117261252

Epoch: 5| Step: 10
Training loss: 1.9631969928741455
Validation loss: 2.2405059734980264

Epoch: 5| Step: 11
Training loss: 1.5052568912506104
Validation loss: 2.203636626402537

Epoch: 268| Step: 0
Training loss: 1.784419059753418
Validation loss: 2.216156537334124

Epoch: 5| Step: 1
Training loss: 2.3063201904296875
Validation loss: 2.1818148344755173

Epoch: 5| Step: 2
Training loss: 1.7410110235214233
Validation loss: 2.164649024605751

Epoch: 5| Step: 3
Training loss: 1.514101266860962
Validation loss: 2.1655841767787933

Epoch: 5| Step: 4
Training loss: 1.8290361166000366
Validation loss: 2.1587941298882165

Epoch: 5| Step: 5
Training loss: 1.9022748470306396
Validation loss: 2.15617265800635

Epoch: 5| Step: 6
Training loss: 2.2060463428497314
Validation loss: 2.1597231527169547

Epoch: 5| Step: 7
Training loss: 1.5426616668701172
Validation loss: 2.1521831502517066

Epoch: 5| Step: 8
Training loss: 1.396980881690979
Validation loss: 2.167112812399864

Epoch: 5| Step: 9
Training loss: 1.8244476318359375
Validation loss: 2.168231040239334

Epoch: 5| Step: 10
Training loss: 1.8967182636260986
Validation loss: 2.2059858441352844

Epoch: 5| Step: 11
Training loss: 4.522405624389648
Validation loss: 2.204859266678492

Epoch: 269| Step: 0
Training loss: 1.5480425357818604
Validation loss: 2.1981838792562485

Epoch: 5| Step: 1
Training loss: 2.715529203414917
Validation loss: 2.2227776547273

Epoch: 5| Step: 2
Training loss: 1.4153945446014404
Validation loss: 2.206878677010536

Epoch: 5| Step: 3
Training loss: 1.8163187503814697
Validation loss: 2.186917473872503

Epoch: 5| Step: 4
Training loss: 2.1024117469787598
Validation loss: 2.1748594542344413

Epoch: 5| Step: 5
Training loss: 1.816441535949707
Validation loss: 2.2006580382585526

Epoch: 5| Step: 6
Training loss: 1.4386242628097534
Validation loss: 2.1841766834259033

Epoch: 5| Step: 7
Training loss: 2.066760540008545
Validation loss: 2.1861224869887033

Epoch: 5| Step: 8
Training loss: 2.157020092010498
Validation loss: 2.2218110859394073

Epoch: 5| Step: 9
Training loss: 2.1362881660461426
Validation loss: 2.185858721534411

Epoch: 5| Step: 10
Training loss: 2.1861732006073
Validation loss: 2.1619298656781516

Epoch: 5| Step: 11
Training loss: 2.3362534046173096
Validation loss: 2.1422522018353143

Epoch: 270| Step: 0
Training loss: 2.1021311283111572
Validation loss: 2.1350420067707696

Epoch: 5| Step: 1
Training loss: 1.9121192693710327
Validation loss: 2.1313256124655404

Epoch: 5| Step: 2
Training loss: 1.7494529485702515
Validation loss: 2.116516758998235

Epoch: 5| Step: 3
Training loss: 1.6963304281234741
Validation loss: 2.1136750131845474

Epoch: 5| Step: 4
Training loss: 2.230587959289551
Validation loss: 2.126632367571195

Epoch: 5| Step: 5
Training loss: 1.7626838684082031
Validation loss: 2.123318682114283

Epoch: 5| Step: 6
Training loss: 2.1258742809295654
Validation loss: 2.1288525660832724

Epoch: 5| Step: 7
Training loss: 2.1369168758392334
Validation loss: 2.124226545294126

Epoch: 5| Step: 8
Training loss: 2.4268088340759277
Validation loss: 2.1212992668151855

Epoch: 5| Step: 9
Training loss: 1.8868019580841064
Validation loss: 2.1305272380510965

Epoch: 5| Step: 10
Training loss: 1.4117199182510376
Validation loss: 2.1349570651849112

Epoch: 5| Step: 11
Training loss: 1.1505268812179565
Validation loss: 2.159089451034864

Epoch: 271| Step: 0
Training loss: 1.418716311454773
Validation loss: 2.1696319033702216

Epoch: 5| Step: 1
Training loss: 2.108867645263672
Validation loss: 2.183701982100805

Epoch: 5| Step: 2
Training loss: 1.5448129177093506
Validation loss: 2.2185157388448715

Epoch: 5| Step: 3
Training loss: 2.021345853805542
Validation loss: 2.2244963943958282

Epoch: 5| Step: 4
Training loss: 1.714455008506775
Validation loss: 2.223780552546183

Epoch: 5| Step: 5
Training loss: 2.6024138927459717
Validation loss: 2.2375394801298776

Epoch: 5| Step: 6
Training loss: 1.7768278121948242
Validation loss: 2.2415454387664795

Epoch: 5| Step: 7
Training loss: 2.0769381523132324
Validation loss: 2.233867218097051

Epoch: 5| Step: 8
Training loss: 1.80574631690979
Validation loss: 2.242698907852173

Epoch: 5| Step: 9
Training loss: 1.4754993915557861
Validation loss: 2.2302629351615906

Epoch: 5| Step: 10
Training loss: 2.2326927185058594
Validation loss: 2.2258820881446204

Epoch: 5| Step: 11
Training loss: 1.3902997970581055
Validation loss: 2.2092958291371665

Epoch: 272| Step: 0
Training loss: 2.3610758781433105
Validation loss: 2.1917008260885873

Epoch: 5| Step: 1
Training loss: 1.6675279140472412
Validation loss: 2.1814159651597342

Epoch: 5| Step: 2
Training loss: 1.6917930841445923
Validation loss: 2.1597074468930564

Epoch: 5| Step: 3
Training loss: 2.1341278553009033
Validation loss: 2.1573226302862167

Epoch: 5| Step: 4
Training loss: 2.000429630279541
Validation loss: 2.158385028441747

Epoch: 5| Step: 5
Training loss: 2.0922069549560547
Validation loss: 2.1593027810255685

Epoch: 5| Step: 6
Training loss: 1.356086015701294
Validation loss: 2.1710951377948127

Epoch: 5| Step: 7
Training loss: 1.84734308719635
Validation loss: 2.1756412237882614

Epoch: 5| Step: 8
Training loss: 1.9541904926300049
Validation loss: 2.1768739422162375

Epoch: 5| Step: 9
Training loss: 1.9872901439666748
Validation loss: 2.177739828824997

Epoch: 5| Step: 10
Training loss: 1.1634302139282227
Validation loss: 2.1759939094384513

Epoch: 5| Step: 11
Training loss: 0.9274868965148926
Validation loss: 2.165175418059031

Epoch: 273| Step: 0
Training loss: 1.8559799194335938
Validation loss: 2.183183431625366

Epoch: 5| Step: 1
Training loss: 2.1802361011505127
Validation loss: 2.1790294498205185

Epoch: 5| Step: 2
Training loss: 1.978560209274292
Validation loss: 2.1863639106353125

Epoch: 5| Step: 3
Training loss: 1.2800633907318115
Validation loss: 2.1579691817363105

Epoch: 5| Step: 4
Training loss: 1.6678342819213867
Validation loss: 2.174157922466596

Epoch: 5| Step: 5
Training loss: 1.7346012592315674
Validation loss: 2.1664203653732934

Epoch: 5| Step: 6
Training loss: 2.035193920135498
Validation loss: 2.1854899674654007

Epoch: 5| Step: 7
Training loss: 1.7637760639190674
Validation loss: 2.166230375568072

Epoch: 5| Step: 8
Training loss: 1.7770254611968994
Validation loss: 2.1758261819680533

Epoch: 5| Step: 9
Training loss: 1.9269237518310547
Validation loss: 2.1785447746515274

Epoch: 5| Step: 10
Training loss: 1.5119507312774658
Validation loss: 2.1832514305909476

Epoch: 5| Step: 11
Training loss: 2.0802950859069824
Validation loss: 2.1887405614058175

Epoch: 274| Step: 0
Training loss: 1.7517082691192627
Validation loss: 2.1812353134155273

Epoch: 5| Step: 1
Training loss: 1.7606881856918335
Validation loss: 2.1935455997784934

Epoch: 5| Step: 2
Training loss: 2.1784186363220215
Validation loss: 2.1897761871417365

Epoch: 5| Step: 3
Training loss: 1.6868482828140259
Validation loss: 2.1971629858016968

Epoch: 5| Step: 4
Training loss: 1.5802435874938965
Validation loss: 2.1787379682064056

Epoch: 5| Step: 5
Training loss: 1.3831455707550049
Validation loss: 2.1869315753380456

Epoch: 5| Step: 6
Training loss: 2.012256622314453
Validation loss: 2.1795819948116937

Epoch: 5| Step: 7
Training loss: 1.782159447669983
Validation loss: 2.2022861689329147

Epoch: 5| Step: 8
Training loss: 1.8826932907104492
Validation loss: 2.185466095805168

Epoch: 5| Step: 9
Training loss: 1.4972422122955322
Validation loss: 2.1916977862517038

Epoch: 5| Step: 10
Training loss: 2.5129587650299072
Validation loss: 2.179908146460851

Epoch: 5| Step: 11
Training loss: 0.4623699188232422
Validation loss: 2.1861698230107627

Epoch: 275| Step: 0
Training loss: 1.5117700099945068
Validation loss: 2.1960200369358063

Epoch: 5| Step: 1
Training loss: 1.7898540496826172
Validation loss: 2.2042907774448395

Epoch: 5| Step: 2
Training loss: 1.570225715637207
Validation loss: 2.1933790196975074

Epoch: 5| Step: 3
Training loss: 1.3349438905715942
Validation loss: 2.208195755879084

Epoch: 5| Step: 4
Training loss: 2.3950705528259277
Validation loss: 2.1794047554334006

Epoch: 5| Step: 5
Training loss: 1.4481079578399658
Validation loss: 2.196272924542427

Epoch: 5| Step: 6
Training loss: 1.964104413986206
Validation loss: 2.2026602973540625

Epoch: 5| Step: 7
Training loss: 1.5199731588363647
Validation loss: 2.1892008433739343

Epoch: 5| Step: 8
Training loss: 2.0384745597839355
Validation loss: 2.1956854661305747

Epoch: 5| Step: 9
Training loss: 1.947416067123413
Validation loss: 2.172444075345993

Epoch: 5| Step: 10
Training loss: 2.296884059906006
Validation loss: 2.1849140177170434

Epoch: 5| Step: 11
Training loss: 2.454559326171875
Validation loss: 2.186187873284022

Epoch: 276| Step: 0
Training loss: 1.551674723625183
Validation loss: 2.181560456752777

Epoch: 5| Step: 1
Training loss: 1.2824674844741821
Validation loss: 2.1714479277531304

Epoch: 5| Step: 2
Training loss: 2.0751519203186035
Validation loss: 2.189230461915334

Epoch: 5| Step: 3
Training loss: 2.270267963409424
Validation loss: 2.178354894121488

Epoch: 5| Step: 4
Training loss: 1.813794732093811
Validation loss: 2.1929497569799423

Epoch: 5| Step: 5
Training loss: 1.9700285196304321
Validation loss: 2.1965862264235816

Epoch: 5| Step: 6
Training loss: 2.371304750442505
Validation loss: 2.208398332198461

Epoch: 5| Step: 7
Training loss: 2.2830708026885986
Validation loss: 2.186951979994774

Epoch: 5| Step: 8
Training loss: 1.731300711631775
Validation loss: 2.1770174403985343

Epoch: 5| Step: 9
Training loss: 1.2086200714111328
Validation loss: 2.182327156265577

Epoch: 5| Step: 10
Training loss: 1.3564668893814087
Validation loss: 2.183702121178309

Epoch: 5| Step: 11
Training loss: 2.007091999053955
Validation loss: 2.1712209482987723

Epoch: 277| Step: 0
Training loss: 1.5997698307037354
Validation loss: 2.161081319053968

Epoch: 5| Step: 1
Training loss: 2.530594825744629
Validation loss: 2.173846885561943

Epoch: 5| Step: 2
Training loss: 1.754267930984497
Validation loss: 2.1828386982282004

Epoch: 5| Step: 3
Training loss: 1.7670023441314697
Validation loss: 2.171336844563484

Epoch: 5| Step: 4
Training loss: 2.2090084552764893
Validation loss: 2.1785838454961777

Epoch: 5| Step: 5
Training loss: 1.8267453908920288
Validation loss: 2.172269264856974

Epoch: 5| Step: 6
Training loss: 1.1654335260391235
Validation loss: 2.1646520644426346

Epoch: 5| Step: 7
Training loss: 1.3231245279312134
Validation loss: 2.161333287755648

Epoch: 5| Step: 8
Training loss: 2.6845555305480957
Validation loss: 2.1756347020467124

Epoch: 5| Step: 9
Training loss: 1.7164943218231201
Validation loss: 2.167294646302859

Epoch: 5| Step: 10
Training loss: 1.664483666419983
Validation loss: 2.1760896891355515

Epoch: 5| Step: 11
Training loss: 0.7479880452156067
Validation loss: 2.1809492111206055

Epoch: 278| Step: 0
Training loss: 1.8355411291122437
Validation loss: 2.176055689652761

Epoch: 5| Step: 1
Training loss: 1.8388748168945312
Validation loss: 2.183617442846298

Epoch: 5| Step: 2
Training loss: 1.8299696445465088
Validation loss: 2.176966200272242

Epoch: 5| Step: 3
Training loss: 2.1755263805389404
Validation loss: 2.1967627753814063

Epoch: 5| Step: 4
Training loss: 0.8161295056343079
Validation loss: 2.2151746600866318

Epoch: 5| Step: 5
Training loss: 1.883833646774292
Validation loss: 2.1798181980848312

Epoch: 5| Step: 6
Training loss: 2.055227041244507
Validation loss: 2.1832288851340613

Epoch: 5| Step: 7
Training loss: 1.2142813205718994
Validation loss: 2.1840450018644333

Epoch: 5| Step: 8
Training loss: 2.170351505279541
Validation loss: 2.170500079790751

Epoch: 5| Step: 9
Training loss: 1.6096433401107788
Validation loss: 2.1705879072348275

Epoch: 5| Step: 10
Training loss: 2.328092575073242
Validation loss: 2.1750991443792977

Epoch: 5| Step: 11
Training loss: 1.5640919208526611
Validation loss: 2.186246251066526

Epoch: 279| Step: 0
Training loss: 0.9215372800827026
Validation loss: 2.1786437233289084

Epoch: 5| Step: 1
Training loss: 2.0912320613861084
Validation loss: 2.171593964099884

Epoch: 5| Step: 2
Training loss: 1.9273738861083984
Validation loss: 2.172677770256996

Epoch: 5| Step: 3
Training loss: 1.5166866779327393
Validation loss: 2.1602599372466407

Epoch: 5| Step: 4
Training loss: 2.8188629150390625
Validation loss: 2.168774222334226

Epoch: 5| Step: 5
Training loss: 1.8451244831085205
Validation loss: 2.1994817157586417

Epoch: 5| Step: 6
Training loss: 1.7914174795150757
Validation loss: 2.1808526068925858

Epoch: 5| Step: 7
Training loss: 1.891318678855896
Validation loss: 2.205867817004522

Epoch: 5| Step: 8
Training loss: 1.5129400491714478
Validation loss: 2.1964473525683084

Epoch: 5| Step: 9
Training loss: 1.3025270700454712
Validation loss: 2.2068375597397485

Epoch: 5| Step: 10
Training loss: 1.8792117834091187
Validation loss: 2.205292751391729

Epoch: 5| Step: 11
Training loss: 1.9196467399597168
Validation loss: 2.213509420553843

Epoch: 280| Step: 0
Training loss: 2.2186779975891113
Validation loss: 2.2086309790611267

Epoch: 5| Step: 1
Training loss: 1.6946361064910889
Validation loss: 2.1920473674933114

Epoch: 5| Step: 2
Training loss: 1.7455852031707764
Validation loss: 2.192495380838712

Epoch: 5| Step: 3
Training loss: 1.6236259937286377
Validation loss: 2.2228361616532006

Epoch: 5| Step: 4
Training loss: 1.6172126531600952
Validation loss: 2.2250839869181314

Epoch: 5| Step: 5
Training loss: 1.6048030853271484
Validation loss: 2.213012064496676

Epoch: 5| Step: 6
Training loss: 2.155197858810425
Validation loss: 2.1934768557548523

Epoch: 5| Step: 7
Training loss: 2.120037317276001
Validation loss: 2.231777956088384

Epoch: 5| Step: 8
Training loss: 1.324580430984497
Validation loss: 2.199188311894735

Epoch: 5| Step: 9
Training loss: 1.8442071676254272
Validation loss: 2.2267921417951584

Epoch: 5| Step: 10
Training loss: 1.7534927129745483
Validation loss: 2.1963324348131814

Epoch: 5| Step: 11
Training loss: 2.573140859603882
Validation loss: 2.2072790563106537

Epoch: 281| Step: 0
Training loss: 1.759497046470642
Validation loss: 2.209381952881813

Epoch: 5| Step: 1
Training loss: 1.9233152866363525
Validation loss: 2.1900577445824942

Epoch: 5| Step: 2
Training loss: 1.8138622045516968
Validation loss: 2.1919575730959573

Epoch: 5| Step: 3
Training loss: 1.498966932296753
Validation loss: 2.2046875407298407

Epoch: 5| Step: 4
Training loss: 1.1386152505874634
Validation loss: 2.2080329606930413

Epoch: 5| Step: 5
Training loss: 1.9811832904815674
Validation loss: 2.2214811791976294

Epoch: 5| Step: 6
Training loss: 1.6259479522705078
Validation loss: 2.2288584411144257

Epoch: 5| Step: 7
Training loss: 2.087404727935791
Validation loss: 2.2456479370594025

Epoch: 5| Step: 8
Training loss: 2.0651447772979736
Validation loss: 2.2552119294802346

Epoch: 5| Step: 9
Training loss: 2.1570050716400146
Validation loss: 2.28475159406662

Epoch: 5| Step: 10
Training loss: 1.5156056880950928
Validation loss: 2.2481490671634674

Epoch: 5| Step: 11
Training loss: 2.763856887817383
Validation loss: 2.2552153716484704

Epoch: 282| Step: 0
Training loss: 1.5084388256072998
Validation loss: 2.2449020445346832

Epoch: 5| Step: 1
Training loss: 1.9584003686904907
Validation loss: 2.212921440601349

Epoch: 5| Step: 2
Training loss: 1.3179677724838257
Validation loss: 2.2064828673998513

Epoch: 5| Step: 3
Training loss: 1.785150170326233
Validation loss: 2.167237957318624

Epoch: 5| Step: 4
Training loss: 1.4636013507843018
Validation loss: 2.1653900345166526

Epoch: 5| Step: 5
Training loss: 2.022679090499878
Validation loss: 2.153068790833155

Epoch: 5| Step: 6
Training loss: 2.219677448272705
Validation loss: 2.1495743791262307

Epoch: 5| Step: 7
Training loss: 1.830528974533081
Validation loss: 2.157970502972603

Epoch: 5| Step: 8
Training loss: 2.1423721313476562
Validation loss: 2.1567474702994027

Epoch: 5| Step: 9
Training loss: 2.2258236408233643
Validation loss: 2.1632054150104523

Epoch: 5| Step: 10
Training loss: 1.9562320709228516
Validation loss: 2.184909294048945

Epoch: 5| Step: 11
Training loss: 1.1701064109802246
Validation loss: 2.1950109551350274

Epoch: 283| Step: 0
Training loss: 1.4860990047454834
Validation loss: 2.224760979413986

Epoch: 5| Step: 1
Training loss: 1.3655003309249878
Validation loss: 2.2487538357575736

Epoch: 5| Step: 2
Training loss: 1.8869225978851318
Validation loss: 2.2518234054247537

Epoch: 5| Step: 3
Training loss: 2.4484286308288574
Validation loss: 2.248173877596855

Epoch: 5| Step: 4
Training loss: 1.7920515537261963
Validation loss: 2.2674161891142526

Epoch: 5| Step: 5
Training loss: 2.3700954914093018
Validation loss: 2.2473267714182534

Epoch: 5| Step: 6
Training loss: 1.6208521127700806
Validation loss: 2.2653840283552804

Epoch: 5| Step: 7
Training loss: 1.9094066619873047
Validation loss: 2.249934365351995

Epoch: 5| Step: 8
Training loss: 1.911149024963379
Validation loss: 2.279458532730738

Epoch: 5| Step: 9
Training loss: 1.524401307106018
Validation loss: 2.2662241061528525

Epoch: 5| Step: 10
Training loss: 1.8774582147598267
Validation loss: 2.256101648012797

Epoch: 5| Step: 11
Training loss: 1.9617831707000732
Validation loss: 2.2371220191319785

Epoch: 284| Step: 0
Training loss: 2.1147749423980713
Validation loss: 2.206167737642924

Epoch: 5| Step: 1
Training loss: 1.8707538843154907
Validation loss: 2.2003062963485718

Epoch: 5| Step: 2
Training loss: 1.5950729846954346
Validation loss: 2.1891586979230246

Epoch: 5| Step: 3
Training loss: 2.018157720565796
Validation loss: 2.1685967644055686

Epoch: 5| Step: 4
Training loss: 1.6978013515472412
Validation loss: 2.169262687365214

Epoch: 5| Step: 5
Training loss: 1.9601424932479858
Validation loss: 2.158668036262194

Epoch: 5| Step: 6
Training loss: 1.8822952508926392
Validation loss: 2.163627251982689

Epoch: 5| Step: 7
Training loss: 1.9791233539581299
Validation loss: 2.1698399484157562

Epoch: 5| Step: 8
Training loss: 1.7826801538467407
Validation loss: 2.1959035446246467

Epoch: 5| Step: 9
Training loss: 1.1370980739593506
Validation loss: 2.2063057273626328

Epoch: 5| Step: 10
Training loss: 2.2931199073791504
Validation loss: 2.213848998149236

Epoch: 5| Step: 11
Training loss: 3.45900297164917
Validation loss: 2.194979170958201

Epoch: 285| Step: 0
Training loss: 1.5791349411010742
Validation loss: 2.1777543425559998

Epoch: 5| Step: 1
Training loss: 2.201244831085205
Validation loss: 2.1975638767083487

Epoch: 5| Step: 2
Training loss: 1.827527642250061
Validation loss: 2.1939439475536346

Epoch: 5| Step: 3
Training loss: 1.6718896627426147
Validation loss: 2.19628777106603

Epoch: 5| Step: 4
Training loss: 1.9799540042877197
Validation loss: 2.1904869079589844

Epoch: 5| Step: 5
Training loss: 2.2187767028808594
Validation loss: 2.1977007935444512

Epoch: 5| Step: 6
Training loss: 1.838629961013794
Validation loss: 2.180448750654856

Epoch: 5| Step: 7
Training loss: 1.7406142950057983
Validation loss: 2.183465431133906

Epoch: 5| Step: 8
Training loss: 1.6029720306396484
Validation loss: 2.190785527229309

Epoch: 5| Step: 9
Training loss: 1.4765807390213013
Validation loss: 2.2130270451307297

Epoch: 5| Step: 10
Training loss: 1.4722251892089844
Validation loss: 2.21790212392807

Epoch: 5| Step: 11
Training loss: 1.5519720315933228
Validation loss: 2.210432549317678

Epoch: 286| Step: 0
Training loss: 1.1942757368087769
Validation loss: 2.2249564031759896

Epoch: 5| Step: 1
Training loss: 1.7065006494522095
Validation loss: 2.207640200853348

Epoch: 5| Step: 2
Training loss: 1.121608018875122
Validation loss: 2.2000265220801034

Epoch: 5| Step: 3
Training loss: 1.9409284591674805
Validation loss: 2.1776762257019677

Epoch: 5| Step: 4
Training loss: 1.6922203302383423
Validation loss: 2.171908915042877

Epoch: 5| Step: 5
Training loss: 1.8124157190322876
Validation loss: 2.169185390075048

Epoch: 5| Step: 6
Training loss: 2.04618501663208
Validation loss: 2.167635604739189

Epoch: 5| Step: 7
Training loss: 2.634838104248047
Validation loss: 2.1547120213508606

Epoch: 5| Step: 8
Training loss: 1.6729366779327393
Validation loss: 2.151548276344935

Epoch: 5| Step: 9
Training loss: 2.2447378635406494
Validation loss: 2.1597768664360046

Epoch: 5| Step: 10
Training loss: 1.7249237298965454
Validation loss: 2.1688760866721473

Epoch: 5| Step: 11
Training loss: 3.6412012577056885
Validation loss: 2.1695738285779953

Epoch: 287| Step: 0
Training loss: 2.1144096851348877
Validation loss: 2.198843836784363

Epoch: 5| Step: 1
Training loss: 2.35400128364563
Validation loss: 2.186396837234497

Epoch: 5| Step: 2
Training loss: 2.042358636856079
Validation loss: 2.1914539635181427

Epoch: 5| Step: 3
Training loss: 1.960097312927246
Validation loss: 2.2308274855216346

Epoch: 5| Step: 4
Training loss: 1.4402567148208618
Validation loss: 2.213921229044596

Epoch: 5| Step: 5
Training loss: 1.9557358026504517
Validation loss: 2.220308472712835

Epoch: 5| Step: 6
Training loss: 1.4724171161651611
Validation loss: 2.2331286569436393

Epoch: 5| Step: 7
Training loss: 1.371074914932251
Validation loss: 2.253115733464559

Epoch: 5| Step: 8
Training loss: 1.8952003717422485
Validation loss: 2.21671199798584

Epoch: 5| Step: 9
Training loss: 1.9788563251495361
Validation loss: 2.22329310576121

Epoch: 5| Step: 10
Training loss: 1.48440420627594
Validation loss: 2.214505190650622

Epoch: 5| Step: 11
Training loss: 0.9287445545196533
Validation loss: 2.2036020159721375

Epoch: 288| Step: 0
Training loss: 2.1165120601654053
Validation loss: 2.1925392746925354

Epoch: 5| Step: 1
Training loss: 1.9114961624145508
Validation loss: 2.1817982296148934

Epoch: 5| Step: 2
Training loss: 1.5489964485168457
Validation loss: 2.192052404085795

Epoch: 5| Step: 3
Training loss: 1.8374788761138916
Validation loss: 2.182409336169561

Epoch: 5| Step: 4
Training loss: 1.5713475942611694
Validation loss: 2.16379281381766

Epoch: 5| Step: 5
Training loss: 1.3468804359436035
Validation loss: 2.1858961482842765

Epoch: 5| Step: 6
Training loss: 1.4689013957977295
Validation loss: 2.139219949642817

Epoch: 5| Step: 7
Training loss: 1.8184362649917603
Validation loss: 2.1710106134414673

Epoch: 5| Step: 8
Training loss: 2.462515354156494
Validation loss: 2.1720839887857437

Epoch: 5| Step: 9
Training loss: 1.8297218084335327
Validation loss: 2.193055659532547

Epoch: 5| Step: 10
Training loss: 1.3758571147918701
Validation loss: 2.179482102394104

Epoch: 5| Step: 11
Training loss: 1.8728855848312378
Validation loss: 2.2011299232641854

Epoch: 289| Step: 0
Training loss: 1.6694341897964478
Validation loss: 2.197864626844724

Epoch: 5| Step: 1
Training loss: 2.0306713581085205
Validation loss: 2.201836804548899

Epoch: 5| Step: 2
Training loss: 1.609084129333496
Validation loss: 2.2066891392072043

Epoch: 5| Step: 3
Training loss: 1.6900720596313477
Validation loss: 2.1932820777098336

Epoch: 5| Step: 4
Training loss: 1.6533857583999634
Validation loss: 2.2279068380594254

Epoch: 5| Step: 5
Training loss: 1.8385975360870361
Validation loss: 2.217521702249845

Epoch: 5| Step: 6
Training loss: 1.6610829830169678
Validation loss: 2.2296505769093833

Epoch: 5| Step: 7
Training loss: 1.6135467290878296
Validation loss: 2.24517884850502

Epoch: 5| Step: 8
Training loss: 1.8276307582855225
Validation loss: 2.2124176075061164

Epoch: 5| Step: 9
Training loss: 1.7857749462127686
Validation loss: 2.2323846568663916

Epoch: 5| Step: 10
Training loss: 1.7494213581085205
Validation loss: 2.224275693297386

Epoch: 5| Step: 11
Training loss: 1.8840019702911377
Validation loss: 2.2104690621296563

Epoch: 290| Step: 0
Training loss: 1.6508629322052002
Validation loss: 2.1890383511781693

Epoch: 5| Step: 1
Training loss: 1.6973445415496826
Validation loss: 2.1656585335731506

Epoch: 5| Step: 2
Training loss: 2.036390781402588
Validation loss: 2.150149712959925

Epoch: 5| Step: 3
Training loss: 1.341796636581421
Validation loss: 2.1516363422075906

Epoch: 5| Step: 4
Training loss: 2.092381000518799
Validation loss: 2.1472250670194626

Epoch: 5| Step: 5
Training loss: 1.8633041381835938
Validation loss: 2.162506625056267

Epoch: 5| Step: 6
Training loss: 2.056323289871216
Validation loss: 2.1707921226819358

Epoch: 5| Step: 7
Training loss: 1.5611127614974976
Validation loss: 2.161226679881414

Epoch: 5| Step: 8
Training loss: 1.2673436403274536
Validation loss: 2.187101051211357

Epoch: 5| Step: 9
Training loss: 2.0930051803588867
Validation loss: 2.1829320192337036

Epoch: 5| Step: 10
Training loss: 1.677010178565979
Validation loss: 2.1760502457618713

Epoch: 5| Step: 11
Training loss: 3.905496120452881
Validation loss: 2.1985709369182587

Epoch: 291| Step: 0
Training loss: 1.3834738731384277
Validation loss: 2.191807175676028

Epoch: 5| Step: 1
Training loss: 2.34051251411438
Validation loss: 2.198141425848007

Epoch: 5| Step: 2
Training loss: 1.6181328296661377
Validation loss: 2.1627505968014398

Epoch: 5| Step: 3
Training loss: 2.13577938079834
Validation loss: 2.1494918117920556

Epoch: 5| Step: 4
Training loss: 2.3078715801239014
Validation loss: 2.1493657330671945

Epoch: 5| Step: 5
Training loss: 1.2186933755874634
Validation loss: 2.141153077284495

Epoch: 5| Step: 6
Training loss: 1.2093185186386108
Validation loss: 2.16796021660169

Epoch: 5| Step: 7
Training loss: 2.1900715827941895
Validation loss: 2.1680120130379996

Epoch: 5| Step: 8
Training loss: 1.4554485082626343
Validation loss: 2.1708326091368995

Epoch: 5| Step: 9
Training loss: 1.4781978130340576
Validation loss: 2.1442652444044747

Epoch: 5| Step: 10
Training loss: 2.0212864875793457
Validation loss: 2.1803684582312903

Epoch: 5| Step: 11
Training loss: 2.728790283203125
Validation loss: 2.1825462778409324

Epoch: 292| Step: 0
Training loss: 2.2211899757385254
Validation loss: 2.169215882817904

Epoch: 5| Step: 1
Training loss: 1.071666955947876
Validation loss: 2.192405049999555

Epoch: 5| Step: 2
Training loss: 1.3000489473342896
Validation loss: 2.1892124315102897

Epoch: 5| Step: 3
Training loss: 1.651802659034729
Validation loss: 2.1883783042430878

Epoch: 5| Step: 4
Training loss: 1.3629882335662842
Validation loss: 2.1698858588933945

Epoch: 5| Step: 5
Training loss: 1.6348479986190796
Validation loss: 2.1663102557261786

Epoch: 5| Step: 6
Training loss: 1.9248497486114502
Validation loss: 2.162704105178515

Epoch: 5| Step: 7
Training loss: 1.8999671936035156
Validation loss: 2.1669775942961373

Epoch: 5| Step: 8
Training loss: 1.5421618223190308
Validation loss: 2.181505391995112

Epoch: 5| Step: 9
Training loss: 2.4239261150360107
Validation loss: 2.1721891462802887

Epoch: 5| Step: 10
Training loss: 2.138256311416626
Validation loss: 2.2007274329662323

Epoch: 5| Step: 11
Training loss: 1.602277159690857
Validation loss: 2.2137413322925568

Epoch: 293| Step: 0
Training loss: 2.282687187194824
Validation loss: 2.2109064708153405

Epoch: 5| Step: 1
Training loss: 0.9482410550117493
Validation loss: 2.2317523856957755

Epoch: 5| Step: 2
Training loss: 1.6357790231704712
Validation loss: 2.224426358938217

Epoch: 5| Step: 3
Training loss: 1.6886955499649048
Validation loss: 2.2192976425091424

Epoch: 5| Step: 4
Training loss: 2.629296064376831
Validation loss: 2.1746074805657067

Epoch: 5| Step: 5
Training loss: 1.9551204442977905
Validation loss: 2.1869032233953476

Epoch: 5| Step: 6
Training loss: 1.2705014944076538
Validation loss: 2.206731617450714

Epoch: 5| Step: 7
Training loss: 1.396793007850647
Validation loss: 2.1747704495986304

Epoch: 5| Step: 8
Training loss: 1.8499294519424438
Validation loss: 2.175038620829582

Epoch: 5| Step: 9
Training loss: 1.9214767217636108
Validation loss: 2.1565964023272195

Epoch: 5| Step: 10
Training loss: 1.5436813831329346
Validation loss: 2.1412974248329797

Epoch: 5| Step: 11
Training loss: 1.1310226917266846
Validation loss: 2.157533879081408

Epoch: 294| Step: 0
Training loss: 1.385656714439392
Validation loss: 2.1645075728495917

Epoch: 5| Step: 1
Training loss: 1.8517366647720337
Validation loss: 2.155444477995237

Epoch: 5| Step: 2
Training loss: 1.7490835189819336
Validation loss: 2.1604362775882087

Epoch: 5| Step: 3
Training loss: 1.293206810951233
Validation loss: 2.181597794095675

Epoch: 5| Step: 4
Training loss: 1.8499809503555298
Validation loss: 2.1607119739055634

Epoch: 5| Step: 5
Training loss: 1.9058897495269775
Validation loss: 2.170044556260109

Epoch: 5| Step: 6
Training loss: 1.4712985754013062
Validation loss: 2.177183692653974

Epoch: 5| Step: 7
Training loss: 2.019421100616455
Validation loss: 2.177631671229998

Epoch: 5| Step: 8
Training loss: 1.113564133644104
Validation loss: 2.1866389214992523

Epoch: 5| Step: 9
Training loss: 2.2234036922454834
Validation loss: 2.2070989310741425

Epoch: 5| Step: 10
Training loss: 2.305682897567749
Validation loss: 2.163804665207863

Epoch: 5| Step: 11
Training loss: 1.8310819864273071
Validation loss: 2.1712098717689514

Epoch: 295| Step: 0
Training loss: 0.9558029174804688
Validation loss: 2.2278384069601693

Epoch: 5| Step: 1
Training loss: 2.0244834423065186
Validation loss: 2.24569300810496

Epoch: 5| Step: 2
Training loss: 1.6335887908935547
Validation loss: 2.2025973796844482

Epoch: 5| Step: 3
Training loss: 2.1882376670837402
Validation loss: 2.20926899711291

Epoch: 5| Step: 4
Training loss: 1.8130992650985718
Validation loss: 2.2254074613253274

Epoch: 5| Step: 5
Training loss: 1.307234525680542
Validation loss: 2.1737908025582633

Epoch: 5| Step: 6
Training loss: 2.262953042984009
Validation loss: 2.1842166433731713

Epoch: 5| Step: 7
Training loss: 2.482728958129883
Validation loss: 2.1635914792617164

Epoch: 5| Step: 8
Training loss: 1.7933708429336548
Validation loss: 2.1592679917812347

Epoch: 5| Step: 9
Training loss: 1.981903076171875
Validation loss: 2.174882153669993

Epoch: 5| Step: 10
Training loss: 2.4045462608337402
Validation loss: 2.1572821040948233

Epoch: 5| Step: 11
Training loss: 2.2417349815368652
Validation loss: 2.1395409057537713

Epoch: 296| Step: 0
Training loss: 1.691674828529358
Validation loss: 2.172225440541903

Epoch: 5| Step: 1
Training loss: 1.959716796875
Validation loss: 2.139804482460022

Epoch: 5| Step: 2
Training loss: 1.837240219116211
Validation loss: 2.1543652762969336

Epoch: 5| Step: 3
Training loss: 1.8381866216659546
Validation loss: 2.16768242418766

Epoch: 5| Step: 4
Training loss: 1.331545352935791
Validation loss: 2.1568247179190316

Epoch: 5| Step: 5
Training loss: 1.799634337425232
Validation loss: 2.148948162794113

Epoch: 5| Step: 6
Training loss: 1.7264337539672852
Validation loss: 2.153319497903188

Epoch: 5| Step: 7
Training loss: 2.075702667236328
Validation loss: 2.1689445128043494

Epoch: 5| Step: 8
Training loss: 2.37900710105896
Validation loss: 2.145226761698723

Epoch: 5| Step: 9
Training loss: 2.19901967048645
Validation loss: 2.155689020951589

Epoch: 5| Step: 10
Training loss: 1.5264980792999268
Validation loss: 2.1762523651123047

Epoch: 5| Step: 11
Training loss: 0.7511950135231018
Validation loss: 2.1699532717466354

Epoch: 297| Step: 0
Training loss: 2.1050379276275635
Validation loss: 2.1650824497143426

Epoch: 5| Step: 1
Training loss: 1.096222162246704
Validation loss: 2.1630620261033378

Epoch: 5| Step: 2
Training loss: 2.0528957843780518
Validation loss: 2.173618644475937

Epoch: 5| Step: 3
Training loss: 1.6677796840667725
Validation loss: 2.1752218355735145

Epoch: 5| Step: 4
Training loss: 1.321715235710144
Validation loss: 2.1786911487579346

Epoch: 5| Step: 5
Training loss: 2.2295546531677246
Validation loss: 2.1907461980978646

Epoch: 5| Step: 6
Training loss: 1.738910436630249
Validation loss: 2.1957404613494873

Epoch: 5| Step: 7
Training loss: 1.5800635814666748
Validation loss: 2.1928632656733194

Epoch: 5| Step: 8
Training loss: 1.6490707397460938
Validation loss: 2.184732715288798

Epoch: 5| Step: 9
Training loss: 2.1128478050231934
Validation loss: 2.18920536339283

Epoch: 5| Step: 10
Training loss: 2.1083920001983643
Validation loss: 2.187261531750361

Epoch: 5| Step: 11
Training loss: 2.410109043121338
Validation loss: 2.172753612200419

Epoch: 298| Step: 0
Training loss: 1.7301632165908813
Validation loss: 2.1858662217855453

Epoch: 5| Step: 1
Training loss: 1.3932807445526123
Validation loss: 2.1883128583431244

Epoch: 5| Step: 2
Training loss: 1.5947283506393433
Validation loss: 2.1810935934384665

Epoch: 5| Step: 3
Training loss: 1.3306105136871338
Validation loss: 2.164099544286728

Epoch: 5| Step: 4
Training loss: 2.1098105907440186
Validation loss: 2.1568703999121985

Epoch: 5| Step: 5
Training loss: 1.5162665843963623
Validation loss: 2.1392396986484528

Epoch: 5| Step: 6
Training loss: 2.7082009315490723
Validation loss: 2.147665078441302

Epoch: 5| Step: 7
Training loss: 1.8917986154556274
Validation loss: 2.136956219871839

Epoch: 5| Step: 8
Training loss: 1.5190664529800415
Validation loss: 2.1597732504208884

Epoch: 5| Step: 9
Training loss: 2.183098077774048
Validation loss: 2.1775055627028146

Epoch: 5| Step: 10
Training loss: 1.902829885482788
Validation loss: 2.1887343426545462

Epoch: 5| Step: 11
Training loss: 1.0171767473220825
Validation loss: 2.193146601319313

Epoch: 299| Step: 0
Training loss: 1.8020775318145752
Validation loss: 2.232746437191963

Epoch: 5| Step: 1
Training loss: 2.275266647338867
Validation loss: 2.2376850893100104

Epoch: 5| Step: 2
Training loss: 1.5162831544876099
Validation loss: 2.231651415427526

Epoch: 5| Step: 3
Training loss: 1.6449248790740967
Validation loss: 2.2485788464546204

Epoch: 5| Step: 4
Training loss: 1.4740386009216309
Validation loss: 2.21486034989357

Epoch: 5| Step: 5
Training loss: 1.70282781124115
Validation loss: 2.223641728361448

Epoch: 5| Step: 6
Training loss: 1.6868302822113037
Validation loss: 2.2202642261981964

Epoch: 5| Step: 7
Training loss: 2.065844774246216
Validation loss: 2.218198905388514

Epoch: 5| Step: 8
Training loss: 2.0886924266815186
Validation loss: 2.221223702033361

Epoch: 5| Step: 9
Training loss: 1.5361135005950928
Validation loss: 2.218009039759636

Epoch: 5| Step: 10
Training loss: 1.7697120904922485
Validation loss: 2.21599417924881

Epoch: 5| Step: 11
Training loss: 1.17645263671875
Validation loss: 2.206196427345276

Epoch: 300| Step: 0
Training loss: 2.3670554161071777
Validation loss: 2.1813122431437173

Epoch: 5| Step: 1
Training loss: 2.0748162269592285
Validation loss: 2.16990797718366

Epoch: 5| Step: 2
Training loss: 1.181936502456665
Validation loss: 2.1698005894819894

Epoch: 5| Step: 3
Training loss: 1.3876371383666992
Validation loss: 2.1698170006275177

Epoch: 5| Step: 4
Training loss: 1.8837181329727173
Validation loss: 2.1656071643034616

Epoch: 5| Step: 5
Training loss: 1.5873889923095703
Validation loss: 2.154546598593394

Epoch: 5| Step: 6
Training loss: 2.199756145477295
Validation loss: 2.1673542857170105

Epoch: 5| Step: 7
Training loss: 1.2496336698532104
Validation loss: 2.1635282784700394

Epoch: 5| Step: 8
Training loss: 1.6682357788085938
Validation loss: 2.1667430251836777

Epoch: 5| Step: 9
Training loss: 2.078232765197754
Validation loss: 2.1705112159252167

Epoch: 5| Step: 10
Training loss: 1.616307020187378
Validation loss: 2.206829602519671

Epoch: 5| Step: 11
Training loss: 2.950040817260742
Validation loss: 2.20431579152743

Epoch: 301| Step: 0
Training loss: 1.577869176864624
Validation loss: 2.208574732144674

Epoch: 5| Step: 1
Training loss: 1.211529016494751
Validation loss: 2.2098549703756967

Epoch: 5| Step: 2
Training loss: 1.343313455581665
Validation loss: 2.18898052473863

Epoch: 5| Step: 3
Training loss: 1.8126156330108643
Validation loss: 2.197136660416921

Epoch: 5| Step: 4
Training loss: 2.2750496864318848
Validation loss: 2.191177705923716

Epoch: 5| Step: 5
Training loss: 1.6353950500488281
Validation loss: 2.1994499613841376

Epoch: 5| Step: 6
Training loss: 1.5402915477752686
Validation loss: 2.1852554082870483

Epoch: 5| Step: 7
Training loss: 1.7986364364624023
Validation loss: 2.1862070858478546

Epoch: 5| Step: 8
Training loss: 2.227755546569824
Validation loss: 2.1905061105887094

Epoch: 5| Step: 9
Training loss: 1.7504844665527344
Validation loss: 2.186209241549174

Epoch: 5| Step: 10
Training loss: 1.6572341918945312
Validation loss: 2.198085382580757

Epoch: 5| Step: 11
Training loss: 1.0343389511108398
Validation loss: 2.18068727850914

Epoch: 302| Step: 0
Training loss: 2.086721897125244
Validation loss: 2.1551238844792047

Epoch: 5| Step: 1
Training loss: 1.8961833715438843
Validation loss: 2.1869463423887887

Epoch: 5| Step: 2
Training loss: 0.9863336682319641
Validation loss: 2.181136374672254

Epoch: 5| Step: 3
Training loss: 1.3161991834640503
Validation loss: 2.1782121062278748

Epoch: 5| Step: 4
Training loss: 1.1526187658309937
Validation loss: 2.189104378223419

Epoch: 5| Step: 5
Training loss: 1.4696694612503052
Validation loss: 2.186617910861969

Epoch: 5| Step: 6
Training loss: 1.6783866882324219
Validation loss: 2.200223738948504

Epoch: 5| Step: 7
Training loss: 2.754788875579834
Validation loss: 2.192766919732094

Epoch: 5| Step: 8
Training loss: 1.9608583450317383
Validation loss: 2.1979740113019943

Epoch: 5| Step: 9
Training loss: 1.8368337154388428
Validation loss: 2.216587647795677

Epoch: 5| Step: 10
Training loss: 2.270660400390625
Validation loss: 2.210505877931913

Epoch: 5| Step: 11
Training loss: 0.9407454133033752
Validation loss: 2.205214778582255

Epoch: 303| Step: 0
Training loss: 1.8337371349334717
Validation loss: 2.22534841299057

Epoch: 5| Step: 1
Training loss: 1.7789443731307983
Validation loss: 2.214173048734665

Epoch: 5| Step: 2
Training loss: 0.9930111169815063
Validation loss: 2.176046838363012

Epoch: 5| Step: 3
Training loss: 2.297630548477173
Validation loss: 2.1981066912412643

Epoch: 5| Step: 4
Training loss: 1.528913974761963
Validation loss: 2.1833570996920266

Epoch: 5| Step: 5
Training loss: 1.8233344554901123
Validation loss: 2.1791408161322274

Epoch: 5| Step: 6
Training loss: 1.9458491802215576
Validation loss: 2.1604816565910974

Epoch: 5| Step: 7
Training loss: 1.7160307168960571
Validation loss: 2.17727784315745

Epoch: 5| Step: 8
Training loss: 1.7525451183319092
Validation loss: 2.1954536686340966

Epoch: 5| Step: 9
Training loss: 1.6117513179779053
Validation loss: 2.1731886068979898

Epoch: 5| Step: 10
Training loss: 1.486055612564087
Validation loss: 2.1705698569615683

Epoch: 5| Step: 11
Training loss: 1.8664052486419678
Validation loss: 2.156522586941719

Epoch: 304| Step: 0
Training loss: 2.3992421627044678
Validation loss: 2.1661692708730698

Epoch: 5| Step: 1
Training loss: 2.1322672367095947
Validation loss: 2.147317369778951

Epoch: 5| Step: 2
Training loss: 1.6679404973983765
Validation loss: 2.167560795942942

Epoch: 5| Step: 3
Training loss: 2.336925506591797
Validation loss: 2.183583835760752

Epoch: 5| Step: 4
Training loss: 1.185189962387085
Validation loss: 2.1762598107258477

Epoch: 5| Step: 5
Training loss: 1.711025595664978
Validation loss: 2.1836777279774346

Epoch: 5| Step: 6
Training loss: 1.5975217819213867
Validation loss: 2.1878005961577096

Epoch: 5| Step: 7
Training loss: 1.8439861536026
Validation loss: 2.1839805245399475

Epoch: 5| Step: 8
Training loss: 1.6216394901275635
Validation loss: 2.174158056577047

Epoch: 5| Step: 9
Training loss: 0.968050479888916
Validation loss: 2.1636067926883698

Epoch: 5| Step: 10
Training loss: 1.8740291595458984
Validation loss: 2.153485432267189

Epoch: 5| Step: 11
Training loss: 0.7344101667404175
Validation loss: 2.14742041627566

Epoch: 305| Step: 0
Training loss: 2.062514066696167
Validation loss: 2.1478062917788825

Epoch: 5| Step: 1
Training loss: 1.8054516315460205
Validation loss: 2.1308015982309976

Epoch: 5| Step: 2
Training loss: 2.3028523921966553
Validation loss: 2.1240349610646567

Epoch: 5| Step: 3
Training loss: 1.9551830291748047
Validation loss: 2.1470221430063248

Epoch: 5| Step: 4
Training loss: 1.555582046508789
Validation loss: 2.169029876589775

Epoch: 5| Step: 5
Training loss: 1.6111301183700562
Validation loss: 2.1671447157859802

Epoch: 5| Step: 6
Training loss: 2.1266915798187256
Validation loss: 2.155461678902308

Epoch: 5| Step: 7
Training loss: 1.4773919582366943
Validation loss: 2.1919469038645425

Epoch: 5| Step: 8
Training loss: 1.5410902500152588
Validation loss: 2.1763028303782144

Epoch: 5| Step: 9
Training loss: 1.6464983224868774
Validation loss: 2.1841493447621665

Epoch: 5| Step: 10
Training loss: 1.3247928619384766
Validation loss: 2.1634089201688766

Epoch: 5| Step: 11
Training loss: 1.5759434700012207
Validation loss: 2.1760172645250955

Epoch: 306| Step: 0
Training loss: 1.5048482418060303
Validation loss: 2.155368223786354

Epoch: 5| Step: 1
Training loss: 1.9403266906738281
Validation loss: 2.1562180568774543

Epoch: 5| Step: 2
Training loss: 1.2948323488235474
Validation loss: 2.1563445329666138

Epoch: 5| Step: 3
Training loss: 1.8618770837783813
Validation loss: 2.168804774681727

Epoch: 5| Step: 4
Training loss: 1.7392997741699219
Validation loss: 2.1678634583950043

Epoch: 5| Step: 5
Training loss: 1.3581346273422241
Validation loss: 2.142099807659785

Epoch: 5| Step: 6
Training loss: 2.058119535446167
Validation loss: 2.155963251988093

Epoch: 5| Step: 7
Training loss: 1.6641260385513306
Validation loss: 2.1501738826433816

Epoch: 5| Step: 8
Training loss: 2.2706618309020996
Validation loss: 2.1577787498633065

Epoch: 5| Step: 9
Training loss: 1.6539608240127563
Validation loss: 2.156443029642105

Epoch: 5| Step: 10
Training loss: 1.8180564641952515
Validation loss: 2.1370030343532562

Epoch: 5| Step: 11
Training loss: 1.1363117694854736
Validation loss: 2.1431358754634857

Epoch: 307| Step: 0
Training loss: 1.3359324932098389
Validation loss: 2.1500327785809836

Epoch: 5| Step: 1
Training loss: 1.2610565423965454
Validation loss: 2.1471783270438514

Epoch: 5| Step: 2
Training loss: 2.08431077003479
Validation loss: 2.1478108117977777

Epoch: 5| Step: 3
Training loss: 1.3087278604507446
Validation loss: 2.1800573567549386

Epoch: 5| Step: 4
Training loss: 2.2273972034454346
Validation loss: 2.190515249967575

Epoch: 5| Step: 5
Training loss: 1.5057075023651123
Validation loss: 2.1886620422204337

Epoch: 5| Step: 6
Training loss: 1.7824382781982422
Validation loss: 2.176912705103556

Epoch: 5| Step: 7
Training loss: 2.1647329330444336
Validation loss: 2.159268230199814

Epoch: 5| Step: 8
Training loss: 1.6898975372314453
Validation loss: 2.1346609691778817

Epoch: 5| Step: 9
Training loss: 1.701894998550415
Validation loss: 2.152379482984543

Epoch: 5| Step: 10
Training loss: 2.014066696166992
Validation loss: 2.1367777983347573

Epoch: 5| Step: 11
Training loss: 1.9072209596633911
Validation loss: 2.1435346802075705

Epoch: 308| Step: 0
Training loss: 1.8212854862213135
Validation loss: 2.1541911462942758

Epoch: 5| Step: 1
Training loss: 1.2203701734542847
Validation loss: 2.1821332375208535

Epoch: 5| Step: 2
Training loss: 1.5828546285629272
Validation loss: 2.1921805838743844

Epoch: 5| Step: 3
Training loss: 1.6420570611953735
Validation loss: 2.1889854023853936

Epoch: 5| Step: 4
Training loss: 1.754716157913208
Validation loss: 2.191623797019323

Epoch: 5| Step: 5
Training loss: 1.9175243377685547
Validation loss: 2.2035608092943826

Epoch: 5| Step: 6
Training loss: 1.3766950368881226
Validation loss: 2.172832732399305

Epoch: 5| Step: 7
Training loss: 2.1434576511383057
Validation loss: 2.203883613149325

Epoch: 5| Step: 8
Training loss: 1.846462607383728
Validation loss: 2.1777305056651435

Epoch: 5| Step: 9
Training loss: 1.9074760675430298
Validation loss: 2.1650109936793647

Epoch: 5| Step: 10
Training loss: 1.2859207391738892
Validation loss: 2.195286085208257

Epoch: 5| Step: 11
Training loss: 3.823413372039795
Validation loss: 2.184549927711487

Epoch: 309| Step: 0
Training loss: 1.7379480600357056
Validation loss: 2.206984301408132

Epoch: 5| Step: 1
Training loss: 1.33371901512146
Validation loss: 2.193469082315763

Epoch: 5| Step: 2
Training loss: 1.7455761432647705
Validation loss: 2.211393490433693

Epoch: 5| Step: 3
Training loss: 1.8694915771484375
Validation loss: 2.191177691022555

Epoch: 5| Step: 4
Training loss: 1.3496516942977905
Validation loss: 2.1953154305617013

Epoch: 5| Step: 5
Training loss: 1.8913240432739258
Validation loss: 2.2078945885101953

Epoch: 5| Step: 6
Training loss: 1.8082431554794312
Validation loss: 2.1903662383556366

Epoch: 5| Step: 7
Training loss: 1.7705940008163452
Validation loss: 2.2055684328079224

Epoch: 5| Step: 8
Training loss: 1.8483566045761108
Validation loss: 2.1915691842635474

Epoch: 5| Step: 9
Training loss: 1.782975435256958
Validation loss: 2.2061866919199624

Epoch: 5| Step: 10
Training loss: 1.7771427631378174
Validation loss: 2.179379239678383

Epoch: 5| Step: 11
Training loss: 0.8878088593482971
Validation loss: 2.177008166909218

Epoch: 310| Step: 0
Training loss: 1.8177998065948486
Validation loss: 2.2069587210814157

Epoch: 5| Step: 1
Training loss: 2.028982162475586
Validation loss: 2.200112079580625

Epoch: 5| Step: 2
Training loss: 1.6018375158309937
Validation loss: 2.1746448477109275

Epoch: 5| Step: 3
Training loss: 2.122525691986084
Validation loss: 2.215627243121465

Epoch: 5| Step: 4
Training loss: 1.858925461769104
Validation loss: 2.200019747018814

Epoch: 5| Step: 5
Training loss: 1.903826355934143
Validation loss: 2.2036732087532678

Epoch: 5| Step: 6
Training loss: 1.2914782762527466
Validation loss: 2.2242456475893655

Epoch: 5| Step: 7
Training loss: 2.0088376998901367
Validation loss: 2.2179132252931595

Epoch: 5| Step: 8
Training loss: 1.6399047374725342
Validation loss: 2.2024046381314597

Epoch: 5| Step: 9
Training loss: 1.986374855041504
Validation loss: 2.156462480624517

Epoch: 5| Step: 10
Training loss: 1.475403070449829
Validation loss: 2.167040154337883

Epoch: 5| Step: 11
Training loss: 1.542602300643921
Validation loss: 2.1547989497582116

Epoch: 311| Step: 0
Training loss: 2.1267504692077637
Validation loss: 2.16109237074852

Epoch: 5| Step: 1
Training loss: 1.3387285470962524
Validation loss: 2.1343781799077988

Epoch: 5| Step: 2
Training loss: 2.3951361179351807
Validation loss: 2.153458461165428

Epoch: 5| Step: 3
Training loss: 1.4527407884597778
Validation loss: 2.1403949757417045

Epoch: 5| Step: 4
Training loss: 1.4259089231491089
Validation loss: 2.1577872733275094

Epoch: 5| Step: 5
Training loss: 1.6032501459121704
Validation loss: 2.1437913477420807

Epoch: 5| Step: 6
Training loss: 1.9502233266830444
Validation loss: 2.1554115414619446

Epoch: 5| Step: 7
Training loss: 1.8013761043548584
Validation loss: 2.186285595099131

Epoch: 5| Step: 8
Training loss: 1.8798000812530518
Validation loss: 2.2139100978771844

Epoch: 5| Step: 9
Training loss: 1.7239367961883545
Validation loss: 2.2330005119244256

Epoch: 5| Step: 10
Training loss: 1.8069063425064087
Validation loss: 2.2808203995227814

Epoch: 5| Step: 11
Training loss: 1.7707486152648926
Validation loss: 2.2559121598800025

Epoch: 312| Step: 0
Training loss: 1.9630523920059204
Validation loss: 2.258332227667173

Epoch: 5| Step: 1
Training loss: 1.3492343425750732
Validation loss: 2.244575326641401

Epoch: 5| Step: 2
Training loss: 2.0268986225128174
Validation loss: 2.2528777519861856

Epoch: 5| Step: 3
Training loss: 1.5551058053970337
Validation loss: 2.223640630642573

Epoch: 5| Step: 4
Training loss: 2.1419005393981934
Validation loss: 2.199581111470858

Epoch: 5| Step: 5
Training loss: 1.4143445491790771
Validation loss: 2.192509189248085

Epoch: 5| Step: 6
Training loss: 1.8806949853897095
Validation loss: 2.1637162367502847

Epoch: 5| Step: 7
Training loss: 1.4060686826705933
Validation loss: 2.14799427986145

Epoch: 5| Step: 8
Training loss: 1.8869088888168335
Validation loss: 2.155082811911901

Epoch: 5| Step: 9
Training loss: 1.2886147499084473
Validation loss: 2.1722039779027305

Epoch: 5| Step: 10
Training loss: 1.9743353128433228
Validation loss: 2.155710553129514

Epoch: 5| Step: 11
Training loss: 2.2394485473632812
Validation loss: 2.1810475339492164

Epoch: 313| Step: 0
Training loss: 1.9427722692489624
Validation loss: 2.1837724347909293

Epoch: 5| Step: 1
Training loss: 2.5067081451416016
Validation loss: 2.2007518212000527

Epoch: 5| Step: 2
Training loss: 1.2304521799087524
Validation loss: 2.197188546260198

Epoch: 5| Step: 3
Training loss: 1.3185856342315674
Validation loss: 2.206805835167567

Epoch: 5| Step: 4
Training loss: 1.5420993566513062
Validation loss: 2.2262667467196784

Epoch: 5| Step: 5
Training loss: 2.0942630767822266
Validation loss: 2.187627598643303

Epoch: 5| Step: 6
Training loss: 2.0439109802246094
Validation loss: 2.2103480299313865

Epoch: 5| Step: 7
Training loss: 1.9223827123641968
Validation loss: 2.2021517008543015

Epoch: 5| Step: 8
Training loss: 1.4620838165283203
Validation loss: 2.2173277338345847

Epoch: 5| Step: 9
Training loss: 1.555290937423706
Validation loss: 2.2168279041846595

Epoch: 5| Step: 10
Training loss: 1.2482900619506836
Validation loss: 2.2211570541063943

Epoch: 5| Step: 11
Training loss: 1.0029375553131104
Validation loss: 2.1836538910865784

Epoch: 314| Step: 0
Training loss: 2.3381240367889404
Validation loss: 2.2235138515631356

Epoch: 5| Step: 1
Training loss: 1.7774425745010376
Validation loss: 2.1991227567195892

Epoch: 5| Step: 2
Training loss: 1.4530187845230103
Validation loss: 2.2138422578573227

Epoch: 5| Step: 3
Training loss: 1.4189616441726685
Validation loss: 2.223148375749588

Epoch: 5| Step: 4
Training loss: 1.7479032278060913
Validation loss: 2.2481080194314322

Epoch: 5| Step: 5
Training loss: 1.806901216506958
Validation loss: 2.2171122084061303

Epoch: 5| Step: 6
Training loss: 1.9684288501739502
Validation loss: 2.2471878230571747

Epoch: 5| Step: 7
Training loss: 1.811171531677246
Validation loss: 2.222054640452067

Epoch: 5| Step: 8
Training loss: 0.9686604738235474
Validation loss: 2.233110189437866

Epoch: 5| Step: 9
Training loss: 2.0581884384155273
Validation loss: 2.254126658042272

Epoch: 5| Step: 10
Training loss: 1.3442260026931763
Validation loss: 2.2243882417678833

Epoch: 5| Step: 11
Training loss: 1.3503514528274536
Validation loss: 2.215697447458903

Epoch: 315| Step: 0
Training loss: 2.0555005073547363
Validation loss: 2.2200109461943307

Epoch: 5| Step: 1
Training loss: 1.6313518285751343
Validation loss: 2.1981769700845084

Epoch: 5| Step: 2
Training loss: 2.063539981842041
Validation loss: 2.183078318834305

Epoch: 5| Step: 3
Training loss: 1.2874505519866943
Validation loss: 2.2167813181877136

Epoch: 5| Step: 4
Training loss: 1.9176933765411377
Validation loss: 2.199211080869039

Epoch: 5| Step: 5
Training loss: 2.132690906524658
Validation loss: 2.189663181702296

Epoch: 5| Step: 6
Training loss: 1.5413397550582886
Validation loss: 2.1696813901265464

Epoch: 5| Step: 7
Training loss: 1.5364534854888916
Validation loss: 2.18379408121109

Epoch: 5| Step: 8
Training loss: 1.03677499294281
Validation loss: 2.1803725957870483

Epoch: 5| Step: 9
Training loss: 1.5535895824432373
Validation loss: 2.16268227994442

Epoch: 5| Step: 10
Training loss: 1.3641597032546997
Validation loss: 2.1800415068864822

Epoch: 5| Step: 11
Training loss: 2.1692962646484375
Validation loss: 2.1734353999296823

Epoch: 316| Step: 0
Training loss: 2.379747152328491
Validation loss: 2.184099997083346

Epoch: 5| Step: 1
Training loss: 1.922579050064087
Validation loss: 2.1959079951047897

Epoch: 5| Step: 2
Training loss: 1.4222559928894043
Validation loss: 2.166665797432264

Epoch: 5| Step: 3
Training loss: 1.5393364429473877
Validation loss: 2.195265516638756

Epoch: 5| Step: 4
Training loss: 1.5720081329345703
Validation loss: 2.1884191632270813

Epoch: 5| Step: 5
Training loss: 1.9731786251068115
Validation loss: 2.171644389629364

Epoch: 5| Step: 6
Training loss: 2.1017229557037354
Validation loss: 2.1671025156974792

Epoch: 5| Step: 7
Training loss: 1.2163869142532349
Validation loss: 2.174069960912069

Epoch: 5| Step: 8
Training loss: 1.312995195388794
Validation loss: 2.153432846069336

Epoch: 5| Step: 9
Training loss: 1.18839430809021
Validation loss: 2.146165892481804

Epoch: 5| Step: 10
Training loss: 1.5572359561920166
Validation loss: 2.118774890899658

Epoch: 5| Step: 11
Training loss: 2.5649871826171875
Validation loss: 2.1142932126919427

Epoch: 317| Step: 0
Training loss: 1.023308515548706
Validation loss: 2.138353625933329

Epoch: 5| Step: 1
Training loss: 1.9584534168243408
Validation loss: 2.1237617433071136

Epoch: 5| Step: 2
Training loss: 1.5798957347869873
Validation loss: 2.1281267950932183

Epoch: 5| Step: 3
Training loss: 1.6613374948501587
Validation loss: 2.139865438143412

Epoch: 5| Step: 4
Training loss: 1.5074306726455688
Validation loss: 2.155136595169703

Epoch: 5| Step: 5
Training loss: 1.6450386047363281
Validation loss: 2.149982273578644

Epoch: 5| Step: 6
Training loss: 1.7046209573745728
Validation loss: 2.14923823873202

Epoch: 5| Step: 7
Training loss: 2.060385227203369
Validation loss: 2.1547747254371643

Epoch: 5| Step: 8
Training loss: 1.7953593730926514
Validation loss: 2.157797728975614

Epoch: 5| Step: 9
Training loss: 1.545504093170166
Validation loss: 2.182468260327975

Epoch: 5| Step: 10
Training loss: 2.01342511177063
Validation loss: 2.193803295493126

Epoch: 5| Step: 11
Training loss: 1.113971471786499
Validation loss: 2.187468176086744

Epoch: 318| Step: 0
Training loss: 1.3229506015777588
Validation loss: 2.1645931005477905

Epoch: 5| Step: 1
Training loss: 1.3416242599487305
Validation loss: 2.151799981792768

Epoch: 5| Step: 2
Training loss: 1.2380963563919067
Validation loss: 2.1623092542092004

Epoch: 5| Step: 3
Training loss: 1.5830706357955933
Validation loss: 2.1527771751085916

Epoch: 5| Step: 4
Training loss: 1.2485666275024414
Validation loss: 2.1635460555553436

Epoch: 5| Step: 5
Training loss: 1.8568881750106812
Validation loss: 2.1557515213886895

Epoch: 5| Step: 6
Training loss: 1.2424633502960205
Validation loss: 2.167479395866394

Epoch: 5| Step: 7
Training loss: 2.4259872436523438
Validation loss: 2.15640789270401

Epoch: 5| Step: 8
Training loss: 1.9672027826309204
Validation loss: 2.1419497430324554

Epoch: 5| Step: 9
Training loss: 2.4044029712677
Validation loss: 2.153623322645823

Epoch: 5| Step: 10
Training loss: 1.442902684211731
Validation loss: 2.1437083383401236

Epoch: 5| Step: 11
Training loss: 1.890958309173584
Validation loss: 2.16704889635245

Epoch: 319| Step: 0
Training loss: 1.6263272762298584
Validation loss: 2.185337081551552

Epoch: 5| Step: 1
Training loss: 1.6325210332870483
Validation loss: 2.222322702407837

Epoch: 5| Step: 2
Training loss: 1.5210683345794678
Validation loss: 2.204218029975891

Epoch: 5| Step: 3
Training loss: 1.5910236835479736
Validation loss: 2.211161678036054

Epoch: 5| Step: 4
Training loss: 1.8891271352767944
Validation loss: 2.1876557817061744

Epoch: 5| Step: 5
Training loss: 1.7181055545806885
Validation loss: 2.216170012950897

Epoch: 5| Step: 6
Training loss: 1.6435877084732056
Validation loss: 2.1934259831905365

Epoch: 5| Step: 7
Training loss: 1.1659762859344482
Validation loss: 2.2113004525502524

Epoch: 5| Step: 8
Training loss: 1.9558429718017578
Validation loss: 2.1920361667871475

Epoch: 5| Step: 9
Training loss: 2.136043071746826
Validation loss: 2.194429705540339

Epoch: 5| Step: 10
Training loss: 1.3927466869354248
Validation loss: 2.1909255186716714

Epoch: 5| Step: 11
Training loss: 1.3928769826889038
Validation loss: 2.185029367605845

Epoch: 320| Step: 0
Training loss: 0.8634213209152222
Validation loss: 2.1874753584464393

Epoch: 5| Step: 1
Training loss: 1.9799121618270874
Validation loss: 2.177249918381373

Epoch: 5| Step: 2
Training loss: 1.198925256729126
Validation loss: 2.1731947312752404

Epoch: 5| Step: 3
Training loss: 1.3733197450637817
Validation loss: 2.1819227933883667

Epoch: 5| Step: 4
Training loss: 2.130993127822876
Validation loss: 2.1918861269950867

Epoch: 5| Step: 5
Training loss: 1.4197790622711182
Validation loss: 2.176898797353109

Epoch: 5| Step: 6
Training loss: 1.6043800115585327
Validation loss: 2.193629210193952

Epoch: 5| Step: 7
Training loss: 2.0640358924865723
Validation loss: 2.2039300302664437

Epoch: 5| Step: 8
Training loss: 2.2796053886413574
Validation loss: 2.2366396387418113

Epoch: 5| Step: 9
Training loss: 1.613290786743164
Validation loss: 2.220349818468094

Epoch: 5| Step: 10
Training loss: 1.9484069347381592
Validation loss: 2.22654989361763

Epoch: 5| Step: 11
Training loss: 2.2323639392852783
Validation loss: 2.2406998773415885

Epoch: 321| Step: 0
Training loss: 1.449135422706604
Validation loss: 2.2125534961620965

Epoch: 5| Step: 1
Training loss: 1.5651838779449463
Validation loss: 2.208873371283213

Epoch: 5| Step: 2
Training loss: 1.973716378211975
Validation loss: 2.1797834634780884

Epoch: 5| Step: 3
Training loss: 1.6129401922225952
Validation loss: 2.1717487573623657

Epoch: 5| Step: 4
Training loss: 1.4430162906646729
Validation loss: 2.1552809874216714

Epoch: 5| Step: 5
Training loss: 1.538874864578247
Validation loss: 2.1687417328357697

Epoch: 5| Step: 6
Training loss: 1.155438780784607
Validation loss: 2.1733864545822144

Epoch: 5| Step: 7
Training loss: 1.2419344186782837
Validation loss: 2.1741285026073456

Epoch: 5| Step: 8
Training loss: 2.1214983463287354
Validation loss: 2.1663533548514047

Epoch: 5| Step: 9
Training loss: 1.846213936805725
Validation loss: 2.131473869085312

Epoch: 5| Step: 10
Training loss: 1.9889634847640991
Validation loss: 2.167059689760208

Epoch: 5| Step: 11
Training loss: 1.529491662979126
Validation loss: 2.1543683211008706

Epoch: 322| Step: 0
Training loss: 1.661015272140503
Validation loss: 2.1597397873799005

Epoch: 5| Step: 1
Training loss: 1.9841045141220093
Validation loss: 2.1619557489951453

Epoch: 5| Step: 2
Training loss: 1.9772087335586548
Validation loss: 2.154688293735186

Epoch: 5| Step: 3
Training loss: 1.2682775259017944
Validation loss: 2.149886647860209

Epoch: 5| Step: 4
Training loss: 1.854909896850586
Validation loss: 2.14054407676061

Epoch: 5| Step: 5
Training loss: 1.404723048210144
Validation loss: 2.147421275575956

Epoch: 5| Step: 6
Training loss: 1.4820339679718018
Validation loss: 2.140356491009394

Epoch: 5| Step: 7
Training loss: 1.660557746887207
Validation loss: 2.1598834892114005

Epoch: 5| Step: 8
Training loss: 0.9455057382583618
Validation loss: 2.1540518701076508

Epoch: 5| Step: 9
Training loss: 1.6878726482391357
Validation loss: 2.1307747264703116

Epoch: 5| Step: 10
Training loss: 1.546776294708252
Validation loss: 2.163267900546392

Epoch: 5| Step: 11
Training loss: 3.2928647994995117
Validation loss: 2.1819014151891074

Epoch: 323| Step: 0
Training loss: 1.4725967645645142
Validation loss: 2.198153187831243

Epoch: 5| Step: 1
Training loss: 1.5798909664154053
Validation loss: 2.208327422539393

Epoch: 5| Step: 2
Training loss: 1.7938064336776733
Validation loss: 2.197600543498993

Epoch: 5| Step: 3
Training loss: 1.826776146888733
Validation loss: 2.218007981777191

Epoch: 5| Step: 4
Training loss: 2.0920114517211914
Validation loss: 2.2499034702777863

Epoch: 5| Step: 5
Training loss: 2.03468656539917
Validation loss: 2.2317810654640198

Epoch: 5| Step: 6
Training loss: 2.2151858806610107
Validation loss: 2.239335760474205

Epoch: 5| Step: 7
Training loss: 1.4503036737442017
Validation loss: 2.2191977302233377

Epoch: 5| Step: 8
Training loss: 1.5073108673095703
Validation loss: 2.2270964483420053

Epoch: 5| Step: 9
Training loss: 1.7155990600585938
Validation loss: 2.2414443641901016

Epoch: 5| Step: 10
Training loss: 1.5385878086090088
Validation loss: 2.2283417681852975

Epoch: 5| Step: 11
Training loss: 0.43917417526245117
Validation loss: 2.198226730028788

Epoch: 324| Step: 0
Training loss: 1.7112979888916016
Validation loss: 2.1743105351924896

Epoch: 5| Step: 1
Training loss: 1.3565289974212646
Validation loss: 2.1765627513329187

Epoch: 5| Step: 2
Training loss: 2.6436448097229004
Validation loss: 2.1616297513246536

Epoch: 5| Step: 3
Training loss: 2.155531644821167
Validation loss: 2.1651119689146676

Epoch: 5| Step: 4
Training loss: 1.935546875
Validation loss: 2.1791471590598426

Epoch: 5| Step: 5
Training loss: 1.1580159664154053
Validation loss: 2.18311870098114

Epoch: 5| Step: 6
Training loss: 1.8747714757919312
Validation loss: 2.1716842701037726

Epoch: 5| Step: 7
Training loss: 2.3328120708465576
Validation loss: 2.1823314478000007

Epoch: 5| Step: 8
Training loss: 1.6577247381210327
Validation loss: 2.173662339647611

Epoch: 5| Step: 9
Training loss: 2.495676040649414
Validation loss: 2.2107939620812735

Epoch: 5| Step: 10
Training loss: 1.4548219442367554
Validation loss: 2.1892959028482437

Epoch: 5| Step: 11
Training loss: 1.3196252584457397
Validation loss: 2.228310465812683

Epoch: 325| Step: 0
Training loss: 1.5782073736190796
Validation loss: 2.231969957550367

Epoch: 5| Step: 1
Training loss: 1.8804908990859985
Validation loss: 2.242795765399933

Epoch: 5| Step: 2
Training loss: 1.2824156284332275
Validation loss: 2.252271090944608

Epoch: 5| Step: 3
Training loss: 1.607659101486206
Validation loss: 2.239507883787155

Epoch: 5| Step: 4
Training loss: 1.2381025552749634
Validation loss: 2.2714951187372208

Epoch: 5| Step: 5
Training loss: 1.9444599151611328
Validation loss: 2.2600569327672324

Epoch: 5| Step: 6
Training loss: 1.7664130926132202
Validation loss: 2.2750363945961

Epoch: 5| Step: 7
Training loss: 1.792930006980896
Validation loss: 2.2637489835421243

Epoch: 5| Step: 8
Training loss: 2.010924816131592
Validation loss: 2.268962795535723

Epoch: 5| Step: 9
Training loss: 1.8056490421295166
Validation loss: 2.2571440637111664

Epoch: 5| Step: 10
Training loss: 1.985369086265564
Validation loss: 2.2373973478873572

Epoch: 5| Step: 11
Training loss: 1.0741885900497437
Validation loss: 2.2296208490928016

Epoch: 326| Step: 0
Training loss: 1.2024673223495483
Validation loss: 2.222596680124601

Epoch: 5| Step: 1
Training loss: 2.09101939201355
Validation loss: 2.208184321721395

Epoch: 5| Step: 2
Training loss: 0.8246099352836609
Validation loss: 2.2155963281790414

Epoch: 5| Step: 3
Training loss: 2.2603325843811035
Validation loss: 2.210804929335912

Epoch: 5| Step: 4
Training loss: 1.946219801902771
Validation loss: 2.161206305027008

Epoch: 5| Step: 5
Training loss: 1.6633203029632568
Validation loss: 2.2011260936657586

Epoch: 5| Step: 6
Training loss: 1.7727534770965576
Validation loss: 2.1857971996068954

Epoch: 5| Step: 7
Training loss: 2.0611252784729004
Validation loss: 2.1821589718262353

Epoch: 5| Step: 8
Training loss: 0.9206655621528625
Validation loss: 2.1819819708665213

Epoch: 5| Step: 9
Training loss: 1.2405321598052979
Validation loss: 2.1958950459957123

Epoch: 5| Step: 10
Training loss: 2.166656017303467
Validation loss: 2.1891586581865945

Epoch: 5| Step: 11
Training loss: 1.5235176086425781
Validation loss: 2.174958427747091

Epoch: 327| Step: 0
Training loss: 1.6192538738250732
Validation loss: 2.180943931142489

Epoch: 5| Step: 1
Training loss: 1.4674327373504639
Validation loss: 2.1945544481277466

Epoch: 5| Step: 2
Training loss: 1.7823909521102905
Validation loss: 2.1918713649113974

Epoch: 5| Step: 3
Training loss: 1.9138882160186768
Validation loss: 2.2021331787109375

Epoch: 5| Step: 4
Training loss: 1.548377275466919
Validation loss: 2.2135917643706002

Epoch: 5| Step: 5
Training loss: 1.4976379871368408
Validation loss: 2.2274954120318093

Epoch: 5| Step: 6
Training loss: 1.9098562002182007
Validation loss: 2.2310899595419564

Epoch: 5| Step: 7
Training loss: 1.102076768875122
Validation loss: 2.2290284434954324

Epoch: 5| Step: 8
Training loss: 2.2407422065734863
Validation loss: 2.22977880636851

Epoch: 5| Step: 9
Training loss: 1.773376703262329
Validation loss: 2.2280988643566766

Epoch: 5| Step: 10
Training loss: 1.3629918098449707
Validation loss: 2.2259294291337333

Epoch: 5| Step: 11
Training loss: 1.7968684434890747
Validation loss: 2.218328376611074

Epoch: 328| Step: 0
Training loss: 1.9207550287246704
Validation loss: 2.192649483680725

Epoch: 5| Step: 1
Training loss: 1.3652217388153076
Validation loss: 2.1989560623963675

Epoch: 5| Step: 2
Training loss: 1.6721417903900146
Validation loss: 2.170376261075338

Epoch: 5| Step: 3
Training loss: 1.5426914691925049
Validation loss: 2.195125783483187

Epoch: 5| Step: 4
Training loss: 1.519225001335144
Validation loss: 2.1843128303686776

Epoch: 5| Step: 5
Training loss: 1.71435546875
Validation loss: 2.1923909783363342

Epoch: 5| Step: 6
Training loss: 1.8788459300994873
Validation loss: 2.207293892900149

Epoch: 5| Step: 7
Training loss: 1.5319037437438965
Validation loss: 2.220531622568766

Epoch: 5| Step: 8
Training loss: 1.4755727052688599
Validation loss: 2.195849488178889

Epoch: 5| Step: 9
Training loss: 1.8470637798309326
Validation loss: 2.2057166198889413

Epoch: 5| Step: 10
Training loss: 1.6662935018539429
Validation loss: 2.1877196033795676

Epoch: 5| Step: 11
Training loss: 2.736588478088379
Validation loss: 2.2057666182518005

Epoch: 329| Step: 0
Training loss: 2.0905098915100098
Validation loss: 2.201431448260943

Epoch: 5| Step: 1
Training loss: 1.734423041343689
Validation loss: 2.186911384264628

Epoch: 5| Step: 2
Training loss: 1.8568538427352905
Validation loss: 2.202038789788882

Epoch: 5| Step: 3
Training loss: 2.2382614612579346
Validation loss: 2.1750621845324836

Epoch: 5| Step: 4
Training loss: 0.9206339120864868
Validation loss: 2.182063336173693

Epoch: 5| Step: 5
Training loss: 1.487541675567627
Validation loss: 2.178325802087784

Epoch: 5| Step: 6
Training loss: 1.3593602180480957
Validation loss: 2.1876499305168786

Epoch: 5| Step: 7
Training loss: 1.4518742561340332
Validation loss: 2.1793656249841056

Epoch: 5| Step: 8
Training loss: 1.4192020893096924
Validation loss: 2.174715667963028

Epoch: 5| Step: 9
Training loss: 2.1255240440368652
Validation loss: 2.171335225303968

Epoch: 5| Step: 10
Training loss: 1.6751571893692017
Validation loss: 2.18663622935613

Epoch: 5| Step: 11
Training loss: 2.526780843734741
Validation loss: 2.1927250921726227

Epoch: 330| Step: 0
Training loss: 1.9424759149551392
Validation loss: 2.1955934961636863

Epoch: 5| Step: 1
Training loss: 1.803356409072876
Validation loss: 2.2028742730617523

Epoch: 5| Step: 2
Training loss: 1.2590891122817993
Validation loss: 2.199517995119095

Epoch: 5| Step: 3
Training loss: 1.811108946800232
Validation loss: 2.2217818796634674

Epoch: 5| Step: 4
Training loss: 2.402508497238159
Validation loss: 2.211627796292305

Epoch: 5| Step: 5
Training loss: 1.1776177883148193
Validation loss: 2.1679550607999167

Epoch: 5| Step: 6
Training loss: 1.1997268199920654
Validation loss: 2.1759736388921738

Epoch: 5| Step: 7
Training loss: 1.8512054681777954
Validation loss: 2.205538436770439

Epoch: 5| Step: 8
Training loss: 1.4707176685333252
Validation loss: 2.184316784143448

Epoch: 5| Step: 9
Training loss: 1.6320140361785889
Validation loss: 2.1858842273553214

Epoch: 5| Step: 10
Training loss: 1.742344617843628
Validation loss: 2.1718843181928

Epoch: 5| Step: 11
Training loss: 1.2030482292175293
Validation loss: 2.1702206134796143

Epoch: 331| Step: 0
Training loss: 1.3785467147827148
Validation loss: 2.1803726255893707

Epoch: 5| Step: 1
Training loss: 1.853891372680664
Validation loss: 2.2032733410596848

Epoch: 5| Step: 2
Training loss: 1.046702265739441
Validation loss: 2.220537225405375

Epoch: 5| Step: 3
Training loss: 2.0168111324310303
Validation loss: 2.2348469694455466

Epoch: 5| Step: 4
Training loss: 2.3193726539611816
Validation loss: 2.2214679767688117

Epoch: 5| Step: 5
Training loss: 1.392662525177002
Validation loss: 2.2047069668769836

Epoch: 5| Step: 6
Training loss: 1.3861335515975952
Validation loss: 2.2221456666787467

Epoch: 5| Step: 7
Training loss: 1.5607835054397583
Validation loss: 2.2175157268842063

Epoch: 5| Step: 8
Training loss: 1.672115683555603
Validation loss: 2.2168957690397897

Epoch: 5| Step: 9
Training loss: 1.7062534093856812
Validation loss: 2.1940419524908066

Epoch: 5| Step: 10
Training loss: 1.5953792333602905
Validation loss: 2.181547482808431

Epoch: 5| Step: 11
Training loss: 0.9375162124633789
Validation loss: 2.1880035996437073

Epoch: 332| Step: 0
Training loss: 1.458472490310669
Validation loss: 2.204318806529045

Epoch: 5| Step: 1
Training loss: 1.2495887279510498
Validation loss: 2.180109888315201

Epoch: 5| Step: 2
Training loss: 2.1175148487091064
Validation loss: 2.1965341170628867

Epoch: 5| Step: 3
Training loss: 1.6450631618499756
Validation loss: 2.20608743528525

Epoch: 5| Step: 4
Training loss: 1.1863443851470947
Validation loss: 2.212357853849729

Epoch: 5| Step: 5
Training loss: 1.2099177837371826
Validation loss: 2.2123103588819504

Epoch: 5| Step: 6
Training loss: 1.320178508758545
Validation loss: 2.2369195421536765

Epoch: 5| Step: 7
Training loss: 1.7540013790130615
Validation loss: 2.2015671133995056

Epoch: 5| Step: 8
Training loss: 1.6865520477294922
Validation loss: 2.2234598845243454

Epoch: 5| Step: 9
Training loss: 1.9902786016464233
Validation loss: 2.2200832813978195

Epoch: 5| Step: 10
Training loss: 2.1018290519714355
Validation loss: 2.228678191701571

Epoch: 5| Step: 11
Training loss: 1.9308444261550903
Validation loss: 2.220031902194023

Epoch: 333| Step: 0
Training loss: 1.5324630737304688
Validation loss: 2.2294990619023642

Epoch: 5| Step: 1
Training loss: 1.4468759298324585
Validation loss: 2.198526084423065

Epoch: 5| Step: 2
Training loss: 1.3264092206954956
Validation loss: 2.1836821138858795

Epoch: 5| Step: 3
Training loss: 2.1833598613739014
Validation loss: 2.1829349795977273

Epoch: 5| Step: 4
Training loss: 1.3372342586517334
Validation loss: 2.176265964905421

Epoch: 5| Step: 5
Training loss: 1.907766580581665
Validation loss: 2.157297303279241

Epoch: 5| Step: 6
Training loss: 1.707760214805603
Validation loss: 2.1688373684883118

Epoch: 5| Step: 7
Training loss: 1.4352197647094727
Validation loss: 2.132556920250257

Epoch: 5| Step: 8
Training loss: 1.4572865962982178
Validation loss: 2.142569124698639

Epoch: 5| Step: 9
Training loss: 1.3088908195495605
Validation loss: 2.1358059297005334

Epoch: 5| Step: 10
Training loss: 1.9081144332885742
Validation loss: 2.1403195907672248

Epoch: 5| Step: 11
Training loss: 1.1795744895935059
Validation loss: 2.1497850120067596

Epoch: 334| Step: 0
Training loss: 1.5630346536636353
Validation loss: 2.1704507817824683

Epoch: 5| Step: 1
Training loss: 1.8488242626190186
Validation loss: 2.17325492699941

Epoch: 5| Step: 2
Training loss: 1.8693736791610718
Validation loss: 2.184235339363416

Epoch: 5| Step: 3
Training loss: 1.2665555477142334
Validation loss: 2.159673144419988

Epoch: 5| Step: 4
Training loss: 2.0889973640441895
Validation loss: 2.156147430340449

Epoch: 5| Step: 5
Training loss: 1.3935086727142334
Validation loss: 2.1598325769106546

Epoch: 5| Step: 6
Training loss: 1.959752082824707
Validation loss: 2.1542261242866516

Epoch: 5| Step: 7
Training loss: 1.7456862926483154
Validation loss: 2.1480932235717773

Epoch: 5| Step: 8
Training loss: 1.1380387544631958
Validation loss: 2.1717216869195304

Epoch: 5| Step: 9
Training loss: 1.9635283946990967
Validation loss: 2.1886466443538666

Epoch: 5| Step: 10
Training loss: 1.183840036392212
Validation loss: 2.1903776129086814

Epoch: 5| Step: 11
Training loss: 1.63203763961792
Validation loss: 2.2120005190372467

Epoch: 335| Step: 0
Training loss: 1.286304235458374
Validation loss: 2.1808676471312842

Epoch: 5| Step: 1
Training loss: 1.6528174877166748
Validation loss: 2.204313188791275

Epoch: 5| Step: 2
Training loss: 1.7456305027008057
Validation loss: 2.193897992372513

Epoch: 5| Step: 3
Training loss: 1.1490904092788696
Validation loss: 2.224433496594429

Epoch: 5| Step: 4
Training loss: 1.6347755193710327
Validation loss: 2.20140374203523

Epoch: 5| Step: 5
Training loss: 1.3799216747283936
Validation loss: 2.2244628171126046

Epoch: 5| Step: 6
Training loss: 1.5240559577941895
Validation loss: 2.2042287985483804

Epoch: 5| Step: 7
Training loss: 1.4840186834335327
Validation loss: 2.1691888719797134

Epoch: 5| Step: 8
Training loss: 2.7542195320129395
Validation loss: 2.192330300807953

Epoch: 5| Step: 9
Training loss: 1.5889308452606201
Validation loss: 2.1846692264080048

Epoch: 5| Step: 10
Training loss: 1.5690051317214966
Validation loss: 2.2112390299638114

Epoch: 5| Step: 11
Training loss: 0.8097901344299316
Validation loss: 2.2014878491560617

Epoch: 336| Step: 0
Training loss: 1.322190284729004
Validation loss: 2.233723670244217

Epoch: 5| Step: 1
Training loss: 2.0925586223602295
Validation loss: 2.2378456741571426

Epoch: 5| Step: 2
Training loss: 1.6361221075057983
Validation loss: 2.212859829266866

Epoch: 5| Step: 3
Training loss: 1.793859839439392
Validation loss: 2.2333247115214667

Epoch: 5| Step: 4
Training loss: 1.9083969593048096
Validation loss: 2.2491915822029114

Epoch: 5| Step: 5
Training loss: 1.832815170288086
Validation loss: 2.252588222424189

Epoch: 5| Step: 6
Training loss: 1.4622266292572021
Validation loss: 2.243660256266594

Epoch: 5| Step: 7
Training loss: 1.8659675121307373
Validation loss: 2.2263879626989365

Epoch: 5| Step: 8
Training loss: 1.08713960647583
Validation loss: 2.1897761772076287

Epoch: 5| Step: 9
Training loss: 1.8748801946640015
Validation loss: 2.1904488106568656

Epoch: 5| Step: 10
Training loss: 1.4288909435272217
Validation loss: 2.1915119538704553

Epoch: 5| Step: 11
Training loss: 1.9216749668121338
Validation loss: 2.185638904571533

Epoch: 337| Step: 0
Training loss: 1.6057296991348267
Validation loss: 2.172686532139778

Epoch: 5| Step: 1
Training loss: 2.00630521774292
Validation loss: 2.2143060068289437

Epoch: 5| Step: 2
Training loss: 1.5495851039886475
Validation loss: 2.215294972062111

Epoch: 5| Step: 3
Training loss: 1.7574994564056396
Validation loss: 2.226891721288363

Epoch: 5| Step: 4
Training loss: 2.245192050933838
Validation loss: 2.244035998980204

Epoch: 5| Step: 5
Training loss: 1.5294959545135498
Validation loss: 2.2525934676329293

Epoch: 5| Step: 6
Training loss: 1.2681440114974976
Validation loss: 2.2552430431048074

Epoch: 5| Step: 7
Training loss: 1.9796454906463623
Validation loss: 2.2716155548890433

Epoch: 5| Step: 8
Training loss: 1.3621747493743896
Validation loss: 2.2184180418650308

Epoch: 5| Step: 9
Training loss: 1.9799220561981201
Validation loss: 2.2165601948897042

Epoch: 5| Step: 10
Training loss: 1.2535749673843384
Validation loss: 2.202390670776367

Epoch: 5| Step: 11
Training loss: 0.8059684038162231
Validation loss: 2.210125138362249

Epoch: 338| Step: 0
Training loss: 1.296188235282898
Validation loss: 2.176683316628138

Epoch: 5| Step: 1
Training loss: 1.3786613941192627
Validation loss: 2.1912492414315543

Epoch: 5| Step: 2
Training loss: 1.139565348625183
Validation loss: 2.1504462560017905

Epoch: 5| Step: 3
Training loss: 1.7638070583343506
Validation loss: 2.1708768208821616

Epoch: 5| Step: 4
Training loss: 1.2666815519332886
Validation loss: 2.1687430838743844

Epoch: 5| Step: 5
Training loss: 1.9567703008651733
Validation loss: 2.159711241722107

Epoch: 5| Step: 6
Training loss: 1.35362708568573
Validation loss: 2.1487594644228616

Epoch: 5| Step: 7
Training loss: 1.7674719095230103
Validation loss: 2.1411051402489343

Epoch: 5| Step: 8
Training loss: 1.9471899271011353
Validation loss: 2.130361184477806

Epoch: 5| Step: 9
Training loss: 2.177588701248169
Validation loss: 2.149020716547966

Epoch: 5| Step: 10
Training loss: 1.3065448999404907
Validation loss: 2.159801652034124

Epoch: 5| Step: 11
Training loss: 1.7717859745025635
Validation loss: 2.163202424844106

Epoch: 339| Step: 0
Training loss: 1.739070177078247
Validation loss: 2.1702167838811874

Epoch: 5| Step: 1
Training loss: 1.4990336894989014
Validation loss: 2.1330676128466926

Epoch: 5| Step: 2
Training loss: 1.1831419467926025
Validation loss: 2.1254986425240836

Epoch: 5| Step: 3
Training loss: 1.5848057270050049
Validation loss: 2.1248233069976172

Epoch: 5| Step: 4
Training loss: 1.6234050989151
Validation loss: 2.1577463199694953

Epoch: 5| Step: 5
Training loss: 1.6495616436004639
Validation loss: 2.1379082103570304

Epoch: 5| Step: 6
Training loss: 1.6103003025054932
Validation loss: 2.148688495159149

Epoch: 5| Step: 7
Training loss: 1.6022857427597046
Validation loss: 2.12811612089475

Epoch: 5| Step: 8
Training loss: 2.236182689666748
Validation loss: 2.1471600979566574

Epoch: 5| Step: 9
Training loss: 1.4410803318023682
Validation loss: 2.1425288220246634

Epoch: 5| Step: 10
Training loss: 1.4767239093780518
Validation loss: 2.160348971684774

Epoch: 5| Step: 11
Training loss: 0.718176543712616
Validation loss: 2.1657156397898993

Epoch: 340| Step: 0
Training loss: 1.840989112854004
Validation loss: 2.171925430496534

Epoch: 5| Step: 1
Training loss: 1.717864990234375
Validation loss: 2.1822304725646973

Epoch: 5| Step: 2
Training loss: 1.8951886892318726
Validation loss: 2.1779509435097375

Epoch: 5| Step: 3
Training loss: 1.051784634590149
Validation loss: 2.164281909664472

Epoch: 5| Step: 4
Training loss: 1.2833997011184692
Validation loss: 2.183329254388809

Epoch: 5| Step: 5
Training loss: 1.9441245794296265
Validation loss: 2.18422723809878

Epoch: 5| Step: 6
Training loss: 1.3920834064483643
Validation loss: 2.199718400835991

Epoch: 5| Step: 7
Training loss: 1.0410382747650146
Validation loss: 2.198057626684507

Epoch: 5| Step: 8
Training loss: 1.7532154321670532
Validation loss: 2.200565720597903

Epoch: 5| Step: 9
Training loss: 1.6784961223602295
Validation loss: 2.188252011934916

Epoch: 5| Step: 10
Training loss: 1.2395058870315552
Validation loss: 2.20529912908872

Epoch: 5| Step: 11
Training loss: 4.4766035079956055
Validation loss: 2.2036709040403366

Epoch: 341| Step: 0
Training loss: 1.784616470336914
Validation loss: 2.1837572157382965

Epoch: 5| Step: 1
Training loss: 1.4934523105621338
Validation loss: 2.215734302997589

Epoch: 5| Step: 2
Training loss: 1.4502441883087158
Validation loss: 2.195160592595736

Epoch: 5| Step: 3
Training loss: 1.7206757068634033
Validation loss: 2.19034572939078

Epoch: 5| Step: 4
Training loss: 1.5401166677474976
Validation loss: 2.1701285441716514

Epoch: 5| Step: 5
Training loss: 1.417536735534668
Validation loss: 2.1616822481155396

Epoch: 5| Step: 6
Training loss: 1.3548758029937744
Validation loss: 2.2079822619756064

Epoch: 5| Step: 7
Training loss: 1.697689414024353
Validation loss: 2.1876125435034433

Epoch: 5| Step: 8
Training loss: 1.5890783071517944
Validation loss: 2.163746585448583

Epoch: 5| Step: 9
Training loss: 1.9891605377197266
Validation loss: 2.1957921236753464

Epoch: 5| Step: 10
Training loss: 1.401918649673462
Validation loss: 2.19085930287838

Epoch: 5| Step: 11
Training loss: 1.6066410541534424
Validation loss: 2.2269229888916016

Epoch: 342| Step: 0
Training loss: 1.3290163278579712
Validation loss: 2.2154165705045066

Epoch: 5| Step: 1
Training loss: 1.741690993309021
Validation loss: 2.268438989917437

Epoch: 5| Step: 2
Training loss: 1.1345798969268799
Validation loss: 2.2541960378487906

Epoch: 5| Step: 3
Training loss: 1.9424453973770142
Validation loss: 2.2570101817448935

Epoch: 5| Step: 4
Training loss: 1.9283710718154907
Validation loss: 2.239022975166639

Epoch: 5| Step: 5
Training loss: 1.8264598846435547
Validation loss: 2.205475077033043

Epoch: 5| Step: 6
Training loss: 1.791925072669983
Validation loss: 2.217231889565786

Epoch: 5| Step: 7
Training loss: 1.3230282068252563
Validation loss: 2.2161686718463898

Epoch: 5| Step: 8
Training loss: 1.3263294696807861
Validation loss: 2.2090836564699807

Epoch: 5| Step: 9
Training loss: 1.799151062965393
Validation loss: 2.198127622405688

Epoch: 5| Step: 10
Training loss: 2.085573196411133
Validation loss: 2.206498165925344

Epoch: 5| Step: 11
Training loss: 2.5939292907714844
Validation loss: 2.214363137880961

Epoch: 343| Step: 0
Training loss: 1.4520854949951172
Validation loss: 2.1826096971829734

Epoch: 5| Step: 1
Training loss: 1.9187889099121094
Validation loss: 2.1881462583939233

Epoch: 5| Step: 2
Training loss: 1.5957732200622559
Validation loss: 2.201942970355352

Epoch: 5| Step: 3
Training loss: 1.1868009567260742
Validation loss: 2.1844143321116767

Epoch: 5| Step: 4
Training loss: 1.5470329523086548
Validation loss: 2.152805437644323

Epoch: 5| Step: 5
Training loss: 1.2884820699691772
Validation loss: 2.2149439553419747

Epoch: 5| Step: 6
Training loss: 2.0810654163360596
Validation loss: 2.2092001289129257

Epoch: 5| Step: 7
Training loss: 1.505501389503479
Validation loss: 2.2527786095937095

Epoch: 5| Step: 8
Training loss: 1.907250165939331
Validation loss: 2.264180839061737

Epoch: 5| Step: 9
Training loss: 2.1694960594177246
Validation loss: 2.2431055704752603

Epoch: 5| Step: 10
Training loss: 1.5483278036117554
Validation loss: 2.2099915593862534

Epoch: 5| Step: 11
Training loss: 1.275535225868225
Validation loss: 2.199894999464353

Epoch: 344| Step: 0
Training loss: 2.21561336517334
Validation loss: 2.1773024598757424

Epoch: 5| Step: 1
Training loss: 0.9407365918159485
Validation loss: 2.1862860520680747

Epoch: 5| Step: 2
Training loss: 1.5688426494598389
Validation loss: 2.166025539239248

Epoch: 5| Step: 3
Training loss: 1.687034010887146
Validation loss: 2.172026053071022

Epoch: 5| Step: 4
Training loss: 1.484587550163269
Validation loss: 2.1590991963942847

Epoch: 5| Step: 5
Training loss: 1.9626976251602173
Validation loss: 2.1906824012597403

Epoch: 5| Step: 6
Training loss: 1.7561218738555908
Validation loss: 2.1826725900173187

Epoch: 5| Step: 7
Training loss: 1.7328513860702515
Validation loss: 2.1466550131638846

Epoch: 5| Step: 8
Training loss: 1.4205137491226196
Validation loss: 2.1927399734656015

Epoch: 5| Step: 9
Training loss: 1.3913360834121704
Validation loss: 2.2214530309041343

Epoch: 5| Step: 10
Training loss: 1.5841280221939087
Validation loss: 2.220977321267128

Epoch: 5| Step: 11
Training loss: 1.9713164567947388
Validation loss: 2.2433406561613083

Epoch: 345| Step: 0
Training loss: 1.5349044799804688
Validation loss: 2.2529959877332053

Epoch: 5| Step: 1
Training loss: 1.6521047353744507
Validation loss: 2.2387268443902335

Epoch: 5| Step: 2
Training loss: 2.0631020069122314
Validation loss: 2.2212896396716437

Epoch: 5| Step: 3
Training loss: 1.438183307647705
Validation loss: 2.2106314400831857

Epoch: 5| Step: 4
Training loss: 1.1568702459335327
Validation loss: 2.2302656322717667

Epoch: 5| Step: 5
Training loss: 1.9056600332260132
Validation loss: 2.1914262970288596

Epoch: 5| Step: 6
Training loss: 1.55476975440979
Validation loss: 2.217364326119423

Epoch: 5| Step: 7
Training loss: 1.4971907138824463
Validation loss: 2.211748639742533

Epoch: 5| Step: 8
Training loss: 1.1244266033172607
Validation loss: 2.2045434614022574

Epoch: 5| Step: 9
Training loss: 1.8722305297851562
Validation loss: 2.1688404083251953

Epoch: 5| Step: 10
Training loss: 1.862383246421814
Validation loss: 2.1494422604640326

Epoch: 5| Step: 11
Training loss: 1.2177793979644775
Validation loss: 2.1352540254592896

Epoch: 346| Step: 0
Training loss: 1.5632225275039673
Validation loss: 2.0964211920897164

Epoch: 5| Step: 1
Training loss: 1.6732536554336548
Validation loss: 2.110606541236242

Epoch: 5| Step: 2
Training loss: 1.3389480113983154
Validation loss: 2.145148073633512

Epoch: 5| Step: 3
Training loss: 1.5910835266113281
Validation loss: 2.131506085395813

Epoch: 5| Step: 4
Training loss: 1.4872747659683228
Validation loss: 2.1480754067500434

Epoch: 5| Step: 5
Training loss: 2.3850669860839844
Validation loss: 2.198693409562111

Epoch: 5| Step: 6
Training loss: 2.084376573562622
Validation loss: 2.2077695429325104

Epoch: 5| Step: 7
Training loss: 1.523551344871521
Validation loss: 2.1984215676784515

Epoch: 5| Step: 8
Training loss: 1.4410412311553955
Validation loss: 2.2265812754631042

Epoch: 5| Step: 9
Training loss: 2.146993637084961
Validation loss: 2.2544935444990792

Epoch: 5| Step: 10
Training loss: 1.6078121662139893
Validation loss: 2.263872812191645

Epoch: 5| Step: 11
Training loss: 2.062987804412842
Validation loss: 2.24236332376798

Epoch: 347| Step: 0
Training loss: 2.005887985229492
Validation loss: 2.21434955795606

Epoch: 5| Step: 1
Training loss: 1.2329556941986084
Validation loss: 2.207656299074491

Epoch: 5| Step: 2
Training loss: 1.2839361429214478
Validation loss: 2.1935724914073944

Epoch: 5| Step: 3
Training loss: 1.1468665599822998
Validation loss: 2.2075917224089303

Epoch: 5| Step: 4
Training loss: 2.340984344482422
Validation loss: 2.2055300126473107

Epoch: 5| Step: 5
Training loss: 2.2654123306274414
Validation loss: 2.2166445900996528

Epoch: 5| Step: 6
Training loss: 1.2770601511001587
Validation loss: 2.1918889780839286

Epoch: 5| Step: 7
Training loss: 1.8941253423690796
Validation loss: 2.2013149857521057

Epoch: 5| Step: 8
Training loss: 1.4192209243774414
Validation loss: 2.216243947545687

Epoch: 5| Step: 9
Training loss: 1.7301591634750366
Validation loss: 2.182266374429067

Epoch: 5| Step: 10
Training loss: 1.7045421600341797
Validation loss: 2.202242652575175

Epoch: 5| Step: 11
Training loss: 1.547792673110962
Validation loss: 2.1986836145321527

Epoch: 348| Step: 0
Training loss: 1.9070746898651123
Validation loss: 2.1806611667076745

Epoch: 5| Step: 1
Training loss: 1.4570518732070923
Validation loss: 2.177539567152659

Epoch: 5| Step: 2
Training loss: 1.8048655986785889
Validation loss: 2.201566686232885

Epoch: 5| Step: 3
Training loss: 1.1283600330352783
Validation loss: 2.1875067303578057

Epoch: 5| Step: 4
Training loss: 1.8964256048202515
Validation loss: 2.2307736029227576

Epoch: 5| Step: 5
Training loss: 1.880019187927246
Validation loss: 2.231025060017904

Epoch: 5| Step: 6
Training loss: 1.9217560291290283
Validation loss: 2.2258888681729636

Epoch: 5| Step: 7
Training loss: 1.9389228820800781
Validation loss: 2.2570577760537467

Epoch: 5| Step: 8
Training loss: 1.1060689687728882
Validation loss: 2.2509280294179916

Epoch: 5| Step: 9
Training loss: 1.189362645149231
Validation loss: 2.2313584138949714

Epoch: 5| Step: 10
Training loss: 1.643663763999939
Validation loss: 2.2306909958521524

Epoch: 5| Step: 11
Training loss: 2.486812114715576
Validation loss: 2.2534940938154855

Epoch: 349| Step: 0
Training loss: 1.6637649536132812
Validation loss: 2.2408399234215417

Epoch: 5| Step: 1
Training loss: 1.739306092262268
Validation loss: 2.2248883744080863

Epoch: 5| Step: 2
Training loss: 1.4788581132888794
Validation loss: 2.219948574900627

Epoch: 5| Step: 3
Training loss: 2.2554516792297363
Validation loss: 2.222127005457878

Epoch: 5| Step: 4
Training loss: 1.5353410243988037
Validation loss: 2.2286898444096246

Epoch: 5| Step: 5
Training loss: 0.9915976524353027
Validation loss: 2.212464382251104

Epoch: 5| Step: 6
Training loss: 1.6398084163665771
Validation loss: 2.1932525088389716

Epoch: 5| Step: 7
Training loss: 1.8826841115951538
Validation loss: 2.1877816319465637

Epoch: 5| Step: 8
Training loss: 1.4475843906402588
Validation loss: 2.1903377175331116

Epoch: 5| Step: 9
Training loss: 1.1597280502319336
Validation loss: 2.2052963922421136

Epoch: 5| Step: 10
Training loss: 1.7563610076904297
Validation loss: 2.2151891688505807

Epoch: 5| Step: 11
Training loss: 1.9438834190368652
Validation loss: 2.2178888022899628

Epoch: 350| Step: 0
Training loss: 1.166368007659912
Validation loss: 2.2192793786525726

Epoch: 5| Step: 1
Training loss: 1.553289532661438
Validation loss: 2.2212709287802377

Epoch: 5| Step: 2
Training loss: 1.08230459690094
Validation loss: 2.236126055320104

Epoch: 5| Step: 3
Training loss: 1.99411141872406
Validation loss: 2.218771060307821

Epoch: 5| Step: 4
Training loss: 1.3947641849517822
Validation loss: 2.229961544275284

Epoch: 5| Step: 5
Training loss: 1.3342448472976685
Validation loss: 2.1971671084562936

Epoch: 5| Step: 6
Training loss: 1.7606490850448608
Validation loss: 2.1988014429807663

Epoch: 5| Step: 7
Training loss: 1.36858332157135
Validation loss: 2.2145468493302665

Epoch: 5| Step: 8
Training loss: 1.8111610412597656
Validation loss: 2.21089498202006

Epoch: 5| Step: 9
Training loss: 1.5763185024261475
Validation loss: 2.1744731763998666

Epoch: 5| Step: 10
Training loss: 2.1495118141174316
Validation loss: 2.1796776354312897

Epoch: 5| Step: 11
Training loss: 1.7043497562408447
Validation loss: 2.1623799900213876

Epoch: 351| Step: 0
Training loss: 1.478432059288025
Validation loss: 2.1656766583522162

Epoch: 5| Step: 1
Training loss: 1.676690697669983
Validation loss: 2.1629032840331397

Epoch: 5| Step: 2
Training loss: 1.410495400428772
Validation loss: 2.1718535174926124

Epoch: 5| Step: 3
Training loss: 1.8023548126220703
Validation loss: 2.15482630332311

Epoch: 5| Step: 4
Training loss: 1.8740146160125732
Validation loss: 2.1357406824827194

Epoch: 5| Step: 5
Training loss: 1.1374337673187256
Validation loss: 2.1570540318886438

Epoch: 5| Step: 6
Training loss: 1.8121330738067627
Validation loss: 2.1546933948993683

Epoch: 5| Step: 7
Training loss: 1.610769510269165
Validation loss: 2.1467115680376687

Epoch: 5| Step: 8
Training loss: 1.9068485498428345
Validation loss: 2.1668343991041183

Epoch: 5| Step: 9
Training loss: 1.3344260454177856
Validation loss: 2.163983022173246

Epoch: 5| Step: 10
Training loss: 1.3803701400756836
Validation loss: 2.156439562638601

Epoch: 5| Step: 11
Training loss: 1.0740097761154175
Validation loss: 2.1413339326779046

Epoch: 352| Step: 0
Training loss: 1.7711570262908936
Validation loss: 2.1408129086097083

Epoch: 5| Step: 1
Training loss: 2.2053258419036865
Validation loss: 2.1296641727288566

Epoch: 5| Step: 2
Training loss: 1.6150243282318115
Validation loss: 2.1351571877797446

Epoch: 5| Step: 3
Training loss: 2.3673288822174072
Validation loss: 2.101627434293429

Epoch: 5| Step: 4
Training loss: 1.3481814861297607
Validation loss: 2.0993328591187796

Epoch: 5| Step: 5
Training loss: 1.4311414957046509
Validation loss: 2.0927882939577103

Epoch: 5| Step: 6
Training loss: 1.1234925985336304
Validation loss: 2.1172699133555093

Epoch: 5| Step: 7
Training loss: 1.9282951354980469
Validation loss: 2.123554309209188

Epoch: 5| Step: 8
Training loss: 1.3028414249420166
Validation loss: 2.144842545191447

Epoch: 5| Step: 9
Training loss: 0.890133261680603
Validation loss: 2.185156653324763

Epoch: 5| Step: 10
Training loss: 1.5649231672286987
Validation loss: 2.1869135995705924

Epoch: 5| Step: 11
Training loss: 1.5966031551361084
Validation loss: 2.207073897123337

Epoch: 353| Step: 0
Training loss: 1.5854402780532837
Validation loss: 2.181188186009725

Epoch: 5| Step: 1
Training loss: 1.6840448379516602
Validation loss: 2.2246901094913483

Epoch: 5| Step: 2
Training loss: 1.6326706409454346
Validation loss: 2.219898283481598

Epoch: 5| Step: 3
Training loss: 1.5680549144744873
Validation loss: 2.2163837601741156

Epoch: 5| Step: 4
Training loss: 1.574415683746338
Validation loss: 2.2018661946058273

Epoch: 5| Step: 5
Training loss: 1.725171446800232
Validation loss: 2.206347867846489

Epoch: 5| Step: 6
Training loss: 1.147245168685913
Validation loss: 2.1967617074648538

Epoch: 5| Step: 7
Training loss: 0.8840509653091431
Validation loss: 2.20934404929479

Epoch: 5| Step: 8
Training loss: 1.4036948680877686
Validation loss: 2.1827409217755

Epoch: 5| Step: 9
Training loss: 1.2923303842544556
Validation loss: 2.193942124644915

Epoch: 5| Step: 10
Training loss: 2.0587856769561768
Validation loss: 2.20609387755394

Epoch: 5| Step: 11
Training loss: 1.2568721771240234
Validation loss: 2.1849744667609534

Epoch: 354| Step: 0
Training loss: 1.2168165445327759
Validation loss: 2.2013720075289407

Epoch: 5| Step: 1
Training loss: 1.7921053171157837
Validation loss: 2.217795724670092

Epoch: 5| Step: 2
Training loss: 1.5569374561309814
Validation loss: 2.1847727398077645

Epoch: 5| Step: 3
Training loss: 1.8631203174591064
Validation loss: 2.2257530788580575

Epoch: 5| Step: 4
Training loss: 2.067599058151245
Validation loss: 2.20584907134374

Epoch: 5| Step: 5
Training loss: 0.9196268320083618
Validation loss: 2.201772779226303

Epoch: 5| Step: 6
Training loss: 0.947240948677063
Validation loss: 2.1921199013789496

Epoch: 5| Step: 7
Training loss: 1.0703264474868774
Validation loss: 2.1946593125661216

Epoch: 5| Step: 8
Training loss: 1.9522819519042969
Validation loss: 2.175253306825956

Epoch: 5| Step: 9
Training loss: 1.848280668258667
Validation loss: 2.149340565005938

Epoch: 5| Step: 10
Training loss: 1.585273027420044
Validation loss: 2.1502948502699533

Epoch: 5| Step: 11
Training loss: 0.7920886278152466
Validation loss: 2.170749599734942

Epoch: 355| Step: 0
Training loss: 1.8427883386611938
Validation loss: 2.1551141838232675

Epoch: 5| Step: 1
Training loss: 1.05814528465271
Validation loss: 2.17770184079806

Epoch: 5| Step: 2
Training loss: 2.119077205657959
Validation loss: 2.1894616335630417

Epoch: 5| Step: 3
Training loss: 1.2664620876312256
Validation loss: 2.1975726981957755

Epoch: 5| Step: 4
Training loss: 1.3590099811553955
Validation loss: 2.1860577861467996

Epoch: 5| Step: 5
Training loss: 1.2854574918746948
Validation loss: 2.1865925242503486

Epoch: 5| Step: 6
Training loss: 1.1864546537399292
Validation loss: 2.176766574382782

Epoch: 5| Step: 7
Training loss: 1.154282569885254
Validation loss: 2.1774742553631463

Epoch: 5| Step: 8
Training loss: 1.5818021297454834
Validation loss: 2.141571452220281

Epoch: 5| Step: 9
Training loss: 1.9258308410644531
Validation loss: 2.200602908929189

Epoch: 5| Step: 10
Training loss: 1.7318084239959717
Validation loss: 2.183806469043096

Epoch: 5| Step: 11
Training loss: 0.8251363039016724
Validation loss: 2.1786969800790152

Epoch: 356| Step: 0
Training loss: 1.4907792806625366
Validation loss: 2.178521911303202

Epoch: 5| Step: 1
Training loss: 1.3075929880142212
Validation loss: 2.192264740665754

Epoch: 5| Step: 2
Training loss: 1.519504189491272
Validation loss: 2.195123960574468

Epoch: 5| Step: 3
Training loss: 1.9709787368774414
Validation loss: 2.209492305914561

Epoch: 5| Step: 4
Training loss: 1.2695987224578857
Validation loss: 2.202445616324743

Epoch: 5| Step: 5
Training loss: 1.4098467826843262
Validation loss: 2.2076502541700997

Epoch: 5| Step: 6
Training loss: 1.3107471466064453
Validation loss: 2.2037994215885797

Epoch: 5| Step: 7
Training loss: 1.1908210515975952
Validation loss: 2.218748316168785

Epoch: 5| Step: 8
Training loss: 1.9043012857437134
Validation loss: 2.1967870891094208

Epoch: 5| Step: 9
Training loss: 1.6705306768417358
Validation loss: 2.19668240348498

Epoch: 5| Step: 10
Training loss: 1.2406038045883179
Validation loss: 2.1826634258031845

Epoch: 5| Step: 11
Training loss: 2.5433523654937744
Validation loss: 2.1870387395222983

Epoch: 357| Step: 0
Training loss: 1.4407155513763428
Validation loss: 2.1693759659926095

Epoch: 5| Step: 1
Training loss: 1.545875072479248
Validation loss: 2.162714953223864

Epoch: 5| Step: 2
Training loss: 1.2410106658935547
Validation loss: 2.1757355630397797

Epoch: 5| Step: 3
Training loss: 1.5726507902145386
Validation loss: 2.18693770468235

Epoch: 5| Step: 4
Training loss: 1.7401740550994873
Validation loss: 2.1656955579916635

Epoch: 5| Step: 5
Training loss: 1.3255023956298828
Validation loss: 2.161025047302246

Epoch: 5| Step: 6
Training loss: 1.59554922580719
Validation loss: 2.1925669511159263

Epoch: 5| Step: 7
Training loss: 1.1976490020751953
Validation loss: 2.201009124517441

Epoch: 5| Step: 8
Training loss: 1.4896602630615234
Validation loss: 2.187803869446119

Epoch: 5| Step: 9
Training loss: 1.5558818578720093
Validation loss: 2.1935846408208213

Epoch: 5| Step: 10
Training loss: 1.2501919269561768
Validation loss: 2.1836486607789993

Epoch: 5| Step: 11
Training loss: 4.031689643859863
Validation loss: 2.169769157965978

Epoch: 358| Step: 0
Training loss: 2.0412776470184326
Validation loss: 2.1514070381720862

Epoch: 5| Step: 1
Training loss: 1.618568778038025
Validation loss: 2.192447612682978

Epoch: 5| Step: 2
Training loss: 1.293487548828125
Validation loss: 2.2040426582098007

Epoch: 5| Step: 3
Training loss: 1.1127052307128906
Validation loss: 2.179617409904798

Epoch: 5| Step: 4
Training loss: 1.4858806133270264
Validation loss: 2.160968398054441

Epoch: 5| Step: 5
Training loss: 1.0547839403152466
Validation loss: 2.1452573438485465

Epoch: 5| Step: 6
Training loss: 1.1166560649871826
Validation loss: 2.1411110560099282

Epoch: 5| Step: 7
Training loss: 2.1436707973480225
Validation loss: 2.1598967909812927

Epoch: 5| Step: 8
Training loss: 1.6110732555389404
Validation loss: 2.1613496641318

Epoch: 5| Step: 9
Training loss: 1.4678137302398682
Validation loss: 2.1396747628847756

Epoch: 5| Step: 10
Training loss: 1.5569032430648804
Validation loss: 2.1466481735308967

Epoch: 5| Step: 11
Training loss: 3.4894845485687256
Validation loss: 2.1163012286027274

Epoch: 359| Step: 0
Training loss: 1.823574423789978
Validation loss: 2.1396600008010864

Epoch: 5| Step: 1
Training loss: 0.9490024447441101
Validation loss: 2.1438051611185074

Epoch: 5| Step: 2
Training loss: 1.8268325328826904
Validation loss: 2.123016873995463

Epoch: 5| Step: 3
Training loss: 1.133986234664917
Validation loss: 2.128587414820989

Epoch: 5| Step: 4
Training loss: 1.2684379816055298
Validation loss: 2.124110072851181

Epoch: 5| Step: 5
Training loss: 2.1387076377868652
Validation loss: 2.1070780058701835

Epoch: 5| Step: 6
Training loss: 1.4865953922271729
Validation loss: 2.1437257875998816

Epoch: 5| Step: 7
Training loss: 1.7619304656982422
Validation loss: 2.163559099038442

Epoch: 5| Step: 8
Training loss: 1.562225103378296
Validation loss: 2.158902039130529

Epoch: 5| Step: 9
Training loss: 1.2874168157577515
Validation loss: 2.1435183187325797

Epoch: 5| Step: 10
Training loss: 1.2889807224273682
Validation loss: 2.1668459425369897

Epoch: 5| Step: 11
Training loss: 1.253924012184143
Validation loss: 2.158478707075119

Epoch: 360| Step: 0
Training loss: 1.4969593286514282
Validation loss: 2.186125790079435

Epoch: 5| Step: 1
Training loss: 1.9946479797363281
Validation loss: 2.192378302415212

Epoch: 5| Step: 2
Training loss: 1.7066452503204346
Validation loss: 2.200625697771708

Epoch: 5| Step: 3
Training loss: 2.241532802581787
Validation loss: 2.197819789250692

Epoch: 5| Step: 4
Training loss: 1.7015281915664673
Validation loss: 2.1873456239700317

Epoch: 5| Step: 5
Training loss: 1.2530888319015503
Validation loss: 2.1569284399350486

Epoch: 5| Step: 6
Training loss: 1.101899266242981
Validation loss: 2.1645748615264893

Epoch: 5| Step: 7
Training loss: 1.025856614112854
Validation loss: 2.1610465149084725

Epoch: 5| Step: 8
Training loss: 1.7281787395477295
Validation loss: 2.175508216023445

Epoch: 5| Step: 9
Training loss: 1.0681051015853882
Validation loss: 2.1439222941795983

Epoch: 5| Step: 10
Training loss: 0.9748609662055969
Validation loss: 2.185692548751831

Epoch: 5| Step: 11
Training loss: 1.7848585844039917
Validation loss: 2.181122049689293

Epoch: 361| Step: 0
Training loss: 1.9486345052719116
Validation loss: 2.2010429402192435

Epoch: 5| Step: 1
Training loss: 1.1628553867340088
Validation loss: 2.1867485543092093

Epoch: 5| Step: 2
Training loss: 1.7421671152114868
Validation loss: 2.1739172687133155

Epoch: 5| Step: 3
Training loss: 1.2214744091033936
Validation loss: 2.185098181168238

Epoch: 5| Step: 4
Training loss: 1.586735725402832
Validation loss: 2.170795718828837

Epoch: 5| Step: 5
Training loss: 1.2759923934936523
Validation loss: 2.2013694991668067

Epoch: 5| Step: 6
Training loss: 1.7523467540740967
Validation loss: 2.172087177634239

Epoch: 5| Step: 7
Training loss: 1.2039282321929932
Validation loss: 2.1757005949815116

Epoch: 5| Step: 8
Training loss: 1.2006293535232544
Validation loss: 2.1693626592556634

Epoch: 5| Step: 9
Training loss: 2.30708646774292
Validation loss: 2.1515073825915656

Epoch: 5| Step: 10
Training loss: 1.281137228012085
Validation loss: 2.169722005724907

Epoch: 5| Step: 11
Training loss: 3.0073866844177246
Validation loss: 2.215831200281779

Epoch: 362| Step: 0
Training loss: 1.2417376041412354
Validation loss: 2.240934501091639

Epoch: 5| Step: 1
Training loss: 1.362293004989624
Validation loss: 2.2054308404525123

Epoch: 5| Step: 2
Training loss: 1.1767892837524414
Validation loss: 2.1827193945646286

Epoch: 5| Step: 3
Training loss: 1.8876583576202393
Validation loss: 2.2114209085702896

Epoch: 5| Step: 4
Training loss: 2.192331552505493
Validation loss: 2.1944735745588937

Epoch: 5| Step: 5
Training loss: 0.94891357421875
Validation loss: 2.199287752310435

Epoch: 5| Step: 6
Training loss: 1.435981273651123
Validation loss: 2.230967159072558

Epoch: 5| Step: 7
Training loss: 1.4787458181381226
Validation loss: 2.202225615580877

Epoch: 5| Step: 8
Training loss: 1.1368095874786377
Validation loss: 2.1751619378725686

Epoch: 5| Step: 9
Training loss: 2.2385661602020264
Validation loss: 2.162969986597697

Epoch: 5| Step: 10
Training loss: 0.7972651720046997
Validation loss: 2.1658412714799247

Epoch: 5| Step: 11
Training loss: 1.1268075704574585
Validation loss: 2.191609417398771

Epoch: 363| Step: 0
Training loss: 1.5689566135406494
Validation loss: 2.1738590647776923

Epoch: 5| Step: 1
Training loss: 1.164050817489624
Validation loss: 2.1460564136505127

Epoch: 5| Step: 2
Training loss: 1.839276909828186
Validation loss: 2.154132584730784

Epoch: 5| Step: 3
Training loss: 1.4708629846572876
Validation loss: 2.1807791938384375

Epoch: 5| Step: 4
Training loss: 1.8098573684692383
Validation loss: 2.182619964083036

Epoch: 5| Step: 5
Training loss: 1.526672601699829
Validation loss: 2.177002936601639

Epoch: 5| Step: 6
Training loss: 1.2049251794815063
Validation loss: 2.1819742222627005

Epoch: 5| Step: 7
Training loss: 1.2343028783798218
Validation loss: 2.20006229976813

Epoch: 5| Step: 8
Training loss: 1.960387945175171
Validation loss: 2.2198760211467743

Epoch: 5| Step: 9
Training loss: 1.1243090629577637
Validation loss: 2.1995633244514465

Epoch: 5| Step: 10
Training loss: 1.404736042022705
Validation loss: 2.201389620701472

Epoch: 5| Step: 11
Training loss: 2.1085915565490723
Validation loss: 2.200124830007553

Epoch: 364| Step: 0
Training loss: 1.423227310180664
Validation loss: 2.2056692192951837

Epoch: 5| Step: 1
Training loss: 1.6987119913101196
Validation loss: 2.2005684872468314

Epoch: 5| Step: 2
Training loss: 1.6233797073364258
Validation loss: 2.1854843695958457

Epoch: 5| Step: 3
Training loss: 1.4761689901351929
Validation loss: 2.191064973672231

Epoch: 5| Step: 4
Training loss: 2.1115734577178955
Validation loss: 2.191883126894633

Epoch: 5| Step: 5
Training loss: 1.323951005935669
Validation loss: 2.195052663485209

Epoch: 5| Step: 6
Training loss: 1.6344430446624756
Validation loss: 2.1800322582324347

Epoch: 5| Step: 7
Training loss: 1.3162877559661865
Validation loss: 2.1823326696952186

Epoch: 5| Step: 8
Training loss: 1.1303575038909912
Validation loss: 2.184841444094976

Epoch: 5| Step: 9
Training loss: 1.1128283739089966
Validation loss: 2.2070688704649606

Epoch: 5| Step: 10
Training loss: 1.3660852909088135
Validation loss: 2.1857833663622537

Epoch: 5| Step: 11
Training loss: 1.5355892181396484
Validation loss: 2.1756890217463174

Epoch: 365| Step: 0
Training loss: 1.0611305236816406
Validation loss: 2.2219722966353097

Epoch: 5| Step: 1
Training loss: 1.3676708936691284
Validation loss: 2.1962282806634903

Epoch: 5| Step: 2
Training loss: 2.091221809387207
Validation loss: 2.2054191629091897

Epoch: 5| Step: 3
Training loss: 1.7113592624664307
Validation loss: 2.2051757127046585

Epoch: 5| Step: 4
Training loss: 1.4078190326690674
Validation loss: 2.1890476097663245

Epoch: 5| Step: 5
Training loss: 1.4725762605667114
Validation loss: 2.177207107345263

Epoch: 5| Step: 6
Training loss: 1.5640552043914795
Validation loss: 2.180803765853246

Epoch: 5| Step: 7
Training loss: 1.7462522983551025
Validation loss: 2.1530160109202066

Epoch: 5| Step: 8
Training loss: 1.5392701625823975
Validation loss: 2.169715717434883

Epoch: 5| Step: 9
Training loss: 1.2262948751449585
Validation loss: 2.1799758474032083

Epoch: 5| Step: 10
Training loss: 0.9784460067749023
Validation loss: 2.173063655694326

Epoch: 5| Step: 11
Training loss: 0.08898091316223145
Validation loss: 2.1791450530290604

Epoch: 366| Step: 0
Training loss: 0.8921173810958862
Validation loss: 2.1811423103014627

Epoch: 5| Step: 1
Training loss: 1.1601901054382324
Validation loss: 2.1535128951072693

Epoch: 5| Step: 2
Training loss: 1.5691255331039429
Validation loss: 2.1734388569990792

Epoch: 5| Step: 3
Training loss: 2.4160590171813965
Validation loss: 2.169844334324201

Epoch: 5| Step: 4
Training loss: 1.3753877878189087
Validation loss: 2.1487760692834854

Epoch: 5| Step: 5
Training loss: 1.3468760251998901
Validation loss: 2.1707825611035028

Epoch: 5| Step: 6
Training loss: 1.247300148010254
Validation loss: 2.18460684021314

Epoch: 5| Step: 7
Training loss: 1.5275251865386963
Validation loss: 2.1829453110694885

Epoch: 5| Step: 8
Training loss: 1.2422274351119995
Validation loss: 2.1899149666229882

Epoch: 5| Step: 9
Training loss: 1.5350844860076904
Validation loss: 2.1926183253526688

Epoch: 5| Step: 10
Training loss: 1.7732175588607788
Validation loss: 2.167072723309199

Epoch: 5| Step: 11
Training loss: 0.8804769515991211
Validation loss: 2.158557871977488

Epoch: 367| Step: 0
Training loss: 1.6219055652618408
Validation loss: 2.155797610680262

Epoch: 5| Step: 1
Training loss: 1.242450475692749
Validation loss: 2.159942552447319

Epoch: 5| Step: 2
Training loss: 1.0340282917022705
Validation loss: 2.1371036072572074

Epoch: 5| Step: 3
Training loss: 1.6545183658599854
Validation loss: 2.127774099508921

Epoch: 5| Step: 4
Training loss: 1.740248441696167
Validation loss: 2.153459678093592

Epoch: 5| Step: 5
Training loss: 1.2696058750152588
Validation loss: 2.171049286921819

Epoch: 5| Step: 6
Training loss: 1.4742430448532104
Validation loss: 2.190938100218773

Epoch: 5| Step: 7
Training loss: 1.5686043500900269
Validation loss: 2.167948583761851

Epoch: 5| Step: 8
Training loss: 1.6142137050628662
Validation loss: 2.2075209667285285

Epoch: 5| Step: 9
Training loss: 1.5955973863601685
Validation loss: 2.179223969578743

Epoch: 5| Step: 10
Training loss: 1.2889741659164429
Validation loss: 2.121570259332657

Epoch: 5| Step: 11
Training loss: 4.219569206237793
Validation loss: 2.168786108493805

Epoch: 368| Step: 0
Training loss: 1.1834136247634888
Validation loss: 2.1702492038408914

Epoch: 5| Step: 1
Training loss: 1.90218985080719
Validation loss: 2.180255194505056

Epoch: 5| Step: 2
Training loss: 1.6191962957382202
Validation loss: 2.1658715258042016

Epoch: 5| Step: 3
Training loss: 1.4604785442352295
Validation loss: 2.1763526499271393

Epoch: 5| Step: 4
Training loss: 1.2984365224838257
Validation loss: 2.163451164960861

Epoch: 5| Step: 5
Training loss: 1.3415555953979492
Validation loss: 2.1723800549904504

Epoch: 5| Step: 6
Training loss: 1.819736123085022
Validation loss: 2.18603552877903

Epoch: 5| Step: 7
Training loss: 1.1417820453643799
Validation loss: 2.1882888078689575

Epoch: 5| Step: 8
Training loss: 1.5696913003921509
Validation loss: 2.191424032052358

Epoch: 5| Step: 9
Training loss: 0.8005849719047546
Validation loss: 2.1544565012057624

Epoch: 5| Step: 10
Training loss: 1.816576361656189
Validation loss: 2.1660691599051156

Epoch: 5| Step: 11
Training loss: 0.6932094097137451
Validation loss: 2.1755230526129403

Epoch: 369| Step: 0
Training loss: 1.703805923461914
Validation loss: 2.1474208533763885

Epoch: 5| Step: 1
Training loss: 1.353743076324463
Validation loss: 2.1803655127684274

Epoch: 5| Step: 2
Training loss: 1.6925346851348877
Validation loss: 2.2044420689344406

Epoch: 5| Step: 3
Training loss: 1.7821903228759766
Validation loss: 2.1952279607454934

Epoch: 5| Step: 4
Training loss: 1.6261180639266968
Validation loss: 2.2170252203941345

Epoch: 5| Step: 5
Training loss: 1.269008755683899
Validation loss: 2.1956124057372413

Epoch: 5| Step: 6
Training loss: 0.9055910110473633
Validation loss: 2.2066828310489655

Epoch: 5| Step: 7
Training loss: 1.1557077169418335
Validation loss: 2.1984507143497467

Epoch: 5| Step: 8
Training loss: 1.6027107238769531
Validation loss: 2.18748015165329

Epoch: 5| Step: 9
Training loss: 1.5024704933166504
Validation loss: 2.1878458311160407

Epoch: 5| Step: 10
Training loss: 1.329785704612732
Validation loss: 2.2126438170671463

Epoch: 5| Step: 11
Training loss: 0.6323699355125427
Validation loss: 2.169535592198372

Epoch: 370| Step: 0
Training loss: 1.279571294784546
Validation loss: 2.181864927212397

Epoch: 5| Step: 1
Training loss: 1.1580960750579834
Validation loss: 2.193944056828817

Epoch: 5| Step: 2
Training loss: 1.808253526687622
Validation loss: 2.1949249655008316

Epoch: 5| Step: 3
Training loss: 1.1749179363250732
Validation loss: 2.192781647046407

Epoch: 5| Step: 4
Training loss: 1.9786474704742432
Validation loss: 2.1992778331041336

Epoch: 5| Step: 5
Training loss: 1.3179848194122314
Validation loss: 2.1918489088614783

Epoch: 5| Step: 6
Training loss: 1.8587650060653687
Validation loss: 2.2201841175556183

Epoch: 5| Step: 7
Training loss: 1.9777148962020874
Validation loss: 2.210150202115377

Epoch: 5| Step: 8
Training loss: 1.1948148012161255
Validation loss: 2.194924001892408

Epoch: 5| Step: 9
Training loss: 1.4200327396392822
Validation loss: 2.187105963627497

Epoch: 5| Step: 10
Training loss: 1.0543980598449707
Validation loss: 2.185829371213913

Epoch: 5| Step: 11
Training loss: 0.2792961001396179
Validation loss: 2.173470452427864

Epoch: 371| Step: 0
Training loss: 1.5833008289337158
Validation loss: 2.196056912342707

Epoch: 5| Step: 1
Training loss: 1.1683828830718994
Validation loss: 2.2054990927378335

Epoch: 5| Step: 2
Training loss: 2.247316837310791
Validation loss: 2.1890855530897775

Epoch: 5| Step: 3
Training loss: 1.6411606073379517
Validation loss: 2.213239143292109

Epoch: 5| Step: 4
Training loss: 1.2066255807876587
Validation loss: 2.1789172341426215

Epoch: 5| Step: 5
Training loss: 1.5176427364349365
Validation loss: 2.2222225765387216

Epoch: 5| Step: 6
Training loss: 1.6062548160552979
Validation loss: 2.2245779782533646

Epoch: 5| Step: 7
Training loss: 1.5729442834854126
Validation loss: 2.2770555317401886

Epoch: 5| Step: 8
Training loss: 1.590814232826233
Validation loss: 2.2066012024879456

Epoch: 5| Step: 9
Training loss: 1.1659077405929565
Validation loss: 2.239128659168879

Epoch: 5| Step: 10
Training loss: 1.3668631315231323
Validation loss: 2.248079468806585

Epoch: 5| Step: 11
Training loss: 0.983725905418396
Validation loss: 2.238888402779897

Epoch: 372| Step: 0
Training loss: 1.060333490371704
Validation loss: 2.200398047765096

Epoch: 5| Step: 1
Training loss: 1.5427653789520264
Validation loss: 2.208237275481224

Epoch: 5| Step: 2
Training loss: 1.3812236785888672
Validation loss: 2.216802398363749

Epoch: 5| Step: 3
Training loss: 2.017037868499756
Validation loss: 2.24946237107118

Epoch: 5| Step: 4
Training loss: 1.1743619441986084
Validation loss: 2.2455683449904122

Epoch: 5| Step: 5
Training loss: 1.6517117023468018
Validation loss: 2.2256631354490914

Epoch: 5| Step: 6
Training loss: 1.4310266971588135
Validation loss: 2.250090107321739

Epoch: 5| Step: 7
Training loss: 1.41487717628479
Validation loss: 2.2142498244841895

Epoch: 5| Step: 8
Training loss: 1.5915359258651733
Validation loss: 2.203754107157389

Epoch: 5| Step: 9
Training loss: 2.259129762649536
Validation loss: 2.2382982820272446

Epoch: 5| Step: 10
Training loss: 1.374892234802246
Validation loss: 2.237815166513125

Epoch: 5| Step: 11
Training loss: 1.4437235593795776
Validation loss: 2.241068571805954

Epoch: 373| Step: 0
Training loss: 1.8627431392669678
Validation loss: 2.221416254838308

Epoch: 5| Step: 1
Training loss: 1.8925822973251343
Validation loss: 2.202431117494901

Epoch: 5| Step: 2
Training loss: 1.5824857950210571
Validation loss: 2.1972634345293045

Epoch: 5| Step: 3
Training loss: 1.397803544998169
Validation loss: 2.2167177299658456

Epoch: 5| Step: 4
Training loss: 0.6354554891586304
Validation loss: 2.1933038979768753

Epoch: 5| Step: 5
Training loss: 1.111372709274292
Validation loss: 2.151296238104502

Epoch: 5| Step: 6
Training loss: 1.9974321126937866
Validation loss: 2.166780193646749

Epoch: 5| Step: 7
Training loss: 1.549188494682312
Validation loss: 2.1756260693073273

Epoch: 5| Step: 8
Training loss: 1.3232651948928833
Validation loss: 2.1798633535703025

Epoch: 5| Step: 9
Training loss: 1.788598656654358
Validation loss: 2.1799990137418113

Epoch: 5| Step: 10
Training loss: 1.5014232397079468
Validation loss: 2.190341427922249

Epoch: 5| Step: 11
Training loss: 2.105632781982422
Validation loss: 2.206770122051239

Epoch: 374| Step: 0
Training loss: 1.5118834972381592
Validation loss: 2.2345675230026245

Epoch: 5| Step: 1
Training loss: 1.703046202659607
Validation loss: 2.195570394396782

Epoch: 5| Step: 2
Training loss: 1.9498224258422852
Validation loss: 2.2251032888889313

Epoch: 5| Step: 3
Training loss: 1.6461979150772095
Validation loss: 2.2725501159826913

Epoch: 5| Step: 4
Training loss: 1.5133192539215088
Validation loss: 2.2649800380071006

Epoch: 5| Step: 5
Training loss: 0.8768573999404907
Validation loss: 2.2277160783608756

Epoch: 5| Step: 6
Training loss: 1.2306585311889648
Validation loss: 2.268600116173426

Epoch: 5| Step: 7
Training loss: 1.8464992046356201
Validation loss: 2.2544383058945336

Epoch: 5| Step: 8
Training loss: 1.7370201349258423
Validation loss: 2.212773804863294

Epoch: 5| Step: 9
Training loss: 1.9505153894424438
Validation loss: 2.1936901211738586

Epoch: 5| Step: 10
Training loss: 1.1066714525222778
Validation loss: 2.1914026538530984

Epoch: 5| Step: 11
Training loss: 1.1994341611862183
Validation loss: 2.168706953525543

Epoch: 375| Step: 0
Training loss: 1.5080344676971436
Validation loss: 2.1859397888183594

Epoch: 5| Step: 1
Training loss: 1.601034164428711
Validation loss: 2.178550511598587

Epoch: 5| Step: 2
Training loss: 1.692466378211975
Validation loss: 2.2041005045175552

Epoch: 5| Step: 3
Training loss: 1.0391589403152466
Validation loss: 2.1597895522912345

Epoch: 5| Step: 4
Training loss: 1.2977840900421143
Validation loss: 2.1597087184588113

Epoch: 5| Step: 5
Training loss: 1.4626352787017822
Validation loss: 2.171401013930639

Epoch: 5| Step: 6
Training loss: 1.775132179260254
Validation loss: 2.163691913088163

Epoch: 5| Step: 7
Training loss: 0.825527548789978
Validation loss: 2.1671678672234216

Epoch: 5| Step: 8
Training loss: 1.6674244403839111
Validation loss: 2.154832894603411

Epoch: 5| Step: 9
Training loss: 1.679040551185608
Validation loss: 2.171905333797137

Epoch: 5| Step: 10
Training loss: 1.3139737844467163
Validation loss: 2.150048648317655

Epoch: 5| Step: 11
Training loss: 2.3608548641204834
Validation loss: 2.1547549068927765

Epoch: 376| Step: 0
Training loss: 1.8583641052246094
Validation loss: 2.155769109725952

Epoch: 5| Step: 1
Training loss: 1.273226022720337
Validation loss: 2.1703096479177475

Epoch: 5| Step: 2
Training loss: 1.5506259202957153
Validation loss: 2.1681182930866876

Epoch: 5| Step: 3
Training loss: 1.2669724225997925
Validation loss: 2.200212597846985

Epoch: 5| Step: 4
Training loss: 1.5526264905929565
Validation loss: 2.220821261405945

Epoch: 5| Step: 5
Training loss: 1.1665518283843994
Validation loss: 2.194942429661751

Epoch: 5| Step: 6
Training loss: 1.5135530233383179
Validation loss: 2.1973191499710083

Epoch: 5| Step: 7
Training loss: 1.176438570022583
Validation loss: 2.1831501921017966

Epoch: 5| Step: 8
Training loss: 1.9781516790390015
Validation loss: 2.2101324945688248

Epoch: 5| Step: 9
Training loss: 1.5704289674758911
Validation loss: 2.2173893799384436

Epoch: 5| Step: 10
Training loss: 1.6100473403930664
Validation loss: 2.2286528746287027

Epoch: 5| Step: 11
Training loss: 0.8818897008895874
Validation loss: 2.204263443748156

Epoch: 377| Step: 0
Training loss: 1.2852510213851929
Validation loss: 2.2138658265272775

Epoch: 5| Step: 1
Training loss: 1.333036184310913
Validation loss: 2.207848916451136

Epoch: 5| Step: 2
Training loss: 1.792764663696289
Validation loss: 2.218924512465795

Epoch: 5| Step: 3
Training loss: 1.351191759109497
Validation loss: 2.1778054237365723

Epoch: 5| Step: 4
Training loss: 1.735730767250061
Validation loss: 2.2042060097058616

Epoch: 5| Step: 5
Training loss: 1.4707262516021729
Validation loss: 2.190594896674156

Epoch: 5| Step: 6
Training loss: 1.605333685874939
Validation loss: 2.193243235349655

Epoch: 5| Step: 7
Training loss: 1.5841795206069946
Validation loss: 2.160204296310743

Epoch: 5| Step: 8
Training loss: 1.2484612464904785
Validation loss: 2.1546398401260376

Epoch: 5| Step: 9
Training loss: 1.423797845840454
Validation loss: 2.1422845224539437

Epoch: 5| Step: 10
Training loss: 1.1055984497070312
Validation loss: 2.1414157251516976

Epoch: 5| Step: 11
Training loss: 2.0186095237731934
Validation loss: 2.129922832051913

Epoch: 378| Step: 0
Training loss: 1.4406888484954834
Validation loss: 2.1059054732322693

Epoch: 5| Step: 1
Training loss: 1.3570373058319092
Validation loss: 2.1210209925969443

Epoch: 5| Step: 2
Training loss: 1.4083645343780518
Validation loss: 2.1365472227334976

Epoch: 5| Step: 3
Training loss: 1.634796380996704
Validation loss: 2.1504343897104263

Epoch: 5| Step: 4
Training loss: 1.7696950435638428
Validation loss: 2.1241604338089624

Epoch: 5| Step: 5
Training loss: 2.1600372791290283
Validation loss: 2.1366580724716187

Epoch: 5| Step: 6
Training loss: 1.0997419357299805
Validation loss: 2.1702574590841928

Epoch: 5| Step: 7
Training loss: 0.9031835794448853
Validation loss: 2.1690432031949363

Epoch: 5| Step: 8
Training loss: 1.8522533178329468
Validation loss: 2.166056642929713

Epoch: 5| Step: 9
Training loss: 0.8608773946762085
Validation loss: 2.2057214975357056

Epoch: 5| Step: 10
Training loss: 1.785757303237915
Validation loss: 2.1825634787480035

Epoch: 5| Step: 11
Training loss: 0.5324068069458008
Validation loss: 2.1431503196557364

Epoch: 379| Step: 0
Training loss: 1.164083480834961
Validation loss: 2.178390766183535

Epoch: 5| Step: 1
Training loss: 2.0181503295898438
Validation loss: 2.174563239018122

Epoch: 5| Step: 2
Training loss: 1.5480238199234009
Validation loss: 2.1944080193837485

Epoch: 5| Step: 3
Training loss: 1.2575877904891968
Validation loss: 2.212875723838806

Epoch: 5| Step: 4
Training loss: 0.941773533821106
Validation loss: 2.180724153916041

Epoch: 5| Step: 5
Training loss: 2.059042453765869
Validation loss: 2.2046919763088226

Epoch: 5| Step: 6
Training loss: 1.5064113140106201
Validation loss: 2.181314835945765

Epoch: 5| Step: 7
Training loss: 1.6570415496826172
Validation loss: 2.2033361991246543

Epoch: 5| Step: 8
Training loss: 0.7976480722427368
Validation loss: 2.222528556982676

Epoch: 5| Step: 9
Training loss: 1.4096791744232178
Validation loss: 2.1758383413155875

Epoch: 5| Step: 10
Training loss: 1.8459209203720093
Validation loss: 2.2048599322636924

Epoch: 5| Step: 11
Training loss: 0.7509522438049316
Validation loss: 2.17098061243693

Epoch: 380| Step: 0
Training loss: 0.5671086311340332
Validation loss: 2.173218841354052

Epoch: 5| Step: 1
Training loss: 2.3620171546936035
Validation loss: 2.1454010208447776

Epoch: 5| Step: 2
Training loss: 1.617364525794983
Validation loss: 2.1232226391633353

Epoch: 5| Step: 3
Training loss: 1.892126441001892
Validation loss: 2.137256145477295

Epoch: 5| Step: 4
Training loss: 1.6307929754257202
Validation loss: 2.1239161491394043

Epoch: 5| Step: 5
Training loss: 1.2274086475372314
Validation loss: 2.1368712186813354

Epoch: 5| Step: 6
Training loss: 1.1724674701690674
Validation loss: 2.1164893954992294

Epoch: 5| Step: 7
Training loss: 1.1815224885940552
Validation loss: 2.1243039121230445

Epoch: 5| Step: 8
Training loss: 1.5531432628631592
Validation loss: 2.158172979950905

Epoch: 5| Step: 9
Training loss: 2.032200813293457
Validation loss: 2.120400001605352

Epoch: 5| Step: 10
Training loss: 1.104777455329895
Validation loss: 2.133688027660052

Epoch: 5| Step: 11
Training loss: 0.6674002408981323
Validation loss: 2.15704453488191

Epoch: 381| Step: 0
Training loss: 1.6051204204559326
Validation loss: 2.141717011729876

Epoch: 5| Step: 1
Training loss: 1.7157074213027954
Validation loss: 2.1366502990325293

Epoch: 5| Step: 2
Training loss: 1.2779759168624878
Validation loss: 2.1615315973758698

Epoch: 5| Step: 3
Training loss: 2.1651101112365723
Validation loss: 2.167928477128347

Epoch: 5| Step: 4
Training loss: 1.2854572534561157
Validation loss: 2.1308365215857825

Epoch: 5| Step: 5
Training loss: 1.284822940826416
Validation loss: 2.1489077607790628

Epoch: 5| Step: 6
Training loss: 1.7050946950912476
Validation loss: 2.17509426176548

Epoch: 5| Step: 7
Training loss: 1.4012776613235474
Validation loss: 2.154274801413218

Epoch: 5| Step: 8
Training loss: 1.1965487003326416
Validation loss: 2.1578970750172934

Epoch: 5| Step: 9
Training loss: 1.4083538055419922
Validation loss: 2.1514623165130615

Epoch: 5| Step: 10
Training loss: 1.182537317276001
Validation loss: 2.148587539792061

Epoch: 5| Step: 11
Training loss: 0.4208146631717682
Validation loss: 2.1622408429781594

Epoch: 382| Step: 0
Training loss: 1.6622421741485596
Validation loss: 2.1252626130978265

Epoch: 5| Step: 1
Training loss: 1.5040247440338135
Validation loss: 2.15301846464475

Epoch: 5| Step: 2
Training loss: 1.545925498008728
Validation loss: 2.138245473305384

Epoch: 5| Step: 3
Training loss: 2.045966625213623
Validation loss: 2.146394064029058

Epoch: 5| Step: 4
Training loss: 2.0744526386260986
Validation loss: 2.171457310517629

Epoch: 5| Step: 5
Training loss: 1.3789385557174683
Validation loss: 2.1575221717357635

Epoch: 5| Step: 6
Training loss: 1.1673352718353271
Validation loss: 2.1835733453432717

Epoch: 5| Step: 7
Training loss: 1.3514615297317505
Validation loss: 2.180204709370931

Epoch: 5| Step: 8
Training loss: 1.2170133590698242
Validation loss: 2.154879088203112

Epoch: 5| Step: 9
Training loss: 1.5956367254257202
Validation loss: 2.1839763472477594

Epoch: 5| Step: 10
Training loss: 0.9403765797615051
Validation loss: 2.1470907231171927

Epoch: 5| Step: 11
Training loss: 1.0486177206039429
Validation loss: 2.1317635973294577

Epoch: 383| Step: 0
Training loss: 1.3185665607452393
Validation loss: 2.1790964901447296

Epoch: 5| Step: 1
Training loss: 2.149977684020996
Validation loss: 2.098489999771118

Epoch: 5| Step: 2
Training loss: 1.7319228649139404
Validation loss: 2.1297967036565146

Epoch: 5| Step: 3
Training loss: 0.9254329800605774
Validation loss: 2.1641078939040503

Epoch: 5| Step: 4
Training loss: 1.5007997751235962
Validation loss: 2.156490281224251

Epoch: 5| Step: 5
Training loss: 1.362562894821167
Validation loss: 2.137411912282308

Epoch: 5| Step: 6
Training loss: 1.6136596202850342
Validation loss: 2.1522551476955414

Epoch: 5| Step: 7
Training loss: 0.8673450350761414
Validation loss: 2.163044974207878

Epoch: 5| Step: 8
Training loss: 1.8104031085968018
Validation loss: 2.1197489549716315

Epoch: 5| Step: 9
Training loss: 1.3768593072891235
Validation loss: 2.137501150369644

Epoch: 5| Step: 10
Training loss: 0.9405721426010132
Validation loss: 2.160150865713755

Epoch: 5| Step: 11
Training loss: 1.6574610471725464
Validation loss: 2.149759352207184

Epoch: 384| Step: 0
Training loss: 1.6721779108047485
Validation loss: 2.1271277368068695

Epoch: 5| Step: 1
Training loss: 1.211276888847351
Validation loss: 2.1069514453411102

Epoch: 5| Step: 2
Training loss: 1.25552499294281
Validation loss: 2.1588312834501266

Epoch: 5| Step: 3
Training loss: 1.2590272426605225
Validation loss: 2.171248475710551

Epoch: 5| Step: 4
Training loss: 1.1312739849090576
Validation loss: 2.160762444138527

Epoch: 5| Step: 5
Training loss: 1.2451425790786743
Validation loss: 2.206901043653488

Epoch: 5| Step: 6
Training loss: 1.8951482772827148
Validation loss: 2.187509040037791

Epoch: 5| Step: 7
Training loss: 2.375863790512085
Validation loss: 2.221449206272761

Epoch: 5| Step: 8
Training loss: 1.3793809413909912
Validation loss: 2.191510563095411

Epoch: 5| Step: 9
Training loss: 1.1047098636627197
Validation loss: 2.200646455089251

Epoch: 5| Step: 10
Training loss: 1.5216584205627441
Validation loss: 2.2094744543234506

Epoch: 5| Step: 11
Training loss: 1.613624930381775
Validation loss: 2.1925267477830253

Epoch: 385| Step: 0
Training loss: 1.2858564853668213
Validation loss: 2.2084273199240365

Epoch: 5| Step: 1
Training loss: 1.6560850143432617
Validation loss: 2.2432190825541816

Epoch: 5| Step: 2
Training loss: 1.5717012882232666
Validation loss: 2.2513067921002707

Epoch: 5| Step: 3
Training loss: 1.8504388332366943
Validation loss: 2.2596147457758584

Epoch: 5| Step: 4
Training loss: 1.2235832214355469
Validation loss: 2.2435355385144553

Epoch: 5| Step: 5
Training loss: 1.1884400844573975
Validation loss: 2.2865431060393653

Epoch: 5| Step: 6
Training loss: 1.167499303817749
Validation loss: 2.269136364261309

Epoch: 5| Step: 7
Training loss: 2.0731823444366455
Validation loss: 2.2188983460267386

Epoch: 5| Step: 8
Training loss: 1.0819207429885864
Validation loss: 2.223229795694351

Epoch: 5| Step: 9
Training loss: 1.2744879722595215
Validation loss: 2.197266459465027

Epoch: 5| Step: 10
Training loss: 1.708888053894043
Validation loss: 2.224442725380262

Epoch: 5| Step: 11
Training loss: 0.45208704471588135
Validation loss: 2.1576342483361564

Epoch: 386| Step: 0
Training loss: 1.0334774255752563
Validation loss: 2.1618793507417045

Epoch: 5| Step: 1
Training loss: 1.875449538230896
Validation loss: 2.17694461842378

Epoch: 5| Step: 2
Training loss: 1.7575092315673828
Validation loss: 2.1522403409083686

Epoch: 5| Step: 3
Training loss: 1.3438127040863037
Validation loss: 2.252559542655945

Epoch: 5| Step: 4
Training loss: 1.150088906288147
Validation loss: 2.2421307961146035

Epoch: 5| Step: 5
Training loss: 1.1475074291229248
Validation loss: 2.2174588640530906

Epoch: 5| Step: 6
Training loss: 1.6589616537094116
Validation loss: 2.1806301375230155

Epoch: 5| Step: 7
Training loss: 1.3620887994766235
Validation loss: 2.162762145201365

Epoch: 5| Step: 8
Training loss: 1.8539421558380127
Validation loss: 2.1049877206484475

Epoch: 5| Step: 9
Training loss: 1.0035431385040283
Validation loss: 2.0956553717454276

Epoch: 5| Step: 10
Training loss: 1.3315074443817139
Validation loss: 2.1039210806290307

Epoch: 5| Step: 11
Training loss: 3.927485466003418
Validation loss: 2.100401704510053

Epoch: 387| Step: 0
Training loss: 1.527500867843628
Validation loss: 2.1193293730417886

Epoch: 5| Step: 1
Training loss: 1.6623051166534424
Validation loss: 2.166204189260801

Epoch: 5| Step: 2
Training loss: 1.3420735597610474
Validation loss: 2.158048982421557

Epoch: 5| Step: 3
Training loss: 1.1560754776000977
Validation loss: 2.1839089691638947

Epoch: 5| Step: 4
Training loss: 1.9316694736480713
Validation loss: 2.2184660037358603

Epoch: 5| Step: 5
Training loss: 1.7931429147720337
Validation loss: 2.2246916194756827

Epoch: 5| Step: 6
Training loss: 1.0342386960983276
Validation loss: 2.195136850078901

Epoch: 5| Step: 7
Training loss: 1.9859895706176758
Validation loss: 2.2101236283779144

Epoch: 5| Step: 8
Training loss: 1.5407500267028809
Validation loss: 2.2289759814739227

Epoch: 5| Step: 9
Training loss: 1.3752670288085938
Validation loss: 2.2091706891854606

Epoch: 5| Step: 10
Training loss: 1.5817474126815796
Validation loss: 2.1920085350672402

Epoch: 5| Step: 11
Training loss: 1.0597295761108398
Validation loss: 2.2326540797948837

Epoch: 388| Step: 0
Training loss: 1.464345932006836
Validation loss: 2.2025830149650574

Epoch: 5| Step: 1
Training loss: 1.8969558477401733
Validation loss: 2.154502958059311

Epoch: 5| Step: 2
Training loss: 1.4813138246536255
Validation loss: 2.1703624576330185

Epoch: 5| Step: 3
Training loss: 0.9825780987739563
Validation loss: 2.1637655844291053

Epoch: 5| Step: 4
Training loss: 1.1216472387313843
Validation loss: 2.1457166373729706

Epoch: 5| Step: 5
Training loss: 1.9072721004486084
Validation loss: 2.171902666489283

Epoch: 5| Step: 6
Training loss: 1.041598916053772
Validation loss: 2.161290397246679

Epoch: 5| Step: 7
Training loss: 1.941074013710022
Validation loss: 2.1435511906941733

Epoch: 5| Step: 8
Training loss: 1.281719446182251
Validation loss: 2.163650388518969

Epoch: 5| Step: 9
Training loss: 1.4891983270645142
Validation loss: 2.173973431189855

Epoch: 5| Step: 10
Training loss: 1.9139678478240967
Validation loss: 2.16946875055631

Epoch: 5| Step: 11
Training loss: 1.475242018699646
Validation loss: 2.2513857980569205

Epoch: 389| Step: 0
Training loss: 1.2524573802947998
Validation loss: 2.2210031350453696

Epoch: 5| Step: 1
Training loss: 1.3654378652572632
Validation loss: 2.23344091574351

Epoch: 5| Step: 2
Training loss: 1.6003891229629517
Validation loss: 2.2218084583679834

Epoch: 5| Step: 3
Training loss: 2.2225334644317627
Validation loss: 2.231210986773173

Epoch: 5| Step: 4
Training loss: 1.2239365577697754
Validation loss: 2.206522822380066

Epoch: 5| Step: 5
Training loss: 1.66275954246521
Validation loss: 2.215366005897522

Epoch: 5| Step: 6
Training loss: 1.6773815155029297
Validation loss: 2.1809904674688974

Epoch: 5| Step: 7
Training loss: 0.7829023003578186
Validation loss: 2.21250419318676

Epoch: 5| Step: 8
Training loss: 2.063933849334717
Validation loss: 2.186818649371465

Epoch: 5| Step: 9
Training loss: 1.196008324623108
Validation loss: 2.19052000840505

Epoch: 5| Step: 10
Training loss: 1.1640212535858154
Validation loss: 2.181624402602514

Epoch: 5| Step: 11
Training loss: 2.48599910736084
Validation loss: 2.1798430184523263

Epoch: 390| Step: 0
Training loss: 1.6445882320404053
Validation loss: 2.192341531316439

Epoch: 5| Step: 1
Training loss: 1.198337197303772
Validation loss: 2.1658495465914407

Epoch: 5| Step: 2
Training loss: 1.2763385772705078
Validation loss: 2.201914260784785

Epoch: 5| Step: 3
Training loss: 1.0105897188186646
Validation loss: 2.188081234693527

Epoch: 5| Step: 4
Training loss: 1.4007129669189453
Validation loss: 2.1332585513591766

Epoch: 5| Step: 5
Training loss: 1.8395570516586304
Validation loss: 2.165385310848554

Epoch: 5| Step: 6
Training loss: 1.613547921180725
Validation loss: 2.1424409796794257

Epoch: 5| Step: 7
Training loss: 1.4196189641952515
Validation loss: 2.14451210697492

Epoch: 5| Step: 8
Training loss: 1.6859651803970337
Validation loss: 2.1348021725813546

Epoch: 5| Step: 9
Training loss: 1.3670463562011719
Validation loss: 2.192495028177897

Epoch: 5| Step: 10
Training loss: 1.1979496479034424
Validation loss: 2.1416233827670417

Epoch: 5| Step: 11
Training loss: 3.5001907348632812
Validation loss: 2.1690523475408554

Epoch: 391| Step: 0
Training loss: 1.1893131732940674
Validation loss: 2.192126010855039

Epoch: 5| Step: 1
Training loss: 1.545690655708313
Validation loss: 2.157545288403829

Epoch: 5| Step: 2
Training loss: 1.5902280807495117
Validation loss: 2.1978940069675446

Epoch: 5| Step: 3
Training loss: 1.5721828937530518
Validation loss: 2.172070230046908

Epoch: 5| Step: 4
Training loss: 2.0083484649658203
Validation loss: 2.172631805141767

Epoch: 5| Step: 5
Training loss: 1.519148588180542
Validation loss: 2.1542736093203225

Epoch: 5| Step: 6
Training loss: 1.787651777267456
Validation loss: 2.152191753188769

Epoch: 5| Step: 7
Training loss: 1.091238260269165
Validation loss: 2.1331341167291007

Epoch: 5| Step: 8
Training loss: 1.4628589153289795
Validation loss: 2.1742544819911322

Epoch: 5| Step: 9
Training loss: 0.6629884839057922
Validation loss: 2.1542137265205383

Epoch: 5| Step: 10
Training loss: 1.0146169662475586
Validation loss: 2.1598076025644937

Epoch: 5| Step: 11
Training loss: 2.013432741165161
Validation loss: 2.1562725454568863

Epoch: 392| Step: 0
Training loss: 1.1594964265823364
Validation loss: 2.174666166305542

Epoch: 5| Step: 1
Training loss: 1.393550157546997
Validation loss: 2.1945859640836716

Epoch: 5| Step: 2
Training loss: 1.3089940547943115
Validation loss: 2.245983357230822

Epoch: 5| Step: 3
Training loss: 1.7880675792694092
Validation loss: 2.1783303022384644

Epoch: 5| Step: 4
Training loss: 1.1857208013534546
Validation loss: 2.164825886487961

Epoch: 5| Step: 5
Training loss: 1.048728108406067
Validation loss: 2.204767276843389

Epoch: 5| Step: 6
Training loss: 1.2020853757858276
Validation loss: 2.2183954219023385

Epoch: 5| Step: 7
Training loss: 2.398527145385742
Validation loss: 2.1817575792471566

Epoch: 5| Step: 8
Training loss: 0.973650336265564
Validation loss: 2.1398265063762665

Epoch: 5| Step: 9
Training loss: 2.021317958831787
Validation loss: 2.16142138838768

Epoch: 5| Step: 10
Training loss: 0.8900914192199707
Validation loss: 2.155385653177897

Epoch: 5| Step: 11
Training loss: 2.4237570762634277
Validation loss: 2.157372464736303

Epoch: 393| Step: 0
Training loss: 1.0890076160430908
Validation loss: 2.1783284693956375

Epoch: 5| Step: 1
Training loss: 1.3822274208068848
Validation loss: 2.1851355781157813

Epoch: 5| Step: 2
Training loss: 1.035592794418335
Validation loss: 2.1943815698226294

Epoch: 5| Step: 3
Training loss: 1.6474189758300781
Validation loss: 2.200080012281736

Epoch: 5| Step: 4
Training loss: 1.9674625396728516
Validation loss: 2.1889228920141854

Epoch: 5| Step: 5
Training loss: 1.3045196533203125
Validation loss: 2.177103673418363

Epoch: 5| Step: 6
Training loss: 1.3686425685882568
Validation loss: 2.1838612059752145

Epoch: 5| Step: 7
Training loss: 1.5475960969924927
Validation loss: 2.222286105155945

Epoch: 5| Step: 8
Training loss: 1.3663060665130615
Validation loss: 2.183063119649887

Epoch: 5| Step: 9
Training loss: 1.2555423974990845
Validation loss: 2.14971953133742

Epoch: 5| Step: 10
Training loss: 1.2085602283477783
Validation loss: 2.1560869415601096

Epoch: 5| Step: 11
Training loss: 1.2995047569274902
Validation loss: 2.120193749666214

Epoch: 394| Step: 0
Training loss: 1.1766815185546875
Validation loss: 2.130194276571274

Epoch: 5| Step: 1
Training loss: 1.2974321842193604
Validation loss: 2.1783067484696708

Epoch: 5| Step: 2
Training loss: 1.584325909614563
Validation loss: 2.1375316431125007

Epoch: 5| Step: 3
Training loss: 0.5780025720596313
Validation loss: 2.1081628749767938

Epoch: 5| Step: 4
Training loss: 1.8586914539337158
Validation loss: 2.140766749779383

Epoch: 5| Step: 5
Training loss: 1.378712773323059
Validation loss: 2.086935078104337

Epoch: 5| Step: 6
Training loss: 0.9835184216499329
Validation loss: 2.1087130159139633

Epoch: 5| Step: 7
Training loss: 1.9856023788452148
Validation loss: 2.080704833070437

Epoch: 5| Step: 8
Training loss: 1.807777762413025
Validation loss: 2.1192578176657357

Epoch: 5| Step: 9
Training loss: 1.193561315536499
Validation loss: 2.0960889210303626

Epoch: 5| Step: 10
Training loss: 1.204708218574524
Validation loss: 2.1194215416908264

Epoch: 5| Step: 11
Training loss: 1.0944733619689941
Validation loss: 2.1484845131635666

Epoch: 395| Step: 0
Training loss: 1.5146152973175049
Validation loss: 2.1378279626369476

Epoch: 5| Step: 1
Training loss: 1.4255588054656982
Validation loss: 2.195118327935537

Epoch: 5| Step: 2
Training loss: 1.4297605752944946
Validation loss: 2.162737488746643

Epoch: 5| Step: 3
Training loss: 1.2840628623962402
Validation loss: 2.140767201781273

Epoch: 5| Step: 4
Training loss: 1.3153839111328125
Validation loss: 2.148528511325518

Epoch: 5| Step: 5
Training loss: 1.146317720413208
Validation loss: 2.1879120022058487

Epoch: 5| Step: 6
Training loss: 1.1555274724960327
Validation loss: 2.189901356895765

Epoch: 5| Step: 7
Training loss: 0.9392411112785339
Validation loss: 2.204492519299189

Epoch: 5| Step: 8
Training loss: 1.6258207559585571
Validation loss: 2.1636273513237634

Epoch: 5| Step: 9
Training loss: 1.661555528640747
Validation loss: 2.1939231604337692

Epoch: 5| Step: 10
Training loss: 1.4507246017456055
Validation loss: 2.238001902898153

Epoch: 5| Step: 11
Training loss: 2.692261219024658
Validation loss: 2.1737938821315765

Epoch: 396| Step: 0
Training loss: 1.2245283126831055
Validation loss: 2.1351413875818253

Epoch: 5| Step: 1
Training loss: 1.485736608505249
Validation loss: 2.13697416583697

Epoch: 5| Step: 2
Training loss: 1.0589237213134766
Validation loss: 2.1740278154611588

Epoch: 5| Step: 3
Training loss: 1.630568265914917
Validation loss: 2.139958610137304

Epoch: 5| Step: 4
Training loss: 1.4753352403640747
Validation loss: 2.149481346209844

Epoch: 5| Step: 5
Training loss: 1.3126739263534546
Validation loss: 2.155667473872503

Epoch: 5| Step: 6
Training loss: 1.859291434288025
Validation loss: 2.125603809952736

Epoch: 5| Step: 7
Training loss: 0.9107683300971985
Validation loss: 2.161103089650472

Epoch: 5| Step: 8
Training loss: 0.9714453816413879
Validation loss: 2.1945758561293283

Epoch: 5| Step: 9
Training loss: 1.8624340295791626
Validation loss: 2.207727844516436

Epoch: 5| Step: 10
Training loss: 1.9755656719207764
Validation loss: 2.2848753134409585

Epoch: 5| Step: 11
Training loss: 0.5974886417388916
Validation loss: 2.294813315073649

Epoch: 397| Step: 0
Training loss: 1.8761022090911865
Validation loss: 2.375399023294449

Epoch: 5| Step: 1
Training loss: 1.5174014568328857
Validation loss: 2.3479687571525574

Epoch: 5| Step: 2
Training loss: 1.416158676147461
Validation loss: 2.2978689819574356

Epoch: 5| Step: 3
Training loss: 1.2287415266036987
Validation loss: 2.275615175565084

Epoch: 5| Step: 4
Training loss: 1.0932843685150146
Validation loss: 2.2352725913127265

Epoch: 5| Step: 5
Training loss: 0.7999639511108398
Validation loss: 2.173095092177391

Epoch: 5| Step: 6
Training loss: 1.5919533967971802
Validation loss: 2.177262231707573

Epoch: 5| Step: 7
Training loss: 1.2226507663726807
Validation loss: 2.1828141808509827

Epoch: 5| Step: 8
Training loss: 2.025597095489502
Validation loss: 2.195270150899887

Epoch: 5| Step: 9
Training loss: 2.024827480316162
Validation loss: 2.204884429772695

Epoch: 5| Step: 10
Training loss: 1.979108452796936
Validation loss: 2.1846863428751626

Epoch: 5| Step: 11
Training loss: 2.877436637878418
Validation loss: 2.2068411856889725

Epoch: 398| Step: 0
Training loss: 1.00188148021698
Validation loss: 2.1974549094835916

Epoch: 5| Step: 1
Training loss: 1.0128190517425537
Validation loss: 2.192327563961347

Epoch: 5| Step: 2
Training loss: 1.9650005102157593
Validation loss: 2.1875828305880227

Epoch: 5| Step: 3
Training loss: 1.336564302444458
Validation loss: 2.1760545124610267

Epoch: 5| Step: 4
Training loss: 1.5118720531463623
Validation loss: 2.205391824245453

Epoch: 5| Step: 5
Training loss: 1.5242774486541748
Validation loss: 2.2553927997748056

Epoch: 5| Step: 6
Training loss: 1.4651734828948975
Validation loss: 2.2381610174973807

Epoch: 5| Step: 7
Training loss: 1.9294216632843018
Validation loss: 2.259504040082296

Epoch: 5| Step: 8
Training loss: 1.5530120134353638
Validation loss: 2.286075542370478

Epoch: 5| Step: 9
Training loss: 1.5044227838516235
Validation loss: 2.2217377622922263

Epoch: 5| Step: 10
Training loss: 1.2915241718292236
Validation loss: 2.1935467620690665

Epoch: 5| Step: 11
Training loss: 1.1967570781707764
Validation loss: 2.2423452834288278

Epoch: 399| Step: 0
Training loss: 1.0905249118804932
Validation loss: 2.1688962330420813

Epoch: 5| Step: 1
Training loss: 1.1939855813980103
Validation loss: 2.185979411005974

Epoch: 5| Step: 2
Training loss: 1.9630235433578491
Validation loss: 2.1863089948892593

Epoch: 5| Step: 3
Training loss: 1.346234917640686
Validation loss: 2.1758934011061988

Epoch: 5| Step: 4
Training loss: 1.34944486618042
Validation loss: 2.176892956097921

Epoch: 5| Step: 5
Training loss: 1.9956457614898682
Validation loss: 2.156467065215111

Epoch: 5| Step: 6
Training loss: 2.210681915283203
Validation loss: 2.1469923158486686

Epoch: 5| Step: 7
Training loss: 1.3964476585388184
Validation loss: 2.1310026745001474

Epoch: 5| Step: 8
Training loss: 1.0241791009902954
Validation loss: 2.089584097266197

Epoch: 5| Step: 9
Training loss: 1.3933746814727783
Validation loss: 2.1735103676716485

Epoch: 5| Step: 10
Training loss: 1.5848712921142578
Validation loss: 2.171429375807444

Epoch: 5| Step: 11
Training loss: 0.868593692779541
Validation loss: 2.2089486022790275

Epoch: 400| Step: 0
Training loss: 1.297440767288208
Validation loss: 2.233916074037552

Epoch: 5| Step: 1
Training loss: 1.7602159976959229
Validation loss: 2.2893679241339364

Epoch: 5| Step: 2
Training loss: 1.8318217992782593
Validation loss: 2.2593924154837928

Epoch: 5| Step: 3
Training loss: 1.2998220920562744
Validation loss: 2.2281501243511834

Epoch: 5| Step: 4
Training loss: 1.7841880321502686
Validation loss: 2.173551787932714

Epoch: 5| Step: 5
Training loss: 1.341917634010315
Validation loss: 2.122950648268064

Epoch: 5| Step: 6
Training loss: 1.2888761758804321
Validation loss: 2.150974983970324

Epoch: 5| Step: 7
Training loss: 1.242687702178955
Validation loss: 2.149497702717781

Epoch: 5| Step: 8
Training loss: 1.3705155849456787
Validation loss: 2.136457766095797

Epoch: 5| Step: 9
Training loss: 1.5747575759887695
Validation loss: 2.1475354433059692

Epoch: 5| Step: 10
Training loss: 1.2306768894195557
Validation loss: 2.177557115753492

Epoch: 5| Step: 11
Training loss: 0.5574982166290283
Validation loss: 2.160710667570432

Epoch: 401| Step: 0
Training loss: 1.4218195676803589
Validation loss: 2.1491780132055283

Epoch: 5| Step: 1
Training loss: 0.9296906590461731
Validation loss: 2.1552621722221375

Epoch: 5| Step: 2
Training loss: 1.2086025476455688
Validation loss: 2.1522732426722846

Epoch: 5| Step: 3
Training loss: 1.3652154207229614
Validation loss: 2.1616479009389877

Epoch: 5| Step: 4
Training loss: 1.269982933998108
Validation loss: 2.162495940923691

Epoch: 5| Step: 5
Training loss: 1.4269944429397583
Validation loss: 2.156871815522512

Epoch: 5| Step: 6
Training loss: 0.9465600252151489
Validation loss: 2.1623895168304443

Epoch: 5| Step: 7
Training loss: 1.372078537940979
Validation loss: 2.1887449522813163

Epoch: 5| Step: 8
Training loss: 1.9061148166656494
Validation loss: 2.1698255389928818

Epoch: 5| Step: 9
Training loss: 1.5488189458847046
Validation loss: 2.22530131538709

Epoch: 5| Step: 10
Training loss: 1.5247390270233154
Validation loss: 2.1817532777786255

Epoch: 5| Step: 11
Training loss: 0.9872258901596069
Validation loss: 2.188918282588323

Epoch: 402| Step: 0
Training loss: 1.6013399362564087
Validation loss: 2.136817236741384

Epoch: 5| Step: 1
Training loss: 1.3358547687530518
Validation loss: 2.1481671233971915

Epoch: 5| Step: 2
Training loss: 0.8337713479995728
Validation loss: 2.148155634601911

Epoch: 5| Step: 3
Training loss: 1.3631722927093506
Validation loss: 2.1577852070331573

Epoch: 5| Step: 4
Training loss: 0.9171612858772278
Validation loss: 2.1523685355981192

Epoch: 5| Step: 5
Training loss: 1.1653114557266235
Validation loss: 2.1374744524558387

Epoch: 5| Step: 6
Training loss: 1.55153489112854
Validation loss: 2.1365914940834045

Epoch: 5| Step: 7
Training loss: 1.3202861547470093
Validation loss: 2.159851868947347

Epoch: 5| Step: 8
Training loss: 2.3154025077819824
Validation loss: 2.1217797299226127

Epoch: 5| Step: 9
Training loss: 1.2614829540252686
Validation loss: 2.1432687441507974

Epoch: 5| Step: 10
Training loss: 1.279017686843872
Validation loss: 2.1513101955254874

Epoch: 5| Step: 11
Training loss: 2.127758264541626
Validation loss: 2.1697015166282654

Epoch: 403| Step: 0
Training loss: 1.0294276475906372
Validation loss: 2.2353756725788116

Epoch: 5| Step: 1
Training loss: 1.3058372735977173
Validation loss: 2.23513400554657

Epoch: 5| Step: 2
Training loss: 2.279266595840454
Validation loss: 2.2313330322504044

Epoch: 5| Step: 3
Training loss: 0.9876973032951355
Validation loss: 2.221646100282669

Epoch: 5| Step: 4
Training loss: 1.3604090213775635
Validation loss: 2.2018034855524697

Epoch: 5| Step: 5
Training loss: 0.7689887285232544
Validation loss: 2.2065703570842743

Epoch: 5| Step: 6
Training loss: 0.8810355067253113
Validation loss: 2.175201892852783

Epoch: 5| Step: 7
Training loss: 1.4927235841751099
Validation loss: 2.123773460586866

Epoch: 5| Step: 8
Training loss: 1.7109127044677734
Validation loss: 2.175426090757052

Epoch: 5| Step: 9
Training loss: 1.405813455581665
Validation loss: 2.1607820242643356

Epoch: 5| Step: 10
Training loss: 1.7325782775878906
Validation loss: 2.196592698494593

Epoch: 5| Step: 11
Training loss: 3.5870537757873535
Validation loss: 2.1401923298835754

Epoch: 404| Step: 0
Training loss: 1.5843303203582764
Validation loss: 2.1616228769222894

Epoch: 5| Step: 1
Training loss: 1.18924880027771
Validation loss: 2.1925763140122094

Epoch: 5| Step: 2
Training loss: 0.942547619342804
Validation loss: 2.2078737368186316

Epoch: 5| Step: 3
Training loss: 1.2835725545883179
Validation loss: 2.199140081803004

Epoch: 5| Step: 4
Training loss: 1.4574463367462158
Validation loss: 2.2201106746991477

Epoch: 5| Step: 5
Training loss: 1.9665582180023193
Validation loss: 2.238611251115799

Epoch: 5| Step: 6
Training loss: 1.6981115341186523
Validation loss: 2.2245738903681436

Epoch: 5| Step: 7
Training loss: 1.3587110042572021
Validation loss: 2.2255458732446036

Epoch: 5| Step: 8
Training loss: 1.176120400428772
Validation loss: 2.180899739265442

Epoch: 5| Step: 9
Training loss: 1.5107440948486328
Validation loss: 2.179275691509247

Epoch: 5| Step: 10
Training loss: 1.2452423572540283
Validation loss: 2.1955956319967904

Epoch: 5| Step: 11
Training loss: 1.2133914232254028
Validation loss: 2.1342726051807404

Epoch: 405| Step: 0
Training loss: 1.2909873723983765
Validation loss: 2.1727059284845986

Epoch: 5| Step: 1
Training loss: 1.036209225654602
Validation loss: 2.143081620335579

Epoch: 5| Step: 2
Training loss: 1.7457195520401
Validation loss: 2.1673444360494614

Epoch: 5| Step: 3
Training loss: 1.145888090133667
Validation loss: 2.1577550023794174

Epoch: 5| Step: 4
Training loss: 1.3560941219329834
Validation loss: 2.1594267785549164

Epoch: 5| Step: 5
Training loss: 1.3572202920913696
Validation loss: 2.149164711435636

Epoch: 5| Step: 6
Training loss: 2.043832302093506
Validation loss: 2.1511769145727158

Epoch: 5| Step: 7
Training loss: 0.8912855386734009
Validation loss: 2.182313467065493

Epoch: 5| Step: 8
Training loss: 1.3595845699310303
Validation loss: 2.148824726541837

Epoch: 5| Step: 9
Training loss: 1.3603445291519165
Validation loss: 2.1488636384407678

Epoch: 5| Step: 10
Training loss: 1.4184999465942383
Validation loss: 2.1476686745882034

Epoch: 5| Step: 11
Training loss: 1.56768798828125
Validation loss: 2.159812738498052

Epoch: 406| Step: 0
Training loss: 0.9514058828353882
Validation loss: 2.1425777127345405

Epoch: 5| Step: 1
Training loss: 1.161373496055603
Validation loss: 2.1023494948943457

Epoch: 5| Step: 2
Training loss: 1.316465139389038
Validation loss: 2.1201713482538858

Epoch: 5| Step: 3
Training loss: 1.8693511486053467
Validation loss: 2.1276914179325104

Epoch: 5| Step: 4
Training loss: 1.5885616540908813
Validation loss: 2.1295675883690515

Epoch: 5| Step: 5
Training loss: 0.7859002351760864
Validation loss: 2.081048304835955

Epoch: 5| Step: 6
Training loss: 2.033022165298462
Validation loss: 2.1019658197959266

Epoch: 5| Step: 7
Training loss: 1.2263381481170654
Validation loss: 2.0874136090278625

Epoch: 5| Step: 8
Training loss: 1.340711236000061
Validation loss: 2.099168762564659

Epoch: 5| Step: 9
Training loss: 0.9760240316390991
Validation loss: 2.0974832425514855

Epoch: 5| Step: 10
Training loss: 1.6194146871566772
Validation loss: 2.121142089366913

Epoch: 5| Step: 11
Training loss: 1.0386362075805664
Validation loss: 2.0862411310275397

Epoch: 407| Step: 0
Training loss: 1.3052432537078857
Validation loss: 2.0972915440797806

Epoch: 5| Step: 1
Training loss: 1.6991665363311768
Validation loss: 2.111868898073832

Epoch: 5| Step: 2
Training loss: 1.6464993953704834
Validation loss: 2.0894342809915543

Epoch: 5| Step: 3
Training loss: 1.0503060817718506
Validation loss: 2.053979218006134

Epoch: 5| Step: 4
Training loss: 0.9402362704277039
Validation loss: 2.1001604149738946

Epoch: 5| Step: 5
Training loss: 1.3175313472747803
Validation loss: 2.103003849585851

Epoch: 5| Step: 6
Training loss: 1.4626338481903076
Validation loss: 2.0841221113999686

Epoch: 5| Step: 7
Training loss: 1.3331537246704102
Validation loss: 2.0836962511142096

Epoch: 5| Step: 8
Training loss: 1.1467010974884033
Validation loss: 2.0708952645460763

Epoch: 5| Step: 9
Training loss: 1.025498628616333
Validation loss: 2.089232638478279

Epoch: 5| Step: 10
Training loss: 1.430967092514038
Validation loss: 2.0738839507102966

Epoch: 5| Step: 11
Training loss: 1.9647516012191772
Validation loss: 2.1131137808163962

Epoch: 408| Step: 0
Training loss: 1.7793254852294922
Validation loss: 2.109830677509308

Epoch: 5| Step: 1
Training loss: 0.7526404857635498
Validation loss: 2.11540021498998

Epoch: 5| Step: 2
Training loss: 1.1929781436920166
Validation loss: 2.1519439071416855

Epoch: 5| Step: 3
Training loss: 1.3735477924346924
Validation loss: 2.1386321038007736

Epoch: 5| Step: 4
Training loss: 1.5408881902694702
Validation loss: 2.1587124864260354

Epoch: 5| Step: 5
Training loss: 1.154557466506958
Validation loss: 2.176481088002523

Epoch: 5| Step: 6
Training loss: 1.4321644306182861
Validation loss: 2.207105835278829

Epoch: 5| Step: 7
Training loss: 1.4028823375701904
Validation loss: 2.178959846496582

Epoch: 5| Step: 8
Training loss: 1.1657536029815674
Validation loss: 2.1473029057184854

Epoch: 5| Step: 9
Training loss: 1.705255150794983
Validation loss: 2.151241754492124

Epoch: 5| Step: 10
Training loss: 1.2036840915679932
Validation loss: 2.1546909163395562

Epoch: 5| Step: 11
Training loss: 1.8662078380584717
Validation loss: 2.161327838897705

Epoch: 409| Step: 0
Training loss: 0.9869101643562317
Validation loss: 2.150200759371122

Epoch: 5| Step: 1
Training loss: 1.4232308864593506
Validation loss: 2.2040864725907645

Epoch: 5| Step: 2
Training loss: 1.0913333892822266
Validation loss: 2.1663765758275986

Epoch: 5| Step: 3
Training loss: 1.6821660995483398
Validation loss: 2.197521557410558

Epoch: 5| Step: 4
Training loss: 1.5123423337936401
Validation loss: 2.17699958384037

Epoch: 5| Step: 5
Training loss: 1.1660315990447998
Validation loss: 2.1559768468141556

Epoch: 5| Step: 6
Training loss: 1.2817847728729248
Validation loss: 2.1840391755104065

Epoch: 5| Step: 7
Training loss: 1.442339539527893
Validation loss: 2.187512402733167

Epoch: 5| Step: 8
Training loss: 1.718611717224121
Validation loss: 2.216653287410736

Epoch: 5| Step: 9
Training loss: 1.4798442125320435
Validation loss: 2.198999231060346

Epoch: 5| Step: 10
Training loss: 1.538666009902954
Validation loss: 2.221593976020813

Epoch: 5| Step: 11
Training loss: 1.0526127815246582
Validation loss: 2.1683185547590256

Epoch: 410| Step: 0
Training loss: 0.8866411447525024
Validation loss: 2.1692097087701163

Epoch: 5| Step: 1
Training loss: 1.5309313535690308
Validation loss: 2.2130439778168998

Epoch: 5| Step: 2
Training loss: 1.070372462272644
Validation loss: 2.187823841969172

Epoch: 5| Step: 3
Training loss: 0.8668340444564819
Validation loss: 2.1753788689772287

Epoch: 5| Step: 4
Training loss: 1.2703099250793457
Validation loss: 2.1543746640284858

Epoch: 5| Step: 5
Training loss: 1.7451339960098267
Validation loss: 2.173897927006086

Epoch: 5| Step: 6
Training loss: 1.8941125869750977
Validation loss: 2.156883324186007

Epoch: 5| Step: 7
Training loss: 1.0616142749786377
Validation loss: 2.166723981499672

Epoch: 5| Step: 8
Training loss: 1.5013706684112549
Validation loss: 2.164655660589536

Epoch: 5| Step: 9
Training loss: 1.3397138118743896
Validation loss: 2.144074489672979

Epoch: 5| Step: 10
Training loss: 1.59079909324646
Validation loss: 2.1549124469359717

Epoch: 5| Step: 11
Training loss: 1.1955418586730957
Validation loss: 2.172731101512909

Epoch: 411| Step: 0
Training loss: 1.1326475143432617
Validation loss: 2.187729060649872

Epoch: 5| Step: 1
Training loss: 1.7607158422470093
Validation loss: 2.1977676302194595

Epoch: 5| Step: 2
Training loss: 1.6656162738800049
Validation loss: 2.1944964081048965

Epoch: 5| Step: 3
Training loss: 0.9013034701347351
Validation loss: 2.201726218064626

Epoch: 5| Step: 4
Training loss: 1.283840298652649
Validation loss: 2.170434355735779

Epoch: 5| Step: 5
Training loss: 1.0544142723083496
Validation loss: 2.1877507964769998

Epoch: 5| Step: 6
Training loss: 1.3690681457519531
Validation loss: 2.1737992465496063

Epoch: 5| Step: 7
Training loss: 1.2402665615081787
Validation loss: 2.1323175678650537

Epoch: 5| Step: 8
Training loss: 1.6102432012557983
Validation loss: 2.129184285799662

Epoch: 5| Step: 9
Training loss: 0.8827577829360962
Validation loss: 2.1275342404842377

Epoch: 5| Step: 10
Training loss: 1.6234862804412842
Validation loss: 2.1620264053344727

Epoch: 5| Step: 11
Training loss: 0.5226635932922363
Validation loss: 2.1237439612547555

Epoch: 412| Step: 0
Training loss: 1.159536600112915
Validation loss: 2.1163481573263803

Epoch: 5| Step: 1
Training loss: 1.3875261545181274
Validation loss: 2.106681043903033

Epoch: 5| Step: 2
Training loss: 1.0757852792739868
Validation loss: 2.1374896268049874

Epoch: 5| Step: 3
Training loss: 1.2236799001693726
Validation loss: 2.1232236276070275

Epoch: 5| Step: 4
Training loss: 1.6769180297851562
Validation loss: 2.1478859186172485

Epoch: 5| Step: 5
Training loss: 1.4079952239990234
Validation loss: 2.0939353009064994

Epoch: 5| Step: 6
Training loss: 1.4804853200912476
Validation loss: 2.1719202796618142

Epoch: 5| Step: 7
Training loss: 1.029126763343811
Validation loss: 2.117140089472135

Epoch: 5| Step: 8
Training loss: 1.7184484004974365
Validation loss: 2.186475843191147

Epoch: 5| Step: 9
Training loss: 0.9868732690811157
Validation loss: 2.147986431916555

Epoch: 5| Step: 10
Training loss: 1.5578514337539673
Validation loss: 2.2180862724781036

Epoch: 5| Step: 11
Training loss: 0.9241635799407959
Validation loss: 2.207304651538531

Epoch: 413| Step: 0
Training loss: 0.8001390695571899
Validation loss: 2.1759957869847617

Epoch: 5| Step: 1
Training loss: 2.6121246814727783
Validation loss: 2.206972365578016

Epoch: 5| Step: 2
Training loss: 1.0939524173736572
Validation loss: 2.145620127518972

Epoch: 5| Step: 3
Training loss: 1.6921297311782837
Validation loss: 2.1232675164937973

Epoch: 5| Step: 4
Training loss: 1.0112853050231934
Validation loss: 2.157287826140722

Epoch: 5| Step: 5
Training loss: 0.7592470049858093
Validation loss: 2.1843158503373465

Epoch: 5| Step: 6
Training loss: 0.798261821269989
Validation loss: 2.1745080649852753

Epoch: 5| Step: 7
Training loss: 1.132269024848938
Validation loss: 2.2049369712670646

Epoch: 5| Step: 8
Training loss: 1.3403100967407227
Validation loss: 2.1982090969880423

Epoch: 5| Step: 9
Training loss: 1.6529489755630493
Validation loss: 2.1972671200831733

Epoch: 5| Step: 10
Training loss: 1.529278039932251
Validation loss: 2.174030418197314

Epoch: 5| Step: 11
Training loss: 1.6300721168518066
Validation loss: 2.2147646894057593

Epoch: 414| Step: 0
Training loss: 1.7515804767608643
Validation loss: 2.2102920015652976

Epoch: 5| Step: 1
Training loss: 1.2002025842666626
Validation loss: 2.2328536907831826

Epoch: 5| Step: 2
Training loss: 0.9043749570846558
Validation loss: 2.1992580691973367

Epoch: 5| Step: 3
Training loss: 1.891404151916504
Validation loss: 2.2512801587581635

Epoch: 5| Step: 4
Training loss: 1.554354190826416
Validation loss: 2.2573647697766623

Epoch: 5| Step: 5
Training loss: 1.8914579153060913
Validation loss: 2.2460603614648185

Epoch: 5| Step: 6
Training loss: 0.9396831393241882
Validation loss: 2.2396708528200784

Epoch: 5| Step: 7
Training loss: 1.145154595375061
Validation loss: 2.2362209210793176

Epoch: 5| Step: 8
Training loss: 1.2670667171478271
Validation loss: 2.178599347670873

Epoch: 5| Step: 9
Training loss: 0.8220928907394409
Validation loss: 2.154754156867663

Epoch: 5| Step: 10
Training loss: 1.3140236139297485
Validation loss: 2.1471401304006577

Epoch: 5| Step: 11
Training loss: 1.0620336532592773
Validation loss: 2.1300163020690284

Epoch: 415| Step: 0
Training loss: 1.0006320476531982
Validation loss: 2.104517340660095

Epoch: 5| Step: 1
Training loss: 1.6566295623779297
Validation loss: 2.145998661716779

Epoch: 5| Step: 2
Training loss: 2.144493818283081
Validation loss: 2.1075006326039634

Epoch: 5| Step: 3
Training loss: 1.1496145725250244
Validation loss: 2.1585758129755654

Epoch: 5| Step: 4
Training loss: 0.7245967984199524
Validation loss: 2.1413511782884598

Epoch: 5| Step: 5
Training loss: 1.2757511138916016
Validation loss: 2.138351375857989

Epoch: 5| Step: 6
Training loss: 1.318626046180725
Validation loss: 2.1520797411600747

Epoch: 5| Step: 7
Training loss: 1.564457654953003
Validation loss: 2.154090459148089

Epoch: 5| Step: 8
Training loss: 1.3743040561676025
Validation loss: 2.1981221785147986

Epoch: 5| Step: 9
Training loss: 1.0303758382797241
Validation loss: 2.206149344642957

Epoch: 5| Step: 10
Training loss: 1.2795573472976685
Validation loss: 2.151922752459844

Epoch: 5| Step: 11
Training loss: 1.8768447637557983
Validation loss: 2.1353337665398917

Epoch: 416| Step: 0
Training loss: 0.7390782237052917
Validation loss: 2.125818873445193

Epoch: 5| Step: 1
Training loss: 1.8986756801605225
Validation loss: 2.123186945915222

Epoch: 5| Step: 2
Training loss: 1.4392530918121338
Validation loss: 2.133635555704435

Epoch: 5| Step: 3
Training loss: 1.0630749464035034
Validation loss: 2.135501950979233

Epoch: 5| Step: 4
Training loss: 1.4410914182662964
Validation loss: 2.154408782720566

Epoch: 5| Step: 5
Training loss: 1.7962268590927124
Validation loss: 2.171456426382065

Epoch: 5| Step: 6
Training loss: 1.2726094722747803
Validation loss: 2.178249071041743

Epoch: 5| Step: 7
Training loss: 1.3903127908706665
Validation loss: 2.193830152352651

Epoch: 5| Step: 8
Training loss: 1.30665123462677
Validation loss: 2.188329041004181

Epoch: 5| Step: 9
Training loss: 1.359664797782898
Validation loss: 2.18661638100942

Epoch: 5| Step: 10
Training loss: 1.11385178565979
Validation loss: 2.247825359304746

Epoch: 5| Step: 11
Training loss: 1.0296850204467773
Validation loss: 2.2548052916924157

Epoch: 417| Step: 0
Training loss: 1.2913763523101807
Validation loss: 2.1965871105591455

Epoch: 5| Step: 1
Training loss: 1.708496332168579
Validation loss: 2.237252876162529

Epoch: 5| Step: 2
Training loss: 1.037353754043579
Validation loss: 2.2005606244007745

Epoch: 5| Step: 3
Training loss: 1.644457221031189
Validation loss: 2.167713239789009

Epoch: 5| Step: 4
Training loss: 1.1843510866165161
Validation loss: 2.146890342235565

Epoch: 5| Step: 5
Training loss: 1.6617733240127563
Validation loss: 2.1788322081168494

Epoch: 5| Step: 6
Training loss: 1.1265383958816528
Validation loss: 2.1467013160387673

Epoch: 5| Step: 7
Training loss: 1.4104548692703247
Validation loss: 2.1476652175188065

Epoch: 5| Step: 8
Training loss: 1.090055227279663
Validation loss: 2.1685616870721183

Epoch: 5| Step: 9
Training loss: 1.1857672929763794
Validation loss: 2.17562169333299

Epoch: 5| Step: 10
Training loss: 1.15053391456604
Validation loss: 2.1781683017810187

Epoch: 5| Step: 11
Training loss: 0.21642088890075684
Validation loss: 2.1826164523760476

Epoch: 418| Step: 0
Training loss: 1.666176199913025
Validation loss: 2.2105683286984763

Epoch: 5| Step: 1
Training loss: 1.2861101627349854
Validation loss: 2.169820547103882

Epoch: 5| Step: 2
Training loss: 0.9566903114318848
Validation loss: 2.1607515017191568

Epoch: 5| Step: 3
Training loss: 0.8416075706481934
Validation loss: 2.176962489883105

Epoch: 5| Step: 4
Training loss: 1.3961055278778076
Validation loss: 2.131126418709755

Epoch: 5| Step: 5
Training loss: 1.5213708877563477
Validation loss: 2.1375592847665152

Epoch: 5| Step: 6
Training loss: 1.1236982345581055
Validation loss: 2.167665104071299

Epoch: 5| Step: 7
Training loss: 1.4194552898406982
Validation loss: 2.167955001195272

Epoch: 5| Step: 8
Training loss: 1.1596482992172241
Validation loss: 2.180831089615822

Epoch: 5| Step: 9
Training loss: 0.9793926477432251
Validation loss: 2.174502675731977

Epoch: 5| Step: 10
Training loss: 1.7404989004135132
Validation loss: 2.149952600399653

Epoch: 5| Step: 11
Training loss: 1.17037832736969
Validation loss: 2.170538822809855

Epoch: 419| Step: 0
Training loss: 1.220694899559021
Validation loss: 2.141274333000183

Epoch: 5| Step: 1
Training loss: 0.9761136770248413
Validation loss: 2.1577541579802832

Epoch: 5| Step: 2
Training loss: 1.0747840404510498
Validation loss: 2.1761894126733146

Epoch: 5| Step: 3
Training loss: 1.6916160583496094
Validation loss: 2.1909961799780526

Epoch: 5| Step: 4
Training loss: 1.194866418838501
Validation loss: 2.1701182574033737

Epoch: 5| Step: 5
Training loss: 1.112997055053711
Validation loss: 2.150896896918615

Epoch: 5| Step: 6
Training loss: 1.0695505142211914
Validation loss: 2.143606409430504

Epoch: 5| Step: 7
Training loss: 1.1465389728546143
Validation loss: 2.120506525039673

Epoch: 5| Step: 8
Training loss: 1.2895234823226929
Validation loss: 2.1366459329922995

Epoch: 5| Step: 9
Training loss: 1.7829738855361938
Validation loss: 2.134110609690348

Epoch: 5| Step: 10
Training loss: 1.6882526874542236
Validation loss: 2.103981470068296

Epoch: 5| Step: 11
Training loss: 1.6540393829345703
Validation loss: 2.0977704425652823

Epoch: 420| Step: 0
Training loss: 0.9037976264953613
Validation loss: 2.136582707365354

Epoch: 5| Step: 1
Training loss: 1.3072435855865479
Validation loss: 2.135475759704908

Epoch: 5| Step: 2
Training loss: 1.7326223850250244
Validation loss: 2.196129262447357

Epoch: 5| Step: 3
Training loss: 1.366623878479004
Validation loss: 2.1901553173859916

Epoch: 5| Step: 4
Training loss: 0.902696430683136
Validation loss: 2.2016252130270004

Epoch: 5| Step: 5
Training loss: 1.227880835533142
Validation loss: 2.216325600941976

Epoch: 5| Step: 6
Training loss: 1.954797387123108
Validation loss: 2.213342621922493

Epoch: 5| Step: 7
Training loss: 1.2307673692703247
Validation loss: 2.191853721936544

Epoch: 5| Step: 8
Training loss: 1.2322689294815063
Validation loss: 2.180411070585251

Epoch: 5| Step: 9
Training loss: 1.4761406183242798
Validation loss: 2.1794759134451547

Epoch: 5| Step: 10
Training loss: 1.6043914556503296
Validation loss: 2.1630667050679526

Epoch: 5| Step: 11
Training loss: 1.7802326679229736
Validation loss: 2.1847151120503745

Epoch: 421| Step: 0
Training loss: 1.08101487159729
Validation loss: 2.164324243863424

Epoch: 5| Step: 1
Training loss: 1.4847911596298218
Validation loss: 2.137903427084287

Epoch: 5| Step: 2
Training loss: 1.0619862079620361
Validation loss: 2.2158667892217636

Epoch: 5| Step: 3
Training loss: 1.0654478073120117
Validation loss: 2.203519274791082

Epoch: 5| Step: 4
Training loss: 1.376921534538269
Validation loss: 2.202016403277715

Epoch: 5| Step: 5
Training loss: 1.1834118366241455
Validation loss: 2.147806167602539

Epoch: 5| Step: 6
Training loss: 1.4375040531158447
Validation loss: 2.1462465574344

Epoch: 5| Step: 7
Training loss: 1.5407350063323975
Validation loss: 2.171765387058258

Epoch: 5| Step: 8
Training loss: 1.265669584274292
Validation loss: 2.1577471693356833

Epoch: 5| Step: 9
Training loss: 1.513472080230713
Validation loss: 2.160292848944664

Epoch: 5| Step: 10
Training loss: 1.1721998453140259
Validation loss: 2.153868814309438

Epoch: 5| Step: 11
Training loss: 1.6489289999008179
Validation loss: 2.1358093917369843

Epoch: 422| Step: 0
Training loss: 1.5098670721054077
Validation loss: 2.1302238355080285

Epoch: 5| Step: 1
Training loss: 1.350158929824829
Validation loss: 2.0951143155495324

Epoch: 5| Step: 2
Training loss: 0.6852899789810181
Validation loss: 2.1475093960762024

Epoch: 5| Step: 3
Training loss: 1.6534696817398071
Validation loss: 2.1057960788408914

Epoch: 5| Step: 4
Training loss: 1.507752537727356
Validation loss: 2.090196212132772

Epoch: 5| Step: 5
Training loss: 0.8724936246871948
Validation loss: 2.0969018787145615

Epoch: 5| Step: 6
Training loss: 1.1519722938537598
Validation loss: 2.119202966491381

Epoch: 5| Step: 7
Training loss: 1.5854156017303467
Validation loss: 2.110986426472664

Epoch: 5| Step: 8
Training loss: 1.1032384634017944
Validation loss: 2.1348185688257217

Epoch: 5| Step: 9
Training loss: 1.1239458322525024
Validation loss: 2.1380264163017273

Epoch: 5| Step: 10
Training loss: 1.0578906536102295
Validation loss: 2.097967972358068

Epoch: 5| Step: 11
Training loss: 4.005868911743164
Validation loss: 2.1259299963712692

Epoch: 423| Step: 0
Training loss: 1.8869915008544922
Validation loss: 2.161981781323751

Epoch: 5| Step: 1
Training loss: 1.2947041988372803
Validation loss: 2.0880653659502664

Epoch: 5| Step: 2
Training loss: 1.2189161777496338
Validation loss: 2.1596697668234506

Epoch: 5| Step: 3
Training loss: 1.5268809795379639
Validation loss: 2.109367643793424

Epoch: 5| Step: 4
Training loss: 1.0507779121398926
Validation loss: 2.0989717145760856

Epoch: 5| Step: 5
Training loss: 0.9120162725448608
Validation loss: 2.0878144900004068

Epoch: 5| Step: 6
Training loss: 0.8250481486320496
Validation loss: 2.1410075177749

Epoch: 5| Step: 7
Training loss: 1.4892606735229492
Validation loss: 2.095884680747986

Epoch: 5| Step: 8
Training loss: 0.5736369490623474
Validation loss: 2.114899898568789

Epoch: 5| Step: 9
Training loss: 1.6825488805770874
Validation loss: 2.192991927266121

Epoch: 5| Step: 10
Training loss: 1.808145523071289
Validation loss: 2.190345158179601

Epoch: 5| Step: 11
Training loss: 1.1329622268676758
Validation loss: 2.2116650889317193

Epoch: 424| Step: 0
Training loss: 1.098293423652649
Validation loss: 2.184621890385946

Epoch: 5| Step: 1
Training loss: 1.0980863571166992
Validation loss: 2.1798613568147025

Epoch: 5| Step: 2
Training loss: 1.0661228895187378
Validation loss: 2.1416568954785666

Epoch: 5| Step: 3
Training loss: 1.2317835092544556
Validation loss: 2.141985277334849

Epoch: 5| Step: 4
Training loss: 1.5785515308380127
Validation loss: 2.1797428081432977

Epoch: 5| Step: 5
Training loss: 1.9126081466674805
Validation loss: 2.144411807258924

Epoch: 5| Step: 6
Training loss: 1.1283519268035889
Validation loss: 2.150725523630778

Epoch: 5| Step: 7
Training loss: 1.0103733539581299
Validation loss: 2.182058056195577

Epoch: 5| Step: 8
Training loss: 1.5064904689788818
Validation loss: 2.1610092371702194

Epoch: 5| Step: 9
Training loss: 1.5153547525405884
Validation loss: 2.1435654362042746

Epoch: 5| Step: 10
Training loss: 1.2275205850601196
Validation loss: 2.1580787003040314

Epoch: 5| Step: 11
Training loss: 2.06938099861145
Validation loss: 2.1459848433732986

Epoch: 425| Step: 0
Training loss: 1.689069390296936
Validation loss: 2.124719589948654

Epoch: 5| Step: 1
Training loss: 0.9483972787857056
Validation loss: 2.1708481212457023

Epoch: 5| Step: 2
Training loss: 1.3050158023834229
Validation loss: 2.1261803209781647

Epoch: 5| Step: 3
Training loss: 0.7389338612556458
Validation loss: 2.18231034775575

Epoch: 5| Step: 4
Training loss: 1.1088178157806396
Validation loss: 2.180664877096812

Epoch: 5| Step: 5
Training loss: 1.1315882205963135
Validation loss: 2.149075910449028

Epoch: 5| Step: 6
Training loss: 0.9854300618171692
Validation loss: 2.12121145427227

Epoch: 5| Step: 7
Training loss: 1.6846510171890259
Validation loss: 2.1412779490152993

Epoch: 5| Step: 8
Training loss: 1.1414560079574585
Validation loss: 2.160117045044899

Epoch: 5| Step: 9
Training loss: 0.9286094903945923
Validation loss: 2.142423669497172

Epoch: 5| Step: 10
Training loss: 1.846095323562622
Validation loss: 2.143451208869616

Epoch: 5| Step: 11
Training loss: 2.160914897918701
Validation loss: 2.157394900918007

Epoch: 426| Step: 0
Training loss: 1.5572266578674316
Validation loss: 2.1125062704086304

Epoch: 5| Step: 1
Training loss: 1.5725018978118896
Validation loss: 2.1684827357530594

Epoch: 5| Step: 2
Training loss: 1.0251907110214233
Validation loss: 2.2082575112581253

Epoch: 5| Step: 3
Training loss: 1.2924054861068726
Validation loss: 2.236815412839254

Epoch: 5| Step: 4
Training loss: 1.3205987215042114
Validation loss: 2.20052777727445

Epoch: 5| Step: 5
Training loss: 1.3683218955993652
Validation loss: 2.1797339618206024

Epoch: 5| Step: 6
Training loss: 1.5728380680084229
Validation loss: 2.1808715065320334

Epoch: 5| Step: 7
Training loss: 1.0870250463485718
Validation loss: 2.1438726484775543

Epoch: 5| Step: 8
Training loss: 1.3791522979736328
Validation loss: 2.1861936201651893

Epoch: 5| Step: 9
Training loss: 0.908673882484436
Validation loss: 2.122127890586853

Epoch: 5| Step: 10
Training loss: 1.0383291244506836
Validation loss: 2.161740099390348

Epoch: 5| Step: 11
Training loss: 1.6200634241104126
Validation loss: 2.143127962946892

Epoch: 427| Step: 0
Training loss: 0.43440771102905273
Validation loss: 2.0806407779455185

Epoch: 5| Step: 1
Training loss: 1.2787818908691406
Validation loss: 2.099515194694201

Epoch: 5| Step: 2
Training loss: 0.939836323261261
Validation loss: 2.1166430910428367

Epoch: 5| Step: 3
Training loss: 0.9950346946716309
Validation loss: 2.1337775141000748

Epoch: 5| Step: 4
Training loss: 1.9836890697479248
Validation loss: 2.1689662834008536

Epoch: 5| Step: 5
Training loss: 1.2893089056015015
Validation loss: 2.1550677915414176

Epoch: 5| Step: 6
Training loss: 1.4591662883758545
Validation loss: 2.193421999613444

Epoch: 5| Step: 7
Training loss: 1.5032103061676025
Validation loss: 2.2036839773257575

Epoch: 5| Step: 8
Training loss: 1.0941129922866821
Validation loss: 2.168178051710129

Epoch: 5| Step: 9
Training loss: 1.3659021854400635
Validation loss: 2.153034736712774

Epoch: 5| Step: 10
Training loss: 1.6242271661758423
Validation loss: 2.1407312552134194

Epoch: 5| Step: 11
Training loss: 1.820256233215332
Validation loss: 2.1051065921783447

Epoch: 428| Step: 0
Training loss: 1.3324625492095947
Validation loss: 2.1429597785075507

Epoch: 5| Step: 1
Training loss: 0.7494056820869446
Validation loss: 2.1524027287960052

Epoch: 5| Step: 2
Training loss: 1.262468695640564
Validation loss: 2.1270698408285775

Epoch: 5| Step: 3
Training loss: 1.540317416191101
Validation loss: 2.143717959523201

Epoch: 5| Step: 4
Training loss: 1.6491855382919312
Validation loss: 2.157482385635376

Epoch: 5| Step: 5
Training loss: 0.934337317943573
Validation loss: 2.1477879534165063

Epoch: 5| Step: 6
Training loss: 1.5810823440551758
Validation loss: 2.15260216097037

Epoch: 5| Step: 7
Training loss: 1.7276155948638916
Validation loss: 2.1933375746011734

Epoch: 5| Step: 8
Training loss: 1.4310245513916016
Validation loss: 2.235555589199066

Epoch: 5| Step: 9
Training loss: 1.3017284870147705
Validation loss: 2.3153254042069116

Epoch: 5| Step: 10
Training loss: 1.178930640220642
Validation loss: 2.3231527556975684

Epoch: 5| Step: 11
Training loss: 1.4649263620376587
Validation loss: 2.2637627025445304

Epoch: 429| Step: 0
Training loss: 1.218709945678711
Validation loss: 2.213667646050453

Epoch: 5| Step: 1
Training loss: 1.3251522779464722
Validation loss: 2.170615995923678

Epoch: 5| Step: 2
Training loss: 0.7471939921379089
Validation loss: 2.139701927701632

Epoch: 5| Step: 3
Training loss: 0.7482373118400574
Validation loss: 2.159203211466471

Epoch: 5| Step: 4
Training loss: 0.8249689340591431
Validation loss: 2.1800776720046997

Epoch: 5| Step: 5
Training loss: 1.8901574611663818
Validation loss: 2.125473732749621

Epoch: 5| Step: 6
Training loss: 1.831271767616272
Validation loss: 2.1453608771165213

Epoch: 5| Step: 7
Training loss: 2.212514877319336
Validation loss: 2.161795362830162

Epoch: 5| Step: 8
Training loss: 1.716762900352478
Validation loss: 2.1618160903453827

Epoch: 5| Step: 9
Training loss: 1.2077019214630127
Validation loss: 2.1651518692572913

Epoch: 5| Step: 10
Training loss: 1.2558566331863403
Validation loss: 2.162655626734098

Epoch: 5| Step: 11
Training loss: 2.653446674346924
Validation loss: 2.1671969642241797

Epoch: 430| Step: 0
Training loss: 1.3245749473571777
Validation loss: 2.14202888806661

Epoch: 5| Step: 1
Training loss: 1.5113228559494019
Validation loss: 2.116589978337288

Epoch: 5| Step: 2
Training loss: 1.6300023794174194
Validation loss: 2.1739910195271173

Epoch: 5| Step: 3
Training loss: 1.6158950328826904
Validation loss: 2.166362076997757

Epoch: 5| Step: 4
Training loss: 1.3740594387054443
Validation loss: 2.16278645892938

Epoch: 5| Step: 5
Training loss: 1.2981932163238525
Validation loss: 2.180727183818817

Epoch: 5| Step: 6
Training loss: 1.3357850313186646
Validation loss: 2.1675672431786857

Epoch: 5| Step: 7
Training loss: 1.1902306079864502
Validation loss: 2.2054737955331802

Epoch: 5| Step: 8
Training loss: 0.9390158653259277
Validation loss: 2.201975847283999

Epoch: 5| Step: 9
Training loss: 0.8381535410881042
Validation loss: 2.1952982942263284

Epoch: 5| Step: 10
Training loss: 1.0686590671539307
Validation loss: 2.183499500155449

Epoch: 5| Step: 11
Training loss: 1.883004903793335
Validation loss: 2.1711986313263574

Epoch: 431| Step: 0
Training loss: 1.4878671169281006
Validation loss: 2.1424033641815186

Epoch: 5| Step: 1
Training loss: 1.9443199634552002
Validation loss: 2.114379068215688

Epoch: 5| Step: 2
Training loss: 0.9401981234550476
Validation loss: 2.165133059024811

Epoch: 5| Step: 3
Training loss: 1.6288563013076782
Validation loss: 2.143029977877935

Epoch: 5| Step: 4
Training loss: 1.522131085395813
Validation loss: 2.1353832334280014

Epoch: 5| Step: 5
Training loss: 0.9657871127128601
Validation loss: 2.1279703080654144

Epoch: 5| Step: 6
Training loss: 1.3505080938339233
Validation loss: 2.1646153181791306

Epoch: 5| Step: 7
Training loss: 0.9216405153274536
Validation loss: 2.22712109486262

Epoch: 5| Step: 8
Training loss: 1.6254091262817383
Validation loss: 2.206063687801361

Epoch: 5| Step: 9
Training loss: 1.00931715965271
Validation loss: 2.225854237874349

Epoch: 5| Step: 10
Training loss: 0.8127428889274597
Validation loss: 2.219173734386762

Epoch: 5| Step: 11
Training loss: 0.7751342058181763
Validation loss: 2.187929332256317

Epoch: 432| Step: 0
Training loss: 1.0532399415969849
Validation loss: 2.1890894174575806

Epoch: 5| Step: 1
Training loss: 1.4592372179031372
Validation loss: 2.2180175284544625

Epoch: 5| Step: 2
Training loss: 0.8308264017105103
Validation loss: 2.2176767687002816

Epoch: 5| Step: 3
Training loss: 1.5990726947784424
Validation loss: 2.2437749405701957

Epoch: 5| Step: 4
Training loss: 1.4479880332946777
Validation loss: 2.2428068419297538

Epoch: 5| Step: 5
Training loss: 1.1083674430847168
Validation loss: 2.246964310606321

Epoch: 5| Step: 6
Training loss: 1.5531946420669556
Validation loss: 2.23427352309227

Epoch: 5| Step: 7
Training loss: 1.2333145141601562
Validation loss: 2.235182066758474

Epoch: 5| Step: 8
Training loss: 2.0003468990325928
Validation loss: 2.242636392513911

Epoch: 5| Step: 9
Training loss: 1.2992461919784546
Validation loss: 2.204666862885157

Epoch: 5| Step: 10
Training loss: 1.3718639612197876
Validation loss: 2.2381038814783096

Epoch: 5| Step: 11
Training loss: 0.7747557163238525
Validation loss: 2.2004238814115524

Epoch: 433| Step: 0
Training loss: 1.6080896854400635
Validation loss: 2.133471334973971

Epoch: 5| Step: 1
Training loss: 1.188846468925476
Validation loss: 2.161826570828756

Epoch: 5| Step: 2
Training loss: 1.2273612022399902
Validation loss: 2.192743311325709

Epoch: 5| Step: 3
Training loss: 0.7907315492630005
Validation loss: 2.1735787441333136

Epoch: 5| Step: 4
Training loss: 0.9214016795158386
Validation loss: 2.168018952012062

Epoch: 5| Step: 5
Training loss: 1.3323314189910889
Validation loss: 2.17440856496493

Epoch: 5| Step: 6
Training loss: 1.1416441202163696
Validation loss: 2.127524256706238

Epoch: 5| Step: 7
Training loss: 1.1652356386184692
Validation loss: 2.1588560740152993

Epoch: 5| Step: 8
Training loss: 1.7084881067276
Validation loss: 2.1061971386273703

Epoch: 5| Step: 9
Training loss: 1.558734655380249
Validation loss: 2.084950178861618

Epoch: 5| Step: 10
Training loss: 1.7552757263183594
Validation loss: 2.0890785306692123

Epoch: 5| Step: 11
Training loss: 1.917243480682373
Validation loss: 2.1144707798957825

Epoch: 434| Step: 0
Training loss: 1.3602221012115479
Validation loss: 2.1275450537602105

Epoch: 5| Step: 1
Training loss: 0.7610790729522705
Validation loss: 2.1502045889695487

Epoch: 5| Step: 2
Training loss: 1.0974318981170654
Validation loss: 2.1275163193543754

Epoch: 5| Step: 3
Training loss: 1.305675745010376
Validation loss: 2.18493260939916

Epoch: 5| Step: 4
Training loss: 1.813530683517456
Validation loss: 2.1577672312657037

Epoch: 5| Step: 5
Training loss: 1.2017767429351807
Validation loss: 2.1801069577534995

Epoch: 5| Step: 6
Training loss: 1.241607666015625
Validation loss: 2.19104565680027

Epoch: 5| Step: 7
Training loss: 0.9816098213195801
Validation loss: 2.219589501619339

Epoch: 5| Step: 8
Training loss: 0.7966760993003845
Validation loss: 2.184341390927633

Epoch: 5| Step: 9
Training loss: 1.5730775594711304
Validation loss: 2.2442679554224014

Epoch: 5| Step: 10
Training loss: 1.519005537033081
Validation loss: 2.224669029315313

Epoch: 5| Step: 11
Training loss: 0.9843777418136597
Validation loss: 2.22769887248675

Epoch: 435| Step: 0
Training loss: 0.7480736970901489
Validation loss: 2.2020675788323083

Epoch: 5| Step: 1
Training loss: 1.8045787811279297
Validation loss: 2.1998431583245597

Epoch: 5| Step: 2
Training loss: 1.3921422958374023
Validation loss: 2.1730087300141654

Epoch: 5| Step: 3
Training loss: 0.6450514793395996
Validation loss: 2.1760606666405997

Epoch: 5| Step: 4
Training loss: 1.8297693729400635
Validation loss: 2.201357220609983

Epoch: 5| Step: 5
Training loss: 1.1903750896453857
Validation loss: 2.176975652575493

Epoch: 5| Step: 6
Training loss: 1.2174264192581177
Validation loss: 2.1880162060260773

Epoch: 5| Step: 7
Training loss: 1.281808614730835
Validation loss: 2.1686298747857413

Epoch: 5| Step: 8
Training loss: 1.5181984901428223
Validation loss: 2.2442263464132943

Epoch: 5| Step: 9
Training loss: 0.9961414337158203
Validation loss: 2.247448960940043

Epoch: 5| Step: 10
Training loss: 1.3899751901626587
Validation loss: 2.2669344345728555

Epoch: 5| Step: 11
Training loss: 2.092170238494873
Validation loss: 2.328252653280894

Epoch: 436| Step: 0
Training loss: 1.7308359146118164
Validation loss: 2.3038750290870667

Epoch: 5| Step: 1
Training loss: 1.2375820875167847
Validation loss: 2.235338881611824

Epoch: 5| Step: 2
Training loss: 1.3001348972320557
Validation loss: 2.202864189942678

Epoch: 5| Step: 3
Training loss: 1.2287729978561401
Validation loss: 2.1654676596323648

Epoch: 5| Step: 4
Training loss: 1.5812313556671143
Validation loss: 2.1792069574197135

Epoch: 5| Step: 5
Training loss: 0.9300445318222046
Validation loss: 2.189948861797651

Epoch: 5| Step: 6
Training loss: 1.1254148483276367
Validation loss: 2.185386816660563

Epoch: 5| Step: 7
Training loss: 0.7096498608589172
Validation loss: 2.202642192443212

Epoch: 5| Step: 8
Training loss: 1.7556034326553345
Validation loss: 2.18289123972257

Epoch: 5| Step: 9
Training loss: 1.2995823621749878
Validation loss: 2.2095140715440116

Epoch: 5| Step: 10
Training loss: 1.6800739765167236
Validation loss: 2.227929726243019

Epoch: 5| Step: 11
Training loss: 0.40572428703308105
Validation loss: 2.1945062627394996

Epoch: 437| Step: 0
Training loss: 1.3088274002075195
Validation loss: 2.159120033184687

Epoch: 5| Step: 1
Training loss: 1.186863660812378
Validation loss: 2.1696090449889502

Epoch: 5| Step: 2
Training loss: 1.8215783834457397
Validation loss: 2.1804149647553763

Epoch: 5| Step: 3
Training loss: 1.6751549243927002
Validation loss: 2.175339246789614

Epoch: 5| Step: 4
Training loss: 0.7421292066574097
Validation loss: 2.1395661383867264

Epoch: 5| Step: 5
Training loss: 0.7681926488876343
Validation loss: 2.1389320641756058

Epoch: 5| Step: 6
Training loss: 1.3369992971420288
Validation loss: 2.133802299698194

Epoch: 5| Step: 7
Training loss: 1.0003557205200195
Validation loss: 2.156319389740626

Epoch: 5| Step: 8
Training loss: 0.950428307056427
Validation loss: 2.121253008643786

Epoch: 5| Step: 9
Training loss: 1.1626132726669312
Validation loss: 2.1124523729085922

Epoch: 5| Step: 10
Training loss: 1.5029442310333252
Validation loss: 2.137443502744039

Epoch: 5| Step: 11
Training loss: 1.0624010562896729
Validation loss: 2.145589123169581

Epoch: 438| Step: 0
Training loss: 1.077797532081604
Validation loss: 2.122503156463305

Epoch: 5| Step: 1
Training loss: 1.281764030456543
Validation loss: 2.144348382949829

Epoch: 5| Step: 2
Training loss: 1.262546420097351
Validation loss: 2.100848063826561

Epoch: 5| Step: 3
Training loss: 1.561366319656372
Validation loss: 2.1425312956174216

Epoch: 5| Step: 4
Training loss: 1.2168409824371338
Validation loss: 2.1334438075621924

Epoch: 5| Step: 5
Training loss: 1.4314697980880737
Validation loss: 2.113408217827479

Epoch: 5| Step: 6
Training loss: 1.137131929397583
Validation loss: 2.1411254853010178

Epoch: 5| Step: 7
Training loss: 1.4885005950927734
Validation loss: 2.1276247849067054

Epoch: 5| Step: 8
Training loss: 0.8969257473945618
Validation loss: 2.1762171586354575

Epoch: 5| Step: 9
Training loss: 1.0494822263717651
Validation loss: 2.1126995533704758

Epoch: 5| Step: 10
Training loss: 0.7719224691390991
Validation loss: 2.158633361260096

Epoch: 5| Step: 11
Training loss: 0.8912287950515747
Validation loss: 2.145327478647232

Epoch: 439| Step: 0
Training loss: 1.0341771841049194
Validation loss: 2.1640720715125403

Epoch: 5| Step: 1
Training loss: 1.1506065130233765
Validation loss: 2.182146449883779

Epoch: 5| Step: 2
Training loss: 1.4905946254730225
Validation loss: 2.139397546648979

Epoch: 5| Step: 3
Training loss: 1.9506986141204834
Validation loss: 2.158246949315071

Epoch: 5| Step: 4
Training loss: 0.7483290433883667
Validation loss: 2.139403392871221

Epoch: 5| Step: 5
Training loss: 0.9467868804931641
Validation loss: 2.1950426399707794

Epoch: 5| Step: 6
Training loss: 1.0491610765457153
Validation loss: 2.192195067803065

Epoch: 5| Step: 7
Training loss: 1.3091930150985718
Validation loss: 2.181551863749822

Epoch: 5| Step: 8
Training loss: 0.9306979179382324
Validation loss: 2.1573552787303925

Epoch: 5| Step: 9
Training loss: 1.5538861751556396
Validation loss: 2.182202676932017

Epoch: 5| Step: 10
Training loss: 0.7668577432632446
Validation loss: 2.168086369832357

Epoch: 5| Step: 11
Training loss: 1.9854754209518433
Validation loss: 2.1550531536340714

Epoch: 440| Step: 0
Training loss: 1.1091762781143188
Validation loss: 2.1709293723106384

Epoch: 5| Step: 1
Training loss: 1.1440696716308594
Validation loss: 2.1649848222732544

Epoch: 5| Step: 2
Training loss: 1.1615087985992432
Validation loss: 2.1477606296539307

Epoch: 5| Step: 3
Training loss: 1.4016960859298706
Validation loss: 2.1578077723582587

Epoch: 5| Step: 4
Training loss: 1.1429424285888672
Validation loss: 2.1878847976525626

Epoch: 5| Step: 5
Training loss: 0.9980236291885376
Validation loss: 2.128695825735728

Epoch: 5| Step: 6
Training loss: 0.9886641502380371
Validation loss: 2.1070611675580344

Epoch: 5| Step: 7
Training loss: 1.3216907978057861
Validation loss: 2.1181326309839883

Epoch: 5| Step: 8
Training loss: 0.9780176281929016
Validation loss: 2.1262627989053726

Epoch: 5| Step: 9
Training loss: 1.4997074604034424
Validation loss: 2.129172613223394

Epoch: 5| Step: 10
Training loss: 1.0363914966583252
Validation loss: 2.1307150622208915

Epoch: 5| Step: 11
Training loss: 2.9884982109069824
Validation loss: 2.1375559916098914

Epoch: 441| Step: 0
Training loss: 1.3276864290237427
Validation loss: 2.118525813023249

Epoch: 5| Step: 1
Training loss: 1.470150113105774
Validation loss: 2.131301070253054

Epoch: 5| Step: 2
Training loss: 0.7305302619934082
Validation loss: 2.1206265091896057

Epoch: 5| Step: 3
Training loss: 0.8732134103775024
Validation loss: 2.136420746644338

Epoch: 5| Step: 4
Training loss: 1.2378509044647217
Validation loss: 2.0950007190306983

Epoch: 5| Step: 5
Training loss: 1.428675651550293
Validation loss: 2.1151035527388253

Epoch: 5| Step: 6
Training loss: 0.9644892811775208
Validation loss: 2.1178486545880637

Epoch: 5| Step: 7
Training loss: 1.1528940200805664
Validation loss: 2.1178725262482962

Epoch: 5| Step: 8
Training loss: 1.19158136844635
Validation loss: 2.1209005316098533

Epoch: 5| Step: 9
Training loss: 1.298468828201294
Validation loss: 2.117367764314016

Epoch: 5| Step: 10
Training loss: 1.0259807109832764
Validation loss: 2.15083384513855

Epoch: 5| Step: 11
Training loss: 1.7555292844772339
Validation loss: 2.1622486313184104

Epoch: 442| Step: 0
Training loss: 1.211188554763794
Validation loss: 2.182384635011355

Epoch: 5| Step: 1
Training loss: 0.8880985379219055
Validation loss: 2.175373653570811

Epoch: 5| Step: 2
Training loss: 1.6777875423431396
Validation loss: 2.1738891700903573

Epoch: 5| Step: 3
Training loss: 1.0775372982025146
Validation loss: 2.124364048242569

Epoch: 5| Step: 4
Training loss: 1.084991455078125
Validation loss: 2.1712252696355185

Epoch: 5| Step: 5
Training loss: 1.2816513776779175
Validation loss: 2.1946925818920135

Epoch: 5| Step: 6
Training loss: 1.6682624816894531
Validation loss: 2.14886004726092

Epoch: 5| Step: 7
Training loss: 0.9475793838500977
Validation loss: 2.1831258833408356

Epoch: 5| Step: 8
Training loss: 0.9368740916252136
Validation loss: 2.1612539291381836

Epoch: 5| Step: 9
Training loss: 1.4533456563949585
Validation loss: 2.1600551853577294

Epoch: 5| Step: 10
Training loss: 1.1879663467407227
Validation loss: 2.163722778360049

Epoch: 5| Step: 11
Training loss: 0.3592396378517151
Validation loss: 2.2226508210102716

Epoch: 443| Step: 0
Training loss: 1.1373565196990967
Validation loss: 2.225816234946251

Epoch: 5| Step: 1
Training loss: 0.9873758554458618
Validation loss: 2.2155840347210565

Epoch: 5| Step: 2
Training loss: 0.8873079419136047
Validation loss: 2.2046889712413154

Epoch: 5| Step: 3
Training loss: 1.5494707822799683
Validation loss: 2.2080940306186676

Epoch: 5| Step: 4
Training loss: 1.0238029956817627
Validation loss: 2.19332363208135

Epoch: 5| Step: 5
Training loss: 1.5467301607131958
Validation loss: 2.1931476394335427

Epoch: 5| Step: 6
Training loss: 1.2134158611297607
Validation loss: 2.240333065390587

Epoch: 5| Step: 7
Training loss: 0.916674792766571
Validation loss: 2.275241181254387

Epoch: 5| Step: 8
Training loss: 0.6244837641716003
Validation loss: 2.2499778171380362

Epoch: 5| Step: 9
Training loss: 0.8037284016609192
Validation loss: 2.2427014956871667

Epoch: 5| Step: 10
Training loss: 2.3777880668640137
Validation loss: 2.23325078189373

Epoch: 5| Step: 11
Training loss: 1.7245482206344604
Validation loss: 2.2005466719468436

Epoch: 444| Step: 0
Training loss: 0.8860037922859192
Validation loss: 2.192160055041313

Epoch: 5| Step: 1
Training loss: 1.2916780710220337
Validation loss: 2.2404933820168176

Epoch: 5| Step: 2
Training loss: 0.9033982157707214
Validation loss: 2.1829299132029214

Epoch: 5| Step: 3
Training loss: 0.6524204611778259
Validation loss: 2.2156266421079636

Epoch: 5| Step: 4
Training loss: 1.9895079135894775
Validation loss: 2.187032158176104

Epoch: 5| Step: 5
Training loss: 0.8192302584648132
Validation loss: 2.204199120402336

Epoch: 5| Step: 6
Training loss: 1.173205018043518
Validation loss: 2.2267770767211914

Epoch: 5| Step: 7
Training loss: 0.7629790306091309
Validation loss: 2.260114754239718

Epoch: 5| Step: 8
Training loss: 1.9546477794647217
Validation loss: 2.225781242052714

Epoch: 5| Step: 9
Training loss: 1.1361634731292725
Validation loss: 2.2336846441030502

Epoch: 5| Step: 10
Training loss: 1.7009872198104858
Validation loss: 2.157000328103701

Epoch: 5| Step: 11
Training loss: 0.7301216721534729
Validation loss: 2.189710626999537

Epoch: 445| Step: 0
Training loss: 0.9873374104499817
Validation loss: 2.1887506941954293

Epoch: 5| Step: 1
Training loss: 1.1302459239959717
Validation loss: 2.214807758728663

Epoch: 5| Step: 2
Training loss: 0.9881526231765747
Validation loss: 2.206772968173027

Epoch: 5| Step: 3
Training loss: 0.5983238816261292
Validation loss: 2.166352470715841

Epoch: 5| Step: 4
Training loss: 1.4331445693969727
Validation loss: 2.2171533902486167

Epoch: 5| Step: 5
Training loss: 1.4878228902816772
Validation loss: 2.1470304131507874

Epoch: 5| Step: 6
Training loss: 1.2281520366668701
Validation loss: 2.13977313041687

Epoch: 5| Step: 7
Training loss: 1.0648497343063354
Validation loss: 2.1548277686039605

Epoch: 5| Step: 8
Training loss: 1.3856070041656494
Validation loss: 2.1272510985533395

Epoch: 5| Step: 9
Training loss: 1.606288194656372
Validation loss: 2.156486839056015

Epoch: 5| Step: 10
Training loss: 0.9525888562202454
Validation loss: 2.1594560543696084

Epoch: 5| Step: 11
Training loss: 1.6174798011779785
Validation loss: 2.1778278052806854

Epoch: 446| Step: 0
Training loss: 0.783161997795105
Validation loss: 2.111552690466245

Epoch: 5| Step: 1
Training loss: 0.7863427996635437
Validation loss: 2.104274188478788

Epoch: 5| Step: 2
Training loss: 1.505027174949646
Validation loss: 2.0885436981916428

Epoch: 5| Step: 3
Training loss: 0.769862174987793
Validation loss: 2.120414932568868

Epoch: 5| Step: 4
Training loss: 1.38429856300354
Validation loss: 2.140515446662903

Epoch: 5| Step: 5
Training loss: 1.4432525634765625
Validation loss: 2.1242615580558777

Epoch: 5| Step: 6
Training loss: 1.0177839994430542
Validation loss: 2.133292704820633

Epoch: 5| Step: 7
Training loss: 0.9765470623970032
Validation loss: 2.166909947991371

Epoch: 5| Step: 8
Training loss: 1.0305358171463013
Validation loss: 2.1201377312342324

Epoch: 5| Step: 9
Training loss: 1.6273329257965088
Validation loss: 2.1483070800701776

Epoch: 5| Step: 10
Training loss: 1.5132935047149658
Validation loss: 2.1446687380472818

Epoch: 5| Step: 11
Training loss: 2.3792147636413574
Validation loss: 2.156758596499761

Epoch: 447| Step: 0
Training loss: 0.8459807634353638
Validation loss: 2.2115770230690637

Epoch: 5| Step: 1
Training loss: 1.16831636428833
Validation loss: 2.2248517870903015

Epoch: 5| Step: 2
Training loss: 1.8588905334472656
Validation loss: 2.269624630610148

Epoch: 5| Step: 3
Training loss: 1.2882418632507324
Validation loss: 2.252524122595787

Epoch: 5| Step: 4
Training loss: 1.409458875656128
Validation loss: 2.227182015776634

Epoch: 5| Step: 5
Training loss: 0.955335795879364
Validation loss: 2.234296997388204

Epoch: 5| Step: 6
Training loss: 1.4354571104049683
Validation loss: 2.147083585460981

Epoch: 5| Step: 7
Training loss: 1.0922603607177734
Validation loss: 2.1915588130553565

Epoch: 5| Step: 8
Training loss: 1.940442681312561
Validation loss: 2.1602209359407425

Epoch: 5| Step: 9
Training loss: 0.9289321899414062
Validation loss: 2.165919467806816

Epoch: 5| Step: 10
Training loss: 1.0121371746063232
Validation loss: 2.165289198358854

Epoch: 5| Step: 11
Training loss: 0.8883765935897827
Validation loss: 2.184334014852842

Epoch: 448| Step: 0
Training loss: 1.1661162376403809
Validation loss: 2.205543781320254

Epoch: 5| Step: 1
Training loss: 1.7921327352523804
Validation loss: 2.1439762512842813

Epoch: 5| Step: 2
Training loss: 0.8863433003425598
Validation loss: 2.1628985504309335

Epoch: 5| Step: 3
Training loss: 1.0489052534103394
Validation loss: 2.126622279485067

Epoch: 5| Step: 4
Training loss: 1.094059944152832
Validation loss: 2.148674185077349

Epoch: 5| Step: 5
Training loss: 1.7973308563232422
Validation loss: 2.152609591682752

Epoch: 5| Step: 6
Training loss: 1.3686860799789429
Validation loss: 2.2040513207515082

Epoch: 5| Step: 7
Training loss: 0.8229674100875854
Validation loss: 2.1752648850282035

Epoch: 5| Step: 8
Training loss: 0.9278577566146851
Validation loss: 2.149941255648931

Epoch: 5| Step: 9
Training loss: 1.2295129299163818
Validation loss: 2.153131748239199

Epoch: 5| Step: 10
Training loss: 1.2883455753326416
Validation loss: 2.1360248178243637

Epoch: 5| Step: 11
Training loss: 0.19098231196403503
Validation loss: 2.115557094415029

Epoch: 449| Step: 0
Training loss: 1.2818233966827393
Validation loss: 2.0668068677186966

Epoch: 5| Step: 1
Training loss: 1.6614930629730225
Validation loss: 2.111671879887581

Epoch: 5| Step: 2
Training loss: 1.335447072982788
Validation loss: 2.0886116524537406

Epoch: 5| Step: 3
Training loss: 1.5930918455123901
Validation loss: 2.0793326447407403

Epoch: 5| Step: 4
Training loss: 0.5381789207458496
Validation loss: 2.129856730500857

Epoch: 5| Step: 5
Training loss: 1.017519235610962
Validation loss: 2.1363500505685806

Epoch: 5| Step: 6
Training loss: 1.6827306747436523
Validation loss: 2.141320059696833

Epoch: 5| Step: 7
Training loss: 1.4366676807403564
Validation loss: 2.099549492200216

Epoch: 5| Step: 8
Training loss: 0.7689812183380127
Validation loss: 2.0826982855796814

Epoch: 5| Step: 9
Training loss: 0.7211810946464539
Validation loss: 2.098339701692263

Epoch: 5| Step: 10
Training loss: 0.9590524435043335
Validation loss: 2.1421892096598945

Epoch: 5| Step: 11
Training loss: 0.49785900115966797
Validation loss: 2.1175327400366464

Epoch: 450| Step: 0
Training loss: 1.176190972328186
Validation loss: 2.1560825953880944

Epoch: 5| Step: 1
Training loss: 0.962304413318634
Validation loss: 2.134533405303955

Epoch: 5| Step: 2
Training loss: 1.5406270027160645
Validation loss: 2.1479178170363107

Epoch: 5| Step: 3
Training loss: 0.8233803510665894
Validation loss: 2.170137350757917

Epoch: 5| Step: 4
Training loss: 1.3807849884033203
Validation loss: 2.2138353288173676

Epoch: 5| Step: 5
Training loss: 1.4882835149765015
Validation loss: 2.192148894071579

Epoch: 5| Step: 6
Training loss: 1.4488205909729004
Validation loss: 2.3129091958204904

Epoch: 5| Step: 7
Training loss: 1.4071557521820068
Validation loss: 2.2472032407919564

Epoch: 5| Step: 8
Training loss: 1.1294177770614624
Validation loss: 2.271485358476639

Epoch: 5| Step: 9
Training loss: 1.3146214485168457
Validation loss: 2.206196963787079

Epoch: 5| Step: 10
Training loss: 1.5845564603805542
Validation loss: 2.185325155655543

Epoch: 5| Step: 11
Training loss: 0.44345882534980774
Validation loss: 2.209033782283465

Testing loss: 2.135568987551353
