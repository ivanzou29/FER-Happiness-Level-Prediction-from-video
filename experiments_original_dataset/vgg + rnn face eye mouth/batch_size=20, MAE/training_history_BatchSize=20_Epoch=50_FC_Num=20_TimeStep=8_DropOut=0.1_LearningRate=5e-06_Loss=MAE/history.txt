Epoch: 1| Step: 0
Training loss: 6.122961521148682
Validation loss: 5.343943476676941

Epoch: 5| Step: 1
Training loss: 6.47516393661499
Validation loss: 5.341507613658905

Epoch: 5| Step: 2
Training loss: 5.908186912536621
Validation loss: 5.33930375178655

Epoch: 5| Step: 3
Training loss: 5.375985145568848
Validation loss: 5.337286353111267

Epoch: 5| Step: 4
Training loss: 5.158982753753662
Validation loss: 5.335246682167053

Epoch: 5| Step: 5
Training loss: 5.412039756774902
Validation loss: 5.333355565865834

Epoch: 5| Step: 6
Training loss: 5.9855780601501465
Validation loss: 5.331558446089427

Epoch: 5| Step: 7
Training loss: 4.078819751739502
Validation loss: 5.329736948013306

Epoch: 5| Step: 8
Training loss: 4.8160505294799805
Validation loss: 5.327851275602977

Epoch: 5| Step: 9
Training loss: 5.0138983726501465
Validation loss: 5.325954556465149

Epoch: 5| Step: 10
Training loss: 5.476796627044678
Validation loss: 5.323949893315633

Epoch: 5| Step: 11
Training loss: 3.4141156673431396
Validation loss: 5.321893393993378

Epoch: 2| Step: 0
Training loss: 5.606386184692383
Validation loss: 5.31974317630132

Epoch: 5| Step: 1
Training loss: 5.007699966430664
Validation loss: 5.317590872446696

Epoch: 5| Step: 2
Training loss: 5.268714904785156
Validation loss: 5.3152620395024615

Epoch: 5| Step: 3
Training loss: 6.073983192443848
Validation loss: 5.31287407875061

Epoch: 5| Step: 4
Training loss: 5.164250373840332
Validation loss: 5.310172239939372

Epoch: 5| Step: 5
Training loss: 4.1951704025268555
Validation loss: 5.307485679785411

Epoch: 5| Step: 6
Training loss: 5.829679012298584
Validation loss: 5.304626901944478

Epoch: 5| Step: 7
Training loss: 5.554044246673584
Validation loss: 5.301625569661458

Epoch: 5| Step: 8
Training loss: 5.253438472747803
Validation loss: 5.298361500104268

Epoch: 5| Step: 9
Training loss: 5.855856418609619
Validation loss: 5.295003414154053

Epoch: 5| Step: 10
Training loss: 5.253078937530518
Validation loss: 5.291526556015015

Epoch: 5| Step: 11
Training loss: 5.704622268676758
Validation loss: 5.2876198291778564

Epoch: 3| Step: 0
Training loss: 5.5730133056640625
Validation loss: 5.283715824286143

Epoch: 5| Step: 1
Training loss: 4.8171539306640625
Validation loss: 5.279678722222646

Epoch: 5| Step: 2
Training loss: 6.099571228027344
Validation loss: 5.275215407212575

Epoch: 5| Step: 3
Training loss: 5.307736873626709
Validation loss: 5.270599067211151

Epoch: 5| Step: 4
Training loss: 5.988377571105957
Validation loss: 5.265875319639842

Epoch: 5| Step: 5
Training loss: 6.07525634765625
Validation loss: 5.260942816734314

Epoch: 5| Step: 6
Training loss: 4.500899314880371
Validation loss: 5.255489706993103

Epoch: 5| Step: 7
Training loss: 4.8437886238098145
Validation loss: 5.249946375687917

Epoch: 5| Step: 8
Training loss: 5.495633125305176
Validation loss: 5.244175652662913

Epoch: 5| Step: 9
Training loss: 5.309683799743652
Validation loss: 5.238439400990804

Epoch: 5| Step: 10
Training loss: 4.6754350662231445
Validation loss: 5.232318937778473

Epoch: 5| Step: 11
Training loss: 4.943390369415283
Validation loss: 5.2259441614151

Epoch: 4| Step: 0
Training loss: 4.304080963134766
Validation loss: 5.219175338745117

Epoch: 5| Step: 1
Training loss: 4.187929630279541
Validation loss: 5.212533672650655

Epoch: 5| Step: 2
Training loss: 6.406378269195557
Validation loss: 5.205732802549998

Epoch: 5| Step: 3
Training loss: 6.066800117492676
Validation loss: 5.198842108249664

Epoch: 5| Step: 4
Training loss: 4.668874740600586
Validation loss: 5.191486855347951

Epoch: 5| Step: 5
Training loss: 6.17496395111084
Validation loss: 5.184135099252065

Epoch: 5| Step: 6
Training loss: 6.739930629730225
Validation loss: 5.1766693989435835

Epoch: 5| Step: 7
Training loss: 4.382289886474609
Validation loss: 5.168754895528157

Epoch: 5| Step: 8
Training loss: 6.095831394195557
Validation loss: 5.16072678565979

Epoch: 5| Step: 9
Training loss: 4.277790069580078
Validation loss: 5.15254020690918

Epoch: 5| Step: 10
Training loss: 5.052624702453613
Validation loss: 5.1445144812266035

Epoch: 5| Step: 11
Training loss: 2.3927700519561768
Validation loss: 5.135873595873515

Epoch: 5| Step: 0
Training loss: 5.245518684387207
Validation loss: 5.126955330371857

Epoch: 5| Step: 1
Training loss: 6.110918998718262
Validation loss: 5.1182352503140764

Epoch: 5| Step: 2
Training loss: 5.225750923156738
Validation loss: 5.1086675723393755

Epoch: 5| Step: 3
Training loss: 5.237082004547119
Validation loss: 5.099334160486857

Epoch: 5| Step: 4
Training loss: 4.8573760986328125
Validation loss: 5.089755515257518

Epoch: 5| Step: 5
Training loss: 4.544177055358887
Validation loss: 5.079641203085582

Epoch: 5| Step: 6
Training loss: 5.608063697814941
Validation loss: 5.069511334101359

Epoch: 5| Step: 7
Training loss: 5.731353759765625
Validation loss: 5.059068083763123

Epoch: 5| Step: 8
Training loss: 4.652852535247803
Validation loss: 5.048436065514882

Epoch: 5| Step: 9
Training loss: 4.6127519607543945
Validation loss: 5.037559350331624

Epoch: 5| Step: 10
Training loss: 5.227053165435791
Validation loss: 5.026605486869812

Epoch: 5| Step: 11
Training loss: 3.301126718521118
Validation loss: 5.01569143931071

Epoch: 6| Step: 0
Training loss: 5.493899345397949
Validation loss: 5.004494200150172

Epoch: 5| Step: 1
Training loss: 5.241452217102051
Validation loss: 4.9937005539735155

Epoch: 5| Step: 2
Training loss: 5.200392246246338
Validation loss: 4.983032782872518

Epoch: 5| Step: 3
Training loss: 4.298892021179199
Validation loss: 4.972491463025411

Epoch: 5| Step: 4
Training loss: 5.4380950927734375
Validation loss: 4.962031185626984

Epoch: 5| Step: 5
Training loss: 4.875962734222412
Validation loss: 4.9519837101300554

Epoch: 5| Step: 6
Training loss: 4.799953460693359
Validation loss: 4.94212539990743

Epoch: 5| Step: 7
Training loss: 4.902298927307129
Validation loss: 4.932438174883525

Epoch: 5| Step: 8
Training loss: 4.615924835205078
Validation loss: 4.923075457413991

Epoch: 5| Step: 9
Training loss: 5.861109733581543
Validation loss: 4.914328257242839

Epoch: 5| Step: 10
Training loss: 5.071272850036621
Validation loss: 4.905728280544281

Epoch: 5| Step: 11
Training loss: 2.974313497543335
Validation loss: 4.897785484790802

Epoch: 7| Step: 0
Training loss: 4.803689956665039
Validation loss: 4.889392733573914

Epoch: 5| Step: 1
Training loss: 4.632066249847412
Validation loss: 4.881726304690043

Epoch: 5| Step: 2
Training loss: 4.28475284576416
Validation loss: 4.874106407165527

Epoch: 5| Step: 3
Training loss: 4.2655134201049805
Validation loss: 4.866786519686381

Epoch: 5| Step: 4
Training loss: 4.641679286956787
Validation loss: 4.85928891102473

Epoch: 5| Step: 5
Training loss: 4.864949703216553
Validation loss: 4.852470179398854

Epoch: 5| Step: 6
Training loss: 4.9502692222595215
Validation loss: 4.845342715581258

Epoch: 5| Step: 7
Training loss: 5.146007061004639
Validation loss: 4.838825325171153

Epoch: 5| Step: 8
Training loss: 5.812082290649414
Validation loss: 4.831838031609853

Epoch: 5| Step: 9
Training loss: 5.39919900894165
Validation loss: 4.824897547562917

Epoch: 5| Step: 10
Training loss: 5.15415096282959
Validation loss: 4.818484346071879

Epoch: 5| Step: 11
Training loss: 6.7979736328125
Validation loss: 4.812287012736003

Epoch: 8| Step: 0
Training loss: 4.166993618011475
Validation loss: 4.805901189645131

Epoch: 5| Step: 1
Training loss: 5.069972515106201
Validation loss: 4.799716293811798

Epoch: 5| Step: 2
Training loss: 5.446916103363037
Validation loss: 4.79353513320287

Epoch: 5| Step: 3
Training loss: 4.616892337799072
Validation loss: 4.787226378917694

Epoch: 5| Step: 4
Training loss: 4.18734073638916
Validation loss: 4.781711300214131

Epoch: 5| Step: 5
Training loss: 4.887697219848633
Validation loss: 4.775387545426686

Epoch: 5| Step: 6
Training loss: 4.763815402984619
Validation loss: 4.76968381802241

Epoch: 5| Step: 7
Training loss: 4.087360858917236
Validation loss: 4.76359236240387

Epoch: 5| Step: 8
Training loss: 4.593411922454834
Validation loss: 4.757993241151174

Epoch: 5| Step: 9
Training loss: 5.777875900268555
Validation loss: 4.7520246009031935

Epoch: 5| Step: 10
Training loss: 5.748666286468506
Validation loss: 4.746074557304382

Epoch: 5| Step: 11
Training loss: 5.719809055328369
Validation loss: 4.740161637465159

Epoch: 9| Step: 0
Training loss: 5.1062421798706055
Validation loss: 4.734104077021281

Epoch: 5| Step: 1
Training loss: 4.319912433624268
Validation loss: 4.7281065583229065

Epoch: 5| Step: 2
Training loss: 5.388806343078613
Validation loss: 4.7220174968242645

Epoch: 5| Step: 3
Training loss: 4.501901149749756
Validation loss: 4.715930799643199

Epoch: 5| Step: 4
Training loss: 5.051926612854004
Validation loss: 4.7096161643664045

Epoch: 5| Step: 5
Training loss: 5.459132194519043
Validation loss: 4.703732411066691

Epoch: 5| Step: 6
Training loss: 4.681638240814209
Validation loss: 4.6967997550964355

Epoch: 5| Step: 7
Training loss: 4.69281005859375
Validation loss: 4.690574198961258

Epoch: 5| Step: 8
Training loss: 4.166358947753906
Validation loss: 4.683939655621846

Epoch: 5| Step: 9
Training loss: 4.5366997718811035
Validation loss: 4.677473545074463

Epoch: 5| Step: 10
Training loss: 4.644777774810791
Validation loss: 4.670287152131398

Epoch: 5| Step: 11
Training loss: 5.897593021392822
Validation loss: 4.664045095443726

Epoch: 10| Step: 0
Training loss: 3.771876573562622
Validation loss: 4.657946785291036

Epoch: 5| Step: 1
Training loss: 4.391748905181885
Validation loss: 4.651461919148763

Epoch: 5| Step: 2
Training loss: 5.37613582611084
Validation loss: 4.644794841607411

Epoch: 5| Step: 3
Training loss: 4.095946311950684
Validation loss: 4.638637314240138

Epoch: 5| Step: 4
Training loss: 5.066292762756348
Validation loss: 4.631736397743225

Epoch: 5| Step: 5
Training loss: 5.51278829574585
Validation loss: 4.624401390552521

Epoch: 5| Step: 6
Training loss: 4.731356143951416
Validation loss: 4.617347518603007

Epoch: 5| Step: 7
Training loss: 4.805771827697754
Validation loss: 4.610385298728943

Epoch: 5| Step: 8
Training loss: 4.734445095062256
Validation loss: 4.602443377176921

Epoch: 5| Step: 9
Training loss: 4.553382873535156
Validation loss: 4.59473733107249

Epoch: 5| Step: 10
Training loss: 4.46414852142334
Validation loss: 4.586855888366699

Epoch: 5| Step: 11
Training loss: 6.858386516571045
Validation loss: 4.579846739768982

Epoch: 11| Step: 0
Training loss: 4.322556495666504
Validation loss: 4.571763515472412

Epoch: 5| Step: 1
Training loss: 5.041731834411621
Validation loss: 4.563952724138896

Epoch: 5| Step: 2
Training loss: 4.607406139373779
Validation loss: 4.556401838858922

Epoch: 5| Step: 3
Training loss: 4.210251808166504
Validation loss: 4.54922080039978

Epoch: 5| Step: 4
Training loss: 5.294281959533691
Validation loss: 4.541542808214824

Epoch: 5| Step: 5
Training loss: 3.5097644329071045
Validation loss: 4.534797747929891

Epoch: 5| Step: 6
Training loss: 5.7241106033325195
Validation loss: 4.527832080920537

Epoch: 5| Step: 7
Training loss: 5.267355918884277
Validation loss: 4.5208293199539185

Epoch: 5| Step: 8
Training loss: 4.117772102355957
Validation loss: 4.513279189666112

Epoch: 5| Step: 9
Training loss: 4.251054286956787
Validation loss: 4.506127029657364

Epoch: 5| Step: 10
Training loss: 4.704363822937012
Validation loss: 4.498875816663106

Epoch: 5| Step: 11
Training loss: 4.381572723388672
Validation loss: 4.491886953512828

Epoch: 12| Step: 0
Training loss: 4.977288246154785
Validation loss: 4.484692573547363

Epoch: 5| Step: 1
Training loss: 5.014223575592041
Validation loss: 4.476777911186218

Epoch: 5| Step: 2
Training loss: 4.950665473937988
Validation loss: 4.4696749945481615

Epoch: 5| Step: 3
Training loss: 4.511740684509277
Validation loss: 4.461968868970871

Epoch: 5| Step: 4
Training loss: 5.070544242858887
Validation loss: 4.454551428556442

Epoch: 5| Step: 5
Training loss: 3.457256317138672
Validation loss: 4.447588344415029

Epoch: 5| Step: 6
Training loss: 4.435704708099365
Validation loss: 4.439612040917079

Epoch: 5| Step: 7
Training loss: 5.150063514709473
Validation loss: 4.431930124759674

Epoch: 5| Step: 8
Training loss: 4.634016990661621
Validation loss: 4.424907664457957

Epoch: 5| Step: 9
Training loss: 4.116336345672607
Validation loss: 4.418393790721893

Epoch: 5| Step: 10
Training loss: 4.009800910949707
Validation loss: 4.411449432373047

Epoch: 5| Step: 11
Training loss: 3.6415114402770996
Validation loss: 4.404329101244609

Epoch: 13| Step: 0
Training loss: 4.469169616699219
Validation loss: 4.397516111532847

Epoch: 5| Step: 1
Training loss: 4.221811771392822
Validation loss: 4.389876296122869

Epoch: 5| Step: 2
Training loss: 4.173182010650635
Validation loss: 4.383833676576614

Epoch: 5| Step: 3
Training loss: 4.614969253540039
Validation loss: 4.376167953014374

Epoch: 5| Step: 4
Training loss: 4.370938301086426
Validation loss: 4.369458754857381

Epoch: 5| Step: 5
Training loss: 4.927746295928955
Validation loss: 4.362475564082463

Epoch: 5| Step: 6
Training loss: 4.131762981414795
Validation loss: 4.355690519014995

Epoch: 5| Step: 7
Training loss: 3.926501512527466
Validation loss: 4.349006175994873

Epoch: 5| Step: 8
Training loss: 4.122210502624512
Validation loss: 4.341185241937637

Epoch: 5| Step: 9
Training loss: 5.148102283477783
Validation loss: 4.334600895643234

Epoch: 5| Step: 10
Training loss: 4.931097984313965
Validation loss: 4.328032354513804

Epoch: 5| Step: 11
Training loss: 5.718160629272461
Validation loss: 4.320432017246882

Epoch: 14| Step: 0
Training loss: 4.925617694854736
Validation loss: 4.315369158983231

Epoch: 5| Step: 1
Training loss: 5.313229084014893
Validation loss: 4.308852841456731

Epoch: 5| Step: 2
Training loss: 4.136569023132324
Validation loss: 4.301963080962499

Epoch: 5| Step: 3
Training loss: 4.233431816101074
Validation loss: 4.294667373100917

Epoch: 5| Step: 4
Training loss: 3.290292739868164
Validation loss: 4.288204948107402

Epoch: 5| Step: 5
Training loss: 5.057141304016113
Validation loss: 4.283332447210948

Epoch: 5| Step: 6
Training loss: 4.1794023513793945
Validation loss: 4.2751146256923676

Epoch: 5| Step: 7
Training loss: 4.11737585067749
Validation loss: 4.269498705863953

Epoch: 5| Step: 8
Training loss: 3.7038211822509766
Validation loss: 4.262486040592194

Epoch: 5| Step: 9
Training loss: 4.635175704956055
Validation loss: 4.256228407224019

Epoch: 5| Step: 10
Training loss: 4.569119930267334
Validation loss: 4.249523043632507

Epoch: 5| Step: 11
Training loss: 6.024993896484375
Validation loss: 4.243027925491333

Epoch: 15| Step: 0
Training loss: 3.3263118267059326
Validation loss: 4.2365041474501295

Epoch: 5| Step: 1
Training loss: 3.6584486961364746
Validation loss: 4.23009181022644

Epoch: 5| Step: 2
Training loss: 5.282601356506348
Validation loss: 4.223584373792012

Epoch: 5| Step: 3
Training loss: 5.033697605133057
Validation loss: 4.217872768640518

Epoch: 5| Step: 4
Training loss: 3.9153811931610107
Validation loss: 4.211244285106659

Epoch: 5| Step: 5
Training loss: 4.704742431640625
Validation loss: 4.2057086030642195

Epoch: 5| Step: 6
Training loss: 3.4367098808288574
Validation loss: 4.198559890190761

Epoch: 5| Step: 7
Training loss: 4.289175987243652
Validation loss: 4.193301310141881

Epoch: 5| Step: 8
Training loss: 4.6486592292785645
Validation loss: 4.1858881413936615

Epoch: 5| Step: 9
Training loss: 4.499205589294434
Validation loss: 4.180527816216151

Epoch: 5| Step: 10
Training loss: 5.088071823120117
Validation loss: 4.1753359735012054

Epoch: 5| Step: 11
Training loss: 3.4440391063690186
Validation loss: 4.168815225362778

Epoch: 16| Step: 0
Training loss: 4.0791778564453125
Validation loss: 4.162529398997624

Epoch: 5| Step: 1
Training loss: 4.233241081237793
Validation loss: 4.15698829293251

Epoch: 5| Step: 2
Training loss: 3.9802474975585938
Validation loss: 4.1507628460725146

Epoch: 5| Step: 3
Training loss: 3.852532148361206
Validation loss: 4.144638498624166

Epoch: 5| Step: 4
Training loss: 4.9177751541137695
Validation loss: 4.138278742631276

Epoch: 5| Step: 5
Training loss: 4.414355278015137
Validation loss: 4.132157226403554

Epoch: 5| Step: 6
Training loss: 4.912802696228027
Validation loss: 4.126816034317017

Epoch: 5| Step: 7
Training loss: 4.980593681335449
Validation loss: 4.121546079715093

Epoch: 5| Step: 8
Training loss: 4.17363977432251
Validation loss: 4.115208009878795

Epoch: 5| Step: 9
Training loss: 3.3212592601776123
Validation loss: 4.109630187352498

Epoch: 5| Step: 10
Training loss: 4.78851842880249
Validation loss: 4.104760676622391

Epoch: 5| Step: 11
Training loss: 0.9728966951370239
Validation loss: 4.098364690939586

Epoch: 17| Step: 0
Training loss: 4.435122489929199
Validation loss: 4.093409836292267

Epoch: 5| Step: 1
Training loss: 3.7409236431121826
Validation loss: 4.088370124499003

Epoch: 5| Step: 2
Training loss: 3.7050747871398926
Validation loss: 4.082314491271973

Epoch: 5| Step: 3
Training loss: 3.5067782402038574
Validation loss: 4.076949993769328

Epoch: 5| Step: 4
Training loss: 5.3368239402771
Validation loss: 4.07197963198026

Epoch: 5| Step: 5
Training loss: 4.932593822479248
Validation loss: 4.067461838324864

Epoch: 5| Step: 6
Training loss: 4.477057933807373
Validation loss: 4.061591575543086

Epoch: 5| Step: 7
Training loss: 4.687364101409912
Validation loss: 4.056585530440013

Epoch: 5| Step: 8
Training loss: 3.800891876220703
Validation loss: 4.051011621952057

Epoch: 5| Step: 9
Training loss: 3.787219285964966
Validation loss: 4.045482754707336

Epoch: 5| Step: 10
Training loss: 3.934081554412842
Validation loss: 4.0406253933906555

Epoch: 5| Step: 11
Training loss: 4.00649881362915
Validation loss: 4.036119103431702

Epoch: 18| Step: 0
Training loss: 3.4858860969543457
Validation loss: 4.030846456686656

Epoch: 5| Step: 1
Training loss: 3.7756659984588623
Validation loss: 4.0264647006988525

Epoch: 5| Step: 2
Training loss: 4.979639053344727
Validation loss: 4.020439515511195

Epoch: 5| Step: 3
Training loss: 4.248371601104736
Validation loss: 4.014748881260554

Epoch: 5| Step: 4
Training loss: 4.1790056228637695
Validation loss: 4.009663979212443

Epoch: 5| Step: 5
Training loss: 4.657753944396973
Validation loss: 4.003898620605469

Epoch: 5| Step: 6
Training loss: 3.6680908203125
Validation loss: 3.9992295304934182

Epoch: 5| Step: 7
Training loss: 4.519392490386963
Validation loss: 3.993307948112488

Epoch: 5| Step: 8
Training loss: 4.184891700744629
Validation loss: 3.9897136986255646

Epoch: 5| Step: 9
Training loss: 3.758633852005005
Validation loss: 3.9819805721441903

Epoch: 5| Step: 10
Training loss: 4.093623161315918
Validation loss: 3.976478556791941

Epoch: 5| Step: 11
Training loss: 4.636781692504883
Validation loss: 3.9722819725672402

Epoch: 19| Step: 0
Training loss: 4.185619354248047
Validation loss: 3.967078516880671

Epoch: 5| Step: 1
Training loss: 4.006166934967041
Validation loss: 3.9608424305915833

Epoch: 5| Step: 2
Training loss: 3.975062608718872
Validation loss: 3.9565230508645377

Epoch: 5| Step: 3
Training loss: 4.429657459259033
Validation loss: 3.9506743351618447

Epoch: 5| Step: 4
Training loss: 2.472937822341919
Validation loss: 3.9441723922888436

Epoch: 5| Step: 5
Training loss: 4.338465213775635
Validation loss: 3.9397921661535897

Epoch: 5| Step: 6
Training loss: 4.459834098815918
Validation loss: 3.933112531900406

Epoch: 5| Step: 7
Training loss: 4.641737937927246
Validation loss: 3.928117742141088

Epoch: 5| Step: 8
Training loss: 3.3238494396209717
Validation loss: 3.9227011998494468

Epoch: 5| Step: 9
Training loss: 4.163328647613525
Validation loss: 3.917546053727468

Epoch: 5| Step: 10
Training loss: 4.891767978668213
Validation loss: 3.9119349817434945

Epoch: 5| Step: 11
Training loss: 4.4546380043029785
Validation loss: 3.906154284874598

Epoch: 20| Step: 0
Training loss: 3.4027581214904785
Validation loss: 3.901955395936966

Epoch: 5| Step: 1
Training loss: 3.800286054611206
Validation loss: 3.896624426047007

Epoch: 5| Step: 2
Training loss: 4.464873313903809
Validation loss: 3.8916301131248474

Epoch: 5| Step: 3
Training loss: 4.819931983947754
Validation loss: 3.8864622016747794

Epoch: 5| Step: 4
Training loss: 3.603559970855713
Validation loss: 3.88213257988294

Epoch: 5| Step: 5
Training loss: 3.572333574295044
Validation loss: 3.8776959478855133

Epoch: 5| Step: 6
Training loss: 4.154627323150635
Validation loss: 3.871658593416214

Epoch: 5| Step: 7
Training loss: 3.927687168121338
Validation loss: 3.8665213088194528

Epoch: 5| Step: 8
Training loss: 4.906447410583496
Validation loss: 3.8616583247979483

Epoch: 5| Step: 9
Training loss: 3.9216468334198
Validation loss: 3.8566019336382547

Epoch: 5| Step: 10
Training loss: 3.437727451324463
Validation loss: 3.851454436779022

Epoch: 5| Step: 11
Training loss: 5.4942803382873535
Validation loss: 3.8466119468212128

Epoch: 21| Step: 0
Training loss: 2.7685399055480957
Validation loss: 3.842392315467199

Epoch: 5| Step: 1
Training loss: 3.9958605766296387
Validation loss: 3.8375205397605896

Epoch: 5| Step: 2
Training loss: 3.598377227783203
Validation loss: 3.8343449234962463

Epoch: 5| Step: 3
Training loss: 3.4026646614074707
Validation loss: 3.8293471932411194

Epoch: 5| Step: 4
Training loss: 4.684503078460693
Validation loss: 3.824486553668976

Epoch: 5| Step: 5
Training loss: 3.974086046218872
Validation loss: 3.8192759255568185

Epoch: 5| Step: 6
Training loss: 5.787379264831543
Validation loss: 3.8140466709931693

Epoch: 5| Step: 7
Training loss: 3.692399501800537
Validation loss: 3.8089552919069924

Epoch: 5| Step: 8
Training loss: 3.953425884246826
Validation loss: 3.8034487068653107

Epoch: 5| Step: 9
Training loss: 4.905918598175049
Validation loss: 3.799214859803518

Epoch: 5| Step: 10
Training loss: 3.0606653690338135
Validation loss: 3.7944230238596597

Epoch: 5| Step: 11
Training loss: 3.3587496280670166
Validation loss: 3.788527031739553

Epoch: 22| Step: 0
Training loss: 4.097638130187988
Validation loss: 3.7855576276779175

Epoch: 5| Step: 1
Training loss: 4.470236301422119
Validation loss: 3.779201030731201

Epoch: 5| Step: 2
Training loss: 3.369678497314453
Validation loss: 3.774749308824539

Epoch: 5| Step: 3
Training loss: 3.6754379272460938
Validation loss: 3.7705510457356772

Epoch: 5| Step: 4
Training loss: 3.659303665161133
Validation loss: 3.766170163949331

Epoch: 5| Step: 5
Training loss: 3.694241762161255
Validation loss: 3.7615870038668313

Epoch: 5| Step: 6
Training loss: 3.8996658325195312
Validation loss: 3.756290227174759

Epoch: 5| Step: 7
Training loss: 3.9034409523010254
Validation loss: 3.7495369712511697

Epoch: 5| Step: 8
Training loss: 4.365537166595459
Validation loss: 3.745496302843094

Epoch: 5| Step: 9
Training loss: 4.665246963500977
Validation loss: 3.7416080832481384

Epoch: 5| Step: 10
Training loss: 3.4310812950134277
Validation loss: 3.736631820599238

Epoch: 5| Step: 11
Training loss: 3.2811758518218994
Validation loss: 3.732045521338781

Epoch: 23| Step: 0
Training loss: 4.098328590393066
Validation loss: 3.7276853223641715

Epoch: 5| Step: 1
Training loss: 3.1276745796203613
Validation loss: 3.7230408092339835

Epoch: 5| Step: 2
Training loss: 3.836757183074951
Validation loss: 3.718844989935557

Epoch: 5| Step: 3
Training loss: 3.6178245544433594
Validation loss: 3.7141550282637277

Epoch: 5| Step: 4
Training loss: 3.645799160003662
Validation loss: 3.709495802720388

Epoch: 5| Step: 5
Training loss: 3.973585844039917
Validation loss: 3.7045843501885733

Epoch: 5| Step: 6
Training loss: 3.6827552318573
Validation loss: 3.700162390867869

Epoch: 5| Step: 7
Training loss: 4.010162353515625
Validation loss: 3.6957590679327645

Epoch: 5| Step: 8
Training loss: 4.314411640167236
Validation loss: 3.6905425588289895

Epoch: 5| Step: 9
Training loss: 4.15965461730957
Validation loss: 3.6862804293632507

Epoch: 5| Step: 10
Training loss: 3.6642463207244873
Validation loss: 3.6810841659704843

Epoch: 5| Step: 11
Training loss: 5.811066627502441
Validation loss: 3.6765551467736564

Epoch: 24| Step: 0
Training loss: 4.080904006958008
Validation loss: 3.672330290079117

Epoch: 5| Step: 1
Training loss: 4.2900285720825195
Validation loss: 3.6677120129267373

Epoch: 5| Step: 2
Training loss: 3.579463481903076
Validation loss: 3.6629939575990043

Epoch: 5| Step: 3
Training loss: 3.4809463024139404
Validation loss: 3.6580055256684623

Epoch: 5| Step: 4
Training loss: 3.8808536529541016
Validation loss: 3.6533132592837014

Epoch: 5| Step: 5
Training loss: 3.9180636405944824
Validation loss: 3.6486320793628693

Epoch: 5| Step: 6
Training loss: 5.180630683898926
Validation loss: 3.644125908613205

Epoch: 5| Step: 7
Training loss: 3.138524293899536
Validation loss: 3.6388742923736572

Epoch: 5| Step: 8
Training loss: 3.717968463897705
Validation loss: 3.634574035803477

Epoch: 5| Step: 9
Training loss: 3.474224090576172
Validation loss: 3.6295210321744285

Epoch: 5| Step: 10
Training loss: 2.933800458908081
Validation loss: 3.625055253505707

Epoch: 5| Step: 11
Training loss: 5.040287971496582
Validation loss: 3.6201569537321725

Epoch: 25| Step: 0
Training loss: 4.438891410827637
Validation loss: 3.6157972713311515

Epoch: 5| Step: 1
Training loss: 2.9708974361419678
Validation loss: 3.6101159155368805

Epoch: 5| Step: 2
Training loss: 4.1634931564331055
Validation loss: 3.605785757303238

Epoch: 5| Step: 3
Training loss: 3.7493834495544434
Validation loss: 3.6008672416210175

Epoch: 5| Step: 4
Training loss: 4.340378284454346
Validation loss: 3.596131185690562

Epoch: 5| Step: 5
Training loss: 3.234523057937622
Validation loss: 3.59147909283638

Epoch: 5| Step: 6
Training loss: 3.5095152854919434
Validation loss: 3.586537480354309

Epoch: 5| Step: 7
Training loss: 3.911561965942383
Validation loss: 3.5819066862265267

Epoch: 5| Step: 8
Training loss: 3.8895103931427
Validation loss: 3.5771683752536774

Epoch: 5| Step: 9
Training loss: 3.9705467224121094
Validation loss: 3.5720575153827667

Epoch: 5| Step: 10
Training loss: 3.523432493209839
Validation loss: 3.567617585261663

Epoch: 5| Step: 11
Training loss: 1.7497973442077637
Validation loss: 3.5624690850575766

Epoch: 26| Step: 0
Training loss: 4.912625312805176
Validation loss: 3.5568780402342477

Epoch: 5| Step: 1
Training loss: 3.7697367668151855
Validation loss: 3.5519820054372153

Epoch: 5| Step: 2
Training loss: 4.498950004577637
Validation loss: 3.5471567809581757

Epoch: 5| Step: 3
Training loss: 2.9358341693878174
Validation loss: 3.541848341623942

Epoch: 5| Step: 4
Training loss: 4.017246246337891
Validation loss: 3.5357866485913596

Epoch: 5| Step: 5
Training loss: 3.129601001739502
Validation loss: 3.530013749996821

Epoch: 5| Step: 6
Training loss: 3.6456284523010254
Validation loss: 3.5245690047740936

Epoch: 5| Step: 7
Training loss: 3.6803715229034424
Validation loss: 3.518998920917511

Epoch: 5| Step: 8
Training loss: 3.054410219192505
Validation loss: 3.5144673883914948

Epoch: 5| Step: 9
Training loss: 4.276093006134033
Validation loss: 3.5075421035289764

Epoch: 5| Step: 10
Training loss: 3.2036221027374268
Validation loss: 3.503396362066269

Epoch: 5| Step: 11
Training loss: 1.4901933670043945
Validation loss: 3.4966571231683097

Epoch: 27| Step: 0
Training loss: 3.397059679031372
Validation loss: 3.4917484521865845

Epoch: 5| Step: 1
Training loss: 2.885413408279419
Validation loss: 3.4854770501454673

Epoch: 5| Step: 2
Training loss: 3.4172332286834717
Validation loss: 3.480556905269623

Epoch: 5| Step: 3
Training loss: 3.7737224102020264
Validation loss: 3.4751238326231637

Epoch: 5| Step: 4
Training loss: 3.877401351928711
Validation loss: 3.4704633951187134

Epoch: 5| Step: 5
Training loss: 3.780970335006714
Validation loss: 3.4659617841243744

Epoch: 5| Step: 6
Training loss: 4.332541465759277
Validation loss: 3.46119757493337

Epoch: 5| Step: 7
Training loss: 4.431291103363037
Validation loss: 3.4553996423880258

Epoch: 5| Step: 8
Training loss: 3.645716905593872
Validation loss: 3.4500968853632608

Epoch: 5| Step: 9
Training loss: 3.2198662757873535
Validation loss: 3.4449228743712106

Epoch: 5| Step: 10
Training loss: 3.2921319007873535
Validation loss: 3.439584066470464

Epoch: 5| Step: 11
Training loss: 3.0448341369628906
Validation loss: 3.4335518181324005

Epoch: 28| Step: 0
Training loss: 3.2427871227264404
Validation loss: 3.428856054941813

Epoch: 5| Step: 1
Training loss: 3.372645616531372
Validation loss: 3.4245068629582724

Epoch: 5| Step: 2
Training loss: 3.2595386505126953
Validation loss: 3.4201626082261405

Epoch: 5| Step: 3
Training loss: 4.133724689483643
Validation loss: 3.414835959672928

Epoch: 5| Step: 4
Training loss: 4.193461894989014
Validation loss: 3.4097370704015098

Epoch: 5| Step: 5
Training loss: 3.5366339683532715
Validation loss: 3.4046259423096976

Epoch: 5| Step: 6
Training loss: 3.4115307331085205
Validation loss: 3.4002899328867593

Epoch: 5| Step: 7
Training loss: 4.143538475036621
Validation loss: 3.3959619303544364

Epoch: 5| Step: 8
Training loss: 3.0572712421417236
Validation loss: 3.3905956546465554

Epoch: 5| Step: 9
Training loss: 3.5091004371643066
Validation loss: 3.3853844900925956

Epoch: 5| Step: 10
Training loss: 3.5783438682556152
Validation loss: 3.3810324172178903

Epoch: 5| Step: 11
Training loss: 2.926713466644287
Validation loss: 3.3765111366907754

Epoch: 29| Step: 0
Training loss: 3.498323440551758
Validation loss: 3.3718897104263306

Epoch: 5| Step: 1
Training loss: 3.466651439666748
Validation loss: 3.3667956988016763

Epoch: 5| Step: 2
Training loss: 2.7377548217773438
Validation loss: 3.3616018692652383

Epoch: 5| Step: 3
Training loss: 3.669050693511963
Validation loss: 3.3569628496964774

Epoch: 5| Step: 4
Training loss: 3.5947136878967285
Validation loss: 3.3519769807656608

Epoch: 5| Step: 5
Training loss: 2.09291410446167
Validation loss: 3.3472706576188407

Epoch: 5| Step: 6
Training loss: 4.628203868865967
Validation loss: 3.342559685309728

Epoch: 5| Step: 7
Training loss: 3.9686431884765625
Validation loss: 3.3384692668914795

Epoch: 5| Step: 8
Training loss: 3.806330919265747
Validation loss: 3.332490841547648

Epoch: 5| Step: 9
Training loss: 3.426440715789795
Validation loss: 3.3275131384531655

Epoch: 5| Step: 10
Training loss: 3.42789888381958
Validation loss: 3.322214881579081

Epoch: 5| Step: 11
Training loss: 5.394596099853516
Validation loss: 3.317259649435679

Epoch: 30| Step: 0
Training loss: 2.627899408340454
Validation loss: 3.31226979692777

Epoch: 5| Step: 1
Training loss: 3.9101035594940186
Validation loss: 3.3070148726304374

Epoch: 5| Step: 2
Training loss: 3.9351868629455566
Validation loss: 3.3020229637622833

Epoch: 5| Step: 3
Training loss: 3.9890944957733154
Validation loss: 3.2978146374225616

Epoch: 5| Step: 4
Training loss: 3.192700147628784
Validation loss: 3.2938453356424966

Epoch: 5| Step: 5
Training loss: 3.648674488067627
Validation loss: 3.2891750435034433

Epoch: 5| Step: 6
Training loss: 3.6645896434783936
Validation loss: 3.28430766860644

Epoch: 5| Step: 7
Training loss: 3.455737590789795
Validation loss: 3.2788336972395578

Epoch: 5| Step: 8
Training loss: 3.7378509044647217
Validation loss: 3.27423357963562

Epoch: 5| Step: 9
Training loss: 3.4055304527282715
Validation loss: 3.2693508664766946

Epoch: 5| Step: 10
Training loss: 2.4883928298950195
Validation loss: 3.265277018149694

Epoch: 5| Step: 11
Training loss: 3.648207426071167
Validation loss: 3.2610351741313934

Epoch: 31| Step: 0
Training loss: 3.778571367263794
Validation loss: 3.255569944779078

Epoch: 5| Step: 1
Training loss: 3.220219850540161
Validation loss: 3.250524898370107

Epoch: 5| Step: 2
Training loss: 2.918020248413086
Validation loss: 3.2453831930955253

Epoch: 5| Step: 3
Training loss: 4.25781774520874
Validation loss: 3.241373598575592

Epoch: 5| Step: 4
Training loss: 3.330603837966919
Validation loss: 3.236834933360418

Epoch: 5| Step: 5
Training loss: 3.923938035964966
Validation loss: 3.2321666975816092

Epoch: 5| Step: 6
Training loss: 2.8956518173217773
Validation loss: 3.2274482746918998

Epoch: 5| Step: 7
Training loss: 3.5562591552734375
Validation loss: 3.2222207287947335

Epoch: 5| Step: 8
Training loss: 3.3965442180633545
Validation loss: 3.218418836593628

Epoch: 5| Step: 9
Training loss: 3.6014695167541504
Validation loss: 3.2172322968641915

Epoch: 5| Step: 10
Training loss: 2.6233620643615723
Validation loss: 3.208048860232035

Epoch: 5| Step: 11
Training loss: 3.548762321472168
Validation loss: 3.2035200595855713

Epoch: 32| Step: 0
Training loss: 2.8559508323669434
Validation loss: 3.2002746959527335

Epoch: 5| Step: 1
Training loss: 2.949030637741089
Validation loss: 3.195859541495641

Epoch: 5| Step: 2
Training loss: 3.872523546218872
Validation loss: 3.1913063724835715

Epoch: 5| Step: 3
Training loss: 3.4527504444122314
Validation loss: 3.1873099307219186

Epoch: 5| Step: 4
Training loss: 3.9545211791992188
Validation loss: 3.182040353616079

Epoch: 5| Step: 5
Training loss: 2.6988139152526855
Validation loss: 3.177326798439026

Epoch: 5| Step: 6
Training loss: 3.146836519241333
Validation loss: 3.1724718709786734

Epoch: 5| Step: 7
Training loss: 2.826690435409546
Validation loss: 3.1691086292266846

Epoch: 5| Step: 8
Training loss: 3.564176559448242
Validation loss: 3.1648084223270416

Epoch: 5| Step: 9
Training loss: 3.629978656768799
Validation loss: 3.1608409881591797

Epoch: 5| Step: 10
Training loss: 3.7128875255584717
Validation loss: 3.15567684173584

Epoch: 5| Step: 11
Training loss: 4.919681549072266
Validation loss: 3.150415360927582

Epoch: 33| Step: 0
Training loss: 3.602865695953369
Validation loss: 3.1458882093429565

Epoch: 5| Step: 1
Training loss: 3.7359073162078857
Validation loss: 3.141626685857773

Epoch: 5| Step: 2
Training loss: 3.8519222736358643
Validation loss: 3.1375509103139243

Epoch: 5| Step: 3
Training loss: 3.1861443519592285
Validation loss: 3.1330124139785767

Epoch: 5| Step: 4
Training loss: 3.1865150928497314
Validation loss: 3.1287436286608377

Epoch: 5| Step: 5
Training loss: 2.5558855533599854
Validation loss: 3.123802969853083

Epoch: 5| Step: 6
Training loss: 3.9406261444091797
Validation loss: 3.1182891726493835

Epoch: 5| Step: 7
Training loss: 3.0701727867126465
Validation loss: 3.113737791776657

Epoch: 5| Step: 8
Training loss: 2.395315170288086
Validation loss: 3.1099232335885367

Epoch: 5| Step: 9
Training loss: 4.083400726318359
Validation loss: 3.106589605410894

Epoch: 5| Step: 10
Training loss: 2.632434129714966
Validation loss: 3.102240095535914

Epoch: 5| Step: 11
Training loss: 4.199970245361328
Validation loss: 3.0970162053902945

Epoch: 34| Step: 0
Training loss: 3.3217062950134277
Validation loss: 3.092191865046819

Epoch: 5| Step: 1
Training loss: 3.223914384841919
Validation loss: 3.088145842154821

Epoch: 5| Step: 2
Training loss: 2.924882650375366
Validation loss: 3.08408655722936

Epoch: 5| Step: 3
Training loss: 3.482389450073242
Validation loss: 3.0803849498430886

Epoch: 5| Step: 4
Training loss: 3.5810208320617676
Validation loss: 3.0763986011346183

Epoch: 5| Step: 5
Training loss: 3.3700757026672363
Validation loss: 3.0726472238699594

Epoch: 5| Step: 6
Training loss: 3.4223875999450684
Validation loss: 3.0688131749629974

Epoch: 5| Step: 7
Training loss: 3.179055690765381
Validation loss: 3.064584026734034

Epoch: 5| Step: 8
Training loss: 2.769378662109375
Validation loss: 3.059851954380671

Epoch: 5| Step: 9
Training loss: 3.5392017364501953
Validation loss: 3.056692143281301

Epoch: 5| Step: 10
Training loss: 3.2248120307922363
Validation loss: 3.0527323782444

Epoch: 5| Step: 11
Training loss: 2.4097659587860107
Validation loss: 3.0490905344486237

Epoch: 35| Step: 0
Training loss: 3.400942325592041
Validation loss: 3.0440972050031028

Epoch: 5| Step: 1
Training loss: 2.72318959236145
Validation loss: 3.0392962594827018

Epoch: 5| Step: 2
Training loss: 3.6890463829040527
Validation loss: 3.0360107421875

Epoch: 5| Step: 3
Training loss: 2.8820242881774902
Validation loss: 3.0321969588597617

Epoch: 5| Step: 4
Training loss: 2.9229795932769775
Validation loss: 3.0280266205469766

Epoch: 5| Step: 5
Training loss: 3.429818630218506
Validation loss: 3.0239934623241425

Epoch: 5| Step: 6
Training loss: 4.00078821182251
Validation loss: 3.0194548765818277

Epoch: 5| Step: 7
Training loss: 3.130866527557373
Validation loss: 3.015438179175059

Epoch: 5| Step: 8
Training loss: 2.8571674823760986
Validation loss: 3.0114304025967917

Epoch: 5| Step: 9
Training loss: 2.6713814735412598
Validation loss: 3.007503946622213

Epoch: 5| Step: 10
Training loss: 3.4338393211364746
Validation loss: 3.0040532648563385

Epoch: 5| Step: 11
Training loss: 4.370178699493408
Validation loss: 2.9997376600901284

Epoch: 36| Step: 0
Training loss: 3.352085590362549
Validation loss: 2.996338725090027

Epoch: 5| Step: 1
Training loss: 3.3757119178771973
Validation loss: 2.992384970188141

Epoch: 5| Step: 2
Training loss: 3.2470028400421143
Validation loss: 2.9887944062550864

Epoch: 5| Step: 3
Training loss: 4.188675403594971
Validation loss: 2.985095630089442

Epoch: 5| Step: 4
Training loss: 3.1123313903808594
Validation loss: 2.980573147535324

Epoch: 5| Step: 5
Training loss: 3.002979278564453
Validation loss: 2.97651544213295

Epoch: 5| Step: 6
Training loss: 3.2538559436798096
Validation loss: 2.9729040463765464

Epoch: 5| Step: 7
Training loss: 2.8303401470184326
Validation loss: 2.9688975512981415

Epoch: 5| Step: 8
Training loss: 2.608893871307373
Validation loss: 2.9650209148724875

Epoch: 5| Step: 9
Training loss: 3.234912872314453
Validation loss: 2.961170474688212

Epoch: 5| Step: 10
Training loss: 2.7839643955230713
Validation loss: 2.9578991134961448

Epoch: 5| Step: 11
Training loss: 2.7998013496398926
Validation loss: 2.9536133805910745

Epoch: 37| Step: 0
Training loss: 3.416411876678467
Validation loss: 2.9497644106547036

Epoch: 5| Step: 1
Training loss: 3.3308265209198
Validation loss: 2.9461429913838706

Epoch: 5| Step: 2
Training loss: 2.608182430267334
Validation loss: 2.9417315125465393

Epoch: 5| Step: 3
Training loss: 3.476144313812256
Validation loss: 2.9380694031715393

Epoch: 5| Step: 4
Training loss: 3.849566698074341
Validation loss: 2.934058725833893

Epoch: 5| Step: 5
Training loss: 3.150272846221924
Validation loss: 2.930136909087499

Epoch: 5| Step: 6
Training loss: 2.478182554244995
Validation loss: 2.9258520007133484

Epoch: 5| Step: 7
Training loss: 2.221144914627075
Validation loss: 2.922703097263972

Epoch: 5| Step: 8
Training loss: 3.483116865158081
Validation loss: 2.919100373983383

Epoch: 5| Step: 9
Training loss: 3.275243043899536
Validation loss: 2.9151637057463327

Epoch: 5| Step: 10
Training loss: 3.1155810356140137
Validation loss: 2.9115940630435944

Epoch: 5| Step: 11
Training loss: 3.3615989685058594
Validation loss: 2.9076954821745553

Epoch: 38| Step: 0
Training loss: 2.622851610183716
Validation loss: 2.9038714369138083

Epoch: 5| Step: 1
Training loss: 3.402313232421875
Validation loss: 2.900014648834864

Epoch: 5| Step: 2
Training loss: 2.7532849311828613
Validation loss: 2.896719733874003

Epoch: 5| Step: 3
Training loss: 3.658795118331909
Validation loss: 2.893178085486094

Epoch: 5| Step: 4
Training loss: 3.3317039012908936
Validation loss: 2.889221101999283

Epoch: 5| Step: 5
Training loss: 3.2009406089782715
Validation loss: 2.8856174051761627

Epoch: 5| Step: 6
Training loss: 2.710540771484375
Validation loss: 2.881664514541626

Epoch: 5| Step: 7
Training loss: 2.131122589111328
Validation loss: 2.8774378299713135

Epoch: 5| Step: 8
Training loss: 2.8600916862487793
Validation loss: 2.8744150896867118

Epoch: 5| Step: 9
Training loss: 3.8216700553894043
Validation loss: 2.870947221914927

Epoch: 5| Step: 10
Training loss: 3.4020400047302246
Validation loss: 2.8670887549718223

Epoch: 5| Step: 11
Training loss: 3.708195686340332
Validation loss: 2.863563984632492

Epoch: 39| Step: 0
Training loss: 3.2216544151306152
Validation loss: 2.8599511782328286

Epoch: 5| Step: 1
Training loss: 3.080306053161621
Validation loss: 2.8566349844137826

Epoch: 5| Step: 2
Training loss: 2.3467421531677246
Validation loss: 2.8522613843282065

Epoch: 5| Step: 3
Training loss: 3.595555067062378
Validation loss: 2.8487798273563385

Epoch: 5| Step: 4
Training loss: 2.9425129890441895
Validation loss: 2.845304230848948

Epoch: 5| Step: 5
Training loss: 3.131470203399658
Validation loss: 2.8416301608085632

Epoch: 5| Step: 6
Training loss: 2.507763385772705
Validation loss: 2.838048537572225

Epoch: 5| Step: 7
Training loss: 3.529578447341919
Validation loss: 2.8352451622486115

Epoch: 5| Step: 8
Training loss: 3.3550524711608887
Validation loss: 2.8318755626678467

Epoch: 5| Step: 9
Training loss: 2.9739928245544434
Validation loss: 2.8285635014375052

Epoch: 5| Step: 10
Training loss: 3.0552265644073486
Validation loss: 2.824930816888809

Epoch: 5| Step: 11
Training loss: 2.251760959625244
Validation loss: 2.8215072602033615

Epoch: 40| Step: 0
Training loss: 3.78979229927063
Validation loss: 2.8184227844079337

Epoch: 5| Step: 1
Training loss: 2.9472274780273438
Validation loss: 2.814761300881704

Epoch: 5| Step: 2
Training loss: 3.1613755226135254
Validation loss: 2.812039166688919

Epoch: 5| Step: 3
Training loss: 2.843291759490967
Validation loss: 2.8082960347334542

Epoch: 5| Step: 4
Training loss: 2.976963520050049
Validation loss: 2.805107136567434

Epoch: 5| Step: 5
Training loss: 2.7719433307647705
Validation loss: 2.80178764462471

Epoch: 5| Step: 6
Training loss: 3.3784847259521484
Validation loss: 2.7983489334583282

Epoch: 5| Step: 7
Training loss: 1.9575588703155518
Validation loss: 2.794955382744471

Epoch: 5| Step: 8
Training loss: 2.9913926124572754
Validation loss: 2.791821757952372

Epoch: 5| Step: 9
Training loss: 3.371628522872925
Validation loss: 2.788833796977997

Epoch: 5| Step: 10
Training loss: 2.984882354736328
Validation loss: 2.785932570695877

Epoch: 5| Step: 11
Training loss: 3.0310354232788086
Validation loss: 2.7830220063527427

Epoch: 41| Step: 0
Training loss: 3.342672824859619
Validation loss: 2.7804626524448395

Epoch: 5| Step: 1
Training loss: 2.8189659118652344
Validation loss: 2.776167462269465

Epoch: 5| Step: 2
Training loss: 3.001884698867798
Validation loss: 2.7736292481422424

Epoch: 5| Step: 3
Training loss: 3.3220508098602295
Validation loss: 2.770884722471237

Epoch: 5| Step: 4
Training loss: 3.0375912189483643
Validation loss: 2.767996142307917

Epoch: 5| Step: 5
Training loss: 2.9942009449005127
Validation loss: 2.764827698469162

Epoch: 5| Step: 6
Training loss: 2.5324044227600098
Validation loss: 2.7618545095125833

Epoch: 5| Step: 7
Training loss: 2.836864471435547
Validation loss: 2.758768459161123

Epoch: 5| Step: 8
Training loss: 2.6409859657287598
Validation loss: 2.75574384133021

Epoch: 5| Step: 9
Training loss: 3.544417142868042
Validation loss: 2.752862493197123

Epoch: 5| Step: 10
Training loss: 2.7271816730499268
Validation loss: 2.749877075354258

Epoch: 5| Step: 11
Training loss: 2.6975743770599365
Validation loss: 2.746496468782425

Epoch: 42| Step: 0
Training loss: 3.094594717025757
Validation loss: 2.7443863848845163

Epoch: 5| Step: 1
Training loss: 2.5350561141967773
Validation loss: 2.7416688402493796

Epoch: 5| Step: 2
Training loss: 2.5050129890441895
Validation loss: 2.738522450129191

Epoch: 5| Step: 3
Training loss: 3.5802371501922607
Validation loss: 2.7360390722751617

Epoch: 5| Step: 4
Training loss: 2.754451036453247
Validation loss: 2.732828418413798

Epoch: 5| Step: 5
Training loss: 3.3727831840515137
Validation loss: 2.7297901113828025

Epoch: 5| Step: 6
Training loss: 3.6228702068328857
Validation loss: 2.7267235616842904

Epoch: 5| Step: 7
Training loss: 3.09272837638855
Validation loss: 2.723417788743973

Epoch: 5| Step: 8
Training loss: 2.487121820449829
Validation loss: 2.720708797375361

Epoch: 5| Step: 9
Training loss: 2.298081636428833
Validation loss: 2.71772900223732

Epoch: 5| Step: 10
Training loss: 2.9376893043518066
Validation loss: 2.714844008286794

Epoch: 5| Step: 11
Training loss: 3.2643001079559326
Validation loss: 2.712455928325653

Epoch: 43| Step: 0
Training loss: 3.3191230297088623
Validation loss: 2.7094778219858804

Epoch: 5| Step: 1
Training loss: 3.0199685096740723
Validation loss: 2.7062987784544625

Epoch: 5| Step: 2
Training loss: 3.1029152870178223
Validation loss: 2.7034643491109214

Epoch: 5| Step: 3
Training loss: 3.0246646404266357
Validation loss: 2.700023094813029

Epoch: 5| Step: 4
Training loss: 2.8501713275909424
Validation loss: 2.696830769379934

Epoch: 5| Step: 5
Training loss: 2.8774633407592773
Validation loss: 2.693742344776789

Epoch: 5| Step: 6
Training loss: 2.6384947299957275
Validation loss: 2.6907108426094055

Epoch: 5| Step: 7
Training loss: 2.8322694301605225
Validation loss: 2.6875602503617606

Epoch: 5| Step: 8
Training loss: 3.288386106491089
Validation loss: 2.6845474938551583

Epoch: 5| Step: 9
Training loss: 2.617924213409424
Validation loss: 2.681831548611323

Epoch: 5| Step: 10
Training loss: 2.489137887954712
Validation loss: 2.6786377926667533

Epoch: 5| Step: 11
Training loss: 2.2706780433654785
Validation loss: 2.6757735311985016

Epoch: 44| Step: 0
Training loss: 2.2431015968322754
Validation loss: 2.6733305752277374

Epoch: 5| Step: 1
Training loss: 3.1964473724365234
Validation loss: 2.6711451709270477

Epoch: 5| Step: 2
Training loss: 2.4534919261932373
Validation loss: 2.669411063194275

Epoch: 5| Step: 3
Training loss: 2.9509434700012207
Validation loss: 2.6667892038822174

Epoch: 5| Step: 4
Training loss: 3.232569932937622
Validation loss: 2.6639232834180198

Epoch: 5| Step: 5
Training loss: 2.5091586112976074
Validation loss: 2.6613360345363617

Epoch: 5| Step: 6
Training loss: 2.6726107597351074
Validation loss: 2.6589798827966056

Epoch: 5| Step: 7
Training loss: 2.444145917892456
Validation loss: 2.6559942762056985

Epoch: 5| Step: 8
Training loss: 3.3913464546203613
Validation loss: 2.653493086496989

Epoch: 5| Step: 9
Training loss: 3.320758819580078
Validation loss: 2.65182634194692

Epoch: 5| Step: 10
Training loss: 3.0812790393829346
Validation loss: 2.6482245326042175

Epoch: 5| Step: 11
Training loss: 2.926334857940674
Validation loss: 2.6446393728256226

Epoch: 45| Step: 0
Training loss: 3.3214943408966064
Validation loss: 2.641784757375717

Epoch: 5| Step: 1
Training loss: 2.7946081161499023
Validation loss: 2.6389012734095254

Epoch: 5| Step: 2
Training loss: 2.3858249187469482
Validation loss: 2.6359298825263977

Epoch: 5| Step: 3
Training loss: 2.445150375366211
Validation loss: 2.6324095328648887

Epoch: 5| Step: 4
Training loss: 3.0645976066589355
Validation loss: 2.6298752079407373

Epoch: 5| Step: 5
Training loss: 2.326307773590088
Validation loss: 2.6269810994466147

Epoch: 5| Step: 6
Training loss: 2.634920120239258
Validation loss: 2.6238001883029938

Epoch: 5| Step: 7
Training loss: 3.160583734512329
Validation loss: 2.620889663696289

Epoch: 5| Step: 8
Training loss: 2.8376383781433105
Validation loss: 2.6180324256420135

Epoch: 5| Step: 9
Training loss: 2.6670944690704346
Validation loss: 2.6149607996145883

Epoch: 5| Step: 10
Training loss: 3.498223066329956
Validation loss: 2.6123289366563163

Epoch: 5| Step: 11
Training loss: 2.848421335220337
Validation loss: 2.609200974305471

Epoch: 46| Step: 0
Training loss: 2.341276168823242
Validation loss: 2.6064219574133554

Epoch: 5| Step: 1
Training loss: 3.333428144454956
Validation loss: 2.603596339623133

Epoch: 5| Step: 2
Training loss: 3.2793350219726562
Validation loss: 2.5999179085095725

Epoch: 5| Step: 3
Training loss: 3.158301591873169
Validation loss: 2.596677949031194

Epoch: 5| Step: 4
Training loss: 2.763042449951172
Validation loss: 2.5937869250774384

Epoch: 5| Step: 5
Training loss: 2.5755457878112793
Validation loss: 2.590482701857885

Epoch: 5| Step: 6
Training loss: 2.607584238052368
Validation loss: 2.5872782170772552

Epoch: 5| Step: 7
Training loss: 3.0560061931610107
Validation loss: 2.58416477839152

Epoch: 5| Step: 8
Training loss: 2.840062379837036
Validation loss: 2.581325888633728

Epoch: 5| Step: 9
Training loss: 2.6784133911132812
Validation loss: 2.578760246435801

Epoch: 5| Step: 10
Training loss: 2.2902798652648926
Validation loss: 2.576222022374471

Epoch: 5| Step: 11
Training loss: 1.7826234102249146
Validation loss: 2.571486790974935

Epoch: 47| Step: 0
Training loss: 2.3996548652648926
Validation loss: 2.569884330034256

Epoch: 5| Step: 1
Training loss: 2.9124770164489746
Validation loss: 2.593996653954188

Epoch: 5| Step: 2
Training loss: 2.94846773147583
Validation loss: 2.5856604278087616

Epoch: 5| Step: 3
Training loss: 2.9532196521759033
Validation loss: 2.562158703804016

Epoch: 5| Step: 4
Training loss: 2.5813021659851074
Validation loss: 2.5625873108704886

Epoch: 5| Step: 5
Training loss: 3.4189720153808594
Validation loss: 2.5634812812010446

Epoch: 5| Step: 6
Training loss: 2.386334180831909
Validation loss: 2.5597681204477944

Epoch: 5| Step: 7
Training loss: 2.989370346069336
Validation loss: 2.555840710798899

Epoch: 5| Step: 8
Training loss: 2.595543384552002
Validation loss: 2.554241200288137

Epoch: 5| Step: 9
Training loss: 3.050347328186035
Validation loss: 2.550625443458557

Epoch: 5| Step: 10
Training loss: 2.3381187915802
Validation loss: 2.547870248556137

Epoch: 5| Step: 11
Training loss: 1.9043421745300293
Validation loss: 2.544960250457128

Epoch: 48| Step: 0
Training loss: 2.589552402496338
Validation loss: 2.5430203477541604

Epoch: 5| Step: 1
Training loss: 2.8617753982543945
Validation loss: 2.540095975001653

Epoch: 5| Step: 2
Training loss: 3.044374704360962
Validation loss: 2.5352381567160287

Epoch: 5| Step: 3
Training loss: 2.9702115058898926
Validation loss: 2.533294399579366

Epoch: 5| Step: 4
Training loss: 2.4120895862579346
Validation loss: 2.5314169228076935

Epoch: 5| Step: 5
Training loss: 3.047412872314453
Validation loss: 2.528223047653834

Epoch: 5| Step: 6
Training loss: 2.559783935546875
Validation loss: 2.52457003792127

Epoch: 5| Step: 7
Training loss: 2.687274217605591
Validation loss: 2.52215376496315

Epoch: 5| Step: 8
Training loss: 3.0459747314453125
Validation loss: 2.5184428791205087

Epoch: 5| Step: 9
Training loss: 2.296426296234131
Validation loss: 2.5163509051005044

Epoch: 5| Step: 10
Training loss: 2.4678120613098145
Validation loss: 2.5121677617232003

Epoch: 5| Step: 11
Training loss: 2.58950138092041
Validation loss: 2.5100150108337402

Epoch: 49| Step: 0
Training loss: 2.5618419647216797
Validation loss: 2.507258782784144

Epoch: 5| Step: 1
Training loss: 2.5793447494506836
Validation loss: 2.5052611033121743

Epoch: 5| Step: 2
Training loss: 2.945685863494873
Validation loss: 2.5004544258117676

Epoch: 5| Step: 3
Training loss: 2.410327434539795
Validation loss: 2.500259518623352

Epoch: 5| Step: 4
Training loss: 2.1738438606262207
Validation loss: 2.4953516821066537

Epoch: 5| Step: 5
Training loss: 2.456880569458008
Validation loss: 2.4921082655588784

Epoch: 5| Step: 6
Training loss: 2.5886387825012207
Validation loss: 2.4902175068855286

Epoch: 5| Step: 7
Training loss: 3.088684320449829
Validation loss: 2.488129566113154

Epoch: 5| Step: 8
Training loss: 2.310767889022827
Validation loss: 2.4852875818808875

Epoch: 5| Step: 9
Training loss: 3.426506757736206
Validation loss: 2.483147233724594

Epoch: 5| Step: 10
Training loss: 2.948127508163452
Validation loss: 2.4791382302840552

Epoch: 5| Step: 11
Training loss: 2.9604806900024414
Validation loss: 2.4783443609873452

Epoch: 50| Step: 0
Training loss: 2.2022721767425537
Validation loss: 2.4771868685881295

Epoch: 5| Step: 1
Training loss: 2.6655848026275635
Validation loss: 2.474633902311325

Epoch: 5| Step: 2
Training loss: 2.40433931350708
Validation loss: 2.472707062959671

Epoch: 5| Step: 3
Training loss: 2.767277240753174
Validation loss: 2.4678714871406555

Epoch: 5| Step: 4
Training loss: 2.4557032585144043
Validation loss: 2.464224169651667

Epoch: 5| Step: 5
Training loss: 2.981342315673828
Validation loss: 2.4600539108117423

Epoch: 5| Step: 6
Training loss: 2.9310295581817627
Validation loss: 2.457257946332296

Epoch: 5| Step: 7
Training loss: 2.6018214225769043
Validation loss: 2.4538746078809104

Epoch: 5| Step: 8
Training loss: 3.106306552886963
Validation loss: 2.450793127218882

Epoch: 5| Step: 9
Training loss: 1.8699867725372314
Validation loss: 2.446495622396469

Epoch: 5| Step: 10
Training loss: 2.994235038757324
Validation loss: 2.4425175736347833

Epoch: 5| Step: 11
Training loss: 3.633098602294922
Validation loss: 2.4406194984912872

Testing loss: 2.0531627231364626
