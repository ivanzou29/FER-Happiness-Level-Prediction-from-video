Epoch: 1| Step: 0
Training loss: 4.627161026000977
Validation loss: 5.378754456837972

Epoch: 5| Step: 1
Training loss: 5.716153621673584
Validation loss: 5.377531250317891

Epoch: 5| Step: 2
Training loss: 5.735050201416016
Validation loss: 5.376352111498515

Epoch: 5| Step: 3
Training loss: 7.2335710525512695
Validation loss: 5.375112175941467

Epoch: 5| Step: 4
Training loss: 5.557596683502197
Validation loss: 5.373852789402008

Epoch: 5| Step: 5
Training loss: 4.741797924041748
Validation loss: 5.372615694999695

Epoch: 5| Step: 6
Training loss: 5.34991455078125
Validation loss: 5.371328155199687

Epoch: 5| Step: 7
Training loss: 4.868044376373291
Validation loss: 5.370087921619415

Epoch: 5| Step: 8
Training loss: 5.3421478271484375
Validation loss: 5.368770798047383

Epoch: 5| Step: 9
Training loss: 5.840059280395508
Validation loss: 5.367384572823842

Epoch: 5| Step: 10
Training loss: 5.068634986877441
Validation loss: 5.366033434867859

Epoch: 5| Step: 11
Training loss: 4.303922653198242
Validation loss: 5.3646184007326765

Epoch: 2| Step: 0
Training loss: 4.687715530395508
Validation loss: 5.3632210691769915

Epoch: 5| Step: 1
Training loss: 5.345725059509277
Validation loss: 5.361737509568532

Epoch: 5| Step: 2
Training loss: 5.079765796661377
Validation loss: 5.360196352005005

Epoch: 5| Step: 3
Training loss: 4.88271427154541
Validation loss: 5.3586355447769165

Epoch: 5| Step: 4
Training loss: 5.333869457244873
Validation loss: 5.357041577498118

Epoch: 5| Step: 5
Training loss: 4.753331184387207
Validation loss: 5.355295995871226

Epoch: 5| Step: 6
Training loss: 5.1615071296691895
Validation loss: 5.3535531759262085

Epoch: 5| Step: 7
Training loss: 6.089724063873291
Validation loss: 5.3517114122708636

Epoch: 5| Step: 8
Training loss: 6.418141841888428
Validation loss: 5.349809626738231

Epoch: 5| Step: 9
Training loss: 5.015885353088379
Validation loss: 5.347785592079163

Epoch: 5| Step: 10
Training loss: 6.370770454406738
Validation loss: 5.345657507578532

Epoch: 5| Step: 11
Training loss: 8.027050018310547
Validation loss: 5.34343687693278

Epoch: 3| Step: 0
Training loss: 5.679709434509277
Validation loss: 5.341047525405884

Epoch: 5| Step: 1
Training loss: 6.616337776184082
Validation loss: 5.338597257932027

Epoch: 5| Step: 2
Training loss: 5.824304580688477
Validation loss: 5.336044172445933

Epoch: 5| Step: 3
Training loss: 5.588050842285156
Validation loss: 5.333306590716044

Epoch: 5| Step: 4
Training loss: 4.617735385894775
Validation loss: 5.330412367979686

Epoch: 5| Step: 5
Training loss: 4.699063777923584
Validation loss: 5.32740459839503

Epoch: 5| Step: 6
Training loss: 4.809017181396484
Validation loss: 5.324229796727498

Epoch: 5| Step: 7
Training loss: 5.0681257247924805
Validation loss: 5.320886254310608

Epoch: 5| Step: 8
Training loss: 5.249101161956787
Validation loss: 5.317294180393219

Epoch: 5| Step: 9
Training loss: 5.9374284744262695
Validation loss: 5.313577135403951

Epoch: 5| Step: 10
Training loss: 5.0826640129089355
Validation loss: 5.309640785058339

Epoch: 5| Step: 11
Training loss: 6.275771617889404
Validation loss: 5.305536230405171

Epoch: 4| Step: 0
Training loss: 5.772781848907471
Validation loss: 5.301347156365712

Epoch: 5| Step: 1
Training loss: 5.861716270446777
Validation loss: 5.296669781208038

Epoch: 5| Step: 2
Training loss: 5.320105075836182
Validation loss: 5.291901965936025

Epoch: 5| Step: 3
Training loss: 4.135670185089111
Validation loss: 5.286766429742177

Epoch: 5| Step: 4
Training loss: 5.1364641189575195
Validation loss: 5.2815330028533936

Epoch: 5| Step: 5
Training loss: 5.505541801452637
Validation loss: 5.276049951712291

Epoch: 5| Step: 6
Training loss: 3.9996140003204346
Validation loss: 5.270331223805745

Epoch: 5| Step: 7
Training loss: 6.293849468231201
Validation loss: 5.264347453912099

Epoch: 5| Step: 8
Training loss: 5.705295562744141
Validation loss: 5.2579464713732404

Epoch: 5| Step: 9
Training loss: 5.550503730773926
Validation loss: 5.25146899620692

Epoch: 5| Step: 10
Training loss: 5.439080238342285
Validation loss: 5.244716604550679

Epoch: 5| Step: 11
Training loss: 5.695980072021484
Validation loss: 5.237833797931671

Epoch: 5| Step: 0
Training loss: 5.0719709396362305
Validation loss: 5.23055366675059

Epoch: 5| Step: 1
Training loss: 5.68938684463501
Validation loss: 5.223117609818776

Epoch: 5| Step: 2
Training loss: 4.903682708740234
Validation loss: 5.215554495652516

Epoch: 5| Step: 3
Training loss: 5.226975440979004
Validation loss: 5.207312782605489

Epoch: 5| Step: 4
Training loss: 5.070249080657959
Validation loss: 5.199171145757039

Epoch: 5| Step: 5
Training loss: 4.6770219802856445
Validation loss: 5.190645317236583

Epoch: 5| Step: 6
Training loss: 5.472418308258057
Validation loss: 5.181980490684509

Epoch: 5| Step: 7
Training loss: 5.080511569976807
Validation loss: 5.17261278629303

Epoch: 5| Step: 8
Training loss: 5.424583435058594
Validation loss: 5.163415729999542

Epoch: 5| Step: 9
Training loss: 5.025752544403076
Validation loss: 5.153554419676463

Epoch: 5| Step: 10
Training loss: 5.766760349273682
Validation loss: 5.143833518028259

Epoch: 5| Step: 11
Training loss: 7.545716285705566
Validation loss: 5.134043216705322

Epoch: 6| Step: 0
Training loss: 5.071619033813477
Validation loss: 5.1236022512118025

Epoch: 5| Step: 1
Training loss: 5.514369010925293
Validation loss: 5.113254606723785

Epoch: 5| Step: 2
Training loss: 5.240992546081543
Validation loss: 5.102783620357513

Epoch: 5| Step: 3
Training loss: 4.634522438049316
Validation loss: 5.092433154582977

Epoch: 5| Step: 4
Training loss: 5.891047477722168
Validation loss: 5.0818889538447065

Epoch: 5| Step: 5
Training loss: 5.4958295822143555
Validation loss: 5.071630895137787

Epoch: 5| Step: 6
Training loss: 4.4484028816223145
Validation loss: 5.061189969380696

Epoch: 5| Step: 7
Training loss: 5.314511299133301
Validation loss: 5.0507527987162275

Epoch: 5| Step: 8
Training loss: 5.710944175720215
Validation loss: 5.040653755267461

Epoch: 5| Step: 9
Training loss: 4.633780479431152
Validation loss: 5.030506829420726

Epoch: 5| Step: 10
Training loss: 5.179513931274414
Validation loss: 5.020383715629578

Epoch: 5| Step: 11
Training loss: 2.6152546405792236
Validation loss: 5.0100221037864685

Epoch: 7| Step: 0
Training loss: 4.768702030181885
Validation loss: 4.999627888202667

Epoch: 5| Step: 1
Training loss: 5.145859718322754
Validation loss: 4.989460110664368

Epoch: 5| Step: 2
Training loss: 5.2799248695373535
Validation loss: 4.978185832500458

Epoch: 5| Step: 3
Training loss: 5.663002967834473
Validation loss: 4.967259565989177

Epoch: 5| Step: 4
Training loss: 5.103153705596924
Validation loss: 4.956381022930145

Epoch: 5| Step: 5
Training loss: 4.539907932281494
Validation loss: 4.9453779856363935

Epoch: 5| Step: 6
Training loss: 4.274270057678223
Validation loss: 4.934593180815379

Epoch: 5| Step: 7
Training loss: 5.505453586578369
Validation loss: 4.9234171112378435

Epoch: 5| Step: 8
Training loss: 5.793760776519775
Validation loss: 4.912519931793213

Epoch: 5| Step: 9
Training loss: 4.654599189758301
Validation loss: 4.901690065860748

Epoch: 5| Step: 10
Training loss: 4.70691442489624
Validation loss: 4.8910033504168196

Epoch: 5| Step: 11
Training loss: 4.500465393066406
Validation loss: 4.880313674608867

Epoch: 8| Step: 0
Training loss: 5.0062079429626465
Validation loss: 4.869680682818095

Epoch: 5| Step: 1
Training loss: 5.381848335266113
Validation loss: 4.858439683914185

Epoch: 5| Step: 2
Training loss: 4.032347679138184
Validation loss: 4.847932597001393

Epoch: 5| Step: 3
Training loss: 5.083569526672363
Validation loss: 4.8374948898951216

Epoch: 5| Step: 4
Training loss: 4.819774627685547
Validation loss: 4.827729761600494

Epoch: 5| Step: 5
Training loss: 4.704741477966309
Validation loss: 4.818123559157054

Epoch: 5| Step: 6
Training loss: 5.0018463134765625
Validation loss: 4.809219539165497

Epoch: 5| Step: 7
Training loss: 5.39231014251709
Validation loss: 4.800816098848979

Epoch: 5| Step: 8
Training loss: 4.869452953338623
Validation loss: 4.79224169254303

Epoch: 5| Step: 9
Training loss: 4.720766067504883
Validation loss: 4.783933023611705

Epoch: 5| Step: 10
Training loss: 5.18785285949707
Validation loss: 4.775616367657979

Epoch: 5| Step: 11
Training loss: 3.806081533432007
Validation loss: 4.767250577608745

Epoch: 9| Step: 0
Training loss: 5.801054954528809
Validation loss: 4.758835315704346

Epoch: 5| Step: 1
Training loss: 5.279067039489746
Validation loss: 4.750476777553558

Epoch: 5| Step: 2
Training loss: 4.422759056091309
Validation loss: 4.742142736911774

Epoch: 5| Step: 3
Training loss: 4.863123893737793
Validation loss: 4.733926753203074

Epoch: 5| Step: 4
Training loss: 3.8769307136535645
Validation loss: 4.726022899150848

Epoch: 5| Step: 5
Training loss: 5.291409969329834
Validation loss: 4.718249559402466

Epoch: 5| Step: 6
Training loss: 3.5848240852355957
Validation loss: 4.710305353005727

Epoch: 5| Step: 7
Training loss: 4.501585960388184
Validation loss: 4.703046381473541

Epoch: 5| Step: 8
Training loss: 5.292618751525879
Validation loss: 4.695531149705251

Epoch: 5| Step: 9
Training loss: 4.868206977844238
Validation loss: 4.6880850195884705

Epoch: 5| Step: 10
Training loss: 5.088148593902588
Validation loss: 4.680612792571385

Epoch: 5| Step: 11
Training loss: 4.975825786590576
Validation loss: 4.6725848615169525

Epoch: 10| Step: 0
Training loss: 4.565825462341309
Validation loss: 4.66474582751592

Epoch: 5| Step: 1
Training loss: 3.9110801219940186
Validation loss: 4.65718408425649

Epoch: 5| Step: 2
Training loss: 4.341804027557373
Validation loss: 4.649701217810313

Epoch: 5| Step: 3
Training loss: 5.160531997680664
Validation loss: 4.642297188440959

Epoch: 5| Step: 4
Training loss: 4.9122843742370605
Validation loss: 4.635081887245178

Epoch: 5| Step: 5
Training loss: 5.03951358795166
Validation loss: 4.627637505531311

Epoch: 5| Step: 6
Training loss: 4.411616325378418
Validation loss: 4.620020667711894

Epoch: 5| Step: 7
Training loss: 4.730923175811768
Validation loss: 4.614003121852875

Epoch: 5| Step: 8
Training loss: 4.95989465713501
Validation loss: 4.607207993666331

Epoch: 5| Step: 9
Training loss: 5.227476596832275
Validation loss: 4.6009987990061445

Epoch: 5| Step: 10
Training loss: 4.604656219482422
Validation loss: 4.594405035177867

Epoch: 5| Step: 11
Training loss: 5.191200256347656
Validation loss: 4.588199853897095

Epoch: 11| Step: 0
Training loss: 5.225224018096924
Validation loss: 4.581956068674724

Epoch: 5| Step: 1
Training loss: 4.4235310554504395
Validation loss: 4.576451142628987

Epoch: 5| Step: 2
Training loss: 4.91558313369751
Validation loss: 4.570488293965657

Epoch: 5| Step: 3
Training loss: 4.828796863555908
Validation loss: 4.564524372418721

Epoch: 5| Step: 4
Training loss: 4.891880989074707
Validation loss: 4.55872627099355

Epoch: 5| Step: 5
Training loss: 4.612576007843018
Validation loss: 4.552893241246541

Epoch: 5| Step: 6
Training loss: 4.7237443923950195
Validation loss: 4.546847860018413

Epoch: 5| Step: 7
Training loss: 4.654287815093994
Validation loss: 4.540824105342229

Epoch: 5| Step: 8
Training loss: 4.503697395324707
Validation loss: 4.53545484940211

Epoch: 5| Step: 9
Training loss: 4.1960859298706055
Validation loss: 4.529059747854869

Epoch: 5| Step: 10
Training loss: 3.9685065746307373
Validation loss: 4.523161977529526

Epoch: 5| Step: 11
Training loss: 5.978962421417236
Validation loss: 4.517285585403442

Epoch: 12| Step: 0
Training loss: 4.753417015075684
Validation loss: 4.511596540609996

Epoch: 5| Step: 1
Training loss: 5.24294376373291
Validation loss: 4.505668133497238

Epoch: 5| Step: 2
Training loss: 4.883014678955078
Validation loss: 4.49954538544019

Epoch: 5| Step: 3
Training loss: 4.47479772567749
Validation loss: 4.493013302485148

Epoch: 5| Step: 4
Training loss: 4.791840076446533
Validation loss: 4.487425406773885

Epoch: 5| Step: 5
Training loss: 5.532126426696777
Validation loss: 4.481641987959544

Epoch: 5| Step: 6
Training loss: 4.795642852783203
Validation loss: 4.475690652926763

Epoch: 5| Step: 7
Training loss: 3.5839195251464844
Validation loss: 4.469916085402171

Epoch: 5| Step: 8
Training loss: 3.328996181488037
Validation loss: 4.46444367369016

Epoch: 5| Step: 9
Training loss: 4.726419448852539
Validation loss: 4.458555281162262

Epoch: 5| Step: 10
Training loss: 4.189783573150635
Validation loss: 4.452491889397304

Epoch: 5| Step: 11
Training loss: 5.533487796783447
Validation loss: 4.4470696449279785

Epoch: 13| Step: 0
Training loss: 4.646073341369629
Validation loss: 4.441226661205292

Epoch: 5| Step: 1
Training loss: 4.121917724609375
Validation loss: 4.434924046198527

Epoch: 5| Step: 2
Training loss: 4.505722999572754
Validation loss: 4.4292559425036115

Epoch: 5| Step: 3
Training loss: 4.58405065536499
Validation loss: 4.422934780518214

Epoch: 5| Step: 4
Training loss: 4.79668664932251
Validation loss: 4.4174922207991285

Epoch: 5| Step: 5
Training loss: 4.565705299377441
Validation loss: 4.411404569943746

Epoch: 5| Step: 6
Training loss: 4.0832929611206055
Validation loss: 4.405569901069005

Epoch: 5| Step: 7
Training loss: 5.905500888824463
Validation loss: 4.399914503097534

Epoch: 5| Step: 8
Training loss: 4.0050787925720215
Validation loss: 4.394182066122691

Epoch: 5| Step: 9
Training loss: 4.213671684265137
Validation loss: 4.388960023721059

Epoch: 5| Step: 10
Training loss: 4.4033708572387695
Validation loss: 4.383127411206563

Epoch: 5| Step: 11
Training loss: 4.355327606201172
Validation loss: 4.377575933933258

Epoch: 14| Step: 0
Training loss: 4.8992767333984375
Validation loss: 4.371894419193268

Epoch: 5| Step: 1
Training loss: 3.9964778423309326
Validation loss: 4.367146501938502

Epoch: 5| Step: 2
Training loss: 4.203259468078613
Validation loss: 4.361641665299733

Epoch: 5| Step: 3
Training loss: 5.260958671569824
Validation loss: 4.3572090069452925

Epoch: 5| Step: 4
Training loss: 5.066936492919922
Validation loss: 4.351299146811168

Epoch: 5| Step: 5
Training loss: 4.3276519775390625
Validation loss: 4.346116612354915

Epoch: 5| Step: 6
Training loss: 4.721743106842041
Validation loss: 4.340796649456024

Epoch: 5| Step: 7
Training loss: 3.3411872386932373
Validation loss: 4.335734794537227

Epoch: 5| Step: 8
Training loss: 4.486363410949707
Validation loss: 4.330383092164993

Epoch: 5| Step: 9
Training loss: 5.073548316955566
Validation loss: 4.325561583042145

Epoch: 5| Step: 10
Training loss: 3.68822979927063
Validation loss: 4.320446580648422

Epoch: 5| Step: 11
Training loss: 4.793481349945068
Validation loss: 4.314824561278026

Epoch: 15| Step: 0
Training loss: 4.152895927429199
Validation loss: 4.310078312953313

Epoch: 5| Step: 1
Training loss: 5.5368547439575195
Validation loss: 4.304332902034123

Epoch: 5| Step: 2
Training loss: 3.757875919342041
Validation loss: 4.298991521199544

Epoch: 5| Step: 3
Training loss: 3.866797924041748
Validation loss: 4.293058216571808

Epoch: 5| Step: 4
Training loss: 4.003242492675781
Validation loss: 4.2876385649045305

Epoch: 5| Step: 5
Training loss: 4.474241733551025
Validation loss: 4.2821869651476545

Epoch: 5| Step: 6
Training loss: 5.392889976501465
Validation loss: 4.277404616276423

Epoch: 5| Step: 7
Training loss: 4.010282516479492
Validation loss: 4.271400322516759

Epoch: 5| Step: 8
Training loss: 4.2259931564331055
Validation loss: 4.265914678573608

Epoch: 5| Step: 9
Training loss: 5.161672592163086
Validation loss: 4.260091801484426

Epoch: 5| Step: 10
Training loss: 4.205904960632324
Validation loss: 4.254073162873586

Epoch: 5| Step: 11
Training loss: 2.8928029537200928
Validation loss: 4.248562892278035

Epoch: 16| Step: 0
Training loss: 3.4444897174835205
Validation loss: 4.243399113416672

Epoch: 5| Step: 1
Training loss: 3.87396240234375
Validation loss: 4.238813042640686

Epoch: 5| Step: 2
Training loss: 3.8014590740203857
Validation loss: 4.233170072237651

Epoch: 5| Step: 3
Training loss: 5.056966304779053
Validation loss: 4.227016001939774

Epoch: 5| Step: 4
Training loss: 5.582333564758301
Validation loss: 4.222311119238536

Epoch: 5| Step: 5
Training loss: 4.308193683624268
Validation loss: 4.216712087392807

Epoch: 5| Step: 6
Training loss: 4.696774959564209
Validation loss: 4.2111326058705645

Epoch: 5| Step: 7
Training loss: 4.369956970214844
Validation loss: 4.205210377772649

Epoch: 5| Step: 8
Training loss: 5.029126167297363
Validation loss: 4.200047413508098

Epoch: 5| Step: 9
Training loss: 3.755249500274658
Validation loss: 4.194350143273671

Epoch: 5| Step: 10
Training loss: 4.326003074645996
Validation loss: 4.1888086299101515

Epoch: 5| Step: 11
Training loss: 2.260894775390625
Validation loss: 4.1830703516801195

Epoch: 17| Step: 0
Training loss: 4.785209655761719
Validation loss: 4.178584973017375

Epoch: 5| Step: 1
Training loss: 4.079598426818848
Validation loss: 4.174205879370372

Epoch: 5| Step: 2
Training loss: 4.403103351593018
Validation loss: 4.168208460013072

Epoch: 5| Step: 3
Training loss: 3.600670576095581
Validation loss: 4.163149853547414

Epoch: 5| Step: 4
Training loss: 4.578129768371582
Validation loss: 4.158506294091542

Epoch: 5| Step: 5
Training loss: 4.431106090545654
Validation loss: 4.153954764207204

Epoch: 5| Step: 6
Training loss: 3.371739149093628
Validation loss: 4.148754467566808

Epoch: 5| Step: 7
Training loss: 4.3114142417907715
Validation loss: 4.143426418304443

Epoch: 5| Step: 8
Training loss: 4.782785892486572
Validation loss: 4.13797069589297

Epoch: 5| Step: 9
Training loss: 4.071031093597412
Validation loss: 4.133605023225148

Epoch: 5| Step: 10
Training loss: 4.353102207183838
Validation loss: 4.128141303857167

Epoch: 5| Step: 11
Training loss: 6.384553909301758
Validation loss: 4.122984478871028

Epoch: 18| Step: 0
Training loss: 3.832831859588623
Validation loss: 4.118793189525604

Epoch: 5| Step: 1
Training loss: 4.609170436859131
Validation loss: 4.113616893688838

Epoch: 5| Step: 2
Training loss: 3.78578519821167
Validation loss: 4.107529143492381

Epoch: 5| Step: 3
Training loss: 3.719393253326416
Validation loss: 4.1027911603450775

Epoch: 5| Step: 4
Training loss: 3.892516613006592
Validation loss: 4.098151872555415

Epoch: 5| Step: 5
Training loss: 4.624337673187256
Validation loss: 4.093969961007436

Epoch: 5| Step: 6
Training loss: 4.533694744110107
Validation loss: 4.088260809580485

Epoch: 5| Step: 7
Training loss: 4.569591999053955
Validation loss: 4.0835067431132

Epoch: 5| Step: 8
Training loss: 4.452952861785889
Validation loss: 4.078945716222127

Epoch: 5| Step: 9
Training loss: 4.2873029708862305
Validation loss: 4.07433807849884

Epoch: 5| Step: 10
Training loss: 4.102524757385254
Validation loss: 4.068472772836685

Epoch: 5| Step: 11
Training loss: 4.986248016357422
Validation loss: 4.063470492760341

Epoch: 19| Step: 0
Training loss: 3.8775851726531982
Validation loss: 4.059047798315684

Epoch: 5| Step: 1
Training loss: 3.8920795917510986
Validation loss: 4.0550756752491

Epoch: 5| Step: 2
Training loss: 4.749918460845947
Validation loss: 4.049397786458333

Epoch: 5| Step: 3
Training loss: 3.738762378692627
Validation loss: 4.044389843940735

Epoch: 5| Step: 4
Training loss: 3.4919142723083496
Validation loss: 4.039583384990692

Epoch: 5| Step: 5
Training loss: 4.217411994934082
Validation loss: 4.035975048939387

Epoch: 5| Step: 6
Training loss: 4.288435935974121
Validation loss: 4.029676179091136

Epoch: 5| Step: 7
Training loss: 5.988601207733154
Validation loss: 4.025546799103419

Epoch: 5| Step: 8
Training loss: 3.8888702392578125
Validation loss: 4.020803441603978

Epoch: 5| Step: 9
Training loss: 3.8980612754821777
Validation loss: 4.016372978687286

Epoch: 5| Step: 10
Training loss: 3.7606041431427
Validation loss: 4.011368731657664

Epoch: 5| Step: 11
Training loss: 5.011532783508301
Validation loss: 4.0065029462178545

Epoch: 20| Step: 0
Training loss: 3.709160327911377
Validation loss: 4.001967092355092

Epoch: 5| Step: 1
Training loss: 4.09298849105835
Validation loss: 3.9986206193765006

Epoch: 5| Step: 2
Training loss: 4.113184928894043
Validation loss: 3.9937438567479453

Epoch: 5| Step: 3
Training loss: 5.214138984680176
Validation loss: 3.988325814406077

Epoch: 5| Step: 4
Training loss: 3.178576946258545
Validation loss: 3.9831481873989105

Epoch: 5| Step: 5
Training loss: 4.588809013366699
Validation loss: 3.9791592558224997

Epoch: 5| Step: 6
Training loss: 3.2902302742004395
Validation loss: 3.9748450418313346

Epoch: 5| Step: 7
Training loss: 4.5738067626953125
Validation loss: 3.969984918832779

Epoch: 5| Step: 8
Training loss: 4.208937644958496
Validation loss: 3.965393046538035

Epoch: 5| Step: 9
Training loss: 4.039889812469482
Validation loss: 3.960742473602295

Epoch: 5| Step: 10
Training loss: 3.9570908546447754
Validation loss: 3.9562880198160806

Epoch: 5| Step: 11
Training loss: 6.165306091308594
Validation loss: 3.9523437321186066

Epoch: 21| Step: 0
Training loss: 4.049306869506836
Validation loss: 3.9476974606513977

Epoch: 5| Step: 1
Training loss: 3.7255375385284424
Validation loss: 3.9435638785362244

Epoch: 5| Step: 2
Training loss: 4.246040344238281
Validation loss: 3.9386520286401114

Epoch: 5| Step: 3
Training loss: 3.813816785812378
Validation loss: 3.9337125221888223

Epoch: 5| Step: 4
Training loss: 4.085711479187012
Validation loss: 3.9294328888257346

Epoch: 5| Step: 5
Training loss: 4.620828628540039
Validation loss: 3.925249715646108

Epoch: 5| Step: 6
Training loss: 4.273476600646973
Validation loss: 3.9212539891401925

Epoch: 5| Step: 7
Training loss: 3.9798362255096436
Validation loss: 3.9173039197921753

Epoch: 5| Step: 8
Training loss: 4.565788269042969
Validation loss: 3.9123784005641937

Epoch: 5| Step: 9
Training loss: 4.056453704833984
Validation loss: 3.9079174598058066

Epoch: 5| Step: 10
Training loss: 3.301474094390869
Validation loss: 3.9039955039819083

Epoch: 5| Step: 11
Training loss: 4.508893013000488
Validation loss: 3.9023810227711997

Epoch: 22| Step: 0
Training loss: 5.131522178649902
Validation loss: 3.895246704419454

Epoch: 5| Step: 1
Training loss: 3.378171443939209
Validation loss: 3.89067276318868

Epoch: 5| Step: 2
Training loss: 4.9024338722229
Validation loss: 3.8870029946168265

Epoch: 5| Step: 3
Training loss: 4.211874961853027
Validation loss: 3.883575121561686

Epoch: 5| Step: 4
Training loss: 3.6765105724334717
Validation loss: 3.879385451475779

Epoch: 5| Step: 5
Training loss: 3.394299030303955
Validation loss: 3.8749596377213797

Epoch: 5| Step: 6
Training loss: 3.900343418121338
Validation loss: 3.869463841120402

Epoch: 5| Step: 7
Training loss: 3.8247947692871094
Validation loss: 3.865018834670385

Epoch: 5| Step: 8
Training loss: 4.4552106857299805
Validation loss: 3.8612496058146157

Epoch: 5| Step: 9
Training loss: 2.7144675254821777
Validation loss: 3.8568896551926932

Epoch: 5| Step: 10
Training loss: 4.784651756286621
Validation loss: 3.8523689210414886

Epoch: 5| Step: 11
Training loss: 3.640808582305908
Validation loss: 3.8484884003798165

Epoch: 23| Step: 0
Training loss: 3.3603813648223877
Validation loss: 3.8437458872795105

Epoch: 5| Step: 1
Training loss: 4.219217300415039
Validation loss: 3.839393307765325

Epoch: 5| Step: 2
Training loss: 4.311399936676025
Validation loss: 3.8352951606114707

Epoch: 5| Step: 3
Training loss: 2.8912596702575684
Validation loss: 3.8302354514598846

Epoch: 5| Step: 4
Training loss: 4.4868011474609375
Validation loss: 3.8261062701543174

Epoch: 5| Step: 5
Training loss: 4.11465311050415
Validation loss: 3.821894963582357

Epoch: 5| Step: 6
Training loss: 3.5535247325897217
Validation loss: 3.8178918063640594

Epoch: 5| Step: 7
Training loss: 4.707463264465332
Validation loss: 3.813365638256073

Epoch: 5| Step: 8
Training loss: 3.744143009185791
Validation loss: 3.8093921343485513

Epoch: 5| Step: 9
Training loss: 4.282751083374023
Validation loss: 3.805830736955007

Epoch: 5| Step: 10
Training loss: 4.413238525390625
Validation loss: 3.8006298343340554

Epoch: 5| Step: 11
Training loss: 2.2588205337524414
Validation loss: 3.7959423661231995

Epoch: 24| Step: 0
Training loss: 4.354357719421387
Validation loss: 3.7926962474981942

Epoch: 5| Step: 1
Training loss: 3.8057034015655518
Validation loss: 3.7890237073103585

Epoch: 5| Step: 2
Training loss: 3.2056891918182373
Validation loss: 3.784951994816462

Epoch: 5| Step: 3
Training loss: 4.309479236602783
Validation loss: 3.7815790871779122

Epoch: 5| Step: 4
Training loss: 3.586024522781372
Validation loss: 3.777755916118622

Epoch: 5| Step: 5
Training loss: 4.179686546325684
Validation loss: 3.773590902487437

Epoch: 5| Step: 6
Training loss: 3.7651875019073486
Validation loss: 3.7698987921079

Epoch: 5| Step: 7
Training loss: 3.0478129386901855
Validation loss: 3.765668511390686

Epoch: 5| Step: 8
Training loss: 4.156426429748535
Validation loss: 3.761426568031311

Epoch: 5| Step: 9
Training loss: 4.5070037841796875
Validation loss: 3.7574693659941354

Epoch: 5| Step: 10
Training loss: 4.132065296173096
Validation loss: 3.7530061105887094

Epoch: 5| Step: 11
Training loss: 4.8774871826171875
Validation loss: 3.7488172749678292

Epoch: 25| Step: 0
Training loss: 3.189119577407837
Validation loss: 3.7446275850137076

Epoch: 5| Step: 1
Training loss: 3.464451551437378
Validation loss: 3.7403275867303214

Epoch: 5| Step: 2
Training loss: 4.448913097381592
Validation loss: 3.7365202407042184

Epoch: 5| Step: 3
Training loss: 4.203948974609375
Validation loss: 3.7325745026270547

Epoch: 5| Step: 4
Training loss: 3.488548994064331
Validation loss: 3.728075534105301

Epoch: 5| Step: 5
Training loss: 2.9669861793518066
Validation loss: 3.724280963341395

Epoch: 5| Step: 6
Training loss: 4.2197265625
Validation loss: 3.720456530650457

Epoch: 5| Step: 7
Training loss: 4.796091556549072
Validation loss: 3.716159681479136

Epoch: 5| Step: 8
Training loss: 3.4376513957977295
Validation loss: 3.712130149205526

Epoch: 5| Step: 9
Training loss: 4.322836399078369
Validation loss: 3.7081993917624154

Epoch: 5| Step: 10
Training loss: 3.9646804332733154
Validation loss: 3.704382300376892

Epoch: 5| Step: 11
Training loss: 4.969776153564453
Validation loss: 3.7002683679262796

Epoch: 26| Step: 0
Training loss: 3.626793622970581
Validation loss: 3.6966123382250466

Epoch: 5| Step: 1
Training loss: 4.034487724304199
Validation loss: 3.692167262236277

Epoch: 5| Step: 2
Training loss: 4.071619987487793
Validation loss: 3.6883971095085144

Epoch: 5| Step: 3
Training loss: 2.846163511276245
Validation loss: 3.683965881665548

Epoch: 5| Step: 4
Training loss: 4.030067443847656
Validation loss: 3.679992993672689

Epoch: 5| Step: 5
Training loss: 4.681222915649414
Validation loss: 3.676431804895401

Epoch: 5| Step: 6
Training loss: 4.325990200042725
Validation loss: 3.671994596719742

Epoch: 5| Step: 7
Training loss: 3.2540669441223145
Validation loss: 3.6669626335302987

Epoch: 5| Step: 8
Training loss: 3.3606815338134766
Validation loss: 3.663221776485443

Epoch: 5| Step: 9
Training loss: 4.176653861999512
Validation loss: 3.6596911350886026

Epoch: 5| Step: 10
Training loss: 3.752577304840088
Validation loss: 3.6557315289974213

Epoch: 5| Step: 11
Training loss: 4.029055118560791
Validation loss: 3.6513806879520416

Epoch: 27| Step: 0
Training loss: 4.133172512054443
Validation loss: 3.6466930508613586

Epoch: 5| Step: 1
Training loss: 3.5321459770202637
Validation loss: 3.6424619952837625

Epoch: 5| Step: 2
Training loss: 2.7282497882843018
Validation loss: 3.637959212064743

Epoch: 5| Step: 3
Training loss: 3.815162181854248
Validation loss: 3.6338131626447043

Epoch: 5| Step: 4
Training loss: 4.2875847816467285
Validation loss: 3.630822012821833

Epoch: 5| Step: 5
Training loss: 4.2224555015563965
Validation loss: 3.6257600486278534

Epoch: 5| Step: 6
Training loss: 4.003958225250244
Validation loss: 3.621790627638499

Epoch: 5| Step: 7
Training loss: 3.494982957839966
Validation loss: 3.6176772117614746

Epoch: 5| Step: 8
Training loss: 3.2745113372802734
Validation loss: 3.61331515510877

Epoch: 5| Step: 9
Training loss: 3.873577117919922
Validation loss: 3.612481047709783

Epoch: 5| Step: 10
Training loss: 4.542307376861572
Validation loss: 3.6048735777537027

Epoch: 5| Step: 11
Training loss: 2.667200803756714
Validation loss: 3.60049440463384

Epoch: 28| Step: 0
Training loss: 3.486910581588745
Validation loss: 3.596227765083313

Epoch: 5| Step: 1
Training loss: 3.907705783843994
Validation loss: 3.592583159605662

Epoch: 5| Step: 2
Training loss: 4.066023826599121
Validation loss: 3.5885075827439628

Epoch: 5| Step: 3
Training loss: 4.178116321563721
Validation loss: 3.5843322475751243

Epoch: 5| Step: 4
Training loss: 3.607112169265747
Validation loss: 3.5799234410127005

Epoch: 5| Step: 5
Training loss: 3.1033935546875
Validation loss: 3.5756334563096366

Epoch: 5| Step: 6
Training loss: 4.240370750427246
Validation loss: 3.5705821911493936

Epoch: 5| Step: 7
Training loss: 4.1709489822387695
Validation loss: 3.5662905971209207

Epoch: 5| Step: 8
Training loss: 3.9332573413848877
Validation loss: 3.562191387017568

Epoch: 5| Step: 9
Training loss: 3.031052350997925
Validation loss: 3.557740092277527

Epoch: 5| Step: 10
Training loss: 3.134087085723877
Validation loss: 3.5534982879956565

Epoch: 5| Step: 11
Training loss: 5.150029182434082
Validation loss: 3.550306816895803

Epoch: 29| Step: 0
Training loss: 3.846275806427002
Validation loss: 3.5452460646629333

Epoch: 5| Step: 1
Training loss: 3.99750018119812
Validation loss: 3.5430340071519217

Epoch: 5| Step: 2
Training loss: 3.850348949432373
Validation loss: 3.5374844074249268

Epoch: 5| Step: 3
Training loss: 3.3833632469177246
Validation loss: 3.5332483847935996

Epoch: 5| Step: 4
Training loss: 3.190288543701172
Validation loss: 3.5292409658432007

Epoch: 5| Step: 5
Training loss: 3.144345760345459
Validation loss: 3.525618016719818

Epoch: 5| Step: 6
Training loss: 4.887202262878418
Validation loss: 3.524730086326599

Epoch: 5| Step: 7
Training loss: 3.590784788131714
Validation loss: 3.5177008907000222

Epoch: 5| Step: 8
Training loss: 3.6682677268981934
Validation loss: 3.5130795935789743

Epoch: 5| Step: 9
Training loss: 3.0198850631713867
Validation loss: 3.5095924039681754

Epoch: 5| Step: 10
Training loss: 4.1082444190979
Validation loss: 3.5052462816238403

Epoch: 5| Step: 11
Training loss: 3.1699814796447754
Validation loss: 3.5015976428985596

Epoch: 30| Step: 0
Training loss: 4.018327713012695
Validation loss: 3.4977067013581595

Epoch: 5| Step: 1
Training loss: 2.6032092571258545
Validation loss: 3.492707302172979

Epoch: 5| Step: 2
Training loss: 4.497837066650391
Validation loss: 3.4883715510368347

Epoch: 5| Step: 3
Training loss: 3.0336742401123047
Validation loss: 3.4839227298895517

Epoch: 5| Step: 4
Training loss: 3.1585440635681152
Validation loss: 3.4818774859110513

Epoch: 5| Step: 5
Training loss: 4.141305446624756
Validation loss: 3.4772187074025473

Epoch: 5| Step: 6
Training loss: 3.7077014446258545
Validation loss: 3.4733217656612396

Epoch: 5| Step: 7
Training loss: 3.763927459716797
Validation loss: 3.4719726939996085

Epoch: 5| Step: 8
Training loss: 4.065398216247559
Validation loss: 3.4694427251815796

Epoch: 5| Step: 9
Training loss: 3.4712741374969482
Validation loss: 3.4600841800371804

Epoch: 5| Step: 10
Training loss: 3.9142982959747314
Validation loss: 3.4586783250172934

Epoch: 5| Step: 11
Training loss: 2.124253749847412
Validation loss: 3.457455039024353

Epoch: 31| Step: 0
Training loss: 3.197883129119873
Validation loss: 3.4518719017505646

Epoch: 5| Step: 1
Training loss: 3.469453811645508
Validation loss: 3.447160313526789

Epoch: 5| Step: 2
Training loss: 3.4223945140838623
Validation loss: 3.4431171218554177

Epoch: 5| Step: 3
Training loss: 3.476179838180542
Validation loss: 3.43992613752683

Epoch: 5| Step: 4
Training loss: 4.008151531219482
Validation loss: 3.4343598186969757

Epoch: 5| Step: 5
Training loss: 2.989119291305542
Validation loss: 3.4287067453066506

Epoch: 5| Step: 6
Training loss: 3.829186201095581
Validation loss: 3.4233237405618033

Epoch: 5| Step: 7
Training loss: 4.094149589538574
Validation loss: 3.4179399013519287

Epoch: 5| Step: 8
Training loss: 4.1407670974731445
Validation loss: 3.413776089747747

Epoch: 5| Step: 9
Training loss: 3.761441707611084
Validation loss: 3.409814109404882

Epoch: 5| Step: 10
Training loss: 3.0826268196105957
Validation loss: 3.4056984782218933

Epoch: 5| Step: 11
Training loss: 4.071380615234375
Validation loss: 3.4030873278776803

Epoch: 32| Step: 0
Training loss: 4.380736351013184
Validation loss: 3.3993583619594574

Epoch: 5| Step: 1
Training loss: 3.780956745147705
Validation loss: 3.395086169242859

Epoch: 5| Step: 2
Training loss: 3.959524631500244
Validation loss: 3.3887492418289185

Epoch: 5| Step: 3
Training loss: 2.754833936691284
Validation loss: 3.3853719830513

Epoch: 5| Step: 4
Training loss: 3.0454933643341064
Validation loss: 3.3810921907424927

Epoch: 5| Step: 5
Training loss: 3.4565443992614746
Validation loss: 3.376732458670934

Epoch: 5| Step: 6
Training loss: 3.623504638671875
Validation loss: 3.373101065556208

Epoch: 5| Step: 7
Training loss: 3.1063790321350098
Validation loss: 3.368668347597122

Epoch: 5| Step: 8
Training loss: 3.369663953781128
Validation loss: 3.3645937939484916

Epoch: 5| Step: 9
Training loss: 4.155987739562988
Validation loss: 3.361243615547816

Epoch: 5| Step: 10
Training loss: 3.4716122150421143
Validation loss: 3.3575182060400643

Epoch: 5| Step: 11
Training loss: 3.026632308959961
Validation loss: 3.35334645708402

Epoch: 33| Step: 0
Training loss: 3.6171317100524902
Validation loss: 3.3494824965794883

Epoch: 5| Step: 1
Training loss: 3.6190974712371826
Validation loss: 3.3449426194032035

Epoch: 5| Step: 2
Training loss: 3.2155280113220215
Validation loss: 3.3402523696422577

Epoch: 5| Step: 3
Training loss: 3.739943027496338
Validation loss: 3.3359374006589255

Epoch: 5| Step: 4
Training loss: 3.51579213142395
Validation loss: 3.331561714410782

Epoch: 5| Step: 5
Training loss: 4.190881252288818
Validation loss: 3.327133427063624

Epoch: 5| Step: 6
Training loss: 3.027535915374756
Validation loss: 3.3232871890068054

Epoch: 5| Step: 7
Training loss: 3.4533801078796387
Validation loss: 3.3190271059672036

Epoch: 5| Step: 8
Training loss: 2.921727180480957
Validation loss: 3.315879374742508

Epoch: 5| Step: 9
Training loss: 3.9194977283477783
Validation loss: 3.31305726369222

Epoch: 5| Step: 10
Training loss: 3.7694954872131348
Validation loss: 3.311408837636312

Epoch: 5| Step: 11
Training loss: 1.088965654373169
Validation loss: 3.308292885621389

Epoch: 34| Step: 0
Training loss: 2.9661316871643066
Validation loss: 3.30673681696256

Epoch: 5| Step: 1
Training loss: 2.927957773208618
Validation loss: 3.2986781100432077

Epoch: 5| Step: 2
Training loss: 3.268256425857544
Validation loss: 3.294720858335495

Epoch: 5| Step: 3
Training loss: 3.368363857269287
Validation loss: 3.290508965651194

Epoch: 5| Step: 4
Training loss: 4.147259712219238
Validation loss: 3.2909609973430634

Epoch: 5| Step: 5
Training loss: 2.293872117996216
Validation loss: 3.283294121424357

Epoch: 5| Step: 6
Training loss: 4.0603346824646
Validation loss: 3.277274787425995

Epoch: 5| Step: 7
Training loss: 3.914149045944214
Validation loss: 3.274317185084025

Epoch: 5| Step: 8
Training loss: 3.335697889328003
Validation loss: 3.27099816997846

Epoch: 5| Step: 9
Training loss: 3.7878174781799316
Validation loss: 3.2667389114697776

Epoch: 5| Step: 10
Training loss: 4.041415214538574
Validation loss: 3.262920449177424

Epoch: 5| Step: 11
Training loss: 3.095913887023926
Validation loss: 3.260106305281321

Epoch: 35| Step: 0
Training loss: 4.197779178619385
Validation loss: 3.2562851905822754

Epoch: 5| Step: 1
Training loss: 2.6383519172668457
Validation loss: 3.252274841070175

Epoch: 5| Step: 2
Training loss: 3.483778476715088
Validation loss: 3.2472007075945535

Epoch: 5| Step: 3
Training loss: 4.142692565917969
Validation loss: 3.2445081571737924

Epoch: 5| Step: 4
Training loss: 2.9937691688537598
Validation loss: 3.239706893761953

Epoch: 5| Step: 5
Training loss: 3.052170991897583
Validation loss: 3.236503173907598

Epoch: 5| Step: 6
Training loss: 2.846139669418335
Validation loss: 3.232278823852539

Epoch: 5| Step: 7
Training loss: 2.987675189971924
Validation loss: 3.229580541451772

Epoch: 5| Step: 8
Training loss: 3.7948386669158936
Validation loss: 3.2260280648867288

Epoch: 5| Step: 9
Training loss: 3.375082015991211
Validation loss: 3.222399026155472

Epoch: 5| Step: 10
Training loss: 4.087468147277832
Validation loss: 3.2198360164960227

Epoch: 5| Step: 11
Training loss: 3.258343458175659
Validation loss: 3.2175331711769104

Epoch: 36| Step: 0
Training loss: 2.8172359466552734
Validation loss: 3.2144913574059806

Epoch: 5| Step: 1
Training loss: 3.43450665473938
Validation loss: 3.2103307644526162

Epoch: 5| Step: 2
Training loss: 3.2451558113098145
Validation loss: 3.2049886087576547

Epoch: 5| Step: 3
Training loss: 4.011125087738037
Validation loss: 3.2006774048010507

Epoch: 5| Step: 4
Training loss: 3.1634886264801025
Validation loss: 3.1964585880438485

Epoch: 5| Step: 5
Training loss: 3.640129804611206
Validation loss: 3.1918339133262634

Epoch: 5| Step: 6
Training loss: 3.0871310234069824
Validation loss: 3.1881172756354013

Epoch: 5| Step: 7
Training loss: 3.0440313816070557
Validation loss: 3.183719058831533

Epoch: 5| Step: 8
Training loss: 3.927809238433838
Validation loss: 3.1798964540163674

Epoch: 5| Step: 9
Training loss: 2.679699182510376
Validation loss: 3.176398823658625

Epoch: 5| Step: 10
Training loss: 3.941317319869995
Validation loss: 3.1733003755410514

Epoch: 5| Step: 11
Training loss: 4.029517650604248
Validation loss: 3.1691884299119315

Epoch: 37| Step: 0
Training loss: 3.5638484954833984
Validation loss: 3.165333171685537

Epoch: 5| Step: 1
Training loss: 2.1947290897369385
Validation loss: 3.1627143224080405

Epoch: 5| Step: 2
Training loss: 3.8339104652404785
Validation loss: 3.1581980486710868

Epoch: 5| Step: 3
Training loss: 3.256572723388672
Validation loss: 3.156113624572754

Epoch: 5| Step: 4
Training loss: 3.9461212158203125
Validation loss: 3.150833080212275

Epoch: 5| Step: 5
Training loss: 3.7639212608337402
Validation loss: 3.1471570829550424

Epoch: 5| Step: 6
Training loss: 2.594275951385498
Validation loss: 3.1424425343672433

Epoch: 5| Step: 7
Training loss: 3.6184897422790527
Validation loss: 3.1384405394395194

Epoch: 5| Step: 8
Training loss: 3.1553595066070557
Validation loss: 3.1351730624834695

Epoch: 5| Step: 9
Training loss: 3.395825147628784
Validation loss: 3.1306705474853516

Epoch: 5| Step: 10
Training loss: 3.0579071044921875
Validation loss: 3.1267323394616446

Epoch: 5| Step: 11
Training loss: 4.582417964935303
Validation loss: 3.125450909137726

Epoch: 38| Step: 0
Training loss: 3.6734156608581543
Validation loss: 3.120550105969111

Epoch: 5| Step: 1
Training loss: 3.8789279460906982
Validation loss: 3.1151743034521737

Epoch: 5| Step: 2
Training loss: 2.2909674644470215
Validation loss: 3.1141815384229026

Epoch: 5| Step: 3
Training loss: 3.8133575916290283
Validation loss: 3.113481968641281

Epoch: 5| Step: 4
Training loss: 2.5645341873168945
Validation loss: 3.1035682360331216

Epoch: 5| Step: 5
Training loss: 2.455798387527466
Validation loss: 3.099390983581543

Epoch: 5| Step: 6
Training loss: 3.3115944862365723
Validation loss: 3.0956770479679108

Epoch: 5| Step: 7
Training loss: 3.4667911529541016
Validation loss: 3.092229813337326

Epoch: 5| Step: 8
Training loss: 3.4199321269989014
Validation loss: 3.0890114307403564

Epoch: 5| Step: 9
Training loss: 3.5737266540527344
Validation loss: 3.085777372121811

Epoch: 5| Step: 10
Training loss: 3.7984421253204346
Validation loss: 3.082820067803065

Epoch: 5| Step: 11
Training loss: 2.860804319381714
Validation loss: 3.079318881034851

Epoch: 39| Step: 0
Training loss: 2.7020926475524902
Validation loss: 3.0758232275644937

Epoch: 5| Step: 1
Training loss: 3.1933035850524902
Validation loss: 3.0725479125976562

Epoch: 5| Step: 2
Training loss: 3.448651075363159
Validation loss: 3.068816145261129

Epoch: 5| Step: 3
Training loss: 3.2679507732391357
Validation loss: 3.0654157797495523

Epoch: 5| Step: 4
Training loss: 3.3263843059539795
Validation loss: 3.061743527650833

Epoch: 5| Step: 5
Training loss: 3.016880512237549
Validation loss: 3.058126320441564

Epoch: 5| Step: 6
Training loss: 3.7697219848632812
Validation loss: 3.054540683825811

Epoch: 5| Step: 7
Training loss: 3.330230712890625
Validation loss: 3.050732990105947

Epoch: 5| Step: 8
Training loss: 3.1897025108337402
Validation loss: 3.0474351048469543

Epoch: 5| Step: 9
Training loss: 3.118068218231201
Validation loss: 3.0444739858309426

Epoch: 5| Step: 10
Training loss: 3.126258134841919
Validation loss: 3.0415741403897605

Epoch: 5| Step: 11
Training loss: 4.362666130065918
Validation loss: 3.038207471370697

Epoch: 40| Step: 0
Training loss: 2.8186259269714355
Validation loss: 3.0336605111757913

Epoch: 5| Step: 1
Training loss: 3.0634961128234863
Validation loss: 3.0295202434062958

Epoch: 5| Step: 2
Training loss: 3.132568836212158
Validation loss: 3.025915871063868

Epoch: 5| Step: 3
Training loss: 3.730065107345581
Validation loss: 3.0220856964588165

Epoch: 5| Step: 4
Training loss: 2.9566028118133545
Validation loss: 3.0188147127628326

Epoch: 5| Step: 5
Training loss: 2.9303078651428223
Validation loss: 3.0148965815703073

Epoch: 5| Step: 6
Training loss: 3.476608991622925
Validation loss: 3.0115923384825387

Epoch: 5| Step: 7
Training loss: 3.372675657272339
Validation loss: 3.0084148248036704

Epoch: 5| Step: 8
Training loss: 3.184680938720703
Validation loss: 3.004631499449412

Epoch: 5| Step: 9
Training loss: 3.3758788108825684
Validation loss: 3.000772178173065

Epoch: 5| Step: 10
Training loss: 3.2504870891571045
Validation loss: 2.997880697250366

Epoch: 5| Step: 11
Training loss: 3.0815563201904297
Validation loss: 2.99358531832695

Epoch: 41| Step: 0
Training loss: 3.526832103729248
Validation loss: 2.990218997001648

Epoch: 5| Step: 1
Training loss: 3.0229783058166504
Validation loss: 2.986656218767166

Epoch: 5| Step: 2
Training loss: 3.798144817352295
Validation loss: 2.985549966494242

Epoch: 5| Step: 3
Training loss: 2.6749958992004395
Validation loss: 2.9830865959326425

Epoch: 5| Step: 4
Training loss: 3.1335511207580566
Validation loss: 2.985188831885656

Epoch: 5| Step: 5
Training loss: 3.2596046924591064
Validation loss: 2.981428990761439

Epoch: 5| Step: 6
Training loss: 3.68174409866333
Validation loss: 2.9780306220054626

Epoch: 5| Step: 7
Training loss: 3.7179431915283203
Validation loss: 2.9706601103146872

Epoch: 5| Step: 8
Training loss: 2.633742570877075
Validation loss: 2.9656327764193215

Epoch: 5| Step: 9
Training loss: 2.9676175117492676
Validation loss: 2.960900495449702

Epoch: 5| Step: 10
Training loss: 2.8623642921447754
Validation loss: 2.958072543144226

Epoch: 5| Step: 11
Training loss: 1.1531805992126465
Validation loss: 2.9566062490145364

Epoch: 42| Step: 0
Training loss: 3.585550308227539
Validation loss: 2.9538038770357766

Epoch: 5| Step: 1
Training loss: 2.830751657485962
Validation loss: 2.9515284597873688

Epoch: 5| Step: 2
Training loss: 3.6951465606689453
Validation loss: 2.9489429593086243

Epoch: 5| Step: 3
Training loss: 3.6439099311828613
Validation loss: 2.943976938724518

Epoch: 5| Step: 4
Training loss: 3.4777634143829346
Validation loss: 2.9397594730059304

Epoch: 5| Step: 5
Training loss: 3.4139702320098877
Validation loss: 2.935484528541565

Epoch: 5| Step: 6
Training loss: 3.0692572593688965
Validation loss: 2.9323969781398773

Epoch: 5| Step: 7
Training loss: 2.7032246589660645
Validation loss: 2.92950502038002

Epoch: 5| Step: 8
Training loss: 3.1555347442626953
Validation loss: 2.9284799993038177

Epoch: 5| Step: 9
Training loss: 2.3473832607269287
Validation loss: 2.9264593025048575

Epoch: 5| Step: 10
Training loss: 2.568021059036255
Validation loss: 2.9246300955613456

Epoch: 5| Step: 11
Training loss: 3.2994418144226074
Validation loss: 2.9200295011202493

Epoch: 43| Step: 0
Training loss: 2.882199764251709
Validation loss: 2.919031471014023

Epoch: 5| Step: 1
Training loss: 2.9533023834228516
Validation loss: 2.91640442609787

Epoch: 5| Step: 2
Training loss: 3.8370203971862793
Validation loss: 2.911727180083593

Epoch: 5| Step: 3
Training loss: 3.2317020893096924
Validation loss: 2.908006012439728

Epoch: 5| Step: 4
Training loss: 2.551060199737549
Validation loss: 2.903631995121638

Epoch: 5| Step: 5
Training loss: 3.182549238204956
Validation loss: 2.900451352198919

Epoch: 5| Step: 6
Training loss: 3.086913585662842
Validation loss: 2.896557241678238

Epoch: 5| Step: 7
Training loss: 3.9520790576934814
Validation loss: 2.894049803415934

Epoch: 5| Step: 8
Training loss: 2.6968376636505127
Validation loss: 2.8917093575000763

Epoch: 5| Step: 9
Training loss: 2.5309505462646484
Validation loss: 2.8874831597010293

Epoch: 5| Step: 10
Training loss: 3.2741055488586426
Validation loss: 2.884211152791977

Epoch: 5| Step: 11
Training loss: 2.800814151763916
Validation loss: 2.8829697966575623

Epoch: 44| Step: 0
Training loss: 2.521472454071045
Validation loss: 2.879601607720057

Epoch: 5| Step: 1
Training loss: 3.1607391834259033
Validation loss: 2.879873981078466

Epoch: 5| Step: 2
Training loss: 3.5364089012145996
Validation loss: 2.8808450599511466

Epoch: 5| Step: 3
Training loss: 3.4198334217071533
Validation loss: 2.875176509221395

Epoch: 5| Step: 4
Training loss: 3.14235782623291
Validation loss: 2.870586941639582

Epoch: 5| Step: 5
Training loss: 2.4862489700317383
Validation loss: 2.866767853498459

Epoch: 5| Step: 6
Training loss: 3.3835091590881348
Validation loss: 2.8629271586736045

Epoch: 5| Step: 7
Training loss: 2.760098457336426
Validation loss: 2.859604845444361

Epoch: 5| Step: 8
Training loss: 3.406371593475342
Validation loss: 2.8546520670255027

Epoch: 5| Step: 9
Training loss: 3.4590911865234375
Validation loss: 2.8518811662991843

Epoch: 5| Step: 10
Training loss: 2.4171102046966553
Validation loss: 2.8498289485772452

Epoch: 5| Step: 11
Training loss: 3.4319536685943604
Validation loss: 2.846208393573761

Epoch: 45| Step: 0
Training loss: 2.9175829887390137
Validation loss: 2.8439380625883737

Epoch: 5| Step: 1
Training loss: 2.9149577617645264
Validation loss: 2.8401862184206643

Epoch: 5| Step: 2
Training loss: 3.2800209522247314
Validation loss: 2.8377529780069985

Epoch: 5| Step: 3
Training loss: 3.174100637435913
Validation loss: 2.83468289176623

Epoch: 5| Step: 4
Training loss: 2.8850271701812744
Validation loss: 2.8318335811297097

Epoch: 5| Step: 5
Training loss: 2.6048836708068848
Validation loss: 2.8280393282572427

Epoch: 5| Step: 6
Training loss: 2.6916873455047607
Validation loss: 2.8251113096872964

Epoch: 5| Step: 7
Training loss: 2.762908935546875
Validation loss: 2.821381688117981

Epoch: 5| Step: 8
Training loss: 3.4579784870147705
Validation loss: 2.8174734016259513

Epoch: 5| Step: 9
Training loss: 3.31306791305542
Validation loss: 2.8148997128009796

Epoch: 5| Step: 10
Training loss: 3.392202377319336
Validation loss: 2.8104830384254456

Epoch: 5| Step: 11
Training loss: 3.0918045043945312
Validation loss: 2.811386932929357

Epoch: 46| Step: 0
Training loss: 3.025606393814087
Validation loss: 2.8065949281056723

Epoch: 5| Step: 1
Training loss: 2.437467098236084
Validation loss: 2.8122557202974954

Epoch: 5| Step: 2
Training loss: 3.073416233062744
Validation loss: 2.814718008041382

Epoch: 5| Step: 3
Training loss: 3.488839626312256
Validation loss: 2.7996910512447357

Epoch: 5| Step: 4
Training loss: 3.0179028511047363
Validation loss: 2.793749292691549

Epoch: 5| Step: 5
Training loss: 3.1937198638916016
Validation loss: 2.7890376448631287

Epoch: 5| Step: 6
Training loss: 2.823840618133545
Validation loss: 2.788143903017044

Epoch: 5| Step: 7
Training loss: 2.885711193084717
Validation loss: 2.785731256008148

Epoch: 5| Step: 8
Training loss: 2.4647819995880127
Validation loss: 2.782391846179962

Epoch: 5| Step: 9
Training loss: 3.4723808765411377
Validation loss: 2.7797217071056366

Epoch: 5| Step: 10
Training loss: 3.048356056213379
Validation loss: 2.7770857314268746

Epoch: 5| Step: 11
Training loss: 3.457883358001709
Validation loss: 2.775579124689102

Epoch: 47| Step: 0
Training loss: 2.7587435245513916
Validation loss: 2.7721470097700753

Epoch: 5| Step: 1
Training loss: 2.978577136993408
Validation loss: 2.7687013943990073

Epoch: 5| Step: 2
Training loss: 3.0834577083587646
Validation loss: 2.7680370112260184

Epoch: 5| Step: 3
Training loss: 3.1158783435821533
Validation loss: 2.7643320858478546

Epoch: 5| Step: 4
Training loss: 3.3655993938446045
Validation loss: 2.760360767443975

Epoch: 5| Step: 5
Training loss: 2.94411039352417
Validation loss: 2.757866849501928

Epoch: 5| Step: 6
Training loss: 3.2252917289733887
Validation loss: 2.7545360227425895

Epoch: 5| Step: 7
Training loss: 3.332670211791992
Validation loss: 2.749348213275274

Epoch: 5| Step: 8
Training loss: 2.7397942543029785
Validation loss: 2.747187634309133

Epoch: 5| Step: 9
Training loss: 2.5114307403564453
Validation loss: 2.7463515996932983

Epoch: 5| Step: 10
Training loss: 2.4802348613739014
Validation loss: 2.7470776438713074

Epoch: 5| Step: 11
Training loss: 3.4301795959472656
Validation loss: 2.7482460041840873

Epoch: 48| Step: 0
Training loss: 3.151113510131836
Validation loss: 2.7368430296579995

Epoch: 5| Step: 1
Training loss: 2.492844820022583
Validation loss: 2.733068197965622

Epoch: 5| Step: 2
Training loss: 3.334573268890381
Validation loss: 2.7282071510950723

Epoch: 5| Step: 3
Training loss: 2.7611591815948486
Validation loss: 2.725515365600586

Epoch: 5| Step: 4
Training loss: 2.9447097778320312
Validation loss: 2.7240328590075173

Epoch: 5| Step: 5
Training loss: 2.7514142990112305
Validation loss: 2.7207414905230203

Epoch: 5| Step: 6
Training loss: 2.906423568725586
Validation loss: 2.7178921699523926

Epoch: 5| Step: 7
Training loss: 2.66705584526062
Validation loss: 2.715682546297709

Epoch: 5| Step: 8
Training loss: 2.548733711242676
Validation loss: 2.714610988895098

Epoch: 5| Step: 9
Training loss: 3.6969943046569824
Validation loss: 2.7110563615957894

Epoch: 5| Step: 10
Training loss: 2.77008318901062
Validation loss: 2.7067457338174186

Epoch: 5| Step: 11
Training loss: 3.638718366622925
Validation loss: 2.702685376008352

Epoch: 49| Step: 0
Training loss: 3.769554853439331
Validation loss: 2.6988605757554374

Epoch: 5| Step: 1
Training loss: 2.716827869415283
Validation loss: 2.6959461768468223

Epoch: 5| Step: 2
Training loss: 3.5588061809539795
Validation loss: 2.6925648748874664

Epoch: 5| Step: 3
Training loss: 2.3840420246124268
Validation loss: 2.688358118136724

Epoch: 5| Step: 4
Training loss: 3.529141664505005
Validation loss: 2.685133864482244

Epoch: 5| Step: 5
Training loss: 2.5701098442077637
Validation loss: 2.6797986328601837

Epoch: 5| Step: 6
Training loss: 2.976252794265747
Validation loss: 2.6774960656960807

Epoch: 5| Step: 7
Training loss: 1.930225133895874
Validation loss: 2.6735735535621643

Epoch: 5| Step: 8
Training loss: 2.723978042602539
Validation loss: 2.6715842882792153

Epoch: 5| Step: 9
Training loss: 2.6113650798797607
Validation loss: 2.6683698693911233

Epoch: 5| Step: 10
Training loss: 3.2470409870147705
Validation loss: 2.666008234024048

Epoch: 5| Step: 11
Training loss: 1.758193016052246
Validation loss: 2.66242187221845

Epoch: 50| Step: 0
Training loss: 2.9608936309814453
Validation loss: 2.6601499815781913

Epoch: 5| Step: 1
Training loss: 3.2064929008483887
Validation loss: 2.6582206785678864

Epoch: 5| Step: 2
Training loss: 2.711439371109009
Validation loss: 2.6559129456679025

Epoch: 5| Step: 3
Training loss: 2.4668192863464355
Validation loss: 2.655014673868815

Epoch: 5| Step: 4
Training loss: 2.3699145317077637
Validation loss: 2.651086926460266

Epoch: 5| Step: 5
Training loss: 2.7961604595184326
Validation loss: 2.658150682846705

Epoch: 5| Step: 6
Training loss: 2.298654079437256
Validation loss: 2.6520859698454538

Epoch: 5| Step: 7
Training loss: 2.2078182697296143
Validation loss: 2.6491146186987558

Epoch: 5| Step: 8
Training loss: 3.1680474281311035
Validation loss: 2.646212081114451

Epoch: 5| Step: 9
Training loss: 3.399385452270508
Validation loss: 2.6349904984235764

Epoch: 5| Step: 10
Training loss: 3.3882815837860107
Validation loss: 2.6308563152949014

Epoch: 5| Step: 11
Training loss: 4.760234832763672
Validation loss: 2.6255253752072654

Epoch: 51| Step: 0
Training loss: 2.180553913116455
Validation loss: 2.6246873438358307

Epoch: 5| Step: 1
Training loss: 2.4828503131866455
Validation loss: 2.6195864578088126

Epoch: 5| Step: 2
Training loss: 3.022073268890381
Validation loss: 2.618218610684077

Epoch: 5| Step: 3
Training loss: 2.4198310375213623
Validation loss: 2.6170531709988913

Epoch: 5| Step: 4
Training loss: 2.8170793056488037
Validation loss: 2.6148633559544883

Epoch: 5| Step: 5
Training loss: 3.049513578414917
Validation loss: 2.611247996489207

Epoch: 5| Step: 6
Training loss: 3.0445685386657715
Validation loss: 2.607103635867437

Epoch: 5| Step: 7
Training loss: 3.0016167163848877
Validation loss: 2.604983111222585

Epoch: 5| Step: 8
Training loss: 2.2432475090026855
Validation loss: 2.5985292891661325

Epoch: 5| Step: 9
Training loss: 2.85750150680542
Validation loss: 2.5972879032293954

Epoch: 5| Step: 10
Training loss: 3.7328109741210938
Validation loss: 2.5950556794802346

Epoch: 5| Step: 11
Training loss: 3.1611990928649902
Validation loss: 2.593609313170115

Epoch: 52| Step: 0
Training loss: 2.5141029357910156
Validation loss: 2.585981160402298

Epoch: 5| Step: 1
Training loss: 2.587050676345825
Validation loss: 2.5848074654738107

Epoch: 5| Step: 2
Training loss: 2.2668237686157227
Validation loss: 2.581927408774694

Epoch: 5| Step: 3
Training loss: 2.6708474159240723
Validation loss: 2.5783082644144693

Epoch: 5| Step: 4
Training loss: 2.746346950531006
Validation loss: 2.5760341684023538

Epoch: 5| Step: 5
Training loss: 2.697512149810791
Validation loss: 2.5764764149983725

Epoch: 5| Step: 6
Training loss: 2.4427402019500732
Validation loss: 2.5746314922968545

Epoch: 5| Step: 7
Training loss: 2.612795114517212
Validation loss: 2.5664678613344827

Epoch: 5| Step: 8
Training loss: 3.558804750442505
Validation loss: 2.5649549265702567

Epoch: 5| Step: 9
Training loss: 3.210158586502075
Validation loss: 2.5595737447341285

Epoch: 5| Step: 10
Training loss: 3.219008684158325
Validation loss: 2.5590594907601676

Epoch: 5| Step: 11
Training loss: 2.4064667224884033
Validation loss: 2.5562207102775574

Epoch: 53| Step: 0
Training loss: 2.576854705810547
Validation loss: 2.5551106135050454

Epoch: 5| Step: 1
Training loss: 3.2877020835876465
Validation loss: 2.553828477859497

Epoch: 5| Step: 2
Training loss: 1.9626424312591553
Validation loss: 2.551854888598124

Epoch: 5| Step: 3
Training loss: 2.9914679527282715
Validation loss: 2.5497005383173623

Epoch: 5| Step: 4
Training loss: 2.612856388092041
Validation loss: 2.5428446531295776

Epoch: 5| Step: 5
Training loss: 2.9229893684387207
Validation loss: 2.5398909548918405

Epoch: 5| Step: 6
Training loss: 2.9640259742736816
Validation loss: 2.5355829298496246

Epoch: 5| Step: 7
Training loss: 3.0830256938934326
Validation loss: 2.532708923021952

Epoch: 5| Step: 8
Training loss: 2.7566683292388916
Validation loss: 2.528624931971232

Epoch: 5| Step: 9
Training loss: 1.935177206993103
Validation loss: 2.5268613398075104

Epoch: 5| Step: 10
Training loss: 2.9391584396362305
Validation loss: 2.5257261097431183

Epoch: 5| Step: 11
Training loss: 2.894878387451172
Validation loss: 2.5161785085995994

Epoch: 54| Step: 0
Training loss: 3.0249128341674805
Validation loss: 2.514997829993566

Epoch: 5| Step: 1
Training loss: 3.0302016735076904
Validation loss: 2.514215042193731

Epoch: 5| Step: 2
Training loss: 2.6165566444396973
Validation loss: 2.509928971529007

Epoch: 5| Step: 3
Training loss: 2.6487624645233154
Validation loss: 2.506226638952891

Epoch: 5| Step: 4
Training loss: 2.031554698944092
Validation loss: 2.505511979262034

Epoch: 5| Step: 5
Training loss: 2.9394068717956543
Validation loss: 2.504463126262029

Epoch: 5| Step: 6
Training loss: 2.6483004093170166
Validation loss: 2.506561905145645

Epoch: 5| Step: 7
Training loss: 2.1776974201202393
Validation loss: 2.5103425284226737

Epoch: 5| Step: 8
Training loss: 2.507864475250244
Validation loss: 2.5068725049495697

Epoch: 5| Step: 9
Training loss: 2.9296059608459473
Validation loss: 2.5007996956507363

Epoch: 5| Step: 10
Training loss: 3.1344282627105713
Validation loss: 2.4931405087312064

Epoch: 5| Step: 11
Training loss: 2.299684762954712
Validation loss: 2.488588869571686

Epoch: 55| Step: 0
Training loss: 3.11482572555542
Validation loss: 2.4863801300525665

Epoch: 5| Step: 1
Training loss: 2.8661296367645264
Validation loss: 2.4871134956677756

Epoch: 5| Step: 2
Training loss: 2.241088390350342
Validation loss: 2.4824600716431937

Epoch: 5| Step: 3
Training loss: 2.364497423171997
Validation loss: 2.4818888356288276

Epoch: 5| Step: 4
Training loss: 3.0255417823791504
Validation loss: 2.478283792734146

Epoch: 5| Step: 5
Training loss: 2.7391178607940674
Validation loss: 2.474677046140035

Epoch: 5| Step: 6
Training loss: 2.831366539001465
Validation loss: 2.476190169652303

Epoch: 5| Step: 7
Training loss: 2.179060220718384
Validation loss: 2.4695072770118713

Epoch: 5| Step: 8
Training loss: 2.5242183208465576
Validation loss: 2.4691129128138223

Epoch: 5| Step: 9
Training loss: 2.412579298019409
Validation loss: 2.464128961165746

Epoch: 5| Step: 10
Training loss: 3.0396838188171387
Validation loss: 2.4616736471652985

Epoch: 5| Step: 11
Training loss: 2.5774197578430176
Validation loss: 2.460628887017568

Epoch: 56| Step: 0
Training loss: 2.832193613052368
Validation loss: 2.4553814431031546

Epoch: 5| Step: 1
Training loss: 2.779834747314453
Validation loss: 2.451507121324539

Epoch: 5| Step: 2
Training loss: 3.0362632274627686
Validation loss: 2.449995001157125

Epoch: 5| Step: 3
Training loss: 2.7063345909118652
Validation loss: 2.4453954001267753

Epoch: 5| Step: 4
Training loss: 2.5644149780273438
Validation loss: 2.4434531182050705

Epoch: 5| Step: 5
Training loss: 2.512437343597412
Validation loss: 2.4401693046092987

Epoch: 5| Step: 6
Training loss: 2.169065475463867
Validation loss: 2.4394902090231576

Epoch: 5| Step: 7
Training loss: 2.4692234992980957
Validation loss: 2.436084270477295

Epoch: 5| Step: 8
Training loss: 2.3727545738220215
Validation loss: 2.431501845518748

Epoch: 5| Step: 9
Training loss: 2.809865713119507
Validation loss: 2.4267229437828064

Epoch: 5| Step: 10
Training loss: 2.6099467277526855
Validation loss: 2.4245399683713913

Epoch: 5| Step: 11
Training loss: 2.8940865993499756
Validation loss: 2.4272934198379517

Epoch: 57| Step: 0
Training loss: 2.5552451610565186
Validation loss: 2.4314866960048676

Epoch: 5| Step: 1
Training loss: 2.9312288761138916
Validation loss: 2.4374251315991082

Epoch: 5| Step: 2
Training loss: 2.017082929611206
Validation loss: 2.4256010353565216

Epoch: 5| Step: 3
Training loss: 2.675788402557373
Validation loss: 2.4207816620667777

Epoch: 5| Step: 4
Training loss: 2.8429577350616455
Validation loss: 2.409048318862915

Epoch: 5| Step: 5
Training loss: 2.3451132774353027
Validation loss: 2.4082244485616684

Epoch: 5| Step: 6
Training loss: 2.182192087173462
Validation loss: 2.401894748210907

Epoch: 5| Step: 7
Training loss: 2.221266269683838
Validation loss: 2.403103321790695

Epoch: 5| Step: 8
Training loss: 3.2439186573028564
Validation loss: 2.3997909873723984

Epoch: 5| Step: 9
Training loss: 2.8336920738220215
Validation loss: 2.399255315462748

Epoch: 5| Step: 10
Training loss: 2.7945685386657715
Validation loss: 2.3998306492964425

Epoch: 5| Step: 11
Training loss: 2.072636365890503
Validation loss: 2.3963077863057456

Epoch: 58| Step: 0
Training loss: 2.6531035900115967
Validation loss: 2.393060947457949

Epoch: 5| Step: 1
Training loss: 2.9148128032684326
Validation loss: 2.3913197914759317

Epoch: 5| Step: 2
Training loss: 2.444249391555786
Validation loss: 2.3915327986081443

Epoch: 5| Step: 3
Training loss: 1.926611304283142
Validation loss: 2.3857598900794983

Epoch: 5| Step: 4
Training loss: 2.2574880123138428
Validation loss: 2.3901160756746926

Epoch: 5| Step: 5
Training loss: 2.9109177589416504
Validation loss: 2.3781800866127014

Epoch: 5| Step: 6
Training loss: 2.963569164276123
Validation loss: 2.3755927781263986

Epoch: 5| Step: 7
Training loss: 2.4406216144561768
Validation loss: 2.374707415699959

Epoch: 5| Step: 8
Training loss: 2.6242408752441406
Validation loss: 2.3734178145726523

Epoch: 5| Step: 9
Training loss: 2.9194273948669434
Validation loss: 2.36835315823555

Epoch: 5| Step: 10
Training loss: 2.1834299564361572
Validation loss: 2.3630348245302835

Epoch: 5| Step: 11
Training loss: 2.280060052871704
Validation loss: 2.3639175395170846

Epoch: 59| Step: 0
Training loss: 2.3378167152404785
Validation loss: 2.371995657682419

Epoch: 5| Step: 1
Training loss: 2.130648136138916
Validation loss: 2.36865304907163

Epoch: 5| Step: 2
Training loss: 2.243856906890869
Validation loss: 2.3668218155701957

Epoch: 5| Step: 3
Training loss: 2.7387919425964355
Validation loss: 2.36361363530159

Epoch: 5| Step: 4
Training loss: 2.577784299850464
Validation loss: 2.3612597286701202

Epoch: 5| Step: 5
Training loss: 2.9922633171081543
Validation loss: 2.355355183283488

Epoch: 5| Step: 6
Training loss: 2.532888889312744
Validation loss: 2.3522147138913474

Epoch: 5| Step: 7
Training loss: 2.700470447540283
Validation loss: 2.348934600750605

Epoch: 5| Step: 8
Training loss: 2.23225736618042
Validation loss: 2.3416647662719092

Epoch: 5| Step: 9
Training loss: 2.6647000312805176
Validation loss: 2.3471446186304092

Epoch: 5| Step: 10
Training loss: 2.7822489738464355
Validation loss: 2.3476695319016776

Epoch: 5| Step: 11
Training loss: 2.119396924972534
Validation loss: 2.3518017133076987

Epoch: 60| Step: 0
Training loss: 2.10542893409729
Validation loss: 2.3457315067450204

Epoch: 5| Step: 1
Training loss: 2.398601770401001
Validation loss: 2.344276656707128

Epoch: 5| Step: 2
Training loss: 2.6961798667907715
Validation loss: 2.3409427801767984

Epoch: 5| Step: 3
Training loss: 2.6838672161102295
Validation loss: 2.336769223213196

Epoch: 5| Step: 4
Training loss: 2.306220531463623
Validation loss: 2.335930426915487

Epoch: 5| Step: 5
Training loss: 2.2173256874084473
Validation loss: 2.328635344902674

Epoch: 5| Step: 6
Training loss: 2.6250360012054443
Validation loss: 2.324208209911982

Epoch: 5| Step: 7
Training loss: 3.0483665466308594
Validation loss: 2.3196609218915305

Epoch: 5| Step: 8
Training loss: 2.2526917457580566
Validation loss: 2.3242573142051697

Epoch: 5| Step: 9
Training loss: 2.7517714500427246
Validation loss: 2.3224372466405234

Epoch: 5| Step: 10
Training loss: 2.1928722858428955
Validation loss: 2.314397464195887

Epoch: 5| Step: 11
Training loss: 3.627197265625
Validation loss: 2.316234221061071

Epoch: 61| Step: 0
Training loss: 2.0008907318115234
Validation loss: 2.3114831149578094

Epoch: 5| Step: 1
Training loss: 2.3026933670043945
Validation loss: 2.3124131162961326

Epoch: 5| Step: 2
Training loss: 2.083914279937744
Validation loss: 2.307694430152575

Epoch: 5| Step: 3
Training loss: 2.656355619430542
Validation loss: 2.304755449295044

Epoch: 5| Step: 4
Training loss: 2.741579294204712
Validation loss: 2.3079795241355896

Epoch: 5| Step: 5
Training loss: 3.047276020050049
Validation loss: 2.3017663856347403

Epoch: 5| Step: 6
Training loss: 2.6942901611328125
Validation loss: 2.30487855275472

Epoch: 5| Step: 7
Training loss: 2.238635540008545
Validation loss: 2.299185554186503

Epoch: 5| Step: 8
Training loss: 2.5324676036834717
Validation loss: 2.2958971560001373

Epoch: 5| Step: 9
Training loss: 2.3683910369873047
Validation loss: 2.296552449464798

Epoch: 5| Step: 10
Training loss: 2.449347972869873
Validation loss: 2.295291726787885

Epoch: 5| Step: 11
Training loss: 2.8209900856018066
Validation loss: 2.298323522011439

Epoch: 62| Step: 0
Training loss: 2.1141104698181152
Validation loss: 2.2874686419963837

Epoch: 5| Step: 1
Training loss: 2.253897190093994
Validation loss: 2.2900902728239694

Epoch: 5| Step: 2
Training loss: 2.720534563064575
Validation loss: 2.287536342938741

Epoch: 5| Step: 3
Training loss: 2.5944504737854004
Validation loss: 2.2828954259554544

Epoch: 5| Step: 4
Training loss: 2.7805163860321045
Validation loss: 2.2860585351785025

Epoch: 5| Step: 5
Training loss: 2.058013916015625
Validation loss: 2.282505358258883

Epoch: 5| Step: 6
Training loss: 2.8310132026672363
Validation loss: 2.284365549683571

Epoch: 5| Step: 7
Training loss: 2.2047417163848877
Validation loss: 2.280510942141215

Epoch: 5| Step: 8
Training loss: 2.536431312561035
Validation loss: 2.2743446429570517

Epoch: 5| Step: 9
Training loss: 2.702296257019043
Validation loss: 2.2687995533148446

Epoch: 5| Step: 10
Training loss: 2.21549916267395
Validation loss: 2.267762710650762

Epoch: 5| Step: 11
Training loss: 2.031317710876465
Validation loss: 2.268514096736908

Epoch: 63| Step: 0
Training loss: 2.938382148742676
Validation loss: 2.269614319006602

Epoch: 5| Step: 1
Training loss: 2.1986422538757324
Validation loss: 2.2695406476656594

Epoch: 5| Step: 2
Training loss: 2.2325539588928223
Validation loss: 2.2685202856858573

Epoch: 5| Step: 3
Training loss: 2.6919174194335938
Validation loss: 2.266351272662481

Epoch: 5| Step: 4
Training loss: 2.1891462802886963
Validation loss: 2.265113284190496

Epoch: 5| Step: 5
Training loss: 2.5757813453674316
Validation loss: 2.262495994567871

Epoch: 5| Step: 6
Training loss: 2.458400249481201
Validation loss: 2.2580468406279883

Epoch: 5| Step: 7
Training loss: 2.5393857955932617
Validation loss: 2.2546909799178443

Epoch: 5| Step: 8
Training loss: 2.205326557159424
Validation loss: 2.2518722067276635

Epoch: 5| Step: 9
Training loss: 2.3269190788269043
Validation loss: 2.2465669214725494

Epoch: 5| Step: 10
Training loss: 2.469724178314209
Validation loss: 2.2462303042411804

Epoch: 5| Step: 11
Training loss: 1.5168201923370361
Validation loss: 2.241567552089691

Epoch: 64| Step: 0
Training loss: 2.345445394515991
Validation loss: 2.2362816532452903

Epoch: 5| Step: 1
Training loss: 2.004129409790039
Validation loss: 2.2425988912582397

Epoch: 5| Step: 2
Training loss: 2.523421049118042
Validation loss: 2.2425383826096854

Epoch: 5| Step: 3
Training loss: 1.9712063074111938
Validation loss: 2.24158509572347

Epoch: 5| Step: 4
Training loss: 2.819770336151123
Validation loss: 2.2438934644063315

Epoch: 5| Step: 5
Training loss: 2.5668787956237793
Validation loss: 2.2367685387531915

Epoch: 5| Step: 6
Training loss: 2.5775232315063477
Validation loss: 2.2385978400707245

Epoch: 5| Step: 7
Training loss: 2.4777870178222656
Validation loss: 2.230736563603083

Epoch: 5| Step: 8
Training loss: 2.633176565170288
Validation loss: 2.2220035394032798

Epoch: 5| Step: 9
Training loss: 1.766165018081665
Validation loss: 2.219327305754026

Epoch: 5| Step: 10
Training loss: 2.7073702812194824
Validation loss: 2.2187061111132302

Epoch: 5| Step: 11
Training loss: 2.2315869331359863
Validation loss: 2.21487849454085

Epoch: 65| Step: 0
Training loss: 2.2642555236816406
Validation loss: 2.21186500787735

Epoch: 5| Step: 1
Training loss: 2.8563218116760254
Validation loss: 2.2099812030792236

Epoch: 5| Step: 2
Training loss: 2.178924083709717
Validation loss: 2.211469680070877

Epoch: 5| Step: 3
Training loss: 2.428530216217041
Validation loss: 2.212401126821836

Epoch: 5| Step: 4
Training loss: 2.3888487815856934
Validation loss: 2.209819277127584

Epoch: 5| Step: 5
Training loss: 2.104551315307617
Validation loss: 2.2135655085245767

Epoch: 5| Step: 6
Training loss: 2.282611608505249
Validation loss: 2.2131195664405823

Epoch: 5| Step: 7
Training loss: 2.42570424079895
Validation loss: 2.213283032178879

Epoch: 5| Step: 8
Training loss: 2.5760107040405273
Validation loss: 2.211199770371119

Epoch: 5| Step: 9
Training loss: 2.3259644508361816
Validation loss: 2.2071187694867453

Epoch: 5| Step: 10
Training loss: 2.4502005577087402
Validation loss: 2.206896498799324

Epoch: 5| Step: 11
Training loss: 1.3912601470947266
Validation loss: 2.1989589780569077

Epoch: 66| Step: 0
Training loss: 2.137866973876953
Validation loss: 2.1975154678026834

Epoch: 5| Step: 1
Training loss: 2.3650712966918945
Validation loss: 2.1968635519345603

Epoch: 5| Step: 2
Training loss: 2.009213924407959
Validation loss: 2.1903244256973267

Epoch: 5| Step: 3
Training loss: 1.9900344610214233
Validation loss: 2.189098616441091

Epoch: 5| Step: 4
Training loss: 2.3003592491149902
Validation loss: 2.185225119193395

Epoch: 5| Step: 5
Training loss: 2.322458267211914
Validation loss: 2.1833098431428275

Epoch: 5| Step: 6
Training loss: 2.277052402496338
Validation loss: 2.18151185909907

Epoch: 5| Step: 7
Training loss: 2.333834171295166
Validation loss: 2.1885263423124948

Epoch: 5| Step: 8
Training loss: 2.306856632232666
Validation loss: 2.1807225892941156

Epoch: 5| Step: 9
Training loss: 2.92991304397583
Validation loss: 2.1874805142482123

Epoch: 5| Step: 10
Training loss: 2.9014596939086914
Validation loss: 2.1776025841633477

Epoch: 5| Step: 11
Training loss: 2.654477119445801
Validation loss: 2.1707118650277457

Epoch: 67| Step: 0
Training loss: 2.4961047172546387
Validation loss: 2.1712277233600616

Epoch: 5| Step: 1
Training loss: 2.6646878719329834
Validation loss: 2.177221397558848

Epoch: 5| Step: 2
Training loss: 2.380166530609131
Validation loss: 2.179299076398214

Epoch: 5| Step: 3
Training loss: 2.1545441150665283
Validation loss: 2.1886754631996155

Epoch: 5| Step: 4
Training loss: 2.022702693939209
Validation loss: 2.1994775980710983

Epoch: 5| Step: 5
Training loss: 1.7356754541397095
Validation loss: 2.217039088408152

Epoch: 5| Step: 6
Training loss: 3.1371371746063232
Validation loss: 2.23124335706234

Epoch: 5| Step: 7
Training loss: 2.1188228130340576
Validation loss: 2.2418732047080994

Epoch: 5| Step: 8
Training loss: 2.308079242706299
Validation loss: 2.231421877940496

Epoch: 5| Step: 9
Training loss: 2.728497266769409
Validation loss: 2.2248639464378357

Epoch: 5| Step: 10
Training loss: 2.3000450134277344
Validation loss: 2.2151036262512207

Epoch: 5| Step: 11
Training loss: 2.2086195945739746
Validation loss: 2.1957183331251144

Epoch: 68| Step: 0
Training loss: 2.2833468914031982
Validation loss: 2.1877208948135376

Epoch: 5| Step: 1
Training loss: 2.237700939178467
Validation loss: 2.183377390106519

Epoch: 5| Step: 2
Training loss: 2.9586589336395264
Validation loss: 2.1771803200244904

Epoch: 5| Step: 3
Training loss: 2.7767627239227295
Validation loss: 2.1704093664884567

Epoch: 5| Step: 4
Training loss: 2.2164902687072754
Validation loss: 2.164179985721906

Epoch: 5| Step: 5
Training loss: 2.0103774070739746
Validation loss: 2.161459426085154

Epoch: 5| Step: 6
Training loss: 2.619319200515747
Validation loss: 2.159445216258367

Epoch: 5| Step: 7
Training loss: 2.0579617023468018
Validation loss: 2.1628236323595047

Epoch: 5| Step: 8
Training loss: 2.6390557289123535
Validation loss: 2.154580076535543

Epoch: 5| Step: 9
Training loss: 1.6698358058929443
Validation loss: 2.1588767220576606

Epoch: 5| Step: 10
Training loss: 2.213561773300171
Validation loss: 2.1491089959939322

Epoch: 5| Step: 11
Training loss: 2.548046588897705
Validation loss: 2.1518780489762626

Epoch: 69| Step: 0
Training loss: 2.0434906482696533
Validation loss: 2.1502583771944046

Epoch: 5| Step: 1
Training loss: 2.6813671588897705
Validation loss: 2.145368511478106

Epoch: 5| Step: 2
Training loss: 2.4832892417907715
Validation loss: 2.1426534752051034

Epoch: 5| Step: 3
Training loss: 2.305600643157959
Validation loss: 2.1477689246336618

Epoch: 5| Step: 4
Training loss: 2.9514338970184326
Validation loss: 2.146605913837751

Epoch: 5| Step: 5
Training loss: 1.9372272491455078
Validation loss: 2.145307093858719

Epoch: 5| Step: 6
Training loss: 2.27325439453125
Validation loss: 2.1486340860525766

Epoch: 5| Step: 7
Training loss: 1.921531319618225
Validation loss: 2.1413869758447013

Epoch: 5| Step: 8
Training loss: 2.412440776824951
Validation loss: 2.141490558783213

Epoch: 5| Step: 9
Training loss: 1.874537706375122
Validation loss: 2.134353627761205

Epoch: 5| Step: 10
Training loss: 2.375410556793213
Validation loss: 2.1386374880870185

Epoch: 5| Step: 11
Training loss: 3.0621018409729004
Validation loss: 2.132158781091372

Epoch: 70| Step: 0
Training loss: 1.9317697286605835
Validation loss: 2.1336834083000817

Epoch: 5| Step: 1
Training loss: 1.839425802230835
Validation loss: 2.1304778108994165

Epoch: 5| Step: 2
Training loss: 2.042090892791748
Validation loss: 2.1255274564027786

Epoch: 5| Step: 3
Training loss: 2.421909809112549
Validation loss: 2.125985413789749

Epoch: 5| Step: 4
Training loss: 2.5314278602600098
Validation loss: 2.121551126241684

Epoch: 5| Step: 5
Training loss: 2.310098171234131
Validation loss: 2.127469172080358

Epoch: 5| Step: 6
Training loss: 2.9252588748931885
Validation loss: 2.126602421204249

Epoch: 5| Step: 7
Training loss: 2.3644886016845703
Validation loss: 2.131394535303116

Epoch: 5| Step: 8
Training loss: 2.4361042976379395
Validation loss: 2.1267678340276084

Epoch: 5| Step: 9
Training loss: 2.4409453868865967
Validation loss: 2.130093663930893

Epoch: 5| Step: 10
Training loss: 2.102177381515503
Validation loss: 2.127272978425026

Epoch: 5| Step: 11
Training loss: 2.1425771713256836
Validation loss: 2.1239797125260034

Epoch: 71| Step: 0
Training loss: 2.490556240081787
Validation loss: 2.1259644428888955

Epoch: 5| Step: 1
Training loss: 2.016439914703369
Validation loss: 2.1245454450448356

Epoch: 5| Step: 2
Training loss: 2.5894951820373535
Validation loss: 2.129542221625646

Epoch: 5| Step: 3
Training loss: 2.1960949897766113
Validation loss: 2.1252852429946265

Epoch: 5| Step: 4
Training loss: 2.617274761199951
Validation loss: 2.138295590877533

Epoch: 5| Step: 5
Training loss: 2.515096664428711
Validation loss: 2.1520317693551383

Epoch: 5| Step: 6
Training loss: 1.8404350280761719
Validation loss: 2.1366293728351593

Epoch: 5| Step: 7
Training loss: 2.314797878265381
Validation loss: 2.128922392924627

Epoch: 5| Step: 8
Training loss: 2.452772378921509
Validation loss: 2.1231354773044586

Epoch: 5| Step: 9
Training loss: 1.989477515220642
Validation loss: 2.108730584383011

Epoch: 5| Step: 10
Training loss: 2.226268768310547
Validation loss: 2.1139464179674783

Epoch: 5| Step: 11
Training loss: 2.4417543411254883
Validation loss: 2.1122740606466928

Epoch: 72| Step: 0
Training loss: 2.110703945159912
Validation loss: 2.113586107889811

Epoch: 5| Step: 1
Training loss: 2.2882816791534424
Validation loss: 2.1127184381087623

Epoch: 5| Step: 2
Training loss: 2.4233686923980713
Validation loss: 2.1167935033639274

Epoch: 5| Step: 3
Training loss: 1.943922996520996
Validation loss: 2.117754062016805

Epoch: 5| Step: 4
Training loss: 2.2519137859344482
Validation loss: 2.1176310777664185

Epoch: 5| Step: 5
Training loss: 2.4880776405334473
Validation loss: 2.1205433358748755

Epoch: 5| Step: 6
Training loss: 2.475220203399658
Validation loss: 2.1196259409189224

Epoch: 5| Step: 7
Training loss: 2.5083718299865723
Validation loss: 2.1218205193678537

Epoch: 5| Step: 8
Training loss: 1.9891021251678467
Validation loss: 2.120782047510147

Epoch: 5| Step: 9
Training loss: 2.5851035118103027
Validation loss: 2.1207604308923087

Epoch: 5| Step: 10
Training loss: 2.1534945964813232
Validation loss: 2.117514212926229

Epoch: 5| Step: 11
Training loss: 2.739776611328125
Validation loss: 2.1210990448792777

Epoch: 73| Step: 0
Training loss: 2.4965386390686035
Validation loss: 2.114781747261683

Epoch: 5| Step: 1
Training loss: 2.210512399673462
Validation loss: 2.111768583456675

Epoch: 5| Step: 2
Training loss: 2.4503231048583984
Validation loss: 2.110760206977526

Epoch: 5| Step: 3
Training loss: 2.3664679527282715
Validation loss: 2.1125356256961823

Epoch: 5| Step: 4
Training loss: 2.0207629203796387
Validation loss: 2.108757192889849

Epoch: 5| Step: 5
Training loss: 2.3899621963500977
Validation loss: 2.1124972055355706

Epoch: 5| Step: 6
Training loss: 1.8760303258895874
Validation loss: 2.1078030417362847

Epoch: 5| Step: 7
Training loss: 2.5680947303771973
Validation loss: 2.1054232021172843

Epoch: 5| Step: 8
Training loss: 1.7683532238006592
Validation loss: 2.104925105969111

Epoch: 5| Step: 9
Training loss: 1.9583371877670288
Validation loss: 2.105240305264791

Epoch: 5| Step: 10
Training loss: 2.7215142250061035
Validation loss: 2.1023972034454346

Epoch: 5| Step: 11
Training loss: 3.972106456756592
Validation loss: 2.101798713207245

Epoch: 74| Step: 0
Training loss: 2.230877161026001
Validation loss: 2.1004855831464133

Epoch: 5| Step: 1
Training loss: 1.8168007135391235
Validation loss: 2.10002992550532

Epoch: 5| Step: 2
Training loss: 1.6251287460327148
Validation loss: 2.0965120991071067

Epoch: 5| Step: 3
Training loss: 2.1977717876434326
Validation loss: 2.0934841682513556

Epoch: 5| Step: 4
Training loss: 2.197364330291748
Validation loss: 2.0908798277378082

Epoch: 5| Step: 5
Training loss: 2.6985936164855957
Validation loss: 2.0933393935362496

Epoch: 5| Step: 6
Training loss: 2.605501890182495
Validation loss: 2.0969017843405404

Epoch: 5| Step: 7
Training loss: 2.753269910812378
Validation loss: 2.09608926375707

Epoch: 5| Step: 8
Training loss: 2.2418694496154785
Validation loss: 2.0941768089930215

Epoch: 5| Step: 9
Training loss: 2.3972928524017334
Validation loss: 2.0841312309106192

Epoch: 5| Step: 10
Training loss: 2.490556001663208
Validation loss: 2.0866868595282235

Epoch: 5| Step: 11
Training loss: 1.3696163892745972
Validation loss: 2.092419534921646

Epoch: 75| Step: 0
Training loss: 2.1433374881744385
Validation loss: 2.0848720719416938

Epoch: 5| Step: 1
Training loss: 2.1654834747314453
Validation loss: 2.079822818438212

Epoch: 5| Step: 2
Training loss: 2.121636390686035
Validation loss: 2.080161785085996

Epoch: 5| Step: 3
Training loss: 1.840746521949768
Validation loss: 2.077341611186663

Epoch: 5| Step: 4
Training loss: 2.8724942207336426
Validation loss: 2.067840258280436

Epoch: 5| Step: 5
Training loss: 1.887505292892456
Validation loss: 2.0762862215439477

Epoch: 5| Step: 6
Training loss: 2.636187791824341
Validation loss: 2.0787313977877298

Epoch: 5| Step: 7
Training loss: 2.516944408416748
Validation loss: 2.077437072992325

Epoch: 5| Step: 8
Training loss: 2.122785806655884
Validation loss: 2.0765534391005835

Epoch: 5| Step: 9
Training loss: 2.23154878616333
Validation loss: 2.0747388501962027

Epoch: 5| Step: 10
Training loss: 2.268667697906494
Validation loss: 2.0825732946395874

Epoch: 5| Step: 11
Training loss: 3.0017776489257812
Validation loss: 2.0726075718800225

Epoch: 76| Step: 0
Training loss: 2.3560783863067627
Validation loss: 2.0703683396180472

Epoch: 5| Step: 1
Training loss: 2.363942861557007
Validation loss: 2.073788598179817

Epoch: 5| Step: 2
Training loss: 2.298807144165039
Validation loss: 2.0639898429314294

Epoch: 5| Step: 3
Training loss: 2.29130482673645
Validation loss: 2.0650726159413657

Epoch: 5| Step: 4
Training loss: 1.9475200176239014
Validation loss: 2.062029262383779

Epoch: 5| Step: 5
Training loss: 2.505476474761963
Validation loss: 2.058697352806727

Epoch: 5| Step: 6
Training loss: 2.3841328620910645
Validation loss: 2.059276426831881

Epoch: 5| Step: 7
Training loss: 2.281167507171631
Validation loss: 2.0633777578671775

Epoch: 5| Step: 8
Training loss: 2.2073097229003906
Validation loss: 2.0578582684199014

Epoch: 5| Step: 9
Training loss: 1.6101385354995728
Validation loss: 2.0652124136686325

Epoch: 5| Step: 10
Training loss: 2.2985708713531494
Validation loss: 2.0648820996284485

Epoch: 5| Step: 11
Training loss: 3.3633594512939453
Validation loss: 2.07066302994887

Epoch: 77| Step: 0
Training loss: 2.4720683097839355
Validation loss: 2.066251754760742

Epoch: 5| Step: 1
Training loss: 2.3563265800476074
Validation loss: 2.0651061683893204

Epoch: 5| Step: 2
Training loss: 2.1899564266204834
Validation loss: 2.0609268148740134

Epoch: 5| Step: 3
Training loss: 2.0506057739257812
Validation loss: 2.0665148893992105

Epoch: 5| Step: 4
Training loss: 1.9900474548339844
Validation loss: 2.06382026274999

Epoch: 5| Step: 5
Training loss: 2.2542970180511475
Validation loss: 2.060658792654673

Epoch: 5| Step: 6
Training loss: 2.0101191997528076
Validation loss: 2.060061971346537

Epoch: 5| Step: 7
Training loss: 1.7689459323883057
Validation loss: 2.056463668743769

Epoch: 5| Step: 8
Training loss: 3.2015299797058105
Validation loss: 2.053880368669828

Epoch: 5| Step: 9
Training loss: 2.599179744720459
Validation loss: 2.0507736007372537

Epoch: 5| Step: 10
Training loss: 2.0266072750091553
Validation loss: 2.0467957903941474

Epoch: 5| Step: 11
Training loss: 1.009067416191101
Validation loss: 2.045533920327822

Epoch: 78| Step: 0
Training loss: 2.623976230621338
Validation loss: 2.047848547498385

Epoch: 5| Step: 1
Training loss: 1.8324248790740967
Validation loss: 2.0464899440606437

Epoch: 5| Step: 2
Training loss: 2.027143955230713
Validation loss: 2.0613248298565545

Epoch: 5| Step: 3
Training loss: 2.6308624744415283
Validation loss: 2.065194542209307

Epoch: 5| Step: 4
Training loss: 2.447057008743286
Validation loss: 2.0742919196685157

Epoch: 5| Step: 5
Training loss: 2.311988592147827
Validation loss: 2.0821594148874283

Epoch: 5| Step: 6
Training loss: 2.650235652923584
Validation loss: 2.0958549131949744

Epoch: 5| Step: 7
Training loss: 2.303067445755005
Validation loss: 2.085474967956543

Epoch: 5| Step: 8
Training loss: 2.0524373054504395
Validation loss: 2.0590715607007346

Epoch: 5| Step: 9
Training loss: 2.0703864097595215
Validation loss: 2.0553785065809884

Epoch: 5| Step: 10
Training loss: 1.7179689407348633
Validation loss: 2.050755133231481

Epoch: 5| Step: 11
Training loss: 2.946911334991455
Validation loss: 2.0484139074881873

Epoch: 79| Step: 0
Training loss: 2.474512815475464
Validation loss: 2.0541300078233085

Epoch: 5| Step: 1
Training loss: 1.9067538976669312
Validation loss: 2.0582101543744407

Epoch: 5| Step: 2
Training loss: 2.5713562965393066
Validation loss: 2.056252842148145

Epoch: 5| Step: 3
Training loss: 2.148230791091919
Validation loss: 2.0581595400969186

Epoch: 5| Step: 4
Training loss: 2.1157286167144775
Validation loss: 2.0583758453528085

Epoch: 5| Step: 5
Training loss: 2.902869701385498
Validation loss: 2.05865141749382

Epoch: 5| Step: 6
Training loss: 2.1391444206237793
Validation loss: 2.061251441637675

Epoch: 5| Step: 7
Training loss: 2.219120502471924
Validation loss: 2.064129278063774

Epoch: 5| Step: 8
Training loss: 1.9505360126495361
Validation loss: 2.0622012317180634

Epoch: 5| Step: 9
Training loss: 2.0766851902008057
Validation loss: 2.0594548980394998

Epoch: 5| Step: 10
Training loss: 2.2432799339294434
Validation loss: 2.0647951563199363

Epoch: 5| Step: 11
Training loss: 1.5572258234024048
Validation loss: 2.05440683166186

Epoch: 80| Step: 0
Training loss: 2.255182981491089
Validation loss: 2.059494361281395

Epoch: 5| Step: 1
Training loss: 2.0629632472991943
Validation loss: 2.05424997707208

Epoch: 5| Step: 2
Training loss: 2.298367977142334
Validation loss: 2.0554779022932053

Epoch: 5| Step: 3
Training loss: 2.326573610305786
Validation loss: 2.051044041911761

Epoch: 5| Step: 4
Training loss: 2.7010436058044434
Validation loss: 2.0488611112038293

Epoch: 5| Step: 5
Training loss: 2.4470813274383545
Validation loss: 2.0457022736469903

Epoch: 5| Step: 6
Training loss: 1.5504789352416992
Validation loss: 2.03874305387338

Epoch: 5| Step: 7
Training loss: 2.254634380340576
Validation loss: 2.036689415574074

Epoch: 5| Step: 8
Training loss: 2.433964490890503
Validation loss: 2.0415247877438865

Epoch: 5| Step: 9
Training loss: 2.128504753112793
Validation loss: 2.030481810371081

Epoch: 5| Step: 10
Training loss: 2.2778961658477783
Validation loss: 2.0328460137049356

Epoch: 5| Step: 11
Training loss: 0.8314660787582397
Validation loss: 2.034305229783058

Epoch: 81| Step: 0
Training loss: 1.973655343055725
Validation loss: 2.030939996242523

Epoch: 5| Step: 1
Training loss: 2.082489490509033
Validation loss: 2.030590777595838

Epoch: 5| Step: 2
Training loss: 3.036633014678955
Validation loss: 2.02809602022171

Epoch: 5| Step: 3
Training loss: 1.7054599523544312
Validation loss: 2.039953718582789

Epoch: 5| Step: 4
Training loss: 2.6273159980773926
Validation loss: 2.0332329471906028

Epoch: 5| Step: 5
Training loss: 2.6133532524108887
Validation loss: 2.0375439325968423

Epoch: 5| Step: 6
Training loss: 2.671091079711914
Validation loss: 2.0318370262781777

Epoch: 5| Step: 7
Training loss: 2.1531128883361816
Validation loss: 2.0285591036081314

Epoch: 5| Step: 8
Training loss: 1.5059969425201416
Validation loss: 2.0368532091379166

Epoch: 5| Step: 9
Training loss: 1.7872995138168335
Validation loss: 2.03725432852904

Epoch: 5| Step: 10
Training loss: 2.1470723152160645
Validation loss: 2.033534919222196

Epoch: 5| Step: 11
Training loss: 2.9361276626586914
Validation loss: 2.03649731973807

Epoch: 82| Step: 0
Training loss: 2.371389389038086
Validation loss: 2.0333262979984283

Epoch: 5| Step: 1
Training loss: 1.855539321899414
Validation loss: 2.04560054341952

Epoch: 5| Step: 2
Training loss: 1.8409464359283447
Validation loss: 2.049277270833651

Epoch: 5| Step: 3
Training loss: 2.5220541954040527
Validation loss: 2.0454413890838623

Epoch: 5| Step: 4
Training loss: 2.2838962078094482
Validation loss: 2.04587060213089

Epoch: 5| Step: 5
Training loss: 2.5130538940429688
Validation loss: 2.043531229098638

Epoch: 5| Step: 6
Training loss: 2.478823661804199
Validation loss: 2.041971762975057

Epoch: 5| Step: 7
Training loss: 2.4909884929656982
Validation loss: 2.04430482784907

Epoch: 5| Step: 8
Training loss: 1.932766318321228
Validation loss: 2.044260546565056

Epoch: 5| Step: 9
Training loss: 2.2897465229034424
Validation loss: 2.0436790784200034

Epoch: 5| Step: 10
Training loss: 2.1642982959747314
Validation loss: 2.0432458420594535

Epoch: 5| Step: 11
Training loss: 0.8011879920959473
Validation loss: 2.045175929864248

Epoch: 83| Step: 0
Training loss: 2.3878378868103027
Validation loss: 2.04567943016688

Epoch: 5| Step: 1
Training loss: 2.077272891998291
Validation loss: 2.0425804952780404

Epoch: 5| Step: 2
Training loss: 2.215808868408203
Validation loss: 2.045036921898524

Epoch: 5| Step: 3
Training loss: 2.3182671070098877
Validation loss: 2.036955550312996

Epoch: 5| Step: 4
Training loss: 2.206115484237671
Validation loss: 2.0385547131299973

Epoch: 5| Step: 5
Training loss: 2.665196657180786
Validation loss: 2.030243307352066

Epoch: 5| Step: 6
Training loss: 1.9142354726791382
Validation loss: 2.0343000143766403

Epoch: 5| Step: 7
Training loss: 1.7423893213272095
Validation loss: 2.035082519054413

Epoch: 5| Step: 8
Training loss: 2.2766239643096924
Validation loss: 2.031068831682205

Epoch: 5| Step: 9
Training loss: 2.2690868377685547
Validation loss: 2.0360130866368613

Epoch: 5| Step: 10
Training loss: 2.4234955310821533
Validation loss: 2.033052235841751

Epoch: 5| Step: 11
Training loss: 1.945338249206543
Validation loss: 2.031263376275698

Epoch: 84| Step: 0
Training loss: 2.1877219676971436
Validation loss: 2.0325916707515717

Epoch: 5| Step: 1
Training loss: 1.8369019031524658
Validation loss: 2.0443713317314782

Epoch: 5| Step: 2
Training loss: 2.4704058170318604
Validation loss: 2.0702680548032126

Epoch: 5| Step: 3
Training loss: 2.3645052909851074
Validation loss: 2.072070380051931

Epoch: 5| Step: 4
Training loss: 2.003261089324951
Validation loss: 2.0636425713698068

Epoch: 5| Step: 5
Training loss: 2.905102491378784
Validation loss: 2.0746188114086785

Epoch: 5| Step: 6
Training loss: 1.783200979232788
Validation loss: 2.066551312804222

Epoch: 5| Step: 7
Training loss: 2.3898491859436035
Validation loss: 2.058940500020981

Epoch: 5| Step: 8
Training loss: 2.1451222896575928
Validation loss: 2.0444465031226478

Epoch: 5| Step: 9
Training loss: 1.9007196426391602
Validation loss: 2.0268072187900543

Epoch: 5| Step: 10
Training loss: 2.4128060340881348
Validation loss: 2.0281660705804825

Epoch: 5| Step: 11
Training loss: 2.925191879272461
Validation loss: 2.0330367336670556

Epoch: 85| Step: 0
Training loss: 1.979648232460022
Validation loss: 2.039503718415896

Epoch: 5| Step: 1
Training loss: 1.8385719060897827
Validation loss: 2.042975147565206

Epoch: 5| Step: 2
Training loss: 2.6608684062957764
Validation loss: 2.0403952896595

Epoch: 5| Step: 3
Training loss: 1.6877565383911133
Validation loss: 2.0408152441183725

Epoch: 5| Step: 4
Training loss: 2.445669412612915
Validation loss: 2.039708877603213

Epoch: 5| Step: 5
Training loss: 2.645101547241211
Validation loss: 2.0415580769379935

Epoch: 5| Step: 6
Training loss: 2.8550353050231934
Validation loss: 2.041475291053454

Epoch: 5| Step: 7
Training loss: 2.0792622566223145
Validation loss: 2.038404439886411

Epoch: 5| Step: 8
Training loss: 1.7539596557617188
Validation loss: 2.0423961530129113

Epoch: 5| Step: 9
Training loss: 2.2780654430389404
Validation loss: 2.0449062337478003

Epoch: 5| Step: 10
Training loss: 2.2823891639709473
Validation loss: 2.036665310462316

Epoch: 5| Step: 11
Training loss: 1.8004834651947021
Validation loss: 2.0394025345643363

Epoch: 86| Step: 0
Training loss: 2.1230149269104004
Validation loss: 2.039643888672193

Epoch: 5| Step: 1
Training loss: 2.4680256843566895
Validation loss: 2.0375943382581077

Epoch: 5| Step: 2
Training loss: 1.8079805374145508
Validation loss: 2.035610318183899

Epoch: 5| Step: 3
Training loss: 1.8790748119354248
Validation loss: 2.0340823382139206

Epoch: 5| Step: 4
Training loss: 2.4383344650268555
Validation loss: 2.0311554869016013

Epoch: 5| Step: 5
Training loss: 1.8511097431182861
Validation loss: 2.0317121694485345

Epoch: 5| Step: 6
Training loss: 2.3152661323547363
Validation loss: 2.030711149175962

Epoch: 5| Step: 7
Training loss: 1.6340879201889038
Validation loss: 2.0301629652579627

Epoch: 5| Step: 8
Training loss: 2.803612232208252
Validation loss: 2.024181306362152

Epoch: 5| Step: 9
Training loss: 2.33204984664917
Validation loss: 2.028933510184288

Epoch: 5| Step: 10
Training loss: 2.3306784629821777
Validation loss: 2.0256047745545707

Epoch: 5| Step: 11
Training loss: 3.7134222984313965
Validation loss: 2.022941544651985

Epoch: 87| Step: 0
Training loss: 1.960120439529419
Validation loss: 2.028892124692599

Epoch: 5| Step: 1
Training loss: 2.2397167682647705
Validation loss: 2.0352393835783005

Epoch: 5| Step: 2
Training loss: 2.227205991744995
Validation loss: 2.039007912079493

Epoch: 5| Step: 3
Training loss: 2.642583131790161
Validation loss: 2.047958622376124

Epoch: 5| Step: 4
Training loss: 2.3526530265808105
Validation loss: 2.056517094373703

Epoch: 5| Step: 5
Training loss: 2.103644609451294
Validation loss: 2.052570586403211

Epoch: 5| Step: 6
Training loss: 1.7131116390228271
Validation loss: 2.0436953405539193

Epoch: 5| Step: 7
Training loss: 1.9750385284423828
Validation loss: 2.0375476479530334

Epoch: 5| Step: 8
Training loss: 2.6042263507843018
Validation loss: 2.035460725426674

Epoch: 5| Step: 9
Training loss: 2.315324306488037
Validation loss: 2.0243979692459106

Epoch: 5| Step: 10
Training loss: 2.3202717304229736
Validation loss: 2.0204348266124725

Epoch: 5| Step: 11
Training loss: 1.4475443363189697
Validation loss: 2.0218580216169357

Epoch: 88| Step: 0
Training loss: 1.934125304222107
Validation loss: 2.0294734289248786

Epoch: 5| Step: 1
Training loss: 2.0178325176239014
Validation loss: 2.0312874565521875

Epoch: 5| Step: 2
Training loss: 2.479736804962158
Validation loss: 2.0346634835004807

Epoch: 5| Step: 3
Training loss: 2.4756345748901367
Validation loss: 2.034270703792572

Epoch: 5| Step: 4
Training loss: 1.9727649688720703
Validation loss: 2.040117268760999

Epoch: 5| Step: 5
Training loss: 1.7435588836669922
Validation loss: 2.0410839964946113

Epoch: 5| Step: 6
Training loss: 2.203662872314453
Validation loss: 2.0453520665566125

Epoch: 5| Step: 7
Training loss: 2.4462058544158936
Validation loss: 2.043446476260821

Epoch: 5| Step: 8
Training loss: 2.35162353515625
Validation loss: 2.0415130456288657

Epoch: 5| Step: 9
Training loss: 2.3476383686065674
Validation loss: 2.0424616833527884

Epoch: 5| Step: 10
Training loss: 2.447360038757324
Validation loss: 2.0434714953104653

Epoch: 5| Step: 11
Training loss: 2.131699323654175
Validation loss: 2.04611873626709

Epoch: 89| Step: 0
Training loss: 2.171787738800049
Validation loss: 2.0391768515110016

Epoch: 5| Step: 1
Training loss: 1.8790056705474854
Validation loss: 2.0359684576590857

Epoch: 5| Step: 2
Training loss: 2.6092734336853027
Validation loss: 2.03018951912721

Epoch: 5| Step: 3
Training loss: 1.8097206354141235
Validation loss: 2.0339819391568503

Epoch: 5| Step: 4
Training loss: 2.4047205448150635
Validation loss: 2.029341792066892

Epoch: 5| Step: 5
Training loss: 2.1439316272735596
Validation loss: 2.0294212996959686

Epoch: 5| Step: 6
Training loss: 2.539489507675171
Validation loss: 2.031556099653244

Epoch: 5| Step: 7
Training loss: 2.3066868782043457
Validation loss: 2.0271575252215066

Epoch: 5| Step: 8
Training loss: 2.329000949859619
Validation loss: 2.0306093990802765

Epoch: 5| Step: 9
Training loss: 1.9865665435791016
Validation loss: 2.032444948951403

Epoch: 5| Step: 10
Training loss: 1.9215257167816162
Validation loss: 2.036094605922699

Epoch: 5| Step: 11
Training loss: 2.122072696685791
Validation loss: 2.030416359504064

Epoch: 90| Step: 0
Training loss: 1.9928325414657593
Validation loss: 2.0463495949904122

Epoch: 5| Step: 1
Training loss: 2.6085104942321777
Validation loss: 2.0276600817839303

Epoch: 5| Step: 2
Training loss: 2.223076581954956
Validation loss: 2.0277096579472222

Epoch: 5| Step: 3
Training loss: 1.5153427124023438
Validation loss: 2.034488628307978

Epoch: 5| Step: 4
Training loss: 1.795239806175232
Validation loss: 2.0395596623420715

Epoch: 5| Step: 5
Training loss: 1.9803097248077393
Validation loss: 2.032169466217359

Epoch: 5| Step: 6
Training loss: 2.597942352294922
Validation loss: 2.039855644106865

Epoch: 5| Step: 7
Training loss: 1.8623058795928955
Validation loss: 2.0333943963050842

Epoch: 5| Step: 8
Training loss: 2.477020740509033
Validation loss: 2.0368095437685647

Epoch: 5| Step: 9
Training loss: 2.5774121284484863
Validation loss: 2.046154816945394

Epoch: 5| Step: 10
Training loss: 2.56794810295105
Validation loss: 2.0320101032654443

Epoch: 5| Step: 11
Training loss: 1.5267348289489746
Validation loss: 2.029394874970118

Epoch: 91| Step: 0
Training loss: 2.063345432281494
Validation loss: 2.025466278195381

Epoch: 5| Step: 1
Training loss: 2.063284397125244
Validation loss: 2.025792509317398

Epoch: 5| Step: 2
Training loss: 2.3095507621765137
Validation loss: 2.023748671015104

Epoch: 5| Step: 3
Training loss: 2.173813819885254
Validation loss: 2.0220309595266976

Epoch: 5| Step: 4
Training loss: 2.367408037185669
Validation loss: 2.025909552971522

Epoch: 5| Step: 5
Training loss: 2.3066797256469727
Validation loss: 2.0335006962219873

Epoch: 5| Step: 6
Training loss: 1.9409656524658203
Validation loss: 2.0376658042271933

Epoch: 5| Step: 7
Training loss: 2.2851405143737793
Validation loss: 2.0338260332743325

Epoch: 5| Step: 8
Training loss: 1.927919626235962
Validation loss: 2.0468909641106925

Epoch: 5| Step: 9
Training loss: 2.247889995574951
Validation loss: 2.045755162835121

Epoch: 5| Step: 10
Training loss: 2.474229574203491
Validation loss: 2.0488840540250144

Epoch: 5| Step: 11
Training loss: 1.63265061378479
Validation loss: 2.0379389425118766

Epoch: 92| Step: 0
Training loss: 2.164497137069702
Validation loss: 2.0426544894774756

Epoch: 5| Step: 1
Training loss: 2.2289998531341553
Validation loss: 2.0328866094350815

Epoch: 5| Step: 2
Training loss: 1.891396164894104
Validation loss: 2.033697952826818

Epoch: 5| Step: 3
Training loss: 2.414885997772217
Validation loss: 2.0349817474683127

Epoch: 5| Step: 4
Training loss: 2.2882087230682373
Validation loss: 2.0215760866800943

Epoch: 5| Step: 5
Training loss: 2.390639066696167
Validation loss: 2.029698913296064

Epoch: 5| Step: 6
Training loss: 1.9830734729766846
Validation loss: 2.0263475825389228

Epoch: 5| Step: 7
Training loss: 2.780184507369995
Validation loss: 2.026821553707123

Epoch: 5| Step: 8
Training loss: 1.6597849130630493
Validation loss: 2.0302438735961914

Epoch: 5| Step: 9
Training loss: 2.2274677753448486
Validation loss: 2.0311158299446106

Epoch: 5| Step: 10
Training loss: 2.013731002807617
Validation loss: 2.023995593190193

Epoch: 5| Step: 11
Training loss: 2.4830331802368164
Validation loss: 2.0322857946157455

Epoch: 93| Step: 0
Training loss: 2.539736747741699
Validation loss: 2.025956297914187

Epoch: 5| Step: 1
Training loss: 2.229947805404663
Validation loss: 2.031502569715182

Epoch: 5| Step: 2
Training loss: 1.6453235149383545
Validation loss: 2.0220427215099335

Epoch: 5| Step: 3
Training loss: 2.3036437034606934
Validation loss: 2.02882781624794

Epoch: 5| Step: 4
Training loss: 2.4653637409210205
Validation loss: 2.024865279595057

Epoch: 5| Step: 5
Training loss: 2.1014747619628906
Validation loss: 2.0211793333292007

Epoch: 5| Step: 6
Training loss: 2.0257492065429688
Validation loss: 2.01984911163648

Epoch: 5| Step: 7
Training loss: 1.8643020391464233
Validation loss: 2.0175151328245797

Epoch: 5| Step: 8
Training loss: 2.0888922214508057
Validation loss: 2.0124849627415338

Epoch: 5| Step: 9
Training loss: 2.538707733154297
Validation loss: 2.018572116891543

Epoch: 5| Step: 10
Training loss: 2.0423388481140137
Validation loss: 2.0234076529741287

Epoch: 5| Step: 11
Training loss: 2.350886344909668
Validation loss: 2.0225863605737686

Epoch: 94| Step: 0
Training loss: 1.9374072551727295
Validation loss: 2.037153681119283

Epoch: 5| Step: 1
Training loss: 2.4484169483184814
Validation loss: 2.0444963375727334

Epoch: 5| Step: 2
Training loss: 2.1549227237701416
Validation loss: 2.049601430694262

Epoch: 5| Step: 3
Training loss: 2.631516933441162
Validation loss: 2.0524957925081253

Epoch: 5| Step: 4
Training loss: 2.1809566020965576
Validation loss: 2.0483449548482895

Epoch: 5| Step: 5
Training loss: 2.2484705448150635
Validation loss: 2.057936410109202

Epoch: 5| Step: 6
Training loss: 2.167024612426758
Validation loss: 2.0663219690322876

Epoch: 5| Step: 7
Training loss: 1.9081741571426392
Validation loss: 2.053520237406095

Epoch: 5| Step: 8
Training loss: 1.9763752222061157
Validation loss: 2.049735556046168

Epoch: 5| Step: 9
Training loss: 2.5223519802093506
Validation loss: 2.0412773291269937

Epoch: 5| Step: 10
Training loss: 1.679694414138794
Validation loss: 2.028744359811147

Epoch: 5| Step: 11
Training loss: 2.630523204803467
Validation loss: 2.0212181409200034

Epoch: 95| Step: 0
Training loss: 2.6519336700439453
Validation loss: 2.022450789809227

Epoch: 5| Step: 1
Training loss: 2.5152177810668945
Validation loss: 2.02076322833697

Epoch: 5| Step: 2
Training loss: 1.946110486984253
Validation loss: 2.0287419160207114

Epoch: 5| Step: 3
Training loss: 2.1305642127990723
Validation loss: 2.020651544133822

Epoch: 5| Step: 4
Training loss: 1.6308889389038086
Validation loss: 2.021178205808004

Epoch: 5| Step: 5
Training loss: 2.0321173667907715
Validation loss: 2.0276115238666534

Epoch: 5| Step: 6
Training loss: 2.0637142658233643
Validation loss: 2.0223377297321954

Epoch: 5| Step: 7
Training loss: 2.4197752475738525
Validation loss: 2.02009753882885

Epoch: 5| Step: 8
Training loss: 2.1324427127838135
Validation loss: 2.023612995942434

Epoch: 5| Step: 9
Training loss: 2.264860153198242
Validation loss: 2.015553832054138

Epoch: 5| Step: 10
Training loss: 1.9480807781219482
Validation loss: 2.0208057910203934

Epoch: 5| Step: 11
Training loss: 2.9907727241516113
Validation loss: 2.0151928464571633

Epoch: 96| Step: 0
Training loss: 2.4532012939453125
Validation loss: 2.0182810028394065

Epoch: 5| Step: 1
Training loss: 2.240995407104492
Validation loss: 2.0130280454953513

Epoch: 5| Step: 2
Training loss: 1.3776521682739258
Validation loss: 2.0049829930067062

Epoch: 5| Step: 3
Training loss: 2.5879554748535156
Validation loss: 2.0143973926703134

Epoch: 5| Step: 4
Training loss: 2.183701753616333
Validation loss: 2.0125501404205957

Epoch: 5| Step: 5
Training loss: 2.4522085189819336
Validation loss: 2.0142053961753845

Epoch: 5| Step: 6
Training loss: 1.71542489528656
Validation loss: 2.0176109820604324

Epoch: 5| Step: 7
Training loss: 1.7677743434906006
Validation loss: 2.018290176987648

Epoch: 5| Step: 8
Training loss: 2.4961540699005127
Validation loss: 2.017102539539337

Epoch: 5| Step: 9
Training loss: 2.371502637863159
Validation loss: 2.0204382141431174

Epoch: 5| Step: 10
Training loss: 1.8924087285995483
Validation loss: 2.020504727959633

Epoch: 5| Step: 11
Training loss: 3.0842771530151367
Validation loss: 2.0244393249352775

Epoch: 97| Step: 0
Training loss: 1.48316490650177
Validation loss: 2.023511618375778

Epoch: 5| Step: 1
Training loss: 2.2542901039123535
Validation loss: 2.0296947260697684

Epoch: 5| Step: 2
Training loss: 2.544980525970459
Validation loss: 2.0275994539260864

Epoch: 5| Step: 3
Training loss: 2.3230042457580566
Validation loss: 2.033725137511889

Epoch: 5| Step: 4
Training loss: 2.342308759689331
Validation loss: 2.0270186911026635

Epoch: 5| Step: 5
Training loss: 1.3067594766616821
Validation loss: 2.018852482239405

Epoch: 5| Step: 6
Training loss: 2.2675693035125732
Validation loss: 2.023184304436048

Epoch: 5| Step: 7
Training loss: 2.6428728103637695
Validation loss: 2.030883481105169

Epoch: 5| Step: 8
Training loss: 2.1214325428009033
Validation loss: 2.028365542491277

Epoch: 5| Step: 9
Training loss: 2.4661998748779297
Validation loss: 2.0239415019750595

Epoch: 5| Step: 10
Training loss: 1.754254698753357
Validation loss: 2.0272635916868844

Epoch: 5| Step: 11
Training loss: 3.236888885498047
Validation loss: 2.031180366873741

Epoch: 98| Step: 0
Training loss: 1.7693984508514404
Validation loss: 2.0301349610090256

Epoch: 5| Step: 1
Training loss: 2.6202168464660645
Validation loss: 2.0331410467624664

Epoch: 5| Step: 2
Training loss: 1.622060775756836
Validation loss: 2.025382454196612

Epoch: 5| Step: 3
Training loss: 1.6958154439926147
Validation loss: 2.0308477580547333

Epoch: 5| Step: 4
Training loss: 1.9862638711929321
Validation loss: 2.035520444313685

Epoch: 5| Step: 5
Training loss: 1.9877945184707642
Validation loss: 2.0288699169953666

Epoch: 5| Step: 6
Training loss: 2.1561362743377686
Validation loss: 2.032657414674759

Epoch: 5| Step: 7
Training loss: 2.456470489501953
Validation loss: 2.0298755119244256

Epoch: 5| Step: 8
Training loss: 2.698914051055908
Validation loss: 2.0322339485088983

Epoch: 5| Step: 9
Training loss: 2.3744919300079346
Validation loss: 2.039201244711876

Epoch: 5| Step: 10
Training loss: 2.0438971519470215
Validation loss: 2.0300473223129907

Epoch: 5| Step: 11
Training loss: 3.2190353870391846
Validation loss: 2.03960482776165

Epoch: 99| Step: 0
Training loss: 1.9877574443817139
Validation loss: 2.0302056868871055

Epoch: 5| Step: 1
Training loss: 2.6551077365875244
Validation loss: 2.023633157213529

Epoch: 5| Step: 2
Training loss: 1.8444827795028687
Validation loss: 2.0197747399409614

Epoch: 5| Step: 3
Training loss: 2.4629180431365967
Validation loss: 2.0215778748194375

Epoch: 5| Step: 4
Training loss: 2.1209185123443604
Validation loss: 2.0354662189881005

Epoch: 5| Step: 5
Training loss: 2.1090850830078125
Validation loss: 2.0264842013518014

Epoch: 5| Step: 6
Training loss: 1.787152886390686
Validation loss: 2.028206338485082

Epoch: 5| Step: 7
Training loss: 2.8244166374206543
Validation loss: 2.0289580126603446

Epoch: 5| Step: 8
Training loss: 2.041902542114258
Validation loss: 2.033004735906919

Epoch: 5| Step: 9
Training loss: 1.9787795543670654
Validation loss: 2.026665449142456

Epoch: 5| Step: 10
Training loss: 2.011070489883423
Validation loss: 2.033745363354683

Epoch: 5| Step: 11
Training loss: 2.524620771408081
Validation loss: 2.036014790336291

Epoch: 100| Step: 0
Training loss: 2.0385756492614746
Validation loss: 2.0311284760634103

Epoch: 5| Step: 1
Training loss: 2.505751371383667
Validation loss: 2.0341473619143167

Epoch: 5| Step: 2
Training loss: 2.586130380630493
Validation loss: 2.0289540191491446

Epoch: 5| Step: 3
Training loss: 2.251577854156494
Validation loss: 2.0324531545241675

Epoch: 5| Step: 4
Training loss: 1.750751256942749
Validation loss: 2.031527817249298

Epoch: 5| Step: 5
Training loss: 1.8264338970184326
Validation loss: 2.01893882950147

Epoch: 5| Step: 6
Training loss: 2.544168472290039
Validation loss: 2.0187747478485107

Epoch: 5| Step: 7
Training loss: 1.7930278778076172
Validation loss: 2.0230192989110947

Epoch: 5| Step: 8
Training loss: 1.5580620765686035
Validation loss: 2.0352615217367807

Epoch: 5| Step: 9
Training loss: 2.5803298950195312
Validation loss: 2.0387926548719406

Epoch: 5| Step: 10
Training loss: 2.4399659633636475
Validation loss: 2.043170819679896

Epoch: 5| Step: 11
Training loss: 2.1338396072387695
Validation loss: 2.0386167565981546

Epoch: 101| Step: 0
Training loss: 1.7150249481201172
Validation loss: 2.0509196470181146

Epoch: 5| Step: 1
Training loss: 2.0975632667541504
Validation loss: 2.048233578602473

Epoch: 5| Step: 2
Training loss: 2.6146669387817383
Validation loss: 2.033853987852732

Epoch: 5| Step: 3
Training loss: 2.81447172164917
Validation loss: 2.031904955705007

Epoch: 5| Step: 4
Training loss: 1.68453848361969
Validation loss: 2.0254476368427277

Epoch: 5| Step: 5
Training loss: 1.9247267246246338
Validation loss: 2.0277617424726486

Epoch: 5| Step: 6
Training loss: 2.199808359146118
Validation loss: 2.0188123136758804

Epoch: 5| Step: 7
Training loss: 1.9532369375228882
Validation loss: 2.017155041297277

Epoch: 5| Step: 8
Training loss: 2.673959493637085
Validation loss: 2.023207346598307

Epoch: 5| Step: 9
Training loss: 2.1895973682403564
Validation loss: 2.0186621894439063

Epoch: 5| Step: 10
Training loss: 1.8122457265853882
Validation loss: 2.024768834312757

Epoch: 5| Step: 11
Training loss: 1.6220815181732178
Validation loss: 2.021253675222397

Epoch: 102| Step: 0
Training loss: 2.4024157524108887
Validation loss: 2.022701362768809

Epoch: 5| Step: 1
Training loss: 2.463857889175415
Validation loss: 2.0301234324773154

Epoch: 5| Step: 2
Training loss: 2.3776116371154785
Validation loss: 2.0382549166679382

Epoch: 5| Step: 3
Training loss: 2.170567750930786
Validation loss: 2.0408132076263428

Epoch: 5| Step: 4
Training loss: 2.325427532196045
Validation loss: 2.026871701081594

Epoch: 5| Step: 5
Training loss: 1.6951205730438232
Validation loss: 2.0391891101996102

Epoch: 5| Step: 6
Training loss: 1.84927499294281
Validation loss: 2.0287237564722695

Epoch: 5| Step: 7
Training loss: 2.4016895294189453
Validation loss: 2.037017280856768

Epoch: 5| Step: 8
Training loss: 1.589425802230835
Validation loss: 2.027949114640554

Epoch: 5| Step: 9
Training loss: 2.0892536640167236
Validation loss: 2.0331586748361588

Epoch: 5| Step: 10
Training loss: 2.3639578819274902
Validation loss: 2.021906942129135

Epoch: 5| Step: 11
Training loss: 2.135223865509033
Validation loss: 2.037377710143725

Epoch: 103| Step: 0
Training loss: 1.615684151649475
Validation loss: 2.0247153689463935

Epoch: 5| Step: 1
Training loss: 2.5825436115264893
Validation loss: 2.0191783706347146

Epoch: 5| Step: 2
Training loss: 2.190014600753784
Validation loss: 2.0270304729541144

Epoch: 5| Step: 3
Training loss: 2.2030186653137207
Validation loss: 2.019940803448359

Epoch: 5| Step: 4
Training loss: 1.9863061904907227
Validation loss: 2.022462765375773

Epoch: 5| Step: 5
Training loss: 1.988690972328186
Validation loss: 2.019868711630503

Epoch: 5| Step: 6
Training loss: 2.287278890609741
Validation loss: 2.022493446866671

Epoch: 5| Step: 7
Training loss: 2.1914520263671875
Validation loss: 2.015845616658529

Epoch: 5| Step: 8
Training loss: 2.2152035236358643
Validation loss: 2.0235309998194375

Epoch: 5| Step: 9
Training loss: 2.1429920196533203
Validation loss: 2.0283143619696298

Epoch: 5| Step: 10
Training loss: 2.178898572921753
Validation loss: 2.035404001673063

Epoch: 5| Step: 11
Training loss: 2.6094741821289062
Validation loss: 2.027975916862488

Epoch: 104| Step: 0
Training loss: 2.2919087409973145
Validation loss: 2.032166669766108

Epoch: 5| Step: 1
Training loss: 2.784842014312744
Validation loss: 2.0445000529289246

Epoch: 5| Step: 2
Training loss: 2.0751914978027344
Validation loss: 2.021715780099233

Epoch: 5| Step: 3
Training loss: 2.1852688789367676
Validation loss: 2.0316956092913947

Epoch: 5| Step: 4
Training loss: 2.609182357788086
Validation loss: 2.0161512047052383

Epoch: 5| Step: 5
Training loss: 2.1012816429138184
Validation loss: 2.015832786758741

Epoch: 5| Step: 6
Training loss: 1.7176767587661743
Validation loss: 2.007391800483068

Epoch: 5| Step: 7
Training loss: 1.2636191844940186
Validation loss: 2.0067871560653052

Epoch: 5| Step: 8
Training loss: 2.079759120941162
Validation loss: 2.0066576153039932

Epoch: 5| Step: 9
Training loss: 2.5003058910369873
Validation loss: 1.999680871764819

Epoch: 5| Step: 10
Training loss: 2.115450143814087
Validation loss: 2.0028009166320166

Epoch: 5| Step: 11
Training loss: 1.6279923915863037
Validation loss: 2.0167119006315866

Epoch: 105| Step: 0
Training loss: 2.124070644378662
Validation loss: 2.0146652907133102

Epoch: 5| Step: 1
Training loss: 2.2520718574523926
Validation loss: 2.0206473966439567

Epoch: 5| Step: 2
Training loss: 2.053288459777832
Validation loss: 2.0440217753251395

Epoch: 5| Step: 3
Training loss: 1.7461097240447998
Validation loss: 2.040759409467379

Epoch: 5| Step: 4
Training loss: 1.7334266901016235
Validation loss: 2.0512923697630563

Epoch: 5| Step: 5
Training loss: 1.7286561727523804
Validation loss: 2.0583647092183432

Epoch: 5| Step: 6
Training loss: 2.365917444229126
Validation loss: 2.0554078618685403

Epoch: 5| Step: 7
Training loss: 2.2622389793395996
Validation loss: 2.045652856429418

Epoch: 5| Step: 8
Training loss: 2.75350284576416
Validation loss: 2.050363620122274

Epoch: 5| Step: 9
Training loss: 2.505265474319458
Validation loss: 2.044504483540853

Epoch: 5| Step: 10
Training loss: 2.3061609268188477
Validation loss: 2.025404746333758

Epoch: 5| Step: 11
Training loss: 2.0162224769592285
Validation loss: 2.0063471496105194

Epoch: 106| Step: 0
Training loss: 2.1379456520080566
Validation loss: 2.010731965303421

Epoch: 5| Step: 1
Training loss: 2.2249436378479004
Validation loss: 2.0068837702274323

Epoch: 5| Step: 2
Training loss: 2.3186182975769043
Validation loss: 2.0041128595670066

Epoch: 5| Step: 3
Training loss: 1.8052246570587158
Validation loss: 2.009389971693357

Epoch: 5| Step: 4
Training loss: 1.556376576423645
Validation loss: 2.0129331747690835

Epoch: 5| Step: 5
Training loss: 3.078317880630493
Validation loss: 2.01746732989947

Epoch: 5| Step: 6
Training loss: 1.5751746892929077
Validation loss: 2.021118720372518

Epoch: 5| Step: 7
Training loss: 2.405783176422119
Validation loss: 2.021501193443934

Epoch: 5| Step: 8
Training loss: 2.6407835483551025
Validation loss: 2.016740237673124

Epoch: 5| Step: 9
Training loss: 2.139965772628784
Validation loss: 2.018633325894674

Epoch: 5| Step: 10
Training loss: 2.104726791381836
Validation loss: 2.0174647122621536

Epoch: 5| Step: 11
Training loss: 0.7950167655944824
Validation loss: 2.0125889480113983

Epoch: 107| Step: 0
Training loss: 2.230797290802002
Validation loss: 2.0123139172792435

Epoch: 5| Step: 1
Training loss: 1.987696647644043
Validation loss: 2.0112564961115518

Epoch: 5| Step: 2
Training loss: 2.308089256286621
Validation loss: 2.0144258787234626

Epoch: 5| Step: 3
Training loss: 2.0513644218444824
Validation loss: 2.028879071275393

Epoch: 5| Step: 4
Training loss: 2.3279120922088623
Validation loss: 2.0440921088059745

Epoch: 5| Step: 5
Training loss: 1.791805624961853
Validation loss: 2.0568218380212784

Epoch: 5| Step: 6
Training loss: 2.0423648357391357
Validation loss: 2.0567020028829575

Epoch: 5| Step: 7
Training loss: 2.2950830459594727
Validation loss: 2.0579224228858948

Epoch: 5| Step: 8
Training loss: 2.5039761066436768
Validation loss: 2.0623245437939963

Epoch: 5| Step: 9
Training loss: 2.047250747680664
Validation loss: 2.0325323790311813

Epoch: 5| Step: 10
Training loss: 2.5524353981018066
Validation loss: 2.027859921256701

Epoch: 5| Step: 11
Training loss: 2.3740451335906982
Validation loss: 2.0180925081173577

Epoch: 108| Step: 0
Training loss: 1.9554173946380615
Validation loss: 2.0073025077581406

Epoch: 5| Step: 1
Training loss: 1.9481451511383057
Validation loss: 2.009716014067332

Epoch: 5| Step: 2
Training loss: 2.362278938293457
Validation loss: 2.009131426612536

Epoch: 5| Step: 3
Training loss: 1.9890638589859009
Validation loss: 2.01890895764033

Epoch: 5| Step: 4
Training loss: 2.189730167388916
Validation loss: 2.0169284343719482

Epoch: 5| Step: 5
Training loss: 2.166301727294922
Validation loss: 2.025059978167216

Epoch: 5| Step: 6
Training loss: 2.5544400215148926
Validation loss: 2.0184356222550073

Epoch: 5| Step: 7
Training loss: 1.9663019180297852
Validation loss: 2.0289713690678277

Epoch: 5| Step: 8
Training loss: 2.2239601612091064
Validation loss: 2.030535951256752

Epoch: 5| Step: 9
Training loss: 2.2470459938049316
Validation loss: 2.023819317420324

Epoch: 5| Step: 10
Training loss: 2.068843126296997
Validation loss: 2.019871120651563

Epoch: 5| Step: 11
Training loss: 3.1015729904174805
Validation loss: 2.015149558583895

Epoch: 109| Step: 0
Training loss: 2.1451685428619385
Validation loss: 2.014898811777433

Epoch: 5| Step: 1
Training loss: 2.2357044219970703
Validation loss: 2.0146836936473846

Epoch: 5| Step: 2
Training loss: 2.4091014862060547
Validation loss: 2.0084060728549957

Epoch: 5| Step: 3
Training loss: 2.2298760414123535
Validation loss: 2.0088645418485007

Epoch: 5| Step: 4
Training loss: 2.4002482891082764
Validation loss: 2.0143615206082663

Epoch: 5| Step: 5
Training loss: 1.8902263641357422
Validation loss: 2.016772508621216

Epoch: 5| Step: 6
Training loss: 1.854720115661621
Validation loss: 2.0110089629888535

Epoch: 5| Step: 7
Training loss: 1.8053357601165771
Validation loss: 2.017155905564626

Epoch: 5| Step: 8
Training loss: 2.8588156700134277
Validation loss: 2.016853744784991

Epoch: 5| Step: 9
Training loss: 1.8499901294708252
Validation loss: 2.029591888189316

Epoch: 5| Step: 10
Training loss: 2.0281310081481934
Validation loss: 2.037489265203476

Epoch: 5| Step: 11
Training loss: 1.8936567306518555
Validation loss: 2.037481506665548

Epoch: 110| Step: 0
Training loss: 1.4394850730895996
Validation loss: 2.0349420805772147

Epoch: 5| Step: 1
Training loss: 2.221754550933838
Validation loss: 2.0473250299692154

Epoch: 5| Step: 2
Training loss: 1.9738686084747314
Validation loss: 2.0448116064071655

Epoch: 5| Step: 3
Training loss: 1.9211944341659546
Validation loss: 2.034704715013504

Epoch: 5| Step: 4
Training loss: 2.8008086681365967
Validation loss: 2.028772840897242

Epoch: 5| Step: 5
Training loss: 2.3125994205474854
Validation loss: 2.0244885186354318

Epoch: 5| Step: 6
Training loss: 2.040438175201416
Validation loss: 2.0197443763415017

Epoch: 5| Step: 7
Training loss: 2.5214521884918213
Validation loss: 2.022163192431132

Epoch: 5| Step: 8
Training loss: 2.6391797065734863
Validation loss: 2.0170992761850357

Epoch: 5| Step: 9
Training loss: 2.316829204559326
Validation loss: 2.0155172646045685

Epoch: 5| Step: 10
Training loss: 1.6554234027862549
Validation loss: 2.02150293191274

Epoch: 5| Step: 11
Training loss: 1.620794653892517
Validation loss: 2.010975867509842

Epoch: 111| Step: 0
Training loss: 2.1399927139282227
Validation loss: 2.0143083035945892

Epoch: 5| Step: 1
Training loss: 1.9637476205825806
Validation loss: 2.0096163203318915

Epoch: 5| Step: 2
Training loss: 2.961287021636963
Validation loss: 2.0201215346654258

Epoch: 5| Step: 3
Training loss: 2.5386829376220703
Validation loss: 2.0219221909840903

Epoch: 5| Step: 4
Training loss: 1.9378818273544312
Validation loss: 2.0153327882289886

Epoch: 5| Step: 5
Training loss: 1.437285304069519
Validation loss: 2.0186965813239417

Epoch: 5| Step: 6
Training loss: 1.883963942527771
Validation loss: 2.018423100312551

Epoch: 5| Step: 7
Training loss: 2.21836519241333
Validation loss: 2.014158229033152

Epoch: 5| Step: 8
Training loss: 2.2450156211853027
Validation loss: 2.023473526040713

Epoch: 5| Step: 9
Training loss: 2.0891528129577637
Validation loss: 2.024495835105578

Epoch: 5| Step: 10
Training loss: 2.198819160461426
Validation loss: 2.0317812810341516

Epoch: 5| Step: 11
Training loss: 2.0518839359283447
Validation loss: 2.039758841196696

Epoch: 112| Step: 0
Training loss: 2.623866558074951
Validation loss: 2.0367298324902854

Epoch: 5| Step: 1
Training loss: 1.9210309982299805
Validation loss: 2.031984696785609

Epoch: 5| Step: 2
Training loss: 1.670044183731079
Validation loss: 2.0366673668225608

Epoch: 5| Step: 3
Training loss: 2.306718349456787
Validation loss: 2.027745465437571

Epoch: 5| Step: 4
Training loss: 2.4585816860198975
Validation loss: 2.0159600426753364

Epoch: 5| Step: 5
Training loss: 2.4379873275756836
Validation loss: 2.0243563652038574

Epoch: 5| Step: 6
Training loss: 1.9522373676300049
Validation loss: 2.0278805096944175

Epoch: 5| Step: 7
Training loss: 2.1108202934265137
Validation loss: 2.0185942500829697

Epoch: 5| Step: 8
Training loss: 2.3157477378845215
Validation loss: 2.018173227707545

Epoch: 5| Step: 9
Training loss: 1.8574039936065674
Validation loss: 2.0041013608376184

Epoch: 5| Step: 10
Training loss: 2.1499714851379395
Validation loss: 2.0203721274932227

Epoch: 5| Step: 11
Training loss: 2.004786491394043
Validation loss: 2.0174726396799088

Epoch: 113| Step: 0
Training loss: 1.664363145828247
Validation loss: 2.0101955185333886

Epoch: 5| Step: 1
Training loss: 1.9443023204803467
Validation loss: 2.016235758860906

Epoch: 5| Step: 2
Training loss: 2.1956207752227783
Validation loss: 2.018206457297007

Epoch: 5| Step: 3
Training loss: 2.4291656017303467
Validation loss: 2.0227111329634986

Epoch: 5| Step: 4
Training loss: 1.5413272380828857
Validation loss: 2.0166295617818832

Epoch: 5| Step: 5
Training loss: 2.6726808547973633
Validation loss: 2.0163262089093528

Epoch: 5| Step: 6
Training loss: 2.064950704574585
Validation loss: 2.0257298350334167

Epoch: 5| Step: 7
Training loss: 2.124779462814331
Validation loss: 2.0240772515535355

Epoch: 5| Step: 8
Training loss: 2.369436264038086
Validation loss: 2.0194195409615836

Epoch: 5| Step: 9
Training loss: 2.185854196548462
Validation loss: 2.0141687840223312

Epoch: 5| Step: 10
Training loss: 2.5675082206726074
Validation loss: 2.0219729046026864

Epoch: 5| Step: 11
Training loss: 2.064210891723633
Validation loss: 2.0194052209456763

Epoch: 114| Step: 0
Training loss: 1.7814977169036865
Validation loss: 2.0170675416787467

Epoch: 5| Step: 1
Training loss: 1.8776748180389404
Validation loss: 2.0160896480083466

Epoch: 5| Step: 2
Training loss: 2.713738203048706
Validation loss: 2.0139453411102295

Epoch: 5| Step: 3
Training loss: 1.9242324829101562
Validation loss: 2.013047824303309

Epoch: 5| Step: 4
Training loss: 2.148172378540039
Validation loss: 2.019029979904493

Epoch: 5| Step: 5
Training loss: 2.4883415699005127
Validation loss: 2.0160648971796036

Epoch: 5| Step: 6
Training loss: 2.222754955291748
Validation loss: 2.0137917598088584

Epoch: 5| Step: 7
Training loss: 1.7761684656143188
Validation loss: 2.011924142638842

Epoch: 5| Step: 8
Training loss: 1.9166443347930908
Validation loss: 2.0155602792898812

Epoch: 5| Step: 9
Training loss: 2.3624720573425293
Validation loss: 2.018624638517698

Epoch: 5| Step: 10
Training loss: 2.1531107425689697
Validation loss: 2.0131713499625525

Epoch: 5| Step: 11
Training loss: 3.0114054679870605
Validation loss: 2.01692126194636

Epoch: 115| Step: 0
Training loss: 2.0714356899261475
Validation loss: 2.0372275908788047

Epoch: 5| Step: 1
Training loss: 1.913037657737732
Validation loss: 2.043101797501246

Epoch: 5| Step: 2
Training loss: 1.8169063329696655
Validation loss: 2.046353275577227

Epoch: 5| Step: 3
Training loss: 1.958863615989685
Validation loss: 2.061090608437856

Epoch: 5| Step: 4
Training loss: 2.094968795776367
Validation loss: 2.059250528613726

Epoch: 5| Step: 5
Training loss: 2.197829008102417
Validation loss: 2.0550173918406167

Epoch: 5| Step: 6
Training loss: 2.502058982849121
Validation loss: 2.066499983270963

Epoch: 5| Step: 7
Training loss: 2.176358461380005
Validation loss: 2.0505213290452957

Epoch: 5| Step: 8
Training loss: 2.8956704139709473
Validation loss: 2.054080287615458

Epoch: 5| Step: 9
Training loss: 2.4508860111236572
Validation loss: 2.0480830619732537

Epoch: 5| Step: 10
Training loss: 1.7786099910736084
Validation loss: 2.0214195996522903

Epoch: 5| Step: 11
Training loss: 2.565812587738037
Validation loss: 2.0282404770453772

Epoch: 116| Step: 0
Training loss: 1.7056944370269775
Validation loss: 2.014244869351387

Epoch: 5| Step: 1
Training loss: 2.3045098781585693
Validation loss: 2.01455623904864

Epoch: 5| Step: 2
Training loss: 2.0292768478393555
Validation loss: 2.0201154400904975

Epoch: 5| Step: 3
Training loss: 2.087432861328125
Validation loss: 2.014218956232071

Epoch: 5| Step: 4
Training loss: 2.2506256103515625
Validation loss: 2.0204110691944757

Epoch: 5| Step: 5
Training loss: 2.103086471557617
Validation loss: 2.0306791216135025

Epoch: 5| Step: 6
Training loss: 2.0622200965881348
Validation loss: 2.0272418906291327

Epoch: 5| Step: 7
Training loss: 2.1310160160064697
Validation loss: 2.0221746613581977

Epoch: 5| Step: 8
Training loss: 2.1456005573272705
Validation loss: 2.034040853381157

Epoch: 5| Step: 9
Training loss: 2.025733470916748
Validation loss: 2.0247112264235816

Epoch: 5| Step: 10
Training loss: 2.8222484588623047
Validation loss: 2.0199554165204368

Epoch: 5| Step: 11
Training loss: 1.9734597206115723
Validation loss: 2.016889547308286

Epoch: 117| Step: 0
Training loss: 2.3244030475616455
Validation loss: 2.014039918780327

Epoch: 5| Step: 1
Training loss: 1.8543281555175781
Validation loss: 2.0147801289955773

Epoch: 5| Step: 2
Training loss: 1.9349209070205688
Validation loss: 2.009861414631208

Epoch: 5| Step: 3
Training loss: 2.6319591999053955
Validation loss: 2.0126137733459473

Epoch: 5| Step: 4
Training loss: 1.923937201499939
Validation loss: 2.010745584964752

Epoch: 5| Step: 5
Training loss: 2.1652932167053223
Validation loss: 2.0114235629638038

Epoch: 5| Step: 6
Training loss: 2.26881742477417
Validation loss: 2.0170382062594094

Epoch: 5| Step: 7
Training loss: 2.6227469444274902
Validation loss: 2.0133696297804513

Epoch: 5| Step: 8
Training loss: 2.137232542037964
Validation loss: 2.016525074839592

Epoch: 5| Step: 9
Training loss: 1.987622618675232
Validation loss: 2.013635978102684

Epoch: 5| Step: 10
Training loss: 1.746148705482483
Validation loss: 2.0102282613515854

Epoch: 5| Step: 11
Training loss: 2.089049816131592
Validation loss: 2.014880751570066

Epoch: 118| Step: 0
Training loss: 2.4816110134124756
Validation loss: 2.0204203575849533

Epoch: 5| Step: 1
Training loss: 2.43638277053833
Validation loss: 2.0197073072195053

Epoch: 5| Step: 2
Training loss: 2.3572490215301514
Validation loss: 2.0274034986893334

Epoch: 5| Step: 3
Training loss: 1.5339076519012451
Validation loss: 2.027056028445562

Epoch: 5| Step: 4
Training loss: 2.2653510570526123
Validation loss: 2.0289165129264197

Epoch: 5| Step: 5
Training loss: 2.223231077194214
Validation loss: 2.0378327816724777

Epoch: 5| Step: 6
Training loss: 1.8728153705596924
Validation loss: 2.0385421564181647

Epoch: 5| Step: 7
Training loss: 1.7615082263946533
Validation loss: 2.039167031645775

Epoch: 5| Step: 8
Training loss: 2.359562635421753
Validation loss: 2.035438905159632

Epoch: 5| Step: 9
Training loss: 1.8122789859771729
Validation loss: 2.031720995903015

Epoch: 5| Step: 10
Training loss: 2.4809770584106445
Validation loss: 2.029897232850393

Epoch: 5| Step: 11
Training loss: 1.7516505718231201
Validation loss: 2.032877042889595

Epoch: 119| Step: 0
Training loss: 1.863126516342163
Validation loss: 2.03109439710776

Epoch: 5| Step: 1
Training loss: 1.985040307044983
Validation loss: 2.0345159421364465

Epoch: 5| Step: 2
Training loss: 2.2534573078155518
Validation loss: 2.035263563195864

Epoch: 5| Step: 3
Training loss: 2.42048978805542
Validation loss: 2.03532882531484

Epoch: 5| Step: 4
Training loss: 2.787275791168213
Validation loss: 2.046643907825152

Epoch: 5| Step: 5
Training loss: 1.7484242916107178
Validation loss: 2.045468250910441

Epoch: 5| Step: 6
Training loss: 2.48282790184021
Validation loss: 2.03782727320989

Epoch: 5| Step: 7
Training loss: 1.8498598337173462
Validation loss: 2.048201779524485

Epoch: 5| Step: 8
Training loss: 2.4652011394500732
Validation loss: 2.035322993993759

Epoch: 5| Step: 9
Training loss: 1.914973258972168
Validation loss: 2.0227179328600564

Epoch: 5| Step: 10
Training loss: 1.8408092260360718
Validation loss: 2.024013022581736

Epoch: 5| Step: 11
Training loss: 1.7332156896591187
Validation loss: 2.0266605764627457

Epoch: 120| Step: 0
Training loss: 2.0537755489349365
Validation loss: 2.023393844564756

Epoch: 5| Step: 1
Training loss: 1.9065824747085571
Validation loss: 2.027798041701317

Epoch: 5| Step: 2
Training loss: 2.26314640045166
Validation loss: 2.017984097202619

Epoch: 5| Step: 3
Training loss: 1.8530744314193726
Validation loss: 2.010480379064878

Epoch: 5| Step: 4
Training loss: 2.032371997833252
Validation loss: 2.0193361093600593

Epoch: 5| Step: 5
Training loss: 1.6086126565933228
Validation loss: 2.0170777986447015

Epoch: 5| Step: 6
Training loss: 2.1869404315948486
Validation loss: 2.0202480057875314

Epoch: 5| Step: 7
Training loss: 2.750670909881592
Validation loss: 2.0300286561250687

Epoch: 5| Step: 8
Training loss: 2.1404595375061035
Validation loss: 2.0235111763079963

Epoch: 5| Step: 9
Training loss: 1.6541163921356201
Validation loss: 2.026019051671028

Epoch: 5| Step: 10
Training loss: 2.917722225189209
Validation loss: 2.018767163157463

Epoch: 5| Step: 11
Training loss: 2.267517566680908
Validation loss: 2.014111638069153

Epoch: 121| Step: 0
Training loss: 1.8875484466552734
Validation loss: 2.0269417514403663

Epoch: 5| Step: 1
Training loss: 2.476308584213257
Validation loss: 2.0240648885567984

Epoch: 5| Step: 2
Training loss: 1.937690019607544
Validation loss: 2.0195461014906564

Epoch: 5| Step: 3
Training loss: 2.032114028930664
Validation loss: 2.019907241066297

Epoch: 5| Step: 4
Training loss: 2.221693754196167
Validation loss: 2.015955006082853

Epoch: 5| Step: 5
Training loss: 2.081326484680176
Validation loss: 2.0138366172711053

Epoch: 5| Step: 6
Training loss: 2.015681743621826
Validation loss: 2.0105630854765573

Epoch: 5| Step: 7
Training loss: 2.3827691078186035
Validation loss: 2.0054869105418525

Epoch: 5| Step: 8
Training loss: 2.1873109340667725
Validation loss: 2.00267859796683

Epoch: 5| Step: 9
Training loss: 2.0087177753448486
Validation loss: 2.0069922705491385

Epoch: 5| Step: 10
Training loss: 2.224811315536499
Validation loss: 2.0111640642086663

Epoch: 5| Step: 11
Training loss: 2.365818500518799
Validation loss: 2.0117390553156533

Epoch: 122| Step: 0
Training loss: 2.8481781482696533
Validation loss: 2.0215635746717453

Epoch: 5| Step: 1
Training loss: 2.339263439178467
Validation loss: 2.007836252450943

Epoch: 5| Step: 2
Training loss: 1.8566242456436157
Validation loss: 2.020544171333313

Epoch: 5| Step: 3
Training loss: 1.8220018148422241
Validation loss: 2.0245644946893058

Epoch: 5| Step: 4
Training loss: 1.4138826131820679
Validation loss: 2.0179315904776254

Epoch: 5| Step: 5
Training loss: 1.9213367700576782
Validation loss: 2.0357033063968024

Epoch: 5| Step: 6
Training loss: 2.065692186355591
Validation loss: 2.0266802608966827

Epoch: 5| Step: 7
Training loss: 2.2640089988708496
Validation loss: 2.0269979387521744

Epoch: 5| Step: 8
Training loss: 2.1005160808563232
Validation loss: 2.015568961699804

Epoch: 5| Step: 9
Training loss: 2.2244036197662354
Validation loss: 2.015059014161428

Epoch: 5| Step: 10
Training loss: 2.510455369949341
Validation loss: 2.0176702489455542

Epoch: 5| Step: 11
Training loss: 2.449747085571289
Validation loss: 2.014486074447632

Epoch: 123| Step: 0
Training loss: 2.009138584136963
Validation loss: 2.009613255659739

Epoch: 5| Step: 1
Training loss: 1.9092426300048828
Validation loss: 2.0076907873153687

Epoch: 5| Step: 2
Training loss: 1.9730637073516846
Validation loss: 2.021122212211291

Epoch: 5| Step: 3
Training loss: 2.1600375175476074
Validation loss: 2.020730177561442

Epoch: 5| Step: 4
Training loss: 2.1023712158203125
Validation loss: 2.0149627228577933

Epoch: 5| Step: 5
Training loss: 2.988740921020508
Validation loss: 2.025113746523857

Epoch: 5| Step: 6
Training loss: 2.4739811420440674
Validation loss: 2.0236620356639228

Epoch: 5| Step: 7
Training loss: 1.6307423114776611
Validation loss: 2.0284480998913446

Epoch: 5| Step: 8
Training loss: 2.4042627811431885
Validation loss: 2.0391879826784134

Epoch: 5| Step: 9
Training loss: 1.9291565418243408
Validation loss: 2.024819642305374

Epoch: 5| Step: 10
Training loss: 1.9822263717651367
Validation loss: 2.0250694354375205

Epoch: 5| Step: 11
Training loss: 1.4596832990646362
Validation loss: 2.0248332967360816

Epoch: 124| Step: 0
Training loss: 2.0747408866882324
Validation loss: 2.0125475227832794

Epoch: 5| Step: 1
Training loss: 2.211817979812622
Validation loss: 2.0111592014630637

Epoch: 5| Step: 2
Training loss: 1.7086153030395508
Validation loss: 2.0108800480763116

Epoch: 5| Step: 3
Training loss: 1.9840739965438843
Validation loss: 2.0148357500632605

Epoch: 5| Step: 4
Training loss: 2.4504809379577637
Validation loss: 2.0119977444410324

Epoch: 5| Step: 5
Training loss: 2.0176775455474854
Validation loss: 2.0170870820681253

Epoch: 5| Step: 6
Training loss: 1.945434331893921
Validation loss: 2.0128765404224396

Epoch: 5| Step: 7
Training loss: 1.7622543573379517
Validation loss: 2.023712004224459

Epoch: 5| Step: 8
Training loss: 2.4510982036590576
Validation loss: 2.0200833529233932

Epoch: 5| Step: 9
Training loss: 2.4490747451782227
Validation loss: 2.025957544644674

Epoch: 5| Step: 10
Training loss: 2.359976291656494
Validation loss: 2.0283211867014566

Epoch: 5| Step: 11
Training loss: 1.8353891372680664
Validation loss: 2.0259645581245422

Epoch: 125| Step: 0
Training loss: 1.7961909770965576
Validation loss: 2.027861605087916

Epoch: 5| Step: 1
Training loss: 1.720934271812439
Validation loss: 2.0241103370984397

Epoch: 5| Step: 2
Training loss: 2.609285354614258
Validation loss: 2.020852113763491

Epoch: 5| Step: 3
Training loss: 2.649017810821533
Validation loss: 2.014058788617452

Epoch: 5| Step: 4
Training loss: 2.2813148498535156
Validation loss: 2.0114653408527374

Epoch: 5| Step: 5
Training loss: 2.048631191253662
Validation loss: 2.0031048208475113

Epoch: 5| Step: 6
Training loss: 2.085360050201416
Validation loss: 2.0121040294567742

Epoch: 5| Step: 7
Training loss: 1.8425298929214478
Validation loss: 2.0073902110258737

Epoch: 5| Step: 8
Training loss: 2.2267978191375732
Validation loss: 2.017603745063146

Epoch: 5| Step: 9
Training loss: 2.155872106552124
Validation loss: 2.0145168205102286

Epoch: 5| Step: 10
Training loss: 2.007098913192749
Validation loss: 2.0117477476596832

Epoch: 5| Step: 11
Training loss: 1.8246097564697266
Validation loss: 2.004700650771459

Epoch: 126| Step: 0
Training loss: 2.2555534839630127
Validation loss: 2.023360381523768

Epoch: 5| Step: 1
Training loss: 1.9522186517715454
Validation loss: 2.0318708221117654

Epoch: 5| Step: 2
Training loss: 2.540701389312744
Validation loss: 2.0335034976402917

Epoch: 5| Step: 3
Training loss: 2.1998884677886963
Validation loss: 2.0299831380446753

Epoch: 5| Step: 4
Training loss: 2.4563469886779785
Validation loss: 2.0186934769153595

Epoch: 5| Step: 5
Training loss: 1.557978630065918
Validation loss: 2.0272817661364875

Epoch: 5| Step: 6
Training loss: 2.1140642166137695
Validation loss: 2.033735771973928

Epoch: 5| Step: 7
Training loss: 1.9175697565078735
Validation loss: 2.022969072063764

Epoch: 5| Step: 8
Training loss: 2.053987979888916
Validation loss: 2.020783911148707

Epoch: 5| Step: 9
Training loss: 2.308011531829834
Validation loss: 2.028835271795591

Epoch: 5| Step: 10
Training loss: 2.2641892433166504
Validation loss: 2.0254409313201904

Epoch: 5| Step: 11
Training loss: 0.7350136041641235
Validation loss: 2.0202308744192123

Epoch: 127| Step: 0
Training loss: 2.7099978923797607
Validation loss: 2.02883409957091

Epoch: 5| Step: 1
Training loss: 2.357994794845581
Validation loss: 2.0255237569411597

Epoch: 5| Step: 2
Training loss: 1.8498709201812744
Validation loss: 2.024416506290436

Epoch: 5| Step: 3
Training loss: 2.147763967514038
Validation loss: 2.0149611085653305

Epoch: 5| Step: 4
Training loss: 2.49372935295105
Validation loss: 2.016050467888514

Epoch: 5| Step: 5
Training loss: 1.4402216672897339
Validation loss: 2.020371754964193

Epoch: 5| Step: 6
Training loss: 2.2263076305389404
Validation loss: 2.0220414996147156

Epoch: 5| Step: 7
Training loss: 1.9023983478546143
Validation loss: 2.0270313223203025

Epoch: 5| Step: 8
Training loss: 2.2966322898864746
Validation loss: 2.0288104812304177

Epoch: 5| Step: 9
Training loss: 2.3241748809814453
Validation loss: 2.027867173155149

Epoch: 5| Step: 10
Training loss: 1.5934282541275024
Validation loss: 2.0325187693039575

Epoch: 5| Step: 11
Training loss: 2.0338072776794434
Validation loss: 2.030875171224276

Epoch: 128| Step: 0
Training loss: 2.1354830265045166
Validation loss: 2.0329766273498535

Epoch: 5| Step: 1
Training loss: 2.1380867958068848
Validation loss: 2.0266729444265366

Epoch: 5| Step: 2
Training loss: 1.9106041193008423
Validation loss: 2.030478209257126

Epoch: 5| Step: 3
Training loss: 1.2917379140853882
Validation loss: 2.0299136390288672

Epoch: 5| Step: 4
Training loss: 2.0055058002471924
Validation loss: 2.0202716489632926

Epoch: 5| Step: 5
Training loss: 2.8399739265441895
Validation loss: 2.023376375436783

Epoch: 5| Step: 6
Training loss: 1.9459969997406006
Validation loss: 2.0118184437354407

Epoch: 5| Step: 7
Training loss: 2.4228103160858154
Validation loss: 2.0047515630722046

Epoch: 5| Step: 8
Training loss: 2.34352445602417
Validation loss: 2.0074235945940018

Epoch: 5| Step: 9
Training loss: 2.2244155406951904
Validation loss: 2.0029193311929703

Epoch: 5| Step: 10
Training loss: 2.0906665325164795
Validation loss: 1.997378945350647

Epoch: 5| Step: 11
Training loss: 1.918607234954834
Validation loss: 1.9983385056257248

Epoch: 129| Step: 0
Training loss: 1.8962421417236328
Validation loss: 2.0009915431340537

Epoch: 5| Step: 1
Training loss: 2.2520859241485596
Validation loss: 2.0041145334641137

Epoch: 5| Step: 2
Training loss: 2.2072720527648926
Validation loss: 1.9965947419404984

Epoch: 5| Step: 3
Training loss: 2.5226869583129883
Validation loss: 2.000052640835444

Epoch: 5| Step: 4
Training loss: 2.148871898651123
Validation loss: 1.9981500208377838

Epoch: 5| Step: 5
Training loss: 2.0134189128875732
Validation loss: 2.0022965371608734

Epoch: 5| Step: 6
Training loss: 1.9074312448501587
Validation loss: 2.0035004764795303

Epoch: 5| Step: 7
Training loss: 1.6232932806015015
Validation loss: 2.0039232124884925

Epoch: 5| Step: 8
Training loss: 2.555518627166748
Validation loss: 2.00444532930851

Epoch: 5| Step: 9
Training loss: 2.0662760734558105
Validation loss: 2.008662352959315

Epoch: 5| Step: 10
Training loss: 1.894792914390564
Validation loss: 2.007570634285609

Epoch: 5| Step: 11
Training loss: 3.749509334564209
Validation loss: 2.0109161337216697

Epoch: 130| Step: 0
Training loss: 2.2581417560577393
Validation loss: 2.015445585052172

Epoch: 5| Step: 1
Training loss: 1.7347294092178345
Validation loss: 2.0096835841735206

Epoch: 5| Step: 2
Training loss: 2.5845980644226074
Validation loss: 2.017201075951258

Epoch: 5| Step: 3
Training loss: 1.7092492580413818
Validation loss: 2.0166055858135223

Epoch: 5| Step: 4
Training loss: 1.969922661781311
Validation loss: 2.0217661410570145

Epoch: 5| Step: 5
Training loss: 2.4145705699920654
Validation loss: 2.019993782043457

Epoch: 5| Step: 6
Training loss: 1.9396108388900757
Validation loss: 2.0178935527801514

Epoch: 5| Step: 7
Training loss: 2.655635356903076
Validation loss: 2.0255219787359238

Epoch: 5| Step: 8
Training loss: 1.6865742206573486
Validation loss: 2.020543401439985

Epoch: 5| Step: 9
Training loss: 1.8820364475250244
Validation loss: 2.0232496658960977

Epoch: 5| Step: 10
Training loss: 2.3766303062438965
Validation loss: 2.014536584417025

Epoch: 5| Step: 11
Training loss: 2.2048540115356445
Validation loss: 2.0149067441622415

Epoch: 131| Step: 0
Training loss: 2.121603012084961
Validation loss: 2.010527412096659

Epoch: 5| Step: 1
Training loss: 1.6591875553131104
Validation loss: 2.005907272299131

Epoch: 5| Step: 2
Training loss: 1.9204094409942627
Validation loss: 2.0035087863604226

Epoch: 5| Step: 3
Training loss: 2.2882494926452637
Validation loss: 1.995602731903394

Epoch: 5| Step: 4
Training loss: 2.1654434204101562
Validation loss: 2.0055121580759683

Epoch: 5| Step: 5
Training loss: 2.331432819366455
Validation loss: 2.0059422055880227

Epoch: 5| Step: 6
Training loss: 2.2116501331329346
Validation loss: 2.0112897058327994

Epoch: 5| Step: 7
Training loss: 1.8257299661636353
Validation loss: 2.0066254436969757

Epoch: 5| Step: 8
Training loss: 2.4143660068511963
Validation loss: 2.0117715299129486

Epoch: 5| Step: 9
Training loss: 1.9955558776855469
Validation loss: 2.0176630367835364

Epoch: 5| Step: 10
Training loss: 2.349520444869995
Validation loss: 2.004635920127233

Epoch: 5| Step: 11
Training loss: 1.9443761110305786
Validation loss: 2.0043943176666894

Epoch: 132| Step: 0
Training loss: 1.841434121131897
Validation loss: 1.996872420112292

Epoch: 5| Step: 1
Training loss: 1.7730461359024048
Validation loss: 1.9993416368961334

Epoch: 5| Step: 2
Training loss: 2.83050799369812
Validation loss: 1.9984012097120285

Epoch: 5| Step: 3
Training loss: 2.640514850616455
Validation loss: 2.001770297686259

Epoch: 5| Step: 4
Training loss: 2.01330304145813
Validation loss: 2.0012829154729843

Epoch: 5| Step: 5
Training loss: 1.7958539724349976
Validation loss: 2.016239196062088

Epoch: 5| Step: 6
Training loss: 1.8318052291870117
Validation loss: 2.008967772126198

Epoch: 5| Step: 7
Training loss: 1.6348388195037842
Validation loss: 2.0131810108820596

Epoch: 5| Step: 8
Training loss: 2.559235095977783
Validation loss: 2.0133978525797525

Epoch: 5| Step: 9
Training loss: 2.3567309379577637
Validation loss: 2.0037729988495507

Epoch: 5| Step: 10
Training loss: 2.1645679473876953
Validation loss: 2.009045953551928

Epoch: 5| Step: 11
Training loss: 2.132448673248291
Validation loss: 2.0036563028891883

Epoch: 133| Step: 0
Training loss: 2.01613450050354
Validation loss: 2.002990091840426

Epoch: 5| Step: 1
Training loss: 2.1827876567840576
Validation loss: 1.9979860583941143

Epoch: 5| Step: 2
Training loss: 2.22761869430542
Validation loss: 1.9989088475704193

Epoch: 5| Step: 3
Training loss: 1.971236228942871
Validation loss: 2.000113293528557

Epoch: 5| Step: 4
Training loss: 2.2232346534729004
Validation loss: 2.0008286039034524

Epoch: 5| Step: 5
Training loss: 2.542245388031006
Validation loss: 2.0034360190232596

Epoch: 5| Step: 6
Training loss: 1.582329511642456
Validation loss: 1.9991657833258312

Epoch: 5| Step: 7
Training loss: 2.017606735229492
Validation loss: 1.9962193816900253

Epoch: 5| Step: 8
Training loss: 1.9375364780426025
Validation loss: 2.0023705859978995

Epoch: 5| Step: 9
Training loss: 1.9687526226043701
Validation loss: 2.008003205060959

Epoch: 5| Step: 10
Training loss: 2.5201449394226074
Validation loss: 2.0106064776579538

Epoch: 5| Step: 11
Training loss: 1.9431002140045166
Validation loss: 2.018367583552996

Epoch: 134| Step: 0
Training loss: 2.0047526359558105
Validation loss: 2.0307579785585403

Epoch: 5| Step: 1
Training loss: 2.0496153831481934
Validation loss: 2.031166215737661

Epoch: 5| Step: 2
Training loss: 1.9259183406829834
Validation loss: 2.057230373223623

Epoch: 5| Step: 3
Training loss: 2.0531373023986816
Validation loss: 2.0454984406630197

Epoch: 5| Step: 4
Training loss: 2.0810461044311523
Validation loss: 2.060288980603218

Epoch: 5| Step: 5
Training loss: 2.060631275177002
Validation loss: 2.0563835253318152

Epoch: 5| Step: 6
Training loss: 2.628239154815674
Validation loss: 2.041288137435913

Epoch: 5| Step: 7
Training loss: 2.5083632469177246
Validation loss: 2.033200055360794

Epoch: 5| Step: 8
Training loss: 1.9934002161026
Validation loss: 2.016435757279396

Epoch: 5| Step: 9
Training loss: 2.112734794616699
Validation loss: 2.014879589279493

Epoch: 5| Step: 10
Training loss: 2.196265935897827
Validation loss: 2.0136371900637946

Epoch: 5| Step: 11
Training loss: 1.7293933629989624
Validation loss: 2.0167923967043557

Epoch: 135| Step: 0
Training loss: 1.7372710704803467
Validation loss: 2.023823161919912

Epoch: 5| Step: 1
Training loss: 2.0531668663024902
Validation loss: 2.0321408261855445

Epoch: 5| Step: 2
Training loss: 2.4563889503479004
Validation loss: 2.0342170546452203

Epoch: 5| Step: 3
Training loss: 2.4305338859558105
Validation loss: 2.034595414996147

Epoch: 5| Step: 4
Training loss: 2.4235150814056396
Validation loss: 2.031245936950048

Epoch: 5| Step: 5
Training loss: 1.5828423500061035
Validation loss: 2.0346228828032813

Epoch: 5| Step: 6
Training loss: 2.5273826122283936
Validation loss: 2.035375729203224

Epoch: 5| Step: 7
Training loss: 2.3637776374816895
Validation loss: 2.029810667037964

Epoch: 5| Step: 8
Training loss: 2.230971336364746
Validation loss: 2.034384777148565

Epoch: 5| Step: 9
Training loss: 2.141730308532715
Validation loss: 2.034603009621302

Epoch: 5| Step: 10
Training loss: 1.9366466999053955
Validation loss: 2.0272167921066284

Epoch: 5| Step: 11
Training loss: 1.740800142288208
Validation loss: 2.032316952943802

Epoch: 136| Step: 0
Training loss: 2.3133742809295654
Validation loss: 2.0321477949619293

Epoch: 5| Step: 1
Training loss: 2.4467413425445557
Validation loss: 2.0332916378974915

Epoch: 5| Step: 2
Training loss: 1.9497371912002563
Validation loss: 2.0301109105348587

Epoch: 5| Step: 3
Training loss: 2.31345796585083
Validation loss: 2.0309958358605704

Epoch: 5| Step: 4
Training loss: 1.923574447631836
Validation loss: 2.0357778817415237

Epoch: 5| Step: 5
Training loss: 2.2806057929992676
Validation loss: 2.023396462202072

Epoch: 5| Step: 6
Training loss: 2.1764464378356934
Validation loss: 2.0194089810053506

Epoch: 5| Step: 7
Training loss: 1.873436689376831
Validation loss: 2.0180772691965103

Epoch: 5| Step: 8
Training loss: 1.784393310546875
Validation loss: 2.012144982814789

Epoch: 5| Step: 9
Training loss: 2.500603199005127
Validation loss: 2.014608452717463

Epoch: 5| Step: 10
Training loss: 1.9235808849334717
Validation loss: 2.0052338937918344

Epoch: 5| Step: 11
Training loss: 2.617103099822998
Validation loss: 2.0098042686780295

Epoch: 137| Step: 0
Training loss: 2.488393783569336
Validation loss: 2.0116428583860397

Epoch: 5| Step: 1
Training loss: 1.9335616827011108
Validation loss: 2.0214148660500846

Epoch: 5| Step: 2
Training loss: 1.759523630142212
Validation loss: 2.021416962146759

Epoch: 5| Step: 3
Training loss: 2.263597011566162
Validation loss: 2.033014729619026

Epoch: 5| Step: 4
Training loss: 2.386843681335449
Validation loss: 2.0328359802563987

Epoch: 5| Step: 5
Training loss: 1.9358587265014648
Validation loss: 2.0431954115629196

Epoch: 5| Step: 6
Training loss: 2.2645418643951416
Validation loss: 2.0506296902894974

Epoch: 5| Step: 7
Training loss: 2.4985578060150146
Validation loss: 2.033696616689364

Epoch: 5| Step: 8
Training loss: 2.264904499053955
Validation loss: 2.0391671607891717

Epoch: 5| Step: 9
Training loss: 1.7205606698989868
Validation loss: 2.0453705489635468

Epoch: 5| Step: 10
Training loss: 1.7033048868179321
Validation loss: 2.0418692330519357

Epoch: 5| Step: 11
Training loss: 2.5131518840789795
Validation loss: 2.0304342408974967

Epoch: 138| Step: 0
Training loss: 2.168315887451172
Validation loss: 2.027423600355784

Epoch: 5| Step: 1
Training loss: 2.9068996906280518
Validation loss: 2.030363475282987

Epoch: 5| Step: 2
Training loss: 2.0648999214172363
Validation loss: 2.0165606439113617

Epoch: 5| Step: 3
Training loss: 2.201871633529663
Validation loss: 2.0222033262252808

Epoch: 5| Step: 4
Training loss: 2.409045457839966
Validation loss: 2.0163202782471976

Epoch: 5| Step: 5
Training loss: 2.435925006866455
Validation loss: 2.017323300242424

Epoch: 5| Step: 6
Training loss: 2.387791395187378
Validation loss: 2.0011581977208457

Epoch: 5| Step: 7
Training loss: 1.4733357429504395
Validation loss: 2.006282632549604

Epoch: 5| Step: 8
Training loss: 1.7984930276870728
Validation loss: 2.0062914391358695

Epoch: 5| Step: 9
Training loss: 1.7913700342178345
Validation loss: 2.012713839610418

Epoch: 5| Step: 10
Training loss: 1.7020524740219116
Validation loss: 2.0174171328544617

Epoch: 5| Step: 11
Training loss: 1.4758572578430176
Validation loss: 2.01875730852286

Epoch: 139| Step: 0
Training loss: 1.6559202671051025
Validation loss: 2.021302322546641

Epoch: 5| Step: 1
Training loss: 2.338477373123169
Validation loss: 2.022239605585734

Epoch: 5| Step: 2
Training loss: 1.6725488901138306
Validation loss: 2.0305201013882956

Epoch: 5| Step: 3
Training loss: 2.4077446460723877
Validation loss: 2.0361225505669913

Epoch: 5| Step: 4
Training loss: 1.818895697593689
Validation loss: 2.032948007186254

Epoch: 5| Step: 5
Training loss: 2.554938793182373
Validation loss: 2.0316612919171653

Epoch: 5| Step: 6
Training loss: 1.4059669971466064
Validation loss: 2.0229319781064987

Epoch: 5| Step: 7
Training loss: 2.432373523712158
Validation loss: 2.018323158224424

Epoch: 5| Step: 8
Training loss: 2.392512559890747
Validation loss: 2.01717010140419

Epoch: 5| Step: 9
Training loss: 2.510974168777466
Validation loss: 2.0086332658926644

Epoch: 5| Step: 10
Training loss: 2.1431705951690674
Validation loss: 2.002712125579516

Epoch: 5| Step: 11
Training loss: 2.368803024291992
Validation loss: 2.0041794081528983

Epoch: 140| Step: 0
Training loss: 1.8909858465194702
Validation loss: 2.001833975315094

Epoch: 5| Step: 1
Training loss: 2.0757763385772705
Validation loss: 2.011421889066696

Epoch: 5| Step: 2
Training loss: 2.216308116912842
Validation loss: 2.01912430425485

Epoch: 5| Step: 3
Training loss: 2.4106101989746094
Validation loss: 2.021139621734619

Epoch: 5| Step: 4
Training loss: 2.0141491889953613
Validation loss: 2.012089485923449

Epoch: 5| Step: 5
Training loss: 1.9865672588348389
Validation loss: 2.0177665054798126

Epoch: 5| Step: 6
Training loss: 2.4728050231933594
Validation loss: 2.0173692454894385

Epoch: 5| Step: 7
Training loss: 1.8225317001342773
Validation loss: 2.007436285416285

Epoch: 5| Step: 8
Training loss: 1.3694467544555664
Validation loss: 2.009317855040232

Epoch: 5| Step: 9
Training loss: 2.322185516357422
Validation loss: 2.0135794579982758

Epoch: 5| Step: 10
Training loss: 2.5450599193573
Validation loss: 2.01537232597669

Epoch: 5| Step: 11
Training loss: 2.1744017601013184
Validation loss: 2.0233854999144874

Epoch: 141| Step: 0
Training loss: 1.743533730506897
Validation loss: 2.016976609826088

Epoch: 5| Step: 1
Training loss: 1.7427221536636353
Validation loss: 2.0380246341228485

Epoch: 5| Step: 2
Training loss: 1.6597673892974854
Validation loss: 2.0188709447781243

Epoch: 5| Step: 3
Training loss: 2.2110164165496826
Validation loss: 2.0342452923456826

Epoch: 5| Step: 4
Training loss: 2.000974655151367
Validation loss: 2.037020539244016

Epoch: 5| Step: 5
Training loss: 2.5810911655426025
Validation loss: 2.029617339372635

Epoch: 5| Step: 6
Training loss: 2.138066053390503
Validation loss: 2.0208595991134644

Epoch: 5| Step: 7
Training loss: 2.261568069458008
Validation loss: 2.0217948108911514

Epoch: 5| Step: 8
Training loss: 2.482595443725586
Validation loss: 2.0249880899985633

Epoch: 5| Step: 9
Training loss: 1.6433079242706299
Validation loss: 2.017515540122986

Epoch: 5| Step: 10
Training loss: 2.511216402053833
Validation loss: 2.0089406867822013

Epoch: 5| Step: 11
Training loss: 3.105574369430542
Validation loss: 2.016226962208748

Epoch: 142| Step: 0
Training loss: 2.420301914215088
Validation loss: 2.01067220667998

Epoch: 5| Step: 1
Training loss: 2.02531099319458
Validation loss: 2.016644145051638

Epoch: 5| Step: 2
Training loss: 2.2909741401672363
Validation loss: 2.022289181749026

Epoch: 5| Step: 3
Training loss: 2.419990062713623
Validation loss: 2.0216843436161676

Epoch: 5| Step: 4
Training loss: 1.6800349950790405
Validation loss: 2.026820053656896

Epoch: 5| Step: 5
Training loss: 1.7917072772979736
Validation loss: 2.034688249230385

Epoch: 5| Step: 6
Training loss: 2.8695120811462402
Validation loss: 2.031571179628372

Epoch: 5| Step: 7
Training loss: 2.4608359336853027
Validation loss: 2.031947116057078

Epoch: 5| Step: 8
Training loss: 2.031817674636841
Validation loss: 2.033870314558347

Epoch: 5| Step: 9
Training loss: 1.784421682357788
Validation loss: 2.034081677595774

Epoch: 5| Step: 10
Training loss: 1.4393364191055298
Validation loss: 2.029205471277237

Epoch: 5| Step: 11
Training loss: 2.3100967407226562
Validation loss: 2.0244430154561996

Epoch: 143| Step: 0
Training loss: 2.155424118041992
Validation loss: 2.0164865801731744

Epoch: 5| Step: 1
Training loss: 1.9050178527832031
Validation loss: 2.0090026954809823

Epoch: 5| Step: 2
Training loss: 1.5365039110183716
Validation loss: 1.9958834101756413

Epoch: 5| Step: 3
Training loss: 2.170382499694824
Validation loss: 1.9916485746701558

Epoch: 5| Step: 4
Training loss: 2.937803268432617
Validation loss: 2.0060941874980927

Epoch: 5| Step: 5
Training loss: 2.075678825378418
Validation loss: 2.00625050564607

Epoch: 5| Step: 6
Training loss: 2.1274497509002686
Validation loss: 2.012851764758428

Epoch: 5| Step: 7
Training loss: 2.4994959831237793
Validation loss: 2.0154142131408057

Epoch: 5| Step: 8
Training loss: 2.080078125
Validation loss: 2.019346455732981

Epoch: 5| Step: 9
Training loss: 1.7315229177474976
Validation loss: 2.016082207361857

Epoch: 5| Step: 10
Training loss: 2.0502986907958984
Validation loss: 2.015648682912191

Epoch: 5| Step: 11
Training loss: 3.515549898147583
Validation loss: 2.0158440619707108

Epoch: 144| Step: 0
Training loss: 2.2806315422058105
Validation loss: 2.011757562557856

Epoch: 5| Step: 1
Training loss: 1.9171056747436523
Validation loss: 2.0077654272317886

Epoch: 5| Step: 2
Training loss: 2.6426944732666016
Validation loss: 2.0026849855979285

Epoch: 5| Step: 3
Training loss: 2.2900726795196533
Validation loss: 2.002966895699501

Epoch: 5| Step: 4
Training loss: 1.8083317279815674
Validation loss: 2.005490014950434

Epoch: 5| Step: 5
Training loss: 2.379729986190796
Validation loss: 2.0030231873194375

Epoch: 5| Step: 6
Training loss: 1.330406904220581
Validation loss: 2.014692564805349

Epoch: 5| Step: 7
Training loss: 2.3417859077453613
Validation loss: 2.0113978385925293

Epoch: 5| Step: 8
Training loss: 1.9685341119766235
Validation loss: 2.018916681408882

Epoch: 5| Step: 9
Training loss: 2.348905563354492
Validation loss: 2.0202448020378747

Epoch: 5| Step: 10
Training loss: 2.108450412750244
Validation loss: 2.0257220764954886

Epoch: 5| Step: 11
Training loss: 1.5741353034973145
Validation loss: 2.019924576083819

Epoch: 145| Step: 0
Training loss: 3.00742244720459
Validation loss: 2.0216070165236792

Epoch: 5| Step: 1
Training loss: 1.8235976696014404
Validation loss: 2.025548701484998

Epoch: 5| Step: 2
Training loss: 1.495274305343628
Validation loss: 2.0280971626440683

Epoch: 5| Step: 3
Training loss: 1.6949303150177002
Validation loss: 2.0324018746614456

Epoch: 5| Step: 4
Training loss: 1.9819780588150024
Validation loss: 2.025707890590032

Epoch: 5| Step: 5
Training loss: 2.2880382537841797
Validation loss: 2.039604142308235

Epoch: 5| Step: 6
Training loss: 2.302687406539917
Validation loss: 2.0273588995138803

Epoch: 5| Step: 7
Training loss: 2.4295828342437744
Validation loss: 2.0281379371881485

Epoch: 5| Step: 8
Training loss: 1.7487624883651733
Validation loss: 2.021305869023005

Epoch: 5| Step: 9
Training loss: 2.058413028717041
Validation loss: 2.010951648155848

Epoch: 5| Step: 10
Training loss: 2.392246961593628
Validation loss: 2.0162239025036492

Epoch: 5| Step: 11
Training loss: 1.105396032333374
Validation loss: 2.020849034190178

Epoch: 146| Step: 0
Training loss: 2.311471462249756
Validation loss: 2.016457478205363

Epoch: 5| Step: 1
Training loss: 2.6062161922454834
Validation loss: 2.0092602570851645

Epoch: 5| Step: 2
Training loss: 2.0470070838928223
Validation loss: 2.0057771801948547

Epoch: 5| Step: 3
Training loss: 2.107563018798828
Validation loss: 2.0034939597050347

Epoch: 5| Step: 4
Training loss: 2.2315144538879395
Validation loss: 2.0061812549829483

Epoch: 5| Step: 5
Training loss: 1.5438135862350464
Validation loss: 2.0074492494265237

Epoch: 5| Step: 6
Training loss: 1.7204983234405518
Validation loss: 2.0007485250631967

Epoch: 5| Step: 7
Training loss: 1.3608591556549072
Validation loss: 2.0063131749629974

Epoch: 5| Step: 8
Training loss: 2.0898971557617188
Validation loss: 2.0153070837259293

Epoch: 5| Step: 9
Training loss: 2.3668127059936523
Validation loss: 2.0257751444975534

Epoch: 5| Step: 10
Training loss: 2.633287191390991
Validation loss: 2.022987405459086

Epoch: 5| Step: 11
Training loss: 3.1468710899353027
Validation loss: 2.0261104057232537

Epoch: 147| Step: 0
Training loss: 1.8941967487335205
Validation loss: 2.0273817628622055

Epoch: 5| Step: 1
Training loss: 1.9265960454940796
Validation loss: 2.031722808877627

Epoch: 5| Step: 2
Training loss: 2.07426118850708
Validation loss: 2.0344213247299194

Epoch: 5| Step: 3
Training loss: 1.9650204181671143
Validation loss: 2.032121643424034

Epoch: 5| Step: 4
Training loss: 2.5166268348693848
Validation loss: 2.026138042410215

Epoch: 5| Step: 5
Training loss: 2.15950083732605
Validation loss: 2.0308018972476325

Epoch: 5| Step: 6
Training loss: 2.1301839351654053
Validation loss: 2.0282994210720062

Epoch: 5| Step: 7
Training loss: 2.039848566055298
Validation loss: 2.0223750323057175

Epoch: 5| Step: 8
Training loss: 2.018303871154785
Validation loss: 2.019773001472155

Epoch: 5| Step: 9
Training loss: 1.9172776937484741
Validation loss: 2.0094829152027764

Epoch: 5| Step: 10
Training loss: 2.5709588527679443
Validation loss: 2.009662543733915

Epoch: 5| Step: 11
Training loss: 2.2179341316223145
Validation loss: 2.0085707356532416

Epoch: 148| Step: 0
Training loss: 2.0626587867736816
Validation loss: 2.0116224537293115

Epoch: 5| Step: 1
Training loss: 1.8005907535552979
Validation loss: 2.018707195917765

Epoch: 5| Step: 2
Training loss: 2.5343785285949707
Validation loss: 2.015457878510157

Epoch: 5| Step: 3
Training loss: 1.987605094909668
Validation loss: 2.0210464894771576

Epoch: 5| Step: 4
Training loss: 2.155226230621338
Validation loss: 2.0164393534262977

Epoch: 5| Step: 5
Training loss: 2.066061019897461
Validation loss: 2.017210682233175

Epoch: 5| Step: 6
Training loss: 1.7008230686187744
Validation loss: 2.0193856159845986

Epoch: 5| Step: 7
Training loss: 2.2983481884002686
Validation loss: 2.0084261695543923

Epoch: 5| Step: 8
Training loss: 2.2664194107055664
Validation loss: 2.0088670750459037

Epoch: 5| Step: 9
Training loss: 1.780069351196289
Validation loss: 2.004767954349518

Epoch: 5| Step: 10
Training loss: 2.4186692237854004
Validation loss: 2.012373854716619

Epoch: 5| Step: 11
Training loss: 3.480196714401245
Validation loss: 2.0199556201696396

Epoch: 149| Step: 0
Training loss: 1.9686212539672852
Validation loss: 2.023563732703527

Epoch: 5| Step: 1
Training loss: 2.2895545959472656
Validation loss: 2.0294921646515527

Epoch: 5| Step: 2
Training loss: 2.029879093170166
Validation loss: 2.042770857612292

Epoch: 5| Step: 3
Training loss: 2.0335259437561035
Validation loss: 2.0386391083399453

Epoch: 5| Step: 4
Training loss: 1.9436266422271729
Validation loss: 2.0628769993782043

Epoch: 5| Step: 5
Training loss: 1.6932971477508545
Validation loss: 2.0569391945997872

Epoch: 5| Step: 6
Training loss: 2.1860508918762207
Validation loss: 2.0576457331577935

Epoch: 5| Step: 7
Training loss: 2.023071527481079
Validation loss: 2.0570119669040046

Epoch: 5| Step: 8
Training loss: 2.899463176727295
Validation loss: 2.0457056164741516

Epoch: 5| Step: 9
Training loss: 2.4442601203918457
Validation loss: 2.041193574666977

Epoch: 5| Step: 10
Training loss: 1.8313331604003906
Validation loss: 2.0257281213998795

Epoch: 5| Step: 11
Training loss: 2.39522385597229
Validation loss: 2.0370271503925323

Epoch: 150| Step: 0
Training loss: 1.7291539907455444
Validation loss: 2.0173009584347406

Epoch: 5| Step: 1
Training loss: 1.7293392419815063
Validation loss: 2.0056016047795615

Epoch: 5| Step: 2
Training loss: 2.7888123989105225
Validation loss: 2.0007683535416922

Epoch: 5| Step: 3
Training loss: 2.088963508605957
Validation loss: 1.9987276991208394

Epoch: 5| Step: 4
Training loss: 2.324575901031494
Validation loss: 2.006918782989184

Epoch: 5| Step: 5
Training loss: 2.467315196990967
Validation loss: 2.0132088512182236

Epoch: 5| Step: 6
Training loss: 2.211970329284668
Validation loss: 2.009492655595144

Epoch: 5| Step: 7
Training loss: 1.7584991455078125
Validation loss: 2.0176310588916144

Epoch: 5| Step: 8
Training loss: 1.8799362182617188
Validation loss: 2.010602444410324

Epoch: 5| Step: 9
Training loss: 2.0613720417022705
Validation loss: 1.9969564080238342

Epoch: 5| Step: 10
Training loss: 2.4004998207092285
Validation loss: 2.000064661105474

Epoch: 5| Step: 11
Training loss: 1.1838923692703247
Validation loss: 2.000796983639399

Epoch: 151| Step: 0
Training loss: 1.7088559865951538
Validation loss: 1.9942391018072765

Epoch: 5| Step: 1
Training loss: 2.1093344688415527
Validation loss: 1.9928169697523117

Epoch: 5| Step: 2
Training loss: 1.6885833740234375
Validation loss: 1.9884436478217442

Epoch: 5| Step: 3
Training loss: 1.7564719915390015
Validation loss: 1.99482266108195

Epoch: 5| Step: 4
Training loss: 2.237279176712036
Validation loss: 2.0042021671930947

Epoch: 5| Step: 5
Training loss: 1.9982792139053345
Validation loss: 2.0064374258120856

Epoch: 5| Step: 6
Training loss: 2.5234391689300537
Validation loss: 2.007125382622083

Epoch: 5| Step: 7
Training loss: 2.4415371417999268
Validation loss: 2.02460840344429

Epoch: 5| Step: 8
Training loss: 1.8680038452148438
Validation loss: 2.0165100395679474

Epoch: 5| Step: 9
Training loss: 2.5734353065490723
Validation loss: 2.029318039615949

Epoch: 5| Step: 10
Training loss: 2.212373733520508
Validation loss: 2.0357767989238105

Epoch: 5| Step: 11
Training loss: 2.393972396850586
Validation loss: 2.036053607861201

Epoch: 152| Step: 0
Training loss: 2.358044385910034
Validation loss: 2.034732848405838

Epoch: 5| Step: 1
Training loss: 2.237244129180908
Validation loss: 2.025293524066607

Epoch: 5| Step: 2
Training loss: 2.1020960807800293
Validation loss: 2.0099481095870337

Epoch: 5| Step: 3
Training loss: 2.688770055770874
Validation loss: 2.0067231953144073

Epoch: 5| Step: 4
Training loss: 1.4738351106643677
Validation loss: 2.0042312294244766

Epoch: 5| Step: 5
Training loss: 2.351243019104004
Validation loss: 2.0118263214826584

Epoch: 5| Step: 6
Training loss: 2.520516872406006
Validation loss: 2.009474148352941

Epoch: 5| Step: 7
Training loss: 1.855006217956543
Validation loss: 2.01499804854393

Epoch: 5| Step: 8
Training loss: 1.8765223026275635
Validation loss: 2.0213940739631653

Epoch: 5| Step: 9
Training loss: 1.819253921508789
Validation loss: 2.0121983836094537

Epoch: 5| Step: 10
Training loss: 2.3064138889312744
Validation loss: 2.0138229380051293

Epoch: 5| Step: 11
Training loss: 0.9194525480270386
Validation loss: 2.0081060379743576

Epoch: 153| Step: 0
Training loss: 2.0261569023132324
Validation loss: 2.0091927448908486

Epoch: 5| Step: 1
Training loss: 2.271078109741211
Validation loss: 2.003895287712415

Epoch: 5| Step: 2
Training loss: 1.8677304983139038
Validation loss: 1.998216688632965

Epoch: 5| Step: 3
Training loss: 2.305668592453003
Validation loss: 1.9979372719923656

Epoch: 5| Step: 4
Training loss: 2.1140358448028564
Validation loss: 2.0059965203205743

Epoch: 5| Step: 5
Training loss: 1.9594405889511108
Validation loss: 2.014818290869395

Epoch: 5| Step: 6
Training loss: 2.22381591796875
Validation loss: 2.006427382429441

Epoch: 5| Step: 7
Training loss: 2.077497959136963
Validation loss: 2.0076920141776404

Epoch: 5| Step: 8
Training loss: 2.082207679748535
Validation loss: 2.0154268046220145

Epoch: 5| Step: 9
Training loss: 2.2105422019958496
Validation loss: 2.012322321534157

Epoch: 5| Step: 10
Training loss: 2.125579833984375
Validation loss: 2.013948768377304

Epoch: 5| Step: 11
Training loss: 1.4775173664093018
Validation loss: 2.0186576396226883

Epoch: 154| Step: 0
Training loss: 1.98724365234375
Validation loss: 2.0090236018101373

Epoch: 5| Step: 1
Training loss: 2.338350772857666
Validation loss: 2.009284238020579

Epoch: 5| Step: 2
Training loss: 2.029156446456909
Validation loss: 2.0148987074693046

Epoch: 5| Step: 3
Training loss: 1.448441505432129
Validation loss: 2.0166971335808435

Epoch: 5| Step: 4
Training loss: 1.8030426502227783
Validation loss: 2.023065055410067

Epoch: 5| Step: 5
Training loss: 1.7447932958602905
Validation loss: 2.016301065683365

Epoch: 5| Step: 6
Training loss: 3.088871479034424
Validation loss: 2.0275580336650214

Epoch: 5| Step: 7
Training loss: 1.9837048053741455
Validation loss: 2.030632416407267

Epoch: 5| Step: 8
Training loss: 1.6047359704971313
Validation loss: 2.0367017885049186

Epoch: 5| Step: 9
Training loss: 2.7087790966033936
Validation loss: 2.0397456735372543

Epoch: 5| Step: 10
Training loss: 2.1791434288024902
Validation loss: 2.0373129149278006

Epoch: 5| Step: 11
Training loss: 2.0507025718688965
Validation loss: 2.044432277480761

Epoch: 155| Step: 0
Training loss: 2.0667004585266113
Validation loss: 2.033180912335714

Epoch: 5| Step: 1
Training loss: 2.1397271156311035
Validation loss: 2.0338232815265656

Epoch: 5| Step: 2
Training loss: 2.071986675262451
Validation loss: 2.0242835134267807

Epoch: 5| Step: 3
Training loss: 2.1913726329803467
Validation loss: 2.0271158119042716

Epoch: 5| Step: 4
Training loss: 2.0152344703674316
Validation loss: 2.0233554343382516

Epoch: 5| Step: 5
Training loss: 1.8298450708389282
Validation loss: 2.0214611838261285

Epoch: 5| Step: 6
Training loss: 2.0951013565063477
Validation loss: 2.026567742228508

Epoch: 5| Step: 7
Training loss: 2.2014448642730713
Validation loss: 2.0213638146718345

Epoch: 5| Step: 8
Training loss: 2.1854329109191895
Validation loss: 2.0196198572715125

Epoch: 5| Step: 9
Training loss: 2.164645195007324
Validation loss: 2.0306813518206277

Epoch: 5| Step: 10
Training loss: 1.9888744354248047
Validation loss: 2.025059019525846

Epoch: 5| Step: 11
Training loss: 1.9202765226364136
Validation loss: 2.0311783204476037

Epoch: 156| Step: 0
Training loss: 2.5204200744628906
Validation loss: 2.0238115340471268

Epoch: 5| Step: 1
Training loss: 1.3782975673675537
Validation loss: 2.0237723737955093

Epoch: 5| Step: 2
Training loss: 2.305717945098877
Validation loss: 2.0176675468683243

Epoch: 5| Step: 3
Training loss: 1.7856452465057373
Validation loss: 2.0137254893779755

Epoch: 5| Step: 4
Training loss: 2.187786102294922
Validation loss: 2.0190874685843787

Epoch: 5| Step: 5
Training loss: 1.6571578979492188
Validation loss: 2.0168426732222238

Epoch: 5| Step: 6
Training loss: 2.3164052963256836
Validation loss: 2.011842727661133

Epoch: 5| Step: 7
Training loss: 2.179759979248047
Validation loss: 2.01572223007679

Epoch: 5| Step: 8
Training loss: 2.6956279277801514
Validation loss: 2.0103245625893273

Epoch: 5| Step: 9
Training loss: 1.8425356149673462
Validation loss: 2.0075453917185464

Epoch: 5| Step: 10
Training loss: 2.172292470932007
Validation loss: 2.0046900659799576

Epoch: 5| Step: 11
Training loss: 1.7578648328781128
Validation loss: 2.011210466424624

Epoch: 157| Step: 0
Training loss: 2.8530120849609375
Validation loss: 2.0137602984905243

Epoch: 5| Step: 1
Training loss: 1.9696769714355469
Validation loss: 2.0114666521549225

Epoch: 5| Step: 2
Training loss: 1.3942254781723022
Validation loss: 2.0081804990768433

Epoch: 5| Step: 3
Training loss: 2.2758259773254395
Validation loss: 2.022246688604355

Epoch: 5| Step: 4
Training loss: 2.5441904067993164
Validation loss: 2.0234144727389016

Epoch: 5| Step: 5
Training loss: 2.251842975616455
Validation loss: 2.0223491837581

Epoch: 5| Step: 6
Training loss: 1.734182357788086
Validation loss: 2.0273916870355606

Epoch: 5| Step: 7
Training loss: 2.0546438694000244
Validation loss: 2.029319331049919

Epoch: 5| Step: 8
Training loss: 1.9540761709213257
Validation loss: 2.022864878177643

Epoch: 5| Step: 9
Training loss: 1.9347635507583618
Validation loss: 2.0233666549126306

Epoch: 5| Step: 10
Training loss: 1.9209861755371094
Validation loss: 2.0078763564427695

Epoch: 5| Step: 11
Training loss: 1.8612626791000366
Validation loss: 2.005131890376409

Epoch: 158| Step: 0
Training loss: 1.859188437461853
Validation loss: 1.9992639869451523

Epoch: 5| Step: 1
Training loss: 1.929528832435608
Validation loss: 2.005427489678065

Epoch: 5| Step: 2
Training loss: 2.2054896354675293
Validation loss: 2.0039191792408624

Epoch: 5| Step: 3
Training loss: 1.7358238697052002
Validation loss: 2.001472840706507

Epoch: 5| Step: 4
Training loss: 2.285773754119873
Validation loss: 2.00445556640625

Epoch: 5| Step: 5
Training loss: 2.1142497062683105
Validation loss: 2.006740296880404

Epoch: 5| Step: 6
Training loss: 1.6919788122177124
Validation loss: 1.9983361810445786

Epoch: 5| Step: 7
Training loss: 1.586235523223877
Validation loss: 2.0032912443081536

Epoch: 5| Step: 8
Training loss: 2.5432729721069336
Validation loss: 2.007243742545446

Epoch: 5| Step: 9
Training loss: 2.250471591949463
Validation loss: 2.0106654167175293

Epoch: 5| Step: 10
Training loss: 2.6678810119628906
Validation loss: 2.0143111646175385

Epoch: 5| Step: 11
Training loss: 2.063995838165283
Validation loss: 2.0156349490086236

Epoch: 159| Step: 0
Training loss: 1.741756796836853
Validation loss: 2.0229833722114563

Epoch: 5| Step: 1
Training loss: 2.1083571910858154
Validation loss: 2.0278445184230804

Epoch: 5| Step: 2
Training loss: 2.0835814476013184
Validation loss: 2.029791682958603

Epoch: 5| Step: 3
Training loss: 2.6783366203308105
Validation loss: 2.0303093045949936

Epoch: 5| Step: 4
Training loss: 1.9288253784179688
Validation loss: 2.03265750904878

Epoch: 5| Step: 5
Training loss: 1.8789581060409546
Validation loss: 2.04912997285525

Epoch: 5| Step: 6
Training loss: 2.3911948204040527
Validation loss: 2.0383409758408866

Epoch: 5| Step: 7
Training loss: 1.9657491445541382
Validation loss: 2.03001236418883

Epoch: 5| Step: 8
Training loss: 2.2585906982421875
Validation loss: 2.034836933016777

Epoch: 5| Step: 9
Training loss: 2.174938678741455
Validation loss: 2.0402269115050635

Epoch: 5| Step: 10
Training loss: 1.658966064453125
Validation loss: 2.0235374867916107

Epoch: 5| Step: 11
Training loss: 2.6910452842712402
Validation loss: 2.0246561070283255

Epoch: 160| Step: 0
Training loss: 1.9096431732177734
Validation loss: 2.0246057411034903

Epoch: 5| Step: 1
Training loss: 1.8467292785644531
Validation loss: 2.0254404544830322

Epoch: 5| Step: 2
Training loss: 2.6615359783172607
Validation loss: 2.0134553412596383

Epoch: 5| Step: 3
Training loss: 1.920986533164978
Validation loss: 2.0115557511647544

Epoch: 5| Step: 4
Training loss: 2.118403911590576
Validation loss: 2.0163523107767105

Epoch: 5| Step: 5
Training loss: 2.0786967277526855
Validation loss: 2.0217445294062295

Epoch: 5| Step: 6
Training loss: 1.737342119216919
Validation loss: 2.0260666608810425

Epoch: 5| Step: 7
Training loss: 1.6927086114883423
Validation loss: 2.025447736183802

Epoch: 5| Step: 8
Training loss: 2.0091681480407715
Validation loss: 2.016482745607694

Epoch: 5| Step: 9
Training loss: 2.601004123687744
Validation loss: 2.024546205997467

Epoch: 5| Step: 10
Training loss: 2.2641942501068115
Validation loss: 2.019616757829984

Epoch: 5| Step: 11
Training loss: 1.9095460176467896
Validation loss: 2.019432952006658

Epoch: 161| Step: 0
Training loss: 2.6240971088409424
Validation loss: 2.0221459666887918

Epoch: 5| Step: 1
Training loss: 1.7987422943115234
Validation loss: 2.014694025119146

Epoch: 5| Step: 2
Training loss: 1.6079047918319702
Validation loss: 2.0245343347390494

Epoch: 5| Step: 3
Training loss: 2.7248268127441406
Validation loss: 2.0213088244199753

Epoch: 5| Step: 4
Training loss: 1.932897925376892
Validation loss: 2.029015153646469

Epoch: 5| Step: 5
Training loss: 2.046621561050415
Validation loss: 2.025053029259046

Epoch: 5| Step: 6
Training loss: 1.8072210550308228
Validation loss: 2.0192939142386117

Epoch: 5| Step: 7
Training loss: 2.14833402633667
Validation loss: 2.029715438683828

Epoch: 5| Step: 8
Training loss: 2.289005994796753
Validation loss: 2.0294602115948996

Epoch: 5| Step: 9
Training loss: 1.603470802307129
Validation loss: 2.0386962989966073

Epoch: 5| Step: 10
Training loss: 2.1149027347564697
Validation loss: 2.0327178090810776

Epoch: 5| Step: 11
Training loss: 2.4396097660064697
Validation loss: 2.043843686580658

Epoch: 162| Step: 0
Training loss: 1.7856098413467407
Validation loss: 2.045335114002228

Epoch: 5| Step: 1
Training loss: 2.5667717456817627
Validation loss: 2.034163609147072

Epoch: 5| Step: 2
Training loss: 1.6671040058135986
Validation loss: 2.036581794420878

Epoch: 5| Step: 3
Training loss: 1.7843230962753296
Validation loss: 2.04837500055631

Epoch: 5| Step: 4
Training loss: 2.1014211177825928
Validation loss: 2.0200051814317703

Epoch: 5| Step: 5
Training loss: 2.1216180324554443
Validation loss: 2.026434833804766

Epoch: 5| Step: 6
Training loss: 2.5715720653533936
Validation loss: 2.0200705776611962

Epoch: 5| Step: 7
Training loss: 2.110861301422119
Validation loss: 2.010116214553515

Epoch: 5| Step: 8
Training loss: 1.589217185974121
Validation loss: 2.011292020479838

Epoch: 5| Step: 9
Training loss: 2.453583240509033
Validation loss: 2.0159841825564704

Epoch: 5| Step: 10
Training loss: 2.189981460571289
Validation loss: 2.0127357045809426

Epoch: 5| Step: 11
Training loss: 2.5402743816375732
Validation loss: 2.018476660052935

Epoch: 163| Step: 0
Training loss: 2.1561951637268066
Validation loss: 2.0040253003438315

Epoch: 5| Step: 1
Training loss: 2.3823132514953613
Validation loss: 2.0068673441807428

Epoch: 5| Step: 2
Training loss: 1.6519677639007568
Validation loss: 2.0092229644457498

Epoch: 5| Step: 3
Training loss: 2.352813243865967
Validation loss: 2.0070379028717675

Epoch: 5| Step: 4
Training loss: 2.0162174701690674
Validation loss: 2.0028614699840546

Epoch: 5| Step: 5
Training loss: 2.7760777473449707
Validation loss: 2.0039025942484536

Epoch: 5| Step: 6
Training loss: 2.0746006965637207
Validation loss: 2.0212127466996512

Epoch: 5| Step: 7
Training loss: 2.0255818367004395
Validation loss: 2.0240969012180963

Epoch: 5| Step: 8
Training loss: 1.9470876455307007
Validation loss: 2.030603731671969

Epoch: 5| Step: 9
Training loss: 1.6204077005386353
Validation loss: 2.034334366520246

Epoch: 5| Step: 10
Training loss: 1.9227123260498047
Validation loss: 2.0334100276231766

Epoch: 5| Step: 11
Training loss: 1.7495689392089844
Validation loss: 2.035408154129982

Epoch: 164| Step: 0
Training loss: 2.054962635040283
Validation loss: 2.0500523994366326

Epoch: 5| Step: 1
Training loss: 1.7277851104736328
Validation loss: 2.0381663888692856

Epoch: 5| Step: 2
Training loss: 2.677781820297241
Validation loss: 2.0471042146285376

Epoch: 5| Step: 3
Training loss: 1.684435248374939
Validation loss: 2.054320603609085

Epoch: 5| Step: 4
Training loss: 1.6781816482543945
Validation loss: 2.0556001166502633

Epoch: 5| Step: 5
Training loss: 1.374829649925232
Validation loss: 2.0601313412189484

Epoch: 5| Step: 6
Training loss: 2.3458991050720215
Validation loss: 2.042073513070742

Epoch: 5| Step: 7
Training loss: 1.9864814281463623
Validation loss: 2.0497419188419976

Epoch: 5| Step: 8
Training loss: 2.3157448768615723
Validation loss: 2.0324095537265143

Epoch: 5| Step: 9
Training loss: 2.1160881519317627
Validation loss: 2.027578646938006

Epoch: 5| Step: 10
Training loss: 2.515078067779541
Validation loss: 2.0277119974295297

Epoch: 5| Step: 11
Training loss: 3.542416572570801
Validation loss: 2.034100910027822

Epoch: 165| Step: 0
Training loss: 1.7034517526626587
Validation loss: 2.020103171467781

Epoch: 5| Step: 1
Training loss: 2.398850440979004
Validation loss: 2.0154693176349006

Epoch: 5| Step: 2
Training loss: 2.061037063598633
Validation loss: 2.020829995473226

Epoch: 5| Step: 3
Training loss: 2.028806686401367
Validation loss: 2.0185230523347855

Epoch: 5| Step: 4
Training loss: 2.2816367149353027
Validation loss: 2.0220729609330497

Epoch: 5| Step: 5
Training loss: 2.4891669750213623
Validation loss: 2.024495075146357

Epoch: 5| Step: 6
Training loss: 2.258026599884033
Validation loss: 2.034036616484324

Epoch: 5| Step: 7
Training loss: 1.7295204401016235
Validation loss: 2.0214460442463555

Epoch: 5| Step: 8
Training loss: 2.201951503753662
Validation loss: 2.027532329161962

Epoch: 5| Step: 9
Training loss: 2.1673531532287598
Validation loss: 2.0188773373762765

Epoch: 5| Step: 10
Training loss: 2.0581912994384766
Validation loss: 2.015842398007711

Epoch: 5| Step: 11
Training loss: 1.6681032180786133
Validation loss: 2.0119720300038657

Epoch: 166| Step: 0
Training loss: 2.1979269981384277
Validation loss: 2.0121182103951774

Epoch: 5| Step: 1
Training loss: 1.4018065929412842
Validation loss: 2.0122087051471076

Epoch: 5| Step: 2
Training loss: 1.960492730140686
Validation loss: 2.010557681322098

Epoch: 5| Step: 3
Training loss: 1.762303352355957
Validation loss: 2.0137663880983987

Epoch: 5| Step: 4
Training loss: 2.387299060821533
Validation loss: 2.0144144346316657

Epoch: 5| Step: 5
Training loss: 3.1195943355560303
Validation loss: 2.0195889423290887

Epoch: 5| Step: 6
Training loss: 1.7929832935333252
Validation loss: 2.019374137123426

Epoch: 5| Step: 7
Training loss: 1.9185142517089844
Validation loss: 2.0288386841615043

Epoch: 5| Step: 8
Training loss: 1.7159147262573242
Validation loss: 2.031893730163574

Epoch: 5| Step: 9
Training loss: 1.9490429162979126
Validation loss: 2.039221574862798

Epoch: 5| Step: 10
Training loss: 2.3052408695220947
Validation loss: 2.0550623138745627

Epoch: 5| Step: 11
Training loss: 1.9709548950195312
Validation loss: 2.0535808404286704

Epoch: 167| Step: 0
Training loss: 2.1259799003601074
Validation loss: 2.069604108730952

Epoch: 5| Step: 1
Training loss: 2.6251039505004883
Validation loss: 2.073039636015892

Epoch: 5| Step: 2
Training loss: 2.4600493907928467
Validation loss: 2.0735276341438293

Epoch: 5| Step: 3
Training loss: 2.31644868850708
Validation loss: 2.076597253481547

Epoch: 5| Step: 4
Training loss: 1.8860795497894287
Validation loss: 2.07463109989961

Epoch: 5| Step: 5
Training loss: 1.740578293800354
Validation loss: 2.0657468885183334

Epoch: 5| Step: 6
Training loss: 1.854233980178833
Validation loss: 2.0421156336863837

Epoch: 5| Step: 7
Training loss: 2.1005921363830566
Validation loss: 2.0325125257174173

Epoch: 5| Step: 8
Training loss: 2.0939109325408936
Validation loss: 2.029080460468928

Epoch: 5| Step: 9
Training loss: 1.8705317974090576
Validation loss: 2.0204658210277557

Epoch: 5| Step: 10
Training loss: 2.433621644973755
Validation loss: 2.0146066695451736

Epoch: 5| Step: 11
Training loss: 2.5163183212280273
Validation loss: 2.0138897051413855

Epoch: 168| Step: 0
Training loss: 2.403158664703369
Validation loss: 2.0078600893417993

Epoch: 5| Step: 1
Training loss: 2.421851396560669
Validation loss: 2.0010583947102227

Epoch: 5| Step: 2
Training loss: 1.9225765466690063
Validation loss: 1.9992205997308095

Epoch: 5| Step: 3
Training loss: 1.9712133407592773
Validation loss: 2.0064069628715515

Epoch: 5| Step: 4
Training loss: 2.4013161659240723
Validation loss: 1.9947414149840672

Epoch: 5| Step: 5
Training loss: 1.6530945301055908
Validation loss: 2.000186115503311

Epoch: 5| Step: 6
Training loss: 1.9667495489120483
Validation loss: 1.997956891854604

Epoch: 5| Step: 7
Training loss: 1.978337287902832
Validation loss: 2.0005119889974594

Epoch: 5| Step: 8
Training loss: 1.615369200706482
Validation loss: 2.013848289847374

Epoch: 5| Step: 9
Training loss: 2.432799816131592
Validation loss: 2.0209544946750007

Epoch: 5| Step: 10
Training loss: 2.1188547611236572
Validation loss: 2.023130476474762

Epoch: 5| Step: 11
Training loss: 1.81492280960083
Validation loss: 2.0380194932222366

Epoch: 169| Step: 0
Training loss: 1.6088321208953857
Validation loss: 2.017584721247355

Epoch: 5| Step: 1
Training loss: 2.0147616863250732
Validation loss: 2.0087355027596154

Epoch: 5| Step: 2
Training loss: 2.42060923576355
Validation loss: 2.012583235899607

Epoch: 5| Step: 3
Training loss: 1.6575390100479126
Validation loss: 2.008435765902201

Epoch: 5| Step: 4
Training loss: 1.8636242151260376
Validation loss: 2.0151102989912033

Epoch: 5| Step: 5
Training loss: 2.2405600547790527
Validation loss: 2.018403316537539

Epoch: 5| Step: 6
Training loss: 2.0225205421447754
Validation loss: 2.02020296951135

Epoch: 5| Step: 7
Training loss: 2.5486292839050293
Validation loss: 2.02286788324515

Epoch: 5| Step: 8
Training loss: 1.969839334487915
Validation loss: 2.0163948088884354

Epoch: 5| Step: 9
Training loss: 2.1810498237609863
Validation loss: 2.0239962885777154

Epoch: 5| Step: 10
Training loss: 2.426103115081787
Validation loss: 2.0236245890458426

Epoch: 5| Step: 11
Training loss: 1.8530542850494385
Validation loss: 2.0210408717393875

Epoch: 170| Step: 0
Training loss: 1.8437111377716064
Validation loss: 2.0348209589719772

Epoch: 5| Step: 1
Training loss: 1.9587523937225342
Validation loss: 2.029956097404162

Epoch: 5| Step: 2
Training loss: 2.1947054862976074
Validation loss: 2.040076663096746

Epoch: 5| Step: 3
Training loss: 1.8918536901474
Validation loss: 2.039878020683924

Epoch: 5| Step: 4
Training loss: 2.4443628787994385
Validation loss: 2.037392074863116

Epoch: 5| Step: 5
Training loss: 2.513093948364258
Validation loss: 2.0342212518056235

Epoch: 5| Step: 6
Training loss: 2.050574541091919
Validation loss: 2.041034067670504

Epoch: 5| Step: 7
Training loss: 2.140465497970581
Validation loss: 2.043781593441963

Epoch: 5| Step: 8
Training loss: 1.5795034170150757
Validation loss: 2.052384709318479

Epoch: 5| Step: 9
Training loss: 2.3104398250579834
Validation loss: 2.0404222905635834

Epoch: 5| Step: 10
Training loss: 1.7718849182128906
Validation loss: 2.043950801094373

Epoch: 5| Step: 11
Training loss: 1.7378443479537964
Validation loss: 2.0481728663047156

Epoch: 171| Step: 0
Training loss: 1.9671005010604858
Validation loss: 2.0445753733317056

Epoch: 5| Step: 1
Training loss: 2.43279767036438
Validation loss: 2.050813173254331

Epoch: 5| Step: 2
Training loss: 2.0030922889709473
Validation loss: 2.045030415058136

Epoch: 5| Step: 3
Training loss: 1.5778838396072388
Validation loss: 2.0476481169462204

Epoch: 5| Step: 4
Training loss: 2.1594035625457764
Validation loss: 2.043651203314463

Epoch: 5| Step: 5
Training loss: 1.9170773029327393
Validation loss: 2.0470753610134125

Epoch: 5| Step: 6
Training loss: 2.2749860286712646
Validation loss: 2.0396116276582084

Epoch: 5| Step: 7
Training loss: 2.249263048171997
Validation loss: 2.0329469988743463

Epoch: 5| Step: 8
Training loss: 1.8628149032592773
Validation loss: 2.034982517361641

Epoch: 5| Step: 9
Training loss: 2.360476016998291
Validation loss: 2.0259263714154563

Epoch: 5| Step: 10
Training loss: 1.7458000183105469
Validation loss: 2.03426423172156

Epoch: 5| Step: 11
Training loss: 1.9299075603485107
Validation loss: 2.0226255704959235

Epoch: 172| Step: 0
Training loss: 1.7613639831542969
Validation loss: 2.018935347596804

Epoch: 5| Step: 1
Training loss: 2.4916436672210693
Validation loss: 2.0277771949768066

Epoch: 5| Step: 2
Training loss: 2.081378936767578
Validation loss: 2.024240424235662

Epoch: 5| Step: 3
Training loss: 2.2647597789764404
Validation loss: 2.035699983437856

Epoch: 5| Step: 4
Training loss: 1.9270966053009033
Validation loss: 2.0416191816329956

Epoch: 5| Step: 5
Training loss: 1.862653374671936
Validation loss: 2.0462513168652854

Epoch: 5| Step: 6
Training loss: 2.186518669128418
Validation loss: 2.040042315920194

Epoch: 5| Step: 7
Training loss: 2.2239346504211426
Validation loss: 2.0482866565386453

Epoch: 5| Step: 8
Training loss: 2.2222440242767334
Validation loss: 2.045672391851743

Epoch: 5| Step: 9
Training loss: 2.0073513984680176
Validation loss: 2.064297844966253

Epoch: 5| Step: 10
Training loss: 1.458809733390808
Validation loss: 2.05925190448761

Epoch: 5| Step: 11
Training loss: 1.9654289484024048
Validation loss: 2.0610165745019913

Epoch: 173| Step: 0
Training loss: 2.2519984245300293
Validation loss: 2.0595814933379493

Epoch: 5| Step: 1
Training loss: 1.7072120904922485
Validation loss: 2.052834928035736

Epoch: 5| Step: 2
Training loss: 2.0109541416168213
Validation loss: 2.0444086641073227

Epoch: 5| Step: 3
Training loss: 1.5688329935073853
Validation loss: 2.0563699106375375

Epoch: 5| Step: 4
Training loss: 2.2842447757720947
Validation loss: 2.054698641101519

Epoch: 5| Step: 5
Training loss: 2.282858371734619
Validation loss: 2.0529800901810327

Epoch: 5| Step: 6
Training loss: 1.8734451532363892
Validation loss: 2.0580723136663437

Epoch: 5| Step: 7
Training loss: 2.2394020557403564
Validation loss: 2.0460340032974877

Epoch: 5| Step: 8
Training loss: 2.3589577674865723
Validation loss: 2.0536156545082727

Epoch: 5| Step: 9
Training loss: 1.9110749959945679
Validation loss: 2.0566442062457404

Epoch: 5| Step: 10
Training loss: 1.9442636966705322
Validation loss: 2.0475490937630334

Epoch: 5| Step: 11
Training loss: 2.365830659866333
Validation loss: 2.04543370505174

Epoch: 174| Step: 0
Training loss: 1.955460548400879
Validation loss: 2.0296807885169983

Epoch: 5| Step: 1
Training loss: 2.2662501335144043
Validation loss: 2.0267302095890045

Epoch: 5| Step: 2
Training loss: 1.7732093334197998
Validation loss: 2.0199303130308786

Epoch: 5| Step: 3
Training loss: 2.5184383392333984
Validation loss: 2.025265321135521

Epoch: 5| Step: 4
Training loss: 1.9484317302703857
Validation loss: 2.0201855103174844

Epoch: 5| Step: 5
Training loss: 1.5887616872787476
Validation loss: 2.025726934274038

Epoch: 5| Step: 6
Training loss: 2.5515618324279785
Validation loss: 2.0183680852254233

Epoch: 5| Step: 7
Training loss: 2.074127435684204
Validation loss: 2.0247084150711694

Epoch: 5| Step: 8
Training loss: 1.728333830833435
Validation loss: 2.0287989377975464

Epoch: 5| Step: 9
Training loss: 1.935770034790039
Validation loss: 2.0293255050977073

Epoch: 5| Step: 10
Training loss: 2.278510093688965
Validation loss: 2.0200990736484528

Epoch: 5| Step: 11
Training loss: 2.3723630905151367
Validation loss: 2.043377846479416

Epoch: 175| Step: 0
Training loss: 1.9076049327850342
Validation loss: 2.0461796671152115

Epoch: 5| Step: 1
Training loss: 2.893155336380005
Validation loss: 2.059024209777514

Epoch: 5| Step: 2
Training loss: 2.118516206741333
Validation loss: 2.0654808481534324

Epoch: 5| Step: 3
Training loss: 2.0278244018554688
Validation loss: 2.0686396112044654

Epoch: 5| Step: 4
Training loss: 2.291003704071045
Validation loss: 2.0659962395826974

Epoch: 5| Step: 5
Training loss: 1.7576401233673096
Validation loss: 2.0484187255303064

Epoch: 5| Step: 6
Training loss: 1.8507903814315796
Validation loss: 2.0436226526896157

Epoch: 5| Step: 7
Training loss: 1.6815979480743408
Validation loss: 2.0362712840239205

Epoch: 5| Step: 8
Training loss: 2.0873193740844727
Validation loss: 2.047240823507309

Epoch: 5| Step: 9
Training loss: 1.89266037940979
Validation loss: 2.044326961040497

Epoch: 5| Step: 10
Training loss: 2.0044872760772705
Validation loss: 2.0440400888522468

Epoch: 5| Step: 11
Training loss: 2.1882574558258057
Validation loss: 2.0511498053868613

Epoch: 176| Step: 0
Training loss: 1.6642215251922607
Validation loss: 2.0493008146683374

Epoch: 5| Step: 1
Training loss: 2.099632978439331
Validation loss: 2.0612605661153793

Epoch: 5| Step: 2
Training loss: 2.143838405609131
Validation loss: 2.054460903008779

Epoch: 5| Step: 3
Training loss: 2.1933887004852295
Validation loss: 2.0676445414622626

Epoch: 5| Step: 4
Training loss: 1.9503313302993774
Validation loss: 2.058691591024399

Epoch: 5| Step: 5
Training loss: 2.3834450244903564
Validation loss: 2.0498569508393607

Epoch: 5| Step: 6
Training loss: 1.664125680923462
Validation loss: 2.0596237579981485

Epoch: 5| Step: 7
Training loss: 1.9428972005844116
Validation loss: 2.0483286728461585

Epoch: 5| Step: 8
Training loss: 2.7349696159362793
Validation loss: 2.0389829302827516

Epoch: 5| Step: 9
Training loss: 1.9488754272460938
Validation loss: 2.01932892203331

Epoch: 5| Step: 10
Training loss: 1.7101093530654907
Validation loss: 2.016336346666018

Epoch: 5| Step: 11
Training loss: 2.09448504447937
Validation loss: 2.0215901732444763

Epoch: 177| Step: 0
Training loss: 2.172146797180176
Validation loss: 2.0179482946793237

Epoch: 5| Step: 1
Training loss: 2.0486700534820557
Validation loss: 2.014547268549601

Epoch: 5| Step: 2
Training loss: 2.310878276824951
Validation loss: 2.02528249224027

Epoch: 5| Step: 3
Training loss: 1.8344866037368774
Validation loss: 2.02106282611688

Epoch: 5| Step: 4
Training loss: 2.290536642074585
Validation loss: 2.021413837869962

Epoch: 5| Step: 5
Training loss: 2.4624552726745605
Validation loss: 2.0321367233991623

Epoch: 5| Step: 6
Training loss: 2.1929800510406494
Validation loss: 2.0335020224253335

Epoch: 5| Step: 7
Training loss: 2.1135141849517822
Validation loss: 2.036968087156614

Epoch: 5| Step: 8
Training loss: 2.026334285736084
Validation loss: 2.0363801270723343

Epoch: 5| Step: 9
Training loss: 1.505878210067749
Validation loss: 2.0259542961915336

Epoch: 5| Step: 10
Training loss: 1.895296335220337
Validation loss: 2.0369919737180076

Epoch: 5| Step: 11
Training loss: 0.4691711366176605
Validation loss: 2.0573874562978745

Epoch: 178| Step: 0
Training loss: 1.4660502672195435
Validation loss: 2.0742653657992682

Epoch: 5| Step: 1
Training loss: 2.2633514404296875
Validation loss: 2.0753354827562966

Epoch: 5| Step: 2
Training loss: 2.2291502952575684
Validation loss: 2.0653573870658875

Epoch: 5| Step: 3
Training loss: 2.021259069442749
Validation loss: 2.0918355782826743

Epoch: 5| Step: 4
Training loss: 2.2452895641326904
Validation loss: 2.0885614305734634

Epoch: 5| Step: 5
Training loss: 2.2094626426696777
Validation loss: 2.068592538436254

Epoch: 5| Step: 6
Training loss: 1.8282225131988525
Validation loss: 2.07254229982694

Epoch: 5| Step: 7
Training loss: 2.4544103145599365
Validation loss: 2.0494446406761804

Epoch: 5| Step: 8
Training loss: 1.9141470193862915
Validation loss: 2.05256716410319

Epoch: 5| Step: 9
Training loss: 1.6979650259017944
Validation loss: 2.038435931007067

Epoch: 5| Step: 10
Training loss: 2.609192132949829
Validation loss: 2.0296650727589927

Epoch: 5| Step: 11
Training loss: 2.7000088691711426
Validation loss: 2.0319772213697433

Epoch: 179| Step: 0
Training loss: 1.6356738805770874
Validation loss: 2.0269308586915336

Epoch: 5| Step: 1
Training loss: 2.3764116764068604
Validation loss: 2.041302959124247

Epoch: 5| Step: 2
Training loss: 1.8007606267929077
Validation loss: 2.0404956936836243

Epoch: 5| Step: 3
Training loss: 2.060781955718994
Validation loss: 2.049238229791323

Epoch: 5| Step: 4
Training loss: 2.3794453144073486
Validation loss: 2.0462764898935952

Epoch: 5| Step: 5
Training loss: 2.7993037700653076
Validation loss: 2.0514117926359177

Epoch: 5| Step: 6
Training loss: 1.8933998346328735
Validation loss: 2.052651604016622

Epoch: 5| Step: 7
Training loss: 2.2360801696777344
Validation loss: 2.0467366874217987

Epoch: 5| Step: 8
Training loss: 2.1019108295440674
Validation loss: 2.046911120414734

Epoch: 5| Step: 9
Training loss: 2.234731674194336
Validation loss: 2.0435599833726883

Epoch: 5| Step: 10
Training loss: 1.5671008825302124
Validation loss: 2.0455061544974646

Epoch: 5| Step: 11
Training loss: 2.700946569442749
Validation loss: 2.0392463505268097

Epoch: 180| Step: 0
Training loss: 2.220153570175171
Validation loss: 2.0477588772773743

Epoch: 5| Step: 1
Training loss: 2.645029067993164
Validation loss: 2.025158161918322

Epoch: 5| Step: 2
Training loss: 1.9760017395019531
Validation loss: 2.0329748491446176

Epoch: 5| Step: 3
Training loss: 2.0243477821350098
Validation loss: 2.0180860509475074

Epoch: 5| Step: 4
Training loss: 1.690138578414917
Validation loss: 2.0166940043369928

Epoch: 5| Step: 5
Training loss: 1.5485754013061523
Validation loss: 2.0107503732045493

Epoch: 5| Step: 6
Training loss: 2.6156208515167236
Validation loss: 2.013898327946663

Epoch: 5| Step: 7
Training loss: 2.130739688873291
Validation loss: 2.014152576526006

Epoch: 5| Step: 8
Training loss: 2.505380153656006
Validation loss: 2.0237044940392175

Epoch: 5| Step: 9
Training loss: 1.8953876495361328
Validation loss: 2.0159941663344703

Epoch: 5| Step: 10
Training loss: 1.6191990375518799
Validation loss: 2.025398919979731

Epoch: 5| Step: 11
Training loss: 1.4817163944244385
Validation loss: 2.0385757188002267

Epoch: 181| Step: 0
Training loss: 2.2892277240753174
Validation loss: 2.0367675721645355

Epoch: 5| Step: 1
Training loss: 1.7819938659667969
Validation loss: 2.0445669442415237

Epoch: 5| Step: 2
Training loss: 2.2268192768096924
Validation loss: 2.050192912419637

Epoch: 5| Step: 3
Training loss: 1.3879001140594482
Validation loss: 2.0373108287652335

Epoch: 5| Step: 4
Training loss: 2.991245746612549
Validation loss: 2.049392133951187

Epoch: 5| Step: 5
Training loss: 2.359898090362549
Validation loss: 2.063092509905497

Epoch: 5| Step: 6
Training loss: 1.9436050653457642
Validation loss: 2.0562220315138497

Epoch: 5| Step: 7
Training loss: 1.5523964166641235
Validation loss: 2.0673965414365134

Epoch: 5| Step: 8
Training loss: 1.6937240362167358
Validation loss: 2.0656584103902182

Epoch: 5| Step: 9
Training loss: 2.0246191024780273
Validation loss: 2.067591115832329

Epoch: 5| Step: 10
Training loss: 2.2907626628875732
Validation loss: 2.0588985482851663

Epoch: 5| Step: 11
Training loss: 1.476909875869751
Validation loss: 2.063083509604136

Epoch: 182| Step: 0
Training loss: 2.629652738571167
Validation loss: 2.0536929965019226

Epoch: 5| Step: 1
Training loss: 1.6800587177276611
Validation loss: 2.041290352741877

Epoch: 5| Step: 2
Training loss: 2.112016201019287
Validation loss: 2.0377420783042908

Epoch: 5| Step: 3
Training loss: 1.9409990310668945
Validation loss: 2.0374465038379035

Epoch: 5| Step: 4
Training loss: 1.8399078845977783
Validation loss: 2.0461280395587287

Epoch: 5| Step: 5
Training loss: 2.1434097290039062
Validation loss: 2.0331306606531143

Epoch: 5| Step: 6
Training loss: 1.9730045795440674
Validation loss: 2.0446758518616357

Epoch: 5| Step: 7
Training loss: 2.2270469665527344
Validation loss: 2.0514178375403085

Epoch: 5| Step: 8
Training loss: 2.0950469970703125
Validation loss: 2.0523416896661124

Epoch: 5| Step: 9
Training loss: 2.2752463817596436
Validation loss: 2.0631568282842636

Epoch: 5| Step: 10
Training loss: 1.5272789001464844
Validation loss: 2.073586563269297

Epoch: 5| Step: 11
Training loss: 2.539083242416382
Validation loss: 2.073795825242996

Epoch: 183| Step: 0
Training loss: 1.9807062149047852
Validation loss: 2.0649872571229935

Epoch: 5| Step: 1
Training loss: 1.5456323623657227
Validation loss: 2.070327048500379

Epoch: 5| Step: 2
Training loss: 1.9232966899871826
Validation loss: 2.053235486149788

Epoch: 5| Step: 3
Training loss: 2.6561741828918457
Validation loss: 2.0566089997688928

Epoch: 5| Step: 4
Training loss: 2.156724214553833
Validation loss: 2.043215796351433

Epoch: 5| Step: 5
Training loss: 2.33797287940979
Validation loss: 2.0395632634560266

Epoch: 5| Step: 6
Training loss: 1.8170315027236938
Validation loss: 2.038015683492025

Epoch: 5| Step: 7
Training loss: 2.6276893615722656
Validation loss: 2.039309486746788

Epoch: 5| Step: 8
Training loss: 1.5678104162216187
Validation loss: 2.0441455940405526

Epoch: 5| Step: 9
Training loss: 2.161914110183716
Validation loss: 2.0402833918730416

Epoch: 5| Step: 10
Training loss: 1.674381971359253
Validation loss: 2.029444605112076

Epoch: 5| Step: 11
Training loss: 2.2912487983703613
Validation loss: 2.042161837220192

Epoch: 184| Step: 0
Training loss: 1.931822419166565
Validation loss: 2.043816308180491

Epoch: 5| Step: 1
Training loss: 1.992799997329712
Validation loss: 2.0503767083088555

Epoch: 5| Step: 2
Training loss: 1.6318883895874023
Validation loss: 2.0661852111419043

Epoch: 5| Step: 3
Training loss: 2.406938076019287
Validation loss: 2.0748585214217505

Epoch: 5| Step: 4
Training loss: 2.3791563510894775
Validation loss: 2.0881282140811286

Epoch: 5| Step: 5
Training loss: 2.5133724212646484
Validation loss: 2.086034670472145

Epoch: 5| Step: 6
Training loss: 2.3378024101257324
Validation loss: 2.1087449292341867

Epoch: 5| Step: 7
Training loss: 2.093113660812378
Validation loss: 2.1069582402706146

Epoch: 5| Step: 8
Training loss: 1.5086199045181274
Validation loss: 2.1067347327868142

Epoch: 5| Step: 9
Training loss: 1.6122486591339111
Validation loss: 2.1044251918792725

Epoch: 5| Step: 10
Training loss: 1.9069404602050781
Validation loss: 2.089853415886561

Epoch: 5| Step: 11
Training loss: 3.5869057178497314
Validation loss: 2.098723421494166

Epoch: 185| Step: 0
Training loss: 1.653486967086792
Validation loss: 2.06069186826547

Epoch: 5| Step: 1
Training loss: 1.981468915939331
Validation loss: 2.0416017870108285

Epoch: 5| Step: 2
Training loss: 2.330883741378784
Validation loss: 2.047538638114929

Epoch: 5| Step: 3
Training loss: 2.104177951812744
Validation loss: 2.0432429015636444

Epoch: 5| Step: 4
Training loss: 1.867140531539917
Validation loss: 2.0505910913149514

Epoch: 5| Step: 5
Training loss: 2.792656898498535
Validation loss: 2.06769992907842

Epoch: 5| Step: 6
Training loss: 2.5034823417663574
Validation loss: 2.0751038789749146

Epoch: 5| Step: 7
Training loss: 2.4457523822784424
Validation loss: 2.079513112703959

Epoch: 5| Step: 8
Training loss: 1.7908709049224854
Validation loss: 2.078210989634196

Epoch: 5| Step: 9
Training loss: 2.1859803199768066
Validation loss: 2.085254669189453

Epoch: 5| Step: 10
Training loss: 1.9735586643218994
Validation loss: 2.0792135099569955

Epoch: 5| Step: 11
Training loss: 1.858479380607605
Validation loss: 2.0713439335425696

Epoch: 186| Step: 0
Training loss: 2.021867275238037
Validation loss: 2.0764664510885873

Epoch: 5| Step: 1
Training loss: 2.3921215534210205
Validation loss: 2.071413993835449

Epoch: 5| Step: 2
Training loss: 1.8995025157928467
Validation loss: 2.0683501064777374

Epoch: 5| Step: 3
Training loss: 1.8810850381851196
Validation loss: 2.067206929127375

Epoch: 5| Step: 4
Training loss: 2.461242914199829
Validation loss: 2.0619748681783676

Epoch: 5| Step: 5
Training loss: 1.3468178510665894
Validation loss: 2.0589291950066886

Epoch: 5| Step: 6
Training loss: 2.444047451019287
Validation loss: 2.047968844572703

Epoch: 5| Step: 7
Training loss: 2.073530673980713
Validation loss: 2.048696552713712

Epoch: 5| Step: 8
Training loss: 2.495241641998291
Validation loss: 2.029222398996353

Epoch: 5| Step: 9
Training loss: 1.9720309972763062
Validation loss: 2.0270594358444214

Epoch: 5| Step: 10
Training loss: 2.6759276390075684
Validation loss: 2.0225012401739755

Epoch: 5| Step: 11
Training loss: 1.8737952709197998
Validation loss: 2.017481118440628

Epoch: 187| Step: 0
Training loss: 2.281776189804077
Validation loss: 2.018479893604914

Epoch: 5| Step: 1
Training loss: 1.7433862686157227
Validation loss: 2.015692005554835

Epoch: 5| Step: 2
Training loss: 2.262340784072876
Validation loss: 2.02228511373202

Epoch: 5| Step: 3
Training loss: 1.8228610754013062
Validation loss: 2.035659834742546

Epoch: 5| Step: 4
Training loss: 1.792565941810608
Validation loss: 2.0353419333696365

Epoch: 5| Step: 5
Training loss: 2.3877742290496826
Validation loss: 2.030013531446457

Epoch: 5| Step: 6
Training loss: 2.065427780151367
Validation loss: 2.032980884114901

Epoch: 5| Step: 7
Training loss: 2.5459094047546387
Validation loss: 2.0361611346403756

Epoch: 5| Step: 8
Training loss: 2.3964409828186035
Validation loss: 2.0478984316190085

Epoch: 5| Step: 9
Training loss: 1.7182056903839111
Validation loss: 2.047623818119367

Epoch: 5| Step: 10
Training loss: 1.86093270778656
Validation loss: 2.048200339078903

Epoch: 5| Step: 11
Training loss: 1.913361668586731
Validation loss: 2.054143245021502

Epoch: 188| Step: 0
Training loss: 2.604919910430908
Validation loss: 2.0585098564624786

Epoch: 5| Step: 1
Training loss: 2.060197114944458
Validation loss: 2.0553885201613107

Epoch: 5| Step: 2
Training loss: 1.9711952209472656
Validation loss: 2.059302717447281

Epoch: 5| Step: 3
Training loss: 1.9081668853759766
Validation loss: 2.0776450087626777

Epoch: 5| Step: 4
Training loss: 2.263866424560547
Validation loss: 2.073427458604177

Epoch: 5| Step: 5
Training loss: 1.6521666049957275
Validation loss: 2.0732251654068627

Epoch: 5| Step: 6
Training loss: 1.751847505569458
Validation loss: 2.080916946132978

Epoch: 5| Step: 7
Training loss: 1.8321888446807861
Validation loss: 2.0790341993172965

Epoch: 5| Step: 8
Training loss: 2.4417624473571777
Validation loss: 2.0668182522058487

Epoch: 5| Step: 9
Training loss: 1.6472885608673096
Validation loss: 2.066147724787394

Epoch: 5| Step: 10
Training loss: 2.378854274749756
Validation loss: 2.04898593823115

Epoch: 5| Step: 11
Training loss: 2.10353684425354
Validation loss: 2.049967959523201

Epoch: 189| Step: 0
Training loss: 1.690568208694458
Validation loss: 2.040309031804403

Epoch: 5| Step: 1
Training loss: 2.301152229309082
Validation loss: 2.047139450907707

Epoch: 5| Step: 2
Training loss: 1.954329490661621
Validation loss: 2.037873481710752

Epoch: 5| Step: 3
Training loss: 1.9977190494537354
Validation loss: 2.0457350661357245

Epoch: 5| Step: 4
Training loss: 1.3958415985107422
Validation loss: 2.0530931055545807

Epoch: 5| Step: 5
Training loss: 2.1422817707061768
Validation loss: 2.0382725298404694

Epoch: 5| Step: 6
Training loss: 2.4262983798980713
Validation loss: 2.0480195432901382

Epoch: 5| Step: 7
Training loss: 2.0120158195495605
Validation loss: 2.0631309747695923

Epoch: 5| Step: 8
Training loss: 2.160642147064209
Validation loss: 2.0643219898144403

Epoch: 5| Step: 9
Training loss: 2.01247501373291
Validation loss: 2.0686602741479874

Epoch: 5| Step: 10
Training loss: 2.213911294937134
Validation loss: 2.064809337258339

Epoch: 5| Step: 11
Training loss: 2.2263989448547363
Validation loss: 2.0697883864243827

Epoch: 190| Step: 0
Training loss: 1.7664449214935303
Validation loss: 2.0837114999691644

Epoch: 5| Step: 1
Training loss: 2.0621771812438965
Validation loss: 2.077737624446551

Epoch: 5| Step: 2
Training loss: 1.8176428079605103
Validation loss: 2.075946738322576

Epoch: 5| Step: 3
Training loss: 2.4353585243225098
Validation loss: 2.074627012014389

Epoch: 5| Step: 4
Training loss: 1.992410659790039
Validation loss: 2.0751450707515082

Epoch: 5| Step: 5
Training loss: 1.9630075693130493
Validation loss: 2.068798840045929

Epoch: 5| Step: 6
Training loss: 1.4494736194610596
Validation loss: 2.0491458773612976

Epoch: 5| Step: 7
Training loss: 2.021324634552002
Validation loss: 2.0658268680175147

Epoch: 5| Step: 8
Training loss: 2.3567352294921875
Validation loss: 2.0475097447633743

Epoch: 5| Step: 9
Training loss: 2.4727773666381836
Validation loss: 2.0429863780736923

Epoch: 5| Step: 10
Training loss: 1.7162415981292725
Validation loss: 2.0362298488616943

Epoch: 5| Step: 11
Training loss: 3.791771411895752
Validation loss: 2.036067917943001

Epoch: 191| Step: 0
Training loss: 1.9157072305679321
Validation loss: 2.04911540945371

Epoch: 5| Step: 1
Training loss: 1.6047725677490234
Validation loss: 2.043323586384455

Epoch: 5| Step: 2
Training loss: 1.9646987915039062
Validation loss: 2.03211576739947

Epoch: 5| Step: 3
Training loss: 2.637071132659912
Validation loss: 2.043905938665072

Epoch: 5| Step: 4
Training loss: 2.7448887825012207
Validation loss: 2.038464809457461

Epoch: 5| Step: 5
Training loss: 1.9824142456054688
Validation loss: 2.0340861479441323

Epoch: 5| Step: 6
Training loss: 1.7543106079101562
Validation loss: 2.04454842209816

Epoch: 5| Step: 7
Training loss: 1.929869294166565
Validation loss: 2.047969788312912

Epoch: 5| Step: 8
Training loss: 1.5996748208999634
Validation loss: 2.0591308623552322

Epoch: 5| Step: 9
Training loss: 2.2507970333099365
Validation loss: 2.067840109268824

Epoch: 5| Step: 10
Training loss: 2.1237101554870605
Validation loss: 2.0742051949103675

Epoch: 5| Step: 11
Training loss: 0.9714404940605164
Validation loss: 2.087828536828359

Epoch: 192| Step: 0
Training loss: 1.9288917779922485
Validation loss: 2.0884181956450143

Epoch: 5| Step: 1
Training loss: 2.0403759479522705
Validation loss: 2.095943585038185

Epoch: 5| Step: 2
Training loss: 2.341647148132324
Validation loss: 2.102051148811976

Epoch: 5| Step: 3
Training loss: 2.013035297393799
Validation loss: 2.099253455797831

Epoch: 5| Step: 4
Training loss: 2.050987958908081
Validation loss: 2.1212980399529138

Epoch: 5| Step: 5
Training loss: 2.275634288787842
Validation loss: 2.108656033873558

Epoch: 5| Step: 6
Training loss: 1.6612770557403564
Validation loss: 2.114074299732844

Epoch: 5| Step: 7
Training loss: 2.177567958831787
Validation loss: 2.0902709861596427

Epoch: 5| Step: 8
Training loss: 2.114475727081299
Validation loss: 2.0990973711013794

Epoch: 5| Step: 9
Training loss: 2.180027961730957
Validation loss: 2.108103925983111

Epoch: 5| Step: 10
Training loss: 1.6198337078094482
Validation loss: 2.086784839630127

Epoch: 5| Step: 11
Training loss: 1.4730228185653687
Validation loss: 2.0923470308383307

Epoch: 193| Step: 0
Training loss: 2.344839096069336
Validation loss: 2.0793773035208383

Epoch: 5| Step: 1
Training loss: 1.7095924615859985
Validation loss: 2.0909103751182556

Epoch: 5| Step: 2
Training loss: 2.3720149993896484
Validation loss: 2.0916300813357034

Epoch: 5| Step: 3
Training loss: 1.5984398126602173
Validation loss: 2.091606835524241

Epoch: 5| Step: 4
Training loss: 1.9878603219985962
Validation loss: 2.0709501455227532

Epoch: 5| Step: 5
Training loss: 1.807122826576233
Validation loss: 2.0748515526453652

Epoch: 5| Step: 6
Training loss: 2.319045305252075
Validation loss: 2.0846780240535736

Epoch: 5| Step: 7
Training loss: 2.2572145462036133
Validation loss: 2.077150652805964

Epoch: 5| Step: 8
Training loss: 1.796465277671814
Validation loss: 2.0803310175736747

Epoch: 5| Step: 9
Training loss: 1.865939736366272
Validation loss: 2.095877170562744

Epoch: 5| Step: 10
Training loss: 2.335141658782959
Validation loss: 2.0905066430568695

Epoch: 5| Step: 11
Training loss: 1.3141814470291138
Validation loss: 2.0932030926148095

Epoch: 194| Step: 0
Training loss: 2.1712751388549805
Validation loss: 2.079447681705157

Epoch: 5| Step: 1
Training loss: 2.1298091411590576
Validation loss: 2.090262154738108

Epoch: 5| Step: 2
Training loss: 2.107980966567993
Validation loss: 2.0937262574831643

Epoch: 5| Step: 3
Training loss: 1.970808982849121
Validation loss: 2.0998758176962533

Epoch: 5| Step: 4
Training loss: 1.3785032033920288
Validation loss: 2.0927670697371163

Epoch: 5| Step: 5
Training loss: 2.740506172180176
Validation loss: 2.08971776564916

Epoch: 5| Step: 6
Training loss: 2.1956000328063965
Validation loss: 2.0933063427607217

Epoch: 5| Step: 7
Training loss: 1.8732421398162842
Validation loss: 2.0806309233109155

Epoch: 5| Step: 8
Training loss: 1.6966416835784912
Validation loss: 2.078132748603821

Epoch: 5| Step: 9
Training loss: 2.188206911087036
Validation loss: 2.085451826453209

Epoch: 5| Step: 10
Training loss: 1.8156416416168213
Validation loss: 2.0800172686576843

Epoch: 5| Step: 11
Training loss: 1.4990931749343872
Validation loss: 2.085809330145518

Epoch: 195| Step: 0
Training loss: 1.4885509014129639
Validation loss: 2.084386706352234

Epoch: 5| Step: 1
Training loss: 1.533085584640503
Validation loss: 2.0937025050322213

Epoch: 5| Step: 2
Training loss: 1.4754440784454346
Validation loss: 2.101500262816747

Epoch: 5| Step: 3
Training loss: 2.2109954357147217
Validation loss: 2.098710914452871

Epoch: 5| Step: 4
Training loss: 2.471592903137207
Validation loss: 2.1148521999518075

Epoch: 5| Step: 5
Training loss: 2.23004150390625
Validation loss: 2.1081738571325936

Epoch: 5| Step: 6
Training loss: 2.05501389503479
Validation loss: 2.0969731211662292

Epoch: 5| Step: 7
Training loss: 2.098893642425537
Validation loss: 2.092863162358602

Epoch: 5| Step: 8
Training loss: 2.5091025829315186
Validation loss: 2.0825654913981757

Epoch: 5| Step: 9
Training loss: 1.913224458694458
Validation loss: 2.0833439429601035

Epoch: 5| Step: 10
Training loss: 2.3114523887634277
Validation loss: 2.088795160253843

Epoch: 5| Step: 11
Training loss: 1.2301199436187744
Validation loss: 2.0866738160451255

Epoch: 196| Step: 0
Training loss: 1.981191635131836
Validation loss: 2.086110015710195

Epoch: 5| Step: 1
Training loss: 2.2100515365600586
Validation loss: 2.0714342643817267

Epoch: 5| Step: 2
Training loss: 1.8811368942260742
Validation loss: 2.0563958138227463

Epoch: 5| Step: 3
Training loss: 1.9745820760726929
Validation loss: 2.0574197471141815

Epoch: 5| Step: 4
Training loss: 2.000166416168213
Validation loss: 2.0616981387138367

Epoch: 5| Step: 5
Training loss: 2.4560558795928955
Validation loss: 2.0587297876675925

Epoch: 5| Step: 6
Training loss: 1.9220106601715088
Validation loss: 2.0709869265556335

Epoch: 5| Step: 7
Training loss: 1.596243977546692
Validation loss: 2.0585360378026962

Epoch: 5| Step: 8
Training loss: 1.7806317806243896
Validation loss: 2.0637412120898566

Epoch: 5| Step: 9
Training loss: 1.7663688659667969
Validation loss: 2.0680530071258545

Epoch: 5| Step: 10
Training loss: 2.2940590381622314
Validation loss: 2.07231812675794

Epoch: 5| Step: 11
Training loss: 3.421787977218628
Validation loss: 2.0894892712434134

Epoch: 197| Step: 0
Training loss: 2.6970949172973633
Validation loss: 2.091198578476906

Epoch: 5| Step: 1
Training loss: 1.4995336532592773
Validation loss: 2.0846097668011985

Epoch: 5| Step: 2
Training loss: 2.2136123180389404
Validation loss: 2.0970358351866403

Epoch: 5| Step: 3
Training loss: 2.251087188720703
Validation loss: 2.099889342983564

Epoch: 5| Step: 4
Training loss: 2.5100674629211426
Validation loss: 2.119724983970324

Epoch: 5| Step: 5
Training loss: 1.7052274942398071
Validation loss: 2.1354933232069016

Epoch: 5| Step: 6
Training loss: 2.00243878364563
Validation loss: 2.1093127379814782

Epoch: 5| Step: 7
Training loss: 1.6524362564086914
Validation loss: 2.1247363736232123

Epoch: 5| Step: 8
Training loss: 2.205200672149658
Validation loss: 2.114790345231692

Epoch: 5| Step: 9
Training loss: 1.9127681255340576
Validation loss: 2.1118458608786264

Epoch: 5| Step: 10
Training loss: 1.5362632274627686
Validation loss: 2.0820405930280685

Epoch: 5| Step: 11
Training loss: 2.3502888679504395
Validation loss: 2.0802953789631524

Epoch: 198| Step: 0
Training loss: 1.9168384075164795
Validation loss: 2.0729957123597464

Epoch: 5| Step: 1
Training loss: 1.894598364830017
Validation loss: 2.0892451157172522

Epoch: 5| Step: 2
Training loss: 1.7128299474716187
Validation loss: 2.096792141596476

Epoch: 5| Step: 3
Training loss: 2.5387513637542725
Validation loss: 2.087268963456154

Epoch: 5| Step: 4
Training loss: 1.7581501007080078
Validation loss: 2.093832850456238

Epoch: 5| Step: 5
Training loss: 2.3090498447418213
Validation loss: 2.093136414885521

Epoch: 5| Step: 6
Training loss: 1.800696611404419
Validation loss: 2.1136009295781455

Epoch: 5| Step: 7
Training loss: 1.9494292736053467
Validation loss: 2.1190196772416434

Epoch: 5| Step: 8
Training loss: 2.432492971420288
Validation loss: 2.1156891683737435

Epoch: 5| Step: 9
Training loss: 1.9932883977890015
Validation loss: 2.110124811530113

Epoch: 5| Step: 10
Training loss: 1.641356110572815
Validation loss: 2.0998285114765167

Epoch: 5| Step: 11
Training loss: 2.724486827850342
Validation loss: 2.107530747850736

Epoch: 199| Step: 0
Training loss: 2.205301284790039
Validation loss: 2.1062706957260766

Epoch: 5| Step: 1
Training loss: 1.9282106161117554
Validation loss: 2.0959471315145493

Epoch: 5| Step: 2
Training loss: 1.7119596004486084
Validation loss: 2.097978567083677

Epoch: 5| Step: 3
Training loss: 2.451598644256592
Validation loss: 2.0951841473579407

Epoch: 5| Step: 4
Training loss: 1.4013915061950684
Validation loss: 2.100906257828077

Epoch: 5| Step: 5
Training loss: 2.3450281620025635
Validation loss: 2.0966950356960297

Epoch: 5| Step: 6
Training loss: 1.6697279214859009
Validation loss: 2.0877425769964852

Epoch: 5| Step: 7
Training loss: 1.8361215591430664
Validation loss: 2.0935987681150436

Epoch: 5| Step: 8
Training loss: 2.0122382640838623
Validation loss: 2.079389293988546

Epoch: 5| Step: 9
Training loss: 1.8178787231445312
Validation loss: 2.073781887690226

Epoch: 5| Step: 10
Training loss: 2.5663955211639404
Validation loss: 2.083222066362699

Epoch: 5| Step: 11
Training loss: 1.7363152503967285
Validation loss: 2.0798074255386987

Epoch: 200| Step: 0
Training loss: 1.477365255355835
Validation loss: 2.099179893732071

Epoch: 5| Step: 1
Training loss: 1.6791257858276367
Validation loss: 2.115381350119909

Epoch: 5| Step: 2
Training loss: 2.4213762283325195
Validation loss: 2.1359221041202545

Epoch: 5| Step: 3
Training loss: 1.915777564048767
Validation loss: 2.132561221718788

Epoch: 5| Step: 4
Training loss: 2.4665279388427734
Validation loss: 2.1177560786406198

Epoch: 5| Step: 5
Training loss: 1.8299064636230469
Validation loss: 2.113881145914396

Epoch: 5| Step: 6
Training loss: 1.64568293094635
Validation loss: 2.1325351844231286

Epoch: 5| Step: 7
Training loss: 2.3412091732025146
Validation loss: 2.1189659237861633

Epoch: 5| Step: 8
Training loss: 2.4320740699768066
Validation loss: 2.1144547959168754

Epoch: 5| Step: 9
Training loss: 1.478837251663208
Validation loss: 2.0859897484381995

Epoch: 5| Step: 10
Training loss: 2.531254529953003
Validation loss: 2.082354004184405

Epoch: 5| Step: 11
Training loss: 2.8225467205047607
Validation loss: 2.066769078373909

Epoch: 201| Step: 0
Training loss: 1.6545488834381104
Validation loss: 2.0700908601284027

Epoch: 5| Step: 1
Training loss: 1.7396122217178345
Validation loss: 2.0710561722517014

Epoch: 5| Step: 2
Training loss: 2.382793664932251
Validation loss: 2.070549060901006

Epoch: 5| Step: 3
Training loss: 1.9745502471923828
Validation loss: 2.0776048054297767

Epoch: 5| Step: 4
Training loss: 2.503365993499756
Validation loss: 2.072414348522822

Epoch: 5| Step: 5
Training loss: 1.9917360544204712
Validation loss: 2.0747648576895394

Epoch: 5| Step: 6
Training loss: 1.685235619544983
Validation loss: 2.07706410686175

Epoch: 5| Step: 7
Training loss: 1.838478684425354
Validation loss: 2.0910408198833466

Epoch: 5| Step: 8
Training loss: 2.1626088619232178
Validation loss: 2.1068157802025476

Epoch: 5| Step: 9
Training loss: 2.398216485977173
Validation loss: 2.099403883020083

Epoch: 5| Step: 10
Training loss: 1.6795991659164429
Validation loss: 2.084958707292875

Epoch: 5| Step: 11
Training loss: 1.632486343383789
Validation loss: 2.0836098293463388

Epoch: 202| Step: 0
Training loss: 2.234919786453247
Validation loss: 2.09390922387441

Epoch: 5| Step: 1
Training loss: 1.8741700649261475
Validation loss: 2.0991811752319336

Epoch: 5| Step: 2
Training loss: 2.589024543762207
Validation loss: 2.0904322266578674

Epoch: 5| Step: 3
Training loss: 2.382772922515869
Validation loss: 2.095484182238579

Epoch: 5| Step: 4
Training loss: 1.9387937784194946
Validation loss: 2.0770252346992493

Epoch: 5| Step: 5
Training loss: 2.1869394779205322
Validation loss: 2.0757625699043274

Epoch: 5| Step: 6
Training loss: 1.798174262046814
Validation loss: 2.0700067579746246

Epoch: 5| Step: 7
Training loss: 1.870748519897461
Validation loss: 2.070936774214109

Epoch: 5| Step: 8
Training loss: 1.5183781385421753
Validation loss: 2.0611733943223953

Epoch: 5| Step: 9
Training loss: 2.240462064743042
Validation loss: 2.0457923412323

Epoch: 5| Step: 10
Training loss: 1.6918537616729736
Validation loss: 2.05881696442763

Epoch: 5| Step: 11
Training loss: 1.59256112575531
Validation loss: 2.072298750281334

Epoch: 203| Step: 0
Training loss: 2.022331953048706
Validation loss: 2.0730391244093576

Epoch: 5| Step: 1
Training loss: 2.267428398132324
Validation loss: 2.082377567887306

Epoch: 5| Step: 2
Training loss: 1.8914597034454346
Validation loss: 2.076908896366755

Epoch: 5| Step: 3
Training loss: 1.79742431640625
Validation loss: 2.095403492450714

Epoch: 5| Step: 4
Training loss: 1.5655189752578735
Validation loss: 2.1207130004962287

Epoch: 5| Step: 5
Training loss: 2.02311372756958
Validation loss: 2.1177481611569724

Epoch: 5| Step: 6
Training loss: 1.8776267766952515
Validation loss: 2.11479714512825

Epoch: 5| Step: 7
Training loss: 2.212249279022217
Validation loss: 2.121060291926066

Epoch: 5| Step: 8
Training loss: 2.2934622764587402
Validation loss: 2.1221147378285727

Epoch: 5| Step: 9
Training loss: 2.2881057262420654
Validation loss: 2.104087313016256

Epoch: 5| Step: 10
Training loss: 1.66877019405365
Validation loss: 2.1007031152645745

Epoch: 5| Step: 11
Training loss: 3.0595312118530273
Validation loss: 2.079251458247503

Epoch: 204| Step: 0
Training loss: 1.8129987716674805
Validation loss: 2.062307596206665

Epoch: 5| Step: 1
Training loss: 2.052337646484375
Validation loss: 2.052737613519033

Epoch: 5| Step: 2
Training loss: 1.680789589881897
Validation loss: 2.0538683036963143

Epoch: 5| Step: 3
Training loss: 1.7022310495376587
Validation loss: 2.0460814932982125

Epoch: 5| Step: 4
Training loss: 1.9714828729629517
Validation loss: 2.035648286342621

Epoch: 5| Step: 5
Training loss: 2.287872314453125
Validation loss: 2.0419840663671494

Epoch: 5| Step: 6
Training loss: 2.508199691772461
Validation loss: 2.0377802650133767

Epoch: 5| Step: 7
Training loss: 2.20902943611145
Validation loss: 2.0256009101867676

Epoch: 5| Step: 8
Training loss: 1.8500196933746338
Validation loss: 2.036686067779859

Epoch: 5| Step: 9
Training loss: 2.5103840827941895
Validation loss: 2.0320920944213867

Epoch: 5| Step: 10
Training loss: 1.7783029079437256
Validation loss: 2.0348577996095023

Epoch: 5| Step: 11
Training loss: 2.008460760116577
Validation loss: 2.0324636896451316

Epoch: 205| Step: 0
Training loss: 1.5753110647201538
Validation loss: 2.040070911248525

Epoch: 5| Step: 1
Training loss: 1.581712007522583
Validation loss: 2.0428352057933807

Epoch: 5| Step: 2
Training loss: 2.133314847946167
Validation loss: 2.058584819237391

Epoch: 5| Step: 3
Training loss: 2.2736706733703613
Validation loss: 2.0641223589579263

Epoch: 5| Step: 4
Training loss: 2.0995635986328125
Validation loss: 2.0670460710922876

Epoch: 5| Step: 5
Training loss: 2.196251630783081
Validation loss: 2.0605207631985345

Epoch: 5| Step: 6
Training loss: 2.1417229175567627
Validation loss: 2.0697028189897537

Epoch: 5| Step: 7
Training loss: 1.7885017395019531
Validation loss: 2.0626955231030784

Epoch: 5| Step: 8
Training loss: 1.7744064331054688
Validation loss: 2.0709689209858575

Epoch: 5| Step: 9
Training loss: 2.125464677810669
Validation loss: 2.069656933347384

Epoch: 5| Step: 10
Training loss: 2.1319339275360107
Validation loss: 2.059124911824862

Epoch: 5| Step: 11
Training loss: 3.902798891067505
Validation loss: 2.056280573209127

Epoch: 206| Step: 0
Training loss: 2.1700446605682373
Validation loss: 2.0619125366210938

Epoch: 5| Step: 1
Training loss: 2.566262722015381
Validation loss: 2.045955757300059

Epoch: 5| Step: 2
Training loss: 1.8587850332260132
Validation loss: 2.05978986620903

Epoch: 5| Step: 3
Training loss: 2.245452880859375
Validation loss: 2.0431695183118186

Epoch: 5| Step: 4
Training loss: 1.345735788345337
Validation loss: 2.0525619288285575

Epoch: 5| Step: 5
Training loss: 1.871525526046753
Validation loss: 2.046438053250313

Epoch: 5| Step: 6
Training loss: 1.9810909032821655
Validation loss: 2.0501821488142014

Epoch: 5| Step: 7
Training loss: 2.3318538665771484
Validation loss: 2.0554545869429908

Epoch: 5| Step: 8
Training loss: 1.8126338720321655
Validation loss: 2.0538183202346167

Epoch: 5| Step: 9
Training loss: 1.837759256362915
Validation loss: 2.063599561651548

Epoch: 5| Step: 10
Training loss: 1.834813117980957
Validation loss: 2.076498414079348

Epoch: 5| Step: 11
Training loss: 2.8286938667297363
Validation loss: 2.0627088298400245

Epoch: 207| Step: 0
Training loss: 2.0454893112182617
Validation loss: 2.0759064157803855

Epoch: 5| Step: 1
Training loss: 3.05029034614563
Validation loss: 2.0699808498223624

Epoch: 5| Step: 2
Training loss: 1.80270516872406
Validation loss: 2.0623695303996405

Epoch: 5| Step: 3
Training loss: 1.4791522026062012
Validation loss: 2.0890328188737235

Epoch: 5| Step: 4
Training loss: 2.3083860874176025
Validation loss: 2.0986233254273734

Epoch: 5| Step: 5
Training loss: 2.100250720977783
Validation loss: 2.104886457324028

Epoch: 5| Step: 6
Training loss: 1.8922916650772095
Validation loss: 2.1137312750021615

Epoch: 5| Step: 7
Training loss: 1.6019748449325562
Validation loss: 2.0943385511636734

Epoch: 5| Step: 8
Training loss: 1.3412306308746338
Validation loss: 2.098704511920611

Epoch: 5| Step: 9
Training loss: 2.580781936645508
Validation loss: 2.092168480157852

Epoch: 5| Step: 10
Training loss: 2.0449161529541016
Validation loss: 2.0899459421634674

Epoch: 5| Step: 11
Training loss: 1.4847463369369507
Validation loss: 2.078311343987783

Epoch: 208| Step: 0
Training loss: 1.8709490299224854
Validation loss: 2.0757346947987876

Epoch: 5| Step: 1
Training loss: 2.0901424884796143
Validation loss: 2.0767909040053687

Epoch: 5| Step: 2
Training loss: 2.1947028636932373
Validation loss: 2.070363019903501

Epoch: 5| Step: 3
Training loss: 2.7277684211730957
Validation loss: 2.0728739450375238

Epoch: 5| Step: 4
Training loss: 1.786908507347107
Validation loss: 2.0710231314102807

Epoch: 5| Step: 5
Training loss: 2.5688486099243164
Validation loss: 2.0718690752983093

Epoch: 5| Step: 6
Training loss: 1.3708596229553223
Validation loss: 2.073282370964686

Epoch: 5| Step: 7
Training loss: 1.9843984842300415
Validation loss: 2.0762433310349784

Epoch: 5| Step: 8
Training loss: 1.631209135055542
Validation loss: 2.0803226828575134

Epoch: 5| Step: 9
Training loss: 1.7052091360092163
Validation loss: 2.0746040592590966

Epoch: 5| Step: 10
Training loss: 2.296915054321289
Validation loss: 2.089233487844467

Epoch: 5| Step: 11
Training loss: 1.3496299982070923
Validation loss: 2.091017027695974

Epoch: 209| Step: 0
Training loss: 1.5527116060256958
Validation loss: 2.1076477617025375

Epoch: 5| Step: 1
Training loss: 1.8556925058364868
Validation loss: 2.1099624186754227

Epoch: 5| Step: 2
Training loss: 2.0036168098449707
Validation loss: 2.116295332709948

Epoch: 5| Step: 3
Training loss: 1.7324014902114868
Validation loss: 2.108814626932144

Epoch: 5| Step: 4
Training loss: 2.2718255519866943
Validation loss: 2.111978366971016

Epoch: 5| Step: 5
Training loss: 2.1096293926239014
Validation loss: 2.12391804655393

Epoch: 5| Step: 6
Training loss: 1.681069016456604
Validation loss: 2.1284684439500174

Epoch: 5| Step: 7
Training loss: 2.004234552383423
Validation loss: 2.114390398065249

Epoch: 5| Step: 8
Training loss: 2.5233941078186035
Validation loss: 2.121880213419596

Epoch: 5| Step: 9
Training loss: 1.7465646266937256
Validation loss: 2.109064425031344

Epoch: 5| Step: 10
Training loss: 2.388115882873535
Validation loss: 2.0927434961001077

Epoch: 5| Step: 11
Training loss: 2.3081130981445312
Validation loss: 2.0893508891264596

Epoch: 210| Step: 0
Training loss: 2.1676692962646484
Validation loss: 2.080925688147545

Epoch: 5| Step: 1
Training loss: 2.087730646133423
Validation loss: 2.0730009327332177

Epoch: 5| Step: 2
Training loss: 2.1027913093566895
Validation loss: 2.0654753843943277

Epoch: 5| Step: 3
Training loss: 1.5218861103057861
Validation loss: 2.0592496196428933

Epoch: 5| Step: 4
Training loss: 2.42280912399292
Validation loss: 2.0502839237451553

Epoch: 5| Step: 5
Training loss: 2.0919787883758545
Validation loss: 2.0597152213255563

Epoch: 5| Step: 6
Training loss: 1.9719517230987549
Validation loss: 2.0630779614051185

Epoch: 5| Step: 7
Training loss: 2.400339126586914
Validation loss: 2.054625282684962

Epoch: 5| Step: 8
Training loss: 1.7041383981704712
Validation loss: 2.0638129810492196

Epoch: 5| Step: 9
Training loss: 1.8433418273925781
Validation loss: 2.0557842502991357

Epoch: 5| Step: 10
Training loss: 1.8388111591339111
Validation loss: 2.0717366337776184

Epoch: 5| Step: 11
Training loss: 1.819014549255371
Validation loss: 2.0812834600607553

Epoch: 211| Step: 0
Training loss: 1.7343757152557373
Validation loss: 2.0801227440436683

Epoch: 5| Step: 1
Training loss: 2.2070155143737793
Validation loss: 2.0953089396158853

Epoch: 5| Step: 2
Training loss: 1.4953244924545288
Validation loss: 2.0934567898511887

Epoch: 5| Step: 3
Training loss: 2.0540926456451416
Validation loss: 2.1032806634902954

Epoch: 5| Step: 4
Training loss: 1.767143964767456
Validation loss: 2.0941696961720786

Epoch: 5| Step: 5
Training loss: 2.300872802734375
Validation loss: 2.091985901196798

Epoch: 5| Step: 6
Training loss: 1.731357216835022
Validation loss: 2.0902930051088333

Epoch: 5| Step: 7
Training loss: 2.478307008743286
Validation loss: 2.076435908675194

Epoch: 5| Step: 8
Training loss: 1.5863288640975952
Validation loss: 2.078550174832344

Epoch: 5| Step: 9
Training loss: 2.577223539352417
Validation loss: 2.06675053636233

Epoch: 5| Step: 10
Training loss: 2.029226779937744
Validation loss: 2.077661116917928

Epoch: 5| Step: 11
Training loss: 1.91473388671875
Validation loss: 2.0684451311826706

Epoch: 212| Step: 0
Training loss: 1.931748390197754
Validation loss: 2.0726195772488913

Epoch: 5| Step: 1
Training loss: 1.617110013961792
Validation loss: 2.066926136612892

Epoch: 5| Step: 2
Training loss: 2.4753777980804443
Validation loss: 2.0486369530359902

Epoch: 5| Step: 3
Training loss: 2.149881601333618
Validation loss: 2.048158715168635

Epoch: 5| Step: 4
Training loss: 1.5095853805541992
Validation loss: 2.060080965360006

Epoch: 5| Step: 5
Training loss: 2.0940918922424316
Validation loss: 2.054897869626681

Epoch: 5| Step: 6
Training loss: 1.8734056949615479
Validation loss: 2.050187826156616

Epoch: 5| Step: 7
Training loss: 2.484999179840088
Validation loss: 2.0618980079889297

Epoch: 5| Step: 8
Training loss: 1.888379693031311
Validation loss: 2.0544584542512894

Epoch: 5| Step: 9
Training loss: 1.8853965997695923
Validation loss: 2.066821207602819

Epoch: 5| Step: 10
Training loss: 2.0620837211608887
Validation loss: 2.0709132005771003

Epoch: 5| Step: 11
Training loss: 2.1105191707611084
Validation loss: 2.0946257412433624

Epoch: 213| Step: 0
Training loss: 2.20754075050354
Validation loss: 2.1085759351650872

Epoch: 5| Step: 1
Training loss: 1.9449055194854736
Validation loss: 2.109195356567701

Epoch: 5| Step: 2
Training loss: 1.9274886846542358
Validation loss: 2.130820006132126

Epoch: 5| Step: 3
Training loss: 2.022637367248535
Validation loss: 2.121778373916944

Epoch: 5| Step: 4
Training loss: 2.018442153930664
Validation loss: 2.1160469502210617

Epoch: 5| Step: 5
Training loss: 1.621172308921814
Validation loss: 2.127022018035253

Epoch: 5| Step: 6
Training loss: 2.2327873706817627
Validation loss: 2.1135745694239936

Epoch: 5| Step: 7
Training loss: 2.3335187435150146
Validation loss: 2.1290062814950943

Epoch: 5| Step: 8
Training loss: 1.5674138069152832
Validation loss: 2.1184199452400208

Epoch: 5| Step: 9
Training loss: 1.9116909503936768
Validation loss: 2.0972544898589454

Epoch: 5| Step: 10
Training loss: 2.097761869430542
Validation loss: 2.0885084668795266

Epoch: 5| Step: 11
Training loss: 3.127034902572632
Validation loss: 2.0768990516662598

Epoch: 214| Step: 0
Training loss: 1.7356973886489868
Validation loss: 2.0635581662257514

Epoch: 5| Step: 1
Training loss: 2.560741662979126
Validation loss: 2.0721036046743393

Epoch: 5| Step: 2
Training loss: 2.0464415550231934
Validation loss: 2.066056475043297

Epoch: 5| Step: 3
Training loss: 2.0104727745056152
Validation loss: 2.061694582303365

Epoch: 5| Step: 4
Training loss: 2.409635543823242
Validation loss: 2.074870636065801

Epoch: 5| Step: 5
Training loss: 2.2813668251037598
Validation loss: 2.055287833015124

Epoch: 5| Step: 6
Training loss: 1.7880197763442993
Validation loss: 2.061410889029503

Epoch: 5| Step: 7
Training loss: 2.07761812210083
Validation loss: 2.07807923356692

Epoch: 5| Step: 8
Training loss: 1.8373454809188843
Validation loss: 2.0711327890555062

Epoch: 5| Step: 9
Training loss: 1.4166549444198608
Validation loss: 2.077294444044431

Epoch: 5| Step: 10
Training loss: 1.8540319204330444
Validation loss: 2.0770039012034736

Epoch: 5| Step: 11
Training loss: 1.8224918842315674
Validation loss: 2.076625327269236

Epoch: 215| Step: 0
Training loss: 2.6073546409606934
Validation loss: 2.079300502936045

Epoch: 5| Step: 1
Training loss: 2.0373339653015137
Validation loss: 2.0793015460173288

Epoch: 5| Step: 2
Training loss: 2.0603036880493164
Validation loss: 2.088294933239619

Epoch: 5| Step: 3
Training loss: 1.7011239528656006
Validation loss: 2.0940550019343696

Epoch: 5| Step: 4
Training loss: 2.029120683670044
Validation loss: 2.0941146661837897

Epoch: 5| Step: 5
Training loss: 1.9244506359100342
Validation loss: 2.083547443151474

Epoch: 5| Step: 6
Training loss: 1.6459426879882812
Validation loss: 2.1006397157907486

Epoch: 5| Step: 7
Training loss: 1.488072395324707
Validation loss: 2.1178564578294754

Epoch: 5| Step: 8
Training loss: 2.467344284057617
Validation loss: 2.1153712073961892

Epoch: 5| Step: 9
Training loss: 2.3240890502929688
Validation loss: 2.118649204572042

Epoch: 5| Step: 10
Training loss: 1.6753251552581787
Validation loss: 2.1045134464899697

Epoch: 5| Step: 11
Training loss: 1.1818087100982666
Validation loss: 2.119290828704834

Epoch: 216| Step: 0
Training loss: 1.6035358905792236
Validation loss: 2.097281123201052

Epoch: 5| Step: 1
Training loss: 1.836658239364624
Validation loss: 2.0793027132749557

Epoch: 5| Step: 2
Training loss: 2.0825226306915283
Validation loss: 2.078952814141909

Epoch: 5| Step: 3
Training loss: 1.8762454986572266
Validation loss: 2.06027615070343

Epoch: 5| Step: 4
Training loss: 2.6361589431762695
Validation loss: 2.064091553290685

Epoch: 5| Step: 5
Training loss: 2.0766077041625977
Validation loss: 2.0602601716915765

Epoch: 5| Step: 6
Training loss: 2.2085297107696533
Validation loss: 2.0669130782286325

Epoch: 5| Step: 7
Training loss: 1.7191013097763062
Validation loss: 2.064643089969953

Epoch: 5| Step: 8
Training loss: 2.2596771717071533
Validation loss: 2.06170354783535

Epoch: 5| Step: 9
Training loss: 1.685428261756897
Validation loss: 2.0793094088633857

Epoch: 5| Step: 10
Training loss: 2.1306381225585938
Validation loss: 2.0715194990237555

Epoch: 5| Step: 11
Training loss: 2.224102735519409
Validation loss: 2.0642485171556473

Epoch: 217| Step: 0
Training loss: 1.7739909887313843
Validation loss: 2.076796660820643

Epoch: 5| Step: 1
Training loss: 2.3380632400512695
Validation loss: 2.0719754844903946

Epoch: 5| Step: 2
Training loss: 1.701208472251892
Validation loss: 2.0875664403041205

Epoch: 5| Step: 3
Training loss: 1.8872820138931274
Validation loss: 2.100779429078102

Epoch: 5| Step: 4
Training loss: 2.1013927459716797
Validation loss: 2.098320464293162

Epoch: 5| Step: 5
Training loss: 1.975987195968628
Validation loss: 2.098977575699488

Epoch: 5| Step: 6
Training loss: 1.6733715534210205
Validation loss: 2.1107145051161447

Epoch: 5| Step: 7
Training loss: 2.1027166843414307
Validation loss: 2.1113210767507553

Epoch: 5| Step: 8
Training loss: 2.2093727588653564
Validation loss: 2.1228020588556924

Epoch: 5| Step: 9
Training loss: 1.9939641952514648
Validation loss: 2.138204495112101

Epoch: 5| Step: 10
Training loss: 1.9648529291152954
Validation loss: 2.1412669072548547

Epoch: 5| Step: 11
Training loss: 3.0063283443450928
Validation loss: 2.1403740098079047

Epoch: 218| Step: 0
Training loss: 1.7454299926757812
Validation loss: 2.151021952430407

Epoch: 5| Step: 1
Training loss: 2.0301513671875
Validation loss: 2.1281872491041818

Epoch: 5| Step: 2
Training loss: 2.244568347930908
Validation loss: 2.119142790635427

Epoch: 5| Step: 3
Training loss: 2.232944965362549
Validation loss: 2.1271365582942963

Epoch: 5| Step: 4
Training loss: 2.077108860015869
Validation loss: 2.119740813970566

Epoch: 5| Step: 5
Training loss: 1.4894400835037231
Validation loss: 2.1263914704322815

Epoch: 5| Step: 6
Training loss: 2.0121257305145264
Validation loss: 2.0990370213985443

Epoch: 5| Step: 7
Training loss: 2.311974287033081
Validation loss: 2.1035115867853165

Epoch: 5| Step: 8
Training loss: 2.1058011054992676
Validation loss: 2.0888408571481705

Epoch: 5| Step: 9
Training loss: 2.0244858264923096
Validation loss: 2.0708278715610504

Epoch: 5| Step: 10
Training loss: 1.7342097759246826
Validation loss: 2.0620383620262146

Epoch: 5| Step: 11
Training loss: 1.9455512762069702
Validation loss: 2.0650735100110373

Epoch: 219| Step: 0
Training loss: 1.7113850116729736
Validation loss: 2.068444386124611

Epoch: 5| Step: 1
Training loss: 2.0061511993408203
Validation loss: 2.069760099053383

Epoch: 5| Step: 2
Training loss: 2.1638998985290527
Validation loss: 2.0723296652237573

Epoch: 5| Step: 3
Training loss: 2.2226405143737793
Validation loss: 2.0706178744633994

Epoch: 5| Step: 4
Training loss: 2.355149507522583
Validation loss: 2.079660947124163

Epoch: 5| Step: 5
Training loss: 1.9554847478866577
Validation loss: 2.089699074625969

Epoch: 5| Step: 6
Training loss: 1.5027467012405396
Validation loss: 2.0887256215016046

Epoch: 5| Step: 7
Training loss: 1.5991607904434204
Validation loss: 2.0956705808639526

Epoch: 5| Step: 8
Training loss: 1.980849266052246
Validation loss: 2.1051232566436133

Epoch: 5| Step: 9
Training loss: 2.187790870666504
Validation loss: 2.084125190973282

Epoch: 5| Step: 10
Training loss: 2.4530527591705322
Validation loss: 2.095506245891253

Epoch: 5| Step: 11
Training loss: 1.905234694480896
Validation loss: 2.107297658920288

Epoch: 220| Step: 0
Training loss: 2.3226113319396973
Validation loss: 2.1005642215410867

Epoch: 5| Step: 1
Training loss: 2.3489694595336914
Validation loss: 2.0979095647732415

Epoch: 5| Step: 2
Training loss: 1.7170040607452393
Validation loss: 2.094401796658834

Epoch: 5| Step: 3
Training loss: 2.342851161956787
Validation loss: 2.1004030803839364

Epoch: 5| Step: 4
Training loss: 2.1132607460021973
Validation loss: 2.08887646595637

Epoch: 5| Step: 5
Training loss: 1.7127363681793213
Validation loss: 2.121370404958725

Epoch: 5| Step: 6
Training loss: 2.2006123065948486
Validation loss: 2.122511848807335

Epoch: 5| Step: 7
Training loss: 1.3651658296585083
Validation loss: 2.1197659770647683

Epoch: 5| Step: 8
Training loss: 2.021273136138916
Validation loss: 2.1219444324572883

Epoch: 5| Step: 9
Training loss: 1.7438981533050537
Validation loss: 2.1106099685033164

Epoch: 5| Step: 10
Training loss: 1.6299190521240234
Validation loss: 2.114761561155319

Epoch: 5| Step: 11
Training loss: 2.0954442024230957
Validation loss: 2.1053273330132165

Epoch: 221| Step: 0
Training loss: 1.8505756855010986
Validation loss: 2.106958950559298

Epoch: 5| Step: 1
Training loss: 1.5512691736221313
Validation loss: 2.1102108508348465

Epoch: 5| Step: 2
Training loss: 2.375081777572632
Validation loss: 2.103037859002749

Epoch: 5| Step: 3
Training loss: 1.7704988718032837
Validation loss: 2.0915340880552926

Epoch: 5| Step: 4
Training loss: 1.898413062095642
Validation loss: 2.105815574526787

Epoch: 5| Step: 5
Training loss: 2.6712803840637207
Validation loss: 2.0958583106597266

Epoch: 5| Step: 6
Training loss: 2.0012335777282715
Validation loss: 2.1114122569561005

Epoch: 5| Step: 7
Training loss: 1.7733485698699951
Validation loss: 2.1285399943590164

Epoch: 5| Step: 8
Training loss: 2.0655159950256348
Validation loss: 2.1117887099583945

Epoch: 5| Step: 9
Training loss: 1.9765609502792358
Validation loss: 2.1188007493813834

Epoch: 5| Step: 10
Training loss: 1.5956733226776123
Validation loss: 2.100351224342982

Epoch: 5| Step: 11
Training loss: 2.7333154678344727
Validation loss: 2.1006371676921844

Epoch: 222| Step: 0
Training loss: 2.307262897491455
Validation loss: 2.073815400401751

Epoch: 5| Step: 1
Training loss: 1.7783514261245728
Validation loss: 2.082237829764684

Epoch: 5| Step: 2
Training loss: 1.6141513586044312
Validation loss: 2.0751463025808334

Epoch: 5| Step: 3
Training loss: 1.8658878803253174
Validation loss: 2.0641745229562125

Epoch: 5| Step: 4
Training loss: 2.4664885997772217
Validation loss: 2.0681183536847434

Epoch: 5| Step: 5
Training loss: 1.942145586013794
Validation loss: 2.068699911236763

Epoch: 5| Step: 6
Training loss: 1.8306224346160889
Validation loss: 2.0658091257015863

Epoch: 5| Step: 7
Training loss: 2.1072230339050293
Validation loss: 2.092624763647715

Epoch: 5| Step: 8
Training loss: 2.1556575298309326
Validation loss: 2.096909314393997

Epoch: 5| Step: 9
Training loss: 2.1683192253112793
Validation loss: 2.117735058069229

Epoch: 5| Step: 10
Training loss: 1.6741501092910767
Validation loss: 2.1044142047564187

Epoch: 5| Step: 11
Training loss: 1.9996610879898071
Validation loss: 2.1118571807940802

Epoch: 223| Step: 0
Training loss: 2.1857199668884277
Validation loss: 2.1199974368015924

Epoch: 5| Step: 1
Training loss: 1.3717641830444336
Validation loss: 2.1119098365306854

Epoch: 5| Step: 2
Training loss: 2.402369260787964
Validation loss: 2.126007388035456

Epoch: 5| Step: 3
Training loss: 1.847956657409668
Validation loss: 2.1292253931363425

Epoch: 5| Step: 4
Training loss: 2.2512128353118896
Validation loss: 2.095252215862274

Epoch: 5| Step: 5
Training loss: 2.152275562286377
Validation loss: 2.0945843706528344

Epoch: 5| Step: 6
Training loss: 2.528157949447632
Validation loss: 2.078149120012919

Epoch: 5| Step: 7
Training loss: 1.5664976835250854
Validation loss: 2.0671952863534293

Epoch: 5| Step: 8
Training loss: 2.0940470695495605
Validation loss: 2.0728902916113534

Epoch: 5| Step: 9
Training loss: 1.969002366065979
Validation loss: 2.0638388941685357

Epoch: 5| Step: 10
Training loss: 1.8473224639892578
Validation loss: 2.067162275314331

Epoch: 5| Step: 11
Training loss: 1.0186952352523804
Validation loss: 2.0891078611214957

Epoch: 224| Step: 0
Training loss: 2.041276454925537
Validation loss: 2.0824836244185767

Epoch: 5| Step: 1
Training loss: 2.074883222579956
Validation loss: 2.0762890179951987

Epoch: 5| Step: 2
Training loss: 2.6097545623779297
Validation loss: 2.076976935068766

Epoch: 5| Step: 3
Training loss: 2.0731396675109863
Validation loss: 2.0690471629301705

Epoch: 5| Step: 4
Training loss: 1.389073371887207
Validation loss: 2.0797723631064096

Epoch: 5| Step: 5
Training loss: 2.139662265777588
Validation loss: 2.0823842883110046

Epoch: 5| Step: 6
Training loss: 2.0885396003723145
Validation loss: 2.094040811061859

Epoch: 5| Step: 7
Training loss: 1.8210052251815796
Validation loss: 2.1003277599811554

Epoch: 5| Step: 8
Training loss: 1.542869210243225
Validation loss: 2.1037663519382477

Epoch: 5| Step: 9
Training loss: 1.3731769323349
Validation loss: 2.1127457668383918

Epoch: 5| Step: 10
Training loss: 2.3587028980255127
Validation loss: 2.1341909766197205

Epoch: 5| Step: 11
Training loss: 2.8515052795410156
Validation loss: 2.133651147286097

Epoch: 225| Step: 0
Training loss: 2.196840763092041
Validation loss: 2.1329625646273294

Epoch: 5| Step: 1
Training loss: 2.2349367141723633
Validation loss: 2.1306580205758414

Epoch: 5| Step: 2
Training loss: 1.3882492780685425
Validation loss: 2.1269523749748864

Epoch: 5| Step: 3
Training loss: 1.9276046752929688
Validation loss: 2.138653794924418

Epoch: 5| Step: 4
Training loss: 1.8281761407852173
Validation loss: 2.1001861790815988

Epoch: 5| Step: 5
Training loss: 1.5436955690383911
Validation loss: 2.0973604321479797

Epoch: 5| Step: 6
Training loss: 2.2773995399475098
Validation loss: 2.0989074955383935

Epoch: 5| Step: 7
Training loss: 1.90226149559021
Validation loss: 2.1013552894194922

Epoch: 5| Step: 8
Training loss: 1.7946126461029053
Validation loss: 2.096760834256808

Epoch: 5| Step: 9
Training loss: 2.1559555530548096
Validation loss: 2.104113062222799

Epoch: 5| Step: 10
Training loss: 2.168844699859619
Validation loss: 2.118527283271154

Epoch: 5| Step: 11
Training loss: 2.55889892578125
Validation loss: 2.1203505297501883

Epoch: 226| Step: 0
Training loss: 1.7267224788665771
Validation loss: 2.110356251398722

Epoch: 5| Step: 1
Training loss: 2.121368885040283
Validation loss: 2.097299044330915

Epoch: 5| Step: 2
Training loss: 2.3416285514831543
Validation loss: 2.0889471024274826

Epoch: 5| Step: 3
Training loss: 2.0429892539978027
Validation loss: 2.0984498957792916

Epoch: 5| Step: 4
Training loss: 1.7838752269744873
Validation loss: 2.0946038216352463

Epoch: 5| Step: 5
Training loss: 1.990835428237915
Validation loss: 2.100819706916809

Epoch: 5| Step: 6
Training loss: 2.111558198928833
Validation loss: 2.0830532014369965

Epoch: 5| Step: 7
Training loss: 2.1283493041992188
Validation loss: 2.106957862774531

Epoch: 5| Step: 8
Training loss: 1.9943393468856812
Validation loss: 2.1033537536859512

Epoch: 5| Step: 9
Training loss: 1.3252760171890259
Validation loss: 2.110121801495552

Epoch: 5| Step: 10
Training loss: 1.9113242626190186
Validation loss: 2.1070054719845452

Epoch: 5| Step: 11
Training loss: 2.496739387512207
Validation loss: 2.095507562160492

Epoch: 227| Step: 0
Training loss: 1.853477120399475
Validation loss: 2.105225071310997

Epoch: 5| Step: 1
Training loss: 1.6623923778533936
Validation loss: 2.098481913407644

Epoch: 5| Step: 2
Training loss: 2.0792453289031982
Validation loss: 2.1104556123415628

Epoch: 5| Step: 3
Training loss: 1.6304662227630615
Validation loss: 2.119881570339203

Epoch: 5| Step: 4
Training loss: 1.6681883335113525
Validation loss: 2.1285344064235687

Epoch: 5| Step: 5
Training loss: 2.304399251937866
Validation loss: 2.103780825932821

Epoch: 5| Step: 6
Training loss: 2.51259183883667
Validation loss: 2.103078320622444

Epoch: 5| Step: 7
Training loss: 1.5352532863616943
Validation loss: 2.113445450862249

Epoch: 5| Step: 8
Training loss: 2.192455530166626
Validation loss: 2.105332612991333

Epoch: 5| Step: 9
Training loss: 2.085376739501953
Validation loss: 2.1032177408536277

Epoch: 5| Step: 10
Training loss: 1.8373037576675415
Validation loss: 2.1064940889676413

Epoch: 5| Step: 11
Training loss: 2.296330690383911
Validation loss: 2.1063863734404245

Epoch: 228| Step: 0
Training loss: 2.0869851112365723
Validation loss: 2.1012205878893533

Epoch: 5| Step: 1
Training loss: 1.66470468044281
Validation loss: 2.103663146495819

Epoch: 5| Step: 2
Training loss: 2.1125638484954834
Validation loss: 2.0888232737779617

Epoch: 5| Step: 3
Training loss: 1.9786382913589478
Validation loss: 2.102393930157026

Epoch: 5| Step: 4
Training loss: 1.721753716468811
Validation loss: 2.0963777850071588

Epoch: 5| Step: 5
Training loss: 1.3896770477294922
Validation loss: 2.118185078104337

Epoch: 5| Step: 6
Training loss: 2.6587376594543457
Validation loss: 2.1237440754969916

Epoch: 5| Step: 7
Training loss: 2.0141053199768066
Validation loss: 2.116612752278646

Epoch: 5| Step: 8
Training loss: 1.5239830017089844
Validation loss: 2.12045348683993

Epoch: 5| Step: 9
Training loss: 1.7118034362792969
Validation loss: 2.137711837887764

Epoch: 5| Step: 10
Training loss: 2.4481544494628906
Validation loss: 2.135825832684835

Epoch: 5| Step: 11
Training loss: 2.0445451736450195
Validation loss: 2.125348220268885

Epoch: 229| Step: 0
Training loss: 1.4272602796554565
Validation loss: 2.1228886346022287

Epoch: 5| Step: 1
Training loss: 2.081472635269165
Validation loss: 2.139645059903463

Epoch: 5| Step: 2
Training loss: 2.073758602142334
Validation loss: 2.1238168676694236

Epoch: 5| Step: 3
Training loss: 2.0492966175079346
Validation loss: 2.1332384745279946

Epoch: 5| Step: 4
Training loss: 2.295825958251953
Validation loss: 2.1302139113346734

Epoch: 5| Step: 5
Training loss: 1.8276588916778564
Validation loss: 2.128842627008756

Epoch: 5| Step: 6
Training loss: 2.081038236618042
Validation loss: 2.1351615687211356

Epoch: 5| Step: 7
Training loss: 2.464195966720581
Validation loss: 2.1356429904699326

Epoch: 5| Step: 8
Training loss: 1.7312027215957642
Validation loss: 2.104219729701678

Epoch: 5| Step: 9
Training loss: 1.7952502965927124
Validation loss: 2.107037583986918

Epoch: 5| Step: 10
Training loss: 1.8463354110717773
Validation loss: 2.113697270552317

Epoch: 5| Step: 11
Training loss: 0.9017155170440674
Validation loss: 2.102395604054133

Epoch: 230| Step: 0
Training loss: 1.9141210317611694
Validation loss: 2.1032683899005256

Epoch: 5| Step: 1
Training loss: 2.2475674152374268
Validation loss: 2.111735905210177

Epoch: 5| Step: 2
Training loss: 2.1592278480529785
Validation loss: 2.1120195239782333

Epoch: 5| Step: 3
Training loss: 2.4093565940856934
Validation loss: 2.1276574581861496

Epoch: 5| Step: 4
Training loss: 1.9012798070907593
Validation loss: 2.0948056081930795

Epoch: 5| Step: 5
Training loss: 2.124828815460205
Validation loss: 2.103024219473203

Epoch: 5| Step: 6
Training loss: 2.0131335258483887
Validation loss: 2.100335737069448

Epoch: 5| Step: 7
Training loss: 1.5916427373886108
Validation loss: 2.0981584588686624

Epoch: 5| Step: 8
Training loss: 2.1195483207702637
Validation loss: 2.111081898212433

Epoch: 5| Step: 9
Training loss: 1.643751859664917
Validation loss: 2.0950883428255715

Epoch: 5| Step: 10
Training loss: 1.8277298212051392
Validation loss: 2.085286761323611

Epoch: 5| Step: 11
Training loss: 1.625259518623352
Validation loss: 2.092504153649012

Epoch: 231| Step: 0
Training loss: 2.558885097503662
Validation loss: 2.0826009958982468

Epoch: 5| Step: 1
Training loss: 1.8393245935440063
Validation loss: 2.0863806108633676

Epoch: 5| Step: 2
Training loss: 1.969928503036499
Validation loss: 2.0749532083670297

Epoch: 5| Step: 3
Training loss: 1.7352415323257446
Validation loss: 2.0829593539237976

Epoch: 5| Step: 4
Training loss: 1.7826452255249023
Validation loss: 2.0856483379999795

Epoch: 5| Step: 5
Training loss: 1.8354495763778687
Validation loss: 2.0947428743044534

Epoch: 5| Step: 6
Training loss: 1.9910598993301392
Validation loss: 2.084151883920034

Epoch: 5| Step: 7
Training loss: 2.2973179817199707
Validation loss: 2.093061109383901

Epoch: 5| Step: 8
Training loss: 2.109365224838257
Validation loss: 2.094947392741839

Epoch: 5| Step: 9
Training loss: 1.3402019739151
Validation loss: 2.1025982002417245

Epoch: 5| Step: 10
Training loss: 2.1093366146087646
Validation loss: 2.0969247023264566

Epoch: 5| Step: 11
Training loss: 2.869649887084961
Validation loss: 2.0998728772004447

Epoch: 232| Step: 0
Training loss: 2.2852375507354736
Validation loss: 2.0804100980361304

Epoch: 5| Step: 1
Training loss: 1.5110533237457275
Validation loss: 2.0763776302337646

Epoch: 5| Step: 2
Training loss: 1.9753997325897217
Validation loss: 2.0619787921508155

Epoch: 5| Step: 3
Training loss: 2.3513331413269043
Validation loss: 2.088922788699468

Epoch: 5| Step: 4
Training loss: 2.083845853805542
Validation loss: 2.0752692272265754

Epoch: 5| Step: 5
Training loss: 2.0811116695404053
Validation loss: 2.08334415157636

Epoch: 5| Step: 6
Training loss: 1.8159246444702148
Validation loss: 2.086908837159475

Epoch: 5| Step: 7
Training loss: 2.328002452850342
Validation loss: 2.0907574792702994

Epoch: 5| Step: 8
Training loss: 1.3821299076080322
Validation loss: 2.093230669697126

Epoch: 5| Step: 9
Training loss: 2.0146851539611816
Validation loss: 2.101062074303627

Epoch: 5| Step: 10
Training loss: 1.9059696197509766
Validation loss: 2.0972255865732827

Epoch: 5| Step: 11
Training loss: 2.499068260192871
Validation loss: 2.1020087202390036

Epoch: 233| Step: 0
Training loss: 1.3508377075195312
Validation loss: 2.1002351542313895

Epoch: 5| Step: 1
Training loss: 1.4414002895355225
Validation loss: 2.1135784486929574

Epoch: 5| Step: 2
Training loss: 1.7304319143295288
Validation loss: 2.1171528001626334

Epoch: 5| Step: 3
Training loss: 1.8502346277236938
Validation loss: 2.134081626931826

Epoch: 5| Step: 4
Training loss: 1.4372484683990479
Validation loss: 2.137315183877945

Epoch: 5| Step: 5
Training loss: 2.243624210357666
Validation loss: 2.124180793762207

Epoch: 5| Step: 6
Training loss: 2.5082736015319824
Validation loss: 2.1182874043782554

Epoch: 5| Step: 7
Training loss: 2.5224225521087646
Validation loss: 2.1008687565724053

Epoch: 5| Step: 8
Training loss: 2.3337063789367676
Validation loss: 2.0981140732765198

Epoch: 5| Step: 9
Training loss: 2.4846348762512207
Validation loss: 2.099990795056025

Epoch: 5| Step: 10
Training loss: 1.825926423072815
Validation loss: 2.0854099690914154

Epoch: 5| Step: 11
Training loss: 1.5015068054199219
Validation loss: 2.086201637983322

Epoch: 234| Step: 0
Training loss: 1.6842025518417358
Validation loss: 2.0893326501051583

Epoch: 5| Step: 1
Training loss: 2.318586826324463
Validation loss: 2.0920829673608146

Epoch: 5| Step: 2
Training loss: 1.3990437984466553
Validation loss: 2.0920564929644265

Epoch: 5| Step: 3
Training loss: 2.080594539642334
Validation loss: 2.099783549706141

Epoch: 5| Step: 4
Training loss: 1.8438228368759155
Validation loss: 2.1002256274223328

Epoch: 5| Step: 5
Training loss: 2.0616092681884766
Validation loss: 2.1137937108675637

Epoch: 5| Step: 6
Training loss: 2.1782925128936768
Validation loss: 2.1267510106166205

Epoch: 5| Step: 7
Training loss: 2.3469414710998535
Validation loss: 2.1064841796954474

Epoch: 5| Step: 8
Training loss: 1.4005900621414185
Validation loss: 2.112648159265518

Epoch: 5| Step: 9
Training loss: 1.7080570459365845
Validation loss: 2.1122473627328873

Epoch: 5| Step: 10
Training loss: 2.0716586112976074
Validation loss: 2.1134603967269263

Epoch: 5| Step: 11
Training loss: 4.297228813171387
Validation loss: 2.1120017965634665

Epoch: 235| Step: 0
Training loss: 2.268394947052002
Validation loss: 2.1011415819327035

Epoch: 5| Step: 1
Training loss: 2.2844882011413574
Validation loss: 2.0995018780231476

Epoch: 5| Step: 2
Training loss: 1.5359256267547607
Validation loss: 2.099981685479482

Epoch: 5| Step: 3
Training loss: 2.5713512897491455
Validation loss: 2.0969816893339157

Epoch: 5| Step: 4
Training loss: 2.0851104259490967
Validation loss: 2.1030885924895606

Epoch: 5| Step: 5
Training loss: 2.206148624420166
Validation loss: 2.095842490593592

Epoch: 5| Step: 6
Training loss: 1.8626251220703125
Validation loss: 2.1011588871479034

Epoch: 5| Step: 7
Training loss: 2.0136513710021973
Validation loss: 2.110835075378418

Epoch: 5| Step: 8
Training loss: 1.6264480352401733
Validation loss: 2.107506051659584

Epoch: 5| Step: 9
Training loss: 1.6501331329345703
Validation loss: 2.1003133008877435

Epoch: 5| Step: 10
Training loss: 1.3642761707305908
Validation loss: 2.121961568792661

Epoch: 5| Step: 11
Training loss: 1.3326613903045654
Validation loss: 2.1244191577037177

Epoch: 236| Step: 0
Training loss: 1.899401068687439
Validation loss: 2.1147422989209494

Epoch: 5| Step: 1
Training loss: 2.1529550552368164
Validation loss: 2.111050317684809

Epoch: 5| Step: 2
Training loss: 2.2100062370300293
Validation loss: 2.110647588968277

Epoch: 5| Step: 3
Training loss: 1.6683051586151123
Validation loss: 2.1060783664385476

Epoch: 5| Step: 4
Training loss: 1.5946028232574463
Validation loss: 2.1242981453736625

Epoch: 5| Step: 5
Training loss: 1.6000429391860962
Validation loss: 2.1129994789759317

Epoch: 5| Step: 6
Training loss: 1.5827053785324097
Validation loss: 2.126900648077329

Epoch: 5| Step: 7
Training loss: 2.083651065826416
Validation loss: 2.122740755478541

Epoch: 5| Step: 8
Training loss: 1.6714446544647217
Validation loss: 2.1146010955174765

Epoch: 5| Step: 9
Training loss: 2.5036487579345703
Validation loss: 2.1137203723192215

Epoch: 5| Step: 10
Training loss: 2.2335762977600098
Validation loss: 2.126121684908867

Epoch: 5| Step: 11
Training loss: 2.0954232215881348
Validation loss: 2.1360648373762765

Epoch: 237| Step: 0
Training loss: 2.2562789916992188
Validation loss: 2.136413097381592

Epoch: 5| Step: 1
Training loss: 1.879894495010376
Validation loss: 2.1335381319125495

Epoch: 5| Step: 2
Training loss: 1.7065184116363525
Validation loss: 2.1336419185002646

Epoch: 5| Step: 3
Training loss: 1.5142406225204468
Validation loss: 2.1259422600269318

Epoch: 5| Step: 4
Training loss: 1.5697078704833984
Validation loss: 2.134691685438156

Epoch: 5| Step: 5
Training loss: 2.3191006183624268
Validation loss: 2.124348590771357

Epoch: 5| Step: 6
Training loss: 1.9832210540771484
Validation loss: 2.1216331869363785

Epoch: 5| Step: 7
Training loss: 1.9442495107650757
Validation loss: 2.1281012296676636

Epoch: 5| Step: 8
Training loss: 1.6898362636566162
Validation loss: 2.1076996326446533

Epoch: 5| Step: 9
Training loss: 2.1701407432556152
Validation loss: 2.120456874370575

Epoch: 5| Step: 10
Training loss: 2.1596615314483643
Validation loss: 2.0949978729089103

Epoch: 5| Step: 11
Training loss: 2.1586389541625977
Validation loss: 2.092405835787455

Epoch: 238| Step: 0
Training loss: 1.4727250337600708
Validation loss: 2.091098815202713

Epoch: 5| Step: 1
Training loss: 1.851395606994629
Validation loss: 2.088949223359426

Epoch: 5| Step: 2
Training loss: 1.8101850748062134
Validation loss: 2.106808523337046

Epoch: 5| Step: 3
Training loss: 1.951531171798706
Validation loss: 2.116522495945295

Epoch: 5| Step: 4
Training loss: 1.797726035118103
Validation loss: 2.1024056325356164

Epoch: 5| Step: 5
Training loss: 2.2296369075775146
Validation loss: 2.112542226910591

Epoch: 5| Step: 6
Training loss: 2.487365245819092
Validation loss: 2.11209204296271

Epoch: 5| Step: 7
Training loss: 1.8177926540374756
Validation loss: 2.13056048254172

Epoch: 5| Step: 8
Training loss: 2.288588762283325
Validation loss: 2.115799516439438

Epoch: 5| Step: 9
Training loss: 2.040400981903076
Validation loss: 2.104657823840777

Epoch: 5| Step: 10
Training loss: 1.5045801401138306
Validation loss: 2.125127603610357

Epoch: 5| Step: 11
Training loss: 2.49676513671875
Validation loss: 2.1386704246203103

Epoch: 239| Step: 0
Training loss: 1.4589779376983643
Validation loss: 2.11296609044075

Epoch: 5| Step: 1
Training loss: 2.01318359375
Validation loss: 2.1382050067186356

Epoch: 5| Step: 2
Training loss: 1.6734470129013062
Validation loss: 2.1188369592030845

Epoch: 5| Step: 3
Training loss: 1.8525041341781616
Validation loss: 2.13726340730985

Epoch: 5| Step: 4
Training loss: 2.5224339962005615
Validation loss: 2.116657038529714

Epoch: 5| Step: 5
Training loss: 2.286353588104248
Validation loss: 2.1341836949189505

Epoch: 5| Step: 6
Training loss: 1.8680870532989502
Validation loss: 2.1268336276213327

Epoch: 5| Step: 7
Training loss: 2.0614306926727295
Validation loss: 2.1396173238754272

Epoch: 5| Step: 8
Training loss: 2.300299882888794
Validation loss: 2.1388596892356873

Epoch: 5| Step: 9
Training loss: 1.4188140630722046
Validation loss: 2.147030626734098

Epoch: 5| Step: 10
Training loss: 1.9487413167953491
Validation loss: 2.1334325621525445

Epoch: 5| Step: 11
Training loss: 1.5338950157165527
Validation loss: 2.1302212178707123

Epoch: 240| Step: 0
Training loss: 2.0080034732818604
Validation loss: 2.1193369378646216

Epoch: 5| Step: 1
Training loss: 1.3380334377288818
Validation loss: 2.11819497247537

Epoch: 5| Step: 2
Training loss: 1.9671909809112549
Validation loss: 2.1352793474992118

Epoch: 5| Step: 3
Training loss: 1.647761583328247
Validation loss: 2.126011535525322

Epoch: 5| Step: 4
Training loss: 2.0806312561035156
Validation loss: 2.128740871946017

Epoch: 5| Step: 5
Training loss: 2.246706008911133
Validation loss: 2.1259961227575936

Epoch: 5| Step: 6
Training loss: 2.6710076332092285
Validation loss: 2.115561525026957

Epoch: 5| Step: 7
Training loss: 1.8306477069854736
Validation loss: 2.113491326570511

Epoch: 5| Step: 8
Training loss: 2.133993625640869
Validation loss: 2.1150969515244165

Epoch: 5| Step: 9
Training loss: 1.4672105312347412
Validation loss: 2.1228067179520926

Epoch: 5| Step: 10
Training loss: 1.6494481563568115
Validation loss: 2.118508537610372

Epoch: 5| Step: 11
Training loss: 2.3866069316864014
Validation loss: 2.137229005495707

Epoch: 241| Step: 0
Training loss: 1.8410392999649048
Validation loss: 2.1465845008691153

Epoch: 5| Step: 1
Training loss: 1.4768177270889282
Validation loss: 2.1508029202620187

Epoch: 5| Step: 2
Training loss: 1.415322184562683
Validation loss: 2.1421394447485604

Epoch: 5| Step: 3
Training loss: 2.053452730178833
Validation loss: 2.1397363394498825

Epoch: 5| Step: 4
Training loss: 2.0941362380981445
Validation loss: 2.1361539363861084

Epoch: 5| Step: 5
Training loss: 2.0108001232147217
Validation loss: 2.1424795538187027

Epoch: 5| Step: 6
Training loss: 2.334510087966919
Validation loss: 2.1350315660238266

Epoch: 5| Step: 7
Training loss: 1.8550498485565186
Validation loss: 2.1396409372488656

Epoch: 5| Step: 8
Training loss: 1.6241185665130615
Validation loss: 2.142523020505905

Epoch: 5| Step: 9
Training loss: 1.7317135334014893
Validation loss: 2.151959473888079

Epoch: 5| Step: 10
Training loss: 2.180128574371338
Validation loss: 2.151206319530805

Epoch: 5| Step: 11
Training loss: 4.520864486694336
Validation loss: 2.1355901062488556

Epoch: 242| Step: 0
Training loss: 1.5066477060317993
Validation loss: 2.1445537308851876

Epoch: 5| Step: 1
Training loss: 1.6077919006347656
Validation loss: 2.1296825855970383

Epoch: 5| Step: 2
Training loss: 2.223827838897705
Validation loss: 2.1318912506103516

Epoch: 5| Step: 3
Training loss: 1.8050731420516968
Validation loss: 2.1429254511992135

Epoch: 5| Step: 4
Training loss: 1.9787180423736572
Validation loss: 2.1494085788726807

Epoch: 5| Step: 5
Training loss: 2.045605182647705
Validation loss: 2.1355372965335846

Epoch: 5| Step: 6
Training loss: 1.9183728694915771
Validation loss: 2.1452491035064063

Epoch: 5| Step: 7
Training loss: 1.3483994007110596
Validation loss: 2.1458805402119956

Epoch: 5| Step: 8
Training loss: 2.5386669635772705
Validation loss: 2.149984285235405

Epoch: 5| Step: 9
Training loss: 2.0457634925842285
Validation loss: 2.167478774984678

Epoch: 5| Step: 10
Training loss: 2.1788461208343506
Validation loss: 2.15673591196537

Epoch: 5| Step: 11
Training loss: 2.1083333492279053
Validation loss: 2.15535905957222

Epoch: 243| Step: 0
Training loss: 2.215620517730713
Validation loss: 2.1379679640134177

Epoch: 5| Step: 1
Training loss: 1.625936508178711
Validation loss: 2.109763354063034

Epoch: 5| Step: 2
Training loss: 2.2974021434783936
Validation loss: 2.116331607103348

Epoch: 5| Step: 3
Training loss: 2.193873167037964
Validation loss: 2.116870015859604

Epoch: 5| Step: 4
Training loss: 1.6221040487289429
Validation loss: 2.115768328309059

Epoch: 5| Step: 5
Training loss: 1.4479548931121826
Validation loss: 2.112342596054077

Epoch: 5| Step: 6
Training loss: 1.6926530599594116
Validation loss: 2.1260413775841394

Epoch: 5| Step: 7
Training loss: 2.0494112968444824
Validation loss: 2.1385266383488974

Epoch: 5| Step: 8
Training loss: 1.8847987651824951
Validation loss: 2.120882118741671

Epoch: 5| Step: 9
Training loss: 1.7650665044784546
Validation loss: 2.128822068373362

Epoch: 5| Step: 10
Training loss: 2.598179340362549
Validation loss: 2.1280771046876907

Epoch: 5| Step: 11
Training loss: 0.9369527101516724
Validation loss: 2.1210228701432547

Epoch: 244| Step: 0
Training loss: 2.626772165298462
Validation loss: 2.126719464858373

Epoch: 5| Step: 1
Training loss: 1.6157032251358032
Validation loss: 2.134121840198835

Epoch: 5| Step: 2
Training loss: 1.6357921361923218
Validation loss: 2.1180114150047302

Epoch: 5| Step: 3
Training loss: 1.9564049243927002
Validation loss: 2.097422738869985

Epoch: 5| Step: 4
Training loss: 1.6388561725616455
Validation loss: 2.105959638953209

Epoch: 5| Step: 5
Training loss: 1.7052710056304932
Validation loss: 2.112820809086164

Epoch: 5| Step: 6
Training loss: 2.1739373207092285
Validation loss: 2.1142839739720025

Epoch: 5| Step: 7
Training loss: 1.7625318765640259
Validation loss: 2.1183997839689255

Epoch: 5| Step: 8
Training loss: 2.081784248352051
Validation loss: 2.091777409116427

Epoch: 5| Step: 9
Training loss: 1.9769887924194336
Validation loss: 2.1076901952425637

Epoch: 5| Step: 10
Training loss: 2.1692731380462646
Validation loss: 2.1047692944606147

Epoch: 5| Step: 11
Training loss: 1.2254040241241455
Validation loss: 2.123399391770363

Epoch: 245| Step: 0
Training loss: 1.684273362159729
Validation loss: 2.115751773118973

Epoch: 5| Step: 1
Training loss: 1.4534332752227783
Validation loss: 2.1180184135834375

Epoch: 5| Step: 2
Training loss: 1.9982578754425049
Validation loss: 2.1130461394786835

Epoch: 5| Step: 3
Training loss: 1.9998258352279663
Validation loss: 2.1174856424331665

Epoch: 5| Step: 4
Training loss: 1.8215125799179077
Validation loss: 2.122340902686119

Epoch: 5| Step: 5
Training loss: 1.5357718467712402
Validation loss: 2.134987701972326

Epoch: 5| Step: 6
Training loss: 1.8670680522918701
Validation loss: 2.1507966617743173

Epoch: 5| Step: 7
Training loss: 1.9156078100204468
Validation loss: 2.1573324352502823

Epoch: 5| Step: 8
Training loss: 2.2166106700897217
Validation loss: 2.165981635451317

Epoch: 5| Step: 9
Training loss: 2.4208452701568604
Validation loss: 2.15423276523749

Epoch: 5| Step: 10
Training loss: 2.128812074661255
Validation loss: 2.1739638447761536

Epoch: 5| Step: 11
Training loss: 3.3892722129821777
Validation loss: 2.187478964527448

Epoch: 246| Step: 0
Training loss: 2.1467456817626953
Validation loss: 2.1693433970212936

Epoch: 5| Step: 1
Training loss: 1.6087391376495361
Validation loss: 2.2013617058595023

Epoch: 5| Step: 2
Training loss: 1.9340829849243164
Validation loss: 2.174867123365402

Epoch: 5| Step: 3
Training loss: 2.0348057746887207
Validation loss: 2.162970617413521

Epoch: 5| Step: 4
Training loss: 1.3731070756912231
Validation loss: 2.145191585024198

Epoch: 5| Step: 5
Training loss: 1.7884066104888916
Validation loss: 2.1569480995337167

Epoch: 5| Step: 6
Training loss: 2.148273468017578
Validation loss: 2.12410676976045

Epoch: 5| Step: 7
Training loss: 1.8412742614746094
Validation loss: 2.1102589716513953

Epoch: 5| Step: 8
Training loss: 2.1289570331573486
Validation loss: 2.126720150311788

Epoch: 5| Step: 9
Training loss: 1.581873893737793
Validation loss: 2.136112486322721

Epoch: 5| Step: 10
Training loss: 2.3366358280181885
Validation loss: 2.113625004887581

Epoch: 5| Step: 11
Training loss: 2.4566056728363037
Validation loss: 2.122284750143687

Epoch: 247| Step: 0
Training loss: 2.6278300285339355
Validation loss: 2.1268918911616006

Epoch: 5| Step: 1
Training loss: 1.5366322994232178
Validation loss: 2.1068492283423743

Epoch: 5| Step: 2
Training loss: 1.3080939054489136
Validation loss: 2.1085450500249863

Epoch: 5| Step: 3
Training loss: 1.7105228900909424
Validation loss: 2.119056314229965

Epoch: 5| Step: 4
Training loss: 1.964555025100708
Validation loss: 2.1100939164559045

Epoch: 5| Step: 5
Training loss: 1.9598448276519775
Validation loss: 2.1197215418020883

Epoch: 5| Step: 6
Training loss: 2.345496654510498
Validation loss: 2.116205647587776

Epoch: 5| Step: 7
Training loss: 2.1156153678894043
Validation loss: 2.1269281456867852

Epoch: 5| Step: 8
Training loss: 1.6720504760742188
Validation loss: 2.136660764614741

Epoch: 5| Step: 9
Training loss: 1.8600826263427734
Validation loss: 2.139977698524793

Epoch: 5| Step: 10
Training loss: 1.6679069995880127
Validation loss: 2.1468273450930915

Epoch: 5| Step: 11
Training loss: 2.8407673835754395
Validation loss: 2.149647523959478

Epoch: 248| Step: 0
Training loss: 1.8178176879882812
Validation loss: 2.148081734776497

Epoch: 5| Step: 1
Training loss: 2.016245126724243
Validation loss: 2.156254584590594

Epoch: 5| Step: 2
Training loss: 1.2620939016342163
Validation loss: 2.163784941037496

Epoch: 5| Step: 3
Training loss: 2.368318796157837
Validation loss: 2.145637924472491

Epoch: 5| Step: 4
Training loss: 1.9115031957626343
Validation loss: 2.154071415464083

Epoch: 5| Step: 5
Training loss: 1.571531057357788
Validation loss: 2.1333135267098746

Epoch: 5| Step: 6
Training loss: 1.8489147424697876
Validation loss: 2.1376876135667167

Epoch: 5| Step: 7
Training loss: 1.6154648065567017
Validation loss: 2.130142410596212

Epoch: 5| Step: 8
Training loss: 2.603712797164917
Validation loss: 2.120336964726448

Epoch: 5| Step: 9
Training loss: 2.097740411758423
Validation loss: 2.124765415986379

Epoch: 5| Step: 10
Training loss: 2.1214957237243652
Validation loss: 2.128608852624893

Epoch: 5| Step: 11
Training loss: 1.2629318237304688
Validation loss: 2.147126426299413

Epoch: 249| Step: 0
Training loss: 2.016923189163208
Validation loss: 2.1374671012163162

Epoch: 5| Step: 1
Training loss: 1.6528667211532593
Validation loss: 2.138483688235283

Epoch: 5| Step: 2
Training loss: 2.1380302906036377
Validation loss: 2.1380821466445923

Epoch: 5| Step: 3
Training loss: 1.7726719379425049
Validation loss: 2.1253052353858948

Epoch: 5| Step: 4
Training loss: 2.3891525268554688
Validation loss: 2.166427363952001

Epoch: 5| Step: 5
Training loss: 1.6455615758895874
Validation loss: 2.165560101469358

Epoch: 5| Step: 6
Training loss: 1.5111843347549438
Validation loss: 2.166967233022054

Epoch: 5| Step: 7
Training loss: 1.90750253200531
Validation loss: 2.166299675901731

Epoch: 5| Step: 8
Training loss: 2.082479953765869
Validation loss: 2.1759868065516152

Epoch: 5| Step: 9
Training loss: 1.7981510162353516
Validation loss: 2.1736924052238464

Epoch: 5| Step: 10
Training loss: 2.1310372352600098
Validation loss: 2.1651059687137604

Epoch: 5| Step: 11
Training loss: 2.6306142807006836
Validation loss: 2.1735174506902695

Epoch: 250| Step: 0
Training loss: 2.249802589416504
Validation loss: 2.175133357445399

Epoch: 5| Step: 1
Training loss: 1.9329429864883423
Validation loss: 2.161301761865616

Epoch: 5| Step: 2
Training loss: 1.5136638879776
Validation loss: 2.147833635409673

Epoch: 5| Step: 3
Training loss: 1.8679683208465576
Validation loss: 2.13694237669309

Epoch: 5| Step: 4
Training loss: 1.5697705745697021
Validation loss: 2.1225220461686454

Epoch: 5| Step: 5
Training loss: 1.5067890882492065
Validation loss: 2.136633798480034

Epoch: 5| Step: 6
Training loss: 2.0270230770111084
Validation loss: 2.1370075891415277

Epoch: 5| Step: 7
Training loss: 2.44543719291687
Validation loss: 2.15690016746521

Epoch: 5| Step: 8
Training loss: 1.8594977855682373
Validation loss: 2.158418213327726

Epoch: 5| Step: 9
Training loss: 2.4285778999328613
Validation loss: 2.1585905104875565

Epoch: 5| Step: 10
Training loss: 1.5618311166763306
Validation loss: 2.140594800313314

Epoch: 5| Step: 11
Training loss: 1.7919927835464478
Validation loss: 2.1554845670859017

Epoch: 251| Step: 0
Training loss: 2.1284563541412354
Validation loss: 2.1389933923880258

Epoch: 5| Step: 1
Training loss: 1.9216833114624023
Validation loss: 2.1327191491921744

Epoch: 5| Step: 2
Training loss: 1.9123684167861938
Validation loss: 2.1098775267601013

Epoch: 5| Step: 3
Training loss: 1.8794113397598267
Validation loss: 2.118250926335653

Epoch: 5| Step: 4
Training loss: 2.143401622772217
Validation loss: 2.1189386496941247

Epoch: 5| Step: 5
Training loss: 1.498896598815918
Validation loss: 2.1284490128358207

Epoch: 5| Step: 6
Training loss: 1.6752588748931885
Validation loss: 2.1308538764715195

Epoch: 5| Step: 7
Training loss: 2.1558680534362793
Validation loss: 2.1345139940579734

Epoch: 5| Step: 8
Training loss: 1.5517812967300415
Validation loss: 2.128798951705297

Epoch: 5| Step: 9
Training loss: 2.1305181980133057
Validation loss: 2.133567919333776

Epoch: 5| Step: 10
Training loss: 1.7868897914886475
Validation loss: 2.161837190389633

Epoch: 5| Step: 11
Training loss: 2.4068691730499268
Validation loss: 2.165120700995127

Epoch: 252| Step: 0
Training loss: 1.489671230316162
Validation loss: 2.176995654900869

Epoch: 5| Step: 1
Training loss: 1.6150767803192139
Validation loss: 2.17718776067098

Epoch: 5| Step: 2
Training loss: 1.931626558303833
Validation loss: 2.1851072957118354

Epoch: 5| Step: 3
Training loss: 2.148404598236084
Validation loss: 2.184734880924225

Epoch: 5| Step: 4
Training loss: 1.7850663661956787
Validation loss: 2.1743810872236886

Epoch: 5| Step: 5
Training loss: 2.1487300395965576
Validation loss: 2.1622976114352546

Epoch: 5| Step: 6
Training loss: 1.6887327432632446
Validation loss: 2.14577283958594

Epoch: 5| Step: 7
Training loss: 2.409868001937866
Validation loss: 2.1281071652968726

Epoch: 5| Step: 8
Training loss: 1.4301058053970337
Validation loss: 2.1298257410526276

Epoch: 5| Step: 9
Training loss: 2.1738052368164062
Validation loss: 2.132213200132052

Epoch: 5| Step: 10
Training loss: 2.0048091411590576
Validation loss: 2.1151446302731833

Epoch: 5| Step: 11
Training loss: 2.7809247970581055
Validation loss: 2.1282164057095847

Epoch: 253| Step: 0
Training loss: 2.3654892444610596
Validation loss: 2.1418004631996155

Epoch: 5| Step: 1
Training loss: 1.7653071880340576
Validation loss: 2.129796658953031

Epoch: 5| Step: 2
Training loss: 1.8939144611358643
Validation loss: 2.1453055888414383

Epoch: 5| Step: 3
Training loss: 2.085421323776245
Validation loss: 2.1383181114991507

Epoch: 5| Step: 4
Training loss: 1.7307679653167725
Validation loss: 2.1508193065722785

Epoch: 5| Step: 5
Training loss: 2.1016440391540527
Validation loss: 2.1673994263013205

Epoch: 5| Step: 6
Training loss: 1.7021633386611938
Validation loss: 2.148969958225886

Epoch: 5| Step: 7
Training loss: 1.6966040134429932
Validation loss: 2.156295428673426

Epoch: 5| Step: 8
Training loss: 2.0306050777435303
Validation loss: 2.162284935514132

Epoch: 5| Step: 9
Training loss: 1.8940982818603516
Validation loss: 2.1732703348000846

Epoch: 5| Step: 10
Training loss: 1.632973074913025
Validation loss: 2.162632097800573

Epoch: 5| Step: 11
Training loss: 1.9696565866470337
Validation loss: 2.160222684343656

Epoch: 254| Step: 0
Training loss: 1.8906599283218384
Validation loss: 2.1459525376558304

Epoch: 5| Step: 1
Training loss: 1.9316648244857788
Validation loss: 2.1438641945521035

Epoch: 5| Step: 2
Training loss: 2.1764121055603027
Validation loss: 2.1419422725836434

Epoch: 5| Step: 3
Training loss: 2.059725284576416
Validation loss: 2.160672187805176

Epoch: 5| Step: 4
Training loss: 1.323547124862671
Validation loss: 2.1616367548704147

Epoch: 5| Step: 5
Training loss: 2.4703526496887207
Validation loss: 2.1566090981165567

Epoch: 5| Step: 6
Training loss: 1.7146832942962646
Validation loss: 2.1551423420508704

Epoch: 5| Step: 7
Training loss: 1.9274358749389648
Validation loss: 2.15425676604112

Epoch: 5| Step: 8
Training loss: 2.0431530475616455
Validation loss: 2.143705223997434

Epoch: 5| Step: 9
Training loss: 1.2421283721923828
Validation loss: 2.148095707098643

Epoch: 5| Step: 10
Training loss: 1.9116628170013428
Validation loss: 2.157325491309166

Epoch: 5| Step: 11
Training loss: 1.5148590803146362
Validation loss: 2.162562221288681

Epoch: 255| Step: 0
Training loss: 2.197923183441162
Validation loss: 2.1652331749598184

Epoch: 5| Step: 1
Training loss: 1.9838491678237915
Validation loss: 2.180391733845075

Epoch: 5| Step: 2
Training loss: 1.5726745128631592
Validation loss: 2.1868862410386405

Epoch: 5| Step: 3
Training loss: 2.2009196281433105
Validation loss: 2.2116896907488504

Epoch: 5| Step: 4
Training loss: 2.1495959758758545
Validation loss: 2.184138004978498

Epoch: 5| Step: 5
Training loss: 1.991299033164978
Validation loss: 2.1823853254318237

Epoch: 5| Step: 6
Training loss: 1.382936716079712
Validation loss: 2.1847742795944214

Epoch: 5| Step: 7
Training loss: 1.7250124216079712
Validation loss: 2.1759014626344046

Epoch: 5| Step: 8
Training loss: 2.4907803535461426
Validation loss: 2.1548405289649963

Epoch: 5| Step: 9
Training loss: 2.2093958854675293
Validation loss: 2.1461044351259866

Epoch: 5| Step: 10
Training loss: 1.651732087135315
Validation loss: 2.1441765079895654

Epoch: 5| Step: 11
Training loss: 0.5112796425819397
Validation loss: 2.1344112555185952

Epoch: 256| Step: 0
Training loss: 1.9588569402694702
Validation loss: 2.152651901046435

Epoch: 5| Step: 1
Training loss: 2.2836780548095703
Validation loss: 2.146010458469391

Epoch: 5| Step: 2
Training loss: 1.9722856283187866
Validation loss: 2.163000633319219

Epoch: 5| Step: 3
Training loss: 1.3454567193984985
Validation loss: 2.1598129669825235

Epoch: 5| Step: 4
Training loss: 2.533175230026245
Validation loss: 2.1520294845104218

Epoch: 5| Step: 5
Training loss: 1.862497329711914
Validation loss: 2.1610911985238395

Epoch: 5| Step: 6
Training loss: 1.7861964702606201
Validation loss: 2.149532655874888

Epoch: 5| Step: 7
Training loss: 2.202749729156494
Validation loss: 2.1657234927018485

Epoch: 5| Step: 8
Training loss: 1.5096054077148438
Validation loss: 2.1676056385040283

Epoch: 5| Step: 9
Training loss: 1.5979723930358887
Validation loss: 2.1720365484555564

Epoch: 5| Step: 10
Training loss: 1.541243553161621
Validation loss: 2.187547897299131

Epoch: 5| Step: 11
Training loss: 2.529086112976074
Validation loss: 2.191665396094322

Epoch: 257| Step: 0
Training loss: 1.797406792640686
Validation loss: 2.1949173907438913

Epoch: 5| Step: 1
Training loss: 1.4943466186523438
Validation loss: 2.158396159609159

Epoch: 5| Step: 2
Training loss: 1.6234813928604126
Validation loss: 2.155108710130056

Epoch: 5| Step: 3
Training loss: 2.0196824073791504
Validation loss: 2.1564588050047555

Epoch: 5| Step: 4
Training loss: 1.587468147277832
Validation loss: 2.1478457351525626

Epoch: 5| Step: 5
Training loss: 2.3757565021514893
Validation loss: 2.14188622434934

Epoch: 5| Step: 6
Training loss: 2.120635509490967
Validation loss: 2.1436089177926383

Epoch: 5| Step: 7
Training loss: 2.242269992828369
Validation loss: 2.1272906213998795

Epoch: 5| Step: 8
Training loss: 1.4938424825668335
Validation loss: 2.1323036899169288

Epoch: 5| Step: 9
Training loss: 1.3570377826690674
Validation loss: 2.142631396651268

Epoch: 5| Step: 10
Training loss: 2.5296452045440674
Validation loss: 2.1776436070601144

Epoch: 5| Step: 11
Training loss: 2.0277371406555176
Validation loss: 2.1568703055381775

Epoch: 258| Step: 0
Training loss: 1.9826698303222656
Validation loss: 2.180595909555753

Epoch: 5| Step: 1
Training loss: 2.3235011100769043
Validation loss: 2.2119622826576233

Epoch: 5| Step: 2
Training loss: 1.4416234493255615
Validation loss: 2.182237575451533

Epoch: 5| Step: 3
Training loss: 1.7800624370574951
Validation loss: 2.211785227060318

Epoch: 5| Step: 4
Training loss: 2.0002388954162598
Validation loss: 2.205042853951454

Epoch: 5| Step: 5
Training loss: 2.235426425933838
Validation loss: 2.1864508936802545

Epoch: 5| Step: 6
Training loss: 2.0235650539398193
Validation loss: 2.2018529723087945

Epoch: 5| Step: 7
Training loss: 1.560924768447876
Validation loss: 2.193019777536392

Epoch: 5| Step: 8
Training loss: 1.6441978216171265
Validation loss: 2.175770471493403

Epoch: 5| Step: 9
Training loss: 1.349352240562439
Validation loss: 2.1650454998016357

Epoch: 5| Step: 10
Training loss: 2.1780078411102295
Validation loss: 2.1531162907679877

Epoch: 5| Step: 11
Training loss: 2.429973602294922
Validation loss: 2.131964589158694

Epoch: 259| Step: 0
Training loss: 2.2307639122009277
Validation loss: 2.1217270294825235

Epoch: 5| Step: 1
Training loss: 1.6544939279556274
Validation loss: 2.1054026732842126

Epoch: 5| Step: 2
Training loss: 1.7598037719726562
Validation loss: 2.1158333321412406

Epoch: 5| Step: 3
Training loss: 1.2532708644866943
Validation loss: 2.0903427799542746

Epoch: 5| Step: 4
Training loss: 1.483597755432129
Validation loss: 2.0964690943559012

Epoch: 5| Step: 5
Training loss: 1.842627763748169
Validation loss: 2.1067436138788858

Epoch: 5| Step: 6
Training loss: 2.043389081954956
Validation loss: 2.1242001255353293

Epoch: 5| Step: 7
Training loss: 1.7542167901992798
Validation loss: 2.1180781523386636

Epoch: 5| Step: 8
Training loss: 2.6697018146514893
Validation loss: 2.139551490545273

Epoch: 5| Step: 9
Training loss: 2.210683822631836
Validation loss: 2.132407863934835

Epoch: 5| Step: 10
Training loss: 2.3795878887176514
Validation loss: 2.140502701203028

Epoch: 5| Step: 11
Training loss: 1.9799387454986572
Validation loss: 2.1585292319456735

Epoch: 260| Step: 0
Training loss: 2.485525131225586
Validation loss: 2.1917438258727393

Epoch: 5| Step: 1
Training loss: 1.775770902633667
Validation loss: 2.187683825691541

Epoch: 5| Step: 2
Training loss: 2.3455400466918945
Validation loss: 2.219141185283661

Epoch: 5| Step: 3
Training loss: 2.21942400932312
Validation loss: 2.2081348647673926

Epoch: 5| Step: 4
Training loss: 2.4441335201263428
Validation loss: 2.1791784365971885

Epoch: 5| Step: 5
Training loss: 1.6982738971710205
Validation loss: 2.1598778665065765

Epoch: 5| Step: 6
Training loss: 1.9741815328598022
Validation loss: 2.1765055457750955

Epoch: 5| Step: 7
Training loss: 1.87654709815979
Validation loss: 2.1723605394363403

Epoch: 5| Step: 8
Training loss: 1.718065857887268
Validation loss: 2.176477442185084

Epoch: 5| Step: 9
Training loss: 1.791847586631775
Validation loss: 2.142344430088997

Epoch: 5| Step: 10
Training loss: 1.775346040725708
Validation loss: 2.118122781316439

Epoch: 5| Step: 11
Training loss: 2.448141098022461
Validation loss: 2.107984110713005

Epoch: 261| Step: 0
Training loss: 2.0493004322052
Validation loss: 2.0967907160520554

Epoch: 5| Step: 1
Training loss: 2.24748158454895
Validation loss: 2.0883426566918692

Epoch: 5| Step: 2
Training loss: 2.0365867614746094
Validation loss: 2.096609488129616

Epoch: 5| Step: 3
Training loss: 1.7521337270736694
Validation loss: 2.096747969587644

Epoch: 5| Step: 4
Training loss: 1.8603652715682983
Validation loss: 2.0951334138711295

Epoch: 5| Step: 5
Training loss: 1.765259027481079
Validation loss: 2.0938061326742172

Epoch: 5| Step: 6
Training loss: 2.2339532375335693
Validation loss: 2.1033567637205124

Epoch: 5| Step: 7
Training loss: 2.0271427631378174
Validation loss: 2.101733555396398

Epoch: 5| Step: 8
Training loss: 1.4091174602508545
Validation loss: 2.0941882828871408

Epoch: 5| Step: 9
Training loss: 2.64504337310791
Validation loss: 2.1018800934155784

Epoch: 5| Step: 10
Training loss: 1.8184798955917358
Validation loss: 2.103904585043589

Epoch: 5| Step: 11
Training loss: 2.444690227508545
Validation loss: 2.126480758190155

Epoch: 262| Step: 0
Training loss: 2.017421245574951
Validation loss: 2.1222358644008636

Epoch: 5| Step: 1
Training loss: 1.8487682342529297
Validation loss: 2.140865077575048

Epoch: 5| Step: 2
Training loss: 2.407259464263916
Validation loss: 2.165627896785736

Epoch: 5| Step: 3
Training loss: 1.6205828189849854
Validation loss: 2.194593091805776

Epoch: 5| Step: 4
Training loss: 1.7221046686172485
Validation loss: 2.17761900027593

Epoch: 5| Step: 5
Training loss: 2.2756619453430176
Validation loss: 2.1792365660270057

Epoch: 5| Step: 6
Training loss: 2.025237560272217
Validation loss: 2.1931066314379373

Epoch: 5| Step: 7
Training loss: 1.514228343963623
Validation loss: 2.1953605314095817

Epoch: 5| Step: 8
Training loss: 2.7030527591705322
Validation loss: 2.1890059461196265

Epoch: 5| Step: 9
Training loss: 1.8614275455474854
Validation loss: 2.1772500971953073

Epoch: 5| Step: 10
Training loss: 1.6845849752426147
Validation loss: 2.159050236145655

Epoch: 5| Step: 11
Training loss: 1.53018057346344
Validation loss: 2.1546909709771476

Epoch: 263| Step: 0
Training loss: 1.523345947265625
Validation loss: 2.1483292629321418

Epoch: 5| Step: 1
Training loss: 1.7856245040893555
Validation loss: 2.139140317837397

Epoch: 5| Step: 2
Training loss: 2.442866086959839
Validation loss: 2.137106160322825

Epoch: 5| Step: 3
Training loss: 1.9923086166381836
Validation loss: 2.13638503352801

Epoch: 5| Step: 4
Training loss: 1.8862247467041016
Validation loss: 2.1520164807637534

Epoch: 5| Step: 5
Training loss: 1.8449327945709229
Validation loss: 2.147077575325966

Epoch: 5| Step: 6
Training loss: 1.7295423746109009
Validation loss: 2.1374063342809677

Epoch: 5| Step: 7
Training loss: 2.7615065574645996
Validation loss: 2.1327477544546127

Epoch: 5| Step: 8
Training loss: 1.5152647495269775
Validation loss: 2.150225023428599

Epoch: 5| Step: 9
Training loss: 1.7222083806991577
Validation loss: 2.1522596577803292

Epoch: 5| Step: 10
Training loss: 1.5085278749465942
Validation loss: 2.160206437110901

Epoch: 5| Step: 11
Training loss: 3.377908229827881
Validation loss: 2.162913034359614

Epoch: 264| Step: 0
Training loss: 2.0210347175598145
Validation loss: 2.1635975937048593

Epoch: 5| Step: 1
Training loss: 1.7395827770233154
Validation loss: 2.164396201570829

Epoch: 5| Step: 2
Training loss: 1.8470185995101929
Validation loss: 2.1725624402364097

Epoch: 5| Step: 3
Training loss: 1.947718858718872
Validation loss: 2.1644972612460456

Epoch: 5| Step: 4
Training loss: 1.4813683032989502
Validation loss: 2.1648855954408646

Epoch: 5| Step: 5
Training loss: 2.107945442199707
Validation loss: 2.1571367581685386

Epoch: 5| Step: 6
Training loss: 1.4718347787857056
Validation loss: 2.1541121502717337

Epoch: 5| Step: 7
Training loss: 2.2949929237365723
Validation loss: 2.1694583942492804

Epoch: 5| Step: 8
Training loss: 1.7712005376815796
Validation loss: 2.177923063437144

Epoch: 5| Step: 9
Training loss: 1.6610743999481201
Validation loss: 2.161730726559957

Epoch: 5| Step: 10
Training loss: 2.0940253734588623
Validation loss: 2.15189461906751

Epoch: 5| Step: 11
Training loss: 1.496803879737854
Validation loss: 2.174071033795675

Epoch: 265| Step: 0
Training loss: 1.5400214195251465
Validation loss: 2.1685454895099006

Epoch: 5| Step: 1
Training loss: 1.7235348224639893
Validation loss: 2.1594636936982474

Epoch: 5| Step: 2
Training loss: 2.003962516784668
Validation loss: 2.1350778490304947

Epoch: 5| Step: 3
Training loss: 1.5697413682937622
Validation loss: 2.1615388890107474

Epoch: 5| Step: 4
Training loss: 2.4984891414642334
Validation loss: 2.188271035750707

Epoch: 5| Step: 5
Training loss: 1.9174236059188843
Validation loss: 2.1828995247681937

Epoch: 5| Step: 6
Training loss: 1.5623700618743896
Validation loss: 2.177041451136271

Epoch: 5| Step: 7
Training loss: 2.0274205207824707
Validation loss: 2.1633740762869516

Epoch: 5| Step: 8
Training loss: 1.897133469581604
Validation loss: 2.1651694079240165

Epoch: 5| Step: 9
Training loss: 1.678450345993042
Validation loss: 2.1620802879333496

Epoch: 5| Step: 10
Training loss: 1.5948067903518677
Validation loss: 2.1552619437376657

Epoch: 5| Step: 11
Training loss: 4.546120643615723
Validation loss: 2.1533828675746918

Epoch: 266| Step: 0
Training loss: 1.5131146907806396
Validation loss: 2.1439641813437142

Epoch: 5| Step: 1
Training loss: 1.9047186374664307
Validation loss: 2.1507738878329596

Epoch: 5| Step: 2
Training loss: 2.4204530715942383
Validation loss: 2.1935523599386215

Epoch: 5| Step: 3
Training loss: 1.6689674854278564
Validation loss: 2.1702686647574105

Epoch: 5| Step: 4
Training loss: 2.244255781173706
Validation loss: 2.1851917107899985

Epoch: 5| Step: 5
Training loss: 1.3414061069488525
Validation loss: 2.1913031190633774

Epoch: 5| Step: 6
Training loss: 1.8234617710113525
Validation loss: 2.189164310693741

Epoch: 5| Step: 7
Training loss: 1.9131447076797485
Validation loss: 2.17105961839358

Epoch: 5| Step: 8
Training loss: 1.6683403253555298
Validation loss: 2.1877409716447196

Epoch: 5| Step: 9
Training loss: 1.8927528858184814
Validation loss: 2.16028094291687

Epoch: 5| Step: 10
Training loss: 2.052088975906372
Validation loss: 2.157192354400953

Epoch: 5| Step: 11
Training loss: 3.2224607467651367
Validation loss: 2.126786376039187

Epoch: 267| Step: 0
Training loss: 2.5051417350769043
Validation loss: 2.1487426459789276

Epoch: 5| Step: 1
Training loss: 1.3565205335617065
Validation loss: 2.129118099808693

Epoch: 5| Step: 2
Training loss: 2.1429378986358643
Validation loss: 2.1413314590851464

Epoch: 5| Step: 3
Training loss: 1.9078776836395264
Validation loss: 2.1514176627000174

Epoch: 5| Step: 4
Training loss: 1.8898122310638428
Validation loss: 2.15791192650795

Epoch: 5| Step: 5
Training loss: 1.6607370376586914
Validation loss: 2.1455516070127487

Epoch: 5| Step: 6
Training loss: 2.54024338722229
Validation loss: 2.166259005665779

Epoch: 5| Step: 7
Training loss: 1.7208032608032227
Validation loss: 2.166876753171285

Epoch: 5| Step: 8
Training loss: 1.723449468612671
Validation loss: 2.1787615617116294

Epoch: 5| Step: 9
Training loss: 1.338049054145813
Validation loss: 2.169471502304077

Epoch: 5| Step: 10
Training loss: 1.8628215789794922
Validation loss: 2.1517987151940665

Epoch: 5| Step: 11
Training loss: 2.2967512607574463
Validation loss: 2.162501265605291

Epoch: 268| Step: 0
Training loss: 1.6712534427642822
Validation loss: 2.1647024850050607

Epoch: 5| Step: 1
Training loss: 2.151752233505249
Validation loss: 2.185463716586431

Epoch: 5| Step: 2
Training loss: 1.7274258136749268
Validation loss: 2.1712442388137183

Epoch: 5| Step: 3
Training loss: 1.179758071899414
Validation loss: 2.1640653908252716

Epoch: 5| Step: 4
Training loss: 2.1670339107513428
Validation loss: 2.1696928342183432

Epoch: 5| Step: 5
Training loss: 2.203418254852295
Validation loss: 2.1670758624871573

Epoch: 5| Step: 6
Training loss: 2.326112747192383
Validation loss: 2.163992484410604

Epoch: 5| Step: 7
Training loss: 2.0029115676879883
Validation loss: 2.1522531658411026

Epoch: 5| Step: 8
Training loss: 1.7514623403549194
Validation loss: 2.1566383639971414

Epoch: 5| Step: 9
Training loss: 1.6809114217758179
Validation loss: 2.1784000595410666

Epoch: 5| Step: 10
Training loss: 1.6810001134872437
Validation loss: 2.171923741698265

Epoch: 5| Step: 11
Training loss: 1.4684557914733887
Validation loss: 2.1777721643447876

Epoch: 269| Step: 0
Training loss: 2.195234537124634
Validation loss: 2.170499250292778

Epoch: 5| Step: 1
Training loss: 2.622004747390747
Validation loss: 2.166015317042669

Epoch: 5| Step: 2
Training loss: 1.5697988271713257
Validation loss: 2.1698687374591827

Epoch: 5| Step: 3
Training loss: 1.558519959449768
Validation loss: 2.169782112042109

Epoch: 5| Step: 4
Training loss: 2.5479817390441895
Validation loss: 2.169278174638748

Epoch: 5| Step: 5
Training loss: 1.7680267095565796
Validation loss: 2.1610419849554696

Epoch: 5| Step: 6
Training loss: 1.348637580871582
Validation loss: 2.1873386402924857

Epoch: 5| Step: 7
Training loss: 1.5986707210540771
Validation loss: 2.1737928092479706

Epoch: 5| Step: 8
Training loss: 1.8904746770858765
Validation loss: 2.1734723846117654

Epoch: 5| Step: 9
Training loss: 1.450117826461792
Validation loss: 2.180526832739512

Epoch: 5| Step: 10
Training loss: 1.7272450923919678
Validation loss: 2.1705979307492576

Epoch: 5| Step: 11
Training loss: 3.127748489379883
Validation loss: 2.166884198784828

Epoch: 270| Step: 0
Training loss: 1.4018644094467163
Validation loss: 2.186096409956614

Epoch: 5| Step: 1
Training loss: 1.9481223821640015
Validation loss: 2.1667585720618567

Epoch: 5| Step: 2
Training loss: 1.718404769897461
Validation loss: 2.182588746150335

Epoch: 5| Step: 3
Training loss: 1.9545978307724
Validation loss: 2.1734897096951804

Epoch: 5| Step: 4
Training loss: 1.7643041610717773
Validation loss: 2.191436434785525

Epoch: 5| Step: 5
Training loss: 2.230874538421631
Validation loss: 2.1739397644996643

Epoch: 5| Step: 6
Training loss: 2.109550952911377
Validation loss: 2.1710735658804574

Epoch: 5| Step: 7
Training loss: 1.7881317138671875
Validation loss: 2.186247314016024

Epoch: 5| Step: 8
Training loss: 1.863659143447876
Validation loss: 2.180310303966204

Epoch: 5| Step: 9
Training loss: 1.5400607585906982
Validation loss: 2.195223018527031

Epoch: 5| Step: 10
Training loss: 2.213268756866455
Validation loss: 2.182958553234736

Epoch: 5| Step: 11
Training loss: 1.9900590181350708
Validation loss: 2.1757469226916633

Epoch: 271| Step: 0
Training loss: 1.9991134405136108
Validation loss: 2.161502093076706

Epoch: 5| Step: 1
Training loss: 1.811274528503418
Validation loss: 2.1795284350713096

Epoch: 5| Step: 2
Training loss: 2.0825703144073486
Validation loss: 2.183118308583895

Epoch: 5| Step: 3
Training loss: 1.3789646625518799
Validation loss: 2.1906018952528634

Epoch: 5| Step: 4
Training loss: 2.3632969856262207
Validation loss: 2.1980688273906708

Epoch: 5| Step: 5
Training loss: 1.9543466567993164
Validation loss: 2.166116327047348

Epoch: 5| Step: 6
Training loss: 1.5181010961532593
Validation loss: 2.187975953022639

Epoch: 5| Step: 7
Training loss: 1.9611880779266357
Validation loss: 2.1841776768366494

Epoch: 5| Step: 8
Training loss: 1.6482913494110107
Validation loss: 2.193764701485634

Epoch: 5| Step: 9
Training loss: 1.7206344604492188
Validation loss: 2.193230797847112

Epoch: 5| Step: 10
Training loss: 2.1309971809387207
Validation loss: 2.18950092792511

Epoch: 5| Step: 11
Training loss: 1.6054151058197021
Validation loss: 2.1737829049428306

Epoch: 272| Step: 0
Training loss: 1.3527824878692627
Validation loss: 2.1917053113381066

Epoch: 5| Step: 1
Training loss: 2.837273120880127
Validation loss: 2.1889727463324866

Epoch: 5| Step: 2
Training loss: 1.2937859296798706
Validation loss: 2.1752348790566125

Epoch: 5| Step: 3
Training loss: 2.025219440460205
Validation loss: 2.1613000681002936

Epoch: 5| Step: 4
Training loss: 1.6698795557022095
Validation loss: 2.177059163649877

Epoch: 5| Step: 5
Training loss: 1.7154000997543335
Validation loss: 2.1741514652967453

Epoch: 5| Step: 6
Training loss: 1.7992550134658813
Validation loss: 2.1799808591604233

Epoch: 5| Step: 7
Training loss: 1.997145652770996
Validation loss: 2.1795412997404733

Epoch: 5| Step: 8
Training loss: 1.8170245885849
Validation loss: 2.1808049182097116

Epoch: 5| Step: 9
Training loss: 1.8380225896835327
Validation loss: 2.1697464237610498

Epoch: 5| Step: 10
Training loss: 2.0174388885498047
Validation loss: 2.1637477030356727

Epoch: 5| Step: 11
Training loss: 1.569505214691162
Validation loss: 2.166212817033132

Epoch: 273| Step: 0
Training loss: 1.7334938049316406
Validation loss: 2.153779457012812

Epoch: 5| Step: 1
Training loss: 1.2741339206695557
Validation loss: 2.137244621912638

Epoch: 5| Step: 2
Training loss: 2.0280914306640625
Validation loss: 2.1285858501990638

Epoch: 5| Step: 3
Training loss: 1.6661796569824219
Validation loss: 2.133427565296491

Epoch: 5| Step: 4
Training loss: 2.212501049041748
Validation loss: 2.1425545314947763

Epoch: 5| Step: 5
Training loss: 2.2071399688720703
Validation loss: 2.1212122291326523

Epoch: 5| Step: 6
Training loss: 1.7684574127197266
Validation loss: 2.1292608032623925

Epoch: 5| Step: 7
Training loss: 2.1320159435272217
Validation loss: 2.1407966216405234

Epoch: 5| Step: 8
Training loss: 2.072187900543213
Validation loss: 2.1616635670264563

Epoch: 5| Step: 9
Training loss: 1.6513086557388306
Validation loss: 2.138282150030136

Epoch: 5| Step: 10
Training loss: 2.1508171558380127
Validation loss: 2.1640715301036835

Epoch: 5| Step: 11
Training loss: 1.1500370502471924
Validation loss: 2.161573847134908

Epoch: 274| Step: 0
Training loss: 1.6193549633026123
Validation loss: 2.1982034345467887

Epoch: 5| Step: 1
Training loss: 1.5291087627410889
Validation loss: 2.184756616751353

Epoch: 5| Step: 2
Training loss: 1.58012056350708
Validation loss: 2.183124303817749

Epoch: 5| Step: 3
Training loss: 1.406846284866333
Validation loss: 2.1868257224559784

Epoch: 5| Step: 4
Training loss: 2.2774243354797363
Validation loss: 2.1579417437314987

Epoch: 5| Step: 5
Training loss: 2.3999171257019043
Validation loss: 2.168902183572451

Epoch: 5| Step: 6
Training loss: 1.76177179813385
Validation loss: 2.161772444844246

Epoch: 5| Step: 7
Training loss: 1.941139578819275
Validation loss: 2.1540502409140267

Epoch: 5| Step: 8
Training loss: 2.487339973449707
Validation loss: 2.1694915195306144

Epoch: 5| Step: 9
Training loss: 1.620225191116333
Validation loss: 2.166323885321617

Epoch: 5| Step: 10
Training loss: 1.6780979633331299
Validation loss: 2.1855306774377823

Epoch: 5| Step: 11
Training loss: 1.3251014947891235
Validation loss: 2.1744822760423026

Epoch: 275| Step: 0
Training loss: 1.4299790859222412
Validation loss: 2.182912607987722

Epoch: 5| Step: 1
Training loss: 1.9353630542755127
Validation loss: 2.175611744324366

Epoch: 5| Step: 2
Training loss: 1.578674554824829
Validation loss: 2.160641814271609

Epoch: 5| Step: 3
Training loss: 2.1159603595733643
Validation loss: 2.1513754228750863

Epoch: 5| Step: 4
Training loss: 2.686832904815674
Validation loss: 2.143582344055176

Epoch: 5| Step: 5
Training loss: 1.679693579673767
Validation loss: 2.163267364104589

Epoch: 5| Step: 6
Training loss: 1.4664350748062134
Validation loss: 2.1631327470143638

Epoch: 5| Step: 7
Training loss: 2.122295379638672
Validation loss: 2.183203846216202

Epoch: 5| Step: 8
Training loss: 1.260099172592163
Validation loss: 2.1846698820590973

Epoch: 5| Step: 9
Training loss: 1.7871100902557373
Validation loss: 2.209616223971049

Epoch: 5| Step: 10
Training loss: 2.4802889823913574
Validation loss: 2.2198235591252646

Epoch: 5| Step: 11
Training loss: 1.5722824335098267
Validation loss: 2.23012346525987

Epoch: 276| Step: 0
Training loss: 1.9654204845428467
Validation loss: 2.2033075441916785

Epoch: 5| Step: 1
Training loss: 1.5239002704620361
Validation loss: 2.179886907339096

Epoch: 5| Step: 2
Training loss: 1.9805552959442139
Validation loss: 2.191265275080999

Epoch: 5| Step: 3
Training loss: 1.6855287551879883
Validation loss: 2.1803743292888007

Epoch: 5| Step: 4
Training loss: 1.7229276895523071
Validation loss: 2.1746675074100494

Epoch: 5| Step: 5
Training loss: 2.1411969661712646
Validation loss: 2.156665692726771

Epoch: 5| Step: 6
Training loss: 2.1415889263153076
Validation loss: 2.1548271725575128

Epoch: 5| Step: 7
Training loss: 2.065887928009033
Validation loss: 2.1606865525245667

Epoch: 5| Step: 8
Training loss: 1.4070534706115723
Validation loss: 2.16668638586998

Epoch: 5| Step: 9
Training loss: 2.164153814315796
Validation loss: 2.1755606283744178

Epoch: 5| Step: 10
Training loss: 1.6489238739013672
Validation loss: 2.1691353221734366

Epoch: 5| Step: 11
Training loss: 2.378232955932617
Validation loss: 2.1562422613302865

Epoch: 277| Step: 0
Training loss: 1.9421991109848022
Validation loss: 2.1817340900500617

Epoch: 5| Step: 1
Training loss: 1.8881666660308838
Validation loss: 2.199847603837649

Epoch: 5| Step: 2
Training loss: 1.9787509441375732
Validation loss: 2.196577399969101

Epoch: 5| Step: 3
Training loss: 1.8523772954940796
Validation loss: 2.181999256213506

Epoch: 5| Step: 4
Training loss: 1.9145939350128174
Validation loss: 2.175564775864283

Epoch: 5| Step: 5
Training loss: 1.9220720529556274
Validation loss: 2.1874578843514123

Epoch: 5| Step: 6
Training loss: 2.055041551589966
Validation loss: 2.198157787322998

Epoch: 5| Step: 7
Training loss: 1.5833561420440674
Validation loss: 2.200660983721415

Epoch: 5| Step: 8
Training loss: 1.606872797012329
Validation loss: 2.188284014662107

Epoch: 5| Step: 9
Training loss: 1.9135751724243164
Validation loss: 2.175381620724996

Epoch: 5| Step: 10
Training loss: 1.8057575225830078
Validation loss: 2.183259611328443

Epoch: 5| Step: 11
Training loss: 1.4715244770050049
Validation loss: 2.1633345782756805

Epoch: 278| Step: 0
Training loss: 2.7015037536621094
Validation loss: 2.1592992146809897

Epoch: 5| Step: 1
Training loss: 1.1937663555145264
Validation loss: 2.1580350597699485

Epoch: 5| Step: 2
Training loss: 2.6571645736694336
Validation loss: 2.1498922407627106

Epoch: 5| Step: 3
Training loss: 1.8278827667236328
Validation loss: 2.147206981976827

Epoch: 5| Step: 4
Training loss: 1.5805652141571045
Validation loss: 2.1257120619217553

Epoch: 5| Step: 5
Training loss: 2.477055072784424
Validation loss: 2.147096132238706

Epoch: 5| Step: 6
Training loss: 1.3160200119018555
Validation loss: 2.1356515139341354

Epoch: 5| Step: 7
Training loss: 1.8247238397598267
Validation loss: 2.151369959115982

Epoch: 5| Step: 8
Training loss: 1.8540699481964111
Validation loss: 2.155846839149793

Epoch: 5| Step: 9
Training loss: 1.5640695095062256
Validation loss: 2.172129491964976

Epoch: 5| Step: 10
Training loss: 1.7237005233764648
Validation loss: 2.186352496345838

Epoch: 5| Step: 11
Training loss: 1.1768269538879395
Validation loss: 2.172603741288185

Epoch: 279| Step: 0
Training loss: 1.8758859634399414
Validation loss: 2.175277625521024

Epoch: 5| Step: 1
Training loss: 1.417462944984436
Validation loss: 2.1792950530846915

Epoch: 5| Step: 2
Training loss: 1.6175765991210938
Validation loss: 2.1727937857309976

Epoch: 5| Step: 3
Training loss: 2.2546749114990234
Validation loss: 2.1802374720573425

Epoch: 5| Step: 4
Training loss: 1.9065940380096436
Validation loss: 2.170553425947825

Epoch: 5| Step: 5
Training loss: 1.5232511758804321
Validation loss: 2.1729726791381836

Epoch: 5| Step: 6
Training loss: 1.981631875038147
Validation loss: 2.1712204217910767

Epoch: 5| Step: 7
Training loss: 1.9678856134414673
Validation loss: 2.166646659374237

Epoch: 5| Step: 8
Training loss: 1.886045217514038
Validation loss: 2.1968610286712646

Epoch: 5| Step: 9
Training loss: 1.6108894348144531
Validation loss: 2.200444986422857

Epoch: 5| Step: 10
Training loss: 2.1629137992858887
Validation loss: 2.1910833219687142

Epoch: 5| Step: 11
Training loss: 0.9049339294433594
Validation loss: 2.180968850851059

Epoch: 280| Step: 0
Training loss: 2.5623526573181152
Validation loss: 2.2031246721744537

Epoch: 5| Step: 1
Training loss: 2.0418288707733154
Validation loss: 2.2147752344608307

Epoch: 5| Step: 2
Training loss: 1.6617717742919922
Validation loss: 2.2172031750281653

Epoch: 5| Step: 3
Training loss: 1.790387511253357
Validation loss: 2.2259696374336877

Epoch: 5| Step: 4
Training loss: 1.7170226573944092
Validation loss: 2.2204928398132324

Epoch: 5| Step: 5
Training loss: 1.8764318227767944
Validation loss: 2.2214014530181885

Epoch: 5| Step: 6
Training loss: 1.6051533222198486
Validation loss: 2.192957118153572

Epoch: 5| Step: 7
Training loss: 1.9154739379882812
Validation loss: 2.20469964047273

Epoch: 5| Step: 8
Training loss: 1.5194091796875
Validation loss: 2.193127304315567

Epoch: 5| Step: 9
Training loss: 1.4854352474212646
Validation loss: 2.1753130902846656

Epoch: 5| Step: 10
Training loss: 2.2315714359283447
Validation loss: 2.163123314579328

Epoch: 5| Step: 11
Training loss: 2.89099383354187
Validation loss: 2.1446700245141983

Epoch: 281| Step: 0
Training loss: 2.1666178703308105
Validation loss: 2.1401447057724

Epoch: 5| Step: 1
Training loss: 1.529787540435791
Validation loss: 2.1404751539230347

Epoch: 5| Step: 2
Training loss: 2.4082727432250977
Validation loss: 2.1176718870798745

Epoch: 5| Step: 3
Training loss: 2.1276695728302
Validation loss: 2.1279675662517548

Epoch: 5| Step: 4
Training loss: 1.6181488037109375
Validation loss: 2.1239745765924454

Epoch: 5| Step: 5
Training loss: 1.8342065811157227
Validation loss: 2.1165180057287216

Epoch: 5| Step: 6
Training loss: 1.7807594537734985
Validation loss: 2.1148413121700287

Epoch: 5| Step: 7
Training loss: 1.7199541330337524
Validation loss: 2.1100452542304993

Epoch: 5| Step: 8
Training loss: 1.7392752170562744
Validation loss: 2.122100775440534

Epoch: 5| Step: 9
Training loss: 1.951629638671875
Validation loss: 2.127709671854973

Epoch: 5| Step: 10
Training loss: 2.3463549613952637
Validation loss: 2.126066416501999

Epoch: 5| Step: 11
Training loss: 1.2361624240875244
Validation loss: 2.1097282618284225

Epoch: 282| Step: 0
Training loss: 2.7352356910705566
Validation loss: 2.1515725404024124

Epoch: 5| Step: 1
Training loss: 1.6113440990447998
Validation loss: 2.1918534636497498

Epoch: 5| Step: 2
Training loss: 2.214197874069214
Validation loss: 2.1709832151730857

Epoch: 5| Step: 3
Training loss: 2.5304219722747803
Validation loss: 2.1619391640027366

Epoch: 5| Step: 4
Training loss: 2.446244955062866
Validation loss: 2.1565778255462646

Epoch: 5| Step: 5
Training loss: 1.5878016948699951
Validation loss: 2.1504525194565454

Epoch: 5| Step: 6
Training loss: 1.72036874294281
Validation loss: 2.1529258141915

Epoch: 5| Step: 7
Training loss: 1.9982668161392212
Validation loss: 2.1638785849014917

Epoch: 5| Step: 8
Training loss: 1.674343466758728
Validation loss: 2.16883019109567

Epoch: 5| Step: 9
Training loss: 1.2469340562820435
Validation loss: 2.1707298954327903

Epoch: 5| Step: 10
Training loss: 1.590140700340271
Validation loss: 2.161513770620028

Epoch: 5| Step: 11
Training loss: 2.654449939727783
Validation loss: 2.154719586173693

Epoch: 283| Step: 0
Training loss: 2.6423346996307373
Validation loss: 2.152630180120468

Epoch: 5| Step: 1
Training loss: 2.2069735527038574
Validation loss: 2.1407343596220016

Epoch: 5| Step: 2
Training loss: 1.5571385622024536
Validation loss: 2.130669186512629

Epoch: 5| Step: 3
Training loss: 2.1004045009613037
Validation loss: 2.124660938978195

Epoch: 5| Step: 4
Training loss: 1.7537673711776733
Validation loss: 2.120416651169459

Epoch: 5| Step: 5
Training loss: 1.3374454975128174
Validation loss: 2.1389968444903693

Epoch: 5| Step: 6
Training loss: 1.7539275884628296
Validation loss: 2.1535040785868964

Epoch: 5| Step: 7
Training loss: 2.4282479286193848
Validation loss: 2.152092605829239

Epoch: 5| Step: 8
Training loss: 1.7514355182647705
Validation loss: 2.177121455470721

Epoch: 5| Step: 9
Training loss: 1.684326410293579
Validation loss: 2.196354866027832

Epoch: 5| Step: 10
Training loss: 1.339847207069397
Validation loss: 2.184138392408689

Epoch: 5| Step: 11
Training loss: 2.2532403469085693
Validation loss: 2.2040468653043113

Epoch: 284| Step: 0
Training loss: 1.9758479595184326
Validation loss: 2.1999252835909524

Epoch: 5| Step: 1
Training loss: 1.4913476705551147
Validation loss: 2.1890789369742074

Epoch: 5| Step: 2
Training loss: 2.115652084350586
Validation loss: 2.180917883912722

Epoch: 5| Step: 3
Training loss: 1.6071335077285767
Validation loss: 2.1733245700597763

Epoch: 5| Step: 4
Training loss: 1.4884169101715088
Validation loss: 2.1826191743214927

Epoch: 5| Step: 5
Training loss: 1.6708968877792358
Validation loss: 2.164965038498243

Epoch: 5| Step: 6
Training loss: 1.863896369934082
Validation loss: 2.168606534600258

Epoch: 5| Step: 7
Training loss: 1.5652095079421997
Validation loss: 2.1825527946154275

Epoch: 5| Step: 8
Training loss: 1.944133996963501
Validation loss: 2.1817704091469445

Epoch: 5| Step: 9
Training loss: 2.076953649520874
Validation loss: 2.186974361538887

Epoch: 5| Step: 10
Training loss: 2.26825213432312
Validation loss: 2.1953435639540353

Epoch: 5| Step: 11
Training loss: 2.48415470123291
Validation loss: 2.164544274409612

Epoch: 285| Step: 0
Training loss: 1.9284826517105103
Validation loss: 2.174998258550962

Epoch: 5| Step: 1
Training loss: 1.990566611289978
Validation loss: 2.150319923957189

Epoch: 5| Step: 2
Training loss: 1.4453117847442627
Validation loss: 2.153068487842878

Epoch: 5| Step: 3
Training loss: 1.3644295930862427
Validation loss: 2.1569161216417947

Epoch: 5| Step: 4
Training loss: 1.7371171712875366
Validation loss: 2.152383973201116

Epoch: 5| Step: 5
Training loss: 2.03908634185791
Validation loss: 2.155145605405172

Epoch: 5| Step: 6
Training loss: 2.1383087635040283
Validation loss: 2.1527810295422873

Epoch: 5| Step: 7
Training loss: 1.8798736333847046
Validation loss: 2.151986077427864

Epoch: 5| Step: 8
Training loss: 1.8536732196807861
Validation loss: 2.177908182144165

Epoch: 5| Step: 9
Training loss: 2.062143325805664
Validation loss: 2.16756534576416

Epoch: 5| Step: 10
Training loss: 1.9274780750274658
Validation loss: 2.169154634078344

Epoch: 5| Step: 11
Training loss: 1.3946369886398315
Validation loss: 2.1569621711969376

Epoch: 286| Step: 0
Training loss: 1.531415581703186
Validation loss: 2.1637379924456277

Epoch: 5| Step: 1
Training loss: 2.05279541015625
Validation loss: 2.153264597058296

Epoch: 5| Step: 2
Training loss: 2.2875359058380127
Validation loss: 2.1683157235383987

Epoch: 5| Step: 3
Training loss: 1.5592408180236816
Validation loss: 2.1663992355267205

Epoch: 5| Step: 4
Training loss: 1.7889182567596436
Validation loss: 2.1760452489058175

Epoch: 5| Step: 5
Training loss: 2.209656238555908
Validation loss: 2.1686462809642157

Epoch: 5| Step: 6
Training loss: 1.9262031316757202
Validation loss: 2.1683524549007416

Epoch: 5| Step: 7
Training loss: 1.8947893381118774
Validation loss: 2.185029129187266

Epoch: 5| Step: 8
Training loss: 1.6597267389297485
Validation loss: 2.177143231034279

Epoch: 5| Step: 9
Training loss: 1.6107782125473022
Validation loss: 2.189132278164228

Epoch: 5| Step: 10
Training loss: 1.5760564804077148
Validation loss: 2.198979447285334

Epoch: 5| Step: 11
Training loss: 1.9924726486206055
Validation loss: 2.2142698665459952

Epoch: 287| Step: 0
Training loss: 1.3830817937850952
Validation loss: 2.216810161868731

Epoch: 5| Step: 1
Training loss: 1.919440507888794
Validation loss: 2.2169811725616455

Epoch: 5| Step: 2
Training loss: 1.6733306646347046
Validation loss: 2.2064266999562583

Epoch: 5| Step: 3
Training loss: 1.7437174320220947
Validation loss: 2.1991675098737082

Epoch: 5| Step: 4
Training loss: 1.5536632537841797
Validation loss: 2.2259250382582345

Epoch: 5| Step: 5
Training loss: 1.7069847583770752
Validation loss: 2.1981297781070075

Epoch: 5| Step: 6
Training loss: 1.6369283199310303
Validation loss: 2.1875703086455665

Epoch: 5| Step: 7
Training loss: 1.856792688369751
Validation loss: 2.1838071395953498

Epoch: 5| Step: 8
Training loss: 2.1437830924987793
Validation loss: 2.1838773985703788

Epoch: 5| Step: 9
Training loss: 1.9283552169799805
Validation loss: 2.173029914498329

Epoch: 5| Step: 10
Training loss: 2.40456223487854
Validation loss: 2.18943560620149

Epoch: 5| Step: 11
Training loss: 3.672985792160034
Validation loss: 2.174715146422386

Epoch: 288| Step: 0
Training loss: 1.3550288677215576
Validation loss: 2.1711028118928275

Epoch: 5| Step: 1
Training loss: 2.4197452068328857
Validation loss: 2.1717025488615036

Epoch: 5| Step: 2
Training loss: 1.546627402305603
Validation loss: 2.170795271794001

Epoch: 5| Step: 3
Training loss: 2.6545472145080566
Validation loss: 2.157570794224739

Epoch: 5| Step: 4
Training loss: 1.7325146198272705
Validation loss: 2.177635525663694

Epoch: 5| Step: 5
Training loss: 2.173513889312744
Validation loss: 2.161968102057775

Epoch: 5| Step: 6
Training loss: 1.7623844146728516
Validation loss: 2.1745438476403556

Epoch: 5| Step: 7
Training loss: 1.5807467699050903
Validation loss: 2.188357934355736

Epoch: 5| Step: 8
Training loss: 1.5585559606552124
Validation loss: 2.1984767417112985

Epoch: 5| Step: 9
Training loss: 1.6775310039520264
Validation loss: 2.1933229863643646

Epoch: 5| Step: 10
Training loss: 1.6921237707138062
Validation loss: 2.180367191632589

Epoch: 5| Step: 11
Training loss: 1.9097241163253784
Validation loss: 2.2094386518001556

Epoch: 289| Step: 0
Training loss: 1.9149610996246338
Validation loss: 2.206535925467809

Epoch: 5| Step: 1
Training loss: 1.9743821620941162
Validation loss: 2.1932039906581244

Epoch: 5| Step: 2
Training loss: 1.4861294031143188
Validation loss: 2.195187951127688

Epoch: 5| Step: 3
Training loss: 1.592560887336731
Validation loss: 2.2113349636395774

Epoch: 5| Step: 4
Training loss: 1.471130132675171
Validation loss: 2.188209036986033

Epoch: 5| Step: 5
Training loss: 1.556941270828247
Validation loss: 2.2069894274075827

Epoch: 5| Step: 6
Training loss: 1.926153540611267
Validation loss: 2.1883539110422134

Epoch: 5| Step: 7
Training loss: 2.2784628868103027
Validation loss: 2.194175327817599

Epoch: 5| Step: 8
Training loss: 1.6942390203475952
Validation loss: 2.172664244969686

Epoch: 5| Step: 9
Training loss: 2.183006763458252
Validation loss: 2.1769143442312875

Epoch: 5| Step: 10
Training loss: 2.012843608856201
Validation loss: 2.151882375280062

Epoch: 5| Step: 11
Training loss: 1.7023407220840454
Validation loss: 2.1793180654446282

Epoch: 290| Step: 0
Training loss: 1.9326350688934326
Validation loss: 2.1554461469252906

Epoch: 5| Step: 1
Training loss: 1.5374387502670288
Validation loss: 2.1480789184570312

Epoch: 5| Step: 2
Training loss: 1.7302955389022827
Validation loss: 2.1295013378063836

Epoch: 5| Step: 3
Training loss: 1.3907479047775269
Validation loss: 2.1459903170665107

Epoch: 5| Step: 4
Training loss: 1.6957868337631226
Validation loss: 2.1388447483380637

Epoch: 5| Step: 5
Training loss: 1.985247015953064
Validation loss: 2.160265545050303

Epoch: 5| Step: 6
Training loss: 2.240140438079834
Validation loss: 2.179244264960289

Epoch: 5| Step: 7
Training loss: 1.7044979333877563
Validation loss: 2.203162690003713

Epoch: 5| Step: 8
Training loss: 2.084601640701294
Validation loss: 2.2082225928703942

Epoch: 5| Step: 9
Training loss: 1.7214778661727905
Validation loss: 2.2174301594495773

Epoch: 5| Step: 10
Training loss: 2.0658771991729736
Validation loss: 2.2338256935278573

Epoch: 5| Step: 11
Training loss: 2.475226640701294
Validation loss: 2.2107786188522973

Epoch: 291| Step: 0
Training loss: 1.7317100763320923
Validation loss: 2.2204209019740424

Epoch: 5| Step: 1
Training loss: 2.487539768218994
Validation loss: 2.2024438877900443

Epoch: 5| Step: 2
Training loss: 2.3387815952301025
Validation loss: 2.2099612702926

Epoch: 5| Step: 3
Training loss: 1.881937026977539
Validation loss: 2.2011267791191735

Epoch: 5| Step: 4
Training loss: 1.5804880857467651
Validation loss: 2.2051515678564706

Epoch: 5| Step: 5
Training loss: 1.8270902633666992
Validation loss: 2.2060256898403168

Epoch: 5| Step: 6
Training loss: 1.424729347229004
Validation loss: 2.208214079340299

Epoch: 5| Step: 7
Training loss: 1.460707664489746
Validation loss: 2.200800657272339

Epoch: 5| Step: 8
Training loss: 1.7570667266845703
Validation loss: 2.1884465167919793

Epoch: 5| Step: 9
Training loss: 1.525669813156128
Validation loss: 2.189774304628372

Epoch: 5| Step: 10
Training loss: 2.140620708465576
Validation loss: 2.1910060991843543

Epoch: 5| Step: 11
Training loss: 0.9558472633361816
Validation loss: 2.2071963250637054

Epoch: 292| Step: 0
Training loss: 1.6368987560272217
Validation loss: 2.182160178820292

Epoch: 5| Step: 1
Training loss: 1.9631439447402954
Validation loss: 2.2055331071217856

Epoch: 5| Step: 2
Training loss: 1.9436943531036377
Validation loss: 2.1931008199850717

Epoch: 5| Step: 3
Training loss: 1.4526680707931519
Validation loss: 2.208765208721161

Epoch: 5| Step: 4
Training loss: 1.4945738315582275
Validation loss: 2.194319119056066

Epoch: 5| Step: 5
Training loss: 1.903946876525879
Validation loss: 2.19562720755736

Epoch: 5| Step: 6
Training loss: 1.365749716758728
Validation loss: 2.175434331099192

Epoch: 5| Step: 7
Training loss: 2.828451633453369
Validation loss: 2.1909483671188354

Epoch: 5| Step: 8
Training loss: 1.7938060760498047
Validation loss: 2.1789442151784897

Epoch: 5| Step: 9
Training loss: 1.7887935638427734
Validation loss: 2.168219526608785

Epoch: 5| Step: 10
Training loss: 2.28248929977417
Validation loss: 2.1700331221024194

Epoch: 5| Step: 11
Training loss: 1.813921570777893
Validation loss: 2.134484519561132

Epoch: 293| Step: 0
Training loss: 1.4413866996765137
Validation loss: 2.136128584543864

Epoch: 5| Step: 1
Training loss: 2.1034507751464844
Validation loss: 2.1571504026651382

Epoch: 5| Step: 2
Training loss: 1.5266691446304321
Validation loss: 2.142978618542353

Epoch: 5| Step: 3
Training loss: 2.5289852619171143
Validation loss: 2.161093900601069

Epoch: 5| Step: 4
Training loss: 1.8281183242797852
Validation loss: 2.1562039454778037

Epoch: 5| Step: 5
Training loss: 1.9385331869125366
Validation loss: 2.154784694314003

Epoch: 5| Step: 6
Training loss: 1.6683361530303955
Validation loss: 2.1679928253094354

Epoch: 5| Step: 7
Training loss: 1.7008832693099976
Validation loss: 2.170325184861819

Epoch: 5| Step: 8
Training loss: 1.5246315002441406
Validation loss: 2.163960794607798

Epoch: 5| Step: 9
Training loss: 2.0136730670928955
Validation loss: 2.183598756790161

Epoch: 5| Step: 10
Training loss: 2.087242603302002
Validation loss: 2.215921406944593

Epoch: 5| Step: 11
Training loss: 1.5352352857589722
Validation loss: 2.2318093677361808

Epoch: 294| Step: 0
Training loss: 2.450561761856079
Validation loss: 2.1905294557412467

Epoch: 5| Step: 1
Training loss: 1.8905178308486938
Validation loss: 2.2179858485857644

Epoch: 5| Step: 2
Training loss: 2.1624364852905273
Validation loss: 2.2077910900115967

Epoch: 5| Step: 3
Training loss: 1.8088634014129639
Validation loss: 2.193637321392695

Epoch: 5| Step: 4
Training loss: 1.6550114154815674
Validation loss: 2.1950176805257797

Epoch: 5| Step: 5
Training loss: 1.7649977207183838
Validation loss: 2.192268878221512

Epoch: 5| Step: 6
Training loss: 1.4976962804794312
Validation loss: 2.1711313724517822

Epoch: 5| Step: 7
Training loss: 1.3303757905960083
Validation loss: 2.2197465548912683

Epoch: 5| Step: 8
Training loss: 2.1389832496643066
Validation loss: 2.187807152668635

Epoch: 5| Step: 9
Training loss: 1.773413896560669
Validation loss: 2.195930282274882

Epoch: 5| Step: 10
Training loss: 1.8306210041046143
Validation loss: 2.2136386036872864

Epoch: 5| Step: 11
Training loss: 1.2477726936340332
Validation loss: 2.2042777637640634

Epoch: 295| Step: 0
Training loss: 1.990661859512329
Validation loss: 2.199835608402888

Epoch: 5| Step: 1
Training loss: 2.090205669403076
Validation loss: 2.217249949773153

Epoch: 5| Step: 2
Training loss: 2.0867247581481934
Validation loss: 2.190378894408544

Epoch: 5| Step: 3
Training loss: 1.7741315364837646
Validation loss: 2.197290375828743

Epoch: 5| Step: 4
Training loss: 1.5937774181365967
Validation loss: 2.1774876763423285

Epoch: 5| Step: 5
Training loss: 2.0686817169189453
Validation loss: 2.1961213747660318

Epoch: 5| Step: 6
Training loss: 2.2857329845428467
Validation loss: 2.1732571870088577

Epoch: 5| Step: 7
Training loss: 1.2398993968963623
Validation loss: 2.1784349928299584

Epoch: 5| Step: 8
Training loss: 1.580268383026123
Validation loss: 2.2042529930671058

Epoch: 5| Step: 9
Training loss: 2.0431952476501465
Validation loss: 2.179329752922058

Epoch: 5| Step: 10
Training loss: 1.233213186264038
Validation loss: 2.1775635480880737

Epoch: 5| Step: 11
Training loss: 1.9058440923690796
Validation loss: 2.176674763361613

Epoch: 296| Step: 0
Training loss: 1.9219768047332764
Validation loss: 2.1758633255958557

Epoch: 5| Step: 1
Training loss: 1.7615957260131836
Validation loss: 2.165855790177981

Epoch: 5| Step: 2
Training loss: 2.3735711574554443
Validation loss: 2.1932923942804337

Epoch: 5| Step: 3
Training loss: 1.5663691759109497
Validation loss: 2.1755277713139853

Epoch: 5| Step: 4
Training loss: 1.6776702404022217
Validation loss: 2.1944827089707055

Epoch: 5| Step: 5
Training loss: 1.3598898649215698
Validation loss: 2.188753833373388

Epoch: 5| Step: 6
Training loss: 2.2389771938323975
Validation loss: 2.1647759477297464

Epoch: 5| Step: 7
Training loss: 1.9435932636260986
Validation loss: 2.161551465590795

Epoch: 5| Step: 8
Training loss: 1.6761878728866577
Validation loss: 2.1702301800251007

Epoch: 5| Step: 9
Training loss: 1.7562564611434937
Validation loss: 2.1812730679909387

Epoch: 5| Step: 10
Training loss: 1.3323472738265991
Validation loss: 2.184934059778849

Epoch: 5| Step: 11
Training loss: 3.8498029708862305
Validation loss: 2.171040107806524

Epoch: 297| Step: 0
Training loss: 1.8349225521087646
Validation loss: 2.172926257054011

Epoch: 5| Step: 1
Training loss: 2.1899099349975586
Validation loss: 2.176584998766581

Epoch: 5| Step: 2
Training loss: 1.876949667930603
Validation loss: 2.174430340528488

Epoch: 5| Step: 3
Training loss: 2.586289644241333
Validation loss: 2.166708548863729

Epoch: 5| Step: 4
Training loss: 1.8285757303237915
Validation loss: 2.1685970028241477

Epoch: 5| Step: 5
Training loss: 1.671964406967163
Validation loss: 2.176521271467209

Epoch: 5| Step: 6
Training loss: 1.3510429859161377
Validation loss: 2.1792884369691214

Epoch: 5| Step: 7
Training loss: 2.000864028930664
Validation loss: 2.18376724421978

Epoch: 5| Step: 8
Training loss: 1.358664870262146
Validation loss: 2.2030260264873505

Epoch: 5| Step: 9
Training loss: 1.5027285814285278
Validation loss: 2.174008866151174

Epoch: 5| Step: 10
Training loss: 1.824655532836914
Validation loss: 2.211262827118238

Epoch: 5| Step: 11
Training loss: 1.4281315803527832
Validation loss: 2.192035883665085

Epoch: 298| Step: 0
Training loss: 1.8386720418930054
Validation loss: 2.1952055593331656

Epoch: 5| Step: 1
Training loss: 1.6512359380722046
Validation loss: 2.196827789147695

Epoch: 5| Step: 2
Training loss: 2.4324843883514404
Validation loss: 2.1784293552239737

Epoch: 5| Step: 3
Training loss: 2.050609827041626
Validation loss: 2.1839776188135147

Epoch: 5| Step: 4
Training loss: 1.543785810470581
Validation loss: 2.1841422021389008

Epoch: 5| Step: 5
Training loss: 1.2040250301361084
Validation loss: 2.1867954234282174

Epoch: 5| Step: 6
Training loss: 1.4358316659927368
Validation loss: 2.1768481582403183

Epoch: 5| Step: 7
Training loss: 1.7411991357803345
Validation loss: 2.1987024446328483

Epoch: 5| Step: 8
Training loss: 2.626875400543213
Validation loss: 2.2240456342697144

Epoch: 5| Step: 9
Training loss: 1.6157697439193726
Validation loss: 2.2119358827670417

Epoch: 5| Step: 10
Training loss: 2.1302552223205566
Validation loss: 2.2313047647476196

Epoch: 5| Step: 11
Training loss: 1.5911033153533936
Validation loss: 2.2162066251039505

Epoch: 299| Step: 0
Training loss: 1.9729435443878174
Validation loss: 2.211412787437439

Epoch: 5| Step: 1
Training loss: 2.354997158050537
Validation loss: 2.2182909001906714

Epoch: 5| Step: 2
Training loss: 1.8583886623382568
Validation loss: 2.2377710143725076

Epoch: 5| Step: 3
Training loss: 1.7506622076034546
Validation loss: 2.2140555630127587

Epoch: 5| Step: 4
Training loss: 1.3849613666534424
Validation loss: 2.211924841006597

Epoch: 5| Step: 5
Training loss: 1.4805519580841064
Validation loss: 2.197860509157181

Epoch: 5| Step: 6
Training loss: 2.3677968978881836
Validation loss: 2.187146008014679

Epoch: 5| Step: 7
Training loss: 1.9949924945831299
Validation loss: 2.1832445164521537

Epoch: 5| Step: 8
Training loss: 1.6534483432769775
Validation loss: 2.1839969406525293

Epoch: 5| Step: 9
Training loss: 1.3954553604125977
Validation loss: 2.163632204135259

Epoch: 5| Step: 10
Training loss: 1.7402703762054443
Validation loss: 2.1752706368764243

Epoch: 5| Step: 11
Training loss: 1.3122990131378174
Validation loss: 2.1911083360513053

Epoch: 300| Step: 0
Training loss: 1.6861683130264282
Validation loss: 2.1875153084596

Epoch: 5| Step: 1
Training loss: 1.4885371923446655
Validation loss: 2.2205925782521567

Epoch: 5| Step: 2
Training loss: 2.183485507965088
Validation loss: 2.2218188444773355

Epoch: 5| Step: 3
Training loss: 1.908060073852539
Validation loss: 2.238942195971807

Epoch: 5| Step: 4
Training loss: 1.1822212934494019
Validation loss: 2.2200862218936286

Epoch: 5| Step: 5
Training loss: 1.4981575012207031
Validation loss: 2.226255103945732

Epoch: 5| Step: 6
Training loss: 2.100470781326294
Validation loss: 2.2072726289431253

Epoch: 5| Step: 7
Training loss: 2.262441873550415
Validation loss: 2.2114691535631814

Epoch: 5| Step: 8
Training loss: 2.0964157581329346
Validation loss: 2.2055128812789917

Epoch: 5| Step: 9
Training loss: 1.8054453134536743
Validation loss: 2.2035829971234002

Epoch: 5| Step: 10
Training loss: 1.5109751224517822
Validation loss: 2.2012352645397186

Epoch: 5| Step: 11
Training loss: 2.784327983856201
Validation loss: 2.196437790989876

Epoch: 301| Step: 0
Training loss: 1.8418552875518799
Validation loss: 2.1941991448402405

Epoch: 5| Step: 1
Training loss: 1.3396599292755127
Validation loss: 2.186627214153608

Epoch: 5| Step: 2
Training loss: 1.735025405883789
Validation loss: 2.1807881941397986

Epoch: 5| Step: 3
Training loss: 1.859309434890747
Validation loss: 2.1835816502571106

Epoch: 5| Step: 4
Training loss: 2.1246566772460938
Validation loss: 2.1760236620903015

Epoch: 5| Step: 5
Training loss: 2.0097310543060303
Validation loss: 2.1827469865481057

Epoch: 5| Step: 6
Training loss: 1.5525286197662354
Validation loss: 2.2024381260077157

Epoch: 5| Step: 7
Training loss: 1.3092321157455444
Validation loss: 2.1966918309529624

Epoch: 5| Step: 8
Training loss: 1.7508251667022705
Validation loss: 2.1896906048059464

Epoch: 5| Step: 9
Training loss: 2.2848849296569824
Validation loss: 2.17906824251016

Epoch: 5| Step: 10
Training loss: 1.9777196645736694
Validation loss: 2.1773345669110618

Epoch: 5| Step: 11
Training loss: 1.7300059795379639
Validation loss: 2.1808363795280457

Epoch: 302| Step: 0
Training loss: 1.7022138833999634
Validation loss: 2.1555628975232444

Epoch: 5| Step: 1
Training loss: 1.579433560371399
Validation loss: 2.180959105491638

Epoch: 5| Step: 2
Training loss: 1.8523170948028564
Validation loss: 2.1796089808146157

Epoch: 5| Step: 3
Training loss: 1.9787712097167969
Validation loss: 2.191432848572731

Epoch: 5| Step: 4
Training loss: 2.0366523265838623
Validation loss: 2.1953428387641907

Epoch: 5| Step: 5
Training loss: 1.8199020624160767
Validation loss: 2.1938888927300773

Epoch: 5| Step: 6
Training loss: 1.33663809299469
Validation loss: 2.1635690927505493

Epoch: 5| Step: 7
Training loss: 1.8073041439056396
Validation loss: 2.18218723932902

Epoch: 5| Step: 8
Training loss: 1.4507192373275757
Validation loss: 2.164798617362976

Epoch: 5| Step: 9
Training loss: 2.148066997528076
Validation loss: 2.187494069337845

Epoch: 5| Step: 10
Training loss: 2.0519471168518066
Validation loss: 2.200780466198921

Epoch: 5| Step: 11
Training loss: 1.343607783317566
Validation loss: 2.211288496851921

Epoch: 303| Step: 0
Training loss: 1.7806551456451416
Validation loss: 2.1748013297716775

Epoch: 5| Step: 1
Training loss: 1.4182087182998657
Validation loss: 2.17785507440567

Epoch: 5| Step: 2
Training loss: 2.057840347290039
Validation loss: 2.1937777400016785

Epoch: 5| Step: 3
Training loss: 1.5023198127746582
Validation loss: 2.192449539899826

Epoch: 5| Step: 4
Training loss: 2.0217316150665283
Validation loss: 2.1869318882624307

Epoch: 5| Step: 5
Training loss: 1.472904920578003
Validation loss: 2.1891865183909736

Epoch: 5| Step: 6
Training loss: 1.4642951488494873
Validation loss: 2.1972798804442086

Epoch: 5| Step: 7
Training loss: 2.2399489879608154
Validation loss: 2.2123724669218063

Epoch: 5| Step: 8
Training loss: 2.1958398818969727
Validation loss: 2.1880036195119223

Epoch: 5| Step: 9
Training loss: 1.5736024379730225
Validation loss: 2.199399029215177

Epoch: 5| Step: 10
Training loss: 2.1673882007598877
Validation loss: 2.1904972145954766

Epoch: 5| Step: 11
Training loss: 1.4927034378051758
Validation loss: 2.170914759238561

Epoch: 304| Step: 0
Training loss: 1.3272346258163452
Validation loss: 2.2203862220048904

Epoch: 5| Step: 1
Training loss: 1.5971838235855103
Validation loss: 2.192682772874832

Epoch: 5| Step: 2
Training loss: 2.0857138633728027
Validation loss: 2.2199796885252

Epoch: 5| Step: 3
Training loss: 1.7812057733535767
Validation loss: 2.2181748151779175

Epoch: 5| Step: 4
Training loss: 1.6459953784942627
Validation loss: 2.2351339558760324

Epoch: 5| Step: 5
Training loss: 1.837486982345581
Validation loss: 2.2478628208239875

Epoch: 5| Step: 6
Training loss: 1.8042404651641846
Validation loss: 2.264244814713796

Epoch: 5| Step: 7
Training loss: 2.063695192337036
Validation loss: 2.2409438490867615

Epoch: 5| Step: 8
Training loss: 1.626729965209961
Validation loss: 2.2481790482997894

Epoch: 5| Step: 9
Training loss: 1.72493577003479
Validation loss: 2.2350409428278604

Epoch: 5| Step: 10
Training loss: 2.2918930053710938
Validation loss: 2.2383808195590973

Epoch: 5| Step: 11
Training loss: 1.4355049133300781
Validation loss: 2.2375778754552207

Epoch: 305| Step: 0
Training loss: 1.5990068912506104
Validation loss: 2.179656242330869

Epoch: 5| Step: 1
Training loss: 1.4931474924087524
Validation loss: 2.2195391952991486

Epoch: 5| Step: 2
Training loss: 1.737436294555664
Validation loss: 2.203769957025846

Epoch: 5| Step: 3
Training loss: 1.199968934059143
Validation loss: 2.2076112776994705

Epoch: 5| Step: 4
Training loss: 1.4904592037200928
Validation loss: 2.2014692574739456

Epoch: 5| Step: 5
Training loss: 2.1824817657470703
Validation loss: 2.211050341526667

Epoch: 5| Step: 6
Training loss: 1.9768024682998657
Validation loss: 2.2286178320646286

Epoch: 5| Step: 7
Training loss: 1.4757273197174072
Validation loss: 2.2300767501195273

Epoch: 5| Step: 8
Training loss: 2.1270546913146973
Validation loss: 2.226742853720983

Epoch: 5| Step: 9
Training loss: 2.2305397987365723
Validation loss: 2.2067563434441886

Epoch: 5| Step: 10
Training loss: 2.354449510574341
Validation loss: 2.210434461633364

Epoch: 5| Step: 11
Training loss: 2.2438101768493652
Validation loss: 2.220193554957708

Epoch: 306| Step: 0
Training loss: 2.2047054767608643
Validation loss: 2.2167162696520486

Epoch: 5| Step: 1
Training loss: 2.0138754844665527
Validation loss: 2.213185022274653

Epoch: 5| Step: 2
Training loss: 1.2635071277618408
Validation loss: 2.212513968348503

Epoch: 5| Step: 3
Training loss: 1.3158496618270874
Validation loss: 2.1595645745595298

Epoch: 5| Step: 4
Training loss: 1.7887518405914307
Validation loss: 2.1881673634052277

Epoch: 5| Step: 5
Training loss: 2.099574327468872
Validation loss: 2.1630756755669913

Epoch: 5| Step: 6
Training loss: 1.3845974206924438
Validation loss: 2.178321619828542

Epoch: 5| Step: 7
Training loss: 2.103172779083252
Validation loss: 2.1903263131777444

Epoch: 5| Step: 8
Training loss: 1.7314109802246094
Validation loss: 2.2127130925655365

Epoch: 5| Step: 9
Training loss: 1.6329421997070312
Validation loss: 2.179718166589737

Epoch: 5| Step: 10
Training loss: 2.088726282119751
Validation loss: 2.199684982498487

Epoch: 5| Step: 11
Training loss: 1.2621722221374512
Validation loss: 2.17925717929999

Epoch: 307| Step: 0
Training loss: 1.6944682598114014
Validation loss: 2.2021076132853827

Epoch: 5| Step: 1
Training loss: 1.5017942190170288
Validation loss: 2.187118490537008

Epoch: 5| Step: 2
Training loss: 2.0099375247955322
Validation loss: 2.1978418231010437

Epoch: 5| Step: 3
Training loss: 1.8154096603393555
Validation loss: 2.193689967195193

Epoch: 5| Step: 4
Training loss: 1.8451573848724365
Validation loss: 2.215752194325129

Epoch: 5| Step: 5
Training loss: 2.156609296798706
Validation loss: 2.200824479262034

Epoch: 5| Step: 6
Training loss: 2.1112418174743652
Validation loss: 2.1848996182282767

Epoch: 5| Step: 7
Training loss: 1.846439003944397
Validation loss: 2.1919941306114197

Epoch: 5| Step: 8
Training loss: 1.7249343395233154
Validation loss: 2.1741484850645065

Epoch: 5| Step: 9
Training loss: 1.4067214727401733
Validation loss: 2.194925238688787

Epoch: 5| Step: 10
Training loss: 1.6811349391937256
Validation loss: 2.1859963039557138

Epoch: 5| Step: 11
Training loss: 1.3771443367004395
Validation loss: 2.1956096291542053

Epoch: 308| Step: 0
Training loss: 1.2369716167449951
Validation loss: 2.2018788854281106

Epoch: 5| Step: 1
Training loss: 1.8328357934951782
Validation loss: 2.1946243792772293

Epoch: 5| Step: 2
Training loss: 2.051957368850708
Validation loss: 2.1965449303388596

Epoch: 5| Step: 3
Training loss: 2.191880226135254
Validation loss: 2.1827737390995026

Epoch: 5| Step: 4
Training loss: 2.0502679347991943
Validation loss: 2.2115560521682105

Epoch: 5| Step: 5
Training loss: 1.9201328754425049
Validation loss: 2.216277062892914

Epoch: 5| Step: 6
Training loss: 1.5750455856323242
Validation loss: 2.201224038998286

Epoch: 5| Step: 7
Training loss: 1.2567031383514404
Validation loss: 2.22234038511912

Epoch: 5| Step: 8
Training loss: 1.3164746761322021
Validation loss: 2.2227243135372796

Epoch: 5| Step: 9
Training loss: 2.1999595165252686
Validation loss: 2.2194305658340454

Epoch: 5| Step: 10
Training loss: 1.6833655834197998
Validation loss: 2.18507319688797

Epoch: 5| Step: 11
Training loss: 3.227810859680176
Validation loss: 2.2162149101495743

Epoch: 309| Step: 0
Training loss: 1.8468393087387085
Validation loss: 2.2078441878159842

Epoch: 5| Step: 1
Training loss: 1.9453859329223633
Validation loss: 2.2138965676228204

Epoch: 5| Step: 2
Training loss: 1.461188554763794
Validation loss: 2.210527499516805

Epoch: 5| Step: 3
Training loss: 1.7566169500350952
Validation loss: 2.1935731371243796

Epoch: 5| Step: 4
Training loss: 1.8622987270355225
Validation loss: 2.181328773498535

Epoch: 5| Step: 5
Training loss: 1.556484580039978
Validation loss: 2.192202458779017

Epoch: 5| Step: 6
Training loss: 1.6408030986785889
Validation loss: 2.1907226592302322

Epoch: 5| Step: 7
Training loss: 1.7553291320800781
Validation loss: 2.201281284292539

Epoch: 5| Step: 8
Training loss: 1.8039476871490479
Validation loss: 2.179404159386953

Epoch: 5| Step: 9
Training loss: 2.4183778762817383
Validation loss: 2.166679799556732

Epoch: 5| Step: 10
Training loss: 2.062587022781372
Validation loss: 2.178376833597819

Epoch: 5| Step: 11
Training loss: 1.5154110193252563
Validation loss: 2.1833840558926263

Epoch: 310| Step: 0
Training loss: 2.2768592834472656
Validation loss: 2.226484020551046

Epoch: 5| Step: 1
Training loss: 1.3529348373413086
Validation loss: 2.220351740717888

Epoch: 5| Step: 2
Training loss: 1.9951374530792236
Validation loss: 2.2443088591098785

Epoch: 5| Step: 3
Training loss: 1.8823108673095703
Validation loss: 2.2289688487847648

Epoch: 5| Step: 4
Training loss: 1.305497407913208
Validation loss: 2.2233565598726273

Epoch: 5| Step: 5
Training loss: 1.3159949779510498
Validation loss: 2.2074884176254272

Epoch: 5| Step: 6
Training loss: 1.7955296039581299
Validation loss: 2.226985529065132

Epoch: 5| Step: 7
Training loss: 2.045398235321045
Validation loss: 2.200670758883158

Epoch: 5| Step: 8
Training loss: 2.1143054962158203
Validation loss: 2.1664370397726693

Epoch: 5| Step: 9
Training loss: 1.779544472694397
Validation loss: 2.191017523407936

Epoch: 5| Step: 10
Training loss: 2.093932628631592
Validation loss: 2.176974907517433

Epoch: 5| Step: 11
Training loss: 1.0158731937408447
Validation loss: 2.1743348439534507

Epoch: 311| Step: 0
Training loss: 1.3578777313232422
Validation loss: 2.1633841693401337

Epoch: 5| Step: 1
Training loss: 1.4304958581924438
Validation loss: 2.1735661725203195

Epoch: 5| Step: 2
Training loss: 1.6741441488265991
Validation loss: 2.151868005593618

Epoch: 5| Step: 3
Training loss: 1.5509459972381592
Validation loss: 2.1771699686845145

Epoch: 5| Step: 4
Training loss: 1.8670209646224976
Validation loss: 2.1869596242904663

Epoch: 5| Step: 5
Training loss: 1.9891083240509033
Validation loss: 2.1940694600343704

Epoch: 5| Step: 6
Training loss: 1.62594473361969
Validation loss: 2.201349357763926

Epoch: 5| Step: 7
Training loss: 2.606962203979492
Validation loss: 2.2137849628925323

Epoch: 5| Step: 8
Training loss: 2.2737629413604736
Validation loss: 2.1945412009954453

Epoch: 5| Step: 9
Training loss: 2.03688907623291
Validation loss: 2.2223194191853204

Epoch: 5| Step: 10
Training loss: 1.6556583642959595
Validation loss: 2.1897832105557122

Epoch: 5| Step: 11
Training loss: 0.6251826286315918
Validation loss: 2.207945038874944

Epoch: 312| Step: 0
Training loss: 2.0799832344055176
Validation loss: 2.2091475228468576

Epoch: 5| Step: 1
Training loss: 1.3489530086517334
Validation loss: 2.197629431883494

Epoch: 5| Step: 2
Training loss: 1.7402489185333252
Validation loss: 2.2064951161543527

Epoch: 5| Step: 3
Training loss: 2.3089230060577393
Validation loss: 2.219847892721494

Epoch: 5| Step: 4
Training loss: 1.9078667163848877
Validation loss: 2.2026411344607673

Epoch: 5| Step: 5
Training loss: 1.7422246932983398
Validation loss: 2.193252275387446

Epoch: 5| Step: 6
Training loss: 1.6222114562988281
Validation loss: 2.1754596730073295

Epoch: 5| Step: 7
Training loss: 1.7760674953460693
Validation loss: 2.1976435681184134

Epoch: 5| Step: 8
Training loss: 1.6998300552368164
Validation loss: 2.1866034666697183

Epoch: 5| Step: 9
Training loss: 1.6995630264282227
Validation loss: 2.175329566001892

Epoch: 5| Step: 10
Training loss: 2.703531265258789
Validation loss: 2.176386281847954

Epoch: 5| Step: 11
Training loss: 1.0742154121398926
Validation loss: 2.175873801112175

Epoch: 313| Step: 0
Training loss: 2.2634034156799316
Validation loss: 2.2021756370862327

Epoch: 5| Step: 1
Training loss: 1.448240041732788
Validation loss: 2.2057154178619385

Epoch: 5| Step: 2
Training loss: 1.855494737625122
Validation loss: 2.2124149054288864

Epoch: 5| Step: 3
Training loss: 2.0525972843170166
Validation loss: 2.2212001333634057

Epoch: 5| Step: 4
Training loss: 1.9287621974945068
Validation loss: 2.2144034107526145

Epoch: 5| Step: 5
Training loss: 1.9181098937988281
Validation loss: 2.2630547086397805

Epoch: 5| Step: 6
Training loss: 1.649876594543457
Validation loss: 2.2351890007654824

Epoch: 5| Step: 7
Training loss: 1.9875061511993408
Validation loss: 2.252558355530103

Epoch: 5| Step: 8
Training loss: 1.7210344076156616
Validation loss: 2.2514697362979255

Epoch: 5| Step: 9
Training loss: 1.9048702716827393
Validation loss: 2.2463579177856445

Epoch: 5| Step: 10
Training loss: 1.7348350286483765
Validation loss: 2.2333758970101676

Epoch: 5| Step: 11
Training loss: 1.467005968093872
Validation loss: 2.2224999169508615

Epoch: 314| Step: 0
Training loss: 1.4986064434051514
Validation loss: 2.222230404615402

Epoch: 5| Step: 1
Training loss: 1.4790608882904053
Validation loss: 2.211255098382632

Epoch: 5| Step: 2
Training loss: 1.3946539163589478
Validation loss: 2.2243186235427856

Epoch: 5| Step: 3
Training loss: 2.335296392440796
Validation loss: 2.2107427616914115

Epoch: 5| Step: 4
Training loss: 2.121288776397705
Validation loss: 2.207032690445582

Epoch: 5| Step: 5
Training loss: 2.1959125995635986
Validation loss: 2.2022437155246735

Epoch: 5| Step: 6
Training loss: 1.3098299503326416
Validation loss: 2.2262565990289054

Epoch: 5| Step: 7
Training loss: 2.232464075088501
Validation loss: 2.2270522316296897

Epoch: 5| Step: 8
Training loss: 1.9345862865447998
Validation loss: 2.191759377717972

Epoch: 5| Step: 9
Training loss: 1.9712022542953491
Validation loss: 2.222851792971293

Epoch: 5| Step: 10
Training loss: 1.5856618881225586
Validation loss: 2.222463140885035

Epoch: 5| Step: 11
Training loss: 0.7314664125442505
Validation loss: 2.2045571009318032

Epoch: 315| Step: 0
Training loss: 1.5389912128448486
Validation loss: 2.217697560787201

Epoch: 5| Step: 1
Training loss: 2.283234119415283
Validation loss: 2.2256947656472525

Epoch: 5| Step: 2
Training loss: 1.2769775390625
Validation loss: 2.2209632148345313

Epoch: 5| Step: 3
Training loss: 1.9472078084945679
Validation loss: 2.202619810899099

Epoch: 5| Step: 4
Training loss: 1.7247613668441772
Validation loss: 2.196987201770147

Epoch: 5| Step: 5
Training loss: 1.271958589553833
Validation loss: 2.2193368872006736

Epoch: 5| Step: 6
Training loss: 2.2465224266052246
Validation loss: 2.214101254940033

Epoch: 5| Step: 7
Training loss: 1.884698510169983
Validation loss: 2.1991494596004486

Epoch: 5| Step: 8
Training loss: 1.9265779256820679
Validation loss: 2.232601006825765

Epoch: 5| Step: 9
Training loss: 1.6470314264297485
Validation loss: 2.232221225897471

Epoch: 5| Step: 10
Training loss: 1.3784759044647217
Validation loss: 2.2360131988922753

Epoch: 5| Step: 11
Training loss: 3.2671267986297607
Validation loss: 2.2321027666330338

Epoch: 316| Step: 0
Training loss: 1.6538896560668945
Validation loss: 2.24568318327268

Epoch: 5| Step: 1
Training loss: 1.3610990047454834
Validation loss: 2.2326303521792092

Epoch: 5| Step: 2
Training loss: 2.1201090812683105
Validation loss: 2.2385642727216086

Epoch: 5| Step: 3
Training loss: 2.042978286743164
Validation loss: 2.220458154877027

Epoch: 5| Step: 4
Training loss: 1.757803201675415
Validation loss: 2.2262864212195077

Epoch: 5| Step: 5
Training loss: 1.3884391784667969
Validation loss: 2.222828487555186

Epoch: 5| Step: 6
Training loss: 1.925775170326233
Validation loss: 2.241136689980825

Epoch: 5| Step: 7
Training loss: 2.3569164276123047
Validation loss: 2.2171734670797982

Epoch: 5| Step: 8
Training loss: 1.735396146774292
Validation loss: 2.2276012102762857

Epoch: 5| Step: 9
Training loss: 1.4390164613723755
Validation loss: 2.2255706091721854

Epoch: 5| Step: 10
Training loss: 1.8656572103500366
Validation loss: 2.225226720174154

Epoch: 5| Step: 11
Training loss: 1.906154990196228
Validation loss: 2.2320348074038825

Epoch: 317| Step: 0
Training loss: 2.1523635387420654
Validation loss: 2.2134654422601066

Epoch: 5| Step: 1
Training loss: 1.8171485662460327
Validation loss: 2.2007225304841995

Epoch: 5| Step: 2
Training loss: 1.4214649200439453
Validation loss: 2.2287164330482483

Epoch: 5| Step: 3
Training loss: 1.870434045791626
Validation loss: 2.213235706090927

Epoch: 5| Step: 4
Training loss: 1.3801801204681396
Validation loss: 2.205511366327604

Epoch: 5| Step: 5
Training loss: 2.1277294158935547
Validation loss: 2.212343230843544

Epoch: 5| Step: 6
Training loss: 1.8902795314788818
Validation loss: 2.186191941301028

Epoch: 5| Step: 7
Training loss: 1.3779913187026978
Validation loss: 2.194114233056704

Epoch: 5| Step: 8
Training loss: 1.7268081903457642
Validation loss: 2.1876241266727448

Epoch: 5| Step: 9
Training loss: 2.1485915184020996
Validation loss: 2.1803285827239356

Epoch: 5| Step: 10
Training loss: 1.743323564529419
Validation loss: 2.2033384243647256

Epoch: 5| Step: 11
Training loss: 1.0311774015426636
Validation loss: 2.1997558176517487

Epoch: 318| Step: 0
Training loss: 1.6369657516479492
Validation loss: 2.1914202173550925

Epoch: 5| Step: 1
Training loss: 1.8737847805023193
Validation loss: 2.206788162390391

Epoch: 5| Step: 2
Training loss: 2.0069189071655273
Validation loss: 2.223483125368754

Epoch: 5| Step: 3
Training loss: 1.4469772577285767
Validation loss: 2.2054275472958884

Epoch: 5| Step: 4
Training loss: 1.788292646408081
Validation loss: 2.203832740585009

Epoch: 5| Step: 5
Training loss: 2.000025987625122
Validation loss: 2.237688511610031

Epoch: 5| Step: 6
Training loss: 1.281465768814087
Validation loss: 2.21136973798275

Epoch: 5| Step: 7
Training loss: 1.4446680545806885
Validation loss: 2.2021345297495523

Epoch: 5| Step: 8
Training loss: 1.9901092052459717
Validation loss: 2.2133429100116095

Epoch: 5| Step: 9
Training loss: 2.088155746459961
Validation loss: 2.1968377381563187

Epoch: 5| Step: 10
Training loss: 1.9416954517364502
Validation loss: 2.196963290373484

Epoch: 5| Step: 11
Training loss: 1.273658037185669
Validation loss: 2.196284830570221

Epoch: 319| Step: 0
Training loss: 1.6633422374725342
Validation loss: 2.1711080571015677

Epoch: 5| Step: 1
Training loss: 2.2163634300231934
Validation loss: 2.166854053735733

Epoch: 5| Step: 2
Training loss: 1.6293598413467407
Validation loss: 2.1861727982759476

Epoch: 5| Step: 3
Training loss: 1.591776967048645
Validation loss: 2.1853618125120797

Epoch: 5| Step: 4
Training loss: 1.2672772407531738
Validation loss: 2.19388480981191

Epoch: 5| Step: 5
Training loss: 1.8699506521224976
Validation loss: 2.187430659929911

Epoch: 5| Step: 6
Training loss: 1.8334051370620728
Validation loss: 2.208298683166504

Epoch: 5| Step: 7
Training loss: 1.931963324546814
Validation loss: 2.210266595085462

Epoch: 5| Step: 8
Training loss: 1.3015769720077515
Validation loss: 2.2153884768486023

Epoch: 5| Step: 9
Training loss: 2.0173163414001465
Validation loss: 2.199078400929769

Epoch: 5| Step: 10
Training loss: 2.119527816772461
Validation loss: 2.2205982953310013

Epoch: 5| Step: 11
Training loss: 1.885583758354187
Validation loss: 2.205518369873365

Epoch: 320| Step: 0
Training loss: 2.2345879077911377
Validation loss: 2.2181939284006753

Epoch: 5| Step: 1
Training loss: 1.7191126346588135
Validation loss: 2.2008704046408334

Epoch: 5| Step: 2
Training loss: 1.619041085243225
Validation loss: 2.2079789489507675

Epoch: 5| Step: 3
Training loss: 1.5600837469100952
Validation loss: 2.166509668032328

Epoch: 5| Step: 4
Training loss: 1.4258877038955688
Validation loss: 2.1844725956519446

Epoch: 5| Step: 5
Training loss: 1.6598020792007446
Validation loss: 2.1817246675491333

Epoch: 5| Step: 6
Training loss: 2.1044487953186035
Validation loss: 2.193768416841825

Epoch: 5| Step: 7
Training loss: 2.227949380874634
Validation loss: 2.2124377538760505

Epoch: 5| Step: 8
Training loss: 2.286799669265747
Validation loss: 2.18195633093516

Epoch: 5| Step: 9
Training loss: 1.385984182357788
Validation loss: 2.1833055317401886

Epoch: 5| Step: 10
Training loss: 1.1911457777023315
Validation loss: 2.1951328019301095

Epoch: 5| Step: 11
Training loss: 2.2312655448913574
Validation loss: 2.1979429125785828

Epoch: 321| Step: 0
Training loss: 1.4226030111312866
Validation loss: 2.2009157141049704

Epoch: 5| Step: 1
Training loss: 1.0765749216079712
Validation loss: 2.2288155456384025

Epoch: 5| Step: 2
Training loss: 2.0248653888702393
Validation loss: 2.19622370103995

Epoch: 5| Step: 3
Training loss: 2.3806891441345215
Validation loss: 2.230920652548472

Epoch: 5| Step: 4
Training loss: 2.0243725776672363
Validation loss: 2.1977194348971048

Epoch: 5| Step: 5
Training loss: 1.588020920753479
Validation loss: 2.182697574297587

Epoch: 5| Step: 6
Training loss: 2.1616387367248535
Validation loss: 2.208881805340449

Epoch: 5| Step: 7
Training loss: 2.0118160247802734
Validation loss: 2.185662940144539

Epoch: 5| Step: 8
Training loss: 1.3177237510681152
Validation loss: 2.2030208508173623

Epoch: 5| Step: 9
Training loss: 2.24247407913208
Validation loss: 2.177914097905159

Epoch: 5| Step: 10
Training loss: 1.7607024908065796
Validation loss: 2.1893313378095627

Epoch: 5| Step: 11
Training loss: 1.404246211051941
Validation loss: 2.1764951199293137

Epoch: 322| Step: 0
Training loss: 2.2285025119781494
Validation loss: 2.163114532828331

Epoch: 5| Step: 1
Training loss: 1.6003366708755493
Validation loss: 2.1668225824832916

Epoch: 5| Step: 2
Training loss: 1.822028398513794
Validation loss: 2.1489671965440116

Epoch: 5| Step: 3
Training loss: 2.3942861557006836
Validation loss: 2.144408951203028

Epoch: 5| Step: 4
Training loss: 2.211608648300171
Validation loss: 2.144577205181122

Epoch: 5| Step: 5
Training loss: 1.3920313119888306
Validation loss: 2.1349419554074607

Epoch: 5| Step: 6
Training loss: 1.7532215118408203
Validation loss: 2.1447549859682717

Epoch: 5| Step: 7
Training loss: 1.1579813957214355
Validation loss: 2.1276244471470513

Epoch: 5| Step: 8
Training loss: 1.551735520362854
Validation loss: 2.1547473073005676

Epoch: 5| Step: 9
Training loss: 1.5872856378555298
Validation loss: 2.1363770912090936

Epoch: 5| Step: 10
Training loss: 2.0457990169525146
Validation loss: 2.144864112138748

Epoch: 5| Step: 11
Training loss: 2.5447773933410645
Validation loss: 2.1625918447971344

Epoch: 323| Step: 0
Training loss: 2.0208754539489746
Validation loss: 2.1327877243359885

Epoch: 5| Step: 1
Training loss: 1.4838083982467651
Validation loss: 2.142317548394203

Epoch: 5| Step: 2
Training loss: 2.041485071182251
Validation loss: 2.139350230495135

Epoch: 5| Step: 3
Training loss: 2.0517168045043945
Validation loss: 2.1364706307649612

Epoch: 5| Step: 4
Training loss: 1.8134491443634033
Validation loss: 2.1510120977958045

Epoch: 5| Step: 5
Training loss: 1.8204978704452515
Validation loss: 2.148296425739924

Epoch: 5| Step: 6
Training loss: 1.753626823425293
Validation loss: 2.155231465895971

Epoch: 5| Step: 7
Training loss: 1.124495267868042
Validation loss: 2.1637694040934243

Epoch: 5| Step: 8
Training loss: 1.29544997215271
Validation loss: 2.147950212160746

Epoch: 5| Step: 9
Training loss: 2.031649351119995
Validation loss: 2.161402886112531

Epoch: 5| Step: 10
Training loss: 2.1156423091888428
Validation loss: 2.1483606100082397

Epoch: 5| Step: 11
Training loss: 1.9493989944458008
Validation loss: 2.1562201380729675

Epoch: 324| Step: 0
Training loss: 2.7638864517211914
Validation loss: 2.172473356127739

Epoch: 5| Step: 1
Training loss: 1.780918836593628
Validation loss: 2.1701385180155435

Epoch: 5| Step: 2
Training loss: 1.3032622337341309
Validation loss: 2.1798551877339682

Epoch: 5| Step: 3
Training loss: 2.1217241287231445
Validation loss: 2.1671269734700522

Epoch: 5| Step: 4
Training loss: 1.7765995264053345
Validation loss: 2.185867210229238

Epoch: 5| Step: 5
Training loss: 1.6151357889175415
Validation loss: 2.160723716020584

Epoch: 5| Step: 6
Training loss: 2.0403239727020264
Validation loss: 2.161196490128835

Epoch: 5| Step: 7
Training loss: 1.5850169658660889
Validation loss: 2.188174625237783

Epoch: 5| Step: 8
Training loss: 2.0080952644348145
Validation loss: 2.1830750753482184

Epoch: 5| Step: 9
Training loss: 1.5478277206420898
Validation loss: 2.179913346966108

Epoch: 5| Step: 10
Training loss: 1.6204936504364014
Validation loss: 2.1856465389331183

Epoch: 5| Step: 11
Training loss: 1.078282356262207
Validation loss: 2.1629216770331063

Epoch: 325| Step: 0
Training loss: 1.4683630466461182
Validation loss: 2.1752092639605203

Epoch: 5| Step: 1
Training loss: 1.8209797143936157
Validation loss: 2.172032023469607

Epoch: 5| Step: 2
Training loss: 1.9015617370605469
Validation loss: 2.1648117303848267

Epoch: 5| Step: 3
Training loss: 1.5241855382919312
Validation loss: 2.149795730908712

Epoch: 5| Step: 4
Training loss: 1.9652481079101562
Validation loss: 2.1626799404621124

Epoch: 5| Step: 5
Training loss: 2.2625608444213867
Validation loss: 2.1704508711894355

Epoch: 5| Step: 6
Training loss: 1.465960144996643
Validation loss: 2.1783136973778405

Epoch: 5| Step: 7
Training loss: 2.146406650543213
Validation loss: 2.1646088560422263

Epoch: 5| Step: 8
Training loss: 1.6174414157867432
Validation loss: 2.1805847783883414

Epoch: 5| Step: 9
Training loss: 1.030369520187378
Validation loss: 2.195017089446386

Epoch: 5| Step: 10
Training loss: 2.1293301582336426
Validation loss: 2.1948696672916412

Epoch: 5| Step: 11
Training loss: 1.867111325263977
Validation loss: 2.1852756838003793

Epoch: 326| Step: 0
Training loss: 1.8892929553985596
Validation loss: 2.2063250293334327

Epoch: 5| Step: 1
Training loss: 1.763821005821228
Validation loss: 2.1953751047452292

Epoch: 5| Step: 2
Training loss: 1.8675639629364014
Validation loss: 2.2067068765560784

Epoch: 5| Step: 3
Training loss: 2.1809659004211426
Validation loss: 2.217420851190885

Epoch: 5| Step: 4
Training loss: 1.7567027807235718
Validation loss: 2.1996067464351654

Epoch: 5| Step: 5
Training loss: 1.8432121276855469
Validation loss: 2.2157300611337027

Epoch: 5| Step: 6
Training loss: 1.4704124927520752
Validation loss: 2.182456076145172

Epoch: 5| Step: 7
Training loss: 1.4548370838165283
Validation loss: 2.186590696374575

Epoch: 5| Step: 8
Training loss: 1.74655020236969
Validation loss: 2.1804310977458954

Epoch: 5| Step: 9
Training loss: 2.0202181339263916
Validation loss: 2.167254149913788

Epoch: 5| Step: 10
Training loss: 1.5678987503051758
Validation loss: 2.1741900642712912

Epoch: 5| Step: 11
Training loss: 1.9607412815093994
Validation loss: 2.1870338370402655

Epoch: 327| Step: 0
Training loss: 1.373305082321167
Validation loss: 2.1869457016388574

Epoch: 5| Step: 1
Training loss: 1.4990432262420654
Validation loss: 2.2073772648970285

Epoch: 5| Step: 2
Training loss: 1.694873571395874
Validation loss: 2.2138495792945228

Epoch: 5| Step: 3
Training loss: 2.0898971557617188
Validation loss: 2.1870935261249542

Epoch: 5| Step: 4
Training loss: 2.073781967163086
Validation loss: 2.1819451451301575

Epoch: 5| Step: 5
Training loss: 1.9552291631698608
Validation loss: 2.2055213103691735

Epoch: 5| Step: 6
Training loss: 2.108194351196289
Validation loss: 2.2007479021946588

Epoch: 5| Step: 7
Training loss: 1.6344640254974365
Validation loss: 2.1964661478996277

Epoch: 5| Step: 8
Training loss: 1.505213975906372
Validation loss: 2.198865075906118

Epoch: 5| Step: 9
Training loss: 1.1429640054702759
Validation loss: 2.2121769984563193

Epoch: 5| Step: 10
Training loss: 2.4563984870910645
Validation loss: 2.199496919910113

Epoch: 5| Step: 11
Training loss: 0.8019211292266846
Validation loss: 2.1845107972621918

Epoch: 328| Step: 0
Training loss: 1.8761069774627686
Validation loss: 2.1781280984481177

Epoch: 5| Step: 1
Training loss: 1.8571481704711914
Validation loss: 2.1618831902742386

Epoch: 5| Step: 2
Training loss: 1.7940298318862915
Validation loss: 2.160042256116867

Epoch: 5| Step: 3
Training loss: 2.042011260986328
Validation loss: 2.16560131808122

Epoch: 5| Step: 4
Training loss: 1.981654167175293
Validation loss: 2.15259151160717

Epoch: 5| Step: 5
Training loss: 1.3771125078201294
Validation loss: 2.1478357315063477

Epoch: 5| Step: 6
Training loss: 1.6115920543670654
Validation loss: 2.154042666157087

Epoch: 5| Step: 7
Training loss: 2.328995943069458
Validation loss: 2.1715241223573685

Epoch: 5| Step: 8
Training loss: 1.800355315208435
Validation loss: 2.1831818968057632

Epoch: 5| Step: 9
Training loss: 1.0654217004776
Validation loss: 2.1725456217924752

Epoch: 5| Step: 10
Training loss: 1.971540093421936
Validation loss: 2.1874555299679437

Epoch: 5| Step: 11
Training loss: 2.0888075828552246
Validation loss: 2.1941185345252356

Epoch: 329| Step: 0
Training loss: 1.6754577159881592
Validation loss: 2.193163722753525

Epoch: 5| Step: 1
Training loss: 1.7247111797332764
Validation loss: 2.2227360606193542

Epoch: 5| Step: 2
Training loss: 1.6667976379394531
Validation loss: 2.203738729159037

Epoch: 5| Step: 3
Training loss: 2.2469303607940674
Validation loss: 2.2128175298372903

Epoch: 5| Step: 4
Training loss: 1.8748900890350342
Validation loss: 2.218018263578415

Epoch: 5| Step: 5
Training loss: 1.8528029918670654
Validation loss: 2.196346173683802

Epoch: 5| Step: 6
Training loss: 2.0604844093322754
Validation loss: 2.217181180914243

Epoch: 5| Step: 7
Training loss: 2.132406711578369
Validation loss: 2.2122281988461814

Epoch: 5| Step: 8
Training loss: 1.8222347497940063
Validation loss: 2.1697625319163003

Epoch: 5| Step: 9
Training loss: 1.8538223505020142
Validation loss: 2.176935816804568

Epoch: 5| Step: 10
Training loss: 1.7093861103057861
Validation loss: 2.1598375340302787

Epoch: 5| Step: 11
Training loss: 1.1358537673950195
Validation loss: 2.156135698159536

Epoch: 330| Step: 0
Training loss: 2.000720739364624
Validation loss: 2.1561093429724374

Epoch: 5| Step: 1
Training loss: 1.946027159690857
Validation loss: 2.1701176911592484

Epoch: 5| Step: 2
Training loss: 2.1440649032592773
Validation loss: 2.1772000739971795

Epoch: 5| Step: 3
Training loss: 1.9227619171142578
Validation loss: 2.1578596780697503

Epoch: 5| Step: 4
Training loss: 1.6136524677276611
Validation loss: 2.1628288278977075

Epoch: 5| Step: 5
Training loss: 1.9416215419769287
Validation loss: 2.170652682582537

Epoch: 5| Step: 6
Training loss: 1.2933681011199951
Validation loss: 2.1780298153559365

Epoch: 5| Step: 7
Training loss: 2.5881481170654297
Validation loss: 2.164813309907913

Epoch: 5| Step: 8
Training loss: 1.4799082279205322
Validation loss: 2.208878144621849

Epoch: 5| Step: 9
Training loss: 1.4200899600982666
Validation loss: 2.2508148352305093

Epoch: 5| Step: 10
Training loss: 1.2402323484420776
Validation loss: 2.2169215182463327

Epoch: 5| Step: 11
Training loss: 1.7050877809524536
Validation loss: 2.2137340903282166

Epoch: 331| Step: 0
Training loss: 1.0685702562332153
Validation loss: 2.2269649505615234

Epoch: 5| Step: 1
Training loss: 1.833242416381836
Validation loss: 2.2384189665317535

Epoch: 5| Step: 2
Training loss: 2.205923080444336
Validation loss: 2.2216508289178214

Epoch: 5| Step: 3
Training loss: 1.7691093683242798
Validation loss: 2.227910061677297

Epoch: 5| Step: 4
Training loss: 1.7108666896820068
Validation loss: 2.2249142626921334

Epoch: 5| Step: 5
Training loss: 2.2257816791534424
Validation loss: 2.2134293218453727

Epoch: 5| Step: 6
Training loss: 2.5190670490264893
Validation loss: 2.221809466679891

Epoch: 5| Step: 7
Training loss: 1.420654058456421
Validation loss: 2.210977519551913

Epoch: 5| Step: 8
Training loss: 1.2116410732269287
Validation loss: 2.198282778263092

Epoch: 5| Step: 9
Training loss: 1.7045166492462158
Validation loss: 2.1571536362171173

Epoch: 5| Step: 10
Training loss: 1.6398169994354248
Validation loss: 2.1804149051507316

Epoch: 5| Step: 11
Training loss: 1.9315078258514404
Validation loss: 2.1761418084303537

Epoch: 332| Step: 0
Training loss: 1.6805446147918701
Validation loss: 2.2144537270069122

Epoch: 5| Step: 1
Training loss: 1.515113115310669
Validation loss: 2.2136132617791495

Epoch: 5| Step: 2
Training loss: 1.3954976797103882
Validation loss: 2.1956966569026313

Epoch: 5| Step: 3
Training loss: 1.71809983253479
Validation loss: 2.198743353287379

Epoch: 5| Step: 4
Training loss: 1.7638952732086182
Validation loss: 2.2192137241363525

Epoch: 5| Step: 5
Training loss: 1.392370343208313
Validation loss: 2.218667447566986

Epoch: 5| Step: 6
Training loss: 1.144060730934143
Validation loss: 2.2174953718980155

Epoch: 5| Step: 7
Training loss: 1.8494329452514648
Validation loss: 2.196267306804657

Epoch: 5| Step: 8
Training loss: 1.9525425434112549
Validation loss: 2.2186880310376487

Epoch: 5| Step: 9
Training loss: 1.902971625328064
Validation loss: 2.206792930761973

Epoch: 5| Step: 10
Training loss: 2.4166347980499268
Validation loss: 2.1872965643803277

Epoch: 5| Step: 11
Training loss: 2.9005305767059326
Validation loss: 2.2050219674905143

Epoch: 333| Step: 0
Training loss: 1.8861764669418335
Validation loss: 2.1976564725240073

Epoch: 5| Step: 1
Training loss: 2.0255656242370605
Validation loss: 2.1993826230367026

Epoch: 5| Step: 2
Training loss: 1.5797126293182373
Validation loss: 2.183863257368406

Epoch: 5| Step: 3
Training loss: 1.8344799280166626
Validation loss: 2.1967883706092834

Epoch: 5| Step: 4
Training loss: 1.3893859386444092
Validation loss: 2.1993288546800613

Epoch: 5| Step: 5
Training loss: 2.0213370323181152
Validation loss: 2.209719995657603

Epoch: 5| Step: 6
Training loss: 1.3430250883102417
Validation loss: 2.2255723973115287

Epoch: 5| Step: 7
Training loss: 2.1852309703826904
Validation loss: 2.2069983084996543

Epoch: 5| Step: 8
Training loss: 1.66596257686615
Validation loss: 2.188890134294828

Epoch: 5| Step: 9
Training loss: 1.579921007156372
Validation loss: 2.186357801159223

Epoch: 5| Step: 10
Training loss: 1.6840438842773438
Validation loss: 2.1977932353814444

Epoch: 5| Step: 11
Training loss: 1.5849883556365967
Validation loss: 2.1949372788270316

Epoch: 334| Step: 0
Training loss: 1.8530504703521729
Validation loss: 2.203077405691147

Epoch: 5| Step: 1
Training loss: 2.271437168121338
Validation loss: 2.2001816034317017

Epoch: 5| Step: 2
Training loss: 1.8781492710113525
Validation loss: 2.186321015159289

Epoch: 5| Step: 3
Training loss: 1.5076342821121216
Validation loss: 2.206490551431974

Epoch: 5| Step: 4
Training loss: 1.9032256603240967
Validation loss: 2.206194003423055

Epoch: 5| Step: 5
Training loss: 1.4763721227645874
Validation loss: 2.203178664048513

Epoch: 5| Step: 6
Training loss: 1.7384955883026123
Validation loss: 2.1838316371043525

Epoch: 5| Step: 7
Training loss: 1.64937424659729
Validation loss: 2.192485347390175

Epoch: 5| Step: 8
Training loss: 1.2756469249725342
Validation loss: 2.2045837938785553

Epoch: 5| Step: 9
Training loss: 1.840894103050232
Validation loss: 2.1988863348960876

Epoch: 5| Step: 10
Training loss: 1.4108834266662598
Validation loss: 2.208111266295115

Epoch: 5| Step: 11
Training loss: 2.6602694988250732
Validation loss: 2.199007456501325

Epoch: 335| Step: 0
Training loss: 1.39858078956604
Validation loss: 2.189268261194229

Epoch: 5| Step: 1
Training loss: 1.800281286239624
Validation loss: 2.1942076732714972

Epoch: 5| Step: 2
Training loss: 2.053056240081787
Validation loss: 2.1966561675071716

Epoch: 5| Step: 3
Training loss: 1.453892469406128
Validation loss: 2.1774282505114875

Epoch: 5| Step: 4
Training loss: 1.46208918094635
Validation loss: 2.2018288423617682

Epoch: 5| Step: 5
Training loss: 1.6129465103149414
Validation loss: 2.2050989468892417

Epoch: 5| Step: 6
Training loss: 1.8196157217025757
Validation loss: 2.1909239590168

Epoch: 5| Step: 7
Training loss: 1.2994946241378784
Validation loss: 2.210831860701243

Epoch: 5| Step: 8
Training loss: 1.9268805980682373
Validation loss: 2.2052803387244544

Epoch: 5| Step: 9
Training loss: 2.223292827606201
Validation loss: 2.220202753941218

Epoch: 5| Step: 10
Training loss: 1.9811875820159912
Validation loss: 2.2165156304836273

Epoch: 5| Step: 11
Training loss: 1.0403273105621338
Validation loss: 2.245397557814916

Epoch: 336| Step: 0
Training loss: 2.281421422958374
Validation loss: 2.226189980904261

Epoch: 5| Step: 1
Training loss: 1.6176952123641968
Validation loss: 2.2443939248720803

Epoch: 5| Step: 2
Training loss: 1.3882970809936523
Validation loss: 2.240738958120346

Epoch: 5| Step: 3
Training loss: 1.3789527416229248
Validation loss: 2.238097002108892

Epoch: 5| Step: 4
Training loss: 2.023735523223877
Validation loss: 2.245883564154307

Epoch: 5| Step: 5
Training loss: 2.396916627883911
Validation loss: 2.2321530679861703

Epoch: 5| Step: 6
Training loss: 1.854553461074829
Validation loss: 2.241530646880468

Epoch: 5| Step: 7
Training loss: 1.5278232097625732
Validation loss: 2.2046999782323837

Epoch: 5| Step: 8
Training loss: 2.1041321754455566
Validation loss: 2.209441681702932

Epoch: 5| Step: 9
Training loss: 1.2725051641464233
Validation loss: 2.225804398457209

Epoch: 5| Step: 10
Training loss: 1.5315282344818115
Validation loss: 2.210370490948359

Epoch: 5| Step: 11
Training loss: 1.1384881734848022
Validation loss: 2.2088522911071777

Epoch: 337| Step: 0
Training loss: 1.7868263721466064
Validation loss: 2.2194092075030007

Epoch: 5| Step: 1
Training loss: 1.2105880975723267
Validation loss: 2.207221964995066

Epoch: 5| Step: 2
Training loss: 1.7166919708251953
Validation loss: 2.2135431518157325

Epoch: 5| Step: 3
Training loss: 1.0798759460449219
Validation loss: 2.222354839245478

Epoch: 5| Step: 4
Training loss: 1.8672631978988647
Validation loss: 2.215707113345464

Epoch: 5| Step: 5
Training loss: 2.0984315872192383
Validation loss: 2.2008621295293174

Epoch: 5| Step: 6
Training loss: 1.864148497581482
Validation loss: 2.218259036540985

Epoch: 5| Step: 7
Training loss: 1.690319299697876
Validation loss: 2.199147865176201

Epoch: 5| Step: 8
Training loss: 1.6855850219726562
Validation loss: 2.21665520966053

Epoch: 5| Step: 9
Training loss: 1.392291784286499
Validation loss: 2.225701555609703

Epoch: 5| Step: 10
Training loss: 2.3969664573669434
Validation loss: 2.2262564450502396

Epoch: 5| Step: 11
Training loss: 2.4913454055786133
Validation loss: 2.2012698551019034

Epoch: 338| Step: 0
Training loss: 1.1613101959228516
Validation loss: 2.216283231973648

Epoch: 5| Step: 1
Training loss: 1.8217029571533203
Validation loss: 2.217176874478658

Epoch: 5| Step: 2
Training loss: 1.984246015548706
Validation loss: 2.1929487387339273

Epoch: 5| Step: 3
Training loss: 1.6076948642730713
Validation loss: 2.2066760659217834

Epoch: 5| Step: 4
Training loss: 1.6368675231933594
Validation loss: 2.21173224846522

Epoch: 5| Step: 5
Training loss: 1.8578554391860962
Validation loss: 2.2138005644083023

Epoch: 5| Step: 6
Training loss: 1.7853695154190063
Validation loss: 2.218052566051483

Epoch: 5| Step: 7
Training loss: 1.8636335134506226
Validation loss: 2.228928635517756

Epoch: 5| Step: 8
Training loss: 1.2970359325408936
Validation loss: 2.2342208127180734

Epoch: 5| Step: 9
Training loss: 1.9815326929092407
Validation loss: 2.210673669974009

Epoch: 5| Step: 10
Training loss: 2.0068230628967285
Validation loss: 2.223817601799965

Epoch: 5| Step: 11
Training loss: 0.8025720119476318
Validation loss: 2.266362061103185

Epoch: 339| Step: 0
Training loss: 1.8111591339111328
Validation loss: 2.2462293207645416

Epoch: 5| Step: 1
Training loss: 1.4331915378570557
Validation loss: 2.2231137603521347

Epoch: 5| Step: 2
Training loss: 2.1800835132598877
Validation loss: 2.208306699991226

Epoch: 5| Step: 3
Training loss: 1.732844591140747
Validation loss: 2.2076159566640854

Epoch: 5| Step: 4
Training loss: 2.445033550262451
Validation loss: 2.200027952591578

Epoch: 5| Step: 5
Training loss: 1.3485912084579468
Validation loss: 2.209720586736997

Epoch: 5| Step: 6
Training loss: 1.4866033792495728
Validation loss: 2.237367888291677

Epoch: 5| Step: 7
Training loss: 1.6019595861434937
Validation loss: 2.2303263793389

Epoch: 5| Step: 8
Training loss: 1.6809113025665283
Validation loss: 2.2080283015966415

Epoch: 5| Step: 9
Training loss: 1.0982317924499512
Validation loss: 2.2109236071507135

Epoch: 5| Step: 10
Training loss: 1.7782070636749268
Validation loss: 2.2245770543813705

Epoch: 5| Step: 11
Training loss: 3.157541513442993
Validation loss: 2.210710992415746

Epoch: 340| Step: 0
Training loss: 1.8066329956054688
Validation loss: 2.209812025229136

Epoch: 5| Step: 1
Training loss: 2.1104326248168945
Validation loss: 2.2117397288481393

Epoch: 5| Step: 2
Training loss: 1.716046690940857
Validation loss: 2.227901374300321

Epoch: 5| Step: 3
Training loss: 1.3648107051849365
Validation loss: 2.2221286793549857

Epoch: 5| Step: 4
Training loss: 1.5480108261108398
Validation loss: 2.2108518183231354

Epoch: 5| Step: 5
Training loss: 1.2958117723464966
Validation loss: 2.194886654615402

Epoch: 5| Step: 6
Training loss: 1.9573612213134766
Validation loss: 2.1988904178142548

Epoch: 5| Step: 7
Training loss: 1.7695404291152954
Validation loss: 2.220038811365763

Epoch: 5| Step: 8
Training loss: 1.930916428565979
Validation loss: 2.2245104014873505

Epoch: 5| Step: 9
Training loss: 1.695972204208374
Validation loss: 2.2065330197413764

Epoch: 5| Step: 10
Training loss: 1.4633581638336182
Validation loss: 2.218681648373604

Epoch: 5| Step: 11
Training loss: 1.551033854484558
Validation loss: 2.2016411821047464

Epoch: 341| Step: 0
Training loss: 1.5692871809005737
Validation loss: 2.208344747622808

Epoch: 5| Step: 1
Training loss: 1.9387184381484985
Validation loss: 2.1579949259757996

Epoch: 5| Step: 2
Training loss: 2.1453137397766113
Validation loss: 2.125794087847074

Epoch: 5| Step: 3
Training loss: 2.0191242694854736
Validation loss: 2.134617875019709

Epoch: 5| Step: 4
Training loss: 2.286478042602539
Validation loss: 2.133292466402054

Epoch: 5| Step: 5
Training loss: 1.7008119821548462
Validation loss: 2.1177341838677726

Epoch: 5| Step: 6
Training loss: 1.6319637298583984
Validation loss: 2.118742177883784

Epoch: 5| Step: 7
Training loss: 1.6544654369354248
Validation loss: 2.1320787270863852

Epoch: 5| Step: 8
Training loss: 1.791830062866211
Validation loss: 2.1062400241692862

Epoch: 5| Step: 9
Training loss: 2.493844509124756
Validation loss: 2.112860679626465

Epoch: 5| Step: 10
Training loss: 2.3566300868988037
Validation loss: 2.1173299749692283

Epoch: 5| Step: 11
Training loss: 1.9320974349975586
Validation loss: 2.1316045820713043

Epoch: 342| Step: 0
Training loss: 2.302314281463623
Validation loss: 2.125886728366216

Epoch: 5| Step: 1
Training loss: 2.1828525066375732
Validation loss: 2.1358404407898584

Epoch: 5| Step: 2
Training loss: 1.9202781915664673
Validation loss: 2.135677362481753

Epoch: 5| Step: 3
Training loss: 2.127365827560425
Validation loss: 2.1200736413399377

Epoch: 5| Step: 4
Training loss: 1.8242557048797607
Validation loss: 2.1379235684871674

Epoch: 5| Step: 5
Training loss: 2.4461934566497803
Validation loss: 2.1415506402651467

Epoch: 5| Step: 6
Training loss: 2.4747252464294434
Validation loss: 2.153901437918345

Epoch: 5| Step: 7
Training loss: 1.2417972087860107
Validation loss: 2.157777031262716

Epoch: 5| Step: 8
Training loss: 1.34345281124115
Validation loss: 2.1689972480138144

Epoch: 5| Step: 9
Training loss: 1.7045974731445312
Validation loss: 2.188218673070272

Epoch: 5| Step: 10
Training loss: 1.7827240228652954
Validation loss: 2.2058548976977668

Epoch: 5| Step: 11
Training loss: 0.9302381277084351
Validation loss: 2.2207965900500617

Epoch: 343| Step: 0
Training loss: 1.408050775527954
Validation loss: 2.22313629090786

Epoch: 5| Step: 1
Training loss: 1.3136656284332275
Validation loss: 2.216704328854879

Epoch: 5| Step: 2
Training loss: 1.80499267578125
Validation loss: 2.2290529112021127

Epoch: 5| Step: 3
Training loss: 1.7388947010040283
Validation loss: 2.2068018714586892

Epoch: 5| Step: 4
Training loss: 2.236644744873047
Validation loss: 2.2524137248595557

Epoch: 5| Step: 5
Training loss: 1.9705088138580322
Validation loss: 2.2367189278205237

Epoch: 5| Step: 6
Training loss: 1.86590576171875
Validation loss: 2.2531353533267975

Epoch: 5| Step: 7
Training loss: 1.499714970588684
Validation loss: 2.2434591253598533

Epoch: 5| Step: 8
Training loss: 1.9477134943008423
Validation loss: 2.263706475496292

Epoch: 5| Step: 9
Training loss: 1.5265882015228271
Validation loss: 2.2384157180786133

Epoch: 5| Step: 10
Training loss: 2.001499891281128
Validation loss: 2.230734338363012

Epoch: 5| Step: 11
Training loss: 2.8687551021575928
Validation loss: 2.2423582673072815

Epoch: 344| Step: 0
Training loss: 1.6492130756378174
Validation loss: 2.2556978364785514

Epoch: 5| Step: 1
Training loss: 1.6135005950927734
Validation loss: 2.2364473839600882

Epoch: 5| Step: 2
Training loss: 1.9074745178222656
Validation loss: 2.2474882900714874

Epoch: 5| Step: 3
Training loss: 1.9778525829315186
Validation loss: 2.2329243818918862

Epoch: 5| Step: 4
Training loss: 1.870603322982788
Validation loss: 2.231305405497551

Epoch: 5| Step: 5
Training loss: 1.7086029052734375
Validation loss: 2.219233900308609

Epoch: 5| Step: 6
Training loss: 1.5558887720108032
Validation loss: 2.246563603480657

Epoch: 5| Step: 7
Training loss: 1.9021275043487549
Validation loss: 2.2278657456239066

Epoch: 5| Step: 8
Training loss: 2.1301746368408203
Validation loss: 2.2628835986057916

Epoch: 5| Step: 9
Training loss: 1.4599237442016602
Validation loss: 2.279533008734385

Epoch: 5| Step: 10
Training loss: 1.3164554834365845
Validation loss: 2.26819309592247

Epoch: 5| Step: 11
Training loss: 1.2484700679779053
Validation loss: 2.253935714562734

Epoch: 345| Step: 0
Training loss: 1.5863279104232788
Validation loss: 2.275761236747106

Epoch: 5| Step: 1
Training loss: 1.798509955406189
Validation loss: 2.2573399990797043

Epoch: 5| Step: 2
Training loss: 1.4898865222930908
Validation loss: 2.2619425455729165

Epoch: 5| Step: 3
Training loss: 1.0590368509292603
Validation loss: 2.2562046150366464

Epoch: 5| Step: 4
Training loss: 2.0286664962768555
Validation loss: 2.2562569876511893

Epoch: 5| Step: 5
Training loss: 1.8079521656036377
Validation loss: 2.24760240316391

Epoch: 5| Step: 6
Training loss: 1.6475824117660522
Validation loss: 2.2419523348410926

Epoch: 5| Step: 7
Training loss: 1.4466562271118164
Validation loss: 2.2437951068083444

Epoch: 5| Step: 8
Training loss: 2.669302463531494
Validation loss: 2.2022919952869415

Epoch: 5| Step: 9
Training loss: 1.6437078714370728
Validation loss: 2.19855527083079

Epoch: 5| Step: 10
Training loss: 2.2096710205078125
Validation loss: 2.187550261616707

Epoch: 5| Step: 11
Training loss: 1.3158830404281616
Validation loss: 2.152511417865753

Epoch: 346| Step: 0
Training loss: 1.4418258666992188
Validation loss: 2.147508134444555

Epoch: 5| Step: 1
Training loss: 2.0133402347564697
Validation loss: 2.1608976821104684

Epoch: 5| Step: 2
Training loss: 2.1115174293518066
Validation loss: 2.15835277736187

Epoch: 5| Step: 3
Training loss: 1.7817901372909546
Validation loss: 2.1738273600737252

Epoch: 5| Step: 4
Training loss: 2.057713747024536
Validation loss: 2.1878833075364432

Epoch: 5| Step: 5
Training loss: 1.5654776096343994
Validation loss: 2.2276773154735565

Epoch: 5| Step: 6
Training loss: 1.8154033422470093
Validation loss: 2.2190230886141458

Epoch: 5| Step: 7
Training loss: 2.0293192863464355
Validation loss: 2.242580105861028

Epoch: 5| Step: 8
Training loss: 1.8864657878875732
Validation loss: 2.248443146546682

Epoch: 5| Step: 9
Training loss: 1.5002472400665283
Validation loss: 2.215031698346138

Epoch: 5| Step: 10
Training loss: 1.6317951679229736
Validation loss: 2.235344191392263

Epoch: 5| Step: 11
Training loss: 0.9634969234466553
Validation loss: 2.2401765237251916

Epoch: 347| Step: 0
Training loss: 1.797267198562622
Validation loss: 2.2469155887762704

Epoch: 5| Step: 1
Training loss: 2.1666085720062256
Validation loss: 2.2736967305342355

Epoch: 5| Step: 2
Training loss: 1.0988858938217163
Validation loss: 2.267486830552419

Epoch: 5| Step: 3
Training loss: 1.6110575199127197
Validation loss: 2.2705094814300537

Epoch: 5| Step: 4
Training loss: 1.3076236248016357
Validation loss: 2.2415877282619476

Epoch: 5| Step: 5
Training loss: 2.1976325511932373
Validation loss: 2.2184184193611145

Epoch: 5| Step: 6
Training loss: 1.2934578657150269
Validation loss: 2.2157603104909263

Epoch: 5| Step: 7
Training loss: 1.4721343517303467
Validation loss: 2.2286641051371894

Epoch: 5| Step: 8
Training loss: 1.7602468729019165
Validation loss: 2.198807721336683

Epoch: 5| Step: 9
Training loss: 1.5859445333480835
Validation loss: 2.1940737813711166

Epoch: 5| Step: 10
Training loss: 2.282648801803589
Validation loss: 2.1825432231028876

Epoch: 5| Step: 11
Training loss: 2.200340509414673
Validation loss: 2.1819841066996255

Epoch: 348| Step: 0
Training loss: 1.9830251932144165
Validation loss: 2.1771205763022103

Epoch: 5| Step: 1
Training loss: 2.156179904937744
Validation loss: 2.173988461494446

Epoch: 5| Step: 2
Training loss: 1.675281286239624
Validation loss: 2.16256619989872

Epoch: 5| Step: 3
Training loss: 1.8321819305419922
Validation loss: 2.194661721587181

Epoch: 5| Step: 4
Training loss: 1.3858387470245361
Validation loss: 2.1783563792705536

Epoch: 5| Step: 5
Training loss: 1.337291955947876
Validation loss: 2.194457362095515

Epoch: 5| Step: 6
Training loss: 1.8124897480010986
Validation loss: 2.2016112953424454

Epoch: 5| Step: 7
Training loss: 1.8543994426727295
Validation loss: 2.2207032392422357

Epoch: 5| Step: 8
Training loss: 1.7228580713272095
Validation loss: 2.2583165168762207

Epoch: 5| Step: 9
Training loss: 1.459219217300415
Validation loss: 2.2378556629021964

Epoch: 5| Step: 10
Training loss: 1.5576274394989014
Validation loss: 2.2305283745129905

Epoch: 5| Step: 11
Training loss: 3.944474697113037
Validation loss: 2.2409071127573648

Epoch: 349| Step: 0
Training loss: 1.867352843284607
Validation loss: 2.2387744188308716

Epoch: 5| Step: 1
Training loss: 1.8293476104736328
Validation loss: 2.2408903439839682

Epoch: 5| Step: 2
Training loss: 1.8602148294448853
Validation loss: 2.2150584161281586

Epoch: 5| Step: 3
Training loss: 1.3824745416641235
Validation loss: 2.23089766005675

Epoch: 5| Step: 4
Training loss: 1.9848134517669678
Validation loss: 2.2417716532945633

Epoch: 5| Step: 5
Training loss: 1.1405482292175293
Validation loss: 2.235702176888784

Epoch: 5| Step: 6
Training loss: 2.043887138366699
Validation loss: 2.2359768698612847

Epoch: 5| Step: 7
Training loss: 1.6730034351348877
Validation loss: 2.2076673905054727

Epoch: 5| Step: 8
Training loss: 2.249202251434326
Validation loss: 2.2136153678099313

Epoch: 5| Step: 9
Training loss: 1.5083173513412476
Validation loss: 2.1853618721167245

Epoch: 5| Step: 10
Training loss: 1.443303108215332
Validation loss: 2.196708162625631

Epoch: 5| Step: 11
Training loss: 1.3980664014816284
Validation loss: 2.2321826418240867

Epoch: 350| Step: 0
Training loss: 1.6904098987579346
Validation loss: 2.2039776345094046

Epoch: 5| Step: 1
Training loss: 1.2782385349273682
Validation loss: 2.183204025030136

Epoch: 5| Step: 2
Training loss: 1.594292402267456
Validation loss: 2.1847215245167413

Epoch: 5| Step: 3
Training loss: 1.036922812461853
Validation loss: 2.1898791243632636

Epoch: 5| Step: 4
Training loss: 2.0099575519561768
Validation loss: 2.159851844112078

Epoch: 5| Step: 5
Training loss: 1.6656494140625
Validation loss: 2.196886027852694

Epoch: 5| Step: 6
Training loss: 1.7184107303619385
Validation loss: 2.213928500811259

Epoch: 5| Step: 7
Training loss: 1.4093742370605469
Validation loss: 2.224414939681689

Epoch: 5| Step: 8
Training loss: 2.062224864959717
Validation loss: 2.211423178513845

Epoch: 5| Step: 9
Training loss: 2.2613420486450195
Validation loss: 2.2251431047916412

Epoch: 5| Step: 10
Training loss: 2.0505356788635254
Validation loss: 2.219825247923533

Epoch: 5| Step: 11
Training loss: 3.6060664653778076
Validation loss: 2.2031228095293045

Epoch: 351| Step: 0
Training loss: 2.071592092514038
Validation loss: 2.1821530163288116

Epoch: 5| Step: 1
Training loss: 1.7435762882232666
Validation loss: 2.1694109638532004

Epoch: 5| Step: 2
Training loss: 1.7838020324707031
Validation loss: 2.144409731030464

Epoch: 5| Step: 3
Training loss: 2.2126457691192627
Validation loss: 2.129800498485565

Epoch: 5| Step: 4
Training loss: 1.2638254165649414
Validation loss: 2.1067366351683936

Epoch: 5| Step: 5
Training loss: 2.07194185256958
Validation loss: 2.1301118781169257

Epoch: 5| Step: 6
Training loss: 1.8141587972640991
Validation loss: 2.10390837987264

Epoch: 5| Step: 7
Training loss: 2.108153820037842
Validation loss: 2.107824911673864

Epoch: 5| Step: 8
Training loss: 1.665276288986206
Validation loss: 2.1158431470394135

Epoch: 5| Step: 9
Training loss: 2.219008207321167
Validation loss: 2.109543373187383

Epoch: 5| Step: 10
Training loss: 1.3256299495697021
Validation loss: 2.119093363483747

Epoch: 5| Step: 11
Training loss: 1.4648692607879639
Validation loss: 2.1210918376843133

Epoch: 352| Step: 0
Training loss: 1.8255703449249268
Validation loss: 2.1329496105511985

Epoch: 5| Step: 1
Training loss: 1.7142384052276611
Validation loss: 2.112041706840197

Epoch: 5| Step: 2
Training loss: 1.6144107580184937
Validation loss: 2.137051706512769

Epoch: 5| Step: 3
Training loss: 1.286116361618042
Validation loss: 2.1636406679948172

Epoch: 5| Step: 4
Training loss: 1.8371143341064453
Validation loss: 2.1289438356955848

Epoch: 5| Step: 5
Training loss: 2.2460477352142334
Validation loss: 2.1563711116711297

Epoch: 5| Step: 6
Training loss: 1.8382285833358765
Validation loss: 2.1507707983255386

Epoch: 5| Step: 7
Training loss: 1.4023618698120117
Validation loss: 2.145467594265938

Epoch: 5| Step: 8
Training loss: 1.8519452810287476
Validation loss: 2.1108727951844535

Epoch: 5| Step: 9
Training loss: 2.0397896766662598
Validation loss: 2.1170654644568763

Epoch: 5| Step: 10
Training loss: 2.0351290702819824
Validation loss: 2.1433509836594262

Epoch: 5| Step: 11
Training loss: 1.228959083557129
Validation loss: 2.132974366346995

Epoch: 353| Step: 0
Training loss: 1.7813301086425781
Validation loss: 2.1403369307518005

Epoch: 5| Step: 1
Training loss: 1.5204304456710815
Validation loss: 2.154941737651825

Epoch: 5| Step: 2
Training loss: 2.1201751232147217
Validation loss: 2.1344889402389526

Epoch: 5| Step: 3
Training loss: 2.591322422027588
Validation loss: 2.170285940170288

Epoch: 5| Step: 4
Training loss: 2.0204524993896484
Validation loss: 2.148407389720281

Epoch: 5| Step: 5
Training loss: 1.424309492111206
Validation loss: 2.1665764153003693

Epoch: 5| Step: 6
Training loss: 1.8163684606552124
Validation loss: 2.150875156124433

Epoch: 5| Step: 7
Training loss: 1.5427589416503906
Validation loss: 2.153179809451103

Epoch: 5| Step: 8
Training loss: 1.3216828107833862
Validation loss: 2.1418952643871307

Epoch: 5| Step: 9
Training loss: 1.6889699697494507
Validation loss: 2.1800994873046875

Epoch: 5| Step: 10
Training loss: 1.2148997783660889
Validation loss: 2.1756566564242044

Epoch: 5| Step: 11
Training loss: 0.9603710174560547
Validation loss: 2.1785277674595513

Epoch: 354| Step: 0
Training loss: 1.607391595840454
Validation loss: 2.1886182775100074

Epoch: 5| Step: 1
Training loss: 2.0606608390808105
Validation loss: 2.1995923866828284

Epoch: 5| Step: 2
Training loss: 1.5503664016723633
Validation loss: 2.1838716665903726

Epoch: 5| Step: 3
Training loss: 1.1919435262680054
Validation loss: 2.1931615670522056

Epoch: 5| Step: 4
Training loss: 1.427788257598877
Validation loss: 2.147964298725128

Epoch: 5| Step: 5
Training loss: 2.1019797325134277
Validation loss: 2.1450607577959695

Epoch: 5| Step: 6
Training loss: 1.5798419713974
Validation loss: 2.1472048461437225

Epoch: 5| Step: 7
Training loss: 1.7885125875473022
Validation loss: 2.149850681424141

Epoch: 5| Step: 8
Training loss: 1.53266179561615
Validation loss: 2.162823031346003

Epoch: 5| Step: 9
Training loss: 2.141934633255005
Validation loss: 2.1546786526838937

Epoch: 5| Step: 10
Training loss: 2.070908308029175
Validation loss: 2.162379890680313

Epoch: 5| Step: 11
Training loss: 2.404376268386841
Validation loss: 2.168787176410357

Epoch: 355| Step: 0
Training loss: 1.5781190395355225
Validation loss: 2.200406774878502

Epoch: 5| Step: 1
Training loss: 1.278472661972046
Validation loss: 2.1728888104359307

Epoch: 5| Step: 2
Training loss: 1.597280740737915
Validation loss: 2.1971699049075446

Epoch: 5| Step: 3
Training loss: 2.568695306777954
Validation loss: 2.176768268148104

Epoch: 5| Step: 4
Training loss: 1.8909080028533936
Validation loss: 2.220282475153605

Epoch: 5| Step: 5
Training loss: 1.140395164489746
Validation loss: 2.222866122921308

Epoch: 5| Step: 6
Training loss: 2.3689045906066895
Validation loss: 2.175252839922905

Epoch: 5| Step: 7
Training loss: 1.7853386402130127
Validation loss: 2.180473253130913

Epoch: 5| Step: 8
Training loss: 1.3808765411376953
Validation loss: 2.201810210943222

Epoch: 5| Step: 9
Training loss: 1.6520487070083618
Validation loss: 2.1671276092529297

Epoch: 5| Step: 10
Training loss: 2.0609545707702637
Validation loss: 2.14802881081899

Epoch: 5| Step: 11
Training loss: 0.9095005989074707
Validation loss: 2.15446637570858

Epoch: 356| Step: 0
Training loss: 2.246066093444824
Validation loss: 2.1273055722316108

Epoch: 5| Step: 1
Training loss: 1.1298267841339111
Validation loss: 2.1337240785360336

Epoch: 5| Step: 2
Training loss: 2.310508966445923
Validation loss: 2.138433188199997

Epoch: 5| Step: 3
Training loss: 1.8709418773651123
Validation loss: 2.1301844318707785

Epoch: 5| Step: 4
Training loss: 1.9762340784072876
Validation loss: 2.139371241132418

Epoch: 5| Step: 5
Training loss: 1.5620157718658447
Validation loss: 2.150115519762039

Epoch: 5| Step: 6
Training loss: 1.6699777841567993
Validation loss: 2.157263934612274

Epoch: 5| Step: 7
Training loss: 1.2186144590377808
Validation loss: 2.158189748724302

Epoch: 5| Step: 8
Training loss: 2.237417221069336
Validation loss: 2.15556001663208

Epoch: 5| Step: 9
Training loss: 1.4465997219085693
Validation loss: 2.16922535498937

Epoch: 5| Step: 10
Training loss: 1.730639100074768
Validation loss: 2.1694641460975013

Epoch: 5| Step: 11
Training loss: 0.21940827369689941
Validation loss: 2.1672233492136

Epoch: 357| Step: 0
Training loss: 1.5039163827896118
Validation loss: 2.1745544771353402

Epoch: 5| Step: 1
Training loss: 1.5879429578781128
Validation loss: 2.168282836675644

Epoch: 5| Step: 2
Training loss: 1.9940707683563232
Validation loss: 2.1675980587800345

Epoch: 5| Step: 3
Training loss: 1.9657504558563232
Validation loss: 2.185401459534963

Epoch: 5| Step: 4
Training loss: 2.1426146030426025
Validation loss: 2.155959894259771

Epoch: 5| Step: 5
Training loss: 1.3021949529647827
Validation loss: 2.151158129175504

Epoch: 5| Step: 6
Training loss: 1.7290160655975342
Validation loss: 2.1557258864243827

Epoch: 5| Step: 7
Training loss: 1.0720387697219849
Validation loss: 2.1697992583115897

Epoch: 5| Step: 8
Training loss: 1.9679336547851562
Validation loss: 2.1724884808063507

Epoch: 5| Step: 9
Training loss: 1.9686095714569092
Validation loss: 2.1666166683038077

Epoch: 5| Step: 10
Training loss: 1.4106003046035767
Validation loss: 2.160215516885122

Epoch: 5| Step: 11
Training loss: 0.7072674632072449
Validation loss: 2.1606391270955405

Epoch: 358| Step: 0
Training loss: 1.4792399406433105
Validation loss: 2.173136239250501

Epoch: 5| Step: 1
Training loss: 1.159100890159607
Validation loss: 2.162019044160843

Epoch: 5| Step: 2
Training loss: 1.6064555644989014
Validation loss: 2.1675268163283667

Epoch: 5| Step: 3
Training loss: 1.8245102167129517
Validation loss: 2.1868551075458527

Epoch: 5| Step: 4
Training loss: 1.4154247045516968
Validation loss: 2.2104028165340424

Epoch: 5| Step: 5
Training loss: 1.7613385915756226
Validation loss: 2.2064420183499656

Epoch: 5| Step: 6
Training loss: 1.8185930252075195
Validation loss: 2.2097078412771225

Epoch: 5| Step: 7
Training loss: 1.3064861297607422
Validation loss: 2.22016749282678

Epoch: 5| Step: 8
Training loss: 1.6607555150985718
Validation loss: 2.1813723742961884

Epoch: 5| Step: 9
Training loss: 2.6177127361297607
Validation loss: 2.1853291740020118

Epoch: 5| Step: 10
Training loss: 1.8854659795761108
Validation loss: 2.1954928189516068

Epoch: 5| Step: 11
Training loss: 2.6274495124816895
Validation loss: 2.197674115498861

Epoch: 359| Step: 0
Training loss: 1.7083041667938232
Validation loss: 2.1753696650266647

Epoch: 5| Step: 1
Training loss: 1.3962074518203735
Validation loss: 2.171455437938372

Epoch: 5| Step: 2
Training loss: 1.573806643486023
Validation loss: 2.1683572282393775

Epoch: 5| Step: 3
Training loss: 3.0844593048095703
Validation loss: 2.1428331385056176

Epoch: 5| Step: 4
Training loss: 1.8148536682128906
Validation loss: 2.161060189207395

Epoch: 5| Step: 5
Training loss: 1.2865571975708008
Validation loss: 2.18168613811334

Epoch: 5| Step: 6
Training loss: 1.5743772983551025
Validation loss: 2.193935697277387

Epoch: 5| Step: 7
Training loss: 1.4708963632583618
Validation loss: 2.198092967271805

Epoch: 5| Step: 8
Training loss: 1.8649938106536865
Validation loss: 2.1908433636029563

Epoch: 5| Step: 9
Training loss: 1.6907389163970947
Validation loss: 2.20943354566892

Epoch: 5| Step: 10
Training loss: 1.1726232767105103
Validation loss: 2.203399414817492

Epoch: 5| Step: 11
Training loss: 2.786917209625244
Validation loss: 2.2159264187018075

Epoch: 360| Step: 0
Training loss: 1.6703180074691772
Validation loss: 2.1898459792137146

Epoch: 5| Step: 1
Training loss: 1.304312825202942
Validation loss: 2.224132706721624

Epoch: 5| Step: 2
Training loss: 1.7825425863265991
Validation loss: 2.22197159131368

Epoch: 5| Step: 3
Training loss: 1.0500514507293701
Validation loss: 2.2135667155186334

Epoch: 5| Step: 4
Training loss: 1.5359445810317993
Validation loss: 2.2074721356232962

Epoch: 5| Step: 5
Training loss: 1.4711343050003052
Validation loss: 2.1949497958024344

Epoch: 5| Step: 6
Training loss: 1.9165143966674805
Validation loss: 2.2036866496006646

Epoch: 5| Step: 7
Training loss: 2.3024556636810303
Validation loss: 2.2160677760839462

Epoch: 5| Step: 8
Training loss: 1.89005446434021
Validation loss: 2.2344211637973785

Epoch: 5| Step: 9
Training loss: 1.6906893253326416
Validation loss: 2.205064664284388

Epoch: 5| Step: 10
Training loss: 1.9115254878997803
Validation loss: 2.1998679538567862

Epoch: 5| Step: 11
Training loss: 1.3889374732971191
Validation loss: 2.1913333535194397

Epoch: 361| Step: 0
Training loss: 1.3242908716201782
Validation loss: 2.2001439879337945

Epoch: 5| Step: 1
Training loss: 1.6125142574310303
Validation loss: 2.1986184964577355

Epoch: 5| Step: 2
Training loss: 1.1004877090454102
Validation loss: 2.189765453338623

Epoch: 5| Step: 3
Training loss: 2.412121057510376
Validation loss: 2.172823558251063

Epoch: 5| Step: 4
Training loss: 1.9351810216903687
Validation loss: 2.190211668610573

Epoch: 5| Step: 5
Training loss: 1.9061477184295654
Validation loss: 2.1669660905996957

Epoch: 5| Step: 6
Training loss: 1.316258430480957
Validation loss: 2.200517629583677

Epoch: 5| Step: 7
Training loss: 1.119508981704712
Validation loss: 2.20108433564504

Epoch: 5| Step: 8
Training loss: 1.7242282629013062
Validation loss: 2.212969849507014

Epoch: 5| Step: 9
Training loss: 1.7278801202774048
Validation loss: 2.188323974609375

Epoch: 5| Step: 10
Training loss: 2.172224521636963
Validation loss: 2.192742163936297

Epoch: 5| Step: 11
Training loss: 1.7229076623916626
Validation loss: 2.178777813911438

Epoch: 362| Step: 0
Training loss: 1.0959928035736084
Validation loss: 2.200891613960266

Epoch: 5| Step: 1
Training loss: 2.3017187118530273
Validation loss: 2.2199261089166007

Epoch: 5| Step: 2
Training loss: 1.433849811553955
Validation loss: 2.176381712158521

Epoch: 5| Step: 3
Training loss: 2.0033304691314697
Validation loss: 2.2054418126742044

Epoch: 5| Step: 4
Training loss: 2.3110294342041016
Validation loss: 2.1814441482226052

Epoch: 5| Step: 5
Training loss: 1.8210780620574951
Validation loss: 2.2072191139062247

Epoch: 5| Step: 6
Training loss: 1.2726614475250244
Validation loss: 2.185596505800883

Epoch: 5| Step: 7
Training loss: 1.7306396961212158
Validation loss: 2.225077271461487

Epoch: 5| Step: 8
Training loss: 1.4934539794921875
Validation loss: 2.2030826012293496

Epoch: 5| Step: 9
Training loss: 1.4963818788528442
Validation loss: 2.210956628123919

Epoch: 5| Step: 10
Training loss: 1.4809563159942627
Validation loss: 2.1739021142323813

Epoch: 5| Step: 11
Training loss: 1.4025263786315918
Validation loss: 2.1918972432613373

Epoch: 363| Step: 0
Training loss: 1.4245662689208984
Validation loss: 2.1669415881236396

Epoch: 5| Step: 1
Training loss: 2.315142869949341
Validation loss: 2.197680577635765

Epoch: 5| Step: 2
Training loss: 1.5023813247680664
Validation loss: 2.160626858472824

Epoch: 5| Step: 3
Training loss: 1.9803650379180908
Validation loss: 2.1913782507181168

Epoch: 5| Step: 4
Training loss: 2.255650043487549
Validation loss: 2.2283491492271423

Epoch: 5| Step: 5
Training loss: 1.8856903314590454
Validation loss: 2.2122136056423187

Epoch: 5| Step: 6
Training loss: 1.5017101764678955
Validation loss: 2.2111998995145163

Epoch: 5| Step: 7
Training loss: 1.6363557577133179
Validation loss: 2.21711465716362

Epoch: 5| Step: 8
Training loss: 1.8469440937042236
Validation loss: 2.2074129482110343

Epoch: 5| Step: 9
Training loss: 1.359365701675415
Validation loss: 2.2227807541688285

Epoch: 5| Step: 10
Training loss: 1.2711368799209595
Validation loss: 2.1786740918954215

Epoch: 5| Step: 11
Training loss: 1.5020588636398315
Validation loss: 2.197630077600479

Epoch: 364| Step: 0
Training loss: 2.0184552669525146
Validation loss: 2.2016792794068656

Epoch: 5| Step: 1
Training loss: 2.2006590366363525
Validation loss: 2.2019872069358826

Epoch: 5| Step: 2
Training loss: 1.3385820388793945
Validation loss: 2.204782416423162

Epoch: 5| Step: 3
Training loss: 1.592046856880188
Validation loss: 2.211472734808922

Epoch: 5| Step: 4
Training loss: 1.7131084203720093
Validation loss: 2.191740204890569

Epoch: 5| Step: 5
Training loss: 0.8726760149002075
Validation loss: 2.2131420969963074

Epoch: 5| Step: 6
Training loss: 2.3250410556793213
Validation loss: 2.185905233025551

Epoch: 5| Step: 7
Training loss: 1.6844075918197632
Validation loss: 2.176020393768946

Epoch: 5| Step: 8
Training loss: 1.7904911041259766
Validation loss: 2.2069314420223236

Epoch: 5| Step: 9
Training loss: 1.4615559577941895
Validation loss: 2.2037748843431473

Epoch: 5| Step: 10
Training loss: 1.5749200582504272
Validation loss: 2.2009316235780716

Epoch: 5| Step: 11
Training loss: 1.5857815742492676
Validation loss: 2.20058344801267

Epoch: 365| Step: 0
Training loss: 1.807624101638794
Validation loss: 2.2045830885569253

Epoch: 5| Step: 1
Training loss: 1.6073917150497437
Validation loss: 2.210841183861097

Epoch: 5| Step: 2
Training loss: 2.3137333393096924
Validation loss: 2.211209883292516

Epoch: 5| Step: 3
Training loss: 1.632775902748108
Validation loss: 2.198563555876414

Epoch: 5| Step: 4
Training loss: 1.420196771621704
Validation loss: 2.215886508425077

Epoch: 5| Step: 5
Training loss: 1.2506592273712158
Validation loss: 2.2085970640182495

Epoch: 5| Step: 6
Training loss: 2.2509384155273438
Validation loss: 2.209261308113734

Epoch: 5| Step: 7
Training loss: 1.5203936100006104
Validation loss: 2.2201932668685913

Epoch: 5| Step: 8
Training loss: 1.5979526042938232
Validation loss: 2.222833956281344

Epoch: 5| Step: 9
Training loss: 1.9134485721588135
Validation loss: 2.198112979531288

Epoch: 5| Step: 10
Training loss: 1.3443689346313477
Validation loss: 2.2027169466018677

Epoch: 5| Step: 11
Training loss: 1.6801753044128418
Validation loss: 2.2067222197850547

Epoch: 366| Step: 0
Training loss: 1.190623164176941
Validation loss: 2.1874939997990928

Epoch: 5| Step: 1
Training loss: 1.4044376611709595
Validation loss: 2.177501122156779

Epoch: 5| Step: 2
Training loss: 1.6592473983764648
Validation loss: 2.175569141904513

Epoch: 5| Step: 3
Training loss: 2.881434202194214
Validation loss: 2.1611630419890084

Epoch: 5| Step: 4
Training loss: 1.3447521924972534
Validation loss: 2.1756607741117477

Epoch: 5| Step: 5
Training loss: 1.3002681732177734
Validation loss: 2.1651062866051993

Epoch: 5| Step: 6
Training loss: 1.8585364818572998
Validation loss: 2.1830904285113015

Epoch: 5| Step: 7
Training loss: 1.6733554601669312
Validation loss: 2.1734163761138916

Epoch: 5| Step: 8
Training loss: 1.5105202198028564
Validation loss: 2.18304177125295

Epoch: 5| Step: 9
Training loss: 1.7016222476959229
Validation loss: 2.1799718042214713

Epoch: 5| Step: 10
Training loss: 1.7411890029907227
Validation loss: 2.1796120703220367

Epoch: 5| Step: 11
Training loss: 1.983508825302124
Validation loss: 2.182625641425451

Epoch: 367| Step: 0
Training loss: 1.8292491436004639
Validation loss: 2.194919099410375

Epoch: 5| Step: 1
Training loss: 1.4915217161178589
Validation loss: 2.1937683522701263

Epoch: 5| Step: 2
Training loss: 1.7809566259384155
Validation loss: 2.1902743031581244

Epoch: 5| Step: 3
Training loss: 1.7313789129257202
Validation loss: 2.1842978497346244

Epoch: 5| Step: 4
Training loss: 1.4686391353607178
Validation loss: 2.165220409631729

Epoch: 5| Step: 5
Training loss: 1.7691230773925781
Validation loss: 2.171063100298246

Epoch: 5| Step: 6
Training loss: 1.1374084949493408
Validation loss: 2.1587677945693335

Epoch: 5| Step: 7
Training loss: 1.8000723123550415
Validation loss: 2.1532598733901978

Epoch: 5| Step: 8
Training loss: 1.6820096969604492
Validation loss: 2.150764917333921

Epoch: 5| Step: 9
Training loss: 2.038121223449707
Validation loss: 2.1652965197960534

Epoch: 5| Step: 10
Training loss: 2.208580493927002
Validation loss: 2.171946386496226

Epoch: 5| Step: 11
Training loss: 0.9730780124664307
Validation loss: 2.1805409093697867

Epoch: 368| Step: 0
Training loss: 1.4258514642715454
Validation loss: 2.1781254510084787

Epoch: 5| Step: 1
Training loss: 1.5027616024017334
Validation loss: 2.1774466931819916

Epoch: 5| Step: 2
Training loss: 1.4866943359375
Validation loss: 2.16166719297568

Epoch: 5| Step: 3
Training loss: 1.7185308933258057
Validation loss: 2.1709559907515845

Epoch: 5| Step: 4
Training loss: 1.581594705581665
Validation loss: 2.2043580164512

Epoch: 5| Step: 5
Training loss: 1.7555229663848877
Validation loss: 2.176452507575353

Epoch: 5| Step: 6
Training loss: 1.4833598136901855
Validation loss: 2.1968593200047812

Epoch: 5| Step: 7
Training loss: 1.676491141319275
Validation loss: 2.2328747510910034

Epoch: 5| Step: 8
Training loss: 1.5196651220321655
Validation loss: 2.2148359219233194

Epoch: 5| Step: 9
Training loss: 2.5191779136657715
Validation loss: 2.2028954376777015

Epoch: 5| Step: 10
Training loss: 1.9364097118377686
Validation loss: 2.204872190952301

Epoch: 5| Step: 11
Training loss: 0.8185766935348511
Validation loss: 2.2248639365037284

Epoch: 369| Step: 0
Training loss: 1.7541061639785767
Validation loss: 2.201193928718567

Epoch: 5| Step: 1
Training loss: 1.4914567470550537
Validation loss: 2.2057002087434134

Epoch: 5| Step: 2
Training loss: 2.0472068786621094
Validation loss: 2.2071347335974374

Epoch: 5| Step: 3
Training loss: 1.7134933471679688
Validation loss: 2.2069437205791473

Epoch: 5| Step: 4
Training loss: 1.6557140350341797
Validation loss: 2.211989333232244

Epoch: 5| Step: 5
Training loss: 1.0975573062896729
Validation loss: 2.201013535261154

Epoch: 5| Step: 6
Training loss: 1.7801315784454346
Validation loss: 2.228432774543762

Epoch: 5| Step: 7
Training loss: 1.7190529108047485
Validation loss: 2.2166663904984794

Epoch: 5| Step: 8
Training loss: 1.6649887561798096
Validation loss: 2.217298671603203

Epoch: 5| Step: 9
Training loss: 1.5095574855804443
Validation loss: 2.2051850259304047

Epoch: 5| Step: 10
Training loss: 1.5999372005462646
Validation loss: 2.2160623371601105

Epoch: 5| Step: 11
Training loss: 3.4104397296905518
Validation loss: 2.2094097832838693

Epoch: 370| Step: 0
Training loss: 1.8444808721542358
Validation loss: 2.1969023644924164

Epoch: 5| Step: 1
Training loss: 1.6684534549713135
Validation loss: 2.1963345309098563

Epoch: 5| Step: 2
Training loss: 1.6225217580795288
Validation loss: 2.2015691051880517

Epoch: 5| Step: 3
Training loss: 1.6841017007827759
Validation loss: 2.173174411058426

Epoch: 5| Step: 4
Training loss: 1.504157304763794
Validation loss: 2.181844249367714

Epoch: 5| Step: 5
Training loss: 1.456374168395996
Validation loss: 2.172383636236191

Epoch: 5| Step: 6
Training loss: 2.172956705093384
Validation loss: 2.1702303290367126

Epoch: 5| Step: 7
Training loss: 1.1611738204956055
Validation loss: 2.1764910519123077

Epoch: 5| Step: 8
Training loss: 1.473479986190796
Validation loss: 2.177790875236193

Epoch: 5| Step: 9
Training loss: 1.5975295305252075
Validation loss: 2.201183224717776

Epoch: 5| Step: 10
Training loss: 1.9730507135391235
Validation loss: 2.186718096335729

Epoch: 5| Step: 11
Training loss: 1.902355432510376
Validation loss: 2.1971241931120553

Epoch: 371| Step: 0
Training loss: 1.0319082736968994
Validation loss: 2.1845338543256125

Epoch: 5| Step: 1
Training loss: 1.8164600133895874
Validation loss: 2.1711209416389465

Epoch: 5| Step: 2
Training loss: 1.6290628910064697
Validation loss: 2.189502010742823

Epoch: 5| Step: 3
Training loss: 1.466655969619751
Validation loss: 2.191339204708735

Epoch: 5| Step: 4
Training loss: 1.7737226486206055
Validation loss: 2.1766297121842704

Epoch: 5| Step: 5
Training loss: 2.057642698287964
Validation loss: 2.163894772529602

Epoch: 5| Step: 6
Training loss: 1.768146276473999
Validation loss: 2.192277893424034

Epoch: 5| Step: 7
Training loss: 2.0444021224975586
Validation loss: 2.197219933072726

Epoch: 5| Step: 8
Training loss: 1.1233060359954834
Validation loss: 2.2070701022942862

Epoch: 5| Step: 9
Training loss: 2.017185688018799
Validation loss: 2.1663860579331717

Epoch: 5| Step: 10
Training loss: 1.3015334606170654
Validation loss: 2.2102061013380685

Epoch: 5| Step: 11
Training loss: 1.1983636617660522
Validation loss: 2.152193854252497

Epoch: 372| Step: 0
Training loss: 1.8637546300888062
Validation loss: 2.1849767168362937

Epoch: 5| Step: 1
Training loss: 1.2212377786636353
Validation loss: 2.195911794900894

Epoch: 5| Step: 2
Training loss: 2.346338987350464
Validation loss: 2.170529047648112

Epoch: 5| Step: 3
Training loss: 1.880722999572754
Validation loss: 2.1753452320893607

Epoch: 5| Step: 4
Training loss: 1.2251064777374268
Validation loss: 2.1466441303491592

Epoch: 5| Step: 5
Training loss: 1.8281043767929077
Validation loss: 2.1585071931282678

Epoch: 5| Step: 6
Training loss: 1.1254981756210327
Validation loss: 2.150452266136805

Epoch: 5| Step: 7
Training loss: 1.6816871166229248
Validation loss: 2.152031342188517

Epoch: 5| Step: 8
Training loss: 1.6720359325408936
Validation loss: 2.1903360386689505

Epoch: 5| Step: 9
Training loss: 1.9250568151474
Validation loss: 2.155425806840261

Epoch: 5| Step: 10
Training loss: 1.3976356983184814
Validation loss: 2.15929385026296

Epoch: 5| Step: 11
Training loss: 1.278839111328125
Validation loss: 2.1648738185564675

Epoch: 373| Step: 0
Training loss: 1.641672134399414
Validation loss: 2.1570298175017038

Epoch: 5| Step: 1
Training loss: 1.854528784751892
Validation loss: 2.1853717068831124

Epoch: 5| Step: 2
Training loss: 1.6830743551254272
Validation loss: 2.203470289707184

Epoch: 5| Step: 3
Training loss: 1.717664122581482
Validation loss: 2.2110908925533295

Epoch: 5| Step: 4
Training loss: 1.2969847917556763
Validation loss: 2.1614767064650855

Epoch: 5| Step: 5
Training loss: 1.8558517694473267
Validation loss: 2.186626821756363

Epoch: 5| Step: 6
Training loss: 1.3081228733062744
Validation loss: 2.1955091704924903

Epoch: 5| Step: 7
Training loss: 1.057615041732788
Validation loss: 2.192959100008011

Epoch: 5| Step: 8
Training loss: 2.1396632194519043
Validation loss: 2.2291728059450784

Epoch: 5| Step: 9
Training loss: 1.8689056634902954
Validation loss: 2.196107029914856

Epoch: 5| Step: 10
Training loss: 1.6884043216705322
Validation loss: 2.21998364229997

Epoch: 5| Step: 11
Training loss: 2.6146979331970215
Validation loss: 2.2140302856763205

Epoch: 374| Step: 0
Training loss: 1.6686559915542603
Validation loss: 2.214623272418976

Epoch: 5| Step: 1
Training loss: 1.8568168878555298
Validation loss: 2.1986267318328223

Epoch: 5| Step: 2
Training loss: 1.7841846942901611
Validation loss: 2.1985434939463935

Epoch: 5| Step: 3
Training loss: 1.473548412322998
Validation loss: 2.1863952775796256

Epoch: 5| Step: 4
Training loss: 1.7310047149658203
Validation loss: 2.183678170045217

Epoch: 5| Step: 5
Training loss: 1.8232609033584595
Validation loss: 2.20678340891997

Epoch: 5| Step: 6
Training loss: 1.2192561626434326
Validation loss: 2.1842820147673288

Epoch: 5| Step: 7
Training loss: 0.9982383847236633
Validation loss: 2.1838766833146415

Epoch: 5| Step: 8
Training loss: 1.6683645248413086
Validation loss: 2.1843801140785217

Epoch: 5| Step: 9
Training loss: 2.0701253414154053
Validation loss: 2.1874916354815164

Epoch: 5| Step: 10
Training loss: 1.698198676109314
Validation loss: 2.1603935062885284

Epoch: 5| Step: 11
Training loss: 1.6577805280685425
Validation loss: 2.1944590409596763

Epoch: 375| Step: 0
Training loss: 1.685790777206421
Validation loss: 2.223343382279078

Epoch: 5| Step: 1
Training loss: 1.3973462581634521
Validation loss: 2.1817860255638757

Epoch: 5| Step: 2
Training loss: 1.217283010482788
Validation loss: 2.2261187930901847

Epoch: 5| Step: 3
Training loss: 1.4494837522506714
Validation loss: 2.207981303334236

Epoch: 5| Step: 4
Training loss: 1.936499834060669
Validation loss: 2.176666329304377

Epoch: 5| Step: 5
Training loss: 1.4201347827911377
Validation loss: 2.235108653704325

Epoch: 5| Step: 6
Training loss: 1.6468687057495117
Validation loss: 2.2109171748161316

Epoch: 5| Step: 7
Training loss: 1.644375205039978
Validation loss: 2.2318272988001504

Epoch: 5| Step: 8
Training loss: 1.3828117847442627
Validation loss: 2.2054111113150916

Epoch: 5| Step: 9
Training loss: 1.7900804281234741
Validation loss: 2.2108970085779824

Epoch: 5| Step: 10
Training loss: 2.320697069168091
Validation loss: 2.2297582825024924

Epoch: 5| Step: 11
Training loss: 2.1947083473205566
Validation loss: 2.211897204319636

Epoch: 376| Step: 0
Training loss: 1.7667983770370483
Validation loss: 2.214523250857989

Epoch: 5| Step: 1
Training loss: 1.813285231590271
Validation loss: 2.17601511379083

Epoch: 5| Step: 2
Training loss: 1.068190097808838
Validation loss: 2.197405775388082

Epoch: 5| Step: 3
Training loss: 1.4693067073822021
Validation loss: 2.224344879388809

Epoch: 5| Step: 4
Training loss: 2.774733543395996
Validation loss: 2.1832476059595742

Epoch: 5| Step: 5
Training loss: 1.8848472833633423
Validation loss: 2.196977590521177

Epoch: 5| Step: 6
Training loss: 1.5227036476135254
Validation loss: 2.1942591071128845

Epoch: 5| Step: 7
Training loss: 1.5573112964630127
Validation loss: 2.2088096936543784

Epoch: 5| Step: 8
Training loss: 1.540325403213501
Validation loss: 2.168288543820381

Epoch: 5| Step: 9
Training loss: 1.5430434942245483
Validation loss: 2.1932700872421265

Epoch: 5| Step: 10
Training loss: 1.4713048934936523
Validation loss: 2.2295318643252053

Epoch: 5| Step: 11
Training loss: 1.7330478429794312
Validation loss: 2.1890440632899604

Epoch: 377| Step: 0
Training loss: 1.794335961341858
Validation loss: 2.1809447606404624

Epoch: 5| Step: 1
Training loss: 1.1889876127243042
Validation loss: 2.1934858858585358

Epoch: 5| Step: 2
Training loss: 2.076596260070801
Validation loss: 2.193932736913363

Epoch: 5| Step: 3
Training loss: 1.3474857807159424
Validation loss: 2.2015519787867865

Epoch: 5| Step: 4
Training loss: 1.626137375831604
Validation loss: 2.20858242114385

Epoch: 5| Step: 5
Training loss: 1.225538969039917
Validation loss: 2.2246507704257965

Epoch: 5| Step: 6
Training loss: 1.6864728927612305
Validation loss: 2.208002140124639

Epoch: 5| Step: 7
Training loss: 1.3845131397247314
Validation loss: 2.229962170124054

Epoch: 5| Step: 8
Training loss: 2.193293571472168
Validation loss: 2.231385678052902

Epoch: 5| Step: 9
Training loss: 2.0127949714660645
Validation loss: 2.193912078936895

Epoch: 5| Step: 10
Training loss: 1.510401964187622
Validation loss: 2.1989122927188873

Epoch: 5| Step: 11
Training loss: 0.9410132169723511
Validation loss: 2.1936682860056558

Epoch: 378| Step: 0
Training loss: 1.5375436544418335
Validation loss: 2.245468020439148

Epoch: 5| Step: 1
Training loss: 2.0484848022460938
Validation loss: 2.236430068810781

Epoch: 5| Step: 2
Training loss: 1.7820647954940796
Validation loss: 2.223741129040718

Epoch: 5| Step: 3
Training loss: 1.9149720668792725
Validation loss: 2.259670833746592

Epoch: 5| Step: 4
Training loss: 1.1900360584259033
Validation loss: 2.211635301510493

Epoch: 5| Step: 5
Training loss: 1.3554675579071045
Validation loss: 2.2320584257443747

Epoch: 5| Step: 6
Training loss: 1.5095661878585815
Validation loss: 2.2206322650114694

Epoch: 5| Step: 7
Training loss: 1.5913759469985962
Validation loss: 2.2199843525886536

Epoch: 5| Step: 8
Training loss: 1.6620756387710571
Validation loss: 2.214197884003321

Epoch: 5| Step: 9
Training loss: 2.0717358589172363
Validation loss: 2.190330058336258

Epoch: 5| Step: 10
Training loss: 0.904826819896698
Validation loss: 2.1903808414936066

Epoch: 5| Step: 11
Training loss: 2.9091365337371826
Validation loss: 2.180564135313034

Epoch: 379| Step: 0
Training loss: 1.2887649536132812
Validation loss: 2.1805234303077063

Epoch: 5| Step: 1
Training loss: 2.0382611751556396
Validation loss: 2.178336908419927

Epoch: 5| Step: 2
Training loss: 1.5158319473266602
Validation loss: 2.200495262940725

Epoch: 5| Step: 3
Training loss: 1.3085134029388428
Validation loss: 2.179787759979566

Epoch: 5| Step: 4
Training loss: 1.6980323791503906
Validation loss: 2.1834826469421387

Epoch: 5| Step: 5
Training loss: 2.0956461429595947
Validation loss: 2.1826823701461158

Epoch: 5| Step: 6
Training loss: 2.2213776111602783
Validation loss: 2.203759183486303

Epoch: 5| Step: 7
Training loss: 1.2816985845565796
Validation loss: 2.176110456387202

Epoch: 5| Step: 8
Training loss: 2.0600669384002686
Validation loss: 2.212989633282026

Epoch: 5| Step: 9
Training loss: 1.515687108039856
Validation loss: 2.1837503165006638

Epoch: 5| Step: 10
Training loss: 1.1082974672317505
Validation loss: 2.2048410971959433

Epoch: 5| Step: 11
Training loss: 0.9575985670089722
Validation loss: 2.1921350906292596

Epoch: 380| Step: 0
Training loss: 1.4258620738983154
Validation loss: 2.1774415324131646

Epoch: 5| Step: 1
Training loss: 1.9022668600082397
Validation loss: 2.1915205121040344

Epoch: 5| Step: 2
Training loss: 1.6515861749649048
Validation loss: 2.197616924842199

Epoch: 5| Step: 3
Training loss: 1.5471858978271484
Validation loss: 2.2235077371199927

Epoch: 5| Step: 4
Training loss: 1.561686635017395
Validation loss: 2.2050273716449738

Epoch: 5| Step: 5
Training loss: 1.8702081441879272
Validation loss: 2.2264356960852942

Epoch: 5| Step: 6
Training loss: 1.577467679977417
Validation loss: 2.208516145745913

Epoch: 5| Step: 7
Training loss: 1.6322314739227295
Validation loss: 2.2114427934090295

Epoch: 5| Step: 8
Training loss: 1.728597640991211
Validation loss: 2.213189164797465

Epoch: 5| Step: 9
Training loss: 1.3132078647613525
Validation loss: 2.2136700550715127

Epoch: 5| Step: 10
Training loss: 1.8325227499008179
Validation loss: 2.239357059200605

Epoch: 5| Step: 11
Training loss: 0.6161938905715942
Validation loss: 2.239727864662806

Epoch: 381| Step: 0
Training loss: 1.7071001529693604
Validation loss: 2.224778339266777

Epoch: 5| Step: 1
Training loss: 1.6429612636566162
Validation loss: 2.220977505048116

Epoch: 5| Step: 2
Training loss: 1.7311089038848877
Validation loss: 2.228560840090116

Epoch: 5| Step: 3
Training loss: 1.8654226064682007
Validation loss: 2.179098978638649

Epoch: 5| Step: 4
Training loss: 1.0689295530319214
Validation loss: 2.1849896560112634

Epoch: 5| Step: 5
Training loss: 1.4858696460723877
Validation loss: 2.210915222764015

Epoch: 5| Step: 6
Training loss: 1.548930048942566
Validation loss: 2.200763334830602

Epoch: 5| Step: 7
Training loss: 1.6916835308074951
Validation loss: 2.200219213962555

Epoch: 5| Step: 8
Training loss: 2.085289716720581
Validation loss: 2.182320306698481

Epoch: 5| Step: 9
Training loss: 1.7790725231170654
Validation loss: 2.199275717139244

Epoch: 5| Step: 10
Training loss: 1.1778061389923096
Validation loss: 2.1890701055526733

Epoch: 5| Step: 11
Training loss: 1.1943016052246094
Validation loss: 2.192710508902868

Epoch: 382| Step: 0
Training loss: 1.934231162071228
Validation loss: 2.1877171645561853

Epoch: 5| Step: 1
Training loss: 1.7685638666152954
Validation loss: 2.227889617284139

Epoch: 5| Step: 2
Training loss: 1.415689468383789
Validation loss: 2.221951196591059

Epoch: 5| Step: 3
Training loss: 1.381413459777832
Validation loss: 2.223808338244756

Epoch: 5| Step: 4
Training loss: 1.7368972301483154
Validation loss: 2.2035373399655023

Epoch: 5| Step: 5
Training loss: 1.4621502161026
Validation loss: 2.1932038962841034

Epoch: 5| Step: 6
Training loss: 1.426378607749939
Validation loss: 2.2051652868588767

Epoch: 5| Step: 7
Training loss: 1.345433235168457
Validation loss: 2.2420706848303475

Epoch: 5| Step: 8
Training loss: 1.7325338125228882
Validation loss: 2.2174279987812042

Epoch: 5| Step: 9
Training loss: 2.0637781620025635
Validation loss: 2.2043438206116357

Epoch: 5| Step: 10
Training loss: 1.1803631782531738
Validation loss: 2.2021113137404122

Epoch: 5| Step: 11
Training loss: 3.306201457977295
Validation loss: 2.1828802625338235

Epoch: 383| Step: 0
Training loss: 1.6494817733764648
Validation loss: 2.1954638063907623

Epoch: 5| Step: 1
Training loss: 1.2439559698104858
Validation loss: 2.17350102464358

Epoch: 5| Step: 2
Training loss: 1.6025346517562866
Validation loss: 2.2055748403072357

Epoch: 5| Step: 3
Training loss: 1.6589933633804321
Validation loss: 2.1844358146190643

Epoch: 5| Step: 4
Training loss: 1.7433582544326782
Validation loss: 2.2274344166119895

Epoch: 5| Step: 5
Training loss: 1.4274265766143799
Validation loss: 2.2020263026158013

Epoch: 5| Step: 6
Training loss: 1.637537956237793
Validation loss: 2.2121084928512573

Epoch: 5| Step: 7
Training loss: 1.3255884647369385
Validation loss: 2.2038068771362305

Epoch: 5| Step: 8
Training loss: 1.6227235794067383
Validation loss: 2.2175179024537406

Epoch: 5| Step: 9
Training loss: 2.5771307945251465
Validation loss: 2.189956953128179

Epoch: 5| Step: 10
Training loss: 1.521490216255188
Validation loss: 2.2119937936464944

Epoch: 5| Step: 11
Training loss: 2.470008134841919
Validation loss: 2.2039012412230172

Epoch: 384| Step: 0
Training loss: 2.2860350608825684
Validation loss: 2.2413826088110604

Epoch: 5| Step: 1
Training loss: 0.8378838300704956
Validation loss: 2.205962141354879

Epoch: 5| Step: 2
Training loss: 2.021231174468994
Validation loss: 2.2090379297733307

Epoch: 5| Step: 3
Training loss: 1.2510030269622803
Validation loss: 2.204001138607661

Epoch: 5| Step: 4
Training loss: 1.4119071960449219
Validation loss: 2.1901897688706717

Epoch: 5| Step: 5
Training loss: 1.1777516603469849
Validation loss: 2.1605461488167443

Epoch: 5| Step: 6
Training loss: 1.5104100704193115
Validation loss: 2.19175423681736

Epoch: 5| Step: 7
Training loss: 1.4903404712677002
Validation loss: 2.208545058965683

Epoch: 5| Step: 8
Training loss: 2.297571897506714
Validation loss: 2.2225105365117392

Epoch: 5| Step: 9
Training loss: 1.6754649877548218
Validation loss: 2.2185065249602

Epoch: 5| Step: 10
Training loss: 1.3441187143325806
Validation loss: 2.208900600671768

Epoch: 5| Step: 11
Training loss: 2.6333231925964355
Validation loss: 2.1948610792557397

Epoch: 385| Step: 0
Training loss: 2.15755033493042
Validation loss: 2.2015521973371506

Epoch: 5| Step: 1
Training loss: 1.3518106937408447
Validation loss: 2.2047898123661676

Epoch: 5| Step: 2
Training loss: 2.1407971382141113
Validation loss: 2.2104102075099945

Epoch: 5| Step: 3
Training loss: 1.3181225061416626
Validation loss: 2.2039989779392877

Epoch: 5| Step: 4
Training loss: 1.2750320434570312
Validation loss: 2.1893857220808663

Epoch: 5| Step: 5
Training loss: 1.6319830417633057
Validation loss: 2.2115213920672736

Epoch: 5| Step: 6
Training loss: 1.9250667095184326
Validation loss: 2.213099777698517

Epoch: 5| Step: 7
Training loss: 1.231654405593872
Validation loss: 2.2313800056775412

Epoch: 5| Step: 8
Training loss: 1.6014032363891602
Validation loss: 2.2318393190701804

Epoch: 5| Step: 9
Training loss: 1.1273524761199951
Validation loss: 2.2239742130041122

Epoch: 5| Step: 10
Training loss: 1.7892818450927734
Validation loss: 2.227133333683014

Epoch: 5| Step: 11
Training loss: 2.5054657459259033
Validation loss: 2.215890094637871

Epoch: 386| Step: 0
Training loss: 1.5188159942626953
Validation loss: 2.2337642212708793

Epoch: 5| Step: 1
Training loss: 1.7238447666168213
Validation loss: 2.224699075023333

Epoch: 5| Step: 2
Training loss: 1.881308913230896
Validation loss: 2.2148525714874268

Epoch: 5| Step: 3
Training loss: 1.2577900886535645
Validation loss: 2.218200614054998

Epoch: 5| Step: 4
Training loss: 1.6670722961425781
Validation loss: 2.2466444621483483

Epoch: 5| Step: 5
Training loss: 1.5343257188796997
Validation loss: 2.2465956111749015

Epoch: 5| Step: 6
Training loss: 1.5402045249938965
Validation loss: 2.2027958184480667

Epoch: 5| Step: 7
Training loss: 1.5366722345352173
Validation loss: 2.1981228291988373

Epoch: 5| Step: 8
Training loss: 1.5032011270523071
Validation loss: 2.178820217649142

Epoch: 5| Step: 9
Training loss: 1.2603288888931274
Validation loss: 2.2305345038572946

Epoch: 5| Step: 10
Training loss: 2.1546785831451416
Validation loss: 2.216882656017939

Epoch: 5| Step: 11
Training loss: 0.8143422603607178
Validation loss: 2.190448338786761

Epoch: 387| Step: 0
Training loss: 1.1529600620269775
Validation loss: 2.1879729678233466

Epoch: 5| Step: 1
Training loss: 1.5251604318618774
Validation loss: 2.1777740021546683

Epoch: 5| Step: 2
Training loss: 1.9851691722869873
Validation loss: 2.1937349239985147

Epoch: 5| Step: 3
Training loss: 1.2128570079803467
Validation loss: 2.1899431198835373

Epoch: 5| Step: 4
Training loss: 1.4009883403778076
Validation loss: 2.2248464127381644

Epoch: 5| Step: 5
Training loss: 2.196195363998413
Validation loss: 2.202680935462316

Epoch: 5| Step: 6
Training loss: 1.8126392364501953
Validation loss: 2.22102157274882

Epoch: 5| Step: 7
Training loss: 1.7462780475616455
Validation loss: 2.2332087556521096

Epoch: 5| Step: 8
Training loss: 2.15824556350708
Validation loss: 2.2346041202545166

Epoch: 5| Step: 9
Training loss: 1.6567726135253906
Validation loss: 2.237274949749311

Epoch: 5| Step: 10
Training loss: 1.715301513671875
Validation loss: 2.219380850593249

Epoch: 5| Step: 11
Training loss: 1.3829772472381592
Validation loss: 2.232600192228953

Epoch: 388| Step: 0
Training loss: 1.336871862411499
Validation loss: 2.251742129524549

Epoch: 5| Step: 1
Training loss: 1.6077009439468384
Validation loss: 2.2260212947924933

Epoch: 5| Step: 2
Training loss: 1.5628741979599
Validation loss: 2.2169049779574075

Epoch: 5| Step: 3
Training loss: 2.9079017639160156
Validation loss: 2.2214873234430947

Epoch: 5| Step: 4
Training loss: 1.7288166284561157
Validation loss: 2.2170870353778205

Epoch: 5| Step: 5
Training loss: 1.396064281463623
Validation loss: 2.2103989770015082

Epoch: 5| Step: 6
Training loss: 0.9489243626594543
Validation loss: 2.223366970817248

Epoch: 5| Step: 7
Training loss: 2.06093168258667
Validation loss: 2.1947092165549598

Epoch: 5| Step: 8
Training loss: 1.3725422620773315
Validation loss: 2.2010992070039115

Epoch: 5| Step: 9
Training loss: 1.4997713565826416
Validation loss: 2.1880251268545785

Epoch: 5| Step: 10
Training loss: 1.1414070129394531
Validation loss: 2.231932833790779

Epoch: 5| Step: 11
Training loss: 3.2549080848693848
Validation loss: 2.215199122826258

Epoch: 389| Step: 0
Training loss: 1.4484121799468994
Validation loss: 2.2255277931690216

Epoch: 5| Step: 1
Training loss: 2.530360698699951
Validation loss: 2.187391608953476

Epoch: 5| Step: 2
Training loss: 1.4191354513168335
Validation loss: 2.2197225292523703

Epoch: 5| Step: 3
Training loss: 1.0431138277053833
Validation loss: 2.2443059782187142

Epoch: 5| Step: 4
Training loss: 1.1631319522857666
Validation loss: 2.2321456372737885

Epoch: 5| Step: 5
Training loss: 1.2574793100357056
Validation loss: 2.194297343492508

Epoch: 5| Step: 6
Training loss: 1.8498872518539429
Validation loss: 2.1963672836621604

Epoch: 5| Step: 7
Training loss: 1.4028421640396118
Validation loss: 2.1799528102080026

Epoch: 5| Step: 8
Training loss: 2.3690361976623535
Validation loss: 2.150111049413681

Epoch: 5| Step: 9
Training loss: 1.6758416891098022
Validation loss: 2.1893972208102546

Epoch: 5| Step: 10
Training loss: 1.969966173171997
Validation loss: 2.1594356298446655

Epoch: 5| Step: 11
Training loss: 1.429856777191162
Validation loss: 2.1673416644334793

Epoch: 390| Step: 0
Training loss: 2.1944215297698975
Validation loss: 2.185582975546519

Epoch: 5| Step: 1
Training loss: 0.9781535863876343
Validation loss: 2.172666201988856

Epoch: 5| Step: 2
Training loss: 1.3776979446411133
Validation loss: 2.178249110778173

Epoch: 5| Step: 3
Training loss: 1.2438750267028809
Validation loss: 2.1781508227189383

Epoch: 5| Step: 4
Training loss: 0.9068652987480164
Validation loss: 2.2044822027285895

Epoch: 5| Step: 5
Training loss: 2.3256962299346924
Validation loss: 2.2021001130342484

Epoch: 5| Step: 6
Training loss: 1.7168693542480469
Validation loss: 2.185891181230545

Epoch: 5| Step: 7
Training loss: 1.819238305091858
Validation loss: 2.1965428491433463

Epoch: 5| Step: 8
Training loss: 1.4450390338897705
Validation loss: 2.1911577781041465

Epoch: 5| Step: 9
Training loss: 1.4603807926177979
Validation loss: 2.1725648095210395

Epoch: 5| Step: 10
Training loss: 2.3293004035949707
Validation loss: 2.166480759779612

Epoch: 5| Step: 11
Training loss: 1.7671077251434326
Validation loss: 2.190845330556234

Epoch: 391| Step: 0
Training loss: 1.6884019374847412
Validation loss: 2.201801414291064

Epoch: 5| Step: 1
Training loss: 1.0580421686172485
Validation loss: 2.1988924940427146

Epoch: 5| Step: 2
Training loss: 1.164247989654541
Validation loss: 2.187848001718521

Epoch: 5| Step: 3
Training loss: 1.3474090099334717
Validation loss: 2.1925242145856223

Epoch: 5| Step: 4
Training loss: 1.9057928323745728
Validation loss: 2.1656044920285544

Epoch: 5| Step: 5
Training loss: 1.487001657485962
Validation loss: 2.1591817835966745

Epoch: 5| Step: 6
Training loss: 1.6247295141220093
Validation loss: 2.1693239708741507

Epoch: 5| Step: 7
Training loss: 1.7005341053009033
Validation loss: 2.1470779478549957

Epoch: 5| Step: 8
Training loss: 1.984753966331482
Validation loss: 2.149901270866394

Epoch: 5| Step: 9
Training loss: 2.131485939025879
Validation loss: 2.160704622666041

Epoch: 5| Step: 10
Training loss: 1.604455590248108
Validation loss: 2.145269960165024

Epoch: 5| Step: 11
Training loss: 1.1119377613067627
Validation loss: 2.2045542150735855

Epoch: 392| Step: 0
Training loss: 1.380881905555725
Validation loss: 2.19938271244367

Epoch: 5| Step: 1
Training loss: 1.9069278240203857
Validation loss: 2.206373711427053

Epoch: 5| Step: 2
Training loss: 2.0353305339813232
Validation loss: 2.222056438525518

Epoch: 5| Step: 3
Training loss: 1.301067590713501
Validation loss: 2.2545272409915924

Epoch: 5| Step: 4
Training loss: 1.7234373092651367
Validation loss: 2.234392692645391

Epoch: 5| Step: 5
Training loss: 1.757173776626587
Validation loss: 2.227155307928721

Epoch: 5| Step: 6
Training loss: 1.4045392274856567
Validation loss: 2.2702273478110633

Epoch: 5| Step: 7
Training loss: 1.6954936981201172
Validation loss: 2.1920583049456277

Epoch: 5| Step: 8
Training loss: 1.5883418321609497
Validation loss: 2.207068234682083

Epoch: 5| Step: 9
Training loss: 1.530360460281372
Validation loss: 2.198844760656357

Epoch: 5| Step: 10
Training loss: 2.0112709999084473
Validation loss: 2.1742534140745797

Epoch: 5| Step: 11
Training loss: 2.1079156398773193
Validation loss: 2.192308341463407

Epoch: 393| Step: 0
Training loss: 1.747027039527893
Validation loss: 2.206614618500074

Epoch: 5| Step: 1
Training loss: 1.3203767538070679
Validation loss: 2.2059026459852853

Epoch: 5| Step: 2
Training loss: 1.5116970539093018
Validation loss: 2.253123462200165

Epoch: 5| Step: 3
Training loss: 1.786935806274414
Validation loss: 2.247058242559433

Epoch: 5| Step: 4
Training loss: 1.2553198337554932
Validation loss: 2.2642884651819863

Epoch: 5| Step: 5
Training loss: 2.0479414463043213
Validation loss: 2.2505465745925903

Epoch: 5| Step: 6
Training loss: 2.193556308746338
Validation loss: 2.255262851715088

Epoch: 5| Step: 7
Training loss: 1.7386611700057983
Validation loss: 2.281572232643763

Epoch: 5| Step: 8
Training loss: 1.1736094951629639
Validation loss: 2.222652241587639

Epoch: 5| Step: 9
Training loss: 2.3465230464935303
Validation loss: 2.1991074085235596

Epoch: 5| Step: 10
Training loss: 1.2418086528778076
Validation loss: 2.2033911645412445

Epoch: 5| Step: 11
Training loss: 2.943016529083252
Validation loss: 2.2123336692651114

Epoch: 394| Step: 0
Training loss: 1.3018388748168945
Validation loss: 2.2026123106479645

Epoch: 5| Step: 1
Training loss: 2.1358160972595215
Validation loss: 2.1880604922771454

Epoch: 5| Step: 2
Training loss: 1.7676299810409546
Validation loss: 2.1946017344792685

Epoch: 5| Step: 3
Training loss: 1.3312599658966064
Validation loss: 2.1992516765991845

Epoch: 5| Step: 4
Training loss: 2.407479763031006
Validation loss: 2.1667973895867667

Epoch: 5| Step: 5
Training loss: 1.4254151582717896
Validation loss: 2.202109048763911

Epoch: 5| Step: 6
Training loss: 1.611670732498169
Validation loss: 2.196554313103358

Epoch: 5| Step: 7
Training loss: 1.3772121667861938
Validation loss: 2.208391547203064

Epoch: 5| Step: 8
Training loss: 1.9696996212005615
Validation loss: 2.2065194894870124

Epoch: 5| Step: 9
Training loss: 1.439477801322937
Validation loss: 2.184205780426661

Epoch: 5| Step: 10
Training loss: 1.5494005680084229
Validation loss: 2.169390375415484

Epoch: 5| Step: 11
Training loss: 0.7902331352233887
Validation loss: 2.2150110552708306

Epoch: 395| Step: 0
Training loss: 1.0772579908370972
Validation loss: 2.182110443711281

Epoch: 5| Step: 1
Training loss: 1.8420305252075195
Validation loss: 2.1900824457406998

Epoch: 5| Step: 2
Training loss: 1.61676025390625
Validation loss: 2.225971211989721

Epoch: 5| Step: 3
Training loss: 2.0114479064941406
Validation loss: 2.2523131171862283

Epoch: 5| Step: 4
Training loss: 1.683664083480835
Validation loss: 2.226866220434507

Epoch: 5| Step: 5
Training loss: 1.8558269739151
Validation loss: 2.259975641965866

Epoch: 5| Step: 6
Training loss: 1.4578630924224854
Validation loss: 2.2398566404978433

Epoch: 5| Step: 7
Training loss: 1.8275245428085327
Validation loss: 2.19073819120725

Epoch: 5| Step: 8
Training loss: 1.154610276222229
Validation loss: 2.208609382311503

Epoch: 5| Step: 9
Training loss: 2.124454975128174
Validation loss: 2.1824235320091248

Epoch: 5| Step: 10
Training loss: 1.2675340175628662
Validation loss: 2.179694806536039

Epoch: 5| Step: 11
Training loss: 1.7743204832077026
Validation loss: 2.1657429734865823

Epoch: 396| Step: 0
Training loss: 1.1867716312408447
Validation loss: 2.1503929247458777

Epoch: 5| Step: 1
Training loss: 1.0628774166107178
Validation loss: 2.167965551217397

Epoch: 5| Step: 2
Training loss: 1.910867691040039
Validation loss: 2.1624364852905273

Epoch: 5| Step: 3
Training loss: 2.0355312824249268
Validation loss: 2.1660473346710205

Epoch: 5| Step: 4
Training loss: 2.098656415939331
Validation loss: 2.182501549522082

Epoch: 5| Step: 5
Training loss: 2.014453411102295
Validation loss: 2.1636239339907966

Epoch: 5| Step: 6
Training loss: 1.2938361167907715
Validation loss: 2.1794702311356864

Epoch: 5| Step: 7
Training loss: 1.0655945539474487
Validation loss: 2.1798844834168754

Epoch: 5| Step: 8
Training loss: 1.9127018451690674
Validation loss: 2.158525690436363

Epoch: 5| Step: 9
Training loss: 1.266765832901001
Validation loss: 2.176030079523722

Epoch: 5| Step: 10
Training loss: 1.575087308883667
Validation loss: 2.2014424055814743

Epoch: 5| Step: 11
Training loss: 1.5339772701263428
Validation loss: 2.1892305612564087

Epoch: 397| Step: 0
Training loss: 1.3820974826812744
Validation loss: 2.196428596973419

Epoch: 5| Step: 1
Training loss: 1.3719218969345093
Validation loss: 2.2283066560824714

Epoch: 5| Step: 2
Training loss: 1.8238451480865479
Validation loss: 2.214232345422109

Epoch: 5| Step: 3
Training loss: 1.1298564672470093
Validation loss: 2.241294408837954

Epoch: 5| Step: 4
Training loss: 1.2639976739883423
Validation loss: 2.2000040113925934

Epoch: 5| Step: 5
Training loss: 1.2536900043487549
Validation loss: 2.206120029091835

Epoch: 5| Step: 6
Training loss: 1.3893742561340332
Validation loss: 2.2074358562628427

Epoch: 5| Step: 7
Training loss: 1.939713716506958
Validation loss: 2.1927522122859955

Epoch: 5| Step: 8
Training loss: 1.7007728815078735
Validation loss: 2.199970359603564

Epoch: 5| Step: 9
Training loss: 1.3329122066497803
Validation loss: 2.2493358850479126

Epoch: 5| Step: 10
Training loss: 2.7788925170898438
Validation loss: 2.2056351204713187

Epoch: 5| Step: 11
Training loss: 2.283383846282959
Validation loss: 2.206384708484014

Epoch: 398| Step: 0
Training loss: 1.4685087203979492
Validation loss: 2.215230713287989

Epoch: 5| Step: 1
Training loss: 1.3606892824172974
Validation loss: 2.1944620013237

Epoch: 5| Step: 2
Training loss: 1.2720344066619873
Validation loss: 2.1926476458708444

Epoch: 5| Step: 3
Training loss: 1.6596378087997437
Validation loss: 2.190290927886963

Epoch: 5| Step: 4
Training loss: 1.6964476108551025
Validation loss: 2.194877008597056

Epoch: 5| Step: 5
Training loss: 1.604801893234253
Validation loss: 2.2056622207164764

Epoch: 5| Step: 6
Training loss: 1.3676776885986328
Validation loss: 2.2105766981840134

Epoch: 5| Step: 7
Training loss: 1.7617183923721313
Validation loss: 2.1835710356632867

Epoch: 5| Step: 8
Training loss: 1.2671196460723877
Validation loss: 2.1904600709676743

Epoch: 5| Step: 9
Training loss: 2.4697425365448
Validation loss: 2.183535103996595

Epoch: 5| Step: 10
Training loss: 1.3721928596496582
Validation loss: 2.194247076908747

Epoch: 5| Step: 11
Training loss: 1.1350077390670776
Validation loss: 2.186447044213613

Epoch: 399| Step: 0
Training loss: 1.9664583206176758
Validation loss: 2.224720517794291

Epoch: 5| Step: 1
Training loss: 1.0947493314743042
Validation loss: 2.1911784162124

Epoch: 5| Step: 2
Training loss: 1.613221526145935
Validation loss: 2.2042276163895926

Epoch: 5| Step: 3
Training loss: 1.4381805658340454
Validation loss: 2.1857452442248664

Epoch: 5| Step: 4
Training loss: 1.3922213315963745
Validation loss: 2.202514946460724

Epoch: 5| Step: 5
Training loss: 1.9073518514633179
Validation loss: 2.1899405171473822

Epoch: 5| Step: 6
Training loss: 1.702588677406311
Validation loss: 2.225954219698906

Epoch: 5| Step: 7
Training loss: 1.1181738376617432
Validation loss: 2.2369910776615143

Epoch: 5| Step: 8
Training loss: 1.5353304147720337
Validation loss: 2.26354589064916

Epoch: 5| Step: 9
Training loss: 1.0514352321624756
Validation loss: 2.2227557003498077

Epoch: 5| Step: 10
Training loss: 2.2014966011047363
Validation loss: 2.1835522850354514

Epoch: 5| Step: 11
Training loss: 2.4013571739196777
Validation loss: 2.1629787484804788

Epoch: 400| Step: 0
Training loss: 1.726610779762268
Validation loss: 2.18380868434906

Epoch: 5| Step: 1
Training loss: 1.3560434579849243
Validation loss: 2.158210262656212

Epoch: 5| Step: 2
Training loss: 1.2985632419586182
Validation loss: 2.17298490802447

Epoch: 5| Step: 3
Training loss: 1.0442363023757935
Validation loss: 2.1906291246414185

Epoch: 5| Step: 4
Training loss: 1.5595793724060059
Validation loss: 2.15823033452034

Epoch: 5| Step: 5
Training loss: 1.5706403255462646
Validation loss: 2.182187467813492

Epoch: 5| Step: 6
Training loss: 1.5817896127700806
Validation loss: 2.1572142591079078

Epoch: 5| Step: 7
Training loss: 1.674065351486206
Validation loss: 2.170432895421982

Epoch: 5| Step: 8
Training loss: 1.387214183807373
Validation loss: 2.181133270263672

Epoch: 5| Step: 9
Training loss: 1.8186689615249634
Validation loss: 2.1784662504990897

Epoch: 5| Step: 10
Training loss: 1.791054368019104
Validation loss: 2.182052358984947

Epoch: 5| Step: 11
Training loss: 2.902937650680542
Validation loss: 2.1805474112431207

Testing loss: 2.0782991947887615
