Epoch: 1| Step: 0
Training loss: 5.756833553314209
Validation loss: 5.23575884103775

Epoch: 5| Step: 1
Training loss: 5.347825527191162
Validation loss: 5.234309275945027

Epoch: 5| Step: 2
Training loss: 5.031281471252441
Validation loss: 5.232782443364461

Epoch: 5| Step: 3
Training loss: 5.279408931732178
Validation loss: 5.231276154518127

Epoch: 5| Step: 4
Training loss: 5.773518085479736
Validation loss: 5.229695041974385

Epoch: 5| Step: 5
Training loss: 5.9105634689331055
Validation loss: 5.228016833464305

Epoch: 5| Step: 6
Training loss: 5.849769115447998
Validation loss: 5.2263754804929095

Epoch: 5| Step: 7
Training loss: 4.852656364440918
Validation loss: 5.224617441495259

Epoch: 5| Step: 8
Training loss: 5.2362565994262695
Validation loss: 5.222785671552022

Epoch: 5| Step: 9
Training loss: 4.634957313537598
Validation loss: 5.220965842405955

Epoch: 5| Step: 10
Training loss: 4.743159294128418
Validation loss: 5.2189909021059675

Epoch: 5| Step: 11
Training loss: 4.554629325866699
Validation loss: 5.217073380947113

Epoch: 2| Step: 0
Training loss: 5.799633979797363
Validation loss: 5.215047558148702

Epoch: 5| Step: 1
Training loss: 3.929007053375244
Validation loss: 5.21298619111379

Epoch: 5| Step: 2
Training loss: 6.155123710632324
Validation loss: 5.210830827554067

Epoch: 5| Step: 3
Training loss: 5.151970863342285
Validation loss: 5.208546062310536

Epoch: 5| Step: 4
Training loss: 5.065518379211426
Validation loss: 5.206214586893718

Epoch: 5| Step: 5
Training loss: 5.438224792480469
Validation loss: 5.203657786051433

Epoch: 5| Step: 6
Training loss: 5.664817810058594
Validation loss: 5.2012433608373

Epoch: 5| Step: 7
Training loss: 4.304616451263428
Validation loss: 5.198463300863902

Epoch: 5| Step: 8
Training loss: 5.831049919128418
Validation loss: 5.195629715919495

Epoch: 5| Step: 9
Training loss: 5.552364349365234
Validation loss: 5.192610303560893

Epoch: 5| Step: 10
Training loss: 5.10085391998291
Validation loss: 5.189598460992177

Epoch: 5| Step: 11
Training loss: 5.295098304748535
Validation loss: 5.186237653096517

Epoch: 3| Step: 0
Training loss: 4.774707317352295
Validation loss: 5.18275914589564

Epoch: 5| Step: 1
Training loss: 4.469551086425781
Validation loss: 5.179031511147817

Epoch: 5| Step: 2
Training loss: 6.6010589599609375
Validation loss: 5.175219893455505

Epoch: 5| Step: 3
Training loss: 5.4575629234313965
Validation loss: 5.171084463596344

Epoch: 5| Step: 4
Training loss: 5.239937782287598
Validation loss: 5.16671746969223

Epoch: 5| Step: 5
Training loss: 5.285818576812744
Validation loss: 5.16215052207311

Epoch: 5| Step: 6
Training loss: 5.668035507202148
Validation loss: 5.157037715117137

Epoch: 5| Step: 7
Training loss: 5.6252570152282715
Validation loss: 5.1520629326502485

Epoch: 5| Step: 8
Training loss: 4.800708770751953
Validation loss: 5.1467105348904925

Epoch: 5| Step: 9
Training loss: 5.094043731689453
Validation loss: 5.140862226486206

Epoch: 5| Step: 10
Training loss: 4.0515875816345215
Validation loss: 5.13489294052124

Epoch: 5| Step: 11
Training loss: 7.649521350860596
Validation loss: 5.128677845001221

Epoch: 4| Step: 0
Training loss: 5.50501012802124
Validation loss: 5.122163027524948

Epoch: 5| Step: 1
Training loss: 5.0929670333862305
Validation loss: 5.115131159623464

Epoch: 5| Step: 2
Training loss: 5.0022807121276855
Validation loss: 5.108298043409984

Epoch: 5| Step: 3
Training loss: 4.6796417236328125
Validation loss: 5.100450038909912

Epoch: 5| Step: 4
Training loss: 5.6913323402404785
Validation loss: 5.092526197433472

Epoch: 5| Step: 5
Training loss: 5.260148048400879
Validation loss: 5.084263543287913

Epoch: 5| Step: 6
Training loss: 5.1207404136657715
Validation loss: 5.075757066408793

Epoch: 5| Step: 7
Training loss: 5.002139091491699
Validation loss: 5.066857834657033

Epoch: 5| Step: 8
Training loss: 5.029233455657959
Validation loss: 5.057604710261027

Epoch: 5| Step: 9
Training loss: 4.658044338226318
Validation loss: 5.047897378603618

Epoch: 5| Step: 10
Training loss: 5.522224426269531
Validation loss: 5.038251241048177

Epoch: 5| Step: 11
Training loss: 5.873422622680664
Validation loss: 5.027831514676412

Epoch: 5| Step: 0
Training loss: 5.319418907165527
Validation loss: 5.017637113730113

Epoch: 5| Step: 1
Training loss: 6.0902299880981445
Validation loss: 5.007094184557597

Epoch: 5| Step: 2
Training loss: 4.9278106689453125
Validation loss: 4.9961609443028765

Epoch: 5| Step: 3
Training loss: 4.431075572967529
Validation loss: 4.9850560029347735

Epoch: 5| Step: 4
Training loss: 5.633339881896973
Validation loss: 4.974037826061249

Epoch: 5| Step: 5
Training loss: 5.7974724769592285
Validation loss: 4.962544987599055

Epoch: 5| Step: 6
Training loss: 3.994232654571533
Validation loss: 4.951418360074361

Epoch: 5| Step: 7
Training loss: 5.833925724029541
Validation loss: 4.940038681030273

Epoch: 5| Step: 8
Training loss: 3.9321162700653076
Validation loss: 4.928765853246053

Epoch: 5| Step: 9
Training loss: 5.59503173828125
Validation loss: 4.917025069395701

Epoch: 5| Step: 10
Training loss: 4.244546890258789
Validation loss: 4.90573263168335

Epoch: 5| Step: 11
Training loss: 3.3774025440216064
Validation loss: 4.894262353579204

Epoch: 6| Step: 0
Training loss: 5.273502826690674
Validation loss: 4.882919728755951

Epoch: 5| Step: 1
Training loss: 5.595613479614258
Validation loss: 4.871579130490621

Epoch: 5| Step: 2
Training loss: 5.7054443359375
Validation loss: 4.860424856344859

Epoch: 5| Step: 3
Training loss: 4.71752405166626
Validation loss: 4.849286198616028

Epoch: 5| Step: 4
Training loss: 4.169421195983887
Validation loss: 4.838326553503673

Epoch: 5| Step: 5
Training loss: 4.280910968780518
Validation loss: 4.826971431573232

Epoch: 5| Step: 6
Training loss: 5.217751502990723
Validation loss: 4.816173871358235

Epoch: 5| Step: 7
Training loss: 4.694607257843018
Validation loss: 4.805738051732381

Epoch: 5| Step: 8
Training loss: 4.703217506408691
Validation loss: 4.794675409793854

Epoch: 5| Step: 9
Training loss: 5.615543842315674
Validation loss: 4.784523089726766

Epoch: 5| Step: 10
Training loss: 3.982985734939575
Validation loss: 4.7741552790006

Epoch: 5| Step: 11
Training loss: 5.374659538269043
Validation loss: 4.764288822809855

Epoch: 7| Step: 0
Training loss: 5.56809663772583
Validation loss: 4.75425108273824

Epoch: 5| Step: 1
Training loss: 5.1726861000061035
Validation loss: 4.74425024787585

Epoch: 5| Step: 2
Training loss: 5.910046100616455
Validation loss: 4.734350701173146

Epoch: 5| Step: 3
Training loss: 3.9150402545928955
Validation loss: 4.724589804808299

Epoch: 5| Step: 4
Training loss: 5.495095252990723
Validation loss: 4.715291539827983

Epoch: 5| Step: 5
Training loss: 3.9795479774475098
Validation loss: 4.706096152464549

Epoch: 5| Step: 6
Training loss: 4.214467525482178
Validation loss: 4.697049081325531

Epoch: 5| Step: 7
Training loss: 4.324797630310059
Validation loss: 4.688394278287888

Epoch: 5| Step: 8
Training loss: 4.696417808532715
Validation loss: 4.6796243985493975

Epoch: 5| Step: 9
Training loss: 4.578363418579102
Validation loss: 4.6707644164562225

Epoch: 5| Step: 10
Training loss: 5.4618635177612305
Validation loss: 4.66186128060023

Epoch: 5| Step: 11
Training loss: 2.194720983505249
Validation loss: 4.6535159548123675

Epoch: 8| Step: 0
Training loss: 4.8405632972717285
Validation loss: 4.645185728867848

Epoch: 5| Step: 1
Training loss: 5.2548508644104
Validation loss: 4.636906673510869

Epoch: 5| Step: 2
Training loss: 4.303189754486084
Validation loss: 4.628775437672933

Epoch: 5| Step: 3
Training loss: 3.4673519134521484
Validation loss: 4.620739142100017

Epoch: 5| Step: 4
Training loss: 3.8781840801239014
Validation loss: 4.612832307815552

Epoch: 5| Step: 5
Training loss: 4.986932754516602
Validation loss: 4.604770839214325

Epoch: 5| Step: 6
Training loss: 5.092286109924316
Validation loss: 4.596763432025909

Epoch: 5| Step: 7
Training loss: 5.315141201019287
Validation loss: 4.588908791542053

Epoch: 5| Step: 8
Training loss: 4.853336334228516
Validation loss: 4.580930044253667

Epoch: 5| Step: 9
Training loss: 4.091872215270996
Validation loss: 4.572496513525645

Epoch: 5| Step: 10
Training loss: 5.374932765960693
Validation loss: 4.564263502756755

Epoch: 5| Step: 11
Training loss: 6.044764995574951
Validation loss: 4.556035141150157

Epoch: 9| Step: 0
Training loss: 4.168621063232422
Validation loss: 4.547160724798839

Epoch: 5| Step: 1
Training loss: 3.978781223297119
Validation loss: 4.539224763711293

Epoch: 5| Step: 2
Training loss: 4.432191848754883
Validation loss: 4.530916551748912

Epoch: 5| Step: 3
Training loss: 4.973307132720947
Validation loss: 4.523484190305074

Epoch: 5| Step: 4
Training loss: 4.408451080322266
Validation loss: 4.515773177146912

Epoch: 5| Step: 5
Training loss: 4.644291877746582
Validation loss: 4.507920900980632

Epoch: 5| Step: 6
Training loss: 4.915740966796875
Validation loss: 4.500605791807175

Epoch: 5| Step: 7
Training loss: 4.716707706451416
Validation loss: 4.4930450320243835

Epoch: 5| Step: 8
Training loss: 5.184138774871826
Validation loss: 4.485593030850093

Epoch: 5| Step: 9
Training loss: 4.325173377990723
Validation loss: 4.477872868378957

Epoch: 5| Step: 10
Training loss: 4.658308982849121
Validation loss: 4.469858964284261

Epoch: 5| Step: 11
Training loss: 6.333367347717285
Validation loss: 4.462475170691808

Epoch: 10| Step: 0
Training loss: 4.410101890563965
Validation loss: 4.454568535089493

Epoch: 5| Step: 1
Training loss: 4.602124214172363
Validation loss: 4.446945051352183

Epoch: 5| Step: 2
Training loss: 4.578216075897217
Validation loss: 4.439123163620631

Epoch: 5| Step: 3
Training loss: 3.574497699737549
Validation loss: 4.431486785411835

Epoch: 5| Step: 4
Training loss: 5.025919437408447
Validation loss: 4.424282471338908

Epoch: 5| Step: 5
Training loss: 4.818146228790283
Validation loss: 4.41716135541598

Epoch: 5| Step: 6
Training loss: 4.215981960296631
Validation loss: 4.409769266843796

Epoch: 5| Step: 7
Training loss: 4.540040016174316
Validation loss: 4.402836551268895

Epoch: 5| Step: 8
Training loss: 4.2764482498168945
Validation loss: 4.396564384301503

Epoch: 5| Step: 9
Training loss: 4.879484176635742
Validation loss: 4.3901578187942505

Epoch: 5| Step: 10
Training loss: 5.5369343757629395
Validation loss: 4.383953849474589

Epoch: 5| Step: 11
Training loss: 1.5629334449768066
Validation loss: 4.377556512753169

Epoch: 11| Step: 0
Training loss: 4.997034549713135
Validation loss: 4.371159166097641

Epoch: 5| Step: 1
Training loss: 4.837165832519531
Validation loss: 4.3651818335056305

Epoch: 5| Step: 2
Training loss: 4.049718856811523
Validation loss: 4.358973026275635

Epoch: 5| Step: 3
Training loss: 3.9699795246124268
Validation loss: 4.353315810362498

Epoch: 5| Step: 4
Training loss: 4.871542930603027
Validation loss: 4.347171296676

Epoch: 5| Step: 5
Training loss: 4.65119743347168
Validation loss: 4.34116929769516

Epoch: 5| Step: 6
Training loss: 3.445269823074341
Validation loss: 4.334719220797221

Epoch: 5| Step: 7
Training loss: 4.7073774337768555
Validation loss: 4.328804512818654

Epoch: 5| Step: 8
Training loss: 3.838362216949463
Validation loss: 4.323172012964885

Epoch: 5| Step: 9
Training loss: 4.808266639709473
Validation loss: 4.316576739152272

Epoch: 5| Step: 10
Training loss: 5.197278022766113
Validation loss: 4.310579270124435

Epoch: 5| Step: 11
Training loss: 3.0670876502990723
Validation loss: 4.3047294318675995

Epoch: 12| Step: 0
Training loss: 4.217040538787842
Validation loss: 4.299561033646266

Epoch: 5| Step: 1
Training loss: 4.753635406494141
Validation loss: 4.293622513612111

Epoch: 5| Step: 2
Training loss: 2.929192304611206
Validation loss: 4.287975211938222

Epoch: 5| Step: 3
Training loss: 3.9888553619384766
Validation loss: 4.283130039771398

Epoch: 5| Step: 4
Training loss: 4.7871856689453125
Validation loss: 4.276943633953731

Epoch: 5| Step: 5
Training loss: 4.649778842926025
Validation loss: 4.270299752553304

Epoch: 5| Step: 6
Training loss: 3.864748477935791
Validation loss: 4.263903955618541

Epoch: 5| Step: 7
Training loss: 3.8124146461486816
Validation loss: 4.2579885721206665

Epoch: 5| Step: 8
Training loss: 5.2551164627075195
Validation loss: 4.251704275608063

Epoch: 5| Step: 9
Training loss: 4.260061740875244
Validation loss: 4.246163537104924

Epoch: 5| Step: 10
Training loss: 5.227077484130859
Validation loss: 4.239298651615779

Epoch: 5| Step: 11
Training loss: 7.484261989593506
Validation loss: 4.233265330394109

Epoch: 13| Step: 0
Training loss: 4.1688666343688965
Validation loss: 4.226996153593063

Epoch: 5| Step: 1
Training loss: 4.425599098205566
Validation loss: 4.221582055091858

Epoch: 5| Step: 2
Training loss: 3.8384616374969482
Validation loss: 4.2159973084926605

Epoch: 5| Step: 3
Training loss: 5.466492652893066
Validation loss: 4.2098948160807295

Epoch: 5| Step: 4
Training loss: 4.170646667480469
Validation loss: 4.203517158826192

Epoch: 5| Step: 5
Training loss: 4.5362348556518555
Validation loss: 4.19614823659261

Epoch: 5| Step: 6
Training loss: 3.3233516216278076
Validation loss: 4.189061880111694

Epoch: 5| Step: 7
Training loss: 4.890528678894043
Validation loss: 4.182397385438283

Epoch: 5| Step: 8
Training loss: 4.478076934814453
Validation loss: 4.1764891147613525

Epoch: 5| Step: 9
Training loss: 3.7957699298858643
Validation loss: 4.1703327894210815

Epoch: 5| Step: 10
Training loss: 4.18897008895874
Validation loss: 4.164284110069275

Epoch: 5| Step: 11
Training loss: 6.039038181304932
Validation loss: 4.158209045728047

Epoch: 14| Step: 0
Training loss: 4.105292320251465
Validation loss: 4.151895503203074

Epoch: 5| Step: 1
Training loss: 3.7568345069885254
Validation loss: 4.145605901877086

Epoch: 5| Step: 2
Training loss: 3.7602851390838623
Validation loss: 4.1393557985623675

Epoch: 5| Step: 3
Training loss: 4.037831783294678
Validation loss: 4.134068677822749

Epoch: 5| Step: 4
Training loss: 4.598426818847656
Validation loss: 4.127872029940288

Epoch: 5| Step: 5
Training loss: 4.985428810119629
Validation loss: 4.122331331173579

Epoch: 5| Step: 6
Training loss: 4.22891902923584
Validation loss: 4.1161375641822815

Epoch: 5| Step: 7
Training loss: 4.222235202789307
Validation loss: 4.109774738550186

Epoch: 5| Step: 8
Training loss: 3.7608819007873535
Validation loss: 4.104061563809712

Epoch: 5| Step: 9
Training loss: 4.439877510070801
Validation loss: 4.098545104265213

Epoch: 5| Step: 10
Training loss: 4.575296878814697
Validation loss: 4.092104772726695

Epoch: 5| Step: 11
Training loss: 6.242342948913574
Validation loss: 4.085898280143738

Epoch: 15| Step: 0
Training loss: 4.197615623474121
Validation loss: 4.080747644106547

Epoch: 5| Step: 1
Training loss: 4.413534641265869
Validation loss: 4.074587980906169

Epoch: 5| Step: 2
Training loss: 4.75141716003418
Validation loss: 4.068496892849605

Epoch: 5| Step: 3
Training loss: 4.094094276428223
Validation loss: 4.063424090544383

Epoch: 5| Step: 4
Training loss: 4.982220649719238
Validation loss: 4.0568374792734785

Epoch: 5| Step: 5
Training loss: 3.4664382934570312
Validation loss: 4.051351636648178

Epoch: 5| Step: 6
Training loss: 4.012572288513184
Validation loss: 4.046215355396271

Epoch: 5| Step: 7
Training loss: 3.9022128582000732
Validation loss: 4.040335963169734

Epoch: 5| Step: 8
Training loss: 3.859302043914795
Validation loss: 4.034549385309219

Epoch: 5| Step: 9
Training loss: 4.508136749267578
Validation loss: 4.029353429873784

Epoch: 5| Step: 10
Training loss: 3.9740700721740723
Validation loss: 4.02320729692777

Epoch: 5| Step: 11
Training loss: 4.17487907409668
Validation loss: 4.018732527891795

Epoch: 16| Step: 0
Training loss: 4.150906562805176
Validation loss: 4.014608571926753

Epoch: 5| Step: 1
Training loss: 3.3873932361602783
Validation loss: 4.0100178718566895

Epoch: 5| Step: 2
Training loss: 4.340150356292725
Validation loss: 4.001951416333516

Epoch: 5| Step: 3
Training loss: 4.084791660308838
Validation loss: 3.995621065298716

Epoch: 5| Step: 4
Training loss: 5.105093955993652
Validation loss: 3.989667683839798

Epoch: 5| Step: 5
Training loss: 3.935767412185669
Validation loss: 3.984620690345764

Epoch: 5| Step: 6
Training loss: 3.6554417610168457
Validation loss: 3.9789116978645325

Epoch: 5| Step: 7
Training loss: 4.080410003662109
Validation loss: 3.9729962050914764

Epoch: 5| Step: 8
Training loss: 3.878927707672119
Validation loss: 3.9666772981484733

Epoch: 5| Step: 9
Training loss: 4.498841762542725
Validation loss: 3.960945208867391

Epoch: 5| Step: 10
Training loss: 4.1800432205200195
Validation loss: 3.956178287665049

Epoch: 5| Step: 11
Training loss: 4.837066650390625
Validation loss: 3.9505464235941568

Epoch: 17| Step: 0
Training loss: 4.40178108215332
Validation loss: 3.94490510225296

Epoch: 5| Step: 1
Training loss: 3.9964003562927246
Validation loss: 3.939677288134893

Epoch: 5| Step: 2
Training loss: 4.9914045333862305
Validation loss: 3.933469980955124

Epoch: 5| Step: 3
Training loss: 4.130393028259277
Validation loss: 3.9281232158342996

Epoch: 5| Step: 4
Training loss: 3.578061580657959
Validation loss: 3.9232768217722573

Epoch: 5| Step: 5
Training loss: 3.0010077953338623
Validation loss: 3.917248090108236

Epoch: 5| Step: 6
Training loss: 3.7268576622009277
Validation loss: 3.9128499130407968

Epoch: 5| Step: 7
Training loss: 3.9353561401367188
Validation loss: 3.9075693587462106

Epoch: 5| Step: 8
Training loss: 4.836769104003906
Validation loss: 3.9015632371107736

Epoch: 5| Step: 9
Training loss: 3.6769306659698486
Validation loss: 3.896301339070002

Epoch: 5| Step: 10
Training loss: 4.403646469116211
Validation loss: 3.8915442327658334

Epoch: 5| Step: 11
Training loss: 4.4341864585876465
Validation loss: 3.886468400557836

Epoch: 18| Step: 0
Training loss: 3.7571120262145996
Validation loss: 3.881976584593455

Epoch: 5| Step: 1
Training loss: 4.712470054626465
Validation loss: 3.8760514557361603

Epoch: 5| Step: 2
Training loss: 3.7855544090270996
Validation loss: 3.8713001708189645

Epoch: 5| Step: 3
Training loss: 4.163862705230713
Validation loss: 3.8667811850706735

Epoch: 5| Step: 4
Training loss: 3.895937442779541
Validation loss: 3.861690034468969

Epoch: 5| Step: 5
Training loss: 4.10675048828125
Validation loss: 3.856851428747177

Epoch: 5| Step: 6
Training loss: 4.273710250854492
Validation loss: 3.8514363964398703

Epoch: 5| Step: 7
Training loss: 3.271573305130005
Validation loss: 3.8459674020608268

Epoch: 5| Step: 8
Training loss: 4.594771385192871
Validation loss: 3.8410141468048096

Epoch: 5| Step: 9
Training loss: 4.108896732330322
Validation loss: 3.835806796948115

Epoch: 5| Step: 10
Training loss: 3.6205382347106934
Validation loss: 3.830916444460551

Epoch: 5| Step: 11
Training loss: 3.011347770690918
Validation loss: 3.8258467813332877

Epoch: 19| Step: 0
Training loss: 2.8075995445251465
Validation loss: 3.8206191062927246

Epoch: 5| Step: 1
Training loss: 3.8856186866760254
Validation loss: 3.81571634610494

Epoch: 5| Step: 2
Training loss: 4.101927757263184
Validation loss: 3.8097871840000153

Epoch: 5| Step: 3
Training loss: 3.8154075145721436
Validation loss: 3.8056507805983224

Epoch: 5| Step: 4
Training loss: 4.775028705596924
Validation loss: 3.8005332946777344

Epoch: 5| Step: 5
Training loss: 3.6844420433044434
Validation loss: 3.795219987630844

Epoch: 5| Step: 6
Training loss: 3.5571579933166504
Validation loss: 3.789444069067637

Epoch: 5| Step: 7
Training loss: 3.4081592559814453
Validation loss: 3.784057637055715

Epoch: 5| Step: 8
Training loss: 5.130389213562012
Validation loss: 3.778964618841807

Epoch: 5| Step: 9
Training loss: 4.074853897094727
Validation loss: 3.7747659186522164

Epoch: 5| Step: 10
Training loss: 4.245674133300781
Validation loss: 3.7704413135846457

Epoch: 5| Step: 11
Training loss: 3.8000712394714355
Validation loss: 3.763471414645513

Epoch: 20| Step: 0
Training loss: 4.229983329772949
Validation loss: 3.7583912511666617

Epoch: 5| Step: 1
Training loss: 4.2352399826049805
Validation loss: 3.75314000248909

Epoch: 5| Step: 2
Training loss: 4.437444686889648
Validation loss: 3.748089691003164

Epoch: 5| Step: 3
Training loss: 4.3564043045043945
Validation loss: 3.742140700419744

Epoch: 5| Step: 4
Training loss: 3.558129072189331
Validation loss: 3.737050543228785

Epoch: 5| Step: 5
Training loss: 4.817390441894531
Validation loss: 3.732937584320704

Epoch: 5| Step: 6
Training loss: 3.150770902633667
Validation loss: 3.7270890871683755

Epoch: 5| Step: 7
Training loss: 3.245365858078003
Validation loss: 3.721913148959478

Epoch: 5| Step: 8
Training loss: 3.184283971786499
Validation loss: 3.7162694533665976

Epoch: 5| Step: 9
Training loss: 3.5783259868621826
Validation loss: 3.711542844772339

Epoch: 5| Step: 10
Training loss: 4.195533752441406
Validation loss: 3.7074935038884482

Epoch: 5| Step: 11
Training loss: 3.0909628868103027
Validation loss: 3.702806830406189

Epoch: 21| Step: 0
Training loss: 4.023622512817383
Validation loss: 3.6997123757998147

Epoch: 5| Step: 1
Training loss: 3.788609266281128
Validation loss: 3.6929517487684884

Epoch: 5| Step: 2
Training loss: 3.818014621734619
Validation loss: 3.6880942583084106

Epoch: 5| Step: 3
Training loss: 3.5494697093963623
Validation loss: 3.684105614821116

Epoch: 5| Step: 4
Training loss: 4.466542720794678
Validation loss: 3.6794389486312866

Epoch: 5| Step: 5
Training loss: 3.6053378582000732
Validation loss: 3.675101806720098

Epoch: 5| Step: 6
Training loss: 3.533376693725586
Validation loss: 3.6697862446308136

Epoch: 5| Step: 7
Training loss: 3.141072988510132
Validation loss: 3.664570232232412

Epoch: 5| Step: 8
Training loss: 4.013814449310303
Validation loss: 3.6593972643216452

Epoch: 5| Step: 9
Training loss: 4.315886974334717
Validation loss: 3.656003067890803

Epoch: 5| Step: 10
Training loss: 3.537917375564575
Validation loss: 3.650679330031077

Epoch: 5| Step: 11
Training loss: 5.822149276733398
Validation loss: 3.6450707018375397

Epoch: 22| Step: 0
Training loss: 4.4320478439331055
Validation loss: 3.6409997741381326

Epoch: 5| Step: 1
Training loss: 4.3209967613220215
Validation loss: 3.638110190629959

Epoch: 5| Step: 2
Training loss: 5.384426116943359
Validation loss: 3.6316336194674173

Epoch: 5| Step: 3
Training loss: 3.0980238914489746
Validation loss: 3.625832070906957

Epoch: 5| Step: 4
Training loss: 3.5332190990448
Validation loss: 3.6207894384860992

Epoch: 5| Step: 5
Training loss: 2.7799062728881836
Validation loss: 3.6172335346539817

Epoch: 5| Step: 6
Training loss: 4.719064235687256
Validation loss: 3.612755537033081

Epoch: 5| Step: 7
Training loss: 3.7334303855895996
Validation loss: 3.6060198545455933

Epoch: 5| Step: 8
Training loss: 3.025024890899658
Validation loss: 3.600717008113861

Epoch: 5| Step: 9
Training loss: 3.552961826324463
Validation loss: 3.5963435073693595

Epoch: 5| Step: 10
Training loss: 3.114368438720703
Validation loss: 3.592125415802002

Epoch: 5| Step: 11
Training loss: 3.1614766120910645
Validation loss: 3.5868795911471048

Epoch: 23| Step: 0
Training loss: 3.8298282623291016
Validation loss: 3.5817075073719025

Epoch: 5| Step: 1
Training loss: 3.6712119579315186
Validation loss: 3.5756992797056832

Epoch: 5| Step: 2
Training loss: 4.2513017654418945
Validation loss: 3.5709887047608695

Epoch: 5| Step: 3
Training loss: 3.897083282470703
Validation loss: 3.5659223794937134

Epoch: 5| Step: 4
Training loss: 3.365253448486328
Validation loss: 3.561181823412577

Epoch: 5| Step: 5
Training loss: 3.769975185394287
Validation loss: 3.5557886163393655

Epoch: 5| Step: 6
Training loss: 3.307360887527466
Validation loss: 3.550968517859777

Epoch: 5| Step: 7
Training loss: 3.732455015182495
Validation loss: 3.545544683933258

Epoch: 5| Step: 8
Training loss: 3.9538798332214355
Validation loss: 3.5410530666510263

Epoch: 5| Step: 9
Training loss: 3.667565107345581
Validation loss: 3.5353458523750305

Epoch: 5| Step: 10
Training loss: 3.830197811126709
Validation loss: 3.5302477180957794

Epoch: 5| Step: 11
Training loss: 1.9065841436386108
Validation loss: 3.5258151491483054

Epoch: 24| Step: 0
Training loss: 3.726557970046997
Validation loss: 3.5214411417643228

Epoch: 5| Step: 1
Training loss: 3.629495143890381
Validation loss: 3.5164893170197806

Epoch: 5| Step: 2
Training loss: 3.5484423637390137
Validation loss: 3.5117340981960297

Epoch: 5| Step: 3
Training loss: 3.003662586212158
Validation loss: 3.5072314937909446

Epoch: 5| Step: 4
Training loss: 3.9080607891082764
Validation loss: 3.50310218334198

Epoch: 5| Step: 5
Training loss: 4.3553056716918945
Validation loss: 3.4980924328168235

Epoch: 5| Step: 6
Training loss: 3.20318603515625
Validation loss: 3.4938756028811135

Epoch: 5| Step: 7
Training loss: 4.2069292068481445
Validation loss: 3.4884259601434073

Epoch: 5| Step: 8
Training loss: 3.7936248779296875
Validation loss: 3.483008692661921

Epoch: 5| Step: 9
Training loss: 3.9245200157165527
Validation loss: 3.4785702228546143

Epoch: 5| Step: 10
Training loss: 3.3258438110351562
Validation loss: 3.474275370438894

Epoch: 5| Step: 11
Training loss: 2.056894063949585
Validation loss: 3.469592501719793

Epoch: 25| Step: 0
Training loss: 3.6727232933044434
Validation loss: 3.469371577103933

Epoch: 5| Step: 1
Training loss: 3.232645034790039
Validation loss: 3.483502964178721

Epoch: 5| Step: 2
Training loss: 3.1457393169403076
Validation loss: 3.463927040497462

Epoch: 5| Step: 3
Training loss: 3.3827998638153076
Validation loss: 3.452158749103546

Epoch: 5| Step: 4
Training loss: 3.7737038135528564
Validation loss: 3.448178142309189

Epoch: 5| Step: 5
Training loss: 4.066986083984375
Validation loss: 3.4515769680341086

Epoch: 5| Step: 6
Training loss: 3.52929949760437
Validation loss: 3.4465790589650473

Epoch: 5| Step: 7
Training loss: 3.8209526538848877
Validation loss: 3.439720024665197

Epoch: 5| Step: 8
Training loss: 4.050550937652588
Validation loss: 3.4330647587776184

Epoch: 5| Step: 9
Training loss: 3.63435435295105
Validation loss: 3.427427589893341

Epoch: 5| Step: 10
Training loss: 3.388124465942383
Validation loss: 3.421998471021652

Epoch: 5| Step: 11
Training loss: 3.8961849212646484
Validation loss: 3.4182792603969574

Epoch: 26| Step: 0
Training loss: 3.5006847381591797
Validation loss: 3.412408103545507

Epoch: 5| Step: 1
Training loss: 2.9373862743377686
Validation loss: 3.4092260797818503

Epoch: 5| Step: 2
Training loss: 3.4734978675842285
Validation loss: 3.4048454463481903

Epoch: 5| Step: 3
Training loss: 4.498278617858887
Validation loss: 3.401206692059835

Epoch: 5| Step: 4
Training loss: 3.2417633533477783
Validation loss: 3.3953599333763123

Epoch: 5| Step: 5
Training loss: 4.109046936035156
Validation loss: 3.390613943338394

Epoch: 5| Step: 6
Training loss: 3.7562904357910156
Validation loss: 3.3846317529678345

Epoch: 5| Step: 7
Training loss: 3.2123093605041504
Validation loss: 3.3795219262441

Epoch: 5| Step: 8
Training loss: 3.977215528488159
Validation loss: 3.3752593994140625

Epoch: 5| Step: 9
Training loss: 3.3438305854797363
Validation loss: 3.3711167871952057

Epoch: 5| Step: 10
Training loss: 3.4267287254333496
Validation loss: 3.3666909635066986

Epoch: 5| Step: 11
Training loss: 1.844221591949463
Validation loss: 3.362001121044159

Epoch: 27| Step: 0
Training loss: 4.051840782165527
Validation loss: 3.3583302597204843

Epoch: 5| Step: 1
Training loss: 3.6211280822753906
Validation loss: 3.3540271719296775

Epoch: 5| Step: 2
Training loss: 3.8418891429901123
Validation loss: 3.3496786057949066

Epoch: 5| Step: 3
Training loss: 3.5162429809570312
Validation loss: 3.344204584757487

Epoch: 5| Step: 4
Training loss: 3.2353973388671875
Validation loss: 3.340049425760905

Epoch: 5| Step: 5
Training loss: 3.1712167263031006
Validation loss: 3.336147685845693

Epoch: 5| Step: 6
Training loss: 3.9658408164978027
Validation loss: 3.331472953160604

Epoch: 5| Step: 7
Training loss: 2.7006330490112305
Validation loss: 3.3271041015783944

Epoch: 5| Step: 8
Training loss: 3.3256607055664062
Validation loss: 3.323307911554972

Epoch: 5| Step: 9
Training loss: 3.601722002029419
Validation loss: 3.3187906642754874

Epoch: 5| Step: 10
Training loss: 3.6340179443359375
Validation loss: 3.314672609170278

Epoch: 5| Step: 11
Training loss: 3.0790369510650635
Validation loss: 3.3105284571647644

Epoch: 28| Step: 0
Training loss: 4.236398220062256
Validation loss: 3.306435247262319

Epoch: 5| Step: 1
Training loss: 2.913363218307495
Validation loss: 3.302067587773005

Epoch: 5| Step: 2
Training loss: 3.2474403381347656
Validation loss: 3.29774209856987

Epoch: 5| Step: 3
Training loss: 2.974639415740967
Validation loss: 3.293689558903376

Epoch: 5| Step: 4
Training loss: 4.078581809997559
Validation loss: 3.28969677289327

Epoch: 5| Step: 5
Training loss: 3.234952211380005
Validation loss: 3.28510320186615

Epoch: 5| Step: 6
Training loss: 3.274275302886963
Validation loss: 3.2806425591309867

Epoch: 5| Step: 7
Training loss: 3.2071259021759033
Validation loss: 3.2768499553203583

Epoch: 5| Step: 8
Training loss: 3.6264572143554688
Validation loss: 3.2726134657859802

Epoch: 5| Step: 9
Training loss: 4.063159465789795
Validation loss: 3.2684823075930276

Epoch: 5| Step: 10
Training loss: 3.624685764312744
Validation loss: 3.264546106259028

Epoch: 5| Step: 11
Training loss: 1.368614912033081
Validation loss: 3.2610198855400085

Epoch: 29| Step: 0
Training loss: 3.4205551147460938
Validation loss: 3.2560559709866843

Epoch: 5| Step: 1
Training loss: 3.9891529083251953
Validation loss: 3.2517603933811188

Epoch: 5| Step: 2
Training loss: 3.2818920612335205
Validation loss: 3.248190442721049

Epoch: 5| Step: 3
Training loss: 3.799971103668213
Validation loss: 3.242749402920405

Epoch: 5| Step: 4
Training loss: 3.784580945968628
Validation loss: 3.23809082309405

Epoch: 5| Step: 5
Training loss: 3.1882050037384033
Validation loss: 3.2340283195177713

Epoch: 5| Step: 6
Training loss: 3.824246644973755
Validation loss: 3.2300263742605844

Epoch: 5| Step: 7
Training loss: 2.969712257385254
Validation loss: 3.223931839068731

Epoch: 5| Step: 8
Training loss: 3.0301108360290527
Validation loss: 3.2191600104173026

Epoch: 5| Step: 9
Training loss: 2.795020818710327
Validation loss: 3.213939825693766

Epoch: 5| Step: 10
Training loss: 3.5232062339782715
Validation loss: 3.209777216116587

Epoch: 5| Step: 11
Training loss: 3.057197093963623
Validation loss: 3.2056351701418557

Epoch: 30| Step: 0
Training loss: 4.769582271575928
Validation loss: 3.201489528020223

Epoch: 5| Step: 1
Training loss: 2.778071641921997
Validation loss: 3.1968374053637185

Epoch: 5| Step: 2
Training loss: 3.107456922531128
Validation loss: 3.1926954686641693

Epoch: 5| Step: 3
Training loss: 3.3364880084991455
Validation loss: 3.18835911154747

Epoch: 5| Step: 4
Training loss: 3.330839157104492
Validation loss: 3.183710436026255

Epoch: 5| Step: 5
Training loss: 3.1940226554870605
Validation loss: 3.1792187988758087

Epoch: 5| Step: 6
Training loss: 2.8974475860595703
Validation loss: 3.175241361061732

Epoch: 5| Step: 7
Training loss: 3.7652010917663574
Validation loss: 3.1707980732123056

Epoch: 5| Step: 8
Training loss: 3.362595796585083
Validation loss: 3.1667784055074057

Epoch: 5| Step: 9
Training loss: 3.2314651012420654
Validation loss: 3.16225329041481

Epoch: 5| Step: 10
Training loss: 2.909137725830078
Validation loss: 3.158027450243632

Epoch: 5| Step: 11
Training loss: 4.936283588409424
Validation loss: 3.1536650359630585

Epoch: 31| Step: 0
Training loss: 3.2956595420837402
Validation loss: 3.149626851081848

Epoch: 5| Step: 1
Training loss: 2.575587511062622
Validation loss: 3.145948896805445

Epoch: 5| Step: 2
Training loss: 3.612645387649536
Validation loss: 3.1418329874674478

Epoch: 5| Step: 3
Training loss: 2.717041254043579
Validation loss: 3.137490143378576

Epoch: 5| Step: 4
Training loss: 4.029330253601074
Validation loss: 3.1337476074695587

Epoch: 5| Step: 5
Training loss: 2.4724667072296143
Validation loss: 3.1298078993956246

Epoch: 5| Step: 6
Training loss: 3.2425332069396973
Validation loss: 3.1259524325529733

Epoch: 5| Step: 7
Training loss: 3.2906203269958496
Validation loss: 3.1218361953894296

Epoch: 5| Step: 8
Training loss: 3.8934292793273926
Validation loss: 3.118406961361567

Epoch: 5| Step: 9
Training loss: 3.119371175765991
Validation loss: 3.1148164371649423

Epoch: 5| Step: 10
Training loss: 4.055983543395996
Validation loss: 3.110582490762075

Epoch: 5| Step: 11
Training loss: 4.132197380065918
Validation loss: 3.106710741917292

Epoch: 32| Step: 0
Training loss: 2.8924121856689453
Validation loss: 3.102105846007665

Epoch: 5| Step: 1
Training loss: 3.6304619312286377
Validation loss: 3.098330785830816

Epoch: 5| Step: 2
Training loss: 3.387115955352783
Validation loss: 3.0941810806592307

Epoch: 5| Step: 3
Training loss: 3.277585506439209
Validation loss: 3.090365986029307

Epoch: 5| Step: 4
Training loss: 2.419926404953003
Validation loss: 3.086206595102946

Epoch: 5| Step: 5
Training loss: 3.453464984893799
Validation loss: 3.082394520441691

Epoch: 5| Step: 6
Training loss: 3.6536834239959717
Validation loss: 3.0778665244579315

Epoch: 5| Step: 7
Training loss: 3.186026096343994
Validation loss: 3.073600689570109

Epoch: 5| Step: 8
Training loss: 3.106652021408081
Validation loss: 3.0693120261033378

Epoch: 5| Step: 9
Training loss: 3.5627048015594482
Validation loss: 3.0653130312760672

Epoch: 5| Step: 10
Training loss: 3.272223711013794
Validation loss: 3.061474839846293

Epoch: 5| Step: 11
Training loss: 4.016010761260986
Validation loss: 3.0573710799217224

Epoch: 33| Step: 0
Training loss: 3.9782745838165283
Validation loss: 3.0535671512285867

Epoch: 5| Step: 1
Training loss: 3.334725856781006
Validation loss: 3.0499257246653237

Epoch: 5| Step: 2
Training loss: 3.786496639251709
Validation loss: 3.0450997352600098

Epoch: 5| Step: 3
Training loss: 2.428349018096924
Validation loss: 3.041686008373896

Epoch: 5| Step: 4
Training loss: 3.2459449768066406
Validation loss: 3.0367854833602905

Epoch: 5| Step: 5
Training loss: 3.389847993850708
Validation loss: 3.033318723241488

Epoch: 5| Step: 6
Training loss: 2.7396063804626465
Validation loss: 3.029216557741165

Epoch: 5| Step: 7
Training loss: 3.1064083576202393
Validation loss: 3.025790144999822

Epoch: 5| Step: 8
Training loss: 3.244074583053589
Validation loss: 3.0225561360518136

Epoch: 5| Step: 9
Training loss: 3.3121426105499268
Validation loss: 3.018897225459417

Epoch: 5| Step: 10
Training loss: 3.040811538696289
Validation loss: 3.0152160425980887

Epoch: 5| Step: 11
Training loss: 2.5670032501220703
Validation loss: 3.011421948671341

Epoch: 34| Step: 0
Training loss: 2.6845266819000244
Validation loss: 3.007118970155716

Epoch: 5| Step: 1
Training loss: 3.655010223388672
Validation loss: 3.0038080414136252

Epoch: 5| Step: 2
Training loss: 3.51640248298645
Validation loss: 3.000075101852417

Epoch: 5| Step: 3
Training loss: 2.945876121520996
Validation loss: 2.9965417981147766

Epoch: 5| Step: 4
Training loss: 2.9983887672424316
Validation loss: 2.9931273261706033

Epoch: 5| Step: 5
Training loss: 3.156865119934082
Validation loss: 2.9887006978193917

Epoch: 5| Step: 6
Training loss: 2.897770643234253
Validation loss: 2.9870905379454293

Epoch: 5| Step: 7
Training loss: 3.336003065109253
Validation loss: 2.9838641782601676

Epoch: 5| Step: 8
Training loss: 2.93336820602417
Validation loss: 2.9776713053385415

Epoch: 5| Step: 9
Training loss: 3.1923136711120605
Validation loss: 2.9742354452610016

Epoch: 5| Step: 10
Training loss: 3.349278211593628
Validation loss: 2.9709927837053933

Epoch: 5| Step: 11
Training loss: 4.946518421173096
Validation loss: 2.9672977129618325

Epoch: 35| Step: 0
Training loss: 2.9068984985351562
Validation loss: 2.963577518860499

Epoch: 5| Step: 1
Training loss: 3.30668568611145
Validation loss: 2.9598046143849692

Epoch: 5| Step: 2
Training loss: 3.4186160564422607
Validation loss: 2.9557199080785117

Epoch: 5| Step: 3
Training loss: 2.7968082427978516
Validation loss: 2.95187575618426

Epoch: 5| Step: 4
Training loss: 3.609980821609497
Validation loss: 2.94778111577034

Epoch: 5| Step: 5
Training loss: 2.949047565460205
Validation loss: 2.9447822670141854

Epoch: 5| Step: 6
Training loss: 3.6399853229522705
Validation loss: 2.9402157266934714

Epoch: 5| Step: 7
Training loss: 2.693324089050293
Validation loss: 2.936396837234497

Epoch: 5| Step: 8
Training loss: 3.079728364944458
Validation loss: 2.9326496720314026

Epoch: 5| Step: 9
Training loss: 3.338181972503662
Validation loss: 2.929580638806025

Epoch: 5| Step: 10
Training loss: 3.0845885276794434
Validation loss: 2.9259451031684875

Epoch: 5| Step: 11
Training loss: 1.9808580875396729
Validation loss: 2.922604650259018

Epoch: 36| Step: 0
Training loss: 2.602294683456421
Validation loss: 2.9202207724253335

Epoch: 5| Step: 1
Training loss: 2.671668529510498
Validation loss: 2.917984584967295

Epoch: 5| Step: 2
Training loss: 3.320201873779297
Validation loss: 2.914705107609431

Epoch: 5| Step: 3
Training loss: 2.427600383758545
Validation loss: 2.911446879307429

Epoch: 5| Step: 4
Training loss: 3.125319719314575
Validation loss: 2.9071872333685556

Epoch: 5| Step: 5
Training loss: 3.2452354431152344
Validation loss: 2.90294756491979

Epoch: 5| Step: 6
Training loss: 3.5433852672576904
Validation loss: 2.8998523155848184

Epoch: 5| Step: 7
Training loss: 3.5375359058380127
Validation loss: 2.8956712782382965

Epoch: 5| Step: 8
Training loss: 3.5027523040771484
Validation loss: 2.893827180067698

Epoch: 5| Step: 9
Training loss: 3.058166980743408
Validation loss: 2.8927253683408103

Epoch: 5| Step: 10
Training loss: 3.1441073417663574
Validation loss: 2.8905222316583

Epoch: 5| Step: 11
Training loss: 3.1233773231506348
Validation loss: 2.8868723809719086

Epoch: 37| Step: 0
Training loss: 3.194007396697998
Validation loss: 2.8816282550493875

Epoch: 5| Step: 1
Training loss: 2.7622761726379395
Validation loss: 2.87689146399498

Epoch: 5| Step: 2
Training loss: 2.8660802841186523
Validation loss: 2.8739193181196847

Epoch: 5| Step: 3
Training loss: 2.963803768157959
Validation loss: 2.8727227995793023

Epoch: 5| Step: 4
Training loss: 2.787841320037842
Validation loss: 2.8699402610460916

Epoch: 5| Step: 5
Training loss: 3.1428565979003906
Validation loss: 2.866678863763809

Epoch: 5| Step: 6
Training loss: 3.397965908050537
Validation loss: 2.8640108505884805

Epoch: 5| Step: 7
Training loss: 3.753100872039795
Validation loss: 2.861020634571711

Epoch: 5| Step: 8
Training loss: 3.1476287841796875
Validation loss: 2.8571610848108926

Epoch: 5| Step: 9
Training loss: 2.827195167541504
Validation loss: 2.8547155459721885

Epoch: 5| Step: 10
Training loss: 2.8172640800476074
Validation loss: 2.850851913293203

Epoch: 5| Step: 11
Training loss: 3.8547794818878174
Validation loss: 2.848523418108622

Epoch: 38| Step: 0
Training loss: 3.395004987716675
Validation loss: 2.845399151245753

Epoch: 5| Step: 1
Training loss: 3.027135133743286
Validation loss: 2.8417568703492484

Epoch: 5| Step: 2
Training loss: 2.7668356895446777
Validation loss: 2.8390813569227853

Epoch: 5| Step: 3
Training loss: 2.8771564960479736
Validation loss: 2.8350330938895545

Epoch: 5| Step: 4
Training loss: 3.500288486480713
Validation loss: 2.83059890071551

Epoch: 5| Step: 5
Training loss: 3.293564558029175
Validation loss: 2.8272760808467865

Epoch: 5| Step: 6
Training loss: 3.165658712387085
Validation loss: 2.8236490885416665

Epoch: 5| Step: 7
Training loss: 2.81709623336792
Validation loss: 2.820145775874456

Epoch: 5| Step: 8
Training loss: 2.769446611404419
Validation loss: 2.8162720998128257

Epoch: 5| Step: 9
Training loss: 3.087270736694336
Validation loss: 2.814233193794886

Epoch: 5| Step: 10
Training loss: 2.772991180419922
Validation loss: 2.8112621903419495

Epoch: 5| Step: 11
Training loss: 2.9081783294677734
Validation loss: 2.808773418267568

Epoch: 39| Step: 0
Training loss: 2.9923393726348877
Validation loss: 2.806154708067576

Epoch: 5| Step: 1
Training loss: 3.681337833404541
Validation loss: 2.803191989660263

Epoch: 5| Step: 2
Training loss: 2.297325611114502
Validation loss: 2.8007074892520905

Epoch: 5| Step: 3
Training loss: 3.055335760116577
Validation loss: 2.797087957461675

Epoch: 5| Step: 4
Training loss: 2.443988561630249
Validation loss: 2.7938486437002816

Epoch: 5| Step: 5
Training loss: 3.772350788116455
Validation loss: 2.7917191088199615

Epoch: 5| Step: 6
Training loss: 3.795762538909912
Validation loss: 2.787978162368139

Epoch: 5| Step: 7
Training loss: 2.998561143875122
Validation loss: 2.7844938337802887

Epoch: 5| Step: 8
Training loss: 2.722679853439331
Validation loss: 2.7820983131726584

Epoch: 5| Step: 9
Training loss: 2.5104689598083496
Validation loss: 2.7779058516025543

Epoch: 5| Step: 10
Training loss: 2.824331045150757
Validation loss: 2.775164167086283

Epoch: 5| Step: 11
Training loss: 2.731785297393799
Validation loss: 2.7725434005260468

Epoch: 40| Step: 0
Training loss: 3.001677989959717
Validation loss: 2.770201086997986

Epoch: 5| Step: 1
Training loss: 2.680370569229126
Validation loss: 2.7679659326871238

Epoch: 5| Step: 2
Training loss: 2.703556537628174
Validation loss: 2.765285094579061

Epoch: 5| Step: 3
Training loss: 2.681387186050415
Validation loss: 2.7630470792452493

Epoch: 5| Step: 4
Training loss: 3.1288981437683105
Validation loss: 2.7601855595906577

Epoch: 5| Step: 5
Training loss: 3.2053725719451904
Validation loss: 2.7576285302639008

Epoch: 5| Step: 6
Training loss: 2.8014957904815674
Validation loss: 2.754433959722519

Epoch: 5| Step: 7
Training loss: 3.1678898334503174
Validation loss: 2.7524653673171997

Epoch: 5| Step: 8
Training loss: 3.549298048019409
Validation loss: 2.7503491640090942

Epoch: 5| Step: 9
Training loss: 3.4683265686035156
Validation loss: 2.7466525534788766

Epoch: 5| Step: 10
Training loss: 2.14201283454895
Validation loss: 2.7435831129550934

Epoch: 5| Step: 11
Training loss: 3.570084571838379
Validation loss: 2.740510791540146

Epoch: 41| Step: 0
Training loss: 2.7027475833892822
Validation loss: 2.7386727233727775

Epoch: 5| Step: 1
Training loss: 2.745889663696289
Validation loss: 2.7389359772205353

Epoch: 5| Step: 2
Training loss: 3.26263689994812
Validation loss: 2.7333456178506217

Epoch: 5| Step: 3
Training loss: 2.3800387382507324
Validation loss: 2.730611647168795

Epoch: 5| Step: 4
Training loss: 3.2197518348693848
Validation loss: 2.726659526427587

Epoch: 5| Step: 5
Training loss: 3.3095481395721436
Validation loss: 2.7243484059969583

Epoch: 5| Step: 6
Training loss: 2.7185134887695312
Validation loss: 2.722596218188604

Epoch: 5| Step: 7
Training loss: 3.292581081390381
Validation loss: 2.720813433329264

Epoch: 5| Step: 8
Training loss: 2.87610125541687
Validation loss: 2.7184687157471976

Epoch: 5| Step: 9
Training loss: 3.0265953540802
Validation loss: 2.7155424853165946

Epoch: 5| Step: 10
Training loss: 2.658360004425049
Validation loss: 2.712738166252772

Epoch: 5| Step: 11
Training loss: 3.3371634483337402
Validation loss: 2.7096987267335257

Epoch: 42| Step: 0
Training loss: 2.9198250770568848
Validation loss: 2.7071229815483093

Epoch: 5| Step: 1
Training loss: 2.9064154624938965
Validation loss: 2.704064150651296

Epoch: 5| Step: 2
Training loss: 2.5646979808807373
Validation loss: 2.7010369300842285

Epoch: 5| Step: 3
Training loss: 2.7331037521362305
Validation loss: 2.6981382966041565

Epoch: 5| Step: 4
Training loss: 2.8747122287750244
Validation loss: 2.6935511430104575

Epoch: 5| Step: 5
Training loss: 3.316551923751831
Validation loss: 2.691472033659617

Epoch: 5| Step: 6
Training loss: 3.342491626739502
Validation loss: 2.688517242670059

Epoch: 5| Step: 7
Training loss: 3.0844788551330566
Validation loss: 2.684607515732447

Epoch: 5| Step: 8
Training loss: 3.168142795562744
Validation loss: 2.6805625557899475

Epoch: 5| Step: 9
Training loss: 2.5028748512268066
Validation loss: 2.6793728868166604

Epoch: 5| Step: 10
Training loss: 2.5456833839416504
Validation loss: 2.6755510667959848

Epoch: 5| Step: 11
Training loss: 2.5193142890930176
Validation loss: 2.6741364200909934

Epoch: 43| Step: 0
Training loss: 3.0891518592834473
Validation loss: 2.6719924012819924

Epoch: 5| Step: 1
Training loss: 2.943469762802124
Validation loss: 2.6712373246749244

Epoch: 5| Step: 2
Training loss: 3.2001426219940186
Validation loss: 2.672608037789663

Epoch: 5| Step: 3
Training loss: 3.155510425567627
Validation loss: 2.663815051317215

Epoch: 5| Step: 4
Training loss: 3.654550552368164
Validation loss: 2.659571478764216

Epoch: 5| Step: 5
Training loss: 3.0587868690490723
Validation loss: 2.6550765534241996

Epoch: 5| Step: 6
Training loss: 2.159620761871338
Validation loss: 2.6533137063185372

Epoch: 5| Step: 7
Training loss: 2.261157989501953
Validation loss: 2.651008903980255

Epoch: 5| Step: 8
Training loss: 2.3605988025665283
Validation loss: 2.650231738885244

Epoch: 5| Step: 9
Training loss: 2.398510217666626
Validation loss: 2.649445374806722

Epoch: 5| Step: 10
Training loss: 3.0441339015960693
Validation loss: 2.6480537255605063

Epoch: 5| Step: 11
Training loss: 3.660386085510254
Validation loss: 2.6454808513323465

Epoch: 44| Step: 0
Training loss: 2.7060272693634033
Validation loss: 2.640632818142573

Epoch: 5| Step: 1
Training loss: 2.7891221046447754
Validation loss: 2.6358609398206077

Epoch: 5| Step: 2
Training loss: 3.117260217666626
Validation loss: 2.632126490275065

Epoch: 5| Step: 3
Training loss: 2.3523950576782227
Validation loss: 2.628445823987325

Epoch: 5| Step: 4
Training loss: 2.9988961219787598
Validation loss: 2.624281277259191

Epoch: 5| Step: 5
Training loss: 3.1633777618408203
Validation loss: 2.6217089196046195

Epoch: 5| Step: 6
Training loss: 3.1936757564544678
Validation loss: 2.620434651772181

Epoch: 5| Step: 7
Training loss: 3.4132847785949707
Validation loss: 2.6170490384101868

Epoch: 5| Step: 8
Training loss: 2.82820200920105
Validation loss: 2.61378143231074

Epoch: 5| Step: 9
Training loss: 1.9977610111236572
Validation loss: 2.6114954153696694

Epoch: 5| Step: 10
Training loss: 2.654545783996582
Validation loss: 2.6096181521813073

Epoch: 5| Step: 11
Training loss: 2.2465872764587402
Validation loss: 2.608593612909317

Epoch: 45| Step: 0
Training loss: 2.021178722381592
Validation loss: 2.604293614625931

Epoch: 5| Step: 1
Training loss: 2.6827189922332764
Validation loss: 2.602006177107493

Epoch: 5| Step: 2
Training loss: 3.087120294570923
Validation loss: 2.5969080924987793

Epoch: 5| Step: 3
Training loss: 2.292656660079956
Validation loss: 2.5922712137301764

Epoch: 5| Step: 4
Training loss: 3.2356231212615967
Validation loss: 2.5905284186204276

Epoch: 5| Step: 5
Training loss: 2.7197651863098145
Validation loss: 2.5879163344701133

Epoch: 5| Step: 6
Training loss: 3.4376251697540283
Validation loss: 2.5857351322968802

Epoch: 5| Step: 7
Training loss: 2.9290611743927
Validation loss: 2.5834720134735107

Epoch: 5| Step: 8
Training loss: 2.1973092555999756
Validation loss: 2.5816399455070496

Epoch: 5| Step: 9
Training loss: 2.5731968879699707
Validation loss: 2.5793088376522064

Epoch: 5| Step: 10
Training loss: 3.487726926803589
Validation loss: 2.57618156572183

Epoch: 5| Step: 11
Training loss: 2.9298155307769775
Validation loss: 2.5745056668917337

Epoch: 46| Step: 0
Training loss: 3.015533447265625
Validation loss: 2.569967339436213

Epoch: 5| Step: 1
Training loss: 2.3244619369506836
Validation loss: 2.5665950179100037

Epoch: 5| Step: 2
Training loss: 2.736841917037964
Validation loss: 2.5644673109054565

Epoch: 5| Step: 3
Training loss: 2.4089741706848145
Validation loss: 2.5615786015987396

Epoch: 5| Step: 4
Training loss: 3.1035540103912354
Validation loss: 2.55849888920784

Epoch: 5| Step: 5
Training loss: 2.815098762512207
Validation loss: 2.5566161473592124

Epoch: 5| Step: 6
Training loss: 3.125035524368286
Validation loss: 2.5536073644955954

Epoch: 5| Step: 7
Training loss: 3.178929090499878
Validation loss: 2.5499419569969177

Epoch: 5| Step: 8
Training loss: 2.1917812824249268
Validation loss: 2.547402282555898

Epoch: 5| Step: 9
Training loss: 2.3907580375671387
Validation loss: 2.544524133205414

Epoch: 5| Step: 10
Training loss: 2.982940912246704
Validation loss: 2.542697717746099

Epoch: 5| Step: 11
Training loss: 2.924229145050049
Validation loss: 2.538904199997584

Epoch: 47| Step: 0
Training loss: 2.8111732006073
Validation loss: 2.5368080039819083

Epoch: 5| Step: 1
Training loss: 2.348618745803833
Validation loss: 2.534180223941803

Epoch: 5| Step: 2
Training loss: 2.5630927085876465
Validation loss: 2.5315779546896615

Epoch: 5| Step: 3
Training loss: 2.9455113410949707
Validation loss: 2.528665602207184

Epoch: 5| Step: 4
Training loss: 2.3423101902008057
Validation loss: 2.526367962360382

Epoch: 5| Step: 5
Training loss: 2.9968156814575195
Validation loss: 2.5227168798446655

Epoch: 5| Step: 6
Training loss: 2.6811652183532715
Validation loss: 2.520473966995875

Epoch: 5| Step: 7
Training loss: 2.637678623199463
Validation loss: 2.5178410907586417

Epoch: 5| Step: 8
Training loss: 2.7942585945129395
Validation loss: 2.516145040591558

Epoch: 5| Step: 9
Training loss: 2.6471571922302246
Validation loss: 2.512358844280243

Epoch: 5| Step: 10
Training loss: 2.91135311126709
Validation loss: 2.510037178794543

Epoch: 5| Step: 11
Training loss: 3.9098827838897705
Validation loss: 2.507804920276006

Epoch: 48| Step: 0
Training loss: 2.549889087677002
Validation loss: 2.5041650583346686

Epoch: 5| Step: 1
Training loss: 2.785778045654297
Validation loss: 2.5017309884230294

Epoch: 5| Step: 2
Training loss: 2.677394390106201
Validation loss: 2.4991491685311

Epoch: 5| Step: 3
Training loss: 3.731734037399292
Validation loss: 2.4967047770818076

Epoch: 5| Step: 4
Training loss: 2.560807704925537
Validation loss: 2.4939328531424203

Epoch: 5| Step: 5
Training loss: 2.696622371673584
Validation loss: 2.4910503029823303

Epoch: 5| Step: 6
Training loss: 2.763770580291748
Validation loss: 2.4874439239501953

Epoch: 5| Step: 7
Training loss: 2.4579498767852783
Validation loss: 2.4854899744192758

Epoch: 5| Step: 8
Training loss: 2.4882500171661377
Validation loss: 2.481441537539164

Epoch: 5| Step: 9
Training loss: 2.3725790977478027
Validation loss: 2.4800940255324044

Epoch: 5| Step: 10
Training loss: 2.6050541400909424
Validation loss: 2.4785596628983817

Epoch: 5| Step: 11
Training loss: 1.95265531539917
Validation loss: 2.4762769093116126

Epoch: 49| Step: 0
Training loss: 2.23176646232605
Validation loss: 2.474039008220037

Epoch: 5| Step: 1
Training loss: 2.9644088745117188
Validation loss: 2.47266016403834

Epoch: 5| Step: 2
Training loss: 2.1166365146636963
Validation loss: 2.46758179863294

Epoch: 5| Step: 3
Training loss: 2.4018654823303223
Validation loss: 2.462307016054789

Epoch: 5| Step: 4
Training loss: 2.849414348602295
Validation loss: 2.4630922774473825

Epoch: 5| Step: 5
Training loss: 2.8995490074157715
Validation loss: 2.4618318478266397

Epoch: 5| Step: 6
Training loss: 3.3682379722595215
Validation loss: 2.4578509430090585

Epoch: 5| Step: 7
Training loss: 2.5954818725585938
Validation loss: 2.4560059309005737

Epoch: 5| Step: 8
Training loss: 2.536166191101074
Validation loss: 2.453492005666097

Epoch: 5| Step: 9
Training loss: 2.4964497089385986
Validation loss: 2.4509941836198172

Epoch: 5| Step: 10
Training loss: 2.764417886734009
Validation loss: 2.4494508306185403

Epoch: 5| Step: 11
Training loss: 2.3957884311676025
Validation loss: 2.4461155086755753

Epoch: 50| Step: 0
Training loss: 2.309156894683838
Validation loss: 2.4445523420969644

Epoch: 5| Step: 1
Training loss: 2.6648616790771484
Validation loss: 2.453534781932831

Epoch: 5| Step: 2
Training loss: 3.1955134868621826
Validation loss: 2.4383799533049264

Epoch: 5| Step: 3
Training loss: 2.9884321689605713
Validation loss: 2.435088853041331

Epoch: 5| Step: 4
Training loss: 2.5040924549102783
Validation loss: 2.434355288743973

Epoch: 5| Step: 5
Training loss: 2.572732448577881
Validation loss: 2.4339431126912436

Epoch: 5| Step: 6
Training loss: 2.509913682937622
Validation loss: 2.432375739018122

Epoch: 5| Step: 7
Training loss: 2.3425254821777344
Validation loss: 2.4309055705865226

Epoch: 5| Step: 8
Training loss: 2.519353151321411
Validation loss: 2.426645795504252

Epoch: 5| Step: 9
Training loss: 2.942889451980591
Validation loss: 2.422748605410258

Epoch: 5| Step: 10
Training loss: 2.152261257171631
Validation loss: 2.4172146320343018

Epoch: 5| Step: 11
Training loss: 3.4120469093322754
Validation loss: 2.416601538658142

Epoch: 51| Step: 0
Training loss: 2.7714362144470215
Validation loss: 2.411582405368487

Epoch: 5| Step: 1
Training loss: 2.6799190044403076
Validation loss: 2.408538301785787

Epoch: 5| Step: 2
Training loss: 2.608165740966797
Validation loss: 2.407369236151377

Epoch: 5| Step: 3
Training loss: 2.8479530811309814
Validation loss: 2.4052525659402213

Epoch: 5| Step: 4
Training loss: 2.080831289291382
Validation loss: 2.4029810031255088

Epoch: 5| Step: 5
Training loss: 2.3713440895080566
Validation loss: 2.4005731443564096

Epoch: 5| Step: 6
Training loss: 2.9762744903564453
Validation loss: 2.402734249830246

Epoch: 5| Step: 7
Training loss: 2.570530891418457
Validation loss: 2.4122126499811807

Epoch: 5| Step: 8
Training loss: 2.3957438468933105
Validation loss: 2.411943922440211

Epoch: 5| Step: 9
Training loss: 2.798736333847046
Validation loss: 2.399144947528839

Epoch: 5| Step: 10
Training loss: 2.4442245960235596
Validation loss: 2.3915970623493195

Epoch: 5| Step: 11
Training loss: 2.4217140674591064
Validation loss: 2.3893556048472724

Epoch: 52| Step: 0
Training loss: 2.9167823791503906
Validation loss: 2.3902160028616586

Epoch: 5| Step: 1
Training loss: 2.0495657920837402
Validation loss: 2.391706943511963

Epoch: 5| Step: 2
Training loss: 1.8792415857315063
Validation loss: 2.3912288546562195

Epoch: 5| Step: 3
Training loss: 2.531364917755127
Validation loss: 2.3911002973715463

Epoch: 5| Step: 4
Training loss: 2.539024829864502
Validation loss: 2.389514168103536

Epoch: 5| Step: 5
Training loss: 2.7950103282928467
Validation loss: 2.386911913752556

Epoch: 5| Step: 6
Training loss: 2.3235042095184326
Validation loss: 2.383606861035029

Epoch: 5| Step: 7
Training loss: 3.105797529220581
Validation loss: 2.3791920145352683

Epoch: 5| Step: 8
Training loss: 3.0293662548065186
Validation loss: 2.3761134843031564

Epoch: 5| Step: 9
Training loss: 2.1187992095947266
Validation loss: 2.3705993394056954

Epoch: 5| Step: 10
Training loss: 3.048466444015503
Validation loss: 2.367440859476725

Epoch: 5| Step: 11
Training loss: 1.664737582206726
Validation loss: 2.36278028289477

Epoch: 53| Step: 0
Training loss: 2.184863328933716
Validation loss: 2.3606497397025428

Epoch: 5| Step: 1
Training loss: 3.1044325828552246
Validation loss: 2.3577319184939065

Epoch: 5| Step: 2
Training loss: 2.447603940963745
Validation loss: 2.35632586479187

Epoch: 5| Step: 3
Training loss: 2.550997018814087
Validation loss: 2.353635390599569

Epoch: 5| Step: 4
Training loss: 1.7486358880996704
Validation loss: 2.350998262564341

Epoch: 5| Step: 5
Training loss: 2.2469911575317383
Validation loss: 2.3474056323369346

Epoch: 5| Step: 6
Training loss: 2.3042681217193604
Validation loss: 2.3466195166110992

Epoch: 5| Step: 7
Training loss: 2.53822922706604
Validation loss: 2.347360630830129

Epoch: 5| Step: 8
Training loss: 3.2058053016662598
Validation loss: 2.343830188115438

Epoch: 5| Step: 9
Training loss: 2.634138584136963
Validation loss: 2.3396416703859964

Epoch: 5| Step: 10
Training loss: 3.0437631607055664
Validation loss: 2.336666335662206

Epoch: 5| Step: 11
Training loss: 1.4269059896469116
Validation loss: 2.3349764247735343

Epoch: 54| Step: 0
Training loss: 2.3365542888641357
Validation loss: 2.3340538243452706

Epoch: 5| Step: 1
Training loss: 1.787322998046875
Validation loss: 2.3312959571679435

Epoch: 5| Step: 2
Training loss: 2.800912380218506
Validation loss: 2.331222494443258

Epoch: 5| Step: 3
Training loss: 2.9088335037231445
Validation loss: 2.331340402364731

Epoch: 5| Step: 4
Training loss: 2.569272756576538
Validation loss: 2.3283321857452393

Epoch: 5| Step: 5
Training loss: 2.6654276847839355
Validation loss: 2.327310154835383

Epoch: 5| Step: 6
Training loss: 2.579500913619995
Validation loss: 2.3258576889832816

Epoch: 5| Step: 7
Training loss: 1.8281759023666382
Validation loss: 2.3236039578914642

Epoch: 5| Step: 8
Training loss: 2.2758970260620117
Validation loss: 2.3214371701081595

Epoch: 5| Step: 9
Training loss: 3.049828290939331
Validation loss: 2.3180826703707376

Epoch: 5| Step: 10
Training loss: 2.448399543762207
Validation loss: 2.3147764454285302

Epoch: 5| Step: 11
Training loss: 3.7047410011291504
Validation loss: 2.308983991543452

Epoch: 55| Step: 0
Training loss: 2.7589244842529297
Validation loss: 2.308830956617991

Epoch: 5| Step: 1
Training loss: 2.7134737968444824
Validation loss: 2.3039872348308563

Epoch: 5| Step: 2
Training loss: 1.501694679260254
Validation loss: 2.3093729317188263

Epoch: 5| Step: 3
Training loss: 2.7904975414276123
Validation loss: 2.30063559114933

Epoch: 5| Step: 4
Training loss: 2.5488390922546387
Validation loss: 2.293541128436724

Epoch: 5| Step: 5
Training loss: 2.8676517009735107
Validation loss: 2.2929620246092477

Epoch: 5| Step: 6
Training loss: 2.5650570392608643
Validation loss: 2.2989889681339264

Epoch: 5| Step: 7
Training loss: 2.22556734085083
Validation loss: 2.29269540309906

Epoch: 5| Step: 8
Training loss: 2.615140438079834
Validation loss: 2.2902415096759796

Epoch: 5| Step: 9
Training loss: 1.9815505743026733
Validation loss: 2.287531097730001

Epoch: 5| Step: 10
Training loss: 2.764758586883545
Validation loss: 2.286524792512258

Epoch: 5| Step: 11
Training loss: 1.668593168258667
Validation loss: 2.282800863186518

Epoch: 56| Step: 0
Training loss: 2.379995822906494
Validation loss: 2.283528079589208

Epoch: 5| Step: 1
Training loss: 2.317863702774048
Validation loss: 2.282889187335968

Epoch: 5| Step: 2
Training loss: 2.9499447345733643
Validation loss: 2.280579258998235

Epoch: 5| Step: 3
Training loss: 1.9582411050796509
Validation loss: 2.2797076801458993

Epoch: 5| Step: 4
Training loss: 2.064774513244629
Validation loss: 2.277422378460566

Epoch: 5| Step: 5
Training loss: 2.7127208709716797
Validation loss: 2.2738913893699646

Epoch: 5| Step: 6
Training loss: 2.733682155609131
Validation loss: 2.272227555513382

Epoch: 5| Step: 7
Training loss: 2.154585361480713
Validation loss: 2.2695168207089105

Epoch: 5| Step: 8
Training loss: 3.1590983867645264
Validation loss: 2.2662674884001413

Epoch: 5| Step: 9
Training loss: 1.6580314636230469
Validation loss: 2.2646462619304657

Epoch: 5| Step: 10
Training loss: 2.674048900604248
Validation loss: 2.2602675457795462

Epoch: 5| Step: 11
Training loss: 2.774702548980713
Validation loss: 2.2590802212556205

Epoch: 57| Step: 0
Training loss: 2.5386910438537598
Validation loss: 2.2574957410494485

Epoch: 5| Step: 1
Training loss: 2.435908317565918
Validation loss: 2.255165755748749

Epoch: 5| Step: 2
Training loss: 2.2043700218200684
Validation loss: 2.254935214916865

Epoch: 5| Step: 3
Training loss: 2.553074359893799
Validation loss: 2.254240393638611

Epoch: 5| Step: 4
Training loss: 2.6566460132598877
Validation loss: 2.2515036265055337

Epoch: 5| Step: 5
Training loss: 2.1386749744415283
Validation loss: 2.2436784406503043

Epoch: 5| Step: 6
Training loss: 2.1725640296936035
Validation loss: 2.2415588100751243

Epoch: 5| Step: 7
Training loss: 2.531601667404175
Validation loss: 2.240339626868566

Epoch: 5| Step: 8
Training loss: 2.622267484664917
Validation loss: 2.2373773554960885

Epoch: 5| Step: 9
Training loss: 2.549164295196533
Validation loss: 2.238932172457377

Epoch: 5| Step: 10
Training loss: 2.2099883556365967
Validation loss: 2.237454354763031

Epoch: 5| Step: 11
Training loss: 1.8401597738265991
Validation loss: 2.2342668871084848

Epoch: 58| Step: 0
Training loss: 1.9721813201904297
Validation loss: 2.242401277025541

Epoch: 5| Step: 1
Training loss: 2.6098694801330566
Validation loss: 2.2549364070097604

Epoch: 5| Step: 2
Training loss: 2.0674452781677246
Validation loss: 2.256962021191915

Epoch: 5| Step: 3
Training loss: 2.3549931049346924
Validation loss: 2.253721982240677

Epoch: 5| Step: 4
Training loss: 1.9901297092437744
Validation loss: 2.2425651252269745

Epoch: 5| Step: 5
Training loss: 2.517796754837036
Validation loss: 2.22955829401811

Epoch: 5| Step: 6
Training loss: 2.5051755905151367
Validation loss: 2.2241324484348297

Epoch: 5| Step: 7
Training loss: 2.250811815261841
Validation loss: 2.2278353373209634

Epoch: 5| Step: 8
Training loss: 2.7524611949920654
Validation loss: 2.22606227795283

Epoch: 5| Step: 9
Training loss: 3.232332706451416
Validation loss: 2.2281574805577598

Epoch: 5| Step: 10
Training loss: 2.22639799118042
Validation loss: 2.2226373106241226

Epoch: 5| Step: 11
Training loss: 1.76014244556427
Validation loss: 2.2226551920175552

Epoch: 59| Step: 0
Training loss: 3.038238286972046
Validation loss: 2.217821637789408

Epoch: 5| Step: 1
Training loss: 2.6228384971618652
Validation loss: 2.2143599838018417

Epoch: 5| Step: 2
Training loss: 2.7226290702819824
Validation loss: 2.211895098288854

Epoch: 5| Step: 3
Training loss: 2.107125997543335
Validation loss: 2.21048296491305

Epoch: 5| Step: 4
Training loss: 2.0732715129852295
Validation loss: 2.2062286039193473

Epoch: 5| Step: 5
Training loss: 1.2015405893325806
Validation loss: 2.205345610777537

Epoch: 5| Step: 6
Training loss: 2.145120620727539
Validation loss: 2.201946049928665

Epoch: 5| Step: 7
Training loss: 2.707645893096924
Validation loss: 2.2027042458454766

Epoch: 5| Step: 8
Training loss: 2.4012298583984375
Validation loss: 2.1988882025082908

Epoch: 5| Step: 9
Training loss: 2.763057231903076
Validation loss: 2.1999282290538154

Epoch: 5| Step: 10
Training loss: 2.0284323692321777
Validation loss: 2.20186377565066

Epoch: 5| Step: 11
Training loss: 3.566863536834717
Validation loss: 2.199265643954277

Epoch: 60| Step: 0
Training loss: 2.6023738384246826
Validation loss: 2.1944283892711005

Epoch: 5| Step: 1
Training loss: 1.363647699356079
Validation loss: 2.194311032692591

Epoch: 5| Step: 2
Training loss: 2.617917537689209
Validation loss: 2.1934255957603455

Epoch: 5| Step: 3
Training loss: 2.564133882522583
Validation loss: 2.1924656430880227

Epoch: 5| Step: 4
Training loss: 2.333444118499756
Validation loss: 2.190609574317932

Epoch: 5| Step: 5
Training loss: 2.274181604385376
Validation loss: 2.1857910652955375

Epoch: 5| Step: 6
Training loss: 2.7422757148742676
Validation loss: 2.1842781404654183

Epoch: 5| Step: 7
Training loss: 2.8322415351867676
Validation loss: 2.182721421122551

Epoch: 5| Step: 8
Training loss: 2.464857816696167
Validation loss: 2.1822276810805

Epoch: 5| Step: 9
Training loss: 1.7214857339859009
Validation loss: 2.185301219423612

Epoch: 5| Step: 10
Training loss: 2.285964012145996
Validation loss: 2.186177978912989

Epoch: 5| Step: 11
Training loss: 2.581845760345459
Validation loss: 2.1832732260227203

Epoch: 61| Step: 0
Training loss: 2.212388277053833
Validation loss: 2.182790696620941

Epoch: 5| Step: 1
Training loss: 2.3257815837860107
Validation loss: 2.1812630792458854

Epoch: 5| Step: 2
Training loss: 2.3866755962371826
Validation loss: 2.181002969543139

Epoch: 5| Step: 3
Training loss: 2.5192854404449463
Validation loss: 2.173655559619268

Epoch: 5| Step: 4
Training loss: 2.397486925125122
Validation loss: 2.1724918136994043

Epoch: 5| Step: 5
Training loss: 2.4330852031707764
Validation loss: 2.1688762406508126

Epoch: 5| Step: 6
Training loss: 1.9473991394042969
Validation loss: 2.1651096095641456

Epoch: 5| Step: 7
Training loss: 2.3518357276916504
Validation loss: 2.1628255198399224

Epoch: 5| Step: 8
Training loss: 2.4331514835357666
Validation loss: 2.1651551524798074

Epoch: 5| Step: 9
Training loss: 2.4055938720703125
Validation loss: 2.165786882241567

Epoch: 5| Step: 10
Training loss: 2.4010379314422607
Validation loss: 2.1689112186431885

Epoch: 5| Step: 11
Training loss: 2.238694906234741
Validation loss: 2.162751535574595

Epoch: 62| Step: 0
Training loss: 2.616939067840576
Validation loss: 2.1611135800679526

Epoch: 5| Step: 1
Training loss: 2.398343563079834
Validation loss: 2.1607612321774163

Epoch: 5| Step: 2
Training loss: 2.128506660461426
Validation loss: 2.1555134455362954

Epoch: 5| Step: 3
Training loss: 2.037605047225952
Validation loss: 2.1552274028460183

Epoch: 5| Step: 4
Training loss: 2.680540084838867
Validation loss: 2.1560172041257224

Epoch: 5| Step: 5
Training loss: 2.595214366912842
Validation loss: 2.1586912920077643

Epoch: 5| Step: 6
Training loss: 1.4946954250335693
Validation loss: 2.1574211567640305

Epoch: 5| Step: 7
Training loss: 2.654151201248169
Validation loss: 2.157003258665403

Epoch: 5| Step: 8
Training loss: 2.3776326179504395
Validation loss: 2.157676085829735

Epoch: 5| Step: 9
Training loss: 2.457123041152954
Validation loss: 2.153884842991829

Epoch: 5| Step: 10
Training loss: 2.2794251441955566
Validation loss: 2.1522948294878006

Epoch: 5| Step: 11
Training loss: 2.1852200031280518
Validation loss: 2.151086618502935

Epoch: 63| Step: 0
Training loss: 1.9989423751831055
Validation loss: 2.145234947403272

Epoch: 5| Step: 1
Training loss: 2.55474853515625
Validation loss: 2.144828816254934

Epoch: 5| Step: 2
Training loss: 2.0848889350891113
Validation loss: 2.1426549752553306

Epoch: 5| Step: 3
Training loss: 2.7848739624023438
Validation loss: 2.143070633212725

Epoch: 5| Step: 4
Training loss: 1.7330995798110962
Validation loss: 2.1407832503318787

Epoch: 5| Step: 5
Training loss: 1.8697383403778076
Validation loss: 2.1400837500890098

Epoch: 5| Step: 6
Training loss: 2.187966823577881
Validation loss: 2.141138265530268

Epoch: 5| Step: 7
Training loss: 2.617340564727783
Validation loss: 2.142300729950269

Epoch: 5| Step: 8
Training loss: 2.736635446548462
Validation loss: 2.1429973989725113

Epoch: 5| Step: 9
Training loss: 2.5684316158294678
Validation loss: 2.1337825606266656

Epoch: 5| Step: 10
Training loss: 2.5530648231506348
Validation loss: 2.1343626230955124

Epoch: 5| Step: 11
Training loss: 1.4116108417510986
Validation loss: 2.1286407858133316

Epoch: 64| Step: 0
Training loss: 2.227634906768799
Validation loss: 2.134184628725052

Epoch: 5| Step: 1
Training loss: 2.5213723182678223
Validation loss: 2.1316593339045844

Epoch: 5| Step: 2
Training loss: 2.4536805152893066
Validation loss: 2.1315653175115585

Epoch: 5| Step: 3
Training loss: 2.192333698272705
Validation loss: 2.1325414727131524

Epoch: 5| Step: 4
Training loss: 2.178744077682495
Validation loss: 2.129181315501531

Epoch: 5| Step: 5
Training loss: 2.582810878753662
Validation loss: 2.134722058971723

Epoch: 5| Step: 6
Training loss: 2.195782423019409
Validation loss: 2.1290642817815146

Epoch: 5| Step: 7
Training loss: 2.8085155487060547
Validation loss: 2.1281299889087677

Epoch: 5| Step: 8
Training loss: 1.9448268413543701
Validation loss: 2.122405548890432

Epoch: 5| Step: 9
Training loss: 2.456109046936035
Validation loss: 2.1176680574814477

Epoch: 5| Step: 10
Training loss: 1.6783618927001953
Validation loss: 2.120323027173678

Epoch: 5| Step: 11
Training loss: 2.8996949195861816
Validation loss: 2.1235396762688956

Epoch: 65| Step: 0
Training loss: 2.128441095352173
Validation loss: 2.1263875315586724

Epoch: 5| Step: 1
Training loss: 2.0558974742889404
Validation loss: 2.128413031498591

Epoch: 5| Step: 2
Training loss: 2.756993055343628
Validation loss: 2.1278821726640067

Epoch: 5| Step: 3
Training loss: 2.1448636054992676
Validation loss: 2.1266447007656097

Epoch: 5| Step: 4
Training loss: 1.9760830402374268
Validation loss: 2.126875266432762

Epoch: 5| Step: 5
Training loss: 2.004427671432495
Validation loss: 2.12000880142053

Epoch: 5| Step: 6
Training loss: 2.7482151985168457
Validation loss: 2.121867756048838

Epoch: 5| Step: 7
Training loss: 2.5358364582061768
Validation loss: 2.1203734229008355

Epoch: 5| Step: 8
Training loss: 2.7336695194244385
Validation loss: 2.1187291890382767

Epoch: 5| Step: 9
Training loss: 2.228243350982666
Validation loss: 2.1239682336648307

Epoch: 5| Step: 10
Training loss: 2.2507715225219727
Validation loss: 2.121961017449697

Epoch: 5| Step: 11
Training loss: 1.2572190761566162
Validation loss: 2.1182228724161782

Epoch: 66| Step: 0
Training loss: 1.7591640949249268
Validation loss: 2.112096851070722

Epoch: 5| Step: 1
Training loss: 2.906139850616455
Validation loss: 2.1124430298805237

Epoch: 5| Step: 2
Training loss: 2.029738426208496
Validation loss: 2.115213304758072

Epoch: 5| Step: 3
Training loss: 2.6463687419891357
Validation loss: 2.1102233082056046

Epoch: 5| Step: 4
Training loss: 2.1135201454162598
Validation loss: 2.111667568484942

Epoch: 5| Step: 5
Training loss: 2.6985154151916504
Validation loss: 2.1141715546449027

Epoch: 5| Step: 6
Training loss: 2.1097629070281982
Validation loss: 2.113879715402921

Epoch: 5| Step: 7
Training loss: 2.3008666038513184
Validation loss: 2.1123230357964835

Epoch: 5| Step: 8
Training loss: 1.9358837604522705
Validation loss: 2.113249803582827

Epoch: 5| Step: 9
Training loss: 2.1334121227264404
Validation loss: 2.1071714907884598

Epoch: 5| Step: 10
Training loss: 2.4838271141052246
Validation loss: 2.1070863902568817

Epoch: 5| Step: 11
Training loss: 2.6136245727539062
Validation loss: 2.101805403828621

Epoch: 67| Step: 0
Training loss: 2.0612833499908447
Validation loss: 2.10433059434096

Epoch: 5| Step: 1
Training loss: 2.270265579223633
Validation loss: 2.1094405204057693

Epoch: 5| Step: 2
Training loss: 2.5244734287261963
Validation loss: 2.1177672495444617

Epoch: 5| Step: 3
Training loss: 2.518416404724121
Validation loss: 2.113204136490822

Epoch: 5| Step: 4
Training loss: 1.9457261562347412
Validation loss: 2.116940975189209

Epoch: 5| Step: 5
Training loss: 2.3358349800109863
Validation loss: 2.1038442899783454

Epoch: 5| Step: 6
Training loss: 2.2646234035491943
Validation loss: 2.0951165556907654

Epoch: 5| Step: 7
Training loss: 2.1593902111053467
Validation loss: 2.0918660710255303

Epoch: 5| Step: 8
Training loss: 1.7242275476455688
Validation loss: 2.097869868079821

Epoch: 5| Step: 9
Training loss: 2.432742118835449
Validation loss: 2.0958985139926276

Epoch: 5| Step: 10
Training loss: 2.8711559772491455
Validation loss: 2.0942446241776147

Epoch: 5| Step: 11
Training loss: 1.9810365438461304
Validation loss: 2.096402123570442

Epoch: 68| Step: 0
Training loss: 2.168915271759033
Validation loss: 2.0952503085136414

Epoch: 5| Step: 1
Training loss: 2.162675142288208
Validation loss: 2.0966152052084603

Epoch: 5| Step: 2
Training loss: 2.422762393951416
Validation loss: 2.094905272126198

Epoch: 5| Step: 3
Training loss: 2.1228928565979004
Validation loss: 2.095244233806928

Epoch: 5| Step: 4
Training loss: 2.416649580001831
Validation loss: 2.0904604444901147

Epoch: 5| Step: 5
Training loss: 2.361076831817627
Validation loss: 2.0892302890618644

Epoch: 5| Step: 6
Training loss: 2.173555850982666
Validation loss: 2.090740824739138

Epoch: 5| Step: 7
Training loss: 2.5078608989715576
Validation loss: 2.0869423200686774

Epoch: 5| Step: 8
Training loss: 2.148545503616333
Validation loss: 2.086857189734777

Epoch: 5| Step: 9
Training loss: 2.2981317043304443
Validation loss: 2.0835393021504083

Epoch: 5| Step: 10
Training loss: 2.1926615238189697
Validation loss: 2.084786742925644

Epoch: 5| Step: 11
Training loss: 2.0487570762634277
Validation loss: 2.075689141949018

Epoch: 69| Step: 0
Training loss: 2.5711140632629395
Validation loss: 2.086711431543032

Epoch: 5| Step: 1
Training loss: 2.4035067558288574
Validation loss: 2.092834477623304

Epoch: 5| Step: 2
Training loss: 2.657668113708496
Validation loss: 2.0971157997846603

Epoch: 5| Step: 3
Training loss: 1.70132577419281
Validation loss: 2.1021690368652344

Epoch: 5| Step: 4
Training loss: 2.123145580291748
Validation loss: 2.1144241293271384

Epoch: 5| Step: 5
Training loss: 2.278174877166748
Validation loss: 2.1110410590966544

Epoch: 5| Step: 6
Training loss: 2.3103044033050537
Validation loss: 2.1018931021293006

Epoch: 5| Step: 7
Training loss: 2.5120601654052734
Validation loss: 2.0881839195887246

Epoch: 5| Step: 8
Training loss: 2.352461338043213
Validation loss: 2.0850661247968674

Epoch: 5| Step: 9
Training loss: 2.488443374633789
Validation loss: 2.0793151756127677

Epoch: 5| Step: 10
Training loss: 1.7988996505737305
Validation loss: 2.077945187687874

Epoch: 5| Step: 11
Training loss: 1.4517136812210083
Validation loss: 2.0770088682572045

Epoch: 70| Step: 0
Training loss: 2.4053032398223877
Validation loss: 2.0757643630107245

Epoch: 5| Step: 1
Training loss: 2.3515448570251465
Validation loss: 2.08120296895504

Epoch: 5| Step: 2
Training loss: 2.4301514625549316
Validation loss: 2.080655559897423

Epoch: 5| Step: 3
Training loss: 2.3049607276916504
Validation loss: 2.0780676851669946

Epoch: 5| Step: 4
Training loss: 1.9879264831542969
Validation loss: 2.0757322907447815

Epoch: 5| Step: 5
Training loss: 2.3150253295898438
Validation loss: 2.070972512165705

Epoch: 5| Step: 6
Training loss: 2.244823932647705
Validation loss: 2.0645482192436853

Epoch: 5| Step: 7
Training loss: 2.089768886566162
Validation loss: 2.0649499893188477

Epoch: 5| Step: 8
Training loss: 2.353846549987793
Validation loss: 2.0638095239798226

Epoch: 5| Step: 9
Training loss: 2.3406002521514893
Validation loss: 2.063150425752004

Epoch: 5| Step: 10
Training loss: 2.250446319580078
Validation loss: 2.0589104493459067

Epoch: 5| Step: 11
Training loss: 0.8003435134887695
Validation loss: 2.062874029080073

Epoch: 71| Step: 0
Training loss: 2.9210238456726074
Validation loss: 2.0607191622257233

Epoch: 5| Step: 1
Training loss: 2.367746353149414
Validation loss: 2.058637102444967

Epoch: 5| Step: 2
Training loss: 2.249978542327881
Validation loss: 2.05661171178023

Epoch: 5| Step: 3
Training loss: 2.004072666168213
Validation loss: 2.0585563629865646

Epoch: 5| Step: 4
Training loss: 2.488312244415283
Validation loss: 2.0595032374064126

Epoch: 5| Step: 5
Training loss: 2.299229383468628
Validation loss: 2.0652223030726113

Epoch: 5| Step: 6
Training loss: 2.3781611919403076
Validation loss: 2.063686673839887

Epoch: 5| Step: 7
Training loss: 2.0993521213531494
Validation loss: 2.062461793422699

Epoch: 5| Step: 8
Training loss: 1.9648624658584595
Validation loss: 2.06159841020902

Epoch: 5| Step: 9
Training loss: 2.0620663166046143
Validation loss: 2.0583463360865912

Epoch: 5| Step: 10
Training loss: 1.8470842838287354
Validation loss: 2.0610699504613876

Epoch: 5| Step: 11
Training loss: 2.3983960151672363
Validation loss: 2.05397463341554

Epoch: 72| Step: 0
Training loss: 2.0087673664093018
Validation loss: 2.0543938080469766

Epoch: 5| Step: 1
Training loss: 3.1469523906707764
Validation loss: 2.0527248879273734

Epoch: 5| Step: 2
Training loss: 2.0608458518981934
Validation loss: 2.0563149551550546

Epoch: 5| Step: 3
Training loss: 2.804321765899658
Validation loss: 2.0485006918509803

Epoch: 5| Step: 4
Training loss: 2.446350574493408
Validation loss: 2.0500321884950004

Epoch: 5| Step: 5
Training loss: 2.146682024002075
Validation loss: 2.0492502252260842

Epoch: 5| Step: 6
Training loss: 2.316707134246826
Validation loss: 2.0452065070470176

Epoch: 5| Step: 7
Training loss: 1.5385167598724365
Validation loss: 2.044073427716891

Epoch: 5| Step: 8
Training loss: 2.02645206451416
Validation loss: 2.04643481473128

Epoch: 5| Step: 9
Training loss: 2.1504733562469482
Validation loss: 2.043600171804428

Epoch: 5| Step: 10
Training loss: 1.9697586297988892
Validation loss: 2.0523363004128137

Epoch: 5| Step: 11
Training loss: 1.7993953227996826
Validation loss: 2.050897796948751

Epoch: 73| Step: 0
Training loss: 2.6055760383605957
Validation loss: 2.051339695851008

Epoch: 5| Step: 1
Training loss: 2.366692066192627
Validation loss: 2.0460200756788254

Epoch: 5| Step: 2
Training loss: 2.157924175262451
Validation loss: 2.054158349831899

Epoch: 5| Step: 3
Training loss: 2.201465129852295
Validation loss: 2.0426433036724725

Epoch: 5| Step: 4
Training loss: 2.1171066761016846
Validation loss: 2.044187252720197

Epoch: 5| Step: 5
Training loss: 2.721243381500244
Validation loss: 2.0364781071742377

Epoch: 5| Step: 6
Training loss: 2.1692593097686768
Validation loss: 2.0452301849921546

Epoch: 5| Step: 7
Training loss: 1.5983858108520508
Validation loss: 2.0439798335234323

Epoch: 5| Step: 8
Training loss: 2.698103904724121
Validation loss: 2.0421885401010513

Epoch: 5| Step: 9
Training loss: 2.0850799083709717
Validation loss: 2.0478276362021766

Epoch: 5| Step: 10
Training loss: 1.790381669998169
Validation loss: 2.0499648799498877

Epoch: 5| Step: 11
Training loss: 2.341493606567383
Validation loss: 2.0508767465750375

Epoch: 74| Step: 0
Training loss: 1.8590532541275024
Validation loss: 2.0477796296278634

Epoch: 5| Step: 1
Training loss: 2.3942863941192627
Validation loss: 2.045743376016617

Epoch: 5| Step: 2
Training loss: 2.2785303592681885
Validation loss: 2.0479630629221597

Epoch: 5| Step: 3
Training loss: 2.559478282928467
Validation loss: 2.0340431729952493

Epoch: 5| Step: 4
Training loss: 1.8953300714492798
Validation loss: 2.0397234112024307

Epoch: 5| Step: 5
Training loss: 2.522843837738037
Validation loss: 2.034474939107895

Epoch: 5| Step: 6
Training loss: 2.2105021476745605
Validation loss: 2.042139912645022

Epoch: 5| Step: 7
Training loss: 2.3833775520324707
Validation loss: 2.041206493973732

Epoch: 5| Step: 8
Training loss: 2.55425763130188
Validation loss: 2.0439025511344275

Epoch: 5| Step: 9
Training loss: 2.113774538040161
Validation loss: 2.0495402465264

Epoch: 5| Step: 10
Training loss: 1.8234269618988037
Validation loss: 2.0466532905896506

Epoch: 5| Step: 11
Training loss: 1.9308146238327026
Validation loss: 2.0525847921768823

Epoch: 75| Step: 0
Training loss: 2.045342206954956
Validation loss: 2.068864583969116

Epoch: 5| Step: 1
Training loss: 2.316164016723633
Validation loss: 2.0799996902545295

Epoch: 5| Step: 2
Training loss: 2.250223398208618
Validation loss: 2.089350536465645

Epoch: 5| Step: 3
Training loss: 2.509495258331299
Validation loss: 2.0899141331513724

Epoch: 5| Step: 4
Training loss: 2.1831908226013184
Validation loss: 2.0845863670110703

Epoch: 5| Step: 5
Training loss: 2.1745593547821045
Validation loss: 2.0837400605281196

Epoch: 5| Step: 6
Training loss: 2.3591744899749756
Validation loss: 2.0788954198360443

Epoch: 5| Step: 7
Training loss: 2.201016664505005
Validation loss: 2.065609961748123

Epoch: 5| Step: 8
Training loss: 1.9126777648925781
Validation loss: 2.0568009416262307

Epoch: 5| Step: 9
Training loss: 2.5393261909484863
Validation loss: 2.0531586656967797

Epoch: 5| Step: 10
Training loss: 2.5078089237213135
Validation loss: 2.053294767936071

Epoch: 5| Step: 11
Training loss: 0.9437922239303589
Validation loss: 2.048738196492195

Epoch: 76| Step: 0
Training loss: 3.1095194816589355
Validation loss: 2.044460892677307

Epoch: 5| Step: 1
Training loss: 2.617457866668701
Validation loss: 2.0450071543455124

Epoch: 5| Step: 2
Training loss: 2.101853847503662
Validation loss: 2.051320637265841

Epoch: 5| Step: 3
Training loss: 1.5836349725723267
Validation loss: 2.0510114481051764

Epoch: 5| Step: 4
Training loss: 2.3565635681152344
Validation loss: 2.0506044030189514

Epoch: 5| Step: 5
Training loss: 2.1589741706848145
Validation loss: 2.041847988963127

Epoch: 5| Step: 6
Training loss: 2.2423949241638184
Validation loss: 2.035814901192983

Epoch: 5| Step: 7
Training loss: 2.472872257232666
Validation loss: 2.0379790564378104

Epoch: 5| Step: 8
Training loss: 2.0871124267578125
Validation loss: 2.032163833578428

Epoch: 5| Step: 9
Training loss: 1.4927436113357544
Validation loss: 2.0260539005200067

Epoch: 5| Step: 10
Training loss: 2.2035129070281982
Validation loss: 2.0294848680496216

Epoch: 5| Step: 11
Training loss: 2.723066806793213
Validation loss: 2.030245771010717

Epoch: 77| Step: 0
Training loss: 2.1813926696777344
Validation loss: 2.0249793281157813

Epoch: 5| Step: 1
Training loss: 1.6654056310653687
Validation loss: 2.03640508155028

Epoch: 5| Step: 2
Training loss: 2.361863851547241
Validation loss: 2.040931830803553

Epoch: 5| Step: 3
Training loss: 2.1901137828826904
Validation loss: 2.0398921420176825

Epoch: 5| Step: 4
Training loss: 2.4388675689697266
Validation loss: 2.0496779332558313

Epoch: 5| Step: 5
Training loss: 2.1353020668029785
Validation loss: 2.0514618853727975

Epoch: 5| Step: 6
Training loss: 1.7264760732650757
Validation loss: 2.05906680226326

Epoch: 5| Step: 7
Training loss: 2.739255666732788
Validation loss: 2.059905245900154

Epoch: 5| Step: 8
Training loss: 2.0741758346557617
Validation loss: 2.062936082482338

Epoch: 5| Step: 9
Training loss: 2.3145763874053955
Validation loss: 2.058203692237536

Epoch: 5| Step: 10
Training loss: 2.7421669960021973
Validation loss: 2.0494496126969657

Epoch: 5| Step: 11
Training loss: 2.2112417221069336
Validation loss: 2.0467555622259774

Epoch: 78| Step: 0
Training loss: 2.6299285888671875
Validation loss: 2.0472373167673745

Epoch: 5| Step: 1
Training loss: 2.247102737426758
Validation loss: 2.041507358352343

Epoch: 5| Step: 2
Training loss: 2.1105988025665283
Validation loss: 2.041760196288427

Epoch: 5| Step: 3
Training loss: 2.22717547416687
Validation loss: 2.038562367359797

Epoch: 5| Step: 4
Training loss: 1.7393066883087158
Validation loss: 2.03807199994723

Epoch: 5| Step: 5
Training loss: 2.316821575164795
Validation loss: 2.0314482003450394

Epoch: 5| Step: 6
Training loss: 2.3186659812927246
Validation loss: 2.0316004554430642

Epoch: 5| Step: 7
Training loss: 1.8034673929214478
Validation loss: 2.0299471418062844

Epoch: 5| Step: 8
Training loss: 2.6872472763061523
Validation loss: 2.0221877147754035

Epoch: 5| Step: 9
Training loss: 2.1940712928771973
Validation loss: 2.0313554108142853

Epoch: 5| Step: 10
Training loss: 2.058720111846924
Validation loss: 2.025119756658872

Epoch: 5| Step: 11
Training loss: 2.188438892364502
Validation loss: 2.025634522239367

Epoch: 79| Step: 0
Training loss: 2.3553519248962402
Validation loss: 2.027285009622574

Epoch: 5| Step: 1
Training loss: 1.8172481060028076
Validation loss: 2.023658658067385

Epoch: 5| Step: 2
Training loss: 2.5564191341400146
Validation loss: 2.0233409653107324

Epoch: 5| Step: 3
Training loss: 2.781362533569336
Validation loss: 2.0242865532636642

Epoch: 5| Step: 4
Training loss: 2.1840574741363525
Validation loss: 2.0263154208660126

Epoch: 5| Step: 5
Training loss: 2.1110098361968994
Validation loss: 2.0255355685949326

Epoch: 5| Step: 6
Training loss: 2.1037826538085938
Validation loss: 2.0257150679826736

Epoch: 5| Step: 7
Training loss: 1.9041948318481445
Validation loss: 2.0299663841724396

Epoch: 5| Step: 8
Training loss: 2.344266176223755
Validation loss: 2.0317404915889106

Epoch: 5| Step: 9
Training loss: 2.3045005798339844
Validation loss: 2.0294276972611747

Epoch: 5| Step: 10
Training loss: 1.8385833501815796
Validation loss: 2.027437428633372

Epoch: 5| Step: 11
Training loss: 2.275054454803467
Validation loss: 2.0251560459534326

Epoch: 80| Step: 0
Training loss: 1.6438229084014893
Validation loss: 2.0272592355807624

Epoch: 5| Step: 1
Training loss: 2.22369384765625
Validation loss: 2.026925270756086

Epoch: 5| Step: 2
Training loss: 2.3774123191833496
Validation loss: 2.0280785461266837

Epoch: 5| Step: 3
Training loss: 2.700753688812256
Validation loss: 2.0255632201830545

Epoch: 5| Step: 4
Training loss: 2.1818156242370605
Validation loss: 2.0238178819417953

Epoch: 5| Step: 5
Training loss: 2.2970850467681885
Validation loss: 2.02631605664889

Epoch: 5| Step: 6
Training loss: 2.4604105949401855
Validation loss: 2.021099716424942

Epoch: 5| Step: 7
Training loss: 1.888624906539917
Validation loss: 2.021600698431333

Epoch: 5| Step: 8
Training loss: 2.465707302093506
Validation loss: 2.0193405002355576

Epoch: 5| Step: 9
Training loss: 2.376598358154297
Validation loss: 2.0220217804114022

Epoch: 5| Step: 10
Training loss: 1.565943956375122
Validation loss: 2.0168100198109946

Epoch: 5| Step: 11
Training loss: 2.480989694595337
Validation loss: 2.018215368191401

Epoch: 81| Step: 0
Training loss: 1.7476866245269775
Validation loss: 2.021915098031362

Epoch: 5| Step: 1
Training loss: 2.95550799369812
Validation loss: 2.021185035506884

Epoch: 5| Step: 2
Training loss: 2.0141777992248535
Validation loss: 2.0131810853878656

Epoch: 5| Step: 3
Training loss: 2.355260133743286
Validation loss: 2.0213949382305145

Epoch: 5| Step: 4
Training loss: 2.1281685829162598
Validation loss: 2.018774628639221

Epoch: 5| Step: 5
Training loss: 2.3611578941345215
Validation loss: 2.01914752026399

Epoch: 5| Step: 6
Training loss: 1.959972620010376
Validation loss: 2.016357034444809

Epoch: 5| Step: 7
Training loss: 2.226609945297241
Validation loss: 2.0095458080371222

Epoch: 5| Step: 8
Training loss: 1.8747243881225586
Validation loss: 2.011601040760676

Epoch: 5| Step: 9
Training loss: 2.4744467735290527
Validation loss: 2.0173895557721457

Epoch: 5| Step: 10
Training loss: 2.0180160999298096
Validation loss: 2.0072111835082374

Epoch: 5| Step: 11
Training loss: 2.415083169937134
Validation loss: 2.013708601395289

Epoch: 82| Step: 0
Training loss: 1.845483422279358
Validation loss: 2.0136868258317313

Epoch: 5| Step: 1
Training loss: 1.642007827758789
Validation loss: 2.0219444930553436

Epoch: 5| Step: 2
Training loss: 1.980543851852417
Validation loss: 2.0190538316965103

Epoch: 5| Step: 3
Training loss: 2.232156991958618
Validation loss: 2.0101128419240317

Epoch: 5| Step: 4
Training loss: 2.8907737731933594
Validation loss: 2.016776889562607

Epoch: 5| Step: 5
Training loss: 2.291987180709839
Validation loss: 2.015648990869522

Epoch: 5| Step: 6
Training loss: 2.13472318649292
Validation loss: 2.0157012244065604

Epoch: 5| Step: 7
Training loss: 1.9926612377166748
Validation loss: 2.020144840081533

Epoch: 5| Step: 8
Training loss: 2.3139688968658447
Validation loss: 2.02063395579656

Epoch: 5| Step: 9
Training loss: 2.541339635848999
Validation loss: 2.0274182309707007

Epoch: 5| Step: 10
Training loss: 2.1076157093048096
Validation loss: 2.0283854802449546

Epoch: 5| Step: 11
Training loss: 2.772106647491455
Validation loss: 2.018107384443283

Epoch: 83| Step: 0
Training loss: 2.1267974376678467
Validation loss: 2.0366026361783347

Epoch: 5| Step: 1
Training loss: 1.8924312591552734
Validation loss: 2.0403296103080115

Epoch: 5| Step: 2
Training loss: 2.7350287437438965
Validation loss: 2.0522181540727615

Epoch: 5| Step: 3
Training loss: 2.298250913619995
Validation loss: 2.0535973807175956

Epoch: 5| Step: 4
Training loss: 2.073531150817871
Validation loss: 2.0433017313480377

Epoch: 5| Step: 5
Training loss: 2.1997787952423096
Validation loss: 2.0414281487464905

Epoch: 5| Step: 6
Training loss: 2.2691757678985596
Validation loss: 2.016963799794515

Epoch: 5| Step: 7
Training loss: 2.344252586364746
Validation loss: 2.020190874735514

Epoch: 5| Step: 8
Training loss: 1.828155517578125
Validation loss: 2.0143155604600906

Epoch: 5| Step: 9
Training loss: 1.7917190790176392
Validation loss: 2.0126168529192605

Epoch: 5| Step: 10
Training loss: 2.567349910736084
Validation loss: 2.0134894301493964

Epoch: 5| Step: 11
Training loss: 2.45951509475708
Validation loss: 2.0190512438615165

Epoch: 84| Step: 0
Training loss: 2.1597917079925537
Validation loss: 2.018921966354052

Epoch: 5| Step: 1
Training loss: 2.646707057952881
Validation loss: 2.0222067683935165

Epoch: 5| Step: 2
Training loss: 2.3455700874328613
Validation loss: 2.022909382979075

Epoch: 5| Step: 3
Training loss: 1.8592021465301514
Validation loss: 2.029499883453051

Epoch: 5| Step: 4
Training loss: 2.5177903175354004
Validation loss: 2.0257268796364465

Epoch: 5| Step: 5
Training loss: 2.071967601776123
Validation loss: 2.0315786401430764

Epoch: 5| Step: 6
Training loss: 1.8539177179336548
Validation loss: 2.0275342812140784

Epoch: 5| Step: 7
Training loss: 1.9490222930908203
Validation loss: 2.0275275707244873

Epoch: 5| Step: 8
Training loss: 2.400970935821533
Validation loss: 2.0145299832026162

Epoch: 5| Step: 9
Training loss: 2.1834168434143066
Validation loss: 2.010456398129463

Epoch: 5| Step: 10
Training loss: 2.196423053741455
Validation loss: 2.0146880199511847

Epoch: 5| Step: 11
Training loss: 1.7627947330474854
Validation loss: 2.0159062494834266

Epoch: 85| Step: 0
Training loss: 2.0239648818969727
Validation loss: 2.0086450030406318

Epoch: 5| Step: 1
Training loss: 2.53157114982605
Validation loss: 2.011492391427358

Epoch: 5| Step: 2
Training loss: 2.0174946784973145
Validation loss: 2.0094224562247596

Epoch: 5| Step: 3
Training loss: 2.1518750190734863
Validation loss: 2.0111252268155417

Epoch: 5| Step: 4
Training loss: 2.055100202560425
Validation loss: 2.0083949168523154

Epoch: 5| Step: 5
Training loss: 2.0377984046936035
Validation loss: 2.0098008463780084

Epoch: 5| Step: 6
Training loss: 2.1296448707580566
Validation loss: 2.0118316064278283

Epoch: 5| Step: 7
Training loss: 2.294710874557495
Validation loss: 2.0090946704149246

Epoch: 5| Step: 8
Training loss: 2.349416971206665
Validation loss: 2.02003313601017

Epoch: 5| Step: 9
Training loss: 2.364845037460327
Validation loss: 2.021429101626078

Epoch: 5| Step: 10
Training loss: 2.0549674034118652
Validation loss: 2.0181188782056174

Epoch: 5| Step: 11
Training loss: 2.000175952911377
Validation loss: 2.0224243104457855

Epoch: 86| Step: 0
Training loss: 2.2525811195373535
Validation loss: 2.0128466735283532

Epoch: 5| Step: 1
Training loss: 2.3750240802764893
Validation loss: 2.01388680934906

Epoch: 5| Step: 2
Training loss: 2.5760207176208496
Validation loss: 2.005659287174543

Epoch: 5| Step: 3
Training loss: 2.4415924549102783
Validation loss: 2.0052492171525955

Epoch: 5| Step: 4
Training loss: 2.2309792041778564
Validation loss: 2.015584240357081

Epoch: 5| Step: 5
Training loss: 1.7629880905151367
Validation loss: 2.019370878736178

Epoch: 5| Step: 6
Training loss: 2.430543899536133
Validation loss: 2.02168045938015

Epoch: 5| Step: 7
Training loss: 1.906191110610962
Validation loss: 2.0225439170996347

Epoch: 5| Step: 8
Training loss: 2.361558437347412
Validation loss: 2.0213729540506997

Epoch: 5| Step: 9
Training loss: 1.7825520038604736
Validation loss: 2.015519713362058

Epoch: 5| Step: 10
Training loss: 1.7687000036239624
Validation loss: 2.015020042657852

Epoch: 5| Step: 11
Training loss: 3.0328798294067383
Validation loss: 2.006811281045278

Epoch: 87| Step: 0
Training loss: 2.1923046112060547
Validation loss: 2.010139216979345

Epoch: 5| Step: 1
Training loss: 2.343787908554077
Validation loss: 2.0151206254959106

Epoch: 5| Step: 2
Training loss: 2.4095571041107178
Validation loss: 2.013642594218254

Epoch: 5| Step: 3
Training loss: 2.6560258865356445
Validation loss: 2.0163991997639337

Epoch: 5| Step: 4
Training loss: 2.5194334983825684
Validation loss: 2.0237534791231155

Epoch: 5| Step: 5
Training loss: 1.54714035987854
Validation loss: 2.021816983819008

Epoch: 5| Step: 6
Training loss: 1.940712332725525
Validation loss: 2.026544918616613

Epoch: 5| Step: 7
Training loss: 1.997227430343628
Validation loss: 2.0326336920261383

Epoch: 5| Step: 8
Training loss: 1.7225029468536377
Validation loss: 2.033881122867266

Epoch: 5| Step: 9
Training loss: 2.2842376232147217
Validation loss: 2.0261273632446923

Epoch: 5| Step: 10
Training loss: 2.05885910987854
Validation loss: 2.021742661794027

Epoch: 5| Step: 11
Training loss: 2.7406296730041504
Validation loss: 2.021026382843653

Epoch: 88| Step: 0
Training loss: 2.5693697929382324
Validation loss: 2.025258556008339

Epoch: 5| Step: 1
Training loss: 2.2640457153320312
Validation loss: 2.014640361070633

Epoch: 5| Step: 2
Training loss: 2.373145580291748
Validation loss: 2.0147349337736764

Epoch: 5| Step: 3
Training loss: 2.2660434246063232
Validation loss: 2.015004833539327

Epoch: 5| Step: 4
Training loss: 2.0089054107666016
Validation loss: 2.010260452826818

Epoch: 5| Step: 5
Training loss: 2.1489527225494385
Validation loss: 2.0033083260059357

Epoch: 5| Step: 6
Training loss: 2.382512092590332
Validation loss: 2.005485345919927

Epoch: 5| Step: 7
Training loss: 1.8700382709503174
Validation loss: 2.0108702232440314

Epoch: 5| Step: 8
Training loss: 2.0650317668914795
Validation loss: 2.0065575341383615

Epoch: 5| Step: 9
Training loss: 1.9504106044769287
Validation loss: 2.008819063504537

Epoch: 5| Step: 10
Training loss: 2.0036656856536865
Validation loss: 2.005674218138059

Epoch: 5| Step: 11
Training loss: 2.167819023132324
Validation loss: 2.010777329405149

Epoch: 89| Step: 0
Training loss: 1.9875030517578125
Validation loss: 2.0029945770899453

Epoch: 5| Step: 1
Training loss: 2.678194046020508
Validation loss: 2.0208607216676078

Epoch: 5| Step: 2
Training loss: 2.35649037361145
Validation loss: 2.026491791009903

Epoch: 5| Step: 3
Training loss: 1.7751655578613281
Validation loss: 2.026484121878942

Epoch: 5| Step: 4
Training loss: 2.1532530784606934
Validation loss: 2.035611947377523

Epoch: 5| Step: 5
Training loss: 2.3240573406219482
Validation loss: 2.023748974005381

Epoch: 5| Step: 6
Training loss: 2.0338478088378906
Validation loss: 2.0289108951886496

Epoch: 5| Step: 7
Training loss: 2.2926275730133057
Validation loss: 2.030240625143051

Epoch: 5| Step: 8
Training loss: 1.4965591430664062
Validation loss: 2.0263023475805917

Epoch: 5| Step: 9
Training loss: 2.327193260192871
Validation loss: 2.0217273235321045

Epoch: 5| Step: 10
Training loss: 2.4998979568481445
Validation loss: 2.0121341794729233

Epoch: 5| Step: 11
Training loss: 1.4467884302139282
Validation loss: 2.0089738170305886

Epoch: 90| Step: 0
Training loss: 2.1690890789031982
Validation loss: 2.0128764708836875

Epoch: 5| Step: 1
Training loss: 2.2102150917053223
Validation loss: 2.017031172911326

Epoch: 5| Step: 2
Training loss: 2.1408305168151855
Validation loss: 2.0112042923768363

Epoch: 5| Step: 3
Training loss: 1.8205598592758179
Validation loss: 2.016590893268585

Epoch: 5| Step: 4
Training loss: 2.0986523628234863
Validation loss: 2.0122048606475196

Epoch: 5| Step: 5
Training loss: 1.870714783668518
Validation loss: 2.0101411938667297

Epoch: 5| Step: 6
Training loss: 2.2598989009857178
Validation loss: 2.0140363723039627

Epoch: 5| Step: 7
Training loss: 1.9688926935195923
Validation loss: 2.0237889687220254

Epoch: 5| Step: 8
Training loss: 2.414771556854248
Validation loss: 2.02355387310187

Epoch: 5| Step: 9
Training loss: 2.079786777496338
Validation loss: 2.0221191545327506

Epoch: 5| Step: 10
Training loss: 2.4642908573150635
Validation loss: 2.0191079129775367

Epoch: 5| Step: 11
Training loss: 2.5080769062042236
Validation loss: 2.012699340780576

Epoch: 91| Step: 0
Training loss: 2.1700031757354736
Validation loss: 2.018689746658007

Epoch: 5| Step: 1
Training loss: 1.9045448303222656
Validation loss: 2.0085148761669793

Epoch: 5| Step: 2
Training loss: 2.298870801925659
Validation loss: 2.011404976248741

Epoch: 5| Step: 3
Training loss: 2.270134449005127
Validation loss: 2.007392962773641

Epoch: 5| Step: 4
Training loss: 1.7071218490600586
Validation loss: 2.0061548401912055

Epoch: 5| Step: 5
Training loss: 2.3764564990997314
Validation loss: 2.010891556739807

Epoch: 5| Step: 6
Training loss: 2.6495394706726074
Validation loss: 2.0097987254460654

Epoch: 5| Step: 7
Training loss: 2.231459140777588
Validation loss: 2.0173005362351737

Epoch: 5| Step: 8
Training loss: 2.0142836570739746
Validation loss: 2.028528099258741

Epoch: 5| Step: 9
Training loss: 1.6689345836639404
Validation loss: 2.0349718828996024

Epoch: 5| Step: 10
Training loss: 2.2496025562286377
Validation loss: 2.0419958035151162

Epoch: 5| Step: 11
Training loss: 2.693897008895874
Validation loss: 2.0477140794197717

Epoch: 92| Step: 0
Training loss: 1.7300968170166016
Validation loss: 2.0829334606726966

Epoch: 5| Step: 1
Training loss: 1.9453659057617188
Validation loss: 2.115868846575419

Epoch: 5| Step: 2
Training loss: 2.647902727127075
Validation loss: 2.1288874646027884

Epoch: 5| Step: 3
Training loss: 2.195225238800049
Validation loss: 2.122926781574885

Epoch: 5| Step: 4
Training loss: 2.4006145000457764
Validation loss: 2.098674714565277

Epoch: 5| Step: 5
Training loss: 2.753884792327881
Validation loss: 2.080912118156751

Epoch: 5| Step: 6
Training loss: 2.649228572845459
Validation loss: 2.0587698171536126

Epoch: 5| Step: 7
Training loss: 1.5929772853851318
Validation loss: 2.03140094379584

Epoch: 5| Step: 8
Training loss: 2.1937763690948486
Validation loss: 2.017407571276029

Epoch: 5| Step: 9
Training loss: 2.4423205852508545
Validation loss: 2.0138187607129416

Epoch: 5| Step: 10
Training loss: 1.9003331661224365
Validation loss: 2.0075920124848685

Epoch: 5| Step: 11
Training loss: 1.8672726154327393
Validation loss: 2.0002755473057428

Epoch: 93| Step: 0
Training loss: 2.193725109100342
Validation loss: 2.0099320660034814

Epoch: 5| Step: 1
Training loss: 2.1362948417663574
Validation loss: 2.0170163214206696

Epoch: 5| Step: 2
Training loss: 2.956882953643799
Validation loss: 2.0160553654034934

Epoch: 5| Step: 3
Training loss: 2.213850498199463
Validation loss: 2.0193960269292197

Epoch: 5| Step: 4
Training loss: 2.096789598464966
Validation loss: 2.016700660188993

Epoch: 5| Step: 5
Training loss: 1.9104926586151123
Validation loss: 2.0160537163416543

Epoch: 5| Step: 6
Training loss: 2.3675284385681152
Validation loss: 2.010935897628466

Epoch: 5| Step: 7
Training loss: 2.3165814876556396
Validation loss: 2.010958418250084

Epoch: 5| Step: 8
Training loss: 1.880096197128296
Validation loss: 2.0105448017517724

Epoch: 5| Step: 9
Training loss: 2.0967819690704346
Validation loss: 2.0046942879756293

Epoch: 5| Step: 10
Training loss: 1.9432531595230103
Validation loss: 2.0014912635087967

Epoch: 5| Step: 11
Training loss: 1.221831202507019
Validation loss: 2.0032857060432434

Epoch: 94| Step: 0
Training loss: 1.9681888818740845
Validation loss: 2.0061630656321845

Epoch: 5| Step: 1
Training loss: 2.0506153106689453
Validation loss: 2.0111739138762155

Epoch: 5| Step: 2
Training loss: 2.269317626953125
Validation loss: 2.018561154603958

Epoch: 5| Step: 3
Training loss: 2.9093494415283203
Validation loss: 2.0282637178897858

Epoch: 5| Step: 4
Training loss: 2.0848610401153564
Validation loss: 2.0320225208997726

Epoch: 5| Step: 5
Training loss: 1.8970975875854492
Validation loss: 2.0324691037336984

Epoch: 5| Step: 6
Training loss: 1.8615520000457764
Validation loss: 2.0270710637172065

Epoch: 5| Step: 7
Training loss: 2.728253126144409
Validation loss: 2.0281752745310464

Epoch: 5| Step: 8
Training loss: 2.285285234451294
Validation loss: 2.013531282544136

Epoch: 5| Step: 9
Training loss: 2.4760406017303467
Validation loss: 2.0052233388026557

Epoch: 5| Step: 10
Training loss: 1.7191890478134155
Validation loss: 2.0045081675052643

Epoch: 5| Step: 11
Training loss: 0.9589934349060059
Validation loss: 2.000272274017334

Epoch: 95| Step: 0
Training loss: 1.803391695022583
Validation loss: 2.003730848431587

Epoch: 5| Step: 1
Training loss: 2.4748148918151855
Validation loss: 2.0028458734353385

Epoch: 5| Step: 2
Training loss: 2.3332066535949707
Validation loss: 1.9998125930627186

Epoch: 5| Step: 3
Training loss: 2.5228934288024902
Validation loss: 2.0066915849844613

Epoch: 5| Step: 4
Training loss: 2.237565279006958
Validation loss: 2.0104947636524835

Epoch: 5| Step: 5
Training loss: 2.4488320350646973
Validation loss: 2.0083340406417847

Epoch: 5| Step: 6
Training loss: 1.9258285760879517
Validation loss: 2.010577658812205

Epoch: 5| Step: 7
Training loss: 1.8657690286636353
Validation loss: 2.0113812337319055

Epoch: 5| Step: 8
Training loss: 2.459986686706543
Validation loss: 2.0107191999753318

Epoch: 5| Step: 9
Training loss: 1.8900724649429321
Validation loss: 2.0061553517977395

Epoch: 5| Step: 10
Training loss: 1.7519903182983398
Validation loss: 2.008134126663208

Epoch: 5| Step: 11
Training loss: 2.609860420227051
Validation loss: 2.006605327129364

Epoch: 96| Step: 0
Training loss: 1.781277060508728
Validation loss: 2.0110983649889627

Epoch: 5| Step: 1
Training loss: 1.8857839107513428
Validation loss: 2.019028956691424

Epoch: 5| Step: 2
Training loss: 2.608849287033081
Validation loss: 2.022348756591479

Epoch: 5| Step: 3
Training loss: 2.142591714859009
Validation loss: 2.040538306037585

Epoch: 5| Step: 4
Training loss: 2.0489630699157715
Validation loss: 2.056412488222122

Epoch: 5| Step: 5
Training loss: 2.445539951324463
Validation loss: 2.063021237651507

Epoch: 5| Step: 6
Training loss: 2.0371687412261963
Validation loss: 2.0682259500026703

Epoch: 5| Step: 7
Training loss: 2.277740001678467
Validation loss: 2.067588915427526

Epoch: 5| Step: 8
Training loss: 2.138075113296509
Validation loss: 2.0661939481894174

Epoch: 5| Step: 9
Training loss: 1.8690849542617798
Validation loss: 2.0487443854411445

Epoch: 5| Step: 10
Training loss: 2.6548538208007812
Validation loss: 2.0305559635162354

Epoch: 5| Step: 11
Training loss: 2.740229845046997
Validation loss: 2.021679033835729

Epoch: 97| Step: 0
Training loss: 1.770573377609253
Validation loss: 2.0060816953579583

Epoch: 5| Step: 1
Training loss: 2.426248073577881
Validation loss: 2.002947916587194

Epoch: 5| Step: 2
Training loss: 1.8705694675445557
Validation loss: 2.002510373791059

Epoch: 5| Step: 3
Training loss: 2.1585726737976074
Validation loss: 2.0074322720368705

Epoch: 5| Step: 4
Training loss: 2.2766172885894775
Validation loss: 2.0083017547925315

Epoch: 5| Step: 5
Training loss: 2.194016695022583
Validation loss: 2.011978968977928

Epoch: 5| Step: 6
Training loss: 2.2743020057678223
Validation loss: 2.0110299438238144

Epoch: 5| Step: 7
Training loss: 2.4516990184783936
Validation loss: 2.011881485581398

Epoch: 5| Step: 8
Training loss: 2.0628161430358887
Validation loss: 2.0023326724767685

Epoch: 5| Step: 9
Training loss: 2.02266001701355
Validation loss: 2.003487398227056

Epoch: 5| Step: 10
Training loss: 2.250753879547119
Validation loss: 2.0118813763062158

Epoch: 5| Step: 11
Training loss: 2.1792523860931396
Validation loss: 1.9991600960493088

Epoch: 98| Step: 0
Training loss: 2.0904011726379395
Validation loss: 2.0013001610835395

Epoch: 5| Step: 1
Training loss: 1.567549228668213
Validation loss: 2.0079890489578247

Epoch: 5| Step: 2
Training loss: 2.0686254501342773
Validation loss: 2.020094638069471

Epoch: 5| Step: 3
Training loss: 1.9044759273529053
Validation loss: 2.0250256657600403

Epoch: 5| Step: 4
Training loss: 2.518977403640747
Validation loss: 2.027778814236323

Epoch: 5| Step: 5
Training loss: 2.256251096725464
Validation loss: 2.031313399473826

Epoch: 5| Step: 6
Training loss: 1.8354209661483765
Validation loss: 2.0264800985654197

Epoch: 5| Step: 7
Training loss: 2.543926239013672
Validation loss: 2.0424076318740845

Epoch: 5| Step: 8
Training loss: 2.0628693103790283
Validation loss: 2.0322705258925757

Epoch: 5| Step: 9
Training loss: 1.8869644403457642
Validation loss: 2.030287434657415

Epoch: 5| Step: 10
Training loss: 2.765193462371826
Validation loss: 2.033160080512365

Epoch: 5| Step: 11
Training loss: 2.7084944248199463
Validation loss: 2.03304756184419

Epoch: 99| Step: 0
Training loss: 2.361703395843506
Validation loss: 2.018799136082331

Epoch: 5| Step: 1
Training loss: 2.1305930614471436
Validation loss: 2.0149552722771964

Epoch: 5| Step: 2
Training loss: 2.5136780738830566
Validation loss: 2.0077019532521567

Epoch: 5| Step: 3
Training loss: 1.9637371301651
Validation loss: 2.0082582384347916

Epoch: 5| Step: 4
Training loss: 1.9335651397705078
Validation loss: 2.0097839683294296

Epoch: 5| Step: 5
Training loss: 2.0297343730926514
Validation loss: 2.005725304285685

Epoch: 5| Step: 6
Training loss: 2.3559508323669434
Validation loss: 1.9998518029848735

Epoch: 5| Step: 7
Training loss: 2.6719326972961426
Validation loss: 2.00180155535539

Epoch: 5| Step: 8
Training loss: 1.8359838724136353
Validation loss: 2.0056110421816506

Epoch: 5| Step: 9
Training loss: 2.1450867652893066
Validation loss: 2.003984108567238

Epoch: 5| Step: 10
Training loss: 1.8029638528823853
Validation loss: 2.0074035823345184

Epoch: 5| Step: 11
Training loss: 1.5310471057891846
Validation loss: 2.0049713999032974

Epoch: 100| Step: 0
Training loss: 2.171506643295288
Validation loss: 1.9994670202334721

Epoch: 5| Step: 1
Training loss: 1.7018349170684814
Validation loss: 2.006139854590098

Epoch: 5| Step: 2
Training loss: 2.044962167739868
Validation loss: 2.0047886222600937

Epoch: 5| Step: 3
Training loss: 1.8455861806869507
Validation loss: 2.0081688662370047

Epoch: 5| Step: 4
Training loss: 2.279203414916992
Validation loss: 2.008182257413864

Epoch: 5| Step: 5
Training loss: 2.6855857372283936
Validation loss: 2.000331620375315

Epoch: 5| Step: 6
Training loss: 2.4248034954071045
Validation loss: 2.013007869323095

Epoch: 5| Step: 7
Training loss: 2.0923104286193848
Validation loss: 2.0052149494489035

Epoch: 5| Step: 8
Training loss: 1.6007859706878662
Validation loss: 2.0116887440284095

Epoch: 5| Step: 9
Training loss: 2.777529716491699
Validation loss: 2.024025951822599

Epoch: 5| Step: 10
Training loss: 1.9749515056610107
Validation loss: 2.0260752042134604

Epoch: 5| Step: 11
Training loss: 2.5384695529937744
Validation loss: 2.0339289208253226

Epoch: 101| Step: 0
Training loss: 2.3427672386169434
Validation loss: 2.01822637518247

Epoch: 5| Step: 1
Training loss: 1.4554356336593628
Validation loss: 2.016303996245066

Epoch: 5| Step: 2
Training loss: 2.5165505409240723
Validation loss: 2.011955256263415

Epoch: 5| Step: 3
Training loss: 2.4366328716278076
Validation loss: 2.0078929712375007

Epoch: 5| Step: 4
Training loss: 2.239560127258301
Validation loss: 2.0033077746629715

Epoch: 5| Step: 5
Training loss: 2.3393301963806152
Validation loss: 2.0079104602336884

Epoch: 5| Step: 6
Training loss: 1.968703031539917
Validation loss: 2.012370765209198

Epoch: 5| Step: 7
Training loss: 1.9317340850830078
Validation loss: 2.0070403714974723

Epoch: 5| Step: 8
Training loss: 2.333625316619873
Validation loss: 2.0077108244101205

Epoch: 5| Step: 9
Training loss: 2.1015708446502686
Validation loss: 2.003032778700193

Epoch: 5| Step: 10
Training loss: 1.904481291770935
Validation loss: 2.0052111198504767

Epoch: 5| Step: 11
Training loss: 1.9418553113937378
Validation loss: 2.0101402401924133

Epoch: 102| Step: 0
Training loss: 2.1509013175964355
Validation loss: 2.0094518860181174

Epoch: 5| Step: 1
Training loss: 2.25022029876709
Validation loss: 2.0090377231438956

Epoch: 5| Step: 2
Training loss: 2.2272677421569824
Validation loss: 2.0186273604631424

Epoch: 5| Step: 3
Training loss: 2.246711254119873
Validation loss: 2.0301659405231476

Epoch: 5| Step: 4
Training loss: 1.6409562826156616
Validation loss: 2.0219598710536957

Epoch: 5| Step: 5
Training loss: 2.1980459690093994
Validation loss: 2.0317903806765876

Epoch: 5| Step: 6
Training loss: 2.176750898361206
Validation loss: 2.0405351569255195

Epoch: 5| Step: 7
Training loss: 2.6680126190185547
Validation loss: 2.0296466698249183

Epoch: 5| Step: 8
Training loss: 1.4182108640670776
Validation loss: 2.0316539307435355

Epoch: 5| Step: 9
Training loss: 1.948693037033081
Validation loss: 2.0308789908885956

Epoch: 5| Step: 10
Training loss: 2.5274252891540527
Validation loss: 2.0340358217557273

Epoch: 5| Step: 11
Training loss: 1.9753811359405518
Validation loss: 2.0324102342128754

Epoch: 103| Step: 0
Training loss: 2.723459243774414
Validation loss: 2.020527412494024

Epoch: 5| Step: 1
Training loss: 1.9902912378311157
Validation loss: 2.0060002555449805

Epoch: 5| Step: 2
Training loss: 2.249685287475586
Validation loss: 2.0120007495085397

Epoch: 5| Step: 3
Training loss: 1.883829116821289
Validation loss: 2.011218706766764

Epoch: 5| Step: 4
Training loss: 2.320589542388916
Validation loss: 2.013401985168457

Epoch: 5| Step: 5
Training loss: 2.2008883953094482
Validation loss: 2.012931704521179

Epoch: 5| Step: 6
Training loss: 2.250537395477295
Validation loss: 2.010808691382408

Epoch: 5| Step: 7
Training loss: 1.913699746131897
Validation loss: 2.0116604963938394

Epoch: 5| Step: 8
Training loss: 1.9572007656097412
Validation loss: 2.0086992184321084

Epoch: 5| Step: 9
Training loss: 2.223878860473633
Validation loss: 2.00857080022494

Epoch: 5| Step: 10
Training loss: 2.203782320022583
Validation loss: 2.005924249688784

Epoch: 5| Step: 11
Training loss: 1.0306001901626587
Validation loss: 2.011593679587046

Epoch: 104| Step: 0
Training loss: 2.01277494430542
Validation loss: 2.00382699072361

Epoch: 5| Step: 1
Training loss: 2.2902607917785645
Validation loss: 2.002378925681114

Epoch: 5| Step: 2
Training loss: 2.0790011882781982
Validation loss: 2.001806770761808

Epoch: 5| Step: 3
Training loss: 2.0746943950653076
Validation loss: 2.020042116443316

Epoch: 5| Step: 4
Training loss: 2.520313262939453
Validation loss: 2.0185053100188575

Epoch: 5| Step: 5
Training loss: 1.9761403799057007
Validation loss: 2.0192201882600784

Epoch: 5| Step: 6
Training loss: 2.485823631286621
Validation loss: 2.0208818465471268

Epoch: 5| Step: 7
Training loss: 1.7659835815429688
Validation loss: 2.009611318508784

Epoch: 5| Step: 8
Training loss: 2.493137836456299
Validation loss: 2.023670499523481

Epoch: 5| Step: 9
Training loss: 2.2150254249572754
Validation loss: 2.010905906558037

Epoch: 5| Step: 10
Training loss: 1.8414121866226196
Validation loss: 2.0135433028141656

Epoch: 5| Step: 11
Training loss: 1.1571252346038818
Validation loss: 2.019597331682841

Epoch: 105| Step: 0
Training loss: 2.0656399726867676
Validation loss: 2.013603538274765

Epoch: 5| Step: 1
Training loss: 2.0040576457977295
Validation loss: 2.0158264487981796

Epoch: 5| Step: 2
Training loss: 2.3611669540405273
Validation loss: 2.0231075833241143

Epoch: 5| Step: 3
Training loss: 2.4661777019500732
Validation loss: 2.019325544436773

Epoch: 5| Step: 4
Training loss: 2.215409755706787
Validation loss: 2.0183055996894836

Epoch: 5| Step: 5
Training loss: 2.3789193630218506
Validation loss: 2.010378837585449

Epoch: 5| Step: 6
Training loss: 2.394174098968506
Validation loss: 2.0160512725512185

Epoch: 5| Step: 7
Training loss: 1.8862807750701904
Validation loss: 2.020560845732689

Epoch: 5| Step: 8
Training loss: 1.9746057987213135
Validation loss: 2.01424577832222

Epoch: 5| Step: 9
Training loss: 1.9017289876937866
Validation loss: 2.016113037864367

Epoch: 5| Step: 10
Training loss: 1.7409530878067017
Validation loss: 2.0151487290859222

Epoch: 5| Step: 11
Training loss: 1.7982240915298462
Validation loss: 2.0195990155140557

Epoch: 106| Step: 0
Training loss: 1.8322700262069702
Validation loss: 2.028621052702268

Epoch: 5| Step: 1
Training loss: 2.4375357627868652
Validation loss: 2.042594000697136

Epoch: 5| Step: 2
Training loss: 1.9921300411224365
Validation loss: 2.0317321568727493

Epoch: 5| Step: 3
Training loss: 2.302129030227661
Validation loss: 2.0313566823800406

Epoch: 5| Step: 4
Training loss: 2.222965717315674
Validation loss: 2.029561460018158

Epoch: 5| Step: 5
Training loss: 2.1166462898254395
Validation loss: 2.026857023437818

Epoch: 5| Step: 6
Training loss: 2.1205761432647705
Validation loss: 2.020238513747851

Epoch: 5| Step: 7
Training loss: 2.138376474380493
Validation loss: 2.024186243613561

Epoch: 5| Step: 8
Training loss: 1.926327109336853
Validation loss: 2.0193398048480353

Epoch: 5| Step: 9
Training loss: 2.276423692703247
Validation loss: 2.0190912385781608

Epoch: 5| Step: 10
Training loss: 2.0545096397399902
Validation loss: 2.019953891634941

Epoch: 5| Step: 11
Training loss: 1.4511537551879883
Validation loss: 2.018943632642428

Epoch: 107| Step: 0
Training loss: 2.2928528785705566
Validation loss: 2.0243065307537713

Epoch: 5| Step: 1
Training loss: 2.3360724449157715
Validation loss: 2.021464387575785

Epoch: 5| Step: 2
Training loss: 2.435692071914673
Validation loss: 2.021805410583814

Epoch: 5| Step: 3
Training loss: 2.0944080352783203
Validation loss: 2.032546818256378

Epoch: 5| Step: 4
Training loss: 1.7541821002960205
Validation loss: 2.026195685068766

Epoch: 5| Step: 5
Training loss: 2.3271737098693848
Validation loss: 2.028366590539614

Epoch: 5| Step: 6
Training loss: 1.7257916927337646
Validation loss: 2.036631186803182

Epoch: 5| Step: 7
Training loss: 1.8847935199737549
Validation loss: 2.040920168161392

Epoch: 5| Step: 8
Training loss: 2.338392972946167
Validation loss: 2.0366574029127755

Epoch: 5| Step: 9
Training loss: 1.901623010635376
Validation loss: 2.0355929881334305

Epoch: 5| Step: 10
Training loss: 1.9836708307266235
Validation loss: 2.0266450494527817

Epoch: 5| Step: 11
Training loss: 3.4067211151123047
Validation loss: 2.01666151980559

Epoch: 108| Step: 0
Training loss: 2.002880811691284
Validation loss: 2.0227410197257996

Epoch: 5| Step: 1
Training loss: 1.720444679260254
Validation loss: 2.011772816379865

Epoch: 5| Step: 2
Training loss: 2.1461429595947266
Validation loss: 1.9995870888233185

Epoch: 5| Step: 3
Training loss: 2.182666301727295
Validation loss: 2.0101539393266044

Epoch: 5| Step: 4
Training loss: 1.868473768234253
Validation loss: 2.0032213677962623

Epoch: 5| Step: 5
Training loss: 2.1910550594329834
Validation loss: 2.002528796593348

Epoch: 5| Step: 6
Training loss: 1.963083267211914
Validation loss: 2.011615683635076

Epoch: 5| Step: 7
Training loss: 2.043989658355713
Validation loss: 2.005355402827263

Epoch: 5| Step: 8
Training loss: 2.1427226066589355
Validation loss: 2.0049262841542563

Epoch: 5| Step: 9
Training loss: 2.316012144088745
Validation loss: 2.012183999021848

Epoch: 5| Step: 10
Training loss: 2.711317777633667
Validation loss: 2.0073086470365524

Epoch: 5| Step: 11
Training loss: 2.632666826248169
Validation loss: 2.0022790282964706

Epoch: 109| Step: 0
Training loss: 2.1844089031219482
Validation loss: 2.016231964031855

Epoch: 5| Step: 1
Training loss: 1.8287508487701416
Validation loss: 2.0120444148778915

Epoch: 5| Step: 2
Training loss: 2.1373870372772217
Validation loss: 2.0300495624542236

Epoch: 5| Step: 3
Training loss: 2.3032259941101074
Validation loss: 2.029667466878891

Epoch: 5| Step: 4
Training loss: 1.886223554611206
Validation loss: 2.0325581630071006

Epoch: 5| Step: 5
Training loss: 2.0868265628814697
Validation loss: 2.0347561687231064

Epoch: 5| Step: 6
Training loss: 2.151787281036377
Validation loss: 2.0303807159264884

Epoch: 5| Step: 7
Training loss: 2.123774290084839
Validation loss: 2.0267422646284103

Epoch: 5| Step: 8
Training loss: 2.222641706466675
Validation loss: 2.022123326857885

Epoch: 5| Step: 9
Training loss: 1.9452953338623047
Validation loss: 2.0136324216922126

Epoch: 5| Step: 10
Training loss: 2.5677411556243896
Validation loss: 2.0051693121592202

Epoch: 5| Step: 11
Training loss: 1.1863071918487549
Validation loss: 2.00446746746699

Epoch: 110| Step: 0
Training loss: 1.9909604787826538
Validation loss: 2.008579894900322

Epoch: 5| Step: 1
Training loss: 2.5352396965026855
Validation loss: 2.0068536698818207

Epoch: 5| Step: 2
Training loss: 2.1306843757629395
Validation loss: 2.007910375793775

Epoch: 5| Step: 3
Training loss: 2.0548672676086426
Validation loss: 2.0176902065674462

Epoch: 5| Step: 4
Training loss: 1.8303495645523071
Validation loss: 2.014752065141996

Epoch: 5| Step: 5
Training loss: 2.5698447227478027
Validation loss: 2.0296331544717154

Epoch: 5| Step: 6
Training loss: 2.111088991165161
Validation loss: 2.027343491713206

Epoch: 5| Step: 7
Training loss: 2.0165019035339355
Validation loss: 2.027613898118337

Epoch: 5| Step: 8
Training loss: 1.6761356592178345
Validation loss: 2.031130795677503

Epoch: 5| Step: 9
Training loss: 2.317659854888916
Validation loss: 2.021140918135643

Epoch: 5| Step: 10
Training loss: 2.5416581630706787
Validation loss: 2.023135150472323

Epoch: 5| Step: 11
Training loss: 1.5262223482131958
Validation loss: 2.014183814326922

Epoch: 111| Step: 0
Training loss: 1.8218291997909546
Validation loss: 2.020086412628492

Epoch: 5| Step: 1
Training loss: 2.788065195083618
Validation loss: 2.0177925874789557

Epoch: 5| Step: 2
Training loss: 2.0163028240203857
Validation loss: 2.0182281335194907

Epoch: 5| Step: 3
Training loss: 2.107759952545166
Validation loss: 2.014129896958669

Epoch: 5| Step: 4
Training loss: 1.9838533401489258
Validation loss: 2.0170539816220603

Epoch: 5| Step: 5
Training loss: 1.856530785560608
Validation loss: 2.0101236750682197

Epoch: 5| Step: 6
Training loss: 2.4047412872314453
Validation loss: 2.018588031331698

Epoch: 5| Step: 7
Training loss: 2.2289156913757324
Validation loss: 2.0204656422138214

Epoch: 5| Step: 8
Training loss: 2.2528066635131836
Validation loss: 2.025327796737353

Epoch: 5| Step: 9
Training loss: 2.1287455558776855
Validation loss: 2.0206254671017327

Epoch: 5| Step: 10
Training loss: 1.6220481395721436
Validation loss: 2.030858521660169

Epoch: 5| Step: 11
Training loss: 1.7551918029785156
Validation loss: 2.037815824151039

Epoch: 112| Step: 0
Training loss: 2.0020480155944824
Validation loss: 2.0538254926602044

Epoch: 5| Step: 1
Training loss: 2.0650625228881836
Validation loss: 2.0732406675815582

Epoch: 5| Step: 2
Training loss: 2.5097153186798096
Validation loss: 2.0809712260961533

Epoch: 5| Step: 3
Training loss: 1.6612861156463623
Validation loss: 2.0812617540359497

Epoch: 5| Step: 4
Training loss: 2.409755229949951
Validation loss: 2.0809625585873923

Epoch: 5| Step: 5
Training loss: 1.6672645807266235
Validation loss: 2.0625420262416205

Epoch: 5| Step: 6
Training loss: 2.1872899532318115
Validation loss: 2.054365406433741

Epoch: 5| Step: 7
Training loss: 2.4135117530822754
Validation loss: 2.0494496822357178

Epoch: 5| Step: 8
Training loss: 2.619072675704956
Validation loss: 2.026172543565432

Epoch: 5| Step: 9
Training loss: 1.4772439002990723
Validation loss: 2.02463906009992

Epoch: 5| Step: 10
Training loss: 2.3675289154052734
Validation loss: 2.026393880446752

Epoch: 5| Step: 11
Training loss: 1.8897851705551147
Validation loss: 2.0158387621243796

Epoch: 113| Step: 0
Training loss: 2.0243897438049316
Validation loss: 2.0195929805437722

Epoch: 5| Step: 1
Training loss: 1.9343048334121704
Validation loss: 2.024796033898989

Epoch: 5| Step: 2
Training loss: 1.3743878602981567
Validation loss: 2.0270081808169684

Epoch: 5| Step: 3
Training loss: 2.3127877712249756
Validation loss: 2.030064215262731

Epoch: 5| Step: 4
Training loss: 2.3859875202178955
Validation loss: 2.0371782183647156

Epoch: 5| Step: 5
Training loss: 2.375792980194092
Validation loss: 2.041153738896052

Epoch: 5| Step: 6
Training loss: 2.2418227195739746
Validation loss: 2.0423811227083206

Epoch: 5| Step: 7
Training loss: 2.4383187294006348
Validation loss: 2.037314772605896

Epoch: 5| Step: 8
Training loss: 2.392270565032959
Validation loss: 2.0410037140051522

Epoch: 5| Step: 9
Training loss: 2.021916627883911
Validation loss: 2.0447621742884317

Epoch: 5| Step: 10
Training loss: 2.1693921089172363
Validation loss: 2.041650727391243

Epoch: 5| Step: 11
Training loss: 2.9115986824035645
Validation loss: 2.046425441900889

Epoch: 114| Step: 0
Training loss: 2.0450425148010254
Validation loss: 2.0401978343725204

Epoch: 5| Step: 1
Training loss: 1.5809924602508545
Validation loss: 2.0391657650470734

Epoch: 5| Step: 2
Training loss: 1.7196394205093384
Validation loss: 2.0359131197134652

Epoch: 5| Step: 3
Training loss: 2.046699285507202
Validation loss: 2.0321452021598816

Epoch: 5| Step: 4
Training loss: 2.2592618465423584
Validation loss: 2.0289233972628913

Epoch: 5| Step: 5
Training loss: 2.2129573822021484
Validation loss: 2.0339663873116174

Epoch: 5| Step: 6
Training loss: 2.4203574657440186
Validation loss: 2.0322009722391763

Epoch: 5| Step: 7
Training loss: 2.0829339027404785
Validation loss: 2.0234993249177933

Epoch: 5| Step: 8
Training loss: 2.693692684173584
Validation loss: 2.027873928348223

Epoch: 5| Step: 9
Training loss: 2.700812816619873
Validation loss: 2.019993389646212

Epoch: 5| Step: 10
Training loss: 2.1052119731903076
Validation loss: 2.0156076848506927

Epoch: 5| Step: 11
Training loss: 1.2256498336791992
Validation loss: 2.0165022164583206

Epoch: 115| Step: 0
Training loss: 2.239638090133667
Validation loss: 2.025553156932195

Epoch: 5| Step: 1
Training loss: 1.9958912134170532
Validation loss: 2.0277101695537567

Epoch: 5| Step: 2
Training loss: 2.2755017280578613
Validation loss: 2.0341704537471137

Epoch: 5| Step: 3
Training loss: 1.694946527481079
Validation loss: 2.038320670525233

Epoch: 5| Step: 4
Training loss: 2.0651748180389404
Validation loss: 2.0397379398345947

Epoch: 5| Step: 5
Training loss: 2.5996835231781006
Validation loss: 2.042612532774607

Epoch: 5| Step: 6
Training loss: 2.095670461654663
Validation loss: 2.0320626298586526

Epoch: 5| Step: 7
Training loss: 2.684600353240967
Validation loss: 2.0338045358657837

Epoch: 5| Step: 8
Training loss: 2.3694205284118652
Validation loss: 2.0394868354002633

Epoch: 5| Step: 9
Training loss: 1.6568511724472046
Validation loss: 2.0379842619101205

Epoch: 5| Step: 10
Training loss: 2.0097343921661377
Validation loss: 2.030345618724823

Epoch: 5| Step: 11
Training loss: 0.6548184156417847
Validation loss: 2.0349860936403275

Epoch: 116| Step: 0
Training loss: 2.115332841873169
Validation loss: 2.027763247489929

Epoch: 5| Step: 1
Training loss: 2.000779151916504
Validation loss: 2.0208698908487954

Epoch: 5| Step: 2
Training loss: 1.8890126943588257
Validation loss: 2.0247046450773873

Epoch: 5| Step: 3
Training loss: 1.690605878829956
Validation loss: 2.027505119641622

Epoch: 5| Step: 4
Training loss: 2.376060962677002
Validation loss: 2.021644080678622

Epoch: 5| Step: 5
Training loss: 1.6541141271591187
Validation loss: 2.014315575361252

Epoch: 5| Step: 6
Training loss: 2.587299108505249
Validation loss: 2.014347811539968

Epoch: 5| Step: 7
Training loss: 1.988438367843628
Validation loss: 2.0164224406083426

Epoch: 5| Step: 8
Training loss: 2.235257625579834
Validation loss: 2.0242849737405777

Epoch: 5| Step: 9
Training loss: 1.9246492385864258
Validation loss: 2.0149139165878296

Epoch: 5| Step: 10
Training loss: 2.430366039276123
Validation loss: 2.020046720902125

Epoch: 5| Step: 11
Training loss: 3.9866461753845215
Validation loss: 2.013966699441274

Epoch: 117| Step: 0
Training loss: 2.146028757095337
Validation loss: 2.0202538073062897

Epoch: 5| Step: 1
Training loss: 2.074824571609497
Validation loss: 2.0170985956986747

Epoch: 5| Step: 2
Training loss: 2.1928534507751465
Validation loss: 2.019340460499128

Epoch: 5| Step: 3
Training loss: 2.148616313934326
Validation loss: 2.0206660330295563

Epoch: 5| Step: 4
Training loss: 2.864716053009033
Validation loss: 2.0286822766065598

Epoch: 5| Step: 5
Training loss: 1.6700360774993896
Validation loss: 2.035298099120458

Epoch: 5| Step: 6
Training loss: 2.2317311763763428
Validation loss: 2.0281815578540168

Epoch: 5| Step: 7
Training loss: 1.972821831703186
Validation loss: 2.040533035993576

Epoch: 5| Step: 8
Training loss: 2.377269983291626
Validation loss: 2.0321798672278724

Epoch: 5| Step: 9
Training loss: 1.283033847808838
Validation loss: 2.030546541015307

Epoch: 5| Step: 10
Training loss: 2.2350783348083496
Validation loss: 2.0341114501158395

Epoch: 5| Step: 11
Training loss: 1.7830973863601685
Validation loss: 2.031343922019005

Epoch: 118| Step: 0
Training loss: 2.6418874263763428
Validation loss: 2.0391902228196463

Epoch: 5| Step: 1
Training loss: 1.84219491481781
Validation loss: 2.032180999716123

Epoch: 5| Step: 2
Training loss: 3.012507915496826
Validation loss: 2.0324059973160424

Epoch: 5| Step: 3
Training loss: 1.9012629985809326
Validation loss: 2.0262074073155723

Epoch: 5| Step: 4
Training loss: 1.8925069570541382
Validation loss: 2.0293676257133484

Epoch: 5| Step: 5
Training loss: 1.8542449474334717
Validation loss: 2.022871951262156

Epoch: 5| Step: 6
Training loss: 1.8396928310394287
Validation loss: 2.020189260443052

Epoch: 5| Step: 7
Training loss: 2.002147674560547
Validation loss: 2.0190940648317337

Epoch: 5| Step: 8
Training loss: 2.5787367820739746
Validation loss: 2.0207444727420807

Epoch: 5| Step: 9
Training loss: 1.7888476848602295
Validation loss: 2.0248346428076425

Epoch: 5| Step: 10
Training loss: 1.7876336574554443
Validation loss: 2.0260065545638404

Epoch: 5| Step: 11
Training loss: 1.8641374111175537
Validation loss: 2.027832309405009

Epoch: 119| Step: 0
Training loss: 2.168820858001709
Validation loss: 2.0369758208592734

Epoch: 5| Step: 1
Training loss: 2.146667003631592
Validation loss: 2.031155933936437

Epoch: 5| Step: 2
Training loss: 2.3132436275482178
Validation loss: 2.0350920458634696

Epoch: 5| Step: 3
Training loss: 2.0949606895446777
Validation loss: 2.0363901952902475

Epoch: 5| Step: 4
Training loss: 1.7484136819839478
Validation loss: 2.0391566703716912

Epoch: 5| Step: 5
Training loss: 1.807161569595337
Validation loss: 2.0402676115433374

Epoch: 5| Step: 6
Training loss: 2.4410648345947266
Validation loss: 2.0330333560705185

Epoch: 5| Step: 7
Training loss: 1.8443673849105835
Validation loss: 2.02792622645696

Epoch: 5| Step: 8
Training loss: 2.308223247528076
Validation loss: 2.0327244997024536

Epoch: 5| Step: 9
Training loss: 1.9357305765151978
Validation loss: 2.0334646105766296

Epoch: 5| Step: 10
Training loss: 1.9368997812271118
Validation loss: 2.028308004140854

Epoch: 5| Step: 11
Training loss: 3.3967697620391846
Validation loss: 2.031050672133764

Epoch: 120| Step: 0
Training loss: 1.9900480508804321
Validation loss: 2.0193398892879486

Epoch: 5| Step: 1
Training loss: 2.716236114501953
Validation loss: 2.009573757648468

Epoch: 5| Step: 2
Training loss: 1.8348112106323242
Validation loss: 2.0008481641610465

Epoch: 5| Step: 3
Training loss: 2.3199195861816406
Validation loss: 2.0047526558240256

Epoch: 5| Step: 4
Training loss: 2.2464537620544434
Validation loss: 2.0006050566832223

Epoch: 5| Step: 5
Training loss: 1.9250272512435913
Validation loss: 2.0189529011646905

Epoch: 5| Step: 6
Training loss: 1.7643725872039795
Validation loss: 2.018930892149607

Epoch: 5| Step: 7
Training loss: 2.0532631874084473
Validation loss: 2.0280617574850717

Epoch: 5| Step: 8
Training loss: 2.136146306991577
Validation loss: 2.0180749744176865

Epoch: 5| Step: 9
Training loss: 2.5491480827331543
Validation loss: 2.021311789751053

Epoch: 5| Step: 10
Training loss: 2.172152280807495
Validation loss: 2.015656312306722

Epoch: 5| Step: 11
Training loss: 1.5663249492645264
Validation loss: 2.0200368563334146

Epoch: 121| Step: 0
Training loss: 2.1126132011413574
Validation loss: 2.016111289461454

Epoch: 5| Step: 1
Training loss: 2.3302347660064697
Validation loss: 2.0044889599084854

Epoch: 5| Step: 2
Training loss: 2.28189754486084
Validation loss: 2.0143456061681113

Epoch: 5| Step: 3
Training loss: 2.1168529987335205
Validation loss: 2.0114614317814508

Epoch: 5| Step: 4
Training loss: 1.822403907775879
Validation loss: 2.017392262816429

Epoch: 5| Step: 5
Training loss: 2.145744800567627
Validation loss: 2.0129373570283255

Epoch: 5| Step: 6
Training loss: 2.3111817836761475
Validation loss: 2.0248122612635293

Epoch: 5| Step: 7
Training loss: 2.0470261573791504
Validation loss: 2.026090939839681

Epoch: 5| Step: 8
Training loss: 2.16282320022583
Validation loss: 2.023152306675911

Epoch: 5| Step: 9
Training loss: 1.9977792501449585
Validation loss: 2.0400309711694717

Epoch: 5| Step: 10
Training loss: 2.074350357055664
Validation loss: 2.053906420866648

Epoch: 5| Step: 11
Training loss: 1.265304446220398
Validation loss: 2.0513747185468674

Epoch: 122| Step: 0
Training loss: 2.455167293548584
Validation loss: 2.0557902803023658

Epoch: 5| Step: 1
Training loss: 1.2601113319396973
Validation loss: 2.0601950734853745

Epoch: 5| Step: 2
Training loss: 2.275101661682129
Validation loss: 2.0456503480672836

Epoch: 5| Step: 3
Training loss: 1.8382937908172607
Validation loss: 2.0494259099165597

Epoch: 5| Step: 4
Training loss: 2.076716661453247
Validation loss: 2.046086529890696

Epoch: 5| Step: 5
Training loss: 2.185500383377075
Validation loss: 2.0444939583539963

Epoch: 5| Step: 6
Training loss: 2.7747931480407715
Validation loss: 2.0364313572645187

Epoch: 5| Step: 7
Training loss: 1.8004257678985596
Validation loss: 2.041814307371775

Epoch: 5| Step: 8
Training loss: 2.095703601837158
Validation loss: 2.0333116948604584

Epoch: 5| Step: 9
Training loss: 1.9616329669952393
Validation loss: 2.0361858208974204

Epoch: 5| Step: 10
Training loss: 2.2018356323242188
Validation loss: 2.0264440923929214

Epoch: 5| Step: 11
Training loss: 2.472280979156494
Validation loss: 2.0296920289595923

Epoch: 123| Step: 0
Training loss: 1.610504150390625
Validation loss: 2.0290584713220596

Epoch: 5| Step: 1
Training loss: 2.1380531787872314
Validation loss: 2.0225369284550347

Epoch: 5| Step: 2
Training loss: 2.5444650650024414
Validation loss: 2.0213356415430703

Epoch: 5| Step: 3
Training loss: 2.89192795753479
Validation loss: 2.0202715446551642

Epoch: 5| Step: 4
Training loss: 2.2733116149902344
Validation loss: 2.015199070175489

Epoch: 5| Step: 5
Training loss: 1.5412033796310425
Validation loss: 2.019384950399399

Epoch: 5| Step: 6
Training loss: 2.1229546070098877
Validation loss: 2.0129953970511756

Epoch: 5| Step: 7
Training loss: 2.0448317527770996
Validation loss: 2.015534366170565

Epoch: 5| Step: 8
Training loss: 1.8126811981201172
Validation loss: 2.022142380475998

Epoch: 5| Step: 9
Training loss: 1.902695655822754
Validation loss: 2.018095706899961

Epoch: 5| Step: 10
Training loss: 2.1048696041107178
Validation loss: 2.0257079352935157

Epoch: 5| Step: 11
Training loss: 2.0466132164001465
Validation loss: 2.02744060754776

Epoch: 124| Step: 0
Training loss: 2.469804286956787
Validation loss: 2.0362754662831626

Epoch: 5| Step: 1
Training loss: 1.912766456604004
Validation loss: 2.0349546720584235

Epoch: 5| Step: 2
Training loss: 1.8647546768188477
Validation loss: 2.035856679081917

Epoch: 5| Step: 3
Training loss: 2.174443006515503
Validation loss: 2.0316581577062607

Epoch: 5| Step: 4
Training loss: 1.8510993719100952
Validation loss: 2.0370826721191406

Epoch: 5| Step: 5
Training loss: 2.2410576343536377
Validation loss: 2.046838790178299

Epoch: 5| Step: 6
Training loss: 2.377042293548584
Validation loss: 2.042151312033335

Epoch: 5| Step: 7
Training loss: 2.174199342727661
Validation loss: 2.045945336421331

Epoch: 5| Step: 8
Training loss: 2.1809682846069336
Validation loss: 2.052592863639196

Epoch: 5| Step: 9
Training loss: 1.7333831787109375
Validation loss: 2.047122468551

Epoch: 5| Step: 10
Training loss: 1.9544035196304321
Validation loss: 2.0512958765029907

Epoch: 5| Step: 11
Training loss: 1.6336543560028076
Validation loss: 2.050671488046646

Epoch: 125| Step: 0
Training loss: 2.503507137298584
Validation loss: 2.048775131503741

Epoch: 5| Step: 1
Training loss: 1.5011152029037476
Validation loss: 2.054022967815399

Epoch: 5| Step: 2
Training loss: 2.587982177734375
Validation loss: 2.05232273042202

Epoch: 5| Step: 3
Training loss: 2.446092128753662
Validation loss: 2.0598108718792596

Epoch: 5| Step: 4
Training loss: 2.3017430305480957
Validation loss: 2.0518187234799066

Epoch: 5| Step: 5
Training loss: 1.8717339038848877
Validation loss: 2.043914427359899

Epoch: 5| Step: 6
Training loss: 1.6248334646224976
Validation loss: 2.0363331784804664

Epoch: 5| Step: 7
Training loss: 1.7240574359893799
Validation loss: 2.044004519780477

Epoch: 5| Step: 8
Training loss: 1.910487174987793
Validation loss: 2.0391682932774224

Epoch: 5| Step: 9
Training loss: 2.3608269691467285
Validation loss: 2.051244323452314

Epoch: 5| Step: 10
Training loss: 2.166289806365967
Validation loss: 2.033501004179319

Epoch: 5| Step: 11
Training loss: 2.186206102371216
Validation loss: 2.0341502875089645

Epoch: 126| Step: 0
Training loss: 2.284921169281006
Validation loss: 2.0319136679172516

Epoch: 5| Step: 1
Training loss: 1.9268920421600342
Validation loss: 2.039100537697474

Epoch: 5| Step: 2
Training loss: 1.6200793981552124
Validation loss: 2.0423143605391183

Epoch: 5| Step: 3
Training loss: 2.937574625015259
Validation loss: 2.0486123313506446

Epoch: 5| Step: 4
Training loss: 2.1921703815460205
Validation loss: 2.051028067866961

Epoch: 5| Step: 5
Training loss: 2.056497573852539
Validation loss: 2.0517518520355225

Epoch: 5| Step: 6
Training loss: 2.138993978500366
Validation loss: 2.0438489516576133

Epoch: 5| Step: 7
Training loss: 1.9574283361434937
Validation loss: 2.043694938222567

Epoch: 5| Step: 8
Training loss: 1.699239730834961
Validation loss: 2.0425906280676522

Epoch: 5| Step: 9
Training loss: 1.5307590961456299
Validation loss: 2.054256647825241

Epoch: 5| Step: 10
Training loss: 2.3723549842834473
Validation loss: 2.04862841963768

Epoch: 5| Step: 11
Training loss: 2.655015707015991
Validation loss: 2.045866752664248

Epoch: 127| Step: 0
Training loss: 2.8760485649108887
Validation loss: 2.0464521745840707

Epoch: 5| Step: 1
Training loss: 1.9181960821151733
Validation loss: 2.039523204167684

Epoch: 5| Step: 2
Training loss: 2.449453592300415
Validation loss: 2.0368123650550842

Epoch: 5| Step: 3
Training loss: 2.483355760574341
Validation loss: 2.024695614973704

Epoch: 5| Step: 4
Training loss: 1.4777504205703735
Validation loss: 2.0303575644890466

Epoch: 5| Step: 5
Training loss: 1.7585939168930054
Validation loss: 2.0230735540390015

Epoch: 5| Step: 6
Training loss: 1.814589500427246
Validation loss: 2.0198684632778168

Epoch: 5| Step: 7
Training loss: 2.11505389213562
Validation loss: 2.0284649233023324

Epoch: 5| Step: 8
Training loss: 1.8336007595062256
Validation loss: 2.022031714518865

Epoch: 5| Step: 9
Training loss: 1.8091166019439697
Validation loss: 2.018910671273867

Epoch: 5| Step: 10
Training loss: 2.1224942207336426
Validation loss: 2.027963876724243

Epoch: 5| Step: 11
Training loss: 3.4373779296875
Validation loss: 2.0283653984467187

Epoch: 128| Step: 0
Training loss: 1.886779546737671
Validation loss: 2.0203728725512824

Epoch: 5| Step: 1
Training loss: 1.9854652881622314
Validation loss: 2.026063640912374

Epoch: 5| Step: 2
Training loss: 1.9815679788589478
Validation loss: 2.0165888716777167

Epoch: 5| Step: 3
Training loss: 2.418107748031616
Validation loss: 2.0282391707102456

Epoch: 5| Step: 4
Training loss: 2.3473331928253174
Validation loss: 2.0224968840678534

Epoch: 5| Step: 5
Training loss: 2.338527202606201
Validation loss: 2.0313989967107773

Epoch: 5| Step: 6
Training loss: 1.91180419921875
Validation loss: 2.0344286312659583

Epoch: 5| Step: 7
Training loss: 2.0229439735412598
Validation loss: 2.041366661588351

Epoch: 5| Step: 8
Training loss: 1.5361285209655762
Validation loss: 2.0498766352732978

Epoch: 5| Step: 9
Training loss: 2.057281017303467
Validation loss: 2.049727206428846

Epoch: 5| Step: 10
Training loss: 2.3781776428222656
Validation loss: 2.0546882251898446

Epoch: 5| Step: 11
Training loss: 3.0329430103302
Validation loss: 2.046202709277471

Epoch: 129| Step: 0
Training loss: 1.8781061172485352
Validation loss: 2.053856670856476

Epoch: 5| Step: 1
Training loss: 2.081326961517334
Validation loss: 2.059147526820501

Epoch: 5| Step: 2
Training loss: 2.72438383102417
Validation loss: 2.0519624749819436

Epoch: 5| Step: 3
Training loss: 2.175856590270996
Validation loss: 2.0547653138637543

Epoch: 5| Step: 4
Training loss: 1.7888662815093994
Validation loss: 2.0532490660746894

Epoch: 5| Step: 5
Training loss: 1.8623626232147217
Validation loss: 2.0538859913746514

Epoch: 5| Step: 6
Training loss: 2.0384175777435303
Validation loss: 2.0577019502719245

Epoch: 5| Step: 7
Training loss: 2.2315821647644043
Validation loss: 2.0525308599074683

Epoch: 5| Step: 8
Training loss: 2.047232151031494
Validation loss: 2.0492411454518638

Epoch: 5| Step: 9
Training loss: 1.760754942893982
Validation loss: 2.045593112707138

Epoch: 5| Step: 10
Training loss: 2.0459439754486084
Validation loss: 2.0418826192617416

Epoch: 5| Step: 11
Training loss: 2.4623541831970215
Validation loss: 2.0408386290073395

Epoch: 130| Step: 0
Training loss: 2.321861743927002
Validation loss: 2.035358265042305

Epoch: 5| Step: 1
Training loss: 2.2434089183807373
Validation loss: 2.029406333963076

Epoch: 5| Step: 2
Training loss: 1.8379093408584595
Validation loss: 2.028786594669024

Epoch: 5| Step: 3
Training loss: 2.0150623321533203
Validation loss: 2.025013451774915

Epoch: 5| Step: 4
Training loss: 1.7422395944595337
Validation loss: 2.039207940300306

Epoch: 5| Step: 5
Training loss: 2.0236940383911133
Validation loss: 2.03174190223217

Epoch: 5| Step: 6
Training loss: 2.4385318756103516
Validation loss: 2.0360309531291327

Epoch: 5| Step: 7
Training loss: 2.038522720336914
Validation loss: 2.0315021524826684

Epoch: 5| Step: 8
Training loss: 2.052020788192749
Validation loss: 2.0359912465016046

Epoch: 5| Step: 9
Training loss: 2.1413025856018066
Validation loss: 2.03536249200503

Epoch: 5| Step: 10
Training loss: 2.1549224853515625
Validation loss: 2.0527626474698386

Epoch: 5| Step: 11
Training loss: 1.3839471340179443
Validation loss: 2.0542849699656167

Epoch: 131| Step: 0
Training loss: 1.9346656799316406
Validation loss: 2.064307823777199

Epoch: 5| Step: 1
Training loss: 2.22857928276062
Validation loss: 2.0567813515663147

Epoch: 5| Step: 2
Training loss: 1.8210630416870117
Validation loss: 2.0625379184881845

Epoch: 5| Step: 3
Training loss: 2.4342145919799805
Validation loss: 2.0671329299608865

Epoch: 5| Step: 4
Training loss: 2.1265854835510254
Validation loss: 2.0696515440940857

Epoch: 5| Step: 5
Training loss: 1.9558242559432983
Validation loss: 2.0678163518508277

Epoch: 5| Step: 6
Training loss: 1.8374683856964111
Validation loss: 2.0719634145498276

Epoch: 5| Step: 7
Training loss: 2.158344030380249
Validation loss: 2.0616015791893005

Epoch: 5| Step: 8
Training loss: 1.9471161365509033
Validation loss: 2.0549860894680023

Epoch: 5| Step: 9
Training loss: 2.228761672973633
Validation loss: 2.058480108777682

Epoch: 5| Step: 10
Training loss: 2.1699137687683105
Validation loss: 2.0553444574276605

Epoch: 5| Step: 11
Training loss: 1.9393852949142456
Validation loss: 2.044169689218203

Epoch: 132| Step: 0
Training loss: 2.2716689109802246
Validation loss: 2.042977804938952

Epoch: 5| Step: 1
Training loss: 2.1981148719787598
Validation loss: 2.0301690101623535

Epoch: 5| Step: 2
Training loss: 2.1729443073272705
Validation loss: 2.0307160715262094

Epoch: 5| Step: 3
Training loss: 2.144517660140991
Validation loss: 2.024904946486155

Epoch: 5| Step: 4
Training loss: 1.7591545581817627
Validation loss: 2.0280812829732895

Epoch: 5| Step: 5
Training loss: 2.1235947608947754
Validation loss: 2.023630072673162

Epoch: 5| Step: 6
Training loss: 2.0276718139648438
Validation loss: 2.019298901160558

Epoch: 5| Step: 7
Training loss: 1.9306350946426392
Validation loss: 2.014184668660164

Epoch: 5| Step: 8
Training loss: 2.049452304840088
Validation loss: 2.019975652297338

Epoch: 5| Step: 9
Training loss: 2.5476486682891846
Validation loss: 2.022569144765536

Epoch: 5| Step: 10
Training loss: 1.8859039545059204
Validation loss: 2.0168343037366867

Epoch: 5| Step: 11
Training loss: 1.7600398063659668
Validation loss: 2.0278415928284326

Epoch: 133| Step: 0
Training loss: 2.197622537612915
Validation loss: 2.035102461775144

Epoch: 5| Step: 1
Training loss: 2.024108409881592
Validation loss: 2.037259836991628

Epoch: 5| Step: 2
Training loss: 1.8762454986572266
Validation loss: 2.0466948399941125

Epoch: 5| Step: 3
Training loss: 1.9155124425888062
Validation loss: 2.0460886657238007

Epoch: 5| Step: 4
Training loss: 2.0828776359558105
Validation loss: 2.052625964085261

Epoch: 5| Step: 5
Training loss: 2.0621085166931152
Validation loss: 2.0462376525004706

Epoch: 5| Step: 6
Training loss: 1.9841810464859009
Validation loss: 2.051724190513293

Epoch: 5| Step: 7
Training loss: 1.6265865564346313
Validation loss: 2.0529961238304772

Epoch: 5| Step: 8
Training loss: 2.6662163734436035
Validation loss: 2.0485376119613647

Epoch: 5| Step: 9
Training loss: 1.976954698562622
Validation loss: 2.055422534545263

Epoch: 5| Step: 10
Training loss: 2.478212833404541
Validation loss: 2.0557115972042084

Epoch: 5| Step: 11
Training loss: 1.1276190280914307
Validation loss: 2.0565021286408105

Epoch: 134| Step: 0
Training loss: 1.9234527349472046
Validation loss: 2.0650656819343567

Epoch: 5| Step: 1
Training loss: 2.0157856941223145
Validation loss: 2.0599342584609985

Epoch: 5| Step: 2
Training loss: 2.667989492416382
Validation loss: 2.051845282316208

Epoch: 5| Step: 3
Training loss: 2.0837039947509766
Validation loss: 2.0427841196457543

Epoch: 5| Step: 4
Training loss: 2.254748582839966
Validation loss: 2.045733869075775

Epoch: 5| Step: 5
Training loss: 1.9710487127304077
Validation loss: 2.037449503938357

Epoch: 5| Step: 6
Training loss: 2.1189520359039307
Validation loss: 2.037060856819153

Epoch: 5| Step: 7
Training loss: 1.7392171621322632
Validation loss: 2.02963720758756

Epoch: 5| Step: 8
Training loss: 2.2111897468566895
Validation loss: 2.0384372621774673

Epoch: 5| Step: 9
Training loss: 2.1760547161102295
Validation loss: 2.038285255432129

Epoch: 5| Step: 10
Training loss: 1.9609010219573975
Validation loss: 2.0405340641736984

Epoch: 5| Step: 11
Training loss: 1.498321533203125
Validation loss: 2.0444396982590356

Epoch: 135| Step: 0
Training loss: 2.417914867401123
Validation loss: 2.0410160571336746

Epoch: 5| Step: 1
Training loss: 1.6611741781234741
Validation loss: 2.049725666642189

Epoch: 5| Step: 2
Training loss: 2.055920124053955
Validation loss: 2.0505512158075967

Epoch: 5| Step: 3
Training loss: 2.611717462539673
Validation loss: 2.0589315742254257

Epoch: 5| Step: 4
Training loss: 1.9663686752319336
Validation loss: 2.056045100092888

Epoch: 5| Step: 5
Training loss: 1.724645972251892
Validation loss: 2.055505484342575

Epoch: 5| Step: 6
Training loss: 2.6455655097961426
Validation loss: 2.0467825531959534

Epoch: 5| Step: 7
Training loss: 1.8178870677947998
Validation loss: 2.040348301331202

Epoch: 5| Step: 8
Training loss: 2.3087143898010254
Validation loss: 2.043055981397629

Epoch: 5| Step: 9
Training loss: 1.5950947999954224
Validation loss: 2.0420586317777634

Epoch: 5| Step: 10
Training loss: 2.2150306701660156
Validation loss: 2.0399902115265527

Epoch: 5| Step: 11
Training loss: 1.1808605194091797
Validation loss: 2.045139893889427

Epoch: 136| Step: 0
Training loss: 2.200226306915283
Validation loss: 2.0419858197371163

Epoch: 5| Step: 1
Training loss: 2.5464906692504883
Validation loss: 2.04621355732282

Epoch: 5| Step: 2
Training loss: 1.9666210412979126
Validation loss: 2.044214347998301

Epoch: 5| Step: 3
Training loss: 1.989797830581665
Validation loss: 2.0368995616833367

Epoch: 5| Step: 4
Training loss: 1.5305830240249634
Validation loss: 2.0434347341458

Epoch: 5| Step: 5
Training loss: 1.6515541076660156
Validation loss: 2.0508648802836738

Epoch: 5| Step: 6
Training loss: 2.198624849319458
Validation loss: 2.0479699770609536

Epoch: 5| Step: 7
Training loss: 1.7137165069580078
Validation loss: 2.046466181675593

Epoch: 5| Step: 8
Training loss: 2.023961305618286
Validation loss: 2.050718421737353

Epoch: 5| Step: 9
Training loss: 2.407787799835205
Validation loss: 2.0520069052775702

Epoch: 5| Step: 10
Training loss: 2.3967599868774414
Validation loss: 2.044768452644348

Epoch: 5| Step: 11
Training loss: 2.238340139389038
Validation loss: 2.047967250148455

Epoch: 137| Step: 0
Training loss: 1.9591152667999268
Validation loss: 2.0512974013884864

Epoch: 5| Step: 1
Training loss: 2.0804526805877686
Validation loss: 2.0458951592445374

Epoch: 5| Step: 2
Training loss: 1.6637914180755615
Validation loss: 2.052251875400543

Epoch: 5| Step: 3
Training loss: 1.744137167930603
Validation loss: 2.0468059331178665

Epoch: 5| Step: 4
Training loss: 2.4557456970214844
Validation loss: 2.0512301921844482

Epoch: 5| Step: 5
Training loss: 2.0983850955963135
Validation loss: 2.049911836783091

Epoch: 5| Step: 6
Training loss: 2.715787172317505
Validation loss: 2.054364502429962

Epoch: 5| Step: 7
Training loss: 2.285966396331787
Validation loss: 2.0442550629377365

Epoch: 5| Step: 8
Training loss: 2.1993372440338135
Validation loss: 2.053788681825002

Epoch: 5| Step: 9
Training loss: 1.6309865713119507
Validation loss: 2.050108234087626

Epoch: 5| Step: 10
Training loss: 1.4132325649261475
Validation loss: 2.0552371641000113

Epoch: 5| Step: 11
Training loss: 3.4744441509246826
Validation loss: 2.0608431696891785

Epoch: 138| Step: 0
Training loss: 1.9886610507965088
Validation loss: 2.0472920536994934

Epoch: 5| Step: 1
Training loss: 2.4186911582946777
Validation loss: 2.045509621500969

Epoch: 5| Step: 2
Training loss: 1.9139297008514404
Validation loss: 2.0494437217712402

Epoch: 5| Step: 3
Training loss: 1.8321841955184937
Validation loss: 2.0520640959342322

Epoch: 5| Step: 4
Training loss: 1.9667047262191772
Validation loss: 2.0390575577815375

Epoch: 5| Step: 5
Training loss: 2.066399097442627
Validation loss: 2.0445329397916794

Epoch: 5| Step: 6
Training loss: 2.2744927406311035
Validation loss: 2.052335133155187

Epoch: 5| Step: 7
Training loss: 1.7605832815170288
Validation loss: 2.0542024622360864

Epoch: 5| Step: 8
Training loss: 1.9970054626464844
Validation loss: 2.056394855181376

Epoch: 5| Step: 9
Training loss: 1.7024046182632446
Validation loss: 2.0540009091297784

Epoch: 5| Step: 10
Training loss: 2.620461940765381
Validation loss: 2.0581114341815314

Epoch: 5| Step: 11
Training loss: 2.739490270614624
Validation loss: 2.0613892575105033

Epoch: 139| Step: 0
Training loss: 1.805111289024353
Validation loss: 2.0584488908449807

Epoch: 5| Step: 1
Training loss: 2.4488720893859863
Validation loss: 2.05697138607502

Epoch: 5| Step: 2
Training loss: 2.2798514366149902
Validation loss: 2.0558017094930015

Epoch: 5| Step: 3
Training loss: 2.5557730197906494
Validation loss: 2.046527480085691

Epoch: 5| Step: 4
Training loss: 2.243600368499756
Validation loss: 2.0478647549947104

Epoch: 5| Step: 5
Training loss: 1.2702503204345703
Validation loss: 2.0453445613384247

Epoch: 5| Step: 6
Training loss: 2.205061435699463
Validation loss: 2.0419634580612183

Epoch: 5| Step: 7
Training loss: 2.1364073753356934
Validation loss: 2.044777144988378

Epoch: 5| Step: 8
Training loss: 1.833848237991333
Validation loss: 2.0449059853951135

Epoch: 5| Step: 9
Training loss: 2.0137436389923096
Validation loss: 2.0458551049232483

Epoch: 5| Step: 10
Training loss: 2.0566155910491943
Validation loss: 2.0531492233276367

Epoch: 5| Step: 11
Training loss: 2.725888967514038
Validation loss: 2.0483145813147225

Epoch: 140| Step: 0
Training loss: 1.933211088180542
Validation loss: 2.056635598341624

Epoch: 5| Step: 1
Training loss: 2.286374568939209
Validation loss: 2.052767589688301

Epoch: 5| Step: 2
Training loss: 2.077660083770752
Validation loss: 2.058733453353246

Epoch: 5| Step: 3
Training loss: 1.8879778385162354
Validation loss: 2.0559111982584

Epoch: 5| Step: 4
Training loss: 2.3558802604675293
Validation loss: 2.0559160808722177

Epoch: 5| Step: 5
Training loss: 1.93085515499115
Validation loss: 2.0630648533503213

Epoch: 5| Step: 6
Training loss: 1.799245834350586
Validation loss: 2.0680287132660546

Epoch: 5| Step: 7
Training loss: 1.8118547201156616
Validation loss: 2.0503168602784476

Epoch: 5| Step: 8
Training loss: 2.0972888469696045
Validation loss: 2.0429776906967163

Epoch: 5| Step: 9
Training loss: 2.2897794246673584
Validation loss: 2.0501523911952972

Epoch: 5| Step: 10
Training loss: 2.056706666946411
Validation loss: 2.044629161556562

Epoch: 5| Step: 11
Training loss: 2.5090644359588623
Validation loss: 2.044570197661718

Epoch: 141| Step: 0
Training loss: 1.9412120580673218
Validation loss: 2.037802149852117

Epoch: 5| Step: 1
Training loss: 2.2630112171173096
Validation loss: 2.0379158705472946

Epoch: 5| Step: 2
Training loss: 1.6485439538955688
Validation loss: 2.031908303499222

Epoch: 5| Step: 3
Training loss: 2.7894809246063232
Validation loss: 2.04063847164313

Epoch: 5| Step: 4
Training loss: 2.06270170211792
Validation loss: 2.0287280678749084

Epoch: 5| Step: 5
Training loss: 2.2085916996002197
Validation loss: 2.0319042652845383

Epoch: 5| Step: 6
Training loss: 1.8376178741455078
Validation loss: 2.0371362765630088

Epoch: 5| Step: 7
Training loss: 2.675210475921631
Validation loss: 2.0350132286548615

Epoch: 5| Step: 8
Training loss: 1.9395354986190796
Validation loss: 2.030776724219322

Epoch: 5| Step: 9
Training loss: 1.360543966293335
Validation loss: 2.0372025072574615

Epoch: 5| Step: 10
Training loss: 2.041630268096924
Validation loss: 2.046516850590706

Epoch: 5| Step: 11
Training loss: 2.2720999717712402
Validation loss: 2.0490121891101203

Epoch: 142| Step: 0
Training loss: 2.383842945098877
Validation loss: 2.052284767230352

Epoch: 5| Step: 1
Training loss: 2.0113844871520996
Validation loss: 2.059507111708323

Epoch: 5| Step: 2
Training loss: 1.5429960489273071
Validation loss: 2.0633838723103204

Epoch: 5| Step: 3
Training loss: 2.460226058959961
Validation loss: 2.0637413760026297

Epoch: 5| Step: 4
Training loss: 2.9908158779144287
Validation loss: 2.0554699848095574

Epoch: 5| Step: 5
Training loss: 1.7409679889678955
Validation loss: 2.045123279094696

Epoch: 5| Step: 6
Training loss: 1.7823539972305298
Validation loss: 2.0427910735209784

Epoch: 5| Step: 7
Training loss: 2.3994739055633545
Validation loss: 2.0460806687672934

Epoch: 5| Step: 8
Training loss: 1.879400610923767
Validation loss: 2.047221784790357

Epoch: 5| Step: 9
Training loss: 1.9277064800262451
Validation loss: 2.0527812788883844

Epoch: 5| Step: 10
Training loss: 1.6298071146011353
Validation loss: 2.046072339018186

Epoch: 5| Step: 11
Training loss: 1.6133228540420532
Validation loss: 2.043814236919085

Epoch: 143| Step: 0
Training loss: 2.4661545753479004
Validation loss: 2.046790157755216

Epoch: 5| Step: 1
Training loss: 1.9844729900360107
Validation loss: 2.048865035176277

Epoch: 5| Step: 2
Training loss: 2.210076332092285
Validation loss: 2.047671208779017

Epoch: 5| Step: 3
Training loss: 2.225602388381958
Validation loss: 2.044258773326874

Epoch: 5| Step: 4
Training loss: 1.556988000869751
Validation loss: 2.040354202191035

Epoch: 5| Step: 5
Training loss: 2.1581735610961914
Validation loss: 2.047114004691442

Epoch: 5| Step: 6
Training loss: 1.6782655715942383
Validation loss: 2.0497354169686637

Epoch: 5| Step: 7
Training loss: 2.7672817707061768
Validation loss: 2.049965222676595

Epoch: 5| Step: 8
Training loss: 1.7111114263534546
Validation loss: 2.050613224506378

Epoch: 5| Step: 9
Training loss: 2.215811252593994
Validation loss: 2.0500639379024506

Epoch: 5| Step: 10
Training loss: 1.5156562328338623
Validation loss: 2.043495128552119

Epoch: 5| Step: 11
Training loss: 2.5446128845214844
Validation loss: 2.057826300462087

Epoch: 144| Step: 0
Training loss: 2.1315085887908936
Validation loss: 2.0539693037668862

Epoch: 5| Step: 1
Training loss: 1.9061435461044312
Validation loss: 2.0693581302960715

Epoch: 5| Step: 2
Training loss: 1.922183632850647
Validation loss: 2.063254495461782

Epoch: 5| Step: 3
Training loss: 2.380284309387207
Validation loss: 2.0594025353590646

Epoch: 5| Step: 4
Training loss: 2.136716604232788
Validation loss: 2.0767393708229065

Epoch: 5| Step: 5
Training loss: 1.3371957540512085
Validation loss: 2.0693668574094772

Epoch: 5| Step: 6
Training loss: 1.990155816078186
Validation loss: 2.061890204747518

Epoch: 5| Step: 7
Training loss: 2.246593475341797
Validation loss: 2.0583595832188926

Epoch: 5| Step: 8
Training loss: 1.9686000347137451
Validation loss: 2.0455502569675446

Epoch: 5| Step: 9
Training loss: 2.342592716217041
Validation loss: 2.0478054185708365

Epoch: 5| Step: 10
Training loss: 2.2890191078186035
Validation loss: 2.0409953395525613

Epoch: 5| Step: 11
Training loss: 1.1641485691070557
Validation loss: 2.0431854923566184

Epoch: 145| Step: 0
Training loss: 2.055607557296753
Validation loss: 2.0382741192976632

Epoch: 5| Step: 1
Training loss: 2.068957805633545
Validation loss: 2.0441303898890815

Epoch: 5| Step: 2
Training loss: 1.929565668106079
Validation loss: 2.0478900919357934

Epoch: 5| Step: 3
Training loss: 2.3066515922546387
Validation loss: 2.039216270049413

Epoch: 5| Step: 4
Training loss: 1.5981861352920532
Validation loss: 2.0420970767736435

Epoch: 5| Step: 5
Training loss: 2.0851800441741943
Validation loss: 2.046427935361862

Epoch: 5| Step: 6
Training loss: 1.963738203048706
Validation loss: 2.047574053208033

Epoch: 5| Step: 7
Training loss: 2.6707961559295654
Validation loss: 2.0403875509897866

Epoch: 5| Step: 8
Training loss: 1.7183434963226318
Validation loss: 2.0428221225738525

Epoch: 5| Step: 9
Training loss: 1.8607574701309204
Validation loss: 2.045765603582064

Epoch: 5| Step: 10
Training loss: 2.0824496746063232
Validation loss: 2.051539977391561

Epoch: 5| Step: 11
Training loss: 3.328235626220703
Validation loss: 2.0485764940579734

Epoch: 146| Step: 0
Training loss: 1.9642436504364014
Validation loss: 2.0477750400702157

Epoch: 5| Step: 1
Training loss: 1.9508880376815796
Validation loss: 2.05172790090243

Epoch: 5| Step: 2
Training loss: 2.3333120346069336
Validation loss: 2.0615055014689765

Epoch: 5| Step: 3
Training loss: 2.1888537406921387
Validation loss: 2.0500824650128684

Epoch: 5| Step: 4
Training loss: 1.7148487567901611
Validation loss: 2.065353751182556

Epoch: 5| Step: 5
Training loss: 2.2499632835388184
Validation loss: 2.052687535683314

Epoch: 5| Step: 6
Training loss: 1.968329668045044
Validation loss: 2.0490489304065704

Epoch: 5| Step: 7
Training loss: 2.1546552181243896
Validation loss: 2.0590314865112305

Epoch: 5| Step: 8
Training loss: 2.268826961517334
Validation loss: 2.0427474826574326

Epoch: 5| Step: 9
Training loss: 2.0613911151885986
Validation loss: 2.048137108484904

Epoch: 5| Step: 10
Training loss: 1.7389453649520874
Validation loss: 2.0471525688966117

Epoch: 5| Step: 11
Training loss: 1.5002541542053223
Validation loss: 2.042208438118299

Epoch: 147| Step: 0
Training loss: 1.7330820560455322
Validation loss: 2.0481970459222794

Epoch: 5| Step: 1
Training loss: 2.3140838146209717
Validation loss: 2.0519905189673104

Epoch: 5| Step: 2
Training loss: 1.561318039894104
Validation loss: 2.043838972846667

Epoch: 5| Step: 3
Training loss: 2.0207886695861816
Validation loss: 2.0446275820334754

Epoch: 5| Step: 4
Training loss: 2.492173433303833
Validation loss: 2.052151327331861

Epoch: 5| Step: 5
Training loss: 2.2628226280212402
Validation loss: 2.045925880471865

Epoch: 5| Step: 6
Training loss: 2.21280574798584
Validation loss: 2.0538951059182486

Epoch: 5| Step: 7
Training loss: 1.8555186986923218
Validation loss: 2.0535184095303216

Epoch: 5| Step: 8
Training loss: 2.182034969329834
Validation loss: 2.049569974342982

Epoch: 5| Step: 9
Training loss: 1.94258713722229
Validation loss: 2.0511429210503898

Epoch: 5| Step: 10
Training loss: 2.192068338394165
Validation loss: 2.0516871313254037

Epoch: 5| Step: 11
Training loss: 1.7413074970245361
Validation loss: 2.055870791276296

Epoch: 148| Step: 0
Training loss: 1.695763349533081
Validation loss: 2.0627346287171044

Epoch: 5| Step: 1
Training loss: 1.7266556024551392
Validation loss: 2.061886285742124

Epoch: 5| Step: 2
Training loss: 2.1250579357147217
Validation loss: 2.068847512205442

Epoch: 5| Step: 3
Training loss: 2.014443874359131
Validation loss: 2.063232551018397

Epoch: 5| Step: 4
Training loss: 2.1283843517303467
Validation loss: 2.0688529014587402

Epoch: 5| Step: 5
Training loss: 2.341545343399048
Validation loss: 2.064861218134562

Epoch: 5| Step: 6
Training loss: 2.117579460144043
Validation loss: 2.0574176212151847

Epoch: 5| Step: 7
Training loss: 1.9033966064453125
Validation loss: 2.0562868068615594

Epoch: 5| Step: 8
Training loss: 2.2618675231933594
Validation loss: 2.0585531840721765

Epoch: 5| Step: 9
Training loss: 2.3392200469970703
Validation loss: 2.0552776008844376

Epoch: 5| Step: 10
Training loss: 1.9762932062149048
Validation loss: 2.057398110628128

Epoch: 5| Step: 11
Training loss: 1.6149346828460693
Validation loss: 2.0512716621160507

Epoch: 149| Step: 0
Training loss: 1.6939146518707275
Validation loss: 2.050634572903315

Epoch: 5| Step: 1
Training loss: 1.4987335205078125
Validation loss: 2.0530684093634286

Epoch: 5| Step: 2
Training loss: 1.3429718017578125
Validation loss: 2.0462165673573813

Epoch: 5| Step: 3
Training loss: 2.5579965114593506
Validation loss: 2.0511995752652488

Epoch: 5| Step: 4
Training loss: 2.2402310371398926
Validation loss: 2.045775388677915

Epoch: 5| Step: 5
Training loss: 2.053640842437744
Validation loss: 2.052413155635198

Epoch: 5| Step: 6
Training loss: 2.2952077388763428
Validation loss: 2.0431729505459466

Epoch: 5| Step: 7
Training loss: 1.6968410015106201
Validation loss: 2.050887331366539

Epoch: 5| Step: 8
Training loss: 2.288696765899658
Validation loss: 2.058179199695587

Epoch: 5| Step: 9
Training loss: 2.7007195949554443
Validation loss: 2.0481136391560235

Epoch: 5| Step: 10
Training loss: 2.294290542602539
Validation loss: 2.054903735717138

Epoch: 5| Step: 11
Training loss: 1.716522455215454
Validation loss: 2.059011777242025

Epoch: 150| Step: 0
Training loss: 1.9861663579940796
Validation loss: 2.052820364634196

Epoch: 5| Step: 1
Training loss: 2.4093141555786133
Validation loss: 2.064434657494227

Epoch: 5| Step: 2
Training loss: 1.837205171585083
Validation loss: 2.069849078853925

Epoch: 5| Step: 3
Training loss: 1.7683331966400146
Validation loss: 2.058345784743627

Epoch: 5| Step: 4
Training loss: 2.384295701980591
Validation loss: 2.068632443745931

Epoch: 5| Step: 5
Training loss: 1.9104950428009033
Validation loss: 2.0542202293872833

Epoch: 5| Step: 6
Training loss: 1.8566033840179443
Validation loss: 2.0533639391263327

Epoch: 5| Step: 7
Training loss: 1.6762101650238037
Validation loss: 2.0526583939790726

Epoch: 5| Step: 8
Training loss: 2.578535556793213
Validation loss: 2.0498196482658386

Epoch: 5| Step: 9
Training loss: 2.1098103523254395
Validation loss: 2.054021547238032

Epoch: 5| Step: 10
Training loss: 2.28383469581604
Validation loss: 2.057136351863543

Epoch: 5| Step: 11
Training loss: 1.0686546564102173
Validation loss: 2.0524851034084954

Epoch: 151| Step: 0
Training loss: 1.9497417211532593
Validation loss: 2.059441124399503

Epoch: 5| Step: 1
Training loss: 1.7634540796279907
Validation loss: 2.0612261494000754

Epoch: 5| Step: 2
Training loss: 2.0900728702545166
Validation loss: 2.0632742444674173

Epoch: 5| Step: 3
Training loss: 2.1913042068481445
Validation loss: 2.064546227455139

Epoch: 5| Step: 4
Training loss: 2.354182243347168
Validation loss: 2.063309520483017

Epoch: 5| Step: 5
Training loss: 1.776384711265564
Validation loss: 2.064086730281512

Epoch: 5| Step: 6
Training loss: 2.348361015319824
Validation loss: 2.067475199699402

Epoch: 5| Step: 7
Training loss: 1.5263386964797974
Validation loss: 2.0615300039450326

Epoch: 5| Step: 8
Training loss: 2.4136180877685547
Validation loss: 2.0640118618806205

Epoch: 5| Step: 9
Training loss: 2.2836296558380127
Validation loss: 2.0723532189925513

Epoch: 5| Step: 10
Training loss: 1.958946943283081
Validation loss: 2.0735798130432763

Epoch: 5| Step: 11
Training loss: 1.4709148406982422
Validation loss: 2.078359996279081

Epoch: 152| Step: 0
Training loss: 1.867570161819458
Validation loss: 2.0774433612823486

Epoch: 5| Step: 1
Training loss: 2.0310120582580566
Validation loss: 2.0765080004930496

Epoch: 5| Step: 2
Training loss: 1.7124340534210205
Validation loss: 2.0698760201533637

Epoch: 5| Step: 3
Training loss: 1.8416063785552979
Validation loss: 2.0695014148950577

Epoch: 5| Step: 4
Training loss: 2.0430188179016113
Validation loss: 2.0740263958772025

Epoch: 5| Step: 5
Training loss: 1.8949483633041382
Validation loss: 2.075266217192014

Epoch: 5| Step: 6
Training loss: 2.4796457290649414
Validation loss: 2.0710084786017737

Epoch: 5| Step: 7
Training loss: 1.7504510879516602
Validation loss: 2.0711298833290734

Epoch: 5| Step: 8
Training loss: 2.3659796714782715
Validation loss: 2.080007235209147

Epoch: 5| Step: 9
Training loss: 2.2152905464172363
Validation loss: 2.0804580648740134

Epoch: 5| Step: 10
Training loss: 2.3834803104400635
Validation loss: 2.0798471868038177

Epoch: 5| Step: 11
Training loss: 1.1241483688354492
Validation loss: 2.079864208896955

Epoch: 153| Step: 0
Training loss: 2.2906317710876465
Validation loss: 2.0822772483030954

Epoch: 5| Step: 1
Training loss: 1.817970871925354
Validation loss: 2.087242220838865

Epoch: 5| Step: 2
Training loss: 2.2305333614349365
Validation loss: 2.0832076569398246

Epoch: 5| Step: 3
Training loss: 1.9973491430282593
Validation loss: 2.083425303300222

Epoch: 5| Step: 4
Training loss: 2.5790915489196777
Validation loss: 2.082015966375669

Epoch: 5| Step: 5
Training loss: 1.8257077932357788
Validation loss: 2.074575513601303

Epoch: 5| Step: 6
Training loss: 1.736092209815979
Validation loss: 2.0829212814569473

Epoch: 5| Step: 7
Training loss: 1.9385408163070679
Validation loss: 2.0857585668563843

Epoch: 5| Step: 8
Training loss: 2.233219861984253
Validation loss: 2.0846608132123947

Epoch: 5| Step: 9
Training loss: 1.3133410215377808
Validation loss: 2.0941495249668756

Epoch: 5| Step: 10
Training loss: 2.1815192699432373
Validation loss: 2.0848680833975473

Epoch: 5| Step: 11
Training loss: 3.0185203552246094
Validation loss: 2.088203271230062

Epoch: 154| Step: 0
Training loss: 1.7414095401763916
Validation loss: 2.091869741678238

Epoch: 5| Step: 1
Training loss: 2.4993391036987305
Validation loss: 2.0847538908322654

Epoch: 5| Step: 2
Training loss: 2.1334710121154785
Validation loss: 2.0915370980898538

Epoch: 5| Step: 3
Training loss: 2.4449431896209717
Validation loss: 2.079945852359136

Epoch: 5| Step: 4
Training loss: 1.3570053577423096
Validation loss: 2.0830996284882226

Epoch: 5| Step: 5
Training loss: 1.9627532958984375
Validation loss: 2.080165902773539

Epoch: 5| Step: 6
Training loss: 2.373504638671875
Validation loss: 2.078238755464554

Epoch: 5| Step: 7
Training loss: 2.04571270942688
Validation loss: 2.0805191745360694

Epoch: 5| Step: 8
Training loss: 1.6235535144805908
Validation loss: 2.0704544385274253

Epoch: 5| Step: 9
Training loss: 2.3078603744506836
Validation loss: 2.0688058932622275

Epoch: 5| Step: 10
Training loss: 1.9381011724472046
Validation loss: 2.069997251033783

Epoch: 5| Step: 11
Training loss: 1.6068485975265503
Validation loss: 2.0814715971549353

Epoch: 155| Step: 0
Training loss: 1.8739759922027588
Validation loss: 2.068768913547198

Epoch: 5| Step: 1
Training loss: 1.4830161333084106
Validation loss: 2.068627640604973

Epoch: 5| Step: 2
Training loss: 2.3162994384765625
Validation loss: 2.0569671789805093

Epoch: 5| Step: 3
Training loss: 1.9112231731414795
Validation loss: 2.055009221037229

Epoch: 5| Step: 4
Training loss: 2.475709915161133
Validation loss: 2.0615558524926505

Epoch: 5| Step: 5
Training loss: 2.2912590503692627
Validation loss: 2.0625102519989014

Epoch: 5| Step: 6
Training loss: 2.06138277053833
Validation loss: 2.062379464507103

Epoch: 5| Step: 7
Training loss: 2.7714977264404297
Validation loss: 2.0570031503836312

Epoch: 5| Step: 8
Training loss: 2.464127779006958
Validation loss: 2.05921870470047

Epoch: 5| Step: 9
Training loss: 1.7526127099990845
Validation loss: 2.05452769001325

Epoch: 5| Step: 10
Training loss: 1.338706135749817
Validation loss: 2.04952002565066

Epoch: 5| Step: 11
Training loss: 0.542407751083374
Validation loss: 2.0515193144480386

Epoch: 156| Step: 0
Training loss: 2.2325305938720703
Validation loss: 2.045980448524157

Epoch: 5| Step: 1
Training loss: 1.9751360416412354
Validation loss: 2.0538713534673056

Epoch: 5| Step: 2
Training loss: 2.384380340576172
Validation loss: 2.054382507999738

Epoch: 5| Step: 3
Training loss: 2.0753002166748047
Validation loss: 2.055992806951205

Epoch: 5| Step: 4
Training loss: 1.3196336030960083
Validation loss: 2.0593722760677338

Epoch: 5| Step: 5
Training loss: 2.282426357269287
Validation loss: 2.062009240190188

Epoch: 5| Step: 6
Training loss: 2.036648988723755
Validation loss: 2.0689332286516824

Epoch: 5| Step: 7
Training loss: 2.028869152069092
Validation loss: 2.0567429115374884

Epoch: 5| Step: 8
Training loss: 1.9786462783813477
Validation loss: 2.0684225261211395

Epoch: 5| Step: 9
Training loss: 2.1186423301696777
Validation loss: 2.05876125395298

Epoch: 5| Step: 10
Training loss: 2.052586555480957
Validation loss: 2.065473347902298

Epoch: 5| Step: 11
Training loss: 1.4859979152679443
Validation loss: 2.0695403665304184

Epoch: 157| Step: 0
Training loss: 1.828669786453247
Validation loss: 2.0725115487972894

Epoch: 5| Step: 1
Training loss: 2.322986125946045
Validation loss: 2.074657122294108

Epoch: 5| Step: 2
Training loss: 2.2488245964050293
Validation loss: 2.0688990453879037

Epoch: 5| Step: 3
Training loss: 1.7575111389160156
Validation loss: 2.053372770547867

Epoch: 5| Step: 4
Training loss: 1.8004363775253296
Validation loss: 2.0580082883437476

Epoch: 5| Step: 5
Training loss: 2.0454800128936768
Validation loss: 2.0603544265031815

Epoch: 5| Step: 6
Training loss: 2.463693141937256
Validation loss: 2.0655315816402435

Epoch: 5| Step: 7
Training loss: 2.17999267578125
Validation loss: 2.0623729079961777

Epoch: 5| Step: 8
Training loss: 2.684053897857666
Validation loss: 2.0692815482616425

Epoch: 5| Step: 9
Training loss: 1.5620137453079224
Validation loss: 2.066309024890264

Epoch: 5| Step: 10
Training loss: 1.3713456392288208
Validation loss: 2.0782270034154258

Epoch: 5| Step: 11
Training loss: 2.2922706604003906
Validation loss: 2.0670905659596124

Epoch: 158| Step: 0
Training loss: 2.7247748374938965
Validation loss: 2.0768624246120453

Epoch: 5| Step: 1
Training loss: 2.096555709838867
Validation loss: 2.0748967925707498

Epoch: 5| Step: 2
Training loss: 2.5833230018615723
Validation loss: 2.0687563518683114

Epoch: 5| Step: 3
Training loss: 1.8872802257537842
Validation loss: 2.071772128343582

Epoch: 5| Step: 4
Training loss: 2.0017943382263184
Validation loss: 2.065283397833506

Epoch: 5| Step: 5
Training loss: 1.5215580463409424
Validation loss: 2.0751758913199105

Epoch: 5| Step: 6
Training loss: 2.0850493907928467
Validation loss: 2.0661273201306662

Epoch: 5| Step: 7
Training loss: 1.5215184688568115
Validation loss: 2.071369235714277

Epoch: 5| Step: 8
Training loss: 1.8395322561264038
Validation loss: 2.057504569490751

Epoch: 5| Step: 9
Training loss: 1.9317413568496704
Validation loss: 2.0589735160271325

Epoch: 5| Step: 10
Training loss: 2.0686185359954834
Validation loss: 2.064490497112274

Epoch: 5| Step: 11
Training loss: 2.307020425796509
Validation loss: 2.063869521021843

Epoch: 159| Step: 0
Training loss: 1.7512619495391846
Validation loss: 2.0658360769351325

Epoch: 5| Step: 1
Training loss: 1.8144114017486572
Validation loss: 2.0706021587053933

Epoch: 5| Step: 2
Training loss: 2.2652130126953125
Validation loss: 2.075263390938441

Epoch: 5| Step: 3
Training loss: 1.503246784210205
Validation loss: 2.0697645594676337

Epoch: 5| Step: 4
Training loss: 1.805712342262268
Validation loss: 2.0751948058605194

Epoch: 5| Step: 5
Training loss: 2.6440906524658203
Validation loss: 2.071924994389216

Epoch: 5| Step: 6
Training loss: 2.0895416736602783
Validation loss: 2.0801554868618646

Epoch: 5| Step: 7
Training loss: 2.043836832046509
Validation loss: 2.0694992740948996

Epoch: 5| Step: 8
Training loss: 2.1420557498931885
Validation loss: 2.0741710563500724

Epoch: 5| Step: 9
Training loss: 2.273306369781494
Validation loss: 2.0713422199090323

Epoch: 5| Step: 10
Training loss: 2.0130467414855957
Validation loss: 2.065649022658666

Epoch: 5| Step: 11
Training loss: 1.5958138704299927
Validation loss: 2.0727809170881906

Epoch: 160| Step: 0
Training loss: 1.9290249347686768
Validation loss: 2.070484141508738

Epoch: 5| Step: 1
Training loss: 1.924454927444458
Validation loss: 2.070567046602567

Epoch: 5| Step: 2
Training loss: 1.701505422592163
Validation loss: 2.074205035964648

Epoch: 5| Step: 3
Training loss: 2.04135799407959
Validation loss: 2.0732610126336417

Epoch: 5| Step: 4
Training loss: 1.8843721151351929
Validation loss: 2.070173998673757

Epoch: 5| Step: 5
Training loss: 2.015289783477783
Validation loss: 2.0785071402788162

Epoch: 5| Step: 6
Training loss: 2.4439563751220703
Validation loss: 2.0734051565329232

Epoch: 5| Step: 7
Training loss: 2.26811146736145
Validation loss: 2.0704159339269004

Epoch: 5| Step: 8
Training loss: 1.7686516046524048
Validation loss: 2.0697490026553473

Epoch: 5| Step: 9
Training loss: 2.059598684310913
Validation loss: 2.07895889878273

Epoch: 5| Step: 10
Training loss: 2.075601100921631
Validation loss: 2.0750521073738732

Epoch: 5| Step: 11
Training loss: 2.0665831565856934
Validation loss: 2.0718878507614136

Epoch: 161| Step: 0
Training loss: 1.6510648727416992
Validation loss: 2.0873647232850394

Epoch: 5| Step: 1
Training loss: 2.685764789581299
Validation loss: 2.0825827419757843

Epoch: 5| Step: 2
Training loss: 1.7003591060638428
Validation loss: 2.080090964833895

Epoch: 5| Step: 3
Training loss: 2.243210554122925
Validation loss: 2.079107070962588

Epoch: 5| Step: 4
Training loss: 1.4500627517700195
Validation loss: 2.0749021470546722

Epoch: 5| Step: 5
Training loss: 1.9418365955352783
Validation loss: 2.081252579887708

Epoch: 5| Step: 6
Training loss: 2.3280673027038574
Validation loss: 2.07653446495533

Epoch: 5| Step: 7
Training loss: 2.3930840492248535
Validation loss: 2.0713010082642236

Epoch: 5| Step: 8
Training loss: 1.885646104812622
Validation loss: 2.0723827381928763

Epoch: 5| Step: 9
Training loss: 2.0582025051116943
Validation loss: 2.07893975575765

Epoch: 5| Step: 10
Training loss: 1.8698272705078125
Validation loss: 2.0746620992819467

Epoch: 5| Step: 11
Training loss: 2.1933882236480713
Validation loss: 2.062247082591057

Epoch: 162| Step: 0
Training loss: 1.593168020248413
Validation loss: 2.0724522123734155

Epoch: 5| Step: 1
Training loss: 2.319053888320923
Validation loss: 2.0811061561107635

Epoch: 5| Step: 2
Training loss: 2.5000901222229004
Validation loss: 2.0834152152140937

Epoch: 5| Step: 3
Training loss: 1.638706922531128
Validation loss: 2.069940765698751

Epoch: 5| Step: 4
Training loss: 2.352874279022217
Validation loss: 2.073765297730764

Epoch: 5| Step: 5
Training loss: 1.5980005264282227
Validation loss: 2.0682068963845572

Epoch: 5| Step: 6
Training loss: 1.90419602394104
Validation loss: 2.077833895881971

Epoch: 5| Step: 7
Training loss: 2.0537705421447754
Validation loss: 2.0802519222100577

Epoch: 5| Step: 8
Training loss: 2.4257073402404785
Validation loss: 2.0745816876490912

Epoch: 5| Step: 9
Training loss: 1.8016490936279297
Validation loss: 2.085933486620585

Epoch: 5| Step: 10
Training loss: 2.126479387283325
Validation loss: 2.073651601870855

Epoch: 5| Step: 11
Training loss: 1.5123655796051025
Validation loss: 2.0783467888832092

Epoch: 163| Step: 0
Training loss: 2.1589388847351074
Validation loss: 2.0745451847712197

Epoch: 5| Step: 1
Training loss: 1.7500355243682861
Validation loss: 2.076273982723554

Epoch: 5| Step: 2
Training loss: 2.409491539001465
Validation loss: 2.0658829708894095

Epoch: 5| Step: 3
Training loss: 2.124439239501953
Validation loss: 2.0673926075299582

Epoch: 5| Step: 4
Training loss: 2.4058549404144287
Validation loss: 2.060431261857351

Epoch: 5| Step: 5
Training loss: 2.1794300079345703
Validation loss: 2.0595573484897614

Epoch: 5| Step: 6
Training loss: 1.5415284633636475
Validation loss: 2.062249998251597

Epoch: 5| Step: 7
Training loss: 2.0448765754699707
Validation loss: 2.0651137133439383

Epoch: 5| Step: 8
Training loss: 1.975579857826233
Validation loss: 2.0441808253526688

Epoch: 5| Step: 9
Training loss: 1.4873428344726562
Validation loss: 2.0479036569595337

Epoch: 5| Step: 10
Training loss: 2.162576675415039
Validation loss: 2.0565800269444785

Epoch: 5| Step: 11
Training loss: 2.486565589904785
Validation loss: 2.0603724867105484

Epoch: 164| Step: 0
Training loss: 2.0993688106536865
Validation loss: 2.0687910517056785

Epoch: 5| Step: 1
Training loss: 2.3167126178741455
Validation loss: 2.076974386970202

Epoch: 5| Step: 2
Training loss: 1.8289581537246704
Validation loss: 2.0995038797458014

Epoch: 5| Step: 3
Training loss: 2.591677665710449
Validation loss: 2.092517872651418

Epoch: 5| Step: 4
Training loss: 2.0082314014434814
Validation loss: 2.0977649043003717

Epoch: 5| Step: 5
Training loss: 2.209887981414795
Validation loss: 2.1015592217445374

Epoch: 5| Step: 6
Training loss: 2.068466901779175
Validation loss: 2.1064825654029846

Epoch: 5| Step: 7
Training loss: 2.1208572387695312
Validation loss: 2.0934618512789407

Epoch: 5| Step: 8
Training loss: 2.2431914806365967
Validation loss: 2.07191293934981

Epoch: 5| Step: 9
Training loss: 1.9634727239608765
Validation loss: 2.060614213347435

Epoch: 5| Step: 10
Training loss: 1.2175137996673584
Validation loss: 2.0612120727698007

Epoch: 5| Step: 11
Training loss: 2.012770414352417
Validation loss: 2.0409356554349265

Epoch: 165| Step: 0
Training loss: 2.315237522125244
Validation loss: 2.055482362707456

Epoch: 5| Step: 1
Training loss: 2.151902675628662
Validation loss: 2.0585953245560327

Epoch: 5| Step: 2
Training loss: 1.5688000917434692
Validation loss: 2.0590882698694863

Epoch: 5| Step: 3
Training loss: 1.7037891149520874
Validation loss: 2.0610613226890564

Epoch: 5| Step: 4
Training loss: 2.5864529609680176
Validation loss: 2.0596994161605835

Epoch: 5| Step: 5
Training loss: 2.0305047035217285
Validation loss: 2.062802776694298

Epoch: 5| Step: 6
Training loss: 2.5550503730773926
Validation loss: 2.063911428054174

Epoch: 5| Step: 7
Training loss: 2.2861061096191406
Validation loss: 2.0677927136421204

Epoch: 5| Step: 8
Training loss: 1.3386917114257812
Validation loss: 2.0666814098755517

Epoch: 5| Step: 9
Training loss: 2.1824278831481934
Validation loss: 2.071345031261444

Epoch: 5| Step: 10
Training loss: 1.6207554340362549
Validation loss: 2.0809920877218246

Epoch: 5| Step: 11
Training loss: 1.538378119468689
Validation loss: 2.0760643581549325

Epoch: 166| Step: 0
Training loss: 1.708967924118042
Validation loss: 2.0789463371038437

Epoch: 5| Step: 1
Training loss: 1.6311250925064087
Validation loss: 2.0891810407241187

Epoch: 5| Step: 2
Training loss: 1.859122633934021
Validation loss: 2.0776140044132867

Epoch: 5| Step: 3
Training loss: 2.3181004524230957
Validation loss: 2.07647605240345

Epoch: 5| Step: 4
Training loss: 2.0740370750427246
Validation loss: 2.0916382372379303

Epoch: 5| Step: 5
Training loss: 2.4664573669433594
Validation loss: 2.080137704809507

Epoch: 5| Step: 6
Training loss: 2.33634877204895
Validation loss: 2.085336372256279

Epoch: 5| Step: 7
Training loss: 2.0275423526763916
Validation loss: 2.088171382745107

Epoch: 5| Step: 8
Training loss: 2.100869655609131
Validation loss: 2.091457784175873

Epoch: 5| Step: 9
Training loss: 1.847537636756897
Validation loss: 2.0879123210906982

Epoch: 5| Step: 10
Training loss: 1.4128576517105103
Validation loss: 2.0858221352100372

Epoch: 5| Step: 11
Training loss: 3.417268753051758
Validation loss: 2.081430673599243

Epoch: 167| Step: 0
Training loss: 2.0651588439941406
Validation loss: 2.067498112718264

Epoch: 5| Step: 1
Training loss: 1.7663583755493164
Validation loss: 2.059928596019745

Epoch: 5| Step: 2
Training loss: 2.267073154449463
Validation loss: 2.0635615239540734

Epoch: 5| Step: 3
Training loss: 1.8150848150253296
Validation loss: 2.0538634061813354

Epoch: 5| Step: 4
Training loss: 2.4074971675872803
Validation loss: 2.0630188584327698

Epoch: 5| Step: 5
Training loss: 1.7599834203720093
Validation loss: 2.054978425304095

Epoch: 5| Step: 6
Training loss: 1.883068323135376
Validation loss: 2.0516790250937142

Epoch: 5| Step: 7
Training loss: 1.8616578578948975
Validation loss: 2.055300692717234

Epoch: 5| Step: 8
Training loss: 1.8679234981536865
Validation loss: 2.063966582218806

Epoch: 5| Step: 9
Training loss: 2.2992537021636963
Validation loss: 2.063655267159144

Epoch: 5| Step: 10
Training loss: 2.1569159030914307
Validation loss: 2.0774451394875846

Epoch: 5| Step: 11
Training loss: 2.2758190631866455
Validation loss: 2.082984447479248

Epoch: 168| Step: 0
Training loss: 1.690093994140625
Validation loss: 2.0964736392100654

Epoch: 5| Step: 1
Training loss: 2.2086730003356934
Validation loss: 2.0982459634542465

Epoch: 5| Step: 2
Training loss: 2.5876083374023438
Validation loss: 2.100711872180303

Epoch: 5| Step: 3
Training loss: 1.9729912281036377
Validation loss: 2.0884026885032654

Epoch: 5| Step: 4
Training loss: 2.3082568645477295
Validation loss: 2.0849401404460273

Epoch: 5| Step: 5
Training loss: 1.7473936080932617
Validation loss: 2.096967260042826

Epoch: 5| Step: 6
Training loss: 2.189411163330078
Validation loss: 2.080680638551712

Epoch: 5| Step: 7
Training loss: 1.3740068674087524
Validation loss: 2.084331581989924

Epoch: 5| Step: 8
Training loss: 2.259204864501953
Validation loss: 2.0859967172145844

Epoch: 5| Step: 9
Training loss: 1.824663519859314
Validation loss: 2.0759161164363227

Epoch: 5| Step: 10
Training loss: 1.9397525787353516
Validation loss: 2.0797748963038125

Epoch: 5| Step: 11
Training loss: 2.34987735748291
Validation loss: 2.078230788310369

Epoch: 169| Step: 0
Training loss: 2.3470540046691895
Validation loss: 2.0827050109704337

Epoch: 5| Step: 1
Training loss: 1.8223199844360352
Validation loss: 2.0738405187924704

Epoch: 5| Step: 2
Training loss: 2.6091651916503906
Validation loss: 2.074021299680074

Epoch: 5| Step: 3
Training loss: 2.6387197971343994
Validation loss: 2.0932802160580954

Epoch: 5| Step: 4
Training loss: 1.4494214057922363
Validation loss: 2.0871655344963074

Epoch: 5| Step: 5
Training loss: 1.8368949890136719
Validation loss: 2.0835313300291696

Epoch: 5| Step: 6
Training loss: 2.5403881072998047
Validation loss: 2.0863907088836036

Epoch: 5| Step: 7
Training loss: 1.507995843887329
Validation loss: 2.084152400493622

Epoch: 5| Step: 8
Training loss: 1.8691905736923218
Validation loss: 2.0740893135468164

Epoch: 5| Step: 9
Training loss: 2.2260665893554688
Validation loss: 2.086962436636289

Epoch: 5| Step: 10
Training loss: 1.2909431457519531
Validation loss: 2.079490880171458

Epoch: 5| Step: 11
Training loss: 1.7422850131988525
Validation loss: 2.0787409593661628

Epoch: 170| Step: 0
Training loss: 1.988476037979126
Validation loss: 2.0897269199291864

Epoch: 5| Step: 1
Training loss: 1.7487510442733765
Validation loss: 2.080523724357287

Epoch: 5| Step: 2
Training loss: 1.878339171409607
Validation loss: 2.0823063800732293

Epoch: 5| Step: 3
Training loss: 2.351407289505005
Validation loss: 2.07871746023496

Epoch: 5| Step: 4
Training loss: 2.0023515224456787
Validation loss: 2.0817540884017944

Epoch: 5| Step: 5
Training loss: 2.202065944671631
Validation loss: 2.0681843707958856

Epoch: 5| Step: 6
Training loss: 2.082582950592041
Validation loss: 2.063977008064588

Epoch: 5| Step: 7
Training loss: 1.8044450283050537
Validation loss: 2.055317203203837

Epoch: 5| Step: 8
Training loss: 1.787221908569336
Validation loss: 2.0546554078658423

Epoch: 5| Step: 9
Training loss: 2.289930820465088
Validation loss: 2.045369411508242

Epoch: 5| Step: 10
Training loss: 2.1693942546844482
Validation loss: 2.053924784064293

Epoch: 5| Step: 11
Training loss: 1.498206615447998
Validation loss: 2.0583091427882514

Epoch: 171| Step: 0
Training loss: 2.170924663543701
Validation loss: 2.0662816216548285

Epoch: 5| Step: 1
Training loss: 1.878485918045044
Validation loss: 2.0637721021970115

Epoch: 5| Step: 2
Training loss: 2.4715163707733154
Validation loss: 2.07934899131457

Epoch: 5| Step: 3
Training loss: 1.7489897012710571
Validation loss: 2.079097037514051

Epoch: 5| Step: 4
Training loss: 1.9828059673309326
Validation loss: 2.077074925104777

Epoch: 5| Step: 5
Training loss: 1.5755096673965454
Validation loss: 2.086055944363276

Epoch: 5| Step: 6
Training loss: 2.3338096141815186
Validation loss: 2.0851138283809028

Epoch: 5| Step: 7
Training loss: 1.8967483043670654
Validation loss: 2.0800779461860657

Epoch: 5| Step: 8
Training loss: 1.8828071355819702
Validation loss: 2.0880214969317117

Epoch: 5| Step: 9
Training loss: 2.740708589553833
Validation loss: 2.08806603650252

Epoch: 5| Step: 10
Training loss: 1.5598053932189941
Validation loss: 2.0793892542521157

Epoch: 5| Step: 11
Training loss: 2.021153450012207
Validation loss: 2.084610730409622

Epoch: 172| Step: 0
Training loss: 1.9619117975234985
Validation loss: 2.088834136724472

Epoch: 5| Step: 1
Training loss: 1.2503107786178589
Validation loss: 2.0904315213362374

Epoch: 5| Step: 2
Training loss: 1.7707099914550781
Validation loss: 2.0954890797535577

Epoch: 5| Step: 3
Training loss: 2.3662400245666504
Validation loss: 2.0827376445134482

Epoch: 5| Step: 4
Training loss: 2.2567801475524902
Validation loss: 2.0814761022726693

Epoch: 5| Step: 5
Training loss: 1.7628562450408936
Validation loss: 2.0825178225835166

Epoch: 5| Step: 6
Training loss: 2.514484405517578
Validation loss: 2.089501569668452

Epoch: 5| Step: 7
Training loss: 2.3742096424102783
Validation loss: 2.069378753503164

Epoch: 5| Step: 8
Training loss: 1.9446327686309814
Validation loss: 2.0781522889932

Epoch: 5| Step: 9
Training loss: 1.8598620891571045
Validation loss: 2.0740133076906204

Epoch: 5| Step: 10
Training loss: 2.0823922157287598
Validation loss: 2.070866490403811

Epoch: 5| Step: 11
Training loss: 2.5426864624023438
Validation loss: 2.0771444886922836

Epoch: 173| Step: 0
Training loss: 2.190183162689209
Validation loss: 2.0727936128775277

Epoch: 5| Step: 1
Training loss: 2.017056941986084
Validation loss: 2.086405952771505

Epoch: 5| Step: 2
Training loss: 2.0323431491851807
Validation loss: 2.0828138639529548

Epoch: 5| Step: 3
Training loss: 2.5127651691436768
Validation loss: 2.0865867088238397

Epoch: 5| Step: 4
Training loss: 1.9066886901855469
Validation loss: 2.0776311407486596

Epoch: 5| Step: 5
Training loss: 1.9075111150741577
Validation loss: 2.0795058459043503

Epoch: 5| Step: 6
Training loss: 1.1127803325653076
Validation loss: 2.0767917037010193

Epoch: 5| Step: 7
Training loss: 2.8233745098114014
Validation loss: 2.070976590116819

Epoch: 5| Step: 8
Training loss: 2.3405392169952393
Validation loss: 2.0598052044709525

Epoch: 5| Step: 9
Training loss: 1.4654533863067627
Validation loss: 2.064602851867676

Epoch: 5| Step: 10
Training loss: 1.968654990196228
Validation loss: 2.062958945830663

Epoch: 5| Step: 11
Training loss: 1.0248196125030518
Validation loss: 2.0664068212111792

Epoch: 174| Step: 0
Training loss: 1.7442680597305298
Validation loss: 2.064893772204717

Epoch: 5| Step: 1
Training loss: 2.2504591941833496
Validation loss: 2.0643028368552527

Epoch: 5| Step: 2
Training loss: 1.8121795654296875
Validation loss: 2.0624677737553916

Epoch: 5| Step: 3
Training loss: 2.3504347801208496
Validation loss: 2.055741921067238

Epoch: 5| Step: 4
Training loss: 1.3934686183929443
Validation loss: 2.056730483969053

Epoch: 5| Step: 5
Training loss: 2.6179039478302
Validation loss: 2.0617255866527557

Epoch: 5| Step: 6
Training loss: 1.736027717590332
Validation loss: 2.0586356967687607

Epoch: 5| Step: 7
Training loss: 2.122450590133667
Validation loss: 2.056401029229164

Epoch: 5| Step: 8
Training loss: 2.098010301589966
Validation loss: 2.058072030544281

Epoch: 5| Step: 9
Training loss: 2.175832748413086
Validation loss: 2.0554726968208947

Epoch: 5| Step: 10
Training loss: 2.0476574897766113
Validation loss: 2.054369101921717

Epoch: 5| Step: 11
Training loss: 1.7815333604812622
Validation loss: 2.054870749513308

Epoch: 175| Step: 0
Training loss: 2.3246312141418457
Validation loss: 2.059683417280515

Epoch: 5| Step: 1
Training loss: 1.7122291326522827
Validation loss: 2.0579242507616677

Epoch: 5| Step: 2
Training loss: 1.67904794216156
Validation loss: 2.0622066954771676

Epoch: 5| Step: 3
Training loss: 2.447770833969116
Validation loss: 2.0665721893310547

Epoch: 5| Step: 4
Training loss: 2.2931411266326904
Validation loss: 2.071363553404808

Epoch: 5| Step: 5
Training loss: 2.1913483142852783
Validation loss: 2.0664421121279397

Epoch: 5| Step: 6
Training loss: 2.252200126647949
Validation loss: 2.0657466103633246

Epoch: 5| Step: 7
Training loss: 2.1345696449279785
Validation loss: 2.069332574804624

Epoch: 5| Step: 8
Training loss: 2.374363422393799
Validation loss: 2.0639666616916656

Epoch: 5| Step: 9
Training loss: 1.5025036334991455
Validation loss: 2.071716547012329

Epoch: 5| Step: 10
Training loss: 1.6736023426055908
Validation loss: 2.0727054526408515

Epoch: 5| Step: 11
Training loss: 1.4460170269012451
Validation loss: 2.0732742100954056

Epoch: 176| Step: 0
Training loss: 1.9023778438568115
Validation loss: 2.077622413635254

Epoch: 5| Step: 1
Training loss: 2.4037880897521973
Validation loss: 2.0660487661759057

Epoch: 5| Step: 2
Training loss: 1.4175046682357788
Validation loss: 2.066671664516131

Epoch: 5| Step: 3
Training loss: 2.1540586948394775
Validation loss: 2.071371535460154

Epoch: 5| Step: 4
Training loss: 2.165295124053955
Validation loss: 2.075679982701937

Epoch: 5| Step: 5
Training loss: 1.7861884832382202
Validation loss: 2.072630817691485

Epoch: 5| Step: 6
Training loss: 1.8385956287384033
Validation loss: 2.0815470467011132

Epoch: 5| Step: 7
Training loss: 2.335249423980713
Validation loss: 2.073974480231603

Epoch: 5| Step: 8
Training loss: 2.032059669494629
Validation loss: 2.0737917373577752

Epoch: 5| Step: 9
Training loss: 2.2211973667144775
Validation loss: 2.0677931010723114

Epoch: 5| Step: 10
Training loss: 1.8146024942398071
Validation loss: 2.0706376979748407

Epoch: 5| Step: 11
Training loss: 2.13454008102417
Validation loss: 2.0703605016072593

Epoch: 177| Step: 0
Training loss: 1.710045576095581
Validation loss: 2.0681033631165824

Epoch: 5| Step: 1
Training loss: 2.175875425338745
Validation loss: 2.0697165677944818

Epoch: 5| Step: 2
Training loss: 2.068795680999756
Validation loss: 2.0694329539934793

Epoch: 5| Step: 3
Training loss: 1.871504545211792
Validation loss: 2.064364790916443

Epoch: 5| Step: 4
Training loss: 2.040639877319336
Validation loss: 2.0668058892091117

Epoch: 5| Step: 5
Training loss: 1.5115798711776733
Validation loss: 2.0594511230786643

Epoch: 5| Step: 6
Training loss: 2.1152758598327637
Validation loss: 2.0658068805933

Epoch: 5| Step: 7
Training loss: 2.4668102264404297
Validation loss: 2.0593339055776596

Epoch: 5| Step: 8
Training loss: 2.38852596282959
Validation loss: 2.0604334473609924

Epoch: 5| Step: 9
Training loss: 1.5822117328643799
Validation loss: 2.0555932919184365

Epoch: 5| Step: 10
Training loss: 2.305570125579834
Validation loss: 2.0566559781630835

Epoch: 5| Step: 11
Training loss: 1.3777161836624146
Validation loss: 2.056553468108177

Epoch: 178| Step: 0
Training loss: 1.6972911357879639
Validation loss: 2.063062792023023

Epoch: 5| Step: 1
Training loss: 2.3294575214385986
Validation loss: 2.0587409287691116

Epoch: 5| Step: 2
Training loss: 1.7274078130722046
Validation loss: 2.061604917049408

Epoch: 5| Step: 3
Training loss: 1.9511216878890991
Validation loss: 2.067520414789518

Epoch: 5| Step: 4
Training loss: 2.4130680561065674
Validation loss: 2.074844708045324

Epoch: 5| Step: 5
Training loss: 2.1646342277526855
Validation loss: 2.062259634335836

Epoch: 5| Step: 6
Training loss: 1.8995466232299805
Validation loss: 2.062076116601626

Epoch: 5| Step: 7
Training loss: 2.077014923095703
Validation loss: 2.0689303229252496

Epoch: 5| Step: 8
Training loss: 1.4043972492218018
Validation loss: 2.0557183921337128

Epoch: 5| Step: 9
Training loss: 2.473187208175659
Validation loss: 2.062670345107714

Epoch: 5| Step: 10
Training loss: 2.1654038429260254
Validation loss: 2.0666424284378686

Epoch: 5| Step: 11
Training loss: 1.046593189239502
Validation loss: 2.067702050010363

Epoch: 179| Step: 0
Training loss: 2.3888237476348877
Validation loss: 2.067078376809756

Epoch: 5| Step: 1
Training loss: 1.7791486978530884
Validation loss: 2.0702077945073447

Epoch: 5| Step: 2
Training loss: 1.9252369403839111
Validation loss: 2.078632523616155

Epoch: 5| Step: 3
Training loss: 2.354860782623291
Validation loss: 2.0746947278579078

Epoch: 5| Step: 4
Training loss: 1.520992636680603
Validation loss: 2.0710535496473312

Epoch: 5| Step: 5
Training loss: 2.546677827835083
Validation loss: 2.0643533964951835

Epoch: 5| Step: 6
Training loss: 1.5210130214691162
Validation loss: 2.075671449303627

Epoch: 5| Step: 7
Training loss: 2.301806926727295
Validation loss: 2.082775508364042

Epoch: 5| Step: 8
Training loss: 1.7566115856170654
Validation loss: 2.081133415301641

Epoch: 5| Step: 9
Training loss: 2.2105801105499268
Validation loss: 2.079579532146454

Epoch: 5| Step: 10
Training loss: 1.9609954357147217
Validation loss: 2.0824698408444724

Epoch: 5| Step: 11
Training loss: 1.7897664308547974
Validation loss: 2.0817216088374457

Epoch: 180| Step: 0
Training loss: 2.346242666244507
Validation loss: 2.0757959137360253

Epoch: 5| Step: 1
Training loss: 1.886855125427246
Validation loss: 2.0784151454766593

Epoch: 5| Step: 2
Training loss: 2.0053741931915283
Validation loss: 2.075796658794085

Epoch: 5| Step: 3
Training loss: 1.6804463863372803
Validation loss: 2.0692530969778695

Epoch: 5| Step: 4
Training loss: 1.5678714513778687
Validation loss: 2.0704570710659027

Epoch: 5| Step: 5
Training loss: 1.8387073278427124
Validation loss: 2.0746632367372513

Epoch: 5| Step: 6
Training loss: 2.6474504470825195
Validation loss: 2.076881304383278

Epoch: 5| Step: 7
Training loss: 2.0977370738983154
Validation loss: 2.0705964068571725

Epoch: 5| Step: 8
Training loss: 2.0836398601531982
Validation loss: 2.075266420841217

Epoch: 5| Step: 9
Training loss: 2.0217316150665283
Validation loss: 2.07080086072286

Epoch: 5| Step: 10
Training loss: 2.0196681022644043
Validation loss: 2.079362908999125

Epoch: 5| Step: 11
Training loss: 1.7229126691818237
Validation loss: 2.063265567024549

Epoch: 181| Step: 0
Training loss: 1.8680200576782227
Validation loss: 2.0704722901185355

Epoch: 5| Step: 1
Training loss: 2.3038558959960938
Validation loss: 2.0731849720080695

Epoch: 5| Step: 2
Training loss: 1.8295987844467163
Validation loss: 2.0556194384892783

Epoch: 5| Step: 3
Training loss: 1.9848140478134155
Validation loss: 2.065798213084539

Epoch: 5| Step: 4
Training loss: 1.3283560276031494
Validation loss: 2.067452291647593

Epoch: 5| Step: 5
Training loss: 2.1376445293426514
Validation loss: 2.0827012111743293

Epoch: 5| Step: 6
Training loss: 2.368640422821045
Validation loss: 2.086131304502487

Epoch: 5| Step: 7
Training loss: 1.6282707452774048
Validation loss: 2.0787195215622583

Epoch: 5| Step: 8
Training loss: 2.6417346000671387
Validation loss: 2.085703839858373

Epoch: 5| Step: 9
Training loss: 1.6484193801879883
Validation loss: 2.085402066508929

Epoch: 5| Step: 10
Training loss: 2.365393877029419
Validation loss: 2.0806618680556617

Epoch: 5| Step: 11
Training loss: 1.8039244413375854
Validation loss: 2.0896080334981284

Epoch: 182| Step: 0
Training loss: 1.3539257049560547
Validation loss: 2.082526574532191

Epoch: 5| Step: 1
Training loss: 1.8880512714385986
Validation loss: 2.07906104127566

Epoch: 5| Step: 2
Training loss: 2.403111457824707
Validation loss: 2.0842881202697754

Epoch: 5| Step: 3
Training loss: 1.959856629371643
Validation loss: 2.06417744855086

Epoch: 5| Step: 4
Training loss: 1.7640495300292969
Validation loss: 2.060160825649897

Epoch: 5| Step: 5
Training loss: 1.9788986444473267
Validation loss: 2.0653823415438333

Epoch: 5| Step: 6
Training loss: 2.3932394981384277
Validation loss: 2.0637189944585166

Epoch: 5| Step: 7
Training loss: 2.096864700317383
Validation loss: 2.0643110970656076

Epoch: 5| Step: 8
Training loss: 2.2055866718292236
Validation loss: 2.066273803512255

Epoch: 5| Step: 9
Training loss: 2.113967180252075
Validation loss: 2.0645309736331305

Epoch: 5| Step: 10
Training loss: 2.079040288925171
Validation loss: 2.069795106848081

Epoch: 5| Step: 11
Training loss: 2.1164326667785645
Validation loss: 2.074666897455851

Epoch: 183| Step: 0
Training loss: 2.0990562438964844
Validation loss: 2.073941503961881

Epoch: 5| Step: 1
Training loss: 1.8023735284805298
Validation loss: 2.0719548563162484

Epoch: 5| Step: 2
Training loss: 1.8964531421661377
Validation loss: 2.075067182381948

Epoch: 5| Step: 3
Training loss: 1.6765708923339844
Validation loss: 2.083838472763697

Epoch: 5| Step: 4
Training loss: 1.7187044620513916
Validation loss: 2.0812142888704934

Epoch: 5| Step: 5
Training loss: 2.045703411102295
Validation loss: 2.0769882202148438

Epoch: 5| Step: 6
Training loss: 1.5202257633209229
Validation loss: 2.0969735234975815

Epoch: 5| Step: 7
Training loss: 2.122807264328003
Validation loss: 2.0888640582561493

Epoch: 5| Step: 8
Training loss: 2.340867042541504
Validation loss: 2.0831004232168198

Epoch: 5| Step: 9
Training loss: 2.4291720390319824
Validation loss: 2.093261336286863

Epoch: 5| Step: 10
Training loss: 2.3175601959228516
Validation loss: 2.0933150152365365

Epoch: 5| Step: 11
Training loss: 2.121906280517578
Validation loss: 2.090403214097023

Epoch: 184| Step: 0
Training loss: 1.9911056756973267
Validation loss: 2.0813185771306357

Epoch: 5| Step: 1
Training loss: 1.7637866735458374
Validation loss: 2.0780292550722756

Epoch: 5| Step: 2
Training loss: 2.3004915714263916
Validation loss: 2.086906388401985

Epoch: 5| Step: 3
Training loss: 2.3154683113098145
Validation loss: 2.082694133122762

Epoch: 5| Step: 4
Training loss: 2.221343755722046
Validation loss: 2.0844147503376007

Epoch: 5| Step: 5
Training loss: 1.2445734739303589
Validation loss: 2.0893684476614

Epoch: 5| Step: 6
Training loss: 2.0314712524414062
Validation loss: 2.088439628481865

Epoch: 5| Step: 7
Training loss: 2.4584383964538574
Validation loss: 2.083458721637726

Epoch: 5| Step: 8
Training loss: 1.7674033641815186
Validation loss: 2.077749972542127

Epoch: 5| Step: 9
Training loss: 1.956658959388733
Validation loss: 2.0808273752530417

Epoch: 5| Step: 10
Training loss: 1.9150784015655518
Validation loss: 2.077620138724645

Epoch: 5| Step: 11
Training loss: 2.34736704826355
Validation loss: 2.0740482012430825

Epoch: 185| Step: 0
Training loss: 2.155179262161255
Validation loss: 2.0774037589629493

Epoch: 5| Step: 1
Training loss: 2.1205756664276123
Validation loss: 2.07563087840875

Epoch: 5| Step: 2
Training loss: 1.9638588428497314
Validation loss: 2.07733021179835

Epoch: 5| Step: 3
Training loss: 2.2122304439544678
Validation loss: 2.0707470724980035

Epoch: 5| Step: 4
Training loss: 1.9238563776016235
Validation loss: 2.0749717950820923

Epoch: 5| Step: 5
Training loss: 2.074094295501709
Validation loss: 2.0855999092260995

Epoch: 5| Step: 6
Training loss: 1.9954659938812256
Validation loss: 2.078113332390785

Epoch: 5| Step: 7
Training loss: 2.122037410736084
Validation loss: 2.0792884627978006

Epoch: 5| Step: 8
Training loss: 1.4322196245193481
Validation loss: 2.075120136141777

Epoch: 5| Step: 9
Training loss: 1.7872711420059204
Validation loss: 2.073623761534691

Epoch: 5| Step: 10
Training loss: 1.8470535278320312
Validation loss: 2.069742480913798

Epoch: 5| Step: 11
Training loss: 4.297610282897949
Validation loss: 2.058480749527613

Epoch: 186| Step: 0
Training loss: 1.9909547567367554
Validation loss: 2.0604960521062217

Epoch: 5| Step: 1
Training loss: 2.035341739654541
Validation loss: 2.049992327888807

Epoch: 5| Step: 2
Training loss: 2.2360222339630127
Validation loss: 2.052329584956169

Epoch: 5| Step: 3
Training loss: 2.089993476867676
Validation loss: 2.0564228941996894

Epoch: 5| Step: 4
Training loss: 2.225175142288208
Validation loss: 2.04751725991567

Epoch: 5| Step: 5
Training loss: 2.278670072555542
Validation loss: 2.0482292671998343

Epoch: 5| Step: 6
Training loss: 1.9340028762817383
Validation loss: 2.050186092654864

Epoch: 5| Step: 7
Training loss: 1.8235164880752563
Validation loss: 2.0452345510323844

Epoch: 5| Step: 8
Training loss: 2.25429368019104
Validation loss: 2.042120243112246

Epoch: 5| Step: 9
Training loss: 1.9172594547271729
Validation loss: 2.0397462298472724

Epoch: 5| Step: 10
Training loss: 1.893302321434021
Validation loss: 2.0348861614863076

Epoch: 5| Step: 11
Training loss: 3.2345142364501953
Validation loss: 2.031065767010053

Epoch: 187| Step: 0
Training loss: 2.058763027191162
Validation loss: 2.047786553700765

Epoch: 5| Step: 1
Training loss: 1.7700941562652588
Validation loss: 2.041699454188347

Epoch: 5| Step: 2
Training loss: 2.0618417263031006
Validation loss: 2.045221741000811

Epoch: 5| Step: 3
Training loss: 1.813741683959961
Validation loss: 2.053455342849096

Epoch: 5| Step: 4
Training loss: 1.9045469760894775
Validation loss: 2.0655268331368766

Epoch: 5| Step: 5
Training loss: 2.06658935546875
Validation loss: 2.069782535235087

Epoch: 5| Step: 6
Training loss: 2.219489336013794
Validation loss: 2.074642683068911

Epoch: 5| Step: 7
Training loss: 1.9002621173858643
Validation loss: 2.0758687953154245

Epoch: 5| Step: 8
Training loss: 1.9963594675064087
Validation loss: 2.070714463790258

Epoch: 5| Step: 9
Training loss: 2.3067874908447266
Validation loss: 2.0676627159118652

Epoch: 5| Step: 10
Training loss: 2.0835683345794678
Validation loss: 2.068426420291265

Epoch: 5| Step: 11
Training loss: 2.6282753944396973
Validation loss: 2.0678021063407264

Epoch: 188| Step: 0
Training loss: 1.8347275257110596
Validation loss: 2.075393949945768

Epoch: 5| Step: 1
Training loss: 1.7266967296600342
Validation loss: 2.068559462825457

Epoch: 5| Step: 2
Training loss: 1.8049424886703491
Validation loss: 2.0685084710518518

Epoch: 5| Step: 3
Training loss: 1.842687964439392
Validation loss: 2.0704743713140488

Epoch: 5| Step: 4
Training loss: 1.9364099502563477
Validation loss: 2.0789926449457803

Epoch: 5| Step: 5
Training loss: 2.4583637714385986
Validation loss: 2.0728435814380646

Epoch: 5| Step: 6
Training loss: 2.051227569580078
Validation loss: 2.069672167301178

Epoch: 5| Step: 7
Training loss: 2.1907715797424316
Validation loss: 2.072207748889923

Epoch: 5| Step: 8
Training loss: 1.8320600986480713
Validation loss: 2.0715675552686057

Epoch: 5| Step: 9
Training loss: 1.753056287765503
Validation loss: 2.073161398371061

Epoch: 5| Step: 10
Training loss: 2.2895379066467285
Validation loss: 2.0808964570363364

Epoch: 5| Step: 11
Training loss: 2.6391043663024902
Validation loss: 2.081269900004069

Epoch: 189| Step: 0
Training loss: 2.098125457763672
Validation loss: 2.08428963025411

Epoch: 5| Step: 1
Training loss: 1.9676103591918945
Validation loss: 2.0714851369460425

Epoch: 5| Step: 2
Training loss: 1.3125313520431519
Validation loss: 2.07620303829511

Epoch: 5| Step: 3
Training loss: 2.2736668586730957
Validation loss: 2.0897486259539924

Epoch: 5| Step: 4
Training loss: 1.9027290344238281
Validation loss: 2.088753933707873

Epoch: 5| Step: 5
Training loss: 1.4200537204742432
Validation loss: 2.086051255464554

Epoch: 5| Step: 6
Training loss: 2.035569667816162
Validation loss: 2.0899545351664224

Epoch: 5| Step: 7
Training loss: 2.5857086181640625
Validation loss: 2.0901778439680734

Epoch: 5| Step: 8
Training loss: 2.410304307937622
Validation loss: 2.0910818725824356

Epoch: 5| Step: 9
Training loss: 1.7773878574371338
Validation loss: 2.081036855777105

Epoch: 5| Step: 10
Training loss: 1.877478003501892
Validation loss: 2.0917897721131644

Epoch: 5| Step: 11
Training loss: 3.414645195007324
Validation loss: 2.094106470545133

Epoch: 190| Step: 0
Training loss: 1.4942147731781006
Validation loss: 2.093398784597715

Epoch: 5| Step: 1
Training loss: 2.675178050994873
Validation loss: 2.096641555428505

Epoch: 5| Step: 2
Training loss: 1.6371583938598633
Validation loss: 2.0824231952428818

Epoch: 5| Step: 3
Training loss: 1.6583776473999023
Validation loss: 2.083586980899175

Epoch: 5| Step: 4
Training loss: 1.575570821762085
Validation loss: 2.0915034959713616

Epoch: 5| Step: 5
Training loss: 2.417466402053833
Validation loss: 2.082536672552427

Epoch: 5| Step: 6
Training loss: 2.9964756965637207
Validation loss: 2.080431029200554

Epoch: 5| Step: 7
Training loss: 1.9598649740219116
Validation loss: 2.0833259920279183

Epoch: 5| Step: 8
Training loss: 1.8001915216445923
Validation loss: 2.0914847602446875

Epoch: 5| Step: 9
Training loss: 1.7993509769439697
Validation loss: 2.077234481771787

Epoch: 5| Step: 10
Training loss: 1.55471932888031
Validation loss: 2.084788590669632

Epoch: 5| Step: 11
Training loss: 2.567615032196045
Validation loss: 2.080387090643247

Epoch: 191| Step: 0
Training loss: 2.2428598403930664
Validation loss: 2.08623705804348

Epoch: 5| Step: 1
Training loss: 2.3350086212158203
Validation loss: 2.087056120236715

Epoch: 5| Step: 2
Training loss: 1.2238786220550537
Validation loss: 2.0851826816797256

Epoch: 5| Step: 3
Training loss: 2.3934192657470703
Validation loss: 2.093547354141871

Epoch: 5| Step: 4
Training loss: 1.6274011135101318
Validation loss: 2.089810460805893

Epoch: 5| Step: 5
Training loss: 2.0497515201568604
Validation loss: 2.1016893833875656

Epoch: 5| Step: 6
Training loss: 2.226630449295044
Validation loss: 2.097675641377767

Epoch: 5| Step: 7
Training loss: 2.108863353729248
Validation loss: 2.0926930010318756

Epoch: 5| Step: 8
Training loss: 1.8836867809295654
Validation loss: 2.095989932616552

Epoch: 5| Step: 9
Training loss: 2.0620040893554688
Validation loss: 2.1037787795066833

Epoch: 5| Step: 10
Training loss: 1.8178552389144897
Validation loss: 2.096429338057836

Epoch: 5| Step: 11
Training loss: 1.1321803331375122
Validation loss: 2.1043977985779443

Epoch: 192| Step: 0
Training loss: 1.824669599533081
Validation loss: 2.095180854201317

Epoch: 5| Step: 1
Training loss: 2.271392822265625
Validation loss: 2.095017751057943

Epoch: 5| Step: 2
Training loss: 1.9425846338272095
Validation loss: 2.095250055193901

Epoch: 5| Step: 3
Training loss: 2.2070813179016113
Validation loss: 2.095467189947764

Epoch: 5| Step: 4
Training loss: 1.8181407451629639
Validation loss: 2.103272115190824

Epoch: 5| Step: 5
Training loss: 2.097804069519043
Validation loss: 2.110966682434082

Epoch: 5| Step: 6
Training loss: 2.19169282913208
Validation loss: 2.095365693171819

Epoch: 5| Step: 7
Training loss: 1.518998622894287
Validation loss: 2.0942833622296653

Epoch: 5| Step: 8
Training loss: 1.8826286792755127
Validation loss: 2.095356196165085

Epoch: 5| Step: 9
Training loss: 2.309086322784424
Validation loss: 2.095551297068596

Epoch: 5| Step: 10
Training loss: 2.046731472015381
Validation loss: 2.097746123870214

Epoch: 5| Step: 11
Training loss: 2.162870407104492
Validation loss: 2.091591810186704

Epoch: 193| Step: 0
Training loss: 1.5522148609161377
Validation loss: 2.0948313772678375

Epoch: 5| Step: 1
Training loss: 1.6484076976776123
Validation loss: 2.0987365742524466

Epoch: 5| Step: 2
Training loss: 2.610319137573242
Validation loss: 2.099544276793798

Epoch: 5| Step: 3
Training loss: 2.4755618572235107
Validation loss: 2.099452883005142

Epoch: 5| Step: 4
Training loss: 1.5748440027236938
Validation loss: 2.101057638724645

Epoch: 5| Step: 5
Training loss: 1.6979420185089111
Validation loss: 2.089971055587133

Epoch: 5| Step: 6
Training loss: 2.6210951805114746
Validation loss: 2.0962569812933602

Epoch: 5| Step: 7
Training loss: 1.6055530309677124
Validation loss: 2.0986251880725226

Epoch: 5| Step: 8
Training loss: 1.5778067111968994
Validation loss: 2.096487725774447

Epoch: 5| Step: 9
Training loss: 2.1800715923309326
Validation loss: 2.102333724498749

Epoch: 5| Step: 10
Training loss: 2.0412373542785645
Validation loss: 2.097280959288279

Epoch: 5| Step: 11
Training loss: 2.914883613586426
Validation loss: 2.103309392929077

Epoch: 194| Step: 0
Training loss: 1.5870106220245361
Validation loss: 2.0980957597494125

Epoch: 5| Step: 1
Training loss: 1.5102689266204834
Validation loss: 2.0895236482222876

Epoch: 5| Step: 2
Training loss: 2.68739652633667
Validation loss: 2.088151996334394

Epoch: 5| Step: 3
Training loss: 1.7087020874023438
Validation loss: 2.1137117594480515

Epoch: 5| Step: 4
Training loss: 1.9104869365692139
Validation loss: 2.1050250977277756

Epoch: 5| Step: 5
Training loss: 2.1427927017211914
Validation loss: 2.104960630337397

Epoch: 5| Step: 6
Training loss: 1.6535484790802002
Validation loss: 2.0922939280668893

Epoch: 5| Step: 7
Training loss: 2.2869887351989746
Validation loss: 2.089288592338562

Epoch: 5| Step: 8
Training loss: 1.6057837009429932
Validation loss: 2.095755805571874

Epoch: 5| Step: 9
Training loss: 2.121004581451416
Validation loss: 2.086049795150757

Epoch: 5| Step: 10
Training loss: 2.2262625694274902
Validation loss: 2.1020322889089584

Epoch: 5| Step: 11
Training loss: 2.6483235359191895
Validation loss: 2.0972931385040283

Epoch: 195| Step: 0
Training loss: 1.318169355392456
Validation loss: 2.0894864052534103

Epoch: 5| Step: 1
Training loss: 2.2292754650115967
Validation loss: 2.098498359322548

Epoch: 5| Step: 2
Training loss: 1.5256541967391968
Validation loss: 2.0908515403668084

Epoch: 5| Step: 3
Training loss: 2.0333566665649414
Validation loss: 2.083632464210192

Epoch: 5| Step: 4
Training loss: 1.8740780353546143
Validation loss: 2.0872679203748703

Epoch: 5| Step: 5
Training loss: 1.9785890579223633
Validation loss: 2.085213487346967

Epoch: 5| Step: 6
Training loss: 2.2182412147521973
Validation loss: 2.0873730778694153

Epoch: 5| Step: 7
Training loss: 2.3881824016571045
Validation loss: 2.076585258046786

Epoch: 5| Step: 8
Training loss: 2.026313066482544
Validation loss: 2.0814208736022315

Epoch: 5| Step: 9
Training loss: 2.0892863273620605
Validation loss: 2.0793330520391464

Epoch: 5| Step: 10
Training loss: 1.9623550176620483
Validation loss: 2.079608569542567

Epoch: 5| Step: 11
Training loss: 2.575362205505371
Validation loss: 2.084348907073339

Epoch: 196| Step: 0
Training loss: 1.6183712482452393
Validation loss: 2.0649999380111694

Epoch: 5| Step: 1
Training loss: 2.0807883739471436
Validation loss: 2.074294482668241

Epoch: 5| Step: 2
Training loss: 1.9556033611297607
Validation loss: 2.0667253683010736

Epoch: 5| Step: 3
Training loss: 2.4833908081054688
Validation loss: 2.0859438478946686

Epoch: 5| Step: 4
Training loss: 2.4268901348114014
Validation loss: 2.0784231772025428

Epoch: 5| Step: 5
Training loss: 2.335789442062378
Validation loss: 2.0781166901191077

Epoch: 5| Step: 6
Training loss: 1.999245047569275
Validation loss: 2.083290462692579

Epoch: 5| Step: 7
Training loss: 1.4654653072357178
Validation loss: 2.096927061676979

Epoch: 5| Step: 8
Training loss: 2.398749828338623
Validation loss: 2.0888677338759103

Epoch: 5| Step: 9
Training loss: 2.0952515602111816
Validation loss: 2.0818719963232675

Epoch: 5| Step: 10
Training loss: 1.4148585796356201
Validation loss: 2.0810152739286423

Epoch: 5| Step: 11
Training loss: 0.5713973045349121
Validation loss: 2.0798183480898538

Epoch: 197| Step: 0
Training loss: 2.11708402633667
Validation loss: 2.0861626664797464

Epoch: 5| Step: 1
Training loss: 2.0306146144866943
Validation loss: 2.0700348963340125

Epoch: 5| Step: 2
Training loss: 1.9801757335662842
Validation loss: 2.0735732515652976

Epoch: 5| Step: 3
Training loss: 1.9234155416488647
Validation loss: 2.0877325435479483

Epoch: 5| Step: 4
Training loss: 1.5674247741699219
Validation loss: 2.0807549953460693

Epoch: 5| Step: 5
Training loss: 2.551833152770996
Validation loss: 2.089701786637306

Epoch: 5| Step: 6
Training loss: 1.8455709218978882
Validation loss: 2.0802686909834542

Epoch: 5| Step: 7
Training loss: 1.7019602060317993
Validation loss: 2.083799401919047

Epoch: 5| Step: 8
Training loss: 1.7831695079803467
Validation loss: 2.095914671818415

Epoch: 5| Step: 9
Training loss: 2.3671088218688965
Validation loss: 2.0955038319031396

Epoch: 5| Step: 10
Training loss: 1.7307125329971313
Validation loss: 2.0906733721494675

Epoch: 5| Step: 11
Training loss: 1.8695255517959595
Validation loss: 2.1058229555686316

Epoch: 198| Step: 0
Training loss: 1.710325002670288
Validation loss: 2.0986756483713784

Epoch: 5| Step: 1
Training loss: 2.7082276344299316
Validation loss: 2.095312555631002

Epoch: 5| Step: 2
Training loss: 2.315047264099121
Validation loss: 2.10246142745018

Epoch: 5| Step: 3
Training loss: 1.8197314739227295
Validation loss: 2.0927929431200027

Epoch: 5| Step: 4
Training loss: 1.7398033142089844
Validation loss: 2.0886886368195214

Epoch: 5| Step: 5
Training loss: 1.8458868265151978
Validation loss: 2.0829490770896277

Epoch: 5| Step: 6
Training loss: 1.8275238275527954
Validation loss: 2.0909049014250436

Epoch: 5| Step: 7
Training loss: 2.213351011276245
Validation loss: 2.077603449424108

Epoch: 5| Step: 8
Training loss: 2.104356288909912
Validation loss: 2.075376197695732

Epoch: 5| Step: 9
Training loss: 2.0335006713867188
Validation loss: 2.0704185167948403

Epoch: 5| Step: 10
Training loss: 1.8905178308486938
Validation loss: 2.0822152396043143

Epoch: 5| Step: 11
Training loss: 1.4526097774505615
Validation loss: 2.0596843957901

Epoch: 199| Step: 0
Training loss: 2.039806842803955
Validation loss: 2.077957570552826

Epoch: 5| Step: 1
Training loss: 2.0395610332489014
Validation loss: 2.082641209165255

Epoch: 5| Step: 2
Training loss: 2.0593743324279785
Validation loss: 2.0880869030952454

Epoch: 5| Step: 3
Training loss: 1.9678668975830078
Validation loss: 2.0888533741235733

Epoch: 5| Step: 4
Training loss: 1.7893329858779907
Validation loss: 2.088431974252065

Epoch: 5| Step: 5
Training loss: 2.1334376335144043
Validation loss: 2.1112921833992004

Epoch: 5| Step: 6
Training loss: 2.0579512119293213
Validation loss: 2.092341805497805

Epoch: 5| Step: 7
Training loss: 2.4555439949035645
Validation loss: 2.1035842498143515

Epoch: 5| Step: 8
Training loss: 2.111048698425293
Validation loss: 2.10686257481575

Epoch: 5| Step: 9
Training loss: 1.5431958436965942
Validation loss: 2.0959551880757012

Epoch: 5| Step: 10
Training loss: 1.883296251296997
Validation loss: 2.1074784298737845

Epoch: 5| Step: 11
Training loss: 1.6214922666549683
Validation loss: 2.1049774636824927

Epoch: 200| Step: 0
Training loss: 1.815070390701294
Validation loss: 2.107758397857348

Epoch: 5| Step: 1
Training loss: 1.916219711303711
Validation loss: 2.102441002925237

Epoch: 5| Step: 2
Training loss: 1.8367048501968384
Validation loss: 2.1050718277692795

Epoch: 5| Step: 3
Training loss: 1.901573896408081
Validation loss: 2.106408029794693

Epoch: 5| Step: 4
Training loss: 2.0890908241271973
Validation loss: 2.107110212246577

Epoch: 5| Step: 5
Training loss: 2.388097047805786
Validation loss: 2.1149445921182632

Epoch: 5| Step: 6
Training loss: 2.572049617767334
Validation loss: 2.116907447576523

Epoch: 5| Step: 7
Training loss: 1.9086605310440063
Validation loss: 2.1113652984301248

Epoch: 5| Step: 8
Training loss: 1.454928994178772
Validation loss: 2.109091783563296

Epoch: 5| Step: 9
Training loss: 1.8054399490356445
Validation loss: 2.113509068886439

Epoch: 5| Step: 10
Training loss: 2.0398783683776855
Validation loss: 2.102623328566551

Epoch: 5| Step: 11
Training loss: 1.7307263612747192
Validation loss: 2.117620751261711

Epoch: 201| Step: 0
Training loss: 2.3367905616760254
Validation loss: 2.114476094643275

Epoch: 5| Step: 1
Training loss: 1.9628347158432007
Validation loss: 2.109065959850947

Epoch: 5| Step: 2
Training loss: 2.1759753227233887
Validation loss: 2.1095860501130423

Epoch: 5| Step: 3
Training loss: 2.094874382019043
Validation loss: 2.1002903381983438

Epoch: 5| Step: 4
Training loss: 2.151837110519409
Validation loss: 2.109670966863632

Epoch: 5| Step: 5
Training loss: 2.007864475250244
Validation loss: 2.115493575731913

Epoch: 5| Step: 6
Training loss: 1.9806745052337646
Validation loss: 2.1050973186890283

Epoch: 5| Step: 7
Training loss: 1.5350029468536377
Validation loss: 2.1118788570165634

Epoch: 5| Step: 8
Training loss: 2.170119524002075
Validation loss: 2.1157390028238297

Epoch: 5| Step: 9
Training loss: 1.6111921072006226
Validation loss: 2.1129828145106635

Epoch: 5| Step: 10
Training loss: 1.6766207218170166
Validation loss: 2.1059815833965936

Epoch: 5| Step: 11
Training loss: 0.8329285979270935
Validation loss: 2.103487635652224

Epoch: 202| Step: 0
Training loss: 2.1408820152282715
Validation loss: 2.086376577615738

Epoch: 5| Step: 1
Training loss: 1.9797203540802002
Validation loss: 2.0966952244440713

Epoch: 5| Step: 2
Training loss: 2.0586466789245605
Validation loss: 2.0860903362433114

Epoch: 5| Step: 3
Training loss: 1.616637945175171
Validation loss: 2.097467174132665

Epoch: 5| Step: 4
Training loss: 2.079983949661255
Validation loss: 2.0867369075616202

Epoch: 5| Step: 5
Training loss: 1.832679033279419
Validation loss: 2.0862914075454078

Epoch: 5| Step: 6
Training loss: 1.404822587966919
Validation loss: 2.0852093497912088

Epoch: 5| Step: 7
Training loss: 2.1981968879699707
Validation loss: 2.093880151708921

Epoch: 5| Step: 8
Training loss: 2.467484951019287
Validation loss: 2.1013275533914566

Epoch: 5| Step: 9
Training loss: 1.8267343044281006
Validation loss: 2.119185040394465

Epoch: 5| Step: 10
Training loss: 2.2412679195404053
Validation loss: 2.11058642466863

Epoch: 5| Step: 11
Training loss: 1.2896627187728882
Validation loss: 2.122015098730723

Epoch: 203| Step: 0
Training loss: 2.222120761871338
Validation loss: 2.117552394668261

Epoch: 5| Step: 1
Training loss: 1.692763090133667
Validation loss: 2.129744033018748

Epoch: 5| Step: 2
Training loss: 2.7671749591827393
Validation loss: 2.1283119718233743

Epoch: 5| Step: 3
Training loss: 2.174591541290283
Validation loss: 2.1318103770414987

Epoch: 5| Step: 4
Training loss: 1.784898042678833
Validation loss: 2.1393204083045325

Epoch: 5| Step: 5
Training loss: 1.8725931644439697
Validation loss: 2.128097956379255

Epoch: 5| Step: 6
Training loss: 1.7251224517822266
Validation loss: 2.1193013191223145

Epoch: 5| Step: 7
Training loss: 2.1919615268707275
Validation loss: 2.1247850557168326

Epoch: 5| Step: 8
Training loss: 1.631211280822754
Validation loss: 2.11301951110363

Epoch: 5| Step: 9
Training loss: 1.894945502281189
Validation loss: 2.1161766995986304

Epoch: 5| Step: 10
Training loss: 1.758309006690979
Validation loss: 2.119816303253174

Epoch: 5| Step: 11
Training loss: 1.9590518474578857
Validation loss: 2.1316447059313455

Epoch: 204| Step: 0
Training loss: 2.4664926528930664
Validation loss: 2.1276995738347373

Epoch: 5| Step: 1
Training loss: 1.6342655420303345
Validation loss: 2.1300794382890067

Epoch: 5| Step: 2
Training loss: 1.4875400066375732
Validation loss: 2.1293581426143646

Epoch: 5| Step: 3
Training loss: 1.9687258005142212
Validation loss: 2.1303794284661612

Epoch: 5| Step: 4
Training loss: 1.6858062744140625
Validation loss: 2.1371564467748008

Epoch: 5| Step: 5
Training loss: 2.2087748050689697
Validation loss: 2.1321565210819244

Epoch: 5| Step: 6
Training loss: 2.1967861652374268
Validation loss: 2.133610134323438

Epoch: 5| Step: 7
Training loss: 1.55074143409729
Validation loss: 2.121562490860621

Epoch: 5| Step: 8
Training loss: 1.7989463806152344
Validation loss: 2.124477098385493

Epoch: 5| Step: 9
Training loss: 2.4819178581237793
Validation loss: 2.1258096992969513

Epoch: 5| Step: 10
Training loss: 2.0208380222320557
Validation loss: 2.1343936224778495

Epoch: 5| Step: 11
Training loss: 1.7427746057510376
Validation loss: 2.130405863126119

Epoch: 205| Step: 0
Training loss: 1.9028606414794922
Validation loss: 2.134060338139534

Epoch: 5| Step: 1
Training loss: 2.1160495281219482
Validation loss: 2.1271203011274338

Epoch: 5| Step: 2
Training loss: 2.075575351715088
Validation loss: 2.1223471413056054

Epoch: 5| Step: 3
Training loss: 2.244459867477417
Validation loss: 2.122922499974569

Epoch: 5| Step: 4
Training loss: 1.6815685033798218
Validation loss: 2.1268088718255362

Epoch: 5| Step: 5
Training loss: 1.9875282049179077
Validation loss: 2.1334738483031592

Epoch: 5| Step: 6
Training loss: 1.642486810684204
Validation loss: 2.1351666996876397

Epoch: 5| Step: 7
Training loss: 1.9703680276870728
Validation loss: 2.137651264667511

Epoch: 5| Step: 8
Training loss: 1.973043441772461
Validation loss: 2.136543055375417

Epoch: 5| Step: 9
Training loss: 2.0751945972442627
Validation loss: 2.1287010113398233

Epoch: 5| Step: 10
Training loss: 2.0124802589416504
Validation loss: 2.1347007552782693

Epoch: 5| Step: 11
Training loss: 1.0410780906677246
Validation loss: 2.1278195728858313

Epoch: 206| Step: 0
Training loss: 2.230879783630371
Validation loss: 2.1347268472115197

Epoch: 5| Step: 1
Training loss: 1.8791911602020264
Validation loss: 2.1305019855499268

Epoch: 5| Step: 2
Training loss: 1.964250922203064
Validation loss: 2.1382357478141785

Epoch: 5| Step: 3
Training loss: 1.7563495635986328
Validation loss: 2.1584430932998657

Epoch: 5| Step: 4
Training loss: 1.2934386730194092
Validation loss: 2.142189472913742

Epoch: 5| Step: 5
Training loss: 1.8622095584869385
Validation loss: 2.1277025242646537

Epoch: 5| Step: 6
Training loss: 2.1451501846313477
Validation loss: 2.1382122486829758

Epoch: 5| Step: 7
Training loss: 2.314548969268799
Validation loss: 2.1381094406048455

Epoch: 5| Step: 8
Training loss: 1.7469679117202759
Validation loss: 2.12584525346756

Epoch: 5| Step: 9
Training loss: 1.9600948095321655
Validation loss: 2.1404164731502533

Epoch: 5| Step: 10
Training loss: 2.024681568145752
Validation loss: 2.12420624991258

Epoch: 5| Step: 11
Training loss: 2.8046045303344727
Validation loss: 2.125655541817347

Epoch: 207| Step: 0
Training loss: 1.7080895900726318
Validation loss: 2.1209819366534552

Epoch: 5| Step: 1
Training loss: 1.9910705089569092
Validation loss: 2.111961459120115

Epoch: 5| Step: 2
Training loss: 1.7288024425506592
Validation loss: 2.112377400199572

Epoch: 5| Step: 3
Training loss: 2.180049419403076
Validation loss: 2.1175515999396644

Epoch: 5| Step: 4
Training loss: 1.8515360355377197
Validation loss: 2.103669121861458

Epoch: 5| Step: 5
Training loss: 1.7230844497680664
Validation loss: 2.0957352121671042

Epoch: 5| Step: 6
Training loss: 2.431377649307251
Validation loss: 2.108690157532692

Epoch: 5| Step: 7
Training loss: 1.8865083456039429
Validation loss: 2.101922561724981

Epoch: 5| Step: 8
Training loss: 1.8627710342407227
Validation loss: 2.1184777269760766

Epoch: 5| Step: 9
Training loss: 2.0521857738494873
Validation loss: 2.1169021328290305

Epoch: 5| Step: 10
Training loss: 1.8830324411392212
Validation loss: 2.1181992838780084

Epoch: 5| Step: 11
Training loss: 3.16733980178833
Validation loss: 2.135940064986547

Epoch: 208| Step: 0
Training loss: 2.0691628456115723
Validation loss: 2.123849163452784

Epoch: 5| Step: 1
Training loss: 1.693545937538147
Validation loss: 2.119567940632502

Epoch: 5| Step: 2
Training loss: 1.2624616622924805
Validation loss: 2.1229838132858276

Epoch: 5| Step: 3
Training loss: 2.2084927558898926
Validation loss: 2.1173626482486725

Epoch: 5| Step: 4
Training loss: 1.637089729309082
Validation loss: 2.1152165830135345

Epoch: 5| Step: 5
Training loss: 2.280411720275879
Validation loss: 2.112707550326983

Epoch: 5| Step: 6
Training loss: 1.887351632118225
Validation loss: 2.107400193810463

Epoch: 5| Step: 7
Training loss: 1.9886020421981812
Validation loss: 2.11901201804479

Epoch: 5| Step: 8
Training loss: 2.0813369750976562
Validation loss: 2.1226311326026917

Epoch: 5| Step: 9
Training loss: 2.5757744312286377
Validation loss: 2.1217285643021264

Epoch: 5| Step: 10
Training loss: 2.0286917686462402
Validation loss: 2.113232081135114

Epoch: 5| Step: 11
Training loss: 1.8801229000091553
Validation loss: 2.106339693069458

Epoch: 209| Step: 0
Training loss: 1.99701726436615
Validation loss: 2.10224919517835

Epoch: 5| Step: 1
Training loss: 2.0188395977020264
Validation loss: 2.0988250176111856

Epoch: 5| Step: 2
Training loss: 1.7368175983428955
Validation loss: 2.1009957989056907

Epoch: 5| Step: 3
Training loss: 1.9604480266571045
Validation loss: 2.0954533020655313

Epoch: 5| Step: 4
Training loss: 1.9636704921722412
Validation loss: 2.091084028283755

Epoch: 5| Step: 5
Training loss: 1.8774089813232422
Validation loss: 2.08829136689504

Epoch: 5| Step: 6
Training loss: 2.1352698802948
Validation loss: 2.089396903912226

Epoch: 5| Step: 7
Training loss: 2.238597869873047
Validation loss: 2.094395264983177

Epoch: 5| Step: 8
Training loss: 1.6499245166778564
Validation loss: 2.084887757897377

Epoch: 5| Step: 9
Training loss: 1.976157784461975
Validation loss: 2.086219772696495

Epoch: 5| Step: 10
Training loss: 2.424656391143799
Validation loss: 2.089410826563835

Epoch: 5| Step: 11
Training loss: 2.114213228225708
Validation loss: 2.094327141841253

Epoch: 210| Step: 0
Training loss: 1.9938223361968994
Validation loss: 2.1017693678538003

Epoch: 5| Step: 1
Training loss: 1.660257339477539
Validation loss: 2.099655787150065

Epoch: 5| Step: 2
Training loss: 2.4614899158477783
Validation loss: 2.105744649966558

Epoch: 5| Step: 3
Training loss: 2.0314674377441406
Validation loss: 2.117843965689341

Epoch: 5| Step: 4
Training loss: 1.6702085733413696
Validation loss: 2.1194195250670114

Epoch: 5| Step: 5
Training loss: 2.3701248168945312
Validation loss: 2.1286860605080924

Epoch: 5| Step: 6
Training loss: 2.0448672771453857
Validation loss: 2.131041248639425

Epoch: 5| Step: 7
Training loss: 1.5068087577819824
Validation loss: 2.129476636648178

Epoch: 5| Step: 8
Training loss: 1.9111210107803345
Validation loss: 2.13187604645888

Epoch: 5| Step: 9
Training loss: 1.9536857604980469
Validation loss: 2.128682017326355

Epoch: 5| Step: 10
Training loss: 1.9323676824569702
Validation loss: 2.1163135965665183

Epoch: 5| Step: 11
Training loss: 2.4059348106384277
Validation loss: 2.1261248042186103

Epoch: 211| Step: 0
Training loss: 1.698365569114685
Validation loss: 2.1200827608505883

Epoch: 5| Step: 1
Training loss: 1.4813772439956665
Validation loss: 2.1251532634099326

Epoch: 5| Step: 2
Training loss: 1.8437902927398682
Validation loss: 2.1193773299455643

Epoch: 5| Step: 3
Training loss: 1.6449639797210693
Validation loss: 2.1193927178780236

Epoch: 5| Step: 4
Training loss: 2.5960655212402344
Validation loss: 2.1105253845453262

Epoch: 5| Step: 5
Training loss: 1.5237246751785278
Validation loss: 2.1138683458169303

Epoch: 5| Step: 6
Training loss: 1.5211290121078491
Validation loss: 2.1034796436627707

Epoch: 5| Step: 7
Training loss: 2.055676221847534
Validation loss: 2.1156062533458075

Epoch: 5| Step: 8
Training loss: 2.6565802097320557
Validation loss: 2.1107959945996604

Epoch: 5| Step: 9
Training loss: 2.1846790313720703
Validation loss: 2.1129759699106216

Epoch: 5| Step: 10
Training loss: 2.4185550212860107
Validation loss: 2.1183714965979257

Epoch: 5| Step: 11
Training loss: 1.28907310962677
Validation loss: 2.1181480139493942

Epoch: 212| Step: 0
Training loss: 1.8239723443984985
Validation loss: 2.130287935336431

Epoch: 5| Step: 1
Training loss: 2.559959888458252
Validation loss: 2.129702255129814

Epoch: 5| Step: 2
Training loss: 1.4885272979736328
Validation loss: 2.133951554695765

Epoch: 5| Step: 3
Training loss: 2.336747646331787
Validation loss: 2.121795271833738

Epoch: 5| Step: 4
Training loss: 1.6422914266586304
Validation loss: 2.119845593969027

Epoch: 5| Step: 5
Training loss: 1.8580650091171265
Validation loss: 2.1304050584634147

Epoch: 5| Step: 6
Training loss: 1.8318370580673218
Validation loss: 2.128916303316752

Epoch: 5| Step: 7
Training loss: 1.4818873405456543
Validation loss: 2.1163115054368973

Epoch: 5| Step: 8
Training loss: 2.27421498298645
Validation loss: 2.1220255345106125

Epoch: 5| Step: 9
Training loss: 2.375936508178711
Validation loss: 2.123504916826884

Epoch: 5| Step: 10
Training loss: 1.876124620437622
Validation loss: 2.1174109180768332

Epoch: 5| Step: 11
Training loss: 1.8179000616073608
Validation loss: 2.1236866116523743

Epoch: 213| Step: 0
Training loss: 1.8366010189056396
Validation loss: 2.1144632697105408

Epoch: 5| Step: 1
Training loss: 1.7680402994155884
Validation loss: 2.1221642096837363

Epoch: 5| Step: 2
Training loss: 2.3435704708099365
Validation loss: 2.1125090022881827

Epoch: 5| Step: 3
Training loss: 1.7005144357681274
Validation loss: 2.110489090283712

Epoch: 5| Step: 4
Training loss: 1.7197107076644897
Validation loss: 2.105302318930626

Epoch: 5| Step: 5
Training loss: 1.5630121231079102
Validation loss: 2.1136917223532996

Epoch: 5| Step: 6
Training loss: 2.8231756687164307
Validation loss: 2.1101682980855307

Epoch: 5| Step: 7
Training loss: 1.8996093273162842
Validation loss: 2.1017823914686837

Epoch: 5| Step: 8
Training loss: 2.171004295349121
Validation loss: 2.104137053092321

Epoch: 5| Step: 9
Training loss: 1.9563238620758057
Validation loss: 2.0953198671340942

Epoch: 5| Step: 10
Training loss: 1.753308892250061
Validation loss: 2.1057167996962867

Epoch: 5| Step: 11
Training loss: 1.6523103713989258
Validation loss: 2.094269643227259

Epoch: 214| Step: 0
Training loss: 2.426811695098877
Validation loss: 2.1016652385393777

Epoch: 5| Step: 1
Training loss: 1.763273000717163
Validation loss: 2.1093737880388894

Epoch: 5| Step: 2
Training loss: 1.7383846044540405
Validation loss: 2.1091888546943665

Epoch: 5| Step: 3
Training loss: 2.1903645992279053
Validation loss: 2.097313721974691

Epoch: 5| Step: 4
Training loss: 2.030510902404785
Validation loss: 2.105653946598371

Epoch: 5| Step: 5
Training loss: 1.693924903869629
Validation loss: 2.096833402911822

Epoch: 5| Step: 6
Training loss: 1.7203832864761353
Validation loss: 2.1098933120568595

Epoch: 5| Step: 7
Training loss: 1.7829567193984985
Validation loss: 2.106643040974935

Epoch: 5| Step: 8
Training loss: 2.0099921226501465
Validation loss: 2.099651589989662

Epoch: 5| Step: 9
Training loss: 1.9955780506134033
Validation loss: 2.112214128176371

Epoch: 5| Step: 10
Training loss: 2.517941474914551
Validation loss: 2.103338211774826

Epoch: 5| Step: 11
Training loss: 0.8888474702835083
Validation loss: 2.097947602470716

Epoch: 215| Step: 0
Training loss: 2.2317423820495605
Validation loss: 2.0994687229394913

Epoch: 5| Step: 1
Training loss: 2.0452094078063965
Validation loss: 2.0949680457512536

Epoch: 5| Step: 2
Training loss: 1.8397066593170166
Validation loss: 2.1034344881772995

Epoch: 5| Step: 3
Training loss: 1.7020238637924194
Validation loss: 2.0999011447032294

Epoch: 5| Step: 4
Training loss: 1.9734036922454834
Validation loss: 2.1096318860848746

Epoch: 5| Step: 5
Training loss: 2.058659076690674
Validation loss: 2.1016162435213723

Epoch: 5| Step: 6
Training loss: 2.0063512325286865
Validation loss: 2.102497786283493

Epoch: 5| Step: 7
Training loss: 1.6029850244522095
Validation loss: 2.0999120275179544

Epoch: 5| Step: 8
Training loss: 2.0218310356140137
Validation loss: 2.0995799551407495

Epoch: 5| Step: 9
Training loss: 1.712825059890747
Validation loss: 2.1068086524804435

Epoch: 5| Step: 10
Training loss: 2.792558431625366
Validation loss: 2.108117943008741

Epoch: 5| Step: 11
Training loss: 1.371230959892273
Validation loss: 2.097912813226382

Epoch: 216| Step: 0
Training loss: 2.0091776847839355
Validation loss: 2.115625520547231

Epoch: 5| Step: 1
Training loss: 2.131136655807495
Validation loss: 2.0919694701830545

Epoch: 5| Step: 2
Training loss: 1.9728498458862305
Validation loss: 2.0991620471080146

Epoch: 5| Step: 3
Training loss: 2.238909959793091
Validation loss: 2.105777387817701

Epoch: 5| Step: 4
Training loss: 2.1904258728027344
Validation loss: 2.0993353029092154

Epoch: 5| Step: 5
Training loss: 2.306032419204712
Validation loss: 2.098504970471064

Epoch: 5| Step: 6
Training loss: 1.7677032947540283
Validation loss: 2.100887914498647

Epoch: 5| Step: 7
Training loss: 1.6781508922576904
Validation loss: 2.100402275721232

Epoch: 5| Step: 8
Training loss: 2.0447163581848145
Validation loss: 2.1086798210938773

Epoch: 5| Step: 9
Training loss: 1.5927549600601196
Validation loss: 2.1086382965246835

Epoch: 5| Step: 10
Training loss: 1.4346933364868164
Validation loss: 2.113089775045713

Epoch: 5| Step: 11
Training loss: 0.9854404330253601
Validation loss: 2.097294439872106

Epoch: 217| Step: 0
Training loss: 1.7594327926635742
Validation loss: 2.105670750141144

Epoch: 5| Step: 1
Training loss: 1.4805351495742798
Validation loss: 2.104072774449984

Epoch: 5| Step: 2
Training loss: 1.3975818157196045
Validation loss: 2.11253921687603

Epoch: 5| Step: 3
Training loss: 1.8691825866699219
Validation loss: 2.123662988344828

Epoch: 5| Step: 4
Training loss: 2.336608409881592
Validation loss: 2.1039526909589767

Epoch: 5| Step: 5
Training loss: 1.9644197225570679
Validation loss: 2.1076031774282455

Epoch: 5| Step: 6
Training loss: 1.7857170104980469
Validation loss: 2.1056994646787643

Epoch: 5| Step: 7
Training loss: 2.122668981552124
Validation loss: 2.1225189864635468

Epoch: 5| Step: 8
Training loss: 2.2304458618164062
Validation loss: 2.1128005981445312

Epoch: 5| Step: 9
Training loss: 2.0649075508117676
Validation loss: 2.1104762107133865

Epoch: 5| Step: 10
Training loss: 1.9652068614959717
Validation loss: 2.1133939921855927

Epoch: 5| Step: 11
Training loss: 2.60880708694458
Validation loss: 2.1100866248210273

Epoch: 218| Step: 0
Training loss: 2.160849094390869
Validation loss: 2.12051593263944

Epoch: 5| Step: 1
Training loss: 1.7085645198822021
Validation loss: 2.119401733080546

Epoch: 5| Step: 2
Training loss: 2.0006916522979736
Validation loss: 2.1318930784861245

Epoch: 5| Step: 3
Training loss: 2.1095845699310303
Validation loss: 2.123229533433914

Epoch: 5| Step: 4
Training loss: 1.4669784307479858
Validation loss: 2.143950199087461

Epoch: 5| Step: 5
Training loss: 1.751410722732544
Validation loss: 2.1345646182696023

Epoch: 5| Step: 6
Training loss: 2.1770761013031006
Validation loss: 2.1389424403508506

Epoch: 5| Step: 7
Training loss: 1.5905482769012451
Validation loss: 2.1360515455404916

Epoch: 5| Step: 8
Training loss: 2.327096939086914
Validation loss: 2.133547614018122

Epoch: 5| Step: 9
Training loss: 1.9154860973358154
Validation loss: 2.1305842300256095

Epoch: 5| Step: 10
Training loss: 2.0129075050354004
Validation loss: 2.11627334356308

Epoch: 5| Step: 11
Training loss: 1.2008388042449951
Validation loss: 2.123384495576223

Epoch: 219| Step: 0
Training loss: 1.2242777347564697
Validation loss: 2.1261317481597266

Epoch: 5| Step: 1
Training loss: 1.700659155845642
Validation loss: 2.1278167913357415

Epoch: 5| Step: 2
Training loss: 1.907430648803711
Validation loss: 2.121090958515803

Epoch: 5| Step: 3
Training loss: 1.8318183422088623
Validation loss: 2.1229677398999534

Epoch: 5| Step: 4
Training loss: 2.202446460723877
Validation loss: 2.114685505628586

Epoch: 5| Step: 5
Training loss: 1.7103732824325562
Validation loss: 2.128387222687403

Epoch: 5| Step: 6
Training loss: 2.042900562286377
Validation loss: 2.1352921426296234

Epoch: 5| Step: 7
Training loss: 1.9079622030258179
Validation loss: 2.1338321963946023

Epoch: 5| Step: 8
Training loss: 1.9273879528045654
Validation loss: 2.1272007723649344

Epoch: 5| Step: 9
Training loss: 2.7009682655334473
Validation loss: 2.1315617014964423

Epoch: 5| Step: 10
Training loss: 2.3661694526672363
Validation loss: 2.137927850087484

Epoch: 5| Step: 11
Training loss: 0.3091905415058136
Validation loss: 2.1310787399609885

Epoch: 220| Step: 0
Training loss: 1.674216866493225
Validation loss: 2.143739918867747

Epoch: 5| Step: 1
Training loss: 1.8335485458374023
Validation loss: 2.128755579392115

Epoch: 5| Step: 2
Training loss: 1.6985433101654053
Validation loss: 2.136417349179586

Epoch: 5| Step: 3
Training loss: 2.1125359535217285
Validation loss: 2.118522673845291

Epoch: 5| Step: 4
Training loss: 2.010295867919922
Validation loss: 2.126038283109665

Epoch: 5| Step: 5
Training loss: 2.4544825553894043
Validation loss: 2.1206005016962686

Epoch: 5| Step: 6
Training loss: 2.021946907043457
Validation loss: 2.12938458720843

Epoch: 5| Step: 7
Training loss: 1.6817957162857056
Validation loss: 2.116820822159449

Epoch: 5| Step: 8
Training loss: 2.434333324432373
Validation loss: 2.127442494034767

Epoch: 5| Step: 9
Training loss: 1.469434380531311
Validation loss: 2.1320659617582955

Epoch: 5| Step: 10
Training loss: 2.0304477214813232
Validation loss: 2.1200593461592994

Epoch: 5| Step: 11
Training loss: 1.3792128562927246
Validation loss: 2.126891106367111

Epoch: 221| Step: 0
Training loss: 1.826223611831665
Validation loss: 2.123469660679499

Epoch: 5| Step: 1
Training loss: 2.0071041584014893
Validation loss: 2.1236966848373413

Epoch: 5| Step: 2
Training loss: 2.060572385787964
Validation loss: 2.130493109424909

Epoch: 5| Step: 3
Training loss: 1.6394548416137695
Validation loss: 2.1253971556822457

Epoch: 5| Step: 4
Training loss: 1.4677813053131104
Validation loss: 2.1183733443419137

Epoch: 5| Step: 5
Training loss: 1.7931772470474243
Validation loss: 2.1287895490725837

Epoch: 5| Step: 6
Training loss: 1.6570374965667725
Validation loss: 2.140402317047119

Epoch: 5| Step: 7
Training loss: 2.6292850971221924
Validation loss: 2.1393711318572364

Epoch: 5| Step: 8
Training loss: 2.074082612991333
Validation loss: 2.144543468952179

Epoch: 5| Step: 9
Training loss: 1.8532819747924805
Validation loss: 2.13858163356781

Epoch: 5| Step: 10
Training loss: 2.179103374481201
Validation loss: 2.1439854552348456

Epoch: 5| Step: 11
Training loss: 2.2683699131011963
Validation loss: 2.1410844027996063

Epoch: 222| Step: 0
Training loss: 1.8517982959747314
Validation loss: 2.142755697170893

Epoch: 5| Step: 1
Training loss: 2.186178684234619
Validation loss: 2.136688689390818

Epoch: 5| Step: 2
Training loss: 2.1988813877105713
Validation loss: 2.1424225866794586

Epoch: 5| Step: 3
Training loss: 1.9643205404281616
Validation loss: 2.142086610198021

Epoch: 5| Step: 4
Training loss: 1.8944787979125977
Validation loss: 2.1411438236633935

Epoch: 5| Step: 5
Training loss: 1.5102767944335938
Validation loss: 2.1449564397335052

Epoch: 5| Step: 6
Training loss: 2.0583271980285645
Validation loss: 2.1361657083034515

Epoch: 5| Step: 7
Training loss: 2.217653274536133
Validation loss: 2.1408458054065704

Epoch: 5| Step: 8
Training loss: 1.6382853984832764
Validation loss: 2.1241985062758126

Epoch: 5| Step: 9
Training loss: 1.9334003925323486
Validation loss: 2.1243757804234824

Epoch: 5| Step: 10
Training loss: 1.8438018560409546
Validation loss: 2.126970941821734

Epoch: 5| Step: 11
Training loss: 1.1739263534545898
Validation loss: 2.1237088640530906

Epoch: 223| Step: 0
Training loss: 1.9582080841064453
Validation loss: 2.136035601298014

Epoch: 5| Step: 1
Training loss: 1.9582042694091797
Validation loss: 2.125279019276301

Epoch: 5| Step: 2
Training loss: 2.010183811187744
Validation loss: 2.1231574515501657

Epoch: 5| Step: 3
Training loss: 1.7885253429412842
Validation loss: 2.136333336432775

Epoch: 5| Step: 4
Training loss: 1.9142032861709595
Validation loss: 2.114311933517456

Epoch: 5| Step: 5
Training loss: 1.8332369327545166
Validation loss: 2.1315560092528663

Epoch: 5| Step: 6
Training loss: 1.7460235357284546
Validation loss: 2.1365205496549606

Epoch: 5| Step: 7
Training loss: 2.0650417804718018
Validation loss: 2.1340557436148324

Epoch: 5| Step: 8
Training loss: 1.7020784616470337
Validation loss: 2.125056028366089

Epoch: 5| Step: 9
Training loss: 1.7253856658935547
Validation loss: 2.1277452210585275

Epoch: 5| Step: 10
Training loss: 2.2930498123168945
Validation loss: 2.128645360469818

Epoch: 5| Step: 11
Training loss: 2.770141124725342
Validation loss: 2.12983504931132

Epoch: 224| Step: 0
Training loss: 2.6846702098846436
Validation loss: 2.133537143468857

Epoch: 5| Step: 1
Training loss: 1.6916866302490234
Validation loss: 2.1291916569073996

Epoch: 5| Step: 2
Training loss: 1.6665687561035156
Validation loss: 2.126871724923452

Epoch: 5| Step: 3
Training loss: 1.7940120697021484
Validation loss: 2.123872235417366

Epoch: 5| Step: 4
Training loss: 1.9246485233306885
Validation loss: 2.129151081045469

Epoch: 5| Step: 5
Training loss: 1.8748222589492798
Validation loss: 2.132565667231878

Epoch: 5| Step: 6
Training loss: 2.092905044555664
Validation loss: 2.138214568297068

Epoch: 5| Step: 7
Training loss: 2.24261474609375
Validation loss: 2.125761161247889

Epoch: 5| Step: 8
Training loss: 1.8074073791503906
Validation loss: 2.134347473581632

Epoch: 5| Step: 9
Training loss: 1.7981830835342407
Validation loss: 2.1273040274779

Epoch: 5| Step: 10
Training loss: 1.4317848682403564
Validation loss: 2.114582121372223

Epoch: 5| Step: 11
Training loss: 1.9918946027755737
Validation loss: 2.1189012080430984

Epoch: 225| Step: 0
Training loss: 1.811621904373169
Validation loss: 2.128655254840851

Epoch: 5| Step: 1
Training loss: 1.9588069915771484
Validation loss: 2.121702323357264

Epoch: 5| Step: 2
Training loss: 1.734114408493042
Validation loss: 2.113802174727122

Epoch: 5| Step: 3
Training loss: 1.7080755233764648
Validation loss: 2.1310000270605087

Epoch: 5| Step: 4
Training loss: 1.4918088912963867
Validation loss: 2.111243337392807

Epoch: 5| Step: 5
Training loss: 2.0695109367370605
Validation loss: 2.1247105797131858

Epoch: 5| Step: 6
Training loss: 2.1721279621124268
Validation loss: 2.133837029337883

Epoch: 5| Step: 7
Training loss: 1.8165355920791626
Validation loss: 2.126786823074023

Epoch: 5| Step: 8
Training loss: 2.0680928230285645
Validation loss: 2.1392290592193604

Epoch: 5| Step: 9
Training loss: 2.002547025680542
Validation loss: 2.1383253236611686

Epoch: 5| Step: 10
Training loss: 1.9680118560791016
Validation loss: 2.140756701429685

Epoch: 5| Step: 11
Training loss: 2.6054978370666504
Validation loss: 2.143162727355957

Epoch: 226| Step: 0
Training loss: 2.3294081687927246
Validation loss: 2.1435391356547675

Epoch: 5| Step: 1
Training loss: 1.7992534637451172
Validation loss: 2.1377508540948233

Epoch: 5| Step: 2
Training loss: 2.376028537750244
Validation loss: 2.1472261548042297

Epoch: 5| Step: 3
Training loss: 2.620515823364258
Validation loss: 2.1507402608791986

Epoch: 5| Step: 4
Training loss: 1.804413080215454
Validation loss: 2.150821437438329

Epoch: 5| Step: 5
Training loss: 1.3337095975875854
Validation loss: 2.1490996380647025

Epoch: 5| Step: 6
Training loss: 1.6605186462402344
Validation loss: 2.1533871591091156

Epoch: 5| Step: 7
Training loss: 2.2067370414733887
Validation loss: 2.1362827519575753

Epoch: 5| Step: 8
Training loss: 1.234362244606018
Validation loss: 2.137176513671875

Epoch: 5| Step: 9
Training loss: 2.2138640880584717
Validation loss: 2.1335015445947647

Epoch: 5| Step: 10
Training loss: 1.5391393899917603
Validation loss: 2.1428131808837256

Epoch: 5| Step: 11
Training loss: 3.0533993244171143
Validation loss: 2.1486933827400208

Epoch: 227| Step: 0
Training loss: 1.8850624561309814
Validation loss: 2.1607718219359717

Epoch: 5| Step: 1
Training loss: 1.9163672924041748
Validation loss: 2.133176604906718

Epoch: 5| Step: 2
Training loss: 1.961266279220581
Validation loss: 2.145021771391233

Epoch: 5| Step: 3
Training loss: 2.233612537384033
Validation loss: 2.1252704312404

Epoch: 5| Step: 4
Training loss: 2.092642307281494
Validation loss: 2.129675736029943

Epoch: 5| Step: 5
Training loss: 1.6665706634521484
Validation loss: 2.132363975048065

Epoch: 5| Step: 6
Training loss: 2.0132956504821777
Validation loss: 2.137972434361776

Epoch: 5| Step: 7
Training loss: 1.9414889812469482
Validation loss: 2.1405399094025293

Epoch: 5| Step: 8
Training loss: 1.356187105178833
Validation loss: 2.136920919020971

Epoch: 5| Step: 9
Training loss: 2.499816417694092
Validation loss: 2.135418489575386

Epoch: 5| Step: 10
Training loss: 1.9437370300292969
Validation loss: 2.1336446553468704

Epoch: 5| Step: 11
Training loss: 0.7930695414543152
Validation loss: 2.1423691560824714

Epoch: 228| Step: 0
Training loss: 2.170140027999878
Validation loss: 2.13456725080808

Epoch: 5| Step: 1
Training loss: 1.7292003631591797
Validation loss: 2.147255470355352

Epoch: 5| Step: 2
Training loss: 1.7308635711669922
Validation loss: 2.1492847204208374

Epoch: 5| Step: 3
Training loss: 2.031714916229248
Validation loss: 2.1504845718542733

Epoch: 5| Step: 4
Training loss: 1.819082260131836
Validation loss: 2.147938703497251

Epoch: 5| Step: 5
Training loss: 2.05663800239563
Validation loss: 2.148140102624893

Epoch: 5| Step: 6
Training loss: 1.8271583318710327
Validation loss: 2.140964686870575

Epoch: 5| Step: 7
Training loss: 1.7446644306182861
Validation loss: 2.1317885319391885

Epoch: 5| Step: 8
Training loss: 1.8331876993179321
Validation loss: 2.139602536956469

Epoch: 5| Step: 9
Training loss: 2.239778518676758
Validation loss: 2.141471187273661

Epoch: 5| Step: 10
Training loss: 1.7942034006118774
Validation loss: 2.152860184510549

Epoch: 5| Step: 11
Training loss: 2.72086238861084
Validation loss: 2.1507836331923804

Epoch: 229| Step: 0
Training loss: 1.5305231809616089
Validation loss: 2.1425447911024094

Epoch: 5| Step: 1
Training loss: 1.8097562789916992
Validation loss: 2.1367706606785455

Epoch: 5| Step: 2
Training loss: 2.305266857147217
Validation loss: 2.135976572831472

Epoch: 5| Step: 3
Training loss: 1.9071975946426392
Validation loss: 2.135302503903707

Epoch: 5| Step: 4
Training loss: 1.9513919353485107
Validation loss: 2.130017494161924

Epoch: 5| Step: 5
Training loss: 1.7344837188720703
Validation loss: 2.125302920738856

Epoch: 5| Step: 6
Training loss: 2.1494698524475098
Validation loss: 2.1170574426651

Epoch: 5| Step: 7
Training loss: 1.807657241821289
Validation loss: 2.1216893096764884

Epoch: 5| Step: 8
Training loss: 1.8692277669906616
Validation loss: 2.1307622492313385

Epoch: 5| Step: 9
Training loss: 2.187929153442383
Validation loss: 2.1351441045602164

Epoch: 5| Step: 10
Training loss: 1.50874924659729
Validation loss: 2.134023209412893

Epoch: 5| Step: 11
Training loss: 2.231884241104126
Validation loss: 2.125967080394427

Epoch: 230| Step: 0
Training loss: 1.9334548711776733
Validation loss: 2.126007849971453

Epoch: 5| Step: 1
Training loss: 1.6969749927520752
Validation loss: 2.1369770665963492

Epoch: 5| Step: 2
Training loss: 1.8653367757797241
Validation loss: 2.1363845417896905

Epoch: 5| Step: 3
Training loss: 2.0174012184143066
Validation loss: 2.1428832610448203

Epoch: 5| Step: 4
Training loss: 1.7814127206802368
Validation loss: 2.1292107552289963

Epoch: 5| Step: 5
Training loss: 2.2574806213378906
Validation loss: 2.1319033950567245

Epoch: 5| Step: 6
Training loss: 2.019491672515869
Validation loss: 2.126393457253774

Epoch: 5| Step: 7
Training loss: 1.8438060283660889
Validation loss: 2.129680593808492

Epoch: 5| Step: 8
Training loss: 1.2962520122528076
Validation loss: 2.139813706278801

Epoch: 5| Step: 9
Training loss: 2.1964149475097656
Validation loss: 2.138458584745725

Epoch: 5| Step: 10
Training loss: 2.0779857635498047
Validation loss: 2.134710838397344

Epoch: 5| Step: 11
Training loss: 1.6930949687957764
Validation loss: 2.137468089660009

Epoch: 231| Step: 0
Training loss: 1.8947179317474365
Validation loss: 2.1310029178857803

Epoch: 5| Step: 1
Training loss: 2.2604687213897705
Validation loss: 2.133716881275177

Epoch: 5| Step: 2
Training loss: 1.9078067541122437
Validation loss: 2.1237745781739554

Epoch: 5| Step: 3
Training loss: 2.5792348384857178
Validation loss: 2.1335779825846353

Epoch: 5| Step: 4
Training loss: 2.106602907180786
Validation loss: 2.134321336944898

Epoch: 5| Step: 5
Training loss: 1.4551713466644287
Validation loss: 2.1349421242872872

Epoch: 5| Step: 6
Training loss: 2.307056427001953
Validation loss: 2.148044983545939

Epoch: 5| Step: 7
Training loss: 2.1846604347229004
Validation loss: 2.140467092394829

Epoch: 5| Step: 8
Training loss: 1.7425148487091064
Validation loss: 2.136248136560122

Epoch: 5| Step: 9
Training loss: 1.653293251991272
Validation loss: 2.1337397942940393

Epoch: 5| Step: 10
Training loss: 1.733602523803711
Validation loss: 2.132254496216774

Epoch: 5| Step: 11
Training loss: 1.187562108039856
Validation loss: 2.1274449825286865

Epoch: 232| Step: 0
Training loss: 1.9913486242294312
Validation loss: 2.1252793769041696

Epoch: 5| Step: 1
Training loss: 1.9539635181427002
Validation loss: 2.1338670353094735

Epoch: 5| Step: 2
Training loss: 1.6995484828948975
Validation loss: 2.136572246750196

Epoch: 5| Step: 3
Training loss: 1.6259286403656006
Validation loss: 2.1298293421665826

Epoch: 5| Step: 4
Training loss: 2.289783477783203
Validation loss: 2.1337265968322754

Epoch: 5| Step: 5
Training loss: 1.9569590091705322
Validation loss: 2.1272093653678894

Epoch: 5| Step: 6
Training loss: 1.8717178106307983
Validation loss: 2.134008134404818

Epoch: 5| Step: 7
Training loss: 2.299011707305908
Validation loss: 2.1303045650323233

Epoch: 5| Step: 8
Training loss: 1.980259656906128
Validation loss: 2.1407068024079003

Epoch: 5| Step: 9
Training loss: 1.8794219493865967
Validation loss: 2.143068070213

Epoch: 5| Step: 10
Training loss: 1.7402740716934204
Validation loss: 2.135896181066831

Epoch: 5| Step: 11
Training loss: 2.997178077697754
Validation loss: 2.1281962196032205

Epoch: 233| Step: 0
Training loss: 1.9251426458358765
Validation loss: 2.1213738520940146

Epoch: 5| Step: 1
Training loss: 1.9761993885040283
Validation loss: 2.107558488845825

Epoch: 5| Step: 2
Training loss: 2.2794480323791504
Validation loss: 2.114540492494901

Epoch: 5| Step: 3
Training loss: 2.0539867877960205
Validation loss: 2.118900716304779

Epoch: 5| Step: 4
Training loss: 1.769648790359497
Validation loss: 2.1220173885424933

Epoch: 5| Step: 5
Training loss: 1.6045955419540405
Validation loss: 2.1303726583719254

Epoch: 5| Step: 6
Training loss: 1.3556511402130127
Validation loss: 2.133826126654943

Epoch: 5| Step: 7
Training loss: 1.7346551418304443
Validation loss: 2.1357892702023187

Epoch: 5| Step: 8
Training loss: 2.21826434135437
Validation loss: 2.140326683719953

Epoch: 5| Step: 9
Training loss: 1.874169111251831
Validation loss: 2.137878884871801

Epoch: 5| Step: 10
Training loss: 2.0315351486206055
Validation loss: 2.131852572162946

Epoch: 5| Step: 11
Training loss: 2.0562379360198975
Validation loss: 2.1211752196153006

Epoch: 234| Step: 0
Training loss: 1.722917914390564
Validation loss: 2.127685730655988

Epoch: 5| Step: 1
Training loss: 1.921655297279358
Validation loss: 2.116809775431951

Epoch: 5| Step: 2
Training loss: 2.653752565383911
Validation loss: 2.1284255931774774

Epoch: 5| Step: 3
Training loss: 1.3938493728637695
Validation loss: 2.124710793296496

Epoch: 5| Step: 4
Training loss: 1.651676893234253
Validation loss: 2.1379849116007485

Epoch: 5| Step: 5
Training loss: 2.398019790649414
Validation loss: 2.1418029814958572

Epoch: 5| Step: 6
Training loss: 2.0988075733184814
Validation loss: 2.129457334677378

Epoch: 5| Step: 7
Training loss: 1.3854726552963257
Validation loss: 2.1253986606995263

Epoch: 5| Step: 8
Training loss: 1.5701261758804321
Validation loss: 2.134330521027247

Epoch: 5| Step: 9
Training loss: 2.1791298389434814
Validation loss: 2.137372230490049

Epoch: 5| Step: 10
Training loss: 1.9717302322387695
Validation loss: 2.1229375203450522

Epoch: 5| Step: 11
Training loss: 2.0693490505218506
Validation loss: 2.131012280782064

Epoch: 235| Step: 0
Training loss: 1.698894739151001
Validation loss: 2.12430531779925

Epoch: 5| Step: 1
Training loss: 1.9210888147354126
Validation loss: 2.123732348283132

Epoch: 5| Step: 2
Training loss: 1.7924087047576904
Validation loss: 2.1417077829440436

Epoch: 5| Step: 3
Training loss: 2.43318510055542
Validation loss: 2.1377291679382324

Epoch: 5| Step: 4
Training loss: 1.8835008144378662
Validation loss: 2.139586642384529

Epoch: 5| Step: 5
Training loss: 1.9332053661346436
Validation loss: 2.137898320953051

Epoch: 5| Step: 6
Training loss: 1.9143356084823608
Validation loss: 2.1266834288835526

Epoch: 5| Step: 7
Training loss: 1.9822099208831787
Validation loss: 2.1312263111273446

Epoch: 5| Step: 8
Training loss: 1.5945796966552734
Validation loss: 2.1350306073824563

Epoch: 5| Step: 9
Training loss: 2.1404106616973877
Validation loss: 2.128269523382187

Epoch: 5| Step: 10
Training loss: 1.4372467994689941
Validation loss: 2.1296978195508323

Epoch: 5| Step: 11
Training loss: 2.7851648330688477
Validation loss: 2.125004306435585

Epoch: 236| Step: 0
Training loss: 2.452626943588257
Validation loss: 2.1268482555945716

Epoch: 5| Step: 1
Training loss: 1.5441116094589233
Validation loss: 2.122052604953448

Epoch: 5| Step: 2
Training loss: 1.2496674060821533
Validation loss: 2.126736889282862

Epoch: 5| Step: 3
Training loss: 1.238229513168335
Validation loss: 2.1284397145112357

Epoch: 5| Step: 4
Training loss: 1.639436960220337
Validation loss: 2.1355078518390656

Epoch: 5| Step: 5
Training loss: 1.4055416584014893
Validation loss: 2.130226582288742

Epoch: 5| Step: 6
Training loss: 2.0020017623901367
Validation loss: 2.1344365080197654

Epoch: 5| Step: 7
Training loss: 2.486945629119873
Validation loss: 2.130573257803917

Epoch: 5| Step: 8
Training loss: 1.91732656955719
Validation loss: 2.122976546486219

Epoch: 5| Step: 9
Training loss: 2.837949752807617
Validation loss: 2.1395281155904136

Epoch: 5| Step: 10
Training loss: 2.0466904640197754
Validation loss: 2.1292774975299835

Epoch: 5| Step: 11
Training loss: 2.4891231060028076
Validation loss: 2.1422141740719476

Epoch: 237| Step: 0
Training loss: 2.108524799346924
Validation loss: 2.1463029185930886

Epoch: 5| Step: 1
Training loss: 1.7909421920776367
Validation loss: 2.138814464211464

Epoch: 5| Step: 2
Training loss: 1.3573126792907715
Validation loss: 2.1502034217119217

Epoch: 5| Step: 3
Training loss: 2.4331119060516357
Validation loss: 2.136540154616038

Epoch: 5| Step: 4
Training loss: 2.3468363285064697
Validation loss: 2.145793085296949

Epoch: 5| Step: 5
Training loss: 1.6676626205444336
Validation loss: 2.1369904279708862

Epoch: 5| Step: 6
Training loss: 2.1833221912384033
Validation loss: 2.141730467478434

Epoch: 5| Step: 7
Training loss: 1.8164799213409424
Validation loss: 2.129114573200544

Epoch: 5| Step: 8
Training loss: 1.3436813354492188
Validation loss: 2.12735253572464

Epoch: 5| Step: 9
Training loss: 2.081970691680908
Validation loss: 2.1145119220018387

Epoch: 5| Step: 10
Training loss: 2.1437900066375732
Validation loss: 2.1200669606526694

Epoch: 5| Step: 11
Training loss: 0.9513221383094788
Validation loss: 2.1188158293565116

Epoch: 238| Step: 0
Training loss: 1.7913315296173096
Validation loss: 2.12562258541584

Epoch: 5| Step: 1
Training loss: 1.723189353942871
Validation loss: 2.1212747544050217

Epoch: 5| Step: 2
Training loss: 1.4612672328948975
Validation loss: 2.142531305551529

Epoch: 5| Step: 3
Training loss: 2.2496707439422607
Validation loss: 2.138836309313774

Epoch: 5| Step: 4
Training loss: 2.5074462890625
Validation loss: 2.1453246076901755

Epoch: 5| Step: 5
Training loss: 1.5483310222625732
Validation loss: 2.132409855723381

Epoch: 5| Step: 6
Training loss: 2.1089000701904297
Validation loss: 2.133975366751353

Epoch: 5| Step: 7
Training loss: 1.8609247207641602
Validation loss: 2.131647298733393

Epoch: 5| Step: 8
Training loss: 1.7137054204940796
Validation loss: 2.1328402956326804

Epoch: 5| Step: 9
Training loss: 1.691595435142517
Validation loss: 2.147264371315638

Epoch: 5| Step: 10
Training loss: 1.9536590576171875
Validation loss: 2.136470541357994

Epoch: 5| Step: 11
Training loss: 2.556169271469116
Validation loss: 2.1414738446474075

Epoch: 239| Step: 0
Training loss: 2.10772705078125
Validation loss: 2.1509744127591452

Epoch: 5| Step: 1
Training loss: 2.1745445728302
Validation loss: 2.1507689903179803

Epoch: 5| Step: 2
Training loss: 1.8722432851791382
Validation loss: 2.1421277622381845

Epoch: 5| Step: 3
Training loss: 1.3908414840698242
Validation loss: 2.1489899257818856

Epoch: 5| Step: 4
Training loss: 1.6411155462265015
Validation loss: 2.1464718729257584

Epoch: 5| Step: 5
Training loss: 2.11312198638916
Validation loss: 2.146016468604406

Epoch: 5| Step: 6
Training loss: 1.9908673763275146
Validation loss: 2.1521179924408593

Epoch: 5| Step: 7
Training loss: 1.844077706336975
Validation loss: 2.1479602803786597

Epoch: 5| Step: 8
Training loss: 2.475494861602783
Validation loss: 2.1616890927155814

Epoch: 5| Step: 9
Training loss: 1.1335896253585815
Validation loss: 2.1545817653338113

Epoch: 5| Step: 10
Training loss: 1.9277830123901367
Validation loss: 2.1510490675767264

Epoch: 5| Step: 11
Training loss: 2.6807148456573486
Validation loss: 2.1514298965533576

Epoch: 240| Step: 0
Training loss: 2.1496357917785645
Validation loss: 2.16251170138518

Epoch: 5| Step: 1
Training loss: 1.7952535152435303
Validation loss: 2.145388220747312

Epoch: 5| Step: 2
Training loss: 2.1293630599975586
Validation loss: 2.1564224511384964

Epoch: 5| Step: 3
Training loss: 1.6604827642440796
Validation loss: 2.151031712690989

Epoch: 5| Step: 4
Training loss: 1.99312424659729
Validation loss: 2.152687281370163

Epoch: 5| Step: 5
Training loss: 2.2444519996643066
Validation loss: 2.1469396899143853

Epoch: 5| Step: 6
Training loss: 2.0509016513824463
Validation loss: 2.1504287471373877

Epoch: 5| Step: 7
Training loss: 1.9258321523666382
Validation loss: 2.157140329480171

Epoch: 5| Step: 8
Training loss: 1.638593316078186
Validation loss: 2.147578169902166

Epoch: 5| Step: 9
Training loss: 1.7444474697113037
Validation loss: 2.1396970748901367

Epoch: 5| Step: 10
Training loss: 1.6359649896621704
Validation loss: 2.1367014100154242

Epoch: 5| Step: 11
Training loss: 1.8230711221694946
Validation loss: 2.1421582400798798

Epoch: 241| Step: 0
Training loss: 1.7804133892059326
Validation loss: 2.1421290735403695

Epoch: 5| Step: 1
Training loss: 1.6991838216781616
Validation loss: 2.13592558602492

Epoch: 5| Step: 2
Training loss: 2.3909850120544434
Validation loss: 2.154112001260122

Epoch: 5| Step: 3
Training loss: 2.094766616821289
Validation loss: 2.149790639678637

Epoch: 5| Step: 4
Training loss: 1.5555440187454224
Validation loss: 2.141036421060562

Epoch: 5| Step: 5
Training loss: 2.072295665740967
Validation loss: 2.130212297042211

Epoch: 5| Step: 6
Training loss: 1.811841607093811
Validation loss: 2.1486533184846244

Epoch: 5| Step: 7
Training loss: 1.9828153848648071
Validation loss: 2.1386170983314514

Epoch: 5| Step: 8
Training loss: 2.118666410446167
Validation loss: 2.13931567966938

Epoch: 5| Step: 9
Training loss: 1.862622618675232
Validation loss: 2.1388813058535256

Epoch: 5| Step: 10
Training loss: 1.5096768140792847
Validation loss: 2.1387077818314233

Epoch: 5| Step: 11
Training loss: 1.1010080575942993
Validation loss: 2.127844288945198

Epoch: 242| Step: 0
Training loss: 1.8876619338989258
Validation loss: 2.1433074921369553

Epoch: 5| Step: 1
Training loss: 2.1735923290252686
Validation loss: 2.14374532798926

Epoch: 5| Step: 2
Training loss: 1.8488155603408813
Validation loss: 2.1492489178975425

Epoch: 5| Step: 3
Training loss: 1.8091716766357422
Validation loss: 2.1622277945280075

Epoch: 5| Step: 4
Training loss: 2.1860249042510986
Validation loss: 2.150794431567192

Epoch: 5| Step: 5
Training loss: 1.2982431650161743
Validation loss: 2.158378819624583

Epoch: 5| Step: 6
Training loss: 1.6340011358261108
Validation loss: 2.1577552556991577

Epoch: 5| Step: 7
Training loss: 1.2489255666732788
Validation loss: 2.1554839511712394

Epoch: 5| Step: 8
Training loss: 2.325396776199341
Validation loss: 2.1650302608807883

Epoch: 5| Step: 9
Training loss: 1.976284384727478
Validation loss: 2.150055150190989

Epoch: 5| Step: 10
Training loss: 2.2650256156921387
Validation loss: 2.1460555096467337

Epoch: 5| Step: 11
Training loss: 2.0439116954803467
Validation loss: 2.139411896467209

Epoch: 243| Step: 0
Training loss: 2.064530372619629
Validation loss: 2.146940136949221

Epoch: 5| Step: 1
Training loss: 1.9412918090820312
Validation loss: 2.136203279097875

Epoch: 5| Step: 2
Training loss: 1.8227628469467163
Validation loss: 2.1380182107289634

Epoch: 5| Step: 3
Training loss: 1.6381851434707642
Validation loss: 2.1419095347325006

Epoch: 5| Step: 4
Training loss: 1.0883915424346924
Validation loss: 2.1531961311896644

Epoch: 5| Step: 5
Training loss: 2.184802532196045
Validation loss: 2.159181222319603

Epoch: 5| Step: 6
Training loss: 2.072385787963867
Validation loss: 2.1543113539616265

Epoch: 5| Step: 7
Training loss: 2.353797197341919
Validation loss: 2.1656121710936227

Epoch: 5| Step: 8
Training loss: 2.1157798767089844
Validation loss: 2.157132094105085

Epoch: 5| Step: 9
Training loss: 1.7350540161132812
Validation loss: 2.144483759999275

Epoch: 5| Step: 10
Training loss: 1.8249213695526123
Validation loss: 2.1492841839790344

Epoch: 5| Step: 11
Training loss: 2.0791258811950684
Validation loss: 2.166449914375941

Epoch: 244| Step: 0
Training loss: 1.7750484943389893
Validation loss: 2.1563103099664054

Epoch: 5| Step: 1
Training loss: 2.4120469093322754
Validation loss: 2.1593606770038605

Epoch: 5| Step: 2
Training loss: 1.4573445320129395
Validation loss: 2.1530939638614655

Epoch: 5| Step: 3
Training loss: 2.1511635780334473
Validation loss: 2.1496018717686334

Epoch: 5| Step: 4
Training loss: 2.281167507171631
Validation loss: 2.165143226583799

Epoch: 5| Step: 5
Training loss: 1.2887036800384521
Validation loss: 2.1620849867661796

Epoch: 5| Step: 6
Training loss: 2.128728151321411
Validation loss: 2.1770072082678475

Epoch: 5| Step: 7
Training loss: 2.1336705684661865
Validation loss: 2.157071535785993

Epoch: 5| Step: 8
Training loss: 1.5418132543563843
Validation loss: 2.160366718967756

Epoch: 5| Step: 9
Training loss: 2.476468324661255
Validation loss: 2.1731997231642404

Epoch: 5| Step: 10
Training loss: 1.563315987586975
Validation loss: 2.160712853074074

Epoch: 5| Step: 11
Training loss: 0.7418649792671204
Validation loss: 2.158088212211927

Epoch: 245| Step: 0
Training loss: 1.8918273448944092
Validation loss: 2.1542093058427176

Epoch: 5| Step: 1
Training loss: 1.5658538341522217
Validation loss: 2.1674752632776895

Epoch: 5| Step: 2
Training loss: 1.5082156658172607
Validation loss: 2.152953952550888

Epoch: 5| Step: 3
Training loss: 1.2499608993530273
Validation loss: 2.1393001675605774

Epoch: 5| Step: 4
Training loss: 2.2412478923797607
Validation loss: 2.150283545255661

Epoch: 5| Step: 5
Training loss: 1.905649185180664
Validation loss: 2.146478548645973

Epoch: 5| Step: 6
Training loss: 1.929731011390686
Validation loss: 2.1404843678077063

Epoch: 5| Step: 7
Training loss: 2.1562581062316895
Validation loss: 2.1514574040969214

Epoch: 5| Step: 8
Training loss: 1.5348632335662842
Validation loss: 2.1476394534111023

Epoch: 5| Step: 9
Training loss: 1.7483189105987549
Validation loss: 2.149913946787516

Epoch: 5| Step: 10
Training loss: 3.0530145168304443
Validation loss: 2.149472470084826

Epoch: 5| Step: 11
Training loss: 1.4146373271942139
Validation loss: 2.140589783589045

Epoch: 246| Step: 0
Training loss: 2.1485755443573
Validation loss: 2.1416273514429727

Epoch: 5| Step: 1
Training loss: 1.8454539775848389
Validation loss: 2.1432883391777673

Epoch: 5| Step: 2
Training loss: 1.1250393390655518
Validation loss: 2.1437995433807373

Epoch: 5| Step: 3
Training loss: 2.0969343185424805
Validation loss: 2.1443739583094916

Epoch: 5| Step: 4
Training loss: 2.4044768810272217
Validation loss: 2.1450886825720468

Epoch: 5| Step: 5
Training loss: 2.320587158203125
Validation loss: 2.144792119661967

Epoch: 5| Step: 6
Training loss: 1.6551851034164429
Validation loss: 2.149110645055771

Epoch: 5| Step: 7
Training loss: 1.7261295318603516
Validation loss: 2.1520717392365136

Epoch: 5| Step: 8
Training loss: 1.5388870239257812
Validation loss: 2.1565374235312142

Epoch: 5| Step: 9
Training loss: 2.508881092071533
Validation loss: 2.1555040578047433

Epoch: 5| Step: 10
Training loss: 1.481133222579956
Validation loss: 2.1535039842128754

Epoch: 5| Step: 11
Training loss: 1.0978959798812866
Validation loss: 2.1526308755079904

Epoch: 247| Step: 0
Training loss: 1.8785394430160522
Validation loss: 2.1496633837620416

Epoch: 5| Step: 1
Training loss: 2.285991668701172
Validation loss: 2.1583995868762336

Epoch: 5| Step: 2
Training loss: 1.8561325073242188
Validation loss: 2.151614636182785

Epoch: 5| Step: 3
Training loss: 1.6311973333358765
Validation loss: 2.149625157316526

Epoch: 5| Step: 4
Training loss: 2.1037824153900146
Validation loss: 2.1611768901348114

Epoch: 5| Step: 5
Training loss: 1.7221031188964844
Validation loss: 2.168643295764923

Epoch: 5| Step: 6
Training loss: 1.479442834854126
Validation loss: 2.160148501396179

Epoch: 5| Step: 7
Training loss: 1.6897847652435303
Validation loss: 2.159534846742948

Epoch: 5| Step: 8
Training loss: 1.586449384689331
Validation loss: 2.1795371621847153

Epoch: 5| Step: 9
Training loss: 1.7473045587539673
Validation loss: 2.165607288479805

Epoch: 5| Step: 10
Training loss: 2.64523983001709
Validation loss: 2.173585737744967

Epoch: 5| Step: 11
Training loss: 1.541277527809143
Validation loss: 2.1521863639354706

Epoch: 248| Step: 0
Training loss: 1.746076226234436
Validation loss: 2.1586256126562753

Epoch: 5| Step: 1
Training loss: 2.2815499305725098
Validation loss: 2.168742462992668

Epoch: 5| Step: 2
Training loss: 1.6336339712142944
Validation loss: 2.162773678700129

Epoch: 5| Step: 3
Training loss: 1.7060158252716064
Validation loss: 2.170720765988032

Epoch: 5| Step: 4
Training loss: 2.1222755908966064
Validation loss: 2.164052332441012

Epoch: 5| Step: 5
Training loss: 1.8347914218902588
Validation loss: 2.165036658445994

Epoch: 5| Step: 6
Training loss: 1.6530392169952393
Validation loss: 2.160997658967972

Epoch: 5| Step: 7
Training loss: 1.6546080112457275
Validation loss: 2.172137593229612

Epoch: 5| Step: 8
Training loss: 1.6459506750106812
Validation loss: 2.1522868424654007

Epoch: 5| Step: 9
Training loss: 2.1556620597839355
Validation loss: 2.1665499210357666

Epoch: 5| Step: 10
Training loss: 2.120049476623535
Validation loss: 2.1626517325639725

Epoch: 5| Step: 11
Training loss: 2.1565537452697754
Validation loss: 2.1761812766393027

Epoch: 249| Step: 0
Training loss: 1.5315377712249756
Validation loss: 2.1584623803695044

Epoch: 5| Step: 1
Training loss: 1.8764238357543945
Validation loss: 2.1670382966597876

Epoch: 5| Step: 2
Training loss: 2.035205364227295
Validation loss: 2.15477026005586

Epoch: 5| Step: 3
Training loss: 1.5689846277236938
Validation loss: 2.176714008053144

Epoch: 5| Step: 4
Training loss: 2.305345296859741
Validation loss: 2.1720082461833954

Epoch: 5| Step: 5
Training loss: 2.523548126220703
Validation loss: 2.1812155147393546

Epoch: 5| Step: 6
Training loss: 1.3687314987182617
Validation loss: 2.1738287806510925

Epoch: 5| Step: 7
Training loss: 2.314948320388794
Validation loss: 2.171994224190712

Epoch: 5| Step: 8
Training loss: 1.7555391788482666
Validation loss: 2.1775100330511727

Epoch: 5| Step: 9
Training loss: 2.191183090209961
Validation loss: 2.167815461754799

Epoch: 5| Step: 10
Training loss: 1.6672000885009766
Validation loss: 2.1644337524970374

Epoch: 5| Step: 11
Training loss: 0.7920935153961182
Validation loss: 2.1761922935644784

Epoch: 250| Step: 0
Training loss: 1.5566028356552124
Validation loss: 2.1870462397734323

Epoch: 5| Step: 1
Training loss: 1.6304872035980225
Validation loss: 2.178775077064832

Epoch: 5| Step: 2
Training loss: 2.2162375450134277
Validation loss: 2.1743885626395545

Epoch: 5| Step: 3
Training loss: 2.4677817821502686
Validation loss: 2.170257290204366

Epoch: 5| Step: 4
Training loss: 1.7916473150253296
Validation loss: 2.166985164086024

Epoch: 5| Step: 5
Training loss: 1.9319517612457275
Validation loss: 2.1596751312414804

Epoch: 5| Step: 6
Training loss: 1.8220138549804688
Validation loss: 2.160129725933075

Epoch: 5| Step: 7
Training loss: 1.9379926919937134
Validation loss: 2.175148914257685

Epoch: 5| Step: 8
Training loss: 1.9090635776519775
Validation loss: 2.1753946393728256

Epoch: 5| Step: 9
Training loss: 2.021479845046997
Validation loss: 2.175541420777639

Epoch: 5| Step: 10
Training loss: 1.629089593887329
Validation loss: 2.174014096458753

Epoch: 5| Step: 11
Training loss: 1.0162906646728516
Validation loss: 2.170967862010002

Epoch: 251| Step: 0
Training loss: 1.9764728546142578
Validation loss: 2.1908966402212777

Epoch: 5| Step: 1
Training loss: 2.03903865814209
Validation loss: 2.1775614668925605

Epoch: 5| Step: 2
Training loss: 1.7249218225479126
Validation loss: 2.1916752258936563

Epoch: 5| Step: 3
Training loss: 1.7972536087036133
Validation loss: 2.1965510894854865

Epoch: 5| Step: 4
Training loss: 1.3865418434143066
Validation loss: 2.1848500619331994

Epoch: 5| Step: 5
Training loss: 2.2522196769714355
Validation loss: 2.205461005369822

Epoch: 5| Step: 6
Training loss: 1.5514185428619385
Validation loss: 2.20337642232577

Epoch: 5| Step: 7
Training loss: 1.749405860900879
Validation loss: 2.191308711965879

Epoch: 5| Step: 8
Training loss: 1.839315414428711
Validation loss: 2.1828328371047974

Epoch: 5| Step: 9
Training loss: 2.340442657470703
Validation loss: 2.1879122952620187

Epoch: 5| Step: 10
Training loss: 1.4579963684082031
Validation loss: 2.1872900277376175

Epoch: 5| Step: 11
Training loss: 3.6052865982055664
Validation loss: 2.188533052802086

Epoch: 252| Step: 0
Training loss: 2.3027825355529785
Validation loss: 2.178574745853742

Epoch: 5| Step: 1
Training loss: 1.9401404857635498
Validation loss: 2.174716532230377

Epoch: 5| Step: 2
Training loss: 2.076465606689453
Validation loss: 2.1837268024683

Epoch: 5| Step: 3
Training loss: 1.7632354497909546
Validation loss: 2.1747121115525565

Epoch: 5| Step: 4
Training loss: 1.7437686920166016
Validation loss: 2.1809668242931366

Epoch: 5| Step: 5
Training loss: 1.2929127216339111
Validation loss: 2.1922342677911124

Epoch: 5| Step: 6
Training loss: 1.8272924423217773
Validation loss: 2.176995644966761

Epoch: 5| Step: 7
Training loss: 1.6666303873062134
Validation loss: 2.178992360830307

Epoch: 5| Step: 8
Training loss: 2.0199992656707764
Validation loss: 2.1770322024822235

Epoch: 5| Step: 9
Training loss: 1.7624719142913818
Validation loss: 2.174684335788091

Epoch: 5| Step: 10
Training loss: 1.9077552556991577
Validation loss: 2.1781869331995645

Epoch: 5| Step: 11
Training loss: 1.6913217306137085
Validation loss: 2.1761630872885385

Epoch: 253| Step: 0
Training loss: 1.7468236684799194
Validation loss: 2.176933373014132

Epoch: 5| Step: 1
Training loss: 1.6121248006820679
Validation loss: 2.1811551054318747

Epoch: 5| Step: 2
Training loss: 1.740557074546814
Validation loss: 2.164717917641004

Epoch: 5| Step: 3
Training loss: 1.7480636835098267
Validation loss: 2.174402048190435

Epoch: 5| Step: 4
Training loss: 1.7683734893798828
Validation loss: 2.1662425647179284

Epoch: 5| Step: 5
Training loss: 1.7272990942001343
Validation loss: 2.168464869260788

Epoch: 5| Step: 6
Training loss: 2.1578919887542725
Validation loss: 2.176505446434021

Epoch: 5| Step: 7
Training loss: 2.0462703704833984
Validation loss: 2.179870833953222

Epoch: 5| Step: 8
Training loss: 1.7186558246612549
Validation loss: 2.179833630720774

Epoch: 5| Step: 9
Training loss: 1.9399820566177368
Validation loss: 2.1725449909766517

Epoch: 5| Step: 10
Training loss: 2.431182861328125
Validation loss: 2.186884492635727

Epoch: 5| Step: 11
Training loss: 1.0029715299606323
Validation loss: 2.1702441970507302

Epoch: 254| Step: 0
Training loss: 1.5300912857055664
Validation loss: 2.1766472508509955

Epoch: 5| Step: 1
Training loss: 2.071424722671509
Validation loss: 2.1696342726548514

Epoch: 5| Step: 2
Training loss: 1.3718574047088623
Validation loss: 2.1654212176799774

Epoch: 5| Step: 3
Training loss: 2.2952191829681396
Validation loss: 2.170478711525599

Epoch: 5| Step: 4
Training loss: 1.8972676992416382
Validation loss: 2.175068750977516

Epoch: 5| Step: 5
Training loss: 1.639678955078125
Validation loss: 2.166707163055738

Epoch: 5| Step: 6
Training loss: 1.9917716979980469
Validation loss: 2.161519860227903

Epoch: 5| Step: 7
Training loss: 1.8876291513442993
Validation loss: 2.1739579488833747

Epoch: 5| Step: 8
Training loss: 2.061371326446533
Validation loss: 2.1785667687654495

Epoch: 5| Step: 9
Training loss: 1.5350475311279297
Validation loss: 2.1912341763575873

Epoch: 5| Step: 10
Training loss: 2.105916738510132
Validation loss: 2.1770988752444587

Epoch: 5| Step: 11
Training loss: 1.6653190851211548
Validation loss: 2.181831290324529

Epoch: 255| Step: 0
Training loss: 1.8655586242675781
Validation loss: 2.190698876976967

Epoch: 5| Step: 1
Training loss: 2.0543854236602783
Validation loss: 2.1666426757971444

Epoch: 5| Step: 2
Training loss: 1.8583288192749023
Validation loss: 2.18944750726223

Epoch: 5| Step: 3
Training loss: 1.2483241558074951
Validation loss: 2.1720266143480935

Epoch: 5| Step: 4
Training loss: 1.3436578512191772
Validation loss: 2.1867290983597436

Epoch: 5| Step: 5
Training loss: 2.2126739025115967
Validation loss: 2.188852330048879

Epoch: 5| Step: 6
Training loss: 1.7440097332000732
Validation loss: 2.188594321409861

Epoch: 5| Step: 7
Training loss: 2.0987331867218018
Validation loss: 2.1822331249713898

Epoch: 5| Step: 8
Training loss: 2.011397123336792
Validation loss: 2.1891473084688187

Epoch: 5| Step: 9
Training loss: 2.237513780593872
Validation loss: 2.193401739001274

Epoch: 5| Step: 10
Training loss: 1.8355274200439453
Validation loss: 2.1844362020492554

Epoch: 5| Step: 11
Training loss: 1.2538715600967407
Validation loss: 2.1876636842886605

Epoch: 256| Step: 0
Training loss: 2.2541348934173584
Validation loss: 2.1881261070569358

Epoch: 5| Step: 1
Training loss: 1.6445577144622803
Validation loss: 2.1821072498957315

Epoch: 5| Step: 2
Training loss: 1.6372798681259155
Validation loss: 2.1783857295910516

Epoch: 5| Step: 3
Training loss: 1.8778798580169678
Validation loss: 2.1873506158590317

Epoch: 5| Step: 4
Training loss: 1.838975191116333
Validation loss: 2.1662407964468002

Epoch: 5| Step: 5
Training loss: 1.3426744937896729
Validation loss: 2.1717564264933267

Epoch: 5| Step: 6
Training loss: 2.4736549854278564
Validation loss: 2.1762145111958184

Epoch: 5| Step: 7
Training loss: 1.8259522914886475
Validation loss: 2.1770217518011727

Epoch: 5| Step: 8
Training loss: 1.964193344116211
Validation loss: 2.1893246521552405

Epoch: 5| Step: 9
Training loss: 1.7024800777435303
Validation loss: 2.179340814550718

Epoch: 5| Step: 10
Training loss: 1.6471904516220093
Validation loss: 2.180171956618627

Epoch: 5| Step: 11
Training loss: 1.9393306970596313
Validation loss: 2.1979412933190665

Epoch: 257| Step: 0
Training loss: 1.8458690643310547
Validation loss: 2.1817068258921304

Epoch: 5| Step: 1
Training loss: 1.640531301498413
Validation loss: 2.1848224053780236

Epoch: 5| Step: 2
Training loss: 2.2599258422851562
Validation loss: 2.1830529471238456

Epoch: 5| Step: 3
Training loss: 1.507351040840149
Validation loss: 2.1789304614067078

Epoch: 5| Step: 4
Training loss: 2.217374086380005
Validation loss: 2.1943152099847794

Epoch: 5| Step: 5
Training loss: 2.2174465656280518
Validation loss: 2.189815570910772

Epoch: 5| Step: 6
Training loss: 2.10102915763855
Validation loss: 2.1837085584799447

Epoch: 5| Step: 7
Training loss: 1.6663751602172852
Validation loss: 2.18841818968455

Epoch: 5| Step: 8
Training loss: 1.6007906198501587
Validation loss: 2.1838894188404083

Epoch: 5| Step: 9
Training loss: 1.390960931777954
Validation loss: 2.188039019703865

Epoch: 5| Step: 10
Training loss: 1.8166875839233398
Validation loss: 2.1843188206354776

Epoch: 5| Step: 11
Training loss: 1.8947029113769531
Validation loss: 2.1901635825634003

Epoch: 258| Step: 0
Training loss: 1.2244415283203125
Validation loss: 2.1837236682573953

Epoch: 5| Step: 1
Training loss: 1.8468258380889893
Validation loss: 2.1777213414510093

Epoch: 5| Step: 2
Training loss: 2.049309253692627
Validation loss: 2.1798006842533746

Epoch: 5| Step: 3
Training loss: 1.5763177871704102
Validation loss: 2.175875723361969

Epoch: 5| Step: 4
Training loss: 3.046905517578125
Validation loss: 2.178235352039337

Epoch: 5| Step: 5
Training loss: 1.9236217737197876
Validation loss: 2.1663650075594583

Epoch: 5| Step: 6
Training loss: 0.941598117351532
Validation loss: 2.180513550837835

Epoch: 5| Step: 7
Training loss: 1.5272960662841797
Validation loss: 2.176908493041992

Epoch: 5| Step: 8
Training loss: 1.8472121953964233
Validation loss: 2.167737921079

Epoch: 5| Step: 9
Training loss: 1.5394799709320068
Validation loss: 2.173277050256729

Epoch: 5| Step: 10
Training loss: 2.3064897060394287
Validation loss: 2.1865765750408173

Epoch: 5| Step: 11
Training loss: 2.5193188190460205
Validation loss: 2.1878946820894876

Epoch: 259| Step: 0
Training loss: 1.551645040512085
Validation loss: 2.184303974111875

Epoch: 5| Step: 1
Training loss: 1.9168472290039062
Validation loss: 2.1813286741574607

Epoch: 5| Step: 2
Training loss: 1.4405649900436401
Validation loss: 2.186262011528015

Epoch: 5| Step: 3
Training loss: 2.039384126663208
Validation loss: 2.181712806224823

Epoch: 5| Step: 4
Training loss: 2.4694361686706543
Validation loss: 2.1798016180594764

Epoch: 5| Step: 5
Training loss: 1.6637678146362305
Validation loss: 2.190025418996811

Epoch: 5| Step: 6
Training loss: 2.192448616027832
Validation loss: 2.1645094702641168

Epoch: 5| Step: 7
Training loss: 2.0224218368530273
Validation loss: 2.1745362927516303

Epoch: 5| Step: 8
Training loss: 1.4509799480438232
Validation loss: 2.189790725708008

Epoch: 5| Step: 9
Training loss: 1.4972206354141235
Validation loss: 2.17518679300944

Epoch: 5| Step: 10
Training loss: 1.9210306406021118
Validation loss: 2.1700085252523422

Epoch: 5| Step: 11
Training loss: 1.6021437644958496
Validation loss: 2.1858969579140344

Epoch: 260| Step: 0
Training loss: 1.7123616933822632
Validation loss: 2.1763335317373276

Epoch: 5| Step: 1
Training loss: 1.7589607238769531
Validation loss: 2.1640287240346274

Epoch: 5| Step: 2
Training loss: 1.482895016670227
Validation loss: 2.1708389619986215

Epoch: 5| Step: 3
Training loss: 2.067811965942383
Validation loss: 2.1622720509767532

Epoch: 5| Step: 4
Training loss: 2.1380341053009033
Validation loss: 2.172269413868586

Epoch: 5| Step: 5
Training loss: 2.027834415435791
Validation loss: 2.1645514468352

Epoch: 5| Step: 6
Training loss: 2.1514761447906494
Validation loss: 2.175051689147949

Epoch: 5| Step: 7
Training loss: 2.175787925720215
Validation loss: 2.1638937493165336

Epoch: 5| Step: 8
Training loss: 1.1060600280761719
Validation loss: 2.175736332933108

Epoch: 5| Step: 9
Training loss: 1.8595199584960938
Validation loss: 2.172575498620669

Epoch: 5| Step: 10
Training loss: 1.466583490371704
Validation loss: 2.1826029221216836

Epoch: 5| Step: 11
Training loss: 1.7141125202178955
Validation loss: 2.175301139553388

Epoch: 261| Step: 0
Training loss: 1.985602617263794
Validation loss: 2.172667255004247

Epoch: 5| Step: 1
Training loss: 1.7396080493927002
Validation loss: 2.177275980512301

Epoch: 5| Step: 2
Training loss: 1.522374153137207
Validation loss: 2.1746567487716675

Epoch: 5| Step: 3
Training loss: 1.6687263250350952
Validation loss: 2.1832793901364007

Epoch: 5| Step: 4
Training loss: 2.3307361602783203
Validation loss: 2.191982219616572

Epoch: 5| Step: 5
Training loss: 1.9191051721572876
Validation loss: 2.1782585978507996

Epoch: 5| Step: 6
Training loss: 2.278191328048706
Validation loss: 2.181442697842916

Epoch: 5| Step: 7
Training loss: 1.8217118978500366
Validation loss: 2.1790452202161155

Epoch: 5| Step: 8
Training loss: 1.7032439708709717
Validation loss: 2.1759655674298606

Epoch: 5| Step: 9
Training loss: 1.9269943237304688
Validation loss: 2.1717427372932434

Epoch: 5| Step: 10
Training loss: 1.4327261447906494
Validation loss: 2.182949885725975

Epoch: 5| Step: 11
Training loss: 1.2049198150634766
Validation loss: 2.1857477128505707

Epoch: 262| Step: 0
Training loss: 2.074249744415283
Validation loss: 2.1739062666893005

Epoch: 5| Step: 1
Training loss: 1.6657317876815796
Validation loss: 2.1802652527888617

Epoch: 5| Step: 2
Training loss: 1.419236660003662
Validation loss: 2.1772735714912415

Epoch: 5| Step: 3
Training loss: 2.4835205078125
Validation loss: 2.186933477719625

Epoch: 5| Step: 4
Training loss: 2.2704880237579346
Validation loss: 2.1859219074249268

Epoch: 5| Step: 5
Training loss: 1.8376381397247314
Validation loss: 2.1825767358144126

Epoch: 5| Step: 6
Training loss: 1.7788121700286865
Validation loss: 2.191961571574211

Epoch: 5| Step: 7
Training loss: 1.1550383567810059
Validation loss: 2.1759637693564096

Epoch: 5| Step: 8
Training loss: 1.8606765270233154
Validation loss: 2.1855479081471763

Epoch: 5| Step: 9
Training loss: 1.4483468532562256
Validation loss: 2.205085506041845

Epoch: 5| Step: 10
Training loss: 2.198363780975342
Validation loss: 2.181594635049502

Epoch: 5| Step: 11
Training loss: 1.6819299459457397
Validation loss: 2.182108481725057

Epoch: 263| Step: 0
Training loss: 1.890424132347107
Validation loss: 2.180273046096166

Epoch: 5| Step: 1
Training loss: 1.2283183336257935
Validation loss: 2.1813439428806305

Epoch: 5| Step: 2
Training loss: 2.1851017475128174
Validation loss: 2.168431287010511

Epoch: 5| Step: 3
Training loss: 1.969449758529663
Validation loss: 2.1760114481051764

Epoch: 5| Step: 4
Training loss: 1.8235273361206055
Validation loss: 2.1908425986766815

Epoch: 5| Step: 5
Training loss: 2.331892728805542
Validation loss: 2.1678461134433746

Epoch: 5| Step: 6
Training loss: 2.0482017993927
Validation loss: 2.176406741142273

Epoch: 5| Step: 7
Training loss: 1.5181862115859985
Validation loss: 2.1854413896799088

Epoch: 5| Step: 8
Training loss: 1.7170969247817993
Validation loss: 2.1744113167126975

Epoch: 5| Step: 9
Training loss: 1.7013676166534424
Validation loss: 2.1798547307650247

Epoch: 5| Step: 10
Training loss: 2.081880569458008
Validation loss: 2.1734072963396707

Epoch: 5| Step: 11
Training loss: 1.0955454111099243
Validation loss: 2.17612191538016

Epoch: 264| Step: 0
Training loss: 1.2588568925857544
Validation loss: 2.185157140096029

Epoch: 5| Step: 1
Training loss: 1.9913418292999268
Validation loss: 2.1794368624687195

Epoch: 5| Step: 2
Training loss: 1.1398557424545288
Validation loss: 2.1974674612283707

Epoch: 5| Step: 3
Training loss: 1.9127670526504517
Validation loss: 2.197301988800367

Epoch: 5| Step: 4
Training loss: 1.890851378440857
Validation loss: 2.191950500011444

Epoch: 5| Step: 5
Training loss: 2.170457363128662
Validation loss: 2.207275544603666

Epoch: 5| Step: 6
Training loss: 1.8247398138046265
Validation loss: 2.19330703218778

Epoch: 5| Step: 7
Training loss: 1.711369276046753
Validation loss: 2.1933065752188363

Epoch: 5| Step: 8
Training loss: 1.9034507274627686
Validation loss: 2.177290161450704

Epoch: 5| Step: 9
Training loss: 2.475215435028076
Validation loss: 2.1880179146925607

Epoch: 5| Step: 10
Training loss: 2.039767026901245
Validation loss: 2.1857583870490394

Epoch: 5| Step: 11
Training loss: 2.6450419425964355
Validation loss: 2.19694318373998

Epoch: 265| Step: 0
Training loss: 1.5735403299331665
Validation loss: 2.189404159784317

Epoch: 5| Step: 1
Training loss: 2.407816171646118
Validation loss: 2.1788112968206406

Epoch: 5| Step: 2
Training loss: 1.8848028182983398
Validation loss: 2.1852617412805557

Epoch: 5| Step: 3
Training loss: 1.8814265727996826
Validation loss: 2.176566561063131

Epoch: 5| Step: 4
Training loss: 1.3433135747909546
Validation loss: 2.1872184375921884

Epoch: 5| Step: 5
Training loss: 1.9864933490753174
Validation loss: 2.1813179155190787

Epoch: 5| Step: 6
Training loss: 2.149374485015869
Validation loss: 2.186777780453364

Epoch: 5| Step: 7
Training loss: 2.037466526031494
Validation loss: 2.180361807346344

Epoch: 5| Step: 8
Training loss: 1.7216888666152954
Validation loss: 2.1779447495937347

Epoch: 5| Step: 9
Training loss: 1.8432718515396118
Validation loss: 2.1864735831816993

Epoch: 5| Step: 10
Training loss: 1.66538405418396
Validation loss: 2.17780265212059

Epoch: 5| Step: 11
Training loss: 1.25406014919281
Validation loss: 2.162355532248815

Epoch: 266| Step: 0
Training loss: 2.218902111053467
Validation loss: 2.1676878233750663

Epoch: 5| Step: 1
Training loss: 1.6222469806671143
Validation loss: 2.16237943371137

Epoch: 5| Step: 2
Training loss: 2.0037951469421387
Validation loss: 2.1720168739557266

Epoch: 5| Step: 3
Training loss: 1.7510217428207397
Validation loss: 2.1875425577163696

Epoch: 5| Step: 4
Training loss: 2.079942226409912
Validation loss: 2.168244957923889

Epoch: 5| Step: 5
Training loss: 2.078878879547119
Validation loss: 2.176641101638476

Epoch: 5| Step: 6
Training loss: 1.753546118736267
Validation loss: 2.1827978839476905

Epoch: 5| Step: 7
Training loss: 1.8171840906143188
Validation loss: 2.1765698393185935

Epoch: 5| Step: 8
Training loss: 1.8434181213378906
Validation loss: 2.1793623169263205

Epoch: 5| Step: 9
Training loss: 1.4921956062316895
Validation loss: 2.180495858192444

Epoch: 5| Step: 10
Training loss: 1.2425768375396729
Validation loss: 2.1756460716327033

Epoch: 5| Step: 11
Training loss: 2.1931724548339844
Validation loss: 2.16960937778155

Epoch: 267| Step: 0
Training loss: 1.453251838684082
Validation loss: 2.1719310581684113

Epoch: 5| Step: 1
Training loss: 2.114705801010132
Validation loss: 2.1652626544237137

Epoch: 5| Step: 2
Training loss: 1.562657117843628
Validation loss: 2.1623750030994415

Epoch: 5| Step: 3
Training loss: 1.6079494953155518
Validation loss: 2.1625430583953857

Epoch: 5| Step: 4
Training loss: 2.1659228801727295
Validation loss: 2.1758358577887216

Epoch: 5| Step: 5
Training loss: 1.9799869060516357
Validation loss: 2.179987187186877

Epoch: 5| Step: 6
Training loss: 1.3872641324996948
Validation loss: 2.1819562216599784

Epoch: 5| Step: 7
Training loss: 2.2989182472229004
Validation loss: 2.1611775159835815

Epoch: 5| Step: 8
Training loss: 1.706477165222168
Validation loss: 2.1821845918893814

Epoch: 5| Step: 9
Training loss: 1.84865403175354
Validation loss: 2.1581275860468545

Epoch: 5| Step: 10
Training loss: 1.8489316701889038
Validation loss: 2.1671933084726334

Epoch: 5| Step: 11
Training loss: 1.6376898288726807
Validation loss: 2.17135252058506

Epoch: 268| Step: 0
Training loss: 1.837354302406311
Validation loss: 2.1556351582209268

Epoch: 5| Step: 1
Training loss: 1.7762641906738281
Validation loss: 2.1719825168450675

Epoch: 5| Step: 2
Training loss: 1.7176538705825806
Validation loss: 2.162003750602404

Epoch: 5| Step: 3
Training loss: 1.6882705688476562
Validation loss: 2.170714348554611

Epoch: 5| Step: 4
Training loss: 2.0295445919036865
Validation loss: 2.16351185242335

Epoch: 5| Step: 5
Training loss: 2.4511570930480957
Validation loss: 2.163141578435898

Epoch: 5| Step: 6
Training loss: 1.6995677947998047
Validation loss: 2.1557013193766275

Epoch: 5| Step: 7
Training loss: 1.7921794652938843
Validation loss: 2.166205202539762

Epoch: 5| Step: 8
Training loss: 2.2353949546813965
Validation loss: 2.180280476808548

Epoch: 5| Step: 9
Training loss: 1.818040132522583
Validation loss: 2.184932291507721

Epoch: 5| Step: 10
Training loss: 1.1957266330718994
Validation loss: 2.182471290230751

Epoch: 5| Step: 11
Training loss: 2.6985387802124023
Validation loss: 2.1760680129130683

Epoch: 269| Step: 0
Training loss: 1.8703737258911133
Validation loss: 2.1670253425836563

Epoch: 5| Step: 1
Training loss: 1.8892545700073242
Validation loss: 2.176598737637202

Epoch: 5| Step: 2
Training loss: 2.220552444458008
Validation loss: 2.1709790428479514

Epoch: 5| Step: 3
Training loss: 1.673706293106079
Validation loss: 2.181916907429695

Epoch: 5| Step: 4
Training loss: 2.042210578918457
Validation loss: 2.1840759217739105

Epoch: 5| Step: 5
Training loss: 2.1283276081085205
Validation loss: 2.171572282910347

Epoch: 5| Step: 6
Training loss: 2.164945602416992
Validation loss: 2.1820151110490165

Epoch: 5| Step: 7
Training loss: 1.4525585174560547
Validation loss: 2.1839269200960794

Epoch: 5| Step: 8
Training loss: 1.581154465675354
Validation loss: 2.1881719728310904

Epoch: 5| Step: 9
Training loss: 1.3979555368423462
Validation loss: 2.1863058606783548

Epoch: 5| Step: 10
Training loss: 2.144911289215088
Validation loss: 2.184760828812917

Epoch: 5| Step: 11
Training loss: 1.8527979850769043
Validation loss: 2.178043787678083

Epoch: 270| Step: 0
Training loss: 1.5105376243591309
Validation loss: 2.1868823270003

Epoch: 5| Step: 1
Training loss: 1.5083627700805664
Validation loss: 2.1735556026299796

Epoch: 5| Step: 2
Training loss: 1.2148702144622803
Validation loss: 2.1947923451662064

Epoch: 5| Step: 3
Training loss: 2.3299014568328857
Validation loss: 2.1961124738057456

Epoch: 5| Step: 4
Training loss: 1.497153401374817
Validation loss: 2.189656749367714

Epoch: 5| Step: 5
Training loss: 1.7108395099639893
Validation loss: 2.2010285556316376

Epoch: 5| Step: 6
Training loss: 2.1956357955932617
Validation loss: 2.1947482426961265

Epoch: 5| Step: 7
Training loss: 2.279200315475464
Validation loss: 2.1807896395524344

Epoch: 5| Step: 8
Training loss: 1.7560218572616577
Validation loss: 2.1931165158748627

Epoch: 5| Step: 9
Training loss: 2.306201457977295
Validation loss: 2.18363356590271

Epoch: 5| Step: 10
Training loss: 1.579397439956665
Validation loss: 2.192122235894203

Epoch: 5| Step: 11
Training loss: 1.301184058189392
Validation loss: 2.183454394340515

Epoch: 271| Step: 0
Training loss: 1.6198924779891968
Validation loss: 2.185046061873436

Epoch: 5| Step: 1
Training loss: 2.1748032569885254
Validation loss: 2.18344617386659

Epoch: 5| Step: 2
Training loss: 2.3543002605438232
Validation loss: 2.1811061998208365

Epoch: 5| Step: 3
Training loss: 1.8200912475585938
Validation loss: 2.183797985315323

Epoch: 5| Step: 4
Training loss: 1.9128137826919556
Validation loss: 2.188874771197637

Epoch: 5| Step: 5
Training loss: 1.6137012243270874
Validation loss: 2.2025524228811264

Epoch: 5| Step: 6
Training loss: 2.3593761920928955
Validation loss: 2.179833004872004

Epoch: 5| Step: 7
Training loss: 1.730291724205017
Validation loss: 2.1935837467511496

Epoch: 5| Step: 8
Training loss: 1.1701629161834717
Validation loss: 2.2047105630238852

Epoch: 5| Step: 9
Training loss: 1.455953598022461
Validation loss: 2.2051864663759866

Epoch: 5| Step: 10
Training loss: 1.6973049640655518
Validation loss: 2.186170836289724

Epoch: 5| Step: 11
Training loss: 1.98694908618927
Validation loss: 2.2054930677016578

Epoch: 272| Step: 0
Training loss: 1.8279091119766235
Validation loss: 2.1782811880111694

Epoch: 5| Step: 1
Training loss: 1.701836347579956
Validation loss: 2.170519436399142

Epoch: 5| Step: 2
Training loss: 2.013388156890869
Validation loss: 2.167403777440389

Epoch: 5| Step: 3
Training loss: 1.5600324869155884
Validation loss: 2.177975277105967

Epoch: 5| Step: 4
Training loss: 2.1464240550994873
Validation loss: 2.1755694349606833

Epoch: 5| Step: 5
Training loss: 1.5988881587982178
Validation loss: 2.1682139237721763

Epoch: 5| Step: 6
Training loss: 1.8127784729003906
Validation loss: 2.1815647929906845

Epoch: 5| Step: 7
Training loss: 1.6082134246826172
Validation loss: 2.179768373568853

Epoch: 5| Step: 8
Training loss: 2.749267578125
Validation loss: 2.1798158983389535

Epoch: 5| Step: 9
Training loss: 1.9494247436523438
Validation loss: 2.192542791366577

Epoch: 5| Step: 10
Training loss: 1.8292465209960938
Validation loss: 2.2027404606342316

Epoch: 5| Step: 11
Training loss: 1.0815503597259521
Validation loss: 2.2129419644673667

Epoch: 273| Step: 0
Training loss: 1.7181198596954346
Validation loss: 2.2111844370762506

Epoch: 5| Step: 1
Training loss: 2.17590069770813
Validation loss: 2.2288048019011817

Epoch: 5| Step: 2
Training loss: 1.681466817855835
Validation loss: 2.231578007340431

Epoch: 5| Step: 3
Training loss: 2.093677043914795
Validation loss: 2.2242616017659507

Epoch: 5| Step: 4
Training loss: 2.2514727115631104
Validation loss: 2.221604347229004

Epoch: 5| Step: 5
Training loss: 2.0101561546325684
Validation loss: 2.2326175471146903

Epoch: 5| Step: 6
Training loss: 2.2799365520477295
Validation loss: 2.214296599229177

Epoch: 5| Step: 7
Training loss: 1.572484016418457
Validation loss: 2.2012663086255393

Epoch: 5| Step: 8
Training loss: 2.366157054901123
Validation loss: 2.1816493471463523

Epoch: 5| Step: 9
Training loss: 1.4504491090774536
Validation loss: 2.1668595522642136

Epoch: 5| Step: 10
Training loss: 1.8728837966918945
Validation loss: 2.167854850490888

Epoch: 5| Step: 11
Training loss: 0.6502047777175903
Validation loss: 2.151035944620768

Epoch: 274| Step: 0
Training loss: 1.4602347612380981
Validation loss: 2.155777633190155

Epoch: 5| Step: 1
Training loss: 1.3397548198699951
Validation loss: 2.1674195925394693

Epoch: 5| Step: 2
Training loss: 1.9118938446044922
Validation loss: 2.1675917903582254

Epoch: 5| Step: 3
Training loss: 1.6606299877166748
Validation loss: 2.1675483087698617

Epoch: 5| Step: 4
Training loss: 2.083104372024536
Validation loss: 2.1516720006863275

Epoch: 5| Step: 5
Training loss: 1.4989690780639648
Validation loss: 2.169022341569265

Epoch: 5| Step: 6
Training loss: 2.260601282119751
Validation loss: 2.1739742904901505

Epoch: 5| Step: 7
Training loss: 2.07240891456604
Validation loss: 2.160943627357483

Epoch: 5| Step: 8
Training loss: 1.5432159900665283
Validation loss: 2.187682737906774

Epoch: 5| Step: 9
Training loss: 2.577139377593994
Validation loss: 2.1820976386467614

Epoch: 5| Step: 10
Training loss: 2.0569381713867188
Validation loss: 2.1773273845513663

Epoch: 5| Step: 11
Training loss: 0.8944145441055298
Validation loss: 2.1876807461182275

Epoch: 275| Step: 0
Training loss: 1.937368631362915
Validation loss: 2.184273968140284

Epoch: 5| Step: 1
Training loss: 1.9786869287490845
Validation loss: 2.1624744832515717

Epoch: 5| Step: 2
Training loss: 1.7939258813858032
Validation loss: 2.1788080483675003

Epoch: 5| Step: 3
Training loss: 1.3586490154266357
Validation loss: 2.1754619578520455

Epoch: 5| Step: 4
Training loss: 1.9641144275665283
Validation loss: 2.190491040547689

Epoch: 5| Step: 5
Training loss: 2.038133144378662
Validation loss: 2.188954641421636

Epoch: 5| Step: 6
Training loss: 1.554449200630188
Validation loss: 2.185249775648117

Epoch: 5| Step: 7
Training loss: 1.3270606994628906
Validation loss: 2.180881197253863

Epoch: 5| Step: 8
Training loss: 2.1701807975769043
Validation loss: 2.188853075106939

Epoch: 5| Step: 9
Training loss: 1.9439293146133423
Validation loss: 2.186310976743698

Epoch: 5| Step: 10
Training loss: 1.3476699590682983
Validation loss: 2.177501698335012

Epoch: 5| Step: 11
Training loss: 3.696909189224243
Validation loss: 2.1730077316363654

Epoch: 276| Step: 0
Training loss: 1.9778099060058594
Validation loss: 2.1946675181388855

Epoch: 5| Step: 1
Training loss: 1.6855716705322266
Validation loss: 2.1749407947063446

Epoch: 5| Step: 2
Training loss: 2.874666690826416
Validation loss: 2.18235049645106

Epoch: 5| Step: 3
Training loss: 1.2003391981124878
Validation loss: 2.1888991743326187

Epoch: 5| Step: 4
Training loss: 1.2610743045806885
Validation loss: 2.2004159887631736

Epoch: 5| Step: 5
Training loss: 1.8633216619491577
Validation loss: 2.200083320339521

Epoch: 5| Step: 6
Training loss: 1.744179129600525
Validation loss: 2.1930703620115914

Epoch: 5| Step: 7
Training loss: 1.9096778631210327
Validation loss: 2.1846978863080344

Epoch: 5| Step: 8
Training loss: 1.736358642578125
Validation loss: 2.205223669608434

Epoch: 5| Step: 9
Training loss: 2.0525870323181152
Validation loss: 2.2087468107541404

Epoch: 5| Step: 10
Training loss: 2.02048921585083
Validation loss: 2.2019228289524713

Epoch: 5| Step: 11
Training loss: 0.376552015542984
Validation loss: 2.2133364329735437

Epoch: 277| Step: 0
Training loss: 1.8992302417755127
Validation loss: 2.196296518047651

Epoch: 5| Step: 1
Training loss: 1.812709093093872
Validation loss: 2.2133435706297555

Epoch: 5| Step: 2
Training loss: 1.5484001636505127
Validation loss: 2.2017110139131546

Epoch: 5| Step: 3
Training loss: 1.7912527322769165
Validation loss: 2.1851554612318673

Epoch: 5| Step: 4
Training loss: 2.3748083114624023
Validation loss: 2.1973669081926346

Epoch: 5| Step: 5
Training loss: 1.3432639837265015
Validation loss: 2.206448738773664

Epoch: 5| Step: 6
Training loss: 1.4682674407958984
Validation loss: 2.17989053328832

Epoch: 5| Step: 7
Training loss: 1.492679238319397
Validation loss: 2.207522710164388

Epoch: 5| Step: 8
Training loss: 2.284238338470459
Validation loss: 2.184365466237068

Epoch: 5| Step: 9
Training loss: 2.256035327911377
Validation loss: 2.204736034075419

Epoch: 5| Step: 10
Training loss: 1.5207140445709229
Validation loss: 2.1888236006100974

Epoch: 5| Step: 11
Training loss: 2.1477646827697754
Validation loss: 2.193233256538709

Epoch: 278| Step: 0
Training loss: 1.7628085613250732
Validation loss: 2.2068038483460746

Epoch: 5| Step: 1
Training loss: 2.2894625663757324
Validation loss: 2.201303169131279

Epoch: 5| Step: 2
Training loss: 1.714276909828186
Validation loss: 2.188737461964289

Epoch: 5| Step: 3
Training loss: 1.7635467052459717
Validation loss: 2.1921318670113883

Epoch: 5| Step: 4
Training loss: 1.9056050777435303
Validation loss: 2.1936365763346353

Epoch: 5| Step: 5
Training loss: 1.598549723625183
Validation loss: 2.2053252955277762

Epoch: 5| Step: 6
Training loss: 1.76833975315094
Validation loss: 2.1890090852975845

Epoch: 5| Step: 7
Training loss: 1.476223349571228
Validation loss: 2.1877612322568893

Epoch: 5| Step: 8
Training loss: 2.1225953102111816
Validation loss: 2.193791483839353

Epoch: 5| Step: 9
Training loss: 1.5632113218307495
Validation loss: 2.19892510275046

Epoch: 5| Step: 10
Training loss: 1.9193780422210693
Validation loss: 2.2082097629706063

Epoch: 5| Step: 11
Training loss: 1.7057781219482422
Validation loss: 2.2015594840049744

Epoch: 279| Step: 0
Training loss: 1.54182767868042
Validation loss: 2.202198565006256

Epoch: 5| Step: 1
Training loss: 1.7919155359268188
Validation loss: 2.1940341691176095

Epoch: 5| Step: 2
Training loss: 1.8387607336044312
Validation loss: 2.1936921874682107

Epoch: 5| Step: 3
Training loss: 1.8864142894744873
Validation loss: 2.2031764487425485

Epoch: 5| Step: 4
Training loss: 2.1699132919311523
Validation loss: 2.1892729153235755

Epoch: 5| Step: 5
Training loss: 1.718161940574646
Validation loss: 2.1754273523887

Epoch: 5| Step: 6
Training loss: 1.4704689979553223
Validation loss: 2.188056449095408

Epoch: 5| Step: 7
Training loss: 1.7339897155761719
Validation loss: 2.1813185264666877

Epoch: 5| Step: 8
Training loss: 1.7427046298980713
Validation loss: 2.1714218854904175

Epoch: 5| Step: 9
Training loss: 2.1681630611419678
Validation loss: 2.1753527522087097

Epoch: 5| Step: 10
Training loss: 1.8360408544540405
Validation loss: 2.193918213248253

Epoch: 5| Step: 11
Training loss: 1.2379183769226074
Validation loss: 2.18749072154363

Epoch: 280| Step: 0
Training loss: 2.413104295730591
Validation loss: 2.1794031957785287

Epoch: 5| Step: 1
Training loss: 1.4875272512435913
Validation loss: 2.182202691833178

Epoch: 5| Step: 2
Training loss: 2.155959367752075
Validation loss: 2.1888925582170486

Epoch: 5| Step: 3
Training loss: 1.6322910785675049
Validation loss: 2.1897021432717643

Epoch: 5| Step: 4
Training loss: 1.7316980361938477
Validation loss: 2.1812263329823813

Epoch: 5| Step: 5
Training loss: 1.9038903713226318
Validation loss: 2.1790804117918015

Epoch: 5| Step: 6
Training loss: 1.4713995456695557
Validation loss: 2.185378144184748

Epoch: 5| Step: 7
Training loss: 1.5336014032363892
Validation loss: 2.193399101495743

Epoch: 5| Step: 8
Training loss: 2.5693180561065674
Validation loss: 2.19203087190787

Epoch: 5| Step: 9
Training loss: 1.3030054569244385
Validation loss: 2.191807101170222

Epoch: 5| Step: 10
Training loss: 1.4134457111358643
Validation loss: 2.197173610329628

Epoch: 5| Step: 11
Training loss: 2.6020989418029785
Validation loss: 2.2033808728059134

Epoch: 281| Step: 0
Training loss: 1.5951176881790161
Validation loss: 2.213650514682134

Epoch: 5| Step: 1
Training loss: 1.7668870687484741
Validation loss: 2.220951497554779

Epoch: 5| Step: 2
Training loss: 1.9416542053222656
Validation loss: 2.212311089038849

Epoch: 5| Step: 3
Training loss: 1.439316987991333
Validation loss: 2.208631088336309

Epoch: 5| Step: 4
Training loss: 2.0190300941467285
Validation loss: 2.2114028682311377

Epoch: 5| Step: 5
Training loss: 1.5166329145431519
Validation loss: 2.211955959598223

Epoch: 5| Step: 6
Training loss: 1.8321651220321655
Validation loss: 2.2061981012423835

Epoch: 5| Step: 7
Training loss: 1.5956257581710815
Validation loss: 2.196574325362841

Epoch: 5| Step: 8
Training loss: 2.5046298503875732
Validation loss: 2.1886046230793

Epoch: 5| Step: 9
Training loss: 2.2740836143493652
Validation loss: 2.204392040769259

Epoch: 5| Step: 10
Training loss: 1.3150479793548584
Validation loss: 2.178044935067495

Epoch: 5| Step: 11
Training loss: 1.4327105283737183
Validation loss: 2.1833341668049493

Epoch: 282| Step: 0
Training loss: 2.002877712249756
Validation loss: 2.2021432320276895

Epoch: 5| Step: 1
Training loss: 1.76288640499115
Validation loss: 2.189517835776011

Epoch: 5| Step: 2
Training loss: 1.7807998657226562
Validation loss: 2.202703138192495

Epoch: 5| Step: 3
Training loss: 1.179508924484253
Validation loss: 2.2042763580878577

Epoch: 5| Step: 4
Training loss: 2.3787925243377686
Validation loss: 2.2077073057492576

Epoch: 5| Step: 5
Training loss: 2.081040620803833
Validation loss: 2.2130743116140366

Epoch: 5| Step: 6
Training loss: 1.852452278137207
Validation loss: 2.2144647538661957

Epoch: 5| Step: 7
Training loss: 1.8418985605239868
Validation loss: 2.215625966588656

Epoch: 5| Step: 8
Training loss: 1.8386576175689697
Validation loss: 2.2044022728999457

Epoch: 5| Step: 9
Training loss: 1.3052842617034912
Validation loss: 2.1999874909718833

Epoch: 5| Step: 10
Training loss: 1.591599702835083
Validation loss: 2.2183226396640143

Epoch: 5| Step: 11
Training loss: 1.4191627502441406
Validation loss: 2.189738243818283

Epoch: 283| Step: 0
Training loss: 1.8773047924041748
Validation loss: 2.1746835907300315

Epoch: 5| Step: 1
Training loss: 1.9620187282562256
Validation loss: 2.163388748963674

Epoch: 5| Step: 2
Training loss: 1.541085124015808
Validation loss: 2.174780949950218

Epoch: 5| Step: 3
Training loss: 1.569183588027954
Validation loss: 2.1755212942759194

Epoch: 5| Step: 4
Training loss: 2.0059103965759277
Validation loss: 2.1657691597938538

Epoch: 5| Step: 5
Training loss: 2.142683506011963
Validation loss: 2.17846671740214

Epoch: 5| Step: 6
Training loss: 2.6066408157348633
Validation loss: 2.1758998135725656

Epoch: 5| Step: 7
Training loss: 1.8631982803344727
Validation loss: 2.1873100648323693

Epoch: 5| Step: 8
Training loss: 1.3253313302993774
Validation loss: 2.1990042328834534

Epoch: 5| Step: 9
Training loss: 1.972059965133667
Validation loss: 2.1986058751742044

Epoch: 5| Step: 10
Training loss: 1.5663896799087524
Validation loss: 2.1916674772898355

Epoch: 5| Step: 11
Training loss: 1.9823899269104004
Validation loss: 2.184935728708903

Epoch: 284| Step: 0
Training loss: 1.534637212753296
Validation loss: 2.2028889109690986

Epoch: 5| Step: 1
Training loss: 1.4142167568206787
Validation loss: 2.1999020079771676

Epoch: 5| Step: 2
Training loss: 2.2431836128234863
Validation loss: 2.1963205436865487

Epoch: 5| Step: 3
Training loss: 2.1914005279541016
Validation loss: 2.2077012807130814

Epoch: 5| Step: 4
Training loss: 1.9935792684555054
Validation loss: 2.218447963396708

Epoch: 5| Step: 5
Training loss: 1.9748328924179077
Validation loss: 2.1916133612394333

Epoch: 5| Step: 6
Training loss: 1.4572595357894897
Validation loss: 2.2063449770212173

Epoch: 5| Step: 7
Training loss: 2.1056630611419678
Validation loss: 2.2010384996732077

Epoch: 5| Step: 8
Training loss: 1.4427769184112549
Validation loss: 2.209056705236435

Epoch: 5| Step: 9
Training loss: 1.5780097246170044
Validation loss: 2.216118738055229

Epoch: 5| Step: 10
Training loss: 1.7106983661651611
Validation loss: 2.213833272457123

Epoch: 5| Step: 11
Training loss: 1.3225271701812744
Validation loss: 2.2151207625865936

Epoch: 285| Step: 0
Training loss: 1.433178186416626
Validation loss: 2.219275653362274

Epoch: 5| Step: 1
Training loss: 1.683109998703003
Validation loss: 2.1866958340009055

Epoch: 5| Step: 2
Training loss: 1.6930866241455078
Validation loss: 2.2106648037830987

Epoch: 5| Step: 3
Training loss: 1.9479930400848389
Validation loss: 2.206744601329168

Epoch: 5| Step: 4
Training loss: 2.046245574951172
Validation loss: 2.200730706254641

Epoch: 5| Step: 5
Training loss: 2.337522029876709
Validation loss: 2.204465866088867

Epoch: 5| Step: 6
Training loss: 1.4773671627044678
Validation loss: 2.195233404636383

Epoch: 5| Step: 7
Training loss: 2.00152587890625
Validation loss: 2.2019658933083215

Epoch: 5| Step: 8
Training loss: 1.7834030389785767
Validation loss: 2.205399677157402

Epoch: 5| Step: 9
Training loss: 1.2943265438079834
Validation loss: 2.185918857653936

Epoch: 5| Step: 10
Training loss: 1.7145065069198608
Validation loss: 2.196884016195933

Epoch: 5| Step: 11
Training loss: 1.8636208772659302
Validation loss: 2.201761096715927

Epoch: 286| Step: 0
Training loss: 1.9304535388946533
Validation loss: 2.184744199117025

Epoch: 5| Step: 1
Training loss: 1.4529321193695068
Validation loss: 2.1997862259546914

Epoch: 5| Step: 2
Training loss: 1.7266933917999268
Validation loss: 2.184738169113795

Epoch: 5| Step: 3
Training loss: 1.6410213708877563
Validation loss: 2.1855474015076957

Epoch: 5| Step: 4
Training loss: 2.0185976028442383
Validation loss: 2.194324259956678

Epoch: 5| Step: 5
Training loss: 1.9387073516845703
Validation loss: 2.1856312652428946

Epoch: 5| Step: 6
Training loss: 1.7607486248016357
Validation loss: 2.182336966196696

Epoch: 5| Step: 7
Training loss: 1.5817582607269287
Validation loss: 2.193301260471344

Epoch: 5| Step: 8
Training loss: 1.8541240692138672
Validation loss: 2.1957383354504905

Epoch: 5| Step: 9
Training loss: 1.7470823526382446
Validation loss: 2.2110529144605002

Epoch: 5| Step: 10
Training loss: 1.7791297435760498
Validation loss: 2.1787735323111215

Epoch: 5| Step: 11
Training loss: 1.2584319114685059
Validation loss: 2.210306227207184

Epoch: 287| Step: 0
Training loss: 2.433565616607666
Validation loss: 2.183811590075493

Epoch: 5| Step: 1
Training loss: 1.1418912410736084
Validation loss: 2.2026926477750144

Epoch: 5| Step: 2
Training loss: 2.896332263946533
Validation loss: 2.179950704177221

Epoch: 5| Step: 3
Training loss: 1.1256873607635498
Validation loss: 2.2064608186483383

Epoch: 5| Step: 4
Training loss: 1.7824398279190063
Validation loss: 2.193369075655937

Epoch: 5| Step: 5
Training loss: 2.753389835357666
Validation loss: 2.200248489777247

Epoch: 5| Step: 6
Training loss: 1.4656116962432861
Validation loss: 2.2081782519817352

Epoch: 5| Step: 7
Training loss: 1.5959326028823853
Validation loss: 2.2095622519652047

Epoch: 5| Step: 8
Training loss: 1.5193395614624023
Validation loss: 2.1937572161356607

Epoch: 5| Step: 9
Training loss: 1.3963979482650757
Validation loss: 2.1817523886760077

Epoch: 5| Step: 10
Training loss: 1.5235607624053955
Validation loss: 2.1938041746616364

Epoch: 5| Step: 11
Training loss: 1.5307674407958984
Validation loss: 2.188878426949183

Epoch: 288| Step: 0
Training loss: 1.6296237707138062
Validation loss: 2.1883859435717263

Epoch: 5| Step: 1
Training loss: 1.649060845375061
Validation loss: 2.169755150874456

Epoch: 5| Step: 2
Training loss: 2.2498443126678467
Validation loss: 2.1947691589593887

Epoch: 5| Step: 3
Training loss: 2.1416659355163574
Validation loss: 2.177210440238317

Epoch: 5| Step: 4
Training loss: 2.1739907264709473
Validation loss: 2.1738771945238113

Epoch: 5| Step: 5
Training loss: 1.5634591579437256
Validation loss: 2.1809320747852325

Epoch: 5| Step: 6
Training loss: 1.3042539358139038
Validation loss: 2.1948013405005136

Epoch: 5| Step: 7
Training loss: 1.7244430780410767
Validation loss: 2.1858485539754233

Epoch: 5| Step: 8
Training loss: 1.5344158411026
Validation loss: 2.209793895483017

Epoch: 5| Step: 9
Training loss: 1.6601930856704712
Validation loss: 2.2100532054901123

Epoch: 5| Step: 10
Training loss: 1.6668150424957275
Validation loss: 2.191819652915001

Epoch: 5| Step: 11
Training loss: 2.6403465270996094
Validation loss: 2.2087853948275247

Epoch: 289| Step: 0
Training loss: 1.818429708480835
Validation loss: 2.2026791324218116

Epoch: 5| Step: 1
Training loss: 1.7517039775848389
Validation loss: 2.1985207299391427

Epoch: 5| Step: 2
Training loss: 1.626373052597046
Validation loss: 2.1959825605154037

Epoch: 5| Step: 3
Training loss: 1.7050249576568604
Validation loss: 2.199977378050486

Epoch: 5| Step: 4
Training loss: 1.614880919456482
Validation loss: 2.181134427587191

Epoch: 5| Step: 5
Training loss: 1.5651729106903076
Validation loss: 2.181711326042811

Epoch: 5| Step: 6
Training loss: 2.7548625469207764
Validation loss: 2.2019914587338767

Epoch: 5| Step: 7
Training loss: 1.9639313220977783
Validation loss: 2.1959807872772217

Epoch: 5| Step: 8
Training loss: 1.8340778350830078
Validation loss: 2.2039827654759088

Epoch: 5| Step: 9
Training loss: 1.475294828414917
Validation loss: 2.2091376185417175

Epoch: 5| Step: 10
Training loss: 1.8346935510635376
Validation loss: 2.2046598345041275

Epoch: 5| Step: 11
Training loss: 0.5680135488510132
Validation loss: 2.2191452930370965

Epoch: 290| Step: 0
Training loss: 1.485025405883789
Validation loss: 2.200609197219213

Epoch: 5| Step: 1
Training loss: 2.287724256515503
Validation loss: 2.217335800329844

Epoch: 5| Step: 2
Training loss: 1.844429612159729
Validation loss: 2.19948743780454

Epoch: 5| Step: 3
Training loss: 1.604888916015625
Validation loss: 2.189320276180903

Epoch: 5| Step: 4
Training loss: 1.8177144527435303
Validation loss: 2.199797918399175

Epoch: 5| Step: 5
Training loss: 1.5752980709075928
Validation loss: 2.1916479965051017

Epoch: 5| Step: 6
Training loss: 2.345766305923462
Validation loss: 2.196549961964289

Epoch: 5| Step: 7
Training loss: 1.9608335494995117
Validation loss: 2.196829835573832

Epoch: 5| Step: 8
Training loss: 2.1662230491638184
Validation loss: 2.189274320999781

Epoch: 5| Step: 9
Training loss: 1.1394636631011963
Validation loss: 2.1857486218214035

Epoch: 5| Step: 10
Training loss: 1.6356548070907593
Validation loss: 2.192251736919085

Epoch: 5| Step: 11
Training loss: 1.261476755142212
Validation loss: 2.1890653371810913

Epoch: 291| Step: 0
Training loss: 1.9113357067108154
Validation loss: 2.214447225133578

Epoch: 5| Step: 1
Training loss: 1.066489338874817
Validation loss: 2.215448255340258

Epoch: 5| Step: 2
Training loss: 1.5742783546447754
Validation loss: 2.2207872420549393

Epoch: 5| Step: 3
Training loss: 2.18308687210083
Validation loss: 2.2330905199050903

Epoch: 5| Step: 4
Training loss: 1.887426733970642
Validation loss: 2.2331945449113846

Epoch: 5| Step: 5
Training loss: 1.414167881011963
Validation loss: 2.2172693411509194

Epoch: 5| Step: 6
Training loss: 1.8101009130477905
Validation loss: 2.217165673772494

Epoch: 5| Step: 7
Training loss: 2.2636055946350098
Validation loss: 2.189341296752294

Epoch: 5| Step: 8
Training loss: 1.3977704048156738
Validation loss: 2.193103884657224

Epoch: 5| Step: 9
Training loss: 1.7211511135101318
Validation loss: 2.1772138675053916

Epoch: 5| Step: 10
Training loss: 2.08554744720459
Validation loss: 2.190716361006101

Epoch: 5| Step: 11
Training loss: 2.030168056488037
Validation loss: 2.1632794787486396

Epoch: 292| Step: 0
Training loss: 1.8781652450561523
Validation loss: 2.184711297353109

Epoch: 5| Step: 1
Training loss: 1.3168814182281494
Validation loss: 2.187297393878301

Epoch: 5| Step: 2
Training loss: 1.4452612400054932
Validation loss: 2.192994068066279

Epoch: 5| Step: 3
Training loss: 1.6651661396026611
Validation loss: 2.2015853027502694

Epoch: 5| Step: 4
Training loss: 1.480010747909546
Validation loss: 2.204356004794439

Epoch: 5| Step: 5
Training loss: 1.6847823858261108
Validation loss: 2.2117732167243958

Epoch: 5| Step: 6
Training loss: 1.7558311223983765
Validation loss: 2.2068896343310676

Epoch: 5| Step: 7
Training loss: 1.9702379703521729
Validation loss: 2.2138252755006156

Epoch: 5| Step: 8
Training loss: 1.5382431745529175
Validation loss: 2.2148589193820953

Epoch: 5| Step: 9
Training loss: 2.482440233230591
Validation loss: 2.219991222023964

Epoch: 5| Step: 10
Training loss: 2.3059520721435547
Validation loss: 2.202888071537018

Epoch: 5| Step: 11
Training loss: 1.01771879196167
Validation loss: 2.2038584848244986

Epoch: 293| Step: 0
Training loss: 1.7978521585464478
Validation loss: 2.205956240495046

Epoch: 5| Step: 1
Training loss: 1.5549403429031372
Validation loss: 2.204468717177709

Epoch: 5| Step: 2
Training loss: 1.3771169185638428
Validation loss: 2.202551454305649

Epoch: 5| Step: 3
Training loss: 2.206000328063965
Validation loss: 2.2023999094963074

Epoch: 5| Step: 4
Training loss: 1.660211205482483
Validation loss: 2.195839817325274

Epoch: 5| Step: 5
Training loss: 1.3036993741989136
Validation loss: 2.2111171235640845

Epoch: 5| Step: 6
Training loss: 1.6474205255508423
Validation loss: 2.1970132688681283

Epoch: 5| Step: 7
Training loss: 2.0157761573791504
Validation loss: 2.198136846224467

Epoch: 5| Step: 8
Training loss: 2.020249843597412
Validation loss: 2.2024985204140344

Epoch: 5| Step: 9
Training loss: 1.7754104137420654
Validation loss: 2.1973194926977158

Epoch: 5| Step: 10
Training loss: 1.6694679260253906
Validation loss: 2.1837278306484222

Epoch: 5| Step: 11
Training loss: 3.493295907974243
Validation loss: 2.1947660545508065

Epoch: 294| Step: 0
Training loss: 2.1439948081970215
Validation loss: 2.17887344956398

Epoch: 5| Step: 1
Training loss: 1.4577194452285767
Validation loss: 2.165893485148748

Epoch: 5| Step: 2
Training loss: 1.9176585674285889
Validation loss: 2.189105808734894

Epoch: 5| Step: 3
Training loss: 2.025023937225342
Validation loss: 2.2055103480815887

Epoch: 5| Step: 4
Training loss: 1.5013660192489624
Validation loss: 2.204226220647494

Epoch: 5| Step: 5
Training loss: 1.7531280517578125
Validation loss: 2.2018185754617057

Epoch: 5| Step: 6
Training loss: 1.8582267761230469
Validation loss: 2.2094059685866037

Epoch: 5| Step: 7
Training loss: 1.055652379989624
Validation loss: 2.2046817193428674

Epoch: 5| Step: 8
Training loss: 1.676754355430603
Validation loss: 2.223660886287689

Epoch: 5| Step: 9
Training loss: 1.864855170249939
Validation loss: 2.2039579848448434

Epoch: 5| Step: 10
Training loss: 1.7174041271209717
Validation loss: 2.2273943722248077

Epoch: 5| Step: 11
Training loss: 2.757669448852539
Validation loss: 2.2122784157594046

Epoch: 295| Step: 0
Training loss: 2.1521735191345215
Validation loss: 2.191186100244522

Epoch: 5| Step: 1
Training loss: 1.5791335105895996
Validation loss: 2.200848509867986

Epoch: 5| Step: 2
Training loss: 1.7258265018463135
Validation loss: 2.1777941435575485

Epoch: 5| Step: 3
Training loss: 2.1540186405181885
Validation loss: 2.185959835847219

Epoch: 5| Step: 4
Training loss: 0.9272410273551941
Validation loss: 2.189971387386322

Epoch: 5| Step: 5
Training loss: 2.149334669113159
Validation loss: 2.208204279343287

Epoch: 5| Step: 6
Training loss: 1.815079927444458
Validation loss: 2.194891611735026

Epoch: 5| Step: 7
Training loss: 1.6800434589385986
Validation loss: 2.205914338429769

Epoch: 5| Step: 8
Training loss: 2.3156304359436035
Validation loss: 2.2128397077322006

Epoch: 5| Step: 9
Training loss: 1.5833076238632202
Validation loss: 2.2004850109418235

Epoch: 5| Step: 10
Training loss: 1.1907256841659546
Validation loss: 2.205917477607727

Epoch: 5| Step: 11
Training loss: 1.7766896486282349
Validation loss: 2.207130422194799

Epoch: 296| Step: 0
Training loss: 2.046703338623047
Validation loss: 2.1934508234262466

Epoch: 5| Step: 1
Training loss: 1.60391366481781
Validation loss: 2.1845817118883133

Epoch: 5| Step: 2
Training loss: 1.7552635669708252
Validation loss: 2.178613399465879

Epoch: 5| Step: 3
Training loss: 1.9600166082382202
Validation loss: 2.1795483281215033

Epoch: 5| Step: 4
Training loss: 1.6787440776824951
Validation loss: 2.1762617578109107

Epoch: 5| Step: 5
Training loss: 1.8916265964508057
Validation loss: 2.1890537093083062

Epoch: 5| Step: 6
Training loss: 1.9720404148101807
Validation loss: 2.1667865415414176

Epoch: 5| Step: 7
Training loss: 1.727744460105896
Validation loss: 2.1852548917134604

Epoch: 5| Step: 8
Training loss: 1.4024494886398315
Validation loss: 2.1925527254740396

Epoch: 5| Step: 9
Training loss: 2.037466049194336
Validation loss: 2.1763535141944885

Epoch: 5| Step: 10
Training loss: 1.7225555181503296
Validation loss: 2.1988238046566644

Epoch: 5| Step: 11
Training loss: 2.583925485610962
Validation loss: 2.2010590583086014

Epoch: 297| Step: 0
Training loss: 1.7086060047149658
Validation loss: 2.2109233140945435

Epoch: 5| Step: 1
Training loss: 1.926343560218811
Validation loss: 2.2224294145902

Epoch: 5| Step: 2
Training loss: 1.4595164060592651
Validation loss: 2.2148557305336

Epoch: 5| Step: 3
Training loss: 1.8082802295684814
Validation loss: 2.2086110363403955

Epoch: 5| Step: 4
Training loss: 1.5826663970947266
Validation loss: 2.213224242130915

Epoch: 5| Step: 5
Training loss: 2.0027761459350586
Validation loss: 2.212188427646955

Epoch: 5| Step: 6
Training loss: 1.6998411417007446
Validation loss: 2.205998962124189

Epoch: 5| Step: 7
Training loss: 1.7129348516464233
Validation loss: 2.2189960330724716

Epoch: 5| Step: 8
Training loss: 1.6363334655761719
Validation loss: 2.2063748141129813

Epoch: 5| Step: 9
Training loss: 2.204206943511963
Validation loss: 2.2206518749396005

Epoch: 5| Step: 10
Training loss: 1.5132644176483154
Validation loss: 2.222080002228419

Epoch: 5| Step: 11
Training loss: 2.5148229598999023
Validation loss: 2.223414738972982

Epoch: 298| Step: 0
Training loss: 1.7391407489776611
Validation loss: 2.2367090582847595

Epoch: 5| Step: 1
Training loss: 1.7363700866699219
Validation loss: 2.1943642795085907

Epoch: 5| Step: 2
Training loss: 1.6576999425888062
Validation loss: 2.219412753979365

Epoch: 5| Step: 3
Training loss: 1.8604059219360352
Validation loss: 2.1928629179795585

Epoch: 5| Step: 4
Training loss: 2.11318039894104
Validation loss: 2.2124103903770447

Epoch: 5| Step: 5
Training loss: 1.2274514436721802
Validation loss: 2.1946452061335244

Epoch: 5| Step: 6
Training loss: 1.4997093677520752
Validation loss: 2.1943179816007614

Epoch: 5| Step: 7
Training loss: 2.2080817222595215
Validation loss: 2.19584921002388

Epoch: 5| Step: 8
Training loss: 1.6931469440460205
Validation loss: 2.1848473995923996

Epoch: 5| Step: 9
Training loss: 1.8283755779266357
Validation loss: 2.1803227066993713

Epoch: 5| Step: 10
Training loss: 1.6585458517074585
Validation loss: 2.1892760396003723

Epoch: 5| Step: 11
Training loss: 2.9931702613830566
Validation loss: 2.183341314395269

Epoch: 299| Step: 0
Training loss: 1.4854775667190552
Validation loss: 2.1751209795475006

Epoch: 5| Step: 1
Training loss: 1.786373496055603
Validation loss: 2.1850732564926147

Epoch: 5| Step: 2
Training loss: 1.837888479232788
Validation loss: 2.1931434522072473

Epoch: 5| Step: 3
Training loss: 1.1212537288665771
Validation loss: 2.1848179697990417

Epoch: 5| Step: 4
Training loss: 1.9912195205688477
Validation loss: 2.184418628613154

Epoch: 5| Step: 5
Training loss: 1.973962426185608
Validation loss: 2.201898843050003

Epoch: 5| Step: 6
Training loss: 1.766038179397583
Validation loss: 2.190293108423551

Epoch: 5| Step: 7
Training loss: 1.8392318487167358
Validation loss: 2.197800745566686

Epoch: 5| Step: 8
Training loss: 2.076270580291748
Validation loss: 2.1989965637524924

Epoch: 5| Step: 9
Training loss: 1.3606832027435303
Validation loss: 2.1941157231728234

Epoch: 5| Step: 10
Training loss: 1.8850090503692627
Validation loss: 2.1987183590730033

Epoch: 5| Step: 11
Training loss: 2.700352668762207
Validation loss: 2.196161165833473

Epoch: 300| Step: 0
Training loss: 1.5757015943527222
Validation loss: 2.2024379819631577

Epoch: 5| Step: 1
Training loss: 1.608597993850708
Validation loss: 2.1841821471850076

Epoch: 5| Step: 2
Training loss: 1.8864643573760986
Validation loss: 2.207947298884392

Epoch: 5| Step: 3
Training loss: 2.0100362300872803
Validation loss: 2.1911675731341043

Epoch: 5| Step: 4
Training loss: 1.5521090030670166
Validation loss: 2.1888461858034134

Epoch: 5| Step: 5
Training loss: 1.189978837966919
Validation loss: 2.1907395720481873

Epoch: 5| Step: 6
Training loss: 1.740753173828125
Validation loss: 2.1933965484301248

Epoch: 5| Step: 7
Training loss: 2.078245162963867
Validation loss: 2.1810413748025894

Epoch: 5| Step: 8
Training loss: 1.7089102268218994
Validation loss: 2.1818369179964066

Epoch: 5| Step: 9
Training loss: 2.023052930831909
Validation loss: 2.2035051882267

Epoch: 5| Step: 10
Training loss: 1.6698720455169678
Validation loss: 2.1761521250009537

Epoch: 5| Step: 11
Training loss: 1.8954827785491943
Validation loss: 2.208423544963201

Testing loss: 1.8951728729892978
