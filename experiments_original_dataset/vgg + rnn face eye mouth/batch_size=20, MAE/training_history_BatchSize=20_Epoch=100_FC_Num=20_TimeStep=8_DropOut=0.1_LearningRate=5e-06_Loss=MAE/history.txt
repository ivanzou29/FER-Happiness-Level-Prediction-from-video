Epoch: 1| Step: 0
Training loss: 5.19508695602417
Validation loss: 5.391416351000468

Epoch: 5| Step: 1
Training loss: 5.983338832855225
Validation loss: 5.389875849088033

Epoch: 5| Step: 2
Training loss: 5.706995964050293
Validation loss: 5.388463695844014

Epoch: 5| Step: 3
Training loss: 5.110627174377441
Validation loss: 5.3870444893836975

Epoch: 5| Step: 4
Training loss: 5.764180660247803
Validation loss: 5.385717272758484

Epoch: 5| Step: 5
Training loss: 4.752848148345947
Validation loss: 5.384316643079122

Epoch: 5| Step: 6
Training loss: 5.476799488067627
Validation loss: 5.382997393608093

Epoch: 5| Step: 7
Training loss: 5.789964199066162
Validation loss: 5.381681938966115

Epoch: 5| Step: 8
Training loss: 5.828545570373535
Validation loss: 5.380293230215709

Epoch: 5| Step: 9
Training loss: 4.877369403839111
Validation loss: 5.378943304220836

Epoch: 5| Step: 10
Training loss: 5.226523399353027
Validation loss: 5.3775859872500105

Epoch: 5| Step: 11
Training loss: 6.817455291748047
Validation loss: 5.376163880030314

Epoch: 2| Step: 0
Training loss: 5.348628044128418
Validation loss: 5.374747733275096

Epoch: 5| Step: 1
Training loss: 5.407027244567871
Validation loss: 5.373310625553131

Epoch: 5| Step: 2
Training loss: 5.840954780578613
Validation loss: 5.371769368648529

Epoch: 5| Step: 3
Training loss: 5.342325687408447
Validation loss: 5.370187481244405

Epoch: 5| Step: 4
Training loss: 6.604018211364746
Validation loss: 5.368536988894145

Epoch: 5| Step: 5
Training loss: 5.534773826599121
Validation loss: 5.366871813933055

Epoch: 5| Step: 6
Training loss: 4.827085018157959
Validation loss: 5.365042269229889

Epoch: 5| Step: 7
Training loss: 4.73260498046875
Validation loss: 5.363167822360992

Epoch: 5| Step: 8
Training loss: 5.265873908996582
Validation loss: 5.361167311668396

Epoch: 5| Step: 9
Training loss: 5.237063884735107
Validation loss: 5.359060664971669

Epoch: 5| Step: 10
Training loss: 5.359747409820557
Validation loss: 5.356869677702586

Epoch: 5| Step: 11
Training loss: 6.8671064376831055
Validation loss: 5.354572991530101

Epoch: 3| Step: 0
Training loss: 4.3610639572143555
Validation loss: 5.352139671643575

Epoch: 5| Step: 1
Training loss: 5.806958198547363
Validation loss: 5.349555134773254

Epoch: 5| Step: 2
Training loss: 4.984928607940674
Validation loss: 5.346851845582326

Epoch: 5| Step: 3
Training loss: 5.369037628173828
Validation loss: 5.3439197937647505

Epoch: 5| Step: 4
Training loss: 4.376914024353027
Validation loss: 5.340930104255676

Epoch: 5| Step: 5
Training loss: 5.220734596252441
Validation loss: 5.337755084037781

Epoch: 5| Step: 6
Training loss: 5.919882774353027
Validation loss: 5.33434812227885

Epoch: 5| Step: 7
Training loss: 5.751270771026611
Validation loss: 5.330862820148468

Epoch: 5| Step: 8
Training loss: 5.599558353424072
Validation loss: 5.327140669027965

Epoch: 5| Step: 9
Training loss: 6.221719741821289
Validation loss: 5.323171555995941

Epoch: 5| Step: 10
Training loss: 6.219837188720703
Validation loss: 5.319089452425639

Epoch: 5| Step: 11
Training loss: 3.5448384284973145
Validation loss: 5.314712663491567

Epoch: 4| Step: 0
Training loss: 5.232104301452637
Validation loss: 5.309985458850861

Epoch: 5| Step: 1
Training loss: 4.575064182281494
Validation loss: 5.305176874001821

Epoch: 5| Step: 2
Training loss: 5.823421478271484
Validation loss: 5.300342500209808

Epoch: 5| Step: 3
Training loss: 5.599916934967041
Validation loss: 5.294996241728465

Epoch: 5| Step: 4
Training loss: 4.485343933105469
Validation loss: 5.289477566878001

Epoch: 5| Step: 5
Training loss: 5.15249490737915
Validation loss: 5.283724228541057

Epoch: 5| Step: 6
Training loss: 5.017276287078857
Validation loss: 5.278063317139943

Epoch: 5| Step: 7
Training loss: 6.294390678405762
Validation loss: 5.271774331728618

Epoch: 5| Step: 8
Training loss: 4.8974504470825195
Validation loss: 5.265344699223836

Epoch: 5| Step: 9
Training loss: 6.400511264801025
Validation loss: 5.258816917737325

Epoch: 5| Step: 10
Training loss: 5.510892391204834
Validation loss: 5.25206200281779

Epoch: 5| Step: 11
Training loss: 4.742919921875
Validation loss: 5.245154241720836

Epoch: 5| Step: 0
Training loss: 5.825839042663574
Validation loss: 5.238023320833842

Epoch: 5| Step: 1
Training loss: 3.823080539703369
Validation loss: 5.230506559213002

Epoch: 5| Step: 2
Training loss: 5.789759635925293
Validation loss: 5.222809712092082

Epoch: 5| Step: 3
Training loss: 5.573925018310547
Validation loss: 5.215012033780416

Epoch: 5| Step: 4
Training loss: 3.9885997772216797
Validation loss: 5.207155803839366

Epoch: 5| Step: 5
Training loss: 4.990649700164795
Validation loss: 5.198563992977142

Epoch: 5| Step: 6
Training loss: 5.93958854675293
Validation loss: 5.190429965655009

Epoch: 5| Step: 7
Training loss: 4.892906665802002
Validation loss: 5.18191643555959

Epoch: 5| Step: 8
Training loss: 5.808675289154053
Validation loss: 5.172747850418091

Epoch: 5| Step: 9
Training loss: 4.970346927642822
Validation loss: 5.164096037546794

Epoch: 5| Step: 10
Training loss: 6.457617282867432
Validation loss: 5.154662946859996

Epoch: 5| Step: 11
Training loss: 4.71085786819458
Validation loss: 5.14514422416687

Epoch: 6| Step: 0
Training loss: 4.953496932983398
Validation loss: 5.135589301586151

Epoch: 5| Step: 1
Training loss: 4.983343601226807
Validation loss: 5.126078426837921

Epoch: 5| Step: 2
Training loss: 5.006998538970947
Validation loss: 5.116268773873647

Epoch: 5| Step: 3
Training loss: 5.57342529296875
Validation loss: 5.107098281383514

Epoch: 5| Step: 4
Training loss: 5.181948661804199
Validation loss: 5.097410182158153

Epoch: 5| Step: 5
Training loss: 4.772967338562012
Validation loss: 5.088338494300842

Epoch: 5| Step: 6
Training loss: 5.732782363891602
Validation loss: 5.078780611356099

Epoch: 5| Step: 7
Training loss: 5.161240577697754
Validation loss: 5.06950710217158

Epoch: 5| Step: 8
Training loss: 5.687556743621826
Validation loss: 5.060345570246379

Epoch: 5| Step: 9
Training loss: 3.9203040599823
Validation loss: 5.051201105117798

Epoch: 5| Step: 10
Training loss: 5.511568546295166
Validation loss: 5.041829913854599

Epoch: 5| Step: 11
Training loss: 6.713101863861084
Validation loss: 5.032743136088054

Epoch: 7| Step: 0
Training loss: 5.276873588562012
Validation loss: 5.023608644803365

Epoch: 5| Step: 1
Training loss: 5.916089057922363
Validation loss: 5.014768580595653

Epoch: 5| Step: 2
Training loss: 4.9879984855651855
Validation loss: 5.005920867125194

Epoch: 5| Step: 3
Training loss: 4.680184364318848
Validation loss: 4.997633278369904

Epoch: 5| Step: 4
Training loss: 5.045964241027832
Validation loss: 4.989072581132253

Epoch: 5| Step: 5
Training loss: 4.277209758758545
Validation loss: 4.980801701545715

Epoch: 5| Step: 6
Training loss: 4.110246181488037
Validation loss: 4.972871661186218

Epoch: 5| Step: 7
Training loss: 4.8505353927612305
Validation loss: 4.964407801628113

Epoch: 5| Step: 8
Training loss: 5.693183422088623
Validation loss: 4.9562310973803205

Epoch: 5| Step: 9
Training loss: 5.903657913208008
Validation loss: 4.9476423263549805

Epoch: 5| Step: 10
Training loss: 4.860711574554443
Validation loss: 4.9391321539878845

Epoch: 5| Step: 11
Training loss: 5.465612888336182
Validation loss: 4.930557529131572

Epoch: 8| Step: 0
Training loss: 5.3542256355285645
Validation loss: 4.922355194886525

Epoch: 5| Step: 1
Training loss: 6.439493656158447
Validation loss: 4.913846949736278

Epoch: 5| Step: 2
Training loss: 4.222691535949707
Validation loss: 4.905946413675944

Epoch: 5| Step: 3
Training loss: 4.727007865905762
Validation loss: 4.897959729035695

Epoch: 5| Step: 4
Training loss: 4.84543514251709
Validation loss: 4.890055358409882

Epoch: 5| Step: 5
Training loss: 3.642587184906006
Validation loss: 4.881756802399953

Epoch: 5| Step: 6
Training loss: 4.918511390686035
Validation loss: 4.872745831807454

Epoch: 5| Step: 7
Training loss: 4.982479095458984
Validation loss: 4.86445568005244

Epoch: 5| Step: 8
Training loss: 4.470653057098389
Validation loss: 4.855523347854614

Epoch: 5| Step: 9
Training loss: 5.799327373504639
Validation loss: 4.845648030440013

Epoch: 5| Step: 10
Training loss: 5.034941673278809
Validation loss: 4.836391866207123

Epoch: 5| Step: 11
Training loss: 5.901275634765625
Validation loss: 4.826897154251735

Epoch: 9| Step: 0
Training loss: 5.228170871734619
Validation loss: 4.818021853764852

Epoch: 5| Step: 1
Training loss: 4.717972755432129
Validation loss: 4.808901687463124

Epoch: 5| Step: 2
Training loss: 4.417281150817871
Validation loss: 4.799469868342082

Epoch: 5| Step: 3
Training loss: 5.206473350524902
Validation loss: 4.79153107603391

Epoch: 5| Step: 4
Training loss: 4.516475677490234
Validation loss: 4.782438268264134

Epoch: 5| Step: 5
Training loss: 4.922149658203125
Validation loss: 4.773679137229919

Epoch: 5| Step: 6
Training loss: 3.8479390144348145
Validation loss: 4.765159060557683

Epoch: 5| Step: 7
Training loss: 5.491093635559082
Validation loss: 4.756776829560597

Epoch: 5| Step: 8
Training loss: 5.636990070343018
Validation loss: 4.747711102167766

Epoch: 5| Step: 9
Training loss: 3.751588821411133
Validation loss: 4.739428162574768

Epoch: 5| Step: 10
Training loss: 5.683699131011963
Validation loss: 4.7305519580841064

Epoch: 5| Step: 11
Training loss: 5.226600170135498
Validation loss: 4.72264176607132

Epoch: 10| Step: 0
Training loss: 4.768795013427734
Validation loss: 4.713981072107951

Epoch: 5| Step: 1
Training loss: 4.777332305908203
Validation loss: 4.705835193395615

Epoch: 5| Step: 2
Training loss: 4.605568885803223
Validation loss: 4.698169608910878

Epoch: 5| Step: 3
Training loss: 5.442629814147949
Validation loss: 4.690712809562683

Epoch: 5| Step: 4
Training loss: 4.8788676261901855
Validation loss: 4.683188438415527

Epoch: 5| Step: 5
Training loss: 4.084324836730957
Validation loss: 4.675662328799565

Epoch: 5| Step: 6
Training loss: 5.156981468200684
Validation loss: 4.667745778958003

Epoch: 5| Step: 7
Training loss: 4.823973178863525
Validation loss: 4.660298784573873

Epoch: 5| Step: 8
Training loss: 5.495619297027588
Validation loss: 4.6533024708429975

Epoch: 5| Step: 9
Training loss: 3.8795390129089355
Validation loss: 4.645671943823497

Epoch: 5| Step: 10
Training loss: 4.1666741371154785
Validation loss: 4.638084361950557

Epoch: 5| Step: 11
Training loss: 6.695083141326904
Validation loss: 4.63117794195811

Epoch: 11| Step: 0
Training loss: 5.046722412109375
Validation loss: 4.6238415241241455

Epoch: 5| Step: 1
Training loss: 3.9273152351379395
Validation loss: 4.6164498925209045

Epoch: 5| Step: 2
Training loss: 5.056063652038574
Validation loss: 4.6092488169670105

Epoch: 5| Step: 3
Training loss: 4.783315181732178
Validation loss: 4.602025707562764

Epoch: 5| Step: 4
Training loss: 4.700991630554199
Validation loss: 4.59464031457901

Epoch: 5| Step: 5
Training loss: 3.72135591506958
Validation loss: 4.587371667226155

Epoch: 5| Step: 6
Training loss: 5.213602066040039
Validation loss: 4.58096628387769

Epoch: 5| Step: 7
Training loss: 3.7669506072998047
Validation loss: 4.573274930318196

Epoch: 5| Step: 8
Training loss: 4.842393398284912
Validation loss: 4.5659540096918745

Epoch: 5| Step: 9
Training loss: 4.48434591293335
Validation loss: 4.559102535247803

Epoch: 5| Step: 10
Training loss: 6.1112847328186035
Validation loss: 4.552630424499512

Epoch: 5| Step: 11
Training loss: 4.2251081466674805
Validation loss: 4.545279661814372

Epoch: 12| Step: 0
Training loss: 3.7663216590881348
Validation loss: 4.537970741589864

Epoch: 5| Step: 1
Training loss: 4.2018232345581055
Validation loss: 4.532205879688263

Epoch: 5| Step: 2
Training loss: 4.358591079711914
Validation loss: 4.5252470175425215

Epoch: 5| Step: 3
Training loss: 4.717474460601807
Validation loss: 4.5184370676676435

Epoch: 5| Step: 4
Training loss: 4.242035865783691
Validation loss: 4.511232554912567

Epoch: 5| Step: 5
Training loss: 4.767061710357666
Validation loss: 4.50517092148463

Epoch: 5| Step: 6
Training loss: 5.032402515411377
Validation loss: 4.497812330722809

Epoch: 5| Step: 7
Training loss: 5.3034467697143555
Validation loss: 4.490878274043401

Epoch: 5| Step: 8
Training loss: 4.073418617248535
Validation loss: 4.483303507169087

Epoch: 5| Step: 9
Training loss: 5.222296714782715
Validation loss: 4.475565433502197

Epoch: 5| Step: 10
Training loss: 4.875150203704834
Validation loss: 4.468037744363149

Epoch: 5| Step: 11
Training loss: 5.29532527923584
Validation loss: 4.46128785610199

Epoch: 13| Step: 0
Training loss: 4.505186557769775
Validation loss: 4.453521112600963

Epoch: 5| Step: 1
Training loss: 5.726568222045898
Validation loss: 4.447054326534271

Epoch: 5| Step: 2
Training loss: 4.412667274475098
Validation loss: 4.439752519130707

Epoch: 5| Step: 3
Training loss: 3.776430130004883
Validation loss: 4.432873070240021

Epoch: 5| Step: 4
Training loss: 4.046401023864746
Validation loss: 4.426212787628174

Epoch: 5| Step: 5
Training loss: 4.989563941955566
Validation loss: 4.4197045763333636

Epoch: 5| Step: 6
Training loss: 4.830132961273193
Validation loss: 4.413064201672872

Epoch: 5| Step: 7
Training loss: 5.282164573669434
Validation loss: 4.406824817260106

Epoch: 5| Step: 8
Training loss: 4.348361968994141
Validation loss: 4.400267114241918

Epoch: 5| Step: 9
Training loss: 4.218430995941162
Validation loss: 4.394330620765686

Epoch: 5| Step: 10
Training loss: 3.8459668159484863
Validation loss: 4.388785223166148

Epoch: 5| Step: 11
Training loss: 4.003262519836426
Validation loss: 4.382357398668925

Epoch: 14| Step: 0
Training loss: 4.1009202003479
Validation loss: 4.376806437969208

Epoch: 5| Step: 1
Training loss: 5.553994178771973
Validation loss: 4.3703950842221575

Epoch: 5| Step: 2
Training loss: 4.2030510902404785
Validation loss: 4.36497167746226

Epoch: 5| Step: 3
Training loss: 4.976654052734375
Validation loss: 4.359694381554921

Epoch: 5| Step: 4
Training loss: 4.508773326873779
Validation loss: 4.35396009683609

Epoch: 5| Step: 5
Training loss: 3.7658538818359375
Validation loss: 4.34827317794164

Epoch: 5| Step: 6
Training loss: 3.934401273727417
Validation loss: 4.342857887347539

Epoch: 5| Step: 7
Training loss: 4.558396816253662
Validation loss: 4.337482810020447

Epoch: 5| Step: 8
Training loss: 5.072073459625244
Validation loss: 4.332376271486282

Epoch: 5| Step: 9
Training loss: 4.917781829833984
Validation loss: 4.326875567436218

Epoch: 5| Step: 10
Training loss: 3.662071943283081
Validation loss: 4.321802139282227

Epoch: 5| Step: 11
Training loss: 3.9690957069396973
Validation loss: 4.316431184609731

Epoch: 15| Step: 0
Training loss: 5.190026760101318
Validation loss: 4.311167538166046

Epoch: 5| Step: 1
Training loss: 4.494767189025879
Validation loss: 4.306351641813914

Epoch: 5| Step: 2
Training loss: 3.976168394088745
Validation loss: 4.300639271736145

Epoch: 5| Step: 3
Training loss: 4.227002143859863
Validation loss: 4.29473078250885

Epoch: 5| Step: 4
Training loss: 4.486019611358643
Validation loss: 4.29008009036382

Epoch: 5| Step: 5
Training loss: 4.900213718414307
Validation loss: 4.284868955612183

Epoch: 5| Step: 6
Training loss: 4.083165168762207
Validation loss: 4.278823812802632

Epoch: 5| Step: 7
Training loss: 4.85161018371582
Validation loss: 4.2741891741752625

Epoch: 5| Step: 8
Training loss: 3.869823455810547
Validation loss: 4.268688132365544

Epoch: 5| Step: 9
Training loss: 4.6088056564331055
Validation loss: 4.264189461867015

Epoch: 5| Step: 10
Training loss: 3.710491180419922
Validation loss: 4.258705814679463

Epoch: 5| Step: 11
Training loss: 5.002857685089111
Validation loss: 4.253508885701497

Epoch: 16| Step: 0
Training loss: 4.196743011474609
Validation loss: 4.246967097123464

Epoch: 5| Step: 1
Training loss: 3.8908493518829346
Validation loss: 4.241761376460393

Epoch: 5| Step: 2
Training loss: 4.293857574462891
Validation loss: 4.237408310174942

Epoch: 5| Step: 3
Training loss: 5.280470848083496
Validation loss: 4.23125437895457

Epoch: 5| Step: 4
Training loss: 5.061219692230225
Validation loss: 4.226950079202652

Epoch: 5| Step: 5
Training loss: 4.303529262542725
Validation loss: 4.2209891478220625

Epoch: 5| Step: 6
Training loss: 4.035345554351807
Validation loss: 4.215967069069545

Epoch: 5| Step: 7
Training loss: 4.188965797424316
Validation loss: 4.21025413274765

Epoch: 5| Step: 8
Training loss: 4.863685607910156
Validation loss: 4.205668429533641

Epoch: 5| Step: 9
Training loss: 4.038273811340332
Validation loss: 4.200247079133987

Epoch: 5| Step: 10
Training loss: 3.9143223762512207
Validation loss: 4.19488920768102

Epoch: 5| Step: 11
Training loss: 3.3681983947753906
Validation loss: 4.189932117859523

Epoch: 17| Step: 0
Training loss: 4.313305854797363
Validation loss: 4.1847410798072815

Epoch: 5| Step: 1
Training loss: 4.247540473937988
Validation loss: 4.179273575544357

Epoch: 5| Step: 2
Training loss: 4.08692741394043
Validation loss: 4.174182802438736

Epoch: 5| Step: 3
Training loss: 3.824699878692627
Validation loss: 4.169149150451024

Epoch: 5| Step: 4
Training loss: 4.2855095863342285
Validation loss: 4.163125236829122

Epoch: 5| Step: 5
Training loss: 4.299326419830322
Validation loss: 4.157765785853068

Epoch: 5| Step: 6
Training loss: 5.086108207702637
Validation loss: 4.153844078381856

Epoch: 5| Step: 7
Training loss: 4.868636608123779
Validation loss: 4.149022092421849

Epoch: 5| Step: 8
Training loss: 4.449739933013916
Validation loss: 4.143560081720352

Epoch: 5| Step: 9
Training loss: 3.869434356689453
Validation loss: 4.1392347911993665

Epoch: 5| Step: 10
Training loss: 4.19832706451416
Validation loss: 4.134260912736257

Epoch: 5| Step: 11
Training loss: 2.8572845458984375
Validation loss: 4.128791977961858

Epoch: 18| Step: 0
Training loss: 3.8185439109802246
Validation loss: 4.126146048307419

Epoch: 5| Step: 1
Training loss: 4.614941596984863
Validation loss: 4.12248961130778

Epoch: 5| Step: 2
Training loss: 4.410111904144287
Validation loss: 4.11694739262263

Epoch: 5| Step: 3
Training loss: 4.140973091125488
Validation loss: 4.112325469652812

Epoch: 5| Step: 4
Training loss: 4.732288837432861
Validation loss: 4.107730587323506

Epoch: 5| Step: 5
Training loss: 4.028937339782715
Validation loss: 4.102723956108093

Epoch: 5| Step: 6
Training loss: 4.505221366882324
Validation loss: 4.0982859035332995

Epoch: 5| Step: 7
Training loss: 4.4561262130737305
Validation loss: 4.094055871168773

Epoch: 5| Step: 8
Training loss: 4.139857292175293
Validation loss: 4.089020639657974

Epoch: 5| Step: 9
Training loss: 3.5339534282684326
Validation loss: 4.0827749868234

Epoch: 5| Step: 10
Training loss: 4.572236061096191
Validation loss: 4.077909380197525

Epoch: 5| Step: 11
Training loss: 2.7990894317626953
Validation loss: 4.073367238044739

Epoch: 19| Step: 0
Training loss: 5.532487392425537
Validation loss: 4.069211274385452

Epoch: 5| Step: 1
Training loss: 4.1709089279174805
Validation loss: 4.0650420387585955

Epoch: 5| Step: 2
Training loss: 3.5259926319122314
Validation loss: 4.059397170941035

Epoch: 5| Step: 3
Training loss: 4.284567356109619
Validation loss: 4.055552810430527

Epoch: 5| Step: 4
Training loss: 4.492231845855713
Validation loss: 4.051093886295955

Epoch: 5| Step: 5
Training loss: 3.362194061279297
Validation loss: 4.046397527058919

Epoch: 5| Step: 6
Training loss: 4.273207664489746
Validation loss: 4.041815867026647

Epoch: 5| Step: 7
Training loss: 3.7153892517089844
Validation loss: 4.037558565537135

Epoch: 5| Step: 8
Training loss: 4.372840404510498
Validation loss: 4.033365935087204

Epoch: 5| Step: 9
Training loss: 4.8819146156311035
Validation loss: 4.028303941090901

Epoch: 5| Step: 10
Training loss: 3.897510051727295
Validation loss: 4.023265888293584

Epoch: 5| Step: 11
Training loss: 2.026946544647217
Validation loss: 4.018667836983998

Epoch: 20| Step: 0
Training loss: 4.803005218505859
Validation loss: 4.0160435537497206

Epoch: 5| Step: 1
Training loss: 4.521398544311523
Validation loss: 4.009131799141566

Epoch: 5| Step: 2
Training loss: 3.9964165687561035
Validation loss: 4.006034811337789

Epoch: 5| Step: 3
Training loss: 3.868256092071533
Validation loss: 4.0022856295108795

Epoch: 5| Step: 4
Training loss: 3.8754172325134277
Validation loss: 3.996931870778402

Epoch: 5| Step: 5
Training loss: 3.758739948272705
Validation loss: 3.9913170834382377

Epoch: 5| Step: 6
Training loss: 4.026724815368652
Validation loss: 3.986364463965098

Epoch: 5| Step: 7
Training loss: 4.2233805656433105
Validation loss: 3.982052822907766

Epoch: 5| Step: 8
Training loss: 4.3126935958862305
Validation loss: 3.977436661720276

Epoch: 5| Step: 9
Training loss: 4.639906883239746
Validation loss: 3.9717509150505066

Epoch: 5| Step: 10
Training loss: 3.652897596359253
Validation loss: 3.96796785791715

Epoch: 5| Step: 11
Training loss: 3.268389940261841
Validation loss: 3.9641216099262238

Epoch: 21| Step: 0
Training loss: 4.124664783477783
Validation loss: 3.9580876926581063

Epoch: 5| Step: 1
Training loss: 5.028525352478027
Validation loss: 3.9529724617799125

Epoch: 5| Step: 2
Training loss: 3.7357964515686035
Validation loss: 3.9493804474671683

Epoch: 5| Step: 3
Training loss: 4.199690818786621
Validation loss: 3.9442342817783356

Epoch: 5| Step: 4
Training loss: 4.243102073669434
Validation loss: 3.9402387936909995

Epoch: 5| Step: 5
Training loss: 3.998319149017334
Validation loss: 3.9355500439802804

Epoch: 5| Step: 6
Training loss: 3.426886796951294
Validation loss: 3.9306110739707947

Epoch: 5| Step: 7
Training loss: 4.12567663192749
Validation loss: 3.9265579183896384

Epoch: 5| Step: 8
Training loss: 4.2341766357421875
Validation loss: 3.921157091856003

Epoch: 5| Step: 9
Training loss: 3.6303627490997314
Validation loss: 3.9160617291927338

Epoch: 5| Step: 10
Training loss: 3.8730201721191406
Validation loss: 3.9117036759853363

Epoch: 5| Step: 11
Training loss: 5.5247297286987305
Validation loss: 3.907527635494868

Epoch: 22| Step: 0
Training loss: 3.847059965133667
Validation loss: 3.9034917751948037

Epoch: 5| Step: 1
Training loss: 3.50097393989563
Validation loss: 3.8991484542687735

Epoch: 5| Step: 2
Training loss: 3.5198655128479004
Validation loss: 3.894892474015554

Epoch: 5| Step: 3
Training loss: 3.7786002159118652
Validation loss: 3.8900289634863534

Epoch: 5| Step: 4
Training loss: 3.7652671337127686
Validation loss: 3.885438541571299

Epoch: 5| Step: 5
Training loss: 3.9839751720428467
Validation loss: 3.8814537723859153

Epoch: 5| Step: 6
Training loss: 4.622008323669434
Validation loss: 3.87776509920756

Epoch: 5| Step: 7
Training loss: 5.533766746520996
Validation loss: 3.8734776775042215

Epoch: 5| Step: 8
Training loss: 4.216098785400391
Validation loss: 3.8684499661127725

Epoch: 5| Step: 9
Training loss: 3.7159245014190674
Validation loss: 3.863829185565313

Epoch: 5| Step: 10
Training loss: 4.050947189331055
Validation loss: 3.8595881958802543

Epoch: 5| Step: 11
Training loss: 3.0399913787841797
Validation loss: 3.8550303876399994

Epoch: 23| Step: 0
Training loss: 3.3049755096435547
Validation loss: 3.8501123587290444

Epoch: 5| Step: 1
Training loss: 3.825894594192505
Validation loss: 3.8465698957443237

Epoch: 5| Step: 2
Training loss: 4.257733345031738
Validation loss: 3.842521289984385

Epoch: 5| Step: 3
Training loss: 4.3434834480285645
Validation loss: 3.8371787865956626

Epoch: 5| Step: 4
Training loss: 3.506465196609497
Validation loss: 3.8325650493303933

Epoch: 5| Step: 5
Training loss: 3.806596040725708
Validation loss: 3.8287603755791983

Epoch: 5| Step: 6
Training loss: 4.654080390930176
Validation loss: 3.8243776063124337

Epoch: 5| Step: 7
Training loss: 4.592225551605225
Validation loss: 3.820139527320862

Epoch: 5| Step: 8
Training loss: 3.4089653491973877
Validation loss: 3.8148262898127236

Epoch: 5| Step: 9
Training loss: 3.9692370891571045
Validation loss: 3.8106633126735687

Epoch: 5| Step: 10
Training loss: 4.172116279602051
Validation loss: 3.8064607679843903

Epoch: 5| Step: 11
Training loss: 3.7163033485412598
Validation loss: 3.802751839160919

Epoch: 24| Step: 0
Training loss: 3.3896262645721436
Validation loss: 3.798439840475718

Epoch: 5| Step: 1
Training loss: 3.6744232177734375
Validation loss: 3.79373765985171

Epoch: 5| Step: 2
Training loss: 4.103244781494141
Validation loss: 3.7890465557575226

Epoch: 5| Step: 3
Training loss: 3.938812732696533
Validation loss: 3.7850130001703897

Epoch: 5| Step: 4
Training loss: 4.940816879272461
Validation loss: 3.780694375435511

Epoch: 5| Step: 5
Training loss: 3.6420083045959473
Validation loss: 3.77692840496699

Epoch: 5| Step: 6
Training loss: 3.874988079071045
Validation loss: 3.7731864949067435

Epoch: 5| Step: 7
Training loss: 3.6195054054260254
Validation loss: 3.7695409059524536

Epoch: 5| Step: 8
Training loss: 3.820241928100586
Validation loss: 3.7652006844679513

Epoch: 5| Step: 9
Training loss: 4.173750877380371
Validation loss: 3.7604877750078836

Epoch: 5| Step: 10
Training loss: 3.97442364692688
Validation loss: 3.7559756537278495

Epoch: 5| Step: 11
Training loss: 4.494879722595215
Validation loss: 3.7510788341363273

Epoch: 25| Step: 0
Training loss: 3.8560073375701904
Validation loss: 3.7463510731856027

Epoch: 5| Step: 1
Training loss: 4.292136192321777
Validation loss: 3.7422568102677665

Epoch: 5| Step: 2
Training loss: 3.8948447704315186
Validation loss: 3.7371878226598105

Epoch: 5| Step: 3
Training loss: 3.4800612926483154
Validation loss: 3.7328918476899466

Epoch: 5| Step: 4
Training loss: 4.5892510414123535
Validation loss: 3.728792200485865

Epoch: 5| Step: 5
Training loss: 4.173243522644043
Validation loss: 3.724377195040385

Epoch: 5| Step: 6
Training loss: 3.2975516319274902
Validation loss: 3.7197595040003457

Epoch: 5| Step: 7
Training loss: 3.9051055908203125
Validation loss: 3.7164769172668457

Epoch: 5| Step: 8
Training loss: 3.21288800239563
Validation loss: 3.71153861284256

Epoch: 5| Step: 9
Training loss: 3.852123975753784
Validation loss: 3.7078216671943665

Epoch: 5| Step: 10
Training loss: 4.326026439666748
Validation loss: 3.7038432955741882

Epoch: 5| Step: 11
Training loss: 3.173668146133423
Validation loss: 3.6994431614875793

Epoch: 26| Step: 0
Training loss: 4.844239234924316
Validation loss: 3.6953336695830026

Epoch: 5| Step: 1
Training loss: 4.160131931304932
Validation loss: 3.6923746864000955

Epoch: 5| Step: 2
Training loss: 4.31832218170166
Validation loss: 3.687033236026764

Epoch: 5| Step: 3
Training loss: 3.8912410736083984
Validation loss: 3.682545026143392

Epoch: 5| Step: 4
Training loss: 3.570070266723633
Validation loss: 3.6790744960308075

Epoch: 5| Step: 5
Training loss: 3.2553017139434814
Validation loss: 3.674846182266871

Epoch: 5| Step: 6
Training loss: 3.5122299194335938
Validation loss: 3.671579678853353

Epoch: 5| Step: 7
Training loss: 2.958857536315918
Validation loss: 3.6671072244644165

Epoch: 5| Step: 8
Training loss: 4.84324312210083
Validation loss: 3.6628403663635254

Epoch: 5| Step: 9
Training loss: 3.7521350383758545
Validation loss: 3.658225357532501

Epoch: 5| Step: 10
Training loss: 3.302849292755127
Validation loss: 3.6542378266652427

Epoch: 5| Step: 11
Training loss: 2.8084311485290527
Validation loss: 3.6501603523890176

Epoch: 27| Step: 0
Training loss: 3.992263078689575
Validation loss: 3.64580046137174

Epoch: 5| Step: 1
Training loss: 4.691882133483887
Validation loss: 3.6415324012438455

Epoch: 5| Step: 2
Training loss: 3.509204387664795
Validation loss: 3.637066731850306

Epoch: 5| Step: 3
Training loss: 4.121886253356934
Validation loss: 3.6325576404730477

Epoch: 5| Step: 4
Training loss: 3.6658661365509033
Validation loss: 3.6280526717503867

Epoch: 5| Step: 5
Training loss: 2.7680771350860596
Validation loss: 3.623682131369909

Epoch: 5| Step: 6
Training loss: 3.8098034858703613
Validation loss: 3.619172523419062

Epoch: 5| Step: 7
Training loss: 3.7021172046661377
Validation loss: 3.6152906020482383

Epoch: 5| Step: 8
Training loss: 3.6678695678710938
Validation loss: 3.6114263037840524

Epoch: 5| Step: 9
Training loss: 4.143802165985107
Validation loss: 3.6065373619397483

Epoch: 5| Step: 10
Training loss: 3.3941216468811035
Validation loss: 3.601824273665746

Epoch: 5| Step: 11
Training loss: 4.674920082092285
Validation loss: 3.597398261229197

Epoch: 28| Step: 0
Training loss: 2.8834667205810547
Validation loss: 3.5935639838377633

Epoch: 5| Step: 1
Training loss: 3.3388755321502686
Validation loss: 3.5895362198352814

Epoch: 5| Step: 2
Training loss: 4.126941680908203
Validation loss: 3.5849336683750153

Epoch: 5| Step: 3
Training loss: 4.014423370361328
Validation loss: 3.5807393292586007

Epoch: 5| Step: 4
Training loss: 3.81645131111145
Validation loss: 3.5761356155077615

Epoch: 5| Step: 5
Training loss: 4.064394474029541
Validation loss: 3.5717564622561135

Epoch: 5| Step: 6
Training loss: 3.6449458599090576
Validation loss: 3.567070792118708

Epoch: 5| Step: 7
Training loss: 3.245262622833252
Validation loss: 3.5636328856150308

Epoch: 5| Step: 8
Training loss: 3.7881202697753906
Validation loss: 3.559283971786499

Epoch: 5| Step: 9
Training loss: 3.8602917194366455
Validation loss: 3.5543924967447915

Epoch: 5| Step: 10
Training loss: 4.327569484710693
Validation loss: 3.5499934951464334

Epoch: 5| Step: 11
Training loss: 3.6700778007507324
Validation loss: 3.546011298894882

Epoch: 29| Step: 0
Training loss: 3.119833469390869
Validation loss: 3.5424708922704062

Epoch: 5| Step: 1
Training loss: 3.6533455848693848
Validation loss: 3.5384380916754403

Epoch: 5| Step: 2
Training loss: 3.3244826793670654
Validation loss: 3.533064881960551

Epoch: 5| Step: 3
Training loss: 3.6845569610595703
Validation loss: 3.528759072224299

Epoch: 5| Step: 4
Training loss: 3.5832958221435547
Validation loss: 3.524560441573461

Epoch: 5| Step: 5
Training loss: 3.103966236114502
Validation loss: 3.5205392241477966

Epoch: 5| Step: 6
Training loss: 4.1533942222595215
Validation loss: 3.516384412844976

Epoch: 5| Step: 7
Training loss: 4.502932548522949
Validation loss: 3.5117339293162027

Epoch: 5| Step: 8
Training loss: 3.6939163208007812
Validation loss: 3.5071267088254294

Epoch: 5| Step: 9
Training loss: 4.1327223777771
Validation loss: 3.5034194588661194

Epoch: 5| Step: 10
Training loss: 3.507272243499756
Validation loss: 3.5006031890710196

Epoch: 5| Step: 11
Training loss: 4.122313022613525
Validation loss: 3.49653826157252

Epoch: 30| Step: 0
Training loss: 4.031785488128662
Validation loss: 3.4919879337151847

Epoch: 5| Step: 1
Training loss: 3.4381701946258545
Validation loss: 3.486369331677755

Epoch: 5| Step: 2
Training loss: 3.0320358276367188
Validation loss: 3.4807891150315604

Epoch: 5| Step: 3
Training loss: 4.5013275146484375
Validation loss: 3.4768565793832145

Epoch: 5| Step: 4
Training loss: 4.023104667663574
Validation loss: 3.472357382376989

Epoch: 5| Step: 5
Training loss: 2.793282985687256
Validation loss: 3.4672434826691947

Epoch: 5| Step: 6
Training loss: 3.9894204139709473
Validation loss: 3.4637312491734824

Epoch: 5| Step: 7
Training loss: 4.060666084289551
Validation loss: 3.45952171087265

Epoch: 5| Step: 8
Training loss: 3.4307150840759277
Validation loss: 3.45620987812678

Epoch: 5| Step: 9
Training loss: 3.357034206390381
Validation loss: 3.4513486127058663

Epoch: 5| Step: 10
Training loss: 3.3920741081237793
Validation loss: 3.446821560462316

Epoch: 5| Step: 11
Training loss: 3.3207430839538574
Validation loss: 3.4409450391928353

Epoch: 31| Step: 0
Training loss: 3.7852821350097656
Validation loss: 3.4365018010139465

Epoch: 5| Step: 1
Training loss: 3.7658157348632812
Validation loss: 3.4316023886203766

Epoch: 5| Step: 2
Training loss: 3.464157819747925
Validation loss: 3.427381694316864

Epoch: 5| Step: 3
Training loss: 3.455104112625122
Validation loss: 3.4226001501083374

Epoch: 5| Step: 4
Training loss: 3.6500110626220703
Validation loss: 3.4178059498469033

Epoch: 5| Step: 5
Training loss: 3.7310898303985596
Validation loss: 3.413118769725164

Epoch: 5| Step: 6
Training loss: 3.946007251739502
Validation loss: 3.408360113700231

Epoch: 5| Step: 7
Training loss: 3.806809902191162
Validation loss: 3.4035694698492684

Epoch: 5| Step: 8
Training loss: 3.2766242027282715
Validation loss: 3.3985040883223214

Epoch: 5| Step: 9
Training loss: 3.139334201812744
Validation loss: 3.393962860107422

Epoch: 5| Step: 10
Training loss: 3.2801711559295654
Validation loss: 3.3896693289279938

Epoch: 5| Step: 11
Training loss: 4.071525573730469
Validation loss: 3.3858193357785544

Epoch: 32| Step: 0
Training loss: 3.1452813148498535
Validation loss: 3.380899171034495

Epoch: 5| Step: 1
Training loss: 3.896510362625122
Validation loss: 3.376499662796656

Epoch: 5| Step: 2
Training loss: 3.407825469970703
Validation loss: 3.372835079828898

Epoch: 5| Step: 3
Training loss: 3.04960298538208
Validation loss: 3.367895801862081

Epoch: 5| Step: 4
Training loss: 4.172482967376709
Validation loss: 3.363724331061045

Epoch: 5| Step: 5
Training loss: 3.827658176422119
Validation loss: 3.3592057128747306

Epoch: 5| Step: 6
Training loss: 3.3060524463653564
Validation loss: 3.3556141555309296

Epoch: 5| Step: 7
Training loss: 3.381103515625
Validation loss: 3.350576102733612

Epoch: 5| Step: 8
Training loss: 4.2451653480529785
Validation loss: 3.3465751012166343

Epoch: 5| Step: 9
Training loss: 3.3168716430664062
Validation loss: 3.34254198273023

Epoch: 5| Step: 10
Training loss: 3.1435961723327637
Validation loss: 3.3380344013373056

Epoch: 5| Step: 11
Training loss: 3.1196939945220947
Validation loss: 3.333186089992523

Epoch: 33| Step: 0
Training loss: 3.3666205406188965
Validation loss: 3.3289075593153634

Epoch: 5| Step: 1
Training loss: 3.3242239952087402
Validation loss: 3.3253357311089835

Epoch: 5| Step: 2
Training loss: 4.18037748336792
Validation loss: 3.320856104294459

Epoch: 5| Step: 3
Training loss: 3.454789638519287
Validation loss: 3.3163467744986215

Epoch: 5| Step: 4
Training loss: 3.917264461517334
Validation loss: 3.3119923174381256

Epoch: 5| Step: 5
Training loss: 3.2751121520996094
Validation loss: 3.3078764379024506

Epoch: 5| Step: 6
Training loss: 3.214224338531494
Validation loss: 3.3024878402551017

Epoch: 5| Step: 7
Training loss: 3.1883702278137207
Validation loss: 3.298911472161611

Epoch: 5| Step: 8
Training loss: 3.452636241912842
Validation loss: 3.2944620152314505

Epoch: 5| Step: 9
Training loss: 3.236600875854492
Validation loss: 3.2903083165486655

Epoch: 5| Step: 10
Training loss: 3.537038803100586
Validation loss: 3.286335905392965

Epoch: 5| Step: 11
Training loss: 4.320008277893066
Validation loss: 3.282979587713877

Epoch: 34| Step: 0
Training loss: 2.5320472717285156
Validation loss: 3.2784678041934967

Epoch: 5| Step: 1
Training loss: 3.7638258934020996
Validation loss: 3.274704953034719

Epoch: 5| Step: 2
Training loss: 3.2192604541778564
Validation loss: 3.271275520324707

Epoch: 5| Step: 3
Training loss: 3.9945290088653564
Validation loss: 3.2672215700149536

Epoch: 5| Step: 4
Training loss: 4.294287204742432
Validation loss: 3.2630410492420197

Epoch: 5| Step: 5
Training loss: 3.4147586822509766
Validation loss: 3.259160339832306

Epoch: 5| Step: 6
Training loss: 3.314455032348633
Validation loss: 3.2555894454320273

Epoch: 5| Step: 7
Training loss: 3.219841718673706
Validation loss: 3.2511348327000937

Epoch: 5| Step: 8
Training loss: 3.7303531169891357
Validation loss: 3.2471337417761483

Epoch: 5| Step: 9
Training loss: 3.290698289871216
Validation loss: 3.243352860212326

Epoch: 5| Step: 10
Training loss: 3.132686138153076
Validation loss: 3.239024023214976

Epoch: 5| Step: 11
Training loss: 2.8759543895721436
Validation loss: 3.2362146178881326

Epoch: 35| Step: 0
Training loss: 3.549912691116333
Validation loss: 3.232365479071935

Epoch: 5| Step: 1
Training loss: 3.2407937049865723
Validation loss: 3.229461411635081

Epoch: 5| Step: 2
Training loss: 2.701540231704712
Validation loss: 3.223688393831253

Epoch: 5| Step: 3
Training loss: 4.132031440734863
Validation loss: 3.2200357417265573

Epoch: 5| Step: 4
Training loss: 3.188842296600342
Validation loss: 3.216322104136149

Epoch: 5| Step: 5
Training loss: 3.504784345626831
Validation loss: 3.215047170718511

Epoch: 5| Step: 6
Training loss: 3.0834426879882812
Validation loss: 3.2103756864865622

Epoch: 5| Step: 7
Training loss: 3.108703374862671
Validation loss: 3.205098291238149

Epoch: 5| Step: 8
Training loss: 3.4759204387664795
Validation loss: 3.201390415430069

Epoch: 5| Step: 9
Training loss: 3.642655849456787
Validation loss: 3.1985207994778952

Epoch: 5| Step: 10
Training loss: 3.4893107414245605
Validation loss: 3.1954364279905954

Epoch: 5| Step: 11
Training loss: 4.439582824707031
Validation loss: 3.1922118961811066

Epoch: 36| Step: 0
Training loss: 3.1366991996765137
Validation loss: 3.187591811021169

Epoch: 5| Step: 1
Training loss: 4.108386039733887
Validation loss: 3.1827017068862915

Epoch: 5| Step: 2
Training loss: 3.392122983932495
Validation loss: 3.1778387327988944

Epoch: 5| Step: 3
Training loss: 3.6109414100646973
Validation loss: 3.173638790845871

Epoch: 5| Step: 4
Training loss: 4.156597137451172
Validation loss: 3.16976265112559

Epoch: 5| Step: 5
Training loss: 2.5864341259002686
Validation loss: 3.165401875972748

Epoch: 5| Step: 6
Training loss: 3.335653305053711
Validation loss: 3.16190313299497

Epoch: 5| Step: 7
Training loss: 3.5776455402374268
Validation loss: 3.1579189896583557

Epoch: 5| Step: 8
Training loss: 3.5129592418670654
Validation loss: 3.1530273656050363

Epoch: 5| Step: 9
Training loss: 2.4543309211730957
Validation loss: 3.1491507291793823

Epoch: 5| Step: 10
Training loss: 2.689847707748413
Validation loss: 3.145779768625895

Epoch: 5| Step: 11
Training loss: 4.884099006652832
Validation loss: 3.142339994510015

Epoch: 37| Step: 0
Training loss: 3.3838741779327393
Validation loss: 3.138401875893275

Epoch: 5| Step: 1
Training loss: 3.289531707763672
Validation loss: 3.134762982527415

Epoch: 5| Step: 2
Training loss: 2.4138011932373047
Validation loss: 3.130686789751053

Epoch: 5| Step: 3
Training loss: 3.2053608894348145
Validation loss: 3.126824597517649

Epoch: 5| Step: 4
Training loss: 3.0591864585876465
Validation loss: 3.1234850883483887

Epoch: 5| Step: 5
Training loss: 3.16581392288208
Validation loss: 3.1196442544460297

Epoch: 5| Step: 6
Training loss: 4.509478569030762
Validation loss: 3.115890920162201

Epoch: 5| Step: 7
Training loss: 3.219554901123047
Validation loss: 3.1116480926672616

Epoch: 5| Step: 8
Training loss: 4.05853796005249
Validation loss: 3.107491413752238

Epoch: 5| Step: 9
Training loss: 3.1872615814208984
Validation loss: 3.103587200244268

Epoch: 5| Step: 10
Training loss: 2.8911263942718506
Validation loss: 3.0996898313363395

Epoch: 5| Step: 11
Training loss: 3.2715392112731934
Validation loss: 3.0960188607374826

Epoch: 38| Step: 0
Training loss: 2.9880754947662354
Validation loss: 3.092474857966105

Epoch: 5| Step: 1
Training loss: 3.3135719299316406
Validation loss: 3.089086870352427

Epoch: 5| Step: 2
Training loss: 3.841825008392334
Validation loss: 3.0855634411176047

Epoch: 5| Step: 3
Training loss: 4.177199363708496
Validation loss: 3.0818224052588143

Epoch: 5| Step: 4
Training loss: 3.058063507080078
Validation loss: 3.078274259964625

Epoch: 5| Step: 5
Training loss: 2.953117847442627
Validation loss: 3.0745400885740914

Epoch: 5| Step: 6
Training loss: 3.532569169998169
Validation loss: 3.0709878404935202

Epoch: 5| Step: 7
Training loss: 2.8120617866516113
Validation loss: 3.0675462086995444

Epoch: 5| Step: 8
Training loss: 3.3306071758270264
Validation loss: 3.063871204853058

Epoch: 5| Step: 9
Training loss: 2.7733490467071533
Validation loss: 3.060428331295649

Epoch: 5| Step: 10
Training loss: 3.1817524433135986
Validation loss: 3.057135760784149

Epoch: 5| Step: 11
Training loss: 3.0673584938049316
Validation loss: 3.05379252632459

Epoch: 39| Step: 0
Training loss: 3.2945587635040283
Validation loss: 3.0497476061185202

Epoch: 5| Step: 1
Training loss: 3.664773941040039
Validation loss: 3.0465288360913596

Epoch: 5| Step: 2
Training loss: 2.7812087535858154
Validation loss: 3.042868753274282

Epoch: 5| Step: 3
Training loss: 3.6315243244171143
Validation loss: 3.0392887691656747

Epoch: 5| Step: 4
Training loss: 3.528715133666992
Validation loss: 3.0358932117621102

Epoch: 5| Step: 5
Training loss: 3.5385901927948
Validation loss: 3.032662570476532

Epoch: 5| Step: 6
Training loss: 2.7467799186706543
Validation loss: 3.029199848572413

Epoch: 5| Step: 7
Training loss: 3.2033677101135254
Validation loss: 3.0258680979410806

Epoch: 5| Step: 8
Training loss: 3.463923931121826
Validation loss: 3.022429406642914

Epoch: 5| Step: 9
Training loss: 3.3823604583740234
Validation loss: 3.0193647940953574

Epoch: 5| Step: 10
Training loss: 2.4802145957946777
Validation loss: 3.015698105096817

Epoch: 5| Step: 11
Training loss: 1.9254629611968994
Validation loss: 3.012000302473704

Epoch: 40| Step: 0
Training loss: 2.518048048019409
Validation loss: 3.008756101131439

Epoch: 5| Step: 1
Training loss: 3.5268807411193848
Validation loss: 3.0049951871236167

Epoch: 5| Step: 2
Training loss: 3.3149139881134033
Validation loss: 3.001470069090525

Epoch: 5| Step: 3
Training loss: 2.604632616043091
Validation loss: 2.9983616371949515

Epoch: 5| Step: 4
Training loss: 2.992074728012085
Validation loss: 2.9949172039826712

Epoch: 5| Step: 5
Training loss: 2.866450548171997
Validation loss: 2.992101480563482

Epoch: 5| Step: 6
Training loss: 3.920924425125122
Validation loss: 2.988761931657791

Epoch: 5| Step: 7
Training loss: 3.169999837875366
Validation loss: 2.985793521006902

Epoch: 5| Step: 8
Training loss: 3.3664748668670654
Validation loss: 2.9824150105317435

Epoch: 5| Step: 9
Training loss: 3.6974663734436035
Validation loss: 2.9795441726843515

Epoch: 5| Step: 10
Training loss: 2.8533775806427
Validation loss: 2.975302775700887

Epoch: 5| Step: 11
Training loss: 4.234726905822754
Validation loss: 2.9717420041561127

Epoch: 41| Step: 0
Training loss: 3.3095505237579346
Validation loss: 2.9684149026870728

Epoch: 5| Step: 1
Training loss: 3.12797474861145
Validation loss: 2.964950680732727

Epoch: 5| Step: 2
Training loss: 3.5990967750549316
Validation loss: 2.961725433667501

Epoch: 5| Step: 3
Training loss: 3.369983673095703
Validation loss: 2.9585448056459427

Epoch: 5| Step: 4
Training loss: 3.5762104988098145
Validation loss: 2.954079578320185

Epoch: 5| Step: 5
Training loss: 2.513810634613037
Validation loss: 2.9505661527315774

Epoch: 5| Step: 6
Training loss: 2.4491488933563232
Validation loss: 2.947136869033178

Epoch: 5| Step: 7
Training loss: 2.9000613689422607
Validation loss: 2.9433717727661133

Epoch: 5| Step: 8
Training loss: 3.4617276191711426
Validation loss: 2.9399444262186685

Epoch: 5| Step: 9
Training loss: 3.4209301471710205
Validation loss: 2.9370157619317374

Epoch: 5| Step: 10
Training loss: 2.9909796714782715
Validation loss: 2.9342122773329415

Epoch: 5| Step: 11
Training loss: 2.8836991786956787
Validation loss: 2.930869152148565

Epoch: 42| Step: 0
Training loss: 2.9527077674865723
Validation loss: 2.927363167206446

Epoch: 5| Step: 1
Training loss: 2.9508419036865234
Validation loss: 2.9234203894933066

Epoch: 5| Step: 2
Training loss: 3.472029209136963
Validation loss: 2.9190928041934967

Epoch: 5| Step: 3
Training loss: 3.3694374561309814
Validation loss: 2.915588249762853

Epoch: 5| Step: 4
Training loss: 3.9063446521759033
Validation loss: 2.9123267829418182

Epoch: 5| Step: 5
Training loss: 2.8500964641571045
Validation loss: 2.909223258495331

Epoch: 5| Step: 6
Training loss: 3.285273313522339
Validation loss: 2.905121127764384

Epoch: 5| Step: 7
Training loss: 3.113369941711426
Validation loss: 2.901747465133667

Epoch: 5| Step: 8
Training loss: 2.471282720565796
Validation loss: 2.898448000351588

Epoch: 5| Step: 9
Training loss: 2.9845340251922607
Validation loss: 2.894895831743876

Epoch: 5| Step: 10
Training loss: 3.030823230743408
Validation loss: 2.891776144504547

Epoch: 5| Step: 11
Training loss: 2.5700573921203613
Validation loss: 2.8884885013103485

Epoch: 43| Step: 0
Training loss: 3.425266981124878
Validation loss: 2.8852112094561257

Epoch: 5| Step: 1
Training loss: 3.220278263092041
Validation loss: 2.8820737401644387

Epoch: 5| Step: 2
Training loss: 2.391613483428955
Validation loss: 2.879059354464213

Epoch: 5| Step: 3
Training loss: 2.90440034866333
Validation loss: 2.8758796552817025

Epoch: 5| Step: 4
Training loss: 3.6238956451416016
Validation loss: 2.8721629778544107

Epoch: 5| Step: 5
Training loss: 2.3800225257873535
Validation loss: 2.869109441836675

Epoch: 5| Step: 6
Training loss: 3.176151752471924
Validation loss: 2.865701993306478

Epoch: 5| Step: 7
Training loss: 3.345499038696289
Validation loss: 2.862366030613581

Epoch: 5| Step: 8
Training loss: 3.1847023963928223
Validation loss: 2.8592379987239838

Epoch: 5| Step: 9
Training loss: 3.435140609741211
Validation loss: 2.856358597675959

Epoch: 5| Step: 10
Training loss: 2.977496385574341
Validation loss: 2.852802793184916

Epoch: 5| Step: 11
Training loss: 2.1351916790008545
Validation loss: 2.849711815516154

Epoch: 44| Step: 0
Training loss: 3.4745171070098877
Validation loss: 2.846912294626236

Epoch: 5| Step: 1
Training loss: 3.0396900177001953
Validation loss: 2.844706724087397

Epoch: 5| Step: 2
Training loss: 3.457888126373291
Validation loss: 2.8419566651185355

Epoch: 5| Step: 3
Training loss: 2.4719033241271973
Validation loss: 2.839584390322367

Epoch: 5| Step: 4
Training loss: 3.1507277488708496
Validation loss: 2.836179037888845

Epoch: 5| Step: 5
Training loss: 3.2184290885925293
Validation loss: 2.834239969650904

Epoch: 5| Step: 6
Training loss: 2.005227565765381
Validation loss: 2.8301502664883933

Epoch: 5| Step: 7
Training loss: 3.0965733528137207
Validation loss: 2.827681918938955

Epoch: 5| Step: 8
Training loss: 3.6092982292175293
Validation loss: 2.8248983124891915

Epoch: 5| Step: 9
Training loss: 2.928130626678467
Validation loss: 2.821509897708893

Epoch: 5| Step: 10
Training loss: 2.8063368797302246
Validation loss: 2.819923331340154

Epoch: 5| Step: 11
Training loss: 4.24753475189209
Validation loss: 2.817040582497915

Epoch: 45| Step: 0
Training loss: 3.0936119556427
Validation loss: 2.814564754565557

Epoch: 5| Step: 1
Training loss: 2.3604860305786133
Validation loss: 2.810527781645457

Epoch: 5| Step: 2
Training loss: 3.3405983448028564
Validation loss: 2.8071941832701364

Epoch: 5| Step: 3
Training loss: 3.134995222091675
Validation loss: 2.8039392828941345

Epoch: 5| Step: 4
Training loss: 3.1236183643341064
Validation loss: 2.8012757698694863

Epoch: 5| Step: 5
Training loss: 3.0286426544189453
Validation loss: 2.798188934723536

Epoch: 5| Step: 6
Training loss: 3.334545850753784
Validation loss: 2.7952999472618103

Epoch: 5| Step: 7
Training loss: 2.971407413482666
Validation loss: 2.792481283346812

Epoch: 5| Step: 8
Training loss: 2.711245059967041
Validation loss: 2.7889936765034995

Epoch: 5| Step: 9
Training loss: 2.750885486602783
Validation loss: 2.78657399614652

Epoch: 5| Step: 10
Training loss: 2.967796564102173
Validation loss: 2.7827424804369607

Epoch: 5| Step: 11
Training loss: 4.5086140632629395
Validation loss: 2.783242642879486

Epoch: 46| Step: 0
Training loss: 3.369190216064453
Validation loss: 2.7797002693017325

Epoch: 5| Step: 1
Training loss: 3.0490808486938477
Validation loss: 2.7757263779640198

Epoch: 5| Step: 2
Training loss: 3.1947479248046875
Validation loss: 2.7835672795772552

Epoch: 5| Step: 3
Training loss: 3.6652228832244873
Validation loss: 2.780772626399994

Epoch: 5| Step: 4
Training loss: 2.9059653282165527
Validation loss: 2.7663170198599496

Epoch: 5| Step: 5
Training loss: 2.519684314727783
Validation loss: 2.7689605156580606

Epoch: 5| Step: 6
Training loss: 2.1980152130126953
Validation loss: 2.7711077531178794

Epoch: 5| Step: 7
Training loss: 3.1628286838531494
Validation loss: 2.768264333407084

Epoch: 5| Step: 8
Training loss: 2.922558307647705
Validation loss: 2.7586780389149985

Epoch: 5| Step: 9
Training loss: 2.5951743125915527
Validation loss: 2.757909511526426

Epoch: 5| Step: 10
Training loss: 3.1166951656341553
Validation loss: 2.7561262448628745

Epoch: 5| Step: 11
Training loss: 3.420769691467285
Validation loss: 2.7495179971059165

Epoch: 47| Step: 0
Training loss: 2.3858237266540527
Validation loss: 2.7453257044156394

Epoch: 5| Step: 1
Training loss: 3.1367459297180176
Validation loss: 2.7561036348342896

Epoch: 5| Step: 2
Training loss: 2.36246657371521
Validation loss: 2.7453908026218414

Epoch: 5| Step: 3
Training loss: 3.8039703369140625
Validation loss: 2.73721111814181

Epoch: 5| Step: 4
Training loss: 2.799895763397217
Validation loss: 2.7344522774219513

Epoch: 5| Step: 5
Training loss: 2.970438003540039
Validation loss: 2.7303145627180734

Epoch: 5| Step: 6
Training loss: 3.1757559776306152
Validation loss: 2.728013734022776

Epoch: 5| Step: 7
Training loss: 3.255462646484375
Validation loss: 2.7247866888840995

Epoch: 5| Step: 8
Training loss: 2.666274309158325
Validation loss: 2.724255383014679

Epoch: 5| Step: 9
Training loss: 2.974396228790283
Validation loss: 2.721605290969213

Epoch: 5| Step: 10
Training loss: 3.009653091430664
Validation loss: 2.7179251611232758

Epoch: 5| Step: 11
Training loss: 2.1443490982055664
Validation loss: 2.7134861946105957

Epoch: 48| Step: 0
Training loss: 2.6274797916412354
Validation loss: 2.711696227391561

Epoch: 5| Step: 1
Training loss: 2.614015579223633
Validation loss: 2.7087063093980155

Epoch: 5| Step: 2
Training loss: 3.0907142162323
Validation loss: 2.7052820523579917

Epoch: 5| Step: 3
Training loss: 2.43314790725708
Validation loss: 2.703684796889623

Epoch: 5| Step: 4
Training loss: 3.1672463417053223
Validation loss: 2.70032865802447

Epoch: 5| Step: 5
Training loss: 3.5029501914978027
Validation loss: 2.697016716003418

Epoch: 5| Step: 6
Training loss: 2.4249141216278076
Validation loss: 2.693680018186569

Epoch: 5| Step: 7
Training loss: 2.8417556285858154
Validation loss: 2.690487573544184

Epoch: 5| Step: 8
Training loss: 3.4900271892547607
Validation loss: 2.6880788107713065

Epoch: 5| Step: 9
Training loss: 2.929715633392334
Validation loss: 2.6847903629144034

Epoch: 5| Step: 10
Training loss: 2.9587807655334473
Validation loss: 2.6824640035629272

Epoch: 5| Step: 11
Training loss: 2.205197811126709
Validation loss: 2.6796494821707406

Epoch: 49| Step: 0
Training loss: 2.749764919281006
Validation loss: 2.675927152236303

Epoch: 5| Step: 1
Training loss: 3.440650224685669
Validation loss: 2.6722446282704673

Epoch: 5| Step: 2
Training loss: 3.0533764362335205
Validation loss: 2.6694887280464172

Epoch: 5| Step: 3
Training loss: 2.692599296569824
Validation loss: 2.665526737769445

Epoch: 5| Step: 4
Training loss: 2.636052370071411
Validation loss: 2.6614054441452026

Epoch: 5| Step: 5
Training loss: 3.05678129196167
Validation loss: 2.658183534940084

Epoch: 5| Step: 6
Training loss: 2.108203411102295
Validation loss: 2.655727118253708

Epoch: 5| Step: 7
Training loss: 2.465358018875122
Validation loss: 2.651243189970652

Epoch: 5| Step: 8
Training loss: 3.05068302154541
Validation loss: 2.6478152175744376

Epoch: 5| Step: 9
Training loss: 3.202177047729492
Validation loss: 2.644930054744085

Epoch: 5| Step: 10
Training loss: 3.122642993927002
Validation loss: 2.6412776857614517

Epoch: 5| Step: 11
Training loss: 2.51859712600708
Validation loss: 2.639378845691681

Epoch: 50| Step: 0
Training loss: 2.9349007606506348
Validation loss: 2.6365818977355957

Epoch: 5| Step: 1
Training loss: 2.905566453933716
Validation loss: 2.6330007314682007

Epoch: 5| Step: 2
Training loss: 2.6114983558654785
Validation loss: 2.630216956138611

Epoch: 5| Step: 3
Training loss: 2.4699339866638184
Validation loss: 2.6271943946679435

Epoch: 5| Step: 4
Training loss: 2.8694443702697754
Validation loss: 2.6245265901088715

Epoch: 5| Step: 5
Training loss: 2.670335054397583
Validation loss: 2.6208786269028983

Epoch: 5| Step: 6
Training loss: 2.9722213745117188
Validation loss: 2.6188395818074546

Epoch: 5| Step: 7
Training loss: 2.794328451156616
Validation loss: 2.615562935670217

Epoch: 5| Step: 8
Training loss: 2.7645962238311768
Validation loss: 2.6136087775230408

Epoch: 5| Step: 9
Training loss: 3.6787452697753906
Validation loss: 2.610558936993281

Epoch: 5| Step: 10
Training loss: 2.4219088554382324
Validation loss: 2.6078158219655356

Epoch: 5| Step: 11
Training loss: 2.639418840408325
Validation loss: 2.6036173601945243

Epoch: 51| Step: 0
Training loss: 3.1265311241149902
Validation loss: 2.6016401449839273

Epoch: 5| Step: 1
Training loss: 2.706824541091919
Validation loss: 2.5971922477086387

Epoch: 5| Step: 2
Training loss: 3.2649829387664795
Validation loss: 2.594675491253535

Epoch: 5| Step: 3
Training loss: 2.597440242767334
Validation loss: 2.5913858711719513

Epoch: 5| Step: 4
Training loss: 2.4380762577056885
Validation loss: 2.58827772239844

Epoch: 5| Step: 5
Training loss: 3.020864486694336
Validation loss: 2.5845554769039154

Epoch: 5| Step: 6
Training loss: 2.5196046829223633
Validation loss: 2.5826697746912637

Epoch: 5| Step: 7
Training loss: 2.8702774047851562
Validation loss: 2.581364472707113

Epoch: 5| Step: 8
Training loss: 2.7674400806427
Validation loss: 2.5770934224128723

Epoch: 5| Step: 9
Training loss: 2.5769729614257812
Validation loss: 2.575669060150782

Epoch: 5| Step: 10
Training loss: 2.5979607105255127
Validation loss: 2.571922093629837

Epoch: 5| Step: 11
Training loss: 3.768740177154541
Validation loss: 2.5687663604815802

Epoch: 52| Step: 0
Training loss: 2.711000680923462
Validation loss: 2.5678098251422248

Epoch: 5| Step: 1
Training loss: 3.086176633834839
Validation loss: 2.563596566518148

Epoch: 5| Step: 2
Training loss: 2.938549518585205
Validation loss: 2.561771700779597

Epoch: 5| Step: 3
Training loss: 2.5959177017211914
Validation loss: 2.5578589042027793

Epoch: 5| Step: 4
Training loss: 2.903168201446533
Validation loss: 2.5536284198363624

Epoch: 5| Step: 5
Training loss: 2.956406354904175
Validation loss: 2.551254312197367

Epoch: 5| Step: 6
Training loss: 2.3740837574005127
Validation loss: 2.547707825899124

Epoch: 5| Step: 7
Training loss: 3.0084915161132812
Validation loss: 2.5449176530043283

Epoch: 5| Step: 8
Training loss: 2.6556568145751953
Validation loss: 2.54243341088295

Epoch: 5| Step: 9
Training loss: 2.652534008026123
Validation loss: 2.5407159527142844

Epoch: 5| Step: 10
Training loss: 2.366382598876953
Validation loss: 2.537891914447149

Epoch: 5| Step: 11
Training loss: 2.923572063446045
Validation loss: 2.5335178871949515

Epoch: 53| Step: 0
Training loss: 2.6358089447021484
Validation loss: 2.530866175889969

Epoch: 5| Step: 1
Training loss: 2.7545247077941895
Validation loss: 2.529495050509771

Epoch: 5| Step: 2
Training loss: 2.941721200942993
Validation loss: 2.527644390861193

Epoch: 5| Step: 3
Training loss: 3.209127902984619
Validation loss: 2.5256690184275308

Epoch: 5| Step: 4
Training loss: 3.413132429122925
Validation loss: 2.5228978991508484

Epoch: 5| Step: 5
Training loss: 2.7835378646850586
Validation loss: 2.52007387081782

Epoch: 5| Step: 6
Training loss: 2.344226598739624
Validation loss: 2.515208532412847

Epoch: 5| Step: 7
Training loss: 2.3145947456359863
Validation loss: 2.5134763022263846

Epoch: 5| Step: 8
Training loss: 2.707368850708008
Validation loss: 2.512898862361908

Epoch: 5| Step: 9
Training loss: 2.0006625652313232
Validation loss: 2.5067109962304435

Epoch: 5| Step: 10
Training loss: 2.8228719234466553
Validation loss: 2.5013349850972495

Epoch: 5| Step: 11
Training loss: 2.509669303894043
Validation loss: 2.5025261839230857

Epoch: 54| Step: 0
Training loss: 2.389509677886963
Validation loss: 2.4981108009815216

Epoch: 5| Step: 1
Training loss: 3.179363489151001
Validation loss: 2.497778366009394

Epoch: 5| Step: 2
Training loss: 2.215331792831421
Validation loss: 2.4957418739795685

Epoch: 5| Step: 3
Training loss: 2.9639153480529785
Validation loss: 2.494102865457535

Epoch: 5| Step: 4
Training loss: 2.8685548305511475
Validation loss: 2.491002986828486

Epoch: 5| Step: 5
Training loss: 2.0273334980010986
Validation loss: 2.485819180806478

Epoch: 5| Step: 6
Training loss: 2.576603412628174
Validation loss: 2.480955868959427

Epoch: 5| Step: 7
Training loss: 2.537412166595459
Validation loss: 2.476134777069092

Epoch: 5| Step: 8
Training loss: 2.4811127185821533
Validation loss: 2.4728638430436454

Epoch: 5| Step: 9
Training loss: 2.5950844287872314
Validation loss: 2.4699905117352805

Epoch: 5| Step: 10
Training loss: 3.5846285820007324
Validation loss: 2.472437192996343

Epoch: 5| Step: 11
Training loss: 2.9063713550567627
Validation loss: 2.477039416631063

Epoch: 55| Step: 0
Training loss: 3.1268763542175293
Validation loss: 2.4909997979799905

Epoch: 5| Step: 1
Training loss: 2.4929537773132324
Validation loss: 2.500014672676722

Epoch: 5| Step: 2
Training loss: 2.6124424934387207
Validation loss: 2.503220856189728

Epoch: 5| Step: 3
Training loss: 2.587907552719116
Validation loss: 2.490502471725146

Epoch: 5| Step: 4
Training loss: 2.8644556999206543
Validation loss: 2.4852973421414695

Epoch: 5| Step: 5
Training loss: 2.779022693634033
Validation loss: 2.4816797773043313

Epoch: 5| Step: 6
Training loss: 2.9271774291992188
Validation loss: 2.4793466130892434

Epoch: 5| Step: 7
Training loss: 2.7913990020751953
Validation loss: 2.4843790431817374

Epoch: 5| Step: 8
Training loss: 2.436525344848633
Validation loss: 2.4818521440029144

Epoch: 5| Step: 9
Training loss: 2.4196064472198486
Validation loss: 2.480705668528875

Epoch: 5| Step: 10
Training loss: 2.555037021636963
Validation loss: 2.47131155927976

Epoch: 5| Step: 11
Training loss: 2.1106014251708984
Validation loss: 2.4709220031897225

Epoch: 56| Step: 0
Training loss: 2.0629210472106934
Validation loss: 2.4726179242134094

Epoch: 5| Step: 1
Training loss: 2.6954433917999268
Validation loss: 2.477005104223887

Epoch: 5| Step: 2
Training loss: 2.26126766204834
Validation loss: 2.5126608113447824

Epoch: 5| Step: 3
Training loss: 3.3742804527282715
Validation loss: 2.5757225453853607

Epoch: 5| Step: 4
Training loss: 2.462557554244995
Validation loss: 2.5229868292808533

Epoch: 5| Step: 5
Training loss: 2.550078868865967
Validation loss: 2.472452570994695

Epoch: 5| Step: 6
Training loss: 2.575983762741089
Validation loss: 2.4510788122812905

Epoch: 5| Step: 7
Training loss: 2.7450687885284424
Validation loss: 2.4467869102954865

Epoch: 5| Step: 8
Training loss: 2.3669421672821045
Validation loss: 2.446902096271515

Epoch: 5| Step: 9
Training loss: 2.561267375946045
Validation loss: 2.4505256613095603

Epoch: 5| Step: 10
Training loss: 3.5643725395202637
Validation loss: 2.4575219998757043

Epoch: 5| Step: 11
Training loss: 3.3942790031433105
Validation loss: 2.459449807802836

Epoch: 57| Step: 0
Training loss: 2.5991947650909424
Validation loss: 2.470099300146103

Epoch: 5| Step: 1
Training loss: 2.117710590362549
Validation loss: 2.4571744799613953

Epoch: 5| Step: 2
Training loss: 2.9614100456237793
Validation loss: 2.4434619744618735

Epoch: 5| Step: 3
Training loss: 2.800790786743164
Validation loss: 2.439945330222448

Epoch: 5| Step: 4
Training loss: 2.824596405029297
Validation loss: 2.431029294927915

Epoch: 5| Step: 5
Training loss: 3.3089191913604736
Validation loss: 2.427812154094378

Epoch: 5| Step: 6
Training loss: 2.8483970165252686
Validation loss: 2.4336359401543937

Epoch: 5| Step: 7
Training loss: 2.119675397872925
Validation loss: 2.419942239920298

Epoch: 5| Step: 8
Training loss: 2.559706449508667
Validation loss: 2.414037545522054

Epoch: 5| Step: 9
Training loss: 2.425762176513672
Validation loss: 2.4082364439964294

Epoch: 5| Step: 10
Training loss: 2.299729108810425
Validation loss: 2.407723675171534

Epoch: 5| Step: 11
Training loss: 2.195584774017334
Validation loss: 2.402894134322802

Epoch: 58| Step: 0
Training loss: 2.9233078956604004
Validation loss: 2.4031001031398773

Epoch: 5| Step: 1
Training loss: 2.1085684299468994
Validation loss: 2.3980009953180947

Epoch: 5| Step: 2
Training loss: 2.20574951171875
Validation loss: 2.396898706754049

Epoch: 5| Step: 3
Training loss: 2.8634321689605713
Validation loss: 2.3943101118008294

Epoch: 5| Step: 4
Training loss: 2.687713384628296
Validation loss: 2.3915138641993203

Epoch: 5| Step: 5
Training loss: 2.3952269554138184
Validation loss: 2.39223575592041

Epoch: 5| Step: 6
Training loss: 2.5806689262390137
Validation loss: 2.3875199953715005

Epoch: 5| Step: 7
Training loss: 2.446739435195923
Validation loss: 2.3891415198644004

Epoch: 5| Step: 8
Training loss: 2.3557193279266357
Validation loss: 2.3862267235914865

Epoch: 5| Step: 9
Training loss: 3.2237205505371094
Validation loss: 2.3818751126527786

Epoch: 5| Step: 10
Training loss: 2.6527562141418457
Validation loss: 2.37923734386762

Epoch: 5| Step: 11
Training loss: 1.6454830169677734
Validation loss: 2.3727931876977286

Epoch: 59| Step: 0
Training loss: 2.2957985401153564
Validation loss: 2.3720480501651764

Epoch: 5| Step: 1
Training loss: 2.3993139266967773
Validation loss: 2.366481045881907

Epoch: 5| Step: 2
Training loss: 2.309095859527588
Validation loss: 2.3596524049838385

Epoch: 5| Step: 3
Training loss: 2.0547733306884766
Validation loss: 2.3507944544156394

Epoch: 5| Step: 4
Training loss: 2.9030025005340576
Validation loss: 2.3440125385920205

Epoch: 5| Step: 5
Training loss: 2.121257781982422
Validation loss: 2.340948631366094

Epoch: 5| Step: 6
Training loss: 3.0812206268310547
Validation loss: 2.3406352500120797

Epoch: 5| Step: 7
Training loss: 2.679172992706299
Validation loss: 2.336729963620504

Epoch: 5| Step: 8
Training loss: 2.5523579120635986
Validation loss: 2.3330646057923636

Epoch: 5| Step: 9
Training loss: 2.5093607902526855
Validation loss: 2.3304815888404846

Epoch: 5| Step: 10
Training loss: 2.770289659500122
Validation loss: 2.3279573072989783

Epoch: 5| Step: 11
Training loss: 2.644801378250122
Validation loss: 2.328182578086853

Epoch: 60| Step: 0
Training loss: 2.655076503753662
Validation loss: 2.3244748214880624

Epoch: 5| Step: 1
Training loss: 2.6579995155334473
Validation loss: 2.321751127640406

Epoch: 5| Step: 2
Training loss: 2.4309704303741455
Validation loss: 2.322799707452456

Epoch: 5| Step: 3
Training loss: 2.3773179054260254
Validation loss: 2.3206187387307486

Epoch: 5| Step: 4
Training loss: 2.606217861175537
Validation loss: 2.3219329019387565

Epoch: 5| Step: 5
Training loss: 2.44730806350708
Validation loss: 2.3203633626302085

Epoch: 5| Step: 6
Training loss: 2.2520222663879395
Validation loss: 2.3175585170586905

Epoch: 5| Step: 7
Training loss: 2.6227073669433594
Validation loss: 2.310484697421392

Epoch: 5| Step: 8
Training loss: 2.8233933448791504
Validation loss: 2.3115343352158866

Epoch: 5| Step: 9
Training loss: 2.1816565990448
Validation loss: 2.3080315540234246

Epoch: 5| Step: 10
Training loss: 2.2895891666412354
Validation loss: 2.305949846903483

Epoch: 5| Step: 11
Training loss: 2.507617950439453
Validation loss: 2.305310438076655

Epoch: 61| Step: 0
Training loss: 2.755256414413452
Validation loss: 2.3006312052408853

Epoch: 5| Step: 1
Training loss: 3.192786931991577
Validation loss: 2.306519349416097

Epoch: 5| Step: 2
Training loss: 2.5683445930480957
Validation loss: 2.30528391400973

Epoch: 5| Step: 3
Training loss: 2.4120235443115234
Validation loss: 2.3002941807111106

Epoch: 5| Step: 4
Training loss: 2.7188870906829834
Validation loss: 2.300687243541082

Epoch: 5| Step: 5
Training loss: 2.416574478149414
Validation loss: 2.3007454375425973

Epoch: 5| Step: 6
Training loss: 2.0716352462768555
Validation loss: 2.290034164985021

Epoch: 5| Step: 7
Training loss: 2.639443874359131
Validation loss: 2.291919062534968

Epoch: 5| Step: 8
Training loss: 1.6175063848495483
Validation loss: 2.283968756596247

Epoch: 5| Step: 9
Training loss: 2.4661757946014404
Validation loss: 2.2828448116779327

Epoch: 5| Step: 10
Training loss: 2.1303789615631104
Validation loss: 2.278431619207064

Epoch: 5| Step: 11
Training loss: 3.065992593765259
Validation loss: 2.275692621866862

Epoch: 62| Step: 0
Training loss: 2.396944761276245
Validation loss: 2.270962213476499

Epoch: 5| Step: 1
Training loss: 2.3778672218322754
Validation loss: 2.2679487069447837

Epoch: 5| Step: 2
Training loss: 2.133591413497925
Validation loss: 2.272322212656339

Epoch: 5| Step: 3
Training loss: 2.4874188899993896
Validation loss: 2.2647262712319693

Epoch: 5| Step: 4
Training loss: 2.4406981468200684
Validation loss: 2.263403038183848

Epoch: 5| Step: 5
Training loss: 2.669097900390625
Validation loss: 2.260322719812393

Epoch: 5| Step: 6
Training loss: 2.1847734451293945
Validation loss: 2.255381832520167

Epoch: 5| Step: 7
Training loss: 2.3009300231933594
Validation loss: 2.2557950913906097

Epoch: 5| Step: 8
Training loss: 2.6946959495544434
Validation loss: 2.2535626888275146

Epoch: 5| Step: 9
Training loss: 2.2072949409484863
Validation loss: 2.2499381999174752

Epoch: 5| Step: 10
Training loss: 2.8209471702575684
Validation loss: 2.251798838376999

Epoch: 5| Step: 11
Training loss: 2.3199477195739746
Validation loss: 2.2461768786112466

Epoch: 63| Step: 0
Training loss: 2.840420961380005
Validation loss: 2.248559132218361

Epoch: 5| Step: 1
Training loss: 2.9405672550201416
Validation loss: 2.2423601349194846

Epoch: 5| Step: 2
Training loss: 2.72477650642395
Validation loss: 2.241517206033071

Epoch: 5| Step: 3
Training loss: 2.2859721183776855
Validation loss: 2.243505358695984

Epoch: 5| Step: 4
Training loss: 1.7693021297454834
Validation loss: 2.2425281753142676

Epoch: 5| Step: 5
Training loss: 2.519300937652588
Validation loss: 2.237542301416397

Epoch: 5| Step: 6
Training loss: 2.0829405784606934
Validation loss: 2.2373715241750083

Epoch: 5| Step: 7
Training loss: 1.9285733699798584
Validation loss: 2.2330103317896524

Epoch: 5| Step: 8
Training loss: 2.4688000679016113
Validation loss: 2.23815123240153

Epoch: 5| Step: 9
Training loss: 2.26515531539917
Validation loss: 2.2407093048095703

Epoch: 5| Step: 10
Training loss: 2.5004353523254395
Validation loss: 2.245167225599289

Epoch: 5| Step: 11
Training loss: 2.6522724628448486
Validation loss: 2.235877970854441

Epoch: 64| Step: 0
Training loss: 2.315788745880127
Validation loss: 2.226055840651194

Epoch: 5| Step: 1
Training loss: 2.181432008743286
Validation loss: 2.223101099332174

Epoch: 5| Step: 2
Training loss: 1.8965057134628296
Validation loss: 2.219666212797165

Epoch: 5| Step: 3
Training loss: 2.899536371231079
Validation loss: 2.2182630697886148

Epoch: 5| Step: 4
Training loss: 2.1375107765197754
Validation loss: 2.2221525758504868

Epoch: 5| Step: 5
Training loss: 2.6657779216766357
Validation loss: 2.2139899879693985

Epoch: 5| Step: 6
Training loss: 2.2346091270446777
Validation loss: 2.2115416626135507

Epoch: 5| Step: 7
Training loss: 2.435535430908203
Validation loss: 2.2092232505480447

Epoch: 5| Step: 8
Training loss: 2.586771011352539
Validation loss: 2.203198010722796

Epoch: 5| Step: 9
Training loss: 2.552262544631958
Validation loss: 2.2045412758986154

Epoch: 5| Step: 10
Training loss: 2.139953374862671
Validation loss: 2.202682947119077

Epoch: 5| Step: 11
Training loss: 2.414454460144043
Validation loss: 2.201531767845154

Epoch: 65| Step: 0
Training loss: 2.1790575981140137
Validation loss: 2.2085840503374734

Epoch: 5| Step: 1
Training loss: 2.2079379558563232
Validation loss: 2.204510052998861

Epoch: 5| Step: 2
Training loss: 2.5123848915100098
Validation loss: 2.2002656112114587

Epoch: 5| Step: 3
Training loss: 2.8576653003692627
Validation loss: 2.1971813440322876

Epoch: 5| Step: 4
Training loss: 2.727832078933716
Validation loss: 2.200940862298012

Epoch: 5| Step: 5
Training loss: 2.258915662765503
Validation loss: 2.2003463208675385

Epoch: 5| Step: 6
Training loss: 1.8563387393951416
Validation loss: 2.2003503491481147

Epoch: 5| Step: 7
Training loss: 2.332064151763916
Validation loss: 2.1946024298667908

Epoch: 5| Step: 8
Training loss: 2.5001285076141357
Validation loss: 2.190222983558973

Epoch: 5| Step: 9
Training loss: 2.000750780105591
Validation loss: 2.187003975113233

Epoch: 5| Step: 10
Training loss: 2.5528650283813477
Validation loss: 2.1834110816319785

Epoch: 5| Step: 11
Training loss: 1.731647253036499
Validation loss: 2.1764894823233285

Epoch: 66| Step: 0
Training loss: 2.9162731170654297
Validation loss: 2.184370219707489

Epoch: 5| Step: 1
Training loss: 2.65427827835083
Validation loss: 2.1780283053716025

Epoch: 5| Step: 2
Training loss: 2.1919548511505127
Validation loss: 2.1753755112489066

Epoch: 5| Step: 3
Training loss: 2.4290382862091064
Validation loss: 2.173496052622795

Epoch: 5| Step: 4
Training loss: 2.618821620941162
Validation loss: 2.1728297024965286

Epoch: 5| Step: 5
Training loss: 1.7021276950836182
Validation loss: 2.177458867430687

Epoch: 5| Step: 6
Training loss: 2.343527317047119
Validation loss: 2.1695017417271933

Epoch: 5| Step: 7
Training loss: 1.7855392694473267
Validation loss: 2.173935135205587

Epoch: 5| Step: 8
Training loss: 2.1477832794189453
Validation loss: 2.1719224403301873

Epoch: 5| Step: 9
Training loss: 2.26080322265625
Validation loss: 2.1685324758291245

Epoch: 5| Step: 10
Training loss: 2.4071691036224365
Validation loss: 2.1643756528695426

Epoch: 5| Step: 11
Training loss: 3.17197322845459
Validation loss: 2.164091259241104

Epoch: 67| Step: 0
Training loss: 2.306732654571533
Validation loss: 2.159210349122683

Epoch: 5| Step: 1
Training loss: 2.5875442028045654
Validation loss: 2.1654435892899833

Epoch: 5| Step: 2
Training loss: 2.2991557121276855
Validation loss: 2.1695393721262612

Epoch: 5| Step: 3
Training loss: 2.3237977027893066
Validation loss: 2.16167159875234

Epoch: 5| Step: 4
Training loss: 2.3235950469970703
Validation loss: 2.1682498157024384

Epoch: 5| Step: 5
Training loss: 2.401651382446289
Validation loss: 2.157561272382736

Epoch: 5| Step: 6
Training loss: 2.267202377319336
Validation loss: 2.1562224874893823

Epoch: 5| Step: 7
Training loss: 2.4409918785095215
Validation loss: 2.1552976171175637

Epoch: 5| Step: 8
Training loss: 2.1385955810546875
Validation loss: 2.157664656639099

Epoch: 5| Step: 9
Training loss: 2.000066041946411
Validation loss: 2.157715752720833

Epoch: 5| Step: 10
Training loss: 2.3237006664276123
Validation loss: 2.159213960170746

Epoch: 5| Step: 11
Training loss: 2.384308338165283
Validation loss: 2.162916213274002

Epoch: 68| Step: 0
Training loss: 2.484260320663452
Validation loss: 2.168032944202423

Epoch: 5| Step: 1
Training loss: 2.2393174171447754
Validation loss: 2.1774675846099854

Epoch: 5| Step: 2
Training loss: 2.425954818725586
Validation loss: 2.1732608675956726

Epoch: 5| Step: 3
Training loss: 1.6683448553085327
Validation loss: 2.1724013487497964

Epoch: 5| Step: 4
Training loss: 2.7539777755737305
Validation loss: 2.173283119996389

Epoch: 5| Step: 5
Training loss: 1.8931045532226562
Validation loss: 2.1646111756563187

Epoch: 5| Step: 6
Training loss: 1.7180055379867554
Validation loss: 2.1524715026219687

Epoch: 5| Step: 7
Training loss: 2.7789406776428223
Validation loss: 2.15045964717865

Epoch: 5| Step: 8
Training loss: 2.4972052574157715
Validation loss: 2.1418014764785767

Epoch: 5| Step: 9
Training loss: 2.911343574523926
Validation loss: 2.1432818522055945

Epoch: 5| Step: 10
Training loss: 2.252211093902588
Validation loss: 2.134661316871643

Epoch: 5| Step: 11
Training loss: 1.8738312721252441
Validation loss: 2.132953862349192

Epoch: 69| Step: 0
Training loss: 2.358084201812744
Validation loss: 2.1328585545221963

Epoch: 5| Step: 1
Training loss: 2.653918743133545
Validation loss: 2.147752414147059

Epoch: 5| Step: 2
Training loss: 2.5522549152374268
Validation loss: 2.1606780290603638

Epoch: 5| Step: 3
Training loss: 2.5587551593780518
Validation loss: 2.1546775301297507

Epoch: 5| Step: 4
Training loss: 2.2005538940429688
Validation loss: 2.1313574463129044

Epoch: 5| Step: 5
Training loss: 2.0787503719329834
Validation loss: 2.128452718257904

Epoch: 5| Step: 6
Training loss: 2.6100661754608154
Validation loss: 2.130033959945043

Epoch: 5| Step: 7
Training loss: 2.4667210578918457
Validation loss: 2.1336702704429626

Epoch: 5| Step: 8
Training loss: 1.7955354452133179
Validation loss: 2.138801008462906

Epoch: 5| Step: 9
Training loss: 2.191378355026245
Validation loss: 2.1419188578923545

Epoch: 5| Step: 10
Training loss: 1.9065059423446655
Validation loss: 2.1467769791682563

Epoch: 5| Step: 11
Training loss: 3.00014591217041
Validation loss: 2.141766140858332

Epoch: 70| Step: 0
Training loss: 2.707148313522339
Validation loss: 2.148562783996264

Epoch: 5| Step: 1
Training loss: 2.358750104904175
Validation loss: 2.138912965854009

Epoch: 5| Step: 2
Training loss: 2.6207962036132812
Validation loss: 2.1385227143764496

Epoch: 5| Step: 3
Training loss: 2.360945224761963
Validation loss: 2.13384618361791

Epoch: 5| Step: 4
Training loss: 1.8407987356185913
Validation loss: 2.132097512483597

Epoch: 5| Step: 5
Training loss: 2.6789307594299316
Validation loss: 2.131102959314982

Epoch: 5| Step: 6
Training loss: 1.8026838302612305
Validation loss: 2.127673168977102

Epoch: 5| Step: 7
Training loss: 1.8352010250091553
Validation loss: 2.12231453259786

Epoch: 5| Step: 8
Training loss: 2.450829029083252
Validation loss: 2.119912435611089

Epoch: 5| Step: 9
Training loss: 1.4448964595794678
Validation loss: 2.1187284886837006

Epoch: 5| Step: 10
Training loss: 2.8539886474609375
Validation loss: 2.108314057191213

Epoch: 5| Step: 11
Training loss: 3.4879541397094727
Validation loss: 2.111259331305822

Epoch: 71| Step: 0
Training loss: 2.426185131072998
Validation loss: 2.1080766518910727

Epoch: 5| Step: 1
Training loss: 2.054309844970703
Validation loss: 2.1288703183333078

Epoch: 5| Step: 2
Training loss: 2.6167397499084473
Validation loss: 2.1271703988313675

Epoch: 5| Step: 3
Training loss: 3.152247667312622
Validation loss: 2.1204917232195535

Epoch: 5| Step: 4
Training loss: 2.378847122192383
Validation loss: 2.1074442664782205

Epoch: 5| Step: 5
Training loss: 2.16524076461792
Validation loss: 2.1051998237768808

Epoch: 5| Step: 6
Training loss: 2.316889762878418
Validation loss: 2.1143602629502616

Epoch: 5| Step: 7
Training loss: 1.6706289052963257
Validation loss: 2.1087403694788613

Epoch: 5| Step: 8
Training loss: 1.5456385612487793
Validation loss: 2.1111326118310294

Epoch: 5| Step: 9
Training loss: 2.5205044746398926
Validation loss: 2.108546942472458

Epoch: 5| Step: 10
Training loss: 2.178680419921875
Validation loss: 2.1100272039572396

Epoch: 5| Step: 11
Training loss: 3.223769426345825
Validation loss: 2.113714133699735

Epoch: 72| Step: 0
Training loss: 2.4261181354522705
Validation loss: 2.103110750516256

Epoch: 5| Step: 1
Training loss: 2.845701217651367
Validation loss: 2.1032013843456903

Epoch: 5| Step: 2
Training loss: 1.696952223777771
Validation loss: 2.1006449361642203

Epoch: 5| Step: 3
Training loss: 2.140040159225464
Validation loss: 2.0961670180161796

Epoch: 5| Step: 4
Training loss: 2.4939329624176025
Validation loss: 2.1025199939807258

Epoch: 5| Step: 5
Training loss: 1.7994416952133179
Validation loss: 2.0930067549149194

Epoch: 5| Step: 6
Training loss: 3.2370822429656982
Validation loss: 2.093691055973371

Epoch: 5| Step: 7
Training loss: 2.2129158973693848
Validation loss: 2.0880866646766663

Epoch: 5| Step: 8
Training loss: 2.4569973945617676
Validation loss: 2.093436668316523

Epoch: 5| Step: 9
Training loss: 1.5422252416610718
Validation loss: 2.088669776916504

Epoch: 5| Step: 10
Training loss: 2.0288045406341553
Validation loss: 2.082388704021772

Epoch: 5| Step: 11
Training loss: 2.125129222869873
Validation loss: 2.093212306499481

Epoch: 73| Step: 0
Training loss: 2.1997013092041016
Validation loss: 2.08046692609787

Epoch: 5| Step: 1
Training loss: 2.0461723804473877
Validation loss: 2.082720344265302

Epoch: 5| Step: 2
Training loss: 2.68522310256958
Validation loss: 2.0810332894325256

Epoch: 5| Step: 3
Training loss: 2.0935218334198
Validation loss: 2.0757774660984674

Epoch: 5| Step: 4
Training loss: 1.7381490468978882
Validation loss: 2.0800767938296

Epoch: 5| Step: 5
Training loss: 2.5237956047058105
Validation loss: 2.086840788523356

Epoch: 5| Step: 6
Training loss: 2.309293746948242
Validation loss: 2.078177039821943

Epoch: 5| Step: 7
Training loss: 2.1563103199005127
Validation loss: 2.0795450111230216

Epoch: 5| Step: 8
Training loss: 2.6288743019104004
Validation loss: 2.072730168700218

Epoch: 5| Step: 9
Training loss: 2.314408540725708
Validation loss: 2.075638403495153

Epoch: 5| Step: 10
Training loss: 2.0982460975646973
Validation loss: 2.072352002064387

Epoch: 5| Step: 11
Training loss: 1.4859051704406738
Validation loss: 2.0838443587223687

Epoch: 74| Step: 0
Training loss: 2.161956310272217
Validation loss: 2.0746271113554635

Epoch: 5| Step: 1
Training loss: 2.9106216430664062
Validation loss: 2.071378087004026

Epoch: 5| Step: 2
Training loss: 2.113746166229248
Validation loss: 2.073806017637253

Epoch: 5| Step: 3
Training loss: 2.1690547466278076
Validation loss: 2.0817838261524835

Epoch: 5| Step: 4
Training loss: 2.0957729816436768
Validation loss: 2.071668580174446

Epoch: 5| Step: 5
Training loss: 2.173387050628662
Validation loss: 2.0744596868753433

Epoch: 5| Step: 6
Training loss: 2.090053081512451
Validation loss: 2.0652947227160134

Epoch: 5| Step: 7
Training loss: 2.2354400157928467
Validation loss: 2.069352542360624

Epoch: 5| Step: 8
Training loss: 2.3148066997528076
Validation loss: 2.0725940565268197

Epoch: 5| Step: 9
Training loss: 2.433720350265503
Validation loss: 2.068450927734375

Epoch: 5| Step: 10
Training loss: 2.011465072631836
Validation loss: 2.0682434091965356

Epoch: 5| Step: 11
Training loss: 1.6505869626998901
Validation loss: 2.0775861740112305

Epoch: 75| Step: 0
Training loss: 2.0956978797912598
Validation loss: 2.0687730411688485

Epoch: 5| Step: 1
Training loss: 2.4303534030914307
Validation loss: 2.070088654756546

Epoch: 5| Step: 2
Training loss: 2.334285259246826
Validation loss: 2.0655122995376587

Epoch: 5| Step: 3
Training loss: 2.411208391189575
Validation loss: 2.0515476067860923

Epoch: 5| Step: 4
Training loss: 1.9963699579238892
Validation loss: 2.0577328354120255

Epoch: 5| Step: 5
Training loss: 2.094940662384033
Validation loss: 2.050218775868416

Epoch: 5| Step: 6
Training loss: 1.900952696800232
Validation loss: 2.054746891061465

Epoch: 5| Step: 7
Training loss: 2.4197909832000732
Validation loss: 2.0525826762119928

Epoch: 5| Step: 8
Training loss: 2.335148811340332
Validation loss: 2.054293771584829

Epoch: 5| Step: 9
Training loss: 2.434044122695923
Validation loss: 2.0455585718154907

Epoch: 5| Step: 10
Training loss: 1.894822120666504
Validation loss: 2.0535247872273126

Epoch: 5| Step: 11
Training loss: 2.993995428085327
Validation loss: 2.0537498692671456

Epoch: 76| Step: 0
Training loss: 1.7422559261322021
Validation loss: 2.044580747683843

Epoch: 5| Step: 1
Training loss: 2.321598768234253
Validation loss: 2.051357011000315

Epoch: 5| Step: 2
Training loss: 2.4924991130828857
Validation loss: 2.04079706966877

Epoch: 5| Step: 3
Training loss: 2.102478504180908
Validation loss: 2.051048924525579

Epoch: 5| Step: 4
Training loss: 1.8544543981552124
Validation loss: 2.0494816104571023

Epoch: 5| Step: 5
Training loss: 2.5489113330841064
Validation loss: 2.048786868651708

Epoch: 5| Step: 6
Training loss: 2.1162121295928955
Validation loss: 2.055718650420507

Epoch: 5| Step: 7
Training loss: 2.2294933795928955
Validation loss: 2.0574616293112435

Epoch: 5| Step: 8
Training loss: 2.41231632232666
Validation loss: 2.066643074154854

Epoch: 5| Step: 9
Training loss: 2.37732195854187
Validation loss: 2.0555445651213327

Epoch: 5| Step: 10
Training loss: 2.1169042587280273
Validation loss: 2.059293727080027

Epoch: 5| Step: 11
Training loss: 3.1086108684539795
Validation loss: 2.055669824282328

Epoch: 77| Step: 0
Training loss: 1.3264975547790527
Validation loss: 2.0436030129591622

Epoch: 5| Step: 1
Training loss: 2.255465030670166
Validation loss: 2.0451357314984002

Epoch: 5| Step: 2
Training loss: 2.4107253551483154
Validation loss: 2.0585360725720725

Epoch: 5| Step: 3
Training loss: 1.4676408767700195
Validation loss: 2.0652289390563965

Epoch: 5| Step: 4
Training loss: 1.8772954940795898
Validation loss: 2.0568725864092507

Epoch: 5| Step: 5
Training loss: 2.6447582244873047
Validation loss: 2.052774747212728

Epoch: 5| Step: 6
Training loss: 2.5055058002471924
Validation loss: 2.0584161082903543

Epoch: 5| Step: 7
Training loss: 2.4444985389709473
Validation loss: 2.055384154121081

Epoch: 5| Step: 8
Training loss: 2.4381022453308105
Validation loss: 2.0459753026564917

Epoch: 5| Step: 9
Training loss: 2.499340772628784
Validation loss: 2.0550284485022225

Epoch: 5| Step: 10
Training loss: 2.456848382949829
Validation loss: 2.0486941635608673

Epoch: 5| Step: 11
Training loss: 2.6175498962402344
Validation loss: 2.0395681957403817

Epoch: 78| Step: 0
Training loss: 1.9910739660263062
Validation loss: 2.035547728339831

Epoch: 5| Step: 1
Training loss: 2.5284056663513184
Validation loss: 2.0452357729276023

Epoch: 5| Step: 2
Training loss: 1.958648443222046
Validation loss: 2.043927644689878

Epoch: 5| Step: 3
Training loss: 2.2970335483551025
Validation loss: 2.0546930680672326

Epoch: 5| Step: 4
Training loss: 1.9264144897460938
Validation loss: 2.0440612534681954

Epoch: 5| Step: 5
Training loss: 1.8196582794189453
Validation loss: 2.052833835283915

Epoch: 5| Step: 6
Training loss: 2.5232949256896973
Validation loss: 2.053818399707476

Epoch: 5| Step: 7
Training loss: 2.017622947692871
Validation loss: 2.0649278859297433

Epoch: 5| Step: 8
Training loss: 2.4891278743743896
Validation loss: 2.044237489501635

Epoch: 5| Step: 9
Training loss: 2.4868240356445312
Validation loss: 2.0520095924536386

Epoch: 5| Step: 10
Training loss: 2.1052656173706055
Validation loss: 2.0343044052521386

Epoch: 5| Step: 11
Training loss: 2.7318062782287598
Validation loss: 2.0417164812485376

Epoch: 79| Step: 0
Training loss: 2.019235610961914
Validation loss: 2.041304717461268

Epoch: 5| Step: 1
Training loss: 2.473414897918701
Validation loss: 2.038469354311625

Epoch: 5| Step: 2
Training loss: 2.6969873905181885
Validation loss: 2.035405601064364

Epoch: 5| Step: 3
Training loss: 2.1252312660217285
Validation loss: 2.0320684065421424

Epoch: 5| Step: 4
Training loss: 2.461318254470825
Validation loss: 2.027674585580826

Epoch: 5| Step: 5
Training loss: 1.551677942276001
Validation loss: 2.0408884485562644

Epoch: 5| Step: 6
Training loss: 2.17284893989563
Validation loss: 2.0295323530832925

Epoch: 5| Step: 7
Training loss: 2.1539509296417236
Validation loss: 2.0368808706601462

Epoch: 5| Step: 8
Training loss: 2.1966073513031006
Validation loss: 2.044943486650785

Epoch: 5| Step: 9
Training loss: 1.7508741617202759
Validation loss: 2.0393537978331246

Epoch: 5| Step: 10
Training loss: 2.5214664936065674
Validation loss: 2.0366191267967224

Epoch: 5| Step: 11
Training loss: 2.4417858123779297
Validation loss: 2.035218561689059

Epoch: 80| Step: 0
Training loss: 2.2659196853637695
Validation loss: 2.039563551545143

Epoch: 5| Step: 1
Training loss: 1.786745309829712
Validation loss: 2.0372962752978006

Epoch: 5| Step: 2
Training loss: 2.5754871368408203
Validation loss: 2.036307250459989

Epoch: 5| Step: 3
Training loss: 2.42974591255188
Validation loss: 2.0346298267443976

Epoch: 5| Step: 4
Training loss: 2.1565420627593994
Validation loss: 2.0337432622909546

Epoch: 5| Step: 5
Training loss: 2.0257785320281982
Validation loss: 2.027557830015818

Epoch: 5| Step: 6
Training loss: 1.7416585683822632
Validation loss: 2.0333988964557648

Epoch: 5| Step: 7
Training loss: 1.8228540420532227
Validation loss: 2.0367936293284097

Epoch: 5| Step: 8
Training loss: 2.173285722732544
Validation loss: 2.0464107990264893

Epoch: 5| Step: 9
Training loss: 2.402611017227173
Validation loss: 2.054210379719734

Epoch: 5| Step: 10
Training loss: 2.609753131866455
Validation loss: 2.0457107524077096

Epoch: 5| Step: 11
Training loss: 3.381661891937256
Validation loss: 2.049434761206309

Epoch: 81| Step: 0
Training loss: 2.3920555114746094
Validation loss: 2.0451094110806785

Epoch: 5| Step: 1
Training loss: 2.5435447692871094
Validation loss: 2.054067939519882

Epoch: 5| Step: 2
Training loss: 1.8678598403930664
Validation loss: 2.0486475974321365

Epoch: 5| Step: 3
Training loss: 2.3213894367218018
Validation loss: 2.044870083530744

Epoch: 5| Step: 4
Training loss: 1.998140573501587
Validation loss: 2.04628132780393

Epoch: 5| Step: 5
Training loss: 2.6583569049835205
Validation loss: 2.0389306396245956

Epoch: 5| Step: 6
Training loss: 1.68427312374115
Validation loss: 2.0455225308736167

Epoch: 5| Step: 7
Training loss: 2.024857997894287
Validation loss: 2.0400496621926627

Epoch: 5| Step: 8
Training loss: 2.251227855682373
Validation loss: 2.025860791405042

Epoch: 5| Step: 9
Training loss: 2.1026062965393066
Validation loss: 2.021274040142695

Epoch: 5| Step: 10
Training loss: 2.131124496459961
Validation loss: 2.0371925632158914

Epoch: 5| Step: 11
Training loss: 2.1675257682800293
Validation loss: 2.0511543651421866

Epoch: 82| Step: 0
Training loss: 2.162105083465576
Validation loss: 2.046225522955259

Epoch: 5| Step: 1
Training loss: 2.2372138500213623
Validation loss: 2.049122562011083

Epoch: 5| Step: 2
Training loss: 2.1161627769470215
Validation loss: 2.04885263244311

Epoch: 5| Step: 3
Training loss: 2.771705150604248
Validation loss: 2.043435965975126

Epoch: 5| Step: 4
Training loss: 2.101022243499756
Validation loss: 2.048037593563398

Epoch: 5| Step: 5
Training loss: 2.7602767944335938
Validation loss: 2.045790712038676

Epoch: 5| Step: 6
Training loss: 2.682683229446411
Validation loss: 2.038448934753736

Epoch: 5| Step: 7
Training loss: 2.0117557048797607
Validation loss: 2.031890665491422

Epoch: 5| Step: 8
Training loss: 1.8471616506576538
Validation loss: 2.028640558322271

Epoch: 5| Step: 9
Training loss: 2.2656748294830322
Validation loss: 2.0229744811852775

Epoch: 5| Step: 10
Training loss: 1.4525238275527954
Validation loss: 2.020448605219523

Epoch: 5| Step: 11
Training loss: 1.5855573415756226
Validation loss: 2.0214127202828727

Epoch: 83| Step: 0
Training loss: 2.5440495014190674
Validation loss: 2.0267353951931

Epoch: 5| Step: 1
Training loss: 2.4134860038757324
Validation loss: 2.037013297279676

Epoch: 5| Step: 2
Training loss: 1.8227577209472656
Validation loss: 2.0435231725374856

Epoch: 5| Step: 3
Training loss: 2.4398741722106934
Validation loss: 2.0540366818507514

Epoch: 5| Step: 4
Training loss: 1.928290605545044
Validation loss: 2.050682842731476

Epoch: 5| Step: 5
Training loss: 2.2222251892089844
Validation loss: 2.046695296963056

Epoch: 5| Step: 6
Training loss: 1.5677179098129272
Validation loss: 2.044049635529518

Epoch: 5| Step: 7
Training loss: 2.1558549404144287
Validation loss: 2.053866366545359

Epoch: 5| Step: 8
Training loss: 2.044043779373169
Validation loss: 2.045468936363856

Epoch: 5| Step: 9
Training loss: 2.446011781692505
Validation loss: 2.0478084633747735

Epoch: 5| Step: 10
Training loss: 2.4564552307128906
Validation loss: 2.0437384198109307

Epoch: 5| Step: 11
Training loss: 1.8314378261566162
Validation loss: 2.0406343936920166

Epoch: 84| Step: 0
Training loss: 2.0163865089416504
Validation loss: 2.0451628466447196

Epoch: 5| Step: 1
Training loss: 2.6496098041534424
Validation loss: 2.0500026990969977

Epoch: 5| Step: 2
Training loss: 2.485668182373047
Validation loss: 2.048568829894066

Epoch: 5| Step: 3
Training loss: 1.780486822128296
Validation loss: 2.0513591319322586

Epoch: 5| Step: 4
Training loss: 2.1075048446655273
Validation loss: 2.049899915854136

Epoch: 5| Step: 5
Training loss: 3.045973539352417
Validation loss: 2.032998949289322

Epoch: 5| Step: 6
Training loss: 2.375676155090332
Validation loss: 2.033282220363617

Epoch: 5| Step: 7
Training loss: 2.1333353519439697
Validation loss: 2.024673263231913

Epoch: 5| Step: 8
Training loss: 1.4381417036056519
Validation loss: 2.021913856267929

Epoch: 5| Step: 9
Training loss: 1.8374162912368774
Validation loss: 2.0155599067608514

Epoch: 5| Step: 10
Training loss: 2.1593141555786133
Validation loss: 2.017598142226537

Epoch: 5| Step: 11
Training loss: 2.274301528930664
Validation loss: 2.0121976186831794

Epoch: 85| Step: 0
Training loss: 2.5268473625183105
Validation loss: 2.0256172517935433

Epoch: 5| Step: 1
Training loss: 2.0675888061523438
Validation loss: 2.015959312518438

Epoch: 5| Step: 2
Training loss: 2.2397658824920654
Validation loss: 2.0194478233655295

Epoch: 5| Step: 3
Training loss: 2.5460922718048096
Validation loss: 2.014791632692019

Epoch: 5| Step: 4
Training loss: 2.1852850914001465
Validation loss: 2.0149159034093223

Epoch: 5| Step: 5
Training loss: 2.168799877166748
Validation loss: 2.023328796029091

Epoch: 5| Step: 6
Training loss: 2.0549657344818115
Validation loss: 2.01241597533226

Epoch: 5| Step: 7
Training loss: 2.1503822803497314
Validation loss: 2.0200803776582084

Epoch: 5| Step: 8
Training loss: 2.2039132118225098
Validation loss: 2.020399490992228

Epoch: 5| Step: 9
Training loss: 1.7349722385406494
Validation loss: 2.021450713276863

Epoch: 5| Step: 10
Training loss: 2.030747175216675
Validation loss: 2.024553726116816

Epoch: 5| Step: 11
Training loss: 2.3385701179504395
Validation loss: 2.023639922340711

Epoch: 86| Step: 0
Training loss: 2.7803263664245605
Validation loss: 2.0234314451615014

Epoch: 5| Step: 1
Training loss: 2.791191339492798
Validation loss: 2.036299710472425

Epoch: 5| Step: 2
Training loss: 1.750739336013794
Validation loss: 2.038418730099996

Epoch: 5| Step: 3
Training loss: 2.039538860321045
Validation loss: 2.03942741950353

Epoch: 5| Step: 4
Training loss: 1.7812591791152954
Validation loss: 2.0440898686647415

Epoch: 5| Step: 5
Training loss: 2.9090991020202637
Validation loss: 2.0308046539624534

Epoch: 5| Step: 6
Training loss: 1.771240234375
Validation loss: 2.0176673779884973

Epoch: 5| Step: 7
Training loss: 2.015079975128174
Validation loss: 2.021983096996943

Epoch: 5| Step: 8
Training loss: 1.835099458694458
Validation loss: 2.0254732370376587

Epoch: 5| Step: 9
Training loss: 2.5774338245391846
Validation loss: 2.0345399379730225

Epoch: 5| Step: 10
Training loss: 1.857560157775879
Validation loss: 2.0406526029109955

Epoch: 5| Step: 11
Training loss: 2.1504106521606445
Validation loss: 2.0368560006221137

Epoch: 87| Step: 0
Training loss: 2.041715145111084
Validation loss: 2.0378960967063904

Epoch: 5| Step: 1
Training loss: 1.7438825368881226
Validation loss: 2.0382192035516105

Epoch: 5| Step: 2
Training loss: 1.8894609212875366
Validation loss: 2.0433584799369178

Epoch: 5| Step: 3
Training loss: 2.3670082092285156
Validation loss: 2.0415328443050385

Epoch: 5| Step: 4
Training loss: 1.8481191396713257
Validation loss: 2.041620413462321

Epoch: 5| Step: 5
Training loss: 2.395551919937134
Validation loss: 2.041580304503441

Epoch: 5| Step: 6
Training loss: 2.6143786907196045
Validation loss: 2.0325027455886207

Epoch: 5| Step: 7
Training loss: 2.016803503036499
Validation loss: 2.038069412112236

Epoch: 5| Step: 8
Training loss: 2.58708119392395
Validation loss: 2.0255770534276962

Epoch: 5| Step: 9
Training loss: 2.1160411834716797
Validation loss: 2.0195537408192954

Epoch: 5| Step: 10
Training loss: 2.498755931854248
Validation loss: 2.02030019958814

Epoch: 5| Step: 11
Training loss: 2.779201030731201
Validation loss: 2.016467417279879

Epoch: 88| Step: 0
Training loss: 2.0545921325683594
Validation loss: 2.0298992097377777

Epoch: 5| Step: 1
Training loss: 1.9829063415527344
Validation loss: 2.0526571571826935

Epoch: 5| Step: 2
Training loss: 2.3754618167877197
Validation loss: 2.061090737581253

Epoch: 5| Step: 3
Training loss: 2.464507579803467
Validation loss: 2.0816638469696045

Epoch: 5| Step: 4
Training loss: 2.4874329566955566
Validation loss: 2.0846846997737885

Epoch: 5| Step: 5
Training loss: 2.0107877254486084
Validation loss: 2.084643686811129

Epoch: 5| Step: 6
Training loss: 2.45019268989563
Validation loss: 2.08585949242115

Epoch: 5| Step: 7
Training loss: 2.4678728580474854
Validation loss: 2.0719893723726273

Epoch: 5| Step: 8
Training loss: 1.9619379043579102
Validation loss: 2.054842780033747

Epoch: 5| Step: 9
Training loss: 2.1571364402770996
Validation loss: 2.032718911767006

Epoch: 5| Step: 10
Training loss: 1.6865594387054443
Validation loss: 2.0282878975073495

Epoch: 5| Step: 11
Training loss: 2.463477849960327
Validation loss: 2.0262307226657867

Epoch: 89| Step: 0
Training loss: 2.000870943069458
Validation loss: 2.0191680739323297

Epoch: 5| Step: 1
Training loss: 2.1441545486450195
Validation loss: 2.0147202610969543

Epoch: 5| Step: 2
Training loss: 2.3628389835357666
Validation loss: 2.013728360335032

Epoch: 5| Step: 3
Training loss: 2.5893912315368652
Validation loss: 2.0313120832045874

Epoch: 5| Step: 4
Training loss: 2.2724435329437256
Validation loss: 2.0302484581867852

Epoch: 5| Step: 5
Training loss: 2.4042282104492188
Validation loss: 2.0276591827472052

Epoch: 5| Step: 6
Training loss: 1.4137792587280273
Validation loss: 2.037244920929273

Epoch: 5| Step: 7
Training loss: 2.239724636077881
Validation loss: 2.0300227304299674

Epoch: 5| Step: 8
Training loss: 2.6874935626983643
Validation loss: 2.0327715277671814

Epoch: 5| Step: 9
Training loss: 1.8144611120224
Validation loss: 2.0284356474876404

Epoch: 5| Step: 10
Training loss: 2.297764539718628
Validation loss: 2.02163402736187

Epoch: 5| Step: 11
Training loss: 1.607863426208496
Validation loss: 2.016295557220777

Epoch: 90| Step: 0
Training loss: 2.0776915550231934
Validation loss: 2.0211895555257797

Epoch: 5| Step: 1
Training loss: 2.0604000091552734
Validation loss: 2.014269436399142

Epoch: 5| Step: 2
Training loss: 2.4727070331573486
Validation loss: 2.00678280989329

Epoch: 5| Step: 3
Training loss: 2.2873523235321045
Validation loss: 2.011064966519674

Epoch: 5| Step: 4
Training loss: 2.5006000995635986
Validation loss: 2.0092222094535828

Epoch: 5| Step: 5
Training loss: 2.170421600341797
Validation loss: 2.01616071164608

Epoch: 5| Step: 6
Training loss: 2.3012359142303467
Validation loss: 2.01246144870917

Epoch: 5| Step: 7
Training loss: 1.8961591720581055
Validation loss: 2.016555373867353

Epoch: 5| Step: 8
Training loss: 1.9678211212158203
Validation loss: 2.0252605925003686

Epoch: 5| Step: 9
Training loss: 1.8102937936782837
Validation loss: 2.039812554915746

Epoch: 5| Step: 10
Training loss: 2.45166277885437
Validation loss: 2.0440233051776886

Epoch: 5| Step: 11
Training loss: 1.4161427021026611
Validation loss: 2.053123816847801

Epoch: 91| Step: 0
Training loss: 2.0239756107330322
Validation loss: 2.0496303141117096

Epoch: 5| Step: 1
Training loss: 2.029048204421997
Validation loss: 2.058371995886167

Epoch: 5| Step: 2
Training loss: 1.9497047662734985
Validation loss: 2.059222395221392

Epoch: 5| Step: 3
Training loss: 2.0442326068878174
Validation loss: 2.052918334801992

Epoch: 5| Step: 4
Training loss: 2.3314967155456543
Validation loss: 2.0504774500926337

Epoch: 5| Step: 5
Training loss: 2.017223834991455
Validation loss: 2.056704660256704

Epoch: 5| Step: 6
Training loss: 2.4362502098083496
Validation loss: 2.0293598423401513

Epoch: 5| Step: 7
Training loss: 1.9296424388885498
Validation loss: 2.0205432375272117

Epoch: 5| Step: 8
Training loss: 2.370407819747925
Validation loss: 2.017613177498182

Epoch: 5| Step: 9
Training loss: 2.2838549613952637
Validation loss: 2.0041498790184655

Epoch: 5| Step: 10
Training loss: 2.4656877517700195
Validation loss: 2.001124600569407

Epoch: 5| Step: 11
Training loss: 1.5850529670715332
Validation loss: 2.010367383559545

Epoch: 92| Step: 0
Training loss: 1.9070905447006226
Validation loss: 2.018091470003128

Epoch: 5| Step: 1
Training loss: 2.6059131622314453
Validation loss: 2.0257114320993423

Epoch: 5| Step: 2
Training loss: 2.18880033493042
Validation loss: 2.0301946153243384

Epoch: 5| Step: 3
Training loss: 2.6525065898895264
Validation loss: 2.0361319879690805

Epoch: 5| Step: 4
Training loss: 1.570253610610962
Validation loss: 2.035907427469889

Epoch: 5| Step: 5
Training loss: 1.752666711807251
Validation loss: 2.0343181043863297

Epoch: 5| Step: 6
Training loss: 2.618542194366455
Validation loss: 2.036316454410553

Epoch: 5| Step: 7
Training loss: 2.093801498413086
Validation loss: 2.02477665245533

Epoch: 5| Step: 8
Training loss: 2.7368416786193848
Validation loss: 2.0242857237656913

Epoch: 5| Step: 9
Training loss: 2.0550272464752197
Validation loss: 2.0209981203079224

Epoch: 5| Step: 10
Training loss: 1.8293685913085938
Validation loss: 2.0190575619538627

Epoch: 5| Step: 11
Training loss: 2.0996382236480713
Validation loss: 2.013752510150274

Epoch: 93| Step: 0
Training loss: 2.0959675312042236
Validation loss: 2.0175064901510873

Epoch: 5| Step: 1
Training loss: 2.38057279586792
Validation loss: 2.05045722424984

Epoch: 5| Step: 2
Training loss: 2.4563028812408447
Validation loss: 2.091825470328331

Epoch: 5| Step: 3
Training loss: 3.3177669048309326
Validation loss: 2.105045815308889

Epoch: 5| Step: 4
Training loss: 2.0422985553741455
Validation loss: 2.087673674027125

Epoch: 5| Step: 5
Training loss: 2.6000194549560547
Validation loss: 2.0744770218928656

Epoch: 5| Step: 6
Training loss: 2.10491943359375
Validation loss: 2.044299989938736

Epoch: 5| Step: 7
Training loss: 2.1868417263031006
Validation loss: 2.0232175240914025

Epoch: 5| Step: 8
Training loss: 1.5529412031173706
Validation loss: 2.0098902036746344

Epoch: 5| Step: 9
Training loss: 2.1859943866729736
Validation loss: 2.0184183716773987

Epoch: 5| Step: 10
Training loss: 1.5695950984954834
Validation loss: 2.0274172723293304

Epoch: 5| Step: 11
Training loss: 1.839257001876831
Validation loss: 2.0244924823443093

Epoch: 94| Step: 0
Training loss: 2.1034445762634277
Validation loss: 2.031717295447985

Epoch: 5| Step: 1
Training loss: 2.3414409160614014
Validation loss: 2.041707302133242

Epoch: 5| Step: 2
Training loss: 1.9171901941299438
Validation loss: 2.0390289276838303

Epoch: 5| Step: 3
Training loss: 2.3067212104797363
Validation loss: 2.0423046201467514

Epoch: 5| Step: 4
Training loss: 1.819053292274475
Validation loss: 2.0387764275074005

Epoch: 5| Step: 5
Training loss: 2.4534382820129395
Validation loss: 2.034635826945305

Epoch: 5| Step: 6
Training loss: 2.342233896255493
Validation loss: 2.034448434909185

Epoch: 5| Step: 7
Training loss: 2.2221572399139404
Validation loss: 2.0392355918884277

Epoch: 5| Step: 8
Training loss: 2.429945468902588
Validation loss: 2.027553826570511

Epoch: 5| Step: 9
Training loss: 2.4966671466827393
Validation loss: 2.024621849258741

Epoch: 5| Step: 10
Training loss: 1.7879070043563843
Validation loss: 2.0164148112138114

Epoch: 5| Step: 11
Training loss: 2.295408248901367
Validation loss: 2.00612103442351

Epoch: 95| Step: 0
Training loss: 2.244838237762451
Validation loss: 1.9992169390122096

Epoch: 5| Step: 1
Training loss: 1.816697359085083
Validation loss: 2.001529340942701

Epoch: 5| Step: 2
Training loss: 1.8808519840240479
Validation loss: 2.0105105688174567

Epoch: 5| Step: 3
Training loss: 2.2787840366363525
Validation loss: 2.012022083004316

Epoch: 5| Step: 4
Training loss: 2.4870684146881104
Validation loss: 2.0072499563296637

Epoch: 5| Step: 5
Training loss: 2.342073917388916
Validation loss: 2.014960785706838

Epoch: 5| Step: 6
Training loss: 2.2434046268463135
Validation loss: 2.0319416423638663

Epoch: 5| Step: 7
Training loss: 2.120887279510498
Validation loss: 2.0318047255277634

Epoch: 5| Step: 8
Training loss: 1.7283366918563843
Validation loss: 2.050357306996981

Epoch: 5| Step: 9
Training loss: 2.48846173286438
Validation loss: 2.0557038138310113

Epoch: 5| Step: 10
Training loss: 2.4168243408203125
Validation loss: 2.0716786086559296

Epoch: 5| Step: 11
Training loss: 1.3162869215011597
Validation loss: 2.072492763400078

Epoch: 96| Step: 0
Training loss: 1.9400463104248047
Validation loss: 2.074797143538793

Epoch: 5| Step: 1
Training loss: 1.2790400981903076
Validation loss: 2.074849456548691

Epoch: 5| Step: 2
Training loss: 1.8595285415649414
Validation loss: 2.0758196661869683

Epoch: 5| Step: 3
Training loss: 2.7186596393585205
Validation loss: 2.0697661638259888

Epoch: 5| Step: 4
Training loss: 2.2833876609802246
Validation loss: 2.0596465319395065

Epoch: 5| Step: 5
Training loss: 2.1800811290740967
Validation loss: 2.0483891367912292

Epoch: 5| Step: 6
Training loss: 2.291696071624756
Validation loss: 2.0309569388628006

Epoch: 5| Step: 7
Training loss: 2.097297191619873
Validation loss: 2.0261509716510773

Epoch: 5| Step: 8
Training loss: 2.477504253387451
Validation loss: 2.02352304259936

Epoch: 5| Step: 9
Training loss: 2.489445686340332
Validation loss: 2.0208151936531067

Epoch: 5| Step: 10
Training loss: 2.295865535736084
Validation loss: 2.032755692799886

Epoch: 5| Step: 11
Training loss: 2.3629467487335205
Validation loss: 2.044710914293925

Epoch: 97| Step: 0
Training loss: 2.1383168697357178
Validation loss: 2.0463199267784753

Epoch: 5| Step: 1
Training loss: 1.8987863063812256
Validation loss: 2.0544483115275702

Epoch: 5| Step: 2
Training loss: 2.147509813308716
Validation loss: 2.0530383239189782

Epoch: 5| Step: 3
Training loss: 2.0534403324127197
Validation loss: 2.055955946445465

Epoch: 5| Step: 4
Training loss: 3.0155913829803467
Validation loss: 2.0556377470493317

Epoch: 5| Step: 5
Training loss: 2.329332113265991
Validation loss: 2.058837299545606

Epoch: 5| Step: 6
Training loss: 2.3610424995422363
Validation loss: 2.0556620558102927

Epoch: 5| Step: 7
Training loss: 2.0929274559020996
Validation loss: 2.0549952586491904

Epoch: 5| Step: 8
Training loss: 1.5645124912261963
Validation loss: 2.056078632672628

Epoch: 5| Step: 9
Training loss: 1.8520656824111938
Validation loss: 2.0534116278092065

Epoch: 5| Step: 10
Training loss: 2.8106091022491455
Validation loss: 2.049733137091001

Epoch: 5| Step: 11
Training loss: 3.3444814682006836
Validation loss: 2.0458296289046607

Epoch: 98| Step: 0
Training loss: 1.548267126083374
Validation loss: 2.0452052851517997

Epoch: 5| Step: 1
Training loss: 2.247012138366699
Validation loss: 2.0462860812743506

Epoch: 5| Step: 2
Training loss: 2.5271453857421875
Validation loss: 2.041641985376676

Epoch: 5| Step: 3
Training loss: 2.4779858589172363
Validation loss: 2.036052177349726

Epoch: 5| Step: 4
Training loss: 2.1253561973571777
Validation loss: 2.0263795952002206

Epoch: 5| Step: 5
Training loss: 2.1880407333374023
Validation loss: 2.0182962268590927

Epoch: 5| Step: 6
Training loss: 1.9539201259613037
Validation loss: 2.019548719127973

Epoch: 5| Step: 7
Training loss: 2.151035785675049
Validation loss: 2.02010540664196

Epoch: 5| Step: 8
Training loss: 2.4413974285125732
Validation loss: 2.036859780550003

Epoch: 5| Step: 9
Training loss: 2.3225722312927246
Validation loss: 2.0315929452578225

Epoch: 5| Step: 10
Training loss: 2.051546573638916
Validation loss: 2.056037977337837

Epoch: 5| Step: 11
Training loss: 2.374907970428467
Validation loss: 2.045822208126386

Epoch: 99| Step: 0
Training loss: 2.444164276123047
Validation loss: 2.055568421880404

Epoch: 5| Step: 1
Training loss: 2.1680476665496826
Validation loss: 2.0653997411330542

Epoch: 5| Step: 2
Training loss: 2.395463466644287
Validation loss: 2.0631042818228402

Epoch: 5| Step: 3
Training loss: 2.42933988571167
Validation loss: 2.0570010393857956

Epoch: 5| Step: 4
Training loss: 1.891488790512085
Validation loss: 2.04340627292792

Epoch: 5| Step: 5
Training loss: 1.968907117843628
Validation loss: 2.0380471299091973

Epoch: 5| Step: 6
Training loss: 2.4823386669158936
Validation loss: 2.031583016117414

Epoch: 5| Step: 7
Training loss: 2.203315258026123
Validation loss: 2.0269499023755393

Epoch: 5| Step: 8
Training loss: 2.0108134746551514
Validation loss: 2.0279071082671485

Epoch: 5| Step: 9
Training loss: 1.9647194147109985
Validation loss: 2.0293949991464615

Epoch: 5| Step: 10
Training loss: 2.040158748626709
Validation loss: 2.0189274648825326

Epoch: 5| Step: 11
Training loss: 1.528937816619873
Validation loss: 2.010796839992205

Epoch: 100| Step: 0
Training loss: 2.9239418506622314
Validation loss: 2.0193986346324286

Epoch: 5| Step: 1
Training loss: 2.2542123794555664
Validation loss: 2.0172971934080124

Epoch: 5| Step: 2
Training loss: 1.187488079071045
Validation loss: 2.0119118889172873

Epoch: 5| Step: 3
Training loss: 1.880048155784607
Validation loss: 2.0203039348125458

Epoch: 5| Step: 4
Training loss: 2.5635018348693848
Validation loss: 2.0177475263675055

Epoch: 5| Step: 5
Training loss: 2.2458014488220215
Validation loss: 2.027366583546003

Epoch: 5| Step: 6
Training loss: 2.1059422492980957
Validation loss: 2.0255747189124427

Epoch: 5| Step: 7
Training loss: 2.188936710357666
Validation loss: 2.0313179244597754

Epoch: 5| Step: 8
Training loss: 2.083665370941162
Validation loss: 2.0505797415971756

Epoch: 5| Step: 9
Training loss: 1.844956636428833
Validation loss: 2.0575717935959497

Epoch: 5| Step: 10
Training loss: 2.3522582054138184
Validation loss: 2.0491654376188913

Epoch: 5| Step: 11
Training loss: 2.8410606384277344
Validation loss: 2.0585372149944305

Testing loss: 1.6104051114843905
