Epoch: 1| Step: 0
Training loss: 5.4765119552612305
Validation loss: 5.368132968743642

Epoch: 5| Step: 1
Training loss: 5.9449543952941895
Validation loss: 5.366333623727162

Epoch: 5| Step: 2
Training loss: 5.123327732086182
Validation loss: 5.3646348516146345

Epoch: 5| Step: 3
Training loss: 4.800973892211914
Validation loss: 5.3628759781519575

Epoch: 5| Step: 4
Training loss: 5.463797092437744
Validation loss: 5.361074447631836

Epoch: 5| Step: 5
Training loss: 6.532845973968506
Validation loss: 5.359373092651367

Epoch: 5| Step: 6
Training loss: 5.431195259094238
Validation loss: 5.3574778238932295

Epoch: 5| Step: 7
Training loss: 5.159283638000488
Validation loss: 5.35548730691274

Epoch: 5| Step: 8
Training loss: 5.542944431304932
Validation loss: 5.353509326775868

Epoch: 5| Step: 9
Training loss: 5.725137710571289
Validation loss: 5.351373632748921

Epoch: 5| Step: 10
Training loss: 4.8318681716918945
Validation loss: 5.3491605917612715

Epoch: 5| Step: 11
Training loss: 3.7888638973236084
Validation loss: 5.346821924050649

Epoch: 2| Step: 0
Training loss: 5.388120174407959
Validation loss: 5.344250063101451

Epoch: 5| Step: 1
Training loss: 5.610287666320801
Validation loss: 5.3414875864982605

Epoch: 5| Step: 2
Training loss: 5.743365287780762
Validation loss: 5.338583429654439

Epoch: 5| Step: 3
Training loss: 6.211926460266113
Validation loss: 5.335493326187134

Epoch: 5| Step: 4
Training loss: 5.372447967529297
Validation loss: 5.332221448421478

Epoch: 5| Step: 5
Training loss: 4.867636680603027
Validation loss: 5.328770101070404

Epoch: 5| Step: 6
Training loss: 5.65031099319458
Validation loss: 5.325096706549327

Epoch: 5| Step: 7
Training loss: 5.328632831573486
Validation loss: 5.321111798286438

Epoch: 5| Step: 8
Training loss: 5.470141410827637
Validation loss: 5.317051351070404

Epoch: 5| Step: 9
Training loss: 4.723175048828125
Validation loss: 5.31275208791097

Epoch: 5| Step: 10
Training loss: 4.959239959716797
Validation loss: 5.308091918627421

Epoch: 5| Step: 11
Training loss: 5.561509132385254
Validation loss: 5.303410649299622

Epoch: 3| Step: 0
Training loss: 5.63851261138916
Validation loss: 5.298116226991017

Epoch: 5| Step: 1
Training loss: 6.424197196960449
Validation loss: 5.2928058703740435

Epoch: 5| Step: 2
Training loss: 4.697756767272949
Validation loss: 5.287190616130829

Epoch: 5| Step: 3
Training loss: 5.14072847366333
Validation loss: 5.281120220820109

Epoch: 5| Step: 4
Training loss: 5.110142230987549
Validation loss: 5.274999558925629

Epoch: 5| Step: 5
Training loss: 5.146231174468994
Validation loss: 5.268310944239299

Epoch: 5| Step: 6
Training loss: 5.174386024475098
Validation loss: 5.261304338773091

Epoch: 5| Step: 7
Training loss: 4.832293510437012
Validation loss: 5.253877500693004

Epoch: 5| Step: 8
Training loss: 5.641088962554932
Validation loss: 5.246330300966899

Epoch: 5| Step: 9
Training loss: 5.418643951416016
Validation loss: 5.238194366296132

Epoch: 5| Step: 10
Training loss: 5.302244663238525
Validation loss: 5.22991959253947

Epoch: 5| Step: 11
Training loss: 6.160091400146484
Validation loss: 5.221276740233104

Epoch: 4| Step: 0
Training loss: 4.121212959289551
Validation loss: 5.212015191713969

Epoch: 5| Step: 1
Training loss: 5.423450469970703
Validation loss: 5.203011850516002

Epoch: 5| Step: 2
Training loss: 5.3740949630737305
Validation loss: 5.1933238208293915

Epoch: 5| Step: 3
Training loss: 4.388821125030518
Validation loss: 5.183225154876709

Epoch: 5| Step: 4
Training loss: 5.035492897033691
Validation loss: 5.1734281579653425

Epoch: 5| Step: 5
Training loss: 4.845368385314941
Validation loss: 5.162921329339345

Epoch: 5| Step: 6
Training loss: 4.586794376373291
Validation loss: 5.152109046777089

Epoch: 5| Step: 7
Training loss: 6.824104309082031
Validation loss: 5.141340414683024

Epoch: 5| Step: 8
Training loss: 6.377805233001709
Validation loss: 5.130791743596395

Epoch: 5| Step: 9
Training loss: 5.167235374450684
Validation loss: 5.119849880536397

Epoch: 5| Step: 10
Training loss: 5.562054634094238
Validation loss: 5.108916064103444

Epoch: 5| Step: 11
Training loss: 4.517082691192627
Validation loss: 5.097471475601196

Epoch: 5| Step: 0
Training loss: 5.135599613189697
Validation loss: 5.086704174677531

Epoch: 5| Step: 1
Training loss: 5.124614715576172
Validation loss: 5.0759503444035845

Epoch: 5| Step: 2
Training loss: 5.15695858001709
Validation loss: 5.06511386235555

Epoch: 5| Step: 3
Training loss: 4.3783745765686035
Validation loss: 5.054079512755076

Epoch: 5| Step: 4
Training loss: 5.2141618728637695
Validation loss: 5.043476641178131

Epoch: 5| Step: 5
Training loss: 5.337374687194824
Validation loss: 5.032592157522838

Epoch: 5| Step: 6
Training loss: 4.24204158782959
Validation loss: 5.0221490661303205

Epoch: 5| Step: 7
Training loss: 5.41976261138916
Validation loss: 5.0120364626248675

Epoch: 5| Step: 8
Training loss: 5.230198860168457
Validation loss: 5.0014930963516235

Epoch: 5| Step: 9
Training loss: 5.471479892730713
Validation loss: 4.991358955701192

Epoch: 5| Step: 10
Training loss: 5.632904052734375
Validation loss: 4.981427550315857

Epoch: 5| Step: 11
Training loss: 4.482831954956055
Validation loss: 4.971532603104909

Epoch: 6| Step: 0
Training loss: 3.4509315490722656
Validation loss: 4.961796462535858

Epoch: 5| Step: 1
Training loss: 5.266486167907715
Validation loss: 4.952478885650635

Epoch: 5| Step: 2
Training loss: 5.027573108673096
Validation loss: 4.943313757578532

Epoch: 5| Step: 3
Training loss: 4.596202373504639
Validation loss: 4.9343218604723615

Epoch: 5| Step: 4
Training loss: 6.151759147644043
Validation loss: 4.924928704897563

Epoch: 5| Step: 5
Training loss: 5.5328216552734375
Validation loss: 4.915976007779439

Epoch: 5| Step: 6
Training loss: 4.106731414794922
Validation loss: 4.906897664070129

Epoch: 5| Step: 7
Training loss: 5.254101753234863
Validation loss: 4.897936562697093

Epoch: 5| Step: 8
Training loss: 5.335083961486816
Validation loss: 4.888928135236104

Epoch: 5| Step: 9
Training loss: 4.963072299957275
Validation loss: 4.880282302697499

Epoch: 5| Step: 10
Training loss: 5.677833557128906
Validation loss: 4.870888908704122

Epoch: 5| Step: 11
Training loss: 3.1682348251342773
Validation loss: 4.861542840798696

Epoch: 7| Step: 0
Training loss: 4.527132987976074
Validation loss: 4.852908293406169

Epoch: 5| Step: 1
Training loss: 4.97511625289917
Validation loss: 4.84395033121109

Epoch: 5| Step: 2
Training loss: 4.052060604095459
Validation loss: 4.835725506146749

Epoch: 5| Step: 3
Training loss: 5.236092567443848
Validation loss: 4.827590564886729

Epoch: 5| Step: 4
Training loss: 3.7262115478515625
Validation loss: 4.819584866364797

Epoch: 5| Step: 5
Training loss: 5.539137840270996
Validation loss: 4.811883707841237

Epoch: 5| Step: 6
Training loss: 4.35699987411499
Validation loss: 4.803917010625203

Epoch: 5| Step: 7
Training loss: 5.927515506744385
Validation loss: 4.795815318822861

Epoch: 5| Step: 8
Training loss: 4.866771221160889
Validation loss: 4.788163423538208

Epoch: 5| Step: 9
Training loss: 6.707850456237793
Validation loss: 4.780328293641408

Epoch: 5| Step: 10
Training loss: 4.247101783752441
Validation loss: 4.772413810094197

Epoch: 5| Step: 11
Training loss: 3.512289524078369
Validation loss: 4.7645679116249084

Epoch: 8| Step: 0
Training loss: 5.280874729156494
Validation loss: 4.756160577138265

Epoch: 5| Step: 1
Training loss: 4.666003704071045
Validation loss: 4.7485037843386335

Epoch: 5| Step: 2
Training loss: 4.708065986633301
Validation loss: 4.740484833717346

Epoch: 5| Step: 3
Training loss: 4.751575469970703
Validation loss: 4.732841432094574

Epoch: 5| Step: 4
Training loss: 4.8639607429504395
Validation loss: 4.725284953912099

Epoch: 5| Step: 5
Training loss: 4.604292869567871
Validation loss: 4.717761377493541

Epoch: 5| Step: 6
Training loss: 4.679255485534668
Validation loss: 4.710353950659434

Epoch: 5| Step: 7
Training loss: 6.522647857666016
Validation loss: 4.703122635682424

Epoch: 5| Step: 8
Training loss: 4.063999652862549
Validation loss: 4.695752441883087

Epoch: 5| Step: 9
Training loss: 4.3095011711120605
Validation loss: 4.688495775063832

Epoch: 5| Step: 10
Training loss: 4.305875301361084
Validation loss: 4.681360383828481

Epoch: 5| Step: 11
Training loss: 5.672773838043213
Validation loss: 4.6739850242932635

Epoch: 9| Step: 0
Training loss: 5.0575995445251465
Validation loss: 4.6672627329826355

Epoch: 5| Step: 1
Training loss: 5.175760746002197
Validation loss: 4.659930070241292

Epoch: 5| Step: 2
Training loss: 4.437534809112549
Validation loss: 4.6528633038202925

Epoch: 5| Step: 3
Training loss: 4.800863742828369
Validation loss: 4.645585477352142

Epoch: 5| Step: 4
Training loss: 5.427711486816406
Validation loss: 4.6378355622291565

Epoch: 5| Step: 5
Training loss: 3.4457831382751465
Validation loss: 4.630903522173564

Epoch: 5| Step: 6
Training loss: 4.565479755401611
Validation loss: 4.6240440507729845

Epoch: 5| Step: 7
Training loss: 4.966573715209961
Validation loss: 4.616881757974625

Epoch: 5| Step: 8
Training loss: 4.607365608215332
Validation loss: 4.6095748245716095

Epoch: 5| Step: 9
Training loss: 4.675518035888672
Validation loss: 4.602195958296458

Epoch: 5| Step: 10
Training loss: 4.8361639976501465
Validation loss: 4.593787332375844

Epoch: 5| Step: 11
Training loss: 4.819882392883301
Validation loss: 4.584733217954636

Epoch: 10| Step: 0
Training loss: 4.552109718322754
Validation loss: 4.575216829776764

Epoch: 5| Step: 1
Training loss: 5.028441429138184
Validation loss: 4.566668550173442

Epoch: 5| Step: 2
Training loss: 5.298959732055664
Validation loss: 4.5601069529851275

Epoch: 5| Step: 3
Training loss: 5.016034126281738
Validation loss: 4.553468426068624

Epoch: 5| Step: 4
Training loss: 4.6457343101501465
Validation loss: 4.545383234818776

Epoch: 5| Step: 5
Training loss: 3.403918504714966
Validation loss: 4.5375816822052

Epoch: 5| Step: 6
Training loss: 5.516013145446777
Validation loss: 4.5310156643390656

Epoch: 5| Step: 7
Training loss: 5.288951396942139
Validation loss: 4.52401065826416

Epoch: 5| Step: 8
Training loss: 3.976397752761841
Validation loss: 4.517753005027771

Epoch: 5| Step: 9
Training loss: 4.053627967834473
Validation loss: 4.51033013065656

Epoch: 5| Step: 10
Training loss: 4.375891208648682
Validation loss: 4.503590444723765

Epoch: 5| Step: 11
Training loss: 4.1573662757873535
Validation loss: 4.496944705645244

Epoch: 11| Step: 0
Training loss: 5.026670455932617
Validation loss: 4.49031600356102

Epoch: 5| Step: 1
Training loss: 4.110128402709961
Validation loss: 4.483788112799327

Epoch: 5| Step: 2
Training loss: 4.386290550231934
Validation loss: 4.477419366439183

Epoch: 5| Step: 3
Training loss: 4.008544921875
Validation loss: 4.47096433242162

Epoch: 5| Step: 4
Training loss: 4.409992218017578
Validation loss: 4.464109639326732

Epoch: 5| Step: 5
Training loss: 4.409279823303223
Validation loss: 4.458656241496404

Epoch: 5| Step: 6
Training loss: 4.502499580383301
Validation loss: 4.452959299087524

Epoch: 5| Step: 7
Training loss: 4.6522674560546875
Validation loss: 4.446848849455516

Epoch: 5| Step: 8
Training loss: 5.210713863372803
Validation loss: 4.440897047519684

Epoch: 5| Step: 9
Training loss: 5.402283668518066
Validation loss: 4.435016572475433

Epoch: 5| Step: 10
Training loss: 4.646214485168457
Validation loss: 4.429638206958771

Epoch: 5| Step: 11
Training loss: 2.0777926445007324
Validation loss: 4.423894176880519

Epoch: 12| Step: 0
Training loss: 4.581495761871338
Validation loss: 4.417995502551396

Epoch: 5| Step: 1
Training loss: 4.453425884246826
Validation loss: 4.413532217343648

Epoch: 5| Step: 2
Training loss: 5.6150641441345215
Validation loss: 4.409347057342529

Epoch: 5| Step: 3
Training loss: 4.266758441925049
Validation loss: 4.40402630964915

Epoch: 5| Step: 4
Training loss: 4.751949310302734
Validation loss: 4.398504743973414

Epoch: 5| Step: 5
Training loss: 4.425029754638672
Validation loss: 4.392041842142741

Epoch: 5| Step: 6
Training loss: 4.045376777648926
Validation loss: 4.386758844057719

Epoch: 5| Step: 7
Training loss: 4.270665645599365
Validation loss: 4.3828957080841064

Epoch: 5| Step: 8
Training loss: 4.22515344619751
Validation loss: 4.37771060069402

Epoch: 5| Step: 9
Training loss: 5.3599090576171875
Validation loss: 4.372107485930125

Epoch: 5| Step: 10
Training loss: 3.4955387115478516
Validation loss: 4.36687429745992

Epoch: 5| Step: 11
Training loss: 5.133050918579102
Validation loss: 4.362198382616043

Epoch: 13| Step: 0
Training loss: 4.661815643310547
Validation loss: 4.35749610265096

Epoch: 5| Step: 1
Training loss: 3.73408579826355
Validation loss: 4.352095067501068

Epoch: 5| Step: 2
Training loss: 4.478440284729004
Validation loss: 4.346761544545491

Epoch: 5| Step: 3
Training loss: 5.126839637756348
Validation loss: 4.34156518181165

Epoch: 5| Step: 4
Training loss: 4.2137651443481445
Validation loss: 4.335954238971074

Epoch: 5| Step: 5
Training loss: 4.7500176429748535
Validation loss: 4.332215964794159

Epoch: 5| Step: 6
Training loss: 4.911609172821045
Validation loss: 4.326381415128708

Epoch: 5| Step: 7
Training loss: 4.690237522125244
Validation loss: 4.321451584498088

Epoch: 5| Step: 8
Training loss: 3.890658140182495
Validation loss: 4.316712141036987

Epoch: 5| Step: 9
Training loss: 4.527077674865723
Validation loss: 4.311931272347768

Epoch: 5| Step: 10
Training loss: 4.076219081878662
Validation loss: 4.307436307271321

Epoch: 5| Step: 11
Training loss: 4.175885200500488
Validation loss: 4.3032812376817065

Epoch: 14| Step: 0
Training loss: 4.540652275085449
Validation loss: 4.298200945059459

Epoch: 5| Step: 1
Training loss: 3.9519619941711426
Validation loss: 4.293336898088455

Epoch: 5| Step: 2
Training loss: 4.919076919555664
Validation loss: 4.288492679595947

Epoch: 5| Step: 3
Training loss: 4.071761131286621
Validation loss: 4.283477604389191

Epoch: 5| Step: 4
Training loss: 4.851833343505859
Validation loss: 4.280000279347102

Epoch: 5| Step: 5
Training loss: 3.8777732849121094
Validation loss: 4.275008867184321

Epoch: 5| Step: 6
Training loss: 4.295580863952637
Validation loss: 4.27016681432724

Epoch: 5| Step: 7
Training loss: 5.547788143157959
Validation loss: 4.264717002709706

Epoch: 5| Step: 8
Training loss: 4.720552921295166
Validation loss: 4.260285635789235

Epoch: 5| Step: 9
Training loss: 3.6611924171447754
Validation loss: 4.25552757581075

Epoch: 5| Step: 10
Training loss: 3.9233994483947754
Validation loss: 4.2511734167734785

Epoch: 5| Step: 11
Training loss: 4.675745487213135
Validation loss: 4.2459584176540375

Epoch: 15| Step: 0
Training loss: 4.655806064605713
Validation loss: 4.24153267343839

Epoch: 5| Step: 1
Training loss: 3.595877170562744
Validation loss: 4.236301153898239

Epoch: 5| Step: 2
Training loss: 3.635819673538208
Validation loss: 4.231779366731644

Epoch: 5| Step: 3
Training loss: 4.102160930633545
Validation loss: 4.226966381072998

Epoch: 5| Step: 4
Training loss: 4.718970775604248
Validation loss: 4.223072896401088

Epoch: 5| Step: 5
Training loss: 5.458642959594727
Validation loss: 4.217080752054851

Epoch: 5| Step: 6
Training loss: 4.561178684234619
Validation loss: 4.211992591619492

Epoch: 5| Step: 7
Training loss: 4.161055564880371
Validation loss: 4.207303623358409

Epoch: 5| Step: 8
Training loss: 4.509367942810059
Validation loss: 4.202229142189026

Epoch: 5| Step: 9
Training loss: 5.408543586730957
Validation loss: 4.197401424249013

Epoch: 5| Step: 10
Training loss: 3.341890811920166
Validation loss: 4.192760547002156

Epoch: 5| Step: 11
Training loss: 2.791851758956909
Validation loss: 4.187856157620748

Epoch: 16| Step: 0
Training loss: 4.1774983406066895
Validation loss: 4.183123409748077

Epoch: 5| Step: 1
Training loss: 3.8681540489196777
Validation loss: 4.1785353521505995

Epoch: 5| Step: 2
Training loss: 3.769801378250122
Validation loss: 4.174964954455693

Epoch: 5| Step: 3
Training loss: 5.249636650085449
Validation loss: 4.169842878977458

Epoch: 5| Step: 4
Training loss: 4.160305023193359
Validation loss: 4.164370000362396

Epoch: 5| Step: 5
Training loss: 4.238121032714844
Validation loss: 4.159473538398743

Epoch: 5| Step: 6
Training loss: 3.8391311168670654
Validation loss: 4.155745089054108

Epoch: 5| Step: 7
Training loss: 5.067268371582031
Validation loss: 4.152282635370891

Epoch: 5| Step: 8
Training loss: 3.985163450241089
Validation loss: 4.147197812795639

Epoch: 5| Step: 9
Training loss: 5.431363105773926
Validation loss: 4.141838560501735

Epoch: 5| Step: 10
Training loss: 3.3530547618865967
Validation loss: 4.137097825606664

Epoch: 5| Step: 11
Training loss: 4.893489837646484
Validation loss: 4.131912956635158

Epoch: 17| Step: 0
Training loss: 4.464926719665527
Validation loss: 4.127597649892171

Epoch: 5| Step: 1
Training loss: 3.7251930236816406
Validation loss: 4.122231036424637

Epoch: 5| Step: 2
Training loss: 3.2968082427978516
Validation loss: 4.117135524749756

Epoch: 5| Step: 3
Training loss: 3.6607024669647217
Validation loss: 4.111878017584483

Epoch: 5| Step: 4
Training loss: 4.573391914367676
Validation loss: 4.107669174671173

Epoch: 5| Step: 5
Training loss: 5.039631366729736
Validation loss: 4.10228767991066

Epoch: 5| Step: 6
Training loss: 4.564403533935547
Validation loss: 4.096975634495418

Epoch: 5| Step: 7
Training loss: 4.171307563781738
Validation loss: 4.091875672340393

Epoch: 5| Step: 8
Training loss: 4.166847229003906
Validation loss: 4.087435523668925

Epoch: 5| Step: 9
Training loss: 5.095580101013184
Validation loss: 4.082066059112549

Epoch: 5| Step: 10
Training loss: 3.913179397583008
Validation loss: 4.076655089855194

Epoch: 5| Step: 11
Training loss: 4.220877647399902
Validation loss: 4.071277588605881

Epoch: 18| Step: 0
Training loss: 3.5405964851379395
Validation loss: 4.067712803681691

Epoch: 5| Step: 1
Training loss: 3.1384270191192627
Validation loss: 4.0621238052845

Epoch: 5| Step: 2
Training loss: 3.776782274246216
Validation loss: 4.0576873024304705

Epoch: 5| Step: 3
Training loss: 3.5185794830322266
Validation loss: 4.053556561470032

Epoch: 5| Step: 4
Training loss: 4.979926109313965
Validation loss: 4.048946559429169

Epoch: 5| Step: 5
Training loss: 4.781696796417236
Validation loss: 4.0438770453135175

Epoch: 5| Step: 6
Training loss: 4.699679374694824
Validation loss: 4.038599530855815

Epoch: 5| Step: 7
Training loss: 4.8173627853393555
Validation loss: 4.034265259901683

Epoch: 5| Step: 8
Training loss: 4.279814720153809
Validation loss: 4.029445022344589

Epoch: 5| Step: 9
Training loss: 5.0663676261901855
Validation loss: 4.024177034695943

Epoch: 5| Step: 10
Training loss: 3.726977586746216
Validation loss: 4.020670811335246

Epoch: 5| Step: 11
Training loss: 2.844886302947998
Validation loss: 4.015112439791362

Epoch: 19| Step: 0
Training loss: 4.560143947601318
Validation loss: 4.011142532030742

Epoch: 5| Step: 1
Training loss: 3.546039581298828
Validation loss: 4.006437838077545

Epoch: 5| Step: 2
Training loss: 4.151575565338135
Validation loss: 4.0012469093004865

Epoch: 5| Step: 3
Training loss: 4.739091873168945
Validation loss: 3.996130734682083

Epoch: 5| Step: 4
Training loss: 4.548159599304199
Validation loss: 3.9926978051662445

Epoch: 5| Step: 5
Training loss: 4.4334797859191895
Validation loss: 3.9875763257344565

Epoch: 5| Step: 6
Training loss: 4.512795925140381
Validation loss: 3.9832937916119895

Epoch: 5| Step: 7
Training loss: 3.881181001663208
Validation loss: 3.977359970410665

Epoch: 5| Step: 8
Training loss: 3.882396697998047
Validation loss: 3.9728535612424216

Epoch: 5| Step: 9
Training loss: 4.230954647064209
Validation loss: 3.9680732985337577

Epoch: 5| Step: 10
Training loss: 3.1348204612731934
Validation loss: 3.963764041662216

Epoch: 5| Step: 11
Training loss: 3.4103593826293945
Validation loss: 3.9591488043467202

Epoch: 20| Step: 0
Training loss: 4.929355621337891
Validation loss: 3.95630943775177

Epoch: 5| Step: 1
Training loss: 3.09904146194458
Validation loss: 3.951414863268534

Epoch: 5| Step: 2
Training loss: 4.114971160888672
Validation loss: 3.9474677443504333

Epoch: 5| Step: 3
Training loss: 4.585496425628662
Validation loss: 3.9426452616850534

Epoch: 5| Step: 4
Training loss: 4.41670036315918
Validation loss: 3.938661257425944

Epoch: 5| Step: 5
Training loss: 3.549912929534912
Validation loss: 3.934024453163147

Epoch: 5| Step: 6
Training loss: 4.6062798500061035
Validation loss: 3.9293230970700583

Epoch: 5| Step: 7
Training loss: 3.52349853515625
Validation loss: 3.9243196845054626

Epoch: 5| Step: 8
Training loss: 3.402052402496338
Validation loss: 3.9197541177272797

Epoch: 5| Step: 9
Training loss: 4.481568336486816
Validation loss: 3.9155416190624237

Epoch: 5| Step: 10
Training loss: 4.142211437225342
Validation loss: 3.9107700884342194

Epoch: 5| Step: 11
Training loss: 4.2259907722473145
Validation loss: 3.905756632486979

Epoch: 21| Step: 0
Training loss: 3.4641456604003906
Validation loss: 3.9015172719955444

Epoch: 5| Step: 1
Training loss: 3.7207839488983154
Validation loss: 3.89688049753507

Epoch: 5| Step: 2
Training loss: 3.1709609031677246
Validation loss: 3.892501711845398

Epoch: 5| Step: 3
Training loss: 3.800499677658081
Validation loss: 3.8869747320810952

Epoch: 5| Step: 4
Training loss: 4.227084159851074
Validation loss: 3.8834207554658255

Epoch: 5| Step: 5
Training loss: 4.3981757164001465
Validation loss: 3.87905752658844

Epoch: 5| Step: 6
Training loss: 3.9442086219787598
Validation loss: 3.874834289153417

Epoch: 5| Step: 7
Training loss: 5.061466217041016
Validation loss: 3.870082507530848

Epoch: 5| Step: 8
Training loss: 3.7230477333068848
Validation loss: 3.8666247129440308

Epoch: 5| Step: 9
Training loss: 4.25412654876709
Validation loss: 3.8607274492581687

Epoch: 5| Step: 10
Training loss: 4.69991397857666
Validation loss: 3.8564035892486572

Epoch: 5| Step: 11
Training loss: 3.287731170654297
Validation loss: 3.8528296252091727

Epoch: 22| Step: 0
Training loss: 3.553899049758911
Validation loss: 3.8483194212118783

Epoch: 5| Step: 1
Training loss: 4.225949287414551
Validation loss: 3.843768378098806

Epoch: 5| Step: 2
Training loss: 4.076561450958252
Validation loss: 3.8398432234923043

Epoch: 5| Step: 3
Training loss: 4.009432315826416
Validation loss: 3.8345117270946503

Epoch: 5| Step: 4
Training loss: 4.158385753631592
Validation loss: 3.8307816485563913

Epoch: 5| Step: 5
Training loss: 3.5113651752471924
Validation loss: 3.825575977563858

Epoch: 5| Step: 6
Training loss: 4.2568817138671875
Validation loss: 3.8208638528982797

Epoch: 5| Step: 7
Training loss: 4.106381416320801
Validation loss: 3.817157099644343

Epoch: 5| Step: 8
Training loss: 3.8760154247283936
Validation loss: 3.812983105580012

Epoch: 5| Step: 9
Training loss: 3.348473072052002
Validation loss: 3.807927946249644

Epoch: 5| Step: 10
Training loss: 4.60853910446167
Validation loss: 3.804159571727117

Epoch: 5| Step: 11
Training loss: 4.237532615661621
Validation loss: 3.7995637555917106

Epoch: 23| Step: 0
Training loss: 4.7128424644470215
Validation loss: 3.794629693031311

Epoch: 5| Step: 1
Training loss: 3.014730215072632
Validation loss: 3.791056215763092

Epoch: 5| Step: 2
Training loss: 3.804112195968628
Validation loss: 3.7873205045859017

Epoch: 5| Step: 3
Training loss: 3.6879115104675293
Validation loss: 3.7825368444124856

Epoch: 5| Step: 4
Training loss: 3.6022086143493652
Validation loss: 3.7788525323073068

Epoch: 5| Step: 5
Training loss: 4.78262186050415
Validation loss: 3.774606982866923

Epoch: 5| Step: 6
Training loss: 4.42876672744751
Validation loss: 3.7698925932248435

Epoch: 5| Step: 7
Training loss: 3.221125841140747
Validation loss: 3.7657347122828164

Epoch: 5| Step: 8
Training loss: 4.2345290184021
Validation loss: 3.762189030647278

Epoch: 5| Step: 9
Training loss: 4.150969982147217
Validation loss: 3.7564972639083862

Epoch: 5| Step: 10
Training loss: 3.3396904468536377
Validation loss: 3.7530634105205536

Epoch: 5| Step: 11
Training loss: 5.26453971862793
Validation loss: 3.748988022406896

Epoch: 24| Step: 0
Training loss: 3.378882646560669
Validation loss: 3.744582454363505

Epoch: 5| Step: 1
Training loss: 3.9368977546691895
Validation loss: 3.740137130022049

Epoch: 5| Step: 2
Training loss: 3.748318910598755
Validation loss: 3.7358168065547943

Epoch: 5| Step: 3
Training loss: 3.0062222480773926
Validation loss: 3.7316119372844696

Epoch: 5| Step: 4
Training loss: 4.382079124450684
Validation loss: 3.7276355226834617

Epoch: 5| Step: 5
Training loss: 3.6062698364257812
Validation loss: 3.723466863234838

Epoch: 5| Step: 6
Training loss: 4.013176441192627
Validation loss: 3.7186631858348846

Epoch: 5| Step: 7
Training loss: 4.061257362365723
Validation loss: 3.7133989334106445

Epoch: 5| Step: 8
Training loss: 4.787686824798584
Validation loss: 3.7111356059710183

Epoch: 5| Step: 9
Training loss: 3.501370906829834
Validation loss: 3.7063335279623666

Epoch: 5| Step: 10
Training loss: 4.304476261138916
Validation loss: 3.701942394177119

Epoch: 5| Step: 11
Training loss: 3.7974298000335693
Validation loss: 3.6979825695355735

Epoch: 25| Step: 0
Training loss: 3.497274875640869
Validation loss: 3.693855047225952

Epoch: 5| Step: 1
Training loss: 4.1799468994140625
Validation loss: 3.68960768977801

Epoch: 5| Step: 2
Training loss: 3.371826648712158
Validation loss: 3.686591853698095

Epoch: 5| Step: 3
Training loss: 4.21627950668335
Validation loss: 3.6818614999453225

Epoch: 5| Step: 4
Training loss: 3.9969635009765625
Validation loss: 3.678406447172165

Epoch: 5| Step: 5
Training loss: 3.442150831222534
Validation loss: 3.6749177674452462

Epoch: 5| Step: 6
Training loss: 3.7427592277526855
Validation loss: 3.670212705930074

Epoch: 5| Step: 7
Training loss: 3.3734512329101562
Validation loss: 3.6664059360822043

Epoch: 5| Step: 8
Training loss: 3.899409055709839
Validation loss: 3.662436137596766

Epoch: 5| Step: 9
Training loss: 3.6384682655334473
Validation loss: 3.658735066652298

Epoch: 5| Step: 10
Training loss: 4.979957580566406
Validation loss: 3.6554343700408936

Epoch: 5| Step: 11
Training loss: 3.130168914794922
Validation loss: 3.6501951615015664

Epoch: 26| Step: 0
Training loss: 3.508737564086914
Validation loss: 3.6452662547429404

Epoch: 5| Step: 1
Training loss: 4.0938825607299805
Validation loss: 3.6420907080173492

Epoch: 5| Step: 2
Training loss: 4.3882975578308105
Validation loss: 3.639060745636622

Epoch: 5| Step: 3
Training loss: 3.4532418251037598
Validation loss: 3.6339780489603677

Epoch: 5| Step: 4
Training loss: 4.083096027374268
Validation loss: 3.629738579193751

Epoch: 5| Step: 5
Training loss: 3.6336207389831543
Validation loss: 3.6250853141148887

Epoch: 5| Step: 6
Training loss: 3.40423583984375
Validation loss: 3.620634784301122

Epoch: 5| Step: 7
Training loss: 4.544792175292969
Validation loss: 3.617259760697683

Epoch: 5| Step: 8
Training loss: 3.5955138206481934
Validation loss: 3.613690664370855

Epoch: 5| Step: 9
Training loss: 3.973052978515625
Validation loss: 3.608935604492823

Epoch: 5| Step: 10
Training loss: 2.959808826446533
Validation loss: 3.6046866178512573

Epoch: 5| Step: 11
Training loss: 3.8872272968292236
Validation loss: 3.6004438598950705

Epoch: 27| Step: 0
Training loss: 3.1338295936584473
Validation loss: 3.59639972448349

Epoch: 5| Step: 1
Training loss: 3.824558973312378
Validation loss: 3.593773086865743

Epoch: 5| Step: 2
Training loss: 3.9718422889709473
Validation loss: 3.586938420931498

Epoch: 5| Step: 3
Training loss: 3.911935329437256
Validation loss: 3.583519866069158

Epoch: 5| Step: 4
Training loss: 3.9800562858581543
Validation loss: 3.581486930449804

Epoch: 5| Step: 5
Training loss: 3.9057273864746094
Validation loss: 3.5759023626645408

Epoch: 5| Step: 6
Training loss: 2.990783214569092
Validation loss: 3.572381228208542

Epoch: 5| Step: 7
Training loss: 3.874988079071045
Validation loss: 3.56764085094134

Epoch: 5| Step: 8
Training loss: 3.610952377319336
Validation loss: 3.5622862378756204

Epoch: 5| Step: 9
Training loss: 3.8257110118865967
Validation loss: 3.5579308768113456

Epoch: 5| Step: 10
Training loss: 4.641146659851074
Validation loss: 3.554290235042572

Epoch: 5| Step: 11
Training loss: 1.1740145683288574
Validation loss: 3.5509861608346305

Epoch: 28| Step: 0
Training loss: 3.9820334911346436
Validation loss: 3.5476894974708557

Epoch: 5| Step: 1
Training loss: 3.7680201530456543
Validation loss: 3.544295161962509

Epoch: 5| Step: 2
Training loss: 2.6878342628479004
Validation loss: 3.5413528978824615

Epoch: 5| Step: 3
Training loss: 3.8369545936584473
Validation loss: 3.5364204943180084

Epoch: 5| Step: 4
Training loss: 3.9381511211395264
Validation loss: 3.532618075609207

Epoch: 5| Step: 5
Training loss: 4.084261417388916
Validation loss: 3.528883785009384

Epoch: 5| Step: 6
Training loss: 2.976605176925659
Validation loss: 3.525631904602051

Epoch: 5| Step: 7
Training loss: 3.513582706451416
Validation loss: 3.5212363998095193

Epoch: 5| Step: 8
Training loss: 4.239903926849365
Validation loss: 3.5174235800902047

Epoch: 5| Step: 9
Training loss: 3.7102863788604736
Validation loss: 3.5132651229699454

Epoch: 5| Step: 10
Training loss: 3.5409481525421143
Validation loss: 3.509446839491526

Epoch: 5| Step: 11
Training loss: 5.489072799682617
Validation loss: 3.505858530600866

Epoch: 29| Step: 0
Training loss: 4.054556846618652
Validation loss: 3.5012031892935433

Epoch: 5| Step: 1
Training loss: 2.9671630859375
Validation loss: 3.49714403351148

Epoch: 5| Step: 2
Training loss: 3.8884975910186768
Validation loss: 3.4939254224300385

Epoch: 5| Step: 3
Training loss: 4.355538845062256
Validation loss: 3.4896853864192963

Epoch: 5| Step: 4
Training loss: 3.7225303649902344
Validation loss: 3.484968433777491

Epoch: 5| Step: 5
Training loss: 3.31451416015625
Validation loss: 3.4809940457344055

Epoch: 5| Step: 6
Training loss: 3.8566222190856934
Validation loss: 3.4772602121035256

Epoch: 5| Step: 7
Training loss: 3.836437940597534
Validation loss: 3.4729654590288797

Epoch: 5| Step: 8
Training loss: 4.087472915649414
Validation loss: 3.4687367975711823

Epoch: 5| Step: 9
Training loss: 2.559485912322998
Validation loss: 3.4641195436318717

Epoch: 5| Step: 10
Training loss: 3.7098610401153564
Validation loss: 3.4604575435320535

Epoch: 5| Step: 11
Training loss: 2.5748214721679688
Validation loss: 3.4569733440876007

Epoch: 30| Step: 0
Training loss: 2.231414318084717
Validation loss: 3.455665647983551

Epoch: 5| Step: 1
Training loss: 3.6665263175964355
Validation loss: 3.4498578011989594

Epoch: 5| Step: 2
Training loss: 3.186790943145752
Validation loss: 3.4449737866719565

Epoch: 5| Step: 3
Training loss: 3.9386794567108154
Validation loss: 3.4422688682874045

Epoch: 5| Step: 4
Training loss: 3.3755481243133545
Validation loss: 3.439413160085678

Epoch: 5| Step: 5
Training loss: 3.7146077156066895
Validation loss: 3.4360620379447937

Epoch: 5| Step: 6
Training loss: 3.4898858070373535
Validation loss: 3.432399849096934

Epoch: 5| Step: 7
Training loss: 3.763317823410034
Validation loss: 3.428484340508779

Epoch: 5| Step: 8
Training loss: 4.364908695220947
Validation loss: 3.424299438794454

Epoch: 5| Step: 9
Training loss: 4.1870293617248535
Validation loss: 3.41986420750618

Epoch: 5| Step: 10
Training loss: 3.832190990447998
Validation loss: 3.4163271288077035

Epoch: 5| Step: 11
Training loss: 2.9353606700897217
Validation loss: 3.41234960158666

Epoch: 31| Step: 0
Training loss: 3.514942169189453
Validation loss: 3.408332178990046

Epoch: 5| Step: 1
Training loss: 3.9515137672424316
Validation loss: 3.4061399102211

Epoch: 5| Step: 2
Training loss: 2.5904464721679688
Validation loss: 3.401404062906901

Epoch: 5| Step: 3
Training loss: 3.7257606983184814
Validation loss: 3.3955543637275696

Epoch: 5| Step: 4
Training loss: 3.8059372901916504
Validation loss: 3.3914067447185516

Epoch: 5| Step: 5
Training loss: 3.94288969039917
Validation loss: 3.3873924016952515

Epoch: 5| Step: 6
Training loss: 3.1817867755889893
Validation loss: 3.3845056295394897

Epoch: 5| Step: 7
Training loss: 2.664933681488037
Validation loss: 3.3809860348701477

Epoch: 5| Step: 8
Training loss: 3.550928831100464
Validation loss: 3.3765325446923575

Epoch: 5| Step: 9
Training loss: 4.240808963775635
Validation loss: 3.371817171573639

Epoch: 5| Step: 10
Training loss: 3.78507924079895
Validation loss: 3.3679771721363068

Epoch: 5| Step: 11
Training loss: 4.359757423400879
Validation loss: 3.3641275266806283

Epoch: 32| Step: 0
Training loss: 2.965059995651245
Validation loss: 3.35930335521698

Epoch: 5| Step: 1
Training loss: 3.9564335346221924
Validation loss: 3.354900081952413

Epoch: 5| Step: 2
Training loss: 3.272022247314453
Validation loss: 3.3507150212923684

Epoch: 5| Step: 3
Training loss: 3.4892265796661377
Validation loss: 3.3466355999310813

Epoch: 5| Step: 4
Training loss: 3.9430034160614014
Validation loss: 3.3423498968283334

Epoch: 5| Step: 5
Training loss: 3.5862507820129395
Validation loss: 3.3381759027640023

Epoch: 5| Step: 6
Training loss: 3.134671449661255
Validation loss: 3.3340446949005127

Epoch: 5| Step: 7
Training loss: 3.481393814086914
Validation loss: 3.3299570977687836

Epoch: 5| Step: 8
Training loss: 3.4671294689178467
Validation loss: 3.3250811298688254

Epoch: 5| Step: 9
Training loss: 4.29461145401001
Validation loss: 3.320619056622187

Epoch: 5| Step: 10
Training loss: 3.19148588180542
Validation loss: 3.3164817293485007

Epoch: 5| Step: 11
Training loss: 2.6362595558166504
Validation loss: 3.312567194302877

Epoch: 33| Step: 0
Training loss: 3.1960561275482178
Validation loss: 3.308748573064804

Epoch: 5| Step: 1
Training loss: 3.593508243560791
Validation loss: 3.304931412140528

Epoch: 5| Step: 2
Training loss: 3.535634994506836
Validation loss: 3.3015181918938956

Epoch: 5| Step: 3
Training loss: 3.5610191822052
Validation loss: 3.296433965365092

Epoch: 5| Step: 4
Training loss: 3.3414928913116455
Validation loss: 3.292535444100698

Epoch: 5| Step: 5
Training loss: 3.0227763652801514
Validation loss: 3.2891264657179513

Epoch: 5| Step: 6
Training loss: 3.7269184589385986
Validation loss: 3.2853626012802124

Epoch: 5| Step: 7
Training loss: 3.10127329826355
Validation loss: 3.281371454397837

Epoch: 5| Step: 8
Training loss: 3.2134411334991455
Validation loss: 3.2769054571787515

Epoch: 5| Step: 9
Training loss: 3.49568510055542
Validation loss: 3.2736619214216867

Epoch: 5| Step: 10
Training loss: 4.116603851318359
Validation loss: 3.2699637512365975

Epoch: 5| Step: 11
Training loss: 4.521986961364746
Validation loss: 3.266016513109207

Epoch: 34| Step: 0
Training loss: 3.2240242958068848
Validation loss: 3.263176828622818

Epoch: 5| Step: 1
Training loss: 3.132350206375122
Validation loss: 3.2592694560686746

Epoch: 5| Step: 2
Training loss: 3.0006103515625
Validation loss: 3.2557484904925027

Epoch: 5| Step: 3
Training loss: 3.1466827392578125
Validation loss: 3.2518232067426047

Epoch: 5| Step: 4
Training loss: 3.360278367996216
Validation loss: 3.2482330401738486

Epoch: 5| Step: 5
Training loss: 4.293066501617432
Validation loss: 3.2450377146402993

Epoch: 5| Step: 6
Training loss: 3.5046253204345703
Validation loss: 3.241220543781916

Epoch: 5| Step: 7
Training loss: 3.1061620712280273
Validation loss: 3.2379436691602073

Epoch: 5| Step: 8
Training loss: 3.7421257495880127
Validation loss: 3.2341374357541404

Epoch: 5| Step: 9
Training loss: 4.087978363037109
Validation loss: 3.2301278511683145

Epoch: 5| Step: 10
Training loss: 3.236311674118042
Validation loss: 3.2260502676169076

Epoch: 5| Step: 11
Training loss: 2.412203788757324
Validation loss: 3.2228632668654122

Epoch: 35| Step: 0
Training loss: 3.0520734786987305
Validation loss: 3.2190275688966117

Epoch: 5| Step: 1
Training loss: 3.698288679122925
Validation loss: 3.214273691177368

Epoch: 5| Step: 2
Training loss: 4.03719425201416
Validation loss: 3.211462358633677

Epoch: 5| Step: 3
Training loss: 3.5693047046661377
Validation loss: 3.207338591416677

Epoch: 5| Step: 4
Training loss: 2.7368791103363037
Validation loss: 3.2034162978331246

Epoch: 5| Step: 5
Training loss: 3.620461940765381
Validation loss: 3.1996718446413674

Epoch: 5| Step: 6
Training loss: 2.656266450881958
Validation loss: 3.1951919992764792

Epoch: 5| Step: 7
Training loss: 3.467768907546997
Validation loss: 3.191805064678192

Epoch: 5| Step: 8
Training loss: 3.276947498321533
Validation loss: 3.1878205239772797

Epoch: 5| Step: 9
Training loss: 3.091428518295288
Validation loss: 3.184822142124176

Epoch: 5| Step: 10
Training loss: 3.795994281768799
Validation loss: 3.180995672941208

Epoch: 5| Step: 11
Training loss: 4.330530643463135
Validation loss: 3.177474687496821

Epoch: 36| Step: 0
Training loss: 3.438244342803955
Validation loss: 3.173980404933294

Epoch: 5| Step: 1
Training loss: 3.191991090774536
Validation loss: 3.1704842150211334

Epoch: 5| Step: 2
Training loss: 3.620145797729492
Validation loss: 3.1664293507734933

Epoch: 5| Step: 3
Training loss: 3.90303111076355
Validation loss: 3.162861088911692

Epoch: 5| Step: 4
Training loss: 3.175337076187134
Validation loss: 3.1593043903509774

Epoch: 5| Step: 5
Training loss: 2.908766508102417
Validation loss: 3.15563835700353

Epoch: 5| Step: 6
Training loss: 3.2854583263397217
Validation loss: 3.152226140101751

Epoch: 5| Step: 7
Training loss: 3.738192319869995
Validation loss: 3.1491465866565704

Epoch: 5| Step: 8
Training loss: 2.699798107147217
Validation loss: 3.1454363067944846

Epoch: 5| Step: 9
Training loss: 3.269690990447998
Validation loss: 3.1421085198720298

Epoch: 5| Step: 10
Training loss: 3.7410874366760254
Validation loss: 3.1386701663335166

Epoch: 5| Step: 11
Training loss: 2.2771904468536377
Validation loss: 3.1352191170056662

Epoch: 37| Step: 0
Training loss: 2.9393324851989746
Validation loss: 3.1321620841821036

Epoch: 5| Step: 1
Training loss: 3.2208290100097656
Validation loss: 3.1297113597393036

Epoch: 5| Step: 2
Training loss: 2.2030177116394043
Validation loss: 3.1264469226201377

Epoch: 5| Step: 3
Training loss: 3.2475783824920654
Validation loss: 3.1232643922170005

Epoch: 5| Step: 4
Training loss: 2.76237154006958
Validation loss: 3.1202957332134247

Epoch: 5| Step: 5
Training loss: 4.996398448944092
Validation loss: 3.1165943344434104

Epoch: 5| Step: 6
Training loss: 3.116560459136963
Validation loss: 3.1141430536905923

Epoch: 5| Step: 7
Training loss: 3.556201457977295
Validation loss: 3.1111579835414886

Epoch: 5| Step: 8
Training loss: 3.8876755237579346
Validation loss: 3.1079819599787393

Epoch: 5| Step: 9
Training loss: 3.3688578605651855
Validation loss: 3.104264736175537

Epoch: 5| Step: 10
Training loss: 3.2169222831726074
Validation loss: 3.1007474859555564

Epoch: 5| Step: 11
Training loss: 2.446969985961914
Validation loss: 3.0977598826090493

Epoch: 38| Step: 0
Training loss: 3.8875389099121094
Validation loss: 3.095651090145111

Epoch: 5| Step: 1
Training loss: 3.5149950981140137
Validation loss: 3.0921384692192078

Epoch: 5| Step: 2
Training loss: 2.5457615852355957
Validation loss: 3.08857927719752

Epoch: 5| Step: 3
Training loss: 2.980562210083008
Validation loss: 3.0854204098383584

Epoch: 5| Step: 4
Training loss: 3.3655829429626465
Validation loss: 3.082146108150482

Epoch: 5| Step: 5
Training loss: 3.689699649810791
Validation loss: 3.0793263812859855

Epoch: 5| Step: 6
Training loss: 2.433204174041748
Validation loss: 3.0766543646653495

Epoch: 5| Step: 7
Training loss: 3.360006809234619
Validation loss: 3.07400835553805

Epoch: 5| Step: 8
Training loss: 3.5976593494415283
Validation loss: 3.071096360683441

Epoch: 5| Step: 9
Training loss: 2.9640347957611084
Validation loss: 3.0679052074750266

Epoch: 5| Step: 10
Training loss: 3.608664035797119
Validation loss: 3.064713716506958

Epoch: 5| Step: 11
Training loss: 3.3032631874084473
Validation loss: 3.0616310437520347

Epoch: 39| Step: 0
Training loss: 2.866410732269287
Validation loss: 3.0580425361792245

Epoch: 5| Step: 1
Training loss: 3.8701255321502686
Validation loss: 3.0552827616532645

Epoch: 5| Step: 2
Training loss: 2.53157377243042
Validation loss: 3.0517013569672904

Epoch: 5| Step: 3
Training loss: 3.1524550914764404
Validation loss: 3.0490115185578666

Epoch: 5| Step: 4
Training loss: 3.6125407218933105
Validation loss: 3.045051028331121

Epoch: 5| Step: 5
Training loss: 2.8031139373779297
Validation loss: 3.0413041611512504

Epoch: 5| Step: 6
Training loss: 2.837278366088867
Validation loss: 3.0381848216056824

Epoch: 5| Step: 7
Training loss: 2.939265727996826
Validation loss: 3.0352300107479095

Epoch: 5| Step: 8
Training loss: 3.579202651977539
Validation loss: 3.0319995979468026

Epoch: 5| Step: 9
Training loss: 3.8988425731658936
Validation loss: 3.028486798206965

Epoch: 5| Step: 10
Training loss: 3.357891798019409
Validation loss: 3.0255468587080636

Epoch: 5| Step: 11
Training loss: 3.8306479454040527
Validation loss: 3.0221081376075745

Epoch: 40| Step: 0
Training loss: 3.479569673538208
Validation loss: 3.0190469324588776

Epoch: 5| Step: 1
Training loss: 2.838082790374756
Validation loss: 3.0164818664391837

Epoch: 5| Step: 2
Training loss: 2.944147825241089
Validation loss: 3.0138523280620575

Epoch: 5| Step: 3
Training loss: 3.7252936363220215
Validation loss: 3.0110062460104623

Epoch: 5| Step: 4
Training loss: 3.4020895957946777
Validation loss: 3.0073767006397247

Epoch: 5| Step: 5
Training loss: 3.4394493103027344
Validation loss: 3.004862775405248

Epoch: 5| Step: 6
Training loss: 3.6793041229248047
Validation loss: 3.0023364325364432

Epoch: 5| Step: 7
Training loss: 3.1792426109313965
Validation loss: 2.999829202890396

Epoch: 5| Step: 8
Training loss: 2.4905476570129395
Validation loss: 2.996194044748942

Epoch: 5| Step: 9
Training loss: 2.944314956665039
Validation loss: 2.9932102461655936

Epoch: 5| Step: 10
Training loss: 3.0656039714813232
Validation loss: 2.9896229207515717

Epoch: 5| Step: 11
Training loss: 3.151371479034424
Validation loss: 2.9879194299379983

Epoch: 41| Step: 0
Training loss: 3.232372999191284
Validation loss: 2.985043873389562

Epoch: 5| Step: 1
Training loss: 3.2821044921875
Validation loss: 2.9805930157502494

Epoch: 5| Step: 2
Training loss: 3.2935879230499268
Validation loss: 2.9772440691788993

Epoch: 5| Step: 3
Training loss: 2.5103821754455566
Validation loss: 2.9742060005664825

Epoch: 5| Step: 4
Training loss: 4.023837089538574
Validation loss: 2.9717901746431985

Epoch: 5| Step: 5
Training loss: 2.699410915374756
Validation loss: 2.968081057071686

Epoch: 5| Step: 6
Training loss: 2.1600677967071533
Validation loss: 2.965428113937378

Epoch: 5| Step: 7
Training loss: 3.0159051418304443
Validation loss: 2.9620880782604218

Epoch: 5| Step: 8
Training loss: 3.6255714893341064
Validation loss: 2.9591207007567086

Epoch: 5| Step: 9
Training loss: 3.488953113555908
Validation loss: 2.95604799191157

Epoch: 5| Step: 10
Training loss: 3.530458927154541
Validation loss: 2.9529615938663483

Epoch: 5| Step: 11
Training loss: 2.993797779083252
Validation loss: 2.9502280553181968

Epoch: 42| Step: 0
Training loss: 3.0936760902404785
Validation loss: 2.947020262479782

Epoch: 5| Step: 1
Training loss: 3.7494399547576904
Validation loss: 2.9440626005331674

Epoch: 5| Step: 2
Training loss: 2.7149887084960938
Validation loss: 2.9408927857875824

Epoch: 5| Step: 3
Training loss: 3.09674072265625
Validation loss: 2.937877506017685

Epoch: 5| Step: 4
Training loss: 4.0737409591674805
Validation loss: 2.934876104195913

Epoch: 5| Step: 5
Training loss: 3.250920057296753
Validation loss: 2.931631753842036

Epoch: 5| Step: 6
Training loss: 2.6506187915802
Validation loss: 2.9289988776048026

Epoch: 5| Step: 7
Training loss: 2.681835651397705
Validation loss: 2.925465335448583

Epoch: 5| Step: 8
Training loss: 2.741891622543335
Validation loss: 2.9230219622453055

Epoch: 5| Step: 9
Training loss: 2.962540626525879
Validation loss: 2.9202789664268494

Epoch: 5| Step: 10
Training loss: 3.196988344192505
Validation loss: 2.9177396496136985

Epoch: 5| Step: 11
Training loss: 4.450798034667969
Validation loss: 2.914998690287272

Epoch: 43| Step: 0
Training loss: 3.524435043334961
Validation loss: 2.911903584996859

Epoch: 5| Step: 1
Training loss: 2.981747627258301
Validation loss: 2.9082386791706085

Epoch: 5| Step: 2
Training loss: 3.2646572589874268
Validation loss: 2.905599296092987

Epoch: 5| Step: 3
Training loss: 3.035552740097046
Validation loss: 2.9030879934628806

Epoch: 5| Step: 4
Training loss: 2.8061602115631104
Validation loss: 2.9000917077064514

Epoch: 5| Step: 5
Training loss: 3.498384952545166
Validation loss: 2.897229333718618

Epoch: 5| Step: 6
Training loss: 3.0829334259033203
Validation loss: 2.894245038429896

Epoch: 5| Step: 7
Training loss: 3.540590763092041
Validation loss: 2.8917057613531747

Epoch: 5| Step: 8
Training loss: 2.6625635623931885
Validation loss: 2.888428956270218

Epoch: 5| Step: 9
Training loss: 3.318629503250122
Validation loss: 2.885268827279409

Epoch: 5| Step: 10
Training loss: 2.594059944152832
Validation loss: 2.8824499050776162

Epoch: 5| Step: 11
Training loss: 2.229767084121704
Validation loss: 2.8793378869692483

Epoch: 44| Step: 0
Training loss: 3.5301544666290283
Validation loss: 2.878883143266042

Epoch: 5| Step: 1
Training loss: 3.814889430999756
Validation loss: 2.875123252471288

Epoch: 5| Step: 2
Training loss: 3.2057487964630127
Validation loss: 2.8731115063031516

Epoch: 5| Step: 3
Training loss: 2.589614152908325
Validation loss: 2.869282384713491

Epoch: 5| Step: 4
Training loss: 3.053415298461914
Validation loss: 2.8671045005321503

Epoch: 5| Step: 5
Training loss: 3.40397572517395
Validation loss: 2.8637048800786338

Epoch: 5| Step: 6
Training loss: 2.7748007774353027
Validation loss: 2.8607137898604074

Epoch: 5| Step: 7
Training loss: 2.036058187484741
Validation loss: 2.858446925878525

Epoch: 5| Step: 8
Training loss: 3.1296324729919434
Validation loss: 2.855075558026632

Epoch: 5| Step: 9
Training loss: 2.939390182495117
Validation loss: 2.8534905115763345

Epoch: 5| Step: 10
Training loss: 3.1710124015808105
Validation loss: 2.850917567809423

Epoch: 5| Step: 11
Training loss: 3.881493091583252
Validation loss: 2.8477769792079926

Epoch: 45| Step: 0
Training loss: 2.6619184017181396
Validation loss: 2.845782866080602

Epoch: 5| Step: 1
Training loss: 2.8631439208984375
Validation loss: 2.8433841367562613

Epoch: 5| Step: 2
Training loss: 3.614152431488037
Validation loss: 2.840463509162267

Epoch: 5| Step: 3
Training loss: 2.6952059268951416
Validation loss: 2.8419806957244873

Epoch: 5| Step: 4
Training loss: 4.075015544891357
Validation loss: 2.841322888930639

Epoch: 5| Step: 5
Training loss: 3.932234525680542
Validation loss: 2.835154285033544

Epoch: 5| Step: 6
Training loss: 2.668196439743042
Validation loss: 2.8319713473320007

Epoch: 5| Step: 7
Training loss: 2.827208995819092
Validation loss: 2.8289490342140198

Epoch: 5| Step: 8
Training loss: 2.731995105743408
Validation loss: 2.826635738213857

Epoch: 5| Step: 9
Training loss: 2.965087413787842
Validation loss: 2.8254541556040444

Epoch: 5| Step: 10
Training loss: 2.6775271892547607
Validation loss: 2.824078013499578

Epoch: 5| Step: 11
Training loss: 1.8728196620941162
Validation loss: 2.824218879143397

Epoch: 46| Step: 0
Training loss: 3.3044979572296143
Validation loss: 2.816626717646917

Epoch: 5| Step: 1
Training loss: 3.1750874519348145
Validation loss: 2.816180576880773

Epoch: 5| Step: 2
Training loss: 3.468266725540161
Validation loss: 2.819872811436653

Epoch: 5| Step: 3
Training loss: 3.3952815532684326
Validation loss: 2.8139040072758994

Epoch: 5| Step: 4
Training loss: 3.3695263862609863
Validation loss: 2.8093120058377585

Epoch: 5| Step: 5
Training loss: 2.715001106262207
Validation loss: 2.8048835595448813

Epoch: 5| Step: 6
Training loss: 2.3673057556152344
Validation loss: 2.8008779883384705

Epoch: 5| Step: 7
Training loss: 2.476640462875366
Validation loss: 2.798539419968923

Epoch: 5| Step: 8
Training loss: 3.224637508392334
Validation loss: 2.795849392811457

Epoch: 5| Step: 9
Training loss: 2.987095594406128
Validation loss: 2.7940797905127206

Epoch: 5| Step: 10
Training loss: 2.5920276641845703
Validation loss: 2.790040214856466

Epoch: 5| Step: 11
Training loss: 3.515413761138916
Validation loss: 2.7881579796473184

Epoch: 47| Step: 0
Training loss: 2.561079502105713
Validation loss: 2.7858726382255554

Epoch: 5| Step: 1
Training loss: 3.146510362625122
Validation loss: 2.7834945817788443

Epoch: 5| Step: 2
Training loss: 2.8781790733337402
Validation loss: 2.780723879734675

Epoch: 5| Step: 3
Training loss: 3.28777813911438
Validation loss: 2.779828275243441

Epoch: 5| Step: 4
Training loss: 2.9627251625061035
Validation loss: 2.7774184246857962

Epoch: 5| Step: 5
Training loss: 2.476475954055786
Validation loss: 2.7758595844109855

Epoch: 5| Step: 6
Training loss: 2.52756667137146
Validation loss: 2.7705949743588767

Epoch: 5| Step: 7
Training loss: 3.9191348552703857
Validation loss: 2.768000374237696

Epoch: 5| Step: 8
Training loss: 3.2581329345703125
Validation loss: 2.7632557153701782

Epoch: 5| Step: 9
Training loss: 3.119819164276123
Validation loss: 2.7609790563583374

Epoch: 5| Step: 10
Training loss: 2.845397472381592
Validation loss: 2.759874254465103

Epoch: 5| Step: 11
Training loss: 2.130796432495117
Validation loss: 2.7544283866882324

Epoch: 48| Step: 0
Training loss: 3.0403828620910645
Validation loss: 2.7579586605230966

Epoch: 5| Step: 1
Training loss: 3.127274751663208
Validation loss: 2.762917677561442

Epoch: 5| Step: 2
Training loss: 3.1888973712921143
Validation loss: 2.7554719895124435

Epoch: 5| Step: 3
Training loss: 3.4779536724090576
Validation loss: 2.7468755741914115

Epoch: 5| Step: 4
Training loss: 2.523014545440674
Validation loss: 2.7411982814470925

Epoch: 5| Step: 5
Training loss: 2.907227039337158
Validation loss: 2.740719129641851

Epoch: 5| Step: 6
Training loss: 2.845057964324951
Validation loss: 2.7372871339321136

Epoch: 5| Step: 7
Training loss: 2.721945285797119
Validation loss: 2.7378673553466797

Epoch: 5| Step: 8
Training loss: 2.7963919639587402
Validation loss: 2.734292874733607

Epoch: 5| Step: 9
Training loss: 3.0874521732330322
Validation loss: 2.7302317122618356

Epoch: 5| Step: 10
Training loss: 2.917649507522583
Validation loss: 2.728122423092524

Epoch: 5| Step: 11
Training loss: 2.1112942695617676
Validation loss: 2.7241913874944053

Epoch: 49| Step: 0
Training loss: 2.3451781272888184
Validation loss: 2.721688230832418

Epoch: 5| Step: 1
Training loss: 3.281651735305786
Validation loss: 2.720242520173391

Epoch: 5| Step: 2
Training loss: 3.766252040863037
Validation loss: 2.71795000632604

Epoch: 5| Step: 3
Training loss: 2.6604678630828857
Validation loss: 2.715111235777537

Epoch: 5| Step: 4
Training loss: 2.7448935508728027
Validation loss: 2.7152123947938285

Epoch: 5| Step: 5
Training loss: 2.984288454055786
Validation loss: 2.709386020898819

Epoch: 5| Step: 6
Training loss: 2.6553683280944824
Validation loss: 2.706853359937668

Epoch: 5| Step: 7
Training loss: 3.089028835296631
Validation loss: 2.7046474615732827

Epoch: 5| Step: 8
Training loss: 3.5369575023651123
Validation loss: 2.6999179124832153

Epoch: 5| Step: 9
Training loss: 2.5557541847229004
Validation loss: 2.699305464824041

Epoch: 5| Step: 10
Training loss: 2.399451732635498
Validation loss: 2.6925266484419503

Epoch: 5| Step: 11
Training loss: 3.129265069961548
Validation loss: 2.6937448183695474

Epoch: 50| Step: 0
Training loss: 2.634345769882202
Validation loss: 2.6927163501580558

Epoch: 5| Step: 1
Training loss: 2.6093077659606934
Validation loss: 2.687055100997289

Epoch: 5| Step: 2
Training loss: 2.788102626800537
Validation loss: 2.684519648551941

Epoch: 5| Step: 3
Training loss: 2.867539882659912
Validation loss: 2.6854610542456308

Epoch: 5| Step: 4
Training loss: 3.021038055419922
Validation loss: 2.6800830165545144

Epoch: 5| Step: 5
Training loss: 3.020418167114258
Validation loss: 2.6783804893493652

Epoch: 5| Step: 6
Training loss: 2.33620548248291
Validation loss: 2.6720298727353415

Epoch: 5| Step: 7
Training loss: 3.7012939453125
Validation loss: 2.6687584221363068

Epoch: 5| Step: 8
Training loss: 2.894470453262329
Validation loss: 2.666089177131653

Epoch: 5| Step: 9
Training loss: 2.869840621948242
Validation loss: 2.665806154410044

Epoch: 5| Step: 10
Training loss: 2.912998914718628
Validation loss: 2.664254536231359

Epoch: 5| Step: 11
Training loss: 2.9099302291870117
Validation loss: 2.6623739202817283

Epoch: 51| Step: 0
Training loss: 2.361948013305664
Validation loss: 2.654672165711721

Epoch: 5| Step: 1
Training loss: 2.862893581390381
Validation loss: 2.6631558537483215

Epoch: 5| Step: 2
Training loss: 2.2882046699523926
Validation loss: 2.66278737783432

Epoch: 5| Step: 3
Training loss: 2.8212180137634277
Validation loss: 2.655201027790705

Epoch: 5| Step: 4
Training loss: 2.407227039337158
Validation loss: 2.648638367652893

Epoch: 5| Step: 5
Training loss: 2.7734017372131348
Validation loss: 2.6457930405934653

Epoch: 5| Step: 6
Training loss: 3.6071674823760986
Validation loss: 2.637855142354965

Epoch: 5| Step: 7
Training loss: 3.0329272747039795
Validation loss: 2.6402479807535806

Epoch: 5| Step: 8
Training loss: 2.8843934535980225
Validation loss: 2.637717753648758

Epoch: 5| Step: 9
Training loss: 2.7069382667541504
Validation loss: 2.6363810201485953

Epoch: 5| Step: 10
Training loss: 3.3722031116485596
Validation loss: 2.6340395907560983

Epoch: 5| Step: 11
Training loss: 3.7202727794647217
Validation loss: 2.6296367843945823

Epoch: 52| Step: 0
Training loss: 3.2352490425109863
Validation loss: 2.625833456714948

Epoch: 5| Step: 1
Training loss: 2.313811779022217
Validation loss: 2.6245899299780526

Epoch: 5| Step: 2
Training loss: 2.4196324348449707
Validation loss: 2.621732215086619

Epoch: 5| Step: 3
Training loss: 3.1883187294006348
Validation loss: 2.623706728219986

Epoch: 5| Step: 4
Training loss: 2.912097215652466
Validation loss: 2.6254294315973916

Epoch: 5| Step: 5
Training loss: 3.104672431945801
Validation loss: 2.6133645474910736

Epoch: 5| Step: 6
Training loss: 2.8794732093811035
Validation loss: 2.6097559332847595

Epoch: 5| Step: 7
Training loss: 3.0020673274993896
Validation loss: 2.6073149045308432

Epoch: 5| Step: 8
Training loss: 2.7803821563720703
Validation loss: 2.6105147202809653

Epoch: 5| Step: 9
Training loss: 2.488910675048828
Validation loss: 2.6067875027656555

Epoch: 5| Step: 10
Training loss: 2.495361328125
Validation loss: 2.604527403910955

Epoch: 5| Step: 11
Training loss: 3.599743604660034
Validation loss: 2.6038291652997336

Epoch: 53| Step: 0
Training loss: 2.7488396167755127
Validation loss: 2.5966788828372955

Epoch: 5| Step: 1
Training loss: 2.655885696411133
Validation loss: 2.5949918230374656

Epoch: 5| Step: 2
Training loss: 2.9057180881500244
Validation loss: 2.5871291905641556

Epoch: 5| Step: 3
Training loss: 2.621532917022705
Validation loss: 2.5865056216716766

Epoch: 5| Step: 4
Training loss: 2.8148396015167236
Validation loss: 2.5832562347253165

Epoch: 5| Step: 5
Training loss: 2.792372465133667
Validation loss: 2.5803439617156982

Epoch: 5| Step: 6
Training loss: 3.15575909614563
Validation loss: 2.5775891542434692

Epoch: 5| Step: 7
Training loss: 2.8507895469665527
Validation loss: 2.5713217556476593

Epoch: 5| Step: 8
Training loss: 2.331176996231079
Validation loss: 2.569115107258161

Epoch: 5| Step: 9
Training loss: 2.5969107151031494
Validation loss: 2.5688407321770987

Epoch: 5| Step: 10
Training loss: 3.0125651359558105
Validation loss: 2.5670543809731803

Epoch: 5| Step: 11
Training loss: 2.982495069503784
Validation loss: 2.561955541372299

Epoch: 54| Step: 0
Training loss: 3.205251693725586
Validation loss: 2.5697587728500366

Epoch: 5| Step: 1
Training loss: 2.2935268878936768
Validation loss: 2.5700466533501944

Epoch: 5| Step: 2
Training loss: 2.7096242904663086
Validation loss: 2.5579304893811545

Epoch: 5| Step: 3
Training loss: 2.438613176345825
Validation loss: 2.551344941059748

Epoch: 5| Step: 4
Training loss: 2.2539010047912598
Validation loss: 2.550994356473287

Epoch: 5| Step: 5
Training loss: 2.8723063468933105
Validation loss: 2.5518668989340463

Epoch: 5| Step: 6
Training loss: 2.514444351196289
Validation loss: 2.5522819260756173

Epoch: 5| Step: 7
Training loss: 3.3762855529785156
Validation loss: 2.549673999349276

Epoch: 5| Step: 8
Training loss: 2.335803270339966
Validation loss: 2.5414116382598877

Epoch: 5| Step: 9
Training loss: 3.226212978363037
Validation loss: 2.5412366092205048

Epoch: 5| Step: 10
Training loss: 2.9989895820617676
Validation loss: 2.5369955003261566

Epoch: 5| Step: 11
Training loss: 2.903120994567871
Validation loss: 2.5368811190128326

Epoch: 55| Step: 0
Training loss: 2.9259185791015625
Validation loss: 2.532458076874415

Epoch: 5| Step: 1
Training loss: 2.737231731414795
Validation loss: 2.528651863336563

Epoch: 5| Step: 2
Training loss: 2.260268449783325
Validation loss: 2.525591626763344

Epoch: 5| Step: 3
Training loss: 2.623412609100342
Validation loss: 2.523156464099884

Epoch: 5| Step: 4
Training loss: 3.24271821975708
Validation loss: 2.5193973978360495

Epoch: 5| Step: 5
Training loss: 2.4836037158966064
Validation loss: 2.516867687304815

Epoch: 5| Step: 6
Training loss: 2.30949068069458
Validation loss: 2.5210313449303308

Epoch: 5| Step: 7
Training loss: 3.0034286975860596
Validation loss: 2.5141453643639884

Epoch: 5| Step: 8
Training loss: 2.6623940467834473
Validation loss: 2.5130055646101632

Epoch: 5| Step: 9
Training loss: 2.8457088470458984
Validation loss: 2.5067987044652305

Epoch: 5| Step: 10
Training loss: 3.04251766204834
Validation loss: 2.505011200904846

Epoch: 5| Step: 11
Training loss: 1.0636889934539795
Validation loss: 2.506587505340576

Epoch: 56| Step: 0
Training loss: 2.3372864723205566
Validation loss: 2.49955286582311

Epoch: 5| Step: 1
Training loss: 3.103736400604248
Validation loss: 2.497782915830612

Epoch: 5| Step: 2
Training loss: 3.027548313140869
Validation loss: 2.502197732528051

Epoch: 5| Step: 3
Training loss: 3.0225272178649902
Validation loss: 2.5019712249437966

Epoch: 5| Step: 4
Training loss: 3.1755728721618652
Validation loss: 2.500560313463211

Epoch: 5| Step: 5
Training loss: 2.7813611030578613
Validation loss: 2.4973861277103424

Epoch: 5| Step: 6
Training loss: 2.299190044403076
Validation loss: 2.4926538268725076

Epoch: 5| Step: 7
Training loss: 2.729691982269287
Validation loss: 2.4855329195658364

Epoch: 5| Step: 8
Training loss: 2.457144260406494
Validation loss: 2.4839651783307395

Epoch: 5| Step: 9
Training loss: 2.3958089351654053
Validation loss: 2.4807353913784027

Epoch: 5| Step: 10
Training loss: 1.9918444156646729
Validation loss: 2.4793343444665275

Epoch: 5| Step: 11
Training loss: 3.6493611335754395
Validation loss: 2.474070052305857

Epoch: 57| Step: 0
Training loss: 2.950604200363159
Validation loss: 2.47345162431399

Epoch: 5| Step: 1
Training loss: 2.2906363010406494
Validation loss: 2.470548003911972

Epoch: 5| Step: 2
Training loss: 2.402247667312622
Validation loss: 2.464855879545212

Epoch: 5| Step: 3
Training loss: 3.0430030822753906
Validation loss: 2.4638498226801553

Epoch: 5| Step: 4
Training loss: 1.9959356784820557
Validation loss: 2.465598245461782

Epoch: 5| Step: 5
Training loss: 2.891228437423706
Validation loss: 2.4576120475927987

Epoch: 5| Step: 6
Training loss: 3.3767001628875732
Validation loss: 2.4532728791236877

Epoch: 5| Step: 7
Training loss: 2.801596164703369
Validation loss: 2.455168237288793

Epoch: 5| Step: 8
Training loss: 3.065730333328247
Validation loss: 2.4474244316418967

Epoch: 5| Step: 9
Training loss: 2.2081573009490967
Validation loss: 2.4461808800697327

Epoch: 5| Step: 10
Training loss: 2.0183472633361816
Validation loss: 2.4444953004519143

Epoch: 5| Step: 11
Training loss: 3.071131706237793
Validation loss: 2.4427689214547477

Epoch: 58| Step: 0
Training loss: 2.7620911598205566
Validation loss: 2.4375216364860535

Epoch: 5| Step: 1
Training loss: 2.464078903198242
Validation loss: 2.438898821671804

Epoch: 5| Step: 2
Training loss: 2.796999454498291
Validation loss: 2.4309017856915793

Epoch: 5| Step: 3
Training loss: 2.8886892795562744
Validation loss: 2.4331155816713967

Epoch: 5| Step: 4
Training loss: 1.9515657424926758
Validation loss: 2.428483267625173

Epoch: 5| Step: 5
Training loss: 2.769954204559326
Validation loss: 2.4349129498004913

Epoch: 5| Step: 6
Training loss: 2.2024009227752686
Validation loss: 2.4382996559143066

Epoch: 5| Step: 7
Training loss: 2.610244035720825
Validation loss: 2.437477479378382

Epoch: 5| Step: 8
Training loss: 2.6911494731903076
Validation loss: 2.426306207974752

Epoch: 5| Step: 9
Training loss: 2.7053418159484863
Validation loss: 2.4166351656119027

Epoch: 5| Step: 10
Training loss: 2.6962428092956543
Validation loss: 2.4155864665905633

Epoch: 5| Step: 11
Training loss: 3.596147060394287
Validation loss: 2.4148407181104026

Epoch: 59| Step: 0
Training loss: 2.6951255798339844
Validation loss: 2.412562141815821

Epoch: 5| Step: 1
Training loss: 2.495569944381714
Validation loss: 2.4113766849040985

Epoch: 5| Step: 2
Training loss: 2.978135585784912
Validation loss: 2.415263682603836

Epoch: 5| Step: 3
Training loss: 3.074903964996338
Validation loss: 2.4142229557037354

Epoch: 5| Step: 4
Training loss: 2.6342644691467285
Validation loss: 2.417249709367752

Epoch: 5| Step: 5
Training loss: 2.1808876991271973
Validation loss: 2.4121534725030265

Epoch: 5| Step: 6
Training loss: 2.639099597930908
Validation loss: 2.405623644590378

Epoch: 5| Step: 7
Training loss: 2.116837978363037
Validation loss: 2.401132141550382

Epoch: 5| Step: 8
Training loss: 2.675551176071167
Validation loss: 2.3968202273050943

Epoch: 5| Step: 9
Training loss: 2.4461967945098877
Validation loss: 2.392978459596634

Epoch: 5| Step: 10
Training loss: 2.466517210006714
Validation loss: 2.3884736597537994

Epoch: 5| Step: 11
Training loss: 3.153592586517334
Validation loss: 2.3905394673347473

Epoch: 60| Step: 0
Training loss: 2.852489948272705
Validation loss: 2.3841225306193032

Epoch: 5| Step: 1
Training loss: 2.6588668823242188
Validation loss: 2.3807881275812783

Epoch: 5| Step: 2
Training loss: 2.407536745071411
Validation loss: 2.3787711213032403

Epoch: 5| Step: 3
Training loss: 2.736222505569458
Validation loss: 2.372763196627299

Epoch: 5| Step: 4
Training loss: 2.294149160385132
Validation loss: 2.3737489680449166

Epoch: 5| Step: 5
Training loss: 2.4997305870056152
Validation loss: 2.3706424832344055

Epoch: 5| Step: 6
Training loss: 3.0895283222198486
Validation loss: 2.3759786784648895

Epoch: 5| Step: 7
Training loss: 2.6943211555480957
Validation loss: 2.3683556616306305

Epoch: 5| Step: 8
Training loss: 2.5463430881500244
Validation loss: 2.3651040395100913

Epoch: 5| Step: 9
Training loss: 2.128352642059326
Validation loss: 2.3608768532673516

Epoch: 5| Step: 10
Training loss: 2.1146938800811768
Validation loss: 2.3603541354338327

Epoch: 5| Step: 11
Training loss: 2.5666451454162598
Validation loss: 2.355637381474177

Epoch: 61| Step: 0
Training loss: 2.1350951194763184
Validation loss: 2.3543992141882577

Epoch: 5| Step: 1
Training loss: 2.4968690872192383
Validation loss: 2.352212687333425

Epoch: 5| Step: 2
Training loss: 2.6133110523223877
Validation loss: 2.351278061668078

Epoch: 5| Step: 3
Training loss: 2.588085651397705
Validation loss: 2.347477287054062

Epoch: 5| Step: 4
Training loss: 2.179028034210205
Validation loss: 2.3454198390245438

Epoch: 5| Step: 5
Training loss: 2.646498441696167
Validation loss: 2.3405449589093528

Epoch: 5| Step: 6
Training loss: 2.136579751968384
Validation loss: 2.341303994258245

Epoch: 5| Step: 7
Training loss: 3.176192283630371
Validation loss: 2.3402673602104187

Epoch: 5| Step: 8
Training loss: 2.3778281211853027
Validation loss: 2.336715449889501

Epoch: 5| Step: 9
Training loss: 2.530003547668457
Validation loss: 2.337423329552015

Epoch: 5| Step: 10
Training loss: 2.7506580352783203
Validation loss: 2.3372664948304496

Epoch: 5| Step: 11
Training loss: 2.7091596126556396
Validation loss: 2.339580625295639

Epoch: 62| Step: 0
Training loss: 2.6011557579040527
Validation loss: 2.3296038607756295

Epoch: 5| Step: 1
Training loss: 2.165893793106079
Validation loss: 2.325799912214279

Epoch: 5| Step: 2
Training loss: 3.2078044414520264
Validation loss: 2.3244843085606894

Epoch: 5| Step: 3
Training loss: 2.544577121734619
Validation loss: 2.3205416848262153

Epoch: 5| Step: 4
Training loss: 2.2491307258605957
Validation loss: 2.3198705514272056

Epoch: 5| Step: 5
Training loss: 2.4355931282043457
Validation loss: 2.32220850388209

Epoch: 5| Step: 6
Training loss: 2.7190356254577637
Validation loss: 2.313666741053263

Epoch: 5| Step: 7
Training loss: 2.4936485290527344
Validation loss: 2.313770761092504

Epoch: 5| Step: 8
Training loss: 2.278703212738037
Validation loss: 2.310448795557022

Epoch: 5| Step: 9
Training loss: 2.2480599880218506
Validation loss: 2.312948996822039

Epoch: 5| Step: 10
Training loss: 2.4940733909606934
Validation loss: 2.3103853166103363

Epoch: 5| Step: 11
Training loss: 2.162881374359131
Validation loss: 2.305734852949778

Epoch: 63| Step: 0
Training loss: 2.4430556297302246
Validation loss: 2.304398333032926

Epoch: 5| Step: 1
Training loss: 2.4600813388824463
Validation loss: 2.302354325850805

Epoch: 5| Step: 2
Training loss: 2.2111611366271973
Validation loss: 2.3022897442181907

Epoch: 5| Step: 3
Training loss: 2.7393510341644287
Validation loss: 2.2939719458421073

Epoch: 5| Step: 4
Training loss: 3.153268814086914
Validation loss: 2.295113037029902

Epoch: 5| Step: 5
Training loss: 2.356351852416992
Validation loss: 2.2905237128337226

Epoch: 5| Step: 6
Training loss: 2.3748161792755127
Validation loss: 2.2871911575396857

Epoch: 5| Step: 7
Training loss: 2.225855827331543
Validation loss: 2.2943368603785834

Epoch: 5| Step: 8
Training loss: 2.5562386512756348
Validation loss: 2.2918484807014465

Epoch: 5| Step: 9
Training loss: 2.372314453125
Validation loss: 2.2901136179765067

Epoch: 5| Step: 10
Training loss: 2.38659930229187
Validation loss: 2.2894860406716666

Epoch: 5| Step: 11
Training loss: 1.4855968952178955
Validation loss: 2.286671926577886

Epoch: 64| Step: 0
Training loss: 2.3501410484313965
Validation loss: 2.277360121409098

Epoch: 5| Step: 1
Training loss: 2.738347291946411
Validation loss: 2.2823734879493713

Epoch: 5| Step: 2
Training loss: 2.4309067726135254
Validation loss: 2.2767091492811837

Epoch: 5| Step: 3
Training loss: 2.2960596084594727
Validation loss: 2.2719409267107644

Epoch: 5| Step: 4
Training loss: 2.2480592727661133
Validation loss: 2.2702920138835907

Epoch: 5| Step: 5
Training loss: 2.698565721511841
Validation loss: 2.269555449485779

Epoch: 5| Step: 6
Training loss: 2.414607524871826
Validation loss: 2.2634330838918686

Epoch: 5| Step: 7
Training loss: 2.484926223754883
Validation loss: 2.266445060571035

Epoch: 5| Step: 8
Training loss: 2.4167656898498535
Validation loss: 2.26636803150177

Epoch: 5| Step: 9
Training loss: 2.0658345222473145
Validation loss: 2.260771468281746

Epoch: 5| Step: 10
Training loss: 2.5107510089874268
Validation loss: 2.2596044143040976

Epoch: 5| Step: 11
Training loss: 2.655893325805664
Validation loss: 2.25909889737765

Epoch: 65| Step: 0
Training loss: 2.3971965312957764
Validation loss: 2.256251628200213

Epoch: 5| Step: 1
Training loss: 2.3666396141052246
Validation loss: 2.2549833357334137

Epoch: 5| Step: 2
Training loss: 2.5497190952301025
Validation loss: 2.2515797118345895

Epoch: 5| Step: 3
Training loss: 1.8009319305419922
Validation loss: 2.251712754368782

Epoch: 5| Step: 4
Training loss: 2.1046760082244873
Validation loss: 2.2495117485523224

Epoch: 5| Step: 5
Training loss: 3.196906328201294
Validation loss: 2.248166561126709

Epoch: 5| Step: 6
Training loss: 1.872492790222168
Validation loss: 2.245894655585289

Epoch: 5| Step: 7
Training loss: 2.541027784347534
Validation loss: 2.246126333872477

Epoch: 5| Step: 8
Training loss: 2.6340413093566895
Validation loss: 2.2395232220490775

Epoch: 5| Step: 9
Training loss: 2.819019317626953
Validation loss: 2.2333771884441376

Epoch: 5| Step: 10
Training loss: 2.137418746948242
Validation loss: 2.2285177956024804

Epoch: 5| Step: 11
Training loss: 2.324246406555176
Validation loss: 2.2344086865584054

Epoch: 66| Step: 0
Training loss: 2.478379487991333
Validation loss: 2.2361167867978415

Epoch: 5| Step: 1
Training loss: 2.4023540019989014
Validation loss: 2.2362720668315887

Epoch: 5| Step: 2
Training loss: 2.459406614303589
Validation loss: 2.2453827063242593

Epoch: 5| Step: 3
Training loss: 2.344464063644409
Validation loss: 2.2436446845531464

Epoch: 5| Step: 4
Training loss: 2.9874908924102783
Validation loss: 2.2312328815460205

Epoch: 5| Step: 5
Training loss: 1.9065707921981812
Validation loss: 2.2148899137973785

Epoch: 5| Step: 6
Training loss: 2.33474063873291
Validation loss: 2.212808758020401

Epoch: 5| Step: 7
Training loss: 2.79875111579895
Validation loss: 2.2115825712680817

Epoch: 5| Step: 8
Training loss: 2.1088922023773193
Validation loss: 2.2206435203552246

Epoch: 5| Step: 9
Training loss: 2.0256590843200684
Validation loss: 2.215994894504547

Epoch: 5| Step: 10
Training loss: 2.396030902862549
Validation loss: 2.2183690617481866

Epoch: 5| Step: 11
Training loss: 1.919686198234558
Validation loss: 2.216065992911657

Epoch: 67| Step: 0
Training loss: 2.0917227268218994
Validation loss: 2.2177208364009857

Epoch: 5| Step: 1
Training loss: 2.4756550788879395
Validation loss: 2.2197704315185547

Epoch: 5| Step: 2
Training loss: 3.219525098800659
Validation loss: 2.2166872521241507

Epoch: 5| Step: 3
Training loss: 2.4110167026519775
Validation loss: 2.2142544041077294

Epoch: 5| Step: 4
Training loss: 2.4412474632263184
Validation loss: 2.2126783231894174

Epoch: 5| Step: 5
Training loss: 1.8000236749649048
Validation loss: 2.2051834762096405

Epoch: 5| Step: 6
Training loss: 2.405672788619995
Validation loss: 2.1999151607354483

Epoch: 5| Step: 7
Training loss: 2.2220191955566406
Validation loss: 2.1976973712444305

Epoch: 5| Step: 8
Training loss: 2.7031455039978027
Validation loss: 2.1945547064145408

Epoch: 5| Step: 9
Training loss: 1.6673362255096436
Validation loss: 2.1898625195026398

Epoch: 5| Step: 10
Training loss: 2.394549608230591
Validation loss: 2.1886527438958487

Epoch: 5| Step: 11
Training loss: 3.0471737384796143
Validation loss: 2.198511610428492

Epoch: 68| Step: 0
Training loss: 2.1219544410705566
Validation loss: 2.204699049393336

Epoch: 5| Step: 1
Training loss: 2.473493814468384
Validation loss: 2.2103082289298377

Epoch: 5| Step: 2
Training loss: 2.394712448120117
Validation loss: 2.2099121610323587

Epoch: 5| Step: 3
Training loss: 2.5879247188568115
Validation loss: 2.193817526102066

Epoch: 5| Step: 4
Training loss: 2.4672698974609375
Validation loss: 2.1914065877596536

Epoch: 5| Step: 5
Training loss: 1.9689830541610718
Validation loss: 2.1878496011098227

Epoch: 5| Step: 6
Training loss: 2.1968600749969482
Validation loss: 2.1805772880713143

Epoch: 5| Step: 7
Training loss: 2.9116547107696533
Validation loss: 2.1776698231697083

Epoch: 5| Step: 8
Training loss: 2.416642427444458
Validation loss: 2.181284765402476

Epoch: 5| Step: 9
Training loss: 2.2390339374542236
Validation loss: 2.1830979039271674

Epoch: 5| Step: 10
Training loss: 2.1510722637176514
Validation loss: 2.184858957926432

Epoch: 5| Step: 11
Training loss: 1.9888569116592407
Validation loss: 2.1871276050806046

Epoch: 69| Step: 0
Training loss: 2.364366054534912
Validation loss: 2.1912665317455926

Epoch: 5| Step: 1
Training loss: 2.2357773780822754
Validation loss: 2.1873178432385125

Epoch: 5| Step: 2
Training loss: 2.6181132793426514
Validation loss: 2.189300075173378

Epoch: 5| Step: 3
Training loss: 2.3449814319610596
Validation loss: 2.185924539963404

Epoch: 5| Step: 4
Training loss: 2.6854465007781982
Validation loss: 2.182834178209305

Epoch: 5| Step: 5
Training loss: 1.7057116031646729
Validation loss: 2.181658218304316

Epoch: 5| Step: 6
Training loss: 2.6519954204559326
Validation loss: 2.1751845628023148

Epoch: 5| Step: 7
Training loss: 2.3616771697998047
Validation loss: 2.1710421989361444

Epoch: 5| Step: 8
Training loss: 2.5275659561157227
Validation loss: 2.169330060482025

Epoch: 5| Step: 9
Training loss: 2.3077023029327393
Validation loss: 2.163799966375033

Epoch: 5| Step: 10
Training loss: 1.9703372716903687
Validation loss: 2.1601617882649102

Epoch: 5| Step: 11
Training loss: 1.869297981262207
Validation loss: 2.1593328764041266

Epoch: 70| Step: 0
Training loss: 2.300797700881958
Validation loss: 2.154867942134539

Epoch: 5| Step: 1
Training loss: 2.897571563720703
Validation loss: 2.157577926913897

Epoch: 5| Step: 2
Training loss: 2.0014681816101074
Validation loss: 2.1584528585275016

Epoch: 5| Step: 3
Training loss: 2.62919282913208
Validation loss: 2.166207899649938

Epoch: 5| Step: 4
Training loss: 2.225109815597534
Validation loss: 2.1530791769425073

Epoch: 5| Step: 5
Training loss: 2.236607313156128
Validation loss: 2.163971091310183

Epoch: 5| Step: 6
Training loss: 2.058664321899414
Validation loss: 2.155612419048945

Epoch: 5| Step: 7
Training loss: 2.172546148300171
Validation loss: 2.158120105663935

Epoch: 5| Step: 8
Training loss: 2.0128140449523926
Validation loss: 2.151287426551183

Epoch: 5| Step: 9
Training loss: 2.3427650928497314
Validation loss: 2.1581828693548837

Epoch: 5| Step: 10
Training loss: 2.4415390491485596
Validation loss: 2.15587525566419

Epoch: 5| Step: 11
Training loss: 2.6188039779663086
Validation loss: 2.1523477534453073

Epoch: 71| Step: 0
Training loss: 2.684732675552368
Validation loss: 2.1531725078821182

Epoch: 5| Step: 1
Training loss: 2.0751595497131348
Validation loss: 2.1539425055185952

Epoch: 5| Step: 2
Training loss: 2.4601047039031982
Validation loss: 2.1611062586307526

Epoch: 5| Step: 3
Training loss: 2.270967960357666
Validation loss: 2.1716498782237372

Epoch: 5| Step: 4
Training loss: 2.489093780517578
Validation loss: 2.1860261857509613

Epoch: 5| Step: 5
Training loss: 2.166635513305664
Validation loss: 2.1942749122778573

Epoch: 5| Step: 6
Training loss: 1.8703346252441406
Validation loss: 2.2065476179122925

Epoch: 5| Step: 7
Training loss: 1.8947906494140625
Validation loss: 2.21119191745917

Epoch: 5| Step: 8
Training loss: 2.6556084156036377
Validation loss: 2.2136386781930923

Epoch: 5| Step: 9
Training loss: 2.19230580329895
Validation loss: 2.2200058549642563

Epoch: 5| Step: 10
Training loss: 2.9107909202575684
Validation loss: 2.2178408205509186

Epoch: 5| Step: 11
Training loss: 2.9772143363952637
Validation loss: 2.2078687946001687

Epoch: 72| Step: 0
Training loss: 2.445037841796875
Validation loss: 2.1909793516000113

Epoch: 5| Step: 1
Training loss: 2.8245561122894287
Validation loss: 2.179108922680219

Epoch: 5| Step: 2
Training loss: 2.4747283458709717
Validation loss: 2.173467054963112

Epoch: 5| Step: 3
Training loss: 1.9446815252304077
Validation loss: 2.1643078327178955

Epoch: 5| Step: 4
Training loss: 2.454019069671631
Validation loss: 2.160991907119751

Epoch: 5| Step: 5
Training loss: 2.3289618492126465
Validation loss: 2.151239042480787

Epoch: 5| Step: 6
Training loss: 2.22920560836792
Validation loss: 2.151499683658282

Epoch: 5| Step: 7
Training loss: 2.132742166519165
Validation loss: 2.145495822032293

Epoch: 5| Step: 8
Training loss: 2.1943583488464355
Validation loss: 2.1445093353589377

Epoch: 5| Step: 9
Training loss: 2.290639638900757
Validation loss: 2.1414919892946878

Epoch: 5| Step: 10
Training loss: 2.1992812156677246
Validation loss: 2.140058080355326

Epoch: 5| Step: 11
Training loss: 2.629551410675049
Validation loss: 2.134677122036616

Epoch: 73| Step: 0
Training loss: 2.3767619132995605
Validation loss: 2.133670146266619

Epoch: 5| Step: 1
Training loss: 1.81758713722229
Validation loss: 2.1281264225641885

Epoch: 5| Step: 2
Training loss: 2.4679336547851562
Validation loss: 2.126453777154287

Epoch: 5| Step: 3
Training loss: 2.0708913803100586
Validation loss: 2.1278080691893897

Epoch: 5| Step: 4
Training loss: 2.1326088905334473
Validation loss: 2.125147819519043

Epoch: 5| Step: 5
Training loss: 2.464207410812378
Validation loss: 2.124711960554123

Epoch: 5| Step: 6
Training loss: 2.1105542182922363
Validation loss: 2.123427247007688

Epoch: 5| Step: 7
Training loss: 2.7286641597747803
Validation loss: 2.1248072336117425

Epoch: 5| Step: 8
Training loss: 2.6687235832214355
Validation loss: 2.1230827420949936

Epoch: 5| Step: 9
Training loss: 2.555222272872925
Validation loss: 2.121109182635943

Epoch: 5| Step: 10
Training loss: 1.7179062366485596
Validation loss: 2.11953296760718

Epoch: 5| Step: 11
Training loss: 3.3042311668395996
Validation loss: 2.1193597614765167

Epoch: 74| Step: 0
Training loss: 2.623000144958496
Validation loss: 2.116335908571879

Epoch: 5| Step: 1
Training loss: 2.1568961143493652
Validation loss: 2.118050863345464

Epoch: 5| Step: 2
Training loss: 1.8982881307601929
Validation loss: 2.1124534209569297

Epoch: 5| Step: 3
Training loss: 2.6407384872436523
Validation loss: 2.1126365462938943

Epoch: 5| Step: 4
Training loss: 2.0681700706481934
Validation loss: 2.1077697823445

Epoch: 5| Step: 5
Training loss: 2.143489360809326
Validation loss: 2.1112155318260193

Epoch: 5| Step: 6
Training loss: 1.8765605688095093
Validation loss: 2.1048153042793274

Epoch: 5| Step: 7
Training loss: 2.1805434226989746
Validation loss: 2.1070824414491653

Epoch: 5| Step: 8
Training loss: 2.2187209129333496
Validation loss: 2.105290820201238

Epoch: 5| Step: 9
Training loss: 2.9506561756134033
Validation loss: 2.1034756948550544

Epoch: 5| Step: 10
Training loss: 2.2827773094177246
Validation loss: 2.0970907310644784

Epoch: 5| Step: 11
Training loss: 2.713667869567871
Validation loss: 2.103292112549146

Epoch: 75| Step: 0
Training loss: 2.9525046348571777
Validation loss: 2.1047109166781106

Epoch: 5| Step: 1
Training loss: 2.049952268600464
Validation loss: 2.105713422099749

Epoch: 5| Step: 2
Training loss: 2.6147866249084473
Validation loss: 2.111001049478849

Epoch: 5| Step: 3
Training loss: 2.374518871307373
Validation loss: 2.1098621040582657

Epoch: 5| Step: 4
Training loss: 1.770636796951294
Validation loss: 2.1051907489697137

Epoch: 5| Step: 5
Training loss: 2.37485933303833
Validation loss: 2.1094521085421243

Epoch: 5| Step: 6
Training loss: 2.298698902130127
Validation loss: 2.0984747260808945

Epoch: 5| Step: 7
Training loss: 2.107673406600952
Validation loss: 2.0942258089780807

Epoch: 5| Step: 8
Training loss: 1.9581878185272217
Validation loss: 2.0944443891445794

Epoch: 5| Step: 9
Training loss: 2.0818004608154297
Validation loss: 2.0935955991347632

Epoch: 5| Step: 10
Training loss: 2.4322502613067627
Validation loss: 2.0872508883476257

Epoch: 5| Step: 11
Training loss: 2.4040446281433105
Validation loss: 2.0937790870666504

Epoch: 76| Step: 0
Training loss: 2.4179348945617676
Validation loss: 2.0895076940457025

Epoch: 5| Step: 1
Training loss: 2.3545098304748535
Validation loss: 2.0936712622642517

Epoch: 5| Step: 2
Training loss: 1.9117504358291626
Validation loss: 2.09039439757665

Epoch: 5| Step: 3
Training loss: 2.739887237548828
Validation loss: 2.0962586055199304

Epoch: 5| Step: 4
Training loss: 2.2515242099761963
Validation loss: 2.088371604681015

Epoch: 5| Step: 5
Training loss: 1.8308515548706055
Validation loss: 2.0855011294285455

Epoch: 5| Step: 6
Training loss: 1.723318099975586
Validation loss: 2.0840738266706467

Epoch: 5| Step: 7
Training loss: 2.406771421432495
Validation loss: 2.0819477488597236

Epoch: 5| Step: 8
Training loss: 2.3067467212677
Validation loss: 2.0791824559370675

Epoch: 5| Step: 9
Training loss: 2.4867451190948486
Validation loss: 2.0808060516913733

Epoch: 5| Step: 10
Training loss: 2.2715234756469727
Validation loss: 2.081072047352791

Epoch: 5| Step: 11
Training loss: 3.1301119327545166
Validation loss: 2.084876368443171

Epoch: 77| Step: 0
Training loss: 1.9342386722564697
Validation loss: 2.088282490770022

Epoch: 5| Step: 1
Training loss: 2.446500778198242
Validation loss: 2.0867879589398703

Epoch: 5| Step: 2
Training loss: 1.7871949672698975
Validation loss: 2.0842815140883126

Epoch: 5| Step: 3
Training loss: 2.0435054302215576
Validation loss: 2.0843463192383447

Epoch: 5| Step: 4
Training loss: 2.67071533203125
Validation loss: 2.0820358842611313

Epoch: 5| Step: 5
Training loss: 2.0735270977020264
Validation loss: 2.080950195590655

Epoch: 5| Step: 6
Training loss: 2.187286853790283
Validation loss: 2.0747556934754052

Epoch: 5| Step: 7
Training loss: 2.585965633392334
Validation loss: 2.0706638346115747

Epoch: 5| Step: 8
Training loss: 2.102128505706787
Validation loss: 2.070918947458267

Epoch: 5| Step: 9
Training loss: 2.4537837505340576
Validation loss: 2.0720318853855133

Epoch: 5| Step: 10
Training loss: 2.173983573913574
Validation loss: 2.070149173339208

Epoch: 5| Step: 11
Training loss: 3.949488639831543
Validation loss: 2.0627996226151786

Epoch: 78| Step: 0
Training loss: 1.8315868377685547
Validation loss: 2.0759384433428445

Epoch: 5| Step: 1
Training loss: 2.164416790008545
Validation loss: 2.074804733196894

Epoch: 5| Step: 2
Training loss: 2.3694443702697754
Validation loss: 2.073517829179764

Epoch: 5| Step: 3
Training loss: 2.7310853004455566
Validation loss: 2.072929541269938

Epoch: 5| Step: 4
Training loss: 2.7367002964019775
Validation loss: 2.06752148270607

Epoch: 5| Step: 5
Training loss: 1.9309303760528564
Validation loss: 2.0651647746562958

Epoch: 5| Step: 6
Training loss: 2.1903393268585205
Validation loss: 2.0651712814966836

Epoch: 5| Step: 7
Training loss: 2.0138039588928223
Validation loss: 2.0614409744739532

Epoch: 5| Step: 8
Training loss: 2.174110174179077
Validation loss: 2.0767162839571633

Epoch: 5| Step: 9
Training loss: 2.2178702354431152
Validation loss: 2.0754580944776535

Epoch: 5| Step: 10
Training loss: 2.298733949661255
Validation loss: 2.0767099459966025

Epoch: 5| Step: 11
Training loss: 2.0762546062469482
Validation loss: 2.077736179033915

Epoch: 79| Step: 0
Training loss: 2.517632484436035
Validation loss: 2.0759035646915436

Epoch: 5| Step: 1
Training loss: 2.454418420791626
Validation loss: 2.079177046815554

Epoch: 5| Step: 2
Training loss: 2.195613384246826
Validation loss: 2.0820946047703424

Epoch: 5| Step: 3
Training loss: 2.289926528930664
Validation loss: 2.0781132926543555

Epoch: 5| Step: 4
Training loss: 2.4960150718688965
Validation loss: 2.0837296495834985

Epoch: 5| Step: 5
Training loss: 2.223611354827881
Validation loss: 2.0776269733905792

Epoch: 5| Step: 6
Training loss: 2.433337688446045
Validation loss: 2.0689868927001953

Epoch: 5| Step: 7
Training loss: 1.9433362483978271
Validation loss: 2.0630308389663696

Epoch: 5| Step: 8
Training loss: 1.9752384424209595
Validation loss: 2.063763598601023

Epoch: 5| Step: 9
Training loss: 1.8157432079315186
Validation loss: 2.0593474209308624

Epoch: 5| Step: 10
Training loss: 2.415165662765503
Validation loss: 2.0629620254039764

Epoch: 5| Step: 11
Training loss: 2.5989503860473633
Validation loss: 2.0623933176199594

Epoch: 80| Step: 0
Training loss: 2.467867612838745
Validation loss: 2.0571497877438865

Epoch: 5| Step: 1
Training loss: 2.324382781982422
Validation loss: 2.0508199681838355

Epoch: 5| Step: 2
Training loss: 1.4437105655670166
Validation loss: 2.0535842080911

Epoch: 5| Step: 3
Training loss: 2.3330893516540527
Validation loss: 2.0516457756360373

Epoch: 5| Step: 4
Training loss: 2.115169048309326
Validation loss: 2.050268918275833

Epoch: 5| Step: 5
Training loss: 2.708944797515869
Validation loss: 2.051118458310763

Epoch: 5| Step: 6
Training loss: 2.6017260551452637
Validation loss: 2.046619564294815

Epoch: 5| Step: 7
Training loss: 2.183159351348877
Validation loss: 2.051818698644638

Epoch: 5| Step: 8
Training loss: 2.546435594558716
Validation loss: 2.0527744044860206

Epoch: 5| Step: 9
Training loss: 1.629357933998108
Validation loss: 2.0448521425326667

Epoch: 5| Step: 10
Training loss: 2.0953593254089355
Validation loss: 2.052591731150945

Epoch: 5| Step: 11
Training loss: 2.533583641052246
Validation loss: 2.047917072971662

Epoch: 81| Step: 0
Training loss: 2.2287087440490723
Validation loss: 2.05459234615167

Epoch: 5| Step: 1
Training loss: 2.6370222568511963
Validation loss: 2.055920963486036

Epoch: 5| Step: 2
Training loss: 2.0874569416046143
Validation loss: 2.0582898457845054

Epoch: 5| Step: 3
Training loss: 2.3528685569763184
Validation loss: 2.0534988244374595

Epoch: 5| Step: 4
Training loss: 2.0637898445129395
Validation loss: 2.0598760743935904

Epoch: 5| Step: 5
Training loss: 2.06972336769104
Validation loss: 2.061495915055275

Epoch: 5| Step: 6
Training loss: 2.3924999237060547
Validation loss: 2.0615400026241937

Epoch: 5| Step: 7
Training loss: 2.2783005237579346
Validation loss: 2.059974451859792

Epoch: 5| Step: 8
Training loss: 1.9672256708145142
Validation loss: 2.065027579665184

Epoch: 5| Step: 9
Training loss: 2.642652988433838
Validation loss: 2.0603591402371726

Epoch: 5| Step: 10
Training loss: 1.9231618642807007
Validation loss: 2.0583545764287314

Epoch: 5| Step: 11
Training loss: 2.543933391571045
Validation loss: 2.06238483885924

Epoch: 82| Step: 0
Training loss: 2.39013409614563
Validation loss: 2.0574541141589484

Epoch: 5| Step: 1
Training loss: 2.413649082183838
Validation loss: 2.0472642680009208

Epoch: 5| Step: 2
Training loss: 2.285130739212036
Validation loss: 2.0502923727035522

Epoch: 5| Step: 3
Training loss: 2.5174596309661865
Validation loss: 2.0429576685031257

Epoch: 5| Step: 4
Training loss: 2.128955364227295
Validation loss: 2.046357328693072

Epoch: 5| Step: 5
Training loss: 2.272531270980835
Validation loss: 2.0449563960234323

Epoch: 5| Step: 6
Training loss: 1.4147379398345947
Validation loss: 2.0597293029228845

Epoch: 5| Step: 7
Training loss: 2.7037413120269775
Validation loss: 2.0596598784128823

Epoch: 5| Step: 8
Training loss: 2.259760856628418
Validation loss: 2.0520328730344772

Epoch: 5| Step: 9
Training loss: 2.7017276287078857
Validation loss: 2.0594343145688376

Epoch: 5| Step: 10
Training loss: 1.8817236423492432
Validation loss: 2.0427908351023993

Epoch: 5| Step: 11
Training loss: 0.8883440494537354
Validation loss: 2.0407277842362723

Epoch: 83| Step: 0
Training loss: 2.308145761489868
Validation loss: 2.0385815401872

Epoch: 5| Step: 1
Training loss: 2.758756637573242
Validation loss: 2.0374204168717065

Epoch: 5| Step: 2
Training loss: 2.1769838333129883
Validation loss: 2.038114527861277

Epoch: 5| Step: 3
Training loss: 2.322085380554199
Validation loss: 2.0360002716382346

Epoch: 5| Step: 4
Training loss: 2.286356210708618
Validation loss: 2.0394323766231537

Epoch: 5| Step: 5
Training loss: 2.208254098892212
Validation loss: 2.0378572146097818

Epoch: 5| Step: 6
Training loss: 2.017350196838379
Validation loss: 2.0400836716095605

Epoch: 5| Step: 7
Training loss: 2.236088752746582
Validation loss: 2.041798874735832

Epoch: 5| Step: 8
Training loss: 2.1054434776306152
Validation loss: 2.04191126426061

Epoch: 5| Step: 9
Training loss: 1.9000322818756104
Validation loss: 2.04191384712855

Epoch: 5| Step: 10
Training loss: 2.1938512325286865
Validation loss: 2.0338572512070336

Epoch: 5| Step: 11
Training loss: 1.181352972984314
Validation loss: 2.0376121600468955

Epoch: 84| Step: 0
Training loss: 2.6821706295013428
Validation loss: 2.0359830359617868

Epoch: 5| Step: 1
Training loss: 2.112062931060791
Validation loss: 2.0344813217719397

Epoch: 5| Step: 2
Training loss: 2.4225521087646484
Validation loss: 2.0490793138742447

Epoch: 5| Step: 3
Training loss: 2.125441074371338
Validation loss: 2.0488283137480416

Epoch: 5| Step: 4
Training loss: 1.6951959133148193
Validation loss: 2.045541897416115

Epoch: 5| Step: 5
Training loss: 2.2909939289093018
Validation loss: 2.0542009472846985

Epoch: 5| Step: 6
Training loss: 2.1388542652130127
Validation loss: 2.0508437554041543

Epoch: 5| Step: 7
Training loss: 1.8856537342071533
Validation loss: 2.0523327589035034

Epoch: 5| Step: 8
Training loss: 2.373164653778076
Validation loss: 2.0563612629969916

Epoch: 5| Step: 9
Training loss: 2.355501174926758
Validation loss: 2.0573583791653314

Epoch: 5| Step: 10
Training loss: 2.2086119651794434
Validation loss: 2.0436958273251853

Epoch: 5| Step: 11
Training loss: 1.9336518049240112
Validation loss: 2.040703316529592

Epoch: 85| Step: 0
Training loss: 2.0270025730133057
Validation loss: 2.0248981614907584

Epoch: 5| Step: 1
Training loss: 2.5235695838928223
Validation loss: 2.0131282260020575

Epoch: 5| Step: 2
Training loss: 2.4811530113220215
Validation loss: 2.0221482863028846

Epoch: 5| Step: 3
Training loss: 2.7441680431365967
Validation loss: 2.027599682410558

Epoch: 5| Step: 4
Training loss: 1.723171591758728
Validation loss: 2.036931907137235

Epoch: 5| Step: 5
Training loss: 2.342869281768799
Validation loss: 2.032801628112793

Epoch: 5| Step: 6
Training loss: 2.0531325340270996
Validation loss: 2.043901098271211

Epoch: 5| Step: 7
Training loss: 2.008023500442505
Validation loss: 2.0318907499313354

Epoch: 5| Step: 8
Training loss: 2.3747456073760986
Validation loss: 2.0221588909626007

Epoch: 5| Step: 9
Training loss: 2.1185219287872314
Validation loss: 2.026503692070643

Epoch: 5| Step: 10
Training loss: 1.8349775075912476
Validation loss: 2.0135169376929603

Epoch: 5| Step: 11
Training loss: 1.595538854598999
Validation loss: 2.022295832633972

Epoch: 86| Step: 0
Training loss: 2.2010979652404785
Validation loss: 2.022663245598475

Epoch: 5| Step: 1
Training loss: 1.7894748449325562
Validation loss: 2.02339177330335

Epoch: 5| Step: 2
Training loss: 1.8537362813949585
Validation loss: 2.020873268445333

Epoch: 5| Step: 3
Training loss: 2.6266720294952393
Validation loss: 2.032115106781324

Epoch: 5| Step: 4
Training loss: 2.7773025035858154
Validation loss: 2.0261197884877524

Epoch: 5| Step: 5
Training loss: 2.201533079147339
Validation loss: 2.030215506752332

Epoch: 5| Step: 6
Training loss: 2.2443034648895264
Validation loss: 2.034229745467504

Epoch: 5| Step: 7
Training loss: 1.9363456964492798
Validation loss: 2.038810282945633

Epoch: 5| Step: 8
Training loss: 2.1221518516540527
Validation loss: 2.0317105601231256

Epoch: 5| Step: 9
Training loss: 2.048809766769409
Validation loss: 2.0330647627512612

Epoch: 5| Step: 10
Training loss: 2.4069926738739014
Validation loss: 2.036642923951149

Epoch: 5| Step: 11
Training loss: 1.374488353729248
Validation loss: 2.02606629828612

Epoch: 87| Step: 0
Training loss: 1.908752202987671
Validation loss: 2.022614339987437

Epoch: 5| Step: 1
Training loss: 2.44970440864563
Validation loss: 2.0268504271904626

Epoch: 5| Step: 2
Training loss: 1.863037109375
Validation loss: 2.019794593254725

Epoch: 5| Step: 3
Training loss: 2.350281238555908
Validation loss: 2.0284178406000137

Epoch: 5| Step: 4
Training loss: 2.344564914703369
Validation loss: 2.037218376994133

Epoch: 5| Step: 5
Training loss: 2.0681262016296387
Validation loss: 2.0307055562734604

Epoch: 5| Step: 6
Training loss: 2.3121931552886963
Validation loss: 2.0325058847665787

Epoch: 5| Step: 7
Training loss: 2.531040668487549
Validation loss: 2.037270257870356

Epoch: 5| Step: 8
Training loss: 1.5760866403579712
Validation loss: 2.027592351039251

Epoch: 5| Step: 9
Training loss: 2.309752941131592
Validation loss: 2.015993674596151

Epoch: 5| Step: 10
Training loss: 2.312255859375
Validation loss: 2.0173088858524957

Epoch: 5| Step: 11
Training loss: 3.2432050704956055
Validation loss: 2.0170157005389533

Epoch: 88| Step: 0
Training loss: 2.462890625
Validation loss: 2.021797835826874

Epoch: 5| Step: 1
Training loss: 2.2786145210266113
Validation loss: 2.0341858665148416

Epoch: 5| Step: 2
Training loss: 2.503889560699463
Validation loss: 2.034127692381541

Epoch: 5| Step: 3
Training loss: 2.167048931121826
Validation loss: 2.04508875310421

Epoch: 5| Step: 4
Training loss: 1.8561532497406006
Validation loss: 2.046326403816541

Epoch: 5| Step: 5
Training loss: 2.574164628982544
Validation loss: 2.041865905125936

Epoch: 5| Step: 6
Training loss: 2.239147663116455
Validation loss: 2.0347991039355597

Epoch: 5| Step: 7
Training loss: 1.969599723815918
Validation loss: 2.034148703018824

Epoch: 5| Step: 8
Training loss: 2.1078507900238037
Validation loss: 2.029200479388237

Epoch: 5| Step: 9
Training loss: 1.9315979480743408
Validation loss: 2.019422064224879

Epoch: 5| Step: 10
Training loss: 2.2008779048919678
Validation loss: 2.022236337264379

Epoch: 5| Step: 11
Training loss: 1.1362366676330566
Validation loss: 2.026084373394648

Epoch: 89| Step: 0
Training loss: 2.370304822921753
Validation loss: 2.033875529964765

Epoch: 5| Step: 1
Training loss: 2.1077258586883545
Validation loss: 2.0221145202716193

Epoch: 5| Step: 2
Training loss: 1.7394062280654907
Validation loss: 2.037757640083631

Epoch: 5| Step: 3
Training loss: 2.484358549118042
Validation loss: 2.040891950329145

Epoch: 5| Step: 4
Training loss: 1.5603914260864258
Validation loss: 2.045967554052671

Epoch: 5| Step: 5
Training loss: 2.3420250415802
Validation loss: 2.0491541624069214

Epoch: 5| Step: 6
Training loss: 2.186527729034424
Validation loss: 2.048948665459951

Epoch: 5| Step: 7
Training loss: 2.751276969909668
Validation loss: 2.0641772200663886

Epoch: 5| Step: 8
Training loss: 2.17503023147583
Validation loss: 2.0474864840507507

Epoch: 5| Step: 9
Training loss: 2.1432597637176514
Validation loss: 2.047174150745074

Epoch: 5| Step: 10
Training loss: 2.0638582706451416
Validation loss: 2.0427407373984656

Epoch: 5| Step: 11
Training loss: 2.3475546836853027
Validation loss: 2.038136124610901

Epoch: 90| Step: 0
Training loss: 1.7255287170410156
Validation loss: 2.027411470810572

Epoch: 5| Step: 1
Training loss: 2.210171699523926
Validation loss: 2.0276334285736084

Epoch: 5| Step: 2
Training loss: 2.247880220413208
Validation loss: 2.0249590426683426

Epoch: 5| Step: 3
Training loss: 1.700556993484497
Validation loss: 2.0251997212568917

Epoch: 5| Step: 4
Training loss: 2.2356362342834473
Validation loss: 2.019704600175222

Epoch: 5| Step: 5
Training loss: 2.3276526927948
Validation loss: 2.0256050527095795

Epoch: 5| Step: 6
Training loss: 2.2738475799560547
Validation loss: 2.027134045958519

Epoch: 5| Step: 7
Training loss: 2.2522506713867188
Validation loss: 2.0253510773181915

Epoch: 5| Step: 8
Training loss: 2.2006888389587402
Validation loss: 2.0244974146286645

Epoch: 5| Step: 9
Training loss: 2.36132550239563
Validation loss: 2.0220208019018173

Epoch: 5| Step: 10
Training loss: 2.6318206787109375
Validation loss: 2.0283846855163574

Epoch: 5| Step: 11
Training loss: 1.4479888677597046
Validation loss: 2.0322461277246475

Epoch: 91| Step: 0
Training loss: 1.797990083694458
Validation loss: 2.025318071246147

Epoch: 5| Step: 1
Training loss: 2.1432673931121826
Validation loss: 2.0283229301373162

Epoch: 5| Step: 2
Training loss: 1.8618004322052002
Validation loss: 2.020884782075882

Epoch: 5| Step: 3
Training loss: 1.9438222646713257
Validation loss: 2.0171192487080893

Epoch: 5| Step: 4
Training loss: 2.40897798538208
Validation loss: 2.0202155113220215

Epoch: 5| Step: 5
Training loss: 2.7617061138153076
Validation loss: 2.0172110895315805

Epoch: 5| Step: 6
Training loss: 1.4441471099853516
Validation loss: 2.017727037270864

Epoch: 5| Step: 7
Training loss: 2.4647202491760254
Validation loss: 2.0287986596425376

Epoch: 5| Step: 8
Training loss: 2.2352495193481445
Validation loss: 2.0271458824475608

Epoch: 5| Step: 9
Training loss: 2.1808371543884277
Validation loss: 2.038631096482277

Epoch: 5| Step: 10
Training loss: 2.60174298286438
Validation loss: 2.045354053378105

Epoch: 5| Step: 11
Training loss: 2.290841579437256
Validation loss: 2.043923109769821

Epoch: 92| Step: 0
Training loss: 2.700784683227539
Validation loss: 2.0322438528140387

Epoch: 5| Step: 1
Training loss: 1.7674859762191772
Validation loss: 2.0267066111167273

Epoch: 5| Step: 2
Training loss: 2.1798207759857178
Validation loss: 2.035477121671041

Epoch: 5| Step: 3
Training loss: 1.9596309661865234
Validation loss: 2.0242809057235718

Epoch: 5| Step: 4
Training loss: 2.4384005069732666
Validation loss: 2.027121290564537

Epoch: 5| Step: 5
Training loss: 1.8936134576797485
Validation loss: 2.0200112561384835

Epoch: 5| Step: 6
Training loss: 2.4914000034332275
Validation loss: 2.0277891953786216

Epoch: 5| Step: 7
Training loss: 2.3722801208496094
Validation loss: 2.0244005968173346

Epoch: 5| Step: 8
Training loss: 1.5161679983139038
Validation loss: 2.0176812261343002

Epoch: 5| Step: 9
Training loss: 2.168107509613037
Validation loss: 2.022472803791364

Epoch: 5| Step: 10
Training loss: 2.2811760902404785
Validation loss: 2.0319679776827493

Epoch: 5| Step: 11
Training loss: 2.338177442550659
Validation loss: 2.033476402362188

Epoch: 93| Step: 0
Training loss: 2.5455241203308105
Validation loss: 2.0377489974101386

Epoch: 5| Step: 1
Training loss: 2.0755808353424072
Validation loss: 2.031002938747406

Epoch: 5| Step: 2
Training loss: 2.55794095993042
Validation loss: 2.0332560588916144

Epoch: 5| Step: 3
Training loss: 2.3906311988830566
Validation loss: 2.033300240834554

Epoch: 5| Step: 4
Training loss: 1.4782794713974
Validation loss: 2.015670413772265

Epoch: 5| Step: 5
Training loss: 1.90886652469635
Validation loss: 2.0119331230719886

Epoch: 5| Step: 6
Training loss: 2.3690147399902344
Validation loss: 2.0205497443675995

Epoch: 5| Step: 7
Training loss: 2.3726859092712402
Validation loss: 2.0169485608736673

Epoch: 5| Step: 8
Training loss: 2.568735361099243
Validation loss: 2.0108107129732766

Epoch: 5| Step: 9
Training loss: 2.3501269817352295
Validation loss: 2.01485875248909

Epoch: 5| Step: 10
Training loss: 1.2733978033065796
Validation loss: 2.0125779708226523

Epoch: 5| Step: 11
Training loss: 2.1330485343933105
Validation loss: 2.0156959891319275

Epoch: 94| Step: 0
Training loss: 2.1415915489196777
Validation loss: 2.029033516844114

Epoch: 5| Step: 1
Training loss: 2.020742654800415
Validation loss: 2.031892562905947

Epoch: 5| Step: 2
Training loss: 2.3784186840057373
Validation loss: 2.0381112595399222

Epoch: 5| Step: 3
Training loss: 2.206791400909424
Validation loss: 2.0502110520998635

Epoch: 5| Step: 4
Training loss: 1.8835433721542358
Validation loss: 2.0481710582971573

Epoch: 5| Step: 5
Training loss: 2.6023590564727783
Validation loss: 2.0417359670003257

Epoch: 5| Step: 6
Training loss: 2.1091482639312744
Validation loss: 2.0486770371596017

Epoch: 5| Step: 7
Training loss: 2.148519515991211
Validation loss: 2.04734576245149

Epoch: 5| Step: 8
Training loss: 1.8755052089691162
Validation loss: 2.037425249814987

Epoch: 5| Step: 9
Training loss: 2.2352283000946045
Validation loss: 2.038871849576632

Epoch: 5| Step: 10
Training loss: 2.334311008453369
Validation loss: 2.027531365553538

Epoch: 5| Step: 11
Training loss: 2.1266231536865234
Validation loss: 2.0231928527355194

Epoch: 95| Step: 0
Training loss: 2.4253668785095215
Validation loss: 2.0239270528157554

Epoch: 5| Step: 1
Training loss: 2.4900426864624023
Validation loss: 2.0202464908361435

Epoch: 5| Step: 2
Training loss: 2.3829798698425293
Validation loss: 2.022011543313662

Epoch: 5| Step: 3
Training loss: 1.9977805614471436
Validation loss: 2.0224804480870566

Epoch: 5| Step: 4
Training loss: 1.7684276103973389
Validation loss: 2.023445188999176

Epoch: 5| Step: 5
Training loss: 2.1849303245544434
Validation loss: 2.027058646082878

Epoch: 5| Step: 6
Training loss: 2.2333836555480957
Validation loss: 2.0268826285998025

Epoch: 5| Step: 7
Training loss: 2.450249671936035
Validation loss: 2.0244572460651398

Epoch: 5| Step: 8
Training loss: 2.336751937866211
Validation loss: 2.0129101226727166

Epoch: 5| Step: 9
Training loss: 2.0014235973358154
Validation loss: 2.012595017751058

Epoch: 5| Step: 10
Training loss: 1.945852518081665
Validation loss: 2.020764797925949

Epoch: 5| Step: 11
Training loss: 0.6668451428413391
Validation loss: 2.0212923338015876

Epoch: 96| Step: 0
Training loss: 1.7601970434188843
Validation loss: 2.0247471034526825

Epoch: 5| Step: 1
Training loss: 2.093536853790283
Validation loss: 2.0366591115792594

Epoch: 5| Step: 2
Training loss: 2.248687505722046
Validation loss: 2.028723880648613

Epoch: 5| Step: 3
Training loss: 2.0264663696289062
Validation loss: 2.042539502183596

Epoch: 5| Step: 4
Training loss: 1.5853908061981201
Validation loss: 2.0413824717203775

Epoch: 5| Step: 5
Training loss: 2.773743152618408
Validation loss: 2.051599924763044

Epoch: 5| Step: 6
Training loss: 2.5628364086151123
Validation loss: 2.041233683625857

Epoch: 5| Step: 7
Training loss: 2.4980154037475586
Validation loss: 2.0394621888796487

Epoch: 5| Step: 8
Training loss: 2.350856304168701
Validation loss: 2.027385632197062

Epoch: 5| Step: 9
Training loss: 2.3233418464660645
Validation loss: 2.018424858649572

Epoch: 5| Step: 10
Training loss: 1.6294472217559814
Validation loss: 2.015796974301338

Epoch: 5| Step: 11
Training loss: 1.8935683965682983
Validation loss: 2.030347635348638

Epoch: 97| Step: 0
Training loss: 2.2477431297302246
Validation loss: 2.0305835405985513

Epoch: 5| Step: 1
Training loss: 2.1468112468719482
Validation loss: 2.036325881878535

Epoch: 5| Step: 2
Training loss: 2.168368101119995
Validation loss: 2.039138595263163

Epoch: 5| Step: 3
Training loss: 1.8555433750152588
Validation loss: 2.0521935721238456

Epoch: 5| Step: 4
Training loss: 2.7375500202178955
Validation loss: 2.039673094948133

Epoch: 5| Step: 5
Training loss: 1.6076076030731201
Validation loss: 2.043912559747696

Epoch: 5| Step: 6
Training loss: 2.1546292304992676
Validation loss: 2.036557594935099

Epoch: 5| Step: 7
Training loss: 2.6346945762634277
Validation loss: 2.0310700883467994

Epoch: 5| Step: 8
Training loss: 2.7900848388671875
Validation loss: 2.034220223625501

Epoch: 5| Step: 9
Training loss: 1.4476232528686523
Validation loss: 2.0204524050156274

Epoch: 5| Step: 10
Training loss: 2.2248895168304443
Validation loss: 2.0084878305594125

Epoch: 5| Step: 11
Training loss: 2.6597719192504883
Validation loss: 2.0093141545852027

Epoch: 98| Step: 0
Training loss: 1.6880824565887451
Validation loss: 2.0221545646588006

Epoch: 5| Step: 1
Training loss: 2.12068772315979
Validation loss: 2.0349536736806235

Epoch: 5| Step: 2
Training loss: 2.690337657928467
Validation loss: 2.0445567071437836

Epoch: 5| Step: 3
Training loss: 2.4782943725585938
Validation loss: 2.0594146996736526

Epoch: 5| Step: 4
Training loss: 1.9277913570404053
Validation loss: 2.0584378639856973

Epoch: 5| Step: 5
Training loss: 2.0411646366119385
Validation loss: 2.0503508895635605

Epoch: 5| Step: 6
Training loss: 2.126004695892334
Validation loss: 2.0442919731140137

Epoch: 5| Step: 7
Training loss: 2.5602493286132812
Validation loss: 2.044501448671023

Epoch: 5| Step: 8
Training loss: 2.1971867084503174
Validation loss: 2.023725296060244

Epoch: 5| Step: 9
Training loss: 2.359212875366211
Validation loss: 2.024080624183019

Epoch: 5| Step: 10
Training loss: 1.8774693012237549
Validation loss: 2.0124832590421042

Epoch: 5| Step: 11
Training loss: 1.6235487461090088
Validation loss: 2.0236487487951913

Epoch: 99| Step: 0
Training loss: 2.088798999786377
Validation loss: 2.0272144426902137

Epoch: 5| Step: 1
Training loss: 1.830514669418335
Validation loss: 2.020116234819094

Epoch: 5| Step: 2
Training loss: 2.584739923477173
Validation loss: 2.0255916913350425

Epoch: 5| Step: 3
Training loss: 1.664341688156128
Validation loss: 2.0253791560729346

Epoch: 5| Step: 4
Training loss: 2.6922342777252197
Validation loss: 2.027534713347753

Epoch: 5| Step: 5
Training loss: 2.1071701049804688
Validation loss: 2.0208185414473214

Epoch: 5| Step: 6
Training loss: 1.613969087600708
Validation loss: 2.018190016349157

Epoch: 5| Step: 7
Training loss: 2.527482271194458
Validation loss: 2.0239433149496713

Epoch: 5| Step: 8
Training loss: 2.5794670581817627
Validation loss: 2.0275987138350806

Epoch: 5| Step: 9
Training loss: 1.9023821353912354
Validation loss: 2.0316605418920517

Epoch: 5| Step: 10
Training loss: 2.1016604900360107
Validation loss: 2.037309284011523

Epoch: 5| Step: 11
Training loss: 2.8529322147369385
Validation loss: 2.0337542792161307

Epoch: 100| Step: 0
Training loss: 2.2037360668182373
Validation loss: 2.04757297039032

Epoch: 5| Step: 1
Training loss: 1.8322521448135376
Validation loss: 2.0347417891025543

Epoch: 5| Step: 2
Training loss: 2.2336840629577637
Validation loss: 2.035834933320681

Epoch: 5| Step: 3
Training loss: 2.4261491298675537
Validation loss: 2.027793064713478

Epoch: 5| Step: 4
Training loss: 2.294445037841797
Validation loss: 2.023686413963636

Epoch: 5| Step: 5
Training loss: 2.6358909606933594
Validation loss: 2.0131001621484756

Epoch: 5| Step: 6
Training loss: 2.097852945327759
Validation loss: 2.019108538826307

Epoch: 5| Step: 7
Training loss: 1.6332203149795532
Validation loss: 2.018859177827835

Epoch: 5| Step: 8
Training loss: 2.08665132522583
Validation loss: 2.0233228305975595

Epoch: 5| Step: 9
Training loss: 1.8590691089630127
Validation loss: 2.017683039108912

Epoch: 5| Step: 10
Training loss: 2.4625675678253174
Validation loss: 2.0183051228523254

Epoch: 5| Step: 11
Training loss: 1.6444017887115479
Validation loss: 2.019133279720942

Epoch: 101| Step: 0
Training loss: 2.066537380218506
Validation loss: 2.024160464604696

Epoch: 5| Step: 1
Training loss: 2.589653491973877
Validation loss: 2.0198300381501517

Epoch: 5| Step: 2
Training loss: 1.9575049877166748
Validation loss: 2.0240292449792228

Epoch: 5| Step: 3
Training loss: 2.2045540809631348
Validation loss: 2.0206228494644165

Epoch: 5| Step: 4
Training loss: 2.4039204120635986
Validation loss: 2.015857458114624

Epoch: 5| Step: 5
Training loss: 1.8644304275512695
Validation loss: 2.024909441669782

Epoch: 5| Step: 6
Training loss: 2.000871181488037
Validation loss: 2.029343475898107

Epoch: 5| Step: 7
Training loss: 2.4519999027252197
Validation loss: 2.0207924445470176

Epoch: 5| Step: 8
Training loss: 1.7024791240692139
Validation loss: 2.02986071507136

Epoch: 5| Step: 9
Training loss: 2.5840675830841064
Validation loss: 2.015566274523735

Epoch: 5| Step: 10
Training loss: 1.7866952419281006
Validation loss: 2.0190360794464746

Epoch: 5| Step: 11
Training loss: 2.8074660301208496
Validation loss: 2.01146736741066

Epoch: 102| Step: 0
Training loss: 2.5363941192626953
Validation loss: 2.0165200531482697

Epoch: 5| Step: 1
Training loss: 2.4704580307006836
Validation loss: 2.011577973763148

Epoch: 5| Step: 2
Training loss: 2.5671067237854004
Validation loss: 2.008342444896698

Epoch: 5| Step: 3
Training loss: 2.2309327125549316
Validation loss: 2.0105997125307717

Epoch: 5| Step: 4
Training loss: 2.576970100402832
Validation loss: 2.011170412103335

Epoch: 5| Step: 5
Training loss: 2.1200757026672363
Validation loss: 2.015064070622126

Epoch: 5| Step: 6
Training loss: 1.7949349880218506
Validation loss: 2.0195038616657257

Epoch: 5| Step: 7
Training loss: 1.8658277988433838
Validation loss: 2.021914228796959

Epoch: 5| Step: 8
Training loss: 2.099257469177246
Validation loss: 2.0325596580902734

Epoch: 5| Step: 9
Training loss: 1.5291411876678467
Validation loss: 2.0334050903717675

Epoch: 5| Step: 10
Training loss: 2.0684244632720947
Validation loss: 2.0299307058254876

Epoch: 5| Step: 11
Training loss: 1.3005695343017578
Validation loss: 2.0232748985290527

Epoch: 103| Step: 0
Training loss: 2.1815133094787598
Validation loss: 2.0252249787251153

Epoch: 5| Step: 1
Training loss: 2.598334550857544
Validation loss: 2.047446444630623

Epoch: 5| Step: 2
Training loss: 2.2690906524658203
Validation loss: 2.0306080977121987

Epoch: 5| Step: 3
Training loss: 1.879468560218811
Validation loss: 2.0280628552039466

Epoch: 5| Step: 4
Training loss: 2.083430767059326
Validation loss: 2.027530406912168

Epoch: 5| Step: 5
Training loss: 2.0505127906799316
Validation loss: 2.026660198966662

Epoch: 5| Step: 6
Training loss: 2.0239195823669434
Validation loss: 2.013174906373024

Epoch: 5| Step: 7
Training loss: 1.6995769739151
Validation loss: 2.0131784031788507

Epoch: 5| Step: 8
Training loss: 2.1372742652893066
Validation loss: 2.0112078189849854

Epoch: 5| Step: 9
Training loss: 2.521467685699463
Validation loss: 2.008320172627767

Epoch: 5| Step: 10
Training loss: 1.929316759109497
Validation loss: 2.0109291026989617

Epoch: 5| Step: 11
Training loss: 3.513683319091797
Validation loss: 2.0101776669422784

Epoch: 104| Step: 0
Training loss: 2.314143419265747
Validation loss: 2.015185669064522

Epoch: 5| Step: 1
Training loss: 1.883669137954712
Validation loss: 2.0191586216290793

Epoch: 5| Step: 2
Training loss: 1.8051280975341797
Validation loss: 2.011896933118502

Epoch: 5| Step: 3
Training loss: 2.49735164642334
Validation loss: 2.0132813900709152

Epoch: 5| Step: 4
Training loss: 2.0230634212493896
Validation loss: 2.009662335117658

Epoch: 5| Step: 5
Training loss: 2.0163376331329346
Validation loss: 2.012201279401779

Epoch: 5| Step: 6
Training loss: 2.1309280395507812
Validation loss: 2.0176544189453125

Epoch: 5| Step: 7
Training loss: 2.177932024002075
Validation loss: 2.0137541641791663

Epoch: 5| Step: 8
Training loss: 1.962589979171753
Validation loss: 2.0216086556514106

Epoch: 5| Step: 9
Training loss: 2.015462875366211
Validation loss: 2.0254164040088654

Epoch: 5| Step: 10
Training loss: 2.5953140258789062
Validation loss: 2.020170191923777

Epoch: 5| Step: 11
Training loss: 2.8735105991363525
Validation loss: 2.016000290711721

Epoch: 105| Step: 0
Training loss: 2.264498472213745
Validation loss: 2.026928255955378

Epoch: 5| Step: 1
Training loss: 1.9953514337539673
Validation loss: 2.010862484574318

Epoch: 5| Step: 2
Training loss: 2.3690216541290283
Validation loss: 2.0225055615107217

Epoch: 5| Step: 3
Training loss: 1.696401834487915
Validation loss: 2.027201697230339

Epoch: 5| Step: 4
Training loss: 1.8275210857391357
Validation loss: 2.028960565725962

Epoch: 5| Step: 5
Training loss: 2.180746555328369
Validation loss: 2.0268820971250534

Epoch: 5| Step: 6
Training loss: 2.3311562538146973
Validation loss: 2.0273279498020806

Epoch: 5| Step: 7
Training loss: 2.034472942352295
Validation loss: 2.0272703419129052

Epoch: 5| Step: 8
Training loss: 2.3425095081329346
Validation loss: 2.0214363634586334

Epoch: 5| Step: 9
Training loss: 2.204857349395752
Validation loss: 2.02418847878774

Epoch: 5| Step: 10
Training loss: 1.9724185466766357
Validation loss: 2.0194913198550544

Epoch: 5| Step: 11
Training loss: 2.784576654434204
Validation loss: 2.0330395996570587

Epoch: 106| Step: 0
Training loss: 2.073061943054199
Validation loss: 2.022421250740687

Epoch: 5| Step: 1
Training loss: 1.896384835243225
Validation loss: 2.0225195785363517

Epoch: 5| Step: 2
Training loss: 1.9555866718292236
Validation loss: 2.0190458993117013

Epoch: 5| Step: 3
Training loss: 1.7560240030288696
Validation loss: 2.021474783619245

Epoch: 5| Step: 4
Training loss: 2.6531589031219482
Validation loss: 2.0210562149683633

Epoch: 5| Step: 5
Training loss: 1.9856069087982178
Validation loss: 2.0203493336836496

Epoch: 5| Step: 6
Training loss: 1.8638479709625244
Validation loss: 2.0150948067506156

Epoch: 5| Step: 7
Training loss: 2.4614417552948
Validation loss: 2.0212426682313285

Epoch: 5| Step: 8
Training loss: 2.134219169616699
Validation loss: 2.0150360663731894

Epoch: 5| Step: 9
Training loss: 2.612908363342285
Validation loss: 2.030223781863848

Epoch: 5| Step: 10
Training loss: 1.795416235923767
Validation loss: 2.027559037009875

Epoch: 5| Step: 11
Training loss: 3.441620349884033
Validation loss: 2.0278175473213196

Epoch: 107| Step: 0
Training loss: 1.8327611684799194
Validation loss: 2.016013359030088

Epoch: 5| Step: 1
Training loss: 1.6793979406356812
Validation loss: 2.0177931437889733

Epoch: 5| Step: 2
Training loss: 1.808039665222168
Validation loss: 2.023105949163437

Epoch: 5| Step: 3
Training loss: 2.6766357421875
Validation loss: 2.0240877717733383

Epoch: 5| Step: 4
Training loss: 2.452186107635498
Validation loss: 2.0332548916339874

Epoch: 5| Step: 5
Training loss: 2.450458288192749
Validation loss: 2.0231579691171646

Epoch: 5| Step: 6
Training loss: 2.0568478107452393
Validation loss: 2.0282348295052848

Epoch: 5| Step: 7
Training loss: 2.315229892730713
Validation loss: 2.0229747345050177

Epoch: 5| Step: 8
Training loss: 2.186812162399292
Validation loss: 2.0364152590433755

Epoch: 5| Step: 9
Training loss: 2.321434497833252
Validation loss: 2.02490825454394

Epoch: 5| Step: 10
Training loss: 2.2719638347625732
Validation loss: 2.0230877796808877

Epoch: 5| Step: 11
Training loss: 1.3524644374847412
Validation loss: 2.023541529973348

Epoch: 108| Step: 0
Training loss: 1.9101520776748657
Validation loss: 2.0139020880063376

Epoch: 5| Step: 1
Training loss: 2.2676949501037598
Validation loss: 2.013378823796908

Epoch: 5| Step: 2
Training loss: 2.063642978668213
Validation loss: 2.0070467789967856

Epoch: 5| Step: 3
Training loss: 2.2647080421447754
Validation loss: 2.019184802969297

Epoch: 5| Step: 4
Training loss: 1.516754150390625
Validation loss: 2.0263875971237817

Epoch: 5| Step: 5
Training loss: 3.0047595500946045
Validation loss: 2.037265787521998

Epoch: 5| Step: 6
Training loss: 1.9990594387054443
Validation loss: 2.0232294301191964

Epoch: 5| Step: 7
Training loss: 2.1871354579925537
Validation loss: 2.035678873459498

Epoch: 5| Step: 8
Training loss: 2.530088186264038
Validation loss: 2.0422132313251495

Epoch: 5| Step: 9
Training loss: 1.8878071308135986
Validation loss: 2.056494484345118

Epoch: 5| Step: 10
Training loss: 2.2002787590026855
Validation loss: 2.0515638142824173

Epoch: 5| Step: 11
Training loss: 1.8789552450180054
Validation loss: 2.0468286822239556

Epoch: 109| Step: 0
Training loss: 2.00823712348938
Validation loss: 2.026416207353274

Epoch: 5| Step: 1
Training loss: 1.7471355199813843
Validation loss: 2.0243294139703116

Epoch: 5| Step: 2
Training loss: 1.5814343690872192
Validation loss: 2.0226144194602966

Epoch: 5| Step: 3
Training loss: 2.443976640701294
Validation loss: 2.0115783711274466

Epoch: 5| Step: 4
Training loss: 2.044839382171631
Validation loss: 2.0148476312557855

Epoch: 5| Step: 5
Training loss: 2.2270472049713135
Validation loss: 2.0124764641126

Epoch: 5| Step: 6
Training loss: 1.6764271259307861
Validation loss: 2.01866685350736

Epoch: 5| Step: 7
Training loss: 2.4858996868133545
Validation loss: 2.0121451864639917

Epoch: 5| Step: 8
Training loss: 2.383791923522949
Validation loss: 2.022851119438807

Epoch: 5| Step: 9
Training loss: 2.2204689979553223
Validation loss: 2.0204885552326837

Epoch: 5| Step: 10
Training loss: 2.3382763862609863
Validation loss: 2.0200622330109277

Epoch: 5| Step: 11
Training loss: 3.527421474456787
Validation loss: 2.0168750236431756

Epoch: 110| Step: 0
Training loss: 2.593015193939209
Validation loss: 2.0223954170942307

Epoch: 5| Step: 1
Training loss: 2.234391689300537
Validation loss: 2.009754464030266

Epoch: 5| Step: 2
Training loss: 1.8277994394302368
Validation loss: 2.0148596465587616

Epoch: 5| Step: 3
Training loss: 1.8448292016983032
Validation loss: 2.0032561272382736

Epoch: 5| Step: 4
Training loss: 1.8984086513519287
Validation loss: 2.0080280154943466

Epoch: 5| Step: 5
Training loss: 2.385817766189575
Validation loss: 2.004532754421234

Epoch: 5| Step: 6
Training loss: 2.513657808303833
Validation loss: 2.005714034040769

Epoch: 5| Step: 7
Training loss: 2.3796372413635254
Validation loss: 2.008232812086741

Epoch: 5| Step: 8
Training loss: 1.7645924091339111
Validation loss: 2.005531683564186

Epoch: 5| Step: 9
Training loss: 2.0226664543151855
Validation loss: 2.003720462322235

Epoch: 5| Step: 10
Training loss: 1.8994213342666626
Validation loss: 2.0135307709376016

Epoch: 5| Step: 11
Training loss: 2.5872697830200195
Validation loss: 2.01267808675766

Epoch: 111| Step: 0
Training loss: 2.002058744430542
Validation loss: 2.0090884069601693

Epoch: 5| Step: 1
Training loss: 2.0573811531066895
Validation loss: 1.9963002155224483

Epoch: 5| Step: 2
Training loss: 2.0074310302734375
Validation loss: 1.9999705304702122

Epoch: 5| Step: 3
Training loss: 1.7010018825531006
Validation loss: 1.9948525428771973

Epoch: 5| Step: 4
Training loss: 2.2416391372680664
Validation loss: 1.9958708236614864

Epoch: 5| Step: 5
Training loss: 2.8088314533233643
Validation loss: 1.9931808908780415

Epoch: 5| Step: 6
Training loss: 2.0063042640686035
Validation loss: 1.9857615729173024

Epoch: 5| Step: 7
Training loss: 1.9163408279418945
Validation loss: 1.9901131341854732

Epoch: 5| Step: 8
Training loss: 1.938574194908142
Validation loss: 1.9850422342618306

Epoch: 5| Step: 9
Training loss: 1.7403532266616821
Validation loss: 1.9867494354645412

Epoch: 5| Step: 10
Training loss: 3.09212327003479
Validation loss: 1.9873071908950806

Epoch: 5| Step: 11
Training loss: 2.621340274810791
Validation loss: 1.9884913265705109

Epoch: 112| Step: 0
Training loss: 2.0256524085998535
Validation loss: 1.9875756452480953

Epoch: 5| Step: 1
Training loss: 1.8230397701263428
Validation loss: 1.9892861644426982

Epoch: 5| Step: 2
Training loss: 2.353708505630493
Validation loss: 1.9903777986764908

Epoch: 5| Step: 3
Training loss: 2.044919490814209
Validation loss: 1.9878668536742528

Epoch: 5| Step: 4
Training loss: 2.203369379043579
Validation loss: 1.9908962945143382

Epoch: 5| Step: 5
Training loss: 2.095973491668701
Validation loss: 1.9897663692633312

Epoch: 5| Step: 6
Training loss: 1.7443382740020752
Validation loss: 1.994070326288541

Epoch: 5| Step: 7
Training loss: 2.183976888656616
Validation loss: 1.9935684750477474

Epoch: 5| Step: 8
Training loss: 1.971106767654419
Validation loss: 1.9914920181035995

Epoch: 5| Step: 9
Training loss: 2.9107937812805176
Validation loss: 1.9948309461275737

Epoch: 5| Step: 10
Training loss: 2.0935747623443604
Validation loss: 1.9993154803911846

Epoch: 5| Step: 11
Training loss: 2.5383267402648926
Validation loss: 2.0093408773342767

Epoch: 113| Step: 0
Training loss: 2.8829128742218018
Validation loss: 2.006329004963239

Epoch: 5| Step: 1
Training loss: 2.1037614345550537
Validation loss: 2.001171221335729

Epoch: 5| Step: 2
Training loss: 2.189094066619873
Validation loss: 2.005271151661873

Epoch: 5| Step: 3
Training loss: 2.0189015865325928
Validation loss: 1.997465545932452

Epoch: 5| Step: 4
Training loss: 2.182929515838623
Validation loss: 2.0121332158644996

Epoch: 5| Step: 5
Training loss: 2.132479190826416
Validation loss: 2.024896596868833

Epoch: 5| Step: 6
Training loss: 2.039560317993164
Validation loss: 2.0261614471673965

Epoch: 5| Step: 7
Training loss: 1.9867950677871704
Validation loss: 2.0245839953422546

Epoch: 5| Step: 8
Training loss: 1.9162323474884033
Validation loss: 2.027467980980873

Epoch: 5| Step: 9
Training loss: 1.875851035118103
Validation loss: 2.0306608031193414

Epoch: 5| Step: 10
Training loss: 1.9986463785171509
Validation loss: 2.0290184815724692

Epoch: 5| Step: 11
Training loss: 2.576401472091675
Validation loss: 2.0300507843494415

Epoch: 114| Step: 0
Training loss: 1.8825159072875977
Validation loss: 2.0317539225021997

Epoch: 5| Step: 1
Training loss: 1.5211271047592163
Validation loss: 2.034520169099172

Epoch: 5| Step: 2
Training loss: 1.3092811107635498
Validation loss: 2.029315873980522

Epoch: 5| Step: 3
Training loss: 2.4157421588897705
Validation loss: 2.0382166455189386

Epoch: 5| Step: 4
Training loss: 1.983581304550171
Validation loss: 2.0433933387200036

Epoch: 5| Step: 5
Training loss: 2.1596617698669434
Validation loss: 2.0330751488606134

Epoch: 5| Step: 6
Training loss: 2.311504364013672
Validation loss: 2.0335032244523368

Epoch: 5| Step: 7
Training loss: 2.5555686950683594
Validation loss: 2.022196263074875

Epoch: 5| Step: 8
Training loss: 2.338911294937134
Validation loss: 2.018839791417122

Epoch: 5| Step: 9
Training loss: 2.2997546195983887
Validation loss: 2.0200835218032203

Epoch: 5| Step: 10
Training loss: 2.5125415325164795
Validation loss: 2.0175660053888955

Epoch: 5| Step: 11
Training loss: 1.7197917699813843
Validation loss: 2.0146254201730094

Epoch: 115| Step: 0
Training loss: 2.374018669128418
Validation loss: 2.0150518218676248

Epoch: 5| Step: 1
Training loss: 2.150887966156006
Validation loss: 2.0162501682837806

Epoch: 5| Step: 2
Training loss: 1.8438827991485596
Validation loss: 2.015646586815516

Epoch: 5| Step: 3
Training loss: 1.9972236156463623
Validation loss: 2.0231978247563043

Epoch: 5| Step: 4
Training loss: 1.8582464456558228
Validation loss: 2.0281477322181067

Epoch: 5| Step: 5
Training loss: 2.649282932281494
Validation loss: 2.028726264834404

Epoch: 5| Step: 6
Training loss: 1.7943294048309326
Validation loss: 2.035987118879954

Epoch: 5| Step: 7
Training loss: 2.0604515075683594
Validation loss: 2.0289837568998337

Epoch: 5| Step: 8
Training loss: 1.9428417682647705
Validation loss: 2.028097232182821

Epoch: 5| Step: 9
Training loss: 2.6613636016845703
Validation loss: 2.025764361023903

Epoch: 5| Step: 10
Training loss: 2.571894884109497
Validation loss: 2.017393017808596

Epoch: 5| Step: 11
Training loss: 2.265908718109131
Validation loss: 2.0250174601872764

Epoch: 116| Step: 0
Training loss: 1.5267337560653687
Validation loss: 2.0232950995365777

Epoch: 5| Step: 1
Training loss: 1.7745678424835205
Validation loss: 2.0184905330340066

Epoch: 5| Step: 2
Training loss: 2.428184747695923
Validation loss: 2.0041366517543793

Epoch: 5| Step: 3
Training loss: 2.2085928916931152
Validation loss: 1.998734454313914

Epoch: 5| Step: 4
Training loss: 2.5509605407714844
Validation loss: 1.9980995456377666

Epoch: 5| Step: 5
Training loss: 2.228193998336792
Validation loss: 1.9984292189280193

Epoch: 5| Step: 6
Training loss: 2.320618152618408
Validation loss: 2.0060352087020874

Epoch: 5| Step: 7
Training loss: 2.13501238822937
Validation loss: 1.9980301608641942

Epoch: 5| Step: 8
Training loss: 2.3506522178649902
Validation loss: 2.0139660239219666

Epoch: 5| Step: 9
Training loss: 2.635211944580078
Validation loss: 2.027620350321134

Epoch: 5| Step: 10
Training loss: 1.6574475765228271
Validation loss: 2.034653996427854

Epoch: 5| Step: 11
Training loss: 1.2618587017059326
Validation loss: 2.0418513417243958

Epoch: 117| Step: 0
Training loss: 2.5235776901245117
Validation loss: 2.0461353063583374

Epoch: 5| Step: 1
Training loss: 2.3406319618225098
Validation loss: 2.056038409471512

Epoch: 5| Step: 2
Training loss: 2.117767810821533
Validation loss: 2.055584634343783

Epoch: 5| Step: 3
Training loss: 2.4301717281341553
Validation loss: 2.0586180637280145

Epoch: 5| Step: 4
Training loss: 1.8886401653289795
Validation loss: 2.0408153732617698

Epoch: 5| Step: 5
Training loss: 1.8126652240753174
Validation loss: 2.033282458782196

Epoch: 5| Step: 6
Training loss: 2.039135456085205
Validation loss: 2.0448953409989676

Epoch: 5| Step: 7
Training loss: 2.388936996459961
Validation loss: 2.030122677485148

Epoch: 5| Step: 8
Training loss: 1.9432487487792969
Validation loss: 2.009492521484693

Epoch: 5| Step: 9
Training loss: 1.9463527202606201
Validation loss: 2.0125222702821097

Epoch: 5| Step: 10
Training loss: 2.3295938968658447
Validation loss: 2.0127200931310654

Epoch: 5| Step: 11
Training loss: 2.5101404190063477
Validation loss: 2.020254229505857

Epoch: 118| Step: 0
Training loss: 1.9865974187850952
Validation loss: 2.0177264163891473

Epoch: 5| Step: 1
Training loss: 1.630689024925232
Validation loss: 2.0112934609254203

Epoch: 5| Step: 2
Training loss: 2.002255439758301
Validation loss: 2.0115043073892593

Epoch: 5| Step: 3
Training loss: 2.32810640335083
Validation loss: 2.0078131655852

Epoch: 5| Step: 4
Training loss: 2.567124128341675
Validation loss: 2.0046178698539734

Epoch: 5| Step: 5
Training loss: 2.404949188232422
Validation loss: 2.0065954575936

Epoch: 5| Step: 6
Training loss: 1.9088239669799805
Validation loss: 2.0108602046966553

Epoch: 5| Step: 7
Training loss: 2.344470262527466
Validation loss: 2.005871072411537

Epoch: 5| Step: 8
Training loss: 1.698638916015625
Validation loss: 2.007729430993398

Epoch: 5| Step: 9
Training loss: 2.247016429901123
Validation loss: 2.0280026892820993

Epoch: 5| Step: 10
Training loss: 2.4300522804260254
Validation loss: 2.021248534321785

Epoch: 5| Step: 11
Training loss: 1.9391605854034424
Validation loss: 2.0301284343004227

Epoch: 119| Step: 0
Training loss: 1.706404447555542
Validation loss: 2.0220757871866226

Epoch: 5| Step: 1
Training loss: 1.913883924484253
Validation loss: 2.0321669479211173

Epoch: 5| Step: 2
Training loss: 1.9412654638290405
Validation loss: 2.031880641976992

Epoch: 5| Step: 3
Training loss: 2.57342791557312
Validation loss: 2.0345249424378076

Epoch: 5| Step: 4
Training loss: 2.363459825515747
Validation loss: 2.0334578305482864

Epoch: 5| Step: 5
Training loss: 2.1739554405212402
Validation loss: 2.039895638823509

Epoch: 5| Step: 6
Training loss: 2.780757427215576
Validation loss: 2.0357946256796517

Epoch: 5| Step: 7
Training loss: 1.4935414791107178
Validation loss: 2.033921147386233

Epoch: 5| Step: 8
Training loss: 2.1596672534942627
Validation loss: 2.0349833915630975

Epoch: 5| Step: 9
Training loss: 1.951857328414917
Validation loss: 2.040190577507019

Epoch: 5| Step: 10
Training loss: 1.9629465341567993
Validation loss: 2.039087717731794

Epoch: 5| Step: 11
Training loss: 3.3467273712158203
Validation loss: 2.040962884823481

Epoch: 120| Step: 0
Training loss: 1.8929319381713867
Validation loss: 2.043389692902565

Epoch: 5| Step: 1
Training loss: 2.218310594558716
Validation loss: 2.0453044275442758

Epoch: 5| Step: 2
Training loss: 2.113832473754883
Validation loss: 2.0433125346899033

Epoch: 5| Step: 3
Training loss: 1.9309148788452148
Validation loss: 2.0357831617196402

Epoch: 5| Step: 4
Training loss: 2.00303316116333
Validation loss: 2.0375870217879615

Epoch: 5| Step: 5
Training loss: 2.3510682582855225
Validation loss: 2.0423786838849387

Epoch: 5| Step: 6
Training loss: 1.950119972229004
Validation loss: 2.036851689219475

Epoch: 5| Step: 7
Training loss: 1.311826467514038
Validation loss: 2.040151536464691

Epoch: 5| Step: 8
Training loss: 2.104222536087036
Validation loss: 2.02483923236529

Epoch: 5| Step: 9
Training loss: 2.2467942237854004
Validation loss: 2.031851813197136

Epoch: 5| Step: 10
Training loss: 2.867374897003174
Validation loss: 2.019451826810837

Epoch: 5| Step: 11
Training loss: 2.9330852031707764
Validation loss: 2.021152451634407

Epoch: 121| Step: 0
Training loss: 2.610299587249756
Validation loss: 2.018287936846415

Epoch: 5| Step: 1
Training loss: 1.9436136484146118
Validation loss: 2.031591922044754

Epoch: 5| Step: 2
Training loss: 1.7005774974822998
Validation loss: 2.0240818858146667

Epoch: 5| Step: 3
Training loss: 2.7618460655212402
Validation loss: 2.027845710515976

Epoch: 5| Step: 4
Training loss: 2.3851888179779053
Validation loss: 2.0195707927147546

Epoch: 5| Step: 5
Training loss: 2.4905292987823486
Validation loss: 2.031439244747162

Epoch: 5| Step: 6
Training loss: 1.7438567876815796
Validation loss: 2.028588980436325

Epoch: 5| Step: 7
Training loss: 2.090122938156128
Validation loss: 2.035768061876297

Epoch: 5| Step: 8
Training loss: 1.6271377801895142
Validation loss: 2.0285617212454476

Epoch: 5| Step: 9
Training loss: 2.197065591812134
Validation loss: 2.0242796689271927

Epoch: 5| Step: 10
Training loss: 1.7400884628295898
Validation loss: 2.0262699176867804

Epoch: 5| Step: 11
Training loss: 1.8542141914367676
Validation loss: 2.0216947346925735

Epoch: 122| Step: 0
Training loss: 2.4258780479431152
Validation loss: 2.024342934290568

Epoch: 5| Step: 1
Training loss: 2.055041551589966
Validation loss: 2.0285991579294205

Epoch: 5| Step: 2
Training loss: 2.272186517715454
Validation loss: 2.03174156943957

Epoch: 5| Step: 3
Training loss: 2.1727280616760254
Validation loss: 2.023329511284828

Epoch: 5| Step: 4
Training loss: 2.313281774520874
Validation loss: 2.0239314138889313

Epoch: 5| Step: 5
Training loss: 1.938219428062439
Validation loss: 2.029822995265325

Epoch: 5| Step: 6
Training loss: 2.333826780319214
Validation loss: 2.030866965651512

Epoch: 5| Step: 7
Training loss: 2.309144973754883
Validation loss: 2.0226604541142783

Epoch: 5| Step: 8
Training loss: 2.073439359664917
Validation loss: 2.027999351421992

Epoch: 5| Step: 9
Training loss: 1.6193891763687134
Validation loss: 2.023820996284485

Epoch: 5| Step: 10
Training loss: 1.7727428674697876
Validation loss: 2.0315292129913964

Epoch: 5| Step: 11
Training loss: 2.415241241455078
Validation loss: 2.02236707508564

Epoch: 123| Step: 0
Training loss: 2.658419370651245
Validation loss: 2.0294995307922363

Epoch: 5| Step: 1
Training loss: 2.019988536834717
Validation loss: 2.01195494333903

Epoch: 5| Step: 2
Training loss: 1.7140018939971924
Validation loss: 2.00500151515007

Epoch: 5| Step: 3
Training loss: 1.9744656085968018
Validation loss: 2.0078743994235992

Epoch: 5| Step: 4
Training loss: 2.2230560779571533
Validation loss: 2.00829087694486

Epoch: 5| Step: 5
Training loss: 2.2950546741485596
Validation loss: 2.0023263692855835

Epoch: 5| Step: 6
Training loss: 2.4841952323913574
Validation loss: 2.00094606479009

Epoch: 5| Step: 7
Training loss: 2.235407590866089
Validation loss: 2.0061449458201728

Epoch: 5| Step: 8
Training loss: 2.105154037475586
Validation loss: 1.9993797292311986

Epoch: 5| Step: 9
Training loss: 2.287264347076416
Validation loss: 1.9981991449991863

Epoch: 5| Step: 10
Training loss: 1.7323137521743774
Validation loss: 1.98992820084095

Epoch: 5| Step: 11
Training loss: 0.8346642851829529
Validation loss: 1.9951070646444957

Epoch: 124| Step: 0
Training loss: 1.7156906127929688
Validation loss: 1.9905287871758144

Epoch: 5| Step: 1
Training loss: 2.0836586952209473
Validation loss: 2.0067548553148904

Epoch: 5| Step: 2
Training loss: 2.030449628829956
Validation loss: 2.0055257926384606

Epoch: 5| Step: 3
Training loss: 2.2574939727783203
Validation loss: 2.000884393850962

Epoch: 5| Step: 4
Training loss: 2.4229578971862793
Validation loss: 2.020975405971209

Epoch: 5| Step: 5
Training loss: 2.0369181632995605
Validation loss: 2.016912341117859

Epoch: 5| Step: 6
Training loss: 2.3272480964660645
Validation loss: 2.028678054610888

Epoch: 5| Step: 7
Training loss: 1.7504431009292603
Validation loss: 2.027130444844564

Epoch: 5| Step: 8
Training loss: 2.1598145961761475
Validation loss: 2.029329707225164

Epoch: 5| Step: 9
Training loss: 2.5582938194274902
Validation loss: 2.033765137195587

Epoch: 5| Step: 10
Training loss: 2.2976787090301514
Validation loss: 2.0312429467837014

Epoch: 5| Step: 11
Training loss: 0.5230089426040649
Validation loss: 2.013362059990565

Epoch: 125| Step: 0
Training loss: 2.1551029682159424
Validation loss: 2.0169768184423447

Epoch: 5| Step: 1
Training loss: 1.591536283493042
Validation loss: 2.0033233811457953

Epoch: 5| Step: 2
Training loss: 1.9984134435653687
Validation loss: 2.0013673653205237

Epoch: 5| Step: 3
Training loss: 2.459564685821533
Validation loss: 1.9978066285451253

Epoch: 5| Step: 4
Training loss: 2.2243340015411377
Validation loss: 1.9994141459465027

Epoch: 5| Step: 5
Training loss: 2.132011890411377
Validation loss: 2.009528800845146

Epoch: 5| Step: 6
Training loss: 1.657525658607483
Validation loss: 2.0002747774124146

Epoch: 5| Step: 7
Training loss: 2.482778549194336
Validation loss: 1.999226709206899

Epoch: 5| Step: 8
Training loss: 1.8668301105499268
Validation loss: 2.0066596070925393

Epoch: 5| Step: 9
Training loss: 2.412564992904663
Validation loss: 2.007114772995313

Epoch: 5| Step: 10
Training loss: 2.2342076301574707
Validation loss: 2.0053354700406394

Epoch: 5| Step: 11
Training loss: 2.2413105964660645
Validation loss: 2.012946049372355

Testing loss: 1.6980108777396112
