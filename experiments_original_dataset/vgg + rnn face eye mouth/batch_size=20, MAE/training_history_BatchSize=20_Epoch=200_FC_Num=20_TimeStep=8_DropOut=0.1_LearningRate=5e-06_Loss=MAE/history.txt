Epoch: 1| Step: 0
Training loss: 5.678170204162598
Validation loss: 5.344740907351176

Epoch: 5| Step: 1
Training loss: 4.690926551818848
Validation loss: 5.342775185902913

Epoch: 5| Step: 2
Training loss: 5.899622917175293
Validation loss: 5.340764164924622

Epoch: 5| Step: 3
Training loss: 5.886804103851318
Validation loss: 5.3387090762456255

Epoch: 5| Step: 4
Training loss: 5.275854587554932
Validation loss: 5.3366754452387495

Epoch: 5| Step: 5
Training loss: 6.218068599700928
Validation loss: 5.334632853666942

Epoch: 5| Step: 6
Training loss: 5.361424446105957
Validation loss: 5.332494715849559

Epoch: 5| Step: 7
Training loss: 4.525479316711426
Validation loss: 5.33040048678716

Epoch: 5| Step: 8
Training loss: 5.795724391937256
Validation loss: 5.3281850417455034

Epoch: 5| Step: 9
Training loss: 4.521186828613281
Validation loss: 5.325880487759908

Epoch: 5| Step: 10
Training loss: 6.197124481201172
Validation loss: 5.323582549889882

Epoch: 5| Step: 11
Training loss: 2.334537982940674
Validation loss: 5.321134805679321

Epoch: 2| Step: 0
Training loss: 6.366159439086914
Validation loss: 5.318606277306874

Epoch: 5| Step: 1
Training loss: 4.434821128845215
Validation loss: 5.3159496784210205

Epoch: 5| Step: 2
Training loss: 5.365113735198975
Validation loss: 5.313310861587524

Epoch: 5| Step: 3
Training loss: 4.967907428741455
Validation loss: 5.310486535231273

Epoch: 5| Step: 4
Training loss: 5.199470043182373
Validation loss: 5.307668368021647

Epoch: 5| Step: 5
Training loss: 5.292245388031006
Validation loss: 5.304616908232371

Epoch: 5| Step: 6
Training loss: 5.707331657409668
Validation loss: 5.301353911558787

Epoch: 5| Step: 7
Training loss: 7.027658939361572
Validation loss: 5.297989726066589

Epoch: 5| Step: 8
Training loss: 5.265614032745361
Validation loss: 5.294653654098511

Epoch: 5| Step: 9
Training loss: 5.850337028503418
Validation loss: 5.290782491366069

Epoch: 5| Step: 10
Training loss: 4.12259578704834
Validation loss: 5.287135203679402

Epoch: 5| Step: 11
Training loss: 2.891413927078247
Validation loss: 5.282989422480266

Epoch: 3| Step: 0
Training loss: 5.6778883934021
Validation loss: 5.27886031071345

Epoch: 5| Step: 1
Training loss: 5.257907390594482
Validation loss: 5.274519582589467

Epoch: 5| Step: 2
Training loss: 5.671931266784668
Validation loss: 5.26981904109319

Epoch: 5| Step: 3
Training loss: 4.213019847869873
Validation loss: 5.265068928400676

Epoch: 5| Step: 4
Training loss: 4.8075971603393555
Validation loss: 5.259897291660309

Epoch: 5| Step: 5
Training loss: 6.1358642578125
Validation loss: 5.254576126734416

Epoch: 5| Step: 6
Training loss: 4.924015998840332
Validation loss: 5.249038020769755

Epoch: 5| Step: 7
Training loss: 5.736342430114746
Validation loss: 5.243395686149597

Epoch: 5| Step: 8
Training loss: 5.6086297035217285
Validation loss: 5.237210631370544

Epoch: 5| Step: 9
Training loss: 5.564997673034668
Validation loss: 5.230848391850789

Epoch: 5| Step: 10
Training loss: 4.708698272705078
Validation loss: 5.224351624647777

Epoch: 5| Step: 11
Training loss: 6.533867359161377
Validation loss: 5.2172490159670515

Epoch: 4| Step: 0
Training loss: 5.234526634216309
Validation loss: 5.210315108299255

Epoch: 5| Step: 1
Training loss: 6.302598476409912
Validation loss: 5.202475130558014

Epoch: 5| Step: 2
Training loss: 4.184151649475098
Validation loss: 5.19503120581309

Epoch: 5| Step: 3
Training loss: 6.168670654296875
Validation loss: 5.186724861462911

Epoch: 5| Step: 4
Training loss: 6.015312194824219
Validation loss: 5.178834577401479

Epoch: 5| Step: 5
Training loss: 4.683901309967041
Validation loss: 5.170121252536774

Epoch: 5| Step: 6
Training loss: 5.77441930770874
Validation loss: 5.161710460980733

Epoch: 5| Step: 7
Training loss: 5.201212406158447
Validation loss: 5.153046131134033

Epoch: 5| Step: 8
Training loss: 4.698753833770752
Validation loss: 5.143539210160573

Epoch: 5| Step: 9
Training loss: 4.443056106567383
Validation loss: 5.134662250677745

Epoch: 5| Step: 10
Training loss: 5.062914848327637
Validation loss: 5.125251154104869

Epoch: 5| Step: 11
Training loss: 4.665515899658203
Validation loss: 5.115699768066406

Epoch: 5| Step: 0
Training loss: 5.500583648681641
Validation loss: 5.106197635332744

Epoch: 5| Step: 1
Training loss: 5.038656234741211
Validation loss: 5.096369345982869

Epoch: 5| Step: 2
Training loss: 5.753589630126953
Validation loss: 5.086510896682739

Epoch: 5| Step: 3
Training loss: 4.750208377838135
Validation loss: 5.076710104942322

Epoch: 5| Step: 4
Training loss: 5.335105895996094
Validation loss: 5.066601037979126

Epoch: 5| Step: 5
Training loss: 5.2699151039123535
Validation loss: 5.0562235315640764

Epoch: 5| Step: 6
Training loss: 4.535633087158203
Validation loss: 5.046156823635101

Epoch: 5| Step: 7
Training loss: 6.229265213012695
Validation loss: 5.035577158133189

Epoch: 5| Step: 8
Training loss: 5.62315034866333
Validation loss: 5.025242030620575

Epoch: 5| Step: 9
Training loss: 4.021117687225342
Validation loss: 5.014513452847798

Epoch: 5| Step: 10
Training loss: 4.519747734069824
Validation loss: 5.003875970840454

Epoch: 5| Step: 11
Training loss: 4.588901519775391
Validation loss: 4.993295907974243

Epoch: 6| Step: 0
Training loss: 5.022187232971191
Validation loss: 4.982239882151286

Epoch: 5| Step: 1
Training loss: 5.123061180114746
Validation loss: 4.971039513746898

Epoch: 5| Step: 2
Training loss: 5.429952621459961
Validation loss: 4.95968763033549

Epoch: 5| Step: 3
Training loss: 6.850008487701416
Validation loss: 4.948514084021251

Epoch: 5| Step: 4
Training loss: 3.9022116661071777
Validation loss: 4.937587837378184

Epoch: 5| Step: 5
Training loss: 5.1927618980407715
Validation loss: 4.927257855733235

Epoch: 5| Step: 6
Training loss: 5.0104498863220215
Validation loss: 4.916778564453125

Epoch: 5| Step: 7
Training loss: 4.018847942352295
Validation loss: 4.906745096047719

Epoch: 5| Step: 8
Training loss: 4.658087730407715
Validation loss: 4.896977365016937

Epoch: 5| Step: 9
Training loss: 5.043467998504639
Validation loss: 4.887270490328471

Epoch: 5| Step: 10
Training loss: 4.769176959991455
Validation loss: 4.877595961093903

Epoch: 5| Step: 11
Training loss: 5.639010429382324
Validation loss: 4.868351578712463

Epoch: 7| Step: 0
Training loss: 5.5329389572143555
Validation loss: 4.8590037027994795

Epoch: 5| Step: 1
Training loss: 5.194417476654053
Validation loss: 4.84964241584142

Epoch: 5| Step: 2
Training loss: 4.131333351135254
Validation loss: 4.840158462524414

Epoch: 5| Step: 3
Training loss: 4.498749732971191
Validation loss: 4.8320087393124895

Epoch: 5| Step: 4
Training loss: 5.574066162109375
Validation loss: 4.8227265278498335

Epoch: 5| Step: 5
Training loss: 5.535614013671875
Validation loss: 4.813741634289424

Epoch: 5| Step: 6
Training loss: 4.655037879943848
Validation loss: 4.805375238259633

Epoch: 5| Step: 7
Training loss: 3.836484432220459
Validation loss: 4.797180573145549

Epoch: 5| Step: 8
Training loss: 5.109307289123535
Validation loss: 4.788853287696838

Epoch: 5| Step: 9
Training loss: 4.761125087738037
Validation loss: 4.780703107515971

Epoch: 5| Step: 10
Training loss: 5.128926753997803
Validation loss: 4.772221545378367

Epoch: 5| Step: 11
Training loss: 4.771449089050293
Validation loss: 4.763810157775879

Epoch: 8| Step: 0
Training loss: 5.3537797927856445
Validation loss: 4.756329377492269

Epoch: 5| Step: 1
Training loss: 5.626290798187256
Validation loss: 4.747976620992024

Epoch: 5| Step: 2
Training loss: 4.788575649261475
Validation loss: 4.739586551984151

Epoch: 5| Step: 3
Training loss: 3.6424641609191895
Validation loss: 4.732077658176422

Epoch: 5| Step: 4
Training loss: 5.9456257820129395
Validation loss: 4.724535425504048

Epoch: 5| Step: 5
Training loss: 4.806027889251709
Validation loss: 4.716513911883037

Epoch: 5| Step: 6
Training loss: 4.701027870178223
Validation loss: 4.709096242984136

Epoch: 5| Step: 7
Training loss: 5.2410783767700195
Validation loss: 4.701547771692276

Epoch: 5| Step: 8
Training loss: 4.759652137756348
Validation loss: 4.694260756174724

Epoch: 5| Step: 9
Training loss: 4.202898025512695
Validation loss: 4.6863817771275835

Epoch: 5| Step: 10
Training loss: 4.2458295822143555
Validation loss: 4.679105669260025

Epoch: 5| Step: 11
Training loss: 2.810703754425049
Validation loss: 4.67230087518692

Epoch: 9| Step: 0
Training loss: 4.216143608093262
Validation loss: 4.665391246477763

Epoch: 5| Step: 1
Training loss: 5.367098808288574
Validation loss: 4.658564209938049

Epoch: 5| Step: 2
Training loss: 4.545079708099365
Validation loss: 4.6518440047899885

Epoch: 5| Step: 3
Training loss: 4.556832313537598
Validation loss: 4.644342551628749

Epoch: 5| Step: 4
Training loss: 5.445715427398682
Validation loss: 4.63755049308141

Epoch: 5| Step: 5
Training loss: 4.672084808349609
Validation loss: 4.630981753269832

Epoch: 5| Step: 6
Training loss: 3.9104816913604736
Validation loss: 4.624222536881764

Epoch: 5| Step: 7
Training loss: 4.216806888580322
Validation loss: 4.61788875857989

Epoch: 5| Step: 8
Training loss: 4.218070030212402
Validation loss: 4.611396054426829

Epoch: 5| Step: 9
Training loss: 5.246255397796631
Validation loss: 4.605253835519155

Epoch: 5| Step: 10
Training loss: 5.530554294586182
Validation loss: 4.598822941382726

Epoch: 5| Step: 11
Training loss: 5.205399513244629
Validation loss: 4.5919122993946075

Epoch: 10| Step: 0
Training loss: 5.250574588775635
Validation loss: 4.586245675881703

Epoch: 5| Step: 1
Training loss: 5.019556522369385
Validation loss: 4.579395512739818

Epoch: 5| Step: 2
Training loss: 4.415353298187256
Validation loss: 4.573701600233714

Epoch: 5| Step: 3
Training loss: 4.089866638183594
Validation loss: 4.567305942376454

Epoch: 5| Step: 4
Training loss: 4.624878883361816
Validation loss: 4.561124801635742

Epoch: 5| Step: 5
Training loss: 4.760505199432373
Validation loss: 4.554362326860428

Epoch: 5| Step: 6
Training loss: 5.0521392822265625
Validation loss: 4.548112789789836

Epoch: 5| Step: 7
Training loss: 4.051600456237793
Validation loss: 4.542860716581345

Epoch: 5| Step: 8
Training loss: 5.01871919631958
Validation loss: 4.536444336175919

Epoch: 5| Step: 9
Training loss: 4.338019847869873
Validation loss: 4.530148684978485

Epoch: 5| Step: 10
Training loss: 4.649714946746826
Validation loss: 4.524053792158763

Epoch: 5| Step: 11
Training loss: 4.469051837921143
Validation loss: 4.517276664574941

Epoch: 11| Step: 0
Training loss: 4.374754905700684
Validation loss: 4.51166112224261

Epoch: 5| Step: 1
Training loss: 4.230923175811768
Validation loss: 4.505686233441035

Epoch: 5| Step: 2
Training loss: 4.091377258300781
Validation loss: 4.499465545018514

Epoch: 5| Step: 3
Training loss: 4.663300514221191
Validation loss: 4.493840456008911

Epoch: 5| Step: 4
Training loss: 4.547431945800781
Validation loss: 4.487634678681691

Epoch: 5| Step: 5
Training loss: 4.606939315795898
Validation loss: 4.4807954629262285

Epoch: 5| Step: 6
Training loss: 5.324833869934082
Validation loss: 4.47476593653361

Epoch: 5| Step: 7
Training loss: 4.6637163162231445
Validation loss: 4.467893838882446

Epoch: 5| Step: 8
Training loss: 4.17362117767334
Validation loss: 4.461788276831309

Epoch: 5| Step: 9
Training loss: 5.161250114440918
Validation loss: 4.455318808555603

Epoch: 5| Step: 10
Training loss: 4.803527355194092
Validation loss: 4.448804636796315

Epoch: 5| Step: 11
Training loss: 3.85554838180542
Validation loss: 4.441883146762848

Epoch: 12| Step: 0
Training loss: 5.2944865226745605
Validation loss: 4.43601135412852

Epoch: 5| Step: 1
Training loss: 3.615729808807373
Validation loss: 4.429813593626022

Epoch: 5| Step: 2
Training loss: 4.485237121582031
Validation loss: 4.423563897609711

Epoch: 5| Step: 3
Training loss: 5.408175468444824
Validation loss: 4.417960226535797

Epoch: 5| Step: 4
Training loss: 4.033513069152832
Validation loss: 4.411613742510478

Epoch: 5| Step: 5
Training loss: 4.231566429138184
Validation loss: 4.404971182346344

Epoch: 5| Step: 6
Training loss: 4.812840938568115
Validation loss: 4.399476061264674

Epoch: 5| Step: 7
Training loss: 4.495405197143555
Validation loss: 4.393133848905563

Epoch: 5| Step: 8
Training loss: 4.951623439788818
Validation loss: 4.386818528175354

Epoch: 5| Step: 9
Training loss: 4.231583595275879
Validation loss: 4.380742162466049

Epoch: 5| Step: 10
Training loss: 4.085397720336914
Validation loss: 4.375061313311259

Epoch: 5| Step: 11
Training loss: 5.012353897094727
Validation loss: 4.368856867154439

Epoch: 13| Step: 0
Training loss: 4.208072662353516
Validation loss: 4.363176504770915

Epoch: 5| Step: 1
Training loss: 5.057768821716309
Validation loss: 4.356684923171997

Epoch: 5| Step: 2
Training loss: 3.811063766479492
Validation loss: 4.35060069958369

Epoch: 5| Step: 3
Training loss: 5.168358325958252
Validation loss: 4.3444093863169355

Epoch: 5| Step: 4
Training loss: 3.960353136062622
Validation loss: 4.338524580001831

Epoch: 5| Step: 5
Training loss: 5.33422327041626
Validation loss: 4.332923382520676

Epoch: 5| Step: 6
Training loss: 4.94137716293335
Validation loss: 4.326542695363362

Epoch: 5| Step: 7
Training loss: 3.3778977394104004
Validation loss: 4.320385376612346

Epoch: 5| Step: 8
Training loss: 4.016251087188721
Validation loss: 4.314685235420863

Epoch: 5| Step: 9
Training loss: 4.31813907623291
Validation loss: 4.309131433566411

Epoch: 5| Step: 10
Training loss: 4.406469821929932
Validation loss: 4.303533871968587

Epoch: 5| Step: 11
Training loss: 6.547603130340576
Validation loss: 4.29738649725914

Epoch: 14| Step: 0
Training loss: 4.685263156890869
Validation loss: 4.291316290696462

Epoch: 5| Step: 1
Training loss: 4.67294454574585
Validation loss: 4.285607248544693

Epoch: 5| Step: 2
Training loss: 3.6568806171417236
Validation loss: 4.279888639847438

Epoch: 5| Step: 3
Training loss: 4.214795112609863
Validation loss: 4.2741706271966295

Epoch: 5| Step: 4
Training loss: 4.582742691040039
Validation loss: 4.268657137950261

Epoch: 5| Step: 5
Training loss: 4.903676509857178
Validation loss: 4.263123611609141

Epoch: 5| Step: 6
Training loss: 4.360912322998047
Validation loss: 4.257286449273427

Epoch: 5| Step: 7
Training loss: 3.735626697540283
Validation loss: 4.251375416914622

Epoch: 5| Step: 8
Training loss: 4.168694496154785
Validation loss: 4.245343158642451

Epoch: 5| Step: 9
Training loss: 5.224966049194336
Validation loss: 4.2397842307885485

Epoch: 5| Step: 10
Training loss: 4.1952080726623535
Validation loss: 4.23392974336942

Epoch: 5| Step: 11
Training loss: 3.830902099609375
Validation loss: 4.227998703718185

Epoch: 15| Step: 0
Training loss: 4.238821983337402
Validation loss: 4.223273356755574

Epoch: 5| Step: 1
Training loss: 4.603113651275635
Validation loss: 4.217126846313477

Epoch: 5| Step: 2
Training loss: 3.9347496032714844
Validation loss: 4.211505512396495

Epoch: 5| Step: 3
Training loss: 4.774988651275635
Validation loss: 4.205418169498444

Epoch: 5| Step: 4
Training loss: 4.388148307800293
Validation loss: 4.2006519337495165

Epoch: 5| Step: 5
Training loss: 3.8287296295166016
Validation loss: 4.195176005363464

Epoch: 5| Step: 6
Training loss: 3.539147138595581
Validation loss: 4.189132312933604

Epoch: 5| Step: 7
Training loss: 4.449930667877197
Validation loss: 4.183805118004481

Epoch: 5| Step: 8
Training loss: 4.744149208068848
Validation loss: 4.179051488637924

Epoch: 5| Step: 9
Training loss: 4.985426902770996
Validation loss: 4.172634065151215

Epoch: 5| Step: 10
Training loss: 3.8910911083221436
Validation loss: 4.166545311609904

Epoch: 5| Step: 11
Training loss: 5.465001583099365
Validation loss: 4.160827159881592

Epoch: 16| Step: 0
Training loss: 4.785195350646973
Validation loss: 4.1558211743831635

Epoch: 5| Step: 1
Training loss: 3.556478977203369
Validation loss: 4.14970999956131

Epoch: 5| Step: 2
Training loss: 4.548077583312988
Validation loss: 4.144034177064896

Epoch: 5| Step: 3
Training loss: 3.658707857131958
Validation loss: 4.138391117254893

Epoch: 5| Step: 4
Training loss: 4.227327823638916
Validation loss: 4.132306317488353

Epoch: 5| Step: 5
Training loss: 3.611537218093872
Validation loss: 4.126745382944743

Epoch: 5| Step: 6
Training loss: 4.537238121032715
Validation loss: 4.120941907167435

Epoch: 5| Step: 7
Training loss: 4.645895957946777
Validation loss: 4.115830024083455

Epoch: 5| Step: 8
Training loss: 4.075304985046387
Validation loss: 4.110816687345505

Epoch: 5| Step: 9
Training loss: 4.8821868896484375
Validation loss: 4.104670335849126

Epoch: 5| Step: 10
Training loss: 4.121758937835693
Validation loss: 4.099421451489131

Epoch: 5| Step: 11
Training loss: 5.608381748199463
Validation loss: 4.093831559022267

Epoch: 17| Step: 0
Training loss: 4.231940269470215
Validation loss: 4.087389866511027

Epoch: 5| Step: 1
Training loss: 4.6489481925964355
Validation loss: 4.0814886291821795

Epoch: 5| Step: 2
Training loss: 4.8982367515563965
Validation loss: 4.076185713211696

Epoch: 5| Step: 3
Training loss: 3.4302005767822266
Validation loss: 4.070268680651982

Epoch: 5| Step: 4
Training loss: 4.68665075302124
Validation loss: 4.064775546391805

Epoch: 5| Step: 5
Training loss: 3.3929543495178223
Validation loss: 4.059970696767171

Epoch: 5| Step: 6
Training loss: 4.749825954437256
Validation loss: 4.054979860782623

Epoch: 5| Step: 7
Training loss: 3.750640869140625
Validation loss: 4.049665053685506

Epoch: 5| Step: 8
Training loss: 4.524595737457275
Validation loss: 4.044844955205917

Epoch: 5| Step: 9
Training loss: 3.7265079021453857
Validation loss: 4.039801200230916

Epoch: 5| Step: 10
Training loss: 4.600574016571045
Validation loss: 4.034298727909724

Epoch: 5| Step: 11
Training loss: 2.166189432144165
Validation loss: 4.030042032400767

Epoch: 18| Step: 0
Training loss: 5.028637886047363
Validation loss: 4.024990151325862

Epoch: 5| Step: 1
Training loss: 4.778254985809326
Validation loss: 4.021129548549652

Epoch: 5| Step: 2
Training loss: 3.782564878463745
Validation loss: 4.015872220198314

Epoch: 5| Step: 3
Training loss: 3.4240341186523438
Validation loss: 4.011254121859868

Epoch: 5| Step: 4
Training loss: 4.129183769226074
Validation loss: 4.007317245006561

Epoch: 5| Step: 5
Training loss: 4.537191390991211
Validation loss: 4.003409534692764

Epoch: 5| Step: 6
Training loss: 4.420787334442139
Validation loss: 3.9977444609006247

Epoch: 5| Step: 7
Training loss: 3.842961549758911
Validation loss: 3.9921012620131173

Epoch: 5| Step: 8
Training loss: 4.710718631744385
Validation loss: 3.987483332554499

Epoch: 5| Step: 9
Training loss: 3.957332134246826
Validation loss: 3.9830098350842795

Epoch: 5| Step: 10
Training loss: 3.154296636581421
Validation loss: 3.97759672999382

Epoch: 5| Step: 11
Training loss: 3.3907880783081055
Validation loss: 3.973051607608795

Epoch: 19| Step: 0
Training loss: 3.7091317176818848
Validation loss: 3.9697046875953674

Epoch: 5| Step: 1
Training loss: 4.027951717376709
Validation loss: 3.964298059542974

Epoch: 5| Step: 2
Training loss: 5.292770862579346
Validation loss: 3.9582492907842

Epoch: 5| Step: 3
Training loss: 3.5284762382507324
Validation loss: 3.9533364474773407

Epoch: 5| Step: 4
Training loss: 4.123063564300537
Validation loss: 3.9482071499029794

Epoch: 5| Step: 5
Training loss: 3.220162868499756
Validation loss: 3.943275292714437

Epoch: 5| Step: 6
Training loss: 4.180569648742676
Validation loss: 3.9390076100826263

Epoch: 5| Step: 7
Training loss: 3.2549290657043457
Validation loss: 3.934044669071833

Epoch: 5| Step: 8
Training loss: 4.1285176277160645
Validation loss: 3.928610155979792

Epoch: 5| Step: 9
Training loss: 4.619775295257568
Validation loss: 3.923787752787272

Epoch: 5| Step: 10
Training loss: 5.312928199768066
Validation loss: 3.9187338749567666

Epoch: 5| Step: 11
Training loss: 2.117565393447876
Validation loss: 3.9139686226844788

Epoch: 20| Step: 0
Training loss: 4.863829612731934
Validation loss: 3.908398191134135

Epoch: 5| Step: 1
Training loss: 3.044261932373047
Validation loss: 3.9033251901467643

Epoch: 5| Step: 2
Training loss: 3.66662335395813
Validation loss: 3.8983039955298104

Epoch: 5| Step: 3
Training loss: 3.8229546546936035
Validation loss: 3.893119156360626

Epoch: 5| Step: 4
Training loss: 4.431199073791504
Validation loss: 3.887842526038488

Epoch: 5| Step: 5
Training loss: 4.269283294677734
Validation loss: 3.8824970920880637

Epoch: 5| Step: 6
Training loss: 4.852322578430176
Validation loss: 3.8771817286809287

Epoch: 5| Step: 7
Training loss: 3.1396021842956543
Validation loss: 3.872033874193827

Epoch: 5| Step: 8
Training loss: 4.3164381980896
Validation loss: 3.8662798007329306

Epoch: 5| Step: 9
Training loss: 4.524166107177734
Validation loss: 3.86097780863444

Epoch: 5| Step: 10
Training loss: 3.5691540241241455
Validation loss: 3.8545099198818207

Epoch: 5| Step: 11
Training loss: 3.3393781185150146
Validation loss: 3.8483332097530365

Epoch: 21| Step: 0
Training loss: 3.684155225753784
Validation loss: 3.8421148558457694

Epoch: 5| Step: 1
Training loss: 4.194090843200684
Validation loss: 3.8372029960155487

Epoch: 5| Step: 2
Training loss: 3.2528090476989746
Validation loss: 3.831123818953832

Epoch: 5| Step: 3
Training loss: 4.067417144775391
Validation loss: 3.8261751234531403

Epoch: 5| Step: 4
Training loss: 3.717308521270752
Validation loss: 3.820423016945521

Epoch: 5| Step: 5
Training loss: 3.4790942668914795
Validation loss: 3.815339078505834

Epoch: 5| Step: 6
Training loss: 4.76022481918335
Validation loss: 3.8100676933924356

Epoch: 5| Step: 7
Training loss: 3.536043643951416
Validation loss: 3.805066059033076

Epoch: 5| Step: 8
Training loss: 4.313872814178467
Validation loss: 3.799971083799998

Epoch: 5| Step: 9
Training loss: 4.436373710632324
Validation loss: 3.794635087251663

Epoch: 5| Step: 10
Training loss: 4.3595452308654785
Validation loss: 3.7894563575585685

Epoch: 5| Step: 11
Training loss: 3.1766233444213867
Validation loss: 3.784256339073181

Epoch: 22| Step: 0
Training loss: 2.666116714477539
Validation loss: 3.7798611323038735

Epoch: 5| Step: 1
Training loss: 2.536619186401367
Validation loss: 3.774211049079895

Epoch: 5| Step: 2
Training loss: 4.0525312423706055
Validation loss: 3.769580294688543

Epoch: 5| Step: 3
Training loss: 4.117349147796631
Validation loss: 3.7648444771766663

Epoch: 5| Step: 4
Training loss: 4.534961700439453
Validation loss: 3.7596819400787354

Epoch: 5| Step: 5
Training loss: 4.264938831329346
Validation loss: 3.7541105647881827

Epoch: 5| Step: 6
Training loss: 3.985064744949341
Validation loss: 3.749620954195658

Epoch: 5| Step: 7
Training loss: 3.9745705127716064
Validation loss: 3.745717783768972

Epoch: 5| Step: 8
Training loss: 4.3626532554626465
Validation loss: 3.739282717307409

Epoch: 5| Step: 9
Training loss: 3.952239990234375
Validation loss: 3.7342281142870584

Epoch: 5| Step: 10
Training loss: 4.852320671081543
Validation loss: 3.729004909594854

Epoch: 5| Step: 11
Training loss: 2.488994598388672
Validation loss: 3.724098821481069

Epoch: 23| Step: 0
Training loss: 3.7511048316955566
Validation loss: 3.7193455696105957

Epoch: 5| Step: 1
Training loss: 3.5365657806396484
Validation loss: 3.71469454964002

Epoch: 5| Step: 2
Training loss: 3.9167187213897705
Validation loss: 3.710426022609075

Epoch: 5| Step: 3
Training loss: 3.906787872314453
Validation loss: 3.7051680584748587

Epoch: 5| Step: 4
Training loss: 4.2005815505981445
Validation loss: 3.700972010691961

Epoch: 5| Step: 5
Training loss: 4.5146284103393555
Validation loss: 3.696480999390284

Epoch: 5| Step: 6
Training loss: 2.446242094039917
Validation loss: 3.6923091312249503

Epoch: 5| Step: 7
Training loss: 4.662222385406494
Validation loss: 3.6875565350055695

Epoch: 5| Step: 8
Training loss: 3.8259711265563965
Validation loss: 3.683052748441696

Epoch: 5| Step: 9
Training loss: 4.005769729614258
Validation loss: 3.6793941259384155

Epoch: 5| Step: 10
Training loss: 3.646749496459961
Validation loss: 3.6735147535800934

Epoch: 5| Step: 11
Training loss: 3.8490376472473145
Validation loss: 3.6690562665462494

Epoch: 24| Step: 0
Training loss: 4.659745693206787
Validation loss: 3.6648031075795493

Epoch: 5| Step: 1
Training loss: 4.077304840087891
Validation loss: 3.660015116135279

Epoch: 5| Step: 2
Training loss: 3.3575940132141113
Validation loss: 3.6543216506640115

Epoch: 5| Step: 3
Training loss: 3.846539258956909
Validation loss: 3.6498166223367057

Epoch: 5| Step: 4
Training loss: 2.436075210571289
Validation loss: 3.6453253825505576

Epoch: 5| Step: 5
Training loss: 3.1602156162261963
Validation loss: 3.6410423517227173

Epoch: 5| Step: 6
Training loss: 4.313321113586426
Validation loss: 3.6357065935929618

Epoch: 5| Step: 7
Training loss: 3.542752742767334
Validation loss: 3.6316421230634055

Epoch: 5| Step: 8
Training loss: 4.8877129554748535
Validation loss: 3.627217650413513

Epoch: 5| Step: 9
Training loss: 3.777087688446045
Validation loss: 3.6223087906837463

Epoch: 5| Step: 10
Training loss: 3.8192317485809326
Validation loss: 3.6181849936644235

Epoch: 5| Step: 11
Training loss: 3.5451292991638184
Validation loss: 3.613451679547628

Epoch: 25| Step: 0
Training loss: 2.743614435195923
Validation loss: 3.6089740494887033

Epoch: 5| Step: 1
Training loss: 3.388399124145508
Validation loss: 3.6051621437072754

Epoch: 5| Step: 2
Training loss: 4.379885196685791
Validation loss: 3.6009393533070884

Epoch: 5| Step: 3
Training loss: 3.981005907058716
Validation loss: 3.5976567467053733

Epoch: 5| Step: 4
Training loss: 3.4091224670410156
Validation loss: 3.5919333000977836

Epoch: 5| Step: 5
Training loss: 4.812202453613281
Validation loss: 3.58754625916481

Epoch: 5| Step: 6
Training loss: 4.013594150543213
Validation loss: 3.582900991042455

Epoch: 5| Step: 7
Training loss: 3.1709368228912354
Validation loss: 3.5791065394878387

Epoch: 5| Step: 8
Training loss: 3.4931254386901855
Validation loss: 3.574816197156906

Epoch: 5| Step: 9
Training loss: 3.5041465759277344
Validation loss: 3.5700163145860038

Epoch: 5| Step: 10
Training loss: 4.372002601623535
Validation loss: 3.5649908979733786

Epoch: 5| Step: 11
Training loss: 3.6665754318237305
Validation loss: 3.560926059881846

Epoch: 26| Step: 0
Training loss: 3.3933632373809814
Validation loss: 3.557104488213857

Epoch: 5| Step: 1
Training loss: 3.180880069732666
Validation loss: 3.5534963607788086

Epoch: 5| Step: 2
Training loss: 3.7419514656066895
Validation loss: 3.549313614765803

Epoch: 5| Step: 3
Training loss: 4.183957099914551
Validation loss: 3.5436732868353524

Epoch: 5| Step: 4
Training loss: 3.5136141777038574
Validation loss: 3.5381929874420166

Epoch: 5| Step: 5
Training loss: 3.499985933303833
Validation loss: 3.5334408779939017

Epoch: 5| Step: 6
Training loss: 4.0711870193481445
Validation loss: 3.5294326841831207

Epoch: 5| Step: 7
Training loss: 2.934809446334839
Validation loss: 3.525458723306656

Epoch: 5| Step: 8
Training loss: 4.2832841873168945
Validation loss: 3.5206999480724335

Epoch: 5| Step: 9
Training loss: 3.874340772628784
Validation loss: 3.5158470968405404

Epoch: 5| Step: 10
Training loss: 3.9834015369415283
Validation loss: 3.51137912273407

Epoch: 5| Step: 11
Training loss: 3.858962297439575
Validation loss: 3.506980617841085

Epoch: 27| Step: 0
Training loss: 3.744957685470581
Validation loss: 3.502351999282837

Epoch: 5| Step: 1
Training loss: 3.480703830718994
Validation loss: 3.4980847537517548

Epoch: 5| Step: 2
Training loss: 3.336183547973633
Validation loss: 3.493713895479838

Epoch: 5| Step: 3
Training loss: 3.5133438110351562
Validation loss: 3.488923023144404

Epoch: 5| Step: 4
Training loss: 3.8855698108673096
Validation loss: 3.485692173242569

Epoch: 5| Step: 5
Training loss: 4.434704303741455
Validation loss: 3.4803748627503714

Epoch: 5| Step: 6
Training loss: 3.47517728805542
Validation loss: 3.4757529199123383

Epoch: 5| Step: 7
Training loss: 3.464865207672119
Validation loss: 3.470639616250992

Epoch: 5| Step: 8
Training loss: 3.4056954383850098
Validation loss: 3.4669714868068695

Epoch: 5| Step: 9
Training loss: 3.76496958732605
Validation loss: 3.462436228990555

Epoch: 5| Step: 10
Training loss: 3.452005386352539
Validation loss: 3.4591432015101113

Epoch: 5| Step: 11
Training loss: 4.4637651443481445
Validation loss: 3.45395165681839

Epoch: 28| Step: 0
Training loss: 4.589635372161865
Validation loss: 3.45002673069636

Epoch: 5| Step: 1
Training loss: 3.6589417457580566
Validation loss: 3.44567463795344

Epoch: 5| Step: 2
Training loss: 3.893115520477295
Validation loss: 3.4405462642510733

Epoch: 5| Step: 3
Training loss: 3.2562384605407715
Validation loss: 3.4361012279987335

Epoch: 5| Step: 4
Training loss: 3.42851185798645
Validation loss: 3.4323877692222595

Epoch: 5| Step: 5
Training loss: 2.4644079208374023
Validation loss: 3.4282257656256356

Epoch: 5| Step: 6
Training loss: 3.6651577949523926
Validation loss: 3.424548625946045

Epoch: 5| Step: 7
Training loss: 4.746448516845703
Validation loss: 3.4204282462596893

Epoch: 5| Step: 8
Training loss: 3.1073989868164062
Validation loss: 3.4163989623387656

Epoch: 5| Step: 9
Training loss: 3.5017166137695312
Validation loss: 3.4122937818368277

Epoch: 5| Step: 10
Training loss: 3.1215481758117676
Validation loss: 3.408412535985311

Epoch: 5| Step: 11
Training loss: 4.2212371826171875
Validation loss: 3.404140532016754

Epoch: 29| Step: 0
Training loss: 3.578068494796753
Validation loss: 3.4006471733252206

Epoch: 5| Step: 1
Training loss: 3.3120341300964355
Validation loss: 3.3963663975397744

Epoch: 5| Step: 2
Training loss: 3.2997124195098877
Validation loss: 3.3922327160835266

Epoch: 5| Step: 3
Training loss: 4.173488140106201
Validation loss: 3.3875694374243417

Epoch: 5| Step: 4
Training loss: 3.3893661499023438
Validation loss: 3.3835221926371255

Epoch: 5| Step: 5
Training loss: 3.22468638420105
Validation loss: 3.379984309275945

Epoch: 5| Step: 6
Training loss: 3.092388153076172
Validation loss: 3.37577090660731

Epoch: 5| Step: 7
Training loss: 3.2678394317626953
Validation loss: 3.3716059029102325

Epoch: 5| Step: 8
Training loss: 3.7560107707977295
Validation loss: 3.3678141931692758

Epoch: 5| Step: 9
Training loss: 3.9458680152893066
Validation loss: 3.363085061311722

Epoch: 5| Step: 10
Training loss: 3.926086902618408
Validation loss: 3.3595938881238303

Epoch: 5| Step: 11
Training loss: 3.915468454360962
Validation loss: 3.3553419212500253

Epoch: 30| Step: 0
Training loss: 3.1585803031921387
Validation loss: 3.351581613222758

Epoch: 5| Step: 1
Training loss: 3.361135482788086
Validation loss: 3.347949822743734

Epoch: 5| Step: 2
Training loss: 4.548216819763184
Validation loss: 3.343605697154999

Epoch: 5| Step: 3
Training loss: 3.355292797088623
Validation loss: 3.3389558692773185

Epoch: 5| Step: 4
Training loss: 3.029578685760498
Validation loss: 3.335407644510269

Epoch: 5| Step: 5
Training loss: 3.877906084060669
Validation loss: 3.331429660320282

Epoch: 5| Step: 6
Training loss: 2.7432291507720947
Validation loss: 3.327463229497274

Epoch: 5| Step: 7
Training loss: 3.721308946609497
Validation loss: 3.324353108803431

Epoch: 5| Step: 8
Training loss: 2.956087112426758
Validation loss: 3.31905206044515

Epoch: 5| Step: 9
Training loss: 3.6289329528808594
Validation loss: 3.3156164288520813

Epoch: 5| Step: 10
Training loss: 4.203066825866699
Validation loss: 3.310949385166168

Epoch: 5| Step: 11
Training loss: 3.316518545150757
Validation loss: 3.306986610094706

Epoch: 31| Step: 0
Training loss: 3.806659698486328
Validation loss: 3.302693247795105

Epoch: 5| Step: 1
Training loss: 3.3743762969970703
Validation loss: 3.298667758703232

Epoch: 5| Step: 2
Training loss: 4.401333808898926
Validation loss: 3.294938246409098

Epoch: 5| Step: 3
Training loss: 3.479485273361206
Validation loss: 3.2911174992720285

Epoch: 5| Step: 4
Training loss: 3.665628433227539
Validation loss: 3.2869258920351663

Epoch: 5| Step: 5
Training loss: 2.633821487426758
Validation loss: 3.2831163009007773

Epoch: 5| Step: 6
Training loss: 3.6984963417053223
Validation loss: 3.2796774009863534

Epoch: 5| Step: 7
Training loss: 2.727891206741333
Validation loss: 3.2758189737796783

Epoch: 5| Step: 8
Training loss: 3.633301258087158
Validation loss: 3.2719674607117972

Epoch: 5| Step: 9
Training loss: 3.6611416339874268
Validation loss: 3.268010993798574

Epoch: 5| Step: 10
Training loss: 2.993316173553467
Validation loss: 3.264481176932653

Epoch: 5| Step: 11
Training loss: 3.365565538406372
Validation loss: 3.261129766702652

Epoch: 32| Step: 0
Training loss: 3.4516537189483643
Validation loss: 3.257050176461538

Epoch: 5| Step: 1
Training loss: 4.137775421142578
Validation loss: 3.253322641054789

Epoch: 5| Step: 2
Training loss: 3.6251769065856934
Validation loss: 3.249741623799006

Epoch: 5| Step: 3
Training loss: 3.182432174682617
Validation loss: 3.245634377002716

Epoch: 5| Step: 4
Training loss: 2.8124935626983643
Validation loss: 3.242377132177353

Epoch: 5| Step: 5
Training loss: 3.7836337089538574
Validation loss: 3.238279620806376

Epoch: 5| Step: 6
Training loss: 2.7551658153533936
Validation loss: 3.234670658906301

Epoch: 5| Step: 7
Training loss: 3.2405648231506348
Validation loss: 3.230848491191864

Epoch: 5| Step: 8
Training loss: 3.347057342529297
Validation loss: 3.2272116442521415

Epoch: 5| Step: 9
Training loss: 3.357006072998047
Validation loss: 3.22360227505366

Epoch: 5| Step: 10
Training loss: 3.6773762702941895
Validation loss: 3.2200123965740204

Epoch: 5| Step: 11
Training loss: 4.450261116027832
Validation loss: 3.216421604156494

Epoch: 33| Step: 0
Training loss: 3.7021172046661377
Validation loss: 3.2123939394950867

Epoch: 5| Step: 1
Training loss: 3.437307834625244
Validation loss: 3.2082373102506003

Epoch: 5| Step: 2
Training loss: 3.7962563037872314
Validation loss: 3.203915605942408

Epoch: 5| Step: 3
Training loss: 3.410536289215088
Validation loss: 3.199867914120356

Epoch: 5| Step: 4
Training loss: 3.421072483062744
Validation loss: 3.195902109146118

Epoch: 5| Step: 5
Training loss: 3.1677212715148926
Validation loss: 3.1910389165083566

Epoch: 5| Step: 6
Training loss: 3.6236846446990967
Validation loss: 3.1869992216428122

Epoch: 5| Step: 7
Training loss: 2.647043228149414
Validation loss: 3.182139406601588

Epoch: 5| Step: 8
Training loss: 3.0315890312194824
Validation loss: 3.177915702263514

Epoch: 5| Step: 9
Training loss: 2.8143351078033447
Validation loss: 3.1747718354066214

Epoch: 5| Step: 10
Training loss: 4.185534954071045
Validation loss: 3.1709727744261422

Epoch: 5| Step: 11
Training loss: 2.824948310852051
Validation loss: 3.1670329173405967

Epoch: 34| Step: 0
Training loss: 3.1917810440063477
Validation loss: 3.164379676183065

Epoch: 5| Step: 1
Training loss: 3.6976141929626465
Validation loss: 3.159436752398809

Epoch: 5| Step: 2
Training loss: 3.144620656967163
Validation loss: 3.1567510763804116

Epoch: 5| Step: 3
Training loss: 3.6252224445343018
Validation loss: 3.1515692869822183

Epoch: 5| Step: 4
Training loss: 3.6397311687469482
Validation loss: 3.1475805739561715

Epoch: 5| Step: 5
Training loss: 3.342419147491455
Validation loss: 3.1434437135855355

Epoch: 5| Step: 6
Training loss: 2.8801350593566895
Validation loss: 3.139517217874527

Epoch: 5| Step: 7
Training loss: 3.635589599609375
Validation loss: 3.1361919144789376

Epoch: 5| Step: 8
Training loss: 3.1616172790527344
Validation loss: 3.1322301626205444

Epoch: 5| Step: 9
Training loss: 3.1400277614593506
Validation loss: 3.1281271278858185

Epoch: 5| Step: 10
Training loss: 3.1880462169647217
Validation loss: 3.124432474374771

Epoch: 5| Step: 11
Training loss: 3.288590908050537
Validation loss: 3.1199486951033273

Epoch: 35| Step: 0
Training loss: 3.2937018871307373
Validation loss: 3.1154598593711853

Epoch: 5| Step: 1
Training loss: 3.8703551292419434
Validation loss: 3.1111502846082053

Epoch: 5| Step: 2
Training loss: 3.414189100265503
Validation loss: 3.1058326760927835

Epoch: 5| Step: 3
Training loss: 3.1899056434631348
Validation loss: 3.1007324953873954

Epoch: 5| Step: 4
Training loss: 3.189997911453247
Validation loss: 3.0971327821413674

Epoch: 5| Step: 5
Training loss: 3.4526448249816895
Validation loss: 3.0937055349349976

Epoch: 5| Step: 6
Training loss: 3.5304648876190186
Validation loss: 3.0901977519194284

Epoch: 5| Step: 7
Training loss: 3.0179049968719482
Validation loss: 3.0865837136904397

Epoch: 5| Step: 8
Training loss: 2.9156970977783203
Validation loss: 3.083648920059204

Epoch: 5| Step: 9
Training loss: 3.138774871826172
Validation loss: 3.0801187654336295

Epoch: 5| Step: 10
Training loss: 3.0604710578918457
Validation loss: 3.0769070784250894

Epoch: 5| Step: 11
Training loss: 3.623347520828247
Validation loss: 3.073204606771469

Epoch: 36| Step: 0
Training loss: 3.516171932220459
Validation loss: 3.070500065883001

Epoch: 5| Step: 1
Training loss: 3.304434299468994
Validation loss: 3.0659745136896768

Epoch: 5| Step: 2
Training loss: 3.2444064617156982
Validation loss: 3.0627814531326294

Epoch: 5| Step: 3
Training loss: 3.7794792652130127
Validation loss: 3.058899074792862

Epoch: 5| Step: 4
Training loss: 2.280271053314209
Validation loss: 3.0554983715216317

Epoch: 5| Step: 5
Training loss: 3.0763955116271973
Validation loss: 3.052146484454473

Epoch: 5| Step: 6
Training loss: 2.7339205741882324
Validation loss: 3.04860124985377

Epoch: 5| Step: 7
Training loss: 3.7944273948669434
Validation loss: 3.0447111427783966

Epoch: 5| Step: 8
Training loss: 4.1501054763793945
Validation loss: 3.0408160289128623

Epoch: 5| Step: 9
Training loss: 2.9725818634033203
Validation loss: 3.037214150031408

Epoch: 5| Step: 10
Training loss: 2.9930195808410645
Validation loss: 3.033600668112437

Epoch: 5| Step: 11
Training loss: 2.3861546516418457
Validation loss: 3.030631879965464

Epoch: 37| Step: 0
Training loss: 3.4073691368103027
Validation loss: 3.027193456888199

Epoch: 5| Step: 1
Training loss: 2.879786729812622
Validation loss: 3.0240854620933533

Epoch: 5| Step: 2
Training loss: 2.9378371238708496
Validation loss: 3.0205332140127816

Epoch: 5| Step: 3
Training loss: 3.479804515838623
Validation loss: 3.01735782623291

Epoch: 5| Step: 4
Training loss: 2.5582973957061768
Validation loss: 3.014319598674774

Epoch: 5| Step: 5
Training loss: 3.1009445190429688
Validation loss: 3.01092591881752

Epoch: 5| Step: 6
Training loss: 3.0048372745513916
Validation loss: 3.0078983207543692

Epoch: 5| Step: 7
Training loss: 3.43884539604187
Validation loss: 3.0046465496222177

Epoch: 5| Step: 8
Training loss: 3.677976131439209
Validation loss: 3.001241813103358

Epoch: 5| Step: 9
Training loss: 3.2283756732940674
Validation loss: 2.998368114233017

Epoch: 5| Step: 10
Training loss: 3.224180221557617
Validation loss: 2.9947865903377533

Epoch: 5| Step: 11
Training loss: 4.753020286560059
Validation loss: 2.9915990432103476

Epoch: 38| Step: 0
Training loss: 2.988621234893799
Validation loss: 2.9883346259593964

Epoch: 5| Step: 1
Training loss: 3.751303195953369
Validation loss: 2.985386073589325

Epoch: 5| Step: 2
Training loss: 3.3664469718933105
Validation loss: 2.9823986291885376

Epoch: 5| Step: 3
Training loss: 3.3606536388397217
Validation loss: 2.9785940448443093

Epoch: 5| Step: 4
Training loss: 2.4366257190704346
Validation loss: 2.975904017686844

Epoch: 5| Step: 5
Training loss: 3.1472103595733643
Validation loss: 2.9727765321731567

Epoch: 5| Step: 6
Training loss: 3.0587661266326904
Validation loss: 2.968995153903961

Epoch: 5| Step: 7
Training loss: 3.158564805984497
Validation loss: 2.965779572725296

Epoch: 5| Step: 8
Training loss: 3.3518848419189453
Validation loss: 2.96273680528005

Epoch: 5| Step: 9
Training loss: 3.466130018234253
Validation loss: 2.9595686395963035

Epoch: 5| Step: 10
Training loss: 2.6475186347961426
Validation loss: 2.955851932366689

Epoch: 5| Step: 11
Training loss: 3.8686318397521973
Validation loss: 2.9526093304157257

Epoch: 39| Step: 0
Training loss: 3.494720935821533
Validation loss: 2.949745148420334

Epoch: 5| Step: 1
Training loss: 3.092888355255127
Validation loss: 2.946807026863098

Epoch: 5| Step: 2
Training loss: 3.4222609996795654
Validation loss: 2.943751106659571

Epoch: 5| Step: 3
Training loss: 2.4749953746795654
Validation loss: 2.9406459828217826

Epoch: 5| Step: 4
Training loss: 3.1947295665740967
Validation loss: 2.9375563263893127

Epoch: 5| Step: 5
Training loss: 3.092221736907959
Validation loss: 2.934759110212326

Epoch: 5| Step: 6
Training loss: 3.619946241378784
Validation loss: 2.932146579027176

Epoch: 5| Step: 7
Training loss: 3.551238536834717
Validation loss: 2.9287518362204232

Epoch: 5| Step: 8
Training loss: 2.9483025074005127
Validation loss: 2.9253943463166556

Epoch: 5| Step: 9
Training loss: 3.1900429725646973
Validation loss: 2.9227342108885446

Epoch: 5| Step: 10
Training loss: 2.5350399017333984
Validation loss: 2.919680674870809

Epoch: 5| Step: 11
Training loss: 2.535641670227051
Validation loss: 2.9166014790534973

Epoch: 40| Step: 0
Training loss: 2.8783979415893555
Validation loss: 2.9140191276868186

Epoch: 5| Step: 1
Training loss: 3.1551754474639893
Validation loss: 2.910937617222468

Epoch: 5| Step: 2
Training loss: 3.668001174926758
Validation loss: 2.9080652395884194

Epoch: 5| Step: 3
Training loss: 3.8620574474334717
Validation loss: 2.904410481452942

Epoch: 5| Step: 4
Training loss: 2.9362051486968994
Validation loss: 2.9007266461849213

Epoch: 5| Step: 5
Training loss: 2.9500839710235596
Validation loss: 2.897629896799723

Epoch: 5| Step: 6
Training loss: 2.8115620613098145
Validation loss: 2.89455708861351

Epoch: 5| Step: 7
Training loss: 3.492069721221924
Validation loss: 2.8911148409048715

Epoch: 5| Step: 8
Training loss: 2.5380680561065674
Validation loss: 2.8881936371326447

Epoch: 5| Step: 9
Training loss: 3.2363224029541016
Validation loss: 2.885227839152018

Epoch: 5| Step: 10
Training loss: 2.6645240783691406
Validation loss: 2.8819860021273294

Epoch: 5| Step: 11
Training loss: 2.9394960403442383
Validation loss: 2.879351407289505

Epoch: 41| Step: 0
Training loss: 2.8139126300811768
Validation loss: 2.876365005970001

Epoch: 5| Step: 1
Training loss: 3.173142671585083
Validation loss: 2.8734627266724906

Epoch: 5| Step: 2
Training loss: 3.5530848503112793
Validation loss: 2.870945990085602

Epoch: 5| Step: 3
Training loss: 3.4821784496307373
Validation loss: 2.867999871571859

Epoch: 5| Step: 4
Training loss: 2.438971996307373
Validation loss: 2.864985764026642

Epoch: 5| Step: 5
Training loss: 2.507300615310669
Validation loss: 2.862676501274109

Epoch: 5| Step: 6
Training loss: 3.433032512664795
Validation loss: 2.8598443071047464

Epoch: 5| Step: 7
Training loss: 3.491415023803711
Validation loss: 2.8573531210422516

Epoch: 5| Step: 8
Training loss: 2.79231595993042
Validation loss: 2.8544437885284424

Epoch: 5| Step: 9
Training loss: 2.6406936645507812
Validation loss: 2.8520268201828003

Epoch: 5| Step: 10
Training loss: 3.205554246902466
Validation loss: 2.849552313486735

Epoch: 5| Step: 11
Training loss: 4.400368690490723
Validation loss: 2.846065362294515

Epoch: 42| Step: 0
Training loss: 3.3167922496795654
Validation loss: 2.843709816535314

Epoch: 5| Step: 1
Training loss: 2.97462797164917
Validation loss: 2.840595801671346

Epoch: 5| Step: 2
Training loss: 3.3828232288360596
Validation loss: 2.8376794954140983

Epoch: 5| Step: 3
Training loss: 2.4906468391418457
Validation loss: 2.8344887296358743

Epoch: 5| Step: 4
Training loss: 2.5578277111053467
Validation loss: 2.831836740175883

Epoch: 5| Step: 5
Training loss: 2.6104650497436523
Validation loss: 2.828928510348002

Epoch: 5| Step: 6
Training loss: 3.405402421951294
Validation loss: 2.826459268728892

Epoch: 5| Step: 7
Training loss: 2.5169341564178467
Validation loss: 2.8238704601923623

Epoch: 5| Step: 8
Training loss: 3.668760299682617
Validation loss: 2.8211402098337808

Epoch: 5| Step: 9
Training loss: 3.1437203884124756
Validation loss: 2.818404952685038

Epoch: 5| Step: 10
Training loss: 3.3464832305908203
Validation loss: 2.8158190151055655

Epoch: 5| Step: 11
Training loss: 3.2687439918518066
Validation loss: 2.8131499687830606

Epoch: 43| Step: 0
Training loss: 2.8001437187194824
Validation loss: 2.810371140638987

Epoch: 5| Step: 1
Training loss: 3.0101265907287598
Validation loss: 2.8078737358252206

Epoch: 5| Step: 2
Training loss: 3.291524887084961
Validation loss: 2.8051703770955405

Epoch: 5| Step: 3
Training loss: 3.772998332977295
Validation loss: 2.802214652299881

Epoch: 5| Step: 4
Training loss: 2.795644521713257
Validation loss: 2.799613267183304

Epoch: 5| Step: 5
Training loss: 3.2026302814483643
Validation loss: 2.7973749240239463

Epoch: 5| Step: 6
Training loss: 2.896989345550537
Validation loss: 2.7944405178229013

Epoch: 5| Step: 7
Training loss: 2.7201037406921387
Validation loss: 2.791927585999171

Epoch: 5| Step: 8
Training loss: 2.4296181201934814
Validation loss: 2.7894994914531708

Epoch: 5| Step: 9
Training loss: 3.4597020149230957
Validation loss: 2.7866112192471824

Epoch: 5| Step: 10
Training loss: 2.769516706466675
Validation loss: 2.784099539120992

Epoch: 5| Step: 11
Training loss: 2.799530029296875
Validation loss: 2.7815671265125275

Epoch: 44| Step: 0
Training loss: 3.393547773361206
Validation loss: 2.7787094712257385

Epoch: 5| Step: 1
Training loss: 3.754143476486206
Validation loss: 2.7751037180423737

Epoch: 5| Step: 2
Training loss: 2.716348648071289
Validation loss: 2.772289623816808

Epoch: 5| Step: 3
Training loss: 3.0430920124053955
Validation loss: 2.769270678361257

Epoch: 5| Step: 4
Training loss: 2.690058469772339
Validation loss: 2.7664437095324197

Epoch: 5| Step: 5
Training loss: 3.1193313598632812
Validation loss: 2.7634231050809226

Epoch: 5| Step: 6
Training loss: 3.146998643875122
Validation loss: 2.7609157860279083

Epoch: 5| Step: 7
Training loss: 2.801178455352783
Validation loss: 2.7579950094223022

Epoch: 5| Step: 8
Training loss: 2.843132734298706
Validation loss: 2.755439966917038

Epoch: 5| Step: 9
Training loss: 2.7213315963745117
Validation loss: 2.752543648084005

Epoch: 5| Step: 10
Training loss: 2.2623605728149414
Validation loss: 2.749599277973175

Epoch: 5| Step: 11
Training loss: 4.3019866943359375
Validation loss: 2.747039536635081

Epoch: 45| Step: 0
Training loss: 3.492060422897339
Validation loss: 2.7444695432980857

Epoch: 5| Step: 1
Training loss: 3.1372742652893066
Validation loss: 2.741716355085373

Epoch: 5| Step: 2
Training loss: 2.320122480392456
Validation loss: 2.738699515660604

Epoch: 5| Step: 3
Training loss: 3.24946928024292
Validation loss: 2.736187865336736

Epoch: 5| Step: 4
Training loss: 3.018289089202881
Validation loss: 2.73340634504954

Epoch: 5| Step: 5
Training loss: 2.6333484649658203
Validation loss: 2.730820655822754

Epoch: 5| Step: 6
Training loss: 3.2078628540039062
Validation loss: 2.728013048569361

Epoch: 5| Step: 7
Training loss: 2.980424642562866
Validation loss: 2.7254149516423545

Epoch: 5| Step: 8
Training loss: 2.783388376235962
Validation loss: 2.721700151761373

Epoch: 5| Step: 9
Training loss: 2.9219939708709717
Validation loss: 2.719818204641342

Epoch: 5| Step: 10
Training loss: 2.398940086364746
Validation loss: 2.716392993927002

Epoch: 5| Step: 11
Training loss: 3.9794559478759766
Validation loss: 2.7142756978670755

Epoch: 46| Step: 0
Training loss: 3.024909257888794
Validation loss: 2.7115913033485413

Epoch: 5| Step: 1
Training loss: 3.5106101036071777
Validation loss: 2.7087951799233756

Epoch: 5| Step: 2
Training loss: 2.7765069007873535
Validation loss: 2.7060953279336295

Epoch: 5| Step: 3
Training loss: 3.0006182193756104
Validation loss: 2.7034698526064553

Epoch: 5| Step: 4
Training loss: 3.015288829803467
Validation loss: 2.700555384159088

Epoch: 5| Step: 5
Training loss: 2.6476566791534424
Validation loss: 2.696800947189331

Epoch: 5| Step: 6
Training loss: 1.8208621740341187
Validation loss: 2.694442937771479

Epoch: 5| Step: 7
Training loss: 2.920823574066162
Validation loss: 2.6914656261603036

Epoch: 5| Step: 8
Training loss: 3.085059404373169
Validation loss: 2.6884278456370034

Epoch: 5| Step: 9
Training loss: 3.143465280532837
Validation loss: 2.6856374541918435

Epoch: 5| Step: 10
Training loss: 2.9726576805114746
Validation loss: 2.682522177696228

Epoch: 5| Step: 11
Training loss: 3.0845298767089844
Validation loss: 2.6801316936810813

Epoch: 47| Step: 0
Training loss: 3.229461193084717
Validation loss: 2.676860968271891

Epoch: 5| Step: 1
Training loss: 2.885592460632324
Validation loss: 2.674162050088247

Epoch: 5| Step: 2
Training loss: 3.082782030105591
Validation loss: 2.671316603819529

Epoch: 5| Step: 3
Training loss: 3.183168888092041
Validation loss: 2.6678309241930642

Epoch: 5| Step: 4
Training loss: 2.864546298980713
Validation loss: 2.6647605995337167

Epoch: 5| Step: 5
Training loss: 2.193190574645996
Validation loss: 2.661022702852885

Epoch: 5| Step: 6
Training loss: 2.756160259246826
Validation loss: 2.658660719792048

Epoch: 5| Step: 7
Training loss: 3.039576292037964
Validation loss: 2.655221084753672

Epoch: 5| Step: 8
Training loss: 3.309312343597412
Validation loss: 2.652235686779022

Epoch: 5| Step: 9
Training loss: 2.4396424293518066
Validation loss: 2.648768792549769

Epoch: 5| Step: 10
Training loss: 2.803773880004883
Validation loss: 2.646519720554352

Epoch: 5| Step: 11
Training loss: 1.7719215154647827
Validation loss: 2.643792361021042

Epoch: 48| Step: 0
Training loss: 3.207820177078247
Validation loss: 2.6414414445559182

Epoch: 5| Step: 1
Training loss: 2.697289228439331
Validation loss: 2.639621024330457

Epoch: 5| Step: 2
Training loss: 2.8023324012756348
Validation loss: 2.637253145376841

Epoch: 5| Step: 3
Training loss: 2.7517495155334473
Validation loss: 2.634213904539744

Epoch: 5| Step: 4
Training loss: 2.914510488510132
Validation loss: 2.6310851077238717

Epoch: 5| Step: 5
Training loss: 2.130765438079834
Validation loss: 2.6289877196153006

Epoch: 5| Step: 6
Training loss: 2.73997163772583
Validation loss: 2.6268533964951835

Epoch: 5| Step: 7
Training loss: 3.2402710914611816
Validation loss: 2.62316424647967

Epoch: 5| Step: 8
Training loss: 2.52260422706604
Validation loss: 2.620460251967112

Epoch: 5| Step: 9
Training loss: 3.3782927989959717
Validation loss: 2.6189004878203073

Epoch: 5| Step: 10
Training loss: 2.793349027633667
Validation loss: 2.6145059764385223

Epoch: 5| Step: 11
Training loss: 2.7633867263793945
Validation loss: 2.6109280983606973

Epoch: 49| Step: 0
Training loss: 2.8655362129211426
Validation loss: 2.60917928814888

Epoch: 5| Step: 1
Training loss: 3.406498670578003
Validation loss: 2.605430632829666

Epoch: 5| Step: 2
Training loss: 2.1832034587860107
Validation loss: 2.60165144999822

Epoch: 5| Step: 3
Training loss: 2.4212939739227295
Validation loss: 2.5995792547861734

Epoch: 5| Step: 4
Training loss: 3.111037015914917
Validation loss: 2.598088636994362

Epoch: 5| Step: 5
Training loss: 3.275552272796631
Validation loss: 2.5937774380048118

Epoch: 5| Step: 6
Training loss: 2.6532444953918457
Validation loss: 2.590891659259796

Epoch: 5| Step: 7
Training loss: 2.2657723426818848
Validation loss: 2.587637424468994

Epoch: 5| Step: 8
Training loss: 2.544679641723633
Validation loss: 2.590921094020208

Epoch: 5| Step: 9
Training loss: 3.1636273860931396
Validation loss: 2.5826836824417114

Epoch: 5| Step: 10
Training loss: 2.915700674057007
Validation loss: 2.57750075062116

Epoch: 5| Step: 11
Training loss: 2.7723546028137207
Validation loss: 2.5757729609807334

Epoch: 50| Step: 0
Training loss: 2.3918333053588867
Validation loss: 2.5837636391321817

Epoch: 5| Step: 1
Training loss: 3.247175693511963
Validation loss: 2.6165575881799064

Epoch: 5| Step: 2
Training loss: 3.2287211418151855
Validation loss: 2.592922737201055

Epoch: 5| Step: 3
Training loss: 1.8807376623153687
Validation loss: 2.5824020206928253

Epoch: 5| Step: 4
Training loss: 2.5264992713928223
Validation loss: 2.5783687631289163

Epoch: 5| Step: 5
Training loss: 2.908088207244873
Validation loss: 2.57624559601148

Epoch: 5| Step: 6
Training loss: 2.5148627758026123
Validation loss: 2.5756697952747345

Epoch: 5| Step: 7
Training loss: 3.0649092197418213
Validation loss: 2.5720707376797995

Epoch: 5| Step: 8
Training loss: 3.1387405395507812
Validation loss: 2.5662865340709686

Epoch: 5| Step: 9
Training loss: 2.710503101348877
Validation loss: 2.5627210438251495

Epoch: 5| Step: 10
Training loss: 3.087329149246216
Validation loss: 2.56116446852684

Epoch: 5| Step: 11
Training loss: 2.192009687423706
Validation loss: 2.557748625675837

Epoch: 51| Step: 0
Training loss: 1.8983319997787476
Validation loss: 2.5538167357444763

Epoch: 5| Step: 1
Training loss: 3.0470714569091797
Validation loss: 2.5512814124425254

Epoch: 5| Step: 2
Training loss: 2.3272323608398438
Validation loss: 2.5468947092692056

Epoch: 5| Step: 3
Training loss: 2.953483819961548
Validation loss: 2.5455742875734964

Epoch: 5| Step: 4
Training loss: 2.4485864639282227
Validation loss: 2.5408187409241996

Epoch: 5| Step: 5
Training loss: 2.9553873538970947
Validation loss: 2.535746912161509

Epoch: 5| Step: 6
Training loss: 2.9645652770996094
Validation loss: 2.533970673878988

Epoch: 5| Step: 7
Training loss: 2.764011859893799
Validation loss: 2.531369556983312

Epoch: 5| Step: 8
Training loss: 3.142986297607422
Validation loss: 2.5292165279388428

Epoch: 5| Step: 9
Training loss: 2.7489631175994873
Validation loss: 2.525591512521108

Epoch: 5| Step: 10
Training loss: 2.842282772064209
Validation loss: 2.5236199299494424

Epoch: 5| Step: 11
Training loss: 2.8893299102783203
Validation loss: 2.521657188733419

Epoch: 52| Step: 0
Training loss: 2.479282855987549
Validation loss: 2.518571764230728

Epoch: 5| Step: 1
Training loss: 3.096205472946167
Validation loss: 2.516301244497299

Epoch: 5| Step: 2
Training loss: 2.492974281311035
Validation loss: 2.513489226500193

Epoch: 5| Step: 3
Training loss: 2.868136167526245
Validation loss: 2.5124262968699136

Epoch: 5| Step: 4
Training loss: 2.4054765701293945
Validation loss: 2.5089340110619864

Epoch: 5| Step: 5
Training loss: 2.964062452316284
Validation loss: 2.506389707326889

Epoch: 5| Step: 6
Training loss: 2.5170376300811768
Validation loss: 2.503644267717997

Epoch: 5| Step: 7
Training loss: 2.3795435428619385
Validation loss: 2.5014066298802695

Epoch: 5| Step: 8
Training loss: 3.2982726097106934
Validation loss: 2.498703107237816

Epoch: 5| Step: 9
Training loss: 2.7896080017089844
Validation loss: 2.496923267841339

Epoch: 5| Step: 10
Training loss: 2.4313366413116455
Validation loss: 2.494191735982895

Epoch: 5| Step: 11
Training loss: 2.851433038711548
Validation loss: 2.4923014044761658

Epoch: 53| Step: 0
Training loss: 2.2351062297821045
Validation loss: 2.489417294661204

Epoch: 5| Step: 1
Training loss: 2.411229133605957
Validation loss: 2.486287842194239

Epoch: 5| Step: 2
Training loss: 3.0224528312683105
Validation loss: 2.4854687054951987

Epoch: 5| Step: 3
Training loss: 2.6628432273864746
Validation loss: 2.4822436372439065

Epoch: 5| Step: 4
Training loss: 3.08046293258667
Validation loss: 2.4810938636461892

Epoch: 5| Step: 5
Training loss: 2.492042064666748
Validation loss: 2.4796562989552817

Epoch: 5| Step: 6
Training loss: 3.068999767303467
Validation loss: 2.4772110680739083

Epoch: 5| Step: 7
Training loss: 2.094252109527588
Validation loss: 2.4748440782229104

Epoch: 5| Step: 8
Training loss: 3.011836528778076
Validation loss: 2.469900796810786

Epoch: 5| Step: 9
Training loss: 2.8291873931884766
Validation loss: 2.4673617680867515

Epoch: 5| Step: 10
Training loss: 2.7134952545166016
Validation loss: 2.46527099609375

Epoch: 5| Step: 11
Training loss: 1.4504953622817993
Validation loss: 2.464228222767512

Epoch: 54| Step: 0
Training loss: 3.1671531200408936
Validation loss: 2.4635649820168815

Epoch: 5| Step: 1
Training loss: 1.9722684621810913
Validation loss: 2.462586830059687

Epoch: 5| Step: 2
Training loss: 2.6314210891723633
Validation loss: 2.4593161245187125

Epoch: 5| Step: 3
Training loss: 3.084965229034424
Validation loss: 2.4576988518238068

Epoch: 5| Step: 4
Training loss: 2.7752339839935303
Validation loss: 2.453944822152456

Epoch: 5| Step: 5
Training loss: 2.590883255004883
Validation loss: 2.4516236782073975

Epoch: 5| Step: 6
Training loss: 2.917145013809204
Validation loss: 2.448201189438502

Epoch: 5| Step: 7
Training loss: 2.7919552326202393
Validation loss: 2.4448789407809577

Epoch: 5| Step: 8
Training loss: 2.5517547130584717
Validation loss: 2.4419935444990792

Epoch: 5| Step: 9
Training loss: 2.3368752002716064
Validation loss: 2.438800354798635

Epoch: 5| Step: 10
Training loss: 2.402716875076294
Validation loss: 2.4370624919732413

Epoch: 5| Step: 11
Training loss: 1.8767986297607422
Validation loss: 2.4334987799326577

Epoch: 55| Step: 0
Training loss: 2.5736172199249268
Validation loss: 2.430888831615448

Epoch: 5| Step: 1
Training loss: 2.734379291534424
Validation loss: 2.429330805937449

Epoch: 5| Step: 2
Training loss: 2.460195541381836
Validation loss: 2.4334707061449685

Epoch: 5| Step: 3
Training loss: 2.8566975593566895
Validation loss: 2.4361575643221536

Epoch: 5| Step: 4
Training loss: 3.0854554176330566
Validation loss: 2.429731314380964

Epoch: 5| Step: 5
Training loss: 2.9031310081481934
Validation loss: 2.421394725640615

Epoch: 5| Step: 6
Training loss: 2.2577853202819824
Validation loss: 2.417003244161606

Epoch: 5| Step: 7
Training loss: 2.225144386291504
Validation loss: 2.4132394095261893

Epoch: 5| Step: 8
Training loss: 2.5195183753967285
Validation loss: 2.4147640069325766

Epoch: 5| Step: 9
Training loss: 2.3929476737976074
Validation loss: 2.4154609690109887

Epoch: 5| Step: 10
Training loss: 2.83087420463562
Validation loss: 2.4106047799189887

Epoch: 5| Step: 11
Training loss: 2.1233558654785156
Validation loss: 2.412965734799703

Epoch: 56| Step: 0
Training loss: 2.0562610626220703
Validation loss: 2.411393711964289

Epoch: 5| Step: 1
Training loss: 2.0357565879821777
Validation loss: 2.4108137091000876

Epoch: 5| Step: 2
Training loss: 2.477353572845459
Validation loss: 2.4081851889689765

Epoch: 5| Step: 3
Training loss: 2.4731931686401367
Validation loss: 2.4055076241493225

Epoch: 5| Step: 4
Training loss: 3.1933963298797607
Validation loss: 2.3998870700597763

Epoch: 5| Step: 5
Training loss: 2.3099424839019775
Validation loss: 2.3979027569293976

Epoch: 5| Step: 6
Training loss: 2.21600079536438
Validation loss: 2.3941593567530313

Epoch: 5| Step: 7
Training loss: 2.481801986694336
Validation loss: 2.3911434461673102

Epoch: 5| Step: 8
Training loss: 3.1720471382141113
Validation loss: 2.388725146651268

Epoch: 5| Step: 9
Training loss: 2.741698741912842
Validation loss: 2.3857968548933663

Epoch: 5| Step: 10
Training loss: 3.0881078243255615
Validation loss: 2.3830106457074485

Epoch: 5| Step: 11
Training loss: 3.2916922569274902
Validation loss: 2.3804876506328583

Epoch: 57| Step: 0
Training loss: 3.1560745239257812
Validation loss: 2.4044123192628226

Epoch: 5| Step: 1
Training loss: 2.872645616531372
Validation loss: 2.4079505503177643

Epoch: 5| Step: 2
Training loss: 3.126361846923828
Validation loss: 2.405476520458857

Epoch: 5| Step: 3
Training loss: 2.2729744911193848
Validation loss: 2.398730049530665

Epoch: 5| Step: 4
Training loss: 2.825127124786377
Validation loss: 2.397554044922193

Epoch: 5| Step: 5
Training loss: 2.262798547744751
Validation loss: 2.3967239260673523

Epoch: 5| Step: 6
Training loss: 2.0244407653808594
Validation loss: 2.3922692040602365

Epoch: 5| Step: 7
Training loss: 2.5361328125
Validation loss: 2.3917012264331183

Epoch: 5| Step: 8
Training loss: 2.0808231830596924
Validation loss: 2.391786386569341

Epoch: 5| Step: 9
Training loss: 2.093961000442505
Validation loss: 2.3880587418874106

Epoch: 5| Step: 10
Training loss: 2.919726848602295
Validation loss: 2.3866557081540427

Epoch: 5| Step: 11
Training loss: 3.773594856262207
Validation loss: 2.3822734355926514

Epoch: 58| Step: 0
Training loss: 2.294940948486328
Validation loss: 2.384020616610845

Epoch: 5| Step: 1
Training loss: 2.420788288116455
Validation loss: 2.3795250058174133

Epoch: 5| Step: 2
Training loss: 2.515871524810791
Validation loss: 2.378465458750725

Epoch: 5| Step: 3
Training loss: 3.243943452835083
Validation loss: 2.3757293124993644

Epoch: 5| Step: 4
Training loss: 2.9859790802001953
Validation loss: 2.3732571800549827

Epoch: 5| Step: 5
Training loss: 1.8570470809936523
Validation loss: 2.3695569336414337

Epoch: 5| Step: 6
Training loss: 2.9322192668914795
Validation loss: 2.3668424735466638

Epoch: 5| Step: 7
Training loss: 2.3593666553497314
Validation loss: 2.3650889893372855

Epoch: 5| Step: 8
Training loss: 2.3057303428649902
Validation loss: 2.3629668851693473

Epoch: 5| Step: 9
Training loss: 2.1766841411590576
Validation loss: 2.360390563805898

Epoch: 5| Step: 10
Training loss: 2.952096462249756
Validation loss: 2.357951561609904

Epoch: 5| Step: 11
Training loss: 2.7285094261169434
Validation loss: 2.3557340502738953

Epoch: 59| Step: 0
Training loss: 2.272264003753662
Validation loss: 2.3537967056035995

Epoch: 5| Step: 1
Training loss: 2.308816432952881
Validation loss: 2.3538404752810798

Epoch: 5| Step: 2
Training loss: 2.4937968254089355
Validation loss: 2.3506573836008706

Epoch: 5| Step: 3
Training loss: 2.8458423614501953
Validation loss: 2.3491418659687042

Epoch: 5| Step: 4
Training loss: 2.7053935527801514
Validation loss: 2.348547657330831

Epoch: 5| Step: 5
Training loss: 2.9312803745269775
Validation loss: 2.34863872329394

Epoch: 5| Step: 6
Training loss: 2.808183193206787
Validation loss: 2.344004765152931

Epoch: 5| Step: 7
Training loss: 2.110579013824463
Validation loss: 2.3406380861997604

Epoch: 5| Step: 8
Training loss: 1.8391780853271484
Validation loss: 2.3363793889681497

Epoch: 5| Step: 9
Training loss: 2.6804325580596924
Validation loss: 2.333993782599767

Epoch: 5| Step: 10
Training loss: 2.749518394470215
Validation loss: 2.330741966764132

Epoch: 5| Step: 11
Training loss: 2.5342445373535156
Validation loss: 2.3293180068333945

Epoch: 60| Step: 0
Training loss: 2.317002534866333
Validation loss: 2.3261445462703705

Epoch: 5| Step: 1
Training loss: 3.1617038249969482
Validation loss: 2.3186572194099426

Epoch: 5| Step: 2
Training loss: 2.4105336666107178
Validation loss: 2.3189733227094016

Epoch: 5| Step: 3
Training loss: 2.326249599456787
Validation loss: 2.3179555435975394

Epoch: 5| Step: 4
Training loss: 2.9756360054016113
Validation loss: 2.313963532447815

Epoch: 5| Step: 5
Training loss: 2.032881259918213
Validation loss: 2.3118943174680076

Epoch: 5| Step: 6
Training loss: 2.553419828414917
Validation loss: 2.30850816766421

Epoch: 5| Step: 7
Training loss: 2.8388400077819824
Validation loss: 2.3090804616610208

Epoch: 5| Step: 8
Training loss: 2.3260021209716797
Validation loss: 2.307653099298477

Epoch: 5| Step: 9
Training loss: 2.0746283531188965
Validation loss: 2.3051328559716544

Epoch: 5| Step: 10
Training loss: 2.309731960296631
Validation loss: 2.3027277688185372

Epoch: 5| Step: 11
Training loss: 2.7697107791900635
Validation loss: 2.2984028259913125

Epoch: 61| Step: 0
Training loss: 2.683673858642578
Validation loss: 2.2953968743483224

Epoch: 5| Step: 1
Training loss: 1.9027656316757202
Validation loss: 2.292388101418813

Epoch: 5| Step: 2
Training loss: 2.7411835193634033
Validation loss: 2.291601707537969

Epoch: 5| Step: 3
Training loss: 2.383249282836914
Validation loss: 2.289717117945353

Epoch: 5| Step: 4
Training loss: 2.7959694862365723
Validation loss: 2.286945015192032

Epoch: 5| Step: 5
Training loss: 2.3794636726379395
Validation loss: 2.283011734485626

Epoch: 5| Step: 6
Training loss: 2.669628143310547
Validation loss: 2.28062770764033

Epoch: 5| Step: 7
Training loss: 1.8866679668426514
Validation loss: 2.2801943719387054

Epoch: 5| Step: 8
Training loss: 2.246241569519043
Validation loss: 2.279854620496432

Epoch: 5| Step: 9
Training loss: 2.7221832275390625
Validation loss: 2.2764208714167276

Epoch: 5| Step: 10
Training loss: 2.6750922203063965
Validation loss: 2.2741688241561255

Epoch: 5| Step: 11
Training loss: 2.1677803993225098
Validation loss: 2.2715935359398522

Epoch: 62| Step: 0
Training loss: 2.8475911617279053
Validation loss: 2.2688001145919166

Epoch: 5| Step: 1
Training loss: 2.2338356971740723
Validation loss: 2.2624636193116507

Epoch: 5| Step: 2
Training loss: 2.9825077056884766
Validation loss: 2.2638632704814277

Epoch: 5| Step: 3
Training loss: 2.0807883739471436
Validation loss: 2.262598007917404

Epoch: 5| Step: 4
Training loss: 2.4358363151550293
Validation loss: 2.2619607945283255

Epoch: 5| Step: 5
Training loss: 2.194976329803467
Validation loss: 2.258043492833773

Epoch: 5| Step: 6
Training loss: 2.0078999996185303
Validation loss: 2.2548287212848663

Epoch: 5| Step: 7
Training loss: 2.7887935638427734
Validation loss: 2.2507977386315665

Epoch: 5| Step: 8
Training loss: 2.5936100482940674
Validation loss: 2.256872226794561

Epoch: 5| Step: 9
Training loss: 2.312840700149536
Validation loss: 2.2599636912345886

Epoch: 5| Step: 10
Training loss: 2.0788795948028564
Validation loss: 2.2571895718574524

Epoch: 5| Step: 11
Training loss: 2.8701391220092773
Validation loss: 2.2438407788674035

Epoch: 63| Step: 0
Training loss: 2.3087260723114014
Validation loss: 2.2404437164465585

Epoch: 5| Step: 1
Training loss: 3.0025715827941895
Validation loss: 2.2401171823342643

Epoch: 5| Step: 2
Training loss: 2.2954113483428955
Validation loss: 2.2363145450750985

Epoch: 5| Step: 3
Training loss: 2.0431606769561768
Validation loss: 2.237605477372805

Epoch: 5| Step: 4
Training loss: 2.2454676628112793
Validation loss: 2.246775135397911

Epoch: 5| Step: 5
Training loss: 2.775179624557495
Validation loss: 2.2510449588298798

Epoch: 5| Step: 6
Training loss: 2.6274189949035645
Validation loss: 2.256376415491104

Epoch: 5| Step: 7
Training loss: 2.3336381912231445
Validation loss: 2.240699271361033

Epoch: 5| Step: 8
Training loss: 2.3212122917175293
Validation loss: 2.230583429336548

Epoch: 5| Step: 9
Training loss: 2.3213248252868652
Validation loss: 2.2183527102073035

Epoch: 5| Step: 10
Training loss: 1.9731073379516602
Validation loss: 2.217099209626516

Epoch: 5| Step: 11
Training loss: 2.908116340637207
Validation loss: 2.2154420912265778

Epoch: 64| Step: 0
Training loss: 2.6787266731262207
Validation loss: 2.208996673425039

Epoch: 5| Step: 1
Training loss: 2.4106991291046143
Validation loss: 2.2009838223457336

Epoch: 5| Step: 2
Training loss: 1.957440972328186
Validation loss: 2.198954035838445

Epoch: 5| Step: 3
Training loss: 2.51037335395813
Validation loss: 2.195388356844584

Epoch: 5| Step: 4
Training loss: 1.9509608745574951
Validation loss: 2.193493520220121

Epoch: 5| Step: 5
Training loss: 1.9053592681884766
Validation loss: 2.1892447570959725

Epoch: 5| Step: 6
Training loss: 2.5452499389648438
Validation loss: 2.190676212310791

Epoch: 5| Step: 7
Training loss: 2.5559134483337402
Validation loss: 2.187117099761963

Epoch: 5| Step: 8
Training loss: 2.3545069694519043
Validation loss: 2.18979349732399

Epoch: 5| Step: 9
Training loss: 2.3249356746673584
Validation loss: 2.184957911570867

Epoch: 5| Step: 10
Training loss: 2.8025240898132324
Validation loss: 2.1789632191260657

Epoch: 5| Step: 11
Training loss: 1.4624818563461304
Validation loss: 2.174589862426122

Epoch: 65| Step: 0
Training loss: 3.1888198852539062
Validation loss: 2.1759518484274545

Epoch: 5| Step: 1
Training loss: 2.0920252799987793
Validation loss: 2.1713792979717255

Epoch: 5| Step: 2
Training loss: 2.261629343032837
Validation loss: 2.167178069551786

Epoch: 5| Step: 3
Training loss: 2.3883800506591797
Validation loss: 2.168551723162333

Epoch: 5| Step: 4
Training loss: 1.991829514503479
Validation loss: 2.1657678931951523

Epoch: 5| Step: 5
Training loss: 2.575106143951416
Validation loss: 2.1654858191808066

Epoch: 5| Step: 6
Training loss: 2.3167755603790283
Validation loss: 2.16374334692955

Epoch: 5| Step: 7
Training loss: 2.512258768081665
Validation loss: 2.1590830832719803

Epoch: 5| Step: 8
Training loss: 2.396942138671875
Validation loss: 2.163763572772344

Epoch: 5| Step: 9
Training loss: 2.5852723121643066
Validation loss: 2.164675533771515

Epoch: 5| Step: 10
Training loss: 1.354640245437622
Validation loss: 2.1613773008187613

Epoch: 5| Step: 11
Training loss: 2.018986940383911
Validation loss: 2.1594543059666953

Epoch: 66| Step: 0
Training loss: 2.266333818435669
Validation loss: 2.158132940530777

Epoch: 5| Step: 1
Training loss: 2.355395793914795
Validation loss: 2.1570997635523477

Epoch: 5| Step: 2
Training loss: 1.8670676946640015
Validation loss: 2.1583843926588693

Epoch: 5| Step: 3
Training loss: 2.495310068130493
Validation loss: 2.157146468758583

Epoch: 5| Step: 4
Training loss: 2.4171805381774902
Validation loss: 2.154457817475001

Epoch: 5| Step: 5
Training loss: 1.978939414024353
Validation loss: 2.1469595779975257

Epoch: 5| Step: 6
Training loss: 2.366894245147705
Validation loss: 2.151645908753077

Epoch: 5| Step: 7
Training loss: 3.012488603591919
Validation loss: 2.1468866964181266

Epoch: 5| Step: 8
Training loss: 2.1687495708465576
Validation loss: 2.1461352507273355

Epoch: 5| Step: 9
Training loss: 2.247584819793701
Validation loss: 2.1468619406223297

Epoch: 5| Step: 10
Training loss: 2.3815221786499023
Validation loss: 2.1456482460101447

Epoch: 5| Step: 11
Training loss: 1.6336268186569214
Validation loss: 2.1469550927480063

Epoch: 67| Step: 0
Training loss: 2.9296557903289795
Validation loss: 2.1484783391157785

Epoch: 5| Step: 1
Training loss: 2.2427830696105957
Validation loss: 2.1511850456396737

Epoch: 5| Step: 2
Training loss: 2.138122081756592
Validation loss: 2.1514305075009665

Epoch: 5| Step: 3
Training loss: 2.3671669960021973
Validation loss: 2.151492272814115

Epoch: 5| Step: 4
Training loss: 2.593679666519165
Validation loss: 2.145576943953832

Epoch: 5| Step: 5
Training loss: 2.0420992374420166
Validation loss: 2.140779137611389

Epoch: 5| Step: 6
Training loss: 2.187375068664551
Validation loss: 2.1349274714787803

Epoch: 5| Step: 7
Training loss: 2.770375967025757
Validation loss: 2.1354452669620514

Epoch: 5| Step: 8
Training loss: 1.7423473596572876
Validation loss: 2.129236325621605

Epoch: 5| Step: 9
Training loss: 2.0301332473754883
Validation loss: 2.125639130671819

Epoch: 5| Step: 10
Training loss: 2.3086256980895996
Validation loss: 2.1254273504018784

Epoch: 5| Step: 11
Training loss: 2.188723564147949
Validation loss: 2.13148196041584

Epoch: 68| Step: 0
Training loss: 1.7625901699066162
Validation loss: 2.119240696231524

Epoch: 5| Step: 1
Training loss: 2.1874406337738037
Validation loss: 2.1222815910975137

Epoch: 5| Step: 2
Training loss: 1.9424703121185303
Validation loss: 2.1249323735634484

Epoch: 5| Step: 3
Training loss: 2.6277682781219482
Validation loss: 2.1273840069770813

Epoch: 5| Step: 4
Training loss: 2.8195552825927734
Validation loss: 2.1241181989510856

Epoch: 5| Step: 5
Training loss: 1.9344050884246826
Validation loss: 2.125820204615593

Epoch: 5| Step: 6
Training loss: 2.1353001594543457
Validation loss: 2.1267607311407724

Epoch: 5| Step: 7
Training loss: 2.6362037658691406
Validation loss: 2.1243259807427726

Epoch: 5| Step: 8
Training loss: 2.657881498336792
Validation loss: 2.127129783233007

Epoch: 5| Step: 9
Training loss: 2.018641948699951
Validation loss: 2.123782694339752

Epoch: 5| Step: 10
Training loss: 2.4449920654296875
Validation loss: 2.122958098848661

Epoch: 5| Step: 11
Training loss: 1.9666205644607544
Validation loss: 2.118195121486982

Epoch: 69| Step: 0
Training loss: 2.3212838172912598
Validation loss: 2.119078462322553

Epoch: 5| Step: 1
Training loss: 1.9056484699249268
Validation loss: 2.1173907617727914

Epoch: 5| Step: 2
Training loss: 2.137948513031006
Validation loss: 2.1155413488547006

Epoch: 5| Step: 3
Training loss: 2.5952861309051514
Validation loss: 2.1144166191418967

Epoch: 5| Step: 4
Training loss: 1.7278516292572021
Validation loss: 2.1129349122444787

Epoch: 5| Step: 5
Training loss: 2.402113437652588
Validation loss: 2.11533730228742

Epoch: 5| Step: 6
Training loss: 2.202786922454834
Validation loss: 2.1061168909072876

Epoch: 5| Step: 7
Training loss: 2.3602657318115234
Validation loss: 2.107109780112902

Epoch: 5| Step: 8
Training loss: 2.4738948345184326
Validation loss: 2.109839990735054

Epoch: 5| Step: 9
Training loss: 2.845754861831665
Validation loss: 2.11658568183581

Epoch: 5| Step: 10
Training loss: 2.095618724822998
Validation loss: 2.1080386439959207

Epoch: 5| Step: 11
Training loss: 2.164456844329834
Validation loss: 2.10541632771492

Epoch: 70| Step: 0
Training loss: 2.291480541229248
Validation loss: 2.0970179388920465

Epoch: 5| Step: 1
Training loss: 2.746211528778076
Validation loss: 2.104366660118103

Epoch: 5| Step: 2
Training loss: 2.693446397781372
Validation loss: 2.1121436109145484

Epoch: 5| Step: 3
Training loss: 2.5947000980377197
Validation loss: 2.10890727241834

Epoch: 5| Step: 4
Training loss: 2.0760738849639893
Validation loss: 2.103955179452896

Epoch: 5| Step: 5
Training loss: 2.0297837257385254
Validation loss: 2.1012934843699136

Epoch: 5| Step: 6
Training loss: 1.8727220296859741
Validation loss: 2.101159711678823

Epoch: 5| Step: 7
Training loss: 2.3847289085388184
Validation loss: 2.0988363126913705

Epoch: 5| Step: 8
Training loss: 1.499090552330017
Validation loss: 2.1009433517853418

Epoch: 5| Step: 9
Training loss: 2.2852046489715576
Validation loss: 2.1079573233922324

Epoch: 5| Step: 10
Training loss: 2.472072124481201
Validation loss: 2.1084868957599006

Epoch: 5| Step: 11
Training loss: 2.159581422805786
Validation loss: 2.1140382985273996

Epoch: 71| Step: 0
Training loss: 2.6264591217041016
Validation loss: 2.1111666162808738

Epoch: 5| Step: 1
Training loss: 2.1051597595214844
Validation loss: 2.1121680438518524

Epoch: 5| Step: 2
Training loss: 2.1148624420166016
Validation loss: 2.118831848104795

Epoch: 5| Step: 3
Training loss: 2.362031936645508
Validation loss: 2.11818598707517

Epoch: 5| Step: 4
Training loss: 2.617642879486084
Validation loss: 2.1202826847632728

Epoch: 5| Step: 5
Training loss: 2.197303295135498
Validation loss: 2.106827055414518

Epoch: 5| Step: 6
Training loss: 2.1836822032928467
Validation loss: 2.102544585863749

Epoch: 5| Step: 7
Training loss: 2.689988613128662
Validation loss: 2.10135584572951

Epoch: 5| Step: 8
Training loss: 2.2994229793548584
Validation loss: 2.099193995197614

Epoch: 5| Step: 9
Training loss: 1.9235090017318726
Validation loss: 2.0934373637040458

Epoch: 5| Step: 10
Training loss: 1.588524580001831
Validation loss: 2.0932602087656655

Epoch: 5| Step: 11
Training loss: 3.489819049835205
Validation loss: 2.0852422962586084

Epoch: 72| Step: 0
Training loss: 2.280954360961914
Validation loss: 2.080692008137703

Epoch: 5| Step: 1
Training loss: 1.9536157846450806
Validation loss: 2.0787944346666336

Epoch: 5| Step: 2
Training loss: 2.059709072113037
Validation loss: 2.077552691102028

Epoch: 5| Step: 3
Training loss: 2.7761123180389404
Validation loss: 2.088539724548658

Epoch: 5| Step: 4
Training loss: 2.3382365703582764
Validation loss: 2.0779896179835

Epoch: 5| Step: 5
Training loss: 1.7135385274887085
Validation loss: 2.0816746155420938

Epoch: 5| Step: 6
Training loss: 2.8983771800994873
Validation loss: 2.0782777667045593

Epoch: 5| Step: 7
Training loss: 2.6794850826263428
Validation loss: 2.0807572454214096

Epoch: 5| Step: 8
Training loss: 2.1047003269195557
Validation loss: 2.0822165310382843

Epoch: 5| Step: 9
Training loss: 1.7010740041732788
Validation loss: 2.080847457051277

Epoch: 5| Step: 10
Training loss: 2.624274730682373
Validation loss: 2.0714725901683173

Epoch: 5| Step: 11
Training loss: 0.7652068734169006
Validation loss: 2.07440455754598

Epoch: 73| Step: 0
Training loss: 2.245464324951172
Validation loss: 2.071397284666697

Epoch: 5| Step: 1
Training loss: 2.22172212600708
Validation loss: 2.0704956551392875

Epoch: 5| Step: 2
Training loss: 1.9980303049087524
Validation loss: 2.0682899057865143

Epoch: 5| Step: 3
Training loss: 2.3236188888549805
Validation loss: 2.072518194715182

Epoch: 5| Step: 4
Training loss: 2.332212448120117
Validation loss: 2.066303556164106

Epoch: 5| Step: 5
Training loss: 2.343214988708496
Validation loss: 2.0693023105462394

Epoch: 5| Step: 6
Training loss: 2.1811745166778564
Validation loss: 2.0672075053056083

Epoch: 5| Step: 7
Training loss: 2.149524211883545
Validation loss: 2.0587356140216193

Epoch: 5| Step: 8
Training loss: 2.360273599624634
Validation loss: 2.063857992490133

Epoch: 5| Step: 9
Training loss: 1.9968960285186768
Validation loss: 2.0607782304286957

Epoch: 5| Step: 10
Training loss: 2.415395736694336
Validation loss: 2.059060345093409

Epoch: 5| Step: 11
Training loss: 2.880330801010132
Validation loss: 2.064949577053388

Epoch: 74| Step: 0
Training loss: 2.216233015060425
Validation loss: 2.0581241846084595

Epoch: 5| Step: 1
Training loss: 2.0013725757598877
Validation loss: 2.0572479963302612

Epoch: 5| Step: 2
Training loss: 2.2032086849212646
Validation loss: 2.054456581672033

Epoch: 5| Step: 3
Training loss: 2.6039376258850098
Validation loss: 2.0636113981405892

Epoch: 5| Step: 4
Training loss: 2.350268602371216
Validation loss: 2.060680309931437

Epoch: 5| Step: 5
Training loss: 2.36553955078125
Validation loss: 2.055482268333435

Epoch: 5| Step: 6
Training loss: 2.212895154953003
Validation loss: 2.0535345524549484

Epoch: 5| Step: 7
Training loss: 2.0606486797332764
Validation loss: 2.055873210231463

Epoch: 5| Step: 8
Training loss: 2.0695436000823975
Validation loss: 2.056461046139399

Epoch: 5| Step: 9
Training loss: 2.173483371734619
Validation loss: 2.058458616336187

Epoch: 5| Step: 10
Training loss: 2.222853183746338
Validation loss: 2.0585788687070212

Epoch: 5| Step: 11
Training loss: 2.5676774978637695
Validation loss: 2.0581563661495843

Epoch: 75| Step: 0
Training loss: 2.046299695968628
Validation loss: 2.0743395537137985

Epoch: 5| Step: 1
Training loss: 2.48172664642334
Validation loss: 2.0754683862129846

Epoch: 5| Step: 2
Training loss: 2.125256299972534
Validation loss: 2.0820732911427817

Epoch: 5| Step: 3
Training loss: 2.371863842010498
Validation loss: 2.083110978205999

Epoch: 5| Step: 4
Training loss: 2.703028917312622
Validation loss: 2.0830122033754983

Epoch: 5| Step: 5
Training loss: 2.2640151977539062
Validation loss: 2.0795383155345917

Epoch: 5| Step: 6
Training loss: 2.627776861190796
Validation loss: 2.075558746854464

Epoch: 5| Step: 7
Training loss: 1.7523679733276367
Validation loss: 2.0730069677035012

Epoch: 5| Step: 8
Training loss: 2.2266769409179688
Validation loss: 2.074107105533282

Epoch: 5| Step: 9
Training loss: 2.3775887489318848
Validation loss: 2.0672850410143533

Epoch: 5| Step: 10
Training loss: 1.9044736623764038
Validation loss: 2.07946669558684

Epoch: 5| Step: 11
Training loss: 0.7625244855880737
Validation loss: 2.082034945487976

Epoch: 76| Step: 0
Training loss: 1.9206689596176147
Validation loss: 2.094036743044853

Epoch: 5| Step: 1
Training loss: 2.100821018218994
Validation loss: 2.096545070409775

Epoch: 5| Step: 2
Training loss: 2.5351638793945312
Validation loss: 2.09435573220253

Epoch: 5| Step: 3
Training loss: 1.9225845336914062
Validation loss: 2.0821820745865502

Epoch: 5| Step: 4
Training loss: 2.2326197624206543
Validation loss: 2.08165580034256

Epoch: 5| Step: 5
Training loss: 2.585374355316162
Validation loss: 2.073586796720823

Epoch: 5| Step: 6
Training loss: 2.4435129165649414
Validation loss: 2.076467593510946

Epoch: 5| Step: 7
Training loss: 2.270585060119629
Validation loss: 2.072595849633217

Epoch: 5| Step: 8
Training loss: 2.6776745319366455
Validation loss: 2.0731241007645926

Epoch: 5| Step: 9
Training loss: 2.244563579559326
Validation loss: 2.064170698324839

Epoch: 5| Step: 10
Training loss: 1.9401744604110718
Validation loss: 2.0661960591872535

Epoch: 5| Step: 11
Training loss: 1.8346015214920044
Validation loss: 2.055981238683065

Epoch: 77| Step: 0
Training loss: 2.331209421157837
Validation loss: 2.056894838809967

Epoch: 5| Step: 1
Training loss: 2.5312752723693848
Validation loss: 2.0560166438420615

Epoch: 5| Step: 2
Training loss: 2.3003087043762207
Validation loss: 2.0563468088706336

Epoch: 5| Step: 3
Training loss: 2.610705852508545
Validation loss: 2.0528806348641715

Epoch: 5| Step: 4
Training loss: 1.805983543395996
Validation loss: 2.050495927532514

Epoch: 5| Step: 5
Training loss: 2.2371997833251953
Validation loss: 2.0491558412710824

Epoch: 5| Step: 6
Training loss: 2.347898006439209
Validation loss: 2.0502417981624603

Epoch: 5| Step: 7
Training loss: 1.8860887289047241
Validation loss: 2.045599619547526

Epoch: 5| Step: 8
Training loss: 2.2431933879852295
Validation loss: 2.042072390516599

Epoch: 5| Step: 9
Training loss: 2.049436569213867
Validation loss: 2.042550136645635

Epoch: 5| Step: 10
Training loss: 2.1095499992370605
Validation loss: 2.0391807556152344

Epoch: 5| Step: 11
Training loss: 1.994472622871399
Validation loss: 2.039191355307897

Epoch: 78| Step: 0
Training loss: 2.150175094604492
Validation loss: 2.0310223003228507

Epoch: 5| Step: 1
Training loss: 2.3360581398010254
Validation loss: 2.0336669037739434

Epoch: 5| Step: 2
Training loss: 2.4388513565063477
Validation loss: 2.0381040374437966

Epoch: 5| Step: 3
Training loss: 2.198099374771118
Validation loss: 2.0410388857126236

Epoch: 5| Step: 4
Training loss: 1.991125464439392
Validation loss: 2.0397585183382034

Epoch: 5| Step: 5
Training loss: 2.212937593460083
Validation loss: 2.04106634358565

Epoch: 5| Step: 6
Training loss: 2.020704984664917
Validation loss: 2.0333517491817474

Epoch: 5| Step: 7
Training loss: 2.219393730163574
Validation loss: 2.03996749718984

Epoch: 5| Step: 8
Training loss: 2.106102228164673
Validation loss: 2.044435977935791

Epoch: 5| Step: 9
Training loss: 2.6194047927856445
Validation loss: 2.037841409444809

Epoch: 5| Step: 10
Training loss: 2.1893398761749268
Validation loss: 2.0463650276263556

Epoch: 5| Step: 11
Training loss: 1.9763869047164917
Validation loss: 2.039442310730616

Epoch: 79| Step: 0
Training loss: 2.38350772857666
Validation loss: 2.0409983545541763

Epoch: 5| Step: 1
Training loss: 2.093599796295166
Validation loss: 2.0400836865107217

Epoch: 5| Step: 2
Training loss: 2.3618721961975098
Validation loss: 2.0367050965627036

Epoch: 5| Step: 3
Training loss: 2.290302038192749
Validation loss: 2.036969463030497

Epoch: 5| Step: 4
Training loss: 2.1572988033294678
Validation loss: 2.0349124570687613

Epoch: 5| Step: 5
Training loss: 2.232840061187744
Validation loss: 2.033035750190417

Epoch: 5| Step: 6
Training loss: 2.741368055343628
Validation loss: 2.025527209043503

Epoch: 5| Step: 7
Training loss: 2.3913333415985107
Validation loss: 2.026342496275902

Epoch: 5| Step: 8
Training loss: 2.0796637535095215
Validation loss: 2.035930171608925

Epoch: 5| Step: 9
Training loss: 1.7266849279403687
Validation loss: 2.0349032084147134

Epoch: 5| Step: 10
Training loss: 1.910589575767517
Validation loss: 2.047188028693199

Epoch: 5| Step: 11
Training loss: 2.3319644927978516
Validation loss: 2.0493130683898926

Epoch: 80| Step: 0
Training loss: 2.361487627029419
Validation loss: 2.049379140138626

Epoch: 5| Step: 1
Training loss: 2.2821059226989746
Validation loss: 2.046257863442103

Epoch: 5| Step: 2
Training loss: 1.9110591411590576
Validation loss: 2.0380704204241433

Epoch: 5| Step: 3
Training loss: 1.8878705501556396
Validation loss: 2.035536135236422

Epoch: 5| Step: 4
Training loss: 1.8389787673950195
Validation loss: 2.034107133746147

Epoch: 5| Step: 5
Training loss: 2.881338119506836
Validation loss: 2.035473957657814

Epoch: 5| Step: 6
Training loss: 2.211463451385498
Validation loss: 2.0320288191239038

Epoch: 5| Step: 7
Training loss: 2.223405599594116
Validation loss: 2.0328222066164017

Epoch: 5| Step: 8
Training loss: 2.2280094623565674
Validation loss: 2.0266439815362296

Epoch: 5| Step: 9
Training loss: 1.827082872390747
Validation loss: 2.0274124294519424

Epoch: 5| Step: 10
Training loss: 2.185673952102661
Validation loss: 2.032525966564814

Epoch: 5| Step: 11
Training loss: 3.9941086769104004
Validation loss: 2.0329808493455253

Epoch: 81| Step: 0
Training loss: 2.1356613636016846
Validation loss: 2.0248139649629593

Epoch: 5| Step: 1
Training loss: 2.1194138526916504
Validation loss: 2.02653561035792

Epoch: 5| Step: 2
Training loss: 2.077847480773926
Validation loss: 2.024850989381472

Epoch: 5| Step: 3
Training loss: 1.9995708465576172
Validation loss: 2.027520706256231

Epoch: 5| Step: 4
Training loss: 2.783449649810791
Validation loss: 2.0208997825781503

Epoch: 5| Step: 5
Training loss: 1.984231948852539
Validation loss: 2.025837312142054

Epoch: 5| Step: 6
Training loss: 2.488086700439453
Validation loss: 2.0296851446231208

Epoch: 5| Step: 7
Training loss: 2.027434825897217
Validation loss: 2.036674439907074

Epoch: 5| Step: 8
Training loss: 2.6701385974884033
Validation loss: 2.0394363602002463

Epoch: 5| Step: 9
Training loss: 2.3352103233337402
Validation loss: 2.0400957564512887

Epoch: 5| Step: 10
Training loss: 1.5760587453842163
Validation loss: 2.0332921793063483

Epoch: 5| Step: 11
Training loss: 2.0458133220672607
Validation loss: 2.02929979066054

Epoch: 82| Step: 0
Training loss: 1.9739259481430054
Validation loss: 2.026435618599256

Epoch: 5| Step: 1
Training loss: 2.1073737144470215
Validation loss: 2.032394617795944

Epoch: 5| Step: 2
Training loss: 2.5373027324676514
Validation loss: 2.031441460053126

Epoch: 5| Step: 3
Training loss: 2.5718181133270264
Validation loss: 2.0324934224287667

Epoch: 5| Step: 4
Training loss: 2.315654754638672
Validation loss: 2.032114545504252

Epoch: 5| Step: 5
Training loss: 1.6542530059814453
Validation loss: 2.03015465537707

Epoch: 5| Step: 6
Training loss: 2.585477352142334
Validation loss: 2.0364504208167395

Epoch: 5| Step: 7
Training loss: 2.0097689628601074
Validation loss: 2.0324900299310684

Epoch: 5| Step: 8
Training loss: 2.2852277755737305
Validation loss: 2.0336901346842446

Epoch: 5| Step: 9
Training loss: 2.3267996311187744
Validation loss: 2.031749869386355

Epoch: 5| Step: 10
Training loss: 1.9089128971099854
Validation loss: 2.0291834572950997

Epoch: 5| Step: 11
Training loss: 1.5269277095794678
Validation loss: 2.02277938524882

Epoch: 83| Step: 0
Training loss: 2.3752505779266357
Validation loss: 2.0166473438342414

Epoch: 5| Step: 1
Training loss: 2.167299270629883
Validation loss: 2.0212953438361487

Epoch: 5| Step: 2
Training loss: 2.025702714920044
Validation loss: 2.023474633693695

Epoch: 5| Step: 3
Training loss: 2.2039504051208496
Validation loss: 2.020410637060801

Epoch: 5| Step: 4
Training loss: 2.037177801132202
Validation loss: 2.0193957885106406

Epoch: 5| Step: 5
Training loss: 2.3500967025756836
Validation loss: 2.0199440916379294

Epoch: 5| Step: 6
Training loss: 1.561062216758728
Validation loss: 2.0165480424960456

Epoch: 5| Step: 7
Training loss: 2.2759857177734375
Validation loss: 2.0166702518860498

Epoch: 5| Step: 8
Training loss: 2.804877281188965
Validation loss: 2.024884879589081

Epoch: 5| Step: 9
Training loss: 2.2029531002044678
Validation loss: 2.0262112567822137

Epoch: 5| Step: 10
Training loss: 1.9831018447875977
Validation loss: 2.024746134877205

Epoch: 5| Step: 11
Training loss: 2.2918436527252197
Validation loss: 2.031666283806165

Epoch: 84| Step: 0
Training loss: 2.5736923217773438
Validation loss: 2.023591637611389

Epoch: 5| Step: 1
Training loss: 1.8202102184295654
Validation loss: 2.017724225918452

Epoch: 5| Step: 2
Training loss: 2.6240415573120117
Validation loss: 2.0193918695052466

Epoch: 5| Step: 3
Training loss: 2.514430522918701
Validation loss: 2.0245669186115265

Epoch: 5| Step: 4
Training loss: 1.579083800315857
Validation loss: 2.019084334373474

Epoch: 5| Step: 5
Training loss: 2.118165969848633
Validation loss: 2.0267864763736725

Epoch: 5| Step: 6
Training loss: 2.452808380126953
Validation loss: 2.0286067773898444

Epoch: 5| Step: 7
Training loss: 2.7099900245666504
Validation loss: 2.0253952691952386

Epoch: 5| Step: 8
Training loss: 1.718244194984436
Validation loss: 2.030570685863495

Epoch: 5| Step: 9
Training loss: 2.104330062866211
Validation loss: 2.0327305446068444

Epoch: 5| Step: 10
Training loss: 1.678788185119629
Validation loss: 2.029157136877378

Epoch: 5| Step: 11
Training loss: 2.0503318309783936
Validation loss: 2.043174390991529

Epoch: 85| Step: 0
Training loss: 2.252180576324463
Validation loss: 2.0354392379522324

Epoch: 5| Step: 1
Training loss: 1.6239312887191772
Validation loss: 2.039224694172541

Epoch: 5| Step: 2
Training loss: 2.284180164337158
Validation loss: 2.0504982322454453

Epoch: 5| Step: 3
Training loss: 2.5168185234069824
Validation loss: 2.0562492410341897

Epoch: 5| Step: 4
Training loss: 2.6796607971191406
Validation loss: 2.0566863119602203

Epoch: 5| Step: 5
Training loss: 2.1278023719787598
Validation loss: 2.054024040699005

Epoch: 5| Step: 6
Training loss: 1.9782884120941162
Validation loss: 2.042346845070521

Epoch: 5| Step: 7
Training loss: 2.339392900466919
Validation loss: 2.0362576792637506

Epoch: 5| Step: 8
Training loss: 1.7366292476654053
Validation loss: 2.0343795269727707

Epoch: 5| Step: 9
Training loss: 2.059135675430298
Validation loss: 2.029171576102575

Epoch: 5| Step: 10
Training loss: 2.390517473220825
Validation loss: 2.034163847565651

Epoch: 5| Step: 11
Training loss: 2.085235118865967
Validation loss: 2.0274861603975296

Epoch: 86| Step: 0
Training loss: 2.7302799224853516
Validation loss: 2.0261446287234626

Epoch: 5| Step: 1
Training loss: 2.0896406173706055
Validation loss: 2.0451262493928275

Epoch: 5| Step: 2
Training loss: 2.154947280883789
Validation loss: 2.035377641518911

Epoch: 5| Step: 3
Training loss: 2.3509907722473145
Validation loss: 2.0431064665317535

Epoch: 5| Step: 4
Training loss: 2.4612948894500732
Validation loss: 2.047059083978335

Epoch: 5| Step: 5
Training loss: 2.08038592338562
Validation loss: 2.0511469741662345

Epoch: 5| Step: 6
Training loss: 1.908341407775879
Validation loss: 2.0530685434738793

Epoch: 5| Step: 7
Training loss: 2.367448568344116
Validation loss: 2.0551023284594216

Epoch: 5| Step: 8
Training loss: 1.9513546228408813
Validation loss: 2.053921485940615

Epoch: 5| Step: 9
Training loss: 2.039411783218384
Validation loss: 2.0486044635375342

Epoch: 5| Step: 10
Training loss: 2.281345844268799
Validation loss: 2.0489034901062646

Epoch: 5| Step: 11
Training loss: 2.233543634414673
Validation loss: 2.0368479192256927

Epoch: 87| Step: 0
Training loss: 2.6687495708465576
Validation loss: 2.03440693517526

Epoch: 5| Step: 1
Training loss: 2.1216342449188232
Validation loss: 2.032940685749054

Epoch: 5| Step: 2
Training loss: 2.343350410461426
Validation loss: 2.0314783453941345

Epoch: 5| Step: 3
Training loss: 1.5604273080825806
Validation loss: 2.0234496146440506

Epoch: 5| Step: 4
Training loss: 2.406013011932373
Validation loss: 2.0217864414056144

Epoch: 5| Step: 5
Training loss: 2.1739554405212402
Validation loss: 2.023571645220121

Epoch: 5| Step: 6
Training loss: 2.4492714405059814
Validation loss: 2.027815187970797

Epoch: 5| Step: 7
Training loss: 1.9749670028686523
Validation loss: 2.018670236070951

Epoch: 5| Step: 8
Training loss: 1.7894115447998047
Validation loss: 2.019569605588913

Epoch: 5| Step: 9
Training loss: 2.44525146484375
Validation loss: 2.023855244119962

Epoch: 5| Step: 10
Training loss: 2.4183993339538574
Validation loss: 2.029100557168325

Epoch: 5| Step: 11
Training loss: 1.3868579864501953
Validation loss: 2.0319906175136566

Epoch: 88| Step: 0
Training loss: 2.885213613510132
Validation loss: 2.0310343702634177

Epoch: 5| Step: 1
Training loss: 2.0940701961517334
Validation loss: 2.0286662379900613

Epoch: 5| Step: 2
Training loss: 1.9812633991241455
Validation loss: 2.0228066196044288

Epoch: 5| Step: 3
Training loss: 1.9150737524032593
Validation loss: 2.013751635948817

Epoch: 5| Step: 4
Training loss: 2.2404654026031494
Validation loss: 2.020833263794581

Epoch: 5| Step: 5
Training loss: 1.8795661926269531
Validation loss: 2.0175642172495523

Epoch: 5| Step: 6
Training loss: 1.8086655139923096
Validation loss: 2.0140274862448373

Epoch: 5| Step: 7
Training loss: 1.9518563747406006
Validation loss: 2.02127406001091

Epoch: 5| Step: 8
Training loss: 2.8618996143341064
Validation loss: 2.0128774444262185

Epoch: 5| Step: 9
Training loss: 1.9700168371200562
Validation loss: 2.0188654313484826

Epoch: 5| Step: 10
Training loss: 2.2551109790802
Validation loss: 2.019857948025068

Epoch: 5| Step: 11
Training loss: 2.9171876907348633
Validation loss: 2.019304300347964

Epoch: 89| Step: 0
Training loss: 2.056485652923584
Validation loss: 2.0203102827072144

Epoch: 5| Step: 1
Training loss: 1.5492992401123047
Validation loss: 2.0416701634724936

Epoch: 5| Step: 2
Training loss: 1.7254676818847656
Validation loss: 2.058376297354698

Epoch: 5| Step: 3
Training loss: 2.2515130043029785
Validation loss: 2.0740246077378592

Epoch: 5| Step: 4
Training loss: 3.0025248527526855
Validation loss: 2.0994562606016793

Epoch: 5| Step: 5
Training loss: 2.8568360805511475
Validation loss: 2.1054917027552924

Epoch: 5| Step: 6
Training loss: 2.3220107555389404
Validation loss: 2.102715482314428

Epoch: 5| Step: 7
Training loss: 2.207976818084717
Validation loss: 2.076209306716919

Epoch: 5| Step: 8
Training loss: 1.731692910194397
Validation loss: 2.0549363692601523

Epoch: 5| Step: 9
Training loss: 2.33746337890625
Validation loss: 2.034291605154673

Epoch: 5| Step: 10
Training loss: 2.218082904815674
Validation loss: 2.021959682305654

Epoch: 5| Step: 11
Training loss: 2.8666648864746094
Validation loss: 2.016963849465052

Epoch: 90| Step: 0
Training loss: 2.399134874343872
Validation loss: 2.017218366265297

Epoch: 5| Step: 1
Training loss: 2.711367607116699
Validation loss: 2.0124698927005134

Epoch: 5| Step: 2
Training loss: 2.074385166168213
Validation loss: 2.0147979060808816

Epoch: 5| Step: 3
Training loss: 1.8817203044891357
Validation loss: 2.0207243214050927

Epoch: 5| Step: 4
Training loss: 2.4369800090789795
Validation loss: 2.013363257050514

Epoch: 5| Step: 5
Training loss: 2.168623685836792
Validation loss: 2.01200840373834

Epoch: 5| Step: 6
Training loss: 2.1402688026428223
Validation loss: 2.015046680967013

Epoch: 5| Step: 7
Training loss: 1.765241026878357
Validation loss: 2.013258770108223

Epoch: 5| Step: 8
Training loss: 2.1948611736297607
Validation loss: 2.008484731117884

Epoch: 5| Step: 9
Training loss: 2.1340603828430176
Validation loss: 2.0130145897467933

Epoch: 5| Step: 10
Training loss: 1.8991047143936157
Validation loss: 2.0147787580887475

Epoch: 5| Step: 11
Training loss: 2.3162970542907715
Validation loss: 2.0119410852591195

Epoch: 91| Step: 0
Training loss: 2.276942729949951
Validation loss: 2.016585777203242

Epoch: 5| Step: 1
Training loss: 2.3138675689697266
Validation loss: 2.023059288660685

Epoch: 5| Step: 2
Training loss: 2.443577289581299
Validation loss: 2.0155067642529807

Epoch: 5| Step: 3
Training loss: 1.7315934896469116
Validation loss: 2.0172021687030792

Epoch: 5| Step: 4
Training loss: 2.3687736988067627
Validation loss: 2.0179208318392434

Epoch: 5| Step: 5
Training loss: 2.1930034160614014
Validation loss: 2.0187117159366608

Epoch: 5| Step: 6
Training loss: 1.7267786264419556
Validation loss: 2.0184793720642724

Epoch: 5| Step: 7
Training loss: 2.446361541748047
Validation loss: 2.020384579896927

Epoch: 5| Step: 8
Training loss: 1.8089584112167358
Validation loss: 2.0262176295121512

Epoch: 5| Step: 9
Training loss: 2.1681385040283203
Validation loss: 2.031275932987531

Epoch: 5| Step: 10
Training loss: 2.3087663650512695
Validation loss: 2.0310749957958856

Epoch: 5| Step: 11
Training loss: 2.348355531692505
Validation loss: 2.028949961066246

Epoch: 92| Step: 0
Training loss: 1.8839571475982666
Validation loss: 2.03692955772082

Epoch: 5| Step: 1
Training loss: 2.376298189163208
Validation loss: 2.0371303955713906

Epoch: 5| Step: 2
Training loss: 2.8951079845428467
Validation loss: 2.0438586374123893

Epoch: 5| Step: 3
Training loss: 2.099165678024292
Validation loss: 2.0468284289042153

Epoch: 5| Step: 4
Training loss: 1.9249883890151978
Validation loss: 2.043608491619428

Epoch: 5| Step: 5
Training loss: 2.506868839263916
Validation loss: 2.036908601721128

Epoch: 5| Step: 6
Training loss: 1.8599449396133423
Validation loss: 2.03501258790493

Epoch: 5| Step: 7
Training loss: 2.357717990875244
Validation loss: 2.0208265533049903

Epoch: 5| Step: 8
Training loss: 1.9460265636444092
Validation loss: 2.0200352519750595

Epoch: 5| Step: 9
Training loss: 1.9500563144683838
Validation loss: 2.016956642270088

Epoch: 5| Step: 10
Training loss: 2.1268184185028076
Validation loss: 2.020372524857521

Epoch: 5| Step: 11
Training loss: 1.6285176277160645
Validation loss: 2.0147618800401688

Epoch: 93| Step: 0
Training loss: 2.1451756954193115
Validation loss: 2.0182248701651893

Epoch: 5| Step: 1
Training loss: 2.274174928665161
Validation loss: 2.0071202218532562

Epoch: 5| Step: 2
Training loss: 2.1324892044067383
Validation loss: 2.017818361520767

Epoch: 5| Step: 3
Training loss: 2.106532573699951
Validation loss: 2.0152382304271064

Epoch: 5| Step: 4
Training loss: 2.2158074378967285
Validation loss: 2.017751465241114

Epoch: 5| Step: 5
Training loss: 2.276381731033325
Validation loss: 2.0174068013827005

Epoch: 5| Step: 6
Training loss: 1.9393932819366455
Validation loss: 2.0184908558924994

Epoch: 5| Step: 7
Training loss: 2.340113878250122
Validation loss: 2.0126882592837014

Epoch: 5| Step: 8
Training loss: 2.3315320014953613
Validation loss: 2.0221801648537316

Epoch: 5| Step: 9
Training loss: 1.9510606527328491
Validation loss: 2.0217991719643273

Epoch: 5| Step: 10
Training loss: 2.1419918537139893
Validation loss: 2.0203201125065484

Epoch: 5| Step: 11
Training loss: 1.6045557260513306
Validation loss: 2.0230483611424765

Epoch: 94| Step: 0
Training loss: 1.5580705404281616
Validation loss: 2.015065590540568

Epoch: 5| Step: 1
Training loss: 2.2046566009521484
Validation loss: 2.0157019992669425

Epoch: 5| Step: 2
Training loss: 1.7529922723770142
Validation loss: 2.0155575474103293

Epoch: 5| Step: 3
Training loss: 2.6065311431884766
Validation loss: 2.018095408876737

Epoch: 5| Step: 4
Training loss: 3.2593979835510254
Validation loss: 2.0125822275877

Epoch: 5| Step: 5
Training loss: 2.0862057209014893
Validation loss: 2.014806881546974

Epoch: 5| Step: 6
Training loss: 2.5567574501037598
Validation loss: 2.0182903756697974

Epoch: 5| Step: 7
Training loss: 2.0110278129577637
Validation loss: 2.0128269294897714

Epoch: 5| Step: 8
Training loss: 2.2537546157836914
Validation loss: 2.016611153880755

Epoch: 5| Step: 9
Training loss: 1.536974310874939
Validation loss: 2.0147388031085334

Epoch: 5| Step: 10
Training loss: 2.2357239723205566
Validation loss: 2.013289918502172

Epoch: 5| Step: 11
Training loss: 0.7592541575431824
Validation loss: 2.008717437585195

Epoch: 95| Step: 0
Training loss: 2.0849149227142334
Validation loss: 2.031623601913452

Epoch: 5| Step: 1
Training loss: 2.2237696647644043
Validation loss: 2.0382876098155975

Epoch: 5| Step: 2
Training loss: 2.1528007984161377
Validation loss: 2.0572667668263116

Epoch: 5| Step: 3
Training loss: 2.2482476234436035
Validation loss: 2.0653148094813027

Epoch: 5| Step: 4
Training loss: 2.2759177684783936
Validation loss: 2.0735714733600616

Epoch: 5| Step: 5
Training loss: 1.9186073541641235
Validation loss: 2.0810369650522866

Epoch: 5| Step: 6
Training loss: 1.6831773519515991
Validation loss: 2.069707373778025

Epoch: 5| Step: 7
Training loss: 2.206953763961792
Validation loss: 2.0642145772775016

Epoch: 5| Step: 8
Training loss: 2.1907496452331543
Validation loss: 2.052079439163208

Epoch: 5| Step: 9
Training loss: 2.374948501586914
Validation loss: 2.0346322506666183

Epoch: 5| Step: 10
Training loss: 2.7335267066955566
Validation loss: 2.017159496744474

Epoch: 5| Step: 11
Training loss: 2.165670871734619
Validation loss: 2.012930303812027

Epoch: 96| Step: 0
Training loss: 2.1979801654815674
Validation loss: 2.007293701171875

Epoch: 5| Step: 1
Training loss: 2.0790278911590576
Validation loss: 2.010871405402819

Epoch: 5| Step: 2
Training loss: 2.2715582847595215
Validation loss: 2.0102926393349967

Epoch: 5| Step: 3
Training loss: 2.260655403137207
Validation loss: 2.005069747567177

Epoch: 5| Step: 4
Training loss: 1.8603684902191162
Validation loss: 2.007103974620501

Epoch: 5| Step: 5
Training loss: 2.186532497406006
Validation loss: 2.0110344936450324

Epoch: 5| Step: 6
Training loss: 2.3740711212158203
Validation loss: 2.015734682480494

Epoch: 5| Step: 7
Training loss: 2.0149428844451904
Validation loss: 2.006372277935346

Epoch: 5| Step: 8
Training loss: 2.388730525970459
Validation loss: 2.006835718949636

Epoch: 5| Step: 9
Training loss: 2.0044150352478027
Validation loss: 2.005877728263537

Epoch: 5| Step: 10
Training loss: 2.0273325443267822
Validation loss: 2.0074035823345184

Epoch: 5| Step: 11
Training loss: 2.206669807434082
Validation loss: 2.012471189101537

Epoch: 97| Step: 0
Training loss: 2.3364064693450928
Validation loss: 2.0215454747279487

Epoch: 5| Step: 1
Training loss: 2.409727096557617
Validation loss: 2.031727746129036

Epoch: 5| Step: 2
Training loss: 2.150036096572876
Validation loss: 2.05427751938502

Epoch: 5| Step: 3
Training loss: 1.9242746829986572
Validation loss: 2.0551017622152963

Epoch: 5| Step: 4
Training loss: 2.2180120944976807
Validation loss: 2.05675778289636

Epoch: 5| Step: 5
Training loss: 2.389791488647461
Validation loss: 2.0773962239424386

Epoch: 5| Step: 6
Training loss: 2.2148046493530273
Validation loss: 2.0733848263820014

Epoch: 5| Step: 7
Training loss: 2.094618558883667
Validation loss: 2.067022373278936

Epoch: 5| Step: 8
Training loss: 1.986943244934082
Validation loss: 2.05171104768912

Epoch: 5| Step: 9
Training loss: 1.952724814414978
Validation loss: 2.0303271959225335

Epoch: 5| Step: 10
Training loss: 2.2527518272399902
Validation loss: 2.0157023866971335

Epoch: 5| Step: 11
Training loss: 1.7543210983276367
Validation loss: 2.0109181503454843

Epoch: 98| Step: 0
Training loss: 2.073767900466919
Validation loss: 2.0051785707473755

Epoch: 5| Step: 1
Training loss: 2.725825548171997
Validation loss: 2.0246940751870475

Epoch: 5| Step: 2
Training loss: 2.309053421020508
Validation loss: 2.036973531047503

Epoch: 5| Step: 3
Training loss: 2.058671474456787
Validation loss: 2.038661703467369

Epoch: 5| Step: 4
Training loss: 2.0391011238098145
Validation loss: 2.0538420975208282

Epoch: 5| Step: 5
Training loss: 2.3205740451812744
Validation loss: 2.0612416515747705

Epoch: 5| Step: 6
Training loss: 2.3794779777526855
Validation loss: 2.0559951066970825

Epoch: 5| Step: 7
Training loss: 2.262226104736328
Validation loss: 2.0605394691228867

Epoch: 5| Step: 8
Training loss: 1.9247210025787354
Validation loss: 2.058261732260386

Epoch: 5| Step: 9
Training loss: 1.9922034740447998
Validation loss: 2.0582343141237893

Epoch: 5| Step: 10
Training loss: 2.31178879737854
Validation loss: 2.0585348457098007

Epoch: 5| Step: 11
Training loss: 2.1311450004577637
Validation loss: 2.0558441827694574

Epoch: 99| Step: 0
Training loss: 2.4398410320281982
Validation loss: 2.05476584037145

Epoch: 5| Step: 1
Training loss: 2.181169271469116
Validation loss: 2.0588193237781525

Epoch: 5| Step: 2
Training loss: 2.1741812229156494
Validation loss: 2.056932916243871

Epoch: 5| Step: 3
Training loss: 2.3014678955078125
Validation loss: 2.0562046418587365

Epoch: 5| Step: 4
Training loss: 2.244476795196533
Validation loss: 2.0522751013437905

Epoch: 5| Step: 5
Training loss: 2.2375552654266357
Validation loss: 2.047701040903727

Epoch: 5| Step: 6
Training loss: 2.7194342613220215
Validation loss: 2.049456904331843

Epoch: 5| Step: 7
Training loss: 1.5594308376312256
Validation loss: 2.044330740968386

Epoch: 5| Step: 8
Training loss: 1.8492475748062134
Validation loss: 2.0346848517656326

Epoch: 5| Step: 9
Training loss: 1.9203647375106812
Validation loss: 2.025315394004186

Epoch: 5| Step: 10
Training loss: 2.486602306365967
Validation loss: 2.016997461517652

Epoch: 5| Step: 11
Training loss: 2.268197536468506
Validation loss: 2.014487852652868

Epoch: 100| Step: 0
Training loss: 1.7288881540298462
Validation loss: 2.010251368085543

Epoch: 5| Step: 1
Training loss: 2.092898368835449
Validation loss: 2.02303709089756

Epoch: 5| Step: 2
Training loss: 2.3359198570251465
Validation loss: 2.027249718705813

Epoch: 5| Step: 3
Training loss: 2.516115427017212
Validation loss: 2.039638469616572

Epoch: 5| Step: 4
Training loss: 2.200626850128174
Validation loss: 2.0308518012364707

Epoch: 5| Step: 5
Training loss: 2.2486579418182373
Validation loss: 2.0320395827293396

Epoch: 5| Step: 6
Training loss: 1.7957404851913452
Validation loss: 2.03445972998937

Epoch: 5| Step: 7
Training loss: 1.4027385711669922
Validation loss: 2.041352947552999

Epoch: 5| Step: 8
Training loss: 2.4190597534179688
Validation loss: 2.0432265351215997

Epoch: 5| Step: 9
Training loss: 2.7140469551086426
Validation loss: 2.0504956046740213

Epoch: 5| Step: 10
Training loss: 2.4527194499969482
Validation loss: 2.0583911637465158

Epoch: 5| Step: 11
Training loss: 1.4955220222473145
Validation loss: 2.0469185014565787

Epoch: 101| Step: 0
Training loss: 1.6221110820770264
Validation loss: 2.0521792471408844

Epoch: 5| Step: 1
Training loss: 3.025223970413208
Validation loss: 2.0505167841911316

Epoch: 5| Step: 2
Training loss: 2.4039652347564697
Validation loss: 2.0335640609264374

Epoch: 5| Step: 3
Training loss: 2.4607276916503906
Validation loss: 2.0210800170898438

Epoch: 5| Step: 4
Training loss: 2.2704272270202637
Validation loss: 2.0164941350618997

Epoch: 5| Step: 5
Training loss: 1.861606240272522
Validation loss: 2.0115305483341217

Epoch: 5| Step: 6
Training loss: 2.079489231109619
Validation loss: 2.0146264731884003

Epoch: 5| Step: 7
Training loss: 2.045746326446533
Validation loss: 2.0162041982014975

Epoch: 5| Step: 8
Training loss: 1.9859225749969482
Validation loss: 2.016906256477038

Epoch: 5| Step: 9
Training loss: 2.2268290519714355
Validation loss: 2.018326143423716

Epoch: 5| Step: 10
Training loss: 1.872586965560913
Validation loss: 2.0137475778659186

Epoch: 5| Step: 11
Training loss: 2.778932571411133
Validation loss: 2.0177949368953705

Epoch: 102| Step: 0
Training loss: 1.8938300609588623
Validation loss: 2.018866499265035

Epoch: 5| Step: 1
Training loss: 2.0949389934539795
Validation loss: 2.018591950337092

Epoch: 5| Step: 2
Training loss: 1.568694829940796
Validation loss: 2.033678725361824

Epoch: 5| Step: 3
Training loss: 2.072070837020874
Validation loss: 2.0364264647165933

Epoch: 5| Step: 4
Training loss: 2.7218387126922607
Validation loss: 2.045399308204651

Epoch: 5| Step: 5
Training loss: 2.1153621673583984
Validation loss: 2.0519595642884574

Epoch: 5| Step: 6
Training loss: 2.2760441303253174
Validation loss: 2.0542821437120438

Epoch: 5| Step: 7
Training loss: 2.365251302719116
Validation loss: 2.055749366680781

Epoch: 5| Step: 8
Training loss: 2.6226956844329834
Validation loss: 2.0470675279696784

Epoch: 5| Step: 9
Training loss: 2.0616109371185303
Validation loss: 2.041415552298228

Epoch: 5| Step: 10
Training loss: 1.9967577457427979
Validation loss: 2.035865440964699

Epoch: 5| Step: 11
Training loss: 2.0191168785095215
Validation loss: 2.029541944464048

Epoch: 103| Step: 0
Training loss: 2.148252010345459
Validation loss: 2.0242351790269217

Epoch: 5| Step: 1
Training loss: 2.2383131980895996
Validation loss: 2.029971937338511

Epoch: 5| Step: 2
Training loss: 1.9646689891815186
Validation loss: 2.023291905721029

Epoch: 5| Step: 3
Training loss: 2.0991921424865723
Validation loss: 2.02253050605456

Epoch: 5| Step: 4
Training loss: 1.635565996170044
Validation loss: 2.015141487121582

Epoch: 5| Step: 5
Training loss: 1.866683006286621
Validation loss: 2.0168313930432

Epoch: 5| Step: 6
Training loss: 2.2599196434020996
Validation loss: 2.0207222998142242

Epoch: 5| Step: 7
Training loss: 2.4960899353027344
Validation loss: 2.0195672710736594

Epoch: 5| Step: 8
Training loss: 2.0333871841430664
Validation loss: 2.0125278433163962

Epoch: 5| Step: 9
Training loss: 2.61466646194458
Validation loss: 2.017805407444636

Epoch: 5| Step: 10
Training loss: 2.274155378341675
Validation loss: 2.022027760744095

Epoch: 5| Step: 11
Training loss: 2.0399746894836426
Validation loss: 2.0220339049895606

Epoch: 104| Step: 0
Training loss: 1.647695779800415
Validation loss: 2.0252501716216407

Epoch: 5| Step: 1
Training loss: 2.2202727794647217
Validation loss: 2.025532598296801

Epoch: 5| Step: 2
Training loss: 1.7056739330291748
Validation loss: 2.015059550603231

Epoch: 5| Step: 3
Training loss: 1.9597022533416748
Validation loss: 2.022724727789561

Epoch: 5| Step: 4
Training loss: 1.8209909200668335
Validation loss: 2.0219516158103943

Epoch: 5| Step: 5
Training loss: 1.9362064599990845
Validation loss: 2.0238809982935586

Epoch: 5| Step: 6
Training loss: 2.7267754077911377
Validation loss: 2.0293327073256173

Epoch: 5| Step: 7
Training loss: 2.2894160747528076
Validation loss: 2.0283251454432807

Epoch: 5| Step: 8
Training loss: 2.154048442840576
Validation loss: 2.029194638133049

Epoch: 5| Step: 9
Training loss: 2.6514744758605957
Validation loss: 2.033875991900762

Epoch: 5| Step: 10
Training loss: 2.2216012477874756
Validation loss: 2.028002748886744

Epoch: 5| Step: 11
Training loss: 2.8014822006225586
Validation loss: 2.0319965134064355

Epoch: 105| Step: 0
Training loss: 2.2923083305358887
Validation loss: 2.026654983560244

Epoch: 5| Step: 1
Training loss: 2.3503692150115967
Validation loss: 2.0273533860842385

Epoch: 5| Step: 2
Training loss: 2.3764357566833496
Validation loss: 2.0262594322363534

Epoch: 5| Step: 3
Training loss: 2.11088228225708
Validation loss: 2.017270674308141

Epoch: 5| Step: 4
Training loss: 1.8523613214492798
Validation loss: 2.011627828081449

Epoch: 5| Step: 5
Training loss: 2.1539015769958496
Validation loss: 2.0164417823155723

Epoch: 5| Step: 6
Training loss: 2.256964921951294
Validation loss: 2.018173356850942

Epoch: 5| Step: 7
Training loss: 2.0360825061798096
Validation loss: 2.0135173896948495

Epoch: 5| Step: 8
Training loss: 2.0981578826904297
Validation loss: 2.0212367326021194

Epoch: 5| Step: 9
Training loss: 1.787893295288086
Validation loss: 2.0150627295176187

Epoch: 5| Step: 10
Training loss: 1.9049594402313232
Validation loss: 2.0241611152887344

Epoch: 5| Step: 11
Training loss: 3.248955726623535
Validation loss: 2.035449797908465

Epoch: 106| Step: 0
Training loss: 2.5567643642425537
Validation loss: 2.045997768640518

Epoch: 5| Step: 1
Training loss: 2.3820927143096924
Validation loss: 2.048987021048864

Epoch: 5| Step: 2
Training loss: 1.6832196712493896
Validation loss: 2.0746651142835617

Epoch: 5| Step: 3
Training loss: 1.9530118703842163
Validation loss: 2.0698143939177194

Epoch: 5| Step: 4
Training loss: 2.4133849143981934
Validation loss: 2.0753892262776694

Epoch: 5| Step: 5
Training loss: 2.1227035522460938
Validation loss: 2.0714620451132455

Epoch: 5| Step: 6
Training loss: 2.076958417892456
Validation loss: 2.0726261337598166

Epoch: 5| Step: 7
Training loss: 2.147134780883789
Validation loss: 2.0615248630444207

Epoch: 5| Step: 8
Training loss: 1.7350246906280518
Validation loss: 2.045864015817642

Epoch: 5| Step: 9
Training loss: 1.906843900680542
Validation loss: 2.032297506928444

Epoch: 5| Step: 10
Training loss: 2.9897048473358154
Validation loss: 2.0218121806780496

Epoch: 5| Step: 11
Training loss: 1.4988330602645874
Validation loss: 2.0201724618673325

Epoch: 107| Step: 0
Training loss: 1.4596625566482544
Validation loss: 2.018185923496882

Epoch: 5| Step: 1
Training loss: 1.9592170715332031
Validation loss: 2.0125650465488434

Epoch: 5| Step: 2
Training loss: 2.243011236190796
Validation loss: 2.005708093444506

Epoch: 5| Step: 3
Training loss: 1.8263351917266846
Validation loss: 2.0127039005359015

Epoch: 5| Step: 4
Training loss: 2.0607264041900635
Validation loss: 2.01619586845239

Epoch: 5| Step: 5
Training loss: 2.636596202850342
Validation loss: 2.014514312148094

Epoch: 5| Step: 6
Training loss: 2.526604413986206
Validation loss: 2.015770668784777

Epoch: 5| Step: 7
Training loss: 2.7147040367126465
Validation loss: 2.0174923141797385

Epoch: 5| Step: 8
Training loss: 2.443521499633789
Validation loss: 2.014671559135119

Epoch: 5| Step: 9
Training loss: 1.7897239923477173
Validation loss: 2.0079194456338882

Epoch: 5| Step: 10
Training loss: 1.9804229736328125
Validation loss: 2.0117538273334503

Epoch: 5| Step: 11
Training loss: 1.8218185901641846
Validation loss: 2.0089618812004724

Epoch: 108| Step: 0
Training loss: 2.4824957847595215
Validation loss: 2.0118992626667023

Epoch: 5| Step: 1
Training loss: 2.466188430786133
Validation loss: 2.019328976670901

Epoch: 5| Step: 2
Training loss: 2.0971531867980957
Validation loss: 2.023155465722084

Epoch: 5| Step: 3
Training loss: 1.904158353805542
Validation loss: 2.02569916844368

Epoch: 5| Step: 4
Training loss: 1.8167283535003662
Validation loss: 2.034506152073542

Epoch: 5| Step: 5
Training loss: 1.5169098377227783
Validation loss: 2.0294428120056787

Epoch: 5| Step: 6
Training loss: 1.9003013372421265
Validation loss: 2.0282261818647385

Epoch: 5| Step: 7
Training loss: 2.447169780731201
Validation loss: 2.0280937453111014

Epoch: 5| Step: 8
Training loss: 2.643038272857666
Validation loss: 2.0343353201945624

Epoch: 5| Step: 9
Training loss: 2.3464016914367676
Validation loss: 2.0393451700607934

Epoch: 5| Step: 10
Training loss: 1.9233691692352295
Validation loss: 2.0284694184859595

Epoch: 5| Step: 11
Training loss: 2.454066753387451
Validation loss: 2.028041193882624

Epoch: 109| Step: 0
Training loss: 2.4450173377990723
Validation loss: 2.0305172403653464

Epoch: 5| Step: 1
Training loss: 2.4850051403045654
Validation loss: 2.0216482877731323

Epoch: 5| Step: 2
Training loss: 1.9144376516342163
Validation loss: 2.021493231256803

Epoch: 5| Step: 3
Training loss: 2.255560874938965
Validation loss: 2.011682406067848

Epoch: 5| Step: 4
Training loss: 1.9944112300872803
Validation loss: 2.007556065917015

Epoch: 5| Step: 5
Training loss: 1.5399340391159058
Validation loss: 2.0118184288342795

Epoch: 5| Step: 6
Training loss: 2.0065999031066895
Validation loss: 2.018653785188993

Epoch: 5| Step: 7
Training loss: 2.554304838180542
Validation loss: 2.017964502175649

Epoch: 5| Step: 8
Training loss: 1.7307252883911133
Validation loss: 2.0204588572184243

Epoch: 5| Step: 9
Training loss: 1.9363183975219727
Validation loss: 2.0264462331930795

Epoch: 5| Step: 10
Training loss: 2.613231658935547
Validation loss: 2.030452852447828

Epoch: 5| Step: 11
Training loss: 2.008352518081665
Validation loss: 2.023935223619143

Epoch: 110| Step: 0
Training loss: 2.287315845489502
Validation loss: 2.0421526531378427

Epoch: 5| Step: 1
Training loss: 2.5977039337158203
Validation loss: 2.037971556186676

Epoch: 5| Step: 2
Training loss: 1.4737173318862915
Validation loss: 2.0366010665893555

Epoch: 5| Step: 3
Training loss: 1.5752042531967163
Validation loss: 2.0378406842549643

Epoch: 5| Step: 4
Training loss: 2.4957692623138428
Validation loss: 2.052092750867208

Epoch: 5| Step: 5
Training loss: 1.3781814575195312
Validation loss: 2.04516963660717

Epoch: 5| Step: 6
Training loss: 2.3327362537384033
Validation loss: 2.038277342915535

Epoch: 5| Step: 7
Training loss: 2.020725727081299
Validation loss: 2.03701742986838

Epoch: 5| Step: 8
Training loss: 1.9805901050567627
Validation loss: 2.0337736109892526

Epoch: 5| Step: 9
Training loss: 2.935091018676758
Validation loss: 2.0304719110329947

Epoch: 5| Step: 10
Training loss: 2.3818607330322266
Validation loss: 2.0132665236790976

Epoch: 5| Step: 11
Training loss: 1.890350103378296
Validation loss: 2.020133992036184

Epoch: 111| Step: 0
Training loss: 1.7614332437515259
Validation loss: 2.0133459518353143

Epoch: 5| Step: 1
Training loss: 2.1945505142211914
Validation loss: 2.012693082292875

Epoch: 5| Step: 2
Training loss: 2.1078925132751465
Validation loss: 2.020825872818629

Epoch: 5| Step: 3
Training loss: 1.8481429815292358
Validation loss: 2.025000015894572

Epoch: 5| Step: 4
Training loss: 2.169661283493042
Validation loss: 2.0238344420989356

Epoch: 5| Step: 5
Training loss: 1.9568074941635132
Validation loss: 2.019052490592003

Epoch: 5| Step: 6
Training loss: 1.9019619226455688
Validation loss: 2.0178773502508798

Epoch: 5| Step: 7
Training loss: 2.291030168533325
Validation loss: 2.023142615954081

Epoch: 5| Step: 8
Training loss: 1.9601110219955444
Validation loss: 2.0180847148100534

Epoch: 5| Step: 9
Training loss: 2.935307741165161
Validation loss: 2.014866511027018

Epoch: 5| Step: 10
Training loss: 2.4219717979431152
Validation loss: 2.012558196981748

Epoch: 5| Step: 11
Training loss: 2.751180410385132
Validation loss: 2.014998326698939

Epoch: 112| Step: 0
Training loss: 1.3725782632827759
Validation loss: 2.0023050258557

Epoch: 5| Step: 1
Training loss: 2.1647515296936035
Validation loss: 2.0132902562618256

Epoch: 5| Step: 2
Training loss: 2.400038242340088
Validation loss: 2.008960505326589

Epoch: 5| Step: 3
Training loss: 1.9911342859268188
Validation loss: 2.01543165743351

Epoch: 5| Step: 4
Training loss: 1.879669189453125
Validation loss: 2.0207132399082184

Epoch: 5| Step: 5
Training loss: 2.2211527824401855
Validation loss: 2.0213703165451684

Epoch: 5| Step: 6
Training loss: 2.1451854705810547
Validation loss: 2.030103623867035

Epoch: 5| Step: 7
Training loss: 2.27933406829834
Validation loss: 2.022734751303991

Epoch: 5| Step: 8
Training loss: 2.513272285461426
Validation loss: 2.0192623138427734

Epoch: 5| Step: 9
Training loss: 1.7906023263931274
Validation loss: 2.0234773804744086

Epoch: 5| Step: 10
Training loss: 2.6963486671447754
Validation loss: 2.027190402150154

Epoch: 5| Step: 11
Training loss: 1.698324203491211
Validation loss: 2.0276915033658347

Epoch: 113| Step: 0
Training loss: 2.025036334991455
Validation loss: 2.0261424829562507

Epoch: 5| Step: 1
Training loss: 2.0378429889678955
Validation loss: 2.019749234120051

Epoch: 5| Step: 2
Training loss: 2.152108669281006
Validation loss: 2.0204800417025885

Epoch: 5| Step: 3
Training loss: 1.8655287027359009
Validation loss: 2.0198649813731513

Epoch: 5| Step: 4
Training loss: 1.9744383096694946
Validation loss: 2.0178317626317344

Epoch: 5| Step: 5
Training loss: 2.647507667541504
Validation loss: 2.0189819683631263

Epoch: 5| Step: 6
Training loss: 2.4619994163513184
Validation loss: 2.0192816456158957

Epoch: 5| Step: 7
Training loss: 2.0721726417541504
Validation loss: 2.0260632733503976

Epoch: 5| Step: 8
Training loss: 1.8282668590545654
Validation loss: 2.01931764682134

Epoch: 5| Step: 9
Training loss: 1.9869089126586914
Validation loss: 2.025579959154129

Epoch: 5| Step: 10
Training loss: 2.285550594329834
Validation loss: 2.0256742338339486

Epoch: 5| Step: 11
Training loss: 2.551588535308838
Validation loss: 2.0297924329837165

Epoch: 114| Step: 0
Training loss: 1.9901106357574463
Validation loss: 2.0214385837316513

Epoch: 5| Step: 1
Training loss: 2.1239354610443115
Validation loss: 2.014721835652987

Epoch: 5| Step: 2
Training loss: 2.3001530170440674
Validation loss: 2.0212561984856925

Epoch: 5| Step: 3
Training loss: 2.113988161087036
Validation loss: 2.016325463851293

Epoch: 5| Step: 4
Training loss: 1.7276957035064697
Validation loss: 2.0151303956906

Epoch: 5| Step: 5
Training loss: 2.0185070037841797
Validation loss: 2.018855700890223

Epoch: 5| Step: 6
Training loss: 2.603938341140747
Validation loss: 2.012431785464287

Epoch: 5| Step: 7
Training loss: 2.2915127277374268
Validation loss: 2.010121295849482

Epoch: 5| Step: 8
Training loss: 2.191955804824829
Validation loss: 2.0139385759830475

Epoch: 5| Step: 9
Training loss: 2.0042476654052734
Validation loss: 2.015265539288521

Epoch: 5| Step: 10
Training loss: 1.8726085424423218
Validation loss: 2.0166227916876474

Epoch: 5| Step: 11
Training loss: 3.3116507530212402
Validation loss: 2.014962042371432

Epoch: 115| Step: 0
Training loss: 1.9665005207061768
Validation loss: 2.016803875565529

Epoch: 5| Step: 1
Training loss: 2.217700719833374
Validation loss: 2.015208507577578

Epoch: 5| Step: 2
Training loss: 2.253786087036133
Validation loss: 2.0271934270858765

Epoch: 5| Step: 3
Training loss: 2.1110479831695557
Validation loss: 2.0247625360886254

Epoch: 5| Step: 4
Training loss: 1.6607061624526978
Validation loss: 2.0240203539530435

Epoch: 5| Step: 5
Training loss: 1.9249145984649658
Validation loss: 2.0283903181552887

Epoch: 5| Step: 6
Training loss: 2.172229051589966
Validation loss: 2.0233577340841293

Epoch: 5| Step: 7
Training loss: 1.447813630104065
Validation loss: 2.0263477067152658

Epoch: 5| Step: 8
Training loss: 2.7064285278320312
Validation loss: 2.0206302156051

Epoch: 5| Step: 9
Training loss: 2.653987169265747
Validation loss: 2.0233546992142997

Epoch: 5| Step: 10
Training loss: 2.2494308948516846
Validation loss: 2.0287481993436813

Epoch: 5| Step: 11
Training loss: 2.024060010910034
Validation loss: 2.0256227056185403

Epoch: 116| Step: 0
Training loss: 1.6659297943115234
Validation loss: 2.0204113324483237

Epoch: 5| Step: 1
Training loss: 2.248091220855713
Validation loss: 2.031690622369448

Epoch: 5| Step: 2
Training loss: 1.9770777225494385
Validation loss: 2.030998463431994

Epoch: 5| Step: 3
Training loss: 2.300239324569702
Validation loss: 2.02320189277331

Epoch: 5| Step: 4
Training loss: 2.1822800636291504
Validation loss: 2.0300005276997886

Epoch: 5| Step: 5
Training loss: 2.4849154949188232
Validation loss: 2.033001939455668

Epoch: 5| Step: 6
Training loss: 2.0739941596984863
Validation loss: 2.0306150317192078

Epoch: 5| Step: 7
Training loss: 2.2092792987823486
Validation loss: 2.0372360994418464

Epoch: 5| Step: 8
Training loss: 2.375162363052368
Validation loss: 2.036291499932607

Epoch: 5| Step: 9
Training loss: 1.6110725402832031
Validation loss: 2.039275656143824

Epoch: 5| Step: 10
Training loss: 2.0915639400482178
Validation loss: 2.0311681727568307

Epoch: 5| Step: 11
Training loss: 1.7918564081192017
Validation loss: 2.0270472367604575

Epoch: 117| Step: 0
Training loss: 1.7579084634780884
Validation loss: 2.030381699403127

Epoch: 5| Step: 1
Training loss: 2.171191453933716
Validation loss: 2.0299983471632004

Epoch: 5| Step: 2
Training loss: 2.4612956047058105
Validation loss: 2.0242816656827927

Epoch: 5| Step: 3
Training loss: 1.4360185861587524
Validation loss: 2.019409661491712

Epoch: 5| Step: 4
Training loss: 2.034694194793701
Validation loss: 2.026847685376803

Epoch: 5| Step: 5
Training loss: 1.988660454750061
Validation loss: 2.0243360847234726

Epoch: 5| Step: 6
Training loss: 1.9111642837524414
Validation loss: 2.0215800056854882

Epoch: 5| Step: 7
Training loss: 2.571791887283325
Validation loss: 2.0263207654158273

Epoch: 5| Step: 8
Training loss: 1.9214318990707397
Validation loss: 2.0252728313207626

Epoch: 5| Step: 9
Training loss: 2.1999692916870117
Validation loss: 2.020826061566671

Epoch: 5| Step: 10
Training loss: 2.687825918197632
Validation loss: 2.0300578822692237

Epoch: 5| Step: 11
Training loss: 2.1978671550750732
Validation loss: 2.0269868125518165

Epoch: 118| Step: 0
Training loss: 2.0495071411132812
Validation loss: 2.017238900065422

Epoch: 5| Step: 1
Training loss: 1.941161870956421
Validation loss: 2.02069890499115

Epoch: 5| Step: 2
Training loss: 2.2481179237365723
Validation loss: 2.01735353966554

Epoch: 5| Step: 3
Training loss: 2.243190288543701
Validation loss: 2.014559417963028

Epoch: 5| Step: 4
Training loss: 2.3264412879943848
Validation loss: 2.0172946651776633

Epoch: 5| Step: 5
Training loss: 2.1546740531921387
Validation loss: 2.021254748106003

Epoch: 5| Step: 6
Training loss: 2.1022539138793945
Validation loss: 2.021390030781428

Epoch: 5| Step: 7
Training loss: 1.7706598043441772
Validation loss: 2.0237814436356225

Epoch: 5| Step: 8
Training loss: 1.9634392261505127
Validation loss: 2.023858959476153

Epoch: 5| Step: 9
Training loss: 2.2413344383239746
Validation loss: 2.023263230919838

Epoch: 5| Step: 10
Training loss: 2.4118056297302246
Validation loss: 2.0225456058979034

Epoch: 5| Step: 11
Training loss: 1.42239511013031
Validation loss: 2.0168114652236304

Epoch: 119| Step: 0
Training loss: 1.7865407466888428
Validation loss: 2.0229046841462455

Epoch: 5| Step: 1
Training loss: 1.7993148565292358
Validation loss: 2.023618370294571

Epoch: 5| Step: 2
Training loss: 1.8199723958969116
Validation loss: 2.0338155726591745

Epoch: 5| Step: 3
Training loss: 2.145615577697754
Validation loss: 2.049077103535334

Epoch: 5| Step: 4
Training loss: 2.536480665206909
Validation loss: 2.069849371910095

Epoch: 5| Step: 5
Training loss: 2.543097734451294
Validation loss: 2.0714562435944877

Epoch: 5| Step: 6
Training loss: 2.1980996131896973
Validation loss: 2.070110152165095

Epoch: 5| Step: 7
Training loss: 2.8145670890808105
Validation loss: 2.0641923546791077

Epoch: 5| Step: 8
Training loss: 2.4010748863220215
Validation loss: 2.055161436398824

Epoch: 5| Step: 9
Training loss: 1.5957273244857788
Validation loss: 2.047175645828247

Epoch: 5| Step: 10
Training loss: 1.9269195795059204
Validation loss: 2.0423838396867118

Epoch: 5| Step: 11
Training loss: 1.4213025569915771
Validation loss: 2.026531552275022

Epoch: 120| Step: 0
Training loss: 2.2617740631103516
Validation loss: 2.0200284073750177

Epoch: 5| Step: 1
Training loss: 2.319631814956665
Validation loss: 2.022503395875295

Epoch: 5| Step: 2
Training loss: 1.5854132175445557
Validation loss: 2.023415729403496

Epoch: 5| Step: 3
Training loss: 2.268960475921631
Validation loss: 2.0164881447950997

Epoch: 5| Step: 4
Training loss: 2.4893622398376465
Validation loss: 2.015787646174431

Epoch: 5| Step: 5
Training loss: 1.7438528537750244
Validation loss: 2.0176725685596466

Epoch: 5| Step: 6
Training loss: 2.124223232269287
Validation loss: 2.0228531807661057

Epoch: 5| Step: 7
Training loss: 2.0031015872955322
Validation loss: 2.021810462077459

Epoch: 5| Step: 8
Training loss: 2.7415194511413574
Validation loss: 2.0237707098325095

Epoch: 5| Step: 9
Training loss: 1.821043610572815
Validation loss: 2.0216874529918036

Epoch: 5| Step: 10
Training loss: 1.9889144897460938
Validation loss: 2.0140555997689567

Epoch: 5| Step: 11
Training loss: 2.267798662185669
Validation loss: 2.0118627150853476

Epoch: 121| Step: 0
Training loss: 1.985774278640747
Validation loss: 2.010565141836802

Epoch: 5| Step: 1
Training loss: 2.015655994415283
Validation loss: 2.017492284377416

Epoch: 5| Step: 2
Training loss: 1.9317563772201538
Validation loss: 2.018901437520981

Epoch: 5| Step: 3
Training loss: 2.201241970062256
Validation loss: 2.0276323010524115

Epoch: 5| Step: 4
Training loss: 2.334928035736084
Validation loss: 2.0377937207619348

Epoch: 5| Step: 5
Training loss: 2.3287389278411865
Validation loss: 2.0447302560011544

Epoch: 5| Step: 6
Training loss: 2.3044419288635254
Validation loss: 2.0375471959511438

Epoch: 5| Step: 7
Training loss: 1.7583892345428467
Validation loss: 2.0413518150647483

Epoch: 5| Step: 8
Training loss: 2.008518695831299
Validation loss: 2.0352143347263336

Epoch: 5| Step: 9
Training loss: 2.049272298812866
Validation loss: 2.0356481075286865

Epoch: 5| Step: 10
Training loss: 2.1759417057037354
Validation loss: 2.0349942247072854

Epoch: 5| Step: 11
Training loss: 2.6002771854400635
Validation loss: 2.0310866137345633

Epoch: 122| Step: 0
Training loss: 1.6971279382705688
Validation loss: 2.0358964999516806

Epoch: 5| Step: 1
Training loss: 2.2624735832214355
Validation loss: 2.035406986872355

Epoch: 5| Step: 2
Training loss: 1.826631784439087
Validation loss: 2.032008613149325

Epoch: 5| Step: 3
Training loss: 2.2556495666503906
Validation loss: 2.041566640138626

Epoch: 5| Step: 4
Training loss: 2.056541919708252
Validation loss: 2.0518203179041543

Epoch: 5| Step: 5
Training loss: 1.943544626235962
Validation loss: 2.037087897459666

Epoch: 5| Step: 6
Training loss: 1.953644037246704
Validation loss: 2.036373555660248

Epoch: 5| Step: 7
Training loss: 2.4134490489959717
Validation loss: 2.039316549897194

Epoch: 5| Step: 8
Training loss: 2.863509178161621
Validation loss: 2.0410353442033133

Epoch: 5| Step: 9
Training loss: 1.6544889211654663
Validation loss: 2.029282048344612

Epoch: 5| Step: 10
Training loss: 2.1898672580718994
Validation loss: 2.0262493739525476

Epoch: 5| Step: 11
Training loss: 3.048225164413452
Validation loss: 2.024482717116674

Epoch: 123| Step: 0
Training loss: 2.1367499828338623
Validation loss: 2.0324491759141288

Epoch: 5| Step: 1
Training loss: 2.4223973751068115
Validation loss: 2.0356295704841614

Epoch: 5| Step: 2
Training loss: 2.4977927207946777
Validation loss: 2.048562397559484

Epoch: 5| Step: 3
Training loss: 1.9929687976837158
Validation loss: 2.058405155936877

Epoch: 5| Step: 4
Training loss: 1.4130014181137085
Validation loss: 2.046155427893003

Epoch: 5| Step: 5
Training loss: 2.4725708961486816
Validation loss: 2.0641450385252633

Epoch: 5| Step: 6
Training loss: 2.119833469390869
Validation loss: 2.062520037094752

Epoch: 5| Step: 7
Training loss: 1.9305078983306885
Validation loss: 2.05104989806811

Epoch: 5| Step: 8
Training loss: 2.392420530319214
Validation loss: 2.0461594065030417

Epoch: 5| Step: 9
Training loss: 2.04541277885437
Validation loss: 2.0338339060544968

Epoch: 5| Step: 10
Training loss: 2.2480475902557373
Validation loss: 2.0306723912556968

Epoch: 5| Step: 11
Training loss: 1.5386962890625
Validation loss: 2.0290883282820382

Epoch: 124| Step: 0
Training loss: 2.5226569175720215
Validation loss: 2.0158327221870422

Epoch: 5| Step: 1
Training loss: 2.176412343978882
Validation loss: 2.0191776007413864

Epoch: 5| Step: 2
Training loss: 1.9993774890899658
Validation loss: 2.0345439861218133

Epoch: 5| Step: 3
Training loss: 2.3440120220184326
Validation loss: 2.039351041118304

Epoch: 5| Step: 4
Training loss: 2.424471378326416
Validation loss: 2.043454110622406

Epoch: 5| Step: 5
Training loss: 2.4356131553649902
Validation loss: 2.044515306750933

Epoch: 5| Step: 6
Training loss: 2.7211673259735107
Validation loss: 2.044991413752238

Epoch: 5| Step: 7
Training loss: 1.7449012994766235
Validation loss: 2.0534144043922424

Epoch: 5| Step: 8
Training loss: 1.5545482635498047
Validation loss: 2.0533722142378488

Epoch: 5| Step: 9
Training loss: 2.124967575073242
Validation loss: 2.0527272323767343

Epoch: 5| Step: 10
Training loss: 1.9387515783309937
Validation loss: 2.0537500977516174

Epoch: 5| Step: 11
Training loss: 1.6810576915740967
Validation loss: 2.0512512226899466

Epoch: 125| Step: 0
Training loss: 2.360133409500122
Validation loss: 2.047022521495819

Epoch: 5| Step: 1
Training loss: 2.3404629230499268
Validation loss: 2.0478105197350183

Epoch: 5| Step: 2
Training loss: 2.1072933673858643
Validation loss: 2.04239950577418

Epoch: 5| Step: 3
Training loss: 2.207109212875366
Validation loss: 2.043827007214228

Epoch: 5| Step: 4
Training loss: 2.6903815269470215
Validation loss: 2.0397051523129144

Epoch: 5| Step: 5
Training loss: 2.3431148529052734
Validation loss: 2.035694792866707

Epoch: 5| Step: 6
Training loss: 1.9716675281524658
Validation loss: 2.0360052287578583

Epoch: 5| Step: 7
Training loss: 1.8943507671356201
Validation loss: 2.022892559568087

Epoch: 5| Step: 8
Training loss: 1.9593626260757446
Validation loss: 2.0280589958031974

Epoch: 5| Step: 9
Training loss: 2.020563840866089
Validation loss: 2.018991932272911

Epoch: 5| Step: 10
Training loss: 1.7296063899993896
Validation loss: 2.0182694594065347

Epoch: 5| Step: 11
Training loss: 2.1575965881347656
Validation loss: 2.0037981470425925

Epoch: 126| Step: 0
Training loss: 1.5539429187774658
Validation loss: 1.9969868610302608

Epoch: 5| Step: 1
Training loss: 2.040351390838623
Validation loss: 2.0138448774814606

Epoch: 5| Step: 2
Training loss: 2.113124132156372
Validation loss: 2.0150349338849387

Epoch: 5| Step: 3
Training loss: 2.1028077602386475
Validation loss: 2.017118811607361

Epoch: 5| Step: 4
Training loss: 2.1136512756347656
Validation loss: 2.0195250312487283

Epoch: 5| Step: 5
Training loss: 2.6849045753479004
Validation loss: 2.028424690167109

Epoch: 5| Step: 6
Training loss: 2.0105578899383545
Validation loss: 2.039749617377917

Epoch: 5| Step: 7
Training loss: 2.1634018421173096
Validation loss: 2.028225302696228

Epoch: 5| Step: 8
Training loss: 1.9835294485092163
Validation loss: 2.025382066766421

Epoch: 5| Step: 9
Training loss: 1.986527442932129
Validation loss: 2.0310198614994683

Epoch: 5| Step: 10
Training loss: 2.3543145656585693
Validation loss: 2.0334013303120932

Epoch: 5| Step: 11
Training loss: 2.9665143489837646
Validation loss: 2.036450450619062

Epoch: 127| Step: 0
Training loss: 2.754176378250122
Validation loss: 2.0293828547000885

Epoch: 5| Step: 1
Training loss: 2.124666452407837
Validation loss: 2.0253896266222

Epoch: 5| Step: 2
Training loss: 1.482647180557251
Validation loss: 2.0233132193485894

Epoch: 5| Step: 3
Training loss: 2.130455493927002
Validation loss: 2.0266978492339454

Epoch: 5| Step: 4
Training loss: 2.4220080375671387
Validation loss: 2.0282858163118362

Epoch: 5| Step: 5
Training loss: 1.9008510112762451
Validation loss: 2.02496171494325

Epoch: 5| Step: 6
Training loss: 2.199077606201172
Validation loss: 2.0241716504096985

Epoch: 5| Step: 7
Training loss: 1.8858473300933838
Validation loss: 2.0250092347462973

Epoch: 5| Step: 8
Training loss: 2.1960861682891846
Validation loss: 2.0240977704524994

Epoch: 5| Step: 9
Training loss: 2.249657392501831
Validation loss: 2.021095017592112

Epoch: 5| Step: 10
Training loss: 1.8251787424087524
Validation loss: 2.0206755846738815

Epoch: 5| Step: 11
Training loss: 2.323089599609375
Validation loss: 2.0163497825463614

Epoch: 128| Step: 0
Training loss: 1.6595332622528076
Validation loss: 2.0275509357452393

Epoch: 5| Step: 1
Training loss: 1.8075815439224243
Validation loss: 2.0378501415252686

Epoch: 5| Step: 2
Training loss: 1.9191467761993408
Validation loss: 2.0399461835622787

Epoch: 5| Step: 3
Training loss: 2.6698620319366455
Validation loss: 2.0480657120545707

Epoch: 5| Step: 4
Training loss: 2.131936550140381
Validation loss: 2.0483987232049308

Epoch: 5| Step: 5
Training loss: 2.0124473571777344
Validation loss: 2.0497149179379144

Epoch: 5| Step: 6
Training loss: 2.3316028118133545
Validation loss: 2.044130265712738

Epoch: 5| Step: 7
Training loss: 2.1456847190856934
Validation loss: 2.0489180187384286

Epoch: 5| Step: 8
Training loss: 2.2102417945861816
Validation loss: 2.0395808815956116

Epoch: 5| Step: 9
Training loss: 2.0359275341033936
Validation loss: 2.045155535141627

Epoch: 5| Step: 10
Training loss: 2.4705910682678223
Validation loss: 2.033125420411428

Epoch: 5| Step: 11
Training loss: 1.9980626106262207
Validation loss: 2.028028647104899

Epoch: 129| Step: 0
Training loss: 2.2675490379333496
Validation loss: 2.025124048193296

Epoch: 5| Step: 1
Training loss: 2.2093632221221924
Validation loss: 2.0230611910422645

Epoch: 5| Step: 2
Training loss: 2.1842761039733887
Validation loss: 2.022233466307322

Epoch: 5| Step: 3
Training loss: 1.8172365427017212
Validation loss: 2.017753486831983

Epoch: 5| Step: 4
Training loss: 1.991884469985962
Validation loss: 2.014049003521601

Epoch: 5| Step: 5
Training loss: 1.8137212991714478
Validation loss: 2.012062852581342

Epoch: 5| Step: 6
Training loss: 1.9992930889129639
Validation loss: 2.0158234337965646

Epoch: 5| Step: 7
Training loss: 1.904772400856018
Validation loss: 2.0112743973731995

Epoch: 5| Step: 8
Training loss: 2.4879138469696045
Validation loss: 2.0112662663062415

Epoch: 5| Step: 9
Training loss: 2.7255513668060303
Validation loss: 2.015497704346975

Epoch: 5| Step: 10
Training loss: 1.790130376815796
Validation loss: 2.0158741921186447

Epoch: 5| Step: 11
Training loss: 2.0752646923065186
Validation loss: 2.0158375203609467

Epoch: 130| Step: 0
Training loss: 1.5147945880889893
Validation loss: 2.020661016305288

Epoch: 5| Step: 1
Training loss: 2.1470999717712402
Validation loss: 2.028788944085439

Epoch: 5| Step: 2
Training loss: 2.452353000640869
Validation loss: 2.039211094379425

Epoch: 5| Step: 3
Training loss: 2.7294921875
Validation loss: 2.0455312033494315

Epoch: 5| Step: 4
Training loss: 1.412077784538269
Validation loss: 2.042708237965902

Epoch: 5| Step: 5
Training loss: 2.0606706142425537
Validation loss: 2.054096539815267

Epoch: 5| Step: 6
Training loss: 1.8908634185791016
Validation loss: 2.043915644288063

Epoch: 5| Step: 7
Training loss: 2.2770285606384277
Validation loss: 2.0390349676211676

Epoch: 5| Step: 8
Training loss: 2.648721694946289
Validation loss: 2.0475571552912393

Epoch: 5| Step: 9
Training loss: 1.9887611865997314
Validation loss: 2.0389015823602676

Epoch: 5| Step: 10
Training loss: 2.2213432788848877
Validation loss: 2.029337520400683

Epoch: 5| Step: 11
Training loss: 1.657781958580017
Validation loss: 2.0232810775438943

Epoch: 131| Step: 0
Training loss: 1.9621574878692627
Validation loss: 2.0244544744491577

Epoch: 5| Step: 1
Training loss: 2.3829185962677
Validation loss: 2.010571708281835

Epoch: 5| Step: 2
Training loss: 2.472792863845825
Validation loss: 2.011408324042956

Epoch: 5| Step: 3
Training loss: 2.2754874229431152
Validation loss: 2.013196428616842

Epoch: 5| Step: 4
Training loss: 2.475067615509033
Validation loss: 2.0201449394226074

Epoch: 5| Step: 5
Training loss: 1.7011594772338867
Validation loss: 2.0135818322499595

Epoch: 5| Step: 6
Training loss: 1.8753687143325806
Validation loss: 2.0153637876113257

Epoch: 5| Step: 7
Training loss: 2.082442045211792
Validation loss: 2.015723849336306

Epoch: 5| Step: 8
Training loss: 1.7396600246429443
Validation loss: 2.022503445545832

Epoch: 5| Step: 9
Training loss: 2.2313947677612305
Validation loss: 2.016460264722506

Epoch: 5| Step: 10
Training loss: 2.1332457065582275
Validation loss: 2.02491886417071

Epoch: 5| Step: 11
Training loss: 2.0257179737091064
Validation loss: 2.0278672575950623

Epoch: 132| Step: 0
Training loss: 1.8040883541107178
Validation loss: 2.0303856829802194

Epoch: 5| Step: 1
Training loss: 1.8144642114639282
Validation loss: 2.0352922727664313

Epoch: 5| Step: 2
Training loss: 2.097425937652588
Validation loss: 2.038289318482081

Epoch: 5| Step: 3
Training loss: 1.4099609851837158
Validation loss: 2.043122266729673

Epoch: 5| Step: 4
Training loss: 2.297210693359375
Validation loss: 2.0406857828299203

Epoch: 5| Step: 5
Training loss: 2.0684127807617188
Validation loss: 2.0434087415536246

Epoch: 5| Step: 6
Training loss: 2.3537654876708984
Validation loss: 2.0401315043369928

Epoch: 5| Step: 7
Training loss: 2.478882312774658
Validation loss: 2.0593522836764655

Epoch: 5| Step: 8
Training loss: 1.9204063415527344
Validation loss: 2.053516740600268

Epoch: 5| Step: 9
Training loss: 2.0675806999206543
Validation loss: 2.0560558487971625

Epoch: 5| Step: 10
Training loss: 2.4949522018432617
Validation loss: 2.0447687904040017

Epoch: 5| Step: 11
Training loss: 3.0460703372955322
Validation loss: 2.0476022958755493

Epoch: 133| Step: 0
Training loss: 2.008584976196289
Validation loss: 2.051854064067205

Epoch: 5| Step: 1
Training loss: 2.572014808654785
Validation loss: 2.0351382543643317

Epoch: 5| Step: 2
Training loss: 1.6589254140853882
Validation loss: 2.032812391718229

Epoch: 5| Step: 3
Training loss: 1.748904824256897
Validation loss: 2.030390188097954

Epoch: 5| Step: 4
Training loss: 1.9810359477996826
Validation loss: 2.0413768887519836

Epoch: 5| Step: 5
Training loss: 2.1846675872802734
Validation loss: 2.025465731819471

Epoch: 5| Step: 6
Training loss: 2.132106065750122
Validation loss: 2.02752777437369

Epoch: 5| Step: 7
Training loss: 2.308650255203247
Validation loss: 2.0322579940160117

Epoch: 5| Step: 8
Training loss: 1.7962192296981812
Validation loss: 2.021145299077034

Epoch: 5| Step: 9
Training loss: 2.198448657989502
Validation loss: 2.0217802276213965

Epoch: 5| Step: 10
Training loss: 2.4925079345703125
Validation loss: 2.01966392993927

Epoch: 5| Step: 11
Training loss: 1.042906403541565
Validation loss: 2.0139297445615134

Epoch: 134| Step: 0
Training loss: 1.91616952419281
Validation loss: 2.016946330666542

Epoch: 5| Step: 1
Training loss: 1.1564182043075562
Validation loss: 2.021504412094752

Epoch: 5| Step: 2
Training loss: 2.4765937328338623
Validation loss: 2.028011361757914

Epoch: 5| Step: 3
Training loss: 2.3070342540740967
Validation loss: 2.023264373342196

Epoch: 5| Step: 4
Training loss: 2.1208839416503906
Validation loss: 2.023185431957245

Epoch: 5| Step: 5
Training loss: 2.155918598175049
Validation loss: 2.02501014371713

Epoch: 5| Step: 6
Training loss: 1.6162912845611572
Validation loss: 2.024477635820707

Epoch: 5| Step: 7
Training loss: 2.7451062202453613
Validation loss: 2.0274651994307837

Epoch: 5| Step: 8
Training loss: 2.271383285522461
Validation loss: 2.0213964581489563

Epoch: 5| Step: 9
Training loss: 2.3951363563537598
Validation loss: 2.0284436543782554

Epoch: 5| Step: 10
Training loss: 1.8887956142425537
Validation loss: 2.0238727728525796

Epoch: 5| Step: 11
Training loss: 1.4988170862197876
Validation loss: 2.022575984398524

Epoch: 135| Step: 0
Training loss: 2.1700968742370605
Validation loss: 2.015039245287577

Epoch: 5| Step: 1
Training loss: 2.258226156234741
Validation loss: 2.0171308666467667

Epoch: 5| Step: 2
Training loss: 2.2796003818511963
Validation loss: 2.026520093282064

Epoch: 5| Step: 3
Training loss: 1.8529884815216064
Validation loss: 2.022493173678716

Epoch: 5| Step: 4
Training loss: 2.3611018657684326
Validation loss: 2.027528723080953

Epoch: 5| Step: 5
Training loss: 2.2512662410736084
Validation loss: 2.0251092861096063

Epoch: 5| Step: 6
Training loss: 2.754488706588745
Validation loss: 2.0267626543839774

Epoch: 5| Step: 7
Training loss: 2.1124513149261475
Validation loss: 2.022529810667038

Epoch: 5| Step: 8
Training loss: 1.7525246143341064
Validation loss: 2.03102741142114

Epoch: 5| Step: 9
Training loss: 1.968187689781189
Validation loss: 2.0325463513533273

Epoch: 5| Step: 10
Training loss: 1.5032012462615967
Validation loss: 2.0285603255033493

Epoch: 5| Step: 11
Training loss: 1.9376685619354248
Validation loss: 2.034005398551623

Epoch: 136| Step: 0
Training loss: 1.9442813396453857
Validation loss: 2.0288595060507455

Epoch: 5| Step: 1
Training loss: 1.9082237482070923
Validation loss: 2.035169223944346

Epoch: 5| Step: 2
Training loss: 2.5998127460479736
Validation loss: 2.0397390176852546

Epoch: 5| Step: 3
Training loss: 2.0124011039733887
Validation loss: 2.0350063840548196

Epoch: 5| Step: 4
Training loss: 2.4106051921844482
Validation loss: 2.0430033653974533

Epoch: 5| Step: 5
Training loss: 2.101128339767456
Validation loss: 2.041636645793915

Epoch: 5| Step: 6
Training loss: 1.9100494384765625
Validation loss: 2.0338825384775796

Epoch: 5| Step: 7
Training loss: 2.1013855934143066
Validation loss: 2.0339558819929757

Epoch: 5| Step: 8
Training loss: 2.1541781425476074
Validation loss: 2.0375246355930963

Epoch: 5| Step: 9
Training loss: 2.0451483726501465
Validation loss: 2.047455832362175

Epoch: 5| Step: 10
Training loss: 1.895603895187378
Validation loss: 2.0409287263949714

Epoch: 5| Step: 11
Training loss: 1.6868512630462646
Validation loss: 2.0420081118742623

Epoch: 137| Step: 0
Training loss: 1.8626701831817627
Validation loss: 2.0463742166757584

Epoch: 5| Step: 1
Training loss: 1.9606115818023682
Validation loss: 2.0477065990368524

Epoch: 5| Step: 2
Training loss: 2.361569881439209
Validation loss: 2.0530168314774833

Epoch: 5| Step: 3
Training loss: 2.5519092082977295
Validation loss: 2.051696260770162

Epoch: 5| Step: 4
Training loss: 2.571937084197998
Validation loss: 2.06056609749794

Epoch: 5| Step: 5
Training loss: 2.170907497406006
Validation loss: 2.0425905535618463

Epoch: 5| Step: 6
Training loss: 1.4504404067993164
Validation loss: 2.05160483221213

Epoch: 5| Step: 7
Training loss: 1.9081294536590576
Validation loss: 2.0416857302188873

Epoch: 5| Step: 8
Training loss: 1.9139506816864014
Validation loss: 2.0350612898667655

Epoch: 5| Step: 9
Training loss: 1.9155855178833008
Validation loss: 2.041934311389923

Epoch: 5| Step: 10
Training loss: 2.5096685886383057
Validation loss: 2.0373849123716354

Epoch: 5| Step: 11
Training loss: 1.371954321861267
Validation loss: 2.0355759412050247

Epoch: 138| Step: 0
Training loss: 2.0572338104248047
Validation loss: 2.028572599093119

Epoch: 5| Step: 1
Training loss: 2.0327398777008057
Validation loss: 2.0366061478853226

Epoch: 5| Step: 2
Training loss: 1.6155760288238525
Validation loss: 2.037633935610453

Epoch: 5| Step: 3
Training loss: 1.7434638738632202
Validation loss: 2.0292288959026337

Epoch: 5| Step: 4
Training loss: 2.4204530715942383
Validation loss: 2.0351360390583673

Epoch: 5| Step: 5
Training loss: 2.0122718811035156
Validation loss: 2.032523920138677

Epoch: 5| Step: 6
Training loss: 2.096019744873047
Validation loss: 2.0328305661678314

Epoch: 5| Step: 7
Training loss: 2.1760177612304688
Validation loss: 2.024119352300962

Epoch: 5| Step: 8
Training loss: 2.106680393218994
Validation loss: 2.035147895415624

Epoch: 5| Step: 9
Training loss: 2.5949039459228516
Validation loss: 2.028970867395401

Epoch: 5| Step: 10
Training loss: 2.169304370880127
Validation loss: 2.038605034351349

Epoch: 5| Step: 11
Training loss: 1.747359037399292
Validation loss: 2.030188649892807

Epoch: 139| Step: 0
Training loss: 2.1535305976867676
Validation loss: 2.045166259010633

Epoch: 5| Step: 1
Training loss: 1.919445276260376
Validation loss: 2.0455581545829773

Epoch: 5| Step: 2
Training loss: 2.828680992126465
Validation loss: 2.051780049999555

Epoch: 5| Step: 3
Training loss: 2.2203521728515625
Validation loss: 2.078878919283549

Epoch: 5| Step: 4
Training loss: 2.623319625854492
Validation loss: 2.104298715790113

Epoch: 5| Step: 5
Training loss: 2.1993467807769775
Validation loss: 2.1104046354691186

Epoch: 5| Step: 6
Training loss: 2.2531821727752686
Validation loss: 2.1190068622430167

Epoch: 5| Step: 7
Training loss: 1.2991195917129517
Validation loss: 2.097335696220398

Epoch: 5| Step: 8
Training loss: 2.29811692237854
Validation loss: 2.0903587887684503

Epoch: 5| Step: 9
Training loss: 2.174983263015747
Validation loss: 2.0497879485289254

Epoch: 5| Step: 10
Training loss: 1.7118682861328125
Validation loss: 2.0349721163511276

Epoch: 5| Step: 11
Training loss: 1.8936669826507568
Validation loss: 2.0413477470477424

Epoch: 140| Step: 0
Training loss: 1.7785594463348389
Validation loss: 2.042962983250618

Epoch: 5| Step: 1
Training loss: 2.7039437294006348
Validation loss: 2.0316413591305413

Epoch: 5| Step: 2
Training loss: 1.9897829294204712
Validation loss: 2.0372881392637887

Epoch: 5| Step: 3
Training loss: 2.2628238201141357
Validation loss: 2.035752092798551

Epoch: 5| Step: 4
Training loss: 2.0968639850616455
Validation loss: 2.0358306070168815

Epoch: 5| Step: 5
Training loss: 2.26360821723938
Validation loss: 2.0397301614284515

Epoch: 5| Step: 6
Training loss: 2.0537753105163574
Validation loss: 2.0427036732435226

Epoch: 5| Step: 7
Training loss: 1.9731113910675049
Validation loss: 2.0377191553513208

Epoch: 5| Step: 8
Training loss: 2.0340938568115234
Validation loss: 2.039060816168785

Epoch: 5| Step: 9
Training loss: 1.678053617477417
Validation loss: 2.0384126752614975

Epoch: 5| Step: 10
Training loss: 2.196110963821411
Validation loss: 2.044412155946096

Epoch: 5| Step: 11
Training loss: 2.4861676692962646
Validation loss: 2.041840801636378

Epoch: 141| Step: 0
Training loss: 1.9122434854507446
Validation loss: 2.0375667115052543

Epoch: 5| Step: 1
Training loss: 2.091083526611328
Validation loss: 2.038511653741201

Epoch: 5| Step: 2
Training loss: 2.451526403427124
Validation loss: 2.043199360370636

Epoch: 5| Step: 3
Training loss: 2.011852264404297
Validation loss: 2.0416934887568154

Epoch: 5| Step: 4
Training loss: 1.9483916759490967
Validation loss: 2.0412189910809198

Epoch: 5| Step: 5
Training loss: 2.653733015060425
Validation loss: 2.0419226785500846

Epoch: 5| Step: 6
Training loss: 2.0840752124786377
Validation loss: 2.0330694069465003

Epoch: 5| Step: 7
Training loss: 2.1815929412841797
Validation loss: 2.034080525239309

Epoch: 5| Step: 8
Training loss: 1.8288853168487549
Validation loss: 2.037278105815252

Epoch: 5| Step: 9
Training loss: 1.5284768342971802
Validation loss: 2.0292787303527198

Epoch: 5| Step: 10
Training loss: 2.1936709880828857
Validation loss: 2.035775532325109

Epoch: 5| Step: 11
Training loss: 2.029526710510254
Validation loss: 2.0254219075043998

Epoch: 142| Step: 0
Training loss: 2.1654274463653564
Validation loss: 2.0390523076057434

Epoch: 5| Step: 1
Training loss: 1.7455596923828125
Validation loss: 2.0417761454979577

Epoch: 5| Step: 2
Training loss: 2.606846570968628
Validation loss: 2.0507291704416275

Epoch: 5| Step: 3
Training loss: 2.0967934131622314
Validation loss: 2.0580204327901206

Epoch: 5| Step: 4
Training loss: 2.659794330596924
Validation loss: 2.0545293440421424

Epoch: 5| Step: 5
Training loss: 1.779247522354126
Validation loss: 2.0583516160647073

Epoch: 5| Step: 6
Training loss: 1.9448601007461548
Validation loss: 2.056079243620237

Epoch: 5| Step: 7
Training loss: 2.1151599884033203
Validation loss: 2.041816234588623

Epoch: 5| Step: 8
Training loss: 2.0862910747528076
Validation loss: 2.034013499816259

Epoch: 5| Step: 9
Training loss: 2.159241199493408
Validation loss: 2.031677410006523

Epoch: 5| Step: 10
Training loss: 1.8214778900146484
Validation loss: 2.028250758846601

Epoch: 5| Step: 11
Training loss: 1.150086760520935
Validation loss: 2.025661145647367

Epoch: 143| Step: 0
Training loss: 2.0814805030822754
Validation loss: 2.0366631746292114

Epoch: 5| Step: 1
Training loss: 2.8994221687316895
Validation loss: 2.032146766781807

Epoch: 5| Step: 2
Training loss: 2.483297348022461
Validation loss: 2.0313815077145896

Epoch: 5| Step: 3
Training loss: 1.9370298385620117
Validation loss: 2.0372859785954156

Epoch: 5| Step: 4
Training loss: 2.3124637603759766
Validation loss: 2.040260925889015

Epoch: 5| Step: 5
Training loss: 2.000072956085205
Validation loss: 2.0244768311580024

Epoch: 5| Step: 6
Training loss: 1.9661880731582642
Validation loss: 2.0305390308300653

Epoch: 5| Step: 7
Training loss: 1.9565225839614868
Validation loss: 2.0317746003468833

Epoch: 5| Step: 8
Training loss: 2.063581943511963
Validation loss: 2.0347678562005362

Epoch: 5| Step: 9
Training loss: 1.2519996166229248
Validation loss: 2.032458797097206

Epoch: 5| Step: 10
Training loss: 2.205456256866455
Validation loss: 2.0311641842126846

Epoch: 5| Step: 11
Training loss: 1.443648099899292
Validation loss: 2.0279321571191153

Epoch: 144| Step: 0
Training loss: 1.8191992044448853
Validation loss: 2.02797398964564

Epoch: 5| Step: 1
Training loss: 1.9672346115112305
Validation loss: 2.0311810870965323

Epoch: 5| Step: 2
Training loss: 1.8800694942474365
Validation loss: 2.0256974597771964

Epoch: 5| Step: 3
Training loss: 2.1344213485717773
Validation loss: 2.0271408458550773

Epoch: 5| Step: 4
Training loss: 2.171719789505005
Validation loss: 2.0237268259127936

Epoch: 5| Step: 5
Training loss: 2.3116352558135986
Validation loss: 2.028490220506986

Epoch: 5| Step: 6
Training loss: 2.2166409492492676
Validation loss: 2.0287150045235953

Epoch: 5| Step: 7
Training loss: 2.2445623874664307
Validation loss: 2.0296744008859

Epoch: 5| Step: 8
Training loss: 1.4482792615890503
Validation loss: 2.0339363664388657

Epoch: 5| Step: 9
Training loss: 2.3120779991149902
Validation loss: 2.0370135605335236

Epoch: 5| Step: 10
Training loss: 2.3038601875305176
Validation loss: 2.0243813892205558

Epoch: 5| Step: 11
Training loss: 1.8851906061172485
Validation loss: 2.0407391091187796

Epoch: 145| Step: 0
Training loss: 2.113765001296997
Validation loss: 2.0289547443389893

Epoch: 5| Step: 1
Training loss: 2.2843332290649414
Validation loss: 2.034497598807017

Epoch: 5| Step: 2
Training loss: 2.2294275760650635
Validation loss: 2.037527104218801

Epoch: 5| Step: 3
Training loss: 1.9034843444824219
Validation loss: 2.0284931510686874

Epoch: 5| Step: 4
Training loss: 1.6208842992782593
Validation loss: 2.0236465533574424

Epoch: 5| Step: 5
Training loss: 2.549203395843506
Validation loss: 2.0326553285121918

Epoch: 5| Step: 6
Training loss: 2.4066309928894043
Validation loss: 2.034742126862208

Epoch: 5| Step: 7
Training loss: 2.2813720703125
Validation loss: 2.034689406553904

Epoch: 5| Step: 8
Training loss: 1.7173471450805664
Validation loss: 2.0351762821276984

Epoch: 5| Step: 9
Training loss: 1.9379373788833618
Validation loss: 2.0277988016605377

Epoch: 5| Step: 10
Training loss: 1.6443191766738892
Validation loss: 2.0372848908106485

Epoch: 5| Step: 11
Training loss: 2.363471031188965
Validation loss: 2.027038981517156

Epoch: 146| Step: 0
Training loss: 1.8620002269744873
Validation loss: 2.0249984761079154

Epoch: 5| Step: 1
Training loss: 2.3309133052825928
Validation loss: 2.034787272413572

Epoch: 5| Step: 2
Training loss: 1.526086688041687
Validation loss: 2.0329850862423577

Epoch: 5| Step: 3
Training loss: 2.5133090019226074
Validation loss: 2.027065376440684

Epoch: 5| Step: 4
Training loss: 2.334446668624878
Validation loss: 2.0294172366460166

Epoch: 5| Step: 5
Training loss: 1.990159034729004
Validation loss: 2.0254878252744675

Epoch: 5| Step: 6
Training loss: 1.8057887554168701
Validation loss: 2.0318745026985803

Epoch: 5| Step: 7
Training loss: 2.4127094745635986
Validation loss: 2.027125890056292

Epoch: 5| Step: 8
Training loss: 2.054569959640503
Validation loss: 2.0422849307457605

Epoch: 5| Step: 9
Training loss: 2.3540616035461426
Validation loss: 2.0299297074476876

Epoch: 5| Step: 10
Training loss: 1.5688891410827637
Validation loss: 2.0266866385936737

Epoch: 5| Step: 11
Training loss: 1.5972089767456055
Validation loss: 2.0345688611268997

Epoch: 147| Step: 0
Training loss: 2.4052939414978027
Validation loss: 2.0368302116791406

Epoch: 5| Step: 1
Training loss: 1.9922573566436768
Validation loss: 2.0277456045150757

Epoch: 5| Step: 2
Training loss: 1.4993940591812134
Validation loss: 2.032135531306267

Epoch: 5| Step: 3
Training loss: 1.9712188243865967
Validation loss: 2.0346473107735314

Epoch: 5| Step: 4
Training loss: 1.7320324182510376
Validation loss: 2.030987794200579

Epoch: 5| Step: 5
Training loss: 2.177159547805786
Validation loss: 2.035942037900289

Epoch: 5| Step: 6
Training loss: 2.253042697906494
Validation loss: 2.0396485527356467

Epoch: 5| Step: 7
Training loss: 2.5481197834014893
Validation loss: 2.02896456917127

Epoch: 5| Step: 8
Training loss: 1.6210572719573975
Validation loss: 2.031123777230581

Epoch: 5| Step: 9
Training loss: 2.0747992992401123
Validation loss: 2.034430652856827

Epoch: 5| Step: 10
Training loss: 2.281256914138794
Validation loss: 2.042678326368332

Epoch: 5| Step: 11
Training loss: 2.3613014221191406
Validation loss: 2.0347333749135337

Epoch: 148| Step: 0
Training loss: 1.7807018756866455
Validation loss: 2.0472853581110635

Epoch: 5| Step: 1
Training loss: 2.310609817504883
Validation loss: 2.040211866299311

Epoch: 5| Step: 2
Training loss: 2.3466124534606934
Validation loss: 2.0345066487789154

Epoch: 5| Step: 3
Training loss: 2.2885756492614746
Validation loss: 2.044087385137876

Epoch: 5| Step: 4
Training loss: 2.17242693901062
Validation loss: 2.0622784942388535

Epoch: 5| Step: 5
Training loss: 2.218862771987915
Validation loss: 2.064563035964966

Epoch: 5| Step: 6
Training loss: 1.8605155944824219
Validation loss: 2.0689571549495063

Epoch: 5| Step: 7
Training loss: 1.896080732345581
Validation loss: 2.0768732676903405

Epoch: 5| Step: 8
Training loss: 2.2990832328796387
Validation loss: 2.0770974357922873

Epoch: 5| Step: 9
Training loss: 2.2068440914154053
Validation loss: 2.072523052493731

Epoch: 5| Step: 10
Training loss: 2.207388401031494
Validation loss: 2.076864088575045

Epoch: 5| Step: 11
Training loss: 2.5070104598999023
Validation loss: 2.0707718978325524

Epoch: 149| Step: 0
Training loss: 2.554161310195923
Validation loss: 2.065944418311119

Epoch: 5| Step: 1
Training loss: 2.165492534637451
Validation loss: 2.0611771841843924

Epoch: 5| Step: 2
Training loss: 2.3014276027679443
Validation loss: 2.0582523246606192

Epoch: 5| Step: 3
Training loss: 2.5394694805145264
Validation loss: 2.039930671453476

Epoch: 5| Step: 4
Training loss: 1.581298589706421
Validation loss: 2.0234827548265457

Epoch: 5| Step: 5
Training loss: 1.6662944555282593
Validation loss: 2.020189399520556

Epoch: 5| Step: 6
Training loss: 2.1916661262512207
Validation loss: 2.020728970567385

Epoch: 5| Step: 7
Training loss: 2.311068058013916
Validation loss: 2.0148472785949707

Epoch: 5| Step: 8
Training loss: 2.396320343017578
Validation loss: 2.019535486896833

Epoch: 5| Step: 9
Training loss: 1.8508663177490234
Validation loss: 2.013599380850792

Epoch: 5| Step: 10
Training loss: 1.8291070461273193
Validation loss: 2.0223255356152854

Epoch: 5| Step: 11
Training loss: 1.6584794521331787
Validation loss: 2.0282916774352393

Epoch: 150| Step: 0
Training loss: 1.6682002544403076
Validation loss: 2.0309077302614846

Epoch: 5| Step: 1
Training loss: 2.446643829345703
Validation loss: 2.0246059000492096

Epoch: 5| Step: 2
Training loss: 2.0247795581817627
Validation loss: 2.0355571806430817

Epoch: 5| Step: 3
Training loss: 2.080026626586914
Validation loss: 2.0246797452370324

Epoch: 5| Step: 4
Training loss: 2.2504007816314697
Validation loss: 2.020352075497309

Epoch: 5| Step: 5
Training loss: 1.9093620777130127
Validation loss: 2.0289028783639274

Epoch: 5| Step: 6
Training loss: 2.104808807373047
Validation loss: 2.0199415435393653

Epoch: 5| Step: 7
Training loss: 1.958847999572754
Validation loss: 2.0126554717620215

Epoch: 5| Step: 8
Training loss: 1.8057823181152344
Validation loss: 2.0162905007600784

Epoch: 5| Step: 9
Training loss: 2.6349616050720215
Validation loss: 2.018322318792343

Epoch: 5| Step: 10
Training loss: 1.7910321950912476
Validation loss: 2.0157004594802856

Epoch: 5| Step: 11
Training loss: 2.771462917327881
Validation loss: 2.0257292836904526

Epoch: 151| Step: 0
Training loss: 2.2150700092315674
Validation loss: 2.0205308894316354

Epoch: 5| Step: 1
Training loss: 2.2455296516418457
Validation loss: 2.025612091024717

Epoch: 5| Step: 2
Training loss: 1.9963716268539429
Validation loss: 2.0206350485483804

Epoch: 5| Step: 3
Training loss: 1.7106918096542358
Validation loss: 2.013823534051577

Epoch: 5| Step: 4
Training loss: 2.7080204486846924
Validation loss: 2.0261956502993903

Epoch: 5| Step: 5
Training loss: 1.5191915035247803
Validation loss: 2.024025266369184

Epoch: 5| Step: 6
Training loss: 2.2923524379730225
Validation loss: 2.0133753965298333

Epoch: 5| Step: 7
Training loss: 1.946930170059204
Validation loss: 2.0295703460772834

Epoch: 5| Step: 8
Training loss: 1.853039026260376
Validation loss: 2.019159014026324

Epoch: 5| Step: 9
Training loss: 2.3011550903320312
Validation loss: 2.0116054515043893

Epoch: 5| Step: 10
Training loss: 1.8832536935806274
Validation loss: 2.021457423766454

Epoch: 5| Step: 11
Training loss: 1.8976311683654785
Validation loss: 2.0237586895624795

Epoch: 152| Step: 0
Training loss: 2.448397159576416
Validation loss: 2.026310697197914

Epoch: 5| Step: 1
Training loss: 1.7922954559326172
Validation loss: 2.023113494118055

Epoch: 5| Step: 2
Training loss: 2.3217735290527344
Validation loss: 2.0239801605542502

Epoch: 5| Step: 3
Training loss: 2.4324727058410645
Validation loss: 2.0337258776028952

Epoch: 5| Step: 4
Training loss: 1.6875321865081787
Validation loss: 2.0317866504192352

Epoch: 5| Step: 5
Training loss: 2.0550460815429688
Validation loss: 2.0278582175572715

Epoch: 5| Step: 6
Training loss: 1.8930145502090454
Validation loss: 2.0319048861662545

Epoch: 5| Step: 7
Training loss: 1.6140310764312744
Validation loss: 2.0299108922481537

Epoch: 5| Step: 8
Training loss: 2.405503988265991
Validation loss: 2.0211579153935113

Epoch: 5| Step: 9
Training loss: 1.6447054147720337
Validation loss: 2.012858251730601

Epoch: 5| Step: 10
Training loss: 2.536670684814453
Validation loss: 2.0241363445917764

Epoch: 5| Step: 11
Training loss: 0.8273990154266357
Validation loss: 2.025717929005623

Epoch: 153| Step: 0
Training loss: 1.8236163854599
Validation loss: 2.026148810982704

Epoch: 5| Step: 1
Training loss: 2.226519823074341
Validation loss: 2.0254514118035636

Epoch: 5| Step: 2
Training loss: 1.8343385457992554
Validation loss: 2.027107059955597

Epoch: 5| Step: 3
Training loss: 1.9748468399047852
Validation loss: 2.0233703553676605

Epoch: 5| Step: 4
Training loss: 2.072486400604248
Validation loss: 2.023262878259023

Epoch: 5| Step: 5
Training loss: 1.9414052963256836
Validation loss: 2.012048756082853

Epoch: 5| Step: 6
Training loss: 1.5938771963119507
Validation loss: 2.015727107723554

Epoch: 5| Step: 7
Training loss: 1.8958772420883179
Validation loss: 2.0155176917711892

Epoch: 5| Step: 8
Training loss: 2.78233003616333
Validation loss: 2.023671726385752

Epoch: 5| Step: 9
Training loss: 1.9747177362442017
Validation loss: 2.026566351453463

Epoch: 5| Step: 10
Training loss: 2.522439479827881
Validation loss: 2.0401192009449005

Epoch: 5| Step: 11
Training loss: 2.601490020751953
Validation loss: 2.0465006778637567

Epoch: 154| Step: 0
Training loss: 2.0172131061553955
Validation loss: 2.0368894934654236

Epoch: 5| Step: 1
Training loss: 2.2032546997070312
Validation loss: 2.0409365197022757

Epoch: 5| Step: 2
Training loss: 1.8774464130401611
Validation loss: 2.03912782172362

Epoch: 5| Step: 3
Training loss: 1.8814105987548828
Validation loss: 2.0499903162320456

Epoch: 5| Step: 4
Training loss: 2.109423875808716
Validation loss: 2.0581167737642923

Epoch: 5| Step: 5
Training loss: 1.9649198055267334
Validation loss: 2.04246257742246

Epoch: 5| Step: 6
Training loss: 1.8632280826568604
Validation loss: 2.0375052243471146

Epoch: 5| Step: 7
Training loss: 2.7024173736572266
Validation loss: 2.0376542508602142

Epoch: 5| Step: 8
Training loss: 1.6393859386444092
Validation loss: 2.0427170793215432

Epoch: 5| Step: 9
Training loss: 2.2984938621520996
Validation loss: 2.0489392230908074

Epoch: 5| Step: 10
Training loss: 1.9619905948638916
Validation loss: 2.0427164485057197

Epoch: 5| Step: 11
Training loss: 2.5971803665161133
Validation loss: 2.042519266406695

Epoch: 155| Step: 0
Training loss: 1.7288042306900024
Validation loss: 2.0362741847833

Epoch: 5| Step: 1
Training loss: 2.115353584289551
Validation loss: 2.0314347743988037

Epoch: 5| Step: 2
Training loss: 2.431995391845703
Validation loss: 2.034835477670034

Epoch: 5| Step: 3
Training loss: 1.9676717519760132
Validation loss: 2.039399509628614

Epoch: 5| Step: 4
Training loss: 1.5200811624526978
Validation loss: 2.0374061167240143

Epoch: 5| Step: 5
Training loss: 2.387021541595459
Validation loss: 2.0332123190164566

Epoch: 5| Step: 6
Training loss: 2.629258155822754
Validation loss: 2.0328503400087357

Epoch: 5| Step: 7
Training loss: 1.904793381690979
Validation loss: 2.0260444631179175

Epoch: 5| Step: 8
Training loss: 2.264955997467041
Validation loss: 2.0296493420998254

Epoch: 5| Step: 9
Training loss: 1.9081920385360718
Validation loss: 2.025370021661123

Epoch: 5| Step: 10
Training loss: 1.5532995462417603
Validation loss: 2.0277179976304374

Epoch: 5| Step: 11
Training loss: 3.223954677581787
Validation loss: 2.0325116018454232

Epoch: 156| Step: 0
Training loss: 2.3669521808624268
Validation loss: 2.023151248693466

Epoch: 5| Step: 1
Training loss: 2.432551860809326
Validation loss: 2.0327124247948327

Epoch: 5| Step: 2
Training loss: 1.4522918462753296
Validation loss: 2.041432316104571

Epoch: 5| Step: 3
Training loss: 1.7665828466415405
Validation loss: 2.037683660785357

Epoch: 5| Step: 4
Training loss: 2.1500627994537354
Validation loss: 2.0269700090090432

Epoch: 5| Step: 5
Training loss: 2.5070693492889404
Validation loss: 2.02480115989844

Epoch: 5| Step: 6
Training loss: 2.193068265914917
Validation loss: 2.0404720455408096

Epoch: 5| Step: 7
Training loss: 2.2103562355041504
Validation loss: 2.044926499327024

Epoch: 5| Step: 8
Training loss: 1.4229915142059326
Validation loss: 2.0381222863992057

Epoch: 5| Step: 9
Training loss: 1.8053258657455444
Validation loss: 2.037931799888611

Epoch: 5| Step: 10
Training loss: 2.1456379890441895
Validation loss: 2.0405773421128592

Epoch: 5| Step: 11
Training loss: 1.9554237127304077
Validation loss: 2.046057199438413

Epoch: 157| Step: 0
Training loss: 1.5626181364059448
Validation loss: 2.051612769563993

Epoch: 5| Step: 1
Training loss: 1.9528621435165405
Validation loss: 2.0420294801394143

Epoch: 5| Step: 2
Training loss: 2.119575023651123
Validation loss: 2.03410342335701

Epoch: 5| Step: 3
Training loss: 2.3421566486358643
Validation loss: 2.045244206984838

Epoch: 5| Step: 4
Training loss: 2.019151210784912
Validation loss: 2.0460915168126426

Epoch: 5| Step: 5
Training loss: 2.57375431060791
Validation loss: 2.0426316062609353

Epoch: 5| Step: 6
Training loss: 2.160830020904541
Validation loss: 2.0358660767475762

Epoch: 5| Step: 7
Training loss: 2.286778450012207
Validation loss: 2.0460756421089172

Epoch: 5| Step: 8
Training loss: 2.5834407806396484
Validation loss: 2.034427965680758

Epoch: 5| Step: 9
Training loss: 1.7647411823272705
Validation loss: 2.031683698296547

Epoch: 5| Step: 10
Training loss: 1.2844114303588867
Validation loss: 2.035655379295349

Epoch: 5| Step: 11
Training loss: 1.082160234451294
Validation loss: 2.0365984638532004

Epoch: 158| Step: 0
Training loss: 1.5411264896392822
Validation loss: 2.0400369266668954

Epoch: 5| Step: 1
Training loss: 2.3643202781677246
Validation loss: 2.0394078542788825

Epoch: 5| Step: 2
Training loss: 1.9773080348968506
Validation loss: 2.0374054362376532

Epoch: 5| Step: 3
Training loss: 1.5632755756378174
Validation loss: 2.0267472018798194

Epoch: 5| Step: 4
Training loss: 1.9786098003387451
Validation loss: 2.0304254243771234

Epoch: 5| Step: 5
Training loss: 2.0107598304748535
Validation loss: 2.016515259941419

Epoch: 5| Step: 6
Training loss: 2.0608363151550293
Validation loss: 2.0304913570483527

Epoch: 5| Step: 7
Training loss: 2.128345251083374
Validation loss: 2.0221088578303656

Epoch: 5| Step: 8
Training loss: 2.2555480003356934
Validation loss: 2.016780028740565

Epoch: 5| Step: 9
Training loss: 2.342318534851074
Validation loss: 2.022213503718376

Epoch: 5| Step: 10
Training loss: 2.6059746742248535
Validation loss: 2.0174890607595444

Epoch: 5| Step: 11
Training loss: 1.3785730600357056
Validation loss: 2.026300847530365

Epoch: 159| Step: 0
Training loss: 1.8824142217636108
Validation loss: 2.024430255095164

Epoch: 5| Step: 1
Training loss: 2.404172897338867
Validation loss: 2.028092309832573

Epoch: 5| Step: 2
Training loss: 2.200012683868408
Validation loss: 2.0234198917945228

Epoch: 5| Step: 3
Training loss: 2.419412136077881
Validation loss: 2.0365696350733438

Epoch: 5| Step: 4
Training loss: 1.8799461126327515
Validation loss: 2.023978978395462

Epoch: 5| Step: 5
Training loss: 2.2794058322906494
Validation loss: 2.034630368153254

Epoch: 5| Step: 6
Training loss: 1.421790599822998
Validation loss: 2.0372670143842697

Epoch: 5| Step: 7
Training loss: 1.6693086624145508
Validation loss: 2.0384528785943985

Epoch: 5| Step: 8
Training loss: 2.3799026012420654
Validation loss: 2.042428349455198

Epoch: 5| Step: 9
Training loss: 2.509356737136841
Validation loss: 2.03087525566419

Epoch: 5| Step: 10
Training loss: 1.4984687566757202
Validation loss: 2.040067786971728

Epoch: 5| Step: 11
Training loss: 1.6147546768188477
Validation loss: 2.0292019844055176

Epoch: 160| Step: 0
Training loss: 1.7818119525909424
Validation loss: 2.0387414395809174

Epoch: 5| Step: 1
Training loss: 1.895981788635254
Validation loss: 2.0445700039466224

Epoch: 5| Step: 2
Training loss: 2.158329725265503
Validation loss: 2.037753790616989

Epoch: 5| Step: 3
Training loss: 2.2236416339874268
Validation loss: 2.0357920080423355

Epoch: 5| Step: 4
Training loss: 1.9531314373016357
Validation loss: 2.046202704310417

Epoch: 5| Step: 5
Training loss: 1.7940555810928345
Validation loss: 2.041309436162313

Epoch: 5| Step: 6
Training loss: 2.151510715484619
Validation loss: 2.0404020100831985

Epoch: 5| Step: 7
Training loss: 2.195253372192383
Validation loss: 2.0359151860078177

Epoch: 5| Step: 8
Training loss: 2.3917975425720215
Validation loss: 2.042372480034828

Epoch: 5| Step: 9
Training loss: 1.9565216302871704
Validation loss: 2.030123417576154

Epoch: 5| Step: 10
Training loss: 2.1614699363708496
Validation loss: 2.0332777897516885

Epoch: 5| Step: 11
Training loss: 1.7944416999816895
Validation loss: 2.047137608130773

Epoch: 161| Step: 0
Training loss: 2.448655605316162
Validation loss: 2.0348894894123077

Epoch: 5| Step: 1
Training loss: 1.7284988164901733
Validation loss: 2.0420919160048165

Epoch: 5| Step: 2
Training loss: 2.1665232181549072
Validation loss: 2.0431916564702988

Epoch: 5| Step: 3
Training loss: 2.0546536445617676
Validation loss: 2.0310937265555062

Epoch: 5| Step: 4
Training loss: 2.1813547611236572
Validation loss: 2.0383828530708947

Epoch: 5| Step: 5
Training loss: 2.3045852184295654
Validation loss: 2.0383251508076987

Epoch: 5| Step: 6
Training loss: 1.9471008777618408
Validation loss: 2.0405446887016296

Epoch: 5| Step: 7
Training loss: 2.433016300201416
Validation loss: 2.0377469758192697

Epoch: 5| Step: 8
Training loss: 1.7686681747436523
Validation loss: 2.0252834955851235

Epoch: 5| Step: 9
Training loss: 1.5235785245895386
Validation loss: 2.030187502503395

Epoch: 5| Step: 10
Training loss: 1.8779586553573608
Validation loss: 2.038874144355456

Epoch: 5| Step: 11
Training loss: 2.137843608856201
Validation loss: 2.041608770688375

Epoch: 162| Step: 0
Training loss: 1.6808061599731445
Validation loss: 2.0368964274724326

Epoch: 5| Step: 1
Training loss: 2.1484768390655518
Validation loss: 2.0422126948833466

Epoch: 5| Step: 2
Training loss: 2.052290678024292
Validation loss: 2.039522002140681

Epoch: 5| Step: 3
Training loss: 1.7832481861114502
Validation loss: 2.0346454282601676

Epoch: 5| Step: 4
Training loss: 2.084975242614746
Validation loss: 2.036979705095291

Epoch: 5| Step: 5
Training loss: 1.9064416885375977
Validation loss: 2.031148756543795

Epoch: 5| Step: 6
Training loss: 2.1881206035614014
Validation loss: 2.043971081574758

Epoch: 5| Step: 7
Training loss: 2.7397379875183105
Validation loss: 2.0447236200173697

Epoch: 5| Step: 8
Training loss: 2.453091859817505
Validation loss: 2.036378855506579

Epoch: 5| Step: 9
Training loss: 1.7267951965332031
Validation loss: 2.0268973112106323

Epoch: 5| Step: 10
Training loss: 1.7877662181854248
Validation loss: 2.0325003316005072

Epoch: 5| Step: 11
Training loss: 1.804274559020996
Validation loss: 2.0313966373602548

Epoch: 163| Step: 0
Training loss: 1.950214147567749
Validation loss: 2.032766342163086

Epoch: 5| Step: 1
Training loss: 1.9365043640136719
Validation loss: 2.0294607132673264

Epoch: 5| Step: 2
Training loss: 2.1902198791503906
Validation loss: 2.0232080966234207

Epoch: 5| Step: 3
Training loss: 1.340457797050476
Validation loss: 2.032110611597697

Epoch: 5| Step: 4
Training loss: 2.241443157196045
Validation loss: 2.0313625733057656

Epoch: 5| Step: 5
Training loss: 1.731201171875
Validation loss: 2.0335236936807632

Epoch: 5| Step: 6
Training loss: 2.424769163131714
Validation loss: 2.0318016707897186

Epoch: 5| Step: 7
Training loss: 2.143528461456299
Validation loss: 2.0481415887673697

Epoch: 5| Step: 8
Training loss: 1.6708605289459229
Validation loss: 2.049794619282087

Epoch: 5| Step: 9
Training loss: 2.244816303253174
Validation loss: 2.0610360304514566

Epoch: 5| Step: 10
Training loss: 2.5319371223449707
Validation loss: 2.0616996536652246

Epoch: 5| Step: 11
Training loss: 3.156078577041626
Validation loss: 2.0568441251913705

Epoch: 164| Step: 0
Training loss: 1.9259557723999023
Validation loss: 2.0544108152389526

Epoch: 5| Step: 1
Training loss: 1.9689838886260986
Validation loss: 2.0634055385986962

Epoch: 5| Step: 2
Training loss: 1.6596336364746094
Validation loss: 2.046454682946205

Epoch: 5| Step: 3
Training loss: 2.3952925205230713
Validation loss: 2.043720026810964

Epoch: 5| Step: 4
Training loss: 2.72953200340271
Validation loss: 2.041120489438375

Epoch: 5| Step: 5
Training loss: 1.4275928735733032
Validation loss: 2.0466452538967133

Epoch: 5| Step: 6
Training loss: 1.7659990787506104
Validation loss: 2.034976050257683

Epoch: 5| Step: 7
Training loss: 1.7457687854766846
Validation loss: 2.0421402057011924

Epoch: 5| Step: 8
Training loss: 2.398367404937744
Validation loss: 2.030805160601934

Epoch: 5| Step: 9
Training loss: 2.3750226497650146
Validation loss: 2.0351633528868356

Epoch: 5| Step: 10
Training loss: 1.7879629135131836
Validation loss: 2.032863145073255

Epoch: 5| Step: 11
Training loss: 2.7103004455566406
Validation loss: 2.025137255589167

Epoch: 165| Step: 0
Training loss: 1.7981802225112915
Validation loss: 2.024433513482412

Epoch: 5| Step: 1
Training loss: 1.337039589881897
Validation loss: 2.0386522114276886

Epoch: 5| Step: 2
Training loss: 1.7604337930679321
Validation loss: 2.029676447312037

Epoch: 5| Step: 3
Training loss: 2.8220505714416504
Validation loss: 2.0255228777726493

Epoch: 5| Step: 4
Training loss: 2.2203619480133057
Validation loss: 2.027224918206533

Epoch: 5| Step: 5
Training loss: 2.0093071460723877
Validation loss: 2.0335116485754647

Epoch: 5| Step: 6
Training loss: 2.168584108352661
Validation loss: 2.0336250017086663

Epoch: 5| Step: 7
Training loss: 2.29579496383667
Validation loss: 2.0351490676403046

Epoch: 5| Step: 8
Training loss: 2.219532012939453
Validation loss: 2.0369013249874115

Epoch: 5| Step: 9
Training loss: 2.308931350708008
Validation loss: 2.044755215446154

Epoch: 5| Step: 10
Training loss: 1.707476019859314
Validation loss: 2.033811002969742

Epoch: 5| Step: 11
Training loss: 1.1219027042388916
Validation loss: 2.0394420276085534

Epoch: 166| Step: 0
Training loss: 2.1311872005462646
Validation loss: 2.0347211559613547

Epoch: 5| Step: 1
Training loss: 1.681460976600647
Validation loss: 2.033120478192965

Epoch: 5| Step: 2
Training loss: 1.6620352268218994
Validation loss: 2.030247246225675

Epoch: 5| Step: 3
Training loss: 1.979058027267456
Validation loss: 2.0437684108813605

Epoch: 5| Step: 4
Training loss: 2.1939730644226074
Validation loss: 2.040022333463033

Epoch: 5| Step: 5
Training loss: 1.7679208517074585
Validation loss: 2.0512901097536087

Epoch: 5| Step: 6
Training loss: 2.531100034713745
Validation loss: 2.0468631436427436

Epoch: 5| Step: 7
Training loss: 2.5692667961120605
Validation loss: 2.045160581668218

Epoch: 5| Step: 8
Training loss: 2.3745086193084717
Validation loss: 2.059217428167661

Epoch: 5| Step: 9
Training loss: 1.7271696329116821
Validation loss: 2.051129241784414

Epoch: 5| Step: 10
Training loss: 1.8585811853408813
Validation loss: 2.049798478682836

Epoch: 5| Step: 11
Training loss: 1.7465453147888184
Validation loss: 2.049164126316706

Epoch: 167| Step: 0
Training loss: 2.164351463317871
Validation loss: 2.036492104331652

Epoch: 5| Step: 1
Training loss: 1.851271390914917
Validation loss: 2.0366477320591607

Epoch: 5| Step: 2
Training loss: 2.3354170322418213
Validation loss: 2.030093396703402

Epoch: 5| Step: 3
Training loss: 2.066793203353882
Validation loss: 2.03270161151886

Epoch: 5| Step: 4
Training loss: 1.934946060180664
Validation loss: 2.024389828244845

Epoch: 5| Step: 5
Training loss: 2.3940412998199463
Validation loss: 2.01750614742438

Epoch: 5| Step: 6
Training loss: 1.9657999277114868
Validation loss: 2.0261081655820212

Epoch: 5| Step: 7
Training loss: 2.0981411933898926
Validation loss: 2.019576812783877

Epoch: 5| Step: 8
Training loss: 2.032024383544922
Validation loss: 2.013559475541115

Epoch: 5| Step: 9
Training loss: 1.8305418491363525
Validation loss: 2.0199908862511315

Epoch: 5| Step: 10
Training loss: 1.8041369915008545
Validation loss: 2.0231615702311196

Epoch: 5| Step: 11
Training loss: 2.5488059520721436
Validation loss: 2.013302509983381

Epoch: 168| Step: 0
Training loss: 1.8574825525283813
Validation loss: 2.031858200828234

Epoch: 5| Step: 1
Training loss: 1.9153034687042236
Validation loss: 2.0315816005071006

Epoch: 5| Step: 2
Training loss: 2.2272918224334717
Validation loss: 2.032852123181025

Epoch: 5| Step: 3
Training loss: 1.8985048532485962
Validation loss: 2.03124592701594

Epoch: 5| Step: 4
Training loss: 1.8430255651474
Validation loss: 2.037285407384237

Epoch: 5| Step: 5
Training loss: 2.4561047554016113
Validation loss: 2.0434813797473907

Epoch: 5| Step: 6
Training loss: 2.1638553142547607
Validation loss: 2.0449505001306534

Epoch: 5| Step: 7
Training loss: 2.228196620941162
Validation loss: 2.046406219402949

Epoch: 5| Step: 8
Training loss: 2.4554755687713623
Validation loss: 2.0521253744761148

Epoch: 5| Step: 9
Training loss: 1.5247712135314941
Validation loss: 2.038582513729731

Epoch: 5| Step: 10
Training loss: 1.8257896900177002
Validation loss: 2.0398046175638833

Epoch: 5| Step: 11
Training loss: 1.446480393409729
Validation loss: 2.037110522389412

Epoch: 169| Step: 0
Training loss: 2.3008475303649902
Validation loss: 2.0372426509857178

Epoch: 5| Step: 1
Training loss: 1.7862727642059326
Validation loss: 2.043629457553228

Epoch: 5| Step: 2
Training loss: 1.927411675453186
Validation loss: 2.0419240593910217

Epoch: 5| Step: 3
Training loss: 2.0827090740203857
Validation loss: 2.0344615479310355

Epoch: 5| Step: 4
Training loss: 1.9116052389144897
Validation loss: 2.033734306693077

Epoch: 5| Step: 5
Training loss: 1.7999225854873657
Validation loss: 2.0462402254343033

Epoch: 5| Step: 6
Training loss: 2.4245784282684326
Validation loss: 2.036635532975197

Epoch: 5| Step: 7
Training loss: 1.8020098209381104
Validation loss: 2.043224265178045

Epoch: 5| Step: 8
Training loss: 2.334131956100464
Validation loss: 2.041652833422025

Epoch: 5| Step: 9
Training loss: 2.440952777862549
Validation loss: 2.0392829179763794

Epoch: 5| Step: 10
Training loss: 1.7915054559707642
Validation loss: 2.0509499659140906

Epoch: 5| Step: 11
Training loss: 1.0110669136047363
Validation loss: 2.0548816124598184

Epoch: 170| Step: 0
Training loss: 1.8993823528289795
Validation loss: 2.041740650931994

Epoch: 5| Step: 1
Training loss: 2.072127103805542
Validation loss: 2.039256681998571

Epoch: 5| Step: 2
Training loss: 2.1166892051696777
Validation loss: 2.0476182947556176

Epoch: 5| Step: 3
Training loss: 2.001359224319458
Validation loss: 2.045213902990023

Epoch: 5| Step: 4
Training loss: 2.516040802001953
Validation loss: 2.0552182843287787

Epoch: 5| Step: 5
Training loss: 2.310154438018799
Validation loss: 2.051915188630422

Epoch: 5| Step: 6
Training loss: 1.9043344259262085
Validation loss: 2.058327093720436

Epoch: 5| Step: 7
Training loss: 2.452367067337036
Validation loss: 2.0603715777397156

Epoch: 5| Step: 8
Training loss: 1.8674285411834717
Validation loss: 2.0476159205039344

Epoch: 5| Step: 9
Training loss: 1.4767128229141235
Validation loss: 2.0422633588314056

Epoch: 5| Step: 10
Training loss: 2.4650485515594482
Validation loss: 2.03738671541214

Epoch: 5| Step: 11
Training loss: 1.879733920097351
Validation loss: 2.0340525656938553

Epoch: 171| Step: 0
Training loss: 1.8804868459701538
Validation loss: 2.044809266924858

Epoch: 5| Step: 1
Training loss: 1.9732725620269775
Validation loss: 2.0514789720376334

Epoch: 5| Step: 2
Training loss: 1.8012365102767944
Validation loss: 2.0489709228277206

Epoch: 5| Step: 3
Training loss: 2.1026387214660645
Validation loss: 2.048579588532448

Epoch: 5| Step: 4
Training loss: 1.8216533660888672
Validation loss: 2.0595949242512384

Epoch: 5| Step: 5
Training loss: 2.464812994003296
Validation loss: 2.0751968820889792

Epoch: 5| Step: 6
Training loss: 2.360748767852783
Validation loss: 2.076155369480451

Epoch: 5| Step: 7
Training loss: 2.084226369857788
Validation loss: 2.0804335524638495

Epoch: 5| Step: 8
Training loss: 2.6231155395507812
Validation loss: 2.0943861852089563

Epoch: 5| Step: 9
Training loss: 1.7039331197738647
Validation loss: 2.0720964620510736

Epoch: 5| Step: 10
Training loss: 2.068723201751709
Validation loss: 2.06163027882576

Epoch: 5| Step: 11
Training loss: 0.9661581516265869
Validation loss: 2.0538686315218606

Epoch: 172| Step: 0
Training loss: 2.1084976196289062
Validation loss: 2.046837796767553

Epoch: 5| Step: 1
Training loss: 2.1782147884368896
Validation loss: 2.0476215481758118

Epoch: 5| Step: 2
Training loss: 2.2667195796966553
Validation loss: 2.0481229374806085

Epoch: 5| Step: 3
Training loss: 1.9112122058868408
Validation loss: 2.0384242236614227

Epoch: 5| Step: 4
Training loss: 1.2899775505065918
Validation loss: 2.040303240219752

Epoch: 5| Step: 5
Training loss: 2.1381402015686035
Validation loss: 2.049128825465838

Epoch: 5| Step: 6
Training loss: 2.01770281791687
Validation loss: 2.037003750602404

Epoch: 5| Step: 7
Training loss: 2.7662177085876465
Validation loss: 2.0457148253917694

Epoch: 5| Step: 8
Training loss: 2.1375176906585693
Validation loss: 2.034906735022863

Epoch: 5| Step: 9
Training loss: 1.8703758716583252
Validation loss: 2.0409550617138543

Epoch: 5| Step: 10
Training loss: 1.8994877338409424
Validation loss: 2.0412394603093467

Epoch: 5| Step: 11
Training loss: 1.8963768482208252
Validation loss: 2.04378479719162

Epoch: 173| Step: 0
Training loss: 1.6587635278701782
Validation loss: 2.052510589361191

Epoch: 5| Step: 1
Training loss: 2.4761128425598145
Validation loss: 2.0554390301307044

Epoch: 5| Step: 2
Training loss: 2.159836530685425
Validation loss: 2.0388690580924353

Epoch: 5| Step: 3
Training loss: 2.1124701499938965
Validation loss: 2.050408278902372

Epoch: 5| Step: 4
Training loss: 2.228250503540039
Validation loss: 2.0596833576758704

Epoch: 5| Step: 5
Training loss: 1.9398844242095947
Validation loss: 2.050177420179049

Epoch: 5| Step: 6
Training loss: 1.9255084991455078
Validation loss: 2.042715768019358

Epoch: 5| Step: 7
Training loss: 1.7716503143310547
Validation loss: 2.050578236579895

Epoch: 5| Step: 8
Training loss: 1.969079613685608
Validation loss: 2.0399024188518524

Epoch: 5| Step: 9
Training loss: 2.12330961227417
Validation loss: 2.04815981288751

Epoch: 5| Step: 10
Training loss: 1.871098518371582
Validation loss: 2.0481185764074326

Epoch: 5| Step: 11
Training loss: 1.5309648513793945
Validation loss: 2.046662191549937

Epoch: 174| Step: 0
Training loss: 2.0121583938598633
Validation loss: 2.0381951928138733

Epoch: 5| Step: 1
Training loss: 2.039952278137207
Validation loss: 2.0459182957808175

Epoch: 5| Step: 2
Training loss: 1.9551931619644165
Validation loss: 2.0505955715974173

Epoch: 5| Step: 3
Training loss: 2.214308500289917
Validation loss: 2.0435110380252204

Epoch: 5| Step: 4
Training loss: 1.9573103189468384
Validation loss: 2.0471965074539185

Epoch: 5| Step: 5
Training loss: 2.221304416656494
Validation loss: 2.0472892125447593

Epoch: 5| Step: 6
Training loss: 2.1349244117736816
Validation loss: 2.0434594651063285

Epoch: 5| Step: 7
Training loss: 1.7102363109588623
Validation loss: 2.04927829404672

Epoch: 5| Step: 8
Training loss: 2.3259246349334717
Validation loss: 2.0536974171797433

Epoch: 5| Step: 9
Training loss: 1.9505374431610107
Validation loss: 2.0494262675444284

Epoch: 5| Step: 10
Training loss: 1.60983407497406
Validation loss: 2.0277534127235413

Epoch: 5| Step: 11
Training loss: 1.945373773574829
Validation loss: 2.051220898826917

Epoch: 175| Step: 0
Training loss: 1.6687214374542236
Validation loss: 2.0414371540149054

Epoch: 5| Step: 1
Training loss: 2.4450974464416504
Validation loss: 2.050853724280993

Epoch: 5| Step: 2
Training loss: 1.801079511642456
Validation loss: 2.0421342104673386

Epoch: 5| Step: 3
Training loss: 1.2671568393707275
Validation loss: 2.041438326239586

Epoch: 5| Step: 4
Training loss: 1.9058196544647217
Validation loss: 2.0580808271964393

Epoch: 5| Step: 5
Training loss: 1.614284873008728
Validation loss: 2.0518476366996765

Epoch: 5| Step: 6
Training loss: 2.4679365158081055
Validation loss: 2.0578863819440207

Epoch: 5| Step: 7
Training loss: 1.6896060705184937
Validation loss: 2.0515195528666177

Epoch: 5| Step: 8
Training loss: 2.254981756210327
Validation loss: 2.0444202721118927

Epoch: 5| Step: 9
Training loss: 2.8293604850769043
Validation loss: 2.0591896375020347

Epoch: 5| Step: 10
Training loss: 1.987044095993042
Validation loss: 2.055656577150027

Epoch: 5| Step: 11
Training loss: 2.5515053272247314
Validation loss: 2.0492562552293143

Epoch: 176| Step: 0
Training loss: 1.8164501190185547
Validation loss: 2.058303957184156

Epoch: 5| Step: 1
Training loss: 1.6975820064544678
Validation loss: 2.0559617231289544

Epoch: 5| Step: 2
Training loss: 2.1604831218719482
Validation loss: 2.050299028555552

Epoch: 5| Step: 3
Training loss: 1.979074478149414
Validation loss: 2.0459282596906028

Epoch: 5| Step: 4
Training loss: 1.7018253803253174
Validation loss: 2.0613591174284616

Epoch: 5| Step: 5
Training loss: 1.4642890691757202
Validation loss: 2.0418881873289743

Epoch: 5| Step: 6
Training loss: 2.346858024597168
Validation loss: 2.0644958366950354

Epoch: 5| Step: 7
Training loss: 2.293139934539795
Validation loss: 2.0621145367622375

Epoch: 5| Step: 8
Training loss: 2.217613935470581
Validation loss: 2.043612480163574

Epoch: 5| Step: 9
Training loss: 2.2707676887512207
Validation loss: 2.0536830772956214

Epoch: 5| Step: 10
Training loss: 2.04655122756958
Validation loss: 2.062735383709272

Epoch: 5| Step: 11
Training loss: 2.379481315612793
Validation loss: 2.061231384674708

Epoch: 177| Step: 0
Training loss: 1.9889304637908936
Validation loss: 2.0477861563364663

Epoch: 5| Step: 1
Training loss: 1.7649790048599243
Validation loss: 2.038581053415934

Epoch: 5| Step: 2
Training loss: 2.065328359603882
Validation loss: 2.049754520257314

Epoch: 5| Step: 3
Training loss: 2.6497910022735596
Validation loss: 2.0515689303477607

Epoch: 5| Step: 4
Training loss: 2.1391215324401855
Validation loss: 2.0619218995173774

Epoch: 5| Step: 5
Training loss: 1.667062759399414
Validation loss: 2.067819193005562

Epoch: 5| Step: 6
Training loss: 1.7571779489517212
Validation loss: 2.0548813144365945

Epoch: 5| Step: 7
Training loss: 2.4090352058410645
Validation loss: 2.0730499227841697

Epoch: 5| Step: 8
Training loss: 1.7683556079864502
Validation loss: 2.047680805126826

Epoch: 5| Step: 9
Training loss: 1.616777777671814
Validation loss: 2.0505792647600174

Epoch: 5| Step: 10
Training loss: 2.449328660964966
Validation loss: 2.041765972971916

Epoch: 5| Step: 11
Training loss: 1.3611819744110107
Validation loss: 2.0475918104251227

Epoch: 178| Step: 0
Training loss: 2.0087890625
Validation loss: 2.040644402305285

Epoch: 5| Step: 1
Training loss: 2.6004436016082764
Validation loss: 2.0444500048955283

Epoch: 5| Step: 2
Training loss: 2.1354453563690186
Validation loss: 2.0372776289780936

Epoch: 5| Step: 3
Training loss: 1.9372117519378662
Validation loss: 2.034129728873571

Epoch: 5| Step: 4
Training loss: 2.320561408996582
Validation loss: 2.0341613590717316

Epoch: 5| Step: 5
Training loss: 2.1669273376464844
Validation loss: 2.038513273000717

Epoch: 5| Step: 6
Training loss: 1.6997334957122803
Validation loss: 2.0374549875656762

Epoch: 5| Step: 7
Training loss: 1.811882734298706
Validation loss: 2.0378050009409585

Epoch: 5| Step: 8
Training loss: 1.7033069133758545
Validation loss: 2.0372058947881064

Epoch: 5| Step: 9
Training loss: 1.640621542930603
Validation loss: 2.0461121698220572

Epoch: 5| Step: 10
Training loss: 2.3841652870178223
Validation loss: 2.0370313425858817

Epoch: 5| Step: 11
Training loss: 1.7719825506210327
Validation loss: 2.032740607857704

Epoch: 179| Step: 0
Training loss: 1.4473189115524292
Validation loss: 2.036560297012329

Epoch: 5| Step: 1
Training loss: 2.704451560974121
Validation loss: 2.0402384797732034

Epoch: 5| Step: 2
Training loss: 2.240201711654663
Validation loss: 2.041643569866816

Epoch: 5| Step: 3
Training loss: 2.3724732398986816
Validation loss: 2.0419632444779077

Epoch: 5| Step: 4
Training loss: 1.6215378046035767
Validation loss: 2.0467651387055716

Epoch: 5| Step: 5
Training loss: 1.8655561208724976
Validation loss: 2.049669846892357

Epoch: 5| Step: 6
Training loss: 2.0132930278778076
Validation loss: 2.0493955860535302

Epoch: 5| Step: 7
Training loss: 1.989201307296753
Validation loss: 2.053815652926763

Epoch: 5| Step: 8
Training loss: 2.3124241828918457
Validation loss: 2.0437249640623727

Epoch: 5| Step: 9
Training loss: 2.0400643348693848
Validation loss: 2.053337732950846

Epoch: 5| Step: 10
Training loss: 1.5608842372894287
Validation loss: 2.068181241552035

Epoch: 5| Step: 11
Training loss: 3.222688674926758
Validation loss: 2.071303427219391

Epoch: 180| Step: 0
Training loss: 2.621290683746338
Validation loss: 2.0687018036842346

Epoch: 5| Step: 1
Training loss: 1.72219979763031
Validation loss: 2.0714444120724997

Epoch: 5| Step: 2
Training loss: 2.2363574504852295
Validation loss: 2.0559145559867225

Epoch: 5| Step: 3
Training loss: 2.0480868816375732
Validation loss: 2.063357412815094

Epoch: 5| Step: 4
Training loss: 1.7919418811798096
Validation loss: 2.0597979923089347

Epoch: 5| Step: 5
Training loss: 1.9611316919326782
Validation loss: 2.05383862555027

Epoch: 5| Step: 6
Training loss: 1.760443925857544
Validation loss: 2.0551646749178567

Epoch: 5| Step: 7
Training loss: 2.1000819206237793
Validation loss: 2.0567810038725534

Epoch: 5| Step: 8
Training loss: 1.7666778564453125
Validation loss: 2.050045594573021

Epoch: 5| Step: 9
Training loss: 2.238328218460083
Validation loss: 2.0482600182294846

Epoch: 5| Step: 10
Training loss: 1.788503646850586
Validation loss: 2.0499587009350457

Epoch: 5| Step: 11
Training loss: 2.076596260070801
Validation loss: 2.0523271411657333

Epoch: 181| Step: 0
Training loss: 1.3270351886749268
Validation loss: 2.0442363172769547

Epoch: 5| Step: 1
Training loss: 2.392353057861328
Validation loss: 2.0531309247016907

Epoch: 5| Step: 2
Training loss: 2.3706612586975098
Validation loss: 2.041787033279737

Epoch: 5| Step: 3
Training loss: 2.156538724899292
Validation loss: 2.0482154339551926

Epoch: 5| Step: 4
Training loss: 1.9175258874893188
Validation loss: 2.0526302506526313

Epoch: 5| Step: 5
Training loss: 2.3306057453155518
Validation loss: 2.0475132167339325

Epoch: 5| Step: 6
Training loss: 1.597302794456482
Validation loss: 2.06179441511631

Epoch: 5| Step: 7
Training loss: 1.5815675258636475
Validation loss: 2.064403608441353

Epoch: 5| Step: 8
Training loss: 2.1646628379821777
Validation loss: 2.0707938571770987

Epoch: 5| Step: 9
Training loss: 2.1561295986175537
Validation loss: 2.0574934780597687

Epoch: 5| Step: 10
Training loss: 1.9792098999023438
Validation loss: 2.0614373634258905

Epoch: 5| Step: 11
Training loss: 2.7673678398132324
Validation loss: 2.06633752087752

Epoch: 182| Step: 0
Training loss: 1.6318355798721313
Validation loss: 2.062359611193339

Epoch: 5| Step: 1
Training loss: 1.9774096012115479
Validation loss: 2.053392544388771

Epoch: 5| Step: 2
Training loss: 2.2969846725463867
Validation loss: 2.0595521877209344

Epoch: 5| Step: 3
Training loss: 2.1040492057800293
Validation loss: 2.062434658408165

Epoch: 5| Step: 4
Training loss: 1.8815433979034424
Validation loss: 2.0423870335022607

Epoch: 5| Step: 5
Training loss: 2.4035592079162598
Validation loss: 2.0552629232406616

Epoch: 5| Step: 6
Training loss: 1.5973261594772339
Validation loss: 2.049487675229708

Epoch: 5| Step: 7
Training loss: 2.3293025493621826
Validation loss: 2.0487308353185654

Epoch: 5| Step: 8
Training loss: 2.3136205673217773
Validation loss: 2.0472143242756524

Epoch: 5| Step: 9
Training loss: 1.7721564769744873
Validation loss: 2.0455492387215295

Epoch: 5| Step: 10
Training loss: 1.7872314453125
Validation loss: 2.0523316065470376

Epoch: 5| Step: 11
Training loss: 1.7537317276000977
Validation loss: 2.0470602065324783

Epoch: 183| Step: 0
Training loss: 2.11907696723938
Validation loss: 2.045149013400078

Epoch: 5| Step: 1
Training loss: 2.048919677734375
Validation loss: 2.0512511183818183

Epoch: 5| Step: 2
Training loss: 1.3959213495254517
Validation loss: 2.0608906149864197

Epoch: 5| Step: 3
Training loss: 2.450658082962036
Validation loss: 2.0611082116762796

Epoch: 5| Step: 4
Training loss: 1.7302337884902954
Validation loss: 2.05641116698583

Epoch: 5| Step: 5
Training loss: 2.2477478981018066
Validation loss: 2.076336736480395

Epoch: 5| Step: 6
Training loss: 2.2582240104675293
Validation loss: 2.072198381026586

Epoch: 5| Step: 7
Training loss: 1.7303346395492554
Validation loss: 2.060490960876147

Epoch: 5| Step: 8
Training loss: 2.2250728607177734
Validation loss: 2.0596946676572165

Epoch: 5| Step: 9
Training loss: 2.171405076980591
Validation loss: 2.0595725973447165

Epoch: 5| Step: 10
Training loss: 1.6942943334579468
Validation loss: 2.0470468004544577

Epoch: 5| Step: 11
Training loss: 1.404618740081787
Validation loss: 2.056377167503039

Epoch: 184| Step: 0
Training loss: 2.0554611682891846
Validation loss: 2.0562926282485328

Epoch: 5| Step: 1
Training loss: 2.1031956672668457
Validation loss: 2.061270793279012

Epoch: 5| Step: 2
Training loss: 1.7292068004608154
Validation loss: 2.051161835590998

Epoch: 5| Step: 3
Training loss: 1.9045145511627197
Validation loss: 2.052115321159363

Epoch: 5| Step: 4
Training loss: 2.0326411724090576
Validation loss: 2.057186797261238

Epoch: 5| Step: 5
Training loss: 1.8059425354003906
Validation loss: 2.050305942694346

Epoch: 5| Step: 6
Training loss: 1.7289903163909912
Validation loss: 2.0617553144693375

Epoch: 5| Step: 7
Training loss: 2.023207902908325
Validation loss: 2.0537378191947937

Epoch: 5| Step: 8
Training loss: 2.122833728790283
Validation loss: 2.060612897078196

Epoch: 5| Step: 9
Training loss: 1.9499645233154297
Validation loss: 2.0633130023876824

Epoch: 5| Step: 10
Training loss: 2.5356788635253906
Validation loss: 2.0516986598571143

Epoch: 5| Step: 11
Training loss: 1.9708309173583984
Validation loss: 2.0701624304056168

Epoch: 185| Step: 0
Training loss: 1.918748140335083
Validation loss: 2.0605655759572983

Epoch: 5| Step: 1
Training loss: 1.7756080627441406
Validation loss: 2.068140149116516

Epoch: 5| Step: 2
Training loss: 1.7416146993637085
Validation loss: 2.069289614756902

Epoch: 5| Step: 3
Training loss: 1.7709897756576538
Validation loss: 2.0585800210634866

Epoch: 5| Step: 4
Training loss: 1.7294883728027344
Validation loss: 2.0578089455763497

Epoch: 5| Step: 5
Training loss: 2.4755091667175293
Validation loss: 2.069188912709554

Epoch: 5| Step: 6
Training loss: 1.960465669631958
Validation loss: 2.0627803057432175

Epoch: 5| Step: 7
Training loss: 1.9584369659423828
Validation loss: 2.074377159277598

Epoch: 5| Step: 8
Training loss: 1.910094976425171
Validation loss: 2.0662487546602883

Epoch: 5| Step: 9
Training loss: 1.8492071628570557
Validation loss: 2.0738547841707864

Epoch: 5| Step: 10
Training loss: 2.4409337043762207
Validation loss: 2.067588895559311

Epoch: 5| Step: 11
Training loss: 3.8627467155456543
Validation loss: 2.0718859980503717

Epoch: 186| Step: 0
Training loss: 1.6459776163101196
Validation loss: 2.071817547082901

Epoch: 5| Step: 1
Training loss: 1.9234098196029663
Validation loss: 2.062613675991694

Epoch: 5| Step: 2
Training loss: 1.7974077463150024
Validation loss: 2.0611342390378318

Epoch: 5| Step: 3
Training loss: 2.058995246887207
Validation loss: 2.053345506389936

Epoch: 5| Step: 4
Training loss: 1.7963424921035767
Validation loss: 2.053722769021988

Epoch: 5| Step: 5
Training loss: 2.2830557823181152
Validation loss: 2.0463286886612573

Epoch: 5| Step: 6
Training loss: 1.8309946060180664
Validation loss: 2.0677085369825363

Epoch: 5| Step: 7
Training loss: 2.434624195098877
Validation loss: 2.062510227163633

Epoch: 5| Step: 8
Training loss: 2.2804620265960693
Validation loss: 2.057813987135887

Epoch: 5| Step: 9
Training loss: 1.7753547430038452
Validation loss: 2.047437315185865

Epoch: 5| Step: 10
Training loss: 2.152524471282959
Validation loss: 2.0473101884126663

Epoch: 5| Step: 11
Training loss: 1.4215868711471558
Validation loss: 2.0567437211672464

Epoch: 187| Step: 0
Training loss: 2.0159289836883545
Validation loss: 2.0563965688149133

Epoch: 5| Step: 1
Training loss: 1.581120491027832
Validation loss: 2.0766223718722663

Epoch: 5| Step: 2
Training loss: 2.3377223014831543
Validation loss: 2.070700153708458

Epoch: 5| Step: 3
Training loss: 1.8886314630508423
Validation loss: 2.0732349505027137

Epoch: 5| Step: 4
Training loss: 2.0007824897766113
Validation loss: 2.080075611670812

Epoch: 5| Step: 5
Training loss: 2.4199161529541016
Validation loss: 2.0727600008249283

Epoch: 5| Step: 6
Training loss: 2.076167345046997
Validation loss: 2.061393991112709

Epoch: 5| Step: 7
Training loss: 1.5509364604949951
Validation loss: 2.0745652318000793

Epoch: 5| Step: 8
Training loss: 2.352536678314209
Validation loss: 2.072079226374626

Epoch: 5| Step: 9
Training loss: 1.8291656970977783
Validation loss: 2.0768029739459357

Epoch: 5| Step: 10
Training loss: 1.9572536945343018
Validation loss: 2.0622551242510476

Epoch: 5| Step: 11
Training loss: 1.5902621746063232
Validation loss: 2.066186641653379

Epoch: 188| Step: 0
Training loss: 1.8600679636001587
Validation loss: 2.070801263054212

Epoch: 5| Step: 1
Training loss: 1.611879587173462
Validation loss: 2.0554377237955728

Epoch: 5| Step: 2
Training loss: 1.944791555404663
Validation loss: 2.05630099773407

Epoch: 5| Step: 3
Training loss: 1.6085618734359741
Validation loss: 2.059599354863167

Epoch: 5| Step: 4
Training loss: 2.5692131519317627
Validation loss: 2.064701055486997

Epoch: 5| Step: 5
Training loss: 1.9166977405548096
Validation loss: 2.0599699517091117

Epoch: 5| Step: 6
Training loss: 1.9019193649291992
Validation loss: 2.068782622615496

Epoch: 5| Step: 7
Training loss: 1.8640499114990234
Validation loss: 2.0771201898654303

Epoch: 5| Step: 8
Training loss: 2.2953944206237793
Validation loss: 2.0694080839554467

Epoch: 5| Step: 9
Training loss: 2.044156312942505
Validation loss: 2.0706103493769965

Epoch: 5| Step: 10
Training loss: 2.489196538925171
Validation loss: 2.066313917438189

Epoch: 5| Step: 11
Training loss: 1.3455796241760254
Validation loss: 2.0790112713972726

Epoch: 189| Step: 0
Training loss: 1.7726644277572632
Validation loss: 2.067999482154846

Epoch: 5| Step: 1
Training loss: 1.7405128479003906
Validation loss: 2.0613776048024497

Epoch: 5| Step: 2
Training loss: 1.1756525039672852
Validation loss: 2.061406825979551

Epoch: 5| Step: 3
Training loss: 2.1529674530029297
Validation loss: 2.0670554637908936

Epoch: 5| Step: 4
Training loss: 1.738501787185669
Validation loss: 2.0736300547917685

Epoch: 5| Step: 5
Training loss: 2.3332021236419678
Validation loss: 2.070055623849233

Epoch: 5| Step: 6
Training loss: 2.890496015548706
Validation loss: 2.0779820680618286

Epoch: 5| Step: 7
Training loss: 2.0798180103302
Validation loss: 2.080701023340225

Epoch: 5| Step: 8
Training loss: 1.8409925699234009
Validation loss: 2.0669330606857934

Epoch: 5| Step: 9
Training loss: 1.8506534099578857
Validation loss: 2.0545241286357245

Epoch: 5| Step: 10
Training loss: 2.1821770668029785
Validation loss: 2.051239714026451

Epoch: 5| Step: 11
Training loss: 2.440373659133911
Validation loss: 2.0583784778912864

Epoch: 190| Step: 0
Training loss: 1.7020403146743774
Validation loss: 2.060042053461075

Epoch: 5| Step: 1
Training loss: 2.0149946212768555
Validation loss: 2.0503239383300147

Epoch: 5| Step: 2
Training loss: 1.8824571371078491
Validation loss: 2.059696132938067

Epoch: 5| Step: 3
Training loss: 1.8530819416046143
Validation loss: 2.0578772326310477

Epoch: 5| Step: 4
Training loss: 2.3073906898498535
Validation loss: 2.056774059931437

Epoch: 5| Step: 5
Training loss: 1.5719895362854004
Validation loss: 2.0492150088151297

Epoch: 5| Step: 6
Training loss: 2.199866533279419
Validation loss: 2.050019512573878

Epoch: 5| Step: 7
Training loss: 1.794068694114685
Validation loss: 2.05337326725324

Epoch: 5| Step: 8
Training loss: 2.091646671295166
Validation loss: 2.0501462817192078

Epoch: 5| Step: 9
Training loss: 2.3934011459350586
Validation loss: 2.053809478878975

Epoch: 5| Step: 10
Training loss: 1.9394718408584595
Validation loss: 2.059365838766098

Epoch: 5| Step: 11
Training loss: 2.7227578163146973
Validation loss: 2.0568707237641015

Epoch: 191| Step: 0
Training loss: 1.7850782871246338
Validation loss: 2.069007803996404

Epoch: 5| Step: 1
Training loss: 1.6349951028823853
Validation loss: 2.0727251966794333

Epoch: 5| Step: 2
Training loss: 2.0703983306884766
Validation loss: 2.0678939123948417

Epoch: 5| Step: 3
Training loss: 2.424734115600586
Validation loss: 2.075211301445961

Epoch: 5| Step: 4
Training loss: 2.0696330070495605
Validation loss: 2.0828973849614463

Epoch: 5| Step: 5
Training loss: 1.7446224689483643
Validation loss: 2.0762797544399896

Epoch: 5| Step: 6
Training loss: 1.9420061111450195
Validation loss: 2.072324891885122

Epoch: 5| Step: 7
Training loss: 1.6610147953033447
Validation loss: 2.0781731655200324

Epoch: 5| Step: 8
Training loss: 2.3495559692382812
Validation loss: 2.0771105041106543

Epoch: 5| Step: 9
Training loss: 1.8215563297271729
Validation loss: 2.0789791146914163

Epoch: 5| Step: 10
Training loss: 2.295032262802124
Validation loss: 2.0720361222823462

Epoch: 5| Step: 11
Training loss: 1.7656774520874023
Validation loss: 2.063529670238495

Epoch: 192| Step: 0
Training loss: 2.197516918182373
Validation loss: 2.061533361673355

Epoch: 5| Step: 1
Training loss: 1.9691118001937866
Validation loss: 2.055937667687734

Epoch: 5| Step: 2
Training loss: 1.8675273656845093
Validation loss: 2.052882214387258

Epoch: 5| Step: 3
Training loss: 1.580823302268982
Validation loss: 2.053096075852712

Epoch: 5| Step: 4
Training loss: 1.9149070978164673
Validation loss: 2.0405478874842324

Epoch: 5| Step: 5
Training loss: 2.091447591781616
Validation loss: 2.0549618353446326

Epoch: 5| Step: 6
Training loss: 2.293915271759033
Validation loss: 2.0582055350144706

Epoch: 5| Step: 7
Training loss: 2.7652359008789062
Validation loss: 2.062925269206365

Epoch: 5| Step: 8
Training loss: 2.3635807037353516
Validation loss: 2.0554429392019906

Epoch: 5| Step: 9
Training loss: 1.8343693017959595
Validation loss: 2.061207413673401

Epoch: 5| Step: 10
Training loss: 1.7278296947479248
Validation loss: 2.0604884177446365

Epoch: 5| Step: 11
Training loss: 0.6107045412063599
Validation loss: 2.0571450839440026

Epoch: 193| Step: 0
Training loss: 2.1565067768096924
Validation loss: 2.070679619908333

Epoch: 5| Step: 1
Training loss: 1.9455382823944092
Validation loss: 2.0619322657585144

Epoch: 5| Step: 2
Training loss: 1.8159652948379517
Validation loss: 2.0638907055060067

Epoch: 5| Step: 3
Training loss: 1.6313683986663818
Validation loss: 2.070049529274305

Epoch: 5| Step: 4
Training loss: 2.0181329250335693
Validation loss: 2.062585934996605

Epoch: 5| Step: 5
Training loss: 2.202756404876709
Validation loss: 2.062362422545751

Epoch: 5| Step: 6
Training loss: 2.7440195083618164
Validation loss: 2.0631853391726813

Epoch: 5| Step: 7
Training loss: 1.9038970470428467
Validation loss: 2.0720647076765695

Epoch: 5| Step: 8
Training loss: 1.2710586786270142
Validation loss: 2.0748798549175262

Epoch: 5| Step: 9
Training loss: 1.7256653308868408
Validation loss: 2.0643646170695624

Epoch: 5| Step: 10
Training loss: 2.3177883625030518
Validation loss: 2.0663055578867593

Epoch: 5| Step: 11
Training loss: 3.129899501800537
Validation loss: 2.0717615336179733

Epoch: 194| Step: 0
Training loss: 1.8561261892318726
Validation loss: 2.0638850728670755

Epoch: 5| Step: 1
Training loss: 1.6231966018676758
Validation loss: 2.062053640683492

Epoch: 5| Step: 2
Training loss: 2.0399186611175537
Validation loss: 2.065479129552841

Epoch: 5| Step: 3
Training loss: 2.4745960235595703
Validation loss: 2.062053586045901

Epoch: 5| Step: 4
Training loss: 2.351078510284424
Validation loss: 2.0663094719251

Epoch: 5| Step: 5
Training loss: 2.074204206466675
Validation loss: 2.060049136479696

Epoch: 5| Step: 6
Training loss: 2.253836154937744
Validation loss: 2.05907333890597

Epoch: 5| Step: 7
Training loss: 1.6507823467254639
Validation loss: 2.06589841345946

Epoch: 5| Step: 8
Training loss: 2.732452392578125
Validation loss: 2.0687829703092575

Epoch: 5| Step: 9
Training loss: 1.7275638580322266
Validation loss: 2.0615420987208686

Epoch: 5| Step: 10
Training loss: 1.1225703954696655
Validation loss: 2.0688678125540414

Epoch: 5| Step: 11
Training loss: 1.6613588333129883
Validation loss: 2.063440576195717

Epoch: 195| Step: 0
Training loss: 2.6122984886169434
Validation loss: 2.0682221055030823

Epoch: 5| Step: 1
Training loss: 1.5183031558990479
Validation loss: 2.073474238316218

Epoch: 5| Step: 2
Training loss: 1.8001315593719482
Validation loss: 2.0665396551291146

Epoch: 5| Step: 3
Training loss: 1.6895630359649658
Validation loss: 2.057674596707026

Epoch: 5| Step: 4
Training loss: 1.7568531036376953
Validation loss: 2.050600399573644

Epoch: 5| Step: 5
Training loss: 2.286025047302246
Validation loss: 2.0501705706119537

Epoch: 5| Step: 6
Training loss: 1.9270397424697876
Validation loss: 2.0521032164494195

Epoch: 5| Step: 7
Training loss: 1.9886184930801392
Validation loss: 2.0448503643274307

Epoch: 5| Step: 8
Training loss: 2.4166431427001953
Validation loss: 2.051805227994919

Epoch: 5| Step: 9
Training loss: 2.257371187210083
Validation loss: 2.0625799944003425

Epoch: 5| Step: 10
Training loss: 1.707802176475525
Validation loss: 2.0536660651365914

Epoch: 5| Step: 11
Training loss: 0.6814297437667847
Validation loss: 2.050959383447965

Epoch: 196| Step: 0
Training loss: 1.404001235961914
Validation loss: 2.067658931016922

Epoch: 5| Step: 1
Training loss: 2.3826406002044678
Validation loss: 2.067610894640287

Epoch: 5| Step: 2
Training loss: 2.3255045413970947
Validation loss: 2.061035687724749

Epoch: 5| Step: 3
Training loss: 2.613454818725586
Validation loss: 2.0601024627685547

Epoch: 5| Step: 4
Training loss: 1.7733837366104126
Validation loss: 2.065177410840988

Epoch: 5| Step: 5
Training loss: 2.3753116130828857
Validation loss: 2.067726264397303

Epoch: 5| Step: 6
Training loss: 1.8131816387176514
Validation loss: 2.068322425087293

Epoch: 5| Step: 7
Training loss: 1.8512356281280518
Validation loss: 2.0728530089060464

Epoch: 5| Step: 8
Training loss: 1.7276477813720703
Validation loss: 2.0587946822245917

Epoch: 5| Step: 9
Training loss: 1.5236916542053223
Validation loss: 2.053481156627337

Epoch: 5| Step: 10
Training loss: 1.9396705627441406
Validation loss: 2.0728977968295417

Epoch: 5| Step: 11
Training loss: 0.9875917434692383
Validation loss: 2.052047769228617

Epoch: 197| Step: 0
Training loss: 2.4439473152160645
Validation loss: 2.055538296699524

Epoch: 5| Step: 1
Training loss: 2.1390299797058105
Validation loss: 2.070162827769915

Epoch: 5| Step: 2
Training loss: 2.2318906784057617
Validation loss: 2.0663327972094216

Epoch: 5| Step: 3
Training loss: 1.802509069442749
Validation loss: 2.065969834725062

Epoch: 5| Step: 4
Training loss: 1.876394510269165
Validation loss: 2.0618250568707785

Epoch: 5| Step: 5
Training loss: 1.6771939992904663
Validation loss: 2.068386738499006

Epoch: 5| Step: 6
Training loss: 2.186081886291504
Validation loss: 2.0618778318166733

Epoch: 5| Step: 7
Training loss: 1.9202076196670532
Validation loss: 2.0781763792037964

Epoch: 5| Step: 8
Training loss: 1.562354326248169
Validation loss: 2.0702498306830726

Epoch: 5| Step: 9
Training loss: 2.1904892921447754
Validation loss: 2.0834973752498627

Epoch: 5| Step: 10
Training loss: 1.7472127676010132
Validation loss: 2.095830043156942

Epoch: 5| Step: 11
Training loss: 2.2411675453186035
Validation loss: 2.0781531631946564

Epoch: 198| Step: 0
Training loss: 1.7611780166625977
Validation loss: 2.070895090699196

Epoch: 5| Step: 1
Training loss: 2.015645742416382
Validation loss: 2.0646986862023673

Epoch: 5| Step: 2
Training loss: 2.014681577682495
Validation loss: 2.0573659241199493

Epoch: 5| Step: 3
Training loss: 1.6223046779632568
Validation loss: 2.068134864171346

Epoch: 5| Step: 4
Training loss: 2.0442280769348145
Validation loss: 2.0777661303679147

Epoch: 5| Step: 5
Training loss: 2.1895482540130615
Validation loss: 2.058140680193901

Epoch: 5| Step: 6
Training loss: 2.3755810260772705
Validation loss: 2.0619191924730935

Epoch: 5| Step: 7
Training loss: 1.5658732652664185
Validation loss: 2.070593371987343

Epoch: 5| Step: 8
Training loss: 1.8920307159423828
Validation loss: 2.073473811149597

Epoch: 5| Step: 9
Training loss: 1.7906475067138672
Validation loss: 2.0743470738331475

Epoch: 5| Step: 10
Training loss: 2.0872693061828613
Validation loss: 2.074460878968239

Epoch: 5| Step: 11
Training loss: 3.5976169109344482
Validation loss: 2.0851809481779733

Epoch: 199| Step: 0
Training loss: 2.019224166870117
Validation loss: 2.078632672627767

Epoch: 5| Step: 1
Training loss: 2.32450795173645
Validation loss: 2.080653041601181

Epoch: 5| Step: 2
Training loss: 2.472538709640503
Validation loss: 2.08557757238547

Epoch: 5| Step: 3
Training loss: 1.8668638467788696
Validation loss: 2.078183819850286

Epoch: 5| Step: 4
Training loss: 1.9496005773544312
Validation loss: 2.0786382059256234

Epoch: 5| Step: 5
Training loss: 2.521317958831787
Validation loss: 2.074402466416359

Epoch: 5| Step: 6
Training loss: 2.130632162094116
Validation loss: 2.0846731762091317

Epoch: 5| Step: 7
Training loss: 1.506467580795288
Validation loss: 2.0822099099556604

Epoch: 5| Step: 8
Training loss: 2.0052731037139893
Validation loss: 2.0847743352254233

Epoch: 5| Step: 9
Training loss: 1.8108211755752563
Validation loss: 2.076257353027662

Epoch: 5| Step: 10
Training loss: 1.301800012588501
Validation loss: 2.0718564887841544

Epoch: 5| Step: 11
Training loss: 1.5989114046096802
Validation loss: 2.08013084034125

Epoch: 200| Step: 0
Training loss: 1.540778398513794
Validation loss: 2.0869031151135764

Epoch: 5| Step: 1
Training loss: 2.376657724380493
Validation loss: 2.0717392762502036

Epoch: 5| Step: 2
Training loss: 1.7487291097640991
Validation loss: 2.0732808212439218

Epoch: 5| Step: 3
Training loss: 2.7412185668945312
Validation loss: 2.070074533422788

Epoch: 5| Step: 4
Training loss: 1.9960544109344482
Validation loss: 2.0844680120547614

Epoch: 5| Step: 5
Training loss: 1.5760986804962158
Validation loss: 2.077912593881289

Epoch: 5| Step: 6
Training loss: 1.5940978527069092
Validation loss: 2.077448690931002

Epoch: 5| Step: 7
Training loss: 2.2152366638183594
Validation loss: 2.085011293490728

Epoch: 5| Step: 8
Training loss: 1.269348382949829
Validation loss: 2.0965838183959327

Epoch: 5| Step: 9
Training loss: 2.418731212615967
Validation loss: 2.076222057143847

Epoch: 5| Step: 10
Training loss: 1.901984453201294
Validation loss: 2.0923913717269897

Epoch: 5| Step: 11
Training loss: 1.7237839698791504
Validation loss: 2.073673889040947

Testing loss: 1.6880032484479945
