Epoch: 1| Step: 0
Training loss: 5.136180400848389
Validation loss: 5.242362300554912

Epoch: 5| Step: 1
Training loss: 4.838649749755859
Validation loss: 5.2403067747751875

Epoch: 5| Step: 2
Training loss: 5.076492786407471
Validation loss: 5.238357524077098

Epoch: 5| Step: 3
Training loss: 4.904566764831543
Validation loss: 5.236514389514923

Epoch: 5| Step: 4
Training loss: 5.733220100402832
Validation loss: 5.234661340713501

Epoch: 5| Step: 5
Training loss: 4.677062511444092
Validation loss: 5.2328493396441145

Epoch: 5| Step: 6
Training loss: 5.283689022064209
Validation loss: 5.231137255827586

Epoch: 5| Step: 7
Training loss: 5.258105278015137
Validation loss: 5.229367792606354

Epoch: 5| Step: 8
Training loss: 5.885885238647461
Validation loss: 5.227601110935211

Epoch: 5| Step: 9
Training loss: 5.120146751403809
Validation loss: 5.22577840089798

Epoch: 5| Step: 10
Training loss: 6.09207820892334
Validation loss: 5.2239822546641035

Epoch: 5| Step: 11
Training loss: 6.911804676055908
Validation loss: 5.222160915533702

Epoch: 2| Step: 0
Training loss: 6.073238372802734
Validation loss: 5.2202038168907166

Epoch: 5| Step: 1
Training loss: 5.871048927307129
Validation loss: 5.218147138754527

Epoch: 5| Step: 2
Training loss: 4.44467306137085
Validation loss: 5.2160946528116865

Epoch: 5| Step: 3
Training loss: 5.64549446105957
Validation loss: 5.213785171508789

Epoch: 5| Step: 4
Training loss: 5.334043979644775
Validation loss: 5.211549818515778

Epoch: 5| Step: 5
Training loss: 5.472054481506348
Validation loss: 5.2089389363924665

Epoch: 5| Step: 6
Training loss: 5.377064228057861
Validation loss: 5.20647531747818

Epoch: 5| Step: 7
Training loss: 4.629823684692383
Validation loss: 5.203643163045247

Epoch: 5| Step: 8
Training loss: 5.1070051193237305
Validation loss: 5.20080844561259

Epoch: 5| Step: 9
Training loss: 4.829410076141357
Validation loss: 5.197967727979024

Epoch: 5| Step: 10
Training loss: 4.648311614990234
Validation loss: 5.194719195365906

Epoch: 5| Step: 11
Training loss: 8.426616668701172
Validation loss: 5.191470781962077

Epoch: 3| Step: 0
Training loss: 5.838074684143066
Validation loss: 5.188051561514537

Epoch: 5| Step: 1
Training loss: 6.079255104064941
Validation loss: 5.18445607026418

Epoch: 5| Step: 2
Training loss: 5.5502824783325195
Validation loss: 5.180744369824727

Epoch: 5| Step: 3
Training loss: 4.159621715545654
Validation loss: 5.176771283149719

Epoch: 5| Step: 4
Training loss: 4.301935195922852
Validation loss: 5.1726963718732195

Epoch: 5| Step: 5
Training loss: 5.177047252655029
Validation loss: 5.1683842440446215

Epoch: 5| Step: 6
Training loss: 5.4315900802612305
Validation loss: 5.163831114768982

Epoch: 5| Step: 7
Training loss: 4.163712501525879
Validation loss: 5.159184455871582

Epoch: 5| Step: 8
Training loss: 5.221368312835693
Validation loss: 5.1541511217753095

Epoch: 5| Step: 9
Training loss: 5.846017360687256
Validation loss: 5.149091760317485

Epoch: 5| Step: 10
Training loss: 5.601879119873047
Validation loss: 5.143812775611877

Epoch: 5| Step: 11
Training loss: 6.4737772941589355
Validation loss: 5.1381639043490095

Epoch: 4| Step: 0
Training loss: 4.397103309631348
Validation loss: 5.132502973079681

Epoch: 5| Step: 1
Training loss: 5.698265552520752
Validation loss: 5.126567721366882

Epoch: 5| Step: 2
Training loss: 5.451340675354004
Validation loss: 5.120169997215271

Epoch: 5| Step: 3
Training loss: 4.775293827056885
Validation loss: 5.1140367190043134

Epoch: 5| Step: 4
Training loss: 4.542433738708496
Validation loss: 5.1072885394096375

Epoch: 5| Step: 5
Training loss: 5.55311918258667
Validation loss: 5.100380003452301

Epoch: 5| Step: 6
Training loss: 4.7741265296936035
Validation loss: 5.093193411827087

Epoch: 5| Step: 7
Training loss: 5.397043228149414
Validation loss: 5.0859335064888

Epoch: 5| Step: 8
Training loss: 4.7132649421691895
Validation loss: 5.078721205393474

Epoch: 5| Step: 9
Training loss: 5.693668365478516
Validation loss: 5.071392258008321

Epoch: 5| Step: 10
Training loss: 5.955723762512207
Validation loss: 5.06351884206136

Epoch: 5| Step: 11
Training loss: 4.9199090003967285
Validation loss: 5.055761973063151

Epoch: 5| Step: 0
Training loss: 5.642246246337891
Validation loss: 5.047911167144775

Epoch: 5| Step: 1
Training loss: 4.0698466300964355
Validation loss: 5.039897163709004

Epoch: 5| Step: 2
Training loss: 5.587225914001465
Validation loss: 5.031714498996735

Epoch: 5| Step: 3
Training loss: 5.2320685386657715
Validation loss: 5.023195683956146

Epoch: 5| Step: 4
Training loss: 5.965725898742676
Validation loss: 5.015296936035156

Epoch: 5| Step: 5
Training loss: 4.211255073547363
Validation loss: 5.006922245025635

Epoch: 5| Step: 6
Training loss: 4.987665176391602
Validation loss: 4.99831889073054

Epoch: 5| Step: 7
Training loss: 4.208563804626465
Validation loss: 4.990172306696574

Epoch: 5| Step: 8
Training loss: 4.738377571105957
Validation loss: 4.981848994890849

Epoch: 5| Step: 9
Training loss: 5.367260932922363
Validation loss: 4.973468919595082

Epoch: 5| Step: 10
Training loss: 5.656027317047119
Validation loss: 4.9649443825085955

Epoch: 5| Step: 11
Training loss: 6.421935558319092
Validation loss: 4.956426839033763

Epoch: 6| Step: 0
Training loss: 5.54851770401001
Validation loss: 4.947948773701985

Epoch: 5| Step: 1
Training loss: 4.491032600402832
Validation loss: 4.938995073239009

Epoch: 5| Step: 2
Training loss: 5.580122947692871
Validation loss: 4.9304461280504865

Epoch: 5| Step: 3
Training loss: 6.006034851074219
Validation loss: 4.921642204125722

Epoch: 5| Step: 4
Training loss: 4.49715518951416
Validation loss: 4.912540117899577

Epoch: 5| Step: 5
Training loss: 4.484596252441406
Validation loss: 4.903770178556442

Epoch: 5| Step: 6
Training loss: 4.589905738830566
Validation loss: 4.894678036371867

Epoch: 5| Step: 7
Training loss: 4.786895751953125
Validation loss: 4.88574747244517

Epoch: 5| Step: 8
Training loss: 4.767321586608887
Validation loss: 4.876533806324005

Epoch: 5| Step: 9
Training loss: 4.621675491333008
Validation loss: 4.867168525854747

Epoch: 5| Step: 10
Training loss: 5.6117024421691895
Validation loss: 4.857542296250661

Epoch: 5| Step: 11
Training loss: 4.320895195007324
Validation loss: 4.848201235135396

Epoch: 7| Step: 0
Training loss: 4.708710670471191
Validation loss: 4.838953018188477

Epoch: 5| Step: 1
Training loss: 6.129573822021484
Validation loss: 4.82966935634613

Epoch: 5| Step: 2
Training loss: 4.543786525726318
Validation loss: 4.821190237998962

Epoch: 5| Step: 3
Training loss: 4.949972629547119
Validation loss: 4.812422434488933

Epoch: 5| Step: 4
Training loss: 4.793206691741943
Validation loss: 4.80397097269694

Epoch: 5| Step: 5
Training loss: 5.774661064147949
Validation loss: 4.795463462670644

Epoch: 5| Step: 6
Training loss: 4.4848313331604
Validation loss: 4.786355406045914

Epoch: 5| Step: 7
Training loss: 4.993121147155762
Validation loss: 4.778268059094747

Epoch: 5| Step: 8
Training loss: 4.374263763427734
Validation loss: 4.769406497478485

Epoch: 5| Step: 9
Training loss: 4.316052436828613
Validation loss: 4.761150062084198

Epoch: 5| Step: 10
Training loss: 4.835545539855957
Validation loss: 4.752888023853302

Epoch: 5| Step: 11
Training loss: 3.9182891845703125
Validation loss: 4.744235694408417

Epoch: 8| Step: 0
Training loss: 5.155986309051514
Validation loss: 4.736158748467763

Epoch: 5| Step: 1
Training loss: 4.795931339263916
Validation loss: 4.728163500626882

Epoch: 5| Step: 2
Training loss: 4.198230743408203
Validation loss: 4.719936827818553

Epoch: 5| Step: 3
Training loss: 4.738124847412109
Validation loss: 4.7120381991068525

Epoch: 5| Step: 4
Training loss: 5.797352313995361
Validation loss: 4.703937192757924

Epoch: 5| Step: 5
Training loss: 4.494265556335449
Validation loss: 4.695554514726003

Epoch: 5| Step: 6
Training loss: 4.650885105133057
Validation loss: 4.687227209409078

Epoch: 5| Step: 7
Training loss: 4.592471122741699
Validation loss: 4.678846697012584

Epoch: 5| Step: 8
Training loss: 5.064515113830566
Validation loss: 4.670231839021047

Epoch: 5| Step: 9
Training loss: 4.323537349700928
Validation loss: 4.6616465250651045

Epoch: 5| Step: 10
Training loss: 4.632185935974121
Validation loss: 4.653644939263661

Epoch: 5| Step: 11
Training loss: 5.989862442016602
Validation loss: 4.644887348016103

Epoch: 9| Step: 0
Training loss: 3.829411745071411
Validation loss: 4.636481682459514

Epoch: 5| Step: 1
Training loss: 4.113877296447754
Validation loss: 4.628192186355591

Epoch: 5| Step: 2
Training loss: 4.172032356262207
Validation loss: 4.62043039004008

Epoch: 5| Step: 3
Training loss: 4.445409774780273
Validation loss: 4.612317125002543

Epoch: 5| Step: 4
Training loss: 4.560413360595703
Validation loss: 4.604030072689056

Epoch: 5| Step: 5
Training loss: 5.445135593414307
Validation loss: 4.596027930577596

Epoch: 5| Step: 6
Training loss: 4.732821464538574
Validation loss: 4.587708572546641

Epoch: 5| Step: 7
Training loss: 5.5264081954956055
Validation loss: 4.579393406709035

Epoch: 5| Step: 8
Training loss: 4.975054740905762
Validation loss: 4.571536282698314

Epoch: 5| Step: 9
Training loss: 5.021421909332275
Validation loss: 4.563352972269058

Epoch: 5| Step: 10
Training loss: 4.665698528289795
Validation loss: 4.555654088656108

Epoch: 5| Step: 11
Training loss: 5.527706146240234
Validation loss: 4.547495226065318

Epoch: 10| Step: 0
Training loss: 4.663235664367676
Validation loss: 4.53968812028567

Epoch: 5| Step: 1
Training loss: 4.862322807312012
Validation loss: 4.532464822133382

Epoch: 5| Step: 2
Training loss: 5.104388236999512
Validation loss: 4.5245828827222185

Epoch: 5| Step: 3
Training loss: 5.311718463897705
Validation loss: 4.5174921949704485

Epoch: 5| Step: 4
Training loss: 4.616812705993652
Validation loss: 4.510257105032603

Epoch: 5| Step: 5
Training loss: 4.479837894439697
Validation loss: 4.503552476565043

Epoch: 5| Step: 6
Training loss: 4.374293327331543
Validation loss: 4.496479252974193

Epoch: 5| Step: 7
Training loss: 4.174866676330566
Validation loss: 4.488768815994263

Epoch: 5| Step: 8
Training loss: 4.049782752990723
Validation loss: 4.481238484382629

Epoch: 5| Step: 9
Training loss: 4.622870922088623
Validation loss: 4.474388013283412

Epoch: 5| Step: 10
Training loss: 4.194552421569824
Validation loss: 4.467850168546041

Epoch: 5| Step: 11
Training loss: 5.873624801635742
Validation loss: 4.461241662502289

Epoch: 11| Step: 0
Training loss: 4.803287029266357
Validation loss: 4.455065707365672

Epoch: 5| Step: 1
Training loss: 4.2493720054626465
Validation loss: 4.449336270491282

Epoch: 5| Step: 2
Training loss: 5.721573829650879
Validation loss: 4.443597833315532

Epoch: 5| Step: 3
Training loss: 4.2775421142578125
Validation loss: 4.438705424467723

Epoch: 5| Step: 4
Training loss: 5.5727033615112305
Validation loss: 4.432933022578557

Epoch: 5| Step: 5
Training loss: 4.215304851531982
Validation loss: 4.427147368590037

Epoch: 5| Step: 6
Training loss: 3.8929061889648438
Validation loss: 4.421703408161799

Epoch: 5| Step: 7
Training loss: 4.962145805358887
Validation loss: 4.4162530700365705

Epoch: 5| Step: 8
Training loss: 3.808617115020752
Validation loss: 4.410879333813985

Epoch: 5| Step: 9
Training loss: 4.433865547180176
Validation loss: 4.405283331871033

Epoch: 5| Step: 10
Training loss: 4.148453712463379
Validation loss: 4.400441825389862

Epoch: 5| Step: 11
Training loss: 3.908632516860962
Validation loss: 4.395100295543671

Epoch: 12| Step: 0
Training loss: 4.977851390838623
Validation loss: 4.389798541863759

Epoch: 5| Step: 1
Training loss: 3.6936755180358887
Validation loss: 4.384361883004506

Epoch: 5| Step: 2
Training loss: 3.7844619750976562
Validation loss: 4.379390428463618

Epoch: 5| Step: 3
Training loss: 4.736756324768066
Validation loss: 4.373853882153829

Epoch: 5| Step: 4
Training loss: 4.598353385925293
Validation loss: 4.3690676887830096

Epoch: 5| Step: 5
Training loss: 4.82236385345459
Validation loss: 4.3639732003211975

Epoch: 5| Step: 6
Training loss: 4.869689464569092
Validation loss: 4.358738213777542

Epoch: 5| Step: 7
Training loss: 5.046408176422119
Validation loss: 4.353846311569214

Epoch: 5| Step: 8
Training loss: 4.073631286621094
Validation loss: 4.3485579291979475

Epoch: 5| Step: 9
Training loss: 4.420709133148193
Validation loss: 4.343281616767247

Epoch: 5| Step: 10
Training loss: 4.356905937194824
Validation loss: 4.338232696056366

Epoch: 5| Step: 11
Training loss: 4.194229602813721
Validation loss: 4.332462012767792

Epoch: 13| Step: 0
Training loss: 4.166207790374756
Validation loss: 4.328175842761993

Epoch: 5| Step: 1
Training loss: 5.488961696624756
Validation loss: 4.323095619678497

Epoch: 5| Step: 2
Training loss: 4.733899116516113
Validation loss: 4.316913733879725

Epoch: 5| Step: 3
Training loss: 3.185234308242798
Validation loss: 4.3123374581336975

Epoch: 5| Step: 4
Training loss: 5.664078712463379
Validation loss: 4.307335595289866

Epoch: 5| Step: 5
Training loss: 4.443751335144043
Validation loss: 4.301956822474797

Epoch: 5| Step: 6
Training loss: 4.815728187561035
Validation loss: 4.297039171059926

Epoch: 5| Step: 7
Training loss: 3.3522114753723145
Validation loss: 4.291849464178085

Epoch: 5| Step: 8
Training loss: 4.264266014099121
Validation loss: 4.287429531415303

Epoch: 5| Step: 9
Training loss: 4.22067928314209
Validation loss: 4.283203840255737

Epoch: 5| Step: 10
Training loss: 4.185877323150635
Validation loss: 4.277783989906311

Epoch: 5| Step: 11
Training loss: 5.280453205108643
Validation loss: 4.272244890530904

Epoch: 14| Step: 0
Training loss: 4.055264949798584
Validation loss: 4.267165770133336

Epoch: 5| Step: 1
Training loss: 4.520890235900879
Validation loss: 4.262457599242528

Epoch: 5| Step: 2
Training loss: 3.341566801071167
Validation loss: 4.257855713367462

Epoch: 5| Step: 3
Training loss: 4.539924144744873
Validation loss: 4.253057221571605

Epoch: 5| Step: 4
Training loss: 4.869449615478516
Validation loss: 4.248418211936951

Epoch: 5| Step: 5
Training loss: 4.7581024169921875
Validation loss: 4.242872476577759

Epoch: 5| Step: 6
Training loss: 4.972686290740967
Validation loss: 4.237695425748825

Epoch: 5| Step: 7
Training loss: 5.019072532653809
Validation loss: 4.2336763342221575

Epoch: 5| Step: 8
Training loss: 3.3621177673339844
Validation loss: 4.228407253821691

Epoch: 5| Step: 9
Training loss: 3.786031723022461
Validation loss: 4.223802894353867

Epoch: 5| Step: 10
Training loss: 4.596158027648926
Validation loss: 4.218892176946004

Epoch: 5| Step: 11
Training loss: 5.735654354095459
Validation loss: 4.214107632637024

Epoch: 15| Step: 0
Training loss: 3.8304946422576904
Validation loss: 4.209755450487137

Epoch: 5| Step: 1
Training loss: 5.167949676513672
Validation loss: 4.2045493721961975

Epoch: 5| Step: 2
Training loss: 3.88102388381958
Validation loss: 4.200383802254994

Epoch: 5| Step: 3
Training loss: 4.457664966583252
Validation loss: 4.195571005344391

Epoch: 5| Step: 4
Training loss: 4.319697380065918
Validation loss: 4.190378169218699

Epoch: 5| Step: 5
Training loss: 4.935644626617432
Validation loss: 4.18572532137235

Epoch: 5| Step: 6
Training loss: 4.383266448974609
Validation loss: 4.180999527374904

Epoch: 5| Step: 7
Training loss: 3.803448438644409
Validation loss: 4.176147202650706

Epoch: 5| Step: 8
Training loss: 4.092466831207275
Validation loss: 4.172265370686849

Epoch: 5| Step: 9
Training loss: 4.355576038360596
Validation loss: 4.1664684017499285

Epoch: 5| Step: 10
Training loss: 3.976905107498169
Validation loss: 4.161919126907985

Epoch: 5| Step: 11
Training loss: 5.8987345695495605
Validation loss: 4.157467822233836

Epoch: 16| Step: 0
Training loss: 4.830632209777832
Validation loss: 4.152759810288747

Epoch: 5| Step: 1
Training loss: 4.1656646728515625
Validation loss: 4.147615085045497

Epoch: 5| Step: 2
Training loss: 4.823075294494629
Validation loss: 4.142477254072825

Epoch: 5| Step: 3
Training loss: 4.079370021820068
Validation loss: 4.138655285040538

Epoch: 5| Step: 4
Training loss: 4.672178745269775
Validation loss: 4.133161266644795

Epoch: 5| Step: 5
Training loss: 4.334507465362549
Validation loss: 4.129507333040237

Epoch: 5| Step: 6
Training loss: 4.249561309814453
Validation loss: 4.124212592840195

Epoch: 5| Step: 7
Training loss: 3.6733498573303223
Validation loss: 4.119879911343257

Epoch: 5| Step: 8
Training loss: 3.435718536376953
Validation loss: 4.115721354881923

Epoch: 5| Step: 9
Training loss: 4.106357574462891
Validation loss: 4.111616134643555

Epoch: 5| Step: 10
Training loss: 4.561395168304443
Validation loss: 4.107519805431366

Epoch: 5| Step: 11
Training loss: 4.401106834411621
Validation loss: 4.102196007966995

Epoch: 17| Step: 0
Training loss: 3.8886356353759766
Validation loss: 4.096686035394669

Epoch: 5| Step: 1
Training loss: 4.318018913269043
Validation loss: 4.0932271083196

Epoch: 5| Step: 2
Training loss: 3.8048362731933594
Validation loss: 4.08923218647639

Epoch: 5| Step: 3
Training loss: 3.9830214977264404
Validation loss: 4.084724764029185

Epoch: 5| Step: 4
Training loss: 4.079387187957764
Validation loss: 4.079800724983215

Epoch: 5| Step: 5
Training loss: 4.798640251159668
Validation loss: 4.076755811770757

Epoch: 5| Step: 6
Training loss: 4.47145938873291
Validation loss: 4.069811443487803

Epoch: 5| Step: 7
Training loss: 3.9770920276641846
Validation loss: 4.0646317799886065

Epoch: 5| Step: 8
Training loss: 4.540502071380615
Validation loss: 4.059342245260875

Epoch: 5| Step: 9
Training loss: 4.437368392944336
Validation loss: 4.055265684922536

Epoch: 5| Step: 10
Training loss: 3.6753087043762207
Validation loss: 4.051079471906026

Epoch: 5| Step: 11
Training loss: 6.173511505126953
Validation loss: 4.045924077431361

Epoch: 18| Step: 0
Training loss: 4.467235565185547
Validation loss: 4.0413230160872144

Epoch: 5| Step: 1
Training loss: 4.19033145904541
Validation loss: 4.036415706078212

Epoch: 5| Step: 2
Training loss: 3.9541263580322266
Validation loss: 4.031956752141316

Epoch: 5| Step: 3
Training loss: 3.933655261993408
Validation loss: 4.027137955029805

Epoch: 5| Step: 4
Training loss: 4.872170925140381
Validation loss: 4.0228486855824785

Epoch: 5| Step: 5
Training loss: 3.122995615005493
Validation loss: 4.019057333469391

Epoch: 5| Step: 6
Training loss: 4.0340070724487305
Validation loss: 4.013801475365956

Epoch: 5| Step: 7
Training loss: 4.085230350494385
Validation loss: 4.008804986874263

Epoch: 5| Step: 8
Training loss: 4.407691478729248
Validation loss: 4.00570962826411

Epoch: 5| Step: 9
Training loss: 3.960026502609253
Validation loss: 4.000767866770427

Epoch: 5| Step: 10
Training loss: 4.783239841461182
Validation loss: 3.996441205342611

Epoch: 5| Step: 11
Training loss: 3.926419973373413
Validation loss: 3.99147363503774

Epoch: 19| Step: 0
Training loss: 3.6697945594787598
Validation loss: 3.9866115152835846

Epoch: 5| Step: 1
Training loss: 4.331051826477051
Validation loss: 3.982720583677292

Epoch: 5| Step: 2
Training loss: 3.5903782844543457
Validation loss: 3.977637300888697

Epoch: 5| Step: 3
Training loss: 4.063893795013428
Validation loss: 3.97438191374143

Epoch: 5| Step: 4
Training loss: 4.3703413009643555
Validation loss: 3.969508707523346

Epoch: 5| Step: 5
Training loss: 4.010296821594238
Validation loss: 3.964689244826635

Epoch: 5| Step: 6
Training loss: 3.7982563972473145
Validation loss: 3.9593392511208854

Epoch: 5| Step: 7
Training loss: 4.453953742980957
Validation loss: 3.9545224010944366

Epoch: 5| Step: 8
Training loss: 4.338963508605957
Validation loss: 3.950660228729248

Epoch: 5| Step: 9
Training loss: 4.4856767654418945
Validation loss: 3.9458680550257363

Epoch: 5| Step: 10
Training loss: 4.021433353424072
Validation loss: 3.9408751726150513

Epoch: 5| Step: 11
Training loss: 4.445855140686035
Validation loss: 3.9364130596319833

Epoch: 20| Step: 0
Training loss: 4.4426422119140625
Validation loss: 3.9326912065347037

Epoch: 5| Step: 1
Training loss: 3.6972336769104004
Validation loss: 3.9280182222525277

Epoch: 5| Step: 2
Training loss: 4.418205738067627
Validation loss: 3.9229144553343454

Epoch: 5| Step: 3
Training loss: 4.1812663078308105
Validation loss: 3.918832391500473

Epoch: 5| Step: 4
Training loss: 3.8859169483184814
Validation loss: 3.913819501797358

Epoch: 5| Step: 5
Training loss: 4.227303504943848
Validation loss: 3.9093902508417764

Epoch: 5| Step: 6
Training loss: 3.6828391551971436
Validation loss: 3.904849112033844

Epoch: 5| Step: 7
Training loss: 4.088313579559326
Validation loss: 3.9010088245073953

Epoch: 5| Step: 8
Training loss: 3.4906258583068848
Validation loss: 3.8965417246023812

Epoch: 5| Step: 9
Training loss: 4.233486175537109
Validation loss: 3.8929394582907357

Epoch: 5| Step: 10
Training loss: 4.184080123901367
Validation loss: 3.8884862065315247

Epoch: 5| Step: 11
Training loss: 4.571308612823486
Validation loss: 3.884027282396952

Epoch: 21| Step: 0
Training loss: 4.169280052185059
Validation loss: 3.880759725968043

Epoch: 5| Step: 1
Training loss: 3.6648125648498535
Validation loss: 3.8765013416608176

Epoch: 5| Step: 2
Training loss: 3.3471763134002686
Validation loss: 3.871358464161555

Epoch: 5| Step: 3
Training loss: 2.668658494949341
Validation loss: 3.8678161402543387

Epoch: 5| Step: 4
Training loss: 4.818843364715576
Validation loss: 3.8632732927799225

Epoch: 5| Step: 5
Training loss: 4.003779888153076
Validation loss: 3.859340717395147

Epoch: 5| Step: 6
Training loss: 4.183943748474121
Validation loss: 3.8552511235078177

Epoch: 5| Step: 7
Training loss: 4.101245880126953
Validation loss: 3.8508519530296326

Epoch: 5| Step: 8
Training loss: 4.47257137298584
Validation loss: 3.8464186787605286

Epoch: 5| Step: 9
Training loss: 4.147136211395264
Validation loss: 3.842446804046631

Epoch: 5| Step: 10
Training loss: 4.839352607727051
Validation loss: 3.8383313020070395

Epoch: 5| Step: 11
Training loss: 2.4378769397735596
Validation loss: 3.8339935541152954

Epoch: 22| Step: 0
Training loss: 4.034304618835449
Validation loss: 3.8296983540058136

Epoch: 5| Step: 1
Training loss: 3.607672929763794
Validation loss: 3.825997700293859

Epoch: 5| Step: 2
Training loss: 5.148643493652344
Validation loss: 3.8208711047967276

Epoch: 5| Step: 3
Training loss: 4.378559589385986
Validation loss: 3.8165906270345054

Epoch: 5| Step: 4
Training loss: 3.8502144813537598
Validation loss: 3.8124724427858987

Epoch: 5| Step: 5
Training loss: 3.8711020946502686
Validation loss: 3.80836550394694

Epoch: 5| Step: 6
Training loss: 3.7596771717071533
Validation loss: 3.8039105335871377

Epoch: 5| Step: 7
Training loss: 3.779177188873291
Validation loss: 3.799691597620646

Epoch: 5| Step: 8
Training loss: 2.9307332038879395
Validation loss: 3.7959172825018563

Epoch: 5| Step: 9
Training loss: 4.731724739074707
Validation loss: 3.792213867108027

Epoch: 5| Step: 10
Training loss: 3.221787929534912
Validation loss: 3.7885718842347464

Epoch: 5| Step: 11
Training loss: 5.401246070861816
Validation loss: 3.783884644508362

Epoch: 23| Step: 0
Training loss: 4.5510640144348145
Validation loss: 3.7809358537197113

Epoch: 5| Step: 1
Training loss: 3.1508915424346924
Validation loss: 3.7757613956928253

Epoch: 5| Step: 2
Training loss: 3.5286242961883545
Validation loss: 3.771441469589869

Epoch: 5| Step: 3
Training loss: 4.411228656768799
Validation loss: 3.767728418111801

Epoch: 5| Step: 4
Training loss: 4.5321221351623535
Validation loss: 3.7636889219284058

Epoch: 5| Step: 5
Training loss: 3.0995705127716064
Validation loss: 3.75914536913236

Epoch: 5| Step: 6
Training loss: 4.702995300292969
Validation loss: 3.754702558120092

Epoch: 5| Step: 7
Training loss: 3.35339093208313
Validation loss: 3.7510336140791574

Epoch: 5| Step: 8
Training loss: 3.821685791015625
Validation loss: 3.7469058632850647

Epoch: 5| Step: 9
Training loss: 4.783530235290527
Validation loss: 3.742887129386266

Epoch: 5| Step: 10
Training loss: 3.468553066253662
Validation loss: 3.739124685525894

Epoch: 5| Step: 11
Training loss: 2.3740625381469727
Validation loss: 3.7347107231616974

Epoch: 24| Step: 0
Training loss: 3.3000946044921875
Validation loss: 3.731085310379664

Epoch: 5| Step: 1
Training loss: 4.033291816711426
Validation loss: 3.727000415325165

Epoch: 5| Step: 2
Training loss: 4.14993143081665
Validation loss: 3.723693678776423

Epoch: 5| Step: 3
Training loss: 3.8286991119384766
Validation loss: 3.7198705077171326

Epoch: 5| Step: 4
Training loss: 3.626427412033081
Validation loss: 3.7161370714505515

Epoch: 5| Step: 5
Training loss: 3.902294635772705
Validation loss: 3.712354322274526

Epoch: 5| Step: 6
Training loss: 4.4122209548950195
Validation loss: 3.7086378037929535

Epoch: 5| Step: 7
Training loss: 3.6681008338928223
Validation loss: 3.704902539650599

Epoch: 5| Step: 8
Training loss: 3.7550747394561768
Validation loss: 3.701074719429016

Epoch: 5| Step: 9
Training loss: 4.792414665222168
Validation loss: 3.697380135456721

Epoch: 5| Step: 10
Training loss: 3.349196195602417
Validation loss: 3.693227539459864

Epoch: 5| Step: 11
Training loss: 2.762277126312256
Validation loss: 3.6899928053220115

Epoch: 25| Step: 0
Training loss: 3.918783664703369
Validation loss: 3.6857309142748513

Epoch: 5| Step: 1
Training loss: 3.955127000808716
Validation loss: 3.6822215219338736

Epoch: 5| Step: 2
Training loss: 3.785569667816162
Validation loss: 3.679800659418106

Epoch: 5| Step: 3
Training loss: 3.311702013015747
Validation loss: 3.6764402290185294

Epoch: 5| Step: 4
Training loss: 4.155674934387207
Validation loss: 3.672662168741226

Epoch: 5| Step: 5
Training loss: 3.2531237602233887
Validation loss: 3.667237172524134

Epoch: 5| Step: 6
Training loss: 3.7994091510772705
Validation loss: 3.6622881293296814

Epoch: 5| Step: 7
Training loss: 4.275765419006348
Validation loss: 3.65759868423144

Epoch: 5| Step: 8
Training loss: 3.227036237716675
Validation loss: 3.6540152430534363

Epoch: 5| Step: 9
Training loss: 4.651463508605957
Validation loss: 3.6501400073369346

Epoch: 5| Step: 10
Training loss: 3.856393337249756
Validation loss: 3.646440863609314

Epoch: 5| Step: 11
Training loss: 3.522799015045166
Validation loss: 3.6424624224503837

Epoch: 26| Step: 0
Training loss: 3.700705051422119
Validation loss: 3.6394728422164917

Epoch: 5| Step: 1
Training loss: 3.689666748046875
Validation loss: 3.6348870992660522

Epoch: 5| Step: 2
Training loss: 3.7375595569610596
Validation loss: 3.6304575701554618

Epoch: 5| Step: 3
Training loss: 3.8181121349334717
Validation loss: 3.6269819935162864

Epoch: 5| Step: 4
Training loss: 4.2503814697265625
Validation loss: 3.6232192615667977

Epoch: 5| Step: 5
Training loss: 4.134537696838379
Validation loss: 3.6199103693167367

Epoch: 5| Step: 6
Training loss: 3.4023666381835938
Validation loss: 3.61617120107015

Epoch: 5| Step: 7
Training loss: 4.521126747131348
Validation loss: 3.612537811199824

Epoch: 5| Step: 8
Training loss: 3.2653117179870605
Validation loss: 3.608449121316274

Epoch: 5| Step: 9
Training loss: 3.713233470916748
Validation loss: 3.605144202709198

Epoch: 5| Step: 10
Training loss: 3.3259873390197754
Validation loss: 3.6013440688451133

Epoch: 5| Step: 11
Training loss: 4.017609119415283
Validation loss: 3.5978506406148276

Epoch: 27| Step: 0
Training loss: 3.5548007488250732
Validation loss: 3.593247562646866

Epoch: 5| Step: 1
Training loss: 3.4963011741638184
Validation loss: 3.5893269876639047

Epoch: 5| Step: 2
Training loss: 3.990689754486084
Validation loss: 3.5848717093467712

Epoch: 5| Step: 3
Training loss: 3.7047722339630127
Validation loss: 3.581346184015274

Epoch: 5| Step: 4
Training loss: 3.7150158882141113
Validation loss: 3.577130079269409

Epoch: 5| Step: 5
Training loss: 5.033544063568115
Validation loss: 3.5736113289992013

Epoch: 5| Step: 6
Training loss: 3.418255567550659
Validation loss: 3.5690137147903442

Epoch: 5| Step: 7
Training loss: 3.405677318572998
Validation loss: 3.5647856096426644

Epoch: 5| Step: 8
Training loss: 4.1913018226623535
Validation loss: 3.56129922469457

Epoch: 5| Step: 9
Training loss: 3.741257429122925
Validation loss: 3.5572292606035867

Epoch: 5| Step: 10
Training loss: 3.1016249656677246
Validation loss: 3.5530474384625754

Epoch: 5| Step: 11
Training loss: 2.5674471855163574
Validation loss: 3.549067497253418

Epoch: 28| Step: 0
Training loss: 3.8654961585998535
Validation loss: 3.5509175658226013

Epoch: 5| Step: 1
Training loss: 3.851461410522461
Validation loss: 3.542217512925466

Epoch: 5| Step: 2
Training loss: 3.481416702270508
Validation loss: 3.5384600460529327

Epoch: 5| Step: 3
Training loss: 3.1437885761260986
Validation loss: 3.5345023473103843

Epoch: 5| Step: 4
Training loss: 3.704866409301758
Validation loss: 3.5304193993409476

Epoch: 5| Step: 5
Training loss: 3.982651472091675
Validation loss: 3.5267078379789987

Epoch: 5| Step: 6
Training loss: 3.961958408355713
Validation loss: 3.522841364145279

Epoch: 5| Step: 7
Training loss: 3.4602787494659424
Validation loss: 3.5189274152119956

Epoch: 5| Step: 8
Training loss: 3.8446357250213623
Validation loss: 3.51504909992218

Epoch: 5| Step: 9
Training loss: 3.5539793968200684
Validation loss: 3.5110683540503183

Epoch: 5| Step: 10
Training loss: 3.8940372467041016
Validation loss: 3.5072104036808014

Epoch: 5| Step: 11
Training loss: 3.1205554008483887
Validation loss: 3.503355155388514

Epoch: 29| Step: 0
Training loss: 3.0920374393463135
Validation loss: 3.49978236357371

Epoch: 5| Step: 1
Training loss: 3.8087525367736816
Validation loss: 3.4957646628220878

Epoch: 5| Step: 2
Training loss: 3.0962445735931396
Validation loss: 3.492061197757721

Epoch: 5| Step: 3
Training loss: 3.7741451263427734
Validation loss: 3.4882045785586038

Epoch: 5| Step: 4
Training loss: 3.5737171173095703
Validation loss: 3.4842311441898346

Epoch: 5| Step: 5
Training loss: 3.6233863830566406
Validation loss: 3.4801214238007865

Epoch: 5| Step: 6
Training loss: 3.2898964881896973
Validation loss: 3.476200580596924

Epoch: 5| Step: 7
Training loss: 4.49058723449707
Validation loss: 3.471973498662313

Epoch: 5| Step: 8
Training loss: 3.3806281089782715
Validation loss: 3.467950095733007

Epoch: 5| Step: 9
Training loss: 4.5207319259643555
Validation loss: 3.463828891515732

Epoch: 5| Step: 10
Training loss: 3.5730690956115723
Validation loss: 3.459686130285263

Epoch: 5| Step: 11
Training loss: 3.0674009323120117
Validation loss: 3.456255078315735

Epoch: 30| Step: 0
Training loss: 3.1067850589752197
Validation loss: 3.453017075856527

Epoch: 5| Step: 1
Training loss: 3.4476256370544434
Validation loss: 3.4490680197874704

Epoch: 5| Step: 2
Training loss: 3.678264617919922
Validation loss: 3.443319449822108

Epoch: 5| Step: 3
Training loss: 3.966931104660034
Validation loss: 3.439502477645874

Epoch: 5| Step: 4
Training loss: 3.2732784748077393
Validation loss: 3.436044762531916

Epoch: 5| Step: 5
Training loss: 2.9290008544921875
Validation loss: 3.43242613474528

Epoch: 5| Step: 6
Training loss: 4.052165508270264
Validation loss: 3.428920199473699

Epoch: 5| Step: 7
Training loss: 4.315915107727051
Validation loss: 3.42556498448054

Epoch: 5| Step: 8
Training loss: 4.2936296463012695
Validation loss: 3.4217377404371896

Epoch: 5| Step: 9
Training loss: 3.8488457202911377
Validation loss: 3.417851527531942

Epoch: 5| Step: 10
Training loss: 2.9692673683166504
Validation loss: 3.4140122135480246

Epoch: 5| Step: 11
Training loss: 2.1485743522644043
Validation loss: 3.409893900156021

Epoch: 31| Step: 0
Training loss: 3.345963716506958
Validation loss: 3.406148006518682

Epoch: 5| Step: 1
Training loss: 3.3056323528289795
Validation loss: 3.4024808406829834

Epoch: 5| Step: 2
Training loss: 3.119119167327881
Validation loss: 3.398590564727783

Epoch: 5| Step: 3
Training loss: 3.9718310832977295
Validation loss: 3.3948525389035544

Epoch: 5| Step: 4
Training loss: 3.6932671070098877
Validation loss: 3.3910083572069802

Epoch: 5| Step: 5
Training loss: 4.326101303100586
Validation loss: 3.386621425549189

Epoch: 5| Step: 6
Training loss: 2.7715892791748047
Validation loss: 3.3828101456165314

Epoch: 5| Step: 7
Training loss: 3.811295986175537
Validation loss: 3.378616432348887

Epoch: 5| Step: 8
Training loss: 3.0026235580444336
Validation loss: 3.3749395608901978

Epoch: 5| Step: 9
Training loss: 4.244152069091797
Validation loss: 3.3708090086778006

Epoch: 5| Step: 10
Training loss: 3.864534378051758
Validation loss: 3.3671661814053855

Epoch: 5| Step: 11
Training loss: 1.9037293195724487
Validation loss: 3.3630088170369468

Epoch: 32| Step: 0
Training loss: 4.244661808013916
Validation loss: 3.3597523669401803

Epoch: 5| Step: 1
Training loss: 3.1899731159210205
Validation loss: 3.3558165033658347

Epoch: 5| Step: 2
Training loss: 3.605924129486084
Validation loss: 3.3529433409372964

Epoch: 5| Step: 3
Training loss: 3.0481019020080566
Validation loss: 3.3489281634489694

Epoch: 5| Step: 4
Training loss: 3.693169116973877
Validation loss: 3.3454413612683616

Epoch: 5| Step: 5
Training loss: 2.9691805839538574
Validation loss: 3.341755429903666

Epoch: 5| Step: 6
Training loss: 3.0794477462768555
Validation loss: 3.3383549551169076

Epoch: 5| Step: 7
Training loss: 3.5217087268829346
Validation loss: 3.334938903649648

Epoch: 5| Step: 8
Training loss: 3.2279419898986816
Validation loss: 3.331662485996882

Epoch: 5| Step: 9
Training loss: 4.646279335021973
Validation loss: 3.3278720577557883

Epoch: 5| Step: 10
Training loss: 3.389582395553589
Validation loss: 3.3244034747282663

Epoch: 5| Step: 11
Training loss: 3.6581506729125977
Validation loss: 3.320195515950521

Epoch: 33| Step: 0
Training loss: 3.2310004234313965
Validation loss: 3.3170606990655265

Epoch: 5| Step: 1
Training loss: 3.719533920288086
Validation loss: 3.313172399997711

Epoch: 5| Step: 2
Training loss: 3.704319715499878
Validation loss: 3.30945552388827

Epoch: 5| Step: 3
Training loss: 3.517805814743042
Validation loss: 3.3055320580800376

Epoch: 5| Step: 4
Training loss: 4.291362762451172
Validation loss: 3.301884780327479

Epoch: 5| Step: 5
Training loss: 3.799025774002075
Validation loss: 3.29789204398791

Epoch: 5| Step: 6
Training loss: 3.1443636417388916
Validation loss: 3.2943611244360604

Epoch: 5| Step: 7
Training loss: 3.106478214263916
Validation loss: 3.290572245915731

Epoch: 5| Step: 8
Training loss: 3.0746994018554688
Validation loss: 3.28694878021876

Epoch: 5| Step: 9
Training loss: 3.041369915008545
Validation loss: 3.283350884914398

Epoch: 5| Step: 10
Training loss: 3.4655704498291016
Validation loss: 3.279744803905487

Epoch: 5| Step: 11
Training loss: 4.037564277648926
Validation loss: 3.27609250942866

Epoch: 34| Step: 0
Training loss: 3.5811469554901123
Validation loss: 3.2721965114275613

Epoch: 5| Step: 1
Training loss: 3.6070914268493652
Validation loss: 3.2681018908818564

Epoch: 5| Step: 2
Training loss: 3.130770444869995
Validation loss: 3.264298677444458

Epoch: 5| Step: 3
Training loss: 3.2117676734924316
Validation loss: 3.26028381784757

Epoch: 5| Step: 4
Training loss: 3.4159789085388184
Validation loss: 3.256349563598633

Epoch: 5| Step: 5
Training loss: 3.9781887531280518
Validation loss: 3.2525509198506675

Epoch: 5| Step: 6
Training loss: 3.415053606033325
Validation loss: 3.2489923536777496

Epoch: 5| Step: 7
Training loss: 3.3704521656036377
Validation loss: 3.2452122966448465

Epoch: 5| Step: 8
Training loss: 3.505507230758667
Validation loss: 3.241273125012716

Epoch: 5| Step: 9
Training loss: 3.8401808738708496
Validation loss: 3.2374671200911203

Epoch: 5| Step: 10
Training loss: 2.6745338439941406
Validation loss: 3.233550945917765

Epoch: 5| Step: 11
Training loss: 3.432126522064209
Validation loss: 3.229660948117574

Epoch: 35| Step: 0
Training loss: 3.551456928253174
Validation loss: 3.2258046170075736

Epoch: 5| Step: 1
Training loss: 3.3697478771209717
Validation loss: 3.2215549647808075

Epoch: 5| Step: 2
Training loss: 3.5516693592071533
Validation loss: 3.217577109734217

Epoch: 5| Step: 3
Training loss: 3.1133289337158203
Validation loss: 3.213292290767034

Epoch: 5| Step: 4
Training loss: 3.3229877948760986
Validation loss: 3.208965172370275

Epoch: 5| Step: 5
Training loss: 3.3665339946746826
Validation loss: 3.205041398604711

Epoch: 5| Step: 6
Training loss: 3.994652509689331
Validation loss: 3.2007220486799874

Epoch: 5| Step: 7
Training loss: 4.157469272613525
Validation loss: 3.196944365898768

Epoch: 5| Step: 8
Training loss: 2.799237012863159
Validation loss: 3.1931915283203125

Epoch: 5| Step: 9
Training loss: 3.001098155975342
Validation loss: 3.1900685727596283

Epoch: 5| Step: 10
Training loss: 3.1791915893554688
Validation loss: 3.1861151456832886

Epoch: 5| Step: 11
Training loss: 2.713498592376709
Validation loss: 3.1821293234825134

Epoch: 36| Step: 0
Training loss: 3.54268217086792
Validation loss: 3.1776407063007355

Epoch: 5| Step: 1
Training loss: 3.448371171951294
Validation loss: 3.1742776930332184

Epoch: 5| Step: 2
Training loss: 3.0644309520721436
Validation loss: 3.1707192758719125

Epoch: 5| Step: 3
Training loss: 3.7912888526916504
Validation loss: 3.1668890913327536

Epoch: 5| Step: 4
Training loss: 3.7382893562316895
Validation loss: 3.1628148555755615

Epoch: 5| Step: 5
Training loss: 3.4892146587371826
Validation loss: 3.1585740049680076

Epoch: 5| Step: 6
Training loss: 3.0527193546295166
Validation loss: 3.154880623022715

Epoch: 5| Step: 7
Training loss: 3.127143383026123
Validation loss: 3.151010493437449

Epoch: 5| Step: 8
Training loss: 2.684697151184082
Validation loss: 3.1472242375214896

Epoch: 5| Step: 9
Training loss: 3.193406581878662
Validation loss: 3.1434481143951416

Epoch: 5| Step: 10
Training loss: 3.4531397819519043
Validation loss: 3.1401127179463706

Epoch: 5| Step: 11
Training loss: 4.43076753616333
Validation loss: 3.136542866627375

Epoch: 37| Step: 0
Training loss: 3.139394760131836
Validation loss: 3.132826050122579

Epoch: 5| Step: 1
Training loss: 3.8710379600524902
Validation loss: 3.1290541887283325

Epoch: 5| Step: 2
Training loss: 2.8419039249420166
Validation loss: 3.124944825967153

Epoch: 5| Step: 3
Training loss: 3.235388994216919
Validation loss: 3.121395210425059

Epoch: 5| Step: 4
Training loss: 3.9919395446777344
Validation loss: 3.117276589075724

Epoch: 5| Step: 5
Training loss: 3.8161864280700684
Validation loss: 3.112990985314051

Epoch: 5| Step: 6
Training loss: 2.509815216064453
Validation loss: 3.1096292038758597

Epoch: 5| Step: 7
Training loss: 3.154611349105835
Validation loss: 3.104868878920873

Epoch: 5| Step: 8
Training loss: 3.0299887657165527
Validation loss: 3.1013569136460624

Epoch: 5| Step: 9
Training loss: 3.292632579803467
Validation loss: 3.09929766257604

Epoch: 5| Step: 10
Training loss: 3.3869965076446533
Validation loss: 3.095786899328232

Epoch: 5| Step: 11
Training loss: 3.6384119987487793
Validation loss: 3.101570318142573

Epoch: 38| Step: 0
Training loss: 2.9286036491394043
Validation loss: 3.0876480440298715

Epoch: 5| Step: 1
Training loss: 3.6414878368377686
Validation loss: 3.085398813088735

Epoch: 5| Step: 2
Training loss: 3.6528382301330566
Validation loss: 3.085125356912613

Epoch: 5| Step: 3
Training loss: 2.6884822845458984
Validation loss: 3.0955059130986533

Epoch: 5| Step: 4
Training loss: 3.467589855194092
Validation loss: 3.0828433533509574

Epoch: 5| Step: 5
Training loss: 3.4076244831085205
Validation loss: 3.0762872993946075

Epoch: 5| Step: 6
Training loss: 3.6402366161346436
Validation loss: 3.0738746921221414

Epoch: 5| Step: 7
Training loss: 2.9947781562805176
Validation loss: 3.072303722302119

Epoch: 5| Step: 8
Training loss: 3.084723472595215
Validation loss: 3.070049593846003

Epoch: 5| Step: 9
Training loss: 2.7172093391418457
Validation loss: 3.0673764844735465

Epoch: 5| Step: 10
Training loss: 3.435952663421631
Validation loss: 3.063714067141215

Epoch: 5| Step: 11
Training loss: 4.70375919342041
Validation loss: 3.0588429073492684

Epoch: 39| Step: 0
Training loss: 3.8876781463623047
Validation loss: 3.052597224712372

Epoch: 5| Step: 1
Training loss: 3.171901226043701
Validation loss: 3.047009438276291

Epoch: 5| Step: 2
Training loss: 3.3790297508239746
Validation loss: 3.0420041580994925

Epoch: 5| Step: 3
Training loss: 3.54374623298645
Validation loss: 3.037775844335556

Epoch: 5| Step: 4
Training loss: 2.1966793537139893
Validation loss: 3.0341454644997916

Epoch: 5| Step: 5
Training loss: 3.2432632446289062
Validation loss: 3.0306438505649567

Epoch: 5| Step: 6
Training loss: 3.6557915210723877
Validation loss: 3.0271766682465873

Epoch: 5| Step: 7
Training loss: 2.979199171066284
Validation loss: 3.0239763855934143

Epoch: 5| Step: 8
Training loss: 3.4593396186828613
Validation loss: 3.020709196726481

Epoch: 5| Step: 9
Training loss: 2.726256847381592
Validation loss: 3.0171421468257904

Epoch: 5| Step: 10
Training loss: 3.463494062423706
Validation loss: 3.0131277044614158

Epoch: 5| Step: 11
Training loss: 1.9162592887878418
Validation loss: 3.0099397401014962

Epoch: 40| Step: 0
Training loss: 3.543550968170166
Validation loss: 3.0066295862197876

Epoch: 5| Step: 1
Training loss: 3.2132956981658936
Validation loss: 3.002784470717112

Epoch: 5| Step: 2
Training loss: 2.75342059135437
Validation loss: 2.999697506427765

Epoch: 5| Step: 3
Training loss: 2.9404120445251465
Validation loss: 2.9959953824679055

Epoch: 5| Step: 4
Training loss: 3.127419948577881
Validation loss: 2.9924549559752145

Epoch: 5| Step: 5
Training loss: 4.0607171058654785
Validation loss: 2.9890848994255066

Epoch: 5| Step: 6
Training loss: 3.5957610607147217
Validation loss: 2.986030012369156

Epoch: 5| Step: 7
Training loss: 3.021054744720459
Validation loss: 2.982248604297638

Epoch: 5| Step: 8
Training loss: 3.286790370941162
Validation loss: 2.9790773689746857

Epoch: 5| Step: 9
Training loss: 2.474036693572998
Validation loss: 2.9755895535151162

Epoch: 5| Step: 10
Training loss: 2.7498226165771484
Validation loss: 2.9721864263216653

Epoch: 5| Step: 11
Training loss: 4.520382881164551
Validation loss: 2.9693903028964996

Epoch: 41| Step: 0
Training loss: 2.4720370769500732
Validation loss: 2.965712974468867

Epoch: 5| Step: 1
Training loss: 3.9575607776641846
Validation loss: 2.962912360827128

Epoch: 5| Step: 2
Training loss: 3.3408737182617188
Validation loss: 2.9591153959433236

Epoch: 5| Step: 3
Training loss: 2.275879383087158
Validation loss: 2.95555650194486

Epoch: 5| Step: 4
Training loss: 3.2461845874786377
Validation loss: 2.951384743054708

Epoch: 5| Step: 5
Training loss: 3.220684766769409
Validation loss: 2.948146959145864

Epoch: 5| Step: 6
Training loss: 2.4127917289733887
Validation loss: 2.944565693537394

Epoch: 5| Step: 7
Training loss: 3.7437853813171387
Validation loss: 2.9410420258839927

Epoch: 5| Step: 8
Training loss: 3.5609164237976074
Validation loss: 2.9377582569917045

Epoch: 5| Step: 9
Training loss: 2.946146011352539
Validation loss: 2.9340363244215646

Epoch: 5| Step: 10
Training loss: 3.416083812713623
Validation loss: 2.931185712416967

Epoch: 5| Step: 11
Training loss: 3.321338415145874
Validation loss: 2.9280501107374826

Epoch: 42| Step: 0
Training loss: 3.1476194858551025
Validation loss: 2.9243032137552896

Epoch: 5| Step: 1
Training loss: 3.3238492012023926
Validation loss: 2.921853462855021

Epoch: 5| Step: 2
Training loss: 2.8476204872131348
Validation loss: 2.9243926803270974

Epoch: 5| Step: 3
Training loss: 2.9540112018585205
Validation loss: 2.9171365598837533

Epoch: 5| Step: 4
Training loss: 3.67747163772583
Validation loss: 2.91173122326533

Epoch: 5| Step: 5
Training loss: 2.781611204147339
Validation loss: 2.9089865485827127

Epoch: 5| Step: 6
Training loss: 2.928999662399292
Validation loss: 2.90497479836146

Epoch: 5| Step: 7
Training loss: 3.8570945262908936
Validation loss: 2.9027645885944366

Epoch: 5| Step: 8
Training loss: 2.687476634979248
Validation loss: 2.8988678057988486

Epoch: 5| Step: 9
Training loss: 3.1466166973114014
Validation loss: 2.896620213985443

Epoch: 5| Step: 10
Training loss: 2.9196953773498535
Validation loss: 2.893602102994919

Epoch: 5| Step: 11
Training loss: 2.932955265045166
Validation loss: 2.8906253476937613

Epoch: 43| Step: 0
Training loss: 3.833176374435425
Validation loss: 2.8870087265968323

Epoch: 5| Step: 1
Training loss: 3.7010788917541504
Validation loss: 2.883458524942398

Epoch: 5| Step: 2
Training loss: 2.511356830596924
Validation loss: 2.8796333571275077

Epoch: 5| Step: 3
Training loss: 3.1722655296325684
Validation loss: 2.8758711417516074

Epoch: 5| Step: 4
Training loss: 2.84907865524292
Validation loss: 2.8721025586128235

Epoch: 5| Step: 5
Training loss: 2.66019606590271
Validation loss: 2.8683960835138955

Epoch: 5| Step: 6
Training loss: 3.6981608867645264
Validation loss: 2.8653395076592765

Epoch: 5| Step: 7
Training loss: 2.951982021331787
Validation loss: 2.8620735506216683

Epoch: 5| Step: 8
Training loss: 2.7590079307556152
Validation loss: 2.858622739712397

Epoch: 5| Step: 9
Training loss: 3.084050178527832
Validation loss: 2.855735123157501

Epoch: 5| Step: 10
Training loss: 2.5696732997894287
Validation loss: 2.8526642521222434

Epoch: 5| Step: 11
Training loss: 3.45487117767334
Validation loss: 2.8490785360336304

Epoch: 44| Step: 0
Training loss: 3.8417000770568848
Validation loss: 2.8458343148231506

Epoch: 5| Step: 1
Training loss: 2.6453659534454346
Validation loss: 2.8430992861588797

Epoch: 5| Step: 2
Training loss: 2.6502902507781982
Validation loss: 2.84041694800059

Epoch: 5| Step: 3
Training loss: 2.9820001125335693
Validation loss: 2.8369203309218087

Epoch: 5| Step: 4
Training loss: 2.8114771842956543
Validation loss: 2.8340580761432648

Epoch: 5| Step: 5
Training loss: 2.8928308486938477
Validation loss: 2.831546117862066

Epoch: 5| Step: 6
Training loss: 3.101116895675659
Validation loss: 2.828232447306315

Epoch: 5| Step: 7
Training loss: 3.3359603881835938
Validation loss: 2.8262054324150085

Epoch: 5| Step: 8
Training loss: 2.8556723594665527
Validation loss: 2.822852532068888

Epoch: 5| Step: 9
Training loss: 3.639932155609131
Validation loss: 2.8205365240573883

Epoch: 5| Step: 10
Training loss: 2.735478401184082
Validation loss: 2.818067789077759

Epoch: 5| Step: 11
Training loss: 2.8484280109405518
Validation loss: 2.8145157297452292

Epoch: 45| Step: 0
Training loss: 3.4791526794433594
Validation loss: 2.811085273822149

Epoch: 5| Step: 1
Training loss: 3.043199062347412
Validation loss: 2.808126072088877

Epoch: 5| Step: 2
Training loss: 3.3812484741210938
Validation loss: 2.8052449921766915

Epoch: 5| Step: 3
Training loss: 2.9627063274383545
Validation loss: 2.801487614711126

Epoch: 5| Step: 4
Training loss: 2.3720622062683105
Validation loss: 2.7989308635393777

Epoch: 5| Step: 5
Training loss: 3.640422821044922
Validation loss: 2.79558394352595

Epoch: 5| Step: 6
Training loss: 2.6689953804016113
Validation loss: 2.7926620046297708

Epoch: 5| Step: 7
Training loss: 3.094640016555786
Validation loss: 2.7891192535559335

Epoch: 5| Step: 8
Training loss: 2.664090394973755
Validation loss: 2.7845016717910767

Epoch: 5| Step: 9
Training loss: 2.8036108016967773
Validation loss: 2.7827007472515106

Epoch: 5| Step: 10
Training loss: 3.0744547843933105
Validation loss: 2.77935000260671

Epoch: 5| Step: 11
Training loss: 2.492332935333252
Validation loss: 2.7768510282039642

Epoch: 46| Step: 0
Training loss: 2.751650333404541
Validation loss: 2.77478751540184

Epoch: 5| Step: 1
Training loss: 3.2183146476745605
Validation loss: 2.7709003190199533

Epoch: 5| Step: 2
Training loss: 2.681434154510498
Validation loss: 2.76710107922554

Epoch: 5| Step: 3
Training loss: 2.786470413208008
Validation loss: 2.763985504706701

Epoch: 5| Step: 4
Training loss: 2.8105475902557373
Validation loss: 2.7633765836556754

Epoch: 5| Step: 5
Training loss: 2.501176357269287
Validation loss: 2.7600243190924325

Epoch: 5| Step: 6
Training loss: 3.2556653022766113
Validation loss: 2.7561272978782654

Epoch: 5| Step: 7
Training loss: 3.3309268951416016
Validation loss: 2.752048800388972

Epoch: 5| Step: 8
Training loss: 2.9612631797790527
Validation loss: 2.749537100394567

Epoch: 5| Step: 9
Training loss: 3.630617618560791
Validation loss: 2.747588445742925

Epoch: 5| Step: 10
Training loss: 2.9126040935516357
Validation loss: 2.744927595059077

Epoch: 5| Step: 11
Training loss: 1.9961577653884888
Validation loss: 2.741722732782364

Epoch: 47| Step: 0
Training loss: 3.5329413414001465
Validation loss: 2.7394560476144156

Epoch: 5| Step: 1
Training loss: 2.519768476486206
Validation loss: 2.7358066141605377

Epoch: 5| Step: 2
Training loss: 2.395155191421509
Validation loss: 2.732566843430201

Epoch: 5| Step: 3
Training loss: 3.4240188598632812
Validation loss: 2.7300694286823273

Epoch: 5| Step: 4
Training loss: 3.6699836254119873
Validation loss: 2.7267255584398904

Epoch: 5| Step: 5
Training loss: 2.9667277336120605
Validation loss: 2.723808695872625

Epoch: 5| Step: 6
Training loss: 2.403134822845459
Validation loss: 2.721134295066198

Epoch: 5| Step: 7
Training loss: 2.778934955596924
Validation loss: 2.7175254921118417

Epoch: 5| Step: 8
Training loss: 2.9293131828308105
Validation loss: 2.7150764564673104

Epoch: 5| Step: 9
Training loss: 2.889430284500122
Validation loss: 2.7112780809402466

Epoch: 5| Step: 10
Training loss: 2.7368054389953613
Validation loss: 2.7076989312966666

Epoch: 5| Step: 11
Training loss: 3.0474777221679688
Validation loss: 2.7045158644517264

Epoch: 48| Step: 0
Training loss: 2.2132163047790527
Validation loss: 2.7012426952521005

Epoch: 5| Step: 1
Training loss: 2.7605133056640625
Validation loss: 2.6990586817264557

Epoch: 5| Step: 2
Training loss: 2.911634922027588
Validation loss: 2.695788194735845

Epoch: 5| Step: 3
Training loss: 2.965116024017334
Validation loss: 2.693975647290548

Epoch: 5| Step: 4
Training loss: 2.944340467453003
Validation loss: 2.6910223265488944

Epoch: 5| Step: 5
Training loss: 3.040634870529175
Validation loss: 2.6879264612992606

Epoch: 5| Step: 6
Training loss: 2.7324631214141846
Validation loss: 2.684427579243978

Epoch: 5| Step: 7
Training loss: 3.0621337890625
Validation loss: 2.682849198579788

Epoch: 5| Step: 8
Training loss: 3.1922411918640137
Validation loss: 2.6794231037298837

Epoch: 5| Step: 9
Training loss: 2.772301435470581
Validation loss: 2.67644269267718

Epoch: 5| Step: 10
Training loss: 3.211688995361328
Validation loss: 2.673393835624059

Epoch: 5| Step: 11
Training loss: 3.099843978881836
Validation loss: 2.6706585685412088

Epoch: 49| Step: 0
Training loss: 2.790386438369751
Validation loss: 2.6679097513357797

Epoch: 5| Step: 1
Training loss: 3.175743579864502
Validation loss: 2.664799133936564

Epoch: 5| Step: 2
Training loss: 2.972592353820801
Validation loss: 2.660345494747162

Epoch: 5| Step: 3
Training loss: 2.671668529510498
Validation loss: 2.6584793527921042

Epoch: 5| Step: 4
Training loss: 2.2870306968688965
Validation loss: 2.6574464440345764

Epoch: 5| Step: 5
Training loss: 2.5650010108947754
Validation loss: 2.6533797482649484

Epoch: 5| Step: 6
Training loss: 3.140019178390503
Validation loss: 2.651318003733953

Epoch: 5| Step: 7
Training loss: 2.774181365966797
Validation loss: 2.6489617625872293

Epoch: 5| Step: 8
Training loss: 3.2509827613830566
Validation loss: 2.645660122235616

Epoch: 5| Step: 9
Training loss: 2.533203601837158
Validation loss: 2.6420804957548776

Epoch: 5| Step: 10
Training loss: 3.0696704387664795
Validation loss: 2.6400985419750214

Epoch: 5| Step: 11
Training loss: 4.001588821411133
Validation loss: 2.6362909773985543

Epoch: 50| Step: 0
Training loss: 2.9812190532684326
Validation loss: 2.634065270423889

Epoch: 5| Step: 1
Training loss: 3.3520965576171875
Validation loss: 2.635358909765879

Epoch: 5| Step: 2
Training loss: 3.1258835792541504
Validation loss: 2.634200702110926

Epoch: 5| Step: 3
Training loss: 3.1321725845336914
Validation loss: 2.629823178052902

Epoch: 5| Step: 4
Training loss: 2.5769126415252686
Validation loss: 2.6253255804379783

Epoch: 5| Step: 5
Training loss: 2.4327311515808105
Validation loss: 2.618927309910456

Epoch: 5| Step: 6
Training loss: 2.7225594520568848
Validation loss: 2.617472936709722

Epoch: 5| Step: 7
Training loss: 2.7841689586639404
Validation loss: 2.6131443083286285

Epoch: 5| Step: 8
Training loss: 2.071885824203491
Validation loss: 2.6094181537628174

Epoch: 5| Step: 9
Training loss: 2.7282469272613525
Validation loss: 2.606708546479543

Epoch: 5| Step: 10
Training loss: 3.2645256519317627
Validation loss: 2.6021257837613425

Epoch: 5| Step: 11
Training loss: 2.439485788345337
Validation loss: 2.601292928059896

Epoch: 51| Step: 0
Training loss: 2.749048948287964
Validation loss: 2.5974891682465873

Epoch: 5| Step: 1
Training loss: 2.951525926589966
Validation loss: 2.595534880956014

Epoch: 5| Step: 2
Training loss: 3.520792007446289
Validation loss: 2.5927076935768127

Epoch: 5| Step: 3
Training loss: 2.6166281700134277
Validation loss: 2.590705454349518

Epoch: 5| Step: 4
Training loss: 3.02824068069458
Validation loss: 2.588634600241979

Epoch: 5| Step: 5
Training loss: 1.709681510925293
Validation loss: 2.5856381257375083

Epoch: 5| Step: 6
Training loss: 2.478135824203491
Validation loss: 2.583381096522013

Epoch: 5| Step: 7
Training loss: 2.7499263286590576
Validation loss: 2.580218195915222

Epoch: 5| Step: 8
Training loss: 3.7679851055145264
Validation loss: 2.5756815373897552

Epoch: 5| Step: 9
Training loss: 3.083291530609131
Validation loss: 2.57280166943868

Epoch: 5| Step: 10
Training loss: 2.1176323890686035
Validation loss: 2.570423940817515

Epoch: 5| Step: 11
Training loss: 2.441119432449341
Validation loss: 2.5675814847151437

Epoch: 52| Step: 0
Training loss: 2.7296817302703857
Validation loss: 2.5646046896775565

Epoch: 5| Step: 1
Training loss: 3.0243277549743652
Validation loss: 2.5634639263153076

Epoch: 5| Step: 2
Training loss: 3.0171847343444824
Validation loss: 2.560345704356829

Epoch: 5| Step: 3
Training loss: 2.3382980823516846
Validation loss: 2.558197538057963

Epoch: 5| Step: 4
Training loss: 2.7337069511413574
Validation loss: 2.557259996732076

Epoch: 5| Step: 5
Training loss: 3.5004782676696777
Validation loss: 2.5536491771539054

Epoch: 5| Step: 6
Training loss: 2.8160014152526855
Validation loss: 2.5527224938074746

Epoch: 5| Step: 7
Training loss: 2.2861247062683105
Validation loss: 2.5467094480991364

Epoch: 5| Step: 8
Training loss: 1.8284971714019775
Validation loss: 2.54740908741951

Epoch: 5| Step: 9
Training loss: 3.700833559036255
Validation loss: 2.5472245812416077

Epoch: 5| Step: 10
Training loss: 2.3149309158325195
Validation loss: 2.5394728978474936

Epoch: 5| Step: 11
Training loss: 2.5632240772247314
Validation loss: 2.5373787184556327

Epoch: 53| Step: 0
Training loss: 2.988605499267578
Validation loss: 2.5333327651023865

Epoch: 5| Step: 1
Training loss: 2.66068434715271
Validation loss: 2.530150999625524

Epoch: 5| Step: 2
Training loss: 3.0560147762298584
Validation loss: 2.5265062053998313

Epoch: 5| Step: 3
Training loss: 2.3754336833953857
Validation loss: 2.5258209009965262

Epoch: 5| Step: 4
Training loss: 3.457555055618286
Validation loss: 2.521298954884211

Epoch: 5| Step: 5
Training loss: 1.6801841259002686
Validation loss: 2.5164020458857217

Epoch: 5| Step: 6
Training loss: 2.886770725250244
Validation loss: 2.5167724788188934

Epoch: 5| Step: 7
Training loss: 2.481433868408203
Validation loss: 2.512150834004084

Epoch: 5| Step: 8
Training loss: 2.8104360103607178
Validation loss: 2.5060486694176993

Epoch: 5| Step: 9
Training loss: 2.7649993896484375
Validation loss: 2.5087073047955832

Epoch: 5| Step: 10
Training loss: 2.7556285858154297
Validation loss: 2.504397372404734

Epoch: 5| Step: 11
Training loss: 2.3269600868225098
Validation loss: 2.502880613009135

Epoch: 54| Step: 0
Training loss: 3.0084779262542725
Validation loss: 2.500123699506124

Epoch: 5| Step: 1
Training loss: 2.0771470069885254
Validation loss: 2.495884040991465

Epoch: 5| Step: 2
Training loss: 2.3462724685668945
Validation loss: 2.4924477140108743

Epoch: 5| Step: 3
Training loss: 2.3802313804626465
Validation loss: 2.490002612272898

Epoch: 5| Step: 4
Training loss: 2.639418125152588
Validation loss: 2.489137649536133

Epoch: 5| Step: 5
Training loss: 3.058117628097534
Validation loss: 2.484357565641403

Epoch: 5| Step: 6
Training loss: 2.7701783180236816
Validation loss: 2.4811957677205405

Epoch: 5| Step: 7
Training loss: 3.162381649017334
Validation loss: 2.4767418603102365

Epoch: 5| Step: 8
Training loss: 2.791381359100342
Validation loss: 2.476087599992752

Epoch: 5| Step: 9
Training loss: 2.533398151397705
Validation loss: 2.474339763323466

Epoch: 5| Step: 10
Training loss: 2.6771483421325684
Validation loss: 2.4705830911795297

Epoch: 5| Step: 11
Training loss: 2.628505229949951
Validation loss: 2.468961477279663

Epoch: 55| Step: 0
Training loss: 2.9431843757629395
Validation loss: 2.4624049961566925

Epoch: 5| Step: 1
Training loss: 2.9851341247558594
Validation loss: 2.4640703002611795

Epoch: 5| Step: 2
Training loss: 2.536207437515259
Validation loss: 2.463192323843638

Epoch: 5| Step: 3
Training loss: 1.9838451147079468
Validation loss: 2.462212378780047

Epoch: 5| Step: 4
Training loss: 2.6972129344940186
Validation loss: 2.4613328874111176

Epoch: 5| Step: 5
Training loss: 3.226759433746338
Validation loss: 2.4656999856233597

Epoch: 5| Step: 6
Training loss: 2.0351192951202393
Validation loss: 2.458568294843038

Epoch: 5| Step: 7
Training loss: 2.832549571990967
Validation loss: 2.4528302351633706

Epoch: 5| Step: 8
Training loss: 3.1721549034118652
Validation loss: 2.4450713197390237

Epoch: 5| Step: 9
Training loss: 2.6001667976379395
Validation loss: 2.439621150493622

Epoch: 5| Step: 10
Training loss: 2.071671724319458
Validation loss: 2.4395031233628592

Epoch: 5| Step: 11
Training loss: 2.732144832611084
Validation loss: 2.43732351064682

Epoch: 56| Step: 0
Training loss: 2.3288447856903076
Validation loss: 2.434293270111084

Epoch: 5| Step: 1
Training loss: 2.860602617263794
Validation loss: 2.4317306776841483

Epoch: 5| Step: 2
Training loss: 2.070866346359253
Validation loss: 2.4273450871308646

Epoch: 5| Step: 3
Training loss: 2.6019303798675537
Validation loss: 2.421209901571274

Epoch: 5| Step: 4
Training loss: 2.483166217803955
Validation loss: 2.416705161333084

Epoch: 5| Step: 5
Training loss: 3.1165385246276855
Validation loss: 2.416138912240664

Epoch: 5| Step: 6
Training loss: 3.3676505088806152
Validation loss: 2.413847098747889

Epoch: 5| Step: 7
Training loss: 2.485429525375366
Validation loss: 2.414701988299688

Epoch: 5| Step: 8
Training loss: 2.1579747200012207
Validation loss: 2.416732688744863

Epoch: 5| Step: 9
Training loss: 2.502958297729492
Validation loss: 2.4187047282854715

Epoch: 5| Step: 10
Training loss: 2.6570286750793457
Validation loss: 2.4159552852312722

Epoch: 5| Step: 11
Training loss: 2.8472037315368652
Validation loss: 2.4100885093212128

Epoch: 57| Step: 0
Training loss: 2.2498087882995605
Validation loss: 2.400779366493225

Epoch: 5| Step: 1
Training loss: 2.926313877105713
Validation loss: 2.392722095052401

Epoch: 5| Step: 2
Training loss: 2.345980644226074
Validation loss: 2.392768532037735

Epoch: 5| Step: 3
Training loss: 2.563687801361084
Validation loss: 2.389688183863958

Epoch: 5| Step: 4
Training loss: 2.916832208633423
Validation loss: 2.3900321573019028

Epoch: 5| Step: 5
Training loss: 2.122079372406006
Validation loss: 2.3920563707749047

Epoch: 5| Step: 6
Training loss: 2.431154727935791
Validation loss: 2.3904685328404107

Epoch: 5| Step: 7
Training loss: 2.7696475982666016
Validation loss: 2.3887685189644494

Epoch: 5| Step: 8
Training loss: 2.6021945476531982
Validation loss: 2.389043152332306

Epoch: 5| Step: 9
Training loss: 2.5278260707855225
Validation loss: 2.3845112323760986

Epoch: 5| Step: 10
Training loss: 2.7149245738983154
Validation loss: 2.3781299889087677

Epoch: 5| Step: 11
Training loss: 2.9916772842407227
Validation loss: 2.378705789645513

Epoch: 58| Step: 0
Training loss: 3.0825247764587402
Validation loss: 2.369140555461248

Epoch: 5| Step: 1
Training loss: 2.4559924602508545
Validation loss: 2.3650593161582947

Epoch: 5| Step: 2
Training loss: 2.852700710296631
Validation loss: 2.3633218705654144

Epoch: 5| Step: 3
Training loss: 2.334325075149536
Validation loss: 2.360063925385475

Epoch: 5| Step: 4
Training loss: 2.312225341796875
Validation loss: 2.3549741407235465

Epoch: 5| Step: 5
Training loss: 2.566967487335205
Validation loss: 2.356295441587766

Epoch: 5| Step: 6
Training loss: 2.318903923034668
Validation loss: 2.354398181041082

Epoch: 5| Step: 7
Training loss: 2.4733824729919434
Validation loss: 2.353922208150228

Epoch: 5| Step: 8
Training loss: 2.294112205505371
Validation loss: 2.354216694831848

Epoch: 5| Step: 9
Training loss: 2.578125476837158
Validation loss: 2.3511617680390677

Epoch: 5| Step: 10
Training loss: 2.566697120666504
Validation loss: 2.3497688323259354

Epoch: 5| Step: 11
Training loss: 2.7030739784240723
Validation loss: 2.3434380243221917

Epoch: 59| Step: 0
Training loss: 2.8618006706237793
Validation loss: 2.340023805697759

Epoch: 5| Step: 1
Training loss: 2.3626198768615723
Validation loss: 2.340540423989296

Epoch: 5| Step: 2
Training loss: 3.0407145023345947
Validation loss: 2.3440004537502923

Epoch: 5| Step: 3
Training loss: 2.388876438140869
Validation loss: 2.3452168802420297

Epoch: 5| Step: 4
Training loss: 2.4550869464874268
Validation loss: 2.351850395401319

Epoch: 5| Step: 5
Training loss: 2.7025744915008545
Validation loss: 2.3455757101376853

Epoch: 5| Step: 6
Training loss: 2.2639079093933105
Validation loss: 2.3402061065038047

Epoch: 5| Step: 7
Training loss: 2.551499843597412
Validation loss: 2.340897540251414

Epoch: 5| Step: 8
Training loss: 2.122366428375244
Validation loss: 2.330563853184382

Epoch: 5| Step: 9
Training loss: 2.4746901988983154
Validation loss: 2.3254540115594864

Epoch: 5| Step: 10
Training loss: 2.2494380474090576
Validation loss: 2.321178952852885

Epoch: 5| Step: 11
Training loss: 3.248772382736206
Validation loss: 2.3191754122575126

Epoch: 60| Step: 0
Training loss: 2.688154935836792
Validation loss: 2.31587515771389

Epoch: 5| Step: 1
Training loss: 2.175093650817871
Validation loss: 2.3123689740896225

Epoch: 5| Step: 2
Training loss: 1.9443668127059937
Validation loss: 2.313955783843994

Epoch: 5| Step: 3
Training loss: 2.373769521713257
Validation loss: 2.310416499773661

Epoch: 5| Step: 4
Training loss: 3.0166146755218506
Validation loss: 2.3101303776105246

Epoch: 5| Step: 5
Training loss: 2.1597554683685303
Validation loss: 2.307278801997503

Epoch: 5| Step: 6
Training loss: 2.869081497192383
Validation loss: 2.3018090426921844

Epoch: 5| Step: 7
Training loss: 2.681286334991455
Validation loss: 2.2980418503284454

Epoch: 5| Step: 8
Training loss: 2.1202785968780518
Validation loss: 2.2936133493979773

Epoch: 5| Step: 9
Training loss: 2.3849892616271973
Validation loss: 2.2943823536237082

Epoch: 5| Step: 10
Training loss: 2.5778021812438965
Validation loss: 2.289231856664022

Epoch: 5| Step: 11
Training loss: 3.567030906677246
Validation loss: 2.2856131494045258

Epoch: 61| Step: 0
Training loss: 2.9119820594787598
Validation loss: 2.2861655255158744

Epoch: 5| Step: 1
Training loss: 2.824683666229248
Validation loss: 2.285739560921987

Epoch: 5| Step: 2
Training loss: 2.1670660972595215
Validation loss: 2.2836082875728607

Epoch: 5| Step: 3
Training loss: 2.4792683124542236
Validation loss: 2.279548188050588

Epoch: 5| Step: 4
Training loss: 2.686171054840088
Validation loss: 2.2773369749387107

Epoch: 5| Step: 5
Training loss: 2.7617852687835693
Validation loss: 2.2716773996750512

Epoch: 5| Step: 6
Training loss: 2.6338295936584473
Validation loss: 2.27084252734979

Epoch: 5| Step: 7
Training loss: 2.002927303314209
Validation loss: 2.2667945524056754

Epoch: 5| Step: 8
Training loss: 2.293762683868408
Validation loss: 2.2630312740802765

Epoch: 5| Step: 9
Training loss: 2.092114210128784
Validation loss: 2.2616045077641806

Epoch: 5| Step: 10
Training loss: 2.154872417449951
Validation loss: 2.258321831623713

Epoch: 5| Step: 11
Training loss: 1.8853533267974854
Validation loss: 2.254588633775711

Epoch: 62| Step: 0
Training loss: 2.527722120285034
Validation loss: 2.2520224303007126

Epoch: 5| Step: 1
Training loss: 2.783351421356201
Validation loss: 2.2526990870634713

Epoch: 5| Step: 2
Training loss: 2.2733511924743652
Validation loss: 2.2477234403292337

Epoch: 5| Step: 3
Training loss: 1.9816455841064453
Validation loss: 2.243828852971395

Epoch: 5| Step: 4
Training loss: 1.842156171798706
Validation loss: 2.2406958043575287

Epoch: 5| Step: 5
Training loss: 2.557018995285034
Validation loss: 2.240937272707621

Epoch: 5| Step: 6
Training loss: 3.3220722675323486
Validation loss: 2.2382560471693673

Epoch: 5| Step: 7
Training loss: 2.553412437438965
Validation loss: 2.2345075805981955

Epoch: 5| Step: 8
Training loss: 2.1082329750061035
Validation loss: 2.2352497428655624

Epoch: 5| Step: 9
Training loss: 2.674129009246826
Validation loss: 2.232201427221298

Epoch: 5| Step: 10
Training loss: 1.8644908666610718
Validation loss: 2.2281689196825027

Epoch: 5| Step: 11
Training loss: 2.005788803100586
Validation loss: 2.2316355109214783

Epoch: 63| Step: 0
Training loss: 2.2735347747802734
Validation loss: 2.2275836914777756

Epoch: 5| Step: 1
Training loss: 2.6917221546173096
Validation loss: 2.2219755252202353

Epoch: 5| Step: 2
Training loss: 2.3765668869018555
Validation loss: 2.2260535856088004

Epoch: 5| Step: 3
Training loss: 2.3086323738098145
Validation loss: 2.2200257877508798

Epoch: 5| Step: 4
Training loss: 2.8231358528137207
Validation loss: 2.2152787297964096

Epoch: 5| Step: 5
Training loss: 1.8250789642333984
Validation loss: 2.2173916002114615

Epoch: 5| Step: 6
Training loss: 2.538379430770874
Validation loss: 2.2171503057082496

Epoch: 5| Step: 7
Training loss: 2.1133084297180176
Validation loss: 2.216030885775884

Epoch: 5| Step: 8
Training loss: 2.665872097015381
Validation loss: 2.2120443930228553

Epoch: 5| Step: 9
Training loss: 2.2696423530578613
Validation loss: 2.2152722080548606

Epoch: 5| Step: 10
Training loss: 2.2029244899749756
Validation loss: 2.2095032036304474

Epoch: 5| Step: 11
Training loss: 2.82804536819458
Validation loss: 2.205698718627294

Epoch: 64| Step: 0
Training loss: 2.314993143081665
Validation loss: 2.2025597542524338

Epoch: 5| Step: 1
Training loss: 2.466505527496338
Validation loss: 2.1986168722311654

Epoch: 5| Step: 2
Training loss: 2.2652926445007324
Validation loss: 2.197447886069616

Epoch: 5| Step: 3
Training loss: 1.6192200183868408
Validation loss: 2.198866218328476

Epoch: 5| Step: 4
Training loss: 2.3371922969818115
Validation loss: 2.1938345233599343

Epoch: 5| Step: 5
Training loss: 2.5497078895568848
Validation loss: 2.192572772502899

Epoch: 5| Step: 6
Training loss: 2.531841516494751
Validation loss: 2.1952428072690964

Epoch: 5| Step: 7
Training loss: 2.5272457599639893
Validation loss: 2.190622309843699

Epoch: 5| Step: 8
Training loss: 2.5889503955841064
Validation loss: 2.192807619770368

Epoch: 5| Step: 9
Training loss: 2.2856597900390625
Validation loss: 2.193783422311147

Epoch: 5| Step: 10
Training loss: 2.3248488903045654
Validation loss: 2.187836706638336

Epoch: 5| Step: 11
Training loss: 2.6226236820220947
Validation loss: 2.189384331305822

Epoch: 65| Step: 0
Training loss: 2.506906509399414
Validation loss: 2.1858191589514413

Epoch: 5| Step: 1
Training loss: 1.9583852291107178
Validation loss: 2.183509315053622

Epoch: 5| Step: 2
Training loss: 2.4510512351989746
Validation loss: 2.1817569037278495

Epoch: 5| Step: 3
Training loss: 2.282276153564453
Validation loss: 2.1787026127179465

Epoch: 5| Step: 4
Training loss: 2.403383255004883
Validation loss: 2.1779216825962067

Epoch: 5| Step: 5
Training loss: 2.398200511932373
Validation loss: 2.1786112685998282

Epoch: 5| Step: 6
Training loss: 2.1418726444244385
Validation loss: 2.16988343000412

Epoch: 5| Step: 7
Training loss: 2.4568963050842285
Validation loss: 2.17188490430514

Epoch: 5| Step: 8
Training loss: 2.3612265586853027
Validation loss: 2.1748257180054984

Epoch: 5| Step: 9
Training loss: 2.3341376781463623
Validation loss: 2.173499663670858

Epoch: 5| Step: 10
Training loss: 2.4987645149230957
Validation loss: 2.1706720292568207

Epoch: 5| Step: 11
Training loss: 2.0428671836853027
Validation loss: 2.1672584613164267

Epoch: 66| Step: 0
Training loss: 2.6807339191436768
Validation loss: 2.1641240417957306

Epoch: 5| Step: 1
Training loss: 2.1866040229797363
Validation loss: 2.1699198136727014

Epoch: 5| Step: 2
Training loss: 2.166959285736084
Validation loss: 2.183755397796631

Epoch: 5| Step: 3
Training loss: 1.8723729848861694
Validation loss: 2.2114042143026986

Epoch: 5| Step: 4
Training loss: 2.3821022510528564
Validation loss: 2.213195155064265

Epoch: 5| Step: 5
Training loss: 2.6469051837921143
Validation loss: 2.19752270479997

Epoch: 5| Step: 6
Training loss: 2.5960190296173096
Validation loss: 2.177244797348976

Epoch: 5| Step: 7
Training loss: 2.8327975273132324
Validation loss: 2.165147145589193

Epoch: 5| Step: 8
Training loss: 2.3032116889953613
Validation loss: 2.15943110982577

Epoch: 5| Step: 9
Training loss: 2.0172677040100098
Validation loss: 2.1628002425034842

Epoch: 5| Step: 10
Training loss: 1.8764495849609375
Validation loss: 2.168634762366613

Epoch: 5| Step: 11
Training loss: 3.6363446712493896
Validation loss: 2.182213847835859

Epoch: 67| Step: 0
Training loss: 2.028235673904419
Validation loss: 2.176355625192324

Epoch: 5| Step: 1
Training loss: 2.503135919570923
Validation loss: 2.1703331768512726

Epoch: 5| Step: 2
Training loss: 2.834587812423706
Validation loss: 2.1684235284725824

Epoch: 5| Step: 3
Training loss: 2.5340774059295654
Validation loss: 2.161383256316185

Epoch: 5| Step: 4
Training loss: 2.5003457069396973
Validation loss: 2.1613697359959283

Epoch: 5| Step: 5
Training loss: 1.5825365781784058
Validation loss: 2.1598183711369834

Epoch: 5| Step: 6
Training loss: 2.0067124366760254
Validation loss: 2.1560016870498657

Epoch: 5| Step: 7
Training loss: 2.1427135467529297
Validation loss: 2.1548228760560355

Epoch: 5| Step: 8
Training loss: 2.695756196975708
Validation loss: 2.148779938618342

Epoch: 5| Step: 9
Training loss: 2.4123504161834717
Validation loss: 2.1466294129689536

Epoch: 5| Step: 10
Training loss: 2.365072727203369
Validation loss: 2.1419416069984436

Epoch: 5| Step: 11
Training loss: 2.470449447631836
Validation loss: 2.1418559153874717

Epoch: 68| Step: 0
Training loss: 2.1432979106903076
Validation loss: 2.1394611398379006

Epoch: 5| Step: 1
Training loss: 2.373249053955078
Validation loss: 2.134628027677536

Epoch: 5| Step: 2
Training loss: 2.342867612838745
Validation loss: 2.130805864930153

Epoch: 5| Step: 3
Training loss: 2.345717191696167
Validation loss: 2.1296741565068564

Epoch: 5| Step: 4
Training loss: 2.0052199363708496
Validation loss: 2.1322874277830124

Epoch: 5| Step: 5
Training loss: 2.3449223041534424
Validation loss: 2.1290068527062735

Epoch: 5| Step: 6
Training loss: 2.210930585861206
Validation loss: 2.128739058971405

Epoch: 5| Step: 7
Training loss: 1.7694613933563232
Validation loss: 2.118121087551117

Epoch: 5| Step: 8
Training loss: 2.3342199325561523
Validation loss: 2.118352929751078

Epoch: 5| Step: 9
Training loss: 2.411958694458008
Validation loss: 2.1103524565696716

Epoch: 5| Step: 10
Training loss: 2.965904951095581
Validation loss: 2.1159717639287314

Epoch: 5| Step: 11
Training loss: 2.475346565246582
Validation loss: 2.11248346666495

Epoch: 69| Step: 0
Training loss: 2.3896288871765137
Validation loss: 2.114486495653788

Epoch: 5| Step: 1
Training loss: 1.9023510217666626
Validation loss: 2.1159496108690896

Epoch: 5| Step: 2
Training loss: 2.5447142124176025
Validation loss: 2.1115516821543374

Epoch: 5| Step: 3
Training loss: 1.700998306274414
Validation loss: 2.115368202328682

Epoch: 5| Step: 4
Training loss: 2.5262763500213623
Validation loss: 2.1119033992290497

Epoch: 5| Step: 5
Training loss: 2.574916124343872
Validation loss: 2.1117925494909286

Epoch: 5| Step: 6
Training loss: 2.826953172683716
Validation loss: 2.1100465257962546

Epoch: 5| Step: 7
Training loss: 2.3160743713378906
Validation loss: 2.1137711505095163

Epoch: 5| Step: 8
Training loss: 2.1855480670928955
Validation loss: 2.110265702009201

Epoch: 5| Step: 9
Training loss: 1.9307184219360352
Validation loss: 2.110974222421646

Epoch: 5| Step: 10
Training loss: 2.460310459136963
Validation loss: 2.1116916487614312

Epoch: 5| Step: 11
Training loss: 1.3075637817382812
Validation loss: 2.1136774520079293

Epoch: 70| Step: 0
Training loss: 1.4415037631988525
Validation loss: 2.1124160289764404

Epoch: 5| Step: 1
Training loss: 2.2571380138397217
Validation loss: 2.114329914251963

Epoch: 5| Step: 2
Training loss: 2.421520471572876
Validation loss: 2.11664409438769

Epoch: 5| Step: 3
Training loss: 2.3734419345855713
Validation loss: 2.1118138134479523

Epoch: 5| Step: 4
Training loss: 2.335634231567383
Validation loss: 2.108791336417198

Epoch: 5| Step: 5
Training loss: 1.8545910120010376
Validation loss: 2.107880800962448

Epoch: 5| Step: 6
Training loss: 2.646369457244873
Validation loss: 2.105372945467631

Epoch: 5| Step: 7
Training loss: 2.0253102779388428
Validation loss: 2.102679873506228

Epoch: 5| Step: 8
Training loss: 2.759805679321289
Validation loss: 2.104883521795273

Epoch: 5| Step: 9
Training loss: 2.552467107772827
Validation loss: 2.1076592803001404

Epoch: 5| Step: 10
Training loss: 2.5764455795288086
Validation loss: 2.0985064009825387

Epoch: 5| Step: 11
Training loss: 1.7506604194641113
Validation loss: 2.092472553253174

Epoch: 71| Step: 0
Training loss: 2.04844331741333
Validation loss: 2.099053164323171

Epoch: 5| Step: 1
Training loss: 2.0206360816955566
Validation loss: 2.0933540016412735

Epoch: 5| Step: 2
Training loss: 1.8224674463272095
Validation loss: 2.0849446753660836

Epoch: 5| Step: 3
Training loss: 2.521120548248291
Validation loss: 2.092344969511032

Epoch: 5| Step: 4
Training loss: 2.092041492462158
Validation loss: 2.0926177153984704

Epoch: 5| Step: 5
Training loss: 2.213879346847534
Validation loss: 2.0959889640410743

Epoch: 5| Step: 6
Training loss: 2.4558658599853516
Validation loss: 2.0929183711608252

Epoch: 5| Step: 7
Training loss: 2.1436927318573
Validation loss: 2.095945358276367

Epoch: 5| Step: 8
Training loss: 2.525559902191162
Validation loss: 2.095890372991562

Epoch: 5| Step: 9
Training loss: 2.3670291900634766
Validation loss: 2.098133678237597

Epoch: 5| Step: 10
Training loss: 2.576044797897339
Validation loss: 2.094332511226336

Epoch: 5| Step: 11
Training loss: 3.209808111190796
Validation loss: 2.0968028604984283

Epoch: 72| Step: 0
Training loss: 2.1550161838531494
Validation loss: 2.100197042028109

Epoch: 5| Step: 1
Training loss: 2.472447633743286
Validation loss: 2.0906296769777932

Epoch: 5| Step: 2
Training loss: 2.016702175140381
Validation loss: 2.090990344683329

Epoch: 5| Step: 3
Training loss: 2.6897387504577637
Validation loss: 2.09060208996137

Epoch: 5| Step: 4
Training loss: 2.196463108062744
Validation loss: 2.0957055340210595

Epoch: 5| Step: 5
Training loss: 2.266249895095825
Validation loss: 2.0880829294522605

Epoch: 5| Step: 6
Training loss: 1.9172061681747437
Validation loss: 2.083353102207184

Epoch: 5| Step: 7
Training loss: 2.0730397701263428
Validation loss: 2.0752357294162116

Epoch: 5| Step: 8
Training loss: 2.550257444381714
Validation loss: 2.0688655426104865

Epoch: 5| Step: 9
Training loss: 1.8546559810638428
Validation loss: 2.0690127660830817

Epoch: 5| Step: 10
Training loss: 2.757073402404785
Validation loss: 2.0702510128418603

Epoch: 5| Step: 11
Training loss: 1.5919578075408936
Validation loss: 2.06821316977342

Epoch: 73| Step: 0
Training loss: 1.6694791316986084
Validation loss: 2.073807716369629

Epoch: 5| Step: 1
Training loss: 2.4868528842926025
Validation loss: 2.0767573763926825

Epoch: 5| Step: 2
Training loss: 2.5136542320251465
Validation loss: 2.0656989167133966

Epoch: 5| Step: 3
Training loss: 2.405378818511963
Validation loss: 2.0615237702926

Epoch: 5| Step: 4
Training loss: 2.4580512046813965
Validation loss: 2.062515844901403

Epoch: 5| Step: 5
Training loss: 2.029721260070801
Validation loss: 2.0601377189159393

Epoch: 5| Step: 6
Training loss: 2.1913676261901855
Validation loss: 2.063036988178889

Epoch: 5| Step: 7
Training loss: 1.9818007946014404
Validation loss: 2.0615494151910148

Epoch: 5| Step: 8
Training loss: 2.3515305519104004
Validation loss: 2.0686437785625458

Epoch: 5| Step: 9
Training loss: 2.2570083141326904
Validation loss: 2.074618632594744

Epoch: 5| Step: 10
Training loss: 2.2855350971221924
Validation loss: 2.0757311433553696

Epoch: 5| Step: 11
Training loss: 2.1524810791015625
Validation loss: 2.071667969226837

Epoch: 74| Step: 0
Training loss: 2.1773998737335205
Validation loss: 2.0805343041817346

Epoch: 5| Step: 1
Training loss: 1.8461147546768188
Validation loss: 2.086205537120501

Epoch: 5| Step: 2
Training loss: 2.2714598178863525
Validation loss: 2.085939516623815

Epoch: 5| Step: 3
Training loss: 2.5795397758483887
Validation loss: 2.088018467028936

Epoch: 5| Step: 4
Training loss: 2.299924612045288
Validation loss: 2.08737376332283

Epoch: 5| Step: 5
Training loss: 2.1524569988250732
Validation loss: 2.078519662221273

Epoch: 5| Step: 6
Training loss: 2.0513312816619873
Validation loss: 2.0847209890683494

Epoch: 5| Step: 7
Training loss: 2.1183841228485107
Validation loss: 2.082179442048073

Epoch: 5| Step: 8
Training loss: 2.552168607711792
Validation loss: 2.0738807370265326

Epoch: 5| Step: 9
Training loss: 1.9814817905426025
Validation loss: 2.0664209872484207

Epoch: 5| Step: 10
Training loss: 2.5430643558502197
Validation loss: 2.065380319952965

Epoch: 5| Step: 11
Training loss: 3.6012163162231445
Validation loss: 2.066112811366717

Epoch: 75| Step: 0
Training loss: 2.061985492706299
Validation loss: 2.058954045176506

Epoch: 5| Step: 1
Training loss: 1.7103111743927002
Validation loss: 2.059660022457441

Epoch: 5| Step: 2
Training loss: 2.382577419281006
Validation loss: 2.058574065566063

Epoch: 5| Step: 3
Training loss: 2.414247989654541
Validation loss: 2.058062498768171

Epoch: 5| Step: 4
Training loss: 2.376077651977539
Validation loss: 2.0562612364689508

Epoch: 5| Step: 5
Training loss: 2.454195737838745
Validation loss: 2.061075910925865

Epoch: 5| Step: 6
Training loss: 2.0563292503356934
Validation loss: 2.0586844136317572

Epoch: 5| Step: 7
Training loss: 2.832221508026123
Validation loss: 2.0481014351050058

Epoch: 5| Step: 8
Training loss: 2.0602385997772217
Validation loss: 2.049167344967524

Epoch: 5| Step: 9
Training loss: 2.5875494480133057
Validation loss: 2.040069798628489

Epoch: 5| Step: 10
Training loss: 1.7749061584472656
Validation loss: 2.0374098072449365

Epoch: 5| Step: 11
Training loss: 1.9018930196762085
Validation loss: 2.045448382695516

Epoch: 76| Step: 0
Training loss: 2.1381819248199463
Validation loss: 2.0448117355505624

Epoch: 5| Step: 1
Training loss: 2.357067346572876
Validation loss: 2.051604762673378

Epoch: 5| Step: 2
Training loss: 2.4085843563079834
Validation loss: 2.0559805085261664

Epoch: 5| Step: 3
Training loss: 1.8880094289779663
Validation loss: 2.0481181691090264

Epoch: 5| Step: 4
Training loss: 2.1468758583068848
Validation loss: 2.041969418525696

Epoch: 5| Step: 5
Training loss: 2.0796139240264893
Validation loss: 2.0415605256954827

Epoch: 5| Step: 6
Training loss: 2.303724765777588
Validation loss: 2.041424204905828

Epoch: 5| Step: 7
Training loss: 2.190638780593872
Validation loss: 2.039201557636261

Epoch: 5| Step: 8
Training loss: 2.3144912719726562
Validation loss: 2.0465953250726066

Epoch: 5| Step: 9
Training loss: 2.501913547515869
Validation loss: 2.036208361387253

Epoch: 5| Step: 10
Training loss: 2.0405306816101074
Validation loss: 2.037278950214386

Epoch: 5| Step: 11
Training loss: 3.055650472640991
Validation loss: 2.038741424679756

Epoch: 77| Step: 0
Training loss: 2.1022286415100098
Validation loss: 2.041751896341642

Epoch: 5| Step: 1
Training loss: 1.7131887674331665
Validation loss: 2.043341025710106

Epoch: 5| Step: 2
Training loss: 2.3281712532043457
Validation loss: 2.038563465078672

Epoch: 5| Step: 3
Training loss: 2.2406041622161865
Validation loss: 2.0399505297342935

Epoch: 5| Step: 4
Training loss: 2.6192188262939453
Validation loss: 2.036582365632057

Epoch: 5| Step: 5
Training loss: 2.258021593093872
Validation loss: 2.032775248090426

Epoch: 5| Step: 6
Training loss: 2.4022438526153564
Validation loss: 2.032471016049385

Epoch: 5| Step: 7
Training loss: 2.1207618713378906
Validation loss: 2.0346723397572837

Epoch: 5| Step: 8
Training loss: 1.7832202911376953
Validation loss: 2.0344789177179337

Epoch: 5| Step: 9
Training loss: 2.675554037094116
Validation loss: 2.0336671620607376

Epoch: 5| Step: 10
Training loss: 2.2730438709259033
Validation loss: 2.0289473086595535

Epoch: 5| Step: 11
Training loss: 1.6143864393234253
Validation loss: 2.0313706596692405

Epoch: 78| Step: 0
Training loss: 2.3644981384277344
Validation loss: 2.026881749431292

Epoch: 5| Step: 1
Training loss: 2.1962637901306152
Validation loss: 2.0327098270257316

Epoch: 5| Step: 2
Training loss: 2.0579028129577637
Validation loss: 2.0303427626689277

Epoch: 5| Step: 3
Training loss: 1.603628396987915
Validation loss: 2.028165355324745

Epoch: 5| Step: 4
Training loss: 2.062605381011963
Validation loss: 2.033611550927162

Epoch: 5| Step: 5
Training loss: 2.089853525161743
Validation loss: 2.0311677952607474

Epoch: 5| Step: 6
Training loss: 1.823421835899353
Validation loss: 2.0318171282609305

Epoch: 5| Step: 7
Training loss: 2.1417744159698486
Validation loss: 2.029410863916079

Epoch: 5| Step: 8
Training loss: 2.4608852863311768
Validation loss: 2.0267293949921927

Epoch: 5| Step: 9
Training loss: 2.802556276321411
Validation loss: 2.024901400009791

Epoch: 5| Step: 10
Training loss: 2.546949625015259
Validation loss: 2.026144797603289

Epoch: 5| Step: 11
Training loss: 3.219738483428955
Validation loss: 2.0336099714040756

Epoch: 79| Step: 0
Training loss: 2.0850954055786133
Validation loss: 2.027683675289154

Epoch: 5| Step: 1
Training loss: 2.1317427158355713
Validation loss: 2.0266780902942023

Epoch: 5| Step: 2
Training loss: 2.0718514919281006
Validation loss: 2.033872420589129

Epoch: 5| Step: 3
Training loss: 2.1882355213165283
Validation loss: 2.028029292821884

Epoch: 5| Step: 4
Training loss: 1.7998268604278564
Validation loss: 2.0274414718151093

Epoch: 5| Step: 5
Training loss: 2.590087890625
Validation loss: 2.027332901954651

Epoch: 5| Step: 6
Training loss: 2.335949420928955
Validation loss: 2.027013639609019

Epoch: 5| Step: 7
Training loss: 2.468158483505249
Validation loss: 2.02176670730114

Epoch: 5| Step: 8
Training loss: 2.247077226638794
Validation loss: 2.0217828353246055

Epoch: 5| Step: 9
Training loss: 1.9710496664047241
Validation loss: 2.0222526540358863

Epoch: 5| Step: 10
Training loss: 2.354241371154785
Validation loss: 2.0261767208576202

Epoch: 5| Step: 11
Training loss: 2.6070187091827393
Validation loss: 2.0308848122755685

Epoch: 80| Step: 0
Training loss: 2.2939112186431885
Validation loss: 2.026156316200892

Epoch: 5| Step: 1
Training loss: 1.259011149406433
Validation loss: 2.0234521478414536

Epoch: 5| Step: 2
Training loss: 1.956363320350647
Validation loss: 2.0208377142747245

Epoch: 5| Step: 3
Training loss: 2.4163506031036377
Validation loss: 2.0176439583301544

Epoch: 5| Step: 4
Training loss: 2.0636887550354004
Validation loss: 2.023078128695488

Epoch: 5| Step: 5
Training loss: 1.6656583547592163
Validation loss: 2.0260984549919763

Epoch: 5| Step: 6
Training loss: 2.6850318908691406
Validation loss: 2.025678043564161

Epoch: 5| Step: 7
Training loss: 2.415806770324707
Validation loss: 2.0244343280792236

Epoch: 5| Step: 8
Training loss: 2.3704700469970703
Validation loss: 2.0312785506248474

Epoch: 5| Step: 9
Training loss: 2.4553799629211426
Validation loss: 2.0312429318825402

Epoch: 5| Step: 10
Training loss: 2.6364798545837402
Validation loss: 2.0207807471354804

Epoch: 5| Step: 11
Training loss: 1.9683231115341187
Validation loss: 2.023464853564898

Epoch: 81| Step: 0
Training loss: 1.9888206720352173
Validation loss: 2.0308606773614883

Epoch: 5| Step: 1
Training loss: 2.001612424850464
Validation loss: 2.0292652944723764

Epoch: 5| Step: 2
Training loss: 2.506687641143799
Validation loss: 2.035056382417679

Epoch: 5| Step: 3
Training loss: 2.7461600303649902
Validation loss: 2.034710014859835

Epoch: 5| Step: 4
Training loss: 2.856025218963623
Validation loss: 2.032413790623347

Epoch: 5| Step: 5
Training loss: 2.0531513690948486
Validation loss: 2.021715904275576

Epoch: 5| Step: 6
Training loss: 2.109614610671997
Validation loss: 2.0266253451506295

Epoch: 5| Step: 7
Training loss: 1.9041475057601929
Validation loss: 2.0291593025128045

Epoch: 5| Step: 8
Training loss: 2.2726502418518066
Validation loss: 2.0284916311502457

Epoch: 5| Step: 9
Training loss: 1.7624527215957642
Validation loss: 2.020894408226013

Epoch: 5| Step: 10
Training loss: 1.891237497329712
Validation loss: 2.023494745294253

Epoch: 5| Step: 11
Training loss: 2.3822145462036133
Validation loss: 2.0261250734329224

Epoch: 82| Step: 0
Training loss: 2.0220675468444824
Validation loss: 2.0332442919413247

Epoch: 5| Step: 1
Training loss: 2.1979825496673584
Validation loss: 2.0234556744496026

Epoch: 5| Step: 2
Training loss: 2.099695920944214
Validation loss: 2.037858431537946

Epoch: 5| Step: 3
Training loss: 2.707655429840088
Validation loss: 2.041307548681895

Epoch: 5| Step: 4
Training loss: 1.729193091392517
Validation loss: 2.0373482952515283

Epoch: 5| Step: 5
Training loss: 2.3848252296447754
Validation loss: 2.0554565538962684

Epoch: 5| Step: 6
Training loss: 2.2724297046661377
Validation loss: 2.055608481168747

Epoch: 5| Step: 7
Training loss: 2.077362537384033
Validation loss: 2.0587259928385415

Epoch: 5| Step: 8
Training loss: 1.8159087896347046
Validation loss: 2.0634118020534515

Epoch: 5| Step: 9
Training loss: 2.561225175857544
Validation loss: 2.0509342501560845

Epoch: 5| Step: 10
Training loss: 2.3818702697753906
Validation loss: 2.0307668149471283

Epoch: 5| Step: 11
Training loss: 1.912899374961853
Validation loss: 2.0277438710133233

Epoch: 83| Step: 0
Training loss: 1.9797160625457764
Validation loss: 2.0191722561915717

Epoch: 5| Step: 1
Training loss: 2.4024393558502197
Validation loss: 2.0219957331816354

Epoch: 5| Step: 2
Training loss: 2.3270795345306396
Validation loss: 2.0178399682044983

Epoch: 5| Step: 3
Training loss: 2.168395757675171
Validation loss: 2.022432247797648

Epoch: 5| Step: 4
Training loss: 2.3154006004333496
Validation loss: 2.0233025600512824

Epoch: 5| Step: 5
Training loss: 2.2209746837615967
Validation loss: 2.013485466440519

Epoch: 5| Step: 6
Training loss: 2.1260809898376465
Validation loss: 2.011240487297376

Epoch: 5| Step: 7
Training loss: 2.2481071949005127
Validation loss: 2.0071599384148917

Epoch: 5| Step: 8
Training loss: 1.8285131454467773
Validation loss: 2.010321502884229

Epoch: 5| Step: 9
Training loss: 2.6727051734924316
Validation loss: 2.015933111310005

Epoch: 5| Step: 10
Training loss: 1.7895824909210205
Validation loss: 2.0167791148026786

Epoch: 5| Step: 11
Training loss: 2.1096863746643066
Validation loss: 2.0088883439699807

Epoch: 84| Step: 0
Training loss: 1.8623749017715454
Validation loss: 2.015338326493899

Epoch: 5| Step: 1
Training loss: 1.6073697805404663
Validation loss: 2.0341566056013107

Epoch: 5| Step: 2
Training loss: 2.3337886333465576
Validation loss: 2.038934682806333

Epoch: 5| Step: 3
Training loss: 2.4194912910461426
Validation loss: 2.047013983130455

Epoch: 5| Step: 4
Training loss: 2.349329710006714
Validation loss: 2.0617158313592276

Epoch: 5| Step: 5
Training loss: 1.7456127405166626
Validation loss: 2.072763135035833

Epoch: 5| Step: 6
Training loss: 2.38417649269104
Validation loss: 2.06535097459952

Epoch: 5| Step: 7
Training loss: 3.0045535564422607
Validation loss: 2.064458042383194

Epoch: 5| Step: 8
Training loss: 1.9044055938720703
Validation loss: 2.0417710493008294

Epoch: 5| Step: 9
Training loss: 2.7518935203552246
Validation loss: 2.031752278407415

Epoch: 5| Step: 10
Training loss: 2.003739595413208
Validation loss: 2.024878203868866

Epoch: 5| Step: 11
Training loss: 1.4431874752044678
Validation loss: 2.0185839434464774

Epoch: 85| Step: 0
Training loss: 2.242584705352783
Validation loss: 2.023406987388929

Epoch: 5| Step: 1
Training loss: 2.319044351577759
Validation loss: 2.026730537414551

Epoch: 5| Step: 2
Training loss: 2.3995394706726074
Validation loss: 2.033870314558347

Epoch: 5| Step: 3
Training loss: 1.9707351922988892
Validation loss: 2.0410775740941367

Epoch: 5| Step: 4
Training loss: 2.1908249855041504
Validation loss: 2.0416436145702996

Epoch: 5| Step: 5
Training loss: 1.9009730815887451
Validation loss: 2.040559565027555

Epoch: 5| Step: 6
Training loss: 1.5678050518035889
Validation loss: 2.0447094241778054

Epoch: 5| Step: 7
Training loss: 2.0919718742370605
Validation loss: 2.0447549323240914

Epoch: 5| Step: 8
Training loss: 2.8919174671173096
Validation loss: 2.0493561724821725

Epoch: 5| Step: 9
Training loss: 2.6724002361297607
Validation loss: 2.0420498798290887

Epoch: 5| Step: 10
Training loss: 2.0689644813537598
Validation loss: 2.0426287402709327

Epoch: 5| Step: 11
Training loss: 2.6116104125976562
Validation loss: 2.0354229658842087

Epoch: 86| Step: 0
Training loss: 2.140300750732422
Validation loss: 2.040875961383184

Epoch: 5| Step: 1
Training loss: 2.0982861518859863
Validation loss: 2.044580345352491

Epoch: 5| Step: 2
Training loss: 2.2783560752868652
Validation loss: 2.035127411286036

Epoch: 5| Step: 3
Training loss: 2.17069673538208
Validation loss: 2.0352591474850974

Epoch: 5| Step: 4
Training loss: 2.523233413696289
Validation loss: 2.034884954492251

Epoch: 5| Step: 5
Training loss: 2.540276527404785
Validation loss: 2.0254086603720984

Epoch: 5| Step: 6
Training loss: 1.7381150722503662
Validation loss: 2.01927882929643

Epoch: 5| Step: 7
Training loss: 2.0023417472839355
Validation loss: 2.019422546029091

Epoch: 5| Step: 8
Training loss: 2.083134412765503
Validation loss: 2.0186012536287308

Epoch: 5| Step: 9
Training loss: 2.246600389480591
Validation loss: 2.019327541192373

Epoch: 5| Step: 10
Training loss: 2.179960012435913
Validation loss: 2.028184245030085

Epoch: 5| Step: 11
Training loss: 2.4390978813171387
Validation loss: 2.0331491778294244

Epoch: 87| Step: 0
Training loss: 2.3383851051330566
Validation loss: 2.0422008434931436

Epoch: 5| Step: 1
Training loss: 2.6024956703186035
Validation loss: 2.0559213906526566

Epoch: 5| Step: 2
Training loss: 2.106079339981079
Validation loss: 2.06157049536705

Epoch: 5| Step: 3
Training loss: 2.0192058086395264
Validation loss: 2.0591577937205634

Epoch: 5| Step: 4
Training loss: 2.4821386337280273
Validation loss: 2.050698379675547

Epoch: 5| Step: 5
Training loss: 2.142427444458008
Validation loss: 2.044620469212532

Epoch: 5| Step: 6
Training loss: 1.4905216693878174
Validation loss: 2.0285544147094092

Epoch: 5| Step: 7
Training loss: 2.136848211288452
Validation loss: 2.023289908965429

Epoch: 5| Step: 8
Training loss: 2.0629758834838867
Validation loss: 2.0194493383169174

Epoch: 5| Step: 9
Training loss: 2.3250184059143066
Validation loss: 2.0217853585879006

Epoch: 5| Step: 10
Training loss: 2.6744191646575928
Validation loss: 2.016215736667315

Epoch: 5| Step: 11
Training loss: 0.7402821779251099
Validation loss: 2.0172791332006454

Epoch: 88| Step: 0
Training loss: 2.4622750282287598
Validation loss: 2.0192333261171975

Epoch: 5| Step: 1
Training loss: 2.027860403060913
Validation loss: 2.007936547199885

Epoch: 5| Step: 2
Training loss: 2.240006923675537
Validation loss: 2.013683572411537

Epoch: 5| Step: 3
Training loss: 2.0295064449310303
Validation loss: 2.0127042482296624

Epoch: 5| Step: 4
Training loss: 2.1007704734802246
Validation loss: 2.014691630999247

Epoch: 5| Step: 5
Training loss: 2.4196224212646484
Validation loss: 2.0039116938908896

Epoch: 5| Step: 6
Training loss: 1.9960861206054688
Validation loss: 2.0018863479296365

Epoch: 5| Step: 7
Training loss: 2.4865078926086426
Validation loss: 2.012400065859159

Epoch: 5| Step: 8
Training loss: 1.5707727670669556
Validation loss: 2.005564570426941

Epoch: 5| Step: 9
Training loss: 2.120089054107666
Validation loss: 2.012116248408953

Epoch: 5| Step: 10
Training loss: 2.5101370811462402
Validation loss: 2.0096840262413025

Epoch: 5| Step: 11
Training loss: 1.6728687286376953
Validation loss: 2.0177103032668433

Epoch: 89| Step: 0
Training loss: 1.871848702430725
Validation loss: 2.0101772944132485

Epoch: 5| Step: 1
Training loss: 2.20900297164917
Validation loss: 2.0069501598676047

Epoch: 5| Step: 2
Training loss: 2.2265334129333496
Validation loss: 2.009994645913442

Epoch: 5| Step: 3
Training loss: 1.44759202003479
Validation loss: 2.0036220798889794

Epoch: 5| Step: 4
Training loss: 2.3280367851257324
Validation loss: 2.005759154756864

Epoch: 5| Step: 5
Training loss: 2.202831983566284
Validation loss: 2.0035719672838845

Epoch: 5| Step: 6
Training loss: 2.529398202896118
Validation loss: 2.013862356543541

Epoch: 5| Step: 7
Training loss: 2.086482286453247
Validation loss: 2.0179188350836434

Epoch: 5| Step: 8
Training loss: 2.7833733558654785
Validation loss: 2.0164995590845742

Epoch: 5| Step: 9
Training loss: 2.0160555839538574
Validation loss: 2.0211992263793945

Epoch: 5| Step: 10
Training loss: 2.350210189819336
Validation loss: 2.0121125131845474

Epoch: 5| Step: 11
Training loss: 1.863869309425354
Validation loss: 2.010287806391716

Epoch: 90| Step: 0
Training loss: 2.122377872467041
Validation loss: 2.0066887587308884

Epoch: 5| Step: 1
Training loss: 1.9649524688720703
Validation loss: 2.003548711538315

Epoch: 5| Step: 2
Training loss: 2.6261582374572754
Validation loss: 2.0106585870186486

Epoch: 5| Step: 3
Training loss: 2.569983959197998
Validation loss: 2.0099066495895386

Epoch: 5| Step: 4
Training loss: 2.3252272605895996
Validation loss: 2.0153884838024774

Epoch: 5| Step: 5
Training loss: 2.4506030082702637
Validation loss: 2.014736622571945

Epoch: 5| Step: 6
Training loss: 2.129976511001587
Validation loss: 2.02077587445577

Epoch: 5| Step: 7
Training loss: 2.4029507637023926
Validation loss: 2.0250407258669534

Epoch: 5| Step: 8
Training loss: 1.8367828130722046
Validation loss: 2.017523596684138

Epoch: 5| Step: 9
Training loss: 1.7019398212432861
Validation loss: 2.0210444629192352

Epoch: 5| Step: 10
Training loss: 1.8261877298355103
Validation loss: 2.0175996720790863

Epoch: 5| Step: 11
Training loss: 1.3868294954299927
Validation loss: 2.020590936144193

Epoch: 91| Step: 0
Training loss: 2.2145533561706543
Validation loss: 2.0209594070911407

Epoch: 5| Step: 1
Training loss: 1.9881227016448975
Validation loss: 2.012752299507459

Epoch: 5| Step: 2
Training loss: 2.203791379928589
Validation loss: 2.016073375940323

Epoch: 5| Step: 3
Training loss: 2.3996424674987793
Validation loss: 2.012448787689209

Epoch: 5| Step: 4
Training loss: 2.5360617637634277
Validation loss: 2.020658031105995

Epoch: 5| Step: 5
Training loss: 2.015164852142334
Validation loss: 2.0088091591993966

Epoch: 5| Step: 6
Training loss: 2.029291868209839
Validation loss: 2.0063310116529465

Epoch: 5| Step: 7
Training loss: 2.1070141792297363
Validation loss: 2.016016572713852

Epoch: 5| Step: 8
Training loss: 2.1047568321228027
Validation loss: 2.0115106254816055

Epoch: 5| Step: 9
Training loss: 1.8392139673233032
Validation loss: 2.0168051222960153

Epoch: 5| Step: 10
Training loss: 2.435600757598877
Validation loss: 2.0146212031443915

Epoch: 5| Step: 11
Training loss: 1.8406087160110474
Validation loss: 2.0115344723065696

Epoch: 92| Step: 0
Training loss: 1.952541708946228
Validation loss: 2.023425832390785

Epoch: 5| Step: 1
Training loss: 2.549309253692627
Validation loss: 2.020642335216204

Epoch: 5| Step: 2
Training loss: 2.4592373371124268
Validation loss: 2.0472437093655267

Epoch: 5| Step: 3
Training loss: 1.5972509384155273
Validation loss: 2.0438672254482904

Epoch: 5| Step: 4
Training loss: 2.408677577972412
Validation loss: 2.0422271539767585

Epoch: 5| Step: 5
Training loss: 2.058865547180176
Validation loss: 2.037203128139178

Epoch: 5| Step: 6
Training loss: 2.4259560108184814
Validation loss: 2.023323878645897

Epoch: 5| Step: 7
Training loss: 2.4009315967559814
Validation loss: 2.027179499467214

Epoch: 5| Step: 8
Training loss: 1.9877586364746094
Validation loss: 2.023165136575699

Epoch: 5| Step: 9
Training loss: 2.1254539489746094
Validation loss: 2.0092881520589194

Epoch: 5| Step: 10
Training loss: 2.0491600036621094
Validation loss: 2.013126070300738

Epoch: 5| Step: 11
Training loss: 2.214556932449341
Validation loss: 2.0078485757112503

Epoch: 93| Step: 0
Training loss: 2.155646324157715
Validation loss: 2.0131413588921228

Epoch: 5| Step: 1
Training loss: 1.9743928909301758
Validation loss: 2.0061806639035544

Epoch: 5| Step: 2
Training loss: 2.5753607749938965
Validation loss: 2.0089968045552573

Epoch: 5| Step: 3
Training loss: 2.208630084991455
Validation loss: 2.004361867904663

Epoch: 5| Step: 4
Training loss: 2.392402172088623
Validation loss: 2.014025499423345

Epoch: 5| Step: 5
Training loss: 1.8374799489974976
Validation loss: 2.0148429771264396

Epoch: 5| Step: 6
Training loss: 2.0637996196746826
Validation loss: 2.0108725080887475

Epoch: 5| Step: 7
Training loss: 2.3034160137176514
Validation loss: 2.0091996838649115

Epoch: 5| Step: 8
Training loss: 1.971083641052246
Validation loss: 2.0108132461706796

Epoch: 5| Step: 9
Training loss: 2.4743828773498535
Validation loss: 2.012617682417234

Epoch: 5| Step: 10
Training loss: 1.7924797534942627
Validation loss: 2.0280272563298545

Epoch: 5| Step: 11
Training loss: 2.159426689147949
Validation loss: 2.0256065080563226

Epoch: 94| Step: 0
Training loss: 1.518978238105774
Validation loss: 2.035959670941035

Epoch: 5| Step: 1
Training loss: 2.697686195373535
Validation loss: 2.0487288186947503

Epoch: 5| Step: 2
Training loss: 1.9950969219207764
Validation loss: 2.0471114416917167

Epoch: 5| Step: 3
Training loss: 2.1402676105499268
Validation loss: 2.0464483549197516

Epoch: 5| Step: 4
Training loss: 2.287485122680664
Validation loss: 2.0518423517545066

Epoch: 5| Step: 5
Training loss: 2.4837379455566406
Validation loss: 2.0563022792339325

Epoch: 5| Step: 6
Training loss: 1.697688102722168
Validation loss: 2.0479200035333633

Epoch: 5| Step: 7
Training loss: 2.022948741912842
Validation loss: 2.0555926163991294

Epoch: 5| Step: 8
Training loss: 2.0999369621276855
Validation loss: 2.0522297869126

Epoch: 5| Step: 9
Training loss: 1.9189159870147705
Validation loss: 2.04564039905866

Epoch: 5| Step: 10
Training loss: 3.002916097640991
Validation loss: 2.0356430610020957

Epoch: 5| Step: 11
Training loss: 1.8473849296569824
Validation loss: 2.0210514217615128

Epoch: 95| Step: 0
Training loss: 2.289675235748291
Validation loss: 2.0071045756340027

Epoch: 5| Step: 1
Training loss: 1.6821343898773193
Validation loss: 2.0042205353577933

Epoch: 5| Step: 2
Training loss: 2.168797731399536
Validation loss: 2.0033695499102273

Epoch: 5| Step: 3
Training loss: 2.7457268238067627
Validation loss: 2.0132220685482025

Epoch: 5| Step: 4
Training loss: 2.723433256149292
Validation loss: 2.0166828682025275

Epoch: 5| Step: 5
Training loss: 1.8090970516204834
Validation loss: 2.0182290176550546

Epoch: 5| Step: 6
Training loss: 2.136043071746826
Validation loss: 2.0187405397494635

Epoch: 5| Step: 7
Training loss: 2.4773290157318115
Validation loss: 2.017751688758532

Epoch: 5| Step: 8
Training loss: 2.0437045097351074
Validation loss: 2.013177419702212

Epoch: 5| Step: 9
Training loss: 2.0391781330108643
Validation loss: 2.0126397609710693

Epoch: 5| Step: 10
Training loss: 2.0084891319274902
Validation loss: 2.012309948603312

Epoch: 5| Step: 11
Training loss: 1.6301991939544678
Validation loss: 2.000944529970487

Epoch: 96| Step: 0
Training loss: 2.390843391418457
Validation loss: 2.004706621170044

Epoch: 5| Step: 1
Training loss: 2.5543105602264404
Validation loss: 2.009045119086901

Epoch: 5| Step: 2
Training loss: 1.9539422988891602
Validation loss: 2.009297693769137

Epoch: 5| Step: 3
Training loss: 1.9985790252685547
Validation loss: 2.0102412154277167

Epoch: 5| Step: 4
Training loss: 2.117734909057617
Validation loss: 2.035004034638405

Epoch: 5| Step: 5
Training loss: 2.4208531379699707
Validation loss: 2.018595745166143

Epoch: 5| Step: 6
Training loss: 2.0239033699035645
Validation loss: 2.0354836036761603

Epoch: 5| Step: 7
Training loss: 2.0677499771118164
Validation loss: 2.0349724938472114

Epoch: 5| Step: 8
Training loss: 2.2364730834960938
Validation loss: 2.028568814198176

Epoch: 5| Step: 9
Training loss: 2.1806464195251465
Validation loss: 2.0216894894838333

Epoch: 5| Step: 10
Training loss: 2.2603976726531982
Validation loss: 2.0185449769099555

Epoch: 5| Step: 11
Training loss: 0.43885862827301025
Validation loss: 2.0154152562220893

Epoch: 97| Step: 0
Training loss: 1.7698490619659424
Validation loss: 2.0102301140626273

Epoch: 5| Step: 1
Training loss: 1.8192230463027954
Validation loss: 2.0097648203372955

Epoch: 5| Step: 2
Training loss: 2.222041606903076
Validation loss: 2.0183536211649575

Epoch: 5| Step: 3
Training loss: 1.7552086114883423
Validation loss: 2.0175727009773254

Epoch: 5| Step: 4
Training loss: 2.4581170082092285
Validation loss: 2.0243273874123893

Epoch: 5| Step: 5
Training loss: 2.153550386428833
Validation loss: 2.021314412355423

Epoch: 5| Step: 6
Training loss: 2.467916488647461
Validation loss: 2.022461488842964

Epoch: 5| Step: 7
Training loss: 2.9813599586486816
Validation loss: 2.0162768165270486

Epoch: 5| Step: 8
Training loss: 1.9540259838104248
Validation loss: 2.0106476147969565

Epoch: 5| Step: 9
Training loss: 2.2182154655456543
Validation loss: 2.0108242481946945

Epoch: 5| Step: 10
Training loss: 1.8976682424545288
Validation loss: 2.0160062660773597

Epoch: 5| Step: 11
Training loss: 1.5544085502624512
Validation loss: 2.0052375197410583

Epoch: 98| Step: 0
Training loss: 1.9325363636016846
Validation loss: 2.0064429938793182

Epoch: 5| Step: 1
Training loss: 2.385028600692749
Validation loss: 2.0052588184674582

Epoch: 5| Step: 2
Training loss: 2.1315479278564453
Validation loss: 2.009333610534668

Epoch: 5| Step: 3
Training loss: 2.1604018211364746
Validation loss: 2.010031441847483

Epoch: 5| Step: 4
Training loss: 2.344433307647705
Validation loss: 2.0162349889675775

Epoch: 5| Step: 5
Training loss: 2.129406452178955
Validation loss: 2.028236443797747

Epoch: 5| Step: 6
Training loss: 2.1980998516082764
Validation loss: 2.0356826931238174

Epoch: 5| Step: 7
Training loss: 2.1219189167022705
Validation loss: 2.041565169890722

Epoch: 5| Step: 8
Training loss: 2.0554726123809814
Validation loss: 2.028292700648308

Epoch: 5| Step: 9
Training loss: 2.0588228702545166
Validation loss: 2.0296512891848884

Epoch: 5| Step: 10
Training loss: 2.0086276531219482
Validation loss: 2.023764575521151

Epoch: 5| Step: 11
Training loss: 2.7377963066101074
Validation loss: 2.012751415371895

Epoch: 99| Step: 0
Training loss: 1.9391409158706665
Validation loss: 2.00544943412145

Epoch: 5| Step: 1
Training loss: 2.452023983001709
Validation loss: 1.9951419631640117

Epoch: 5| Step: 2
Training loss: 2.0459280014038086
Validation loss: 2.0020261804262796

Epoch: 5| Step: 3
Training loss: 2.0915918350219727
Validation loss: 1.9974170327186584

Epoch: 5| Step: 4
Training loss: 1.9995019435882568
Validation loss: 1.9984297504027684

Epoch: 5| Step: 5
Training loss: 2.232785224914551
Validation loss: 2.00565937658151

Epoch: 5| Step: 6
Training loss: 2.0870814323425293
Validation loss: 1.9991721957921982

Epoch: 5| Step: 7
Training loss: 2.145352602005005
Validation loss: 2.0022955536842346

Epoch: 5| Step: 8
Training loss: 2.1673800945281982
Validation loss: 2.000029315551122

Epoch: 5| Step: 9
Training loss: 2.7708306312561035
Validation loss: 2.00232957303524

Epoch: 5| Step: 10
Training loss: 1.685670256614685
Validation loss: 2.0012173652648926

Epoch: 5| Step: 11
Training loss: 2.272667646408081
Validation loss: 2.0027203063170114

Epoch: 100| Step: 0
Training loss: 2.2331607341766357
Validation loss: 1.9981931000947952

Epoch: 5| Step: 1
Training loss: 2.648940324783325
Validation loss: 2.003327483932177

Epoch: 5| Step: 2
Training loss: 2.376452684402466
Validation loss: 2.006189579765002

Epoch: 5| Step: 3
Training loss: 2.104001522064209
Validation loss: 2.009235034386317

Epoch: 5| Step: 4
Training loss: 1.5797464847564697
Validation loss: 2.00057490170002

Epoch: 5| Step: 5
Training loss: 2.123617172241211
Validation loss: 2.00828093290329

Epoch: 5| Step: 6
Training loss: 2.1813578605651855
Validation loss: 2.010060335199038

Epoch: 5| Step: 7
Training loss: 2.213866949081421
Validation loss: 2.0114058405160904

Epoch: 5| Step: 8
Training loss: 1.3260443210601807
Validation loss: 2.0167541404565177

Epoch: 5| Step: 9
Training loss: 2.780994415283203
Validation loss: 2.0193776289621987

Epoch: 5| Step: 10
Training loss: 1.9146835803985596
Validation loss: 2.0182785938183465

Epoch: 5| Step: 11
Training loss: 2.1147758960723877
Validation loss: 2.023831660548846

Testing loss: 1.638782724202108
