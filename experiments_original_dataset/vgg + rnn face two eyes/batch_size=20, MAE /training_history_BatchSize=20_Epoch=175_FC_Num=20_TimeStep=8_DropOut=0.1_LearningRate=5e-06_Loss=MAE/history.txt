Epoch: 1| Step: 0
Training loss: 5.6791205406188965
Validation loss: 5.325636665026347

Epoch: 5| Step: 1
Training loss: 5.54771089553833
Validation loss: 5.3241385618845625

Epoch: 5| Step: 2
Training loss: 4.531126499176025
Validation loss: 5.3226171135902405

Epoch: 5| Step: 3
Training loss: 5.769907474517822
Validation loss: 5.321090737978618

Epoch: 5| Step: 4
Training loss: 5.118031024932861
Validation loss: 5.319611211617787

Epoch: 5| Step: 5
Training loss: 5.442488670349121
Validation loss: 5.318105002244313

Epoch: 5| Step: 6
Training loss: 4.935826778411865
Validation loss: 5.316719214121501

Epoch: 5| Step: 7
Training loss: 6.528604030609131
Validation loss: 5.31527594725291

Epoch: 5| Step: 8
Training loss: 5.942111015319824
Validation loss: 5.313833196957906

Epoch: 5| Step: 9
Training loss: 4.776613712310791
Validation loss: 5.312400996685028

Epoch: 5| Step: 10
Training loss: 4.9733405113220215
Validation loss: 5.3109351595242815

Epoch: 5| Step: 11
Training loss: 5.446341514587402
Validation loss: 5.309438864390056

Epoch: 2| Step: 0
Training loss: 5.5006256103515625
Validation loss: 5.3078433473904925

Epoch: 5| Step: 1
Training loss: 5.253454685211182
Validation loss: 5.3063063621521

Epoch: 5| Step: 2
Training loss: 4.933406829833984
Validation loss: 5.3046048283576965

Epoch: 5| Step: 3
Training loss: 5.100783348083496
Validation loss: 5.302769601345062

Epoch: 5| Step: 4
Training loss: 5.934281826019287
Validation loss: 5.300993641217549

Epoch: 5| Step: 5
Training loss: 5.004519462585449
Validation loss: 5.299124161402385

Epoch: 5| Step: 6
Training loss: 4.410943031311035
Validation loss: 5.297200381755829

Epoch: 5| Step: 7
Training loss: 5.4211931228637695
Validation loss: 5.295172254244487

Epoch: 5| Step: 8
Training loss: 5.407008171081543
Validation loss: 5.292993565400441

Epoch: 5| Step: 9
Training loss: 5.806078910827637
Validation loss: 5.290846168994904

Epoch: 5| Step: 10
Training loss: 6.525422096252441
Validation loss: 5.288510084152222

Epoch: 5| Step: 11
Training loss: 4.104727745056152
Validation loss: 5.286064823468526

Epoch: 3| Step: 0
Training loss: 5.1053595542907715
Validation loss: 5.283481379350026

Epoch: 5| Step: 1
Training loss: 5.216891765594482
Validation loss: 5.2808834711710615

Epoch: 5| Step: 2
Training loss: 6.017434120178223
Validation loss: 5.278098563353221

Epoch: 5| Step: 3
Training loss: 4.486778259277344
Validation loss: 5.275313178698222

Epoch: 5| Step: 4
Training loss: 6.9905500411987305
Validation loss: 5.272117932637532

Epoch: 5| Step: 5
Training loss: 5.766646385192871
Validation loss: 5.268871625264485

Epoch: 5| Step: 6
Training loss: 4.992522239685059
Validation loss: 5.265606721242269

Epoch: 5| Step: 7
Training loss: 5.437381744384766
Validation loss: 5.26193900903066

Epoch: 5| Step: 8
Training loss: 4.874222755432129
Validation loss: 5.258126060167949

Epoch: 5| Step: 9
Training loss: 5.157711982727051
Validation loss: 5.254168748855591

Epoch: 5| Step: 10
Training loss: 4.564743995666504
Validation loss: 5.250131726264954

Epoch: 5| Step: 11
Training loss: 5.8006911277771
Validation loss: 5.245698610941569

Epoch: 4| Step: 0
Training loss: 5.358867645263672
Validation loss: 5.240866204102834

Epoch: 5| Step: 1
Training loss: 6.414294242858887
Validation loss: 5.2361887494723005

Epoch: 5| Step: 2
Training loss: 5.14296817779541
Validation loss: 5.231043756008148

Epoch: 5| Step: 3
Training loss: 4.904428958892822
Validation loss: 5.225758492946625

Epoch: 5| Step: 4
Training loss: 5.799695014953613
Validation loss: 5.220255931218465

Epoch: 5| Step: 5
Training loss: 6.006178379058838
Validation loss: 5.214326024055481

Epoch: 5| Step: 6
Training loss: 3.868495225906372
Validation loss: 5.208451151847839

Epoch: 5| Step: 7
Training loss: 4.91147518157959
Validation loss: 5.202104548613231

Epoch: 5| Step: 8
Training loss: 5.812707424163818
Validation loss: 5.1955909331639605

Epoch: 5| Step: 9
Training loss: 4.576432228088379
Validation loss: 5.188866118590037

Epoch: 5| Step: 10
Training loss: 5.829653739929199
Validation loss: 5.1818592349688215

Epoch: 5| Step: 11
Training loss: 2.72666597366333
Validation loss: 5.174625655015309

Epoch: 5| Step: 0
Training loss: 5.819184303283691
Validation loss: 5.167046089967092

Epoch: 5| Step: 1
Training loss: 5.87572717666626
Validation loss: 5.159011324246724

Epoch: 5| Step: 2
Training loss: 4.700150966644287
Validation loss: 5.151463568210602

Epoch: 5| Step: 3
Training loss: 4.651909828186035
Validation loss: 5.1430607835451765

Epoch: 5| Step: 4
Training loss: 6.356931686401367
Validation loss: 5.134919106960297

Epoch: 5| Step: 5
Training loss: 4.8429694175720215
Validation loss: 5.1265774965286255

Epoch: 5| Step: 6
Training loss: 5.894601821899414
Validation loss: 5.117746154467265

Epoch: 5| Step: 7
Training loss: 5.369819641113281
Validation loss: 5.108879864215851

Epoch: 5| Step: 8
Training loss: 4.6979475021362305
Validation loss: 5.099773307641347

Epoch: 5| Step: 9
Training loss: 4.386434555053711
Validation loss: 5.090802371501923

Epoch: 5| Step: 10
Training loss: 4.35768985748291
Validation loss: 5.0813365777333575

Epoch: 5| Step: 11
Training loss: 6.32335090637207
Validation loss: 5.071896990140279

Epoch: 6| Step: 0
Training loss: 4.600566864013672
Validation loss: 5.061952372392018

Epoch: 5| Step: 1
Training loss: 5.535628318786621
Validation loss: 5.052322308222453

Epoch: 5| Step: 2
Training loss: 5.356606960296631
Validation loss: 5.0426506996154785

Epoch: 5| Step: 3
Training loss: 5.355198383331299
Validation loss: 5.032987395922343

Epoch: 5| Step: 4
Training loss: 4.161643028259277
Validation loss: 5.023286124070485

Epoch: 5| Step: 5
Training loss: 5.053557395935059
Validation loss: 5.013542612393697

Epoch: 5| Step: 6
Training loss: 5.039353370666504
Validation loss: 5.003861248493195

Epoch: 5| Step: 7
Training loss: 4.725747585296631
Validation loss: 4.994208633899689

Epoch: 5| Step: 8
Training loss: 4.654444694519043
Validation loss: 4.984519839286804

Epoch: 5| Step: 9
Training loss: 5.703518867492676
Validation loss: 4.974884291489919

Epoch: 5| Step: 10
Training loss: 5.836435794830322
Validation loss: 4.965528239806493

Epoch: 5| Step: 11
Training loss: 5.005023956298828
Validation loss: 4.95596428712209

Epoch: 7| Step: 0
Training loss: 5.599165439605713
Validation loss: 4.94645631313324

Epoch: 5| Step: 1
Training loss: 5.8689866065979
Validation loss: 4.937142690022786

Epoch: 5| Step: 2
Training loss: 4.491784572601318
Validation loss: 4.9279225667317705

Epoch: 5| Step: 3
Training loss: 5.251294136047363
Validation loss: 4.918546597162883

Epoch: 5| Step: 4
Training loss: 5.405695915222168
Validation loss: 4.909151573975881

Epoch: 5| Step: 5
Training loss: 5.193530559539795
Validation loss: 4.900286138057709

Epoch: 5| Step: 6
Training loss: 5.102231502532959
Validation loss: 4.891265193621318

Epoch: 5| Step: 7
Training loss: 4.3805131912231445
Validation loss: 4.882558882236481

Epoch: 5| Step: 8
Training loss: 4.654903888702393
Validation loss: 4.873686412970225

Epoch: 5| Step: 9
Training loss: 5.379408836364746
Validation loss: 4.865087906519572

Epoch: 5| Step: 10
Training loss: 3.6479344367980957
Validation loss: 4.856781840324402

Epoch: 5| Step: 11
Training loss: 4.322199821472168
Validation loss: 4.848035116990407

Epoch: 8| Step: 0
Training loss: 4.610353946685791
Validation loss: 4.839761634667714

Epoch: 5| Step: 1
Training loss: 5.439402103424072
Validation loss: 4.831503550211589

Epoch: 5| Step: 2
Training loss: 5.477468490600586
Validation loss: 4.823895255724589

Epoch: 5| Step: 3
Training loss: 5.536797046661377
Validation loss: 4.815845648447673

Epoch: 5| Step: 4
Training loss: 6.034590721130371
Validation loss: 4.808461308479309

Epoch: 5| Step: 5
Training loss: 3.2054405212402344
Validation loss: 4.800822536150615

Epoch: 5| Step: 6
Training loss: 4.294634819030762
Validation loss: 4.793342928091685

Epoch: 5| Step: 7
Training loss: 5.070424556732178
Validation loss: 4.786136716604233

Epoch: 5| Step: 8
Training loss: 5.194873332977295
Validation loss: 4.778986483812332

Epoch: 5| Step: 9
Training loss: 4.1689348220825195
Validation loss: 4.771573921044667

Epoch: 5| Step: 10
Training loss: 4.418642997741699
Validation loss: 4.7644389271736145

Epoch: 5| Step: 11
Training loss: 6.619892120361328
Validation loss: 4.7571835815906525

Epoch: 9| Step: 0
Training loss: 5.302379608154297
Validation loss: 4.749746700127919

Epoch: 5| Step: 1
Training loss: 4.440245628356934
Validation loss: 4.742839256922404

Epoch: 5| Step: 2
Training loss: 4.740349769592285
Validation loss: 4.736086428165436

Epoch: 5| Step: 3
Training loss: 5.203007698059082
Validation loss: 4.7295936942100525

Epoch: 5| Step: 4
Training loss: 4.898560523986816
Validation loss: 4.722614338000615

Epoch: 5| Step: 5
Training loss: 5.686278343200684
Validation loss: 4.71608837445577

Epoch: 5| Step: 6
Training loss: 4.7085723876953125
Validation loss: 4.709431827068329

Epoch: 5| Step: 7
Training loss: 3.9953453540802
Validation loss: 4.702997446060181

Epoch: 5| Step: 8
Training loss: 4.8430047035217285
Validation loss: 4.697072009245555

Epoch: 5| Step: 9
Training loss: 5.547459602355957
Validation loss: 4.691140055656433

Epoch: 5| Step: 10
Training loss: 3.829366683959961
Validation loss: 4.685506999492645

Epoch: 5| Step: 11
Training loss: 3.3553359508514404
Validation loss: 4.679577589035034

Epoch: 10| Step: 0
Training loss: 5.308160781860352
Validation loss: 4.673916061719258

Epoch: 5| Step: 1
Training loss: 5.575594902038574
Validation loss: 4.6686723828315735

Epoch: 5| Step: 2
Training loss: 4.523484230041504
Validation loss: 4.662899434566498

Epoch: 5| Step: 3
Training loss: 4.845824241638184
Validation loss: 4.65738050142924

Epoch: 5| Step: 4
Training loss: 4.201570987701416
Validation loss: 4.652058899402618

Epoch: 5| Step: 5
Training loss: 4.234791278839111
Validation loss: 4.646669844786326

Epoch: 5| Step: 6
Training loss: 4.057602882385254
Validation loss: 4.64126988252004

Epoch: 5| Step: 7
Training loss: 5.426934242248535
Validation loss: 4.6355271736780805

Epoch: 5| Step: 8
Training loss: 4.973271369934082
Validation loss: 4.630578716595967

Epoch: 5| Step: 9
Training loss: 4.95517110824585
Validation loss: 4.625459392865499

Epoch: 5| Step: 10
Training loss: 4.230223655700684
Validation loss: 4.620231171449025

Epoch: 5| Step: 11
Training loss: 3.943279981613159
Validation loss: 4.614975740512212

Epoch: 11| Step: 0
Training loss: 5.156457424163818
Validation loss: 4.609961171944936

Epoch: 5| Step: 1
Training loss: 4.417015075683594
Validation loss: 4.605066478252411

Epoch: 5| Step: 2
Training loss: 5.481886863708496
Validation loss: 4.6002683142821

Epoch: 5| Step: 3
Training loss: 4.4684553146362305
Validation loss: 4.595069418350856

Epoch: 5| Step: 4
Training loss: 4.132880210876465
Validation loss: 4.589660118023555

Epoch: 5| Step: 5
Training loss: 5.238116264343262
Validation loss: 4.5848361651102705

Epoch: 5| Step: 6
Training loss: 4.688588619232178
Validation loss: 4.579452455043793

Epoch: 5| Step: 7
Training loss: 4.887803554534912
Validation loss: 4.574324131011963

Epoch: 5| Step: 8
Training loss: 4.2701735496521
Validation loss: 4.569271246592204

Epoch: 5| Step: 9
Training loss: 4.427813529968262
Validation loss: 4.564489682515462

Epoch: 5| Step: 10
Training loss: 4.49921178817749
Validation loss: 4.559550106525421

Epoch: 5| Step: 11
Training loss: 4.011203765869141
Validation loss: 4.554614186286926

Epoch: 12| Step: 0
Training loss: 4.483620643615723
Validation loss: 4.549799680709839

Epoch: 5| Step: 1
Training loss: 4.9655046463012695
Validation loss: 4.544541716575623

Epoch: 5| Step: 2
Training loss: 4.854096412658691
Validation loss: 4.539744695027669

Epoch: 5| Step: 3
Training loss: 4.33502721786499
Validation loss: 4.5346799492836

Epoch: 5| Step: 4
Training loss: 3.9163734912872314
Validation loss: 4.529676695664723

Epoch: 5| Step: 5
Training loss: 4.435040473937988
Validation loss: 4.524590611457825

Epoch: 5| Step: 6
Training loss: 4.480470180511475
Validation loss: 4.519925951957703

Epoch: 5| Step: 7
Training loss: 4.5454421043396
Validation loss: 4.514756997426351

Epoch: 5| Step: 8
Training loss: 5.43206787109375
Validation loss: 4.510581195354462

Epoch: 5| Step: 9
Training loss: 4.5158867835998535
Validation loss: 4.505255271991094

Epoch: 5| Step: 10
Training loss: 4.757068157196045
Validation loss: 4.5005589326222735

Epoch: 5| Step: 11
Training loss: 5.5904436111450195
Validation loss: 4.495245595773061

Epoch: 13| Step: 0
Training loss: 4.228123664855957
Validation loss: 4.489571571350098

Epoch: 5| Step: 1
Training loss: 5.11566686630249
Validation loss: 4.483964920043945

Epoch: 5| Step: 2
Training loss: 4.646549224853516
Validation loss: 4.478297611077626

Epoch: 5| Step: 3
Training loss: 4.225489616394043
Validation loss: 4.472050726413727

Epoch: 5| Step: 4
Training loss: 4.686722755432129
Validation loss: 4.465425928433736

Epoch: 5| Step: 5
Training loss: 3.6498641967773438
Validation loss: 4.459280908107758

Epoch: 5| Step: 6
Training loss: 4.595221996307373
Validation loss: 4.452700614929199

Epoch: 5| Step: 7
Training loss: 4.973274230957031
Validation loss: 4.4464361270268755

Epoch: 5| Step: 8
Training loss: 4.575407981872559
Validation loss: 4.440175652503967

Epoch: 5| Step: 9
Training loss: 4.64730167388916
Validation loss: 4.4337758620580034

Epoch: 5| Step: 10
Training loss: 4.586259365081787
Validation loss: 4.427364607652028

Epoch: 5| Step: 11
Training loss: 6.209131240844727
Validation loss: 4.421430339415868

Epoch: 14| Step: 0
Training loss: 4.760566711425781
Validation loss: 4.415726741154988

Epoch: 5| Step: 1
Training loss: 3.713975191116333
Validation loss: 4.409875253836314

Epoch: 5| Step: 2
Training loss: 4.023672103881836
Validation loss: 4.404302954673767

Epoch: 5| Step: 3
Training loss: 5.832038402557373
Validation loss: 4.3983326355616255

Epoch: 5| Step: 4
Training loss: 4.247310161590576
Validation loss: 4.39265854159991

Epoch: 5| Step: 5
Training loss: 4.846154689788818
Validation loss: 4.387381017208099

Epoch: 5| Step: 6
Training loss: 3.471633195877075
Validation loss: 4.381103098392487

Epoch: 5| Step: 7
Training loss: 4.759851455688477
Validation loss: 4.375746299823125

Epoch: 5| Step: 8
Training loss: 4.237637519836426
Validation loss: 4.370112657546997

Epoch: 5| Step: 9
Training loss: 4.307187080383301
Validation loss: 4.364545255899429

Epoch: 5| Step: 10
Training loss: 5.186092376708984
Validation loss: 4.359220703442891

Epoch: 5| Step: 11
Training loss: 5.243379592895508
Validation loss: 4.353721469640732

Epoch: 15| Step: 0
Training loss: 4.435944557189941
Validation loss: 4.348132570584615

Epoch: 5| Step: 1
Training loss: 5.041726112365723
Validation loss: 4.342711369196574

Epoch: 5| Step: 2
Training loss: 3.9966609477996826
Validation loss: 4.337473094463348

Epoch: 5| Step: 3
Training loss: 4.53366756439209
Validation loss: 4.332165698210399

Epoch: 5| Step: 4
Training loss: 5.445070743560791
Validation loss: 4.3263082305590315

Epoch: 5| Step: 5
Training loss: 3.8277268409729004
Validation loss: 4.320727517207463

Epoch: 5| Step: 6
Training loss: 4.897049427032471
Validation loss: 4.315339614947637

Epoch: 5| Step: 7
Training loss: 4.503271579742432
Validation loss: 4.309807290633519

Epoch: 5| Step: 8
Training loss: 3.5443859100341797
Validation loss: 4.30434916416804

Epoch: 5| Step: 9
Training loss: 3.747809886932373
Validation loss: 4.299247692028682

Epoch: 5| Step: 10
Training loss: 4.9982757568359375
Validation loss: 4.293939014275868

Epoch: 5| Step: 11
Training loss: 3.98838210105896
Validation loss: 4.288532972335815

Epoch: 16| Step: 0
Training loss: 4.400716781616211
Validation loss: 4.284023841222127

Epoch: 5| Step: 1
Training loss: 4.841535568237305
Validation loss: 4.278580695390701

Epoch: 5| Step: 2
Training loss: 4.609061241149902
Validation loss: 4.273024678230286

Epoch: 5| Step: 3
Training loss: 3.393170118331909
Validation loss: 4.267325013875961

Epoch: 5| Step: 4
Training loss: 3.724309206008911
Validation loss: 4.262295722961426

Epoch: 5| Step: 5
Training loss: 5.270162582397461
Validation loss: 4.256014138460159

Epoch: 5| Step: 6
Training loss: 4.3335442543029785
Validation loss: 4.250787576039632

Epoch: 5| Step: 7
Training loss: 3.7265427112579346
Validation loss: 4.245193004608154

Epoch: 5| Step: 8
Training loss: 4.26263427734375
Validation loss: 4.239501406749089

Epoch: 5| Step: 9
Training loss: 4.947666645050049
Validation loss: 4.233943283557892

Epoch: 5| Step: 10
Training loss: 4.58270788192749
Validation loss: 4.228307902812958

Epoch: 5| Step: 11
Training loss: 5.030406951904297
Validation loss: 4.2233076095581055

Epoch: 17| Step: 0
Training loss: 3.3177108764648438
Validation loss: 4.2183415194352465

Epoch: 5| Step: 1
Training loss: 4.445645332336426
Validation loss: 4.213082432746887

Epoch: 5| Step: 2
Training loss: 4.3900628089904785
Validation loss: 4.207073599100113

Epoch: 5| Step: 3
Training loss: 3.2797634601593018
Validation loss: 4.20134683450063

Epoch: 5| Step: 4
Training loss: 3.4422545433044434
Validation loss: 4.196455419063568

Epoch: 5| Step: 5
Training loss: 5.312305927276611
Validation loss: 4.192112634579341

Epoch: 5| Step: 6
Training loss: 4.962611198425293
Validation loss: 4.1861227949460345

Epoch: 5| Step: 7
Training loss: 4.779119968414307
Validation loss: 4.180727620919545

Epoch: 5| Step: 8
Training loss: 4.902559280395508
Validation loss: 4.175271153450012

Epoch: 5| Step: 9
Training loss: 3.9824562072753906
Validation loss: 4.170749882857005

Epoch: 5| Step: 10
Training loss: 4.929125785827637
Validation loss: 4.165031651655833

Epoch: 5| Step: 11
Training loss: 3.385301113128662
Validation loss: 4.160004844268163

Epoch: 18| Step: 0
Training loss: 3.881584882736206
Validation loss: 4.153947174549103

Epoch: 5| Step: 1
Training loss: 4.677514553070068
Validation loss: 4.148628930250804

Epoch: 5| Step: 2
Training loss: 4.244095802307129
Validation loss: 4.14344001809756

Epoch: 5| Step: 3
Training loss: 3.8309502601623535
Validation loss: 4.139003624518712

Epoch: 5| Step: 4
Training loss: 4.456446647644043
Validation loss: 4.133893350760142

Epoch: 5| Step: 5
Training loss: 4.145080089569092
Validation loss: 4.128919929265976

Epoch: 5| Step: 6
Training loss: 3.9677913188934326
Validation loss: 4.123837461074193

Epoch: 5| Step: 7
Training loss: 3.4609227180480957
Validation loss: 4.119217147429784

Epoch: 5| Step: 8
Training loss: 4.795892238616943
Validation loss: 4.114580750465393

Epoch: 5| Step: 9
Training loss: 5.1912922859191895
Validation loss: 4.109109282493591

Epoch: 5| Step: 10
Training loss: 4.69605016708374
Validation loss: 4.1041073103745775

Epoch: 5| Step: 11
Training loss: 2.1853201389312744
Validation loss: 4.09953452150027

Epoch: 19| Step: 0
Training loss: 4.725644111633301
Validation loss: 4.094901611407598

Epoch: 5| Step: 1
Training loss: 4.724484920501709
Validation loss: 4.089969078699748

Epoch: 5| Step: 2
Training loss: 3.730328321456909
Validation loss: 4.085311979055405

Epoch: 5| Step: 3
Training loss: 4.108222007751465
Validation loss: 4.080205798149109

Epoch: 5| Step: 4
Training loss: 4.60166072845459
Validation loss: 4.0757180253664655

Epoch: 5| Step: 5
Training loss: 4.366497039794922
Validation loss: 4.070744087298711

Epoch: 5| Step: 6
Training loss: 3.6415886878967285
Validation loss: 4.065616259972255

Epoch: 5| Step: 7
Training loss: 3.405407667160034
Validation loss: 4.061213324467341

Epoch: 5| Step: 8
Training loss: 4.4592742919921875
Validation loss: 4.056727300087611

Epoch: 5| Step: 9
Training loss: 4.574367523193359
Validation loss: 4.052481849988301

Epoch: 5| Step: 10
Training loss: 3.9179012775421143
Validation loss: 4.048021058241527

Epoch: 5| Step: 11
Training loss: 4.615963935852051
Validation loss: 4.043768803278605

Epoch: 20| Step: 0
Training loss: 3.3039371967315674
Validation loss: 4.040204465389252

Epoch: 5| Step: 1
Training loss: 3.4936180114746094
Validation loss: 4.036939243475596

Epoch: 5| Step: 2
Training loss: 3.8230578899383545
Validation loss: 4.033029655615489

Epoch: 5| Step: 3
Training loss: 3.8389039039611816
Validation loss: 4.027331133683522

Epoch: 5| Step: 4
Training loss: 4.2640461921691895
Validation loss: 4.023196438948314

Epoch: 5| Step: 5
Training loss: 4.809630393981934
Validation loss: 4.019221882025401

Epoch: 5| Step: 6
Training loss: 4.89446496963501
Validation loss: 4.015698870023091

Epoch: 5| Step: 7
Training loss: 4.605020046234131
Validation loss: 4.011097391446431

Epoch: 5| Step: 8
Training loss: 4.453361511230469
Validation loss: 4.005905131498973

Epoch: 5| Step: 9
Training loss: 4.6195268630981445
Validation loss: 4.001537511746089

Epoch: 5| Step: 10
Training loss: 4.023667335510254
Validation loss: 3.99749763806661

Epoch: 5| Step: 11
Training loss: 2.4758105278015137
Validation loss: 3.9933866262435913

Epoch: 21| Step: 0
Training loss: 4.0213727951049805
Validation loss: 3.9898988405863443

Epoch: 5| Step: 1
Training loss: 4.658874034881592
Validation loss: 3.985162377357483

Epoch: 5| Step: 2
Training loss: 5.367754936218262
Validation loss: 3.9802723626295724

Epoch: 5| Step: 3
Training loss: 4.340310096740723
Validation loss: 3.9758825600147247

Epoch: 5| Step: 4
Training loss: 3.674283981323242
Validation loss: 3.9739610254764557

Epoch: 5| Step: 5
Training loss: 4.608578681945801
Validation loss: 3.9675652583440146

Epoch: 5| Step: 6
Training loss: 3.621605634689331
Validation loss: 3.963671704133352

Epoch: 5| Step: 7
Training loss: 3.467625856399536
Validation loss: 3.9596309761206308

Epoch: 5| Step: 8
Training loss: 3.351327419281006
Validation loss: 3.955522209405899

Epoch: 5| Step: 9
Training loss: 4.352778911590576
Validation loss: 3.951476583878199

Epoch: 5| Step: 10
Training loss: 3.6923999786376953
Validation loss: 3.9474844535191855

Epoch: 5| Step: 11
Training loss: 4.55808162689209
Validation loss: 3.942948579788208

Epoch: 22| Step: 0
Training loss: 3.3542380332946777
Validation loss: 3.9388158321380615

Epoch: 5| Step: 1
Training loss: 5.101194858551025
Validation loss: 3.934762825568517

Epoch: 5| Step: 2
Training loss: 4.100790977478027
Validation loss: 3.9299091398715973

Epoch: 5| Step: 3
Training loss: 3.495314836502075
Validation loss: 3.9256384670734406

Epoch: 5| Step: 4
Training loss: 3.5965588092803955
Validation loss: 3.921870231628418

Epoch: 5| Step: 5
Training loss: 4.465035438537598
Validation loss: 3.9170880019664764

Epoch: 5| Step: 6
Training loss: 4.371128082275391
Validation loss: 3.913116931915283

Epoch: 5| Step: 7
Training loss: 3.6411292552948
Validation loss: 3.9085830251375833

Epoch: 5| Step: 8
Training loss: 3.6152939796447754
Validation loss: 3.9044214884440103

Epoch: 5| Step: 9
Training loss: 4.818789482116699
Validation loss: 3.9000686407089233

Epoch: 5| Step: 10
Training loss: 4.196178436279297
Validation loss: 3.89626012245814

Epoch: 5| Step: 11
Training loss: 3.9262008666992188
Validation loss: 3.892235110203425

Epoch: 23| Step: 0
Training loss: 3.6108779907226562
Validation loss: 3.8888924717903137

Epoch: 5| Step: 1
Training loss: 4.169069766998291
Validation loss: 3.884500821431478

Epoch: 5| Step: 2
Training loss: 4.284180641174316
Validation loss: 3.8803290824095407

Epoch: 5| Step: 3
Training loss: 3.322938919067383
Validation loss: 3.876213848590851

Epoch: 5| Step: 4
Training loss: 4.6070661544799805
Validation loss: 3.87188712755839

Epoch: 5| Step: 5
Training loss: 4.524133682250977
Validation loss: 3.8681582113107047

Epoch: 5| Step: 6
Training loss: 3.4274401664733887
Validation loss: 3.863754451274872

Epoch: 5| Step: 7
Training loss: 4.127179145812988
Validation loss: 3.8601512710253396

Epoch: 5| Step: 8
Training loss: 3.882779598236084
Validation loss: 3.8560020426909127

Epoch: 5| Step: 9
Training loss: 3.6419169902801514
Validation loss: 3.851708640654882

Epoch: 5| Step: 10
Training loss: 4.509484767913818
Validation loss: 3.8472394744555154

Epoch: 5| Step: 11
Training loss: 4.534536361694336
Validation loss: 3.8435084323088327

Epoch: 24| Step: 0
Training loss: 4.052189350128174
Validation loss: 3.8392825524012246

Epoch: 5| Step: 1
Training loss: 3.653876781463623
Validation loss: 3.8355533679326377

Epoch: 5| Step: 2
Training loss: 4.009547233581543
Validation loss: 3.831610898176829

Epoch: 5| Step: 3
Training loss: 4.588645935058594
Validation loss: 3.8271480003992715

Epoch: 5| Step: 4
Training loss: 3.356597423553467
Validation loss: 3.823130508263906

Epoch: 5| Step: 5
Training loss: 4.212261199951172
Validation loss: 3.818813214699427

Epoch: 5| Step: 6
Training loss: 3.589268922805786
Validation loss: 3.81482595205307

Epoch: 5| Step: 7
Training loss: 4.392869472503662
Validation loss: 3.8106289207935333

Epoch: 5| Step: 8
Training loss: 3.827975034713745
Validation loss: 3.8069398502508798

Epoch: 5| Step: 9
Training loss: 4.260664939880371
Validation loss: 3.8027751048405967

Epoch: 5| Step: 10
Training loss: 3.892726421356201
Validation loss: 3.7987093528111777

Epoch: 5| Step: 11
Training loss: 3.4323854446411133
Validation loss: 3.79489071170489

Epoch: 25| Step: 0
Training loss: 4.1331400871276855
Validation loss: 3.79128568371137

Epoch: 5| Step: 1
Training loss: 3.889880657196045
Validation loss: 3.787061552206675

Epoch: 5| Step: 2
Training loss: 4.122739315032959
Validation loss: 3.7833228011926017

Epoch: 5| Step: 3
Training loss: 4.381014823913574
Validation loss: 3.779519627491633

Epoch: 5| Step: 4
Training loss: 3.2122840881347656
Validation loss: 3.775870551665624

Epoch: 5| Step: 5
Training loss: 3.9967105388641357
Validation loss: 3.772047499815623

Epoch: 5| Step: 6
Training loss: 3.077971935272217
Validation loss: 3.768362124760946

Epoch: 5| Step: 7
Training loss: 4.240181922912598
Validation loss: 3.7639386653900146

Epoch: 5| Step: 8
Training loss: 4.724469184875488
Validation loss: 3.7600083152453103

Epoch: 5| Step: 9
Training loss: 3.7170727252960205
Validation loss: 3.755612591902415

Epoch: 5| Step: 10
Training loss: 3.597193956375122
Validation loss: 3.752156764268875

Epoch: 5| Step: 11
Training loss: 4.610199928283691
Validation loss: 3.7483478585879006

Epoch: 26| Step: 0
Training loss: 3.57934308052063
Validation loss: 3.7444385290145874

Epoch: 5| Step: 1
Training loss: 3.9806435108184814
Validation loss: 3.74052902062734

Epoch: 5| Step: 2
Training loss: 3.7742984294891357
Validation loss: 3.735824724038442

Epoch: 5| Step: 3
Training loss: 4.6208415031433105
Validation loss: 3.731748809417089

Epoch: 5| Step: 4
Training loss: 4.391566753387451
Validation loss: 3.727811813354492

Epoch: 5| Step: 5
Training loss: 3.459285259246826
Validation loss: 3.7241472403208413

Epoch: 5| Step: 6
Training loss: 3.916323184967041
Validation loss: 3.7197494208812714

Epoch: 5| Step: 7
Training loss: 4.143386363983154
Validation loss: 3.7163084149360657

Epoch: 5| Step: 8
Training loss: 3.681278944015503
Validation loss: 3.7123166620731354

Epoch: 5| Step: 9
Training loss: 3.172280788421631
Validation loss: 3.7083841264247894

Epoch: 5| Step: 10
Training loss: 3.764639377593994
Validation loss: 3.704512635866801

Epoch: 5| Step: 11
Training loss: 5.170632362365723
Validation loss: 3.700526624917984

Epoch: 27| Step: 0
Training loss: 3.8639779090881348
Validation loss: 3.696342428525289

Epoch: 5| Step: 1
Training loss: 2.8585822582244873
Validation loss: 3.6925351520379386

Epoch: 5| Step: 2
Training loss: 3.280857801437378
Validation loss: 3.688718557357788

Epoch: 5| Step: 3
Training loss: 3.806089401245117
Validation loss: 3.684739718834559

Epoch: 5| Step: 4
Training loss: 4.5933098793029785
Validation loss: 3.680666079123815

Epoch: 5| Step: 5
Training loss: 4.2481489181518555
Validation loss: 3.6764516035715737

Epoch: 5| Step: 6
Training loss: 3.6068482398986816
Validation loss: 3.672430763641993

Epoch: 5| Step: 7
Training loss: 4.480058670043945
Validation loss: 3.668407529592514

Epoch: 5| Step: 8
Training loss: 4.038623809814453
Validation loss: 3.6646884083747864

Epoch: 5| Step: 9
Training loss: 3.2371859550476074
Validation loss: 3.6604069670041404

Epoch: 5| Step: 10
Training loss: 3.897552967071533
Validation loss: 3.6563642024993896

Epoch: 5| Step: 11
Training loss: 5.38470458984375
Validation loss: 3.652634491523107

Epoch: 28| Step: 0
Training loss: 4.070330619812012
Validation loss: 3.6482991178830466

Epoch: 5| Step: 1
Training loss: 3.20501708984375
Validation loss: 3.644372453292211

Epoch: 5| Step: 2
Training loss: 3.8051884174346924
Validation loss: 3.6398366590340934

Epoch: 5| Step: 3
Training loss: 3.3563008308410645
Validation loss: 3.635853866736094

Epoch: 5| Step: 4
Training loss: 3.0443549156188965
Validation loss: 3.63166672984759

Epoch: 5| Step: 5
Training loss: 4.328418731689453
Validation loss: 3.6284912824630737

Epoch: 5| Step: 6
Training loss: 3.3196091651916504
Validation loss: 3.6238042414188385

Epoch: 5| Step: 7
Training loss: 4.3436174392700195
Validation loss: 3.6195459266503653

Epoch: 5| Step: 8
Training loss: 4.547869682312012
Validation loss: 3.6153056224187217

Epoch: 5| Step: 9
Training loss: 4.150606155395508
Validation loss: 3.611048718293508

Epoch: 5| Step: 10
Training loss: 3.631986141204834
Validation loss: 3.606574237346649

Epoch: 5| Step: 11
Training loss: 3.1335067749023438
Validation loss: 3.6019588907559714

Epoch: 29| Step: 0
Training loss: 4.2472429275512695
Validation loss: 3.5980448126792908

Epoch: 5| Step: 1
Training loss: 4.4250993728637695
Validation loss: 3.594168802102407

Epoch: 5| Step: 2
Training loss: 2.729015827178955
Validation loss: 3.5895935396353402

Epoch: 5| Step: 3
Training loss: 3.8126144409179688
Validation loss: 3.585177252689997

Epoch: 5| Step: 4
Training loss: 3.832529067993164
Validation loss: 3.5808220903078714

Epoch: 5| Step: 5
Training loss: 4.308670520782471
Validation loss: 3.5765888889630637

Epoch: 5| Step: 6
Training loss: 4.189914226531982
Validation loss: 3.5721709529558816

Epoch: 5| Step: 7
Training loss: 3.136202335357666
Validation loss: 3.567800849676132

Epoch: 5| Step: 8
Training loss: 3.0833849906921387
Validation loss: 3.563465048869451

Epoch: 5| Step: 9
Training loss: 3.7870841026306152
Validation loss: 3.55936927596728

Epoch: 5| Step: 10
Training loss: 3.4825732707977295
Validation loss: 3.5548310577869415

Epoch: 5| Step: 11
Training loss: 4.324042797088623
Validation loss: 3.55128076672554

Epoch: 30| Step: 0
Training loss: 3.3415393829345703
Validation loss: 3.5464739004770913

Epoch: 5| Step: 1
Training loss: 3.37397837638855
Validation loss: 3.542717089255651

Epoch: 5| Step: 2
Training loss: 4.025132179260254
Validation loss: 3.538493444522222

Epoch: 5| Step: 3
Training loss: 4.348989963531494
Validation loss: 3.534551372130712

Epoch: 5| Step: 4
Training loss: 2.9000580310821533
Validation loss: 3.530421515305837

Epoch: 5| Step: 5
Training loss: 3.595212459564209
Validation loss: 3.526148170232773

Epoch: 5| Step: 6
Training loss: 3.9255948066711426
Validation loss: 3.521551728248596

Epoch: 5| Step: 7
Training loss: 3.6098198890686035
Validation loss: 3.5173106590906777

Epoch: 5| Step: 8
Training loss: 3.346252918243408
Validation loss: 3.5132973194122314

Epoch: 5| Step: 9
Training loss: 4.501246452331543
Validation loss: 3.5087310870488486

Epoch: 5| Step: 10
Training loss: 3.5952975749969482
Validation loss: 3.504542052745819

Epoch: 5| Step: 11
Training loss: 3.863708972930908
Validation loss: 3.500479429960251

Epoch: 31| Step: 0
Training loss: 3.8425285816192627
Validation loss: 3.496249496936798

Epoch: 5| Step: 1
Training loss: 3.500441312789917
Validation loss: 3.49191477894783

Epoch: 5| Step: 2
Training loss: 3.153404712677002
Validation loss: 3.487524559100469

Epoch: 5| Step: 3
Training loss: 3.4140095710754395
Validation loss: 3.4833967983722687

Epoch: 5| Step: 4
Training loss: 4.322154521942139
Validation loss: 3.4790824353694916

Epoch: 5| Step: 5
Training loss: 2.5327365398406982
Validation loss: 3.4744759698708854

Epoch: 5| Step: 6
Training loss: 4.126418590545654
Validation loss: 3.470117678244909

Epoch: 5| Step: 7
Training loss: 3.70991587638855
Validation loss: 3.4653520584106445

Epoch: 5| Step: 8
Training loss: 3.4313957691192627
Validation loss: 3.461136430501938

Epoch: 5| Step: 9
Training loss: 4.005880355834961
Validation loss: 3.4567249914010367

Epoch: 5| Step: 10
Training loss: 3.7239842414855957
Validation loss: 3.452085723479589

Epoch: 5| Step: 11
Training loss: 5.081241130828857
Validation loss: 3.4473512768745422

Epoch: 32| Step: 0
Training loss: 4.143460273742676
Validation loss: 3.4427864849567413

Epoch: 5| Step: 1
Training loss: 3.718116283416748
Validation loss: 3.438104122877121

Epoch: 5| Step: 2
Training loss: 3.015285015106201
Validation loss: 3.4335476656754813

Epoch: 5| Step: 3
Training loss: 4.096652030944824
Validation loss: 3.4292508562405906

Epoch: 5| Step: 4
Training loss: 2.9521079063415527
Validation loss: 3.424714505672455

Epoch: 5| Step: 5
Training loss: 4.201951026916504
Validation loss: 3.4202586114406586

Epoch: 5| Step: 6
Training loss: 2.6782572269439697
Validation loss: 3.4157189627488456

Epoch: 5| Step: 7
Training loss: 2.9070026874542236
Validation loss: 3.4115234116713204

Epoch: 5| Step: 8
Training loss: 3.800973415374756
Validation loss: 3.40816322962443

Epoch: 5| Step: 9
Training loss: 4.292507171630859
Validation loss: 3.402267018953959

Epoch: 5| Step: 10
Training loss: 3.813788652420044
Validation loss: 3.3978020747502646

Epoch: 5| Step: 11
Training loss: 2.8347978591918945
Validation loss: 3.393787831068039

Epoch: 33| Step: 0
Training loss: 4.2576093673706055
Validation loss: 3.389501392841339

Epoch: 5| Step: 1
Training loss: 2.989285707473755
Validation loss: 3.384930541117986

Epoch: 5| Step: 2
Training loss: 3.6176960468292236
Validation loss: 3.3802586495876312

Epoch: 5| Step: 3
Training loss: 3.5314369201660156
Validation loss: 3.3752224147319794

Epoch: 5| Step: 4
Training loss: 3.500255584716797
Validation loss: 3.3700970808664956

Epoch: 5| Step: 5
Training loss: 3.8221282958984375
Validation loss: 3.3660049935181937

Epoch: 5| Step: 6
Training loss: 2.4551844596862793
Validation loss: 3.361314763625463

Epoch: 5| Step: 7
Training loss: 3.488990306854248
Validation loss: 3.356636414925257

Epoch: 5| Step: 8
Training loss: 4.122519493103027
Validation loss: 3.3526793817679086

Epoch: 5| Step: 9
Training loss: 2.9728493690490723
Validation loss: 3.348305265108744

Epoch: 5| Step: 10
Training loss: 3.631330966949463
Validation loss: 3.344011386235555

Epoch: 5| Step: 11
Training loss: 6.107149124145508
Validation loss: 3.3397600650787354

Epoch: 34| Step: 0
Training loss: 4.002568244934082
Validation loss: 3.335017810265223

Epoch: 5| Step: 1
Training loss: 2.89367413520813
Validation loss: 3.3306554655234017

Epoch: 5| Step: 2
Training loss: 3.0322341918945312
Validation loss: 3.3260060449441275

Epoch: 5| Step: 3
Training loss: 3.086127519607544
Validation loss: 3.3219908277193704

Epoch: 5| Step: 4
Training loss: 3.253751277923584
Validation loss: 3.3175413409868875

Epoch: 5| Step: 5
Training loss: 3.6993236541748047
Validation loss: 3.313328663508097

Epoch: 5| Step: 6
Training loss: 3.9378662109375
Validation loss: 3.3096665839354196

Epoch: 5| Step: 7
Training loss: 3.739598035812378
Validation loss: 3.3053398728370667

Epoch: 5| Step: 8
Training loss: 4.310332775115967
Validation loss: 3.301209568977356

Epoch: 5| Step: 9
Training loss: 2.4516875743865967
Validation loss: 3.296690672636032

Epoch: 5| Step: 10
Training loss: 3.8654427528381348
Validation loss: 3.2925372421741486

Epoch: 5| Step: 11
Training loss: 3.810246467590332
Validation loss: 3.2877011795838675

Epoch: 35| Step: 0
Training loss: 3.1792352199554443
Validation loss: 3.28261790672938

Epoch: 5| Step: 1
Training loss: 3.2486953735351562
Validation loss: 3.278015593687693

Epoch: 5| Step: 2
Training loss: 2.7975525856018066
Validation loss: 3.2735299666722617

Epoch: 5| Step: 3
Training loss: 3.5213425159454346
Validation loss: 3.269320070743561

Epoch: 5| Step: 4
Training loss: 4.482396125793457
Validation loss: 3.2665295700232186

Epoch: 5| Step: 5
Training loss: 2.8318991661071777
Validation loss: 3.258370210727056

Epoch: 5| Step: 6
Training loss: 3.6255271434783936
Validation loss: 3.2548177540302277

Epoch: 5| Step: 7
Training loss: 3.7006564140319824
Validation loss: 3.251037061214447

Epoch: 5| Step: 8
Training loss: 3.751195192337036
Validation loss: 3.2469866573810577

Epoch: 5| Step: 9
Training loss: 3.3119754791259766
Validation loss: 3.2426003019014993

Epoch: 5| Step: 10
Training loss: 3.4930834770202637
Validation loss: 3.2378125389417014

Epoch: 5| Step: 11
Training loss: 2.797299861907959
Validation loss: 3.232992281516393

Epoch: 36| Step: 0
Training loss: 4.4565653800964355
Validation loss: 3.2290070056915283

Epoch: 5| Step: 1
Training loss: 3.71516752243042
Validation loss: 3.224921683470408

Epoch: 5| Step: 2
Training loss: 3.3822624683380127
Validation loss: 3.2209174036979675

Epoch: 5| Step: 3
Training loss: 3.29814076423645
Validation loss: 3.215797563393911

Epoch: 5| Step: 4
Training loss: 2.358590602874756
Validation loss: 3.21163276831309

Epoch: 5| Step: 5
Training loss: 3.5053038597106934
Validation loss: 3.2076088885466256

Epoch: 5| Step: 6
Training loss: 3.071256399154663
Validation loss: 3.203400433063507

Epoch: 5| Step: 7
Training loss: 2.968135356903076
Validation loss: 3.1985749105612435

Epoch: 5| Step: 8
Training loss: 2.457263469696045
Validation loss: 3.1948509911696115

Epoch: 5| Step: 9
Training loss: 4.066738605499268
Validation loss: 3.1909784575303397

Epoch: 5| Step: 10
Training loss: 3.983243227005005
Validation loss: 3.186927239100138

Epoch: 5| Step: 11
Training loss: 3.549544095993042
Validation loss: 3.1828214526176453

Epoch: 37| Step: 0
Training loss: 3.434159755706787
Validation loss: 3.178835153579712

Epoch: 5| Step: 1
Training loss: 1.9205394983291626
Validation loss: 3.1739703516165414

Epoch: 5| Step: 2
Training loss: 3.8644821643829346
Validation loss: 3.1703577041625977

Epoch: 5| Step: 3
Training loss: 3.634403705596924
Validation loss: 3.166562875111898

Epoch: 5| Step: 4
Training loss: 2.801391124725342
Validation loss: 3.1620319386323295

Epoch: 5| Step: 5
Training loss: 3.369377851486206
Validation loss: 3.158348778883616

Epoch: 5| Step: 6
Training loss: 3.367832660675049
Validation loss: 3.1547084947427115

Epoch: 5| Step: 7
Training loss: 3.2089428901672363
Validation loss: 3.150581866502762

Epoch: 5| Step: 8
Training loss: 3.284350633621216
Validation loss: 3.1464968820412955

Epoch: 5| Step: 9
Training loss: 3.3682594299316406
Validation loss: 3.1424784660339355

Epoch: 5| Step: 10
Training loss: 4.41464376449585
Validation loss: 3.13837006688118

Epoch: 5| Step: 11
Training loss: 3.824693202972412
Validation loss: 3.1343405743439994

Epoch: 38| Step: 0
Training loss: 3.1077351570129395
Validation loss: 3.13014417886734

Epoch: 5| Step: 1
Training loss: 4.118001937866211
Validation loss: 3.1258272429307303

Epoch: 5| Step: 2
Training loss: 2.680914878845215
Validation loss: 3.1213940580685935

Epoch: 5| Step: 3
Training loss: 2.8778507709503174
Validation loss: 3.1174693504969277

Epoch: 5| Step: 4
Training loss: 3.3730225563049316
Validation loss: 3.1131706635157266

Epoch: 5| Step: 5
Training loss: 3.633028030395508
Validation loss: 3.1094627479712167

Epoch: 5| Step: 6
Training loss: 2.8252549171447754
Validation loss: 3.105194012324015

Epoch: 5| Step: 7
Training loss: 3.6089844703674316
Validation loss: 3.1009433964888253

Epoch: 5| Step: 8
Training loss: 2.8344295024871826
Validation loss: 3.0968057413895926

Epoch: 5| Step: 9
Training loss: 3.6416141986846924
Validation loss: 3.0929406781991324

Epoch: 5| Step: 10
Training loss: 3.3435051441192627
Validation loss: 3.0890067170063653

Epoch: 5| Step: 11
Training loss: 4.485925674438477
Validation loss: 3.0855544606844583

Epoch: 39| Step: 0
Training loss: 3.026130199432373
Validation loss: 3.081319938103358

Epoch: 5| Step: 1
Training loss: 3.3977952003479004
Validation loss: 3.0787489910920462

Epoch: 5| Step: 2
Training loss: 3.8000099658966064
Validation loss: 3.0750814576943717

Epoch: 5| Step: 3
Training loss: 3.211472988128662
Validation loss: 3.0712167620658875

Epoch: 5| Step: 4
Training loss: 3.426074504852295
Validation loss: 3.0679400165875754

Epoch: 5| Step: 5
Training loss: 2.9053966999053955
Validation loss: 3.063857138156891

Epoch: 5| Step: 6
Training loss: 3.0955193042755127
Validation loss: 3.0597462356090546

Epoch: 5| Step: 7
Training loss: 2.7287402153015137
Validation loss: 3.0565837919712067

Epoch: 5| Step: 8
Training loss: 2.890681743621826
Validation loss: 3.05321196715037

Epoch: 5| Step: 9
Training loss: 4.12122917175293
Validation loss: 3.04958039522171

Epoch: 5| Step: 10
Training loss: 2.8798108100891113
Validation loss: 3.045835127433141

Epoch: 5| Step: 11
Training loss: 4.821178913116455
Validation loss: 3.0423744916915894

Epoch: 40| Step: 0
Training loss: 3.072335720062256
Validation loss: 3.0385651290416718

Epoch: 5| Step: 1
Training loss: 2.813026189804077
Validation loss: 3.0347148875395455

Epoch: 5| Step: 2
Training loss: 3.7695987224578857
Validation loss: 3.031202713648478

Epoch: 5| Step: 3
Training loss: 2.6699130535125732
Validation loss: 3.027789612611135

Epoch: 5| Step: 4
Training loss: 3.731518268585205
Validation loss: 3.0243077476819358

Epoch: 5| Step: 5
Training loss: 2.7649712562561035
Validation loss: 3.0216732720534005

Epoch: 5| Step: 6
Training loss: 3.5079047679901123
Validation loss: 3.0168901483217874

Epoch: 5| Step: 7
Training loss: 3.398707628250122
Validation loss: 3.0139705340067544

Epoch: 5| Step: 8
Training loss: 2.8985531330108643
Validation loss: 3.010614583889643

Epoch: 5| Step: 9
Training loss: 3.464906692504883
Validation loss: 3.00589985648791

Epoch: 5| Step: 10
Training loss: 3.128746271133423
Validation loss: 3.002256671587626

Epoch: 5| Step: 11
Training loss: 3.8223440647125244
Validation loss: 2.997920662164688

Epoch: 41| Step: 0
Training loss: 3.0380778312683105
Validation loss: 2.994106928507487

Epoch: 5| Step: 1
Training loss: 3.4443869590759277
Validation loss: 2.991109699010849

Epoch: 5| Step: 2
Training loss: 2.826873302459717
Validation loss: 2.9883444011211395

Epoch: 5| Step: 3
Training loss: 2.787461042404175
Validation loss: 2.9838404854138694

Epoch: 5| Step: 4
Training loss: 3.1281332969665527
Validation loss: 2.98168017466863

Epoch: 5| Step: 5
Training loss: 2.885659694671631
Validation loss: 2.9764522910118103

Epoch: 5| Step: 6
Training loss: 3.4970405101776123
Validation loss: 2.9730872213840485

Epoch: 5| Step: 7
Training loss: 3.1572182178497314
Validation loss: 2.969121734301249

Epoch: 5| Step: 8
Training loss: 3.121634006500244
Validation loss: 2.965884586175283

Epoch: 5| Step: 9
Training loss: 3.6275665760040283
Validation loss: 2.9630225797494254

Epoch: 5| Step: 10
Training loss: 3.449021577835083
Validation loss: 2.959580034017563

Epoch: 5| Step: 11
Training loss: 2.8739078044891357
Validation loss: 2.9556795756022134

Epoch: 42| Step: 0
Training loss: 3.3493103981018066
Validation loss: 2.951915512482325

Epoch: 5| Step: 1
Training loss: 2.9969515800476074
Validation loss: 2.948045641183853

Epoch: 5| Step: 2
Training loss: 2.8388888835906982
Validation loss: 2.9440316259860992

Epoch: 5| Step: 3
Training loss: 3.2471439838409424
Validation loss: 2.9409207701683044

Epoch: 5| Step: 4
Training loss: 3.491591215133667
Validation loss: 2.936224639415741

Epoch: 5| Step: 5
Training loss: 3.4251739978790283
Validation loss: 2.932872196038564

Epoch: 5| Step: 6
Training loss: 2.4709229469299316
Validation loss: 2.9290632605552673

Epoch: 5| Step: 7
Training loss: 3.111321210861206
Validation loss: 2.9247571329275766

Epoch: 5| Step: 8
Training loss: 3.396303176879883
Validation loss: 2.921561191479365

Epoch: 5| Step: 9
Training loss: 2.628627300262451
Validation loss: 2.9174675345420837

Epoch: 5| Step: 10
Training loss: 3.4775683879852295
Validation loss: 2.9144146740436554

Epoch: 5| Step: 11
Training loss: 3.512363910675049
Validation loss: 2.911336729923884

Epoch: 43| Step: 0
Training loss: 3.025479793548584
Validation loss: 2.9080945551395416

Epoch: 5| Step: 1
Training loss: 3.5997321605682373
Validation loss: 2.9044933915138245

Epoch: 5| Step: 2
Training loss: 3.019583225250244
Validation loss: 2.901785353819529

Epoch: 5| Step: 3
Training loss: 3.465785264968872
Validation loss: 2.8975213170051575

Epoch: 5| Step: 4
Training loss: 3.1312196254730225
Validation loss: 2.8946122328440347

Epoch: 5| Step: 5
Training loss: 2.7683675289154053
Validation loss: 2.8916655083497367

Epoch: 5| Step: 6
Training loss: 3.1719813346862793
Validation loss: 2.901027907927831

Epoch: 5| Step: 7
Training loss: 3.079723596572876
Validation loss: 2.8851886987686157

Epoch: 5| Step: 8
Training loss: 2.3274214267730713
Validation loss: 2.8806477387746177

Epoch: 5| Step: 9
Training loss: 3.286538600921631
Validation loss: 2.877880950768789

Epoch: 5| Step: 10
Training loss: 2.9156994819641113
Validation loss: 2.8747395277023315

Epoch: 5| Step: 11
Training loss: 4.652307510375977
Validation loss: 2.8723055919011435

Epoch: 44| Step: 0
Training loss: 3.273611545562744
Validation loss: 2.8687008718649545

Epoch: 5| Step: 1
Training loss: 3.66404390335083
Validation loss: 2.866088628768921

Epoch: 5| Step: 2
Training loss: 2.960467576980591
Validation loss: 2.862234632174174

Epoch: 5| Step: 3
Training loss: 2.7081289291381836
Validation loss: 2.8586099247137704

Epoch: 5| Step: 4
Training loss: 2.864987850189209
Validation loss: 2.855245808760325

Epoch: 5| Step: 5
Training loss: 3.3110854625701904
Validation loss: 2.8518850803375244

Epoch: 5| Step: 6
Training loss: 2.4943387508392334
Validation loss: 2.8485108415285745

Epoch: 5| Step: 7
Training loss: 2.932551383972168
Validation loss: 2.845141847928365

Epoch: 5| Step: 8
Training loss: 3.543410062789917
Validation loss: 2.842178682486216

Epoch: 5| Step: 9
Training loss: 3.3797459602355957
Validation loss: 2.839638590812683

Epoch: 5| Step: 10
Training loss: 2.472749710083008
Validation loss: 2.8355362017949424

Epoch: 5| Step: 11
Training loss: 3.5390913486480713
Validation loss: 2.8360946774482727

Epoch: 45| Step: 0
Training loss: 2.4530766010284424
Validation loss: 2.8417316476504006

Epoch: 5| Step: 1
Training loss: 2.856675386428833
Validation loss: 2.834188679854075

Epoch: 5| Step: 2
Training loss: 3.353957414627075
Validation loss: 2.8264352778593698

Epoch: 5| Step: 3
Training loss: 2.797232151031494
Validation loss: 2.820639411608378

Epoch: 5| Step: 4
Training loss: 2.946446418762207
Validation loss: 2.818080504735311

Epoch: 5| Step: 5
Training loss: 3.5203113555908203
Validation loss: 2.8162865142027536

Epoch: 5| Step: 6
Training loss: 3.0515780448913574
Validation loss: 2.8145942091941833

Epoch: 5| Step: 7
Training loss: 3.115334987640381
Validation loss: 2.8125580549240112

Epoch: 5| Step: 8
Training loss: 3.580653667449951
Validation loss: 2.808436026175817

Epoch: 5| Step: 9
Training loss: 2.8549113273620605
Validation loss: 2.8049043118953705

Epoch: 5| Step: 10
Training loss: 2.824955940246582
Validation loss: 2.801343689362208

Epoch: 5| Step: 11
Training loss: 2.9094350337982178
Validation loss: 2.798103153705597

Epoch: 46| Step: 0
Training loss: 2.014976978302002
Validation loss: 2.7945318718751273

Epoch: 5| Step: 1
Training loss: 2.6017441749572754
Validation loss: 2.7921108106772103

Epoch: 5| Step: 2
Training loss: 3.058621644973755
Validation loss: 2.7893584271272025

Epoch: 5| Step: 3
Training loss: 3.226224899291992
Validation loss: 2.7885843912760415

Epoch: 5| Step: 4
Training loss: 2.9333369731903076
Validation loss: 2.783946047226588

Epoch: 5| Step: 5
Training loss: 3.75445818901062
Validation loss: 2.7806871136029563

Epoch: 5| Step: 6
Training loss: 3.6404316425323486
Validation loss: 2.778939167658488

Epoch: 5| Step: 7
Training loss: 3.7429680824279785
Validation loss: 2.7796405951182046

Epoch: 5| Step: 8
Training loss: 3.0676050186157227
Validation loss: 2.772730201482773

Epoch: 5| Step: 9
Training loss: 2.4867849349975586
Validation loss: 2.770170340935389

Epoch: 5| Step: 10
Training loss: 2.413355588912964
Validation loss: 2.765812337398529

Epoch: 5| Step: 11
Training loss: 2.8157548904418945
Validation loss: 2.764186610778173

Epoch: 47| Step: 0
Training loss: 3.1916866302490234
Validation loss: 2.760608901580175

Epoch: 5| Step: 1
Training loss: 2.666734457015991
Validation loss: 2.7577000558376312

Epoch: 5| Step: 2
Training loss: 2.7020211219787598
Validation loss: 2.753212665518125

Epoch: 5| Step: 3
Training loss: 3.5189239978790283
Validation loss: 2.7519082029660544

Epoch: 5| Step: 4
Training loss: 2.9474475383758545
Validation loss: 2.7477183043956757

Epoch: 5| Step: 5
Training loss: 3.7351040840148926
Validation loss: 2.7450136045614877

Epoch: 5| Step: 6
Training loss: 2.7736716270446777
Validation loss: 2.7433567941188812

Epoch: 5| Step: 7
Training loss: 2.815368175506592
Validation loss: 2.739613095919291

Epoch: 5| Step: 8
Training loss: 2.9331703186035156
Validation loss: 2.7351448933283486

Epoch: 5| Step: 9
Training loss: 2.576319932937622
Validation loss: 2.7324674824873605

Epoch: 5| Step: 10
Training loss: 2.680716037750244
Validation loss: 2.730383058389028

Epoch: 5| Step: 11
Training loss: 2.7910375595092773
Validation loss: 2.728795419136683

Epoch: 48| Step: 0
Training loss: 2.868454933166504
Validation loss: 2.7378859718640647

Epoch: 5| Step: 1
Training loss: 2.6722874641418457
Validation loss: 2.762069816390673

Epoch: 5| Step: 2
Training loss: 3.127910614013672
Validation loss: 2.7691972156365714

Epoch: 5| Step: 3
Training loss: 2.734807252883911
Validation loss: 2.744681944449743

Epoch: 5| Step: 4
Training loss: 2.528576612472534
Validation loss: 2.7215556601683297

Epoch: 5| Step: 5
Training loss: 3.014125108718872
Validation loss: 2.7123181025187173

Epoch: 5| Step: 6
Training loss: 2.8927836418151855
Validation loss: 2.711817572514216

Epoch: 5| Step: 7
Training loss: 2.4404139518737793
Validation loss: 2.727403144041697

Epoch: 5| Step: 8
Training loss: 3.0410897731781006
Validation loss: 2.7449088295300803

Epoch: 5| Step: 9
Training loss: 3.519627094268799
Validation loss: 2.7662419279416404

Epoch: 5| Step: 10
Training loss: 3.597376585006714
Validation loss: 2.7345436016718545

Epoch: 5| Step: 11
Training loss: 2.5430490970611572
Validation loss: 2.707021395365397

Epoch: 49| Step: 0
Training loss: 2.688141345977783
Validation loss: 2.6979715724786124

Epoch: 5| Step: 1
Training loss: 2.9312949180603027
Validation loss: 2.695632974306742

Epoch: 5| Step: 2
Training loss: 2.868320941925049
Validation loss: 2.6959356566270194

Epoch: 5| Step: 3
Training loss: 3.307525634765625
Validation loss: 2.695895105600357

Epoch: 5| Step: 4
Training loss: 2.7645773887634277
Validation loss: 2.687548885742823

Epoch: 5| Step: 5
Training loss: 3.5245399475097656
Validation loss: 2.6801112989584603

Epoch: 5| Step: 6
Training loss: 2.820671796798706
Validation loss: 2.677619367837906

Epoch: 5| Step: 7
Training loss: 2.9664642810821533
Validation loss: 2.677866945664088

Epoch: 5| Step: 8
Training loss: 2.2165656089782715
Validation loss: 2.675807317097982

Epoch: 5| Step: 9
Training loss: 3.012758493423462
Validation loss: 2.668459335962931

Epoch: 5| Step: 10
Training loss: 2.953482151031494
Validation loss: 2.6683788200219474

Epoch: 5| Step: 11
Training loss: 1.6077187061309814
Validation loss: 2.665366510550181

Epoch: 50| Step: 0
Training loss: 2.5277342796325684
Validation loss: 2.6651179591814675

Epoch: 5| Step: 1
Training loss: 2.7284536361694336
Validation loss: 2.6574903229872384

Epoch: 5| Step: 2
Training loss: 2.9792983531951904
Validation loss: 2.6598737885554633

Epoch: 5| Step: 3
Training loss: 3.157956600189209
Validation loss: 2.652640034755071

Epoch: 5| Step: 4
Training loss: 2.1270663738250732
Validation loss: 2.6530978083610535

Epoch: 5| Step: 5
Training loss: 3.0500576496124268
Validation loss: 2.658986826737722

Epoch: 5| Step: 6
Training loss: 2.7860889434814453
Validation loss: 2.647666503985723

Epoch: 5| Step: 7
Training loss: 3.183177947998047
Validation loss: 2.6430291732152305

Epoch: 5| Step: 8
Training loss: 2.8494250774383545
Validation loss: 2.639550656080246

Epoch: 5| Step: 9
Training loss: 2.9340479373931885
Validation loss: 2.635540952285131

Epoch: 5| Step: 10
Training loss: 3.2321197986602783
Validation loss: 2.6341597537199655

Epoch: 5| Step: 11
Training loss: 1.8998768329620361
Validation loss: 2.630305230617523

Epoch: 51| Step: 0
Training loss: 2.586287260055542
Validation loss: 2.629327028989792

Epoch: 5| Step: 1
Training loss: 2.470766544342041
Validation loss: 2.627120832602183

Epoch: 5| Step: 2
Training loss: 3.0580477714538574
Validation loss: 2.624330719312032

Epoch: 5| Step: 3
Training loss: 3.396865129470825
Validation loss: 2.6209789713223777

Epoch: 5| Step: 4
Training loss: 3.1323254108428955
Validation loss: 2.617585097750028

Epoch: 5| Step: 5
Training loss: 2.6361708641052246
Validation loss: 2.612614611784617

Epoch: 5| Step: 6
Training loss: 2.7081336975097656
Validation loss: 2.608832677205404

Epoch: 5| Step: 7
Training loss: 2.3946473598480225
Validation loss: 2.6056631902853646

Epoch: 5| Step: 8
Training loss: 2.5796570777893066
Validation loss: 2.606217473745346

Epoch: 5| Step: 9
Training loss: 3.4755241870880127
Validation loss: 2.6054874459902444

Epoch: 5| Step: 10
Training loss: 2.6312413215637207
Validation loss: 2.5984917680422464

Epoch: 5| Step: 11
Training loss: 2.335651397705078
Validation loss: 2.5935652355353036

Epoch: 52| Step: 0
Training loss: 2.5102784633636475
Validation loss: 2.5962556501229606

Epoch: 5| Step: 1
Training loss: 3.1254777908325195
Validation loss: 2.599469244480133

Epoch: 5| Step: 2
Training loss: 2.8425450325012207
Validation loss: 2.591178297996521

Epoch: 5| Step: 3
Training loss: 2.7509124279022217
Validation loss: 2.58765638868014

Epoch: 5| Step: 4
Training loss: 2.4765143394470215
Validation loss: 2.583293596903483

Epoch: 5| Step: 5
Training loss: 2.7693631649017334
Validation loss: 2.576251576344172

Epoch: 5| Step: 6
Training loss: 2.9340202808380127
Validation loss: 2.5738967210054398

Epoch: 5| Step: 7
Training loss: 2.8591742515563965
Validation loss: 2.5722256203492484

Epoch: 5| Step: 8
Training loss: 2.757704973220825
Validation loss: 2.570612837870916

Epoch: 5| Step: 9
Training loss: 3.168991804122925
Validation loss: 2.569141079982122

Epoch: 5| Step: 10
Training loss: 2.4342474937438965
Validation loss: 2.568225930134455

Epoch: 5| Step: 11
Training loss: 2.9988231658935547
Validation loss: 2.5651189734538398

Epoch: 53| Step: 0
Training loss: 2.2605972290039062
Validation loss: 2.5638634165128074

Epoch: 5| Step: 1
Training loss: 3.1589126586914062
Validation loss: 2.5588466227054596

Epoch: 5| Step: 2
Training loss: 1.9843158721923828
Validation loss: 2.5574795305728912

Epoch: 5| Step: 3
Training loss: 2.794924259185791
Validation loss: 2.5537469188372293

Epoch: 5| Step: 4
Training loss: 3.142057180404663
Validation loss: 2.5508088568846383

Epoch: 5| Step: 5
Training loss: 2.4513328075408936
Validation loss: 2.551991820335388

Epoch: 5| Step: 6
Training loss: 3.12451171875
Validation loss: 2.5464037160078683

Epoch: 5| Step: 7
Training loss: 2.8848888874053955
Validation loss: 2.5471365451812744

Epoch: 5| Step: 8
Training loss: 2.0520858764648438
Validation loss: 2.547779013713201

Epoch: 5| Step: 9
Training loss: 3.3345532417297363
Validation loss: 2.5519615610440574

Epoch: 5| Step: 10
Training loss: 3.0699031352996826
Validation loss: 2.544859081506729

Epoch: 5| Step: 11
Training loss: 2.651172399520874
Validation loss: 2.5426956613858542

Epoch: 54| Step: 0
Training loss: 2.319148540496826
Validation loss: 2.5421507904926934

Epoch: 5| Step: 1
Training loss: 2.727461576461792
Validation loss: 2.5308043559392295

Epoch: 5| Step: 2
Training loss: 2.444471597671509
Validation loss: 2.526702960332235

Epoch: 5| Step: 3
Training loss: 2.985586404800415
Validation loss: 2.525816152493159

Epoch: 5| Step: 4
Training loss: 2.8142991065979004
Validation loss: 2.523578161994616

Epoch: 5| Step: 5
Training loss: 2.871704578399658
Validation loss: 2.5204326609770455

Epoch: 5| Step: 6
Training loss: 2.97337007522583
Validation loss: 2.5197311292092004

Epoch: 5| Step: 7
Training loss: 2.3678927421569824
Validation loss: 2.518934885660807

Epoch: 5| Step: 8
Training loss: 2.5507149696350098
Validation loss: 2.514538178841273

Epoch: 5| Step: 9
Training loss: 3.0642147064208984
Validation loss: 2.5143355429172516

Epoch: 5| Step: 10
Training loss: 3.0066304206848145
Validation loss: 2.511392722527186

Epoch: 5| Step: 11
Training loss: 1.6708518266677856
Validation loss: 2.507729093233744

Epoch: 55| Step: 0
Training loss: 2.1775271892547607
Validation loss: 2.506176312764486

Epoch: 5| Step: 1
Training loss: 2.7363433837890625
Validation loss: 2.500124136606852

Epoch: 5| Step: 2
Training loss: 2.4311683177948
Validation loss: 2.4984012097120285

Epoch: 5| Step: 3
Training loss: 2.618213653564453
Validation loss: 2.495304971933365

Epoch: 5| Step: 4
Training loss: 2.6725268363952637
Validation loss: 2.4900340338548026

Epoch: 5| Step: 5
Training loss: 2.3785347938537598
Validation loss: 2.4906102120876312

Epoch: 5| Step: 6
Training loss: 3.412184953689575
Validation loss: 2.4910381933053336

Epoch: 5| Step: 7
Training loss: 3.0404276847839355
Validation loss: 2.485920548439026

Epoch: 5| Step: 8
Training loss: 2.940587282180786
Validation loss: 2.4849480986595154

Epoch: 5| Step: 9
Training loss: 2.375204086303711
Validation loss: 2.480480263630549

Epoch: 5| Step: 10
Training loss: 2.7716915607452393
Validation loss: 2.481910223762194

Epoch: 5| Step: 11
Training loss: 2.3524091243743896
Validation loss: 2.4833698173364005

Epoch: 56| Step: 0
Training loss: 2.662788152694702
Validation loss: 2.483669102191925

Epoch: 5| Step: 1
Training loss: 2.865201473236084
Validation loss: 2.4764238198598227

Epoch: 5| Step: 2
Training loss: 2.7509944438934326
Validation loss: 2.465682024757067

Epoch: 5| Step: 3
Training loss: 2.895230531692505
Validation loss: 2.4642734279235206

Epoch: 5| Step: 4
Training loss: 2.6613287925720215
Validation loss: 2.464250927170118

Epoch: 5| Step: 5
Training loss: 3.1013176441192627
Validation loss: 2.4611540337403617

Epoch: 5| Step: 6
Training loss: 2.174008369445801
Validation loss: 2.458156108856201

Epoch: 5| Step: 7
Training loss: 2.4379611015319824
Validation loss: 2.4581815203030906

Epoch: 5| Step: 8
Training loss: 2.457075595855713
Validation loss: 2.4550265272458396

Epoch: 5| Step: 9
Training loss: 2.8095297813415527
Validation loss: 2.4542515774567923

Epoch: 5| Step: 10
Training loss: 2.1588847637176514
Validation loss: 2.45147505402565

Epoch: 5| Step: 11
Training loss: 3.657721996307373
Validation loss: 2.449646145105362

Epoch: 57| Step: 0
Training loss: 2.370400905609131
Validation loss: 2.4487518270810447

Epoch: 5| Step: 1
Training loss: 2.639084577560425
Validation loss: 2.442536413669586

Epoch: 5| Step: 2
Training loss: 2.908113956451416
Validation loss: 2.440649221340815

Epoch: 5| Step: 3
Training loss: 2.734039545059204
Validation loss: 2.4386741320292153

Epoch: 5| Step: 4
Training loss: 2.535097360610962
Validation loss: 2.4347079197565713

Epoch: 5| Step: 5
Training loss: 2.604170322418213
Validation loss: 2.4325272142887115

Epoch: 5| Step: 6
Training loss: 2.60383677482605
Validation loss: 2.429873824119568

Epoch: 5| Step: 7
Training loss: 2.1933114528656006
Validation loss: 2.431080291668574

Epoch: 5| Step: 8
Training loss: 2.8339130878448486
Validation loss: 2.4257329255342484

Epoch: 5| Step: 9
Training loss: 2.855863332748413
Validation loss: 2.4278451999028525

Epoch: 5| Step: 10
Training loss: 2.6184070110321045
Validation loss: 2.4229835172494254

Epoch: 5| Step: 11
Training loss: 2.1725082397460938
Validation loss: 2.4184756875038147

Epoch: 58| Step: 0
Training loss: 2.8749659061431885
Validation loss: 2.412095790108045

Epoch: 5| Step: 1
Training loss: 3.4210243225097656
Validation loss: 2.411258041858673

Epoch: 5| Step: 2
Training loss: 2.8893280029296875
Validation loss: 2.4097225964069366

Epoch: 5| Step: 3
Training loss: 2.2493679523468018
Validation loss: 2.4060894350210824

Epoch: 5| Step: 4
Training loss: 1.9538297653198242
Validation loss: 2.4058051953713098

Epoch: 5| Step: 5
Training loss: 1.8651330471038818
Validation loss: 2.4016061822573342

Epoch: 5| Step: 6
Training loss: 2.5057144165039062
Validation loss: 2.400617867708206

Epoch: 5| Step: 7
Training loss: 2.774545192718506
Validation loss: 2.3965400755405426

Epoch: 5| Step: 8
Training loss: 2.2769100666046143
Validation loss: 2.3957776923974357

Epoch: 5| Step: 9
Training loss: 2.6738243103027344
Validation loss: 2.393849710623423

Epoch: 5| Step: 10
Training loss: 2.8491058349609375
Validation loss: 2.3887933492660522

Epoch: 5| Step: 11
Training loss: 2.67276668548584
Validation loss: 2.3877228001753488

Epoch: 59| Step: 0
Training loss: 2.4825057983398438
Validation loss: 2.3883754213651023

Epoch: 5| Step: 1
Training loss: 2.1852738857269287
Validation loss: 2.3839721580346427

Epoch: 5| Step: 2
Training loss: 2.4078965187072754
Validation loss: 2.3793077170848846

Epoch: 5| Step: 3
Training loss: 2.8488075733184814
Validation loss: 2.380394200483958

Epoch: 5| Step: 4
Training loss: 2.2023181915283203
Validation loss: 2.3778637101252875

Epoch: 5| Step: 5
Training loss: 2.4305357933044434
Validation loss: 2.3745597700277963

Epoch: 5| Step: 6
Training loss: 2.7078564167022705
Validation loss: 2.371261785427729

Epoch: 5| Step: 7
Training loss: 2.6768500804901123
Validation loss: 2.371371110280355

Epoch: 5| Step: 8
Training loss: 2.9146883487701416
Validation loss: 2.3641154964764914

Epoch: 5| Step: 9
Training loss: 2.5871434211730957
Validation loss: 2.3653886119524636

Epoch: 5| Step: 10
Training loss: 2.475856304168701
Validation loss: 2.3619655768076577

Epoch: 5| Step: 11
Training loss: 2.701876163482666
Validation loss: 2.3630201518535614

Epoch: 60| Step: 0
Training loss: 1.7232290506362915
Validation loss: 2.3695384363333383

Epoch: 5| Step: 1
Training loss: 2.585808277130127
Validation loss: 2.373409410317739

Epoch: 5| Step: 2
Training loss: 3.238870143890381
Validation loss: 2.3616716315348945

Epoch: 5| Step: 3
Training loss: 2.5493416786193848
Validation loss: 2.3484149177869162

Epoch: 5| Step: 4
Training loss: 2.5207743644714355
Validation loss: 2.3460809091726937

Epoch: 5| Step: 5
Training loss: 2.3850576877593994
Validation loss: 2.345536212126414

Epoch: 5| Step: 6
Training loss: 1.8558088541030884
Validation loss: 2.340391824642817

Epoch: 5| Step: 7
Training loss: 2.810579299926758
Validation loss: 2.3454857220252356

Epoch: 5| Step: 8
Training loss: 2.6823935508728027
Validation loss: 2.3408515950043998

Epoch: 5| Step: 9
Training loss: 2.563809871673584
Validation loss: 2.3349622885386148

Epoch: 5| Step: 10
Training loss: 2.737968921661377
Validation loss: 2.332579880952835

Epoch: 5| Step: 11
Training loss: 2.4322288036346436
Validation loss: 2.3311826388041177

Epoch: 61| Step: 0
Training loss: 2.7429325580596924
Validation loss: 2.3304744263490043

Epoch: 5| Step: 1
Training loss: 3.0516164302825928
Validation loss: 2.3218715488910675

Epoch: 5| Step: 2
Training loss: 2.0472846031188965
Validation loss: 2.3246844112873077

Epoch: 5| Step: 3
Training loss: 2.233635425567627
Validation loss: 2.328033631046613

Epoch: 5| Step: 4
Training loss: 2.62176251411438
Validation loss: 2.327486495176951

Epoch: 5| Step: 5
Training loss: 2.432549238204956
Validation loss: 2.3225209712982178

Epoch: 5| Step: 6
Training loss: 2.353287696838379
Validation loss: 2.317994331320127

Epoch: 5| Step: 7
Training loss: 2.7416977882385254
Validation loss: 2.3144681255022683

Epoch: 5| Step: 8
Training loss: 2.5621676445007324
Validation loss: 2.3094461460908255

Epoch: 5| Step: 9
Training loss: 2.819706439971924
Validation loss: 2.308108905951182

Epoch: 5| Step: 10
Training loss: 1.83327317237854
Validation loss: 2.308375666538874

Epoch: 5| Step: 11
Training loss: 1.8805235624313354
Validation loss: 2.31311505039533

Epoch: 62| Step: 0
Training loss: 2.5579257011413574
Validation loss: 2.3145917852719626

Epoch: 5| Step: 1
Training loss: 2.869198799133301
Validation loss: 2.3140632112820945

Epoch: 5| Step: 2
Training loss: 2.8365654945373535
Validation loss: 2.3171072900295258

Epoch: 5| Step: 3
Training loss: 2.260779619216919
Validation loss: 2.3069615413745246

Epoch: 5| Step: 4
Training loss: 2.304321050643921
Validation loss: 2.3080706099669137

Epoch: 5| Step: 5
Training loss: 2.2087011337280273
Validation loss: 2.2969959576924643

Epoch: 5| Step: 6
Training loss: 2.2384591102600098
Validation loss: 2.2934480408827462

Epoch: 5| Step: 7
Training loss: 2.194551944732666
Validation loss: 2.290401056408882

Epoch: 5| Step: 8
Training loss: 2.723517417907715
Validation loss: 2.2888276875019073

Epoch: 5| Step: 9
Training loss: 2.2251973152160645
Validation loss: 2.2856040398279824

Epoch: 5| Step: 10
Training loss: 2.6139004230499268
Validation loss: 2.2792895237604776

Epoch: 5| Step: 11
Training loss: 2.3025336265563965
Validation loss: 2.2754519283771515

Epoch: 63| Step: 0
Training loss: 2.0479235649108887
Validation loss: 2.280103032787641

Epoch: 5| Step: 1
Training loss: 2.1746485233306885
Validation loss: 2.294308975338936

Epoch: 5| Step: 2
Training loss: 2.4478933811187744
Validation loss: 2.3038844913244247

Epoch: 5| Step: 3
Training loss: 2.8612189292907715
Validation loss: 2.3041932582855225

Epoch: 5| Step: 4
Training loss: 2.3939170837402344
Validation loss: 2.283705542484919

Epoch: 5| Step: 5
Training loss: 2.3094558715820312
Validation loss: 2.2684379418691

Epoch: 5| Step: 6
Training loss: 2.5076143741607666
Validation loss: 2.2591220090786615

Epoch: 5| Step: 7
Training loss: 2.75130033493042
Validation loss: 2.2582671344280243

Epoch: 5| Step: 8
Training loss: 2.6047873497009277
Validation loss: 2.259807606538137

Epoch: 5| Step: 9
Training loss: 2.0315496921539307
Validation loss: 2.260520060857137

Epoch: 5| Step: 10
Training loss: 2.659482955932617
Validation loss: 2.262550011277199

Epoch: 5| Step: 11
Training loss: 2.5222229957580566
Validation loss: 2.258168096343676

Epoch: 64| Step: 0
Training loss: 2.3308897018432617
Validation loss: 2.25980606675148

Epoch: 5| Step: 1
Training loss: 2.075488328933716
Validation loss: 2.260053644577662

Epoch: 5| Step: 2
Training loss: 2.282332420349121
Validation loss: 2.2654397934675217

Epoch: 5| Step: 3
Training loss: 2.162214994430542
Validation loss: 2.2566540092229843

Epoch: 5| Step: 4
Training loss: 2.4992899894714355
Validation loss: 2.255543291568756

Epoch: 5| Step: 5
Training loss: 2.357130527496338
Validation loss: 2.2478946149349213

Epoch: 5| Step: 6
Training loss: 2.618880271911621
Validation loss: 2.248387267192205

Epoch: 5| Step: 7
Training loss: 2.693063259124756
Validation loss: 2.2397230664889016

Epoch: 5| Step: 8
Training loss: 2.4386963844299316
Validation loss: 2.2414367397626243

Epoch: 5| Step: 9
Training loss: 2.7034103870391846
Validation loss: 2.244123876094818

Epoch: 5| Step: 10
Training loss: 2.4984796047210693
Validation loss: 2.2391315946976342

Epoch: 5| Step: 11
Training loss: 1.4682440757751465
Validation loss: 2.237117037177086

Epoch: 65| Step: 0
Training loss: 2.7088589668273926
Validation loss: 2.2370292047659555

Epoch: 5| Step: 1
Training loss: 2.6519618034362793
Validation loss: 2.226338336865107

Epoch: 5| Step: 2
Training loss: 2.3192532062530518
Validation loss: 2.2293315629164376

Epoch: 5| Step: 3
Training loss: 2.510592460632324
Validation loss: 2.2243512322505317

Epoch: 5| Step: 4
Training loss: 2.7659385204315186
Validation loss: 2.2280947913726172

Epoch: 5| Step: 5
Training loss: 2.3063933849334717
Validation loss: 2.2286876241366067

Epoch: 5| Step: 6
Training loss: 2.2656986713409424
Validation loss: 2.222708597779274

Epoch: 5| Step: 7
Training loss: 1.9604177474975586
Validation loss: 2.22351935505867

Epoch: 5| Step: 8
Training loss: 2.168478488922119
Validation loss: 2.219006578127543

Epoch: 5| Step: 9
Training loss: 2.3126864433288574
Validation loss: 2.218086212873459

Epoch: 5| Step: 10
Training loss: 2.1893889904022217
Validation loss: 2.2161452869574227

Epoch: 5| Step: 11
Training loss: 2.6030168533325195
Validation loss: 2.2140577336152396

Epoch: 66| Step: 0
Training loss: 2.3052120208740234
Validation loss: 2.2100541293621063

Epoch: 5| Step: 1
Training loss: 2.063544273376465
Validation loss: 2.2087126970291138

Epoch: 5| Step: 2
Training loss: 2.1553876399993896
Validation loss: 2.205071359872818

Epoch: 5| Step: 3
Training loss: 2.108983278274536
Validation loss: 2.193326065937678

Epoch: 5| Step: 4
Training loss: 2.174705982208252
Validation loss: 2.185919940471649

Epoch: 5| Step: 5
Training loss: 2.4805541038513184
Validation loss: 2.1884160538514457

Epoch: 5| Step: 6
Training loss: 2.7236390113830566
Validation loss: 2.1938526978095374

Epoch: 5| Step: 7
Training loss: 2.8516523838043213
Validation loss: 2.19316000243028

Epoch: 5| Step: 8
Training loss: 2.5683741569519043
Validation loss: 2.1873286366462708

Epoch: 5| Step: 9
Training loss: 2.2948620319366455
Validation loss: 2.186015064517657

Epoch: 5| Step: 10
Training loss: 2.2395858764648438
Validation loss: 2.182672674457232

Epoch: 5| Step: 11
Training loss: 2.572591781616211
Validation loss: 2.1806995073954263

Epoch: 67| Step: 0
Training loss: 1.9866421222686768
Validation loss: 2.186030531922976

Epoch: 5| Step: 1
Training loss: 2.845578670501709
Validation loss: 2.178962836662928

Epoch: 5| Step: 2
Training loss: 2.2735965251922607
Validation loss: 2.1851932456096015

Epoch: 5| Step: 3
Training loss: 2.3048644065856934
Validation loss: 2.1863795717557273

Epoch: 5| Step: 4
Training loss: 2.247030735015869
Validation loss: 2.1807794173558555

Epoch: 5| Step: 5
Training loss: 2.2609400749206543
Validation loss: 2.180214782555898

Epoch: 5| Step: 6
Training loss: 1.7021701335906982
Validation loss: 2.1752589344978333

Epoch: 5| Step: 7
Training loss: 2.6732757091522217
Validation loss: 2.1744109988212585

Epoch: 5| Step: 8
Training loss: 2.0686779022216797
Validation loss: 2.1704587638378143

Epoch: 5| Step: 9
Training loss: 2.5515224933624268
Validation loss: 2.1668602724870047

Epoch: 5| Step: 10
Training loss: 2.9010226726531982
Validation loss: 2.1623855531215668

Epoch: 5| Step: 11
Training loss: 1.6860642433166504
Validation loss: 2.1656667391459146

Epoch: 68| Step: 0
Training loss: 2.6075692176818848
Validation loss: 2.1603180865446725

Epoch: 5| Step: 1
Training loss: 2.5125317573547363
Validation loss: 2.198971043030421

Epoch: 5| Step: 2
Training loss: 2.5287845134735107
Validation loss: 2.2057957351207733

Epoch: 5| Step: 3
Training loss: 2.210665225982666
Validation loss: 2.2003796050945916

Epoch: 5| Step: 4
Training loss: 2.736741304397583
Validation loss: 2.173025647799174

Epoch: 5| Step: 5
Training loss: 2.144026279449463
Validation loss: 2.1601964930693307

Epoch: 5| Step: 6
Training loss: 2.4042389392852783
Validation loss: 2.153260514140129

Epoch: 5| Step: 7
Training loss: 2.341118335723877
Validation loss: 2.1549481401840844

Epoch: 5| Step: 8
Training loss: 1.9736568927764893
Validation loss: 2.1673582245906196

Epoch: 5| Step: 9
Training loss: 2.184792995452881
Validation loss: 2.1695448458194733

Epoch: 5| Step: 10
Training loss: 2.0595078468322754
Validation loss: 2.17164446413517

Epoch: 5| Step: 11
Training loss: 2.917365789413452
Validation loss: 2.1731836597124734

Epoch: 69| Step: 0
Training loss: 2.2709078788757324
Validation loss: 2.1721778263648353

Epoch: 5| Step: 1
Training loss: 1.7848455905914307
Validation loss: 2.1775316298007965

Epoch: 5| Step: 2
Training loss: 2.035313129425049
Validation loss: 2.1712848047415414

Epoch: 5| Step: 3
Training loss: 2.652592658996582
Validation loss: 2.1674447655677795

Epoch: 5| Step: 4
Training loss: 2.2119555473327637
Validation loss: 2.1708402882019677

Epoch: 5| Step: 5
Training loss: 2.516003131866455
Validation loss: 2.1686998307704926

Epoch: 5| Step: 6
Training loss: 2.2695770263671875
Validation loss: 2.1634321908156076

Epoch: 5| Step: 7
Training loss: 2.720343828201294
Validation loss: 2.160380780696869

Epoch: 5| Step: 8
Training loss: 2.4387428760528564
Validation loss: 2.1539753129084906

Epoch: 5| Step: 9
Training loss: 2.2560200691223145
Validation loss: 2.151101062695185

Epoch: 5| Step: 10
Training loss: 2.3640928268432617
Validation loss: 2.148802563548088

Epoch: 5| Step: 11
Training loss: 2.681262969970703
Validation loss: 2.145356148481369

Epoch: 70| Step: 0
Training loss: 2.568054676055908
Validation loss: 2.139146407445272

Epoch: 5| Step: 1
Training loss: 2.1331920623779297
Validation loss: 2.13494540254275

Epoch: 5| Step: 2
Training loss: 2.1926522254943848
Validation loss: 2.1384140700101852

Epoch: 5| Step: 3
Training loss: 2.1113839149475098
Validation loss: 2.1366832107305527

Epoch: 5| Step: 4
Training loss: 2.3205480575561523
Validation loss: 2.1339630087216697

Epoch: 5| Step: 5
Training loss: 2.6272571086883545
Validation loss: 2.1327743232250214

Epoch: 5| Step: 6
Training loss: 2.347688674926758
Validation loss: 2.1315316607554755

Epoch: 5| Step: 7
Training loss: 2.3242249488830566
Validation loss: 2.1332676708698273

Epoch: 5| Step: 8
Training loss: 2.1740708351135254
Validation loss: 2.1307998994986215

Epoch: 5| Step: 9
Training loss: 2.0025105476379395
Validation loss: 2.123674909273783

Epoch: 5| Step: 10
Training loss: 2.6137423515319824
Validation loss: 2.1204815606276193

Epoch: 5| Step: 11
Training loss: 1.3594828844070435
Validation loss: 2.1269660194714866

Epoch: 71| Step: 0
Training loss: 2.767789363861084
Validation loss: 2.1214104195435843

Epoch: 5| Step: 1
Training loss: 2.0491557121276855
Validation loss: 2.1242796232302985

Epoch: 5| Step: 2
Training loss: 1.6461079120635986
Validation loss: 2.1284337093432746

Epoch: 5| Step: 3
Training loss: 2.911410331726074
Validation loss: 2.124779149889946

Epoch: 5| Step: 4
Training loss: 2.4549338817596436
Validation loss: 2.127170979976654

Epoch: 5| Step: 5
Training loss: 2.26505708694458
Validation loss: 2.126443564891815

Epoch: 5| Step: 6
Training loss: 1.661900281906128
Validation loss: 2.131104459365209

Epoch: 5| Step: 7
Training loss: 2.2308549880981445
Validation loss: 2.119240249196688

Epoch: 5| Step: 8
Training loss: 2.632429599761963
Validation loss: 2.122426673769951

Epoch: 5| Step: 9
Training loss: 1.841040015220642
Validation loss: 2.1216050535440445

Epoch: 5| Step: 10
Training loss: 2.4554667472839355
Validation loss: 2.1198531289895377

Epoch: 5| Step: 11
Training loss: 3.3243215084075928
Validation loss: 2.1110696494579315

Epoch: 72| Step: 0
Training loss: 2.0320732593536377
Validation loss: 2.1140157133340836

Epoch: 5| Step: 1
Training loss: 1.9550119638442993
Validation loss: 2.1146131803592048

Epoch: 5| Step: 2
Training loss: 2.5447351932525635
Validation loss: 2.109543427824974

Epoch: 5| Step: 3
Training loss: 2.1744112968444824
Validation loss: 2.1074558943510056

Epoch: 5| Step: 4
Training loss: 1.887679100036621
Validation loss: 2.1094398697217307

Epoch: 5| Step: 5
Training loss: 2.7378010749816895
Validation loss: 2.113982712229093

Epoch: 5| Step: 6
Training loss: 2.1549410820007324
Validation loss: 2.119051600495974

Epoch: 5| Step: 7
Training loss: 2.50338077545166
Validation loss: 2.115482653180758

Epoch: 5| Step: 8
Training loss: 2.5838303565979004
Validation loss: 2.111447627345721

Epoch: 5| Step: 9
Training loss: 2.254464864730835
Validation loss: 2.104445586601893

Epoch: 5| Step: 10
Training loss: 2.212338924407959
Validation loss: 2.101936866839727

Epoch: 5| Step: 11
Training loss: 2.3563971519470215
Validation loss: 2.1048937141895294

Epoch: 73| Step: 0
Training loss: 2.159191608428955
Validation loss: 2.102156107624372

Epoch: 5| Step: 1
Training loss: 2.1377549171447754
Validation loss: 2.1018158892790475

Epoch: 5| Step: 2
Training loss: 2.1958932876586914
Validation loss: 2.1058758149544397

Epoch: 5| Step: 3
Training loss: 2.448408842086792
Validation loss: 2.1158356964588165

Epoch: 5| Step: 4
Training loss: 1.5092531442642212
Validation loss: 2.114863703648249

Epoch: 5| Step: 5
Training loss: 2.7470364570617676
Validation loss: 2.1118318488200507

Epoch: 5| Step: 6
Training loss: 2.694363832473755
Validation loss: 2.1109440674384436

Epoch: 5| Step: 7
Training loss: 2.255413055419922
Validation loss: 2.1106968820095062

Epoch: 5| Step: 8
Training loss: 2.413112163543701
Validation loss: 2.1061967462301254

Epoch: 5| Step: 9
Training loss: 2.3532164096832275
Validation loss: 2.093818078438441

Epoch: 5| Step: 10
Training loss: 2.0754470825195312
Validation loss: 2.095018227895101

Epoch: 5| Step: 11
Training loss: 2.2394003868103027
Validation loss: 2.0978871087233224

Epoch: 74| Step: 0
Training loss: 2.710512638092041
Validation loss: 2.1054174999396005

Epoch: 5| Step: 1
Training loss: 2.418985605239868
Validation loss: 2.108997811873754

Epoch: 5| Step: 2
Training loss: 2.2727808952331543
Validation loss: 2.1060335636138916

Epoch: 5| Step: 3
Training loss: 2.7934346199035645
Validation loss: 2.1061799228191376

Epoch: 5| Step: 4
Training loss: 1.6390364170074463
Validation loss: 2.106305405497551

Epoch: 5| Step: 5
Training loss: 2.093730926513672
Validation loss: 2.107123851776123

Epoch: 5| Step: 6
Training loss: 1.676534652709961
Validation loss: 2.106238683064779

Epoch: 5| Step: 7
Training loss: 2.8287224769592285
Validation loss: 2.1000544726848602

Epoch: 5| Step: 8
Training loss: 2.3363051414489746
Validation loss: 2.0974970857302346

Epoch: 5| Step: 9
Training loss: 2.050457000732422
Validation loss: 2.0961340069770813

Epoch: 5| Step: 10
Training loss: 1.8455359935760498
Validation loss: 2.091625596086184

Epoch: 5| Step: 11
Training loss: 3.587254047393799
Validation loss: 2.087096080183983

Epoch: 75| Step: 0
Training loss: 2.1246933937072754
Validation loss: 2.0863041281700134

Epoch: 5| Step: 1
Training loss: 2.160707712173462
Validation loss: 2.0874325335025787

Epoch: 5| Step: 2
Training loss: 2.4555583000183105
Validation loss: 2.0839134454727173

Epoch: 5| Step: 3
Training loss: 2.6953701972961426
Validation loss: 2.0791937857866287

Epoch: 5| Step: 4
Training loss: 2.0162434577941895
Validation loss: 2.0798112551371255

Epoch: 5| Step: 5
Training loss: 2.4277377128601074
Validation loss: 2.0708415657281876

Epoch: 5| Step: 6
Training loss: 2.117816925048828
Validation loss: 2.066815420985222

Epoch: 5| Step: 7
Training loss: 2.2911453247070312
Validation loss: 2.069267064332962

Epoch: 5| Step: 8
Training loss: 2.1412723064422607
Validation loss: 2.070896436770757

Epoch: 5| Step: 9
Training loss: 2.3752377033233643
Validation loss: 2.080835203329722

Epoch: 5| Step: 10
Training loss: 1.8755992650985718
Validation loss: 2.0844056208928428

Epoch: 5| Step: 11
Training loss: 2.661747455596924
Validation loss: 2.077596748868624

Epoch: 76| Step: 0
Training loss: 2.704622745513916
Validation loss: 2.0746382425228753

Epoch: 5| Step: 1
Training loss: 1.77777898311615
Validation loss: 2.0652682383855185

Epoch: 5| Step: 2
Training loss: 2.632229804992676
Validation loss: 2.069138060013453

Epoch: 5| Step: 3
Training loss: 2.064506769180298
Validation loss: 2.068045342961947

Epoch: 5| Step: 4
Training loss: 1.886732816696167
Validation loss: 2.063785210251808

Epoch: 5| Step: 5
Training loss: 2.584596633911133
Validation loss: 2.0695329109827676

Epoch: 5| Step: 6
Training loss: 2.0576605796813965
Validation loss: 2.072932248314222

Epoch: 5| Step: 7
Training loss: 1.871431589126587
Validation loss: 2.0718068331480026

Epoch: 5| Step: 8
Training loss: 2.4859066009521484
Validation loss: 2.0717540283997855

Epoch: 5| Step: 9
Training loss: 2.1169068813323975
Validation loss: 2.0700106670459113

Epoch: 5| Step: 10
Training loss: 2.516510486602783
Validation loss: 2.0672557900349298

Epoch: 5| Step: 11
Training loss: 1.6185755729675293
Validation loss: 2.0614682535330453

Epoch: 77| Step: 0
Training loss: 2.0923643112182617
Validation loss: 2.060295914610227

Epoch: 5| Step: 1
Training loss: 2.021028995513916
Validation loss: 2.052409072717031

Epoch: 5| Step: 2
Training loss: 2.580033540725708
Validation loss: 2.060480604569117

Epoch: 5| Step: 3
Training loss: 2.614687442779541
Validation loss: 2.0603523701429367

Epoch: 5| Step: 4
Training loss: 1.8206619024276733
Validation loss: 2.060543492436409

Epoch: 5| Step: 5
Training loss: 2.1767687797546387
Validation loss: 2.0634931127230325

Epoch: 5| Step: 6
Training loss: 1.8737878799438477
Validation loss: 2.06894181172053

Epoch: 5| Step: 7
Training loss: 2.014669418334961
Validation loss: 2.0750829776128135

Epoch: 5| Step: 8
Training loss: 2.279745101928711
Validation loss: 2.068316807349523

Epoch: 5| Step: 9
Training loss: 2.4656176567077637
Validation loss: 2.0712528278430304

Epoch: 5| Step: 10
Training loss: 2.510345458984375
Validation loss: 2.060813029607137

Epoch: 5| Step: 11
Training loss: 2.463383197784424
Validation loss: 2.055733382701874

Epoch: 78| Step: 0
Training loss: 2.379322052001953
Validation loss: 2.0530808518330255

Epoch: 5| Step: 1
Training loss: 2.4788873195648193
Validation loss: 2.058876862128576

Epoch: 5| Step: 2
Training loss: 1.6819511651992798
Validation loss: 2.052921618024508

Epoch: 5| Step: 3
Training loss: 2.2912278175354004
Validation loss: 2.0505869636933007

Epoch: 5| Step: 4
Training loss: 2.317552089691162
Validation loss: 2.0563904543717704

Epoch: 5| Step: 5
Training loss: 1.9554393291473389
Validation loss: 2.0535987267891564

Epoch: 5| Step: 6
Training loss: 2.002899646759033
Validation loss: 2.0493007401625314

Epoch: 5| Step: 7
Training loss: 2.025968074798584
Validation loss: 2.0504296670357385

Epoch: 5| Step: 8
Training loss: 2.753476619720459
Validation loss: 2.055502787232399

Epoch: 5| Step: 9
Training loss: 2.3541159629821777
Validation loss: 2.054954086740812

Epoch: 5| Step: 10
Training loss: 2.2685534954071045
Validation loss: 2.0563111106554666

Epoch: 5| Step: 11
Training loss: 1.5962588787078857
Validation loss: 2.0534428358078003

Epoch: 79| Step: 0
Training loss: 1.9941437244415283
Validation loss: 2.054260070125262

Epoch: 5| Step: 1
Training loss: 2.4754538536071777
Validation loss: 2.0498828341563544

Epoch: 5| Step: 2
Training loss: 1.737919569015503
Validation loss: 2.052892178297043

Epoch: 5| Step: 3
Training loss: 1.852741003036499
Validation loss: 2.050467034180959

Epoch: 5| Step: 4
Training loss: 2.1614878177642822
Validation loss: 2.049392114082972

Epoch: 5| Step: 5
Training loss: 2.2291667461395264
Validation loss: 2.04804997642835

Epoch: 5| Step: 6
Training loss: 2.018190622329712
Validation loss: 2.050139844417572

Epoch: 5| Step: 7
Training loss: 2.80928373336792
Validation loss: 2.040693690379461

Epoch: 5| Step: 8
Training loss: 2.500796318054199
Validation loss: 2.0460300147533417

Epoch: 5| Step: 9
Training loss: 2.127197504043579
Validation loss: 2.052192449569702

Epoch: 5| Step: 10
Training loss: 2.5460665225982666
Validation loss: 2.0573503375053406

Epoch: 5| Step: 11
Training loss: 1.440989375114441
Validation loss: 2.0640229334433875

Epoch: 80| Step: 0
Training loss: 2.449578046798706
Validation loss: 2.069766571124395

Epoch: 5| Step: 1
Training loss: 2.246598720550537
Validation loss: 2.07418392598629

Epoch: 5| Step: 2
Training loss: 1.8927638530731201
Validation loss: 2.0701962610085807

Epoch: 5| Step: 3
Training loss: 2.2968921661376953
Validation loss: 2.0501238852739334

Epoch: 5| Step: 4
Training loss: 2.027642250061035
Validation loss: 2.03910094499588

Epoch: 5| Step: 5
Training loss: 2.4079716205596924
Validation loss: 2.0430423667033515

Epoch: 5| Step: 6
Training loss: 2.179893970489502
Validation loss: 2.051483228802681

Epoch: 5| Step: 7
Training loss: 2.7392377853393555
Validation loss: 2.0490665833155313

Epoch: 5| Step: 8
Training loss: 1.8873426914215088
Validation loss: 2.0560000042120614

Epoch: 5| Step: 9
Training loss: 1.7201684713363647
Validation loss: 2.055173709988594

Epoch: 5| Step: 10
Training loss: 2.6657800674438477
Validation loss: 2.059795543551445

Epoch: 5| Step: 11
Training loss: 2.3509039878845215
Validation loss: 2.053615609804789

Epoch: 81| Step: 0
Training loss: 2.5708489418029785
Validation loss: 2.0571178694566092

Epoch: 5| Step: 1
Training loss: 2.3376739025115967
Validation loss: 2.0531512399514518

Epoch: 5| Step: 2
Training loss: 2.075471878051758
Validation loss: 2.0601515819629035

Epoch: 5| Step: 3
Training loss: 2.4142580032348633
Validation loss: 2.055989980697632

Epoch: 5| Step: 4
Training loss: 2.3793487548828125
Validation loss: 2.0472393532594046

Epoch: 5| Step: 5
Training loss: 2.1997368335723877
Validation loss: 2.0536803950866065

Epoch: 5| Step: 6
Training loss: 2.148118495941162
Validation loss: 2.043387065331141

Epoch: 5| Step: 7
Training loss: 1.624096155166626
Validation loss: 2.0463922868172326

Epoch: 5| Step: 8
Training loss: 2.488969326019287
Validation loss: 2.0384196092685065

Epoch: 5| Step: 9
Training loss: 2.069809675216675
Validation loss: 2.038271779815356

Epoch: 5| Step: 10
Training loss: 2.007258892059326
Validation loss: 2.048838277657827

Epoch: 5| Step: 11
Training loss: 2.2224512100219727
Validation loss: 2.0588596761226654

Epoch: 82| Step: 0
Training loss: 2.690626859664917
Validation loss: 2.0743526071310043

Epoch: 5| Step: 1
Training loss: 1.9020023345947266
Validation loss: 2.083869978785515

Epoch: 5| Step: 2
Training loss: 2.1955411434173584
Validation loss: 2.0833468486865363

Epoch: 5| Step: 3
Training loss: 1.8238794803619385
Validation loss: 2.085402190685272

Epoch: 5| Step: 4
Training loss: 2.368889093399048
Validation loss: 2.0790317406256995

Epoch: 5| Step: 5
Training loss: 1.7542091608047485
Validation loss: 2.0733622908592224

Epoch: 5| Step: 6
Training loss: 1.9330475330352783
Validation loss: 2.057152658700943

Epoch: 5| Step: 7
Training loss: 2.7158219814300537
Validation loss: 2.038168177008629

Epoch: 5| Step: 8
Training loss: 1.878160834312439
Validation loss: 2.0327764799197516

Epoch: 5| Step: 9
Training loss: 2.727692127227783
Validation loss: 2.033431659142176

Epoch: 5| Step: 10
Training loss: 2.2653286457061768
Validation loss: 2.041072423259417

Epoch: 5| Step: 11
Training loss: 2.052386522293091
Validation loss: 2.042417565981547

Epoch: 83| Step: 0
Training loss: 2.3580498695373535
Validation loss: 2.048838054140409

Epoch: 5| Step: 1
Training loss: 2.019979238510132
Validation loss: 2.0516365319490433

Epoch: 5| Step: 2
Training loss: 2.4994144439697266
Validation loss: 2.0561103175083795

Epoch: 5| Step: 3
Training loss: 2.0338215827941895
Validation loss: 2.0629887133836746

Epoch: 5| Step: 4
Training loss: 2.03288197517395
Validation loss: 2.066230371594429

Epoch: 5| Step: 5
Training loss: 3.0767946243286133
Validation loss: 2.0689440965652466

Epoch: 5| Step: 6
Training loss: 1.8618505001068115
Validation loss: 2.0605148623387017

Epoch: 5| Step: 7
Training loss: 1.8913017511367798
Validation loss: 2.061700557669004

Epoch: 5| Step: 8
Training loss: 2.5663299560546875
Validation loss: 2.058839331070582

Epoch: 5| Step: 9
Training loss: 2.156342029571533
Validation loss: 2.054790715376536

Epoch: 5| Step: 10
Training loss: 2.3543007373809814
Validation loss: 2.053365727265676

Epoch: 5| Step: 11
Training loss: 1.3496837615966797
Validation loss: 2.0482514252265296

Epoch: 84| Step: 0
Training loss: 2.2871222496032715
Validation loss: 2.0416805843512216

Epoch: 5| Step: 1
Training loss: 2.828071117401123
Validation loss: 2.044961705803871

Epoch: 5| Step: 2
Training loss: 2.2944979667663574
Validation loss: 2.041912948091825

Epoch: 5| Step: 3
Training loss: 1.8288671970367432
Validation loss: 2.033105254173279

Epoch: 5| Step: 4
Training loss: 2.1755621433258057
Validation loss: 2.031535138686498

Epoch: 5| Step: 5
Training loss: 2.1106934547424316
Validation loss: 2.033601383368174

Epoch: 5| Step: 6
Training loss: 1.749285101890564
Validation loss: 2.0448008279005685

Epoch: 5| Step: 7
Training loss: 2.593400001525879
Validation loss: 2.050153454144796

Epoch: 5| Step: 8
Training loss: 1.8990871906280518
Validation loss: 2.0523778746525445

Epoch: 5| Step: 9
Training loss: 1.813891053199768
Validation loss: 2.0619329661130905

Epoch: 5| Step: 10
Training loss: 2.4878299236297607
Validation loss: 2.0572567731142044

Epoch: 5| Step: 11
Training loss: 2.656874656677246
Validation loss: 2.0778641601403556

Epoch: 85| Step: 0
Training loss: 1.5918015241622925
Validation loss: 2.0597795794407525

Epoch: 5| Step: 1
Training loss: 2.1118698120117188
Validation loss: 2.061217044790586

Epoch: 5| Step: 2
Training loss: 2.7642881870269775
Validation loss: 2.057521735628446

Epoch: 5| Step: 3
Training loss: 2.0521559715270996
Validation loss: 2.033002962668737

Epoch: 5| Step: 4
Training loss: 2.384467601776123
Validation loss: 2.0302174985408783

Epoch: 5| Step: 5
Training loss: 2.070155382156372
Validation loss: 2.0287716885407767

Epoch: 5| Step: 6
Training loss: 2.0783772468566895
Validation loss: 2.0284818758567176

Epoch: 5| Step: 7
Training loss: 2.14567232131958
Validation loss: 2.036703586578369

Epoch: 5| Step: 8
Training loss: 2.5157763957977295
Validation loss: 2.0326968481143317

Epoch: 5| Step: 9
Training loss: 2.0648560523986816
Validation loss: 2.037968397140503

Epoch: 5| Step: 10
Training loss: 2.390681743621826
Validation loss: 2.037272850672404

Epoch: 5| Step: 11
Training loss: 2.4325785636901855
Validation loss: 2.0360207806030908

Epoch: 86| Step: 0
Training loss: 2.010591983795166
Validation loss: 2.038294404745102

Epoch: 5| Step: 1
Training loss: 2.7403321266174316
Validation loss: 2.0410132656494775

Epoch: 5| Step: 2
Training loss: 2.5630390644073486
Validation loss: 2.036536529660225

Epoch: 5| Step: 3
Training loss: 2.3134965896606445
Validation loss: 2.025964245200157

Epoch: 5| Step: 4
Training loss: 2.107004165649414
Validation loss: 2.0321903824806213

Epoch: 5| Step: 5
Training loss: 2.132885456085205
Validation loss: 2.030124763647715

Epoch: 5| Step: 6
Training loss: 2.7381069660186768
Validation loss: 2.0263655334711075

Epoch: 5| Step: 7
Training loss: 1.6364176273345947
Validation loss: 2.032734125852585

Epoch: 5| Step: 8
Training loss: 1.7860761880874634
Validation loss: 2.0276608020067215

Epoch: 5| Step: 9
Training loss: 1.8771469593048096
Validation loss: 2.0284381111462912

Epoch: 5| Step: 10
Training loss: 2.377316951751709
Validation loss: 2.0254401514927545

Epoch: 5| Step: 11
Training loss: 1.5052762031555176
Validation loss: 2.0238540967305503

Epoch: 87| Step: 0
Training loss: 2.0791804790496826
Validation loss: 2.0419364223877587

Epoch: 5| Step: 1
Training loss: 2.092855930328369
Validation loss: 2.0534699658552804

Epoch: 5| Step: 2
Training loss: 2.3747007846832275
Validation loss: 2.0631840378046036

Epoch: 5| Step: 3
Training loss: 1.509624719619751
Validation loss: 2.0759353637695312

Epoch: 5| Step: 4
Training loss: 2.6621296405792236
Validation loss: 2.082181011637052

Epoch: 5| Step: 5
Training loss: 2.4587717056274414
Validation loss: 2.0974127650260925

Epoch: 5| Step: 6
Training loss: 2.233449935913086
Validation loss: 2.084161718686422

Epoch: 5| Step: 7
Training loss: 2.3006014823913574
Validation loss: 2.0748715748389563

Epoch: 5| Step: 8
Training loss: 2.338937282562256
Validation loss: 2.067407270272573

Epoch: 5| Step: 9
Training loss: 2.336526870727539
Validation loss: 2.05489644408226

Epoch: 5| Step: 10
Training loss: 2.3384833335876465
Validation loss: 2.0536677787701287

Epoch: 5| Step: 11
Training loss: 1.228064775466919
Validation loss: 2.0467064678668976

Epoch: 88| Step: 0
Training loss: 2.2187416553497314
Validation loss: 2.033332054813703

Epoch: 5| Step: 1
Training loss: 1.761441946029663
Validation loss: 2.0268412878115973

Epoch: 5| Step: 2
Training loss: 2.288548707962036
Validation loss: 2.0245935966571174

Epoch: 5| Step: 3
Training loss: 1.9654489755630493
Validation loss: 2.0311165153980255

Epoch: 5| Step: 4
Training loss: 1.933363914489746
Validation loss: 2.031085252761841

Epoch: 5| Step: 5
Training loss: 1.8065767288208008
Validation loss: 2.040307799975077

Epoch: 5| Step: 6
Training loss: 2.38334584236145
Validation loss: 2.036661018927892

Epoch: 5| Step: 7
Training loss: 2.24226450920105
Validation loss: 2.037032206853231

Epoch: 5| Step: 8
Training loss: 2.2997536659240723
Validation loss: 2.0413936177889505

Epoch: 5| Step: 9
Training loss: 2.4327244758605957
Validation loss: 2.036456053455671

Epoch: 5| Step: 10
Training loss: 2.6051528453826904
Validation loss: 2.0336298843224845

Epoch: 5| Step: 11
Training loss: 2.50671124458313
Validation loss: 2.034107501308123

Epoch: 89| Step: 0
Training loss: 1.6298023462295532
Validation loss: 2.0410990715026855

Epoch: 5| Step: 1
Training loss: 2.2413690090179443
Validation loss: 2.0317055682341256

Epoch: 5| Step: 2
Training loss: 2.4359724521636963
Validation loss: 2.0318079789479575

Epoch: 5| Step: 3
Training loss: 2.096874475479126
Validation loss: 2.035933872063955

Epoch: 5| Step: 4
Training loss: 2.559539794921875
Validation loss: 2.0242330680290856

Epoch: 5| Step: 5
Training loss: 1.8761377334594727
Validation loss: 2.0335127115249634

Epoch: 5| Step: 6
Training loss: 2.1569976806640625
Validation loss: 2.0401050547758737

Epoch: 5| Step: 7
Training loss: 2.2203121185302734
Validation loss: 2.045491879185041

Epoch: 5| Step: 8
Training loss: 1.9620018005371094
Validation loss: 2.060351863503456

Epoch: 5| Step: 9
Training loss: 2.230665445327759
Validation loss: 2.073380579551061

Epoch: 5| Step: 10
Training loss: 2.5950915813446045
Validation loss: 2.0785052279631295

Epoch: 5| Step: 11
Training loss: 2.7049593925476074
Validation loss: 2.072888751824697

Epoch: 90| Step: 0
Training loss: 2.1586034297943115
Validation loss: 2.0501836289962134

Epoch: 5| Step: 1
Training loss: 2.4471020698547363
Validation loss: 2.045054559906324

Epoch: 5| Step: 2
Training loss: 1.929674744606018
Validation loss: 2.024332528313001

Epoch: 5| Step: 3
Training loss: 2.0509331226348877
Validation loss: 2.026956265171369

Epoch: 5| Step: 4
Training loss: 1.9955085515975952
Validation loss: 2.0353241860866547

Epoch: 5| Step: 5
Training loss: 1.8952395915985107
Validation loss: 2.027956714232763

Epoch: 5| Step: 6
Training loss: 2.444413661956787
Validation loss: 2.0402794629335403

Epoch: 5| Step: 7
Training loss: 2.5654754638671875
Validation loss: 2.0337995340426764

Epoch: 5| Step: 8
Training loss: 1.6153453588485718
Validation loss: 2.034264783064524

Epoch: 5| Step: 9
Training loss: 2.683260202407837
Validation loss: 2.038985714316368

Epoch: 5| Step: 10
Training loss: 2.5509657859802246
Validation loss: 2.0405413260062537

Epoch: 5| Step: 11
Training loss: 1.1559269428253174
Validation loss: 2.0334494411945343

Epoch: 91| Step: 0
Training loss: 1.9671123027801514
Validation loss: 2.030055229862531

Epoch: 5| Step: 1
Training loss: 2.1327731609344482
Validation loss: 2.0277209679285684

Epoch: 5| Step: 2
Training loss: 2.2580997943878174
Validation loss: 2.0243942538897195

Epoch: 5| Step: 3
Training loss: 2.5401203632354736
Validation loss: 2.026816035310427

Epoch: 5| Step: 4
Training loss: 2.087336778640747
Validation loss: 2.021859516700109

Epoch: 5| Step: 5
Training loss: 2.362041711807251
Validation loss: 2.027089615662893

Epoch: 5| Step: 6
Training loss: 2.1121420860290527
Validation loss: 2.018148591121038

Epoch: 5| Step: 7
Training loss: 1.9696305990219116
Validation loss: 2.0242716620365777

Epoch: 5| Step: 8
Training loss: 1.6382993459701538
Validation loss: 2.0241900285085044

Epoch: 5| Step: 9
Training loss: 2.5378804206848145
Validation loss: 2.0289691338936486

Epoch: 5| Step: 10
Training loss: 2.6518075466156006
Validation loss: 2.0352394382158914

Epoch: 5| Step: 11
Training loss: 0.8868869543075562
Validation loss: 2.0303638329108558

Epoch: 92| Step: 0
Training loss: 1.7917671203613281
Validation loss: 2.0397589256366095

Epoch: 5| Step: 1
Training loss: 2.7505576610565186
Validation loss: 2.04666901131471

Epoch: 5| Step: 2
Training loss: 2.3555908203125
Validation loss: 2.0488463938236237

Epoch: 5| Step: 3
Training loss: 2.5716187953948975
Validation loss: 2.0386179288228354

Epoch: 5| Step: 4
Training loss: 2.3747451305389404
Validation loss: 2.038627803325653

Epoch: 5| Step: 5
Training loss: 1.9258066415786743
Validation loss: 2.0321166266997657

Epoch: 5| Step: 6
Training loss: 2.0993711948394775
Validation loss: 2.0314174195130668

Epoch: 5| Step: 7
Training loss: 1.6615413427352905
Validation loss: 2.0272535433371863

Epoch: 5| Step: 8
Training loss: 2.371190071105957
Validation loss: 2.028720195094744

Epoch: 5| Step: 9
Training loss: 1.7277214527130127
Validation loss: 2.0298554797967276

Epoch: 5| Step: 10
Training loss: 2.209559917449951
Validation loss: 2.029389207561811

Epoch: 5| Step: 11
Training loss: 2.74666166305542
Validation loss: 2.030734827121099

Epoch: 93| Step: 0
Training loss: 2.4115488529205322
Validation loss: 2.024035448829333

Epoch: 5| Step: 1
Training loss: 1.984731912612915
Validation loss: 2.039676939447721

Epoch: 5| Step: 2
Training loss: 2.3595998287200928
Validation loss: 2.0442669093608856

Epoch: 5| Step: 3
Training loss: 1.1686588525772095
Validation loss: 2.0514691223700843

Epoch: 5| Step: 4
Training loss: 2.4054508209228516
Validation loss: 2.0537853091955185

Epoch: 5| Step: 5
Training loss: 2.002861499786377
Validation loss: 2.057332624991735

Epoch: 5| Step: 6
Training loss: 2.673044443130493
Validation loss: 2.0538125981887183

Epoch: 5| Step: 7
Training loss: 2.646092176437378
Validation loss: 2.0474387605985007

Epoch: 5| Step: 8
Training loss: 2.6223678588867188
Validation loss: 2.03589994708697

Epoch: 5| Step: 9
Training loss: 1.7629928588867188
Validation loss: 2.0376170625289283

Epoch: 5| Step: 10
Training loss: 1.9452288150787354
Validation loss: 2.029630556702614

Epoch: 5| Step: 11
Training loss: 1.7971079349517822
Validation loss: 2.032931943734487

Epoch: 94| Step: 0
Training loss: 2.066906452178955
Validation loss: 2.0443839182456336

Epoch: 5| Step: 1
Training loss: 2.356370449066162
Validation loss: 2.0425277004639306

Epoch: 5| Step: 2
Training loss: 1.9509117603302002
Validation loss: 2.047505741318067

Epoch: 5| Step: 3
Training loss: 1.6336071491241455
Validation loss: 2.0465529511372247

Epoch: 5| Step: 4
Training loss: 2.3542540073394775
Validation loss: 2.050597161054611

Epoch: 5| Step: 5
Training loss: 1.8651676177978516
Validation loss: 2.042346715927124

Epoch: 5| Step: 6
Training loss: 2.284829616546631
Validation loss: 2.0483919282754264

Epoch: 5| Step: 7
Training loss: 2.6896307468414307
Validation loss: 2.0481182585159936

Epoch: 5| Step: 8
Training loss: 2.612866163253784
Validation loss: 2.0452225704987845

Epoch: 5| Step: 9
Training loss: 1.850337266921997
Validation loss: 2.050173078974088

Epoch: 5| Step: 10
Training loss: 2.21075177192688
Validation loss: 2.0515768975019455

Epoch: 5| Step: 11
Training loss: 1.5095677375793457
Validation loss: 2.048924465974172

Epoch: 95| Step: 0
Training loss: 2.075155258178711
Validation loss: 2.039407789707184

Epoch: 5| Step: 1
Training loss: 1.3045233488082886
Validation loss: 2.037870024641355

Epoch: 5| Step: 2
Training loss: 2.5418453216552734
Validation loss: 2.0405711829662323

Epoch: 5| Step: 3
Training loss: 1.9460948705673218
Validation loss: 2.04620290795962

Epoch: 5| Step: 4
Training loss: 2.2978439331054688
Validation loss: 2.033851241072019

Epoch: 5| Step: 5
Training loss: 2.71407151222229
Validation loss: 2.0478344013293586

Epoch: 5| Step: 6
Training loss: 1.9478477239608765
Validation loss: 2.046191230416298

Epoch: 5| Step: 7
Training loss: 2.213042736053467
Validation loss: 2.0577617088953652

Epoch: 5| Step: 8
Training loss: 2.1555681228637695
Validation loss: 2.0571187337239585

Epoch: 5| Step: 9
Training loss: 1.7535804510116577
Validation loss: 2.0568625132242837

Epoch: 5| Step: 10
Training loss: 2.475222587585449
Validation loss: 2.061801170309385

Epoch: 5| Step: 11
Training loss: 3.63871431350708
Validation loss: 2.0574083427588143

Epoch: 96| Step: 0
Training loss: 2.16614031791687
Validation loss: 2.056159123778343

Epoch: 5| Step: 1
Training loss: 2.5510616302490234
Validation loss: 2.0558957209189734

Epoch: 5| Step: 2
Training loss: 1.7559576034545898
Validation loss: 2.049682080745697

Epoch: 5| Step: 3
Training loss: 2.059225559234619
Validation loss: 2.048101077477137

Epoch: 5| Step: 4
Training loss: 1.9322818517684937
Validation loss: 2.0453142474095025

Epoch: 5| Step: 5
Training loss: 1.9302875995635986
Validation loss: 2.03938781718413

Epoch: 5| Step: 6
Training loss: 2.4470455646514893
Validation loss: 2.029146815339724

Epoch: 5| Step: 7
Training loss: 2.667275905609131
Validation loss: 2.0431483338276544

Epoch: 5| Step: 8
Training loss: 2.2445428371429443
Validation loss: 2.0384816924730935

Epoch: 5| Step: 9
Training loss: 2.2241058349609375
Validation loss: 2.0381484031677246

Epoch: 5| Step: 10
Training loss: 1.9460569620132446
Validation loss: 2.029404158393542

Epoch: 5| Step: 11
Training loss: 1.1843377351760864
Validation loss: 2.044006869196892

Epoch: 97| Step: 0
Training loss: 2.2445974349975586
Validation loss: 2.041978349288305

Epoch: 5| Step: 1
Training loss: 2.3448190689086914
Validation loss: 2.0465077608823776

Epoch: 5| Step: 2
Training loss: 1.8260889053344727
Validation loss: 2.0514084696769714

Epoch: 5| Step: 3
Training loss: 1.8544864654541016
Validation loss: 2.0536542584498725

Epoch: 5| Step: 4
Training loss: 2.1000123023986816
Validation loss: 2.063141862551371

Epoch: 5| Step: 5
Training loss: 2.2309601306915283
Validation loss: 2.052829295396805

Epoch: 5| Step: 6
Training loss: 2.35555100440979
Validation loss: 2.0669935792684555

Epoch: 5| Step: 7
Training loss: 2.677324056625366
Validation loss: 2.0620469748973846

Epoch: 5| Step: 8
Training loss: 2.212841033935547
Validation loss: 2.0528933505217233

Epoch: 5| Step: 9
Training loss: 2.457939624786377
Validation loss: 2.0567012379566827

Epoch: 5| Step: 10
Training loss: 1.6649776697158813
Validation loss: 2.0397928903500238

Epoch: 5| Step: 11
Training loss: 1.8411343097686768
Validation loss: 2.0388878931601844

Epoch: 98| Step: 0
Training loss: 2.254931926727295
Validation loss: 2.0412795742352805

Epoch: 5| Step: 1
Training loss: 2.5245144367218018
Validation loss: 2.0336921960115433

Epoch: 5| Step: 2
Training loss: 2.4315760135650635
Validation loss: 2.0342095295588174

Epoch: 5| Step: 3
Training loss: 1.9047033786773682
Validation loss: 2.0353024899959564

Epoch: 5| Step: 4
Training loss: 2.198941707611084
Validation loss: 2.042062133550644

Epoch: 5| Step: 5
Training loss: 2.183972120285034
Validation loss: 2.041237657268842

Epoch: 5| Step: 6
Training loss: 1.7433029413223267
Validation loss: 2.0444400757551193

Epoch: 5| Step: 7
Training loss: 1.796311616897583
Validation loss: 2.0381750762462616

Epoch: 5| Step: 8
Training loss: 1.8309093713760376
Validation loss: 2.0320591181516647

Epoch: 5| Step: 9
Training loss: 2.101905345916748
Validation loss: 2.0279835810263953

Epoch: 5| Step: 10
Training loss: 2.847309112548828
Validation loss: 2.0253613740205765

Epoch: 5| Step: 11
Training loss: 1.6574199199676514
Validation loss: 2.0249517957369485

Epoch: 99| Step: 0
Training loss: 1.9202874898910522
Validation loss: 2.0334666818380356

Epoch: 5| Step: 1
Training loss: 2.492842435836792
Validation loss: 2.0334193458159766

Epoch: 5| Step: 2
Training loss: 2.384052276611328
Validation loss: 2.0348821679751077

Epoch: 5| Step: 3
Training loss: 2.188328266143799
Validation loss: 2.0386984845002494

Epoch: 5| Step: 4
Training loss: 2.089104175567627
Validation loss: 2.0339667399724326

Epoch: 5| Step: 5
Training loss: 2.5639617443084717
Validation loss: 2.0350638131300607

Epoch: 5| Step: 6
Training loss: 1.7631641626358032
Validation loss: 2.0333083470662436

Epoch: 5| Step: 7
Training loss: 2.0739407539367676
Validation loss: 2.03078522781531

Epoch: 5| Step: 8
Training loss: 2.4373912811279297
Validation loss: 2.030489275852839

Epoch: 5| Step: 9
Training loss: 2.358295202255249
Validation loss: 2.028448407848676

Epoch: 5| Step: 10
Training loss: 1.619166612625122
Validation loss: 2.0320153484741845

Epoch: 5| Step: 11
Training loss: 1.8788527250289917
Validation loss: 2.036887754996618

Epoch: 100| Step: 0
Training loss: 2.2875893115997314
Validation loss: 2.039837305744489

Epoch: 5| Step: 1
Training loss: 1.886021375656128
Validation loss: 2.050412396589915

Epoch: 5| Step: 2
Training loss: 2.7739760875701904
Validation loss: 2.058472216129303

Epoch: 5| Step: 3
Training loss: 2.147444725036621
Validation loss: 2.061943610509237

Epoch: 5| Step: 4
Training loss: 2.0237739086151123
Validation loss: 2.051246548692385

Epoch: 5| Step: 5
Training loss: 2.2308242321014404
Validation loss: 2.0387469629446664

Epoch: 5| Step: 6
Training loss: 2.0324740409851074
Validation loss: 2.039601966738701

Epoch: 5| Step: 7
Training loss: 1.9032342433929443
Validation loss: 2.042698845267296

Epoch: 5| Step: 8
Training loss: 1.734147310256958
Validation loss: 2.03557259341081

Epoch: 5| Step: 9
Training loss: 2.368255138397217
Validation loss: 2.036652465661367

Epoch: 5| Step: 10
Training loss: 2.51427960395813
Validation loss: 2.0347501039505005

Epoch: 5| Step: 11
Training loss: 1.1675701141357422
Validation loss: 2.0281552175680795

Epoch: 101| Step: 0
Training loss: 2.061760425567627
Validation loss: 2.0246586253245673

Epoch: 5| Step: 1
Training loss: 2.2943832874298096
Validation loss: 2.021955798069636

Epoch: 5| Step: 2
Training loss: 2.5591580867767334
Validation loss: 2.0254658460617065

Epoch: 5| Step: 3
Training loss: 2.057626724243164
Validation loss: 2.0269738833109536

Epoch: 5| Step: 4
Training loss: 1.873884916305542
Validation loss: 2.0246895054976144

Epoch: 5| Step: 5
Training loss: 2.495230197906494
Validation loss: 2.0257286777098975

Epoch: 5| Step: 6
Training loss: 2.373805522918701
Validation loss: 2.0282285263140998

Epoch: 5| Step: 7
Training loss: 2.7226388454437256
Validation loss: 2.023256560166677

Epoch: 5| Step: 8
Training loss: 1.4122717380523682
Validation loss: 2.018676663438479

Epoch: 5| Step: 9
Training loss: 2.0213375091552734
Validation loss: 2.0241394340991974

Epoch: 5| Step: 10
Training loss: 2.1297850608825684
Validation loss: 2.0128526935974755

Epoch: 5| Step: 11
Training loss: 1.3208394050598145
Validation loss: 2.0288591533899307

Epoch: 102| Step: 0
Training loss: 2.6823782920837402
Validation loss: 2.0430512775977454

Epoch: 5| Step: 1
Training loss: 1.8981962203979492
Validation loss: 2.0487588296333947

Epoch: 5| Step: 2
Training loss: 2.6363418102264404
Validation loss: 2.0740894228219986

Epoch: 5| Step: 3
Training loss: 2.0538346767425537
Validation loss: 2.09493096669515

Epoch: 5| Step: 4
Training loss: 2.5269739627838135
Validation loss: 2.0955698092778525

Epoch: 5| Step: 5
Training loss: 1.864325761795044
Validation loss: 2.0772338211536407

Epoch: 5| Step: 6
Training loss: 1.910951852798462
Validation loss: 2.0667358338832855

Epoch: 5| Step: 7
Training loss: 1.7786756753921509
Validation loss: 2.0674252410729728

Epoch: 5| Step: 8
Training loss: 2.3599190711975098
Validation loss: 2.052878131469091

Epoch: 5| Step: 9
Training loss: 2.3818674087524414
Validation loss: 2.0401493906974792

Epoch: 5| Step: 10
Training loss: 1.976755142211914
Validation loss: 2.0387772917747498

Epoch: 5| Step: 11
Training loss: 2.0580105781555176
Validation loss: 2.022322321931521

Epoch: 103| Step: 0
Training loss: 2.3857693672180176
Validation loss: 2.013881499568621

Epoch: 5| Step: 1
Training loss: 2.4176647663116455
Validation loss: 2.0256212602059045

Epoch: 5| Step: 2
Training loss: 2.0336802005767822
Validation loss: 2.0357012500365577

Epoch: 5| Step: 3
Training loss: 2.2411396503448486
Validation loss: 2.0354022781054177

Epoch: 5| Step: 4
Training loss: 2.118028402328491
Validation loss: 2.0412558366854987

Epoch: 5| Step: 5
Training loss: 2.5344600677490234
Validation loss: 2.0420100589593253

Epoch: 5| Step: 6
Training loss: 1.922847032546997
Validation loss: 2.0356392165025077

Epoch: 5| Step: 7
Training loss: 2.186281681060791
Validation loss: 2.0401606361071267

Epoch: 5| Step: 8
Training loss: 2.539914131164551
Validation loss: 2.0344717850287757

Epoch: 5| Step: 9
Training loss: 1.7166398763656616
Validation loss: 2.033960461616516

Epoch: 5| Step: 10
Training loss: 1.801367998123169
Validation loss: 2.032109002272288

Epoch: 5| Step: 11
Training loss: 2.816771984100342
Validation loss: 2.0319139510393143

Epoch: 104| Step: 0
Training loss: 2.534649610519409
Validation loss: 2.03549254933993

Epoch: 5| Step: 1
Training loss: 2.302523612976074
Validation loss: 2.0360203782717385

Epoch: 5| Step: 2
Training loss: 2.3267219066619873
Validation loss: 2.034361407160759

Epoch: 5| Step: 3
Training loss: 2.4074456691741943
Validation loss: 2.039008393883705

Epoch: 5| Step: 4
Training loss: 2.2249741554260254
Validation loss: 2.036500871181488

Epoch: 5| Step: 5
Training loss: 2.082440137863159
Validation loss: 2.036144509911537

Epoch: 5| Step: 6
Training loss: 2.331592559814453
Validation loss: 2.0305124819278717

Epoch: 5| Step: 7
Training loss: 1.6257063150405884
Validation loss: 2.0262064586083093

Epoch: 5| Step: 8
Training loss: 2.0164363384246826
Validation loss: 2.0185658931732178

Epoch: 5| Step: 9
Training loss: 2.2687718868255615
Validation loss: 2.026459058125814

Epoch: 5| Step: 10
Training loss: 1.8030617237091064
Validation loss: 2.0366614758968353

Epoch: 5| Step: 11
Training loss: 1.3815999031066895
Validation loss: 2.05319174627463

Epoch: 105| Step: 0
Training loss: 1.585982322692871
Validation loss: 2.0570424596468606

Epoch: 5| Step: 1
Training loss: 2.5918526649475098
Validation loss: 2.06036868194739

Epoch: 5| Step: 2
Training loss: 1.7936586141586304
Validation loss: 2.059520199894905

Epoch: 5| Step: 3
Training loss: 1.8737070560455322
Validation loss: 2.0622198432683945

Epoch: 5| Step: 4
Training loss: 1.8686819076538086
Validation loss: 2.0501617987950644

Epoch: 5| Step: 5
Training loss: 1.8214441537857056
Validation loss: 2.058692827820778

Epoch: 5| Step: 6
Training loss: 2.2086145877838135
Validation loss: 2.0528028855721154

Epoch: 5| Step: 7
Training loss: 2.665309190750122
Validation loss: 2.055537854631742

Epoch: 5| Step: 8
Training loss: 2.354102373123169
Validation loss: 2.043993274370829

Epoch: 5| Step: 9
Training loss: 2.4303622245788574
Validation loss: 2.0539273023605347

Epoch: 5| Step: 10
Training loss: 2.3755829334259033
Validation loss: 2.0393056869506836

Epoch: 5| Step: 11
Training loss: 2.873420238494873
Validation loss: 2.024473840991656

Epoch: 106| Step: 0
Training loss: 1.5600011348724365
Validation loss: 2.0227944552898407

Epoch: 5| Step: 1
Training loss: 2.6206843852996826
Validation loss: 2.0303328732649484

Epoch: 5| Step: 2
Training loss: 2.5997490882873535
Validation loss: 2.0371121615171432

Epoch: 5| Step: 3
Training loss: 2.000032901763916
Validation loss: 2.045091246565183

Epoch: 5| Step: 4
Training loss: 1.984876036643982
Validation loss: 2.044203827778498

Epoch: 5| Step: 5
Training loss: 2.0986504554748535
Validation loss: 2.0391839742660522

Epoch: 5| Step: 6
Training loss: 1.9367691278457642
Validation loss: 2.0432267487049103

Epoch: 5| Step: 7
Training loss: 2.4222991466522217
Validation loss: 2.043813238541285

Epoch: 5| Step: 8
Training loss: 2.5886776447296143
Validation loss: 2.0420206437508264

Epoch: 5| Step: 9
Training loss: 2.3378241062164307
Validation loss: 2.046079099178314

Epoch: 5| Step: 10
Training loss: 1.9569648504257202
Validation loss: 2.0418410499890647

Epoch: 5| Step: 11
Training loss: 2.198392868041992
Validation loss: 2.044783736268679

Epoch: 107| Step: 0
Training loss: 2.263436794281006
Validation loss: 2.040624832113584

Epoch: 5| Step: 1
Training loss: 2.144371509552002
Validation loss: 2.0412519027789435

Epoch: 5| Step: 2
Training loss: 2.0911166667938232
Validation loss: 2.048089772462845

Epoch: 5| Step: 3
Training loss: 2.0217041969299316
Validation loss: 2.041031946738561

Epoch: 5| Step: 4
Training loss: 1.8447271585464478
Validation loss: 2.043512706955274

Epoch: 5| Step: 5
Training loss: 2.3646082878112793
Validation loss: 2.0469791342814765

Epoch: 5| Step: 6
Training loss: 2.200305938720703
Validation loss: 2.043280432621638

Epoch: 5| Step: 7
Training loss: 2.175846576690674
Validation loss: 2.0449797908465066

Epoch: 5| Step: 8
Training loss: 1.9889841079711914
Validation loss: 2.04412117600441

Epoch: 5| Step: 9
Training loss: 2.351529121398926
Validation loss: 2.0374580274025598

Epoch: 5| Step: 10
Training loss: 2.6325221061706543
Validation loss: 2.034241105119387

Epoch: 5| Step: 11
Training loss: 2.446627140045166
Validation loss: 2.0377824952205024

Epoch: 108| Step: 0
Training loss: 2.1017661094665527
Validation loss: 2.0318961292505264

Epoch: 5| Step: 1
Training loss: 2.603010892868042
Validation loss: 2.0374922901391983

Epoch: 5| Step: 2
Training loss: 1.9153636693954468
Validation loss: 2.0370503962039948

Epoch: 5| Step: 3
Training loss: 2.0240073204040527
Validation loss: 2.03115684290727

Epoch: 5| Step: 4
Training loss: 2.108273983001709
Validation loss: 2.034203583995501

Epoch: 5| Step: 5
Training loss: 1.5233075618743896
Validation loss: 2.033197576800982

Epoch: 5| Step: 6
Training loss: 2.18023419380188
Validation loss: 2.028471181790034

Epoch: 5| Step: 7
Training loss: 2.0875303745269775
Validation loss: 2.0281768987576165

Epoch: 5| Step: 8
Training loss: 1.7783544063568115
Validation loss: 2.0379187862078347

Epoch: 5| Step: 9
Training loss: 2.6634204387664795
Validation loss: 2.0536933292945228

Epoch: 5| Step: 10
Training loss: 2.536231279373169
Validation loss: 2.0455889304478965

Epoch: 5| Step: 11
Training loss: 2.239866256713867
Validation loss: 2.0533334612846375

Epoch: 109| Step: 0
Training loss: 1.6836210489273071
Validation loss: 2.04430723687013

Epoch: 5| Step: 1
Training loss: 1.7645810842514038
Validation loss: 2.0525459746519723

Epoch: 5| Step: 2
Training loss: 2.214439868927002
Validation loss: 2.047790676355362

Epoch: 5| Step: 3
Training loss: 2.0755279064178467
Validation loss: 2.0458683719237647

Epoch: 5| Step: 4
Training loss: 2.135120391845703
Validation loss: 2.0472053786118827

Epoch: 5| Step: 5
Training loss: 2.046025037765503
Validation loss: 2.0454704463481903

Epoch: 5| Step: 6
Training loss: 2.361581325531006
Validation loss: 2.035092850526174

Epoch: 5| Step: 7
Training loss: 2.219482898712158
Validation loss: 2.0382220447063446

Epoch: 5| Step: 8
Training loss: 1.9734351634979248
Validation loss: 2.0420291324456534

Epoch: 5| Step: 9
Training loss: 2.4724013805389404
Validation loss: 2.0420665442943573

Epoch: 5| Step: 10
Training loss: 2.22102427482605
Validation loss: 2.0453232526779175

Epoch: 5| Step: 11
Training loss: 3.7973666191101074
Validation loss: 2.0372490833202996

Epoch: 110| Step: 0
Training loss: 2.0174877643585205
Validation loss: 2.037345384558042

Epoch: 5| Step: 1
Training loss: 2.293271780014038
Validation loss: 2.038389022151629

Epoch: 5| Step: 2
Training loss: 1.7904449701309204
Validation loss: 2.0316726664702096

Epoch: 5| Step: 3
Training loss: 1.4703376293182373
Validation loss: 2.0412246187527976

Epoch: 5| Step: 4
Training loss: 2.244811534881592
Validation loss: 2.0462972869475684

Epoch: 5| Step: 5
Training loss: 2.730360746383667
Validation loss: 2.0418684581915536

Epoch: 5| Step: 6
Training loss: 2.1455307006835938
Validation loss: 2.0443389117717743

Epoch: 5| Step: 7
Training loss: 2.2208640575408936
Validation loss: 2.0372222860654197

Epoch: 5| Step: 8
Training loss: 3.0263524055480957
Validation loss: 2.0386374294757843

Epoch: 5| Step: 9
Training loss: 2.1849517822265625
Validation loss: 2.034960925579071

Epoch: 5| Step: 10
Training loss: 1.6141560077667236
Validation loss: 2.037361075480779

Epoch: 5| Step: 11
Training loss: 1.428195595741272
Validation loss: 2.040459558367729

Epoch: 111| Step: 0
Training loss: 2.324577569961548
Validation loss: 2.028685306509336

Epoch: 5| Step: 1
Training loss: 1.886322259902954
Validation loss: 2.0299200216929116

Epoch: 5| Step: 2
Training loss: 2.3462650775909424
Validation loss: 2.02616810798645

Epoch: 5| Step: 3
Training loss: 2.1353964805603027
Validation loss: 2.0259645332892737

Epoch: 5| Step: 4
Training loss: 1.9201533794403076
Validation loss: 2.031954954067866

Epoch: 5| Step: 5
Training loss: 2.355985164642334
Validation loss: 2.029100075364113

Epoch: 5| Step: 6
Training loss: 1.909848928451538
Validation loss: 2.034878840049108

Epoch: 5| Step: 7
Training loss: 2.2881767749786377
Validation loss: 2.0590364982684455

Epoch: 5| Step: 8
Training loss: 2.1531002521514893
Validation loss: 2.0533150931199393

Epoch: 5| Step: 9
Training loss: 2.106714963912964
Validation loss: 2.0483300487200418

Epoch: 5| Step: 10
Training loss: 2.244349241256714
Validation loss: 2.040151839454969

Epoch: 5| Step: 11
Training loss: 1.8024555444717407
Validation loss: 2.0473591486612954

Epoch: 112| Step: 0
Training loss: 1.8608417510986328
Validation loss: 2.045576040943464

Epoch: 5| Step: 1
Training loss: 2.2810120582580566
Validation loss: 2.0494345823923745

Epoch: 5| Step: 2
Training loss: 2.4983272552490234
Validation loss: 2.025650441646576

Epoch: 5| Step: 3
Training loss: 2.083796977996826
Validation loss: 2.0277042438586554

Epoch: 5| Step: 4
Training loss: 2.073690891265869
Validation loss: 2.029957816004753

Epoch: 5| Step: 5
Training loss: 2.3117001056671143
Validation loss: 2.0298735797405243

Epoch: 5| Step: 6
Training loss: 1.8322826623916626
Validation loss: 2.026615490516027

Epoch: 5| Step: 7
Training loss: 2.297063112258911
Validation loss: 2.0290914376576743

Epoch: 5| Step: 8
Training loss: 2.1399242877960205
Validation loss: 2.033936565121015

Epoch: 5| Step: 9
Training loss: 1.6860382556915283
Validation loss: 2.039393275976181

Epoch: 5| Step: 10
Training loss: 2.2014031410217285
Validation loss: 2.0405832330385842

Epoch: 5| Step: 11
Training loss: 3.4081263542175293
Validation loss: 2.047732934355736

Epoch: 113| Step: 0
Training loss: 2.1553292274475098
Validation loss: 2.041345089673996

Epoch: 5| Step: 1
Training loss: 1.7542006969451904
Validation loss: 2.0514417787392936

Epoch: 5| Step: 2
Training loss: 2.1256537437438965
Validation loss: 2.0503604660431543

Epoch: 5| Step: 3
Training loss: 2.2065720558166504
Validation loss: 2.0658790469169617

Epoch: 5| Step: 4
Training loss: 2.0271527767181396
Validation loss: 2.0555166949828467

Epoch: 5| Step: 5
Training loss: 1.592548131942749
Validation loss: 2.0423713773489

Epoch: 5| Step: 6
Training loss: 2.094726085662842
Validation loss: 2.0545238902171454

Epoch: 5| Step: 7
Training loss: 2.3349273204803467
Validation loss: 2.0379909723997116

Epoch: 5| Step: 8
Training loss: 2.2384917736053467
Validation loss: 2.0343225648005805

Epoch: 5| Step: 9
Training loss: 2.4393184185028076
Validation loss: 2.032693848013878

Epoch: 5| Step: 10
Training loss: 2.4768006801605225
Validation loss: 2.0258222818374634

Epoch: 5| Step: 11
Training loss: 1.9434610605239868
Validation loss: 2.0277547190586724

Epoch: 114| Step: 0
Training loss: 2.218301296234131
Validation loss: 2.036990776658058

Epoch: 5| Step: 1
Training loss: 1.7986841201782227
Validation loss: 2.0315691779057183

Epoch: 5| Step: 2
Training loss: 1.9013307094573975
Validation loss: 2.031229794025421

Epoch: 5| Step: 3
Training loss: 2.0017471313476562
Validation loss: 2.0329351127147675

Epoch: 5| Step: 4
Training loss: 2.306121826171875
Validation loss: 2.0349436650673547

Epoch: 5| Step: 5
Training loss: 2.0591113567352295
Validation loss: 2.038241739074389

Epoch: 5| Step: 6
Training loss: 2.5822412967681885
Validation loss: 2.0394668032725654

Epoch: 5| Step: 7
Training loss: 1.8108774423599243
Validation loss: 2.0350861052672067

Epoch: 5| Step: 8
Training loss: 2.3199501037597656
Validation loss: 2.0400744527578354

Epoch: 5| Step: 9
Training loss: 2.286472797393799
Validation loss: 2.0350628743569055

Epoch: 5| Step: 10
Training loss: 2.193376064300537
Validation loss: 2.038202474514643

Epoch: 5| Step: 11
Training loss: 2.059291362762451
Validation loss: 2.0435209572315216

Epoch: 115| Step: 0
Training loss: 1.8077309131622314
Validation loss: 2.0466129928827286

Epoch: 5| Step: 1
Training loss: 2.134193181991577
Validation loss: 2.0418872833251953

Epoch: 5| Step: 2
Training loss: 2.102132797241211
Validation loss: 2.0517113705476127

Epoch: 5| Step: 3
Training loss: 2.3855369091033936
Validation loss: 2.0468583554029465

Epoch: 5| Step: 4
Training loss: 2.0706446170806885
Validation loss: 2.0553171038627625

Epoch: 5| Step: 5
Training loss: 1.973369836807251
Validation loss: 2.051328515013059

Epoch: 5| Step: 6
Training loss: 2.355142116546631
Validation loss: 2.048522094885508

Epoch: 5| Step: 7
Training loss: 2.8869519233703613
Validation loss: 2.03763248026371

Epoch: 5| Step: 8
Training loss: 1.4381935596466064
Validation loss: 2.047188460826874

Epoch: 5| Step: 9
Training loss: 2.394181489944458
Validation loss: 2.0382525573174157

Epoch: 5| Step: 10
Training loss: 2.026824951171875
Validation loss: 2.0299060940742493

Epoch: 5| Step: 11
Training loss: 2.152036428451538
Validation loss: 2.027158955732981

Epoch: 116| Step: 0
Training loss: 2.1351208686828613
Validation loss: 2.024956693251928

Epoch: 5| Step: 1
Training loss: 2.061305046081543
Validation loss: 2.028824200232824

Epoch: 5| Step: 2
Training loss: 1.3312174081802368
Validation loss: 2.0290394127368927

Epoch: 5| Step: 3
Training loss: 2.4419217109680176
Validation loss: 2.0325733522574105

Epoch: 5| Step: 4
Training loss: 2.33003306388855
Validation loss: 2.040502925713857

Epoch: 5| Step: 5
Training loss: 2.2453410625457764
Validation loss: 2.043834393223127

Epoch: 5| Step: 6
Training loss: 2.7343010902404785
Validation loss: 2.0385977228482566

Epoch: 5| Step: 7
Training loss: 2.223740339279175
Validation loss: 2.0591083268324533

Epoch: 5| Step: 8
Training loss: 1.9069633483886719
Validation loss: 2.050036902228991

Epoch: 5| Step: 9
Training loss: 2.150712728500366
Validation loss: 2.0494857082764306

Epoch: 5| Step: 10
Training loss: 2.1037325859069824
Validation loss: 2.0401478757460914

Epoch: 5| Step: 11
Training loss: 1.9560520648956299
Validation loss: 2.0410437236229577

Epoch: 117| Step: 0
Training loss: 2.5132434368133545
Validation loss: 2.0329523930946984

Epoch: 5| Step: 1
Training loss: 2.1016454696655273
Validation loss: 2.031596024831136

Epoch: 5| Step: 2
Training loss: 2.082340955734253
Validation loss: 2.0443618992964425

Epoch: 5| Step: 3
Training loss: 2.0313591957092285
Validation loss: 2.033017118771871

Epoch: 5| Step: 4
Training loss: 1.8773517608642578
Validation loss: 2.035540521144867

Epoch: 5| Step: 5
Training loss: 1.8212368488311768
Validation loss: 2.0278769433498383

Epoch: 5| Step: 6
Training loss: 2.3332018852233887
Validation loss: 2.0297472973664603

Epoch: 5| Step: 7
Training loss: 1.9995126724243164
Validation loss: 2.0256187170743942

Epoch: 5| Step: 8
Training loss: 2.6852524280548096
Validation loss: 2.034742161631584

Epoch: 5| Step: 9
Training loss: 2.666172504425049
Validation loss: 2.018863985935847

Epoch: 5| Step: 10
Training loss: 1.5971325635910034
Validation loss: 2.0229522436857224

Epoch: 5| Step: 11
Training loss: 1.3689450025558472
Validation loss: 2.025229369600614

Epoch: 118| Step: 0
Training loss: 2.102579355239868
Validation loss: 2.0329371094703674

Epoch: 5| Step: 1
Training loss: 2.280971050262451
Validation loss: 2.0306881815195084

Epoch: 5| Step: 2
Training loss: 3.0842137336730957
Validation loss: 2.025582586725553

Epoch: 5| Step: 3
Training loss: 1.370413064956665
Validation loss: 2.0246322005987167

Epoch: 5| Step: 4
Training loss: 2.1791553497314453
Validation loss: 2.031836122274399

Epoch: 5| Step: 5
Training loss: 2.3913321495056152
Validation loss: 2.0229570666948953

Epoch: 5| Step: 6
Training loss: 1.7873163223266602
Validation loss: 2.0295593043168387

Epoch: 5| Step: 7
Training loss: 2.41253399848938
Validation loss: 2.0379759718974433

Epoch: 5| Step: 8
Training loss: 1.8639862537384033
Validation loss: 2.0372208952903748

Epoch: 5| Step: 9
Training loss: 2.0153777599334717
Validation loss: 2.0385898500680923

Epoch: 5| Step: 10
Training loss: 2.1845433712005615
Validation loss: 2.0420952488978705

Epoch: 5| Step: 11
Training loss: 1.415773868560791
Validation loss: 2.0373467008272805

Epoch: 119| Step: 0
Training loss: 2.036208391189575
Validation loss: 2.05214424431324

Epoch: 5| Step: 1
Training loss: 2.6025233268737793
Validation loss: 2.057462985316912

Epoch: 5| Step: 2
Training loss: 2.2984139919281006
Validation loss: 2.060650775829951

Epoch: 5| Step: 3
Training loss: 1.7875983715057373
Validation loss: 2.060938040415446

Epoch: 5| Step: 4
Training loss: 2.0904700756073
Validation loss: 2.0624762574831643

Epoch: 5| Step: 5
Training loss: 2.6982719898223877
Validation loss: 2.072087506453196

Epoch: 5| Step: 6
Training loss: 2.6693451404571533
Validation loss: 2.0584075649579368

Epoch: 5| Step: 7
Training loss: 1.9380314350128174
Validation loss: 2.060009643435478

Epoch: 5| Step: 8
Training loss: 1.4731104373931885
Validation loss: 2.0606722633043923

Epoch: 5| Step: 9
Training loss: 2.0215904712677
Validation loss: 2.050225724776586

Epoch: 5| Step: 10
Training loss: 1.9274547100067139
Validation loss: 2.048369084795316

Epoch: 5| Step: 11
Training loss: 2.9092419147491455
Validation loss: 2.0504113038380942

Epoch: 120| Step: 0
Training loss: 2.324531078338623
Validation loss: 2.0295582761367164

Epoch: 5| Step: 1
Training loss: 2.0984065532684326
Validation loss: 2.026400292913119

Epoch: 5| Step: 2
Training loss: 2.5445003509521484
Validation loss: 2.025652219851812

Epoch: 5| Step: 3
Training loss: 1.899725317955017
Validation loss: 2.026134803891182

Epoch: 5| Step: 4
Training loss: 2.020853042602539
Validation loss: 2.0301005840301514

Epoch: 5| Step: 5
Training loss: 2.180845022201538
Validation loss: 2.0307932843764624

Epoch: 5| Step: 6
Training loss: 2.1049702167510986
Validation loss: 2.036568601926168

Epoch: 5| Step: 7
Training loss: 2.4850449562072754
Validation loss: 2.0273280143737793

Epoch: 5| Step: 8
Training loss: 2.0586161613464355
Validation loss: 2.0304603377978006

Epoch: 5| Step: 9
Training loss: 2.1226882934570312
Validation loss: 2.018849551677704

Epoch: 5| Step: 10
Training loss: 2.064833879470825
Validation loss: 2.020663862427076

Epoch: 5| Step: 11
Training loss: 1.0751264095306396
Validation loss: 2.033936987320582

Epoch: 121| Step: 0
Training loss: 2.125216007232666
Validation loss: 2.034049481153488

Epoch: 5| Step: 1
Training loss: 1.9277870655059814
Validation loss: 2.034753312667211

Epoch: 5| Step: 2
Training loss: 1.8204097747802734
Validation loss: 2.0326321919759116

Epoch: 5| Step: 3
Training loss: 2.2751269340515137
Validation loss: 2.0371994574864707

Epoch: 5| Step: 4
Training loss: 2.625749349594116
Validation loss: 2.027360444267591

Epoch: 5| Step: 5
Training loss: 1.9163825511932373
Validation loss: 2.032790939013163

Epoch: 5| Step: 6
Training loss: 1.8142292499542236
Validation loss: 2.0283308029174805

Epoch: 5| Step: 7
Training loss: 2.3927152156829834
Validation loss: 2.033957779407501

Epoch: 5| Step: 8
Training loss: 2.1202569007873535
Validation loss: 2.033621519804001

Epoch: 5| Step: 9
Training loss: 2.358241558074951
Validation loss: 2.0413918197155

Epoch: 5| Step: 10
Training loss: 2.377708911895752
Validation loss: 2.044078772266706

Epoch: 5| Step: 11
Training loss: 0.8293888568878174
Validation loss: 2.049830973148346

Epoch: 122| Step: 0
Training loss: 1.790357232093811
Validation loss: 2.0549924075603485

Epoch: 5| Step: 1
Training loss: 2.44978404045105
Validation loss: 2.049589842557907

Epoch: 5| Step: 2
Training loss: 1.5762344598770142
Validation loss: 2.05074114104112

Epoch: 5| Step: 3
Training loss: 2.3870508670806885
Validation loss: 2.056675468881925

Epoch: 5| Step: 4
Training loss: 1.4515894651412964
Validation loss: 2.060686101516088

Epoch: 5| Step: 5
Training loss: 1.6920585632324219
Validation loss: 2.0576951255400977

Epoch: 5| Step: 6
Training loss: 2.7663421630859375
Validation loss: 2.0695764819780984

Epoch: 5| Step: 7
Training loss: 2.3616178035736084
Validation loss: 2.060648669799169

Epoch: 5| Step: 8
Training loss: 2.905059337615967
Validation loss: 2.0499625454346337

Epoch: 5| Step: 9
Training loss: 1.996116042137146
Validation loss: 2.0441388686498008

Epoch: 5| Step: 10
Training loss: 2.2532734870910645
Validation loss: 2.0375804801781974

Epoch: 5| Step: 11
Training loss: 2.5766525268554688
Validation loss: 2.0513953963915506

Epoch: 123| Step: 0
Training loss: 2.264376163482666
Validation loss: 2.033370385567347

Epoch: 5| Step: 1
Training loss: 1.8750044107437134
Validation loss: 2.0250002245108285

Epoch: 5| Step: 2
Training loss: 2.0185725688934326
Validation loss: 2.036855712532997

Epoch: 5| Step: 3
Training loss: 1.7360103130340576
Validation loss: 2.047752797603607

Epoch: 5| Step: 4
Training loss: 2.075946092605591
Validation loss: 2.0467620541652045

Epoch: 5| Step: 5
Training loss: 2.1775600910186768
Validation loss: 2.0460434009631476

Epoch: 5| Step: 6
Training loss: 2.1932625770568848
Validation loss: 2.043379843235016

Epoch: 5| Step: 7
Training loss: 2.574477434158325
Validation loss: 2.0444657653570175

Epoch: 5| Step: 8
Training loss: 2.3239409923553467
Validation loss: 2.043779879808426

Epoch: 5| Step: 9
Training loss: 2.4594368934631348
Validation loss: 2.0395876367886863

Epoch: 5| Step: 10
Training loss: 2.2037758827209473
Validation loss: 2.044037769238154

Epoch: 5| Step: 11
Training loss: 1.8505613803863525
Validation loss: 2.0388587961594262

Epoch: 124| Step: 0
Training loss: 2.3363888263702393
Validation loss: 2.038286214073499

Epoch: 5| Step: 1
Training loss: 1.9471065998077393
Validation loss: 2.039719745516777

Epoch: 5| Step: 2
Training loss: 2.3538172245025635
Validation loss: 2.043499062458674

Epoch: 5| Step: 3
Training loss: 1.9580316543579102
Validation loss: 2.034555812676748

Epoch: 5| Step: 4
Training loss: 1.6718432903289795
Validation loss: 2.0443623811006546

Epoch: 5| Step: 5
Training loss: 2.033491611480713
Validation loss: 2.0409304797649384

Epoch: 5| Step: 6
Training loss: 2.6395764350891113
Validation loss: 2.035646061102549

Epoch: 5| Step: 7
Training loss: 2.6825830936431885
Validation loss: 2.0390038043260574

Epoch: 5| Step: 8
Training loss: 1.9837958812713623
Validation loss: 2.0396881252527237

Epoch: 5| Step: 9
Training loss: 2.0024800300598145
Validation loss: 2.0404101411501565

Epoch: 5| Step: 10
Training loss: 2.1108696460723877
Validation loss: 2.034818410873413

Epoch: 5| Step: 11
Training loss: 3.6220364570617676
Validation loss: 2.0313212871551514

Epoch: 125| Step: 0
Training loss: 2.222001791000366
Validation loss: 2.0255376597245536

Epoch: 5| Step: 1
Training loss: 1.7915675640106201
Validation loss: 2.031033933162689

Epoch: 5| Step: 2
Training loss: 2.127229690551758
Validation loss: 2.040080572168032

Epoch: 5| Step: 3
Training loss: 2.2059531211853027
Validation loss: 2.03384696940581

Epoch: 5| Step: 4
Training loss: 2.298840045928955
Validation loss: 2.0391571521759033

Epoch: 5| Step: 5
Training loss: 1.780011534690857
Validation loss: 2.044412682453791

Epoch: 5| Step: 6
Training loss: 2.425490617752075
Validation loss: 2.0371812035640082

Epoch: 5| Step: 7
Training loss: 1.6555246114730835
Validation loss: 2.0332358926534653

Epoch: 5| Step: 8
Training loss: 2.640733003616333
Validation loss: 2.0362695852915444

Epoch: 5| Step: 9
Training loss: 2.4205265045166016
Validation loss: 2.0444202770789466

Epoch: 5| Step: 10
Training loss: 2.021963596343994
Validation loss: 2.0408136943976083

Epoch: 5| Step: 11
Training loss: 1.714335322380066
Validation loss: 2.034035931030909

Epoch: 126| Step: 0
Training loss: 1.5767309665679932
Validation loss: 2.0329279601573944

Epoch: 5| Step: 1
Training loss: 2.2657923698425293
Validation loss: 2.0168435672918954

Epoch: 5| Step: 2
Training loss: 2.068695545196533
Validation loss: 2.0201240479946136

Epoch: 5| Step: 3
Training loss: 2.3636116981506348
Validation loss: 2.019547333319982

Epoch: 5| Step: 4
Training loss: 1.9933717250823975
Validation loss: 2.0232030749320984

Epoch: 5| Step: 5
Training loss: 2.3234403133392334
Validation loss: 2.033925339579582

Epoch: 5| Step: 6
Training loss: 2.120318651199341
Validation loss: 2.034548888603846

Epoch: 5| Step: 7
Training loss: 2.2614526748657227
Validation loss: 2.0449203848838806

Epoch: 5| Step: 8
Training loss: 2.32983660697937
Validation loss: 2.041247089703878

Epoch: 5| Step: 9
Training loss: 2.04878830909729
Validation loss: 2.0411973893642426

Epoch: 5| Step: 10
Training loss: 2.147859811782837
Validation loss: 2.0382951349020004

Epoch: 5| Step: 11
Training loss: 2.6520516872406006
Validation loss: 2.0438656906286874

Epoch: 127| Step: 0
Training loss: 2.7022154331207275
Validation loss: 2.0402163565158844

Epoch: 5| Step: 1
Training loss: 1.644608736038208
Validation loss: 2.0343164751927056

Epoch: 5| Step: 2
Training loss: 2.2446675300598145
Validation loss: 2.0378196835517883

Epoch: 5| Step: 3
Training loss: 1.8693010807037354
Validation loss: 2.0298671474059424

Epoch: 5| Step: 4
Training loss: 2.387457847595215
Validation loss: 2.0336992343266806

Epoch: 5| Step: 5
Training loss: 2.0073819160461426
Validation loss: 2.032592698931694

Epoch: 5| Step: 6
Training loss: 2.261693239212036
Validation loss: 2.0370210160811744

Epoch: 5| Step: 7
Training loss: 2.0400426387786865
Validation loss: 2.0381546864906945

Epoch: 5| Step: 8
Training loss: 2.0507776737213135
Validation loss: 2.0466971496740975

Epoch: 5| Step: 9
Training loss: 2.202493190765381
Validation loss: 2.054938385883967

Epoch: 5| Step: 10
Training loss: 2.0039286613464355
Validation loss: 2.0538427929083505

Epoch: 5| Step: 11
Training loss: 2.0264482498168945
Validation loss: 2.0641096780697503

Epoch: 128| Step: 0
Training loss: 1.9799747467041016
Validation loss: 2.066770354906718

Epoch: 5| Step: 1
Training loss: 2.5556559562683105
Validation loss: 2.045821785926819

Epoch: 5| Step: 2
Training loss: 2.8375697135925293
Validation loss: 2.05520794292291

Epoch: 5| Step: 3
Training loss: 1.8595035076141357
Validation loss: 2.039160539706548

Epoch: 5| Step: 4
Training loss: 2.361971616744995
Validation loss: 2.0462270925442376

Epoch: 5| Step: 5
Training loss: 1.7971843481063843
Validation loss: 2.0524416863918304

Epoch: 5| Step: 6
Training loss: 2.4197206497192383
Validation loss: 2.046377196907997

Epoch: 5| Step: 7
Training loss: 1.6767027378082275
Validation loss: 2.0416431923707328

Epoch: 5| Step: 8
Training loss: 1.8572323322296143
Validation loss: 2.0451561212539673

Epoch: 5| Step: 9
Training loss: 2.256526470184326
Validation loss: 2.0453194926182428

Epoch: 5| Step: 10
Training loss: 1.9102706909179688
Validation loss: 2.0404168566068015

Epoch: 5| Step: 11
Training loss: 1.6949101686477661
Validation loss: 2.0368466128905616

Epoch: 129| Step: 0
Training loss: 1.8674147129058838
Validation loss: 2.0460353940725327

Epoch: 5| Step: 1
Training loss: 2.304262638092041
Validation loss: 2.042116885383924

Epoch: 5| Step: 2
Training loss: 2.768437385559082
Validation loss: 2.0392966270446777

Epoch: 5| Step: 3
Training loss: 2.2546098232269287
Validation loss: 2.045982221762339

Epoch: 5| Step: 4
Training loss: 2.595193386077881
Validation loss: 2.0368808954954147

Epoch: 5| Step: 5
Training loss: 1.4991493225097656
Validation loss: 2.040908098220825

Epoch: 5| Step: 6
Training loss: 1.6807870864868164
Validation loss: 2.037255267302195

Epoch: 5| Step: 7
Training loss: 1.9986250400543213
Validation loss: 2.0519487410783768

Epoch: 5| Step: 8
Training loss: 2.354492425918579
Validation loss: 2.0513191372156143

Epoch: 5| Step: 9
Training loss: 2.0437703132629395
Validation loss: 2.056032677491506

Epoch: 5| Step: 10
Training loss: 2.0474932193756104
Validation loss: 2.039247219761213

Epoch: 5| Step: 11
Training loss: 2.071645736694336
Validation loss: 2.057206869125366

Epoch: 130| Step: 0
Training loss: 2.2467119693756104
Validation loss: 2.0431823134422302

Epoch: 5| Step: 1
Training loss: 1.9803663492202759
Validation loss: 2.0477237751086554

Epoch: 5| Step: 2
Training loss: 1.8906900882720947
Validation loss: 2.049465705951055

Epoch: 5| Step: 3
Training loss: 2.178685188293457
Validation loss: 2.050294334689776

Epoch: 5| Step: 4
Training loss: 2.2420880794525146
Validation loss: 2.0462644398212433

Epoch: 5| Step: 5
Training loss: 1.9054450988769531
Validation loss: 2.0431254158417382

Epoch: 5| Step: 6
Training loss: 2.2172977924346924
Validation loss: 2.050344462196032

Epoch: 5| Step: 7
Training loss: 2.5116617679595947
Validation loss: 2.0445940792560577

Epoch: 5| Step: 8
Training loss: 1.9867076873779297
Validation loss: 2.0492667108774185

Epoch: 5| Step: 9
Training loss: 2.4779598712921143
Validation loss: 2.043919305006663

Epoch: 5| Step: 10
Training loss: 1.8137800693511963
Validation loss: 2.046949644883474

Epoch: 5| Step: 11
Training loss: 2.276808261871338
Validation loss: 2.0365308423837027

Epoch: 131| Step: 0
Training loss: 2.0937678813934326
Validation loss: 2.047964404026667

Epoch: 5| Step: 1
Training loss: 2.447875499725342
Validation loss: 2.034660895665487

Epoch: 5| Step: 2
Training loss: 2.8142144680023193
Validation loss: 2.0393900771935782

Epoch: 5| Step: 3
Training loss: 1.953125
Validation loss: 2.0303898404041925

Epoch: 5| Step: 4
Training loss: 1.9750804901123047
Validation loss: 2.0318265507618585

Epoch: 5| Step: 5
Training loss: 1.657637596130371
Validation loss: 2.0366997569799423

Epoch: 5| Step: 6
Training loss: 2.3247592449188232
Validation loss: 2.042985593279203

Epoch: 5| Step: 7
Training loss: 1.8009264469146729
Validation loss: 2.041430031259855

Epoch: 5| Step: 8
Training loss: 2.1846582889556885
Validation loss: 2.0396316051483154

Epoch: 5| Step: 9
Training loss: 2.4499258995056152
Validation loss: 2.0445527086655297

Epoch: 5| Step: 10
Training loss: 1.643851637840271
Validation loss: 2.045791064699491

Epoch: 5| Step: 11
Training loss: 2.1880505084991455
Validation loss: 2.056488205989202

Epoch: 132| Step: 0
Training loss: 2.0886828899383545
Validation loss: 2.04801078637441

Epoch: 5| Step: 1
Training loss: 2.1623916625976562
Validation loss: 2.044148380557696

Epoch: 5| Step: 2
Training loss: 2.134124279022217
Validation loss: 2.0432763497034707

Epoch: 5| Step: 3
Training loss: 1.984810471534729
Validation loss: 2.0378927936156592

Epoch: 5| Step: 4
Training loss: 1.7449004650115967
Validation loss: 2.040764103333155

Epoch: 5| Step: 5
Training loss: 2.8556067943573
Validation loss: 2.041984885931015

Epoch: 5| Step: 6
Training loss: 2.197875499725342
Validation loss: 2.045900901158651

Epoch: 5| Step: 7
Training loss: 2.101102590560913
Validation loss: 2.047444681326548

Epoch: 5| Step: 8
Training loss: 2.183096408843994
Validation loss: 2.0380176454782486

Epoch: 5| Step: 9
Training loss: 1.856536865234375
Validation loss: 2.0482391019662223

Epoch: 5| Step: 10
Training loss: 1.8977272510528564
Validation loss: 2.0421872983376184

Epoch: 5| Step: 11
Training loss: 2.2299752235412598
Validation loss: 2.044661909341812

Epoch: 133| Step: 0
Training loss: 1.9376285076141357
Validation loss: 2.043763260046641

Epoch: 5| Step: 1
Training loss: 2.3378677368164062
Validation loss: 2.046660224596659

Epoch: 5| Step: 2
Training loss: 2.1406636238098145
Validation loss: 2.0553282648324966

Epoch: 5| Step: 3
Training loss: 2.4205029010772705
Validation loss: 2.044487252831459

Epoch: 5| Step: 4
Training loss: 1.877454400062561
Validation loss: 2.0476863980293274

Epoch: 5| Step: 5
Training loss: 2.048504114151001
Validation loss: 2.0454453279574714

Epoch: 5| Step: 6
Training loss: 2.6714134216308594
Validation loss: 2.0545645505189896

Epoch: 5| Step: 7
Training loss: 2.1433300971984863
Validation loss: 2.0449636777242026

Epoch: 5| Step: 8
Training loss: 1.7195284366607666
Validation loss: 2.0449747989575067

Epoch: 5| Step: 9
Training loss: 1.783434271812439
Validation loss: 2.043059711654981

Epoch: 5| Step: 10
Training loss: 2.1668667793273926
Validation loss: 2.042159760991732

Epoch: 5| Step: 11
Training loss: 2.441819906234741
Validation loss: 2.032974953452746

Epoch: 134| Step: 0
Training loss: 2.3084981441497803
Validation loss: 2.0237135936816535

Epoch: 5| Step: 1
Training loss: 2.2290425300598145
Validation loss: 2.024757424990336

Epoch: 5| Step: 2
Training loss: 2.3229548931121826
Validation loss: 2.0291326542695365

Epoch: 5| Step: 3
Training loss: 2.5355772972106934
Validation loss: 2.030740479628245

Epoch: 5| Step: 4
Training loss: 2.037245512008667
Validation loss: 2.0223057021697364

Epoch: 5| Step: 5
Training loss: 2.4492435455322266
Validation loss: 2.0196687479813895

Epoch: 5| Step: 6
Training loss: 1.967947006225586
Validation loss: 2.0206234653790793

Epoch: 5| Step: 7
Training loss: 1.7297579050064087
Validation loss: 2.0167156904935837

Epoch: 5| Step: 8
Training loss: 1.7675926685333252
Validation loss: 2.016794110337893

Epoch: 5| Step: 9
Training loss: 2.634314775466919
Validation loss: 2.020353545745214

Epoch: 5| Step: 10
Training loss: 1.5840060710906982
Validation loss: 2.023685226837794

Epoch: 5| Step: 11
Training loss: 1.579789161682129
Validation loss: 2.036841298143069

Epoch: 135| Step: 0
Training loss: 2.211080551147461
Validation loss: 2.039332459370295

Epoch: 5| Step: 1
Training loss: 2.48793625831604
Validation loss: 2.0361728221178055

Epoch: 5| Step: 2
Training loss: 1.993640661239624
Validation loss: 2.0418802400430045

Epoch: 5| Step: 3
Training loss: 2.0411524772644043
Validation loss: 2.031121631463369

Epoch: 5| Step: 4
Training loss: 2.776641368865967
Validation loss: 2.025833010673523

Epoch: 5| Step: 5
Training loss: 2.394909381866455
Validation loss: 2.03261170287927

Epoch: 5| Step: 6
Training loss: 2.1828696727752686
Validation loss: 2.0339277237653732

Epoch: 5| Step: 7
Training loss: 1.7847719192504883
Validation loss: 2.0244891941547394

Epoch: 5| Step: 8
Training loss: 1.723198652267456
Validation loss: 2.0234924455483756

Epoch: 5| Step: 9
Training loss: 1.9593126773834229
Validation loss: 2.027278716365496

Epoch: 5| Step: 10
Training loss: 1.7725242376327515
Validation loss: 2.0329831540584564

Epoch: 5| Step: 11
Training loss: 2.1790719032287598
Validation loss: 2.035004029671351

Epoch: 136| Step: 0
Training loss: 2.378342628479004
Validation loss: 2.0397718201080957

Epoch: 5| Step: 1
Training loss: 2.6126201152801514
Validation loss: 2.0504174133141837

Epoch: 5| Step: 2
Training loss: 1.7031593322753906
Validation loss: 2.0480785419543586

Epoch: 5| Step: 3
Training loss: 2.2902469635009766
Validation loss: 2.057210683822632

Epoch: 5| Step: 4
Training loss: 2.203165292739868
Validation loss: 2.0837810933589935

Epoch: 5| Step: 5
Training loss: 1.9323838949203491
Validation loss: 2.092029874523481

Epoch: 5| Step: 6
Training loss: 2.1494827270507812
Validation loss: 2.0766209264596305

Epoch: 5| Step: 7
Training loss: 2.572258710861206
Validation loss: 2.0661989053090415

Epoch: 5| Step: 8
Training loss: 2.041991710662842
Validation loss: 2.054240360856056

Epoch: 5| Step: 9
Training loss: 2.0361196994781494
Validation loss: 2.0502479573090873

Epoch: 5| Step: 10
Training loss: 1.9616107940673828
Validation loss: 2.0521846264600754

Epoch: 5| Step: 11
Training loss: 0.8062970638275146
Validation loss: 2.0470664302508035

Epoch: 137| Step: 0
Training loss: 1.9052674770355225
Validation loss: 2.023832360903422

Epoch: 5| Step: 1
Training loss: 2.5612354278564453
Validation loss: 2.033936023712158

Epoch: 5| Step: 2
Training loss: 2.3089442253112793
Validation loss: 2.040787011384964

Epoch: 5| Step: 3
Training loss: 2.617234706878662
Validation loss: 2.0336525042851767

Epoch: 5| Step: 4
Training loss: 2.1092991828918457
Validation loss: 2.0419260064760842

Epoch: 5| Step: 5
Training loss: 1.7012431621551514
Validation loss: 2.039318487048149

Epoch: 5| Step: 6
Training loss: 1.849855661392212
Validation loss: 2.0382660975058875

Epoch: 5| Step: 7
Training loss: 2.1628174781799316
Validation loss: 2.0319660703341165

Epoch: 5| Step: 8
Training loss: 2.425851345062256
Validation loss: 2.036469722787539

Epoch: 5| Step: 9
Training loss: 2.174776792526245
Validation loss: 2.0302855720122657

Epoch: 5| Step: 10
Training loss: 1.8618967533111572
Validation loss: 2.0356394002834954

Epoch: 5| Step: 11
Training loss: 2.546027183532715
Validation loss: 2.033677955468496

Epoch: 138| Step: 0
Training loss: 2.2664237022399902
Validation loss: 2.0334565540154776

Epoch: 5| Step: 1
Training loss: 1.5715553760528564
Validation loss: 2.03024190167586

Epoch: 5| Step: 2
Training loss: 2.963567018508911
Validation loss: 2.039191111922264

Epoch: 5| Step: 3
Training loss: 2.0196409225463867
Validation loss: 2.0403721034526825

Epoch: 5| Step: 4
Training loss: 2.0666255950927734
Validation loss: 2.034033844868342

Epoch: 5| Step: 5
Training loss: 1.9337230920791626
Validation loss: 2.034482608238856

Epoch: 5| Step: 6
Training loss: 2.0575671195983887
Validation loss: 2.0336932937304177

Epoch: 5| Step: 7
Training loss: 2.3921430110931396
Validation loss: 2.0414580951134362

Epoch: 5| Step: 8
Training loss: 1.9991962909698486
Validation loss: 2.052061294515928

Epoch: 5| Step: 9
Training loss: 1.9127296209335327
Validation loss: 2.0461337516705194

Epoch: 5| Step: 10
Training loss: 2.442077398300171
Validation loss: 2.049154515067736

Epoch: 5| Step: 11
Training loss: 1.8402546644210815
Validation loss: 2.0479167997837067

Epoch: 139| Step: 0
Training loss: 2.1570351123809814
Validation loss: 2.0521459629138312

Epoch: 5| Step: 1
Training loss: 2.0615029335021973
Validation loss: 2.0496437748273215

Epoch: 5| Step: 2
Training loss: 1.5487534999847412
Validation loss: 2.05643138786157

Epoch: 5| Step: 3
Training loss: 2.3200860023498535
Validation loss: 2.052531272172928

Epoch: 5| Step: 4
Training loss: 2.4497132301330566
Validation loss: 2.0557864805062613

Epoch: 5| Step: 5
Training loss: 2.2838973999023438
Validation loss: 2.0476339211066565

Epoch: 5| Step: 6
Training loss: 2.122498035430908
Validation loss: 2.0514466216166816

Epoch: 5| Step: 7
Training loss: 1.4734814167022705
Validation loss: 2.0496213187774024

Epoch: 5| Step: 8
Training loss: 2.265122890472412
Validation loss: 2.0481124023596444

Epoch: 5| Step: 9
Training loss: 2.6116766929626465
Validation loss: 2.050469289223353

Epoch: 5| Step: 10
Training loss: 2.146811008453369
Validation loss: 2.044834981362025

Epoch: 5| Step: 11
Training loss: 1.623998761177063
Validation loss: 2.0399356136719384

Epoch: 140| Step: 0
Training loss: 2.033003330230713
Validation loss: 2.041901042064031

Epoch: 5| Step: 1
Training loss: 1.4945958852767944
Validation loss: 2.048606182138125

Epoch: 5| Step: 2
Training loss: 2.39078950881958
Validation loss: 2.042237177491188

Epoch: 5| Step: 3
Training loss: 2.5523886680603027
Validation loss: 2.043547570705414

Epoch: 5| Step: 4
Training loss: 2.4096779823303223
Validation loss: 2.0411698619524636

Epoch: 5| Step: 5
Training loss: 1.9407761096954346
Validation loss: 2.049892485141754

Epoch: 5| Step: 6
Training loss: 1.3643478155136108
Validation loss: 2.0506008913119635

Epoch: 5| Step: 7
Training loss: 1.8760055303573608
Validation loss: 2.0539718916018805

Epoch: 5| Step: 8
Training loss: 2.4228169918060303
Validation loss: 2.0501893957455954

Epoch: 5| Step: 9
Training loss: 2.414614200592041
Validation loss: 2.045226603746414

Epoch: 5| Step: 10
Training loss: 2.3589398860931396
Validation loss: 2.0418226371208825

Epoch: 5| Step: 11
Training loss: 2.201491355895996
Validation loss: 2.0406997054815292

Epoch: 141| Step: 0
Training loss: 2.0056722164154053
Validation loss: 2.0458580454190574

Epoch: 5| Step: 1
Training loss: 2.379723310470581
Validation loss: 2.045339415470759

Epoch: 5| Step: 2
Training loss: 2.2532742023468018
Validation loss: 2.046232799688975

Epoch: 5| Step: 3
Training loss: 1.9249565601348877
Validation loss: 2.044325038790703

Epoch: 5| Step: 4
Training loss: 1.992924690246582
Validation loss: 2.041821534434954

Epoch: 5| Step: 5
Training loss: 2.5443031787872314
Validation loss: 2.053516060113907

Epoch: 5| Step: 6
Training loss: 2.0316195487976074
Validation loss: 2.054243430495262

Epoch: 5| Step: 7
Training loss: 1.8356339931488037
Validation loss: 2.049214412768682

Epoch: 5| Step: 8
Training loss: 1.6878039836883545
Validation loss: 2.0578275471925735

Epoch: 5| Step: 9
Training loss: 2.4870200157165527
Validation loss: 2.06097948551178

Epoch: 5| Step: 10
Training loss: 1.9107472896575928
Validation loss: 2.068923145532608

Epoch: 5| Step: 11
Training loss: 2.7361953258514404
Validation loss: 2.077881872653961

Epoch: 142| Step: 0
Training loss: 2.113013744354248
Validation loss: 2.0617239276568093

Epoch: 5| Step: 1
Training loss: 2.4854660034179688
Validation loss: 2.0605871379375458

Epoch: 5| Step: 2
Training loss: 2.0638673305511475
Validation loss: 2.0604592760403952

Epoch: 5| Step: 3
Training loss: 2.0826499462127686
Validation loss: 2.050195718804995

Epoch: 5| Step: 4
Training loss: 2.295637607574463
Validation loss: 2.055760140220324

Epoch: 5| Step: 5
Training loss: 2.4108662605285645
Validation loss: 2.0507415582736335

Epoch: 5| Step: 6
Training loss: 1.5504868030548096
Validation loss: 2.039771154522896

Epoch: 5| Step: 7
Training loss: 2.353614330291748
Validation loss: 2.0480276296536126

Epoch: 5| Step: 8
Training loss: 2.1170449256896973
Validation loss: 2.0378016779820123

Epoch: 5| Step: 9
Training loss: 2.0755152702331543
Validation loss: 2.046814724802971

Epoch: 5| Step: 10
Training loss: 1.9018293619155884
Validation loss: 2.0492260654767356

Epoch: 5| Step: 11
Training loss: 0.6736449003219604
Validation loss: 2.0463943779468536

Epoch: 143| Step: 0
Training loss: 2.3415355682373047
Validation loss: 2.0425540010134378

Epoch: 5| Step: 1
Training loss: 2.0689501762390137
Validation loss: 2.0379969477653503

Epoch: 5| Step: 2
Training loss: 2.2092623710632324
Validation loss: 2.047824442386627

Epoch: 5| Step: 3
Training loss: 2.149348020553589
Validation loss: 2.0347697685162225

Epoch: 5| Step: 4
Training loss: 1.7774360179901123
Validation loss: 2.035990367333094

Epoch: 5| Step: 5
Training loss: 2.201747417449951
Validation loss: 2.0374606450398765

Epoch: 5| Step: 6
Training loss: 2.407815933227539
Validation loss: 2.0438063740730286

Epoch: 5| Step: 7
Training loss: 1.6115195751190186
Validation loss: 2.0472086519002914

Epoch: 5| Step: 8
Training loss: 2.0465140342712402
Validation loss: 2.0504917949438095

Epoch: 5| Step: 9
Training loss: 1.8495867252349854
Validation loss: 2.052343115210533

Epoch: 5| Step: 10
Training loss: 2.5162601470947266
Validation loss: 2.0523638824621835

Epoch: 5| Step: 11
Training loss: 2.0310285091400146
Validation loss: 2.057262048125267

Epoch: 144| Step: 0
Training loss: 1.5842115879058838
Validation loss: 2.041578322649002

Epoch: 5| Step: 1
Training loss: 2.193418025970459
Validation loss: 2.0525038639704385

Epoch: 5| Step: 2
Training loss: 2.029512405395508
Validation loss: 2.053369551897049

Epoch: 5| Step: 3
Training loss: 2.371899127960205
Validation loss: 2.0534935941298804

Epoch: 5| Step: 4
Training loss: 1.9796550273895264
Validation loss: 2.0520860999822617

Epoch: 5| Step: 5
Training loss: 2.2708537578582764
Validation loss: 2.057126671075821

Epoch: 5| Step: 6
Training loss: 2.214719772338867
Validation loss: 2.042461564143499

Epoch: 5| Step: 7
Training loss: 2.0413639545440674
Validation loss: 2.0487069686253867

Epoch: 5| Step: 8
Training loss: 2.193756580352783
Validation loss: 2.056127349535624

Epoch: 5| Step: 9
Training loss: 2.018385410308838
Validation loss: 2.0530634274085364

Epoch: 5| Step: 10
Training loss: 2.35396146774292
Validation loss: 2.0464366674423218

Epoch: 5| Step: 11
Training loss: 1.3223522901535034
Validation loss: 2.045924127101898

Epoch: 145| Step: 0
Training loss: 2.0197415351867676
Validation loss: 2.048915500442187

Epoch: 5| Step: 1
Training loss: 2.4693527221679688
Validation loss: 2.0432586471239724

Epoch: 5| Step: 2
Training loss: 1.8885549306869507
Validation loss: 2.0454523911078772

Epoch: 5| Step: 3
Training loss: 1.48805570602417
Validation loss: 2.043793390194575

Epoch: 5| Step: 4
Training loss: 2.239017963409424
Validation loss: 2.049804945786794

Epoch: 5| Step: 5
Training loss: 1.932133674621582
Validation loss: 2.05145670970281

Epoch: 5| Step: 6
Training loss: 2.1905264854431152
Validation loss: 2.0507846623659134

Epoch: 5| Step: 7
Training loss: 2.193916082382202
Validation loss: 2.0518097380797067

Epoch: 5| Step: 8
Training loss: 2.009570837020874
Validation loss: 2.05390835305055

Epoch: 5| Step: 9
Training loss: 2.1233811378479004
Validation loss: 2.0620286017656326

Epoch: 5| Step: 10
Training loss: 2.705130100250244
Validation loss: 2.05824176967144

Epoch: 5| Step: 11
Training loss: 1.6209752559661865
Validation loss: 2.06019826233387

Epoch: 146| Step: 0
Training loss: 2.595163106918335
Validation loss: 2.0581735968589783

Epoch: 5| Step: 1
Training loss: 2.18937611579895
Validation loss: 2.064641773700714

Epoch: 5| Step: 2
Training loss: 1.5826932191848755
Validation loss: 2.06504754225413

Epoch: 5| Step: 3
Training loss: 2.299414873123169
Validation loss: 2.0687275826931

Epoch: 5| Step: 4
Training loss: 2.189455986022949
Validation loss: 2.0536941240231195

Epoch: 5| Step: 5
Training loss: 1.7443275451660156
Validation loss: 2.0405707707007728

Epoch: 5| Step: 6
Training loss: 2.480708599090576
Validation loss: 2.0491653233766556

Epoch: 5| Step: 7
Training loss: 1.6252524852752686
Validation loss: 2.0320299863815308

Epoch: 5| Step: 8
Training loss: 2.1319406032562256
Validation loss: 2.038979450861613

Epoch: 5| Step: 9
Training loss: 2.595703601837158
Validation loss: 2.043230210741361

Epoch: 5| Step: 10
Training loss: 1.8151273727416992
Validation loss: 2.043608138958613

Epoch: 5| Step: 11
Training loss: 1.9176366329193115
Validation loss: 2.0488068213065467

Epoch: 147| Step: 0
Training loss: 1.5081539154052734
Validation loss: 2.060058444738388

Epoch: 5| Step: 1
Training loss: 1.9042892456054688
Validation loss: 2.0553410152594247

Epoch: 5| Step: 2
Training loss: 1.949885606765747
Validation loss: 2.060263474782308

Epoch: 5| Step: 3
Training loss: 2.6785671710968018
Validation loss: 2.0518667896588645

Epoch: 5| Step: 4
Training loss: 1.8861461877822876
Validation loss: 2.0627146313587823

Epoch: 5| Step: 5
Training loss: 2.229173183441162
Validation loss: 2.061875502268473

Epoch: 5| Step: 6
Training loss: 2.169565200805664
Validation loss: 2.0640030999978385

Epoch: 5| Step: 7
Training loss: 1.910818338394165
Validation loss: 2.0529002050558725

Epoch: 5| Step: 8
Training loss: 2.238295793533325
Validation loss: 2.0528986155986786

Epoch: 5| Step: 9
Training loss: 1.9197235107421875
Validation loss: 2.0630396803220115

Epoch: 5| Step: 10
Training loss: 2.374800205230713
Validation loss: 2.061422437429428

Epoch: 5| Step: 11
Training loss: 3.3321447372436523
Validation loss: 2.0679499308268228

Epoch: 148| Step: 0
Training loss: 2.0871498584747314
Validation loss: 2.059546654423078

Epoch: 5| Step: 1
Training loss: 2.575057029724121
Validation loss: 2.048776552081108

Epoch: 5| Step: 2
Training loss: 1.913568139076233
Validation loss: 2.0405613283316293

Epoch: 5| Step: 3
Training loss: 1.9525848627090454
Validation loss: 2.0348792324463525

Epoch: 5| Step: 4
Training loss: 2.6221327781677246
Validation loss: 2.0461164166529975

Epoch: 5| Step: 5
Training loss: 1.9266055822372437
Validation loss: 2.040160963932673

Epoch: 5| Step: 6
Training loss: 2.1481287479400635
Validation loss: 2.029305418332418

Epoch: 5| Step: 7
Training loss: 1.924375295639038
Validation loss: 2.0270695885022483

Epoch: 5| Step: 8
Training loss: 1.7017076015472412
Validation loss: 2.038857544461886

Epoch: 5| Step: 9
Training loss: 2.1025118827819824
Validation loss: 2.041822468241056

Epoch: 5| Step: 10
Training loss: 2.030607223510742
Validation loss: 2.059335301319758

Epoch: 5| Step: 11
Training loss: 2.896341562271118
Validation loss: 2.0479004184405007

Epoch: 149| Step: 0
Training loss: 2.0374321937561035
Validation loss: 2.049351245164871

Epoch: 5| Step: 1
Training loss: 1.59650456905365
Validation loss: 2.052521660923958

Epoch: 5| Step: 2
Training loss: 2.177711009979248
Validation loss: 2.0606726557016373

Epoch: 5| Step: 3
Training loss: 2.4770331382751465
Validation loss: 2.056150491038958

Epoch: 5| Step: 4
Training loss: 1.8314611911773682
Validation loss: 2.0590430398782096

Epoch: 5| Step: 5
Training loss: 2.077035427093506
Validation loss: 2.0641423811515174

Epoch: 5| Step: 6
Training loss: 2.233717679977417
Validation loss: 2.069991320371628

Epoch: 5| Step: 7
Training loss: 2.131192445755005
Validation loss: 2.0565194686253867

Epoch: 5| Step: 8
Training loss: 2.349064588546753
Validation loss: 2.054531609018644

Epoch: 5| Step: 9
Training loss: 2.1407055854797363
Validation loss: 2.0546282778183618

Epoch: 5| Step: 10
Training loss: 2.392320394515991
Validation loss: 2.0624142040808997

Epoch: 5| Step: 11
Training loss: 0.9432849884033203
Validation loss: 2.060157453020414

Epoch: 150| Step: 0
Training loss: 1.746474027633667
Validation loss: 2.0522355685631433

Epoch: 5| Step: 1
Training loss: 1.8951648473739624
Validation loss: 2.041032999753952

Epoch: 5| Step: 2
Training loss: 2.332228422164917
Validation loss: 2.0606805880864463

Epoch: 5| Step: 3
Training loss: 1.9251524209976196
Validation loss: 2.049209331472715

Epoch: 5| Step: 4
Training loss: 2.1343321800231934
Validation loss: 2.0476569881041846

Epoch: 5| Step: 5
Training loss: 2.280052661895752
Validation loss: 2.0394878586133323

Epoch: 5| Step: 6
Training loss: 2.5395379066467285
Validation loss: 2.0459343989690146

Epoch: 5| Step: 7
Training loss: 2.6141388416290283
Validation loss: 2.045928662021955

Epoch: 5| Step: 8
Training loss: 1.6643517017364502
Validation loss: 2.0467145442962646

Epoch: 5| Step: 9
Training loss: 1.9857580661773682
Validation loss: 2.043358623981476

Epoch: 5| Step: 10
Training loss: 2.089083194732666
Validation loss: 2.0512434939543405

Epoch: 5| Step: 11
Training loss: 1.676515817642212
Validation loss: 2.053973913192749

Epoch: 151| Step: 0
Training loss: 2.2023491859436035
Validation loss: 2.0611141125361123

Epoch: 5| Step: 1
Training loss: 2.480623245239258
Validation loss: 2.0652473171552024

Epoch: 5| Step: 2
Training loss: 1.9980518817901611
Validation loss: 2.0634838541348777

Epoch: 5| Step: 3
Training loss: 2.1815078258514404
Validation loss: 2.0670524487892785

Epoch: 5| Step: 4
Training loss: 2.371471881866455
Validation loss: 2.0629289150238037

Epoch: 5| Step: 5
Training loss: 2.2985734939575195
Validation loss: 2.05632554491361

Epoch: 5| Step: 6
Training loss: 2.0315957069396973
Validation loss: 2.0636843889951706

Epoch: 5| Step: 7
Training loss: 1.5218477249145508
Validation loss: 2.0599657793839774

Epoch: 5| Step: 8
Training loss: 1.8811492919921875
Validation loss: 2.0567295948664346

Epoch: 5| Step: 9
Training loss: 2.1549434661865234
Validation loss: 2.0606707483530045

Epoch: 5| Step: 10
Training loss: 2.1924800872802734
Validation loss: 2.061641961336136

Epoch: 5| Step: 11
Training loss: 2.2038938999176025
Validation loss: 2.048901895682017

Epoch: 152| Step: 0
Training loss: 1.9555928707122803
Validation loss: 2.0452073365449905

Epoch: 5| Step: 1
Training loss: 2.099555253982544
Validation loss: 2.0496676911910376

Epoch: 5| Step: 2
Training loss: 2.2662625312805176
Validation loss: 2.0518600841363273

Epoch: 5| Step: 3
Training loss: 2.360292434692383
Validation loss: 2.0595656832059226

Epoch: 5| Step: 4
Training loss: 2.2065093517303467
Validation loss: 2.0592587739229202

Epoch: 5| Step: 5
Training loss: 1.5212202072143555
Validation loss: 2.067837650577227

Epoch: 5| Step: 6
Training loss: 2.3894906044006348
Validation loss: 2.063946838180224

Epoch: 5| Step: 7
Training loss: 2.011478900909424
Validation loss: 2.0776889522870383

Epoch: 5| Step: 8
Training loss: 1.8957065343856812
Validation loss: 2.066682850321134

Epoch: 5| Step: 9
Training loss: 1.691070795059204
Validation loss: 2.059015562136968

Epoch: 5| Step: 10
Training loss: 2.757394790649414
Validation loss: 2.058798611164093

Epoch: 5| Step: 11
Training loss: 1.4701755046844482
Validation loss: 2.065865824619929

Epoch: 153| Step: 0
Training loss: 2.6685571670532227
Validation loss: 2.052982827027639

Epoch: 5| Step: 1
Training loss: 2.1824493408203125
Validation loss: 2.049030433098475

Epoch: 5| Step: 2
Training loss: 2.018136501312256
Validation loss: 2.038360968232155

Epoch: 5| Step: 3
Training loss: 1.8978354930877686
Validation loss: 2.033004621664683

Epoch: 5| Step: 4
Training loss: 1.9867374897003174
Validation loss: 2.0401631593704224

Epoch: 5| Step: 5
Training loss: 2.0986876487731934
Validation loss: 2.038898895184199

Epoch: 5| Step: 6
Training loss: 1.8136345148086548
Validation loss: 2.0477742652098336

Epoch: 5| Step: 7
Training loss: 2.5563082695007324
Validation loss: 2.042128766576449

Epoch: 5| Step: 8
Training loss: 2.0056862831115723
Validation loss: 2.032766173283259

Epoch: 5| Step: 9
Training loss: 1.9567495584487915
Validation loss: 2.041220967968305

Epoch: 5| Step: 10
Training loss: 1.9881179332733154
Validation loss: 2.049107253551483

Epoch: 5| Step: 11
Training loss: 1.813413143157959
Validation loss: 2.0628766417503357

Epoch: 154| Step: 0
Training loss: 2.686915874481201
Validation loss: 2.0542838474114737

Epoch: 5| Step: 1
Training loss: 2.343226194381714
Validation loss: 2.0524579733610153

Epoch: 5| Step: 2
Training loss: 2.2772603034973145
Validation loss: 2.0573030908902488

Epoch: 5| Step: 3
Training loss: 1.7733886241912842
Validation loss: 2.046393016974131

Epoch: 5| Step: 4
Training loss: 2.3636269569396973
Validation loss: 2.0355769048134484

Epoch: 5| Step: 5
Training loss: 1.8226425647735596
Validation loss: 2.028458759188652

Epoch: 5| Step: 6
Training loss: 2.084685802459717
Validation loss: 2.036863083640734

Epoch: 5| Step: 7
Training loss: 2.111776828765869
Validation loss: 2.0370840529600778

Epoch: 5| Step: 8
Training loss: 2.0085487365722656
Validation loss: 2.043381854891777

Epoch: 5| Step: 9
Training loss: 1.9463472366333008
Validation loss: 2.0478764325380325

Epoch: 5| Step: 10
Training loss: 1.72195565700531
Validation loss: 2.052526757121086

Epoch: 5| Step: 11
Training loss: 1.3326255083084106
Validation loss: 2.051987946033478

Epoch: 155| Step: 0
Training loss: 2.0492355823516846
Validation loss: 2.077757110198339

Epoch: 5| Step: 1
Training loss: 2.0097053050994873
Validation loss: 2.0887414316336312

Epoch: 5| Step: 2
Training loss: 2.701796770095825
Validation loss: 2.078837896386782

Epoch: 5| Step: 3
Training loss: 2.374537229537964
Validation loss: 2.0892768055200577

Epoch: 5| Step: 4
Training loss: 2.0312113761901855
Validation loss: 2.0882807821035385

Epoch: 5| Step: 5
Training loss: 1.8820831775665283
Validation loss: 2.061628336707751

Epoch: 5| Step: 6
Training loss: 1.9684349298477173
Validation loss: 2.067399804790815

Epoch: 5| Step: 7
Training loss: 2.0512373447418213
Validation loss: 2.041938920815786

Epoch: 5| Step: 8
Training loss: 2.4061429500579834
Validation loss: 2.0319638699293137

Epoch: 5| Step: 9
Training loss: 1.8181025981903076
Validation loss: 2.030034830172857

Epoch: 5| Step: 10
Training loss: 2.6475799083709717
Validation loss: 2.034505218267441

Epoch: 5| Step: 11
Training loss: 1.660971999168396
Validation loss: 2.04745019475619

Epoch: 156| Step: 0
Training loss: 2.4848392009735107
Validation loss: 2.048963447411855

Epoch: 5| Step: 1
Training loss: 2.429797649383545
Validation loss: 2.049415022134781

Epoch: 5| Step: 2
Training loss: 2.0591702461242676
Validation loss: 2.045448119441668

Epoch: 5| Step: 3
Training loss: 2.2404818534851074
Validation loss: 2.050875018040339

Epoch: 5| Step: 4
Training loss: 2.3529105186462402
Validation loss: 2.050389920671781

Epoch: 5| Step: 5
Training loss: 2.0442941188812256
Validation loss: 2.0519790798425674

Epoch: 5| Step: 6
Training loss: 2.062533140182495
Validation loss: 2.0530949185291925

Epoch: 5| Step: 7
Training loss: 2.1523218154907227
Validation loss: 2.046550745765368

Epoch: 5| Step: 8
Training loss: 1.8845100402832031
Validation loss: 2.049122472604116

Epoch: 5| Step: 9
Training loss: 1.854547142982483
Validation loss: 2.049513394633929

Epoch: 5| Step: 10
Training loss: 2.1802783012390137
Validation loss: 2.0433325370152793

Epoch: 5| Step: 11
Training loss: 2.658118963241577
Validation loss: 2.03865913550059

Epoch: 157| Step: 0
Training loss: 1.8927208185195923
Validation loss: 2.0370630820592246

Epoch: 5| Step: 1
Training loss: 2.131906032562256
Validation loss: 2.0321137805779776

Epoch: 5| Step: 2
Training loss: 2.0521352291107178
Validation loss: 2.0398433059453964

Epoch: 5| Step: 3
Training loss: 2.5775845050811768
Validation loss: 2.037387192249298

Epoch: 5| Step: 4
Training loss: 2.3753504753112793
Validation loss: 2.0375486612319946

Epoch: 5| Step: 5
Training loss: 2.123964548110962
Validation loss: 2.0382577031850815

Epoch: 5| Step: 6
Training loss: 2.2115139961242676
Validation loss: 2.0415284782648087

Epoch: 5| Step: 7
Training loss: 2.094029188156128
Validation loss: 2.041448632876078

Epoch: 5| Step: 8
Training loss: 1.620484709739685
Validation loss: 2.0368809352318444

Epoch: 5| Step: 9
Training loss: 2.2753281593322754
Validation loss: 2.028532455364863

Epoch: 5| Step: 10
Training loss: 2.1520867347717285
Validation loss: 2.0305596788724265

Epoch: 5| Step: 11
Training loss: 2.1838929653167725
Validation loss: 2.0213229805231094

Epoch: 158| Step: 0
Training loss: 2.012319326400757
Validation loss: 2.0387834707895913

Epoch: 5| Step: 1
Training loss: 2.5774245262145996
Validation loss: 2.0574302126963935

Epoch: 5| Step: 2
Training loss: 1.5553429126739502
Validation loss: 2.0405523478984833

Epoch: 5| Step: 3
Training loss: 1.9093177318572998
Validation loss: 2.042138303319613

Epoch: 5| Step: 4
Training loss: 2.2193939685821533
Validation loss: 2.0512296855449677

Epoch: 5| Step: 5
Training loss: 2.276444435119629
Validation loss: 2.0541808356841407

Epoch: 5| Step: 6
Training loss: 2.6850385665893555
Validation loss: 2.0660555760065713

Epoch: 5| Step: 7
Training loss: 1.5631352663040161
Validation loss: 2.047159011165301

Epoch: 5| Step: 8
Training loss: 2.059614658355713
Validation loss: 2.058490887284279

Epoch: 5| Step: 9
Training loss: 2.3860974311828613
Validation loss: 2.0683115224043527

Epoch: 5| Step: 10
Training loss: 1.9719905853271484
Validation loss: 2.0601844588915506

Epoch: 5| Step: 11
Training loss: 2.1563851833343506
Validation loss: 2.0720548083384833

Epoch: 159| Step: 0
Training loss: 2.446732521057129
Validation loss: 2.056990832090378

Epoch: 5| Step: 1
Training loss: 2.5200250148773193
Validation loss: 2.063596064845721

Epoch: 5| Step: 2
Training loss: 1.7202026844024658
Validation loss: 2.072412853439649

Epoch: 5| Step: 3
Training loss: 1.9509624242782593
Validation loss: 2.0642349869012833

Epoch: 5| Step: 4
Training loss: 2.0307350158691406
Validation loss: 2.06956980129083

Epoch: 5| Step: 5
Training loss: 1.9217439889907837
Validation loss: 2.065492277344068

Epoch: 5| Step: 6
Training loss: 2.210143804550171
Validation loss: 2.0620213945706687

Epoch: 5| Step: 7
Training loss: 1.6596177816390991
Validation loss: 2.0692474842071533

Epoch: 5| Step: 8
Training loss: 2.196038246154785
Validation loss: 2.0607717831929526

Epoch: 5| Step: 9
Training loss: 2.320189952850342
Validation loss: 2.0406829168399176

Epoch: 5| Step: 10
Training loss: 2.096940517425537
Validation loss: 2.042710781097412

Epoch: 5| Step: 11
Training loss: 1.7773408889770508
Validation loss: 2.042053610086441

Epoch: 160| Step: 0
Training loss: 2.0579190254211426
Validation loss: 2.053922643264135

Epoch: 5| Step: 1
Training loss: 2.0712203979492188
Validation loss: 2.05711463590463

Epoch: 5| Step: 2
Training loss: 2.5703558921813965
Validation loss: 2.0645820697148642

Epoch: 5| Step: 3
Training loss: 1.9583698511123657
Validation loss: 2.0649779538313546

Epoch: 5| Step: 4
Training loss: 2.6336207389831543
Validation loss: 2.079687148332596

Epoch: 5| Step: 5
Training loss: 2.2905662059783936
Validation loss: 2.0662692288557687

Epoch: 5| Step: 6
Training loss: 2.210118055343628
Validation loss: 2.0763671596844993

Epoch: 5| Step: 7
Training loss: 2.3361403942108154
Validation loss: 2.0824568768342337

Epoch: 5| Step: 8
Training loss: 1.5050355195999146
Validation loss: 2.0746659487485886

Epoch: 5| Step: 9
Training loss: 1.9514188766479492
Validation loss: 2.07255386809508

Epoch: 5| Step: 10
Training loss: 1.3901423215866089
Validation loss: 2.0682215889294944

Epoch: 5| Step: 11
Training loss: 2.0387837886810303
Validation loss: 2.0484911600748696

Epoch: 161| Step: 0
Training loss: 1.845965027809143
Validation loss: 2.050757830341657

Epoch: 5| Step: 1
Training loss: 2.4613418579101562
Validation loss: 2.0455840080976486

Epoch: 5| Step: 2
Training loss: 2.0821633338928223
Validation loss: 2.0514721820751824

Epoch: 5| Step: 3
Training loss: 1.9597208499908447
Validation loss: 2.0538454751173654

Epoch: 5| Step: 4
Training loss: 1.6776500940322876
Validation loss: 2.0437673330307007

Epoch: 5| Step: 5
Training loss: 2.3589775562286377
Validation loss: 2.057351524631182

Epoch: 5| Step: 6
Training loss: 2.479781150817871
Validation loss: 2.0386225283145905

Epoch: 5| Step: 7
Training loss: 1.9177322387695312
Validation loss: 2.0498195588588715

Epoch: 5| Step: 8
Training loss: 1.954909086227417
Validation loss: 2.0504675060510635

Epoch: 5| Step: 9
Training loss: 2.185088872909546
Validation loss: 2.0458792398373284

Epoch: 5| Step: 10
Training loss: 2.163397789001465
Validation loss: 2.063437263170878

Epoch: 5| Step: 11
Training loss: 1.1258251667022705
Validation loss: 2.062865967551867

Epoch: 162| Step: 0
Training loss: 2.120295524597168
Validation loss: 2.083174705505371

Epoch: 5| Step: 1
Training loss: 1.9201545715332031
Validation loss: 2.083925262093544

Epoch: 5| Step: 2
Training loss: 2.189786911010742
Validation loss: 2.087093015511831

Epoch: 5| Step: 3
Training loss: 1.5490175485610962
Validation loss: 2.079662253459295

Epoch: 5| Step: 4
Training loss: 2.4097602367401123
Validation loss: 2.079283833503723

Epoch: 5| Step: 5
Training loss: 2.4941177368164062
Validation loss: 2.0753802756468454

Epoch: 5| Step: 6
Training loss: 1.7454427480697632
Validation loss: 2.0595012505849204

Epoch: 5| Step: 7
Training loss: 2.301527500152588
Validation loss: 2.054263805349668

Epoch: 5| Step: 8
Training loss: 2.3491885662078857
Validation loss: 2.0370542307694754

Epoch: 5| Step: 9
Training loss: 2.327847719192505
Validation loss: 2.0448454370101294

Epoch: 5| Step: 10
Training loss: 1.9046348333358765
Validation loss: 2.043533076842626

Epoch: 5| Step: 11
Training loss: 2.598906993865967
Validation loss: 2.0391338020563126

Epoch: 163| Step: 0
Training loss: 1.6500145196914673
Validation loss: 2.039023066560427

Epoch: 5| Step: 1
Training loss: 2.3281257152557373
Validation loss: 2.0467663357655206

Epoch: 5| Step: 2
Training loss: 1.821049690246582
Validation loss: 2.0420750925938287

Epoch: 5| Step: 3
Training loss: 1.891482949256897
Validation loss: 2.041344871123632

Epoch: 5| Step: 4
Training loss: 1.9396034479141235
Validation loss: 2.0452484289805093

Epoch: 5| Step: 5
Training loss: 2.3827943801879883
Validation loss: 2.039924149711927

Epoch: 5| Step: 6
Training loss: 1.9742168188095093
Validation loss: 2.0379590143760047

Epoch: 5| Step: 7
Training loss: 2.188243865966797
Validation loss: 2.0408031394084296

Epoch: 5| Step: 8
Training loss: 2.12660551071167
Validation loss: 2.042014797528585

Epoch: 5| Step: 9
Training loss: 1.7221816778182983
Validation loss: 2.051346570253372

Epoch: 5| Step: 10
Training loss: 3.16494083404541
Validation loss: 2.0468648026386895

Epoch: 5| Step: 11
Training loss: 1.8500747680664062
Validation loss: 2.0584218998750052

Epoch: 164| Step: 0
Training loss: 1.675891637802124
Validation loss: 2.0491654574871063

Epoch: 5| Step: 1
Training loss: 2.0715935230255127
Validation loss: 2.0449255208174386

Epoch: 5| Step: 2
Training loss: 2.7161874771118164
Validation loss: 2.05157678325971

Epoch: 5| Step: 3
Training loss: 2.6975467205047607
Validation loss: 2.0375570307175317

Epoch: 5| Step: 4
Training loss: 1.779981017112732
Validation loss: 2.0496476938327155

Epoch: 5| Step: 5
Training loss: 1.753183364868164
Validation loss: 2.038649966319402

Epoch: 5| Step: 6
Training loss: 2.1620917320251465
Validation loss: 2.040248061219851

Epoch: 5| Step: 7
Training loss: 2.3406198024749756
Validation loss: 2.03971536954244

Epoch: 5| Step: 8
Training loss: 1.6386209726333618
Validation loss: 2.038253421584765

Epoch: 5| Step: 9
Training loss: 1.8696647882461548
Validation loss: 2.041847954193751

Epoch: 5| Step: 10
Training loss: 2.021092414855957
Validation loss: 2.0383841345707574

Epoch: 5| Step: 11
Training loss: 2.890441656112671
Validation loss: 2.052219202121099

Epoch: 165| Step: 0
Training loss: 1.783498764038086
Validation loss: 2.0426826973756156

Epoch: 5| Step: 1
Training loss: 1.856055498123169
Validation loss: 2.0336877604325614

Epoch: 5| Step: 2
Training loss: 2.4184353351593018
Validation loss: 2.041257311900457

Epoch: 5| Step: 3
Training loss: 2.5925683975219727
Validation loss: 2.0453419238328934

Epoch: 5| Step: 4
Training loss: 1.8887710571289062
Validation loss: 2.0455385694901147

Epoch: 5| Step: 5
Training loss: 1.7388728857040405
Validation loss: 2.0410878558953605

Epoch: 5| Step: 6
Training loss: 2.0123238563537598
Validation loss: 2.0359786997238793

Epoch: 5| Step: 7
Training loss: 2.1771082878112793
Validation loss: 2.039611836274465

Epoch: 5| Step: 8
Training loss: 1.5773478746414185
Validation loss: 2.046334276596705

Epoch: 5| Step: 9
Training loss: 2.4863955974578857
Validation loss: 2.0532831301291785

Epoch: 5| Step: 10
Training loss: 2.237403631210327
Validation loss: 2.0420642644166946

Epoch: 5| Step: 11
Training loss: 3.1881790161132812
Validation loss: 2.063156634569168

Epoch: 166| Step: 0
Training loss: 2.196643829345703
Validation loss: 2.04753806690375

Epoch: 5| Step: 1
Training loss: 2.3848366737365723
Validation loss: 2.0394294559955597

Epoch: 5| Step: 2
Training loss: 2.0488648414611816
Validation loss: 2.035443996389707

Epoch: 5| Step: 3
Training loss: 2.410369873046875
Validation loss: 2.0364064276218414

Epoch: 5| Step: 4
Training loss: 2.7049214839935303
Validation loss: 2.0402663499116898

Epoch: 5| Step: 5
Training loss: 1.678417444229126
Validation loss: 2.044027184446653

Epoch: 5| Step: 6
Training loss: 2.45176362991333
Validation loss: 2.0396468490362167

Epoch: 5| Step: 7
Training loss: 1.8002954721450806
Validation loss: 2.0336857736110687

Epoch: 5| Step: 8
Training loss: 2.113621234893799
Validation loss: 2.0374112774928412

Epoch: 5| Step: 9
Training loss: 1.363793969154358
Validation loss: 2.0375490337610245

Epoch: 5| Step: 10
Training loss: 2.122253894805908
Validation loss: 2.0308854480584464

Epoch: 5| Step: 11
Training loss: 1.9091683626174927
Validation loss: 2.0431592017412186

Epoch: 167| Step: 0
Training loss: 1.9772802591323853
Validation loss: 2.0310717076063156

Epoch: 5| Step: 1
Training loss: 2.5260133743286133
Validation loss: 2.037712881962458

Epoch: 5| Step: 2
Training loss: 2.468877077102661
Validation loss: 2.038448318839073

Epoch: 5| Step: 3
Training loss: 2.411633014678955
Validation loss: 2.0357135931650796

Epoch: 5| Step: 4
Training loss: 1.4522651433944702
Validation loss: 2.0373929142951965

Epoch: 5| Step: 5
Training loss: 1.6822059154510498
Validation loss: 2.052259470025698

Epoch: 5| Step: 6
Training loss: 1.9178438186645508
Validation loss: 2.046943018833796

Epoch: 5| Step: 7
Training loss: 2.1454880237579346
Validation loss: 2.046947995821635

Epoch: 5| Step: 8
Training loss: 2.142455816268921
Validation loss: 2.0435157070557275

Epoch: 5| Step: 9
Training loss: 2.3090720176696777
Validation loss: 2.0441058228413262

Epoch: 5| Step: 10
Training loss: 1.9825494289398193
Validation loss: 2.0468957722187042

Epoch: 5| Step: 11
Training loss: 1.2879297733306885
Validation loss: 2.0542751451333365

Epoch: 168| Step: 0
Training loss: 2.072291851043701
Validation loss: 2.046066070596377

Epoch: 5| Step: 1
Training loss: 1.686815857887268
Validation loss: 2.0445641378561654

Epoch: 5| Step: 2
Training loss: 1.4245195388793945
Validation loss: 2.0440643628438315

Epoch: 5| Step: 3
Training loss: 1.3563404083251953
Validation loss: 2.0548020601272583

Epoch: 5| Step: 4
Training loss: 2.5937201976776123
Validation loss: 2.052619457244873

Epoch: 5| Step: 5
Training loss: 2.6320948600769043
Validation loss: 2.060701603690783

Epoch: 5| Step: 6
Training loss: 2.7064807415008545
Validation loss: 2.0582944651444754

Epoch: 5| Step: 7
Training loss: 1.6107286214828491
Validation loss: 2.070498118797938

Epoch: 5| Step: 8
Training loss: 1.9379196166992188
Validation loss: 2.055658996105194

Epoch: 5| Step: 9
Training loss: 2.1061367988586426
Validation loss: 2.055787523587545

Epoch: 5| Step: 10
Training loss: 2.508617877960205
Validation loss: 2.0683076977729797

Epoch: 5| Step: 11
Training loss: 3.119722366333008
Validation loss: 2.0633652210235596

Epoch: 169| Step: 0
Training loss: 1.8293367624282837
Validation loss: 2.0474074433247247

Epoch: 5| Step: 1
Training loss: 2.6257987022399902
Validation loss: 2.046261558930079

Epoch: 5| Step: 2
Training loss: 2.6289830207824707
Validation loss: 2.048463523387909

Epoch: 5| Step: 3
Training loss: 1.5936411619186401
Validation loss: 2.0429422358671823

Epoch: 5| Step: 4
Training loss: 2.141709327697754
Validation loss: 2.0480736593405404

Epoch: 5| Step: 5
Training loss: 2.277806043624878
Validation loss: 2.0566784540812173

Epoch: 5| Step: 6
Training loss: 2.003159284591675
Validation loss: 2.0548454920450845

Epoch: 5| Step: 7
Training loss: 1.8487170934677124
Validation loss: 2.047390361626943

Epoch: 5| Step: 8
Training loss: 1.988874077796936
Validation loss: 2.050006851553917

Epoch: 5| Step: 9
Training loss: 2.3466198444366455
Validation loss: 2.0474105775356293

Epoch: 5| Step: 10
Training loss: 1.8206729888916016
Validation loss: 2.0594512224197388

Epoch: 5| Step: 11
Training loss: 2.11337947845459
Validation loss: 2.0705120166142783

Epoch: 170| Step: 0
Training loss: 1.79559326171875
Validation loss: 2.0628984918196998

Epoch: 5| Step: 1
Training loss: 2.5507774353027344
Validation loss: 2.065567130843798

Epoch: 5| Step: 2
Training loss: 2.5261361598968506
Validation loss: 2.057562698920568

Epoch: 5| Step: 3
Training loss: 1.9401123523712158
Validation loss: 2.067842905720075

Epoch: 5| Step: 4
Training loss: 2.2114644050598145
Validation loss: 2.059016520778338

Epoch: 5| Step: 5
Training loss: 1.5210880041122437
Validation loss: 2.0566159586111703

Epoch: 5| Step: 6
Training loss: 2.0557796955108643
Validation loss: 2.056034669280052

Epoch: 5| Step: 7
Training loss: 2.113966703414917
Validation loss: 2.053234542409579

Epoch: 5| Step: 8
Training loss: 1.7564704418182373
Validation loss: 2.0602076252301535

Epoch: 5| Step: 9
Training loss: 1.8336560726165771
Validation loss: 2.056773285071055

Epoch: 5| Step: 10
Training loss: 2.390176773071289
Validation loss: 2.055171092351278

Epoch: 5| Step: 11
Training loss: 2.4264988899230957
Validation loss: 2.045416365067164

Epoch: 171| Step: 0
Training loss: 2.2717745304107666
Validation loss: 2.0508489658435187

Epoch: 5| Step: 1
Training loss: 1.9631357192993164
Validation loss: 2.0462390234073005

Epoch: 5| Step: 2
Training loss: 1.7111915349960327
Validation loss: 2.0671440611282983

Epoch: 5| Step: 3
Training loss: 2.1774585247039795
Validation loss: 2.05859866241614

Epoch: 5| Step: 4
Training loss: 2.523042678833008
Validation loss: 2.062299445271492

Epoch: 5| Step: 5
Training loss: 2.016709566116333
Validation loss: 2.0635753124952316

Epoch: 5| Step: 6
Training loss: 1.7518657445907593
Validation loss: 2.0560544282197952

Epoch: 5| Step: 7
Training loss: 2.310553550720215
Validation loss: 2.0615539848804474

Epoch: 5| Step: 8
Training loss: 1.9601924419403076
Validation loss: 2.0621659805377326

Epoch: 5| Step: 9
Training loss: 2.2467846870422363
Validation loss: 2.056552285949389

Epoch: 5| Step: 10
Training loss: 1.944240927696228
Validation loss: 2.0458777397871017

Epoch: 5| Step: 11
Training loss: 1.130948781967163
Validation loss: 2.0552795380353928

Epoch: 172| Step: 0
Training loss: 2.3405921459198
Validation loss: 2.0494598547617593

Epoch: 5| Step: 1
Training loss: 1.7582772970199585
Validation loss: 2.045821870366732

Epoch: 5| Step: 2
Training loss: 2.299748182296753
Validation loss: 2.03764279683431

Epoch: 5| Step: 3
Training loss: 2.1619603633880615
Validation loss: 2.0461953431367874

Epoch: 5| Step: 4
Training loss: 1.78684401512146
Validation loss: 2.041851212580999

Epoch: 5| Step: 5
Training loss: 1.546415090560913
Validation loss: 2.0386138012011847

Epoch: 5| Step: 6
Training loss: 2.0424468517303467
Validation loss: 2.0475780963897705

Epoch: 5| Step: 7
Training loss: 1.8772510290145874
Validation loss: 2.0487366020679474

Epoch: 5| Step: 8
Training loss: 2.2787556648254395
Validation loss: 2.060961236556371

Epoch: 5| Step: 9
Training loss: 1.8071314096450806
Validation loss: 2.056410933534304

Epoch: 5| Step: 10
Training loss: 2.971703052520752
Validation loss: 2.063806027173996

Epoch: 5| Step: 11
Training loss: 1.3627982139587402
Validation loss: 2.0723171134789786

Epoch: 173| Step: 0
Training loss: 2.289093017578125
Validation loss: 2.081512371699015

Epoch: 5| Step: 1
Training loss: 1.7309296131134033
Validation loss: 2.0634553035100303

Epoch: 5| Step: 2
Training loss: 2.2055554389953613
Validation loss: 2.069201866785685

Epoch: 5| Step: 3
Training loss: 1.9382336139678955
Validation loss: 2.066476305325826

Epoch: 5| Step: 4
Training loss: 1.7367748022079468
Validation loss: 2.0636058847109475

Epoch: 5| Step: 5
Training loss: 2.1650099754333496
Validation loss: 2.063421368598938

Epoch: 5| Step: 6
Training loss: 1.8546291589736938
Validation loss: 2.068476527929306

Epoch: 5| Step: 7
Training loss: 2.198429584503174
Validation loss: 2.064168984691302

Epoch: 5| Step: 8
Training loss: 2.3723678588867188
Validation loss: 2.0618103742599487

Epoch: 5| Step: 9
Training loss: 2.343787431716919
Validation loss: 2.0550660689671836

Epoch: 5| Step: 10
Training loss: 2.3257389068603516
Validation loss: 2.0672620435555777

Epoch: 5| Step: 11
Training loss: 1.5129406452178955
Validation loss: 2.060774718721708

Epoch: 174| Step: 0
Training loss: 1.932716727256775
Validation loss: 2.060479924082756

Epoch: 5| Step: 1
Training loss: 2.1963024139404297
Validation loss: 2.0639125357071557

Epoch: 5| Step: 2
Training loss: 1.7719221115112305
Validation loss: 2.071448231736819

Epoch: 5| Step: 3
Training loss: 1.2756506204605103
Validation loss: 2.067584494749705

Epoch: 5| Step: 4
Training loss: 1.8580106496810913
Validation loss: 2.0595502853393555

Epoch: 5| Step: 5
Training loss: 2.3430678844451904
Validation loss: 2.0611585825681686

Epoch: 5| Step: 6
Training loss: 2.593824863433838
Validation loss: 2.063445061445236

Epoch: 5| Step: 7
Training loss: 2.1574368476867676
Validation loss: 2.070591534177462

Epoch: 5| Step: 8
Training loss: 1.8794711828231812
Validation loss: 2.065514196952184

Epoch: 5| Step: 9
Training loss: 2.266732692718506
Validation loss: 2.0755752275387445

Epoch: 5| Step: 10
Training loss: 2.8695216178894043
Validation loss: 2.0701593408981958

Epoch: 5| Step: 11
Training loss: 1.1837646961212158
Validation loss: 2.069034685691198

Epoch: 175| Step: 0
Training loss: 2.457543134689331
Validation loss: 2.060739358266195

Epoch: 5| Step: 1
Training loss: 2.359348773956299
Validation loss: 2.0660572747389474

Epoch: 5| Step: 2
Training loss: 2.1626598834991455
Validation loss: 2.0649393449227014

Epoch: 5| Step: 3
Training loss: 1.3009345531463623
Validation loss: 2.0624577750762305

Epoch: 5| Step: 4
Training loss: 2.7463595867156982
Validation loss: 2.0624098827441535

Epoch: 5| Step: 5
Training loss: 1.6314103603363037
Validation loss: 2.0665763864914575

Epoch: 5| Step: 6
Training loss: 2.4249014854431152
Validation loss: 2.058606038490931

Epoch: 5| Step: 7
Training loss: 2.0081918239593506
Validation loss: 2.0503852367401123

Epoch: 5| Step: 8
Training loss: 1.5779889822006226
Validation loss: 2.052795886993408

Epoch: 5| Step: 9
Training loss: 1.8970458507537842
Validation loss: 2.057783762613932

Epoch: 5| Step: 10
Training loss: 2.3416364192962646
Validation loss: 2.0560735861460366

Epoch: 5| Step: 11
Training loss: 2.421781539916992
Validation loss: 2.06039867301782

Testing loss: 1.7232973121053023
