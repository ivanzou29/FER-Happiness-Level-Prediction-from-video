Epoch: 1| Step: 0
Training loss: 5.217618942260742
Validation loss: 5.414046386877696

Epoch: 5| Step: 1
Training loss: 5.085932731628418
Validation loss: 5.412214557329814

Epoch: 5| Step: 2
Training loss: 5.359116554260254
Validation loss: 5.410463054974874

Epoch: 5| Step: 3
Training loss: 5.492149829864502
Validation loss: 5.408741037050883

Epoch: 5| Step: 4
Training loss: 6.525740623474121
Validation loss: 5.406973501046498

Epoch: 5| Step: 5
Training loss: 5.433689117431641
Validation loss: 5.405246257781982

Epoch: 5| Step: 6
Training loss: 5.236705780029297
Validation loss: 5.403593897819519

Epoch: 5| Step: 7
Training loss: 5.161210536956787
Validation loss: 5.401910126209259

Epoch: 5| Step: 8
Training loss: 6.287417411804199
Validation loss: 5.400235176086426

Epoch: 5| Step: 9
Training loss: 5.417333126068115
Validation loss: 5.398445705572764

Epoch: 5| Step: 10
Training loss: 5.034663200378418
Validation loss: 5.3967525362968445

Epoch: 5| Step: 11
Training loss: 5.283473968505859
Validation loss: 5.3949504892031355

Epoch: 2| Step: 0
Training loss: 5.206429481506348
Validation loss: 5.393128275871277

Epoch: 5| Step: 1
Training loss: 5.665736675262451
Validation loss: 5.391214052836101

Epoch: 5| Step: 2
Training loss: 5.302913665771484
Validation loss: 5.389196038246155

Epoch: 5| Step: 3
Training loss: 5.200026035308838
Validation loss: 5.387130260467529

Epoch: 5| Step: 4
Training loss: 5.404788017272949
Validation loss: 5.385033289591472

Epoch: 5| Step: 5
Training loss: 4.922636985778809
Validation loss: 5.382690926392873

Epoch: 5| Step: 6
Training loss: 6.436440944671631
Validation loss: 5.380507528781891

Epoch: 5| Step: 7
Training loss: 5.431899070739746
Validation loss: 5.377889474232991

Epoch: 5| Step: 8
Training loss: 4.1089067459106445
Validation loss: 5.375378290812175

Epoch: 5| Step: 9
Training loss: 6.179963111877441
Validation loss: 5.372732798258464

Epoch: 5| Step: 10
Training loss: 6.082777976989746
Validation loss: 5.370015104611714

Epoch: 5| Step: 11
Training loss: 5.530725955963135
Validation loss: 5.36705219745636

Epoch: 3| Step: 0
Training loss: 4.6033034324646
Validation loss: 5.363936642805736

Epoch: 5| Step: 1
Training loss: 5.065417289733887
Validation loss: 5.3607253432273865

Epoch: 5| Step: 2
Training loss: 5.688189506530762
Validation loss: 5.357412934303284

Epoch: 5| Step: 3
Training loss: 5.986103057861328
Validation loss: 5.35393210252126

Epoch: 5| Step: 4
Training loss: 5.827648639678955
Validation loss: 5.350270648797353

Epoch: 5| Step: 5
Training loss: 5.769038200378418
Validation loss: 5.346349775791168

Epoch: 5| Step: 6
Training loss: 4.951188087463379
Validation loss: 5.342586874961853

Epoch: 5| Step: 7
Training loss: 5.346704006195068
Validation loss: 5.3383194009462995

Epoch: 5| Step: 8
Training loss: 5.776282787322998
Validation loss: 5.333905577659607

Epoch: 5| Step: 9
Training loss: 5.450623512268066
Validation loss: 5.329284687836965

Epoch: 5| Step: 10
Training loss: 5.259972095489502
Validation loss: 5.324335098266602

Epoch: 5| Step: 11
Training loss: 4.55905294418335
Validation loss: 5.319530884424846

Epoch: 4| Step: 0
Training loss: 4.445866107940674
Validation loss: 5.314245243867238

Epoch: 5| Step: 1
Training loss: 5.03973388671875
Validation loss: 5.308784782886505

Epoch: 5| Step: 2
Training loss: 6.2134222984313965
Validation loss: 5.3028861085573835

Epoch: 5| Step: 3
Training loss: 4.7921061515808105
Validation loss: 5.297100245952606

Epoch: 5| Step: 4
Training loss: 5.316487789154053
Validation loss: 5.290859699249268

Epoch: 5| Step: 5
Training loss: 5.9226813316345215
Validation loss: 5.284250438213348

Epoch: 5| Step: 6
Training loss: 6.222100734710693
Validation loss: 5.2774843374888105

Epoch: 5| Step: 7
Training loss: 4.720035552978516
Validation loss: 5.270353019237518

Epoch: 5| Step: 8
Training loss: 5.1646409034729
Validation loss: 5.26297801733017

Epoch: 5| Step: 9
Training loss: 4.939850807189941
Validation loss: 5.255555172761281

Epoch: 5| Step: 10
Training loss: 5.914312362670898
Validation loss: 5.247738043467204

Epoch: 5| Step: 11
Training loss: 6.260013580322266
Validation loss: 5.239721616109212

Epoch: 5| Step: 0
Training loss: 5.159460544586182
Validation loss: 5.231787264347076

Epoch: 5| Step: 1
Training loss: 6.078434467315674
Validation loss: 5.223182201385498

Epoch: 5| Step: 2
Training loss: 4.02791166305542
Validation loss: 5.214678764343262

Epoch: 5| Step: 3
Training loss: 6.309011936187744
Validation loss: 5.206049859523773

Epoch: 5| Step: 4
Training loss: 4.96887731552124
Validation loss: 5.1971379319826765

Epoch: 5| Step: 5
Training loss: 4.976337432861328
Validation loss: 5.188358624776204

Epoch: 5| Step: 6
Training loss: 5.922998428344727
Validation loss: 5.179574966430664

Epoch: 5| Step: 7
Training loss: 4.795207977294922
Validation loss: 5.170460601647695

Epoch: 5| Step: 8
Training loss: 4.9256157875061035
Validation loss: 5.161332031091054

Epoch: 5| Step: 9
Training loss: 5.937506675720215
Validation loss: 5.151917080084483

Epoch: 5| Step: 10
Training loss: 4.922693729400635
Validation loss: 5.142752130826314

Epoch: 5| Step: 11
Training loss: 4.413141250610352
Validation loss: 5.133460919062297

Epoch: 6| Step: 0
Training loss: 5.329211235046387
Validation loss: 5.1244211594263716

Epoch: 5| Step: 1
Training loss: 5.72346830368042
Validation loss: 5.114770690600078

Epoch: 5| Step: 2
Training loss: 4.233277320861816
Validation loss: 5.1053193012873335

Epoch: 5| Step: 3
Training loss: 4.633875370025635
Validation loss: 5.09573249022166

Epoch: 5| Step: 4
Training loss: 4.669795513153076
Validation loss: 5.08589365084966

Epoch: 5| Step: 5
Training loss: 6.156009674072266
Validation loss: 5.075843195120494

Epoch: 5| Step: 6
Training loss: 4.695484638214111
Validation loss: 5.06536744038264

Epoch: 5| Step: 7
Training loss: 6.142651557922363
Validation loss: 5.054958403110504

Epoch: 5| Step: 8
Training loss: 5.956875801086426
Validation loss: 5.044924080371857

Epoch: 5| Step: 9
Training loss: 4.8806538581848145
Validation loss: 5.03456038236618

Epoch: 5| Step: 10
Training loss: 4.184222221374512
Validation loss: 5.0250926812489825

Epoch: 5| Step: 11
Training loss: 5.441072940826416
Validation loss: 5.015204012393951

Epoch: 7| Step: 0
Training loss: 4.976107597351074
Validation loss: 5.006172140439351

Epoch: 5| Step: 1
Training loss: 6.179551124572754
Validation loss: 4.996817270914714

Epoch: 5| Step: 2
Training loss: 5.728684902191162
Validation loss: 4.988024195035298

Epoch: 5| Step: 3
Training loss: 5.255215644836426
Validation loss: 4.979351838429769

Epoch: 5| Step: 4
Training loss: 5.153444766998291
Validation loss: 4.9703818162282305

Epoch: 5| Step: 5
Training loss: 4.650860786437988
Validation loss: 4.961655139923096

Epoch: 5| Step: 6
Training loss: 4.743741989135742
Validation loss: 4.952697336673737

Epoch: 5| Step: 7
Training loss: 4.752190589904785
Validation loss: 4.943817754586537

Epoch: 5| Step: 8
Training loss: 5.077847480773926
Validation loss: 4.934637288252513

Epoch: 5| Step: 9
Training loss: 4.818284511566162
Validation loss: 4.9251245856285095

Epoch: 5| Step: 10
Training loss: 4.130678653717041
Validation loss: 4.91529122988383

Epoch: 5| Step: 11
Training loss: 5.0342512130737305
Validation loss: 4.906069040298462

Epoch: 8| Step: 0
Training loss: 5.37445068359375
Validation loss: 4.897063910961151

Epoch: 5| Step: 1
Training loss: 5.324309349060059
Validation loss: 4.887555778026581

Epoch: 5| Step: 2
Training loss: 5.910155296325684
Validation loss: 4.87891282637914

Epoch: 5| Step: 3
Training loss: 5.1742072105407715
Validation loss: 4.870270848274231

Epoch: 5| Step: 4
Training loss: 3.368079662322998
Validation loss: 4.861478388309479

Epoch: 5| Step: 5
Training loss: 5.481493949890137
Validation loss: 4.852326492468516

Epoch: 5| Step: 6
Training loss: 4.727704048156738
Validation loss: 4.8439250985781355

Epoch: 5| Step: 7
Training loss: 4.47033166885376
Validation loss: 4.835975269476573

Epoch: 5| Step: 8
Training loss: 3.8378360271453857
Validation loss: 4.828110873699188

Epoch: 5| Step: 9
Training loss: 5.530786991119385
Validation loss: 4.820558210213979

Epoch: 5| Step: 10
Training loss: 5.070767879486084
Validation loss: 4.813492317994435

Epoch: 5| Step: 11
Training loss: 5.338922500610352
Validation loss: 4.806134541829427

Epoch: 9| Step: 0
Training loss: 4.929973125457764
Validation loss: 4.799044410387675

Epoch: 5| Step: 1
Training loss: 5.398308277130127
Validation loss: 4.792798658212026

Epoch: 5| Step: 2
Training loss: 4.734574317932129
Validation loss: 4.786043663819631

Epoch: 5| Step: 3
Training loss: 5.739027976989746
Validation loss: 4.779944101969401

Epoch: 5| Step: 4
Training loss: 4.759743690490723
Validation loss: 4.773753662904103

Epoch: 5| Step: 5
Training loss: 4.448074817657471
Validation loss: 4.767849882443746

Epoch: 5| Step: 6
Training loss: 4.771174907684326
Validation loss: 4.761992116769155

Epoch: 5| Step: 7
Training loss: 4.264057636260986
Validation loss: 4.755621075630188

Epoch: 5| Step: 8
Training loss: 5.8038787841796875
Validation loss: 4.749093373616536

Epoch: 5| Step: 9
Training loss: 4.529120445251465
Validation loss: 4.743289391199748

Epoch: 5| Step: 10
Training loss: 3.9625651836395264
Validation loss: 4.736868729194005

Epoch: 5| Step: 11
Training loss: 5.394837856292725
Validation loss: 4.731291751066844

Epoch: 10| Step: 0
Training loss: 5.873236179351807
Validation loss: 4.725945850213368

Epoch: 5| Step: 1
Training loss: 4.3590826988220215
Validation loss: 4.720263481140137

Epoch: 5| Step: 2
Training loss: 4.634100914001465
Validation loss: 4.714910288651784

Epoch: 5| Step: 3
Training loss: 4.224416732788086
Validation loss: 4.708924512068431

Epoch: 5| Step: 4
Training loss: 4.657568454742432
Validation loss: 4.703257938226064

Epoch: 5| Step: 5
Training loss: 5.202368259429932
Validation loss: 4.697595556577046

Epoch: 5| Step: 6
Training loss: 3.9535794258117676
Validation loss: 4.691777139902115

Epoch: 5| Step: 7
Training loss: 5.317657470703125
Validation loss: 4.685977598031362

Epoch: 5| Step: 8
Training loss: 5.581332206726074
Validation loss: 4.679526676734288

Epoch: 5| Step: 9
Training loss: 4.440944194793701
Validation loss: 4.673114895820618

Epoch: 5| Step: 10
Training loss: 4.4707183837890625
Validation loss: 4.667286405960719

Epoch: 5| Step: 11
Training loss: 4.721884250640869
Validation loss: 4.662137548128764

Epoch: 11| Step: 0
Training loss: 5.614358901977539
Validation loss: 4.657173593839009

Epoch: 5| Step: 1
Training loss: 5.314830780029297
Validation loss: 4.650603085756302

Epoch: 5| Step: 2
Training loss: 4.1880598068237305
Validation loss: 4.644863148530324

Epoch: 5| Step: 3
Training loss: 4.208072662353516
Validation loss: 4.639370083808899

Epoch: 5| Step: 4
Training loss: 3.743025541305542
Validation loss: 4.634691039721171

Epoch: 5| Step: 5
Training loss: 5.145603179931641
Validation loss: 4.629487534364064

Epoch: 5| Step: 6
Training loss: 5.2577619552612305
Validation loss: 4.623806416988373

Epoch: 5| Step: 7
Training loss: 4.5253705978393555
Validation loss: 4.6175723274548846

Epoch: 5| Step: 8
Training loss: 5.253814697265625
Validation loss: 4.612303227186203

Epoch: 5| Step: 9
Training loss: 4.602060794830322
Validation loss: 4.606925467650096

Epoch: 5| Step: 10
Training loss: 3.9985413551330566
Validation loss: 4.601454416910808

Epoch: 5| Step: 11
Training loss: 5.4116411209106445
Validation loss: 4.595706403255463

Epoch: 12| Step: 0
Training loss: 3.901275634765625
Validation loss: 4.589638551076253

Epoch: 5| Step: 1
Training loss: 5.1861653327941895
Validation loss: 4.584515035152435

Epoch: 5| Step: 2
Training loss: 3.7662644386291504
Validation loss: 4.579575409491857

Epoch: 5| Step: 3
Training loss: 4.817095756530762
Validation loss: 4.574209988117218

Epoch: 5| Step: 4
Training loss: 4.74648904800415
Validation loss: 4.568908184766769

Epoch: 5| Step: 5
Training loss: 5.422074317932129
Validation loss: 4.563053886095683

Epoch: 5| Step: 6
Training loss: 3.9230170249938965
Validation loss: 4.558704634507497

Epoch: 5| Step: 7
Training loss: 4.563218116760254
Validation loss: 4.552524745464325

Epoch: 5| Step: 8
Training loss: 5.458340167999268
Validation loss: 4.547267516454061

Epoch: 5| Step: 9
Training loss: 4.747630596160889
Validation loss: 4.540667176246643

Epoch: 5| Step: 10
Training loss: 4.866088390350342
Validation loss: 4.535383820533752

Epoch: 5| Step: 11
Training loss: 4.144502639770508
Validation loss: 4.5301132798194885

Epoch: 13| Step: 0
Training loss: 5.069430351257324
Validation loss: 4.524144331614177

Epoch: 5| Step: 1
Training loss: 4.982072830200195
Validation loss: 4.5184372166792555

Epoch: 5| Step: 2
Training loss: 3.7529678344726562
Validation loss: 4.51227190097173

Epoch: 5| Step: 3
Training loss: 4.706748962402344
Validation loss: 4.5079184373219805

Epoch: 5| Step: 4
Training loss: 3.9709854125976562
Validation loss: 4.5018461147944135

Epoch: 5| Step: 5
Training loss: 4.83308219909668
Validation loss: 4.496106773614883

Epoch: 5| Step: 6
Training loss: 4.668275356292725
Validation loss: 4.490615467230479

Epoch: 5| Step: 7
Training loss: 6.053177356719971
Validation loss: 4.48492431640625

Epoch: 5| Step: 8
Training loss: 3.729012966156006
Validation loss: 4.478970408439636

Epoch: 5| Step: 9
Training loss: 4.604701519012451
Validation loss: 4.473433196544647

Epoch: 5| Step: 10
Training loss: 4.0819501876831055
Validation loss: 4.467640737692515

Epoch: 5| Step: 11
Training loss: 5.538138389587402
Validation loss: 4.462059497833252

Epoch: 14| Step: 0
Training loss: 3.681194305419922
Validation loss: 4.456200540065765

Epoch: 5| Step: 1
Training loss: 5.1321868896484375
Validation loss: 4.450169960657756

Epoch: 5| Step: 2
Training loss: 4.827245712280273
Validation loss: 4.4448860088984175

Epoch: 5| Step: 3
Training loss: 4.505958557128906
Validation loss: 4.439252465963364

Epoch: 5| Step: 4
Training loss: 4.462679386138916
Validation loss: 4.4331709543863935

Epoch: 5| Step: 5
Training loss: 4.5841546058654785
Validation loss: 4.426696538925171

Epoch: 5| Step: 6
Training loss: 4.661561012268066
Validation loss: 4.420974880456924

Epoch: 5| Step: 7
Training loss: 4.419319152832031
Validation loss: 4.4155831933021545

Epoch: 5| Step: 8
Training loss: 4.503509521484375
Validation loss: 4.4095242619514465

Epoch: 5| Step: 9
Training loss: 4.6312174797058105
Validation loss: 4.403786222139995

Epoch: 5| Step: 10
Training loss: 4.370746612548828
Validation loss: 4.3983229001363116

Epoch: 5| Step: 11
Training loss: 5.398904323577881
Validation loss: 4.3922711710135145

Epoch: 15| Step: 0
Training loss: 4.436213493347168
Validation loss: 4.387050489584605

Epoch: 5| Step: 1
Training loss: 4.777437686920166
Validation loss: 4.3815329273541765

Epoch: 5| Step: 2
Training loss: 4.758847236633301
Validation loss: 4.375763287146886

Epoch: 5| Step: 3
Training loss: 5.81105899810791
Validation loss: 4.3698572516441345

Epoch: 5| Step: 4
Training loss: 3.847120761871338
Validation loss: 4.363833794991176

Epoch: 5| Step: 5
Training loss: 4.238284587860107
Validation loss: 4.357151617606481

Epoch: 5| Step: 6
Training loss: 3.5055770874023438
Validation loss: 4.350550810496013

Epoch: 5| Step: 7
Training loss: 4.939356327056885
Validation loss: 4.345284591118495

Epoch: 5| Step: 8
Training loss: 3.789567232131958
Validation loss: 4.340084840854009

Epoch: 5| Step: 9
Training loss: 3.434232234954834
Validation loss: 4.333249270915985

Epoch: 5| Step: 10
Training loss: 5.583380699157715
Validation loss: 4.327429552872975

Epoch: 5| Step: 11
Training loss: 5.162964820861816
Validation loss: 4.320652147134145

Epoch: 16| Step: 0
Training loss: 4.23463773727417
Validation loss: 4.315153479576111

Epoch: 5| Step: 1
Training loss: 4.439763069152832
Validation loss: 4.310187518596649

Epoch: 5| Step: 2
Training loss: 4.412959575653076
Validation loss: 4.3049814105033875

Epoch: 5| Step: 3
Training loss: 4.333274841308594
Validation loss: 4.296736498673757

Epoch: 5| Step: 4
Training loss: 4.3068389892578125
Validation loss: 4.2914311190446215

Epoch: 5| Step: 5
Training loss: 4.5700788497924805
Validation loss: 4.286739567915599

Epoch: 5| Step: 6
Training loss: 4.358405113220215
Validation loss: 4.280916064977646

Epoch: 5| Step: 7
Training loss: 4.699110507965088
Validation loss: 4.274978131055832

Epoch: 5| Step: 8
Training loss: 3.821937084197998
Validation loss: 4.26838747660319

Epoch: 5| Step: 9
Training loss: 4.6620192527771
Validation loss: 4.262122372786204

Epoch: 5| Step: 10
Training loss: 4.117923736572266
Validation loss: 4.257105122009913

Epoch: 5| Step: 11
Training loss: 7.248963356018066
Validation loss: 4.251394867897034

Epoch: 17| Step: 0
Training loss: 4.8009443283081055
Validation loss: 4.2452588478724165

Epoch: 5| Step: 1
Training loss: 5.334412574768066
Validation loss: 4.2387925783793134

Epoch: 5| Step: 2
Training loss: 3.124462842941284
Validation loss: 4.233156581719716

Epoch: 5| Step: 3
Training loss: 3.9176926612854004
Validation loss: 4.227105259895325

Epoch: 5| Step: 4
Training loss: 3.4798991680145264
Validation loss: 4.2209112246831255

Epoch: 5| Step: 5
Training loss: 4.852226257324219
Validation loss: 4.21521790822347

Epoch: 5| Step: 6
Training loss: 5.077733516693115
Validation loss: 4.209915439287822

Epoch: 5| Step: 7
Training loss: 3.440869092941284
Validation loss: 4.206022163232167

Epoch: 5| Step: 8
Training loss: 4.546639442443848
Validation loss: 4.198588768641154

Epoch: 5| Step: 9
Training loss: 4.730359077453613
Validation loss: 4.192609806855519

Epoch: 5| Step: 10
Training loss: 4.68890380859375
Validation loss: 4.1858945687611895

Epoch: 5| Step: 11
Training loss: 3.4481401443481445
Validation loss: 4.1795176565647125

Epoch: 18| Step: 0
Training loss: 4.038549423217773
Validation loss: 4.174069583415985

Epoch: 5| Step: 1
Training loss: 4.184410572052002
Validation loss: 4.168838381767273

Epoch: 5| Step: 2
Training loss: 4.272356986999512
Validation loss: 4.163750559091568

Epoch: 5| Step: 3
Training loss: 4.587847709655762
Validation loss: 4.156787425279617

Epoch: 5| Step: 4
Training loss: 3.4198665618896484
Validation loss: 4.152230938275655

Epoch: 5| Step: 5
Training loss: 3.7070789337158203
Validation loss: 4.146144320567449

Epoch: 5| Step: 6
Training loss: 3.65082049369812
Validation loss: 4.140177557865779

Epoch: 5| Step: 7
Training loss: 5.278263092041016
Validation loss: 4.1359448830286665

Epoch: 5| Step: 8
Training loss: 4.070162773132324
Validation loss: 4.12838813662529

Epoch: 5| Step: 9
Training loss: 4.456826210021973
Validation loss: 4.122864345709483

Epoch: 5| Step: 10
Training loss: 5.2460503578186035
Validation loss: 4.117404023806254

Epoch: 5| Step: 11
Training loss: 5.240686416625977
Validation loss: 4.11097173889478

Epoch: 19| Step: 0
Training loss: 4.329959392547607
Validation loss: 4.104944566885631

Epoch: 5| Step: 1
Training loss: 4.679329872131348
Validation loss: 4.100276122490565

Epoch: 5| Step: 2
Training loss: 4.870640277862549
Validation loss: 4.093939453363419

Epoch: 5| Step: 3
Training loss: 4.1459431648254395
Validation loss: 4.087671438852946

Epoch: 5| Step: 4
Training loss: 3.844635009765625
Validation loss: 4.081639001766841

Epoch: 5| Step: 5
Training loss: 4.460112571716309
Validation loss: 4.075197498003642

Epoch: 5| Step: 6
Training loss: 3.7451367378234863
Validation loss: 4.069416920344035

Epoch: 5| Step: 7
Training loss: 4.094685077667236
Validation loss: 4.0632931888103485

Epoch: 5| Step: 8
Training loss: 4.4521965980529785
Validation loss: 4.058843404054642

Epoch: 5| Step: 9
Training loss: 3.437640428543091
Validation loss: 4.052604873975118

Epoch: 5| Step: 10
Training loss: 4.09407901763916
Validation loss: 4.046567420164744

Epoch: 5| Step: 11
Training loss: 5.405673503875732
Validation loss: 4.040470639864604

Epoch: 20| Step: 0
Training loss: 5.183533668518066
Validation loss: 4.034505506356557

Epoch: 5| Step: 1
Training loss: 4.1289167404174805
Validation loss: 4.0289556582768755

Epoch: 5| Step: 2
Training loss: 4.709023475646973
Validation loss: 4.023259520530701

Epoch: 5| Step: 3
Training loss: 3.815009355545044
Validation loss: 4.018808275461197

Epoch: 5| Step: 4
Training loss: 4.043444633483887
Validation loss: 4.012915303309758

Epoch: 5| Step: 5
Training loss: 3.122251510620117
Validation loss: 4.006462424993515

Epoch: 5| Step: 6
Training loss: 4.751908302307129
Validation loss: 4.000996867815654

Epoch: 5| Step: 7
Training loss: 3.9758541584014893
Validation loss: 3.9935464759667716

Epoch: 5| Step: 8
Training loss: 5.392568111419678
Validation loss: 3.988279571135839

Epoch: 5| Step: 9
Training loss: 3.697542905807495
Validation loss: 3.982695003350576

Epoch: 5| Step: 10
Training loss: 2.984572172164917
Validation loss: 3.9774367610613504

Epoch: 5| Step: 11
Training loss: 3.33707857131958
Validation loss: 3.9694524308045707

Epoch: 21| Step: 0
Training loss: 3.1867525577545166
Validation loss: 3.9656005203723907

Epoch: 5| Step: 1
Training loss: 3.8553624153137207
Validation loss: 3.9642845888932547

Epoch: 5| Step: 2
Training loss: 3.914747953414917
Validation loss: 3.9592806696891785

Epoch: 5| Step: 3
Training loss: 4.13034200668335
Validation loss: 3.951191246509552

Epoch: 5| Step: 4
Training loss: 3.740879774093628
Validation loss: 3.94363401333491

Epoch: 5| Step: 5
Training loss: 4.1850972175598145
Validation loss: 3.9375160535176597

Epoch: 5| Step: 6
Training loss: 4.188338279724121
Validation loss: 3.9326668878396354

Epoch: 5| Step: 7
Training loss: 4.019814491271973
Validation loss: 3.927070051431656

Epoch: 5| Step: 8
Training loss: 4.4976806640625
Validation loss: 3.920057455698649

Epoch: 5| Step: 9
Training loss: 3.6881446838378906
Validation loss: 3.9134968519210815

Epoch: 5| Step: 10
Training loss: 5.239859580993652
Validation loss: 3.907191048065821

Epoch: 5| Step: 11
Training loss: 5.3947248458862305
Validation loss: 3.901389996210734

Epoch: 22| Step: 0
Training loss: 3.222203016281128
Validation loss: 3.8954524795214334

Epoch: 5| Step: 1
Training loss: 3.6122848987579346
Validation loss: 3.889113038778305

Epoch: 5| Step: 2
Training loss: 4.100454807281494
Validation loss: 3.882222831249237

Epoch: 5| Step: 3
Training loss: 4.086241722106934
Validation loss: 3.875427554051081

Epoch: 5| Step: 4
Training loss: 4.715660095214844
Validation loss: 3.8699556291103363

Epoch: 5| Step: 5
Training loss: 4.49632453918457
Validation loss: 3.8637826641400657

Epoch: 5| Step: 6
Training loss: 4.417638301849365
Validation loss: 3.857494314511617

Epoch: 5| Step: 7
Training loss: 3.7797374725341797
Validation loss: 3.85073584318161

Epoch: 5| Step: 8
Training loss: 3.8888118267059326
Validation loss: 3.8454105854034424

Epoch: 5| Step: 9
Training loss: 4.558161735534668
Validation loss: 3.839354465405146

Epoch: 5| Step: 10
Training loss: 3.5188446044921875
Validation loss: 3.8324842154979706

Epoch: 5| Step: 11
Training loss: 2.87587571144104
Validation loss: 3.829619208971659

Epoch: 23| Step: 0
Training loss: 3.2759006023406982
Validation loss: 3.8268948992093406

Epoch: 5| Step: 1
Training loss: 3.612271785736084
Validation loss: 3.8227045039335885

Epoch: 5| Step: 2
Training loss: 3.334104061126709
Validation loss: 3.8133966823418937

Epoch: 5| Step: 3
Training loss: 3.534259080886841
Validation loss: 3.8066656390825906

Epoch: 5| Step: 4
Training loss: 4.114686489105225
Validation loss: 3.8017746011416116

Epoch: 5| Step: 5
Training loss: 4.354635238647461
Validation loss: 3.796335220336914

Epoch: 5| Step: 6
Training loss: 4.084317207336426
Validation loss: 3.7921890715758004

Epoch: 5| Step: 7
Training loss: 3.6360886096954346
Validation loss: 3.7853703796863556

Epoch: 5| Step: 8
Training loss: 5.172461986541748
Validation loss: 3.780086189508438

Epoch: 5| Step: 9
Training loss: 3.9206314086914062
Validation loss: 3.773948887983958

Epoch: 5| Step: 10
Training loss: 4.719508171081543
Validation loss: 3.768155495325724

Epoch: 5| Step: 11
Training loss: 2.354891061782837
Validation loss: 3.7628886799017587

Epoch: 24| Step: 0
Training loss: 3.966001033782959
Validation loss: 3.7577453752358756

Epoch: 5| Step: 1
Training loss: 4.239253997802734
Validation loss: 3.751508524020513

Epoch: 5| Step: 2
Training loss: 3.8427577018737793
Validation loss: 3.7463645537694297

Epoch: 5| Step: 3
Training loss: 4.27170467376709
Validation loss: 3.741160968939463

Epoch: 5| Step: 4
Training loss: 4.107609748840332
Validation loss: 3.7358598907788596

Epoch: 5| Step: 5
Training loss: 3.814332962036133
Validation loss: 3.7289902667204538

Epoch: 5| Step: 6
Training loss: 4.1103715896606445
Validation loss: 3.7241967916488647

Epoch: 5| Step: 7
Training loss: 3.6195309162139893
Validation loss: 3.718907356262207

Epoch: 5| Step: 8
Training loss: 3.8488826751708984
Validation loss: 3.71204740802447

Epoch: 5| Step: 9
Training loss: 4.033153533935547
Validation loss: 3.707090357939402

Epoch: 5| Step: 10
Training loss: 2.9520983695983887
Validation loss: 3.7010588546593985

Epoch: 5| Step: 11
Training loss: 3.7176859378814697
Validation loss: 3.696010778347651

Epoch: 25| Step: 0
Training loss: 4.202643871307373
Validation loss: 3.6904267966747284

Epoch: 5| Step: 1
Training loss: 4.4509382247924805
Validation loss: 3.6853768030802407

Epoch: 5| Step: 2
Training loss: 3.0141513347625732
Validation loss: 3.6801345447699227

Epoch: 5| Step: 3
Training loss: 3.7588748931884766
Validation loss: 3.6737632354100547

Epoch: 5| Step: 4
Training loss: 4.060269355773926
Validation loss: 3.669068912665049

Epoch: 5| Step: 5
Training loss: 3.340737819671631
Validation loss: 3.663057734568914

Epoch: 5| Step: 6
Training loss: 3.8156352043151855
Validation loss: 3.6570189793904624

Epoch: 5| Step: 7
Training loss: 4.135627269744873
Validation loss: 3.651225517193476

Epoch: 5| Step: 8
Training loss: 3.9600250720977783
Validation loss: 3.6457149386405945

Epoch: 5| Step: 9
Training loss: 3.9824607372283936
Validation loss: 3.6401063402493796

Epoch: 5| Step: 10
Training loss: 3.082625150680542
Validation loss: 3.6345741351445517

Epoch: 5| Step: 11
Training loss: 5.096224308013916
Validation loss: 3.629627545674642

Epoch: 26| Step: 0
Training loss: 4.136888027191162
Validation loss: 3.623063931862513

Epoch: 5| Step: 1
Training loss: 3.990908145904541
Validation loss: 3.617205113172531

Epoch: 5| Step: 2
Training loss: 2.7777793407440186
Validation loss: 3.611740380525589

Epoch: 5| Step: 3
Training loss: 4.115121364593506
Validation loss: 3.6077715853850045

Epoch: 5| Step: 4
Training loss: 3.1385748386383057
Validation loss: 3.6005982061227164

Epoch: 5| Step: 5
Training loss: 4.477404594421387
Validation loss: 3.596364845832189

Epoch: 5| Step: 6
Training loss: 3.212261199951172
Validation loss: 3.592367301384608

Epoch: 5| Step: 7
Training loss: 3.9389476776123047
Validation loss: 3.586757004261017

Epoch: 5| Step: 8
Training loss: 3.4960601329803467
Validation loss: 3.579979161421458

Epoch: 5| Step: 9
Training loss: 4.268041133880615
Validation loss: 3.575519214073817

Epoch: 5| Step: 10
Training loss: 3.6993346214294434
Validation loss: 3.5702712337176004

Epoch: 5| Step: 11
Training loss: 4.191307067871094
Validation loss: 3.5656555692354837

Epoch: 27| Step: 0
Training loss: 3.5086238384246826
Validation loss: 3.560392737388611

Epoch: 5| Step: 1
Training loss: 3.449955701828003
Validation loss: 3.5522388319174447

Epoch: 5| Step: 2
Training loss: 2.6206469535827637
Validation loss: 3.5469142397244773

Epoch: 5| Step: 3
Training loss: 3.598214626312256
Validation loss: 3.542716860771179

Epoch: 5| Step: 4
Training loss: 4.049368381500244
Validation loss: 3.5379698574543

Epoch: 5| Step: 5
Training loss: 3.981318950653076
Validation loss: 3.531686305999756

Epoch: 5| Step: 6
Training loss: 4.842212677001953
Validation loss: 3.526470720767975

Epoch: 5| Step: 7
Training loss: 3.533923387527466
Validation loss: 3.5211183726787567

Epoch: 5| Step: 8
Training loss: 3.699303388595581
Validation loss: 3.5150724152723947

Epoch: 5| Step: 9
Training loss: 3.149460554122925
Validation loss: 3.507846007744471

Epoch: 5| Step: 10
Training loss: 4.118243217468262
Validation loss: 3.504817843437195

Epoch: 5| Step: 11
Training loss: 4.2117133140563965
Validation loss: 3.4985209008057914

Epoch: 28| Step: 0
Training loss: 4.077925205230713
Validation loss: 3.4933150907357535

Epoch: 5| Step: 1
Training loss: 4.043126106262207
Validation loss: 3.487698723872503

Epoch: 5| Step: 2
Training loss: 3.7311062812805176
Validation loss: 3.4824766318003335

Epoch: 5| Step: 3
Training loss: 3.6129238605499268
Validation loss: 3.4774155219395957

Epoch: 5| Step: 4
Training loss: 3.0712990760803223
Validation loss: 3.4712971846262612

Epoch: 5| Step: 5
Training loss: 3.9570820331573486
Validation loss: 3.468469132979711

Epoch: 5| Step: 6
Training loss: 3.9758472442626953
Validation loss: 3.4642830888430276

Epoch: 5| Step: 7
Training loss: 3.0729317665100098
Validation loss: 3.4546643495559692

Epoch: 5| Step: 8
Training loss: 3.3278987407684326
Validation loss: 3.450215697288513

Epoch: 5| Step: 9
Training loss: 3.769779682159424
Validation loss: 3.4455507397651672

Epoch: 5| Step: 10
Training loss: 3.593372344970703
Validation loss: 3.44281467795372

Epoch: 5| Step: 11
Training loss: 2.2815229892730713
Validation loss: 3.437227616707484

Epoch: 29| Step: 0
Training loss: 3.1691513061523438
Validation loss: 3.433298627535502

Epoch: 5| Step: 1
Training loss: 2.8283214569091797
Validation loss: 3.425994594891866

Epoch: 5| Step: 2
Training loss: 3.690755844116211
Validation loss: 3.4202802578608194

Epoch: 5| Step: 3
Training loss: 2.956549644470215
Validation loss: 3.416229248046875

Epoch: 5| Step: 4
Training loss: 4.1066060066223145
Validation loss: 3.4157817363739014

Epoch: 5| Step: 5
Training loss: 3.441798448562622
Validation loss: 3.407763491074244

Epoch: 5| Step: 6
Training loss: 3.4098198413848877
Validation loss: 3.3990075290203094

Epoch: 5| Step: 7
Training loss: 4.238894462585449
Validation loss: 3.395899683237076

Epoch: 5| Step: 8
Training loss: 3.7890725135803223
Validation loss: 3.3923674523830414

Epoch: 5| Step: 9
Training loss: 3.8454575538635254
Validation loss: 3.3879640102386475

Epoch: 5| Step: 10
Training loss: 3.693708896636963
Validation loss: 3.384303311506907

Epoch: 5| Step: 11
Training loss: 4.178607940673828
Validation loss: 3.378978580236435

Epoch: 30| Step: 0
Training loss: 2.59873366355896
Validation loss: 3.3739335040251413

Epoch: 5| Step: 1
Training loss: 4.059229850769043
Validation loss: 3.3679986000061035

Epoch: 5| Step: 2
Training loss: 3.674243450164795
Validation loss: 3.3631986578305564

Epoch: 5| Step: 3
Training loss: 2.8437442779541016
Validation loss: 3.3580353458722434

Epoch: 5| Step: 4
Training loss: 3.1430792808532715
Validation loss: 3.3539857268333435

Epoch: 5| Step: 5
Training loss: 3.5211377143859863
Validation loss: 3.3496233522892

Epoch: 5| Step: 6
Training loss: 4.178907871246338
Validation loss: 3.3450061778227487

Epoch: 5| Step: 7
Training loss: 3.5209083557128906
Validation loss: 3.338309168815613

Epoch: 5| Step: 8
Training loss: 3.9174818992614746
Validation loss: 3.334019045035044

Epoch: 5| Step: 9
Training loss: 3.683436155319214
Validation loss: 3.3284589449564614

Epoch: 5| Step: 10
Training loss: 3.885180711746216
Validation loss: 3.322625289360682

Epoch: 5| Step: 11
Training loss: 1.8627126216888428
Validation loss: 3.317217340071996

Epoch: 31| Step: 0
Training loss: 2.536245822906494
Validation loss: 3.314634462197622

Epoch: 5| Step: 1
Training loss: 3.9067978858947754
Validation loss: 3.310508519411087

Epoch: 5| Step: 2
Training loss: 3.266766309738159
Validation loss: 3.3060660560925803

Epoch: 5| Step: 3
Training loss: 2.9830524921417236
Validation loss: 3.3012563784917197

Epoch: 5| Step: 4
Training loss: 2.856931686401367
Validation loss: 3.3000233471393585

Epoch: 5| Step: 5
Training loss: 3.3979086875915527
Validation loss: 3.2957488795121512

Epoch: 5| Step: 6
Training loss: 3.219686985015869
Validation loss: 3.300712635119756

Epoch: 5| Step: 7
Training loss: 3.9387423992156982
Validation loss: 3.2922892967859902

Epoch: 5| Step: 8
Training loss: 4.41593074798584
Validation loss: 3.2869145274162292

Epoch: 5| Step: 9
Training loss: 3.775963544845581
Validation loss: 3.277295251687368

Epoch: 5| Step: 10
Training loss: 3.8932902812957764
Validation loss: 3.2738393048445382

Epoch: 5| Step: 11
Training loss: 3.2251174449920654
Validation loss: 3.270247141520182

Epoch: 32| Step: 0
Training loss: 3.2606215476989746
Validation loss: 3.267820725838343

Epoch: 5| Step: 1
Training loss: 3.037611961364746
Validation loss: 3.263224999109904

Epoch: 5| Step: 2
Training loss: 4.346738338470459
Validation loss: 3.257303516070048

Epoch: 5| Step: 3
Training loss: 3.5096611976623535
Validation loss: 3.2527084052562714

Epoch: 5| Step: 4
Training loss: 2.512120008468628
Validation loss: 3.2479068537553153

Epoch: 5| Step: 5
Training loss: 3.084491014480591
Validation loss: 3.24358798066775

Epoch: 5| Step: 6
Training loss: 3.069546699523926
Validation loss: 3.2385992407798767

Epoch: 5| Step: 7
Training loss: 3.8225865364074707
Validation loss: 3.2350785434246063

Epoch: 5| Step: 8
Training loss: 3.258727550506592
Validation loss: 3.229542911052704

Epoch: 5| Step: 9
Training loss: 3.690495014190674
Validation loss: 3.2256201803684235

Epoch: 5| Step: 10
Training loss: 3.7282352447509766
Validation loss: 3.22209303577741

Epoch: 5| Step: 11
Training loss: 4.867893218994141
Validation loss: 3.2178674141565957

Epoch: 33| Step: 0
Training loss: 3.4054176807403564
Validation loss: 3.2116179764270782

Epoch: 5| Step: 1
Training loss: 3.120666980743408
Validation loss: 3.2086112598578134

Epoch: 5| Step: 2
Training loss: 3.699265241622925
Validation loss: 3.2058266599973044

Epoch: 5| Step: 3
Training loss: 3.7525901794433594
Validation loss: 3.2029987275600433

Epoch: 5| Step: 4
Training loss: 3.547891139984131
Validation loss: 3.1964867413043976

Epoch: 5| Step: 5
Training loss: 3.4528205394744873
Validation loss: 3.191518396139145

Epoch: 5| Step: 6
Training loss: 2.980837106704712
Validation loss: 3.185747673114141

Epoch: 5| Step: 7
Training loss: 3.3371269702911377
Validation loss: 3.1814178824424744

Epoch: 5| Step: 8
Training loss: 2.4183380603790283
Validation loss: 3.1762002408504486

Epoch: 5| Step: 9
Training loss: 4.035183429718018
Validation loss: 3.1763967871665955

Epoch: 5| Step: 10
Training loss: 3.32973051071167
Validation loss: 3.167998731136322

Epoch: 5| Step: 11
Training loss: 3.468796730041504
Validation loss: 3.1634719371795654

Epoch: 34| Step: 0
Training loss: 3.6396374702453613
Validation loss: 3.159161855777105

Epoch: 5| Step: 1
Training loss: 3.6407840251922607
Validation loss: 3.1556305388609567

Epoch: 5| Step: 2
Training loss: 2.7792410850524902
Validation loss: 3.1564526160558066

Epoch: 5| Step: 3
Training loss: 3.0819361209869385
Validation loss: 3.1462451020876565

Epoch: 5| Step: 4
Training loss: 3.1416079998016357
Validation loss: 3.142003118991852

Epoch: 5| Step: 5
Training loss: 2.950038194656372
Validation loss: 3.1359477937221527

Epoch: 5| Step: 6
Training loss: 3.559372663497925
Validation loss: 3.1315487027168274

Epoch: 5| Step: 7
Training loss: 3.7095046043395996
Validation loss: 3.1276990373929343

Epoch: 5| Step: 8
Training loss: 3.223660945892334
Validation loss: 3.125125298897425

Epoch: 5| Step: 9
Training loss: 3.5199012756347656
Validation loss: 3.1215999126434326

Epoch: 5| Step: 10
Training loss: 3.0359320640563965
Validation loss: 3.1176859041055045

Epoch: 5| Step: 11
Training loss: 4.551420211791992
Validation loss: 3.1132104297478995

Epoch: 35| Step: 0
Training loss: 3.1081554889678955
Validation loss: 3.1072650452454886

Epoch: 5| Step: 1
Training loss: 3.7988109588623047
Validation loss: 3.1029402812321982

Epoch: 5| Step: 2
Training loss: 3.34150767326355
Validation loss: 3.0978963474432626

Epoch: 5| Step: 3
Training loss: 3.872955799102783
Validation loss: 3.094407707452774

Epoch: 5| Step: 4
Training loss: 3.461905002593994
Validation loss: 3.0899295111497245

Epoch: 5| Step: 5
Training loss: 3.3486697673797607
Validation loss: 3.085917502641678

Epoch: 5| Step: 6
Training loss: 3.4692115783691406
Validation loss: 3.0833202997843423

Epoch: 5| Step: 7
Training loss: 3.067197322845459
Validation loss: 3.078712781270345

Epoch: 5| Step: 8
Training loss: 2.984849452972412
Validation loss: 3.077938417593638

Epoch: 5| Step: 9
Training loss: 2.7953476905822754
Validation loss: 3.0719028214613595

Epoch: 5| Step: 10
Training loss: 2.7324042320251465
Validation loss: 3.069415718317032

Epoch: 5| Step: 11
Training loss: 3.5698800086975098
Validation loss: 3.063806970914205

Epoch: 36| Step: 0
Training loss: 3.822575330734253
Validation loss: 3.0580493609110513

Epoch: 5| Step: 1
Training loss: 4.072386741638184
Validation loss: 3.0542649825414023

Epoch: 5| Step: 2
Training loss: 3.172926664352417
Validation loss: 3.0514164765675864

Epoch: 5| Step: 3
Training loss: 2.5143470764160156
Validation loss: 3.047926753759384

Epoch: 5| Step: 4
Training loss: 3.9140625
Validation loss: 3.0441983739535012

Epoch: 5| Step: 5
Training loss: 3.359286069869995
Validation loss: 3.040895253419876

Epoch: 5| Step: 6
Training loss: 2.8964476585388184
Validation loss: 3.0361897150675454

Epoch: 5| Step: 7
Training loss: 2.7166101932525635
Validation loss: 3.0339815517266593

Epoch: 5| Step: 8
Training loss: 2.9420926570892334
Validation loss: 3.0300329824288688

Epoch: 5| Step: 9
Training loss: 3.1316497325897217
Validation loss: 3.0254074037075043

Epoch: 5| Step: 10
Training loss: 3.0300936698913574
Validation loss: 3.021729439496994

Epoch: 5| Step: 11
Training loss: 3.0504202842712402
Validation loss: 3.0186824202537537

Epoch: 37| Step: 0
Training loss: 2.9248135089874268
Validation loss: 3.0152065654595694

Epoch: 5| Step: 1
Training loss: 2.996030807495117
Validation loss: 3.0106052259604135

Epoch: 5| Step: 2
Training loss: 3.2687313556671143
Validation loss: 3.0076428254445395

Epoch: 5| Step: 3
Training loss: 3.5640692710876465
Validation loss: 3.0104719698429108

Epoch: 5| Step: 4
Training loss: 3.012269973754883
Validation loss: 3.004180908203125

Epoch: 5| Step: 5
Training loss: 2.7557363510131836
Validation loss: 2.9960982898871102

Epoch: 5| Step: 6
Training loss: 2.9690680503845215
Validation loss: 2.9925781786441803

Epoch: 5| Step: 7
Training loss: 3.518911838531494
Validation loss: 2.989845037460327

Epoch: 5| Step: 8
Training loss: 3.445408582687378
Validation loss: 2.983237554629644

Epoch: 5| Step: 9
Training loss: 3.459202527999878
Validation loss: 2.982110212246577

Epoch: 5| Step: 10
Training loss: 3.172882556915283
Validation loss: 2.978073904911677

Epoch: 5| Step: 11
Training loss: 3.093287467956543
Validation loss: 2.9772524535655975

Epoch: 38| Step: 0
Training loss: 2.5419418811798096
Validation loss: 2.9756065607070923

Epoch: 5| Step: 1
Training loss: 3.092400312423706
Validation loss: 2.9709482391675315

Epoch: 5| Step: 2
Training loss: 2.9202277660369873
Validation loss: 2.9660270710786185

Epoch: 5| Step: 3
Training loss: 2.8597984313964844
Validation loss: 2.960019439458847

Epoch: 5| Step: 4
Training loss: 3.880005359649658
Validation loss: 2.9556232392787933

Epoch: 5| Step: 5
Training loss: 3.5590415000915527
Validation loss: 2.9517197708288827

Epoch: 5| Step: 6
Training loss: 3.610280990600586
Validation loss: 2.9481448332468667

Epoch: 5| Step: 7
Training loss: 2.5295252799987793
Validation loss: 2.9438172976175943

Epoch: 5| Step: 8
Training loss: 3.135335922241211
Validation loss: 2.942050298055013

Epoch: 5| Step: 9
Training loss: 2.7822396755218506
Validation loss: 2.937857369581858

Epoch: 5| Step: 10
Training loss: 3.5247085094451904
Validation loss: 2.9385278125603995

Epoch: 5| Step: 11
Training loss: 4.279132843017578
Validation loss: 2.9376524686813354

Epoch: 39| Step: 0
Training loss: 2.89996600151062
Validation loss: 2.930103898048401

Epoch: 5| Step: 1
Training loss: 3.0735747814178467
Validation loss: 2.923539400100708

Epoch: 5| Step: 2
Training loss: 3.548236846923828
Validation loss: 2.9199832876523337

Epoch: 5| Step: 3
Training loss: 2.431561231613159
Validation loss: 2.9174148539702096

Epoch: 5| Step: 4
Training loss: 3.563709259033203
Validation loss: 2.912907471259435

Epoch: 5| Step: 5
Training loss: 3.269484043121338
Validation loss: 2.908568521340688

Epoch: 5| Step: 6
Training loss: 2.732069492340088
Validation loss: 2.9081400632858276

Epoch: 5| Step: 7
Training loss: 3.082740306854248
Validation loss: 2.900890896717707

Epoch: 5| Step: 8
Training loss: 3.4843497276306152
Validation loss: 2.8964238365491233

Epoch: 5| Step: 9
Training loss: 3.2705821990966797
Validation loss: 2.8919987877209983

Epoch: 5| Step: 10
Training loss: 3.1263632774353027
Validation loss: 2.889901578426361

Epoch: 5| Step: 11
Training loss: 1.7148807048797607
Validation loss: 2.8898096680641174

Epoch: 40| Step: 0
Training loss: 2.9088175296783447
Validation loss: 2.8841266334056854

Epoch: 5| Step: 1
Training loss: 2.6013073921203613
Validation loss: 2.8863767186800637

Epoch: 5| Step: 2
Training loss: 2.685777425765991
Validation loss: 2.879164000352224

Epoch: 5| Step: 3
Training loss: 3.132411241531372
Validation loss: 2.875058819850286

Epoch: 5| Step: 4
Training loss: 3.6865830421447754
Validation loss: 2.8708547552426658

Epoch: 5| Step: 5
Training loss: 3.1869606971740723
Validation loss: 2.866319000720978

Epoch: 5| Step: 6
Training loss: 2.992288112640381
Validation loss: 2.8640777468681335

Epoch: 5| Step: 7
Training loss: 2.8928606510162354
Validation loss: 2.860292434692383

Epoch: 5| Step: 8
Training loss: 3.514554500579834
Validation loss: 2.857887258132299

Epoch: 5| Step: 9
Training loss: 3.6993088722229004
Validation loss: 2.853739559650421

Epoch: 5| Step: 10
Training loss: 2.405155658721924
Validation loss: 2.8523584405581155

Epoch: 5| Step: 11
Training loss: 3.5609991550445557
Validation loss: 2.849338392416636

Epoch: 41| Step: 0
Training loss: 3.0431511402130127
Validation loss: 2.8464221556981406

Epoch: 5| Step: 1
Training loss: 2.5082499980926514
Validation loss: 2.8468534648418427

Epoch: 5| Step: 2
Training loss: 2.6513094902038574
Validation loss: 2.861968457698822

Epoch: 5| Step: 3
Training loss: 3.0602989196777344
Validation loss: 2.8497456709543862

Epoch: 5| Step: 4
Training loss: 3.099614381790161
Validation loss: 2.83180304368337

Epoch: 5| Step: 5
Training loss: 3.2707130908966064
Validation loss: 2.8289680778980255

Epoch: 5| Step: 6
Training loss: 3.6548519134521484
Validation loss: 2.8301540911197662

Epoch: 5| Step: 7
Training loss: 3.020925521850586
Validation loss: 2.8286945074796677

Epoch: 5| Step: 8
Training loss: 3.73553204536438
Validation loss: 2.827372560898463

Epoch: 5| Step: 9
Training loss: 2.926147699356079
Validation loss: 2.82834662993749

Epoch: 5| Step: 10
Training loss: 2.944120407104492
Validation loss: 2.8214058180650077

Epoch: 5| Step: 11
Training loss: 0.8323607444763184
Validation loss: 2.8154317438602448

Epoch: 42| Step: 0
Training loss: 2.868178129196167
Validation loss: 2.810787816842397

Epoch: 5| Step: 1
Training loss: 2.9190685749053955
Validation loss: 2.8118265171845755

Epoch: 5| Step: 2
Training loss: 3.5475401878356934
Validation loss: 2.808826873699824

Epoch: 5| Step: 3
Training loss: 2.86999249458313
Validation loss: 2.805846561988195

Epoch: 5| Step: 4
Training loss: 2.8908228874206543
Validation loss: 2.8033111095428467

Epoch: 5| Step: 5
Training loss: 3.0143699645996094
Validation loss: 2.7990000247955322

Epoch: 5| Step: 6
Training loss: 3.114055871963501
Validation loss: 2.7931585609912872

Epoch: 5| Step: 7
Training loss: 3.110301971435547
Validation loss: 2.7921938995520272

Epoch: 5| Step: 8
Training loss: 2.9866552352905273
Validation loss: 2.789968649546305

Epoch: 5| Step: 9
Training loss: 2.965134859085083
Validation loss: 2.787266651789347

Epoch: 5| Step: 10
Training loss: 2.7772345542907715
Validation loss: 2.7834327618281045

Epoch: 5| Step: 11
Training loss: 3.09916353225708
Validation loss: 2.7807272573312125

Epoch: 43| Step: 0
Training loss: 3.432422637939453
Validation loss: 2.779524028301239

Epoch: 5| Step: 1
Training loss: 2.8057315349578857
Validation loss: 2.776334673166275

Epoch: 5| Step: 2
Training loss: 3.220283031463623
Validation loss: 2.7776509622732797

Epoch: 5| Step: 3
Training loss: 2.6017746925354004
Validation loss: 2.775158782800039

Epoch: 5| Step: 4
Training loss: 2.372903347015381
Validation loss: 2.770547568798065

Epoch: 5| Step: 5
Training loss: 3.6029210090637207
Validation loss: 2.7796558936436973

Epoch: 5| Step: 6
Training loss: 3.1953704357147217
Validation loss: 2.7617619335651398

Epoch: 5| Step: 7
Training loss: 3.0560975074768066
Validation loss: 2.7562081019083657

Epoch: 5| Step: 8
Training loss: 2.7851409912109375
Validation loss: 2.7560149431228638

Epoch: 5| Step: 9
Training loss: 3.2400784492492676
Validation loss: 2.7523674964904785

Epoch: 5| Step: 10
Training loss: 2.7163872718811035
Validation loss: 2.7506611148516336

Epoch: 5| Step: 11
Training loss: 1.2100419998168945
Validation loss: 2.7490729987621307

Epoch: 44| Step: 0
Training loss: 2.355156898498535
Validation loss: 2.7469446857770285

Epoch: 5| Step: 1
Training loss: 2.8403916358947754
Validation loss: 2.7453622023264566

Epoch: 5| Step: 2
Training loss: 2.2837462425231934
Validation loss: 2.7439826329549155

Epoch: 5| Step: 3
Training loss: 2.591658592224121
Validation loss: 2.7404085199038186

Epoch: 5| Step: 4
Training loss: 3.5892109870910645
Validation loss: 2.736565242211024

Epoch: 5| Step: 5
Training loss: 2.790107250213623
Validation loss: 2.7338643074035645

Epoch: 5| Step: 6
Training loss: 3.358975887298584
Validation loss: 2.730986843506495

Epoch: 5| Step: 7
Training loss: 3.874333143234253
Validation loss: 2.7285862068335214

Epoch: 5| Step: 8
Training loss: 3.3433189392089844
Validation loss: 2.7227582136789956

Epoch: 5| Step: 9
Training loss: 2.999912738800049
Validation loss: 2.7193431158860526

Epoch: 5| Step: 10
Training loss: 2.250153064727783
Validation loss: 2.7148185769716897

Epoch: 5| Step: 11
Training loss: 3.1881582736968994
Validation loss: 2.7125704487164817

Epoch: 45| Step: 0
Training loss: 3.035646915435791
Validation loss: 2.708450198173523

Epoch: 5| Step: 1
Training loss: 2.9022018909454346
Validation loss: 2.7056582967440286

Epoch: 5| Step: 2
Training loss: 3.443514347076416
Validation loss: 2.7030579447746277

Epoch: 5| Step: 3
Training loss: 2.2796943187713623
Validation loss: 2.701068510611852

Epoch: 5| Step: 4
Training loss: 2.8167483806610107
Validation loss: 2.6935851077238717

Epoch: 5| Step: 5
Training loss: 2.6396303176879883
Validation loss: 2.693134973446528

Epoch: 5| Step: 6
Training loss: 2.536668300628662
Validation loss: 2.692532241344452

Epoch: 5| Step: 7
Training loss: 3.2171149253845215
Validation loss: 2.686066190401713

Epoch: 5| Step: 8
Training loss: 2.905463218688965
Validation loss: 2.680378516515096

Epoch: 5| Step: 9
Training loss: 3.251117706298828
Validation loss: 2.677397464712461

Epoch: 5| Step: 10
Training loss: 2.8259496688842773
Validation loss: 2.6762071748574576

Epoch: 5| Step: 11
Training loss: 2.9432785511016846
Validation loss: 2.6730033655961356

Epoch: 46| Step: 0
Training loss: 2.3031208515167236
Validation loss: 2.6697270572185516

Epoch: 5| Step: 1
Training loss: 2.7651822566986084
Validation loss: 2.6688794791698456

Epoch: 5| Step: 2
Training loss: 3.0323634147644043
Validation loss: 2.664489974578222

Epoch: 5| Step: 3
Training loss: 3.23215913772583
Validation loss: 2.6621468365192413

Epoch: 5| Step: 4
Training loss: 2.9304943084716797
Validation loss: 2.6584704915682473

Epoch: 5| Step: 5
Training loss: 2.6725900173187256
Validation loss: 2.6554366052150726

Epoch: 5| Step: 6
Training loss: 2.8106937408447266
Validation loss: 2.6476363639036813

Epoch: 5| Step: 7
Training loss: 2.397216796875
Validation loss: 2.647522578636805

Epoch: 5| Step: 8
Training loss: 3.018822431564331
Validation loss: 2.645516852537791

Epoch: 5| Step: 9
Training loss: 2.8523542881011963
Validation loss: 2.6449106434981027

Epoch: 5| Step: 10
Training loss: 3.2808737754821777
Validation loss: 2.6406915187835693

Epoch: 5| Step: 11
Training loss: 3.4823195934295654
Validation loss: 2.6366174866755805

Epoch: 47| Step: 0
Training loss: 2.977377414703369
Validation loss: 2.6327586273352304

Epoch: 5| Step: 1
Training loss: 2.984785795211792
Validation loss: 2.626739223798116

Epoch: 5| Step: 2
Training loss: 2.8554139137268066
Validation loss: 2.624859005212784

Epoch: 5| Step: 3
Training loss: 3.12939453125
Validation loss: 2.622588276863098

Epoch: 5| Step: 4
Training loss: 2.512385129928589
Validation loss: 2.6190781394640603

Epoch: 5| Step: 5
Training loss: 2.684324026107788
Validation loss: 2.6138719817002616

Epoch: 5| Step: 6
Training loss: 2.403535842895508
Validation loss: 2.6131007969379425

Epoch: 5| Step: 7
Training loss: 2.462681531906128
Validation loss: 2.6107534368832908

Epoch: 5| Step: 8
Training loss: 3.002772808074951
Validation loss: 2.605224152406057

Epoch: 5| Step: 9
Training loss: 2.9650344848632812
Validation loss: 2.6051895717779794

Epoch: 5| Step: 10
Training loss: 2.9750752449035645
Validation loss: 2.598404328028361

Epoch: 5| Step: 11
Training loss: 3.0050747394561768
Validation loss: 2.5950373808542886

Epoch: 48| Step: 0
Training loss: 2.1732430458068848
Validation loss: 2.591612085700035

Epoch: 5| Step: 1
Training loss: 2.916372537612915
Validation loss: 2.5880194107691445

Epoch: 5| Step: 2
Training loss: 3.201190948486328
Validation loss: 2.5867185642321906

Epoch: 5| Step: 3
Training loss: 2.606522798538208
Validation loss: 2.581132392088572

Epoch: 5| Step: 4
Training loss: 2.8160085678100586
Validation loss: 2.578882078329722

Epoch: 5| Step: 5
Training loss: 2.709476947784424
Validation loss: 2.583629702528318

Epoch: 5| Step: 6
Training loss: 3.182403087615967
Validation loss: 2.5791949331760406

Epoch: 5| Step: 7
Training loss: 2.9628524780273438
Validation loss: 2.5712508658568063

Epoch: 5| Step: 8
Training loss: 3.5405502319335938
Validation loss: 2.565812736749649

Epoch: 5| Step: 9
Training loss: 2.20414137840271
Validation loss: 2.563882658878962

Epoch: 5| Step: 10
Training loss: 2.436486005783081
Validation loss: 2.559412330389023

Epoch: 5| Step: 11
Training loss: 1.8038183450698853
Validation loss: 2.558021346728007

Epoch: 49| Step: 0
Training loss: 2.577188014984131
Validation loss: 2.5598305563131967

Epoch: 5| Step: 1
Training loss: 2.918865203857422
Validation loss: 2.552283227443695

Epoch: 5| Step: 2
Training loss: 2.7062301635742188
Validation loss: 2.5522193908691406

Epoch: 5| Step: 3
Training loss: 2.297574043273926
Validation loss: 2.549656927585602

Epoch: 5| Step: 4
Training loss: 2.6117305755615234
Validation loss: 2.5459018299976983

Epoch: 5| Step: 5
Training loss: 2.8868343830108643
Validation loss: 2.5432790319124856

Epoch: 5| Step: 6
Training loss: 2.554255962371826
Validation loss: 2.5390386283397675

Epoch: 5| Step: 7
Training loss: 2.699144124984741
Validation loss: 2.535777042309443

Epoch: 5| Step: 8
Training loss: 2.8655316829681396
Validation loss: 2.535432457923889

Epoch: 5| Step: 9
Training loss: 3.034588575363159
Validation loss: 2.5282007257143655

Epoch: 5| Step: 10
Training loss: 2.9637653827667236
Validation loss: 2.528414954741796

Epoch: 5| Step: 11
Training loss: 2.8683435916900635
Validation loss: 2.523597667614619

Epoch: 50| Step: 0
Training loss: 2.6542744636535645
Validation loss: 2.521670341491699

Epoch: 5| Step: 1
Training loss: 2.7712321281433105
Validation loss: 2.5168839395046234

Epoch: 5| Step: 2
Training loss: 2.4876670837402344
Validation loss: 2.5147856871287027

Epoch: 5| Step: 3
Training loss: 2.696749448776245
Validation loss: 2.5115504066149392

Epoch: 5| Step: 4
Training loss: 2.697665214538574
Validation loss: 2.510460913181305

Epoch: 5| Step: 5
Training loss: 2.685906410217285
Validation loss: 2.5064652065436044

Epoch: 5| Step: 6
Training loss: 2.541111707687378
Validation loss: 2.5032107532024384

Epoch: 5| Step: 7
Training loss: 2.6577415466308594
Validation loss: 2.5020860930283866

Epoch: 5| Step: 8
Training loss: 2.806379795074463
Validation loss: 2.4947025775909424

Epoch: 5| Step: 9
Training loss: 2.740787982940674
Validation loss: 2.4957348604997

Epoch: 5| Step: 10
Training loss: 3.212122678756714
Validation loss: 2.4928633819023767

Epoch: 5| Step: 11
Training loss: 1.4701664447784424
Validation loss: 2.4939054747422538

Epoch: 51| Step: 0
Training loss: 2.4718031883239746
Validation loss: 2.4893487791220346

Epoch: 5| Step: 1
Training loss: 2.7063941955566406
Validation loss: 2.4844051202138266

Epoch: 5| Step: 2
Training loss: 2.984745502471924
Validation loss: 2.482809712489446

Epoch: 5| Step: 3
Training loss: 2.7034029960632324
Validation loss: 2.4777477979660034

Epoch: 5| Step: 4
Training loss: 2.825660228729248
Validation loss: 2.4759554266929626

Epoch: 5| Step: 5
Training loss: 2.900489330291748
Validation loss: 2.4742573300997415

Epoch: 5| Step: 6
Training loss: 2.382554531097412
Validation loss: 2.4707432985305786

Epoch: 5| Step: 7
Training loss: 2.5096077919006348
Validation loss: 2.4673133889834085

Epoch: 5| Step: 8
Training loss: 2.5403547286987305
Validation loss: 2.464789549509684

Epoch: 5| Step: 9
Training loss: 2.5699503421783447
Validation loss: 2.4636966784795127

Epoch: 5| Step: 10
Training loss: 2.7122550010681152
Validation loss: 2.460386003057162

Epoch: 5| Step: 11
Training loss: 2.9125168323516846
Validation loss: 2.458415428797404

Epoch: 52| Step: 0
Training loss: 2.443239688873291
Validation loss: 2.453969438870748

Epoch: 5| Step: 1
Training loss: 2.122114896774292
Validation loss: 2.449990232785543

Epoch: 5| Step: 2
Training loss: 2.0726354122161865
Validation loss: 2.4481561183929443

Epoch: 5| Step: 3
Training loss: 3.0422110557556152
Validation loss: 2.4469346006711326

Epoch: 5| Step: 4
Training loss: 2.769625186920166
Validation loss: 2.4412370721499124

Epoch: 5| Step: 5
Training loss: 2.4637043476104736
Validation loss: 2.4384655555089316

Epoch: 5| Step: 6
Training loss: 2.8258891105651855
Validation loss: 2.4343062937259674

Epoch: 5| Step: 7
Training loss: 2.2340755462646484
Validation loss: 2.432852784792582

Epoch: 5| Step: 8
Training loss: 2.7560646533966064
Validation loss: 2.4296747048695884

Epoch: 5| Step: 9
Training loss: 2.8586487770080566
Validation loss: 2.427782972653707

Epoch: 5| Step: 10
Training loss: 3.3086445331573486
Validation loss: 2.424435834089915

Epoch: 5| Step: 11
Training loss: 2.6876373291015625
Validation loss: 2.420204242070516

Epoch: 53| Step: 0
Training loss: 3.2540981769561768
Validation loss: 2.4188328882058463

Epoch: 5| Step: 1
Training loss: 2.936218738555908
Validation loss: 2.416019340356191

Epoch: 5| Step: 2
Training loss: 2.870405673980713
Validation loss: 2.4123226602872214

Epoch: 5| Step: 3
Training loss: 2.430527925491333
Validation loss: 2.410007044672966

Epoch: 5| Step: 4
Training loss: 2.3179469108581543
Validation loss: 2.4085455238819122

Epoch: 5| Step: 5
Training loss: 2.3182826042175293
Validation loss: 2.4048217038313546

Epoch: 5| Step: 6
Training loss: 2.6727795600891113
Validation loss: 2.403376877307892

Epoch: 5| Step: 7
Training loss: 3.034346103668213
Validation loss: 2.4050744076569877

Epoch: 5| Step: 8
Training loss: 2.058835506439209
Validation loss: 2.4007919132709503

Epoch: 5| Step: 9
Training loss: 2.328016996383667
Validation loss: 2.3980549971262612

Epoch: 5| Step: 10
Training loss: 2.1695942878723145
Validation loss: 2.3962415158748627

Epoch: 5| Step: 11
Training loss: 3.048224449157715
Validation loss: 2.392280548810959

Epoch: 54| Step: 0
Training loss: 2.2680420875549316
Validation loss: 2.3862966299057007

Epoch: 5| Step: 1
Training loss: 2.6360645294189453
Validation loss: 2.3829571853081384

Epoch: 5| Step: 2
Training loss: 2.5939555168151855
Validation loss: 2.383186548948288

Epoch: 5| Step: 3
Training loss: 2.361729860305786
Validation loss: 2.3803180853525796

Epoch: 5| Step: 4
Training loss: 2.249396800994873
Validation loss: 2.378262758255005

Epoch: 5| Step: 5
Training loss: 2.7544631958007812
Validation loss: 2.37204742928346

Epoch: 5| Step: 6
Training loss: 2.688568592071533
Validation loss: 2.371802677710851

Epoch: 5| Step: 7
Training loss: 3.0835120677948
Validation loss: 2.3676037192344666

Epoch: 5| Step: 8
Training loss: 2.6255290508270264
Validation loss: 2.3626266568899155

Epoch: 5| Step: 9
Training loss: 2.270393133163452
Validation loss: 2.361143628756205

Epoch: 5| Step: 10
Training loss: 2.644972324371338
Validation loss: 2.357418109973272

Epoch: 5| Step: 11
Training loss: 1.9860948324203491
Validation loss: 2.3591441412766776

Epoch: 55| Step: 0
Training loss: 2.4763312339782715
Validation loss: 2.35529995461305

Epoch: 5| Step: 1
Training loss: 1.8069486618041992
Validation loss: 2.348670800526937

Epoch: 5| Step: 2
Training loss: 2.484590530395508
Validation loss: 2.3562365422646203

Epoch: 5| Step: 3
Training loss: 2.5530147552490234
Validation loss: 2.3469053705533347

Epoch: 5| Step: 4
Training loss: 2.5874671936035156
Validation loss: 2.3443911969661713

Epoch: 5| Step: 5
Training loss: 2.3287246227264404
Validation loss: 2.340303192536036

Epoch: 5| Step: 6
Training loss: 2.6255319118499756
Validation loss: 2.337272673845291

Epoch: 5| Step: 7
Training loss: 2.2566750049591064
Validation loss: 2.3397910396258035

Epoch: 5| Step: 8
Training loss: 2.925179958343506
Validation loss: 2.35977910955747

Epoch: 5| Step: 9
Training loss: 2.903634548187256
Validation loss: 2.348012318213781

Epoch: 5| Step: 10
Training loss: 2.811383008956909
Validation loss: 2.3291344145933786

Epoch: 5| Step: 11
Training loss: 2.6032752990722656
Validation loss: 2.3263744364182153

Epoch: 56| Step: 0
Training loss: 2.3380444049835205
Validation loss: 2.3352001508076987

Epoch: 5| Step: 1
Training loss: 2.5626819133758545
Validation loss: 2.336062798897425

Epoch: 5| Step: 2
Training loss: 2.8712527751922607
Validation loss: 2.343975707888603

Epoch: 5| Step: 3
Training loss: 1.7400099039077759
Validation loss: 2.3405174762010574

Epoch: 5| Step: 4
Training loss: 2.564884662628174
Validation loss: 2.3389597733815513

Epoch: 5| Step: 5
Training loss: 3.0160610675811768
Validation loss: 2.334283431371053

Epoch: 5| Step: 6
Training loss: 2.015510082244873
Validation loss: 2.3307146430015564

Epoch: 5| Step: 7
Training loss: 2.5286190509796143
Validation loss: 2.325557748476664

Epoch: 5| Step: 8
Training loss: 2.447324752807617
Validation loss: 2.321696693698565

Epoch: 5| Step: 9
Training loss: 2.913949489593506
Validation loss: 2.3146457374095917

Epoch: 5| Step: 10
Training loss: 2.3698301315307617
Validation loss: 2.3111815055211387

Epoch: 5| Step: 11
Training loss: 3.316394329071045
Validation loss: 2.303529053926468

Epoch: 57| Step: 0
Training loss: 2.7775824069976807
Validation loss: 2.3033202290534973

Epoch: 5| Step: 1
Training loss: 3.00260853767395
Validation loss: 2.297762339313825

Epoch: 5| Step: 2
Training loss: 1.7201213836669922
Validation loss: 2.299009144306183

Epoch: 5| Step: 3
Training loss: 1.8720080852508545
Validation loss: 2.293804481625557

Epoch: 5| Step: 4
Training loss: 2.702162742614746
Validation loss: 2.289074112971624

Epoch: 5| Step: 5
Training loss: 2.6543796062469482
Validation loss: 2.2897366136312485

Epoch: 5| Step: 6
Training loss: 2.2688021659851074
Validation loss: 2.2854028940200806

Epoch: 5| Step: 7
Training loss: 2.238393545150757
Validation loss: 2.2831565539042153

Epoch: 5| Step: 8
Training loss: 2.7882065773010254
Validation loss: 2.2795382291078568

Epoch: 5| Step: 9
Training loss: 2.738389253616333
Validation loss: 2.278446843226751

Epoch: 5| Step: 10
Training loss: 2.417517900466919
Validation loss: 2.2741117725769677

Epoch: 5| Step: 11
Training loss: 1.8334827423095703
Validation loss: 2.2712874760230384

Epoch: 58| Step: 0
Training loss: 2.39689564704895
Validation loss: 2.2745032608509064

Epoch: 5| Step: 1
Training loss: 2.856515407562256
Validation loss: 2.267472356557846

Epoch: 5| Step: 2
Training loss: 2.8063008785247803
Validation loss: 2.280396689971288

Epoch: 5| Step: 3
Training loss: 1.9598922729492188
Validation loss: 2.272304673989614

Epoch: 5| Step: 4
Training loss: 2.7652878761291504
Validation loss: 2.269734114408493

Epoch: 5| Step: 5
Training loss: 2.7235829830169678
Validation loss: 2.2614292899767556

Epoch: 5| Step: 6
Training loss: 2.272096872329712
Validation loss: 2.253642112016678

Epoch: 5| Step: 7
Training loss: 2.3407485485076904
Validation loss: 2.2508012304703393

Epoch: 5| Step: 8
Training loss: 2.3468387126922607
Validation loss: 2.2463123550017676

Epoch: 5| Step: 9
Training loss: 1.760987639427185
Validation loss: 2.244350334008535

Epoch: 5| Step: 10
Training loss: 2.386950731277466
Validation loss: 2.242204566796621

Epoch: 5| Step: 11
Training loss: 2.6266236305236816
Validation loss: 2.2435320367415748

Epoch: 59| Step: 0
Training loss: 2.5107665061950684
Validation loss: 2.244610851009687

Epoch: 5| Step: 1
Training loss: 1.7549110651016235
Validation loss: 2.2452768683433533

Epoch: 5| Step: 2
Training loss: 2.6403090953826904
Validation loss: 2.234171375632286

Epoch: 5| Step: 3
Training loss: 2.767578601837158
Validation loss: 2.234566166996956

Epoch: 5| Step: 4
Training loss: 2.271322727203369
Validation loss: 2.2343891660372415

Epoch: 5| Step: 5
Training loss: 2.5703165531158447
Validation loss: 2.229163105289141

Epoch: 5| Step: 6
Training loss: 2.3284363746643066
Validation loss: 2.230706642071406

Epoch: 5| Step: 7
Training loss: 2.1750011444091797
Validation loss: 2.223177880048752

Epoch: 5| Step: 8
Training loss: 2.3261494636535645
Validation loss: 2.225121319293976

Epoch: 5| Step: 9
Training loss: 2.2171783447265625
Validation loss: 2.2247718423604965

Epoch: 5| Step: 10
Training loss: 2.7823708057403564
Validation loss: 2.2253949691851935

Epoch: 5| Step: 11
Training loss: 2.2400453090667725
Validation loss: 2.2143498808145523

Epoch: 60| Step: 0
Training loss: 2.365067720413208
Validation loss: 2.213389585415522

Epoch: 5| Step: 1
Training loss: 2.3172287940979004
Validation loss: 2.2085123856862388

Epoch: 5| Step: 2
Training loss: 2.1282362937927246
Validation loss: 2.207304527362188

Epoch: 5| Step: 3
Training loss: 2.772134304046631
Validation loss: 2.203275054693222

Epoch: 5| Step: 4
Training loss: 2.5272936820983887
Validation loss: 2.203966279824575

Epoch: 5| Step: 5
Training loss: 2.5280652046203613
Validation loss: 2.2024857501188913

Epoch: 5| Step: 6
Training loss: 2.671233654022217
Validation loss: 2.2002564469973245

Epoch: 5| Step: 7
Training loss: 1.7368857860565186
Validation loss: 2.204187879959742

Epoch: 5| Step: 8
Training loss: 2.666947841644287
Validation loss: 2.2006427546342215

Epoch: 5| Step: 9
Training loss: 1.813360571861267
Validation loss: 2.1979225426912308

Epoch: 5| Step: 10
Training loss: 2.3938727378845215
Validation loss: 2.1997091621160507

Epoch: 5| Step: 11
Training loss: 2.7729716300964355
Validation loss: 2.1977021048466363

Epoch: 61| Step: 0
Training loss: 2.489109754562378
Validation loss: 2.198506553967794

Epoch: 5| Step: 1
Training loss: 2.4543135166168213
Validation loss: 2.194807986418406

Epoch: 5| Step: 2
Training loss: 2.4509220123291016
Validation loss: 2.1937354107697806

Epoch: 5| Step: 3
Training loss: 2.937070369720459
Validation loss: 2.19362207253774

Epoch: 5| Step: 4
Training loss: 2.182961940765381
Validation loss: 2.1877652953068414

Epoch: 5| Step: 5
Training loss: 2.2948944568634033
Validation loss: 2.1886239598194757

Epoch: 5| Step: 6
Training loss: 1.6590874195098877
Validation loss: 2.190420279900233

Epoch: 5| Step: 7
Training loss: 1.9511337280273438
Validation loss: 2.1844383428494134

Epoch: 5| Step: 8
Training loss: 2.204043388366699
Validation loss: 2.1865716725587845

Epoch: 5| Step: 9
Training loss: 2.684117078781128
Validation loss: 2.1848656137784324

Epoch: 5| Step: 10
Training loss: 2.4328196048736572
Validation loss: 2.1815538108348846

Epoch: 5| Step: 11
Training loss: 2.9499504566192627
Validation loss: 2.1809576650460563

Epoch: 62| Step: 0
Training loss: 2.4014601707458496
Validation loss: 2.1729095776875815

Epoch: 5| Step: 1
Training loss: 1.6787385940551758
Validation loss: 2.176671544710795

Epoch: 5| Step: 2
Training loss: 2.1634082794189453
Validation loss: 2.171660895148913

Epoch: 5| Step: 3
Training loss: 2.3949952125549316
Validation loss: 2.171378696958224

Epoch: 5| Step: 4
Training loss: 2.414196729660034
Validation loss: 2.166535407304764

Epoch: 5| Step: 5
Training loss: 2.211280345916748
Validation loss: 2.1639795303344727

Epoch: 5| Step: 6
Training loss: 2.2558064460754395
Validation loss: 2.1636818796396255

Epoch: 5| Step: 7
Training loss: 2.841015338897705
Validation loss: 2.161218280593554

Epoch: 5| Step: 8
Training loss: 2.5706429481506348
Validation loss: 2.15327517191569

Epoch: 5| Step: 9
Training loss: 2.225213050842285
Validation loss: 2.1548888434966407

Epoch: 5| Step: 10
Training loss: 2.4523558616638184
Validation loss: 2.15633595486482

Epoch: 5| Step: 11
Training loss: 1.92250657081604
Validation loss: 2.1586390137672424

Epoch: 63| Step: 0
Training loss: 2.328843355178833
Validation loss: 2.1551841497421265

Epoch: 5| Step: 1
Training loss: 1.7637230157852173
Validation loss: 2.1484927336374917

Epoch: 5| Step: 2
Training loss: 1.9057706594467163
Validation loss: 2.144687235355377

Epoch: 5| Step: 3
Training loss: 2.308655261993408
Validation loss: 2.151188979546229

Epoch: 5| Step: 4
Training loss: 2.426253318786621
Validation loss: 2.151096006234487

Epoch: 5| Step: 5
Training loss: 2.204782009124756
Validation loss: 2.1514259427785873

Epoch: 5| Step: 6
Training loss: 2.28879976272583
Validation loss: 2.147554854551951

Epoch: 5| Step: 7
Training loss: 2.561830997467041
Validation loss: 2.1432255854209266

Epoch: 5| Step: 8
Training loss: 2.8761911392211914
Validation loss: 2.142268488804499

Epoch: 5| Step: 9
Training loss: 2.5263354778289795
Validation loss: 2.1441940516233444

Epoch: 5| Step: 10
Training loss: 2.00476336479187
Validation loss: 2.143731047709783

Epoch: 5| Step: 11
Training loss: 3.690485954284668
Validation loss: 2.139280214905739

Epoch: 64| Step: 0
Training loss: 2.653412342071533
Validation loss: 2.1415861000617347

Epoch: 5| Step: 1
Training loss: 2.464900255203247
Validation loss: 2.1361043751239777

Epoch: 5| Step: 2
Training loss: 2.4643046855926514
Validation loss: 2.1335519601901374

Epoch: 5| Step: 3
Training loss: 2.1038966178894043
Validation loss: 2.133171637852987

Epoch: 5| Step: 4
Training loss: 2.4321682453155518
Validation loss: 2.1292391320069632

Epoch: 5| Step: 5
Training loss: 2.1634411811828613
Validation loss: 2.1337082535028458

Epoch: 5| Step: 6
Training loss: 2.2525248527526855
Validation loss: 2.1346939504146576

Epoch: 5| Step: 7
Training loss: 2.045804262161255
Validation loss: 2.1263623336950936

Epoch: 5| Step: 8
Training loss: 1.7867906093597412
Validation loss: 2.124205951889356

Epoch: 5| Step: 9
Training loss: 2.2619822025299072
Validation loss: 2.119917720556259

Epoch: 5| Step: 10
Training loss: 2.2451958656311035
Validation loss: 2.1267559776703515

Epoch: 5| Step: 11
Training loss: 3.7709245681762695
Validation loss: 2.128095363577207

Epoch: 65| Step: 0
Training loss: 2.452857494354248
Validation loss: 2.1445304105679193

Epoch: 5| Step: 1
Training loss: 2.1595990657806396
Validation loss: 2.1354796836773553

Epoch: 5| Step: 2
Training loss: 1.6455720663070679
Validation loss: 2.131283034880956

Epoch: 5| Step: 3
Training loss: 1.6814571619033813
Validation loss: 2.127252067128817

Epoch: 5| Step: 4
Training loss: 2.3743784427642822
Validation loss: 2.121651659409205

Epoch: 5| Step: 5
Training loss: 2.8200325965881348
Validation loss: 2.1186635345220566

Epoch: 5| Step: 6
Training loss: 2.5068957805633545
Validation loss: 2.125095009803772

Epoch: 5| Step: 7
Training loss: 2.6908867359161377
Validation loss: 2.118499423066775

Epoch: 5| Step: 8
Training loss: 2.3801872730255127
Validation loss: 2.125706742207209

Epoch: 5| Step: 9
Training loss: 2.7785544395446777
Validation loss: 2.1257428576548896

Epoch: 5| Step: 10
Training loss: 1.8653730154037476
Validation loss: 2.1247609108686447

Epoch: 5| Step: 11
Training loss: 1.5145782232284546
Validation loss: 2.117568532625834

Epoch: 66| Step: 0
Training loss: 2.619250774383545
Validation loss: 2.118303711215655

Epoch: 5| Step: 1
Training loss: 2.550630807876587
Validation loss: 2.1158392826716104

Epoch: 5| Step: 2
Training loss: 2.0512187480926514
Validation loss: 2.110930254062017

Epoch: 5| Step: 3
Training loss: 2.2338993549346924
Validation loss: 2.1128863443930945

Epoch: 5| Step: 4
Training loss: 1.7554035186767578
Validation loss: 2.111304755012194

Epoch: 5| Step: 5
Training loss: 2.250213146209717
Validation loss: 2.112018113334974

Epoch: 5| Step: 6
Training loss: 2.0961737632751465
Validation loss: 2.1060136606295905

Epoch: 5| Step: 7
Training loss: 2.2191882133483887
Validation loss: 2.108825162053108

Epoch: 5| Step: 8
Training loss: 2.622285842895508
Validation loss: 2.101333533724149

Epoch: 5| Step: 9
Training loss: 2.76810359954834
Validation loss: 2.1022235453128815

Epoch: 5| Step: 10
Training loss: 1.885932207107544
Validation loss: 2.1000815530618033

Epoch: 5| Step: 11
Training loss: 1.8816337585449219
Validation loss: 2.0937861998875937

Epoch: 67| Step: 0
Training loss: 2.7582850456237793
Validation loss: 2.091958314180374

Epoch: 5| Step: 1
Training loss: 2.2386245727539062
Validation loss: 2.095894252260526

Epoch: 5| Step: 2
Training loss: 2.0905802249908447
Validation loss: 2.0992763141791024

Epoch: 5| Step: 3
Training loss: 1.6471261978149414
Validation loss: 2.0949776818354926

Epoch: 5| Step: 4
Training loss: 3.029233455657959
Validation loss: 2.1053575028975806

Epoch: 5| Step: 5
Training loss: 2.703378200531006
Validation loss: 2.0959246357282004

Epoch: 5| Step: 6
Training loss: 2.258134365081787
Validation loss: 2.088592290878296

Epoch: 5| Step: 7
Training loss: 2.0943527221679688
Validation loss: 2.0911653389533362

Epoch: 5| Step: 8
Training loss: 1.911481499671936
Validation loss: 2.100752497712771

Epoch: 5| Step: 9
Training loss: 1.8789758682250977
Validation loss: 2.098465989033381

Epoch: 5| Step: 10
Training loss: 2.468552350997925
Validation loss: 2.090196361144384

Epoch: 5| Step: 11
Training loss: 1.6175340414047241
Validation loss: 2.09357225894928

Epoch: 68| Step: 0
Training loss: 1.8708667755126953
Validation loss: 2.0987229694922767

Epoch: 5| Step: 1
Training loss: 2.714498519897461
Validation loss: 2.088429719209671

Epoch: 5| Step: 2
Training loss: 2.4456264972686768
Validation loss: 2.085519919792811

Epoch: 5| Step: 3
Training loss: 2.0859169960021973
Validation loss: 2.08507210512956

Epoch: 5| Step: 4
Training loss: 1.782862663269043
Validation loss: 2.0750323881705603

Epoch: 5| Step: 5
Training loss: 2.7649967670440674
Validation loss: 2.0746349493662515

Epoch: 5| Step: 6
Training loss: 1.7144562005996704
Validation loss: 2.079555014769236

Epoch: 5| Step: 7
Training loss: 2.126303195953369
Validation loss: 2.08494425813357

Epoch: 5| Step: 8
Training loss: 2.8682398796081543
Validation loss: 2.0848228484392166

Epoch: 5| Step: 9
Training loss: 2.0008153915405273
Validation loss: 2.0805720339218774

Epoch: 5| Step: 10
Training loss: 2.4414663314819336
Validation loss: 2.0866948664188385

Epoch: 5| Step: 11
Training loss: 2.0701065063476562
Validation loss: 2.0816627144813538

Epoch: 69| Step: 0
Training loss: 1.9259464740753174
Validation loss: 2.0712363918622336

Epoch: 5| Step: 1
Training loss: 2.2674245834350586
Validation loss: 2.0687574247519174

Epoch: 5| Step: 2
Training loss: 2.4812283515930176
Validation loss: 2.0696263164281845

Epoch: 5| Step: 3
Training loss: 2.592297077178955
Validation loss: 2.0796354860067368

Epoch: 5| Step: 4
Training loss: 2.4141032695770264
Validation loss: 2.0872763295968375

Epoch: 5| Step: 5
Training loss: 2.3511970043182373
Validation loss: 2.0957638919353485

Epoch: 5| Step: 6
Training loss: 1.9196784496307373
Validation loss: 2.1014963189760842

Epoch: 5| Step: 7
Training loss: 1.9782756567001343
Validation loss: 2.1056723296642303

Epoch: 5| Step: 8
Training loss: 2.573361873626709
Validation loss: 2.1041247894366584

Epoch: 5| Step: 9
Training loss: 2.184737205505371
Validation loss: 2.1040120273828506

Epoch: 5| Step: 10
Training loss: 2.2244553565979004
Validation loss: 2.1025108148654303

Epoch: 5| Step: 11
Training loss: 2.4210362434387207
Validation loss: 2.108476862311363

Epoch: 70| Step: 0
Training loss: 2.046980381011963
Validation loss: 2.1022127916415534

Epoch: 5| Step: 1
Training loss: 2.3998560905456543
Validation loss: 2.0924835801124573

Epoch: 5| Step: 2
Training loss: 1.823865294456482
Validation loss: 2.090984736879667

Epoch: 5| Step: 3
Training loss: 2.3837220668792725
Validation loss: 2.092735692858696

Epoch: 5| Step: 4
Training loss: 2.1102194786071777
Validation loss: 2.0849746664365134

Epoch: 5| Step: 5
Training loss: 2.3570117950439453
Validation loss: 2.0868958135445914

Epoch: 5| Step: 6
Training loss: 2.386671543121338
Validation loss: 2.089268739024798

Epoch: 5| Step: 7
Training loss: 2.821262836456299
Validation loss: 2.0803591310977936

Epoch: 5| Step: 8
Training loss: 2.1291377544403076
Validation loss: 2.078367124001185

Epoch: 5| Step: 9
Training loss: 1.957088828086853
Validation loss: 2.077045187354088

Epoch: 5| Step: 10
Training loss: 2.3535358905792236
Validation loss: 2.076169808705648

Epoch: 5| Step: 11
Training loss: 3.0477190017700195
Validation loss: 2.0698454727729163

Epoch: 71| Step: 0
Training loss: 1.7483198642730713
Validation loss: 2.061598539352417

Epoch: 5| Step: 1
Training loss: 2.0795838832855225
Validation loss: 2.052190507451693

Epoch: 5| Step: 2
Training loss: 2.8456788063049316
Validation loss: 2.056656281153361

Epoch: 5| Step: 3
Training loss: 2.13429594039917
Validation loss: 2.068917195002238

Epoch: 5| Step: 4
Training loss: 1.827831506729126
Validation loss: 2.0765472998221717

Epoch: 5| Step: 5
Training loss: 2.3751702308654785
Validation loss: 2.0649011631806693

Epoch: 5| Step: 6
Training loss: 2.0505142211914062
Validation loss: 2.057103708386421

Epoch: 5| Step: 7
Training loss: 2.4984707832336426
Validation loss: 2.0568501353263855

Epoch: 5| Step: 8
Training loss: 2.4349780082702637
Validation loss: 2.050554573535919

Epoch: 5| Step: 9
Training loss: 1.929938554763794
Validation loss: 2.048321560025215

Epoch: 5| Step: 10
Training loss: 2.4766042232513428
Validation loss: 2.0496290226777396

Epoch: 5| Step: 11
Training loss: 3.1972455978393555
Validation loss: 2.0503639380137124

Epoch: 72| Step: 0
Training loss: 2.0492630004882812
Validation loss: 2.05298804740111

Epoch: 5| Step: 1
Training loss: 2.428492546081543
Validation loss: 2.0519162714481354

Epoch: 5| Step: 2
Training loss: 1.9516546726226807
Validation loss: 2.0585359930992126

Epoch: 5| Step: 3
Training loss: 2.400509834289551
Validation loss: 2.0576243797938027

Epoch: 5| Step: 4
Training loss: 1.964084267616272
Validation loss: 2.0584969172875085

Epoch: 5| Step: 5
Training loss: 2.7045083045959473
Validation loss: 2.053912416100502

Epoch: 5| Step: 6
Training loss: 2.297231435775757
Validation loss: 2.0521347373723984

Epoch: 5| Step: 7
Training loss: 2.4627513885498047
Validation loss: 2.053737665216128

Epoch: 5| Step: 8
Training loss: 1.9457101821899414
Validation loss: 2.054129699865977

Epoch: 5| Step: 9
Training loss: 2.3870997428894043
Validation loss: 2.050182968378067

Epoch: 5| Step: 10
Training loss: 2.0515265464782715
Validation loss: 2.051913728316625

Epoch: 5| Step: 11
Training loss: 1.7132238149642944
Validation loss: 2.0438896665970483

Epoch: 73| Step: 0
Training loss: 2.2441325187683105
Validation loss: 2.0422465403874717

Epoch: 5| Step: 1
Training loss: 2.477809429168701
Validation loss: 2.0473129401604333

Epoch: 5| Step: 2
Training loss: 2.4198951721191406
Validation loss: 2.0455620884895325

Epoch: 5| Step: 3
Training loss: 2.418226480484009
Validation loss: 2.050663083791733

Epoch: 5| Step: 4
Training loss: 2.4290289878845215
Validation loss: 2.046157717704773

Epoch: 5| Step: 5
Training loss: 1.9116477966308594
Validation loss: 2.047782689332962

Epoch: 5| Step: 6
Training loss: 2.228705883026123
Validation loss: 2.0473431100447974

Epoch: 5| Step: 7
Training loss: 1.5481361150741577
Validation loss: 2.0548859337965646

Epoch: 5| Step: 8
Training loss: 2.6352343559265137
Validation loss: 2.0474740266799927

Epoch: 5| Step: 9
Training loss: 2.5080924034118652
Validation loss: 2.047601953148842

Epoch: 5| Step: 10
Training loss: 1.7214244604110718
Validation loss: 2.0452532519896827

Epoch: 5| Step: 11
Training loss: 1.7829861640930176
Validation loss: 2.041080450018247

Epoch: 74| Step: 0
Training loss: 2.0798990726470947
Validation loss: 2.0444667438666024

Epoch: 5| Step: 1
Training loss: 2.098104476928711
Validation loss: 2.05012409389019

Epoch: 5| Step: 2
Training loss: 1.986538290977478
Validation loss: 2.0472534944613776

Epoch: 5| Step: 3
Training loss: 2.0982556343078613
Validation loss: 2.038041278719902

Epoch: 5| Step: 4
Training loss: 2.543497323989868
Validation loss: 2.0399277607599893

Epoch: 5| Step: 5
Training loss: 2.6257388591766357
Validation loss: 2.0391649901866913

Epoch: 5| Step: 6
Training loss: 2.3405990600585938
Validation loss: 2.047441447774569

Epoch: 5| Step: 7
Training loss: 2.0594990253448486
Validation loss: 2.060219317674637

Epoch: 5| Step: 8
Training loss: 2.0633187294006348
Validation loss: 2.060635725657145

Epoch: 5| Step: 9
Training loss: 2.119598865509033
Validation loss: 2.0724057157834372

Epoch: 5| Step: 10
Training loss: 2.518523693084717
Validation loss: 2.069838657975197

Epoch: 5| Step: 11
Training loss: 2.164372444152832
Validation loss: 2.0674332678318024

Epoch: 75| Step: 0
Training loss: 2.091817855834961
Validation loss: 2.0614488323529563

Epoch: 5| Step: 1
Training loss: 2.4084200859069824
Validation loss: 2.0507688572009406

Epoch: 5| Step: 2
Training loss: 2.51788067817688
Validation loss: 2.043858900666237

Epoch: 5| Step: 3
Training loss: 2.4087746143341064
Validation loss: 2.044841612378756

Epoch: 5| Step: 4
Training loss: 2.1033241748809814
Validation loss: 2.0375175327062607

Epoch: 5| Step: 5
Training loss: 1.7022444009780884
Validation loss: 2.038578818241755

Epoch: 5| Step: 6
Training loss: 2.5139453411102295
Validation loss: 2.0295360883076987

Epoch: 5| Step: 7
Training loss: 2.4063656330108643
Validation loss: 2.0306512812773385

Epoch: 5| Step: 8
Training loss: 1.901850938796997
Validation loss: 2.023142466942469

Epoch: 5| Step: 9
Training loss: 2.557234525680542
Validation loss: 2.029158999522527

Epoch: 5| Step: 10
Training loss: 1.8758289813995361
Validation loss: 2.030286267399788

Epoch: 5| Step: 11
Training loss: 2.141289472579956
Validation loss: 2.035471280415853

Epoch: 76| Step: 0
Training loss: 2.258479595184326
Validation loss: 2.0486007630825043

Epoch: 5| Step: 1
Training loss: 2.342027187347412
Validation loss: 2.0588219662507377

Epoch: 5| Step: 2
Training loss: 2.482046127319336
Validation loss: 2.057515303293864

Epoch: 5| Step: 3
Training loss: 2.507296085357666
Validation loss: 2.0545739829540253

Epoch: 5| Step: 4
Training loss: 1.9069610834121704
Validation loss: 2.0462034245332084

Epoch: 5| Step: 5
Training loss: 2.0157318115234375
Validation loss: 2.045419529080391

Epoch: 5| Step: 6
Training loss: 2.1209611892700195
Validation loss: 2.042071372270584

Epoch: 5| Step: 7
Training loss: 2.1012871265411377
Validation loss: 2.0404841949542365

Epoch: 5| Step: 8
Training loss: 2.1169161796569824
Validation loss: 2.04406109948953

Epoch: 5| Step: 9
Training loss: 1.9101645946502686
Validation loss: 2.0339272866646447

Epoch: 5| Step: 10
Training loss: 2.7549538612365723
Validation loss: 2.0296186208724976

Epoch: 5| Step: 11
Training loss: 2.189201831817627
Validation loss: 2.026422599951426

Epoch: 77| Step: 0
Training loss: 2.277301788330078
Validation loss: 2.02805395424366

Epoch: 5| Step: 1
Training loss: 1.9892475605010986
Validation loss: 2.0361514538526535

Epoch: 5| Step: 2
Training loss: 1.8179991245269775
Validation loss: 2.0378754138946533

Epoch: 5| Step: 3
Training loss: 2.1483535766601562
Validation loss: 2.0401270389556885

Epoch: 5| Step: 4
Training loss: 2.6282596588134766
Validation loss: 2.0426597197850547

Epoch: 5| Step: 5
Training loss: 2.274576425552368
Validation loss: 2.0500938991705575

Epoch: 5| Step: 6
Training loss: 2.3455758094787598
Validation loss: 2.0439222306013107

Epoch: 5| Step: 7
Training loss: 2.3434462547302246
Validation loss: 2.0425154517094293

Epoch: 5| Step: 8
Training loss: 2.691905975341797
Validation loss: 2.043007751305898

Epoch: 5| Step: 9
Training loss: 2.3302485942840576
Validation loss: 2.0387304921944938

Epoch: 5| Step: 10
Training loss: 1.610784888267517
Validation loss: 2.0428982426722846

Epoch: 5| Step: 11
Training loss: 1.8089442253112793
Validation loss: 2.0377506415049234

Epoch: 78| Step: 0
Training loss: 1.7769314050674438
Validation loss: 2.035370503862699

Epoch: 5| Step: 1
Training loss: 2.054255962371826
Validation loss: 2.037601595123609

Epoch: 5| Step: 2
Training loss: 1.9723514318466187
Validation loss: 2.030463973681132

Epoch: 5| Step: 3
Training loss: 2.2534773349761963
Validation loss: 2.0224342246850333

Epoch: 5| Step: 4
Training loss: 2.120568037033081
Validation loss: 2.0280742744604745

Epoch: 5| Step: 5
Training loss: 2.3117661476135254
Validation loss: 2.026904066403707

Epoch: 5| Step: 6
Training loss: 1.8817579746246338
Validation loss: 2.031087319056193

Epoch: 5| Step: 7
Training loss: 3.077502489089966
Validation loss: 2.0246512442827225

Epoch: 5| Step: 8
Training loss: 1.9232778549194336
Validation loss: 2.019761006037394

Epoch: 5| Step: 9
Training loss: 2.5437045097351074
Validation loss: 2.021100014448166

Epoch: 5| Step: 10
Training loss: 2.5553195476531982
Validation loss: 2.0218440741300583

Epoch: 5| Step: 11
Training loss: 1.7444573640823364
Validation loss: 2.0220160533984504

Epoch: 79| Step: 0
Training loss: 2.27864408493042
Validation loss: 2.0207022726535797

Epoch: 5| Step: 1
Training loss: 1.9821970462799072
Validation loss: 2.0271117985248566

Epoch: 5| Step: 2
Training loss: 2.033329486846924
Validation loss: 2.029237022002538

Epoch: 5| Step: 3
Training loss: 2.047412395477295
Validation loss: 2.0222623298565545

Epoch: 5| Step: 4
Training loss: 2.1624977588653564
Validation loss: 2.0241309454043708

Epoch: 5| Step: 5
Training loss: 2.3562870025634766
Validation loss: 2.022883653640747

Epoch: 5| Step: 6
Training loss: 2.272322416305542
Validation loss: 2.027560239036878

Epoch: 5| Step: 7
Training loss: 1.9513752460479736
Validation loss: 2.0216794262329736

Epoch: 5| Step: 8
Training loss: 2.6412606239318848
Validation loss: 2.0319375346104303

Epoch: 5| Step: 9
Training loss: 2.2488341331481934
Validation loss: 2.0244600226481757

Epoch: 5| Step: 10
Training loss: 2.2212886810302734
Validation loss: 2.021500209967295

Epoch: 5| Step: 11
Training loss: 1.7987195253372192
Validation loss: 2.034642348686854

Epoch: 80| Step: 0
Training loss: 2.0143609046936035
Validation loss: 2.033678874373436

Epoch: 5| Step: 1
Training loss: 2.190981388092041
Validation loss: 2.047038028637568

Epoch: 5| Step: 2
Training loss: 2.0756187438964844
Validation loss: 2.0465139945348105

Epoch: 5| Step: 3
Training loss: 1.852283239364624
Validation loss: 2.0442542235056558

Epoch: 5| Step: 4
Training loss: 2.896979808807373
Validation loss: 2.0367131729920707

Epoch: 5| Step: 5
Training loss: 1.9496959447860718
Validation loss: 2.030913387735685

Epoch: 5| Step: 6
Training loss: 2.266993522644043
Validation loss: 2.016423389315605

Epoch: 5| Step: 7
Training loss: 2.14589262008667
Validation loss: 2.0259925623734794

Epoch: 5| Step: 8
Training loss: 2.278628349304199
Validation loss: 2.0142374287048974

Epoch: 5| Step: 9
Training loss: 2.240954637527466
Validation loss: 2.0290944625933967

Epoch: 5| Step: 10
Training loss: 2.3385391235351562
Validation loss: 2.020280823111534

Epoch: 5| Step: 11
Training loss: 2.6195316314697266
Validation loss: 2.0330247282981873

Epoch: 81| Step: 0
Training loss: 2.6284945011138916
Validation loss: 2.025981297095617

Epoch: 5| Step: 1
Training loss: 1.9613673686981201
Validation loss: 2.0321720937887826

Epoch: 5| Step: 2
Training loss: 1.7147047519683838
Validation loss: 2.030797893802325

Epoch: 5| Step: 3
Training loss: 2.26017427444458
Validation loss: 2.0385541021823883

Epoch: 5| Step: 4
Training loss: 2.3887295722961426
Validation loss: 2.0356458822886148

Epoch: 5| Step: 5
Training loss: 2.084338903427124
Validation loss: 2.0347639371951423

Epoch: 5| Step: 6
Training loss: 1.9827258586883545
Validation loss: 2.0286814272403717

Epoch: 5| Step: 7
Training loss: 2.149869680404663
Validation loss: 2.033474857608477

Epoch: 5| Step: 8
Training loss: 2.5409858226776123
Validation loss: 2.0288936297098794

Epoch: 5| Step: 9
Training loss: 2.44260573387146
Validation loss: 2.0238512804110846

Epoch: 5| Step: 10
Training loss: 2.404242753982544
Validation loss: 2.0211656341950097

Epoch: 5| Step: 11
Training loss: 0.8279288411140442
Validation loss: 2.020370900630951

Epoch: 82| Step: 0
Training loss: 2.1680445671081543
Validation loss: 2.01776651541392

Epoch: 5| Step: 1
Training loss: 2.800877332687378
Validation loss: 2.0225400974353156

Epoch: 5| Step: 2
Training loss: 1.687246322631836
Validation loss: 2.023253525296847

Epoch: 5| Step: 3
Training loss: 2.076402187347412
Validation loss: 2.0336217681566873

Epoch: 5| Step: 4
Training loss: 1.8162578344345093
Validation loss: 2.0388235300779343

Epoch: 5| Step: 5
Training loss: 2.389019727706909
Validation loss: 2.0390957991282144

Epoch: 5| Step: 6
Training loss: 2.468702554702759
Validation loss: 2.0340788811445236

Epoch: 5| Step: 7
Training loss: 2.2943649291992188
Validation loss: 2.026740645368894

Epoch: 5| Step: 8
Training loss: 2.3455708026885986
Validation loss: 2.019578898946444

Epoch: 5| Step: 9
Training loss: 2.16329288482666
Validation loss: 2.0223712076743445

Epoch: 5| Step: 10
Training loss: 2.1858694553375244
Validation loss: 2.0267193764448166

Epoch: 5| Step: 11
Training loss: 1.0659767389297485
Validation loss: 2.015025610725085

Epoch: 83| Step: 0
Training loss: 2.202333688735962
Validation loss: 2.0210504879554114

Epoch: 5| Step: 1
Training loss: 2.831326961517334
Validation loss: 2.01888740559419

Epoch: 5| Step: 2
Training loss: 1.9998623132705688
Validation loss: 2.0187031577030816

Epoch: 5| Step: 3
Training loss: 1.8929636478424072
Validation loss: 2.0156158804893494

Epoch: 5| Step: 4
Training loss: 1.5858474969863892
Validation loss: 2.0187795062859855

Epoch: 5| Step: 5
Training loss: 2.3131818771362305
Validation loss: 2.020374129215876

Epoch: 5| Step: 6
Training loss: 1.9593589305877686
Validation loss: 2.020468607544899

Epoch: 5| Step: 7
Training loss: 2.1783204078674316
Validation loss: 2.031737138827642

Epoch: 5| Step: 8
Training loss: 1.9547204971313477
Validation loss: 2.0302658329407373

Epoch: 5| Step: 9
Training loss: 2.4418208599090576
Validation loss: 2.0313439716895423

Epoch: 5| Step: 10
Training loss: 2.354156017303467
Validation loss: 2.0293077876170478

Epoch: 5| Step: 11
Training loss: 3.312934398651123
Validation loss: 2.0148186633984246

Epoch: 84| Step: 0
Training loss: 1.9060770273208618
Validation loss: 2.023100435733795

Epoch: 5| Step: 1
Training loss: 1.7746703624725342
Validation loss: 2.022120793660482

Epoch: 5| Step: 2
Training loss: 1.6797828674316406
Validation loss: 2.027798821528753

Epoch: 5| Step: 3
Training loss: 2.065761089324951
Validation loss: 2.0402882446845374

Epoch: 5| Step: 4
Training loss: 2.9268386363983154
Validation loss: 2.0436846067508063

Epoch: 5| Step: 5
Training loss: 2.4022603034973145
Validation loss: 2.045845856269201

Epoch: 5| Step: 6
Training loss: 2.3792920112609863
Validation loss: 2.047685677806536

Epoch: 5| Step: 7
Training loss: 2.061018705368042
Validation loss: 2.039077579975128

Epoch: 5| Step: 8
Training loss: 2.540597438812256
Validation loss: 2.04017906387647

Epoch: 5| Step: 9
Training loss: 2.4021406173706055
Validation loss: 2.0388915638128915

Epoch: 5| Step: 10
Training loss: 2.217540740966797
Validation loss: 2.0417084097862244

Epoch: 5| Step: 11
Training loss: 1.9781169891357422
Validation loss: 2.0344451516866684

Epoch: 85| Step: 0
Training loss: 2.1069960594177246
Validation loss: 2.0337156454722085

Epoch: 5| Step: 1
Training loss: 1.7697197198867798
Validation loss: 2.0274881968895593

Epoch: 5| Step: 2
Training loss: 2.6599855422973633
Validation loss: 2.023639361063639

Epoch: 5| Step: 3
Training loss: 1.9361531734466553
Validation loss: 2.01588266591231

Epoch: 5| Step: 4
Training loss: 1.8535354137420654
Validation loss: 2.019942050178846

Epoch: 5| Step: 5
Training loss: 2.0502820014953613
Validation loss: 2.0175483028093972

Epoch: 5| Step: 6
Training loss: 2.7342846393585205
Validation loss: 2.0241733888785043

Epoch: 5| Step: 7
Training loss: 2.31561279296875
Validation loss: 2.0356956670681634

Epoch: 5| Step: 8
Training loss: 1.7217849493026733
Validation loss: 2.0335878481467566

Epoch: 5| Step: 9
Training loss: 2.6338930130004883
Validation loss: 2.029782618085543

Epoch: 5| Step: 10
Training loss: 1.877937912940979
Validation loss: 2.0333621501922607

Epoch: 5| Step: 11
Training loss: 3.4060962200164795
Validation loss: 2.041347771883011

Epoch: 86| Step: 0
Training loss: 1.9344240427017212
Validation loss: 2.025003766020139

Epoch: 5| Step: 1
Training loss: 1.9375333786010742
Validation loss: 2.043202886978785

Epoch: 5| Step: 2
Training loss: 1.5433061122894287
Validation loss: 2.035579969485601

Epoch: 5| Step: 3
Training loss: 1.9234790802001953
Validation loss: 2.04237108429273

Epoch: 5| Step: 4
Training loss: 2.085435390472412
Validation loss: 2.0445341964562735

Epoch: 5| Step: 5
Training loss: 2.3901405334472656
Validation loss: 2.044590418537458

Epoch: 5| Step: 6
Training loss: 2.486832618713379
Validation loss: 2.028321628769239

Epoch: 5| Step: 7
Training loss: 2.372762441635132
Validation loss: 2.021999811132749

Epoch: 5| Step: 8
Training loss: 2.294128179550171
Validation loss: 2.0219667106866837

Epoch: 5| Step: 9
Training loss: 2.1685256958007812
Validation loss: 2.0229029456774392

Epoch: 5| Step: 10
Training loss: 2.8089706897735596
Validation loss: 2.024016097187996

Epoch: 5| Step: 11
Training loss: 1.4980778694152832
Validation loss: 2.0198277036348977

Epoch: 87| Step: 0
Training loss: 2.29736328125
Validation loss: 2.025147408246994

Epoch: 5| Step: 1
Training loss: 1.8059234619140625
Validation loss: 2.023005723953247

Epoch: 5| Step: 2
Training loss: 2.020613431930542
Validation loss: 2.0230563829342523

Epoch: 5| Step: 3
Training loss: 2.358023166656494
Validation loss: 2.015757535894712

Epoch: 5| Step: 4
Training loss: 1.5369141101837158
Validation loss: 2.030105302731196

Epoch: 5| Step: 5
Training loss: 2.2782979011535645
Validation loss: 2.015426605939865

Epoch: 5| Step: 6
Training loss: 2.029513120651245
Validation loss: 2.032803157965342

Epoch: 5| Step: 7
Training loss: 2.249413013458252
Validation loss: 2.0316527783870697

Epoch: 5| Step: 8
Training loss: 2.979057788848877
Validation loss: 2.037112901608149

Epoch: 5| Step: 9
Training loss: 1.7772338390350342
Validation loss: 2.0454685240983963

Epoch: 5| Step: 10
Training loss: 2.316389560699463
Validation loss: 2.0372600754102073

Epoch: 5| Step: 11
Training loss: 3.357178211212158
Validation loss: 2.035938322544098

Epoch: 88| Step: 0
Training loss: 2.272737979888916
Validation loss: 2.0214742372433343

Epoch: 5| Step: 1
Training loss: 2.1356589794158936
Validation loss: 2.0157318711280823

Epoch: 5| Step: 2
Training loss: 2.1918485164642334
Validation loss: 2.0193590372800827

Epoch: 5| Step: 3
Training loss: 2.0438220500946045
Validation loss: 2.021289865175883

Epoch: 5| Step: 4
Training loss: 2.3017802238464355
Validation loss: 2.033768763144811

Epoch: 5| Step: 5
Training loss: 1.707898736000061
Validation loss: 2.0273188402255378

Epoch: 5| Step: 6
Training loss: 2.369957447052002
Validation loss: 2.0387609402338662

Epoch: 5| Step: 7
Training loss: 1.9750347137451172
Validation loss: 2.0380260050296783

Epoch: 5| Step: 8
Training loss: 2.4114584922790527
Validation loss: 2.0403536011775336

Epoch: 5| Step: 9
Training loss: 2.4409565925598145
Validation loss: 2.0350856433312097

Epoch: 5| Step: 10
Training loss: 1.9446113109588623
Validation loss: 2.033508767684301

Epoch: 5| Step: 11
Training loss: 3.249629259109497
Validation loss: 2.0411574095487595

Epoch: 89| Step: 0
Training loss: 2.0758414268493652
Validation loss: 2.036673660079638

Epoch: 5| Step: 1
Training loss: 2.281440019607544
Validation loss: 2.032342736919721

Epoch: 5| Step: 2
Training loss: 2.5486197471618652
Validation loss: 2.037377958496412

Epoch: 5| Step: 3
Training loss: 2.313828229904175
Validation loss: 2.0281354437271752

Epoch: 5| Step: 4
Training loss: 2.4501843452453613
Validation loss: 2.029507373770078

Epoch: 5| Step: 5
Training loss: 2.451145648956299
Validation loss: 2.027579108874003

Epoch: 5| Step: 6
Training loss: 1.8515491485595703
Validation loss: 2.0282079627116523

Epoch: 5| Step: 7
Training loss: 2.247828245162964
Validation loss: 2.0187205324570336

Epoch: 5| Step: 8
Training loss: 1.5133754014968872
Validation loss: 2.022817090153694

Epoch: 5| Step: 9
Training loss: 1.948415994644165
Validation loss: 2.030352527896563

Epoch: 5| Step: 10
Training loss: 2.535045623779297
Validation loss: 2.03495916724205

Epoch: 5| Step: 11
Training loss: 0.8830523490905762
Validation loss: 2.0405191282431283

Epoch: 90| Step: 0
Training loss: 2.183563709259033
Validation loss: 2.0589044193426767

Epoch: 5| Step: 1
Training loss: 2.462803363800049
Validation loss: 2.092754786213239

Epoch: 5| Step: 2
Training loss: 2.0624592304229736
Validation loss: 2.088786001006762

Epoch: 5| Step: 3
Training loss: 2.1761133670806885
Validation loss: 2.0789021253585815

Epoch: 5| Step: 4
Training loss: 2.068227529525757
Validation loss: 2.0602451165517173

Epoch: 5| Step: 5
Training loss: 2.2989277839660645
Validation loss: 2.0563267966111503

Epoch: 5| Step: 6
Training loss: 2.3905155658721924
Validation loss: 2.0308829893668494

Epoch: 5| Step: 7
Training loss: 1.941978096961975
Validation loss: 2.020748327175776

Epoch: 5| Step: 8
Training loss: 1.9089622497558594
Validation loss: 2.0155645360549292

Epoch: 5| Step: 9
Training loss: 2.143273115158081
Validation loss: 2.0186570435762405

Epoch: 5| Step: 10
Training loss: 2.786736249923706
Validation loss: 2.0249943137168884

Epoch: 5| Step: 11
Training loss: 1.4621355533599854
Validation loss: 2.029348994294802

Epoch: 91| Step: 0
Training loss: 2.186805486679077
Validation loss: 2.0235851258039474

Epoch: 5| Step: 1
Training loss: 2.359494686126709
Validation loss: 2.0266453276077905

Epoch: 5| Step: 2
Training loss: 2.5038516521453857
Validation loss: 2.03411332766215

Epoch: 5| Step: 3
Training loss: 2.109950304031372
Validation loss: 2.0348705550034842

Epoch: 5| Step: 4
Training loss: 1.6338485479354858
Validation loss: 2.0178982317447662

Epoch: 5| Step: 5
Training loss: 2.291861057281494
Validation loss: 2.0116150875886283

Epoch: 5| Step: 6
Training loss: 1.8924671411514282
Validation loss: 2.0123927146196365

Epoch: 5| Step: 7
Training loss: 2.444892406463623
Validation loss: 2.0100345462560654

Epoch: 5| Step: 8
Training loss: 2.2300775051116943
Validation loss: 2.010546306769053

Epoch: 5| Step: 9
Training loss: 1.5762392282485962
Validation loss: 2.0089507699012756

Epoch: 5| Step: 10
Training loss: 2.387315034866333
Validation loss: 2.0099022686481476

Epoch: 5| Step: 11
Training loss: 3.539597749710083
Validation loss: 2.0233660340309143

Epoch: 92| Step: 0
Training loss: 2.1658458709716797
Validation loss: 2.0215098758538566

Epoch: 5| Step: 1
Training loss: 2.2120213508605957
Validation loss: 2.010628044605255

Epoch: 5| Step: 2
Training loss: 2.2800326347351074
Validation loss: 2.0133812626202903

Epoch: 5| Step: 3
Training loss: 2.5854594707489014
Validation loss: 2.008872300386429

Epoch: 5| Step: 4
Training loss: 1.8970634937286377
Validation loss: 2.011256585518519

Epoch: 5| Step: 5
Training loss: 2.1588356494903564
Validation loss: 2.0090680917104087

Epoch: 5| Step: 6
Training loss: 1.5278542041778564
Validation loss: 2.00816876689593

Epoch: 5| Step: 7
Training loss: 2.8629682064056396
Validation loss: 2.009278784195582

Epoch: 5| Step: 8
Training loss: 1.4162765741348267
Validation loss: 2.0099995136260986

Epoch: 5| Step: 9
Training loss: 2.422194719314575
Validation loss: 2.017258365948995

Epoch: 5| Step: 10
Training loss: 2.3689377307891846
Validation loss: 2.0125138610601425

Epoch: 5| Step: 11
Training loss: 1.1093209981918335
Validation loss: 2.013985057671865

Epoch: 93| Step: 0
Training loss: 1.9259408712387085
Validation loss: 2.0134471903244653

Epoch: 5| Step: 1
Training loss: 1.7539275884628296
Validation loss: 2.013757343093554

Epoch: 5| Step: 2
Training loss: 2.664052963256836
Validation loss: 2.0206707268953323

Epoch: 5| Step: 3
Training loss: 2.405219554901123
Validation loss: 2.027236580848694

Epoch: 5| Step: 4
Training loss: 1.9944355487823486
Validation loss: 2.035723184545835

Epoch: 5| Step: 5
Training loss: 2.111219882965088
Validation loss: 2.042006934682528

Epoch: 5| Step: 6
Training loss: 2.146716356277466
Validation loss: 2.0313651661078134

Epoch: 5| Step: 7
Training loss: 2.471083879470825
Validation loss: 2.0418489575386047

Epoch: 5| Step: 8
Training loss: 1.7272920608520508
Validation loss: 2.037385726968447

Epoch: 5| Step: 9
Training loss: 1.9661357402801514
Validation loss: 2.040926272670428

Epoch: 5| Step: 10
Training loss: 2.6030619144439697
Validation loss: 2.0313499172528586

Epoch: 5| Step: 11
Training loss: 2.4224328994750977
Validation loss: 2.0338183840115867

Epoch: 94| Step: 0
Training loss: 2.1756839752197266
Validation loss: 2.019534394145012

Epoch: 5| Step: 1
Training loss: 1.9662586450576782
Validation loss: 2.0216561754544577

Epoch: 5| Step: 2
Training loss: 2.142188310623169
Validation loss: 2.025174250205358

Epoch: 5| Step: 3
Training loss: 2.3016295433044434
Validation loss: 2.0280841588974

Epoch: 5| Step: 4
Training loss: 2.007681369781494
Validation loss: 2.0273212591807046

Epoch: 5| Step: 5
Training loss: 1.9468520879745483
Validation loss: 2.0290078272422156

Epoch: 5| Step: 6
Training loss: 2.498159885406494
Validation loss: 2.0356873124837875

Epoch: 5| Step: 7
Training loss: 2.4447102546691895
Validation loss: 2.0243760844071708

Epoch: 5| Step: 8
Training loss: 2.246577501296997
Validation loss: 2.0226469735304513

Epoch: 5| Step: 9
Training loss: 2.3183436393737793
Validation loss: 2.011670375863711

Epoch: 5| Step: 10
Training loss: 1.7216800451278687
Validation loss: 2.0160035540660224

Epoch: 5| Step: 11
Training loss: 1.6063079833984375
Validation loss: 2.0122832159201303

Epoch: 95| Step: 0
Training loss: 2.3739562034606934
Validation loss: 2.016059031089147

Epoch: 5| Step: 1
Training loss: 1.931102991104126
Validation loss: 2.02167779703935

Epoch: 5| Step: 2
Training loss: 2.924307107925415
Validation loss: 2.018990154067675

Epoch: 5| Step: 3
Training loss: 1.7348753213882446
Validation loss: 2.0210385620594025

Epoch: 5| Step: 4
Training loss: 2.413193464279175
Validation loss: 2.026595284541448

Epoch: 5| Step: 5
Training loss: 1.9499527215957642
Validation loss: 2.0290093570947647

Epoch: 5| Step: 6
Training loss: 2.2901980876922607
Validation loss: 2.0332314471403756

Epoch: 5| Step: 7
Training loss: 1.670861005783081
Validation loss: 2.0294918765624366

Epoch: 5| Step: 8
Training loss: 1.7623145580291748
Validation loss: 2.0390885223944983

Epoch: 5| Step: 9
Training loss: 1.958518624305725
Validation loss: 2.028413032492002

Epoch: 5| Step: 10
Training loss: 2.431800365447998
Validation loss: 2.0265026539564133

Epoch: 5| Step: 11
Training loss: 2.7740731239318848
Validation loss: 2.0274262577295303

Epoch: 96| Step: 0
Training loss: 2.0468668937683105
Validation loss: 2.0254701475302377

Epoch: 5| Step: 1
Training loss: 1.9793739318847656
Validation loss: 2.0371281256278357

Epoch: 5| Step: 2
Training loss: 2.4596989154815674
Validation loss: 2.0252512941757836

Epoch: 5| Step: 3
Training loss: 1.8632758855819702
Validation loss: 2.025750304261843

Epoch: 5| Step: 4
Training loss: 1.9273678064346313
Validation loss: 2.0342144121726355

Epoch: 5| Step: 5
Training loss: 2.3623950481414795
Validation loss: 2.011678288380305

Epoch: 5| Step: 6
Training loss: 1.920060157775879
Validation loss: 2.023833677172661

Epoch: 5| Step: 7
Training loss: 2.265143632888794
Validation loss: 2.019665072361628

Epoch: 5| Step: 8
Training loss: 2.6595942974090576
Validation loss: 2.0190223505099616

Epoch: 5| Step: 9
Training loss: 2.3829052448272705
Validation loss: 2.016772528489431

Epoch: 5| Step: 10
Training loss: 2.012308120727539
Validation loss: 2.018437554438909

Epoch: 5| Step: 11
Training loss: 0.9624357223510742
Validation loss: 2.0126740137736

Epoch: 97| Step: 0
Training loss: 1.8814847469329834
Validation loss: 2.016960695385933

Epoch: 5| Step: 1
Training loss: 1.8304812908172607
Validation loss: 2.0189222743113837

Epoch: 5| Step: 2
Training loss: 1.760589361190796
Validation loss: 2.0218050678571067

Epoch: 5| Step: 3
Training loss: 2.491788625717163
Validation loss: 2.029539783795675

Epoch: 5| Step: 4
Training loss: 2.1838583946228027
Validation loss: 2.029994840423266

Epoch: 5| Step: 5
Training loss: 2.122256278991699
Validation loss: 2.039890095591545

Epoch: 5| Step: 6
Training loss: 2.4127485752105713
Validation loss: 2.0356552402178445

Epoch: 5| Step: 7
Training loss: 2.0637764930725098
Validation loss: 2.0392211029926934

Epoch: 5| Step: 8
Training loss: 1.7666031122207642
Validation loss: 2.0282516926527023

Epoch: 5| Step: 9
Training loss: 2.5965583324432373
Validation loss: 2.037885457277298

Epoch: 5| Step: 10
Training loss: 2.597766399383545
Validation loss: 2.0266408373912177

Epoch: 5| Step: 11
Training loss: 2.212279796600342
Validation loss: 2.024985363086065

Epoch: 98| Step: 0
Training loss: 1.9448013305664062
Validation loss: 2.020317872365316

Epoch: 5| Step: 1
Training loss: 1.9840028285980225
Validation loss: 2.025555208325386

Epoch: 5| Step: 2
Training loss: 2.3064372539520264
Validation loss: 2.022670735915502

Epoch: 5| Step: 3
Training loss: 2.533454418182373
Validation loss: 2.026967446009318

Epoch: 5| Step: 4
Training loss: 2.3956873416900635
Validation loss: 2.026158327857653

Epoch: 5| Step: 5
Training loss: 2.2128467559814453
Validation loss: 2.0232779681682587

Epoch: 5| Step: 6
Training loss: 2.026319980621338
Validation loss: 2.0337817867596946

Epoch: 5| Step: 7
Training loss: 2.6729044914245605
Validation loss: 2.0247671554485955

Epoch: 5| Step: 8
Training loss: 2.021512031555176
Validation loss: 2.026288757721583

Epoch: 5| Step: 9
Training loss: 1.7004048824310303
Validation loss: 2.018522545695305

Epoch: 5| Step: 10
Training loss: 1.8644723892211914
Validation loss: 2.020035967230797

Epoch: 5| Step: 11
Training loss: 2.2823500633239746
Validation loss: 2.0213384280602136

Epoch: 99| Step: 0
Training loss: 2.2269110679626465
Validation loss: 2.011212080717087

Epoch: 5| Step: 1
Training loss: 2.1352176666259766
Validation loss: 2.0249992857376733

Epoch: 5| Step: 2
Training loss: 1.2620896100997925
Validation loss: 2.0294183244307837

Epoch: 5| Step: 3
Training loss: 2.1053457260131836
Validation loss: 2.0377839654684067

Epoch: 5| Step: 4
Training loss: 2.2226648330688477
Validation loss: 2.031443511446317

Epoch: 5| Step: 5
Training loss: 2.3459630012512207
Validation loss: 2.0480331977208457

Epoch: 5| Step: 6
Training loss: 2.0580267906188965
Validation loss: 2.049413854877154

Epoch: 5| Step: 7
Training loss: 2.573261260986328
Validation loss: 2.061342050631841

Epoch: 5| Step: 8
Training loss: 2.888054847717285
Validation loss: 2.0624460726976395

Epoch: 5| Step: 9
Training loss: 2.3163657188415527
Validation loss: 2.054831956823667

Epoch: 5| Step: 10
Training loss: 1.763523817062378
Validation loss: 2.0285035520792007

Epoch: 5| Step: 11
Training loss: 2.10744047164917
Validation loss: 2.020765999952952

Epoch: 100| Step: 0
Training loss: 1.6196238994598389
Validation loss: 2.0155026962359748

Epoch: 5| Step: 1
Training loss: 2.1517035961151123
Validation loss: 2.0097066313028336

Epoch: 5| Step: 2
Training loss: 2.3928043842315674
Validation loss: 2.0196707447369895

Epoch: 5| Step: 3
Training loss: 1.9231395721435547
Validation loss: 2.0221212406953177

Epoch: 5| Step: 4
Training loss: 2.067101240158081
Validation loss: 2.020876715580622

Epoch: 5| Step: 5
Training loss: 2.037822723388672
Validation loss: 2.025155479709307

Epoch: 5| Step: 6
Training loss: 2.162900686264038
Validation loss: 2.0225862165292106

Epoch: 5| Step: 7
Training loss: 1.836620569229126
Validation loss: 2.023915926615397

Epoch: 5| Step: 8
Training loss: 2.488189220428467
Validation loss: 2.027029832204183

Epoch: 5| Step: 9
Training loss: 2.2993876934051514
Validation loss: 2.0287624448537827

Epoch: 5| Step: 10
Training loss: 2.3661017417907715
Validation loss: 2.024059772491455

Epoch: 5| Step: 11
Training loss: 3.854830265045166
Validation loss: 2.021179919441541

Epoch: 101| Step: 0
Training loss: 2.0919766426086426
Validation loss: 2.013594006498655

Epoch: 5| Step: 1
Training loss: 2.2378859519958496
Validation loss: 2.0264740139245987

Epoch: 5| Step: 2
Training loss: 2.4563817977905273
Validation loss: 2.02662293612957

Epoch: 5| Step: 3
Training loss: 1.762734055519104
Validation loss: 2.053771143158277

Epoch: 5| Step: 4
Training loss: 2.4673023223876953
Validation loss: 2.0712281316518784

Epoch: 5| Step: 5
Training loss: 2.3743579387664795
Validation loss: 2.072633629043897

Epoch: 5| Step: 6
Training loss: 1.92428457736969
Validation loss: 2.073682909210523

Epoch: 5| Step: 7
Training loss: 1.7893577814102173
Validation loss: 2.058966582020124

Epoch: 5| Step: 8
Training loss: 2.433486223220825
Validation loss: 2.047703837354978

Epoch: 5| Step: 9
Training loss: 2.1363449096679688
Validation loss: 2.0405568381150565

Epoch: 5| Step: 10
Training loss: 2.0575594902038574
Validation loss: 2.0293526500463486

Epoch: 5| Step: 11
Training loss: 2.1725239753723145
Validation loss: 2.0288707266251245

Epoch: 102| Step: 0
Training loss: 2.1560122966766357
Validation loss: 2.017520929376284

Epoch: 5| Step: 1
Training loss: 1.9378427267074585
Validation loss: 2.003935550649961

Epoch: 5| Step: 2
Training loss: 2.3813111782073975
Validation loss: 2.010459214448929

Epoch: 5| Step: 3
Training loss: 1.986806869506836
Validation loss: 2.006055697798729

Epoch: 5| Step: 4
Training loss: 1.7764686346054077
Validation loss: 2.0069672763347626

Epoch: 5| Step: 5
Training loss: 2.104215383529663
Validation loss: 2.0122703512509665

Epoch: 5| Step: 6
Training loss: 2.4617111682891846
Validation loss: 2.003870258728663

Epoch: 5| Step: 7
Training loss: 2.3366246223449707
Validation loss: 2.0114725083112717

Epoch: 5| Step: 8
Training loss: 2.518310070037842
Validation loss: 2.0102137625217438

Epoch: 5| Step: 9
Training loss: 2.1199278831481934
Validation loss: 2.0233319153388343

Epoch: 5| Step: 10
Training loss: 1.7792308330535889
Validation loss: 2.020514488220215

Epoch: 5| Step: 11
Training loss: 1.6126457452774048
Validation loss: 2.016555959979693

Epoch: 103| Step: 0
Training loss: 2.3329696655273438
Validation loss: 2.0287391940752664

Epoch: 5| Step: 1
Training loss: 1.930270791053772
Validation loss: 2.0287877917289734

Epoch: 5| Step: 2
Training loss: 1.930212378501892
Validation loss: 2.0287779768308005

Epoch: 5| Step: 3
Training loss: 1.7936944961547852
Validation loss: 2.0366635421911874

Epoch: 5| Step: 4
Training loss: 2.3705849647521973
Validation loss: 2.039360299706459

Epoch: 5| Step: 5
Training loss: 2.334801435470581
Validation loss: 2.041000028451284

Epoch: 5| Step: 6
Training loss: 1.900455117225647
Validation loss: 2.038097381591797

Epoch: 5| Step: 7
Training loss: 2.311509609222412
Validation loss: 2.0349512497584024

Epoch: 5| Step: 8
Training loss: 2.1614773273468018
Validation loss: 2.031175742546717

Epoch: 5| Step: 9
Training loss: 2.0747549533843994
Validation loss: 2.0211190382639566

Epoch: 5| Step: 10
Training loss: 2.1557579040527344
Validation loss: 2.0175408869981766

Epoch: 5| Step: 11
Training loss: 2.5811104774475098
Validation loss: 2.0087371269861856

Epoch: 104| Step: 0
Training loss: 1.821192741394043
Validation loss: 2.003088648120562

Epoch: 5| Step: 1
Training loss: 2.1501102447509766
Validation loss: 2.0068368911743164

Epoch: 5| Step: 2
Training loss: 2.4436843395233154
Validation loss: 2.007309228181839

Epoch: 5| Step: 3
Training loss: 2.5087814331054688
Validation loss: 2.0089015811681747

Epoch: 5| Step: 4
Training loss: 2.240011215209961
Validation loss: 2.0178391337394714

Epoch: 5| Step: 5
Training loss: 2.8724944591522217
Validation loss: 2.012086590131124

Epoch: 5| Step: 6
Training loss: 1.688267469406128
Validation loss: 2.014882137378057

Epoch: 5| Step: 7
Training loss: 1.808044672012329
Validation loss: 2.0174313485622406

Epoch: 5| Step: 8
Training loss: 2.2223477363586426
Validation loss: 2.019006366531054

Epoch: 5| Step: 9
Training loss: 1.7008947134017944
Validation loss: 2.0217841068903604

Epoch: 5| Step: 10
Training loss: 1.9795764684677124
Validation loss: 2.0315751234690347

Epoch: 5| Step: 11
Training loss: 2.5493054389953613
Validation loss: 2.0220873604218164

Epoch: 105| Step: 0
Training loss: 2.3992838859558105
Validation loss: 2.0285132378339767

Epoch: 5| Step: 1
Training loss: 2.158895969390869
Validation loss: 2.0179076145092645

Epoch: 5| Step: 2
Training loss: 2.2157981395721436
Validation loss: 2.0248940785725913

Epoch: 5| Step: 3
Training loss: 2.027390956878662
Validation loss: 2.0291300068298974

Epoch: 5| Step: 4
Training loss: 1.5518347024917603
Validation loss: 2.0282968332370124

Epoch: 5| Step: 5
Training loss: 2.384624481201172
Validation loss: 2.0309544702370963

Epoch: 5| Step: 6
Training loss: 1.783359169960022
Validation loss: 2.038450747728348

Epoch: 5| Step: 7
Training loss: 1.992354154586792
Validation loss: 2.025885373353958

Epoch: 5| Step: 8
Training loss: 2.2054667472839355
Validation loss: 2.033601090312004

Epoch: 5| Step: 9
Training loss: 2.0664501190185547
Validation loss: 2.024923582871755

Epoch: 5| Step: 10
Training loss: 2.2642180919647217
Validation loss: 2.028730889161428

Epoch: 5| Step: 11
Training loss: 2.88608717918396
Validation loss: 2.0257413585980735

Epoch: 106| Step: 0
Training loss: 2.732055902481079
Validation loss: 2.026382947961489

Epoch: 5| Step: 1
Training loss: 2.056696653366089
Validation loss: 2.021475891272227

Epoch: 5| Step: 2
Training loss: 2.010762929916382
Validation loss: 2.027163709203402

Epoch: 5| Step: 3
Training loss: 1.8264977931976318
Validation loss: 2.0257738580306373

Epoch: 5| Step: 4
Training loss: 2.08245849609375
Validation loss: 2.0235307216644287

Epoch: 5| Step: 5
Training loss: 2.409961223602295
Validation loss: 2.0326664994160333

Epoch: 5| Step: 6
Training loss: 1.4539326429367065
Validation loss: 2.032909279068311

Epoch: 5| Step: 7
Training loss: 2.53532338142395
Validation loss: 2.0292599548896155

Epoch: 5| Step: 8
Training loss: 2.142653226852417
Validation loss: 2.037071322401365

Epoch: 5| Step: 9
Training loss: 2.055689811706543
Validation loss: 2.0269934137662253

Epoch: 5| Step: 10
Training loss: 2.290416717529297
Validation loss: 2.0193354388078055

Epoch: 5| Step: 11
Training loss: 1.2582554817199707
Validation loss: 2.025189613302549

Epoch: 107| Step: 0
Training loss: 1.89333975315094
Validation loss: 2.0303057730197906

Epoch: 5| Step: 1
Training loss: 2.4535975456237793
Validation loss: 2.0218631674846015

Epoch: 5| Step: 2
Training loss: 1.8599426746368408
Validation loss: 2.0155351708332696

Epoch: 5| Step: 3
Training loss: 2.381181240081787
Validation loss: 2.0135861535867057

Epoch: 5| Step: 4
Training loss: 2.409541130065918
Validation loss: 2.018800213932991

Epoch: 5| Step: 5
Training loss: 1.8933197259902954
Validation loss: 2.023131802678108

Epoch: 5| Step: 6
Training loss: 2.3555729389190674
Validation loss: 2.014622593919436

Epoch: 5| Step: 7
Training loss: 1.842864751815796
Validation loss: 2.0153016299009323

Epoch: 5| Step: 8
Training loss: 2.2041547298431396
Validation loss: 2.022240847349167

Epoch: 5| Step: 9
Training loss: 2.0594043731689453
Validation loss: 2.029730091492335

Epoch: 5| Step: 10
Training loss: 1.9411637783050537
Validation loss: 2.022682100534439

Epoch: 5| Step: 11
Training loss: 1.6444008350372314
Validation loss: 2.025159001350403

Epoch: 108| Step: 0
Training loss: 2.376979351043701
Validation loss: 2.028411015868187

Epoch: 5| Step: 1
Training loss: 2.5693728923797607
Validation loss: 2.0219765454530716

Epoch: 5| Step: 2
Training loss: 2.211935520172119
Validation loss: 2.021634648243586

Epoch: 5| Step: 3
Training loss: 2.295912265777588
Validation loss: 2.0269920329252877

Epoch: 5| Step: 4
Training loss: 1.684099555015564
Validation loss: 2.0290543188651404

Epoch: 5| Step: 5
Training loss: 1.971533179283142
Validation loss: 2.0201543122529984

Epoch: 5| Step: 6
Training loss: 1.691663384437561
Validation loss: 2.0222874681154885

Epoch: 5| Step: 7
Training loss: 2.414590358734131
Validation loss: 2.033071587483088

Epoch: 5| Step: 8
Training loss: 2.1592812538146973
Validation loss: 2.0189629197120667

Epoch: 5| Step: 9
Training loss: 2.3572940826416016
Validation loss: 2.0228162556886673

Epoch: 5| Step: 10
Training loss: 1.7858806848526
Validation loss: 2.0258410423994064

Epoch: 5| Step: 11
Training loss: 1.6753545999526978
Validation loss: 2.022217651208242

Epoch: 109| Step: 0
Training loss: 2.1642050743103027
Validation loss: 2.0231576959292092

Epoch: 5| Step: 1
Training loss: 1.878577470779419
Validation loss: 2.0204524795214334

Epoch: 5| Step: 2
Training loss: 1.6684057712554932
Validation loss: 2.0230620553096137

Epoch: 5| Step: 3
Training loss: 2.430183172225952
Validation loss: 2.0224570085604987

Epoch: 5| Step: 4
Training loss: 1.4490845203399658
Validation loss: 2.0226868093013763

Epoch: 5| Step: 5
Training loss: 2.0988688468933105
Validation loss: 2.0182286401589713

Epoch: 5| Step: 6
Training loss: 2.258749485015869
Validation loss: 2.019160951177279

Epoch: 5| Step: 7
Training loss: 2.318216323852539
Validation loss: 2.029742479324341

Epoch: 5| Step: 8
Training loss: 2.604965925216675
Validation loss: 2.0240784784158072

Epoch: 5| Step: 9
Training loss: 1.9174079895019531
Validation loss: 2.026169031858444

Epoch: 5| Step: 10
Training loss: 2.418851375579834
Validation loss: 2.025875916083654

Epoch: 5| Step: 11
Training loss: 2.0441675186157227
Validation loss: 2.0257320255041122

Epoch: 110| Step: 0
Training loss: 1.7405140399932861
Validation loss: 2.023097982009252

Epoch: 5| Step: 1
Training loss: 2.0528407096862793
Validation loss: 2.0201358795166016

Epoch: 5| Step: 2
Training loss: 2.1062986850738525
Validation loss: 2.033189927538236

Epoch: 5| Step: 3
Training loss: 2.3219027519226074
Validation loss: 2.025895675023397

Epoch: 5| Step: 4
Training loss: 2.280324697494507
Validation loss: 2.010522579153379

Epoch: 5| Step: 5
Training loss: 2.0705466270446777
Validation loss: 2.017685517668724

Epoch: 5| Step: 6
Training loss: 1.9360618591308594
Validation loss: 2.0276498198509216

Epoch: 5| Step: 7
Training loss: 2.191488742828369
Validation loss: 2.027802214026451

Epoch: 5| Step: 8
Training loss: 2.1933817863464355
Validation loss: 2.0283420781294503

Epoch: 5| Step: 9
Training loss: 1.887137770652771
Validation loss: 2.0290077279011407

Epoch: 5| Step: 10
Training loss: 2.4482614994049072
Validation loss: 2.0301509648561478

Epoch: 5| Step: 11
Training loss: 1.7972345352172852
Validation loss: 2.0280425399541855

Epoch: 111| Step: 0
Training loss: 2.121725082397461
Validation loss: 2.01443812251091

Epoch: 5| Step: 1
Training loss: 1.559480905532837
Validation loss: 2.0222011109193168

Epoch: 5| Step: 2
Training loss: 2.312849760055542
Validation loss: 2.0193043053150177

Epoch: 5| Step: 3
Training loss: 2.1551899909973145
Validation loss: 2.0188245375951133

Epoch: 5| Step: 4
Training loss: 2.215562105178833
Validation loss: 2.0334369291861853

Epoch: 5| Step: 5
Training loss: 2.0468735694885254
Validation loss: 2.0263943672180176

Epoch: 5| Step: 6
Training loss: 2.5745320320129395
Validation loss: 2.0205638657013574

Epoch: 5| Step: 7
Training loss: 2.2777562141418457
Validation loss: 2.022173141439756

Epoch: 5| Step: 8
Training loss: 1.5217139720916748
Validation loss: 2.031463071703911

Epoch: 5| Step: 9
Training loss: 2.262305736541748
Validation loss: 2.036257639527321

Epoch: 5| Step: 10
Training loss: 2.085631847381592
Validation loss: 2.0361129393180213

Epoch: 5| Step: 11
Training loss: 2.8009097576141357
Validation loss: 2.031013250350952

Epoch: 112| Step: 0
Training loss: 2.0173141956329346
Validation loss: 2.024530087908109

Epoch: 5| Step: 1
Training loss: 2.2966256141662598
Validation loss: 2.0220191925764084

Epoch: 5| Step: 2
Training loss: 1.9123916625976562
Validation loss: 2.022657419244448

Epoch: 5| Step: 3
Training loss: 2.4646248817443848
Validation loss: 2.019172435005506

Epoch: 5| Step: 4
Training loss: 1.9207490682601929
Validation loss: 2.0199278195699057

Epoch: 5| Step: 5
Training loss: 1.5212218761444092
Validation loss: 2.026809647679329

Epoch: 5| Step: 6
Training loss: 2.578557014465332
Validation loss: 2.019599974155426

Epoch: 5| Step: 7
Training loss: 2.2621922492980957
Validation loss: 2.0238594909509025

Epoch: 5| Step: 8
Training loss: 1.9940078258514404
Validation loss: 2.02898999551932

Epoch: 5| Step: 9
Training loss: 2.135122776031494
Validation loss: 2.0192188819249473

Epoch: 5| Step: 10
Training loss: 2.177424907684326
Validation loss: 2.034354194998741

Epoch: 5| Step: 11
Training loss: 1.795800805091858
Validation loss: 2.0226874301830926

Epoch: 113| Step: 0
Training loss: 1.7475932836532593
Validation loss: 2.0195155640443168

Epoch: 5| Step: 1
Training loss: 2.5404205322265625
Validation loss: 2.0272530963023505

Epoch: 5| Step: 2
Training loss: 2.6402504444122314
Validation loss: 2.0180925180514655

Epoch: 5| Step: 3
Training loss: 2.0621657371520996
Validation loss: 2.0270134657621384

Epoch: 5| Step: 4
Training loss: 1.7415142059326172
Validation loss: 2.0179623564084372

Epoch: 5| Step: 5
Training loss: 2.123195171356201
Validation loss: 2.012836918234825

Epoch: 5| Step: 6
Training loss: 1.9397227764129639
Validation loss: 2.0222531259059906

Epoch: 5| Step: 7
Training loss: 1.9312976598739624
Validation loss: 2.022602061430613

Epoch: 5| Step: 8
Training loss: 2.188277244567871
Validation loss: 2.0138558397690454

Epoch: 5| Step: 9
Training loss: 2.612269878387451
Validation loss: 2.0170276711384454

Epoch: 5| Step: 10
Training loss: 1.892217993736267
Validation loss: 2.018254960576693

Epoch: 5| Step: 11
Training loss: 1.1279397010803223
Validation loss: 2.02580326795578

Epoch: 114| Step: 0
Training loss: 1.9357631206512451
Validation loss: 2.0230773240327835

Epoch: 5| Step: 1
Training loss: 2.1291513442993164
Validation loss: 2.0226620187362037

Epoch: 5| Step: 2
Training loss: 2.0049307346343994
Validation loss: 2.026351069410642

Epoch: 5| Step: 3
Training loss: 2.435412883758545
Validation loss: 2.018128385146459

Epoch: 5| Step: 4
Training loss: 2.452038288116455
Validation loss: 2.021618038415909

Epoch: 5| Step: 5
Training loss: 2.0232949256896973
Validation loss: 2.025411978363991

Epoch: 5| Step: 6
Training loss: 2.4783897399902344
Validation loss: 2.0307830770810447

Epoch: 5| Step: 7
Training loss: 1.4882938861846924
Validation loss: 2.0332537293434143

Epoch: 5| Step: 8
Training loss: 2.572308301925659
Validation loss: 2.0337266623973846

Epoch: 5| Step: 9
Training loss: 1.6953117847442627
Validation loss: 2.030090560515722

Epoch: 5| Step: 10
Training loss: 1.8659610748291016
Validation loss: 2.0269025713205338

Epoch: 5| Step: 11
Training loss: 2.298065185546875
Validation loss: 2.0296546270449958

Epoch: 115| Step: 0
Training loss: 2.053063154220581
Validation loss: 2.0163965870936713

Epoch: 5| Step: 1
Training loss: 1.9881126880645752
Validation loss: 2.0237972984711328

Epoch: 5| Step: 2
Training loss: 2.2476043701171875
Validation loss: 2.0272385478019714

Epoch: 5| Step: 3
Training loss: 2.133056640625
Validation loss: 2.0252379129330316

Epoch: 5| Step: 4
Training loss: 2.0267417430877686
Validation loss: 2.023299902677536

Epoch: 5| Step: 5
Training loss: 1.781585693359375
Validation loss: 2.02761510014534

Epoch: 5| Step: 6
Training loss: 2.0724527835845947
Validation loss: 2.026905352870623

Epoch: 5| Step: 7
Training loss: 2.332080602645874
Validation loss: 2.028188109397888

Epoch: 5| Step: 8
Training loss: 1.8448944091796875
Validation loss: 2.0347911516825357

Epoch: 5| Step: 9
Training loss: 2.0688207149505615
Validation loss: 2.039007544517517

Epoch: 5| Step: 10
Training loss: 2.547818899154663
Validation loss: 2.0408931225538254

Epoch: 5| Step: 11
Training loss: 2.109945297241211
Validation loss: 2.034389555454254

Epoch: 116| Step: 0
Training loss: 2.41772723197937
Validation loss: 2.027000774939855

Epoch: 5| Step: 1
Training loss: 2.0236656665802
Validation loss: 2.0303208579619727

Epoch: 5| Step: 2
Training loss: 2.216200351715088
Validation loss: 2.029469142357508

Epoch: 5| Step: 3
Training loss: 2.016488552093506
Validation loss: 2.0294877340396247

Epoch: 5| Step: 4
Training loss: 1.7692756652832031
Validation loss: 2.020347148180008

Epoch: 5| Step: 5
Training loss: 1.5626437664031982
Validation loss: 2.021318197250366

Epoch: 5| Step: 6
Training loss: 2.3078503608703613
Validation loss: 2.0254126141468682

Epoch: 5| Step: 7
Training loss: 1.7953517436981201
Validation loss: 2.027895783384641

Epoch: 5| Step: 8
Training loss: 2.3111987113952637
Validation loss: 2.019604747494062

Epoch: 5| Step: 9
Training loss: 2.1804118156433105
Validation loss: 2.0268492648998895

Epoch: 5| Step: 10
Training loss: 2.7478175163269043
Validation loss: 2.022495537996292

Epoch: 5| Step: 11
Training loss: 1.9800026416778564
Validation loss: 2.0189425547917685

Epoch: 117| Step: 0
Training loss: 2.0860538482666016
Validation loss: 2.0173163612683616

Epoch: 5| Step: 1
Training loss: 2.032000780105591
Validation loss: 2.022392153739929

Epoch: 5| Step: 2
Training loss: 1.7573401927947998
Validation loss: 2.0242325911919274

Epoch: 5| Step: 3
Training loss: 1.88467276096344
Validation loss: 2.0194285859664283

Epoch: 5| Step: 4
Training loss: 2.0835185050964355
Validation loss: 2.0222988526026406

Epoch: 5| Step: 5
Training loss: 2.2195706367492676
Validation loss: 2.0247628887494407

Epoch: 5| Step: 6
Training loss: 2.3421709537506104
Validation loss: 2.015450874964396

Epoch: 5| Step: 7
Training loss: 2.570324659347534
Validation loss: 2.011274993419647

Epoch: 5| Step: 8
Training loss: 2.3134727478027344
Validation loss: 2.0214275072018304

Epoch: 5| Step: 9
Training loss: 2.000026226043701
Validation loss: 2.0145188719034195

Epoch: 5| Step: 10
Training loss: 2.015787124633789
Validation loss: 2.011085664232572

Epoch: 5| Step: 11
Training loss: 2.467694044113159
Validation loss: 2.0195617576440177

Epoch: 118| Step: 0
Training loss: 2.304462432861328
Validation loss: 2.023968224724134

Epoch: 5| Step: 1
Training loss: 2.44824481010437
Validation loss: 2.0354277888933816

Epoch: 5| Step: 2
Training loss: 1.7321971654891968
Validation loss: 2.0315229098002114

Epoch: 5| Step: 3
Training loss: 2.2363123893737793
Validation loss: 2.0227761417627335

Epoch: 5| Step: 4
Training loss: 1.9199409484863281
Validation loss: 2.02776962518692

Epoch: 5| Step: 5
Training loss: 2.4690327644348145
Validation loss: 2.0136150270700455

Epoch: 5| Step: 6
Training loss: 2.1668448448181152
Validation loss: 2.015328675508499

Epoch: 5| Step: 7
Training loss: 1.4286409616470337
Validation loss: 2.023386523127556

Epoch: 5| Step: 8
Training loss: 2.412130832672119
Validation loss: 2.0232931325833

Epoch: 5| Step: 9
Training loss: 1.6690009832382202
Validation loss: 2.027568762501081

Epoch: 5| Step: 10
Training loss: 2.5732502937316895
Validation loss: 2.0198720693588257

Epoch: 5| Step: 11
Training loss: 1.7451589107513428
Validation loss: 2.0331320414940515

Epoch: 119| Step: 0
Training loss: 2.6440258026123047
Validation loss: 2.0251706540584564

Epoch: 5| Step: 1
Training loss: 2.2379655838012695
Validation loss: 2.0287116865317025

Epoch: 5| Step: 2
Training loss: 1.8202488422393799
Validation loss: 2.018755242228508

Epoch: 5| Step: 3
Training loss: 1.8909122943878174
Validation loss: 2.0234984954198203

Epoch: 5| Step: 4
Training loss: 1.915684461593628
Validation loss: 2.021230012178421

Epoch: 5| Step: 5
Training loss: 1.9356906414031982
Validation loss: 2.01691863934199

Epoch: 5| Step: 6
Training loss: 2.7042510509490967
Validation loss: 2.038039500514666

Epoch: 5| Step: 7
Training loss: 2.3835372924804688
Validation loss: 2.0257588575283685

Epoch: 5| Step: 8
Training loss: 1.5184242725372314
Validation loss: 2.020193596680959

Epoch: 5| Step: 9
Training loss: 1.7295970916748047
Validation loss: 2.016767740249634

Epoch: 5| Step: 10
Training loss: 2.3453001976013184
Validation loss: 2.014226034283638

Epoch: 5| Step: 11
Training loss: 2.1596264839172363
Validation loss: 2.0170781016349792

Epoch: 120| Step: 0
Training loss: 1.9286558628082275
Validation loss: 2.016732946038246

Epoch: 5| Step: 1
Training loss: 2.4299569129943848
Validation loss: 2.0144726932048798

Epoch: 5| Step: 2
Training loss: 2.087131977081299
Validation loss: 2.0163897573947906

Epoch: 5| Step: 3
Training loss: 1.935760498046875
Validation loss: 2.021901855866114

Epoch: 5| Step: 4
Training loss: 1.7892990112304688
Validation loss: 2.0226378738880157

Epoch: 5| Step: 5
Training loss: 2.498422145843506
Validation loss: 2.031102955341339

Epoch: 5| Step: 6
Training loss: 1.9891090393066406
Validation loss: 2.0282018929719925

Epoch: 5| Step: 7
Training loss: 2.1465072631835938
Validation loss: 2.0176159044106803

Epoch: 5| Step: 8
Training loss: 2.041149377822876
Validation loss: 2.0181917250156403

Epoch: 5| Step: 9
Training loss: 2.5734355449676514
Validation loss: 2.020556335647901

Epoch: 5| Step: 10
Training loss: 1.9444046020507812
Validation loss: 2.017610544959704

Epoch: 5| Step: 11
Training loss: 1.4796324968338013
Validation loss: 2.020837982495626

Epoch: 121| Step: 0
Training loss: 2.519782304763794
Validation loss: 2.020170455177625

Epoch: 5| Step: 1
Training loss: 2.255068302154541
Validation loss: 2.0292439460754395

Epoch: 5| Step: 2
Training loss: 1.8163816928863525
Validation loss: 2.028612087170283

Epoch: 5| Step: 3
Training loss: 2.2370617389678955
Validation loss: 2.041255757212639

Epoch: 5| Step: 4
Training loss: 1.6621309518814087
Validation loss: 2.047176947196325

Epoch: 5| Step: 5
Training loss: 2.4114267826080322
Validation loss: 2.036140119036039

Epoch: 5| Step: 6
Training loss: 2.139730215072632
Validation loss: 2.0219939947128296

Epoch: 5| Step: 7
Training loss: 1.7159706354141235
Validation loss: 2.0329382767279944

Epoch: 5| Step: 8
Training loss: 2.541907787322998
Validation loss: 2.027095079421997

Epoch: 5| Step: 9
Training loss: 1.9635711908340454
Validation loss: 2.017886201540629

Epoch: 5| Step: 10
Training loss: 2.0552818775177
Validation loss: 2.0170535892248154

Epoch: 5| Step: 11
Training loss: 3.411874294281006
Validation loss: 2.0274412681659064

Epoch: 122| Step: 0
Training loss: 2.2864813804626465
Validation loss: 2.0180794397989907

Epoch: 5| Step: 1
Training loss: 1.6389240026474
Validation loss: 2.0254295816024146

Epoch: 5| Step: 2
Training loss: 1.8190780878067017
Validation loss: 2.0144160638252893

Epoch: 5| Step: 3
Training loss: 2.5733535289764404
Validation loss: 2.017677774031957

Epoch: 5| Step: 4
Training loss: 2.240877389907837
Validation loss: 2.0243301143248877

Epoch: 5| Step: 5
Training loss: 1.9522044658660889
Validation loss: 2.020312711596489

Epoch: 5| Step: 6
Training loss: 1.7888273000717163
Validation loss: 2.0293681224187217

Epoch: 5| Step: 7
Training loss: 1.8512214422225952
Validation loss: 2.025651400287946

Epoch: 5| Step: 8
Training loss: 2.5587971210479736
Validation loss: 2.019688829779625

Epoch: 5| Step: 9
Training loss: 1.8812029361724854
Validation loss: 2.030383358399073

Epoch: 5| Step: 10
Training loss: 2.339736223220825
Validation loss: 2.0186112771431604

Epoch: 5| Step: 11
Training loss: 2.688143253326416
Validation loss: 2.03385724623998

Epoch: 123| Step: 0
Training loss: 2.5313079357147217
Validation loss: 2.0252933353185654

Epoch: 5| Step: 1
Training loss: 2.9349865913391113
Validation loss: 2.0215895622968674

Epoch: 5| Step: 2
Training loss: 1.550142765045166
Validation loss: 2.0186911821365356

Epoch: 5| Step: 3
Training loss: 2.4407989978790283
Validation loss: 2.0157558917999268

Epoch: 5| Step: 4
Training loss: 1.4701714515686035
Validation loss: 2.0236573268969855

Epoch: 5| Step: 5
Training loss: 2.178518295288086
Validation loss: 2.0281151682138443

Epoch: 5| Step: 6
Training loss: 2.4795870780944824
Validation loss: 2.0252887457609177

Epoch: 5| Step: 7
Training loss: 2.195084571838379
Validation loss: 2.032202069958051

Epoch: 5| Step: 8
Training loss: 1.4747264385223389
Validation loss: 2.0274018744627633

Epoch: 5| Step: 9
Training loss: 2.1330935955047607
Validation loss: 2.023408964276314

Epoch: 5| Step: 10
Training loss: 1.9046121835708618
Validation loss: 2.0159461150566735

Epoch: 5| Step: 11
Training loss: 1.5685136318206787
Validation loss: 2.0245915402968726

Epoch: 124| Step: 0
Training loss: 1.9042003154754639
Validation loss: 2.025139018893242

Epoch: 5| Step: 1
Training loss: 2.2879059314727783
Validation loss: 2.019447381297747

Epoch: 5| Step: 2
Training loss: 2.453019380569458
Validation loss: 2.03056134780248

Epoch: 5| Step: 3
Training loss: 2.3644237518310547
Validation loss: 2.028952807188034

Epoch: 5| Step: 4
Training loss: 1.8821489810943604
Validation loss: 2.029179031650225

Epoch: 5| Step: 5
Training loss: 2.122701406478882
Validation loss: 2.027780224879583

Epoch: 5| Step: 6
Training loss: 2.146393299102783
Validation loss: 2.0210763663053513

Epoch: 5| Step: 7
Training loss: 2.0349090099334717
Validation loss: 2.027053082982699

Epoch: 5| Step: 8
Training loss: 2.069288730621338
Validation loss: 2.0168229838212333

Epoch: 5| Step: 9
Training loss: 1.764204978942871
Validation loss: 2.0222522070010505

Epoch: 5| Step: 10
Training loss: 1.9230568408966064
Validation loss: 2.018383195002874

Epoch: 5| Step: 11
Training loss: 2.7075212001800537
Validation loss: 2.0305534303188324

Epoch: 125| Step: 0
Training loss: 1.9268033504486084
Validation loss: 2.0276229828596115

Epoch: 5| Step: 1
Training loss: 2.073521852493286
Validation loss: 2.037523423631986

Epoch: 5| Step: 2
Training loss: 2.7502970695495605
Validation loss: 2.0197375963131585

Epoch: 5| Step: 3
Training loss: 1.9226272106170654
Validation loss: 2.0307468424240747

Epoch: 5| Step: 4
Training loss: 2.1897196769714355
Validation loss: 2.0283953497807183

Epoch: 5| Step: 5
Training loss: 2.278743267059326
Validation loss: 2.02791890501976

Epoch: 5| Step: 6
Training loss: 1.6497948169708252
Validation loss: 2.021910031636556

Epoch: 5| Step: 7
Training loss: 1.9391292333602905
Validation loss: 2.0288445552190146

Epoch: 5| Step: 8
Training loss: 1.5801326036453247
Validation loss: 2.03106996913751

Epoch: 5| Step: 9
Training loss: 2.5061118602752686
Validation loss: 2.025957316160202

Epoch: 5| Step: 10
Training loss: 2.066603899002075
Validation loss: 2.0169797986745834

Epoch: 5| Step: 11
Training loss: 2.230581521987915
Validation loss: 2.0283390084902444

Epoch: 126| Step: 0
Training loss: 1.8795413970947266
Validation loss: 2.0260036389033

Epoch: 5| Step: 1
Training loss: 1.8145506381988525
Validation loss: 2.049483999609947

Epoch: 5| Step: 2
Training loss: 2.245835065841675
Validation loss: 2.054037074247996

Epoch: 5| Step: 3
Training loss: 1.9679820537567139
Validation loss: 2.077310159802437

Epoch: 5| Step: 4
Training loss: 2.2285022735595703
Validation loss: 2.0862020949522653

Epoch: 5| Step: 5
Training loss: 2.1380677223205566
Validation loss: 2.099088499943415

Epoch: 5| Step: 6
Training loss: 2.197937488555908
Validation loss: 2.0906231751044593

Epoch: 5| Step: 7
Training loss: 2.3131861686706543
Validation loss: 2.074512998263041

Epoch: 5| Step: 8
Training loss: 2.3980534076690674
Validation loss: 2.055058086911837

Epoch: 5| Step: 9
Training loss: 2.677006244659424
Validation loss: 2.0296657383441925

Epoch: 5| Step: 10
Training loss: 2.095670461654663
Validation loss: 2.029199113448461

Epoch: 5| Step: 11
Training loss: 2.0612921714782715
Validation loss: 2.0145600587129593

Epoch: 127| Step: 0
Training loss: 2.1123507022857666
Validation loss: 2.011892467737198

Epoch: 5| Step: 1
Training loss: 1.8402786254882812
Validation loss: 2.031134565671285

Epoch: 5| Step: 2
Training loss: 2.4846367835998535
Validation loss: 2.0258798797925315

Epoch: 5| Step: 3
Training loss: 1.8977127075195312
Validation loss: 2.034490684668223

Epoch: 5| Step: 4
Training loss: 1.6945617198944092
Validation loss: 2.0483177999655404

Epoch: 5| Step: 5
Training loss: 1.938894271850586
Validation loss: 2.0571697503328323

Epoch: 5| Step: 6
Training loss: 2.5103518962860107
Validation loss: 2.055919071038564

Epoch: 5| Step: 7
Training loss: 2.1356728076934814
Validation loss: 2.050305724143982

Epoch: 5| Step: 8
Training loss: 1.8099803924560547
Validation loss: 2.0474999845027924

Epoch: 5| Step: 9
Training loss: 2.085085153579712
Validation loss: 2.0583460877339044

Epoch: 5| Step: 10
Training loss: 2.981447696685791
Validation loss: 2.041592925786972

Epoch: 5| Step: 11
Training loss: 3.0402350425720215
Validation loss: 2.0384368201096854

Epoch: 128| Step: 0
Training loss: 1.8856347799301147
Validation loss: 2.028681437174479

Epoch: 5| Step: 1
Training loss: 2.218248128890991
Validation loss: 2.020067190130552

Epoch: 5| Step: 2
Training loss: 2.2704365253448486
Validation loss: 2.013854036728541

Epoch: 5| Step: 3
Training loss: 2.1158204078674316
Validation loss: 2.0110877454280853

Epoch: 5| Step: 4
Training loss: 2.5316696166992188
Validation loss: 2.0163171192010245

Epoch: 5| Step: 5
Training loss: 1.9594703912734985
Validation loss: 2.021131157875061

Epoch: 5| Step: 6
Training loss: 2.5323996543884277
Validation loss: 2.0222859531641006

Epoch: 5| Step: 7
Training loss: 2.2272791862487793
Validation loss: 2.022738908727964

Epoch: 5| Step: 8
Training loss: 1.6834850311279297
Validation loss: 2.015068287650744

Epoch: 5| Step: 9
Training loss: 1.9398167133331299
Validation loss: 2.015016923348109

Epoch: 5| Step: 10
Training loss: 2.076533794403076
Validation loss: 2.0124850422143936

Epoch: 5| Step: 11
Training loss: 1.2488477230072021
Validation loss: 2.013624206185341

Epoch: 129| Step: 0
Training loss: 1.6042499542236328
Validation loss: 2.0171933670838675

Epoch: 5| Step: 1
Training loss: 2.420764923095703
Validation loss: 2.0161465803782144

Epoch: 5| Step: 2
Training loss: 2.306617021560669
Validation loss: 2.0168802638848624

Epoch: 5| Step: 3
Training loss: 2.363516330718994
Validation loss: 2.025314599275589

Epoch: 5| Step: 4
Training loss: 2.0675034523010254
Validation loss: 2.026090686519941

Epoch: 5| Step: 5
Training loss: 2.2700722217559814
Validation loss: 2.0192325015862784

Epoch: 5| Step: 6
Training loss: 2.460728645324707
Validation loss: 2.023173049092293

Epoch: 5| Step: 7
Training loss: 1.6764637231826782
Validation loss: 2.0243760148684182

Epoch: 5| Step: 8
Training loss: 2.033585548400879
Validation loss: 2.025513137380282

Epoch: 5| Step: 9
Training loss: 2.002812623977661
Validation loss: 2.0285134265820184

Epoch: 5| Step: 10
Training loss: 1.7865917682647705
Validation loss: 2.0293664932250977

Epoch: 5| Step: 11
Training loss: 2.424588203430176
Validation loss: 2.030841499567032

Epoch: 130| Step: 0
Training loss: 2.4773035049438477
Validation loss: 2.0253255863984427

Epoch: 5| Step: 1
Training loss: 1.7312395572662354
Validation loss: 2.0163459479808807

Epoch: 5| Step: 2
Training loss: 2.255091905593872
Validation loss: 2.0279157906770706

Epoch: 5| Step: 3
Training loss: 1.880599021911621
Validation loss: 2.0368138204018273

Epoch: 5| Step: 4
Training loss: 2.182800769805908
Validation loss: 2.0191382815440497

Epoch: 5| Step: 5
Training loss: 2.3026771545410156
Validation loss: 2.0183873027563095

Epoch: 5| Step: 6
Training loss: 1.7420679330825806
Validation loss: 2.0290541698535285

Epoch: 5| Step: 7
Training loss: 2.2846169471740723
Validation loss: 2.029764915506045

Epoch: 5| Step: 8
Training loss: 1.9342418909072876
Validation loss: 2.028910999496778

Epoch: 5| Step: 9
Training loss: 1.8746964931488037
Validation loss: 2.033003658056259

Epoch: 5| Step: 10
Training loss: 2.557814598083496
Validation loss: 2.033687502145767

Epoch: 5| Step: 11
Training loss: 0.6355835199356079
Validation loss: 2.025465245048205

Epoch: 131| Step: 0
Training loss: 2.677597761154175
Validation loss: 2.031888564427694

Epoch: 5| Step: 1
Training loss: 2.0569865703582764
Validation loss: 2.033627917369207

Epoch: 5| Step: 2
Training loss: 2.0289199352264404
Validation loss: 2.0338307321071625

Epoch: 5| Step: 3
Training loss: 2.6207785606384277
Validation loss: 2.0346630066633224

Epoch: 5| Step: 4
Training loss: 1.8473613262176514
Validation loss: 2.041945288578669

Epoch: 5| Step: 5
Training loss: 2.298945665359497
Validation loss: 2.025871401031812

Epoch: 5| Step: 6
Training loss: 1.7438844442367554
Validation loss: 2.0294376214345298

Epoch: 5| Step: 7
Training loss: 1.7084242105484009
Validation loss: 2.032167375087738

Epoch: 5| Step: 8
Training loss: 2.450594663619995
Validation loss: 2.0310201694568

Epoch: 5| Step: 9
Training loss: 1.8222792148590088
Validation loss: 2.037689507007599

Epoch: 5| Step: 10
Training loss: 2.0405807495117188
Validation loss: 2.034907634059588

Epoch: 5| Step: 11
Training loss: 1.3077630996704102
Validation loss: 2.032903437813123

Epoch: 132| Step: 0
Training loss: 1.891646146774292
Validation loss: 2.0490670700867972

Epoch: 5| Step: 1
Training loss: 1.88568115234375
Validation loss: 2.0337569216887155

Epoch: 5| Step: 2
Training loss: 1.8607423305511475
Validation loss: 2.038258746266365

Epoch: 5| Step: 3
Training loss: 1.8929340839385986
Validation loss: 2.034266173839569

Epoch: 5| Step: 4
Training loss: 2.2868759632110596
Validation loss: 2.033848449587822

Epoch: 5| Step: 5
Training loss: 2.0336709022521973
Validation loss: 2.038778230547905

Epoch: 5| Step: 6
Training loss: 2.56638503074646
Validation loss: 2.0230080833037696

Epoch: 5| Step: 7
Training loss: 2.1815381050109863
Validation loss: 2.0255162914594016

Epoch: 5| Step: 8
Training loss: 2.3587071895599365
Validation loss: 2.0308261464039483

Epoch: 5| Step: 9
Training loss: 2.5506463050842285
Validation loss: 2.0280083368221917

Epoch: 5| Step: 10
Training loss: 1.634433388710022
Validation loss: 2.031538267930349

Epoch: 5| Step: 11
Training loss: 1.1425621509552002
Validation loss: 2.038956547776858

Epoch: 133| Step: 0
Training loss: 2.069153308868408
Validation loss: 2.033863455057144

Epoch: 5| Step: 1
Training loss: 2.202439308166504
Validation loss: 2.0415281554063163

Epoch: 5| Step: 2
Training loss: 1.9894239902496338
Validation loss: 2.034754236539205

Epoch: 5| Step: 3
Training loss: 1.927996277809143
Validation loss: 2.0332197099924088

Epoch: 5| Step: 4
Training loss: 2.249105930328369
Validation loss: 2.0329095870256424

Epoch: 5| Step: 5
Training loss: 1.918335199356079
Validation loss: 2.040685380498568

Epoch: 5| Step: 6
Training loss: 1.9332778453826904
Validation loss: 2.0391394098599753

Epoch: 5| Step: 7
Training loss: 2.2788009643554688
Validation loss: 2.0292493601640067

Epoch: 5| Step: 8
Training loss: 2.0769824981689453
Validation loss: 2.0314796368281045

Epoch: 5| Step: 9
Training loss: 2.3415591716766357
Validation loss: 2.03417561451594

Epoch: 5| Step: 10
Training loss: 2.078433036804199
Validation loss: 2.0342663129170737

Epoch: 5| Step: 11
Training loss: 1.878003478050232
Validation loss: 2.0416942288478217

Epoch: 134| Step: 0
Training loss: 1.9589742422103882
Validation loss: 2.040279229482015

Epoch: 5| Step: 1
Training loss: 1.9564603567123413
Validation loss: 2.0354682952165604

Epoch: 5| Step: 2
Training loss: 2.1888794898986816
Validation loss: 2.043927709261576

Epoch: 5| Step: 3
Training loss: 1.966920256614685
Validation loss: 2.0463943630456924

Epoch: 5| Step: 4
Training loss: 2.3128724098205566
Validation loss: 2.050087327758471

Epoch: 5| Step: 5
Training loss: 2.2271807193756104
Validation loss: 2.049085612098376

Epoch: 5| Step: 6
Training loss: 1.8807331323623657
Validation loss: 2.0487043311198554

Epoch: 5| Step: 7
Training loss: 2.360795497894287
Validation loss: 2.053082158168157

Epoch: 5| Step: 8
Training loss: 2.113767385482788
Validation loss: 2.0464310348033905

Epoch: 5| Step: 9
Training loss: 2.2507965564727783
Validation loss: 2.053633784254392

Epoch: 5| Step: 10
Training loss: 2.3749492168426514
Validation loss: 2.0476967493693032

Epoch: 5| Step: 11
Training loss: 2.508540391921997
Validation loss: 2.047610620657603

Epoch: 135| Step: 0
Training loss: 2.244546413421631
Validation loss: 2.049041206638018

Epoch: 5| Step: 1
Training loss: 2.410693883895874
Validation loss: 2.0494961539904275

Epoch: 5| Step: 2
Training loss: 1.8337700366973877
Validation loss: 2.041029671827952

Epoch: 5| Step: 3
Training loss: 1.9293301105499268
Validation loss: 2.031154125928879

Epoch: 5| Step: 4
Training loss: 2.5609371662139893
Validation loss: 2.0225254744291306

Epoch: 5| Step: 5
Training loss: 2.3089308738708496
Validation loss: 2.0249209652344384

Epoch: 5| Step: 6
Training loss: 1.7641050815582275
Validation loss: 2.021055127183596

Epoch: 5| Step: 7
Training loss: 1.6517292261123657
Validation loss: 2.020112559199333

Epoch: 5| Step: 8
Training loss: 2.244342803955078
Validation loss: 2.0127852956453958

Epoch: 5| Step: 9
Training loss: 1.9833366870880127
Validation loss: 2.0118665794531503

Epoch: 5| Step: 10
Training loss: 2.3072352409362793
Validation loss: 2.014348496993383

Epoch: 5| Step: 11
Training loss: 2.14300274848938
Validation loss: 2.020519440372785

Epoch: 136| Step: 0
Training loss: 2.0026304721832275
Validation loss: 2.023936773339907

Epoch: 5| Step: 1
Training loss: 1.953002691268921
Validation loss: 2.0461955120166144

Epoch: 5| Step: 2
Training loss: 2.048549175262451
Validation loss: 2.0349981238444648

Epoch: 5| Step: 3
Training loss: 1.5490283966064453
Validation loss: 2.0368685821692147

Epoch: 5| Step: 4
Training loss: 2.4841132164001465
Validation loss: 2.041780948638916

Epoch: 5| Step: 5
Training loss: 2.570359706878662
Validation loss: 2.0627414931853614

Epoch: 5| Step: 6
Training loss: 1.8438904285430908
Validation loss: 2.0729625274737677

Epoch: 5| Step: 7
Training loss: 2.5178451538085938
Validation loss: 2.0767142921686172

Epoch: 5| Step: 8
Training loss: 2.2933061122894287
Validation loss: 2.0752962678670883

Epoch: 5| Step: 9
Training loss: 2.4351019859313965
Validation loss: 2.0796419183413186

Epoch: 5| Step: 10
Training loss: 1.8669160604476929
Validation loss: 2.064961299300194

Epoch: 5| Step: 11
Training loss: 1.5973726511001587
Validation loss: 2.0329735030730567

Epoch: 137| Step: 0
Training loss: 1.6829025745391846
Validation loss: 2.035368020335833

Epoch: 5| Step: 1
Training loss: 2.2740767002105713
Validation loss: 2.029770294825236

Epoch: 5| Step: 2
Training loss: 1.7372944355010986
Validation loss: 2.0344980359077454

Epoch: 5| Step: 3
Training loss: 2.07524037361145
Validation loss: 2.0379071682691574

Epoch: 5| Step: 4
Training loss: 1.9090690612792969
Validation loss: 2.0437511652708054

Epoch: 5| Step: 5
Training loss: 2.314492702484131
Validation loss: 2.0435095727443695

Epoch: 5| Step: 6
Training loss: 1.5243133306503296
Validation loss: 2.040108566482862

Epoch: 5| Step: 7
Training loss: 2.2260360717773438
Validation loss: 2.0420139729976654

Epoch: 5| Step: 8
Training loss: 1.7199690341949463
Validation loss: 2.0340694735447564

Epoch: 5| Step: 9
Training loss: 2.9275739192962646
Validation loss: 2.0424097031354904

Epoch: 5| Step: 10
Training loss: 2.6275858879089355
Validation loss: 2.0285348097483316

Epoch: 5| Step: 11
Training loss: 3.672332286834717
Validation loss: 2.0309339314699173

Epoch: 138| Step: 0
Training loss: 2.0355441570281982
Validation loss: 2.030926212668419

Epoch: 5| Step: 1
Training loss: 2.6448142528533936
Validation loss: 2.0329849421977997

Epoch: 5| Step: 2
Training loss: 1.8390916585922241
Validation loss: 2.0265141129493713

Epoch: 5| Step: 3
Training loss: 1.5448763370513916
Validation loss: 2.024501293897629

Epoch: 5| Step: 4
Training loss: 2.284731864929199
Validation loss: 2.023192827900251

Epoch: 5| Step: 5
Training loss: 1.5832010507583618
Validation loss: 2.0197521249453225

Epoch: 5| Step: 6
Training loss: 2.059337615966797
Validation loss: 2.0121216475963593

Epoch: 5| Step: 7
Training loss: 2.1840271949768066
Validation loss: 2.01787302394708

Epoch: 5| Step: 8
Training loss: 2.7943997383117676
Validation loss: 2.016978830099106

Epoch: 5| Step: 9
Training loss: 1.9178358316421509
Validation loss: 2.022920181353887

Epoch: 5| Step: 10
Training loss: 2.6153693199157715
Validation loss: 2.0193001379569373

Epoch: 5| Step: 11
Training loss: 1.4129594564437866
Validation loss: 2.0176289876302085

Epoch: 139| Step: 0
Training loss: 1.9248077869415283
Validation loss: 2.0204087992509208

Epoch: 5| Step: 1
Training loss: 2.5817925930023193
Validation loss: 2.0223761051893234

Epoch: 5| Step: 2
Training loss: 2.933966875076294
Validation loss: 2.0253065327803292

Epoch: 5| Step: 3
Training loss: 2.5800178050994873
Validation loss: 2.0281415482362113

Epoch: 5| Step: 4
Training loss: 1.930869460105896
Validation loss: 2.025240570306778

Epoch: 5| Step: 5
Training loss: 1.738917589187622
Validation loss: 2.0263648132483163

Epoch: 5| Step: 6
Training loss: 1.8026502132415771
Validation loss: 2.02988508840402

Epoch: 5| Step: 7
Training loss: 1.5675761699676514
Validation loss: 2.030047044157982

Epoch: 5| Step: 8
Training loss: 1.918517827987671
Validation loss: 2.0316679875055947

Epoch: 5| Step: 9
Training loss: 2.4875245094299316
Validation loss: 2.028736193974813

Epoch: 5| Step: 10
Training loss: 1.5346745252609253
Validation loss: 2.0352108031511307

Epoch: 5| Step: 11
Training loss: 1.8783278465270996
Validation loss: 2.0306342790524163

Epoch: 140| Step: 0
Training loss: 2.530219554901123
Validation loss: 2.0321263720591864

Epoch: 5| Step: 1
Training loss: 2.294482707977295
Validation loss: 2.0277220755815506

Epoch: 5| Step: 2
Training loss: 1.7666375637054443
Validation loss: 2.0387880305449166

Epoch: 5| Step: 3
Training loss: 2.4009275436401367
Validation loss: 2.0416739185651145

Epoch: 5| Step: 4
Training loss: 1.4542237520217896
Validation loss: 2.038156509399414

Epoch: 5| Step: 5
Training loss: 1.728711724281311
Validation loss: 2.0464419374863305

Epoch: 5| Step: 6
Training loss: 2.181227445602417
Validation loss: 2.053047686815262

Epoch: 5| Step: 7
Training loss: 2.292006731033325
Validation loss: 2.041078895330429

Epoch: 5| Step: 8
Training loss: 1.8061683177947998
Validation loss: 2.0290220280488334

Epoch: 5| Step: 9
Training loss: 2.3278839588165283
Validation loss: 2.0253250002861023

Epoch: 5| Step: 10
Training loss: 2.0721964836120605
Validation loss: 2.0308634837468467

Epoch: 5| Step: 11
Training loss: 1.711991786956787
Validation loss: 2.0273869782686234

Epoch: 141| Step: 0
Training loss: 1.6196861267089844
Validation loss: 2.025009592374166

Epoch: 5| Step: 1
Training loss: 2.1199870109558105
Validation loss: 2.0317269663016

Epoch: 5| Step: 2
Training loss: 2.3835787773132324
Validation loss: 2.0400039752324424

Epoch: 5| Step: 3
Training loss: 2.197897434234619
Validation loss: 2.036950578292211

Epoch: 5| Step: 4
Training loss: 1.9427855014801025
Validation loss: 2.0262373139460883

Epoch: 5| Step: 5
Training loss: 2.4368090629577637
Validation loss: 2.0352706561485925

Epoch: 5| Step: 6
Training loss: 1.6774095296859741
Validation loss: 2.024823233485222

Epoch: 5| Step: 7
Training loss: 1.8535997867584229
Validation loss: 2.0287429094314575

Epoch: 5| Step: 8
Training loss: 2.998422861099243
Validation loss: 2.0252589086691537

Epoch: 5| Step: 9
Training loss: 1.7533401250839233
Validation loss: 2.029087553421656

Epoch: 5| Step: 10
Training loss: 2.1059155464172363
Validation loss: 2.0286429474751153

Epoch: 5| Step: 11
Training loss: 2.8455891609191895
Validation loss: 2.031979034344355

Epoch: 142| Step: 0
Training loss: 2.2068123817443848
Validation loss: 2.0397300720214844

Epoch: 5| Step: 1
Training loss: 2.085996150970459
Validation loss: 2.029354080557823

Epoch: 5| Step: 2
Training loss: 2.0230679512023926
Validation loss: 2.044424662987391

Epoch: 5| Step: 3
Training loss: 1.8756771087646484
Validation loss: 2.0322461128234863

Epoch: 5| Step: 4
Training loss: 2.0408759117126465
Validation loss: 2.0419843147198358

Epoch: 5| Step: 5
Training loss: 2.3297061920166016
Validation loss: 2.0468500206867852

Epoch: 5| Step: 6
Training loss: 1.5410770177841187
Validation loss: 2.0579317460457482

Epoch: 5| Step: 7
Training loss: 2.5848937034606934
Validation loss: 2.052295431494713

Epoch: 5| Step: 8
Training loss: 2.7082626819610596
Validation loss: 2.041494349638621

Epoch: 5| Step: 9
Training loss: 1.500735878944397
Validation loss: 2.043123642603556

Epoch: 5| Step: 10
Training loss: 1.8800544738769531
Validation loss: 2.033819312850634

Epoch: 5| Step: 11
Training loss: 2.340728998184204
Validation loss: 2.029081419110298

Epoch: 143| Step: 0
Training loss: 1.983904242515564
Validation loss: 2.028886372844378

Epoch: 5| Step: 1
Training loss: 1.8901598453521729
Validation loss: 2.0318603515625

Epoch: 5| Step: 2
Training loss: 2.218395948410034
Validation loss: 2.036467288931211

Epoch: 5| Step: 3
Training loss: 2.33400559425354
Validation loss: 2.023194139202436

Epoch: 5| Step: 4
Training loss: 2.1801912784576416
Validation loss: 2.0298305600881577

Epoch: 5| Step: 5
Training loss: 1.8661339282989502
Validation loss: 2.035753086209297

Epoch: 5| Step: 6
Training loss: 1.8561118841171265
Validation loss: 2.0318853159745536

Epoch: 5| Step: 7
Training loss: 2.2807538509368896
Validation loss: 2.034335826834043

Epoch: 5| Step: 8
Training loss: 2.3093748092651367
Validation loss: 2.0236462304989495

Epoch: 5| Step: 9
Training loss: 2.059587001800537
Validation loss: 2.03462153673172

Epoch: 5| Step: 10
Training loss: 1.8974144458770752
Validation loss: 2.0321128120025

Epoch: 5| Step: 11
Training loss: 2.204556465148926
Validation loss: 2.0220475246508918

Epoch: 144| Step: 0
Training loss: 2.0988426208496094
Validation loss: 2.024856060743332

Epoch: 5| Step: 1
Training loss: 1.5076384544372559
Validation loss: 2.029491643110911

Epoch: 5| Step: 2
Training loss: 1.7768452167510986
Validation loss: 2.0287202447652817

Epoch: 5| Step: 3
Training loss: 1.45699942111969
Validation loss: 2.028116171558698

Epoch: 5| Step: 4
Training loss: 2.1834821701049805
Validation loss: 2.0336934377749762

Epoch: 5| Step: 5
Training loss: 2.297023296356201
Validation loss: 2.0272081593672433

Epoch: 5| Step: 6
Training loss: 2.004317283630371
Validation loss: 2.037656525770823

Epoch: 5| Step: 7
Training loss: 2.801990032196045
Validation loss: 2.0385876347621283

Epoch: 5| Step: 8
Training loss: 2.64823579788208
Validation loss: 2.0306024054686227

Epoch: 5| Step: 9
Training loss: 1.9864037036895752
Validation loss: 2.0329646170139313

Epoch: 5| Step: 10
Training loss: 1.9220088720321655
Validation loss: 2.0215334246555963

Epoch: 5| Step: 11
Training loss: 3.0122437477111816
Validation loss: 2.0304817159970603

Epoch: 145| Step: 0
Training loss: 1.684709906578064
Validation loss: 2.0291388432184854

Epoch: 5| Step: 1
Training loss: 2.2238831520080566
Validation loss: 2.0285149117310843

Epoch: 5| Step: 2
Training loss: 2.2874321937561035
Validation loss: 2.0310516307751336

Epoch: 5| Step: 3
Training loss: 1.8464794158935547
Validation loss: 2.0296985854705176

Epoch: 5| Step: 4
Training loss: 2.2410330772399902
Validation loss: 2.0372542639573417

Epoch: 5| Step: 5
Training loss: 1.9180576801300049
Validation loss: 2.038622503479322

Epoch: 5| Step: 6
Training loss: 1.9991343021392822
Validation loss: 2.0369296769301095

Epoch: 5| Step: 7
Training loss: 2.572767734527588
Validation loss: 2.0419143537680307

Epoch: 5| Step: 8
Training loss: 1.9339271783828735
Validation loss: 2.0306560347477594

Epoch: 5| Step: 9
Training loss: 2.1458723545074463
Validation loss: 2.0336692382891974

Epoch: 5| Step: 10
Training loss: 1.9112821817398071
Validation loss: 2.0266928325096765

Epoch: 5| Step: 11
Training loss: 1.7017056941986084
Validation loss: 2.022610048453013

Epoch: 146| Step: 0
Training loss: 2.387972354888916
Validation loss: 2.026415745417277

Epoch: 5| Step: 1
Training loss: 1.7078571319580078
Validation loss: 2.0303717156251273

Epoch: 5| Step: 2
Training loss: 1.7564855813980103
Validation loss: 2.0311637868483863

Epoch: 5| Step: 3
Training loss: 1.972262978553772
Validation loss: 2.0383106420437493

Epoch: 5| Step: 4
Training loss: 1.5994679927825928
Validation loss: 2.035521815220515

Epoch: 5| Step: 5
Training loss: 2.221031665802002
Validation loss: 2.0432735035816827

Epoch: 5| Step: 6
Training loss: 1.6632080078125
Validation loss: 2.0323230922222137

Epoch: 5| Step: 7
Training loss: 2.4040675163269043
Validation loss: 2.0535285025835037

Epoch: 5| Step: 8
Training loss: 2.5261240005493164
Validation loss: 2.039350539445877

Epoch: 5| Step: 9
Training loss: 2.165069580078125
Validation loss: 2.0492655684550605

Epoch: 5| Step: 10
Training loss: 2.232661724090576
Validation loss: 2.040622110168139

Epoch: 5| Step: 11
Training loss: 2.2784476280212402
Validation loss: 2.039529507358869

Epoch: 147| Step: 0
Training loss: 2.4480643272399902
Validation loss: 2.0456726054350534

Epoch: 5| Step: 1
Training loss: 2.1017062664031982
Validation loss: 2.034178520242373

Epoch: 5| Step: 2
Training loss: 2.3430066108703613
Validation loss: 2.0436243961254754

Epoch: 5| Step: 3
Training loss: 2.489377498626709
Validation loss: 2.0441584289073944

Epoch: 5| Step: 4
Training loss: 2.135091781616211
Validation loss: 2.050637369354566

Epoch: 5| Step: 5
Training loss: 1.410122036933899
Validation loss: 2.050530100862185

Epoch: 5| Step: 6
Training loss: 1.9464164972305298
Validation loss: 2.045835296312968

Epoch: 5| Step: 7
Training loss: 2.114722728729248
Validation loss: 2.0530893802642822

Epoch: 5| Step: 8
Training loss: 1.92941415309906
Validation loss: 2.03606253862381

Epoch: 5| Step: 9
Training loss: 2.2775447368621826
Validation loss: 2.0479247172673545

Epoch: 5| Step: 10
Training loss: 1.8804662227630615
Validation loss: 2.052838404973348

Epoch: 5| Step: 11
Training loss: 1.014694333076477
Validation loss: 2.0541665653387704

Epoch: 148| Step: 0
Training loss: 1.3113869428634644
Validation loss: 2.0472217748562493

Epoch: 5| Step: 1
Training loss: 2.1856789588928223
Validation loss: 2.035240347186724

Epoch: 5| Step: 2
Training loss: 2.1126232147216797
Validation loss: 2.039737264315287

Epoch: 5| Step: 3
Training loss: 2.0146498680114746
Validation loss: 2.0413767794768014

Epoch: 5| Step: 4
Training loss: 2.523674249649048
Validation loss: 2.0412394801775613

Epoch: 5| Step: 5
Training loss: 2.132819652557373
Validation loss: 2.044554680585861

Epoch: 5| Step: 6
Training loss: 2.2024824619293213
Validation loss: 2.043042555451393

Epoch: 5| Step: 7
Training loss: 2.143012523651123
Validation loss: 2.042187839746475

Epoch: 5| Step: 8
Training loss: 2.699620485305786
Validation loss: 2.0457509060700736

Epoch: 5| Step: 9
Training loss: 1.8684475421905518
Validation loss: 2.0448691099882126

Epoch: 5| Step: 10
Training loss: 1.9675474166870117
Validation loss: 2.043333808581034

Epoch: 5| Step: 11
Training loss: 1.6290838718414307
Validation loss: 2.0410473942756653

Epoch: 149| Step: 0
Training loss: 1.6416194438934326
Validation loss: 2.0402857462565103

Epoch: 5| Step: 1
Training loss: 2.023383617401123
Validation loss: 2.0469273030757904

Epoch: 5| Step: 2
Training loss: 2.4487693309783936
Validation loss: 2.0841068774461746

Epoch: 5| Step: 3
Training loss: 2.0309669971466064
Validation loss: 2.1323299507300058

Epoch: 5| Step: 4
Training loss: 2.2873473167419434
Validation loss: 2.1381672869126

Epoch: 5| Step: 5
Training loss: 2.123680830001831
Validation loss: 2.1687912146250405

Epoch: 5| Step: 6
Training loss: 1.7649123668670654
Validation loss: 2.164732962846756

Epoch: 5| Step: 7
Training loss: 2.6267757415771484
Validation loss: 2.147522355119387

Epoch: 5| Step: 8
Training loss: 2.4465036392211914
Validation loss: 2.085615282257398

Epoch: 5| Step: 9
Training loss: 2.5995476245880127
Validation loss: 2.0668172339598336

Epoch: 5| Step: 10
Training loss: 2.26300048828125
Validation loss: 2.0296981235345206

Epoch: 5| Step: 11
Training loss: 2.890456438064575
Validation loss: 2.011919324596723

Epoch: 150| Step: 0
Training loss: 2.351961612701416
Validation loss: 2.0067194352547326

Epoch: 5| Step: 1
Training loss: 1.7849572896957397
Validation loss: 2.002119019627571

Epoch: 5| Step: 2
Training loss: 2.299853801727295
Validation loss: 2.018064205845197

Epoch: 5| Step: 3
Training loss: 2.0210559368133545
Validation loss: 2.0238900035619736

Epoch: 5| Step: 4
Training loss: 2.0602285861968994
Validation loss: 2.033687894543012

Epoch: 5| Step: 5
Training loss: 2.1785876750946045
Validation loss: 2.050001805027326

Epoch: 5| Step: 6
Training loss: 1.4753491878509521
Validation loss: 2.0566705713669458

Epoch: 5| Step: 7
Training loss: 2.8446547985076904
Validation loss: 2.062955151001612

Epoch: 5| Step: 8
Training loss: 2.6130142211914062
Validation loss: 2.0697608242432275

Epoch: 5| Step: 9
Training loss: 2.3408892154693604
Validation loss: 2.077844281991323

Epoch: 5| Step: 10
Training loss: 2.0158333778381348
Validation loss: 2.070761193831762

Epoch: 5| Step: 11
Training loss: 2.2291297912597656
Validation loss: 2.0804120103518167

Epoch: 151| Step: 0
Training loss: 2.474194049835205
Validation loss: 2.0754994054635367

Epoch: 5| Step: 1
Training loss: 1.8406257629394531
Validation loss: 2.0778881261746087

Epoch: 5| Step: 2
Training loss: 2.1217939853668213
Validation loss: 2.0697385420401893

Epoch: 5| Step: 3
Training loss: 2.4970035552978516
Validation loss: 2.058769464492798

Epoch: 5| Step: 4
Training loss: 2.5860095024108887
Validation loss: 2.05041374762853

Epoch: 5| Step: 5
Training loss: 2.317714214324951
Validation loss: 2.04168564081192

Epoch: 5| Step: 6
Training loss: 2.233609437942505
Validation loss: 2.0358520398537316

Epoch: 5| Step: 7
Training loss: 2.1644034385681152
Validation loss: 2.0373444308837256

Epoch: 5| Step: 8
Training loss: 2.061535596847534
Validation loss: 2.0251342256863913

Epoch: 5| Step: 9
Training loss: 1.6974503993988037
Validation loss: 2.026711737116178

Epoch: 5| Step: 10
Training loss: 2.028029680252075
Validation loss: 2.0288825730482736

Epoch: 5| Step: 11
Training loss: 1.198852777481079
Validation loss: 2.040823350350062

Epoch: 152| Step: 0
Training loss: 2.20025634765625
Validation loss: 2.0386705646912255

Epoch: 5| Step: 1
Training loss: 1.9028631448745728
Validation loss: 2.050171638528506

Epoch: 5| Step: 2
Training loss: 2.075423002243042
Validation loss: 2.065794905026754

Epoch: 5| Step: 3
Training loss: 2.3122944831848145
Validation loss: 2.05292401711146

Epoch: 5| Step: 4
Training loss: 1.961167573928833
Validation loss: 2.070352310935656

Epoch: 5| Step: 5
Training loss: 1.913779854774475
Validation loss: 2.064556802312533

Epoch: 5| Step: 6
Training loss: 2.228342294692993
Validation loss: 2.0788450638453164

Epoch: 5| Step: 7
Training loss: 1.975402593612671
Validation loss: 2.057982032497724

Epoch: 5| Step: 8
Training loss: 2.8151211738586426
Validation loss: 2.0560465455055237

Epoch: 5| Step: 9
Training loss: 2.092665672302246
Validation loss: 2.036299298206965

Epoch: 5| Step: 10
Training loss: 1.5366696119308472
Validation loss: 2.0374690890312195

Epoch: 5| Step: 11
Training loss: 1.976534366607666
Validation loss: 2.042392755548159

Epoch: 153| Step: 0
Training loss: 2.054706335067749
Validation loss: 2.035649965206782

Epoch: 5| Step: 1
Training loss: 2.131876230239868
Validation loss: 2.0322092920541763

Epoch: 5| Step: 2
Training loss: 1.6947860717773438
Validation loss: 2.0295804888010025

Epoch: 5| Step: 3
Training loss: 2.180840492248535
Validation loss: 2.0306871185700097

Epoch: 5| Step: 4
Training loss: 2.1936018466949463
Validation loss: 2.034812202056249

Epoch: 5| Step: 5
Training loss: 2.3433666229248047
Validation loss: 2.040280650059382

Epoch: 5| Step: 6
Training loss: 1.9265735149383545
Validation loss: 2.0432189851999283

Epoch: 5| Step: 7
Training loss: 2.5563578605651855
Validation loss: 2.0354706396659217

Epoch: 5| Step: 8
Training loss: 2.07920503616333
Validation loss: 2.0371171732743583

Epoch: 5| Step: 9
Training loss: 1.8916873931884766
Validation loss: 2.038456747929255

Epoch: 5| Step: 10
Training loss: 2.2770702838897705
Validation loss: 2.0345624138911567

Epoch: 5| Step: 11
Training loss: 2.380484104156494
Validation loss: 2.0344551503658295

Epoch: 154| Step: 0
Training loss: 2.6535282135009766
Validation loss: 2.0288140575091043

Epoch: 5| Step: 1
Training loss: 2.1513290405273438
Validation loss: 2.0298980524142585

Epoch: 5| Step: 2
Training loss: 1.7139734029769897
Validation loss: 2.0300708214441934

Epoch: 5| Step: 3
Training loss: 1.7406036853790283
Validation loss: 2.033506825566292

Epoch: 5| Step: 4
Training loss: 1.8492851257324219
Validation loss: 2.0335964461167655

Epoch: 5| Step: 5
Training loss: 1.957553505897522
Validation loss: 2.0419518500566483

Epoch: 5| Step: 6
Training loss: 2.0034515857696533
Validation loss: 2.041576862335205

Epoch: 5| Step: 7
Training loss: 1.8305723667144775
Validation loss: 2.053677628437678

Epoch: 5| Step: 8
Training loss: 2.0709779262542725
Validation loss: 2.0493433276812234

Epoch: 5| Step: 9
Training loss: 2.2654531002044678
Validation loss: 2.0472786327203116

Epoch: 5| Step: 10
Training loss: 2.3505094051361084
Validation loss: 2.039843961596489

Epoch: 5| Step: 11
Training loss: 3.7819554805755615
Validation loss: 2.040120020508766

Epoch: 155| Step: 0
Training loss: 2.619868516921997
Validation loss: 2.04156556725502

Epoch: 5| Step: 1
Training loss: 1.7925958633422852
Validation loss: 2.0359609574079514

Epoch: 5| Step: 2
Training loss: 2.1555161476135254
Validation loss: 2.0418263375759125

Epoch: 5| Step: 3
Training loss: 2.3016369342803955
Validation loss: 2.029128685593605

Epoch: 5| Step: 4
Training loss: 2.432229518890381
Validation loss: 2.0390058060487113

Epoch: 5| Step: 5
Training loss: 1.6139529943466187
Validation loss: 2.0360752741495767

Epoch: 5| Step: 6
Training loss: 1.7610523700714111
Validation loss: 2.037476802865664

Epoch: 5| Step: 7
Training loss: 1.904741644859314
Validation loss: 2.0338296741247177

Epoch: 5| Step: 8
Training loss: 1.7466827630996704
Validation loss: 2.038848251104355

Epoch: 5| Step: 9
Training loss: 2.366192579269409
Validation loss: 2.030103628834089

Epoch: 5| Step: 10
Training loss: 2.050870180130005
Validation loss: 2.0237773209810257

Epoch: 5| Step: 11
Training loss: 2.494804620742798
Validation loss: 2.0335616767406464

Epoch: 156| Step: 0
Training loss: 1.9347854852676392
Validation loss: 2.0440842608610788

Epoch: 5| Step: 1
Training loss: 1.6951141357421875
Validation loss: 2.0342667996883392

Epoch: 5| Step: 2
Training loss: 1.8983325958251953
Validation loss: 2.0418144265810647

Epoch: 5| Step: 3
Training loss: 2.5438196659088135
Validation loss: 2.047197292248408

Epoch: 5| Step: 4
Training loss: 2.4842042922973633
Validation loss: 2.055723895629247

Epoch: 5| Step: 5
Training loss: 2.2754952907562256
Validation loss: 2.0659009416898093

Epoch: 5| Step: 6
Training loss: 2.5700182914733887
Validation loss: 2.0519622613986335

Epoch: 5| Step: 7
Training loss: 1.6927896738052368
Validation loss: 2.0578126112620034

Epoch: 5| Step: 8
Training loss: 1.514765977859497
Validation loss: 2.051598399877548

Epoch: 5| Step: 9
Training loss: 2.1046977043151855
Validation loss: 2.0411531974871955

Epoch: 5| Step: 10
Training loss: 2.0484628677368164
Validation loss: 2.0461074064175286

Epoch: 5| Step: 11
Training loss: 2.7275407314300537
Validation loss: 2.0401192804177604

Epoch: 157| Step: 0
Training loss: 2.3187015056610107
Validation loss: 2.0471124897400537

Epoch: 5| Step: 1
Training loss: 2.3242969512939453
Validation loss: 2.033223713437716

Epoch: 5| Step: 2
Training loss: 1.4028832912445068
Validation loss: 2.0303639670213065

Epoch: 5| Step: 3
Training loss: 2.127445936203003
Validation loss: 2.039470965663592

Epoch: 5| Step: 4
Training loss: 1.8535267114639282
Validation loss: 2.034577260414759

Epoch: 5| Step: 5
Training loss: 2.168565034866333
Validation loss: 2.0408593912919364

Epoch: 5| Step: 6
Training loss: 1.7977383136749268
Validation loss: 2.0387465804815292

Epoch: 5| Step: 7
Training loss: 2.016490936279297
Validation loss: 2.036878531177839

Epoch: 5| Step: 8
Training loss: 1.9024864435195923
Validation loss: 2.0458966741959252

Epoch: 5| Step: 9
Training loss: 2.132399797439575
Validation loss: 2.034140333533287

Epoch: 5| Step: 10
Training loss: 2.6954286098480225
Validation loss: 2.0480259358882904

Epoch: 5| Step: 11
Training loss: 3.2068793773651123
Validation loss: 2.062157322963079

Epoch: 158| Step: 0
Training loss: 1.324326753616333
Validation loss: 2.0535400907198587

Epoch: 5| Step: 1
Training loss: 1.717969536781311
Validation loss: 2.058879072467486

Epoch: 5| Step: 2
Training loss: 2.5538222789764404
Validation loss: 2.055696745713552

Epoch: 5| Step: 3
Training loss: 2.5376510620117188
Validation loss: 2.0577083925406137

Epoch: 5| Step: 4
Training loss: 2.1378438472747803
Validation loss: 2.060702905058861

Epoch: 5| Step: 5
Training loss: 2.1945126056671143
Validation loss: 2.0579072535037994

Epoch: 5| Step: 6
Training loss: 1.8630917072296143
Validation loss: 2.0533961206674576

Epoch: 5| Step: 7
Training loss: 2.069455623626709
Validation loss: 2.05984690785408

Epoch: 5| Step: 8
Training loss: 1.849773645401001
Validation loss: 2.0570328384637833

Epoch: 5| Step: 9
Training loss: 2.3763809204101562
Validation loss: 2.057739739616712

Epoch: 5| Step: 10
Training loss: 2.2056000232696533
Validation loss: 2.0506883362929025

Epoch: 5| Step: 11
Training loss: 2.446202516555786
Validation loss: 2.045367032289505

Epoch: 159| Step: 0
Training loss: 2.141392230987549
Validation loss: 2.0672172059615455

Epoch: 5| Step: 1
Training loss: 1.6430022716522217
Validation loss: 2.057543238004049

Epoch: 5| Step: 2
Training loss: 1.673269271850586
Validation loss: 2.0564744770526886

Epoch: 5| Step: 3
Training loss: 2.7995848655700684
Validation loss: 2.047033801674843

Epoch: 5| Step: 4
Training loss: 2.3297133445739746
Validation loss: 2.049871563911438

Epoch: 5| Step: 5
Training loss: 1.7844905853271484
Validation loss: 2.0466798494259515

Epoch: 5| Step: 6
Training loss: 2.0236010551452637
Validation loss: 2.0544615437587104

Epoch: 5| Step: 7
Training loss: 2.0859017372131348
Validation loss: 2.0476100742816925

Epoch: 5| Step: 8
Training loss: 2.1348297595977783
Validation loss: 2.0523377060890198

Epoch: 5| Step: 9
Training loss: 1.757249116897583
Validation loss: 2.040580376982689

Epoch: 5| Step: 10
Training loss: 2.4488909244537354
Validation loss: 2.053465669353803

Epoch: 5| Step: 11
Training loss: 1.6105694770812988
Validation loss: 2.0520426481962204

Epoch: 160| Step: 0
Training loss: 1.905630111694336
Validation loss: 2.0569679737091064

Epoch: 5| Step: 1
Training loss: 1.9361522197723389
Validation loss: 2.058028037349383

Epoch: 5| Step: 2
Training loss: 2.2561655044555664
Validation loss: 2.0559893051783242

Epoch: 5| Step: 3
Training loss: 2.7905759811401367
Validation loss: 2.0548978000879288

Epoch: 5| Step: 4
Training loss: 1.8911510705947876
Validation loss: 2.0554392288128533

Epoch: 5| Step: 5
Training loss: 2.446108102798462
Validation loss: 2.057651087641716

Epoch: 5| Step: 6
Training loss: 1.9117408990859985
Validation loss: 2.050968279441198

Epoch: 5| Step: 7
Training loss: 2.303034543991089
Validation loss: 2.053943191965421

Epoch: 5| Step: 8
Training loss: 1.6208372116088867
Validation loss: 2.0530445724725723

Epoch: 5| Step: 9
Training loss: 1.7258288860321045
Validation loss: 2.053470949331919

Epoch: 5| Step: 10
Training loss: 1.9455817937850952
Validation loss: 2.0481490790843964

Epoch: 5| Step: 11
Training loss: 1.6147980690002441
Validation loss: 2.049920136729876

Epoch: 161| Step: 0
Training loss: 2.319070339202881
Validation loss: 2.04702727496624

Epoch: 5| Step: 1
Training loss: 2.3923099040985107
Validation loss: 2.0530802855889

Epoch: 5| Step: 2
Training loss: 2.2360854148864746
Validation loss: 2.048148130377134

Epoch: 5| Step: 3
Training loss: 1.9830849170684814
Validation loss: 2.0470753014087677

Epoch: 5| Step: 4
Training loss: 1.9160375595092773
Validation loss: 2.056348810593287

Epoch: 5| Step: 5
Training loss: 1.3143389225006104
Validation loss: 2.051850378513336

Epoch: 5| Step: 6
Training loss: 1.8438440561294556
Validation loss: 2.056059976418813

Epoch: 5| Step: 7
Training loss: 2.41731595993042
Validation loss: 2.057136749227842

Epoch: 5| Step: 8
Training loss: 1.5032730102539062
Validation loss: 2.061730742454529

Epoch: 5| Step: 9
Training loss: 2.256639003753662
Validation loss: 2.054156477252642

Epoch: 5| Step: 10
Training loss: 2.464224338531494
Validation loss: 2.0529702454805374

Epoch: 5| Step: 11
Training loss: 2.0230422019958496
Validation loss: 2.0472957342863083

Epoch: 162| Step: 0
Training loss: 1.5108553171157837
Validation loss: 2.054120952884356

Epoch: 5| Step: 1
Training loss: 2.1531264781951904
Validation loss: 2.060187965631485

Epoch: 5| Step: 2
Training loss: 1.7325395345687866
Validation loss: 2.0568515956401825

Epoch: 5| Step: 3
Training loss: 2.2509446144104004
Validation loss: 2.0476200381914773

Epoch: 5| Step: 4
Training loss: 1.87090265750885
Validation loss: 2.05974251528581

Epoch: 5| Step: 5
Training loss: 2.179577112197876
Validation loss: 2.059286897381147

Epoch: 5| Step: 6
Training loss: 2.1496927738189697
Validation loss: 2.043800786137581

Epoch: 5| Step: 7
Training loss: 2.1508471965789795
Validation loss: 2.0432114948829017

Epoch: 5| Step: 8
Training loss: 2.1448051929473877
Validation loss: 2.0505959540605545

Epoch: 5| Step: 9
Training loss: 2.3471271991729736
Validation loss: 2.045143668850263

Epoch: 5| Step: 10
Training loss: 2.322965145111084
Validation loss: 2.0468323081731796

Epoch: 5| Step: 11
Training loss: 1.1009963750839233
Validation loss: 2.044616882999738

Epoch: 163| Step: 0
Training loss: 2.0810420513153076
Validation loss: 2.0473233312368393

Epoch: 5| Step: 1
Training loss: 2.199129819869995
Validation loss: 2.0453471491734185

Epoch: 5| Step: 2
Training loss: 1.806605577468872
Validation loss: 2.041539972027143

Epoch: 5| Step: 3
Training loss: 1.9598560333251953
Validation loss: 2.043297693133354

Epoch: 5| Step: 4
Training loss: 2.013401746749878
Validation loss: 2.0485146840413413

Epoch: 5| Step: 5
Training loss: 2.5941052436828613
Validation loss: 2.040693774819374

Epoch: 5| Step: 6
Training loss: 1.598016619682312
Validation loss: 2.0426854441563287

Epoch: 5| Step: 7
Training loss: 1.9509429931640625
Validation loss: 2.0411290377378464

Epoch: 5| Step: 8
Training loss: 1.9815565347671509
Validation loss: 2.0573367377122245

Epoch: 5| Step: 9
Training loss: 2.524901866912842
Validation loss: 2.047214517990748

Epoch: 5| Step: 10
Training loss: 1.777319312095642
Validation loss: 2.0530896286169686

Epoch: 5| Step: 11
Training loss: 2.0200939178466797
Validation loss: 2.0439200599988303

Epoch: 164| Step: 0
Training loss: 2.285006284713745
Validation loss: 2.0590480069319406

Epoch: 5| Step: 1
Training loss: 1.843225121498108
Validation loss: 2.068137695391973

Epoch: 5| Step: 2
Training loss: 1.8820340633392334
Validation loss: 2.064599429567655

Epoch: 5| Step: 3
Training loss: 2.431807279586792
Validation loss: 2.0710336615641913

Epoch: 5| Step: 4
Training loss: 2.7036566734313965
Validation loss: 2.0706809361775718

Epoch: 5| Step: 5
Training loss: 2.287825107574463
Validation loss: 2.061112587650617

Epoch: 5| Step: 6
Training loss: 1.4835946559906006
Validation loss: 2.049648846189181

Epoch: 5| Step: 7
Training loss: 1.5900089740753174
Validation loss: 2.0555500040451684

Epoch: 5| Step: 8
Training loss: 2.187790870666504
Validation loss: 2.035143713156382

Epoch: 5| Step: 9
Training loss: 1.9614722728729248
Validation loss: 2.0357278933127723

Epoch: 5| Step: 10
Training loss: 2.1033642292022705
Validation loss: 2.0373939524094262

Epoch: 5| Step: 11
Training loss: 1.6990007162094116
Validation loss: 2.0494366536537805

Epoch: 165| Step: 0
Training loss: 2.109179973602295
Validation loss: 2.036153237024943

Epoch: 5| Step: 1
Training loss: 1.7917978763580322
Validation loss: 2.0430856198072433

Epoch: 5| Step: 2
Training loss: 2.3556466102600098
Validation loss: 2.0426129897435508

Epoch: 5| Step: 3
Training loss: 2.4362294673919678
Validation loss: 2.0377820432186127

Epoch: 5| Step: 4
Training loss: 1.6416816711425781
Validation loss: 2.043524980545044

Epoch: 5| Step: 5
Training loss: 1.9596138000488281
Validation loss: 2.0390267968177795

Epoch: 5| Step: 6
Training loss: 1.7316135168075562
Validation loss: 2.0454773902893066

Epoch: 5| Step: 7
Training loss: 2.305143356323242
Validation loss: 2.0387906034787497

Epoch: 5| Step: 8
Training loss: 2.1277523040771484
Validation loss: 2.0553929060697556

Epoch: 5| Step: 9
Training loss: 2.070420503616333
Validation loss: 2.060478369394938

Epoch: 5| Step: 10
Training loss: 2.129983425140381
Validation loss: 2.0585284680128098

Epoch: 5| Step: 11
Training loss: 2.7728383541107178
Validation loss: 2.065856024622917

Epoch: 166| Step: 0
Training loss: 2.1071927547454834
Validation loss: 2.0677276055018106

Epoch: 5| Step: 1
Training loss: 2.021569013595581
Validation loss: 2.058580666780472

Epoch: 5| Step: 2
Training loss: 2.2530319690704346
Validation loss: 2.0612815221150718

Epoch: 5| Step: 3
Training loss: 1.8140395879745483
Validation loss: 2.054175595442454

Epoch: 5| Step: 4
Training loss: 2.510251045227051
Validation loss: 2.0632404536008835

Epoch: 5| Step: 5
Training loss: 1.7392847537994385
Validation loss: 2.0629292676846185

Epoch: 5| Step: 6
Training loss: 2.176644802093506
Validation loss: 2.050130988160769

Epoch: 5| Step: 7
Training loss: 2.4675564765930176
Validation loss: 2.0430863002936044

Epoch: 5| Step: 8
Training loss: 1.6690616607666016
Validation loss: 2.0411917169888816

Epoch: 5| Step: 9
Training loss: 2.167391777038574
Validation loss: 2.0470613092184067

Epoch: 5| Step: 10
Training loss: 1.7387609481811523
Validation loss: 2.0346814493338266

Epoch: 5| Step: 11
Training loss: 1.1051164865493774
Validation loss: 2.0459762811660767

Epoch: 167| Step: 0
Training loss: 2.239112615585327
Validation loss: 2.0347228894631066

Epoch: 5| Step: 1
Training loss: 2.0219578742980957
Validation loss: 2.048142130176226

Epoch: 5| Step: 2
Training loss: 2.018646717071533
Validation loss: 2.0438023855288825

Epoch: 5| Step: 3
Training loss: 1.8296377658843994
Validation loss: 2.0522946566343307

Epoch: 5| Step: 4
Training loss: 2.163475513458252
Validation loss: 2.05097596347332

Epoch: 5| Step: 5
Training loss: 1.9027202129364014
Validation loss: 2.051773061354955

Epoch: 5| Step: 6
Training loss: 1.689727544784546
Validation loss: 2.061083892981211

Epoch: 5| Step: 7
Training loss: 1.8444671630859375
Validation loss: 2.0475150098403296

Epoch: 5| Step: 8
Training loss: 2.4513297080993652
Validation loss: 2.0578995446364083

Epoch: 5| Step: 9
Training loss: 2.0812957286834717
Validation loss: 2.047990615169207

Epoch: 5| Step: 10
Training loss: 2.010303497314453
Validation loss: 2.050758183002472

Epoch: 5| Step: 11
Training loss: 2.8740005493164062
Validation loss: 2.045893664161364

Epoch: 168| Step: 0
Training loss: 2.192920684814453
Validation loss: 2.043133387962977

Epoch: 5| Step: 1
Training loss: 2.3410890102386475
Validation loss: 2.0500107556581497

Epoch: 5| Step: 2
Training loss: 2.668853282928467
Validation loss: 2.0464226504166922

Epoch: 5| Step: 3
Training loss: 1.9761085510253906
Validation loss: 2.0513729552427926

Epoch: 5| Step: 4
Training loss: 1.7851005792617798
Validation loss: 2.049320643146833

Epoch: 5| Step: 5
Training loss: 2.3178963661193848
Validation loss: 2.056738848487536

Epoch: 5| Step: 6
Training loss: 2.4124627113342285
Validation loss: 2.051949843764305

Epoch: 5| Step: 7
Training loss: 1.602121114730835
Validation loss: 2.055300757288933

Epoch: 5| Step: 8
Training loss: 1.9471285343170166
Validation loss: 2.0552078634500504

Epoch: 5| Step: 9
Training loss: 1.2473394870758057
Validation loss: 2.045986369252205

Epoch: 5| Step: 10
Training loss: 1.9246008396148682
Validation loss: 2.065108299255371

Epoch: 5| Step: 11
Training loss: 1.4496479034423828
Validation loss: 2.056837280591329

Epoch: 169| Step: 0
Training loss: 2.2078728675842285
Validation loss: 2.063448578119278

Epoch: 5| Step: 1
Training loss: 2.2005536556243896
Validation loss: 2.0542784283558526

Epoch: 5| Step: 2
Training loss: 1.3742188215255737
Validation loss: 2.04641784230868

Epoch: 5| Step: 3
Training loss: 2.285871982574463
Validation loss: 2.0468642016251883

Epoch: 5| Step: 4
Training loss: 1.6342474222183228
Validation loss: 2.048988471428553

Epoch: 5| Step: 5
Training loss: 2.021595001220703
Validation loss: 2.0373609016338983

Epoch: 5| Step: 6
Training loss: 2.8030343055725098
Validation loss: 2.0379309902588525

Epoch: 5| Step: 7
Training loss: 1.864914894104004
Validation loss: 2.0381101816892624

Epoch: 5| Step: 8
Training loss: 2.266990900039673
Validation loss: 2.0348739375670752

Epoch: 5| Step: 9
Training loss: 2.2984378337860107
Validation loss: 2.036903907855352

Epoch: 5| Step: 10
Training loss: 1.6117408275604248
Validation loss: 2.0392647832632065

Epoch: 5| Step: 11
Training loss: 1.6498702764511108
Validation loss: 2.030312091112137

Epoch: 170| Step: 0
Training loss: 1.6247081756591797
Validation loss: 2.045383075873057

Epoch: 5| Step: 1
Training loss: 2.4983489513397217
Validation loss: 2.035989671945572

Epoch: 5| Step: 2
Training loss: 1.8989185094833374
Validation loss: 2.042623817920685

Epoch: 5| Step: 3
Training loss: 1.9575731754302979
Validation loss: 2.041708176334699

Epoch: 5| Step: 4
Training loss: 1.4706261157989502
Validation loss: 2.0543664445479712

Epoch: 5| Step: 5
Training loss: 1.3076989650726318
Validation loss: 2.049706811706225

Epoch: 5| Step: 6
Training loss: 2.757024049758911
Validation loss: 2.0551457007726035

Epoch: 5| Step: 7
Training loss: 2.5489649772644043
Validation loss: 2.0450253734985986

Epoch: 5| Step: 8
Training loss: 2.3454463481903076
Validation loss: 2.0577982564767203

Epoch: 5| Step: 9
Training loss: 1.9525699615478516
Validation loss: 2.062559336423874

Epoch: 5| Step: 10
Training loss: 1.9389197826385498
Validation loss: 2.059763938188553

Epoch: 5| Step: 11
Training loss: 2.229670763015747
Validation loss: 2.0554160873095193

Epoch: 171| Step: 0
Training loss: 1.8067249059677124
Validation loss: 2.0518315384785333

Epoch: 5| Step: 1
Training loss: 2.317357301712036
Validation loss: 2.0530287424723306

Epoch: 5| Step: 2
Training loss: 1.7170066833496094
Validation loss: 2.035673831899961

Epoch: 5| Step: 3
Training loss: 2.2015602588653564
Validation loss: 2.041508068641027

Epoch: 5| Step: 4
Training loss: 1.7743003368377686
Validation loss: 2.0340848863124847

Epoch: 5| Step: 5
Training loss: 2.027010440826416
Validation loss: 2.037346661090851

Epoch: 5| Step: 6
Training loss: 2.4190785884857178
Validation loss: 2.044539655248324

Epoch: 5| Step: 7
Training loss: 1.5640277862548828
Validation loss: 2.0414229383071265

Epoch: 5| Step: 8
Training loss: 1.9346096515655518
Validation loss: 2.034020041426023

Epoch: 5| Step: 9
Training loss: 2.241665840148926
Validation loss: 2.0490194658438363

Epoch: 5| Step: 10
Training loss: 2.0917916297912598
Validation loss: 2.059556265672048

Epoch: 5| Step: 11
Training loss: 3.9682912826538086
Validation loss: 2.0623008807500205

Epoch: 172| Step: 0
Training loss: 1.6828914880752563
Validation loss: 2.0786601503690085

Epoch: 5| Step: 1
Training loss: 1.9391721487045288
Validation loss: 2.0638975352048874

Epoch: 5| Step: 2
Training loss: 2.2735602855682373
Validation loss: 2.074645534157753

Epoch: 5| Step: 3
Training loss: 1.900208830833435
Validation loss: 2.067670385042826

Epoch: 5| Step: 4
Training loss: 2.2375524044036865
Validation loss: 2.0715955744187036

Epoch: 5| Step: 5
Training loss: 2.297619104385376
Validation loss: 2.0722992022832236

Epoch: 5| Step: 6
Training loss: 1.6231930255889893
Validation loss: 2.0771795213222504

Epoch: 5| Step: 7
Training loss: 1.7556263208389282
Validation loss: 2.077312082052231

Epoch: 5| Step: 8
Training loss: 2.2392284870147705
Validation loss: 2.063293914000193

Epoch: 5| Step: 9
Training loss: 2.186283588409424
Validation loss: 2.053880368669828

Epoch: 5| Step: 10
Training loss: 1.9516656398773193
Validation loss: 2.0653283993403115

Epoch: 5| Step: 11
Training loss: 2.8130369186401367
Validation loss: 2.07271080215772

Epoch: 173| Step: 0
Training loss: 2.457120895385742
Validation loss: 2.061465948820114

Epoch: 5| Step: 1
Training loss: 1.8448905944824219
Validation loss: 2.055044934153557

Epoch: 5| Step: 2
Training loss: 1.6896064281463623
Validation loss: 2.0447267343600593

Epoch: 5| Step: 3
Training loss: 1.8231204748153687
Validation loss: 2.0422711024681726

Epoch: 5| Step: 4
Training loss: 1.839821457862854
Validation loss: 2.0456762115160623

Epoch: 5| Step: 5
Training loss: 1.9145187139511108
Validation loss: 2.04272797703743

Epoch: 5| Step: 6
Training loss: 2.336575746536255
Validation loss: 2.0405196050802865

Epoch: 5| Step: 7
Training loss: 1.8141683340072632
Validation loss: 2.0302321861187616

Epoch: 5| Step: 8
Training loss: 2.2040352821350098
Validation loss: 2.0377422322829566

Epoch: 5| Step: 9
Training loss: 2.228423595428467
Validation loss: 2.0462822218736014

Epoch: 5| Step: 10
Training loss: 2.064455270767212
Validation loss: 2.0465641021728516

Epoch: 5| Step: 11
Training loss: 2.9306535720825195
Validation loss: 2.0481377790371575

Epoch: 174| Step: 0
Training loss: 1.7772724628448486
Validation loss: 2.0378692597150803

Epoch: 5| Step: 1
Training loss: 2.031259536743164
Validation loss: 2.0412402351697287

Epoch: 5| Step: 2
Training loss: 2.2858405113220215
Validation loss: 2.040019060174624

Epoch: 5| Step: 3
Training loss: 1.7691211700439453
Validation loss: 2.0393857260545096

Epoch: 5| Step: 4
Training loss: 1.7860996723175049
Validation loss: 2.0343347738186517

Epoch: 5| Step: 5
Training loss: 2.213127374649048
Validation loss: 2.0478476534287133

Epoch: 5| Step: 6
Training loss: 2.122272253036499
Validation loss: 2.0440521240234375

Epoch: 5| Step: 7
Training loss: 2.1379992961883545
Validation loss: 2.062380646665891

Epoch: 5| Step: 8
Training loss: 1.9635635614395142
Validation loss: 2.0528260668118796

Epoch: 5| Step: 9
Training loss: 2.1207470893859863
Validation loss: 2.048923780520757

Epoch: 5| Step: 10
Training loss: 2.0391507148742676
Validation loss: 2.057061195373535

Epoch: 5| Step: 11
Training loss: 1.9344335794448853
Validation loss: 2.0606949031352997

Epoch: 175| Step: 0
Training loss: 2.156912088394165
Validation loss: 2.0716368655363717

Epoch: 5| Step: 1
Training loss: 1.6877962350845337
Validation loss: 2.0800527781248093

Epoch: 5| Step: 2
Training loss: 2.4540741443634033
Validation loss: 2.0859777381022773

Epoch: 5| Step: 3
Training loss: 2.459411382675171
Validation loss: 2.0707180748383203

Epoch: 5| Step: 4
Training loss: 2.1295769214630127
Validation loss: 2.060354898373286

Epoch: 5| Step: 5
Training loss: 1.6616321802139282
Validation loss: 2.063716913263003

Epoch: 5| Step: 6
Training loss: 1.627833366394043
Validation loss: 2.0394160201152167

Epoch: 5| Step: 7
Training loss: 2.3730995655059814
Validation loss: 2.0492188185453415

Epoch: 5| Step: 8
Training loss: 2.0338096618652344
Validation loss: 2.0458451906840005

Epoch: 5| Step: 9
Training loss: 2.131230115890503
Validation loss: 2.0524924943844476

Epoch: 5| Step: 10
Training loss: 1.8797624111175537
Validation loss: 2.042933776974678

Epoch: 5| Step: 11
Training loss: 1.7769668102264404
Validation loss: 2.0402016093333564

Epoch: 176| Step: 0
Training loss: 2.4944186210632324
Validation loss: 2.044926772514979

Epoch: 5| Step: 1
Training loss: 1.80890691280365
Validation loss: 2.0416233142217

Epoch: 5| Step: 2
Training loss: 2.07895565032959
Validation loss: 2.0411797960599265

Epoch: 5| Step: 3
Training loss: 1.6979596614837646
Validation loss: 2.061236023902893

Epoch: 5| Step: 4
Training loss: 2.7378265857696533
Validation loss: 2.055995355049769

Epoch: 5| Step: 5
Training loss: 1.9624500274658203
Validation loss: 2.058098321159681

Epoch: 5| Step: 6
Training loss: 1.3214285373687744
Validation loss: 2.078595702846845

Epoch: 5| Step: 7
Training loss: 2.155052423477173
Validation loss: 2.0648359805345535

Epoch: 5| Step: 8
Training loss: 2.0443663597106934
Validation loss: 2.071974446376165

Epoch: 5| Step: 9
Training loss: 2.3777852058410645
Validation loss: 2.077266976237297

Epoch: 5| Step: 10
Training loss: 1.5620235204696655
Validation loss: 2.063691591223081

Epoch: 5| Step: 11
Training loss: 2.7912676334381104
Validation loss: 2.065614178776741

Epoch: 177| Step: 0
Training loss: 2.419053316116333
Validation loss: 2.0691135028998056

Epoch: 5| Step: 1
Training loss: 1.7925994396209717
Validation loss: 2.044093151887258

Epoch: 5| Step: 2
Training loss: 1.7705539464950562
Validation loss: 2.047932674487432

Epoch: 5| Step: 3
Training loss: 2.005840301513672
Validation loss: 2.0493367413679757

Epoch: 5| Step: 4
Training loss: 2.2275500297546387
Validation loss: 2.0546098152796426

Epoch: 5| Step: 5
Training loss: 1.863552451133728
Validation loss: 2.0501012404759726

Epoch: 5| Step: 6
Training loss: 1.7761058807373047
Validation loss: 2.0535310904184976

Epoch: 5| Step: 7
Training loss: 1.401792049407959
Validation loss: 2.047489210963249

Epoch: 5| Step: 8
Training loss: 2.163656234741211
Validation loss: 2.043884053826332

Epoch: 5| Step: 9
Training loss: 2.3281636238098145
Validation loss: 2.0517499297857285

Epoch: 5| Step: 10
Training loss: 2.3708393573760986
Validation loss: 2.0516284008820853

Epoch: 5| Step: 11
Training loss: 1.6048767566680908
Validation loss: 2.0569155315558114

Epoch: 178| Step: 0
Training loss: 2.0376882553100586
Validation loss: 2.0606577893098197

Epoch: 5| Step: 1
Training loss: 2.089740037918091
Validation loss: 2.0447505712509155

Epoch: 5| Step: 2
Training loss: 1.7483634948730469
Validation loss: 2.050217683116595

Epoch: 5| Step: 3
Training loss: 1.452042579650879
Validation loss: 2.05011876920859

Epoch: 5| Step: 4
Training loss: 2.38032865524292
Validation loss: 2.045460363229116

Epoch: 5| Step: 5
Training loss: 2.399853229522705
Validation loss: 2.0493547171354294

Epoch: 5| Step: 6
Training loss: 1.7495288848876953
Validation loss: 2.0442531456549964

Epoch: 5| Step: 7
Training loss: 2.523364543914795
Validation loss: 2.0472661356131234

Epoch: 5| Step: 8
Training loss: 2.0669119358062744
Validation loss: 2.043592686454455

Epoch: 5| Step: 9
Training loss: 1.8641544580459595
Validation loss: 2.044260491927465

Epoch: 5| Step: 10
Training loss: 1.9590270519256592
Validation loss: 2.0445353587468467

Epoch: 5| Step: 11
Training loss: 1.8376352787017822
Validation loss: 2.039987802505493

Epoch: 179| Step: 0
Training loss: 1.986541748046875
Validation loss: 2.048190345366796

Epoch: 5| Step: 1
Training loss: 1.8322546482086182
Validation loss: 2.0434546768665314

Epoch: 5| Step: 2
Training loss: 2.0451130867004395
Validation loss: 2.045262267192205

Epoch: 5| Step: 3
Training loss: 2.2535269260406494
Validation loss: 2.0461425532897315

Epoch: 5| Step: 4
Training loss: 1.9669857025146484
Validation loss: 2.0469762136538825

Epoch: 5| Step: 5
Training loss: 2.0771663188934326
Validation loss: 2.0461510121822357

Epoch: 5| Step: 6
Training loss: 2.401432752609253
Validation loss: 2.053246796131134

Epoch: 5| Step: 7
Training loss: 2.045419931411743
Validation loss: 2.0479393700758615

Epoch: 5| Step: 8
Training loss: 2.110288143157959
Validation loss: 2.056433061758677

Epoch: 5| Step: 9
Training loss: 1.7844130992889404
Validation loss: 2.0541715572277703

Epoch: 5| Step: 10
Training loss: 1.7909166812896729
Validation loss: 2.06050735215346

Epoch: 5| Step: 11
Training loss: 2.7068376541137695
Validation loss: 2.056231662631035

Epoch: 180| Step: 0
Training loss: 2.6084470748901367
Validation loss: 2.0525311827659607

Epoch: 5| Step: 1
Training loss: 1.6746206283569336
Validation loss: 2.059122756123543

Epoch: 5| Step: 2
Training loss: 1.8543994426727295
Validation loss: 2.0682314038276672

Epoch: 5| Step: 3
Training loss: 2.356039524078369
Validation loss: 2.0519300351540246

Epoch: 5| Step: 4
Training loss: 2.011629581451416
Validation loss: 2.0612076421578727

Epoch: 5| Step: 5
Training loss: 2.0947911739349365
Validation loss: 2.053254301349322

Epoch: 5| Step: 6
Training loss: 2.0617454051971436
Validation loss: 2.0656403650840125

Epoch: 5| Step: 7
Training loss: 1.6176799535751343
Validation loss: 2.0555975486834845

Epoch: 5| Step: 8
Training loss: 1.392015814781189
Validation loss: 2.0459978779157004

Epoch: 5| Step: 9
Training loss: 1.877176284790039
Validation loss: 2.0512598355611167

Epoch: 5| Step: 10
Training loss: 2.550135374069214
Validation loss: 2.0388597349325814

Epoch: 5| Step: 11
Training loss: 4.409691333770752
Validation loss: 2.061415712038676

Epoch: 181| Step: 0
Training loss: 2.3894004821777344
Validation loss: 2.041923334201177

Epoch: 5| Step: 1
Training loss: 2.0875210762023926
Validation loss: 2.05463237563769

Epoch: 5| Step: 2
Training loss: 2.148005247116089
Validation loss: 2.059795618057251

Epoch: 5| Step: 3
Training loss: 1.9232372045516968
Validation loss: 2.0471370021502175

Epoch: 5| Step: 4
Training loss: 2.0735344886779785
Validation loss: 2.039399728178978

Epoch: 5| Step: 5
Training loss: 1.7679246664047241
Validation loss: 2.0415854503711066

Epoch: 5| Step: 6
Training loss: 2.093693256378174
Validation loss: 2.050786793231964

Epoch: 5| Step: 7
Training loss: 1.6964040994644165
Validation loss: 2.054505546887716

Epoch: 5| Step: 8
Training loss: 2.3624391555786133
Validation loss: 2.046677981813749

Epoch: 5| Step: 9
Training loss: 1.7138391733169556
Validation loss: 2.045185918609301

Epoch: 5| Step: 10
Training loss: 2.4741358757019043
Validation loss: 2.044920414686203

Epoch: 5| Step: 11
Training loss: 0.7223160266876221
Validation loss: 2.046962395310402

Epoch: 182| Step: 0
Training loss: 2.124734878540039
Validation loss: 2.0438519765933356

Epoch: 5| Step: 1
Training loss: 2.2585811614990234
Validation loss: 2.0504437436660132

Epoch: 5| Step: 2
Training loss: 1.6196657419204712
Validation loss: 2.0389638791481652

Epoch: 5| Step: 3
Training loss: 2.0257294178009033
Validation loss: 2.049004261692365

Epoch: 5| Step: 4
Training loss: 2.239921808242798
Validation loss: 2.0381326576073966

Epoch: 5| Step: 5
Training loss: 2.1159894466400146
Validation loss: 2.040908768773079

Epoch: 5| Step: 6
Training loss: 1.889116644859314
Validation loss: 2.034087767203649

Epoch: 5| Step: 7
Training loss: 2.003803253173828
Validation loss: 2.045213902990023

Epoch: 5| Step: 8
Training loss: 1.747511863708496
Validation loss: 2.0357379615306854

Epoch: 5| Step: 9
Training loss: 1.8055107593536377
Validation loss: 2.046154702703158

Epoch: 5| Step: 10
Training loss: 2.3638370037078857
Validation loss: 2.048230608304342

Epoch: 5| Step: 11
Training loss: 2.0332794189453125
Validation loss: 2.047212769587835

Epoch: 183| Step: 0
Training loss: 1.7196838855743408
Validation loss: 2.0626262525717416

Epoch: 5| Step: 1
Training loss: 1.6669960021972656
Validation loss: 2.07093475262324

Epoch: 5| Step: 2
Training loss: 2.1911301612854004
Validation loss: 2.0912452737490335

Epoch: 5| Step: 3
Training loss: 2.516188144683838
Validation loss: 2.1005749901135764

Epoch: 5| Step: 4
Training loss: 1.6269855499267578
Validation loss: 2.127093722422918

Epoch: 5| Step: 5
Training loss: 1.6662006378173828
Validation loss: 2.084310938914617

Epoch: 5| Step: 6
Training loss: 2.328245162963867
Validation loss: 2.0774793873230615

Epoch: 5| Step: 7
Training loss: 2.5669820308685303
Validation loss: 2.083627760410309

Epoch: 5| Step: 8
Training loss: 1.8925174474716187
Validation loss: 2.0857498347759247

Epoch: 5| Step: 9
Training loss: 1.641066312789917
Validation loss: 2.0668709178765616

Epoch: 5| Step: 10
Training loss: 2.3821616172790527
Validation loss: 2.0645588537057242

Epoch: 5| Step: 11
Training loss: 2.7762017250061035
Validation loss: 2.0690588851769767

Epoch: 184| Step: 0
Training loss: 2.2997968196868896
Validation loss: 2.05826103190581

Epoch: 5| Step: 1
Training loss: 2.303212881088257
Validation loss: 2.0621748914321265

Epoch: 5| Step: 2
Training loss: 2.5047004222869873
Validation loss: 2.0578937033812204

Epoch: 5| Step: 3
Training loss: 1.6343406438827515
Validation loss: 2.051220198472341

Epoch: 5| Step: 4
Training loss: 2.46852970123291
Validation loss: 2.0528579701979957

Epoch: 5| Step: 5
Training loss: 1.6875512599945068
Validation loss: 2.048940896987915

Epoch: 5| Step: 6
Training loss: 2.0402255058288574
Validation loss: 2.0591686815023422

Epoch: 5| Step: 7
Training loss: 2.345360517501831
Validation loss: 2.0669967432816825

Epoch: 5| Step: 8
Training loss: 1.6002376079559326
Validation loss: 2.063197781642278

Epoch: 5| Step: 9
Training loss: 1.8263136148452759
Validation loss: 2.0651268512010574

Epoch: 5| Step: 10
Training loss: 1.6907994747161865
Validation loss: 2.0736392736434937

Epoch: 5| Step: 11
Training loss: 1.8509950637817383
Validation loss: 2.0784468948841095

Epoch: 185| Step: 0
Training loss: 2.1366069316864014
Validation loss: 2.077339361111323

Epoch: 5| Step: 1
Training loss: 1.498557448387146
Validation loss: 2.0782309770584106

Epoch: 5| Step: 2
Training loss: 1.7463533878326416
Validation loss: 2.057856241861979

Epoch: 5| Step: 3
Training loss: 1.9600101709365845
Validation loss: 2.0634276072184243

Epoch: 5| Step: 4
Training loss: 1.4864909648895264
Validation loss: 2.0577165136734643

Epoch: 5| Step: 5
Training loss: 2.364074230194092
Validation loss: 2.06540318330129

Epoch: 5| Step: 6
Training loss: 1.7357978820800781
Validation loss: 2.057434926430384

Epoch: 5| Step: 7
Training loss: 2.168785572052002
Validation loss: 2.0735682348410287

Epoch: 5| Step: 8
Training loss: 2.9792792797088623
Validation loss: 2.0679480582475662

Epoch: 5| Step: 9
Training loss: 2.0904791355133057
Validation loss: 2.0705618262290955

Epoch: 5| Step: 10
Training loss: 2.0327820777893066
Validation loss: 2.076276088754336

Epoch: 5| Step: 11
Training loss: 1.7127463817596436
Validation loss: 2.057313938935598

Epoch: 186| Step: 0
Training loss: 2.483116626739502
Validation loss: 2.0551870316267014

Epoch: 5| Step: 1
Training loss: 2.3223726749420166
Validation loss: 2.0527638693650565

Epoch: 5| Step: 2
Training loss: 1.7759830951690674
Validation loss: 2.0516136437654495

Epoch: 5| Step: 3
Training loss: 2.133028984069824
Validation loss: 2.0469018518924713

Epoch: 5| Step: 4
Training loss: 1.8272145986557007
Validation loss: 2.042004739244779

Epoch: 5| Step: 5
Training loss: 2.359130382537842
Validation loss: 2.0408557107051215

Epoch: 5| Step: 6
Training loss: 2.0681614875793457
Validation loss: 2.0563494861125946

Epoch: 5| Step: 7
Training loss: 1.85113525390625
Validation loss: 2.0461894472440085

Epoch: 5| Step: 8
Training loss: 1.9117523431777954
Validation loss: 2.0604130923748016

Epoch: 5| Step: 9
Training loss: 2.182255983352661
Validation loss: 2.0593942950169244

Epoch: 5| Step: 10
Training loss: 1.3016421794891357
Validation loss: 2.0709766944249473

Epoch: 5| Step: 11
Training loss: 1.6616950035095215
Validation loss: 2.0737295150756836

Epoch: 187| Step: 0
Training loss: 1.597008466720581
Validation loss: 2.082061400016149

Epoch: 5| Step: 1
Training loss: 2.4515128135681152
Validation loss: 2.092943678299586

Epoch: 5| Step: 2
Training loss: 2.4064533710479736
Validation loss: 2.0949528366327286

Epoch: 5| Step: 3
Training loss: 2.284878730773926
Validation loss: 2.0971540411313376

Epoch: 5| Step: 4
Training loss: 2.0423927307128906
Validation loss: 2.0736971497535706

Epoch: 5| Step: 5
Training loss: 2.0195658206939697
Validation loss: 2.0698222567637763

Epoch: 5| Step: 6
Training loss: 1.5579383373260498
Validation loss: 2.0554876724878945

Epoch: 5| Step: 7
Training loss: 2.090580463409424
Validation loss: 2.0479498207569122

Epoch: 5| Step: 8
Training loss: 2.016103744506836
Validation loss: 2.043610761562983

Epoch: 5| Step: 9
Training loss: 2.316099166870117
Validation loss: 2.044162154197693

Epoch: 5| Step: 10
Training loss: 2.2113757133483887
Validation loss: 2.039357160528501

Epoch: 5| Step: 11
Training loss: 1.6240360736846924
Validation loss: 2.038785850008329

Epoch: 188| Step: 0
Training loss: 2.5307090282440186
Validation loss: 2.0461964160203934

Epoch: 5| Step: 1
Training loss: 2.055398941040039
Validation loss: 2.045421818892161

Epoch: 5| Step: 2
Training loss: 1.9428479671478271
Validation loss: 2.0411833177010217

Epoch: 5| Step: 3
Training loss: 1.8057682514190674
Validation loss: 2.0534788419802985

Epoch: 5| Step: 4
Training loss: 2.62855863571167
Validation loss: 2.040412267049154

Epoch: 5| Step: 5
Training loss: 2.67687726020813
Validation loss: 2.040252481897672

Epoch: 5| Step: 6
Training loss: 1.6041415929794312
Validation loss: 2.0545291552941003

Epoch: 5| Step: 7
Training loss: 1.5608218908309937
Validation loss: 2.0563880652189255

Epoch: 5| Step: 8
Training loss: 1.9887386560440063
Validation loss: 2.0619684755802155

Epoch: 5| Step: 9
Training loss: 1.4786125421524048
Validation loss: 2.06212184826533

Epoch: 5| Step: 10
Training loss: 2.136021614074707
Validation loss: 2.0638148486614227

Epoch: 5| Step: 11
Training loss: 1.5501998662948608
Validation loss: 2.069210261106491

Epoch: 189| Step: 0
Training loss: 2.35532808303833
Validation loss: 2.066781977812449

Epoch: 5| Step: 1
Training loss: 1.769972801208496
Validation loss: 2.0690943201382956

Epoch: 5| Step: 2
Training loss: 1.8886486291885376
Validation loss: 2.0693325450023017

Epoch: 5| Step: 3
Training loss: 2.046928882598877
Validation loss: 2.080641279617945

Epoch: 5| Step: 4
Training loss: 2.0835742950439453
Validation loss: 2.070338244239489

Epoch: 5| Step: 5
Training loss: 1.7553825378417969
Validation loss: 2.0869646122058234

Epoch: 5| Step: 6
Training loss: 2.1371893882751465
Validation loss: 2.069239914417267

Epoch: 5| Step: 7
Training loss: 2.0943825244903564
Validation loss: 2.070933630069097

Epoch: 5| Step: 8
Training loss: 2.039839506149292
Validation loss: 2.062463025252024

Epoch: 5| Step: 9
Training loss: 1.9236217737197876
Validation loss: 2.074759195248286

Epoch: 5| Step: 10
Training loss: 1.9525928497314453
Validation loss: 2.0659768680731454

Epoch: 5| Step: 11
Training loss: 2.1113014221191406
Validation loss: 2.0626068313916526

Epoch: 190| Step: 0
Training loss: 1.8790614604949951
Validation loss: 2.06168324748675

Epoch: 5| Step: 1
Training loss: 1.8664484024047852
Validation loss: 2.0629746367534003

Epoch: 5| Step: 2
Training loss: 2.382990837097168
Validation loss: 2.069824144244194

Epoch: 5| Step: 3
Training loss: 2.014854669570923
Validation loss: 2.062334895133972

Epoch: 5| Step: 4
Training loss: 2.2394611835479736
Validation loss: 2.0677529076735177

Epoch: 5| Step: 5
Training loss: 2.07344651222229
Validation loss: 2.073278541366259

Epoch: 5| Step: 6
Training loss: 1.6577857732772827
Validation loss: 2.0660764575004578

Epoch: 5| Step: 7
Training loss: 2.355133056640625
Validation loss: 2.064566597342491

Epoch: 5| Step: 8
Training loss: 2.4051742553710938
Validation loss: 2.0788023124138513

Epoch: 5| Step: 9
Training loss: 1.78096604347229
Validation loss: 2.069204385081927

Epoch: 5| Step: 10
Training loss: 1.4424676895141602
Validation loss: 2.0666228234767914

Epoch: 5| Step: 11
Training loss: 1.9842156171798706
Validation loss: 2.076546256740888

Epoch: 191| Step: 0
Training loss: 2.117790460586548
Validation loss: 2.0757095714410148

Epoch: 5| Step: 1
Training loss: 2.1864917278289795
Validation loss: 2.0784951647122702

Epoch: 5| Step: 2
Training loss: 1.7605453729629517
Validation loss: 2.0877725233634314

Epoch: 5| Step: 3
Training loss: 2.4026710987091064
Validation loss: 2.082325572768847

Epoch: 5| Step: 4
Training loss: 2.491386890411377
Validation loss: 2.0818578799565635

Epoch: 5| Step: 5
Training loss: 1.659040093421936
Validation loss: 2.0651702533165612

Epoch: 5| Step: 6
Training loss: 2.1275148391723633
Validation loss: 2.0691308130820594

Epoch: 5| Step: 7
Training loss: 1.9870668649673462
Validation loss: 2.0545114626487098

Epoch: 5| Step: 8
Training loss: 1.909420371055603
Validation loss: 2.0610398153464

Epoch: 5| Step: 9
Training loss: 1.7939252853393555
Validation loss: 2.070321872830391

Epoch: 5| Step: 10
Training loss: 1.643409013748169
Validation loss: 2.065378730495771

Epoch: 5| Step: 11
Training loss: 2.132218599319458
Validation loss: 2.0749683330456414

Epoch: 192| Step: 0
Training loss: 2.415736198425293
Validation loss: 2.0758089323838553

Epoch: 5| Step: 1
Training loss: 2.154006242752075
Validation loss: 2.084550971786181

Epoch: 5| Step: 2
Training loss: 2.0816285610198975
Validation loss: 2.068031921982765

Epoch: 5| Step: 3
Training loss: 2.0086355209350586
Validation loss: 2.059176708261172

Epoch: 5| Step: 4
Training loss: 2.0815000534057617
Validation loss: 2.0627477169036865

Epoch: 5| Step: 5
Training loss: 1.8234208822250366
Validation loss: 2.068693995475769

Epoch: 5| Step: 6
Training loss: 1.877558946609497
Validation loss: 2.0769717345635095

Epoch: 5| Step: 7
Training loss: 2.167424201965332
Validation loss: 2.081076646844546

Epoch: 5| Step: 8
Training loss: 1.881786584854126
Validation loss: 2.077835271755854

Epoch: 5| Step: 9
Training loss: 1.7981936931610107
Validation loss: 2.0705860207478204

Epoch: 5| Step: 10
Training loss: 1.8275963068008423
Validation loss: 2.077599768837293

Epoch: 5| Step: 11
Training loss: 1.9061311483383179
Validation loss: 2.0771948993206024

Epoch: 193| Step: 0
Training loss: 2.151946783065796
Validation loss: 2.0605282684167228

Epoch: 5| Step: 1
Training loss: 2.1560964584350586
Validation loss: 2.0713915824890137

Epoch: 5| Step: 2
Training loss: 2.021972179412842
Validation loss: 2.0522658874591193

Epoch: 5| Step: 3
Training loss: 2.2702856063842773
Validation loss: 2.0656088342269263

Epoch: 5| Step: 4
Training loss: 1.8328468799591064
Validation loss: 2.060980439186096

Epoch: 5| Step: 5
Training loss: 1.9704755544662476
Validation loss: 2.0560289422671

Epoch: 5| Step: 6
Training loss: 2.018467426300049
Validation loss: 2.06879098713398

Epoch: 5| Step: 7
Training loss: 1.932746171951294
Validation loss: 2.0606522858142853

Epoch: 5| Step: 8
Training loss: 1.9729945659637451
Validation loss: 2.068235451976458

Epoch: 5| Step: 9
Training loss: 1.6689023971557617
Validation loss: 2.0585016111532846

Epoch: 5| Step: 10
Training loss: 2.0935683250427246
Validation loss: 2.0617118775844574

Epoch: 5| Step: 11
Training loss: 2.490225076675415
Validation loss: 2.058832531174024

Epoch: 194| Step: 0
Training loss: 1.8359047174453735
Validation loss: 2.0560091038544974

Epoch: 5| Step: 1
Training loss: 2.1881468296051025
Validation loss: 2.0560778975486755

Epoch: 5| Step: 2
Training loss: 1.537728190422058
Validation loss: 2.073824887474378

Epoch: 5| Step: 3
Training loss: 2.0133795738220215
Validation loss: 2.0727785726388297

Epoch: 5| Step: 4
Training loss: 2.5723750591278076
Validation loss: 2.0801326682170234

Epoch: 5| Step: 5
Training loss: 2.160656690597534
Validation loss: 2.0666975577672324

Epoch: 5| Step: 6
Training loss: 1.7753417491912842
Validation loss: 2.0699636290470758

Epoch: 5| Step: 7
Training loss: 1.8902623653411865
Validation loss: 2.0637052158514657

Epoch: 5| Step: 8
Training loss: 2.0496652126312256
Validation loss: 2.066518103082975

Epoch: 5| Step: 9
Training loss: 2.1575584411621094
Validation loss: 2.055938263734182

Epoch: 5| Step: 10
Training loss: 2.0512747764587402
Validation loss: 2.0466182281573615

Epoch: 5| Step: 11
Training loss: 1.775449514389038
Validation loss: 2.0465953399737677

Epoch: 195| Step: 0
Training loss: 1.9850876331329346
Validation loss: 2.054636095960935

Epoch: 5| Step: 1
Training loss: 2.2392165660858154
Validation loss: 2.0531193812688193

Epoch: 5| Step: 2
Training loss: 2.4013242721557617
Validation loss: 2.0426320880651474

Epoch: 5| Step: 3
Training loss: 1.8887983560562134
Validation loss: 2.0615548143784204

Epoch: 5| Step: 4
Training loss: 2.006714105606079
Validation loss: 2.0551227082808814

Epoch: 5| Step: 5
Training loss: 2.1222517490386963
Validation loss: 2.057999392350515

Epoch: 5| Step: 6
Training loss: 1.8653881549835205
Validation loss: 2.054397543271383

Epoch: 5| Step: 7
Training loss: 1.8872140645980835
Validation loss: 2.0626818339029946

Epoch: 5| Step: 8
Training loss: 1.6637799739837646
Validation loss: 2.0591822216908136

Epoch: 5| Step: 9
Training loss: 1.8879878520965576
Validation loss: 2.0655709554751716

Epoch: 5| Step: 10
Training loss: 1.9832146167755127
Validation loss: 2.0530492961406708

Epoch: 5| Step: 11
Training loss: 2.6432619094848633
Validation loss: 2.0695755034685135

Epoch: 196| Step: 0
Training loss: 1.572014570236206
Validation loss: 2.075155273079872

Epoch: 5| Step: 1
Training loss: 1.8165206909179688
Validation loss: 2.0757705668608346

Epoch: 5| Step: 2
Training loss: 2.1571383476257324
Validation loss: 2.0721199959516525

Epoch: 5| Step: 3
Training loss: 2.1568024158477783
Validation loss: 2.064129799604416

Epoch: 5| Step: 4
Training loss: 1.7439546585083008
Validation loss: 2.068474218249321

Epoch: 5| Step: 5
Training loss: 2.0106053352355957
Validation loss: 2.0715733021497726

Epoch: 5| Step: 6
Training loss: 1.8130617141723633
Validation loss: 2.0636718223492303

Epoch: 5| Step: 7
Training loss: 2.3907809257507324
Validation loss: 2.0653322289387384

Epoch: 5| Step: 8
Training loss: 2.048576831817627
Validation loss: 2.0686572591463723

Epoch: 5| Step: 9
Training loss: 2.5933074951171875
Validation loss: 2.074373329679171

Epoch: 5| Step: 10
Training loss: 1.812665343284607
Validation loss: 2.0703703463077545

Epoch: 5| Step: 11
Training loss: 1.7259976863861084
Validation loss: 2.070126806696256

Epoch: 197| Step: 0
Training loss: 1.3716298341751099
Validation loss: 2.0749072333176932

Epoch: 5| Step: 1
Training loss: 1.4249168634414673
Validation loss: 2.080039153496424

Epoch: 5| Step: 2
Training loss: 2.0424423217773438
Validation loss: 2.085435926914215

Epoch: 5| Step: 3
Training loss: 2.022989273071289
Validation loss: 2.0924696375926337

Epoch: 5| Step: 4
Training loss: 2.2323977947235107
Validation loss: 2.1076129426558814

Epoch: 5| Step: 5
Training loss: 1.7843583822250366
Validation loss: 2.128067751725515

Epoch: 5| Step: 6
Training loss: 2.194511890411377
Validation loss: 2.1066005577643714

Epoch: 5| Step: 7
Training loss: 2.8159422874450684
Validation loss: 2.0983109921216965

Epoch: 5| Step: 8
Training loss: 2.346059560775757
Validation loss: 2.09389229118824

Epoch: 5| Step: 9
Training loss: 2.285616397857666
Validation loss: 2.1022976338863373

Epoch: 5| Step: 10
Training loss: 1.7747790813446045
Validation loss: 2.0971779922644296

Epoch: 5| Step: 11
Training loss: 2.0238072872161865
Validation loss: 2.088703006505966

Epoch: 198| Step: 0
Training loss: 1.4155884981155396
Validation loss: 2.1059367607037225

Epoch: 5| Step: 1
Training loss: 1.887117624282837
Validation loss: 2.083945115407308

Epoch: 5| Step: 2
Training loss: 1.688561201095581
Validation loss: 2.0853995978832245

Epoch: 5| Step: 3
Training loss: 1.8205299377441406
Validation loss: 2.0914624532063804

Epoch: 5| Step: 4
Training loss: 2.909940481185913
Validation loss: 2.0955500404040017

Epoch: 5| Step: 5
Training loss: 1.9436330795288086
Validation loss: 2.0783292849858603

Epoch: 5| Step: 6
Training loss: 1.9494552612304688
Validation loss: 2.0903201003869376

Epoch: 5| Step: 7
Training loss: 1.975583791732788
Validation loss: 2.072993422547976

Epoch: 5| Step: 8
Training loss: 1.842002272605896
Validation loss: 2.080388238032659

Epoch: 5| Step: 9
Training loss: 2.601780414581299
Validation loss: 2.0779162695010505

Epoch: 5| Step: 10
Training loss: 1.6968262195587158
Validation loss: 2.0632974753777185

Epoch: 5| Step: 11
Training loss: 3.2544283866882324
Validation loss: 2.0740424344937005

Epoch: 199| Step: 0
Training loss: 1.681618332862854
Validation loss: 2.07344987988472

Epoch: 5| Step: 1
Training loss: 1.9676685333251953
Validation loss: 2.071087136864662

Epoch: 5| Step: 2
Training loss: 2.2451305389404297
Validation loss: 2.084619010488192

Epoch: 5| Step: 3
Training loss: 1.770679235458374
Validation loss: 2.070081040263176

Epoch: 5| Step: 4
Training loss: 1.4852782487869263
Validation loss: 2.078229397535324

Epoch: 5| Step: 5
Training loss: 2.114029884338379
Validation loss: 2.0877069582541785

Epoch: 5| Step: 6
Training loss: 2.343400716781616
Validation loss: 2.0827916810909906

Epoch: 5| Step: 7
Training loss: 2.0960943698883057
Validation loss: 2.088340625166893

Epoch: 5| Step: 8
Training loss: 1.4815088510513306
Validation loss: 2.069107304016749

Epoch: 5| Step: 9
Training loss: 2.6207211017608643
Validation loss: 2.0890462150176368

Epoch: 5| Step: 10
Training loss: 2.1636431217193604
Validation loss: 2.090497781833013

Epoch: 5| Step: 11
Training loss: 1.1359901428222656
Validation loss: 2.093921502431234

Epoch: 200| Step: 0
Training loss: 1.6416566371917725
Validation loss: 2.0926005939642587

Epoch: 5| Step: 1
Training loss: 2.254284381866455
Validation loss: 2.0885675251483917

Epoch: 5| Step: 2
Training loss: 1.7443068027496338
Validation loss: 2.0821521331866584

Epoch: 5| Step: 3
Training loss: 1.688076376914978
Validation loss: 2.0751389066378274

Epoch: 5| Step: 4
Training loss: 2.475454330444336
Validation loss: 2.077434321244558

Epoch: 5| Step: 5
Training loss: 2.374253749847412
Validation loss: 2.0849835326274238

Epoch: 5| Step: 6
Training loss: 2.303864002227783
Validation loss: 2.069835921128591

Epoch: 5| Step: 7
Training loss: 1.5328197479248047
Validation loss: 2.070753668745359

Epoch: 5| Step: 8
Training loss: 2.617431640625
Validation loss: 2.079409182071686

Epoch: 5| Step: 9
Training loss: 1.9350351095199585
Validation loss: 2.0703789641459784

Epoch: 5| Step: 10
Training loss: 1.6783154010772705
Validation loss: 2.0728733986616135

Epoch: 5| Step: 11
Training loss: 2.6420364379882812
Validation loss: 2.071440910299619

Epoch: 201| Step: 0
Training loss: 2.1911792755126953
Validation loss: 2.0781299571196237

Epoch: 5| Step: 1
Training loss: 2.1368746757507324
Validation loss: 2.082003742456436

Epoch: 5| Step: 2
Training loss: 2.1015360355377197
Validation loss: 2.088210860888163

Epoch: 5| Step: 3
Training loss: 2.1652626991271973
Validation loss: 2.090256914496422

Epoch: 5| Step: 4
Training loss: 2.049774646759033
Validation loss: 2.106074874599775

Epoch: 5| Step: 5
Training loss: 1.8318239450454712
Validation loss: 2.1066439151763916

Epoch: 5| Step: 6
Training loss: 2.277747631072998
Validation loss: 2.1184621453285217

Epoch: 5| Step: 7
Training loss: 2.062368392944336
Validation loss: 2.1096273163954415

Epoch: 5| Step: 8
Training loss: 1.711416482925415
Validation loss: 2.111558919151624

Epoch: 5| Step: 9
Training loss: 2.014350175857544
Validation loss: 2.10139795144399

Epoch: 5| Step: 10
Training loss: 1.9106069803237915
Validation loss: 2.0934685419003167

Epoch: 5| Step: 11
Training loss: 0.9917724132537842
Validation loss: 2.073464627067248

Epoch: 202| Step: 0
Training loss: 1.891821265220642
Validation loss: 2.0968101024627686

Epoch: 5| Step: 1
Training loss: 1.916264295578003
Validation loss: 2.087844207882881

Epoch: 5| Step: 2
Training loss: 1.8160762786865234
Validation loss: 2.09644045929114

Epoch: 5| Step: 3
Training loss: 2.9376819133758545
Validation loss: 2.085364878177643

Epoch: 5| Step: 4
Training loss: 1.7362892627716064
Validation loss: 2.0842128793398538

Epoch: 5| Step: 5
Training loss: 2.210707664489746
Validation loss: 2.0952366640170417

Epoch: 5| Step: 6
Training loss: 1.8337494134902954
Validation loss: 2.093698268135389

Epoch: 5| Step: 7
Training loss: 1.6629406213760376
Validation loss: 2.1085667610168457

Epoch: 5| Step: 8
Training loss: 2.1575729846954346
Validation loss: 2.102623855074247

Epoch: 5| Step: 9
Training loss: 2.389326572418213
Validation loss: 2.105709741512934

Epoch: 5| Step: 10
Training loss: 1.2121143341064453
Validation loss: 2.102059910694758

Epoch: 5| Step: 11
Training loss: 1.1065754890441895
Validation loss: 2.1095469892024994

Epoch: 203| Step: 0
Training loss: 1.7946302890777588
Validation loss: 2.0826022873322168

Epoch: 5| Step: 1
Training loss: 1.9392099380493164
Validation loss: 2.0728934009869895

Epoch: 5| Step: 2
Training loss: 2.4784722328186035
Validation loss: 2.058177729447683

Epoch: 5| Step: 3
Training loss: 2.085573434829712
Validation loss: 2.0541324267784753

Epoch: 5| Step: 4
Training loss: 2.1449761390686035
Validation loss: 2.0647348513205848

Epoch: 5| Step: 5
Training loss: 2.279458999633789
Validation loss: 2.0592096050580344

Epoch: 5| Step: 6
Training loss: 1.7896740436553955
Validation loss: 2.059701363245646

Epoch: 5| Step: 7
Training loss: 2.022395133972168
Validation loss: 2.0759006241957345

Epoch: 5| Step: 8
Training loss: 2.3369531631469727
Validation loss: 2.0702189107735953

Epoch: 5| Step: 9
Training loss: 1.806261420249939
Validation loss: 2.087749550739924

Epoch: 5| Step: 10
Training loss: 1.2720768451690674
Validation loss: 2.100431660811106

Epoch: 5| Step: 11
Training loss: 1.9074513912200928
Validation loss: 2.0945199579000473

Epoch: 204| Step: 0
Training loss: 1.770416259765625
Validation loss: 2.0952690045038858

Epoch: 5| Step: 1
Training loss: 1.976087212562561
Validation loss: 2.1013438751300177

Epoch: 5| Step: 2
Training loss: 1.7022011280059814
Validation loss: 2.0825770099957785

Epoch: 5| Step: 3
Training loss: 2.068390130996704
Validation loss: 2.0938788652420044

Epoch: 5| Step: 4
Training loss: 1.8311249017715454
Validation loss: 2.084293102224668

Epoch: 5| Step: 5
Training loss: 2.336385488510132
Validation loss: 2.0854166746139526

Epoch: 5| Step: 6
Training loss: 2.2454538345336914
Validation loss: 2.087489585081736

Epoch: 5| Step: 7
Training loss: 2.2372665405273438
Validation loss: 2.0924785484870276

Epoch: 5| Step: 8
Training loss: 1.432542085647583
Validation loss: 2.08891827861468

Epoch: 5| Step: 9
Training loss: 1.859941840171814
Validation loss: 2.085246895750364

Epoch: 5| Step: 10
Training loss: 2.0651211738586426
Validation loss: 2.0890489518642426

Epoch: 5| Step: 11
Training loss: 2.1831321716308594
Validation loss: 2.0918783148129783

Epoch: 205| Step: 0
Training loss: 1.502719521522522
Validation loss: 2.0831942359606423

Epoch: 5| Step: 1
Training loss: 2.3470613956451416
Validation loss: 2.0920600096384683

Epoch: 5| Step: 2
Training loss: 1.768978476524353
Validation loss: 2.08758145570755

Epoch: 5| Step: 3
Training loss: 2.143627166748047
Validation loss: 2.085349773367246

Epoch: 5| Step: 4
Training loss: 2.160175323486328
Validation loss: 2.091409593820572

Epoch: 5| Step: 5
Training loss: 1.988039255142212
Validation loss: 2.084229658047358

Epoch: 5| Step: 6
Training loss: 1.7695739269256592
Validation loss: 2.079430967569351

Epoch: 5| Step: 7
Training loss: 1.8199743032455444
Validation loss: 2.087388758858045

Epoch: 5| Step: 8
Training loss: 1.67732834815979
Validation loss: 2.079024796684583

Epoch: 5| Step: 9
Training loss: 1.8416246175765991
Validation loss: 2.0809518843889236

Epoch: 5| Step: 10
Training loss: 2.559377908706665
Validation loss: 2.0876592248678207

Epoch: 5| Step: 11
Training loss: 2.178651809692383
Validation loss: 2.0944571842749915

Epoch: 206| Step: 0
Training loss: 2.1572046279907227
Validation loss: 2.080888291200002

Epoch: 5| Step: 1
Training loss: 2.176487445831299
Validation loss: 2.07764740784963

Epoch: 5| Step: 2
Training loss: 1.977961540222168
Validation loss: 2.080482989549637

Epoch: 5| Step: 3
Training loss: 1.8345327377319336
Validation loss: 2.0684121946493783

Epoch: 5| Step: 4
Training loss: 1.8360942602157593
Validation loss: 2.084800829490026

Epoch: 5| Step: 5
Training loss: 1.9380099773406982
Validation loss: 2.0688013434410095

Epoch: 5| Step: 6
Training loss: 1.9581645727157593
Validation loss: 2.0782876710096994

Epoch: 5| Step: 7
Training loss: 1.6910899877548218
Validation loss: 2.072222799062729

Epoch: 5| Step: 8
Training loss: 2.3825156688690186
Validation loss: 2.070668414235115

Epoch: 5| Step: 9
Training loss: 1.5287930965423584
Validation loss: 2.0638730575640998

Epoch: 5| Step: 10
Training loss: 2.386667013168335
Validation loss: 2.074654459953308

Epoch: 5| Step: 11
Training loss: 1.7384209632873535
Validation loss: 2.0641413778066635

Epoch: 207| Step: 0
Training loss: 1.8003902435302734
Validation loss: 2.0764355957508087

Epoch: 5| Step: 1
Training loss: 1.9289335012435913
Validation loss: 2.077692066629728

Epoch: 5| Step: 2
Training loss: 1.9046919345855713
Validation loss: 2.0789610693852105

Epoch: 5| Step: 3
Training loss: 2.204885721206665
Validation loss: 2.0705506900946298

Epoch: 5| Step: 4
Training loss: 2.3088269233703613
Validation loss: 2.07398983836174

Epoch: 5| Step: 5
Training loss: 1.4705874919891357
Validation loss: 2.077023615439733

Epoch: 5| Step: 6
Training loss: 2.128910541534424
Validation loss: 2.0784878830115

Epoch: 5| Step: 7
Training loss: 2.0187249183654785
Validation loss: 2.086384763320287

Epoch: 5| Step: 8
Training loss: 1.837405800819397
Validation loss: 2.0797675301631293

Epoch: 5| Step: 9
Training loss: 2.292571783065796
Validation loss: 2.094300096233686

Epoch: 5| Step: 10
Training loss: 2.0000393390655518
Validation loss: 2.08186799287796

Epoch: 5| Step: 11
Training loss: 1.2861196994781494
Validation loss: 2.083504324158033

Epoch: 208| Step: 0
Training loss: 1.7488791942596436
Validation loss: 2.0914714286724725

Epoch: 5| Step: 1
Training loss: 1.3223298788070679
Validation loss: 2.0825530042250953

Epoch: 5| Step: 2
Training loss: 2.3863308429718018
Validation loss: 2.073228528102239

Epoch: 5| Step: 3
Training loss: 2.1566309928894043
Validation loss: 2.072985385855039

Epoch: 5| Step: 4
Training loss: 2.0675368309020996
Validation loss: 2.080647751688957

Epoch: 5| Step: 5
Training loss: 2.346330404281616
Validation loss: 2.0764474173386893

Epoch: 5| Step: 6
Training loss: 1.7453171014785767
Validation loss: 2.079771339893341

Epoch: 5| Step: 7
Training loss: 2.3147757053375244
Validation loss: 2.0658681988716125

Epoch: 5| Step: 8
Training loss: 2.129868984222412
Validation loss: 2.0668548146883645

Epoch: 5| Step: 9
Training loss: 1.9790370464324951
Validation loss: 2.0808261732260385

Epoch: 5| Step: 10
Training loss: 1.877350091934204
Validation loss: 2.0900687177975974

Epoch: 5| Step: 11
Training loss: 1.3375184535980225
Validation loss: 2.092527906099955

Epoch: 209| Step: 0
Training loss: 1.876929521560669
Validation loss: 2.0930734872817993

Epoch: 5| Step: 1
Training loss: 2.3866500854492188
Validation loss: 2.1098500390847525

Epoch: 5| Step: 2
Training loss: 2.080869674682617
Validation loss: 2.1058878699938455

Epoch: 5| Step: 3
Training loss: 2.0753719806671143
Validation loss: 2.1306975881258645

Epoch: 5| Step: 4
Training loss: 1.9361339807510376
Validation loss: 2.1483316818873086

Epoch: 5| Step: 5
Training loss: 1.8646358251571655
Validation loss: 2.1706471045811973

Epoch: 5| Step: 6
Training loss: 2.147937297821045
Validation loss: 2.122385839621226

Epoch: 5| Step: 7
Training loss: 2.387392520904541
Validation loss: 2.111870288848877

Epoch: 5| Step: 8
Training loss: 2.3547446727752686
Validation loss: 2.0868807236353555

Epoch: 5| Step: 9
Training loss: 1.4279649257659912
Validation loss: 2.0643471529086432

Epoch: 5| Step: 10
Training loss: 1.6908390522003174
Validation loss: 2.064895416299502

Epoch: 5| Step: 11
Training loss: 1.8517588376998901
Validation loss: 2.0700157483418784

Epoch: 210| Step: 0
Training loss: 2.0985522270202637
Validation loss: 2.0590185870726905

Epoch: 5| Step: 1
Training loss: 1.6988685131072998
Validation loss: 2.0594126731157303

Epoch: 5| Step: 2
Training loss: 2.3477909564971924
Validation loss: 2.0620976040760675

Epoch: 5| Step: 3
Training loss: 2.1210901737213135
Validation loss: 2.0588166614373526

Epoch: 5| Step: 4
Training loss: 2.142108678817749
Validation loss: 2.05803174773852

Epoch: 5| Step: 5
Training loss: 2.350865602493286
Validation loss: 2.06302701930205

Epoch: 5| Step: 6
Training loss: 1.5492792129516602
Validation loss: 2.0579284032185874

Epoch: 5| Step: 7
Training loss: 2.005417585372925
Validation loss: 2.0531794279813766

Epoch: 5| Step: 8
Training loss: 2.0981948375701904
Validation loss: 2.0688296258449554

Epoch: 5| Step: 9
Training loss: 1.9262202978134155
Validation loss: 2.0602752218643823

Epoch: 5| Step: 10
Training loss: 1.782552719116211
Validation loss: 2.071530759334564

Epoch: 5| Step: 11
Training loss: 1.9452403783798218
Validation loss: 2.0796234558025994

Epoch: 211| Step: 0
Training loss: 2.281158685684204
Validation loss: 2.070497194925944

Epoch: 5| Step: 1
Training loss: 2.3177309036254883
Validation loss: 2.0894053330024085

Epoch: 5| Step: 2
Training loss: 2.8203012943267822
Validation loss: 2.093659525116285

Epoch: 5| Step: 3
Training loss: 2.3357856273651123
Validation loss: 2.111050938566526

Epoch: 5| Step: 4
Training loss: 1.5896902084350586
Validation loss: 2.0909505983193717

Epoch: 5| Step: 5
Training loss: 1.973899245262146
Validation loss: 2.0874124616384506

Epoch: 5| Step: 6
Training loss: 1.3735148906707764
Validation loss: 2.0710949351390204

Epoch: 5| Step: 7
Training loss: 2.5409748554229736
Validation loss: 2.073322117328644

Epoch: 5| Step: 8
Training loss: 2.0712192058563232
Validation loss: 2.07195915778478

Epoch: 5| Step: 9
Training loss: 1.3090845346450806
Validation loss: 2.0627163350582123

Epoch: 5| Step: 10
Training loss: 1.523605465888977
Validation loss: 2.069398989280065

Epoch: 5| Step: 11
Training loss: 1.8369814157485962
Validation loss: 2.0660908122857413

Epoch: 212| Step: 0
Training loss: 2.112830638885498
Validation loss: 2.075819820165634

Epoch: 5| Step: 1
Training loss: 1.6375882625579834
Validation loss: 2.070979669690132

Epoch: 5| Step: 2
Training loss: 2.3361780643463135
Validation loss: 2.0620868653059006

Epoch: 5| Step: 3
Training loss: 1.7669696807861328
Validation loss: 2.0710806300242743

Epoch: 5| Step: 4
Training loss: 2.1438510417938232
Validation loss: 2.0745691607395806

Epoch: 5| Step: 5
Training loss: 2.2626800537109375
Validation loss: 2.0690450171629586

Epoch: 5| Step: 6
Training loss: 2.2543299198150635
Validation loss: 2.084260488549868

Epoch: 5| Step: 7
Training loss: 1.582667589187622
Validation loss: 2.0825487077236176

Epoch: 5| Step: 8
Training loss: 1.875623345375061
Validation loss: 2.0898500184218087

Epoch: 5| Step: 9
Training loss: 1.2637689113616943
Validation loss: 2.099532832702001

Epoch: 5| Step: 10
Training loss: 2.42509126663208
Validation loss: 2.094661350051562

Epoch: 5| Step: 11
Training loss: 3.122297525405884
Validation loss: 2.1064723134040833

Epoch: 213| Step: 0
Training loss: 1.6394439935684204
Validation loss: 2.1027469535668692

Epoch: 5| Step: 1
Training loss: 1.322089433670044
Validation loss: 2.1034814218680062

Epoch: 5| Step: 2
Training loss: 1.782546043395996
Validation loss: 2.1002333958943686

Epoch: 5| Step: 3
Training loss: 2.586280107498169
Validation loss: 2.0870402256647744

Epoch: 5| Step: 4
Training loss: 2.0901126861572266
Validation loss: 2.0984290738900504

Epoch: 5| Step: 5
Training loss: 1.9778741598129272
Validation loss: 2.093747610847155

Epoch: 5| Step: 6
Training loss: 2.222472906112671
Validation loss: 2.090744271874428

Epoch: 5| Step: 7
Training loss: 1.8282289505004883
Validation loss: 2.0923496037721634

Epoch: 5| Step: 8
Training loss: 1.9328724145889282
Validation loss: 2.081811179717382

Epoch: 5| Step: 9
Training loss: 2.120755195617676
Validation loss: 2.073257625102997

Epoch: 5| Step: 10
Training loss: 1.904319405555725
Validation loss: 2.084006359179815

Epoch: 5| Step: 11
Training loss: 3.3577489852905273
Validation loss: 2.085405429204305

Epoch: 214| Step: 0
Training loss: 2.2365384101867676
Validation loss: 2.0719953974088035

Epoch: 5| Step: 1
Training loss: 1.878551721572876
Validation loss: 2.079843819141388

Epoch: 5| Step: 2
Training loss: 2.0803043842315674
Validation loss: 2.0806373010079064

Epoch: 5| Step: 3
Training loss: 2.61510968208313
Validation loss: 2.0895785987377167

Epoch: 5| Step: 4
Training loss: 1.3187593221664429
Validation loss: 2.0929804891347885

Epoch: 5| Step: 5
Training loss: 1.5587079524993896
Validation loss: 2.1047076930602393

Epoch: 5| Step: 6
Training loss: 2.010279893875122
Validation loss: 2.1029577453931174

Epoch: 5| Step: 7
Training loss: 2.3121418952941895
Validation loss: 2.107871949672699

Epoch: 5| Step: 8
Training loss: 1.5614153146743774
Validation loss: 2.0996411939462027

Epoch: 5| Step: 9
Training loss: 1.8275865316390991
Validation loss: 2.1128326753775277

Epoch: 5| Step: 10
Training loss: 1.9443318843841553
Validation loss: 2.1217714697122574

Epoch: 5| Step: 11
Training loss: 3.330078601837158
Validation loss: 2.0994296173254647

Epoch: 215| Step: 0
Training loss: 1.8816897869110107
Validation loss: 2.122503717740377

Epoch: 5| Step: 1
Training loss: 1.7129476070404053
Validation loss: 2.107720454533895

Epoch: 5| Step: 2
Training loss: 1.8312394618988037
Validation loss: 2.095678652326266

Epoch: 5| Step: 3
Training loss: 1.9040460586547852
Validation loss: 2.088129475712776

Epoch: 5| Step: 4
Training loss: 2.0665597915649414
Validation loss: 2.0821967323621116

Epoch: 5| Step: 5
Training loss: 2.0026931762695312
Validation loss: 2.0889909664789834

Epoch: 5| Step: 6
Training loss: 1.7183526754379272
Validation loss: 2.099705715974172

Epoch: 5| Step: 7
Training loss: 2.282649517059326
Validation loss: 2.080343797802925

Epoch: 5| Step: 8
Training loss: 2.0505080223083496
Validation loss: 2.091076831022898

Epoch: 5| Step: 9
Training loss: 2.195319890975952
Validation loss: 2.084558978676796

Epoch: 5| Step: 10
Training loss: 2.23173189163208
Validation loss: 2.086929256717364

Epoch: 5| Step: 11
Training loss: 2.225919008255005
Validation loss: 2.0970461716254554

Epoch: 216| Step: 0
Training loss: 1.8004705905914307
Validation loss: 2.100869302948316

Epoch: 5| Step: 1
Training loss: 1.872248888015747
Validation loss: 2.0955557972192764

Epoch: 5| Step: 2
Training loss: 2.0535078048706055
Validation loss: 2.101199651757876

Epoch: 5| Step: 3
Training loss: 2.3528456687927246
Validation loss: 2.099079112211863

Epoch: 5| Step: 4
Training loss: 1.7675883769989014
Validation loss: 2.088064879179001

Epoch: 5| Step: 5
Training loss: 2.1178336143493652
Validation loss: 2.0905131300290427

Epoch: 5| Step: 6
Training loss: 1.7069803476333618
Validation loss: 2.0947785675525665

Epoch: 5| Step: 7
Training loss: 2.4002413749694824
Validation loss: 2.0915129830439887

Epoch: 5| Step: 8
Training loss: 1.6552248001098633
Validation loss: 2.092389906446139

Epoch: 5| Step: 9
Training loss: 2.3372693061828613
Validation loss: 2.0913098206122718

Epoch: 5| Step: 10
Training loss: 1.7568271160125732
Validation loss: 2.083270475268364

Epoch: 5| Step: 11
Training loss: 2.2800841331481934
Validation loss: 2.0846211463212967

Epoch: 217| Step: 0
Training loss: 1.7851381301879883
Validation loss: 2.089365909496943

Epoch: 5| Step: 1
Training loss: 1.849373459815979
Validation loss: 2.0780168573061624

Epoch: 5| Step: 2
Training loss: 1.9106372594833374
Validation loss: 2.089937408765157

Epoch: 5| Step: 3
Training loss: 2.320619821548462
Validation loss: 2.0948180655638375

Epoch: 5| Step: 4
Training loss: 1.517922043800354
Validation loss: 2.0900777081648507

Epoch: 5| Step: 5
Training loss: 2.551562786102295
Validation loss: 2.100771889090538

Epoch: 5| Step: 6
Training loss: 1.656170129776001
Validation loss: 2.102317973971367

Epoch: 5| Step: 7
Training loss: 2.3775622844696045
Validation loss: 2.10050701101621

Epoch: 5| Step: 8
Training loss: 1.8440992832183838
Validation loss: 2.1078581462303796

Epoch: 5| Step: 9
Training loss: 1.8818953037261963
Validation loss: 2.0946887930234275

Epoch: 5| Step: 10
Training loss: 1.8196287155151367
Validation loss: 2.111721063653628

Epoch: 5| Step: 11
Training loss: 1.4158637523651123
Validation loss: 2.0991246749957404

Epoch: 218| Step: 0
Training loss: 1.8716964721679688
Validation loss: 2.104166865348816

Epoch: 5| Step: 1
Training loss: 2.120197296142578
Validation loss: 2.100733498732249

Epoch: 5| Step: 2
Training loss: 1.784057378768921
Validation loss: 2.115206301212311

Epoch: 5| Step: 3
Training loss: 2.3722450733184814
Validation loss: 2.094820410013199

Epoch: 5| Step: 4
Training loss: 1.3146003484725952
Validation loss: 2.1019570032755532

Epoch: 5| Step: 5
Training loss: 1.6835018396377563
Validation loss: 2.0801768650611243

Epoch: 5| Step: 6
Training loss: 1.747125267982483
Validation loss: 2.094339907169342

Epoch: 5| Step: 7
Training loss: 1.8770935535430908
Validation loss: 2.089891701936722

Epoch: 5| Step: 8
Training loss: 1.9626598358154297
Validation loss: 2.086847792069117

Epoch: 5| Step: 9
Training loss: 2.5176498889923096
Validation loss: 2.115617116292318

Epoch: 5| Step: 10
Training loss: 2.1245970726013184
Validation loss: 2.1074728270371756

Epoch: 5| Step: 11
Training loss: 3.309267282485962
Validation loss: 2.1212893476088843

Epoch: 219| Step: 0
Training loss: 1.9453647136688232
Validation loss: 2.1007723162571588

Epoch: 5| Step: 1
Training loss: 1.8663651943206787
Validation loss: 2.102381944656372

Epoch: 5| Step: 2
Training loss: 2.2407689094543457
Validation loss: 2.1118816832701364

Epoch: 5| Step: 3
Training loss: 2.398247241973877
Validation loss: 2.0992004672686257

Epoch: 5| Step: 4
Training loss: 1.8077176809310913
Validation loss: 2.0979428191979728

Epoch: 5| Step: 5
Training loss: 1.8758761882781982
Validation loss: 2.0973756512006125

Epoch: 5| Step: 6
Training loss: 1.8205814361572266
Validation loss: 2.116849089662234

Epoch: 5| Step: 7
Training loss: 2.3772215843200684
Validation loss: 2.120221753915151

Epoch: 5| Step: 8
Training loss: 2.0727508068084717
Validation loss: 2.116666629910469

Epoch: 5| Step: 9
Training loss: 1.7603496313095093
Validation loss: 2.1050523122151694

Epoch: 5| Step: 10
Training loss: 1.4769995212554932
Validation loss: 2.1025985926389694

Epoch: 5| Step: 11
Training loss: 1.2424708604812622
Validation loss: 2.105513652165731

Epoch: 220| Step: 0
Training loss: 1.5987229347229004
Validation loss: 2.088920141259829

Epoch: 5| Step: 1
Training loss: 1.959899663925171
Validation loss: 2.0908068815867105

Epoch: 5| Step: 2
Training loss: 2.0626094341278076
Validation loss: 2.089514230688413

Epoch: 5| Step: 3
Training loss: 1.8778804540634155
Validation loss: 2.0713781466086707

Epoch: 5| Step: 4
Training loss: 2.054514169692993
Validation loss: 2.0797660698493323

Epoch: 5| Step: 5
Training loss: 2.1566162109375
Validation loss: 2.081544116139412

Epoch: 5| Step: 6
Training loss: 1.9813404083251953
Validation loss: 2.08325723807017

Epoch: 5| Step: 7
Training loss: 1.689276099205017
Validation loss: 2.094650069872538

Epoch: 5| Step: 8
Training loss: 2.6189842224121094
Validation loss: 2.101441810528437

Epoch: 5| Step: 9
Training loss: 2.2402966022491455
Validation loss: 2.1081609278917313

Epoch: 5| Step: 10
Training loss: 1.6531438827514648
Validation loss: 2.0799487282832465

Epoch: 5| Step: 11
Training loss: 1.6625431776046753
Validation loss: 2.0997318476438522

Epoch: 221| Step: 0
Training loss: 2.0270402431488037
Validation loss: 2.1161657522122064

Epoch: 5| Step: 1
Training loss: 1.5290071964263916
Validation loss: 2.0912105987469354

Epoch: 5| Step: 2
Training loss: 1.9133573770523071
Validation loss: 2.0997458547353745

Epoch: 5| Step: 3
Training loss: 1.9677371978759766
Validation loss: 2.098315586646398

Epoch: 5| Step: 4
Training loss: 1.7279331684112549
Validation loss: 2.122784197330475

Epoch: 5| Step: 5
Training loss: 2.008655071258545
Validation loss: 2.111052622397741

Epoch: 5| Step: 6
Training loss: 1.8606750965118408
Validation loss: 2.122417852282524

Epoch: 5| Step: 7
Training loss: 1.9835987091064453
Validation loss: 2.115056941906611

Epoch: 5| Step: 8
Training loss: 2.0950350761413574
Validation loss: 2.1127082208792367

Epoch: 5| Step: 9
Training loss: 2.1160974502563477
Validation loss: 2.1149539401133857

Epoch: 5| Step: 10
Training loss: 1.9682857990264893
Validation loss: 2.121680517991384

Epoch: 5| Step: 11
Training loss: 2.21777606010437
Validation loss: 2.1373849709828696

Epoch: 222| Step: 0
Training loss: 1.9253034591674805
Validation loss: 2.1399189978837967

Epoch: 5| Step: 1
Training loss: 1.9719505310058594
Validation loss: 2.115607668956121

Epoch: 5| Step: 2
Training loss: 1.5981770753860474
Validation loss: 2.104067196448644

Epoch: 5| Step: 3
Training loss: 1.9197490215301514
Validation loss: 2.1172367384036384

Epoch: 5| Step: 4
Training loss: 2.0141937732696533
Validation loss: 2.105857456723849

Epoch: 5| Step: 5
Training loss: 1.6787248849868774
Validation loss: 2.1143995920817056

Epoch: 5| Step: 6
Training loss: 1.7084461450576782
Validation loss: 2.1123303969701133

Epoch: 5| Step: 7
Training loss: 2.4106783866882324
Validation loss: 2.104199692606926

Epoch: 5| Step: 8
Training loss: 1.1878598928451538
Validation loss: 2.117529888947805

Epoch: 5| Step: 9
Training loss: 2.3400697708129883
Validation loss: 2.1040847649176917

Epoch: 5| Step: 10
Training loss: 2.261586904525757
Validation loss: 2.113789275288582

Epoch: 5| Step: 11
Training loss: 2.677734136581421
Validation loss: 2.112668881813685

Epoch: 223| Step: 0
Training loss: 1.9326835870742798
Validation loss: 2.1285794228315353

Epoch: 5| Step: 1
Training loss: 1.6864280700683594
Validation loss: 2.106530636548996

Epoch: 5| Step: 2
Training loss: 1.8312251567840576
Validation loss: 2.119022856156031

Epoch: 5| Step: 3
Training loss: 1.9672034978866577
Validation loss: 2.1171762148539224

Epoch: 5| Step: 4
Training loss: 1.8941259384155273
Validation loss: 2.125758190949758

Epoch: 5| Step: 5
Training loss: 1.9033453464508057
Validation loss: 2.104210078716278

Epoch: 5| Step: 6
Training loss: 1.9626182317733765
Validation loss: 2.124749327699343

Epoch: 5| Step: 7
Training loss: 1.7100460529327393
Validation loss: 2.120952308177948

Epoch: 5| Step: 8
Training loss: 1.9324569702148438
Validation loss: 2.1350723206996918

Epoch: 5| Step: 9
Training loss: 2.3566622734069824
Validation loss: 2.1220529278119407

Epoch: 5| Step: 10
Training loss: 1.9374637603759766
Validation loss: 2.1151481370131173

Epoch: 5| Step: 11
Training loss: 1.9316895008087158
Validation loss: 2.119934176405271

Epoch: 224| Step: 0
Training loss: 1.8266124725341797
Validation loss: 2.1197340240081153

Epoch: 5| Step: 1
Training loss: 1.817070722579956
Validation loss: 2.117022931575775

Epoch: 5| Step: 2
Training loss: 1.8548202514648438
Validation loss: 2.1216101000706353

Epoch: 5| Step: 3
Training loss: 2.066101551055908
Validation loss: 2.111914187669754

Epoch: 5| Step: 4
Training loss: 1.4241602420806885
Validation loss: 2.1106434017419815

Epoch: 5| Step: 5
Training loss: 2.5189013481140137
Validation loss: 2.12192831436793

Epoch: 5| Step: 6
Training loss: 1.47148597240448
Validation loss: 2.122107610106468

Epoch: 5| Step: 7
Training loss: 1.5824806690216064
Validation loss: 2.12564084927241

Epoch: 5| Step: 8
Training loss: 2.394993305206299
Validation loss: 2.1362537095944085

Epoch: 5| Step: 9
Training loss: 2.327409029006958
Validation loss: 2.1067718863487244

Epoch: 5| Step: 10
Training loss: 1.9465957880020142
Validation loss: 2.1109640846649804

Epoch: 5| Step: 11
Training loss: 1.5581367015838623
Validation loss: 2.1019033789634705

Epoch: 225| Step: 0
Training loss: 2.1377811431884766
Validation loss: 2.096703131993612

Epoch: 5| Step: 1
Training loss: 2.1961159706115723
Validation loss: 2.102054918805758

Epoch: 5| Step: 2
Training loss: 1.529697299003601
Validation loss: 2.1055097778638205

Epoch: 5| Step: 3
Training loss: 2.414916515350342
Validation loss: 2.1097435504198074

Epoch: 5| Step: 4
Training loss: 2.2221150398254395
Validation loss: 2.115330452720324

Epoch: 5| Step: 5
Training loss: 1.7001845836639404
Validation loss: 2.1257880479097366

Epoch: 5| Step: 6
Training loss: 1.7072172164916992
Validation loss: 2.1114168415466943

Epoch: 5| Step: 7
Training loss: 1.4734387397766113
Validation loss: 2.1085795958836875

Epoch: 5| Step: 8
Training loss: 2.282851457595825
Validation loss: 2.118884657820066

Epoch: 5| Step: 9
Training loss: 1.636663794517517
Validation loss: 2.1053715149561563

Epoch: 5| Step: 10
Training loss: 1.9958584308624268
Validation loss: 2.129418984055519

Epoch: 5| Step: 11
Training loss: 1.3333094120025635
Validation loss: 2.1165654261906943

Epoch: 226| Step: 0
Training loss: 1.843627691268921
Validation loss: 2.125434229771296

Epoch: 5| Step: 1
Training loss: 1.781984567642212
Validation loss: 2.124103849132856

Epoch: 5| Step: 2
Training loss: 1.9345375299453735
Validation loss: 2.120391324162483

Epoch: 5| Step: 3
Training loss: 2.0618062019348145
Validation loss: 2.1316628654797873

Epoch: 5| Step: 4
Training loss: 1.9868720769882202
Validation loss: 2.131477475166321

Epoch: 5| Step: 5
Training loss: 2.5176589488983154
Validation loss: 2.122948467731476

Epoch: 5| Step: 6
Training loss: 2.0445568561553955
Validation loss: 2.1075054556131363

Epoch: 5| Step: 7
Training loss: 1.1044881343841553
Validation loss: 2.1095460603634515

Epoch: 5| Step: 8
Training loss: 1.9822067022323608
Validation loss: 2.1108423868815103

Epoch: 5| Step: 9
Training loss: 1.8656326532363892
Validation loss: 2.127448504169782

Epoch: 5| Step: 10
Training loss: 1.900094985961914
Validation loss: 2.1085909754037857

Epoch: 5| Step: 11
Training loss: 2.49912428855896
Validation loss: 2.109374523162842

Epoch: 227| Step: 0
Training loss: 1.2539546489715576
Validation loss: 2.1084167857964835

Epoch: 5| Step: 1
Training loss: 2.322920322418213
Validation loss: 2.1154003739356995

Epoch: 5| Step: 2
Training loss: 2.243785858154297
Validation loss: 2.117074509461721

Epoch: 5| Step: 3
Training loss: 1.5990631580352783
Validation loss: 2.1012120445569358

Epoch: 5| Step: 4
Training loss: 1.2299652099609375
Validation loss: 2.11701991657416

Epoch: 5| Step: 5
Training loss: 2.2435717582702637
Validation loss: 2.1096517791350684

Epoch: 5| Step: 6
Training loss: 2.1100802421569824
Validation loss: 2.112847700715065

Epoch: 5| Step: 7
Training loss: 1.9354164600372314
Validation loss: 2.119483098387718

Epoch: 5| Step: 8
Training loss: 1.6806132793426514
Validation loss: 2.1137491116921105

Epoch: 5| Step: 9
Training loss: 2.466604709625244
Validation loss: 2.1228235016266503

Epoch: 5| Step: 10
Training loss: 2.056472063064575
Validation loss: 2.128641426563263

Epoch: 5| Step: 11
Training loss: 1.8253809213638306
Validation loss: 2.129493703444799

Epoch: 228| Step: 0
Training loss: 1.6384594440460205
Validation loss: 2.125075399875641

Epoch: 5| Step: 1
Training loss: 1.9990017414093018
Validation loss: 2.122900436321894

Epoch: 5| Step: 2
Training loss: 1.6433098316192627
Validation loss: 2.1249283949534097

Epoch: 5| Step: 3
Training loss: 2.166210651397705
Validation loss: 2.1162714759508767

Epoch: 5| Step: 4
Training loss: 1.9646097421646118
Validation loss: 2.128600776195526

Epoch: 5| Step: 5
Training loss: 2.016653537750244
Validation loss: 2.1316547294457755

Epoch: 5| Step: 6
Training loss: 1.216376543045044
Validation loss: 2.132285783688227

Epoch: 5| Step: 7
Training loss: 1.8510814905166626
Validation loss: 2.1269116501013436

Epoch: 5| Step: 8
Training loss: 2.05177640914917
Validation loss: 2.1201505959033966

Epoch: 5| Step: 9
Training loss: 2.054408073425293
Validation loss: 2.1065677404403687

Epoch: 5| Step: 10
Training loss: 2.572856903076172
Validation loss: 2.122510621945063

Epoch: 5| Step: 11
Training loss: 1.5141838788986206
Validation loss: 2.117297440767288

Epoch: 229| Step: 0
Training loss: 2.4304702281951904
Validation loss: 2.1246193250020347

Epoch: 5| Step: 1
Training loss: 2.009335994720459
Validation loss: 2.1375387658675513

Epoch: 5| Step: 2
Training loss: 1.6501184701919556
Validation loss: 2.1285289525985718

Epoch: 5| Step: 3
Training loss: 1.6529576778411865
Validation loss: 2.1602941503127417

Epoch: 5| Step: 4
Training loss: 2.1460165977478027
Validation loss: 2.149980107943217

Epoch: 5| Step: 5
Training loss: 1.8232183456420898
Validation loss: 2.1591752568880715

Epoch: 5| Step: 6
Training loss: 1.8345743417739868
Validation loss: 2.150809660553932

Epoch: 5| Step: 7
Training loss: 1.7135446071624756
Validation loss: 2.1185073206822076

Epoch: 5| Step: 8
Training loss: 2.50115704536438
Validation loss: 2.1186393996079764

Epoch: 5| Step: 9
Training loss: 2.090075969696045
Validation loss: 2.1272175113360086

Epoch: 5| Step: 10
Training loss: 1.6436002254486084
Validation loss: 2.0923435240983963

Epoch: 5| Step: 11
Training loss: 1.027394413948059
Validation loss: 2.096043805281321

Epoch: 230| Step: 0
Training loss: 2.363706350326538
Validation loss: 2.099077209830284

Epoch: 5| Step: 1
Training loss: 2.2074732780456543
Validation loss: 2.1136374274889627

Epoch: 5| Step: 2
Training loss: 2.1206583976745605
Validation loss: 2.1202340523401895

Epoch: 5| Step: 3
Training loss: 2.024221897125244
Validation loss: 2.1243736346562705

Epoch: 5| Step: 4
Training loss: 2.1433682441711426
Validation loss: 2.1243299692869186

Epoch: 5| Step: 5
Training loss: 2.4694461822509766
Validation loss: 2.122374082605044

Epoch: 5| Step: 6
Training loss: 1.739410400390625
Validation loss: 2.113014648358027

Epoch: 5| Step: 7
Training loss: 2.61590838432312
Validation loss: 2.1253071278333664

Epoch: 5| Step: 8
Training loss: 1.4015275239944458
Validation loss: 2.1165177722771964

Epoch: 5| Step: 9
Training loss: 1.9111783504486084
Validation loss: 2.1153213878472648

Epoch: 5| Step: 10
Training loss: 1.8863226175308228
Validation loss: 2.109784280260404

Epoch: 5| Step: 11
Training loss: 1.3977936506271362
Validation loss: 2.099692612886429

Epoch: 231| Step: 0
Training loss: 1.9672693014144897
Validation loss: 2.1008638540903726

Epoch: 5| Step: 1
Training loss: 1.922032356262207
Validation loss: 2.100656325618426

Epoch: 5| Step: 2
Training loss: 1.6807502508163452
Validation loss: 2.093871086835861

Epoch: 5| Step: 3
Training loss: 1.8383569717407227
Validation loss: 2.1112952679395676

Epoch: 5| Step: 4
Training loss: 2.199570894241333
Validation loss: 2.110215147336324

Epoch: 5| Step: 5
Training loss: 2.186246633529663
Validation loss: 2.1334018210570016

Epoch: 5| Step: 6
Training loss: 2.0827808380126953
Validation loss: 2.1268386195103326

Epoch: 5| Step: 7
Training loss: 1.3907806873321533
Validation loss: 2.1491653472185135

Epoch: 5| Step: 8
Training loss: 1.6557722091674805
Validation loss: 2.154662107427915

Epoch: 5| Step: 9
Training loss: 2.0294346809387207
Validation loss: 2.1570377002159753

Epoch: 5| Step: 10
Training loss: 2.1276097297668457
Validation loss: 2.1392209281524024

Epoch: 5| Step: 11
Training loss: 1.819037914276123
Validation loss: 2.1433192243178687

Epoch: 232| Step: 0
Training loss: 1.9254947900772095
Validation loss: 2.14539901415507

Epoch: 5| Step: 1
Training loss: 1.6571528911590576
Validation loss: 2.1421417742967606

Epoch: 5| Step: 2
Training loss: 1.8075727224349976
Validation loss: 2.1246060828367868

Epoch: 5| Step: 3
Training loss: 2.4770023822784424
Validation loss: 2.14082578321298

Epoch: 5| Step: 4
Training loss: 1.607485055923462
Validation loss: 2.118584007024765

Epoch: 5| Step: 5
Training loss: 2.1105690002441406
Validation loss: 2.1055076022942862

Epoch: 5| Step: 6
Training loss: 2.1183090209960938
Validation loss: 2.1386831949154534

Epoch: 5| Step: 7
Training loss: 1.9316895008087158
Validation loss: 2.1352612674236298

Epoch: 5| Step: 8
Training loss: 1.6034162044525146
Validation loss: 2.1371226012706757

Epoch: 5| Step: 9
Training loss: 2.224963903427124
Validation loss: 2.1356644531091056

Epoch: 5| Step: 10
Training loss: 1.487831473350525
Validation loss: 2.1304559409618378

Epoch: 5| Step: 11
Training loss: 1.7048404216766357
Validation loss: 2.123068908850352

Epoch: 233| Step: 0
Training loss: 1.597672939300537
Validation loss: 2.111898352702459

Epoch: 5| Step: 1
Training loss: 1.9724769592285156
Validation loss: 2.1214602887630463

Epoch: 5| Step: 2
Training loss: 2.1155545711517334
Validation loss: 2.119422579805056

Epoch: 5| Step: 3
Training loss: 1.5717452764511108
Validation loss: 2.1224028120438256

Epoch: 5| Step: 4
Training loss: 2.0996203422546387
Validation loss: 2.1193662782510123

Epoch: 5| Step: 5
Training loss: 1.8169374465942383
Validation loss: 2.1303327480951944

Epoch: 5| Step: 6
Training loss: 2.0090484619140625
Validation loss: 2.1269875367482505

Epoch: 5| Step: 7
Training loss: 2.2259857654571533
Validation loss: 2.12221289674441

Epoch: 5| Step: 8
Training loss: 1.9057648181915283
Validation loss: 2.1223321855068207

Epoch: 5| Step: 9
Training loss: 1.5051898956298828
Validation loss: 2.118193820118904

Epoch: 5| Step: 10
Training loss: 2.0224595069885254
Validation loss: 2.1379843999942145

Epoch: 5| Step: 11
Training loss: 2.3687376976013184
Validation loss: 2.1528749664624534

Epoch: 234| Step: 0
Training loss: 1.8449885845184326
Validation loss: 2.125832443435987

Epoch: 5| Step: 1
Training loss: 1.5150048732757568
Validation loss: 2.136147459348043

Epoch: 5| Step: 2
Training loss: 2.704740285873413
Validation loss: 2.140523999929428

Epoch: 5| Step: 3
Training loss: 1.8806469440460205
Validation loss: 2.1186869740486145

Epoch: 5| Step: 4
Training loss: 2.10750412940979
Validation loss: 2.11951852341493

Epoch: 5| Step: 5
Training loss: 2.441033363342285
Validation loss: 2.1329376796881356

Epoch: 5| Step: 6
Training loss: 1.7655894756317139
Validation loss: 2.128111263116201

Epoch: 5| Step: 7
Training loss: 1.5924071073532104
Validation loss: 2.137969841559728

Epoch: 5| Step: 8
Training loss: 1.8636516332626343
Validation loss: 2.134608839948972

Epoch: 5| Step: 9
Training loss: 1.4319976568222046
Validation loss: 2.129765351613363

Epoch: 5| Step: 10
Training loss: 1.8155368566513062
Validation loss: 2.1436108549435935

Epoch: 5| Step: 11
Training loss: 1.9460077285766602
Validation loss: 2.1773992627859116

Epoch: 235| Step: 0
Training loss: 1.6001269817352295
Validation loss: 2.1523345510164895

Epoch: 5| Step: 1
Training loss: 2.1258609294891357
Validation loss: 2.1646267473697662

Epoch: 5| Step: 2
Training loss: 2.2474677562713623
Validation loss: 2.1604886054992676

Epoch: 5| Step: 3
Training loss: 1.550486445426941
Validation loss: 2.165497342745463

Epoch: 5| Step: 4
Training loss: 1.413204550743103
Validation loss: 2.1634389460086823

Epoch: 5| Step: 5
Training loss: 1.5280252695083618
Validation loss: 2.164287805557251

Epoch: 5| Step: 6
Training loss: 1.7583057880401611
Validation loss: 2.1307958712180457

Epoch: 5| Step: 7
Training loss: 2.094433069229126
Validation loss: 2.144295116265615

Epoch: 5| Step: 8
Training loss: 2.4151148796081543
Validation loss: 2.130806118249893

Epoch: 5| Step: 9
Training loss: 2.2354466915130615
Validation loss: 2.1392227609952292

Epoch: 5| Step: 10
Training loss: 2.174586057662964
Validation loss: 2.152147779862086

Epoch: 5| Step: 11
Training loss: 1.8138957023620605
Validation loss: 2.1464533110459647

Epoch: 236| Step: 0
Training loss: 2.111598253250122
Validation loss: 2.1289517482121787

Epoch: 5| Step: 1
Training loss: 1.4683306217193604
Validation loss: 2.152153601249059

Epoch: 5| Step: 2
Training loss: 1.5518109798431396
Validation loss: 2.1658637126286826

Epoch: 5| Step: 3
Training loss: 2.199387788772583
Validation loss: 2.152492269873619

Epoch: 5| Step: 4
Training loss: 1.6047918796539307
Validation loss: 2.1674733261267343

Epoch: 5| Step: 5
Training loss: 2.6423444747924805
Validation loss: 2.1592602034409842

Epoch: 5| Step: 6
Training loss: 1.4791008234024048
Validation loss: 2.147641266385714

Epoch: 5| Step: 7
Training loss: 2.4980461597442627
Validation loss: 2.131117433309555

Epoch: 5| Step: 8
Training loss: 1.887397050857544
Validation loss: 2.1197242736816406

Epoch: 5| Step: 9
Training loss: 2.0850725173950195
Validation loss: 2.132683957616488

Epoch: 5| Step: 10
Training loss: 1.6577212810516357
Validation loss: 2.1327318946520486

Epoch: 5| Step: 11
Training loss: 1.7214562892913818
Validation loss: 2.140084649125735

Epoch: 237| Step: 0
Training loss: 1.946899175643921
Validation loss: 2.1339591095844903

Epoch: 5| Step: 1
Training loss: 1.9242620468139648
Validation loss: 2.157520850499471

Epoch: 5| Step: 2
Training loss: 2.065431833267212
Validation loss: 2.1405101468165717

Epoch: 5| Step: 3
Training loss: 2.3037590980529785
Validation loss: 2.1500475654999414

Epoch: 5| Step: 4
Training loss: 1.4491329193115234
Validation loss: 2.1435403178135553

Epoch: 5| Step: 5
Training loss: 1.3177913427352905
Validation loss: 2.119721536835035

Epoch: 5| Step: 6
Training loss: 2.120896100997925
Validation loss: 2.1182570358117423

Epoch: 5| Step: 7
Training loss: 1.66249680519104
Validation loss: 2.1394445995489755

Epoch: 5| Step: 8
Training loss: 2.693140745162964
Validation loss: 2.1180571566025415

Epoch: 5| Step: 9
Training loss: 1.7235586643218994
Validation loss: 2.109391987323761

Epoch: 5| Step: 10
Training loss: 2.0509207248687744
Validation loss: 2.1036987950404487

Epoch: 5| Step: 11
Training loss: 1.0816067457199097
Validation loss: 2.105579217274984

Epoch: 238| Step: 0
Training loss: 2.0106422901153564
Validation loss: 2.102679987748464

Epoch: 5| Step: 1
Training loss: 1.4575735330581665
Validation loss: 2.1038936326901116

Epoch: 5| Step: 2
Training loss: 3.1197242736816406
Validation loss: 2.1039306024710336

Epoch: 5| Step: 3
Training loss: 1.3488613367080688
Validation loss: 2.1023179441690445

Epoch: 5| Step: 4
Training loss: 2.0154380798339844
Validation loss: 2.1103914777437844

Epoch: 5| Step: 5
Training loss: 1.8288414478302002
Validation loss: 2.1122191747029624

Epoch: 5| Step: 6
Training loss: 2.588115692138672
Validation loss: 2.121478026111921

Epoch: 5| Step: 7
Training loss: 1.6217619180679321
Validation loss: 2.13043050467968

Epoch: 5| Step: 8
Training loss: 2.2492260932922363
Validation loss: 2.130720148483912

Epoch: 5| Step: 9
Training loss: 1.519406795501709
Validation loss: 2.131674125790596

Epoch: 5| Step: 10
Training loss: 1.4106359481811523
Validation loss: 2.14097069700559

Epoch: 5| Step: 11
Training loss: 1.4973440170288086
Validation loss: 2.1332303235928216

Epoch: 239| Step: 0
Training loss: 2.00856351852417
Validation loss: 2.1707844734191895

Epoch: 5| Step: 1
Training loss: 2.268303155899048
Validation loss: 2.182369281848272

Epoch: 5| Step: 2
Training loss: 1.674750566482544
Validation loss: 2.172096014022827

Epoch: 5| Step: 3
Training loss: 1.7916942834854126
Validation loss: 2.1520383656024933

Epoch: 5| Step: 4
Training loss: 2.337829113006592
Validation loss: 2.1551949133475623

Epoch: 5| Step: 5
Training loss: 2.0601868629455566
Validation loss: 2.1459870040416718

Epoch: 5| Step: 6
Training loss: 1.9753307104110718
Validation loss: 2.142892370621363

Epoch: 5| Step: 7
Training loss: 1.413360595703125
Validation loss: 2.1199154059092202

Epoch: 5| Step: 8
Training loss: 1.7544898986816406
Validation loss: 2.124854822953542

Epoch: 5| Step: 9
Training loss: 1.997642159461975
Validation loss: 2.1098935852448144

Epoch: 5| Step: 10
Training loss: 1.6467349529266357
Validation loss: 2.112900892893473

Epoch: 5| Step: 11
Training loss: 2.4163756370544434
Validation loss: 2.100827306509018

Epoch: 240| Step: 0
Training loss: 1.8689988851547241
Validation loss: 2.1069787641366324

Epoch: 5| Step: 1
Training loss: 2.0038938522338867
Validation loss: 2.0989015698432922

Epoch: 5| Step: 2
Training loss: 1.8023960590362549
Validation loss: 2.107767770687739

Epoch: 5| Step: 3
Training loss: 1.9664322137832642
Validation loss: 2.1014298101266227

Epoch: 5| Step: 4
Training loss: 1.9668989181518555
Validation loss: 2.106444721420606

Epoch: 5| Step: 5
Training loss: 2.3149912357330322
Validation loss: 2.1199894646803537

Epoch: 5| Step: 6
Training loss: 2.118534564971924
Validation loss: 2.107973744471868

Epoch: 5| Step: 7
Training loss: 1.5810920000076294
Validation loss: 2.138083333770434

Epoch: 5| Step: 8
Training loss: 1.8360612392425537
Validation loss: 2.1355830281972885

Epoch: 5| Step: 9
Training loss: 1.7778819799423218
Validation loss: 2.151990900437037

Epoch: 5| Step: 10
Training loss: 2.52205753326416
Validation loss: 2.159089128176371

Epoch: 5| Step: 11
Training loss: 1.8367846012115479
Validation loss: 2.137731194496155

Epoch: 241| Step: 0
Training loss: 1.8069196939468384
Validation loss: 2.1270675162474313

Epoch: 5| Step: 1
Training loss: 2.2049922943115234
Validation loss: 2.137879103422165

Epoch: 5| Step: 2
Training loss: 1.8843002319335938
Validation loss: 2.115269293387731

Epoch: 5| Step: 3
Training loss: 1.685534119606018
Validation loss: 2.1241313020388284

Epoch: 5| Step: 4
Training loss: 1.7977203130722046
Validation loss: 2.13076014816761

Epoch: 5| Step: 5
Training loss: 1.850078821182251
Validation loss: 2.128681868314743

Epoch: 5| Step: 6
Training loss: 1.5098416805267334
Validation loss: 2.115631257494291

Epoch: 5| Step: 7
Training loss: 2.1585965156555176
Validation loss: 2.1127767264842987

Epoch: 5| Step: 8
Training loss: 2.2251675128936768
Validation loss: 2.139789586265882

Epoch: 5| Step: 9
Training loss: 2.078619956970215
Validation loss: 2.130163545409838

Epoch: 5| Step: 10
Training loss: 1.835475206375122
Validation loss: 2.129738504687945

Epoch: 5| Step: 11
Training loss: 1.7476651668548584
Validation loss: 2.1433021277189255

Epoch: 242| Step: 0
Training loss: 1.508367896080017
Validation loss: 2.130954066912333

Epoch: 5| Step: 1
Training loss: 2.5157694816589355
Validation loss: 2.13156421482563

Epoch: 5| Step: 2
Training loss: 2.1553759574890137
Validation loss: 2.1421492596467337

Epoch: 5| Step: 3
Training loss: 1.7566372156143188
Validation loss: 2.139893094698588

Epoch: 5| Step: 4
Training loss: 2.2405612468719482
Validation loss: 2.1695439418156943

Epoch: 5| Step: 5
Training loss: 2.3429107666015625
Validation loss: 2.194038599729538

Epoch: 5| Step: 6
Training loss: 1.9952980279922485
Validation loss: 2.2010099242130914

Epoch: 5| Step: 7
Training loss: 1.446229338645935
Validation loss: 2.1945895701646805

Epoch: 5| Step: 8
Training loss: 1.971574068069458
Validation loss: 2.1911300172408423

Epoch: 5| Step: 9
Training loss: 1.3965232372283936
Validation loss: 2.174202178915342

Epoch: 5| Step: 10
Training loss: 2.0135891437530518
Validation loss: 2.1603810787200928

Epoch: 5| Step: 11
Training loss: 1.0631762742996216
Validation loss: 2.1503373632828393

Epoch: 243| Step: 0
Training loss: 1.7321243286132812
Validation loss: 2.118788997332255

Epoch: 5| Step: 1
Training loss: 1.84450364112854
Validation loss: 2.108014037211736

Epoch: 5| Step: 2
Training loss: 2.0412001609802246
Validation loss: 2.104530319571495

Epoch: 5| Step: 3
Training loss: 2.3302981853485107
Validation loss: 2.129695783058802

Epoch: 5| Step: 4
Training loss: 2.146693706512451
Validation loss: 2.1249373853206635

Epoch: 5| Step: 5
Training loss: 2.567404270172119
Validation loss: 2.1307614346345267

Epoch: 5| Step: 6
Training loss: 1.8614269495010376
Validation loss: 2.14012019832929

Epoch: 5| Step: 7
Training loss: 2.2133901119232178
Validation loss: 2.1454810400803885

Epoch: 5| Step: 8
Training loss: 1.7827352285385132
Validation loss: 2.1416444728771844

Epoch: 5| Step: 9
Training loss: 2.033947467803955
Validation loss: 2.136700357000033

Epoch: 5| Step: 10
Training loss: 2.366946220397949
Validation loss: 2.127612292766571

Epoch: 5| Step: 11
Training loss: 2.741690158843994
Validation loss: 2.1204307128985724

Epoch: 244| Step: 0
Training loss: 2.452716588973999
Validation loss: 2.1131539841492972

Epoch: 5| Step: 1
Training loss: 1.915144920349121
Validation loss: 2.1075436969598136

Epoch: 5| Step: 2
Training loss: 1.7912547588348389
Validation loss: 2.1196864744027457

Epoch: 5| Step: 3
Training loss: 2.0423593521118164
Validation loss: 2.1283001403013864

Epoch: 5| Step: 4
Training loss: 1.9903843402862549
Validation loss: 2.138389448324839

Epoch: 5| Step: 5
Training loss: 1.5067529678344727
Validation loss: 2.163072700301806

Epoch: 5| Step: 6
Training loss: 1.6455882787704468
Validation loss: 2.1615364849567413

Epoch: 5| Step: 7
Training loss: 2.4483957290649414
Validation loss: 2.197808106740316

Epoch: 5| Step: 8
Training loss: 2.7739686965942383
Validation loss: 2.220350722471873

Epoch: 5| Step: 9
Training loss: 1.7411479949951172
Validation loss: 2.1999645431836448

Epoch: 5| Step: 10
Training loss: 2.0649495124816895
Validation loss: 2.2000592052936554

Epoch: 5| Step: 11
Training loss: 1.067149043083191
Validation loss: 2.156756361325582

Epoch: 245| Step: 0
Training loss: 2.184333324432373
Validation loss: 2.1447160641352334

Epoch: 5| Step: 1
Training loss: 2.188149929046631
Validation loss: 2.127525488535563

Epoch: 5| Step: 2
Training loss: 1.3846049308776855
Validation loss: 2.1171934803326926

Epoch: 5| Step: 3
Training loss: 2.099835157394409
Validation loss: 2.124054729938507

Epoch: 5| Step: 4
Training loss: 1.857715368270874
Validation loss: 2.125844399134318

Epoch: 5| Step: 5
Training loss: 1.677626371383667
Validation loss: 2.108914097150167

Epoch: 5| Step: 6
Training loss: 2.1796040534973145
Validation loss: 2.1095277070999146

Epoch: 5| Step: 7
Training loss: 2.0309267044067383
Validation loss: 2.1115285555521646

Epoch: 5| Step: 8
Training loss: 1.7686913013458252
Validation loss: 2.110006724794706

Epoch: 5| Step: 9
Training loss: 2.0076825618743896
Validation loss: 2.1110299974679947

Epoch: 5| Step: 10
Training loss: 2.0562493801116943
Validation loss: 2.1220750411351523

Epoch: 5| Step: 11
Training loss: 2.5197882652282715
Validation loss: 2.1229130725065866

Epoch: 246| Step: 0
Training loss: 1.9524074792861938
Validation loss: 2.1140000422795615

Epoch: 5| Step: 1
Training loss: 2.4336295127868652
Validation loss: 2.1248639722665152

Epoch: 5| Step: 2
Training loss: 2.2428956031799316
Validation loss: 2.1394877433776855

Epoch: 5| Step: 3
Training loss: 1.721226453781128
Validation loss: 2.1285333981116614

Epoch: 5| Step: 4
Training loss: 2.319016933441162
Validation loss: 2.133682588736216

Epoch: 5| Step: 5
Training loss: 1.786868691444397
Validation loss: 2.137826551993688

Epoch: 5| Step: 6
Training loss: 1.4018956422805786
Validation loss: 2.1433403690656028

Epoch: 5| Step: 7
Training loss: 2.1447432041168213
Validation loss: 2.1553092996279397

Epoch: 5| Step: 8
Training loss: 1.6059001684188843
Validation loss: 2.1347804913918176

Epoch: 5| Step: 9
Training loss: 2.14705228805542
Validation loss: 2.166879882415136

Epoch: 5| Step: 10
Training loss: 1.383660078048706
Validation loss: 2.1562262872854867

Epoch: 5| Step: 11
Training loss: 1.3762290477752686
Validation loss: 2.1813960522413254

Epoch: 247| Step: 0
Training loss: 2.1812186241149902
Validation loss: 2.1543289025624595

Epoch: 5| Step: 1
Training loss: 1.5506802797317505
Validation loss: 2.1382521937290826

Epoch: 5| Step: 2
Training loss: 1.6410472393035889
Validation loss: 2.1324387192726135

Epoch: 5| Step: 3
Training loss: 2.044708728790283
Validation loss: 2.130750685930252

Epoch: 5| Step: 4
Training loss: 2.1124846935272217
Validation loss: 2.1194974929094315

Epoch: 5| Step: 5
Training loss: 1.8467674255371094
Validation loss: 2.114003782471021

Epoch: 5| Step: 6
Training loss: 2.2277774810791016
Validation loss: 2.1137801905473075

Epoch: 5| Step: 7
Training loss: 1.6112871170043945
Validation loss: 2.139720598856608

Epoch: 5| Step: 8
Training loss: 1.6158618927001953
Validation loss: 2.117969418565432

Epoch: 5| Step: 9
Training loss: 2.200836420059204
Validation loss: 2.13794972995917

Epoch: 5| Step: 10
Training loss: 1.9198423624038696
Validation loss: 2.1253272891044617

Epoch: 5| Step: 11
Training loss: 1.3180575370788574
Validation loss: 2.1424871534109116

Epoch: 248| Step: 0
Training loss: 2.212627410888672
Validation loss: 2.144968256354332

Epoch: 5| Step: 1
Training loss: 1.550372838973999
Validation loss: 2.1402972439924874

Epoch: 5| Step: 2
Training loss: 1.266416311264038
Validation loss: 2.1580142428477607

Epoch: 5| Step: 3
Training loss: 2.1391549110412598
Validation loss: 2.1665611267089844

Epoch: 5| Step: 4
Training loss: 1.9746246337890625
Validation loss: 2.1655184030532837

Epoch: 5| Step: 5
Training loss: 2.2646400928497314
Validation loss: 2.1478042900562286

Epoch: 5| Step: 6
Training loss: 2.111335277557373
Validation loss: 2.151087765892347

Epoch: 5| Step: 7
Training loss: 1.5747883319854736
Validation loss: 2.150100419918696

Epoch: 5| Step: 8
Training loss: 1.9899780750274658
Validation loss: 2.1506934513648353

Epoch: 5| Step: 9
Training loss: 1.4424818754196167
Validation loss: 2.162740170955658

Epoch: 5| Step: 10
Training loss: 2.150608539581299
Validation loss: 2.1498572130997977

Epoch: 5| Step: 11
Training loss: 2.3787522315979004
Validation loss: 2.1400247116883597

Epoch: 249| Step: 0
Training loss: 1.7140041589736938
Validation loss: 2.1436898907025657

Epoch: 5| Step: 1
Training loss: 1.8211055994033813
Validation loss: 2.1396867285172143

Epoch: 5| Step: 2
Training loss: 2.2248129844665527
Validation loss: 2.1295334647099176

Epoch: 5| Step: 3
Training loss: 1.6555538177490234
Validation loss: 2.1264655888080597

Epoch: 5| Step: 4
Training loss: 2.1868643760681152
Validation loss: 2.1315216720104218

Epoch: 5| Step: 5
Training loss: 2.237180709838867
Validation loss: 2.1364835103352866

Epoch: 5| Step: 6
Training loss: 1.9630672931671143
Validation loss: 2.1400333841641745

Epoch: 5| Step: 7
Training loss: 2.085517406463623
Validation loss: 2.135871301094691

Epoch: 5| Step: 8
Training loss: 1.8026689291000366
Validation loss: 2.1484054177999496

Epoch: 5| Step: 9
Training loss: 2.019611120223999
Validation loss: 2.1450161983569465

Epoch: 5| Step: 10
Training loss: 1.627436876296997
Validation loss: 2.1581717332204184

Epoch: 5| Step: 11
Training loss: 1.002313256263733
Validation loss: 2.15536630153656

Epoch: 250| Step: 0
Training loss: 1.4570813179016113
Validation loss: 2.1400876144568124

Epoch: 5| Step: 1
Training loss: 1.7971961498260498
Validation loss: 2.1523343125979104

Epoch: 5| Step: 2
Training loss: 1.8905856609344482
Validation loss: 2.1463675995667777

Epoch: 5| Step: 3
Training loss: 2.3259620666503906
Validation loss: 2.1724667151769004

Epoch: 5| Step: 4
Training loss: 1.743910551071167
Validation loss: 2.161895215511322

Epoch: 5| Step: 5
Training loss: 2.5234742164611816
Validation loss: 2.1609511176745095

Epoch: 5| Step: 6
Training loss: 1.612367033958435
Validation loss: 2.133951927224795

Epoch: 5| Step: 7
Training loss: 2.568026065826416
Validation loss: 2.1397550155719123

Epoch: 5| Step: 8
Training loss: 1.5486253499984741
Validation loss: 2.1294512301683426

Epoch: 5| Step: 9
Training loss: 2.415003776550293
Validation loss: 2.1265943000713983

Epoch: 5| Step: 10
Training loss: 1.8051252365112305
Validation loss: 2.114251201351484

Epoch: 5| Step: 11
Training loss: 1.7209954261779785
Validation loss: 2.107508341471354

Epoch: 251| Step: 0
Training loss: 1.7438617944717407
Validation loss: 2.124791373809179

Epoch: 5| Step: 1
Training loss: 1.7072608470916748
Validation loss: 2.112125441431999

Epoch: 5| Step: 2
Training loss: 1.3906240463256836
Validation loss: 2.128705307841301

Epoch: 5| Step: 3
Training loss: 2.43837308883667
Validation loss: 2.1208345790704093

Epoch: 5| Step: 4
Training loss: 1.4257889986038208
Validation loss: 2.1254025300343833

Epoch: 5| Step: 5
Training loss: 1.5559271574020386
Validation loss: 2.1197605480750403

Epoch: 5| Step: 6
Training loss: 2.3302807807922363
Validation loss: 2.125125636657079

Epoch: 5| Step: 7
Training loss: 2.078423023223877
Validation loss: 2.1244611591100693

Epoch: 5| Step: 8
Training loss: 2.325547695159912
Validation loss: 2.1340916206439338

Epoch: 5| Step: 9
Training loss: 1.7000935077667236
Validation loss: 2.1188825219869614

Epoch: 5| Step: 10
Training loss: 1.9673389196395874
Validation loss: 2.1351099063952765

Epoch: 5| Step: 11
Training loss: 2.437723159790039
Validation loss: 2.1280893435080848

Epoch: 252| Step: 0
Training loss: 2.2461624145507812
Validation loss: 2.1181113620599112

Epoch: 5| Step: 1
Training loss: 2.2337450981140137
Validation loss: 2.124979337056478

Epoch: 5| Step: 2
Training loss: 1.6640331745147705
Validation loss: 2.1303860545158386

Epoch: 5| Step: 3
Training loss: 1.852307915687561
Validation loss: 2.1284140199422836

Epoch: 5| Step: 4
Training loss: 1.7021148204803467
Validation loss: 2.1256131331125894

Epoch: 5| Step: 5
Training loss: 2.0929558277130127
Validation loss: 2.1205472896496453

Epoch: 5| Step: 6
Training loss: 1.997476577758789
Validation loss: 2.1262885679801307

Epoch: 5| Step: 7
Training loss: 1.7034156322479248
Validation loss: 2.105682134628296

Epoch: 5| Step: 8
Training loss: 1.907062292098999
Validation loss: 2.1313654283682504

Epoch: 5| Step: 9
Training loss: 1.5585927963256836
Validation loss: 2.113411063949267

Epoch: 5| Step: 10
Training loss: 1.8295024633407593
Validation loss: 2.1154984335104623

Epoch: 5| Step: 11
Training loss: 1.929225206375122
Validation loss: 2.1135343760252

Epoch: 253| Step: 0
Training loss: 1.5907970666885376
Validation loss: 2.1145463387171426

Epoch: 5| Step: 1
Training loss: 2.550769329071045
Validation loss: 2.1329990327358246

Epoch: 5| Step: 2
Training loss: 1.6818650960922241
Validation loss: 2.138557275136312

Epoch: 5| Step: 3
Training loss: 2.3469462394714355
Validation loss: 2.16499196489652

Epoch: 5| Step: 4
Training loss: 1.8677072525024414
Validation loss: 2.1486723522345224

Epoch: 5| Step: 5
Training loss: 2.472996950149536
Validation loss: 2.142023409406344

Epoch: 5| Step: 6
Training loss: 1.6818640232086182
Validation loss: 2.1422156343857446

Epoch: 5| Step: 7
Training loss: 1.3137863874435425
Validation loss: 2.1500403682390847

Epoch: 5| Step: 8
Training loss: 1.794478178024292
Validation loss: 2.1331540644168854

Epoch: 5| Step: 9
Training loss: 1.9237797260284424
Validation loss: 2.1386121809482574

Epoch: 5| Step: 10
Training loss: 1.7586437463760376
Validation loss: 2.1352904538313546

Epoch: 5| Step: 11
Training loss: 1.1856716871261597
Validation loss: 2.1364042113224664

Epoch: 254| Step: 0
Training loss: 1.9201910495758057
Validation loss: 2.1354677180449166

Epoch: 5| Step: 1
Training loss: 1.6300783157348633
Validation loss: 2.131818562746048

Epoch: 5| Step: 2
Training loss: 0.9841599464416504
Validation loss: 2.1460733811060586

Epoch: 5| Step: 3
Training loss: 2.4151082038879395
Validation loss: 2.1469782888889313

Epoch: 5| Step: 4
Training loss: 2.1993696689605713
Validation loss: 2.1447797218958535

Epoch: 5| Step: 5
Training loss: 2.0207409858703613
Validation loss: 2.150889277458191

Epoch: 5| Step: 6
Training loss: 1.9166978597640991
Validation loss: 2.138784642020861

Epoch: 5| Step: 7
Training loss: 1.491912603378296
Validation loss: 2.146881033976873

Epoch: 5| Step: 8
Training loss: 2.729480743408203
Validation loss: 2.141923745473226

Epoch: 5| Step: 9
Training loss: 2.13331937789917
Validation loss: 2.158992583552996

Epoch: 5| Step: 10
Training loss: 1.3693405389785767
Validation loss: 2.1458971401055655

Epoch: 5| Step: 11
Training loss: 1.5207176208496094
Validation loss: 2.142857238650322

Epoch: 255| Step: 0
Training loss: 2.039764642715454
Validation loss: 2.1415909230709076

Epoch: 5| Step: 1
Training loss: 1.9493885040283203
Validation loss: 2.13846987982591

Epoch: 5| Step: 2
Training loss: 1.6284958124160767
Validation loss: 2.1297907680273056

Epoch: 5| Step: 3
Training loss: 2.2284581661224365
Validation loss: 2.139017179608345

Epoch: 5| Step: 4
Training loss: 1.8942381143569946
Validation loss: 2.1362906247377396

Epoch: 5| Step: 5
Training loss: 1.9555060863494873
Validation loss: 2.1236585776011148

Epoch: 5| Step: 6
Training loss: 2.0817477703094482
Validation loss: 2.122266178329786

Epoch: 5| Step: 7
Training loss: 2.167938709259033
Validation loss: 2.1364107628663382

Epoch: 5| Step: 8
Training loss: 1.4964942932128906
Validation loss: 2.132374087969462

Epoch: 5| Step: 9
Training loss: 1.7762060165405273
Validation loss: 2.1287491470575333

Epoch: 5| Step: 10
Training loss: 1.6334857940673828
Validation loss: 2.1481413543224335

Epoch: 5| Step: 11
Training loss: 1.1365798711776733
Validation loss: 2.1536094695329666

Epoch: 256| Step: 0
Training loss: 1.6084239482879639
Validation loss: 2.1596664985020957

Epoch: 5| Step: 1
Training loss: 1.9757360219955444
Validation loss: 2.1861201524734497

Epoch: 5| Step: 2
Training loss: 1.694981575012207
Validation loss: 2.182029594977697

Epoch: 5| Step: 3
Training loss: 2.315746545791626
Validation loss: 2.188814332087835

Epoch: 5| Step: 4
Training loss: 2.1027777194976807
Validation loss: 2.15288915236791

Epoch: 5| Step: 5
Training loss: 1.406358003616333
Validation loss: 2.191570222377777

Epoch: 5| Step: 6
Training loss: 1.978062629699707
Validation loss: 2.166716252764066

Epoch: 5| Step: 7
Training loss: 2.0289955139160156
Validation loss: 2.150427500406901

Epoch: 5| Step: 8
Training loss: 1.7674640417099
Validation loss: 2.139527608950933

Epoch: 5| Step: 9
Training loss: 1.8114207983016968
Validation loss: 2.131303697824478

Epoch: 5| Step: 10
Training loss: 2.354754686355591
Validation loss: 2.1173529426256814

Epoch: 5| Step: 11
Training loss: 3.368107795715332
Validation loss: 2.132017359137535

Epoch: 257| Step: 0
Training loss: 2.12807297706604
Validation loss: 2.112861305475235

Epoch: 5| Step: 1
Training loss: 2.0073206424713135
Validation loss: 2.1255952467521033

Epoch: 5| Step: 2
Training loss: 2.035891532897949
Validation loss: 2.1248347560564675

Epoch: 5| Step: 3
Training loss: 1.689989447593689
Validation loss: 2.1309959441423416

Epoch: 5| Step: 4
Training loss: 1.6784188747406006
Validation loss: 2.1342512518167496

Epoch: 5| Step: 5
Training loss: 1.680821418762207
Validation loss: 2.1496338546276093

Epoch: 5| Step: 6
Training loss: 1.3573319911956787
Validation loss: 2.1432618300120034

Epoch: 5| Step: 7
Training loss: 2.2094497680664062
Validation loss: 2.1478337148825326

Epoch: 5| Step: 8
Training loss: 2.2715067863464355
Validation loss: 2.1400145987669625

Epoch: 5| Step: 9
Training loss: 1.7270565032958984
Validation loss: 2.139523282647133

Epoch: 5| Step: 10
Training loss: 2.086427927017212
Validation loss: 2.149750525752703

Epoch: 5| Step: 11
Training loss: 0.7836411595344543
Validation loss: 2.1572075436512628

Epoch: 258| Step: 0
Training loss: 1.4147508144378662
Validation loss: 2.16644524037838

Epoch: 5| Step: 1
Training loss: 2.0127453804016113
Validation loss: 2.166606694459915

Epoch: 5| Step: 2
Training loss: 1.4993007183074951
Validation loss: 2.163731560111046

Epoch: 5| Step: 3
Training loss: 1.757249116897583
Validation loss: 2.147825996081034

Epoch: 5| Step: 4
Training loss: 1.7300478219985962
Validation loss: 2.1582076847553253

Epoch: 5| Step: 5
Training loss: 1.880805253982544
Validation loss: 2.131063496073087

Epoch: 5| Step: 6
Training loss: 2.279153823852539
Validation loss: 2.157903512318929

Epoch: 5| Step: 7
Training loss: 1.8561283349990845
Validation loss: 2.137481614947319

Epoch: 5| Step: 8
Training loss: 1.934637427330017
Validation loss: 2.1306699911753335

Epoch: 5| Step: 9
Training loss: 1.8841698169708252
Validation loss: 2.132806440194448

Epoch: 5| Step: 10
Training loss: 2.411839246749878
Validation loss: 2.146559417247772

Epoch: 5| Step: 11
Training loss: 1.6142873764038086
Validation loss: 2.1436468760172525

Epoch: 259| Step: 0
Training loss: 2.382133960723877
Validation loss: 2.158363699913025

Epoch: 5| Step: 1
Training loss: 1.5491492748260498
Validation loss: 2.1434289664030075

Epoch: 5| Step: 2
Training loss: 1.7757841348648071
Validation loss: 2.1547446300586066

Epoch: 5| Step: 3
Training loss: 1.8775631189346313
Validation loss: 2.1556897362073264

Epoch: 5| Step: 4
Training loss: 1.8780008554458618
Validation loss: 2.1405639946460724

Epoch: 5| Step: 5
Training loss: 1.6329164505004883
Validation loss: 2.1555865108966827

Epoch: 5| Step: 6
Training loss: 1.206977128982544
Validation loss: 2.1674234767754874

Epoch: 5| Step: 7
Training loss: 2.0216190814971924
Validation loss: 2.155908986926079

Epoch: 5| Step: 8
Training loss: 2.1115078926086426
Validation loss: 2.1448369224866233

Epoch: 5| Step: 9
Training loss: 1.8983242511749268
Validation loss: 2.16123695174853

Epoch: 5| Step: 10
Training loss: 2.007546901702881
Validation loss: 2.1515213946501413

Epoch: 5| Step: 11
Training loss: 2.3860533237457275
Validation loss: 2.154850482940674

Epoch: 260| Step: 0
Training loss: 1.830336332321167
Validation loss: 2.14274596174558

Epoch: 5| Step: 1
Training loss: 2.137812376022339
Validation loss: 2.1629007856051126

Epoch: 5| Step: 2
Training loss: 1.7791748046875
Validation loss: 2.159492721160253

Epoch: 5| Step: 3
Training loss: 2.6000616550445557
Validation loss: 2.1396679133176804

Epoch: 5| Step: 4
Training loss: 1.7412265539169312
Validation loss: 2.1674023369948068

Epoch: 5| Step: 5
Training loss: 1.8958568572998047
Validation loss: 2.192883516351382

Epoch: 5| Step: 6
Training loss: 1.7800430059432983
Validation loss: 2.1815313398838043

Epoch: 5| Step: 7
Training loss: 1.729156494140625
Validation loss: 2.1730370273192725

Epoch: 5| Step: 8
Training loss: 1.8763360977172852
Validation loss: 2.1909419695536294

Epoch: 5| Step: 9
Training loss: 1.7177162170410156
Validation loss: 2.187143842379252

Epoch: 5| Step: 10
Training loss: 1.183601975440979
Validation loss: 2.1724098920822144

Epoch: 5| Step: 11
Training loss: 1.6504936218261719
Validation loss: 2.175433943669001

Epoch: 261| Step: 0
Training loss: 1.594482421875
Validation loss: 2.1434531857570014

Epoch: 5| Step: 1
Training loss: 2.0927886962890625
Validation loss: 2.14218016465505

Epoch: 5| Step: 2
Training loss: 2.0561413764953613
Validation loss: 2.125687892238299

Epoch: 5| Step: 3
Training loss: 2.1406569480895996
Validation loss: 2.1316372702519097

Epoch: 5| Step: 4
Training loss: 1.8530327081680298
Validation loss: 2.133552541335424

Epoch: 5| Step: 5
Training loss: 1.5521951913833618
Validation loss: 2.1322547694047294

Epoch: 5| Step: 6
Training loss: 1.841909646987915
Validation loss: 2.133689691623052

Epoch: 5| Step: 7
Training loss: 1.9135181903839111
Validation loss: 2.1324805120627084

Epoch: 5| Step: 8
Training loss: 2.0454940795898438
Validation loss: 2.140661358833313

Epoch: 5| Step: 9
Training loss: 1.7177734375
Validation loss: 2.1364947160085044

Epoch: 5| Step: 10
Training loss: 2.189605712890625
Validation loss: 2.1395133584737778

Epoch: 5| Step: 11
Training loss: 3.4202568531036377
Validation loss: 2.160033186276754

Epoch: 262| Step: 0
Training loss: 1.8637710809707642
Validation loss: 2.161499152580897

Epoch: 5| Step: 1
Training loss: 1.9484386444091797
Validation loss: 2.1518775522708893

Epoch: 5| Step: 2
Training loss: 2.2895889282226562
Validation loss: 2.156147946914037

Epoch: 5| Step: 3
Training loss: 1.8229252099990845
Validation loss: 2.1332847426335015

Epoch: 5| Step: 4
Training loss: 2.075676441192627
Validation loss: 2.1681483536958694

Epoch: 5| Step: 5
Training loss: 1.6813793182373047
Validation loss: 2.137483318646749

Epoch: 5| Step: 6
Training loss: 1.7823784351348877
Validation loss: 2.1107438802719116

Epoch: 5| Step: 7
Training loss: 1.9638277292251587
Validation loss: 2.1073832710584006

Epoch: 5| Step: 8
Training loss: 2.5156493186950684
Validation loss: 2.1244083841641745

Epoch: 5| Step: 9
Training loss: 2.1405794620513916
Validation loss: 2.1092209070920944

Epoch: 5| Step: 10
Training loss: 1.7467176914215088
Validation loss: 2.108438233534495

Epoch: 5| Step: 11
Training loss: 2.2575125694274902
Validation loss: 2.103712851802508

Epoch: 263| Step: 0
Training loss: 2.0265865325927734
Validation loss: 2.0812974075476327

Epoch: 5| Step: 1
Training loss: 2.365267515182495
Validation loss: 2.0902668833732605

Epoch: 5| Step: 2
Training loss: 1.6013094186782837
Validation loss: 2.093616450826327

Epoch: 5| Step: 3
Training loss: 2.4816596508026123
Validation loss: 2.099563797314962

Epoch: 5| Step: 4
Training loss: 1.9890763759613037
Validation loss: 2.0904468446969986

Epoch: 5| Step: 5
Training loss: 1.8377058506011963
Validation loss: 2.1166358292102814

Epoch: 5| Step: 6
Training loss: 1.8795804977416992
Validation loss: 2.112919270992279

Epoch: 5| Step: 7
Training loss: 1.8377418518066406
Validation loss: 2.1151684870322547

Epoch: 5| Step: 8
Training loss: 1.6080869436264038
Validation loss: 2.113724668820699

Epoch: 5| Step: 9
Training loss: 2.273207187652588
Validation loss: 2.111100514729818

Epoch: 5| Step: 10
Training loss: 1.9515186548233032
Validation loss: 2.1238414645195007

Epoch: 5| Step: 11
Training loss: 1.7936993837356567
Validation loss: 2.113699128230413

Epoch: 264| Step: 0
Training loss: 2.2518210411071777
Validation loss: 2.140402431289355

Epoch: 5| Step: 1
Training loss: 2.033964157104492
Validation loss: 2.121272866924604

Epoch: 5| Step: 2
Training loss: 1.6195037364959717
Validation loss: 2.1573165456453958

Epoch: 5| Step: 3
Training loss: 2.4143567085266113
Validation loss: 2.173141727844874

Epoch: 5| Step: 4
Training loss: 1.6679489612579346
Validation loss: 2.1758988400300345

Epoch: 5| Step: 5
Training loss: 1.850041151046753
Validation loss: 2.180880685647329

Epoch: 5| Step: 6
Training loss: 1.2778643369674683
Validation loss: 2.2179288963476815

Epoch: 5| Step: 7
Training loss: 2.1451337337493896
Validation loss: 2.1939683904250464

Epoch: 5| Step: 8
Training loss: 1.9113050699234009
Validation loss: 2.162369648615519

Epoch: 5| Step: 9
Training loss: 2.073880672454834
Validation loss: 2.1590407490730286

Epoch: 5| Step: 10
Training loss: 1.857405424118042
Validation loss: 2.1617177625497184

Epoch: 5| Step: 11
Training loss: 1.658832311630249
Validation loss: 2.1417931964000068

Epoch: 265| Step: 0
Training loss: 2.0150704383850098
Validation loss: 2.1294342428445816

Epoch: 5| Step: 1
Training loss: 1.6752926111221313
Validation loss: 2.135824794570605

Epoch: 5| Step: 2
Training loss: 1.8845161199569702
Validation loss: 2.130834852655729

Epoch: 5| Step: 3
Training loss: 2.0121102333068848
Validation loss: 2.1405271192391715

Epoch: 5| Step: 4
Training loss: 1.7388789653778076
Validation loss: 2.1318676422039666

Epoch: 5| Step: 5
Training loss: 1.8345887660980225
Validation loss: 2.131121272842089

Epoch: 5| Step: 6
Training loss: 1.8841012716293335
Validation loss: 2.145774265130361

Epoch: 5| Step: 7
Training loss: 2.0954298973083496
Validation loss: 2.154021223386129

Epoch: 5| Step: 8
Training loss: 2.2773261070251465
Validation loss: 2.165686249732971

Epoch: 5| Step: 9
Training loss: 1.852826714515686
Validation loss: 2.1657612174749374

Epoch: 5| Step: 10
Training loss: 1.4706147909164429
Validation loss: 2.1566925942897797

Epoch: 5| Step: 11
Training loss: 3.359858989715576
Validation loss: 2.151973436276118

Epoch: 266| Step: 0
Training loss: 1.9177420139312744
Validation loss: 2.1716017921765647

Epoch: 5| Step: 1
Training loss: 1.6231743097305298
Validation loss: 2.220164676507314

Epoch: 5| Step: 2
Training loss: 2.7161335945129395
Validation loss: 2.2089156856139502

Epoch: 5| Step: 3
Training loss: 1.8787877559661865
Validation loss: 2.2102966606616974

Epoch: 5| Step: 4
Training loss: 2.2191660404205322
Validation loss: 2.1888316571712494

Epoch: 5| Step: 5
Training loss: 1.798269271850586
Validation loss: 2.17133695880572

Epoch: 5| Step: 6
Training loss: 1.9186588525772095
Validation loss: 2.1474583943684897

Epoch: 5| Step: 7
Training loss: 1.9494339227676392
Validation loss: 2.1464717586835227

Epoch: 5| Step: 8
Training loss: 1.4337700605392456
Validation loss: 2.1376771330833435

Epoch: 5| Step: 9
Training loss: 1.9474608898162842
Validation loss: 2.1299034853776297

Epoch: 5| Step: 10
Training loss: 2.6682093143463135
Validation loss: 2.125552495320638

Epoch: 5| Step: 11
Training loss: 1.685234546661377
Validation loss: 2.131199926137924

Epoch: 267| Step: 0
Training loss: 1.8680450916290283
Validation loss: 2.1336609621842704

Epoch: 5| Step: 1
Training loss: 2.1366944313049316
Validation loss: 2.1405658274888992

Epoch: 5| Step: 2
Training loss: 1.707672119140625
Validation loss: 2.135495364665985

Epoch: 5| Step: 3
Training loss: 2.2964770793914795
Validation loss: 2.134486918648084

Epoch: 5| Step: 4
Training loss: 1.8810018301010132
Validation loss: 2.1348440647125244

Epoch: 5| Step: 5
Training loss: 1.817095398902893
Validation loss: 2.128593529264132

Epoch: 5| Step: 6
Training loss: 2.318948268890381
Validation loss: 2.150760978460312

Epoch: 5| Step: 7
Training loss: 1.6811268329620361
Validation loss: 2.16275625427564

Epoch: 5| Step: 8
Training loss: 1.3570144176483154
Validation loss: 2.1464661359786987

Epoch: 5| Step: 9
Training loss: 2.1159157752990723
Validation loss: 2.1576477885246277

Epoch: 5| Step: 10
Training loss: 1.5652978420257568
Validation loss: 2.160861387848854

Epoch: 5| Step: 11
Training loss: 0.9290350675582886
Validation loss: 2.1638471484184265

Epoch: 268| Step: 0
Training loss: 2.086402654647827
Validation loss: 2.191990906993548

Epoch: 5| Step: 1
Training loss: 1.787148118019104
Validation loss: 2.1879397183656693

Epoch: 5| Step: 2
Training loss: 1.9273099899291992
Validation loss: 2.1960428605477014

Epoch: 5| Step: 3
Training loss: 2.2834737300872803
Validation loss: 2.2090048293272653

Epoch: 5| Step: 4
Training loss: 1.6146843433380127
Validation loss: 2.1981668174266815

Epoch: 5| Step: 5
Training loss: 1.8576877117156982
Validation loss: 2.1970211962858834

Epoch: 5| Step: 6
Training loss: 1.8691892623901367
Validation loss: 2.1839533150196075

Epoch: 5| Step: 7
Training loss: 1.8063989877700806
Validation loss: 2.157395675778389

Epoch: 5| Step: 8
Training loss: 1.8746925592422485
Validation loss: 2.156498610973358

Epoch: 5| Step: 9
Training loss: 1.8713390827178955
Validation loss: 2.1508326530456543

Epoch: 5| Step: 10
Training loss: 1.427237629890442
Validation loss: 2.159862220287323

Epoch: 5| Step: 11
Training loss: 1.5828319787979126
Validation loss: 2.1572800278663635

Epoch: 269| Step: 0
Training loss: 1.3969846963882446
Validation loss: 2.157167285680771

Epoch: 5| Step: 1
Training loss: 1.746953010559082
Validation loss: 2.1353963911533356

Epoch: 5| Step: 2
Training loss: 1.0653449296951294
Validation loss: 2.1390914618968964

Epoch: 5| Step: 3
Training loss: 1.9375346899032593
Validation loss: 2.152294859290123

Epoch: 5| Step: 4
Training loss: 1.8661807775497437
Validation loss: 2.1377277225255966

Epoch: 5| Step: 5
Training loss: 2.2006449699401855
Validation loss: 2.157110114892324

Epoch: 5| Step: 6
Training loss: 2.2548668384552
Validation loss: 2.1579101284344993

Epoch: 5| Step: 7
Training loss: 1.5385310649871826
Validation loss: 2.157493144273758

Epoch: 5| Step: 8
Training loss: 1.9352134466171265
Validation loss: 2.1635144551595054

Epoch: 5| Step: 9
Training loss: 2.2157154083251953
Validation loss: 2.170662522315979

Epoch: 5| Step: 10
Training loss: 2.4512217044830322
Validation loss: 2.193897465864817

Epoch: 5| Step: 11
Training loss: 2.03776478767395
Validation loss: 2.197103346387545

Epoch: 270| Step: 0
Training loss: 1.6385574340820312
Validation loss: 2.1762655377388

Epoch: 5| Step: 1
Training loss: 2.077200412750244
Validation loss: 2.181955248117447

Epoch: 5| Step: 2
Training loss: 2.115570545196533
Validation loss: 2.1816420207420983

Epoch: 5| Step: 3
Training loss: 2.1311092376708984
Validation loss: 2.1858943899472556

Epoch: 5| Step: 4
Training loss: 1.9338805675506592
Validation loss: 2.1870724658171334

Epoch: 5| Step: 5
Training loss: 1.8051471710205078
Validation loss: 2.164364198843638

Epoch: 5| Step: 6
Training loss: 1.7067387104034424
Validation loss: 2.154241199294726

Epoch: 5| Step: 7
Training loss: 1.8278639316558838
Validation loss: 2.1718524446090064

Epoch: 5| Step: 8
Training loss: 2.020580768585205
Validation loss: 2.1680580774943032

Epoch: 5| Step: 9
Training loss: 1.1609482765197754
Validation loss: 2.1530006577571235

Epoch: 5| Step: 10
Training loss: 1.8888330459594727
Validation loss: 2.1746001640955606

Epoch: 5| Step: 11
Training loss: 1.1022692918777466
Validation loss: 2.1884263356526694

Epoch: 271| Step: 0
Training loss: 2.352510452270508
Validation loss: 2.1798099875450134

Epoch: 5| Step: 1
Training loss: 2.035841464996338
Validation loss: 2.1931349436442056

Epoch: 5| Step: 2
Training loss: 1.4108854532241821
Validation loss: 2.1946087131897607

Epoch: 5| Step: 3
Training loss: 2.0882086753845215
Validation loss: 2.1814456482728324

Epoch: 5| Step: 4
Training loss: 1.3723385334014893
Validation loss: 2.197169244289398

Epoch: 5| Step: 5
Training loss: 1.4405269622802734
Validation loss: 2.1747026294469833

Epoch: 5| Step: 6
Training loss: 1.6135215759277344
Validation loss: 2.1735202272733054

Epoch: 5| Step: 7
Training loss: 2.505995035171509
Validation loss: 2.1830593993266425

Epoch: 5| Step: 8
Training loss: 1.7243554592132568
Validation loss: 2.1755807300408683

Epoch: 5| Step: 9
Training loss: 1.5607342720031738
Validation loss: 2.1837088018655777

Epoch: 5| Step: 10
Training loss: 1.6884033679962158
Validation loss: 2.1632895469665527

Epoch: 5| Step: 11
Training loss: 2.6926681995391846
Validation loss: 2.1897969792286553

Epoch: 272| Step: 0
Training loss: 2.000155210494995
Validation loss: 2.178316424290339

Epoch: 5| Step: 1
Training loss: 1.4044837951660156
Validation loss: 2.167244161168734

Epoch: 5| Step: 2
Training loss: 2.106160879135132
Validation loss: 2.169121111432711

Epoch: 5| Step: 3
Training loss: 2.3668835163116455
Validation loss: 2.175559734304746

Epoch: 5| Step: 4
Training loss: 2.0528085231781006
Validation loss: 2.182928204536438

Epoch: 5| Step: 5
Training loss: 1.544392466545105
Validation loss: 2.1773308912913003

Epoch: 5| Step: 6
Training loss: 1.7121846675872803
Validation loss: 2.1835839450359344

Epoch: 5| Step: 7
Training loss: 1.7565332651138306
Validation loss: 2.1907196640968323

Epoch: 5| Step: 8
Training loss: 1.7488305568695068
Validation loss: 2.1970760921637216

Epoch: 5| Step: 9
Training loss: 1.8264386653900146
Validation loss: 2.197416658202807

Epoch: 5| Step: 10
Training loss: 1.388692021369934
Validation loss: 2.181161105632782

Epoch: 5| Step: 11
Training loss: 2.0366058349609375
Validation loss: 2.1601242969433465

Epoch: 273| Step: 0
Training loss: 2.1089158058166504
Validation loss: 2.157512918114662

Epoch: 5| Step: 1
Training loss: 1.8700311183929443
Validation loss: 2.145462473233541

Epoch: 5| Step: 2
Training loss: 2.8402163982391357
Validation loss: 2.15993370115757

Epoch: 5| Step: 3
Training loss: 1.8337364196777344
Validation loss: 2.1558067401250205

Epoch: 5| Step: 4
Training loss: 1.8811399936676025
Validation loss: 2.1527353624502816

Epoch: 5| Step: 5
Training loss: 1.6425920724868774
Validation loss: 2.1457639733950296

Epoch: 5| Step: 6
Training loss: 1.89963698387146
Validation loss: 2.1503035028775535

Epoch: 5| Step: 7
Training loss: 1.6287931203842163
Validation loss: 2.1540164252122245

Epoch: 5| Step: 8
Training loss: 2.0338897705078125
Validation loss: 2.1547916730244956

Epoch: 5| Step: 9
Training loss: 1.414827585220337
Validation loss: 2.16602756579717

Epoch: 5| Step: 10
Training loss: 1.5664771795272827
Validation loss: 2.1659200886885324

Epoch: 5| Step: 11
Training loss: 2.0225954055786133
Validation loss: 2.1853750944137573

Epoch: 274| Step: 0
Training loss: 1.9303627014160156
Validation loss: 2.224314585328102

Epoch: 5| Step: 1
Training loss: 2.350069284439087
Validation loss: 2.2129627416531243

Epoch: 5| Step: 2
Training loss: 2.138211727142334
Validation loss: 2.2428081085284552

Epoch: 5| Step: 3
Training loss: 2.0790321826934814
Validation loss: 2.2126202235619226

Epoch: 5| Step: 4
Training loss: 1.559424877166748
Validation loss: 2.221177483598391

Epoch: 5| Step: 5
Training loss: 1.4024510383605957
Validation loss: 2.206690102815628

Epoch: 5| Step: 6
Training loss: 2.0993735790252686
Validation loss: 2.196284512678782

Epoch: 5| Step: 7
Training loss: 1.349550485610962
Validation loss: 2.1765236606200538

Epoch: 5| Step: 8
Training loss: 2.014465808868408
Validation loss: 2.164070134361585

Epoch: 5| Step: 9
Training loss: 1.662651777267456
Validation loss: 2.1585601568222046

Epoch: 5| Step: 10
Training loss: 2.2036426067352295
Validation loss: 2.1487590918938317

Epoch: 5| Step: 11
Training loss: 1.448723316192627
Validation loss: 2.143972416718801

Epoch: 275| Step: 0
Training loss: 1.5439651012420654
Validation loss: 2.149670347571373

Epoch: 5| Step: 1
Training loss: 2.061685085296631
Validation loss: 2.1566927234331765

Epoch: 5| Step: 2
Training loss: 1.9047753810882568
Validation loss: 2.1673206289609275

Epoch: 5| Step: 3
Training loss: 1.699127435684204
Validation loss: 2.170809547106425

Epoch: 5| Step: 4
Training loss: 1.8243741989135742
Validation loss: 2.167874048153559

Epoch: 5| Step: 5
Training loss: 1.4594076871871948
Validation loss: 2.160267944137255

Epoch: 5| Step: 6
Training loss: 1.9809318780899048
Validation loss: 2.1798124810059867

Epoch: 5| Step: 7
Training loss: 1.6558496952056885
Validation loss: 2.184708187977473

Epoch: 5| Step: 8
Training loss: 2.0537571907043457
Validation loss: 2.1971659610668817

Epoch: 5| Step: 9
Training loss: 1.9035285711288452
Validation loss: 2.1960986852645874

Epoch: 5| Step: 10
Training loss: 1.780175805091858
Validation loss: 2.1860443502664566

Epoch: 5| Step: 11
Training loss: 1.2661675214767456
Validation loss: 2.1911428024371467

Epoch: 276| Step: 0
Training loss: 1.6310844421386719
Validation loss: 2.189850072065989

Epoch: 5| Step: 1
Training loss: 1.4822930097579956
Validation loss: 2.2088713298241296

Epoch: 5| Step: 2
Training loss: 2.0513551235198975
Validation loss: 2.177165081103643

Epoch: 5| Step: 3
Training loss: 2.3385396003723145
Validation loss: 2.1776057283083596

Epoch: 5| Step: 4
Training loss: 1.8756319284439087
Validation loss: 2.1520135700702667

Epoch: 5| Step: 5
Training loss: 1.589202880859375
Validation loss: 2.1516686330238977

Epoch: 5| Step: 6
Training loss: 2.0063393115997314
Validation loss: 2.1698796302080154

Epoch: 5| Step: 7
Training loss: 1.476703405380249
Validation loss: 2.156713366508484

Epoch: 5| Step: 8
Training loss: 1.8497073650360107
Validation loss: 2.156511048475901

Epoch: 5| Step: 9
Training loss: 2.0091052055358887
Validation loss: 2.146984656651815

Epoch: 5| Step: 10
Training loss: 1.7298564910888672
Validation loss: 2.166879956920942

Epoch: 5| Step: 11
Training loss: 2.9237258434295654
Validation loss: 2.149980107943217

Epoch: 277| Step: 0
Training loss: 1.9257045984268188
Validation loss: 2.181705892086029

Epoch: 5| Step: 1
Training loss: 1.453705072402954
Validation loss: 2.1983363380034766

Epoch: 5| Step: 2
Training loss: 0.9440024495124817
Validation loss: 2.190220778187116

Epoch: 5| Step: 3
Training loss: 1.365374207496643
Validation loss: 2.190105656782786

Epoch: 5| Step: 4
Training loss: 2.110055685043335
Validation loss: 2.201984683672587

Epoch: 5| Step: 5
Training loss: 1.8289871215820312
Validation loss: 2.2303266127904258

Epoch: 5| Step: 6
Training loss: 1.635110855102539
Validation loss: 2.206186999877294

Epoch: 5| Step: 7
Training loss: 2.6546642780303955
Validation loss: 2.2086893220742545

Epoch: 5| Step: 8
Training loss: 1.9210491180419922
Validation loss: 2.1977805296579995

Epoch: 5| Step: 9
Training loss: 1.544616937637329
Validation loss: 2.2117835134267807

Epoch: 5| Step: 10
Training loss: 1.941724181175232
Validation loss: 2.215045983592669

Epoch: 5| Step: 11
Training loss: 4.478044509887695
Validation loss: 2.206363171339035

Epoch: 278| Step: 0
Training loss: 1.9498306512832642
Validation loss: 2.201485832532247

Epoch: 5| Step: 1
Training loss: 1.6078704595565796
Validation loss: 2.1921234130859375

Epoch: 5| Step: 2
Training loss: 1.7787128686904907
Validation loss: 2.1945622811714807

Epoch: 5| Step: 3
Training loss: 2.2614636421203613
Validation loss: 2.17309562365214

Epoch: 5| Step: 4
Training loss: 2.166553020477295
Validation loss: 2.1901518603165946

Epoch: 5| Step: 5
Training loss: 1.490831971168518
Validation loss: 2.1726668973763785

Epoch: 5| Step: 6
Training loss: 1.5138695240020752
Validation loss: 2.182687679926554

Epoch: 5| Step: 7
Training loss: 2.061859369277954
Validation loss: 2.186814417441686

Epoch: 5| Step: 8
Training loss: 1.634033203125
Validation loss: 2.1867952098449073

Epoch: 5| Step: 9
Training loss: 1.6891024112701416
Validation loss: 2.174152900775274

Epoch: 5| Step: 10
Training loss: 1.4364713430404663
Validation loss: 2.179689645767212

Epoch: 5| Step: 11
Training loss: 2.2826223373413086
Validation loss: 2.1730839610099792

Epoch: 279| Step: 0
Training loss: 2.203005313873291
Validation loss: 2.1745378325382867

Epoch: 5| Step: 1
Training loss: 1.7052395343780518
Validation loss: 2.1832574158906937

Epoch: 5| Step: 2
Training loss: 1.6259876489639282
Validation loss: 2.190373405814171

Epoch: 5| Step: 3
Training loss: 2.095668077468872
Validation loss: 2.1800552109877267

Epoch: 5| Step: 4
Training loss: 1.7646833658218384
Validation loss: 2.2035864094893136

Epoch: 5| Step: 5
Training loss: 2.0216197967529297
Validation loss: 2.2065100272496543

Epoch: 5| Step: 6
Training loss: 1.9507383108139038
Validation loss: 2.1851564000050225

Epoch: 5| Step: 7
Training loss: 1.4622738361358643
Validation loss: 2.221501479546229

Epoch: 5| Step: 8
Training loss: 2.050426959991455
Validation loss: 2.2264208843310676

Epoch: 5| Step: 9
Training loss: 1.1868741512298584
Validation loss: 2.2243090917666755

Epoch: 5| Step: 10
Training loss: 1.4955061674118042
Validation loss: 2.224609603484472

Epoch: 5| Step: 11
Training loss: 2.1634366512298584
Validation loss: 2.218728964527448

Epoch: 280| Step: 0
Training loss: 1.7600212097167969
Validation loss: 2.1990568339824677

Epoch: 5| Step: 1
Training loss: 1.5049352645874023
Validation loss: 2.2098215321699777

Epoch: 5| Step: 2
Training loss: 1.38875412940979
Validation loss: 2.2269629140694938

Epoch: 5| Step: 3
Training loss: 1.6625922918319702
Validation loss: 2.2174310088157654

Epoch: 5| Step: 4
Training loss: 1.9137462377548218
Validation loss: 2.1949197202920914

Epoch: 5| Step: 5
Training loss: 1.7766205072402954
Validation loss: 2.1881719479958215

Epoch: 5| Step: 6
Training loss: 2.3289103507995605
Validation loss: 2.160258412361145

Epoch: 5| Step: 7
Training loss: 1.8686431646347046
Validation loss: 2.1513388405243554

Epoch: 5| Step: 8
Training loss: 2.6422812938690186
Validation loss: 2.156350776553154

Epoch: 5| Step: 9
Training loss: 1.3129472732543945
Validation loss: 2.1636947443087897

Epoch: 5| Step: 10
Training loss: 1.7509453296661377
Validation loss: 2.161624108751615

Epoch: 5| Step: 11
Training loss: 1.8733149766921997
Validation loss: 2.1582828958829245

Epoch: 281| Step: 0
Training loss: 1.8836479187011719
Validation loss: 2.170303707321485

Epoch: 5| Step: 1
Training loss: 1.7102601528167725
Validation loss: 2.183260848124822

Epoch: 5| Step: 2
Training loss: 2.209381580352783
Validation loss: 2.207694858312607

Epoch: 5| Step: 3
Training loss: 1.8471319675445557
Validation loss: 2.198022574186325

Epoch: 5| Step: 4
Training loss: 1.5668160915374756
Validation loss: 2.2219448536634445

Epoch: 5| Step: 5
Training loss: 1.11173415184021
Validation loss: 2.2215673327445984

Epoch: 5| Step: 6
Training loss: 2.53290057182312
Validation loss: 2.230231980482737

Epoch: 5| Step: 7
Training loss: 1.6221473217010498
Validation loss: 2.2221071074406304

Epoch: 5| Step: 8
Training loss: 2.0013372898101807
Validation loss: 2.211697588364283

Epoch: 5| Step: 9
Training loss: 1.918391466140747
Validation loss: 2.198922355969747

Epoch: 5| Step: 10
Training loss: 1.3805263042449951
Validation loss: 2.200540875395139

Epoch: 5| Step: 11
Training loss: 0.9232380986213684
Validation loss: 2.181329220533371

Epoch: 282| Step: 0
Training loss: 2.077692985534668
Validation loss: 2.167125920454661

Epoch: 5| Step: 1
Training loss: 1.6432647705078125
Validation loss: 2.165306195616722

Epoch: 5| Step: 2
Training loss: 1.8722732067108154
Validation loss: 2.1589329143365226

Epoch: 5| Step: 3
Training loss: 1.7093002796173096
Validation loss: 2.153464471300443

Epoch: 5| Step: 4
Training loss: 1.7579677104949951
Validation loss: 2.1582059214512506

Epoch: 5| Step: 5
Training loss: 1.3693499565124512
Validation loss: 2.162669519583384

Epoch: 5| Step: 6
Training loss: 1.6237462759017944
Validation loss: 2.1693562418222427

Epoch: 5| Step: 7
Training loss: 1.6797950267791748
Validation loss: 2.181092992424965

Epoch: 5| Step: 8
Training loss: 2.1798813343048096
Validation loss: 2.152406473954519

Epoch: 5| Step: 9
Training loss: 2.274850606918335
Validation loss: 2.1791769613822303

Epoch: 5| Step: 10
Training loss: 1.3552862405776978
Validation loss: 2.1780042350292206

Epoch: 5| Step: 11
Training loss: 0.9343720078468323
Validation loss: 2.1655793885389962

Epoch: 283| Step: 0
Training loss: 1.6965383291244507
Validation loss: 2.1753062258164086

Epoch: 5| Step: 1
Training loss: 2.1802029609680176
Validation loss: 2.1950189769268036

Epoch: 5| Step: 2
Training loss: 1.657074213027954
Validation loss: 2.207078287998835

Epoch: 5| Step: 3
Training loss: 1.7795217037200928
Validation loss: 2.2127261559168496

Epoch: 5| Step: 4
Training loss: 1.737276315689087
Validation loss: 2.205440729856491

Epoch: 5| Step: 5
Training loss: 1.9629064798355103
Validation loss: 2.1538922786712646

Epoch: 5| Step: 6
Training loss: 2.1540229320526123
Validation loss: 2.1681916465361915

Epoch: 5| Step: 7
Training loss: 1.9549648761749268
Validation loss: 2.1620766321818032

Epoch: 5| Step: 8
Training loss: 1.6685893535614014
Validation loss: 2.152811219294866

Epoch: 5| Step: 9
Training loss: 1.4916942119598389
Validation loss: 2.155873730778694

Epoch: 5| Step: 10
Training loss: 2.082730531692505
Validation loss: 2.156708608071009

Epoch: 5| Step: 11
Training loss: 2.5943315029144287
Validation loss: 2.1408663541078568

Epoch: 284| Step: 0
Training loss: 2.011011838912964
Validation loss: 2.1549306412537894

Epoch: 5| Step: 1
Training loss: 1.4805272817611694
Validation loss: 2.141602332393328

Epoch: 5| Step: 2
Training loss: 2.0870566368103027
Validation loss: 2.1572387466828027

Epoch: 5| Step: 3
Training loss: 1.32069730758667
Validation loss: 2.173694461584091

Epoch: 5| Step: 4
Training loss: 1.8479276895523071
Validation loss: 2.1729603111743927

Epoch: 5| Step: 5
Training loss: 2.4095871448516846
Validation loss: 2.1900831162929535

Epoch: 5| Step: 6
Training loss: 2.107231616973877
Validation loss: 2.1758125325043998

Epoch: 5| Step: 7
Training loss: 1.6553939580917358
Validation loss: 2.1895363430182138

Epoch: 5| Step: 8
Training loss: 1.816521406173706
Validation loss: 2.200423374772072

Epoch: 5| Step: 9
Training loss: 1.706479787826538
Validation loss: 2.2213979611794152

Epoch: 5| Step: 10
Training loss: 1.5426139831542969
Validation loss: 2.219939942161242

Epoch: 5| Step: 11
Training loss: 1.5430619716644287
Validation loss: 2.208440845211347

Epoch: 285| Step: 0
Training loss: 1.9063743352890015
Validation loss: 2.233851666251818

Epoch: 5| Step: 1
Training loss: 2.0114989280700684
Validation loss: 2.245346332589785

Epoch: 5| Step: 2
Training loss: 1.7395397424697876
Validation loss: 2.2081312338511148

Epoch: 5| Step: 3
Training loss: 1.2760447263717651
Validation loss: 2.1926194727420807

Epoch: 5| Step: 4
Training loss: 1.4941221475601196
Validation loss: 2.192656477292379

Epoch: 5| Step: 5
Training loss: 1.7763656377792358
Validation loss: 2.179018646478653

Epoch: 5| Step: 6
Training loss: 2.158963680267334
Validation loss: 2.1772513141234717

Epoch: 5| Step: 7
Training loss: 1.7750155925750732
Validation loss: 2.1641572415828705

Epoch: 5| Step: 8
Training loss: 1.5855491161346436
Validation loss: 2.165821353594462

Epoch: 5| Step: 9
Training loss: 2.1378722190856934
Validation loss: 2.1809103886286416

Epoch: 5| Step: 10
Training loss: 2.2365763187408447
Validation loss: 2.172886778910955

Epoch: 5| Step: 11
Training loss: 2.853102207183838
Validation loss: 2.180796355009079

Epoch: 286| Step: 0
Training loss: 1.8587284088134766
Validation loss: 2.1855749090512595

Epoch: 5| Step: 1
Training loss: 2.1072514057159424
Validation loss: 2.21139786640803

Epoch: 5| Step: 2
Training loss: 2.367495059967041
Validation loss: 2.2163581947485604

Epoch: 5| Step: 3
Training loss: 1.5986003875732422
Validation loss: 2.2014523446559906

Epoch: 5| Step: 4
Training loss: 1.7602310180664062
Validation loss: 2.224505419532458

Epoch: 5| Step: 5
Training loss: 2.1357333660125732
Validation loss: 2.2305298298597336

Epoch: 5| Step: 6
Training loss: 1.7010360956192017
Validation loss: 2.212264373898506

Epoch: 5| Step: 7
Training loss: 1.2908604145050049
Validation loss: 2.19595460096995

Epoch: 5| Step: 8
Training loss: 2.0754826068878174
Validation loss: 2.1938101102908454

Epoch: 5| Step: 9
Training loss: 2.2406413555145264
Validation loss: 2.179367790619532

Epoch: 5| Step: 10
Training loss: 1.3059284687042236
Validation loss: 2.1866379777590432

Epoch: 5| Step: 11
Training loss: 2.4222984313964844
Validation loss: 2.161409914493561

Epoch: 287| Step: 0
Training loss: 1.9391968250274658
Validation loss: 2.1750796486934028

Epoch: 5| Step: 1
Training loss: 1.4316858053207397
Validation loss: 2.169711008667946

Epoch: 5| Step: 2
Training loss: 1.8428148031234741
Validation loss: 2.1730260401964188

Epoch: 5| Step: 3
Training loss: 1.5489962100982666
Validation loss: 2.163156419992447

Epoch: 5| Step: 4
Training loss: 1.336323618888855
Validation loss: 2.15898368259271

Epoch: 5| Step: 5
Training loss: 1.911623239517212
Validation loss: 2.189200838406881

Epoch: 5| Step: 6
Training loss: 2.434262990951538
Validation loss: 2.169618546962738

Epoch: 5| Step: 7
Training loss: 1.668028473854065
Validation loss: 2.19380791982015

Epoch: 5| Step: 8
Training loss: 2.0829918384552
Validation loss: 2.1942322750886283

Epoch: 5| Step: 9
Training loss: 1.9271385669708252
Validation loss: 2.208397775888443

Epoch: 5| Step: 10
Training loss: 1.7398065328598022
Validation loss: 2.22252290447553

Epoch: 5| Step: 11
Training loss: 1.962078332901001
Validation loss: 2.1983280032873154

Epoch: 288| Step: 0
Training loss: 1.8045566082000732
Validation loss: 2.19164148469766

Epoch: 5| Step: 1
Training loss: 1.6453571319580078
Validation loss: 2.196663667758306

Epoch: 5| Step: 2
Training loss: 1.6846920251846313
Validation loss: 2.2128827621539435

Epoch: 5| Step: 3
Training loss: 1.427746057510376
Validation loss: 2.1819258332252502

Epoch: 5| Step: 4
Training loss: 2.3950791358947754
Validation loss: 2.1768862158060074

Epoch: 5| Step: 5
Training loss: 1.7739025354385376
Validation loss: 2.173410107692083

Epoch: 5| Step: 6
Training loss: 1.9063494205474854
Validation loss: 2.1704052289326987

Epoch: 5| Step: 7
Training loss: 1.4577138423919678
Validation loss: 2.1786933143933616

Epoch: 5| Step: 8
Training loss: 1.7925186157226562
Validation loss: 2.1817848285039267

Epoch: 5| Step: 9
Training loss: 1.7660713195800781
Validation loss: 2.18373633424441

Epoch: 5| Step: 10
Training loss: 2.1151504516601562
Validation loss: 2.1948255449533463

Epoch: 5| Step: 11
Training loss: 2.3359382152557373
Validation loss: 2.177502820889155

Epoch: 289| Step: 0
Training loss: 1.6593894958496094
Validation loss: 2.200950652360916

Epoch: 5| Step: 1
Training loss: 1.8906097412109375
Validation loss: 2.190001666545868

Epoch: 5| Step: 2
Training loss: 1.672109842300415
Validation loss: 2.1987329622109733

Epoch: 5| Step: 3
Training loss: 1.9003865718841553
Validation loss: 2.1946177979310355

Epoch: 5| Step: 4
Training loss: 1.8710517883300781
Validation loss: 2.1941478749116263

Epoch: 5| Step: 5
Training loss: 1.6932227611541748
Validation loss: 2.2001232703526816

Epoch: 5| Step: 6
Training loss: 1.6763629913330078
Validation loss: 2.1780003756284714

Epoch: 5| Step: 7
Training loss: 1.6411349773406982
Validation loss: 2.1841457883516946

Epoch: 5| Step: 8
Training loss: 2.1958789825439453
Validation loss: 2.1941056549549103

Epoch: 5| Step: 9
Training loss: 1.5437853336334229
Validation loss: 2.166711241006851

Epoch: 5| Step: 10
Training loss: 2.1387381553649902
Validation loss: 2.1759497125943503

Epoch: 5| Step: 11
Training loss: 1.7488585710525513
Validation loss: 2.176121642192205

Epoch: 290| Step: 0
Training loss: 2.1707749366760254
Validation loss: 2.1776274144649506

Epoch: 5| Step: 1
Training loss: 1.853888750076294
Validation loss: 2.1653391321500144

Epoch: 5| Step: 2
Training loss: 1.608432412147522
Validation loss: 2.1941462804873786

Epoch: 5| Step: 3
Training loss: 2.0506014823913574
Validation loss: 2.200949798027674

Epoch: 5| Step: 4
Training loss: 1.4239866733551025
Validation loss: 2.207292010386785

Epoch: 5| Step: 5
Training loss: 1.585066556930542
Validation loss: 2.2094703366359076

Epoch: 5| Step: 6
Training loss: 2.20893931388855
Validation loss: 2.211094856262207

Epoch: 5| Step: 7
Training loss: 2.214528799057007
Validation loss: 2.2372382283210754

Epoch: 5| Step: 8
Training loss: 1.8197944164276123
Validation loss: 2.2154535402854285

Epoch: 5| Step: 9
Training loss: 1.360950231552124
Validation loss: 2.2340959111849465

Epoch: 5| Step: 10
Training loss: 1.329742431640625
Validation loss: 2.243420258164406

Epoch: 5| Step: 11
Training loss: 1.6293935775756836
Validation loss: 2.239852567513784

Epoch: 291| Step: 0
Training loss: 2.2896218299865723
Validation loss: 2.2262911399205527

Epoch: 5| Step: 1
Training loss: 1.6832294464111328
Validation loss: 2.247704734404882

Epoch: 5| Step: 2
Training loss: 1.7731109857559204
Validation loss: 2.2360951403776803

Epoch: 5| Step: 3
Training loss: 1.8886520862579346
Validation loss: 2.219818194707235

Epoch: 5| Step: 4
Training loss: 1.7196346521377563
Validation loss: 2.2381963431835175

Epoch: 5| Step: 5
Training loss: 1.945092797279358
Validation loss: 2.234221011400223

Epoch: 5| Step: 6
Training loss: 1.8440983295440674
Validation loss: 2.2107703238725662

Epoch: 5| Step: 7
Training loss: 1.735857367515564
Validation loss: 2.212386598189672

Epoch: 5| Step: 8
Training loss: 1.930651307106018
Validation loss: 2.2156249582767487

Epoch: 5| Step: 9
Training loss: 1.1420016288757324
Validation loss: 2.211473122239113

Epoch: 5| Step: 10
Training loss: 1.8330659866333008
Validation loss: 2.1867437064647675

Epoch: 5| Step: 11
Training loss: 2.3592894077301025
Validation loss: 2.2095160434643426

Epoch: 292| Step: 0
Training loss: 1.7519416809082031
Validation loss: 2.214097892244657

Epoch: 5| Step: 1
Training loss: 1.7246183156967163
Validation loss: 2.2177030046780906

Epoch: 5| Step: 2
Training loss: 1.9680588245391846
Validation loss: 2.1998137931029

Epoch: 5| Step: 3
Training loss: 2.185319423675537
Validation loss: 2.194370776414871

Epoch: 5| Step: 4
Training loss: 1.794409990310669
Validation loss: 2.2127804507811866

Epoch: 5| Step: 5
Training loss: 1.5756057500839233
Validation loss: 2.2071435501178107

Epoch: 5| Step: 6
Training loss: 1.6623748540878296
Validation loss: 2.1895999560753503

Epoch: 5| Step: 7
Training loss: 1.8466402292251587
Validation loss: 2.204011787970861

Epoch: 5| Step: 8
Training loss: 1.6206305027008057
Validation loss: 2.1933597872654595

Epoch: 5| Step: 9
Training loss: 1.7387386560440063
Validation loss: 2.220933213829994

Epoch: 5| Step: 10
Training loss: 1.8189083337783813
Validation loss: 2.2167059729496636

Epoch: 5| Step: 11
Training loss: 0.8431086540222168
Validation loss: 2.2257954676946006

Epoch: 293| Step: 0
Training loss: 2.265310764312744
Validation loss: 2.212959408760071

Epoch: 5| Step: 1
Training loss: 1.4295096397399902
Validation loss: 2.1824223150809607

Epoch: 5| Step: 2
Training loss: 1.6411997079849243
Validation loss: 2.191401332616806

Epoch: 5| Step: 3
Training loss: 1.4477800130844116
Validation loss: 2.1870052019755044

Epoch: 5| Step: 4
Training loss: 1.8414922952651978
Validation loss: 2.1974675059318542

Epoch: 5| Step: 5
Training loss: 1.4599330425262451
Validation loss: 2.1878692507743835

Epoch: 5| Step: 6
Training loss: 1.240614652633667
Validation loss: 2.210513412952423

Epoch: 5| Step: 7
Training loss: 1.5573786497116089
Validation loss: 2.213740438222885

Epoch: 5| Step: 8
Training loss: 2.5328221321105957
Validation loss: 2.1988602379957833

Epoch: 5| Step: 9
Training loss: 1.5435457229614258
Validation loss: 2.192038287719091

Epoch: 5| Step: 10
Training loss: 2.741192102432251
Validation loss: 2.1964819381634393

Epoch: 5| Step: 11
Training loss: 1.590469241142273
Validation loss: 2.231075088183085

Epoch: 294| Step: 0
Training loss: 1.991539716720581
Validation loss: 2.207892060279846

Epoch: 5| Step: 1
Training loss: 2.04522442817688
Validation loss: 2.2419679760932922

Epoch: 5| Step: 2
Training loss: 1.8973562717437744
Validation loss: 2.223746135830879

Epoch: 5| Step: 3
Training loss: 1.5574462413787842
Validation loss: 2.2312736908594766

Epoch: 5| Step: 4
Training loss: 2.2598958015441895
Validation loss: 2.230124612649282

Epoch: 5| Step: 5
Training loss: 1.043655514717102
Validation loss: 2.232442617416382

Epoch: 5| Step: 6
Training loss: 1.3907034397125244
Validation loss: 2.2192754795153937

Epoch: 5| Step: 7
Training loss: 1.295261025428772
Validation loss: 2.1825574537118277

Epoch: 5| Step: 8
Training loss: 1.6825129985809326
Validation loss: 2.1931125621000924

Epoch: 5| Step: 9
Training loss: 1.7636858224868774
Validation loss: 2.1635032494862876

Epoch: 5| Step: 10
Training loss: 2.6182243824005127
Validation loss: 2.149177481730779

Epoch: 5| Step: 11
Training loss: 1.7980589866638184
Validation loss: 2.1523195803165436

Epoch: 295| Step: 0
Training loss: 2.274644374847412
Validation loss: 2.151368180910746

Epoch: 5| Step: 1
Training loss: 1.9989211559295654
Validation loss: 2.160472199320793

Epoch: 5| Step: 2
Training loss: 1.4085592031478882
Validation loss: 2.1724341213703156

Epoch: 5| Step: 3
Training loss: 1.5954234600067139
Validation loss: 2.1621836374203363

Epoch: 5| Step: 4
Training loss: 1.4943602085113525
Validation loss: 2.171704724431038

Epoch: 5| Step: 5
Training loss: 2.0977530479431152
Validation loss: 2.1711020121971765

Epoch: 5| Step: 6
Training loss: 1.542903184890747
Validation loss: 2.161201218763987

Epoch: 5| Step: 7
Training loss: 2.0860626697540283
Validation loss: 2.163361003001531

Epoch: 5| Step: 8
Training loss: 1.6377885341644287
Validation loss: 2.181270952026049

Epoch: 5| Step: 9
Training loss: 1.4965521097183228
Validation loss: 2.1917691429456077

Epoch: 5| Step: 10
Training loss: 2.2495312690734863
Validation loss: 2.205748955408732

Epoch: 5| Step: 11
Training loss: 2.7228622436523438
Validation loss: 2.214530646800995

Epoch: 296| Step: 0
Training loss: 1.854954719543457
Validation loss: 2.217043732603391

Epoch: 5| Step: 1
Training loss: 2.1247711181640625
Validation loss: 2.232309808333715

Epoch: 5| Step: 2
Training loss: 1.4933555126190186
Validation loss: 2.2727087835470834

Epoch: 5| Step: 3
Training loss: 1.633567452430725
Validation loss: 2.2556813657283783

Epoch: 5| Step: 4
Training loss: 1.6709468364715576
Validation loss: 2.2304233610630035

Epoch: 5| Step: 5
Training loss: 2.4080913066864014
Validation loss: 2.2388952175776162

Epoch: 5| Step: 6
Training loss: 1.105373740196228
Validation loss: 2.224414254228274

Epoch: 5| Step: 7
Training loss: 1.6720390319824219
Validation loss: 2.2173099716504416

Epoch: 5| Step: 8
Training loss: 2.093013048171997
Validation loss: 2.1888818393150964

Epoch: 5| Step: 9
Training loss: 1.6665446758270264
Validation loss: 2.2012477119763694

Epoch: 5| Step: 10
Training loss: 2.0514867305755615
Validation loss: 2.1934251934289932

Epoch: 5| Step: 11
Training loss: 1.400230884552002
Validation loss: 2.1780419697364173

Epoch: 297| Step: 0
Training loss: 1.9109580516815186
Validation loss: 2.1981334686279297

Epoch: 5| Step: 1
Training loss: 2.2020151615142822
Validation loss: 2.189081917206446

Epoch: 5| Step: 2
Training loss: 1.7688446044921875
Validation loss: 2.1801818509896598

Epoch: 5| Step: 3
Training loss: 1.6004068851470947
Validation loss: 2.2029171933730445

Epoch: 5| Step: 4
Training loss: 1.8798720836639404
Validation loss: 2.2111950467030206

Epoch: 5| Step: 5
Training loss: 1.5005366802215576
Validation loss: 2.2157434672117233

Epoch: 5| Step: 6
Training loss: 1.405147910118103
Validation loss: 2.2344708492358527

Epoch: 5| Step: 7
Training loss: 2.0615975856781006
Validation loss: 2.232652341326078

Epoch: 5| Step: 8
Training loss: 1.5775549411773682
Validation loss: 2.2167877356211343

Epoch: 5| Step: 9
Training loss: 1.7484626770019531
Validation loss: 2.2268699357906976

Epoch: 5| Step: 10
Training loss: 1.7084060907363892
Validation loss: 2.212400734424591

Epoch: 5| Step: 11
Training loss: 3.1023097038269043
Validation loss: 2.2265385389328003

Epoch: 298| Step: 0
Training loss: 1.897315263748169
Validation loss: 2.228295221924782

Epoch: 5| Step: 1
Training loss: 1.7644582986831665
Validation loss: 2.2350283513466516

Epoch: 5| Step: 2
Training loss: 1.579486608505249
Validation loss: 2.2299233277638755

Epoch: 5| Step: 3
Training loss: 1.7205657958984375
Validation loss: 2.2441968520482383

Epoch: 5| Step: 4
Training loss: 1.6787822246551514
Validation loss: 2.2296368529399238

Epoch: 5| Step: 5
Training loss: 1.7058334350585938
Validation loss: 2.226096292336782

Epoch: 5| Step: 6
Training loss: 1.8864047527313232
Validation loss: 2.21635336180528

Epoch: 5| Step: 7
Training loss: 1.780625581741333
Validation loss: 2.218271737297376

Epoch: 5| Step: 8
Training loss: 1.9204639196395874
Validation loss: 2.2217193792263665

Epoch: 5| Step: 9
Training loss: 1.3892822265625
Validation loss: 2.2024478763341904

Epoch: 5| Step: 10
Training loss: 1.7973207235336304
Validation loss: 2.2347202003002167

Epoch: 5| Step: 11
Training loss: 1.955736756324768
Validation loss: 2.2332531809806824

Epoch: 299| Step: 0
Training loss: 1.4534305334091187
Validation loss: 2.2106345295906067

Epoch: 5| Step: 1
Training loss: 1.8561255931854248
Validation loss: 2.2306448270877204

Epoch: 5| Step: 2
Training loss: 1.6057058572769165
Validation loss: 2.2177502562602363

Epoch: 5| Step: 3
Training loss: 1.272451639175415
Validation loss: 2.206327090660731

Epoch: 5| Step: 4
Training loss: 1.4693827629089355
Validation loss: 2.2034454544385276

Epoch: 5| Step: 5
Training loss: 1.8625810146331787
Validation loss: 2.1925995349884033

Epoch: 5| Step: 6
Training loss: 2.50020170211792
Validation loss: 2.199224422375361

Epoch: 5| Step: 7
Training loss: 1.8983904123306274
Validation loss: 2.1826927910248437

Epoch: 5| Step: 8
Training loss: 2.1554548740386963
Validation loss: 2.1904515624046326

Epoch: 5| Step: 9
Training loss: 1.8734050989151
Validation loss: 2.191722313563029

Epoch: 5| Step: 10
Training loss: 1.6376888751983643
Validation loss: 2.186542809009552

Epoch: 5| Step: 11
Training loss: 1.3308494091033936
Validation loss: 2.199803257981936

Epoch: 300| Step: 0
Training loss: 1.405187964439392
Validation loss: 2.1883395463228226

Epoch: 5| Step: 1
Training loss: 2.192051410675049
Validation loss: 2.199681838353475

Epoch: 5| Step: 2
Training loss: 1.6513057947158813
Validation loss: 2.2024924556414285

Epoch: 5| Step: 3
Training loss: 1.400517225265503
Validation loss: 2.195998673637708

Epoch: 5| Step: 4
Training loss: 1.6657969951629639
Validation loss: 2.193169817328453

Epoch: 5| Step: 5
Training loss: 1.8753292560577393
Validation loss: 2.185058613618215

Epoch: 5| Step: 6
Training loss: 2.116945266723633
Validation loss: 2.193292021751404

Epoch: 5| Step: 7
Training loss: 1.7543926239013672
Validation loss: 2.194291040301323

Epoch: 5| Step: 8
Training loss: 1.4815306663513184
Validation loss: 2.1811523089806237

Epoch: 5| Step: 9
Training loss: 1.907265067100525
Validation loss: 2.1842550933361053

Epoch: 5| Step: 10
Training loss: 1.8018461465835571
Validation loss: 2.19684969385465

Epoch: 5| Step: 11
Training loss: 2.1486520767211914
Validation loss: 2.203756034374237

Testing loss: 1.8735261349369297
