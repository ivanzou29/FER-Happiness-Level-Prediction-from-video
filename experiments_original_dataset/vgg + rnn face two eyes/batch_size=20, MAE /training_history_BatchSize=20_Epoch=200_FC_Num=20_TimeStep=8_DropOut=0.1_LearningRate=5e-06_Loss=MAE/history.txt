Epoch: 1| Step: 0
Training loss: 5.81376838684082
Validation loss: 5.330282469590505

Epoch: 5| Step: 1
Training loss: 5.107349872589111
Validation loss: 5.328648726145427

Epoch: 5| Step: 2
Training loss: 4.705404281616211
Validation loss: 5.327069699764252

Epoch: 5| Step: 3
Training loss: 6.7994513511657715
Validation loss: 5.325562338034312

Epoch: 5| Step: 4
Training loss: 5.122132301330566
Validation loss: 5.324007173379262

Epoch: 5| Step: 5
Training loss: 5.190308094024658
Validation loss: 5.322568893432617

Epoch: 5| Step: 6
Training loss: 4.7205986976623535
Validation loss: 5.321049829324086

Epoch: 5| Step: 7
Training loss: 5.637726306915283
Validation loss: 5.31960388024648

Epoch: 5| Step: 8
Training loss: 5.541127681732178
Validation loss: 5.318173925081889

Epoch: 5| Step: 9
Training loss: 4.749729633331299
Validation loss: 5.316637655099233

Epoch: 5| Step: 10
Training loss: 5.889765739440918
Validation loss: 5.315172612667084

Epoch: 5| Step: 11
Training loss: 5.5254716873168945
Validation loss: 5.313537935415904

Epoch: 2| Step: 0
Training loss: 5.3700642585754395
Validation loss: 5.31193733215332

Epoch: 5| Step: 1
Training loss: 4.183801651000977
Validation loss: 5.310199518998464

Epoch: 5| Step: 2
Training loss: 5.379881858825684
Validation loss: 5.308509687582652

Epoch: 5| Step: 3
Training loss: 6.325435161590576
Validation loss: 5.306577384471893

Epoch: 5| Step: 4
Training loss: 5.801119804382324
Validation loss: 5.304623405138652

Epoch: 5| Step: 5
Training loss: 6.051813125610352
Validation loss: 5.302602767944336

Epoch: 5| Step: 6
Training loss: 5.271109580993652
Validation loss: 5.300392905871074

Epoch: 5| Step: 7
Training loss: 5.54567813873291
Validation loss: 5.29811676343282

Epoch: 5| Step: 8
Training loss: 5.300044059753418
Validation loss: 5.2957377632459

Epoch: 5| Step: 9
Training loss: 4.683547019958496
Validation loss: 5.293180227279663

Epoch: 5| Step: 10
Training loss: 5.029571533203125
Validation loss: 5.290508389472961

Epoch: 5| Step: 11
Training loss: 6.0537824630737305
Validation loss: 5.287712633609772

Epoch: 3| Step: 0
Training loss: 4.9616217613220215
Validation loss: 5.284786383310954

Epoch: 5| Step: 1
Training loss: 5.128312110900879
Validation loss: 5.281675577163696

Epoch: 5| Step: 2
Training loss: 4.4403910636901855
Validation loss: 5.278259476025899

Epoch: 5| Step: 3
Training loss: 6.220986366271973
Validation loss: 5.274701038996379

Epoch: 5| Step: 4
Training loss: 5.470782279968262
Validation loss: 5.2710062464078264

Epoch: 5| Step: 5
Training loss: 5.5894012451171875
Validation loss: 5.266988555590312

Epoch: 5| Step: 6
Training loss: 4.4271440505981445
Validation loss: 5.262803236643474

Epoch: 5| Step: 7
Training loss: 6.242688179016113
Validation loss: 5.258264760176341

Epoch: 5| Step: 8
Training loss: 5.138520240783691
Validation loss: 5.253628234068553

Epoch: 5| Step: 9
Training loss: 4.921504020690918
Validation loss: 5.248499075571696

Epoch: 5| Step: 10
Training loss: 5.672082424163818
Validation loss: 5.243360996246338

Epoch: 5| Step: 11
Training loss: 7.68964958190918
Validation loss: 5.237787067890167

Epoch: 4| Step: 0
Training loss: 5.719247817993164
Validation loss: 5.231821616490682

Epoch: 5| Step: 1
Training loss: 6.182489395141602
Validation loss: 5.2254553238550825

Epoch: 5| Step: 2
Training loss: 4.897676467895508
Validation loss: 5.219041883945465

Epoch: 5| Step: 3
Training loss: 4.190279483795166
Validation loss: 5.21212116877238

Epoch: 5| Step: 4
Training loss: 4.870263576507568
Validation loss: 5.204905370871226

Epoch: 5| Step: 5
Training loss: 5.840035438537598
Validation loss: 5.1973949273427325

Epoch: 5| Step: 6
Training loss: 4.936492443084717
Validation loss: 5.1895081003506975

Epoch: 5| Step: 7
Training loss: 6.221951484680176
Validation loss: 5.181305487950643

Epoch: 5| Step: 8
Training loss: 5.803728103637695
Validation loss: 5.17260483900706

Epoch: 5| Step: 9
Training loss: 5.016323566436768
Validation loss: 5.163488407929738

Epoch: 5| Step: 10
Training loss: 4.267734050750732
Validation loss: 5.154540101687114

Epoch: 5| Step: 11
Training loss: 5.157648086547852
Validation loss: 5.144536157449086

Epoch: 5| Step: 0
Training loss: 5.132755279541016
Validation loss: 5.134780605634053

Epoch: 5| Step: 1
Training loss: 4.653952598571777
Validation loss: 5.1247057517369585

Epoch: 5| Step: 2
Training loss: 4.366484642028809
Validation loss: 5.11420605580012

Epoch: 5| Step: 3
Training loss: 3.448359727859497
Validation loss: 5.103684524695079

Epoch: 5| Step: 4
Training loss: 5.486800193786621
Validation loss: 5.093045334021251

Epoch: 5| Step: 5
Training loss: 5.529688835144043
Validation loss: 5.0818937222162885

Epoch: 5| Step: 6
Training loss: 4.5962958335876465
Validation loss: 5.071005304654439

Epoch: 5| Step: 7
Training loss: 5.668022155761719
Validation loss: 5.060071428616841

Epoch: 5| Step: 8
Training loss: 5.710212230682373
Validation loss: 5.049051523208618

Epoch: 5| Step: 9
Training loss: 5.683526039123535
Validation loss: 5.037967463334401

Epoch: 5| Step: 10
Training loss: 6.555898189544678
Validation loss: 5.026803433895111

Epoch: 5| Step: 11
Training loss: 4.5813493728637695
Validation loss: 5.016292154788971

Epoch: 6| Step: 0
Training loss: 5.253386497497559
Validation loss: 5.005456109841664

Epoch: 5| Step: 1
Training loss: 4.353273868560791
Validation loss: 4.994338194529216

Epoch: 5| Step: 2
Training loss: 5.362919807434082
Validation loss: 4.984224081039429

Epoch: 5| Step: 3
Training loss: 4.542035102844238
Validation loss: 4.9737605055173235

Epoch: 5| Step: 4
Training loss: 5.029240608215332
Validation loss: 4.963660180568695

Epoch: 5| Step: 5
Training loss: 5.937470436096191
Validation loss: 4.953531314929326

Epoch: 5| Step: 6
Training loss: 5.483300685882568
Validation loss: 4.943317115306854

Epoch: 5| Step: 7
Training loss: 5.055660247802734
Validation loss: 4.933529953161876

Epoch: 5| Step: 8
Training loss: 5.407889366149902
Validation loss: 4.92355614900589

Epoch: 5| Step: 9
Training loss: 5.075891017913818
Validation loss: 4.914125104745229

Epoch: 5| Step: 10
Training loss: 4.28116512298584
Validation loss: 4.905202507972717

Epoch: 5| Step: 11
Training loss: 3.1054182052612305
Validation loss: 4.896498739719391

Epoch: 7| Step: 0
Training loss: 6.0728373527526855
Validation loss: 4.887977818648021

Epoch: 5| Step: 1
Training loss: 5.567625522613525
Validation loss: 4.8797237277030945

Epoch: 5| Step: 2
Training loss: 4.658404350280762
Validation loss: 4.871474941571553

Epoch: 5| Step: 3
Training loss: 4.814896583557129
Validation loss: 4.863149921099345

Epoch: 5| Step: 4
Training loss: 4.455656051635742
Validation loss: 4.854763388633728

Epoch: 5| Step: 5
Training loss: 4.878584861755371
Validation loss: 4.8465956052144366

Epoch: 5| Step: 6
Training loss: 5.237191200256348
Validation loss: 4.838730216026306

Epoch: 5| Step: 7
Training loss: 4.070389270782471
Validation loss: 4.830793837706248

Epoch: 5| Step: 8
Training loss: 5.129047870635986
Validation loss: 4.82324876387914

Epoch: 5| Step: 9
Training loss: 5.027968406677246
Validation loss: 4.815745075543721

Epoch: 5| Step: 10
Training loss: 4.107312202453613
Validation loss: 4.808423896630605

Epoch: 5| Step: 11
Training loss: 6.240607261657715
Validation loss: 4.801510155200958

Epoch: 8| Step: 0
Training loss: 4.568503379821777
Validation loss: 4.794693311055501

Epoch: 5| Step: 1
Training loss: 4.290522575378418
Validation loss: 4.78711199760437

Epoch: 5| Step: 2
Training loss: 5.097867965698242
Validation loss: 4.780685464541118

Epoch: 5| Step: 3
Training loss: 4.846508979797363
Validation loss: 4.773834645748138

Epoch: 5| Step: 4
Training loss: 4.757081985473633
Validation loss: 4.766731361548106

Epoch: 5| Step: 5
Training loss: 4.672192573547363
Validation loss: 4.759880314270656

Epoch: 5| Step: 6
Training loss: 4.906123161315918
Validation loss: 4.753304421901703

Epoch: 5| Step: 7
Training loss: 4.128037929534912
Validation loss: 4.7460552255312605

Epoch: 5| Step: 8
Training loss: 4.351410865783691
Validation loss: 4.739490667978923

Epoch: 5| Step: 9
Training loss: 5.998597621917725
Validation loss: 4.732767780621846

Epoch: 5| Step: 10
Training loss: 6.131841659545898
Validation loss: 4.726470073064168

Epoch: 5| Step: 11
Training loss: 2.790558338165283
Validation loss: 4.719758083422978

Epoch: 9| Step: 0
Training loss: 4.673450469970703
Validation loss: 4.713171809911728

Epoch: 5| Step: 1
Training loss: 4.979154109954834
Validation loss: 4.706674416859944

Epoch: 5| Step: 2
Training loss: 5.1103925704956055
Validation loss: 4.699922641118367

Epoch: 5| Step: 3
Training loss: 3.8714423179626465
Validation loss: 4.693638304869334

Epoch: 5| Step: 4
Training loss: 4.410516262054443
Validation loss: 4.686940987904866

Epoch: 5| Step: 5
Training loss: 5.764060974121094
Validation loss: 4.680512348810832

Epoch: 5| Step: 6
Training loss: 5.731093406677246
Validation loss: 4.674298981825511

Epoch: 5| Step: 7
Training loss: 4.854772090911865
Validation loss: 4.66814402739207

Epoch: 5| Step: 8
Training loss: 4.390809535980225
Validation loss: 4.661501745382945

Epoch: 5| Step: 9
Training loss: 5.200328350067139
Validation loss: 4.655351022879283

Epoch: 5| Step: 10
Training loss: 3.874253034591675
Validation loss: 4.649219711621602

Epoch: 5| Step: 11
Training loss: 3.153611421585083
Validation loss: 4.6431194345156355

Epoch: 10| Step: 0
Training loss: 4.891779899597168
Validation loss: 4.6371137499809265

Epoch: 5| Step: 1
Training loss: 4.665294170379639
Validation loss: 4.6317116022109985

Epoch: 5| Step: 2
Training loss: 5.03875207901001
Validation loss: 4.625602761904399

Epoch: 5| Step: 3
Training loss: 5.349581241607666
Validation loss: 4.61920952796936

Epoch: 5| Step: 4
Training loss: 4.118067741394043
Validation loss: 4.613121569156647

Epoch: 5| Step: 5
Training loss: 4.827699184417725
Validation loss: 4.607141117254893

Epoch: 5| Step: 6
Training loss: 4.509970188140869
Validation loss: 4.6008519033590956

Epoch: 5| Step: 7
Training loss: 5.053675651550293
Validation loss: 4.594640552997589

Epoch: 5| Step: 8
Training loss: 4.3036980628967285
Validation loss: 4.588760673999786

Epoch: 5| Step: 9
Training loss: 4.800812244415283
Validation loss: 4.582662562529246

Epoch: 5| Step: 10
Training loss: 4.270486831665039
Validation loss: 4.576601982116699

Epoch: 5| Step: 11
Training loss: 4.361649513244629
Validation loss: 4.570877234141032

Epoch: 11| Step: 0
Training loss: 4.878378868103027
Validation loss: 4.564253568649292

Epoch: 5| Step: 1
Training loss: 4.558283805847168
Validation loss: 4.558442413806915

Epoch: 5| Step: 2
Training loss: 4.846298694610596
Validation loss: 4.552027463912964

Epoch: 5| Step: 3
Training loss: 5.130345821380615
Validation loss: 4.546576182047526

Epoch: 5| Step: 4
Training loss: 4.544112205505371
Validation loss: 4.540088891983032

Epoch: 5| Step: 5
Training loss: 4.706132411956787
Validation loss: 4.533853352069855

Epoch: 5| Step: 6
Training loss: 4.4763407707214355
Validation loss: 4.527320583661397

Epoch: 5| Step: 7
Training loss: 4.707212924957275
Validation loss: 4.521067818005879

Epoch: 5| Step: 8
Training loss: 3.82344126701355
Validation loss: 4.515223165353139

Epoch: 5| Step: 9
Training loss: 4.6064863204956055
Validation loss: 4.508953253428142

Epoch: 5| Step: 10
Training loss: 4.816951751708984
Validation loss: 4.502734879652659

Epoch: 5| Step: 11
Training loss: 4.200932502746582
Validation loss: 4.4965446790059405

Epoch: 12| Step: 0
Training loss: 4.51937198638916
Validation loss: 4.491041302680969

Epoch: 5| Step: 1
Training loss: 5.054186820983887
Validation loss: 4.485892633597056

Epoch: 5| Step: 2
Training loss: 3.3346495628356934
Validation loss: 4.479448467493057

Epoch: 5| Step: 3
Training loss: 4.891470909118652
Validation loss: 4.473297715187073

Epoch: 5| Step: 4
Training loss: 4.447009563446045
Validation loss: 4.468055744965871

Epoch: 5| Step: 5
Training loss: 5.174019813537598
Validation loss: 4.461443702379863

Epoch: 5| Step: 6
Training loss: 4.340635776519775
Validation loss: 4.455577929814656

Epoch: 5| Step: 7
Training loss: 5.0389909744262695
Validation loss: 4.4493245879809065

Epoch: 5| Step: 8
Training loss: 4.791145324707031
Validation loss: 4.442313194274902

Epoch: 5| Step: 9
Training loss: 4.664806365966797
Validation loss: 4.4367408355077105

Epoch: 5| Step: 10
Training loss: 4.179402828216553
Validation loss: 4.430823306242625

Epoch: 5| Step: 11
Training loss: 3.774233341217041
Validation loss: 4.42511373758316

Epoch: 13| Step: 0
Training loss: 5.3451032638549805
Validation loss: 4.418397317330043

Epoch: 5| Step: 1
Training loss: 4.647183895111084
Validation loss: 4.411820590496063

Epoch: 5| Step: 2
Training loss: 4.737748146057129
Validation loss: 4.405736168225606

Epoch: 5| Step: 3
Training loss: 4.674748420715332
Validation loss: 4.399965673685074

Epoch: 5| Step: 4
Training loss: 4.168145179748535
Validation loss: 4.393516143163045

Epoch: 5| Step: 5
Training loss: 4.3530402183532715
Validation loss: 4.3868401547273

Epoch: 5| Step: 6
Training loss: 4.038615703582764
Validation loss: 4.381109297275543

Epoch: 5| Step: 7
Training loss: 3.9616684913635254
Validation loss: 4.374992291132609

Epoch: 5| Step: 8
Training loss: 4.382726669311523
Validation loss: 4.369374563296636

Epoch: 5| Step: 9
Training loss: 4.460294246673584
Validation loss: 4.363313873608907

Epoch: 5| Step: 10
Training loss: 4.438996315002441
Validation loss: 4.357470850149791

Epoch: 5| Step: 11
Training loss: 6.255649089813232
Validation loss: 4.35223467151324

Epoch: 14| Step: 0
Training loss: 4.7347307205200195
Validation loss: 4.346650868654251

Epoch: 5| Step: 1
Training loss: 4.749340057373047
Validation loss: 4.340454190969467

Epoch: 5| Step: 2
Training loss: 3.94963002204895
Validation loss: 4.33450190226237

Epoch: 5| Step: 3
Training loss: 4.381839752197266
Validation loss: 4.328992774089177

Epoch: 5| Step: 4
Training loss: 4.491477966308594
Validation loss: 4.323063552379608

Epoch: 5| Step: 5
Training loss: 4.095089912414551
Validation loss: 4.317938764890035

Epoch: 5| Step: 6
Training loss: 5.352567195892334
Validation loss: 4.3123739361763

Epoch: 5| Step: 7
Training loss: 3.4347636699676514
Validation loss: 4.30634934703509

Epoch: 5| Step: 8
Training loss: 4.417351722717285
Validation loss: 4.300726483265559

Epoch: 5| Step: 9
Training loss: 4.756999492645264
Validation loss: 4.295473476250966

Epoch: 5| Step: 10
Training loss: 4.191961765289307
Validation loss: 4.289767285188039

Epoch: 5| Step: 11
Training loss: 5.933244705200195
Validation loss: 4.283931175867717

Epoch: 15| Step: 0
Training loss: 3.873929977416992
Validation loss: 4.278639763593674

Epoch: 5| Step: 1
Training loss: 3.8863067626953125
Validation loss: 4.27275816599528

Epoch: 5| Step: 2
Training loss: 4.379141330718994
Validation loss: 4.267391016085942

Epoch: 5| Step: 3
Training loss: 4.722434997558594
Validation loss: 4.261018057664235

Epoch: 5| Step: 4
Training loss: 4.389332294464111
Validation loss: 4.256281654040019

Epoch: 5| Step: 5
Training loss: 4.545809268951416
Validation loss: 4.251777738332748

Epoch: 5| Step: 6
Training loss: 4.840316295623779
Validation loss: 4.244936615228653

Epoch: 5| Step: 7
Training loss: 3.9319255352020264
Validation loss: 4.238485087951024

Epoch: 5| Step: 8
Training loss: 4.595610618591309
Validation loss: 4.232731809218724

Epoch: 5| Step: 9
Training loss: 3.972959041595459
Validation loss: 4.226856221755345

Epoch: 5| Step: 10
Training loss: 4.871029853820801
Validation loss: 4.221581041812897

Epoch: 5| Step: 11
Training loss: 5.119714736938477
Validation loss: 4.215418954690297

Epoch: 16| Step: 0
Training loss: 4.5484619140625
Validation loss: 4.209977010885875

Epoch: 5| Step: 1
Training loss: 3.746476650238037
Validation loss: 4.202818711598714

Epoch: 5| Step: 2
Training loss: 4.652817726135254
Validation loss: 4.198541323343913

Epoch: 5| Step: 3
Training loss: 4.128615379333496
Validation loss: 4.19402947028478

Epoch: 5| Step: 4
Training loss: 4.586438179016113
Validation loss: 4.188497523466746

Epoch: 5| Step: 5
Training loss: 5.007000923156738
Validation loss: 4.182782640059789

Epoch: 5| Step: 6
Training loss: 3.664060592651367
Validation loss: 4.176457951466243

Epoch: 5| Step: 7
Training loss: 4.0932512283325195
Validation loss: 4.1719979246457415

Epoch: 5| Step: 8
Training loss: 5.1088480949401855
Validation loss: 4.166221708059311

Epoch: 5| Step: 9
Training loss: 4.131087779998779
Validation loss: 4.160929401715596

Epoch: 5| Step: 10
Training loss: 4.147855281829834
Validation loss: 4.1558528045813246

Epoch: 5| Step: 11
Training loss: 2.6547553539276123
Validation loss: 4.150082568327586

Epoch: 17| Step: 0
Training loss: 4.250676155090332
Validation loss: 4.144340167442958

Epoch: 5| Step: 1
Training loss: 4.652161598205566
Validation loss: 4.139728466669719

Epoch: 5| Step: 2
Training loss: 4.900553226470947
Validation loss: 4.133595546086629

Epoch: 5| Step: 3
Training loss: 4.394543170928955
Validation loss: 4.128855288028717

Epoch: 5| Step: 4
Training loss: 4.110907554626465
Validation loss: 4.12348226706187

Epoch: 5| Step: 5
Training loss: 4.286055564880371
Validation loss: 4.118418991565704

Epoch: 5| Step: 6
Training loss: 3.710484266281128
Validation loss: 4.113711506128311

Epoch: 5| Step: 7
Training loss: 4.936575889587402
Validation loss: 4.107963015635808

Epoch: 5| Step: 8
Training loss: 3.9665749073028564
Validation loss: 4.102433135112126

Epoch: 5| Step: 9
Training loss: 4.109421730041504
Validation loss: 4.097514132658641

Epoch: 5| Step: 10
Training loss: 3.4430179595947266
Validation loss: 4.092902660369873

Epoch: 5| Step: 11
Training loss: 4.777817726135254
Validation loss: 4.088465660810471

Epoch: 18| Step: 0
Training loss: 4.081043243408203
Validation loss: 4.08339735865593

Epoch: 5| Step: 1
Training loss: 4.418420314788818
Validation loss: 4.077837606271108

Epoch: 5| Step: 2
Training loss: 3.9534401893615723
Validation loss: 4.072713732719421

Epoch: 5| Step: 3
Training loss: 4.635976314544678
Validation loss: 4.068671733140945

Epoch: 5| Step: 4
Training loss: 3.558612823486328
Validation loss: 4.06364032626152

Epoch: 5| Step: 5
Training loss: 4.4087300300598145
Validation loss: 4.0578795075416565

Epoch: 5| Step: 6
Training loss: 4.354351997375488
Validation loss: 4.053929686546326

Epoch: 5| Step: 7
Training loss: 4.231095790863037
Validation loss: 4.048047840595245

Epoch: 5| Step: 8
Training loss: 4.479381561279297
Validation loss: 4.04324824611346

Epoch: 5| Step: 9
Training loss: 4.553958892822266
Validation loss: 4.038346370061238

Epoch: 5| Step: 10
Training loss: 3.5494492053985596
Validation loss: 4.033234457174937

Epoch: 5| Step: 11
Training loss: 4.126501560211182
Validation loss: 4.028287251790364

Epoch: 19| Step: 0
Training loss: 4.27114200592041
Validation loss: 4.023030112187068

Epoch: 5| Step: 1
Training loss: 4.531759738922119
Validation loss: 4.018629461526871

Epoch: 5| Step: 2
Training loss: 3.5955100059509277
Validation loss: 4.013546993335088

Epoch: 5| Step: 3
Training loss: 4.4189772605896
Validation loss: 4.008430550495784

Epoch: 5| Step: 4
Training loss: 3.9167792797088623
Validation loss: 4.004077027241389

Epoch: 5| Step: 5
Training loss: 3.8423194885253906
Validation loss: 3.9992970128854117

Epoch: 5| Step: 6
Training loss: 4.587649345397949
Validation loss: 3.9940964678923288

Epoch: 5| Step: 7
Training loss: 4.964069366455078
Validation loss: 3.989572117726008

Epoch: 5| Step: 8
Training loss: 3.9955132007598877
Validation loss: 3.9851061503092446

Epoch: 5| Step: 9
Training loss: 3.365216016769409
Validation loss: 3.9794167280197144

Epoch: 5| Step: 10
Training loss: 3.7232699394226074
Validation loss: 3.9742853343486786

Epoch: 5| Step: 11
Training loss: 6.00540828704834
Validation loss: 3.9692614376544952

Epoch: 20| Step: 0
Training loss: 3.776371717453003
Validation loss: 3.9652608732382455

Epoch: 5| Step: 1
Training loss: 4.641705513000488
Validation loss: 3.9591336051623025

Epoch: 5| Step: 2
Training loss: 4.026077747344971
Validation loss: 3.954363524913788

Epoch: 5| Step: 3
Training loss: 4.789078712463379
Validation loss: 3.949380318323771

Epoch: 5| Step: 4
Training loss: 3.887253999710083
Validation loss: 3.9468355576197305

Epoch: 5| Step: 5
Training loss: 4.559075832366943
Validation loss: 3.9399933417638144

Epoch: 5| Step: 6
Training loss: 3.802438259124756
Validation loss: 3.9347010354200997

Epoch: 5| Step: 7
Training loss: 3.496828556060791
Validation loss: 3.930767556031545

Epoch: 5| Step: 8
Training loss: 3.407055616378784
Validation loss: 3.925778845945994

Epoch: 5| Step: 9
Training loss: 4.30450439453125
Validation loss: 3.921141187349955

Epoch: 5| Step: 10
Training loss: 4.515872001647949
Validation loss: 3.915991226832072

Epoch: 5| Step: 11
Training loss: 2.8766672611236572
Validation loss: 3.9112842679023743

Epoch: 21| Step: 0
Training loss: 4.207353115081787
Validation loss: 3.906090021133423

Epoch: 5| Step: 1
Training loss: 4.450333595275879
Validation loss: 3.901327242453893

Epoch: 5| Step: 2
Training loss: 4.442193508148193
Validation loss: 3.8960549533367157

Epoch: 5| Step: 3
Training loss: 4.661803245544434
Validation loss: 3.8919006983439126

Epoch: 5| Step: 4
Training loss: 3.421365261077881
Validation loss: 3.88545885682106

Epoch: 5| Step: 5
Training loss: 4.1849446296691895
Validation loss: 3.8821561336517334

Epoch: 5| Step: 6
Training loss: 3.4452767372131348
Validation loss: 3.8761840164661407

Epoch: 5| Step: 7
Training loss: 4.513333320617676
Validation loss: 3.872639705737432

Epoch: 5| Step: 8
Training loss: 3.863079786300659
Validation loss: 3.8675370514392853

Epoch: 5| Step: 9
Training loss: 3.7291717529296875
Validation loss: 3.8640988866488137

Epoch: 5| Step: 10
Training loss: 3.693910598754883
Validation loss: 3.859990874926249

Epoch: 5| Step: 11
Training loss: 2.8715429306030273
Validation loss: 3.855873395999273

Epoch: 22| Step: 0
Training loss: 4.660135746002197
Validation loss: 3.8505409757296243

Epoch: 5| Step: 1
Training loss: 3.0391452312469482
Validation loss: 3.847698916991552

Epoch: 5| Step: 2
Training loss: 4.740323066711426
Validation loss: 3.8462626238663993

Epoch: 5| Step: 3
Training loss: 2.3708319664001465
Validation loss: 3.842738151550293

Epoch: 5| Step: 4
Training loss: 4.258472442626953
Validation loss: 3.839778999487559

Epoch: 5| Step: 5
Training loss: 4.500561237335205
Validation loss: 3.8351513346036277

Epoch: 5| Step: 6
Training loss: 4.211446285247803
Validation loss: 3.828085700670878

Epoch: 5| Step: 7
Training loss: 4.283907890319824
Validation loss: 3.8212886651357016

Epoch: 5| Step: 8
Training loss: 3.8068649768829346
Validation loss: 3.8163427114486694

Epoch: 5| Step: 9
Training loss: 3.4280998706817627
Validation loss: 3.812078058719635

Epoch: 5| Step: 10
Training loss: 4.664134979248047
Validation loss: 3.808572789033254

Epoch: 5| Step: 11
Training loss: 3.3553662300109863
Validation loss: 3.804355094830195

Epoch: 23| Step: 0
Training loss: 3.881763458251953
Validation loss: 3.8013918101787567

Epoch: 5| Step: 1
Training loss: 3.7736454010009766
Validation loss: 3.794648359219233

Epoch: 5| Step: 2
Training loss: 3.6325721740722656
Validation loss: 3.789029667774836

Epoch: 5| Step: 3
Training loss: 3.9256751537323
Validation loss: 3.7844267984231315

Epoch: 5| Step: 4
Training loss: 3.9075958728790283
Validation loss: 3.7798836628595986

Epoch: 5| Step: 5
Training loss: 4.800662040710449
Validation loss: 3.7743493914604187

Epoch: 5| Step: 6
Training loss: 3.2056641578674316
Validation loss: 3.769085834423701

Epoch: 5| Step: 7
Training loss: 3.7226524353027344
Validation loss: 3.764019181330999

Epoch: 5| Step: 8
Training loss: 4.7637152671813965
Validation loss: 3.7591311732927957

Epoch: 5| Step: 9
Training loss: 3.6464664936065674
Validation loss: 3.7547933558622995

Epoch: 5| Step: 10
Training loss: 4.201478004455566
Validation loss: 3.750257114569346

Epoch: 5| Step: 11
Training loss: 2.8028769493103027
Validation loss: 3.7449632485707602

Epoch: 24| Step: 0
Training loss: 3.5743701457977295
Validation loss: 3.739978472391764

Epoch: 5| Step: 1
Training loss: 3.968569278717041
Validation loss: 3.734760453303655

Epoch: 5| Step: 2
Training loss: 3.6875839233398438
Validation loss: 3.7308875918388367

Epoch: 5| Step: 3
Training loss: 3.760773181915283
Validation loss: 3.7265868882338204

Epoch: 5| Step: 4
Training loss: 4.289385795593262
Validation loss: 3.720868080854416

Epoch: 5| Step: 5
Training loss: 3.948378086090088
Validation loss: 3.7171090245246887

Epoch: 5| Step: 6
Training loss: 2.9161903858184814
Validation loss: 3.711263428131739

Epoch: 5| Step: 7
Training loss: 3.976879119873047
Validation loss: 3.7074103554089866

Epoch: 5| Step: 8
Training loss: 4.296008110046387
Validation loss: 3.702380806207657

Epoch: 5| Step: 9
Training loss: 4.393485069274902
Validation loss: 3.697832614183426

Epoch: 5| Step: 10
Training loss: 3.5077500343322754
Validation loss: 3.6931203603744507

Epoch: 5| Step: 11
Training loss: 5.482431411743164
Validation loss: 3.688313285509745

Epoch: 25| Step: 0
Training loss: 4.290555000305176
Validation loss: 3.6841085155804953

Epoch: 5| Step: 1
Training loss: 3.6545214653015137
Validation loss: 3.6792049606641135

Epoch: 5| Step: 2
Training loss: 3.9745097160339355
Validation loss: 3.6743007798989615

Epoch: 5| Step: 3
Training loss: 4.030018329620361
Validation loss: 3.6689213116963706

Epoch: 5| Step: 4
Training loss: 3.656806230545044
Validation loss: 3.665009707212448

Epoch: 5| Step: 5
Training loss: 3.623332977294922
Validation loss: 3.6605327824751535

Epoch: 5| Step: 6
Training loss: 2.6247270107269287
Validation loss: 3.656059443950653

Epoch: 5| Step: 7
Training loss: 4.434976100921631
Validation loss: 3.650713642438253

Epoch: 5| Step: 8
Training loss: 3.9972362518310547
Validation loss: 3.645617534716924

Epoch: 5| Step: 9
Training loss: 3.6995582580566406
Validation loss: 3.640692879756292

Epoch: 5| Step: 10
Training loss: 3.649580478668213
Validation loss: 3.6358346045017242

Epoch: 5| Step: 11
Training loss: 5.876174449920654
Validation loss: 3.631131947040558

Epoch: 26| Step: 0
Training loss: 3.8102619647979736
Validation loss: 3.6257345378398895

Epoch: 5| Step: 1
Training loss: 3.1542296409606934
Validation loss: 3.619768182436625

Epoch: 5| Step: 2
Training loss: 3.3188705444335938
Validation loss: 3.6164538264274597

Epoch: 5| Step: 3
Training loss: 3.74609637260437
Validation loss: 3.6113862494627633

Epoch: 5| Step: 4
Training loss: 3.6524276733398438
Validation loss: 3.6070725321769714

Epoch: 5| Step: 5
Training loss: 4.427346706390381
Validation loss: 3.601918250322342

Epoch: 5| Step: 6
Training loss: 3.454930543899536
Validation loss: 3.596228172381719

Epoch: 5| Step: 7
Training loss: 4.772757530212402
Validation loss: 3.5918314357598624

Epoch: 5| Step: 8
Training loss: 3.869002103805542
Validation loss: 3.5869220991929374

Epoch: 5| Step: 9
Training loss: 3.8775832653045654
Validation loss: 3.581297089656194

Epoch: 5| Step: 10
Training loss: 3.6208178997039795
Validation loss: 3.575900544722875

Epoch: 5| Step: 11
Training loss: 2.181837797164917
Validation loss: 3.5707535445690155

Epoch: 27| Step: 0
Training loss: 3.168400526046753
Validation loss: 3.566234072049459

Epoch: 5| Step: 1
Training loss: 3.332183837890625
Validation loss: 3.5607629219690957

Epoch: 5| Step: 2
Training loss: 4.615697860717773
Validation loss: 3.5561197300752005

Epoch: 5| Step: 3
Training loss: 4.649270057678223
Validation loss: 3.550387571255366

Epoch: 5| Step: 4
Training loss: 4.028652191162109
Validation loss: 3.5451600750287375

Epoch: 5| Step: 5
Training loss: 3.3576622009277344
Validation loss: 3.54111577073733

Epoch: 5| Step: 6
Training loss: 3.2805190086364746
Validation loss: 3.534971604744593

Epoch: 5| Step: 7
Training loss: 2.6597883701324463
Validation loss: 3.530961891015371

Epoch: 5| Step: 8
Training loss: 3.6987080574035645
Validation loss: 3.524773508310318

Epoch: 5| Step: 9
Training loss: 4.364563941955566
Validation loss: 3.5197232961654663

Epoch: 5| Step: 10
Training loss: 3.669947862625122
Validation loss: 3.5147595405578613

Epoch: 5| Step: 11
Training loss: 3.3951518535614014
Validation loss: 3.509644736846288

Epoch: 28| Step: 0
Training loss: 3.2817420959472656
Validation loss: 3.5056063135464988

Epoch: 5| Step: 1
Training loss: 3.3067126274108887
Validation loss: 3.4996537069479623

Epoch: 5| Step: 2
Training loss: 4.218964576721191
Validation loss: 3.495510677496592

Epoch: 5| Step: 3
Training loss: 3.611927032470703
Validation loss: 3.4912734230359397

Epoch: 5| Step: 4
Training loss: 3.0627901554107666
Validation loss: 3.4864271680514016

Epoch: 5| Step: 5
Training loss: 3.5019378662109375
Validation loss: 3.4822527368863425

Epoch: 5| Step: 6
Training loss: 4.067537784576416
Validation loss: 3.476472099622091

Epoch: 5| Step: 7
Training loss: 3.006377696990967
Validation loss: 3.4714718659718833

Epoch: 5| Step: 8
Training loss: 3.347363233566284
Validation loss: 3.46686989068985

Epoch: 5| Step: 9
Training loss: 4.396814823150635
Validation loss: 3.4619423349698386

Epoch: 5| Step: 10
Training loss: 4.237917423248291
Validation loss: 3.456827074289322

Epoch: 5| Step: 11
Training loss: 4.077326774597168
Validation loss: 3.452228138844172

Epoch: 29| Step: 0
Training loss: 3.8392701148986816
Validation loss: 3.447734773159027

Epoch: 5| Step: 1
Training loss: 3.238600254058838
Validation loss: 3.442465752363205

Epoch: 5| Step: 2
Training loss: 4.567968845367432
Validation loss: 3.4375261863072715

Epoch: 5| Step: 3
Training loss: 2.928583860397339
Validation loss: 3.4329505960146585

Epoch: 5| Step: 4
Training loss: 4.313573360443115
Validation loss: 3.4282880624135337

Epoch: 5| Step: 5
Training loss: 3.2399380207061768
Validation loss: 3.4235240717728934

Epoch: 5| Step: 6
Training loss: 3.9271671772003174
Validation loss: 3.418496568997701

Epoch: 5| Step: 7
Training loss: 3.315065383911133
Validation loss: 3.414107541243235

Epoch: 5| Step: 8
Training loss: 3.4121127128601074
Validation loss: 3.4093936483065286

Epoch: 5| Step: 9
Training loss: 3.8694605827331543
Validation loss: 3.404988487561544

Epoch: 5| Step: 10
Training loss: 2.8850197792053223
Validation loss: 3.4002484182516732

Epoch: 5| Step: 11
Training loss: 3.409308433532715
Validation loss: 3.396058221658071

Epoch: 30| Step: 0
Training loss: 3.7540931701660156
Validation loss: 3.3909975787003837

Epoch: 5| Step: 1
Training loss: 4.245176315307617
Validation loss: 3.386209706465403

Epoch: 5| Step: 2
Training loss: 3.062228202819824
Validation loss: 3.3814115623633065

Epoch: 5| Step: 3
Training loss: 3.0740342140197754
Validation loss: 3.377283821503321

Epoch: 5| Step: 4
Training loss: 3.7148940563201904
Validation loss: 3.372988114754359

Epoch: 5| Step: 5
Training loss: 4.218701362609863
Validation loss: 3.3679953118165336

Epoch: 5| Step: 6
Training loss: 3.022266149520874
Validation loss: 3.362976332505544

Epoch: 5| Step: 7
Training loss: 3.877650499343872
Validation loss: 3.357313483953476

Epoch: 5| Step: 8
Training loss: 3.6947944164276123
Validation loss: 3.352938155333201

Epoch: 5| Step: 9
Training loss: 3.581183671951294
Validation loss: 3.348312815030416

Epoch: 5| Step: 10
Training loss: 2.9855263233184814
Validation loss: 3.343123346567154

Epoch: 5| Step: 11
Training loss: 1.932789921760559
Validation loss: 3.338658094406128

Epoch: 31| Step: 0
Training loss: 3.157320976257324
Validation loss: 3.333889106909434

Epoch: 5| Step: 1
Training loss: 4.0602192878723145
Validation loss: 3.3290752271811166

Epoch: 5| Step: 2
Training loss: 3.762359619140625
Validation loss: 3.3252870440483093

Epoch: 5| Step: 3
Training loss: 3.0448622703552246
Validation loss: 3.320542256037394

Epoch: 5| Step: 4
Training loss: 2.8622658252716064
Validation loss: 3.316746940215429

Epoch: 5| Step: 5
Training loss: 3.3253417015075684
Validation loss: 3.3120012084643045

Epoch: 5| Step: 6
Training loss: 4.103346824645996
Validation loss: 3.3071989913781485

Epoch: 5| Step: 7
Training loss: 4.514046669006348
Validation loss: 3.302279363075892

Epoch: 5| Step: 8
Training loss: 3.40675687789917
Validation loss: 3.2979549765586853

Epoch: 5| Step: 9
Training loss: 3.5540060997009277
Validation loss: 3.293398857116699

Epoch: 5| Step: 10
Training loss: 2.8415656089782715
Validation loss: 3.2872315843900046

Epoch: 5| Step: 11
Training loss: 1.9357290267944336
Validation loss: 3.2813513576984406

Epoch: 32| Step: 0
Training loss: 3.6413676738739014
Validation loss: 3.2761181394259133

Epoch: 5| Step: 1
Training loss: 3.1120259761810303
Validation loss: 3.27105051279068

Epoch: 5| Step: 2
Training loss: 3.159318208694458
Validation loss: 3.265611340602239

Epoch: 5| Step: 3
Training loss: 3.235427141189575
Validation loss: 3.2604215244452157

Epoch: 5| Step: 4
Training loss: 3.0338892936706543
Validation loss: 3.254906048377355

Epoch: 5| Step: 5
Training loss: 2.7006897926330566
Validation loss: 3.2510753671328225

Epoch: 5| Step: 6
Training loss: 3.610417127609253
Validation loss: 3.2460751831531525

Epoch: 5| Step: 7
Training loss: 4.461799621582031
Validation loss: 3.242088943719864

Epoch: 5| Step: 8
Training loss: 2.998446464538574
Validation loss: 3.23636061946551

Epoch: 5| Step: 9
Training loss: 3.633392333984375
Validation loss: 3.231495976448059

Epoch: 5| Step: 10
Training loss: 3.7965266704559326
Validation loss: 3.225993643204371

Epoch: 5| Step: 11
Training loss: 4.98167085647583
Validation loss: 3.2218386828899384

Epoch: 33| Step: 0
Training loss: 3.3572468757629395
Validation loss: 3.2172552247842154

Epoch: 5| Step: 1
Training loss: 3.897956132888794
Validation loss: 3.212126503388087

Epoch: 5| Step: 2
Training loss: 3.9885780811309814
Validation loss: 3.2104165156682334

Epoch: 5| Step: 3
Training loss: 3.32035756111145
Validation loss: 3.2032688160737357

Epoch: 5| Step: 4
Training loss: 3.5267837047576904
Validation loss: 3.1970771749814353

Epoch: 5| Step: 5
Training loss: 3.098268747329712
Validation loss: 3.1928023596604667

Epoch: 5| Step: 6
Training loss: 3.6217856407165527
Validation loss: 3.187081277370453

Epoch: 5| Step: 7
Training loss: 3.292055606842041
Validation loss: 3.182459980249405

Epoch: 5| Step: 8
Training loss: 2.259197235107422
Validation loss: 3.1774700383345285

Epoch: 5| Step: 9
Training loss: 3.699209690093994
Validation loss: 3.172878215710322

Epoch: 5| Step: 10
Training loss: 2.7199907302856445
Validation loss: 3.169009973605474

Epoch: 5| Step: 11
Training loss: 5.130303382873535
Validation loss: 3.16479355096817

Epoch: 34| Step: 0
Training loss: 2.927402973175049
Validation loss: 3.1603970925013223

Epoch: 5| Step: 1
Training loss: 3.753936767578125
Validation loss: 3.156184355417887

Epoch: 5| Step: 2
Training loss: 2.7031211853027344
Validation loss: 3.1508382856845856

Epoch: 5| Step: 3
Training loss: 3.308039903640747
Validation loss: 3.1465151806672416

Epoch: 5| Step: 4
Training loss: 3.8308799266815186
Validation loss: 3.141925851504008

Epoch: 5| Step: 5
Training loss: 3.600484848022461
Validation loss: 3.1381655732790628

Epoch: 5| Step: 6
Training loss: 2.8191521167755127
Validation loss: 3.1333749194939933

Epoch: 5| Step: 7
Training loss: 3.800457715988159
Validation loss: 3.1284307142098746

Epoch: 5| Step: 8
Training loss: 3.010544538497925
Validation loss: 3.1235901415348053

Epoch: 5| Step: 9
Training loss: 3.4722366333007812
Validation loss: 3.119362344344457

Epoch: 5| Step: 10
Training loss: 3.2165865898132324
Validation loss: 3.1145120362440744

Epoch: 5| Step: 11
Training loss: 3.878781318664551
Validation loss: 3.1111832658449807

Epoch: 35| Step: 0
Training loss: 4.367951393127441
Validation loss: 3.10652893781662

Epoch: 5| Step: 1
Training loss: 2.908231258392334
Validation loss: 3.1026469568411508

Epoch: 5| Step: 2
Training loss: 2.8615753650665283
Validation loss: 3.0986409982045493

Epoch: 5| Step: 3
Training loss: 4.247198581695557
Validation loss: 3.094854772090912

Epoch: 5| Step: 4
Training loss: 3.7010369300842285
Validation loss: 3.0899553100268045

Epoch: 5| Step: 5
Training loss: 3.513404130935669
Validation loss: 3.085922062397003

Epoch: 5| Step: 6
Training loss: 2.818542003631592
Validation loss: 3.0820062855879464

Epoch: 5| Step: 7
Training loss: 3.127410888671875
Validation loss: 3.077477882305781

Epoch: 5| Step: 8
Training loss: 3.1581966876983643
Validation loss: 3.0735560059547424

Epoch: 5| Step: 9
Training loss: 2.9952046871185303
Validation loss: 3.0698894262313843

Epoch: 5| Step: 10
Training loss: 2.5849578380584717
Validation loss: 3.065873165925344

Epoch: 5| Step: 11
Training loss: 2.086171865463257
Validation loss: 3.0624019503593445

Epoch: 36| Step: 0
Training loss: 3.0942373275756836
Validation loss: 3.058283040920893

Epoch: 5| Step: 1
Training loss: 3.528588056564331
Validation loss: 3.054870913426081

Epoch: 5| Step: 2
Training loss: 3.6295504570007324
Validation loss: 3.05164697766304

Epoch: 5| Step: 3
Training loss: 2.834277391433716
Validation loss: 3.048383762439092

Epoch: 5| Step: 4
Training loss: 2.760324716567993
Validation loss: 3.0447621941566467

Epoch: 5| Step: 5
Training loss: 3.5390121936798096
Validation loss: 3.041403810183207

Epoch: 5| Step: 6
Training loss: 2.758406400680542
Validation loss: 3.0379435817400613

Epoch: 5| Step: 7
Training loss: 2.8485798835754395
Validation loss: 3.034424384435018

Epoch: 5| Step: 8
Training loss: 3.3630473613739014
Validation loss: 3.0310207108656564

Epoch: 5| Step: 9
Training loss: 3.3582160472869873
Validation loss: 3.0271228551864624

Epoch: 5| Step: 10
Training loss: 3.758089065551758
Validation loss: 3.023043086131414

Epoch: 5| Step: 11
Training loss: 3.4557971954345703
Validation loss: 3.0190244913101196

Epoch: 37| Step: 0
Training loss: 2.867236375808716
Validation loss: 3.014783372481664

Epoch: 5| Step: 1
Training loss: 3.467099666595459
Validation loss: 3.0116646587848663

Epoch: 5| Step: 2
Training loss: 3.130319118499756
Validation loss: 3.0076228082180023

Epoch: 5| Step: 3
Training loss: 3.37073016166687
Validation loss: 3.0045416553815207

Epoch: 5| Step: 4
Training loss: 3.5730342864990234
Validation loss: 3.00132421652476

Epoch: 5| Step: 5
Training loss: 2.7969717979431152
Validation loss: 2.9995474020640054

Epoch: 5| Step: 6
Training loss: 3.3836662769317627
Validation loss: 2.9941601157188416

Epoch: 5| Step: 7
Training loss: 2.91971755027771
Validation loss: 2.988820274670919

Epoch: 5| Step: 8
Training loss: 2.707231044769287
Validation loss: 2.984983662764231

Epoch: 5| Step: 9
Training loss: 3.2846665382385254
Validation loss: 2.9804497361183167

Epoch: 5| Step: 10
Training loss: 3.6249470710754395
Validation loss: 2.9767157832781472

Epoch: 5| Step: 11
Training loss: 3.0202174186706543
Validation loss: 2.972757558027903

Epoch: 38| Step: 0
Training loss: 2.048099994659424
Validation loss: 2.9700867533683777

Epoch: 5| Step: 1
Training loss: 3.7094955444335938
Validation loss: 2.9665694733460746

Epoch: 5| Step: 2
Training loss: 3.7386558055877686
Validation loss: 2.963802138964335

Epoch: 5| Step: 3
Training loss: 3.1070704460144043
Validation loss: 2.9596610218286514

Epoch: 5| Step: 4
Training loss: 2.802980661392212
Validation loss: 2.9556800425052643

Epoch: 5| Step: 5
Training loss: 2.843555212020874
Validation loss: 2.9525842368602753

Epoch: 5| Step: 6
Training loss: 3.4615654945373535
Validation loss: 2.9494099815686545

Epoch: 5| Step: 7
Training loss: 3.0749754905700684
Validation loss: 2.9457489947477975

Epoch: 5| Step: 8
Training loss: 3.4039740562438965
Validation loss: 2.9427510698636374

Epoch: 5| Step: 9
Training loss: 3.1610801219940186
Validation loss: 2.9384969671567283

Epoch: 5| Step: 10
Training loss: 3.737767457962036
Validation loss: 2.934358229239782

Epoch: 5| Step: 11
Training loss: 0.9936719536781311
Validation loss: 2.931659907102585

Epoch: 39| Step: 0
Training loss: 2.6707615852355957
Validation loss: 2.927641044060389

Epoch: 5| Step: 1
Training loss: 2.4294705390930176
Validation loss: 2.9250580966472626

Epoch: 5| Step: 2
Training loss: 3.5099074840545654
Validation loss: 2.9218122164408364

Epoch: 5| Step: 3
Training loss: 2.7263476848602295
Validation loss: 2.9199452002843223

Epoch: 5| Step: 4
Training loss: 3.1031928062438965
Validation loss: 2.916322578986486

Epoch: 5| Step: 5
Training loss: 3.101247787475586
Validation loss: 2.9128836393356323

Epoch: 5| Step: 6
Training loss: 3.876713991165161
Validation loss: 2.909704178571701

Epoch: 5| Step: 7
Training loss: 3.5313096046447754
Validation loss: 2.906534512837728

Epoch: 5| Step: 8
Training loss: 3.5539822578430176
Validation loss: 2.90297723809878

Epoch: 5| Step: 9
Training loss: 3.5561375617980957
Validation loss: 2.8993722796440125

Epoch: 5| Step: 10
Training loss: 2.1133313179016113
Validation loss: 2.895460784435272

Epoch: 5| Step: 11
Training loss: 3.512852430343628
Validation loss: 2.891796131928762

Epoch: 40| Step: 0
Training loss: 2.9284958839416504
Validation loss: 2.888925482829412

Epoch: 5| Step: 1
Training loss: 3.0491509437561035
Validation loss: 2.8854500552018485

Epoch: 5| Step: 2
Training loss: 2.981755495071411
Validation loss: 2.8838051358858743

Epoch: 5| Step: 3
Training loss: 3.5272834300994873
Validation loss: 2.8824261724948883

Epoch: 5| Step: 4
Training loss: 2.9994263648986816
Validation loss: 2.8750465710957847

Epoch: 5| Step: 5
Training loss: 2.784512996673584
Validation loss: 2.8712328473726907

Epoch: 5| Step: 6
Training loss: 3.501575469970703
Validation loss: 2.8679935137430825

Epoch: 5| Step: 7
Training loss: 3.0237796306610107
Validation loss: 2.8653796017169952

Epoch: 5| Step: 8
Training loss: 3.231046199798584
Validation loss: 2.862535377343496

Epoch: 5| Step: 9
Training loss: 2.6051366329193115
Validation loss: 2.8590217729409537

Epoch: 5| Step: 10
Training loss: 3.1555328369140625
Validation loss: 2.855835646390915

Epoch: 5| Step: 11
Training loss: 3.45552396774292
Validation loss: 2.8523727357387543

Epoch: 41| Step: 0
Training loss: 2.994189977645874
Validation loss: 2.848325272401174

Epoch: 5| Step: 1
Training loss: 3.2578601837158203
Validation loss: 2.844755550225576

Epoch: 5| Step: 2
Training loss: 2.530369520187378
Validation loss: 2.841602941354116

Epoch: 5| Step: 3
Training loss: 3.108767032623291
Validation loss: 2.8369996150334678

Epoch: 5| Step: 4
Training loss: 2.944007396697998
Validation loss: 2.83347420891126

Epoch: 5| Step: 5
Training loss: 2.9233486652374268
Validation loss: 2.829964985450109

Epoch: 5| Step: 6
Training loss: 2.953946590423584
Validation loss: 2.826915919780731

Epoch: 5| Step: 7
Training loss: 3.3302695751190186
Validation loss: 2.8236821393171945

Epoch: 5| Step: 8
Training loss: 3.0074875354766846
Validation loss: 2.820530047019323

Epoch: 5| Step: 9
Training loss: 2.846953868865967
Validation loss: 2.8182051181793213

Epoch: 5| Step: 10
Training loss: 3.46893310546875
Validation loss: 2.8150800466537476

Epoch: 5| Step: 11
Training loss: 3.5149803161621094
Validation loss: 2.812501092751821

Epoch: 42| Step: 0
Training loss: 3.403393268585205
Validation loss: 2.8080992003281913

Epoch: 5| Step: 1
Training loss: 2.8088061809539795
Validation loss: 2.804746280113856

Epoch: 5| Step: 2
Training loss: 3.1598379611968994
Validation loss: 2.800971527894338

Epoch: 5| Step: 3
Training loss: 2.826544761657715
Validation loss: 2.798184255758921

Epoch: 5| Step: 4
Training loss: 3.0440151691436768
Validation loss: 2.796170949935913

Epoch: 5| Step: 5
Training loss: 2.9205474853515625
Validation loss: 2.7949902613957724

Epoch: 5| Step: 6
Training loss: 2.6577072143554688
Validation loss: 2.7966884275277457

Epoch: 5| Step: 7
Training loss: 2.9201836585998535
Validation loss: 2.81029204527537

Epoch: 5| Step: 8
Training loss: 3.3307127952575684
Validation loss: 2.782794237136841

Epoch: 5| Step: 9
Training loss: 2.7020792961120605
Validation loss: 2.7790129482746124

Epoch: 5| Step: 10
Training loss: 3.369824171066284
Validation loss: 2.7809801598389945

Epoch: 5| Step: 11
Training loss: 2.568981647491455
Validation loss: 2.783238629500071

Epoch: 43| Step: 0
Training loss: 3.3705921173095703
Validation loss: 2.918030391136805

Epoch: 5| Step: 1
Training loss: 3.0528054237365723
Validation loss: 2.8087093830108643

Epoch: 5| Step: 2
Training loss: 2.798086643218994
Validation loss: 2.764760434627533

Epoch: 5| Step: 3
Training loss: 3.203676223754883
Validation loss: 2.763715227444967

Epoch: 5| Step: 4
Training loss: 3.174307107925415
Validation loss: 2.768709192673365

Epoch: 5| Step: 5
Training loss: 2.629660129547119
Validation loss: 2.778068423271179

Epoch: 5| Step: 6
Training loss: 2.655374050140381
Validation loss: 2.7831147015094757

Epoch: 5| Step: 7
Training loss: 3.384298324584961
Validation loss: 2.779372423887253

Epoch: 5| Step: 8
Training loss: 3.0996501445770264
Validation loss: 2.768707642952601

Epoch: 5| Step: 9
Training loss: 3.0134124755859375
Validation loss: 2.7585810919602713

Epoch: 5| Step: 10
Training loss: 2.624537229537964
Validation loss: 2.7528535525004068

Epoch: 5| Step: 11
Training loss: 3.3974685668945312
Validation loss: 2.750692347685496

Epoch: 44| Step: 0
Training loss: 2.7711551189422607
Validation loss: 2.74893652399381

Epoch: 5| Step: 1
Training loss: 3.249206066131592
Validation loss: 2.7444310188293457

Epoch: 5| Step: 2
Training loss: 2.8564536571502686
Validation loss: 2.7427737017472587

Epoch: 5| Step: 3
Training loss: 2.768263339996338
Validation loss: 2.736206909020742

Epoch: 5| Step: 4
Training loss: 2.7374796867370605
Validation loss: 2.7330775260925293

Epoch: 5| Step: 5
Training loss: 2.800004720687866
Validation loss: 2.7268496453762054

Epoch: 5| Step: 6
Training loss: 2.342984437942505
Validation loss: 2.7233680188655853

Epoch: 5| Step: 7
Training loss: 3.1078879833221436
Validation loss: 2.719170937935511

Epoch: 5| Step: 8
Training loss: 3.4856085777282715
Validation loss: 2.7141664822896323

Epoch: 5| Step: 9
Training loss: 3.2110259532928467
Validation loss: 2.710347423950831

Epoch: 5| Step: 10
Training loss: 2.8912181854248047
Validation loss: 2.7065967520078025

Epoch: 5| Step: 11
Training loss: 3.343273162841797
Validation loss: 2.703729728857676

Epoch: 45| Step: 0
Training loss: 3.477818012237549
Validation loss: 2.698569416999817

Epoch: 5| Step: 1
Training loss: 2.942518949508667
Validation loss: 2.695678989092509

Epoch: 5| Step: 2
Training loss: 3.0288875102996826
Validation loss: 2.690968175729116

Epoch: 5| Step: 3
Training loss: 2.515634059906006
Validation loss: 2.6870581209659576

Epoch: 5| Step: 4
Training loss: 2.4760279655456543
Validation loss: 2.683628340562185

Epoch: 5| Step: 5
Training loss: 3.2309138774871826
Validation loss: 2.6796495666106543

Epoch: 5| Step: 6
Training loss: 2.472986936569214
Validation loss: 2.6758649547894797

Epoch: 5| Step: 7
Training loss: 3.3874459266662598
Validation loss: 2.6710354685783386

Epoch: 5| Step: 8
Training loss: 2.575122356414795
Validation loss: 2.6691789627075195

Epoch: 5| Step: 9
Training loss: 3.0262701511383057
Validation loss: 2.6679195761680603

Epoch: 5| Step: 10
Training loss: 2.5466976165771484
Validation loss: 2.662074387073517

Epoch: 5| Step: 11
Training loss: 3.385082960128784
Validation loss: 2.658979614575704

Epoch: 46| Step: 0
Training loss: 3.0337395668029785
Validation loss: 2.656269073486328

Epoch: 5| Step: 1
Training loss: 2.401427745819092
Validation loss: 2.6525779167811074

Epoch: 5| Step: 2
Training loss: 3.0218920707702637
Validation loss: 2.6487483183542886

Epoch: 5| Step: 3
Training loss: 3.5050411224365234
Validation loss: 2.6468858818213143

Epoch: 5| Step: 4
Training loss: 2.6225998401641846
Validation loss: 2.64176869392395

Epoch: 5| Step: 5
Training loss: 2.698270082473755
Validation loss: 2.640693098306656

Epoch: 5| Step: 6
Training loss: 2.434030294418335
Validation loss: 2.638123353322347

Epoch: 5| Step: 7
Training loss: 2.9710781574249268
Validation loss: 2.6311146318912506

Epoch: 5| Step: 8
Training loss: 2.6125802993774414
Validation loss: 2.6297260324160256

Epoch: 5| Step: 9
Training loss: 2.9233322143554688
Validation loss: 2.6261764566103616

Epoch: 5| Step: 10
Training loss: 2.8985347747802734
Validation loss: 2.625179429848989

Epoch: 5| Step: 11
Training loss: 3.6448168754577637
Validation loss: 2.6215917766094208

Epoch: 47| Step: 0
Training loss: 3.2734813690185547
Validation loss: 2.617210497458776

Epoch: 5| Step: 1
Training loss: 2.842108726501465
Validation loss: 2.613248437643051

Epoch: 5| Step: 2
Training loss: 2.513714075088501
Validation loss: 2.610262711842855

Epoch: 5| Step: 3
Training loss: 2.0663211345672607
Validation loss: 2.605300337076187

Epoch: 5| Step: 4
Training loss: 2.9363090991973877
Validation loss: 2.602226108312607

Epoch: 5| Step: 5
Training loss: 1.9207496643066406
Validation loss: 2.600459784269333

Epoch: 5| Step: 6
Training loss: 2.827454090118408
Validation loss: 2.5986282527446747

Epoch: 5| Step: 7
Training loss: 2.956824541091919
Validation loss: 2.5930172204971313

Epoch: 5| Step: 8
Training loss: 3.284161329269409
Validation loss: 2.5907645920912423

Epoch: 5| Step: 9
Training loss: 2.5562658309936523
Validation loss: 2.586482067902883

Epoch: 5| Step: 10
Training loss: 3.6296439170837402
Validation loss: 2.5841180980205536

Epoch: 5| Step: 11
Training loss: 2.972724437713623
Validation loss: 2.5810069938500724

Epoch: 48| Step: 0
Training loss: 3.115142822265625
Validation loss: 2.578982174396515

Epoch: 5| Step: 1
Training loss: 3.1392340660095215
Validation loss: 2.579805999994278

Epoch: 5| Step: 2
Training loss: 3.4622626304626465
Validation loss: 2.573890914519628

Epoch: 5| Step: 3
Training loss: 2.4509074687957764
Validation loss: 2.569738785425822

Epoch: 5| Step: 4
Training loss: 2.3896071910858154
Validation loss: 2.567267199357351

Epoch: 5| Step: 5
Training loss: 2.8528404235839844
Validation loss: 2.5617284576098123

Epoch: 5| Step: 6
Training loss: 3.1387360095977783
Validation loss: 2.561415195465088

Epoch: 5| Step: 7
Training loss: 2.4333090782165527
Validation loss: 2.557991454998652

Epoch: 5| Step: 8
Training loss: 2.2698168754577637
Validation loss: 2.5564122200012207

Epoch: 5| Step: 9
Training loss: 3.0645346641540527
Validation loss: 2.55094646414121

Epoch: 5| Step: 10
Training loss: 2.179213047027588
Validation loss: 2.5498812596003213

Epoch: 5| Step: 11
Training loss: 2.735058307647705
Validation loss: 2.547328641017278

Epoch: 49| Step: 0
Training loss: 2.5741662979125977
Validation loss: 2.543303738037745

Epoch: 5| Step: 1
Training loss: 2.4098165035247803
Validation loss: 2.5428689618905387

Epoch: 5| Step: 2
Training loss: 3.0396034717559814
Validation loss: 2.540516177813212

Epoch: 5| Step: 3
Training loss: 2.002720594406128
Validation loss: 2.539246012767156

Epoch: 5| Step: 4
Training loss: 3.7291274070739746
Validation loss: 2.536197086175283

Epoch: 5| Step: 5
Training loss: 2.0984950065612793
Validation loss: 2.5325500269730887

Epoch: 5| Step: 6
Training loss: 3.4405853748321533
Validation loss: 2.5295096139113107

Epoch: 5| Step: 7
Training loss: 2.290630340576172
Validation loss: 2.5239686171213784

Epoch: 5| Step: 8
Training loss: 2.968240737915039
Validation loss: 2.520542581876119

Epoch: 5| Step: 9
Training loss: 3.409320831298828
Validation loss: 2.516353448232015

Epoch: 5| Step: 10
Training loss: 2.2145233154296875
Validation loss: 2.5154273907343545

Epoch: 5| Step: 11
Training loss: 2.1599504947662354
Validation loss: 2.511659930149714

Epoch: 50| Step: 0
Training loss: 2.2043309211730957
Validation loss: 2.509515623251597

Epoch: 5| Step: 1
Training loss: 2.3546271324157715
Validation loss: 2.505210886398951

Epoch: 5| Step: 2
Training loss: 2.208495616912842
Validation loss: 2.5035574237505593

Epoch: 5| Step: 3
Training loss: 3.1608948707580566
Validation loss: 2.4998928705851235

Epoch: 5| Step: 4
Training loss: 3.153043746948242
Validation loss: 2.4960629045963287

Epoch: 5| Step: 5
Training loss: 2.2370822429656982
Validation loss: 2.4942402144273124

Epoch: 5| Step: 6
Training loss: 2.93861722946167
Validation loss: 2.49245023727417

Epoch: 5| Step: 7
Training loss: 2.650365114212036
Validation loss: 2.4897153278191886

Epoch: 5| Step: 8
Training loss: 3.1677374839782715
Validation loss: 2.4881337881088257

Epoch: 5| Step: 9
Training loss: 2.710014581680298
Validation loss: 2.484461506207784

Epoch: 5| Step: 10
Training loss: 3.005565643310547
Validation loss: 2.482252856095632

Epoch: 5| Step: 11
Training loss: 1.9412100315093994
Validation loss: 2.4792638222376504

Epoch: 51| Step: 0
Training loss: 2.9249813556671143
Validation loss: 2.475726837913195

Epoch: 5| Step: 1
Training loss: 2.8191115856170654
Validation loss: 2.4730381071567535

Epoch: 5| Step: 2
Training loss: 2.5470669269561768
Validation loss: 2.472455690304438

Epoch: 5| Step: 3
Training loss: 2.7505009174346924
Validation loss: 2.4688316583633423

Epoch: 5| Step: 4
Training loss: 2.260345697402954
Validation loss: 2.4662225047747293

Epoch: 5| Step: 5
Training loss: 2.8409721851348877
Validation loss: 2.4621452589829764

Epoch: 5| Step: 6
Training loss: 2.3869290351867676
Validation loss: 2.4585978388786316

Epoch: 5| Step: 7
Training loss: 2.8682994842529297
Validation loss: 2.456112672885259

Epoch: 5| Step: 8
Training loss: 2.64989972114563
Validation loss: 2.4540926416714988

Epoch: 5| Step: 9
Training loss: 2.74943208694458
Validation loss: 2.4571217447519302

Epoch: 5| Step: 10
Training loss: 2.651724100112915
Validation loss: 2.458203752835592

Epoch: 5| Step: 11
Training loss: 1.5744378566741943
Validation loss: 2.452649066845576

Epoch: 52| Step: 0
Training loss: 2.6523962020874023
Validation loss: 2.4445991615454354

Epoch: 5| Step: 1
Training loss: 2.55635142326355
Validation loss: 2.4431295494238534

Epoch: 5| Step: 2
Training loss: 2.4297986030578613
Validation loss: 2.4438220411539078

Epoch: 5| Step: 3
Training loss: 2.395615816116333
Validation loss: 2.4436359852552414

Epoch: 5| Step: 4
Training loss: 3.199462413787842
Validation loss: 2.444854954878489

Epoch: 5| Step: 5
Training loss: 2.0926642417907715
Validation loss: 2.4450222849845886

Epoch: 5| Step: 6
Training loss: 2.7738921642303467
Validation loss: 2.4398299853006997

Epoch: 5| Step: 7
Training loss: 2.505962371826172
Validation loss: 2.433708111445109

Epoch: 5| Step: 8
Training loss: 2.4789323806762695
Validation loss: 2.427722076574961

Epoch: 5| Step: 9
Training loss: 3.052011251449585
Validation loss: 2.4252008398373923

Epoch: 5| Step: 10
Training loss: 2.65877103805542
Validation loss: 2.422078768412272

Epoch: 5| Step: 11
Training loss: 3.0463175773620605
Validation loss: 2.4193946719169617

Epoch: 53| Step: 0
Training loss: 2.3586819171905518
Validation loss: 2.416722814242045

Epoch: 5| Step: 1
Training loss: 2.4761738777160645
Validation loss: 2.4142364859580994

Epoch: 5| Step: 2
Training loss: 2.104665756225586
Validation loss: 2.4084090888500214

Epoch: 5| Step: 3
Training loss: 3.183427095413208
Validation loss: 2.404935047030449

Epoch: 5| Step: 4
Training loss: 3.2174487113952637
Validation loss: 2.401427408059438

Epoch: 5| Step: 5
Training loss: 2.347856283187866
Validation loss: 2.3993873794873557

Epoch: 5| Step: 6
Training loss: 2.7259812355041504
Validation loss: 2.398502310117086

Epoch: 5| Step: 7
Training loss: 2.278597354888916
Validation loss: 2.3946618338425956

Epoch: 5| Step: 8
Training loss: 2.059889554977417
Validation loss: 2.391459216674169

Epoch: 5| Step: 9
Training loss: 2.6195638179779053
Validation loss: 2.3919961154460907

Epoch: 5| Step: 10
Training loss: 2.7313084602355957
Validation loss: 2.389046480258306

Epoch: 5| Step: 11
Training loss: 4.374591827392578
Validation loss: 2.381713797648748

Epoch: 54| Step: 0
Training loss: 1.9977328777313232
Validation loss: 2.3793572982152305

Epoch: 5| Step: 1
Training loss: 2.7862586975097656
Validation loss: 2.377460459868113

Epoch: 5| Step: 2
Training loss: 2.6626944541931152
Validation loss: 2.3753265937169394

Epoch: 5| Step: 3
Training loss: 2.580772876739502
Validation loss: 2.3753947714964547

Epoch: 5| Step: 4
Training loss: 2.790012836456299
Validation loss: 2.3740066836277642

Epoch: 5| Step: 5
Training loss: 2.520474910736084
Validation loss: 2.3731272319952645

Epoch: 5| Step: 6
Training loss: 2.5595240592956543
Validation loss: 2.3705042600631714

Epoch: 5| Step: 7
Training loss: 2.8017992973327637
Validation loss: 2.3674972653388977

Epoch: 5| Step: 8
Training loss: 1.889897108078003
Validation loss: 2.3641423881053925

Epoch: 5| Step: 9
Training loss: 2.2566802501678467
Validation loss: 2.3591402818759284

Epoch: 5| Step: 10
Training loss: 2.7822349071502686
Validation loss: 2.3571930428346

Epoch: 5| Step: 11
Training loss: 4.769351005554199
Validation loss: 2.355353742837906

Epoch: 55| Step: 0
Training loss: 1.9679123163223267
Validation loss: 2.3513065725564957

Epoch: 5| Step: 1
Training loss: 2.372190237045288
Validation loss: 2.3481468607982

Epoch: 5| Step: 2
Training loss: 2.815056562423706
Validation loss: 2.3457343777020774

Epoch: 5| Step: 3
Training loss: 2.7629942893981934
Validation loss: 2.338914528489113

Epoch: 5| Step: 4
Training loss: 1.8188037872314453
Validation loss: 2.334093987941742

Epoch: 5| Step: 5
Training loss: 2.6493730545043945
Validation loss: 2.3318735361099243

Epoch: 5| Step: 6
Training loss: 2.3070690631866455
Validation loss: 2.3296725849310556

Epoch: 5| Step: 7
Training loss: 3.02404522895813
Validation loss: 2.3287824292977652

Epoch: 5| Step: 8
Training loss: 2.68030047416687
Validation loss: 2.323910395304362

Epoch: 5| Step: 9
Training loss: 2.473543882369995
Validation loss: 2.3229909439881644

Epoch: 5| Step: 10
Training loss: 2.6963233947753906
Validation loss: 2.3222835958004

Epoch: 5| Step: 11
Training loss: 2.8592453002929688
Validation loss: 2.3216497798760733

Epoch: 56| Step: 0
Training loss: 2.3407886028289795
Validation loss: 2.3270363410313926

Epoch: 5| Step: 1
Training loss: 2.369649887084961
Validation loss: 2.3234911958376565

Epoch: 5| Step: 2
Training loss: 2.6479320526123047
Validation loss: 2.324091285467148

Epoch: 5| Step: 3
Training loss: 1.7610986232757568
Validation loss: 2.311653425296148

Epoch: 5| Step: 4
Training loss: 2.1827592849731445
Validation loss: 2.3026363054911294

Epoch: 5| Step: 5
Training loss: 2.8675150871276855
Validation loss: 2.301630069812139

Epoch: 5| Step: 6
Training loss: 3.0097365379333496
Validation loss: 2.3030739774306617

Epoch: 5| Step: 7
Training loss: 2.3052821159362793
Validation loss: 2.3000824550787606

Epoch: 5| Step: 8
Training loss: 2.1915783882141113
Validation loss: 2.299833352367083

Epoch: 5| Step: 9
Training loss: 2.588560104370117
Validation loss: 2.2956505864858627

Epoch: 5| Step: 10
Training loss: 2.8320765495300293
Validation loss: 2.2939405341943107

Epoch: 5| Step: 11
Training loss: 3.566680669784546
Validation loss: 2.295648455619812

Epoch: 57| Step: 0
Training loss: 2.1029763221740723
Validation loss: 2.287420709927877

Epoch: 5| Step: 1
Training loss: 2.7360150814056396
Validation loss: 2.2904417514801025

Epoch: 5| Step: 2
Training loss: 2.799651861190796
Validation loss: 2.2810794661442437

Epoch: 5| Step: 3
Training loss: 2.6269140243530273
Validation loss: 2.2806632270415625

Epoch: 5| Step: 4
Training loss: 1.8877477645874023
Validation loss: 2.28768598039945

Epoch: 5| Step: 5
Training loss: 2.5484535694122314
Validation loss: 2.300187254945437

Epoch: 5| Step: 6
Training loss: 2.6133408546447754
Validation loss: 2.2987916568915048

Epoch: 5| Step: 7
Training loss: 2.7671313285827637
Validation loss: 2.286621242761612

Epoch: 5| Step: 8
Training loss: 2.8060905933380127
Validation loss: 2.2732759018739066

Epoch: 5| Step: 9
Training loss: 1.755907654762268
Validation loss: 2.2688006361325583

Epoch: 5| Step: 10
Training loss: 2.465221643447876
Validation loss: 2.269230688611666

Epoch: 5| Step: 11
Training loss: 2.75313401222229
Validation loss: 2.274211118618647

Epoch: 58| Step: 0
Training loss: 2.9846668243408203
Validation loss: 2.292520746588707

Epoch: 5| Step: 1
Training loss: 2.333544969558716
Validation loss: 2.301673730214437

Epoch: 5| Step: 2
Training loss: 2.59167742729187
Validation loss: 2.292816330989202

Epoch: 5| Step: 3
Training loss: 2.5625123977661133
Validation loss: 2.2810269594192505

Epoch: 5| Step: 4
Training loss: 2.084545850753784
Validation loss: 2.2731640140215554

Epoch: 5| Step: 5
Training loss: 1.796431541442871
Validation loss: 2.2638551791508994

Epoch: 5| Step: 6
Training loss: 2.3851966857910156
Validation loss: 2.266161243120829

Epoch: 5| Step: 7
Training loss: 2.605346918106079
Validation loss: 2.2611980636914573

Epoch: 5| Step: 8
Training loss: 2.8342509269714355
Validation loss: 2.255785579482714

Epoch: 5| Step: 9
Training loss: 2.3989620208740234
Validation loss: 2.2520814538002014

Epoch: 5| Step: 10
Training loss: 2.008863687515259
Validation loss: 2.249758765101433

Epoch: 5| Step: 11
Training loss: 3.515507221221924
Validation loss: 2.2441305816173553

Epoch: 59| Step: 0
Training loss: 2.103342056274414
Validation loss: 2.238890767097473

Epoch: 5| Step: 1
Training loss: 2.025759696960449
Validation loss: 2.2341416478157043

Epoch: 5| Step: 2
Training loss: 2.2250235080718994
Validation loss: 2.231894021232923

Epoch: 5| Step: 3
Training loss: 2.461613893508911
Validation loss: 2.238347679376602

Epoch: 5| Step: 4
Training loss: 2.8733584880828857
Validation loss: 2.2417352298895517

Epoch: 5| Step: 5
Training loss: 2.764150857925415
Validation loss: 2.235125944018364

Epoch: 5| Step: 6
Training loss: 2.372565507888794
Validation loss: 2.226089825232824

Epoch: 5| Step: 7
Training loss: 2.294699192047119
Validation loss: 2.224079132080078

Epoch: 5| Step: 8
Training loss: 2.3709263801574707
Validation loss: 2.2172502974669137

Epoch: 5| Step: 9
Training loss: 3.121129274368286
Validation loss: 2.2225548525651297

Epoch: 5| Step: 10
Training loss: 1.6958558559417725
Validation loss: 2.2186983128388724

Epoch: 5| Step: 11
Training loss: 2.592751979827881
Validation loss: 2.2197507470846176

Epoch: 60| Step: 0
Training loss: 2.139897584915161
Validation loss: 2.2155346969763436

Epoch: 5| Step: 1
Training loss: 2.1353745460510254
Validation loss: 2.2172229985396066

Epoch: 5| Step: 2
Training loss: 2.63033390045166
Validation loss: 2.2134639422098794

Epoch: 5| Step: 3
Training loss: 2.4484894275665283
Validation loss: 2.2145486722389855

Epoch: 5| Step: 4
Training loss: 2.5865986347198486
Validation loss: 2.2069954623778663

Epoch: 5| Step: 5
Training loss: 2.7573232650756836
Validation loss: 2.208219677209854

Epoch: 5| Step: 6
Training loss: 1.8854538202285767
Validation loss: 2.2104768057664237

Epoch: 5| Step: 7
Training loss: 2.570965528488159
Validation loss: 2.2086745699246726

Epoch: 5| Step: 8
Training loss: 2.3117785453796387
Validation loss: 2.198263997832934

Epoch: 5| Step: 9
Training loss: 2.196206569671631
Validation loss: 2.2006784776846566

Epoch: 5| Step: 10
Training loss: 2.4573721885681152
Validation loss: 2.1981058418750763

Epoch: 5| Step: 11
Training loss: 2.0725584030151367
Validation loss: 2.2014169792334237

Epoch: 61| Step: 0
Training loss: 2.301823377609253
Validation loss: 2.1951866994301477

Epoch: 5| Step: 1
Training loss: 2.410015106201172
Validation loss: 2.1967523048321405

Epoch: 5| Step: 2
Training loss: 2.679502487182617
Validation loss: 2.193032036225001

Epoch: 5| Step: 3
Training loss: 2.278568983078003
Validation loss: 2.1930457651615143

Epoch: 5| Step: 4
Training loss: 2.2340779304504395
Validation loss: 2.193511794010798

Epoch: 5| Step: 5
Training loss: 2.491830348968506
Validation loss: 2.189105361700058

Epoch: 5| Step: 6
Training loss: 2.4782567024230957
Validation loss: 2.1906967709461846

Epoch: 5| Step: 7
Training loss: 2.1659157276153564
Validation loss: 2.1898560921351113

Epoch: 5| Step: 8
Training loss: 2.62373948097229
Validation loss: 2.1875287195046744

Epoch: 5| Step: 9
Training loss: 2.349843978881836
Validation loss: 2.1871407330036163

Epoch: 5| Step: 10
Training loss: 1.9861606359481812
Validation loss: 2.184594770272573

Epoch: 5| Step: 11
Training loss: 1.7249614000320435
Validation loss: 2.1833474139372506

Epoch: 62| Step: 0
Training loss: 2.4173877239227295
Validation loss: 2.180915723244349

Epoch: 5| Step: 1
Training loss: 2.5601227283477783
Validation loss: 2.177741438150406

Epoch: 5| Step: 2
Training loss: 2.4378089904785156
Validation loss: 2.1768684138854346

Epoch: 5| Step: 3
Training loss: 2.131471633911133
Validation loss: 2.173616662621498

Epoch: 5| Step: 4
Training loss: 1.9541040658950806
Validation loss: 2.1728314956029258

Epoch: 5| Step: 5
Training loss: 2.8671300411224365
Validation loss: 2.171665921807289

Epoch: 5| Step: 6
Training loss: 1.9895904064178467
Validation loss: 2.169786269466082

Epoch: 5| Step: 7
Training loss: 2.2260544300079346
Validation loss: 2.1732009599606195

Epoch: 5| Step: 8
Training loss: 2.281874418258667
Validation loss: 2.1719340880711875

Epoch: 5| Step: 9
Training loss: 2.18969988822937
Validation loss: 2.1680465837319693

Epoch: 5| Step: 10
Training loss: 2.538658857345581
Validation loss: 2.1626964708169303

Epoch: 5| Step: 11
Training loss: 2.815593957901001
Validation loss: 2.1650029718875885

Epoch: 63| Step: 0
Training loss: 2.1657652854919434
Validation loss: 2.1589450935522714

Epoch: 5| Step: 1
Training loss: 2.829221487045288
Validation loss: 2.1622428645690284

Epoch: 5| Step: 2
Training loss: 2.013852596282959
Validation loss: 2.1586205661296844

Epoch: 5| Step: 3
Training loss: 2.280296802520752
Validation loss: 2.1601635118325553

Epoch: 5| Step: 4
Training loss: 2.6303727626800537
Validation loss: 2.160247435172399

Epoch: 5| Step: 5
Training loss: 2.447012424468994
Validation loss: 2.1597747852404914

Epoch: 5| Step: 6
Training loss: 2.420896530151367
Validation loss: 2.155566786726316

Epoch: 5| Step: 7
Training loss: 2.314091205596924
Validation loss: 2.1578567077716193

Epoch: 5| Step: 8
Training loss: 2.047154426574707
Validation loss: 2.1553014566500983

Epoch: 5| Step: 9
Training loss: 2.3842499256134033
Validation loss: 2.1538073817888894

Epoch: 5| Step: 10
Training loss: 1.9460846185684204
Validation loss: 2.1517985810836158

Epoch: 5| Step: 11
Training loss: 2.7307310104370117
Validation loss: 2.146446535984675

Epoch: 64| Step: 0
Training loss: 2.5670666694641113
Validation loss: 2.14323391020298

Epoch: 5| Step: 1
Training loss: 2.684221029281616
Validation loss: 2.1395157128572464

Epoch: 5| Step: 2
Training loss: 1.505665898323059
Validation loss: 2.135484461983045

Epoch: 5| Step: 3
Training loss: 1.941976547241211
Validation loss: 2.134605531891187

Epoch: 5| Step: 4
Training loss: 2.1357243061065674
Validation loss: 2.1314072012901306

Epoch: 5| Step: 5
Training loss: 2.3427021503448486
Validation loss: 2.131930614511172

Epoch: 5| Step: 6
Training loss: 2.481865406036377
Validation loss: 2.126077617208163

Epoch: 5| Step: 7
Training loss: 2.370159864425659
Validation loss: 2.1336718698342643

Epoch: 5| Step: 8
Training loss: 2.5583221912384033
Validation loss: 2.1280144850413003

Epoch: 5| Step: 9
Training loss: 2.0810883045196533
Validation loss: 2.1263507902622223

Epoch: 5| Step: 10
Training loss: 2.614720344543457
Validation loss: 2.125514214237531

Epoch: 5| Step: 11
Training loss: 2.708920478820801
Validation loss: 2.1199531654516854

Epoch: 65| Step: 0
Training loss: 1.9861431121826172
Validation loss: 2.1193654239177704

Epoch: 5| Step: 1
Training loss: 2.8571527004241943
Validation loss: 2.1218500435352325

Epoch: 5| Step: 2
Training loss: 2.234659433364868
Validation loss: 2.1141548107067742

Epoch: 5| Step: 3
Training loss: 2.1253581047058105
Validation loss: 2.1189688046773276

Epoch: 5| Step: 4
Training loss: 1.957664132118225
Validation loss: 2.11816676457723

Epoch: 5| Step: 5
Training loss: 2.03178071975708
Validation loss: 2.115715061624845

Epoch: 5| Step: 6
Training loss: 2.9166762828826904
Validation loss: 2.1199327955643334

Epoch: 5| Step: 7
Training loss: 2.709974527359009
Validation loss: 2.1143317818641663

Epoch: 5| Step: 8
Training loss: 2.7988812923431396
Validation loss: 2.10910627245903

Epoch: 5| Step: 9
Training loss: 2.1619722843170166
Validation loss: 2.1122014025847116

Epoch: 5| Step: 10
Training loss: 1.527348518371582
Validation loss: 2.1085956345001855

Epoch: 5| Step: 11
Training loss: 2.127687692642212
Validation loss: 2.1118629574775696

Epoch: 66| Step: 0
Training loss: 2.0476815700531006
Validation loss: 2.108623817563057

Epoch: 5| Step: 1
Training loss: 2.3997440338134766
Validation loss: 2.110691343744596

Epoch: 5| Step: 2
Training loss: 2.130300521850586
Validation loss: 2.1101757983366647

Epoch: 5| Step: 3
Training loss: 2.41172456741333
Validation loss: 2.1072925676902137

Epoch: 5| Step: 4
Training loss: 2.017625331878662
Validation loss: 2.1081028133630753

Epoch: 5| Step: 5
Training loss: 2.09741473197937
Validation loss: 2.106007988254229

Epoch: 5| Step: 6
Training loss: 2.8015575408935547
Validation loss: 2.110459347565969

Epoch: 5| Step: 7
Training loss: 2.0566985607147217
Validation loss: 2.104685679078102

Epoch: 5| Step: 8
Training loss: 2.7841262817382812
Validation loss: 2.1052276690800986

Epoch: 5| Step: 9
Training loss: 2.2841198444366455
Validation loss: 2.102725381652514

Epoch: 5| Step: 10
Training loss: 2.1124320030212402
Validation loss: 2.0977859646081924

Epoch: 5| Step: 11
Training loss: 2.241525650024414
Validation loss: 2.09649366637071

Epoch: 67| Step: 0
Training loss: 2.147327184677124
Validation loss: 2.097126603126526

Epoch: 5| Step: 1
Training loss: 2.192478656768799
Validation loss: 2.096648693084717

Epoch: 5| Step: 2
Training loss: 2.4185867309570312
Validation loss: 2.0921072562535605

Epoch: 5| Step: 3
Training loss: 2.6340696811676025
Validation loss: 2.0959745099147162

Epoch: 5| Step: 4
Training loss: 1.7302815914154053
Validation loss: 2.091507226228714

Epoch: 5| Step: 5
Training loss: 2.148797035217285
Validation loss: 2.092317516605059

Epoch: 5| Step: 6
Training loss: 2.57026743888855
Validation loss: 2.09605044623216

Epoch: 5| Step: 7
Training loss: 1.9699313640594482
Validation loss: 2.0902698884407678

Epoch: 5| Step: 8
Training loss: 2.16312313079834
Validation loss: 2.0907192627588906

Epoch: 5| Step: 9
Training loss: 2.2906506061553955
Validation loss: 2.092820997039477

Epoch: 5| Step: 10
Training loss: 2.5710179805755615
Validation loss: 2.0927889545758567

Epoch: 5| Step: 11
Training loss: 3.127174139022827
Validation loss: 2.0878991534312568

Epoch: 68| Step: 0
Training loss: 2.4797277450561523
Validation loss: 2.096434106429418

Epoch: 5| Step: 1
Training loss: 1.7259275913238525
Validation loss: 2.094175030787786

Epoch: 5| Step: 2
Training loss: 2.345024585723877
Validation loss: 2.0935390839974084

Epoch: 5| Step: 3
Training loss: 1.7813047170639038
Validation loss: 2.0904496361811957

Epoch: 5| Step: 4
Training loss: 2.2989866733551025
Validation loss: 2.093739698330561

Epoch: 5| Step: 5
Training loss: 2.784494400024414
Validation loss: 2.0871929228305817

Epoch: 5| Step: 6
Training loss: 2.405179262161255
Validation loss: 2.0802314976851144

Epoch: 5| Step: 7
Training loss: 2.1795191764831543
Validation loss: 2.0833837340275445

Epoch: 5| Step: 8
Training loss: 2.0956835746765137
Validation loss: 2.070151040951411

Epoch: 5| Step: 9
Training loss: 2.09869647026062
Validation loss: 2.0793252338965735

Epoch: 5| Step: 10
Training loss: 2.4269728660583496
Validation loss: 2.0725734482208886

Epoch: 5| Step: 11
Training loss: 3.289879322052002
Validation loss: 2.0815053979555764

Epoch: 69| Step: 0
Training loss: 1.8677291870117188
Validation loss: 2.0790744622548423

Epoch: 5| Step: 1
Training loss: 2.2336630821228027
Validation loss: 2.0775250842173896

Epoch: 5| Step: 2
Training loss: 2.0758190155029297
Validation loss: 2.0767763207356134

Epoch: 5| Step: 3
Training loss: 2.208881378173828
Validation loss: 2.0854176680246987

Epoch: 5| Step: 4
Training loss: 2.26950740814209
Validation loss: 2.081100141008695

Epoch: 5| Step: 5
Training loss: 2.1481773853302
Validation loss: 2.0844103594621024

Epoch: 5| Step: 6
Training loss: 2.348496913909912
Validation loss: 2.081443359454473

Epoch: 5| Step: 7
Training loss: 2.5110933780670166
Validation loss: 2.0724116216103234

Epoch: 5| Step: 8
Training loss: 2.218142032623291
Validation loss: 2.062294617295265

Epoch: 5| Step: 9
Training loss: 2.6479275226593018
Validation loss: 2.0680390844742456

Epoch: 5| Step: 10
Training loss: 2.497157335281372
Validation loss: 2.0689433813095093

Epoch: 5| Step: 11
Training loss: 1.9040956497192383
Validation loss: 2.0706383089224496

Epoch: 70| Step: 0
Training loss: 2.3509039878845215
Validation loss: 2.069280465443929

Epoch: 5| Step: 1
Training loss: 2.269408702850342
Validation loss: 2.0704656591018042

Epoch: 5| Step: 2
Training loss: 2.3998024463653564
Validation loss: 2.0644932836294174

Epoch: 5| Step: 3
Training loss: 2.330594778060913
Validation loss: 2.0636021395524344

Epoch: 5| Step: 4
Training loss: 2.672560214996338
Validation loss: 2.066052660346031

Epoch: 5| Step: 5
Training loss: 2.1663010120391846
Validation loss: 2.0627729296684265

Epoch: 5| Step: 6
Training loss: 2.587402820587158
Validation loss: 2.0659935971101127

Epoch: 5| Step: 7
Training loss: 2.2141270637512207
Validation loss: 2.065496578812599

Epoch: 5| Step: 8
Training loss: 2.5605924129486084
Validation loss: 2.061295365293821

Epoch: 5| Step: 9
Training loss: 1.3487101793289185
Validation loss: 2.054781287908554

Epoch: 5| Step: 10
Training loss: 1.6942676305770874
Validation loss: 2.055305391550064

Epoch: 5| Step: 11
Training loss: 2.921703577041626
Validation loss: 2.058349202076594

Epoch: 71| Step: 0
Training loss: 2.375903606414795
Validation loss: 2.0552618155876794

Epoch: 5| Step: 1
Training loss: 1.502378225326538
Validation loss: 2.047731558481852

Epoch: 5| Step: 2
Training loss: 1.8015425205230713
Validation loss: 2.0515424559513726

Epoch: 5| Step: 3
Training loss: 2.573925495147705
Validation loss: 2.051848903298378

Epoch: 5| Step: 4
Training loss: 2.0582282543182373
Validation loss: 2.0575897792975106

Epoch: 5| Step: 5
Training loss: 2.5805907249450684
Validation loss: 2.056904365619024

Epoch: 5| Step: 6
Training loss: 2.561739444732666
Validation loss: 2.0579203267892203

Epoch: 5| Step: 7
Training loss: 2.7665812969207764
Validation loss: 2.0566871215899787

Epoch: 5| Step: 8
Training loss: 2.424315929412842
Validation loss: 2.0466163059075675

Epoch: 5| Step: 9
Training loss: 2.419809579849243
Validation loss: 2.043905481696129

Epoch: 5| Step: 10
Training loss: 1.680161714553833
Validation loss: 2.0484688033660254

Epoch: 5| Step: 11
Training loss: 2.132582664489746
Validation loss: 2.054185743133227

Epoch: 72| Step: 0
Training loss: 2.4348950386047363
Validation loss: 2.0514532178640366

Epoch: 5| Step: 1
Training loss: 2.0870003700256348
Validation loss: 2.055888523658117

Epoch: 5| Step: 2
Training loss: 1.5966999530792236
Validation loss: 2.0574514071146646

Epoch: 5| Step: 3
Training loss: 2.4942147731781006
Validation loss: 2.058679868777593

Epoch: 5| Step: 4
Training loss: 1.7932857275009155
Validation loss: 2.0582568446795144

Epoch: 5| Step: 5
Training loss: 3.1672394275665283
Validation loss: 2.0619118263324103

Epoch: 5| Step: 6
Training loss: 2.240734100341797
Validation loss: 2.0636168966690698

Epoch: 5| Step: 7
Training loss: 2.680717945098877
Validation loss: 2.0606063902378082

Epoch: 5| Step: 8
Training loss: 1.9104549884796143
Validation loss: 2.0586617439985275

Epoch: 5| Step: 9
Training loss: 1.8698818683624268
Validation loss: 2.0565881729125977

Epoch: 5| Step: 10
Training loss: 2.369147539138794
Validation loss: 2.0484576721986136

Epoch: 5| Step: 11
Training loss: 2.3323559761047363
Validation loss: 2.0509739220142365

Epoch: 73| Step: 0
Training loss: 1.5532093048095703
Validation loss: 2.0497109492619834

Epoch: 5| Step: 1
Training loss: 1.7286055088043213
Validation loss: 2.044650355974833

Epoch: 5| Step: 2
Training loss: 3.008573055267334
Validation loss: 2.0439189076423645

Epoch: 5| Step: 3
Training loss: 1.9478824138641357
Validation loss: 2.0379759867986045

Epoch: 5| Step: 4
Training loss: 2.8284029960632324
Validation loss: 2.0437416235605874

Epoch: 5| Step: 5
Training loss: 2.1740148067474365
Validation loss: 2.041978269815445

Epoch: 5| Step: 6
Training loss: 2.5573933124542236
Validation loss: 2.0394825289646783

Epoch: 5| Step: 7
Training loss: 2.0022125244140625
Validation loss: 2.0337652266025543

Epoch: 5| Step: 8
Training loss: 2.033364772796631
Validation loss: 2.0405736714601517

Epoch: 5| Step: 9
Training loss: 1.8648360967636108
Validation loss: 2.03490349650383

Epoch: 5| Step: 10
Training loss: 2.52959942817688
Validation loss: 2.0343083341916404

Epoch: 5| Step: 11
Training loss: 3.501451253890991
Validation loss: 2.032015691200892

Epoch: 74| Step: 0
Training loss: 2.6263692378997803
Validation loss: 2.0324155191580453

Epoch: 5| Step: 1
Training loss: 2.0879883766174316
Validation loss: 2.0358761151631675

Epoch: 5| Step: 2
Training loss: 1.8732200860977173
Validation loss: 2.0278065701325736

Epoch: 5| Step: 3
Training loss: 2.1779019832611084
Validation loss: 2.0325233340263367

Epoch: 5| Step: 4
Training loss: 2.235058546066284
Validation loss: 2.03592740992705

Epoch: 5| Step: 5
Training loss: 2.500023603439331
Validation loss: 2.0284990469614663

Epoch: 5| Step: 6
Training loss: 2.122041702270508
Validation loss: 2.0318586230278015

Epoch: 5| Step: 7
Training loss: 2.5718908309936523
Validation loss: 2.0355094820261

Epoch: 5| Step: 8
Training loss: 2.29390549659729
Validation loss: 2.031686450044314

Epoch: 5| Step: 9
Training loss: 1.9348771572113037
Validation loss: 2.0335690478483834

Epoch: 5| Step: 10
Training loss: 1.9981437921524048
Validation loss: 2.0314009934663773

Epoch: 5| Step: 11
Training loss: 2.0799989700317383
Validation loss: 2.0302645365397134

Epoch: 75| Step: 0
Training loss: 2.7704596519470215
Validation loss: 2.0275190571943917

Epoch: 5| Step: 1
Training loss: 1.5571367740631104
Validation loss: 2.029078463713328

Epoch: 5| Step: 2
Training loss: 1.8095121383666992
Validation loss: 2.026829957962036

Epoch: 5| Step: 3
Training loss: 2.2308249473571777
Validation loss: 2.0286269883314767

Epoch: 5| Step: 4
Training loss: 2.2678282260894775
Validation loss: 2.0410554856061935

Epoch: 5| Step: 5
Training loss: 2.197354793548584
Validation loss: 2.0379064877827964

Epoch: 5| Step: 6
Training loss: 1.8125460147857666
Validation loss: 2.0385756691296897

Epoch: 5| Step: 7
Training loss: 1.8158899545669556
Validation loss: 2.043131267031034

Epoch: 5| Step: 8
Training loss: 3.1781814098358154
Validation loss: 2.040239080786705

Epoch: 5| Step: 9
Training loss: 2.353908061981201
Validation loss: 2.0303528805573783

Epoch: 5| Step: 10
Training loss: 2.4361460208892822
Validation loss: 2.025718172391256

Epoch: 5| Step: 11
Training loss: 2.7536938190460205
Validation loss: 2.020253598690033

Epoch: 76| Step: 0
Training loss: 2.3983561992645264
Validation loss: 2.0293586552143097

Epoch: 5| Step: 1
Training loss: 2.2053043842315674
Validation loss: 2.037390107909838

Epoch: 5| Step: 2
Training loss: 2.2703380584716797
Validation loss: 2.0411007901032767

Epoch: 5| Step: 3
Training loss: 1.822119116783142
Validation loss: 2.045572578907013

Epoch: 5| Step: 4
Training loss: 2.0235273838043213
Validation loss: 2.0439325074354806

Epoch: 5| Step: 5
Training loss: 2.4530367851257324
Validation loss: 2.049585501352946

Epoch: 5| Step: 6
Training loss: 2.283710479736328
Validation loss: 2.049518202741941

Epoch: 5| Step: 7
Training loss: 1.7089555263519287
Validation loss: 2.045367106795311

Epoch: 5| Step: 8
Training loss: 2.7508208751678467
Validation loss: 2.038443182905515

Epoch: 5| Step: 9
Training loss: 2.017096757888794
Validation loss: 2.0440357327461243

Epoch: 5| Step: 10
Training loss: 2.6491000652313232
Validation loss: 2.0433945457140603

Epoch: 5| Step: 11
Training loss: 1.9521633386611938
Validation loss: 2.03880612552166

Epoch: 77| Step: 0
Training loss: 2.3112680912017822
Validation loss: 2.0311060349146524

Epoch: 5| Step: 1
Training loss: 2.1546943187713623
Validation loss: 2.023539811372757

Epoch: 5| Step: 2
Training loss: 2.280742883682251
Validation loss: 2.025519366065661

Epoch: 5| Step: 3
Training loss: 1.987592339515686
Validation loss: 2.0228622953097024

Epoch: 5| Step: 4
Training loss: 2.019644260406494
Validation loss: 2.0233305195967355

Epoch: 5| Step: 5
Training loss: 2.2653326988220215
Validation loss: 2.025393635034561

Epoch: 5| Step: 6
Training loss: 2.091660261154175
Validation loss: 2.0257094701131186

Epoch: 5| Step: 7
Training loss: 2.0189380645751953
Validation loss: 2.0240320513645806

Epoch: 5| Step: 8
Training loss: 2.867257595062256
Validation loss: 2.0298551668723426

Epoch: 5| Step: 9
Training loss: 2.4820151329040527
Validation loss: 2.0375999063253403

Epoch: 5| Step: 10
Training loss: 1.7615970373153687
Validation loss: 2.0445864697297416

Epoch: 5| Step: 11
Training loss: 2.032705783843994
Validation loss: 2.0336710661649704

Epoch: 78| Step: 0
Training loss: 2.759401798248291
Validation loss: 2.0413450251022973

Epoch: 5| Step: 1
Training loss: 2.4263224601745605
Validation loss: 2.0443254510561624

Epoch: 5| Step: 2
Training loss: 2.111572027206421
Validation loss: 2.0333538353443146

Epoch: 5| Step: 3
Training loss: 2.5074689388275146
Validation loss: 2.0273161182800927

Epoch: 5| Step: 4
Training loss: 2.4011454582214355
Validation loss: 2.0176359017690024

Epoch: 5| Step: 5
Training loss: 2.143751859664917
Validation loss: 2.014493559797605

Epoch: 5| Step: 6
Training loss: 2.4851901531219482
Validation loss: 2.0154745876789093

Epoch: 5| Step: 7
Training loss: 1.9668651819229126
Validation loss: 2.0215873420238495

Epoch: 5| Step: 8
Training loss: 1.678540825843811
Validation loss: 2.022833824157715

Epoch: 5| Step: 9
Training loss: 2.412769317626953
Validation loss: 2.021723583340645

Epoch: 5| Step: 10
Training loss: 1.5473653078079224
Validation loss: 2.01888744533062

Epoch: 5| Step: 11
Training loss: 1.7676975727081299
Validation loss: 2.0205269753932953

Epoch: 79| Step: 0
Training loss: 2.4155526161193848
Validation loss: 2.0234120736519494

Epoch: 5| Step: 1
Training loss: 2.3783459663391113
Validation loss: 2.023134092489878

Epoch: 5| Step: 2
Training loss: 2.4309990406036377
Validation loss: 2.0207987229029336

Epoch: 5| Step: 3
Training loss: 2.3515572547912598
Validation loss: 2.0207866777976355

Epoch: 5| Step: 4
Training loss: 2.048600435256958
Validation loss: 2.01942544678847

Epoch: 5| Step: 5
Training loss: 2.1181528568267822
Validation loss: 2.0195698887109756

Epoch: 5| Step: 6
Training loss: 2.0812442302703857
Validation loss: 2.0180981159210205

Epoch: 5| Step: 7
Training loss: 1.7745304107666016
Validation loss: 2.0117963204781213

Epoch: 5| Step: 8
Training loss: 2.1024386882781982
Validation loss: 2.013424431284269

Epoch: 5| Step: 9
Training loss: 2.0933780670166016
Validation loss: 2.0201486945152283

Epoch: 5| Step: 10
Training loss: 2.53796124458313
Validation loss: 2.0118135064840317

Epoch: 5| Step: 11
Training loss: 1.6559746265411377
Validation loss: 2.0252683560053506

Epoch: 80| Step: 0
Training loss: 1.4802348613739014
Validation loss: 2.018468181292216

Epoch: 5| Step: 1
Training loss: 1.7168267965316772
Validation loss: 2.033369223276774

Epoch: 5| Step: 2
Training loss: 2.432969570159912
Validation loss: 2.023244092861811

Epoch: 5| Step: 3
Training loss: 2.4984488487243652
Validation loss: 2.03040803472201

Epoch: 5| Step: 4
Training loss: 2.339240789413452
Validation loss: 2.0348791579405465

Epoch: 5| Step: 5
Training loss: 2.924908399581909
Validation loss: 2.0244363248348236

Epoch: 5| Step: 6
Training loss: 2.5499489307403564
Validation loss: 2.025998517870903

Epoch: 5| Step: 7
Training loss: 2.0190553665161133
Validation loss: 2.0173576275507608

Epoch: 5| Step: 8
Training loss: 2.3995683193206787
Validation loss: 2.0129676262537637

Epoch: 5| Step: 9
Training loss: 2.4691708087921143
Validation loss: 2.0137638549009957

Epoch: 5| Step: 10
Training loss: 1.4383139610290527
Validation loss: 2.017320901155472

Epoch: 5| Step: 11
Training loss: 1.4661381244659424
Validation loss: 2.0136295904715857

Epoch: 81| Step: 0
Training loss: 2.2647056579589844
Validation loss: 2.0144225607315698

Epoch: 5| Step: 1
Training loss: 2.417815685272217
Validation loss: 2.013909801840782

Epoch: 5| Step: 2
Training loss: 2.0687131881713867
Validation loss: 2.013738587498665

Epoch: 5| Step: 3
Training loss: 2.2405223846435547
Validation loss: 2.0157390236854553

Epoch: 5| Step: 4
Training loss: 2.0922887325286865
Validation loss: 2.012039894858996

Epoch: 5| Step: 5
Training loss: 1.9974002838134766
Validation loss: 2.016597405076027

Epoch: 5| Step: 6
Training loss: 2.531472682952881
Validation loss: 2.0185041576623917

Epoch: 5| Step: 7
Training loss: 2.298816204071045
Validation loss: 2.028740202387174

Epoch: 5| Step: 8
Training loss: 1.973325490951538
Validation loss: 2.0215200086434684

Epoch: 5| Step: 9
Training loss: 2.144235134124756
Validation loss: 2.016645163297653

Epoch: 5| Step: 10
Training loss: 1.82554030418396
Validation loss: 2.0141209959983826

Epoch: 5| Step: 11
Training loss: 3.208436965942383
Validation loss: 2.0254003008206687

Epoch: 82| Step: 0
Training loss: 2.369138240814209
Validation loss: 2.021371752023697

Epoch: 5| Step: 1
Training loss: 2.14855694770813
Validation loss: 2.0211154570182166

Epoch: 5| Step: 2
Training loss: 2.18768048286438
Validation loss: 2.0263719161351523

Epoch: 5| Step: 3
Training loss: 1.9077749252319336
Validation loss: 2.020385354757309

Epoch: 5| Step: 4
Training loss: 2.615612745285034
Validation loss: 2.0151809006929398

Epoch: 5| Step: 5
Training loss: 2.3318240642547607
Validation loss: 2.0166846563418708

Epoch: 5| Step: 6
Training loss: 1.935340166091919
Validation loss: 2.0200839738051095

Epoch: 5| Step: 7
Training loss: 1.6224454641342163
Validation loss: 2.0130410492420197

Epoch: 5| Step: 8
Training loss: 2.2642409801483154
Validation loss: 2.015174006422361

Epoch: 5| Step: 9
Training loss: 2.2461354732513428
Validation loss: 2.0133183747529984

Epoch: 5| Step: 10
Training loss: 2.216135025024414
Validation loss: 2.0183707773685455

Epoch: 5| Step: 11
Training loss: 2.6328461170196533
Validation loss: 2.020933225750923

Epoch: 83| Step: 0
Training loss: 1.247930884361267
Validation loss: 2.0177192638317742

Epoch: 5| Step: 1
Training loss: 2.690871238708496
Validation loss: 2.012024372816086

Epoch: 5| Step: 2
Training loss: 2.5784246921539307
Validation loss: 2.007174332936605

Epoch: 5| Step: 3
Training loss: 2.3497567176818848
Validation loss: 2.0150569826364517

Epoch: 5| Step: 4
Training loss: 2.9051263332366943
Validation loss: 2.009142890572548

Epoch: 5| Step: 5
Training loss: 1.8920402526855469
Validation loss: 2.0104791025320687

Epoch: 5| Step: 6
Training loss: 1.9741542339324951
Validation loss: 2.0116027941306434

Epoch: 5| Step: 7
Training loss: 2.7793993949890137
Validation loss: 2.0079020659128823

Epoch: 5| Step: 8
Training loss: 1.7380644083023071
Validation loss: 2.0037904928127923

Epoch: 5| Step: 9
Training loss: 1.6354236602783203
Validation loss: 2.00303553044796

Epoch: 5| Step: 10
Training loss: 2.301285982131958
Validation loss: 2.0042805473009744

Epoch: 5| Step: 11
Training loss: 1.6691287755966187
Validation loss: 2.0091652820507684

Epoch: 84| Step: 0
Training loss: 2.256408214569092
Validation loss: 2.00586607058843

Epoch: 5| Step: 1
Training loss: 1.748835563659668
Validation loss: 2.004769444465637

Epoch: 5| Step: 2
Training loss: 1.6499903202056885
Validation loss: 2.007493724425634

Epoch: 5| Step: 3
Training loss: 2.404961109161377
Validation loss: 1.9971138288577397

Epoch: 5| Step: 4
Training loss: 1.6596896648406982
Validation loss: 2.0022349109252295

Epoch: 5| Step: 5
Training loss: 2.8541290760040283
Validation loss: 2.004864757259687

Epoch: 5| Step: 6
Training loss: 1.9638420343399048
Validation loss: 2.0012000848849616

Epoch: 5| Step: 7
Training loss: 3.1237971782684326
Validation loss: 2.0041758666435876

Epoch: 5| Step: 8
Training loss: 2.2575881481170654
Validation loss: 2.00474181274573

Epoch: 5| Step: 9
Training loss: 2.0643069744110107
Validation loss: 2.006690392891566

Epoch: 5| Step: 10
Training loss: 2.0711076259613037
Validation loss: 2.0065779288609824

Epoch: 5| Step: 11
Training loss: 1.1106255054473877
Validation loss: 2.009222740928332

Epoch: 85| Step: 0
Training loss: 1.8076744079589844
Validation loss: 2.012574464082718

Epoch: 5| Step: 1
Training loss: 2.3060104846954346
Validation loss: 2.0225559820731482

Epoch: 5| Step: 2
Training loss: 2.1339502334594727
Validation loss: 2.0201822767655053

Epoch: 5| Step: 3
Training loss: 2.6299705505371094
Validation loss: 2.023718367020289

Epoch: 5| Step: 4
Training loss: 1.8972365856170654
Validation loss: 2.0185007403294244

Epoch: 5| Step: 5
Training loss: 2.3932275772094727
Validation loss: 2.0315338323513665

Epoch: 5| Step: 6
Training loss: 1.9659818410873413
Validation loss: 2.038101385037104

Epoch: 5| Step: 7
Training loss: 2.0724568367004395
Validation loss: 2.0490906884272895

Epoch: 5| Step: 8
Training loss: 1.8063997030258179
Validation loss: 2.054888998468717

Epoch: 5| Step: 9
Training loss: 2.63787579536438
Validation loss: 2.0661985923846564

Epoch: 5| Step: 10
Training loss: 2.088642120361328
Validation loss: 2.055445929368337

Epoch: 5| Step: 11
Training loss: 4.021936416625977
Validation loss: 2.047354872028033

Epoch: 86| Step: 0
Training loss: 2.517427682876587
Validation loss: 2.030230075120926

Epoch: 5| Step: 1
Training loss: 1.6048015356063843
Validation loss: 2.031466613213221

Epoch: 5| Step: 2
Training loss: 1.6140317916870117
Validation loss: 2.0120985905329385

Epoch: 5| Step: 3
Training loss: 2.062288284301758
Validation loss: 2.017232154806455

Epoch: 5| Step: 4
Training loss: 2.556816577911377
Validation loss: 2.0129707554976144

Epoch: 5| Step: 5
Training loss: 2.108546733856201
Validation loss: 2.0095461209615073

Epoch: 5| Step: 6
Training loss: 2.3928775787353516
Validation loss: 2.015927563110987

Epoch: 5| Step: 7
Training loss: 1.753008484840393
Validation loss: 2.0119720002015433

Epoch: 5| Step: 8
Training loss: 2.3205533027648926
Validation loss: 2.0204428335030875

Epoch: 5| Step: 9
Training loss: 2.5980470180511475
Validation loss: 2.0209120512008667

Epoch: 5| Step: 10
Training loss: 2.2921030521392822
Validation loss: 2.0221117238203683

Epoch: 5| Step: 11
Training loss: 1.7037816047668457
Validation loss: 2.0192927718162537

Epoch: 87| Step: 0
Training loss: 1.8680391311645508
Validation loss: 2.0201671719551086

Epoch: 5| Step: 1
Training loss: 2.5260767936706543
Validation loss: 2.0224071045716605

Epoch: 5| Step: 2
Training loss: 2.400085926055908
Validation loss: 2.0226587603489556

Epoch: 5| Step: 3
Training loss: 2.084062099456787
Validation loss: 2.0212780088186264

Epoch: 5| Step: 4
Training loss: 2.074392318725586
Validation loss: 2.022974585493406

Epoch: 5| Step: 5
Training loss: 2.414304256439209
Validation loss: 2.0182869136333466

Epoch: 5| Step: 6
Training loss: 1.7265489101409912
Validation loss: 2.012139067053795

Epoch: 5| Step: 7
Training loss: 2.52885103225708
Validation loss: 2.011440654595693

Epoch: 5| Step: 8
Training loss: 2.349550485610962
Validation loss: 2.0154066930214563

Epoch: 5| Step: 9
Training loss: 1.994657278060913
Validation loss: 2.008243883649508

Epoch: 5| Step: 10
Training loss: 2.1922621726989746
Validation loss: 2.0057292381922402

Epoch: 5| Step: 11
Training loss: 0.7023848295211792
Validation loss: 2.0180245439211526

Epoch: 88| Step: 0
Training loss: 2.0325441360473633
Validation loss: 2.016836812098821

Epoch: 5| Step: 1
Training loss: 2.2063469886779785
Validation loss: 2.0221969236930213

Epoch: 5| Step: 2
Training loss: 1.4977061748504639
Validation loss: 2.0252777685721717

Epoch: 5| Step: 3
Training loss: 2.406928539276123
Validation loss: 2.03507528702418

Epoch: 5| Step: 4
Training loss: 2.172975540161133
Validation loss: 2.0337977011998496

Epoch: 5| Step: 5
Training loss: 1.7661319971084595
Validation loss: 2.0308935791254044

Epoch: 5| Step: 6
Training loss: 2.412926435470581
Validation loss: 2.0329781621694565

Epoch: 5| Step: 7
Training loss: 2.6967005729675293
Validation loss: 2.0348172088464103

Epoch: 5| Step: 8
Training loss: 2.264641523361206
Validation loss: 2.0247888465722403

Epoch: 5| Step: 9
Training loss: 2.2341866493225098
Validation loss: 2.0231912632783255

Epoch: 5| Step: 10
Training loss: 2.2267048358917236
Validation loss: 2.009912500778834

Epoch: 5| Step: 11
Training loss: 1.5344902276992798
Validation loss: 2.013193890452385

Epoch: 89| Step: 0
Training loss: 2.291170835494995
Validation loss: 2.0130309959252677

Epoch: 5| Step: 1
Training loss: 1.926117181777954
Validation loss: 2.010342155893644

Epoch: 5| Step: 2
Training loss: 1.989831566810608
Validation loss: 2.016114021341006

Epoch: 5| Step: 3
Training loss: 2.198136568069458
Validation loss: 2.0141001294056573

Epoch: 5| Step: 4
Training loss: 2.2444701194763184
Validation loss: 2.023629685242971

Epoch: 5| Step: 5
Training loss: 2.1411290168762207
Validation loss: 2.0198073784510293

Epoch: 5| Step: 6
Training loss: 2.0313880443573
Validation loss: 2.0171165515979133

Epoch: 5| Step: 7
Training loss: 2.094282865524292
Validation loss: 2.0194664299488068

Epoch: 5| Step: 8
Training loss: 2.424251079559326
Validation loss: 2.0228802263736725

Epoch: 5| Step: 9
Training loss: 2.013051748275757
Validation loss: 2.023433710138003

Epoch: 5| Step: 10
Training loss: 2.488323926925659
Validation loss: 2.023988296588262

Epoch: 5| Step: 11
Training loss: 1.109721302986145
Validation loss: 2.027049938837687

Epoch: 90| Step: 0
Training loss: 1.9757152795791626
Validation loss: 2.0340298612912497

Epoch: 5| Step: 1
Training loss: 2.4853148460388184
Validation loss: 2.030573770403862

Epoch: 5| Step: 2
Training loss: 2.3813674449920654
Validation loss: 2.0353015661239624

Epoch: 5| Step: 3
Training loss: 2.380688428878784
Validation loss: 2.037061870098114

Epoch: 5| Step: 4
Training loss: 1.8538001775741577
Validation loss: 2.0541038811206818

Epoch: 5| Step: 5
Training loss: 1.604717493057251
Validation loss: 2.0477271378040314

Epoch: 5| Step: 6
Training loss: 2.757920026779175
Validation loss: 2.0416533748308816

Epoch: 5| Step: 7
Training loss: 2.5377488136291504
Validation loss: 2.0538177539904914

Epoch: 5| Step: 8
Training loss: 1.2744251489639282
Validation loss: 2.034404377142588

Epoch: 5| Step: 9
Training loss: 2.2820632457733154
Validation loss: 2.0266563097635903

Epoch: 5| Step: 10
Training loss: 2.4815874099731445
Validation loss: 2.0185278952121735

Epoch: 5| Step: 11
Training loss: 1.1988840103149414
Validation loss: 2.0120391498009362

Epoch: 91| Step: 0
Training loss: 2.003117084503174
Validation loss: 2.0139252692461014

Epoch: 5| Step: 1
Training loss: 2.368572950363159
Validation loss: 2.02610744535923

Epoch: 5| Step: 2
Training loss: 1.9262968301773071
Validation loss: 2.033852015932401

Epoch: 5| Step: 3
Training loss: 2.133028030395508
Validation loss: 2.040406718850136

Epoch: 5| Step: 4
Training loss: 2.0998857021331787
Validation loss: 2.0400636196136475

Epoch: 5| Step: 5
Training loss: 2.729796886444092
Validation loss: 2.044056405623754

Epoch: 5| Step: 6
Training loss: 2.372960090637207
Validation loss: 2.0438309609889984

Epoch: 5| Step: 7
Training loss: 2.194387435913086
Validation loss: 2.0448646495739617

Epoch: 5| Step: 8
Training loss: 2.7458927631378174
Validation loss: 2.0390909562508264

Epoch: 5| Step: 9
Training loss: 2.132230758666992
Validation loss: 2.038088043530782

Epoch: 5| Step: 10
Training loss: 1.6407979726791382
Validation loss: 2.034162243207296

Epoch: 5| Step: 11
Training loss: 1.6756397485733032
Validation loss: 2.0355908324321113

Epoch: 92| Step: 0
Training loss: 2.2811214923858643
Validation loss: 2.0343694587548575

Epoch: 5| Step: 1
Training loss: 1.8320026397705078
Validation loss: 2.03120227654775

Epoch: 5| Step: 2
Training loss: 2.509899616241455
Validation loss: 2.0287803212801614

Epoch: 5| Step: 3
Training loss: 1.9857547283172607
Validation loss: 2.0237939854462943

Epoch: 5| Step: 4
Training loss: 2.3585593700408936
Validation loss: 2.0229642490545907

Epoch: 5| Step: 5
Training loss: 2.3507633209228516
Validation loss: 2.0238991330067315

Epoch: 5| Step: 6
Training loss: 2.5352864265441895
Validation loss: 2.0237272133429847

Epoch: 5| Step: 7
Training loss: 2.1315560340881348
Validation loss: 2.032983427246412

Epoch: 5| Step: 8
Training loss: 2.189936399459839
Validation loss: 2.0487637519836426

Epoch: 5| Step: 9
Training loss: 2.0785937309265137
Validation loss: 2.042416661977768

Epoch: 5| Step: 10
Training loss: 1.8482338190078735
Validation loss: 2.033207635084788

Epoch: 5| Step: 11
Training loss: 2.5747408866882324
Validation loss: 2.0466657876968384

Epoch: 93| Step: 0
Training loss: 1.9050061702728271
Validation loss: 2.0326062937577567

Epoch: 5| Step: 1
Training loss: 2.1345248222351074
Validation loss: 2.031765023867289

Epoch: 5| Step: 2
Training loss: 2.376699447631836
Validation loss: 2.0306731313467026

Epoch: 5| Step: 3
Training loss: 1.6425997018814087
Validation loss: 2.019531806310018

Epoch: 5| Step: 4
Training loss: 2.774799346923828
Validation loss: 2.0246289720137916

Epoch: 5| Step: 5
Training loss: 1.9337056875228882
Validation loss: 2.0119542330503464

Epoch: 5| Step: 6
Training loss: 2.07023286819458
Validation loss: 2.015060395002365

Epoch: 5| Step: 7
Training loss: 2.0729737281799316
Validation loss: 2.0168541024128595

Epoch: 5| Step: 8
Training loss: 2.074859142303467
Validation loss: 2.0123262653748193

Epoch: 5| Step: 9
Training loss: 2.2325170040130615
Validation loss: 2.0066210279862084

Epoch: 5| Step: 10
Training loss: 2.3003106117248535
Validation loss: 2.0051269779602685

Epoch: 5| Step: 11
Training loss: 2.548766613006592
Validation loss: 2.012094189723333

Epoch: 94| Step: 0
Training loss: 2.5306079387664795
Validation loss: 2.0033687502145767

Epoch: 5| Step: 1
Training loss: 2.7765040397644043
Validation loss: 2.0053994903961816

Epoch: 5| Step: 2
Training loss: 2.212554693222046
Validation loss: 2.0062882751226425

Epoch: 5| Step: 3
Training loss: 2.283778667449951
Validation loss: 2.006823316216469

Epoch: 5| Step: 4
Training loss: 2.459184169769287
Validation loss: 2.0097643534342446

Epoch: 5| Step: 5
Training loss: 1.8696794509887695
Validation loss: 2.0085964302221933

Epoch: 5| Step: 6
Training loss: 2.0452425479888916
Validation loss: 2.0038162072499595

Epoch: 5| Step: 7
Training loss: 1.5085607767105103
Validation loss: 2.0072080194950104

Epoch: 5| Step: 8
Training loss: 1.7541803121566772
Validation loss: 2.0017605870962143

Epoch: 5| Step: 9
Training loss: 2.163231611251831
Validation loss: 2.01393191019694

Epoch: 5| Step: 10
Training loss: 2.1533279418945312
Validation loss: 2.011440023779869

Epoch: 5| Step: 11
Training loss: 1.55939519405365
Validation loss: 2.0122825453678765

Epoch: 95| Step: 0
Training loss: 2.146383047103882
Validation loss: 2.015447353323301

Epoch: 5| Step: 1
Training loss: 2.4464306831359863
Validation loss: 2.0126193463802338

Epoch: 5| Step: 2
Training loss: 1.9976383447647095
Validation loss: 2.009146526455879

Epoch: 5| Step: 3
Training loss: 1.9645450115203857
Validation loss: 2.01808009048303

Epoch: 5| Step: 4
Training loss: 2.2346363067626953
Validation loss: 2.007413143912951

Epoch: 5| Step: 5
Training loss: 2.115480899810791
Validation loss: 2.0112643589576087

Epoch: 5| Step: 6
Training loss: 2.018620729446411
Validation loss: 2.0187015434106192

Epoch: 5| Step: 7
Training loss: 2.6405768394470215
Validation loss: 2.014226963122686

Epoch: 5| Step: 8
Training loss: 2.233907699584961
Validation loss: 2.017297620574633

Epoch: 5| Step: 9
Training loss: 1.9484288692474365
Validation loss: 2.0199765165646872

Epoch: 5| Step: 10
Training loss: 1.8146146535873413
Validation loss: 2.0176552136739097

Epoch: 5| Step: 11
Training loss: 2.186607837677002
Validation loss: 2.014190206925074

Epoch: 96| Step: 0
Training loss: 2.287736415863037
Validation loss: 2.0208238661289215

Epoch: 5| Step: 1
Training loss: 2.1057021617889404
Validation loss: 2.0220919797817865

Epoch: 5| Step: 2
Training loss: 1.9177509546279907
Validation loss: 2.024739215771357

Epoch: 5| Step: 3
Training loss: 2.075303316116333
Validation loss: 2.026264190673828

Epoch: 5| Step: 4
Training loss: 2.1963446140289307
Validation loss: 2.032575155297915

Epoch: 5| Step: 5
Training loss: 2.2820143699645996
Validation loss: 2.0392110844453177

Epoch: 5| Step: 6
Training loss: 1.895395040512085
Validation loss: 2.0359378357728324

Epoch: 5| Step: 7
Training loss: 2.6103899478912354
Validation loss: 2.0404009471337

Epoch: 5| Step: 8
Training loss: 1.9363571405410767
Validation loss: 2.0497254381577172

Epoch: 5| Step: 9
Training loss: 2.7203598022460938
Validation loss: 2.0381587892770767

Epoch: 5| Step: 10
Training loss: 1.9185718297958374
Validation loss: 2.03661439816157

Epoch: 5| Step: 11
Training loss: 1.1584140062332153
Validation loss: 2.0238881607850394

Epoch: 97| Step: 0
Training loss: 2.359679698944092
Validation loss: 2.024475653966268

Epoch: 5| Step: 1
Training loss: 2.196289539337158
Validation loss: 2.016199385126432

Epoch: 5| Step: 2
Training loss: 2.689347505569458
Validation loss: 2.019729365905126

Epoch: 5| Step: 3
Training loss: 1.9852323532104492
Validation loss: 2.019186094403267

Epoch: 5| Step: 4
Training loss: 1.6767804622650146
Validation loss: 2.020345166325569

Epoch: 5| Step: 5
Training loss: 2.3564326763153076
Validation loss: 2.0197911312182746

Epoch: 5| Step: 6
Training loss: 2.0780189037323
Validation loss: 2.0256475806236267

Epoch: 5| Step: 7
Training loss: 2.4868576526641846
Validation loss: 2.031224568684896

Epoch: 5| Step: 8
Training loss: 1.927016258239746
Validation loss: 2.0315141479174295

Epoch: 5| Step: 9
Training loss: 2.588144302368164
Validation loss: 2.036608040332794

Epoch: 5| Step: 10
Training loss: 1.4629700183868408
Validation loss: 2.0327629844347634

Epoch: 5| Step: 11
Training loss: 1.4220800399780273
Validation loss: 2.028686821460724

Epoch: 98| Step: 0
Training loss: 2.393455982208252
Validation loss: 2.027652144432068

Epoch: 5| Step: 1
Training loss: 1.886728048324585
Validation loss: 2.019642616311709

Epoch: 5| Step: 2
Training loss: 2.3377461433410645
Validation loss: 2.021200805902481

Epoch: 5| Step: 3
Training loss: 2.0452213287353516
Validation loss: 2.020914375782013

Epoch: 5| Step: 4
Training loss: 1.8886268138885498
Validation loss: 2.014091203610102

Epoch: 5| Step: 5
Training loss: 2.704289674758911
Validation loss: 2.0220629572868347

Epoch: 5| Step: 6
Training loss: 1.729997992515564
Validation loss: 2.026661862929662

Epoch: 5| Step: 7
Training loss: 2.0710489749908447
Validation loss: 2.0361506839593253

Epoch: 5| Step: 8
Training loss: 2.053304672241211
Validation loss: 2.034527371327082

Epoch: 5| Step: 9
Training loss: 2.1411895751953125
Validation loss: 2.0380077213048935

Epoch: 5| Step: 10
Training loss: 2.065857172012329
Validation loss: 2.038273056348165

Epoch: 5| Step: 11
Training loss: 2.9856176376342773
Validation loss: 2.0325536827246347

Epoch: 99| Step: 0
Training loss: 1.713492751121521
Validation loss: 2.0543416291475296

Epoch: 5| Step: 1
Training loss: 2.4405601024627686
Validation loss: 2.052795191605886

Epoch: 5| Step: 2
Training loss: 2.9993088245391846
Validation loss: 2.0624066839615502

Epoch: 5| Step: 3
Training loss: 2.189612627029419
Validation loss: 2.0536622355381646

Epoch: 5| Step: 4
Training loss: 2.1165332794189453
Validation loss: 2.054375186562538

Epoch: 5| Step: 5
Training loss: 1.7814085483551025
Validation loss: 2.0523944000403085

Epoch: 5| Step: 6
Training loss: 1.744066596031189
Validation loss: 2.041138529777527

Epoch: 5| Step: 7
Training loss: 2.746626615524292
Validation loss: 2.0303612500429153

Epoch: 5| Step: 8
Training loss: 2.1232733726501465
Validation loss: 2.0264845242102942

Epoch: 5| Step: 9
Training loss: 2.044811725616455
Validation loss: 2.0154708474874496

Epoch: 5| Step: 10
Training loss: 1.8047914505004883
Validation loss: 2.014163091778755

Epoch: 5| Step: 11
Training loss: 2.555514335632324
Validation loss: 2.0156231423219046

Epoch: 100| Step: 0
Training loss: 1.5564252138137817
Validation loss: 2.0159016996622086

Epoch: 5| Step: 1
Training loss: 2.4256844520568848
Validation loss: 2.0190946459770203

Epoch: 5| Step: 2
Training loss: 2.1090617179870605
Validation loss: 2.0145351638396582

Epoch: 5| Step: 3
Training loss: 2.415346622467041
Validation loss: 2.016858865817388

Epoch: 5| Step: 4
Training loss: 2.3147339820861816
Validation loss: 2.0195285429557166

Epoch: 5| Step: 5
Training loss: 2.231910228729248
Validation loss: 2.021039734284083

Epoch: 5| Step: 6
Training loss: 2.5900652408599854
Validation loss: 2.021550844113032

Epoch: 5| Step: 7
Training loss: 1.8344053030014038
Validation loss: 2.0224179377158484

Epoch: 5| Step: 8
Training loss: 2.2595951557159424
Validation loss: 2.0223378290732703

Epoch: 5| Step: 9
Training loss: 2.1998531818389893
Validation loss: 2.0245224436124167

Epoch: 5| Step: 10
Training loss: 1.9509871006011963
Validation loss: 2.022409295042356

Epoch: 5| Step: 11
Training loss: 1.9561764001846313
Validation loss: 2.012497286001841

Epoch: 101| Step: 0
Training loss: 2.5107789039611816
Validation loss: 2.018880953391393

Epoch: 5| Step: 1
Training loss: 1.659158706665039
Validation loss: 2.0137354532877603

Epoch: 5| Step: 2
Training loss: 2.477329969406128
Validation loss: 2.01310462752978

Epoch: 5| Step: 3
Training loss: 1.7913014888763428
Validation loss: 2.007689207792282

Epoch: 5| Step: 4
Training loss: 1.9548650979995728
Validation loss: 2.007228747010231

Epoch: 5| Step: 5
Training loss: 1.6836967468261719
Validation loss: 2.0090250422557197

Epoch: 5| Step: 6
Training loss: 2.604109525680542
Validation loss: 2.016241028904915

Epoch: 5| Step: 7
Training loss: 1.9962244033813477
Validation loss: 2.018115927775701

Epoch: 5| Step: 8
Training loss: 2.565117359161377
Validation loss: 2.0189459224541983

Epoch: 5| Step: 9
Training loss: 2.4608054161071777
Validation loss: 2.019208093484243

Epoch: 5| Step: 10
Training loss: 1.869381308555603
Validation loss: 2.019175445040067

Epoch: 5| Step: 11
Training loss: 2.5671000480651855
Validation loss: 2.0112109581629434

Epoch: 102| Step: 0
Training loss: 2.1559062004089355
Validation loss: 2.0232144594192505

Epoch: 5| Step: 1
Training loss: 1.5555615425109863
Validation loss: 2.02590648829937

Epoch: 5| Step: 2
Training loss: 2.303041934967041
Validation loss: 2.03315939505895

Epoch: 5| Step: 3
Training loss: 2.2124686241149902
Validation loss: 2.0447721232970557

Epoch: 5| Step: 4
Training loss: 2.2490203380584717
Validation loss: 2.035977060596148

Epoch: 5| Step: 5
Training loss: 2.265717029571533
Validation loss: 2.040695920586586

Epoch: 5| Step: 6
Training loss: 2.2045631408691406
Validation loss: 2.0318314830462136

Epoch: 5| Step: 7
Training loss: 2.3466429710388184
Validation loss: 2.0349000841379166

Epoch: 5| Step: 8
Training loss: 1.7528972625732422
Validation loss: 2.041379059354464

Epoch: 5| Step: 9
Training loss: 2.606529712677002
Validation loss: 2.0367427319288254

Epoch: 5| Step: 10
Training loss: 1.622521162033081
Validation loss: 2.0317628433307013

Epoch: 5| Step: 11
Training loss: 3.2030818462371826
Validation loss: 2.0332258393367133

Epoch: 103| Step: 0
Training loss: 2.3818345069885254
Validation loss: 2.0298212518294654

Epoch: 5| Step: 1
Training loss: 2.1535286903381348
Validation loss: 2.0242415368556976

Epoch: 5| Step: 2
Training loss: 1.966383695602417
Validation loss: 2.019033595919609

Epoch: 5| Step: 3
Training loss: 1.863844633102417
Validation loss: 2.008594418565432

Epoch: 5| Step: 4
Training loss: 1.6448522806167603
Validation loss: 2.01556367178758

Epoch: 5| Step: 5
Training loss: 2.596676826477051
Validation loss: 2.0068514943122864

Epoch: 5| Step: 6
Training loss: 2.3961939811706543
Validation loss: 2.0082601656516395

Epoch: 5| Step: 7
Training loss: 1.9199044704437256
Validation loss: 2.0070349077383676

Epoch: 5| Step: 8
Training loss: 2.1412665843963623
Validation loss: 2.002096196015676

Epoch: 5| Step: 9
Training loss: 2.2605128288269043
Validation loss: 2.0039813866217933

Epoch: 5| Step: 10
Training loss: 2.2630817890167236
Validation loss: 2.0074358681837716

Epoch: 5| Step: 11
Training loss: 2.5962347984313965
Validation loss: 2.005487690369288

Epoch: 104| Step: 0
Training loss: 2.0971977710723877
Validation loss: 2.004659761985143

Epoch: 5| Step: 1
Training loss: 2.675184965133667
Validation loss: 2.0072851131359735

Epoch: 5| Step: 2
Training loss: 1.8308645486831665
Validation loss: 2.0111494114001593

Epoch: 5| Step: 3
Training loss: 2.5836381912231445
Validation loss: 2.0127288103103638

Epoch: 5| Step: 4
Training loss: 2.345602035522461
Validation loss: 2.011100709438324

Epoch: 5| Step: 5
Training loss: 1.5952342748641968
Validation loss: 2.008337323864301

Epoch: 5| Step: 6
Training loss: 2.4143548011779785
Validation loss: 2.0080906401077905

Epoch: 5| Step: 7
Training loss: 2.2126247882843018
Validation loss: 1.999885156750679

Epoch: 5| Step: 8
Training loss: 2.1643850803375244
Validation loss: 1.9967630008856456

Epoch: 5| Step: 9
Training loss: 1.7852319478988647
Validation loss: 2.011180207133293

Epoch: 5| Step: 10
Training loss: 2.012725830078125
Validation loss: 2.017138918240865

Epoch: 5| Step: 11
Training loss: 1.9134900569915771
Validation loss: 2.0274452616771064

Epoch: 105| Step: 0
Training loss: 1.7359530925750732
Validation loss: 2.035632168253263

Epoch: 5| Step: 1
Training loss: 2.754418134689331
Validation loss: 2.043685997525851

Epoch: 5| Step: 2
Training loss: 2.5769615173339844
Validation loss: 2.0403537501891456

Epoch: 5| Step: 3
Training loss: 1.9480587244033813
Validation loss: 2.060971568028132

Epoch: 5| Step: 4
Training loss: 2.9572641849517822
Validation loss: 2.0585066179434457

Epoch: 5| Step: 5
Training loss: 2.0636324882507324
Validation loss: 2.054705778757731

Epoch: 5| Step: 6
Training loss: 2.0954952239990234
Validation loss: 2.041610156496366

Epoch: 5| Step: 7
Training loss: 2.2992727756500244
Validation loss: 2.0485258599122367

Epoch: 5| Step: 8
Training loss: 2.352778673171997
Validation loss: 2.0362644096215567

Epoch: 5| Step: 9
Training loss: 1.2629625797271729
Validation loss: 2.020409574111303

Epoch: 5| Step: 10
Training loss: 2.042966842651367
Validation loss: 2.012148146828016

Epoch: 5| Step: 11
Training loss: 2.3507626056671143
Validation loss: 2.012518251935641

Epoch: 106| Step: 0
Training loss: 2.430758476257324
Validation loss: 2.010132153828939

Epoch: 5| Step: 1
Training loss: 2.2576143741607666
Validation loss: 2.006644348303477

Epoch: 5| Step: 2
Training loss: 2.491032600402832
Validation loss: 2.0105156203111014

Epoch: 5| Step: 3
Training loss: 1.9051787853240967
Validation loss: 2.0159623523553214

Epoch: 5| Step: 4
Training loss: 1.7901279926300049
Validation loss: 2.016782268881798

Epoch: 5| Step: 5
Training loss: 2.6308863162994385
Validation loss: 2.0123887260754905

Epoch: 5| Step: 6
Training loss: 1.8715473413467407
Validation loss: 2.008285626769066

Epoch: 5| Step: 7
Training loss: 2.1235756874084473
Validation loss: 2.009687398870786

Epoch: 5| Step: 8
Training loss: 2.387742519378662
Validation loss: 2.012205943465233

Epoch: 5| Step: 9
Training loss: 2.0062453746795654
Validation loss: 2.010679473479589

Epoch: 5| Step: 10
Training loss: 2.0380702018737793
Validation loss: 2.0082666675249734

Epoch: 5| Step: 11
Training loss: 2.260150909423828
Validation loss: 2.0081454515457153

Epoch: 107| Step: 0
Training loss: 2.2550365924835205
Validation loss: 2.0140567322572074

Epoch: 5| Step: 1
Training loss: 2.1726832389831543
Validation loss: 2.002359449863434

Epoch: 5| Step: 2
Training loss: 1.7746070623397827
Validation loss: 2.0042265951633453

Epoch: 5| Step: 3
Training loss: 2.1585865020751953
Validation loss: 2.000595192114512

Epoch: 5| Step: 4
Training loss: 2.34881329536438
Validation loss: 2.007497971256574

Epoch: 5| Step: 5
Training loss: 2.2633628845214844
Validation loss: 2.0035641491413116

Epoch: 5| Step: 6
Training loss: 1.8298976421356201
Validation loss: 2.009769782423973

Epoch: 5| Step: 7
Training loss: 2.699720859527588
Validation loss: 2.015036955475807

Epoch: 5| Step: 8
Training loss: 1.5767128467559814
Validation loss: 2.0105055620272956

Epoch: 5| Step: 9
Training loss: 1.9560425281524658
Validation loss: 2.0189828673998513

Epoch: 5| Step: 10
Training loss: 2.3581743240356445
Validation loss: 2.0230830361445746

Epoch: 5| Step: 11
Training loss: 3.341780185699463
Validation loss: 2.0232846389214196

Epoch: 108| Step: 0
Training loss: 2.2900149822235107
Validation loss: 2.0263002614180246

Epoch: 5| Step: 1
Training loss: 1.828465223312378
Validation loss: 2.0275809168815613

Epoch: 5| Step: 2
Training loss: 2.627833843231201
Validation loss: 2.0313808917999268

Epoch: 5| Step: 3
Training loss: 2.3602852821350098
Validation loss: 2.037186255057653

Epoch: 5| Step: 4
Training loss: 2.650242328643799
Validation loss: 2.0337990125020347

Epoch: 5| Step: 5
Training loss: 1.4719152450561523
Validation loss: 2.032375122110049

Epoch: 5| Step: 6
Training loss: 1.7181899547576904
Validation loss: 2.0245655129353204

Epoch: 5| Step: 7
Training loss: 1.6870132684707642
Validation loss: 2.0353783120711646

Epoch: 5| Step: 8
Training loss: 2.2567667961120605
Validation loss: 2.019972468415896

Epoch: 5| Step: 9
Training loss: 2.6231205463409424
Validation loss: 2.024513378739357

Epoch: 5| Step: 10
Training loss: 1.811819314956665
Validation loss: 2.027504692475001

Epoch: 5| Step: 11
Training loss: 2.9408650398254395
Validation loss: 2.035238261024157

Epoch: 109| Step: 0
Training loss: 1.7193520069122314
Validation loss: 2.0270807991425195

Epoch: 5| Step: 1
Training loss: 2.339110851287842
Validation loss: 2.024133493502935

Epoch: 5| Step: 2
Training loss: 2.9056549072265625
Validation loss: 2.026850382486979

Epoch: 5| Step: 3
Training loss: 2.0654404163360596
Validation loss: 2.022325793902079

Epoch: 5| Step: 4
Training loss: 1.8332607746124268
Validation loss: 2.0256709456443787

Epoch: 5| Step: 5
Training loss: 2.2413249015808105
Validation loss: 2.025354743003845

Epoch: 5| Step: 6
Training loss: 2.2512576580047607
Validation loss: 2.0241631269454956

Epoch: 5| Step: 7
Training loss: 2.363085985183716
Validation loss: 2.025088613231977

Epoch: 5| Step: 8
Training loss: 1.7224643230438232
Validation loss: 2.0121834129095078

Epoch: 5| Step: 9
Training loss: 2.3153510093688965
Validation loss: 2.0004238883654275

Epoch: 5| Step: 10
Training loss: 1.5119192600250244
Validation loss: 2.001439501841863

Epoch: 5| Step: 11
Training loss: 2.8347368240356445
Validation loss: 2.0054090519746146

Epoch: 110| Step: 0
Training loss: 2.2933707237243652
Validation loss: 2.0074397176504135

Epoch: 5| Step: 1
Training loss: 2.236313581466675
Validation loss: 2.0100430051485696

Epoch: 5| Step: 2
Training loss: 2.487510919570923
Validation loss: 2.004474694530169

Epoch: 5| Step: 3
Training loss: 2.0324487686157227
Validation loss: 2.0137548049290976

Epoch: 5| Step: 4
Training loss: 2.1192142963409424
Validation loss: 2.019713799158732

Epoch: 5| Step: 5
Training loss: 2.0166890621185303
Validation loss: 2.0123049219449363

Epoch: 5| Step: 6
Training loss: 2.37274169921875
Validation loss: 2.008118897676468

Epoch: 5| Step: 7
Training loss: 2.5604965686798096
Validation loss: 2.0080163379510245

Epoch: 5| Step: 8
Training loss: 1.9854532480239868
Validation loss: 2.0179575781027475

Epoch: 5| Step: 9
Training loss: 1.7178512811660767
Validation loss: 2.0074524780114493

Epoch: 5| Step: 10
Training loss: 1.8155295848846436
Validation loss: 2.0148008118073144

Epoch: 5| Step: 11
Training loss: 1.3711551427841187
Validation loss: 2.005341256658236

Epoch: 111| Step: 0
Training loss: 2.2581019401550293
Validation loss: 2.018199866016706

Epoch: 5| Step: 1
Training loss: 1.7958368062973022
Validation loss: 2.01082643866539

Epoch: 5| Step: 2
Training loss: 2.5586230754852295
Validation loss: 2.0250863085190454

Epoch: 5| Step: 3
Training loss: 1.9848785400390625
Validation loss: 2.0363984405994415

Epoch: 5| Step: 4
Training loss: 1.6156198978424072
Validation loss: 2.057826648155848

Epoch: 5| Step: 5
Training loss: 1.8682286739349365
Validation loss: 2.0715298851331077

Epoch: 5| Step: 6
Training loss: 2.076141119003296
Validation loss: 2.066052650411924

Epoch: 5| Step: 7
Training loss: 2.5456185340881348
Validation loss: 2.0626277029514313

Epoch: 5| Step: 8
Training loss: 2.3491878509521484
Validation loss: 2.0393777887026467

Epoch: 5| Step: 9
Training loss: 2.4815306663513184
Validation loss: 2.033896048863729

Epoch: 5| Step: 10
Training loss: 2.349240779876709
Validation loss: 2.0193402022123337

Epoch: 5| Step: 11
Training loss: 1.8930139541625977
Validation loss: 2.007319604357084

Epoch: 112| Step: 0
Training loss: 2.2782680988311768
Validation loss: 2.0194509774446487

Epoch: 5| Step: 1
Training loss: 2.030094623565674
Validation loss: 2.022962917884191

Epoch: 5| Step: 2
Training loss: 2.119379758834839
Validation loss: 2.018948346376419

Epoch: 5| Step: 3
Training loss: 1.5234060287475586
Validation loss: 2.0276542057593665

Epoch: 5| Step: 4
Training loss: 2.3832430839538574
Validation loss: 2.0284061431884766

Epoch: 5| Step: 5
Training loss: 2.339095115661621
Validation loss: 2.0333532045284906

Epoch: 5| Step: 6
Training loss: 2.441710948944092
Validation loss: 2.030511592825254

Epoch: 5| Step: 7
Training loss: 2.1360082626342773
Validation loss: 2.035942127307256

Epoch: 5| Step: 8
Training loss: 2.1955580711364746
Validation loss: 2.034284859895706

Epoch: 5| Step: 9
Training loss: 2.100944757461548
Validation loss: 2.030304049452146

Epoch: 5| Step: 10
Training loss: 2.291125774383545
Validation loss: 2.0362924933433533

Epoch: 5| Step: 11
Training loss: 2.369968891143799
Validation loss: 2.0317337413628898

Epoch: 113| Step: 0
Training loss: 1.9037309885025024
Validation loss: 2.0218970477581024

Epoch: 5| Step: 1
Training loss: 2.2973761558532715
Validation loss: 2.0247631768385568

Epoch: 5| Step: 2
Training loss: 2.2058911323547363
Validation loss: 2.0260660549004874

Epoch: 5| Step: 3
Training loss: 2.4928367137908936
Validation loss: 2.0273015995820365

Epoch: 5| Step: 4
Training loss: 1.8835426568984985
Validation loss: 2.0226325740416846

Epoch: 5| Step: 5
Training loss: 2.738630771636963
Validation loss: 2.019216979543368

Epoch: 5| Step: 6
Training loss: 2.0322093963623047
Validation loss: 2.016045317053795

Epoch: 5| Step: 7
Training loss: 2.2680323123931885
Validation loss: 2.0192482620477676

Epoch: 5| Step: 8
Training loss: 1.467246174812317
Validation loss: 2.0128720055023828

Epoch: 5| Step: 9
Training loss: 1.875756025314331
Validation loss: 2.008032813668251

Epoch: 5| Step: 10
Training loss: 2.406744956970215
Validation loss: 2.005753368139267

Epoch: 5| Step: 11
Training loss: 2.8743205070495605
Validation loss: 2.008303572734197

Epoch: 114| Step: 0
Training loss: 1.9834197759628296
Validation loss: 2.004242425163587

Epoch: 5| Step: 1
Training loss: 1.791765570640564
Validation loss: 1.9998444964488347

Epoch: 5| Step: 2
Training loss: 2.4483046531677246
Validation loss: 2.00637948513031

Epoch: 5| Step: 3
Training loss: 2.037562131881714
Validation loss: 2.008009652296702

Epoch: 5| Step: 4
Training loss: 1.829419732093811
Validation loss: 2.013971894979477

Epoch: 5| Step: 5
Training loss: 2.2372331619262695
Validation loss: 2.0146437337001166

Epoch: 5| Step: 6
Training loss: 1.9401485919952393
Validation loss: 2.014031191666921

Epoch: 5| Step: 7
Training loss: 2.45162034034729
Validation loss: 2.0144127905368805

Epoch: 5| Step: 8
Training loss: 2.3010449409484863
Validation loss: 2.0142957121133804

Epoch: 5| Step: 9
Training loss: 1.8778798580169678
Validation loss: 2.0234433660904565

Epoch: 5| Step: 10
Training loss: 2.6440134048461914
Validation loss: 2.023994117975235

Epoch: 5| Step: 11
Training loss: 1.5920836925506592
Validation loss: 2.0308636724948883

Epoch: 115| Step: 0
Training loss: 2.030245304107666
Validation loss: 2.0461022506157556

Epoch: 5| Step: 1
Training loss: 2.2007386684417725
Validation loss: 2.040997510155042

Epoch: 5| Step: 2
Training loss: 1.7140668630599976
Validation loss: 2.0477204074462256

Epoch: 5| Step: 3
Training loss: 2.1540842056274414
Validation loss: 2.0418939540783563

Epoch: 5| Step: 4
Training loss: 1.9666532278060913
Validation loss: 2.034142086903254

Epoch: 5| Step: 5
Training loss: 1.9446837902069092
Validation loss: 2.0260931253433228

Epoch: 5| Step: 6
Training loss: 2.780252456665039
Validation loss: 2.0227355360984802

Epoch: 5| Step: 7
Training loss: 2.0816216468811035
Validation loss: 2.026644920309385

Epoch: 5| Step: 8
Training loss: 2.114668607711792
Validation loss: 2.025352716445923

Epoch: 5| Step: 9
Training loss: 2.381700038909912
Validation loss: 2.0194506496191025

Epoch: 5| Step: 10
Training loss: 2.103532314300537
Validation loss: 2.022385453184446

Epoch: 5| Step: 11
Training loss: 2.3821303844451904
Validation loss: 2.0241998781760535

Epoch: 116| Step: 0
Training loss: 2.209773063659668
Validation loss: 2.014796962340673

Epoch: 5| Step: 1
Training loss: 2.509732723236084
Validation loss: 2.02648135026296

Epoch: 5| Step: 2
Training loss: 2.472046375274658
Validation loss: 2.0099643766880035

Epoch: 5| Step: 3
Training loss: 2.6348483562469482
Validation loss: 2.026017889380455

Epoch: 5| Step: 4
Training loss: 2.4063010215759277
Validation loss: 2.032930761575699

Epoch: 5| Step: 5
Training loss: 1.870079755783081
Validation loss: 2.030777722597122

Epoch: 5| Step: 6
Training loss: 1.7827644348144531
Validation loss: 2.023185208439827

Epoch: 5| Step: 7
Training loss: 1.6249358654022217
Validation loss: 2.017805819710096

Epoch: 5| Step: 8
Training loss: 2.476998805999756
Validation loss: 2.016591946283976

Epoch: 5| Step: 9
Training loss: 2.0475192070007324
Validation loss: 2.0138679444789886

Epoch: 5| Step: 10
Training loss: 1.2597894668579102
Validation loss: 2.0042012333869934

Epoch: 5| Step: 11
Training loss: 2.8381292819976807
Validation loss: 2.008458216985067

Epoch: 117| Step: 0
Training loss: 2.1723084449768066
Validation loss: 2.0168906847635903

Epoch: 5| Step: 1
Training loss: 1.7440061569213867
Validation loss: 2.0257467379172645

Epoch: 5| Step: 2
Training loss: 2.5796291828155518
Validation loss: 2.03606050213178

Epoch: 5| Step: 3
Training loss: 1.6976549625396729
Validation loss: 2.0360562851031623

Epoch: 5| Step: 4
Training loss: 2.436777114868164
Validation loss: 2.0412069261074066

Epoch: 5| Step: 5
Training loss: 1.9205853939056396
Validation loss: 2.0483615348736444

Epoch: 5| Step: 6
Training loss: 2.5647926330566406
Validation loss: 2.0487827509641647

Epoch: 5| Step: 7
Training loss: 1.6391559839248657
Validation loss: 2.0527819842100143

Epoch: 5| Step: 8
Training loss: 2.5513598918914795
Validation loss: 2.0399203151464462

Epoch: 5| Step: 9
Training loss: 1.9157817363739014
Validation loss: 2.044623166322708

Epoch: 5| Step: 10
Training loss: 1.9421870708465576
Validation loss: 2.045243407289187

Epoch: 5| Step: 11
Training loss: 2.7767488956451416
Validation loss: 2.0531223018964133

Epoch: 118| Step: 0
Training loss: 1.3926641941070557
Validation loss: 2.045339663823446

Epoch: 5| Step: 1
Training loss: 2.7414445877075195
Validation loss: 2.041070510943731

Epoch: 5| Step: 2
Training loss: 2.196671962738037
Validation loss: 2.0447086294492087

Epoch: 5| Step: 3
Training loss: 1.9323539733886719
Validation loss: 2.0340801974137626

Epoch: 5| Step: 4
Training loss: 2.63470721244812
Validation loss: 2.0391115645567575

Epoch: 5| Step: 5
Training loss: 1.8810367584228516
Validation loss: 2.0356030662854514

Epoch: 5| Step: 6
Training loss: 2.103569507598877
Validation loss: 2.0393480360507965

Epoch: 5| Step: 7
Training loss: 2.403933048248291
Validation loss: 2.0298921167850494

Epoch: 5| Step: 8
Training loss: 1.798269510269165
Validation loss: 2.034013440211614

Epoch: 5| Step: 9
Training loss: 2.335723400115967
Validation loss: 2.0219861616690955

Epoch: 5| Step: 10
Training loss: 1.9367319345474243
Validation loss: 2.0304376830657325

Epoch: 5| Step: 11
Training loss: 1.5022046566009521
Validation loss: 2.0223083198070526

Epoch: 119| Step: 0
Training loss: 2.397848606109619
Validation loss: 2.026314228773117

Epoch: 5| Step: 1
Training loss: 1.9032557010650635
Validation loss: 2.021364669005076

Epoch: 5| Step: 2
Training loss: 1.5204957723617554
Validation loss: 2.0234984159469604

Epoch: 5| Step: 3
Training loss: 1.8285211324691772
Validation loss: 2.027668351928393

Epoch: 5| Step: 4
Training loss: 1.992028832435608
Validation loss: 2.0259851068258286

Epoch: 5| Step: 5
Training loss: 2.599148988723755
Validation loss: 2.021134997407595

Epoch: 5| Step: 6
Training loss: 2.2031779289245605
Validation loss: 2.0227305442094803

Epoch: 5| Step: 7
Training loss: 1.9847564697265625
Validation loss: 2.01588965455691

Epoch: 5| Step: 8
Training loss: 2.4102730751037598
Validation loss: 2.021985868612925

Epoch: 5| Step: 9
Training loss: 1.9992660284042358
Validation loss: 2.021652415394783

Epoch: 5| Step: 10
Training loss: 2.349353313446045
Validation loss: 2.022090603907903

Epoch: 5| Step: 11
Training loss: 2.1554555892944336
Validation loss: 2.027104506889979

Epoch: 120| Step: 0
Training loss: 2.4848315715789795
Validation loss: 2.0229337165753045

Epoch: 5| Step: 1
Training loss: 2.012457847595215
Validation loss: 2.0209058920542398

Epoch: 5| Step: 2
Training loss: 1.9366261959075928
Validation loss: 2.0246220380067825

Epoch: 5| Step: 3
Training loss: 2.3225295543670654
Validation loss: 2.0232960879802704

Epoch: 5| Step: 4
Training loss: 2.186140775680542
Validation loss: 2.0302005062500634

Epoch: 5| Step: 5
Training loss: 2.331399440765381
Validation loss: 2.0297850569089255

Epoch: 5| Step: 6
Training loss: 1.8604446649551392
Validation loss: 2.0294508834679923

Epoch: 5| Step: 7
Training loss: 2.415550470352173
Validation loss: 2.030968432625135

Epoch: 5| Step: 8
Training loss: 1.9911237955093384
Validation loss: 2.030907412370046

Epoch: 5| Step: 9
Training loss: 2.4289469718933105
Validation loss: 2.0306249807278314

Epoch: 5| Step: 10
Training loss: 1.3947468996047974
Validation loss: 2.0379386842250824

Epoch: 5| Step: 11
Training loss: 1.2897489070892334
Validation loss: 2.0284234484036765

Epoch: 121| Step: 0
Training loss: 1.9698940515518188
Validation loss: 2.0268830557664237

Epoch: 5| Step: 1
Training loss: 1.7196308374404907
Validation loss: 2.022707924246788

Epoch: 5| Step: 2
Training loss: 2.2098889350891113
Validation loss: 2.019455537199974

Epoch: 5| Step: 3
Training loss: 2.3428635597229004
Validation loss: 2.0232639213403067

Epoch: 5| Step: 4
Training loss: 2.101787805557251
Validation loss: 2.025460163752238

Epoch: 5| Step: 5
Training loss: 2.5266125202178955
Validation loss: 2.0324662874142327

Epoch: 5| Step: 6
Training loss: 1.8867095708847046
Validation loss: 2.0264725039402642

Epoch: 5| Step: 7
Training loss: 2.049574375152588
Validation loss: 2.0186887284119925

Epoch: 5| Step: 8
Training loss: 2.058281660079956
Validation loss: 2.0267188797394433

Epoch: 5| Step: 9
Training loss: 1.9468704462051392
Validation loss: 2.0212929099798203

Epoch: 5| Step: 10
Training loss: 2.4337058067321777
Validation loss: 2.02371317644914

Epoch: 5| Step: 11
Training loss: 3.041280508041382
Validation loss: 2.0272928128639855

Epoch: 122| Step: 0
Training loss: 2.298038959503174
Validation loss: 2.0281568666299186

Epoch: 5| Step: 1
Training loss: 2.320502758026123
Validation loss: 2.023138781388601

Epoch: 5| Step: 2
Training loss: 2.0355753898620605
Validation loss: 2.0273138880729675

Epoch: 5| Step: 3
Training loss: 2.0270230770111084
Validation loss: 2.0281276305516562

Epoch: 5| Step: 4
Training loss: 1.5730704069137573
Validation loss: 2.0251027892033258

Epoch: 5| Step: 5
Training loss: 2.5660769939422607
Validation loss: 2.0310839811960855

Epoch: 5| Step: 6
Training loss: 1.9084545373916626
Validation loss: 2.0276614477237067

Epoch: 5| Step: 7
Training loss: 1.8637832403182983
Validation loss: 2.031228393316269

Epoch: 5| Step: 8
Training loss: 1.7436602115631104
Validation loss: 2.0451404601335526

Epoch: 5| Step: 9
Training loss: 2.0527701377868652
Validation loss: 2.0315330922603607

Epoch: 5| Step: 10
Training loss: 2.7461023330688477
Validation loss: 2.045671542485555

Epoch: 5| Step: 11
Training loss: 3.0938878059387207
Validation loss: 2.033063088854154

Epoch: 123| Step: 0
Training loss: 2.080791711807251
Validation loss: 2.0357194592555365

Epoch: 5| Step: 1
Training loss: 1.4418551921844482
Validation loss: 2.0261672933896384

Epoch: 5| Step: 2
Training loss: 2.135658025741577
Validation loss: 2.0166872292757034

Epoch: 5| Step: 3
Training loss: 2.1875860691070557
Validation loss: 2.0130124539136887

Epoch: 5| Step: 4
Training loss: 2.6694862842559814
Validation loss: 2.0124500493208566

Epoch: 5| Step: 5
Training loss: 2.1318001747131348
Validation loss: 2.0072283347447715

Epoch: 5| Step: 6
Training loss: 2.054687976837158
Validation loss: 2.0065192878246307

Epoch: 5| Step: 7
Training loss: 1.8352909088134766
Validation loss: 1.9982710083325703

Epoch: 5| Step: 8
Training loss: 2.1974148750305176
Validation loss: 2.0133445262908936

Epoch: 5| Step: 9
Training loss: 2.215222120285034
Validation loss: 2.0175984104474387

Epoch: 5| Step: 10
Training loss: 2.2994461059570312
Validation loss: 2.0147967984279

Epoch: 5| Step: 11
Training loss: 2.0343856811523438
Validation loss: 2.0186962286631265

Epoch: 124| Step: 0
Training loss: 2.514526844024658
Validation loss: 2.0120966931184134

Epoch: 5| Step: 1
Training loss: 1.826263666152954
Validation loss: 2.0119778911272683

Epoch: 5| Step: 2
Training loss: 1.6880724430084229
Validation loss: 2.0111596087614694

Epoch: 5| Step: 3
Training loss: 2.413025379180908
Validation loss: 2.015049308538437

Epoch: 5| Step: 4
Training loss: 1.7517344951629639
Validation loss: 2.0178974916537604

Epoch: 5| Step: 5
Training loss: 2.6799991130828857
Validation loss: 2.016877497235934

Epoch: 5| Step: 6
Training loss: 2.131218671798706
Validation loss: 2.0194469889005027

Epoch: 5| Step: 7
Training loss: 1.9117205142974854
Validation loss: 2.0299559285243354

Epoch: 5| Step: 8
Training loss: 1.4382511377334595
Validation loss: 2.0203960786263147

Epoch: 5| Step: 9
Training loss: 2.218229055404663
Validation loss: 2.0180759678284326

Epoch: 5| Step: 10
Training loss: 2.4788334369659424
Validation loss: 2.019759237766266

Epoch: 5| Step: 11
Training loss: 3.656334400177002
Validation loss: 2.0172727406024933

Epoch: 125| Step: 0
Training loss: 1.8729270696640015
Validation loss: 2.0111927489439645

Epoch: 5| Step: 1
Training loss: 2.35854172706604
Validation loss: 2.001007984081904

Epoch: 5| Step: 2
Training loss: 2.1426150798797607
Validation loss: 1.9964836935202281

Epoch: 5| Step: 3
Training loss: 2.678382396697998
Validation loss: 1.9962101231018703

Epoch: 5| Step: 4
Training loss: 1.867940902709961
Validation loss: 1.9910598595937092

Epoch: 5| Step: 5
Training loss: 2.3936853408813477
Validation loss: 1.9953027814626694

Epoch: 5| Step: 6
Training loss: 2.180155038833618
Validation loss: 1.995999385913213

Epoch: 5| Step: 7
Training loss: 1.6953461170196533
Validation loss: 1.9939765681823094

Epoch: 5| Step: 8
Training loss: 2.132509708404541
Validation loss: 1.992432360847791

Epoch: 5| Step: 9
Training loss: 1.8160581588745117
Validation loss: 1.9914602388938267

Epoch: 5| Step: 10
Training loss: 2.2436530590057373
Validation loss: 1.9973651816447575

Epoch: 5| Step: 11
Training loss: 2.0483927726745605
Validation loss: 1.9987677137056987

Epoch: 126| Step: 0
Training loss: 1.6682199239730835
Validation loss: 2.0041345755259194

Epoch: 5| Step: 1
Training loss: 1.6531593799591064
Validation loss: 2.0120565990606942

Epoch: 5| Step: 2
Training loss: 2.1931960582733154
Validation loss: 2.0220188995202384

Epoch: 5| Step: 3
Training loss: 2.4788239002227783
Validation loss: 2.0317114293575287

Epoch: 5| Step: 4
Training loss: 2.136768341064453
Validation loss: 2.044802779952685

Epoch: 5| Step: 5
Training loss: 1.9647512435913086
Validation loss: 2.0399427513281503

Epoch: 5| Step: 6
Training loss: 2.350541591644287
Validation loss: 2.039978285630544

Epoch: 5| Step: 7
Training loss: 1.9066524505615234
Validation loss: 2.0326059510310492

Epoch: 5| Step: 8
Training loss: 2.4682328701019287
Validation loss: 2.0432591090599694

Epoch: 5| Step: 9
Training loss: 2.124317169189453
Validation loss: 2.035209839542707

Epoch: 5| Step: 10
Training loss: 2.6413745880126953
Validation loss: 2.013355016708374

Epoch: 5| Step: 11
Training loss: 1.632049798965454
Validation loss: 1.9926432420810063

Epoch: 127| Step: 0
Training loss: 2.0671632289886475
Validation loss: 1.9954068561395009

Epoch: 5| Step: 1
Training loss: 2.1900975704193115
Validation loss: 1.9936150560776393

Epoch: 5| Step: 2
Training loss: 2.345278263092041
Validation loss: 1.9961580137411754

Epoch: 5| Step: 3
Training loss: 2.153726816177368
Validation loss: 2.006396477421125

Epoch: 5| Step: 4
Training loss: 2.0374419689178467
Validation loss: 2.0045015662908554

Epoch: 5| Step: 5
Training loss: 2.1244113445281982
Validation loss: 2.0094646314779916

Epoch: 5| Step: 6
Training loss: 2.1284122467041016
Validation loss: 2.0095610320568085

Epoch: 5| Step: 7
Training loss: 2.090409755706787
Validation loss: 2.0025550027688346

Epoch: 5| Step: 8
Training loss: 2.1565334796905518
Validation loss: 2.000041574239731

Epoch: 5| Step: 9
Training loss: 1.8575572967529297
Validation loss: 2.0057886987924576

Epoch: 5| Step: 10
Training loss: 2.164024829864502
Validation loss: 2.014134262998899

Epoch: 5| Step: 11
Training loss: 2.156442165374756
Validation loss: 2.0173917412757874

Epoch: 128| Step: 0
Training loss: 2.274383068084717
Validation loss: 2.0289180328448615

Epoch: 5| Step: 1
Training loss: 2.007986068725586
Validation loss: 2.0472189684708915

Epoch: 5| Step: 2
Training loss: 1.8715336322784424
Validation loss: 2.0663649241129556

Epoch: 5| Step: 3
Training loss: 2.1669957637786865
Validation loss: 2.0564031253258386

Epoch: 5| Step: 4
Training loss: 2.3602678775787354
Validation loss: 2.0710850407679877

Epoch: 5| Step: 5
Training loss: 2.2031593322753906
Validation loss: 2.068602070212364

Epoch: 5| Step: 6
Training loss: 2.0099151134490967
Validation loss: 2.056538313627243

Epoch: 5| Step: 7
Training loss: 2.3143088817596436
Validation loss: 2.054118181268374

Epoch: 5| Step: 8
Training loss: 1.4618388414382935
Validation loss: 2.0515092561642327

Epoch: 5| Step: 9
Training loss: 2.911226749420166
Validation loss: 2.043065960208575

Epoch: 5| Step: 10
Training loss: 2.001896619796753
Validation loss: 2.0302263299624124

Epoch: 5| Step: 11
Training loss: 1.5732873678207397
Validation loss: 2.03230212132136

Epoch: 129| Step: 0
Training loss: 2.1680901050567627
Validation loss: 2.025815303126971

Epoch: 5| Step: 1
Training loss: 2.38901948928833
Validation loss: 2.0182431737581887

Epoch: 5| Step: 2
Training loss: 2.6784884929656982
Validation loss: 2.0156991134087243

Epoch: 5| Step: 3
Training loss: 1.2583763599395752
Validation loss: 2.015572264790535

Epoch: 5| Step: 4
Training loss: 1.6672531366348267
Validation loss: 2.0153637727101645

Epoch: 5| Step: 5
Training loss: 2.58233380317688
Validation loss: 2.0209348599116006

Epoch: 5| Step: 6
Training loss: 1.7859890460968018
Validation loss: 2.0186115354299545

Epoch: 5| Step: 7
Training loss: 1.910123586654663
Validation loss: 2.019253378113111

Epoch: 5| Step: 8
Training loss: 2.129986047744751
Validation loss: 2.0224962482849755

Epoch: 5| Step: 9
Training loss: 2.385127544403076
Validation loss: 2.017447213331858

Epoch: 5| Step: 10
Training loss: 2.19584059715271
Validation loss: 2.0294349441925683

Epoch: 5| Step: 11
Training loss: 2.257235527038574
Validation loss: 2.025115430355072

Epoch: 130| Step: 0
Training loss: 1.92169189453125
Validation loss: 2.030048434933027

Epoch: 5| Step: 1
Training loss: 2.4823269844055176
Validation loss: 2.03179839750131

Epoch: 5| Step: 2
Training loss: 2.17213773727417
Validation loss: 2.02153180539608

Epoch: 5| Step: 3
Training loss: 2.4007413387298584
Validation loss: 2.0247797270615897

Epoch: 5| Step: 4
Training loss: 1.8557870388031006
Validation loss: 2.0354812145233154

Epoch: 5| Step: 5
Training loss: 1.9142833948135376
Validation loss: 2.034667337934176

Epoch: 5| Step: 6
Training loss: 2.369525671005249
Validation loss: 2.023441677292188

Epoch: 5| Step: 7
Training loss: 1.9034416675567627
Validation loss: 2.023572484652201

Epoch: 5| Step: 8
Training loss: 2.238926649093628
Validation loss: 2.0211512595415115

Epoch: 5| Step: 9
Training loss: 1.8647695779800415
Validation loss: 2.0251652002334595

Epoch: 5| Step: 10
Training loss: 1.963623046875
Validation loss: 2.0211061835289

Epoch: 5| Step: 11
Training loss: 1.651918649673462
Validation loss: 2.029105380177498

Epoch: 131| Step: 0
Training loss: 1.4842569828033447
Validation loss: 2.0219418654839196

Epoch: 5| Step: 1
Training loss: 1.6087284088134766
Validation loss: 2.0252005209525428

Epoch: 5| Step: 2
Training loss: 1.8130124807357788
Validation loss: 2.020343691110611

Epoch: 5| Step: 3
Training loss: 2.3412115573883057
Validation loss: 2.0226282626390457

Epoch: 5| Step: 4
Training loss: 2.4771625995635986
Validation loss: 2.032880832751592

Epoch: 5| Step: 5
Training loss: 2.0979790687561035
Validation loss: 2.0340374062458673

Epoch: 5| Step: 6
Training loss: 2.6653189659118652
Validation loss: 2.026678889989853

Epoch: 5| Step: 7
Training loss: 1.819016456604004
Validation loss: 2.031638423601786

Epoch: 5| Step: 8
Training loss: 2.3900763988494873
Validation loss: 2.0311374813318253

Epoch: 5| Step: 9
Training loss: 2.461890697479248
Validation loss: 2.0342685679594674

Epoch: 5| Step: 10
Training loss: 1.7276531457901
Validation loss: 2.034249464670817

Epoch: 5| Step: 11
Training loss: 2.9268245697021484
Validation loss: 2.032856340209643

Epoch: 132| Step: 0
Training loss: 2.0559160709381104
Validation loss: 2.022042542695999

Epoch: 5| Step: 1
Training loss: 1.956888198852539
Validation loss: 2.0227315177520118

Epoch: 5| Step: 2
Training loss: 2.797032594680786
Validation loss: 2.032065441211065

Epoch: 5| Step: 3
Training loss: 1.6881532669067383
Validation loss: 2.028347204128901

Epoch: 5| Step: 4
Training loss: 2.1150057315826416
Validation loss: 2.03391470015049

Epoch: 5| Step: 5
Training loss: 2.2724664211273193
Validation loss: 2.0264187504847846

Epoch: 5| Step: 6
Training loss: 2.1752891540527344
Validation loss: 2.03266512354215

Epoch: 5| Step: 7
Training loss: 1.8292171955108643
Validation loss: 2.0243227928876877

Epoch: 5| Step: 8
Training loss: 1.8122698068618774
Validation loss: 2.0248154948155084

Epoch: 5| Step: 9
Training loss: 2.0378994941711426
Validation loss: 2.018102064728737

Epoch: 5| Step: 10
Training loss: 2.0660204887390137
Validation loss: 2.016222968697548

Epoch: 5| Step: 11
Training loss: 2.6835527420043945
Validation loss: 2.009208078185717

Epoch: 133| Step: 0
Training loss: 2.1627819538116455
Validation loss: 2.016084993879

Epoch: 5| Step: 1
Training loss: 1.9774436950683594
Validation loss: 2.012317806482315

Epoch: 5| Step: 2
Training loss: 2.0881149768829346
Validation loss: 2.016598025957743

Epoch: 5| Step: 3
Training loss: 2.71516489982605
Validation loss: 2.0155415534973145

Epoch: 5| Step: 4
Training loss: 1.9682624340057373
Validation loss: 2.024053434530894

Epoch: 5| Step: 5
Training loss: 1.6240952014923096
Validation loss: 2.0221210022767386

Epoch: 5| Step: 6
Training loss: 1.7793350219726562
Validation loss: 2.0212303400039673

Epoch: 5| Step: 7
Training loss: 1.8429100513458252
Validation loss: 2.026225288709005

Epoch: 5| Step: 8
Training loss: 2.270066738128662
Validation loss: 2.024445762236913

Epoch: 5| Step: 9
Training loss: 2.204420566558838
Validation loss: 2.020954410235087

Epoch: 5| Step: 10
Training loss: 2.3016510009765625
Validation loss: 2.0307362576325736

Epoch: 5| Step: 11
Training loss: 2.6749184131622314
Validation loss: 2.030336062113444

Epoch: 134| Step: 0
Training loss: 2.534269332885742
Validation loss: 2.0252791742483773

Epoch: 5| Step: 1
Training loss: 2.174834728240967
Validation loss: 2.0326664050420127

Epoch: 5| Step: 2
Training loss: 1.7568378448486328
Validation loss: 2.0290498584508896

Epoch: 5| Step: 3
Training loss: 1.7849206924438477
Validation loss: 2.0309922446807227

Epoch: 5| Step: 4
Training loss: 2.2162747383117676
Validation loss: 2.0328905085722604

Epoch: 5| Step: 5
Training loss: 2.2246341705322266
Validation loss: 2.036940520008405

Epoch: 5| Step: 6
Training loss: 2.4304072856903076
Validation loss: 2.032713611920675

Epoch: 5| Step: 7
Training loss: 1.7243850231170654
Validation loss: 2.0361423989137015

Epoch: 5| Step: 8
Training loss: 1.3790833950042725
Validation loss: 2.041087677081426

Epoch: 5| Step: 9
Training loss: 2.1898045539855957
Validation loss: 2.0470601320266724

Epoch: 5| Step: 10
Training loss: 2.4400362968444824
Validation loss: 2.0322809666395187

Epoch: 5| Step: 11
Training loss: 2.0026159286499023
Validation loss: 2.036747937401136

Epoch: 135| Step: 0
Training loss: 2.0324597358703613
Validation loss: 2.0362687408924103

Epoch: 5| Step: 1
Training loss: 2.080869197845459
Validation loss: 2.03193228940169

Epoch: 5| Step: 2
Training loss: 1.979315161705017
Validation loss: 2.0389419744412103

Epoch: 5| Step: 3
Training loss: 1.9740362167358398
Validation loss: 2.034202585617701

Epoch: 5| Step: 4
Training loss: 2.2933945655822754
Validation loss: 2.022329847017924

Epoch: 5| Step: 5
Training loss: 2.4719228744506836
Validation loss: 2.0239696353673935

Epoch: 5| Step: 6
Training loss: 1.7312084436416626
Validation loss: 2.0184516310691833

Epoch: 5| Step: 7
Training loss: 2.03316068649292
Validation loss: 2.026770497361819

Epoch: 5| Step: 8
Training loss: 2.553135395050049
Validation loss: 2.020033245285352

Epoch: 5| Step: 9
Training loss: 1.7791192531585693
Validation loss: 2.028001844882965

Epoch: 5| Step: 10
Training loss: 2.0611696243286133
Validation loss: 2.0207678228616714

Epoch: 5| Step: 11
Training loss: 2.188422679901123
Validation loss: 2.0289273460706077

Epoch: 136| Step: 0
Training loss: 1.8116687536239624
Validation loss: 2.0275126794974008

Epoch: 5| Step: 1
Training loss: 1.8065487146377563
Validation loss: 2.0378008782863617

Epoch: 5| Step: 2
Training loss: 2.3191564083099365
Validation loss: 2.0435204108556113

Epoch: 5| Step: 3
Training loss: 2.2089970111846924
Validation loss: 2.0513600558042526

Epoch: 5| Step: 4
Training loss: 2.1909165382385254
Validation loss: 2.0461058616638184

Epoch: 5| Step: 5
Training loss: 1.920515775680542
Validation loss: 2.0482145051161447

Epoch: 5| Step: 6
Training loss: 1.8584320545196533
Validation loss: 2.0518047312895455

Epoch: 5| Step: 7
Training loss: 2.6562342643737793
Validation loss: 2.0593874951203666

Epoch: 5| Step: 8
Training loss: 2.513650894165039
Validation loss: 2.058044741551081

Epoch: 5| Step: 9
Training loss: 1.6343066692352295
Validation loss: 2.045472870270411

Epoch: 5| Step: 10
Training loss: 2.0401976108551025
Validation loss: 2.0594485998153687

Epoch: 5| Step: 11
Training loss: 0.9402543306350708
Validation loss: 2.066001534461975

Epoch: 137| Step: 0
Training loss: 2.085869550704956
Validation loss: 2.0642399042844772

Epoch: 5| Step: 1
Training loss: 2.316148042678833
Validation loss: 2.062910790244738

Epoch: 5| Step: 2
Training loss: 2.2006587982177734
Validation loss: 2.079478989044825

Epoch: 5| Step: 3
Training loss: 1.7379624843597412
Validation loss: 2.08633254468441

Epoch: 5| Step: 4
Training loss: 2.083545207977295
Validation loss: 2.0631037453810372

Epoch: 5| Step: 5
Training loss: 2.8861281871795654
Validation loss: 2.056203782558441

Epoch: 5| Step: 6
Training loss: 1.7652736902236938
Validation loss: 2.0524407823880515

Epoch: 5| Step: 7
Training loss: 1.1651265621185303
Validation loss: 2.0562371661265693

Epoch: 5| Step: 8
Training loss: 2.4618358612060547
Validation loss: 2.0672156512737274

Epoch: 5| Step: 9
Training loss: 2.3791518211364746
Validation loss: 2.056918149193128

Epoch: 5| Step: 10
Training loss: 1.7143011093139648
Validation loss: 2.050918072462082

Epoch: 5| Step: 11
Training loss: 2.529345989227295
Validation loss: 2.0471882075071335

Epoch: 138| Step: 0
Training loss: 1.8079220056533813
Validation loss: 2.0516820400953293

Epoch: 5| Step: 1
Training loss: 2.460191488265991
Validation loss: 2.049039214849472

Epoch: 5| Step: 2
Training loss: 2.235862970352173
Validation loss: 2.0544487734635672

Epoch: 5| Step: 3
Training loss: 1.7788654565811157
Validation loss: 2.04769167304039

Epoch: 5| Step: 4
Training loss: 2.0296664237976074
Validation loss: 2.0539352794488273

Epoch: 5| Step: 5
Training loss: 1.7704731225967407
Validation loss: 2.0507110208272934

Epoch: 5| Step: 6
Training loss: 2.3443946838378906
Validation loss: 2.0535251845916114

Epoch: 5| Step: 7
Training loss: 2.1332898139953613
Validation loss: 2.0507598320643106

Epoch: 5| Step: 8
Training loss: 1.9077491760253906
Validation loss: 2.0504419952630997

Epoch: 5| Step: 9
Training loss: 2.461428165435791
Validation loss: 2.050862987836202

Epoch: 5| Step: 10
Training loss: 1.917677640914917
Validation loss: 2.05779700477918

Epoch: 5| Step: 11
Training loss: 2.705209732055664
Validation loss: 2.048394834001859

Epoch: 139| Step: 0
Training loss: 1.982297658920288
Validation loss: 2.0577446470657983

Epoch: 5| Step: 1
Training loss: 2.1487765312194824
Validation loss: 2.0568883468707404

Epoch: 5| Step: 2
Training loss: 2.374617338180542
Validation loss: 2.0511716107527413

Epoch: 5| Step: 3
Training loss: 2.2680835723876953
Validation loss: 2.0401664574941

Epoch: 5| Step: 4
Training loss: 1.6185575723648071
Validation loss: 2.0440743068854013

Epoch: 5| Step: 5
Training loss: 2.053292989730835
Validation loss: 2.039379268884659

Epoch: 5| Step: 6
Training loss: 2.192614793777466
Validation loss: 2.0295141537984214

Epoch: 5| Step: 7
Training loss: 1.3522017002105713
Validation loss: 2.0388518571853638

Epoch: 5| Step: 8
Training loss: 2.4024252891540527
Validation loss: 2.03807599345843

Epoch: 5| Step: 9
Training loss: 2.0830819606781006
Validation loss: 2.030673493941625

Epoch: 5| Step: 10
Training loss: 2.5192599296569824
Validation loss: 2.02791228890419

Epoch: 5| Step: 11
Training loss: 1.6926499605178833
Validation loss: 2.0268340557813644

Epoch: 140| Step: 0
Training loss: 1.5160595178604126
Validation loss: 2.032789255181948

Epoch: 5| Step: 1
Training loss: 1.9489049911499023
Validation loss: 2.031340370575587

Epoch: 5| Step: 2
Training loss: 1.7388166189193726
Validation loss: 2.036223674813906

Epoch: 5| Step: 3
Training loss: 1.9581940174102783
Validation loss: 2.0448957979679108

Epoch: 5| Step: 4
Training loss: 2.1205756664276123
Validation loss: 2.0391713827848434

Epoch: 5| Step: 5
Training loss: 1.938306450843811
Validation loss: 2.049059654275576

Epoch: 5| Step: 6
Training loss: 2.7424635887145996
Validation loss: 2.0470203508933387

Epoch: 5| Step: 7
Training loss: 2.67187762260437
Validation loss: 2.0568120380242667

Epoch: 5| Step: 8
Training loss: 2.1128201484680176
Validation loss: 2.0580112636089325

Epoch: 5| Step: 9
Training loss: 1.8344208002090454
Validation loss: 2.052674780289332

Epoch: 5| Step: 10
Training loss: 2.3545148372650146
Validation loss: 2.054523895184199

Epoch: 5| Step: 11
Training loss: 2.1621487140655518
Validation loss: 2.0705840239922204

Epoch: 141| Step: 0
Training loss: 1.7179456949234009
Validation loss: 2.0608957757552466

Epoch: 5| Step: 1
Training loss: 2.0764236450195312
Validation loss: 2.0647303412357965

Epoch: 5| Step: 2
Training loss: 2.594954013824463
Validation loss: 2.061095361908277

Epoch: 5| Step: 3
Training loss: 1.2955337762832642
Validation loss: 2.055386483669281

Epoch: 5| Step: 4
Training loss: 2.2466471195220947
Validation loss: 2.057482570409775

Epoch: 5| Step: 5
Training loss: 2.0174434185028076
Validation loss: 2.049662391344706

Epoch: 5| Step: 6
Training loss: 1.9444869756698608
Validation loss: 2.052789648373922

Epoch: 5| Step: 7
Training loss: 2.250371217727661
Validation loss: 2.056586151321729

Epoch: 5| Step: 8
Training loss: 2.7317099571228027
Validation loss: 2.0536577055851617

Epoch: 5| Step: 9
Training loss: 1.9302839040756226
Validation loss: 2.0641366938749948

Epoch: 5| Step: 10
Training loss: 1.8274701833724976
Validation loss: 2.0594032804171243

Epoch: 5| Step: 11
Training loss: 3.4133853912353516
Validation loss: 2.052539656559626

Epoch: 142| Step: 0
Training loss: 1.6714115142822266
Validation loss: 2.0552784552176795

Epoch: 5| Step: 1
Training loss: 2.8004631996154785
Validation loss: 2.0503104676802955

Epoch: 5| Step: 2
Training loss: 2.0756280422210693
Validation loss: 2.0508618354797363

Epoch: 5| Step: 3
Training loss: 1.8587634563446045
Validation loss: 2.0516110161940255

Epoch: 5| Step: 4
Training loss: 2.250739097595215
Validation loss: 2.0485514253377914

Epoch: 5| Step: 5
Training loss: 1.9867687225341797
Validation loss: 2.036229059100151

Epoch: 5| Step: 6
Training loss: 1.6435524225234985
Validation loss: 2.0299104948838553

Epoch: 5| Step: 7
Training loss: 1.7784595489501953
Validation loss: 2.0473582794268927

Epoch: 5| Step: 8
Training loss: 2.159099817276001
Validation loss: 2.0401505132516227

Epoch: 5| Step: 9
Training loss: 2.1413626670837402
Validation loss: 2.0462755610545478

Epoch: 5| Step: 10
Training loss: 2.4891583919525146
Validation loss: 2.0429911762475967

Epoch: 5| Step: 11
Training loss: 1.1708630323410034
Validation loss: 2.037753646572431

Epoch: 143| Step: 0
Training loss: 2.117760181427002
Validation loss: 2.0391801496346793

Epoch: 5| Step: 1
Training loss: 2.058533191680908
Validation loss: 2.040349597732226

Epoch: 5| Step: 2
Training loss: 2.5471863746643066
Validation loss: 2.0369873642921448

Epoch: 5| Step: 3
Training loss: 2.077578544616699
Validation loss: 2.0508684664964676

Epoch: 5| Step: 4
Training loss: 1.5555849075317383
Validation loss: 2.0373822301626205

Epoch: 5| Step: 5
Training loss: 1.9957160949707031
Validation loss: 2.0529190599918365

Epoch: 5| Step: 6
Training loss: 1.7876704931259155
Validation loss: 2.0535708566506705

Epoch: 5| Step: 7
Training loss: 1.6686317920684814
Validation loss: 2.04268749554952

Epoch: 5| Step: 8
Training loss: 2.3457224369049072
Validation loss: 2.0476168592770896

Epoch: 5| Step: 9
Training loss: 2.602346897125244
Validation loss: 2.052085051933924

Epoch: 5| Step: 10
Training loss: 2.1253137588500977
Validation loss: 2.0558747053146362

Epoch: 5| Step: 11
Training loss: 1.1848969459533691
Validation loss: 2.0478667865196862

Epoch: 144| Step: 0
Training loss: 2.3715977668762207
Validation loss: 2.0485039353370667

Epoch: 5| Step: 1
Training loss: 1.9309431314468384
Validation loss: 2.0382259438435235

Epoch: 5| Step: 2
Training loss: 2.42478084564209
Validation loss: 2.042979801694552

Epoch: 5| Step: 3
Training loss: 1.7133398056030273
Validation loss: 2.036569873491923

Epoch: 5| Step: 4
Training loss: 2.315969228744507
Validation loss: 2.040542811155319

Epoch: 5| Step: 5
Training loss: 2.3433890342712402
Validation loss: 2.0411683122316995

Epoch: 5| Step: 6
Training loss: 1.755902647972107
Validation loss: 2.038033107916514

Epoch: 5| Step: 7
Training loss: 2.2446792125701904
Validation loss: 2.0389935970306396

Epoch: 5| Step: 8
Training loss: 2.1184017658233643
Validation loss: 2.0340984066327414

Epoch: 5| Step: 9
Training loss: 2.0202088356018066
Validation loss: 2.036562999089559

Epoch: 5| Step: 10
Training loss: 1.5582598447799683
Validation loss: 2.0259335289398828

Epoch: 5| Step: 11
Training loss: 2.9124884605407715
Validation loss: 2.0408104757467904

Epoch: 145| Step: 0
Training loss: 1.806653380393982
Validation loss: 2.0420168985923133

Epoch: 5| Step: 1
Training loss: 2.3898158073425293
Validation loss: 2.0425994197527566

Epoch: 5| Step: 2
Training loss: 2.219752550125122
Validation loss: 2.05314273138841

Epoch: 5| Step: 3
Training loss: 1.7041168212890625
Validation loss: 2.0443577468395233

Epoch: 5| Step: 4
Training loss: 2.381016969680786
Validation loss: 2.0431342174609504

Epoch: 5| Step: 5
Training loss: 2.328829765319824
Validation loss: 2.0456680158774057

Epoch: 5| Step: 6
Training loss: 1.4521193504333496
Validation loss: 2.045542965332667

Epoch: 5| Step: 7
Training loss: 2.5935778617858887
Validation loss: 2.0560253063837686

Epoch: 5| Step: 8
Training loss: 1.8468269109725952
Validation loss: 2.0626533230145774

Epoch: 5| Step: 9
Training loss: 2.249453067779541
Validation loss: 2.063117062052091

Epoch: 5| Step: 10
Training loss: 1.8445125818252563
Validation loss: 2.0545502404371896

Epoch: 5| Step: 11
Training loss: 1.3698759078979492
Validation loss: 2.0534357329209647

Epoch: 146| Step: 0
Training loss: 2.0657293796539307
Validation loss: 2.0618097533782325

Epoch: 5| Step: 1
Training loss: 1.847560167312622
Validation loss: 2.0544233173131943

Epoch: 5| Step: 2
Training loss: 2.0630016326904297
Validation loss: 2.0423996498187384

Epoch: 5| Step: 3
Training loss: 2.5155601501464844
Validation loss: 2.049072210987409

Epoch: 5| Step: 4
Training loss: 1.5641794204711914
Validation loss: 2.0461610605319343

Epoch: 5| Step: 5
Training loss: 2.2151577472686768
Validation loss: 2.0454563250144324

Epoch: 5| Step: 6
Training loss: 2.117809295654297
Validation loss: 2.0492613315582275

Epoch: 5| Step: 7
Training loss: 2.20522403717041
Validation loss: 2.044106811285019

Epoch: 5| Step: 8
Training loss: 2.0699782371520996
Validation loss: 2.049622103571892

Epoch: 5| Step: 9
Training loss: 1.844517707824707
Validation loss: 2.0339732468128204

Epoch: 5| Step: 10
Training loss: 2.3130438327789307
Validation loss: 2.0376349290211997

Epoch: 5| Step: 11
Training loss: 1.7496298551559448
Validation loss: 2.0530374199151993

Epoch: 147| Step: 0
Training loss: 2.3170599937438965
Validation loss: 2.0438791712125144

Epoch: 5| Step: 1
Training loss: 2.424006700515747
Validation loss: 2.04852328201135

Epoch: 5| Step: 2
Training loss: 2.2487905025482178
Validation loss: 2.0474909941355386

Epoch: 5| Step: 3
Training loss: 2.3637728691101074
Validation loss: 2.047918056448301

Epoch: 5| Step: 4
Training loss: 1.9303194284439087
Validation loss: 2.0445173531770706

Epoch: 5| Step: 5
Training loss: 1.836449384689331
Validation loss: 2.0454363326231637

Epoch: 5| Step: 6
Training loss: 2.2268693447113037
Validation loss: 2.028485362728437

Epoch: 5| Step: 7
Training loss: 2.123767137527466
Validation loss: 2.0310843686262765

Epoch: 5| Step: 8
Training loss: 1.8402583599090576
Validation loss: 2.0239215741554895

Epoch: 5| Step: 9
Training loss: 1.9762614965438843
Validation loss: 2.021791622042656

Epoch: 5| Step: 10
Training loss: 1.5621538162231445
Validation loss: 2.0325223902861276

Epoch: 5| Step: 11
Training loss: 1.1025416851043701
Validation loss: 2.037904903292656

Epoch: 148| Step: 0
Training loss: 1.6237417459487915
Validation loss: 2.034643923242887

Epoch: 5| Step: 1
Training loss: 2.125074863433838
Validation loss: 2.051542436083158

Epoch: 5| Step: 2
Training loss: 2.4384264945983887
Validation loss: 2.064204196135203

Epoch: 5| Step: 3
Training loss: 1.7744791507720947
Validation loss: 2.062806412577629

Epoch: 5| Step: 4
Training loss: 1.9440269470214844
Validation loss: 2.048125391205152

Epoch: 5| Step: 5
Training loss: 1.9732452630996704
Validation loss: 2.048144042491913

Epoch: 5| Step: 6
Training loss: 2.027404308319092
Validation loss: 2.0348400622606277

Epoch: 5| Step: 7
Training loss: 1.8452510833740234
Validation loss: 2.017832398414612

Epoch: 5| Step: 8
Training loss: 2.249161720275879
Validation loss: 2.0231509457031884

Epoch: 5| Step: 9
Training loss: 2.358246088027954
Validation loss: 2.017503629128138

Epoch: 5| Step: 10
Training loss: 2.1047825813293457
Validation loss: 2.0142916987339654

Epoch: 5| Step: 11
Training loss: 3.531980514526367
Validation loss: 2.0187858641147614

Epoch: 149| Step: 0
Training loss: 2.2136197090148926
Validation loss: 2.017627870043119

Epoch: 5| Step: 1
Training loss: 1.8210604190826416
Validation loss: 2.0269202490647635

Epoch: 5| Step: 2
Training loss: 2.223396062850952
Validation loss: 2.0496996343135834

Epoch: 5| Step: 3
Training loss: 2.517017126083374
Validation loss: 2.0442463060220084

Epoch: 5| Step: 4
Training loss: 2.130350351333618
Validation loss: 2.0427668193976083

Epoch: 5| Step: 5
Training loss: 2.3975601196289062
Validation loss: 2.0444335540135703

Epoch: 5| Step: 6
Training loss: 2.1568655967712402
Validation loss: 2.038730571667353

Epoch: 5| Step: 7
Training loss: 1.80693781375885
Validation loss: 2.0410476326942444

Epoch: 5| Step: 8
Training loss: 1.8119392395019531
Validation loss: 2.0350458721319833

Epoch: 5| Step: 9
Training loss: 1.988172173500061
Validation loss: 2.025219942132632

Epoch: 5| Step: 10
Training loss: 2.222040891647339
Validation loss: 2.02342027425766

Epoch: 5| Step: 11
Training loss: 2.372600555419922
Validation loss: 2.0142187625169754

Epoch: 150| Step: 0
Training loss: 1.8254499435424805
Validation loss: 2.028430605928103

Epoch: 5| Step: 1
Training loss: 2.1806702613830566
Validation loss: 2.0145297050476074

Epoch: 5| Step: 2
Training loss: 2.3441689014434814
Validation loss: 2.028367668390274

Epoch: 5| Step: 3
Training loss: 1.756697654724121
Validation loss: 2.0368887136379876

Epoch: 5| Step: 4
Training loss: 2.2514095306396484
Validation loss: 2.042689656217893

Epoch: 5| Step: 5
Training loss: 1.5550516843795776
Validation loss: 2.0429424991210303

Epoch: 5| Step: 6
Training loss: 1.8266502618789673
Validation loss: 2.048095236221949

Epoch: 5| Step: 7
Training loss: 2.59885311126709
Validation loss: 2.060097321867943

Epoch: 5| Step: 8
Training loss: 2.4061055183410645
Validation loss: 2.0527080049117408

Epoch: 5| Step: 9
Training loss: 2.0429420471191406
Validation loss: 2.0559387554725013

Epoch: 5| Step: 10
Training loss: 2.044370174407959
Validation loss: 2.0551402121782303

Epoch: 5| Step: 11
Training loss: 2.505537509918213
Validation loss: 2.056237811843554

Epoch: 151| Step: 0
Training loss: 1.5945470333099365
Validation loss: 2.0509868462880454

Epoch: 5| Step: 1
Training loss: 2.1289737224578857
Validation loss: 2.0454212675491967

Epoch: 5| Step: 2
Training loss: 2.4325573444366455
Validation loss: 2.041014795502027

Epoch: 5| Step: 3
Training loss: 2.4131031036376953
Validation loss: 2.0284492820501328

Epoch: 5| Step: 4
Training loss: 1.6930301189422607
Validation loss: 2.041316971182823

Epoch: 5| Step: 5
Training loss: 1.8577630519866943
Validation loss: 2.0424751937389374

Epoch: 5| Step: 6
Training loss: 2.5775885581970215
Validation loss: 2.0512701173623404

Epoch: 5| Step: 7
Training loss: 1.9222419261932373
Validation loss: 2.0335654268662133

Epoch: 5| Step: 8
Training loss: 1.8033794164657593
Validation loss: 2.0474601835012436

Epoch: 5| Step: 9
Training loss: 2.2769360542297363
Validation loss: 2.049117157856623

Epoch: 5| Step: 10
Training loss: 2.5100860595703125
Validation loss: 2.040172020594279

Epoch: 5| Step: 11
Training loss: 1.3533909320831299
Validation loss: 2.0379552841186523

Epoch: 152| Step: 0
Training loss: 1.961957573890686
Validation loss: 2.034363016486168

Epoch: 5| Step: 1
Training loss: 1.8208786249160767
Validation loss: 2.041791101296743

Epoch: 5| Step: 2
Training loss: 2.270045042037964
Validation loss: 2.035735920071602

Epoch: 5| Step: 3
Training loss: 1.7888911962509155
Validation loss: 2.038460905353228

Epoch: 5| Step: 4
Training loss: 2.384239673614502
Validation loss: 2.04174833993117

Epoch: 5| Step: 5
Training loss: 2.319204807281494
Validation loss: 2.044510528445244

Epoch: 5| Step: 6
Training loss: 2.039958953857422
Validation loss: 2.0394321282704673

Epoch: 5| Step: 7
Training loss: 1.859122633934021
Validation loss: 2.0417284071445465

Epoch: 5| Step: 8
Training loss: 1.6773264408111572
Validation loss: 2.0553211520115533

Epoch: 5| Step: 9
Training loss: 2.7126011848449707
Validation loss: 2.034019649028778

Epoch: 5| Step: 10
Training loss: 1.696833610534668
Validation loss: 2.044848322868347

Epoch: 5| Step: 11
Training loss: 1.9073035717010498
Validation loss: 2.051600903272629

Epoch: 153| Step: 0
Training loss: 1.9345331192016602
Validation loss: 2.038402353723844

Epoch: 5| Step: 1
Training loss: 2.0479750633239746
Validation loss: 2.0526808351278305

Epoch: 5| Step: 2
Training loss: 1.8691704273223877
Validation loss: 2.0398764610290527

Epoch: 5| Step: 3
Training loss: 2.2371559143066406
Validation loss: 2.036735554536184

Epoch: 5| Step: 4
Training loss: 2.021146535873413
Validation loss: 2.0345413039127984

Epoch: 5| Step: 5
Training loss: 2.19254207611084
Validation loss: 2.0315359085798264

Epoch: 5| Step: 6
Training loss: 2.470457077026367
Validation loss: 2.0441033045450845

Epoch: 5| Step: 7
Training loss: 2.3295531272888184
Validation loss: 2.03309229016304

Epoch: 5| Step: 8
Training loss: 1.4828832149505615
Validation loss: 2.042976771791776

Epoch: 5| Step: 9
Training loss: 2.1039695739746094
Validation loss: 2.0371084262927375

Epoch: 5| Step: 10
Training loss: 2.3053641319274902
Validation loss: 2.0439238945643106

Epoch: 5| Step: 11
Training loss: 1.5367432832717896
Validation loss: 2.0436127881209054

Epoch: 154| Step: 0
Training loss: 1.862531304359436
Validation loss: 2.0445967515309653

Epoch: 5| Step: 1
Training loss: 2.363226890563965
Validation loss: 2.044200743238131

Epoch: 5| Step: 2
Training loss: 2.0672810077667236
Validation loss: 2.0449528296788535

Epoch: 5| Step: 3
Training loss: 2.259230136871338
Validation loss: 2.034805417060852

Epoch: 5| Step: 4
Training loss: 2.0004544258117676
Validation loss: 2.043833831946055

Epoch: 5| Step: 5
Training loss: 2.3464975357055664
Validation loss: 2.0411243240038552

Epoch: 5| Step: 6
Training loss: 1.6135975122451782
Validation loss: 2.046165337165197

Epoch: 5| Step: 7
Training loss: 2.5419681072235107
Validation loss: 2.045061022043228

Epoch: 5| Step: 8
Training loss: 1.9716103076934814
Validation loss: 2.046835963924726

Epoch: 5| Step: 9
Training loss: 1.6951324939727783
Validation loss: 2.052847608923912

Epoch: 5| Step: 10
Training loss: 1.9564971923828125
Validation loss: 2.0432412326335907

Epoch: 5| Step: 11
Training loss: 1.4390335083007812
Validation loss: 2.0407143433888755

Epoch: 155| Step: 0
Training loss: 1.662902593612671
Validation loss: 2.0441646526257196

Epoch: 5| Step: 1
Training loss: 1.5286561250686646
Validation loss: 2.0482373932997384

Epoch: 5| Step: 2
Training loss: 1.9785594940185547
Validation loss: 2.0434446732203164

Epoch: 5| Step: 3
Training loss: 1.654446005821228
Validation loss: 2.052435507376989

Epoch: 5| Step: 4
Training loss: 2.7866034507751465
Validation loss: 2.036838283141454

Epoch: 5| Step: 5
Training loss: 2.2452454566955566
Validation loss: 2.0347367773453393

Epoch: 5| Step: 6
Training loss: 1.5854120254516602
Validation loss: 2.0456531395514808

Epoch: 5| Step: 7
Training loss: 2.272338390350342
Validation loss: 2.033452327052752

Epoch: 5| Step: 8
Training loss: 2.955307722091675
Validation loss: 2.03487965464592

Epoch: 5| Step: 9
Training loss: 1.8305898904800415
Validation loss: 2.038302098711332

Epoch: 5| Step: 10
Training loss: 2.178683280944824
Validation loss: 2.0386992841959

Epoch: 5| Step: 11
Training loss: 0.4578011631965637
Validation loss: 2.037832389275233

Epoch: 156| Step: 0
Training loss: 2.152731418609619
Validation loss: 2.0332711984713874

Epoch: 5| Step: 1
Training loss: 2.287278652191162
Validation loss: 2.054790288209915

Epoch: 5| Step: 2
Training loss: 2.12283992767334
Validation loss: 2.0521306147178016

Epoch: 5| Step: 3
Training loss: 1.704520583152771
Validation loss: 2.041381984949112

Epoch: 5| Step: 4
Training loss: 1.7485477924346924
Validation loss: 2.0409822911024094

Epoch: 5| Step: 5
Training loss: 2.452263355255127
Validation loss: 2.046689917643865

Epoch: 5| Step: 6
Training loss: 2.008053779602051
Validation loss: 2.036486883958181

Epoch: 5| Step: 7
Training loss: 1.8913536071777344
Validation loss: 2.0307330886522927

Epoch: 5| Step: 8
Training loss: 2.427680492401123
Validation loss: 2.040875713030497

Epoch: 5| Step: 9
Training loss: 2.3686752319335938
Validation loss: 2.047495742638906

Epoch: 5| Step: 10
Training loss: 1.3766756057739258
Validation loss: 2.038531015316645

Epoch: 5| Step: 11
Training loss: 1.6449785232543945
Validation loss: 2.037394548455874

Epoch: 157| Step: 0
Training loss: 1.8871755599975586
Validation loss: 2.043677215774854

Epoch: 5| Step: 1
Training loss: 2.1231281757354736
Validation loss: 2.041594992081324

Epoch: 5| Step: 2
Training loss: 2.08536434173584
Validation loss: 2.0356467266877494

Epoch: 5| Step: 3
Training loss: 2.1541295051574707
Validation loss: 2.045498381058375

Epoch: 5| Step: 4
Training loss: 1.9908363819122314
Validation loss: 2.0392969946066537

Epoch: 5| Step: 5
Training loss: 1.6850693225860596
Validation loss: 2.050469756126404

Epoch: 5| Step: 6
Training loss: 2.0793166160583496
Validation loss: 2.040490205089251

Epoch: 5| Step: 7
Training loss: 1.9691139459609985
Validation loss: 2.0394197404384613

Epoch: 5| Step: 8
Training loss: 2.092940092086792
Validation loss: 2.0349278350671134

Epoch: 5| Step: 9
Training loss: 2.360440492630005
Validation loss: 2.0411391208569207

Epoch: 5| Step: 10
Training loss: 2.3114805221557617
Validation loss: 2.0366325626770654

Epoch: 5| Step: 11
Training loss: 2.3669421672821045
Validation loss: 2.04359932243824

Epoch: 158| Step: 0
Training loss: 2.4829537868499756
Validation loss: 2.037880544861158

Epoch: 5| Step: 1
Training loss: 1.739492654800415
Validation loss: 2.0438006669282913

Epoch: 5| Step: 2
Training loss: 1.4620646238327026
Validation loss: 2.049245148897171

Epoch: 5| Step: 3
Training loss: 1.753260850906372
Validation loss: 2.053165758649508

Epoch: 5| Step: 4
Training loss: 2.3857498168945312
Validation loss: 2.0524764160315194

Epoch: 5| Step: 5
Training loss: 1.8417726755142212
Validation loss: 2.0626381685336432

Epoch: 5| Step: 6
Training loss: 2.1130142211914062
Validation loss: 2.0499562174081802

Epoch: 5| Step: 7
Training loss: 2.1743550300598145
Validation loss: 2.054163088401159

Epoch: 5| Step: 8
Training loss: 2.227395534515381
Validation loss: 2.0466627130905786

Epoch: 5| Step: 9
Training loss: 2.1892380714416504
Validation loss: 2.042148912946383

Epoch: 5| Step: 10
Training loss: 1.9260047674179077
Validation loss: 2.060019781192144

Epoch: 5| Step: 11
Training loss: 2.3772614002227783
Validation loss: 2.0525291363398233

Epoch: 159| Step: 0
Training loss: 2.1756927967071533
Validation loss: 2.059824878970782

Epoch: 5| Step: 1
Training loss: 2.4251675605773926
Validation loss: 2.059362525741259

Epoch: 5| Step: 2
Training loss: 2.3145744800567627
Validation loss: 2.043377305070559

Epoch: 5| Step: 3
Training loss: 1.673099160194397
Validation loss: 2.0550454606612525

Epoch: 5| Step: 4
Training loss: 2.24350643157959
Validation loss: 2.067101925611496

Epoch: 5| Step: 5
Training loss: 2.4470279216766357
Validation loss: 2.0631014158328376

Epoch: 5| Step: 6
Training loss: 1.2277194261550903
Validation loss: 2.0589614709218345

Epoch: 5| Step: 7
Training loss: 2.0322747230529785
Validation loss: 2.049583146969477

Epoch: 5| Step: 8
Training loss: 2.1348555088043213
Validation loss: 2.0621535132328668

Epoch: 5| Step: 9
Training loss: 2.149181842803955
Validation loss: 2.0535354167222977

Epoch: 5| Step: 10
Training loss: 1.3016129732131958
Validation loss: 2.047367130716642

Epoch: 5| Step: 11
Training loss: 2.654200315475464
Validation loss: 2.0442777325709662

Epoch: 160| Step: 0
Training loss: 1.8622089624404907
Validation loss: 2.044003168741862

Epoch: 5| Step: 1
Training loss: 1.9401493072509766
Validation loss: 2.0459608087937036

Epoch: 5| Step: 2
Training loss: 1.5456219911575317
Validation loss: 2.0509262681007385

Epoch: 5| Step: 3
Training loss: 2.1632063388824463
Validation loss: 2.048799157142639

Epoch: 5| Step: 4
Training loss: 2.630699872970581
Validation loss: 2.0373467107613883

Epoch: 5| Step: 5
Training loss: 2.1316089630126953
Validation loss: 2.0631664842367172

Epoch: 5| Step: 6
Training loss: 1.8185619115829468
Validation loss: 2.056278814872106

Epoch: 5| Step: 7
Training loss: 2.6197750568389893
Validation loss: 2.062857002019882

Epoch: 5| Step: 8
Training loss: 1.2352193593978882
Validation loss: 2.051893432935079

Epoch: 5| Step: 9
Training loss: 2.186677932739258
Validation loss: 2.053221215804418

Epoch: 5| Step: 10
Training loss: 2.0604140758514404
Validation loss: 2.0591989854971566

Epoch: 5| Step: 11
Training loss: 2.7606863975524902
Validation loss: 2.054722785949707

Epoch: 161| Step: 0
Training loss: 2.0553441047668457
Validation loss: 2.0590959886709848

Epoch: 5| Step: 1
Training loss: 2.038421869277954
Validation loss: 2.0744504829247794

Epoch: 5| Step: 2
Training loss: 2.5456950664520264
Validation loss: 2.1094064861536026

Epoch: 5| Step: 3
Training loss: 2.3549115657806396
Validation loss: 2.1122566958268485

Epoch: 5| Step: 4
Training loss: 2.333418369293213
Validation loss: 2.111528525749842

Epoch: 5| Step: 5
Training loss: 2.4772439002990723
Validation loss: 2.1036106944084167

Epoch: 5| Step: 6
Training loss: 1.9270012378692627
Validation loss: 2.1073700239260993

Epoch: 5| Step: 7
Training loss: 1.3838320970535278
Validation loss: 2.075653294722239

Epoch: 5| Step: 8
Training loss: 2.1024558544158936
Validation loss: 2.068595548470815

Epoch: 5| Step: 9
Training loss: 1.9608657360076904
Validation loss: 2.063752293586731

Epoch: 5| Step: 10
Training loss: 1.6900142431259155
Validation loss: 2.0509428282578788

Epoch: 5| Step: 11
Training loss: 2.4078478813171387
Validation loss: 2.029504249493281

Epoch: 162| Step: 0
Training loss: 1.8839349746704102
Validation loss: 2.046969269712766

Epoch: 5| Step: 1
Training loss: 1.7431408166885376
Validation loss: 2.0616035958131156

Epoch: 5| Step: 2
Training loss: 2.57732892036438
Validation loss: 2.0643341342608132

Epoch: 5| Step: 3
Training loss: 3.0255959033966064
Validation loss: 2.0694980323314667

Epoch: 5| Step: 4
Training loss: 2.145514965057373
Validation loss: 2.090223545829455

Epoch: 5| Step: 5
Training loss: 2.218048095703125
Validation loss: 2.090980221827825

Epoch: 5| Step: 6
Training loss: 2.10444974899292
Validation loss: 2.0933188746372857

Epoch: 5| Step: 7
Training loss: 2.0674667358398438
Validation loss: 2.0961048305034637

Epoch: 5| Step: 8
Training loss: 2.0752155780792236
Validation loss: 2.102350393931071

Epoch: 5| Step: 9
Training loss: 1.9176822900772095
Validation loss: 2.1025700668493905

Epoch: 5| Step: 10
Training loss: 2.360469341278076
Validation loss: 2.094528098901113

Epoch: 5| Step: 11
Training loss: 2.041584014892578
Validation loss: 2.1037372002998986

Epoch: 163| Step: 0
Training loss: 2.4845383167266846
Validation loss: 2.096385439236959

Epoch: 5| Step: 1
Training loss: 1.6119515895843506
Validation loss: 2.1001624912023544

Epoch: 5| Step: 2
Training loss: 2.4314236640930176
Validation loss: 2.0875965605179467

Epoch: 5| Step: 3
Training loss: 2.1455435752868652
Validation loss: 2.0910394390424094

Epoch: 5| Step: 4
Training loss: 2.5082595348358154
Validation loss: 2.0823768277963004

Epoch: 5| Step: 5
Training loss: 1.995750069618225
Validation loss: 2.0800508161385856

Epoch: 5| Step: 6
Training loss: 1.9524414539337158
Validation loss: 2.078868413964907

Epoch: 5| Step: 7
Training loss: 1.6916955709457397
Validation loss: 2.07282521824042

Epoch: 5| Step: 8
Training loss: 2.054663896560669
Validation loss: 2.062329034010569

Epoch: 5| Step: 9
Training loss: 3.0800039768218994
Validation loss: 2.062378148237864

Epoch: 5| Step: 10
Training loss: 1.758893609046936
Validation loss: 2.046028549472491

Epoch: 5| Step: 11
Training loss: 2.801180601119995
Validation loss: 2.0490253617366156

Epoch: 164| Step: 0
Training loss: 2.3431692123413086
Validation loss: 2.0476050625244775

Epoch: 5| Step: 1
Training loss: 1.9714457988739014
Validation loss: 2.0478182484706244

Epoch: 5| Step: 2
Training loss: 2.76379656791687
Validation loss: 2.040211503704389

Epoch: 5| Step: 3
Training loss: 1.2577298879623413
Validation loss: 2.0387667963902154

Epoch: 5| Step: 4
Training loss: 2.650012493133545
Validation loss: 2.0398189375797906

Epoch: 5| Step: 5
Training loss: 2.21777081489563
Validation loss: 2.019486973683039

Epoch: 5| Step: 6
Training loss: 1.401322603225708
Validation loss: 2.032598545153936

Epoch: 5| Step: 7
Training loss: 2.3899052143096924
Validation loss: 2.0328534146149955

Epoch: 5| Step: 8
Training loss: 2.0284583568573
Validation loss: 2.015109106898308

Epoch: 5| Step: 9
Training loss: 1.809910535812378
Validation loss: 2.0363975365956626

Epoch: 5| Step: 10
Training loss: 2.157841682434082
Validation loss: 2.0308171659708023

Epoch: 5| Step: 11
Training loss: 1.6958435773849487
Validation loss: 2.0295306146144867

Epoch: 165| Step: 0
Training loss: 2.4375367164611816
Validation loss: 2.03967014948527

Epoch: 5| Step: 1
Training loss: 1.7848176956176758
Validation loss: 2.023623526096344

Epoch: 5| Step: 2
Training loss: 2.2619082927703857
Validation loss: 2.018695428967476

Epoch: 5| Step: 3
Training loss: 1.58005690574646
Validation loss: 2.022430583834648

Epoch: 5| Step: 4
Training loss: 1.9097788333892822
Validation loss: 2.030234937866529

Epoch: 5| Step: 5
Training loss: 1.6200015544891357
Validation loss: 2.030310163895289

Epoch: 5| Step: 6
Training loss: 2.359405517578125
Validation loss: 2.0231510996818542

Epoch: 5| Step: 7
Training loss: 2.5563805103302
Validation loss: 2.039081404606501

Epoch: 5| Step: 8
Training loss: 2.0441043376922607
Validation loss: 2.030966967344284

Epoch: 5| Step: 9
Training loss: 1.7879810333251953
Validation loss: 2.039938285946846

Epoch: 5| Step: 10
Training loss: 2.433640956878662
Validation loss: 2.033674264947573

Epoch: 5| Step: 11
Training loss: 2.50968599319458
Validation loss: 2.02859195570151

Epoch: 166| Step: 0
Training loss: 2.0814614295959473
Validation loss: 2.0191836853822074

Epoch: 5| Step: 1
Training loss: 1.7169513702392578
Validation loss: 2.0215297987063727

Epoch: 5| Step: 2
Training loss: 1.6486507654190063
Validation loss: 2.0214659919341407

Epoch: 5| Step: 3
Training loss: 2.3704161643981934
Validation loss: 2.025944486260414

Epoch: 5| Step: 4
Training loss: 2.0065956115722656
Validation loss: 2.0328965187072754

Epoch: 5| Step: 5
Training loss: 2.2100508213043213
Validation loss: 2.034421890974045

Epoch: 5| Step: 6
Training loss: 2.1411168575286865
Validation loss: 2.0368697941303253

Epoch: 5| Step: 7
Training loss: 2.5977442264556885
Validation loss: 2.0487422893444696

Epoch: 5| Step: 8
Training loss: 1.8358583450317383
Validation loss: 2.048032194375992

Epoch: 5| Step: 9
Training loss: 1.955933928489685
Validation loss: 2.0487712025642395

Epoch: 5| Step: 10
Training loss: 2.054337501525879
Validation loss: 2.0354537665843964

Epoch: 5| Step: 11
Training loss: 1.7574613094329834
Validation loss: 2.047048936287562

Epoch: 167| Step: 0
Training loss: 2.4228427410125732
Validation loss: 2.044440766175588

Epoch: 5| Step: 1
Training loss: 2.1845271587371826
Validation loss: 2.0466747730970383

Epoch: 5| Step: 2
Training loss: 1.9617398977279663
Validation loss: 2.0532219211260476

Epoch: 5| Step: 3
Training loss: 2.3423140048980713
Validation loss: 2.062056690454483

Epoch: 5| Step: 4
Training loss: 1.8911933898925781
Validation loss: 2.0532984882593155

Epoch: 5| Step: 5
Training loss: 1.6378599405288696
Validation loss: 2.062712222337723

Epoch: 5| Step: 6
Training loss: 2.068657636642456
Validation loss: 2.0609132846196494

Epoch: 5| Step: 7
Training loss: 2.125129461288452
Validation loss: 2.0500966807206473

Epoch: 5| Step: 8
Training loss: 1.5414260625839233
Validation loss: 2.0476051966349282

Epoch: 5| Step: 9
Training loss: 1.8185513019561768
Validation loss: 2.0455771734317145

Epoch: 5| Step: 10
Training loss: 2.1594491004943848
Validation loss: 2.0526318897803626

Epoch: 5| Step: 11
Training loss: 3.170384407043457
Validation loss: 2.0383752286434174

Epoch: 168| Step: 0
Training loss: 2.202009439468384
Validation loss: 2.04572930932045

Epoch: 5| Step: 1
Training loss: 1.8820558786392212
Validation loss: 2.041340043147405

Epoch: 5| Step: 2
Training loss: 2.194150447845459
Validation loss: 2.0388460407654443

Epoch: 5| Step: 3
Training loss: 1.890557885169983
Validation loss: 2.0300547381242118

Epoch: 5| Step: 4
Training loss: 1.8962091207504272
Validation loss: 2.022142509619395

Epoch: 5| Step: 5
Training loss: 2.466254949569702
Validation loss: 2.031048814455668

Epoch: 5| Step: 6
Training loss: 2.4674291610717773
Validation loss: 2.0336428930362067

Epoch: 5| Step: 7
Training loss: 2.156864643096924
Validation loss: 2.033172686894735

Epoch: 5| Step: 8
Training loss: 1.4706867933273315
Validation loss: 2.027040476600329

Epoch: 5| Step: 9
Training loss: 2.09582257270813
Validation loss: 2.0185016642014184

Epoch: 5| Step: 10
Training loss: 2.071890354156494
Validation loss: 2.028099606434504

Epoch: 5| Step: 11
Training loss: 1.8704310655593872
Validation loss: 2.0143701235453286

Epoch: 169| Step: 0
Training loss: 2.134925365447998
Validation loss: 2.021521990497907

Epoch: 5| Step: 1
Training loss: 2.2751336097717285
Validation loss: 2.0206004778544107

Epoch: 5| Step: 2
Training loss: 1.573568344116211
Validation loss: 2.0184357116619744

Epoch: 5| Step: 3
Training loss: 2.194258689880371
Validation loss: 2.029862567782402

Epoch: 5| Step: 4
Training loss: 2.8799707889556885
Validation loss: 2.028868153691292

Epoch: 5| Step: 5
Training loss: 1.8014469146728516
Validation loss: 2.035507077972094

Epoch: 5| Step: 6
Training loss: 1.5445749759674072
Validation loss: 2.038174942135811

Epoch: 5| Step: 7
Training loss: 1.9038245677947998
Validation loss: 2.03670368095239

Epoch: 5| Step: 8
Training loss: 1.8164819478988647
Validation loss: 2.0465097030003867

Epoch: 5| Step: 9
Training loss: 2.307309627532959
Validation loss: 2.0449881851673126

Epoch: 5| Step: 10
Training loss: 1.9170808792114258
Validation loss: 2.047113170226415

Epoch: 5| Step: 11
Training loss: 2.362969398498535
Validation loss: 2.0575773318608603

Epoch: 170| Step: 0
Training loss: 2.5167834758758545
Validation loss: 2.0424263924360275

Epoch: 5| Step: 1
Training loss: 2.076826572418213
Validation loss: 2.0376460502545037

Epoch: 5| Step: 2
Training loss: 1.839464783668518
Validation loss: 2.041503682732582

Epoch: 5| Step: 3
Training loss: 1.9086717367172241
Validation loss: 2.0388678163290024

Epoch: 5| Step: 4
Training loss: 2.113719940185547
Validation loss: 2.0366488049427667

Epoch: 5| Step: 5
Training loss: 2.0088798999786377
Validation loss: 2.0361971954504647

Epoch: 5| Step: 6
Training loss: 2.3073558807373047
Validation loss: 2.0382386843363443

Epoch: 5| Step: 7
Training loss: 1.8544212579727173
Validation loss: 2.0402680536111197

Epoch: 5| Step: 8
Training loss: 1.9759719371795654
Validation loss: 2.0401692489782968

Epoch: 5| Step: 9
Training loss: 1.739572286605835
Validation loss: 2.0401348769664764

Epoch: 5| Step: 10
Training loss: 2.062791109085083
Validation loss: 2.042314355572065

Epoch: 5| Step: 11
Training loss: 2.5021402835845947
Validation loss: 2.036473805705706

Epoch: 171| Step: 0
Training loss: 2.2993667125701904
Validation loss: 2.033242846528689

Epoch: 5| Step: 1
Training loss: 2.0964255332946777
Validation loss: 2.040832057595253

Epoch: 5| Step: 2
Training loss: 2.6126246452331543
Validation loss: 2.0545983562866845

Epoch: 5| Step: 3
Training loss: 2.106828212738037
Validation loss: 2.053979516029358

Epoch: 5| Step: 4
Training loss: 1.8606822490692139
Validation loss: 2.063631241520246

Epoch: 5| Step: 5
Training loss: 1.9319454431533813
Validation loss: 2.0591529458761215

Epoch: 5| Step: 6
Training loss: 2.225151538848877
Validation loss: 2.0659338384866714

Epoch: 5| Step: 7
Training loss: 1.683868408203125
Validation loss: 2.058139517903328

Epoch: 5| Step: 8
Training loss: 2.0968146324157715
Validation loss: 2.0433192253112793

Epoch: 5| Step: 9
Training loss: 1.8690307140350342
Validation loss: 2.0267964551846185

Epoch: 5| Step: 10
Training loss: 2.2116870880126953
Validation loss: 2.0187591860691705

Epoch: 5| Step: 11
Training loss: 2.065037488937378
Validation loss: 2.0200510174036026

Epoch: 172| Step: 0
Training loss: 1.8001811504364014
Validation loss: 2.0218225667874017

Epoch: 5| Step: 1
Training loss: 1.8419227600097656
Validation loss: 2.028057490785917

Epoch: 5| Step: 2
Training loss: 1.8411611318588257
Validation loss: 2.0462219218413034

Epoch: 5| Step: 3
Training loss: 1.7170730829238892
Validation loss: 2.0455805162588754

Epoch: 5| Step: 4
Training loss: 2.2009963989257812
Validation loss: 2.049844225247701

Epoch: 5| Step: 5
Training loss: 2.50039005279541
Validation loss: 2.051057750980059

Epoch: 5| Step: 6
Training loss: 2.3366546630859375
Validation loss: 2.0555108934640884

Epoch: 5| Step: 7
Training loss: 2.353010654449463
Validation loss: 2.0552472670873008

Epoch: 5| Step: 8
Training loss: 2.3347554206848145
Validation loss: 2.059034377336502

Epoch: 5| Step: 9
Training loss: 1.7450408935546875
Validation loss: 2.0560266027847924

Epoch: 5| Step: 10
Training loss: 2.388704776763916
Validation loss: 2.0552714814742408

Epoch: 5| Step: 11
Training loss: 1.1894713640213013
Validation loss: 2.040272533893585

Epoch: 173| Step: 0
Training loss: 2.5505154132843018
Validation loss: 2.0483548690875373

Epoch: 5| Step: 1
Training loss: 2.2280547618865967
Validation loss: 2.0353972613811493

Epoch: 5| Step: 2
Training loss: 1.9388341903686523
Validation loss: 2.0388654371102652

Epoch: 5| Step: 3
Training loss: 1.4489881992340088
Validation loss: 2.0319384833176932

Epoch: 5| Step: 4
Training loss: 2.1544864177703857
Validation loss: 2.0380188822746277

Epoch: 5| Step: 5
Training loss: 1.8316962718963623
Validation loss: 2.042032534877459

Epoch: 5| Step: 6
Training loss: 2.422823190689087
Validation loss: 2.048261652390162

Epoch: 5| Step: 7
Training loss: 2.01353120803833
Validation loss: 2.0467128654321036

Epoch: 5| Step: 8
Training loss: 2.5826473236083984
Validation loss: 2.051292116443316

Epoch: 5| Step: 9
Training loss: 1.8181629180908203
Validation loss: 2.056244527300199

Epoch: 5| Step: 10
Training loss: 1.714708685874939
Validation loss: 2.04894757270813

Epoch: 5| Step: 11
Training loss: 1.7865509986877441
Validation loss: 2.0418758541345596

Epoch: 174| Step: 0
Training loss: 2.3336360454559326
Validation loss: 2.0372690558433533

Epoch: 5| Step: 1
Training loss: 1.7913334369659424
Validation loss: 2.040478636821111

Epoch: 5| Step: 2
Training loss: 1.6524121761322021
Validation loss: 2.045740614334742

Epoch: 5| Step: 3
Training loss: 2.3512635231018066
Validation loss: 2.0486924598614373

Epoch: 5| Step: 4
Training loss: 2.2625374794006348
Validation loss: 2.06328554948171

Epoch: 5| Step: 5
Training loss: 1.8224689960479736
Validation loss: 2.060930738846461

Epoch: 5| Step: 6
Training loss: 2.187351703643799
Validation loss: 2.0529117385546365

Epoch: 5| Step: 7
Training loss: 1.1721546649932861
Validation loss: 2.059413726131121

Epoch: 5| Step: 8
Training loss: 2.0255203247070312
Validation loss: 2.0695840617020926

Epoch: 5| Step: 9
Training loss: 1.7487447261810303
Validation loss: 2.071111485362053

Epoch: 5| Step: 10
Training loss: 2.6781768798828125
Validation loss: 2.0755707224210105

Epoch: 5| Step: 11
Training loss: 3.5310628414154053
Validation loss: 2.074484889705976

Epoch: 175| Step: 0
Training loss: 1.7785440683364868
Validation loss: 2.0609067529439926

Epoch: 5| Step: 1
Training loss: 2.703909158706665
Validation loss: 2.0576989402373633

Epoch: 5| Step: 2
Training loss: 2.0834927558898926
Validation loss: 2.043981825311979

Epoch: 5| Step: 3
Training loss: 2.236048460006714
Validation loss: 2.0553297052780786

Epoch: 5| Step: 4
Training loss: 1.6886008977890015
Validation loss: 2.0477578938007355

Epoch: 5| Step: 5
Training loss: 2.1225972175598145
Validation loss: 2.039502943555514

Epoch: 5| Step: 6
Training loss: 1.6907117366790771
Validation loss: 2.0361773322025933

Epoch: 5| Step: 7
Training loss: 2.013327121734619
Validation loss: 2.044582019249598

Epoch: 5| Step: 8
Training loss: 1.3106153011322021
Validation loss: 2.0428249537944794

Epoch: 5| Step: 9
Training loss: 2.4794297218322754
Validation loss: 2.039121742049853

Epoch: 5| Step: 10
Training loss: 2.222698926925659
Validation loss: 2.029622053106626

Epoch: 5| Step: 11
Training loss: 2.243072509765625
Validation loss: 2.0455242097377777

Epoch: 176| Step: 0
Training loss: 2.044128894805908
Validation loss: 2.035624717672666

Epoch: 5| Step: 1
Training loss: 1.776268720626831
Validation loss: 2.040816123286883

Epoch: 5| Step: 2
Training loss: 2.143433094024658
Validation loss: 2.03336763381958

Epoch: 5| Step: 3
Training loss: 1.896985411643982
Validation loss: 2.038174589474996

Epoch: 5| Step: 4
Training loss: 1.971604347229004
Validation loss: 2.04990624388059

Epoch: 5| Step: 5
Training loss: 1.536486268043518
Validation loss: 2.0323435813188553

Epoch: 5| Step: 6
Training loss: 2.088686943054199
Validation loss: 2.02871801952521

Epoch: 5| Step: 7
Training loss: 2.3518099784851074
Validation loss: 2.031868507464727

Epoch: 5| Step: 8
Training loss: 2.215747833251953
Validation loss: 2.031807228922844

Epoch: 5| Step: 9
Training loss: 2.126455783843994
Validation loss: 2.0380472938219705

Epoch: 5| Step: 10
Training loss: 2.2699177265167236
Validation loss: 2.039326017101606

Epoch: 5| Step: 11
Training loss: 1.605013132095337
Validation loss: 2.03195991118749

Epoch: 177| Step: 0
Training loss: 2.2662012577056885
Validation loss: 2.0310534487167993

Epoch: 5| Step: 1
Training loss: 1.7536327838897705
Validation loss: 2.036162575085958

Epoch: 5| Step: 2
Training loss: 1.9094245433807373
Validation loss: 2.034229596455892

Epoch: 5| Step: 3
Training loss: 1.748180627822876
Validation loss: 2.0469290912151337

Epoch: 5| Step: 4
Training loss: 1.8528797626495361
Validation loss: 2.0433521469434104

Epoch: 5| Step: 5
Training loss: 1.777325987815857
Validation loss: 2.0235245376825333

Epoch: 5| Step: 6
Training loss: 2.7695460319519043
Validation loss: 2.0416062275568643

Epoch: 5| Step: 7
Training loss: 2.0054478645324707
Validation loss: 2.014899735649427

Epoch: 5| Step: 8
Training loss: 2.092747926712036
Validation loss: 2.0404225140810013

Epoch: 5| Step: 9
Training loss: 2.2557520866394043
Validation loss: 2.0247336824735007

Epoch: 5| Step: 10
Training loss: 2.2160727977752686
Validation loss: 2.0405770738919577

Epoch: 5| Step: 11
Training loss: 1.2153812646865845
Validation loss: 2.042877435684204

Epoch: 178| Step: 0
Training loss: 1.894850492477417
Validation loss: 2.0347975144783654

Epoch: 5| Step: 1
Training loss: 1.911435842514038
Validation loss: 2.0293497095505395

Epoch: 5| Step: 2
Training loss: 2.012666940689087
Validation loss: 2.0506981362899146

Epoch: 5| Step: 3
Training loss: 1.5918242931365967
Validation loss: 2.0687498648961387

Epoch: 5| Step: 4
Training loss: 1.8556592464447021
Validation loss: 2.065931499004364

Epoch: 5| Step: 5
Training loss: 2.4660065174102783
Validation loss: 2.052295575539271

Epoch: 5| Step: 6
Training loss: 2.2744221687316895
Validation loss: 2.0528616656859717

Epoch: 5| Step: 7
Training loss: 1.576155424118042
Validation loss: 2.039811059832573

Epoch: 5| Step: 8
Training loss: 2.1252803802490234
Validation loss: 2.0463742911815643

Epoch: 5| Step: 9
Training loss: 2.1095993518829346
Validation loss: 2.0360683103402457

Epoch: 5| Step: 10
Training loss: 2.60492205619812
Validation loss: 2.0339627861976624

Epoch: 5| Step: 11
Training loss: 2.2274553775787354
Validation loss: 2.0337515672047934

Epoch: 179| Step: 0
Training loss: 2.169869899749756
Validation loss: 2.0304593394200006

Epoch: 5| Step: 1
Training loss: 2.0558745861053467
Validation loss: 2.0112309406201043

Epoch: 5| Step: 2
Training loss: 2.452509641647339
Validation loss: 2.017462983727455

Epoch: 5| Step: 3
Training loss: 2.064155101776123
Validation loss: 2.011741667985916

Epoch: 5| Step: 4
Training loss: 2.1973369121551514
Validation loss: 2.0173149506251016

Epoch: 5| Step: 5
Training loss: 1.8294509649276733
Validation loss: 2.0222827196121216

Epoch: 5| Step: 6
Training loss: 1.5650966167449951
Validation loss: 2.017514616250992

Epoch: 5| Step: 7
Training loss: 2.283658266067505
Validation loss: 2.031912555297216

Epoch: 5| Step: 8
Training loss: 1.60824716091156
Validation loss: 2.0377616931994758

Epoch: 5| Step: 9
Training loss: 2.1905124187469482
Validation loss: 2.027742460370064

Epoch: 5| Step: 10
Training loss: 2.213024139404297
Validation loss: 2.0469800184170404

Epoch: 5| Step: 11
Training loss: 1.336341381072998
Validation loss: 2.0395428289969764

Epoch: 180| Step: 0
Training loss: 1.641853928565979
Validation loss: 2.0323306123415628

Epoch: 5| Step: 1
Training loss: 2.0986037254333496
Validation loss: 2.0457900166511536

Epoch: 5| Step: 2
Training loss: 2.11216402053833
Validation loss: 2.036401480436325

Epoch: 5| Step: 3
Training loss: 1.5411049127578735
Validation loss: 2.041505460937818

Epoch: 5| Step: 4
Training loss: 2.5616164207458496
Validation loss: 2.053058718641599

Epoch: 5| Step: 5
Training loss: 1.9537090063095093
Validation loss: 2.0485734790563583

Epoch: 5| Step: 6
Training loss: 1.8260033130645752
Validation loss: 2.047940040628115

Epoch: 5| Step: 7
Training loss: 2.115309238433838
Validation loss: 2.066348284482956

Epoch: 5| Step: 8
Training loss: 1.7296301126480103
Validation loss: 2.05985693136851

Epoch: 5| Step: 9
Training loss: 2.3907790184020996
Validation loss: 2.041654715935389

Epoch: 5| Step: 10
Training loss: 2.083934783935547
Validation loss: 2.0490455627441406

Epoch: 5| Step: 11
Training loss: 2.455108880996704
Validation loss: 2.0538597454627356

Epoch: 181| Step: 0
Training loss: 2.1602859497070312
Validation loss: 2.058919057250023

Epoch: 5| Step: 1
Training loss: 1.9230220317840576
Validation loss: 2.070549656947454

Epoch: 5| Step: 2
Training loss: 2.7277512550354004
Validation loss: 2.0604832420746484

Epoch: 5| Step: 3
Training loss: 1.4241987466812134
Validation loss: 2.0622678945461907

Epoch: 5| Step: 4
Training loss: 2.3591532707214355
Validation loss: 2.057970797022184

Epoch: 5| Step: 5
Training loss: 2.162778854370117
Validation loss: 2.0650092164675393

Epoch: 5| Step: 6
Training loss: 2.1770119667053223
Validation loss: 2.072534069418907

Epoch: 5| Step: 7
Training loss: 1.7775672674179077
Validation loss: 2.070002799232801

Epoch: 5| Step: 8
Training loss: 2.2284865379333496
Validation loss: 2.0711709707975388

Epoch: 5| Step: 9
Training loss: 1.466813325881958
Validation loss: 2.069484362999598

Epoch: 5| Step: 10
Training loss: 1.8854420185089111
Validation loss: 2.0695945223172507

Epoch: 5| Step: 11
Training loss: 0.9163810014724731
Validation loss: 2.072143708666166

Epoch: 182| Step: 0
Training loss: 1.7506799697875977
Validation loss: 2.0723279317220054

Epoch: 5| Step: 1
Training loss: 2.052488327026367
Validation loss: 2.0756694177786508

Epoch: 5| Step: 2
Training loss: 2.119523525238037
Validation loss: 2.0767821967601776

Epoch: 5| Step: 3
Training loss: 1.7354854345321655
Validation loss: 2.0741972972949347

Epoch: 5| Step: 4
Training loss: 2.2103328704833984
Validation loss: 2.07449180384477

Epoch: 5| Step: 5
Training loss: 1.5635788440704346
Validation loss: 2.0795141657193503

Epoch: 5| Step: 6
Training loss: 1.7195608615875244
Validation loss: 2.0891378670930862

Epoch: 5| Step: 7
Training loss: 2.2745330333709717
Validation loss: 2.089301347732544

Epoch: 5| Step: 8
Training loss: 2.1135966777801514
Validation loss: 2.0756255437930426

Epoch: 5| Step: 9
Training loss: 2.02959942817688
Validation loss: 2.0856789648532867

Epoch: 5| Step: 10
Training loss: 2.3353452682495117
Validation loss: 2.092919647693634

Epoch: 5| Step: 11
Training loss: 2.405236005783081
Validation loss: 2.087660829226176

Epoch: 183| Step: 0
Training loss: 1.680149793624878
Validation loss: 2.088174988826116

Epoch: 5| Step: 1
Training loss: 1.8722200393676758
Validation loss: 2.085037733117739

Epoch: 5| Step: 2
Training loss: 2.4133498668670654
Validation loss: 2.093452289700508

Epoch: 5| Step: 3
Training loss: 1.9357563257217407
Validation loss: 2.0901537289222083

Epoch: 5| Step: 4
Training loss: 2.1706771850585938
Validation loss: 2.097460766633352

Epoch: 5| Step: 5
Training loss: 2.016188144683838
Validation loss: 2.1029902547597885

Epoch: 5| Step: 6
Training loss: 1.7033402919769287
Validation loss: 2.082002873222033

Epoch: 5| Step: 7
Training loss: 1.9137636423110962
Validation loss: 2.096831222375234

Epoch: 5| Step: 8
Training loss: 2.506054639816284
Validation loss: 2.0804460098346076

Epoch: 5| Step: 9
Training loss: 1.6191139221191406
Validation loss: 2.088418776790301

Epoch: 5| Step: 10
Training loss: 1.991309404373169
Validation loss: 2.076334531108538

Epoch: 5| Step: 11
Training loss: 2.7848517894744873
Validation loss: 2.0817660291989646

Epoch: 184| Step: 0
Training loss: 1.7746288776397705
Validation loss: 2.086825579404831

Epoch: 5| Step: 1
Training loss: 2.0631651878356934
Validation loss: 2.0828975637753806

Epoch: 5| Step: 2
Training loss: 1.6684658527374268
Validation loss: 2.081964229544004

Epoch: 5| Step: 3
Training loss: 2.018183469772339
Validation loss: 2.069545552134514

Epoch: 5| Step: 4
Training loss: 2.245651960372925
Validation loss: 2.0818693737188974

Epoch: 5| Step: 5
Training loss: 2.077971935272217
Validation loss: 2.089380373557409

Epoch: 5| Step: 6
Training loss: 1.8700841665267944
Validation loss: 2.085883046189944

Epoch: 5| Step: 7
Training loss: 1.8956737518310547
Validation loss: 2.0741670479377112

Epoch: 5| Step: 8
Training loss: 2.2294414043426514
Validation loss: 2.073634366194407

Epoch: 5| Step: 9
Training loss: 2.388842821121216
Validation loss: 2.072614088654518

Epoch: 5| Step: 10
Training loss: 1.7856552600860596
Validation loss: 2.0728986213604608

Epoch: 5| Step: 11
Training loss: 2.2350916862487793
Validation loss: 2.0763175835212073

Epoch: 185| Step: 0
Training loss: 1.9530185461044312
Validation loss: 2.113255942861239

Epoch: 5| Step: 1
Training loss: 1.7941402196884155
Validation loss: 2.0882734855016074

Epoch: 5| Step: 2
Training loss: 1.7810118198394775
Validation loss: 2.079385752479235

Epoch: 5| Step: 3
Training loss: 2.064101457595825
Validation loss: 2.06613223751386

Epoch: 5| Step: 4
Training loss: 1.6762197017669678
Validation loss: 2.054120421409607

Epoch: 5| Step: 5
Training loss: 2.0542404651641846
Validation loss: 2.0724718471368155

Epoch: 5| Step: 6
Training loss: 1.729852318763733
Validation loss: 2.056256035963694

Epoch: 5| Step: 7
Training loss: 2.8009352684020996
Validation loss: 2.0543861339489617

Epoch: 5| Step: 8
Training loss: 2.35949969291687
Validation loss: 2.031314104795456

Epoch: 5| Step: 9
Training loss: 1.7076038122177124
Validation loss: 2.048393507798513

Epoch: 5| Step: 10
Training loss: 2.049633264541626
Validation loss: 2.0411358227332435

Epoch: 5| Step: 11
Training loss: 2.442622423171997
Validation loss: 2.0378474444150925

Epoch: 186| Step: 0
Training loss: 1.9200384616851807
Validation loss: 2.024054487546285

Epoch: 5| Step: 1
Training loss: 1.7577006816864014
Validation loss: 2.019058202703794

Epoch: 5| Step: 2
Training loss: 2.0741677284240723
Validation loss: 2.0263659258683524

Epoch: 5| Step: 3
Training loss: 2.1290359497070312
Validation loss: 2.014066621661186

Epoch: 5| Step: 4
Training loss: 2.1076722145080566
Validation loss: 2.0158488055070243

Epoch: 5| Step: 5
Training loss: 2.123591899871826
Validation loss: 2.0150862832864127

Epoch: 5| Step: 6
Training loss: 2.396299123764038
Validation loss: 2.021956115961075

Epoch: 5| Step: 7
Training loss: 1.624882698059082
Validation loss: 2.020509714881579

Epoch: 5| Step: 8
Training loss: 1.9476234912872314
Validation loss: 2.018640716870626

Epoch: 5| Step: 9
Training loss: 2.268122911453247
Validation loss: 2.0313308338324227

Epoch: 5| Step: 10
Training loss: 2.1497340202331543
Validation loss: 2.020955433448156

Epoch: 5| Step: 11
Training loss: 1.923271894454956
Validation loss: 2.0278818358977637

Epoch: 187| Step: 0
Training loss: 1.2986633777618408
Validation loss: 2.0411042173703513

Epoch: 5| Step: 1
Training loss: 2.016371965408325
Validation loss: 2.0324344833691916

Epoch: 5| Step: 2
Training loss: 1.7441896200180054
Validation loss: 2.0505343476931253

Epoch: 5| Step: 3
Training loss: 2.5609843730926514
Validation loss: 2.0589072356621423

Epoch: 5| Step: 4
Training loss: 2.2945556640625
Validation loss: 2.061791956424713

Epoch: 5| Step: 5
Training loss: 2.0790157318115234
Validation loss: 2.0585742543141046

Epoch: 5| Step: 6
Training loss: 2.0904810428619385
Validation loss: 2.0700863003730774

Epoch: 5| Step: 7
Training loss: 1.752598762512207
Validation loss: 2.067137822508812

Epoch: 5| Step: 8
Training loss: 2.799365997314453
Validation loss: 2.073983604709307

Epoch: 5| Step: 9
Training loss: 1.824151635169983
Validation loss: 2.0578603645165763

Epoch: 5| Step: 10
Training loss: 1.777806043624878
Validation loss: 2.0637907485167184

Epoch: 5| Step: 11
Training loss: 1.5135847330093384
Validation loss: 2.067348450422287

Epoch: 188| Step: 0
Training loss: 1.6051117181777954
Validation loss: 2.048295627037684

Epoch: 5| Step: 1
Training loss: 2.143575668334961
Validation loss: 2.0354174425204596

Epoch: 5| Step: 2
Training loss: 1.8107283115386963
Validation loss: 2.06740195552508

Epoch: 5| Step: 3
Training loss: 2.560358762741089
Validation loss: 2.0764384071032205

Epoch: 5| Step: 4
Training loss: 1.4095842838287354
Validation loss: 2.065821240345637

Epoch: 5| Step: 5
Training loss: 2.1850762367248535
Validation loss: 2.076081613699595

Epoch: 5| Step: 6
Training loss: 2.495177984237671
Validation loss: 2.083750774463018

Epoch: 5| Step: 7
Training loss: 2.204000949859619
Validation loss: 2.0644924690326056

Epoch: 5| Step: 8
Training loss: 2.273346424102783
Validation loss: 2.0701505740483603

Epoch: 5| Step: 9
Training loss: 2.4865036010742188
Validation loss: 2.0720565815766654

Epoch: 5| Step: 10
Training loss: 1.911024808883667
Validation loss: 2.0645066599051156

Epoch: 5| Step: 11
Training loss: 1.8586446046829224
Validation loss: 2.0668776084979377

Epoch: 189| Step: 0
Training loss: 1.8288110494613647
Validation loss: 2.0642090141773224

Epoch: 5| Step: 1
Training loss: 2.3601434230804443
Validation loss: 2.0589666118224463

Epoch: 5| Step: 2
Training loss: 2.581817626953125
Validation loss: 2.040702352921168

Epoch: 5| Step: 3
Training loss: 1.6986154317855835
Validation loss: 2.0497756054004035

Epoch: 5| Step: 4
Training loss: 2.0707664489746094
Validation loss: 2.0479788978894553

Epoch: 5| Step: 5
Training loss: 2.300806760787964
Validation loss: 2.048888603846232

Epoch: 5| Step: 6
Training loss: 2.1382813453674316
Validation loss: 2.045631761352221

Epoch: 5| Step: 7
Training loss: 1.9638593196868896
Validation loss: 2.050356164574623

Epoch: 5| Step: 8
Training loss: 2.0156538486480713
Validation loss: 2.0427894393603006

Epoch: 5| Step: 9
Training loss: 1.7138900756835938
Validation loss: 2.052738770842552

Epoch: 5| Step: 10
Training loss: 2.243342876434326
Validation loss: 2.056384483973185

Epoch: 5| Step: 11
Training loss: 1.7766196727752686
Validation loss: 2.0448806981245675

Epoch: 190| Step: 0
Training loss: 1.7495330572128296
Validation loss: 2.0577418506145477

Epoch: 5| Step: 1
Training loss: 1.6896774768829346
Validation loss: 2.056323528289795

Epoch: 5| Step: 2
Training loss: 2.123549222946167
Validation loss: 2.051520844300588

Epoch: 5| Step: 3
Training loss: 2.039318323135376
Validation loss: 2.061317279934883

Epoch: 5| Step: 4
Training loss: 2.0764336585998535
Validation loss: 2.0520002245903015

Epoch: 5| Step: 5
Training loss: 2.0691959857940674
Validation loss: 2.0498308887084327

Epoch: 5| Step: 6
Training loss: 2.325035810470581
Validation loss: 2.0552860697110495

Epoch: 5| Step: 7
Training loss: 2.3955116271972656
Validation loss: 2.055421680212021

Epoch: 5| Step: 8
Training loss: 2.370788097381592
Validation loss: 2.04647496342659

Epoch: 5| Step: 9
Training loss: 1.8370628356933594
Validation loss: 2.0629651049772897

Epoch: 5| Step: 10
Training loss: 1.8734657764434814
Validation loss: 2.058256655931473

Epoch: 5| Step: 11
Training loss: 1.570631980895996
Validation loss: 2.07330655058225

Epoch: 191| Step: 0
Training loss: 1.5409209728240967
Validation loss: 2.0626932829618454

Epoch: 5| Step: 1
Training loss: 2.2438178062438965
Validation loss: 2.0635633319616318

Epoch: 5| Step: 2
Training loss: 2.239309310913086
Validation loss: 2.063059151172638

Epoch: 5| Step: 3
Training loss: 2.3094189167022705
Validation loss: 2.0635945995648703

Epoch: 5| Step: 4
Training loss: 1.8136799335479736
Validation loss: 2.0625957349936166

Epoch: 5| Step: 5
Training loss: 2.514791488647461
Validation loss: 2.067529653509458

Epoch: 5| Step: 6
Training loss: 2.336501359939575
Validation loss: 2.069269965092341

Epoch: 5| Step: 7
Training loss: 1.5470850467681885
Validation loss: 2.0710536539554596

Epoch: 5| Step: 8
Training loss: 1.8317797183990479
Validation loss: 2.068374673525492

Epoch: 5| Step: 9
Training loss: 1.6298749446868896
Validation loss: 2.0653428435325623

Epoch: 5| Step: 10
Training loss: 2.2759177684783936
Validation loss: 2.055141935745875

Epoch: 5| Step: 11
Training loss: 1.999870777130127
Validation loss: 2.0723101248343787

Epoch: 192| Step: 0
Training loss: 2.1753411293029785
Validation loss: 2.063077981273333

Epoch: 5| Step: 1
Training loss: 2.1501340866088867
Validation loss: 2.0832374642292657

Epoch: 5| Step: 2
Training loss: 2.4589035511016846
Validation loss: 2.061236431201299

Epoch: 5| Step: 3
Training loss: 1.4404178857803345
Validation loss: 2.057862604657809

Epoch: 5| Step: 4
Training loss: 1.5458625555038452
Validation loss: 2.0564569731553397

Epoch: 5| Step: 5
Training loss: 2.352233409881592
Validation loss: 2.0553629646698632

Epoch: 5| Step: 6
Training loss: 1.668238878250122
Validation loss: 2.052767167488734

Epoch: 5| Step: 7
Training loss: 2.1540496349334717
Validation loss: 2.060392012198766

Epoch: 5| Step: 8
Training loss: 1.9137847423553467
Validation loss: 2.054419293999672

Epoch: 5| Step: 9
Training loss: 1.7969980239868164
Validation loss: 2.054995536804199

Epoch: 5| Step: 10
Training loss: 2.30363130569458
Validation loss: 2.063489630818367

Epoch: 5| Step: 11
Training loss: 2.362812042236328
Validation loss: 2.0592894156773887

Epoch: 193| Step: 0
Training loss: 1.5945311784744263
Validation loss: 2.059172491232554

Epoch: 5| Step: 1
Training loss: 2.060305118560791
Validation loss: 2.0607795218626657

Epoch: 5| Step: 2
Training loss: 1.948530912399292
Validation loss: 2.064376095930735

Epoch: 5| Step: 3
Training loss: 1.6805131435394287
Validation loss: 2.059978981812795

Epoch: 5| Step: 4
Training loss: 1.7190778255462646
Validation loss: 2.070491219560305

Epoch: 5| Step: 5
Training loss: 2.340991258621216
Validation loss: 2.0700639883677163

Epoch: 5| Step: 6
Training loss: 1.7494068145751953
Validation loss: 2.0782981365919113

Epoch: 5| Step: 7
Training loss: 2.6153147220611572
Validation loss: 2.0781956712404885

Epoch: 5| Step: 8
Training loss: 2.413733959197998
Validation loss: 2.0745287785927453

Epoch: 5| Step: 9
Training loss: 1.888117790222168
Validation loss: 2.0765338937441506

Epoch: 5| Step: 10
Training loss: 1.8187828063964844
Validation loss: 2.081592932343483

Epoch: 5| Step: 11
Training loss: 2.302321434020996
Validation loss: 2.0806338091691337

Epoch: 194| Step: 0
Training loss: 1.6150896549224854
Validation loss: 2.0886709839105606

Epoch: 5| Step: 1
Training loss: 1.7140223979949951
Validation loss: 2.0786324441432953

Epoch: 5| Step: 2
Training loss: 2.3845887184143066
Validation loss: 2.0650993982950845

Epoch: 5| Step: 3
Training loss: 2.013646125793457
Validation loss: 2.050520807504654

Epoch: 5| Step: 4
Training loss: 2.1171715259552
Validation loss: 2.059100310007731

Epoch: 5| Step: 5
Training loss: 1.740447759628296
Validation loss: 2.0423912703990936

Epoch: 5| Step: 6
Training loss: 2.7422752380371094
Validation loss: 2.0545541743437448

Epoch: 5| Step: 7
Training loss: 1.9601218700408936
Validation loss: 2.048766906062762

Epoch: 5| Step: 8
Training loss: 1.5511491298675537
Validation loss: 2.047047500809034

Epoch: 5| Step: 9
Training loss: 1.909979224205017
Validation loss: 2.0366060783465705

Epoch: 5| Step: 10
Training loss: 2.275357723236084
Validation loss: 2.056990926464399

Epoch: 5| Step: 11
Training loss: 2.234683036804199
Validation loss: 2.050201659401258

Epoch: 195| Step: 0
Training loss: 1.79171884059906
Validation loss: 2.0551915069421134

Epoch: 5| Step: 1
Training loss: 1.7595469951629639
Validation loss: 2.058508331576983

Epoch: 5| Step: 2
Training loss: 2.431318998336792
Validation loss: 2.0774786174297333

Epoch: 5| Step: 3
Training loss: 1.8313219547271729
Validation loss: 2.0827531069517136

Epoch: 5| Step: 4
Training loss: 1.9890339374542236
Validation loss: 2.0735313991705575

Epoch: 5| Step: 5
Training loss: 1.7677299976348877
Validation loss: 2.0830139418443046

Epoch: 5| Step: 6
Training loss: 2.4218544960021973
Validation loss: 2.082149550318718

Epoch: 5| Step: 7
Training loss: 2.1366443634033203
Validation loss: 2.0875568985939026

Epoch: 5| Step: 8
Training loss: 1.8678274154663086
Validation loss: 2.0969526171684265

Epoch: 5| Step: 9
Training loss: 1.8217452764511108
Validation loss: 2.0995328028996787

Epoch: 5| Step: 10
Training loss: 2.106127977371216
Validation loss: 2.099000468850136

Epoch: 5| Step: 11
Training loss: 2.357689380645752
Validation loss: 2.0704978307088218

Epoch: 196| Step: 0
Training loss: 2.2223927974700928
Validation loss: 2.071677957971891

Epoch: 5| Step: 1
Training loss: 1.8743822574615479
Validation loss: 2.068829223513603

Epoch: 5| Step: 2
Training loss: 2.0715270042419434
Validation loss: 2.06901844839255

Epoch: 5| Step: 3
Training loss: 2.638244152069092
Validation loss: 2.068666383624077

Epoch: 5| Step: 4
Training loss: 1.708857774734497
Validation loss: 2.075992132226626

Epoch: 5| Step: 5
Training loss: 1.7398430109024048
Validation loss: 2.0836710184812546

Epoch: 5| Step: 6
Training loss: 2.008469820022583
Validation loss: 2.0858145654201508

Epoch: 5| Step: 7
Training loss: 1.9708114862442017
Validation loss: 2.07993283867836

Epoch: 5| Step: 8
Training loss: 2.5927836894989014
Validation loss: 2.0850145469109216

Epoch: 5| Step: 9
Training loss: 2.374471426010132
Validation loss: 2.082127163807551

Epoch: 5| Step: 10
Training loss: 1.7784703969955444
Validation loss: 2.0729306985934577

Epoch: 5| Step: 11
Training loss: 2.2449307441711426
Validation loss: 2.074263642231623

Epoch: 197| Step: 0
Training loss: 2.0241916179656982
Validation loss: 2.0568639238675437

Epoch: 5| Step: 1
Training loss: 2.054858446121216
Validation loss: 2.0615738729635873

Epoch: 5| Step: 2
Training loss: 1.8442566394805908
Validation loss: 2.0546477138996124

Epoch: 5| Step: 3
Training loss: 1.7749261856079102
Validation loss: 2.0661273996035256

Epoch: 5| Step: 4
Training loss: 2.2270431518554688
Validation loss: 2.062027101715406

Epoch: 5| Step: 5
Training loss: 2.5768940448760986
Validation loss: 2.066803435484568

Epoch: 5| Step: 6
Training loss: 1.3806495666503906
Validation loss: 2.0576268335183463

Epoch: 5| Step: 7
Training loss: 1.443124532699585
Validation loss: 2.0873350401719413

Epoch: 5| Step: 8
Training loss: 2.634929656982422
Validation loss: 2.0823160807291665

Epoch: 5| Step: 9
Training loss: 1.9329626560211182
Validation loss: 2.076721449693044

Epoch: 5| Step: 10
Training loss: 2.0153582096099854
Validation loss: 2.085540453592936

Epoch: 5| Step: 11
Training loss: 3.1689577102661133
Validation loss: 2.1009035110473633

Epoch: 198| Step: 0
Training loss: 2.3492515087127686
Validation loss: 2.0764575600624084

Epoch: 5| Step: 1
Training loss: 1.4662717580795288
Validation loss: 2.0909805645545325

Epoch: 5| Step: 2
Training loss: 2.4545717239379883
Validation loss: 2.110839252670606

Epoch: 5| Step: 3
Training loss: 1.9557769298553467
Validation loss: 2.0976391484340033

Epoch: 5| Step: 4
Training loss: 2.0773820877075195
Validation loss: 2.0890794843435287

Epoch: 5| Step: 5
Training loss: 2.3560128211975098
Validation loss: 2.090523843963941

Epoch: 5| Step: 6
Training loss: 1.8504693508148193
Validation loss: 2.0964574366807938

Epoch: 5| Step: 7
Training loss: 1.426375150680542
Validation loss: 2.0821008880933127

Epoch: 5| Step: 8
Training loss: 2.20819354057312
Validation loss: 2.0909676204125085

Epoch: 5| Step: 9
Training loss: 1.508795142173767
Validation loss: 2.0854064226150513

Epoch: 5| Step: 10
Training loss: 2.1280157566070557
Validation loss: 2.072317878405253

Epoch: 5| Step: 11
Training loss: 1.7935874462127686
Validation loss: 2.074014812707901

Epoch: 199| Step: 0
Training loss: 2.031857967376709
Validation loss: 2.087186207373937

Epoch: 5| Step: 1
Training loss: 2.3646888732910156
Validation loss: 2.0949873427549996

Epoch: 5| Step: 2
Training loss: 1.9393666982650757
Validation loss: 2.0891302675008774

Epoch: 5| Step: 3
Training loss: 2.3620028495788574
Validation loss: 2.0881149570147195

Epoch: 5| Step: 4
Training loss: 2.174726724624634
Validation loss: 2.109506517648697

Epoch: 5| Step: 5
Training loss: 1.675781011581421
Validation loss: 2.0997851540644965

Epoch: 5| Step: 6
Training loss: 1.6732782125473022
Validation loss: 2.1185948650042215

Epoch: 5| Step: 7
Training loss: 1.914354681968689
Validation loss: 2.097950905561447

Epoch: 5| Step: 8
Training loss: 1.8600231409072876
Validation loss: 2.1039407700300217

Epoch: 5| Step: 9
Training loss: 1.3530305624008179
Validation loss: 2.1071191926797233

Epoch: 5| Step: 10
Training loss: 2.332441568374634
Validation loss: 2.102434058984121

Epoch: 5| Step: 11
Training loss: 2.220794439315796
Validation loss: 2.103568191329638

Epoch: 200| Step: 0
Training loss: 1.5075747966766357
Validation loss: 2.104775056242943

Epoch: 5| Step: 1
Training loss: 2.041853427886963
Validation loss: 2.105222687125206

Epoch: 5| Step: 2
Training loss: 1.9248631000518799
Validation loss: 2.097812940677007

Epoch: 5| Step: 3
Training loss: 2.8253378868103027
Validation loss: 2.110320046544075

Epoch: 5| Step: 4
Training loss: 2.291266679763794
Validation loss: 2.112368881702423

Epoch: 5| Step: 5
Training loss: 1.8544483184814453
Validation loss: 2.1145284871260324

Epoch: 5| Step: 6
Training loss: 1.7056039571762085
Validation loss: 2.1201885491609573

Epoch: 5| Step: 7
Training loss: 1.3299686908721924
Validation loss: 2.1145434379577637

Epoch: 5| Step: 8
Training loss: 1.674208402633667
Validation loss: 2.115775242447853

Epoch: 5| Step: 9
Training loss: 2.3012917041778564
Validation loss: 2.1147794226805368

Epoch: 5| Step: 10
Training loss: 2.2998170852661133
Validation loss: 2.114697595437368

Epoch: 5| Step: 11
Training loss: 1.9352909326553345
Validation loss: 2.1162723998228707

Testing loss: 1.748683428592819
