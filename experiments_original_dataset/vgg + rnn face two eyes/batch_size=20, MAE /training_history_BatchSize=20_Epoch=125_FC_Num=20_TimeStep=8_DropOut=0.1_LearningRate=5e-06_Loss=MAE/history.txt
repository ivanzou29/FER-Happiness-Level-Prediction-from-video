Epoch: 1| Step: 0
Training loss: 3.776339292526245
Validation loss: 5.3227353890736895

Epoch: 5| Step: 1
Training loss: 4.84956693649292
Validation loss: 5.320945243040721

Epoch: 5| Step: 2
Training loss: 4.397895336151123
Validation loss: 5.319246788819631

Epoch: 5| Step: 3
Training loss: 6.555389404296875
Validation loss: 5.317636688550313

Epoch: 5| Step: 4
Training loss: 5.4491143226623535
Validation loss: 5.316125551859538

Epoch: 5| Step: 5
Training loss: 4.833489418029785
Validation loss: 5.314551691214244

Epoch: 5| Step: 6
Training loss: 5.721164703369141
Validation loss: 5.312990228335063

Epoch: 5| Step: 7
Training loss: 6.313362121582031
Validation loss: 5.311368266741435

Epoch: 5| Step: 8
Training loss: 5.293999671936035
Validation loss: 5.309733072916667

Epoch: 5| Step: 9
Training loss: 6.402262210845947
Validation loss: 5.307978669802348

Epoch: 5| Step: 10
Training loss: 5.743438720703125
Validation loss: 5.306306680043538

Epoch: 5| Step: 11
Training loss: 4.767914772033691
Validation loss: 5.304282963275909

Epoch: 2| Step: 0
Training loss: 5.356858730316162
Validation loss: 5.302381257216136

Epoch: 5| Step: 1
Training loss: 5.721686363220215
Validation loss: 5.3004326820373535

Epoch: 5| Step: 2
Training loss: 6.18731689453125
Validation loss: 5.298316518465678

Epoch: 5| Step: 3
Training loss: 3.7820944786071777
Validation loss: 5.296054621537526

Epoch: 5| Step: 4
Training loss: 5.36962366104126
Validation loss: 5.293671429157257

Epoch: 5| Step: 5
Training loss: 5.406546115875244
Validation loss: 5.291175266106923

Epoch: 5| Step: 6
Training loss: 5.1697587966918945
Validation loss: 5.288459599018097

Epoch: 5| Step: 7
Training loss: 3.7237632274627686
Validation loss: 5.2855923771858215

Epoch: 5| Step: 8
Training loss: 5.464699745178223
Validation loss: 5.282746930917104

Epoch: 5| Step: 9
Training loss: 6.154354095458984
Validation loss: 5.279575228691101

Epoch: 5| Step: 10
Training loss: 6.295614719390869
Validation loss: 5.2763199011484785

Epoch: 5| Step: 11
Training loss: 6.922300338745117
Validation loss: 5.27266005674998

Epoch: 3| Step: 0
Training loss: 5.155821800231934
Validation loss: 5.268986165523529

Epoch: 5| Step: 1
Training loss: 4.620581150054932
Validation loss: 5.265027344226837

Epoch: 5| Step: 2
Training loss: 5.685707092285156
Validation loss: 5.261144022146861

Epoch: 5| Step: 3
Training loss: 5.487811088562012
Validation loss: 5.256883164246877

Epoch: 5| Step: 4
Training loss: 4.794009208679199
Validation loss: 5.252476890881856

Epoch: 5| Step: 5
Training loss: 4.931816577911377
Validation loss: 5.2476551334063215

Epoch: 5| Step: 6
Training loss: 5.727738857269287
Validation loss: 5.242742200692494

Epoch: 5| Step: 7
Training loss: 5.532993316650391
Validation loss: 5.237550576527913

Epoch: 5| Step: 8
Training loss: 5.431736469268799
Validation loss: 5.232234021027883

Epoch: 5| Step: 9
Training loss: 5.799991130828857
Validation loss: 5.226358870665233

Epoch: 5| Step: 10
Training loss: 5.228226661682129
Validation loss: 5.220423142115275

Epoch: 5| Step: 11
Training loss: 5.6565070152282715
Validation loss: 5.214386900266011

Epoch: 4| Step: 0
Training loss: 5.643668174743652
Validation loss: 5.207576215267181

Epoch: 5| Step: 1
Training loss: 4.810206413269043
Validation loss: 5.2010031541188555

Epoch: 5| Step: 2
Training loss: 4.603885173797607
Validation loss: 5.1937945286432905

Epoch: 5| Step: 3
Training loss: 5.394939422607422
Validation loss: 5.187073926130931

Epoch: 5| Step: 4
Training loss: 5.157343864440918
Validation loss: 5.179497083028157

Epoch: 5| Step: 5
Training loss: 4.883378982543945
Validation loss: 5.171717981497447

Epoch: 5| Step: 6
Training loss: 5.8470778465271
Validation loss: 5.163860658804576

Epoch: 5| Step: 7
Training loss: 5.680700778961182
Validation loss: 5.155602077643077

Epoch: 5| Step: 8
Training loss: 4.6222381591796875
Validation loss: 5.147537370522817

Epoch: 5| Step: 9
Training loss: 6.60244607925415
Validation loss: 5.1394087473551435

Epoch: 5| Step: 10
Training loss: 4.459175109863281
Validation loss: 5.130635499954224

Epoch: 5| Step: 11
Training loss: 5.0147624015808105
Validation loss: 5.121949553489685

Epoch: 5| Step: 0
Training loss: 6.294663429260254
Validation loss: 5.11315123240153

Epoch: 5| Step: 1
Training loss: 4.393273830413818
Validation loss: 5.104366779327393

Epoch: 5| Step: 2
Training loss: 6.176225185394287
Validation loss: 5.095564305782318

Epoch: 5| Step: 3
Training loss: 4.691742897033691
Validation loss: 5.086712886889775

Epoch: 5| Step: 4
Training loss: 4.684048652648926
Validation loss: 5.07760904232661

Epoch: 5| Step: 5
Training loss: 4.699164867401123
Validation loss: 5.068739354610443

Epoch: 5| Step: 6
Training loss: 5.506758213043213
Validation loss: 5.06007198492686

Epoch: 5| Step: 7
Training loss: 5.6930975914001465
Validation loss: 5.051106194655101

Epoch: 5| Step: 8
Training loss: 4.761724472045898
Validation loss: 5.042370835940043

Epoch: 5| Step: 9
Training loss: 4.556763648986816
Validation loss: 5.033800681432088

Epoch: 5| Step: 10
Training loss: 5.379300594329834
Validation loss: 5.025400698184967

Epoch: 5| Step: 11
Training loss: 3.9513630867004395
Validation loss: 5.01680713891983

Epoch: 6| Step: 0
Training loss: 4.9495768547058105
Validation loss: 5.008165339628856

Epoch: 5| Step: 1
Training loss: 5.570748329162598
Validation loss: 4.999578773975372

Epoch: 5| Step: 2
Training loss: 4.984371185302734
Validation loss: 4.9909741679827375

Epoch: 5| Step: 3
Training loss: 4.6548542976379395
Validation loss: 4.982848942279816

Epoch: 5| Step: 4
Training loss: 4.96090030670166
Validation loss: 4.974302122990291

Epoch: 5| Step: 5
Training loss: 5.192698001861572
Validation loss: 4.965345561504364

Epoch: 5| Step: 6
Training loss: 4.945797443389893
Validation loss: 4.956804851690928

Epoch: 5| Step: 7
Training loss: 5.219918727874756
Validation loss: 4.948304196198781

Epoch: 5| Step: 8
Training loss: 5.62997579574585
Validation loss: 4.939692576726277

Epoch: 5| Step: 9
Training loss: 5.064927101135254
Validation loss: 4.930702944596608

Epoch: 5| Step: 10
Training loss: 4.009378910064697
Validation loss: 4.92194135983785

Epoch: 5| Step: 11
Training loss: 6.688084602355957
Validation loss: 4.913289586702983

Epoch: 7| Step: 0
Training loss: 5.425692558288574
Validation loss: 4.904742976029714

Epoch: 5| Step: 1
Training loss: 5.030385494232178
Validation loss: 4.896257559458415

Epoch: 5| Step: 2
Training loss: 5.596346378326416
Validation loss: 4.887315134207408

Epoch: 5| Step: 3
Training loss: 4.638141632080078
Validation loss: 4.878174086411794

Epoch: 5| Step: 4
Training loss: 5.237787246704102
Validation loss: 4.868889033794403

Epoch: 5| Step: 5
Training loss: 4.626424789428711
Validation loss: 4.859705249468486

Epoch: 5| Step: 6
Training loss: 3.9368882179260254
Validation loss: 4.849847316741943

Epoch: 5| Step: 7
Training loss: 3.7528586387634277
Validation loss: 4.840474406878154

Epoch: 5| Step: 8
Training loss: 5.889993190765381
Validation loss: 4.831863691409429

Epoch: 5| Step: 9
Training loss: 4.932621955871582
Validation loss: 4.8233042160669966

Epoch: 5| Step: 10
Training loss: 5.3354339599609375
Validation loss: 4.815009653568268

Epoch: 5| Step: 11
Training loss: 4.9597392082214355
Validation loss: 4.806978682676951

Epoch: 8| Step: 0
Training loss: 4.768936634063721
Validation loss: 4.799153516689937

Epoch: 5| Step: 1
Training loss: 5.256096839904785
Validation loss: 4.791125734647115

Epoch: 5| Step: 2
Training loss: 4.957293510437012
Validation loss: 4.783385276794434

Epoch: 5| Step: 3
Training loss: 5.313396453857422
Validation loss: 4.774895946184794

Epoch: 5| Step: 4
Training loss: 5.211084842681885
Validation loss: 4.766647318998973

Epoch: 5| Step: 5
Training loss: 4.223264217376709
Validation loss: 4.758482376734416

Epoch: 5| Step: 6
Training loss: 3.96431040763855
Validation loss: 4.750256995360057

Epoch: 5| Step: 7
Training loss: 5.790444850921631
Validation loss: 4.741487205028534

Epoch: 5| Step: 8
Training loss: 4.874199867248535
Validation loss: 4.733279267946879

Epoch: 5| Step: 9
Training loss: 4.5461297035217285
Validation loss: 4.7248170375823975

Epoch: 5| Step: 10
Training loss: 4.43399715423584
Validation loss: 4.717297275861104

Epoch: 5| Step: 11
Training loss: 4.764701843261719
Validation loss: 4.70950589577357

Epoch: 9| Step: 0
Training loss: 4.672604560852051
Validation loss: 4.702547927697499

Epoch: 5| Step: 1
Training loss: 5.71194314956665
Validation loss: 4.695470939079921

Epoch: 5| Step: 2
Training loss: 5.275241374969482
Validation loss: 4.688678602377574

Epoch: 5| Step: 3
Training loss: 4.60166072845459
Validation loss: 4.681493798891704

Epoch: 5| Step: 4
Training loss: 4.483209133148193
Validation loss: 4.674623191356659

Epoch: 5| Step: 5
Training loss: 4.741974830627441
Validation loss: 4.667340795199077

Epoch: 5| Step: 6
Training loss: 4.818485260009766
Validation loss: 4.660667310158412

Epoch: 5| Step: 7
Training loss: 5.532684803009033
Validation loss: 4.653630097707112

Epoch: 5| Step: 8
Training loss: 3.873875379562378
Validation loss: 4.646794557571411

Epoch: 5| Step: 9
Training loss: 3.875394821166992
Validation loss: 4.640335241953532

Epoch: 5| Step: 10
Training loss: 4.756440162658691
Validation loss: 4.633446296056111

Epoch: 5| Step: 11
Training loss: 4.982878684997559
Validation loss: 4.626499096552531

Epoch: 10| Step: 0
Training loss: 5.557792663574219
Validation loss: 4.620290259520213

Epoch: 5| Step: 1
Training loss: 4.221044063568115
Validation loss: 4.613791763782501

Epoch: 5| Step: 2
Training loss: 4.777624130249023
Validation loss: 4.6070383588473005

Epoch: 5| Step: 3
Training loss: 4.744465351104736
Validation loss: 4.600859075784683

Epoch: 5| Step: 4
Training loss: 4.417471408843994
Validation loss: 4.594215512275696

Epoch: 5| Step: 5
Training loss: 3.7906413078308105
Validation loss: 4.588353931903839

Epoch: 5| Step: 6
Training loss: 4.945988655090332
Validation loss: 4.5817102789878845

Epoch: 5| Step: 7
Training loss: 5.6536688804626465
Validation loss: 4.575532495975494

Epoch: 5| Step: 8
Training loss: 3.474559783935547
Validation loss: 4.56899215777715

Epoch: 5| Step: 9
Training loss: 5.009761810302734
Validation loss: 4.562849601109822

Epoch: 5| Step: 10
Training loss: 4.8547539710998535
Validation loss: 4.55650778611501

Epoch: 5| Step: 11
Training loss: 5.225142478942871
Validation loss: 4.550143172343572

Epoch: 11| Step: 0
Training loss: 3.67919659614563
Validation loss: 4.544123033682506

Epoch: 5| Step: 1
Training loss: 5.1458516120910645
Validation loss: 4.537742525339127

Epoch: 5| Step: 2
Training loss: 5.031240940093994
Validation loss: 4.532021741072337

Epoch: 5| Step: 3
Training loss: 4.753960609436035
Validation loss: 4.526255369186401

Epoch: 5| Step: 4
Training loss: 4.162900447845459
Validation loss: 4.520367781321208

Epoch: 5| Step: 5
Training loss: 5.754128456115723
Validation loss: 4.514798233906428

Epoch: 5| Step: 6
Training loss: 4.28342866897583
Validation loss: 4.509092211723328

Epoch: 5| Step: 7
Training loss: 4.433271408081055
Validation loss: 4.503057738145192

Epoch: 5| Step: 8
Training loss: 4.331538677215576
Validation loss: 4.497055888175964

Epoch: 5| Step: 9
Training loss: 4.450340270996094
Validation loss: 4.491014858086904

Epoch: 5| Step: 10
Training loss: 4.9027605056762695
Validation loss: 4.4853680829207105

Epoch: 5| Step: 11
Training loss: 3.9153733253479004
Validation loss: 4.479596267143886

Epoch: 12| Step: 0
Training loss: 4.103957176208496
Validation loss: 4.474051853020986

Epoch: 5| Step: 1
Training loss: 5.241802215576172
Validation loss: 4.468551317850749

Epoch: 5| Step: 2
Training loss: 4.049344062805176
Validation loss: 4.462684174378713

Epoch: 5| Step: 3
Training loss: 4.49206018447876
Validation loss: 4.457029898961385

Epoch: 5| Step: 4
Training loss: 4.789267539978027
Validation loss: 4.451656411091487

Epoch: 5| Step: 5
Training loss: 5.528928279876709
Validation loss: 4.445847362279892

Epoch: 5| Step: 6
Training loss: 5.730984210968018
Validation loss: 4.440266033013661

Epoch: 5| Step: 7
Training loss: 4.701663970947266
Validation loss: 4.435148815313975

Epoch: 5| Step: 8
Training loss: 3.8232922554016113
Validation loss: 4.429913381735484

Epoch: 5| Step: 9
Training loss: 4.967929363250732
Validation loss: 4.424364000558853

Epoch: 5| Step: 10
Training loss: 3.3351597785949707
Validation loss: 4.419381529092789

Epoch: 5| Step: 11
Training loss: 1.3808062076568604
Validation loss: 4.414586683114369

Epoch: 13| Step: 0
Training loss: 4.158840179443359
Validation loss: 4.409603555997212

Epoch: 5| Step: 1
Training loss: 5.215978622436523
Validation loss: 4.405091236035029

Epoch: 5| Step: 2
Training loss: 4.404476642608643
Validation loss: 4.400316933790843

Epoch: 5| Step: 3
Training loss: 4.832472324371338
Validation loss: 4.395638664563497

Epoch: 5| Step: 4
Training loss: 5.141522407531738
Validation loss: 4.390614539384842

Epoch: 5| Step: 5
Training loss: 5.133447647094727
Validation loss: 4.385977774858475

Epoch: 5| Step: 6
Training loss: 4.384581089019775
Validation loss: 4.381292472283046

Epoch: 5| Step: 7
Training loss: 3.7462525367736816
Validation loss: 4.3763924439748125

Epoch: 5| Step: 8
Training loss: 4.635817527770996
Validation loss: 4.372128585974376

Epoch: 5| Step: 9
Training loss: 3.7251815795898438
Validation loss: 4.367296010255814

Epoch: 5| Step: 10
Training loss: 4.370087623596191
Validation loss: 4.3633100390434265

Epoch: 5| Step: 11
Training loss: 3.4478626251220703
Validation loss: 4.358933548132579

Epoch: 14| Step: 0
Training loss: 4.310202598571777
Validation loss: 4.35436949133873

Epoch: 5| Step: 1
Training loss: 5.036037445068359
Validation loss: 4.349930206934611

Epoch: 5| Step: 2
Training loss: 3.8619141578674316
Validation loss: 4.344843407471974

Epoch: 5| Step: 3
Training loss: 4.18700647354126
Validation loss: 4.340318659941356

Epoch: 5| Step: 4
Training loss: 3.7808635234832764
Validation loss: 4.335857927799225

Epoch: 5| Step: 5
Training loss: 5.4184250831604
Validation loss: 4.331553280353546

Epoch: 5| Step: 6
Training loss: 5.173172473907471
Validation loss: 4.3274571895599365

Epoch: 5| Step: 7
Training loss: 3.9048640727996826
Validation loss: 4.32305630048116

Epoch: 5| Step: 8
Training loss: 5.114971160888672
Validation loss: 4.318913082281749

Epoch: 5| Step: 9
Training loss: 3.2580819129943848
Validation loss: 4.314625769853592

Epoch: 5| Step: 10
Training loss: 4.5303120613098145
Validation loss: 4.3103805383046465

Epoch: 5| Step: 11
Training loss: 6.541047096252441
Validation loss: 4.306488066911697

Epoch: 15| Step: 0
Training loss: 5.442797660827637
Validation loss: 4.302339563767116

Epoch: 5| Step: 1
Training loss: 4.130642890930176
Validation loss: 4.298042953014374

Epoch: 5| Step: 2
Training loss: 4.600419998168945
Validation loss: 4.293935418128967

Epoch: 5| Step: 3
Training loss: 4.436737537384033
Validation loss: 4.289396196603775

Epoch: 5| Step: 4
Training loss: 3.3232123851776123
Validation loss: 4.285915553569794

Epoch: 5| Step: 5
Training loss: 4.329629898071289
Validation loss: 4.281664003928502

Epoch: 5| Step: 6
Training loss: 4.637808799743652
Validation loss: 4.277667293945949

Epoch: 5| Step: 7
Training loss: 3.8978989124298096
Validation loss: 4.273425241311391

Epoch: 5| Step: 8
Training loss: 3.989783525466919
Validation loss: 4.268510659535726

Epoch: 5| Step: 9
Training loss: 4.851138114929199
Validation loss: 4.26466832558314

Epoch: 5| Step: 10
Training loss: 4.813986778259277
Validation loss: 4.260575373967488

Epoch: 5| Step: 11
Training loss: 4.5067338943481445
Validation loss: 4.256533523400624

Epoch: 16| Step: 0
Training loss: 3.822885036468506
Validation loss: 4.252749760945638

Epoch: 5| Step: 1
Training loss: 4.014048099517822
Validation loss: 4.248704671859741

Epoch: 5| Step: 2
Training loss: 4.907416820526123
Validation loss: 4.244201918443044

Epoch: 5| Step: 3
Training loss: 4.693830966949463
Validation loss: 4.2407751977443695

Epoch: 5| Step: 4
Training loss: 4.447564601898193
Validation loss: 4.236499826113383

Epoch: 5| Step: 5
Training loss: 4.97409725189209
Validation loss: 4.23274490237236

Epoch: 5| Step: 6
Training loss: 4.108304023742676
Validation loss: 4.228275080521901

Epoch: 5| Step: 7
Training loss: 4.324687480926514
Validation loss: 4.224250058333079

Epoch: 5| Step: 8
Training loss: 4.138480186462402
Validation loss: 4.220229933659236

Epoch: 5| Step: 9
Training loss: 3.7174506187438965
Validation loss: 4.215674946705501

Epoch: 5| Step: 10
Training loss: 4.549225807189941
Validation loss: 4.211463878552119

Epoch: 5| Step: 11
Training loss: 5.778439521789551
Validation loss: 4.207421948512395

Epoch: 17| Step: 0
Training loss: 4.224491596221924
Validation loss: 4.203054865201314

Epoch: 5| Step: 1
Training loss: 3.9340240955352783
Validation loss: 4.198566873868306

Epoch: 5| Step: 2
Training loss: 4.861403465270996
Validation loss: 4.194634834925334

Epoch: 5| Step: 3
Training loss: 4.260801315307617
Validation loss: 4.190359711647034

Epoch: 5| Step: 4
Training loss: 3.662140369415283
Validation loss: 4.185795525709788

Epoch: 5| Step: 5
Training loss: 4.5076518058776855
Validation loss: 4.180445909500122

Epoch: 5| Step: 6
Training loss: 4.359314918518066
Validation loss: 4.17672539750735

Epoch: 5| Step: 7
Training loss: 4.465901851654053
Validation loss: 4.171311428149541

Epoch: 5| Step: 8
Training loss: 4.362656593322754
Validation loss: 4.167040715614955

Epoch: 5| Step: 9
Training loss: 4.431454658508301
Validation loss: 4.161187718311946

Epoch: 5| Step: 10
Training loss: 4.590609550476074
Validation loss: 4.156525820493698

Epoch: 5| Step: 11
Training loss: 3.3009281158447266
Validation loss: 4.15125114719073

Epoch: 18| Step: 0
Training loss: 4.800821304321289
Validation loss: 4.146119187275569

Epoch: 5| Step: 1
Training loss: 4.27101993560791
Validation loss: 4.140672077735265

Epoch: 5| Step: 2
Training loss: 4.689821720123291
Validation loss: 4.135832180579503

Epoch: 5| Step: 3
Training loss: 4.5899977684021
Validation loss: 4.130574454863866

Epoch: 5| Step: 4
Training loss: 4.166797637939453
Validation loss: 4.125143269697825

Epoch: 5| Step: 5
Training loss: 4.062005996704102
Validation loss: 4.1209394335746765

Epoch: 5| Step: 6
Training loss: 4.0256667137146
Validation loss: 4.117036134004593

Epoch: 5| Step: 7
Training loss: 2.9801526069641113
Validation loss: 4.1115118861198425

Epoch: 5| Step: 8
Training loss: 4.3957743644714355
Validation loss: 4.107896755139033

Epoch: 5| Step: 9
Training loss: 4.537592887878418
Validation loss: 4.103790084520976

Epoch: 5| Step: 10
Training loss: 4.366754055023193
Validation loss: 4.099392592906952

Epoch: 5| Step: 11
Training loss: 4.194272518157959
Validation loss: 4.095037599404653

Epoch: 19| Step: 0
Training loss: 4.543995380401611
Validation loss: 4.0917733907699585

Epoch: 5| Step: 1
Training loss: 4.189764976501465
Validation loss: 4.088416576385498

Epoch: 5| Step: 2
Training loss: 4.401439666748047
Validation loss: 4.082875311374664

Epoch: 5| Step: 3
Training loss: 4.151122093200684
Validation loss: 4.0781601170698805

Epoch: 5| Step: 4
Training loss: 3.667942762374878
Validation loss: 4.074574003616969

Epoch: 5| Step: 5
Training loss: 4.2882399559021
Validation loss: 4.070487101872762

Epoch: 5| Step: 6
Training loss: 4.06889533996582
Validation loss: 4.066529273986816

Epoch: 5| Step: 7
Training loss: 4.104623317718506
Validation loss: 4.0612643758455915

Epoch: 5| Step: 8
Training loss: 4.78594446182251
Validation loss: 4.0576684176921844

Epoch: 5| Step: 9
Training loss: 4.519105911254883
Validation loss: 4.053863873084386

Epoch: 5| Step: 10
Training loss: 3.8530044555664062
Validation loss: 4.048556794722875

Epoch: 5| Step: 11
Training loss: 2.9779505729675293
Validation loss: 4.045168608427048

Epoch: 20| Step: 0
Training loss: 4.647475719451904
Validation loss: 4.041201750437419

Epoch: 5| Step: 1
Training loss: 4.12477445602417
Validation loss: 4.037242780129115

Epoch: 5| Step: 2
Training loss: 4.003523349761963
Validation loss: 4.03280786673228

Epoch: 5| Step: 3
Training loss: 4.141182899475098
Validation loss: 4.0277822613716125

Epoch: 5| Step: 4
Training loss: 5.158859729766846
Validation loss: 4.024532208840053

Epoch: 5| Step: 5
Training loss: 4.067839622497559
Validation loss: 4.020411729812622

Epoch: 5| Step: 6
Training loss: 4.856482982635498
Validation loss: 4.015839219093323

Epoch: 5| Step: 7
Training loss: 3.9450783729553223
Validation loss: 4.011828790108363

Epoch: 5| Step: 8
Training loss: 3.3112540245056152
Validation loss: 4.007362673679988

Epoch: 5| Step: 9
Training loss: 4.275477886199951
Validation loss: 4.004112660884857

Epoch: 5| Step: 10
Training loss: 3.478283643722534
Validation loss: 3.999641259511312

Epoch: 5| Step: 11
Training loss: 3.17795991897583
Validation loss: 3.995379328727722

Epoch: 21| Step: 0
Training loss: 4.0864715576171875
Validation loss: 3.991478423277537

Epoch: 5| Step: 1
Training loss: 3.8019721508026123
Validation loss: 3.98764905333519

Epoch: 5| Step: 2
Training loss: 3.664328098297119
Validation loss: 3.9839932322502136

Epoch: 5| Step: 3
Training loss: 3.683647871017456
Validation loss: 3.980191727479299

Epoch: 5| Step: 4
Training loss: 4.616286277770996
Validation loss: 3.9760323961575827

Epoch: 5| Step: 5
Training loss: 3.681826114654541
Validation loss: 3.9720823168754578

Epoch: 5| Step: 6
Training loss: 3.94293212890625
Validation loss: 3.9681229889392853

Epoch: 5| Step: 7
Training loss: 3.363917827606201
Validation loss: 3.964746137460073

Epoch: 5| Step: 8
Training loss: 5.59956693649292
Validation loss: 3.9604192773501077

Epoch: 5| Step: 9
Training loss: 5.178180694580078
Validation loss: 3.957128793001175

Epoch: 5| Step: 10
Training loss: 3.6161580085754395
Validation loss: 3.952891002098719

Epoch: 5| Step: 11
Training loss: 4.356234550476074
Validation loss: 3.9487768411636353

Epoch: 22| Step: 0
Training loss: 3.568554401397705
Validation loss: 3.944872736930847

Epoch: 5| Step: 1
Training loss: 4.845574378967285
Validation loss: 3.9410621921221414

Epoch: 5| Step: 2
Training loss: 3.2797718048095703
Validation loss: 3.936913718779882

Epoch: 5| Step: 3
Training loss: 4.326268196105957
Validation loss: 3.93250235915184

Epoch: 5| Step: 4
Training loss: 4.6565752029418945
Validation loss: 3.9289671182632446

Epoch: 5| Step: 5
Training loss: 3.8304495811462402
Validation loss: 3.9247597754001617

Epoch: 5| Step: 6
Training loss: 4.1872358322143555
Validation loss: 3.9207966327667236

Epoch: 5| Step: 7
Training loss: 4.466662406921387
Validation loss: 3.9165331621964774

Epoch: 5| Step: 8
Training loss: 4.253663539886475
Validation loss: 3.912415772676468

Epoch: 5| Step: 9
Training loss: 3.435305118560791
Validation loss: 3.9083541134993234

Epoch: 5| Step: 10
Training loss: 3.7753162384033203
Validation loss: 3.9045934279759726

Epoch: 5| Step: 11
Training loss: 4.971932888031006
Validation loss: 3.9009679158528647

Epoch: 23| Step: 0
Training loss: 4.297397136688232
Validation loss: 3.896214226881663

Epoch: 5| Step: 1
Training loss: 2.909292697906494
Validation loss: 3.8928657670815787

Epoch: 5| Step: 2
Training loss: 4.183920383453369
Validation loss: 3.8889151215553284

Epoch: 5| Step: 3
Training loss: 3.4497008323669434
Validation loss: 3.885283042987188

Epoch: 5| Step: 4
Training loss: 4.375988960266113
Validation loss: 3.8816141982873282

Epoch: 5| Step: 5
Training loss: 4.358223915100098
Validation loss: 3.877397288878759

Epoch: 5| Step: 6
Training loss: 4.387021064758301
Validation loss: 3.8742103576660156

Epoch: 5| Step: 7
Training loss: 3.421201705932617
Validation loss: 3.870200534661611

Epoch: 5| Step: 8
Training loss: 3.96470308303833
Validation loss: 3.866227706273397

Epoch: 5| Step: 9
Training loss: 4.900526523590088
Validation loss: 3.8624899288018546

Epoch: 5| Step: 10
Training loss: 4.039560317993164
Validation loss: 3.858675758043925

Epoch: 5| Step: 11
Training loss: 4.095225811004639
Validation loss: 3.8545374472935996

Epoch: 24| Step: 0
Training loss: 4.612494468688965
Validation loss: 3.850469172000885

Epoch: 5| Step: 1
Training loss: 4.217816352844238
Validation loss: 3.846404085556666

Epoch: 5| Step: 2
Training loss: 4.205355167388916
Validation loss: 3.842770536740621

Epoch: 5| Step: 3
Training loss: 3.8412671089172363
Validation loss: 3.8384684324264526

Epoch: 5| Step: 4
Training loss: 3.4401512145996094
Validation loss: 3.833883653084437

Epoch: 5| Step: 5
Training loss: 4.382737159729004
Validation loss: 3.8305641214052835

Epoch: 5| Step: 6
Training loss: 3.7373969554901123
Validation loss: 3.826351205507914

Epoch: 5| Step: 7
Training loss: 4.323303699493408
Validation loss: 3.822851002216339

Epoch: 5| Step: 8
Training loss: 4.046207427978516
Validation loss: 3.8184652825196586

Epoch: 5| Step: 9
Training loss: 3.993349552154541
Validation loss: 3.8145165940125785

Epoch: 5| Step: 10
Training loss: 3.246689558029175
Validation loss: 3.810565342505773

Epoch: 5| Step: 11
Training loss: 2.990079879760742
Validation loss: 3.8070127069950104

Epoch: 25| Step: 0
Training loss: 4.087808132171631
Validation loss: 3.804086903731028

Epoch: 5| Step: 1
Training loss: 3.1904873847961426
Validation loss: 3.799948980410894

Epoch: 5| Step: 2
Training loss: 4.597712516784668
Validation loss: 3.796031564474106

Epoch: 5| Step: 3
Training loss: 3.9946773052215576
Validation loss: 3.792603443066279

Epoch: 5| Step: 4
Training loss: 4.533066749572754
Validation loss: 3.789248059193293

Epoch: 5| Step: 5
Training loss: 4.514338493347168
Validation loss: 3.7855710685253143

Epoch: 5| Step: 6
Training loss: 4.084635257720947
Validation loss: 3.781618684530258

Epoch: 5| Step: 7
Training loss: 3.231736660003662
Validation loss: 3.7777900298436484

Epoch: 5| Step: 8
Training loss: 3.417851209640503
Validation loss: 3.774128645658493

Epoch: 5| Step: 9
Training loss: 4.221549034118652
Validation loss: 3.7698374489943185

Epoch: 5| Step: 10
Training loss: 3.4168648719787598
Validation loss: 3.7662570575873056

Epoch: 5| Step: 11
Training loss: 4.381329536437988
Validation loss: 3.7623914976914725

Epoch: 26| Step: 0
Training loss: 3.5734493732452393
Validation loss: 3.7586682736873627

Epoch: 5| Step: 1
Training loss: 3.9608356952667236
Validation loss: 3.7552244563897452

Epoch: 5| Step: 2
Training loss: 3.4035773277282715
Validation loss: 3.751466612021128

Epoch: 5| Step: 3
Training loss: 3.3082668781280518
Validation loss: 3.7471012671788535

Epoch: 5| Step: 4
Training loss: 4.727149963378906
Validation loss: 3.743304749329885

Epoch: 5| Step: 5
Training loss: 5.0626220703125
Validation loss: 3.739729960759481

Epoch: 5| Step: 6
Training loss: 3.662609815597534
Validation loss: 3.736328274011612

Epoch: 5| Step: 7
Training loss: 3.639415740966797
Validation loss: 3.732955108086268

Epoch: 5| Step: 8
Training loss: 3.3510403633117676
Validation loss: 3.7285701831181846

Epoch: 5| Step: 9
Training loss: 3.887645721435547
Validation loss: 3.7249903281529746

Epoch: 5| Step: 10
Training loss: 3.98905873298645
Validation loss: 3.721264958381653

Epoch: 5| Step: 11
Training loss: 5.543295860290527
Validation loss: 3.7174658278624215

Epoch: 27| Step: 0
Training loss: 3.8974220752716064
Validation loss: 3.7140643298625946

Epoch: 5| Step: 1
Training loss: 3.1308305263519287
Validation loss: 3.710316310326258

Epoch: 5| Step: 2
Training loss: 3.8097171783447266
Validation loss: 3.70648056268692

Epoch: 5| Step: 3
Training loss: 3.6032814979553223
Validation loss: 3.7033855517705283

Epoch: 5| Step: 4
Training loss: 4.083871364593506
Validation loss: 3.699840565522512

Epoch: 5| Step: 5
Training loss: 4.010769844055176
Validation loss: 3.6962384482224784

Epoch: 5| Step: 6
Training loss: 3.345592498779297
Validation loss: 3.6926247576872506

Epoch: 5| Step: 7
Training loss: 3.7182388305664062
Validation loss: 3.6886920432249704

Epoch: 5| Step: 8
Training loss: 3.7072017192840576
Validation loss: 3.6851437588532767

Epoch: 5| Step: 9
Training loss: 4.5161566734313965
Validation loss: 3.681775212287903

Epoch: 5| Step: 10
Training loss: 4.568267822265625
Validation loss: 3.677594075600306

Epoch: 5| Step: 11
Training loss: 4.013071060180664
Validation loss: 3.6742853820323944

Epoch: 28| Step: 0
Training loss: 3.0479137897491455
Validation loss: 3.6706555982430777

Epoch: 5| Step: 1
Training loss: 3.212131977081299
Validation loss: 3.6667503813902536

Epoch: 5| Step: 2
Training loss: 4.2505784034729
Validation loss: 3.663402865330378

Epoch: 5| Step: 3
Training loss: 4.958863258361816
Validation loss: 3.6594464580217996

Epoch: 5| Step: 4
Training loss: 4.410257339477539
Validation loss: 3.6557586590449014

Epoch: 5| Step: 5
Training loss: 3.822209596633911
Validation loss: 3.651487578948339

Epoch: 5| Step: 6
Training loss: 2.6439833641052246
Validation loss: 3.6476928194363913

Epoch: 5| Step: 7
Training loss: 3.515389919281006
Validation loss: 3.643713504076004

Epoch: 5| Step: 8
Training loss: 4.714763641357422
Validation loss: 3.6399581730365753

Epoch: 5| Step: 9
Training loss: 3.641573667526245
Validation loss: 3.6363600293795266

Epoch: 5| Step: 10
Training loss: 3.7740318775177
Validation loss: 3.6323948303858438

Epoch: 5| Step: 11
Training loss: 3.5983104705810547
Validation loss: 3.628566414117813

Epoch: 29| Step: 0
Training loss: 3.089674711227417
Validation loss: 3.625093420346578

Epoch: 5| Step: 1
Training loss: 4.147585391998291
Validation loss: 3.621200849612554

Epoch: 5| Step: 2
Training loss: 3.67039155960083
Validation loss: 3.617077132066091

Epoch: 5| Step: 3
Training loss: 3.6526706218719482
Validation loss: 3.613295296827952

Epoch: 5| Step: 4
Training loss: 3.699856996536255
Validation loss: 3.609004964431127

Epoch: 5| Step: 5
Training loss: 4.470338821411133
Validation loss: 3.605135222276052

Epoch: 5| Step: 6
Training loss: 3.3697268962860107
Validation loss: 3.6010346114635468

Epoch: 5| Step: 7
Training loss: 4.011643409729004
Validation loss: 3.5966899593671164

Epoch: 5| Step: 8
Training loss: 3.813652753829956
Validation loss: 3.5925464630126953

Epoch: 5| Step: 9
Training loss: 3.976431369781494
Validation loss: 3.5885280768076577

Epoch: 5| Step: 10
Training loss: 3.334534168243408
Validation loss: 3.5849263270696006

Epoch: 5| Step: 11
Training loss: 4.815047740936279
Validation loss: 3.5812946259975433

Epoch: 30| Step: 0
Training loss: 4.360079765319824
Validation loss: 3.576670010884603

Epoch: 5| Step: 1
Training loss: 3.5049691200256348
Validation loss: 3.573236654202143

Epoch: 5| Step: 2
Training loss: 3.1102969646453857
Validation loss: 3.5691077510515847

Epoch: 5| Step: 3
Training loss: 4.288424015045166
Validation loss: 3.5651643574237823

Epoch: 5| Step: 4
Training loss: 3.349565029144287
Validation loss: 3.5603853662808738

Epoch: 5| Step: 5
Training loss: 3.669997453689575
Validation loss: 3.5567260881265006

Epoch: 5| Step: 6
Training loss: 2.9023680686950684
Validation loss: 3.5530196130275726

Epoch: 5| Step: 7
Training loss: 4.001644611358643
Validation loss: 3.549555013577143

Epoch: 5| Step: 8
Training loss: 3.5390708446502686
Validation loss: 3.5454774598280587

Epoch: 5| Step: 9
Training loss: 3.6140618324279785
Validation loss: 3.5416049659252167

Epoch: 5| Step: 10
Training loss: 4.617830753326416
Validation loss: 3.5373641153176627

Epoch: 5| Step: 11
Training loss: 3.6238276958465576
Validation loss: 3.532868186632792

Epoch: 31| Step: 0
Training loss: 4.034433841705322
Validation loss: 3.529175659020742

Epoch: 5| Step: 1
Training loss: 3.142873764038086
Validation loss: 3.525120814641317

Epoch: 5| Step: 2
Training loss: 3.8352324962615967
Validation loss: 3.520679920911789

Epoch: 5| Step: 3
Training loss: 4.16714334487915
Validation loss: 3.516288101673126

Epoch: 5| Step: 4
Training loss: 3.5096633434295654
Validation loss: 3.5121222933133445

Epoch: 5| Step: 5
Training loss: 4.067246437072754
Validation loss: 3.508033593495687

Epoch: 5| Step: 6
Training loss: 3.213967800140381
Validation loss: 3.5041059950987496

Epoch: 5| Step: 7
Training loss: 3.8743858337402344
Validation loss: 3.5000754793485007

Epoch: 5| Step: 8
Training loss: 4.016463756561279
Validation loss: 3.4958874185880027

Epoch: 5| Step: 9
Training loss: 3.4667389392852783
Validation loss: 3.491959939400355

Epoch: 5| Step: 10
Training loss: 3.31988263130188
Validation loss: 3.488095541795095

Epoch: 5| Step: 11
Training loss: 2.629547595977783
Validation loss: 3.484077791372935

Epoch: 32| Step: 0
Training loss: 3.427809953689575
Validation loss: 3.480088929335276

Epoch: 5| Step: 1
Training loss: 4.014745235443115
Validation loss: 3.4762257238229117

Epoch: 5| Step: 2
Training loss: 3.121896266937256
Validation loss: 3.472150514523188

Epoch: 5| Step: 3
Training loss: 3.5751852989196777
Validation loss: 3.468415707349777

Epoch: 5| Step: 4
Training loss: 3.1904079914093018
Validation loss: 3.4647779365380607

Epoch: 5| Step: 5
Training loss: 3.2769742012023926
Validation loss: 3.460955719153086

Epoch: 5| Step: 6
Training loss: 4.144306182861328
Validation loss: 3.45758127172788

Epoch: 5| Step: 7
Training loss: 3.622742176055908
Validation loss: 3.4532584051291146

Epoch: 5| Step: 8
Training loss: 4.254137992858887
Validation loss: 3.4494937360286713

Epoch: 5| Step: 9
Training loss: 3.5061843395233154
Validation loss: 3.445741295814514

Epoch: 5| Step: 10
Training loss: 3.9619648456573486
Validation loss: 3.4417953491210938

Epoch: 5| Step: 11
Training loss: 2.6222801208496094
Validation loss: 3.4379642407099404

Epoch: 33| Step: 0
Training loss: 3.5317349433898926
Validation loss: 3.434019764264425

Epoch: 5| Step: 1
Training loss: 3.4370906352996826
Validation loss: 3.4299433827400208

Epoch: 5| Step: 2
Training loss: 4.600399971008301
Validation loss: 3.4260870615641275

Epoch: 5| Step: 3
Training loss: 3.304100513458252
Validation loss: 3.4222216606140137

Epoch: 5| Step: 4
Training loss: 3.127796173095703
Validation loss: 3.4179380436738334

Epoch: 5| Step: 5
Training loss: 2.8425166606903076
Validation loss: 3.4140161176522574

Epoch: 5| Step: 6
Training loss: 3.629542827606201
Validation loss: 3.4102660417556763

Epoch: 5| Step: 7
Training loss: 3.368910312652588
Validation loss: 3.406401435534159

Epoch: 5| Step: 8
Training loss: 3.7231526374816895
Validation loss: 3.4022215207417807

Epoch: 5| Step: 9
Training loss: 4.154208183288574
Validation loss: 3.398666203022003

Epoch: 5| Step: 10
Training loss: 3.6051013469696045
Validation loss: 3.39471968015035

Epoch: 5| Step: 11
Training loss: 3.9533042907714844
Validation loss: 3.390872150659561

Epoch: 34| Step: 0
Training loss: 4.403175354003906
Validation loss: 3.3867439130942025

Epoch: 5| Step: 1
Training loss: 3.617237091064453
Validation loss: 3.382689952850342

Epoch: 5| Step: 2
Training loss: 3.9007961750030518
Validation loss: 3.378644069035848

Epoch: 5| Step: 3
Training loss: 3.390824556350708
Validation loss: 3.3749764263629913

Epoch: 5| Step: 4
Training loss: 3.7761826515197754
Validation loss: 3.3711561063925424

Epoch: 5| Step: 5
Training loss: 3.573540210723877
Validation loss: 3.367199848095576

Epoch: 5| Step: 6
Training loss: 3.0842463970184326
Validation loss: 3.3632124861081443

Epoch: 5| Step: 7
Training loss: 2.962165117263794
Validation loss: 3.359056572119395

Epoch: 5| Step: 8
Training loss: 3.2444777488708496
Validation loss: 3.3551906843980155

Epoch: 5| Step: 9
Training loss: 3.6778883934020996
Validation loss: 3.3513085146745047

Epoch: 5| Step: 10
Training loss: 3.1109354496002197
Validation loss: 3.347464601198832

Epoch: 5| Step: 11
Training loss: 4.362926483154297
Validation loss: 3.3434424300988517

Epoch: 35| Step: 0
Training loss: 3.183353900909424
Validation loss: 3.3392530381679535

Epoch: 5| Step: 1
Training loss: 4.2454514503479
Validation loss: 3.335669159889221

Epoch: 5| Step: 2
Training loss: 3.951087236404419
Validation loss: 3.3309958477814994

Epoch: 5| Step: 3
Training loss: 2.8221774101257324
Validation loss: 3.326909671227137

Epoch: 5| Step: 4
Training loss: 3.2844181060791016
Validation loss: 3.322954922914505

Epoch: 5| Step: 5
Training loss: 3.7732532024383545
Validation loss: 3.3187452057997384

Epoch: 5| Step: 6
Training loss: 3.562077283859253
Validation loss: 3.3145703176657357

Epoch: 5| Step: 7
Training loss: 3.3865997791290283
Validation loss: 3.3111029962698617

Epoch: 5| Step: 8
Training loss: 3.4348208904266357
Validation loss: 3.307123144467672

Epoch: 5| Step: 9
Training loss: 3.3796401023864746
Validation loss: 3.3036187887191772

Epoch: 5| Step: 10
Training loss: 3.650698184967041
Validation loss: 3.2999227941036224

Epoch: 5| Step: 11
Training loss: 2.2502200603485107
Validation loss: 3.296006421248118

Epoch: 36| Step: 0
Training loss: 3.827282428741455
Validation loss: 3.292009269197782

Epoch: 5| Step: 1
Training loss: 3.5951271057128906
Validation loss: 3.2885363499323526

Epoch: 5| Step: 2
Training loss: 3.3180389404296875
Validation loss: 3.284290075302124

Epoch: 5| Step: 3
Training loss: 3.318035840988159
Validation loss: 3.280150612195333

Epoch: 5| Step: 4
Training loss: 3.52295184135437
Validation loss: 3.276369631290436

Epoch: 5| Step: 5
Training loss: 3.2040538787841797
Validation loss: 3.272612899541855

Epoch: 5| Step: 6
Training loss: 3.7003605365753174
Validation loss: 3.268970767656962

Epoch: 5| Step: 7
Training loss: 3.8301334381103516
Validation loss: 3.265356719493866

Epoch: 5| Step: 8
Training loss: 3.646103620529175
Validation loss: 3.2614775200684867

Epoch: 5| Step: 9
Training loss: 3.0313243865966797
Validation loss: 3.257942040761312

Epoch: 5| Step: 10
Training loss: 3.0880284309387207
Validation loss: 3.2538269758224487

Epoch: 5| Step: 11
Training loss: 2.8438720703125
Validation loss: 3.250446915626526

Epoch: 37| Step: 0
Training loss: 4.081237316131592
Validation loss: 3.246685047944387

Epoch: 5| Step: 1
Training loss: 3.2585608959198
Validation loss: 3.2432834605375924

Epoch: 5| Step: 2
Training loss: 3.277660846710205
Validation loss: 3.2395664950211844

Epoch: 5| Step: 3
Training loss: 2.6376490592956543
Validation loss: 3.2360250651836395

Epoch: 5| Step: 4
Training loss: 3.347092390060425
Validation loss: 3.2327524224917092

Epoch: 5| Step: 5
Training loss: 2.831618309020996
Validation loss: 3.229053874810537

Epoch: 5| Step: 6
Training loss: 3.5910162925720215
Validation loss: 3.225398451089859

Epoch: 5| Step: 7
Training loss: 3.586195468902588
Validation loss: 3.2215948899586997

Epoch: 5| Step: 8
Training loss: 3.249298572540283
Validation loss: 3.2183659374713898

Epoch: 5| Step: 9
Training loss: 3.175933599472046
Validation loss: 3.214877039194107

Epoch: 5| Step: 10
Training loss: 4.079563140869141
Validation loss: 3.2113848427931466

Epoch: 5| Step: 11
Training loss: 5.288760185241699
Validation loss: 3.208071639140447

Epoch: 38| Step: 0
Training loss: 3.188227415084839
Validation loss: 3.2041364312171936

Epoch: 5| Step: 1
Training loss: 3.032400608062744
Validation loss: 3.200197567542394

Epoch: 5| Step: 2
Training loss: 3.1176674365997314
Validation loss: 3.1964200337727866

Epoch: 5| Step: 3
Training loss: 3.9580554962158203
Validation loss: 3.1926214694976807

Epoch: 5| Step: 4
Training loss: 3.2550995349884033
Validation loss: 3.1889568865299225

Epoch: 5| Step: 5
Training loss: 4.008345127105713
Validation loss: 3.18503945072492

Epoch: 5| Step: 6
Training loss: 3.706270933151245
Validation loss: 3.18096332748731

Epoch: 5| Step: 7
Training loss: 2.750244617462158
Validation loss: 3.177116721868515

Epoch: 5| Step: 8
Training loss: 3.7593250274658203
Validation loss: 3.1732991139094033

Epoch: 5| Step: 9
Training loss: 2.9874744415283203
Validation loss: 3.1694549322128296

Epoch: 5| Step: 10
Training loss: 3.7795231342315674
Validation loss: 3.1659676333268485

Epoch: 5| Step: 11
Training loss: 1.0278213024139404
Validation loss: 3.16218372186025

Epoch: 39| Step: 0
Training loss: 2.7864537239074707
Validation loss: 3.1593598822752633

Epoch: 5| Step: 1
Training loss: 3.5956718921661377
Validation loss: 3.1567100286483765

Epoch: 5| Step: 2
Training loss: 2.643836736679077
Validation loss: 3.153835192322731

Epoch: 5| Step: 3
Training loss: 3.2229104042053223
Validation loss: 3.150992512702942

Epoch: 5| Step: 4
Training loss: 3.9135220050811768
Validation loss: 3.147975424925486

Epoch: 5| Step: 5
Training loss: 3.9309582710266113
Validation loss: 3.144796202580134

Epoch: 5| Step: 6
Training loss: 2.8904056549072266
Validation loss: 3.1415299077828727

Epoch: 5| Step: 7
Training loss: 3.7751235961914062
Validation loss: 3.1383795738220215

Epoch: 5| Step: 8
Training loss: 3.1416738033294678
Validation loss: 3.1350347101688385

Epoch: 5| Step: 9
Training loss: 3.4783291816711426
Validation loss: 3.1315461099147797

Epoch: 5| Step: 10
Training loss: 3.5987706184387207
Validation loss: 3.1285866498947144

Epoch: 5| Step: 11
Training loss: 1.6440892219543457
Validation loss: 3.1250953376293182

Epoch: 40| Step: 0
Training loss: 2.681955337524414
Validation loss: 3.1219269931316376

Epoch: 5| Step: 1
Training loss: 3.0161473751068115
Validation loss: 3.1184381544589996

Epoch: 5| Step: 2
Training loss: 3.202198028564453
Validation loss: 3.1151085694630942

Epoch: 5| Step: 3
Training loss: 3.1437172889709473
Validation loss: 3.111743301153183

Epoch: 5| Step: 4
Training loss: 3.639634609222412
Validation loss: 3.1086387634277344

Epoch: 5| Step: 5
Training loss: 4.099221229553223
Validation loss: 3.1052162249883017

Epoch: 5| Step: 6
Training loss: 3.3596529960632324
Validation loss: 3.1018007596333823

Epoch: 5| Step: 7
Training loss: 2.6085076332092285
Validation loss: 3.098738968372345

Epoch: 5| Step: 8
Training loss: 4.117031574249268
Validation loss: 3.0956527640422187

Epoch: 5| Step: 9
Training loss: 3.12499737739563
Validation loss: 3.092477430899938

Epoch: 5| Step: 10
Training loss: 3.3016304969787598
Validation loss: 3.0893113215764365

Epoch: 5| Step: 11
Training loss: 3.0117690563201904
Validation loss: 3.0862896839777627

Epoch: 41| Step: 0
Training loss: 3.6558609008789062
Validation loss: 3.0831658045450845

Epoch: 5| Step: 1
Training loss: 3.284921646118164
Validation loss: 3.079899549484253

Epoch: 5| Step: 2
Training loss: 3.3968968391418457
Validation loss: 3.076780845721563

Epoch: 5| Step: 3
Training loss: 2.9701898097991943
Validation loss: 3.073454032341639

Epoch: 5| Step: 4
Training loss: 3.225985050201416
Validation loss: 3.0702750583489737

Epoch: 5| Step: 5
Training loss: 4.028839588165283
Validation loss: 3.0675728619098663

Epoch: 5| Step: 6
Training loss: 3.1718204021453857
Validation loss: 3.064019868771235

Epoch: 5| Step: 7
Training loss: 3.579430341720581
Validation loss: 3.060731142759323

Epoch: 5| Step: 8
Training loss: 2.6143767833709717
Validation loss: 3.057701696952184

Epoch: 5| Step: 9
Training loss: 2.418180465698242
Validation loss: 3.0543819864590964

Epoch: 5| Step: 10
Training loss: 3.2792553901672363
Validation loss: 3.051520903905233

Epoch: 5| Step: 11
Training loss: 4.404264450073242
Validation loss: 3.048650542894999

Epoch: 42| Step: 0
Training loss: 3.3387465476989746
Validation loss: 3.0454593499501548

Epoch: 5| Step: 1
Training loss: 3.0587570667266846
Validation loss: 3.042340805133184

Epoch: 5| Step: 2
Training loss: 3.1108555793762207
Validation loss: 3.0395050247510276

Epoch: 5| Step: 3
Training loss: 3.794848680496216
Validation loss: 3.0361851950486503

Epoch: 5| Step: 4
Training loss: 3.4009220600128174
Validation loss: 3.0331397553284964

Epoch: 5| Step: 5
Training loss: 3.5814480781555176
Validation loss: 3.029756098985672

Epoch: 5| Step: 6
Training loss: 2.7848002910614014
Validation loss: 3.02653114994367

Epoch: 5| Step: 7
Training loss: 3.315532684326172
Validation loss: 3.0235599875450134

Epoch: 5| Step: 8
Training loss: 3.2565808296203613
Validation loss: 3.020645966132482

Epoch: 5| Step: 9
Training loss: 2.5817465782165527
Validation loss: 3.0175341268380484

Epoch: 5| Step: 10
Training loss: 3.36989164352417
Validation loss: 3.0144655207792916

Epoch: 5| Step: 11
Training loss: 2.6020023822784424
Validation loss: 3.011613498131434

Epoch: 43| Step: 0
Training loss: 3.33075213432312
Validation loss: 3.0088785191377005

Epoch: 5| Step: 1
Training loss: 3.2064929008483887
Validation loss: 3.0060021380583444

Epoch: 5| Step: 2
Training loss: 3.2207558155059814
Validation loss: 3.003115991751353

Epoch: 5| Step: 3
Training loss: 2.7377376556396484
Validation loss: 3.0004026691118875

Epoch: 5| Step: 4
Training loss: 2.9878430366516113
Validation loss: 2.9975081086158752

Epoch: 5| Step: 5
Training loss: 2.983020544052124
Validation loss: 2.99492218097051

Epoch: 5| Step: 6
Training loss: 3.9850354194641113
Validation loss: 2.9923443595568338

Epoch: 5| Step: 7
Training loss: 2.7842941284179688
Validation loss: 2.989632566769918

Epoch: 5| Step: 8
Training loss: 3.787609100341797
Validation loss: 2.986950695514679

Epoch: 5| Step: 9
Training loss: 2.838827610015869
Validation loss: 2.9837463895479837

Epoch: 5| Step: 10
Training loss: 3.0854883193969727
Validation loss: 2.980893244345983

Epoch: 5| Step: 11
Training loss: 3.868518829345703
Validation loss: 2.9775161941846213

Epoch: 44| Step: 0
Training loss: 3.6059963703155518
Validation loss: 2.9745075901349387

Epoch: 5| Step: 1
Training loss: 2.6159911155700684
Validation loss: 2.9715879460175834

Epoch: 5| Step: 2
Training loss: 2.9408459663391113
Validation loss: 2.968905965487162

Epoch: 5| Step: 3
Training loss: 3.5405097007751465
Validation loss: 2.966159701347351

Epoch: 5| Step: 4
Training loss: 3.010903835296631
Validation loss: 2.9631956815719604

Epoch: 5| Step: 5
Training loss: 3.448439359664917
Validation loss: 2.960201472043991

Epoch: 5| Step: 6
Training loss: 3.8509209156036377
Validation loss: 2.957237641016642

Epoch: 5| Step: 7
Training loss: 2.79880428314209
Validation loss: 2.954317092895508

Epoch: 5| Step: 8
Training loss: 3.026541233062744
Validation loss: 2.95129785935084

Epoch: 5| Step: 9
Training loss: 2.941683769226074
Validation loss: 2.9483569661776223

Epoch: 5| Step: 10
Training loss: 2.8447418212890625
Validation loss: 2.945213476816813

Epoch: 5| Step: 11
Training loss: 3.77703857421875
Validation loss: 2.9421015878518424

Epoch: 45| Step: 0
Training loss: 3.93634295463562
Validation loss: 2.939055581887563

Epoch: 5| Step: 1
Training loss: 3.6069836616516113
Validation loss: 2.935809781153997

Epoch: 5| Step: 2
Training loss: 2.977339267730713
Validation loss: 2.932561715443929

Epoch: 5| Step: 3
Training loss: 3.4324212074279785
Validation loss: 2.929219295581182

Epoch: 5| Step: 4
Training loss: 2.9994068145751953
Validation loss: 2.926220864057541

Epoch: 5| Step: 5
Training loss: 2.991511821746826
Validation loss: 2.9230512181917825

Epoch: 5| Step: 6
Training loss: 2.8691132068634033
Validation loss: 2.9199820160865784

Epoch: 5| Step: 7
Training loss: 2.564584255218506
Validation loss: 2.916991005341212

Epoch: 5| Step: 8
Training loss: 3.7052364349365234
Validation loss: 2.9137777189413705

Epoch: 5| Step: 9
Training loss: 2.830021619796753
Validation loss: 2.9106705089410148

Epoch: 5| Step: 10
Training loss: 2.8385732173919678
Validation loss: 2.9076868295669556

Epoch: 5| Step: 11
Training loss: 1.475394368171692
Validation loss: 2.904970000187556

Epoch: 46| Step: 0
Training loss: 3.2218101024627686
Validation loss: 2.902377128601074

Epoch: 5| Step: 1
Training loss: 2.430650234222412
Validation loss: 2.8997392853101096

Epoch: 5| Step: 2
Training loss: 3.0943868160247803
Validation loss: 2.897279143333435

Epoch: 5| Step: 3
Training loss: 3.8861243724823
Validation loss: 2.8948956628640494

Epoch: 5| Step: 4
Training loss: 3.034465789794922
Validation loss: 2.89245214064916

Epoch: 5| Step: 5
Training loss: 3.110476016998291
Validation loss: 2.8899705906709037

Epoch: 5| Step: 6
Training loss: 3.0434927940368652
Validation loss: 2.8873685896396637

Epoch: 5| Step: 7
Training loss: 3.9070048332214355
Validation loss: 2.8846173882484436

Epoch: 5| Step: 8
Training loss: 2.602069139480591
Validation loss: 2.881653815507889

Epoch: 5| Step: 9
Training loss: 3.1675543785095215
Validation loss: 2.878655423720678

Epoch: 5| Step: 10
Training loss: 2.7266252040863037
Validation loss: 2.875885546207428

Epoch: 5| Step: 11
Training loss: 2.347834348678589
Validation loss: 2.8729364375273385

Epoch: 47| Step: 0
Training loss: 3.9297313690185547
Validation loss: 2.8705246647198996

Epoch: 5| Step: 1
Training loss: 2.528559446334839
Validation loss: 2.8680319488048553

Epoch: 5| Step: 2
Training loss: 3.4398300647735596
Validation loss: 2.865529050429662

Epoch: 5| Step: 3
Training loss: 2.8756556510925293
Validation loss: 2.862995535135269

Epoch: 5| Step: 4
Training loss: 2.7967352867126465
Validation loss: 2.8601419428984323

Epoch: 5| Step: 5
Training loss: 3.4575488567352295
Validation loss: 2.857334395249685

Epoch: 5| Step: 6
Training loss: 2.4040427207946777
Validation loss: 2.854691485563914

Epoch: 5| Step: 7
Training loss: 3.3474011421203613
Validation loss: 2.852059930562973

Epoch: 5| Step: 8
Training loss: 2.826758861541748
Validation loss: 2.849526305993398

Epoch: 5| Step: 9
Training loss: 3.359463930130005
Validation loss: 2.84707044561704

Epoch: 5| Step: 10
Training loss: 2.9308688640594482
Validation loss: 2.844717492659887

Epoch: 5| Step: 11
Training loss: 2.4750046730041504
Validation loss: 2.8422698279221854

Epoch: 48| Step: 0
Training loss: 2.3069281578063965
Validation loss: 2.840212434530258

Epoch: 5| Step: 1
Training loss: 3.605199098587036
Validation loss: 2.8379439214865365

Epoch: 5| Step: 2
Training loss: 3.4413254261016846
Validation loss: 2.8355344235897064

Epoch: 5| Step: 3
Training loss: 2.7183079719543457
Validation loss: 2.8330462872982025

Epoch: 5| Step: 4
Training loss: 3.905756711959839
Validation loss: 2.8308006525039673

Epoch: 5| Step: 5
Training loss: 2.518662452697754
Validation loss: 2.828199793895086

Epoch: 5| Step: 6
Training loss: 3.104393720626831
Validation loss: 2.8258766730626426

Epoch: 5| Step: 7
Training loss: 2.8184659481048584
Validation loss: 2.823478023211161

Epoch: 5| Step: 8
Training loss: 2.5285873413085938
Validation loss: 2.8209493458271027

Epoch: 5| Step: 9
Training loss: 3.1559464931488037
Validation loss: 2.8186186651388803

Epoch: 5| Step: 10
Training loss: 3.343035936355591
Validation loss: 2.8162209490935006

Epoch: 5| Step: 11
Training loss: 3.1210968494415283
Validation loss: 2.8141245444615683

Epoch: 49| Step: 0
Training loss: 4.153443336486816
Validation loss: 2.8119256595770517

Epoch: 5| Step: 1
Training loss: 2.7894816398620605
Validation loss: 2.809258669614792

Epoch: 5| Step: 2
Training loss: 2.966522693634033
Validation loss: 2.8065791030724845

Epoch: 5| Step: 3
Training loss: 2.983031749725342
Validation loss: 2.8041700522104898

Epoch: 5| Step: 4
Training loss: 2.4924426078796387
Validation loss: 2.8015033503373465

Epoch: 5| Step: 5
Training loss: 2.7459757328033447
Validation loss: 2.799126813809077

Epoch: 5| Step: 6
Training loss: 2.9527106285095215
Validation loss: 2.7966292202472687

Epoch: 5| Step: 7
Training loss: 3.436232089996338
Validation loss: 2.7940633793671927

Epoch: 5| Step: 8
Training loss: 2.6403510570526123
Validation loss: 2.791594604651133

Epoch: 5| Step: 9
Training loss: 3.1458678245544434
Validation loss: 2.7891520162423453

Epoch: 5| Step: 10
Training loss: 2.6725118160247803
Validation loss: 2.786736845970154

Epoch: 5| Step: 11
Training loss: 3.9552435874938965
Validation loss: 2.7846038341522217

Epoch: 50| Step: 0
Training loss: 3.3940906524658203
Validation loss: 2.782215674718221

Epoch: 5| Step: 1
Training loss: 2.546891450881958
Validation loss: 2.7797887325286865

Epoch: 5| Step: 2
Training loss: 3.085932970046997
Validation loss: 2.777301639318466

Epoch: 5| Step: 3
Training loss: 3.9057109355926514
Validation loss: 2.7749256988366446

Epoch: 5| Step: 4
Training loss: 2.55157470703125
Validation loss: 2.772571086883545

Epoch: 5| Step: 5
Training loss: 3.199929714202881
Validation loss: 2.770308881998062

Epoch: 5| Step: 6
Training loss: 2.7433924674987793
Validation loss: 2.7680021226406097

Epoch: 5| Step: 7
Training loss: 3.1108310222625732
Validation loss: 2.765755226214727

Epoch: 5| Step: 8
Training loss: 2.75528621673584
Validation loss: 2.763410280148188

Epoch: 5| Step: 9
Training loss: 3.0100350379943848
Validation loss: 2.7612819174925485

Epoch: 5| Step: 10
Training loss: 2.8637797832489014
Validation loss: 2.7589250405629477

Epoch: 5| Step: 11
Training loss: 1.1994972229003906
Validation loss: 2.756604144970576

Epoch: 51| Step: 0
Training loss: 2.8683996200561523
Validation loss: 2.754524310429891

Epoch: 5| Step: 1
Training loss: 2.7274646759033203
Validation loss: 2.7523480355739594

Epoch: 5| Step: 2
Training loss: 2.304464340209961
Validation loss: 2.7500849266846976

Epoch: 5| Step: 3
Training loss: 2.9160234928131104
Validation loss: 2.7477718393007913

Epoch: 5| Step: 4
Training loss: 3.0689961910247803
Validation loss: 2.7458100020885468

Epoch: 5| Step: 5
Training loss: 2.7401530742645264
Validation loss: 2.7433313926060996

Epoch: 5| Step: 6
Training loss: 3.6550381183624268
Validation loss: 2.7411986192067466

Epoch: 5| Step: 7
Training loss: 3.3058300018310547
Validation loss: 2.738753308852514

Epoch: 5| Step: 8
Training loss: 3.0352816581726074
Validation loss: 2.7362354695796967

Epoch: 5| Step: 9
Training loss: 3.2078144550323486
Validation loss: 2.733659118413925

Epoch: 5| Step: 10
Training loss: 2.840712070465088
Validation loss: 2.7313678165276847

Epoch: 5| Step: 11
Training loss: 2.138064384460449
Validation loss: 2.729186018308004

Epoch: 52| Step: 0
Training loss: 2.5167346000671387
Validation loss: 2.72695924838384

Epoch: 5| Step: 1
Training loss: 2.722027540206909
Validation loss: 2.7248952984809875

Epoch: 5| Step: 2
Training loss: 3.3113231658935547
Validation loss: 2.7226350704828897

Epoch: 5| Step: 3
Training loss: 3.106280565261841
Validation loss: 2.720247914393743

Epoch: 5| Step: 4
Training loss: 3.0152359008789062
Validation loss: 2.717846840620041

Epoch: 5| Step: 5
Training loss: 3.57952618598938
Validation loss: 2.715481698513031

Epoch: 5| Step: 6
Training loss: 3.348118305206299
Validation loss: 2.7130966981252036

Epoch: 5| Step: 7
Training loss: 2.4373793601989746
Validation loss: 2.7106341818968454

Epoch: 5| Step: 8
Training loss: 2.4565107822418213
Validation loss: 2.7081980804602304

Epoch: 5| Step: 9
Training loss: 2.4345650672912598
Validation loss: 2.7059234281380973

Epoch: 5| Step: 10
Training loss: 3.217682361602783
Validation loss: 2.703725645939509

Epoch: 5| Step: 11
Training loss: 3.1004445552825928
Validation loss: 2.7015548249085746

Epoch: 53| Step: 0
Training loss: 3.387909412384033
Validation loss: 2.6994290550549827

Epoch: 5| Step: 1
Training loss: 2.133044719696045
Validation loss: 2.69734055797259

Epoch: 5| Step: 2
Training loss: 3.343575954437256
Validation loss: 2.695233921209971

Epoch: 5| Step: 3
Training loss: 2.811955690383911
Validation loss: 2.692956546942393

Epoch: 5| Step: 4
Training loss: 2.8940093517303467
Validation loss: 2.690555453300476

Epoch: 5| Step: 5
Training loss: 3.052462339401245
Validation loss: 2.6882024755080542

Epoch: 5| Step: 6
Training loss: 2.7060818672180176
Validation loss: 2.685502121845881

Epoch: 5| Step: 7
Training loss: 3.176450729370117
Validation loss: 2.6836192905902863

Epoch: 5| Step: 8
Training loss: 2.9704408645629883
Validation loss: 2.6806176602840424

Epoch: 5| Step: 9
Training loss: 2.4643399715423584
Validation loss: 2.6783917446931205

Epoch: 5| Step: 10
Training loss: 2.879347085952759
Validation loss: 2.6742673416932425

Epoch: 5| Step: 11
Training loss: 3.022825241088867
Validation loss: 2.6729560097058616

Epoch: 54| Step: 0
Training loss: 3.442387342453003
Validation loss: 2.67042409380277

Epoch: 5| Step: 1
Training loss: 2.620905637741089
Validation loss: 2.6681771278381348

Epoch: 5| Step: 2
Training loss: 2.5926883220672607
Validation loss: 2.668195595343908

Epoch: 5| Step: 3
Training loss: 2.3237550258636475
Validation loss: 2.6656469156344733

Epoch: 5| Step: 4
Training loss: 2.7267730236053467
Validation loss: 2.6709729929765067

Epoch: 5| Step: 5
Training loss: 3.2194342613220215
Validation loss: 2.6582054495811462

Epoch: 5| Step: 6
Training loss: 3.0472171306610107
Validation loss: 2.6587440371513367

Epoch: 5| Step: 7
Training loss: 3.023470640182495
Validation loss: 2.657297690709432

Epoch: 5| Step: 8
Training loss: 2.9801650047302246
Validation loss: 2.6562611361344657

Epoch: 5| Step: 9
Training loss: 2.1883609294891357
Validation loss: 2.6544223626454673

Epoch: 5| Step: 10
Training loss: 3.38966703414917
Validation loss: 2.6528438329696655

Epoch: 5| Step: 11
Training loss: 2.646944522857666
Validation loss: 2.650437980890274

Epoch: 55| Step: 0
Training loss: 2.90427827835083
Validation loss: 2.647137761116028

Epoch: 5| Step: 1
Training loss: 3.28668475151062
Validation loss: 2.6449212431907654

Epoch: 5| Step: 2
Training loss: 3.0463461875915527
Validation loss: 2.6413417756557465

Epoch: 5| Step: 3
Training loss: 2.9567434787750244
Validation loss: 2.6391699512799582

Epoch: 5| Step: 4
Training loss: 2.710906982421875
Validation loss: 2.636944135030111

Epoch: 5| Step: 5
Training loss: 2.5900416374206543
Validation loss: 2.633576730887095

Epoch: 5| Step: 6
Training loss: 3.068699836730957
Validation loss: 2.630406141281128

Epoch: 5| Step: 7
Training loss: 2.541820526123047
Validation loss: 2.6272238890329995

Epoch: 5| Step: 8
Training loss: 2.8527190685272217
Validation loss: 2.625638206799825

Epoch: 5| Step: 9
Training loss: 2.8584682941436768
Validation loss: 2.633838286002477

Epoch: 5| Step: 10
Training loss: 2.352513074874878
Validation loss: 2.6203536093235016

Epoch: 5| Step: 11
Training loss: 3.065868854522705
Validation loss: 2.6175339917341867

Epoch: 56| Step: 0
Training loss: 2.402848482131958
Validation loss: 2.6162702242533364

Epoch: 5| Step: 1
Training loss: 2.9360718727111816
Validation loss: 2.61433744430542

Epoch: 5| Step: 2
Training loss: 3.120943069458008
Validation loss: 2.6129131615161896

Epoch: 5| Step: 3
Training loss: 2.583263397216797
Validation loss: 2.6117677887280784

Epoch: 5| Step: 4
Training loss: 2.7090981006622314
Validation loss: 2.6095419426759086

Epoch: 5| Step: 5
Training loss: 2.393101692199707
Validation loss: 2.607113222281138

Epoch: 5| Step: 6
Training loss: 2.268667221069336
Validation loss: 2.605141351620356

Epoch: 5| Step: 7
Training loss: 3.199303150177002
Validation loss: 2.602388878663381

Epoch: 5| Step: 8
Training loss: 3.2541346549987793
Validation loss: 2.6003287633260093

Epoch: 5| Step: 9
Training loss: 3.3147125244140625
Validation loss: 2.5972050726413727

Epoch: 5| Step: 10
Training loss: 2.9680991172790527
Validation loss: 2.5937694807847342

Epoch: 5| Step: 11
Training loss: 1.4997906684875488
Validation loss: 2.590768883625666

Epoch: 57| Step: 0
Training loss: 3.089989185333252
Validation loss: 2.5873848497867584

Epoch: 5| Step: 1
Training loss: 2.97117018699646
Validation loss: 2.5841351052125296

Epoch: 5| Step: 2
Training loss: 2.6960651874542236
Validation loss: 2.5841848055521646

Epoch: 5| Step: 3
Training loss: 3.091451644897461
Validation loss: 2.5787266890207925

Epoch: 5| Step: 4
Training loss: 2.954209566116333
Validation loss: 2.5786442955334983

Epoch: 5| Step: 5
Training loss: 2.7796339988708496
Validation loss: 2.575242509444555

Epoch: 5| Step: 6
Training loss: 2.3421072959899902
Validation loss: 2.572029173374176

Epoch: 5| Step: 7
Training loss: 2.6663713455200195
Validation loss: 2.5719428261121116

Epoch: 5| Step: 8
Training loss: 2.640746831893921
Validation loss: 2.5677313605944314

Epoch: 5| Step: 9
Training loss: 2.827540874481201
Validation loss: 2.5659014681975045

Epoch: 5| Step: 10
Training loss: 2.661000967025757
Validation loss: 2.562599336107572

Epoch: 5| Step: 11
Training loss: 2.005648136138916
Validation loss: 2.559996555248896

Epoch: 58| Step: 0
Training loss: 3.1976943016052246
Validation loss: 2.558020750681559

Epoch: 5| Step: 1
Training loss: 2.9035139083862305
Validation loss: 2.554895500342051

Epoch: 5| Step: 2
Training loss: 2.724808931350708
Validation loss: 2.5522795220216117

Epoch: 5| Step: 3
Training loss: 3.109450101852417
Validation loss: 2.551371286312739

Epoch: 5| Step: 4
Training loss: 2.8435447216033936
Validation loss: 2.5500564674536386

Epoch: 5| Step: 5
Training loss: 2.9676918983459473
Validation loss: 2.5514080822467804

Epoch: 5| Step: 6
Training loss: 2.1622726917266846
Validation loss: 2.5463236471017203

Epoch: 5| Step: 7
Training loss: 2.852674961090088
Validation loss: 2.5426772435506186

Epoch: 5| Step: 8
Training loss: 2.546644687652588
Validation loss: 2.5512425899505615

Epoch: 5| Step: 9
Training loss: 2.917576551437378
Validation loss: 2.539964348077774

Epoch: 5| Step: 10
Training loss: 2.056121349334717
Validation loss: 2.5357152422269187

Epoch: 5| Step: 11
Training loss: 2.426701068878174
Validation loss: 2.535062392552694

Epoch: 59| Step: 0
Training loss: 2.5208611488342285
Validation loss: 2.541041205326716

Epoch: 5| Step: 1
Training loss: 2.834195852279663
Validation loss: 2.547751098871231

Epoch: 5| Step: 2
Training loss: 2.845508098602295
Validation loss: 2.5486740867296853

Epoch: 5| Step: 3
Training loss: 2.91514253616333
Validation loss: 2.541047046581904

Epoch: 5| Step: 4
Training loss: 3.107326030731201
Validation loss: 2.533174971739451

Epoch: 5| Step: 5
Training loss: 2.667325258255005
Validation loss: 2.5258330007394156

Epoch: 5| Step: 6
Training loss: 2.8768234252929688
Validation loss: 2.5186873575051627

Epoch: 5| Step: 7
Training loss: 2.2915244102478027
Validation loss: 2.517430235942205

Epoch: 5| Step: 8
Training loss: 2.3302180767059326
Validation loss: 2.51505313316981

Epoch: 5| Step: 9
Training loss: 3.0694689750671387
Validation loss: 2.5134036342302957

Epoch: 5| Step: 10
Training loss: 2.6727380752563477
Validation loss: 2.509145895640055

Epoch: 5| Step: 11
Training loss: 2.09521746635437
Validation loss: 2.5097981095314026

Epoch: 60| Step: 0
Training loss: 2.5109031200408936
Validation loss: 2.5084799031416574

Epoch: 5| Step: 1
Training loss: 2.284032106399536
Validation loss: 2.513326565424601

Epoch: 5| Step: 2
Training loss: 2.88200044631958
Validation loss: 2.5125070810317993

Epoch: 5| Step: 3
Training loss: 2.4770164489746094
Validation loss: 2.504070063432058

Epoch: 5| Step: 4
Training loss: 2.943474531173706
Validation loss: 2.497544209162394

Epoch: 5| Step: 5
Training loss: 2.4291415214538574
Validation loss: 2.4964216450850167

Epoch: 5| Step: 6
Training loss: 2.820951461791992
Validation loss: 2.493553558985392

Epoch: 5| Step: 7
Training loss: 2.6923439502716064
Validation loss: 2.492363760868708

Epoch: 5| Step: 8
Training loss: 2.436858892440796
Validation loss: 2.489734411239624

Epoch: 5| Step: 9
Training loss: 3.0366814136505127
Validation loss: 2.4874468247095742

Epoch: 5| Step: 10
Training loss: 3.1088664531707764
Validation loss: 2.488086466987928

Epoch: 5| Step: 11
Training loss: 2.6254806518554688
Validation loss: 2.487253417571386

Epoch: 61| Step: 0
Training loss: 2.5519907474517822
Validation loss: 2.4833959341049194

Epoch: 5| Step: 1
Training loss: 2.5063276290893555
Validation loss: 2.4849200596412024

Epoch: 5| Step: 2
Training loss: 2.630845546722412
Validation loss: 2.4817596673965454

Epoch: 5| Step: 3
Training loss: 2.9330546855926514
Validation loss: 2.4826589226722717

Epoch: 5| Step: 4
Training loss: 2.455542802810669
Validation loss: 2.476372569799423

Epoch: 5| Step: 5
Training loss: 3.2794482707977295
Validation loss: 2.473607152700424

Epoch: 5| Step: 6
Training loss: 2.5173420906066895
Validation loss: 2.47135137518247

Epoch: 5| Step: 7
Training loss: 2.5194554328918457
Validation loss: 2.4678055346012115

Epoch: 5| Step: 8
Training loss: 2.535459041595459
Validation loss: 2.4673129618167877

Epoch: 5| Step: 9
Training loss: 2.6545772552490234
Validation loss: 2.463766247034073

Epoch: 5| Step: 10
Training loss: 2.6845858097076416
Validation loss: 2.461891839901606

Epoch: 5| Step: 11
Training loss: 2.9635605812072754
Validation loss: 2.4618284503618875

Epoch: 62| Step: 0
Training loss: 2.3387022018432617
Validation loss: 2.4585621456305184

Epoch: 5| Step: 1
Training loss: 2.9127249717712402
Validation loss: 2.457527553041776

Epoch: 5| Step: 2
Training loss: 2.3477015495300293
Validation loss: 2.4546839793523154

Epoch: 5| Step: 3
Training loss: 2.529705762863159
Validation loss: 2.452069262663523

Epoch: 5| Step: 4
Training loss: 2.94793963432312
Validation loss: 2.4479798873265586

Epoch: 5| Step: 5
Training loss: 2.6370646953582764
Validation loss: 2.446221709251404

Epoch: 5| Step: 6
Training loss: 2.8312554359436035
Validation loss: 2.441483994325002

Epoch: 5| Step: 7
Training loss: 2.384916305541992
Validation loss: 2.443462630112966

Epoch: 5| Step: 8
Training loss: 2.8263983726501465
Validation loss: 2.4425158500671387

Epoch: 5| Step: 9
Training loss: 2.9160730838775635
Validation loss: 2.4434329171975455

Epoch: 5| Step: 10
Training loss: 2.406080722808838
Validation loss: 2.4503622551759086

Epoch: 5| Step: 11
Training loss: 2.4178762435913086
Validation loss: 2.4391298790772757

Epoch: 63| Step: 0
Training loss: 2.6361823081970215
Validation loss: 2.4626777271429696

Epoch: 5| Step: 1
Training loss: 2.3873841762542725
Validation loss: 2.4839430451393127

Epoch: 5| Step: 2
Training loss: 2.4687654972076416
Validation loss: 2.503342737754186

Epoch: 5| Step: 3
Training loss: 2.717390298843384
Validation loss: 2.4745921591917672

Epoch: 5| Step: 4
Training loss: 2.4359683990478516
Validation loss: 2.4434825281302133

Epoch: 5| Step: 5
Training loss: 2.6780624389648438
Validation loss: 2.4257141749064126

Epoch: 5| Step: 6
Training loss: 2.8107516765594482
Validation loss: 2.4222590923309326

Epoch: 5| Step: 7
Training loss: 2.253368616104126
Validation loss: 2.4201755225658417

Epoch: 5| Step: 8
Training loss: 2.8467044830322266
Validation loss: 2.4287238816420236

Epoch: 5| Step: 9
Training loss: 3.160649538040161
Validation loss: 2.432964871327082

Epoch: 5| Step: 10
Training loss: 2.4493680000305176
Validation loss: 2.436485434571902

Epoch: 5| Step: 11
Training loss: 2.093717098236084
Validation loss: 2.4431163370609283

Epoch: 64| Step: 0
Training loss: 3.1664645671844482
Validation loss: 2.437933792670568

Epoch: 5| Step: 1
Training loss: 2.8056514263153076
Validation loss: 2.43430757522583

Epoch: 5| Step: 2
Training loss: 3.036649227142334
Validation loss: 2.4284746944904327

Epoch: 5| Step: 3
Training loss: 2.4341769218444824
Validation loss: 2.423449327548345

Epoch: 5| Step: 4
Training loss: 2.358074903488159
Validation loss: 2.412698268890381

Epoch: 5| Step: 5
Training loss: 2.536372184753418
Validation loss: 2.4091190497080484

Epoch: 5| Step: 6
Training loss: 2.3269200325012207
Validation loss: 2.413819839557012

Epoch: 5| Step: 7
Training loss: 2.650245189666748
Validation loss: 2.42254039645195

Epoch: 5| Step: 8
Training loss: 2.631830930709839
Validation loss: 2.4123135209083557

Epoch: 5| Step: 9
Training loss: 2.5127110481262207
Validation loss: 2.402111123005549

Epoch: 5| Step: 10
Training loss: 2.4561104774475098
Validation loss: 2.394164800643921

Epoch: 5| Step: 11
Training loss: 1.3238847255706787
Validation loss: 2.392886151870092

Epoch: 65| Step: 0
Training loss: 2.5644538402557373
Validation loss: 2.3917929927508035

Epoch: 5| Step: 1
Training loss: 3.003800868988037
Validation loss: 2.385882576306661

Epoch: 5| Step: 2
Training loss: 3.157482862472534
Validation loss: 2.385427330931028

Epoch: 5| Step: 3
Training loss: 3.0187244415283203
Validation loss: 2.382599353790283

Epoch: 5| Step: 4
Training loss: 2.4296374320983887
Validation loss: 2.3811169465382895

Epoch: 5| Step: 5
Training loss: 2.4076449871063232
Validation loss: 2.379728535811106

Epoch: 5| Step: 6
Training loss: 2.124969244003296
Validation loss: 2.3774203658103943

Epoch: 5| Step: 7
Training loss: 2.6291842460632324
Validation loss: 2.377328336238861

Epoch: 5| Step: 8
Training loss: 1.9594980478286743
Validation loss: 2.3770008087158203

Epoch: 5| Step: 9
Training loss: 2.17887806892395
Validation loss: 2.376201421022415

Epoch: 5| Step: 10
Training loss: 2.549614429473877
Validation loss: 2.369902655482292

Epoch: 5| Step: 11
Training loss: 3.3806700706481934
Validation loss: 2.368680104613304

Epoch: 66| Step: 0
Training loss: 2.756260633468628
Validation loss: 2.362849692503611

Epoch: 5| Step: 1
Training loss: 1.8051974773406982
Validation loss: 2.362181986371676

Epoch: 5| Step: 2
Training loss: 2.837623119354248
Validation loss: 2.3604160944620767

Epoch: 5| Step: 3
Training loss: 2.452613353729248
Validation loss: 2.3578544557094574

Epoch: 5| Step: 4
Training loss: 2.7491424083709717
Validation loss: 2.3600744704405465

Epoch: 5| Step: 5
Training loss: 2.5703725814819336
Validation loss: 2.3545429011185965

Epoch: 5| Step: 6
Training loss: 2.139570713043213
Validation loss: 2.3528369466463723

Epoch: 5| Step: 7
Training loss: 2.8345882892608643
Validation loss: 2.3538844188054404

Epoch: 5| Step: 8
Training loss: 2.6729962825775146
Validation loss: 2.3467738976081214

Epoch: 5| Step: 9
Training loss: 2.615408182144165
Validation loss: 2.3472907493511834

Epoch: 5| Step: 10
Training loss: 2.6893057823181152
Validation loss: 2.3483409583568573

Epoch: 5| Step: 11
Training loss: 1.0371441841125488
Validation loss: 2.342651108900706

Epoch: 67| Step: 0
Training loss: 2.2384705543518066
Validation loss: 2.342268501718839

Epoch: 5| Step: 1
Training loss: 2.168670177459717
Validation loss: 2.3411752035220466

Epoch: 5| Step: 2
Training loss: 2.8053691387176514
Validation loss: 2.3439158449570336

Epoch: 5| Step: 3
Training loss: 2.1042556762695312
Validation loss: 2.3402270625034967

Epoch: 5| Step: 4
Training loss: 2.3593697547912598
Validation loss: 2.3439199924468994

Epoch: 5| Step: 5
Training loss: 2.1460349559783936
Validation loss: 2.33980530500412

Epoch: 5| Step: 6
Training loss: 2.7854397296905518
Validation loss: 2.336905062198639

Epoch: 5| Step: 7
Training loss: 2.3503236770629883
Validation loss: 2.338117261727651

Epoch: 5| Step: 8
Training loss: 3.0702805519104004
Validation loss: 2.337357590595881

Epoch: 5| Step: 9
Training loss: 2.8786110877990723
Validation loss: 2.3280375798543296

Epoch: 5| Step: 10
Training loss: 2.5008716583251953
Validation loss: 2.331522285938263

Epoch: 5| Step: 11
Training loss: 3.129784107208252
Validation loss: 2.32421875

Epoch: 68| Step: 0
Training loss: 2.9403512477874756
Validation loss: 2.3184399406115213

Epoch: 5| Step: 1
Training loss: 2.1227426528930664
Validation loss: 2.3186201453208923

Epoch: 5| Step: 2
Training loss: 2.8188061714172363
Validation loss: 2.320334553718567

Epoch: 5| Step: 3
Training loss: 2.6252193450927734
Validation loss: 2.3160612682501474

Epoch: 5| Step: 4
Training loss: 2.4767119884490967
Validation loss: 2.3143767416477203

Epoch: 5| Step: 5
Training loss: 1.9831260442733765
Validation loss: 2.3112762371699014

Epoch: 5| Step: 6
Training loss: 2.5897109508514404
Validation loss: 2.310626268386841

Epoch: 5| Step: 7
Training loss: 2.046903133392334
Validation loss: 2.307875166336695

Epoch: 5| Step: 8
Training loss: 2.3800604343414307
Validation loss: 2.309182425340017

Epoch: 5| Step: 9
Training loss: 2.5858495235443115
Validation loss: 2.306437944372495

Epoch: 5| Step: 10
Training loss: 2.718660831451416
Validation loss: 2.3017806311448417

Epoch: 5| Step: 11
Training loss: 2.5362186431884766
Validation loss: 2.298608899116516

Epoch: 69| Step: 0
Training loss: 2.836033582687378
Validation loss: 2.2996424734592438

Epoch: 5| Step: 1
Training loss: 2.362868547439575
Validation loss: 2.2959166367848716

Epoch: 5| Step: 2
Training loss: 3.009810209274292
Validation loss: 2.298929199576378

Epoch: 5| Step: 3
Training loss: 1.8571758270263672
Validation loss: 2.2951962500810623

Epoch: 5| Step: 4
Training loss: 2.602336883544922
Validation loss: 2.289386421442032

Epoch: 5| Step: 5
Training loss: 1.8840755224227905
Validation loss: 2.299471562107404

Epoch: 5| Step: 6
Training loss: 2.30021595954895
Validation loss: 2.2932159105936685

Epoch: 5| Step: 7
Training loss: 2.86637544631958
Validation loss: 2.2837928980588913

Epoch: 5| Step: 8
Training loss: 2.526851177215576
Validation loss: 2.284973531961441

Epoch: 5| Step: 9
Training loss: 2.289783477783203
Validation loss: 2.2836224933465323

Epoch: 5| Step: 10
Training loss: 2.324320077896118
Validation loss: 2.280416026711464

Epoch: 5| Step: 11
Training loss: 3.0500848293304443
Validation loss: 2.274998724460602

Epoch: 70| Step: 0
Training loss: 2.955549716949463
Validation loss: 2.2768806914488473

Epoch: 5| Step: 1
Training loss: 2.7070395946502686
Validation loss: 2.2776317795117698

Epoch: 5| Step: 2
Training loss: 2.3716862201690674
Validation loss: 2.279822518428167

Epoch: 5| Step: 3
Training loss: 2.1307849884033203
Validation loss: 2.274656891822815

Epoch: 5| Step: 4
Training loss: 2.247710704803467
Validation loss: 2.2736393163601556

Epoch: 5| Step: 5
Training loss: 2.3644590377807617
Validation loss: 2.273649573326111

Epoch: 5| Step: 6
Training loss: 2.2046945095062256
Validation loss: 2.2701423466205597

Epoch: 5| Step: 7
Training loss: 2.181943416595459
Validation loss: 2.264305273691813

Epoch: 5| Step: 8
Training loss: 2.970658779144287
Validation loss: 2.2635960082213082

Epoch: 5| Step: 9
Training loss: 1.9609607458114624
Validation loss: 2.264317442973455

Epoch: 5| Step: 10
Training loss: 2.5999033451080322
Validation loss: 2.264344111084938

Epoch: 5| Step: 11
Training loss: 2.849931001663208
Validation loss: 2.2607176502545676

Epoch: 71| Step: 0
Training loss: 2.397174119949341
Validation loss: 2.258145252863566

Epoch: 5| Step: 1
Training loss: 2.2344250679016113
Validation loss: 2.256894826889038

Epoch: 5| Step: 2
Training loss: 2.5674870014190674
Validation loss: 2.2538974781831107

Epoch: 5| Step: 3
Training loss: 2.549467086791992
Validation loss: 2.252536435921987

Epoch: 5| Step: 4
Training loss: 2.569605588912964
Validation loss: 2.2504718601703644

Epoch: 5| Step: 5
Training loss: 2.040780782699585
Validation loss: 2.243686780333519

Epoch: 5| Step: 6
Training loss: 2.081505298614502
Validation loss: 2.2440470159053802

Epoch: 5| Step: 7
Training loss: 2.42216420173645
Validation loss: 2.2459621131420135

Epoch: 5| Step: 8
Training loss: 2.8021609783172607
Validation loss: 2.246303672591845

Epoch: 5| Step: 9
Training loss: 2.4249167442321777
Validation loss: 2.247241502006849

Epoch: 5| Step: 10
Training loss: 2.2005069255828857
Validation loss: 2.251266156633695

Epoch: 5| Step: 11
Training loss: 3.032893657684326
Validation loss: 2.242761939764023

Epoch: 72| Step: 0
Training loss: 2.8161349296569824
Validation loss: 2.2396032412846885

Epoch: 5| Step: 1
Training loss: 2.7876267433166504
Validation loss: 2.2349514961242676

Epoch: 5| Step: 2
Training loss: 1.6337788105010986
Validation loss: 2.235708405574163

Epoch: 5| Step: 3
Training loss: 2.038116216659546
Validation loss: 2.2375817199548087

Epoch: 5| Step: 4
Training loss: 2.65966796875
Validation loss: 2.2369375427563987

Epoch: 5| Step: 5
Training loss: 2.133117914199829
Validation loss: 2.238278110822042

Epoch: 5| Step: 6
Training loss: 2.698399782180786
Validation loss: 2.2386272251605988

Epoch: 5| Step: 7
Training loss: 2.565993547439575
Validation loss: 2.2410136659940085

Epoch: 5| Step: 8
Training loss: 2.1943752765655518
Validation loss: 2.2365439236164093

Epoch: 5| Step: 9
Training loss: 2.2194528579711914
Validation loss: 2.2342360814412436

Epoch: 5| Step: 10
Training loss: 2.8767616748809814
Validation loss: 2.2318176130453744

Epoch: 5| Step: 11
Training loss: 1.3811275959014893
Validation loss: 2.2328147888183594

Epoch: 73| Step: 0
Training loss: 1.8722116947174072
Validation loss: 2.2290629148483276

Epoch: 5| Step: 1
Training loss: 2.087404727935791
Validation loss: 2.226923609773318

Epoch: 5| Step: 2
Training loss: 2.5009775161743164
Validation loss: 2.224902013937632

Epoch: 5| Step: 3
Training loss: 2.353447437286377
Validation loss: 2.2244589825471244

Epoch: 5| Step: 4
Training loss: 3.095977783203125
Validation loss: 2.2183465460936227

Epoch: 5| Step: 5
Training loss: 2.362346649169922
Validation loss: 2.2177889198064804

Epoch: 5| Step: 6
Training loss: 1.8613665103912354
Validation loss: 2.2143833935260773

Epoch: 5| Step: 7
Training loss: 2.250532627105713
Validation loss: 2.2186064968506494

Epoch: 5| Step: 8
Training loss: 2.6299571990966797
Validation loss: 2.2184963126977286

Epoch: 5| Step: 9
Training loss: 2.510334014892578
Validation loss: 2.2148129443327584

Epoch: 5| Step: 10
Training loss: 2.512601852416992
Validation loss: 2.225933318336805

Epoch: 5| Step: 11
Training loss: 2.8701090812683105
Validation loss: 2.2224184473355613

Epoch: 74| Step: 0
Training loss: 1.7838712930679321
Validation loss: 2.2065342466036477

Epoch: 5| Step: 1
Training loss: 2.1216142177581787
Validation loss: 2.2089547415574393

Epoch: 5| Step: 2
Training loss: 2.9446139335632324
Validation loss: 2.202162727713585

Epoch: 5| Step: 3
Training loss: 2.066598415374756
Validation loss: 2.204688683152199

Epoch: 5| Step: 4
Training loss: 2.334259033203125
Validation loss: 2.199957619110743

Epoch: 5| Step: 5
Training loss: 2.5009355545043945
Validation loss: 2.2015701234340668

Epoch: 5| Step: 6
Training loss: 2.221371650695801
Validation loss: 2.199062834183375

Epoch: 5| Step: 7
Training loss: 2.4198591709136963
Validation loss: 2.1971746683120728

Epoch: 5| Step: 8
Training loss: 2.466672420501709
Validation loss: 2.1932538052399955

Epoch: 5| Step: 9
Training loss: 2.0568222999572754
Validation loss: 2.1919034918149314

Epoch: 5| Step: 10
Training loss: 2.7305705547332764
Validation loss: 2.191494887073835

Epoch: 5| Step: 11
Training loss: 3.2213821411132812
Validation loss: 2.1901602546374

Epoch: 75| Step: 0
Training loss: 2.495972156524658
Validation loss: 2.1968971441189447

Epoch: 5| Step: 1
Training loss: 2.2469091415405273
Validation loss: 2.19745334982872

Epoch: 5| Step: 2
Training loss: 2.717080593109131
Validation loss: 2.1970783521731696

Epoch: 5| Step: 3
Training loss: 2.2236576080322266
Validation loss: 2.202800820271174

Epoch: 5| Step: 4
Training loss: 2.7856578826904297
Validation loss: 2.2008359829584756

Epoch: 5| Step: 5
Training loss: 2.1730921268463135
Validation loss: 2.2016757826010385

Epoch: 5| Step: 6
Training loss: 2.1395938396453857
Validation loss: 2.199731945991516

Epoch: 5| Step: 7
Training loss: 1.7217241525650024
Validation loss: 2.1998280733823776

Epoch: 5| Step: 8
Training loss: 1.871904730796814
Validation loss: 2.1963662604490914

Epoch: 5| Step: 9
Training loss: 2.253138303756714
Validation loss: 2.1963838885227838

Epoch: 5| Step: 10
Training loss: 2.936995029449463
Validation loss: 2.193600748976072

Epoch: 5| Step: 11
Training loss: 3.6628785133361816
Validation loss: 2.192606990536054

Epoch: 76| Step: 0
Training loss: 2.1456990242004395
Validation loss: 2.1886493116617203

Epoch: 5| Step: 1
Training loss: 2.4974584579467773
Validation loss: 2.179285595814387

Epoch: 5| Step: 2
Training loss: 2.1258859634399414
Validation loss: 2.176835387945175

Epoch: 5| Step: 3
Training loss: 2.3205692768096924
Validation loss: 2.177062680323919

Epoch: 5| Step: 4
Training loss: 1.8394415378570557
Validation loss: 2.171080470085144

Epoch: 5| Step: 5
Training loss: 2.5077996253967285
Validation loss: 2.170512020587921

Epoch: 5| Step: 6
Training loss: 2.2964370250701904
Validation loss: 2.1659013430277505

Epoch: 5| Step: 7
Training loss: 2.8583920001983643
Validation loss: 2.163417155543963

Epoch: 5| Step: 8
Training loss: 2.147139072418213
Validation loss: 2.1810067544380822

Epoch: 5| Step: 9
Training loss: 2.5861129760742188
Validation loss: 2.192184035976728

Epoch: 5| Step: 10
Training loss: 2.1955630779266357
Validation loss: 2.1981346855560937

Epoch: 5| Step: 11
Training loss: 2.2604236602783203
Validation loss: 2.205935219923655

Epoch: 77| Step: 0
Training loss: 2.1150081157684326
Validation loss: 2.2503369400898614

Epoch: 5| Step: 1
Training loss: 2.390232563018799
Validation loss: 2.263380696376165

Epoch: 5| Step: 2
Training loss: 2.386155605316162
Validation loss: 2.2414977649847665

Epoch: 5| Step: 3
Training loss: 2.580145835876465
Validation loss: 2.200047175089518

Epoch: 5| Step: 4
Training loss: 2.127582550048828
Validation loss: 2.1624485651652017

Epoch: 5| Step: 5
Training loss: 2.3427324295043945
Validation loss: 2.150411273042361

Epoch: 5| Step: 6
Training loss: 2.3032655715942383
Validation loss: 2.1630818049112954

Epoch: 5| Step: 7
Training loss: 3.054673910140991
Validation loss: 2.1648027449846268

Epoch: 5| Step: 8
Training loss: 2.142517566680908
Validation loss: 2.168250565727552

Epoch: 5| Step: 9
Training loss: 1.8479712009429932
Validation loss: 2.1698180387417474

Epoch: 5| Step: 10
Training loss: 2.5963783264160156
Validation loss: 2.1730157335599265

Epoch: 5| Step: 11
Training loss: 3.0115880966186523
Validation loss: 2.17421318590641

Epoch: 78| Step: 0
Training loss: 1.9083131551742554
Validation loss: 2.174413710832596

Epoch: 5| Step: 1
Training loss: 1.9605369567871094
Validation loss: 2.1762258211771646

Epoch: 5| Step: 2
Training loss: 2.0209145545959473
Validation loss: 2.1709409803152084

Epoch: 5| Step: 3
Training loss: 2.7176575660705566
Validation loss: 2.1682528456052146

Epoch: 5| Step: 4
Training loss: 2.4209446907043457
Validation loss: 2.167221928636233

Epoch: 5| Step: 5
Training loss: 2.87284779548645
Validation loss: 2.168327877918879

Epoch: 5| Step: 6
Training loss: 2.161299467086792
Validation loss: 2.1631847272316613

Epoch: 5| Step: 7
Training loss: 2.3475124835968018
Validation loss: 2.1598291248083115

Epoch: 5| Step: 8
Training loss: 2.60697603225708
Validation loss: 2.1601660549640656

Epoch: 5| Step: 9
Training loss: 2.4728286266326904
Validation loss: 2.1581418017546334

Epoch: 5| Step: 10
Training loss: 2.278357744216919
Validation loss: 2.1571836719910302

Epoch: 5| Step: 11
Training loss: 1.7504065036773682
Validation loss: 2.1529410928487778

Epoch: 79| Step: 0
Training loss: 2.314312696456909
Validation loss: 2.152363250652949

Epoch: 5| Step: 1
Training loss: 2.065552234649658
Validation loss: 2.1496863265832267

Epoch: 5| Step: 2
Training loss: 2.29299259185791
Validation loss: 2.1487409422794976

Epoch: 5| Step: 3
Training loss: 1.9552412033081055
Validation loss: 2.148543809851011

Epoch: 5| Step: 4
Training loss: 2.3689751625061035
Validation loss: 2.1473838090896606

Epoch: 5| Step: 5
Training loss: 2.3829236030578613
Validation loss: 2.1428459137678146

Epoch: 5| Step: 6
Training loss: 2.7551519870758057
Validation loss: 2.1479680190483728

Epoch: 5| Step: 7
Training loss: 1.9414503574371338
Validation loss: 2.146297221382459

Epoch: 5| Step: 8
Training loss: 2.6134657859802246
Validation loss: 2.1386849731206894

Epoch: 5| Step: 9
Training loss: 2.633324146270752
Validation loss: 2.1382124374310174

Epoch: 5| Step: 10
Training loss: 2.12904691696167
Validation loss: 2.137145847082138

Epoch: 5| Step: 11
Training loss: 1.9156254529953003
Validation loss: 2.1377964913845062

Epoch: 80| Step: 0
Training loss: 2.3423523902893066
Validation loss: 2.1284389098485312

Epoch: 5| Step: 1
Training loss: 2.183199167251587
Validation loss: 2.1396197577317557

Epoch: 5| Step: 2
Training loss: 2.384429454803467
Validation loss: 2.147880216439565

Epoch: 5| Step: 3
Training loss: 2.43357515335083
Validation loss: 2.1474599043528237

Epoch: 5| Step: 4
Training loss: 2.310560703277588
Validation loss: 2.152797674139341

Epoch: 5| Step: 5
Training loss: 1.9502952098846436
Validation loss: 2.1532688240210214

Epoch: 5| Step: 6
Training loss: 2.420166492462158
Validation loss: 2.1448345482349396

Epoch: 5| Step: 7
Training loss: 2.1232686042785645
Validation loss: 2.1336026787757874

Epoch: 5| Step: 8
Training loss: 2.423444986343384
Validation loss: 2.1320330748955407

Epoch: 5| Step: 9
Training loss: 2.598907232284546
Validation loss: 2.1226824074983597

Epoch: 5| Step: 10
Training loss: 2.1976687908172607
Validation loss: 2.121479724844297

Epoch: 5| Step: 11
Training loss: 1.6200562715530396
Validation loss: 2.1173198521137238

Epoch: 81| Step: 0
Training loss: 2.7018425464630127
Validation loss: 2.1116696993509927

Epoch: 5| Step: 1
Training loss: 2.5203652381896973
Validation loss: 2.1102150132258735

Epoch: 5| Step: 2
Training loss: 2.4210400581359863
Validation loss: 2.1119811087846756

Epoch: 5| Step: 3
Training loss: 2.0856430530548096
Validation loss: 2.1154435326655707

Epoch: 5| Step: 4
Training loss: 1.9296624660491943
Validation loss: 2.1177221139272056

Epoch: 5| Step: 5
Training loss: 1.9908673763275146
Validation loss: 2.118045300245285

Epoch: 5| Step: 6
Training loss: 2.014403820037842
Validation loss: 2.1199849049250283

Epoch: 5| Step: 7
Training loss: 2.7339704036712646
Validation loss: 2.1156356980403266

Epoch: 5| Step: 8
Training loss: 2.374516010284424
Validation loss: 2.1094801326592765

Epoch: 5| Step: 9
Training loss: 1.9720852375030518
Validation loss: 2.1156693398952484

Epoch: 5| Step: 10
Training loss: 2.290512800216675
Validation loss: 2.113767017920812

Epoch: 5| Step: 11
Training loss: 2.3496665954589844
Validation loss: 2.111335044105848

Epoch: 82| Step: 0
Training loss: 2.232426881790161
Validation loss: 2.105832835038503

Epoch: 5| Step: 1
Training loss: 1.6086794137954712
Validation loss: 2.1045465717713037

Epoch: 5| Step: 2
Training loss: 1.892324447631836
Validation loss: 2.103470802307129

Epoch: 5| Step: 3
Training loss: 2.8912391662597656
Validation loss: 2.107527121901512

Epoch: 5| Step: 4
Training loss: 2.5608198642730713
Validation loss: 2.1055076022942862

Epoch: 5| Step: 5
Training loss: 2.4867103099823
Validation loss: 2.1032837380965552

Epoch: 5| Step: 6
Training loss: 1.8533767461776733
Validation loss: 2.1004388481378555

Epoch: 5| Step: 7
Training loss: 2.3068788051605225
Validation loss: 2.1084078003962836

Epoch: 5| Step: 8
Training loss: 2.6032862663269043
Validation loss: 2.106737121939659

Epoch: 5| Step: 9
Training loss: 2.1226086616516113
Validation loss: 2.11782243847847

Epoch: 5| Step: 10
Training loss: 2.3288283348083496
Validation loss: 2.1109011669953666

Epoch: 5| Step: 11
Training loss: 2.278087615966797
Validation loss: 2.1078882763783136

Epoch: 83| Step: 0
Training loss: 2.3023829460144043
Validation loss: 2.1072756151358285

Epoch: 5| Step: 1
Training loss: 2.4733641147613525
Validation loss: 2.1042964160442352

Epoch: 5| Step: 2
Training loss: 2.5594191551208496
Validation loss: 2.10814405977726

Epoch: 5| Step: 3
Training loss: 2.4577832221984863
Validation loss: 2.1091265032688775

Epoch: 5| Step: 4
Training loss: 2.280787706375122
Validation loss: 2.1212042222420373

Epoch: 5| Step: 5
Training loss: 2.791551113128662
Validation loss: 2.1154193530480065

Epoch: 5| Step: 6
Training loss: 1.993524193763733
Validation loss: 2.1063474665085473

Epoch: 5| Step: 7
Training loss: 1.797181487083435
Validation loss: 2.1105742156505585

Epoch: 5| Step: 8
Training loss: 2.142587184906006
Validation loss: 2.0989421904087067

Epoch: 5| Step: 9
Training loss: 2.1892752647399902
Validation loss: 2.094522883494695

Epoch: 5| Step: 10
Training loss: 1.896053671836853
Validation loss: 2.08559742073218

Epoch: 5| Step: 11
Training loss: 2.127661943435669
Validation loss: 2.0889219592014947

Epoch: 84| Step: 0
Training loss: 2.0171780586242676
Validation loss: 2.090714459617933

Epoch: 5| Step: 1
Training loss: 2.81547474861145
Validation loss: 2.0912808775901794

Epoch: 5| Step: 2
Training loss: 1.9752798080444336
Validation loss: 2.096376339594523

Epoch: 5| Step: 3
Training loss: 2.291210651397705
Validation loss: 2.093092525998751

Epoch: 5| Step: 4
Training loss: 2.4171669483184814
Validation loss: 2.106967637936274

Epoch: 5| Step: 5
Training loss: 2.194227695465088
Validation loss: 2.097953587770462

Epoch: 5| Step: 6
Training loss: 2.2645726203918457
Validation loss: 2.094024841984113

Epoch: 5| Step: 7
Training loss: 1.9531497955322266
Validation loss: 2.0860107094049454

Epoch: 5| Step: 8
Training loss: 2.096769332885742
Validation loss: 2.0872593273719153

Epoch: 5| Step: 9
Training loss: 2.542330265045166
Validation loss: 2.088823139667511

Epoch: 5| Step: 10
Training loss: 2.2249035835266113
Validation loss: 2.0944691052039466

Epoch: 5| Step: 11
Training loss: 2.1744418144226074
Validation loss: 2.0970194737116494

Epoch: 85| Step: 0
Training loss: 2.212794542312622
Validation loss: 2.088418180743853

Epoch: 5| Step: 1
Training loss: 2.57792329788208
Validation loss: 2.093020513653755

Epoch: 5| Step: 2
Training loss: 2.235051393508911
Validation loss: 2.0940110087394714

Epoch: 5| Step: 3
Training loss: 1.950239896774292
Validation loss: 2.0950863659381866

Epoch: 5| Step: 4
Training loss: 2.686415195465088
Validation loss: 2.083279753724734

Epoch: 5| Step: 5
Training loss: 1.6446807384490967
Validation loss: 2.0830056170622506

Epoch: 5| Step: 6
Training loss: 1.9162418842315674
Validation loss: 2.0862912088632584

Epoch: 5| Step: 7
Training loss: 1.8538455963134766
Validation loss: 2.090262249112129

Epoch: 5| Step: 8
Training loss: 2.2886204719543457
Validation loss: 2.0868957142035165

Epoch: 5| Step: 9
Training loss: 2.8968985080718994
Validation loss: 2.0895058612028756

Epoch: 5| Step: 10
Training loss: 2.036878824234009
Validation loss: 2.093310291568438

Epoch: 5| Step: 11
Training loss: 3.3635754585266113
Validation loss: 2.0869527210791907

Epoch: 86| Step: 0
Training loss: 2.576885938644409
Validation loss: 2.073135902484258

Epoch: 5| Step: 1
Training loss: 2.149293899536133
Validation loss: 2.073074455062548

Epoch: 5| Step: 2
Training loss: 2.5243632793426514
Validation loss: 2.0847105979919434

Epoch: 5| Step: 3
Training loss: 2.2304561138153076
Validation loss: 2.07963856558005

Epoch: 5| Step: 4
Training loss: 2.3854622840881348
Validation loss: 2.077781413992246

Epoch: 5| Step: 5
Training loss: 2.015730381011963
Validation loss: 2.081763193011284

Epoch: 5| Step: 6
Training loss: 1.9553359746932983
Validation loss: 2.0752474069595337

Epoch: 5| Step: 7
Training loss: 2.035520076751709
Validation loss: 2.071250001589457

Epoch: 5| Step: 8
Training loss: 2.0198769569396973
Validation loss: 2.075293560822805

Epoch: 5| Step: 9
Training loss: 2.4751248359680176
Validation loss: 2.079827164610227

Epoch: 5| Step: 10
Training loss: 2.3088269233703613
Validation loss: 2.070585901538531

Epoch: 5| Step: 11
Training loss: 2.0897481441497803
Validation loss: 2.0804755141337714

Epoch: 87| Step: 0
Training loss: 2.235044002532959
Validation loss: 2.065893908341726

Epoch: 5| Step: 1
Training loss: 2.009779214859009
Validation loss: 2.0709632684787116

Epoch: 5| Step: 2
Training loss: 2.2378411293029785
Validation loss: 2.0694513022899628

Epoch: 5| Step: 3
Training loss: 2.296253204345703
Validation loss: 2.068632125854492

Epoch: 5| Step: 4
Training loss: 2.2942891120910645
Validation loss: 2.062474330266317

Epoch: 5| Step: 5
Training loss: 2.532780170440674
Validation loss: 2.0608452558517456

Epoch: 5| Step: 6
Training loss: 2.4942965507507324
Validation loss: 2.0648110012213388

Epoch: 5| Step: 7
Training loss: 2.7413599491119385
Validation loss: 2.058070903023084

Epoch: 5| Step: 8
Training loss: 1.915186882019043
Validation loss: 2.064172943433126

Epoch: 5| Step: 9
Training loss: 2.2999227046966553
Validation loss: 2.0664405028025308

Epoch: 5| Step: 10
Training loss: 1.3716298341751099
Validation loss: 2.0591088930765786

Epoch: 5| Step: 11
Training loss: 2.6250157356262207
Validation loss: 2.0795887062946954

Epoch: 88| Step: 0
Training loss: 2.3470919132232666
Validation loss: 2.0611894577741623

Epoch: 5| Step: 1
Training loss: 2.1579384803771973
Validation loss: 2.0586620469888053

Epoch: 5| Step: 2
Training loss: 2.422820806503296
Validation loss: 2.056945870320002

Epoch: 5| Step: 3
Training loss: 1.977407693862915
Validation loss: 2.0513742615779242

Epoch: 5| Step: 4
Training loss: 2.4572594165802
Validation loss: 2.0497921208540597

Epoch: 5| Step: 5
Training loss: 1.8543142080307007
Validation loss: 2.0562101900577545

Epoch: 5| Step: 6
Training loss: 2.230037212371826
Validation loss: 2.0533470859130225

Epoch: 5| Step: 7
Training loss: 2.1074204444885254
Validation loss: 2.0557127445936203

Epoch: 5| Step: 8
Training loss: 1.8643121719360352
Validation loss: 2.0533129374186196

Epoch: 5| Step: 9
Training loss: 2.4848923683166504
Validation loss: 2.0540236085653305

Epoch: 5| Step: 10
Training loss: 2.290139675140381
Validation loss: 2.059954990943273

Epoch: 5| Step: 11
Training loss: 3.6357152462005615
Validation loss: 2.052766422430674

Epoch: 89| Step: 0
Training loss: 1.8787386417388916
Validation loss: 2.0532331417004266

Epoch: 5| Step: 1
Training loss: 2.3376212120056152
Validation loss: 2.048458680510521

Epoch: 5| Step: 2
Training loss: 2.166749954223633
Validation loss: 2.0534281680981317

Epoch: 5| Step: 3
Training loss: 2.4899814128875732
Validation loss: 2.0547674794991813

Epoch: 5| Step: 4
Training loss: 1.6521472930908203
Validation loss: 2.0570106158653894

Epoch: 5| Step: 5
Training loss: 2.276092052459717
Validation loss: 2.0573293417692184

Epoch: 5| Step: 6
Training loss: 2.1694018840789795
Validation loss: 2.0636217643817267

Epoch: 5| Step: 7
Training loss: 2.384904623031616
Validation loss: 2.06167766948541

Epoch: 5| Step: 8
Training loss: 2.1500320434570312
Validation loss: 2.0641150573889413

Epoch: 5| Step: 9
Training loss: 2.4276859760284424
Validation loss: 2.061950077613195

Epoch: 5| Step: 10
Training loss: 2.614546775817871
Validation loss: 2.0574071804682412

Epoch: 5| Step: 11
Training loss: 2.5337600708007812
Validation loss: 2.065539906422297

Epoch: 90| Step: 0
Training loss: 2.3455796241760254
Validation loss: 2.05796713133653

Epoch: 5| Step: 1
Training loss: 2.430659770965576
Validation loss: 2.0620027085145316

Epoch: 5| Step: 2
Training loss: 2.2963337898254395
Validation loss: 2.059242695569992

Epoch: 5| Step: 3
Training loss: 2.0043797492980957
Validation loss: 2.0547776321570077

Epoch: 5| Step: 4
Training loss: 2.3369452953338623
Validation loss: 2.0599053452412286

Epoch: 5| Step: 5
Training loss: 2.2111146450042725
Validation loss: 2.057605360945066

Epoch: 5| Step: 6
Training loss: 2.345146894454956
Validation loss: 2.0572032431761422

Epoch: 5| Step: 7
Training loss: 1.8772071599960327
Validation loss: 2.0557551831007004

Epoch: 5| Step: 8
Training loss: 2.83622407913208
Validation loss: 2.055110757549604

Epoch: 5| Step: 9
Training loss: 1.968341588973999
Validation loss: 2.0529072682062783

Epoch: 5| Step: 10
Training loss: 2.026995897293091
Validation loss: 2.0475486566623053

Epoch: 5| Step: 11
Training loss: 2.021906852722168
Validation loss: 2.0398555994033813

Epoch: 91| Step: 0
Training loss: 2.2737979888916016
Validation loss: 2.0400563776493073

Epoch: 5| Step: 1
Training loss: 2.0699634552001953
Validation loss: 2.049055983622869

Epoch: 5| Step: 2
Training loss: 2.3135087490081787
Validation loss: 2.0588220606247583

Epoch: 5| Step: 3
Training loss: 2.153674364089966
Validation loss: 2.071814422806104

Epoch: 5| Step: 4
Training loss: 2.507713794708252
Validation loss: 2.0833733727534614

Epoch: 5| Step: 5
Training loss: 2.0254247188568115
Validation loss: 2.0892772177855172

Epoch: 5| Step: 6
Training loss: 2.3015146255493164
Validation loss: 2.093858083089193

Epoch: 5| Step: 7
Training loss: 1.8590943813323975
Validation loss: 2.0947154661019645

Epoch: 5| Step: 8
Training loss: 2.6510939598083496
Validation loss: 2.0906570851802826

Epoch: 5| Step: 9
Training loss: 2.32792067527771
Validation loss: 2.0872985422611237

Epoch: 5| Step: 10
Training loss: 2.08778715133667
Validation loss: 2.0657914529244104

Epoch: 5| Step: 11
Training loss: 3.118955135345459
Validation loss: 2.0635300328334174

Epoch: 92| Step: 0
Training loss: 2.3230671882629395
Validation loss: 2.0474041352669397

Epoch: 5| Step: 1
Training loss: 1.7337945699691772
Validation loss: 2.045189137260119

Epoch: 5| Step: 2
Training loss: 2.674718141555786
Validation loss: 2.0410621762275696

Epoch: 5| Step: 3
Training loss: 2.341076374053955
Validation loss: 2.04463829100132

Epoch: 5| Step: 4
Training loss: 2.598259687423706
Validation loss: 2.050105482339859

Epoch: 5| Step: 5
Training loss: 1.9461848735809326
Validation loss: 2.046992609898249

Epoch: 5| Step: 6
Training loss: 2.2536182403564453
Validation loss: 2.048720250527064

Epoch: 5| Step: 7
Training loss: 2.1534430980682373
Validation loss: 2.051422198613485

Epoch: 5| Step: 8
Training loss: 2.280884027481079
Validation loss: 2.050009881456693

Epoch: 5| Step: 9
Training loss: 1.9779949188232422
Validation loss: 2.0457357466220856

Epoch: 5| Step: 10
Training loss: 2.3246593475341797
Validation loss: 2.046368420124054

Epoch: 5| Step: 11
Training loss: 1.69391930103302
Validation loss: 2.0472972244024277

Epoch: 93| Step: 0
Training loss: 2.911222457885742
Validation loss: 2.0387143393357596

Epoch: 5| Step: 1
Training loss: 1.8001854419708252
Validation loss: 2.0384195695320764

Epoch: 5| Step: 2
Training loss: 2.344414472579956
Validation loss: 2.0375792483488717

Epoch: 5| Step: 3
Training loss: 1.8503763675689697
Validation loss: 2.0317471275726953

Epoch: 5| Step: 4
Training loss: 2.596292018890381
Validation loss: 2.03561469912529

Epoch: 5| Step: 5
Training loss: 2.8291449546813965
Validation loss: 2.048418511946996

Epoch: 5| Step: 6
Training loss: 2.100123167037964
Validation loss: 2.063599775234858

Epoch: 5| Step: 7
Training loss: 2.254042387008667
Validation loss: 2.070180962483088

Epoch: 5| Step: 8
Training loss: 2.3123669624328613
Validation loss: 2.0604446281989417

Epoch: 5| Step: 9
Training loss: 1.860063910484314
Validation loss: 2.061479235688845

Epoch: 5| Step: 10
Training loss: 1.3447678089141846
Validation loss: 2.06658236682415

Epoch: 5| Step: 11
Training loss: 2.5391440391540527
Validation loss: 2.053801198800405

Epoch: 94| Step: 0
Training loss: 2.1979873180389404
Validation loss: 2.04807918270429

Epoch: 5| Step: 1
Training loss: 2.1624319553375244
Validation loss: 2.0429129203160605

Epoch: 5| Step: 2
Training loss: 1.9980676174163818
Validation loss: 2.0332506646712623

Epoch: 5| Step: 3
Training loss: 2.415590763092041
Validation loss: 2.0298513571421304

Epoch: 5| Step: 4
Training loss: 2.4121956825256348
Validation loss: 2.0310869415601096

Epoch: 5| Step: 5
Training loss: 2.37435245513916
Validation loss: 2.034923995534579

Epoch: 5| Step: 6
Training loss: 2.2641968727111816
Validation loss: 2.0288459757963815

Epoch: 5| Step: 7
Training loss: 2.2491116523742676
Validation loss: 2.035598963499069

Epoch: 5| Step: 8
Training loss: 2.0512237548828125
Validation loss: 2.03267631928126

Epoch: 5| Step: 9
Training loss: 2.0752129554748535
Validation loss: 2.0290012806653976

Epoch: 5| Step: 10
Training loss: 1.8895810842514038
Validation loss: 2.036244109272957

Epoch: 5| Step: 11
Training loss: 2.706465244293213
Validation loss: 2.032448331514994

Epoch: 95| Step: 0
Training loss: 1.914362907409668
Validation loss: 2.0284549444913864

Epoch: 5| Step: 1
Training loss: 2.4720401763916016
Validation loss: 2.0300042629241943

Epoch: 5| Step: 2
Training loss: 2.2696051597595215
Validation loss: 2.027651528517405

Epoch: 5| Step: 3
Training loss: 1.714695692062378
Validation loss: 2.029785210887591

Epoch: 5| Step: 4
Training loss: 1.8788940906524658
Validation loss: 2.039410720268885

Epoch: 5| Step: 5
Training loss: 2.5134034156799316
Validation loss: 2.0317658136288324

Epoch: 5| Step: 6
Training loss: 2.3308265209198
Validation loss: 2.046267737944921

Epoch: 5| Step: 7
Training loss: 1.972085952758789
Validation loss: 2.0465628852446875

Epoch: 5| Step: 8
Training loss: 2.7582554817199707
Validation loss: 2.049411714076996

Epoch: 5| Step: 9
Training loss: 2.731299638748169
Validation loss: 2.0591641863187156

Epoch: 5| Step: 10
Training loss: 1.667806625366211
Validation loss: 2.0464301457007728

Epoch: 5| Step: 11
Training loss: 2.436002731323242
Validation loss: 2.0472647696733475

Epoch: 96| Step: 0
Training loss: 2.0748798847198486
Validation loss: 2.038082793354988

Epoch: 5| Step: 1
Training loss: 2.254521608352661
Validation loss: 2.0354493161042533

Epoch: 5| Step: 2
Training loss: 2.122709274291992
Validation loss: 2.030978575348854

Epoch: 5| Step: 3
Training loss: 2.740872383117676
Validation loss: 2.0353432347377143

Epoch: 5| Step: 4
Training loss: 2.5778040885925293
Validation loss: 2.0359715074300766

Epoch: 5| Step: 5
Training loss: 1.9616279602050781
Validation loss: 2.0371312151352563

Epoch: 5| Step: 6
Training loss: 1.651716947555542
Validation loss: 2.0432993372281394

Epoch: 5| Step: 7
Training loss: 2.591627597808838
Validation loss: 2.037802259127299

Epoch: 5| Step: 8
Training loss: 2.4219183921813965
Validation loss: 2.041984955469767

Epoch: 5| Step: 9
Training loss: 1.63905930519104
Validation loss: 2.0346788316965103

Epoch: 5| Step: 10
Training loss: 2.084364891052246
Validation loss: 2.0282491644223533

Epoch: 5| Step: 11
Training loss: 2.598670482635498
Validation loss: 2.0310889234145484

Epoch: 97| Step: 0
Training loss: 1.8698508739471436
Validation loss: 2.0256821562846503

Epoch: 5| Step: 1
Training loss: 2.772186756134033
Validation loss: 2.0419191171725593

Epoch: 5| Step: 2
Training loss: 2.509122371673584
Validation loss: 2.0524938056866326

Epoch: 5| Step: 3
Training loss: 2.170671224594116
Validation loss: 2.0673824151357016

Epoch: 5| Step: 4
Training loss: 1.8353874683380127
Validation loss: 2.076324467857679

Epoch: 5| Step: 5
Training loss: 2.231302261352539
Validation loss: 2.0982126692930856

Epoch: 5| Step: 6
Training loss: 1.910638451576233
Validation loss: 2.104869822661082

Epoch: 5| Step: 7
Training loss: 2.7746987342834473
Validation loss: 2.0848666777213416

Epoch: 5| Step: 8
Training loss: 2.5160720348358154
Validation loss: 2.0796985775232315

Epoch: 5| Step: 9
Training loss: 2.1237826347351074
Validation loss: 2.0733600010474524

Epoch: 5| Step: 10
Training loss: 1.8135722875595093
Validation loss: 2.067844271659851

Epoch: 5| Step: 11
Training loss: 1.3126107454299927
Validation loss: 2.0670447746912637

Epoch: 98| Step: 0
Training loss: 1.8189083337783813
Validation loss: 2.070440113544464

Epoch: 5| Step: 1
Training loss: 2.238454818725586
Validation loss: 2.071400597691536

Epoch: 5| Step: 2
Training loss: 2.176701068878174
Validation loss: 2.069792702794075

Epoch: 5| Step: 3
Training loss: 2.2827706336975098
Validation loss: 2.071915735801061

Epoch: 5| Step: 4
Training loss: 2.38965106010437
Validation loss: 2.0534019768238068

Epoch: 5| Step: 5
Training loss: 2.7260305881500244
Validation loss: 2.054459974169731

Epoch: 5| Step: 6
Training loss: 2.264267683029175
Validation loss: 2.037229726711909

Epoch: 5| Step: 7
Training loss: 2.402484178543091
Validation loss: 2.024360343813896

Epoch: 5| Step: 8
Training loss: 2.4766030311584473
Validation loss: 2.0304685483376184

Epoch: 5| Step: 9
Training loss: 1.864457368850708
Validation loss: 2.029634644587835

Epoch: 5| Step: 10
Training loss: 2.1181750297546387
Validation loss: 2.041596531867981

Epoch: 5| Step: 11
Training loss: 0.4889761507511139
Validation loss: 2.042861411968867

Epoch: 99| Step: 0
Training loss: 1.9157193899154663
Validation loss: 2.0429670164982476

Epoch: 5| Step: 1
Training loss: 1.6333576440811157
Validation loss: 2.0410650024811425

Epoch: 5| Step: 2
Training loss: 2.2860751152038574
Validation loss: 2.042408049106598

Epoch: 5| Step: 3
Training loss: 2.453941822052002
Validation loss: 2.0369718273480735

Epoch: 5| Step: 4
Training loss: 2.24495267868042
Validation loss: 2.0443441967169442

Epoch: 5| Step: 5
Training loss: 2.319115161895752
Validation loss: 2.037852202852567

Epoch: 5| Step: 6
Training loss: 2.0945613384246826
Validation loss: 2.037507474422455

Epoch: 5| Step: 7
Training loss: 2.3639533519744873
Validation loss: 2.0317820807298026

Epoch: 5| Step: 8
Training loss: 1.9906895160675049
Validation loss: 2.029095411300659

Epoch: 5| Step: 9
Training loss: 2.6573917865753174
Validation loss: 2.034566809733709

Epoch: 5| Step: 10
Training loss: 2.4373745918273926
Validation loss: 2.029130071401596

Epoch: 5| Step: 11
Training loss: 1.7049850225448608
Validation loss: 2.023335744937261

Epoch: 100| Step: 0
Training loss: 1.9468586444854736
Validation loss: 2.029314801096916

Epoch: 5| Step: 1
Training loss: 2.2715296745300293
Validation loss: 2.0241332004467645

Epoch: 5| Step: 2
Training loss: 2.355768918991089
Validation loss: 2.040584812561671

Epoch: 5| Step: 3
Training loss: 2.4120166301727295
Validation loss: 2.039715215563774

Epoch: 5| Step: 4
Training loss: 1.8007562160491943
Validation loss: 2.050346021850904

Epoch: 5| Step: 5
Training loss: 2.295476198196411
Validation loss: 2.0572058955828347

Epoch: 5| Step: 6
Training loss: 2.0271482467651367
Validation loss: 2.065003683169683

Epoch: 5| Step: 7
Training loss: 2.0616860389709473
Validation loss: 2.0626676430304847

Epoch: 5| Step: 8
Training loss: 2.1772263050079346
Validation loss: 2.0601105789343515

Epoch: 5| Step: 9
Training loss: 2.0721728801727295
Validation loss: 2.0609032412370047

Epoch: 5| Step: 10
Training loss: 2.4756646156311035
Validation loss: 2.0614806761344275

Epoch: 5| Step: 11
Training loss: 3.0010275840759277
Validation loss: 2.0598637461662292

Epoch: 101| Step: 0
Training loss: 2.0873820781707764
Validation loss: 2.054712325334549

Epoch: 5| Step: 1
Training loss: 1.9671504497528076
Validation loss: 2.0398857643206916

Epoch: 5| Step: 2
Training loss: 2.180729389190674
Validation loss: 2.031672795613607

Epoch: 5| Step: 3
Training loss: 2.5948104858398438
Validation loss: 2.0296299854914346

Epoch: 5| Step: 4
Training loss: 1.545355200767517
Validation loss: 2.0296442210674286

Epoch: 5| Step: 5
Training loss: 2.199017286300659
Validation loss: 2.026463747024536

Epoch: 5| Step: 6
Training loss: 2.0232319831848145
Validation loss: 2.0265228847662606

Epoch: 5| Step: 7
Training loss: 2.066143751144409
Validation loss: 2.0389411648114524

Epoch: 5| Step: 8
Training loss: 2.386340618133545
Validation loss: 2.0267063975334167

Epoch: 5| Step: 9
Training loss: 2.3698506355285645
Validation loss: 2.0402431041002274

Epoch: 5| Step: 10
Training loss: 2.3814549446105957
Validation loss: 2.039769152800242

Epoch: 5| Step: 11
Training loss: 2.9718174934387207
Validation loss: 2.034502238035202

Epoch: 102| Step: 0
Training loss: 2.0274298191070557
Validation loss: 2.0316689858833947

Epoch: 5| Step: 1
Training loss: 2.4315695762634277
Validation loss: 2.0365374783674874

Epoch: 5| Step: 2
Training loss: 1.6038999557495117
Validation loss: 2.0358784049749374

Epoch: 5| Step: 3
Training loss: 2.197330951690674
Validation loss: 2.0300312091906867

Epoch: 5| Step: 4
Training loss: 1.9056535959243774
Validation loss: 2.044668028752009

Epoch: 5| Step: 5
Training loss: 1.9395835399627686
Validation loss: 2.037344699104627

Epoch: 5| Step: 6
Training loss: 2.566434383392334
Validation loss: 2.04057285686334

Epoch: 5| Step: 7
Training loss: 2.2175509929656982
Validation loss: 2.0404477566480637

Epoch: 5| Step: 8
Training loss: 2.562711238861084
Validation loss: 2.0296093970537186

Epoch: 5| Step: 9
Training loss: 2.5188980102539062
Validation loss: 2.0256448537111282

Epoch: 5| Step: 10
Training loss: 1.9881582260131836
Validation loss: 2.0369157642126083

Epoch: 5| Step: 11
Training loss: 2.0942816734313965
Validation loss: 2.028040811419487

Epoch: 103| Step: 0
Training loss: 2.091522693634033
Validation loss: 2.0368283291657767

Epoch: 5| Step: 1
Training loss: 2.583958148956299
Validation loss: 2.0464855333169303

Epoch: 5| Step: 2
Training loss: 2.0272433757781982
Validation loss: 2.062646081050237

Epoch: 5| Step: 3
Training loss: 2.4576878547668457
Validation loss: 2.0815119594335556

Epoch: 5| Step: 4
Training loss: 1.9403438568115234
Validation loss: 2.080132156610489

Epoch: 5| Step: 5
Training loss: 1.997841477394104
Validation loss: 2.0741624385118484

Epoch: 5| Step: 6
Training loss: 2.2051568031311035
Validation loss: 2.068268353740374

Epoch: 5| Step: 7
Training loss: 1.8443924188613892
Validation loss: 2.0615505973498025

Epoch: 5| Step: 8
Training loss: 2.357689380645752
Validation loss: 2.0574626127878823

Epoch: 5| Step: 9
Training loss: 2.8623857498168945
Validation loss: 2.0466303328673043

Epoch: 5| Step: 10
Training loss: 1.9021409749984741
Validation loss: 2.0293065309524536

Epoch: 5| Step: 11
Training loss: 2.027134656906128
Validation loss: 2.0141847729682922

Epoch: 104| Step: 0
Training loss: 2.067473888397217
Validation loss: 2.014228790998459

Epoch: 5| Step: 1
Training loss: 2.0863289833068848
Validation loss: 2.0259887476762137

Epoch: 5| Step: 2
Training loss: 2.729912281036377
Validation loss: 2.029881631334623

Epoch: 5| Step: 3
Training loss: 1.9473539590835571
Validation loss: 2.0312582651774087

Epoch: 5| Step: 4
Training loss: 2.5336079597473145
Validation loss: 2.0298562298218408

Epoch: 5| Step: 5
Training loss: 2.7907989025115967
Validation loss: 2.0302866945664086

Epoch: 5| Step: 6
Training loss: 1.8248519897460938
Validation loss: 2.035921727617582

Epoch: 5| Step: 7
Training loss: 2.0005385875701904
Validation loss: 2.0334662149349847

Epoch: 5| Step: 8
Training loss: 2.0446677207946777
Validation loss: 2.0314467499653497

Epoch: 5| Step: 9
Training loss: 2.0427279472351074
Validation loss: 2.033585245410601

Epoch: 5| Step: 10
Training loss: 2.2146522998809814
Validation loss: 2.028302326798439

Epoch: 5| Step: 11
Training loss: 1.349898099899292
Validation loss: 2.0246120442946753

Epoch: 105| Step: 0
Training loss: 2.3176631927490234
Validation loss: 2.0208818465471268

Epoch: 5| Step: 1
Training loss: 2.1266262531280518
Validation loss: 2.0222917894522348

Epoch: 5| Step: 2
Training loss: 2.3278746604919434
Validation loss: 2.0408134212096534

Epoch: 5| Step: 3
Training loss: 2.285712480545044
Validation loss: 2.0369106332461038

Epoch: 5| Step: 4
Training loss: 1.8603448867797852
Validation loss: 2.0386787553628287

Epoch: 5| Step: 5
Training loss: 2.3447413444519043
Validation loss: 2.049588476618131

Epoch: 5| Step: 6
Training loss: 1.485803246498108
Validation loss: 2.0490770737330117

Epoch: 5| Step: 7
Training loss: 2.112941265106201
Validation loss: 2.0576173116763434

Epoch: 5| Step: 8
Training loss: 1.9915993213653564
Validation loss: 2.0559927026430764

Epoch: 5| Step: 9
Training loss: 2.4532806873321533
Validation loss: 2.0653895835081735

Epoch: 5| Step: 10
Training loss: 2.677344799041748
Validation loss: 2.0675730407238007

Epoch: 5| Step: 11
Training loss: 1.8731099367141724
Validation loss: 2.0716910312573114

Epoch: 106| Step: 0
Training loss: 2.3904266357421875
Validation loss: 2.0580854018529258

Epoch: 5| Step: 1
Training loss: 2.0386712551116943
Validation loss: 2.0565083026885986

Epoch: 5| Step: 2
Training loss: 2.2120766639709473
Validation loss: 2.0478757172822952

Epoch: 5| Step: 3
Training loss: 1.465498924255371
Validation loss: 2.034751147031784

Epoch: 5| Step: 4
Training loss: 2.1512722969055176
Validation loss: 2.0268640915552774

Epoch: 5| Step: 5
Training loss: 1.8907989263534546
Validation loss: 2.0268913308779397

Epoch: 5| Step: 6
Training loss: 2.338925838470459
Validation loss: 2.0337045192718506

Epoch: 5| Step: 7
Training loss: 2.436061143875122
Validation loss: 2.031546006600062

Epoch: 5| Step: 8
Training loss: 2.212923526763916
Validation loss: 2.034656231602033

Epoch: 5| Step: 9
Training loss: 1.9750831127166748
Validation loss: 2.0329413264989853

Epoch: 5| Step: 10
Training loss: 2.6717820167541504
Validation loss: 2.0334500720103583

Epoch: 5| Step: 11
Training loss: 3.685420036315918
Validation loss: 2.0252457559108734

Epoch: 107| Step: 0
Training loss: 2.184345245361328
Validation loss: 2.033513049284617

Epoch: 5| Step: 1
Training loss: 2.4429004192352295
Validation loss: 2.0339648127555847

Epoch: 5| Step: 2
Training loss: 2.2624635696411133
Validation loss: 2.0357384085655212

Epoch: 5| Step: 3
Training loss: 2.54168438911438
Validation loss: 2.039785881837209

Epoch: 5| Step: 4
Training loss: 2.4364047050476074
Validation loss: 2.042654186487198

Epoch: 5| Step: 5
Training loss: 1.4494776725769043
Validation loss: 2.0407601694266

Epoch: 5| Step: 6
Training loss: 2.0704894065856934
Validation loss: 2.0579172472159066

Epoch: 5| Step: 7
Training loss: 2.0979442596435547
Validation loss: 2.0634078880151114

Epoch: 5| Step: 8
Training loss: 2.3692047595977783
Validation loss: 2.0801543295383453

Epoch: 5| Step: 9
Training loss: 1.8659168481826782
Validation loss: 2.0910724649826684

Epoch: 5| Step: 10
Training loss: 2.0151989459991455
Validation loss: 2.0824881543715796

Epoch: 5| Step: 11
Training loss: 2.147897720336914
Validation loss: 2.085374727845192

Epoch: 108| Step: 0
Training loss: 2.3054184913635254
Validation loss: 2.073161393404007

Epoch: 5| Step: 1
Training loss: 1.715291976928711
Validation loss: 2.0678338557481766

Epoch: 5| Step: 2
Training loss: 2.562540054321289
Validation loss: 2.04815507431825

Epoch: 5| Step: 3
Training loss: 2.0470950603485107
Validation loss: 2.046243667602539

Epoch: 5| Step: 4
Training loss: 2.5866775512695312
Validation loss: 2.0416927685340247

Epoch: 5| Step: 5
Training loss: 1.6890037059783936
Validation loss: 2.0452905893325806

Epoch: 5| Step: 6
Training loss: 1.6415679454803467
Validation loss: 2.045863628387451

Epoch: 5| Step: 7
Training loss: 2.564221143722534
Validation loss: 2.043047229448954

Epoch: 5| Step: 8
Training loss: 2.5206828117370605
Validation loss: 2.039727265636126

Epoch: 5| Step: 9
Training loss: 2.0329785346984863
Validation loss: 2.036908730864525

Epoch: 5| Step: 10
Training loss: 2.2615966796875
Validation loss: 2.0348891218503318

Epoch: 5| Step: 11
Training loss: 2.7326951026916504
Validation loss: 2.036472588777542

Epoch: 109| Step: 0
Training loss: 1.5689815282821655
Validation loss: 2.035823533932368

Epoch: 5| Step: 1
Training loss: 2.5033905506134033
Validation loss: 2.03398605187734

Epoch: 5| Step: 2
Training loss: 1.8297233581542969
Validation loss: 2.0413150588671365

Epoch: 5| Step: 3
Training loss: 1.6543290615081787
Validation loss: 2.0418169597784677

Epoch: 5| Step: 4
Training loss: 2.129274368286133
Validation loss: 2.0564311345418296

Epoch: 5| Step: 5
Training loss: 1.8706506490707397
Validation loss: 2.056309382120768

Epoch: 5| Step: 6
Training loss: 2.0787129402160645
Validation loss: 2.057181254029274

Epoch: 5| Step: 7
Training loss: 2.525587320327759
Validation loss: 2.056310459971428

Epoch: 5| Step: 8
Training loss: 2.3590359687805176
Validation loss: 2.0796967844168344

Epoch: 5| Step: 9
Training loss: 2.6055006980895996
Validation loss: 2.0665076474348703

Epoch: 5| Step: 10
Training loss: 2.7911128997802734
Validation loss: 2.0782020340363183

Epoch: 5| Step: 11
Training loss: 1.6317261457443237
Validation loss: 2.0782911429802575

Epoch: 110| Step: 0
Training loss: 2.2340376377105713
Validation loss: 2.0660771131515503

Epoch: 5| Step: 1
Training loss: 1.9428513050079346
Validation loss: 2.053835853934288

Epoch: 5| Step: 2
Training loss: 1.8767549991607666
Validation loss: 2.045842240254084

Epoch: 5| Step: 3
Training loss: 2.337125062942505
Validation loss: 2.031597375869751

Epoch: 5| Step: 4
Training loss: 2.170815944671631
Validation loss: 2.029833401242892

Epoch: 5| Step: 5
Training loss: 2.365618944168091
Validation loss: 2.0328224897384644

Epoch: 5| Step: 6
Training loss: 1.541593313217163
Validation loss: 2.032895967364311

Epoch: 5| Step: 7
Training loss: 2.167201519012451
Validation loss: 2.0324889918168387

Epoch: 5| Step: 8
Training loss: 2.153542995452881
Validation loss: 2.028535932302475

Epoch: 5| Step: 9
Training loss: 2.6223742961883545
Validation loss: 2.034379626313845

Epoch: 5| Step: 10
Training loss: 2.471768856048584
Validation loss: 2.0412800212701163

Epoch: 5| Step: 11
Training loss: 2.6466307640075684
Validation loss: 2.0360307842493057

Epoch: 111| Step: 0
Training loss: 2.1741085052490234
Validation loss: 2.03093251089255

Epoch: 5| Step: 1
Training loss: 2.073054790496826
Validation loss: 2.0299831430117288

Epoch: 5| Step: 2
Training loss: 2.085392713546753
Validation loss: 2.028164893388748

Epoch: 5| Step: 3
Training loss: 2.128469944000244
Validation loss: 2.0323949803908667

Epoch: 5| Step: 4
Training loss: 2.062697649002075
Validation loss: 2.0395971536636353

Epoch: 5| Step: 5
Training loss: 2.2618625164031982
Validation loss: 2.033222039540609

Epoch: 5| Step: 6
Training loss: 2.179619789123535
Validation loss: 2.0246515721082687

Epoch: 5| Step: 7
Training loss: 2.1092288494110107
Validation loss: 2.0383974065383277

Epoch: 5| Step: 8
Training loss: 2.6648354530334473
Validation loss: 2.036762297153473

Epoch: 5| Step: 9
Training loss: 1.9630954265594482
Validation loss: 2.032812848687172

Epoch: 5| Step: 10
Training loss: 2.4840779304504395
Validation loss: 2.0310367792844772

Epoch: 5| Step: 11
Training loss: 0.9561483263969421
Validation loss: 2.042108873526255

Epoch: 112| Step: 0
Training loss: 2.5531983375549316
Validation loss: 2.037138983607292

Epoch: 5| Step: 1
Training loss: 2.2463457584381104
Validation loss: 2.035982236266136

Epoch: 5| Step: 2
Training loss: 2.291532516479492
Validation loss: 2.0301971584558487

Epoch: 5| Step: 3
Training loss: 2.001077890396118
Validation loss: 2.037410631775856

Epoch: 5| Step: 4
Training loss: 2.240621328353882
Validation loss: 2.032624453306198

Epoch: 5| Step: 5
Training loss: 2.7826600074768066
Validation loss: 2.033322880665461

Epoch: 5| Step: 6
Training loss: 1.4129632711410522
Validation loss: 2.0362937996784845

Epoch: 5| Step: 7
Training loss: 2.236443042755127
Validation loss: 2.029198373357455

Epoch: 5| Step: 8
Training loss: 2.293748617172241
Validation loss: 2.0316564490397773

Epoch: 5| Step: 9
Training loss: 1.9666492938995361
Validation loss: 2.023859644929568

Epoch: 5| Step: 10
Training loss: 1.9869508743286133
Validation loss: 2.0329154481490455

Epoch: 5| Step: 11
Training loss: 0.7471826076507568
Validation loss: 2.0135164658228555

Epoch: 113| Step: 0
Training loss: 2.2878565788269043
Validation loss: 2.0266093214352927

Epoch: 5| Step: 1
Training loss: 2.0133419036865234
Validation loss: 2.0274237543344498

Epoch: 5| Step: 2
Training loss: 2.175647735595703
Validation loss: 2.0247353365023932

Epoch: 5| Step: 3
Training loss: 2.4291045665740967
Validation loss: 2.0215811083714166

Epoch: 5| Step: 4
Training loss: 2.308758020401001
Validation loss: 2.0296589930852256

Epoch: 5| Step: 5
Training loss: 1.8314930200576782
Validation loss: 2.033153712749481

Epoch: 5| Step: 6
Training loss: 2.2377817630767822
Validation loss: 2.0375822484493256

Epoch: 5| Step: 7
Training loss: 1.8042856454849243
Validation loss: 2.029459978143374

Epoch: 5| Step: 8
Training loss: 2.2301700115203857
Validation loss: 2.0356836020946503

Epoch: 5| Step: 9
Training loss: 2.0638108253479004
Validation loss: 2.036312406261762

Epoch: 5| Step: 10
Training loss: 2.4104104042053223
Validation loss: 2.042342414458593

Epoch: 5| Step: 11
Training loss: 1.3593825101852417
Validation loss: 2.025716339548429

Epoch: 114| Step: 0
Training loss: 2.0649962425231934
Validation loss: 2.033832664291064

Epoch: 5| Step: 1
Training loss: 1.8536685705184937
Validation loss: 2.027081623673439

Epoch: 5| Step: 2
Training loss: 1.7869226932525635
Validation loss: 2.025876209139824

Epoch: 5| Step: 3
Training loss: 2.3274288177490234
Validation loss: 2.030909756819407

Epoch: 5| Step: 4
Training loss: 2.330808639526367
Validation loss: 2.0256976584593454

Epoch: 5| Step: 5
Training loss: 2.3953871726989746
Validation loss: 2.0287081400553384

Epoch: 5| Step: 6
Training loss: 2.011751413345337
Validation loss: 2.028289477030436

Epoch: 5| Step: 7
Training loss: 2.762000322341919
Validation loss: 2.041225403547287

Epoch: 5| Step: 8
Training loss: 1.8415210247039795
Validation loss: 2.0398737440506616

Epoch: 5| Step: 9
Training loss: 2.1887192726135254
Validation loss: 2.0393025626738868

Epoch: 5| Step: 10
Training loss: 1.9737968444824219
Validation loss: 2.0446134557326636

Epoch: 5| Step: 11
Training loss: 2.592188835144043
Validation loss: 2.052332724134127

Epoch: 115| Step: 0
Training loss: 2.329211950302124
Validation loss: 2.0493010928233466

Epoch: 5| Step: 1
Training loss: 2.280879259109497
Validation loss: 2.048925225933393

Epoch: 5| Step: 2
Training loss: 2.1501166820526123
Validation loss: 2.027682994802793

Epoch: 5| Step: 3
Training loss: 2.085439920425415
Validation loss: 2.019233579436938

Epoch: 5| Step: 4
Training loss: 2.333479166030884
Validation loss: 2.0138617704312005

Epoch: 5| Step: 5
Training loss: 2.3597826957702637
Validation loss: 2.0111228227615356

Epoch: 5| Step: 6
Training loss: 2.0339927673339844
Validation loss: 2.019892821709315

Epoch: 5| Step: 7
Training loss: 1.96616530418396
Validation loss: 2.0270641644795737

Epoch: 5| Step: 8
Training loss: 2.019524097442627
Validation loss: 2.0231253802776337

Epoch: 5| Step: 9
Training loss: 1.922234296798706
Validation loss: 2.025796656807264

Epoch: 5| Step: 10
Training loss: 2.3977251052856445
Validation loss: 2.024092505375544

Epoch: 5| Step: 11
Training loss: 2.2833964824676514
Validation loss: 2.0171555330355964

Epoch: 116| Step: 0
Training loss: 2.103883743286133
Validation loss: 2.0179386536280313

Epoch: 5| Step: 1
Training loss: 2.571220636367798
Validation loss: 2.022365594903628

Epoch: 5| Step: 2
Training loss: 2.520909070968628
Validation loss: 2.0147398312886557

Epoch: 5| Step: 3
Training loss: 1.8981027603149414
Validation loss: 2.0157450834910073

Epoch: 5| Step: 4
Training loss: 2.37471079826355
Validation loss: 2.012332166234652

Epoch: 5| Step: 5
Training loss: 2.0325207710266113
Validation loss: 2.0112479279438653

Epoch: 5| Step: 6
Training loss: 1.9403178691864014
Validation loss: 2.0177266697088876

Epoch: 5| Step: 7
Training loss: 1.6028263568878174
Validation loss: 2.025465190410614

Epoch: 5| Step: 8
Training loss: 2.152437448501587
Validation loss: 2.035740002989769

Epoch: 5| Step: 9
Training loss: 2.1139883995056152
Validation loss: 2.0304433753093085

Epoch: 5| Step: 10
Training loss: 2.0818352699279785
Validation loss: 2.0325410713752112

Epoch: 5| Step: 11
Training loss: 3.282153606414795
Validation loss: 2.0445848604043326

Epoch: 117| Step: 0
Training loss: 1.9151090383529663
Validation loss: 2.065843457976977

Epoch: 5| Step: 1
Training loss: 1.8111753463745117
Validation loss: 2.060507054130236

Epoch: 5| Step: 2
Training loss: 2.018587589263916
Validation loss: 2.097181479136149

Epoch: 5| Step: 3
Training loss: 2.498872995376587
Validation loss: 2.1047864655653634

Epoch: 5| Step: 4
Training loss: 2.694000244140625
Validation loss: 2.09680837392807

Epoch: 5| Step: 5
Training loss: 2.2273852825164795
Validation loss: 2.0723711947600045

Epoch: 5| Step: 6
Training loss: 1.5340315103530884
Validation loss: 2.058486814300219

Epoch: 5| Step: 7
Training loss: 2.678915500640869
Validation loss: 2.041363616784414

Epoch: 5| Step: 8
Training loss: 2.571300745010376
Validation loss: 2.0150416245063147

Epoch: 5| Step: 9
Training loss: 2.0322673320770264
Validation loss: 2.0107597410678864

Epoch: 5| Step: 10
Training loss: 2.2274625301361084
Validation loss: 2.0096565981705985

Epoch: 5| Step: 11
Training loss: 2.065169334411621
Validation loss: 2.024348964293798

Epoch: 118| Step: 0
Training loss: 2.8077216148376465
Validation loss: 2.0305729707082114

Epoch: 5| Step: 1
Training loss: 1.590166449546814
Validation loss: 2.0385524332523346

Epoch: 5| Step: 2
Training loss: 1.7498430013656616
Validation loss: 2.0395759592453637

Epoch: 5| Step: 3
Training loss: 1.855476975440979
Validation loss: 2.040380224585533

Epoch: 5| Step: 4
Training loss: 2.0369460582733154
Validation loss: 2.041857490936915

Epoch: 5| Step: 5
Training loss: 1.8114745616912842
Validation loss: 2.045922666788101

Epoch: 5| Step: 6
Training loss: 2.5416879653930664
Validation loss: 2.0406793703635535

Epoch: 5| Step: 7
Training loss: 2.5341804027557373
Validation loss: 2.042730758587519

Epoch: 5| Step: 8
Training loss: 2.9163615703582764
Validation loss: 2.0406974454720817

Epoch: 5| Step: 9
Training loss: 2.21451735496521
Validation loss: 2.035229762395223

Epoch: 5| Step: 10
Training loss: 2.269232749938965
Validation loss: 2.03353151679039

Epoch: 5| Step: 11
Training loss: 1.4332749843597412
Validation loss: 2.025170927246412

Epoch: 119| Step: 0
Training loss: 2.4866459369659424
Validation loss: 2.0253371795018515

Epoch: 5| Step: 1
Training loss: 2.424236297607422
Validation loss: 2.0225349068641663

Epoch: 5| Step: 2
Training loss: 2.0745179653167725
Validation loss: 2.0118992626667023

Epoch: 5| Step: 3
Training loss: 2.4109179973602295
Validation loss: 2.012601618965467

Epoch: 5| Step: 4
Training loss: 2.2369213104248047
Validation loss: 2.012768422563871

Epoch: 5| Step: 5
Training loss: 2.070446014404297
Validation loss: 2.006342425942421

Epoch: 5| Step: 6
Training loss: 1.8852695226669312
Validation loss: 2.011211469769478

Epoch: 5| Step: 7
Training loss: 2.2429826259613037
Validation loss: 2.0139868209759393

Epoch: 5| Step: 8
Training loss: 2.271672487258911
Validation loss: 2.0201938350995383

Epoch: 5| Step: 9
Training loss: 1.6824071407318115
Validation loss: 2.0257979879776635

Epoch: 5| Step: 10
Training loss: 1.9550988674163818
Validation loss: 2.025677353143692

Epoch: 5| Step: 11
Training loss: 2.2191672325134277
Validation loss: 2.0269684145847955

Epoch: 120| Step: 0
Training loss: 1.704460859298706
Validation loss: 2.0346964399019876

Epoch: 5| Step: 1
Training loss: 2.585292100906372
Validation loss: 2.030804326136907

Epoch: 5| Step: 2
Training loss: 2.049773931503296
Validation loss: 2.0274321834246316

Epoch: 5| Step: 3
Training loss: 2.1175589561462402
Validation loss: 2.043137098352114

Epoch: 5| Step: 4
Training loss: 2.306901693344116
Validation loss: 2.0315510829289756

Epoch: 5| Step: 5
Training loss: 2.0798749923706055
Validation loss: 2.0459467818339667

Epoch: 5| Step: 6
Training loss: 2.545860767364502
Validation loss: 2.0446680833896003

Epoch: 5| Step: 7
Training loss: 1.978672742843628
Validation loss: 2.037760799129804

Epoch: 5| Step: 8
Training loss: 2.0640523433685303
Validation loss: 2.0408184627691903

Epoch: 5| Step: 9
Training loss: 2.472907304763794
Validation loss: 2.0256693263848624

Epoch: 5| Step: 10
Training loss: 1.664594054222107
Validation loss: 2.036655197540919

Epoch: 5| Step: 11
Training loss: 2.459880828857422
Validation loss: 2.027391016483307

Epoch: 121| Step: 0
Training loss: 1.284984827041626
Validation loss: 2.0307749013106027

Epoch: 5| Step: 1
Training loss: 1.8096107244491577
Validation loss: 2.022222970922788

Epoch: 5| Step: 2
Training loss: 3.073582172393799
Validation loss: 2.0180966556072235

Epoch: 5| Step: 3
Training loss: 2.3963851928710938
Validation loss: 2.022494927048683

Epoch: 5| Step: 4
Training loss: 2.0078861713409424
Validation loss: 2.022451932231585

Epoch: 5| Step: 5
Training loss: 2.211808681488037
Validation loss: 2.026550938685735

Epoch: 5| Step: 6
Training loss: 2.3996310234069824
Validation loss: 2.0254248678684235

Epoch: 5| Step: 7
Training loss: 2.1944050788879395
Validation loss: 2.0307055711746216

Epoch: 5| Step: 8
Training loss: 2.3525609970092773
Validation loss: 2.0309015264113746

Epoch: 5| Step: 9
Training loss: 1.7523835897445679
Validation loss: 2.0203604847192764

Epoch: 5| Step: 10
Training loss: 2.351762056350708
Validation loss: 2.0313558081785836

Epoch: 5| Step: 11
Training loss: 1.1426137685775757
Validation loss: 2.0252961913744607

Epoch: 122| Step: 0
Training loss: 2.4058220386505127
Validation loss: 2.0320683817068734

Epoch: 5| Step: 1
Training loss: 2.6729283332824707
Validation loss: 2.023312970995903

Epoch: 5| Step: 2
Training loss: 2.1627016067504883
Validation loss: 2.019139309724172

Epoch: 5| Step: 3
Training loss: 1.6787941455841064
Validation loss: 2.0254978785912194

Epoch: 5| Step: 4
Training loss: 2.172450304031372
Validation loss: 2.0228446473677955

Epoch: 5| Step: 5
Training loss: 1.9829280376434326
Validation loss: 2.0140181432167688

Epoch: 5| Step: 6
Training loss: 2.221174716949463
Validation loss: 2.011953348914782

Epoch: 5| Step: 7
Training loss: 2.399460554122925
Validation loss: 2.0160574465990067

Epoch: 5| Step: 8
Training loss: 1.5200586318969727
Validation loss: 2.0108880698680878

Epoch: 5| Step: 9
Training loss: 2.104869842529297
Validation loss: 2.0219593942165375

Epoch: 5| Step: 10
Training loss: 2.2018465995788574
Validation loss: 2.023373226324717

Epoch: 5| Step: 11
Training loss: 2.581820487976074
Validation loss: 2.0314185371001563

Epoch: 123| Step: 0
Training loss: 1.9317474365234375
Validation loss: 2.032764663298925

Epoch: 5| Step: 1
Training loss: 2.238988161087036
Validation loss: 2.0510015338659286

Epoch: 5| Step: 2
Training loss: 1.7841583490371704
Validation loss: 2.0473292768001556

Epoch: 5| Step: 3
Training loss: 1.5570299625396729
Validation loss: 2.059183826049169

Epoch: 5| Step: 4
Training loss: 2.584550142288208
Validation loss: 2.0623835076888404

Epoch: 5| Step: 5
Training loss: 2.03686261177063
Validation loss: 2.0781417985757193

Epoch: 5| Step: 6
Training loss: 2.7468154430389404
Validation loss: 2.0897911339998245

Epoch: 5| Step: 7
Training loss: 2.1317687034606934
Validation loss: 2.0833269308010736

Epoch: 5| Step: 8
Training loss: 2.1840615272521973
Validation loss: 2.0738906065622964

Epoch: 5| Step: 9
Training loss: 2.1756815910339355
Validation loss: 2.0834084351857505

Epoch: 5| Step: 10
Training loss: 2.5064196586608887
Validation loss: 2.062433580557505

Epoch: 5| Step: 11
Training loss: 2.408168077468872
Validation loss: 2.0577702820301056

Epoch: 124| Step: 0
Training loss: 2.180210828781128
Validation loss: 2.0343042562405267

Epoch: 5| Step: 1
Training loss: 2.045104503631592
Validation loss: 2.0206785202026367

Epoch: 5| Step: 2
Training loss: 2.1829476356506348
Validation loss: 2.0239142974217734

Epoch: 5| Step: 3
Training loss: 2.2126729488372803
Validation loss: 2.025695060690244

Epoch: 5| Step: 4
Training loss: 2.15520977973938
Validation loss: 2.03429584701856

Epoch: 5| Step: 5
Training loss: 2.5062599182128906
Validation loss: 2.042749360203743

Epoch: 5| Step: 6
Training loss: 2.400395631790161
Validation loss: 2.0522016833225885

Epoch: 5| Step: 7
Training loss: 1.9006798267364502
Validation loss: 2.050970738132795

Epoch: 5| Step: 8
Training loss: 2.0176608562469482
Validation loss: 2.0545928676923118

Epoch: 5| Step: 9
Training loss: 2.4937610626220703
Validation loss: 2.0658830205599465

Epoch: 5| Step: 10
Training loss: 2.371117353439331
Validation loss: 2.0643629829088845

Epoch: 5| Step: 11
Training loss: 1.266897201538086
Validation loss: 2.0643921196460724

Epoch: 125| Step: 0
Training loss: 2.5946245193481445
Validation loss: 2.0609859377145767

Epoch: 5| Step: 1
Training loss: 1.9033857583999634
Validation loss: 2.0574734210968018

Epoch: 5| Step: 2
Training loss: 2.264779567718506
Validation loss: 2.057493214805921

Epoch: 5| Step: 3
Training loss: 2.1567909717559814
Validation loss: 2.057612737019857

Epoch: 5| Step: 4
Training loss: 2.6112213134765625
Validation loss: 2.046485682328542

Epoch: 5| Step: 5
Training loss: 2.6504740715026855
Validation loss: 2.0468730479478836

Epoch: 5| Step: 6
Training loss: 1.6959097385406494
Validation loss: 2.044766843318939

Epoch: 5| Step: 7
Training loss: 2.484506368637085
Validation loss: 2.0405276964108148

Epoch: 5| Step: 8
Training loss: 1.8025505542755127
Validation loss: 2.0362866123517356

Epoch: 5| Step: 9
Training loss: 2.2533726692199707
Validation loss: 2.0345602681239447

Epoch: 5| Step: 10
Training loss: 1.9175828695297241
Validation loss: 2.036343291401863

Epoch: 5| Step: 11
Training loss: 2.7549257278442383
Validation loss: 2.0311259329319

Testing loss: 1.6807022866585273
