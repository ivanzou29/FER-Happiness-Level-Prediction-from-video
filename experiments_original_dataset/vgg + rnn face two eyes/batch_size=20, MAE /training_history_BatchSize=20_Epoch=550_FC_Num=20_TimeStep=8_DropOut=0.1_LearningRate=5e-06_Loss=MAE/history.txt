Epoch: 1| Step: 0
Training loss: 4.841370582580566
Validation loss: 5.285158395767212

Epoch: 5| Step: 1
Training loss: 4.2173380851745605
Validation loss: 5.283617575963338

Epoch: 5| Step: 2
Training loss: 5.610705375671387
Validation loss: 5.282105922698975

Epoch: 5| Step: 3
Training loss: 5.259241580963135
Validation loss: 5.280493179957072

Epoch: 5| Step: 4
Training loss: 5.828044891357422
Validation loss: 5.278898596763611

Epoch: 5| Step: 5
Training loss: 5.879995822906494
Validation loss: 5.277289847532908

Epoch: 5| Step: 6
Training loss: 5.909098148345947
Validation loss: 5.2756891051928205

Epoch: 5| Step: 7
Training loss: 5.152886390686035
Validation loss: 5.274099787076314

Epoch: 5| Step: 8
Training loss: 4.801467418670654
Validation loss: 5.27244617541631

Epoch: 5| Step: 9
Training loss: 6.168512344360352
Validation loss: 5.270797332127889

Epoch: 5| Step: 10
Training loss: 4.84257698059082
Validation loss: 5.269069790840149

Epoch: 5| Step: 11
Training loss: 6.827944755554199
Validation loss: 5.267346133788426

Epoch: 2| Step: 0
Training loss: 5.924263954162598
Validation loss: 5.265573779741923

Epoch: 5| Step: 1
Training loss: 4.650998115539551
Validation loss: 5.263721466064453

Epoch: 5| Step: 2
Training loss: 5.456055641174316
Validation loss: 5.261860589186351

Epoch: 5| Step: 3
Training loss: 4.720912456512451
Validation loss: 5.259862383206685

Epoch: 5| Step: 4
Training loss: 4.867199897766113
Validation loss: 5.2577473521232605

Epoch: 5| Step: 5
Training loss: 5.626601219177246
Validation loss: 5.255599995454152

Epoch: 5| Step: 6
Training loss: 5.264404296875
Validation loss: 5.253244459629059

Epoch: 5| Step: 7
Training loss: 5.374861240386963
Validation loss: 5.250927627086639

Epoch: 5| Step: 8
Training loss: 5.692723274230957
Validation loss: 5.248391270637512

Epoch: 5| Step: 9
Training loss: 5.670158863067627
Validation loss: 5.2456397612889605

Epoch: 5| Step: 10
Training loss: 5.132626056671143
Validation loss: 5.242913524309794

Epoch: 5| Step: 11
Training loss: 6.246026992797852
Validation loss: 5.239913662274678

Epoch: 3| Step: 0
Training loss: 6.016092777252197
Validation loss: 5.2368141412734985

Epoch: 5| Step: 1
Training loss: 5.105025768280029
Validation loss: 5.23351248105367

Epoch: 5| Step: 2
Training loss: 5.593243598937988
Validation loss: 5.229975700378418

Epoch: 5| Step: 3
Training loss: 5.686158657073975
Validation loss: 5.2261820038159685

Epoch: 5| Step: 4
Training loss: 4.9424872398376465
Validation loss: 5.222263713677724

Epoch: 5| Step: 5
Training loss: 4.70436954498291
Validation loss: 5.218146522839864

Epoch: 5| Step: 6
Training loss: 5.480790615081787
Validation loss: 5.213615735371907

Epoch: 5| Step: 7
Training loss: 5.0153303146362305
Validation loss: 5.209113498528798

Epoch: 5| Step: 8
Training loss: 5.594346046447754
Validation loss: 5.2043031851450605

Epoch: 5| Step: 9
Training loss: 5.8047709465026855
Validation loss: 5.199214577674866

Epoch: 5| Step: 10
Training loss: 4.522900581359863
Validation loss: 5.193781117598216

Epoch: 5| Step: 11
Training loss: 3.746885299682617
Validation loss: 5.187887767950694

Epoch: 4| Step: 0
Training loss: 5.763673305511475
Validation loss: 5.18195104598999

Epoch: 5| Step: 1
Training loss: 5.978816509246826
Validation loss: 5.175454239050548

Epoch: 5| Step: 2
Training loss: 5.092706203460693
Validation loss: 5.168859879175822

Epoch: 5| Step: 3
Training loss: 5.62082576751709
Validation loss: 5.161690791447957

Epoch: 5| Step: 4
Training loss: 5.387162685394287
Validation loss: 5.154218713442485

Epoch: 5| Step: 5
Training loss: 4.816553592681885
Validation loss: 5.146342933177948

Epoch: 5| Step: 6
Training loss: 5.5606865882873535
Validation loss: 5.1378317674001055

Epoch: 5| Step: 7
Training loss: 5.276700019836426
Validation loss: 5.129119435946147

Epoch: 5| Step: 8
Training loss: 4.686164855957031
Validation loss: 5.11975101629893

Epoch: 5| Step: 9
Training loss: 4.869915008544922
Validation loss: 5.110519627730052

Epoch: 5| Step: 10
Training loss: 4.518056869506836
Validation loss: 5.100484748681386

Epoch: 5| Step: 11
Training loss: 4.27772855758667
Validation loss: 5.090405980745952

Epoch: 5| Step: 0
Training loss: 5.022028923034668
Validation loss: 5.079854806264241

Epoch: 5| Step: 1
Training loss: 5.94736909866333
Validation loss: 5.068960507710774

Epoch: 5| Step: 2
Training loss: 5.975058078765869
Validation loss: 5.057951112588246

Epoch: 5| Step: 3
Training loss: 4.9413580894470215
Validation loss: 5.046388765176137

Epoch: 5| Step: 4
Training loss: 4.357490539550781
Validation loss: 5.034368932247162

Epoch: 5| Step: 5
Training loss: 5.728156089782715
Validation loss: 5.023129224777222

Epoch: 5| Step: 6
Training loss: 4.6594696044921875
Validation loss: 5.011050979296367

Epoch: 5| Step: 7
Training loss: 4.922173500061035
Validation loss: 4.998724818229675

Epoch: 5| Step: 8
Training loss: 4.633608341217041
Validation loss: 4.986823002497355

Epoch: 5| Step: 9
Training loss: 5.387991905212402
Validation loss: 4.974710245927175

Epoch: 5| Step: 10
Training loss: 4.886895179748535
Validation loss: 4.962947964668274

Epoch: 5| Step: 11
Training loss: 3.3526716232299805
Validation loss: 4.951112190882365

Epoch: 6| Step: 0
Training loss: 5.066641330718994
Validation loss: 4.939666410287221

Epoch: 5| Step: 1
Training loss: 5.062897205352783
Validation loss: 4.92879847685496

Epoch: 5| Step: 2
Training loss: 6.432951927185059
Validation loss: 4.917614817619324

Epoch: 5| Step: 3
Training loss: 4.69705057144165
Validation loss: 4.907046794891357

Epoch: 5| Step: 4
Training loss: 5.152073383331299
Validation loss: 4.896525800228119

Epoch: 5| Step: 5
Training loss: 4.763064384460449
Validation loss: 4.8865587910016375

Epoch: 5| Step: 6
Training loss: 4.824998378753662
Validation loss: 4.875876764456431

Epoch: 5| Step: 7
Training loss: 5.761870384216309
Validation loss: 4.865910192330678

Epoch: 5| Step: 8
Training loss: 4.182224273681641
Validation loss: 4.855920692284902

Epoch: 5| Step: 9
Training loss: 4.459842205047607
Validation loss: 4.846485952536265

Epoch: 5| Step: 10
Training loss: 4.5823140144348145
Validation loss: 4.836970488230388

Epoch: 5| Step: 11
Training loss: 3.5083601474761963
Validation loss: 4.82800954580307

Epoch: 7| Step: 0
Training loss: 4.784881114959717
Validation loss: 4.818683207035065

Epoch: 5| Step: 1
Training loss: 4.892130374908447
Validation loss: 4.809457679589589

Epoch: 5| Step: 2
Training loss: 4.1799187660217285
Validation loss: 4.800574203332265

Epoch: 5| Step: 3
Training loss: 4.89949893951416
Validation loss: 4.791776518026988

Epoch: 5| Step: 4
Training loss: 5.575235366821289
Validation loss: 4.782867232958476

Epoch: 5| Step: 5
Training loss: 4.74849796295166
Validation loss: 4.774357656637828

Epoch: 5| Step: 6
Training loss: 4.845808982849121
Validation loss: 4.766204257806142

Epoch: 5| Step: 7
Training loss: 5.017024993896484
Validation loss: 4.75773823261261

Epoch: 5| Step: 8
Training loss: 4.708294868469238
Validation loss: 4.7498473127683

Epoch: 5| Step: 9
Training loss: 5.374103546142578
Validation loss: 4.741573989391327

Epoch: 5| Step: 10
Training loss: 4.644916534423828
Validation loss: 4.733863890171051

Epoch: 5| Step: 11
Training loss: 4.167141914367676
Validation loss: 4.726511538028717

Epoch: 8| Step: 0
Training loss: 5.648502349853516
Validation loss: 4.719344933827718

Epoch: 5| Step: 1
Training loss: 5.373229026794434
Validation loss: 4.712261786063512

Epoch: 5| Step: 2
Training loss: 4.600990295410156
Validation loss: 4.705435236295064

Epoch: 5| Step: 3
Training loss: 4.975356578826904
Validation loss: 4.698076168696086

Epoch: 5| Step: 4
Training loss: 4.3570237159729
Validation loss: 4.691327393054962

Epoch: 5| Step: 5
Training loss: 5.055665016174316
Validation loss: 4.684873859087626

Epoch: 5| Step: 6
Training loss: 4.07853364944458
Validation loss: 4.678119122982025

Epoch: 5| Step: 7
Training loss: 3.9725890159606934
Validation loss: 4.671930392583211

Epoch: 5| Step: 8
Training loss: 4.090263843536377
Validation loss: 4.665062506993611

Epoch: 5| Step: 9
Training loss: 5.1417012214660645
Validation loss: 4.658779799938202

Epoch: 5| Step: 10
Training loss: 5.407332420349121
Validation loss: 4.652674466371536

Epoch: 5| Step: 11
Training loss: 4.212034225463867
Validation loss: 4.646403233210246

Epoch: 9| Step: 0
Training loss: 4.931430339813232
Validation loss: 4.6407748858133955

Epoch: 5| Step: 1
Training loss: 4.870959281921387
Validation loss: 4.63482924302419

Epoch: 5| Step: 2
Training loss: 5.296300411224365
Validation loss: 4.6290150086085005

Epoch: 5| Step: 3
Training loss: 4.205548286437988
Validation loss: 4.622622241576512

Epoch: 5| Step: 4
Training loss: 4.9098005294799805
Validation loss: 4.616901159286499

Epoch: 5| Step: 5
Training loss: 4.1832475662231445
Validation loss: 4.6107354164123535

Epoch: 5| Step: 6
Training loss: 4.992762565612793
Validation loss: 4.605011363824208

Epoch: 5| Step: 7
Training loss: 4.729371070861816
Validation loss: 4.598769903182983

Epoch: 5| Step: 8
Training loss: 5.074682235717773
Validation loss: 4.592545390129089

Epoch: 5| Step: 9
Training loss: 3.461742401123047
Validation loss: 4.586652974287669

Epoch: 5| Step: 10
Training loss: 4.986461639404297
Validation loss: 4.580193797747294

Epoch: 5| Step: 11
Training loss: 5.566044330596924
Validation loss: 4.57351682583491

Epoch: 10| Step: 0
Training loss: 3.9028427600860596
Validation loss: 4.56720557808876

Epoch: 5| Step: 1
Training loss: 4.102713108062744
Validation loss: 4.560290336608887

Epoch: 5| Step: 2
Training loss: 4.464058876037598
Validation loss: 4.552826762199402

Epoch: 5| Step: 3
Training loss: 4.059201240539551
Validation loss: 4.5455271402994795

Epoch: 5| Step: 4
Training loss: 4.534916877746582
Validation loss: 4.537312388420105

Epoch: 5| Step: 5
Training loss: 4.935221195220947
Validation loss: 4.52935258547465

Epoch: 5| Step: 6
Training loss: 5.414670467376709
Validation loss: 4.522017886241277

Epoch: 5| Step: 7
Training loss: 4.361892223358154
Validation loss: 4.514678875605266

Epoch: 5| Step: 8
Training loss: 5.221991062164307
Validation loss: 4.507699191570282

Epoch: 5| Step: 9
Training loss: 5.0211029052734375
Validation loss: 4.500939706961314

Epoch: 5| Step: 10
Training loss: 5.056896209716797
Validation loss: 4.494498709837596

Epoch: 5| Step: 11
Training loss: 4.160442352294922
Validation loss: 4.4882123072942095

Epoch: 11| Step: 0
Training loss: 4.734572410583496
Validation loss: 4.481373687585195

Epoch: 5| Step: 1
Training loss: 4.019373416900635
Validation loss: 4.476395517587662

Epoch: 5| Step: 2
Training loss: 5.103964805603027
Validation loss: 4.4701966643333435

Epoch: 5| Step: 3
Training loss: 3.915045976638794
Validation loss: 4.463937997817993

Epoch: 5| Step: 4
Training loss: 3.5377895832061768
Validation loss: 4.457934747139613

Epoch: 5| Step: 5
Training loss: 5.8495965003967285
Validation loss: 4.451482216517131

Epoch: 5| Step: 6
Training loss: 5.09561824798584
Validation loss: 4.44527002175649

Epoch: 5| Step: 7
Training loss: 4.51300048828125
Validation loss: 4.439564327398936

Epoch: 5| Step: 8
Training loss: 4.304146766662598
Validation loss: 4.434054046869278

Epoch: 5| Step: 9
Training loss: 4.0378899574279785
Validation loss: 4.427908966938655

Epoch: 5| Step: 10
Training loss: 5.090909004211426
Validation loss: 4.421225825945537

Epoch: 5| Step: 11
Training loss: 4.601043701171875
Validation loss: 4.415541311105092

Epoch: 12| Step: 0
Training loss: 4.407883644104004
Validation loss: 4.409126083056132

Epoch: 5| Step: 1
Training loss: 5.47808313369751
Validation loss: 4.402994513511658

Epoch: 5| Step: 2
Training loss: 4.233737945556641
Validation loss: 4.397032459576924

Epoch: 5| Step: 3
Training loss: 3.70124888420105
Validation loss: 4.390758444865544

Epoch: 5| Step: 4
Training loss: 4.802143096923828
Validation loss: 4.384048134088516

Epoch: 5| Step: 5
Training loss: 4.382894515991211
Validation loss: 4.378198007742564

Epoch: 5| Step: 6
Training loss: 4.041187286376953
Validation loss: 4.3712514241536455

Epoch: 5| Step: 7
Training loss: 5.119187355041504
Validation loss: 4.36519913872083

Epoch: 5| Step: 8
Training loss: 4.496318817138672
Validation loss: 4.35872358083725

Epoch: 5| Step: 9
Training loss: 3.9116034507751465
Validation loss: 4.352453966935475

Epoch: 5| Step: 10
Training loss: 4.7693023681640625
Validation loss: 4.346711903810501

Epoch: 5| Step: 11
Training loss: 5.131502151489258
Validation loss: 4.340938846270244

Epoch: 13| Step: 0
Training loss: 4.111565113067627
Validation loss: 4.335241178671519

Epoch: 5| Step: 1
Training loss: 5.485570907592773
Validation loss: 4.329305628935496

Epoch: 5| Step: 2
Training loss: 4.465838432312012
Validation loss: 4.322932918866475

Epoch: 5| Step: 3
Training loss: 4.558701992034912
Validation loss: 4.317282617092133

Epoch: 5| Step: 4
Training loss: 3.7380104064941406
Validation loss: 4.31223017970721

Epoch: 5| Step: 5
Training loss: 5.005901336669922
Validation loss: 4.30660339196523

Epoch: 5| Step: 6
Training loss: 4.1354475021362305
Validation loss: 4.300311625003815

Epoch: 5| Step: 7
Training loss: 4.242830276489258
Validation loss: 4.293881217638652

Epoch: 5| Step: 8
Training loss: 4.386569023132324
Validation loss: 4.288220266501109

Epoch: 5| Step: 9
Training loss: 4.2646331787109375
Validation loss: 4.282429456710815

Epoch: 5| Step: 10
Training loss: 4.026301383972168
Validation loss: 4.276296993096669

Epoch: 5| Step: 11
Training loss: 6.052509307861328
Validation loss: 4.270537704229355

Epoch: 14| Step: 0
Training loss: 3.0627243518829346
Validation loss: 4.2643089691797895

Epoch: 5| Step: 1
Training loss: 5.465519905090332
Validation loss: 4.258000115553538

Epoch: 5| Step: 2
Training loss: 4.786959648132324
Validation loss: 4.252098550399144

Epoch: 5| Step: 3
Training loss: 3.511537551879883
Validation loss: 4.245652914047241

Epoch: 5| Step: 4
Training loss: 5.344464302062988
Validation loss: 4.239028682311376

Epoch: 5| Step: 5
Training loss: 4.742341041564941
Validation loss: 4.233118186394374

Epoch: 5| Step: 6
Training loss: 4.343894958496094
Validation loss: 4.226066033045451

Epoch: 5| Step: 7
Training loss: 4.535984992980957
Validation loss: 4.2191634476184845

Epoch: 5| Step: 8
Training loss: 4.8022356033325195
Validation loss: 4.213444163401921

Epoch: 5| Step: 9
Training loss: 4.527498722076416
Validation loss: 4.206473171710968

Epoch: 5| Step: 10
Training loss: 3.3144054412841797
Validation loss: 4.200144896904628

Epoch: 5| Step: 11
Training loss: 2.161808729171753
Validation loss: 4.19390669465065

Epoch: 15| Step: 0
Training loss: 4.227210521697998
Validation loss: 4.189414610465367

Epoch: 5| Step: 1
Training loss: 4.747854232788086
Validation loss: 4.184169640143712

Epoch: 5| Step: 2
Training loss: 4.124205589294434
Validation loss: 4.177568942308426

Epoch: 5| Step: 3
Training loss: 4.909941673278809
Validation loss: 4.170795689026515

Epoch: 5| Step: 4
Training loss: 4.4683356285095215
Validation loss: 4.165430158376694

Epoch: 5| Step: 5
Training loss: 3.716564178466797
Validation loss: 4.160297493139903

Epoch: 5| Step: 6
Training loss: 3.755507230758667
Validation loss: 4.154463787873586

Epoch: 5| Step: 7
Training loss: 4.169130802154541
Validation loss: 4.148800104856491

Epoch: 5| Step: 8
Training loss: 4.540396213531494
Validation loss: 4.1442485849062605

Epoch: 5| Step: 9
Training loss: 4.244194984436035
Validation loss: 4.138614435990651

Epoch: 5| Step: 10
Training loss: 4.792825698852539
Validation loss: 4.13282831509908

Epoch: 5| Step: 11
Training loss: 2.218888759613037
Validation loss: 4.128325521945953

Epoch: 16| Step: 0
Training loss: 4.749335289001465
Validation loss: 4.121642778317134

Epoch: 5| Step: 1
Training loss: 4.850208759307861
Validation loss: 4.117738286654155

Epoch: 5| Step: 2
Training loss: 4.497613430023193
Validation loss: 4.112172385056813

Epoch: 5| Step: 3
Training loss: 3.3839545249938965
Validation loss: 4.1072521309057874

Epoch: 5| Step: 4
Training loss: 3.338547945022583
Validation loss: 4.103395889202754

Epoch: 5| Step: 5
Training loss: 3.5839202404022217
Validation loss: 4.097635855277379

Epoch: 5| Step: 6
Training loss: 5.006777763366699
Validation loss: 4.091507116953532

Epoch: 5| Step: 7
Training loss: 3.8080685138702393
Validation loss: 4.08635135491689

Epoch: 5| Step: 8
Training loss: 4.425318241119385
Validation loss: 4.08166045943896

Epoch: 5| Step: 9
Training loss: 5.075957298278809
Validation loss: 4.077272603909175

Epoch: 5| Step: 10
Training loss: 3.8656973838806152
Validation loss: 4.071387996276219

Epoch: 5| Step: 11
Training loss: 4.465625286102295
Validation loss: 4.067160099744797

Epoch: 17| Step: 0
Training loss: 3.841090679168701
Validation loss: 4.064551333586375

Epoch: 5| Step: 1
Training loss: 4.065520763397217
Validation loss: 4.060640215873718

Epoch: 5| Step: 2
Training loss: 4.300570011138916
Validation loss: 4.053788393735886

Epoch: 5| Step: 3
Training loss: 4.774925708770752
Validation loss: 4.047568539778392

Epoch: 5| Step: 4
Training loss: 4.018685340881348
Validation loss: 4.044713666041692

Epoch: 5| Step: 5
Training loss: 4.55068826675415
Validation loss: 4.040491332610448

Epoch: 5| Step: 6
Training loss: 3.9903595447540283
Validation loss: 4.036150346199672

Epoch: 5| Step: 7
Training loss: 3.7339274883270264
Validation loss: 4.030021697282791

Epoch: 5| Step: 8
Training loss: 4.052821159362793
Validation loss: 4.024693667888641

Epoch: 5| Step: 9
Training loss: 4.341357231140137
Validation loss: 4.020358403523763

Epoch: 5| Step: 10
Training loss: 4.210052490234375
Validation loss: 4.016164233287175

Epoch: 5| Step: 11
Training loss: 4.921972751617432
Validation loss: 4.011956572532654

Epoch: 18| Step: 0
Training loss: 3.739215850830078
Validation loss: 4.005891819794972

Epoch: 5| Step: 1
Training loss: 3.424298048019409
Validation loss: 4.001548449198405

Epoch: 5| Step: 2
Training loss: 4.147436618804932
Validation loss: 3.9977453450361886

Epoch: 5| Step: 3
Training loss: 4.583600044250488
Validation loss: 3.9933225015799203

Epoch: 5| Step: 4
Training loss: 4.870068073272705
Validation loss: 3.9877586464087167

Epoch: 5| Step: 5
Training loss: 3.715108871459961
Validation loss: 3.9821767807006836

Epoch: 5| Step: 6
Training loss: 5.129681587219238
Validation loss: 3.977535237868627

Epoch: 5| Step: 7
Training loss: 4.233994960784912
Validation loss: 3.972299645344416

Epoch: 5| Step: 8
Training loss: 3.9383463859558105
Validation loss: 3.9667992889881134

Epoch: 5| Step: 9
Training loss: 3.8822391033172607
Validation loss: 3.9617000818252563

Epoch: 5| Step: 10
Training loss: 3.9194514751434326
Validation loss: 3.956387589375178

Epoch: 5| Step: 11
Training loss: 3.3281667232513428
Validation loss: 3.9515567322572074

Epoch: 19| Step: 0
Training loss: 2.941871166229248
Validation loss: 3.9474972983201346

Epoch: 5| Step: 1
Training loss: 3.500340223312378
Validation loss: 3.9421168069044747

Epoch: 5| Step: 2
Training loss: 4.437338829040527
Validation loss: 3.937554826339086

Epoch: 5| Step: 3
Training loss: 3.8985302448272705
Validation loss: 3.9326162238915763

Epoch: 5| Step: 4
Training loss: 4.701333045959473
Validation loss: 3.9281260073184967

Epoch: 5| Step: 5
Training loss: 4.176285266876221
Validation loss: 3.923014481862386

Epoch: 5| Step: 6
Training loss: 3.659435749053955
Validation loss: 3.918552209933599

Epoch: 5| Step: 7
Training loss: 4.331242084503174
Validation loss: 3.913689206043879

Epoch: 5| Step: 8
Training loss: 5.423083305358887
Validation loss: 3.9082151552041373

Epoch: 5| Step: 9
Training loss: 4.012008190155029
Validation loss: 3.9027518928050995

Epoch: 5| Step: 10
Training loss: 3.999934434890747
Validation loss: 3.897629121939341

Epoch: 5| Step: 11
Training loss: 2.595437526702881
Validation loss: 3.892413546641668

Epoch: 20| Step: 0
Training loss: 3.3981635570526123
Validation loss: 3.889451632897059

Epoch: 5| Step: 1
Training loss: 3.758406162261963
Validation loss: 3.8870460788408914

Epoch: 5| Step: 2
Training loss: 4.5886549949646
Validation loss: 3.882923722267151

Epoch: 5| Step: 3
Training loss: 5.079407215118408
Validation loss: 3.8768460353215537

Epoch: 5| Step: 4
Training loss: 4.155544757843018
Validation loss: 3.8716688652833304

Epoch: 5| Step: 5
Training loss: 4.486807346343994
Validation loss: 3.867628256479899

Epoch: 5| Step: 6
Training loss: 4.6789469718933105
Validation loss: 3.8620013097922006

Epoch: 5| Step: 7
Training loss: 4.153608798980713
Validation loss: 3.8568157156308494

Epoch: 5| Step: 8
Training loss: 4.643474102020264
Validation loss: 3.8506992757320404

Epoch: 5| Step: 9
Training loss: 2.6832070350646973
Validation loss: 3.845005879799525

Epoch: 5| Step: 10
Training loss: 3.0975985527038574
Validation loss: 3.8398578564325967

Epoch: 5| Step: 11
Training loss: 1.4205055236816406
Validation loss: 3.835709492365519

Epoch: 21| Step: 0
Training loss: 3.530054807662964
Validation loss: 3.8321977953116098

Epoch: 5| Step: 1
Training loss: 4.157177448272705
Validation loss: 3.829919159412384

Epoch: 5| Step: 2
Training loss: 4.2649760246276855
Validation loss: 3.822905649741491

Epoch: 5| Step: 3
Training loss: 3.5278453826904297
Validation loss: 3.816968639691671

Epoch: 5| Step: 4
Training loss: 4.806971549987793
Validation loss: 3.812933703263601

Epoch: 5| Step: 5
Training loss: 3.5773727893829346
Validation loss: 3.807969411214193

Epoch: 5| Step: 6
Training loss: 4.377018928527832
Validation loss: 3.8033737738927207

Epoch: 5| Step: 7
Training loss: 3.705512285232544
Validation loss: 3.7982035080591836

Epoch: 5| Step: 8
Training loss: 3.4857699871063232
Validation loss: 3.7939364115397134

Epoch: 5| Step: 9
Training loss: 4.047835350036621
Validation loss: 3.7884060740470886

Epoch: 5| Step: 10
Training loss: 4.192706108093262
Validation loss: 3.7844310899575553

Epoch: 5| Step: 11
Training loss: 3.603423833847046
Validation loss: 3.780535707871119

Epoch: 22| Step: 0
Training loss: 3.1328446865081787
Validation loss: 3.7754360338052115

Epoch: 5| Step: 1
Training loss: 4.037676811218262
Validation loss: 3.7717026472091675

Epoch: 5| Step: 2
Training loss: 3.6218254566192627
Validation loss: 3.767064561446508

Epoch: 5| Step: 3
Training loss: 4.306258678436279
Validation loss: 3.7622710963090262

Epoch: 5| Step: 4
Training loss: 3.807185649871826
Validation loss: 3.758013923962911

Epoch: 5| Step: 5
Training loss: 4.647691249847412
Validation loss: 3.7533637483914695

Epoch: 5| Step: 6
Training loss: 4.113336086273193
Validation loss: 3.7486566801865897

Epoch: 5| Step: 7
Training loss: 3.867504835128784
Validation loss: 3.7436886032422385

Epoch: 5| Step: 8
Training loss: 3.261706590652466
Validation loss: 3.7398625711599984

Epoch: 5| Step: 9
Training loss: 4.284766674041748
Validation loss: 3.7345825731754303

Epoch: 5| Step: 10
Training loss: 3.8224921226501465
Validation loss: 3.730615754922231

Epoch: 5| Step: 11
Training loss: 4.501534938812256
Validation loss: 3.7257903019587197

Epoch: 23| Step: 0
Training loss: 4.159049034118652
Validation loss: 3.721157819032669

Epoch: 5| Step: 1
Training loss: 3.787330150604248
Validation loss: 3.716320743163427

Epoch: 5| Step: 2
Training loss: 4.111785411834717
Validation loss: 3.7114557723204293

Epoch: 5| Step: 3
Training loss: 3.691096544265747
Validation loss: 3.7070411841074624

Epoch: 5| Step: 4
Training loss: 3.7610931396484375
Validation loss: 3.702638268470764

Epoch: 5| Step: 5
Training loss: 4.279824733734131
Validation loss: 3.6981506248315177

Epoch: 5| Step: 6
Training loss: 3.9620513916015625
Validation loss: 3.6934787829717

Epoch: 5| Step: 7
Training loss: 3.3951897621154785
Validation loss: 3.6882996459801993

Epoch: 5| Step: 8
Training loss: 3.7843775749206543
Validation loss: 3.6843837002913156

Epoch: 5| Step: 9
Training loss: 3.907508134841919
Validation loss: 3.680631438891093

Epoch: 5| Step: 10
Training loss: 3.705418109893799
Validation loss: 3.6749395032723746

Epoch: 5| Step: 11
Training loss: 3.447645664215088
Validation loss: 3.672599027554194

Epoch: 24| Step: 0
Training loss: 3.9084134101867676
Validation loss: 3.6672926545143127

Epoch: 5| Step: 1
Training loss: 4.042290687561035
Validation loss: 3.6631107727686563

Epoch: 5| Step: 2
Training loss: 3.648026943206787
Validation loss: 3.6576280295848846

Epoch: 5| Step: 3
Training loss: 3.1960058212280273
Validation loss: 3.653625955184301

Epoch: 5| Step: 4
Training loss: 3.077928066253662
Validation loss: 3.6501278479894004

Epoch: 5| Step: 5
Training loss: 4.598315238952637
Validation loss: 3.6443640291690826

Epoch: 5| Step: 6
Training loss: 3.245302677154541
Validation loss: 3.6387687027454376

Epoch: 5| Step: 7
Training loss: 3.5128960609436035
Validation loss: 3.635158101717631

Epoch: 5| Step: 8
Training loss: 3.850705623626709
Validation loss: 3.6303950349489846

Epoch: 5| Step: 9
Training loss: 4.041802406311035
Validation loss: 3.626425872246424

Epoch: 5| Step: 10
Training loss: 4.658984661102295
Validation loss: 3.621321032444636

Epoch: 5| Step: 11
Training loss: 4.308793067932129
Validation loss: 3.61610609292984

Epoch: 25| Step: 0
Training loss: 4.159313201904297
Validation loss: 3.61191933353742

Epoch: 5| Step: 1
Training loss: 3.430506944656372
Validation loss: 3.6073469718297324

Epoch: 5| Step: 2
Training loss: 2.773751974105835
Validation loss: 3.601766179005305

Epoch: 5| Step: 3
Training loss: 3.990025758743286
Validation loss: 3.5972038308779397

Epoch: 5| Step: 4
Training loss: 4.96808385848999
Validation loss: 3.5931373635927835

Epoch: 5| Step: 5
Training loss: 2.744237184524536
Validation loss: 3.586630254983902

Epoch: 5| Step: 6
Training loss: 3.249746799468994
Validation loss: 3.582841068506241

Epoch: 5| Step: 7
Training loss: 3.536886692047119
Validation loss: 3.5787315467993417

Epoch: 5| Step: 8
Training loss: 4.309905052185059
Validation loss: 3.5752246181170144

Epoch: 5| Step: 9
Training loss: 3.777026414871216
Validation loss: 3.5703423221906028

Epoch: 5| Step: 10
Training loss: 3.919628858566284
Validation loss: 3.5656795303026834

Epoch: 5| Step: 11
Training loss: 5.785109996795654
Validation loss: 3.559914747873942

Epoch: 26| Step: 0
Training loss: 3.4314918518066406
Validation loss: 3.555950810511907

Epoch: 5| Step: 1
Training loss: 3.5717945098876953
Validation loss: 3.55206698179245

Epoch: 5| Step: 2
Training loss: 3.1356465816497803
Validation loss: 3.545392652352651

Epoch: 5| Step: 3
Training loss: 3.8269317150115967
Validation loss: 3.5406367083390555

Epoch: 5| Step: 4
Training loss: 3.37849760055542
Validation loss: 3.5363778173923492

Epoch: 5| Step: 5
Training loss: 3.3326473236083984
Validation loss: 3.532766650120417

Epoch: 5| Step: 6
Training loss: 4.351654052734375
Validation loss: 3.528112222750982

Epoch: 5| Step: 7
Training loss: 3.9173121452331543
Validation loss: 3.5230311850706735

Epoch: 5| Step: 8
Training loss: 3.7773208618164062
Validation loss: 3.516864776611328

Epoch: 5| Step: 9
Training loss: 3.818087100982666
Validation loss: 3.512697001298269

Epoch: 5| Step: 10
Training loss: 4.600703239440918
Validation loss: 3.507947325706482

Epoch: 5| Step: 11
Training loss: 1.3567174673080444
Validation loss: 3.503110279639562

Epoch: 27| Step: 0
Training loss: 3.83777117729187
Validation loss: 3.498729129632314

Epoch: 5| Step: 1
Training loss: 3.403876543045044
Validation loss: 3.493615289529165

Epoch: 5| Step: 2
Training loss: 3.2426209449768066
Validation loss: 3.4891677101453147

Epoch: 5| Step: 3
Training loss: 3.5725059509277344
Validation loss: 3.4837182760238647

Epoch: 5| Step: 4
Training loss: 3.3699893951416016
Validation loss: 3.47864759961764

Epoch: 5| Step: 5
Training loss: 3.8600761890411377
Validation loss: 3.4737999637921653

Epoch: 5| Step: 6
Training loss: 3.8312618732452393
Validation loss: 3.470690965652466

Epoch: 5| Step: 7
Training loss: 3.391566038131714
Validation loss: 3.465764512618383

Epoch: 5| Step: 8
Training loss: 4.078702449798584
Validation loss: 3.4605773588021598

Epoch: 5| Step: 9
Training loss: 3.935920000076294
Validation loss: 3.454769253730774

Epoch: 5| Step: 10
Training loss: 3.7192044258117676
Validation loss: 3.4503420293331146

Epoch: 5| Step: 11
Training loss: 2.6948037147521973
Validation loss: 3.445461372534434

Epoch: 28| Step: 0
Training loss: 3.549870729446411
Validation loss: 3.4412972927093506

Epoch: 5| Step: 1
Training loss: 3.4345784187316895
Validation loss: 3.4375626742839813

Epoch: 5| Step: 2
Training loss: 3.9243361949920654
Validation loss: 3.4340049624443054

Epoch: 5| Step: 3
Training loss: 3.1419384479522705
Validation loss: 3.4285031159718833

Epoch: 5| Step: 4
Training loss: 3.924546480178833
Validation loss: 3.42515437801679

Epoch: 5| Step: 5
Training loss: 3.107379198074341
Validation loss: 3.4205403327941895

Epoch: 5| Step: 6
Training loss: 4.626743316650391
Validation loss: 3.415832996368408

Epoch: 5| Step: 7
Training loss: 3.7838473320007324
Validation loss: 3.4119028449058533

Epoch: 5| Step: 8
Training loss: 3.2260146141052246
Validation loss: 3.4065148731072745

Epoch: 5| Step: 9
Training loss: 3.385585069656372
Validation loss: 3.402769366900126

Epoch: 5| Step: 10
Training loss: 3.5417628288269043
Validation loss: 3.398424804210663

Epoch: 5| Step: 11
Training loss: 2.6127192974090576
Validation loss: 3.394001175959905

Epoch: 29| Step: 0
Training loss: 3.9872384071350098
Validation loss: 3.3888792395591736

Epoch: 5| Step: 1
Training loss: 3.8541641235351562
Validation loss: 3.3842230836550393

Epoch: 5| Step: 2
Training loss: 3.7301077842712402
Validation loss: 3.3792065183321633

Epoch: 5| Step: 3
Training loss: 3.491180896759033
Validation loss: 3.3748339414596558

Epoch: 5| Step: 4
Training loss: 3.1045825481414795
Validation loss: 3.369930773973465

Epoch: 5| Step: 5
Training loss: 3.7371647357940674
Validation loss: 3.36679341395696

Epoch: 5| Step: 6
Training loss: 2.683079242706299
Validation loss: 3.3728637993335724

Epoch: 5| Step: 7
Training loss: 2.832850933074951
Validation loss: 3.3558730284372964

Epoch: 5| Step: 8
Training loss: 3.6238455772399902
Validation loss: 3.3537389437357583

Epoch: 5| Step: 9
Training loss: 3.798607587814331
Validation loss: 3.3534006774425507

Epoch: 5| Step: 10
Training loss: 4.129730701446533
Validation loss: 3.350295821825663

Epoch: 5| Step: 11
Training loss: 3.212904930114746
Validation loss: 3.3436038494110107

Epoch: 30| Step: 0
Training loss: 3.6727535724639893
Validation loss: 3.336693932612737

Epoch: 5| Step: 1
Training loss: 3.435739040374756
Validation loss: 3.3323487639427185

Epoch: 5| Step: 2
Training loss: 3.1628432273864746
Validation loss: 3.327124744653702

Epoch: 5| Step: 3
Training loss: 3.349379777908325
Validation loss: 3.3227909207344055

Epoch: 5| Step: 4
Training loss: 3.680751323699951
Validation loss: 3.319026639064153

Epoch: 5| Step: 5
Training loss: 4.374663352966309
Validation loss: 3.3150421579678855

Epoch: 5| Step: 6
Training loss: 3.8373031616210938
Validation loss: 3.3102288246154785

Epoch: 5| Step: 7
Training loss: 3.2713122367858887
Validation loss: 3.3052189449469247

Epoch: 5| Step: 8
Training loss: 3.1680285930633545
Validation loss: 3.2987817923227944

Epoch: 5| Step: 9
Training loss: 2.7209091186523438
Validation loss: 3.2945657869180045

Epoch: 5| Step: 10
Training loss: 3.4162864685058594
Validation loss: 3.290439695119858

Epoch: 5| Step: 11
Training loss: 4.787585258483887
Validation loss: 3.2855900128682456

Epoch: 31| Step: 0
Training loss: 3.0350029468536377
Validation loss: 3.2801543970902762

Epoch: 5| Step: 1
Training loss: 3.8604202270507812
Validation loss: 3.276975909868876

Epoch: 5| Step: 2
Training loss: 4.141567230224609
Validation loss: 3.271204878886541

Epoch: 5| Step: 3
Training loss: 3.408393144607544
Validation loss: 3.2670998871326447

Epoch: 5| Step: 4
Training loss: 3.9741978645324707
Validation loss: 3.2617777585983276

Epoch: 5| Step: 5
Training loss: 3.47918701171875
Validation loss: 3.2567141950130463

Epoch: 5| Step: 6
Training loss: 3.893552780151367
Validation loss: 3.2515863279501596

Epoch: 5| Step: 7
Training loss: 2.603642225265503
Validation loss: 3.247577359278997

Epoch: 5| Step: 8
Training loss: 3.3279290199279785
Validation loss: 3.2435760299364724

Epoch: 5| Step: 9
Training loss: 2.968074083328247
Validation loss: 3.238625317811966

Epoch: 5| Step: 10
Training loss: 3.359254837036133
Validation loss: 3.235052307446798

Epoch: 5| Step: 11
Training loss: 2.128655433654785
Validation loss: 3.231768250465393

Epoch: 32| Step: 0
Training loss: 2.937227964401245
Validation loss: 3.225717008113861

Epoch: 5| Step: 1
Training loss: 3.7833073139190674
Validation loss: 3.2240738372008004

Epoch: 5| Step: 2
Training loss: 3.6636033058166504
Validation loss: 3.2239381472269693

Epoch: 5| Step: 3
Training loss: 3.7673752307891846
Validation loss: 3.2229764560858407

Epoch: 5| Step: 4
Training loss: 2.8718950748443604
Validation loss: 3.216143786907196

Epoch: 5| Step: 5
Training loss: 3.3061420917510986
Validation loss: 3.208394706249237

Epoch: 5| Step: 6
Training loss: 2.912461280822754
Validation loss: 3.2037182251612344

Epoch: 5| Step: 7
Training loss: 4.178798675537109
Validation loss: 3.199991762638092

Epoch: 5| Step: 8
Training loss: 3.4307048320770264
Validation loss: 3.196363389492035

Epoch: 5| Step: 9
Training loss: 3.10697603225708
Validation loss: 3.1927992006142936

Epoch: 5| Step: 10
Training loss: 3.470766544342041
Validation loss: 3.189246674378713

Epoch: 5| Step: 11
Training loss: 2.546556234359741
Validation loss: 3.184503883123398

Epoch: 33| Step: 0
Training loss: 3.1575069427490234
Validation loss: 3.181361277898153

Epoch: 5| Step: 1
Training loss: 3.368695020675659
Validation loss: 3.1790092488129935

Epoch: 5| Step: 2
Training loss: 4.1219587326049805
Validation loss: 3.1749534408251443

Epoch: 5| Step: 3
Training loss: 2.5496373176574707
Validation loss: 3.1698305308818817

Epoch: 5| Step: 4
Training loss: 3.381425142288208
Validation loss: 3.1631057957808175

Epoch: 5| Step: 5
Training loss: 3.7938899993896484
Validation loss: 3.15945831934611

Epoch: 5| Step: 6
Training loss: 3.6128127574920654
Validation loss: 3.152898738781611

Epoch: 5| Step: 7
Training loss: 2.2936463356018066
Validation loss: 3.148414800564448

Epoch: 5| Step: 8
Training loss: 3.9946773052215576
Validation loss: 3.144066592057546

Epoch: 5| Step: 9
Training loss: 3.3912665843963623
Validation loss: 3.1401952107747397

Epoch: 5| Step: 10
Training loss: 3.2412490844726562
Validation loss: 3.1354916393756866

Epoch: 5| Step: 11
Training loss: 2.773210048675537
Validation loss: 3.131556252638499

Epoch: 34| Step: 0
Training loss: 3.3364462852478027
Validation loss: 3.1277330617109933

Epoch: 5| Step: 1
Training loss: 3.2468008995056152
Validation loss: 3.122448851664861

Epoch: 5| Step: 2
Training loss: 3.375187397003174
Validation loss: 3.1174142162005105

Epoch: 5| Step: 3
Training loss: 3.3348209857940674
Validation loss: 3.114049623409907

Epoch: 5| Step: 4
Training loss: 3.392524003982544
Validation loss: 3.1091997027397156

Epoch: 5| Step: 5
Training loss: 3.2667629718780518
Validation loss: 3.104337284962336

Epoch: 5| Step: 6
Training loss: 2.7603743076324463
Validation loss: 3.1024571359157562

Epoch: 5| Step: 7
Training loss: 2.9553678035736084
Validation loss: 3.1008345683415732

Epoch: 5| Step: 8
Training loss: 4.12232780456543
Validation loss: 3.103691985209783

Epoch: 5| Step: 9
Training loss: 3.119800329208374
Validation loss: 3.1058001617590585

Epoch: 5| Step: 10
Training loss: 3.4229655265808105
Validation loss: 3.0915202597777047

Epoch: 5| Step: 11
Training loss: 2.880682945251465
Validation loss: 3.083175450563431

Epoch: 35| Step: 0
Training loss: 2.7945408821105957
Validation loss: 3.078336536884308

Epoch: 5| Step: 1
Training loss: 3.544017791748047
Validation loss: 3.0755108495553336

Epoch: 5| Step: 2
Training loss: 2.9774932861328125
Validation loss: 3.0723974208037057

Epoch: 5| Step: 3
Training loss: 2.9768929481506348
Validation loss: 3.067394951979319

Epoch: 5| Step: 4
Training loss: 3.520174026489258
Validation loss: 3.0637442767620087

Epoch: 5| Step: 5
Training loss: 3.5900466442108154
Validation loss: 3.0613461335500083

Epoch: 5| Step: 6
Training loss: 2.8630497455596924
Validation loss: 3.055401861667633

Epoch: 5| Step: 7
Training loss: 3.4338538646698
Validation loss: 3.0525277654329934

Epoch: 5| Step: 8
Training loss: 3.9824204444885254
Validation loss: 3.0482466320196786

Epoch: 5| Step: 9
Training loss: 3.1022820472717285
Validation loss: 3.044433464606603

Epoch: 5| Step: 10
Training loss: 2.6394331455230713
Validation loss: 3.0419432123502097

Epoch: 5| Step: 11
Training loss: 4.709836006164551
Validation loss: 3.036476661761602

Epoch: 36| Step: 0
Training loss: 3.413996458053589
Validation loss: 3.0336451133092246

Epoch: 5| Step: 1
Training loss: 2.9201245307922363
Validation loss: 3.029657552639643

Epoch: 5| Step: 2
Training loss: 2.996509552001953
Validation loss: 3.024829715490341

Epoch: 5| Step: 3
Training loss: 2.493363857269287
Validation loss: 3.0205767353375754

Epoch: 5| Step: 4
Training loss: 3.60444712638855
Validation loss: 3.0168151259422302

Epoch: 5| Step: 5
Training loss: 3.018610715866089
Validation loss: 3.013042390346527

Epoch: 5| Step: 6
Training loss: 3.5093207359313965
Validation loss: 3.0090419948101044

Epoch: 5| Step: 7
Training loss: 3.4000344276428223
Validation loss: 3.004591683546702

Epoch: 5| Step: 8
Training loss: 3.224611759185791
Validation loss: 3.0004963477452598

Epoch: 5| Step: 9
Training loss: 3.4017319679260254
Validation loss: 2.9970217446486154

Epoch: 5| Step: 10
Training loss: 3.248203992843628
Validation loss: 2.9935616652170816

Epoch: 5| Step: 11
Training loss: 3.1280689239501953
Validation loss: 2.9884375433127084

Epoch: 37| Step: 0
Training loss: 3.453129291534424
Validation loss: 2.9845718244711557

Epoch: 5| Step: 1
Training loss: 2.8728725910186768
Validation loss: 2.9819357792536416

Epoch: 5| Step: 2
Training loss: 2.7680485248565674
Validation loss: 2.9938177267710366

Epoch: 5| Step: 3
Training loss: 3.123124361038208
Validation loss: 2.996747761964798

Epoch: 5| Step: 4
Training loss: 3.324735164642334
Validation loss: 2.973233252763748

Epoch: 5| Step: 5
Training loss: 3.696300983428955
Validation loss: 2.9659913976987204

Epoch: 5| Step: 6
Training loss: 3.0062153339385986
Validation loss: 2.9606259167194366

Epoch: 5| Step: 7
Training loss: 3.5110526084899902
Validation loss: 2.9577972888946533

Epoch: 5| Step: 8
Training loss: 2.778562068939209
Validation loss: 2.9569892088572183

Epoch: 5| Step: 9
Training loss: 3.2501778602600098
Validation loss: 2.9573197265466056

Epoch: 5| Step: 10
Training loss: 3.103695869445801
Validation loss: 2.954976280530294

Epoch: 5| Step: 11
Training loss: 2.6225266456604004
Validation loss: 2.9481858015060425

Epoch: 38| Step: 0
Training loss: 3.1282856464385986
Validation loss: 2.94064728418986

Epoch: 5| Step: 1
Training loss: 3.0760886669158936
Validation loss: 2.9354716638724008

Epoch: 5| Step: 2
Training loss: 2.8536369800567627
Validation loss: 2.931285490592321

Epoch: 5| Step: 3
Training loss: 2.5382418632507324
Validation loss: 2.927605479955673

Epoch: 5| Step: 4
Training loss: 2.9301583766937256
Validation loss: 2.926684856414795

Epoch: 5| Step: 5
Training loss: 3.9788169860839844
Validation loss: 2.9257263441880546

Epoch: 5| Step: 6
Training loss: 2.8561723232269287
Validation loss: 2.920767625172933

Epoch: 5| Step: 7
Training loss: 3.572399139404297
Validation loss: 2.915201117595037

Epoch: 5| Step: 8
Training loss: 2.7516071796417236
Validation loss: 2.9104070464769998

Epoch: 5| Step: 9
Training loss: 3.977266788482666
Validation loss: 2.9058368702729545

Epoch: 5| Step: 10
Training loss: 2.745771884918213
Validation loss: 2.9012800653775535

Epoch: 5| Step: 11
Training loss: 2.598876953125
Validation loss: 2.897269994020462

Epoch: 39| Step: 0
Training loss: 3.2692923545837402
Validation loss: 2.893221994241079

Epoch: 5| Step: 1
Training loss: 3.376174211502075
Validation loss: 2.889076739549637

Epoch: 5| Step: 2
Training loss: 2.9992358684539795
Validation loss: 2.884349505106608

Epoch: 5| Step: 3
Training loss: 3.185147523880005
Validation loss: 2.8820337454477944

Epoch: 5| Step: 4
Training loss: 3.569967746734619
Validation loss: 2.877203712860743

Epoch: 5| Step: 5
Training loss: 3.269320011138916
Validation loss: 2.874001165231069

Epoch: 5| Step: 6
Training loss: 3.1331143379211426
Validation loss: 2.8693582117557526

Epoch: 5| Step: 7
Training loss: 3.0387954711914062
Validation loss: 2.8648560841878257

Epoch: 5| Step: 8
Training loss: 2.7393925189971924
Validation loss: 2.861642907063166

Epoch: 5| Step: 9
Training loss: 2.6494383811950684
Validation loss: 2.8575724065303802

Epoch: 5| Step: 10
Training loss: 2.671844005584717
Validation loss: 2.85358856121699

Epoch: 5| Step: 11
Training loss: 2.740959405899048
Validation loss: 2.850054462750753

Epoch: 40| Step: 0
Training loss: 2.9873156547546387
Validation loss: 2.846226384242376

Epoch: 5| Step: 1
Training loss: 3.802767276763916
Validation loss: 2.841999957958857

Epoch: 5| Step: 2
Training loss: 3.2473068237304688
Validation loss: 2.8374601006507874

Epoch: 5| Step: 3
Training loss: 3.170070171356201
Validation loss: 2.833780417839686

Epoch: 5| Step: 4
Training loss: 2.9975383281707764
Validation loss: 2.830353260040283

Epoch: 5| Step: 5
Training loss: 3.1586873531341553
Validation loss: 2.8273737728595734

Epoch: 5| Step: 6
Training loss: 2.9235103130340576
Validation loss: 2.8234453996022544

Epoch: 5| Step: 7
Training loss: 2.6845884323120117
Validation loss: 2.8201139668623605

Epoch: 5| Step: 8
Training loss: 2.8559422492980957
Validation loss: 2.8159563342730203

Epoch: 5| Step: 9
Training loss: 2.499450206756592
Validation loss: 2.8139843245347342

Epoch: 5| Step: 10
Training loss: 2.765040397644043
Validation loss: 2.812585433324178

Epoch: 5| Step: 11
Training loss: 4.429024696350098
Validation loss: 2.808765560388565

Epoch: 41| Step: 0
Training loss: 2.571152448654175
Validation loss: 2.8047783772150674

Epoch: 5| Step: 1
Training loss: 2.7023251056671143
Validation loss: 2.8033104141553244

Epoch: 5| Step: 2
Training loss: 3.3201777935028076
Validation loss: 2.8009303410847983

Epoch: 5| Step: 3
Training loss: 2.974778890609741
Validation loss: 2.7990424831708274

Epoch: 5| Step: 4
Training loss: 3.0264317989349365
Validation loss: 2.7928014993667603

Epoch: 5| Step: 5
Training loss: 3.3611083030700684
Validation loss: 2.7909460067749023

Epoch: 5| Step: 6
Training loss: 2.548278570175171
Validation loss: 2.7842074731985726

Epoch: 5| Step: 7
Training loss: 2.9080746173858643
Validation loss: 2.7789806127548218

Epoch: 5| Step: 8
Training loss: 3.7713890075683594
Validation loss: 2.775845170021057

Epoch: 5| Step: 9
Training loss: 2.8698246479034424
Validation loss: 2.771733204523722

Epoch: 5| Step: 10
Training loss: 2.8256871700286865
Validation loss: 2.768989384174347

Epoch: 5| Step: 11
Training loss: 3.335561990737915
Validation loss: 2.7670868039131165

Epoch: 42| Step: 0
Training loss: 3.2159523963928223
Validation loss: 2.763956755399704

Epoch: 5| Step: 1
Training loss: 3.9944539070129395
Validation loss: 2.7586485842863717

Epoch: 5| Step: 2
Training loss: 2.97298002243042
Validation loss: 2.7555567423502603

Epoch: 5| Step: 3
Training loss: 3.1933281421661377
Validation loss: 2.751761813958486

Epoch: 5| Step: 4
Training loss: 2.9588630199432373
Validation loss: 2.748349001010259

Epoch: 5| Step: 5
Training loss: 2.609607219696045
Validation loss: 2.7451160848140717

Epoch: 5| Step: 6
Training loss: 2.477306365966797
Validation loss: 2.742206335067749

Epoch: 5| Step: 7
Training loss: 2.7257304191589355
Validation loss: 2.740676869948705

Epoch: 5| Step: 8
Training loss: 3.477391481399536
Validation loss: 2.7373810708522797

Epoch: 5| Step: 9
Training loss: 2.0702619552612305
Validation loss: 2.7315597236156464

Epoch: 5| Step: 10
Training loss: 2.666285991668701
Validation loss: 2.7277840077877045

Epoch: 5| Step: 11
Training loss: 3.655240774154663
Validation loss: 2.7246715327103934

Epoch: 43| Step: 0
Training loss: 2.9061195850372314
Validation loss: 2.721228947242101

Epoch: 5| Step: 1
Training loss: 3.199559450149536
Validation loss: 2.7193275690078735

Epoch: 5| Step: 2
Training loss: 2.240898609161377
Validation loss: 2.715121775865555

Epoch: 5| Step: 3
Training loss: 3.3639838695526123
Validation loss: 2.7125838696956635

Epoch: 5| Step: 4
Training loss: 3.1103768348693848
Validation loss: 2.7103679279486337

Epoch: 5| Step: 5
Training loss: 2.920628547668457
Validation loss: 2.704873929421107

Epoch: 5| Step: 6
Training loss: 3.9003326892852783
Validation loss: 2.702703813711802

Epoch: 5| Step: 7
Training loss: 2.0286178588867188
Validation loss: 2.6986573139826455

Epoch: 5| Step: 8
Training loss: 3.086111545562744
Validation loss: 2.695351521174113

Epoch: 5| Step: 9
Training loss: 2.675532579421997
Validation loss: 2.6930428743362427

Epoch: 5| Step: 10
Training loss: 2.5867488384246826
Validation loss: 2.686789204676946

Epoch: 5| Step: 11
Training loss: 2.781935214996338
Validation loss: 2.6877050598462424

Epoch: 44| Step: 0
Training loss: 3.102287769317627
Validation loss: 2.682698925336202

Epoch: 5| Step: 1
Training loss: 2.6028170585632324
Validation loss: 2.6806937952836356

Epoch: 5| Step: 2
Training loss: 2.559483289718628
Validation loss: 2.6779767175515494

Epoch: 5| Step: 3
Training loss: 2.9377360343933105
Validation loss: 2.678993731737137

Epoch: 5| Step: 4
Training loss: 3.0882554054260254
Validation loss: 2.6751154164473214

Epoch: 5| Step: 5
Training loss: 2.374342203140259
Validation loss: 2.6733063558737435

Epoch: 5| Step: 6
Training loss: 2.493685245513916
Validation loss: 2.6654974222183228

Epoch: 5| Step: 7
Training loss: 3.1726765632629395
Validation loss: 2.65826423962911

Epoch: 5| Step: 8
Training loss: 3.402656078338623
Validation loss: 2.655842592318853

Epoch: 5| Step: 9
Training loss: 3.176949977874756
Validation loss: 2.654101630051931

Epoch: 5| Step: 10
Training loss: 2.518845796585083
Validation loss: 2.65630433956782

Epoch: 5| Step: 11
Training loss: 3.4124035835266113
Validation loss: 2.6525911688804626

Epoch: 45| Step: 0
Training loss: 3.087650775909424
Validation loss: 2.648028443257014

Epoch: 5| Step: 1
Training loss: 2.708981990814209
Validation loss: 2.644583225250244

Epoch: 5| Step: 2
Training loss: 2.5468037128448486
Validation loss: 2.636105954647064

Epoch: 5| Step: 3
Training loss: 2.6091604232788086
Validation loss: 2.6315013269583383

Epoch: 5| Step: 4
Training loss: 2.9766221046447754
Validation loss: 2.6288059651851654

Epoch: 5| Step: 5
Training loss: 2.7686896324157715
Validation loss: 2.6282476782798767

Epoch: 5| Step: 6
Training loss: 3.0321602821350098
Validation loss: 2.625697582960129

Epoch: 5| Step: 7
Training loss: 3.208292007446289
Validation loss: 2.6259563167889914

Epoch: 5| Step: 8
Training loss: 2.6379246711730957
Validation loss: 2.617749681075414

Epoch: 5| Step: 9
Training loss: 2.693117141723633
Validation loss: 2.610753188530604

Epoch: 5| Step: 10
Training loss: 2.8937392234802246
Validation loss: 2.609070281187693

Epoch: 5| Step: 11
Training loss: 2.60153865814209
Validation loss: 2.604486624399821

Epoch: 46| Step: 0
Training loss: 2.6869685649871826
Validation loss: 2.6027561922868094

Epoch: 5| Step: 1
Training loss: 2.709798812866211
Validation loss: 2.6025062004725137

Epoch: 5| Step: 2
Training loss: 2.365213632583618
Validation loss: 2.601462870836258

Epoch: 5| Step: 3
Training loss: 2.3839271068573
Validation loss: 2.5975510478019714

Epoch: 5| Step: 4
Training loss: 3.5001227855682373
Validation loss: 2.5922346711158752

Epoch: 5| Step: 5
Training loss: 2.7730867862701416
Validation loss: 2.586139589548111

Epoch: 5| Step: 6
Training loss: 2.698350191116333
Validation loss: 2.581458161274592

Epoch: 5| Step: 7
Training loss: 2.655003070831299
Validation loss: 2.578968365987142

Epoch: 5| Step: 8
Training loss: 2.929490327835083
Validation loss: 2.5754338105519614

Epoch: 5| Step: 9
Training loss: 3.3137238025665283
Validation loss: 2.572388082742691

Epoch: 5| Step: 10
Training loss: 2.8101792335510254
Validation loss: 2.570497671763102

Epoch: 5| Step: 11
Training loss: 1.8402454853057861
Validation loss: 2.5675716201464334

Epoch: 47| Step: 0
Training loss: 2.4517624378204346
Validation loss: 2.5676164031028748

Epoch: 5| Step: 1
Training loss: 2.9495270252227783
Validation loss: 2.5658863186836243

Epoch: 5| Step: 2
Training loss: 2.8928585052490234
Validation loss: 2.5660067598025003

Epoch: 5| Step: 3
Training loss: 2.3498268127441406
Validation loss: 2.5607031186421714

Epoch: 5| Step: 4
Training loss: 3.0526390075683594
Validation loss: 2.5531321863333383

Epoch: 5| Step: 5
Training loss: 3.0706353187561035
Validation loss: 2.5481819113095603

Epoch: 5| Step: 6
Training loss: 2.6541874408721924
Validation loss: 2.545120378335317

Epoch: 5| Step: 7
Training loss: 3.4084153175354004
Validation loss: 2.5407534539699554

Epoch: 5| Step: 8
Training loss: 2.469015121459961
Validation loss: 2.5375445783138275

Epoch: 5| Step: 9
Training loss: 2.517259120941162
Validation loss: 2.534121870994568

Epoch: 5| Step: 10
Training loss: 2.6283998489379883
Validation loss: 2.53267831603686

Epoch: 5| Step: 11
Training loss: 1.5413458347320557
Validation loss: 2.5307642817497253

Epoch: 48| Step: 0
Training loss: 2.994417667388916
Validation loss: 2.5296048472325006

Epoch: 5| Step: 1
Training loss: 2.792015790939331
Validation loss: 2.526789685090383

Epoch: 5| Step: 2
Training loss: 2.797647476196289
Validation loss: 2.5202516913414

Epoch: 5| Step: 3
Training loss: 2.809218406677246
Validation loss: 2.517744650443395

Epoch: 5| Step: 4
Training loss: 2.4730119705200195
Validation loss: 2.512826939423879

Epoch: 5| Step: 5
Training loss: 2.7508888244628906
Validation loss: 2.511937290430069

Epoch: 5| Step: 6
Training loss: 2.6919796466827393
Validation loss: 2.510542462269465

Epoch: 5| Step: 7
Training loss: 1.8870983123779297
Validation loss: 2.508917341629664

Epoch: 5| Step: 8
Training loss: 3.0786938667297363
Validation loss: 2.5088561177253723

Epoch: 5| Step: 9
Training loss: 3.1183319091796875
Validation loss: 2.5130832493305206

Epoch: 5| Step: 10
Training loss: 2.621319532394409
Validation loss: 2.516999344031016

Epoch: 5| Step: 11
Training loss: 1.6954419612884521
Validation loss: 2.5168424348036447

Epoch: 49| Step: 0
Training loss: 2.5802159309387207
Validation loss: 2.505756139755249

Epoch: 5| Step: 1
Training loss: 2.3427517414093018
Validation loss: 2.4938743313153586

Epoch: 5| Step: 2
Training loss: 2.9343810081481934
Validation loss: 2.4904282689094543

Epoch: 5| Step: 3
Training loss: 2.829181671142578
Validation loss: 2.488272378842036

Epoch: 5| Step: 4
Training loss: 2.6754305362701416
Validation loss: 2.4860648016134896

Epoch: 5| Step: 5
Training loss: 3.2458834648132324
Validation loss: 2.4844475984573364

Epoch: 5| Step: 6
Training loss: 2.6599011421203613
Validation loss: 2.483961363633474

Epoch: 5| Step: 7
Training loss: 2.004034996032715
Validation loss: 2.4803673724333444

Epoch: 5| Step: 8
Training loss: 2.428982734680176
Validation loss: 2.479584723711014

Epoch: 5| Step: 9
Training loss: 2.5358803272247314
Validation loss: 2.4768077731132507

Epoch: 5| Step: 10
Training loss: 3.041073799133301
Validation loss: 2.472242514292399

Epoch: 5| Step: 11
Training loss: 3.4325733184814453
Validation loss: 2.470286717017492

Epoch: 50| Step: 0
Training loss: 2.1323082447052
Validation loss: 2.4682875275611877

Epoch: 5| Step: 1
Training loss: 3.133723497390747
Validation loss: 2.4636873404184976

Epoch: 5| Step: 2
Training loss: 2.781649351119995
Validation loss: 2.461520900328954

Epoch: 5| Step: 3
Training loss: 2.586526393890381
Validation loss: 2.4581525027751923

Epoch: 5| Step: 4
Training loss: 3.3528084754943848
Validation loss: 2.4560731699069343

Epoch: 5| Step: 5
Training loss: 2.5603814125061035
Validation loss: 2.454557051261266

Epoch: 5| Step: 6
Training loss: 2.4082560539245605
Validation loss: 2.4512555499871573

Epoch: 5| Step: 7
Training loss: 2.82912015914917
Validation loss: 2.449554597338041

Epoch: 5| Step: 8
Training loss: 2.420870065689087
Validation loss: 2.4443215131759644

Epoch: 5| Step: 9
Training loss: 2.363300085067749
Validation loss: 2.442948301633199

Epoch: 5| Step: 10
Training loss: 2.5437278747558594
Validation loss: 2.4385604510704675

Epoch: 5| Step: 11
Training loss: 2.112722873687744
Validation loss: 2.4372438887755075

Epoch: 51| Step: 0
Training loss: 3.0002357959747314
Validation loss: 2.432362655798594

Epoch: 5| Step: 1
Training loss: 2.159083843231201
Validation loss: 2.430399566888809

Epoch: 5| Step: 2
Training loss: 2.5123798847198486
Validation loss: 2.428157369295756

Epoch: 5| Step: 3
Training loss: 3.014157772064209
Validation loss: 2.4231213529904685

Epoch: 5| Step: 4
Training loss: 2.1061949729919434
Validation loss: 2.424874315659205

Epoch: 5| Step: 5
Training loss: 2.536386728286743
Validation loss: 2.4197967847188315

Epoch: 5| Step: 6
Training loss: 2.654825448989868
Validation loss: 2.418793186545372

Epoch: 5| Step: 7
Training loss: 2.375779628753662
Validation loss: 2.417425016562144

Epoch: 5| Step: 8
Training loss: 2.9310595989227295
Validation loss: 2.411348342895508

Epoch: 5| Step: 9
Training loss: 2.7998130321502686
Validation loss: 2.4099359711011252

Epoch: 5| Step: 10
Training loss: 2.548693895339966
Validation loss: 2.40734393397967

Epoch: 5| Step: 11
Training loss: 2.4997596740722656
Validation loss: 2.4024049242337546

Epoch: 52| Step: 0
Training loss: 2.6520886421203613
Validation loss: 2.40279421210289

Epoch: 5| Step: 1
Training loss: 2.3203978538513184
Validation loss: 2.4005037446816764

Epoch: 5| Step: 2
Training loss: 2.3906702995300293
Validation loss: 2.3968378702799478

Epoch: 5| Step: 3
Training loss: 2.471247434616089
Validation loss: 2.3968687504529953

Epoch: 5| Step: 4
Training loss: 2.1671338081359863
Validation loss: 2.395191411177317

Epoch: 5| Step: 5
Training loss: 2.687370777130127
Validation loss: 2.401466210683187

Epoch: 5| Step: 6
Training loss: 3.0528271198272705
Validation loss: 2.403074930111567

Epoch: 5| Step: 7
Training loss: 2.4654126167297363
Validation loss: 2.3949398001035056

Epoch: 5| Step: 8
Training loss: 2.594648838043213
Validation loss: 2.381973812977473

Epoch: 5| Step: 9
Training loss: 2.956019639968872
Validation loss: 2.380678176879883

Epoch: 5| Step: 10
Training loss: 2.5716214179992676
Validation loss: 2.3927014668782554

Epoch: 5| Step: 11
Training loss: 2.500291109085083
Validation loss: 2.4058300654093423

Epoch: 53| Step: 0
Training loss: 3.2277114391326904
Validation loss: 2.4123498797416687

Epoch: 5| Step: 1
Training loss: 2.7518515586853027
Validation loss: 2.40235702196757

Epoch: 5| Step: 2
Training loss: 2.0095980167388916
Validation loss: 2.3834241976340613

Epoch: 5| Step: 3
Training loss: 2.6372735500335693
Validation loss: 2.3706477880477905

Epoch: 5| Step: 4
Training loss: 2.330967664718628
Validation loss: 2.3660275042057037

Epoch: 5| Step: 5
Training loss: 2.599900245666504
Validation loss: 2.3649185597896576

Epoch: 5| Step: 6
Training loss: 2.481600284576416
Validation loss: 2.362707565228144

Epoch: 5| Step: 7
Training loss: 2.2279717922210693
Validation loss: 2.3622181167205176

Epoch: 5| Step: 8
Training loss: 2.4787003993988037
Validation loss: 2.358071118593216

Epoch: 5| Step: 9
Training loss: 2.882190465927124
Validation loss: 2.353867163260778

Epoch: 5| Step: 10
Training loss: 2.3290700912475586
Validation loss: 2.3486304581165314

Epoch: 5| Step: 11
Training loss: 2.6923305988311768
Validation loss: 2.3435903092225394

Epoch: 54| Step: 0
Training loss: 2.8679590225219727
Validation loss: 2.3407619297504425

Epoch: 5| Step: 1
Training loss: 2.2800188064575195
Validation loss: 2.3397575120131173

Epoch: 5| Step: 2
Training loss: 2.5083651542663574
Validation loss: 2.3363457024097443

Epoch: 5| Step: 3
Training loss: 2.5005271434783936
Validation loss: 2.334431976079941

Epoch: 5| Step: 4
Training loss: 2.1991708278656006
Validation loss: 2.3370962043603263

Epoch: 5| Step: 5
Training loss: 2.8035099506378174
Validation loss: 2.3333555161952972

Epoch: 5| Step: 6
Training loss: 2.455657482147217
Validation loss: 2.329384391506513

Epoch: 5| Step: 7
Training loss: 2.3198161125183105
Validation loss: 2.327583516637484

Epoch: 5| Step: 8
Training loss: 2.821394681930542
Validation loss: 2.3237229386965432

Epoch: 5| Step: 9
Training loss: 2.751108169555664
Validation loss: 2.3207020461559296

Epoch: 5| Step: 10
Training loss: 1.9018256664276123
Validation loss: 2.3203590512275696

Epoch: 5| Step: 11
Training loss: 3.182309150695801
Validation loss: 2.316971371571223

Epoch: 55| Step: 0
Training loss: 2.923111915588379
Validation loss: 2.3183522323767343

Epoch: 5| Step: 1
Training loss: 1.9366652965545654
Validation loss: 2.3123694161574044

Epoch: 5| Step: 2
Training loss: 2.5573673248291016
Validation loss: 2.30847076078256

Epoch: 5| Step: 3
Training loss: 2.0009348392486572
Validation loss: 2.306841403245926

Epoch: 5| Step: 4
Training loss: 2.367368221282959
Validation loss: 2.3031146426995597

Epoch: 5| Step: 5
Training loss: 2.390183687210083
Validation loss: 2.3033324678738913

Epoch: 5| Step: 6
Training loss: 2.824655055999756
Validation loss: 2.2989726463953652

Epoch: 5| Step: 7
Training loss: 1.9734214544296265
Validation loss: 2.295767863591512

Epoch: 5| Step: 8
Training loss: 2.5551633834838867
Validation loss: 2.2969216207663217

Epoch: 5| Step: 9
Training loss: 2.270390033721924
Validation loss: 2.2943975081046424

Epoch: 5| Step: 10
Training loss: 3.224470853805542
Validation loss: 2.295449902613958

Epoch: 5| Step: 11
Training loss: 3.06856107711792
Validation loss: 2.290847897529602

Epoch: 56| Step: 0
Training loss: 2.53899884223938
Validation loss: 2.284368326266607

Epoch: 5| Step: 1
Training loss: 2.609126567840576
Validation loss: 2.287116010983785

Epoch: 5| Step: 2
Training loss: 2.304272413253784
Validation loss: 2.2765248715877533

Epoch: 5| Step: 3
Training loss: 2.3345448970794678
Validation loss: 2.2737249384323754

Epoch: 5| Step: 4
Training loss: 2.2377407550811768
Validation loss: 2.2763953705628714

Epoch: 5| Step: 5
Training loss: 2.629427433013916
Validation loss: 2.27252725760142

Epoch: 5| Step: 6
Training loss: 2.3687798976898193
Validation loss: 2.270405411720276

Epoch: 5| Step: 7
Training loss: 2.3741002082824707
Validation loss: 2.269441843032837

Epoch: 5| Step: 8
Training loss: 2.5833237171173096
Validation loss: 2.2671367526054382

Epoch: 5| Step: 9
Training loss: 2.23858642578125
Validation loss: 2.263834516207377

Epoch: 5| Step: 10
Training loss: 2.643690586090088
Validation loss: 2.2605237563451133

Epoch: 5| Step: 11
Training loss: 1.9605201482772827
Validation loss: 2.259876479705175

Epoch: 57| Step: 0
Training loss: 2.3704516887664795
Validation loss: 2.253815313180288

Epoch: 5| Step: 1
Training loss: 2.049213409423828
Validation loss: 2.255865906675657

Epoch: 5| Step: 2
Training loss: 2.142223358154297
Validation loss: 2.2531319161256156

Epoch: 5| Step: 3
Training loss: 2.3547122478485107
Validation loss: 2.2510277181863785

Epoch: 5| Step: 4
Training loss: 2.7608561515808105
Validation loss: 2.2527147283156714

Epoch: 5| Step: 5
Training loss: 2.5951778888702393
Validation loss: 2.2456925561030707

Epoch: 5| Step: 6
Training loss: 2.5825748443603516
Validation loss: 2.238543152809143

Epoch: 5| Step: 7
Training loss: 2.5522327423095703
Validation loss: 2.2367138961950936

Epoch: 5| Step: 8
Training loss: 2.0124802589416504
Validation loss: 2.233055700858434

Epoch: 5| Step: 9
Training loss: 3.215233564376831
Validation loss: 2.2303113440672555

Epoch: 5| Step: 10
Training loss: 1.7342212200164795
Validation loss: 2.2311378518740335

Epoch: 5| Step: 11
Training loss: 2.7619009017944336
Validation loss: 2.2345229983329773

Epoch: 58| Step: 0
Training loss: 2.577566623687744
Validation loss: 2.2334991792837777

Epoch: 5| Step: 1
Training loss: 2.2990851402282715
Validation loss: 2.23235817750295

Epoch: 5| Step: 2
Training loss: 1.947211503982544
Validation loss: 2.2277769396702447

Epoch: 5| Step: 3
Training loss: 2.7269530296325684
Validation loss: 2.2253074596325555

Epoch: 5| Step: 4
Training loss: 2.282855987548828
Validation loss: 2.2216272950172424

Epoch: 5| Step: 5
Training loss: 2.065004348754883
Validation loss: 2.216162617007891

Epoch: 5| Step: 6
Training loss: 2.424131155014038
Validation loss: 2.211385130882263

Epoch: 5| Step: 7
Training loss: 2.7777512073516846
Validation loss: 2.2124823381503425

Epoch: 5| Step: 8
Training loss: 2.309849262237549
Validation loss: 2.210047925511996

Epoch: 5| Step: 9
Training loss: 2.373103141784668
Validation loss: 2.2053723633289337

Epoch: 5| Step: 10
Training loss: 2.010723829269409
Validation loss: 2.2057269563277564

Epoch: 5| Step: 11
Training loss: 4.243487358093262
Validation loss: 2.211688647667567

Epoch: 59| Step: 0
Training loss: 1.845447301864624
Validation loss: 2.202981472015381

Epoch: 5| Step: 1
Training loss: 2.458686351776123
Validation loss: 2.203423410654068

Epoch: 5| Step: 2
Training loss: 2.6606996059417725
Validation loss: 2.2051014999548593

Epoch: 5| Step: 3
Training loss: 2.2310733795166016
Validation loss: 2.203694278995196

Epoch: 5| Step: 4
Training loss: 1.8114150762557983
Validation loss: 2.205661108096441

Epoch: 5| Step: 5
Training loss: 2.176412343978882
Validation loss: 2.212852641940117

Epoch: 5| Step: 6
Training loss: 2.1657230854034424
Validation loss: 2.20229934155941

Epoch: 5| Step: 7
Training loss: 2.6912598609924316
Validation loss: 2.2000317523876824

Epoch: 5| Step: 8
Training loss: 2.152693271636963
Validation loss: 2.194291094938914

Epoch: 5| Step: 9
Training loss: 2.739793062210083
Validation loss: 2.192801614602407

Epoch: 5| Step: 10
Training loss: 2.8522400856018066
Validation loss: 2.1855422953764596

Epoch: 5| Step: 11
Training loss: 2.7673654556274414
Validation loss: 2.1867431849241257

Epoch: 60| Step: 0
Training loss: 2.185131788253784
Validation loss: 2.1824031521876655

Epoch: 5| Step: 1
Training loss: 2.05804181098938
Validation loss: 2.1854396363099418

Epoch: 5| Step: 2
Training loss: 2.291442394256592
Validation loss: 2.2002031852801642

Epoch: 5| Step: 3
Training loss: 2.6643075942993164
Validation loss: 2.188888212045034

Epoch: 5| Step: 4
Training loss: 2.43184494972229
Validation loss: 2.18196148176988

Epoch: 5| Step: 5
Training loss: 2.714261293411255
Validation loss: 2.1870587219794593

Epoch: 5| Step: 6
Training loss: 2.5862174034118652
Validation loss: 2.1771010061105094

Epoch: 5| Step: 7
Training loss: 2.1310067176818848
Validation loss: 2.1794041444857917

Epoch: 5| Step: 8
Training loss: 2.423051357269287
Validation loss: 2.1811876694361367

Epoch: 5| Step: 9
Training loss: 2.004234552383423
Validation loss: 2.180484250187874

Epoch: 5| Step: 10
Training loss: 2.0643181800842285
Validation loss: 2.1828271001577377

Epoch: 5| Step: 11
Training loss: 3.169419050216675
Validation loss: 2.1821726908286414

Epoch: 61| Step: 0
Training loss: 2.0157408714294434
Validation loss: 2.180495878060659

Epoch: 5| Step: 1
Training loss: 1.793830156326294
Validation loss: 2.181697969635328

Epoch: 5| Step: 2
Training loss: 2.709799289703369
Validation loss: 2.1772381911675134

Epoch: 5| Step: 3
Training loss: 2.3837294578552246
Validation loss: 2.178183689713478

Epoch: 5| Step: 4
Training loss: 2.5204060077667236
Validation loss: 2.175951510667801

Epoch: 5| Step: 5
Training loss: 2.1129708290100098
Validation loss: 2.1743505795796714

Epoch: 5| Step: 6
Training loss: 2.8255419731140137
Validation loss: 2.1708390563726425

Epoch: 5| Step: 7
Training loss: 2.3346400260925293
Validation loss: 2.1674378911654153

Epoch: 5| Step: 8
Training loss: 2.3706986904144287
Validation loss: 2.1584587494532266

Epoch: 5| Step: 9
Training loss: 1.7359815835952759
Validation loss: 2.1665613849957785

Epoch: 5| Step: 10
Training loss: 2.705252170562744
Validation loss: 2.177565703789393

Epoch: 5| Step: 11
Training loss: 3.1698544025421143
Validation loss: 2.1809850136439004

Epoch: 62| Step: 0
Training loss: 2.5454115867614746
Validation loss: 2.1635731210311255

Epoch: 5| Step: 1
Training loss: 1.7814744710922241
Validation loss: 2.149588500459989

Epoch: 5| Step: 2
Training loss: 2.9762580394744873
Validation loss: 2.15867418050766

Epoch: 5| Step: 3
Training loss: 2.435945510864258
Validation loss: 2.1663761337598166

Epoch: 5| Step: 4
Training loss: 2.3770222663879395
Validation loss: 2.173856953779856

Epoch: 5| Step: 5
Training loss: 1.9003570079803467
Validation loss: 2.1797473082939782

Epoch: 5| Step: 6
Training loss: 2.8739397525787354
Validation loss: 2.192492733399073

Epoch: 5| Step: 7
Training loss: 2.4080586433410645
Validation loss: 2.1988418052593866

Epoch: 5| Step: 8
Training loss: 2.1977334022521973
Validation loss: 2.202672600746155

Epoch: 5| Step: 9
Training loss: 2.1342480182647705
Validation loss: 2.1986257433891296

Epoch: 5| Step: 10
Training loss: 2.0518715381622314
Validation loss: 2.1894009113311768

Epoch: 5| Step: 11
Training loss: 2.807870626449585
Validation loss: 2.180808256069819

Epoch: 63| Step: 0
Training loss: 2.0787789821624756
Validation loss: 2.176296462615331

Epoch: 5| Step: 1
Training loss: 2.0269877910614014
Validation loss: 2.1712629149357476

Epoch: 5| Step: 2
Training loss: 1.854530930519104
Validation loss: 2.1612174113591514

Epoch: 5| Step: 3
Training loss: 2.471689462661743
Validation loss: 2.15386134882768

Epoch: 5| Step: 4
Training loss: 2.4594621658325195
Validation loss: 2.146876017252604

Epoch: 5| Step: 5
Training loss: 2.111468553543091
Validation loss: 2.1368697434663773

Epoch: 5| Step: 6
Training loss: 2.351754903793335
Validation loss: 2.1445326755444207

Epoch: 5| Step: 7
Training loss: 2.7802023887634277
Validation loss: 2.140408178170522

Epoch: 5| Step: 8
Training loss: 2.9480972290039062
Validation loss: 2.139751598238945

Epoch: 5| Step: 9
Training loss: 2.486424684524536
Validation loss: 2.142789642016093

Epoch: 5| Step: 10
Training loss: 1.7311193943023682
Validation loss: 2.1421274741490683

Epoch: 5| Step: 11
Training loss: 3.266261577606201
Validation loss: 2.1299175520737967

Epoch: 64| Step: 0
Training loss: 1.8990284204483032
Validation loss: 2.1324117332696915

Epoch: 5| Step: 1
Training loss: 2.3512890338897705
Validation loss: 2.1411135296026864

Epoch: 5| Step: 2
Training loss: 2.4302918910980225
Validation loss: 2.144406939546267

Epoch: 5| Step: 3
Training loss: 2.4331576824188232
Validation loss: 2.149197762211164

Epoch: 5| Step: 4
Training loss: 2.2539479732513428
Validation loss: 2.1492559909820557

Epoch: 5| Step: 5
Training loss: 2.682919502258301
Validation loss: 2.156995246807734

Epoch: 5| Step: 6
Training loss: 2.3558175563812256
Validation loss: 2.1635090112686157

Epoch: 5| Step: 7
Training loss: 2.182762622833252
Validation loss: 2.1609344482421875

Epoch: 5| Step: 8
Training loss: 2.196507215499878
Validation loss: 2.160569737354914

Epoch: 5| Step: 9
Training loss: 2.4416511058807373
Validation loss: 2.1523798356453576

Epoch: 5| Step: 10
Training loss: 2.282616376876831
Validation loss: 2.153467779358228

Epoch: 5| Step: 11
Training loss: 2.120790958404541
Validation loss: 2.1444207032521567

Epoch: 65| Step: 0
Training loss: 2.081495761871338
Validation loss: 2.143822098771731

Epoch: 5| Step: 1
Training loss: 2.440624952316284
Validation loss: 2.1373059153556824

Epoch: 5| Step: 2
Training loss: 2.3606557846069336
Validation loss: 2.1321299771467843

Epoch: 5| Step: 3
Training loss: 2.050729513168335
Validation loss: 2.1320356726646423

Epoch: 5| Step: 4
Training loss: 2.018941879272461
Validation loss: 2.1267583817243576

Epoch: 5| Step: 5
Training loss: 2.5557074546813965
Validation loss: 2.122428913911184

Epoch: 5| Step: 6
Training loss: 1.804710030555725
Validation loss: 2.1200178265571594

Epoch: 5| Step: 7
Training loss: 2.7402734756469727
Validation loss: 2.1177277664343515

Epoch: 5| Step: 8
Training loss: 2.1079113483428955
Validation loss: 2.12102801601092

Epoch: 5| Step: 9
Training loss: 2.407987117767334
Validation loss: 2.115021069844564

Epoch: 5| Step: 10
Training loss: 2.811861515045166
Validation loss: 2.1120523611704507

Epoch: 5| Step: 11
Training loss: 1.8527193069458008
Validation loss: 2.1126877665519714

Epoch: 66| Step: 0
Training loss: 2.544736623764038
Validation loss: 2.1106335520744324

Epoch: 5| Step: 1
Training loss: 2.5576388835906982
Validation loss: 2.112924113869667

Epoch: 5| Step: 2
Training loss: 1.7415030002593994
Validation loss: 2.113572413722674

Epoch: 5| Step: 3
Training loss: 2.7283778190612793
Validation loss: 2.112043648958206

Epoch: 5| Step: 4
Training loss: 2.582181215286255
Validation loss: 2.1165439834197364

Epoch: 5| Step: 5
Training loss: 2.229261875152588
Validation loss: 2.114022195339203

Epoch: 5| Step: 6
Training loss: 2.862640857696533
Validation loss: 2.1075818091630936

Epoch: 5| Step: 7
Training loss: 1.542536973953247
Validation loss: 2.101563190420469

Epoch: 5| Step: 8
Training loss: 2.3805527687072754
Validation loss: 2.0962825417518616

Epoch: 5| Step: 9
Training loss: 1.748843789100647
Validation loss: 2.1035669843355813

Epoch: 5| Step: 10
Training loss: 2.257272720336914
Validation loss: 2.1022196859121323

Epoch: 5| Step: 11
Training loss: 2.2218918800354004
Validation loss: 2.0958112180233

Epoch: 67| Step: 0
Training loss: 2.06221604347229
Validation loss: 2.097256511449814

Epoch: 5| Step: 1
Training loss: 2.1302192211151123
Validation loss: 2.096854344010353

Epoch: 5| Step: 2
Training loss: 2.299898862838745
Validation loss: 2.0955263525247574

Epoch: 5| Step: 3
Training loss: 1.7908207178115845
Validation loss: 2.0951893677314124

Epoch: 5| Step: 4
Training loss: 2.3972573280334473
Validation loss: 2.094409704208374

Epoch: 5| Step: 5
Training loss: 2.799107074737549
Validation loss: 2.094646061460177

Epoch: 5| Step: 6
Training loss: 2.1290743350982666
Validation loss: 2.0910227298736572

Epoch: 5| Step: 7
Training loss: 2.296738624572754
Validation loss: 2.0905850181976953

Epoch: 5| Step: 8
Training loss: 2.196866750717163
Validation loss: 2.0889490296443305

Epoch: 5| Step: 9
Training loss: 2.494504451751709
Validation loss: 2.087361072500547

Epoch: 5| Step: 10
Training loss: 2.46697735786438
Validation loss: 2.0843550711870193

Epoch: 5| Step: 11
Training loss: 2.03056001663208
Validation loss: 2.0875667730967202

Epoch: 68| Step: 0
Training loss: 2.436650276184082
Validation loss: 2.0843272507190704

Epoch: 5| Step: 1
Training loss: 2.2870261669158936
Validation loss: 2.087925841410955

Epoch: 5| Step: 2
Training loss: 2.5635361671447754
Validation loss: 2.1116085996230445

Epoch: 5| Step: 3
Training loss: 2.2825729846954346
Validation loss: 2.122614324092865

Epoch: 5| Step: 4
Training loss: 2.6307880878448486
Validation loss: 2.118322968482971

Epoch: 5| Step: 5
Training loss: 2.3119122982025146
Validation loss: 2.090605452656746

Epoch: 5| Step: 6
Training loss: 2.2758049964904785
Validation loss: 2.0780018915732703

Epoch: 5| Step: 7
Training loss: 2.129751682281494
Validation loss: 2.0795992414156594

Epoch: 5| Step: 8
Training loss: 2.450488805770874
Validation loss: 2.08816526333491

Epoch: 5| Step: 9
Training loss: 1.430812954902649
Validation loss: 2.0956552575031915

Epoch: 5| Step: 10
Training loss: 2.2809510231018066
Validation loss: 2.0953243325153985

Epoch: 5| Step: 11
Training loss: 1.7932016849517822
Validation loss: 2.100903113683065

Epoch: 69| Step: 0
Training loss: 2.506215810775757
Validation loss: 2.108126605550448

Epoch: 5| Step: 1
Training loss: 2.309605121612549
Validation loss: 2.1190041253964105

Epoch: 5| Step: 2
Training loss: 1.7656173706054688
Validation loss: 2.1287761628627777

Epoch: 5| Step: 3
Training loss: 2.3406436443328857
Validation loss: 2.1168881009022393

Epoch: 5| Step: 4
Training loss: 2.5750646591186523
Validation loss: 2.110313574473063

Epoch: 5| Step: 5
Training loss: 2.095736026763916
Validation loss: 2.1094640543063483

Epoch: 5| Step: 6
Training loss: 2.1680386066436768
Validation loss: 2.10103369752566

Epoch: 5| Step: 7
Training loss: 2.6671929359436035
Validation loss: 2.0955620259046555

Epoch: 5| Step: 8
Training loss: 2.545973539352417
Validation loss: 2.090887909134229

Epoch: 5| Step: 9
Training loss: 1.6566894054412842
Validation loss: 2.0871626337369285

Epoch: 5| Step: 10
Training loss: 2.5107882022857666
Validation loss: 2.0879987627267838

Epoch: 5| Step: 11
Training loss: 2.137808322906494
Validation loss: 2.0840766429901123

Epoch: 70| Step: 0
Training loss: 2.5321590900421143
Validation loss: 2.0795309642950692

Epoch: 5| Step: 1
Training loss: 1.9514261484146118
Validation loss: 2.0718541940053306

Epoch: 5| Step: 2
Training loss: 2.7369110584259033
Validation loss: 2.071430519223213

Epoch: 5| Step: 3
Training loss: 1.983192801475525
Validation loss: 2.069926788409551

Epoch: 5| Step: 4
Training loss: 1.9517847299575806
Validation loss: 2.065595328807831

Epoch: 5| Step: 5
Training loss: 2.048938274383545
Validation loss: 2.064382870992025

Epoch: 5| Step: 6
Training loss: 2.196605682373047
Validation loss: 2.0627818604310355

Epoch: 5| Step: 7
Training loss: 2.676417112350464
Validation loss: 2.058731640378634

Epoch: 5| Step: 8
Training loss: 2.2478249073028564
Validation loss: 2.069360986351967

Epoch: 5| Step: 9
Training loss: 2.6711480617523193
Validation loss: 2.0636790494124093

Epoch: 5| Step: 10
Training loss: 1.6838464736938477
Validation loss: 2.055375888943672

Epoch: 5| Step: 11
Training loss: 2.850801467895508
Validation loss: 2.06186805665493

Epoch: 71| Step: 0
Training loss: 2.157284736633301
Validation loss: 2.051562483112017

Epoch: 5| Step: 1
Training loss: 2.484389066696167
Validation loss: 2.0575557500123978

Epoch: 5| Step: 2
Training loss: 2.653233051300049
Validation loss: 2.0515847951173782

Epoch: 5| Step: 3
Training loss: 2.1379432678222656
Validation loss: 2.05513796210289

Epoch: 5| Step: 4
Training loss: 2.1452412605285645
Validation loss: 2.055490881204605

Epoch: 5| Step: 5
Training loss: 2.029684066772461
Validation loss: 2.0511611501375833

Epoch: 5| Step: 6
Training loss: 2.00707745552063
Validation loss: 2.0485604455073676

Epoch: 5| Step: 7
Training loss: 2.4032998085021973
Validation loss: 2.054820497830709

Epoch: 5| Step: 8
Training loss: 2.134608507156372
Validation loss: 2.0546571016311646

Epoch: 5| Step: 9
Training loss: 1.9275325536727905
Validation loss: 2.04836139579614

Epoch: 5| Step: 10
Training loss: 2.504842519760132
Validation loss: 2.0517978022495904

Epoch: 5| Step: 11
Training loss: 2.7191555500030518
Validation loss: 2.0520572513341904

Epoch: 72| Step: 0
Training loss: 2.1721551418304443
Validation loss: 2.050226400295893

Epoch: 5| Step: 1
Training loss: 2.176146984100342
Validation loss: 2.0516694486141205

Epoch: 5| Step: 2
Training loss: 2.1099863052368164
Validation loss: 2.076781372229258

Epoch: 5| Step: 3
Training loss: 2.4775943756103516
Validation loss: 2.092933565378189

Epoch: 5| Step: 4
Training loss: 2.143522262573242
Validation loss: 2.094011440873146

Epoch: 5| Step: 5
Training loss: 2.6139464378356934
Validation loss: 2.0750126043955484

Epoch: 5| Step: 6
Training loss: 2.324860095977783
Validation loss: 2.0663321018218994

Epoch: 5| Step: 7
Training loss: 2.414963722229004
Validation loss: 2.055407777428627

Epoch: 5| Step: 8
Training loss: 2.440215587615967
Validation loss: 2.0587967981894812

Epoch: 5| Step: 9
Training loss: 1.9538984298706055
Validation loss: 2.049268886446953

Epoch: 5| Step: 10
Training loss: 2.038386583328247
Validation loss: 2.0444894979397454

Epoch: 5| Step: 11
Training loss: 1.7030984163284302
Validation loss: 2.050956924756368

Epoch: 73| Step: 0
Training loss: 1.9749101400375366
Validation loss: 2.0500841538111367

Epoch: 5| Step: 1
Training loss: 2.443251132965088
Validation loss: 2.0516922970612845

Epoch: 5| Step: 2
Training loss: 2.29337739944458
Validation loss: 2.051400144894918

Epoch: 5| Step: 3
Training loss: 1.9631130695343018
Validation loss: 2.054905340075493

Epoch: 5| Step: 4
Training loss: 1.7762978076934814
Validation loss: 2.0597120821475983

Epoch: 5| Step: 5
Training loss: 1.7297874689102173
Validation loss: 2.055759603778521

Epoch: 5| Step: 6
Training loss: 2.183140277862549
Validation loss: 2.058603043357531

Epoch: 5| Step: 7
Training loss: 2.4260334968566895
Validation loss: 2.0539450347423553

Epoch: 5| Step: 8
Training loss: 2.5315101146698
Validation loss: 2.0549424290657043

Epoch: 5| Step: 9
Training loss: 2.1480062007904053
Validation loss: 2.041064441204071

Epoch: 5| Step: 10
Training loss: 2.888563632965088
Validation loss: 2.0450141231218972

Epoch: 5| Step: 11
Training loss: 2.9488048553466797
Validation loss: 2.034387081861496

Epoch: 74| Step: 0
Training loss: 1.780059576034546
Validation loss: 2.0338544249534607

Epoch: 5| Step: 1
Training loss: 2.359393358230591
Validation loss: 2.030020132660866

Epoch: 5| Step: 2
Training loss: 2.060408353805542
Validation loss: 2.035275479157766

Epoch: 5| Step: 3
Training loss: 2.635502576828003
Validation loss: 2.034197131792704

Epoch: 5| Step: 4
Training loss: 2.167675018310547
Validation loss: 2.0325848956902823

Epoch: 5| Step: 5
Training loss: 1.9825408458709717
Validation loss: 2.0304803053538003

Epoch: 5| Step: 6
Training loss: 2.246188163757324
Validation loss: 2.0335116386413574

Epoch: 5| Step: 7
Training loss: 1.8256094455718994
Validation loss: 2.031116063396136

Epoch: 5| Step: 8
Training loss: 2.3881781101226807
Validation loss: 2.0318682491779327

Epoch: 5| Step: 9
Training loss: 2.2031166553497314
Validation loss: 2.035038933157921

Epoch: 5| Step: 10
Training loss: 2.7440950870513916
Validation loss: 2.0325394670168557

Epoch: 5| Step: 11
Training loss: 2.1055192947387695
Validation loss: 2.035164495309194

Epoch: 75| Step: 0
Training loss: 2.070829391479492
Validation loss: 2.0371972968180976

Epoch: 5| Step: 1
Training loss: 1.6902450323104858
Validation loss: 2.03517613808314

Epoch: 5| Step: 2
Training loss: 2.5527873039245605
Validation loss: 2.0330986777941384

Epoch: 5| Step: 3
Training loss: 2.1772260665893555
Validation loss: 2.0294482360283532

Epoch: 5| Step: 4
Training loss: 2.362473249435425
Validation loss: 2.032788539926211

Epoch: 5| Step: 5
Training loss: 2.3995280265808105
Validation loss: 2.0281294882297516

Epoch: 5| Step: 6
Training loss: 2.260410785675049
Validation loss: 2.022239754597346

Epoch: 5| Step: 7
Training loss: 1.4944612979888916
Validation loss: 2.0297911465168

Epoch: 5| Step: 8
Training loss: 2.660179853439331
Validation loss: 2.034912591179212

Epoch: 5| Step: 9
Training loss: 2.234614610671997
Validation loss: 2.0289794902006784

Epoch: 5| Step: 10
Training loss: 2.332852602005005
Validation loss: 2.0279346058766046

Epoch: 5| Step: 11
Training loss: 2.6003589630126953
Validation loss: 2.0213379114866257

Epoch: 76| Step: 0
Training loss: 2.2175917625427246
Validation loss: 2.0316768487294516

Epoch: 5| Step: 1
Training loss: 1.9445101022720337
Validation loss: 2.030926684538523

Epoch: 5| Step: 2
Training loss: 1.64419686794281
Validation loss: 2.0263490428527198

Epoch: 5| Step: 3
Training loss: 2.485377788543701
Validation loss: 2.0304600248734155

Epoch: 5| Step: 4
Training loss: 1.4398794174194336
Validation loss: 2.029748727877935

Epoch: 5| Step: 5
Training loss: 2.7254836559295654
Validation loss: 2.0261885871489844

Epoch: 5| Step: 6
Training loss: 2.6631243228912354
Validation loss: 2.0289596219857535

Epoch: 5| Step: 7
Training loss: 2.4297597408294678
Validation loss: 2.022632986307144

Epoch: 5| Step: 8
Training loss: 2.0268826484680176
Validation loss: 2.024028862516085

Epoch: 5| Step: 9
Training loss: 2.3778767585754395
Validation loss: 2.028358985980352

Epoch: 5| Step: 10
Training loss: 2.24165415763855
Validation loss: 2.0212469696998596

Epoch: 5| Step: 11
Training loss: 2.7409563064575195
Validation loss: 2.0224710504213967

Epoch: 77| Step: 0
Training loss: 2.272461414337158
Validation loss: 2.0300806810458503

Epoch: 5| Step: 1
Training loss: 2.3882267475128174
Validation loss: 2.027269721031189

Epoch: 5| Step: 2
Training loss: 2.599278688430786
Validation loss: 2.0298856695493064

Epoch: 5| Step: 3
Training loss: 2.332460641860962
Validation loss: 2.0265926321347556

Epoch: 5| Step: 4
Training loss: 1.9440586566925049
Validation loss: 2.0296960969765983

Epoch: 5| Step: 5
Training loss: 2.563270330429077
Validation loss: 2.033773109316826

Epoch: 5| Step: 6
Training loss: 1.8918548822402954
Validation loss: 2.0374078353246055

Epoch: 5| Step: 7
Training loss: 2.0543417930603027
Validation loss: 2.0286025752623877

Epoch: 5| Step: 8
Training loss: 2.1630401611328125
Validation loss: 2.031919553875923

Epoch: 5| Step: 9
Training loss: 2.0307507514953613
Validation loss: 2.023290435473124

Epoch: 5| Step: 10
Training loss: 1.8488401174545288
Validation loss: 2.024848222732544

Epoch: 5| Step: 11
Training loss: 2.863126754760742
Validation loss: 2.0135425130526223

Epoch: 78| Step: 0
Training loss: 2.5933573246002197
Validation loss: 2.0154436926047006

Epoch: 5| Step: 1
Training loss: 2.7822296619415283
Validation loss: 2.0201586882273355

Epoch: 5| Step: 2
Training loss: 1.6373188495635986
Validation loss: 2.0380593140920005

Epoch: 5| Step: 3
Training loss: 1.8202823400497437
Validation loss: 2.031293973326683

Epoch: 5| Step: 4
Training loss: 2.6160149574279785
Validation loss: 2.029192551970482

Epoch: 5| Step: 5
Training loss: 2.0269627571105957
Validation loss: 2.0419353246688843

Epoch: 5| Step: 6
Training loss: 2.001477003097534
Validation loss: 2.0569244821866355

Epoch: 5| Step: 7
Training loss: 2.182516098022461
Validation loss: 2.054596096277237

Epoch: 5| Step: 8
Training loss: 2.0563323497772217
Validation loss: 2.0332913547754288

Epoch: 5| Step: 9
Training loss: 2.355212688446045
Validation loss: 2.02578337987264

Epoch: 5| Step: 10
Training loss: 2.194758176803589
Validation loss: 2.0217653661966324

Epoch: 5| Step: 11
Training loss: 2.8669238090515137
Validation loss: 2.0302112251520157

Epoch: 79| Step: 0
Training loss: 2.1073577404022217
Validation loss: 2.0268628845612207

Epoch: 5| Step: 1
Training loss: 2.17556095123291
Validation loss: 2.031740814447403

Epoch: 5| Step: 2
Training loss: 2.3146252632141113
Validation loss: 2.0276372085014978

Epoch: 5| Step: 3
Training loss: 2.2036221027374268
Validation loss: 2.0345287173986435

Epoch: 5| Step: 4
Training loss: 2.0991032123565674
Validation loss: 2.0353835622469583

Epoch: 5| Step: 5
Training loss: 1.9856764078140259
Validation loss: 2.0343603044748306

Epoch: 5| Step: 6
Training loss: 1.9325393438339233
Validation loss: 2.0318070352077484

Epoch: 5| Step: 7
Training loss: 2.2560806274414062
Validation loss: 2.0270911157131195

Epoch: 5| Step: 8
Training loss: 2.417086362838745
Validation loss: 2.026176795363426

Epoch: 5| Step: 9
Training loss: 2.4507346153259277
Validation loss: 2.0224389135837555

Epoch: 5| Step: 10
Training loss: 2.21966290473938
Validation loss: 2.0192254930734634

Epoch: 5| Step: 11
Training loss: 2.9633450508117676
Validation loss: 2.0166877806186676

Epoch: 80| Step: 0
Training loss: 2.144991874694824
Validation loss: 2.017203003168106

Epoch: 5| Step: 1
Training loss: 2.3247992992401123
Validation loss: 2.011693591872851

Epoch: 5| Step: 2
Training loss: 2.394615888595581
Validation loss: 2.0140059490998587

Epoch: 5| Step: 3
Training loss: 2.251554012298584
Validation loss: 2.024388149380684

Epoch: 5| Step: 4
Training loss: 2.3786962032318115
Validation loss: 2.028126522898674

Epoch: 5| Step: 5
Training loss: 1.978532075881958
Validation loss: 2.030652488271395

Epoch: 5| Step: 6
Training loss: 2.6209723949432373
Validation loss: 2.0261162718137107

Epoch: 5| Step: 7
Training loss: 2.2056920528411865
Validation loss: 2.0310628563165665

Epoch: 5| Step: 8
Training loss: 2.0454962253570557
Validation loss: 2.0200087428092957

Epoch: 5| Step: 9
Training loss: 2.0535836219787598
Validation loss: 2.0144960433244705

Epoch: 5| Step: 10
Training loss: 2.1928000450134277
Validation loss: 2.0140793273846307

Epoch: 5| Step: 11
Training loss: 0.37788665294647217
Validation loss: 2.01226336757342

Epoch: 81| Step: 0
Training loss: 2.0373904705047607
Validation loss: 2.0146579643090567

Epoch: 5| Step: 1
Training loss: 2.5752933025360107
Validation loss: 2.011916294693947

Epoch: 5| Step: 2
Training loss: 1.719373106956482
Validation loss: 2.011453946431478

Epoch: 5| Step: 3
Training loss: 1.7155990600585938
Validation loss: 2.0186342000961304

Epoch: 5| Step: 4
Training loss: 2.796772003173828
Validation loss: 2.023508384823799

Epoch: 5| Step: 5
Training loss: 2.5043296813964844
Validation loss: 2.008328596750895

Epoch: 5| Step: 6
Training loss: 2.0456886291503906
Validation loss: 2.0125192403793335

Epoch: 5| Step: 7
Training loss: 2.67242431640625
Validation loss: 2.018207256992658

Epoch: 5| Step: 8
Training loss: 1.9199371337890625
Validation loss: 2.0061944127082825

Epoch: 5| Step: 9
Training loss: 2.107755661010742
Validation loss: 2.008955796559652

Epoch: 5| Step: 10
Training loss: 2.0097811222076416
Validation loss: 2.012377063433329

Epoch: 5| Step: 11
Training loss: 1.8527299165725708
Validation loss: 2.014474997917811

Epoch: 82| Step: 0
Training loss: 1.7217251062393188
Validation loss: 2.0102094958225885

Epoch: 5| Step: 1
Training loss: 1.7916008234024048
Validation loss: 2.010569045941035

Epoch: 5| Step: 2
Training loss: 1.7568527460098267
Validation loss: 2.0112686306238174

Epoch: 5| Step: 3
Training loss: 2.4014055728912354
Validation loss: 2.015744293729464

Epoch: 5| Step: 4
Training loss: 1.5802199840545654
Validation loss: 2.007384474078814

Epoch: 5| Step: 5
Training loss: 2.239841938018799
Validation loss: 2.00755882759889

Epoch: 5| Step: 6
Training loss: 2.8106722831726074
Validation loss: 2.011998732884725

Epoch: 5| Step: 7
Training loss: 2.6982696056365967
Validation loss: 2.0158634185791016

Epoch: 5| Step: 8
Training loss: 1.9277231693267822
Validation loss: 2.0233233273029327

Epoch: 5| Step: 9
Training loss: 2.663329601287842
Validation loss: 2.0215028872092566

Epoch: 5| Step: 10
Training loss: 2.5754053592681885
Validation loss: 2.029385656118393

Epoch: 5| Step: 11
Training loss: 1.7375365495681763
Validation loss: 2.026777242620786

Epoch: 83| Step: 0
Training loss: 2.1894679069519043
Validation loss: 2.010154257218043

Epoch: 5| Step: 1
Training loss: 2.2558186054229736
Validation loss: 2.0098190208276114

Epoch: 5| Step: 2
Training loss: 2.0190773010253906
Validation loss: 2.008510261774063

Epoch: 5| Step: 3
Training loss: 2.42995023727417
Validation loss: 2.005250866214434

Epoch: 5| Step: 4
Training loss: 2.573059558868408
Validation loss: 2.007387379805247

Epoch: 5| Step: 5
Training loss: 2.6486499309539795
Validation loss: 2.015613337357839

Epoch: 5| Step: 6
Training loss: 1.981769323348999
Validation loss: 2.030691275993983

Epoch: 5| Step: 7
Training loss: 1.7210102081298828
Validation loss: 2.0267555018266044

Epoch: 5| Step: 8
Training loss: 2.396472454071045
Validation loss: 2.020277957121531

Epoch: 5| Step: 9
Training loss: 2.2896056175231934
Validation loss: 2.022597461938858

Epoch: 5| Step: 10
Training loss: 1.7876189947128296
Validation loss: 2.03057761490345

Epoch: 5| Step: 11
Training loss: 0.4351893663406372
Validation loss: 2.029944827159246

Epoch: 84| Step: 0
Training loss: 2.1344988346099854
Validation loss: 2.0301952908436456

Epoch: 5| Step: 1
Training loss: 2.227173328399658
Validation loss: 2.0187901804844537

Epoch: 5| Step: 2
Training loss: 2.0692062377929688
Validation loss: 2.0359703501065574

Epoch: 5| Step: 3
Training loss: 1.5847855806350708
Validation loss: 2.0297916581233344

Epoch: 5| Step: 4
Training loss: 2.4112250804901123
Validation loss: 2.026345729827881

Epoch: 5| Step: 5
Training loss: 2.2067694664001465
Validation loss: 2.01658666630586

Epoch: 5| Step: 6
Training loss: 2.532400131225586
Validation loss: 2.0142456392447152

Epoch: 5| Step: 7
Training loss: 1.9255012273788452
Validation loss: 2.0078125298023224

Epoch: 5| Step: 8
Training loss: 2.3300325870513916
Validation loss: 2.0098455051581063

Epoch: 5| Step: 9
Training loss: 2.352271795272827
Validation loss: 2.0154476910829544

Epoch: 5| Step: 10
Training loss: 2.0745835304260254
Validation loss: 2.009644294778506

Epoch: 5| Step: 11
Training loss: 2.82545804977417
Validation loss: 2.0076704223950705

Epoch: 85| Step: 0
Training loss: 1.5621554851531982
Validation loss: 2.003618617852529

Epoch: 5| Step: 1
Training loss: 2.488646984100342
Validation loss: 2.010330706834793

Epoch: 5| Step: 2
Training loss: 2.3616182804107666
Validation loss: 2.0066518684228263

Epoch: 5| Step: 3
Training loss: 2.1595568656921387
Validation loss: 2.0293155511220298

Epoch: 5| Step: 4
Training loss: 2.2489688396453857
Validation loss: 2.059499820073446

Epoch: 5| Step: 5
Training loss: 1.3162171840667725
Validation loss: 2.059587756792704

Epoch: 5| Step: 6
Training loss: 3.035522937774658
Validation loss: 2.083925093213717

Epoch: 5| Step: 7
Training loss: 2.2266860008239746
Validation loss: 2.0757136940956116

Epoch: 5| Step: 8
Training loss: 2.362248182296753
Validation loss: 2.0506827384233475

Epoch: 5| Step: 9
Training loss: 2.5225300788879395
Validation loss: 2.0479979316393533

Epoch: 5| Step: 10
Training loss: 1.8911418914794922
Validation loss: 2.0417712728182473

Epoch: 5| Step: 11
Training loss: 2.6239705085754395
Validation loss: 2.0276254216829934

Epoch: 86| Step: 0
Training loss: 2.176967144012451
Validation loss: 2.02159554262956

Epoch: 5| Step: 1
Training loss: 1.9573253393173218
Validation loss: 2.0227741599082947

Epoch: 5| Step: 2
Training loss: 2.1778199672698975
Validation loss: 2.015985849002997

Epoch: 5| Step: 3
Training loss: 2.013829469680786
Validation loss: 2.01609605550766

Epoch: 5| Step: 4
Training loss: 2.2655601501464844
Validation loss: 2.0242974857489267

Epoch: 5| Step: 5
Training loss: 2.360888719558716
Validation loss: 2.0216585944096246

Epoch: 5| Step: 6
Training loss: 1.9565969705581665
Validation loss: 2.023045668999354

Epoch: 5| Step: 7
Training loss: 2.1068387031555176
Validation loss: 2.022653246919314

Epoch: 5| Step: 8
Training loss: 2.497687816619873
Validation loss: 2.015704800685247

Epoch: 5| Step: 9
Training loss: 2.04457426071167
Validation loss: 2.0190907617410025

Epoch: 5| Step: 10
Training loss: 2.1711432933807373
Validation loss: 2.0098602324724197

Epoch: 5| Step: 11
Training loss: 3.2432432174682617
Validation loss: 2.010269636909167

Epoch: 87| Step: 0
Training loss: 1.7100461721420288
Validation loss: 2.0128616193930307

Epoch: 5| Step: 1
Training loss: 2.4451212882995605
Validation loss: 2.009673923254013

Epoch: 5| Step: 2
Training loss: 2.497119426727295
Validation loss: 2.0058315247297287

Epoch: 5| Step: 3
Training loss: 1.630748987197876
Validation loss: 1.9997545381387074

Epoch: 5| Step: 4
Training loss: 2.0657424926757812
Validation loss: 2.0090641180674234

Epoch: 5| Step: 5
Training loss: 2.5560150146484375
Validation loss: 2.0011813392241797

Epoch: 5| Step: 6
Training loss: 2.654154062271118
Validation loss: 2.0074000358581543

Epoch: 5| Step: 7
Training loss: 2.1290194988250732
Validation loss: 1.999201665321986

Epoch: 5| Step: 8
Training loss: 2.2080698013305664
Validation loss: 2.0082150350014367

Epoch: 5| Step: 9
Training loss: 1.622826337814331
Validation loss: 2.0057679265737534

Epoch: 5| Step: 10
Training loss: 2.17586088180542
Validation loss: 2.0172497779130936

Epoch: 5| Step: 11
Training loss: 3.0582618713378906
Validation loss: 2.0224895030260086

Epoch: 88| Step: 0
Training loss: 2.4139914512634277
Validation loss: 2.0169180184602737

Epoch: 5| Step: 1
Training loss: 2.128728151321411
Validation loss: 2.0151232481002808

Epoch: 5| Step: 2
Training loss: 2.1235191822052
Validation loss: 2.0110204219818115

Epoch: 5| Step: 3
Training loss: 2.373950719833374
Validation loss: 2.018883923689524

Epoch: 5| Step: 4
Training loss: 1.994823694229126
Validation loss: 2.026037489374479

Epoch: 5| Step: 5
Training loss: 2.0192933082580566
Validation loss: 2.034167895714442

Epoch: 5| Step: 6
Training loss: 2.3655800819396973
Validation loss: 2.036424070596695

Epoch: 5| Step: 7
Training loss: 1.7255300283432007
Validation loss: 2.0191409389177957

Epoch: 5| Step: 8
Training loss: 2.6321511268615723
Validation loss: 2.0144544889529548

Epoch: 5| Step: 9
Training loss: 1.9694935083389282
Validation loss: 2.0069401810566583

Epoch: 5| Step: 10
Training loss: 2.048201084136963
Validation loss: 2.009952242175738

Epoch: 5| Step: 11
Training loss: 2.44260573387146
Validation loss: 2.006959373752276

Epoch: 89| Step: 0
Training loss: 2.314197540283203
Validation loss: 2.0089416801929474

Epoch: 5| Step: 1
Training loss: 1.9827592372894287
Validation loss: 2.0180293172597885

Epoch: 5| Step: 2
Training loss: 2.5242953300476074
Validation loss: 2.025934894879659

Epoch: 5| Step: 3
Training loss: 2.569061517715454
Validation loss: 2.030002703269323

Epoch: 5| Step: 4
Training loss: 1.876468300819397
Validation loss: 2.037762999534607

Epoch: 5| Step: 5
Training loss: 2.222719192504883
Validation loss: 2.045442134141922

Epoch: 5| Step: 6
Training loss: 2.195444107055664
Validation loss: 2.0472459346055984

Epoch: 5| Step: 7
Training loss: 2.151498794555664
Validation loss: 2.062158097823461

Epoch: 5| Step: 8
Training loss: 2.1575634479522705
Validation loss: 2.052055930097898

Epoch: 5| Step: 9
Training loss: 2.2121453285217285
Validation loss: 2.051512971520424

Epoch: 5| Step: 10
Training loss: 1.9874188899993896
Validation loss: 2.049010912577311

Epoch: 5| Step: 11
Training loss: 2.81355619430542
Validation loss: 2.0411673734585443

Epoch: 90| Step: 0
Training loss: 1.8091943264007568
Validation loss: 2.0311397363742194

Epoch: 5| Step: 1
Training loss: 2.2574400901794434
Validation loss: 2.029641737540563

Epoch: 5| Step: 2
Training loss: 2.538853883743286
Validation loss: 2.0289501448472342

Epoch: 5| Step: 3
Training loss: 2.011613368988037
Validation loss: 2.037777324517568

Epoch: 5| Step: 4
Training loss: 2.3659255504608154
Validation loss: 2.033980816602707

Epoch: 5| Step: 5
Training loss: 1.9922826290130615
Validation loss: 2.02864562968413

Epoch: 5| Step: 6
Training loss: 1.7804148197174072
Validation loss: 2.0310711165269217

Epoch: 5| Step: 7
Training loss: 2.7931606769561768
Validation loss: 2.013955662647883

Epoch: 5| Step: 8
Training loss: 1.9451558589935303
Validation loss: 2.007892444729805

Epoch: 5| Step: 9
Training loss: 1.9793561697006226
Validation loss: 2.00031416118145

Epoch: 5| Step: 10
Training loss: 2.2457640171051025
Validation loss: 2.0031318118174872

Epoch: 5| Step: 11
Training loss: 2.6575934886932373
Validation loss: 2.0068695892890296

Epoch: 91| Step: 0
Training loss: 2.36987566947937
Validation loss: 2.039873883128166

Epoch: 5| Step: 1
Training loss: 1.7874215841293335
Validation loss: 2.0624602238337197

Epoch: 5| Step: 2
Training loss: 1.9477074146270752
Validation loss: 2.081941013534864

Epoch: 5| Step: 3
Training loss: 1.6284122467041016
Validation loss: 2.0761141578356423

Epoch: 5| Step: 4
Training loss: 2.2452011108398438
Validation loss: 2.068436175584793

Epoch: 5| Step: 5
Training loss: 2.179368495941162
Validation loss: 2.064235364397367

Epoch: 5| Step: 6
Training loss: 2.1182689666748047
Validation loss: 2.047440384825071

Epoch: 5| Step: 7
Training loss: 1.8581161499023438
Validation loss: 2.031719600160917

Epoch: 5| Step: 8
Training loss: 2.9807655811309814
Validation loss: 2.0348704953988395

Epoch: 5| Step: 9
Training loss: 2.494291305541992
Validation loss: 2.0184330344200134

Epoch: 5| Step: 10
Training loss: 2.19509220123291
Validation loss: 2.0145785361528397

Epoch: 5| Step: 11
Training loss: 2.5987257957458496
Validation loss: 2.0141340444485345

Epoch: 92| Step: 0
Training loss: 1.8791736364364624
Validation loss: 1.99972960849603

Epoch: 5| Step: 1
Training loss: 1.9666483402252197
Validation loss: 1.998695249358813

Epoch: 5| Step: 2
Training loss: 2.31330943107605
Validation loss: 2.0040621558825173

Epoch: 5| Step: 3
Training loss: 2.25298810005188
Validation loss: 1.999259243408839

Epoch: 5| Step: 4
Training loss: 1.403130292892456
Validation loss: 2.0006966839234033

Epoch: 5| Step: 5
Training loss: 2.9550321102142334
Validation loss: 2.0000500877698264

Epoch: 5| Step: 6
Training loss: 2.244716167449951
Validation loss: 1.9984815865755081

Epoch: 5| Step: 7
Training loss: 2.376582384109497
Validation loss: 1.9968147824207942

Epoch: 5| Step: 8
Training loss: 2.346308946609497
Validation loss: 1.9991018275419872

Epoch: 5| Step: 9
Training loss: 1.9777435064315796
Validation loss: 2.0070531020561853

Epoch: 5| Step: 10
Training loss: 2.1569671630859375
Validation loss: 2.0023311177889505

Epoch: 5| Step: 11
Training loss: 1.7398754358291626
Validation loss: 2.009462351600329

Epoch: 93| Step: 0
Training loss: 2.061358690261841
Validation loss: 2.017779548962911

Epoch: 5| Step: 1
Training loss: 2.4696764945983887
Validation loss: 2.0316959073146186

Epoch: 5| Step: 2
Training loss: 2.4557533264160156
Validation loss: 2.0279744416475296

Epoch: 5| Step: 3
Training loss: 1.9258735179901123
Validation loss: 2.047573501865069

Epoch: 5| Step: 4
Training loss: 2.19275164604187
Validation loss: 2.0704539070526757

Epoch: 5| Step: 5
Training loss: 1.799290418624878
Validation loss: 2.0637473315000534

Epoch: 5| Step: 6
Training loss: 1.7828550338745117
Validation loss: 2.0464666932821274

Epoch: 5| Step: 7
Training loss: 2.4284729957580566
Validation loss: 2.0392836779356003

Epoch: 5| Step: 8
Training loss: 2.3590023517608643
Validation loss: 2.0254696110884347

Epoch: 5| Step: 9
Training loss: 2.3072779178619385
Validation loss: 2.005523125330607

Epoch: 5| Step: 10
Training loss: 1.8975502252578735
Validation loss: 1.9964341421922047

Epoch: 5| Step: 11
Training loss: 3.033052444458008
Validation loss: 2.0006426821152368

Epoch: 94| Step: 0
Training loss: 2.3041605949401855
Validation loss: 2.0163135876258216

Epoch: 5| Step: 1
Training loss: 1.762037992477417
Validation loss: 2.0286608040332794

Epoch: 5| Step: 2
Training loss: 2.411760091781616
Validation loss: 2.029258370399475

Epoch: 5| Step: 3
Training loss: 1.9746110439300537
Validation loss: 2.0258076389630637

Epoch: 5| Step: 4
Training loss: 2.4485743045806885
Validation loss: 2.0213299492994943

Epoch: 5| Step: 5
Training loss: 1.6711441278457642
Validation loss: 2.0244870533545813

Epoch: 5| Step: 6
Training loss: 2.0697712898254395
Validation loss: 2.0111797402302423

Epoch: 5| Step: 7
Training loss: 2.3921120166778564
Validation loss: 2.012071803212166

Epoch: 5| Step: 8
Training loss: 2.292222261428833
Validation loss: 2.0097287197907767

Epoch: 5| Step: 9
Training loss: 1.7562679052352905
Validation loss: 2.009056309858958

Epoch: 5| Step: 10
Training loss: 2.7158355712890625
Validation loss: 2.00239189962546

Epoch: 5| Step: 11
Training loss: 2.7007384300231934
Validation loss: 2.0029044846693673

Epoch: 95| Step: 0
Training loss: 2.5103297233581543
Validation loss: 1.9964626232783

Epoch: 5| Step: 1
Training loss: 1.3470014333724976
Validation loss: 1.9995710204044979

Epoch: 5| Step: 2
Training loss: 2.417104721069336
Validation loss: 2.003274122873942

Epoch: 5| Step: 3
Training loss: 2.348686695098877
Validation loss: 2.0030073076486588

Epoch: 5| Step: 4
Training loss: 1.9546560049057007
Validation loss: 2.0070146918296814

Epoch: 5| Step: 5
Training loss: 2.6468799114227295
Validation loss: 2.0152096996704736

Epoch: 5| Step: 6
Training loss: 1.9021066427230835
Validation loss: 2.0151467323303223

Epoch: 5| Step: 7
Training loss: 1.3302793502807617
Validation loss: 2.0234596580266953

Epoch: 5| Step: 8
Training loss: 2.402548313140869
Validation loss: 2.024305984377861

Epoch: 5| Step: 9
Training loss: 2.2158102989196777
Validation loss: 2.030590146780014

Epoch: 5| Step: 10
Training loss: 2.5569090843200684
Validation loss: 2.0217230220635733

Epoch: 5| Step: 11
Training loss: 1.991943359375
Validation loss: 2.0223964800437293

Epoch: 96| Step: 0
Training loss: 2.7160725593566895
Validation loss: 2.0253252734740577

Epoch: 5| Step: 1
Training loss: 1.846930742263794
Validation loss: 2.019407346844673

Epoch: 5| Step: 2
Training loss: 2.0206382274627686
Validation loss: 2.013338620464007

Epoch: 5| Step: 3
Training loss: 1.3706120252609253
Validation loss: 2.0150369654099145

Epoch: 5| Step: 4
Training loss: 2.3457133769989014
Validation loss: 2.0185844749212265

Epoch: 5| Step: 5
Training loss: 2.114398241043091
Validation loss: 2.009422332048416

Epoch: 5| Step: 6
Training loss: 1.7213108539581299
Validation loss: 2.0102486660083136

Epoch: 5| Step: 7
Training loss: 2.0494487285614014
Validation loss: 2.01320810119311

Epoch: 5| Step: 8
Training loss: 2.4843850135803223
Validation loss: 2.016588012377421

Epoch: 5| Step: 9
Training loss: 2.3539061546325684
Validation loss: 2.0203818877538047

Epoch: 5| Step: 10
Training loss: 2.523759126663208
Validation loss: 2.0197661171356835

Epoch: 5| Step: 11
Training loss: 2.151327133178711
Validation loss: 2.019573633869489

Epoch: 97| Step: 0
Training loss: 2.028846502304077
Validation loss: 2.0155843098958335

Epoch: 5| Step: 1
Training loss: 2.408825635910034
Validation loss: 2.0154116998116174

Epoch: 5| Step: 2
Training loss: 2.5134117603302
Validation loss: 2.012468452254931

Epoch: 5| Step: 3
Training loss: 1.4964679479599
Validation loss: 2.008614644408226

Epoch: 5| Step: 4
Training loss: 2.3781700134277344
Validation loss: 2.0183005879322686

Epoch: 5| Step: 5
Training loss: 1.6400638818740845
Validation loss: 2.017964949210485

Epoch: 5| Step: 6
Training loss: 2.4460837841033936
Validation loss: 2.01947084069252

Epoch: 5| Step: 7
Training loss: 2.6106340885162354
Validation loss: 2.0227986574172974

Epoch: 5| Step: 8
Training loss: 1.9084364175796509
Validation loss: 2.0231448262929916

Epoch: 5| Step: 9
Training loss: 2.057448625564575
Validation loss: 2.035755048195521

Epoch: 5| Step: 10
Training loss: 2.256251811981201
Validation loss: 2.0615189919869104

Epoch: 5| Step: 11
Training loss: 1.4899128675460815
Validation loss: 2.0549173603455224

Epoch: 98| Step: 0
Training loss: 2.3574564456939697
Validation loss: 2.0293708542982736

Epoch: 5| Step: 1
Training loss: 1.8628984689712524
Validation loss: 2.0307828138271966

Epoch: 5| Step: 2
Training loss: 1.9915097951889038
Validation loss: 2.014331211646398

Epoch: 5| Step: 3
Training loss: 2.188642978668213
Validation loss: 2.010127385457357

Epoch: 5| Step: 4
Training loss: 2.2930102348327637
Validation loss: 1.9986227452754974

Epoch: 5| Step: 5
Training loss: 2.4767563343048096
Validation loss: 2.0054822266101837

Epoch: 5| Step: 6
Training loss: 2.5258355140686035
Validation loss: 1.9978621403376262

Epoch: 5| Step: 7
Training loss: 2.0289673805236816
Validation loss: 1.999136636654536

Epoch: 5| Step: 8
Training loss: 2.094346523284912
Validation loss: 2.0078565776348114

Epoch: 5| Step: 9
Training loss: 2.003289222717285
Validation loss: 2.0008404503266015

Epoch: 5| Step: 10
Training loss: 1.5168216228485107
Validation loss: 2.0104932437340417

Epoch: 5| Step: 11
Training loss: 2.528221607208252
Validation loss: 2.0042343735694885

Epoch: 99| Step: 0
Training loss: 2.3695578575134277
Validation loss: 2.005583946903547

Epoch: 5| Step: 1
Training loss: 2.255650758743286
Validation loss: 1.9891993701457977

Epoch: 5| Step: 2
Training loss: 1.954713225364685
Validation loss: 2.004787713289261

Epoch: 5| Step: 3
Training loss: 2.00384783744812
Validation loss: 2.0018183141946793

Epoch: 5| Step: 4
Training loss: 2.246626377105713
Validation loss: 2.00027667482694

Epoch: 5| Step: 5
Training loss: 2.202235698699951
Validation loss: 2.0080489863952002

Epoch: 5| Step: 6
Training loss: 2.175741672515869
Validation loss: 2.0060086299975715

Epoch: 5| Step: 7
Training loss: 2.255441188812256
Validation loss: 1.9997108976046245

Epoch: 5| Step: 8
Training loss: 1.8756914138793945
Validation loss: 1.999831552306811

Epoch: 5| Step: 9
Training loss: 2.0613160133361816
Validation loss: 1.99483156700929

Epoch: 5| Step: 10
Training loss: 2.2123465538024902
Validation loss: 2.001470535993576

Epoch: 5| Step: 11
Training loss: 1.0957854986190796
Validation loss: 2.0110084116458893

Epoch: 100| Step: 0
Training loss: 2.0669987201690674
Validation loss: 2.0141210605700812

Epoch: 5| Step: 1
Training loss: 1.7201893329620361
Validation loss: 2.0044831037521362

Epoch: 5| Step: 2
Training loss: 2.486971139907837
Validation loss: 2.004743014772733

Epoch: 5| Step: 3
Training loss: 2.2446117401123047
Validation loss: 2.0233047008514404

Epoch: 5| Step: 4
Training loss: 1.5226396322250366
Validation loss: 2.012993494669596

Epoch: 5| Step: 5
Training loss: 2.046553134918213
Validation loss: 2.0084726164738336

Epoch: 5| Step: 6
Training loss: 2.36929988861084
Validation loss: 2.0011270195245743

Epoch: 5| Step: 7
Training loss: 1.9882723093032837
Validation loss: 2.011348456144333

Epoch: 5| Step: 8
Training loss: 2.5708603858947754
Validation loss: 2.0107744385798774

Epoch: 5| Step: 9
Training loss: 1.9133589267730713
Validation loss: 2.0210105031728745

Epoch: 5| Step: 10
Training loss: 2.4335684776306152
Validation loss: 2.0115422954161963

Epoch: 5| Step: 11
Training loss: 2.169600486755371
Validation loss: 2.0090158780415854

Epoch: 101| Step: 0
Training loss: 2.4739766120910645
Validation loss: 2.026765356461207

Epoch: 5| Step: 1
Training loss: 2.4351494312286377
Validation loss: 2.0232811868190765

Epoch: 5| Step: 2
Training loss: 1.9842536449432373
Validation loss: 2.0266075879335403

Epoch: 5| Step: 3
Training loss: 1.986363172531128
Validation loss: 2.018825739622116

Epoch: 5| Step: 4
Training loss: 1.4670177698135376
Validation loss: 2.053742448488871

Epoch: 5| Step: 5
Training loss: 2.1121838092803955
Validation loss: 2.036334753036499

Epoch: 5| Step: 6
Training loss: 2.6393542289733887
Validation loss: 2.044952690601349

Epoch: 5| Step: 7
Training loss: 2.0811164379119873
Validation loss: 2.0328603386878967

Epoch: 5| Step: 8
Training loss: 2.0804224014282227
Validation loss: 2.0313841005166373

Epoch: 5| Step: 9
Training loss: 1.8705203533172607
Validation loss: 2.017842228213946

Epoch: 5| Step: 10
Training loss: 2.298740863800049
Validation loss: 2.0232126216093698

Epoch: 5| Step: 11
Training loss: 1.8173030614852905
Validation loss: 2.037001391251882

Epoch: 102| Step: 0
Training loss: 1.7932288646697998
Validation loss: 2.0199740727742515

Epoch: 5| Step: 1
Training loss: 2.0414278507232666
Validation loss: 2.0146355032920837

Epoch: 5| Step: 2
Training loss: 2.089632511138916
Validation loss: 2.0075785567363105

Epoch: 5| Step: 3
Training loss: 2.639592170715332
Validation loss: 2.016256645321846

Epoch: 5| Step: 4
Training loss: 1.4247300624847412
Validation loss: 2.001775955160459

Epoch: 5| Step: 5
Training loss: 2.9632210731506348
Validation loss: 2.001325478156408

Epoch: 5| Step: 6
Training loss: 2.4291253089904785
Validation loss: 2.0128569900989532

Epoch: 5| Step: 7
Training loss: 2.2695770263671875
Validation loss: 2.0072357058525085

Epoch: 5| Step: 8
Training loss: 1.940391182899475
Validation loss: 1.995915412902832

Epoch: 5| Step: 9
Training loss: 1.6906979084014893
Validation loss: 2.0124259988466897

Epoch: 5| Step: 10
Training loss: 2.436131000518799
Validation loss: 2.005176658431689

Epoch: 5| Step: 11
Training loss: 1.2865784168243408
Validation loss: 2.008108675479889

Epoch: 103| Step: 0
Training loss: 2.27034068107605
Validation loss: 2.0033256063858667

Epoch: 5| Step: 1
Training loss: 2.779571294784546
Validation loss: 2.0140514175097146

Epoch: 5| Step: 2
Training loss: 2.024271011352539
Validation loss: 2.0151493549346924

Epoch: 5| Step: 3
Training loss: 2.093449115753174
Validation loss: 2.0251651058594384

Epoch: 5| Step: 4
Training loss: 2.0599594116210938
Validation loss: 2.0382031003634133

Epoch: 5| Step: 5
Training loss: 1.4007185697555542
Validation loss: 2.0265865325927734

Epoch: 5| Step: 6
Training loss: 1.8955638408660889
Validation loss: 2.0480752289295197

Epoch: 5| Step: 7
Training loss: 2.724332094192505
Validation loss: 2.0367161631584167

Epoch: 5| Step: 8
Training loss: 1.86452317237854
Validation loss: 2.0407756666342416

Epoch: 5| Step: 9
Training loss: 2.1853017807006836
Validation loss: 2.042867138981819

Epoch: 5| Step: 10
Training loss: 2.0169596672058105
Validation loss: 2.0344941715399423

Epoch: 5| Step: 11
Training loss: 2.3985936641693115
Validation loss: 2.011832336584727

Epoch: 104| Step: 0
Training loss: 1.9951509237289429
Validation loss: 2.023719936609268

Epoch: 5| Step: 1
Training loss: 2.091618776321411
Validation loss: 2.025340403119723

Epoch: 5| Step: 2
Training loss: 2.578997850418091
Validation loss: 2.018289272983869

Epoch: 5| Step: 3
Training loss: 1.6987816095352173
Validation loss: 2.023294985294342

Epoch: 5| Step: 4
Training loss: 2.0319132804870605
Validation loss: 2.014910658200582

Epoch: 5| Step: 5
Training loss: 2.511385440826416
Validation loss: 2.011975104610125

Epoch: 5| Step: 6
Training loss: 1.9636707305908203
Validation loss: 2.0206693708896637

Epoch: 5| Step: 7
Training loss: 1.8533542156219482
Validation loss: 2.0160705198844275

Epoch: 5| Step: 8
Training loss: 2.4170775413513184
Validation loss: 2.029776468873024

Epoch: 5| Step: 9
Training loss: 2.373288869857788
Validation loss: 2.0386825501918793

Epoch: 5| Step: 10
Training loss: 1.6018714904785156
Validation loss: 2.0278367896874747

Epoch: 5| Step: 11
Training loss: 2.9383413791656494
Validation loss: 2.019517203172048

Epoch: 105| Step: 0
Training loss: 2.4330790042877197
Validation loss: 2.0108134150505066

Epoch: 5| Step: 1
Training loss: 1.8927561044692993
Validation loss: 2.006667802731196

Epoch: 5| Step: 2
Training loss: 1.6649978160858154
Validation loss: 2.00123538573583

Epoch: 5| Step: 3
Training loss: 1.8322585821151733
Validation loss: 2.009081890185674

Epoch: 5| Step: 4
Training loss: 2.687370538711548
Validation loss: 2.0062266141176224

Epoch: 5| Step: 5
Training loss: 1.774501085281372
Validation loss: 2.010630120833715

Epoch: 5| Step: 6
Training loss: 1.9103734493255615
Validation loss: 2.003443638483683

Epoch: 5| Step: 7
Training loss: 2.3656527996063232
Validation loss: 2.013949672381083

Epoch: 5| Step: 8
Training loss: 2.5474133491516113
Validation loss: 2.0211075643698373

Epoch: 5| Step: 9
Training loss: 2.133575916290283
Validation loss: 2.0102606813112893

Epoch: 5| Step: 10
Training loss: 2.2010700702667236
Validation loss: 2.0062658488750458

Epoch: 5| Step: 11
Training loss: 2.214661121368408
Validation loss: 2.009363050262133

Epoch: 106| Step: 0
Training loss: 2.1126697063446045
Validation loss: 2.0044842114051185

Epoch: 5| Step: 1
Training loss: 2.467947483062744
Validation loss: 2.007608344157537

Epoch: 5| Step: 2
Training loss: 2.415339231491089
Validation loss: 2.0158753593762717

Epoch: 5| Step: 3
Training loss: 1.938947319984436
Validation loss: 2.0124520560105643

Epoch: 5| Step: 4
Training loss: 1.8604316711425781
Validation loss: 2.0076267570257187

Epoch: 5| Step: 5
Training loss: 1.9444408416748047
Validation loss: 1.9910288800795872

Epoch: 5| Step: 6
Training loss: 2.242784023284912
Validation loss: 2.0170378585656485

Epoch: 5| Step: 7
Training loss: 1.8228557109832764
Validation loss: 2.0236890017986298

Epoch: 5| Step: 8
Training loss: 1.2118886709213257
Validation loss: 2.0208944578965506

Epoch: 5| Step: 9
Training loss: 2.371488571166992
Validation loss: 2.0244621386130652

Epoch: 5| Step: 10
Training loss: 2.6109707355499268
Validation loss: 2.046614502867063

Epoch: 5| Step: 11
Training loss: 3.5989928245544434
Validation loss: 2.046990623076757

Epoch: 107| Step: 0
Training loss: 2.138558864593506
Validation loss: 2.0400046904881797

Epoch: 5| Step: 1
Training loss: 2.2805349826812744
Validation loss: 2.029303401708603

Epoch: 5| Step: 2
Training loss: 1.5940368175506592
Validation loss: 2.016176864504814

Epoch: 5| Step: 3
Training loss: 1.5812571048736572
Validation loss: 2.0120160281658173

Epoch: 5| Step: 4
Training loss: 2.2436769008636475
Validation loss: 2.018241206804911

Epoch: 5| Step: 5
Training loss: 2.2555928230285645
Validation loss: 2.0163559913635254

Epoch: 5| Step: 6
Training loss: 2.774070978164673
Validation loss: 2.0249653259913125

Epoch: 5| Step: 7
Training loss: 2.571300506591797
Validation loss: 2.035507028301557

Epoch: 5| Step: 8
Training loss: 2.0387868881225586
Validation loss: 2.0366890331109366

Epoch: 5| Step: 9
Training loss: 2.130673885345459
Validation loss: 2.055573249856631

Epoch: 5| Step: 10
Training loss: 1.542487382888794
Validation loss: 2.042426457007726

Epoch: 5| Step: 11
Training loss: 2.5568809509277344
Validation loss: 2.020082250237465

Epoch: 108| Step: 0
Training loss: 2.2766544818878174
Validation loss: 2.01281746228536

Epoch: 5| Step: 1
Training loss: 2.0956661701202393
Validation loss: 2.0088856716950736

Epoch: 5| Step: 2
Training loss: 2.329428195953369
Validation loss: 2.0053114742040634

Epoch: 5| Step: 3
Training loss: 2.276817798614502
Validation loss: 2.011276975274086

Epoch: 5| Step: 4
Training loss: 1.9677833318710327
Validation loss: 2.0063259849945703

Epoch: 5| Step: 5
Training loss: 2.0810723304748535
Validation loss: 2.012087275584539

Epoch: 5| Step: 6
Training loss: 1.9940999746322632
Validation loss: 2.008688102165858

Epoch: 5| Step: 7
Training loss: 1.888636589050293
Validation loss: 2.013646185398102

Epoch: 5| Step: 8
Training loss: 2.0124263763427734
Validation loss: 2.0152746438980103

Epoch: 5| Step: 9
Training loss: 2.0950112342834473
Validation loss: 2.012891188263893

Epoch: 5| Step: 10
Training loss: 2.265794038772583
Validation loss: 2.0106468399365744

Epoch: 5| Step: 11
Training loss: 2.561277389526367
Validation loss: 2.008064458767573

Epoch: 109| Step: 0
Training loss: 2.6660573482513428
Validation loss: 2.0134469171365104

Epoch: 5| Step: 1
Training loss: 2.1201987266540527
Validation loss: 2.0057161152362823

Epoch: 5| Step: 2
Training loss: 2.4400486946105957
Validation loss: 2.013480936487516

Epoch: 5| Step: 3
Training loss: 2.136420488357544
Validation loss: 2.01383875310421

Epoch: 5| Step: 4
Training loss: 1.8283532857894897
Validation loss: 2.024588172634443

Epoch: 5| Step: 5
Training loss: 1.8100332021713257
Validation loss: 2.051645835240682

Epoch: 5| Step: 6
Training loss: 2.1638550758361816
Validation loss: 2.0729486842950187

Epoch: 5| Step: 7
Training loss: 2.301556348800659
Validation loss: 2.0838712553183236

Epoch: 5| Step: 8
Training loss: 2.494286060333252
Validation loss: 2.076395109295845

Epoch: 5| Step: 9
Training loss: 1.8195654153823853
Validation loss: 2.0537244379520416

Epoch: 5| Step: 10
Training loss: 1.5945570468902588
Validation loss: 2.045018086830775

Epoch: 5| Step: 11
Training loss: 1.7291992902755737
Validation loss: 2.0146960069735846

Epoch: 110| Step: 0
Training loss: 1.853968620300293
Validation loss: 2.0129026224215827

Epoch: 5| Step: 1
Training loss: 2.681697368621826
Validation loss: 2.0091694643100104

Epoch: 5| Step: 2
Training loss: 2.5276713371276855
Validation loss: 2.013727138439814

Epoch: 5| Step: 3
Training loss: 2.2536935806274414
Validation loss: 2.0117800384759903

Epoch: 5| Step: 4
Training loss: 1.2439874410629272
Validation loss: 2.0126851250727973

Epoch: 5| Step: 5
Training loss: 2.1923460960388184
Validation loss: 2.015837619702021

Epoch: 5| Step: 6
Training loss: 2.1208653450012207
Validation loss: 2.015836944182714

Epoch: 5| Step: 7
Training loss: 2.130103588104248
Validation loss: 2.011824975411097

Epoch: 5| Step: 8
Training loss: 1.965488076210022
Validation loss: 2.011673018336296

Epoch: 5| Step: 9
Training loss: 2.0965189933776855
Validation loss: 2.014777118961016

Epoch: 5| Step: 10
Training loss: 2.247002124786377
Validation loss: 2.0086975594361625

Epoch: 5| Step: 11
Training loss: 2.275686025619507
Validation loss: 2.0102972785631814

Epoch: 111| Step: 0
Training loss: 1.7679945230484009
Validation loss: 2.0032673378785453

Epoch: 5| Step: 1
Training loss: 2.3067469596862793
Validation loss: 2.007115960121155

Epoch: 5| Step: 2
Training loss: 2.426112413406372
Validation loss: 1.997535839676857

Epoch: 5| Step: 3
Training loss: 1.7931203842163086
Validation loss: 2.0048335641622543

Epoch: 5| Step: 4
Training loss: 1.6390177011489868
Validation loss: 2.016470034917196

Epoch: 5| Step: 5
Training loss: 1.9924609661102295
Validation loss: 2.008268495400747

Epoch: 5| Step: 6
Training loss: 2.1075520515441895
Validation loss: 2.0189927419026694

Epoch: 5| Step: 7
Training loss: 2.5959744453430176
Validation loss: 2.0374162048101425

Epoch: 5| Step: 8
Training loss: 2.132939338684082
Validation loss: 2.0259938836097717

Epoch: 5| Step: 9
Training loss: 1.9878705739974976
Validation loss: 2.0401617536942163

Epoch: 5| Step: 10
Training loss: 2.407108783721924
Validation loss: 2.0708697140216827

Epoch: 5| Step: 11
Training loss: 1.441563367843628
Validation loss: 2.068217252691587

Epoch: 112| Step: 0
Training loss: 1.9365053176879883
Validation loss: 2.0720035483439765

Epoch: 5| Step: 1
Training loss: 1.795480728149414
Validation loss: 2.0454795410235724

Epoch: 5| Step: 2
Training loss: 1.7837498188018799
Validation loss: 2.036807427803675

Epoch: 5| Step: 3
Training loss: 2.0502707958221436
Validation loss: 2.0251147150993347

Epoch: 5| Step: 4
Training loss: 2.4065794944763184
Validation loss: 2.018858641386032

Epoch: 5| Step: 5
Training loss: 1.9451879262924194
Validation loss: 2.013042385379473

Epoch: 5| Step: 6
Training loss: 2.285306453704834
Validation loss: 2.0184362630049386

Epoch: 5| Step: 7
Training loss: 2.1912786960601807
Validation loss: 2.014100725452105

Epoch: 5| Step: 8
Training loss: 1.8525793552398682
Validation loss: 2.0296326527992883

Epoch: 5| Step: 9
Training loss: 2.0523521900177
Validation loss: 2.0308898289998374

Epoch: 5| Step: 10
Training loss: 2.9490790367126465
Validation loss: 2.03166955212752

Epoch: 5| Step: 11
Training loss: 2.053474187850952
Validation loss: 2.0350682785113654

Epoch: 113| Step: 0
Training loss: 2.1667661666870117
Validation loss: 2.0301878650983176

Epoch: 5| Step: 1
Training loss: 2.2034685611724854
Validation loss: 2.0243168026208878

Epoch: 5| Step: 2
Training loss: 1.9740073680877686
Validation loss: 2.0242836624383926

Epoch: 5| Step: 3
Training loss: 2.217332124710083
Validation loss: 2.016732926170031

Epoch: 5| Step: 4
Training loss: 2.1567721366882324
Validation loss: 2.0223815540472665

Epoch: 5| Step: 5
Training loss: 1.4414197206497192
Validation loss: 2.013358637690544

Epoch: 5| Step: 6
Training loss: 2.509070634841919
Validation loss: 2.012642502784729

Epoch: 5| Step: 7
Training loss: 2.403357982635498
Validation loss: 2.0051746865113578

Epoch: 5| Step: 8
Training loss: 2.5958056449890137
Validation loss: 2.0079337656497955

Epoch: 5| Step: 9
Training loss: 2.030991315841675
Validation loss: 2.012624313433965

Epoch: 5| Step: 10
Training loss: 1.796531081199646
Validation loss: 2.0023667166630426

Epoch: 5| Step: 11
Training loss: 1.84194815158844
Validation loss: 2.021339630087217

Epoch: 114| Step: 0
Training loss: 1.663956642150879
Validation loss: 2.023186375697454

Epoch: 5| Step: 1
Training loss: 1.8450244665145874
Validation loss: 2.0356898109118142

Epoch: 5| Step: 2
Training loss: 2.536179780960083
Validation loss: 2.0489051192998886

Epoch: 5| Step: 3
Training loss: 1.8750905990600586
Validation loss: 2.0518254389365516

Epoch: 5| Step: 4
Training loss: 2.2123332023620605
Validation loss: 2.036788761615753

Epoch: 5| Step: 5
Training loss: 2.2125563621520996
Validation loss: 2.0274947186311087

Epoch: 5| Step: 6
Training loss: 2.5098884105682373
Validation loss: 2.0256116141875586

Epoch: 5| Step: 7
Training loss: 1.1775470972061157
Validation loss: 2.0079458902279534

Epoch: 5| Step: 8
Training loss: 2.472057819366455
Validation loss: 2.023919716477394

Epoch: 5| Step: 9
Training loss: 2.220059871673584
Validation loss: 2.0099692791700363

Epoch: 5| Step: 10
Training loss: 2.5353879928588867
Validation loss: 2.0084858536720276

Epoch: 5| Step: 11
Training loss: 2.0495879650115967
Validation loss: 2.015042265256246

Epoch: 115| Step: 0
Training loss: 2.4758353233337402
Validation loss: 2.0085289577643075

Epoch: 5| Step: 1
Training loss: 2.2571663856506348
Validation loss: 2.0136879831552505

Epoch: 5| Step: 2
Training loss: 2.675053119659424
Validation loss: 2.0152812898159027

Epoch: 5| Step: 3
Training loss: 2.1242549419403076
Validation loss: 2.0114717384179435

Epoch: 5| Step: 4
Training loss: 1.646519422531128
Validation loss: 2.0161977062622705

Epoch: 5| Step: 5
Training loss: 1.9437646865844727
Validation loss: 2.0130699475606284

Epoch: 5| Step: 6
Training loss: 2.5387301445007324
Validation loss: 2.0316732426484427

Epoch: 5| Step: 7
Training loss: 1.9784256219863892
Validation loss: 2.033757006128629

Epoch: 5| Step: 8
Training loss: 2.5012266635894775
Validation loss: 2.04002853234609

Epoch: 5| Step: 9
Training loss: 1.7286350727081299
Validation loss: 2.0425390948851905

Epoch: 5| Step: 10
Training loss: 1.5563400983810425
Validation loss: 2.0442796846230826

Epoch: 5| Step: 11
Training loss: 0.7921664714813232
Validation loss: 2.042959397037824

Epoch: 116| Step: 0
Training loss: 2.203425407409668
Validation loss: 2.0753539403279624

Epoch: 5| Step: 1
Training loss: 2.2816925048828125
Validation loss: 2.0815474490324655

Epoch: 5| Step: 2
Training loss: 2.069514751434326
Validation loss: 2.084733967979749

Epoch: 5| Step: 3
Training loss: 2.7407162189483643
Validation loss: 2.1080627540747323

Epoch: 5| Step: 4
Training loss: 2.0595955848693848
Validation loss: 2.0919586519400277

Epoch: 5| Step: 5
Training loss: 1.7315822839736938
Validation loss: 2.0561679204305015

Epoch: 5| Step: 6
Training loss: 2.012178421020508
Validation loss: 2.037636458873749

Epoch: 5| Step: 7
Training loss: 1.8237292766571045
Validation loss: 2.0323287695646286

Epoch: 5| Step: 8
Training loss: 2.096858263015747
Validation loss: 2.0202833861112595

Epoch: 5| Step: 9
Training loss: 2.3423972129821777
Validation loss: 2.0274751385053

Epoch: 5| Step: 10
Training loss: 2.022406816482544
Validation loss: 2.0174184292554855

Epoch: 5| Step: 11
Training loss: 2.059701919555664
Validation loss: 2.022142464915911

Epoch: 117| Step: 0
Training loss: 2.489903450012207
Validation loss: 2.0215877294540405

Epoch: 5| Step: 1
Training loss: 1.8299970626831055
Validation loss: 2.0093744496504464

Epoch: 5| Step: 2
Training loss: 2.304396152496338
Validation loss: 2.0128101855516434

Epoch: 5| Step: 3
Training loss: 1.5875914096832275
Validation loss: 2.004381795724233

Epoch: 5| Step: 4
Training loss: 1.8496730327606201
Validation loss: 2.0066406230131784

Epoch: 5| Step: 5
Training loss: 1.6918340921401978
Validation loss: 2.0215583195288978

Epoch: 5| Step: 6
Training loss: 2.075601100921631
Validation loss: 2.0165622482697168

Epoch: 5| Step: 7
Training loss: 2.513671875
Validation loss: 2.0238644232352576

Epoch: 5| Step: 8
Training loss: 2.541499376296997
Validation loss: 2.044828255971273

Epoch: 5| Step: 9
Training loss: 1.8691259622573853
Validation loss: 2.051777809858322

Epoch: 5| Step: 10
Training loss: 2.433892011642456
Validation loss: 2.055607095360756

Epoch: 5| Step: 11
Training loss: 2.128357172012329
Validation loss: 2.0423336823781333

Epoch: 118| Step: 0
Training loss: 2.612687587738037
Validation loss: 2.0386245946089425

Epoch: 5| Step: 1
Training loss: 1.9194023609161377
Validation loss: 2.042747437953949

Epoch: 5| Step: 2
Training loss: 2.2848598957061768
Validation loss: 2.033371776342392

Epoch: 5| Step: 3
Training loss: 2.069148540496826
Validation loss: 2.0249409675598145

Epoch: 5| Step: 4
Training loss: 2.4764366149902344
Validation loss: 2.011777157584826

Epoch: 5| Step: 5
Training loss: 1.981549620628357
Validation loss: 2.0164184172948203

Epoch: 5| Step: 6
Training loss: 1.6769466400146484
Validation loss: 2.012473692496618

Epoch: 5| Step: 7
Training loss: 2.200204372406006
Validation loss: 2.0044487168391547

Epoch: 5| Step: 8
Training loss: 2.143719434738159
Validation loss: 2.0122945457696915

Epoch: 5| Step: 9
Training loss: 1.9643408060073853
Validation loss: 2.006771147251129

Epoch: 5| Step: 10
Training loss: 1.8354806900024414
Validation loss: 1.9981150726477306

Epoch: 5| Step: 11
Training loss: 1.626813530921936
Validation loss: 2.0128964384396872

Epoch: 119| Step: 0
Training loss: 2.432365655899048
Validation loss: 2.0149535834789276

Epoch: 5| Step: 1
Training loss: 2.199711322784424
Validation loss: 2.024588296810786

Epoch: 5| Step: 2
Training loss: 2.257498264312744
Validation loss: 2.03138534228007

Epoch: 5| Step: 3
Training loss: 1.7778711318969727
Validation loss: 2.0549944937229156

Epoch: 5| Step: 4
Training loss: 1.792974829673767
Validation loss: 2.0690394937992096

Epoch: 5| Step: 5
Training loss: 1.5880628824234009
Validation loss: 2.084291165073713

Epoch: 5| Step: 6
Training loss: 2.4006741046905518
Validation loss: 2.087304284175237

Epoch: 5| Step: 7
Training loss: 2.26867938041687
Validation loss: 2.092618008454641

Epoch: 5| Step: 8
Training loss: 1.5235941410064697
Validation loss: 2.1014990359544754

Epoch: 5| Step: 9
Training loss: 2.0209548473358154
Validation loss: 2.0593035419782004

Epoch: 5| Step: 10
Training loss: 2.8555853366851807
Validation loss: 2.070184295376142

Epoch: 5| Step: 11
Training loss: 1.308119297027588
Validation loss: 2.0363909552494683

Epoch: 120| Step: 0
Training loss: 2.156872034072876
Validation loss: 2.0157160659631095

Epoch: 5| Step: 1
Training loss: 1.8390522003173828
Validation loss: 2.016823718945185

Epoch: 5| Step: 2
Training loss: 2.4542744159698486
Validation loss: 2.0300107101599374

Epoch: 5| Step: 3
Training loss: 1.9580657482147217
Validation loss: 2.047674631079038

Epoch: 5| Step: 4
Training loss: 2.0832977294921875
Validation loss: 2.0577192505200705

Epoch: 5| Step: 5
Training loss: 2.1421051025390625
Validation loss: 2.0755194276571274

Epoch: 5| Step: 6
Training loss: 2.4304451942443848
Validation loss: 2.080263485511144

Epoch: 5| Step: 7
Training loss: 2.6173038482666016
Validation loss: 2.071645254890124

Epoch: 5| Step: 8
Training loss: 1.5553086996078491
Validation loss: 2.0742668261130652

Epoch: 5| Step: 9
Training loss: 2.3847928047180176
Validation loss: 2.077751085162163

Epoch: 5| Step: 10
Training loss: 2.4373703002929688
Validation loss: 2.078575154145559

Epoch: 5| Step: 11
Training loss: 2.900606632232666
Validation loss: 2.076269363363584

Epoch: 121| Step: 0
Training loss: 2.0092475414276123
Validation loss: 2.066104973355929

Epoch: 5| Step: 1
Training loss: 2.0367438793182373
Validation loss: 2.0624263187249503

Epoch: 5| Step: 2
Training loss: 2.0706121921539307
Validation loss: 2.065237358212471

Epoch: 5| Step: 3
Training loss: 2.454218864440918
Validation loss: 2.0566696723302207

Epoch: 5| Step: 4
Training loss: 2.530963182449341
Validation loss: 2.046722928682963

Epoch: 5| Step: 5
Training loss: 1.842287302017212
Validation loss: 2.0450163384278617

Epoch: 5| Step: 6
Training loss: 2.578171491622925
Validation loss: 2.0342767238616943

Epoch: 5| Step: 7
Training loss: 1.8605678081512451
Validation loss: 2.0174447745084763

Epoch: 5| Step: 8
Training loss: 2.0021839141845703
Validation loss: 2.019406328598658

Epoch: 5| Step: 9
Training loss: 2.0600438117980957
Validation loss: 2.0218447844187417

Epoch: 5| Step: 10
Training loss: 1.9912115335464478
Validation loss: 2.0388875802357993

Epoch: 5| Step: 11
Training loss: 3.3843703269958496
Validation loss: 2.053063377737999

Epoch: 122| Step: 0
Training loss: 1.9222192764282227
Validation loss: 2.0479959646860757

Epoch: 5| Step: 1
Training loss: 1.8995431661605835
Validation loss: 2.061202347278595

Epoch: 5| Step: 2
Training loss: 2.3732242584228516
Validation loss: 2.0560380468765893

Epoch: 5| Step: 3
Training loss: 2.508359909057617
Validation loss: 2.025176857908567

Epoch: 5| Step: 4
Training loss: 1.962262511253357
Validation loss: 2.023170997699102

Epoch: 5| Step: 5
Training loss: 2.4210963249206543
Validation loss: 2.030738035837809

Epoch: 5| Step: 6
Training loss: 1.672083854675293
Validation loss: 2.034994532664617

Epoch: 5| Step: 7
Training loss: 2.161818504333496
Validation loss: 2.039153983195623

Epoch: 5| Step: 8
Training loss: 1.8138662576675415
Validation loss: 2.0341901630163193

Epoch: 5| Step: 9
Training loss: 2.4965856075286865
Validation loss: 2.0333949426809945

Epoch: 5| Step: 10
Training loss: 1.7374897003173828
Validation loss: 2.029118607441584

Epoch: 5| Step: 11
Training loss: 2.228411912918091
Validation loss: 2.02021594842275

Epoch: 123| Step: 0
Training loss: 1.951637625694275
Validation loss: 2.014151324828466

Epoch: 5| Step: 1
Training loss: 2.2767691612243652
Validation loss: 2.0158590972423553

Epoch: 5| Step: 2
Training loss: 2.6192333698272705
Validation loss: 2.013376767436663

Epoch: 5| Step: 3
Training loss: 2.0538032054901123
Validation loss: 2.0061888098716736

Epoch: 5| Step: 4
Training loss: 1.6412349939346313
Validation loss: 2.015896519025167

Epoch: 5| Step: 5
Training loss: 1.5471758842468262
Validation loss: 2.0128890027602515

Epoch: 5| Step: 6
Training loss: 2.534431219100952
Validation loss: 2.0138737807671228

Epoch: 5| Step: 7
Training loss: 1.9703376293182373
Validation loss: 2.020464837551117

Epoch: 5| Step: 8
Training loss: 1.9295690059661865
Validation loss: 2.012418121099472

Epoch: 5| Step: 9
Training loss: 2.2986178398132324
Validation loss: 2.004427174727122

Epoch: 5| Step: 10
Training loss: 2.4112703800201416
Validation loss: 2.014235019683838

Epoch: 5| Step: 11
Training loss: 1.4938905239105225
Validation loss: 2.003062163790067

Epoch: 124| Step: 0
Training loss: 2.100503921508789
Validation loss: 2.010015313824018

Epoch: 5| Step: 1
Training loss: 2.1291167736053467
Validation loss: 2.0095329781373343

Epoch: 5| Step: 2
Training loss: 2.20076060295105
Validation loss: 2.0077783167362213

Epoch: 5| Step: 3
Training loss: 1.7507381439208984
Validation loss: 2.02487018207709

Epoch: 5| Step: 4
Training loss: 2.418084144592285
Validation loss: 2.0114997724692025

Epoch: 5| Step: 5
Training loss: 1.892831563949585
Validation loss: 2.01825417081515

Epoch: 5| Step: 6
Training loss: 2.5237317085266113
Validation loss: 2.026556054751078

Epoch: 5| Step: 7
Training loss: 1.9003360271453857
Validation loss: 2.019707346955935

Epoch: 5| Step: 8
Training loss: 1.770437240600586
Validation loss: 2.0216131259997687

Epoch: 5| Step: 9
Training loss: 2.4984748363494873
Validation loss: 2.0330893248319626

Epoch: 5| Step: 10
Training loss: 1.553234338760376
Validation loss: 2.0466654201348624

Epoch: 5| Step: 11
Training loss: 2.470334529876709
Validation loss: 2.053893764813741

Epoch: 125| Step: 0
Training loss: 1.936478853225708
Validation loss: 2.062069614728292

Epoch: 5| Step: 1
Training loss: 2.708512544631958
Validation loss: 2.053915133078893

Epoch: 5| Step: 2
Training loss: 2.0725619792938232
Validation loss: 2.0517729371786118

Epoch: 5| Step: 3
Training loss: 1.851820707321167
Validation loss: 2.0405190686384835

Epoch: 5| Step: 4
Training loss: 2.0877485275268555
Validation loss: 2.0440873404343924

Epoch: 5| Step: 5
Training loss: 2.1307194232940674
Validation loss: 2.0332539131244025

Epoch: 5| Step: 6
Training loss: 1.9088208675384521
Validation loss: 2.017433394988378

Epoch: 5| Step: 7
Training loss: 1.5121957063674927
Validation loss: 2.030122255285581

Epoch: 5| Step: 8
Training loss: 2.4108176231384277
Validation loss: 2.0142960051695504

Epoch: 5| Step: 9
Training loss: 2.0276901721954346
Validation loss: 2.023398205637932

Epoch: 5| Step: 10
Training loss: 2.3061747550964355
Validation loss: 2.013950988650322

Epoch: 5| Step: 11
Training loss: 1.3170756101608276
Validation loss: 2.023544286688169

Epoch: 126| Step: 0
Training loss: 1.5412933826446533
Validation loss: 2.018332287669182

Epoch: 5| Step: 1
Training loss: 1.8124316930770874
Validation loss: 2.019375503063202

Epoch: 5| Step: 2
Training loss: 1.9862921237945557
Validation loss: 2.0233522852261863

Epoch: 5| Step: 3
Training loss: 2.288135290145874
Validation loss: 2.0331620077292123

Epoch: 5| Step: 4
Training loss: 1.7074562311172485
Validation loss: 2.0360272377729416

Epoch: 5| Step: 5
Training loss: 2.1301109790802
Validation loss: 2.0496956755717597

Epoch: 5| Step: 6
Training loss: 1.4686137437820435
Validation loss: 2.0442338039477668

Epoch: 5| Step: 7
Training loss: 2.3920116424560547
Validation loss: 2.040223479270935

Epoch: 5| Step: 8
Training loss: 2.1895155906677246
Validation loss: 2.0383498867352805

Epoch: 5| Step: 9
Training loss: 2.450258731842041
Validation loss: 2.0457461774349213

Epoch: 5| Step: 10
Training loss: 2.743804931640625
Validation loss: 2.0433764904737473

Epoch: 5| Step: 11
Training loss: 2.357975482940674
Validation loss: 2.0300029665231705

Epoch: 127| Step: 0
Training loss: 1.8374392986297607
Validation loss: 2.029371882478396

Epoch: 5| Step: 1
Training loss: 2.0941405296325684
Validation loss: 2.034756690263748

Epoch: 5| Step: 2
Training loss: 2.262840509414673
Validation loss: 2.0334698408842087

Epoch: 5| Step: 3
Training loss: 2.0768299102783203
Validation loss: 2.041161651412646

Epoch: 5| Step: 4
Training loss: 2.6737046241760254
Validation loss: 2.028729741772016

Epoch: 5| Step: 5
Training loss: 2.1331803798675537
Validation loss: 2.0407577753067017

Epoch: 5| Step: 6
Training loss: 2.1767473220825195
Validation loss: 2.052821318308512

Epoch: 5| Step: 7
Training loss: 1.7246322631835938
Validation loss: 2.0604239155848822

Epoch: 5| Step: 8
Training loss: 2.13572096824646
Validation loss: 2.059379701813062

Epoch: 5| Step: 9
Training loss: 1.8581340312957764
Validation loss: 2.0447857280572257

Epoch: 5| Step: 10
Training loss: 1.6456445455551147
Validation loss: 2.0456087787946067

Epoch: 5| Step: 11
Training loss: 2.8538904190063477
Validation loss: 2.056919644276301

Epoch: 128| Step: 0
Training loss: 1.9469192028045654
Validation loss: 2.0327093501885733

Epoch: 5| Step: 1
Training loss: 1.8034346103668213
Validation loss: 2.024356176455816

Epoch: 5| Step: 2
Training loss: 1.9876182079315186
Validation loss: 2.0233649412790933

Epoch: 5| Step: 3
Training loss: 2.2206146717071533
Validation loss: 2.0185778041680655

Epoch: 5| Step: 4
Training loss: 1.7564224004745483
Validation loss: 2.0244128902753196

Epoch: 5| Step: 5
Training loss: 2.2550911903381348
Validation loss: 2.015801136692365

Epoch: 5| Step: 6
Training loss: 2.665559768676758
Validation loss: 2.027311682701111

Epoch: 5| Step: 7
Training loss: 1.6238749027252197
Validation loss: 2.0251072694857917

Epoch: 5| Step: 8
Training loss: 1.6860477924346924
Validation loss: 2.0280402451753616

Epoch: 5| Step: 9
Training loss: 2.101017951965332
Validation loss: 2.025440588593483

Epoch: 5| Step: 10
Training loss: 3.074892044067383
Validation loss: 2.0420750081539154

Epoch: 5| Step: 11
Training loss: 1.1794438362121582
Validation loss: 2.0472606470187507

Epoch: 129| Step: 0
Training loss: 2.101874589920044
Validation loss: 2.064982200662295

Epoch: 5| Step: 1
Training loss: 1.6548221111297607
Validation loss: 2.0739559680223465

Epoch: 5| Step: 2
Training loss: 2.1555943489074707
Validation loss: 2.074736461043358

Epoch: 5| Step: 3
Training loss: 2.3720405101776123
Validation loss: 2.081571718056997

Epoch: 5| Step: 4
Training loss: 1.979081153869629
Validation loss: 2.0774410466353097

Epoch: 5| Step: 5
Training loss: 2.163151979446411
Validation loss: 2.0708468357721963

Epoch: 5| Step: 6
Training loss: 2.0627150535583496
Validation loss: 2.0658771842718124

Epoch: 5| Step: 7
Training loss: 2.187171459197998
Validation loss: 2.0684478084246316

Epoch: 5| Step: 8
Training loss: 1.7937755584716797
Validation loss: 2.055149828394254

Epoch: 5| Step: 9
Training loss: 2.338411331176758
Validation loss: 2.0493523875872293

Epoch: 5| Step: 10
Training loss: 2.09917950630188
Validation loss: 2.0406471888224282

Epoch: 5| Step: 11
Training loss: 1.612303376197815
Validation loss: 2.0367864618698754

Epoch: 130| Step: 0
Training loss: 2.48687481880188
Validation loss: 2.035446355740229

Epoch: 5| Step: 1
Training loss: 2.352175235748291
Validation loss: 2.0338532427946725

Epoch: 5| Step: 2
Training loss: 1.7282769680023193
Validation loss: 2.033709332346916

Epoch: 5| Step: 3
Training loss: 1.9491825103759766
Validation loss: 2.0327337086200714

Epoch: 5| Step: 4
Training loss: 1.8212506771087646
Validation loss: 2.0267749627431235

Epoch: 5| Step: 5
Training loss: 2.744602680206299
Validation loss: 2.0334642430146537

Epoch: 5| Step: 6
Training loss: 1.9148447513580322
Validation loss: 2.0404961655537286

Epoch: 5| Step: 7
Training loss: 1.9159198999404907
Validation loss: 2.053257331252098

Epoch: 5| Step: 8
Training loss: 1.9532032012939453
Validation loss: 2.0492127339045205

Epoch: 5| Step: 9
Training loss: 1.783360242843628
Validation loss: 2.05792864660422

Epoch: 5| Step: 10
Training loss: 1.7581583261489868
Validation loss: 2.048181558648745

Epoch: 5| Step: 11
Training loss: 3.4642412662506104
Validation loss: 2.0226337959369025

Epoch: 131| Step: 0
Training loss: 2.2152905464172363
Validation loss: 2.022214263677597

Epoch: 5| Step: 1
Training loss: 1.7846046686172485
Validation loss: 2.017401004830996

Epoch: 5| Step: 2
Training loss: 2.289304494857788
Validation loss: 2.0273934503396354

Epoch: 5| Step: 3
Training loss: 1.5858616828918457
Validation loss: 2.0301914314428964

Epoch: 5| Step: 4
Training loss: 1.8025238513946533
Validation loss: 2.02474079032739

Epoch: 5| Step: 5
Training loss: 2.1081113815307617
Validation loss: 2.0263760536909103

Epoch: 5| Step: 6
Training loss: 2.609949827194214
Validation loss: 2.0188216914733252

Epoch: 5| Step: 7
Training loss: 2.0216777324676514
Validation loss: 2.0273080865542092

Epoch: 5| Step: 8
Training loss: 2.0441837310791016
Validation loss: 2.024020175139109

Epoch: 5| Step: 9
Training loss: 2.5213053226470947
Validation loss: 2.0301748315493264

Epoch: 5| Step: 10
Training loss: 2.021052360534668
Validation loss: 2.0325144032637277

Epoch: 5| Step: 11
Training loss: 1.3088462352752686
Validation loss: 2.038179169098536

Epoch: 132| Step: 0
Training loss: 2.013878345489502
Validation loss: 2.0278711169958115

Epoch: 5| Step: 1
Training loss: 2.173429012298584
Validation loss: 2.020026554663976

Epoch: 5| Step: 2
Training loss: 1.203183889389038
Validation loss: 2.018428067366282

Epoch: 5| Step: 3
Training loss: 1.952431082725525
Validation loss: 2.019774943590164

Epoch: 5| Step: 4
Training loss: 2.823795795440674
Validation loss: 2.0151677280664444

Epoch: 5| Step: 5
Training loss: 2.114443778991699
Validation loss: 2.0178238997856774

Epoch: 5| Step: 6
Training loss: 1.9020817279815674
Validation loss: 2.036419227719307

Epoch: 5| Step: 7
Training loss: 2.3280510902404785
Validation loss: 2.027104819814364

Epoch: 5| Step: 8
Training loss: 2.254291534423828
Validation loss: 2.0337684055169425

Epoch: 5| Step: 9
Training loss: 1.9686520099639893
Validation loss: 2.0435026387373605

Epoch: 5| Step: 10
Training loss: 2.3378243446350098
Validation loss: 2.0324815064668655

Epoch: 5| Step: 11
Training loss: 2.021453619003296
Validation loss: 2.026857629418373

Epoch: 133| Step: 0
Training loss: 1.952459692955017
Validation loss: 2.0557743857304254

Epoch: 5| Step: 1
Training loss: 1.856671690940857
Validation loss: 2.0517571767171225

Epoch: 5| Step: 2
Training loss: 1.561213731765747
Validation loss: 2.0625696082909903

Epoch: 5| Step: 3
Training loss: 2.0538170337677
Validation loss: 2.0540747990210853

Epoch: 5| Step: 4
Training loss: 1.8515084981918335
Validation loss: 2.0452800393104553

Epoch: 5| Step: 5
Training loss: 2.2524476051330566
Validation loss: 2.0407631496588388

Epoch: 5| Step: 6
Training loss: 2.232116460800171
Validation loss: 2.038966874281565

Epoch: 5| Step: 7
Training loss: 2.46842622756958
Validation loss: 2.0279782811800637

Epoch: 5| Step: 8
Training loss: 2.2260119915008545
Validation loss: 2.0177549024422965

Epoch: 5| Step: 9
Training loss: 1.7959911823272705
Validation loss: 2.028581514954567

Epoch: 5| Step: 10
Training loss: 2.187978744506836
Validation loss: 2.0350035578012466

Epoch: 5| Step: 11
Training loss: 3.468379497528076
Validation loss: 2.037367711464564

Epoch: 134| Step: 0
Training loss: 1.9674243927001953
Validation loss: 2.0385315070549646

Epoch: 5| Step: 1
Training loss: 2.0230255126953125
Validation loss: 2.035113905866941

Epoch: 5| Step: 2
Training loss: 1.8809788227081299
Validation loss: 2.041243145863215

Epoch: 5| Step: 3
Training loss: 1.8302390575408936
Validation loss: 2.035019194086393

Epoch: 5| Step: 4
Training loss: 1.9291677474975586
Validation loss: 2.0447216033935547

Epoch: 5| Step: 5
Training loss: 2.0426933765411377
Validation loss: 2.0466554512580237

Epoch: 5| Step: 6
Training loss: 1.9573030471801758
Validation loss: 2.047937939564387

Epoch: 5| Step: 7
Training loss: 1.6333732604980469
Validation loss: 2.0531817426284156

Epoch: 5| Step: 8
Training loss: 1.6869609355926514
Validation loss: 2.0578886767228446

Epoch: 5| Step: 9
Training loss: 2.5745811462402344
Validation loss: 2.0792153676350913

Epoch: 5| Step: 10
Training loss: 2.7914109230041504
Validation loss: 2.0977472265561423

Epoch: 5| Step: 11
Training loss: 3.9314494132995605
Validation loss: 2.111022710800171

Epoch: 135| Step: 0
Training loss: 1.909851312637329
Validation loss: 2.097625747323036

Epoch: 5| Step: 1
Training loss: 2.2667148113250732
Validation loss: 2.1007477045059204

Epoch: 5| Step: 2
Training loss: 1.9841511249542236
Validation loss: 2.087879424293836

Epoch: 5| Step: 3
Training loss: 2.4702789783477783
Validation loss: 2.097136919697126

Epoch: 5| Step: 4
Training loss: 1.7832006216049194
Validation loss: 2.0649847785631814

Epoch: 5| Step: 5
Training loss: 1.7976268529891968
Validation loss: 2.048234701156616

Epoch: 5| Step: 6
Training loss: 1.6428415775299072
Validation loss: 2.051000088453293

Epoch: 5| Step: 7
Training loss: 1.4904286861419678
Validation loss: 2.0424055010080338

Epoch: 5| Step: 8
Training loss: 2.205522060394287
Validation loss: 2.0384082595507302

Epoch: 5| Step: 9
Training loss: 2.4512665271759033
Validation loss: 2.03238707780838

Epoch: 5| Step: 10
Training loss: 2.4051222801208496
Validation loss: 2.0289306243260703

Epoch: 5| Step: 11
Training loss: 3.3646392822265625
Validation loss: 2.03117598593235

Epoch: 136| Step: 0
Training loss: 1.4222151041030884
Validation loss: 2.0404177953799567

Epoch: 5| Step: 1
Training loss: 2.7700397968292236
Validation loss: 2.0589859584967294

Epoch: 5| Step: 2
Training loss: 1.9509963989257812
Validation loss: 2.0482220153013864

Epoch: 5| Step: 3
Training loss: 2.3294179439544678
Validation loss: 2.0507443149884543

Epoch: 5| Step: 4
Training loss: 2.5534708499908447
Validation loss: 2.0753731727600098

Epoch: 5| Step: 5
Training loss: 2.002784252166748
Validation loss: 2.0780929923057556

Epoch: 5| Step: 6
Training loss: 2.2299301624298096
Validation loss: 2.082804580529531

Epoch: 5| Step: 7
Training loss: 1.8978173732757568
Validation loss: 2.08967254559199

Epoch: 5| Step: 8
Training loss: 1.9226524829864502
Validation loss: 2.063713868459066

Epoch: 5| Step: 9
Training loss: 1.9986190795898438
Validation loss: 2.0598053137461343

Epoch: 5| Step: 10
Training loss: 1.682295799255371
Validation loss: 2.0499976376692453

Epoch: 5| Step: 11
Training loss: 1.8073675632476807
Validation loss: 2.046264871954918

Epoch: 137| Step: 0
Training loss: 1.6227893829345703
Validation loss: 2.0385919213294983

Epoch: 5| Step: 1
Training loss: 1.6564924716949463
Validation loss: 2.039470146099726

Epoch: 5| Step: 2
Training loss: 1.653395414352417
Validation loss: 2.038802742958069

Epoch: 5| Step: 3
Training loss: 2.4751644134521484
Validation loss: 2.0354364663362503

Epoch: 5| Step: 4
Training loss: 2.3920395374298096
Validation loss: 2.0547924836476645

Epoch: 5| Step: 5
Training loss: 2.087134599685669
Validation loss: 2.0411454886198044

Epoch: 5| Step: 6
Training loss: 2.2334420680999756
Validation loss: 2.0684163520733514

Epoch: 5| Step: 7
Training loss: 1.9469581842422485
Validation loss: 2.0678002387285233

Epoch: 5| Step: 8
Training loss: 2.5025362968444824
Validation loss: 2.0429390172163644

Epoch: 5| Step: 9
Training loss: 1.7221266031265259
Validation loss: 2.043621063232422

Epoch: 5| Step: 10
Training loss: 2.120516777038574
Validation loss: 2.043811450401942

Epoch: 5| Step: 11
Training loss: 2.003204345703125
Validation loss: 2.05227755010128

Epoch: 138| Step: 0
Training loss: 1.6216800212860107
Validation loss: 2.029844492673874

Epoch: 5| Step: 1
Training loss: 1.5852806568145752
Validation loss: 2.0285531878471375

Epoch: 5| Step: 2
Training loss: 1.5528910160064697
Validation loss: 2.025843342145284

Epoch: 5| Step: 3
Training loss: 2.3072400093078613
Validation loss: 2.0302897294362388

Epoch: 5| Step: 4
Training loss: 2.2672646045684814
Validation loss: 2.0255495806535087

Epoch: 5| Step: 5
Training loss: 1.939353585243225
Validation loss: 2.040316710869471

Epoch: 5| Step: 6
Training loss: 2.005082607269287
Validation loss: 2.0302404264609017

Epoch: 5| Step: 7
Training loss: 2.4353413581848145
Validation loss: 2.061364238460859

Epoch: 5| Step: 8
Training loss: 2.4964261054992676
Validation loss: 2.0489570995171866

Epoch: 5| Step: 9
Training loss: 2.5108132362365723
Validation loss: 2.056915437181791

Epoch: 5| Step: 10
Training loss: 2.3531250953674316
Validation loss: 2.05274660885334

Epoch: 5| Step: 11
Training loss: 3.2384374141693115
Validation loss: 2.043851067622503

Epoch: 139| Step: 0
Training loss: 2.3338377475738525
Validation loss: 2.0463704615831375

Epoch: 5| Step: 1
Training loss: 2.6647496223449707
Validation loss: 2.044916753967603

Epoch: 5| Step: 2
Training loss: 1.7957559823989868
Validation loss: 2.0505796571572623

Epoch: 5| Step: 3
Training loss: 2.045140027999878
Validation loss: 2.038878401120504

Epoch: 5| Step: 4
Training loss: 1.8811805248260498
Validation loss: 2.0422452092170715

Epoch: 5| Step: 5
Training loss: 1.8409017324447632
Validation loss: 2.0324165920416513

Epoch: 5| Step: 6
Training loss: 1.8173118829727173
Validation loss: 2.0257039864857993

Epoch: 5| Step: 7
Training loss: 2.4965412616729736
Validation loss: 2.0217174291610718

Epoch: 5| Step: 8
Training loss: 2.1923465728759766
Validation loss: 2.024552822113037

Epoch: 5| Step: 9
Training loss: 2.120760440826416
Validation loss: 2.027707686026891

Epoch: 5| Step: 10
Training loss: 1.985015869140625
Validation loss: 2.0365602721770606

Epoch: 5| Step: 11
Training loss: 1.7387611865997314
Validation loss: 2.0480840305487313

Epoch: 140| Step: 0
Training loss: 2.1886234283447266
Validation loss: 2.0559791922569275

Epoch: 5| Step: 1
Training loss: 1.9125163555145264
Validation loss: 2.0640939424435296

Epoch: 5| Step: 2
Training loss: 1.858030080795288
Validation loss: 2.105166330933571

Epoch: 5| Step: 3
Training loss: 2.168262004852295
Validation loss: 2.1222473035256066

Epoch: 5| Step: 4
Training loss: 2.476472854614258
Validation loss: 2.1400728722413382

Epoch: 5| Step: 5
Training loss: 2.437074661254883
Validation loss: 2.1601148595412574

Epoch: 5| Step: 6
Training loss: 2.1369411945343018
Validation loss: 2.151772916316986

Epoch: 5| Step: 7
Training loss: 2.4038186073303223
Validation loss: 2.11159910261631

Epoch: 5| Step: 8
Training loss: 2.348008632659912
Validation loss: 2.105936954418818

Epoch: 5| Step: 9
Training loss: 1.5823005437850952
Validation loss: 2.075048009554545

Epoch: 5| Step: 10
Training loss: 1.6179172992706299
Validation loss: 2.0589946111043296

Epoch: 5| Step: 11
Training loss: 1.1061842441558838
Validation loss: 2.0397322475910187

Epoch: 141| Step: 0
Training loss: 1.894689917564392
Validation loss: 2.0289143919944763

Epoch: 5| Step: 1
Training loss: 1.9603030681610107
Validation loss: 2.0313140799601874

Epoch: 5| Step: 2
Training loss: 1.8106954097747803
Validation loss: 2.0337956647078195

Epoch: 5| Step: 3
Training loss: 1.7344611883163452
Validation loss: 2.0280899902184806

Epoch: 5| Step: 4
Training loss: 1.8004964590072632
Validation loss: 2.0368890265623727

Epoch: 5| Step: 5
Training loss: 2.025496006011963
Validation loss: 2.0400981307029724

Epoch: 5| Step: 6
Training loss: 2.7425336837768555
Validation loss: 2.0363422483205795

Epoch: 5| Step: 7
Training loss: 2.454995632171631
Validation loss: 2.028261125087738

Epoch: 5| Step: 8
Training loss: 2.0472095012664795
Validation loss: 2.0345309178034463

Epoch: 5| Step: 9
Training loss: 2.436455249786377
Validation loss: 2.0286036928494773

Epoch: 5| Step: 10
Training loss: 1.9754722118377686
Validation loss: 2.0257740865151086

Epoch: 5| Step: 11
Training loss: 2.917677879333496
Validation loss: 2.0332938681046167

Epoch: 142| Step: 0
Training loss: 1.969128966331482
Validation loss: 2.028849273920059

Epoch: 5| Step: 1
Training loss: 2.1081833839416504
Validation loss: 2.0309949219226837

Epoch: 5| Step: 2
Training loss: 2.269078493118286
Validation loss: 2.0234395215908685

Epoch: 5| Step: 3
Training loss: 1.5997793674468994
Validation loss: 2.032810151576996

Epoch: 5| Step: 4
Training loss: 1.7645623683929443
Validation loss: 2.032782410581907

Epoch: 5| Step: 5
Training loss: 2.4068188667297363
Validation loss: 2.0279460002978644

Epoch: 5| Step: 6
Training loss: 2.678007125854492
Validation loss: 2.0448097735643387

Epoch: 5| Step: 7
Training loss: 2.016721487045288
Validation loss: 2.030162731806437

Epoch: 5| Step: 8
Training loss: 1.7115137577056885
Validation loss: 2.034400925040245

Epoch: 5| Step: 9
Training loss: 1.7886165380477905
Validation loss: 2.019421860575676

Epoch: 5| Step: 10
Training loss: 2.3417458534240723
Validation loss: 2.0393621027469635

Epoch: 5| Step: 11
Training loss: 2.173548460006714
Validation loss: 2.045695409178734

Epoch: 143| Step: 0
Training loss: 1.8918936252593994
Validation loss: 2.0563486268122992

Epoch: 5| Step: 1
Training loss: 2.441016435623169
Validation loss: 2.0596409936745963

Epoch: 5| Step: 2
Training loss: 2.0945401191711426
Validation loss: 2.0708416551351547

Epoch: 5| Step: 3
Training loss: 1.6730749607086182
Validation loss: 2.0731250246365867

Epoch: 5| Step: 4
Training loss: 2.139946460723877
Validation loss: 2.0623008807500205

Epoch: 5| Step: 5
Training loss: 2.0725760459899902
Validation loss: 2.080473631620407

Epoch: 5| Step: 6
Training loss: 1.6163578033447266
Validation loss: 2.0776198456684747

Epoch: 5| Step: 7
Training loss: 1.4852755069732666
Validation loss: 2.0850282510121665

Epoch: 5| Step: 8
Training loss: 2.3573195934295654
Validation loss: 2.081702321767807

Epoch: 5| Step: 9
Training loss: 2.062347173690796
Validation loss: 2.0946557770172753

Epoch: 5| Step: 10
Training loss: 2.7549214363098145
Validation loss: 2.0777375201384225

Epoch: 5| Step: 11
Training loss: 2.7373008728027344
Validation loss: 2.08399627606074

Epoch: 144| Step: 0
Training loss: 2.0497145652770996
Validation loss: 2.060148686170578

Epoch: 5| Step: 1
Training loss: 1.907152533531189
Validation loss: 2.037345916032791

Epoch: 5| Step: 2
Training loss: 2.0038084983825684
Validation loss: 2.0293013155460358

Epoch: 5| Step: 3
Training loss: 2.2969212532043457
Validation loss: 2.0381418069203696

Epoch: 5| Step: 4
Training loss: 2.2895612716674805
Validation loss: 2.0302061339219413

Epoch: 5| Step: 5
Training loss: 1.803533911705017
Validation loss: 2.0427689601977668

Epoch: 5| Step: 6
Training loss: 1.544310212135315
Validation loss: 2.038988629976908

Epoch: 5| Step: 7
Training loss: 1.713327407836914
Validation loss: 2.0473008255163827

Epoch: 5| Step: 8
Training loss: 2.2496132850646973
Validation loss: 2.044518858194351

Epoch: 5| Step: 9
Training loss: 2.420088291168213
Validation loss: 2.038817748427391

Epoch: 5| Step: 10
Training loss: 2.327329635620117
Validation loss: 2.038323630889257

Epoch: 5| Step: 11
Training loss: 3.990938425064087
Validation loss: 2.0340129832426705

Epoch: 145| Step: 0
Training loss: 1.815707802772522
Validation loss: 2.034887050588926

Epoch: 5| Step: 1
Training loss: 1.98737370967865
Validation loss: 2.0390009532372155

Epoch: 5| Step: 2
Training loss: 1.4066898822784424
Validation loss: 2.033467928568522

Epoch: 5| Step: 3
Training loss: 2.3024020195007324
Validation loss: 2.035450210173925

Epoch: 5| Step: 4
Training loss: 2.4973461627960205
Validation loss: 2.0509622246026993

Epoch: 5| Step: 5
Training loss: 1.9933223724365234
Validation loss: 2.0375705460707345

Epoch: 5| Step: 6
Training loss: 2.2330687046051025
Validation loss: 2.0435663759708405

Epoch: 5| Step: 7
Training loss: 2.486844301223755
Validation loss: 2.0475338151057563

Epoch: 5| Step: 8
Training loss: 2.1179378032684326
Validation loss: 2.053139249483744

Epoch: 5| Step: 9
Training loss: 1.725481629371643
Validation loss: 2.060835520426432

Epoch: 5| Step: 10
Training loss: 1.965206503868103
Validation loss: 2.04425377647082

Epoch: 5| Step: 11
Training loss: 2.15879225730896
Validation loss: 2.061421900987625

Epoch: 146| Step: 0
Training loss: 1.5511908531188965
Validation loss: 2.0588948130607605

Epoch: 5| Step: 1
Training loss: 2.6480166912078857
Validation loss: 2.0693989793459573

Epoch: 5| Step: 2
Training loss: 1.9790422916412354
Validation loss: 2.078094258904457

Epoch: 5| Step: 3
Training loss: 1.9134830236434937
Validation loss: 2.094208280245463

Epoch: 5| Step: 4
Training loss: 2.1296911239624023
Validation loss: 2.088908756772677

Epoch: 5| Step: 5
Training loss: 2.1057565212249756
Validation loss: 2.085006167491277

Epoch: 5| Step: 6
Training loss: 2.217421770095825
Validation loss: 2.070376147826513

Epoch: 5| Step: 7
Training loss: 1.8234609365463257
Validation loss: 2.0746202717224755

Epoch: 5| Step: 8
Training loss: 2.242591619491577
Validation loss: 2.052710880835851

Epoch: 5| Step: 9
Training loss: 2.139798641204834
Validation loss: 2.063206523656845

Epoch: 5| Step: 10
Training loss: 1.9098924398422241
Validation loss: 2.0620981752872467

Epoch: 5| Step: 11
Training loss: 1.9971675872802734
Validation loss: 2.0519596338272095

Epoch: 147| Step: 0
Training loss: 1.4717292785644531
Validation loss: 2.0464324206113815

Epoch: 5| Step: 1
Training loss: 1.7206909656524658
Validation loss: 2.036065012216568

Epoch: 5| Step: 2
Training loss: 2.2368223667144775
Validation loss: 2.0382633805274963

Epoch: 5| Step: 3
Training loss: 2.3028156757354736
Validation loss: 2.0461581548055015

Epoch: 5| Step: 4
Training loss: 2.3766467571258545
Validation loss: 2.0438287556171417

Epoch: 5| Step: 5
Training loss: 2.1334400177001953
Validation loss: 2.0408539722363153

Epoch: 5| Step: 6
Training loss: 1.665326714515686
Validation loss: 2.0532742142677307

Epoch: 5| Step: 7
Training loss: 2.1143574714660645
Validation loss: 2.0576916933059692

Epoch: 5| Step: 8
Training loss: 1.759049654006958
Validation loss: 2.054388334353765

Epoch: 5| Step: 9
Training loss: 2.6228694915771484
Validation loss: 2.0706051339705787

Epoch: 5| Step: 10
Training loss: 2.0780227184295654
Validation loss: 2.077936773498853

Epoch: 5| Step: 11
Training loss: 2.283456563949585
Validation loss: 2.065149779121081

Epoch: 148| Step: 0
Training loss: 1.3556392192840576
Validation loss: 2.057770758867264

Epoch: 5| Step: 1
Training loss: 2.0010604858398438
Validation loss: 2.0547127226988473

Epoch: 5| Step: 2
Training loss: 1.9009342193603516
Validation loss: 2.0436311066150665

Epoch: 5| Step: 3
Training loss: 2.250413417816162
Validation loss: 2.036387801170349

Epoch: 5| Step: 4
Training loss: 1.8414512872695923
Validation loss: 2.0397264262040458

Epoch: 5| Step: 5
Training loss: 2.268143892288208
Validation loss: 2.0276421258846917

Epoch: 5| Step: 6
Training loss: 1.9927616119384766
Validation loss: 2.0328044643004737

Epoch: 5| Step: 7
Training loss: 2.25601863861084
Validation loss: 2.036150728662809

Epoch: 5| Step: 8
Training loss: 2.1722640991210938
Validation loss: 2.0392596820990243

Epoch: 5| Step: 9
Training loss: 2.0250039100646973
Validation loss: 2.0284201006094613

Epoch: 5| Step: 10
Training loss: 2.4539833068847656
Validation loss: 2.0459171583255134

Epoch: 5| Step: 11
Training loss: 1.21624755859375
Validation loss: 2.045897608002027

Epoch: 149| Step: 0
Training loss: 1.5384647846221924
Validation loss: 2.0525207618872323

Epoch: 5| Step: 1
Training loss: 2.0223679542541504
Validation loss: 2.0430004795392356

Epoch: 5| Step: 2
Training loss: 2.562053680419922
Validation loss: 2.0374698787927628

Epoch: 5| Step: 3
Training loss: 2.302668809890747
Validation loss: 2.0460111498832703

Epoch: 5| Step: 4
Training loss: 1.779528021812439
Validation loss: 2.047388046979904

Epoch: 5| Step: 5
Training loss: 2.146301746368408
Validation loss: 2.054787834485372

Epoch: 5| Step: 6
Training loss: 2.332440137863159
Validation loss: 2.0475855072339377

Epoch: 5| Step: 7
Training loss: 2.0582215785980225
Validation loss: 2.0502913296222687

Epoch: 5| Step: 8
Training loss: 1.530827283859253
Validation loss: 2.0550640175739923

Epoch: 5| Step: 9
Training loss: 1.961133599281311
Validation loss: 2.0611217319965363

Epoch: 5| Step: 10
Training loss: 1.8447492122650146
Validation loss: 2.058987110853195

Epoch: 5| Step: 11
Training loss: 2.4215567111968994
Validation loss: 2.052947014570236

Epoch: 150| Step: 0
Training loss: 2.2276368141174316
Validation loss: 2.0680277595917382

Epoch: 5| Step: 1
Training loss: 2.341163396835327
Validation loss: 2.0849267144997916

Epoch: 5| Step: 2
Training loss: 1.9756971597671509
Validation loss: 2.076791519920031

Epoch: 5| Step: 3
Training loss: 1.9057657718658447
Validation loss: 2.0932682702938714

Epoch: 5| Step: 4
Training loss: 2.032564640045166
Validation loss: 2.0729081332683563

Epoch: 5| Step: 5
Training loss: 1.7608588933944702
Validation loss: 2.0736284951368966

Epoch: 5| Step: 6
Training loss: 2.2458138465881348
Validation loss: 2.069328953822454

Epoch: 5| Step: 7
Training loss: 2.3508241176605225
Validation loss: 2.0644627511501312

Epoch: 5| Step: 8
Training loss: 2.051582098007202
Validation loss: 2.0593421459198

Epoch: 5| Step: 9
Training loss: 2.0321598052978516
Validation loss: 2.053919886549314

Epoch: 5| Step: 10
Training loss: 1.688615083694458
Validation loss: 2.0596539129813514

Epoch: 5| Step: 11
Training loss: 1.833664059638977
Validation loss: 2.044928729534149

Epoch: 151| Step: 0
Training loss: 2.101181983947754
Validation loss: 2.0307659109433494

Epoch: 5| Step: 1
Training loss: 1.8265117406845093
Validation loss: 2.0481579651435218

Epoch: 5| Step: 2
Training loss: 1.9184261560440063
Validation loss: 2.041796773672104

Epoch: 5| Step: 3
Training loss: 2.393528699874878
Validation loss: 2.0483522564172745

Epoch: 5| Step: 4
Training loss: 1.6092357635498047
Validation loss: 2.0654510060946145

Epoch: 5| Step: 5
Training loss: 2.096524953842163
Validation loss: 2.052465543150902

Epoch: 5| Step: 6
Training loss: 2.1556966304779053
Validation loss: 2.063996230562528

Epoch: 5| Step: 7
Training loss: 1.7684993743896484
Validation loss: 2.074505180120468

Epoch: 5| Step: 8
Training loss: 2.2485125064849854
Validation loss: 2.0691168854633966

Epoch: 5| Step: 9
Training loss: 2.15781569480896
Validation loss: 2.0763820310433707

Epoch: 5| Step: 10
Training loss: 1.9309585094451904
Validation loss: 2.0695221225420632

Epoch: 5| Step: 11
Training loss: 2.4132494926452637
Validation loss: 2.0746617019176483

Epoch: 152| Step: 0
Training loss: 2.0098776817321777
Validation loss: 2.0656077166398368

Epoch: 5| Step: 1
Training loss: 2.318232297897339
Validation loss: 2.0720235109329224

Epoch: 5| Step: 2
Training loss: 2.041161060333252
Validation loss: 2.078080728650093

Epoch: 5| Step: 3
Training loss: 1.470325231552124
Validation loss: 2.060429314772288

Epoch: 5| Step: 4
Training loss: 2.1761155128479004
Validation loss: 2.0695579200983047

Epoch: 5| Step: 5
Training loss: 2.3808302879333496
Validation loss: 2.0712072054545083

Epoch: 5| Step: 6
Training loss: 1.8987823724746704
Validation loss: 2.075493355592092

Epoch: 5| Step: 7
Training loss: 1.5329813957214355
Validation loss: 2.0631264646848044

Epoch: 5| Step: 8
Training loss: 2.5573086738586426
Validation loss: 2.0538567900657654

Epoch: 5| Step: 9
Training loss: 2.1064789295196533
Validation loss: 2.078311011195183

Epoch: 5| Step: 10
Training loss: 1.6893892288208008
Validation loss: 2.0610657731691995

Epoch: 5| Step: 11
Training loss: 1.9072997570037842
Validation loss: 2.0686482737461724

Epoch: 153| Step: 0
Training loss: 2.017817735671997
Validation loss: 2.063613931337992

Epoch: 5| Step: 1
Training loss: 2.2377820014953613
Validation loss: 2.080743362506231

Epoch: 5| Step: 2
Training loss: 1.920689582824707
Validation loss: 2.0585647573073707

Epoch: 5| Step: 3
Training loss: 1.7713077068328857
Validation loss: 2.050650432705879

Epoch: 5| Step: 4
Training loss: 1.5331523418426514
Validation loss: 2.06098273396492

Epoch: 5| Step: 5
Training loss: 2.3967747688293457
Validation loss: 2.059433196981748

Epoch: 5| Step: 6
Training loss: 2.0543410778045654
Validation loss: 2.0613111406564713

Epoch: 5| Step: 7
Training loss: 1.979884386062622
Validation loss: 2.0397347460190454

Epoch: 5| Step: 8
Training loss: 2.6730053424835205
Validation loss: 2.0363657971223197

Epoch: 5| Step: 9
Training loss: 2.165815830230713
Validation loss: 2.0315162241458893

Epoch: 5| Step: 10
Training loss: 1.5853439569473267
Validation loss: 2.032976652185122

Epoch: 5| Step: 11
Training loss: 2.09144926071167
Validation loss: 2.033494765559832

Epoch: 154| Step: 0
Training loss: 1.9567683935165405
Validation loss: 2.0444789131482444

Epoch: 5| Step: 1
Training loss: 1.7953087091445923
Validation loss: 2.044599468509356

Epoch: 5| Step: 2
Training loss: 2.251532793045044
Validation loss: 2.0470952888329825

Epoch: 5| Step: 3
Training loss: 1.6376371383666992
Validation loss: 2.0515611420075097

Epoch: 5| Step: 4
Training loss: 1.8485103845596313
Validation loss: 2.056258181730906

Epoch: 5| Step: 5
Training loss: 2.1639530658721924
Validation loss: 2.060457040866216

Epoch: 5| Step: 6
Training loss: 2.0179049968719482
Validation loss: 2.0518460075060525

Epoch: 5| Step: 7
Training loss: 2.3084418773651123
Validation loss: 2.0818873047828674

Epoch: 5| Step: 8
Training loss: 1.8174892663955688
Validation loss: 2.0628139873345694

Epoch: 5| Step: 9
Training loss: 2.3979873657226562
Validation loss: 2.0565205166737237

Epoch: 5| Step: 10
Training loss: 1.8437416553497314
Validation loss: 2.073855464657148

Epoch: 5| Step: 11
Training loss: 3.0056984424591064
Validation loss: 2.0888299395640693

Epoch: 155| Step: 0
Training loss: 1.472078800201416
Validation loss: 2.068184514840444

Epoch: 5| Step: 1
Training loss: 2.5474977493286133
Validation loss: 2.0589394718408585

Epoch: 5| Step: 2
Training loss: 2.2749104499816895
Validation loss: 2.0626924484968185

Epoch: 5| Step: 3
Training loss: 1.8518092632293701
Validation loss: 2.0702759822209678

Epoch: 5| Step: 4
Training loss: 1.6876932382583618
Validation loss: 2.069298282265663

Epoch: 5| Step: 5
Training loss: 2.7866733074188232
Validation loss: 2.0796080032984414

Epoch: 5| Step: 6
Training loss: 2.15655255317688
Validation loss: 2.0751992414395013

Epoch: 5| Step: 7
Training loss: 1.915278434753418
Validation loss: 2.098964894811312

Epoch: 5| Step: 8
Training loss: 1.834608793258667
Validation loss: 2.0901118169228234

Epoch: 5| Step: 9
Training loss: 1.6862157583236694
Validation loss: 2.0918982376654944

Epoch: 5| Step: 10
Training loss: 1.9518623352050781
Validation loss: 2.090207412838936

Epoch: 5| Step: 11
Training loss: 2.023865222930908
Validation loss: 2.0665665914614997

Epoch: 156| Step: 0
Training loss: 1.7406924962997437
Validation loss: 2.086678057909012

Epoch: 5| Step: 1
Training loss: 2.2552971839904785
Validation loss: 2.075582171479861

Epoch: 5| Step: 2
Training loss: 1.5719969272613525
Validation loss: 2.0739264488220215

Epoch: 5| Step: 3
Training loss: 1.741621971130371
Validation loss: 2.0523185382286706

Epoch: 5| Step: 4
Training loss: 2.176990032196045
Validation loss: 2.059308350086212

Epoch: 5| Step: 5
Training loss: 2.1687703132629395
Validation loss: 2.0490801533063254

Epoch: 5| Step: 6
Training loss: 2.1496169567108154
Validation loss: 2.0547187825043998

Epoch: 5| Step: 7
Training loss: 1.88921320438385
Validation loss: 2.0595719665288925

Epoch: 5| Step: 8
Training loss: 1.8847801685333252
Validation loss: 2.064060186346372

Epoch: 5| Step: 9
Training loss: 2.3878495693206787
Validation loss: 2.0743599086999893

Epoch: 5| Step: 10
Training loss: 2.032973289489746
Validation loss: 2.0773105223973594

Epoch: 5| Step: 11
Training loss: 2.0502309799194336
Validation loss: 2.076018979152044

Epoch: 157| Step: 0
Training loss: 2.0840439796447754
Validation loss: 2.0764358987410865

Epoch: 5| Step: 1
Training loss: 2.279303550720215
Validation loss: 2.0745145082473755

Epoch: 5| Step: 2
Training loss: 2.2380073070526123
Validation loss: 2.092426056663195

Epoch: 5| Step: 3
Training loss: 1.0204241275787354
Validation loss: 2.06583463648955

Epoch: 5| Step: 4
Training loss: 1.9979121685028076
Validation loss: 2.098005602757136

Epoch: 5| Step: 5
Training loss: 2.1635780334472656
Validation loss: 2.1043690145015717

Epoch: 5| Step: 6
Training loss: 1.5401194095611572
Validation loss: 2.0900252908468246

Epoch: 5| Step: 7
Training loss: 2.438774585723877
Validation loss: 2.0667351682980857

Epoch: 5| Step: 8
Training loss: 2.396317720413208
Validation loss: 2.0849661231040955

Epoch: 5| Step: 9
Training loss: 1.799740195274353
Validation loss: 2.0732632875442505

Epoch: 5| Step: 10
Training loss: 2.02099347114563
Validation loss: 2.0586961060762405

Epoch: 5| Step: 11
Training loss: 1.716131329536438
Validation loss: 2.061614861090978

Epoch: 158| Step: 0
Training loss: 2.5103774070739746
Validation loss: 2.047436942656835

Epoch: 5| Step: 1
Training loss: 1.4909143447875977
Validation loss: 2.056870386004448

Epoch: 5| Step: 2
Training loss: 2.0782864093780518
Validation loss: 2.0531680087248483

Epoch: 5| Step: 3
Training loss: 2.5314581394195557
Validation loss: 2.060529813170433

Epoch: 5| Step: 4
Training loss: 2.16355562210083
Validation loss: 2.0778133074442544

Epoch: 5| Step: 5
Training loss: 1.937260389328003
Validation loss: 2.0703196227550507

Epoch: 5| Step: 6
Training loss: 1.5188347101211548
Validation loss: 2.0880542347828546

Epoch: 5| Step: 7
Training loss: 3.2508339881896973
Validation loss: 2.1070088744163513

Epoch: 5| Step: 8
Training loss: 1.295249104499817
Validation loss: 2.0922655860582986

Epoch: 5| Step: 9
Training loss: 2.1704585552215576
Validation loss: 2.1062937577565513

Epoch: 5| Step: 10
Training loss: 1.5948448181152344
Validation loss: 2.0896951854228973

Epoch: 5| Step: 11
Training loss: 0.9885225892066956
Validation loss: 2.0831085046132407

Epoch: 159| Step: 0
Training loss: 2.297938585281372
Validation loss: 2.0618730882803598

Epoch: 5| Step: 1
Training loss: 2.4218828678131104
Validation loss: 2.0560275415579476

Epoch: 5| Step: 2
Training loss: 2.297171115875244
Validation loss: 2.0498260110616684

Epoch: 5| Step: 3
Training loss: 1.9075462818145752
Validation loss: 2.0232412417729697

Epoch: 5| Step: 4
Training loss: 1.4497750997543335
Validation loss: 2.0336533387502036

Epoch: 5| Step: 5
Training loss: 2.068479537963867
Validation loss: 2.0317164609829583

Epoch: 5| Step: 6
Training loss: 2.052473783493042
Validation loss: 2.0500394850969315

Epoch: 5| Step: 7
Training loss: 1.727296233177185
Validation loss: 2.044896533091863

Epoch: 5| Step: 8
Training loss: 1.7652040719985962
Validation loss: 2.0457301090161004

Epoch: 5| Step: 9
Training loss: 2.4646828174591064
Validation loss: 2.051249315341314

Epoch: 5| Step: 10
Training loss: 1.896600365638733
Validation loss: 2.030668318271637

Epoch: 5| Step: 11
Training loss: 2.306281566619873
Validation loss: 2.0426226357618966

Epoch: 160| Step: 0
Training loss: 1.7049872875213623
Validation loss: 2.034238030513128

Epoch: 5| Step: 1
Training loss: 2.242382287979126
Validation loss: 2.0375191469987235

Epoch: 5| Step: 2
Training loss: 2.093912124633789
Validation loss: 2.0401446173588433

Epoch: 5| Step: 3
Training loss: 2.1221718788146973
Validation loss: 2.032146299878756

Epoch: 5| Step: 4
Training loss: 1.7788612842559814
Validation loss: 2.0417685260375342

Epoch: 5| Step: 5
Training loss: 2.0979433059692383
Validation loss: 2.045154015223185

Epoch: 5| Step: 6
Training loss: 2.1113293170928955
Validation loss: 2.042351335287094

Epoch: 5| Step: 7
Training loss: 1.7013771533966064
Validation loss: 2.0577702720959983

Epoch: 5| Step: 8
Training loss: 2.440589427947998
Validation loss: 2.073622410496076

Epoch: 5| Step: 9
Training loss: 2.0858194828033447
Validation loss: 2.0840755999088287

Epoch: 5| Step: 10
Training loss: 2.097270965576172
Validation loss: 2.0903890281915665

Epoch: 5| Step: 11
Training loss: 2.659806251525879
Validation loss: 2.100246568520864

Epoch: 161| Step: 0
Training loss: 2.015319347381592
Validation loss: 2.0966565211613974

Epoch: 5| Step: 1
Training loss: 2.244580030441284
Validation loss: 2.0648587296406427

Epoch: 5| Step: 2
Training loss: 1.8975517749786377
Validation loss: 2.06669948498408

Epoch: 5| Step: 3
Training loss: 1.581070065498352
Validation loss: 2.044016848007838

Epoch: 5| Step: 4
Training loss: 2.196195125579834
Validation loss: 2.042506063977877

Epoch: 5| Step: 5
Training loss: 1.5193461179733276
Validation loss: 2.0382482757170997

Epoch: 5| Step: 6
Training loss: 2.0049846172332764
Validation loss: 2.048643931746483

Epoch: 5| Step: 7
Training loss: 2.1727538108825684
Validation loss: 2.049485375483831

Epoch: 5| Step: 8
Training loss: 2.595696210861206
Validation loss: 2.0501497089862823

Epoch: 5| Step: 9
Training loss: 1.6579625606536865
Validation loss: 2.054255793491999

Epoch: 5| Step: 10
Training loss: 2.073312759399414
Validation loss: 2.0536512037118277

Epoch: 5| Step: 11
Training loss: 3.2177443504333496
Validation loss: 2.0645000586907067

Epoch: 162| Step: 0
Training loss: 1.9480844736099243
Validation loss: 2.0748873502016068

Epoch: 5| Step: 1
Training loss: 2.5197815895080566
Validation loss: 2.04716420173645

Epoch: 5| Step: 2
Training loss: 2.220027446746826
Validation loss: 2.0729495187600455

Epoch: 5| Step: 3
Training loss: 1.4713648557662964
Validation loss: 2.075481802225113

Epoch: 5| Step: 4
Training loss: 2.151402235031128
Validation loss: 2.0828527410825095

Epoch: 5| Step: 5
Training loss: 1.5171024799346924
Validation loss: 2.070964718858401

Epoch: 5| Step: 6
Training loss: 2.249924898147583
Validation loss: 2.084931269288063

Epoch: 5| Step: 7
Training loss: 1.8473488092422485
Validation loss: 2.078303496042887

Epoch: 5| Step: 8
Training loss: 1.7644141912460327
Validation loss: 2.0817830661932626

Epoch: 5| Step: 9
Training loss: 2.015164613723755
Validation loss: 2.0624786963065467

Epoch: 5| Step: 10
Training loss: 2.5205588340759277
Validation loss: 2.0676595866680145

Epoch: 5| Step: 11
Training loss: 1.3465075492858887
Validation loss: 2.062610516945521

Epoch: 163| Step: 0
Training loss: 1.843001127243042
Validation loss: 2.0512250860532126

Epoch: 5| Step: 1
Training loss: 2.0828425884246826
Validation loss: 2.056936651468277

Epoch: 5| Step: 2
Training loss: 1.7905304431915283
Validation loss: 2.047486111521721

Epoch: 5| Step: 3
Training loss: 1.8248659372329712
Validation loss: 2.0419631799062095

Epoch: 5| Step: 4
Training loss: 1.7809474468231201
Validation loss: 2.04624276359876

Epoch: 5| Step: 5
Training loss: 2.5322060585021973
Validation loss: 2.0487855474154153

Epoch: 5| Step: 6
Training loss: 2.08312726020813
Validation loss: 2.044728701313337

Epoch: 5| Step: 7
Training loss: 2.3291079998016357
Validation loss: 2.047198921442032

Epoch: 5| Step: 8
Training loss: 1.8712270259857178
Validation loss: 2.054282248020172

Epoch: 5| Step: 9
Training loss: 1.5648460388183594
Validation loss: 2.0495338489611945

Epoch: 5| Step: 10
Training loss: 2.1411805152893066
Validation loss: 2.027634466687838

Epoch: 5| Step: 11
Training loss: 3.291933059692383
Validation loss: 2.069153924783071

Epoch: 164| Step: 0
Training loss: 2.3721537590026855
Validation loss: 2.062268227338791

Epoch: 5| Step: 1
Training loss: 1.5883394479751587
Validation loss: 2.0950052638848624

Epoch: 5| Step: 2
Training loss: 2.085768461227417
Validation loss: 2.0947679380575814

Epoch: 5| Step: 3
Training loss: 1.8136062622070312
Validation loss: 2.1047752598921456

Epoch: 5| Step: 4
Training loss: 2.769106149673462
Validation loss: 2.089094862341881

Epoch: 5| Step: 5
Training loss: 1.9293756484985352
Validation loss: 2.0863703737656274

Epoch: 5| Step: 6
Training loss: 2.611255407333374
Validation loss: 2.085965777436892

Epoch: 5| Step: 7
Training loss: 2.2205917835235596
Validation loss: 2.073415771126747

Epoch: 5| Step: 8
Training loss: 1.7600723505020142
Validation loss: 2.0546529243389764

Epoch: 5| Step: 9
Training loss: 1.709499716758728
Validation loss: 2.048416847983996

Epoch: 5| Step: 10
Training loss: 1.7656329870224
Validation loss: 2.047840024034182

Epoch: 5| Step: 11
Training loss: 1.1986416578292847
Validation loss: 2.0473800698916116

Epoch: 165| Step: 0
Training loss: 2.582141876220703
Validation loss: 2.0516723295052848

Epoch: 5| Step: 1
Training loss: 1.7087271213531494
Validation loss: 2.049453149239222

Epoch: 5| Step: 2
Training loss: 1.6702152490615845
Validation loss: 2.051457166671753

Epoch: 5| Step: 3
Training loss: 1.7316640615463257
Validation loss: 2.0417089462280273

Epoch: 5| Step: 4
Training loss: 1.644801378250122
Validation loss: 2.058940256635348

Epoch: 5| Step: 5
Training loss: 1.7486759424209595
Validation loss: 2.05403071641922

Epoch: 5| Step: 6
Training loss: 2.634817361831665
Validation loss: 2.078225761651993

Epoch: 5| Step: 7
Training loss: 2.1124730110168457
Validation loss: 2.0731226007143655

Epoch: 5| Step: 8
Training loss: 2.374505043029785
Validation loss: 2.091471945246061

Epoch: 5| Step: 9
Training loss: 2.439113140106201
Validation loss: 2.0907407850027084

Epoch: 5| Step: 10
Training loss: 1.6635907888412476
Validation loss: 2.0786236226558685

Epoch: 5| Step: 11
Training loss: 1.5139681100845337
Validation loss: 2.0902807215849557

Epoch: 166| Step: 0
Training loss: 2.036181926727295
Validation loss: 2.0816322565078735

Epoch: 5| Step: 1
Training loss: 1.9411051273345947
Validation loss: 2.0908669183651605

Epoch: 5| Step: 2
Training loss: 2.1874053478240967
Validation loss: 2.079453925291697

Epoch: 5| Step: 3
Training loss: 2.506727457046509
Validation loss: 2.0655070344607034

Epoch: 5| Step: 4
Training loss: 1.6670547723770142
Validation loss: 2.063758467634519

Epoch: 5| Step: 5
Training loss: 1.7979156970977783
Validation loss: 2.071154067913691

Epoch: 5| Step: 6
Training loss: 2.1061012744903564
Validation loss: 2.0772803525129953

Epoch: 5| Step: 7
Training loss: 1.943648099899292
Validation loss: 2.085760474205017

Epoch: 5| Step: 8
Training loss: 1.858842134475708
Validation loss: 2.083045562108358

Epoch: 5| Step: 9
Training loss: 1.9610302448272705
Validation loss: 2.085502788424492

Epoch: 5| Step: 10
Training loss: 2.005218267440796
Validation loss: 2.0909055272738137

Epoch: 5| Step: 11
Training loss: 1.7634193897247314
Validation loss: 2.10480668147405

Epoch: 167| Step: 0
Training loss: 2.4180984497070312
Validation loss: 2.1166422267754874

Epoch: 5| Step: 1
Training loss: 2.0207552909851074
Validation loss: 2.110060820976893

Epoch: 5| Step: 2
Training loss: 1.7397493124008179
Validation loss: 2.11234616736571

Epoch: 5| Step: 3
Training loss: 2.449852705001831
Validation loss: 2.1136593222618103

Epoch: 5| Step: 4
Training loss: 2.2491207122802734
Validation loss: 2.1049235115448632

Epoch: 5| Step: 5
Training loss: 1.8987464904785156
Validation loss: 2.095785766839981

Epoch: 5| Step: 6
Training loss: 1.619463562965393
Validation loss: 2.1087642510732016

Epoch: 5| Step: 7
Training loss: 1.804918885231018
Validation loss: 2.100917547941208

Epoch: 5| Step: 8
Training loss: 1.414629340171814
Validation loss: 2.100723385810852

Epoch: 5| Step: 9
Training loss: 2.090546131134033
Validation loss: 2.1041728854179382

Epoch: 5| Step: 10
Training loss: 2.3249621391296387
Validation loss: 2.1045065025488534

Epoch: 5| Step: 11
Training loss: 1.836184024810791
Validation loss: 2.1012253115574517

Epoch: 168| Step: 0
Training loss: 1.9133684635162354
Validation loss: 2.110861678918203

Epoch: 5| Step: 1
Training loss: 1.7048065662384033
Validation loss: 2.105371341109276

Epoch: 5| Step: 2
Training loss: 2.31538462638855
Validation loss: 2.099768062432607

Epoch: 5| Step: 3
Training loss: 2.0340421199798584
Validation loss: 2.0961801211039224

Epoch: 5| Step: 4
Training loss: 1.9367952346801758
Validation loss: 2.1149993936220803

Epoch: 5| Step: 5
Training loss: 1.8793662786483765
Validation loss: 2.101175511876742

Epoch: 5| Step: 6
Training loss: 2.3394672870635986
Validation loss: 2.1066568543513617

Epoch: 5| Step: 7
Training loss: 2.0087790489196777
Validation loss: 2.1155900756518045

Epoch: 5| Step: 8
Training loss: 2.113358974456787
Validation loss: 2.1031272212664285

Epoch: 5| Step: 9
Training loss: 1.749654769897461
Validation loss: 2.0911672214667

Epoch: 5| Step: 10
Training loss: 1.9325811862945557
Validation loss: 2.124949499964714

Epoch: 5| Step: 11
Training loss: 1.0538156032562256
Validation loss: 2.0885301182667413

Epoch: 169| Step: 0
Training loss: 2.3781142234802246
Validation loss: 2.0920408566792807

Epoch: 5| Step: 1
Training loss: 2.1309452056884766
Validation loss: 2.1060534765323005

Epoch: 5| Step: 2
Training loss: 1.7918697595596313
Validation loss: 2.0981012334426246

Epoch: 5| Step: 3
Training loss: 1.7818365097045898
Validation loss: 2.0937001605828605

Epoch: 5| Step: 4
Training loss: 2.034243106842041
Validation loss: 2.101836254199346

Epoch: 5| Step: 5
Training loss: 2.139200210571289
Validation loss: 2.097790280977885

Epoch: 5| Step: 6
Training loss: 1.947011947631836
Validation loss: 2.0943963527679443

Epoch: 5| Step: 7
Training loss: 1.9312632083892822
Validation loss: 2.108624681830406

Epoch: 5| Step: 8
Training loss: 2.2472620010375977
Validation loss: 2.106350709994634

Epoch: 5| Step: 9
Training loss: 1.5171566009521484
Validation loss: 2.1026380558808646

Epoch: 5| Step: 10
Training loss: 1.9212566614151
Validation loss: 2.111838847398758

Epoch: 5| Step: 11
Training loss: 1.278037190437317
Validation loss: 2.1021220286687217

Epoch: 170| Step: 0
Training loss: 1.9199711084365845
Validation loss: 2.1031867315371833

Epoch: 5| Step: 1
Training loss: 1.6219608783721924
Validation loss: 2.094475025931994

Epoch: 5| Step: 2
Training loss: 2.3807921409606934
Validation loss: 2.0858023862044015

Epoch: 5| Step: 3
Training loss: 2.223273515701294
Validation loss: 2.09171270330747

Epoch: 5| Step: 4
Training loss: 1.8092235326766968
Validation loss: 2.0944886108239493

Epoch: 5| Step: 5
Training loss: 1.9606268405914307
Validation loss: 2.084617147843043

Epoch: 5| Step: 6
Training loss: 1.9671337604522705
Validation loss: 2.1034459471702576

Epoch: 5| Step: 7
Training loss: 2.0203120708465576
Validation loss: 2.106820359826088

Epoch: 5| Step: 8
Training loss: 2.436511993408203
Validation loss: 2.106839135289192

Epoch: 5| Step: 9
Training loss: 2.0870299339294434
Validation loss: 2.113770912090937

Epoch: 5| Step: 10
Training loss: 1.5704160928726196
Validation loss: 2.1148199836413064

Epoch: 5| Step: 11
Training loss: 1.1360887289047241
Validation loss: 2.1141577859719596

Epoch: 171| Step: 0
Training loss: 2.1857855319976807
Validation loss: 2.1123937169710794

Epoch: 5| Step: 1
Training loss: 1.569622278213501
Validation loss: 2.1200153827667236

Epoch: 5| Step: 2
Training loss: 1.5483351945877075
Validation loss: 2.1248090664545694

Epoch: 5| Step: 3
Training loss: 2.1657321453094482
Validation loss: 2.1176723738511405

Epoch: 5| Step: 4
Training loss: 1.36892569065094
Validation loss: 2.1084528267383575

Epoch: 5| Step: 5
Training loss: 1.89926016330719
Validation loss: 2.1123234728972116

Epoch: 5| Step: 6
Training loss: 1.5662391185760498
Validation loss: 2.1104866663614907

Epoch: 5| Step: 7
Training loss: 2.0637292861938477
Validation loss: 2.105678930878639

Epoch: 5| Step: 8
Training loss: 2.789393186569214
Validation loss: 2.1006958335638046

Epoch: 5| Step: 9
Training loss: 1.9950859546661377
Validation loss: 2.099813958009084

Epoch: 5| Step: 10
Training loss: 2.7195725440979004
Validation loss: 2.1218538681666055

Epoch: 5| Step: 11
Training loss: 0.7331569194793701
Validation loss: 2.1070581674575806

Epoch: 172| Step: 0
Training loss: 2.227914571762085
Validation loss: 2.109643042087555

Epoch: 5| Step: 1
Training loss: 2.1155619621276855
Validation loss: 2.093496471643448

Epoch: 5| Step: 2
Training loss: 2.3451931476593018
Validation loss: 2.09815913438797

Epoch: 5| Step: 3
Training loss: 2.06632661819458
Validation loss: 2.123622864484787

Epoch: 5| Step: 4
Training loss: 1.8906314373016357
Validation loss: 2.1090524792671204

Epoch: 5| Step: 5
Training loss: 1.424591302871704
Validation loss: 2.1322911183039346

Epoch: 5| Step: 6
Training loss: 2.7896525859832764
Validation loss: 2.12082048257192

Epoch: 5| Step: 7
Training loss: 1.9619624614715576
Validation loss: 2.1193068424860635

Epoch: 5| Step: 8
Training loss: 1.6473881006240845
Validation loss: 2.1183803429206214

Epoch: 5| Step: 9
Training loss: 1.7696412801742554
Validation loss: 2.12502957880497

Epoch: 5| Step: 10
Training loss: 1.3058605194091797
Validation loss: 2.1123567074537277

Epoch: 5| Step: 11
Training loss: 2.154855251312256
Validation loss: 2.1249096989631653

Epoch: 173| Step: 0
Training loss: 2.5814402103424072
Validation loss: 2.118207315603892

Epoch: 5| Step: 1
Training loss: 1.942291498184204
Validation loss: 2.1108036736647287

Epoch: 5| Step: 2
Training loss: 1.9360711574554443
Validation loss: 2.1295909931262336

Epoch: 5| Step: 3
Training loss: 1.630292296409607
Validation loss: 2.1136637777090073

Epoch: 5| Step: 4
Training loss: 1.871925950050354
Validation loss: 2.1152846664190292

Epoch: 5| Step: 5
Training loss: 2.4050660133361816
Validation loss: 2.0864435732364655

Epoch: 5| Step: 6
Training loss: 1.9023211002349854
Validation loss: 2.0691226720809937

Epoch: 5| Step: 7
Training loss: 1.6799333095550537
Validation loss: 2.0812588781118393

Epoch: 5| Step: 8
Training loss: 1.6544033288955688
Validation loss: 2.107820436358452

Epoch: 5| Step: 9
Training loss: 1.8106660842895508
Validation loss: 2.0927833914756775

Epoch: 5| Step: 10
Training loss: 1.8740631341934204
Validation loss: 2.1088410019874573

Epoch: 5| Step: 11
Training loss: 2.7834606170654297
Validation loss: 2.1109536637862525

Epoch: 174| Step: 0
Training loss: 2.4202842712402344
Validation loss: 2.124027838309606

Epoch: 5| Step: 1
Training loss: 1.5402016639709473
Validation loss: 2.1609127819538116

Epoch: 5| Step: 2
Training loss: 1.9284557104110718
Validation loss: 2.1868547797203064

Epoch: 5| Step: 3
Training loss: 2.650574207305908
Validation loss: 2.1736471156279245

Epoch: 5| Step: 4
Training loss: 2.2233612537384033
Validation loss: 2.1780514419078827

Epoch: 5| Step: 5
Training loss: 1.875187635421753
Validation loss: 2.1491005271673203

Epoch: 5| Step: 6
Training loss: 2.0808472633361816
Validation loss: 2.1243114123741784

Epoch: 5| Step: 7
Training loss: 1.8366668224334717
Validation loss: 2.1138502111037574

Epoch: 5| Step: 8
Training loss: 2.1911840438842773
Validation loss: 2.104811275998751

Epoch: 5| Step: 9
Training loss: 1.9423854351043701
Validation loss: 2.074678306778272

Epoch: 5| Step: 10
Training loss: 1.4681622982025146
Validation loss: 2.0605408996343613

Epoch: 5| Step: 11
Training loss: 2.690311908721924
Validation loss: 2.0494164476792016

Epoch: 175| Step: 0
Training loss: 2.2605223655700684
Validation loss: 2.048793683449427

Epoch: 5| Step: 1
Training loss: 2.0511770248413086
Validation loss: 2.0530106027921042

Epoch: 5| Step: 2
Training loss: 1.8767772912979126
Validation loss: 2.0562662382920585

Epoch: 5| Step: 3
Training loss: 2.313753843307495
Validation loss: 2.0584900627533593

Epoch: 5| Step: 4
Training loss: 2.5619113445281982
Validation loss: 2.04328087468942

Epoch: 5| Step: 5
Training loss: 1.7787001132965088
Validation loss: 2.048886612057686

Epoch: 5| Step: 6
Training loss: 2.048311710357666
Validation loss: 2.0502093732357025

Epoch: 5| Step: 7
Training loss: 1.8755842447280884
Validation loss: 2.0620561093091965

Epoch: 5| Step: 8
Training loss: 1.260658621788025
Validation loss: 2.065631926059723

Epoch: 5| Step: 9
Training loss: 2.901337146759033
Validation loss: 2.0730840265750885

Epoch: 5| Step: 10
Training loss: 1.8121830224990845
Validation loss: 2.080437332391739

Epoch: 5| Step: 11
Training loss: 0.8651844263076782
Validation loss: 2.099781647324562

Epoch: 176| Step: 0
Training loss: 2.0604045391082764
Validation loss: 2.1288950592279434

Epoch: 5| Step: 1
Training loss: 2.2282776832580566
Validation loss: 2.1528427551190057

Epoch: 5| Step: 2
Training loss: 2.3514537811279297
Validation loss: 2.1829326202472052

Epoch: 5| Step: 3
Training loss: 2.513345241546631
Validation loss: 2.2034791111946106

Epoch: 5| Step: 4
Training loss: 2.686647653579712
Validation loss: 2.2119462192058563

Epoch: 5| Step: 5
Training loss: 2.5614449977874756
Validation loss: 2.186766212185224

Epoch: 5| Step: 6
Training loss: 2.6634716987609863
Validation loss: 2.159859379132589

Epoch: 5| Step: 7
Training loss: 1.4756953716278076
Validation loss: 2.114152361949285

Epoch: 5| Step: 8
Training loss: 1.4489409923553467
Validation loss: 2.1040649910767875

Epoch: 5| Step: 9
Training loss: 1.7306673526763916
Validation loss: 2.081818143526713

Epoch: 5| Step: 10
Training loss: 1.6047395467758179
Validation loss: 2.0818353394667306

Epoch: 5| Step: 11
Training loss: 1.2968761920928955
Validation loss: 2.0672599524259567

Epoch: 177| Step: 0
Training loss: 1.8287261724472046
Validation loss: 2.0664753913879395

Epoch: 5| Step: 1
Training loss: 1.8200976848602295
Validation loss: 2.0586385279893875

Epoch: 5| Step: 2
Training loss: 1.8923110961914062
Validation loss: 2.063688745101293

Epoch: 5| Step: 3
Training loss: 2.194934129714966
Validation loss: 2.0795823434988656

Epoch: 5| Step: 4
Training loss: 2.305129289627075
Validation loss: 2.078594893217087

Epoch: 5| Step: 5
Training loss: 1.460890531539917
Validation loss: 2.0707147121429443

Epoch: 5| Step: 6
Training loss: 2.1393141746520996
Validation loss: 2.0867805033922195

Epoch: 5| Step: 7
Training loss: 1.950562834739685
Validation loss: 2.0764946788549423

Epoch: 5| Step: 8
Training loss: 1.5757659673690796
Validation loss: 2.0827264140049615

Epoch: 5| Step: 9
Training loss: 2.6284806728363037
Validation loss: 2.068384403983752

Epoch: 5| Step: 10
Training loss: 1.7384850978851318
Validation loss: 2.078292911251386

Epoch: 5| Step: 11
Training loss: 3.0930445194244385
Validation loss: 2.0875227053960166

Epoch: 178| Step: 0
Training loss: 1.887359857559204
Validation loss: 2.1040916045506797

Epoch: 5| Step: 1
Training loss: 2.56939435005188
Validation loss: 2.1514725188414254

Epoch: 5| Step: 2
Training loss: 2.7247371673583984
Validation loss: 2.1807960669199624

Epoch: 5| Step: 3
Training loss: 2.3757569789886475
Validation loss: 2.1807647297779718

Epoch: 5| Step: 4
Training loss: 2.4026601314544678
Validation loss: 2.213911091287931

Epoch: 5| Step: 5
Training loss: 1.8390098810195923
Validation loss: 2.1928808987140656

Epoch: 5| Step: 6
Training loss: 2.598453998565674
Validation loss: 2.1803592493136725

Epoch: 5| Step: 7
Training loss: 2.068943977355957
Validation loss: 2.1381742109855018

Epoch: 5| Step: 8
Training loss: 1.9492822885513306
Validation loss: 2.0994866490364075

Epoch: 5| Step: 9
Training loss: 1.9849750995635986
Validation loss: 2.1094895551602044

Epoch: 5| Step: 10
Training loss: 1.2846567630767822
Validation loss: 2.100442965825399

Epoch: 5| Step: 11
Training loss: 1.0384645462036133
Validation loss: 2.0854054192701974

Epoch: 179| Step: 0
Training loss: 1.9369583129882812
Validation loss: 2.097208430369695

Epoch: 5| Step: 1
Training loss: 1.730752944946289
Validation loss: 2.099866976340612

Epoch: 5| Step: 2
Training loss: 1.812929391860962
Validation loss: 2.079895039399465

Epoch: 5| Step: 3
Training loss: 2.016848087310791
Validation loss: 2.073663984735807

Epoch: 5| Step: 4
Training loss: 2.428828716278076
Validation loss: 2.072995056708654

Epoch: 5| Step: 5
Training loss: 2.112464427947998
Validation loss: 2.0772263556718826

Epoch: 5| Step: 6
Training loss: 2.006549835205078
Validation loss: 2.0840960294008255

Epoch: 5| Step: 7
Training loss: 2.1308655738830566
Validation loss: 2.077560211221377

Epoch: 5| Step: 8
Training loss: 2.1353302001953125
Validation loss: 2.0773661683003106

Epoch: 5| Step: 9
Training loss: 1.8390991687774658
Validation loss: 2.0911919375260672

Epoch: 5| Step: 10
Training loss: 1.875950574874878
Validation loss: 2.1018598477045694

Epoch: 5| Step: 11
Training loss: 2.089672327041626
Validation loss: 2.0913305232922235

Epoch: 180| Step: 0
Training loss: 1.939827561378479
Validation loss: 2.1087235460678735

Epoch: 5| Step: 1
Training loss: 2.4885196685791016
Validation loss: 2.104020049174627

Epoch: 5| Step: 2
Training loss: 1.9772403240203857
Validation loss: 2.114986479282379

Epoch: 5| Step: 3
Training loss: 2.002035140991211
Validation loss: 2.1111597071091333

Epoch: 5| Step: 4
Training loss: 2.1107239723205566
Validation loss: 2.1036379287640252

Epoch: 5| Step: 5
Training loss: 1.5465154647827148
Validation loss: 2.103782390554746

Epoch: 5| Step: 6
Training loss: 2.229154109954834
Validation loss: 2.0988922715187073

Epoch: 5| Step: 7
Training loss: 1.8478174209594727
Validation loss: 2.074622079730034

Epoch: 5| Step: 8
Training loss: 1.9627479314804077
Validation loss: 2.087372144063314

Epoch: 5| Step: 9
Training loss: 1.8270984888076782
Validation loss: 2.087815930445989

Epoch: 5| Step: 10
Training loss: 2.0185964107513428
Validation loss: 2.1072397430737815

Epoch: 5| Step: 11
Training loss: 2.803361654281616
Validation loss: 2.1046216984589896

Epoch: 181| Step: 0
Training loss: 2.2501187324523926
Validation loss: 2.1372746229171753

Epoch: 5| Step: 1
Training loss: 2.1123054027557373
Validation loss: 2.138443037867546

Epoch: 5| Step: 2
Training loss: 1.7439985275268555
Validation loss: 2.1400206784407296

Epoch: 5| Step: 3
Training loss: 2.249083995819092
Validation loss: 2.1417401234308877

Epoch: 5| Step: 4
Training loss: 1.510401725769043
Validation loss: 2.137495363752047

Epoch: 5| Step: 5
Training loss: 1.5343146324157715
Validation loss: 2.1441491146882377

Epoch: 5| Step: 6
Training loss: 2.1793816089630127
Validation loss: 2.132688785592715

Epoch: 5| Step: 7
Training loss: 1.9909753799438477
Validation loss: 2.1384071856737137

Epoch: 5| Step: 8
Training loss: 1.8337332010269165
Validation loss: 2.133847802877426

Epoch: 5| Step: 9
Training loss: 2.1652560234069824
Validation loss: 2.136339177687963

Epoch: 5| Step: 10
Training loss: 1.8022146224975586
Validation loss: 2.1244534651438394

Epoch: 5| Step: 11
Training loss: 3.094594955444336
Validation loss: 2.1295999735593796

Epoch: 182| Step: 0
Training loss: 2.386165142059326
Validation loss: 2.116713583469391

Epoch: 5| Step: 1
Training loss: 2.5224270820617676
Validation loss: 2.0885570496320724

Epoch: 5| Step: 2
Training loss: 1.9367952346801758
Validation loss: 2.0851635734240213

Epoch: 5| Step: 3
Training loss: 2.016112804412842
Validation loss: 2.0767702211936316

Epoch: 5| Step: 4
Training loss: 1.6317802667617798
Validation loss: 2.0727755029996238

Epoch: 5| Step: 5
Training loss: 2.0552918910980225
Validation loss: 2.0754046589136124

Epoch: 5| Step: 6
Training loss: 2.000805616378784
Validation loss: 2.0799792110919952

Epoch: 5| Step: 7
Training loss: 1.9427229166030884
Validation loss: 2.07145231962204

Epoch: 5| Step: 8
Training loss: 1.32917320728302
Validation loss: 2.0673968394597373

Epoch: 5| Step: 9
Training loss: 2.2697837352752686
Validation loss: 2.0693979064623513

Epoch: 5| Step: 10
Training loss: 1.8636586666107178
Validation loss: 2.0655060758193335

Epoch: 5| Step: 11
Training loss: 2.384554862976074
Validation loss: 2.0761702954769135

Epoch: 183| Step: 0
Training loss: 1.7458140850067139
Validation loss: 2.0729864984750748

Epoch: 5| Step: 1
Training loss: 2.2034060955047607
Validation loss: 2.0889408787091575

Epoch: 5| Step: 2
Training loss: 2.1404309272766113
Validation loss: 2.096575528383255

Epoch: 5| Step: 3
Training loss: 2.2149569988250732
Validation loss: 2.1003670940796533

Epoch: 5| Step: 4
Training loss: 2.1255898475646973
Validation loss: 2.130603611469269

Epoch: 5| Step: 5
Training loss: 1.9383137226104736
Validation loss: 2.1214871207873025

Epoch: 5| Step: 6
Training loss: 1.6700795888900757
Validation loss: 2.1322730779647827

Epoch: 5| Step: 7
Training loss: 1.4297220706939697
Validation loss: 2.1259961277246475

Epoch: 5| Step: 8
Training loss: 2.3987159729003906
Validation loss: 2.105163117249807

Epoch: 5| Step: 9
Training loss: 1.7614145278930664
Validation loss: 2.1159022400776544

Epoch: 5| Step: 10
Training loss: 2.398070812225342
Validation loss: 2.1085276007652283

Epoch: 5| Step: 11
Training loss: 2.238316059112549
Validation loss: 2.1153319080670676

Epoch: 184| Step: 0
Training loss: 1.9778993129730225
Validation loss: 2.115676000714302

Epoch: 5| Step: 1
Training loss: 2.285543918609619
Validation loss: 2.1163127472003302

Epoch: 5| Step: 2
Training loss: 1.7126481533050537
Validation loss: 2.1238578061262765

Epoch: 5| Step: 3
Training loss: 1.6714454889297485
Validation loss: 2.121319144964218

Epoch: 5| Step: 4
Training loss: 1.6140425205230713
Validation loss: 2.1223324040571847

Epoch: 5| Step: 5
Training loss: 2.1024699211120605
Validation loss: 2.1169454058011374

Epoch: 5| Step: 6
Training loss: 2.1062958240509033
Validation loss: 2.094119146466255

Epoch: 5| Step: 7
Training loss: 1.9305965900421143
Validation loss: 2.1062323848406472

Epoch: 5| Step: 8
Training loss: 2.230642795562744
Validation loss: 2.098628063996633

Epoch: 5| Step: 9
Training loss: 2.4954235553741455
Validation loss: 2.10561070839564

Epoch: 5| Step: 10
Training loss: 1.800807237625122
Validation loss: 2.0990948726733527

Epoch: 5| Step: 11
Training loss: 0.9918873310089111
Validation loss: 2.093509331345558

Epoch: 185| Step: 0
Training loss: 2.208397626876831
Validation loss: 2.0932374199231467

Epoch: 5| Step: 1
Training loss: 2.1927316188812256
Validation loss: 2.1001802732547126

Epoch: 5| Step: 2
Training loss: 2.679723024368286
Validation loss: 2.0968728214502335

Epoch: 5| Step: 3
Training loss: 2.1545205116271973
Validation loss: 2.1030202905337014

Epoch: 5| Step: 4
Training loss: 1.626918077468872
Validation loss: 2.1032360841830573

Epoch: 5| Step: 5
Training loss: 1.9832404851913452
Validation loss: 2.111040696501732

Epoch: 5| Step: 6
Training loss: 1.583045482635498
Validation loss: 2.0988003462553024

Epoch: 5| Step: 7
Training loss: 1.5818793773651123
Validation loss: 2.1145032793283463

Epoch: 5| Step: 8
Training loss: 2.2742626667022705
Validation loss: 2.1043164432048798

Epoch: 5| Step: 9
Training loss: 1.7576179504394531
Validation loss: 2.115548054377238

Epoch: 5| Step: 10
Training loss: 1.6820303201675415
Validation loss: 2.119932681322098

Epoch: 5| Step: 11
Training loss: 1.7106448411941528
Validation loss: 2.111779193083445

Epoch: 186| Step: 0
Training loss: 1.88687002658844
Validation loss: 2.1005839854478836

Epoch: 5| Step: 1
Training loss: 2.038634777069092
Validation loss: 2.1115767657756805

Epoch: 5| Step: 2
Training loss: 2.0649571418762207
Validation loss: 2.1032232542832694

Epoch: 5| Step: 3
Training loss: 1.8156179189682007
Validation loss: 2.1033037503560386

Epoch: 5| Step: 4
Training loss: 2.183349132537842
Validation loss: 2.1010784606138864

Epoch: 5| Step: 5
Training loss: 2.168888568878174
Validation loss: 2.10720361272494

Epoch: 5| Step: 6
Training loss: 1.8960587978363037
Validation loss: 2.0901168286800385

Epoch: 5| Step: 7
Training loss: 2.041992425918579
Validation loss: 2.0965258181095123

Epoch: 5| Step: 8
Training loss: 1.372659683227539
Validation loss: 2.095635617772738

Epoch: 5| Step: 9
Training loss: 2.0069527626037598
Validation loss: 2.0792843947807946

Epoch: 5| Step: 10
Training loss: 2.6210849285125732
Validation loss: 2.0944683651129403

Epoch: 5| Step: 11
Training loss: 0.7558534145355225
Validation loss: 2.089138483007749

Epoch: 187| Step: 0
Training loss: 2.4702305793762207
Validation loss: 2.0970193445682526

Epoch: 5| Step: 1
Training loss: 1.6298824548721313
Validation loss: 2.1047834306955338

Epoch: 5| Step: 2
Training loss: 1.7795727252960205
Validation loss: 2.0922384510437646

Epoch: 5| Step: 3
Training loss: 1.706369400024414
Validation loss: 2.124903440475464

Epoch: 5| Step: 4
Training loss: 1.8503761291503906
Validation loss: 2.1022598892450333

Epoch: 5| Step: 5
Training loss: 2.6700809001922607
Validation loss: 2.112869625290235

Epoch: 5| Step: 6
Training loss: 1.9761674404144287
Validation loss: 2.1185315400362015

Epoch: 5| Step: 7
Training loss: 1.295600414276123
Validation loss: 2.111032028992971

Epoch: 5| Step: 8
Training loss: 2.3632192611694336
Validation loss: 2.1095394492149353

Epoch: 5| Step: 9
Training loss: 1.9474674463272095
Validation loss: 2.109502633412679

Epoch: 5| Step: 10
Training loss: 1.8563543558120728
Validation loss: 2.1112426618734994

Epoch: 5| Step: 11
Training loss: 1.4092192649841309
Validation loss: 2.1320969561735788

Epoch: 188| Step: 0
Training loss: 2.0179810523986816
Validation loss: 2.099945987264315

Epoch: 5| Step: 1
Training loss: 1.4078376293182373
Validation loss: 2.105917697151502

Epoch: 5| Step: 2
Training loss: 1.7293071746826172
Validation loss: 2.0994425465663276

Epoch: 5| Step: 3
Training loss: 1.8902877569198608
Validation loss: 2.1121236930290856

Epoch: 5| Step: 4
Training loss: 2.0182862281799316
Validation loss: 2.109191710750262

Epoch: 5| Step: 5
Training loss: 2.480703353881836
Validation loss: 2.1167200009028115

Epoch: 5| Step: 6
Training loss: 1.239825963973999
Validation loss: 2.100595618287722

Epoch: 5| Step: 7
Training loss: 2.017916440963745
Validation loss: 2.088509276509285

Epoch: 5| Step: 8
Training loss: 2.19010853767395
Validation loss: 2.103226731220881

Epoch: 5| Step: 9
Training loss: 2.1172494888305664
Validation loss: 2.0972249507904053

Epoch: 5| Step: 10
Training loss: 2.207296848297119
Validation loss: 2.093887597322464

Epoch: 5| Step: 11
Training loss: 2.36331844329834
Validation loss: 2.109093522032102

Epoch: 189| Step: 0
Training loss: 1.7407824993133545
Validation loss: 2.1208463261524835

Epoch: 5| Step: 1
Training loss: 1.9757883548736572
Validation loss: 2.146540721257528

Epoch: 5| Step: 2
Training loss: 1.829100251197815
Validation loss: 2.1642368336518607

Epoch: 5| Step: 3
Training loss: 2.1115376949310303
Validation loss: 2.154551515976588

Epoch: 5| Step: 4
Training loss: 2.3115265369415283
Validation loss: 2.1577626218398414

Epoch: 5| Step: 5
Training loss: 1.8779710531234741
Validation loss: 2.1502682069937387

Epoch: 5| Step: 6
Training loss: 1.8662868738174438
Validation loss: 2.140308067202568

Epoch: 5| Step: 7
Training loss: 1.9170706272125244
Validation loss: 2.1437400629123053

Epoch: 5| Step: 8
Training loss: 2.037842035293579
Validation loss: 2.1218215425809226

Epoch: 5| Step: 9
Training loss: 1.7701135873794556
Validation loss: 2.1155916253725686

Epoch: 5| Step: 10
Training loss: 2.2947630882263184
Validation loss: 2.1177597840627036

Epoch: 5| Step: 11
Training loss: 1.7871994972229004
Validation loss: 2.106948052843412

Epoch: 190| Step: 0
Training loss: 1.6841121912002563
Validation loss: 2.098656008640925

Epoch: 5| Step: 1
Training loss: 1.7626594305038452
Validation loss: 2.085241511464119

Epoch: 5| Step: 2
Training loss: 1.9408454895019531
Validation loss: 2.0963819324970245

Epoch: 5| Step: 3
Training loss: 2.048429012298584
Validation loss: 2.088364541530609

Epoch: 5| Step: 4
Training loss: 2.062394142150879
Validation loss: 2.099754363298416

Epoch: 5| Step: 5
Training loss: 1.716552734375
Validation loss: 2.1155056754748025

Epoch: 5| Step: 6
Training loss: 1.709363579750061
Validation loss: 2.111057534813881

Epoch: 5| Step: 7
Training loss: 2.6296629905700684
Validation loss: 2.130268414815267

Epoch: 5| Step: 8
Training loss: 2.48577618598938
Validation loss: 2.143902709086736

Epoch: 5| Step: 9
Training loss: 2.001223087310791
Validation loss: 2.150077243645986

Epoch: 5| Step: 10
Training loss: 1.5651109218597412
Validation loss: 2.131191963950793

Epoch: 5| Step: 11
Training loss: 1.9897781610488892
Validation loss: 2.1334344247976937

Epoch: 191| Step: 0
Training loss: 2.268749475479126
Validation loss: 2.109317590792974

Epoch: 5| Step: 1
Training loss: 2.1574642658233643
Validation loss: 2.125952278574308

Epoch: 5| Step: 2
Training loss: 1.758331060409546
Validation loss: 2.1048432091871896

Epoch: 5| Step: 3
Training loss: 2.169043779373169
Validation loss: 2.110600993037224

Epoch: 5| Step: 4
Training loss: 1.8528337478637695
Validation loss: 2.0907412419716516

Epoch: 5| Step: 5
Training loss: 1.5007925033569336
Validation loss: 2.094280476371447

Epoch: 5| Step: 6
Training loss: 1.805957555770874
Validation loss: 2.0927336364984512

Epoch: 5| Step: 7
Training loss: 1.9073889255523682
Validation loss: 2.10064231355985

Epoch: 5| Step: 8
Training loss: 1.7883806228637695
Validation loss: 2.096263438463211

Epoch: 5| Step: 9
Training loss: 1.5593700408935547
Validation loss: 2.1181214402119317

Epoch: 5| Step: 10
Training loss: 2.393655300140381
Validation loss: 2.1054554184277854

Epoch: 5| Step: 11
Training loss: 3.85432767868042
Validation loss: 2.1195976038773856

Epoch: 192| Step: 0
Training loss: 1.8624861240386963
Validation loss: 2.1151188562313714

Epoch: 5| Step: 1
Training loss: 2.341958999633789
Validation loss: 2.116649960478147

Epoch: 5| Step: 2
Training loss: 1.6004998683929443
Validation loss: 2.1146117597818375

Epoch: 5| Step: 3
Training loss: 2.3849234580993652
Validation loss: 2.1324271261692047

Epoch: 5| Step: 4
Training loss: 2.179293155670166
Validation loss: 2.1080277959505715

Epoch: 5| Step: 5
Training loss: 1.5815064907073975
Validation loss: 2.1197390456994376

Epoch: 5| Step: 6
Training loss: 2.2443928718566895
Validation loss: 2.1260659843683243

Epoch: 5| Step: 7
Training loss: 2.0753395557403564
Validation loss: 2.114426001906395

Epoch: 5| Step: 8
Training loss: 1.8872668743133545
Validation loss: 2.1157996704181037

Epoch: 5| Step: 9
Training loss: 1.677386999130249
Validation loss: 2.12978458404541

Epoch: 5| Step: 10
Training loss: 1.4868875741958618
Validation loss: 2.1287049651145935

Epoch: 5| Step: 11
Training loss: 1.3179991245269775
Validation loss: 2.118660862247149

Epoch: 193| Step: 0
Training loss: 1.9223175048828125
Validation loss: 2.1358643174171448

Epoch: 5| Step: 1
Training loss: 2.298877000808716
Validation loss: 2.112994442383448

Epoch: 5| Step: 2
Training loss: 1.4533369541168213
Validation loss: 2.1184733659029007

Epoch: 5| Step: 3
Training loss: 1.85812509059906
Validation loss: 2.1290078411499658

Epoch: 5| Step: 4
Training loss: 2.365692138671875
Validation loss: 2.124651407202085

Epoch: 5| Step: 5
Training loss: 1.9694992303848267
Validation loss: 2.1245538194974265

Epoch: 5| Step: 6
Training loss: 2.044783115386963
Validation loss: 2.1164240141709647

Epoch: 5| Step: 7
Training loss: 1.8700618743896484
Validation loss: 2.1044105341037116

Epoch: 5| Step: 8
Training loss: 2.05747127532959
Validation loss: 2.122731218735377

Epoch: 5| Step: 9
Training loss: 1.2539252042770386
Validation loss: 2.1233921895424523

Epoch: 5| Step: 10
Training loss: 2.1005465984344482
Validation loss: 2.102705031633377

Epoch: 5| Step: 11
Training loss: 2.4923288822174072
Validation loss: 2.102279156446457

Epoch: 194| Step: 0
Training loss: 1.4949162006378174
Validation loss: 2.129617616534233

Epoch: 5| Step: 1
Training loss: 1.6363872289657593
Validation loss: 2.1293568313121796

Epoch: 5| Step: 2
Training loss: 1.7432448863983154
Validation loss: 2.128185455997785

Epoch: 5| Step: 3
Training loss: 1.9543834924697876
Validation loss: 2.1473757127920785

Epoch: 5| Step: 4
Training loss: 2.10858154296875
Validation loss: 2.130735605955124

Epoch: 5| Step: 5
Training loss: 2.108285427093506
Validation loss: 2.1473151495059333

Epoch: 5| Step: 6
Training loss: 2.0006346702575684
Validation loss: 2.1515763203303018

Epoch: 5| Step: 7
Training loss: 1.822751760482788
Validation loss: 2.130827561020851

Epoch: 5| Step: 8
Training loss: 2.3991737365722656
Validation loss: 2.1342926522096

Epoch: 5| Step: 9
Training loss: 2.1189353466033936
Validation loss: 2.11563773949941

Epoch: 5| Step: 10
Training loss: 1.7566680908203125
Validation loss: 2.154928127924601

Epoch: 5| Step: 11
Training loss: 1.9795470237731934
Validation loss: 2.1231781244277954

Epoch: 195| Step: 0
Training loss: 1.9353606700897217
Validation loss: 2.1283009946346283

Epoch: 5| Step: 1
Training loss: 1.817624807357788
Validation loss: 2.1140851179758706

Epoch: 5| Step: 2
Training loss: 2.011035680770874
Validation loss: 2.1010030806064606

Epoch: 5| Step: 3
Training loss: 2.3960928916931152
Validation loss: 2.1128256767988205

Epoch: 5| Step: 4
Training loss: 2.2233688831329346
Validation loss: 2.1158649971087775

Epoch: 5| Step: 5
Training loss: 1.9908475875854492
Validation loss: 2.115999882419904

Epoch: 5| Step: 6
Training loss: 2.359009265899658
Validation loss: 2.1113673696915307

Epoch: 5| Step: 7
Training loss: 1.4246916770935059
Validation loss: 2.1231859028339386

Epoch: 5| Step: 8
Training loss: 1.281304955482483
Validation loss: 2.1027036954959235

Epoch: 5| Step: 9
Training loss: 2.2398855686187744
Validation loss: 2.1125736981630325

Epoch: 5| Step: 10
Training loss: 1.7425518035888672
Validation loss: 2.108308970928192

Epoch: 5| Step: 11
Training loss: 1.1751384735107422
Validation loss: 2.0955125937859216

Epoch: 196| Step: 0
Training loss: 1.5599435567855835
Validation loss: 2.10877226293087

Epoch: 5| Step: 1
Training loss: 1.4370769262313843
Validation loss: 2.117951820294062

Epoch: 5| Step: 2
Training loss: 1.9200470447540283
Validation loss: 2.092657059431076

Epoch: 5| Step: 3
Training loss: 1.8902069330215454
Validation loss: 2.1169619063536325

Epoch: 5| Step: 4
Training loss: 1.8152189254760742
Validation loss: 2.1079092820485434

Epoch: 5| Step: 5
Training loss: 2.351918935775757
Validation loss: 2.116208548347155

Epoch: 5| Step: 6
Training loss: 1.53719961643219
Validation loss: 2.1245704740285873

Epoch: 5| Step: 7
Training loss: 2.156059980392456
Validation loss: 2.122999275724093

Epoch: 5| Step: 8
Training loss: 2.2755885124206543
Validation loss: 2.125553399324417

Epoch: 5| Step: 9
Training loss: 2.3179421424865723
Validation loss: 2.132710506518682

Epoch: 5| Step: 10
Training loss: 1.8465293645858765
Validation loss: 2.1393274813890457

Epoch: 5| Step: 11
Training loss: 2.5842883586883545
Validation loss: 2.120885213216146

Epoch: 197| Step: 0
Training loss: 2.1326630115509033
Validation loss: 2.1249940345684686

Epoch: 5| Step: 1
Training loss: 1.6415235996246338
Validation loss: 2.126806288957596

Epoch: 5| Step: 2
Training loss: 1.7040481567382812
Validation loss: 2.1287445227305093

Epoch: 5| Step: 3
Training loss: 1.5894062519073486
Validation loss: 2.122335289915403

Epoch: 5| Step: 4
Training loss: 1.6725314855575562
Validation loss: 2.129784772793452

Epoch: 5| Step: 5
Training loss: 2.0384511947631836
Validation loss: 2.1190460324287415

Epoch: 5| Step: 6
Training loss: 2.16609787940979
Validation loss: 2.1270831376314163

Epoch: 5| Step: 7
Training loss: 2.3304667472839355
Validation loss: 2.1358586798111596

Epoch: 5| Step: 8
Training loss: 2.083034038543701
Validation loss: 2.1239533921082816

Epoch: 5| Step: 9
Training loss: 1.9158347845077515
Validation loss: 2.1238685697317123

Epoch: 5| Step: 10
Training loss: 1.9453881978988647
Validation loss: 2.1170433262983956

Epoch: 5| Step: 11
Training loss: 2.5858967304229736
Validation loss: 2.1224456628163657

Epoch: 198| Step: 0
Training loss: 2.3794045448303223
Validation loss: 2.133750081062317

Epoch: 5| Step: 1
Training loss: 2.0779378414154053
Validation loss: 2.1249389549096427

Epoch: 5| Step: 2
Training loss: 1.7228832244873047
Validation loss: 2.1254250705242157

Epoch: 5| Step: 3
Training loss: 2.229994058609009
Validation loss: 2.145351693034172

Epoch: 5| Step: 4
Training loss: 1.2123022079467773
Validation loss: 2.15057701865832

Epoch: 5| Step: 5
Training loss: 2.297053813934326
Validation loss: 2.1410104036331177

Epoch: 5| Step: 6
Training loss: 1.5209769010543823
Validation loss: 2.1253606428702674

Epoch: 5| Step: 7
Training loss: 2.356745481491089
Validation loss: 2.1293436785538993

Epoch: 5| Step: 8
Training loss: 1.8387129306793213
Validation loss: 2.1430369913578033

Epoch: 5| Step: 9
Training loss: 1.8372972011566162
Validation loss: 2.134672204653422

Epoch: 5| Step: 10
Training loss: 1.6449531316757202
Validation loss: 2.1422666708628335

Epoch: 5| Step: 11
Training loss: 1.8789597749710083
Validation loss: 2.12461127837499

Epoch: 199| Step: 0
Training loss: 1.8468151092529297
Validation loss: 2.0974204738934836

Epoch: 5| Step: 1
Training loss: 1.8056716918945312
Validation loss: 2.0910405615965524

Epoch: 5| Step: 2
Training loss: 1.7200214862823486
Validation loss: 2.091516301035881

Epoch: 5| Step: 3
Training loss: 1.5486794710159302
Validation loss: 2.1003971248865128

Epoch: 5| Step: 4
Training loss: 1.9968163967132568
Validation loss: 2.0871157497167587

Epoch: 5| Step: 5
Training loss: 2.039062023162842
Validation loss: 2.085594430565834

Epoch: 5| Step: 6
Training loss: 1.8906786441802979
Validation loss: 2.08357372879982

Epoch: 5| Step: 7
Training loss: 2.1646809577941895
Validation loss: 2.0870014478762946

Epoch: 5| Step: 8
Training loss: 2.0901358127593994
Validation loss: 2.1060047248999276

Epoch: 5| Step: 9
Training loss: 2.2694010734558105
Validation loss: 2.102268526951472

Epoch: 5| Step: 10
Training loss: 2.089996814727783
Validation loss: 2.10957163075606

Epoch: 5| Step: 11
Training loss: 1.701838493347168
Validation loss: 2.1386830459038415

Epoch: 200| Step: 0
Training loss: 1.699938178062439
Validation loss: 2.1459557116031647

Epoch: 5| Step: 1
Training loss: 1.4682807922363281
Validation loss: 2.1366526385148368

Epoch: 5| Step: 2
Training loss: 1.9149163961410522
Validation loss: 2.1361399590969086

Epoch: 5| Step: 3
Training loss: 1.8908472061157227
Validation loss: 2.140635629494985

Epoch: 5| Step: 4
Training loss: 2.17742657661438
Validation loss: 2.1545774737993875

Epoch: 5| Step: 5
Training loss: 1.8445045948028564
Validation loss: 2.133949786424637

Epoch: 5| Step: 6
Training loss: 1.9539844989776611
Validation loss: 2.146821548541387

Epoch: 5| Step: 7
Training loss: 1.9783035516738892
Validation loss: 2.1363602181275687

Epoch: 5| Step: 8
Training loss: 1.6243751049041748
Validation loss: 2.13171349465847

Epoch: 5| Step: 9
Training loss: 2.466797113418579
Validation loss: 2.1287416170040765

Epoch: 5| Step: 10
Training loss: 1.9991590976715088
Validation loss: 2.1241361846526465

Epoch: 5| Step: 11
Training loss: 1.2632592916488647
Validation loss: 2.1216540386279426

Epoch: 201| Step: 0
Training loss: 1.9652010202407837
Validation loss: 2.10098659992218

Epoch: 5| Step: 1
Training loss: 1.670882225036621
Validation loss: 2.0897027949492135

Epoch: 5| Step: 2
Training loss: 2.1379218101501465
Validation loss: 2.083969071507454

Epoch: 5| Step: 3
Training loss: 1.9120872020721436
Validation loss: 2.0842113494873047

Epoch: 5| Step: 4
Training loss: 2.1883084774017334
Validation loss: 2.0867116202910743

Epoch: 5| Step: 5
Training loss: 1.674330711364746
Validation loss: 2.106278801957766

Epoch: 5| Step: 6
Training loss: 1.9010162353515625
Validation loss: 2.097577527165413

Epoch: 5| Step: 7
Training loss: 1.85942804813385
Validation loss: 2.112943852941195

Epoch: 5| Step: 8
Training loss: 2.2348904609680176
Validation loss: 2.120058705409368

Epoch: 5| Step: 9
Training loss: 1.7695947885513306
Validation loss: 2.1361141403516135

Epoch: 5| Step: 10
Training loss: 2.363579750061035
Validation loss: 2.121593048175176

Epoch: 5| Step: 11
Training loss: 1.4313452243804932
Validation loss: 2.1525973677635193

Epoch: 202| Step: 0
Training loss: 1.7757890224456787
Validation loss: 2.159087340037028

Epoch: 5| Step: 1
Training loss: 1.5943161249160767
Validation loss: 2.166505749026934

Epoch: 5| Step: 2
Training loss: 1.890271782875061
Validation loss: 2.1331139504909515

Epoch: 5| Step: 3
Training loss: 1.9805850982666016
Validation loss: 2.1442290941874185

Epoch: 5| Step: 4
Training loss: 2.071730852127075
Validation loss: 2.1480904519557953

Epoch: 5| Step: 5
Training loss: 2.6087493896484375
Validation loss: 2.1302581429481506

Epoch: 5| Step: 6
Training loss: 1.7117221355438232
Validation loss: 2.1285107731819153

Epoch: 5| Step: 7
Training loss: 2.6260130405426025
Validation loss: 2.117093319694201

Epoch: 5| Step: 8
Training loss: 1.687349557876587
Validation loss: 2.096628785133362

Epoch: 5| Step: 9
Training loss: 1.6634933948516846
Validation loss: 2.0958220014969506

Epoch: 5| Step: 10
Training loss: 2.1794941425323486
Validation loss: 2.0947721054156623

Epoch: 5| Step: 11
Training loss: 2.11409330368042
Validation loss: 2.087913821140925

Epoch: 203| Step: 0
Training loss: 1.9801403284072876
Validation loss: 2.0839105993509293

Epoch: 5| Step: 1
Training loss: 2.064838409423828
Validation loss: 2.092908392349879

Epoch: 5| Step: 2
Training loss: 1.711309790611267
Validation loss: 2.1047428200642266

Epoch: 5| Step: 3
Training loss: 1.6903295516967773
Validation loss: 2.099885647495588

Epoch: 5| Step: 4
Training loss: 2.008300304412842
Validation loss: 2.1180516183376312

Epoch: 5| Step: 5
Training loss: 2.235623836517334
Validation loss: 2.136007954676946

Epoch: 5| Step: 6
Training loss: 2.015897274017334
Validation loss: 2.1177546034256616

Epoch: 5| Step: 7
Training loss: 2.3660879135131836
Validation loss: 2.130627011259397

Epoch: 5| Step: 8
Training loss: 1.669192910194397
Validation loss: 2.131692032019297

Epoch: 5| Step: 9
Training loss: 1.8509113788604736
Validation loss: 2.134380022684733

Epoch: 5| Step: 10
Training loss: 1.9301140308380127
Validation loss: 2.1561790804068246

Epoch: 5| Step: 11
Training loss: 1.5514339208602905
Validation loss: 2.140520532925924

Epoch: 204| Step: 0
Training loss: 1.9037435054779053
Validation loss: 2.1498520175615945

Epoch: 5| Step: 1
Training loss: 2.637289047241211
Validation loss: 2.1738591690858207

Epoch: 5| Step: 2
Training loss: 2.020642042160034
Validation loss: 2.1717008550961814

Epoch: 5| Step: 3
Training loss: 2.1695547103881836
Validation loss: 2.1490068634351096

Epoch: 5| Step: 4
Training loss: 1.9687732458114624
Validation loss: 2.173726201057434

Epoch: 5| Step: 5
Training loss: 2.243204116821289
Validation loss: 2.1548611521720886

Epoch: 5| Step: 6
Training loss: 1.827903389930725
Validation loss: 2.137779841820399

Epoch: 5| Step: 7
Training loss: 1.7629095315933228
Validation loss: 2.1227029263973236

Epoch: 5| Step: 8
Training loss: 1.9573400020599365
Validation loss: 2.14158067603906

Epoch: 5| Step: 9
Training loss: 1.6425451040267944
Validation loss: 2.1414794325828552

Epoch: 5| Step: 10
Training loss: 1.7930196523666382
Validation loss: 2.119543567299843

Epoch: 5| Step: 11
Training loss: 1.5356621742248535
Validation loss: 2.1322409013907113

Epoch: 205| Step: 0
Training loss: 2.356235980987549
Validation loss: 2.1254282792409263

Epoch: 5| Step: 1
Training loss: 2.0948710441589355
Validation loss: 2.1157068808873496

Epoch: 5| Step: 2
Training loss: 2.097656011581421
Validation loss: 2.088086868325869

Epoch: 5| Step: 3
Training loss: 2.108743667602539
Validation loss: 2.097497363885244

Epoch: 5| Step: 4
Training loss: 2.1074061393737793
Validation loss: 2.096468821167946

Epoch: 5| Step: 5
Training loss: 1.8319507837295532
Validation loss: 2.0970095892747245

Epoch: 5| Step: 6
Training loss: 1.6564037799835205
Validation loss: 2.102835570772489

Epoch: 5| Step: 7
Training loss: 2.058195114135742
Validation loss: 2.1060314625501633

Epoch: 5| Step: 8
Training loss: 1.5782880783081055
Validation loss: 2.1091181437174478

Epoch: 5| Step: 9
Training loss: 1.9967577457427979
Validation loss: 2.0998913049697876

Epoch: 5| Step: 10
Training loss: 1.9749953746795654
Validation loss: 2.0957676619291306

Epoch: 5| Step: 11
Training loss: 1.4209462404251099
Validation loss: 2.1041417866945267

Epoch: 206| Step: 0
Training loss: 2.186134099960327
Validation loss: 2.116973618666331

Epoch: 5| Step: 1
Training loss: 1.7803322076797485
Validation loss: 2.1153733680645623

Epoch: 5| Step: 2
Training loss: 2.0770680904388428
Validation loss: 2.1148336778084436

Epoch: 5| Step: 3
Training loss: 1.8467614650726318
Validation loss: 2.1138469874858856

Epoch: 5| Step: 4
Training loss: 1.7105777263641357
Validation loss: 2.1234428534905114

Epoch: 5| Step: 5
Training loss: 2.199685573577881
Validation loss: 2.1179746786753335

Epoch: 5| Step: 6
Training loss: 1.8071295022964478
Validation loss: 2.1312278310457864

Epoch: 5| Step: 7
Training loss: 1.9425264596939087
Validation loss: 2.133418306708336

Epoch: 5| Step: 8
Training loss: 1.7034015655517578
Validation loss: 2.123164718349775

Epoch: 5| Step: 9
Training loss: 1.6150346994400024
Validation loss: 2.1294144888718924

Epoch: 5| Step: 10
Training loss: 2.4553444385528564
Validation loss: 2.1441724399725595

Epoch: 5| Step: 11
Training loss: 2.3578102588653564
Validation loss: 2.133054261406263

Epoch: 207| Step: 0
Training loss: 2.006082534790039
Validation loss: 2.121903811891874

Epoch: 5| Step: 1
Training loss: 1.5755963325500488
Validation loss: 2.139864593744278

Epoch: 5| Step: 2
Training loss: 1.7009929418563843
Validation loss: 2.140089983741442

Epoch: 5| Step: 3
Training loss: 1.8746888637542725
Validation loss: 2.1344843953847885

Epoch: 5| Step: 4
Training loss: 2.1894476413726807
Validation loss: 2.1275971035162606

Epoch: 5| Step: 5
Training loss: 2.2688653469085693
Validation loss: 2.1381327907244363

Epoch: 5| Step: 6
Training loss: 2.1811201572418213
Validation loss: 2.1301359385252

Epoch: 5| Step: 7
Training loss: 1.5475541353225708
Validation loss: 2.1416154702504477

Epoch: 5| Step: 8
Training loss: 1.4857410192489624
Validation loss: 2.151592507958412

Epoch: 5| Step: 9
Training loss: 1.6942169666290283
Validation loss: 2.125043307741483

Epoch: 5| Step: 10
Training loss: 2.3505873680114746
Validation loss: 2.1287440359592438

Epoch: 5| Step: 11
Training loss: 1.6765021085739136
Validation loss: 2.130094975233078

Epoch: 208| Step: 0
Training loss: 1.8094959259033203
Validation loss: 2.128771831591924

Epoch: 5| Step: 1
Training loss: 2.2673287391662598
Validation loss: 2.1245955526828766

Epoch: 5| Step: 2
Training loss: 1.5698158740997314
Validation loss: 2.139704947670301

Epoch: 5| Step: 3
Training loss: 2.164039134979248
Validation loss: 2.153982867797216

Epoch: 5| Step: 4
Training loss: 1.6536071300506592
Validation loss: 2.149570658802986

Epoch: 5| Step: 5
Training loss: 1.6880909204483032
Validation loss: 2.1658907532691956

Epoch: 5| Step: 6
Training loss: 2.3195457458496094
Validation loss: 2.162572503089905

Epoch: 5| Step: 7
Training loss: 2.1685945987701416
Validation loss: 2.1574183156092963

Epoch: 5| Step: 8
Training loss: 1.3090684413909912
Validation loss: 2.171463261047999

Epoch: 5| Step: 9
Training loss: 1.9299020767211914
Validation loss: 2.1411337554454803

Epoch: 5| Step: 10
Training loss: 1.9340276718139648
Validation loss: 2.150101641813914

Epoch: 5| Step: 11
Training loss: 2.2029895782470703
Validation loss: 2.13167604804039

Epoch: 209| Step: 0
Training loss: 2.2119357585906982
Validation loss: 2.1426307410001755

Epoch: 5| Step: 1
Training loss: 1.5376532077789307
Validation loss: 2.1378165781497955

Epoch: 5| Step: 2
Training loss: 1.9862339496612549
Validation loss: 2.1171733985344567

Epoch: 5| Step: 3
Training loss: 2.377829074859619
Validation loss: 2.1007241010665894

Epoch: 5| Step: 4
Training loss: 2.4200191497802734
Validation loss: 2.1101969182491302

Epoch: 5| Step: 5
Training loss: 1.5526678562164307
Validation loss: 2.11066472530365

Epoch: 5| Step: 6
Training loss: 2.06618595123291
Validation loss: 2.1278012742598853

Epoch: 5| Step: 7
Training loss: 1.686894178390503
Validation loss: 2.098952184120814

Epoch: 5| Step: 8
Training loss: 1.7194650173187256
Validation loss: 2.121981163819631

Epoch: 5| Step: 9
Training loss: 1.930267095565796
Validation loss: 2.1166412134965262

Epoch: 5| Step: 10
Training loss: 1.6884515285491943
Validation loss: 2.108966052532196

Epoch: 5| Step: 11
Training loss: 1.454058051109314
Validation loss: 2.12750710050265

Epoch: 210| Step: 0
Training loss: 2.2871298789978027
Validation loss: 2.121823161840439

Epoch: 5| Step: 1
Training loss: 1.7886310815811157
Validation loss: 2.115368435780207

Epoch: 5| Step: 2
Training loss: 1.6342289447784424
Validation loss: 2.1164188782374063

Epoch: 5| Step: 3
Training loss: 1.9084112644195557
Validation loss: 2.135501762231191

Epoch: 5| Step: 4
Training loss: 2.3144679069519043
Validation loss: 2.1272949079672494

Epoch: 5| Step: 5
Training loss: 1.7260459661483765
Validation loss: 2.1392430464426675

Epoch: 5| Step: 6
Training loss: 1.8712507486343384
Validation loss: 2.1343049705028534

Epoch: 5| Step: 7
Training loss: 1.3029943704605103
Validation loss: 2.1419069369633994

Epoch: 5| Step: 8
Training loss: 2.558742046356201
Validation loss: 2.1599324395259223

Epoch: 5| Step: 9
Training loss: 1.4799704551696777
Validation loss: 2.1436195274194083

Epoch: 5| Step: 10
Training loss: 1.8622407913208008
Validation loss: 2.1495618522167206

Epoch: 5| Step: 11
Training loss: 2.9923195838928223
Validation loss: 2.1056357820828757

Epoch: 211| Step: 0
Training loss: 1.3755017518997192
Validation loss: 2.140383372704188

Epoch: 5| Step: 1
Training loss: 1.6806831359863281
Validation loss: 2.113418052593867

Epoch: 5| Step: 2
Training loss: 2.1042819023132324
Validation loss: 2.1347778191169104

Epoch: 5| Step: 3
Training loss: 1.9871978759765625
Validation loss: 2.1183273096879325

Epoch: 5| Step: 4
Training loss: 2.1622042655944824
Validation loss: 2.0963648160298667

Epoch: 5| Step: 5
Training loss: 2.482267141342163
Validation loss: 2.0939822793006897

Epoch: 5| Step: 6
Training loss: 1.5860306024551392
Validation loss: 2.092235580086708

Epoch: 5| Step: 7
Training loss: 2.042830228805542
Validation loss: 2.1035997023185096

Epoch: 5| Step: 8
Training loss: 1.7515751123428345
Validation loss: 2.107444946964582

Epoch: 5| Step: 9
Training loss: 1.9131085872650146
Validation loss: 2.0960656503836312

Epoch: 5| Step: 10
Training loss: 2.0819849967956543
Validation loss: 2.1184574564297995

Epoch: 5| Step: 11
Training loss: 1.8189451694488525
Validation loss: 2.133206695318222

Epoch: 212| Step: 0
Training loss: 1.8014819622039795
Validation loss: 2.1329533606767654

Epoch: 5| Step: 1
Training loss: 2.0741076469421387
Validation loss: 2.152020499110222

Epoch: 5| Step: 2
Training loss: 1.6005268096923828
Validation loss: 2.1570182939370475

Epoch: 5| Step: 3
Training loss: 2.1504979133605957
Validation loss: 2.1396869321664176

Epoch: 5| Step: 4
Training loss: 1.7239696979522705
Validation loss: 2.1552108029524484

Epoch: 5| Step: 5
Training loss: 1.8148761987686157
Validation loss: 2.1490085323651633

Epoch: 5| Step: 6
Training loss: 1.825002908706665
Validation loss: 2.1525965680678687

Epoch: 5| Step: 7
Training loss: 1.8219845294952393
Validation loss: 2.141395245989164

Epoch: 5| Step: 8
Training loss: 2.332219123840332
Validation loss: 2.1481674710909524

Epoch: 5| Step: 9
Training loss: 1.9048118591308594
Validation loss: 2.1294298420349755

Epoch: 5| Step: 10
Training loss: 1.5861282348632812
Validation loss: 2.14361734688282

Epoch: 5| Step: 11
Training loss: 3.5700957775115967
Validation loss: 2.1513337790966034

Epoch: 213| Step: 0
Training loss: 2.0712051391601562
Validation loss: 2.131669263044993

Epoch: 5| Step: 1
Training loss: 2.007864475250244
Validation loss: 2.125774100422859

Epoch: 5| Step: 2
Training loss: 1.7888996601104736
Validation loss: 2.1487877617279687

Epoch: 5| Step: 3
Training loss: 1.0803818702697754
Validation loss: 2.1470037698745728

Epoch: 5| Step: 4
Training loss: 1.6735801696777344
Validation loss: 2.116118237376213

Epoch: 5| Step: 5
Training loss: 1.8909410238265991
Validation loss: 2.1424529204765954

Epoch: 5| Step: 6
Training loss: 2.4510693550109863
Validation loss: 2.1235311726729074

Epoch: 5| Step: 7
Training loss: 1.9594790935516357
Validation loss: 2.146586447954178

Epoch: 5| Step: 8
Training loss: 1.8928844928741455
Validation loss: 2.1332185119390488

Epoch: 5| Step: 9
Training loss: 1.9617149829864502
Validation loss: 2.1653200139602027

Epoch: 5| Step: 10
Training loss: 2.018820285797119
Validation loss: 2.1745244761308036

Epoch: 5| Step: 11
Training loss: 1.9841768741607666
Validation loss: 2.1350275029738746

Epoch: 214| Step: 0
Training loss: 2.767777919769287
Validation loss: 2.1390603433052697

Epoch: 5| Step: 1
Training loss: 1.8562180995941162
Validation loss: 2.142763674259186

Epoch: 5| Step: 2
Training loss: 1.7757259607315063
Validation loss: 2.1420403569936752

Epoch: 5| Step: 3
Training loss: 1.5384175777435303
Validation loss: 2.1519122223059335

Epoch: 5| Step: 4
Training loss: 1.865928053855896
Validation loss: 2.106686254342397

Epoch: 5| Step: 5
Training loss: 1.1074577569961548
Validation loss: 2.1181254436572394

Epoch: 5| Step: 6
Training loss: 1.9032245874404907
Validation loss: 2.146867334842682

Epoch: 5| Step: 7
Training loss: 1.9653466939926147
Validation loss: 2.126243660847346

Epoch: 5| Step: 8
Training loss: 1.8314183950424194
Validation loss: 2.143681595722834

Epoch: 5| Step: 9
Training loss: 1.9644298553466797
Validation loss: 2.1426035364468894

Epoch: 5| Step: 10
Training loss: 1.9371131658554077
Validation loss: 2.1316250214974084

Epoch: 5| Step: 11
Training loss: 3.4017891883850098
Validation loss: 2.1593742966651917

Epoch: 215| Step: 0
Training loss: 2.0606977939605713
Validation loss: 2.158981665968895

Epoch: 5| Step: 1
Training loss: 2.210334062576294
Validation loss: 2.1724603722492852

Epoch: 5| Step: 2
Training loss: 1.9805854558944702
Validation loss: 2.1655397415161133

Epoch: 5| Step: 3
Training loss: 1.6998615264892578
Validation loss: 2.1670664052168527

Epoch: 5| Step: 4
Training loss: 1.2799077033996582
Validation loss: 2.1601575513680777

Epoch: 5| Step: 5
Training loss: 1.298971176147461
Validation loss: 2.157685250043869

Epoch: 5| Step: 6
Training loss: 2.1876156330108643
Validation loss: 2.1481475134690604

Epoch: 5| Step: 7
Training loss: 2.0054585933685303
Validation loss: 2.1308997571468353

Epoch: 5| Step: 8
Training loss: 1.5360000133514404
Validation loss: 2.1353512157996497

Epoch: 5| Step: 9
Training loss: 2.3723464012145996
Validation loss: 2.122645527124405

Epoch: 5| Step: 10
Training loss: 2.0444655418395996
Validation loss: 2.1067320108413696

Epoch: 5| Step: 11
Training loss: 2.254647731781006
Validation loss: 2.127654025952021

Epoch: 216| Step: 0
Training loss: 1.703064203262329
Validation loss: 2.1169844269752502

Epoch: 5| Step: 1
Training loss: 1.7230556011199951
Validation loss: 2.116978863875071

Epoch: 5| Step: 2
Training loss: 1.7869043350219727
Validation loss: 2.1147336463133493

Epoch: 5| Step: 3
Training loss: 1.796619176864624
Validation loss: 2.126920367280642

Epoch: 5| Step: 4
Training loss: 1.5434342622756958
Validation loss: 2.119796335697174

Epoch: 5| Step: 5
Training loss: 1.5645811557769775
Validation loss: 2.129964048663775

Epoch: 5| Step: 6
Training loss: 2.337226390838623
Validation loss: 2.1235216160615287

Epoch: 5| Step: 7
Training loss: 1.9540698528289795
Validation loss: 2.1280966798464456

Epoch: 5| Step: 8
Training loss: 2.2594590187072754
Validation loss: 2.1358663737773895

Epoch: 5| Step: 9
Training loss: 1.8352190256118774
Validation loss: 2.1709416111310325

Epoch: 5| Step: 10
Training loss: 2.2166385650634766
Validation loss: 2.167563502987226

Epoch: 5| Step: 11
Training loss: 3.7125589847564697
Validation loss: 2.138350953658422

Epoch: 217| Step: 0
Training loss: 1.6806209087371826
Validation loss: 2.1765011747678122

Epoch: 5| Step: 1
Training loss: 1.8759454488754272
Validation loss: 2.1721289455890656

Epoch: 5| Step: 2
Training loss: 2.1181280612945557
Validation loss: 2.1478665272394815

Epoch: 5| Step: 3
Training loss: 1.6174240112304688
Validation loss: 2.145925988753637

Epoch: 5| Step: 4
Training loss: 1.8010075092315674
Validation loss: 2.160685489575068

Epoch: 5| Step: 5
Training loss: 1.8547239303588867
Validation loss: 2.1665912767251334

Epoch: 5| Step: 6
Training loss: 2.1464295387268066
Validation loss: 2.150999257961909

Epoch: 5| Step: 7
Training loss: 2.1070494651794434
Validation loss: 2.119941850503286

Epoch: 5| Step: 8
Training loss: 1.8580436706542969
Validation loss: 2.1363447507222495

Epoch: 5| Step: 9
Training loss: 1.8985942602157593
Validation loss: 2.134736657142639

Epoch: 5| Step: 10
Training loss: 1.5778863430023193
Validation loss: 2.1310111979643502

Epoch: 5| Step: 11
Training loss: 2.933901309967041
Validation loss: 2.128338391582171

Epoch: 218| Step: 0
Training loss: 1.7591907978057861
Validation loss: 2.1159065067768097

Epoch: 5| Step: 1
Training loss: 2.314703941345215
Validation loss: 2.1350648254156113

Epoch: 5| Step: 2
Training loss: 1.3570048809051514
Validation loss: 2.152008975545565

Epoch: 5| Step: 3
Training loss: 1.8851436376571655
Validation loss: 2.1440735310316086

Epoch: 5| Step: 4
Training loss: 1.4005540609359741
Validation loss: 2.141788070400556

Epoch: 5| Step: 5
Training loss: 2.110862970352173
Validation loss: 2.173876166343689

Epoch: 5| Step: 6
Training loss: 1.7997291088104248
Validation loss: 2.1546510756015778

Epoch: 5| Step: 7
Training loss: 2.4599692821502686
Validation loss: 2.138393690188726

Epoch: 5| Step: 8
Training loss: 1.8153362274169922
Validation loss: 2.1233522295951843

Epoch: 5| Step: 9
Training loss: 1.5792012214660645
Validation loss: 2.156283105413119

Epoch: 5| Step: 10
Training loss: 2.1020824909210205
Validation loss: 2.1588543901840844

Epoch: 5| Step: 11
Training loss: 1.7639943361282349
Validation loss: 2.143197183807691

Epoch: 219| Step: 0
Training loss: 1.3129562139511108
Validation loss: 2.152691895763079

Epoch: 5| Step: 1
Training loss: 2.4894886016845703
Validation loss: 2.1343713849782944

Epoch: 5| Step: 2
Training loss: 2.15598464012146
Validation loss: 2.1343758602937064

Epoch: 5| Step: 3
Training loss: 2.0956199169158936
Validation loss: 2.1386461406946182

Epoch: 5| Step: 4
Training loss: 1.9308311939239502
Validation loss: 2.1396808276573815

Epoch: 5| Step: 5
Training loss: 1.666759729385376
Validation loss: 2.1372475028038025

Epoch: 5| Step: 6
Training loss: 1.9428974390029907
Validation loss: 2.1103030691544213

Epoch: 5| Step: 7
Training loss: 1.6432647705078125
Validation loss: 2.1507072697083154

Epoch: 5| Step: 8
Training loss: 1.8614778518676758
Validation loss: 2.1456534614165625

Epoch: 5| Step: 9
Training loss: 1.9172117710113525
Validation loss: 2.1333767722050347

Epoch: 5| Step: 10
Training loss: 1.8170013427734375
Validation loss: 2.1300414502620697

Epoch: 5| Step: 11
Training loss: 1.54313325881958
Validation loss: 2.1446040918429694

Epoch: 220| Step: 0
Training loss: 1.7735717296600342
Validation loss: 2.1276718378067017

Epoch: 5| Step: 1
Training loss: 1.6429176330566406
Validation loss: 2.1446696569522223

Epoch: 5| Step: 2
Training loss: 1.4506595134735107
Validation loss: 2.129232113560041

Epoch: 5| Step: 3
Training loss: 2.6000280380249023
Validation loss: 2.1044622411330542

Epoch: 5| Step: 4
Training loss: 1.5123648643493652
Validation loss: 2.099054624636968

Epoch: 5| Step: 5
Training loss: 2.0417141914367676
Validation loss: 2.115088621775309

Epoch: 5| Step: 6
Training loss: 1.6600983142852783
Validation loss: 2.126638506849607

Epoch: 5| Step: 7
Training loss: 1.4909969568252563
Validation loss: 2.111579934755961

Epoch: 5| Step: 8
Training loss: 1.7937593460083008
Validation loss: 2.1306198040644326

Epoch: 5| Step: 9
Training loss: 2.493778705596924
Validation loss: 2.145831217368444

Epoch: 5| Step: 10
Training loss: 2.1031553745269775
Validation loss: 2.1253302693367004

Epoch: 5| Step: 11
Training loss: 2.4974803924560547
Validation loss: 2.1515853255987167

Epoch: 221| Step: 0
Training loss: 1.7069272994995117
Validation loss: 2.1472097088893256

Epoch: 5| Step: 1
Training loss: 1.750714659690857
Validation loss: 2.153377821048101

Epoch: 5| Step: 2
Training loss: 2.099321126937866
Validation loss: 2.1499101171890893

Epoch: 5| Step: 3
Training loss: 1.359337568283081
Validation loss: 2.174967482686043

Epoch: 5| Step: 4
Training loss: 1.5340216159820557
Validation loss: 2.1408630907535553

Epoch: 5| Step: 5
Training loss: 1.6200180053710938
Validation loss: 2.1676257153352103

Epoch: 5| Step: 6
Training loss: 2.2837252616882324
Validation loss: 2.1318805565436683

Epoch: 5| Step: 7
Training loss: 1.7777084112167358
Validation loss: 2.138555293281873

Epoch: 5| Step: 8
Training loss: 2.473557710647583
Validation loss: 2.1338140765825906

Epoch: 5| Step: 9
Training loss: 1.9418805837631226
Validation loss: 2.1449070821205773

Epoch: 5| Step: 10
Training loss: 2.0359761714935303
Validation loss: 2.135957603653272

Epoch: 5| Step: 11
Training loss: 2.458034038543701
Validation loss: 2.151933570702871

Epoch: 222| Step: 0
Training loss: 1.4250152111053467
Validation loss: 2.159353350599607

Epoch: 5| Step: 1
Training loss: 2.185915946960449
Validation loss: 2.1719916661580405

Epoch: 5| Step: 2
Training loss: 1.8281360864639282
Validation loss: 2.1748606810967126

Epoch: 5| Step: 3
Training loss: 1.6138595342636108
Validation loss: 2.1646647850672402

Epoch: 5| Step: 4
Training loss: 1.7055044174194336
Validation loss: 2.1745935579140983

Epoch: 5| Step: 5
Training loss: 2.250572443008423
Validation loss: 2.2022824436426163

Epoch: 5| Step: 6
Training loss: 1.8809711933135986
Validation loss: 2.1937040984630585

Epoch: 5| Step: 7
Training loss: 1.8056204319000244
Validation loss: 2.191183865070343

Epoch: 5| Step: 8
Training loss: 2.509474277496338
Validation loss: 2.15363118549188

Epoch: 5| Step: 9
Training loss: 1.8098853826522827
Validation loss: 2.1416145215431848

Epoch: 5| Step: 10
Training loss: 2.229154109954834
Validation loss: 2.1367918203274407

Epoch: 5| Step: 11
Training loss: 1.0594085454940796
Validation loss: 2.1223861624797187

Epoch: 223| Step: 0
Training loss: 2.169617176055908
Validation loss: 2.1137114614248276

Epoch: 5| Step: 1
Training loss: 1.7539739608764648
Validation loss: 2.132125457127889

Epoch: 5| Step: 2
Training loss: 2.0592617988586426
Validation loss: 2.1162425577640533

Epoch: 5| Step: 3
Training loss: 1.601941704750061
Validation loss: 2.1296910643577576

Epoch: 5| Step: 4
Training loss: 2.367382049560547
Validation loss: 2.122806424895922

Epoch: 5| Step: 5
Training loss: 2.1490747928619385
Validation loss: 2.1241925110419593

Epoch: 5| Step: 6
Training loss: 1.750870704650879
Validation loss: 2.120537430047989

Epoch: 5| Step: 7
Training loss: 1.371588945388794
Validation loss: 2.127044936021169

Epoch: 5| Step: 8
Training loss: 1.6964483261108398
Validation loss: 2.1316599200169244

Epoch: 5| Step: 9
Training loss: 2.169842004776001
Validation loss: 2.174092029531797

Epoch: 5| Step: 10
Training loss: 1.7849022150039673
Validation loss: 2.1597408453623452

Epoch: 5| Step: 11
Training loss: 2.2565245628356934
Validation loss: 2.1765104631582894

Epoch: 224| Step: 0
Training loss: 1.7526664733886719
Validation loss: 2.2072529991467795

Epoch: 5| Step: 1
Training loss: 1.5398253202438354
Validation loss: 2.1850246538718543

Epoch: 5| Step: 2
Training loss: 1.7812902927398682
Validation loss: 2.2257957061131797

Epoch: 5| Step: 3
Training loss: 2.4580273628234863
Validation loss: 2.196287820736567

Epoch: 5| Step: 4
Training loss: 1.9070580005645752
Validation loss: 2.167096177736918

Epoch: 5| Step: 5
Training loss: 2.4360432624816895
Validation loss: 2.1624090870221457

Epoch: 5| Step: 6
Training loss: 1.842972755432129
Validation loss: 2.146604835987091

Epoch: 5| Step: 7
Training loss: 1.9084125757217407
Validation loss: 2.1341498494148254

Epoch: 5| Step: 8
Training loss: 1.637904405593872
Validation loss: 2.1297811965147653

Epoch: 5| Step: 9
Training loss: 1.7709484100341797
Validation loss: 2.122454951206843

Epoch: 5| Step: 10
Training loss: 2.298081636428833
Validation loss: 2.1157947381337485

Epoch: 5| Step: 11
Training loss: 1.6880629062652588
Validation loss: 2.0957285265127816

Epoch: 225| Step: 0
Training loss: 1.8206695318222046
Validation loss: 2.1155640532573066

Epoch: 5| Step: 1
Training loss: 1.7699458599090576
Validation loss: 2.1096717764933905

Epoch: 5| Step: 2
Training loss: 2.046342372894287
Validation loss: 2.1128881722688675

Epoch: 5| Step: 3
Training loss: 1.5238863229751587
Validation loss: 2.1102420886357627

Epoch: 5| Step: 4
Training loss: 1.7775157690048218
Validation loss: 2.114024266600609

Epoch: 5| Step: 5
Training loss: 1.7678890228271484
Validation loss: 2.1181607147057853

Epoch: 5| Step: 6
Training loss: 2.4852004051208496
Validation loss: 2.118313337365786

Epoch: 5| Step: 7
Training loss: 2.5026557445526123
Validation loss: 2.1243108908335366

Epoch: 5| Step: 8
Training loss: 2.347626209259033
Validation loss: 2.1155256628990173

Epoch: 5| Step: 9
Training loss: 1.8376731872558594
Validation loss: 2.105848103761673

Epoch: 5| Step: 10
Training loss: 2.060680866241455
Validation loss: 2.126304879784584

Epoch: 5| Step: 11
Training loss: 1.3880454301834106
Validation loss: 2.144213631749153

Epoch: 226| Step: 0
Training loss: 1.5783946514129639
Validation loss: 2.1441677113374076

Epoch: 5| Step: 1
Training loss: 1.4607908725738525
Validation loss: 2.141165256500244

Epoch: 5| Step: 2
Training loss: 1.7978225946426392
Validation loss: 2.1536710361639657

Epoch: 5| Step: 3
Training loss: 2.050691604614258
Validation loss: 2.1283998837073645

Epoch: 5| Step: 4
Training loss: 2.0222482681274414
Validation loss: 2.1439536809921265

Epoch: 5| Step: 5
Training loss: 1.9949289560317993
Validation loss: 2.1450583785772324

Epoch: 5| Step: 6
Training loss: 1.8277581930160522
Validation loss: 2.148430441816648

Epoch: 5| Step: 7
Training loss: 1.5908757448196411
Validation loss: 2.1485186715920768

Epoch: 5| Step: 8
Training loss: 2.5271997451782227
Validation loss: 2.1572318871816

Epoch: 5| Step: 9
Training loss: 1.6540530920028687
Validation loss: 2.155590067307154

Epoch: 5| Step: 10
Training loss: 1.8373758792877197
Validation loss: 2.151413217186928

Epoch: 5| Step: 11
Training loss: 2.732605457305908
Validation loss: 2.1375121225913367

Epoch: 227| Step: 0
Training loss: 1.8126178979873657
Validation loss: 2.1701685388882956

Epoch: 5| Step: 1
Training loss: 1.8625733852386475
Validation loss: 2.158919930458069

Epoch: 5| Step: 2
Training loss: 2.0678181648254395
Validation loss: 2.1513467729091644

Epoch: 5| Step: 3
Training loss: 1.5763665437698364
Validation loss: 2.142649923761686

Epoch: 5| Step: 4
Training loss: 2.254826068878174
Validation loss: 2.1447369356950126

Epoch: 5| Step: 5
Training loss: 1.7698694467544556
Validation loss: 2.1320175528526306

Epoch: 5| Step: 6
Training loss: 2.136446714401245
Validation loss: 2.1459942857424417

Epoch: 5| Step: 7
Training loss: 1.7634642124176025
Validation loss: 2.1524882912635803

Epoch: 5| Step: 8
Training loss: 1.862432837486267
Validation loss: 2.168629308541616

Epoch: 5| Step: 9
Training loss: 1.7323135137557983
Validation loss: 2.1370610942443213

Epoch: 5| Step: 10
Training loss: 1.6054458618164062
Validation loss: 2.1515219459931054

Epoch: 5| Step: 11
Training loss: 1.1258797645568848
Validation loss: 2.163143907984098

Epoch: 228| Step: 0
Training loss: 2.550295352935791
Validation loss: 2.171819726626078

Epoch: 5| Step: 1
Training loss: 2.431124448776245
Validation loss: 2.1795190821091333

Epoch: 5| Step: 2
Training loss: 1.9314247369766235
Validation loss: 2.1699806402126947

Epoch: 5| Step: 3
Training loss: 1.4416544437408447
Validation loss: 2.171429847677549

Epoch: 5| Step: 4
Training loss: 1.3787816762924194
Validation loss: 2.1621839801470437

Epoch: 5| Step: 5
Training loss: 1.7574913501739502
Validation loss: 2.173455615838369

Epoch: 5| Step: 6
Training loss: 2.047318458557129
Validation loss: 2.182370960712433

Epoch: 5| Step: 7
Training loss: 1.6457237005233765
Validation loss: 2.163314864039421

Epoch: 5| Step: 8
Training loss: 1.4138253927230835
Validation loss: 2.1635407706101737

Epoch: 5| Step: 9
Training loss: 1.4180612564086914
Validation loss: 2.1632214238246283

Epoch: 5| Step: 10
Training loss: 2.4972522258758545
Validation loss: 2.1539041300614676

Epoch: 5| Step: 11
Training loss: 1.6019550561904907
Validation loss: 2.142346734801928

Epoch: 229| Step: 0
Training loss: 1.7922331094741821
Validation loss: 2.159651041030884

Epoch: 5| Step: 1
Training loss: 1.5998212099075317
Validation loss: 2.168521116177241

Epoch: 5| Step: 2
Training loss: 1.8267914056777954
Validation loss: 2.181641717751821

Epoch: 5| Step: 3
Training loss: 2.3557980060577393
Validation loss: 2.175894637902578

Epoch: 5| Step: 4
Training loss: 1.9374593496322632
Validation loss: 2.1871658265590668

Epoch: 5| Step: 5
Training loss: 1.4514950513839722
Validation loss: 2.205351402362188

Epoch: 5| Step: 6
Training loss: 1.6117359399795532
Validation loss: 2.185999204715093

Epoch: 5| Step: 7
Training loss: 1.4693304300308228
Validation loss: 2.173114851117134

Epoch: 5| Step: 8
Training loss: 1.7095630168914795
Validation loss: 2.173586984475454

Epoch: 5| Step: 9
Training loss: 2.2810091972351074
Validation loss: 2.135059247414271

Epoch: 5| Step: 10
Training loss: 2.3354082107543945
Validation loss: 2.1264358858267465

Epoch: 5| Step: 11
Training loss: 2.3938348293304443
Validation loss: 2.1323453336954117

Epoch: 230| Step: 0
Training loss: 2.1621437072753906
Validation loss: 2.1213918576637902

Epoch: 5| Step: 1
Training loss: 2.0695064067840576
Validation loss: 2.1072734942038855

Epoch: 5| Step: 2
Training loss: 2.0581116676330566
Validation loss: 2.1052534679571786

Epoch: 5| Step: 3
Training loss: 2.2241768836975098
Validation loss: 2.1248254229625068

Epoch: 5| Step: 4
Training loss: 1.5486268997192383
Validation loss: 2.1122615039348602

Epoch: 5| Step: 5
Training loss: 2.040771722793579
Validation loss: 2.122361660003662

Epoch: 5| Step: 6
Training loss: 1.6159591674804688
Validation loss: 2.1141680677731833

Epoch: 5| Step: 7
Training loss: 2.005869150161743
Validation loss: 2.1250482896963754

Epoch: 5| Step: 8
Training loss: 1.8040729761123657
Validation loss: 2.1305933445692062

Epoch: 5| Step: 9
Training loss: 1.858751654624939
Validation loss: 2.1533553500970206

Epoch: 5| Step: 10
Training loss: 2.115596294403076
Validation loss: 2.1499864757061005

Epoch: 5| Step: 11
Training loss: 1.0300374031066895
Validation loss: 2.1817136704921722

Epoch: 231| Step: 0
Training loss: 2.097656488418579
Validation loss: 2.177500824133555

Epoch: 5| Step: 1
Training loss: 1.807185173034668
Validation loss: 2.202188397447268

Epoch: 5| Step: 2
Training loss: 2.1588234901428223
Validation loss: 2.17711632947127

Epoch: 5| Step: 3
Training loss: 1.1229702234268188
Validation loss: 2.182793175180753

Epoch: 5| Step: 4
Training loss: 1.6903228759765625
Validation loss: 2.1507826099793115

Epoch: 5| Step: 5
Training loss: 1.664041519165039
Validation loss: 2.1567443956931434

Epoch: 5| Step: 6
Training loss: 2.03183650970459
Validation loss: 2.1360823959112167

Epoch: 5| Step: 7
Training loss: 1.9673229455947876
Validation loss: 2.1310261885325112

Epoch: 5| Step: 8
Training loss: 2.2576632499694824
Validation loss: 2.1263261288404465

Epoch: 5| Step: 9
Training loss: 1.8062515258789062
Validation loss: 2.133805205424627

Epoch: 5| Step: 10
Training loss: 2.1271414756774902
Validation loss: 2.13922056555748

Epoch: 5| Step: 11
Training loss: 1.8171086311340332
Validation loss: 2.15570275982221

Epoch: 232| Step: 0
Training loss: 1.606105089187622
Validation loss: 2.1480900893608728

Epoch: 5| Step: 1
Training loss: 1.4335603713989258
Validation loss: 2.188473323980967

Epoch: 5| Step: 2
Training loss: 1.7417351007461548
Validation loss: 2.1621023416519165

Epoch: 5| Step: 3
Training loss: 1.53972589969635
Validation loss: 2.1599540462096534

Epoch: 5| Step: 4
Training loss: 2.2924814224243164
Validation loss: 2.151847114165624

Epoch: 5| Step: 5
Training loss: 2.0083746910095215
Validation loss: 2.156619355082512

Epoch: 5| Step: 6
Training loss: 1.7150251865386963
Validation loss: 2.1684742718935013

Epoch: 5| Step: 7
Training loss: 2.261709213256836
Validation loss: 2.169071465730667

Epoch: 5| Step: 8
Training loss: 1.946223497390747
Validation loss: 2.1788089325030646

Epoch: 5| Step: 9
Training loss: 1.0671250820159912
Validation loss: 2.1746713618437448

Epoch: 5| Step: 10
Training loss: 2.5775535106658936
Validation loss: 2.1717112759749093

Epoch: 5| Step: 11
Training loss: 1.3284058570861816
Validation loss: 2.149058386683464

Epoch: 233| Step: 0
Training loss: 1.6214125156402588
Validation loss: 2.1463758250077567

Epoch: 5| Step: 1
Training loss: 1.7503334283828735
Validation loss: 2.138855735460917

Epoch: 5| Step: 2
Training loss: 1.8184057474136353
Validation loss: 2.1427874316771827

Epoch: 5| Step: 3
Training loss: 2.4778478145599365
Validation loss: 2.139153520266215

Epoch: 5| Step: 4
Training loss: 1.4890730381011963
Validation loss: 2.145553926626841

Epoch: 5| Step: 5
Training loss: 1.650415062904358
Validation loss: 2.1284466981887817

Epoch: 5| Step: 6
Training loss: 2.0896973609924316
Validation loss: 2.1508549650510154

Epoch: 5| Step: 7
Training loss: 1.8194553852081299
Validation loss: 2.1630684534708657

Epoch: 5| Step: 8
Training loss: 2.3530592918395996
Validation loss: 2.1546695977449417

Epoch: 5| Step: 9
Training loss: 2.1353392601013184
Validation loss: 2.15950445830822

Epoch: 5| Step: 10
Training loss: 1.4073853492736816
Validation loss: 2.1473241796096167

Epoch: 5| Step: 11
Training loss: 0.9396557807922363
Validation loss: 2.1334905177354813

Epoch: 234| Step: 0
Training loss: 1.690338373184204
Validation loss: 2.1242004881302514

Epoch: 5| Step: 1
Training loss: 1.185284972190857
Validation loss: 2.1059353053569794

Epoch: 5| Step: 2
Training loss: 1.756869912147522
Validation loss: 2.1371206492185593

Epoch: 5| Step: 3
Training loss: 1.945111632347107
Validation loss: 2.1264450947443643

Epoch: 5| Step: 4
Training loss: 2.1211323738098145
Validation loss: 2.1513255337874093

Epoch: 5| Step: 5
Training loss: 2.364191770553589
Validation loss: 2.124253903826078

Epoch: 5| Step: 6
Training loss: 1.7642542123794556
Validation loss: 2.131159539024035

Epoch: 5| Step: 7
Training loss: 1.7755721807479858
Validation loss: 2.1456598242123923

Epoch: 5| Step: 8
Training loss: 2.305037021636963
Validation loss: 2.168640896677971

Epoch: 5| Step: 9
Training loss: 2.0491480827331543
Validation loss: 2.1539217829704285

Epoch: 5| Step: 10
Training loss: 1.735478401184082
Validation loss: 2.1376855969429016

Epoch: 5| Step: 11
Training loss: 2.1752185821533203
Validation loss: 2.1600163082281747

Epoch: 235| Step: 0
Training loss: 1.6977910995483398
Validation loss: 2.175141930580139

Epoch: 5| Step: 1
Training loss: 1.7844959497451782
Validation loss: 2.165092686812083

Epoch: 5| Step: 2
Training loss: 1.9177792072296143
Validation loss: 2.172213762998581

Epoch: 5| Step: 3
Training loss: 2.2196719646453857
Validation loss: 2.155759170651436

Epoch: 5| Step: 4
Training loss: 1.543731451034546
Validation loss: 2.169763058423996

Epoch: 5| Step: 5
Training loss: 1.5220451354980469
Validation loss: 2.1542077163855233

Epoch: 5| Step: 6
Training loss: 1.8560203313827515
Validation loss: 2.1523949950933456

Epoch: 5| Step: 7
Training loss: 1.5534639358520508
Validation loss: 2.1283033788204193

Epoch: 5| Step: 8
Training loss: 2.4431352615356445
Validation loss: 2.1495999147494635

Epoch: 5| Step: 9
Training loss: 2.3241665363311768
Validation loss: 2.1341524521509805

Epoch: 5| Step: 10
Training loss: 1.4853441715240479
Validation loss: 2.130347490310669

Epoch: 5| Step: 11
Training loss: 1.3861764669418335
Validation loss: 2.1401247084140778

Epoch: 236| Step: 0
Training loss: 1.3013529777526855
Validation loss: 2.1347665985425315

Epoch: 5| Step: 1
Training loss: 2.2509655952453613
Validation loss: 2.137447034319242

Epoch: 5| Step: 2
Training loss: 1.8479160070419312
Validation loss: 2.127210105458895

Epoch: 5| Step: 3
Training loss: 1.7554880380630493
Validation loss: 2.123331904411316

Epoch: 5| Step: 4
Training loss: 2.2734909057617188
Validation loss: 2.1419966220855713

Epoch: 5| Step: 5
Training loss: 2.059375762939453
Validation loss: 2.133865570028623

Epoch: 5| Step: 6
Training loss: 1.4203522205352783
Validation loss: 2.132382700840632

Epoch: 5| Step: 7
Training loss: 1.494863510131836
Validation loss: 2.1595593790213266

Epoch: 5| Step: 8
Training loss: 2.0040647983551025
Validation loss: 2.1498035887877145

Epoch: 5| Step: 9
Training loss: 1.7551186084747314
Validation loss: 2.12884255250295

Epoch: 5| Step: 10
Training loss: 2.2614102363586426
Validation loss: 2.162424474954605

Epoch: 5| Step: 11
Training loss: 1.1244786977767944
Validation loss: 2.176148404677709

Epoch: 237| Step: 0
Training loss: 1.9207805395126343
Validation loss: 2.168426771958669

Epoch: 5| Step: 1
Training loss: 1.809643030166626
Validation loss: 2.145093157887459

Epoch: 5| Step: 2
Training loss: 1.767660140991211
Validation loss: 2.180470551053683

Epoch: 5| Step: 3
Training loss: 1.6039806604385376
Validation loss: 2.1511082549889884

Epoch: 5| Step: 4
Training loss: 1.5533570051193237
Validation loss: 2.1462614635626474

Epoch: 5| Step: 5
Training loss: 1.784844994544983
Validation loss: 2.1437553515036902

Epoch: 5| Step: 6
Training loss: 2.454759120941162
Validation loss: 2.108167509237925

Epoch: 5| Step: 7
Training loss: 1.986538290977478
Validation loss: 2.1107800602912903

Epoch: 5| Step: 8
Training loss: 1.891679048538208
Validation loss: 2.106757640838623

Epoch: 5| Step: 9
Training loss: 1.894736886024475
Validation loss: 2.126262510816256

Epoch: 5| Step: 10
Training loss: 1.5078130960464478
Validation loss: 2.1293619920810065

Epoch: 5| Step: 11
Training loss: 1.539243221282959
Validation loss: 2.1121273934841156

Epoch: 238| Step: 0
Training loss: 1.6946521997451782
Validation loss: 2.1106505692005157

Epoch: 5| Step: 1
Training loss: 2.0323379039764404
Validation loss: 2.12626318136851

Epoch: 5| Step: 2
Training loss: 1.6001421213150024
Validation loss: 2.1366350253423056

Epoch: 5| Step: 3
Training loss: 2.0453124046325684
Validation loss: 2.120473171273867

Epoch: 5| Step: 4
Training loss: 1.645577073097229
Validation loss: 2.14734781285127

Epoch: 5| Step: 5
Training loss: 1.5911365747451782
Validation loss: 2.1426331996917725

Epoch: 5| Step: 6
Training loss: 2.2824578285217285
Validation loss: 2.1815729339917502

Epoch: 5| Step: 7
Training loss: 2.0993874073028564
Validation loss: 2.1529120753208795

Epoch: 5| Step: 8
Training loss: 1.8892463445663452
Validation loss: 2.178233673175176

Epoch: 5| Step: 9
Training loss: 1.6057363748550415
Validation loss: 2.1753581215937934

Epoch: 5| Step: 10
Training loss: 1.8956995010375977
Validation loss: 2.154289493958155

Epoch: 5| Step: 11
Training loss: 1.5749602317810059
Validation loss: 2.130773435036341

Epoch: 239| Step: 0
Training loss: 1.713404655456543
Validation loss: 2.1626984576384225

Epoch: 5| Step: 1
Training loss: 1.359586477279663
Validation loss: 2.1499120692412057

Epoch: 5| Step: 2
Training loss: 2.0061163902282715
Validation loss: 2.1231230795383453

Epoch: 5| Step: 3
Training loss: 1.6464678049087524
Validation loss: 2.1455962558587394

Epoch: 5| Step: 4
Training loss: 1.8477131128311157
Validation loss: 2.1337665021419525

Epoch: 5| Step: 5
Training loss: 1.833829641342163
Validation loss: 2.147451321283976

Epoch: 5| Step: 6
Training loss: 1.6157424449920654
Validation loss: 2.133620331684748

Epoch: 5| Step: 7
Training loss: 1.6174758672714233
Validation loss: 2.1385274728139243

Epoch: 5| Step: 8
Training loss: 1.896458387374878
Validation loss: 2.1197091937065125

Epoch: 5| Step: 9
Training loss: 2.573538303375244
Validation loss: 2.138053745031357

Epoch: 5| Step: 10
Training loss: 1.550930142402649
Validation loss: 2.15615580479304

Epoch: 5| Step: 11
Training loss: 4.080312728881836
Validation loss: 2.1724142531553903

Epoch: 240| Step: 0
Training loss: 2.2050774097442627
Validation loss: 2.1694964170455933

Epoch: 5| Step: 1
Training loss: 2.1895554065704346
Validation loss: 2.1631168723106384

Epoch: 5| Step: 2
Training loss: 2.5519566535949707
Validation loss: 2.150593265891075

Epoch: 5| Step: 3
Training loss: 1.184234619140625
Validation loss: 2.1818918039401374

Epoch: 5| Step: 4
Training loss: 1.5252262353897095
Validation loss: 2.1931662311156592

Epoch: 5| Step: 5
Training loss: 1.9703452587127686
Validation loss: 2.1834045549233756

Epoch: 5| Step: 6
Training loss: 1.6324760913848877
Validation loss: 2.19175331791242

Epoch: 5| Step: 7
Training loss: 1.6991876363754272
Validation loss: 2.176380236943563

Epoch: 5| Step: 8
Training loss: 1.8582403659820557
Validation loss: 2.1617299218972525

Epoch: 5| Step: 9
Training loss: 1.676723837852478
Validation loss: 2.146937608718872

Epoch: 5| Step: 10
Training loss: 1.3892054557800293
Validation loss: 2.142316540082296

Epoch: 5| Step: 11
Training loss: 2.1878628730773926
Validation loss: 2.11861223479112

Epoch: 241| Step: 0
Training loss: 1.8300479650497437
Validation loss: 2.124522884686788

Epoch: 5| Step: 1
Training loss: 1.7097156047821045
Validation loss: 2.099970539410909

Epoch: 5| Step: 2
Training loss: 1.8525161743164062
Validation loss: 2.1273118456204734

Epoch: 5| Step: 3
Training loss: 2.272204875946045
Validation loss: 2.1090170492728553

Epoch: 5| Step: 4
Training loss: 1.8773984909057617
Validation loss: 2.1007273544867835

Epoch: 5| Step: 5
Training loss: 1.5651724338531494
Validation loss: 2.1401932636896768

Epoch: 5| Step: 6
Training loss: 2.279843807220459
Validation loss: 2.1182516117890677

Epoch: 5| Step: 7
Training loss: 1.564927101135254
Validation loss: 2.1154737571875253

Epoch: 5| Step: 8
Training loss: 1.5520082712173462
Validation loss: 2.1201691776514053

Epoch: 5| Step: 9
Training loss: 2.0183308124542236
Validation loss: 2.1568885147571564

Epoch: 5| Step: 10
Training loss: 1.718756079673767
Validation loss: 2.1345992386341095

Epoch: 5| Step: 11
Training loss: 1.9834738969802856
Validation loss: 2.1393897185722985

Epoch: 242| Step: 0
Training loss: 1.6264652013778687
Validation loss: 2.160163089632988

Epoch: 5| Step: 1
Training loss: 1.7337472438812256
Validation loss: 2.151487668355306

Epoch: 5| Step: 2
Training loss: 1.8427989482879639
Validation loss: 2.1724027593930564

Epoch: 5| Step: 3
Training loss: 2.048640012741089
Validation loss: 2.194541578491529

Epoch: 5| Step: 4
Training loss: 1.8018321990966797
Validation loss: 2.1776236097017923

Epoch: 5| Step: 5
Training loss: 2.017636775970459
Validation loss: 2.173397978146871

Epoch: 5| Step: 6
Training loss: 1.804626703262329
Validation loss: 2.188106417655945

Epoch: 5| Step: 7
Training loss: 2.377312421798706
Validation loss: 2.1385123233000436

Epoch: 5| Step: 8
Training loss: 1.7815790176391602
Validation loss: 2.120738372206688

Epoch: 5| Step: 9
Training loss: 1.8455718755722046
Validation loss: 2.107874423265457

Epoch: 5| Step: 10
Training loss: 1.4459105730056763
Validation loss: 2.106117178996404

Epoch: 5| Step: 11
Training loss: 1.2262346744537354
Validation loss: 2.1134619613488517

Epoch: 243| Step: 0
Training loss: 2.133164644241333
Validation loss: 2.1135723690191903

Epoch: 5| Step: 1
Training loss: 1.9800323247909546
Validation loss: 2.1213716119527817

Epoch: 5| Step: 2
Training loss: 2.2349743843078613
Validation loss: 2.1167928874492645

Epoch: 5| Step: 3
Training loss: 1.9152228832244873
Validation loss: 2.122987985610962

Epoch: 5| Step: 4
Training loss: 2.279714584350586
Validation loss: 2.12917830546697

Epoch: 5| Step: 5
Training loss: 1.633247971534729
Validation loss: 2.1532638669013977

Epoch: 5| Step: 6
Training loss: 1.261343002319336
Validation loss: 2.156842033068339

Epoch: 5| Step: 7
Training loss: 1.842386245727539
Validation loss: 2.158573086063067

Epoch: 5| Step: 8
Training loss: 1.430314302444458
Validation loss: 2.183681160211563

Epoch: 5| Step: 9
Training loss: 1.871530532836914
Validation loss: 2.2025574098030725

Epoch: 5| Step: 10
Training loss: 1.9118716716766357
Validation loss: 2.1716667314370475

Epoch: 5| Step: 11
Training loss: 1.7161725759506226
Validation loss: 2.186507677038511

Epoch: 244| Step: 0
Training loss: 1.6719356775283813
Validation loss: 2.1500418186187744

Epoch: 5| Step: 1
Training loss: 1.5811946392059326
Validation loss: 2.110044608513514

Epoch: 5| Step: 2
Training loss: 1.4450658559799194
Validation loss: 2.101069430510203

Epoch: 5| Step: 3
Training loss: 2.2533955574035645
Validation loss: 2.1182463268438974

Epoch: 5| Step: 4
Training loss: 2.2706239223480225
Validation loss: 2.090768446524938

Epoch: 5| Step: 5
Training loss: 1.8830912113189697
Validation loss: 2.113459974527359

Epoch: 5| Step: 6
Training loss: 1.7283836603164673
Validation loss: 2.099349935849508

Epoch: 5| Step: 7
Training loss: 2.27483868598938
Validation loss: 2.109187955657641

Epoch: 5| Step: 8
Training loss: 1.7809937000274658
Validation loss: 2.102528914809227

Epoch: 5| Step: 9
Training loss: 1.7999426126480103
Validation loss: 2.0999596317609153

Epoch: 5| Step: 10
Training loss: 1.7297780513763428
Validation loss: 2.0777847667535148

Epoch: 5| Step: 11
Training loss: 2.1897850036621094
Validation loss: 2.101468617717425

Epoch: 245| Step: 0
Training loss: 1.6324446201324463
Validation loss: 2.097619980573654

Epoch: 5| Step: 1
Training loss: 2.024169921875
Validation loss: 2.1237241377433143

Epoch: 5| Step: 2
Training loss: 1.438008189201355
Validation loss: 2.133535216252009

Epoch: 5| Step: 3
Training loss: 1.8179376125335693
Validation loss: 2.151693398753802

Epoch: 5| Step: 4
Training loss: 1.6317787170410156
Validation loss: 2.138598511616389

Epoch: 5| Step: 5
Training loss: 2.2614998817443848
Validation loss: 2.1403642495473227

Epoch: 5| Step: 6
Training loss: 1.7135837078094482
Validation loss: 2.1568666895230613

Epoch: 5| Step: 7
Training loss: 2.220839262008667
Validation loss: 2.1465836266676583

Epoch: 5| Step: 8
Training loss: 2.2099056243896484
Validation loss: 2.136900415023168

Epoch: 5| Step: 9
Training loss: 1.554091215133667
Validation loss: 2.1318815797567368

Epoch: 5| Step: 10
Training loss: 1.7425289154052734
Validation loss: 2.1436078548431396

Epoch: 5| Step: 11
Training loss: 2.557929039001465
Validation loss: 2.147325644890467

Epoch: 246| Step: 0
Training loss: 1.689422845840454
Validation loss: 2.137184038758278

Epoch: 5| Step: 1
Training loss: 2.0237069129943848
Validation loss: 2.1097533951203027

Epoch: 5| Step: 2
Training loss: 1.374368667602539
Validation loss: 2.1067403058211007

Epoch: 5| Step: 3
Training loss: 1.5147581100463867
Validation loss: 2.1379467993974686

Epoch: 5| Step: 4
Training loss: 2.2225325107574463
Validation loss: 2.1376351366440454

Epoch: 5| Step: 5
Training loss: 1.7302204370498657
Validation loss: 2.126862262686094

Epoch: 5| Step: 6
Training loss: 1.7906465530395508
Validation loss: 2.103145251671473

Epoch: 5| Step: 7
Training loss: 1.581504225730896
Validation loss: 2.132486571868261

Epoch: 5| Step: 8
Training loss: 1.8284209966659546
Validation loss: 2.129908581574758

Epoch: 5| Step: 9
Training loss: 2.0349884033203125
Validation loss: 2.1282353748877845

Epoch: 5| Step: 10
Training loss: 2.135502338409424
Validation loss: 2.1431462864081063

Epoch: 5| Step: 11
Training loss: 2.3222784996032715
Validation loss: 2.13881308833758

Epoch: 247| Step: 0
Training loss: 1.663208246231079
Validation loss: 2.1235340436299643

Epoch: 5| Step: 1
Training loss: 2.209876775741577
Validation loss: 2.1318509926398597

Epoch: 5| Step: 2
Training loss: 2.5949203968048096
Validation loss: 2.1285870323578515

Epoch: 5| Step: 3
Training loss: 1.7823021411895752
Validation loss: 2.1137389491001763

Epoch: 5| Step: 4
Training loss: 1.8887319564819336
Validation loss: 2.125846356153488

Epoch: 5| Step: 5
Training loss: 1.5281485319137573
Validation loss: 2.141063024600347

Epoch: 5| Step: 6
Training loss: 1.6366466283798218
Validation loss: 2.0991269052028656

Epoch: 5| Step: 7
Training loss: 1.6266406774520874
Validation loss: 2.1277186969916024

Epoch: 5| Step: 8
Training loss: 1.929094672203064
Validation loss: 2.1192696491877236

Epoch: 5| Step: 9
Training loss: 1.480629563331604
Validation loss: 2.1269031912088394

Epoch: 5| Step: 10
Training loss: 1.4298673868179321
Validation loss: 2.1467110365629196

Epoch: 5| Step: 11
Training loss: 1.6153265237808228
Validation loss: 2.118667076031367

Epoch: 248| Step: 0
Training loss: 1.9575207233428955
Validation loss: 2.1229597429434457

Epoch: 5| Step: 1
Training loss: 2.2768044471740723
Validation loss: 2.1249037782351174

Epoch: 5| Step: 2
Training loss: 1.5568004846572876
Validation loss: 2.144200329979261

Epoch: 5| Step: 3
Training loss: 1.279267430305481
Validation loss: 2.1368166506290436

Epoch: 5| Step: 4
Training loss: 1.7595735788345337
Validation loss: 2.133218288421631

Epoch: 5| Step: 5
Training loss: 1.9905351400375366
Validation loss: 2.1420128295818963

Epoch: 5| Step: 6
Training loss: 1.5174095630645752
Validation loss: 2.1603141526381173

Epoch: 5| Step: 7
Training loss: 1.7448982000350952
Validation loss: 2.1433484653631845

Epoch: 5| Step: 8
Training loss: 1.9495575428009033
Validation loss: 2.161252419153849

Epoch: 5| Step: 9
Training loss: 1.682163953781128
Validation loss: 2.195341100295385

Epoch: 5| Step: 10
Training loss: 1.716644287109375
Validation loss: 2.166619355479876

Epoch: 5| Step: 11
Training loss: 2.073296308517456
Validation loss: 2.1855589151382446

Epoch: 249| Step: 0
Training loss: 1.822404146194458
Validation loss: 2.203780328234037

Epoch: 5| Step: 1
Training loss: 2.6075522899627686
Validation loss: 2.188847894469897

Epoch: 5| Step: 2
Training loss: 1.586182951927185
Validation loss: 2.21007177233696

Epoch: 5| Step: 3
Training loss: 1.7385585308074951
Validation loss: 2.1643746942281723

Epoch: 5| Step: 4
Training loss: 2.103480100631714
Validation loss: 2.1888550321261087

Epoch: 5| Step: 5
Training loss: 1.9979679584503174
Validation loss: 2.1571789334217706

Epoch: 5| Step: 6
Training loss: 1.9234914779663086
Validation loss: 2.1534263590971627

Epoch: 5| Step: 7
Training loss: 1.9701683521270752
Validation loss: 2.111457904179891

Epoch: 5| Step: 8
Training loss: 1.372800588607788
Validation loss: 2.110319967071215

Epoch: 5| Step: 9
Training loss: 1.3249645233154297
Validation loss: 2.116653402646383

Epoch: 5| Step: 10
Training loss: 1.8361120223999023
Validation loss: 2.094292794664701

Epoch: 5| Step: 11
Training loss: 1.0335015058517456
Validation loss: 2.0813101480404534

Epoch: 250| Step: 0
Training loss: 1.585738182067871
Validation loss: 2.08942773938179

Epoch: 5| Step: 1
Training loss: 2.1877784729003906
Validation loss: 2.098835085829099

Epoch: 5| Step: 2
Training loss: 2.566391706466675
Validation loss: 2.0829253842433295

Epoch: 5| Step: 3
Training loss: 1.340661644935608
Validation loss: 2.1011227518320084

Epoch: 5| Step: 4
Training loss: 1.6474037170410156
Validation loss: 2.1199903090794883

Epoch: 5| Step: 5
Training loss: 1.9230753183364868
Validation loss: 2.127146229147911

Epoch: 5| Step: 6
Training loss: 1.706467866897583
Validation loss: 2.1137672861417136

Epoch: 5| Step: 7
Training loss: 1.9500176906585693
Validation loss: 2.1339758733908334

Epoch: 5| Step: 8
Training loss: 1.9173263311386108
Validation loss: 2.1239855587482452

Epoch: 5| Step: 9
Training loss: 1.5038692951202393
Validation loss: 2.139864280819893

Epoch: 5| Step: 10
Training loss: 1.5012067556381226
Validation loss: 2.1512970626354218

Epoch: 5| Step: 11
Training loss: 1.4751864671707153
Validation loss: 2.1618366738160453

Epoch: 251| Step: 0
Training loss: 1.8146209716796875
Validation loss: 2.1620705922444663

Epoch: 5| Step: 1
Training loss: 1.4223026037216187
Validation loss: 2.180169294277827

Epoch: 5| Step: 2
Training loss: 2.4492175579071045
Validation loss: 2.205757518609365

Epoch: 5| Step: 3
Training loss: 1.8815622329711914
Validation loss: 2.197250083088875

Epoch: 5| Step: 4
Training loss: 1.7733150720596313
Validation loss: 2.2007997930049896

Epoch: 5| Step: 5
Training loss: 1.665461778640747
Validation loss: 2.1858703196048737

Epoch: 5| Step: 6
Training loss: 1.9570446014404297
Validation loss: 2.172458296020826

Epoch: 5| Step: 7
Training loss: 1.311104655265808
Validation loss: 2.1671336392561593

Epoch: 5| Step: 8
Training loss: 2.407301187515259
Validation loss: 2.14096366862456

Epoch: 5| Step: 9
Training loss: 1.7561858892440796
Validation loss: 2.150177478790283

Epoch: 5| Step: 10
Training loss: 1.6276729106903076
Validation loss: 2.1418827325105667

Epoch: 5| Step: 11
Training loss: 2.5820178985595703
Validation loss: 2.119581793745359

Epoch: 252| Step: 0
Training loss: 1.773008942604065
Validation loss: 2.0920634965101876

Epoch: 5| Step: 1
Training loss: 1.953345537185669
Validation loss: 2.0932991604010263

Epoch: 5| Step: 2
Training loss: 2.268491744995117
Validation loss: 2.1003763576348624

Epoch: 5| Step: 3
Training loss: 1.9165172576904297
Validation loss: 2.1073447167873383

Epoch: 5| Step: 4
Training loss: 1.7282603979110718
Validation loss: 2.0682022869586945

Epoch: 5| Step: 5
Training loss: 2.0756053924560547
Validation loss: 2.073399066925049

Epoch: 5| Step: 6
Training loss: 1.7960138320922852
Validation loss: 2.0889794528484344

Epoch: 5| Step: 7
Training loss: 1.7227294445037842
Validation loss: 2.1019842276970544

Epoch: 5| Step: 8
Training loss: 1.8823055028915405
Validation loss: 2.124105821053187

Epoch: 5| Step: 9
Training loss: 1.6385266780853271
Validation loss: 2.137810359398524

Epoch: 5| Step: 10
Training loss: 1.310187578201294
Validation loss: 2.160042633612951

Epoch: 5| Step: 11
Training loss: 1.5636390447616577
Validation loss: 2.171649068593979

Epoch: 253| Step: 0
Training loss: 2.123594045639038
Validation loss: 2.1467968871196113

Epoch: 5| Step: 1
Training loss: 1.5401452779769897
Validation loss: 2.154181425770124

Epoch: 5| Step: 2
Training loss: 2.035806894302368
Validation loss: 2.127109001080195

Epoch: 5| Step: 3
Training loss: 1.784582495689392
Validation loss: 2.130376636981964

Epoch: 5| Step: 4
Training loss: 2.0571038722991943
Validation loss: 2.14252016445001

Epoch: 5| Step: 5
Training loss: 1.9320762157440186
Validation loss: 2.1344547470410666

Epoch: 5| Step: 6
Training loss: 2.0009515285491943
Validation loss: 2.1337437282005944

Epoch: 5| Step: 7
Training loss: 2.055244207382202
Validation loss: 2.131222575902939

Epoch: 5| Step: 8
Training loss: 1.4242020845413208
Validation loss: 2.134253670771917

Epoch: 5| Step: 9
Training loss: 1.4041279554367065
Validation loss: 2.105454757809639

Epoch: 5| Step: 10
Training loss: 1.485649585723877
Validation loss: 2.1322200198968253

Epoch: 5| Step: 11
Training loss: 1.45609450340271
Validation loss: 2.129939690232277

Epoch: 254| Step: 0
Training loss: 1.7975364923477173
Validation loss: 2.1455051004886627

Epoch: 5| Step: 1
Training loss: 1.8427085876464844
Validation loss: 2.15371236205101

Epoch: 5| Step: 2
Training loss: 1.5440692901611328
Validation loss: 2.145068903764089

Epoch: 5| Step: 3
Training loss: 1.8988850116729736
Validation loss: 2.1604795902967453

Epoch: 5| Step: 4
Training loss: 1.8848364353179932
Validation loss: 2.1343878457943597

Epoch: 5| Step: 5
Training loss: 1.4525424242019653
Validation loss: 2.1543830037117004

Epoch: 5| Step: 6
Training loss: 1.4130957126617432
Validation loss: 2.1480650156736374

Epoch: 5| Step: 7
Training loss: 2.093850612640381
Validation loss: 2.1353136400381723

Epoch: 5| Step: 8
Training loss: 1.6462472677230835
Validation loss: 2.1463487992684045

Epoch: 5| Step: 9
Training loss: 2.0157761573791504
Validation loss: 2.155224993824959

Epoch: 5| Step: 10
Training loss: 1.6775468587875366
Validation loss: 2.1657078117132187

Epoch: 5| Step: 11
Training loss: 2.062654495239258
Validation loss: 2.157554099957148

Epoch: 255| Step: 0
Training loss: 1.9279896020889282
Validation loss: 2.1750730921824775

Epoch: 5| Step: 1
Training loss: 1.8856796026229858
Validation loss: 2.1684055974086127

Epoch: 5| Step: 2
Training loss: 1.7739651203155518
Validation loss: 2.189074839154879

Epoch: 5| Step: 3
Training loss: 1.5224779844284058
Validation loss: 2.1883769830067954

Epoch: 5| Step: 4
Training loss: 1.8704760074615479
Validation loss: 2.1927017122507095

Epoch: 5| Step: 5
Training loss: 1.7771583795547485
Validation loss: 2.180834005276362

Epoch: 5| Step: 6
Training loss: 1.9952980279922485
Validation loss: 2.1837354252735772

Epoch: 5| Step: 7
Training loss: 1.575836181640625
Validation loss: 2.1535277316967645

Epoch: 5| Step: 8
Training loss: 2.0661792755126953
Validation loss: 2.143755614757538

Epoch: 5| Step: 9
Training loss: 1.846243143081665
Validation loss: 2.1077486276626587

Epoch: 5| Step: 10
Training loss: 1.439815640449524
Validation loss: 2.108664790789286

Epoch: 5| Step: 11
Training loss: 1.356711745262146
Validation loss: 2.110821778575579

Epoch: 256| Step: 0
Training loss: 2.3074023723602295
Validation loss: 2.098945220311483

Epoch: 5| Step: 1
Training loss: 1.4188941717147827
Validation loss: 2.1087599446376166

Epoch: 5| Step: 2
Training loss: 1.6978371143341064
Validation loss: 2.110896497964859

Epoch: 5| Step: 3
Training loss: 1.3370745182037354
Validation loss: 2.098033905029297

Epoch: 5| Step: 4
Training loss: 1.5733611583709717
Validation loss: 2.0947488049666085

Epoch: 5| Step: 5
Training loss: 2.050097703933716
Validation loss: 2.121365894873937

Epoch: 5| Step: 6
Training loss: 1.9404125213623047
Validation loss: 2.1124074955781302

Epoch: 5| Step: 7
Training loss: 1.7526500225067139
Validation loss: 2.1382466355959573

Epoch: 5| Step: 8
Training loss: 1.7795308828353882
Validation loss: 2.1305783092975616

Epoch: 5| Step: 9
Training loss: 1.7332292795181274
Validation loss: 2.137175887823105

Epoch: 5| Step: 10
Training loss: 2.130002498626709
Validation loss: 2.143648222088814

Epoch: 5| Step: 11
Training loss: 2.718163013458252
Validation loss: 2.1529950002829232

Epoch: 257| Step: 0
Training loss: 1.4997384548187256
Validation loss: 2.1842831621567407

Epoch: 5| Step: 1
Training loss: 1.9749066829681396
Validation loss: 2.166074901819229

Epoch: 5| Step: 2
Training loss: 1.473304271697998
Validation loss: 2.132154236237208

Epoch: 5| Step: 3
Training loss: 1.8113559484481812
Validation loss: 2.1089372038841248

Epoch: 5| Step: 4
Training loss: 1.6271522045135498
Validation loss: 2.149104341864586

Epoch: 5| Step: 5
Training loss: 2.0408530235290527
Validation loss: 2.1145531882842383

Epoch: 5| Step: 6
Training loss: 1.3027050495147705
Validation loss: 2.1313135474920273

Epoch: 5| Step: 7
Training loss: 1.9346561431884766
Validation loss: 2.1275084813435874

Epoch: 5| Step: 8
Training loss: 1.5059435367584229
Validation loss: 2.11769562959671

Epoch: 5| Step: 9
Training loss: 1.8956695795059204
Validation loss: 2.1062913735707602

Epoch: 5| Step: 10
Training loss: 2.228008985519409
Validation loss: 2.1471378107865653

Epoch: 5| Step: 11
Training loss: 2.129237651824951
Validation loss: 2.1375214010477066

Epoch: 258| Step: 0
Training loss: 1.2896759510040283
Validation loss: 2.18752014140288

Epoch: 5| Step: 1
Training loss: 1.744127869606018
Validation loss: 2.1993121008078256

Epoch: 5| Step: 2
Training loss: 1.891103982925415
Validation loss: 2.209597190221151

Epoch: 5| Step: 3
Training loss: 1.9482675790786743
Validation loss: 2.204793984691302

Epoch: 5| Step: 4
Training loss: 2.0067989826202393
Validation loss: 2.2536199490229287

Epoch: 5| Step: 5
Training loss: 2.205576181411743
Validation loss: 2.2404183397690454

Epoch: 5| Step: 6
Training loss: 2.0352396965026855
Validation loss: 2.2045815338691077

Epoch: 5| Step: 7
Training loss: 2.2428722381591797
Validation loss: 2.1929880877335868

Epoch: 5| Step: 8
Training loss: 1.4848519563674927
Validation loss: 2.211352527141571

Epoch: 5| Step: 9
Training loss: 2.023540496826172
Validation loss: 2.169301281372706

Epoch: 5| Step: 10
Training loss: 1.5855739116668701
Validation loss: 2.134355992078781

Epoch: 5| Step: 11
Training loss: 2.7413535118103027
Validation loss: 2.1293644408384957

Epoch: 259| Step: 0
Training loss: 2.071882724761963
Validation loss: 2.140535444021225

Epoch: 5| Step: 1
Training loss: 1.5024254322052002
Validation loss: 2.127666652202606

Epoch: 5| Step: 2
Training loss: 1.6107330322265625
Validation loss: 2.1292658547560372

Epoch: 5| Step: 3
Training loss: 1.5547841787338257
Validation loss: 2.12933083375295

Epoch: 5| Step: 4
Training loss: 1.856156349182129
Validation loss: 2.125503341356913

Epoch: 5| Step: 5
Training loss: 1.386144995689392
Validation loss: 2.112966318925222

Epoch: 5| Step: 6
Training loss: 2.4110395908355713
Validation loss: 2.1219089974959693

Epoch: 5| Step: 7
Training loss: 1.7527036666870117
Validation loss: 2.1582126766443253

Epoch: 5| Step: 8
Training loss: 1.746670126914978
Validation loss: 2.1327780286471048

Epoch: 5| Step: 9
Training loss: 1.8902870416641235
Validation loss: 2.1624088188012442

Epoch: 5| Step: 10
Training loss: 2.2180347442626953
Validation loss: 2.1619646002848945

Epoch: 5| Step: 11
Training loss: 1.4082818031311035
Validation loss: 2.171449134747187

Epoch: 260| Step: 0
Training loss: 1.6087684631347656
Validation loss: 2.157285581032435

Epoch: 5| Step: 1
Training loss: 2.1516823768615723
Validation loss: 2.161202465494474

Epoch: 5| Step: 2
Training loss: 1.5085604190826416
Validation loss: 2.169451435407003

Epoch: 5| Step: 3
Training loss: 1.9327583312988281
Validation loss: 2.162669767936071

Epoch: 5| Step: 4
Training loss: 2.1282665729522705
Validation loss: 2.1524891555309296

Epoch: 5| Step: 5
Training loss: 2.11476731300354
Validation loss: 2.146131917834282

Epoch: 5| Step: 6
Training loss: 1.7691940069198608
Validation loss: 2.1597041686375937

Epoch: 5| Step: 7
Training loss: 1.5779669284820557
Validation loss: 2.130696107943853

Epoch: 5| Step: 8
Training loss: 1.3988964557647705
Validation loss: 2.133253743251165

Epoch: 5| Step: 9
Training loss: 1.6508680582046509
Validation loss: 2.115102767944336

Epoch: 5| Step: 10
Training loss: 1.919415831565857
Validation loss: 2.1224077393611274

Epoch: 5| Step: 11
Training loss: 3.2322328090667725
Validation loss: 2.1315636734167733

Epoch: 261| Step: 0
Training loss: 2.1387548446655273
Validation loss: 2.1228478103876114

Epoch: 5| Step: 1
Training loss: 1.3984620571136475
Validation loss: 2.127678712209066

Epoch: 5| Step: 2
Training loss: 1.872117280960083
Validation loss: 2.143883009751638

Epoch: 5| Step: 3
Training loss: 1.6962864398956299
Validation loss: 2.157702868183454

Epoch: 5| Step: 4
Training loss: 1.7072654962539673
Validation loss: 2.179993917544683

Epoch: 5| Step: 5
Training loss: 1.6432368755340576
Validation loss: 2.1561980793873468

Epoch: 5| Step: 6
Training loss: 1.6188995838165283
Validation loss: 2.156757434209188

Epoch: 5| Step: 7
Training loss: 1.9137649536132812
Validation loss: 2.1616212129592896

Epoch: 5| Step: 8
Training loss: 1.8146177530288696
Validation loss: 2.187117869655291

Epoch: 5| Step: 9
Training loss: 1.4966330528259277
Validation loss: 2.1935399870077767

Epoch: 5| Step: 10
Training loss: 1.96044921875
Validation loss: 2.181689957777659

Epoch: 5| Step: 11
Training loss: 3.494717836380005
Validation loss: 2.1743075301249823

Epoch: 262| Step: 0
Training loss: 2.005735397338867
Validation loss: 2.1393723587195077

Epoch: 5| Step: 1
Training loss: 1.6908481121063232
Validation loss: 2.1383723616600037

Epoch: 5| Step: 2
Training loss: 1.8897966146469116
Validation loss: 2.154532859722773

Epoch: 5| Step: 3
Training loss: 1.3211870193481445
Validation loss: 2.1308930615584054

Epoch: 5| Step: 4
Training loss: 1.7388073205947876
Validation loss: 2.1328012943267822

Epoch: 5| Step: 5
Training loss: 2.5136313438415527
Validation loss: 2.1376823584238687

Epoch: 5| Step: 6
Training loss: 1.554248332977295
Validation loss: 2.1247478723526

Epoch: 5| Step: 7
Training loss: 1.9221404790878296
Validation loss: 2.1260563830534616

Epoch: 5| Step: 8
Training loss: 1.3548681735992432
Validation loss: 2.133590300877889

Epoch: 5| Step: 9
Training loss: 1.7254129648208618
Validation loss: 2.1363835632801056

Epoch: 5| Step: 10
Training loss: 1.641829490661621
Validation loss: 2.129594018061956

Epoch: 5| Step: 11
Training loss: 3.117234230041504
Validation loss: 2.1268675327301025

Epoch: 263| Step: 0
Training loss: 1.8243345022201538
Validation loss: 2.1707741618156433

Epoch: 5| Step: 1
Training loss: 1.6755921840667725
Validation loss: 2.1633632679780326

Epoch: 5| Step: 2
Training loss: 1.2115405797958374
Validation loss: 2.178589016199112

Epoch: 5| Step: 3
Training loss: 1.1778992414474487
Validation loss: 2.1750317911307016

Epoch: 5| Step: 4
Training loss: 1.4897847175598145
Validation loss: 2.180120885372162

Epoch: 5| Step: 5
Training loss: 1.4794617891311646
Validation loss: 2.151652902364731

Epoch: 5| Step: 6
Training loss: 1.8899942636489868
Validation loss: 2.1823513309160867

Epoch: 5| Step: 7
Training loss: 1.9778162240982056
Validation loss: 2.185691778858503

Epoch: 5| Step: 8
Training loss: 2.393009662628174
Validation loss: 2.158614049355189

Epoch: 5| Step: 9
Training loss: 2.0963587760925293
Validation loss: 2.174932802716891

Epoch: 5| Step: 10
Training loss: 2.173387050628662
Validation loss: 2.1583067874113717

Epoch: 5| Step: 11
Training loss: 1.655346393585205
Validation loss: 2.166428416967392

Epoch: 264| Step: 0
Training loss: 2.233806610107422
Validation loss: 2.159338523944219

Epoch: 5| Step: 1
Training loss: 1.6294004917144775
Validation loss: 2.1520296186208725

Epoch: 5| Step: 2
Training loss: 1.4914109706878662
Validation loss: 2.139331301053365

Epoch: 5| Step: 3
Training loss: 2.2449231147766113
Validation loss: 2.123113383849462

Epoch: 5| Step: 4
Training loss: 1.540170669555664
Validation loss: 2.1366281857093177

Epoch: 5| Step: 5
Training loss: 1.6674280166625977
Validation loss: 2.1418156127134957

Epoch: 5| Step: 6
Training loss: 1.2395002841949463
Validation loss: 2.1262169679005942

Epoch: 5| Step: 7
Training loss: 2.1995177268981934
Validation loss: 2.138417194286982

Epoch: 5| Step: 8
Training loss: 1.6876083612442017
Validation loss: 2.1439238091309867

Epoch: 5| Step: 9
Training loss: 1.5215604305267334
Validation loss: 2.162026892105738

Epoch: 5| Step: 10
Training loss: 1.7220752239227295
Validation loss: 2.143089016278585

Epoch: 5| Step: 11
Training loss: 2.3925364017486572
Validation loss: 2.185984432697296

Epoch: 265| Step: 0
Training loss: 1.565940499305725
Validation loss: 2.120846634109815

Epoch: 5| Step: 1
Training loss: 1.9893156290054321
Validation loss: 2.151516298453013

Epoch: 5| Step: 2
Training loss: 2.253378391265869
Validation loss: 2.164153511325518

Epoch: 5| Step: 3
Training loss: 1.9024654626846313
Validation loss: 2.150093674659729

Epoch: 5| Step: 4
Training loss: 1.183960199356079
Validation loss: 2.1355182826519012

Epoch: 5| Step: 5
Training loss: 2.0409023761749268
Validation loss: 2.165365715821584

Epoch: 5| Step: 6
Training loss: 1.2969125509262085
Validation loss: 2.1930435498555503

Epoch: 5| Step: 7
Training loss: 1.668609619140625
Validation loss: 2.1639129420121512

Epoch: 5| Step: 8
Training loss: 1.931614875793457
Validation loss: 2.164964700738589

Epoch: 5| Step: 9
Training loss: 1.610722303390503
Validation loss: 2.203316072622935

Epoch: 5| Step: 10
Training loss: 1.7067410945892334
Validation loss: 2.1891517589489617

Epoch: 5| Step: 11
Training loss: 1.5290257930755615
Validation loss: 2.1964595367511115

Epoch: 266| Step: 0
Training loss: 1.2789055109024048
Validation loss: 2.1626965949932733

Epoch: 5| Step: 1
Training loss: 1.2009904384613037
Validation loss: 2.1953319807847342

Epoch: 5| Step: 2
Training loss: 1.8083503246307373
Validation loss: 2.1975475549697876

Epoch: 5| Step: 3
Training loss: 1.5286157131195068
Validation loss: 2.186982144912084

Epoch: 5| Step: 4
Training loss: 1.4649927616119385
Validation loss: 2.1664468000332513

Epoch: 5| Step: 5
Training loss: 2.0699596405029297
Validation loss: 2.157959704597791

Epoch: 5| Step: 6
Training loss: 2.1651997566223145
Validation loss: 2.1525473594665527

Epoch: 5| Step: 7
Training loss: 1.580971121788025
Validation loss: 2.1417761594057083

Epoch: 5| Step: 8
Training loss: 1.969559907913208
Validation loss: 2.1368873715400696

Epoch: 5| Step: 9
Training loss: 2.153193712234497
Validation loss: 2.12716381251812

Epoch: 5| Step: 10
Training loss: 2.0628600120544434
Validation loss: 2.1114353289206824

Epoch: 5| Step: 11
Training loss: 1.2909489870071411
Validation loss: 2.153562287489573

Epoch: 267| Step: 0
Training loss: 1.8477942943572998
Validation loss: 2.1390719413757324

Epoch: 5| Step: 1
Training loss: 1.752453088760376
Validation loss: 2.1779588808616004

Epoch: 5| Step: 2
Training loss: 1.8604087829589844
Validation loss: 2.174322078625361

Epoch: 5| Step: 3
Training loss: 1.825279951095581
Validation loss: 2.2140590151151023

Epoch: 5| Step: 4
Training loss: 2.185727119445801
Validation loss: 2.220859785874685

Epoch: 5| Step: 5
Training loss: 1.5991767644882202
Validation loss: 2.2161932587623596

Epoch: 5| Step: 6
Training loss: 1.5237970352172852
Validation loss: 2.2187452614307404

Epoch: 5| Step: 7
Training loss: 1.5134834051132202
Validation loss: 2.185856501261393

Epoch: 5| Step: 8
Training loss: 2.1835005283355713
Validation loss: 2.1420581291119256

Epoch: 5| Step: 9
Training loss: 1.4963639974594116
Validation loss: 2.1595446169376373

Epoch: 5| Step: 10
Training loss: 1.4925177097320557
Validation loss: 2.1473255654176078

Epoch: 5| Step: 11
Training loss: 0.8586387634277344
Validation loss: 2.11984155078729

Epoch: 268| Step: 0
Training loss: 1.6194438934326172
Validation loss: 2.117643723885218

Epoch: 5| Step: 1
Training loss: 1.358567714691162
Validation loss: 2.1297925462325416

Epoch: 5| Step: 2
Training loss: 2.1128430366516113
Validation loss: 2.1210352033376694

Epoch: 5| Step: 3
Training loss: 1.9009895324707031
Validation loss: 2.134865169723829

Epoch: 5| Step: 4
Training loss: 1.9641730785369873
Validation loss: 2.1558697670698166

Epoch: 5| Step: 5
Training loss: 2.162074565887451
Validation loss: 2.1369950671990714

Epoch: 5| Step: 6
Training loss: 1.2029939889907837
Validation loss: 2.138998880982399

Epoch: 5| Step: 7
Training loss: 2.0124049186706543
Validation loss: 2.1626055985689163

Epoch: 5| Step: 8
Training loss: 2.1165266036987305
Validation loss: 2.165076494216919

Epoch: 5| Step: 9
Training loss: 1.2779409885406494
Validation loss: 2.1696817378203073

Epoch: 5| Step: 10
Training loss: 1.742509126663208
Validation loss: 2.1799375464518866

Epoch: 5| Step: 11
Training loss: 2.2276575565338135
Validation loss: 2.1629545936981835

Epoch: 269| Step: 0
Training loss: 2.4811224937438965
Validation loss: 2.173788473010063

Epoch: 5| Step: 1
Training loss: 1.3589651584625244
Validation loss: 2.1617037703593573

Epoch: 5| Step: 2
Training loss: 1.3309167623519897
Validation loss: 2.1543949395418167

Epoch: 5| Step: 3
Training loss: 2.1284680366516113
Validation loss: 2.128574699163437

Epoch: 5| Step: 4
Training loss: 1.579306960105896
Validation loss: 2.134734953443209

Epoch: 5| Step: 5
Training loss: 2.4244656562805176
Validation loss: 2.1232292701800666

Epoch: 5| Step: 6
Training loss: 1.8421013355255127
Validation loss: 2.1262282033761344

Epoch: 5| Step: 7
Training loss: 1.6364109516143799
Validation loss: 2.0913215577602386

Epoch: 5| Step: 8
Training loss: 1.3154799938201904
Validation loss: 2.130689784884453

Epoch: 5| Step: 9
Training loss: 1.9399213790893555
Validation loss: 2.1061978886524835

Epoch: 5| Step: 10
Training loss: 2.1093029975891113
Validation loss: 2.132565667231878

Epoch: 5| Step: 11
Training loss: 1.4341838359832764
Validation loss: 2.128122389316559

Epoch: 270| Step: 0
Training loss: 1.9596134424209595
Validation loss: 2.1407082875569663

Epoch: 5| Step: 1
Training loss: 1.39491868019104
Validation loss: 2.1570391903320947

Epoch: 5| Step: 2
Training loss: 2.408419132232666
Validation loss: 2.1367511550585427

Epoch: 5| Step: 3
Training loss: 2.1135127544403076
Validation loss: 2.151273176074028

Epoch: 5| Step: 4
Training loss: 1.2268385887145996
Validation loss: 2.160458584626516

Epoch: 5| Step: 5
Training loss: 1.8283981084823608
Validation loss: 2.1744273950656257

Epoch: 5| Step: 6
Training loss: 1.8522074222564697
Validation loss: 2.1584675312042236

Epoch: 5| Step: 7
Training loss: 1.5716512203216553
Validation loss: 2.204493428270022

Epoch: 5| Step: 8
Training loss: 1.6477760076522827
Validation loss: 2.172047217686971

Epoch: 5| Step: 9
Training loss: 1.7533369064331055
Validation loss: 2.1738246083259583

Epoch: 5| Step: 10
Training loss: 1.7686179876327515
Validation loss: 2.1708558003107705

Epoch: 5| Step: 11
Training loss: 1.4871610403060913
Validation loss: 2.1554913322130838

Epoch: 271| Step: 0
Training loss: 1.083155632019043
Validation loss: 2.160953382651011

Epoch: 5| Step: 1
Training loss: 2.537480592727661
Validation loss: 2.1449029048283896

Epoch: 5| Step: 2
Training loss: 1.6785309314727783
Validation loss: 2.133718421061834

Epoch: 5| Step: 3
Training loss: 1.4408302307128906
Validation loss: 2.1378838270902634

Epoch: 5| Step: 4
Training loss: 1.8975021839141846
Validation loss: 2.1425145864486694

Epoch: 5| Step: 5
Training loss: 1.566648006439209
Validation loss: 2.1388475199540458

Epoch: 5| Step: 6
Training loss: 1.6929957866668701
Validation loss: 2.1202254792054496

Epoch: 5| Step: 7
Training loss: 1.545593023300171
Validation loss: 2.1304722974697747

Epoch: 5| Step: 8
Training loss: 1.868032693862915
Validation loss: 2.136756787697474

Epoch: 5| Step: 9
Training loss: 2.027155876159668
Validation loss: 2.1203248500823975

Epoch: 5| Step: 10
Training loss: 1.76739501953125
Validation loss: 2.164501870671908

Epoch: 5| Step: 11
Training loss: 2.723504066467285
Validation loss: 2.172616293032964

Epoch: 272| Step: 0
Training loss: 1.8873777389526367
Validation loss: 2.173416326443354

Epoch: 5| Step: 1
Training loss: 2.184671640396118
Validation loss: 2.1741526325543723

Epoch: 5| Step: 2
Training loss: 1.7353687286376953
Validation loss: 2.165292128920555

Epoch: 5| Step: 3
Training loss: 1.6469920873641968
Validation loss: 2.1557460526625314

Epoch: 5| Step: 4
Training loss: 1.654439926147461
Validation loss: 2.127152373393377

Epoch: 5| Step: 5
Training loss: 1.706717848777771
Validation loss: 2.1208346436421075

Epoch: 5| Step: 6
Training loss: 1.542062520980835
Validation loss: 2.1383743385473886

Epoch: 5| Step: 7
Training loss: 1.6565539836883545
Validation loss: 2.1239221493403115

Epoch: 5| Step: 8
Training loss: 2.2703967094421387
Validation loss: 2.118517359097799

Epoch: 5| Step: 9
Training loss: 1.646688461303711
Validation loss: 2.1071293701728186

Epoch: 5| Step: 10
Training loss: 1.4524601697921753
Validation loss: 2.1465237786372504

Epoch: 5| Step: 11
Training loss: 1.6794383525848389
Validation loss: 2.1257660736640296

Epoch: 273| Step: 0
Training loss: 2.520813465118408
Validation loss: 2.135449474056562

Epoch: 5| Step: 1
Training loss: 1.5947140455245972
Validation loss: 2.157120148340861

Epoch: 5| Step: 2
Training loss: 1.1615993976593018
Validation loss: 2.116712808609009

Epoch: 5| Step: 3
Training loss: 2.046363353729248
Validation loss: 2.128335803747177

Epoch: 5| Step: 4
Training loss: 1.3657435178756714
Validation loss: 2.150633543729782

Epoch: 5| Step: 5
Training loss: 2.0711498260498047
Validation loss: 2.1371623128652573

Epoch: 5| Step: 6
Training loss: 1.7297964096069336
Validation loss: 2.149408628543218

Epoch: 5| Step: 7
Training loss: 1.6611312627792358
Validation loss: 2.1374191592137017

Epoch: 5| Step: 8
Training loss: 1.3996217250823975
Validation loss: 2.118485316634178

Epoch: 5| Step: 9
Training loss: 1.9121748208999634
Validation loss: 2.1184214452902475

Epoch: 5| Step: 10
Training loss: 1.9017791748046875
Validation loss: 2.1053729156653085

Epoch: 5| Step: 11
Training loss: 1.5283945798873901
Validation loss: 2.1437508513530097

Epoch: 274| Step: 0
Training loss: 1.2125346660614014
Validation loss: 2.115502138932546

Epoch: 5| Step: 1
Training loss: 1.6625903844833374
Validation loss: 2.1430906305710473

Epoch: 5| Step: 2
Training loss: 1.6413984298706055
Validation loss: 2.1237931499878564

Epoch: 5| Step: 3
Training loss: 2.0397911071777344
Validation loss: 2.1585313280423484

Epoch: 5| Step: 4
Training loss: 2.411790132522583
Validation loss: 2.173305948575338

Epoch: 5| Step: 5
Training loss: 1.8358443975448608
Validation loss: 2.2109588583310447

Epoch: 5| Step: 6
Training loss: 1.6445480585098267
Validation loss: 2.2164448648691177

Epoch: 5| Step: 7
Training loss: 1.4927477836608887
Validation loss: 2.2232986638943353

Epoch: 5| Step: 8
Training loss: 1.6378366947174072
Validation loss: 2.151906450589498

Epoch: 5| Step: 9
Training loss: 1.6602506637573242
Validation loss: 2.187591180205345

Epoch: 5| Step: 10
Training loss: 1.8233808279037476
Validation loss: 2.156186838944753

Epoch: 5| Step: 11
Training loss: 1.212220311164856
Validation loss: 2.1365302304426828

Epoch: 275| Step: 0
Training loss: 2.0070488452911377
Validation loss: 2.143889288107554

Epoch: 5| Step: 1
Training loss: 2.428476095199585
Validation loss: 2.1183386941750846

Epoch: 5| Step: 2
Training loss: 1.2415223121643066
Validation loss: 2.1321569979190826

Epoch: 5| Step: 3
Training loss: 1.858263611793518
Validation loss: 2.1089898546536765

Epoch: 5| Step: 4
Training loss: 1.5955584049224854
Validation loss: 2.125958094994227

Epoch: 5| Step: 5
Training loss: 1.5947952270507812
Validation loss: 2.1242558856805167

Epoch: 5| Step: 6
Training loss: 2.4111499786376953
Validation loss: 2.1122569839159646

Epoch: 5| Step: 7
Training loss: 1.5015251636505127
Validation loss: 2.15686796605587

Epoch: 5| Step: 8
Training loss: 1.8475223779678345
Validation loss: 2.165885349114736

Epoch: 5| Step: 9
Training loss: 1.6285040378570557
Validation loss: 2.1347974042097726

Epoch: 5| Step: 10
Training loss: 1.4281821250915527
Validation loss: 2.214897279938062

Epoch: 5| Step: 11
Training loss: 2.062410831451416
Validation loss: 2.2030243376890817

Epoch: 276| Step: 0
Training loss: 1.9632905721664429
Validation loss: 2.1799941112597785

Epoch: 5| Step: 1
Training loss: 1.524416208267212
Validation loss: 2.1925501773754754

Epoch: 5| Step: 2
Training loss: 1.5289788246154785
Validation loss: 2.2008887926737466

Epoch: 5| Step: 3
Training loss: 1.6441898345947266
Validation loss: 2.164709950486819

Epoch: 5| Step: 4
Training loss: 2.771017551422119
Validation loss: 2.1627473880847297

Epoch: 5| Step: 5
Training loss: 1.5623098611831665
Validation loss: 2.1378256479899087

Epoch: 5| Step: 6
Training loss: 1.7245897054672241
Validation loss: 2.147972822189331

Epoch: 5| Step: 7
Training loss: 1.7767215967178345
Validation loss: 2.1446159730354943

Epoch: 5| Step: 8
Training loss: 1.526757001876831
Validation loss: 2.16213496029377

Epoch: 5| Step: 9
Training loss: 1.5451889038085938
Validation loss: 2.1845801572004953

Epoch: 5| Step: 10
Training loss: 1.5008127689361572
Validation loss: 2.2219424744447074

Epoch: 5| Step: 11
Training loss: 0.870369017124176
Validation loss: 2.1870710452397666

Epoch: 277| Step: 0
Training loss: 1.2448089122772217
Validation loss: 2.184842566649119

Epoch: 5| Step: 1
Training loss: 1.8680168390274048
Validation loss: 2.1859359741210938

Epoch: 5| Step: 2
Training loss: 1.4904683828353882
Validation loss: 2.1844025204579034

Epoch: 5| Step: 3
Training loss: 2.030229091644287
Validation loss: 2.184875542918841

Epoch: 5| Step: 4
Training loss: 1.636139154434204
Validation loss: 2.1559344877799353

Epoch: 5| Step: 5
Training loss: 2.011888027191162
Validation loss: 2.1460883816083274

Epoch: 5| Step: 6
Training loss: 1.5819199085235596
Validation loss: 2.1392240772644677

Epoch: 5| Step: 7
Training loss: 1.693777084350586
Validation loss: 2.138376926382383

Epoch: 5| Step: 8
Training loss: 1.7704271078109741
Validation loss: 2.161079744497935

Epoch: 5| Step: 9
Training loss: 2.428248167037964
Validation loss: 2.13922555744648

Epoch: 5| Step: 10
Training loss: 1.2459022998809814
Validation loss: 2.1452465752760568

Epoch: 5| Step: 11
Training loss: 1.2541329860687256
Validation loss: 2.1613952815532684

Epoch: 278| Step: 0
Training loss: 2.0476980209350586
Validation loss: 2.149257938067118

Epoch: 5| Step: 1
Training loss: 1.7424545288085938
Validation loss: 2.1977552821238837

Epoch: 5| Step: 2
Training loss: 2.1279172897338867
Validation loss: 2.210152437289556

Epoch: 5| Step: 3
Training loss: 1.3636243343353271
Validation loss: 2.2103856901327767

Epoch: 5| Step: 4
Training loss: 2.1396145820617676
Validation loss: 2.2160687694946923

Epoch: 5| Step: 5
Training loss: 1.2270677089691162
Validation loss: 2.1980503300825753

Epoch: 5| Step: 6
Training loss: 1.5695527791976929
Validation loss: 2.22332896788915

Epoch: 5| Step: 7
Training loss: 1.5296647548675537
Validation loss: 2.207884763677915

Epoch: 5| Step: 8
Training loss: 1.4593772888183594
Validation loss: 2.1875244478384652

Epoch: 5| Step: 9
Training loss: 1.6668369770050049
Validation loss: 2.164292777578036

Epoch: 5| Step: 10
Training loss: 1.8268053531646729
Validation loss: 2.1571881473064423

Epoch: 5| Step: 11
Training loss: 2.256467342376709
Validation loss: 2.137687702973684

Epoch: 279| Step: 0
Training loss: 2.136991024017334
Validation loss: 2.115181336800257

Epoch: 5| Step: 1
Training loss: 1.9678329229354858
Validation loss: 2.1073680569728217

Epoch: 5| Step: 2
Training loss: 1.6177902221679688
Validation loss: 2.116661091645559

Epoch: 5| Step: 3
Training loss: 1.8476186990737915
Validation loss: 2.1303761253754296

Epoch: 5| Step: 4
Training loss: 1.8658695220947266
Validation loss: 2.1091322203477225

Epoch: 5| Step: 5
Training loss: 1.8694210052490234
Validation loss: 2.1183465719223022

Epoch: 5| Step: 6
Training loss: 1.5959479808807373
Validation loss: 2.1330102384090424

Epoch: 5| Step: 7
Training loss: 1.2788581848144531
Validation loss: 2.145875076452891

Epoch: 5| Step: 8
Training loss: 1.2678792476654053
Validation loss: 2.1650229593118033

Epoch: 5| Step: 9
Training loss: 1.73407781124115
Validation loss: 2.2104164958000183

Epoch: 5| Step: 10
Training loss: 1.6299537420272827
Validation loss: 2.216201369961103

Epoch: 5| Step: 11
Training loss: 1.4415805339813232
Validation loss: 2.212366039554278

Epoch: 280| Step: 0
Training loss: 1.9800792932510376
Validation loss: 2.2328690737485886

Epoch: 5| Step: 1
Training loss: 1.90176260471344
Validation loss: 2.2555750012397766

Epoch: 5| Step: 2
Training loss: 2.012582540512085
Validation loss: 2.2223750154177346

Epoch: 5| Step: 3
Training loss: 1.7993628978729248
Validation loss: 2.2212146868308387

Epoch: 5| Step: 4
Training loss: 1.566414475440979
Validation loss: 2.1903868516286216

Epoch: 5| Step: 5
Training loss: 1.6099668741226196
Validation loss: 2.16944228609403

Epoch: 5| Step: 6
Training loss: 1.1064475774765015
Validation loss: 2.1719814290603003

Epoch: 5| Step: 7
Training loss: 1.546539545059204
Validation loss: 2.1595207502444587

Epoch: 5| Step: 8
Training loss: 1.817456603050232
Validation loss: 2.1699223816394806

Epoch: 5| Step: 9
Training loss: 2.155268907546997
Validation loss: 2.1375312010447183

Epoch: 5| Step: 10
Training loss: 1.7984974384307861
Validation loss: 2.1431828439235687

Epoch: 5| Step: 11
Training loss: 2.644385814666748
Validation loss: 2.1474194626013436

Epoch: 281| Step: 0
Training loss: 1.404645323753357
Validation loss: 2.1631731390953064

Epoch: 5| Step: 1
Training loss: 1.3218797445297241
Validation loss: 2.170445755124092

Epoch: 5| Step: 2
Training loss: 1.6970182657241821
Validation loss: 2.158294419447581

Epoch: 5| Step: 3
Training loss: 2.2009940147399902
Validation loss: 2.156912346680959

Epoch: 5| Step: 4
Training loss: 2.1065874099731445
Validation loss: 2.202722912033399

Epoch: 5| Step: 5
Training loss: 1.793952226638794
Validation loss: 2.2219372391700745

Epoch: 5| Step: 6
Training loss: 1.9261350631713867
Validation loss: 2.2094624837239585

Epoch: 5| Step: 7
Training loss: 1.3980991840362549
Validation loss: 2.208792527516683

Epoch: 5| Step: 8
Training loss: 1.5698529481887817
Validation loss: 2.2205296456813812

Epoch: 5| Step: 9
Training loss: 2.0486292839050293
Validation loss: 2.1862411548693976

Epoch: 5| Step: 10
Training loss: 1.9612789154052734
Validation loss: 2.2013620336850486

Epoch: 5| Step: 11
Training loss: 0.7499614357948303
Validation loss: 2.147364387909571

Epoch: 282| Step: 0
Training loss: 1.352846622467041
Validation loss: 2.1635364343722663

Epoch: 5| Step: 1
Training loss: 1.2461436986923218
Validation loss: 2.1691849331061044

Epoch: 5| Step: 2
Training loss: 1.7251694202423096
Validation loss: 2.1576952040195465

Epoch: 5| Step: 3
Training loss: 1.3694347143173218
Validation loss: 2.170314699411392

Epoch: 5| Step: 4
Training loss: 1.7463181018829346
Validation loss: 2.1948115825653076

Epoch: 5| Step: 5
Training loss: 1.591718077659607
Validation loss: 2.160518705844879

Epoch: 5| Step: 6
Training loss: 2.6960949897766113
Validation loss: 2.1503972907861075

Epoch: 5| Step: 7
Training loss: 1.2918918132781982
Validation loss: 2.2010095417499542

Epoch: 5| Step: 8
Training loss: 1.5138009786605835
Validation loss: 2.1979530105988183

Epoch: 5| Step: 9
Training loss: 1.8197317123413086
Validation loss: 2.188722684979439

Epoch: 5| Step: 10
Training loss: 1.853415846824646
Validation loss: 2.1835253884394965

Epoch: 5| Step: 11
Training loss: 3.125004291534424
Validation loss: 2.1864248464504876

Epoch: 283| Step: 0
Training loss: 1.7914037704467773
Validation loss: 2.197260022163391

Epoch: 5| Step: 1
Training loss: 2.0235331058502197
Validation loss: 2.2027360747257867

Epoch: 5| Step: 2
Training loss: 1.56975519657135
Validation loss: 2.2100032716989517

Epoch: 5| Step: 3
Training loss: 1.6742045879364014
Validation loss: 2.170100376009941

Epoch: 5| Step: 4
Training loss: 1.7128093242645264
Validation loss: 2.1680755267540612

Epoch: 5| Step: 5
Training loss: 1.536451816558838
Validation loss: 2.181871379415194

Epoch: 5| Step: 6
Training loss: 1.2623522281646729
Validation loss: 2.1580782930056253

Epoch: 5| Step: 7
Training loss: 1.7665278911590576
Validation loss: 2.1596598625183105

Epoch: 5| Step: 8
Training loss: 1.7136991024017334
Validation loss: 2.1302943974733353

Epoch: 5| Step: 9
Training loss: 1.782270073890686
Validation loss: 2.1444151202837625

Epoch: 5| Step: 10
Training loss: 2.0023322105407715
Validation loss: 2.1400151203076043

Epoch: 5| Step: 11
Training loss: 1.101193904876709
Validation loss: 2.1689813981453576

Epoch: 284| Step: 0
Training loss: 2.181448221206665
Validation loss: 2.130252882838249

Epoch: 5| Step: 1
Training loss: 1.708927869796753
Validation loss: 2.1361517161130905

Epoch: 5| Step: 2
Training loss: 2.57456636428833
Validation loss: 2.1295029520988464

Epoch: 5| Step: 3
Training loss: 1.3513957262039185
Validation loss: 2.114715948700905

Epoch: 5| Step: 4
Training loss: 1.451658010482788
Validation loss: 2.1639493306477866

Epoch: 5| Step: 5
Training loss: 1.1381728649139404
Validation loss: 2.164445107181867

Epoch: 5| Step: 6
Training loss: 1.6558955907821655
Validation loss: 2.143876259525617

Epoch: 5| Step: 7
Training loss: 1.9444217681884766
Validation loss: 2.1583402951558432

Epoch: 5| Step: 8
Training loss: 1.3756227493286133
Validation loss: 2.1652944485346475

Epoch: 5| Step: 9
Training loss: 1.8063485622406006
Validation loss: 2.1575105090936026

Epoch: 5| Step: 10
Training loss: 1.688359022140503
Validation loss: 2.1378885010878244

Epoch: 5| Step: 11
Training loss: 1.2885382175445557
Validation loss: 2.182688315709432

Epoch: 285| Step: 0
Training loss: 1.5773760080337524
Validation loss: 2.1778784841299057

Epoch: 5| Step: 1
Training loss: 1.7029449939727783
Validation loss: 2.1361537178357444

Epoch: 5| Step: 2
Training loss: 1.1948636770248413
Validation loss: 2.160701245069504

Epoch: 5| Step: 3
Training loss: 2.0342259407043457
Validation loss: 2.166648825009664

Epoch: 5| Step: 4
Training loss: 2.1548144817352295
Validation loss: 2.16425758600235

Epoch: 5| Step: 5
Training loss: 2.1522176265716553
Validation loss: 2.136676385998726

Epoch: 5| Step: 6
Training loss: 1.073547124862671
Validation loss: 2.139073779185613

Epoch: 5| Step: 7
Training loss: 1.599768877029419
Validation loss: 2.143909434477488

Epoch: 5| Step: 8
Training loss: 1.1313871145248413
Validation loss: 2.1463072448968887

Epoch: 5| Step: 9
Training loss: 1.8165061473846436
Validation loss: 2.177003353834152

Epoch: 5| Step: 10
Training loss: 1.3931487798690796
Validation loss: 2.2229397694269815

Epoch: 5| Step: 11
Training loss: 2.938934803009033
Validation loss: 2.203765168786049

Epoch: 286| Step: 0
Training loss: 1.4018256664276123
Validation loss: 2.194317509730657

Epoch: 5| Step: 1
Training loss: 1.8632144927978516
Validation loss: 2.2306385238965354

Epoch: 5| Step: 2
Training loss: 1.788527250289917
Validation loss: 2.18826816479365

Epoch: 5| Step: 3
Training loss: 1.6520092487335205
Validation loss: 2.214040001233419

Epoch: 5| Step: 4
Training loss: 2.0403106212615967
Validation loss: 2.222416857878367

Epoch: 5| Step: 5
Training loss: 1.844855546951294
Validation loss: 2.210244437058767

Epoch: 5| Step: 6
Training loss: 1.4280188083648682
Validation loss: 2.2078174402316413

Epoch: 5| Step: 7
Training loss: 2.1262729167938232
Validation loss: 2.204771180947622

Epoch: 5| Step: 8
Training loss: 1.3317954540252686
Validation loss: 2.158823236823082

Epoch: 5| Step: 9
Training loss: 2.3604488372802734
Validation loss: 2.122604231039683

Epoch: 5| Step: 10
Training loss: 1.2513742446899414
Validation loss: 2.1237772007783255

Epoch: 5| Step: 11
Training loss: 0.7319856286048889
Validation loss: 2.1381295919418335

Epoch: 287| Step: 0
Training loss: 2.0230555534362793
Validation loss: 2.1539328495661416

Epoch: 5| Step: 1
Training loss: 2.1317248344421387
Validation loss: 2.171343058347702

Epoch: 5| Step: 2
Training loss: 1.5980793237686157
Validation loss: 2.127160211404165

Epoch: 5| Step: 3
Training loss: 1.690127968788147
Validation loss: 2.149701734383901

Epoch: 5| Step: 4
Training loss: 0.9293750524520874
Validation loss: 2.1843383510907493

Epoch: 5| Step: 5
Training loss: 1.5993555784225464
Validation loss: 2.143085479736328

Epoch: 5| Step: 6
Training loss: 1.7451311349868774
Validation loss: 2.137693539261818

Epoch: 5| Step: 7
Training loss: 1.6124780178070068
Validation loss: 2.1621018648147583

Epoch: 5| Step: 8
Training loss: 1.7098493576049805
Validation loss: 2.120535731315613

Epoch: 5| Step: 9
Training loss: 1.8320112228393555
Validation loss: 2.1694338421026864

Epoch: 5| Step: 10
Training loss: 1.3402036428451538
Validation loss: 2.1615913013617196

Epoch: 5| Step: 11
Training loss: 0.7429832220077515
Validation loss: 2.1638110180695853

Epoch: 288| Step: 0
Training loss: 1.7249929904937744
Validation loss: 2.138015558322271

Epoch: 5| Step: 1
Training loss: 2.348823070526123
Validation loss: 2.1330951750278473

Epoch: 5| Step: 2
Training loss: 1.504804015159607
Validation loss: 2.136194164554278

Epoch: 5| Step: 3
Training loss: 1.7227537631988525
Validation loss: 2.145853742957115

Epoch: 5| Step: 4
Training loss: 1.8570983409881592
Validation loss: 2.1453633407751718

Epoch: 5| Step: 5
Training loss: 1.564407229423523
Validation loss: 2.1413026501735053

Epoch: 5| Step: 6
Training loss: 1.7236661911010742
Validation loss: 2.139413704474767

Epoch: 5| Step: 7
Training loss: 2.054304599761963
Validation loss: 2.174074649810791

Epoch: 5| Step: 8
Training loss: 1.9394874572753906
Validation loss: 2.1675389409065247

Epoch: 5| Step: 9
Training loss: 1.3982020616531372
Validation loss: 2.1519249826669693

Epoch: 5| Step: 10
Training loss: 1.5556156635284424
Validation loss: 2.1381563544273376

Epoch: 5| Step: 11
Training loss: 1.8776514530181885
Validation loss: 2.173334459463755

Epoch: 289| Step: 0
Training loss: 1.8007370233535767
Validation loss: 2.1381445775429406

Epoch: 5| Step: 1
Training loss: 1.8455448150634766
Validation loss: 2.1442843973636627

Epoch: 5| Step: 2
Training loss: 1.8047376871109009
Validation loss: 2.168495843807856

Epoch: 5| Step: 3
Training loss: 2.03063702583313
Validation loss: 2.1648310671250024

Epoch: 5| Step: 4
Training loss: 1.7637290954589844
Validation loss: 2.1798619677623114

Epoch: 5| Step: 5
Training loss: 2.0113627910614014
Validation loss: 2.187685549259186

Epoch: 5| Step: 6
Training loss: 2.1653895378112793
Validation loss: 2.212183172504107

Epoch: 5| Step: 7
Training loss: 1.5247385501861572
Validation loss: 2.2106226136287055

Epoch: 5| Step: 8
Training loss: 1.5473301410675049
Validation loss: 2.222598433494568

Epoch: 5| Step: 9
Training loss: 2.3117401599884033
Validation loss: 2.1973839749892554

Epoch: 5| Step: 10
Training loss: 1.3734267950057983
Validation loss: 2.207608143488566

Epoch: 5| Step: 11
Training loss: 1.4883685111999512
Validation loss: 2.1860927045345306

Epoch: 290| Step: 0
Training loss: 1.996961236000061
Validation loss: 2.231980303923289

Epoch: 5| Step: 1
Training loss: 1.6876167058944702
Validation loss: 2.2206062972545624

Epoch: 5| Step: 2
Training loss: 1.5213056802749634
Validation loss: 2.215439587831497

Epoch: 5| Step: 3
Training loss: 2.4373953342437744
Validation loss: 2.1882497320572534

Epoch: 5| Step: 4
Training loss: 1.801408052444458
Validation loss: 2.2011225124200187

Epoch: 5| Step: 5
Training loss: 1.4077280759811401
Validation loss: 2.190369427204132

Epoch: 5| Step: 6
Training loss: 1.7674068212509155
Validation loss: 2.175133779644966

Epoch: 5| Step: 7
Training loss: 2.071749210357666
Validation loss: 2.178975353638331

Epoch: 5| Step: 8
Training loss: 1.686629295349121
Validation loss: 2.1735243002573648

Epoch: 5| Step: 9
Training loss: 1.7058613300323486
Validation loss: 2.2017675389846167

Epoch: 5| Step: 10
Training loss: 2.3049163818359375
Validation loss: 2.1791874120632806

Epoch: 5| Step: 11
Training loss: 0.2065749168395996
Validation loss: 2.1974577407042184

Epoch: 291| Step: 0
Training loss: 1.548005223274231
Validation loss: 2.195075730482737

Epoch: 5| Step: 1
Training loss: 1.7558997869491577
Validation loss: 2.182882865269979

Epoch: 5| Step: 2
Training loss: 1.4017431735992432
Validation loss: 2.221278950572014

Epoch: 5| Step: 3
Training loss: 1.5366184711456299
Validation loss: 2.177540307243665

Epoch: 5| Step: 4
Training loss: 2.035069227218628
Validation loss: 2.147719586888949

Epoch: 5| Step: 5
Training loss: 1.9464048147201538
Validation loss: 2.1662480433781943

Epoch: 5| Step: 6
Training loss: 1.6221301555633545
Validation loss: 2.134476309021314

Epoch: 5| Step: 7
Training loss: 1.8745168447494507
Validation loss: 2.1471922596295676

Epoch: 5| Step: 8
Training loss: 2.12628173828125
Validation loss: 2.1187314093112946

Epoch: 5| Step: 9
Training loss: 1.5552833080291748
Validation loss: 2.1336633761723838

Epoch: 5| Step: 10
Training loss: 1.8357934951782227
Validation loss: 2.123834182818731

Epoch: 5| Step: 11
Training loss: 1.9791760444641113
Validation loss: 2.116991236805916

Epoch: 292| Step: 0
Training loss: 2.647055149078369
Validation loss: 2.13907856742541

Epoch: 5| Step: 1
Training loss: 2.1113977432250977
Validation loss: 2.138902336359024

Epoch: 5| Step: 2
Training loss: 1.0764976739883423
Validation loss: 2.115265041589737

Epoch: 5| Step: 3
Training loss: 1.5469890832901
Validation loss: 2.119512528181076

Epoch: 5| Step: 4
Training loss: 1.4494478702545166
Validation loss: 2.141888603568077

Epoch: 5| Step: 5
Training loss: 1.2960598468780518
Validation loss: 2.133369187513987

Epoch: 5| Step: 6
Training loss: 1.252457618713379
Validation loss: 2.181802993019422

Epoch: 5| Step: 7
Training loss: 1.5925118923187256
Validation loss: 2.1352445632219315

Epoch: 5| Step: 8
Training loss: 1.7700223922729492
Validation loss: 2.1567599177360535

Epoch: 5| Step: 9
Training loss: 2.529196262359619
Validation loss: 2.192444016536077

Epoch: 5| Step: 10
Training loss: 1.484933614730835
Validation loss: 2.205368012189865

Epoch: 5| Step: 11
Training loss: 2.9690394401550293
Validation loss: 2.1913138926029205

Epoch: 293| Step: 0
Training loss: 1.6846656799316406
Validation loss: 2.2009978791077933

Epoch: 5| Step: 1
Training loss: 1.5935499668121338
Validation loss: 2.192273830374082

Epoch: 5| Step: 2
Training loss: 1.6674678325653076
Validation loss: 2.1947367191314697

Epoch: 5| Step: 3
Training loss: 2.018735408782959
Validation loss: 2.2072044909000397

Epoch: 5| Step: 4
Training loss: 2.0972580909729004
Validation loss: 2.172804127136866

Epoch: 5| Step: 5
Training loss: 1.6170470714569092
Validation loss: 2.181611423691114

Epoch: 5| Step: 6
Training loss: 1.5982227325439453
Validation loss: 2.1345245043436685

Epoch: 5| Step: 7
Training loss: 1.4767231941223145
Validation loss: 2.1545306146144867

Epoch: 5| Step: 8
Training loss: 2.1060290336608887
Validation loss: 2.1478071808815002

Epoch: 5| Step: 9
Training loss: 1.5052587985992432
Validation loss: 2.109140838185946

Epoch: 5| Step: 10
Training loss: 1.4037705659866333
Validation loss: 2.1337328255176544

Epoch: 5| Step: 11
Training loss: 2.4643564224243164
Validation loss: 2.1250037203232446

Epoch: 294| Step: 0
Training loss: 1.9152472019195557
Validation loss: 2.1252215107282004

Epoch: 5| Step: 1
Training loss: 1.8916654586791992
Validation loss: 2.140480473637581

Epoch: 5| Step: 2
Training loss: 1.607964277267456
Validation loss: 2.140337492028872

Epoch: 5| Step: 3
Training loss: 1.6440540552139282
Validation loss: 2.179759606719017

Epoch: 5| Step: 4
Training loss: 1.4076354503631592
Validation loss: 2.165317287047704

Epoch: 5| Step: 5
Training loss: 1.7263412475585938
Validation loss: 2.1689076920350394

Epoch: 5| Step: 6
Training loss: 1.2772871255874634
Validation loss: 2.1714393198490143

Epoch: 5| Step: 7
Training loss: 1.286387324333191
Validation loss: 2.178337504466375

Epoch: 5| Step: 8
Training loss: 1.632089376449585
Validation loss: 2.184515635172526

Epoch: 5| Step: 9
Training loss: 1.2922303676605225
Validation loss: 2.1957567632198334

Epoch: 5| Step: 10
Training loss: 2.0753495693206787
Validation loss: 2.147454539934794

Epoch: 5| Step: 11
Training loss: 3.3391547203063965
Validation loss: 2.134557694196701

Epoch: 295| Step: 0
Training loss: 3.0198042392730713
Validation loss: 2.161951790253321

Epoch: 5| Step: 1
Training loss: 0.9891341924667358
Validation loss: 2.1563433756430945

Epoch: 5| Step: 2
Training loss: 1.5224182605743408
Validation loss: 2.1632604400316873

Epoch: 5| Step: 3
Training loss: 1.5935957431793213
Validation loss: 2.1560979088147483

Epoch: 5| Step: 4
Training loss: 2.629284381866455
Validation loss: 2.1605371634165444

Epoch: 5| Step: 5
Training loss: 1.4785850048065186
Validation loss: 2.2215412060419717

Epoch: 5| Step: 6
Training loss: 1.547269582748413
Validation loss: 2.1677184651295343

Epoch: 5| Step: 7
Training loss: 1.0479635000228882
Validation loss: 2.178352559606234

Epoch: 5| Step: 8
Training loss: 1.4965028762817383
Validation loss: 2.208228126168251

Epoch: 5| Step: 9
Training loss: 1.2258070707321167
Validation loss: 2.180291031797727

Epoch: 5| Step: 10
Training loss: 1.8539756536483765
Validation loss: 2.2042481899261475

Epoch: 5| Step: 11
Training loss: 1.7319488525390625
Validation loss: 2.2135194142659507

Epoch: 296| Step: 0
Training loss: 2.0924577713012695
Validation loss: 2.169128214319547

Epoch: 5| Step: 1
Training loss: 1.546761155128479
Validation loss: 2.1657937318086624

Epoch: 5| Step: 2
Training loss: 1.6602840423583984
Validation loss: 2.157515232761701

Epoch: 5| Step: 3
Training loss: 1.6984459161758423
Validation loss: 2.1629513700803122

Epoch: 5| Step: 4
Training loss: 2.591825246810913
Validation loss: 2.1536693473656974

Epoch: 5| Step: 5
Training loss: 1.5401203632354736
Validation loss: 2.164515351255735

Epoch: 5| Step: 6
Training loss: 2.004376173019409
Validation loss: 2.1569943676392236

Epoch: 5| Step: 7
Training loss: 1.4016199111938477
Validation loss: 2.1540494859218597

Epoch: 5| Step: 8
Training loss: 1.1735225915908813
Validation loss: 2.194800610343615

Epoch: 5| Step: 9
Training loss: 1.4743961095809937
Validation loss: 2.15301913022995

Epoch: 5| Step: 10
Training loss: 1.3154208660125732
Validation loss: 2.165723577141762

Epoch: 5| Step: 11
Training loss: 0.8060125112533569
Validation loss: 2.1860879560311637

Epoch: 297| Step: 0
Training loss: 1.9286835193634033
Validation loss: 2.2079774538675943

Epoch: 5| Step: 1
Training loss: 1.0164363384246826
Validation loss: 2.1820925573507943

Epoch: 5| Step: 2
Training loss: 1.8353554010391235
Validation loss: 2.193206707636515

Epoch: 5| Step: 3
Training loss: 2.0043182373046875
Validation loss: 2.2257262965043387

Epoch: 5| Step: 4
Training loss: 1.395139455795288
Validation loss: 2.177421599626541

Epoch: 5| Step: 5
Training loss: 1.5137965679168701
Validation loss: 2.191671535372734

Epoch: 5| Step: 6
Training loss: 1.3833461999893188
Validation loss: 2.1903493106365204

Epoch: 5| Step: 7
Training loss: 1.7371208667755127
Validation loss: 2.2069934755563736

Epoch: 5| Step: 8
Training loss: 1.7035391330718994
Validation loss: 2.20823572576046

Epoch: 5| Step: 9
Training loss: 2.0250792503356934
Validation loss: 2.187854399283727

Epoch: 5| Step: 10
Training loss: 1.2862350940704346
Validation loss: 2.1925705671310425

Epoch: 5| Step: 11
Training loss: 2.4593329429626465
Validation loss: 2.1699459304412207

Epoch: 298| Step: 0
Training loss: 1.7556709051132202
Validation loss: 2.1826472729444504

Epoch: 5| Step: 1
Training loss: 2.3172178268432617
Validation loss: 2.1594017446041107

Epoch: 5| Step: 2
Training loss: 1.2930958271026611
Validation loss: 2.1878213435411453

Epoch: 5| Step: 3
Training loss: 1.3931437730789185
Validation loss: 2.1670788129170737

Epoch: 5| Step: 4
Training loss: 1.127854585647583
Validation loss: 2.1653996954361596

Epoch: 5| Step: 5
Training loss: 1.271470069885254
Validation loss: 2.1734347492456436

Epoch: 5| Step: 6
Training loss: 1.3936856985092163
Validation loss: 2.1995649139086404

Epoch: 5| Step: 7
Training loss: 1.8698084354400635
Validation loss: 2.158149868249893

Epoch: 5| Step: 8
Training loss: 1.7083899974822998
Validation loss: 2.1537260661522546

Epoch: 5| Step: 9
Training loss: 1.3912343978881836
Validation loss: 2.1625383446613946

Epoch: 5| Step: 10
Training loss: 2.166715383529663
Validation loss: 2.1677519232034683

Epoch: 5| Step: 11
Training loss: 1.7363461256027222
Validation loss: 2.1540300101041794

Epoch: 299| Step: 0
Training loss: 1.8791831731796265
Validation loss: 2.2034367819627128

Epoch: 5| Step: 1
Training loss: 1.6661045551300049
Validation loss: 2.1619467039903006

Epoch: 5| Step: 2
Training loss: 1.9775062799453735
Validation loss: 2.1559887131055198

Epoch: 5| Step: 3
Training loss: 1.4362547397613525
Validation loss: 2.2004915177822113

Epoch: 5| Step: 4
Training loss: 0.8637441396713257
Validation loss: 2.1869912346204123

Epoch: 5| Step: 5
Training loss: 1.8138929605484009
Validation loss: 2.2214163641134896

Epoch: 5| Step: 6
Training loss: 2.141732931137085
Validation loss: 2.1943179766337075

Epoch: 5| Step: 7
Training loss: 1.436669111251831
Validation loss: 2.158112848798434

Epoch: 5| Step: 8
Training loss: 1.4479650259017944
Validation loss: 2.1664161731799445

Epoch: 5| Step: 9
Training loss: 0.975692629814148
Validation loss: 2.1637660562992096

Epoch: 5| Step: 10
Training loss: 1.4256106615066528
Validation loss: 2.157652825117111

Epoch: 5| Step: 11
Training loss: 5.068359851837158
Validation loss: 2.1649969468514123

Epoch: 300| Step: 0
Training loss: 1.286010980606079
Validation loss: 2.166207899649938

Epoch: 5| Step: 1
Training loss: 1.772759199142456
Validation loss: 2.1969405313332877

Epoch: 5| Step: 2
Training loss: 1.6048986911773682
Validation loss: 2.1864442427953086

Epoch: 5| Step: 3
Training loss: 1.3516467809677124
Validation loss: 2.1770157516002655

Epoch: 5| Step: 4
Training loss: 1.9433262348175049
Validation loss: 2.188155233860016

Epoch: 5| Step: 5
Training loss: 1.7469364404678345
Validation loss: 2.1951931913693747

Epoch: 5| Step: 6
Training loss: 1.5086376667022705
Validation loss: 2.15485247472922

Epoch: 5| Step: 7
Training loss: 1.5605056285858154
Validation loss: 2.1786339481671653

Epoch: 5| Step: 8
Training loss: 1.4599522352218628
Validation loss: 2.1372331778208413

Epoch: 5| Step: 9
Training loss: 1.520817518234253
Validation loss: 2.1638917873303094

Epoch: 5| Step: 10
Training loss: 2.390444278717041
Validation loss: 2.1275144517421722

Epoch: 5| Step: 11
Training loss: 1.619116187095642
Validation loss: 2.158255269130071

Epoch: 301| Step: 0
Training loss: 1.4379503726959229
Validation loss: 2.182277182737986

Epoch: 5| Step: 1
Training loss: 1.6734545230865479
Validation loss: 2.2428524444500604

Epoch: 5| Step: 2
Training loss: 1.197077751159668
Validation loss: 2.192721650004387

Epoch: 5| Step: 3
Training loss: 1.969312071800232
Validation loss: 2.216953918337822

Epoch: 5| Step: 4
Training loss: 1.5097525119781494
Validation loss: 2.2212938368320465

Epoch: 5| Step: 5
Training loss: 1.8115812540054321
Validation loss: 2.232400765021642

Epoch: 5| Step: 6
Training loss: 1.8477119207382202
Validation loss: 2.202175815900167

Epoch: 5| Step: 7
Training loss: 1.5999631881713867
Validation loss: 2.222832436362902

Epoch: 5| Step: 8
Training loss: 2.1510567665100098
Validation loss: 2.193197642763456

Epoch: 5| Step: 9
Training loss: 1.5554563999176025
Validation loss: 2.1693259278933206

Epoch: 5| Step: 10
Training loss: 1.5415040254592896
Validation loss: 2.172273506720861

Epoch: 5| Step: 11
Training loss: 0.7057663798332214
Validation loss: 2.1433825194835663

Epoch: 302| Step: 0
Training loss: 2.212803363800049
Validation loss: 2.1684322158495584

Epoch: 5| Step: 1
Training loss: 1.2280070781707764
Validation loss: 2.138679256041845

Epoch: 5| Step: 2
Training loss: 1.933240294456482
Validation loss: 2.187017252047857

Epoch: 5| Step: 3
Training loss: 1.4789496660232544
Validation loss: 2.203886484106382

Epoch: 5| Step: 4
Training loss: 1.4509118795394897
Validation loss: 2.2575629552205405

Epoch: 5| Step: 5
Training loss: 1.5587867498397827
Validation loss: 2.2204400350650153

Epoch: 5| Step: 6
Training loss: 1.2187970876693726
Validation loss: 2.261378228664398

Epoch: 5| Step: 7
Training loss: 1.8627322912216187
Validation loss: 2.2144708236058555

Epoch: 5| Step: 8
Training loss: 1.6180477142333984
Validation loss: 2.1959992994864783

Epoch: 5| Step: 9
Training loss: 1.8057289123535156
Validation loss: 2.174574131766955

Epoch: 5| Step: 10
Training loss: 1.3451884984970093
Validation loss: 2.20043853422006

Epoch: 5| Step: 11
Training loss: 1.7602999210357666
Validation loss: 2.1700392365455627

Epoch: 303| Step: 0
Training loss: 1.881278395652771
Validation loss: 2.1721304257710776

Epoch: 5| Step: 1
Training loss: 1.9702268838882446
Validation loss: 2.1889969259500504

Epoch: 5| Step: 2
Training loss: 1.6071453094482422
Validation loss: 2.224738667408625

Epoch: 5| Step: 3
Training loss: 1.8333580493927002
Validation loss: 2.2064348657925925

Epoch: 5| Step: 4
Training loss: 1.550100564956665
Validation loss: 2.223894586165746

Epoch: 5| Step: 5
Training loss: 1.4974740743637085
Validation loss: 2.2100168665250144

Epoch: 5| Step: 6
Training loss: 1.0399020910263062
Validation loss: 2.2117859621842704

Epoch: 5| Step: 7
Training loss: 1.2752399444580078
Validation loss: 2.1988312005996704

Epoch: 5| Step: 8
Training loss: 1.6584171056747437
Validation loss: 2.18567086259524

Epoch: 5| Step: 9
Training loss: 1.6078357696533203
Validation loss: 2.1629188557465873

Epoch: 5| Step: 10
Training loss: 1.8174355030059814
Validation loss: 2.1810173789660134

Epoch: 5| Step: 11
Training loss: 1.1271297931671143
Validation loss: 2.165025979280472

Epoch: 304| Step: 0
Training loss: 1.5131161212921143
Validation loss: 2.1772257685661316

Epoch: 5| Step: 1
Training loss: 1.2683422565460205
Validation loss: 2.2106593350569406

Epoch: 5| Step: 2
Training loss: 2.021181106567383
Validation loss: 2.1619137078523636

Epoch: 5| Step: 3
Training loss: 1.6864430904388428
Validation loss: 2.1769866943359375

Epoch: 5| Step: 4
Training loss: 1.8722622394561768
Validation loss: 2.20893062154452

Epoch: 5| Step: 5
Training loss: 1.7440513372421265
Validation loss: 2.1846961230039597

Epoch: 5| Step: 6
Training loss: 1.6830909252166748
Validation loss: 2.1424703299999237

Epoch: 5| Step: 7
Training loss: 1.6737992763519287
Validation loss: 2.1643157253662744

Epoch: 5| Step: 8
Training loss: 1.4498099088668823
Validation loss: 2.175362154841423

Epoch: 5| Step: 9
Training loss: 2.0225400924682617
Validation loss: 2.179755295316378

Epoch: 5| Step: 10
Training loss: 1.3372082710266113
Validation loss: 2.208675970633825

Epoch: 5| Step: 11
Training loss: 0.519416868686676
Validation loss: 2.2214818000793457

Epoch: 305| Step: 0
Training loss: 1.434945821762085
Validation loss: 2.1982901642719903

Epoch: 5| Step: 1
Training loss: 1.3731218576431274
Validation loss: 2.2270968755086265

Epoch: 5| Step: 2
Training loss: 1.1052567958831787
Validation loss: 2.2483073075612388

Epoch: 5| Step: 3
Training loss: 2.0459542274475098
Validation loss: 2.2438874542713165

Epoch: 5| Step: 4
Training loss: 2.1844356060028076
Validation loss: 2.2061637292305627

Epoch: 5| Step: 5
Training loss: 1.6573045253753662
Validation loss: 2.1869121889273324

Epoch: 5| Step: 6
Training loss: 1.0638744831085205
Validation loss: 2.164193034172058

Epoch: 5| Step: 7
Training loss: 1.290979266166687
Validation loss: 2.1452270646890006

Epoch: 5| Step: 8
Training loss: 1.3403478860855103
Validation loss: 2.1487879902124405

Epoch: 5| Step: 9
Training loss: 2.1158804893493652
Validation loss: 2.1711578369140625

Epoch: 5| Step: 10
Training loss: 2.493476629257202
Validation loss: 2.181681031982104

Epoch: 5| Step: 11
Training loss: 0.698766827583313
Validation loss: 2.173421541849772

Epoch: 306| Step: 0
Training loss: 1.8397939205169678
Validation loss: 2.1982044080893197

Epoch: 5| Step: 1
Training loss: 1.9525649547576904
Validation loss: 2.2481853316227594

Epoch: 5| Step: 2
Training loss: 1.0651997327804565
Validation loss: 2.2649029890696206

Epoch: 5| Step: 3
Training loss: 1.8761173486709595
Validation loss: 2.280656029780706

Epoch: 5| Step: 4
Training loss: 1.5515501499176025
Validation loss: 2.25588928659757

Epoch: 5| Step: 5
Training loss: 1.7608836889266968
Validation loss: 2.2928377588589988

Epoch: 5| Step: 6
Training loss: 1.6748384237289429
Validation loss: 2.227251340945562

Epoch: 5| Step: 7
Training loss: 1.7506892681121826
Validation loss: 2.193559984366099

Epoch: 5| Step: 8
Training loss: 1.7095906734466553
Validation loss: 2.1798106332619986

Epoch: 5| Step: 9
Training loss: 2.064100980758667
Validation loss: 2.1688730120658875

Epoch: 5| Step: 10
Training loss: 1.35336434841156
Validation loss: 2.1419450690348945

Epoch: 5| Step: 11
Training loss: 1.3998548984527588
Validation loss: 2.165959154566129

Epoch: 307| Step: 0
Training loss: 1.512548804283142
Validation loss: 2.169994076093038

Epoch: 5| Step: 1
Training loss: 1.7636499404907227
Validation loss: 2.150780960917473

Epoch: 5| Step: 2
Training loss: 1.4864747524261475
Validation loss: 2.1449204981327057

Epoch: 5| Step: 3
Training loss: 1.9282013177871704
Validation loss: 2.1611789613962173

Epoch: 5| Step: 4
Training loss: 1.8104419708251953
Validation loss: 2.164782404899597

Epoch: 5| Step: 5
Training loss: 2.0166943073272705
Validation loss: 2.2339055041472116

Epoch: 5| Step: 6
Training loss: 1.4921438694000244
Validation loss: 2.22667795419693

Epoch: 5| Step: 7
Training loss: 1.6610969305038452
Validation loss: 2.211093381047249

Epoch: 5| Step: 8
Training loss: 1.4178141355514526
Validation loss: 2.2727820773919425

Epoch: 5| Step: 9
Training loss: 0.9948789477348328
Validation loss: 2.2249976893266044

Epoch: 5| Step: 10
Training loss: 1.8713451623916626
Validation loss: 2.21356800198555

Epoch: 5| Step: 11
Training loss: 1.7936177253723145
Validation loss: 2.1999869545300803

Epoch: 308| Step: 0
Training loss: 1.5993127822875977
Validation loss: 2.1571704894304276

Epoch: 5| Step: 1
Training loss: 1.781839370727539
Validation loss: 2.149904410044352

Epoch: 5| Step: 2
Training loss: 1.6635078191757202
Validation loss: 2.1582767417033515

Epoch: 5| Step: 3
Training loss: 1.5899033546447754
Validation loss: 2.1678769985834756

Epoch: 5| Step: 4
Training loss: 2.45603609085083
Validation loss: 2.1728700747092566

Epoch: 5| Step: 5
Training loss: 2.1174728870391846
Validation loss: 2.1692481438318887

Epoch: 5| Step: 6
Training loss: 1.7607886791229248
Validation loss: 2.1900991102059684

Epoch: 5| Step: 7
Training loss: 2.155117988586426
Validation loss: 2.167465547720591

Epoch: 5| Step: 8
Training loss: 1.7413804531097412
Validation loss: 2.1751746336619058

Epoch: 5| Step: 9
Training loss: 0.9278454780578613
Validation loss: 2.1546324690183005

Epoch: 5| Step: 10
Training loss: 1.1141207218170166
Validation loss: 2.1745642324288688

Epoch: 5| Step: 11
Training loss: 1.1268824338912964
Validation loss: 2.1842990716298423

Epoch: 309| Step: 0
Training loss: 1.507576584815979
Validation loss: 2.2312288184960685

Epoch: 5| Step: 1
Training loss: 1.71243417263031
Validation loss: 2.2566722631454468

Epoch: 5| Step: 2
Training loss: 1.9555351734161377
Validation loss: 2.260417660077413

Epoch: 5| Step: 3
Training loss: 1.5294727087020874
Validation loss: 2.2836251854896545

Epoch: 5| Step: 4
Training loss: 1.4684005975723267
Validation loss: 2.276382048924764

Epoch: 5| Step: 5
Training loss: 1.4586138725280762
Validation loss: 2.2533316810925803

Epoch: 5| Step: 6
Training loss: 1.428215503692627
Validation loss: 2.205933521191279

Epoch: 5| Step: 7
Training loss: 1.8405754566192627
Validation loss: 2.1904359559218087

Epoch: 5| Step: 8
Training loss: 1.9189586639404297
Validation loss: 2.189538632829984

Epoch: 5| Step: 9
Training loss: 2.109579086303711
Validation loss: 2.1620141764481864

Epoch: 5| Step: 10
Training loss: 1.44541335105896
Validation loss: 2.18878964583079

Epoch: 5| Step: 11
Training loss: 1.1354494094848633
Validation loss: 2.1853672564029694

Epoch: 310| Step: 0
Training loss: 1.8364909887313843
Validation loss: 2.209185461203257

Epoch: 5| Step: 1
Training loss: 1.4786560535430908
Validation loss: 2.2150105088949203

Epoch: 5| Step: 2
Training loss: 1.4497168064117432
Validation loss: 2.1793834815422692

Epoch: 5| Step: 3
Training loss: 1.6077104806900024
Validation loss: 2.1907055974006653

Epoch: 5| Step: 4
Training loss: 1.3365825414657593
Validation loss: 2.1953247686227164

Epoch: 5| Step: 5
Training loss: 2.138563632965088
Validation loss: 2.2065592259168625

Epoch: 5| Step: 6
Training loss: 1.6463435888290405
Validation loss: 2.2229826351006827

Epoch: 5| Step: 7
Training loss: 1.6762077808380127
Validation loss: 2.185476223627726

Epoch: 5| Step: 8
Training loss: 1.304655909538269
Validation loss: 2.2455373307069144

Epoch: 5| Step: 9
Training loss: 1.3785921335220337
Validation loss: 2.2207356890042624

Epoch: 5| Step: 10
Training loss: 1.7377650737762451
Validation loss: 2.2074321508407593

Epoch: 5| Step: 11
Training loss: 0.6047106385231018
Validation loss: 2.2227070728937783

Epoch: 311| Step: 0
Training loss: 1.3560606241226196
Validation loss: 2.2060424784819284

Epoch: 5| Step: 1
Training loss: 1.4638187885284424
Validation loss: 2.18875482181708

Epoch: 5| Step: 2
Training loss: 1.5722424983978271
Validation loss: 2.1840886175632477

Epoch: 5| Step: 3
Training loss: 1.1467945575714111
Validation loss: 2.2096131245295205

Epoch: 5| Step: 4
Training loss: 1.8538970947265625
Validation loss: 2.1839334021011987

Epoch: 5| Step: 5
Training loss: 1.7197964191436768
Validation loss: 2.1645777920881906

Epoch: 5| Step: 6
Training loss: 1.7081890106201172
Validation loss: 2.215010051925977

Epoch: 5| Step: 7
Training loss: 1.8378181457519531
Validation loss: 2.1860115776459375

Epoch: 5| Step: 8
Training loss: 1.9370701313018799
Validation loss: 2.1860361943642297

Epoch: 5| Step: 9
Training loss: 1.2960084676742554
Validation loss: 2.229865978161494

Epoch: 5| Step: 10
Training loss: 1.177367925643921
Validation loss: 2.239182631174723

Epoch: 5| Step: 11
Training loss: 2.632596731185913
Validation loss: 2.221951425075531

Epoch: 312| Step: 0
Training loss: 1.3684052228927612
Validation loss: 2.229195053378741

Epoch: 5| Step: 1
Training loss: 1.198088526725769
Validation loss: 2.2014479686816535

Epoch: 5| Step: 2
Training loss: 2.01704478263855
Validation loss: 2.223999867836634

Epoch: 5| Step: 3
Training loss: 1.0664236545562744
Validation loss: 2.230945274233818

Epoch: 5| Step: 4
Training loss: 2.1497397422790527
Validation loss: 2.2373753786087036

Epoch: 5| Step: 5
Training loss: 1.5218178033828735
Validation loss: 2.2209199766318

Epoch: 5| Step: 6
Training loss: 1.5595839023590088
Validation loss: 2.202952732642492

Epoch: 5| Step: 7
Training loss: 1.6277364492416382
Validation loss: 2.2230928440888724

Epoch: 5| Step: 8
Training loss: 1.8361690044403076
Validation loss: 2.2082900206247964

Epoch: 5| Step: 9
Training loss: 1.5570881366729736
Validation loss: 2.1921759446461997

Epoch: 5| Step: 10
Training loss: 1.0531079769134521
Validation loss: 2.188752442598343

Epoch: 5| Step: 11
Training loss: 2.2034008502960205
Validation loss: 2.1903208593527475

Epoch: 313| Step: 0
Training loss: 1.305738091468811
Validation loss: 2.199795206387838

Epoch: 5| Step: 1
Training loss: 2.010612964630127
Validation loss: 2.2405429830153785

Epoch: 5| Step: 2
Training loss: 2.2747275829315186
Validation loss: 2.223804146051407

Epoch: 5| Step: 3
Training loss: 1.3169481754302979
Validation loss: 2.2336168388525643

Epoch: 5| Step: 4
Training loss: 1.380484700202942
Validation loss: 2.213626300295194

Epoch: 5| Step: 5
Training loss: 1.7921558618545532
Validation loss: 2.2548163731892905

Epoch: 5| Step: 6
Training loss: 0.9352202415466309
Validation loss: 2.215484062830607

Epoch: 5| Step: 7
Training loss: 1.7731237411499023
Validation loss: 2.2381763060887656

Epoch: 5| Step: 8
Training loss: 1.869398832321167
Validation loss: 2.1679224967956543

Epoch: 5| Step: 9
Training loss: 1.4733104705810547
Validation loss: 2.1702590386072793

Epoch: 5| Step: 10
Training loss: 0.907817006111145
Validation loss: 2.18070180217425

Epoch: 5| Step: 11
Training loss: 1.8816555738449097
Validation loss: 2.156061604619026

Epoch: 314| Step: 0
Training loss: 1.7273931503295898
Validation loss: 2.1698754727840424

Epoch: 5| Step: 1
Training loss: 1.0559899806976318
Validation loss: 2.2214953104654946

Epoch: 5| Step: 2
Training loss: 1.2686686515808105
Validation loss: 2.241431141893069

Epoch: 5| Step: 3
Training loss: 1.6210464239120483
Validation loss: 2.243239015340805

Epoch: 5| Step: 4
Training loss: 1.932999849319458
Validation loss: 2.246512323617935

Epoch: 5| Step: 5
Training loss: 1.6123472452163696
Validation loss: 2.273935928940773

Epoch: 5| Step: 6
Training loss: 1.5850061178207397
Validation loss: 2.3000798722108207

Epoch: 5| Step: 7
Training loss: 1.8426151275634766
Validation loss: 2.275924190878868

Epoch: 5| Step: 8
Training loss: 1.2199896574020386
Validation loss: 2.248665695389112

Epoch: 5| Step: 9
Training loss: 1.3906924724578857
Validation loss: 2.213217114408811

Epoch: 5| Step: 10
Training loss: 2.195075511932373
Validation loss: 2.197562351822853

Epoch: 5| Step: 11
Training loss: 0.5068624019622803
Validation loss: 2.1741908689339957

Epoch: 315| Step: 0
Training loss: 1.6987184286117554
Validation loss: 2.182681456208229

Epoch: 5| Step: 1
Training loss: 1.8118946552276611
Validation loss: 2.1896858563025794

Epoch: 5| Step: 2
Training loss: 1.9320026636123657
Validation loss: 2.1493419806162515

Epoch: 5| Step: 3
Training loss: 1.4655380249023438
Validation loss: 2.1856018950541816

Epoch: 5| Step: 4
Training loss: 1.5611579418182373
Validation loss: 2.1868205467859902

Epoch: 5| Step: 5
Training loss: 0.9350342750549316
Validation loss: 2.2188915510972342

Epoch: 5| Step: 6
Training loss: 1.4985015392303467
Validation loss: 2.175404414534569

Epoch: 5| Step: 7
Training loss: 1.3146241903305054
Validation loss: 2.207993119955063

Epoch: 5| Step: 8
Training loss: 2.160510540008545
Validation loss: 2.2137511869271598

Epoch: 5| Step: 9
Training loss: 1.4989888668060303
Validation loss: 2.2005292971928916

Epoch: 5| Step: 10
Training loss: 1.0141119956970215
Validation loss: 2.183852881193161

Epoch: 5| Step: 11
Training loss: 2.226203441619873
Validation loss: 2.2327675223350525

Epoch: 316| Step: 0
Training loss: 1.4758715629577637
Validation loss: 2.171090245246887

Epoch: 5| Step: 1
Training loss: 1.8947207927703857
Validation loss: 2.1774632136027017

Epoch: 5| Step: 2
Training loss: 1.762296438217163
Validation loss: 2.1698715587457023

Epoch: 5| Step: 3
Training loss: 1.309546709060669
Validation loss: 2.1635697285334268

Epoch: 5| Step: 4
Training loss: 1.4277637004852295
Validation loss: 2.16752361257871

Epoch: 5| Step: 5
Training loss: 1.6556603908538818
Validation loss: 2.1921829183896384

Epoch: 5| Step: 6
Training loss: 1.4503854513168335
Validation loss: 2.1678716590007148

Epoch: 5| Step: 7
Training loss: 1.5674442052841187
Validation loss: 2.2087695747613907

Epoch: 5| Step: 8
Training loss: 1.5570785999298096
Validation loss: 2.1948294838269553

Epoch: 5| Step: 9
Training loss: 1.643284559249878
Validation loss: 2.201808656255404

Epoch: 5| Step: 10
Training loss: 1.7024364471435547
Validation loss: 2.196587637066841

Epoch: 5| Step: 11
Training loss: 0.8416640758514404
Validation loss: 2.197011520465215

Epoch: 317| Step: 0
Training loss: 1.4251670837402344
Validation loss: 2.189305365085602

Epoch: 5| Step: 1
Training loss: 2.507352113723755
Validation loss: 2.179061939318975

Epoch: 5| Step: 2
Training loss: 1.941205382347107
Validation loss: 2.1720702846844993

Epoch: 5| Step: 3
Training loss: 1.5562225580215454
Validation loss: 2.17328534523646

Epoch: 5| Step: 4
Training loss: 1.1566832065582275
Validation loss: 2.130994771917661

Epoch: 5| Step: 5
Training loss: 1.3606493473052979
Validation loss: 2.1612358341614404

Epoch: 5| Step: 6
Training loss: 1.2034238576889038
Validation loss: 2.167218724886576

Epoch: 5| Step: 7
Training loss: 1.5232017040252686
Validation loss: 2.1870731761058173

Epoch: 5| Step: 8
Training loss: 1.6216373443603516
Validation loss: 2.186726287007332

Epoch: 5| Step: 9
Training loss: 1.4584863185882568
Validation loss: 2.166269967953364

Epoch: 5| Step: 10
Training loss: 1.891736388206482
Validation loss: 2.1521370261907578

Epoch: 5| Step: 11
Training loss: 1.8321866989135742
Validation loss: 2.1586096237103143

Epoch: 318| Step: 0
Training loss: 1.0711690187454224
Validation loss: 2.1529763440291085

Epoch: 5| Step: 1
Training loss: 1.9055020809173584
Validation loss: 2.1979976991812387

Epoch: 5| Step: 2
Training loss: 1.3603770732879639
Validation loss: 2.2142502665519714

Epoch: 5| Step: 3
Training loss: 1.5155247449874878
Validation loss: 2.2113532225290933

Epoch: 5| Step: 4
Training loss: 1.228771448135376
Validation loss: 2.2421864370505014

Epoch: 5| Step: 5
Training loss: 1.6255156993865967
Validation loss: 2.2396531999111176

Epoch: 5| Step: 6
Training loss: 1.5763378143310547
Validation loss: 2.2288122475147247

Epoch: 5| Step: 7
Training loss: 1.514878749847412
Validation loss: 2.1734439929326377

Epoch: 5| Step: 8
Training loss: 2.0281083583831787
Validation loss: 2.1565895875295005

Epoch: 5| Step: 9
Training loss: 1.5292987823486328
Validation loss: 2.1792149345080056

Epoch: 5| Step: 10
Training loss: 1.4346815347671509
Validation loss: 2.1346296072006226

Epoch: 5| Step: 11
Training loss: 0.9837116003036499
Validation loss: 2.180950254201889

Epoch: 319| Step: 0
Training loss: 1.3306022882461548
Validation loss: 2.1343303124109902

Epoch: 5| Step: 1
Training loss: 1.9379104375839233
Validation loss: 2.1275988618532815

Epoch: 5| Step: 2
Training loss: 1.4710819721221924
Validation loss: 2.143455063303312

Epoch: 5| Step: 3
Training loss: 1.8191344738006592
Validation loss: 2.180942495663961

Epoch: 5| Step: 4
Training loss: 1.112891435623169
Validation loss: 2.1695580383141837

Epoch: 5| Step: 5
Training loss: 1.3592783212661743
Validation loss: 2.1314296424388885

Epoch: 5| Step: 6
Training loss: 1.2512571811676025
Validation loss: 2.1209586759408317

Epoch: 5| Step: 7
Training loss: 2.1391477584838867
Validation loss: 2.1761619647343955

Epoch: 5| Step: 8
Training loss: 1.426780343055725
Validation loss: 2.1894433200359344

Epoch: 5| Step: 9
Training loss: 1.2781776189804077
Validation loss: 2.2084646423657737

Epoch: 5| Step: 10
Training loss: 1.5808804035186768
Validation loss: 2.166050970554352

Epoch: 5| Step: 11
Training loss: 1.7393323183059692
Validation loss: 2.1593931366999946

Epoch: 320| Step: 0
Training loss: 1.4059994220733643
Validation loss: 2.1658126215140023

Epoch: 5| Step: 1
Training loss: 0.7700543999671936
Validation loss: 2.120155170559883

Epoch: 5| Step: 2
Training loss: 1.9337947368621826
Validation loss: 2.147167737285296

Epoch: 5| Step: 3
Training loss: 0.9690464735031128
Validation loss: 2.200882946451505

Epoch: 5| Step: 4
Training loss: 1.3252894878387451
Validation loss: 2.165011758605639

Epoch: 5| Step: 5
Training loss: 1.9073079824447632
Validation loss: 2.209204470117887

Epoch: 5| Step: 6
Training loss: 1.8637895584106445
Validation loss: 2.2093375623226166

Epoch: 5| Step: 7
Training loss: 1.5319277048110962
Validation loss: 2.2385107229153314

Epoch: 5| Step: 8
Training loss: 1.5644521713256836
Validation loss: 2.169480954607328

Epoch: 5| Step: 9
Training loss: 1.5458048582077026
Validation loss: 2.166216457883517

Epoch: 5| Step: 10
Training loss: 2.09014630317688
Validation loss: 2.198810706535975

Epoch: 5| Step: 11
Training loss: 0.7485363483428955
Validation loss: 2.1949283281962075

Epoch: 321| Step: 0
Training loss: 1.7987420558929443
Validation loss: 2.1750665456056595

Epoch: 5| Step: 1
Training loss: 2.3204169273376465
Validation loss: 2.1818259159723916

Epoch: 5| Step: 2
Training loss: 0.6388480067253113
Validation loss: 2.1782815158367157

Epoch: 5| Step: 3
Training loss: 2.1737523078918457
Validation loss: 2.1694141924381256

Epoch: 5| Step: 4
Training loss: 1.392245888710022
Validation loss: 2.186683624982834

Epoch: 5| Step: 5
Training loss: 1.4170587062835693
Validation loss: 2.179774304231008

Epoch: 5| Step: 6
Training loss: 1.2505391836166382
Validation loss: 2.176378528277079

Epoch: 5| Step: 7
Training loss: 1.0815218687057495
Validation loss: 2.1673689633607864

Epoch: 5| Step: 8
Training loss: 1.4834314584732056
Validation loss: 2.1619739085435867

Epoch: 5| Step: 9
Training loss: 1.4592993259429932
Validation loss: 2.184146081407865

Epoch: 5| Step: 10
Training loss: 1.7413389682769775
Validation loss: 2.194448550542196

Epoch: 5| Step: 11
Training loss: 2.206800699234009
Validation loss: 2.2393563638130822

Epoch: 322| Step: 0
Training loss: 1.5710326433181763
Validation loss: 2.239732936024666

Epoch: 5| Step: 1
Training loss: 1.1864629983901978
Validation loss: 2.260843262076378

Epoch: 5| Step: 2
Training loss: 1.5279344320297241
Validation loss: 2.2464106579621634

Epoch: 5| Step: 3
Training loss: 1.350682020187378
Validation loss: 2.2374828855196633

Epoch: 5| Step: 4
Training loss: 2.198824644088745
Validation loss: 2.2031025191148124

Epoch: 5| Step: 5
Training loss: 1.5163793563842773
Validation loss: 2.1697015364964805

Epoch: 5| Step: 6
Training loss: 1.5826244354248047
Validation loss: 2.200627878308296

Epoch: 5| Step: 7
Training loss: 1.3919246196746826
Validation loss: 2.1680271675189338

Epoch: 5| Step: 8
Training loss: 1.997534990310669
Validation loss: 2.1967051525910697

Epoch: 5| Step: 9
Training loss: 1.8981622457504272
Validation loss: 2.1991366893053055

Epoch: 5| Step: 10
Training loss: 1.1889605522155762
Validation loss: 2.276385098695755

Epoch: 5| Step: 11
Training loss: 1.3171541690826416
Validation loss: 2.2552243123451867

Epoch: 323| Step: 0
Training loss: 1.737300157546997
Validation loss: 2.204792136947314

Epoch: 5| Step: 1
Training loss: 1.1411254405975342
Validation loss: 2.145368834336599

Epoch: 5| Step: 2
Training loss: 1.477370262145996
Validation loss: 2.158168062567711

Epoch: 5| Step: 3
Training loss: 1.4329111576080322
Validation loss: 2.1507638742526374

Epoch: 5| Step: 4
Training loss: 1.6833600997924805
Validation loss: 2.1829136461019516

Epoch: 5| Step: 5
Training loss: 1.2359894514083862
Validation loss: 2.1576258639494577

Epoch: 5| Step: 6
Training loss: 1.879332184791565
Validation loss: 2.1892570157845817

Epoch: 5| Step: 7
Training loss: 0.6357923746109009
Validation loss: 2.18294029434522

Epoch: 5| Step: 8
Training loss: 2.1282191276550293
Validation loss: 2.2001864115397134

Epoch: 5| Step: 9
Training loss: 2.3109819889068604
Validation loss: 2.253349165121714

Epoch: 5| Step: 10
Training loss: 1.8609784841537476
Validation loss: 2.20154100159804

Epoch: 5| Step: 11
Training loss: 1.3209996223449707
Validation loss: 2.2111223389705024

Epoch: 324| Step: 0
Training loss: 1.777884840965271
Validation loss: 2.2112713356812796

Epoch: 5| Step: 1
Training loss: 1.4331468343734741
Validation loss: 2.2214803944031396

Epoch: 5| Step: 2
Training loss: 1.5295634269714355
Validation loss: 2.1658174842596054

Epoch: 5| Step: 3
Training loss: 1.3904831409454346
Validation loss: 2.1668417851130166

Epoch: 5| Step: 4
Training loss: 1.2363897562026978
Validation loss: 2.1523722807566323

Epoch: 5| Step: 5
Training loss: 2.208810567855835
Validation loss: 2.1568219463030496

Epoch: 5| Step: 6
Training loss: 1.2981820106506348
Validation loss: 2.161815802256266

Epoch: 5| Step: 7
Training loss: 1.6276016235351562
Validation loss: 2.185572455326716

Epoch: 5| Step: 8
Training loss: 1.8500118255615234
Validation loss: 2.1924714098374047

Epoch: 5| Step: 9
Training loss: 1.551949381828308
Validation loss: 2.1610422929128013

Epoch: 5| Step: 10
Training loss: 1.7494255304336548
Validation loss: 2.176620826125145

Epoch: 5| Step: 11
Training loss: 2.127861738204956
Validation loss: 2.153228302796682

Epoch: 325| Step: 0
Training loss: 1.463338851928711
Validation loss: 2.2075189848740897

Epoch: 5| Step: 1
Training loss: 1.707109808921814
Validation loss: 2.203047056992849

Epoch: 5| Step: 2
Training loss: 1.7021392583847046
Validation loss: 2.231082558631897

Epoch: 5| Step: 3
Training loss: 1.511124849319458
Validation loss: 2.2604026198387146

Epoch: 5| Step: 4
Training loss: 1.8568925857543945
Validation loss: 2.2518580158551535

Epoch: 5| Step: 5
Training loss: 1.850836157798767
Validation loss: 2.2824276636044183

Epoch: 5| Step: 6
Training loss: 1.2697713375091553
Validation loss: 2.247308522462845

Epoch: 5| Step: 7
Training loss: 1.581761121749878
Validation loss: 2.244652738173803

Epoch: 5| Step: 8
Training loss: 1.2021243572235107
Validation loss: 2.213254069288572

Epoch: 5| Step: 9
Training loss: 2.0509297847747803
Validation loss: 2.21702179312706

Epoch: 5| Step: 10
Training loss: 1.3048819303512573
Validation loss: 2.186668669184049

Epoch: 5| Step: 11
Training loss: 1.5224487781524658
Validation loss: 2.1544132928053537

Epoch: 326| Step: 0
Training loss: 1.9272350072860718
Validation loss: 2.142944802840551

Epoch: 5| Step: 1
Training loss: 1.258359670639038
Validation loss: 2.177288845181465

Epoch: 5| Step: 2
Training loss: 1.402716875076294
Validation loss: 2.1725040078163147

Epoch: 5| Step: 3
Training loss: 1.8093469142913818
Validation loss: 2.148224780956904

Epoch: 5| Step: 4
Training loss: 1.347812533378601
Validation loss: 2.2032634963591895

Epoch: 5| Step: 5
Training loss: 2.1035122871398926
Validation loss: 2.231354683637619

Epoch: 5| Step: 6
Training loss: 1.2072776556015015
Validation loss: 2.2263366281986237

Epoch: 5| Step: 7
Training loss: 2.0319294929504395
Validation loss: 2.1930982073148093

Epoch: 5| Step: 8
Training loss: 1.5431644916534424
Validation loss: 2.204746981461843

Epoch: 5| Step: 9
Training loss: 1.829031229019165
Validation loss: 2.2279273321231208

Epoch: 5| Step: 10
Training loss: 1.0132265090942383
Validation loss: 2.2112529277801514

Epoch: 5| Step: 11
Training loss: 0.7090584635734558
Validation loss: 2.2042771875858307

Epoch: 327| Step: 0
Training loss: 1.9634850025177002
Validation loss: 2.1633054415384927

Epoch: 5| Step: 1
Training loss: 1.314037561416626
Validation loss: 2.152890145778656

Epoch: 5| Step: 2
Training loss: 1.4187456369400024
Validation loss: 2.1604052086671195

Epoch: 5| Step: 3
Training loss: 1.7353757619857788
Validation loss: 2.1774701178073883

Epoch: 5| Step: 4
Training loss: 1.4865062236785889
Validation loss: 2.153007462620735

Epoch: 5| Step: 5
Training loss: 1.8866716623306274
Validation loss: 2.1451577991247177

Epoch: 5| Step: 6
Training loss: 1.1222479343414307
Validation loss: 2.1906716972589493

Epoch: 5| Step: 7
Training loss: 1.1623430252075195
Validation loss: 2.1586242665847144

Epoch: 5| Step: 8
Training loss: 2.276038408279419
Validation loss: 2.1662610669930777

Epoch: 5| Step: 9
Training loss: 1.4719088077545166
Validation loss: 2.22144578397274

Epoch: 5| Step: 10
Training loss: 1.1379482746124268
Validation loss: 2.224059055248896

Epoch: 5| Step: 11
Training loss: 2.317396402359009
Validation loss: 2.1672703623771667

Epoch: 328| Step: 0
Training loss: 1.4503766298294067
Validation loss: 2.1814084301392236

Epoch: 5| Step: 1
Training loss: 1.8354177474975586
Validation loss: 2.172544608513514

Epoch: 5| Step: 2
Training loss: 1.6581655740737915
Validation loss: 2.183034618695577

Epoch: 5| Step: 3
Training loss: 1.9396507740020752
Validation loss: 2.176310489575068

Epoch: 5| Step: 4
Training loss: 1.7663100957870483
Validation loss: 2.1903353879849115

Epoch: 5| Step: 5
Training loss: 1.4909493923187256
Validation loss: 2.1950450936953225

Epoch: 5| Step: 6
Training loss: 1.3294843435287476
Validation loss: 2.180280680457751

Epoch: 5| Step: 7
Training loss: 1.5306251049041748
Validation loss: 2.1737839927275977

Epoch: 5| Step: 8
Training loss: 1.9020541906356812
Validation loss: 2.1565612703561783

Epoch: 5| Step: 9
Training loss: 1.2733014822006226
Validation loss: 2.177739664912224

Epoch: 5| Step: 10
Training loss: 1.2027637958526611
Validation loss: 2.147725140055021

Epoch: 5| Step: 11
Training loss: 1.496010661125183
Validation loss: 2.1861611853043237

Epoch: 329| Step: 0
Training loss: 1.349020004272461
Validation loss: 2.1919868687788644

Epoch: 5| Step: 1
Training loss: 1.3705689907073975
Validation loss: 2.1936918050050735

Epoch: 5| Step: 2
Training loss: 1.6579101085662842
Validation loss: 2.2019368410110474

Epoch: 5| Step: 3
Training loss: 1.8663005828857422
Validation loss: 2.1566511690616608

Epoch: 5| Step: 4
Training loss: 2.0378642082214355
Validation loss: 2.1723265747229257

Epoch: 5| Step: 5
Training loss: 1.0246117115020752
Validation loss: 2.175904229283333

Epoch: 5| Step: 6
Training loss: 1.8082473278045654
Validation loss: 2.1907193064689636

Epoch: 5| Step: 7
Training loss: 1.3002071380615234
Validation loss: 2.1715808709462485

Epoch: 5| Step: 8
Training loss: 1.1926292181015015
Validation loss: 2.1664075553417206

Epoch: 5| Step: 9
Training loss: 1.328149676322937
Validation loss: 2.1876197159290314

Epoch: 5| Step: 10
Training loss: 1.6184839010238647
Validation loss: 2.200621763865153

Epoch: 5| Step: 11
Training loss: 2.039548635482788
Validation loss: 2.2624069849650064

Epoch: 330| Step: 0
Training loss: 2.194493532180786
Validation loss: 2.243213544289271

Epoch: 5| Step: 1
Training loss: 1.6382471323013306
Validation loss: 2.2428491612275443

Epoch: 5| Step: 2
Training loss: 1.8704115152359009
Validation loss: 2.215774620572726

Epoch: 5| Step: 3
Training loss: 1.2052266597747803
Validation loss: 2.2113429506619773

Epoch: 5| Step: 4
Training loss: 1.5902775526046753
Validation loss: 2.1940636237462363

Epoch: 5| Step: 5
Training loss: 1.199827790260315
Validation loss: 2.1801274865865707

Epoch: 5| Step: 6
Training loss: 0.9902351498603821
Validation loss: 2.19241730372111

Epoch: 5| Step: 7
Training loss: 1.8685925006866455
Validation loss: 2.1837057868639627

Epoch: 5| Step: 8
Training loss: 1.896767258644104
Validation loss: 2.1895327965418496

Epoch: 5| Step: 9
Training loss: 1.5289957523345947
Validation loss: 2.18070379892985

Epoch: 5| Step: 10
Training loss: 0.8810206651687622
Validation loss: 2.1797205358743668

Epoch: 5| Step: 11
Training loss: 1.066917061805725
Validation loss: 2.1945329159498215

Epoch: 331| Step: 0
Training loss: 1.2249720096588135
Validation loss: 2.209437628587087

Epoch: 5| Step: 1
Training loss: 1.417388916015625
Validation loss: 2.179739405711492

Epoch: 5| Step: 2
Training loss: 1.0897927284240723
Validation loss: 2.1937331904967627

Epoch: 5| Step: 3
Training loss: 1.101501226425171
Validation loss: 2.206156680981318

Epoch: 5| Step: 4
Training loss: 0.7364408373832703
Validation loss: 2.190799047549566

Epoch: 5| Step: 5
Training loss: 1.4806950092315674
Validation loss: 2.189068744579951

Epoch: 5| Step: 6
Training loss: 1.5589624643325806
Validation loss: 2.1719334026177726

Epoch: 5| Step: 7
Training loss: 1.3969972133636475
Validation loss: 2.159560223420461

Epoch: 5| Step: 8
Training loss: 2.2847769260406494
Validation loss: 2.175533021489779

Epoch: 5| Step: 9
Training loss: 2.6399242877960205
Validation loss: 2.173641453186671

Epoch: 5| Step: 10
Training loss: 1.5949108600616455
Validation loss: 2.1850377172231674

Epoch: 5| Step: 11
Training loss: 1.4605191946029663
Validation loss: 2.2034372289975486

Epoch: 332| Step: 0
Training loss: 0.9013804197311401
Validation loss: 2.203473076224327

Epoch: 5| Step: 1
Training loss: 1.5738649368286133
Validation loss: 2.2449798782666526

Epoch: 5| Step: 2
Training loss: 1.4933980703353882
Validation loss: 2.2124336610237756

Epoch: 5| Step: 3
Training loss: 1.1714242696762085
Validation loss: 2.23425285021464

Epoch: 5| Step: 4
Training loss: 1.7195794582366943
Validation loss: 2.197411373257637

Epoch: 5| Step: 5
Training loss: 1.5156075954437256
Validation loss: 2.1612611413002014

Epoch: 5| Step: 6
Training loss: 1.6519334316253662
Validation loss: 2.166597773631414

Epoch: 5| Step: 7
Training loss: 1.5792129039764404
Validation loss: 2.2070136616627374

Epoch: 5| Step: 8
Training loss: 2.0594801902770996
Validation loss: 2.1551464597384133

Epoch: 5| Step: 9
Training loss: 1.7467482089996338
Validation loss: 2.1636941581964493

Epoch: 5| Step: 10
Training loss: 1.2054345607757568
Validation loss: 2.207790126403173

Epoch: 5| Step: 11
Training loss: 0.551486074924469
Validation loss: 2.1539514362812042

Epoch: 333| Step: 0
Training loss: 1.202746033668518
Validation loss: 2.178292746345202

Epoch: 5| Step: 1
Training loss: 1.4712657928466797
Validation loss: 2.1492913564046225

Epoch: 5| Step: 2
Training loss: 1.2112691402435303
Validation loss: 2.1485094328721366

Epoch: 5| Step: 3
Training loss: 2.1278157234191895
Validation loss: 2.161273250977198

Epoch: 5| Step: 4
Training loss: 1.6271045207977295
Validation loss: 2.1844338476657867

Epoch: 5| Step: 5
Training loss: 1.3685425519943237
Validation loss: 2.1856847008069358

Epoch: 5| Step: 6
Training loss: 1.9108508825302124
Validation loss: 2.1871918737888336

Epoch: 5| Step: 7
Training loss: 1.2937889099121094
Validation loss: 2.1855192134777703

Epoch: 5| Step: 8
Training loss: 1.2958412170410156
Validation loss: 2.1583436330159507

Epoch: 5| Step: 9
Training loss: 1.725386381149292
Validation loss: 2.1738290886084237

Epoch: 5| Step: 10
Training loss: 1.4394547939300537
Validation loss: 2.1793660074472427

Epoch: 5| Step: 11
Training loss: 0.8330501317977905
Validation loss: 2.187735160191854

Epoch: 334| Step: 0
Training loss: 1.8222548961639404
Validation loss: 2.154586056868235

Epoch: 5| Step: 1
Training loss: 2.4952008724212646
Validation loss: 2.1844426095485687

Epoch: 5| Step: 2
Training loss: 1.3620535135269165
Validation loss: 2.213855594396591

Epoch: 5| Step: 3
Training loss: 1.705749273300171
Validation loss: 2.183972050746282

Epoch: 5| Step: 4
Training loss: 1.3961626291275024
Validation loss: 2.181856984893481

Epoch: 5| Step: 5
Training loss: 1.2761309146881104
Validation loss: 2.1811018884181976

Epoch: 5| Step: 6
Training loss: 0.9210774302482605
Validation loss: 2.1259928743044534

Epoch: 5| Step: 7
Training loss: 1.2485711574554443
Validation loss: 2.160440276066462

Epoch: 5| Step: 8
Training loss: 1.274677038192749
Validation loss: 2.1473827163378396

Epoch: 5| Step: 9
Training loss: 1.5404431819915771
Validation loss: 2.1946172018845878

Epoch: 5| Step: 10
Training loss: 1.304747462272644
Validation loss: 2.183401584625244

Epoch: 5| Step: 11
Training loss: 1.6816277503967285
Validation loss: 2.175406585137049

Epoch: 335| Step: 0
Training loss: 1.5367590188980103
Validation loss: 2.229941060145696

Epoch: 5| Step: 1
Training loss: 0.9385541677474976
Validation loss: 2.265219658613205

Epoch: 5| Step: 2
Training loss: 1.7560012340545654
Validation loss: 2.2656210213899612

Epoch: 5| Step: 3
Training loss: 1.889153242111206
Validation loss: 2.2478505671024323

Epoch: 5| Step: 4
Training loss: 1.3446974754333496
Validation loss: 2.2284634113311768

Epoch: 5| Step: 5
Training loss: 1.2892111539840698
Validation loss: 2.2369712789853415

Epoch: 5| Step: 6
Training loss: 1.9374500513076782
Validation loss: 2.2704022179047265

Epoch: 5| Step: 7
Training loss: 1.2411975860595703
Validation loss: 2.237078830599785

Epoch: 5| Step: 8
Training loss: 1.5463972091674805
Validation loss: 2.192721570531527

Epoch: 5| Step: 9
Training loss: 1.6813493967056274
Validation loss: 2.1644923090934753

Epoch: 5| Step: 10
Training loss: 2.3649420738220215
Validation loss: 2.142238805691401

Epoch: 5| Step: 11
Training loss: 0.7205791473388672
Validation loss: 2.155310948689779

Epoch: 336| Step: 0
Training loss: 0.9549684524536133
Validation loss: 2.1349370727936425

Epoch: 5| Step: 1
Training loss: 1.6999098062515259
Validation loss: 2.1699021011590958

Epoch: 5| Step: 2
Training loss: 1.696628212928772
Validation loss: 2.173938329021136

Epoch: 5| Step: 3
Training loss: 1.2315094470977783
Validation loss: 2.2052032351493835

Epoch: 5| Step: 4
Training loss: 2.151319742202759
Validation loss: 2.1803816010554633

Epoch: 5| Step: 5
Training loss: 2.1016297340393066
Validation loss: 2.1783450146516166

Epoch: 5| Step: 6
Training loss: 1.3608710765838623
Validation loss: 2.2383392552534738

Epoch: 5| Step: 7
Training loss: 1.3766103982925415
Validation loss: 2.222058812777201

Epoch: 5| Step: 8
Training loss: 2.1495072841644287
Validation loss: 2.2230826963980994

Epoch: 5| Step: 9
Training loss: 1.4326306581497192
Validation loss: 2.2003238797187805

Epoch: 5| Step: 10
Training loss: 1.0640144348144531
Validation loss: 2.159564216931661

Epoch: 5| Step: 11
Training loss: 0.913875937461853
Validation loss: 2.129043678442637

Epoch: 337| Step: 0
Training loss: 1.8683040142059326
Validation loss: 2.1744931439558663

Epoch: 5| Step: 1
Training loss: 1.3783104419708252
Validation loss: 2.1517506341139474

Epoch: 5| Step: 2
Training loss: 0.8284499049186707
Validation loss: 2.1862972180048623

Epoch: 5| Step: 3
Training loss: 2.148538589477539
Validation loss: 2.1842098087072372

Epoch: 5| Step: 4
Training loss: 1.4239311218261719
Validation loss: 2.210362061858177

Epoch: 5| Step: 5
Training loss: 1.8357738256454468
Validation loss: 2.220379347602526

Epoch: 5| Step: 6
Training loss: 1.955945611000061
Validation loss: 2.2155921508868537

Epoch: 5| Step: 7
Training loss: 1.6134700775146484
Validation loss: 2.1723674535751343

Epoch: 5| Step: 8
Training loss: 1.7304964065551758
Validation loss: 2.173327758908272

Epoch: 5| Step: 9
Training loss: 1.9358673095703125
Validation loss: 2.1733632187048593

Epoch: 5| Step: 10
Training loss: 1.704538106918335
Validation loss: 2.2100821435451508

Epoch: 5| Step: 11
Training loss: 1.6333292722702026
Validation loss: 2.2253459145625434

Epoch: 338| Step: 0
Training loss: 1.9480667114257812
Validation loss: 2.2170806924502053

Epoch: 5| Step: 1
Training loss: 1.1355756521224976
Validation loss: 2.2267009615898132

Epoch: 5| Step: 2
Training loss: 1.7266685962677002
Validation loss: 2.233697081605593

Epoch: 5| Step: 3
Training loss: 1.380098581314087
Validation loss: 2.2542321185270944

Epoch: 5| Step: 4
Training loss: 1.6523563861846924
Validation loss: 2.2423979490995407

Epoch: 5| Step: 5
Training loss: 2.0393073558807373
Validation loss: 2.235742688179016

Epoch: 5| Step: 6
Training loss: 1.3603893518447876
Validation loss: 2.238418181737264

Epoch: 5| Step: 7
Training loss: 2.2968759536743164
Validation loss: 2.2117385963598886

Epoch: 5| Step: 8
Training loss: 1.4987993240356445
Validation loss: 2.2225812574227652

Epoch: 5| Step: 9
Training loss: 1.0695466995239258
Validation loss: 2.222734267512957

Epoch: 5| Step: 10
Training loss: 1.8031806945800781
Validation loss: 2.2035896331071854

Epoch: 5| Step: 11
Training loss: 0.4255133271217346
Validation loss: 2.189942946036657

Epoch: 339| Step: 0
Training loss: 1.1564397811889648
Validation loss: 2.193165212869644

Epoch: 5| Step: 1
Training loss: 1.5568974018096924
Validation loss: 2.21416067580382

Epoch: 5| Step: 2
Training loss: 2.2907369136810303
Validation loss: 2.2156838178634644

Epoch: 5| Step: 3
Training loss: 1.2861607074737549
Validation loss: 2.211217741171519

Epoch: 5| Step: 4
Training loss: 2.042128801345825
Validation loss: 2.228569909930229

Epoch: 5| Step: 5
Training loss: 1.1536035537719727
Validation loss: 2.2007183680931726

Epoch: 5| Step: 6
Training loss: 1.0861905813217163
Validation loss: 2.2207782665888467

Epoch: 5| Step: 7
Training loss: 2.434680700302124
Validation loss: 2.22466941177845

Epoch: 5| Step: 8
Training loss: 1.5581002235412598
Validation loss: 2.228640859325727

Epoch: 5| Step: 9
Training loss: 1.4752833843231201
Validation loss: 2.2490139106909433

Epoch: 5| Step: 10
Training loss: 1.1122925281524658
Validation loss: 2.2529574980338416

Epoch: 5| Step: 11
Training loss: 1.981887698173523
Validation loss: 2.275287871559461

Epoch: 340| Step: 0
Training loss: 1.6848338842391968
Validation loss: 2.2303011318047843

Epoch: 5| Step: 1
Training loss: 0.7762364149093628
Validation loss: 2.208860049645106

Epoch: 5| Step: 2
Training loss: 1.2427165508270264
Validation loss: 2.2488971004883447

Epoch: 5| Step: 3
Training loss: 1.4121620655059814
Validation loss: 2.210712105035782

Epoch: 5| Step: 4
Training loss: 1.034545660018921
Validation loss: 2.196567803621292

Epoch: 5| Step: 5
Training loss: 1.423654317855835
Validation loss: 2.2172542115052543

Epoch: 5| Step: 6
Training loss: 1.2154295444488525
Validation loss: 2.1799531131982803

Epoch: 5| Step: 7
Training loss: 0.9900442361831665
Validation loss: 2.1984523236751556

Epoch: 5| Step: 8
Training loss: 2.072009563446045
Validation loss: 2.2145815640687943

Epoch: 5| Step: 9
Training loss: 1.94075608253479
Validation loss: 2.2273791084686914

Epoch: 5| Step: 10
Training loss: 2.711146831512451
Validation loss: 2.1895261655251184

Epoch: 5| Step: 11
Training loss: 1.1321135759353638
Validation loss: 2.2071787863969803

Epoch: 341| Step: 0
Training loss: 1.257332682609558
Validation loss: 2.213691915074984

Epoch: 5| Step: 1
Training loss: 1.4651895761489868
Validation loss: 2.218803331255913

Epoch: 5| Step: 2
Training loss: 1.5557597875595093
Validation loss: 2.1840198586384454

Epoch: 5| Step: 3
Training loss: 1.1586307287216187
Validation loss: 2.20464034875234

Epoch: 5| Step: 4
Training loss: 1.2017933130264282
Validation loss: 2.195566733678182

Epoch: 5| Step: 5
Training loss: 2.1010842323303223
Validation loss: 2.2218036502599716

Epoch: 5| Step: 6
Training loss: 1.2921887636184692
Validation loss: 2.2234606941541037

Epoch: 5| Step: 7
Training loss: 0.8364567756652832
Validation loss: 2.2137130747238793

Epoch: 5| Step: 8
Training loss: 1.6389061212539673
Validation loss: 2.2522897521654763

Epoch: 5| Step: 9
Training loss: 1.9898239374160767
Validation loss: 2.2291869819164276

Epoch: 5| Step: 10
Training loss: 1.7822198867797852
Validation loss: 2.2796396215756736

Epoch: 5| Step: 11
Training loss: 0.8052874803543091
Validation loss: 2.2951283156871796

Epoch: 342| Step: 0
Training loss: 1.2435544729232788
Validation loss: 2.283666198452314

Epoch: 5| Step: 1
Training loss: 1.80196213722229
Validation loss: 2.2702586700518927

Epoch: 5| Step: 2
Training loss: 1.031616449356079
Validation loss: 2.287339592973391

Epoch: 5| Step: 3
Training loss: 1.3929557800292969
Validation loss: 2.2377691566944122

Epoch: 5| Step: 4
Training loss: 1.3128793239593506
Validation loss: 2.2443800965944924

Epoch: 5| Step: 5
Training loss: 1.7831106185913086
Validation loss: 2.1813031683365502

Epoch: 5| Step: 6
Training loss: 1.3219139575958252
Validation loss: 2.1807674219210944

Epoch: 5| Step: 7
Training loss: 1.5916306972503662
Validation loss: 2.1986114035050073

Epoch: 5| Step: 8
Training loss: 2.0941996574401855
Validation loss: 2.1825112650791803

Epoch: 5| Step: 9
Training loss: 1.0611518621444702
Validation loss: 2.1678729752699533

Epoch: 5| Step: 10
Training loss: 1.7874292135238647
Validation loss: 2.1994768679142

Epoch: 5| Step: 11
Training loss: 1.9254868030548096
Validation loss: 2.1692417363325753

Epoch: 343| Step: 0
Training loss: 1.7150466442108154
Validation loss: 2.1669560819864273

Epoch: 5| Step: 1
Training loss: 1.6260488033294678
Validation loss: 2.221266513069471

Epoch: 5| Step: 2
Training loss: 1.8186107873916626
Validation loss: 2.20580001672109

Epoch: 5| Step: 3
Training loss: 1.5038026571273804
Validation loss: 2.217369685570399

Epoch: 5| Step: 4
Training loss: 1.259804368019104
Validation loss: 2.2067005038261414

Epoch: 5| Step: 5
Training loss: 1.3502553701400757
Validation loss: 2.2325651347637177

Epoch: 5| Step: 6
Training loss: 1.6535497903823853
Validation loss: 2.215072989463806

Epoch: 5| Step: 7
Training loss: 1.6786924600601196
Validation loss: 2.2270918587843576

Epoch: 5| Step: 8
Training loss: 1.3995015621185303
Validation loss: 2.2187166611353555

Epoch: 5| Step: 9
Training loss: 1.1349375247955322
Validation loss: 2.194439172744751

Epoch: 5| Step: 10
Training loss: 0.7783089876174927
Validation loss: 2.173004855712255

Epoch: 5| Step: 11
Training loss: 2.4038753509521484
Validation loss: 2.1720140278339386

Epoch: 344| Step: 0
Training loss: 1.748876929283142
Validation loss: 2.2074269354343414

Epoch: 5| Step: 1
Training loss: 2.5895590782165527
Validation loss: 2.229087005058924

Epoch: 5| Step: 2
Training loss: 1.7799152135849
Validation loss: 2.199628179272016

Epoch: 5| Step: 3
Training loss: 1.7970138788223267
Validation loss: 2.205691486597061

Epoch: 5| Step: 4
Training loss: 1.2062046527862549
Validation loss: 2.1946191440025964

Epoch: 5| Step: 5
Training loss: 1.1907012462615967
Validation loss: 2.153695752223333

Epoch: 5| Step: 6
Training loss: 1.3773001432418823
Validation loss: 2.20912096897761

Epoch: 5| Step: 7
Training loss: 1.3399287462234497
Validation loss: 2.1816352009773254

Epoch: 5| Step: 8
Training loss: 1.571776270866394
Validation loss: 2.188463677962621

Epoch: 5| Step: 9
Training loss: 1.123732328414917
Validation loss: 2.2110075851281485

Epoch: 5| Step: 10
Training loss: 1.6647746562957764
Validation loss: 2.2217757056156793

Epoch: 5| Step: 11
Training loss: 0.982291579246521
Validation loss: 2.2033663590749106

Epoch: 345| Step: 0
Training loss: 1.6905635595321655
Validation loss: 2.2052941968043647

Epoch: 5| Step: 1
Training loss: 1.5973683595657349
Validation loss: 2.1750771502653756

Epoch: 5| Step: 2
Training loss: 1.4664268493652344
Validation loss: 2.1542299886544547

Epoch: 5| Step: 3
Training loss: 1.6659557819366455
Validation loss: 2.168929477532705

Epoch: 5| Step: 4
Training loss: 1.2680338621139526
Validation loss: 2.1752492835124335

Epoch: 5| Step: 5
Training loss: 1.8056071996688843
Validation loss: 2.1906305154164634

Epoch: 5| Step: 6
Training loss: 1.7412220239639282
Validation loss: 2.1975926955540976

Epoch: 5| Step: 7
Training loss: 1.3433494567871094
Validation loss: 2.211982404192289

Epoch: 5| Step: 8
Training loss: 1.2168521881103516
Validation loss: 2.1930261900027594

Epoch: 5| Step: 9
Training loss: 1.4381803274154663
Validation loss: 2.193693369626999

Epoch: 5| Step: 10
Training loss: 1.480421781539917
Validation loss: 2.215259383122126

Epoch: 5| Step: 11
Training loss: 1.3642525672912598
Validation loss: 2.217535783847173

Epoch: 346| Step: 0
Training loss: 1.4276841878890991
Validation loss: 2.227697586019834

Epoch: 5| Step: 1
Training loss: 1.5988924503326416
Validation loss: 2.258625715970993

Epoch: 5| Step: 2
Training loss: 1.5399360656738281
Validation loss: 2.181571746865908

Epoch: 5| Step: 3
Training loss: 2.134732484817505
Validation loss: 2.1898838728666306

Epoch: 5| Step: 4
Training loss: 1.4614630937576294
Validation loss: 2.1822381714979806

Epoch: 5| Step: 5
Training loss: 1.8511995077133179
Validation loss: 2.2075183540582657

Epoch: 5| Step: 6
Training loss: 1.430760383605957
Validation loss: 2.2002525329589844

Epoch: 5| Step: 7
Training loss: 0.8881290555000305
Validation loss: 2.1925376852353415

Epoch: 5| Step: 8
Training loss: 1.7728321552276611
Validation loss: 2.192978620529175

Epoch: 5| Step: 9
Training loss: 1.6305755376815796
Validation loss: 2.2081606686115265

Epoch: 5| Step: 10
Training loss: 1.2265218496322632
Validation loss: 2.1808481911818185

Epoch: 5| Step: 11
Training loss: 2.067582130432129
Validation loss: 2.1779175301392875

Epoch: 347| Step: 0
Training loss: 1.6181631088256836
Validation loss: 2.1622673074404397

Epoch: 5| Step: 1
Training loss: 1.5090891122817993
Validation loss: 2.216766824324926

Epoch: 5| Step: 2
Training loss: 1.1724021434783936
Validation loss: 2.2039929727713266

Epoch: 5| Step: 3
Training loss: 1.5646684169769287
Validation loss: 2.250171105066935

Epoch: 5| Step: 4
Training loss: 1.1908817291259766
Validation loss: 2.2672941188017526

Epoch: 5| Step: 5
Training loss: 1.3130548000335693
Validation loss: 2.235633045434952

Epoch: 5| Step: 6
Training loss: 1.8413435220718384
Validation loss: 2.2512324303388596

Epoch: 5| Step: 7
Training loss: 1.6997829675674438
Validation loss: 2.235179295142492

Epoch: 5| Step: 8
Training loss: 2.108672857284546
Validation loss: 2.224404662847519

Epoch: 5| Step: 9
Training loss: 1.272031545639038
Validation loss: 2.230992868542671

Epoch: 5| Step: 10
Training loss: 1.2938287258148193
Validation loss: 2.2045741776625314

Epoch: 5| Step: 11
Training loss: 0.613189697265625
Validation loss: 2.1936203787724176

Epoch: 348| Step: 0
Training loss: 1.9314472675323486
Validation loss: 2.1735548973083496

Epoch: 5| Step: 1
Training loss: 1.3264517784118652
Validation loss: 2.195083270470301

Epoch: 5| Step: 2
Training loss: 1.3803960084915161
Validation loss: 2.191209370891253

Epoch: 5| Step: 3
Training loss: 2.290799617767334
Validation loss: 2.2021111994981766

Epoch: 5| Step: 4
Training loss: 1.0263303518295288
Validation loss: 2.19872385263443

Epoch: 5| Step: 5
Training loss: 0.9946799278259277
Validation loss: 2.2203118403752646

Epoch: 5| Step: 6
Training loss: 1.4882194995880127
Validation loss: 2.2505135337511697

Epoch: 5| Step: 7
Training loss: 1.0433413982391357
Validation loss: 2.2300186455249786

Epoch: 5| Step: 8
Training loss: 1.0900671482086182
Validation loss: 2.2154984325170517

Epoch: 5| Step: 9
Training loss: 1.4848575592041016
Validation loss: 2.25679545601209

Epoch: 5| Step: 10
Training loss: 1.7799651622772217
Validation loss: 2.2334417353073754

Epoch: 5| Step: 11
Training loss: 1.9817231893539429
Validation loss: 2.1955772787332535

Epoch: 349| Step: 0
Training loss: 1.580893874168396
Validation loss: 2.2046110232671103

Epoch: 5| Step: 1
Training loss: 1.8177133798599243
Validation loss: 2.2285056660572686

Epoch: 5| Step: 2
Training loss: 1.9153163433074951
Validation loss: 2.1967104921738305

Epoch: 5| Step: 3
Training loss: 1.3433287143707275
Validation loss: 2.1973287214835486

Epoch: 5| Step: 4
Training loss: 0.6699206829071045
Validation loss: 2.1860476632912955

Epoch: 5| Step: 5
Training loss: 2.001227855682373
Validation loss: 2.2016182045141854

Epoch: 5| Step: 6
Training loss: 1.4923465251922607
Validation loss: 2.155744711558024

Epoch: 5| Step: 7
Training loss: 1.4255669116973877
Validation loss: 2.165818234284719

Epoch: 5| Step: 8
Training loss: 1.1105985641479492
Validation loss: 2.2061735888322196

Epoch: 5| Step: 9
Training loss: 0.8990810513496399
Validation loss: 2.175241068005562

Epoch: 5| Step: 10
Training loss: 1.4006456136703491
Validation loss: 2.193572446703911

Epoch: 5| Step: 11
Training loss: 1.2228591442108154
Validation loss: 2.1798105190197625

Epoch: 350| Step: 0
Training loss: 1.08437180519104
Validation loss: 2.1899544298648834

Epoch: 5| Step: 1
Training loss: 1.7404839992523193
Validation loss: 2.163076266646385

Epoch: 5| Step: 2
Training loss: 1.6789894104003906
Validation loss: 2.1955688347419104

Epoch: 5| Step: 3
Training loss: 1.3550307750701904
Validation loss: 2.169950251777967

Epoch: 5| Step: 4
Training loss: 2.0046579837799072
Validation loss: 2.201588282982508

Epoch: 5| Step: 5
Training loss: 1.6370683908462524
Validation loss: 2.1899082213640213

Epoch: 5| Step: 6
Training loss: 1.5263744592666626
Validation loss: 2.219696303208669

Epoch: 5| Step: 7
Training loss: 1.3273426294326782
Validation loss: 2.1765070458253226

Epoch: 5| Step: 8
Training loss: 1.755226492881775
Validation loss: 2.212011660138766

Epoch: 5| Step: 9
Training loss: 1.162757396697998
Validation loss: 2.186752527952194

Epoch: 5| Step: 10
Training loss: 0.8757115602493286
Validation loss: 2.198109269142151

Epoch: 5| Step: 11
Training loss: 1.1789664030075073
Validation loss: 2.189557741085688

Epoch: 351| Step: 0
Training loss: 1.1749929189682007
Validation loss: 2.2066294103860855

Epoch: 5| Step: 1
Training loss: 1.6934401988983154
Validation loss: 2.1604989568392434

Epoch: 5| Step: 2
Training loss: 1.2352975606918335
Validation loss: 2.180609484513601

Epoch: 5| Step: 3
Training loss: 1.0814887285232544
Validation loss: 2.163167188564936

Epoch: 5| Step: 4
Training loss: 1.6761434078216553
Validation loss: 2.2098616609970727

Epoch: 5| Step: 5
Training loss: 1.9048540592193604
Validation loss: 2.2048464765151343

Epoch: 5| Step: 6
Training loss: 1.2561851739883423
Validation loss: 2.2103782643874488

Epoch: 5| Step: 7
Training loss: 1.890142798423767
Validation loss: 2.230282247066498

Epoch: 5| Step: 8
Training loss: 1.312951683998108
Validation loss: 2.193430855870247

Epoch: 5| Step: 9
Training loss: 1.6814273595809937
Validation loss: 2.177682419617971

Epoch: 5| Step: 10
Training loss: 1.5030477046966553
Validation loss: 2.1979825645685196

Epoch: 5| Step: 11
Training loss: 1.1985468864440918
Validation loss: 2.1853142380714417

Epoch: 352| Step: 0
Training loss: 1.2603775262832642
Validation loss: 2.205501228570938

Epoch: 5| Step: 1
Training loss: 1.8155988454818726
Validation loss: 2.2384388744831085

Epoch: 5| Step: 2
Training loss: 1.7825634479522705
Validation loss: 2.226729159553846

Epoch: 5| Step: 3
Training loss: 1.1558849811553955
Validation loss: 2.2118273029724755

Epoch: 5| Step: 4
Training loss: 0.888105571269989
Validation loss: 2.258574734131495

Epoch: 5| Step: 5
Training loss: 1.6266841888427734
Validation loss: 2.2140138000249863

Epoch: 5| Step: 6
Training loss: 1.9632158279418945
Validation loss: 2.198130081097285

Epoch: 5| Step: 7
Training loss: 1.3189502954483032
Validation loss: 2.1876284778118134

Epoch: 5| Step: 8
Training loss: 1.359844446182251
Validation loss: 2.1831296235322952

Epoch: 5| Step: 9
Training loss: 1.0007833242416382
Validation loss: 2.190539757410685

Epoch: 5| Step: 10
Training loss: 1.5163321495056152
Validation loss: 2.187896211942037

Epoch: 5| Step: 11
Training loss: 1.53887939453125
Validation loss: 2.1880674362182617

Epoch: 353| Step: 0
Training loss: 1.7368005514144897
Validation loss: 2.2125558654467263

Epoch: 5| Step: 1
Training loss: 1.5958073139190674
Validation loss: 2.228767986098925

Epoch: 5| Step: 2
Training loss: 1.3162727355957031
Validation loss: 2.1803116649389267

Epoch: 5| Step: 3
Training loss: 0.9002068638801575
Validation loss: 2.2290647476911545

Epoch: 5| Step: 4
Training loss: 1.4645392894744873
Validation loss: 2.200670545299848

Epoch: 5| Step: 5
Training loss: 1.8585354089736938
Validation loss: 2.1929524143536887

Epoch: 5| Step: 6
Training loss: 1.4471192359924316
Validation loss: 2.2143970280885696

Epoch: 5| Step: 7
Training loss: 1.1872366666793823
Validation loss: 2.1946544299523034

Epoch: 5| Step: 8
Training loss: 1.8407764434814453
Validation loss: 2.198857436577479

Epoch: 5| Step: 9
Training loss: 1.2961292266845703
Validation loss: 2.197742054859797

Epoch: 5| Step: 10
Training loss: 1.4799892902374268
Validation loss: 2.2173162698745728

Epoch: 5| Step: 11
Training loss: 0.25126391649246216
Validation loss: 2.2491049269835153

Epoch: 354| Step: 0
Training loss: 1.855806589126587
Validation loss: 2.2322728037834167

Epoch: 5| Step: 1
Training loss: 1.4763013124465942
Validation loss: 2.216484715541204

Epoch: 5| Step: 2
Training loss: 0.9831177592277527
Validation loss: 2.222158004840215

Epoch: 5| Step: 3
Training loss: 1.290647268295288
Validation loss: 2.2324796865383782

Epoch: 5| Step: 4
Training loss: 1.976000189781189
Validation loss: 2.221455996235212

Epoch: 5| Step: 5
Training loss: 1.3915541172027588
Validation loss: 2.233073651790619

Epoch: 5| Step: 6
Training loss: 1.3276591300964355
Validation loss: 2.209812104701996

Epoch: 5| Step: 7
Training loss: 1.2433147430419922
Validation loss: 2.1746398210525513

Epoch: 5| Step: 8
Training loss: 1.3762651681900024
Validation loss: 2.1706278920173645

Epoch: 5| Step: 9
Training loss: 1.1497802734375
Validation loss: 2.1582681387662888

Epoch: 5| Step: 10
Training loss: 1.5891128778457642
Validation loss: 2.186663975318273

Epoch: 5| Step: 11
Training loss: 3.5367050170898438
Validation loss: 2.1719551533460617

Epoch: 355| Step: 0
Training loss: 1.9764589071273804
Validation loss: 2.174684305985769

Epoch: 5| Step: 1
Training loss: 1.3152120113372803
Validation loss: 2.1898385683695474

Epoch: 5| Step: 2
Training loss: 1.3034861087799072
Validation loss: 2.1949038604895272

Epoch: 5| Step: 3
Training loss: 1.3863781690597534
Validation loss: 2.210537001490593

Epoch: 5| Step: 4
Training loss: 1.5857595205307007
Validation loss: 2.2164252003033957

Epoch: 5| Step: 5
Training loss: 1.4187016487121582
Validation loss: 2.205482562383016

Epoch: 5| Step: 6
Training loss: 1.307978868484497
Validation loss: 2.2120314637819924

Epoch: 5| Step: 7
Training loss: 1.574238657951355
Validation loss: 2.179183840751648

Epoch: 5| Step: 8
Training loss: 1.5497705936431885
Validation loss: 2.2115290065606437

Epoch: 5| Step: 9
Training loss: 0.8293099403381348
Validation loss: 2.1890627592802048

Epoch: 5| Step: 10
Training loss: 1.529469609260559
Validation loss: 2.187270869811376

Epoch: 5| Step: 11
Training loss: 2.2977209091186523
Validation loss: 2.171781371037165

Epoch: 356| Step: 0
Training loss: 1.7878316640853882
Validation loss: 2.2014155934254327

Epoch: 5| Step: 1
Training loss: 1.3203648328781128
Validation loss: 2.2455598016579947

Epoch: 5| Step: 2
Training loss: 1.606636643409729
Validation loss: 2.187216560045878

Epoch: 5| Step: 3
Training loss: 1.497515082359314
Validation loss: 2.2204955021540322

Epoch: 5| Step: 4
Training loss: 0.6991713643074036
Validation loss: 2.1731374760468802

Epoch: 5| Step: 5
Training loss: 1.558608055114746
Validation loss: 2.1939598321914673

Epoch: 5| Step: 6
Training loss: 1.0119421482086182
Validation loss: 2.2234606742858887

Epoch: 5| Step: 7
Training loss: 1.6171993017196655
Validation loss: 2.2077033817768097

Epoch: 5| Step: 8
Training loss: 1.3667436838150024
Validation loss: 2.1926056096951165

Epoch: 5| Step: 9
Training loss: 1.9027150869369507
Validation loss: 2.21334378918012

Epoch: 5| Step: 10
Training loss: 1.2002084255218506
Validation loss: 2.2005531092484794

Epoch: 5| Step: 11
Training loss: 1.996413230895996
Validation loss: 2.1898821691672006

Epoch: 357| Step: 0
Training loss: 1.8200762271881104
Validation loss: 2.193759709596634

Epoch: 5| Step: 1
Training loss: 2.12372088432312
Validation loss: 2.2170479794343314

Epoch: 5| Step: 2
Training loss: 1.3339518308639526
Validation loss: 2.222541789213816

Epoch: 5| Step: 3
Training loss: 1.8668320178985596
Validation loss: 2.2211047410964966

Epoch: 5| Step: 4
Training loss: 1.3564668893814087
Validation loss: 2.16524900496006

Epoch: 5| Step: 5
Training loss: 1.2258319854736328
Validation loss: 2.1900238593419394

Epoch: 5| Step: 6
Training loss: 1.0982815027236938
Validation loss: 2.183722053964933

Epoch: 5| Step: 7
Training loss: 1.3263880014419556
Validation loss: 2.2170222302277884

Epoch: 5| Step: 8
Training loss: 1.3311790227890015
Validation loss: 2.1310164034366608

Epoch: 5| Step: 9
Training loss: 1.4031424522399902
Validation loss: 2.217091535528501

Epoch: 5| Step: 10
Training loss: 0.8363357782363892
Validation loss: 2.1842851042747498

Epoch: 5| Step: 11
Training loss: 0.432901531457901
Validation loss: 2.206405828396479

Epoch: 358| Step: 0
Training loss: 1.7084839344024658
Validation loss: 2.2193876107533774

Epoch: 5| Step: 1
Training loss: 1.3819879293441772
Validation loss: 2.259571189681689

Epoch: 5| Step: 2
Training loss: 1.2850284576416016
Validation loss: 2.2435135692358017

Epoch: 5| Step: 3
Training loss: 1.672178864479065
Validation loss: 2.1991037925084433

Epoch: 5| Step: 4
Training loss: 1.5982770919799805
Validation loss: 2.2778181980053582

Epoch: 5| Step: 5
Training loss: 1.3207175731658936
Validation loss: 2.2394331942001977

Epoch: 5| Step: 6
Training loss: 1.338439702987671
Validation loss: 2.2343003253142038

Epoch: 5| Step: 7
Training loss: 1.4799494743347168
Validation loss: 2.239194760719935

Epoch: 5| Step: 8
Training loss: 1.4644832611083984
Validation loss: 2.2059867084026337

Epoch: 5| Step: 9
Training loss: 1.6964021921157837
Validation loss: 2.189876288175583

Epoch: 5| Step: 10
Training loss: 1.524713158607483
Validation loss: 2.205955589811007

Epoch: 5| Step: 11
Training loss: 0.5691967010498047
Validation loss: 2.201129510998726

Epoch: 359| Step: 0
Training loss: 1.5041661262512207
Validation loss: 2.20214019715786

Epoch: 5| Step: 1
Training loss: 1.1806366443634033
Validation loss: 2.1878336717685065

Epoch: 5| Step: 2
Training loss: 0.8817813992500305
Validation loss: 2.1894014378388724

Epoch: 5| Step: 3
Training loss: 1.4322855472564697
Validation loss: 2.1866078476111093

Epoch: 5| Step: 4
Training loss: 1.793408989906311
Validation loss: 2.193581481774648

Epoch: 5| Step: 5
Training loss: 1.4684507846832275
Validation loss: 2.1902688443660736

Epoch: 5| Step: 6
Training loss: 1.6244003772735596
Validation loss: 2.1919080366690955

Epoch: 5| Step: 7
Training loss: 0.9120685458183289
Validation loss: 2.210982213417689

Epoch: 5| Step: 8
Training loss: 1.692618727684021
Validation loss: 2.2172372241814933

Epoch: 5| Step: 9
Training loss: 1.7626310586929321
Validation loss: 2.2035305351018906

Epoch: 5| Step: 10
Training loss: 1.2984907627105713
Validation loss: 2.234753578901291

Epoch: 5| Step: 11
Training loss: 1.729120135307312
Validation loss: 2.2195094923178353

Epoch: 360| Step: 0
Training loss: 2.0029101371765137
Validation loss: 2.232975502808889

Epoch: 5| Step: 1
Training loss: 1.1636594533920288
Validation loss: 2.2377196898063025

Epoch: 5| Step: 2
Training loss: 1.7589826583862305
Validation loss: 2.244634156425794

Epoch: 5| Step: 3
Training loss: 1.6175520420074463
Validation loss: 2.231835901737213

Epoch: 5| Step: 4
Training loss: 1.1053961515426636
Validation loss: 2.2343510886033378

Epoch: 5| Step: 5
Training loss: 1.3581080436706543
Validation loss: 2.2376952866713204

Epoch: 5| Step: 6
Training loss: 1.0709279775619507
Validation loss: 2.2179168462753296

Epoch: 5| Step: 7
Training loss: 1.1353249549865723
Validation loss: 2.2006726215283074

Epoch: 5| Step: 8
Training loss: 1.2764590978622437
Validation loss: 2.217498262723287

Epoch: 5| Step: 9
Training loss: 1.5108861923217773
Validation loss: 2.1730993588765464

Epoch: 5| Step: 10
Training loss: 1.728517770767212
Validation loss: 2.2264522860447564

Epoch: 5| Step: 11
Training loss: 1.1874258518218994
Validation loss: 2.210119833548864

Epoch: 361| Step: 0
Training loss: 1.6730687618255615
Validation loss: 2.1864784955978394

Epoch: 5| Step: 1
Training loss: 1.4957026243209839
Validation loss: 2.177793244520823

Epoch: 5| Step: 2
Training loss: 1.4155919551849365
Validation loss: 2.1851263840993247

Epoch: 5| Step: 3
Training loss: 1.6546112298965454
Validation loss: 2.1328006833791733

Epoch: 5| Step: 4
Training loss: 1.2574713230133057
Validation loss: 2.171096126238505

Epoch: 5| Step: 5
Training loss: 1.1453777551651
Validation loss: 2.192360738913218

Epoch: 5| Step: 6
Training loss: 1.105776071548462
Validation loss: 2.1553909480571747

Epoch: 5| Step: 7
Training loss: 1.6131486892700195
Validation loss: 2.1725496699412665

Epoch: 5| Step: 8
Training loss: 1.6562618017196655
Validation loss: 2.1340436041355133

Epoch: 5| Step: 9
Training loss: 0.9999309778213501
Validation loss: 2.1471494982639947

Epoch: 5| Step: 10
Training loss: 1.4025217294692993
Validation loss: 2.163203398386637

Epoch: 5| Step: 11
Training loss: 1.5879509449005127
Validation loss: 2.175246094663938

Epoch: 362| Step: 0
Training loss: 1.2130911350250244
Validation loss: 2.19488492111365

Epoch: 5| Step: 1
Training loss: 1.095295786857605
Validation loss: 2.1306989192962646

Epoch: 5| Step: 2
Training loss: 1.4762133359909058
Validation loss: 2.156254917383194

Epoch: 5| Step: 3
Training loss: 2.0947165489196777
Validation loss: 2.1958782573541007

Epoch: 5| Step: 4
Training loss: 1.3061813116073608
Validation loss: 2.18110491335392

Epoch: 5| Step: 5
Training loss: 1.0830731391906738
Validation loss: 2.1804019709428153

Epoch: 5| Step: 6
Training loss: 1.1666980981826782
Validation loss: 2.166933303078016

Epoch: 5| Step: 7
Training loss: 1.9733359813690186
Validation loss: 2.1882027238607407

Epoch: 5| Step: 8
Training loss: 0.8783319592475891
Validation loss: 2.1746531575918198

Epoch: 5| Step: 9
Training loss: 1.6648553609848022
Validation loss: 2.139406527082125

Epoch: 5| Step: 10
Training loss: 1.6485153436660767
Validation loss: 2.157446339726448

Epoch: 5| Step: 11
Training loss: 1.9056432247161865
Validation loss: 2.1659355560938516

Epoch: 363| Step: 0
Training loss: 1.663232445716858
Validation loss: 2.1724806229273477

Epoch: 5| Step: 1
Training loss: 1.3379528522491455
Validation loss: 2.158458044131597

Epoch: 5| Step: 2
Training loss: 1.387222409248352
Validation loss: 2.18671124180158

Epoch: 5| Step: 3
Training loss: 1.0334289073944092
Validation loss: 2.1754114429155984

Epoch: 5| Step: 4
Training loss: 1.553581953048706
Validation loss: 2.1076605866352716

Epoch: 5| Step: 5
Training loss: 1.2939420938491821
Validation loss: 2.1243207405010858

Epoch: 5| Step: 6
Training loss: 1.2981822490692139
Validation loss: 2.1509093791246414

Epoch: 5| Step: 7
Training loss: 1.3617398738861084
Validation loss: 2.1546567181746163

Epoch: 5| Step: 8
Training loss: 1.1864134073257446
Validation loss: 2.139469633499781

Epoch: 5| Step: 9
Training loss: 1.3786327838897705
Validation loss: 2.1520768105983734

Epoch: 5| Step: 10
Training loss: 1.811317801475525
Validation loss: 2.1913996636867523

Epoch: 5| Step: 11
Training loss: 0.5743240118026733
Validation loss: 2.136313478151957

Epoch: 364| Step: 0
Training loss: 1.447414755821228
Validation loss: 2.1926338175932565

Epoch: 5| Step: 1
Training loss: 1.2811046838760376
Validation loss: 2.2017139991124473

Epoch: 5| Step: 2
Training loss: 1.3568617105484009
Validation loss: 2.191347524523735

Epoch: 5| Step: 3
Training loss: 1.4200748205184937
Validation loss: 2.183926746249199

Epoch: 5| Step: 4
Training loss: 1.1965479850769043
Validation loss: 2.1876739213864007

Epoch: 5| Step: 5
Training loss: 1.9955532550811768
Validation loss: 2.202955424785614

Epoch: 5| Step: 6
Training loss: 1.43217933177948
Validation loss: 2.2131071289380393

Epoch: 5| Step: 7
Training loss: 1.725589394569397
Validation loss: 2.1994347870349884

Epoch: 5| Step: 8
Training loss: 1.1943467855453491
Validation loss: 2.238703136642774

Epoch: 5| Step: 9
Training loss: 1.3837817907333374
Validation loss: 2.221312309304873

Epoch: 5| Step: 10
Training loss: 1.2583770751953125
Validation loss: 2.2062296867370605

Epoch: 5| Step: 11
Training loss: 1.2772741317749023
Validation loss: 2.2281981855630875

Epoch: 365| Step: 0
Training loss: 1.8425300121307373
Validation loss: 2.21779265999794

Epoch: 5| Step: 1
Training loss: 1.1707433462142944
Validation loss: 2.221776003638903

Epoch: 5| Step: 2
Training loss: 1.8185771703720093
Validation loss: 2.1938354472319284

Epoch: 5| Step: 3
Training loss: 1.0102089643478394
Validation loss: 2.1819426119327545

Epoch: 5| Step: 4
Training loss: 1.326725721359253
Validation loss: 2.1950003852446875

Epoch: 5| Step: 5
Training loss: 1.1992930173873901
Validation loss: 2.1959505329529443

Epoch: 5| Step: 6
Training loss: 1.0034621953964233
Validation loss: 2.1797850330670676

Epoch: 5| Step: 7
Training loss: 1.7916326522827148
Validation loss: 2.1632690727710724

Epoch: 5| Step: 8
Training loss: 1.8392492532730103
Validation loss: 2.191621502240499

Epoch: 5| Step: 9
Training loss: 1.8318777084350586
Validation loss: 2.2006399432818093

Epoch: 5| Step: 10
Training loss: 0.7219647169113159
Validation loss: 2.21310788889726

Epoch: 5| Step: 11
Training loss: 0.588516116142273
Validation loss: 2.1559532483418784

Epoch: 366| Step: 0
Training loss: 1.5571001768112183
Validation loss: 2.200638105471929

Epoch: 5| Step: 1
Training loss: 1.7755355834960938
Validation loss: 2.244990905125936

Epoch: 5| Step: 2
Training loss: 1.3713016510009766
Validation loss: 2.2066035121679306

Epoch: 5| Step: 3
Training loss: 1.5218689441680908
Validation loss: 2.1803668091694512

Epoch: 5| Step: 4
Training loss: 1.2309523820877075
Validation loss: 2.190235753854116

Epoch: 5| Step: 5
Training loss: 0.863781750202179
Validation loss: 2.18318772315979

Epoch: 5| Step: 6
Training loss: 0.9853545427322388
Validation loss: 2.180268814166387

Epoch: 5| Step: 7
Training loss: 1.7163692712783813
Validation loss: 2.1923855443795524

Epoch: 5| Step: 8
Training loss: 1.2660961151123047
Validation loss: 2.2099536756674447

Epoch: 5| Step: 9
Training loss: 1.9019460678100586
Validation loss: 2.1761551052331924

Epoch: 5| Step: 10
Training loss: 1.4239428043365479
Validation loss: 2.1580186088879905

Epoch: 5| Step: 11
Training loss: 0.9493496417999268
Validation loss: 2.180181955297788

Epoch: 367| Step: 0
Training loss: 1.7311763763427734
Validation loss: 2.134698902567228

Epoch: 5| Step: 1
Training loss: 1.06803297996521
Validation loss: 2.207061360279719

Epoch: 5| Step: 2
Training loss: 1.0110493898391724
Validation loss: 2.17451773583889

Epoch: 5| Step: 3
Training loss: 1.0694546699523926
Validation loss: 2.1423428704341254

Epoch: 5| Step: 4
Training loss: 1.2136883735656738
Validation loss: 2.174502765138944

Epoch: 5| Step: 5
Training loss: 1.637094497680664
Validation loss: 2.221241941054662

Epoch: 5| Step: 6
Training loss: 1.0786316394805908
Validation loss: 2.2108711252609887

Epoch: 5| Step: 7
Training loss: 1.5307599306106567
Validation loss: 2.1602744857470193

Epoch: 5| Step: 8
Training loss: 1.3520952463150024
Validation loss: 2.222339083751043

Epoch: 5| Step: 9
Training loss: 1.3896671533584595
Validation loss: 2.1893870880206427

Epoch: 5| Step: 10
Training loss: 1.7604137659072876
Validation loss: 2.1728516270716987

Epoch: 5| Step: 11
Training loss: 3.235466957092285
Validation loss: 2.1803413927555084

Epoch: 368| Step: 0
Training loss: 1.0714787244796753
Validation loss: 2.1929881076018014

Epoch: 5| Step: 1
Training loss: 1.2494398355484009
Validation loss: 2.1606221745411553

Epoch: 5| Step: 2
Training loss: 1.636338472366333
Validation loss: 2.1889761686325073

Epoch: 5| Step: 3
Training loss: 1.407078742980957
Validation loss: 2.21851413945357

Epoch: 5| Step: 4
Training loss: 1.1224644184112549
Validation loss: 2.1997664322455726

Epoch: 5| Step: 5
Training loss: 1.2218564748764038
Validation loss: 2.1638482362031937

Epoch: 5| Step: 6
Training loss: 2.062737226486206
Validation loss: 2.1993708511193595

Epoch: 5| Step: 7
Training loss: 1.6544965505599976
Validation loss: 2.20541421075662

Epoch: 5| Step: 8
Training loss: 1.7574427127838135
Validation loss: 2.1925926407178244

Epoch: 5| Step: 9
Training loss: 1.1814353466033936
Validation loss: 2.1906652003526688

Epoch: 5| Step: 10
Training loss: 1.352569341659546
Validation loss: 2.2364593942960105

Epoch: 5| Step: 11
Training loss: 1.0554494857788086
Validation loss: 2.179859757423401

Epoch: 369| Step: 0
Training loss: 1.1612985134124756
Validation loss: 2.2020958761374154

Epoch: 5| Step: 1
Training loss: 0.909959614276886
Validation loss: 2.2224807341893515

Epoch: 5| Step: 2
Training loss: 1.2553441524505615
Validation loss: 2.2242722660303116

Epoch: 5| Step: 3
Training loss: 1.5997834205627441
Validation loss: 2.237175534168879

Epoch: 5| Step: 4
Training loss: 1.5966589450836182
Validation loss: 2.1994113326072693

Epoch: 5| Step: 5
Training loss: 1.385409951210022
Validation loss: 2.198161562283834

Epoch: 5| Step: 6
Training loss: 1.9182186126708984
Validation loss: 2.2002244095007577

Epoch: 5| Step: 7
Training loss: 1.2821738719940186
Validation loss: 2.2384175260861716

Epoch: 5| Step: 8
Training loss: 1.4148595333099365
Validation loss: 2.219572434822718

Epoch: 5| Step: 9
Training loss: 1.2486225366592407
Validation loss: 2.227901130914688

Epoch: 5| Step: 10
Training loss: 1.5779736042022705
Validation loss: 2.2113587905963263

Epoch: 5| Step: 11
Training loss: 1.1541228294372559
Validation loss: 2.205748359362284

Epoch: 370| Step: 0
Training loss: 1.74356210231781
Validation loss: 2.2140208085378013

Epoch: 5| Step: 1
Training loss: 0.9216644167900085
Validation loss: 2.1902965803941092

Epoch: 5| Step: 2
Training loss: 1.3980506658554077
Validation loss: 2.206840544939041

Epoch: 5| Step: 3
Training loss: 1.600407600402832
Validation loss: 2.1751415530840554

Epoch: 5| Step: 4
Training loss: 0.8606674075126648
Validation loss: 2.228553439180056

Epoch: 5| Step: 5
Training loss: 0.9539534449577332
Validation loss: 2.2112341125806174

Epoch: 5| Step: 6
Training loss: 1.6459344625473022
Validation loss: 2.2348207930723825

Epoch: 5| Step: 7
Training loss: 1.3148316144943237
Validation loss: 2.275388782223066

Epoch: 5| Step: 8
Training loss: 1.2525694370269775
Validation loss: 2.1827785025040307

Epoch: 5| Step: 9
Training loss: 2.1262001991271973
Validation loss: 2.230869104464849

Epoch: 5| Step: 10
Training loss: 1.4702684879302979
Validation loss: 2.2125247518221536

Epoch: 5| Step: 11
Training loss: 0.6876106262207031
Validation loss: 2.2543317625919976

Epoch: 371| Step: 0
Training loss: 1.8166710138320923
Validation loss: 2.245218833287557

Epoch: 5| Step: 1
Training loss: 1.2504708766937256
Validation loss: 2.221814751625061

Epoch: 5| Step: 2
Training loss: 0.9878617525100708
Validation loss: 2.1886297265688577

Epoch: 5| Step: 3
Training loss: 1.7023388147354126
Validation loss: 2.2118807087341943

Epoch: 5| Step: 4
Training loss: 0.9993990659713745
Validation loss: 2.156609758734703

Epoch: 5| Step: 5
Training loss: 1.600276231765747
Validation loss: 2.1592600544293723

Epoch: 5| Step: 6
Training loss: 2.2022171020507812
Validation loss: 2.1715660293896994

Epoch: 5| Step: 7
Training loss: 1.4998939037322998
Validation loss: 2.1937281042337418

Epoch: 5| Step: 8
Training loss: 1.3035563230514526
Validation loss: 2.2008307923873267

Epoch: 5| Step: 9
Training loss: 1.084777593612671
Validation loss: 2.1640547613302865

Epoch: 5| Step: 10
Training loss: 1.0277774333953857
Validation loss: 2.1196368088324866

Epoch: 5| Step: 11
Training loss: 0.4466671645641327
Validation loss: 2.1499187350273132

Epoch: 372| Step: 0
Training loss: 1.1577889919281006
Validation loss: 2.161334882179896

Epoch: 5| Step: 1
Training loss: 1.391047477722168
Validation loss: 2.1499115427335105

Epoch: 5| Step: 2
Training loss: 0.6686998605728149
Validation loss: 2.174999246994654

Epoch: 5| Step: 3
Training loss: 1.7459402084350586
Validation loss: 2.135650157928467

Epoch: 5| Step: 4
Training loss: 1.3665159940719604
Validation loss: 2.185279702146848

Epoch: 5| Step: 5
Training loss: 1.2416201829910278
Validation loss: 2.196163276831309

Epoch: 5| Step: 6
Training loss: 1.9868204593658447
Validation loss: 2.190577507019043

Epoch: 5| Step: 7
Training loss: 1.1116247177124023
Validation loss: 2.185467412074407

Epoch: 5| Step: 8
Training loss: 1.1397836208343506
Validation loss: 2.197931945323944

Epoch: 5| Step: 9
Training loss: 2.0131912231445312
Validation loss: 2.1746957699457803

Epoch: 5| Step: 10
Training loss: 1.1516693830490112
Validation loss: 2.188798318306605

Epoch: 5| Step: 11
Training loss: 1.228102445602417
Validation loss: 2.203496053814888

Epoch: 373| Step: 0
Training loss: 1.250732183456421
Validation loss: 2.2268304179112115

Epoch: 5| Step: 1
Training loss: 1.5870095491409302
Validation loss: 2.2299015820026398

Epoch: 5| Step: 2
Training loss: 1.5800377130508423
Validation loss: 2.251934955517451

Epoch: 5| Step: 3
Training loss: 1.3125579357147217
Validation loss: 2.1702359318733215

Epoch: 5| Step: 4
Training loss: 1.0251706838607788
Validation loss: 2.1881426672140756

Epoch: 5| Step: 5
Training loss: 1.0070210695266724
Validation loss: 2.1914632519086203

Epoch: 5| Step: 6
Training loss: 1.6302597522735596
Validation loss: 2.1993342638015747

Epoch: 5| Step: 7
Training loss: 1.871529221534729
Validation loss: 2.218217055002848

Epoch: 5| Step: 8
Training loss: 1.1324899196624756
Validation loss: 2.1714886923631034

Epoch: 5| Step: 9
Training loss: 1.414709448814392
Validation loss: 2.1894635458787284

Epoch: 5| Step: 10
Training loss: 1.5380594730377197
Validation loss: 2.2096607287724814

Epoch: 5| Step: 11
Training loss: 0.9092766642570496
Validation loss: 2.1910524368286133

Epoch: 374| Step: 0
Training loss: 1.3768702745437622
Validation loss: 2.1819521685441337

Epoch: 5| Step: 1
Training loss: 1.0311853885650635
Validation loss: 2.1792581925789514

Epoch: 5| Step: 2
Training loss: 1.5764596462249756
Validation loss: 2.154135892788569

Epoch: 5| Step: 3
Training loss: 1.9688419103622437
Validation loss: 2.2125807652870813

Epoch: 5| Step: 4
Training loss: 1.9621856212615967
Validation loss: 2.1801344007253647

Epoch: 5| Step: 5
Training loss: 1.009704828262329
Validation loss: 2.1786410907904306

Epoch: 5| Step: 6
Training loss: 1.2356626987457275
Validation loss: 2.2026121815045676

Epoch: 5| Step: 7
Training loss: 0.9454512596130371
Validation loss: 2.2004140814145408

Epoch: 5| Step: 8
Training loss: 1.2528140544891357
Validation loss: 2.2078824043273926

Epoch: 5| Step: 9
Training loss: 1.1212694644927979
Validation loss: 2.2432733476161957

Epoch: 5| Step: 10
Training loss: 1.2516855001449585
Validation loss: 2.2006199955940247

Epoch: 5| Step: 11
Training loss: 2.8114211559295654
Validation loss: 2.179756542046865

Epoch: 375| Step: 0
Training loss: 0.6337774991989136
Validation loss: 2.1688921004533768

Epoch: 5| Step: 1
Training loss: 1.0489810705184937
Validation loss: 2.223729113737742

Epoch: 5| Step: 2
Training loss: 0.9745597839355469
Validation loss: 2.2249996066093445

Epoch: 5| Step: 3
Training loss: 1.0804407596588135
Validation loss: 2.2098218301932016

Epoch: 5| Step: 4
Training loss: 1.469153642654419
Validation loss: 2.194681932528814

Epoch: 5| Step: 5
Training loss: 1.6991506814956665
Validation loss: 2.206112096707026

Epoch: 5| Step: 6
Training loss: 1.0670301914215088
Validation loss: 2.1970103283723197

Epoch: 5| Step: 7
Training loss: 1.9923765659332275
Validation loss: 2.2197620819012323

Epoch: 5| Step: 8
Training loss: 1.3250843286514282
Validation loss: 2.225132887562116

Epoch: 5| Step: 9
Training loss: 1.844085693359375
Validation loss: 2.2406057318051658

Epoch: 5| Step: 10
Training loss: 1.4093890190124512
Validation loss: 2.233458270629247

Epoch: 5| Step: 11
Training loss: 2.1055331230163574
Validation loss: 2.2095274329185486

Epoch: 376| Step: 0
Training loss: 1.2605316638946533
Validation loss: 2.235414912303289

Epoch: 5| Step: 1
Training loss: 1.2201460599899292
Validation loss: 2.2296961744626365

Epoch: 5| Step: 2
Training loss: 1.32663094997406
Validation loss: 2.2136184026797614

Epoch: 5| Step: 3
Training loss: 1.1054821014404297
Validation loss: 2.2269963721434274

Epoch: 5| Step: 4
Training loss: 1.5641505718231201
Validation loss: 2.218392570813497

Epoch: 5| Step: 5
Training loss: 1.698251485824585
Validation loss: 2.210040499766668

Epoch: 5| Step: 6
Training loss: 1.5100741386413574
Validation loss: 2.198533614476522

Epoch: 5| Step: 7
Training loss: 1.691185712814331
Validation loss: 2.212274899085363

Epoch: 5| Step: 8
Training loss: 0.9481617212295532
Validation loss: 2.2107465664545694

Epoch: 5| Step: 9
Training loss: 1.0029737949371338
Validation loss: 2.22284401456515

Epoch: 5| Step: 10
Training loss: 1.2030622959136963
Validation loss: 2.2024392634630203

Epoch: 5| Step: 11
Training loss: 1.5427967309951782
Validation loss: 2.223431388537089

Epoch: 377| Step: 0
Training loss: 1.3316084146499634
Validation loss: 2.2034869541724524

Epoch: 5| Step: 1
Training loss: 1.6227195262908936
Validation loss: 2.2133342077334723

Epoch: 5| Step: 2
Training loss: 2.0660946369171143
Validation loss: 2.2442376166582108

Epoch: 5| Step: 3
Training loss: 0.6912854313850403
Validation loss: 2.2807884017626443

Epoch: 5| Step: 4
Training loss: 1.1781578063964844
Validation loss: 2.221426914135615

Epoch: 5| Step: 5
Training loss: 1.1843217611312866
Validation loss: 2.2350711276133857

Epoch: 5| Step: 6
Training loss: 1.0081379413604736
Validation loss: 2.1863466997941337

Epoch: 5| Step: 7
Training loss: 1.5431082248687744
Validation loss: 2.2109831670920053

Epoch: 5| Step: 8
Training loss: 1.218226432800293
Validation loss: 2.225413680076599

Epoch: 5| Step: 9
Training loss: 1.349094271659851
Validation loss: 2.2231710255146027

Epoch: 5| Step: 10
Training loss: 1.4522414207458496
Validation loss: 2.233003924290339

Epoch: 5| Step: 11
Training loss: 0.7952936887741089
Validation loss: 2.2477741042772927

Epoch: 378| Step: 0
Training loss: 1.704401969909668
Validation loss: 2.244531442721685

Epoch: 5| Step: 1
Training loss: 1.4066863059997559
Validation loss: 2.212658812602361

Epoch: 5| Step: 2
Training loss: 1.1731281280517578
Validation loss: 2.204672396183014

Epoch: 5| Step: 3
Training loss: 1.3278828859329224
Validation loss: 2.2291676104068756

Epoch: 5| Step: 4
Training loss: 1.312809705734253
Validation loss: 2.1925936738650003

Epoch: 5| Step: 5
Training loss: 1.262333869934082
Validation loss: 2.203114757935206

Epoch: 5| Step: 6
Training loss: 1.441015601158142
Validation loss: 2.1853719502687454

Epoch: 5| Step: 7
Training loss: 2.1242778301239014
Validation loss: 2.231942077477773

Epoch: 5| Step: 8
Training loss: 1.5137302875518799
Validation loss: 2.258307248353958

Epoch: 5| Step: 9
Training loss: 1.2869012355804443
Validation loss: 2.2314445475737252

Epoch: 5| Step: 10
Training loss: 1.6447290182113647
Validation loss: 2.210141325990359

Epoch: 5| Step: 11
Training loss: 2.341498374938965
Validation loss: 2.2411659359931946

Epoch: 379| Step: 0
Training loss: 1.548018217086792
Validation loss: 2.2594422648350396

Epoch: 5| Step: 1
Training loss: 1.3853331804275513
Validation loss: 2.2490775336821875

Epoch: 5| Step: 2
Training loss: 1.3248052597045898
Validation loss: 2.2512634148200354

Epoch: 5| Step: 3
Training loss: 1.6397838592529297
Validation loss: 2.247701088587443

Epoch: 5| Step: 4
Training loss: 1.265117883682251
Validation loss: 2.2377269715070724

Epoch: 5| Step: 5
Training loss: 1.528963565826416
Validation loss: 2.210274467865626

Epoch: 5| Step: 6
Training loss: 1.0861965417861938
Validation loss: 2.2241646697123847

Epoch: 5| Step: 7
Training loss: 1.8150691986083984
Validation loss: 2.205085734526316

Epoch: 5| Step: 8
Training loss: 1.716332197189331
Validation loss: 2.271097948153814

Epoch: 5| Step: 9
Training loss: 1.3114551305770874
Validation loss: 2.2477713028589883

Epoch: 5| Step: 10
Training loss: 1.2760423421859741
Validation loss: 2.2515399903059006

Epoch: 5| Step: 11
Training loss: 2.05218243598938
Validation loss: 2.2639233072598777

Epoch: 380| Step: 0
Training loss: 1.3838976621627808
Validation loss: 2.244621748725573

Epoch: 5| Step: 1
Training loss: 1.6428025960922241
Validation loss: 2.221104403336843

Epoch: 5| Step: 2
Training loss: 1.9129825830459595
Validation loss: 2.248662158846855

Epoch: 5| Step: 3
Training loss: 1.0341461896896362
Validation loss: 2.254512051741282

Epoch: 5| Step: 4
Training loss: 1.3820370435714722
Validation loss: 2.2396744837363562

Epoch: 5| Step: 5
Training loss: 0.7966357469558716
Validation loss: 2.2302157630523047

Epoch: 5| Step: 6
Training loss: 1.1663652658462524
Validation loss: 2.2410444716612496

Epoch: 5| Step: 7
Training loss: 1.0161365270614624
Validation loss: 2.2622916400432587

Epoch: 5| Step: 8
Training loss: 1.3704876899719238
Validation loss: 2.248716672261556

Epoch: 5| Step: 9
Training loss: 1.2674974203109741
Validation loss: 2.286754826704661

Epoch: 5| Step: 10
Training loss: 1.1531193256378174
Validation loss: 2.2367782592773438

Epoch: 5| Step: 11
Training loss: 3.4390783309936523
Validation loss: 2.25345815718174

Epoch: 381| Step: 0
Training loss: 1.4528684616088867
Validation loss: 2.2259101569652557

Epoch: 5| Step: 1
Training loss: 1.5380332469940186
Validation loss: 2.2221757719914117

Epoch: 5| Step: 2
Training loss: 1.248904824256897
Validation loss: 2.254025916258494

Epoch: 5| Step: 3
Training loss: 1.0153634548187256
Validation loss: 2.261512368917465

Epoch: 5| Step: 4
Training loss: 1.9194854497909546
Validation loss: 2.2535747786362967

Epoch: 5| Step: 5
Training loss: 1.379520058631897
Validation loss: 2.230623538295428

Epoch: 5| Step: 6
Training loss: 1.2947524785995483
Validation loss: 2.2553965151309967

Epoch: 5| Step: 7
Training loss: 1.1103216409683228
Validation loss: 2.19103995958964

Epoch: 5| Step: 8
Training loss: 1.230375051498413
Validation loss: 2.2470143884420395

Epoch: 5| Step: 9
Training loss: 1.1705689430236816
Validation loss: 2.2790304074684777

Epoch: 5| Step: 10
Training loss: 1.589207410812378
Validation loss: 2.275175948937734

Epoch: 5| Step: 11
Training loss: 2.416877031326294
Validation loss: 2.242646043499311

Epoch: 382| Step: 0
Training loss: 1.7029831409454346
Validation loss: 2.2443540543317795

Epoch: 5| Step: 1
Training loss: 1.6409022808074951
Validation loss: 2.2135157684485116

Epoch: 5| Step: 2
Training loss: 1.1934444904327393
Validation loss: 2.245278999209404

Epoch: 5| Step: 3
Training loss: 0.8645831942558289
Validation loss: 2.2422472337881723

Epoch: 5| Step: 4
Training loss: 0.9627671241760254
Validation loss: 2.25666614373525

Epoch: 5| Step: 5
Training loss: 1.2724530696868896
Validation loss: 2.2722030778725943

Epoch: 5| Step: 6
Training loss: 1.516394019126892
Validation loss: 2.2443180878957114

Epoch: 5| Step: 7
Training loss: 1.4924372434616089
Validation loss: 2.2746131072441735

Epoch: 5| Step: 8
Training loss: 2.002033233642578
Validation loss: 2.234812021255493

Epoch: 5| Step: 9
Training loss: 1.3165677785873413
Validation loss: 2.2286890745162964

Epoch: 5| Step: 10
Training loss: 1.4290878772735596
Validation loss: 2.2400383055210114

Epoch: 5| Step: 11
Training loss: 0.9146767258644104
Validation loss: 2.2321725686391196

Epoch: 383| Step: 0
Training loss: 1.892706274986267
Validation loss: 2.206094428896904

Epoch: 5| Step: 1
Training loss: 1.5959800481796265
Validation loss: 2.214593062798182

Epoch: 5| Step: 2
Training loss: 1.311760663986206
Validation loss: 2.2761993060509362

Epoch: 5| Step: 3
Training loss: 1.6119346618652344
Validation loss: 2.2364649573961892

Epoch: 5| Step: 4
Training loss: 1.1407054662704468
Validation loss: 2.256432597835859

Epoch: 5| Step: 5
Training loss: 0.6840547323226929
Validation loss: 2.278028388818105

Epoch: 5| Step: 6
Training loss: 0.9786057472229004
Validation loss: 2.265656699736913

Epoch: 5| Step: 7
Training loss: 1.7030836343765259
Validation loss: 2.2640872250000634

Epoch: 5| Step: 8
Training loss: 1.5924866199493408
Validation loss: 2.24953422943751

Epoch: 5| Step: 9
Training loss: 1.0586450099945068
Validation loss: 2.2351737221082053

Epoch: 5| Step: 10
Training loss: 1.2657291889190674
Validation loss: 2.246336117386818

Epoch: 5| Step: 11
Training loss: 1.0072253942489624
Validation loss: 2.2565452257792153

Epoch: 384| Step: 0
Training loss: 1.1176661252975464
Validation loss: 2.263362059990565

Epoch: 5| Step: 1
Training loss: 1.5372194051742554
Validation loss: 2.230066438515981

Epoch: 5| Step: 2
Training loss: 1.5198590755462646
Validation loss: 2.261682868003845

Epoch: 5| Step: 3
Training loss: 1.421265721321106
Validation loss: 2.2212021946907043

Epoch: 5| Step: 4
Training loss: 0.9322502017021179
Validation loss: 2.239900047580401

Epoch: 5| Step: 5
Training loss: 0.7088627815246582
Validation loss: 2.2484400967756906

Epoch: 5| Step: 6
Training loss: 1.64125657081604
Validation loss: 2.233704353372256

Epoch: 5| Step: 7
Training loss: 1.378320336341858
Validation loss: 2.2306758562723794

Epoch: 5| Step: 8
Training loss: 1.2736742496490479
Validation loss: 2.210032492876053

Epoch: 5| Step: 9
Training loss: 1.2766361236572266
Validation loss: 2.221807077527046

Epoch: 5| Step: 10
Training loss: 1.3254740238189697
Validation loss: 2.1862887094418206

Epoch: 5| Step: 11
Training loss: 1.8939018249511719
Validation loss: 2.2090966602166495

Epoch: 385| Step: 0
Training loss: 1.0275434255599976
Validation loss: 2.231775979200999

Epoch: 5| Step: 1
Training loss: 1.4922574758529663
Validation loss: 2.256824334462484

Epoch: 5| Step: 2
Training loss: 1.4079469442367554
Validation loss: 2.228949854771296

Epoch: 5| Step: 3
Training loss: 1.4342504739761353
Validation loss: 2.2109324038028717

Epoch: 5| Step: 4
Training loss: 1.480803370475769
Validation loss: 2.2140618711709976

Epoch: 5| Step: 5
Training loss: 1.1213287115097046
Validation loss: 2.2206067740917206

Epoch: 5| Step: 6
Training loss: 1.798496961593628
Validation loss: 2.2247911294301352

Epoch: 5| Step: 7
Training loss: 0.8037958145141602
Validation loss: 2.228992293278376

Epoch: 5| Step: 8
Training loss: 1.6956894397735596
Validation loss: 2.215726926922798

Epoch: 5| Step: 9
Training loss: 0.8689975738525391
Validation loss: 2.199702337384224

Epoch: 5| Step: 10
Training loss: 1.3063709735870361
Validation loss: 2.2192920545736947

Epoch: 5| Step: 11
Training loss: 1.4491509199142456
Validation loss: 2.2085673610369363

Epoch: 386| Step: 0
Training loss: 1.573360562324524
Validation loss: 2.2152439008156457

Epoch: 5| Step: 1
Training loss: 1.0442479848861694
Validation loss: 2.243934412797292

Epoch: 5| Step: 2
Training loss: 1.342766523361206
Validation loss: 2.250702122847239

Epoch: 5| Step: 3
Training loss: 0.9102336764335632
Validation loss: 2.274295379718145

Epoch: 5| Step: 4
Training loss: 1.0458990335464478
Validation loss: 2.2579757322867713

Epoch: 5| Step: 5
Training loss: 2.1240715980529785
Validation loss: 2.2563916643460593

Epoch: 5| Step: 6
Training loss: 1.0331392288208008
Validation loss: 2.25057844320933

Epoch: 5| Step: 7
Training loss: 1.7357591390609741
Validation loss: 2.226425369580587

Epoch: 5| Step: 8
Training loss: 0.913351833820343
Validation loss: 2.207892825206121

Epoch: 5| Step: 9
Training loss: 1.0750635862350464
Validation loss: 2.2490416367848716

Epoch: 5| Step: 10
Training loss: 1.4527441263198853
Validation loss: 2.23426561554273

Epoch: 5| Step: 11
Training loss: 0.5683863162994385
Validation loss: 2.2320818652709327

Epoch: 387| Step: 0
Training loss: 1.3466840982437134
Validation loss: 2.2237374087174735

Epoch: 5| Step: 1
Training loss: 1.1932265758514404
Validation loss: 2.2086463620265326

Epoch: 5| Step: 2
Training loss: 1.231330156326294
Validation loss: 2.227201282978058

Epoch: 5| Step: 3
Training loss: 1.3180469274520874
Validation loss: 2.233148063222567

Epoch: 5| Step: 4
Training loss: 1.4227091073989868
Validation loss: 2.2464804351329803

Epoch: 5| Step: 5
Training loss: 1.3990615606307983
Validation loss: 2.2419481774171195

Epoch: 5| Step: 6
Training loss: 1.9355804920196533
Validation loss: 2.214428166548411

Epoch: 5| Step: 7
Training loss: 2.2584428787231445
Validation loss: 2.228215495745341

Epoch: 5| Step: 8
Training loss: 0.9946710467338562
Validation loss: 2.232656647761663

Epoch: 5| Step: 9
Training loss: 1.5227388143539429
Validation loss: 2.276357273260752

Epoch: 5| Step: 10
Training loss: 0.7344352006912231
Validation loss: 2.2414633383353553

Epoch: 5| Step: 11
Training loss: 0.5544148683547974
Validation loss: 2.224596828222275

Epoch: 388| Step: 0
Training loss: 1.2869480848312378
Validation loss: 2.2185477217038474

Epoch: 5| Step: 1
Training loss: 2.0437347888946533
Validation loss: 2.2307064284880957

Epoch: 5| Step: 2
Training loss: 1.4706103801727295
Validation loss: 2.20206019282341

Epoch: 5| Step: 3
Training loss: 1.029038667678833
Validation loss: 2.1809154599905014

Epoch: 5| Step: 4
Training loss: 1.7441291809082031
Validation loss: 2.2037984132766724

Epoch: 5| Step: 5
Training loss: 1.096583604812622
Validation loss: 2.201033373673757

Epoch: 5| Step: 6
Training loss: 1.1065548658370972
Validation loss: 2.2565532525380454

Epoch: 5| Step: 7
Training loss: 1.399296522140503
Validation loss: 2.235711375872294

Epoch: 5| Step: 8
Training loss: 0.9964798092842102
Validation loss: 2.2267023473978043

Epoch: 5| Step: 9
Training loss: 1.2951043844223022
Validation loss: 2.2596010516087213

Epoch: 5| Step: 10
Training loss: 0.8845162391662598
Validation loss: 2.231531580289205

Epoch: 5| Step: 11
Training loss: 0.8976855278015137
Validation loss: 2.235170846184095

Epoch: 389| Step: 0
Training loss: 1.0079278945922852
Validation loss: 2.272220234076182

Epoch: 5| Step: 1
Training loss: 1.166225790977478
Validation loss: 2.256732165813446

Epoch: 5| Step: 2
Training loss: 0.8173403739929199
Validation loss: 2.2060908675193787

Epoch: 5| Step: 3
Training loss: 1.3626964092254639
Validation loss: 2.2691988746325173

Epoch: 5| Step: 4
Training loss: 2.278027296066284
Validation loss: 2.215587834517161

Epoch: 5| Step: 5
Training loss: 1.1638691425323486
Validation loss: 2.27768112719059

Epoch: 5| Step: 6
Training loss: 1.3691787719726562
Validation loss: 2.243723382552465

Epoch: 5| Step: 7
Training loss: 1.6715662479400635
Validation loss: 2.25071057677269

Epoch: 5| Step: 8
Training loss: 1.0647104978561401
Validation loss: 2.232263674338659

Epoch: 5| Step: 9
Training loss: 1.2554658651351929
Validation loss: 2.2444624106089273

Epoch: 5| Step: 10
Training loss: 0.8284009695053101
Validation loss: 2.2587282061576843

Epoch: 5| Step: 11
Training loss: 1.0293916463851929
Validation loss: 2.2540422876675925

Epoch: 390| Step: 0
Training loss: 0.9698139429092407
Validation loss: 2.250978281100591

Epoch: 5| Step: 1
Training loss: 0.8080617785453796
Validation loss: 2.2139550050099692

Epoch: 5| Step: 2
Training loss: 1.3895385265350342
Validation loss: 2.2418505748113

Epoch: 5| Step: 3
Training loss: 1.7230144739151
Validation loss: 2.2234137852986655

Epoch: 5| Step: 4
Training loss: 1.0673267841339111
Validation loss: 2.23926908771197

Epoch: 5| Step: 5
Training loss: 0.9778278470039368
Validation loss: 2.2006230552991233

Epoch: 5| Step: 6
Training loss: 1.7301582098007202
Validation loss: 2.2094621608654657

Epoch: 5| Step: 7
Training loss: 2.1484735012054443
Validation loss: 2.2192318638165793

Epoch: 5| Step: 8
Training loss: 1.0058081150054932
Validation loss: 2.1927606215079627

Epoch: 5| Step: 9
Training loss: 1.2844666242599487
Validation loss: 2.206480781237284

Epoch: 5| Step: 10
Training loss: 1.30325448513031
Validation loss: 2.1736837228139243

Epoch: 5| Step: 11
Training loss: 1.3191248178482056
Validation loss: 2.2110453943411508

Epoch: 391| Step: 0
Training loss: 1.955272912979126
Validation loss: 2.2058002948760986

Epoch: 5| Step: 1
Training loss: 0.9715777635574341
Validation loss: 2.2279288868109384

Epoch: 5| Step: 2
Training loss: 1.1208851337432861
Validation loss: 2.2431389590104422

Epoch: 5| Step: 3
Training loss: 1.6708447933197021
Validation loss: 2.244247019290924

Epoch: 5| Step: 4
Training loss: 1.2422716617584229
Validation loss: 2.1896386047204337

Epoch: 5| Step: 5
Training loss: 1.4187707901000977
Validation loss: 2.208258738120397

Epoch: 5| Step: 6
Training loss: 1.0013854503631592
Validation loss: 2.2036992410818734

Epoch: 5| Step: 7
Training loss: 1.741316795349121
Validation loss: 2.1548378467559814

Epoch: 5| Step: 8
Training loss: 1.5836271047592163
Validation loss: 2.1394651184479394

Epoch: 5| Step: 9
Training loss: 1.10500168800354
Validation loss: 2.1879279563824334

Epoch: 5| Step: 10
Training loss: 1.2075531482696533
Validation loss: 2.152923365434011

Epoch: 5| Step: 11
Training loss: 1.5769962072372437
Validation loss: 2.1613533099492392

Epoch: 392| Step: 0
Training loss: 1.2571415901184082
Validation loss: 2.1955502331256866

Epoch: 5| Step: 1
Training loss: 1.455214262008667
Validation loss: 2.234473248322805

Epoch: 5| Step: 2
Training loss: 1.3122550249099731
Validation loss: 2.1960956156253815

Epoch: 5| Step: 3
Training loss: 0.7893146872520447
Validation loss: 2.194035589694977

Epoch: 5| Step: 4
Training loss: 0.9609631299972534
Validation loss: 2.1541002790133157

Epoch: 5| Step: 5
Training loss: 0.8500558733940125
Validation loss: 2.214927444855372

Epoch: 5| Step: 6
Training loss: 1.291329264640808
Validation loss: 2.184201017022133

Epoch: 5| Step: 7
Training loss: 1.3045464754104614
Validation loss: 2.1877151330312095

Epoch: 5| Step: 8
Training loss: 1.7137447595596313
Validation loss: 2.1391870180765786

Epoch: 5| Step: 9
Training loss: 1.728945016860962
Validation loss: 2.1751872301101685

Epoch: 5| Step: 10
Training loss: 1.1092969179153442
Validation loss: 2.189417118827502

Epoch: 5| Step: 11
Training loss: 1.0906678438186646
Validation loss: 2.168215294679006

Epoch: 393| Step: 0
Training loss: 1.036537528038025
Validation loss: 2.2175589501857758

Epoch: 5| Step: 1
Training loss: 1.0645817518234253
Validation loss: 2.1929017851750054

Epoch: 5| Step: 2
Training loss: 1.074878454208374
Validation loss: 2.2070161402225494

Epoch: 5| Step: 3
Training loss: 1.4748340845108032
Validation loss: 2.2133936434984207

Epoch: 5| Step: 4
Training loss: 1.2298529148101807
Validation loss: 2.1906927277644477

Epoch: 5| Step: 5
Training loss: 1.887704610824585
Validation loss: 2.17742587129275

Epoch: 5| Step: 6
Training loss: 1.1427656412124634
Validation loss: 2.185611218214035

Epoch: 5| Step: 7
Training loss: 1.0728708505630493
Validation loss: 2.213004916906357

Epoch: 5| Step: 8
Training loss: 1.3959747552871704
Validation loss: 2.202141046524048

Epoch: 5| Step: 9
Training loss: 1.1906019449234009
Validation loss: 2.190832475821177

Epoch: 5| Step: 10
Training loss: 1.6353458166122437
Validation loss: 2.1679374674956002

Epoch: 5| Step: 11
Training loss: 0.9120053052902222
Validation loss: 2.1288613080978394

Epoch: 394| Step: 0
Training loss: 1.097630262374878
Validation loss: 2.162330910563469

Epoch: 5| Step: 1
Training loss: 0.9964233636856079
Validation loss: 2.1470439036687217

Epoch: 5| Step: 2
Training loss: 1.1544702053070068
Validation loss: 2.168295681476593

Epoch: 5| Step: 3
Training loss: 0.9996827840805054
Validation loss: 2.1887998978296914

Epoch: 5| Step: 4
Training loss: 1.8985782861709595
Validation loss: 2.176576147476832

Epoch: 5| Step: 5
Training loss: 1.3455989360809326
Validation loss: 2.193512519200643

Epoch: 5| Step: 6
Training loss: 0.5564934611320496
Validation loss: 2.223308488726616

Epoch: 5| Step: 7
Training loss: 1.920406699180603
Validation loss: 2.214288204908371

Epoch: 5| Step: 8
Training loss: 1.4813233613967896
Validation loss: 2.191251516342163

Epoch: 5| Step: 9
Training loss: 1.3450181484222412
Validation loss: 2.1694719741741815

Epoch: 5| Step: 10
Training loss: 1.3077131509780884
Validation loss: 2.1727649867534637

Epoch: 5| Step: 11
Training loss: 0.6949098110198975
Validation loss: 2.1554187585910163

Epoch: 395| Step: 0
Training loss: 1.4653054475784302
Validation loss: 2.12798073887825

Epoch: 5| Step: 1
Training loss: 1.0003340244293213
Validation loss: 2.175915002822876

Epoch: 5| Step: 2
Training loss: 1.5013223886489868
Validation loss: 2.163583089907964

Epoch: 5| Step: 3
Training loss: 1.5719754695892334
Validation loss: 2.162116895119349

Epoch: 5| Step: 4
Training loss: 1.3417242765426636
Validation loss: 2.124828507502874

Epoch: 5| Step: 5
Training loss: 1.1382701396942139
Validation loss: 2.1869356582562127

Epoch: 5| Step: 6
Training loss: 0.7376884818077087
Validation loss: 2.197250564893087

Epoch: 5| Step: 7
Training loss: 1.3285760879516602
Validation loss: 2.230600039164225

Epoch: 5| Step: 8
Training loss: 1.2291098833084106
Validation loss: 2.214188108841578

Epoch: 5| Step: 9
Training loss: 1.7372300624847412
Validation loss: 2.220588505268097

Epoch: 5| Step: 10
Training loss: 1.2908549308776855
Validation loss: 2.175845036904017

Epoch: 5| Step: 11
Training loss: 0.6308987140655518
Validation loss: 2.2127962907155356

Epoch: 396| Step: 0
Training loss: 1.5694611072540283
Validation loss: 2.1793270111083984

Epoch: 5| Step: 1
Training loss: 1.5472100973129272
Validation loss: 2.1789401272932687

Epoch: 5| Step: 2
Training loss: 1.8627811670303345
Validation loss: 2.1583434343338013

Epoch: 5| Step: 3
Training loss: 1.0908021926879883
Validation loss: 2.212767149011294

Epoch: 5| Step: 4
Training loss: 1.2793827056884766
Validation loss: 2.2031425336996713

Epoch: 5| Step: 5
Training loss: 1.2455170154571533
Validation loss: 2.2170738677183786

Epoch: 5| Step: 6
Training loss: 1.4000123739242554
Validation loss: 2.1847792714834213

Epoch: 5| Step: 7
Training loss: 1.2308192253112793
Validation loss: 2.226077675819397

Epoch: 5| Step: 8
Training loss: 1.67141592502594
Validation loss: 2.1785767326752343

Epoch: 5| Step: 9
Training loss: 0.8451825380325317
Validation loss: 2.2340547144412994

Epoch: 5| Step: 10
Training loss: 0.9207531213760376
Validation loss: 2.194025536378225

Epoch: 5| Step: 11
Training loss: 1.8864575624465942
Validation loss: 2.2251139978567758

Epoch: 397| Step: 0
Training loss: 1.0140364170074463
Validation loss: 2.243860642115275

Epoch: 5| Step: 1
Training loss: 1.781195044517517
Validation loss: 2.229437823096911

Epoch: 5| Step: 2
Training loss: 1.107776403427124
Validation loss: 2.2112634231646857

Epoch: 5| Step: 3
Training loss: 0.9929765462875366
Validation loss: 2.139307623108228

Epoch: 5| Step: 4
Training loss: 1.5326554775238037
Validation loss: 2.198652724424998

Epoch: 5| Step: 5
Training loss: 1.1875011920928955
Validation loss: 2.187177782257398

Epoch: 5| Step: 6
Training loss: 1.0615551471710205
Validation loss: 2.1772167334953942

Epoch: 5| Step: 7
Training loss: 1.704789400100708
Validation loss: 2.1879496971766152

Epoch: 5| Step: 8
Training loss: 1.1994481086730957
Validation loss: 2.213033323486646

Epoch: 5| Step: 9
Training loss: 1.126426100730896
Validation loss: 2.168233096599579

Epoch: 5| Step: 10
Training loss: 1.1205848455429077
Validation loss: 2.1986595491568246

Epoch: 5| Step: 11
Training loss: 1.3902610540390015
Validation loss: 2.1851435601711273

Epoch: 398| Step: 0
Training loss: 1.9109729528427124
Validation loss: 2.227597326040268

Epoch: 5| Step: 1
Training loss: 0.9677540063858032
Validation loss: 2.2251329123973846

Epoch: 5| Step: 2
Training loss: 0.9301787614822388
Validation loss: 2.2027317186196647

Epoch: 5| Step: 3
Training loss: 1.110674262046814
Validation loss: 2.200246940056483

Epoch: 5| Step: 4
Training loss: 1.5856640338897705
Validation loss: 2.197238271435102

Epoch: 5| Step: 5
Training loss: 0.8259137868881226
Validation loss: 2.1749933660030365

Epoch: 5| Step: 6
Training loss: 0.9700256586074829
Validation loss: 2.181248520811399

Epoch: 5| Step: 7
Training loss: 1.8005186319351196
Validation loss: 2.151848410566648

Epoch: 5| Step: 8
Training loss: 1.0680596828460693
Validation loss: 2.179249773422877

Epoch: 5| Step: 9
Training loss: 1.0574815273284912
Validation loss: 2.1577634314695993

Epoch: 5| Step: 10
Training loss: 1.4904180765151978
Validation loss: 2.1894648671150208

Epoch: 5| Step: 11
Training loss: 1.4157415628433228
Validation loss: 2.177601878841718

Epoch: 399| Step: 0
Training loss: 0.8419516682624817
Validation loss: 2.1549911300341287

Epoch: 5| Step: 1
Training loss: 1.457434892654419
Validation loss: 2.1287064850330353

Epoch: 5| Step: 2
Training loss: 1.288532018661499
Validation loss: 2.1299818456172943

Epoch: 5| Step: 3
Training loss: 1.1950011253356934
Validation loss: 2.1325427939494452

Epoch: 5| Step: 4
Training loss: 1.2309650182724
Validation loss: 2.154800921678543

Epoch: 5| Step: 5
Training loss: 1.150362253189087
Validation loss: 2.134334539373716

Epoch: 5| Step: 6
Training loss: 1.3681635856628418
Validation loss: 2.1938493649164834

Epoch: 5| Step: 7
Training loss: 0.8720490336418152
Validation loss: 2.233739192287127

Epoch: 5| Step: 8
Training loss: 1.690495252609253
Validation loss: 2.2211350997289023

Epoch: 5| Step: 9
Training loss: 1.2786026000976562
Validation loss: 2.230614493290583

Epoch: 5| Step: 10
Training loss: 1.4105722904205322
Validation loss: 2.2099975645542145

Epoch: 5| Step: 11
Training loss: 2.336668014526367
Validation loss: 2.2167935570081077

Epoch: 400| Step: 0
Training loss: 1.3213951587677002
Validation loss: 2.238495707511902

Epoch: 5| Step: 1
Training loss: 1.0937811136245728
Validation loss: 2.2305774887402854

Epoch: 5| Step: 2
Training loss: 1.4768075942993164
Validation loss: 2.221104164918264

Epoch: 5| Step: 3
Training loss: 1.1984584331512451
Validation loss: 2.2097845474878945

Epoch: 5| Step: 4
Training loss: 0.9972730875015259
Validation loss: 2.192913750807444

Epoch: 5| Step: 5
Training loss: 1.2467195987701416
Validation loss: 2.1848788609107337

Epoch: 5| Step: 6
Training loss: 0.7501999735832214
Validation loss: 2.1873600780963898

Epoch: 5| Step: 7
Training loss: 1.4591801166534424
Validation loss: 2.1908042083183923

Epoch: 5| Step: 8
Training loss: 1.2978498935699463
Validation loss: 2.191252956787745

Epoch: 5| Step: 9
Training loss: 1.9729912281036377
Validation loss: 2.1393766750892005

Epoch: 5| Step: 10
Training loss: 0.8869653940200806
Validation loss: 2.196756591399511

Epoch: 5| Step: 11
Training loss: 0.5115384459495544
Validation loss: 2.23193696141243

Epoch: 401| Step: 0
Training loss: 1.1433000564575195
Validation loss: 2.180022989710172

Epoch: 5| Step: 1
Training loss: 1.7805277109146118
Validation loss: 2.201243594288826

Epoch: 5| Step: 2
Training loss: 0.9328101873397827
Validation loss: 2.219126363595327

Epoch: 5| Step: 3
Training loss: 2.1277923583984375
Validation loss: 2.2159049610296884

Epoch: 5| Step: 4
Training loss: 2.140437364578247
Validation loss: 2.1866647650798163

Epoch: 5| Step: 5
Training loss: 0.7242153286933899
Validation loss: 2.200644666949908

Epoch: 5| Step: 6
Training loss: 1.2008203268051147
Validation loss: 2.2464968264102936

Epoch: 5| Step: 7
Training loss: 0.703193187713623
Validation loss: 2.186342711249987

Epoch: 5| Step: 8
Training loss: 0.8709657788276672
Validation loss: 2.1038963943719864

Epoch: 5| Step: 9
Training loss: 1.4299380779266357
Validation loss: 2.1648264875014624

Epoch: 5| Step: 10
Training loss: 1.016761064529419
Validation loss: 2.1285079618295035

Epoch: 5| Step: 11
Training loss: 0.6184915900230408
Validation loss: 2.142921676238378

Epoch: 402| Step: 0
Training loss: 2.1435484886169434
Validation loss: 2.135098397731781

Epoch: 5| Step: 1
Training loss: 1.0835230350494385
Validation loss: 2.1163330475489297

Epoch: 5| Step: 2
Training loss: 1.6264044046401978
Validation loss: 2.1599894215663276

Epoch: 5| Step: 3
Training loss: 1.0148674249649048
Validation loss: 2.2077038437128067

Epoch: 5| Step: 4
Training loss: 0.7042677998542786
Validation loss: 2.2303824673096337

Epoch: 5| Step: 5
Training loss: 1.1734071969985962
Validation loss: 2.2393770863612494

Epoch: 5| Step: 6
Training loss: 1.7267860174179077
Validation loss: 2.265757421652476

Epoch: 5| Step: 7
Training loss: 1.23970365524292
Validation loss: 2.2684981425603232

Epoch: 5| Step: 8
Training loss: 1.2891589403152466
Validation loss: 2.218928004304568

Epoch: 5| Step: 9
Training loss: 0.619213879108429
Validation loss: 2.2032831062873206

Epoch: 5| Step: 10
Training loss: 1.4113094806671143
Validation loss: 2.217029790083567

Epoch: 5| Step: 11
Training loss: 0.6486862897872925
Validation loss: 2.1816668609778085

Epoch: 403| Step: 0
Training loss: 1.631430983543396
Validation loss: 2.1831300457318625

Epoch: 5| Step: 1
Training loss: 1.4039947986602783
Validation loss: 2.1893051167329154

Epoch: 5| Step: 2
Training loss: 1.2005422115325928
Validation loss: 2.2119975090026855

Epoch: 5| Step: 3
Training loss: 0.7092658281326294
Validation loss: 2.2176980624596276

Epoch: 5| Step: 4
Training loss: 1.6585689783096313
Validation loss: 2.2188288221756616

Epoch: 5| Step: 5
Training loss: 0.8803303837776184
Validation loss: 2.2196579774220786

Epoch: 5| Step: 6
Training loss: 1.1289409399032593
Validation loss: 2.229656438032786

Epoch: 5| Step: 7
Training loss: 1.373483419418335
Validation loss: 2.1978018482526145

Epoch: 5| Step: 8
Training loss: 1.6441940069198608
Validation loss: 2.2118216206630072

Epoch: 5| Step: 9
Training loss: 1.4085384607315063
Validation loss: 2.208848093946775

Epoch: 5| Step: 10
Training loss: 1.1380645036697388
Validation loss: 2.1439134230216346

Epoch: 5| Step: 11
Training loss: 0.8791180849075317
Validation loss: 2.1599957843621573

Epoch: 404| Step: 0
Training loss: 1.0036509037017822
Validation loss: 2.1975316554307938

Epoch: 5| Step: 1
Training loss: 1.5093761682510376
Validation loss: 2.1732549170653024

Epoch: 5| Step: 2
Training loss: 1.069974660873413
Validation loss: 2.217439115047455

Epoch: 5| Step: 3
Training loss: 1.0691181421279907
Validation loss: 2.201946626106898

Epoch: 5| Step: 4
Training loss: 2.045137405395508
Validation loss: 2.2452454417943954

Epoch: 5| Step: 5
Training loss: 1.298782229423523
Validation loss: 2.2219640662272773

Epoch: 5| Step: 6
Training loss: 0.4947664141654968
Validation loss: 2.232240527868271

Epoch: 5| Step: 7
Training loss: 0.7791780233383179
Validation loss: 2.2131312489509583

Epoch: 5| Step: 8
Training loss: 1.1762564182281494
Validation loss: 2.2213277419408164

Epoch: 5| Step: 9
Training loss: 1.7256879806518555
Validation loss: 2.2376796156167984

Epoch: 5| Step: 10
Training loss: 1.2806336879730225
Validation loss: 2.1871448208888373

Epoch: 5| Step: 11
Training loss: 1.6873360872268677
Validation loss: 2.187255620956421

Epoch: 405| Step: 0
Training loss: 1.8464466333389282
Validation loss: 2.1653936207294464

Epoch: 5| Step: 1
Training loss: 1.3290661573410034
Validation loss: 2.198110431432724

Epoch: 5| Step: 2
Training loss: 0.8951137661933899
Validation loss: 2.1812348316113153

Epoch: 5| Step: 3
Training loss: 0.8584373593330383
Validation loss: 2.1759637147188187

Epoch: 5| Step: 4
Training loss: 1.2286570072174072
Validation loss: 2.203941116730372

Epoch: 5| Step: 5
Training loss: 1.4379783868789673
Validation loss: 2.2254751324653625

Epoch: 5| Step: 6
Training loss: 1.8160533905029297
Validation loss: 2.2057411720355353

Epoch: 5| Step: 7
Training loss: 0.8439741134643555
Validation loss: 2.1921148747205734

Epoch: 5| Step: 8
Training loss: 1.4597066640853882
Validation loss: 2.206131085753441

Epoch: 5| Step: 9
Training loss: 1.2268030643463135
Validation loss: 2.2208720048268638

Epoch: 5| Step: 10
Training loss: 0.8439216613769531
Validation loss: 2.1848989874124527

Epoch: 5| Step: 11
Training loss: 1.0399417877197266
Validation loss: 2.2170584996541343

Epoch: 406| Step: 0
Training loss: 1.1190464496612549
Validation loss: 2.2516471445560455

Epoch: 5| Step: 1
Training loss: 1.058261752128601
Validation loss: 2.1842530171076455

Epoch: 5| Step: 2
Training loss: 0.7660028338432312
Validation loss: 2.2190316369136176

Epoch: 5| Step: 3
Training loss: 1.3003103733062744
Validation loss: 2.248948886990547

Epoch: 5| Step: 4
Training loss: 1.0858556032180786
Validation loss: 2.197214037179947

Epoch: 5| Step: 5
Training loss: 0.9749038815498352
Validation loss: 2.1902159502108893

Epoch: 5| Step: 6
Training loss: 1.3884748220443726
Validation loss: 2.2024027605851493

Epoch: 5| Step: 7
Training loss: 1.5273263454437256
Validation loss: 2.1944333910942078

Epoch: 5| Step: 8
Training loss: 1.4893009662628174
Validation loss: 2.1533405731121698

Epoch: 5| Step: 9
Training loss: 1.6370567083358765
Validation loss: 2.182879870136579

Epoch: 5| Step: 10
Training loss: 1.3188645839691162
Validation loss: 2.20831490556399

Epoch: 5| Step: 11
Training loss: 0.8612123727798462
Validation loss: 2.2021698156992593

Epoch: 407| Step: 0
Training loss: 0.6014067530632019
Validation loss: 2.234782407681147

Epoch: 5| Step: 1
Training loss: 1.729783296585083
Validation loss: 2.2361170053482056

Epoch: 5| Step: 2
Training loss: 1.1754496097564697
Validation loss: 2.2550982236862183

Epoch: 5| Step: 3
Training loss: 1.6451575756072998
Validation loss: 2.239049345254898

Epoch: 5| Step: 4
Training loss: 1.2581195831298828
Validation loss: 2.210310777028402

Epoch: 5| Step: 5
Training loss: 0.8212814331054688
Validation loss: 2.2027945121129355

Epoch: 5| Step: 6
Training loss: 1.0534855127334595
Validation loss: 2.2346682300170264

Epoch: 5| Step: 7
Training loss: 1.6167945861816406
Validation loss: 2.1692810157934823

Epoch: 5| Step: 8
Training loss: 1.2318332195281982
Validation loss: 2.170718938112259

Epoch: 5| Step: 9
Training loss: 1.847039818763733
Validation loss: 2.1323365370432534

Epoch: 5| Step: 10
Training loss: 0.6625776886940002
Validation loss: 2.2152644395828247

Epoch: 5| Step: 11
Training loss: 0.7664761543273926
Validation loss: 2.201041415333748

Epoch: 408| Step: 0
Training loss: 1.1551096439361572
Validation loss: 2.195816437403361

Epoch: 5| Step: 1
Training loss: 1.622841477394104
Validation loss: 2.223605513572693

Epoch: 5| Step: 2
Training loss: 0.9037957191467285
Validation loss: 2.2688052455584207

Epoch: 5| Step: 3
Training loss: 1.6951329708099365
Validation loss: 2.2691429058710733

Epoch: 5| Step: 4
Training loss: 1.932482123374939
Validation loss: 2.24612994492054

Epoch: 5| Step: 5
Training loss: 1.1300874948501587
Validation loss: 2.239994247754415

Epoch: 5| Step: 6
Training loss: 0.6280921697616577
Validation loss: 2.2208652893702188

Epoch: 5| Step: 7
Training loss: 1.4708932638168335
Validation loss: 2.2134784708420434

Epoch: 5| Step: 8
Training loss: 1.3451604843139648
Validation loss: 2.2124661405881247

Epoch: 5| Step: 9
Training loss: 1.3168914318084717
Validation loss: 2.1806977093219757

Epoch: 5| Step: 10
Training loss: 1.2331531047821045
Validation loss: 2.138652210434278

Epoch: 5| Step: 11
Training loss: 1.6123733520507812
Validation loss: 2.19026284913222

Epoch: 409| Step: 0
Training loss: 1.1734366416931152
Validation loss: 2.1233808398246765

Epoch: 5| Step: 1
Training loss: 1.1465425491333008
Validation loss: 2.196965848406156

Epoch: 5| Step: 2
Training loss: 1.7014362812042236
Validation loss: 2.1804371376832328

Epoch: 5| Step: 3
Training loss: 1.2372125387191772
Validation loss: 2.1589333415031433

Epoch: 5| Step: 4
Training loss: 1.1978925466537476
Validation loss: 2.2439338713884354

Epoch: 5| Step: 5
Training loss: 1.6901166439056396
Validation loss: 2.239587893088659

Epoch: 5| Step: 6
Training loss: 1.4936141967773438
Validation loss: 2.2467649976412454

Epoch: 5| Step: 7
Training loss: 1.0857139825820923
Validation loss: 2.261777530113856

Epoch: 5| Step: 8
Training loss: 1.3685455322265625
Validation loss: 2.236566806832949

Epoch: 5| Step: 9
Training loss: 1.397306203842163
Validation loss: 2.2211329539616904

Epoch: 5| Step: 10
Training loss: 0.7214280962944031
Validation loss: 2.2148147175709405

Epoch: 5| Step: 11
Training loss: 1.172696828842163
Validation loss: 2.19437667230765

Epoch: 410| Step: 0
Training loss: 0.9151217341423035
Validation loss: 2.2140177488327026

Epoch: 5| Step: 1
Training loss: 0.8755108118057251
Validation loss: 2.217151294151942

Epoch: 5| Step: 2
Training loss: 1.501489281654358
Validation loss: 2.1942294190327325

Epoch: 5| Step: 3
Training loss: 0.8062319755554199
Validation loss: 2.21375306447347

Epoch: 5| Step: 4
Training loss: 1.6598360538482666
Validation loss: 2.199764092763265

Epoch: 5| Step: 5
Training loss: 1.6903873682022095
Validation loss: 2.205276280641556

Epoch: 5| Step: 6
Training loss: 1.2008498907089233
Validation loss: 2.205937231580416

Epoch: 5| Step: 7
Training loss: 0.7732580304145813
Validation loss: 2.20339406033357

Epoch: 5| Step: 8
Training loss: 1.2421257495880127
Validation loss: 2.2504317412773767

Epoch: 5| Step: 9
Training loss: 1.7212276458740234
Validation loss: 2.240994870662689

Epoch: 5| Step: 10
Training loss: 0.796395480632782
Validation loss: 2.2322321782509484

Epoch: 5| Step: 11
Training loss: 1.7532668113708496
Validation loss: 2.2519091268380484

Epoch: 411| Step: 0
Training loss: 0.755695641040802
Validation loss: 2.2330348889033

Epoch: 5| Step: 1
Training loss: 1.6274662017822266
Validation loss: 2.2478800614674888

Epoch: 5| Step: 2
Training loss: 1.2036678791046143
Validation loss: 2.2647498895724616

Epoch: 5| Step: 3
Training loss: 1.2397836446762085
Validation loss: 2.2266244292259216

Epoch: 5| Step: 4
Training loss: 1.3350799083709717
Validation loss: 2.207156683007876

Epoch: 5| Step: 5
Training loss: 1.8034067153930664
Validation loss: 2.238931576410929

Epoch: 5| Step: 6
Training loss: 1.2178322076797485
Validation loss: 2.1940581500530243

Epoch: 5| Step: 7
Training loss: 1.3892625570297241
Validation loss: 2.2328234016895294

Epoch: 5| Step: 8
Training loss: 1.3232471942901611
Validation loss: 2.2134968638420105

Epoch: 5| Step: 9
Training loss: 1.2089084386825562
Validation loss: 2.176448941230774

Epoch: 5| Step: 10
Training loss: 1.3478307723999023
Validation loss: 2.2395425587892532

Epoch: 5| Step: 11
Training loss: 0.8162600994110107
Validation loss: 2.2255804538726807

Epoch: 412| Step: 0
Training loss: 1.1077520847320557
Validation loss: 2.2688189993302026

Epoch: 5| Step: 1
Training loss: 1.227829933166504
Validation loss: 2.2795902689297995

Epoch: 5| Step: 2
Training loss: 1.4133275747299194
Validation loss: 2.2545257757107415

Epoch: 5| Step: 3
Training loss: 1.554220199584961
Validation loss: 2.266180788477262

Epoch: 5| Step: 4
Training loss: 1.4917004108428955
Validation loss: 2.2831514875094094

Epoch: 5| Step: 5
Training loss: 1.7314777374267578
Validation loss: 2.2573130428791046

Epoch: 5| Step: 6
Training loss: 1.1893171072006226
Validation loss: 2.2888318995634713

Epoch: 5| Step: 7
Training loss: 0.900155246257782
Validation loss: 2.237158164381981

Epoch: 5| Step: 8
Training loss: 1.0101385116577148
Validation loss: 2.2528085857629776

Epoch: 5| Step: 9
Training loss: 1.4159905910491943
Validation loss: 2.2089661955833435

Epoch: 5| Step: 10
Training loss: 1.5451576709747314
Validation loss: 2.207304815451304

Epoch: 5| Step: 11
Training loss: 0.9465891718864441
Validation loss: 2.2494990527629852

Epoch: 413| Step: 0
Training loss: 0.8532862663269043
Validation loss: 2.2287876904010773

Epoch: 5| Step: 1
Training loss: 1.777234673500061
Validation loss: 2.2951132158438363

Epoch: 5| Step: 2
Training loss: 1.9558264017105103
Validation loss: 2.2677008608977

Epoch: 5| Step: 3
Training loss: 1.123652458190918
Validation loss: 2.225546956062317

Epoch: 5| Step: 4
Training loss: 0.9110183715820312
Validation loss: 2.2084046403566995

Epoch: 5| Step: 5
Training loss: 1.1392385959625244
Validation loss: 2.1610077470541

Epoch: 5| Step: 6
Training loss: 1.0764414072036743
Validation loss: 2.175995950897535

Epoch: 5| Step: 7
Training loss: 1.457148790359497
Validation loss: 2.2139960527420044

Epoch: 5| Step: 8
Training loss: 0.8895173072814941
Validation loss: 2.2416193087895713

Epoch: 5| Step: 9
Training loss: 1.3105690479278564
Validation loss: 2.222886552413305

Epoch: 5| Step: 10
Training loss: 1.5978137254714966
Validation loss: 2.2185611575841904

Epoch: 5| Step: 11
Training loss: 1.5346702337265015
Validation loss: 2.177851294477781

Epoch: 414| Step: 0
Training loss: 1.2399241924285889
Validation loss: 2.2034677962462106

Epoch: 5| Step: 1
Training loss: 1.5049949884414673
Validation loss: 2.172411864002546

Epoch: 5| Step: 2
Training loss: 1.3245108127593994
Validation loss: 2.141374424099922

Epoch: 5| Step: 3
Training loss: 1.4840235710144043
Validation loss: 2.148452788591385

Epoch: 5| Step: 4
Training loss: 1.2205795049667358
Validation loss: 2.1111696561177573

Epoch: 5| Step: 5
Training loss: 0.9789875745773315
Validation loss: 2.125864108403524

Epoch: 5| Step: 6
Training loss: 1.4507216215133667
Validation loss: 2.13552588224411

Epoch: 5| Step: 7
Training loss: 1.3790075778961182
Validation loss: 2.1329309046268463

Epoch: 5| Step: 8
Training loss: 0.8802115321159363
Validation loss: 2.1604294379552207

Epoch: 5| Step: 9
Training loss: 1.2530982494354248
Validation loss: 2.220380892356237

Epoch: 5| Step: 10
Training loss: 1.3531720638275146
Validation loss: 2.2087501337130866

Epoch: 5| Step: 11
Training loss: 1.2458221912384033
Validation loss: 2.2115225543578467

Epoch: 415| Step: 0
Training loss: 1.5788440704345703
Validation loss: 2.2051123678684235

Epoch: 5| Step: 1
Training loss: 1.0767558813095093
Validation loss: 2.1786099870999656

Epoch: 5| Step: 2
Training loss: 1.3035551309585571
Validation loss: 2.1739497433106103

Epoch: 5| Step: 3
Training loss: 1.344978928565979
Validation loss: 2.146789704759916

Epoch: 5| Step: 4
Training loss: 0.9552539587020874
Validation loss: 2.2307124535242715

Epoch: 5| Step: 5
Training loss: 1.3398864269256592
Validation loss: 2.1162939071655273

Epoch: 5| Step: 6
Training loss: 1.3709527254104614
Validation loss: 2.1610675056775412

Epoch: 5| Step: 7
Training loss: 0.9310035705566406
Validation loss: 2.2288375000158944

Epoch: 5| Step: 8
Training loss: 1.2356853485107422
Validation loss: 2.2028435120979943

Epoch: 5| Step: 9
Training loss: 0.6679608821868896
Validation loss: 2.2143206049998603

Epoch: 5| Step: 10
Training loss: 1.5008440017700195
Validation loss: 2.2453595399856567

Epoch: 5| Step: 11
Training loss: 0.5918068289756775
Validation loss: 2.2483491202195487

Epoch: 416| Step: 0
Training loss: 1.1407297849655151
Validation loss: 2.186586876710256

Epoch: 5| Step: 1
Training loss: 1.6210476160049438
Validation loss: 2.2042285352945328

Epoch: 5| Step: 2
Training loss: 0.9983583688735962
Validation loss: 2.1690532763799033

Epoch: 5| Step: 3
Training loss: 0.9883099794387817
Validation loss: 2.1350014905134835

Epoch: 5| Step: 4
Training loss: 1.6917270421981812
Validation loss: 2.1537076830863953

Epoch: 5| Step: 5
Training loss: 1.5108156204223633
Validation loss: 2.145332992076874

Epoch: 5| Step: 6
Training loss: 1.1928539276123047
Validation loss: 2.17869500319163

Epoch: 5| Step: 7
Training loss: 1.066962480545044
Validation loss: 2.207922319571177

Epoch: 5| Step: 8
Training loss: 1.3758313655853271
Validation loss: 2.1860177417596183

Epoch: 5| Step: 9
Training loss: 1.4623606204986572
Validation loss: 2.2238082935412726

Epoch: 5| Step: 10
Training loss: 0.8271002769470215
Validation loss: 2.193128695090612

Epoch: 5| Step: 11
Training loss: 0.6933644413948059
Validation loss: 2.1770958602428436

Epoch: 417| Step: 0
Training loss: 1.1985148191452026
Validation loss: 2.22071040670077

Epoch: 5| Step: 1
Training loss: 0.9763976335525513
Validation loss: 2.183786297837893

Epoch: 5| Step: 2
Training loss: 1.6675536632537842
Validation loss: 2.2265335420767465

Epoch: 5| Step: 3
Training loss: 1.1498382091522217
Validation loss: 2.210237999757131

Epoch: 5| Step: 4
Training loss: 0.7896596789360046
Validation loss: 2.2111523747444153

Epoch: 5| Step: 5
Training loss: 1.0107778310775757
Validation loss: 2.209420531988144

Epoch: 5| Step: 6
Training loss: 1.1544355154037476
Validation loss: 2.19598322113355

Epoch: 5| Step: 7
Training loss: 0.7579637765884399
Validation loss: 2.1833809514840445

Epoch: 5| Step: 8
Training loss: 1.2463054656982422
Validation loss: 2.1723029712835946

Epoch: 5| Step: 9
Training loss: 1.6770431995391846
Validation loss: 2.2072983384132385

Epoch: 5| Step: 10
Training loss: 1.28020441532135
Validation loss: 2.231163243452708

Epoch: 5| Step: 11
Training loss: 1.7170497179031372
Validation loss: 2.172732944289843

Epoch: 418| Step: 0
Training loss: 1.490864634513855
Validation loss: 2.1828602155049643

Epoch: 5| Step: 1
Training loss: 1.1209194660186768
Validation loss: 2.198059896628062

Epoch: 5| Step: 2
Training loss: 1.6009032726287842
Validation loss: 2.1722679932912192

Epoch: 5| Step: 3
Training loss: 1.1273276805877686
Validation loss: 2.164520209034284

Epoch: 5| Step: 4
Training loss: 1.3111114501953125
Validation loss: 2.1890355944633484

Epoch: 5| Step: 5
Training loss: 0.9663732647895813
Validation loss: 2.2295411129792533

Epoch: 5| Step: 6
Training loss: 1.6946624517440796
Validation loss: 2.2341114034255347

Epoch: 5| Step: 7
Training loss: 0.7018521428108215
Validation loss: 2.2086798946062722

Epoch: 5| Step: 8
Training loss: 1.5624468326568604
Validation loss: 2.207929407556852

Epoch: 5| Step: 9
Training loss: 0.755660891532898
Validation loss: 2.191198324163755

Epoch: 5| Step: 10
Training loss: 1.1431264877319336
Validation loss: 2.253460625807444

Epoch: 5| Step: 11
Training loss: 0.4947960674762726
Validation loss: 2.1716501464446387

Epoch: 419| Step: 0
Training loss: 1.0430264472961426
Validation loss: 2.2156709482272468

Epoch: 5| Step: 1
Training loss: 1.4129934310913086
Validation loss: 2.199806978305181

Epoch: 5| Step: 2
Training loss: 1.4360939264297485
Validation loss: 2.258195479710897

Epoch: 5| Step: 3
Training loss: 1.2148497104644775
Validation loss: 2.229513337214788

Epoch: 5| Step: 4
Training loss: 0.6783729195594788
Validation loss: 2.215918868780136

Epoch: 5| Step: 5
Training loss: 1.4043464660644531
Validation loss: 2.176332046588262

Epoch: 5| Step: 6
Training loss: 1.243809700012207
Validation loss: 2.2194992353518805

Epoch: 5| Step: 7
Training loss: 1.3422739505767822
Validation loss: 2.1979244152704873

Epoch: 5| Step: 8
Training loss: 1.0604312419891357
Validation loss: 2.2412777145703635

Epoch: 5| Step: 9
Training loss: 0.9534921646118164
Validation loss: 2.178019175926844

Epoch: 5| Step: 10
Training loss: 0.9046555757522583
Validation loss: 2.186535209417343

Epoch: 5| Step: 11
Training loss: 1.0648503303527832
Validation loss: 2.1926887532075248

Epoch: 420| Step: 0
Training loss: 0.9794411659240723
Validation loss: 2.2048443953196206

Epoch: 5| Step: 1
Training loss: 0.9112787246704102
Validation loss: 2.1480572621027627

Epoch: 5| Step: 2
Training loss: 1.413120985031128
Validation loss: 2.1142991383870444

Epoch: 5| Step: 3
Training loss: 1.3799766302108765
Validation loss: 2.1282400091489158

Epoch: 5| Step: 4
Training loss: 1.3972053527832031
Validation loss: 2.1526722560326257

Epoch: 5| Step: 5
Training loss: 1.1827036142349243
Validation loss: 2.1875286449988685

Epoch: 5| Step: 6
Training loss: 1.8133666515350342
Validation loss: 2.2041343301534653

Epoch: 5| Step: 7
Training loss: 0.7535516023635864
Validation loss: 2.176823854446411

Epoch: 5| Step: 8
Training loss: 0.86646568775177
Validation loss: 2.1988107512394586

Epoch: 5| Step: 9
Training loss: 1.3895578384399414
Validation loss: 2.194117248058319

Epoch: 5| Step: 10
Training loss: 1.0900369882583618
Validation loss: 2.197552631298701

Epoch: 5| Step: 11
Training loss: 1.6100752353668213
Validation loss: 2.1948029001553855

Epoch: 421| Step: 0
Training loss: 1.0534061193466187
Validation loss: 2.1685829957326255

Epoch: 5| Step: 1
Training loss: 1.0558937788009644
Validation loss: 2.2198538283507028

Epoch: 5| Step: 2
Training loss: 0.9355356097221375
Validation loss: 2.19788924853007

Epoch: 5| Step: 3
Training loss: 1.227089762687683
Validation loss: 2.207771524786949

Epoch: 5| Step: 4
Training loss: 0.885033905506134
Validation loss: 2.2241365065177283

Epoch: 5| Step: 5
Training loss: 1.213071584701538
Validation loss: 2.2395487427711487

Epoch: 5| Step: 6
Training loss: 1.310860514640808
Validation loss: 2.2303289572397866

Epoch: 5| Step: 7
Training loss: 1.3647539615631104
Validation loss: 2.2680536657571793

Epoch: 5| Step: 8
Training loss: 1.3072093725204468
Validation loss: 2.2324243436257043

Epoch: 5| Step: 9
Training loss: 0.8319881558418274
Validation loss: 2.201578135291735

Epoch: 5| Step: 10
Training loss: 2.0811398029327393
Validation loss: 2.2830841640631356

Epoch: 5| Step: 11
Training loss: 0.12699449062347412
Validation loss: 2.1896053850650787

Epoch: 422| Step: 0
Training loss: 1.1218328475952148
Validation loss: 2.174344231685003

Epoch: 5| Step: 1
Training loss: 1.1077817678451538
Validation loss: 2.1992116222778955

Epoch: 5| Step: 2
Training loss: 1.2390110492706299
Validation loss: 2.1940646966298423

Epoch: 5| Step: 3
Training loss: 0.9553612470626831
Validation loss: 2.202591677506765

Epoch: 5| Step: 4
Training loss: 0.7924674153327942
Validation loss: 2.2179209142923355

Epoch: 5| Step: 5
Training loss: 1.0414037704467773
Validation loss: 2.249445994695028

Epoch: 5| Step: 6
Training loss: 1.6114956140518188
Validation loss: 2.24171781539917

Epoch: 5| Step: 7
Training loss: 1.1392090320587158
Validation loss: 2.218172162771225

Epoch: 5| Step: 8
Training loss: 1.12968111038208
Validation loss: 2.191527704397837

Epoch: 5| Step: 9
Training loss: 1.2963190078735352
Validation loss: 2.192191998163859

Epoch: 5| Step: 10
Training loss: 1.3769840002059937
Validation loss: 2.167519142230352

Epoch: 5| Step: 11
Training loss: 1.01314115524292
Validation loss: 2.1212160686651864

Epoch: 423| Step: 0
Training loss: 0.6395215392112732
Validation loss: 2.210682133833567

Epoch: 5| Step: 1
Training loss: 1.2628730535507202
Validation loss: 2.239159161845843

Epoch: 5| Step: 2
Training loss: 1.1878273487091064
Validation loss: 2.2173887491226196

Epoch: 5| Step: 3
Training loss: 1.232917308807373
Validation loss: 2.2505768537521362

Epoch: 5| Step: 4
Training loss: 1.7478958368301392
Validation loss: 2.2430969576040902

Epoch: 5| Step: 5
Training loss: 1.5694375038146973
Validation loss: 2.1933266719182334

Epoch: 5| Step: 6
Training loss: 1.0513746738433838
Validation loss: 2.207583730419477

Epoch: 5| Step: 7
Training loss: 1.2380521297454834
Validation loss: 2.211937293410301

Epoch: 5| Step: 8
Training loss: 0.8628988265991211
Validation loss: 2.2056193252404532

Epoch: 5| Step: 9
Training loss: 0.6886316537857056
Validation loss: 2.2381134033203125

Epoch: 5| Step: 10
Training loss: 1.2442152500152588
Validation loss: 2.226564347743988

Epoch: 5| Step: 11
Training loss: 0.4749142527580261
Validation loss: 2.212711756428083

Epoch: 424| Step: 0
Training loss: 0.8627222180366516
Validation loss: 2.231700321038564

Epoch: 5| Step: 1
Training loss: 1.3165743350982666
Validation loss: 2.2599814236164093

Epoch: 5| Step: 2
Training loss: 0.7555891871452332
Validation loss: 2.2418871223926544

Epoch: 5| Step: 3
Training loss: 1.516587495803833
Validation loss: 2.21992057065169

Epoch: 5| Step: 4
Training loss: 1.1092259883880615
Validation loss: 2.249207148949305

Epoch: 5| Step: 5
Training loss: 1.3496383428573608
Validation loss: 2.2250111599763236

Epoch: 5| Step: 6
Training loss: 0.8983448147773743
Validation loss: 2.2170942574739456

Epoch: 5| Step: 7
Training loss: 1.3817024230957031
Validation loss: 2.1820274045070014

Epoch: 5| Step: 8
Training loss: 1.3436914682388306
Validation loss: 2.217778002222379

Epoch: 5| Step: 9
Training loss: 1.089197039604187
Validation loss: 2.1762259751558304

Epoch: 5| Step: 10
Training loss: 1.2172633409500122
Validation loss: 2.1266533037026725

Epoch: 5| Step: 11
Training loss: 0.9057379961013794
Validation loss: 2.185139015316963

Epoch: 425| Step: 0
Training loss: 0.870571494102478
Validation loss: 2.092240417997042

Epoch: 5| Step: 1
Training loss: 1.61882746219635
Validation loss: 2.134877840677897

Epoch: 5| Step: 2
Training loss: 1.1829012632369995
Validation loss: 2.225558817386627

Epoch: 5| Step: 3
Training loss: 0.9059915542602539
Validation loss: 2.2150989174842834

Epoch: 5| Step: 4
Training loss: 0.8132890462875366
Validation loss: 2.2221168329318366

Epoch: 5| Step: 5
Training loss: 1.287996530532837
Validation loss: 2.200851415594419

Epoch: 5| Step: 6
Training loss: 1.9523547887802124
Validation loss: 2.2389789819717407

Epoch: 5| Step: 7
Training loss: 0.526134192943573
Validation loss: 2.22467211385568

Epoch: 5| Step: 8
Training loss: 0.8989855051040649
Validation loss: 2.225725789864858

Epoch: 5| Step: 9
Training loss: 1.4636666774749756
Validation loss: 2.2545173267523446

Epoch: 5| Step: 10
Training loss: 1.4925214052200317
Validation loss: 2.2041477660338082

Epoch: 5| Step: 11
Training loss: 1.0519074201583862
Validation loss: 2.1950228810310364

Epoch: 426| Step: 0
Training loss: 0.9565784335136414
Validation loss: 2.1536550174156823

Epoch: 5| Step: 1
Training loss: 0.9713374376296997
Validation loss: 2.2006075580914817

Epoch: 5| Step: 2
Training loss: 1.2250988483428955
Validation loss: 2.212354451417923

Epoch: 5| Step: 3
Training loss: 1.7642558813095093
Validation loss: 2.1688812424739203

Epoch: 5| Step: 4
Training loss: 0.7916254997253418
Validation loss: 2.2259706805149713

Epoch: 5| Step: 5
Training loss: 0.6984456777572632
Validation loss: 2.2157832086086273

Epoch: 5| Step: 6
Training loss: 1.364761233329773
Validation loss: 2.265638694167137

Epoch: 5| Step: 7
Training loss: 2.1331610679626465
Validation loss: 2.1654564092556634

Epoch: 5| Step: 8
Training loss: 1.1553484201431274
Validation loss: 2.229453588525454

Epoch: 5| Step: 9
Training loss: 1.1669527292251587
Validation loss: 2.2212277750174203

Epoch: 5| Step: 10
Training loss: 0.8770231008529663
Validation loss: 2.2282255391279855

Epoch: 5| Step: 11
Training loss: 0.8316355347633362
Validation loss: 2.2096791764100394

Epoch: 427| Step: 0
Training loss: 1.3332228660583496
Validation loss: 2.1967515448729196

Epoch: 5| Step: 1
Training loss: 1.556117296218872
Validation loss: 2.1989029993613562

Epoch: 5| Step: 2
Training loss: 1.3463164567947388
Validation loss: 2.2020091315110526

Epoch: 5| Step: 3
Training loss: 1.1091938018798828
Validation loss: 2.165844738483429

Epoch: 5| Step: 4
Training loss: 0.77293860912323
Validation loss: 2.151325603326162

Epoch: 5| Step: 5
Training loss: 1.299300193786621
Validation loss: 2.125860422849655

Epoch: 5| Step: 6
Training loss: 0.8994576334953308
Validation loss: 2.133548448483149

Epoch: 5| Step: 7
Training loss: 1.6482150554656982
Validation loss: 2.1197045892477036

Epoch: 5| Step: 8
Training loss: 0.8055909872055054
Validation loss: 2.1021324694156647

Epoch: 5| Step: 9
Training loss: 1.2802599668502808
Validation loss: 2.1371216724316278

Epoch: 5| Step: 10
Training loss: 0.6371150016784668
Validation loss: 2.1411976168553033

Epoch: 5| Step: 11
Training loss: 0.43316757678985596
Validation loss: 2.126863956451416

Epoch: 428| Step: 0
Training loss: 1.060892939567566
Validation loss: 2.190496822198232

Epoch: 5| Step: 1
Training loss: 1.6469253301620483
Validation loss: 2.184793839852015

Epoch: 5| Step: 2
Training loss: 1.4649971723556519
Validation loss: 2.1772818664709725

Epoch: 5| Step: 3
Training loss: 1.9125299453735352
Validation loss: 2.2001628379027047

Epoch: 5| Step: 4
Training loss: 1.055444359779358
Validation loss: 2.227654352784157

Epoch: 5| Step: 5
Training loss: 0.8033121228218079
Validation loss: 2.149362693230311

Epoch: 5| Step: 6
Training loss: 1.7288806438446045
Validation loss: 2.1641084055105844

Epoch: 5| Step: 7
Training loss: 1.1781682968139648
Validation loss: 2.1626761853694916

Epoch: 5| Step: 8
Training loss: 1.3677091598510742
Validation loss: 2.1961295704046884

Epoch: 5| Step: 9
Training loss: 1.012499213218689
Validation loss: 2.163209453225136

Epoch: 5| Step: 10
Training loss: 0.7777262926101685
Validation loss: 2.2195038000742593

Epoch: 5| Step: 11
Training loss: 0.7488272190093994
Validation loss: 2.228866974512736

Epoch: 429| Step: 0
Training loss: 0.5200039148330688
Validation loss: 2.2150170306364694

Epoch: 5| Step: 1
Training loss: 2.7104787826538086
Validation loss: 2.2108420729637146

Epoch: 5| Step: 2
Training loss: 1.5455783605575562
Validation loss: 2.2195467154184976

Epoch: 5| Step: 3
Training loss: 1.0982307195663452
Validation loss: 2.2128438651561737

Epoch: 5| Step: 4
Training loss: 1.1290605068206787
Validation loss: 2.2739806274573007

Epoch: 5| Step: 5
Training loss: 1.5082063674926758
Validation loss: 2.2908736964066825

Epoch: 5| Step: 6
Training loss: 0.9586860537528992
Validation loss: 2.2653113454580307

Epoch: 5| Step: 7
Training loss: 1.1863747835159302
Validation loss: 2.2344227135181427

Epoch: 5| Step: 8
Training loss: 1.3675291538238525
Validation loss: 2.205062821507454

Epoch: 5| Step: 9
Training loss: 1.102217435836792
Validation loss: 2.2248337914546332

Epoch: 5| Step: 10
Training loss: 0.7976601719856262
Validation loss: 2.25698813299338

Epoch: 5| Step: 11
Training loss: 0.9376997947692871
Validation loss: 2.258020058274269

Epoch: 430| Step: 0
Training loss: 1.4343125820159912
Validation loss: 2.2462306718031564

Epoch: 5| Step: 1
Training loss: 0.9000385999679565
Validation loss: 2.197468638420105

Epoch: 5| Step: 2
Training loss: 0.8334875106811523
Validation loss: 2.2012081841627755

Epoch: 5| Step: 3
Training loss: 1.9653432369232178
Validation loss: 2.231580158074697

Epoch: 5| Step: 4
Training loss: 1.3857977390289307
Validation loss: 2.195059726635615

Epoch: 5| Step: 5
Training loss: 1.0451648235321045
Validation loss: 2.1950699786345163

Epoch: 5| Step: 6
Training loss: 1.2448590993881226
Validation loss: 2.1637863715489707

Epoch: 5| Step: 7
Training loss: 1.1532782316207886
Validation loss: 2.2215771973133087

Epoch: 5| Step: 8
Training loss: 0.8596118092536926
Validation loss: 2.178928683201472

Epoch: 5| Step: 9
Training loss: 1.144615650177002
Validation loss: 2.2725077917178473

Epoch: 5| Step: 10
Training loss: 1.467149257659912
Validation loss: 2.2036691854397454

Epoch: 5| Step: 11
Training loss: 0.8505795001983643
Validation loss: 2.2041440109411874

Epoch: 431| Step: 0
Training loss: 1.9543644189834595
Validation loss: 2.2168130576610565

Epoch: 5| Step: 1
Training loss: 0.9662661552429199
Validation loss: 2.189651290575663

Epoch: 5| Step: 2
Training loss: 0.7738008499145508
Validation loss: 2.182778924703598

Epoch: 5| Step: 3
Training loss: 1.1042020320892334
Validation loss: 2.146217922369639

Epoch: 5| Step: 4
Training loss: 1.5433154106140137
Validation loss: 2.1461069881916046

Epoch: 5| Step: 5
Training loss: 1.14108407497406
Validation loss: 2.1209347198406854

Epoch: 5| Step: 6
Training loss: 0.7568470239639282
Validation loss: 2.152172033985456

Epoch: 5| Step: 7
Training loss: 0.9153473973274231
Validation loss: 2.118705600500107

Epoch: 5| Step: 8
Training loss: 1.7259565591812134
Validation loss: 2.174890155593554

Epoch: 5| Step: 9
Training loss: 0.8361619710922241
Validation loss: 2.181631311774254

Epoch: 5| Step: 10
Training loss: 1.0002949237823486
Validation loss: 2.151541749636332

Epoch: 5| Step: 11
Training loss: 0.5751071572303772
Validation loss: 2.212759032845497

Epoch: 432| Step: 0
Training loss: 0.9579254388809204
Validation loss: 2.135198563337326

Epoch: 5| Step: 1
Training loss: 1.2795521020889282
Validation loss: 2.2000380903482437

Epoch: 5| Step: 2
Training loss: 0.8295565843582153
Validation loss: 2.201315015554428

Epoch: 5| Step: 3
Training loss: 1.1073596477508545
Validation loss: 2.200975313782692

Epoch: 5| Step: 4
Training loss: 0.8297992944717407
Validation loss: 2.191963871320089

Epoch: 5| Step: 5
Training loss: 1.1767170429229736
Validation loss: 2.1391944338877997

Epoch: 5| Step: 6
Training loss: 1.564170479774475
Validation loss: 2.1589174966017404

Epoch: 5| Step: 7
Training loss: 0.8849107623100281
Validation loss: 2.109563320875168

Epoch: 5| Step: 8
Training loss: 1.8347036838531494
Validation loss: 2.1299277494351068

Epoch: 5| Step: 9
Training loss: 1.142071008682251
Validation loss: 2.1308047274748483

Epoch: 5| Step: 10
Training loss: 0.8471685647964478
Validation loss: 2.088073273499807

Epoch: 5| Step: 11
Training loss: 0.7101645469665527
Validation loss: 2.1272923151652017

Epoch: 433| Step: 0
Training loss: 1.180389642715454
Validation loss: 2.145906984806061

Epoch: 5| Step: 1
Training loss: 1.2580859661102295
Validation loss: 2.102489103873571

Epoch: 5| Step: 2
Training loss: 1.2977818250656128
Validation loss: 2.159927914539973

Epoch: 5| Step: 3
Training loss: 0.9864972829818726
Validation loss: 2.168920487165451

Epoch: 5| Step: 4
Training loss: 0.8636582493782043
Validation loss: 2.159226010243098

Epoch: 5| Step: 5
Training loss: 1.1446998119354248
Validation loss: 2.166308581829071

Epoch: 5| Step: 6
Training loss: 1.0625306367874146
Validation loss: 2.137678583463033

Epoch: 5| Step: 7
Training loss: 1.008974313735962
Validation loss: 2.188889185587565

Epoch: 5| Step: 8
Training loss: 1.2194340229034424
Validation loss: 2.1770721673965454

Epoch: 5| Step: 9
Training loss: 1.0511726140975952
Validation loss: 2.164293343822161

Epoch: 5| Step: 10
Training loss: 1.2130577564239502
Validation loss: 2.176384468873342

Epoch: 5| Step: 11
Training loss: 1.088114857673645
Validation loss: 2.2144442349672318

Epoch: 434| Step: 0
Training loss: 1.6515302658081055
Validation loss: 2.2053732623656592

Epoch: 5| Step: 1
Training loss: 1.1004558801651
Validation loss: 2.2073678175608316

Epoch: 5| Step: 2
Training loss: 0.9660751223564148
Validation loss: 2.196499635775884

Epoch: 5| Step: 3
Training loss: 1.42485773563385
Validation loss: 2.136695310473442

Epoch: 5| Step: 4
Training loss: 1.579073190689087
Validation loss: 2.1870489021142325

Epoch: 5| Step: 5
Training loss: 1.3531534671783447
Validation loss: 2.1711914589007697

Epoch: 5| Step: 6
Training loss: 0.49820590019226074
Validation loss: 2.1465041091044745

Epoch: 5| Step: 7
Training loss: 0.8197180032730103
Validation loss: 2.183944344520569

Epoch: 5| Step: 8
Training loss: 0.5917945504188538
Validation loss: 2.1286418239275613

Epoch: 5| Step: 9
Training loss: 1.4445228576660156
Validation loss: 2.1147303730249405

Epoch: 5| Step: 10
Training loss: 0.7710073590278625
Validation loss: 2.1447750478982925

Epoch: 5| Step: 11
Training loss: 0.7030338048934937
Validation loss: 2.1575738886992135

Epoch: 435| Step: 0
Training loss: 0.7403316497802734
Validation loss: 2.2067457884550095

Epoch: 5| Step: 1
Training loss: 1.2795690298080444
Validation loss: 2.13537535071373

Epoch: 5| Step: 2
Training loss: 1.1039860248565674
Validation loss: 2.173780952890714

Epoch: 5| Step: 3
Training loss: 1.5117919445037842
Validation loss: 2.1856393615404763

Epoch: 5| Step: 4
Training loss: 1.3142478466033936
Validation loss: 2.2139479319254556

Epoch: 5| Step: 5
Training loss: 1.209387183189392
Validation loss: 2.193888912598292

Epoch: 5| Step: 6
Training loss: 1.4811762571334839
Validation loss: 2.150867978731791

Epoch: 5| Step: 7
Training loss: 1.0193654298782349
Validation loss: 2.1642058044672012

Epoch: 5| Step: 8
Training loss: 0.629549503326416
Validation loss: 2.17690442999204

Epoch: 5| Step: 9
Training loss: 1.2022225856781006
Validation loss: 2.1578236669301987

Epoch: 5| Step: 10
Training loss: 0.82935631275177
Validation loss: 2.1645399083693824

Epoch: 5| Step: 11
Training loss: 0.9278647899627686
Validation loss: 2.1707826803127923

Epoch: 436| Step: 0
Training loss: 0.8220854997634888
Validation loss: 2.175942083199819

Epoch: 5| Step: 1
Training loss: 1.169386625289917
Validation loss: 2.159586032231649

Epoch: 5| Step: 2
Training loss: 1.2951219081878662
Validation loss: 2.1919686992963157

Epoch: 5| Step: 3
Training loss: 0.9456836581230164
Validation loss: 2.1861319045225778

Epoch: 5| Step: 4
Training loss: 0.8764387965202332
Validation loss: 2.1677721639474234

Epoch: 5| Step: 5
Training loss: 1.0853182077407837
Validation loss: 2.138892744978269

Epoch: 5| Step: 6
Training loss: 0.9510676264762878
Validation loss: 2.1950362026691437

Epoch: 5| Step: 7
Training loss: 1.532934308052063
Validation loss: 2.1753693222999573

Epoch: 5| Step: 8
Training loss: 0.9719687700271606
Validation loss: 2.1346682757139206

Epoch: 5| Step: 9
Training loss: 1.4475090503692627
Validation loss: 2.150856375694275

Epoch: 5| Step: 10
Training loss: 0.7931104302406311
Validation loss: 2.135055124759674

Epoch: 5| Step: 11
Training loss: 0.6959257125854492
Validation loss: 2.1751770079135895

Epoch: 437| Step: 0
Training loss: 0.7428065538406372
Validation loss: 2.1807208408912024

Epoch: 5| Step: 1
Training loss: 1.4080034494400024
Validation loss: 2.1353647659222283

Epoch: 5| Step: 2
Training loss: 1.0214866399765015
Validation loss: 2.1530193587144217

Epoch: 5| Step: 3
Training loss: 1.2057358026504517
Validation loss: 2.2008996506532035

Epoch: 5| Step: 4
Training loss: 1.10576331615448
Validation loss: 2.219562272230784

Epoch: 5| Step: 5
Training loss: 1.1923186779022217
Validation loss: 2.201809287071228

Epoch: 5| Step: 6
Training loss: 0.6103280782699585
Validation loss: 2.195005784432093

Epoch: 5| Step: 7
Training loss: 0.8916624784469604
Validation loss: 2.1659558018048606

Epoch: 5| Step: 8
Training loss: 1.250248670578003
Validation loss: 2.1633014927307763

Epoch: 5| Step: 9
Training loss: 0.8006521463394165
Validation loss: 2.123706564307213

Epoch: 5| Step: 10
Training loss: 1.7086766958236694
Validation loss: 2.1740075101455054

Epoch: 5| Step: 11
Training loss: 0.6072990298271179
Validation loss: 2.154183348019918

Epoch: 438| Step: 0
Training loss: 1.1025965213775635
Validation loss: 2.155685489376386

Epoch: 5| Step: 1
Training loss: 1.1490209102630615
Validation loss: 2.164017453789711

Epoch: 5| Step: 2
Training loss: 1.319218397140503
Validation loss: 2.227862074971199

Epoch: 5| Step: 3
Training loss: 1.2343660593032837
Validation loss: 2.201817418138186

Epoch: 5| Step: 4
Training loss: 0.4822046160697937
Validation loss: 2.2159087558587394

Epoch: 5| Step: 5
Training loss: 0.6794975996017456
Validation loss: 2.21294196943442

Epoch: 5| Step: 6
Training loss: 1.1418771743774414
Validation loss: 2.2446489185094833

Epoch: 5| Step: 7
Training loss: 1.7109285593032837
Validation loss: 2.2280755092700324

Epoch: 5| Step: 8
Training loss: 1.2698004245758057
Validation loss: 2.266486485799154

Epoch: 5| Step: 9
Training loss: 0.9650551080703735
Validation loss: 2.2230911453564963

Epoch: 5| Step: 10
Training loss: 0.8973619341850281
Validation loss: 2.2612445453802743

Epoch: 5| Step: 11
Training loss: 1.290989875793457
Validation loss: 2.1900606900453568

Epoch: 439| Step: 0
Training loss: 1.0589392185211182
Validation loss: 2.217899978160858

Epoch: 5| Step: 1
Training loss: 1.095191478729248
Validation loss: 2.1801348129908242

Epoch: 5| Step: 2
Training loss: 0.9358910322189331
Validation loss: 2.209335302313169

Epoch: 5| Step: 3
Training loss: 0.8731157183647156
Validation loss: 2.1943276772896447

Epoch: 5| Step: 4
Training loss: 1.2142287492752075
Validation loss: 2.170432135462761

Epoch: 5| Step: 5
Training loss: 0.8784288167953491
Validation loss: 2.203397532304128

Epoch: 5| Step: 6
Training loss: 0.869892954826355
Validation loss: 2.1591795881589255

Epoch: 5| Step: 7
Training loss: 1.4136050939559937
Validation loss: 2.190888067086538

Epoch: 5| Step: 8
Training loss: 1.1131099462509155
Validation loss: 2.1449534197648368

Epoch: 5| Step: 9
Training loss: 0.8645491600036621
Validation loss: 2.1712067971626916

Epoch: 5| Step: 10
Training loss: 1.351277470588684
Validation loss: 2.1162810772657394

Epoch: 5| Step: 11
Training loss: 1.0894362926483154
Validation loss: 2.1513971934715905

Epoch: 440| Step: 0
Training loss: 0.5433563590049744
Validation loss: 2.164197946588198

Epoch: 5| Step: 1
Training loss: 1.5999302864074707
Validation loss: 2.1853042592604957

Epoch: 5| Step: 2
Training loss: 0.8690875172615051
Validation loss: 2.203401197989782

Epoch: 5| Step: 3
Training loss: 0.8028262257575989
Validation loss: 2.191745509703954

Epoch: 5| Step: 4
Training loss: 1.26826012134552
Validation loss: 2.198841298619906

Epoch: 5| Step: 5
Training loss: 1.3061010837554932
Validation loss: 2.199943701426188

Epoch: 5| Step: 6
Training loss: 1.5385688543319702
Validation loss: 2.1423000593980155

Epoch: 5| Step: 7
Training loss: 0.8621804118156433
Validation loss: 2.173207923769951

Epoch: 5| Step: 8
Training loss: 1.0921776294708252
Validation loss: 2.158689394593239

Epoch: 5| Step: 9
Training loss: 0.9491634368896484
Validation loss: 2.1433852712313333

Epoch: 5| Step: 10
Training loss: 1.0396137237548828
Validation loss: 2.1288587798674903

Epoch: 5| Step: 11
Training loss: 0.7173388004302979
Validation loss: 2.1260739217201867

Epoch: 441| Step: 0
Training loss: 0.997035026550293
Validation loss: 2.11060697833697

Epoch: 5| Step: 1
Training loss: 1.3762784004211426
Validation loss: 2.153065487742424

Epoch: 5| Step: 2
Training loss: 1.2441822290420532
Validation loss: 2.1211419304211936

Epoch: 5| Step: 3
Training loss: 1.2020834684371948
Validation loss: 2.1133659283320108

Epoch: 5| Step: 4
Training loss: 1.100150465965271
Validation loss: 2.149195834994316

Epoch: 5| Step: 5
Training loss: 1.1087759733200073
Validation loss: 2.1647984385490417

Epoch: 5| Step: 6
Training loss: 1.5635273456573486
Validation loss: 2.1642242123683295

Epoch: 5| Step: 7
Training loss: 0.48383766412734985
Validation loss: 2.185756062467893

Epoch: 5| Step: 8
Training loss: 1.1537411212921143
Validation loss: 2.167914013067881

Epoch: 5| Step: 9
Training loss: 0.8876943588256836
Validation loss: 2.1676986813545227

Epoch: 5| Step: 10
Training loss: 0.8832546472549438
Validation loss: 2.194269229968389

Epoch: 5| Step: 11
Training loss: 0.9067930579185486
Validation loss: 2.13563264409701

Epoch: 442| Step: 0
Training loss: 1.0650100708007812
Validation loss: 2.1629923482735953

Epoch: 5| Step: 1
Training loss: 1.2227798700332642
Validation loss: 2.16704132159551

Epoch: 5| Step: 2
Training loss: 1.4955387115478516
Validation loss: 2.136862099170685

Epoch: 5| Step: 3
Training loss: 0.9776799082756042
Validation loss: 2.154320781429609

Epoch: 5| Step: 4
Training loss: 1.766646385192871
Validation loss: 2.1878608663876853

Epoch: 5| Step: 5
Training loss: 0.5477043390274048
Validation loss: 2.140540530284246

Epoch: 5| Step: 6
Training loss: 1.3377444744110107
Validation loss: 2.188692549864451

Epoch: 5| Step: 7
Training loss: 0.7784777283668518
Validation loss: 2.1886708041032157

Epoch: 5| Step: 8
Training loss: 0.5097551941871643
Validation loss: 2.1559962332248688

Epoch: 5| Step: 9
Training loss: 1.0199085474014282
Validation loss: 2.1983906775712967

Epoch: 5| Step: 10
Training loss: 1.7140896320343018
Validation loss: 2.2093869547049203

Epoch: 5| Step: 11
Training loss: 1.042582631111145
Validation loss: 2.229380319515864

Epoch: 443| Step: 0
Training loss: 1.2502052783966064
Validation loss: 2.1925819565852485

Epoch: 5| Step: 1
Training loss: 1.2149219512939453
Validation loss: 2.181711440285047

Epoch: 5| Step: 2
Training loss: 1.0262908935546875
Validation loss: 2.158784657716751

Epoch: 5| Step: 3
Training loss: 1.3620538711547852
Validation loss: 2.1841266055901847

Epoch: 5| Step: 4
Training loss: 0.6994427442550659
Validation loss: 2.1205398639043174

Epoch: 5| Step: 5
Training loss: 0.7717618942260742
Validation loss: 2.147185464700063

Epoch: 5| Step: 6
Training loss: 1.2249011993408203
Validation loss: 2.200428918004036

Epoch: 5| Step: 7
Training loss: 0.7955173850059509
Validation loss: 2.154681752125422

Epoch: 5| Step: 8
Training loss: 1.6708955764770508
Validation loss: 2.133353049556414

Epoch: 5| Step: 9
Training loss: 1.1472313404083252
Validation loss: 2.1598690499862037

Epoch: 5| Step: 10
Training loss: 0.9367005228996277
Validation loss: 2.1360251208146415

Epoch: 5| Step: 11
Training loss: 1.2372277975082397
Validation loss: 2.1703204810619354

Epoch: 444| Step: 0
Training loss: 1.4158895015716553
Validation loss: 2.1221336821715036

Epoch: 5| Step: 1
Training loss: 1.2516995668411255
Validation loss: 2.1272545903921127

Epoch: 5| Step: 2
Training loss: 1.2336868047714233
Validation loss: 2.1062411616245904

Epoch: 5| Step: 3
Training loss: 1.0264111757278442
Validation loss: 2.1597024649381638

Epoch: 5| Step: 4
Training loss: 1.4048694372177124
Validation loss: 2.1066109339396157

Epoch: 5| Step: 5
Training loss: 1.1801546812057495
Validation loss: 2.108164817094803

Epoch: 5| Step: 6
Training loss: 1.1961312294006348
Validation loss: 2.125997006893158

Epoch: 5| Step: 7
Training loss: 1.000139594078064
Validation loss: 2.2203520437081656

Epoch: 5| Step: 8
Training loss: 1.0926563739776611
Validation loss: 2.1805805265903473

Epoch: 5| Step: 9
Training loss: 0.9084485173225403
Validation loss: 2.235330502192179

Epoch: 5| Step: 10
Training loss: 0.8475929498672485
Validation loss: 2.199631005525589

Epoch: 5| Step: 11
Training loss: 1.0209472179412842
Validation loss: 2.211762949824333

Epoch: 445| Step: 0
Training loss: 1.1912206411361694
Validation loss: 2.2148887117703757

Epoch: 5| Step: 1
Training loss: 0.7940276861190796
Validation loss: 2.219710389773051

Epoch: 5| Step: 2
Training loss: 0.6811509132385254
Validation loss: 2.1797003149986267

Epoch: 5| Step: 3
Training loss: 0.7372757196426392
Validation loss: 2.1909432808558145

Epoch: 5| Step: 4
Training loss: 1.3250012397766113
Validation loss: 2.2370691299438477

Epoch: 5| Step: 5
Training loss: 1.0515766143798828
Validation loss: 2.2145192474126816

Epoch: 5| Step: 6
Training loss: 1.4597187042236328
Validation loss: 2.2142892380555472

Epoch: 5| Step: 7
Training loss: 1.632117509841919
Validation loss: 2.20770625770092

Epoch: 5| Step: 8
Training loss: 1.073157548904419
Validation loss: 2.187637517849604

Epoch: 5| Step: 9
Training loss: 1.1335055828094482
Validation loss: 2.1544607877731323

Epoch: 5| Step: 10
Training loss: 1.0195358991622925
Validation loss: 2.2011599838733673

Epoch: 5| Step: 11
Training loss: 1.8480970859527588
Validation loss: 2.201018919547399

Epoch: 446| Step: 0
Training loss: 0.9198333621025085
Validation loss: 2.258695666988691

Epoch: 5| Step: 1
Training loss: 1.4717835187911987
Validation loss: 2.2800968090693154

Epoch: 5| Step: 2
Training loss: 1.160475492477417
Validation loss: 2.2633834232886634

Epoch: 5| Step: 3
Training loss: 1.6360499858856201
Validation loss: 2.2347840865453086

Epoch: 5| Step: 4
Training loss: 0.8040728569030762
Validation loss: 2.232456003626188

Epoch: 5| Step: 5
Training loss: 1.2945747375488281
Validation loss: 2.264710227648417

Epoch: 5| Step: 6
Training loss: 0.8613349199295044
Validation loss: 2.2672781447569528

Epoch: 5| Step: 7
Training loss: 1.2296946048736572
Validation loss: 2.2091818203528724

Epoch: 5| Step: 8
Training loss: 1.0947415828704834
Validation loss: 2.231048285961151

Epoch: 5| Step: 9
Training loss: 1.088728666305542
Validation loss: 2.2063639710346856

Epoch: 5| Step: 10
Training loss: 1.4786036014556885
Validation loss: 2.198893835147222

Epoch: 5| Step: 11
Training loss: 0.736352801322937
Validation loss: 2.2382959922154746

Epoch: 447| Step: 0
Training loss: 1.9438749551773071
Validation loss: 2.29820687075456

Epoch: 5| Step: 1
Training loss: 1.9053176641464233
Validation loss: 2.219654381275177

Epoch: 5| Step: 2
Training loss: 0.956141471862793
Validation loss: 2.2352095594008765

Epoch: 5| Step: 3
Training loss: 0.9312136769294739
Validation loss: 2.17052261531353

Epoch: 5| Step: 4
Training loss: 1.077327013015747
Validation loss: 2.201299419005712

Epoch: 5| Step: 5
Training loss: 1.193207025527954
Validation loss: 2.225437119603157

Epoch: 5| Step: 6
Training loss: 1.1577106714248657
Validation loss: 2.1907451301813126

Epoch: 5| Step: 7
Training loss: 0.8662931323051453
Validation loss: 2.254538635412852

Epoch: 5| Step: 8
Training loss: 1.287689208984375
Validation loss: 2.2506494720776877

Epoch: 5| Step: 9
Training loss: 1.3230726718902588
Validation loss: 2.206450968980789

Epoch: 5| Step: 10
Training loss: 1.036535382270813
Validation loss: 2.1951306760311127

Epoch: 5| Step: 11
Training loss: 1.9395830631256104
Validation loss: 2.2049870689709983

Epoch: 448| Step: 0
Training loss: 1.061893343925476
Validation loss: 2.152336905399958

Epoch: 5| Step: 1
Training loss: 0.8428535461425781
Validation loss: 2.1415321230888367

Epoch: 5| Step: 2
Training loss: 1.8301169872283936
Validation loss: 2.1738499800364175

Epoch: 5| Step: 3
Training loss: 1.499079704284668
Validation loss: 2.2020176549752555

Epoch: 5| Step: 4
Training loss: 1.6377232074737549
Validation loss: 2.1782431304454803

Epoch: 5| Step: 5
Training loss: 1.4093472957611084
Validation loss: 2.2029099464416504

Epoch: 5| Step: 6
Training loss: 0.9942156672477722
Validation loss: 2.200357993443807

Epoch: 5| Step: 7
Training loss: 0.9963849186897278
Validation loss: 2.1409965654214225

Epoch: 5| Step: 8
Training loss: 1.3469349145889282
Validation loss: 2.209681530793508

Epoch: 5| Step: 9
Training loss: 0.8088818788528442
Validation loss: 2.2274573842684426

Epoch: 5| Step: 10
Training loss: 0.9157150387763977
Validation loss: 2.2443076968193054

Epoch: 5| Step: 11
Training loss: 0.8498834371566772
Validation loss: 2.2323388159275055

Epoch: 449| Step: 0
Training loss: 1.4486143589019775
Validation loss: 2.2513417849938073

Epoch: 5| Step: 1
Training loss: 0.549181342124939
Validation loss: 2.248735894759496

Epoch: 5| Step: 2
Training loss: 0.9279360771179199
Validation loss: 2.2714280734459558

Epoch: 5| Step: 3
Training loss: 1.2835074663162231
Validation loss: 2.2628140250841775

Epoch: 5| Step: 4
Training loss: 1.0004901885986328
Validation loss: 2.2349278926849365

Epoch: 5| Step: 5
Training loss: 1.3295787572860718
Validation loss: 2.2625141739845276

Epoch: 5| Step: 6
Training loss: 1.4751927852630615
Validation loss: 2.2487205266952515

Epoch: 5| Step: 7
Training loss: 1.5451090335845947
Validation loss: 2.265532354513804

Epoch: 5| Step: 8
Training loss: 1.00213623046875
Validation loss: 2.2462981939315796

Epoch: 5| Step: 9
Training loss: 0.6643057465553284
Validation loss: 2.2255196273326874

Epoch: 5| Step: 10
Training loss: 1.1194714307785034
Validation loss: 2.2501745025316873

Epoch: 5| Step: 11
Training loss: 0.5331946611404419
Validation loss: 2.2368537187576294

Epoch: 450| Step: 0
Training loss: 1.1428459882736206
Validation loss: 2.2069986859957376

Epoch: 5| Step: 1
Training loss: 1.090704321861267
Validation loss: 2.215952053666115

Epoch: 5| Step: 2
Training loss: 0.9259098172187805
Validation loss: 2.245430827140808

Epoch: 5| Step: 3
Training loss: 0.6796752214431763
Validation loss: 2.1736559917529426

Epoch: 5| Step: 4
Training loss: 1.3577821254730225
Validation loss: 2.234552353620529

Epoch: 5| Step: 5
Training loss: 1.0352367162704468
Validation loss: 2.2313050031661987

Epoch: 5| Step: 6
Training loss: 1.856909990310669
Validation loss: 2.1837413360675177

Epoch: 5| Step: 7
Training loss: 0.8407424688339233
Validation loss: 2.176002085208893

Epoch: 5| Step: 8
Training loss: 0.746318519115448
Validation loss: 2.2164619117975235

Epoch: 5| Step: 9
Training loss: 1.0926628112792969
Validation loss: 2.2655671586592994

Epoch: 5| Step: 10
Training loss: 1.0476353168487549
Validation loss: 2.1907733033100762

Epoch: 5| Step: 11
Training loss: 1.3346874713897705
Validation loss: 2.188643048206965

Epoch: 451| Step: 0
Training loss: 0.9141610264778137
Validation loss: 2.154592603445053

Epoch: 5| Step: 1
Training loss: 1.0845710039138794
Validation loss: 2.179155429204305

Epoch: 5| Step: 2
Training loss: 1.211104154586792
Validation loss: 2.207249234120051

Epoch: 5| Step: 3
Training loss: 0.9704623222351074
Validation loss: 2.1511049966017404

Epoch: 5| Step: 4
Training loss: 0.9956949353218079
Validation loss: 2.178270955880483

Epoch: 5| Step: 5
Training loss: 0.7407737970352173
Validation loss: 2.1492642909288406

Epoch: 5| Step: 6
Training loss: 0.6852571368217468
Validation loss: 2.1664027671019235

Epoch: 5| Step: 7
Training loss: 1.2411078214645386
Validation loss: 2.173584351936976

Epoch: 5| Step: 8
Training loss: 0.6941319704055786
Validation loss: 2.1833147555589676

Epoch: 5| Step: 9
Training loss: 1.729688286781311
Validation loss: 2.188279648621877

Epoch: 5| Step: 10
Training loss: 1.0736414194107056
Validation loss: 2.1777706344922385

Epoch: 5| Step: 11
Training loss: 0.27070480585098267
Validation loss: 2.1383003989855447

Epoch: 452| Step: 0
Training loss: 1.116715669631958
Validation loss: 2.1737229774395623

Epoch: 5| Step: 1
Training loss: 1.0999672412872314
Validation loss: 2.1188421050707498

Epoch: 5| Step: 2
Training loss: 0.608869194984436
Validation loss: 2.171311249335607

Epoch: 5| Step: 3
Training loss: 1.2070249319076538
Validation loss: 2.1556787292162576

Epoch: 5| Step: 4
Training loss: 1.1272554397583008
Validation loss: 2.1130427618821463

Epoch: 5| Step: 5
Training loss: 1.1740903854370117
Validation loss: 2.182794466614723

Epoch: 5| Step: 6
Training loss: 1.1857554912567139
Validation loss: 2.1140092660983405

Epoch: 5| Step: 7
Training loss: 0.7286490201950073
Validation loss: 2.1407438218593597

Epoch: 5| Step: 8
Training loss: 0.9842793345451355
Validation loss: 2.1762539446353912

Epoch: 5| Step: 9
Training loss: 0.6439189910888672
Validation loss: 2.146135558684667

Epoch: 5| Step: 10
Training loss: 1.1293047666549683
Validation loss: 2.1299558728933334

Epoch: 5| Step: 11
Training loss: 1.0956647396087646
Validation loss: 2.1828998972972236

Epoch: 453| Step: 0
Training loss: 0.4912700057029724
Validation loss: 2.199263741572698

Epoch: 5| Step: 1
Training loss: 1.1488134860992432
Validation loss: 2.158433551589648

Epoch: 5| Step: 2
Training loss: 0.924793541431427
Validation loss: 2.1768933733304343

Epoch: 5| Step: 3
Training loss: 1.6005032062530518
Validation loss: 2.1793831090132394

Epoch: 5| Step: 4
Training loss: 0.7382080554962158
Validation loss: 2.1755183339118958

Epoch: 5| Step: 5
Training loss: 0.9361149668693542
Validation loss: 2.2030960669120154

Epoch: 5| Step: 6
Training loss: 0.6344238519668579
Validation loss: 2.1113208035628

Epoch: 5| Step: 7
Training loss: 1.5298106670379639
Validation loss: 2.1811097810665765

Epoch: 5| Step: 8
Training loss: 1.5606008768081665
Validation loss: 2.109402522444725

Epoch: 5| Step: 9
Training loss: 0.9038921594619751
Validation loss: 2.145932152867317

Epoch: 5| Step: 10
Training loss: 0.8014278411865234
Validation loss: 2.153259575366974

Epoch: 5| Step: 11
Training loss: 0.8081820607185364
Validation loss: 2.1571477899948754

Epoch: 454| Step: 0
Training loss: 1.7800782918930054
Validation loss: 2.180330062905947

Epoch: 5| Step: 1
Training loss: 0.6080644726753235
Validation loss: 2.1742049753665924

Epoch: 5| Step: 2
Training loss: 0.9287484288215637
Validation loss: 2.1889881591002145

Epoch: 5| Step: 3
Training loss: 1.0761414766311646
Validation loss: 2.1933510502179465

Epoch: 5| Step: 4
Training loss: 0.7027286291122437
Validation loss: 2.198522686958313

Epoch: 5| Step: 5
Training loss: 0.6062353849411011
Validation loss: 2.2041963835557303

Epoch: 5| Step: 6
Training loss: 1.0152604579925537
Validation loss: 2.16680246591568

Epoch: 5| Step: 7
Training loss: 1.2022769451141357
Validation loss: 2.1780454516410828

Epoch: 5| Step: 8
Training loss: 0.704927384853363
Validation loss: 2.124991019566854

Epoch: 5| Step: 9
Training loss: 0.9631198048591614
Validation loss: 2.175829897324244

Epoch: 5| Step: 10
Training loss: 1.010805368423462
Validation loss: 2.1645607203245163

Epoch: 5| Step: 11
Training loss: 2.8668134212493896
Validation loss: 2.1659543812274933

Epoch: 455| Step: 0
Training loss: 1.0493148565292358
Validation loss: 2.1269685328006744

Epoch: 5| Step: 1
Training loss: 1.3331018686294556
Validation loss: 2.1159093379974365

Epoch: 5| Step: 2
Training loss: 0.821235179901123
Validation loss: 2.094021131594976

Epoch: 5| Step: 3
Training loss: 1.4998642206192017
Validation loss: 2.133958160877228

Epoch: 5| Step: 4
Training loss: 1.0369023084640503
Validation loss: 2.1378387014071145

Epoch: 5| Step: 5
Training loss: 0.8239861726760864
Validation loss: 2.1658394038677216

Epoch: 5| Step: 6
Training loss: 1.3427221775054932
Validation loss: 2.1871674160162606

Epoch: 5| Step: 7
Training loss: 0.6040845513343811
Validation loss: 2.187403996785482

Epoch: 5| Step: 8
Training loss: 0.9440265893936157
Validation loss: 2.1846427669127784

Epoch: 5| Step: 9
Training loss: 1.197731375694275
Validation loss: 2.214663768808047

Epoch: 5| Step: 10
Training loss: 1.1459566354751587
Validation loss: 2.230640023946762

Epoch: 5| Step: 11
Training loss: 0.710591197013855
Validation loss: 2.1766605973243713

Epoch: 456| Step: 0
Training loss: 1.3330544233322144
Validation loss: 2.232426275809606

Epoch: 5| Step: 1
Training loss: 0.935106635093689
Validation loss: 2.1727930108706155

Epoch: 5| Step: 2
Training loss: 0.5913386940956116
Validation loss: 2.1857567628224692

Epoch: 5| Step: 3
Training loss: 0.7685884237289429
Validation loss: 2.2064678172270455

Epoch: 5| Step: 4
Training loss: 0.939257800579071
Validation loss: 2.199645926554998

Epoch: 5| Step: 5
Training loss: 0.7024611234664917
Validation loss: 2.112543592850367

Epoch: 5| Step: 6
Training loss: 0.7698405981063843
Validation loss: 2.169723923007647

Epoch: 5| Step: 7
Training loss: 1.4035828113555908
Validation loss: 2.152984842658043

Epoch: 5| Step: 8
Training loss: 1.3355076313018799
Validation loss: 2.139782557884852

Epoch: 5| Step: 9
Training loss: 1.6343326568603516
Validation loss: 2.144031504789988

Epoch: 5| Step: 10
Training loss: 0.7623065114021301
Validation loss: 2.170222888390223

Epoch: 5| Step: 11
Training loss: 0.20284710824489594
Validation loss: 2.1531260510285697

Epoch: 457| Step: 0
Training loss: 1.1422755718231201
Validation loss: 2.1464565843343735

Epoch: 5| Step: 1
Training loss: 1.2242722511291504
Validation loss: 2.161008099714915

Epoch: 5| Step: 2
Training loss: 1.000230312347412
Validation loss: 2.155226454138756

Epoch: 5| Step: 3
Training loss: 1.059481143951416
Validation loss: 2.1101970871289573

Epoch: 5| Step: 4
Training loss: 0.9241121411323547
Validation loss: 2.147665351629257

Epoch: 5| Step: 5
Training loss: 0.5849220752716064
Validation loss: 2.1615869204203286

Epoch: 5| Step: 6
Training loss: 0.9775063395500183
Validation loss: 2.128515432278315

Epoch: 5| Step: 7
Training loss: 0.7414716482162476
Validation loss: 2.206292986869812

Epoch: 5| Step: 8
Training loss: 0.7990762591362
Validation loss: 2.1520186066627502

Epoch: 5| Step: 9
Training loss: 0.9380348920822144
Validation loss: 2.170960853497187

Epoch: 5| Step: 10
Training loss: 1.1588506698608398
Validation loss: 2.1127295593420663

Epoch: 5| Step: 11
Training loss: 0.8723583817481995
Validation loss: 2.1359985172748566

Epoch: 458| Step: 0
Training loss: 1.1460398435592651
Validation loss: 2.1537624498208365

Epoch: 5| Step: 1
Training loss: 1.2537293434143066
Validation loss: 2.1657094409068427

Epoch: 5| Step: 2
Training loss: 0.635727047920227
Validation loss: 2.1322253247102103

Epoch: 5| Step: 3
Training loss: 0.6331757307052612
Validation loss: 2.1490469872951508

Epoch: 5| Step: 4
Training loss: 1.2309448719024658
Validation loss: 2.139571934938431

Epoch: 5| Step: 5
Training loss: 1.0527963638305664
Validation loss: 2.119579995671908

Epoch: 5| Step: 6
Training loss: 1.1862698793411255
Validation loss: 2.1287084917227426

Epoch: 5| Step: 7
Training loss: 1.390730857849121
Validation loss: 2.1491036315759025

Epoch: 5| Step: 8
Training loss: 1.013124704360962
Validation loss: 2.1372612516085305

Epoch: 5| Step: 9
Training loss: 0.9570469856262207
Validation loss: 2.1646687040726342

Epoch: 5| Step: 10
Training loss: 1.1638561487197876
Validation loss: 2.090729534626007

Epoch: 5| Step: 11
Training loss: 0.491131067276001
Validation loss: 2.139740248521169

Epoch: 459| Step: 0
Training loss: 1.0351299047470093
Validation loss: 2.0770860066016517

Epoch: 5| Step: 1
Training loss: 0.671314537525177
Validation loss: 2.071344330906868

Epoch: 5| Step: 2
Training loss: 1.2219593524932861
Validation loss: 2.1132024427254996

Epoch: 5| Step: 3
Training loss: 1.3657869100570679
Validation loss: 2.078586831688881

Epoch: 5| Step: 4
Training loss: 0.9014900922775269
Validation loss: 2.0597424457470574

Epoch: 5| Step: 5
Training loss: 1.1515706777572632
Validation loss: 2.1359708408514657

Epoch: 5| Step: 6
Training loss: 1.5304481983184814
Validation loss: 2.1082672526439032

Epoch: 5| Step: 7
Training loss: 0.6663347482681274
Validation loss: 2.0877847969532013

Epoch: 5| Step: 8
Training loss: 0.7614259719848633
Validation loss: 2.126274580756823

Epoch: 5| Step: 9
Training loss: 0.7179352641105652
Validation loss: 2.1414972245693207

Epoch: 5| Step: 10
Training loss: 1.36239755153656
Validation loss: 2.1649047980705896

Epoch: 5| Step: 11
Training loss: 0.5384423136711121
Validation loss: 2.1575053930282593

Epoch: 460| Step: 0
Training loss: 1.0964255332946777
Validation loss: 2.1344023942947388

Epoch: 5| Step: 1
Training loss: 1.1856589317321777
Validation loss: 2.140105480949084

Epoch: 5| Step: 2
Training loss: 0.942513644695282
Validation loss: 2.135689208904902

Epoch: 5| Step: 3
Training loss: 0.9863239526748657
Validation loss: 2.0698842654625573

Epoch: 5| Step: 4
Training loss: 0.9210483431816101
Validation loss: 2.111305077870687

Epoch: 5| Step: 5
Training loss: 1.4126133918762207
Validation loss: 2.0532985677321753

Epoch: 5| Step: 6
Training loss: 0.7691288590431213
Validation loss: 2.1036608815193176

Epoch: 5| Step: 7
Training loss: 1.07771897315979
Validation loss: 2.133343448241552

Epoch: 5| Step: 8
Training loss: 1.0006464719772339
Validation loss: 2.1327030807733536

Epoch: 5| Step: 9
Training loss: 0.7691665291786194
Validation loss: 2.123118003209432

Epoch: 5| Step: 10
Training loss: 0.9148481488227844
Validation loss: 2.112017899751663

Epoch: 5| Step: 11
Training loss: 1.7537634372711182
Validation loss: 2.1265089213848114

Epoch: 461| Step: 0
Training loss: 0.7569966316223145
Validation loss: 2.119342098633448

Epoch: 5| Step: 1
Training loss: 0.7509747743606567
Validation loss: 2.0978987514972687

Epoch: 5| Step: 2
Training loss: 0.7666902542114258
Validation loss: 2.1300993065039315

Epoch: 5| Step: 3
Training loss: 1.0497276782989502
Validation loss: 2.1326140761375427

Epoch: 5| Step: 4
Training loss: 0.9031399488449097
Validation loss: 2.134956801931063

Epoch: 5| Step: 5
Training loss: 1.8196899890899658
Validation loss: 2.15850559870402

Epoch: 5| Step: 6
Training loss: 0.7719475626945496
Validation loss: 2.1379867792129517

Epoch: 5| Step: 7
Training loss: 0.9937059283256531
Validation loss: 2.131203164656957

Epoch: 5| Step: 8
Training loss: 1.1046963930130005
Validation loss: 2.137731353441874

Epoch: 5| Step: 9
Training loss: 0.8372602462768555
Validation loss: 2.139196808139483

Epoch: 5| Step: 10
Training loss: 0.6800701022148132
Validation loss: 2.114286536971728

Epoch: 5| Step: 11
Training loss: 1.984104871749878
Validation loss: 2.1384310126304626

Epoch: 462| Step: 0
Training loss: 1.0396859645843506
Validation loss: 2.1459939181804657

Epoch: 5| Step: 1
Training loss: 0.7193912863731384
Validation loss: 2.1505070527394614

Epoch: 5| Step: 2
Training loss: 1.3930251598358154
Validation loss: 2.098389064272245

Epoch: 5| Step: 3
Training loss: 1.0384680032730103
Validation loss: 2.198659429947535

Epoch: 5| Step: 4
Training loss: 1.003566861152649
Validation loss: 2.12235164642334

Epoch: 5| Step: 5
Training loss: 0.9453665614128113
Validation loss: 2.189826250076294

Epoch: 5| Step: 6
Training loss: 0.9119285345077515
Validation loss: 2.140200858314832

Epoch: 5| Step: 7
Training loss: 0.7682262063026428
Validation loss: 2.1590409030516944

Epoch: 5| Step: 8
Training loss: 0.9181981086730957
Validation loss: 2.1763442854086557

Epoch: 5| Step: 9
Training loss: 0.8105207681655884
Validation loss: 2.1192121456066766

Epoch: 5| Step: 10
Training loss: 1.031636357307434
Validation loss: 2.176130016644796

Epoch: 5| Step: 11
Training loss: 1.0010342597961426
Validation loss: 2.1698416471481323

Epoch: 463| Step: 0
Training loss: 1.2089853286743164
Validation loss: 2.1602419118086496

Epoch: 5| Step: 1
Training loss: 0.8921786546707153
Validation loss: 2.1800175309181213

Epoch: 5| Step: 2
Training loss: 1.1278942823410034
Validation loss: 2.172843982776006

Epoch: 5| Step: 3
Training loss: 1.0089799165725708
Validation loss: 2.106796915332476

Epoch: 5| Step: 4
Training loss: 0.8635624647140503
Validation loss: 2.171536306540171

Epoch: 5| Step: 5
Training loss: 0.7368618845939636
Validation loss: 2.166205406188965

Epoch: 5| Step: 6
Training loss: 0.5405533909797668
Validation loss: 2.1104446798563004

Epoch: 5| Step: 7
Training loss: 0.9315181970596313
Validation loss: 2.149723395705223

Epoch: 5| Step: 8
Training loss: 0.834622859954834
Validation loss: 2.1142416497071586

Epoch: 5| Step: 9
Training loss: 1.3626253604888916
Validation loss: 2.131192624568939

Epoch: 5| Step: 10
Training loss: 1.2943763732910156
Validation loss: 2.2020194232463837

Epoch: 5| Step: 11
Training loss: 0.6486732959747314
Validation loss: 2.136212502916654

Epoch: 464| Step: 0
Training loss: 1.2868657112121582
Validation loss: 2.1338152090708413

Epoch: 5| Step: 1
Training loss: 0.704900860786438
Validation loss: 2.122113893429438

Epoch: 5| Step: 2
Training loss: 1.2889974117279053
Validation loss: 2.1336026042699814

Epoch: 5| Step: 3
Training loss: 0.814367949962616
Validation loss: 2.1336975395679474

Epoch: 5| Step: 4
Training loss: 0.777377724647522
Validation loss: 2.1011846413215003

Epoch: 5| Step: 5
Training loss: 1.1751906871795654
Validation loss: 2.080544506510099

Epoch: 5| Step: 6
Training loss: 1.108180284500122
Validation loss: 2.1137356559435525

Epoch: 5| Step: 7
Training loss: 0.7265518307685852
Validation loss: 2.1604268898566565

Epoch: 5| Step: 8
Training loss: 0.8962481617927551
Validation loss: 2.116719370086988

Epoch: 5| Step: 9
Training loss: 0.8064533472061157
Validation loss: 2.1091468731562295

Epoch: 5| Step: 10
Training loss: 0.9733507037162781
Validation loss: 2.1181637297074

Epoch: 5| Step: 11
Training loss: 2.748521327972412
Validation loss: 2.138388236363729

Epoch: 465| Step: 0
Training loss: 1.0731791257858276
Validation loss: 2.1267760594685874

Epoch: 5| Step: 1
Training loss: 0.8108442425727844
Validation loss: 2.095411558945974

Epoch: 5| Step: 2
Training loss: 1.2291215658187866
Validation loss: 2.0796371698379517

Epoch: 5| Step: 3
Training loss: 1.0643222332000732
Validation loss: 2.097167819738388

Epoch: 5| Step: 4
Training loss: 0.6259946823120117
Validation loss: 2.1309064080317817

Epoch: 5| Step: 5
Training loss: 0.8713704347610474
Validation loss: 2.16988967359066

Epoch: 5| Step: 6
Training loss: 0.6825374364852905
Validation loss: 2.1042681833108268

Epoch: 5| Step: 7
Training loss: 0.7925891876220703
Validation loss: 2.086841250459353

Epoch: 5| Step: 8
Training loss: 1.5097334384918213
Validation loss: 2.1123753835757575

Epoch: 5| Step: 9
Training loss: 0.7075471878051758
Validation loss: 2.0680999557177224

Epoch: 5| Step: 10
Training loss: 1.110628366470337
Validation loss: 2.0494924634695053

Epoch: 5| Step: 11
Training loss: 2.9942498207092285
Validation loss: 2.0196511149406433

Epoch: 466| Step: 0
Training loss: 1.235634446144104
Validation loss: 2.0245053271452584

Epoch: 5| Step: 1
Training loss: 0.7271268963813782
Validation loss: 2.071721096833547

Epoch: 5| Step: 2
Training loss: 0.7386242151260376
Validation loss: 2.0833343118429184

Epoch: 5| Step: 3
Training loss: 0.4729928970336914
Validation loss: 2.076602563261986

Epoch: 5| Step: 4
Training loss: 1.1451534032821655
Validation loss: 2.0958692133426666

Epoch: 5| Step: 5
Training loss: 0.9662216901779175
Validation loss: 2.1194944630066552

Epoch: 5| Step: 6
Training loss: 1.9890447854995728
Validation loss: 2.0957927107810974

Epoch: 5| Step: 7
Training loss: 1.2308945655822754
Validation loss: 2.0965228180090585

Epoch: 5| Step: 8
Training loss: 0.665917694568634
Validation loss: 2.1094207763671875

Epoch: 5| Step: 9
Training loss: 0.8877164125442505
Validation loss: 2.147623519102732

Epoch: 5| Step: 10
Training loss: 1.0442402362823486
Validation loss: 2.1176493167877197

Epoch: 5| Step: 11
Training loss: 0.7440119385719299
Validation loss: 2.1286986271540322

Epoch: 467| Step: 0
Training loss: 1.1428207159042358
Validation loss: 2.2353166292111077

Epoch: 5| Step: 1
Training loss: 0.8750993609428406
Validation loss: 2.1684375206629434

Epoch: 5| Step: 2
Training loss: 1.1736923456192017
Validation loss: 2.205132707953453

Epoch: 5| Step: 3
Training loss: 0.6886266469955444
Validation loss: 2.1913147966066995

Epoch: 5| Step: 4
Training loss: 1.0111663341522217
Validation loss: 2.148153414328893

Epoch: 5| Step: 5
Training loss: 0.7102624177932739
Validation loss: 2.1773686756690345

Epoch: 5| Step: 6
Training loss: 0.8163480758666992
Validation loss: 2.1727050791184106

Epoch: 5| Step: 7
Training loss: 1.2669847011566162
Validation loss: 2.248389055331548

Epoch: 5| Step: 8
Training loss: 1.4429250955581665
Validation loss: 2.2005973954995475

Epoch: 5| Step: 9
Training loss: 1.1518179178237915
Validation loss: 2.232761094967524

Epoch: 5| Step: 10
Training loss: 1.0071979761123657
Validation loss: 2.1803176601727805

Epoch: 5| Step: 11
Training loss: 0.7832951545715332
Validation loss: 2.1224197099606195

Epoch: 468| Step: 0
Training loss: 0.7510401010513306
Validation loss: 2.1054230531056723

Epoch: 5| Step: 1
Training loss: 1.639221429824829
Validation loss: 2.147679646809896

Epoch: 5| Step: 2
Training loss: 0.7761842012405396
Validation loss: 2.1540415783723197

Epoch: 5| Step: 3
Training loss: 0.8684832453727722
Validation loss: 2.16443133354187

Epoch: 5| Step: 4
Training loss: 0.7973169684410095
Validation loss: 2.1639597316583

Epoch: 5| Step: 5
Training loss: 1.2357258796691895
Validation loss: 2.1607362826665244

Epoch: 5| Step: 6
Training loss: 0.6214160919189453
Validation loss: 2.1399897237618766

Epoch: 5| Step: 7
Training loss: 0.859730064868927
Validation loss: 2.1541327635447183

Epoch: 5| Step: 8
Training loss: 1.245314359664917
Validation loss: 2.137706309556961

Epoch: 5| Step: 9
Training loss: 0.7347744703292847
Validation loss: 2.1652584820985794

Epoch: 5| Step: 10
Training loss: 1.3821499347686768
Validation loss: 2.1579642593860626

Epoch: 5| Step: 11
Training loss: 0.8069452047348022
Validation loss: 2.093245357275009

Epoch: 469| Step: 0
Training loss: 0.6143007874488831
Validation loss: 2.15677817662557

Epoch: 5| Step: 1
Training loss: 0.5696593523025513
Validation loss: 2.113657827178637

Epoch: 5| Step: 2
Training loss: 1.229802131652832
Validation loss: 2.1262212842702866

Epoch: 5| Step: 3
Training loss: 0.6784757375717163
Validation loss: 2.1154305388530097

Epoch: 5| Step: 4
Training loss: 0.8360956311225891
Validation loss: 2.1526117424170175

Epoch: 5| Step: 5
Training loss: 0.585952639579773
Validation loss: 2.1063402742147446

Epoch: 5| Step: 6
Training loss: 0.8589469790458679
Validation loss: 2.0959620823462806

Epoch: 5| Step: 7
Training loss: 1.6200730800628662
Validation loss: 2.0984185139338174

Epoch: 5| Step: 8
Training loss: 0.6407870650291443
Validation loss: 2.172866553068161

Epoch: 5| Step: 9
Training loss: 1.1476233005523682
Validation loss: 2.147905871272087

Epoch: 5| Step: 10
Training loss: 1.2125828266143799
Validation loss: 2.1203368107477822

Epoch: 5| Step: 11
Training loss: 2.029567003250122
Validation loss: 2.1598505477110543

Epoch: 470| Step: 0
Training loss: 1.5423129796981812
Validation loss: 2.125474880139033

Epoch: 5| Step: 1
Training loss: 0.9426954984664917
Validation loss: 2.0913724452257156

Epoch: 5| Step: 2
Training loss: 0.7511230111122131
Validation loss: 2.1452317436536155

Epoch: 5| Step: 3
Training loss: 0.8211272358894348
Validation loss: 2.1491681337356567

Epoch: 5| Step: 4
Training loss: 0.7522580027580261
Validation loss: 2.1318416794141135

Epoch: 5| Step: 5
Training loss: 0.7514188289642334
Validation loss: 2.172043740749359

Epoch: 5| Step: 6
Training loss: 0.9311969876289368
Validation loss: 2.1140087644259133

Epoch: 5| Step: 7
Training loss: 0.8052338361740112
Validation loss: 2.1641490707794824

Epoch: 5| Step: 8
Training loss: 0.8700357675552368
Validation loss: 2.178201893965403

Epoch: 5| Step: 9
Training loss: 1.0162997245788574
Validation loss: 2.1948609550793967

Epoch: 5| Step: 10
Training loss: 0.7808462381362915
Validation loss: 2.15091735124588

Epoch: 5| Step: 11
Training loss: 1.4975498914718628
Validation loss: 2.1802793741226196

Epoch: 471| Step: 0
Training loss: 1.125759482383728
Validation loss: 2.143039579192797

Epoch: 5| Step: 1
Training loss: 1.331812858581543
Validation loss: 2.140354707837105

Epoch: 5| Step: 2
Training loss: 0.7492432594299316
Validation loss: 2.079834431409836

Epoch: 5| Step: 3
Training loss: 0.915981650352478
Validation loss: 2.1012505243221917

Epoch: 5| Step: 4
Training loss: 0.9724273681640625
Validation loss: 2.143103376030922

Epoch: 5| Step: 5
Training loss: 1.688985824584961
Validation loss: 2.1159173945585885

Epoch: 5| Step: 6
Training loss: 0.6602363586425781
Validation loss: 2.1387729346752167

Epoch: 5| Step: 7
Training loss: 0.910932719707489
Validation loss: 2.139754285415014

Epoch: 5| Step: 8
Training loss: 0.6867326498031616
Validation loss: 2.17644731203715

Epoch: 5| Step: 9
Training loss: 0.7412883043289185
Validation loss: 2.217362955212593

Epoch: 5| Step: 10
Training loss: 0.713159441947937
Validation loss: 2.2277515282233558

Epoch: 5| Step: 11
Training loss: 1.1660963296890259
Validation loss: 2.2221450060606003

Epoch: 472| Step: 0
Training loss: 0.6988351345062256
Validation loss: 2.1532060553630195

Epoch: 5| Step: 1
Training loss: 1.030703067779541
Validation loss: 2.215932622551918

Epoch: 5| Step: 2
Training loss: 1.3133140802383423
Validation loss: 2.220744957526525

Epoch: 5| Step: 3
Training loss: 1.183182716369629
Validation loss: 2.2239269763231277

Epoch: 5| Step: 4
Training loss: 0.7670966982841492
Validation loss: 2.195974364876747

Epoch: 5| Step: 5
Training loss: 0.7590847015380859
Validation loss: 2.178846816221873

Epoch: 5| Step: 6
Training loss: 0.44363850355148315
Validation loss: 2.1770054499308267

Epoch: 5| Step: 7
Training loss: 1.0724259614944458
Validation loss: 2.13693035642306

Epoch: 5| Step: 8
Training loss: 0.8405252695083618
Validation loss: 2.1505145529905954

Epoch: 5| Step: 9
Training loss: 1.1228539943695068
Validation loss: 2.179970512787501

Epoch: 5| Step: 10
Training loss: 0.9870142936706543
Validation loss: 2.140017658472061

Epoch: 5| Step: 11
Training loss: 0.5671200752258301
Validation loss: 2.2005717903375626

Epoch: 473| Step: 0
Training loss: 0.8260423541069031
Validation loss: 2.1470917960007987

Epoch: 5| Step: 1
Training loss: 0.7146097421646118
Validation loss: 2.142821575204531

Epoch: 5| Step: 2
Training loss: 0.584708034992218
Validation loss: 2.17095023393631

Epoch: 5| Step: 3
Training loss: 0.8146100044250488
Validation loss: 2.1120928625265756

Epoch: 5| Step: 4
Training loss: 0.7756465673446655
Validation loss: 2.132988174756368

Epoch: 5| Step: 5
Training loss: 1.197985053062439
Validation loss: 2.16226593653361

Epoch: 5| Step: 6
Training loss: 1.1712790727615356
Validation loss: 2.1597772737344108

Epoch: 5| Step: 7
Training loss: 1.2427419424057007
Validation loss: 2.21875769396623

Epoch: 5| Step: 8
Training loss: 0.9860785603523254
Validation loss: 2.207794119914373

Epoch: 5| Step: 9
Training loss: 1.1726908683776855
Validation loss: 2.154783546924591

Epoch: 5| Step: 10
Training loss: 0.9805936813354492
Validation loss: 2.1794994870821633

Epoch: 5| Step: 11
Training loss: 0.5085597634315491
Validation loss: 2.201498101154963

Epoch: 474| Step: 0
Training loss: 0.6950694918632507
Validation loss: 2.177269831299782

Epoch: 5| Step: 1
Training loss: 0.7104933261871338
Validation loss: 2.2102465530236564

Epoch: 5| Step: 2
Training loss: 1.0996079444885254
Validation loss: 2.2227814197540283

Epoch: 5| Step: 3
Training loss: 1.2537771463394165
Validation loss: 2.2108099261919656

Epoch: 5| Step: 4
Training loss: 0.8209930658340454
Validation loss: 2.2314028243223825

Epoch: 5| Step: 5
Training loss: 0.9405967593193054
Validation loss: 2.2136181394259133

Epoch: 5| Step: 6
Training loss: 1.0148804187774658
Validation loss: 2.2428613205750785

Epoch: 5| Step: 7
Training loss: 0.9041775465011597
Validation loss: 2.2112592309713364

Epoch: 5| Step: 8
Training loss: 1.3467193841934204
Validation loss: 2.2018074691295624

Epoch: 5| Step: 9
Training loss: 0.7297557592391968
Validation loss: 2.2528096536795297

Epoch: 5| Step: 10
Training loss: 0.7015917897224426
Validation loss: 2.2096741596857705

Epoch: 5| Step: 11
Training loss: 0.7743180394172668
Validation loss: 2.1373377392689386

Epoch: 475| Step: 0
Training loss: 1.1512430906295776
Validation loss: 2.167990272243818

Epoch: 5| Step: 1
Training loss: 0.8707079887390137
Validation loss: 2.186816473801931

Epoch: 5| Step: 2
Training loss: 0.8272438049316406
Validation loss: 2.172589366634687

Epoch: 5| Step: 3
Training loss: 0.877040684223175
Validation loss: 2.140247086683909

Epoch: 5| Step: 4
Training loss: 0.9730939865112305
Validation loss: 2.2105149875084558

Epoch: 5| Step: 5
Training loss: 0.587348997592926
Validation loss: 2.1784828901290894

Epoch: 5| Step: 6
Training loss: 0.6236294507980347
Validation loss: 2.192911853392919

Epoch: 5| Step: 7
Training loss: 0.7779380679130554
Validation loss: 2.1777201940615973

Epoch: 5| Step: 8
Training loss: 1.063788652420044
Validation loss: 2.154528021812439

Epoch: 5| Step: 9
Training loss: 0.754733681678772
Validation loss: 2.168758119146029

Epoch: 5| Step: 10
Training loss: 1.0236101150512695
Validation loss: 2.1763269901275635

Epoch: 5| Step: 11
Training loss: 0.7984309792518616
Validation loss: 2.1247748086849847

Epoch: 476| Step: 0
Training loss: 0.8412405252456665
Validation loss: 2.130211293697357

Epoch: 5| Step: 1
Training loss: 0.9851730465888977
Validation loss: 2.114068791270256

Epoch: 5| Step: 2
Training loss: 1.3211333751678467
Validation loss: 2.1158820192019143

Epoch: 5| Step: 3
Training loss: 0.922497570514679
Validation loss: 2.0939462184906006

Epoch: 5| Step: 4
Training loss: 0.755815327167511
Validation loss: 2.1371012677749

Epoch: 5| Step: 5
Training loss: 1.3381922245025635
Validation loss: 2.170686403910319

Epoch: 5| Step: 6
Training loss: 0.6934345960617065
Validation loss: 2.097145070632299

Epoch: 5| Step: 7
Training loss: 0.6816774010658264
Validation loss: 2.132262726624807

Epoch: 5| Step: 8
Training loss: 1.4954588413238525
Validation loss: 2.1141475290060043

Epoch: 5| Step: 9
Training loss: 1.189995288848877
Validation loss: 2.134450683991114

Epoch: 5| Step: 10
Training loss: 0.4737703204154968
Validation loss: 2.0912346045176187

Epoch: 5| Step: 11
Training loss: 0.7235232591629028
Validation loss: 2.136653497815132

Epoch: 477| Step: 0
Training loss: 1.3199187517166138
Validation loss: 2.1295719196399054

Epoch: 5| Step: 1
Training loss: 1.2957264184951782
Validation loss: 2.1777427097161612

Epoch: 5| Step: 2
Training loss: 1.0487130880355835
Validation loss: 2.1904275914033255

Epoch: 5| Step: 3
Training loss: 0.5736470222473145
Validation loss: 2.1126309831937156

Epoch: 5| Step: 4
Training loss: 0.6237969398498535
Validation loss: 2.146214375893275

Epoch: 5| Step: 5
Training loss: 0.5971065759658813
Validation loss: 2.1502356976270676

Epoch: 5| Step: 6
Training loss: 0.9695132970809937
Validation loss: 2.1671727498372397

Epoch: 5| Step: 7
Training loss: 1.2092552185058594
Validation loss: 2.1306313574314117

Epoch: 5| Step: 8
Training loss: 1.524324655532837
Validation loss: 2.1572024126847587

Epoch: 5| Step: 9
Training loss: 0.8966242671012878
Validation loss: 2.1424712787071862

Epoch: 5| Step: 10
Training loss: 1.3266513347625732
Validation loss: 2.1946537594000497

Epoch: 5| Step: 11
Training loss: 0.6157662868499756
Validation loss: 2.129234880208969

Epoch: 478| Step: 0
Training loss: 0.7088260650634766
Validation loss: 2.117183248202006

Epoch: 5| Step: 1
Training loss: 1.2017486095428467
Validation loss: 2.1472050646940866

Epoch: 5| Step: 2
Training loss: 0.8469168543815613
Validation loss: 2.2191611975431442

Epoch: 5| Step: 3
Training loss: 1.6371593475341797
Validation loss: 2.20914559563001

Epoch: 5| Step: 4
Training loss: 0.8039517402648926
Validation loss: 2.148219272494316

Epoch: 5| Step: 5
Training loss: 1.174500823020935
Validation loss: 2.1226718773444495

Epoch: 5| Step: 6
Training loss: 0.7752736806869507
Validation loss: 2.1776572912931442

Epoch: 5| Step: 7
Training loss: 1.018813133239746
Validation loss: 2.1647885590791702

Epoch: 5| Step: 8
Training loss: 0.8707453608512878
Validation loss: 2.164880931377411

Epoch: 5| Step: 9
Training loss: 0.6927399039268494
Validation loss: 2.1527105073134103

Epoch: 5| Step: 10
Training loss: 1.1105202436447144
Validation loss: 2.113995209336281

Epoch: 5| Step: 11
Training loss: 0.8752735257148743
Validation loss: 2.1369433204332986

Epoch: 479| Step: 0
Training loss: 0.7157875299453735
Validation loss: 2.1366357803344727

Epoch: 5| Step: 1
Training loss: 1.5562480688095093
Validation loss: 2.1182251969973245

Epoch: 5| Step: 2
Training loss: 0.8379206657409668
Validation loss: 2.1259747644265494

Epoch: 5| Step: 3
Training loss: 0.8018655776977539
Validation loss: 2.0995503813028336

Epoch: 5| Step: 4
Training loss: 1.1459182500839233
Validation loss: 2.120278467734655

Epoch: 5| Step: 5
Training loss: 0.8162662386894226
Validation loss: 2.1312409192323685

Epoch: 5| Step: 6
Training loss: 0.7566306591033936
Validation loss: 2.1070622950792313

Epoch: 5| Step: 7
Training loss: 0.5999425053596497
Validation loss: 2.0851243187983832

Epoch: 5| Step: 8
Training loss: 0.8247964978218079
Validation loss: 2.1830367892980576

Epoch: 5| Step: 9
Training loss: 1.5401856899261475
Validation loss: 2.177350699901581

Epoch: 5| Step: 10
Training loss: 0.848425567150116
Validation loss: 2.177089144786199

Epoch: 5| Step: 11
Training loss: 0.5559118986129761
Validation loss: 2.125809888044993

Epoch: 480| Step: 0
Training loss: 0.9513177871704102
Validation loss: 2.111424391468366

Epoch: 5| Step: 1
Training loss: 0.5148707628250122
Validation loss: 2.182993729909261

Epoch: 5| Step: 2
Training loss: 0.7599708437919617
Validation loss: 2.156105548143387

Epoch: 5| Step: 3
Training loss: 1.5934849977493286
Validation loss: 2.1243443340063095

Epoch: 5| Step: 4
Training loss: 0.7206935882568359
Validation loss: 2.16999880472819

Epoch: 5| Step: 5
Training loss: 0.887982189655304
Validation loss: 2.1397918363412223

Epoch: 5| Step: 6
Training loss: 0.7308977842330933
Validation loss: 2.1148719092210135

Epoch: 5| Step: 7
Training loss: 0.943317711353302
Validation loss: 2.126769185066223

Epoch: 5| Step: 8
Training loss: 0.9090320467948914
Validation loss: 2.202834829688072

Epoch: 5| Step: 9
Training loss: 1.528617262840271
Validation loss: 2.1423466553290686

Epoch: 5| Step: 10
Training loss: 0.7094737887382507
Validation loss: 2.1173167328039804

Epoch: 5| Step: 11
Training loss: 0.7421720027923584
Validation loss: 2.085381935040156

Epoch: 481| Step: 0
Training loss: 1.4383859634399414
Validation loss: 2.0996389389038086

Epoch: 5| Step: 1
Training loss: 1.1066970825195312
Validation loss: 2.056913817922274

Epoch: 5| Step: 2
Training loss: 1.3864637613296509
Validation loss: 2.087481568257014

Epoch: 5| Step: 3
Training loss: 0.6762924194335938
Validation loss: 2.1003274023532867

Epoch: 5| Step: 4
Training loss: 0.6291825175285339
Validation loss: 2.1062574783960977

Epoch: 5| Step: 5
Training loss: 1.2484252452850342
Validation loss: 2.1234074036280313

Epoch: 5| Step: 6
Training loss: 0.9099540710449219
Validation loss: 2.15067595243454

Epoch: 5| Step: 7
Training loss: 0.6222556829452515
Validation loss: 2.174365465839704

Epoch: 5| Step: 8
Training loss: 1.024335503578186
Validation loss: 2.166587769985199

Epoch: 5| Step: 9
Training loss: 0.4271754324436188
Validation loss: 2.0886728713909783

Epoch: 5| Step: 10
Training loss: 0.5612796545028687
Validation loss: 2.1790460596481958

Epoch: 5| Step: 11
Training loss: 0.5180708169937134
Validation loss: 2.198557992776235

Epoch: 482| Step: 0
Training loss: 0.7069182395935059
Validation loss: 2.163027827938398

Epoch: 5| Step: 1
Training loss: 0.6491433382034302
Validation loss: 2.1586883664131165

Epoch: 5| Step: 2
Training loss: 1.3553985357284546
Validation loss: 2.179275875290235

Epoch: 5| Step: 3
Training loss: 0.6054061055183411
Validation loss: 2.1830715934435525

Epoch: 5| Step: 4
Training loss: 0.7402697801589966
Validation loss: 2.153045356273651

Epoch: 5| Step: 5
Training loss: 1.2050559520721436
Validation loss: 2.1399389704068503

Epoch: 5| Step: 6
Training loss: 0.711628258228302
Validation loss: 2.1459679504235587

Epoch: 5| Step: 7
Training loss: 0.7206799387931824
Validation loss: 2.171343500415484

Epoch: 5| Step: 8
Training loss: 0.9054385423660278
Validation loss: 2.201278249422709

Epoch: 5| Step: 9
Training loss: 1.200976014137268
Validation loss: 2.160259266694387

Epoch: 5| Step: 10
Training loss: 0.8592696189880371
Validation loss: 2.157806466023127

Epoch: 5| Step: 11
Training loss: 0.3738294839859009
Validation loss: 2.166420047481855

Epoch: 483| Step: 0
Training loss: 1.4052519798278809
Validation loss: 2.1621535470088324

Epoch: 5| Step: 1
Training loss: 0.8578222393989563
Validation loss: 2.152925968170166

Epoch: 5| Step: 2
Training loss: 0.89628666639328
Validation loss: 2.1554836134115853

Epoch: 5| Step: 3
Training loss: 0.9917443990707397
Validation loss: 2.095165694753329

Epoch: 5| Step: 4
Training loss: 0.6297196745872498
Validation loss: 2.1128025452295938

Epoch: 5| Step: 5
Training loss: 1.0581164360046387
Validation loss: 2.128474702437719

Epoch: 5| Step: 6
Training loss: 1.137164831161499
Validation loss: 2.1257869799931846

Epoch: 5| Step: 7
Training loss: 0.4842658042907715
Validation loss: 2.1032035052776337

Epoch: 5| Step: 8
Training loss: 0.8925353288650513
Validation loss: 2.129244938492775

Epoch: 5| Step: 9
Training loss: 0.6692182421684265
Validation loss: 2.090787207086881

Epoch: 5| Step: 10
Training loss: 0.588100790977478
Validation loss: 2.1015019565820694

Epoch: 5| Step: 11
Training loss: 0.5927391052246094
Validation loss: 2.114402547478676

Epoch: 484| Step: 0
Training loss: 0.7361217737197876
Validation loss: 2.0664892544349036

Epoch: 5| Step: 1
Training loss: 1.0308153629302979
Validation loss: 2.089388688405355

Epoch: 5| Step: 2
Training loss: 0.6531776189804077
Validation loss: 2.107874184846878

Epoch: 5| Step: 3
Training loss: 0.9707853198051453
Validation loss: 2.0101620008548102

Epoch: 5| Step: 4
Training loss: 0.5142029523849487
Validation loss: 2.0455248008171716

Epoch: 5| Step: 5
Training loss: 0.8846498727798462
Validation loss: 2.0551942884922028

Epoch: 5| Step: 6
Training loss: 1.1001765727996826
Validation loss: 2.0845962266127267

Epoch: 5| Step: 7
Training loss: 1.0137081146240234
Validation loss: 2.1182125906149545

Epoch: 5| Step: 8
Training loss: 1.3460417985916138
Validation loss: 2.109446187814077

Epoch: 5| Step: 9
Training loss: 0.9444938898086548
Validation loss: 2.1513289312521615

Epoch: 5| Step: 10
Training loss: 0.37998634576797485
Validation loss: 2.1501930554707847

Epoch: 5| Step: 11
Training loss: 1.025718092918396
Validation loss: 2.112983470161756

Epoch: 485| Step: 0
Training loss: 0.9643548130989075
Validation loss: 2.146222030123075

Epoch: 5| Step: 1
Training loss: 0.6515311002731323
Validation loss: 2.133571594953537

Epoch: 5| Step: 2
Training loss: 0.8053178787231445
Validation loss: 2.1552524864673615

Epoch: 5| Step: 3
Training loss: 0.9071933627128601
Validation loss: 2.1381863057613373

Epoch: 5| Step: 4
Training loss: 1.01973295211792
Validation loss: 2.0826959957679114

Epoch: 5| Step: 5
Training loss: 0.6178555488586426
Validation loss: 2.1209404269854226

Epoch: 5| Step: 6
Training loss: 0.581871747970581
Validation loss: 2.143559848268827

Epoch: 5| Step: 7
Training loss: 0.8184634447097778
Validation loss: 2.1567197342713675

Epoch: 5| Step: 8
Training loss: 1.3048293590545654
Validation loss: 2.154521236817042

Epoch: 5| Step: 9
Training loss: 0.7763178944587708
Validation loss: 2.135309790571531

Epoch: 5| Step: 10
Training loss: 0.7978624105453491
Validation loss: 2.1355001280705133

Epoch: 5| Step: 11
Training loss: 1.962615966796875
Validation loss: 2.1454772700866065

Epoch: 486| Step: 0
Training loss: 1.0598474740982056
Validation loss: 2.166358008980751

Epoch: 5| Step: 1
Training loss: 1.0845451354980469
Validation loss: 2.167251795530319

Epoch: 5| Step: 2
Training loss: 0.9962085485458374
Validation loss: 2.2239064127206802

Epoch: 5| Step: 3
Training loss: 1.053479552268982
Validation loss: 2.28997665643692

Epoch: 5| Step: 4
Training loss: 1.0122935771942139
Validation loss: 2.2278262078762054

Epoch: 5| Step: 5
Training loss: 0.7020252346992493
Validation loss: 2.2303859144449234

Epoch: 5| Step: 6
Training loss: 0.8603240847587585
Validation loss: 2.202368751168251

Epoch: 5| Step: 7
Training loss: 0.5716930031776428
Validation loss: 2.1866312424341836

Epoch: 5| Step: 8
Training loss: 0.6533831357955933
Validation loss: 2.181409647067388

Epoch: 5| Step: 9
Training loss: 1.07353937625885
Validation loss: 2.199892724553744

Epoch: 5| Step: 10
Training loss: 0.9145376086235046
Validation loss: 2.153136730194092

Epoch: 5| Step: 11
Training loss: 2.7414660453796387
Validation loss: 2.177263781428337

Epoch: 487| Step: 0
Training loss: 0.776680588722229
Validation loss: 2.1638622979323068

Epoch: 5| Step: 1
Training loss: 1.0991365909576416
Validation loss: 2.2407097667455673

Epoch: 5| Step: 2
Training loss: 1.2821952104568481
Validation loss: 2.211974779764811

Epoch: 5| Step: 3
Training loss: 1.1217349767684937
Validation loss: 2.2280982981125512

Epoch: 5| Step: 4
Training loss: 0.872010350227356
Validation loss: 2.2389920949935913

Epoch: 5| Step: 5
Training loss: 1.2430121898651123
Validation loss: 2.271624058485031

Epoch: 5| Step: 6
Training loss: 0.7374590635299683
Validation loss: 2.23041237394015

Epoch: 5| Step: 7
Training loss: 1.2097234725952148
Validation loss: 2.2095357129971185

Epoch: 5| Step: 8
Training loss: 0.9572348594665527
Validation loss: 2.1812065690755844

Epoch: 5| Step: 9
Training loss: 0.7905084490776062
Validation loss: 2.1702646911144257

Epoch: 5| Step: 10
Training loss: 0.491682231426239
Validation loss: 2.1977792233228683

Epoch: 5| Step: 11
Training loss: 0.2800910472869873
Validation loss: 2.1346514374017715

Epoch: 488| Step: 0
Training loss: 1.0345041751861572
Validation loss: 2.1860176722208657

Epoch: 5| Step: 1
Training loss: 0.6263900995254517
Validation loss: 2.1902620991071067

Epoch: 5| Step: 2
Training loss: 0.8572646379470825
Validation loss: 2.194813678661982

Epoch: 5| Step: 3
Training loss: 0.4114510118961334
Validation loss: 2.1366333067417145

Epoch: 5| Step: 4
Training loss: 1.0264084339141846
Validation loss: 2.139535203576088

Epoch: 5| Step: 5
Training loss: 1.3033630847930908
Validation loss: 2.135674019654592

Epoch: 5| Step: 6
Training loss: 0.9130754470825195
Validation loss: 2.1536493003368378

Epoch: 5| Step: 7
Training loss: 0.8949371576309204
Validation loss: 2.122955376903216

Epoch: 5| Step: 8
Training loss: 0.9196497201919556
Validation loss: 2.1211632192134857

Epoch: 5| Step: 9
Training loss: 1.0805509090423584
Validation loss: 2.1588588058948517

Epoch: 5| Step: 10
Training loss: 0.745652973651886
Validation loss: 2.1581088850895562

Epoch: 5| Step: 11
Training loss: 0.4158594608306885
Validation loss: 2.16848515967528

Epoch: 489| Step: 0
Training loss: 0.7776034474372864
Validation loss: 2.226937140027682

Epoch: 5| Step: 1
Training loss: 0.9262847900390625
Validation loss: 2.214828779300054

Epoch: 5| Step: 2
Training loss: 1.0028982162475586
Validation loss: 2.1857439130544662

Epoch: 5| Step: 3
Training loss: 0.5564878582954407
Validation loss: 2.189545661211014

Epoch: 5| Step: 4
Training loss: 1.071264624595642
Validation loss: 2.13371908167998

Epoch: 5| Step: 5
Training loss: 1.2554051876068115
Validation loss: 2.1491150160630546

Epoch: 5| Step: 6
Training loss: 1.0140855312347412
Validation loss: 2.1533371011416116

Epoch: 5| Step: 7
Training loss: 0.7341427803039551
Validation loss: 2.12458565334479

Epoch: 5| Step: 8
Training loss: 0.841535210609436
Validation loss: 2.090168962876002

Epoch: 5| Step: 9
Training loss: 0.6416524052619934
Validation loss: 2.1036472668250403

Epoch: 5| Step: 10
Training loss: 0.7395557761192322
Validation loss: 2.141634479165077

Epoch: 5| Step: 11
Training loss: 1.210491418838501
Validation loss: 2.149382397532463

Epoch: 490| Step: 0
Training loss: 0.473283588886261
Validation loss: 2.0975295454263687

Epoch: 5| Step: 1
Training loss: 0.9036922454833984
Validation loss: 2.1415580113728843

Epoch: 5| Step: 2
Training loss: 0.7860514521598816
Validation loss: 2.0970755318800607

Epoch: 5| Step: 3
Training loss: 1.5773355960845947
Validation loss: 2.1205232044061026

Epoch: 5| Step: 4
Training loss: 0.7955880165100098
Validation loss: 2.1684095015128455

Epoch: 5| Step: 5
Training loss: 0.9611899256706238
Validation loss: 2.125314215819041

Epoch: 5| Step: 6
Training loss: 0.8173657655715942
Validation loss: 2.160337676604589

Epoch: 5| Step: 7
Training loss: 0.7107710242271423
Validation loss: 2.182559455434481

Epoch: 5| Step: 8
Training loss: 0.6852344870567322
Validation loss: 2.152958333492279

Epoch: 5| Step: 9
Training loss: 1.1157029867172241
Validation loss: 2.127159665028254

Epoch: 5| Step: 10
Training loss: 0.6603693962097168
Validation loss: 2.104828119277954

Epoch: 5| Step: 11
Training loss: 0.5360333323478699
Validation loss: 2.0954631765683494

Epoch: 491| Step: 0
Training loss: 1.5426775217056274
Validation loss: 2.111145863930384

Epoch: 5| Step: 1
Training loss: 0.7669479250907898
Validation loss: 2.11016375819842

Epoch: 5| Step: 2
Training loss: 0.8512970209121704
Validation loss: 2.137954533100128

Epoch: 5| Step: 3
Training loss: 0.6357182264328003
Validation loss: 2.131250540415446

Epoch: 5| Step: 4
Training loss: 0.7913366556167603
Validation loss: 2.095479945341746

Epoch: 5| Step: 5
Training loss: 0.6731002926826477
Validation loss: 2.0756693283716836

Epoch: 5| Step: 6
Training loss: 1.072827935218811
Validation loss: 2.084256485104561

Epoch: 5| Step: 7
Training loss: 0.5274551510810852
Validation loss: 2.1040525337060294

Epoch: 5| Step: 8
Training loss: 0.9635431170463562
Validation loss: 2.0957741737365723

Epoch: 5| Step: 9
Training loss: 0.7976208329200745
Validation loss: 2.1259919305642447

Epoch: 5| Step: 10
Training loss: 0.8894861340522766
Validation loss: 2.1833696017662683

Epoch: 5| Step: 11
Training loss: 0.35430729389190674
Validation loss: 2.1757158438364663

Epoch: 492| Step: 0
Training loss: 0.8814952969551086
Validation loss: 2.1371239374081292

Epoch: 5| Step: 1
Training loss: 0.6316997408866882
Validation loss: 2.1413145810365677

Epoch: 5| Step: 2
Training loss: 0.3769962787628174
Validation loss: 2.1909000178178153

Epoch: 5| Step: 3
Training loss: 1.2101489305496216
Validation loss: 2.1255545020103455

Epoch: 5| Step: 4
Training loss: 0.7644761204719543
Validation loss: 2.1629468152920404

Epoch: 5| Step: 5
Training loss: 0.6571156978607178
Validation loss: 2.135165572166443

Epoch: 5| Step: 6
Training loss: 1.1547073125839233
Validation loss: 2.1212101628383

Epoch: 5| Step: 7
Training loss: 0.9906049966812134
Validation loss: 2.1220279236634574

Epoch: 5| Step: 8
Training loss: 0.7793446779251099
Validation loss: 2.099609116713206

Epoch: 5| Step: 9
Training loss: 0.5021203756332397
Validation loss: 2.1157778153816857

Epoch: 5| Step: 10
Training loss: 1.1730469465255737
Validation loss: 2.124667858084043

Epoch: 5| Step: 11
Training loss: 1.797395944595337
Validation loss: 2.2139263451099396

Epoch: 493| Step: 0
Training loss: 0.6247222423553467
Validation loss: 2.1672869424025216

Epoch: 5| Step: 1
Training loss: 0.6514593362808228
Validation loss: 2.1484093368053436

Epoch: 5| Step: 2
Training loss: 0.40976381301879883
Validation loss: 2.1287729938824973

Epoch: 5| Step: 3
Training loss: 0.5542317032814026
Validation loss: 2.1527718355258307

Epoch: 5| Step: 4
Training loss: 1.003393530845642
Validation loss: 2.12668713927269

Epoch: 5| Step: 5
Training loss: 0.7011429071426392
Validation loss: 2.1191157897313437

Epoch: 5| Step: 6
Training loss: 0.9331805109977722
Validation loss: 2.1049991101026535

Epoch: 5| Step: 7
Training loss: 0.9813358187675476
Validation loss: 2.140962521235148

Epoch: 5| Step: 8
Training loss: 0.833328127861023
Validation loss: 2.1508449564377465

Epoch: 5| Step: 9
Training loss: 0.6721743941307068
Validation loss: 2.095533470312754

Epoch: 5| Step: 10
Training loss: 2.1050069332122803
Validation loss: 2.1742549538612366

Epoch: 5| Step: 11
Training loss: 1.132749319076538
Validation loss: 2.175873930255572

Epoch: 494| Step: 0
Training loss: 0.8872105479240417
Validation loss: 2.141389658053716

Epoch: 5| Step: 1
Training loss: 1.0347487926483154
Validation loss: 2.147413139541944

Epoch: 5| Step: 2
Training loss: 1.480136752128601
Validation loss: 2.146375447511673

Epoch: 5| Step: 3
Training loss: 0.7097340226173401
Validation loss: 2.1639999697605767

Epoch: 5| Step: 4
Training loss: 0.9223419427871704
Validation loss: 2.1785792311032615

Epoch: 5| Step: 5
Training loss: 1.087531328201294
Validation loss: 2.1616426755984626

Epoch: 5| Step: 6
Training loss: 0.8279640078544617
Validation loss: 2.1887099345525107

Epoch: 5| Step: 7
Training loss: 0.6405701637268066
Validation loss: 2.1856242219607034

Epoch: 5| Step: 8
Training loss: 0.5969082117080688
Validation loss: 2.1243875324726105

Epoch: 5| Step: 9
Training loss: 0.5136376619338989
Validation loss: 2.127303972840309

Epoch: 5| Step: 10
Training loss: 0.7425600290298462
Validation loss: 2.1225968251625695

Epoch: 5| Step: 11
Training loss: 0.6754008531570435
Validation loss: 2.1276950339476266

Epoch: 495| Step: 0
Training loss: 0.7984570860862732
Validation loss: 2.155193030834198

Epoch: 5| Step: 1
Training loss: 1.017785668373108
Validation loss: 2.1602774212757745

Epoch: 5| Step: 2
Training loss: 0.9389070272445679
Validation loss: 2.1423139373461404

Epoch: 5| Step: 3
Training loss: 1.4607118368148804
Validation loss: 2.1380040844281516

Epoch: 5| Step: 4
Training loss: 0.7072224617004395
Validation loss: 2.1542903631925583

Epoch: 5| Step: 5
Training loss: 0.8887630701065063
Validation loss: 2.171200613180796

Epoch: 5| Step: 6
Training loss: 1.0114142894744873
Validation loss: 2.183746859431267

Epoch: 5| Step: 7
Training loss: 0.5464940667152405
Validation loss: 2.181480179230372

Epoch: 5| Step: 8
Training loss: 0.9257642030715942
Validation loss: 2.1390859683354697

Epoch: 5| Step: 9
Training loss: 0.6036540865898132
Validation loss: 2.1252520382404327

Epoch: 5| Step: 10
Training loss: 0.638220489025116
Validation loss: 2.1721235563357673

Epoch: 5| Step: 11
Training loss: 0.17188426852226257
Validation loss: 2.143007601300875

Epoch: 496| Step: 0
Training loss: 0.6036993265151978
Validation loss: 2.143863926331202

Epoch: 5| Step: 1
Training loss: 0.9224563837051392
Validation loss: 2.183898409207662

Epoch: 5| Step: 2
Training loss: 0.7148463129997253
Validation loss: 2.135067343711853

Epoch: 5| Step: 3
Training loss: 1.1809980869293213
Validation loss: 2.133765161037445

Epoch: 5| Step: 4
Training loss: 0.9999968409538269
Validation loss: 2.1158090978860855

Epoch: 5| Step: 5
Training loss: 0.8890544772148132
Validation loss: 2.1515214343865714

Epoch: 5| Step: 6
Training loss: 0.8498298525810242
Validation loss: 2.091774195432663

Epoch: 5| Step: 7
Training loss: 0.5304628610610962
Validation loss: 2.1307036727666855

Epoch: 5| Step: 8
Training loss: 0.676956057548523
Validation loss: 2.1632017393906913

Epoch: 5| Step: 9
Training loss: 1.0561083555221558
Validation loss: 2.1147750119368234

Epoch: 5| Step: 10
Training loss: 0.9405225515365601
Validation loss: 2.1101706822713218

Epoch: 5| Step: 11
Training loss: 0.5462735891342163
Validation loss: 2.136302520831426

Epoch: 497| Step: 0
Training loss: 1.1472184658050537
Validation loss: 2.1438783506552377

Epoch: 5| Step: 1
Training loss: 0.4923396110534668
Validation loss: 2.222473219037056

Epoch: 5| Step: 2
Training loss: 0.9807196855545044
Validation loss: 2.1919084191322327

Epoch: 5| Step: 3
Training loss: 0.6054245829582214
Validation loss: 2.1817399064699807

Epoch: 5| Step: 4
Training loss: 0.8183957934379578
Validation loss: 2.213268886009852

Epoch: 5| Step: 5
Training loss: 0.9285003542900085
Validation loss: 2.27787809073925

Epoch: 5| Step: 6
Training loss: 0.8339554071426392
Validation loss: 2.2910451541344323

Epoch: 5| Step: 7
Training loss: 0.7243427038192749
Validation loss: 2.2094117949406304

Epoch: 5| Step: 8
Training loss: 0.9288915395736694
Validation loss: 2.1472536424795785

Epoch: 5| Step: 9
Training loss: 1.3820146322250366
Validation loss: 2.086088498433431

Epoch: 5| Step: 10
Training loss: 1.0457655191421509
Validation loss: 2.1643865406513214

Epoch: 5| Step: 11
Training loss: 1.1231029033660889
Validation loss: 2.158638283610344

Epoch: 498| Step: 0
Training loss: 1.0496882200241089
Validation loss: 2.1242082019646964

Epoch: 5| Step: 1
Training loss: 0.9845673441886902
Validation loss: 2.142842710018158

Epoch: 5| Step: 2
Training loss: 0.89300137758255
Validation loss: 2.171222150325775

Epoch: 5| Step: 3
Training loss: 1.1483488082885742
Validation loss: 2.1423810174067817

Epoch: 5| Step: 4
Training loss: 1.2139103412628174
Validation loss: 2.210084229707718

Epoch: 5| Step: 5
Training loss: 0.7608333826065063
Validation loss: 2.1395295361677804

Epoch: 5| Step: 6
Training loss: 0.7031065225601196
Validation loss: 2.1763355483611426

Epoch: 5| Step: 7
Training loss: 1.2826764583587646
Validation loss: 2.1345478842655816

Epoch: 5| Step: 8
Training loss: 0.7448493242263794
Validation loss: 2.191206340988477

Epoch: 5| Step: 9
Training loss: 0.9564436078071594
Validation loss: 2.191215688983599

Epoch: 5| Step: 10
Training loss: 0.3683903217315674
Validation loss: 2.120348905523618

Epoch: 5| Step: 11
Training loss: 0.4090452194213867
Validation loss: 2.173435479402542

Epoch: 499| Step: 0
Training loss: 0.8358699083328247
Validation loss: 2.135384495059649

Epoch: 5| Step: 1
Training loss: 1.1307471990585327
Validation loss: 2.179498399297396

Epoch: 5| Step: 2
Training loss: 0.9086242914199829
Validation loss: 2.17958457271258

Epoch: 5| Step: 3
Training loss: 1.209322214126587
Validation loss: 2.1659330477317176

Epoch: 5| Step: 4
Training loss: 0.6954683065414429
Validation loss: 2.1054855038722358

Epoch: 5| Step: 5
Training loss: 0.8812322616577148
Validation loss: 2.0902675092220306

Epoch: 5| Step: 6
Training loss: 0.9315007925033569
Validation loss: 2.1069971919059753

Epoch: 5| Step: 7
Training loss: 0.6866253018379211
Validation loss: 2.096527506907781

Epoch: 5| Step: 8
Training loss: 0.7026504278182983
Validation loss: 2.076470563809077

Epoch: 5| Step: 9
Training loss: 0.716028094291687
Validation loss: 2.061697562535604

Epoch: 5| Step: 10
Training loss: 0.9050266146659851
Validation loss: 2.0645744055509567

Epoch: 5| Step: 11
Training loss: 2.0429625511169434
Validation loss: 2.0774435500303903

Epoch: 500| Step: 0
Training loss: 0.69171142578125
Validation loss: 2.0594087491432824

Epoch: 5| Step: 1
Training loss: 0.828416645526886
Validation loss: 2.09212464094162

Epoch: 5| Step: 2
Training loss: 0.8358887434005737
Validation loss: 2.1298718253771463

Epoch: 5| Step: 3
Training loss: 0.5731526613235474
Validation loss: 2.1441421508789062

Epoch: 5| Step: 4
Training loss: 0.9425972104072571
Validation loss: 2.148599296808243

Epoch: 5| Step: 5
Training loss: 1.0035127401351929
Validation loss: 2.199416975180308

Epoch: 5| Step: 6
Training loss: 0.707857608795166
Validation loss: 2.2031087974707284

Epoch: 5| Step: 7
Training loss: 0.7544845342636108
Validation loss: 2.2027473151683807

Epoch: 5| Step: 8
Training loss: 0.7818018794059753
Validation loss: 2.1942843894163766

Epoch: 5| Step: 9
Training loss: 1.2829309701919556
Validation loss: 2.1766619284947715

Epoch: 5| Step: 10
Training loss: 0.7858627438545227
Validation loss: 2.0960707664489746

Epoch: 5| Step: 11
Training loss: 1.5232951641082764
Validation loss: 2.0935155948003135

Epoch: 501| Step: 0
Training loss: 0.8551020622253418
Validation loss: 2.147640903790792

Epoch: 5| Step: 1
Training loss: 1.5232456922531128
Validation loss: 2.1616608003775277

Epoch: 5| Step: 2
Training loss: 1.2874478101730347
Validation loss: 2.1448304603497186

Epoch: 5| Step: 3
Training loss: 0.6264287233352661
Validation loss: 2.147186736265818

Epoch: 5| Step: 4
Training loss: 0.8630423545837402
Validation loss: 2.145582213997841

Epoch: 5| Step: 5
Training loss: 0.7465788722038269
Validation loss: 2.113017350435257

Epoch: 5| Step: 6
Training loss: 0.7412530779838562
Validation loss: 2.136167640487353

Epoch: 5| Step: 7
Training loss: 1.2885147333145142
Validation loss: 2.1162753999233246

Epoch: 5| Step: 8
Training loss: 0.5027269124984741
Validation loss: 2.121235176920891

Epoch: 5| Step: 9
Training loss: 0.6016465425491333
Validation loss: 2.1554079751173654

Epoch: 5| Step: 10
Training loss: 0.6319742202758789
Validation loss: 2.196696082750956

Epoch: 5| Step: 11
Training loss: 0.4166215658187866
Validation loss: 2.195244630177816

Epoch: 502| Step: 0
Training loss: 1.0446078777313232
Validation loss: 2.280835916598638

Epoch: 5| Step: 1
Training loss: 1.0532596111297607
Validation loss: 2.3553113490343094

Epoch: 5| Step: 2
Training loss: 1.2018495798110962
Validation loss: 2.33589605987072

Epoch: 5| Step: 3
Training loss: 0.8944790959358215
Validation loss: 2.2186804761489234

Epoch: 5| Step: 4
Training loss: 0.9157765507698059
Validation loss: 2.1432703038056693

Epoch: 5| Step: 5
Training loss: 0.874241054058075
Validation loss: 2.09688871105512

Epoch: 5| Step: 6
Training loss: 1.0581705570220947
Validation loss: 2.1786282112201056

Epoch: 5| Step: 7
Training loss: 0.7035931348800659
Validation loss: 2.163738191127777

Epoch: 5| Step: 8
Training loss: 1.2344601154327393
Validation loss: 2.1941412687301636

Epoch: 5| Step: 9
Training loss: 0.8140579462051392
Validation loss: 2.1770938436190286

Epoch: 5| Step: 10
Training loss: 1.0596909523010254
Validation loss: 2.1875035961469016

Epoch: 5| Step: 11
Training loss: 1.9615755081176758
Validation loss: 2.1361485024293265

Epoch: 503| Step: 0
Training loss: 1.096912145614624
Validation loss: 2.1137870798508325

Epoch: 5| Step: 1
Training loss: 0.7889996767044067
Validation loss: 2.2121248741944632

Epoch: 5| Step: 2
Training loss: 1.0819958448410034
Validation loss: 2.1939984261989594

Epoch: 5| Step: 3
Training loss: 0.9058735966682434
Validation loss: 2.281845897436142

Epoch: 5| Step: 4
Training loss: 1.2538444995880127
Validation loss: 2.2738299717505774

Epoch: 5| Step: 5
Training loss: 0.534492015838623
Validation loss: 2.2341045339902244

Epoch: 5| Step: 6
Training loss: 0.9626837968826294
Validation loss: 2.2398520509401956

Epoch: 5| Step: 7
Training loss: 0.9377216100692749
Validation loss: 2.18522047996521

Epoch: 5| Step: 8
Training loss: 1.0719029903411865
Validation loss: 2.2266857773065567

Epoch: 5| Step: 9
Training loss: 0.43687158823013306
Validation loss: 2.1842268804709115

Epoch: 5| Step: 10
Training loss: 1.3247897624969482
Validation loss: 2.1785919666290283

Epoch: 5| Step: 11
Training loss: 0.6769983768463135
Validation loss: 2.153576443592707

Epoch: 504| Step: 0
Training loss: 0.48065558075904846
Validation loss: 2.1111323734124503

Epoch: 5| Step: 1
Training loss: 0.7576638460159302
Validation loss: 2.084272548556328

Epoch: 5| Step: 2
Training loss: 1.1043250560760498
Validation loss: 2.066678216060003

Epoch: 5| Step: 3
Training loss: 0.7886154055595398
Validation loss: 2.120789314309756

Epoch: 5| Step: 4
Training loss: 1.1666948795318604
Validation loss: 2.118022153774897

Epoch: 5| Step: 5
Training loss: 0.8375347256660461
Validation loss: 2.1213738520940146

Epoch: 5| Step: 6
Training loss: 1.0047967433929443
Validation loss: 2.0948549111684165

Epoch: 5| Step: 7
Training loss: 1.0125389099121094
Validation loss: 2.1135900914669037

Epoch: 5| Step: 8
Training loss: 0.6033223271369934
Validation loss: 2.106723631421725

Epoch: 5| Step: 9
Training loss: 0.6574767827987671
Validation loss: 2.1138248592615128

Epoch: 5| Step: 10
Training loss: 1.004876971244812
Validation loss: 2.1458207865556083

Epoch: 5| Step: 11
Training loss: 2.2824227809906006
Validation loss: 2.119774947563807

Epoch: 505| Step: 0
Training loss: 0.7738456130027771
Validation loss: 2.1206348141034446

Epoch: 5| Step: 1
Training loss: 0.7028183937072754
Validation loss: 2.1967234114805856

Epoch: 5| Step: 2
Training loss: 0.832131028175354
Validation loss: 2.177938868602117

Epoch: 5| Step: 3
Training loss: 0.5770514011383057
Validation loss: 2.1301395297050476

Epoch: 5| Step: 4
Training loss: 0.4896431863307953
Validation loss: 2.135868271191915

Epoch: 5| Step: 5
Training loss: 0.969201922416687
Validation loss: 2.120542282859484

Epoch: 5| Step: 6
Training loss: 0.5552934408187866
Validation loss: 2.2016820957263312

Epoch: 5| Step: 7
Training loss: 1.1045416593551636
Validation loss: 2.1559830208619437

Epoch: 5| Step: 8
Training loss: 0.9924022555351257
Validation loss: 2.123804658651352

Epoch: 5| Step: 9
Training loss: 0.777550995349884
Validation loss: 2.1236687898635864

Epoch: 5| Step: 10
Training loss: 0.9893342852592468
Validation loss: 2.0880416284004846

Epoch: 5| Step: 11
Training loss: 0.17913413047790527
Validation loss: 2.0970266858736673

Epoch: 506| Step: 0
Training loss: 0.9588192701339722
Validation loss: 2.13634184996287

Epoch: 5| Step: 1
Training loss: 1.010494589805603
Validation loss: 2.1443471362193427

Epoch: 5| Step: 2
Training loss: 1.2467644214630127
Validation loss: 2.1310260693232217

Epoch: 5| Step: 3
Training loss: 0.7624934911727905
Validation loss: 2.1580708821614585

Epoch: 5| Step: 4
Training loss: 0.8501410484313965
Validation loss: 2.1974054872989655

Epoch: 5| Step: 5
Training loss: 0.6573269963264465
Validation loss: 2.1818840404351554

Epoch: 5| Step: 6
Training loss: 0.8161781430244446
Validation loss: 2.1182819406191506

Epoch: 5| Step: 7
Training loss: 0.8380657434463501
Validation loss: 2.186888352036476

Epoch: 5| Step: 8
Training loss: 0.7832611203193665
Validation loss: 2.135531132419904

Epoch: 5| Step: 9
Training loss: 0.6278146505355835
Validation loss: 2.1492296556631723

Epoch: 5| Step: 10
Training loss: 0.643173336982727
Validation loss: 2.1876458674669266

Epoch: 5| Step: 11
Training loss: 0.6924003958702087
Validation loss: 2.113935266931852

Epoch: 507| Step: 0
Training loss: 0.47550803422927856
Validation loss: 2.1527700374523797

Epoch: 5| Step: 1
Training loss: 0.7284563183784485
Validation loss: 2.1477787544329963

Epoch: 5| Step: 2
Training loss: 0.604884922504425
Validation loss: 2.1859731574853263

Epoch: 5| Step: 3
Training loss: 1.0008811950683594
Validation loss: 2.1623275130987167

Epoch: 5| Step: 4
Training loss: 0.6705804467201233
Validation loss: 2.16628830631574

Epoch: 5| Step: 5
Training loss: 1.4725418090820312
Validation loss: 2.168982411424319

Epoch: 5| Step: 6
Training loss: 0.8106002807617188
Validation loss: 2.1381462812423706

Epoch: 5| Step: 7
Training loss: 0.6623227596282959
Validation loss: 2.1264807482560477

Epoch: 5| Step: 8
Training loss: 0.9773473739624023
Validation loss: 2.1108820140361786

Epoch: 5| Step: 9
Training loss: 0.7131363749504089
Validation loss: 2.1587789406379065

Epoch: 5| Step: 10
Training loss: 0.8526611328125
Validation loss: 2.1121299862861633

Epoch: 5| Step: 11
Training loss: 0.7560067176818848
Validation loss: 2.083453267812729

Epoch: 508| Step: 0
Training loss: 0.6989747285842896
Validation loss: 2.0864142328500748

Epoch: 5| Step: 1
Training loss: 0.7460153698921204
Validation loss: 2.1020554502805076

Epoch: 5| Step: 2
Training loss: 0.6222892999649048
Validation loss: 2.1267015039920807

Epoch: 5| Step: 3
Training loss: 0.8913067579269409
Validation loss: 2.145394573609034

Epoch: 5| Step: 4
Training loss: 0.8196932673454285
Validation loss: 2.160344441731771

Epoch: 5| Step: 5
Training loss: 0.911568820476532
Validation loss: 2.1525109807650247

Epoch: 5| Step: 6
Training loss: 0.6855677366256714
Validation loss: 2.167543684442838

Epoch: 5| Step: 7
Training loss: 0.8376511335372925
Validation loss: 2.1508337954680123

Epoch: 5| Step: 8
Training loss: 1.1794472932815552
Validation loss: 2.1648697008689246

Epoch: 5| Step: 9
Training loss: 0.8415929675102234
Validation loss: 2.1554785817861557

Epoch: 5| Step: 10
Training loss: 0.6381571292877197
Validation loss: 2.1235972891251245

Epoch: 5| Step: 11
Training loss: 0.31561750173568726
Validation loss: 2.1807167480389276

Epoch: 509| Step: 0
Training loss: 1.1045539379119873
Validation loss: 2.1443789104620614

Epoch: 5| Step: 1
Training loss: 0.5228865742683411
Validation loss: 2.2254325846831002

Epoch: 5| Step: 2
Training loss: 1.2141177654266357
Validation loss: 2.1627867370843887

Epoch: 5| Step: 3
Training loss: 0.9572783708572388
Validation loss: 2.2467552423477173

Epoch: 5| Step: 4
Training loss: 0.7886340618133545
Validation loss: 2.1982820530732474

Epoch: 5| Step: 5
Training loss: 0.784589409828186
Validation loss: 2.2101150105396905

Epoch: 5| Step: 6
Training loss: 0.7422677874565125
Validation loss: 2.1530790428320565

Epoch: 5| Step: 7
Training loss: 0.9031642079353333
Validation loss: 2.1200489699840546

Epoch: 5| Step: 8
Training loss: 0.7175272703170776
Validation loss: 2.0757763435443244

Epoch: 5| Step: 9
Training loss: 0.8792058229446411
Validation loss: 2.107109010219574

Epoch: 5| Step: 10
Training loss: 0.5793473124504089
Validation loss: 2.050866554180781

Epoch: 5| Step: 11
Training loss: 0.2565833330154419
Validation loss: 2.083714003364245

Epoch: 510| Step: 0
Training loss: 0.8315909504890442
Validation loss: 2.1248993078867593

Epoch: 5| Step: 1
Training loss: 1.183872938156128
Validation loss: 2.1426042914390564

Epoch: 5| Step: 2
Training loss: 0.8327562212944031
Validation loss: 2.1301208833853402

Epoch: 5| Step: 3
Training loss: 0.9293587803840637
Validation loss: 2.175840432445208

Epoch: 5| Step: 4
Training loss: 0.7826604843139648
Validation loss: 2.158950060606003

Epoch: 5| Step: 5
Training loss: 1.1370741128921509
Validation loss: 2.131372238198916

Epoch: 5| Step: 6
Training loss: 0.37407946586608887
Validation loss: 2.1400564859310784

Epoch: 5| Step: 7
Training loss: 0.544080376625061
Validation loss: 2.1528468132019043

Epoch: 5| Step: 8
Training loss: 1.0612785816192627
Validation loss: 2.182953586181005

Epoch: 5| Step: 9
Training loss: 1.0732613801956177
Validation loss: 2.144697700937589

Epoch: 5| Step: 10
Training loss: 0.7867224216461182
Validation loss: 2.136062870422999

Epoch: 5| Step: 11
Training loss: 0.3136501908302307
Validation loss: 2.16045152147611

Epoch: 511| Step: 0
Training loss: 1.090125322341919
Validation loss: 2.175236468513807

Epoch: 5| Step: 1
Training loss: 1.2709274291992188
Validation loss: 2.1464976966381073

Epoch: 5| Step: 2
Training loss: 0.41772904992103577
Validation loss: 2.175615837176641

Epoch: 5| Step: 3
Training loss: 1.233921766281128
Validation loss: 2.1363061368465424

Epoch: 5| Step: 4
Training loss: 0.6003087759017944
Validation loss: 2.240564852952957

Epoch: 5| Step: 5
Training loss: 0.7130383849143982
Validation loss: 2.1438984175523124

Epoch: 5| Step: 6
Training loss: 0.9331802129745483
Validation loss: 2.0902849584817886

Epoch: 5| Step: 7
Training loss: 0.7274428009986877
Validation loss: 2.131581738591194

Epoch: 5| Step: 8
Training loss: 1.0772334337234497
Validation loss: 2.128533179561297

Epoch: 5| Step: 9
Training loss: 0.4879218637943268
Validation loss: 2.0983716746171317

Epoch: 5| Step: 10
Training loss: 0.42819857597351074
Validation loss: 2.0940315822760263

Epoch: 5| Step: 11
Training loss: 2.328645706176758
Validation loss: 2.091319113969803

Epoch: 512| Step: 0
Training loss: 0.5313122868537903
Validation loss: 2.1415550857782364

Epoch: 5| Step: 1
Training loss: 0.7216526865959167
Validation loss: 2.2269625266393027

Epoch: 5| Step: 2
Training loss: 0.8383844494819641
Validation loss: 2.268318315347036

Epoch: 5| Step: 3
Training loss: 0.895719051361084
Validation loss: 2.285332202911377

Epoch: 5| Step: 4
Training loss: 0.7991002798080444
Validation loss: 2.2347132762273154

Epoch: 5| Step: 5
Training loss: 1.0455267429351807
Validation loss: 2.2090858866771064

Epoch: 5| Step: 6
Training loss: 1.245828628540039
Validation loss: 2.148719926675161

Epoch: 5| Step: 7
Training loss: 0.8482770919799805
Validation loss: 2.1210311353206635

Epoch: 5| Step: 8
Training loss: 1.2679898738861084
Validation loss: 2.135183369119962

Epoch: 5| Step: 9
Training loss: 0.970380425453186
Validation loss: 2.108671650290489

Epoch: 5| Step: 10
Training loss: 1.0153321027755737
Validation loss: 2.1055370966593423

Epoch: 5| Step: 11
Training loss: 0.6091564893722534
Validation loss: 2.079418937365214

Epoch: 513| Step: 0
Training loss: 0.8000894784927368
Validation loss: 2.0529853204886117

Epoch: 5| Step: 1
Training loss: 1.069154143333435
Validation loss: 2.0766729762156806

Epoch: 5| Step: 2
Training loss: 0.6614400148391724
Validation loss: 2.104040707151095

Epoch: 5| Step: 3
Training loss: 0.8175439834594727
Validation loss: 2.095459202925364

Epoch: 5| Step: 4
Training loss: 0.6923232078552246
Validation loss: 2.1055183907349906

Epoch: 5| Step: 5
Training loss: 0.7428573369979858
Validation loss: 2.1672217746575675

Epoch: 5| Step: 6
Training loss: 1.0529967546463013
Validation loss: 2.158428500096003

Epoch: 5| Step: 7
Training loss: 0.8418213725090027
Validation loss: 2.195222109556198

Epoch: 5| Step: 8
Training loss: 0.5997944474220276
Validation loss: 2.1668208241462708

Epoch: 5| Step: 9
Training loss: 0.5793532729148865
Validation loss: 2.197796185811361

Epoch: 5| Step: 10
Training loss: 0.9294147491455078
Validation loss: 2.181274796525637

Epoch: 5| Step: 11
Training loss: 0.31690913438796997
Validation loss: 2.223039373755455

Epoch: 514| Step: 0
Training loss: 0.3736788034439087
Validation loss: 2.1813819060722985

Epoch: 5| Step: 1
Training loss: 0.8366537094116211
Validation loss: 2.101426358024279

Epoch: 5| Step: 2
Training loss: 0.6328211426734924
Validation loss: 2.142698218425115

Epoch: 5| Step: 3
Training loss: 0.7769366502761841
Validation loss: 2.0951512853304544

Epoch: 5| Step: 4
Training loss: 0.974067211151123
Validation loss: 2.103048011660576

Epoch: 5| Step: 5
Training loss: 0.5684462785720825
Validation loss: 2.1460938652356467

Epoch: 5| Step: 6
Training loss: 0.9367197751998901
Validation loss: 2.1231787900129953

Epoch: 5| Step: 7
Training loss: 0.6564314961433411
Validation loss: 2.108264764149984

Epoch: 5| Step: 8
Training loss: 1.2701036930084229
Validation loss: 2.1445175111293793

Epoch: 5| Step: 9
Training loss: 0.9528258442878723
Validation loss: 2.1997477263212204

Epoch: 5| Step: 10
Training loss: 0.8433311581611633
Validation loss: 2.1598175267378488

Epoch: 5| Step: 11
Training loss: 0.34155118465423584
Validation loss: 2.1329514731963477

Epoch: 515| Step: 0
Training loss: 0.4149869978427887
Validation loss: 2.128704165418943

Epoch: 5| Step: 1
Training loss: 0.6471040844917297
Validation loss: 2.137779712677002

Epoch: 5| Step: 2
Training loss: 0.6930827498435974
Validation loss: 2.1248253683249154

Epoch: 5| Step: 3
Training loss: 1.1794685125350952
Validation loss: 2.1796293556690216

Epoch: 5| Step: 4
Training loss: 0.5423967838287354
Validation loss: 2.081155146161715

Epoch: 5| Step: 5
Training loss: 0.6881812214851379
Validation loss: 2.0981615285078683

Epoch: 5| Step: 6
Training loss: 1.0691581964492798
Validation loss: 2.149887591600418

Epoch: 5| Step: 7
Training loss: 0.989201545715332
Validation loss: 2.1633700827757516

Epoch: 5| Step: 8
Training loss: 1.1271120309829712
Validation loss: 2.155576969186465

Epoch: 5| Step: 9
Training loss: 0.7124205827713013
Validation loss: 2.1996461004018784

Epoch: 5| Step: 10
Training loss: 0.7548199892044067
Validation loss: 2.133488819003105

Epoch: 5| Step: 11
Training loss: 0.34681445360183716
Validation loss: 2.0710762987534204

Epoch: 516| Step: 0
Training loss: 1.0514888763427734
Validation loss: 2.180661325653394

Epoch: 5| Step: 1
Training loss: 0.9663764238357544
Validation loss: 2.139959121743838

Epoch: 5| Step: 2
Training loss: 1.1040847301483154
Validation loss: 2.1463847557703652

Epoch: 5| Step: 3
Training loss: 0.7607515454292297
Validation loss: 2.1800464590390525

Epoch: 5| Step: 4
Training loss: 0.6317349672317505
Validation loss: 2.171722561120987

Epoch: 5| Step: 5
Training loss: 0.7233100533485413
Validation loss: 2.1653345872958503

Epoch: 5| Step: 6
Training loss: 0.7166320085525513
Validation loss: 2.185003032286962

Epoch: 5| Step: 7
Training loss: 0.5079500079154968
Validation loss: 2.2212841461102166

Epoch: 5| Step: 8
Training loss: 0.47680920362472534
Validation loss: 2.179572810729345

Epoch: 5| Step: 9
Training loss: 0.3780805468559265
Validation loss: 2.152224143346151

Epoch: 5| Step: 10
Training loss: 1.0600645542144775
Validation loss: 2.1751231203476586

Epoch: 5| Step: 11
Training loss: 1.1297316551208496
Validation loss: 2.1564580351114273

Epoch: 517| Step: 0
Training loss: 0.6910411715507507
Validation loss: 2.1079610933860145

Epoch: 5| Step: 1
Training loss: 1.2213095426559448
Validation loss: 2.153864324092865

Epoch: 5| Step: 2
Training loss: 0.8441165089607239
Validation loss: 2.156576027472814

Epoch: 5| Step: 3
Training loss: 0.5398048162460327
Validation loss: 2.1642272671063743

Epoch: 5| Step: 4
Training loss: 0.8459268808364868
Validation loss: 2.1304816603660583

Epoch: 5| Step: 5
Training loss: 0.9296444058418274
Validation loss: 2.1617583533128104

Epoch: 5| Step: 6
Training loss: 1.0396100282669067
Validation loss: 2.2072651286919913

Epoch: 5| Step: 7
Training loss: 0.6498464345932007
Validation loss: 2.1731382310390472

Epoch: 5| Step: 8
Training loss: 0.7219818830490112
Validation loss: 2.1815098275740943

Epoch: 5| Step: 9
Training loss: 0.5694355368614197
Validation loss: 2.1631509264310202

Epoch: 5| Step: 10
Training loss: 0.6733790636062622
Validation loss: 2.136752059062322

Epoch: 5| Step: 11
Training loss: 1.5265384912490845
Validation loss: 2.162118415037791

Epoch: 518| Step: 0
Training loss: 0.9955833554267883
Validation loss: 2.141380767027537

Epoch: 5| Step: 1
Training loss: 0.8361179232597351
Validation loss: 2.1868038376172385

Epoch: 5| Step: 2
Training loss: 0.6548119187355042
Validation loss: 2.179781566063563

Epoch: 5| Step: 3
Training loss: 0.8969232439994812
Validation loss: 2.153114969531695

Epoch: 5| Step: 4
Training loss: 0.7265394926071167
Validation loss: 2.222569912672043

Epoch: 5| Step: 5
Training loss: 0.5076030492782593
Validation loss: 2.1897926926612854

Epoch: 5| Step: 6
Training loss: 0.7205241918563843
Validation loss: 2.1826676229635873

Epoch: 5| Step: 7
Training loss: 1.1872246265411377
Validation loss: 2.130343124270439

Epoch: 5| Step: 8
Training loss: 0.6922918558120728
Validation loss: 2.1467134058475494

Epoch: 5| Step: 9
Training loss: 1.0747545957565308
Validation loss: 2.0891548792521157

Epoch: 5| Step: 10
Training loss: 0.6158236861228943
Validation loss: 2.1264652460813522

Epoch: 5| Step: 11
Training loss: 0.24733972549438477
Validation loss: 2.1086699018875756

Epoch: 519| Step: 0
Training loss: 0.9328750371932983
Validation loss: 2.101952443520228

Epoch: 5| Step: 1
Training loss: 0.6746785044670105
Validation loss: 2.0984830359617868

Epoch: 5| Step: 2
Training loss: 0.8541695475578308
Validation loss: 2.1316120326519012

Epoch: 5| Step: 3
Training loss: 0.8402783274650574
Validation loss: 2.125454301635424

Epoch: 5| Step: 4
Training loss: 1.0123543739318848
Validation loss: 2.1140530109405518

Epoch: 5| Step: 5
Training loss: 0.6399930715560913
Validation loss: 2.1551038871208825

Epoch: 5| Step: 6
Training loss: 0.837418258190155
Validation loss: 2.1612940977017083

Epoch: 5| Step: 7
Training loss: 0.8225959539413452
Validation loss: 2.1885053316752114

Epoch: 5| Step: 8
Training loss: 0.6647888422012329
Validation loss: 2.2378980070352554

Epoch: 5| Step: 9
Training loss: 1.0886211395263672
Validation loss: 2.188552657763163

Epoch: 5| Step: 10
Training loss: 0.5266236066818237
Validation loss: 2.2165989577770233

Epoch: 5| Step: 11
Training loss: 0.6825969815254211
Validation loss: 2.129756117860476

Epoch: 520| Step: 0
Training loss: 0.5357983708381653
Validation loss: 2.136051500837008

Epoch: 5| Step: 1
Training loss: 0.5208583474159241
Validation loss: 2.1321116536855698

Epoch: 5| Step: 2
Training loss: 1.0416500568389893
Validation loss: 2.0668195386727652

Epoch: 5| Step: 3
Training loss: 1.0993754863739014
Validation loss: 2.1266195873419442

Epoch: 5| Step: 4
Training loss: 0.6297590136528015
Validation loss: 2.0980230967203775

Epoch: 5| Step: 5
Training loss: 0.6134942173957825
Validation loss: 2.1183895270029702

Epoch: 5| Step: 6
Training loss: 0.8945339918136597
Validation loss: 2.1063280006249747

Epoch: 5| Step: 7
Training loss: 0.46701258420944214
Validation loss: 2.157244990269343

Epoch: 5| Step: 8
Training loss: 0.8957939147949219
Validation loss: 2.196634605526924

Epoch: 5| Step: 9
Training loss: 0.777812123298645
Validation loss: 2.1733961353699365

Epoch: 5| Step: 10
Training loss: 0.8329696655273438
Validation loss: 2.181344966093699

Epoch: 5| Step: 11
Training loss: 0.8449331521987915
Validation loss: 2.173356463511785

Epoch: 521| Step: 0
Training loss: 0.6545981168746948
Validation loss: 2.2002616226673126

Epoch: 5| Step: 1
Training loss: 0.60932457447052
Validation loss: 2.220332925518354

Epoch: 5| Step: 2
Training loss: 0.4430236220359802
Validation loss: 2.1681501319011054

Epoch: 5| Step: 3
Training loss: 0.8966252207756042
Validation loss: 2.1960672239462533

Epoch: 5| Step: 4
Training loss: 0.6633619666099548
Validation loss: 2.164823109904925

Epoch: 5| Step: 5
Training loss: 0.7058188915252686
Validation loss: 2.148758669694265

Epoch: 5| Step: 6
Training loss: 0.9891272783279419
Validation loss: 2.132144014040629

Epoch: 5| Step: 7
Training loss: 1.1476715803146362
Validation loss: 2.19094251592954

Epoch: 5| Step: 8
Training loss: 0.5723266005516052
Validation loss: 2.127730906009674

Epoch: 5| Step: 9
Training loss: 0.9860571026802063
Validation loss: 2.093844090898832

Epoch: 5| Step: 10
Training loss: 0.46879369020462036
Validation loss: 2.138839657107989

Epoch: 5| Step: 11
Training loss: 1.3184871673583984
Validation loss: 2.142601897319158

Epoch: 522| Step: 0
Training loss: 0.37725114822387695
Validation loss: 2.168844203154246

Epoch: 5| Step: 1
Training loss: 1.1988606452941895
Validation loss: 2.188977907101313

Epoch: 5| Step: 2
Training loss: 0.48564013838768005
Validation loss: 2.186116029818853

Epoch: 5| Step: 3
Training loss: 0.7123411893844604
Validation loss: 2.215873827536901

Epoch: 5| Step: 4
Training loss: 0.8690999746322632
Validation loss: 2.215499227245649

Epoch: 5| Step: 5
Training loss: 0.7355816960334778
Validation loss: 2.2212246706088385

Epoch: 5| Step: 6
Training loss: 0.9216488599777222
Validation loss: 2.2356902410586676

Epoch: 5| Step: 7
Training loss: 0.6569480895996094
Validation loss: 2.206640303134918

Epoch: 5| Step: 8
Training loss: 1.1121776103973389
Validation loss: 2.227064922451973

Epoch: 5| Step: 9
Training loss: 0.43606215715408325
Validation loss: 2.254370575149854

Epoch: 5| Step: 10
Training loss: 0.863448977470398
Validation loss: 2.222910856207212

Epoch: 5| Step: 11
Training loss: 0.48443418741226196
Validation loss: 2.2155220905939736

Epoch: 523| Step: 0
Training loss: 0.7612016797065735
Validation loss: 2.1792945166428885

Epoch: 5| Step: 1
Training loss: 0.7475044131278992
Validation loss: 2.1594123045603433

Epoch: 5| Step: 2
Training loss: 0.5820544958114624
Validation loss: 2.1678166339794793

Epoch: 5| Step: 3
Training loss: 0.5785617232322693
Validation loss: 2.177693009376526

Epoch: 5| Step: 4
Training loss: 0.8768106698989868
Validation loss: 2.1435368607441583

Epoch: 5| Step: 5
Training loss: 0.9093794822692871
Validation loss: 2.160009041428566

Epoch: 5| Step: 6
Training loss: 0.7580998539924622
Validation loss: 2.1221037159363427

Epoch: 5| Step: 7
Training loss: 0.5131267309188843
Validation loss: 2.1575370331605277

Epoch: 5| Step: 8
Training loss: 0.599136471748352
Validation loss: 2.1419341961542764

Epoch: 5| Step: 9
Training loss: 0.9705103039741516
Validation loss: 2.2121496548255286

Epoch: 5| Step: 10
Training loss: 0.8322576284408569
Validation loss: 2.2975530872742334

Epoch: 5| Step: 11
Training loss: 1.3055419921875
Validation loss: 2.2584500511487327

Epoch: 524| Step: 0
Training loss: 0.5982747673988342
Validation loss: 2.241295958558718

Epoch: 5| Step: 1
Training loss: 0.4808509349822998
Validation loss: 2.195137709379196

Epoch: 5| Step: 2
Training loss: 0.7180549502372742
Validation loss: 2.1927255441745124

Epoch: 5| Step: 3
Training loss: 0.7292936444282532
Validation loss: 2.1714174896478653

Epoch: 5| Step: 4
Training loss: 0.776504635810852
Validation loss: 2.1467711428801217

Epoch: 5| Step: 5
Training loss: 1.0453150272369385
Validation loss: 2.154799739519755

Epoch: 5| Step: 6
Training loss: 0.764369010925293
Validation loss: 2.1508916318416595

Epoch: 5| Step: 7
Training loss: 1.1732124090194702
Validation loss: 2.1516781598329544

Epoch: 5| Step: 8
Training loss: 0.4979909062385559
Validation loss: 2.1680861115455627

Epoch: 5| Step: 9
Training loss: 1.0470163822174072
Validation loss: 2.170577496290207

Epoch: 5| Step: 10
Training loss: 0.6918825507164001
Validation loss: 2.234999438126882

Epoch: 5| Step: 11
Training loss: 1.331878900527954
Validation loss: 2.2406235188245773

Epoch: 525| Step: 0
Training loss: 1.2817790508270264
Validation loss: 2.301295965909958

Epoch: 5| Step: 1
Training loss: 1.091117024421692
Validation loss: 2.3505905071894326

Epoch: 5| Step: 2
Training loss: 0.8970131874084473
Validation loss: 2.291324704885483

Epoch: 5| Step: 3
Training loss: 0.809319019317627
Validation loss: 2.275709201892217

Epoch: 5| Step: 4
Training loss: 0.8076784014701843
Validation loss: 2.1900534431139627

Epoch: 5| Step: 5
Training loss: 0.5826143026351929
Validation loss: 2.194557641943296

Epoch: 5| Step: 6
Training loss: 0.9069679975509644
Validation loss: 2.199181745449702

Epoch: 5| Step: 7
Training loss: 0.6699970960617065
Validation loss: 2.226341406504313

Epoch: 5| Step: 8
Training loss: 1.208783507347107
Validation loss: 2.1546478271484375

Epoch: 5| Step: 9
Training loss: 0.604333221912384
Validation loss: 2.193014085292816

Epoch: 5| Step: 10
Training loss: 0.6050917506217957
Validation loss: 2.1865917245546975

Epoch: 5| Step: 11
Training loss: 0.9151417016983032
Validation loss: 2.1738930443922677

Epoch: 526| Step: 0
Training loss: 0.5903857946395874
Validation loss: 2.2201781968275704

Epoch: 5| Step: 1
Training loss: 1.3774715662002563
Validation loss: 2.178425376613935

Epoch: 5| Step: 2
Training loss: 0.766661524772644
Validation loss: 2.1749627590179443

Epoch: 5| Step: 3
Training loss: 0.58946692943573
Validation loss: 2.186387767394384

Epoch: 5| Step: 4
Training loss: 0.6129817962646484
Validation loss: 2.160774737596512

Epoch: 5| Step: 5
Training loss: 0.7609862089157104
Validation loss: 2.1997803250948587

Epoch: 5| Step: 6
Training loss: 0.712291419506073
Validation loss: 2.141587277253469

Epoch: 5| Step: 7
Training loss: 0.96934574842453
Validation loss: 2.1852346807718277

Epoch: 5| Step: 8
Training loss: 0.9046157598495483
Validation loss: 2.1497546434402466

Epoch: 5| Step: 9
Training loss: 0.9458322525024414
Validation loss: 2.173181856671969

Epoch: 5| Step: 10
Training loss: 0.6493209004402161
Validation loss: 2.2235011607408524

Epoch: 5| Step: 11
Training loss: 0.3630458414554596
Validation loss: 2.1940972407658896

Epoch: 527| Step: 0
Training loss: 0.680555522441864
Validation loss: 2.187312791744868

Epoch: 5| Step: 1
Training loss: 0.793965220451355
Validation loss: 2.2022766123215356

Epoch: 5| Step: 2
Training loss: 0.5190412402153015
Validation loss: 2.2111720144748688

Epoch: 5| Step: 3
Training loss: 0.8026213645935059
Validation loss: 2.1444978962341943

Epoch: 5| Step: 4
Training loss: 0.3897375762462616
Validation loss: 2.1721066534519196

Epoch: 5| Step: 5
Training loss: 0.7679604291915894
Validation loss: 2.1584380070368447

Epoch: 5| Step: 6
Training loss: 0.8487720489501953
Validation loss: 2.1079921076695123

Epoch: 5| Step: 7
Training loss: 0.8760340809822083
Validation loss: 2.123236363132795

Epoch: 5| Step: 8
Training loss: 0.7537118792533875
Validation loss: 2.1090095192193985

Epoch: 5| Step: 9
Training loss: 0.8503085374832153
Validation loss: 2.114209771156311

Epoch: 5| Step: 10
Training loss: 0.8847606778144836
Validation loss: 2.1265611201524734

Epoch: 5| Step: 11
Training loss: 0.8440228700637817
Validation loss: 2.154338836669922

Epoch: 528| Step: 0
Training loss: 0.48456984758377075
Validation loss: 2.1136751721302667

Epoch: 5| Step: 1
Training loss: 0.6986939907073975
Validation loss: 2.2692230443159738

Epoch: 5| Step: 2
Training loss: 0.8223273158073425
Validation loss: 2.1795296470324197

Epoch: 5| Step: 3
Training loss: 0.7990735769271851
Validation loss: 2.2452034254868827

Epoch: 5| Step: 4
Training loss: 0.9727275967597961
Validation loss: 2.1783742954333625

Epoch: 5| Step: 5
Training loss: 0.6482819318771362
Validation loss: 2.1052878946065903

Epoch: 5| Step: 6
Training loss: 0.5834885835647583
Validation loss: 2.1547460158665976

Epoch: 5| Step: 7
Training loss: 0.9432190656661987
Validation loss: 2.1733846167723336

Epoch: 5| Step: 8
Training loss: 0.7136098146438599
Validation loss: 2.213885893424352

Epoch: 5| Step: 9
Training loss: 0.6337205767631531
Validation loss: 2.183621267477671

Epoch: 5| Step: 10
Training loss: 0.7893936038017273
Validation loss: 2.1390346040328345

Epoch: 5| Step: 11
Training loss: 1.2078155279159546
Validation loss: 2.173653155565262

Epoch: 529| Step: 0
Training loss: 0.49790939688682556
Validation loss: 2.1989132463932037

Epoch: 5| Step: 1
Training loss: 1.0782902240753174
Validation loss: 2.153408259153366

Epoch: 5| Step: 2
Training loss: 0.685064435005188
Validation loss: 2.139679123957952

Epoch: 5| Step: 3
Training loss: 1.062284231185913
Validation loss: 2.1491038302580514

Epoch: 5| Step: 4
Training loss: 0.8953167200088501
Validation loss: 2.1968579590320587

Epoch: 5| Step: 5
Training loss: 0.8019353151321411
Validation loss: 2.18117227156957

Epoch: 5| Step: 6
Training loss: 0.7183877229690552
Validation loss: 2.209875762462616

Epoch: 5| Step: 7
Training loss: 0.628150999546051
Validation loss: 2.185965637365977

Epoch: 5| Step: 8
Training loss: 0.4134639799594879
Validation loss: 2.1433668732643127

Epoch: 5| Step: 9
Training loss: 0.5148441195487976
Validation loss: 2.131775716940562

Epoch: 5| Step: 10
Training loss: 0.7008830308914185
Validation loss: 2.1321622828642526

Epoch: 5| Step: 11
Training loss: 0.5367165803909302
Validation loss: 2.1886648635069528

Epoch: 530| Step: 0
Training loss: 0.7874641418457031
Validation loss: 2.1718062460422516

Epoch: 5| Step: 1
Training loss: 0.9903190732002258
Validation loss: 2.186633378267288

Epoch: 5| Step: 2
Training loss: 0.39229312539100647
Validation loss: 2.1284292389949164

Epoch: 5| Step: 3
Training loss: 0.6465513110160828
Validation loss: 2.109697312116623

Epoch: 5| Step: 4
Training loss: 0.7164012789726257
Validation loss: 2.156679521004359

Epoch: 5| Step: 5
Training loss: 0.46656984090805054
Validation loss: 2.165915792187055

Epoch: 5| Step: 6
Training loss: 0.6240667104721069
Validation loss: 2.1589994629224143

Epoch: 5| Step: 7
Training loss: 1.2936131954193115
Validation loss: 2.1653489073117576

Epoch: 5| Step: 8
Training loss: 0.8331853747367859
Validation loss: 2.1675532112518945

Epoch: 5| Step: 9
Training loss: 0.8313370943069458
Validation loss: 2.140592098236084

Epoch: 5| Step: 10
Training loss: 0.444614976644516
Validation loss: 2.169443652033806

Epoch: 5| Step: 11
Training loss: 0.49465179443359375
Validation loss: 2.1656821270783744

Epoch: 531| Step: 0
Training loss: 0.815212070941925
Validation loss: 2.121218661467234

Epoch: 5| Step: 1
Training loss: 0.8220731616020203
Validation loss: 2.125436693429947

Epoch: 5| Step: 2
Training loss: 0.6193876266479492
Validation loss: 2.090295677383741

Epoch: 5| Step: 3
Training loss: 0.6123052835464478
Validation loss: 2.106868917743365

Epoch: 5| Step: 4
Training loss: 0.9616381525993347
Validation loss: 2.1465915540854135

Epoch: 5| Step: 5
Training loss: 0.7730429768562317
Validation loss: 2.1881315310796103

Epoch: 5| Step: 6
Training loss: 0.9050553441047668
Validation loss: 2.1560660898685455

Epoch: 5| Step: 7
Training loss: 0.6097621321678162
Validation loss: 2.177464803059896

Epoch: 5| Step: 8
Training loss: 0.5150416493415833
Validation loss: 2.16647935907046

Epoch: 5| Step: 9
Training loss: 0.766084611415863
Validation loss: 2.1168019523223243

Epoch: 5| Step: 10
Training loss: 0.8983346819877625
Validation loss: 2.13248410820961

Epoch: 5| Step: 11
Training loss: 0.992651104927063
Validation loss: 2.179382691780726

Epoch: 532| Step: 0
Training loss: 0.8117128610610962
Validation loss: 2.1451400419076285

Epoch: 5| Step: 1
Training loss: 1.3923171758651733
Validation loss: 2.186720793445905

Epoch: 5| Step: 2
Training loss: 0.951215922832489
Validation loss: 2.151913349827131

Epoch: 5| Step: 3
Training loss: 0.5513508915901184
Validation loss: 2.12444199124972

Epoch: 5| Step: 4
Training loss: 0.6972138285636902
Validation loss: 2.1617126961549125

Epoch: 5| Step: 5
Training loss: 0.6232529282569885
Validation loss: 2.2367988725503287

Epoch: 5| Step: 6
Training loss: 0.7396886348724365
Validation loss: 2.21668433646361

Epoch: 5| Step: 7
Training loss: 0.5209368467330933
Validation loss: 2.2125138392051062

Epoch: 5| Step: 8
Training loss: 0.577705979347229
Validation loss: 2.1724093010028205

Epoch: 5| Step: 9
Training loss: 0.7914670705795288
Validation loss: 2.1629896064599357

Epoch: 5| Step: 10
Training loss: 0.663823127746582
Validation loss: 2.1135903894901276

Epoch: 5| Step: 11
Training loss: 0.42386913299560547
Validation loss: 2.136598805586497

Epoch: 533| Step: 0
Training loss: 0.43418630957603455
Validation loss: 2.160737340648969

Epoch: 5| Step: 1
Training loss: 0.6749459505081177
Validation loss: 2.143446698784828

Epoch: 5| Step: 2
Training loss: 0.6401503682136536
Validation loss: 2.270017003019651

Epoch: 5| Step: 3
Training loss: 0.920244038105011
Validation loss: 2.3292084286610284

Epoch: 5| Step: 4
Training loss: 0.6346872448921204
Validation loss: 2.3227481047312417

Epoch: 5| Step: 5
Training loss: 0.7552317380905151
Validation loss: 2.294021258751551

Epoch: 5| Step: 6
Training loss: 0.49888572096824646
Validation loss: 2.282629837592443

Epoch: 5| Step: 7
Training loss: 0.530380129814148
Validation loss: 2.1983481446901956

Epoch: 5| Step: 8
Training loss: 1.015376329421997
Validation loss: 2.1792177508274713

Epoch: 5| Step: 9
Training loss: 1.5399668216705322
Validation loss: 2.1363182862599692

Epoch: 5| Step: 10
Training loss: 0.9988405108451843
Validation loss: 2.139337047934532

Epoch: 5| Step: 11
Training loss: 0.6200414896011353
Validation loss: 2.182963321606318

Epoch: 534| Step: 0
Training loss: 0.7056506276130676
Validation loss: 2.1523366570472717

Epoch: 5| Step: 1
Training loss: 0.6732667684555054
Validation loss: 2.1845550537109375

Epoch: 5| Step: 2
Training loss: 0.9296032190322876
Validation loss: 2.186945507923762

Epoch: 5| Step: 3
Training loss: 0.8617447018623352
Validation loss: 2.2320694476366043

Epoch: 5| Step: 4
Training loss: 0.5573371648788452
Validation loss: 2.2075198590755463

Epoch: 5| Step: 5
Training loss: 0.6329672932624817
Validation loss: 2.2037950654824576

Epoch: 5| Step: 6
Training loss: 0.8467159271240234
Validation loss: 2.153151830037435

Epoch: 5| Step: 7
Training loss: 1.0215613842010498
Validation loss: 2.176279366016388

Epoch: 5| Step: 8
Training loss: 0.5342956185340881
Validation loss: 2.148887957135836

Epoch: 5| Step: 9
Training loss: 0.9364442825317383
Validation loss: 2.124032139778137

Epoch: 5| Step: 10
Training loss: 1.353144884109497
Validation loss: 2.17861137787501

Epoch: 5| Step: 11
Training loss: 0.8059073686599731
Validation loss: 2.189041177431742

Epoch: 535| Step: 0
Training loss: 0.7447658777236938
Validation loss: 2.1556035031874976

Epoch: 5| Step: 1
Training loss: 1.3122438192367554
Validation loss: 2.1371616472800574

Epoch: 5| Step: 2
Training loss: 0.7271479368209839
Validation loss: 2.232943137486776

Epoch: 5| Step: 3
Training loss: 1.0565578937530518
Validation loss: 2.3004607210556665

Epoch: 5| Step: 4
Training loss: 0.6843731999397278
Validation loss: 2.3547205924987793

Epoch: 5| Step: 5
Training loss: 0.6297086477279663
Validation loss: 2.3328755299250283

Epoch: 5| Step: 6
Training loss: 0.9305578470230103
Validation loss: 2.292863974968592

Epoch: 5| Step: 7
Training loss: 0.815853476524353
Validation loss: 2.203592504064242

Epoch: 5| Step: 8
Training loss: 0.45034345984458923
Validation loss: 2.1792971839507422

Epoch: 5| Step: 9
Training loss: 1.0858895778656006
Validation loss: 2.1898082345724106

Epoch: 5| Step: 10
Training loss: 1.0840513706207275
Validation loss: 2.2156937519709268

Epoch: 5| Step: 11
Training loss: 0.3723398745059967
Validation loss: 2.219138875603676

Epoch: 536| Step: 0
Training loss: 0.5821541547775269
Validation loss: 2.2204151898622513

Epoch: 5| Step: 1
Training loss: 1.074661374092102
Validation loss: 2.19107515613238

Epoch: 5| Step: 2
Training loss: 0.39039286971092224
Validation loss: 2.240095595518748

Epoch: 5| Step: 3
Training loss: 0.9212400317192078
Validation loss: 2.2324578066666922

Epoch: 5| Step: 4
Training loss: 0.5442134141921997
Validation loss: 2.233134130636851

Epoch: 5| Step: 5
Training loss: 0.9737975001335144
Validation loss: 2.2455592453479767

Epoch: 5| Step: 6
Training loss: 1.2305946350097656
Validation loss: 2.254981150229772

Epoch: 5| Step: 7
Training loss: 0.5170953869819641
Validation loss: 2.2864633997281394

Epoch: 5| Step: 8
Training loss: 0.7881900668144226
Validation loss: 2.1833686033884683

Epoch: 5| Step: 9
Training loss: 0.8922353982925415
Validation loss: 2.190748249491056

Epoch: 5| Step: 10
Training loss: 0.6937142610549927
Validation loss: 2.185232957204183

Epoch: 5| Step: 11
Training loss: 0.15175235271453857
Validation loss: 2.1225436627864838

Epoch: 537| Step: 0
Training loss: 0.5937418341636658
Validation loss: 2.1713819801807404

Epoch: 5| Step: 1
Training loss: 0.9250640869140625
Validation loss: 2.1832290490468345

Epoch: 5| Step: 2
Training loss: 0.8833869695663452
Validation loss: 2.1958534717559814

Epoch: 5| Step: 3
Training loss: 0.5040704607963562
Validation loss: 2.154475306471189

Epoch: 5| Step: 4
Training loss: 0.7924483418464661
Validation loss: 2.192271962761879

Epoch: 5| Step: 5
Training loss: 0.5891483426094055
Validation loss: 2.1861471831798553

Epoch: 5| Step: 6
Training loss: 0.7882727384567261
Validation loss: 2.2561806539694467

Epoch: 5| Step: 7
Training loss: 0.947733998298645
Validation loss: 2.230829561750094

Epoch: 5| Step: 8
Training loss: 0.7772504687309265
Validation loss: 2.253250772754351

Epoch: 5| Step: 9
Training loss: 1.169252872467041
Validation loss: 2.3026343286037445

Epoch: 5| Step: 10
Training loss: 0.47309809923171997
Validation loss: 2.253114034732183

Epoch: 5| Step: 11
Training loss: 2.0201773643493652
Validation loss: 2.221042901277542

Epoch: 538| Step: 0
Training loss: 0.676445484161377
Validation loss: 2.2256816774606705

Epoch: 5| Step: 1
Training loss: 0.7632554173469543
Validation loss: 2.1951829691727958

Epoch: 5| Step: 2
Training loss: 0.6221851110458374
Validation loss: 2.1316828529040017

Epoch: 5| Step: 3
Training loss: 0.6043798923492432
Validation loss: 2.1469980478286743

Epoch: 5| Step: 4
Training loss: 0.6153000593185425
Validation loss: 2.1285961816708245

Epoch: 5| Step: 5
Training loss: 0.5895454287528992
Validation loss: 2.1835676381985345

Epoch: 5| Step: 6
Training loss: 1.1234101057052612
Validation loss: 2.1534001231193542

Epoch: 5| Step: 7
Training loss: 0.7379603981971741
Validation loss: 2.18286761144797

Epoch: 5| Step: 8
Training loss: 0.7475331425666809
Validation loss: 2.171466996272405

Epoch: 5| Step: 9
Training loss: 0.9423729181289673
Validation loss: 2.2144678433736167

Epoch: 5| Step: 10
Training loss: 0.9410494565963745
Validation loss: 2.2141535927851996

Epoch: 5| Step: 11
Training loss: 1.0341649055480957
Validation loss: 2.242057686050733

Epoch: 539| Step: 0
Training loss: 0.7624797821044922
Validation loss: 2.236494650443395

Epoch: 5| Step: 1
Training loss: 0.6896227598190308
Validation loss: 2.249400109052658

Epoch: 5| Step: 2
Training loss: 0.7473016381263733
Validation loss: 2.303936173518499

Epoch: 5| Step: 3
Training loss: 0.7743914723396301
Validation loss: 2.2522467176119485

Epoch: 5| Step: 4
Training loss: 0.782056450843811
Validation loss: 2.2367080052693686

Epoch: 5| Step: 5
Training loss: 0.6336890459060669
Validation loss: 2.1664231618245444

Epoch: 5| Step: 6
Training loss: 0.6647289991378784
Validation loss: 2.1412364691495895

Epoch: 5| Step: 7
Training loss: 1.005246639251709
Validation loss: 2.1530831158161163

Epoch: 5| Step: 8
Training loss: 1.1797512769699097
Validation loss: 2.1548031667868295

Epoch: 5| Step: 9
Training loss: 0.8523661494255066
Validation loss: 2.1627234518527985

Epoch: 5| Step: 10
Training loss: 0.6291480660438538
Validation loss: 2.137389192978541

Epoch: 5| Step: 11
Training loss: 0.16954252123832703
Validation loss: 2.1663715740044913

Epoch: 540| Step: 0
Training loss: 0.7350783348083496
Validation loss: 2.166911651690801

Epoch: 5| Step: 1
Training loss: 0.9064735174179077
Validation loss: 2.205610156059265

Epoch: 5| Step: 2
Training loss: 0.9105228185653687
Validation loss: 2.206392685572306

Epoch: 5| Step: 3
Training loss: 0.7909260988235474
Validation loss: 2.1875438541173935

Epoch: 5| Step: 4
Training loss: 0.6139654517173767
Validation loss: 2.208788350224495

Epoch: 5| Step: 5
Training loss: 1.0397675037384033
Validation loss: 2.164083460966746

Epoch: 5| Step: 6
Training loss: 0.5795269012451172
Validation loss: 2.174912080168724

Epoch: 5| Step: 7
Training loss: 0.5804499387741089
Validation loss: 2.1546632200479507

Epoch: 5| Step: 8
Training loss: 0.5481883883476257
Validation loss: 2.143025358517965

Epoch: 5| Step: 9
Training loss: 0.6710838675498962
Validation loss: 2.1673161635796228

Epoch: 5| Step: 10
Training loss: 0.5199100971221924
Validation loss: 2.133253345886866

Epoch: 5| Step: 11
Training loss: 0.14492321014404297
Validation loss: 2.13350140551726

Epoch: 541| Step: 0
Training loss: 0.6384031176567078
Validation loss: 2.1420563459396362

Epoch: 5| Step: 1
Training loss: 0.6088234186172485
Validation loss: 2.121400147676468

Epoch: 5| Step: 2
Training loss: 0.7016394734382629
Validation loss: 2.1439937899510064

Epoch: 5| Step: 3
Training loss: 0.4511933922767639
Validation loss: 2.0834827522436776

Epoch: 5| Step: 4
Training loss: 0.9571282267570496
Validation loss: 2.143081098794937

Epoch: 5| Step: 5
Training loss: 0.7854821085929871
Validation loss: 2.1716775397459664

Epoch: 5| Step: 6
Training loss: 0.49255451560020447
Validation loss: 2.1052604566017785

Epoch: 5| Step: 7
Training loss: 0.5310422778129578
Validation loss: 2.2517459293206534

Epoch: 5| Step: 8
Training loss: 0.7012221813201904
Validation loss: 2.2204811026652655

Epoch: 5| Step: 9
Training loss: 0.7704403400421143
Validation loss: 2.1437870860099792

Epoch: 5| Step: 10
Training loss: 1.084202527999878
Validation loss: 2.126200258731842

Epoch: 5| Step: 11
Training loss: 0.6933118104934692
Validation loss: 2.1213334699471793

Epoch: 542| Step: 0
Training loss: 0.65522700548172
Validation loss: 2.126705303788185

Epoch: 5| Step: 1
Training loss: 0.5092765092849731
Validation loss: 2.1303060054779053

Epoch: 5| Step: 2
Training loss: 0.9632965326309204
Validation loss: 2.1506709307432175

Epoch: 5| Step: 3
Training loss: 0.610581636428833
Validation loss: 2.131419688463211

Epoch: 5| Step: 4
Training loss: 0.5826455354690552
Validation loss: 2.089202950398127

Epoch: 5| Step: 5
Training loss: 1.1089400053024292
Validation loss: 2.1226747830708823

Epoch: 5| Step: 6
Training loss: 0.8220826983451843
Validation loss: 2.1366319010655084

Epoch: 5| Step: 7
Training loss: 0.6812229752540588
Validation loss: 2.1463392029205957

Epoch: 5| Step: 8
Training loss: 0.7581014037132263
Validation loss: 2.1392785211404166

Epoch: 5| Step: 9
Training loss: 0.5974735021591187
Validation loss: 2.1673678706089654

Epoch: 5| Step: 10
Training loss: 0.5516027212142944
Validation loss: 2.1663752098878226

Epoch: 5| Step: 11
Training loss: 0.4201294183731079
Validation loss: 2.160664548476537

Epoch: 543| Step: 0
Training loss: 0.6076001524925232
Validation loss: 2.1514177918434143

Epoch: 5| Step: 1
Training loss: 0.6829520463943481
Validation loss: 2.1631485521793365

Epoch: 5| Step: 2
Training loss: 1.1576048135757446
Validation loss: 2.165247122446696

Epoch: 5| Step: 3
Training loss: 0.9278532862663269
Validation loss: 2.127969190478325

Epoch: 5| Step: 4
Training loss: 0.841429591178894
Validation loss: 2.1670864671468735

Epoch: 5| Step: 5
Training loss: 0.8234239816665649
Validation loss: 2.1144332587718964

Epoch: 5| Step: 6
Training loss: 1.0356186628341675
Validation loss: 2.136875872810682

Epoch: 5| Step: 7
Training loss: 0.8174735903739929
Validation loss: 2.186784322063128

Epoch: 5| Step: 8
Training loss: 0.5496430993080139
Validation loss: 2.1904645760854087

Epoch: 5| Step: 9
Training loss: 0.7881439328193665
Validation loss: 2.221668849388758

Epoch: 5| Step: 10
Training loss: 0.5572854280471802
Validation loss: 2.158826490243276

Epoch: 5| Step: 11
Training loss: 0.7898353934288025
Validation loss: 2.1086213886737823

Epoch: 544| Step: 0
Training loss: 0.9502479434013367
Validation loss: 2.186783581972122

Epoch: 5| Step: 1
Training loss: 0.6393062472343445
Validation loss: 2.140282154083252

Epoch: 5| Step: 2
Training loss: 0.2647314667701721
Validation loss: 2.205064261953036

Epoch: 5| Step: 3
Training loss: 0.3106347918510437
Validation loss: 2.1708655655384064

Epoch: 5| Step: 4
Training loss: 0.8131935000419617
Validation loss: 2.1699066211779914

Epoch: 5| Step: 5
Training loss: 0.9367448687553406
Validation loss: 2.2199429720640182

Epoch: 5| Step: 6
Training loss: 0.9974552989006042
Validation loss: 2.147195508082708

Epoch: 5| Step: 7
Training loss: 0.6950966715812683
Validation loss: 2.196474860111872

Epoch: 5| Step: 8
Training loss: 0.4309404492378235
Validation loss: 2.1844596763451896

Epoch: 5| Step: 9
Training loss: 0.5593725442886353
Validation loss: 2.209502190351486

Epoch: 5| Step: 10
Training loss: 1.2672522068023682
Validation loss: 2.213206246495247

Epoch: 5| Step: 11
Training loss: 0.33433640003204346
Validation loss: 2.203275819619497

Epoch: 545| Step: 0
Training loss: 0.7165902853012085
Validation loss: 2.153690551718076

Epoch: 5| Step: 1
Training loss: 0.7643719911575317
Validation loss: 2.1659377813339233

Epoch: 5| Step: 2
Training loss: 0.7014049291610718
Validation loss: 2.146690681576729

Epoch: 5| Step: 3
Training loss: 0.6187392473220825
Validation loss: 2.2007315953572593

Epoch: 5| Step: 4
Training loss: 0.46779173612594604
Validation loss: 2.1226770828167596

Epoch: 5| Step: 5
Training loss: 0.44552022218704224
Validation loss: 2.1504260102907815

Epoch: 5| Step: 6
Training loss: 0.7909530997276306
Validation loss: 2.151833236217499

Epoch: 5| Step: 7
Training loss: 0.5455169081687927
Validation loss: 2.1509087731440864

Epoch: 5| Step: 8
Training loss: 0.9523002505302429
Validation loss: 2.1610765159130096

Epoch: 5| Step: 9
Training loss: 0.8876155614852905
Validation loss: 2.1941785166660943

Epoch: 5| Step: 10
Training loss: 0.6569011807441711
Validation loss: 2.1675835102796555

Epoch: 5| Step: 11
Training loss: 0.7183990478515625
Validation loss: 2.230469435453415

Epoch: 546| Step: 0
Training loss: 0.9659339785575867
Validation loss: 2.2256610691547394

Epoch: 5| Step: 1
Training loss: 0.892532229423523
Validation loss: 2.2568558355172477

Epoch: 5| Step: 2
Training loss: 1.141822099685669
Validation loss: 2.280968109766642

Epoch: 5| Step: 3
Training loss: 0.7485619187355042
Validation loss: 2.225486934185028

Epoch: 5| Step: 4
Training loss: 0.8392403721809387
Validation loss: 2.1712875167528787

Epoch: 5| Step: 5
Training loss: 0.4700074791908264
Validation loss: 2.144244079788526

Epoch: 5| Step: 6
Training loss: 0.718915581703186
Validation loss: 2.1606658597787223

Epoch: 5| Step: 7
Training loss: 0.6212655901908875
Validation loss: 2.1984309355417886

Epoch: 5| Step: 8
Training loss: 0.44955262541770935
Validation loss: 2.1296028047800064

Epoch: 5| Step: 9
Training loss: 0.6164981126785278
Validation loss: 2.1177370895942054

Epoch: 5| Step: 10
Training loss: 0.5416483879089355
Validation loss: 2.1499471217393875

Epoch: 5| Step: 11
Training loss: 0.24157047271728516
Validation loss: 2.22834320863088

Epoch: 547| Step: 0
Training loss: 0.7264825701713562
Validation loss: 2.1806544611851373

Epoch: 5| Step: 1
Training loss: 0.3203294575214386
Validation loss: 2.214608053366343

Epoch: 5| Step: 2
Training loss: 1.0057226419448853
Validation loss: 2.269704262415568

Epoch: 5| Step: 3
Training loss: 1.2437636852264404
Validation loss: 2.2951409220695496

Epoch: 5| Step: 4
Training loss: 0.6500992178916931
Validation loss: 2.220145801703135

Epoch: 5| Step: 5
Training loss: 0.8423492312431335
Validation loss: 2.20851993560791

Epoch: 5| Step: 6
Training loss: 0.42136842012405396
Validation loss: 2.2038393716017404

Epoch: 5| Step: 7
Training loss: 0.5754488706588745
Validation loss: 2.169457048177719

Epoch: 5| Step: 8
Training loss: 0.6928364038467407
Validation loss: 2.1618653436501822

Epoch: 5| Step: 9
Training loss: 0.710370659828186
Validation loss: 2.1422027548154197

Epoch: 5| Step: 10
Training loss: 0.558728814125061
Validation loss: 2.135492205619812

Epoch: 5| Step: 11
Training loss: 1.0306410789489746
Validation loss: 2.1584101915359497

Epoch: 548| Step: 0
Training loss: 0.46239566802978516
Validation loss: 2.2029102941354117

Epoch: 5| Step: 1
Training loss: 0.5930389165878296
Validation loss: 2.354385942220688

Epoch: 5| Step: 2
Training loss: 1.2624844312667847
Validation loss: 2.413803165157636

Epoch: 5| Step: 3
Training loss: 0.9060964584350586
Validation loss: 2.4587903320789337

Epoch: 5| Step: 4
Training loss: 1.0982987880706787
Validation loss: 2.3406664629777274

Epoch: 5| Step: 5
Training loss: 1.2661359310150146
Validation loss: 2.3316600769758224

Epoch: 5| Step: 6
Training loss: 0.8072234988212585
Validation loss: 2.2611044446627298

Epoch: 5| Step: 7
Training loss: 0.6301109194755554
Validation loss: 2.26008377969265

Epoch: 5| Step: 8
Training loss: 0.5754190683364868
Validation loss: 2.1981436014175415

Epoch: 5| Step: 9
Training loss: 0.5785428881645203
Validation loss: 2.152256414294243

Epoch: 5| Step: 10
Training loss: 0.6831042766571045
Validation loss: 2.1438327183326087

Epoch: 5| Step: 11
Training loss: 0.7039732336997986
Validation loss: 2.099050536751747

Epoch: 549| Step: 0
Training loss: 0.9750148057937622
Validation loss: 2.166592409213384

Epoch: 5| Step: 1
Training loss: 0.6688030362129211
Validation loss: 2.1231821527083716

Epoch: 5| Step: 2
Training loss: 0.6383289098739624
Validation loss: 2.1275989562273026

Epoch: 5| Step: 3
Training loss: 0.3431268334388733
Validation loss: 2.1765567610661187

Epoch: 5| Step: 4
Training loss: 0.41995495557785034
Validation loss: 2.158613085746765

Epoch: 5| Step: 5
Training loss: 0.7444049119949341
Validation loss: 2.1333834578593573

Epoch: 5| Step: 6
Training loss: 0.6500033736228943
Validation loss: 2.175715913375219

Epoch: 5| Step: 7
Training loss: 0.7523226141929626
Validation loss: 2.214261452356974

Epoch: 5| Step: 8
Training loss: 1.233177900314331
Validation loss: 2.1759033103783927

Epoch: 5| Step: 9
Training loss: 0.8088656663894653
Validation loss: 2.196644296248754

Epoch: 5| Step: 10
Training loss: 0.5220240354537964
Validation loss: 2.2742556780576706

Epoch: 5| Step: 11
Training loss: 0.6649840474128723
Validation loss: 2.2375489374001822

Epoch: 550| Step: 0
Training loss: 0.49616917967796326
Validation loss: 2.269268607099851

Epoch: 5| Step: 1
Training loss: 0.5002161860466003
Validation loss: 2.234021246433258

Epoch: 5| Step: 2
Training loss: 0.5694531798362732
Validation loss: 2.3138743142286935

Epoch: 5| Step: 3
Training loss: 0.7160462141036987
Validation loss: 2.299543301264445

Epoch: 5| Step: 4
Training loss: 0.6600745916366577
Validation loss: 2.304947371284167

Epoch: 5| Step: 5
Training loss: 0.7798764109611511
Validation loss: 2.280025064945221

Epoch: 5| Step: 6
Training loss: 0.5474548935890198
Validation loss: 2.255499099691709

Epoch: 5| Step: 7
Training loss: 1.5215632915496826
Validation loss: 2.218287537495295

Epoch: 5| Step: 8
Training loss: 0.3931364417076111
Validation loss: 2.192281574010849

Epoch: 5| Step: 9
Training loss: 0.6019231081008911
Validation loss: 2.199051866928736

Epoch: 5| Step: 10
Training loss: 0.7298556566238403
Validation loss: 2.2273410161336265

Epoch: 5| Step: 11
Training loss: 0.31500446796417236
Validation loss: 2.1616538614034653

Testing loss: 1.9435847302992566
