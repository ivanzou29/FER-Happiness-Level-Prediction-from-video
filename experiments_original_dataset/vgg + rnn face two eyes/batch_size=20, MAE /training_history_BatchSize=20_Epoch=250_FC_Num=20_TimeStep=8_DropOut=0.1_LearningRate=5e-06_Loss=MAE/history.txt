Epoch: 1| Step: 0
Training loss: 5.946226119995117
Validation loss: 5.357583304246266

Epoch: 5| Step: 1
Training loss: 4.879392623901367
Validation loss: 5.355921546618144

Epoch: 5| Step: 2
Training loss: 5.4029221534729
Validation loss: 5.354237178961436

Epoch: 5| Step: 3
Training loss: 5.380841255187988
Validation loss: 5.352572977542877

Epoch: 5| Step: 4
Training loss: 6.209162712097168
Validation loss: 5.35099333524704

Epoch: 5| Step: 5
Training loss: 5.282440185546875
Validation loss: 5.349351723988851

Epoch: 5| Step: 6
Training loss: 4.789957523345947
Validation loss: 5.347679555416107

Epoch: 5| Step: 7
Training loss: 5.9156904220581055
Validation loss: 5.34604827562968

Epoch: 5| Step: 8
Training loss: 5.473321914672852
Validation loss: 5.34430597225825

Epoch: 5| Step: 9
Training loss: 5.476286888122559
Validation loss: 5.342352986335754

Epoch: 5| Step: 10
Training loss: 5.099437713623047
Validation loss: 5.340578715006511

Epoch: 5| Step: 11
Training loss: 4.129199981689453
Validation loss: 5.338494499524434

Epoch: 2| Step: 0
Training loss: 5.809931755065918
Validation loss: 5.336366534233093

Epoch: 5| Step: 1
Training loss: 5.661149978637695
Validation loss: 5.33416889111201

Epoch: 5| Step: 2
Training loss: 5.222156524658203
Validation loss: 5.331816116968791

Epoch: 5| Step: 3
Training loss: 5.922276496887207
Validation loss: 5.329329868157704

Epoch: 5| Step: 4
Training loss: 4.558122158050537
Validation loss: 5.326674123605092

Epoch: 5| Step: 5
Training loss: 5.853814601898193
Validation loss: 5.323986013730367

Epoch: 5| Step: 6
Training loss: 4.907544136047363
Validation loss: 5.3209468126297

Epoch: 5| Step: 7
Training loss: 5.238591194152832
Validation loss: 5.318006972471873

Epoch: 5| Step: 8
Training loss: 4.710615158081055
Validation loss: 5.314791818459828

Epoch: 5| Step: 9
Training loss: 6.091905117034912
Validation loss: 5.3113972544670105

Epoch: 5| Step: 10
Training loss: 5.426095008850098
Validation loss: 5.307693044344584

Epoch: 5| Step: 11
Training loss: 4.921414375305176
Validation loss: 5.3039683898289995

Epoch: 3| Step: 0
Training loss: 5.355372428894043
Validation loss: 5.299819389979045

Epoch: 5| Step: 1
Training loss: 5.527819633483887
Validation loss: 5.295590182145436

Epoch: 5| Step: 2
Training loss: 4.667518615722656
Validation loss: 5.291059712568919

Epoch: 5| Step: 3
Training loss: 6.56909704208374
Validation loss: 5.286325454711914

Epoch: 5| Step: 4
Training loss: 5.466275215148926
Validation loss: 5.281314571698506

Epoch: 5| Step: 5
Training loss: 4.968420505523682
Validation loss: 5.276057223478953

Epoch: 5| Step: 6
Training loss: 5.586109161376953
Validation loss: 5.270516137282054

Epoch: 5| Step: 7
Training loss: 5.139559745788574
Validation loss: 5.264930784702301

Epoch: 5| Step: 8
Training loss: 4.326822280883789
Validation loss: 5.259002546469371

Epoch: 5| Step: 9
Training loss: 6.13079309463501
Validation loss: 5.252583781878154

Epoch: 5| Step: 10
Training loss: 4.741624355316162
Validation loss: 5.245977799097697

Epoch: 5| Step: 11
Training loss: 6.858063697814941
Validation loss: 5.238981942335765

Epoch: 4| Step: 0
Training loss: 6.43322229385376
Validation loss: 5.231876929601033

Epoch: 5| Step: 1
Training loss: 5.053849697113037
Validation loss: 5.224542697270711

Epoch: 5| Step: 2
Training loss: 4.929041862487793
Validation loss: 5.216509242852529

Epoch: 5| Step: 3
Training loss: 5.046360969543457
Validation loss: 5.2087587515513105

Epoch: 5| Step: 4
Training loss: 5.910666465759277
Validation loss: 5.200106263160706

Epoch: 5| Step: 5
Training loss: 4.065707206726074
Validation loss: 5.191575825214386

Epoch: 5| Step: 6
Training loss: 5.439309120178223
Validation loss: 5.182851850986481

Epoch: 5| Step: 7
Training loss: 4.849998474121094
Validation loss: 5.17410750190417

Epoch: 5| Step: 8
Training loss: 5.1712846755981445
Validation loss: 5.164896607398987

Epoch: 5| Step: 9
Training loss: 5.899228096008301
Validation loss: 5.155282457669576

Epoch: 5| Step: 10
Training loss: 5.10338020324707
Validation loss: 5.1453070640563965

Epoch: 5| Step: 11
Training loss: 5.130146026611328
Validation loss: 5.135799864927928

Epoch: 5| Step: 0
Training loss: 5.382080078125
Validation loss: 5.125871996084849

Epoch: 5| Step: 1
Training loss: 5.060144901275635
Validation loss: 5.1159854332606

Epoch: 5| Step: 2
Training loss: 4.898468494415283
Validation loss: 5.105401039123535

Epoch: 5| Step: 3
Training loss: 4.94260311126709
Validation loss: 5.0952757596969604

Epoch: 5| Step: 4
Training loss: 5.380529403686523
Validation loss: 5.084623316923778

Epoch: 5| Step: 5
Training loss: 4.854808807373047
Validation loss: 5.074328621228536

Epoch: 5| Step: 6
Training loss: 4.8213701248168945
Validation loss: 5.064087867736816

Epoch: 5| Step: 7
Training loss: 4.619963645935059
Validation loss: 5.053773522377014

Epoch: 5| Step: 8
Training loss: 4.748635292053223
Validation loss: 5.043222030003865

Epoch: 5| Step: 9
Training loss: 6.556402683258057
Validation loss: 5.032665352026622

Epoch: 5| Step: 10
Training loss: 5.347287178039551
Validation loss: 5.021885097026825

Epoch: 5| Step: 11
Training loss: 5.29650354385376
Validation loss: 5.01162326335907

Epoch: 6| Step: 0
Training loss: 5.034517288208008
Validation loss: 5.0007850130399065

Epoch: 5| Step: 1
Training loss: 4.630611896514893
Validation loss: 4.990192631880443

Epoch: 5| Step: 2
Training loss: 5.738182544708252
Validation loss: 4.9797826409339905

Epoch: 5| Step: 3
Training loss: 4.914999961853027
Validation loss: 4.968870759010315

Epoch: 5| Step: 4
Training loss: 5.224772930145264
Validation loss: 4.957911888758342

Epoch: 5| Step: 5
Training loss: 4.886359691619873
Validation loss: 4.9469117025534315

Epoch: 5| Step: 6
Training loss: 4.736214637756348
Validation loss: 4.935452520847321

Epoch: 5| Step: 7
Training loss: 4.224997520446777
Validation loss: 4.9243203202883405

Epoch: 5| Step: 8
Training loss: 5.903256416320801
Validation loss: 4.913190384705861

Epoch: 5| Step: 9
Training loss: 4.886353969573975
Validation loss: 4.902041018009186

Epoch: 5| Step: 10
Training loss: 5.513503074645996
Validation loss: 4.890727738539378

Epoch: 5| Step: 11
Training loss: 3.15040922164917
Validation loss: 4.880156179269155

Epoch: 7| Step: 0
Training loss: 4.6945672035217285
Validation loss: 4.87022066116333

Epoch: 5| Step: 1
Training loss: 4.928287982940674
Validation loss: 4.860259612401326

Epoch: 5| Step: 2
Training loss: 4.7612104415893555
Validation loss: 4.850701967875163

Epoch: 5| Step: 3
Training loss: 4.5695481300354
Validation loss: 4.841798444588979

Epoch: 5| Step: 4
Training loss: 5.130710601806641
Validation loss: 4.833117167154948

Epoch: 5| Step: 5
Training loss: 5.040343761444092
Validation loss: 4.82462336619695

Epoch: 5| Step: 6
Training loss: 4.421191215515137
Validation loss: 4.816019852956136

Epoch: 5| Step: 7
Training loss: 5.303123950958252
Validation loss: 4.807357887427012

Epoch: 5| Step: 8
Training loss: 4.923712253570557
Validation loss: 4.798371533552806

Epoch: 5| Step: 9
Training loss: 5.477067470550537
Validation loss: 4.789991637070973

Epoch: 5| Step: 10
Training loss: 4.881708145141602
Validation loss: 4.781535545984904

Epoch: 5| Step: 11
Training loss: 4.409278392791748
Validation loss: 4.7726388573646545

Epoch: 8| Step: 0
Training loss: 4.7967095375061035
Validation loss: 4.764504313468933

Epoch: 5| Step: 1
Training loss: 4.821974277496338
Validation loss: 4.755978643894196

Epoch: 5| Step: 2
Training loss: 4.732207298278809
Validation loss: 4.748035788536072

Epoch: 5| Step: 3
Training loss: 5.190189361572266
Validation loss: 4.739673227071762

Epoch: 5| Step: 4
Training loss: 4.564111232757568
Validation loss: 4.7315429250399275

Epoch: 5| Step: 5
Training loss: 4.5533833503723145
Validation loss: 4.723409533500671

Epoch: 5| Step: 6
Training loss: 4.952211856842041
Validation loss: 4.715645770231883

Epoch: 5| Step: 7
Training loss: 3.5545921325683594
Validation loss: 4.707862834135692

Epoch: 5| Step: 8
Training loss: 5.343803405761719
Validation loss: 4.700443466504415

Epoch: 5| Step: 9
Training loss: 5.542569160461426
Validation loss: 4.692515293757121

Epoch: 5| Step: 10
Training loss: 4.767088413238525
Validation loss: 4.684807101885478

Epoch: 5| Step: 11
Training loss: 5.59660530090332
Validation loss: 4.677392264207204

Epoch: 9| Step: 0
Training loss: 5.1934614181518555
Validation loss: 4.6691348751386

Epoch: 5| Step: 1
Training loss: 5.521903038024902
Validation loss: 4.6608525315920515

Epoch: 5| Step: 2
Training loss: 4.61989688873291
Validation loss: 4.652631938457489

Epoch: 5| Step: 3
Training loss: 5.441812038421631
Validation loss: 4.644442657629649

Epoch: 5| Step: 4
Training loss: 4.055084228515625
Validation loss: 4.635875006516774

Epoch: 5| Step: 5
Training loss: 4.2001495361328125
Validation loss: 4.62823086977005

Epoch: 5| Step: 6
Training loss: 4.561315059661865
Validation loss: 4.619881371657054

Epoch: 5| Step: 7
Training loss: 5.42453670501709
Validation loss: 4.6116903424263

Epoch: 5| Step: 8
Training loss: 4.1610589027404785
Validation loss: 4.603905359903972

Epoch: 5| Step: 9
Training loss: 4.278763771057129
Validation loss: 4.596366922060649

Epoch: 5| Step: 10
Training loss: 4.776467800140381
Validation loss: 4.587923268477122

Epoch: 5| Step: 11
Training loss: 3.480146646499634
Validation loss: 4.579148282607396

Epoch: 10| Step: 0
Training loss: 4.639791965484619
Validation loss: 4.570047338803609

Epoch: 5| Step: 1
Training loss: 5.1418867111206055
Validation loss: 4.561078766981761

Epoch: 5| Step: 2
Training loss: 4.43906307220459
Validation loss: 4.552143553892772

Epoch: 5| Step: 3
Training loss: 4.176341533660889
Validation loss: 4.544481744368871

Epoch: 5| Step: 4
Training loss: 4.823675632476807
Validation loss: 4.536470383405685

Epoch: 5| Step: 5
Training loss: 4.8925652503967285
Validation loss: 4.529083430767059

Epoch: 5| Step: 6
Training loss: 4.9831671714782715
Validation loss: 4.520873516798019

Epoch: 5| Step: 7
Training loss: 4.289540767669678
Validation loss: 4.513069113095601

Epoch: 5| Step: 8
Training loss: 5.004826545715332
Validation loss: 4.504493395487468

Epoch: 5| Step: 9
Training loss: 4.166867733001709
Validation loss: 4.49633526802063

Epoch: 5| Step: 10
Training loss: 5.003774166107178
Validation loss: 4.488290508588155

Epoch: 5| Step: 11
Training loss: 1.6118762493133545
Validation loss: 4.4803775151570635

Epoch: 11| Step: 0
Training loss: 3.7395706176757812
Validation loss: 4.472862323125203

Epoch: 5| Step: 1
Training loss: 5.841456413269043
Validation loss: 4.465212066968282

Epoch: 5| Step: 2
Training loss: 4.18253231048584
Validation loss: 4.45738227168719

Epoch: 5| Step: 3
Training loss: 4.5161309242248535
Validation loss: 4.450663129488627

Epoch: 5| Step: 4
Training loss: 5.049353122711182
Validation loss: 4.442651132742564

Epoch: 5| Step: 5
Training loss: 4.4875006675720215
Validation loss: 4.435278962055842

Epoch: 5| Step: 6
Training loss: 4.491227626800537
Validation loss: 4.426656444867452

Epoch: 5| Step: 7
Training loss: 5.029071807861328
Validation loss: 4.418691883484523

Epoch: 5| Step: 8
Training loss: 3.8982608318328857
Validation loss: 4.41172730922699

Epoch: 5| Step: 9
Training loss: 4.579007148742676
Validation loss: 4.404284099737803

Epoch: 5| Step: 10
Training loss: 4.387840747833252
Validation loss: 4.3969143231709795

Epoch: 5| Step: 11
Training loss: 3.619938611984253
Validation loss: 4.389746298392613

Epoch: 12| Step: 0
Training loss: 4.541541576385498
Validation loss: 4.383071720600128

Epoch: 5| Step: 1
Training loss: 4.853152275085449
Validation loss: 4.375844240188599

Epoch: 5| Step: 2
Training loss: 3.586648464202881
Validation loss: 4.368469387292862

Epoch: 5| Step: 3
Training loss: 4.362455368041992
Validation loss: 4.3617773453394575

Epoch: 5| Step: 4
Training loss: 4.49153995513916
Validation loss: 4.354621191819509

Epoch: 5| Step: 5
Training loss: 4.38956880569458
Validation loss: 4.346973439057668

Epoch: 5| Step: 6
Training loss: 3.941241502761841
Validation loss: 4.340909779071808

Epoch: 5| Step: 7
Training loss: 4.420327186584473
Validation loss: 4.333914707104365

Epoch: 5| Step: 8
Training loss: 4.967764854431152
Validation loss: 4.327272812525432

Epoch: 5| Step: 9
Training loss: 4.600645065307617
Validation loss: 4.320198744535446

Epoch: 5| Step: 10
Training loss: 4.897248268127441
Validation loss: 4.313019514083862

Epoch: 5| Step: 11
Training loss: 4.946812629699707
Validation loss: 4.305592894554138

Epoch: 13| Step: 0
Training loss: 4.357627868652344
Validation loss: 4.298720101515452

Epoch: 5| Step: 1
Training loss: 5.435254096984863
Validation loss: 4.292826036612193

Epoch: 5| Step: 2
Training loss: 4.8317437171936035
Validation loss: 4.28522190451622

Epoch: 5| Step: 3
Training loss: 4.541075706481934
Validation loss: 4.278315921624501

Epoch: 5| Step: 4
Training loss: 3.7676620483398438
Validation loss: 4.272259632746379

Epoch: 5| Step: 5
Training loss: 4.413626670837402
Validation loss: 4.265564978122711

Epoch: 5| Step: 6
Training loss: 3.6605610847473145
Validation loss: 4.2591075003147125

Epoch: 5| Step: 7
Training loss: 4.348943710327148
Validation loss: 4.251774897178014

Epoch: 5| Step: 8
Training loss: 5.183706760406494
Validation loss: 4.245083500941594

Epoch: 5| Step: 9
Training loss: 3.701937437057495
Validation loss: 4.238233715295792

Epoch: 5| Step: 10
Training loss: 4.202894687652588
Validation loss: 4.231857111056645

Epoch: 5| Step: 11
Training loss: 3.7884154319763184
Validation loss: 4.225258727868398

Epoch: 14| Step: 0
Training loss: 3.2228260040283203
Validation loss: 4.219232072432836

Epoch: 5| Step: 1
Training loss: 4.587845802307129
Validation loss: 4.212850620349248

Epoch: 5| Step: 2
Training loss: 4.562252044677734
Validation loss: 4.2071770032246905

Epoch: 5| Step: 3
Training loss: 5.175443649291992
Validation loss: 4.200838456551234

Epoch: 5| Step: 4
Training loss: 4.461640357971191
Validation loss: 4.195045620203018

Epoch: 5| Step: 5
Training loss: 4.56249475479126
Validation loss: 4.188774327437083

Epoch: 5| Step: 6
Training loss: 5.107394695281982
Validation loss: 4.182725876569748

Epoch: 5| Step: 7
Training loss: 4.223024845123291
Validation loss: 4.176528354485829

Epoch: 5| Step: 8
Training loss: 3.880950927734375
Validation loss: 4.169827500979106

Epoch: 5| Step: 9
Training loss: 4.047030448913574
Validation loss: 4.164042145013809

Epoch: 5| Step: 10
Training loss: 3.8827013969421387
Validation loss: 4.157827436923981

Epoch: 5| Step: 11
Training loss: 3.496983051300049
Validation loss: 4.151301274696986

Epoch: 15| Step: 0
Training loss: 4.7856574058532715
Validation loss: 4.145402113596599

Epoch: 5| Step: 1
Training loss: 4.346341609954834
Validation loss: 4.139248073101044

Epoch: 5| Step: 2
Training loss: 4.5762834548950195
Validation loss: 4.133074174324672

Epoch: 5| Step: 3
Training loss: 4.114075183868408
Validation loss: 4.126554042100906

Epoch: 5| Step: 4
Training loss: 3.4899964332580566
Validation loss: 4.120908985535304

Epoch: 5| Step: 5
Training loss: 5.03950309753418
Validation loss: 4.114746669928233

Epoch: 5| Step: 6
Training loss: 4.717022895812988
Validation loss: 4.108985364437103

Epoch: 5| Step: 7
Training loss: 3.7901082038879395
Validation loss: 4.1029719312985735

Epoch: 5| Step: 8
Training loss: 4.144196510314941
Validation loss: 4.096941570440928

Epoch: 5| Step: 9
Training loss: 3.3964028358459473
Validation loss: 4.091595192750295

Epoch: 5| Step: 10
Training loss: 4.3916168212890625
Validation loss: 4.0851171016693115

Epoch: 5| Step: 11
Training loss: 4.21830415725708
Validation loss: 4.078877021869023

Epoch: 16| Step: 0
Training loss: 4.706857681274414
Validation loss: 4.072257459163666

Epoch: 5| Step: 1
Training loss: 3.0465149879455566
Validation loss: 4.0657467146714525

Epoch: 5| Step: 2
Training loss: 4.535434722900391
Validation loss: 4.060221244891484

Epoch: 5| Step: 3
Training loss: 3.453404664993286
Validation loss: 4.054678658644359

Epoch: 5| Step: 4
Training loss: 4.378332138061523
Validation loss: 4.048267384370168

Epoch: 5| Step: 5
Training loss: 4.506760120391846
Validation loss: 4.042033523321152

Epoch: 5| Step: 6
Training loss: 5.175250053405762
Validation loss: 4.036608308553696

Epoch: 5| Step: 7
Training loss: 3.3498196601867676
Validation loss: 4.030241072177887

Epoch: 5| Step: 8
Training loss: 4.267607688903809
Validation loss: 4.024779697259267

Epoch: 5| Step: 9
Training loss: 3.831429958343506
Validation loss: 4.019267717997233

Epoch: 5| Step: 10
Training loss: 4.661540508270264
Validation loss: 4.01342789332072

Epoch: 5| Step: 11
Training loss: 4.799344062805176
Validation loss: 4.00779711206754

Epoch: 17| Step: 0
Training loss: 4.510350227355957
Validation loss: 4.0022023518880205

Epoch: 5| Step: 1
Training loss: 4.94688081741333
Validation loss: 3.9961708188056946

Epoch: 5| Step: 2
Training loss: 3.7187225818634033
Validation loss: 3.9902336796124778

Epoch: 5| Step: 3
Training loss: 3.720327854156494
Validation loss: 3.9856174687544503

Epoch: 5| Step: 4
Training loss: 4.13370418548584
Validation loss: 3.9795266886552176

Epoch: 5| Step: 5
Training loss: 3.6204304695129395
Validation loss: 3.9746471544106803

Epoch: 5| Step: 6
Training loss: 4.095542907714844
Validation loss: 3.9677694936593375

Epoch: 5| Step: 7
Training loss: 3.8053455352783203
Validation loss: 3.9628923734029136

Epoch: 5| Step: 8
Training loss: 4.186981201171875
Validation loss: 3.9574520687262216

Epoch: 5| Step: 9
Training loss: 4.251595973968506
Validation loss: 3.9513195753097534

Epoch: 5| Step: 10
Training loss: 4.1480393409729
Validation loss: 3.945515205462774

Epoch: 5| Step: 11
Training loss: 5.026424884796143
Validation loss: 3.941140075524648

Epoch: 18| Step: 0
Training loss: 4.816575050354004
Validation loss: 3.937066674232483

Epoch: 5| Step: 1
Training loss: 4.362499713897705
Validation loss: 3.930380513270696

Epoch: 5| Step: 2
Training loss: 3.3003134727478027
Validation loss: 3.9223644733428955

Epoch: 5| Step: 3
Training loss: 3.393423080444336
Validation loss: 3.9160388906796775

Epoch: 5| Step: 4
Training loss: 4.047070503234863
Validation loss: 3.91046675046285

Epoch: 5| Step: 5
Training loss: 4.283080577850342
Validation loss: 3.908111482858658

Epoch: 5| Step: 6
Training loss: 3.657099485397339
Validation loss: 3.8995219469070435

Epoch: 5| Step: 7
Training loss: 4.778943061828613
Validation loss: 3.8964718679587045

Epoch: 5| Step: 8
Training loss: 3.9191932678222656
Validation loss: 3.8903721074263253

Epoch: 5| Step: 9
Training loss: 3.792689561843872
Validation loss: 3.8847729365030923

Epoch: 5| Step: 10
Training loss: 4.191615581512451
Validation loss: 3.8783849279085794

Epoch: 5| Step: 11
Training loss: 4.441351890563965
Validation loss: 3.873460531234741

Epoch: 19| Step: 0
Training loss: 4.652481555938721
Validation loss: 3.8684193889300027

Epoch: 5| Step: 1
Training loss: 4.077424049377441
Validation loss: 3.862974335749944

Epoch: 5| Step: 2
Training loss: 3.6007003784179688
Validation loss: 3.8571400245030723

Epoch: 5| Step: 3
Training loss: 3.906097412109375
Validation loss: 3.8521007001399994

Epoch: 5| Step: 4
Training loss: 3.4684677124023438
Validation loss: 3.8469864825407663

Epoch: 5| Step: 5
Training loss: 3.084153652191162
Validation loss: 3.8423161804676056

Epoch: 5| Step: 6
Training loss: 4.373306751251221
Validation loss: 3.8363168040911355

Epoch: 5| Step: 7
Training loss: 4.051491737365723
Validation loss: 3.831289162238439

Epoch: 5| Step: 8
Training loss: 4.341534614562988
Validation loss: 3.8268721600373587

Epoch: 5| Step: 9
Training loss: 3.9953620433807373
Validation loss: 3.8215467830499015

Epoch: 5| Step: 10
Training loss: 4.389441013336182
Validation loss: 3.816530833641688

Epoch: 5| Step: 11
Training loss: 4.0672197341918945
Validation loss: 3.81184251109759

Epoch: 20| Step: 0
Training loss: 3.8265724182128906
Validation loss: 3.8071254988511405

Epoch: 5| Step: 1
Training loss: 4.328269004821777
Validation loss: 3.802495151758194

Epoch: 5| Step: 2
Training loss: 3.3431899547576904
Validation loss: 3.800598214070002

Epoch: 5| Step: 3
Training loss: 3.8364243507385254
Validation loss: 3.802696466445923

Epoch: 5| Step: 4
Training loss: 4.344995975494385
Validation loss: 3.788288782040278

Epoch: 5| Step: 5
Training loss: 4.287741661071777
Validation loss: 3.783797949552536

Epoch: 5| Step: 6
Training loss: 3.951220989227295
Validation loss: 3.780424177646637

Epoch: 5| Step: 7
Training loss: 3.5284411907196045
Validation loss: 3.7759771148363748

Epoch: 5| Step: 8
Training loss: 4.215266227722168
Validation loss: 3.7731416622797647

Epoch: 5| Step: 9
Training loss: 3.67279052734375
Validation loss: 3.766261080900828

Epoch: 5| Step: 10
Training loss: 4.19825553894043
Validation loss: 3.760737438996633

Epoch: 5| Step: 11
Training loss: 3.0058846473693848
Validation loss: 3.7563547094662986

Epoch: 21| Step: 0
Training loss: 4.236904621124268
Validation loss: 3.753246088822683

Epoch: 5| Step: 1
Training loss: 3.679703950881958
Validation loss: 3.7479699353377023

Epoch: 5| Step: 2
Training loss: 3.8699886798858643
Validation loss: 3.7428264816602073

Epoch: 5| Step: 3
Training loss: 4.133462905883789
Validation loss: 3.73658479253451

Epoch: 5| Step: 4
Training loss: 3.8838207721710205
Validation loss: 3.7315414547920227

Epoch: 5| Step: 5
Training loss: 3.966825008392334
Validation loss: 3.727257271607717

Epoch: 5| Step: 6
Training loss: 4.522831916809082
Validation loss: 3.7227766116460166

Epoch: 5| Step: 7
Training loss: 3.8006319999694824
Validation loss: 3.7171722849210105

Epoch: 5| Step: 8
Training loss: 3.4258453845977783
Validation loss: 3.711290051539739

Epoch: 5| Step: 9
Training loss: 2.94642972946167
Validation loss: 3.707176983356476

Epoch: 5| Step: 10
Training loss: 4.280898094177246
Validation loss: 3.701714704434077

Epoch: 5| Step: 11
Training loss: 3.941136360168457
Validation loss: 3.6969077587127686

Epoch: 22| Step: 0
Training loss: 2.8240904808044434
Validation loss: 3.692386935154597

Epoch: 5| Step: 1
Training loss: 4.254289150238037
Validation loss: 3.688350021839142

Epoch: 5| Step: 2
Training loss: 3.724918842315674
Validation loss: 3.6833844582239785

Epoch: 5| Step: 3
Training loss: 4.124881267547607
Validation loss: 3.6798532605171204

Epoch: 5| Step: 4
Training loss: 3.250849962234497
Validation loss: 3.6736246744791665

Epoch: 5| Step: 5
Training loss: 4.755363941192627
Validation loss: 3.6697683235009513

Epoch: 5| Step: 6
Training loss: 4.7249603271484375
Validation loss: 3.666311353445053

Epoch: 5| Step: 7
Training loss: 3.6506054401397705
Validation loss: 3.661125431458155

Epoch: 5| Step: 8
Training loss: 3.7935073375701904
Validation loss: 3.65548038482666

Epoch: 5| Step: 9
Training loss: 3.2609317302703857
Validation loss: 3.6515879730383554

Epoch: 5| Step: 10
Training loss: 3.554696559906006
Validation loss: 3.6471038659413657

Epoch: 5| Step: 11
Training loss: 4.935202598571777
Validation loss: 3.6424014369646707

Epoch: 23| Step: 0
Training loss: 4.223412036895752
Validation loss: 3.638086368640264

Epoch: 5| Step: 1
Training loss: 3.6532859802246094
Validation loss: 3.6340585748354592

Epoch: 5| Step: 2
Training loss: 3.905623197555542
Validation loss: 3.6291476587454476

Epoch: 5| Step: 3
Training loss: 4.178801536560059
Validation loss: 3.6234440008799234

Epoch: 5| Step: 4
Training loss: 4.169281005859375
Validation loss: 3.6175214648246765

Epoch: 5| Step: 5
Training loss: 3.242070436477661
Validation loss: 3.613058934609095

Epoch: 5| Step: 6
Training loss: 3.681731700897217
Validation loss: 3.607871433099111

Epoch: 5| Step: 7
Training loss: 4.064318656921387
Validation loss: 3.603566120068232

Epoch: 5| Step: 8
Training loss: 3.2394680976867676
Validation loss: 3.5983157753944397

Epoch: 5| Step: 9
Training loss: 3.3855812549591064
Validation loss: 3.5945800046126046

Epoch: 5| Step: 10
Training loss: 3.5833067893981934
Validation loss: 3.5898233354091644

Epoch: 5| Step: 11
Training loss: 4.814532279968262
Validation loss: 3.5852827032407126

Epoch: 24| Step: 0
Training loss: 3.2443172931671143
Validation loss: 3.580242524544398

Epoch: 5| Step: 1
Training loss: 3.7605361938476562
Validation loss: 3.574599951505661

Epoch: 5| Step: 2
Training loss: 3.9399211406707764
Validation loss: 3.5699863334496817

Epoch: 5| Step: 3
Training loss: 4.249234676361084
Validation loss: 3.565732220808665

Epoch: 5| Step: 4
Training loss: 3.49434232711792
Validation loss: 3.559874633948008

Epoch: 5| Step: 5
Training loss: 3.1323914527893066
Validation loss: 3.5551233887672424

Epoch: 5| Step: 6
Training loss: 3.2590320110321045
Validation loss: 3.5502368112405143

Epoch: 5| Step: 7
Training loss: 4.180394172668457
Validation loss: 3.5450828274091086

Epoch: 5| Step: 8
Training loss: 3.8563835620880127
Validation loss: 3.5395022432009378

Epoch: 5| Step: 9
Training loss: 3.712120771408081
Validation loss: 3.5360840360323587

Epoch: 5| Step: 10
Training loss: 3.969593048095703
Validation loss: 3.5320643881956735

Epoch: 5| Step: 11
Training loss: 4.320132255554199
Validation loss: 3.5254147946834564

Epoch: 25| Step: 0
Training loss: 2.8665575981140137
Validation loss: 3.520349472761154

Epoch: 5| Step: 1
Training loss: 4.248044967651367
Validation loss: 3.5159156719843545

Epoch: 5| Step: 2
Training loss: 3.2999725341796875
Validation loss: 3.5105448961257935

Epoch: 5| Step: 3
Training loss: 4.132116794586182
Validation loss: 3.5055992702643075

Epoch: 5| Step: 4
Training loss: 3.406292676925659
Validation loss: 3.500692347685496

Epoch: 5| Step: 5
Training loss: 3.4913418292999268
Validation loss: 3.495596557855606

Epoch: 5| Step: 6
Training loss: 4.56923770904541
Validation loss: 3.490980237722397

Epoch: 5| Step: 7
Training loss: 3.8908638954162598
Validation loss: 3.4861753483613334

Epoch: 5| Step: 8
Training loss: 3.04449725151062
Validation loss: 3.480981012185415

Epoch: 5| Step: 9
Training loss: 3.0991625785827637
Validation loss: 3.476299673318863

Epoch: 5| Step: 10
Training loss: 4.447417259216309
Validation loss: 3.472130914529165

Epoch: 5| Step: 11
Training loss: 2.5864200592041016
Validation loss: 3.4674177169799805

Epoch: 26| Step: 0
Training loss: 3.4460277557373047
Validation loss: 3.4621217250823975

Epoch: 5| Step: 1
Training loss: 4.448100566864014
Validation loss: 3.457656671603521

Epoch: 5| Step: 2
Training loss: 2.7185864448547363
Validation loss: 3.451891750097275

Epoch: 5| Step: 3
Training loss: 3.939865827560425
Validation loss: 3.4474576810995736

Epoch: 5| Step: 4
Training loss: 3.4226486682891846
Validation loss: 3.4433164397875466

Epoch: 5| Step: 5
Training loss: 2.8947014808654785
Validation loss: 3.437417278687159

Epoch: 5| Step: 6
Training loss: 4.165679931640625
Validation loss: 3.4323669175306954

Epoch: 5| Step: 7
Training loss: 3.9742279052734375
Validation loss: 3.4286228319009147

Epoch: 5| Step: 8
Training loss: 3.096890926361084
Validation loss: 3.4238248765468597

Epoch: 5| Step: 9
Training loss: 3.6342415809631348
Validation loss: 3.41861355304718

Epoch: 5| Step: 10
Training loss: 3.733980178833008
Validation loss: 3.4137642085552216

Epoch: 5| Step: 11
Training loss: 4.523710250854492
Validation loss: 3.408693720897039

Epoch: 27| Step: 0
Training loss: 3.774139404296875
Validation loss: 3.4045320252577462

Epoch: 5| Step: 1
Training loss: 2.531251907348633
Validation loss: 3.4004742006460824

Epoch: 5| Step: 2
Training loss: 3.486727237701416
Validation loss: 3.3963957826296487

Epoch: 5| Step: 3
Training loss: 4.217292785644531
Validation loss: 3.3908607562383017

Epoch: 5| Step: 4
Training loss: 3.995265245437622
Validation loss: 3.385871648788452

Epoch: 5| Step: 5
Training loss: 3.90312123298645
Validation loss: 3.3813914954662323

Epoch: 5| Step: 6
Training loss: 3.2803521156311035
Validation loss: 3.376190890868505

Epoch: 5| Step: 7
Training loss: 3.314181089401245
Validation loss: 3.3712161481380463

Epoch: 5| Step: 8
Training loss: 4.238329887390137
Validation loss: 3.366528113683065

Epoch: 5| Step: 9
Training loss: 3.461495876312256
Validation loss: 3.3617762327194214

Epoch: 5| Step: 10
Training loss: 3.0681490898132324
Validation loss: 3.3578373392422995

Epoch: 5| Step: 11
Training loss: 2.4970576763153076
Validation loss: 3.352907965580622

Epoch: 28| Step: 0
Training loss: 3.380173921585083
Validation loss: 3.3491427997748056

Epoch: 5| Step: 1
Training loss: 3.115875720977783
Validation loss: 3.343263417482376

Epoch: 5| Step: 2
Training loss: 3.570664882659912
Validation loss: 3.33898264169693

Epoch: 5| Step: 3
Training loss: 2.889395236968994
Validation loss: 3.3335111141204834

Epoch: 5| Step: 4
Training loss: 3.555189847946167
Validation loss: 3.3296945790449777

Epoch: 5| Step: 5
Training loss: 3.250723361968994
Validation loss: 3.326362907886505

Epoch: 5| Step: 6
Training loss: 4.072390079498291
Validation loss: 3.323236266771952

Epoch: 5| Step: 7
Training loss: 3.981714963912964
Validation loss: 3.3171020249525704

Epoch: 5| Step: 8
Training loss: 3.1752467155456543
Validation loss: 3.3206779758135476

Epoch: 5| Step: 9
Training loss: 2.90671968460083
Validation loss: 3.306118220090866

Epoch: 5| Step: 10
Training loss: 4.211772441864014
Validation loss: 3.3024234672387442

Epoch: 5| Step: 11
Training loss: 5.346621513366699
Validation loss: 3.3035553793112435

Epoch: 29| Step: 0
Training loss: 4.219086647033691
Validation loss: 3.305434077978134

Epoch: 5| Step: 1
Training loss: 3.0606589317321777
Validation loss: 3.293806473414103

Epoch: 5| Step: 2
Training loss: 3.418862819671631
Validation loss: 3.292139877875646

Epoch: 5| Step: 3
Training loss: 3.365896224975586
Validation loss: 3.2862878143787384

Epoch: 5| Step: 4
Training loss: 3.0565390586853027
Validation loss: 3.279252847035726

Epoch: 5| Step: 5
Training loss: 2.982975482940674
Validation loss: 3.2764484584331512

Epoch: 5| Step: 6
Training loss: 4.476318359375
Validation loss: 3.2741824189821878

Epoch: 5| Step: 7
Training loss: 3.4885826110839844
Validation loss: 3.2672136624654136

Epoch: 5| Step: 8
Training loss: 2.8080687522888184
Validation loss: 3.2639213601748147

Epoch: 5| Step: 9
Training loss: 3.3336174488067627
Validation loss: 3.2593002319335938

Epoch: 5| Step: 10
Training loss: 3.768153429031372
Validation loss: 3.2533770898977914

Epoch: 5| Step: 11
Training loss: 3.605257511138916
Validation loss: 3.2503682076931

Epoch: 30| Step: 0
Training loss: 3.64892578125
Validation loss: 3.2454298535982766

Epoch: 5| Step: 1
Training loss: 3.1687512397766113
Validation loss: 3.2404884696006775

Epoch: 5| Step: 2
Training loss: 3.783735752105713
Validation loss: 3.2355405390262604

Epoch: 5| Step: 3
Training loss: 3.979814052581787
Validation loss: 3.230863789717356

Epoch: 5| Step: 4
Training loss: 4.005136966705322
Validation loss: 3.2261100709438324

Epoch: 5| Step: 5
Training loss: 2.4041755199432373
Validation loss: 3.2207535803318024

Epoch: 5| Step: 6
Training loss: 3.407031536102295
Validation loss: 3.216177850961685

Epoch: 5| Step: 7
Training loss: 3.5874266624450684
Validation loss: 3.211286783218384

Epoch: 5| Step: 8
Training loss: 3.1003577709198
Validation loss: 3.207002858320872

Epoch: 5| Step: 9
Training loss: 2.993178129196167
Validation loss: 3.203509400288264

Epoch: 5| Step: 10
Training loss: 3.050732135772705
Validation loss: 3.197886457045873

Epoch: 5| Step: 11
Training loss: 4.692786693572998
Validation loss: 3.1946421762307486

Epoch: 31| Step: 0
Training loss: 3.450132369995117
Validation loss: 3.1896553536256156

Epoch: 5| Step: 1
Training loss: 3.739436388015747
Validation loss: 3.1848674416542053

Epoch: 5| Step: 2
Training loss: 3.347616672515869
Validation loss: 3.179011901219686

Epoch: 5| Step: 3
Training loss: 2.6760828495025635
Validation loss: 3.1743962367375693

Epoch: 5| Step: 4
Training loss: 3.41402006149292
Validation loss: 3.169413854678472

Epoch: 5| Step: 5
Training loss: 2.5141215324401855
Validation loss: 3.164259652296702

Epoch: 5| Step: 6
Training loss: 3.37309193611145
Validation loss: 3.160100758075714

Epoch: 5| Step: 7
Training loss: 2.9328179359436035
Validation loss: 3.156399220228195

Epoch: 5| Step: 8
Training loss: 3.4336066246032715
Validation loss: 3.1520631114641824

Epoch: 5| Step: 9
Training loss: 3.5862910747528076
Validation loss: 3.1487467686335244

Epoch: 5| Step: 10
Training loss: 4.209887504577637
Validation loss: 3.14362695813179

Epoch: 5| Step: 11
Training loss: 4.134374618530273
Validation loss: 3.1407760183016458

Epoch: 32| Step: 0
Training loss: 3.4265942573547363
Validation loss: 3.1354945500691733

Epoch: 5| Step: 1
Training loss: 3.0058350563049316
Validation loss: 3.131140132745107

Epoch: 5| Step: 2
Training loss: 2.833984613418579
Validation loss: 3.1275890469551086

Epoch: 5| Step: 3
Training loss: 3.9225730895996094
Validation loss: 3.1229467193285623

Epoch: 5| Step: 4
Training loss: 2.9306044578552246
Validation loss: 3.118941674629847

Epoch: 5| Step: 5
Training loss: 3.296851396560669
Validation loss: 3.112588236729304

Epoch: 5| Step: 6
Training loss: 3.6747195720672607
Validation loss: 3.10871293147405

Epoch: 5| Step: 7
Training loss: 4.3319902420043945
Validation loss: 3.10425732533137

Epoch: 5| Step: 8
Training loss: 2.852982997894287
Validation loss: 3.100846221049627

Epoch: 5| Step: 9
Training loss: 2.6181674003601074
Validation loss: 3.0960023403167725

Epoch: 5| Step: 10
Training loss: 3.3612587451934814
Validation loss: 3.0929753283659616

Epoch: 5| Step: 11
Training loss: 3.4019923210144043
Validation loss: 3.0879894892374673

Epoch: 33| Step: 0
Training loss: 3.2112345695495605
Validation loss: 3.084191620349884

Epoch: 5| Step: 1
Training loss: 3.1619439125061035
Validation loss: 3.0797755420207977

Epoch: 5| Step: 2
Training loss: 4.0113525390625
Validation loss: 3.0768593748410544

Epoch: 5| Step: 3
Training loss: 3.4946930408477783
Validation loss: 3.0718528230985007

Epoch: 5| Step: 4
Training loss: 2.4929358959198
Validation loss: 3.0683523416519165

Epoch: 5| Step: 5
Training loss: 3.3581244945526123
Validation loss: 3.064997504154841

Epoch: 5| Step: 6
Training loss: 3.500951051712036
Validation loss: 3.0605897903442383

Epoch: 5| Step: 7
Training loss: 3.125466823577881
Validation loss: 3.056222081184387

Epoch: 5| Step: 8
Training loss: 3.631657838821411
Validation loss: 3.0527690052986145

Epoch: 5| Step: 9
Training loss: 2.351914167404175
Validation loss: 3.048374513785044

Epoch: 5| Step: 10
Training loss: 3.5126984119415283
Validation loss: 3.0448010563850403

Epoch: 5| Step: 11
Training loss: 2.8736329078674316
Validation loss: 3.0406716565291085

Epoch: 34| Step: 0
Training loss: 2.716620445251465
Validation loss: 3.03714848558108

Epoch: 5| Step: 1
Training loss: 3.2389912605285645
Validation loss: 3.032463550567627

Epoch: 5| Step: 2
Training loss: 3.0960161685943604
Validation loss: 3.029184798399607

Epoch: 5| Step: 3
Training loss: 4.031959056854248
Validation loss: 3.0254730780919394

Epoch: 5| Step: 4
Training loss: 3.6361708641052246
Validation loss: 3.021060665448507

Epoch: 5| Step: 5
Training loss: 4.020163536071777
Validation loss: 3.0164926648139954

Epoch: 5| Step: 6
Training loss: 3.362025499343872
Validation loss: 3.0130209922790527

Epoch: 5| Step: 7
Training loss: 2.9714088439941406
Validation loss: 3.0084253450234733

Epoch: 5| Step: 8
Training loss: 3.2095961570739746
Validation loss: 3.0044102668762207

Epoch: 5| Step: 9
Training loss: 2.2227725982666016
Validation loss: 3.000151207049688

Epoch: 5| Step: 10
Training loss: 3.064607620239258
Validation loss: 2.9954866071542106

Epoch: 5| Step: 11
Training loss: 1.9577277898788452
Validation loss: 2.9934030572573342

Epoch: 35| Step: 0
Training loss: 3.2258312702178955
Validation loss: 2.9907971620559692

Epoch: 5| Step: 1
Training loss: 3.24151873588562
Validation loss: 2.9863460262616477

Epoch: 5| Step: 2
Training loss: 2.7351877689361572
Validation loss: 2.98442479968071

Epoch: 5| Step: 3
Training loss: 2.6718626022338867
Validation loss: 2.9817845225334167

Epoch: 5| Step: 4
Training loss: 2.82527232170105
Validation loss: 2.9770281513532004

Epoch: 5| Step: 5
Training loss: 3.340893507003784
Validation loss: 2.973519225915273

Epoch: 5| Step: 6
Training loss: 2.8562405109405518
Validation loss: 2.969470133384069

Epoch: 5| Step: 7
Training loss: 3.407477855682373
Validation loss: 2.9634757240613303

Epoch: 5| Step: 8
Training loss: 3.1267104148864746
Validation loss: 2.9604606131712594

Epoch: 5| Step: 9
Training loss: 3.546438217163086
Validation loss: 2.9572339256604514

Epoch: 5| Step: 10
Training loss: 3.6196746826171875
Validation loss: 2.953662693500519

Epoch: 5| Step: 11
Training loss: 4.3171916007995605
Validation loss: 2.9496154685815177

Epoch: 36| Step: 0
Training loss: 2.915743589401245
Validation loss: 2.9470333953698478

Epoch: 5| Step: 1
Training loss: 2.50053071975708
Validation loss: 2.944059113661448

Epoch: 5| Step: 2
Training loss: 3.1193745136260986
Validation loss: 2.9429109493891397

Epoch: 5| Step: 3
Training loss: 3.5187251567840576
Validation loss: 2.9358899692694345

Epoch: 5| Step: 4
Training loss: 2.6938934326171875
Validation loss: 2.932011047999064

Epoch: 5| Step: 5
Training loss: 3.0195343494415283
Validation loss: 2.9285588463147483

Epoch: 5| Step: 6
Training loss: 3.066467523574829
Validation loss: 2.9242405891418457

Epoch: 5| Step: 7
Training loss: 3.382847547531128
Validation loss: 2.921805510918299

Epoch: 5| Step: 8
Training loss: 3.1938743591308594
Validation loss: 2.9193090299765267

Epoch: 5| Step: 9
Training loss: 3.5950584411621094
Validation loss: 2.915732522805532

Epoch: 5| Step: 10
Training loss: 3.1843578815460205
Validation loss: 2.9115308225154877

Epoch: 5| Step: 11
Training loss: 4.263677597045898
Validation loss: 2.9082981050014496

Epoch: 37| Step: 0
Training loss: 3.149121046066284
Validation loss: 2.9087393283843994

Epoch: 5| Step: 1
Training loss: 3.2674267292022705
Validation loss: 2.902816598614057

Epoch: 5| Step: 2
Training loss: 3.1012072563171387
Validation loss: 2.8968664904435477

Epoch: 5| Step: 3
Training loss: 3.2048473358154297
Validation loss: 2.8913718362649283

Epoch: 5| Step: 4
Training loss: 3.089714527130127
Validation loss: 2.8875187734762826

Epoch: 5| Step: 5
Training loss: 3.101886749267578
Validation loss: 2.8840939005215964

Epoch: 5| Step: 6
Training loss: 2.554563045501709
Validation loss: 2.880576272805532

Epoch: 5| Step: 7
Training loss: 3.3984553813934326
Validation loss: 2.8759238719940186

Epoch: 5| Step: 8
Training loss: 3.5040812492370605
Validation loss: 2.8731471796830497

Epoch: 5| Step: 9
Training loss: 3.2628014087677
Validation loss: 2.8700177570184073

Epoch: 5| Step: 10
Training loss: 2.519697904586792
Validation loss: 2.8663564324378967

Epoch: 5| Step: 11
Training loss: 2.3511226177215576
Validation loss: 2.86105348666509

Epoch: 38| Step: 0
Training loss: 3.353242874145508
Validation loss: 2.8585131069024405

Epoch: 5| Step: 1
Training loss: 3.0293288230895996
Validation loss: 2.8565358420213065

Epoch: 5| Step: 2
Training loss: 2.6798739433288574
Validation loss: 2.865642865498861

Epoch: 5| Step: 3
Training loss: 2.9457430839538574
Validation loss: 2.8703010976314545

Epoch: 5| Step: 4
Training loss: 3.5560882091522217
Validation loss: 2.8496562242507935

Epoch: 5| Step: 5
Training loss: 3.0234131813049316
Validation loss: 2.8429014682769775

Epoch: 5| Step: 6
Training loss: 2.8923146724700928
Validation loss: 2.84090926249822

Epoch: 5| Step: 7
Training loss: 3.1725783348083496
Validation loss: 2.8381008406480155

Epoch: 5| Step: 8
Training loss: 3.6244635581970215
Validation loss: 2.8332912027835846

Epoch: 5| Step: 9
Training loss: 3.0081238746643066
Validation loss: 2.8292171955108643

Epoch: 5| Step: 10
Training loss: 2.4128975868225098
Validation loss: 2.8275227745374045

Epoch: 5| Step: 11
Training loss: 2.4191513061523438
Validation loss: 2.823848714431127

Epoch: 39| Step: 0
Training loss: 3.8104469776153564
Validation loss: 2.821754048268

Epoch: 5| Step: 1
Training loss: 2.8360543251037598
Validation loss: 2.8184899985790253

Epoch: 5| Step: 2
Training loss: 3.143784999847412
Validation loss: 2.814810742934545

Epoch: 5| Step: 3
Training loss: 3.589639663696289
Validation loss: 2.8124902049700418

Epoch: 5| Step: 4
Training loss: 3.2291159629821777
Validation loss: 2.8088519473870597

Epoch: 5| Step: 5
Training loss: 2.745382785797119
Validation loss: 2.8039201498031616

Epoch: 5| Step: 6
Training loss: 2.7969846725463867
Validation loss: 2.8004707296689353

Epoch: 5| Step: 7
Training loss: 2.7598354816436768
Validation loss: 2.7977385918299356

Epoch: 5| Step: 8
Training loss: 2.554659366607666
Validation loss: 2.7953442533810935

Epoch: 5| Step: 9
Training loss: 2.965437412261963
Validation loss: 2.7928046882152557

Epoch: 5| Step: 10
Training loss: 2.4155375957489014
Validation loss: 2.7895279030005136

Epoch: 5| Step: 11
Training loss: 4.710285186767578
Validation loss: 2.7854309479395547

Epoch: 40| Step: 0
Training loss: 3.387742280960083
Validation loss: 2.7843899528185525

Epoch: 5| Step: 1
Training loss: 2.9623961448669434
Validation loss: 2.780811826388041

Epoch: 5| Step: 2
Training loss: 2.889402151107788
Validation loss: 2.7764875988165536

Epoch: 5| Step: 3
Training loss: 3.063533306121826
Validation loss: 2.7728201150894165

Epoch: 5| Step: 4
Training loss: 3.325352907180786
Validation loss: 2.7707306842009225

Epoch: 5| Step: 5
Training loss: 2.94337797164917
Validation loss: 2.7645503878593445

Epoch: 5| Step: 6
Training loss: 2.8814666271209717
Validation loss: 2.7622353732585907

Epoch: 5| Step: 7
Training loss: 3.209404468536377
Validation loss: 2.7597656548023224

Epoch: 5| Step: 8
Training loss: 2.566765308380127
Validation loss: 2.7550874451796212

Epoch: 5| Step: 9
Training loss: 2.5996928215026855
Validation loss: 2.7568271259466806

Epoch: 5| Step: 10
Training loss: 3.160210371017456
Validation loss: 2.7503599524497986

Epoch: 5| Step: 11
Training loss: 1.625345230102539
Validation loss: 2.7467485070228577

Epoch: 41| Step: 0
Training loss: 3.035834789276123
Validation loss: 2.745213955640793

Epoch: 5| Step: 1
Training loss: 2.870943546295166
Validation loss: 2.7417468428611755

Epoch: 5| Step: 2
Training loss: 2.0485148429870605
Validation loss: 2.7429759005705514

Epoch: 5| Step: 3
Training loss: 2.8289332389831543
Validation loss: 2.7352763017018638

Epoch: 5| Step: 4
Training loss: 3.5522818565368652
Validation loss: 2.7320627570152283

Epoch: 5| Step: 5
Training loss: 3.222283124923706
Validation loss: 2.730734129746755

Epoch: 5| Step: 6
Training loss: 3.1247317790985107
Validation loss: 2.7267978886763253

Epoch: 5| Step: 7
Training loss: 2.6094307899475098
Validation loss: 2.7235711415608725

Epoch: 5| Step: 8
Training loss: 2.9744439125061035
Validation loss: 2.7205303013324738

Epoch: 5| Step: 9
Training loss: 3.291442394256592
Validation loss: 2.7172029415766397

Epoch: 5| Step: 10
Training loss: 2.866455554962158
Validation loss: 2.713167587916056

Epoch: 5| Step: 11
Training loss: 2.395789623260498
Validation loss: 2.7102845907211304

Epoch: 42| Step: 0
Training loss: 3.8597633838653564
Validation loss: 2.709424247344335

Epoch: 5| Step: 1
Training loss: 2.518059730529785
Validation loss: 2.705511818329493

Epoch: 5| Step: 2
Training loss: 2.989650249481201
Validation loss: 2.7022648255030313

Epoch: 5| Step: 3
Training loss: 2.5512020587921143
Validation loss: 2.698933760325114

Epoch: 5| Step: 4
Training loss: 3.188119888305664
Validation loss: 2.6948823432127633

Epoch: 5| Step: 5
Training loss: 2.5573477745056152
Validation loss: 2.6910325785477958

Epoch: 5| Step: 6
Training loss: 2.271000623703003
Validation loss: 2.6877042651176453

Epoch: 5| Step: 7
Training loss: 2.7906880378723145
Validation loss: 2.6844333012898765

Epoch: 5| Step: 8
Training loss: 2.5010323524475098
Validation loss: 2.6827444632848105

Epoch: 5| Step: 9
Training loss: 3.226483106613159
Validation loss: 2.6779339611530304

Epoch: 5| Step: 10
Training loss: 3.5509860515594482
Validation loss: 2.679165005683899

Epoch: 5| Step: 11
Training loss: 2.1940462589263916
Validation loss: 2.6800647576649985

Epoch: 43| Step: 0
Training loss: 2.979457378387451
Validation loss: 2.6874698400497437

Epoch: 5| Step: 1
Training loss: 2.9324564933776855
Validation loss: 2.7089964350064597

Epoch: 5| Step: 2
Training loss: 3.327786922454834
Validation loss: 2.708105723063151

Epoch: 5| Step: 3
Training loss: 2.8498504161834717
Validation loss: 2.6752519806226096

Epoch: 5| Step: 4
Training loss: 3.038520336151123
Validation loss: 2.6619216899077096

Epoch: 5| Step: 5
Training loss: 2.642152786254883
Validation loss: 2.658479948838552

Epoch: 5| Step: 6
Training loss: 2.8054537773132324
Validation loss: 2.653519625465075

Epoch: 5| Step: 7
Training loss: 2.352928876876831
Validation loss: 2.653026228149732

Epoch: 5| Step: 8
Training loss: 3.0485243797302246
Validation loss: 2.649277319510778

Epoch: 5| Step: 9
Training loss: 2.9022433757781982
Validation loss: 2.6473873456319175

Epoch: 5| Step: 10
Training loss: 2.5120251178741455
Validation loss: 2.646094764272372

Epoch: 5| Step: 11
Training loss: 3.3413302898406982
Validation loss: 2.6448435485363007

Epoch: 44| Step: 0
Training loss: 2.8355393409729004
Validation loss: 2.641459435224533

Epoch: 5| Step: 1
Training loss: 2.9640965461730957
Validation loss: 2.6394696136315665

Epoch: 5| Step: 2
Training loss: 3.1378402709960938
Validation loss: 2.6299078464508057

Epoch: 5| Step: 3
Training loss: 2.7022156715393066
Validation loss: 2.6248187820116677

Epoch: 5| Step: 4
Training loss: 2.4869370460510254
Validation loss: 2.622500995794932

Epoch: 5| Step: 5
Training loss: 2.834249258041382
Validation loss: 2.620537370443344

Epoch: 5| Step: 6
Training loss: 2.6466715335845947
Validation loss: 2.633774240811666

Epoch: 5| Step: 7
Training loss: 2.4458956718444824
Validation loss: 2.6302428344885507

Epoch: 5| Step: 8
Training loss: 2.964768886566162
Validation loss: 2.6250964800516763

Epoch: 5| Step: 9
Training loss: 2.6193227767944336
Validation loss: 2.616094872355461

Epoch: 5| Step: 10
Training loss: 3.239879608154297
Validation loss: 2.6077544490496316

Epoch: 5| Step: 11
Training loss: 3.830883026123047
Validation loss: 2.5990661680698395

Epoch: 45| Step: 0
Training loss: 3.1545536518096924
Validation loss: 2.595617135365804

Epoch: 5| Step: 1
Training loss: 2.576054334640503
Validation loss: 2.592121144135793

Epoch: 5| Step: 2
Training loss: 2.8432931900024414
Validation loss: 2.5931006322304406

Epoch: 5| Step: 3
Training loss: 2.721174716949463
Validation loss: 2.594088524580002

Epoch: 5| Step: 4
Training loss: 3.077960968017578
Validation loss: 2.5957829852898917

Epoch: 5| Step: 5
Training loss: 2.850834369659424
Validation loss: 2.587318331003189

Epoch: 5| Step: 6
Training loss: 3.400498867034912
Validation loss: 2.5873674054940543

Epoch: 5| Step: 7
Training loss: 2.284576892852783
Validation loss: 2.576294998327891

Epoch: 5| Step: 8
Training loss: 2.765225887298584
Validation loss: 2.570442189772924

Epoch: 5| Step: 9
Training loss: 2.6368696689605713
Validation loss: 2.563683936993281

Epoch: 5| Step: 10
Training loss: 2.3402981758117676
Validation loss: 2.5626431504885354

Epoch: 5| Step: 11
Training loss: 2.638662815093994
Validation loss: 2.5594661633173623

Epoch: 46| Step: 0
Training loss: 2.7860188484191895
Validation loss: 2.559658279021581

Epoch: 5| Step: 1
Training loss: 3.1946544647216797
Validation loss: 2.5559594134489694

Epoch: 5| Step: 2
Training loss: 2.5823211669921875
Validation loss: 2.5603055308262506

Epoch: 5| Step: 3
Training loss: 2.4366579055786133
Validation loss: 2.5627618034680686

Epoch: 5| Step: 4
Training loss: 2.4882993698120117
Validation loss: 2.55802055199941

Epoch: 5| Step: 5
Training loss: 3.2795231342315674
Validation loss: 2.552364652355512

Epoch: 5| Step: 6
Training loss: 2.5043935775756836
Validation loss: 2.544526601831118

Epoch: 5| Step: 7
Training loss: 2.801128625869751
Validation loss: 2.5396757622559867

Epoch: 5| Step: 8
Training loss: 2.679239273071289
Validation loss: 2.534459431966146

Epoch: 5| Step: 9
Training loss: 2.715502977371216
Validation loss: 2.529733568429947

Epoch: 5| Step: 10
Training loss: 2.9332194328308105
Validation loss: 2.5278596381346383

Epoch: 5| Step: 11
Training loss: 1.3053791522979736
Validation loss: 2.5251256873210273

Epoch: 47| Step: 0
Training loss: 3.208115339279175
Validation loss: 2.521157612403234

Epoch: 5| Step: 1
Training loss: 2.8583779335021973
Validation loss: 2.5201817750930786

Epoch: 5| Step: 2
Training loss: 2.794820785522461
Validation loss: 2.5179742574691772

Epoch: 5| Step: 3
Training loss: 2.3038620948791504
Validation loss: 2.514070908228556

Epoch: 5| Step: 4
Training loss: 1.8689861297607422
Validation loss: 2.511386046806971

Epoch: 5| Step: 5
Training loss: 2.5819878578186035
Validation loss: 2.507533440987269

Epoch: 5| Step: 6
Training loss: 3.082549571990967
Validation loss: 2.503698463241259

Epoch: 5| Step: 7
Training loss: 2.1548123359680176
Validation loss: 2.500896006822586

Epoch: 5| Step: 8
Training loss: 2.7512385845184326
Validation loss: 2.4979641884565353

Epoch: 5| Step: 9
Training loss: 2.990967273712158
Validation loss: 2.4965863724549613

Epoch: 5| Step: 10
Training loss: 3.086613655090332
Validation loss: 2.4909537633260093

Epoch: 5| Step: 11
Training loss: 2.9793200492858887
Validation loss: 2.4877407352129617

Epoch: 48| Step: 0
Training loss: 1.967511534690857
Validation loss: 2.4837669134140015

Epoch: 5| Step: 1
Training loss: 2.6024951934814453
Validation loss: 2.481437106927236

Epoch: 5| Step: 2
Training loss: 2.681567668914795
Validation loss: 2.480042497316996

Epoch: 5| Step: 3
Training loss: 2.6512229442596436
Validation loss: 2.4721777141094208

Epoch: 5| Step: 4
Training loss: 3.5605664253234863
Validation loss: 2.472457935412725

Epoch: 5| Step: 5
Training loss: 2.631896495819092
Validation loss: 2.4707844803730645

Epoch: 5| Step: 6
Training loss: 2.87849760055542
Validation loss: 2.46747225522995

Epoch: 5| Step: 7
Training loss: 2.486506700515747
Validation loss: 2.4607642392317453

Epoch: 5| Step: 8
Training loss: 2.293769598007202
Validation loss: 2.4614271124204

Epoch: 5| Step: 9
Training loss: 2.4379537105560303
Validation loss: 2.457484761873881

Epoch: 5| Step: 10
Training loss: 3.022778034210205
Validation loss: 2.4544809261957803

Epoch: 5| Step: 11
Training loss: 2.896131992340088
Validation loss: 2.4548607766628265

Epoch: 49| Step: 0
Training loss: 2.6456100940704346
Validation loss: 2.451181317369143

Epoch: 5| Step: 1
Training loss: 2.361945629119873
Validation loss: 2.4438514709472656

Epoch: 5| Step: 2
Training loss: 2.8965320587158203
Validation loss: 2.444887657960256

Epoch: 5| Step: 3
Training loss: 2.794675350189209
Validation loss: 2.4415751894315085

Epoch: 5| Step: 4
Training loss: 2.331798791885376
Validation loss: 2.4408181657393775

Epoch: 5| Step: 5
Training loss: 2.685152769088745
Validation loss: 2.432691385348638

Epoch: 5| Step: 6
Training loss: 2.6783738136291504
Validation loss: 2.436299959818522

Epoch: 5| Step: 7
Training loss: 2.4129478931427
Validation loss: 2.436711847782135

Epoch: 5| Step: 8
Training loss: 2.876187562942505
Validation loss: 2.434600571791331

Epoch: 5| Step: 9
Training loss: 3.2454819679260254
Validation loss: 2.421566824118296

Epoch: 5| Step: 10
Training loss: 2.016892910003662
Validation loss: 2.4215568701426187

Epoch: 5| Step: 11
Training loss: 1.6600489616394043
Validation loss: 2.4140355587005615

Epoch: 50| Step: 0
Training loss: 2.4152920246124268
Validation loss: 2.415075500806173

Epoch: 5| Step: 1
Training loss: 2.8533480167388916
Validation loss: 2.41031406323115

Epoch: 5| Step: 2
Training loss: 2.1579411029815674
Validation loss: 2.4142216940720878

Epoch: 5| Step: 3
Training loss: 2.0164427757263184
Validation loss: 2.4115201036135354

Epoch: 5| Step: 4
Training loss: 2.8545098304748535
Validation loss: 2.4086353480815887

Epoch: 5| Step: 5
Training loss: 2.8031461238861084
Validation loss: 2.4044316609700522

Epoch: 5| Step: 6
Training loss: 3.181382417678833
Validation loss: 2.4021510779857635

Epoch: 5| Step: 7
Training loss: 2.624854564666748
Validation loss: 2.400131950775782

Epoch: 5| Step: 8
Training loss: 2.5412704944610596
Validation loss: 2.3982015450795493

Epoch: 5| Step: 9
Training loss: 1.7952301502227783
Validation loss: 2.3933064540227256

Epoch: 5| Step: 10
Training loss: 2.9431395530700684
Validation loss: 2.3928012748559317

Epoch: 5| Step: 11
Training loss: 3.796480655670166
Validation loss: 2.3899148305257163

Epoch: 51| Step: 0
Training loss: 2.809990406036377
Validation loss: 2.3849965184926987

Epoch: 5| Step: 1
Training loss: 3.186389207839966
Validation loss: 2.3788032680749893

Epoch: 5| Step: 2
Training loss: 3.1577792167663574
Validation loss: 2.3784686625003815

Epoch: 5| Step: 3
Training loss: 1.798079252243042
Validation loss: 2.3773676455020905

Epoch: 5| Step: 4
Training loss: 2.5287678241729736
Validation loss: 2.3770859142144523

Epoch: 5| Step: 5
Training loss: 2.669264316558838
Validation loss: 2.378418276707331

Epoch: 5| Step: 6
Training loss: 2.1659770011901855
Validation loss: 2.373364806175232

Epoch: 5| Step: 7
Training loss: 2.0228869915008545
Validation loss: 2.3723470071951547

Epoch: 5| Step: 8
Training loss: 2.8075954914093018
Validation loss: 2.3678286969661713

Epoch: 5| Step: 9
Training loss: 2.4937703609466553
Validation loss: 2.3603168030579886

Epoch: 5| Step: 10
Training loss: 2.6452953815460205
Validation loss: 2.3553761889537177

Epoch: 5| Step: 11
Training loss: 1.854142665863037
Validation loss: 2.354177395502726

Epoch: 52| Step: 0
Training loss: 2.8647444248199463
Validation loss: 2.349349101384481

Epoch: 5| Step: 1
Training loss: 2.446753978729248
Validation loss: 2.3482322692871094

Epoch: 5| Step: 2
Training loss: 2.833993911743164
Validation loss: 2.34769669175148

Epoch: 5| Step: 3
Training loss: 2.4084153175354004
Validation loss: 2.3438544968763986

Epoch: 5| Step: 4
Training loss: 2.7174060344696045
Validation loss: 2.3438643713792167

Epoch: 5| Step: 5
Training loss: 2.7387752532958984
Validation loss: 2.342516471942266

Epoch: 5| Step: 6
Training loss: 2.487199544906616
Validation loss: 2.339962750673294

Epoch: 5| Step: 7
Training loss: 2.378279685974121
Validation loss: 2.3324789901574454

Epoch: 5| Step: 8
Training loss: 1.8501373529434204
Validation loss: 2.334358334541321

Epoch: 5| Step: 9
Training loss: 2.545422077178955
Validation loss: 2.3298637866973877

Epoch: 5| Step: 10
Training loss: 2.44610595703125
Validation loss: 2.3270327101151147

Epoch: 5| Step: 11
Training loss: 2.2852251529693604
Validation loss: 2.330130065480868

Epoch: 53| Step: 0
Training loss: 2.3895695209503174
Validation loss: 2.3214851866165795

Epoch: 5| Step: 1
Training loss: 2.863501787185669
Validation loss: 2.3268261651198068

Epoch: 5| Step: 2
Training loss: 2.162252426147461
Validation loss: 2.3216173301140466

Epoch: 5| Step: 3
Training loss: 2.450697898864746
Validation loss: 2.3143302897612252

Epoch: 5| Step: 4
Training loss: 1.8146421909332275
Validation loss: 2.315409461657206

Epoch: 5| Step: 5
Training loss: 3.0214290618896484
Validation loss: 2.3116869032382965

Epoch: 5| Step: 6
Training loss: 2.6071865558624268
Validation loss: 2.3154932111501694

Epoch: 5| Step: 7
Training loss: 2.427307605743408
Validation loss: 2.3098127245903015

Epoch: 5| Step: 8
Training loss: 2.526982069015503
Validation loss: 2.3068731923898063

Epoch: 5| Step: 9
Training loss: 2.456434726715088
Validation loss: 2.2992224295934043

Epoch: 5| Step: 10
Training loss: 2.6315081119537354
Validation loss: 2.300222267707189

Epoch: 5| Step: 11
Training loss: 2.2655625343322754
Validation loss: 2.295549601316452

Epoch: 54| Step: 0
Training loss: 2.6568026542663574
Validation loss: 2.2955717047055564

Epoch: 5| Step: 1
Training loss: 2.618069887161255
Validation loss: 2.2929445107777915

Epoch: 5| Step: 2
Training loss: 2.016477584838867
Validation loss: 2.287735174099604

Epoch: 5| Step: 3
Training loss: 2.5545272827148438
Validation loss: 2.2873742282390594

Epoch: 5| Step: 4
Training loss: 2.479602813720703
Validation loss: 2.285478492577871

Epoch: 5| Step: 5
Training loss: 1.847516655921936
Validation loss: 2.286417414744695

Epoch: 5| Step: 6
Training loss: 2.724642276763916
Validation loss: 2.274284308155378

Epoch: 5| Step: 7
Training loss: 2.469939708709717
Validation loss: 2.274611383676529

Epoch: 5| Step: 8
Training loss: 2.909902572631836
Validation loss: 2.2764528393745422

Epoch: 5| Step: 9
Training loss: 2.217191696166992
Validation loss: 2.273375188310941

Epoch: 5| Step: 10
Training loss: 2.416649580001831
Validation loss: 2.2669829378525415

Epoch: 5| Step: 11
Training loss: 2.3240113258361816
Validation loss: 2.262579838434855

Epoch: 55| Step: 0
Training loss: 2.2486648559570312
Validation loss: 2.26755553483963

Epoch: 5| Step: 1
Training loss: 1.924180030822754
Validation loss: 2.261742194493612

Epoch: 5| Step: 2
Training loss: 2.858259916305542
Validation loss: 2.2608596881230674

Epoch: 5| Step: 3
Training loss: 2.5867199897766113
Validation loss: 2.2575658162434897

Epoch: 5| Step: 4
Training loss: 2.176286458969116
Validation loss: 2.2549573679765067

Epoch: 5| Step: 5
Training loss: 2.371032238006592
Validation loss: 2.2521185129880905

Epoch: 5| Step: 6
Training loss: 2.2886974811553955
Validation loss: 2.2513075371583304

Epoch: 5| Step: 7
Training loss: 2.3887381553649902
Validation loss: 2.2435124665498734

Epoch: 5| Step: 8
Training loss: 2.5652050971984863
Validation loss: 2.239298244317373

Epoch: 5| Step: 9
Training loss: 2.652850866317749
Validation loss: 2.2378567159175873

Epoch: 5| Step: 10
Training loss: 2.3934764862060547
Validation loss: 2.233869959910711

Epoch: 5| Step: 11
Training loss: 2.635270595550537
Validation loss: 2.23821326593558

Epoch: 56| Step: 0
Training loss: 2.3267135620117188
Validation loss: 2.2254841923713684

Epoch: 5| Step: 1
Training loss: 2.342510223388672
Validation loss: 2.233924220005671

Epoch: 5| Step: 2
Training loss: 2.3777852058410645
Validation loss: 2.2287352134784064

Epoch: 5| Step: 3
Training loss: 2.072613000869751
Validation loss: 2.2220966517925262

Epoch: 5| Step: 4
Training loss: 2.3406479358673096
Validation loss: 2.2233069241046906

Epoch: 5| Step: 5
Training loss: 1.8689708709716797
Validation loss: 2.2205303410689035

Epoch: 5| Step: 6
Training loss: 2.8101298809051514
Validation loss: 2.2169725000858307

Epoch: 5| Step: 7
Training loss: 2.557785749435425
Validation loss: 2.215902333458265

Epoch: 5| Step: 8
Training loss: 2.906316041946411
Validation loss: 2.21023058394591

Epoch: 5| Step: 9
Training loss: 2.0316364765167236
Validation loss: 2.212913895646731

Epoch: 5| Step: 10
Training loss: 2.47149920463562
Validation loss: 2.213082417845726

Epoch: 5| Step: 11
Training loss: 2.2771971225738525
Validation loss: 2.207918703556061

Epoch: 57| Step: 0
Training loss: 2.7299981117248535
Validation loss: 2.2062511642773948

Epoch: 5| Step: 1
Training loss: 1.930976152420044
Validation loss: 2.2024273574352264

Epoch: 5| Step: 2
Training loss: 2.4531521797180176
Validation loss: 2.2100046972433725

Epoch: 5| Step: 3
Training loss: 2.6421432495117188
Validation loss: 2.2076351096232734

Epoch: 5| Step: 4
Training loss: 1.902663230895996
Validation loss: 2.203662564357122

Epoch: 5| Step: 5
Training loss: 2.3096425533294678
Validation loss: 2.197184776266416

Epoch: 5| Step: 6
Training loss: 2.2263453006744385
Validation loss: 2.1962466736634574

Epoch: 5| Step: 7
Training loss: 2.9639053344726562
Validation loss: 2.188763995965322

Epoch: 5| Step: 8
Training loss: 1.9851710796356201
Validation loss: 2.1815400073925653

Epoch: 5| Step: 9
Training loss: 2.131664276123047
Validation loss: 2.187211806575457

Epoch: 5| Step: 10
Training loss: 2.459486961364746
Validation loss: 2.1962421288092933

Epoch: 5| Step: 11
Training loss: 3.3328027725219727
Validation loss: 2.188666711250941

Epoch: 58| Step: 0
Training loss: 2.041358232498169
Validation loss: 2.1766419609387717

Epoch: 5| Step: 1
Training loss: 2.1712586879730225
Validation loss: 2.175972878932953

Epoch: 5| Step: 2
Training loss: 3.0941414833068848
Validation loss: 2.1662459671497345

Epoch: 5| Step: 3
Training loss: 2.289428234100342
Validation loss: 2.1738737473885217

Epoch: 5| Step: 4
Training loss: 2.4076600074768066
Validation loss: 2.1702305525541306

Epoch: 5| Step: 5
Training loss: 2.5315327644348145
Validation loss: 2.16947403550148

Epoch: 5| Step: 6
Training loss: 2.246304512023926
Validation loss: 2.1853080689907074

Epoch: 5| Step: 7
Training loss: 2.6655020713806152
Validation loss: 2.1732624570528665

Epoch: 5| Step: 8
Training loss: 2.3448333740234375
Validation loss: 2.1782471438248954

Epoch: 5| Step: 9
Training loss: 1.9082199335098267
Validation loss: 2.1735567996899285

Epoch: 5| Step: 10
Training loss: 1.9925743341445923
Validation loss: 2.1664315462112427

Epoch: 5| Step: 11
Training loss: 2.121614694595337
Validation loss: 2.1637201805909476

Epoch: 59| Step: 0
Training loss: 2.6540961265563965
Validation loss: 2.1577426145474115

Epoch: 5| Step: 1
Training loss: 2.226206064224243
Validation loss: 2.164876013994217

Epoch: 5| Step: 2
Training loss: 2.7083849906921387
Validation loss: 2.157603661219279

Epoch: 5| Step: 3
Training loss: 2.069476366043091
Validation loss: 2.163470596075058

Epoch: 5| Step: 4
Training loss: 1.861419439315796
Validation loss: 2.153876190384229

Epoch: 5| Step: 5
Training loss: 2.0035746097564697
Validation loss: 2.147753914197286

Epoch: 5| Step: 6
Training loss: 2.0057990550994873
Validation loss: 2.152569909890493

Epoch: 5| Step: 7
Training loss: 2.5305776596069336
Validation loss: 2.140811632076899

Epoch: 5| Step: 8
Training loss: 2.802403450012207
Validation loss: 2.1539197812477746

Epoch: 5| Step: 9
Training loss: 2.3092904090881348
Validation loss: 2.146497055888176

Epoch: 5| Step: 10
Training loss: 2.0618348121643066
Validation loss: 2.136474460363388

Epoch: 5| Step: 11
Training loss: 2.9472146034240723
Validation loss: 2.1379989931980767

Epoch: 60| Step: 0
Training loss: 2.5791640281677246
Validation loss: 2.135710229476293

Epoch: 5| Step: 1
Training loss: 2.198108673095703
Validation loss: 2.1427617967128754

Epoch: 5| Step: 2
Training loss: 2.7135684490203857
Validation loss: 2.1547810087601342

Epoch: 5| Step: 3
Training loss: 2.6028189659118652
Validation loss: 2.1562966456015906

Epoch: 5| Step: 4
Training loss: 2.0117712020874023
Validation loss: 2.162832960486412

Epoch: 5| Step: 5
Training loss: 2.1620078086853027
Validation loss: 2.1684341579675674

Epoch: 5| Step: 6
Training loss: 2.4188120365142822
Validation loss: 2.1629523634910583

Epoch: 5| Step: 7
Training loss: 2.3389933109283447
Validation loss: 2.1551587333281836

Epoch: 5| Step: 8
Training loss: 2.4601361751556396
Validation loss: 2.139973506331444

Epoch: 5| Step: 9
Training loss: 2.231297731399536
Validation loss: 2.1382846981287003

Epoch: 5| Step: 10
Training loss: 2.0236856937408447
Validation loss: 2.1370749125878015

Epoch: 5| Step: 11
Training loss: 1.1719505786895752
Validation loss: 2.12591061492761

Epoch: 61| Step: 0
Training loss: 2.2095296382904053
Validation loss: 2.122256795565287

Epoch: 5| Step: 1
Training loss: 2.8598506450653076
Validation loss: 2.1213686764240265

Epoch: 5| Step: 2
Training loss: 2.29127836227417
Validation loss: 2.1256920844316483

Epoch: 5| Step: 3
Training loss: 2.4672017097473145
Validation loss: 2.1306935598452887

Epoch: 5| Step: 4
Training loss: 1.8709291219711304
Validation loss: 2.127412815888723

Epoch: 5| Step: 5
Training loss: 2.0388073921203613
Validation loss: 2.115474114815394

Epoch: 5| Step: 6
Training loss: 2.2335641384124756
Validation loss: 2.1187151074409485

Epoch: 5| Step: 7
Training loss: 2.0704565048217773
Validation loss: 2.1122416059176126

Epoch: 5| Step: 8
Training loss: 2.1205523014068604
Validation loss: 2.11601655681928

Epoch: 5| Step: 9
Training loss: 2.405378580093384
Validation loss: 2.1208840558926263

Epoch: 5| Step: 10
Training loss: 2.5018603801727295
Validation loss: 2.119835779070854

Epoch: 5| Step: 11
Training loss: 3.0473804473876953
Validation loss: 2.116854985555013

Epoch: 62| Step: 0
Training loss: 2.559688091278076
Validation loss: 2.116594061255455

Epoch: 5| Step: 1
Training loss: 1.6860746145248413
Validation loss: 2.1154500246047974

Epoch: 5| Step: 2
Training loss: 2.1519010066986084
Validation loss: 2.1153155813614526

Epoch: 5| Step: 3
Training loss: 2.0534701347351074
Validation loss: 2.1168953826030097

Epoch: 5| Step: 4
Training loss: 2.2885472774505615
Validation loss: 2.1203187108039856

Epoch: 5| Step: 5
Training loss: 2.313615322113037
Validation loss: 2.114902983109156

Epoch: 5| Step: 6
Training loss: 2.5244240760803223
Validation loss: 2.112454354763031

Epoch: 5| Step: 7
Training loss: 2.4381396770477295
Validation loss: 2.1066804081201553

Epoch: 5| Step: 8
Training loss: 2.1691975593566895
Validation loss: 2.1075541178385415

Epoch: 5| Step: 9
Training loss: 2.3946986198425293
Validation loss: 2.1060945143302283

Epoch: 5| Step: 10
Training loss: 2.4045605659484863
Validation loss: 2.1078115105628967

Epoch: 5| Step: 11
Training loss: 3.1284079551696777
Validation loss: 2.1064536422491074

Epoch: 63| Step: 0
Training loss: 1.907846450805664
Validation loss: 2.099107007185618

Epoch: 5| Step: 1
Training loss: 2.351531982421875
Validation loss: 2.100096116463343

Epoch: 5| Step: 2
Training loss: 3.041842222213745
Validation loss: 2.0986406753460565

Epoch: 5| Step: 3
Training loss: 2.164757490158081
Validation loss: 2.0904476046562195

Epoch: 5| Step: 4
Training loss: 2.0524024963378906
Validation loss: 2.0922658095757165

Epoch: 5| Step: 5
Training loss: 2.153014659881592
Validation loss: 2.088635578751564

Epoch: 5| Step: 6
Training loss: 2.1330790519714355
Validation loss: 2.089625805616379

Epoch: 5| Step: 7
Training loss: 2.376112937927246
Validation loss: 2.0877431482076645

Epoch: 5| Step: 8
Training loss: 2.763920307159424
Validation loss: 2.087769796450933

Epoch: 5| Step: 9
Training loss: 2.404452085494995
Validation loss: 2.0892651081085205

Epoch: 5| Step: 10
Training loss: 1.8247299194335938
Validation loss: 2.0878466864426932

Epoch: 5| Step: 11
Training loss: 1.2089239358901978
Validation loss: 2.0844825158516564

Epoch: 64| Step: 0
Training loss: 2.5488903522491455
Validation loss: 2.083517630894979

Epoch: 5| Step: 1
Training loss: 2.424614429473877
Validation loss: 2.089464927713076

Epoch: 5| Step: 2
Training loss: 2.103625774383545
Validation loss: 2.0926410456498465

Epoch: 5| Step: 3
Training loss: 2.3701088428497314
Validation loss: 2.087365244825681

Epoch: 5| Step: 4
Training loss: 2.7481322288513184
Validation loss: 2.0994409173727036

Epoch: 5| Step: 5
Training loss: 2.1273975372314453
Validation loss: 2.0929148544867835

Epoch: 5| Step: 6
Training loss: 2.2325515747070312
Validation loss: 2.089146544535955

Epoch: 5| Step: 7
Training loss: 2.312354564666748
Validation loss: 2.0847554355859756

Epoch: 5| Step: 8
Training loss: 2.2978618144989014
Validation loss: 2.082225431998571

Epoch: 5| Step: 9
Training loss: 1.702985405921936
Validation loss: 2.076711967587471

Epoch: 5| Step: 10
Training loss: 2.211914539337158
Validation loss: 2.076725125312805

Epoch: 5| Step: 11
Training loss: 1.31459641456604
Validation loss: 2.0779180278380713

Epoch: 65| Step: 0
Training loss: 2.151601552963257
Validation loss: 2.1204441090424857

Epoch: 5| Step: 1
Training loss: 2.578176975250244
Validation loss: 2.164919152855873

Epoch: 5| Step: 2
Training loss: 2.278458833694458
Validation loss: 2.2161251306533813

Epoch: 5| Step: 3
Training loss: 2.3028295040130615
Validation loss: 2.1908812870581946

Epoch: 5| Step: 4
Training loss: 1.879253625869751
Validation loss: 2.1185134599606195

Epoch: 5| Step: 5
Training loss: 3.0976669788360596
Validation loss: 2.0790058026711145

Epoch: 5| Step: 6
Training loss: 1.8039820194244385
Validation loss: 2.0709200352430344

Epoch: 5| Step: 7
Training loss: 2.6295225620269775
Validation loss: 2.07749405503273

Epoch: 5| Step: 8
Training loss: 2.3028857707977295
Validation loss: 2.082505762577057

Epoch: 5| Step: 9
Training loss: 2.082900285720825
Validation loss: 2.0957240064938865

Epoch: 5| Step: 10
Training loss: 2.282848596572876
Validation loss: 2.1055125097433725

Epoch: 5| Step: 11
Training loss: 2.460663318634033
Validation loss: 2.115665207306544

Epoch: 66| Step: 0
Training loss: 2.342036724090576
Validation loss: 2.126447613040606

Epoch: 5| Step: 1
Training loss: 2.281872272491455
Validation loss: 2.1339340607325235

Epoch: 5| Step: 2
Training loss: 1.8610515594482422
Validation loss: 2.137216071287791

Epoch: 5| Step: 3
Training loss: 1.878971815109253
Validation loss: 2.13076022764047

Epoch: 5| Step: 4
Training loss: 2.3017125129699707
Validation loss: 2.1229395320018134

Epoch: 5| Step: 5
Training loss: 2.851283073425293
Validation loss: 2.1116875807444253

Epoch: 5| Step: 6
Training loss: 2.491522789001465
Validation loss: 2.1047529578208923

Epoch: 5| Step: 7
Training loss: 2.399585723876953
Validation loss: 2.0954503268003464

Epoch: 5| Step: 8
Training loss: 1.9446979761123657
Validation loss: 2.0879997263352075

Epoch: 5| Step: 9
Training loss: 2.633943557739258
Validation loss: 2.081388602654139

Epoch: 5| Step: 10
Training loss: 2.087205410003662
Validation loss: 2.0786990423997245

Epoch: 5| Step: 11
Training loss: 2.824373245239258
Validation loss: 2.07396133740743

Epoch: 67| Step: 0
Training loss: 2.926222085952759
Validation loss: 2.0639841059843698

Epoch: 5| Step: 1
Training loss: 2.2594707012176514
Validation loss: 2.0556981613238654

Epoch: 5| Step: 2
Training loss: 2.3594119548797607
Validation loss: 2.0548830727736154

Epoch: 5| Step: 3
Training loss: 2.3763763904571533
Validation loss: 2.0567538191874823

Epoch: 5| Step: 4
Training loss: 1.964632272720337
Validation loss: 2.047640780607859

Epoch: 5| Step: 5
Training loss: 1.75458562374115
Validation loss: 2.045893078049024

Epoch: 5| Step: 6
Training loss: 2.443021297454834
Validation loss: 2.047098676363627

Epoch: 5| Step: 7
Training loss: 2.654123544692993
Validation loss: 2.050029695034027

Epoch: 5| Step: 8
Training loss: 1.83295476436615
Validation loss: 2.055344561735789

Epoch: 5| Step: 9
Training loss: 1.5794732570648193
Validation loss: 2.04989130795002

Epoch: 5| Step: 10
Training loss: 2.3929944038391113
Validation loss: 2.0512841741243997

Epoch: 5| Step: 11
Training loss: 2.596599578857422
Validation loss: 2.0484196146329245

Epoch: 68| Step: 0
Training loss: 2.411933422088623
Validation loss: 2.0464329520861306

Epoch: 5| Step: 1
Training loss: 1.9088878631591797
Validation loss: 2.046308606863022

Epoch: 5| Step: 2
Training loss: 2.036133289337158
Validation loss: 2.047259400288264

Epoch: 5| Step: 3
Training loss: 2.6636581420898438
Validation loss: 2.0521939198176065

Epoch: 5| Step: 4
Training loss: 1.9482803344726562
Validation loss: 2.058107410868009

Epoch: 5| Step: 5
Training loss: 2.0741639137268066
Validation loss: 2.055782899260521

Epoch: 5| Step: 6
Training loss: 1.4279099702835083
Validation loss: 2.0522297273079553

Epoch: 5| Step: 7
Training loss: 2.3058083057403564
Validation loss: 2.047983482480049

Epoch: 5| Step: 8
Training loss: 2.3868563175201416
Validation loss: 2.0508374075094857

Epoch: 5| Step: 9
Training loss: 2.550917863845825
Validation loss: 2.0476491302251816

Epoch: 5| Step: 10
Training loss: 2.6549880504608154
Validation loss: 2.0431362688541412

Epoch: 5| Step: 11
Training loss: 3.101595163345337
Validation loss: 2.0413112541039786

Epoch: 69| Step: 0
Training loss: 2.1327602863311768
Validation loss: 2.0430801659822464

Epoch: 5| Step: 1
Training loss: 2.2345259189605713
Validation loss: 2.0475770185391107

Epoch: 5| Step: 2
Training loss: 2.1399006843566895
Validation loss: 2.055891493956248

Epoch: 5| Step: 3
Training loss: 2.514157772064209
Validation loss: 2.0667219161987305

Epoch: 5| Step: 4
Training loss: 1.6619517803192139
Validation loss: 2.0600509444872537

Epoch: 5| Step: 5
Training loss: 2.0880286693573
Validation loss: 2.067631339033445

Epoch: 5| Step: 6
Training loss: 2.9107866287231445
Validation loss: 2.063274790843328

Epoch: 5| Step: 7
Training loss: 2.984818696975708
Validation loss: 2.0603185494740806

Epoch: 5| Step: 8
Training loss: 2.0536437034606934
Validation loss: 2.0575017978747687

Epoch: 5| Step: 9
Training loss: 1.6345762014389038
Validation loss: 2.052917386094729

Epoch: 5| Step: 10
Training loss: 2.363158702850342
Validation loss: 2.0548685789108276

Epoch: 5| Step: 11
Training loss: 2.0450363159179688
Validation loss: 2.042923058072726

Epoch: 70| Step: 0
Training loss: 1.7609388828277588
Validation loss: 2.0449711779753366

Epoch: 5| Step: 1
Training loss: 2.1769235134124756
Validation loss: 2.0379105458656945

Epoch: 5| Step: 2
Training loss: 2.020507335662842
Validation loss: 2.033193568388621

Epoch: 5| Step: 3
Training loss: 1.4630804061889648
Validation loss: 2.0354914565881095

Epoch: 5| Step: 4
Training loss: 2.1372182369232178
Validation loss: 2.0288406312465668

Epoch: 5| Step: 5
Training loss: 2.6978566646575928
Validation loss: 2.028969739874204

Epoch: 5| Step: 6
Training loss: 2.3954195976257324
Validation loss: 2.0318447897831597

Epoch: 5| Step: 7
Training loss: 2.2338106632232666
Validation loss: 2.0270097851753235

Epoch: 5| Step: 8
Training loss: 2.9064652919769287
Validation loss: 2.0264065861701965

Epoch: 5| Step: 9
Training loss: 2.1930177211761475
Validation loss: 2.0246891578038535

Epoch: 5| Step: 10
Training loss: 2.3464243412017822
Validation loss: 2.0341892540454865

Epoch: 5| Step: 11
Training loss: 2.503568649291992
Validation loss: 2.0268967896699905

Epoch: 71| Step: 0
Training loss: 2.2756285667419434
Validation loss: 2.029759481549263

Epoch: 5| Step: 1
Training loss: 2.192441940307617
Validation loss: 2.0372996230920157

Epoch: 5| Step: 2
Training loss: 2.359318256378174
Validation loss: 2.0364845246076584

Epoch: 5| Step: 3
Training loss: 2.447375535964966
Validation loss: 2.042387122909228

Epoch: 5| Step: 4
Training loss: 2.3829288482666016
Validation loss: 2.034506211678187

Epoch: 5| Step: 5
Training loss: 2.3017609119415283
Validation loss: 2.0322265923023224

Epoch: 5| Step: 6
Training loss: 1.7593796253204346
Validation loss: 2.023481011390686

Epoch: 5| Step: 7
Training loss: 2.2261383533477783
Validation loss: 2.0321156978607178

Epoch: 5| Step: 8
Training loss: 2.5286459922790527
Validation loss: 2.029355466365814

Epoch: 5| Step: 9
Training loss: 1.7699133157730103
Validation loss: 2.0253343234459558

Epoch: 5| Step: 10
Training loss: 2.216897487640381
Validation loss: 2.0300797671079636

Epoch: 5| Step: 11
Training loss: 1.6482230424880981
Validation loss: 2.0316686928272247

Epoch: 72| Step: 0
Training loss: 2.354363441467285
Validation loss: 2.0316560566425323

Epoch: 5| Step: 1
Training loss: 2.0623509883880615
Validation loss: 2.0293306608994803

Epoch: 5| Step: 2
Training loss: 2.237440824508667
Validation loss: 2.0332289934158325

Epoch: 5| Step: 3
Training loss: 2.5949745178222656
Validation loss: 2.022737145423889

Epoch: 5| Step: 4
Training loss: 2.406956911087036
Validation loss: 2.0333530952533088

Epoch: 5| Step: 5
Training loss: 1.788156509399414
Validation loss: 2.0300664554039636

Epoch: 5| Step: 6
Training loss: 1.9777805805206299
Validation loss: 2.036795819799105

Epoch: 5| Step: 7
Training loss: 1.828919768333435
Validation loss: 2.01731946070989

Epoch: 5| Step: 8
Training loss: 2.084097385406494
Validation loss: 2.015402168035507

Epoch: 5| Step: 9
Training loss: 2.0780231952667236
Validation loss: 2.0137756715218225

Epoch: 5| Step: 10
Training loss: 2.732239246368408
Validation loss: 2.015382875998815

Epoch: 5| Step: 11
Training loss: 1.9294127225875854
Validation loss: 2.019844576716423

Epoch: 73| Step: 0
Training loss: 1.9472366571426392
Validation loss: 2.0282062292099

Epoch: 5| Step: 1
Training loss: 1.803236722946167
Validation loss: 2.0313648879528046

Epoch: 5| Step: 2
Training loss: 2.7233994007110596
Validation loss: 2.03605725367864

Epoch: 5| Step: 3
Training loss: 2.5349812507629395
Validation loss: 2.041129916906357

Epoch: 5| Step: 4
Training loss: 2.083343505859375
Validation loss: 2.036155010263125

Epoch: 5| Step: 5
Training loss: 2.19913649559021
Validation loss: 2.0390107532342276

Epoch: 5| Step: 6
Training loss: 2.3306596279144287
Validation loss: 2.033859690030416

Epoch: 5| Step: 7
Training loss: 2.4566636085510254
Validation loss: 2.0358854879935584

Epoch: 5| Step: 8
Training loss: 2.1049869060516357
Validation loss: 2.0303763151168823

Epoch: 5| Step: 9
Training loss: 2.1600146293640137
Validation loss: 2.025979772210121

Epoch: 5| Step: 10
Training loss: 1.8461427688598633
Validation loss: 2.018075088659922

Epoch: 5| Step: 11
Training loss: 2.54376220703125
Validation loss: 2.0122420887152352

Epoch: 74| Step: 0
Training loss: 2.1466000080108643
Validation loss: 2.0157217532396317

Epoch: 5| Step: 1
Training loss: 2.2366981506347656
Validation loss: 2.011428192257881

Epoch: 5| Step: 2
Training loss: 2.074719190597534
Validation loss: 2.0102762977282205

Epoch: 5| Step: 3
Training loss: 1.9936681985855103
Validation loss: 2.0245967358350754

Epoch: 5| Step: 4
Training loss: 1.885843276977539
Validation loss: 2.021829297145208

Epoch: 5| Step: 5
Training loss: 1.6888965368270874
Validation loss: 2.016297106941541

Epoch: 5| Step: 6
Training loss: 1.65298330783844
Validation loss: 2.013560468951861

Epoch: 5| Step: 7
Training loss: 2.4242050647735596
Validation loss: 2.0218038856983185

Epoch: 5| Step: 8
Training loss: 2.700774908065796
Validation loss: 2.0120185762643814

Epoch: 5| Step: 9
Training loss: 2.601043462753296
Validation loss: 2.01572755475839

Epoch: 5| Step: 10
Training loss: 2.521873950958252
Validation loss: 2.015212371945381

Epoch: 5| Step: 11
Training loss: 3.0818614959716797
Validation loss: 2.014677733182907

Epoch: 75| Step: 0
Training loss: 2.569000720977783
Validation loss: 2.02628002067407

Epoch: 5| Step: 1
Training loss: 2.1166629791259766
Validation loss: 2.0305475493272147

Epoch: 5| Step: 2
Training loss: 2.6622982025146484
Validation loss: 2.027121673027674

Epoch: 5| Step: 3
Training loss: 1.9833141565322876
Validation loss: 2.029702047506968

Epoch: 5| Step: 4
Training loss: 2.627566337585449
Validation loss: 2.026866222421328

Epoch: 5| Step: 5
Training loss: 1.9792144298553467
Validation loss: 2.033995116750399

Epoch: 5| Step: 6
Training loss: 2.0147387981414795
Validation loss: 2.0382744818925858

Epoch: 5| Step: 7
Training loss: 2.3234190940856934
Validation loss: 2.0241085588932037

Epoch: 5| Step: 8
Training loss: 1.9752368927001953
Validation loss: 2.0232276171445847

Epoch: 5| Step: 9
Training loss: 2.285524845123291
Validation loss: 2.0081659654776254

Epoch: 5| Step: 10
Training loss: 1.6120086908340454
Validation loss: 2.0134952465693154

Epoch: 5| Step: 11
Training loss: 1.853971004486084
Validation loss: 2.015850936373075

Epoch: 76| Step: 0
Training loss: 2.3483004570007324
Validation loss: 2.0278458098570504

Epoch: 5| Step: 1
Training loss: 1.9308780431747437
Validation loss: 2.032577763001124

Epoch: 5| Step: 2
Training loss: 1.6239935159683228
Validation loss: 2.024013767639796

Epoch: 5| Step: 3
Training loss: 2.4288692474365234
Validation loss: 2.0199579298496246

Epoch: 5| Step: 4
Training loss: 2.1429381370544434
Validation loss: 2.019640470544497

Epoch: 5| Step: 5
Training loss: 1.9650218486785889
Validation loss: 2.0084705551465354

Epoch: 5| Step: 6
Training loss: 2.4709784984588623
Validation loss: 2.0113770812749863

Epoch: 5| Step: 7
Training loss: 2.344153881072998
Validation loss: 2.0202913880348206

Epoch: 5| Step: 8
Training loss: 2.3745715618133545
Validation loss: 2.0103926261266074

Epoch: 5| Step: 9
Training loss: 2.44327449798584
Validation loss: 2.0123866299788156

Epoch: 5| Step: 10
Training loss: 2.24948787689209
Validation loss: 2.0126021057367325

Epoch: 5| Step: 11
Training loss: 1.6311261653900146
Validation loss: 2.010073403517405

Epoch: 77| Step: 0
Training loss: 2.393725633621216
Validation loss: 2.0132113645474115

Epoch: 5| Step: 1
Training loss: 2.028085708618164
Validation loss: 1.9959762791792552

Epoch: 5| Step: 2
Training loss: 2.1186447143554688
Validation loss: 2.0113932540019355

Epoch: 5| Step: 3
Training loss: 2.6800808906555176
Validation loss: 2.0172077814737954

Epoch: 5| Step: 4
Training loss: 2.038947582244873
Validation loss: 2.02710068722566

Epoch: 5| Step: 5
Training loss: 1.9712841510772705
Validation loss: 2.0426937540372214

Epoch: 5| Step: 6
Training loss: 1.597254991531372
Validation loss: 2.0332051565249762

Epoch: 5| Step: 7
Training loss: 2.8536548614501953
Validation loss: 2.040529037515322

Epoch: 5| Step: 8
Training loss: 1.9116586446762085
Validation loss: 2.0397403140862784

Epoch: 5| Step: 9
Training loss: 2.2331905364990234
Validation loss: 2.0347318102916083

Epoch: 5| Step: 10
Training loss: 2.3487730026245117
Validation loss: 2.0243042012055716

Epoch: 5| Step: 11
Training loss: 2.3598198890686035
Validation loss: 2.0076758513847985

Epoch: 78| Step: 0
Training loss: 2.264223337173462
Validation loss: 2.0110780696074166

Epoch: 5| Step: 1
Training loss: 2.1271860599517822
Validation loss: 2.012742062409719

Epoch: 5| Step: 2
Training loss: 2.297595500946045
Validation loss: 2.018422454595566

Epoch: 5| Step: 3
Training loss: 2.4821419715881348
Validation loss: 2.02986840903759

Epoch: 5| Step: 4
Training loss: 2.6860766410827637
Validation loss: 2.030542607108752

Epoch: 5| Step: 5
Training loss: 2.1307175159454346
Validation loss: 2.05118191242218

Epoch: 5| Step: 6
Training loss: 2.196488857269287
Validation loss: 2.038990095257759

Epoch: 5| Step: 7
Training loss: 2.1405117511749268
Validation loss: 2.0400926917791367

Epoch: 5| Step: 8
Training loss: 1.7701057195663452
Validation loss: 2.025617614388466

Epoch: 5| Step: 9
Training loss: 1.8017890453338623
Validation loss: 2.0166403303543725

Epoch: 5| Step: 10
Training loss: 1.9725109338760376
Validation loss: 2.0156376510858536

Epoch: 5| Step: 11
Training loss: 2.4085590839385986
Validation loss: 2.0099869767824807

Epoch: 79| Step: 0
Training loss: 2.3790385723114014
Validation loss: 2.0082895358403525

Epoch: 5| Step: 1
Training loss: 2.3596553802490234
Validation loss: 2.0206093788146973

Epoch: 5| Step: 2
Training loss: 2.466012477874756
Validation loss: 2.0208160181840262

Epoch: 5| Step: 3
Training loss: 2.3317759037017822
Validation loss: 2.022733603914579

Epoch: 5| Step: 4
Training loss: 2.217156171798706
Validation loss: 2.0266509453455606

Epoch: 5| Step: 5
Training loss: 1.840439796447754
Validation loss: 2.0205295284589133

Epoch: 5| Step: 6
Training loss: 1.9229007959365845
Validation loss: 2.017029901345571

Epoch: 5| Step: 7
Training loss: 2.3267862796783447
Validation loss: 2.0139543612798056

Epoch: 5| Step: 8
Training loss: 2.5814766883850098
Validation loss: 2.0028340369462967

Epoch: 5| Step: 9
Training loss: 1.3072048425674438
Validation loss: 2.016415163874626

Epoch: 5| Step: 10
Training loss: 2.3659114837646484
Validation loss: 2.006090650955836

Epoch: 5| Step: 11
Training loss: 2.3203821182250977
Validation loss: 2.003066380818685

Epoch: 80| Step: 0
Training loss: 2.4866652488708496
Validation loss: 2.018958772222201

Epoch: 5| Step: 1
Training loss: 2.4738643169403076
Validation loss: 2.0321635206540427

Epoch: 5| Step: 2
Training loss: 2.399259328842163
Validation loss: 2.0486272474129996

Epoch: 5| Step: 3
Training loss: 2.311933755874634
Validation loss: 2.0627527981996536

Epoch: 5| Step: 4
Training loss: 1.7472063302993774
Validation loss: 2.0723068614800773

Epoch: 5| Step: 5
Training loss: 2.099112033843994
Validation loss: 2.0759682953357697

Epoch: 5| Step: 6
Training loss: 1.468161940574646
Validation loss: 2.0375722696383796

Epoch: 5| Step: 7
Training loss: 2.709045886993408
Validation loss: 2.0305943936109543

Epoch: 5| Step: 8
Training loss: 2.3762779235839844
Validation loss: 2.0136488378047943

Epoch: 5| Step: 9
Training loss: 1.9337928295135498
Validation loss: 2.002778629461924

Epoch: 5| Step: 10
Training loss: 2.1842503547668457
Validation loss: 2.009856363137563

Epoch: 5| Step: 11
Training loss: 1.9505980014801025
Validation loss: 2.023251791795095

Epoch: 81| Step: 0
Training loss: 2.4108948707580566
Validation loss: 2.0297721972068152

Epoch: 5| Step: 1
Training loss: 2.4321346282958984
Validation loss: 2.0345836778481803

Epoch: 5| Step: 2
Training loss: 1.8671207427978516
Validation loss: 2.0454840511083603

Epoch: 5| Step: 3
Training loss: 2.5657670497894287
Validation loss: 2.040126472711563

Epoch: 5| Step: 4
Training loss: 1.8051799535751343
Validation loss: 2.0394784808158875

Epoch: 5| Step: 5
Training loss: 1.9403663873672485
Validation loss: 2.043573185801506

Epoch: 5| Step: 6
Training loss: 2.434241771697998
Validation loss: 2.0400775174299874

Epoch: 5| Step: 7
Training loss: 2.1507840156555176
Validation loss: 2.031559571623802

Epoch: 5| Step: 8
Training loss: 1.9795787334442139
Validation loss: 2.028204749027888

Epoch: 5| Step: 9
Training loss: 1.9242737293243408
Validation loss: 2.0162570426861444

Epoch: 5| Step: 10
Training loss: 2.7933998107910156
Validation loss: 2.0121707171201706

Epoch: 5| Step: 11
Training loss: 2.0940818786621094
Validation loss: 2.023346190651258

Epoch: 82| Step: 0
Training loss: 1.6107333898544312
Validation loss: 2.0157647331555686

Epoch: 5| Step: 1
Training loss: 2.6132500171661377
Validation loss: 2.0139113565286

Epoch: 5| Step: 2
Training loss: 1.6505534648895264
Validation loss: 2.0180646826823554

Epoch: 5| Step: 3
Training loss: 1.8786541223526
Validation loss: 2.0133645832538605

Epoch: 5| Step: 4
Training loss: 2.3256068229675293
Validation loss: 2.0275742759307227

Epoch: 5| Step: 5
Training loss: 2.688751220703125
Validation loss: 2.0328445533911386

Epoch: 5| Step: 6
Training loss: 2.7368040084838867
Validation loss: 2.0333944112062454

Epoch: 5| Step: 7
Training loss: 2.323978900909424
Validation loss: 2.036411186059316

Epoch: 5| Step: 8
Training loss: 2.146106719970703
Validation loss: 2.0244464427232742

Epoch: 5| Step: 9
Training loss: 2.2846579551696777
Validation loss: 2.021496425072352

Epoch: 5| Step: 10
Training loss: 1.673547387123108
Validation loss: 2.0278501013914743

Epoch: 5| Step: 11
Training loss: 1.0896687507629395
Validation loss: 2.0291909923156104

Epoch: 83| Step: 0
Training loss: 2.1151299476623535
Validation loss: 2.02703062693278

Epoch: 5| Step: 1
Training loss: 2.010519504547119
Validation loss: 2.0180190602938333

Epoch: 5| Step: 2
Training loss: 2.0062484741210938
Validation loss: 2.0217099636793137

Epoch: 5| Step: 3
Training loss: 2.566138505935669
Validation loss: 2.0244631618261337

Epoch: 5| Step: 4
Training loss: 2.3824541568756104
Validation loss: 2.0314711133639016

Epoch: 5| Step: 5
Training loss: 1.7418193817138672
Validation loss: 2.024503673116366

Epoch: 5| Step: 6
Training loss: 1.983401894569397
Validation loss: 2.0212256461381912

Epoch: 5| Step: 7
Training loss: 2.6305992603302
Validation loss: 2.02663225432237

Epoch: 5| Step: 8
Training loss: 1.9269847869873047
Validation loss: 2.021899168690046

Epoch: 5| Step: 9
Training loss: 1.8975082635879517
Validation loss: 2.013931095600128

Epoch: 5| Step: 10
Training loss: 2.0388128757476807
Validation loss: 2.0115005870660148

Epoch: 5| Step: 11
Training loss: 3.961608648300171
Validation loss: 2.006590262055397

Epoch: 84| Step: 0
Training loss: 2.57051157951355
Validation loss: 2.0202404210964837

Epoch: 5| Step: 1
Training loss: 1.4030412435531616
Validation loss: 2.016452511151632

Epoch: 5| Step: 2
Training loss: 2.44807505607605
Validation loss: 2.019617055853208

Epoch: 5| Step: 3
Training loss: 1.7964445352554321
Validation loss: 2.021236697832743

Epoch: 5| Step: 4
Training loss: 1.7577394247055054
Validation loss: 2.0234070420265198

Epoch: 5| Step: 5
Training loss: 2.3723411560058594
Validation loss: 2.010941962401072

Epoch: 5| Step: 6
Training loss: 2.2404892444610596
Validation loss: 2.0224230835835137

Epoch: 5| Step: 7
Training loss: 2.4598658084869385
Validation loss: 2.0246205230553946

Epoch: 5| Step: 8
Training loss: 1.9226245880126953
Validation loss: 2.0232610205809274

Epoch: 5| Step: 9
Training loss: 2.489722728729248
Validation loss: 2.0294066667556763

Epoch: 5| Step: 10
Training loss: 2.4233767986297607
Validation loss: 2.03279780348142

Epoch: 5| Step: 11
Training loss: 2.004451274871826
Validation loss: 2.0106836358706155

Epoch: 85| Step: 0
Training loss: 2.4769978523254395
Validation loss: 2.0066563238700232

Epoch: 5| Step: 1
Training loss: 1.6655820608139038
Validation loss: 2.0086220850547156

Epoch: 5| Step: 2
Training loss: 2.2544398307800293
Validation loss: 2.0110474824905396

Epoch: 5| Step: 3
Training loss: 1.861106514930725
Validation loss: 2.0179663747549057

Epoch: 5| Step: 4
Training loss: 2.20279598236084
Validation loss: 2.0044819017251334

Epoch: 5| Step: 5
Training loss: 1.8969608545303345
Validation loss: 2.0074494779109955

Epoch: 5| Step: 6
Training loss: 2.599860429763794
Validation loss: 2.0036517729361853

Epoch: 5| Step: 7
Training loss: 2.4213337898254395
Validation loss: 2.004871462782224

Epoch: 5| Step: 8
Training loss: 1.8519397974014282
Validation loss: 2.003938764333725

Epoch: 5| Step: 9
Training loss: 2.4311025142669678
Validation loss: 2.008785054087639

Epoch: 5| Step: 10
Training loss: 2.139166831970215
Validation loss: 2.0062975933154426

Epoch: 5| Step: 11
Training loss: 1.9143311977386475
Validation loss: 2.0075013786554337

Epoch: 86| Step: 0
Training loss: 2.154733896255493
Validation loss: 2.0049849102894464

Epoch: 5| Step: 1
Training loss: 2.575320243835449
Validation loss: 2.0079051852226257

Epoch: 5| Step: 2
Training loss: 2.2563540935516357
Validation loss: 2.0130428075790405

Epoch: 5| Step: 3
Training loss: 2.0232625007629395
Validation loss: 2.013677105307579

Epoch: 5| Step: 4
Training loss: 1.9218292236328125
Validation loss: 2.0055241088072457

Epoch: 5| Step: 5
Training loss: 2.3282368183135986
Validation loss: 2.010404333472252

Epoch: 5| Step: 6
Training loss: 2.020369291305542
Validation loss: 2.018953482309977

Epoch: 5| Step: 7
Training loss: 2.2344813346862793
Validation loss: 2.0187284449736276

Epoch: 5| Step: 8
Training loss: 1.379570722579956
Validation loss: 2.0074734538793564

Epoch: 5| Step: 9
Training loss: 2.494053840637207
Validation loss: 2.01631852487723

Epoch: 5| Step: 10
Training loss: 2.208576202392578
Validation loss: 2.0180380741755166

Epoch: 5| Step: 11
Training loss: 1.8940813541412354
Validation loss: 2.033483395973841

Epoch: 87| Step: 0
Training loss: 2.217315673828125
Validation loss: 2.017081250747045

Epoch: 5| Step: 1
Training loss: 2.464250087738037
Validation loss: 2.009589344263077

Epoch: 5| Step: 2
Training loss: 2.4569661617279053
Validation loss: 2.0194828311602273

Epoch: 5| Step: 3
Training loss: 2.194105863571167
Validation loss: 2.0022182017564774

Epoch: 5| Step: 4
Training loss: 1.7942196130752563
Validation loss: 1.998516043027242

Epoch: 5| Step: 5
Training loss: 2.373049259185791
Validation loss: 2.0055650224288306

Epoch: 5| Step: 6
Training loss: 2.113921642303467
Validation loss: 2.007739171385765

Epoch: 5| Step: 7
Training loss: 1.98210871219635
Validation loss: 2.001671850681305

Epoch: 5| Step: 8
Training loss: 2.3596224784851074
Validation loss: 2.0107682744661965

Epoch: 5| Step: 9
Training loss: 1.876438856124878
Validation loss: 2.004486858844757

Epoch: 5| Step: 10
Training loss: 1.932289481163025
Validation loss: 1.994776427745819

Epoch: 5| Step: 11
Training loss: 1.7102516889572144
Validation loss: 2.017260859409968

Epoch: 88| Step: 0
Training loss: 1.5809341669082642
Validation loss: 2.038641035556793

Epoch: 5| Step: 1
Training loss: 2.8356919288635254
Validation loss: 2.0770360181728997

Epoch: 5| Step: 2
Training loss: 3.3533833026885986
Validation loss: 2.1248240868250527

Epoch: 5| Step: 3
Training loss: 2.1254124641418457
Validation loss: 2.142558753490448

Epoch: 5| Step: 4
Training loss: 1.8640248775482178
Validation loss: 2.0776822715997696

Epoch: 5| Step: 5
Training loss: 2.300569534301758
Validation loss: 2.0639576464891434

Epoch: 5| Step: 6
Training loss: 2.369014263153076
Validation loss: 2.0227947582801185

Epoch: 5| Step: 7
Training loss: 1.8925626277923584
Validation loss: 1.9940781742334366

Epoch: 5| Step: 8
Training loss: 1.9100027084350586
Validation loss: 2.00591113169988

Epoch: 5| Step: 9
Training loss: 1.841579794883728
Validation loss: 2.0252861926952996

Epoch: 5| Step: 10
Training loss: 2.7105002403259277
Validation loss: 2.0347807755072913

Epoch: 5| Step: 11
Training loss: 2.4070353507995605
Validation loss: 2.0369561910629272

Epoch: 89| Step: 0
Training loss: 2.395411968231201
Validation loss: 2.0430095493793488

Epoch: 5| Step: 1
Training loss: 2.0633552074432373
Validation loss: 2.0426783114671707

Epoch: 5| Step: 2
Training loss: 2.890432357788086
Validation loss: 2.040186439951261

Epoch: 5| Step: 3
Training loss: 1.7482049465179443
Validation loss: 2.0246870865424476

Epoch: 5| Step: 4
Training loss: 2.2470312118530273
Validation loss: 2.036517729361852

Epoch: 5| Step: 5
Training loss: 2.4793150424957275
Validation loss: 2.0363838324944177

Epoch: 5| Step: 6
Training loss: 2.5627403259277344
Validation loss: 2.0200048933426538

Epoch: 5| Step: 7
Training loss: 1.6581922769546509
Validation loss: 2.0261024087667465

Epoch: 5| Step: 8
Training loss: 1.8880012035369873
Validation loss: 2.010377118984858

Epoch: 5| Step: 9
Training loss: 2.212002992630005
Validation loss: 2.014058922727903

Epoch: 5| Step: 10
Training loss: 1.988477349281311
Validation loss: 2.0086938639481864

Epoch: 5| Step: 11
Training loss: 1.5671677589416504
Validation loss: 1.9998332659403484

Epoch: 90| Step: 0
Training loss: 1.9982221126556396
Validation loss: 1.9894114484389622

Epoch: 5| Step: 1
Training loss: 1.9041763544082642
Validation loss: 1.9980347504218419

Epoch: 5| Step: 2
Training loss: 2.4243228435516357
Validation loss: 2.005903258919716

Epoch: 5| Step: 3
Training loss: 1.9870460033416748
Validation loss: 2.0196485221385956

Epoch: 5| Step: 4
Training loss: 1.9682872295379639
Validation loss: 2.024540493885676

Epoch: 5| Step: 5
Training loss: 1.8695141077041626
Validation loss: 2.022529517610868

Epoch: 5| Step: 6
Training loss: 2.737406015396118
Validation loss: 2.010434091091156

Epoch: 5| Step: 7
Training loss: 2.275233745574951
Validation loss: 1.996358836690585

Epoch: 5| Step: 8
Training loss: 2.404247760772705
Validation loss: 1.9970085869232814

Epoch: 5| Step: 9
Training loss: 2.1743850708007812
Validation loss: 1.9997366815805435

Epoch: 5| Step: 10
Training loss: 2.0602941513061523
Validation loss: 1.9940452029307683

Epoch: 5| Step: 11
Training loss: 1.8117461204528809
Validation loss: 1.987699344754219

Epoch: 91| Step: 0
Training loss: 2.369278907775879
Validation loss: 2.0042362113793692

Epoch: 5| Step: 1
Training loss: 2.060600757598877
Validation loss: 2.0092013627290726

Epoch: 5| Step: 2
Training loss: 3.1852359771728516
Validation loss: 2.010814383625984

Epoch: 5| Step: 3
Training loss: 1.7611793279647827
Validation loss: 2.00687508781751

Epoch: 5| Step: 4
Training loss: 1.505231261253357
Validation loss: 2.0157568603754044

Epoch: 5| Step: 5
Training loss: 2.2918622493743896
Validation loss: 2.0161048571268716

Epoch: 5| Step: 6
Training loss: 2.287198781967163
Validation loss: 2.0167469481627145

Epoch: 5| Step: 7
Training loss: 1.9076073169708252
Validation loss: 2.013782540957133

Epoch: 5| Step: 8
Training loss: 1.6436119079589844
Validation loss: 2.013316551844279

Epoch: 5| Step: 9
Training loss: 1.998577356338501
Validation loss: 2.0261465311050415

Epoch: 5| Step: 10
Training loss: 2.623039722442627
Validation loss: 2.0165986120700836

Epoch: 5| Step: 11
Training loss: 1.5943113565444946
Validation loss: 2.0195120374361673

Epoch: 92| Step: 0
Training loss: 2.157374858856201
Validation loss: 2.0238366027673087

Epoch: 5| Step: 1
Training loss: 2.227553367614746
Validation loss: 2.0267960826555886

Epoch: 5| Step: 2
Training loss: 2.340179443359375
Validation loss: 2.034990891814232

Epoch: 5| Step: 3
Training loss: 1.9899238348007202
Validation loss: 2.025849759578705

Epoch: 5| Step: 4
Training loss: 2.6208183765411377
Validation loss: 2.023963287472725

Epoch: 5| Step: 5
Training loss: 2.445213794708252
Validation loss: 2.0198275397221246

Epoch: 5| Step: 6
Training loss: 1.458795189857483
Validation loss: 2.023839846253395

Epoch: 5| Step: 7
Training loss: 1.8739795684814453
Validation loss: 2.0146347284317017

Epoch: 5| Step: 8
Training loss: 1.519841194152832
Validation loss: 2.0130240668853125

Epoch: 5| Step: 9
Training loss: 1.9623000621795654
Validation loss: 2.018077790737152

Epoch: 5| Step: 10
Training loss: 2.573324680328369
Validation loss: 2.017322470744451

Epoch: 5| Step: 11
Training loss: 3.5227556228637695
Validation loss: 2.0155235081911087

Epoch: 93| Step: 0
Training loss: 2.12060809135437
Validation loss: 2.0182691862185798

Epoch: 5| Step: 1
Training loss: 2.108829975128174
Validation loss: 2.021532356739044

Epoch: 5| Step: 2
Training loss: 1.8264172077178955
Validation loss: 2.0228139460086823

Epoch: 5| Step: 3
Training loss: 1.7115894556045532
Validation loss: 2.0313312162955603

Epoch: 5| Step: 4
Training loss: 2.2896745204925537
Validation loss: 2.023775960008303

Epoch: 5| Step: 5
Training loss: 2.2248520851135254
Validation loss: 2.0197396179040275

Epoch: 5| Step: 6
Training loss: 2.498042345046997
Validation loss: 2.009099950393041

Epoch: 5| Step: 7
Training loss: 2.699857234954834
Validation loss: 2.0087659706672034

Epoch: 5| Step: 8
Training loss: 1.9456956386566162
Validation loss: 2.0086555729309716

Epoch: 5| Step: 9
Training loss: 2.215632915496826
Validation loss: 2.005820388595263

Epoch: 5| Step: 10
Training loss: 1.9420289993286133
Validation loss: 2.0078610628843307

Epoch: 5| Step: 11
Training loss: 1.773561716079712
Validation loss: 2.0087712109088898

Epoch: 94| Step: 0
Training loss: 2.185469627380371
Validation loss: 2.0122477412223816

Epoch: 5| Step: 1
Training loss: 1.829846739768982
Validation loss: 2.0109726786613464

Epoch: 5| Step: 2
Training loss: 2.223618984222412
Validation loss: 2.015291526913643

Epoch: 5| Step: 3
Training loss: 2.1478238105773926
Validation loss: 2.0101035237312317

Epoch: 5| Step: 4
Training loss: 2.0749998092651367
Validation loss: 2.0165564517180123

Epoch: 5| Step: 5
Training loss: 2.0688304901123047
Validation loss: 2.011453236142794

Epoch: 5| Step: 6
Training loss: 2.643385410308838
Validation loss: 2.0226573199033737

Epoch: 5| Step: 7
Training loss: 2.748541831970215
Validation loss: 2.020031342903773

Epoch: 5| Step: 8
Training loss: 2.0838065147399902
Validation loss: 2.0178589473168054

Epoch: 5| Step: 9
Training loss: 1.8542444705963135
Validation loss: 2.0133366833130517

Epoch: 5| Step: 10
Training loss: 1.8492710590362549
Validation loss: 2.0180046459039054

Epoch: 5| Step: 11
Training loss: 0.9609792828559875
Validation loss: 2.016678144534429

Epoch: 95| Step: 0
Training loss: 2.049823522567749
Validation loss: 2.018968164920807

Epoch: 5| Step: 1
Training loss: 2.139296054840088
Validation loss: 2.0218407660722733

Epoch: 5| Step: 2
Training loss: 2.341785430908203
Validation loss: 2.0226184825102487

Epoch: 5| Step: 3
Training loss: 1.815122365951538
Validation loss: 2.0152113934357962

Epoch: 5| Step: 4
Training loss: 2.0466206073760986
Validation loss: 2.0168657253185907

Epoch: 5| Step: 5
Training loss: 2.4269070625305176
Validation loss: 2.0218688944975534

Epoch: 5| Step: 6
Training loss: 1.6894409656524658
Validation loss: 2.0250275482734046

Epoch: 5| Step: 7
Training loss: 2.1436760425567627
Validation loss: 2.0284434407949448

Epoch: 5| Step: 8
Training loss: 2.009115695953369
Validation loss: 2.0248535871505737

Epoch: 5| Step: 9
Training loss: 2.2924671173095703
Validation loss: 2.01988555987676

Epoch: 5| Step: 10
Training loss: 2.1624107360839844
Validation loss: 2.041000301639239

Epoch: 5| Step: 11
Training loss: 3.538087844848633
Validation loss: 2.0250737965106964

Epoch: 96| Step: 0
Training loss: 2.3484387397766113
Validation loss: 2.0229398359855018

Epoch: 5| Step: 1
Training loss: 2.6239051818847656
Validation loss: 2.0283900052309036

Epoch: 5| Step: 2
Training loss: 2.1544137001037598
Validation loss: 2.034234051903089

Epoch: 5| Step: 3
Training loss: 1.901658296585083
Validation loss: 2.0297215382258096

Epoch: 5| Step: 4
Training loss: 2.0410852432250977
Validation loss: 2.025905057787895

Epoch: 5| Step: 5
Training loss: 2.415724515914917
Validation loss: 2.03263229628404

Epoch: 5| Step: 6
Training loss: 1.9307529926300049
Validation loss: 2.0398087153832116

Epoch: 5| Step: 7
Training loss: 2.4984304904937744
Validation loss: 2.039793148636818

Epoch: 5| Step: 8
Training loss: 1.784996747970581
Validation loss: 2.0365308870871863

Epoch: 5| Step: 9
Training loss: 1.9558489322662354
Validation loss: 2.0247203360001245

Epoch: 5| Step: 10
Training loss: 1.830346703529358
Validation loss: 2.024285505215327

Epoch: 5| Step: 11
Training loss: 1.7187049388885498
Validation loss: 2.02537369231383

Epoch: 97| Step: 0
Training loss: 2.0503413677215576
Validation loss: 2.0300658692916236

Epoch: 5| Step: 1
Training loss: 2.0465197563171387
Validation loss: 2.0289701521396637

Epoch: 5| Step: 2
Training loss: 2.3611819744110107
Validation loss: 2.0281638701756797

Epoch: 5| Step: 3
Training loss: 1.4516723155975342
Validation loss: 2.029135455687841

Epoch: 5| Step: 4
Training loss: 2.1690783500671387
Validation loss: 2.0417487770318985

Epoch: 5| Step: 5
Training loss: 2.290177583694458
Validation loss: 2.0408892283837

Epoch: 5| Step: 6
Training loss: 2.213935613632202
Validation loss: 2.0402102569739022

Epoch: 5| Step: 7
Training loss: 2.103785276412964
Validation loss: 2.0469459195931754

Epoch: 5| Step: 8
Training loss: 2.083437204360962
Validation loss: 2.028599282105764

Epoch: 5| Step: 9
Training loss: 2.3282675743103027
Validation loss: 2.033644820253054

Epoch: 5| Step: 10
Training loss: 2.0122954845428467
Validation loss: 2.024385372797648

Epoch: 5| Step: 11
Training loss: 3.684624433517456
Validation loss: 2.0166857490936914

Epoch: 98| Step: 0
Training loss: 1.9792242050170898
Validation loss: 2.01016699274381

Epoch: 5| Step: 1
Training loss: 2.250861644744873
Validation loss: 2.0167774856090546

Epoch: 5| Step: 2
Training loss: 2.180105209350586
Validation loss: 2.022803242007891

Epoch: 5| Step: 3
Training loss: 2.275351047515869
Validation loss: 2.034717708826065

Epoch: 5| Step: 4
Training loss: 1.758474588394165
Validation loss: 2.034092793862025

Epoch: 5| Step: 5
Training loss: 2.4126622676849365
Validation loss: 2.030646542708079

Epoch: 5| Step: 6
Training loss: 2.02327561378479
Validation loss: 2.036271318793297

Epoch: 5| Step: 7
Training loss: 2.8249671459198
Validation loss: 2.040932923555374

Epoch: 5| Step: 8
Training loss: 2.199303150177002
Validation loss: 2.0335925122102103

Epoch: 5| Step: 9
Training loss: 1.8541479110717773
Validation loss: 2.037135417262713

Epoch: 5| Step: 10
Training loss: 2.316453456878662
Validation loss: 2.033218026161194

Epoch: 5| Step: 11
Training loss: 2.138862133026123
Validation loss: 2.0351045429706573

Epoch: 99| Step: 0
Training loss: 1.7677898406982422
Validation loss: 2.0296562810738883

Epoch: 5| Step: 1
Training loss: 2.2878966331481934
Validation loss: 2.026620626449585

Epoch: 5| Step: 2
Training loss: 2.090217113494873
Validation loss: 2.020519961913427

Epoch: 5| Step: 3
Training loss: 2.462191104888916
Validation loss: 2.014891877770424

Epoch: 5| Step: 4
Training loss: 2.344611167907715
Validation loss: 2.0069068471590676

Epoch: 5| Step: 5
Training loss: 2.4730582237243652
Validation loss: 2.009805366396904

Epoch: 5| Step: 6
Training loss: 1.13770592212677
Validation loss: 2.0139318058888116

Epoch: 5| Step: 7
Training loss: 1.7428019046783447
Validation loss: 2.008348450064659

Epoch: 5| Step: 8
Training loss: 2.2408852577209473
Validation loss: 2.0353761315345764

Epoch: 5| Step: 9
Training loss: 2.482172727584839
Validation loss: 2.0404760042826333

Epoch: 5| Step: 10
Training loss: 2.330519914627075
Validation loss: 2.0327342053254447

Epoch: 5| Step: 11
Training loss: 3.1563425064086914
Validation loss: 2.0359931141138077

Epoch: 100| Step: 0
Training loss: 2.1038658618927
Validation loss: 2.0416498382886252

Epoch: 5| Step: 1
Training loss: 2.5370495319366455
Validation loss: 2.0344725449879966

Epoch: 5| Step: 2
Training loss: 1.8855783939361572
Validation loss: 2.018248289823532

Epoch: 5| Step: 3
Training loss: 2.607698917388916
Validation loss: 2.032469948132833

Epoch: 5| Step: 4
Training loss: 2.066887140274048
Validation loss: 2.013525833686193

Epoch: 5| Step: 5
Training loss: 1.9737493991851807
Validation loss: 2.0126634339491525

Epoch: 5| Step: 6
Training loss: 1.568367600440979
Validation loss: 2.009619648257891

Epoch: 5| Step: 7
Training loss: 2.3276314735412598
Validation loss: 2.008472502231598

Epoch: 5| Step: 8
Training loss: 2.088059425354004
Validation loss: 2.009368990858396

Epoch: 5| Step: 9
Training loss: 2.1471481323242188
Validation loss: 2.009005606174469

Epoch: 5| Step: 10
Training loss: 2.358342409133911
Validation loss: 2.0131259163220725

Epoch: 5| Step: 11
Training loss: 1.6713731288909912
Validation loss: 2.0142255971829095

Epoch: 101| Step: 0
Training loss: 2.204045295715332
Validation loss: 2.0133781830469766

Epoch: 5| Step: 1
Training loss: 1.7648128271102905
Validation loss: 2.029111529390017

Epoch: 5| Step: 2
Training loss: 2.182889461517334
Validation loss: 2.0296147565046945

Epoch: 5| Step: 3
Training loss: 1.9691311120986938
Validation loss: 2.042298341790835

Epoch: 5| Step: 4
Training loss: 2.303861141204834
Validation loss: 2.048185889919599

Epoch: 5| Step: 5
Training loss: 2.351808547973633
Validation loss: 2.049867327014605

Epoch: 5| Step: 6
Training loss: 1.633487343788147
Validation loss: 2.0513233145078025

Epoch: 5| Step: 7
Training loss: 2.394777774810791
Validation loss: 2.052322362860044

Epoch: 5| Step: 8
Training loss: 2.279607057571411
Validation loss: 2.043342957894007

Epoch: 5| Step: 9
Training loss: 2.142228603363037
Validation loss: 2.0540768752495446

Epoch: 5| Step: 10
Training loss: 2.241507053375244
Validation loss: 2.047713483373324

Epoch: 5| Step: 11
Training loss: 2.449526309967041
Validation loss: 2.0179405907789865

Epoch: 102| Step: 0
Training loss: 1.9935582876205444
Validation loss: 2.0132689625024796

Epoch: 5| Step: 1
Training loss: 2.752688407897949
Validation loss: 2.0165093888839087

Epoch: 5| Step: 2
Training loss: 2.1126163005828857
Validation loss: 2.013980890313784

Epoch: 5| Step: 3
Training loss: 1.8739277124404907
Validation loss: 2.0129912048578262

Epoch: 5| Step: 4
Training loss: 2.383985757827759
Validation loss: 2.004815379778544

Epoch: 5| Step: 5
Training loss: 2.162832736968994
Validation loss: 2.0004673252503076

Epoch: 5| Step: 6
Training loss: 1.9348220825195312
Validation loss: 2.0105354537566504

Epoch: 5| Step: 7
Training loss: 2.2325310707092285
Validation loss: 2.0020961364110312

Epoch: 5| Step: 8
Training loss: 1.9908727407455444
Validation loss: 2.0076292852560678

Epoch: 5| Step: 9
Training loss: 1.8708311319351196
Validation loss: 2.011312633752823

Epoch: 5| Step: 10
Training loss: 2.077993869781494
Validation loss: 2.02592741449674

Epoch: 5| Step: 11
Training loss: 1.9964035749435425
Validation loss: 2.0273720969756446

Epoch: 103| Step: 0
Training loss: 2.6321911811828613
Validation loss: 2.024947846929232

Epoch: 5| Step: 1
Training loss: 2.00412654876709
Validation loss: 2.027020658055941

Epoch: 5| Step: 2
Training loss: 1.9577792882919312
Validation loss: 2.0224628200133643

Epoch: 5| Step: 3
Training loss: 2.106546640396118
Validation loss: 2.03121609489123

Epoch: 5| Step: 4
Training loss: 1.9823639392852783
Validation loss: 2.0383362472057343

Epoch: 5| Step: 5
Training loss: 2.0249533653259277
Validation loss: 2.0239478399356208

Epoch: 5| Step: 6
Training loss: 2.3457775115966797
Validation loss: 2.031611144542694

Epoch: 5| Step: 7
Training loss: 1.7382036447525024
Validation loss: 2.0362114558617272

Epoch: 5| Step: 8
Training loss: 2.2678380012512207
Validation loss: 2.016384487350782

Epoch: 5| Step: 9
Training loss: 2.3444344997406006
Validation loss: 2.0270865062872567

Epoch: 5| Step: 10
Training loss: 2.0828757286071777
Validation loss: 2.026519497235616

Epoch: 5| Step: 11
Training loss: 0.7545129060745239
Validation loss: 2.016742820541064

Epoch: 104| Step: 0
Training loss: 2.020904302597046
Validation loss: 2.0204435884952545

Epoch: 5| Step: 1
Training loss: 1.8010406494140625
Validation loss: 2.0232985466718674

Epoch: 5| Step: 2
Training loss: 1.7774738073349
Validation loss: 2.03104638059934

Epoch: 5| Step: 3
Training loss: 2.381784439086914
Validation loss: 2.032440116008123

Epoch: 5| Step: 4
Training loss: 2.9532699584960938
Validation loss: 2.0651487906773887

Epoch: 5| Step: 5
Training loss: 1.9797582626342773
Validation loss: 2.070571223894755

Epoch: 5| Step: 6
Training loss: 1.8878631591796875
Validation loss: 2.0596527258555093

Epoch: 5| Step: 7
Training loss: 2.287865161895752
Validation loss: 2.049166892965635

Epoch: 5| Step: 8
Training loss: 2.3121485710144043
Validation loss: 2.0579810490210853

Epoch: 5| Step: 9
Training loss: 2.201969861984253
Validation loss: 2.0363787362972894

Epoch: 5| Step: 10
Training loss: 1.6190831661224365
Validation loss: 2.0463309536377587

Epoch: 5| Step: 11
Training loss: 3.5939059257507324
Validation loss: 2.0244979659716287

Epoch: 105| Step: 0
Training loss: 2.2326502799987793
Validation loss: 2.017843340833982

Epoch: 5| Step: 1
Training loss: 2.4320051670074463
Validation loss: 2.0175315688053765

Epoch: 5| Step: 2
Training loss: 2.568082094192505
Validation loss: 2.0237654646237693

Epoch: 5| Step: 3
Training loss: 2.024717330932617
Validation loss: 2.012522687514623

Epoch: 5| Step: 4
Training loss: 2.1846578121185303
Validation loss: 2.009028270840645

Epoch: 5| Step: 5
Training loss: 1.8679101467132568
Validation loss: 2.0124569833278656

Epoch: 5| Step: 6
Training loss: 2.197050094604492
Validation loss: 2.020400936404864

Epoch: 5| Step: 7
Training loss: 1.8932781219482422
Validation loss: 2.019299348195394

Epoch: 5| Step: 8
Training loss: 1.8675670623779297
Validation loss: 2.0283632228771844

Epoch: 5| Step: 9
Training loss: 2.3942151069641113
Validation loss: 2.0319513281186423

Epoch: 5| Step: 10
Training loss: 1.8737564086914062
Validation loss: 2.04987733066082

Epoch: 5| Step: 11
Training loss: 0.9471415877342224
Validation loss: 2.0319132655858994

Epoch: 106| Step: 0
Training loss: 1.819957971572876
Validation loss: 2.0424237002929053

Epoch: 5| Step: 1
Training loss: 1.5977556705474854
Validation loss: 2.053967759013176

Epoch: 5| Step: 2
Training loss: 2.595583438873291
Validation loss: 2.0768506129582724

Epoch: 5| Step: 3
Training loss: 2.1379876136779785
Validation loss: 2.0767605006694794

Epoch: 5| Step: 4
Training loss: 2.3512773513793945
Validation loss: 2.0827327569325766

Epoch: 5| Step: 5
Training loss: 2.046543836593628
Validation loss: 2.056293547153473

Epoch: 5| Step: 6
Training loss: 2.274900436401367
Validation loss: 2.0445262690385184

Epoch: 5| Step: 7
Training loss: 2.4369964599609375
Validation loss: 2.0308031688133874

Epoch: 5| Step: 8
Training loss: 1.9339320659637451
Validation loss: 2.0247385650873184

Epoch: 5| Step: 9
Training loss: 2.0804901123046875
Validation loss: 2.016234581669172

Epoch: 5| Step: 10
Training loss: 2.3480494022369385
Validation loss: 2.0057943612337112

Epoch: 5| Step: 11
Training loss: 1.4672162532806396
Validation loss: 2.009566376606623

Epoch: 107| Step: 0
Training loss: 1.7664146423339844
Validation loss: 2.018497794866562

Epoch: 5| Step: 1
Training loss: 2.3656749725341797
Validation loss: 2.0153764883677163

Epoch: 5| Step: 2
Training loss: 2.012333393096924
Validation loss: 2.023266469438871

Epoch: 5| Step: 3
Training loss: 2.120723247528076
Validation loss: 2.0216070661942163

Epoch: 5| Step: 4
Training loss: 2.351696014404297
Validation loss: 2.0149575422207513

Epoch: 5| Step: 5
Training loss: 2.261545181274414
Validation loss: 2.0174012929201126

Epoch: 5| Step: 6
Training loss: 2.200125217437744
Validation loss: 2.0146181086699166

Epoch: 5| Step: 7
Training loss: 2.4151949882507324
Validation loss: 2.011624281605085

Epoch: 5| Step: 8
Training loss: 2.4232354164123535
Validation loss: 2.0050829648971558

Epoch: 5| Step: 9
Training loss: 2.2681829929351807
Validation loss: 2.0133841186761856

Epoch: 5| Step: 10
Training loss: 1.6770598888397217
Validation loss: 2.0112160642941794

Epoch: 5| Step: 11
Training loss: 0.550323486328125
Validation loss: 2.015003507335981

Epoch: 108| Step: 0
Training loss: 1.9760059118270874
Validation loss: 2.007875536878904

Epoch: 5| Step: 1
Training loss: 2.39223313331604
Validation loss: 1.9997784545024235

Epoch: 5| Step: 2
Training loss: 1.2851285934448242
Validation loss: 1.9995379348595936

Epoch: 5| Step: 3
Training loss: 2.5186781883239746
Validation loss: 2.010904977718989

Epoch: 5| Step: 4
Training loss: 1.9775464534759521
Validation loss: 2.0082686046759286

Epoch: 5| Step: 5
Training loss: 1.20756995677948
Validation loss: 2.006585791707039

Epoch: 5| Step: 6
Training loss: 1.8364152908325195
Validation loss: 1.998486007253329

Epoch: 5| Step: 7
Training loss: 2.6204631328582764
Validation loss: 2.0053557455539703

Epoch: 5| Step: 8
Training loss: 2.391697645187378
Validation loss: 2.0014065504074097

Epoch: 5| Step: 9
Training loss: 2.510741949081421
Validation loss: 2.0031147996584573

Epoch: 5| Step: 10
Training loss: 2.744950294494629
Validation loss: 2.0052764862775803

Epoch: 5| Step: 11
Training loss: 2.177539348602295
Validation loss: 2.006372963388761

Epoch: 109| Step: 0
Training loss: 1.5350654125213623
Validation loss: 2.0125465591748557

Epoch: 5| Step: 1
Training loss: 1.8655275106430054
Validation loss: 2.0194983134667077

Epoch: 5| Step: 2
Training loss: 2.0234813690185547
Validation loss: 2.0184617936611176

Epoch: 5| Step: 3
Training loss: 2.3197948932647705
Validation loss: 2.0254079600175223

Epoch: 5| Step: 4
Training loss: 1.972342848777771
Validation loss: 2.0306107501188913

Epoch: 5| Step: 5
Training loss: 2.225809097290039
Validation loss: 2.0452557057142258

Epoch: 5| Step: 6
Training loss: 2.3489887714385986
Validation loss: 2.0437239756186805

Epoch: 5| Step: 7
Training loss: 2.4683802127838135
Validation loss: 2.0579331715901694

Epoch: 5| Step: 8
Training loss: 1.8668512105941772
Validation loss: 2.0612156639496484

Epoch: 5| Step: 9
Training loss: 2.396655321121216
Validation loss: 2.068421776096026

Epoch: 5| Step: 10
Training loss: 2.5103631019592285
Validation loss: 2.077800373236338

Epoch: 5| Step: 11
Training loss: 1.353543996810913
Validation loss: 2.056430165966352

Epoch: 110| Step: 0
Training loss: 2.053879499435425
Validation loss: 2.0646755745013556

Epoch: 5| Step: 1
Training loss: 2.187441349029541
Validation loss: 2.075559124350548

Epoch: 5| Step: 2
Training loss: 2.408708333969116
Validation loss: 2.0748636623223624

Epoch: 5| Step: 3
Training loss: 1.916825294494629
Validation loss: 2.064024478197098

Epoch: 5| Step: 4
Training loss: 2.146854877471924
Validation loss: 2.050496722261111

Epoch: 5| Step: 5
Training loss: 2.115964412689209
Validation loss: 2.049564301967621

Epoch: 5| Step: 6
Training loss: 1.993438959121704
Validation loss: 2.0244410584370294

Epoch: 5| Step: 7
Training loss: 2.085000514984131
Validation loss: 2.0314905991156897

Epoch: 5| Step: 8
Training loss: 2.1552603244781494
Validation loss: 2.0158968220154443

Epoch: 5| Step: 9
Training loss: 2.4022202491760254
Validation loss: 2.0231769482294717

Epoch: 5| Step: 10
Training loss: 2.028850793838501
Validation loss: 2.0220245818297067

Epoch: 5| Step: 11
Training loss: 2.1800894737243652
Validation loss: 2.024255027373632

Epoch: 111| Step: 0
Training loss: 2.004751205444336
Validation loss: 2.0468688060839972

Epoch: 5| Step: 1
Training loss: 2.127290725708008
Validation loss: 2.046195834875107

Epoch: 5| Step: 2
Training loss: 2.108689069747925
Validation loss: 2.0625057568152747

Epoch: 5| Step: 3
Training loss: 1.941494345664978
Validation loss: 2.042522226770719

Epoch: 5| Step: 4
Training loss: 2.2258334159851074
Validation loss: 2.053452044725418

Epoch: 5| Step: 5
Training loss: 1.733970284461975
Validation loss: 2.0564473470052085

Epoch: 5| Step: 6
Training loss: 2.2309842109680176
Validation loss: 2.053194999694824

Epoch: 5| Step: 7
Training loss: 2.4146347045898438
Validation loss: 2.041591172417005

Epoch: 5| Step: 8
Training loss: 1.9443527460098267
Validation loss: 2.04818889995416

Epoch: 5| Step: 9
Training loss: 1.9526159763336182
Validation loss: 2.0391863832871118

Epoch: 5| Step: 10
Training loss: 2.2053802013397217
Validation loss: 2.0334211587905884

Epoch: 5| Step: 11
Training loss: 3.637733221054077
Validation loss: 2.034876217444738

Epoch: 112| Step: 0
Training loss: 2.0847716331481934
Validation loss: 2.0289549082517624

Epoch: 5| Step: 1
Training loss: 2.201322317123413
Validation loss: 2.027123361825943

Epoch: 5| Step: 2
Training loss: 1.994803786277771
Validation loss: 2.022032310565313

Epoch: 5| Step: 3
Training loss: 1.7721627950668335
Validation loss: 2.01598813633124

Epoch: 5| Step: 4
Training loss: 1.974203109741211
Validation loss: 2.023034935196241

Epoch: 5| Step: 5
Training loss: 2.589962959289551
Validation loss: 2.0194189995527267

Epoch: 5| Step: 6
Training loss: 2.2494490146636963
Validation loss: 2.017431785662969

Epoch: 5| Step: 7
Training loss: 2.18355131149292
Validation loss: 2.020036300023397

Epoch: 5| Step: 8
Training loss: 1.9811956882476807
Validation loss: 2.009238878885905

Epoch: 5| Step: 9
Training loss: 1.844280481338501
Validation loss: 2.0173080265522003

Epoch: 5| Step: 10
Training loss: 2.376992702484131
Validation loss: 2.0199713557958603

Epoch: 5| Step: 11
Training loss: 1.294440746307373
Validation loss: 2.0343643178542457

Epoch: 113| Step: 0
Training loss: 2.5508151054382324
Validation loss: 2.034877891341845

Epoch: 5| Step: 1
Training loss: 2.0901989936828613
Validation loss: 2.040229176481565

Epoch: 5| Step: 2
Training loss: 2.233010768890381
Validation loss: 2.0382880667845407

Epoch: 5| Step: 3
Training loss: 2.1357758045196533
Validation loss: 2.0404962251583734

Epoch: 5| Step: 4
Training loss: 1.6750190258026123
Validation loss: 2.046626831094424

Epoch: 5| Step: 5
Training loss: 1.4249387979507446
Validation loss: 2.0397344877322516

Epoch: 5| Step: 6
Training loss: 1.953304648399353
Validation loss: 2.043231954177221

Epoch: 5| Step: 7
Training loss: 2.0498764514923096
Validation loss: 2.0459236850341163

Epoch: 5| Step: 8
Training loss: 2.8498194217681885
Validation loss: 2.0553048998117447

Epoch: 5| Step: 9
Training loss: 1.8487720489501953
Validation loss: 2.0478524367014566

Epoch: 5| Step: 10
Training loss: 2.088327169418335
Validation loss: 2.0375846872727075

Epoch: 5| Step: 11
Training loss: 3.1425158977508545
Validation loss: 2.0237638602654138

Epoch: 114| Step: 0
Training loss: 1.9673659801483154
Validation loss: 2.024281765023867

Epoch: 5| Step: 1
Training loss: 2.303445816040039
Validation loss: 2.0197590639193854

Epoch: 5| Step: 2
Training loss: 2.364957332611084
Validation loss: 2.0108189235130944

Epoch: 5| Step: 3
Training loss: 1.9594976902008057
Validation loss: 2.001693512002627

Epoch: 5| Step: 4
Training loss: 1.9368845224380493
Validation loss: 1.998340090115865

Epoch: 5| Step: 5
Training loss: 2.1030068397521973
Validation loss: 2.009242907166481

Epoch: 5| Step: 6
Training loss: 1.6932897567749023
Validation loss: 2.008030593395233

Epoch: 5| Step: 7
Training loss: 2.330674648284912
Validation loss: 2.010948414603869

Epoch: 5| Step: 8
Training loss: 2.1291465759277344
Validation loss: 2.0083337326844535

Epoch: 5| Step: 9
Training loss: 2.1750271320343018
Validation loss: 2.020550414919853

Epoch: 5| Step: 10
Training loss: 2.150444746017456
Validation loss: 2.0336487094561257

Epoch: 5| Step: 11
Training loss: 2.014285087585449
Validation loss: 2.045346145828565

Epoch: 115| Step: 0
Training loss: 1.5703685283660889
Validation loss: 2.0452531029780707

Epoch: 5| Step: 1
Training loss: 2.2022056579589844
Validation loss: 2.048823987444242

Epoch: 5| Step: 2
Training loss: 2.3370351791381836
Validation loss: 2.0561299920082092

Epoch: 5| Step: 3
Training loss: 2.1635146141052246
Validation loss: 2.0452875743309655

Epoch: 5| Step: 4
Training loss: 2.184455394744873
Validation loss: 2.0533406486113868

Epoch: 5| Step: 5
Training loss: 2.3057565689086914
Validation loss: 2.047568882505099

Epoch: 5| Step: 6
Training loss: 1.8673546314239502
Validation loss: 2.05240506430467

Epoch: 5| Step: 7
Training loss: 2.2986042499542236
Validation loss: 2.0428840021292367

Epoch: 5| Step: 8
Training loss: 1.7038596868515015
Validation loss: 2.032248397668203

Epoch: 5| Step: 9
Training loss: 2.319983959197998
Validation loss: 2.0305691361427307

Epoch: 5| Step: 10
Training loss: 2.179534673690796
Validation loss: 2.018523375193278

Epoch: 5| Step: 11
Training loss: 1.9038841724395752
Validation loss: 2.0210830867290497

Epoch: 116| Step: 0
Training loss: 1.570570945739746
Validation loss: 2.022740696867307

Epoch: 5| Step: 1
Training loss: 1.8192195892333984
Validation loss: 2.017261882623037

Epoch: 5| Step: 2
Training loss: 2.4805822372436523
Validation loss: 2.015045394500097

Epoch: 5| Step: 3
Training loss: 2.0850963592529297
Validation loss: 2.0107078005870185

Epoch: 5| Step: 4
Training loss: 2.0714566707611084
Validation loss: 2.014254485567411

Epoch: 5| Step: 5
Training loss: 2.4277138710021973
Validation loss: 2.010609820485115

Epoch: 5| Step: 6
Training loss: 1.94672429561615
Validation loss: 2.022603655854861

Epoch: 5| Step: 7
Training loss: 2.293090343475342
Validation loss: 2.0213706443707147

Epoch: 5| Step: 8
Training loss: 2.2665207386016846
Validation loss: 2.0157258113225303

Epoch: 5| Step: 9
Training loss: 2.5645313262939453
Validation loss: 2.0123822589715323

Epoch: 5| Step: 10
Training loss: 1.8016630411148071
Validation loss: 2.0260753134886422

Epoch: 5| Step: 11
Training loss: 1.620330572128296
Validation loss: 2.0287346839904785

Epoch: 117| Step: 0
Training loss: 1.726196527481079
Validation loss: 2.0333605259656906

Epoch: 5| Step: 1
Training loss: 2.3658931255340576
Validation loss: 2.0347126026948295

Epoch: 5| Step: 2
Training loss: 2.0644168853759766
Validation loss: 2.039870540301005

Epoch: 5| Step: 3
Training loss: 1.8835872411727905
Validation loss: 2.0616044799486795

Epoch: 5| Step: 4
Training loss: 1.9921420812606812
Validation loss: 2.070954978466034

Epoch: 5| Step: 5
Training loss: 2.3371145725250244
Validation loss: 2.0687522689501443

Epoch: 5| Step: 6
Training loss: 1.6607506275177002
Validation loss: 2.0594229698181152

Epoch: 5| Step: 7
Training loss: 2.329636335372925
Validation loss: 2.054923728108406

Epoch: 5| Step: 8
Training loss: 2.023164749145508
Validation loss: 2.0536025315523148

Epoch: 5| Step: 9
Training loss: 2.1035258769989014
Validation loss: 2.0323002288738885

Epoch: 5| Step: 10
Training loss: 2.491128921508789
Validation loss: 2.030829682946205

Epoch: 5| Step: 11
Training loss: 2.3177261352539062
Validation loss: 2.034066826105118

Epoch: 118| Step: 0
Training loss: 1.8040876388549805
Validation loss: 2.0284760147333145

Epoch: 5| Step: 1
Training loss: 2.028641700744629
Validation loss: 2.0283976395924888

Epoch: 5| Step: 2
Training loss: 2.2989501953125
Validation loss: 2.028556520740191

Epoch: 5| Step: 3
Training loss: 2.0029385089874268
Validation loss: 2.0192213157812753

Epoch: 5| Step: 4
Training loss: 1.9700263738632202
Validation loss: 2.0353068013985953

Epoch: 5| Step: 5
Training loss: 2.0883607864379883
Validation loss: 2.0270919601122537

Epoch: 5| Step: 6
Training loss: 1.969460129737854
Validation loss: 2.021412501732508

Epoch: 5| Step: 7
Training loss: 2.403844118118286
Validation loss: 2.0163043638070426

Epoch: 5| Step: 8
Training loss: 1.7345190048217773
Validation loss: 2.023825854063034

Epoch: 5| Step: 9
Training loss: 1.830287218093872
Validation loss: 2.0143919388453164

Epoch: 5| Step: 10
Training loss: 2.605257749557495
Validation loss: 2.0279896010955176

Epoch: 5| Step: 11
Training loss: 2.710752487182617
Validation loss: 2.0427913516759872

Epoch: 119| Step: 0
Training loss: 2.202545166015625
Validation loss: 2.0325513233741126

Epoch: 5| Step: 1
Training loss: 2.2373359203338623
Validation loss: 2.0519264390071235

Epoch: 5| Step: 2
Training loss: 2.3295326232910156
Validation loss: 2.067268600066503

Epoch: 5| Step: 3
Training loss: 2.0175747871398926
Validation loss: 2.0530149042606354

Epoch: 5| Step: 4
Training loss: 1.6447175741195679
Validation loss: 2.0715723037719727

Epoch: 5| Step: 5
Training loss: 1.9275503158569336
Validation loss: 2.0569957941770554

Epoch: 5| Step: 6
Training loss: 2.5174412727355957
Validation loss: 2.0517139732837677

Epoch: 5| Step: 7
Training loss: 2.052138566970825
Validation loss: 2.048896079262098

Epoch: 5| Step: 8
Training loss: 2.0873169898986816
Validation loss: 2.0461693604787192

Epoch: 5| Step: 9
Training loss: 1.8499618768692017
Validation loss: 2.039593900243441

Epoch: 5| Step: 10
Training loss: 2.065891742706299
Validation loss: 2.0269623696804047

Epoch: 5| Step: 11
Training loss: 2.143937349319458
Validation loss: 2.022474298874537

Epoch: 120| Step: 0
Training loss: 1.8984794616699219
Validation loss: 2.020920222004255

Epoch: 5| Step: 1
Training loss: 2.135688304901123
Validation loss: 2.019783228635788

Epoch: 5| Step: 2
Training loss: 1.7240749597549438
Validation loss: 2.014972671866417

Epoch: 5| Step: 3
Training loss: 1.9925991296768188
Validation loss: 2.022272596756617

Epoch: 5| Step: 4
Training loss: 1.6681859493255615
Validation loss: 2.017599791288376

Epoch: 5| Step: 5
Training loss: 1.869736909866333
Validation loss: 2.0211954365173974

Epoch: 5| Step: 6
Training loss: 1.8817799091339111
Validation loss: 2.019256427884102

Epoch: 5| Step: 7
Training loss: 2.791964054107666
Validation loss: 2.023776392141978

Epoch: 5| Step: 8
Training loss: 2.474794864654541
Validation loss: 2.037915820876757

Epoch: 5| Step: 9
Training loss: 1.9284130334854126
Validation loss: 2.0417426178852716

Epoch: 5| Step: 10
Training loss: 2.2377095222473145
Validation loss: 2.0456198354562125

Epoch: 5| Step: 11
Training loss: 3.844979763031006
Validation loss: 2.048726131518682

Epoch: 121| Step: 0
Training loss: 2.1907708644866943
Validation loss: 2.0596000452836356

Epoch: 5| Step: 1
Training loss: 2.2241263389587402
Validation loss: 2.062560419241587

Epoch: 5| Step: 2
Training loss: 1.6289573907852173
Validation loss: 2.059190725286802

Epoch: 5| Step: 3
Training loss: 1.9524192810058594
Validation loss: 2.0545659313599267

Epoch: 5| Step: 4
Training loss: 1.5334194898605347
Validation loss: 2.060617431998253

Epoch: 5| Step: 5
Training loss: 2.4890618324279785
Validation loss: 2.0482310553391776

Epoch: 5| Step: 6
Training loss: 1.8431358337402344
Validation loss: 2.041872506340345

Epoch: 5| Step: 7
Training loss: 2.605834722518921
Validation loss: 2.041119193037351

Epoch: 5| Step: 8
Training loss: 2.129845380783081
Validation loss: 2.039594367146492

Epoch: 5| Step: 9
Training loss: 2.160071849822998
Validation loss: 2.02636610964934

Epoch: 5| Step: 10
Training loss: 2.184990644454956
Validation loss: 2.026355748375257

Epoch: 5| Step: 11
Training loss: 1.6353286504745483
Validation loss: 2.011341323455175

Epoch: 122| Step: 0
Training loss: 2.001225709915161
Validation loss: 2.024952327211698

Epoch: 5| Step: 1
Training loss: 2.1863017082214355
Validation loss: 2.043090229233106

Epoch: 5| Step: 2
Training loss: 2.3023574352264404
Validation loss: 2.0483189622561135

Epoch: 5| Step: 3
Training loss: 1.8550468683242798
Validation loss: 2.0432826628287635

Epoch: 5| Step: 4
Training loss: 2.1624622344970703
Validation loss: 2.057313988606135

Epoch: 5| Step: 5
Training loss: 1.2954928874969482
Validation loss: 2.048475667834282

Epoch: 5| Step: 6
Training loss: 2.347567081451416
Validation loss: 2.0519700894753137

Epoch: 5| Step: 7
Training loss: 2.307345390319824
Validation loss: 2.066884994506836

Epoch: 5| Step: 8
Training loss: 1.9973595142364502
Validation loss: 2.064090629418691

Epoch: 5| Step: 9
Training loss: 2.204385280609131
Validation loss: 2.057492181658745

Epoch: 5| Step: 10
Training loss: 2.386340618133545
Validation loss: 2.054862300554911

Epoch: 5| Step: 11
Training loss: 1.3347337245941162
Validation loss: 2.0412157277266183

Epoch: 123| Step: 0
Training loss: 2.2275660037994385
Validation loss: 2.0388811926047006

Epoch: 5| Step: 1
Training loss: 2.0517287254333496
Validation loss: 2.0432357788085938

Epoch: 5| Step: 2
Training loss: 1.781084418296814
Validation loss: 2.0437202403942742

Epoch: 5| Step: 3
Training loss: 1.754339575767517
Validation loss: 2.041501839955648

Epoch: 5| Step: 4
Training loss: 2.215214252471924
Validation loss: 2.0444020529588065

Epoch: 5| Step: 5
Training loss: 2.2726001739501953
Validation loss: 2.0477358301480613

Epoch: 5| Step: 6
Training loss: 1.3862121105194092
Validation loss: 2.0545478761196136

Epoch: 5| Step: 7
Training loss: 2.5849175453186035
Validation loss: 2.0533929814894996

Epoch: 5| Step: 8
Training loss: 1.9149373769760132
Validation loss: 2.0354410161574683

Epoch: 5| Step: 9
Training loss: 2.3617191314697266
Validation loss: 2.0353347758452096

Epoch: 5| Step: 10
Training loss: 2.160116672515869
Validation loss: 2.0251326113939285

Epoch: 5| Step: 11
Training loss: 2.7237281799316406
Validation loss: 2.0295592149098716

Epoch: 124| Step: 0
Training loss: 2.7357685565948486
Validation loss: 2.022634426752726

Epoch: 5| Step: 1
Training loss: 1.9020694494247437
Validation loss: 2.029138912757238

Epoch: 5| Step: 2
Training loss: 2.3915882110595703
Validation loss: 2.0327765494585037

Epoch: 5| Step: 3
Training loss: 2.3921561241149902
Validation loss: 2.031686787803968

Epoch: 5| Step: 4
Training loss: 1.8935282230377197
Validation loss: 2.0342004597187042

Epoch: 5| Step: 5
Training loss: 1.9022226333618164
Validation loss: 2.032191962003708

Epoch: 5| Step: 6
Training loss: 1.678765058517456
Validation loss: 2.0280334850152335

Epoch: 5| Step: 7
Training loss: 2.2525980472564697
Validation loss: 2.0371632277965546

Epoch: 5| Step: 8
Training loss: 2.296900987625122
Validation loss: 2.04110749065876

Epoch: 5| Step: 9
Training loss: 1.7187303304672241
Validation loss: 2.041942209005356

Epoch: 5| Step: 10
Training loss: 1.819522500038147
Validation loss: 2.0537966142098107

Epoch: 5| Step: 11
Training loss: 1.464658260345459
Validation loss: 2.064817120631536

Epoch: 125| Step: 0
Training loss: 1.4406001567840576
Validation loss: 2.0525545279184976

Epoch: 5| Step: 1
Training loss: 2.089338779449463
Validation loss: 2.053032631675402

Epoch: 5| Step: 2
Training loss: 1.8208986520767212
Validation loss: 2.046555072069168

Epoch: 5| Step: 3
Training loss: 2.1141273975372314
Validation loss: 2.049210478862127

Epoch: 5| Step: 4
Training loss: 2.282625675201416
Validation loss: 2.0327508648236594

Epoch: 5| Step: 5
Training loss: 2.3595261573791504
Validation loss: 2.0339493403832116

Epoch: 5| Step: 6
Training loss: 2.6579995155334473
Validation loss: 2.0245755463838577

Epoch: 5| Step: 7
Training loss: 2.4361605644226074
Validation loss: 2.0212235947450004

Epoch: 5| Step: 8
Training loss: 1.7372783422470093
Validation loss: 2.0395244856675467

Epoch: 5| Step: 9
Training loss: 1.9346387386322021
Validation loss: 2.03167853752772

Epoch: 5| Step: 10
Training loss: 1.8488099575042725
Validation loss: 2.0426753411690393

Epoch: 5| Step: 11
Training loss: 2.9962801933288574
Validation loss: 2.032067303856214

Epoch: 126| Step: 0
Training loss: 1.7395683526992798
Validation loss: 2.0548727214336395

Epoch: 5| Step: 1
Training loss: 2.244128465652466
Validation loss: 2.0637405117352805

Epoch: 5| Step: 2
Training loss: 2.0609636306762695
Validation loss: 2.053295145432154

Epoch: 5| Step: 3
Training loss: 1.876264214515686
Validation loss: 2.0741596470276513

Epoch: 5| Step: 4
Training loss: 2.1802151203155518
Validation loss: 2.0662347127993903

Epoch: 5| Step: 5
Training loss: 2.3854928016662598
Validation loss: 2.0685381094614663

Epoch: 5| Step: 6
Training loss: 2.3890175819396973
Validation loss: 2.073210045695305

Epoch: 5| Step: 7
Training loss: 1.92282235622406
Validation loss: 2.072694346308708

Epoch: 5| Step: 8
Training loss: 2.148496627807617
Validation loss: 2.070502276221911

Epoch: 5| Step: 9
Training loss: 2.04433012008667
Validation loss: 2.0734990437825522

Epoch: 5| Step: 10
Training loss: 1.9276167154312134
Validation loss: 2.0827722499767938

Epoch: 5| Step: 11
Training loss: 0.7897142767906189
Validation loss: 2.078582674264908

Epoch: 127| Step: 0
Training loss: 2.255666732788086
Validation loss: 2.0754477232694626

Epoch: 5| Step: 1
Training loss: 2.212376117706299
Validation loss: 2.0609254837036133

Epoch: 5| Step: 2
Training loss: 2.437580108642578
Validation loss: 2.0672181447347007

Epoch: 5| Step: 3
Training loss: 2.1211488246917725
Validation loss: 2.05426595111688

Epoch: 5| Step: 4
Training loss: 2.2688159942626953
Validation loss: 2.0511982838312783

Epoch: 5| Step: 5
Training loss: 2.420578718185425
Validation loss: 2.0406131595373154

Epoch: 5| Step: 6
Training loss: 1.9932647943496704
Validation loss: 2.0330930650234222

Epoch: 5| Step: 7
Training loss: 1.9005504846572876
Validation loss: 2.0227229644854865

Epoch: 5| Step: 8
Training loss: 2.4109745025634766
Validation loss: 2.022412955760956

Epoch: 5| Step: 9
Training loss: 1.707531213760376
Validation loss: 2.034072866042455

Epoch: 5| Step: 10
Training loss: 2.032750129699707
Validation loss: 2.029123976826668

Epoch: 5| Step: 11
Training loss: 1.3540571928024292
Validation loss: 2.0374668141206107

Epoch: 128| Step: 0
Training loss: 2.078179121017456
Validation loss: 2.032471686601639

Epoch: 5| Step: 1
Training loss: 2.5111923217773438
Validation loss: 2.032864729563395

Epoch: 5| Step: 2
Training loss: 2.4379794597625732
Validation loss: 2.0310468673706055

Epoch: 5| Step: 3
Training loss: 1.7915818691253662
Validation loss: 2.032212972640991

Epoch: 5| Step: 4
Training loss: 1.886547327041626
Validation loss: 2.023604522148768

Epoch: 5| Step: 5
Training loss: 1.8595291376113892
Validation loss: 2.0188315957784653

Epoch: 5| Step: 6
Training loss: 1.537595272064209
Validation loss: 2.033699298898379

Epoch: 5| Step: 7
Training loss: 1.9003044366836548
Validation loss: 2.026201978325844

Epoch: 5| Step: 8
Training loss: 1.9150583744049072
Validation loss: 2.0352528194586434

Epoch: 5| Step: 9
Training loss: 2.3562541007995605
Validation loss: 2.0311145583788552

Epoch: 5| Step: 10
Training loss: 2.70937180519104
Validation loss: 2.0447319944699607

Epoch: 5| Step: 11
Training loss: 2.981997489929199
Validation loss: 2.047075942158699

Epoch: 129| Step: 0
Training loss: 2.4445300102233887
Validation loss: 2.048234244187673

Epoch: 5| Step: 1
Training loss: 2.57732892036438
Validation loss: 2.0481568574905396

Epoch: 5| Step: 2
Training loss: 2.114704132080078
Validation loss: 2.04562276105086

Epoch: 5| Step: 3
Training loss: 1.9440298080444336
Validation loss: 2.0393445640802383

Epoch: 5| Step: 4
Training loss: 2.2436556816101074
Validation loss: 2.05195422967275

Epoch: 5| Step: 5
Training loss: 2.3504037857055664
Validation loss: 2.0462444772322974

Epoch: 5| Step: 6
Training loss: 2.0576586723327637
Validation loss: 2.05788325270017

Epoch: 5| Step: 7
Training loss: 2.226478099822998
Validation loss: 2.0641372303167977

Epoch: 5| Step: 8
Training loss: 1.6219059228897095
Validation loss: 2.0371744483709335

Epoch: 5| Step: 9
Training loss: 1.8983598947525024
Validation loss: 2.022419512271881

Epoch: 5| Step: 10
Training loss: 1.560651183128357
Validation loss: 2.0187688221534095

Epoch: 5| Step: 11
Training loss: 0.9731606245040894
Validation loss: 2.021929000814756

Epoch: 130| Step: 0
Training loss: 2.0213418006896973
Validation loss: 2.0244584331909814

Epoch: 5| Step: 1
Training loss: 1.828490972518921
Validation loss: 2.019597659508387

Epoch: 5| Step: 2
Training loss: 2.2275867462158203
Validation loss: 2.0283824602762857

Epoch: 5| Step: 3
Training loss: 2.4790825843811035
Validation loss: 2.0318652937809625

Epoch: 5| Step: 4
Training loss: 2.0586884021759033
Validation loss: 2.0302387277285256

Epoch: 5| Step: 5
Training loss: 2.2201669216156006
Validation loss: 2.038276751836141

Epoch: 5| Step: 6
Training loss: 1.9542192220687866
Validation loss: 2.0320894171794257

Epoch: 5| Step: 7
Training loss: 1.5900523662567139
Validation loss: 2.0363932698965073

Epoch: 5| Step: 8
Training loss: 2.073967456817627
Validation loss: 2.046732410788536

Epoch: 5| Step: 9
Training loss: 2.2925374507904053
Validation loss: 2.0517951995134354

Epoch: 5| Step: 10
Training loss: 1.871363639831543
Validation loss: 2.0521764556566873

Epoch: 5| Step: 11
Training loss: 2.0173418521881104
Validation loss: 2.059810663263003

Epoch: 131| Step: 0
Training loss: 2.1519086360931396
Validation loss: 2.069970205426216

Epoch: 5| Step: 1
Training loss: 1.850807547569275
Validation loss: 2.0767073978980384

Epoch: 5| Step: 2
Training loss: 1.7422298192977905
Validation loss: 2.062991514801979

Epoch: 5| Step: 3
Training loss: 1.7349869012832642
Validation loss: 2.0787554383277893

Epoch: 5| Step: 4
Training loss: 2.008641481399536
Validation loss: 2.067243034640948

Epoch: 5| Step: 5
Training loss: 2.642707586288452
Validation loss: 2.0731036414702735

Epoch: 5| Step: 6
Training loss: 2.1281869411468506
Validation loss: 2.081410219271978

Epoch: 5| Step: 7
Training loss: 2.122065544128418
Validation loss: 2.0881661027669907

Epoch: 5| Step: 8
Training loss: 2.5668578147888184
Validation loss: 2.0984163532654443

Epoch: 5| Step: 9
Training loss: 1.617455244064331
Validation loss: 2.077566221356392

Epoch: 5| Step: 10
Training loss: 1.942710518836975
Validation loss: 2.0784204651912055

Epoch: 5| Step: 11
Training loss: 3.2665982246398926
Validation loss: 2.0790190945068994

Epoch: 132| Step: 0
Training loss: 2.56535267829895
Validation loss: 2.0624938110510507

Epoch: 5| Step: 1
Training loss: 2.057215690612793
Validation loss: 2.045414666334788

Epoch: 5| Step: 2
Training loss: 1.8691046237945557
Validation loss: 2.033021628856659

Epoch: 5| Step: 3
Training loss: 2.152924060821533
Validation loss: 2.0272682507832847

Epoch: 5| Step: 4
Training loss: 1.7640243768692017
Validation loss: 2.0333265711863837

Epoch: 5| Step: 5
Training loss: 2.0713493824005127
Validation loss: 2.0380174269278846

Epoch: 5| Step: 6
Training loss: 2.45686674118042
Validation loss: 2.0333376973867416

Epoch: 5| Step: 7
Training loss: 2.4643261432647705
Validation loss: 2.0268267393112183

Epoch: 5| Step: 8
Training loss: 2.258172035217285
Validation loss: 2.0313221464554467

Epoch: 5| Step: 9
Training loss: 1.8554394245147705
Validation loss: 2.023512125015259

Epoch: 5| Step: 10
Training loss: 1.5639111995697021
Validation loss: 2.037301907936732

Epoch: 5| Step: 11
Training loss: 2.1284914016723633
Validation loss: 2.0417908678452172

Epoch: 133| Step: 0
Training loss: 1.842879056930542
Validation loss: 2.052698642015457

Epoch: 5| Step: 1
Training loss: 2.1649415493011475
Validation loss: 2.0666072567303977

Epoch: 5| Step: 2
Training loss: 1.948728322982788
Validation loss: 2.0890166014432907

Epoch: 5| Step: 3
Training loss: 2.141937732696533
Validation loss: 2.087711120645205

Epoch: 5| Step: 4
Training loss: 2.1594855785369873
Validation loss: 2.1010701407988868

Epoch: 5| Step: 5
Training loss: 1.9911502599716187
Validation loss: 2.098072980841001

Epoch: 5| Step: 6
Training loss: 2.4490585327148438
Validation loss: 2.108055373032888

Epoch: 5| Step: 7
Training loss: 1.911218285560608
Validation loss: 2.0855063448349633

Epoch: 5| Step: 8
Training loss: 2.063304901123047
Validation loss: 2.0954383412996926

Epoch: 5| Step: 9
Training loss: 1.904214859008789
Validation loss: 2.096743772427241

Epoch: 5| Step: 10
Training loss: 1.951581597328186
Validation loss: 2.0989421705404916

Epoch: 5| Step: 11
Training loss: 2.8799829483032227
Validation loss: 2.0824301540851593

Epoch: 134| Step: 0
Training loss: 2.1057677268981934
Validation loss: 2.059154654542605

Epoch: 5| Step: 1
Training loss: 2.0419511795043945
Validation loss: 2.038458521167437

Epoch: 5| Step: 2
Training loss: 2.3370087146759033
Validation loss: 2.0337665726741156

Epoch: 5| Step: 3
Training loss: 1.9488471746444702
Validation loss: 2.038118988275528

Epoch: 5| Step: 4
Training loss: 2.5353803634643555
Validation loss: 2.0429751624663672

Epoch: 5| Step: 5
Training loss: 2.082040309906006
Validation loss: 2.042228569587072

Epoch: 5| Step: 6
Training loss: 1.6723337173461914
Validation loss: 2.0482091903686523

Epoch: 5| Step: 7
Training loss: 2.4191792011260986
Validation loss: 2.0478311826785407

Epoch: 5| Step: 8
Training loss: 1.804088830947876
Validation loss: 2.038729598124822

Epoch: 5| Step: 9
Training loss: 2.0204033851623535
Validation loss: 2.0429563572009406

Epoch: 5| Step: 10
Training loss: 1.9724833965301514
Validation loss: 2.033564512928327

Epoch: 5| Step: 11
Training loss: 2.609015941619873
Validation loss: 2.0411093483368554

Epoch: 135| Step: 0
Training loss: 2.5142650604248047
Validation loss: 2.035560518503189

Epoch: 5| Step: 1
Training loss: 1.5519864559173584
Validation loss: 2.0423070987065635

Epoch: 5| Step: 2
Training loss: 2.177748918533325
Validation loss: 2.0414838592211404

Epoch: 5| Step: 3
Training loss: 2.1473963260650635
Validation loss: 2.042720486720403

Epoch: 5| Step: 4
Training loss: 1.9502102136611938
Validation loss: 2.047357047597567

Epoch: 5| Step: 5
Training loss: 1.9962942600250244
Validation loss: 2.0419646352529526

Epoch: 5| Step: 6
Training loss: 1.6167837381362915
Validation loss: 2.0469078620274863

Epoch: 5| Step: 7
Training loss: 2.5431981086730957
Validation loss: 2.054665078719457

Epoch: 5| Step: 8
Training loss: 1.4272844791412354
Validation loss: 2.0596854388713837

Epoch: 5| Step: 9
Training loss: 2.5002379417419434
Validation loss: 2.0734817534685135

Epoch: 5| Step: 10
Training loss: 2.2573935985565186
Validation loss: 2.0543812115987143

Epoch: 5| Step: 11
Training loss: 2.887664794921875
Validation loss: 2.063910409808159

Epoch: 136| Step: 0
Training loss: 1.9210811853408813
Validation loss: 2.0589184562365213

Epoch: 5| Step: 1
Training loss: 2.024592876434326
Validation loss: 2.0800535480181375

Epoch: 5| Step: 2
Training loss: 2.009697437286377
Validation loss: 2.0599088072776794

Epoch: 5| Step: 3
Training loss: 2.0886027812957764
Validation loss: 2.0642252465089164

Epoch: 5| Step: 4
Training loss: 1.9914817810058594
Validation loss: 2.0458694398403168

Epoch: 5| Step: 5
Training loss: 1.9272029399871826
Validation loss: 2.0571791976690292

Epoch: 5| Step: 6
Training loss: 2.416609287261963
Validation loss: 2.0445370376110077

Epoch: 5| Step: 7
Training loss: 2.498523712158203
Validation loss: 2.033354232708613

Epoch: 5| Step: 8
Training loss: 1.798730492591858
Validation loss: 2.034510930379232

Epoch: 5| Step: 9
Training loss: 1.9215425252914429
Validation loss: 2.041005089879036

Epoch: 5| Step: 10
Training loss: 2.1134092807769775
Validation loss: 2.043066293001175

Epoch: 5| Step: 11
Training loss: 2.543560266494751
Validation loss: 2.0403555830319724

Epoch: 137| Step: 0
Training loss: 2.010422706604004
Validation loss: 2.066049431761106

Epoch: 5| Step: 1
Training loss: 2.7036452293395996
Validation loss: 2.070482904712359

Epoch: 5| Step: 2
Training loss: 2.2603325843811035
Validation loss: 2.095721662044525

Epoch: 5| Step: 3
Training loss: 1.8868296146392822
Validation loss: 2.0854083796342215

Epoch: 5| Step: 4
Training loss: 1.4173046350479126
Validation loss: 2.0799145003159842

Epoch: 5| Step: 5
Training loss: 2.0735602378845215
Validation loss: 2.0793265451987586

Epoch: 5| Step: 6
Training loss: 2.167634963989258
Validation loss: 2.0724453230698905

Epoch: 5| Step: 7
Training loss: 2.3741977214813232
Validation loss: 2.0790834426879883

Epoch: 5| Step: 8
Training loss: 2.100567579269409
Validation loss: 2.066566010316213

Epoch: 5| Step: 9
Training loss: 1.6652355194091797
Validation loss: 2.0661048541466394

Epoch: 5| Step: 10
Training loss: 2.0453007221221924
Validation loss: 2.0619283070166907

Epoch: 5| Step: 11
Training loss: 2.342794895172119
Validation loss: 2.0711900293827057

Epoch: 138| Step: 0
Training loss: 2.131253719329834
Validation loss: 2.0501465102036796

Epoch: 5| Step: 1
Training loss: 1.9992574453353882
Validation loss: 2.0492344051599503

Epoch: 5| Step: 2
Training loss: 2.3166213035583496
Validation loss: 2.0421205262343087

Epoch: 5| Step: 3
Training loss: 1.8337745666503906
Validation loss: 2.0459813276926675

Epoch: 5| Step: 4
Training loss: 1.964855432510376
Validation loss: 2.032637814680735

Epoch: 5| Step: 5
Training loss: 2.213073492050171
Validation loss: 2.039931779106458

Epoch: 5| Step: 6
Training loss: 1.8605480194091797
Validation loss: 2.0420207182566323

Epoch: 5| Step: 7
Training loss: 1.8661998510360718
Validation loss: 2.0404510498046875

Epoch: 5| Step: 8
Training loss: 3.106999635696411
Validation loss: 2.0472259173790612

Epoch: 5| Step: 9
Training loss: 1.1985018253326416
Validation loss: 2.045905048648516

Epoch: 5| Step: 10
Training loss: 2.107325315475464
Validation loss: 2.048251524567604

Epoch: 5| Step: 11
Training loss: 2.0130765438079834
Validation loss: 2.052862291534742

Epoch: 139| Step: 0
Training loss: 2.320152759552002
Validation loss: 2.0638115108013153

Epoch: 5| Step: 1
Training loss: 1.4705064296722412
Validation loss: 2.0655071834723153

Epoch: 5| Step: 2
Training loss: 2.3359735012054443
Validation loss: 2.0744852423667908

Epoch: 5| Step: 3
Training loss: 2.1631369590759277
Validation loss: 2.0540129790703454

Epoch: 5| Step: 4
Training loss: 1.7690629959106445
Validation loss: 2.076224133372307

Epoch: 5| Step: 5
Training loss: 2.025568962097168
Validation loss: 2.0586085319519043

Epoch: 5| Step: 6
Training loss: 1.6567577123641968
Validation loss: 2.0665592551231384

Epoch: 5| Step: 7
Training loss: 1.9822410345077515
Validation loss: 2.065861756602923

Epoch: 5| Step: 8
Training loss: 1.9921795129776
Validation loss: 2.064333160718282

Epoch: 5| Step: 9
Training loss: 2.004176616668701
Validation loss: 2.0704899231592813

Epoch: 5| Step: 10
Training loss: 2.412956714630127
Validation loss: 2.067075952887535

Epoch: 5| Step: 11
Training loss: 3.5716896057128906
Validation loss: 2.0668256928523383

Epoch: 140| Step: 0
Training loss: 2.0935354232788086
Validation loss: 2.0691774487495422

Epoch: 5| Step: 1
Training loss: 1.8236182928085327
Validation loss: 2.0656368682781854

Epoch: 5| Step: 2
Training loss: 1.9863779544830322
Validation loss: 2.0513353496789932

Epoch: 5| Step: 3
Training loss: 1.9678466320037842
Validation loss: 2.056128521760305

Epoch: 5| Step: 4
Training loss: 1.7547422647476196
Validation loss: 2.0509616484244666

Epoch: 5| Step: 5
Training loss: 2.547799825668335
Validation loss: 2.066754882534345

Epoch: 5| Step: 6
Training loss: 1.9182872772216797
Validation loss: 2.0504709283510842

Epoch: 5| Step: 7
Training loss: 1.7400976419448853
Validation loss: 2.05739297469457

Epoch: 5| Step: 8
Training loss: 2.183204174041748
Validation loss: 2.042796562115351

Epoch: 5| Step: 9
Training loss: 2.449901580810547
Validation loss: 2.0499321073293686

Epoch: 5| Step: 10
Training loss: 2.0806162357330322
Validation loss: 2.058814456065496

Epoch: 5| Step: 11
Training loss: 1.1335556507110596
Validation loss: 2.0597686966260276

Epoch: 141| Step: 0
Training loss: 1.589756727218628
Validation loss: 2.0578424483537674

Epoch: 5| Step: 1
Training loss: 2.246724843978882
Validation loss: 2.0455108880996704

Epoch: 5| Step: 2
Training loss: 1.916314721107483
Validation loss: 2.049238791068395

Epoch: 5| Step: 3
Training loss: 1.3742260932922363
Validation loss: 2.0591517984867096

Epoch: 5| Step: 4
Training loss: 2.2755043506622314
Validation loss: 2.0636127293109894

Epoch: 5| Step: 5
Training loss: 2.3752102851867676
Validation loss: 2.070217341184616

Epoch: 5| Step: 6
Training loss: 1.831656813621521
Validation loss: 2.0702796628077826

Epoch: 5| Step: 7
Training loss: 2.0509419441223145
Validation loss: 2.066819667816162

Epoch: 5| Step: 8
Training loss: 2.1955342292785645
Validation loss: 2.0739754686752954

Epoch: 5| Step: 9
Training loss: 2.191288948059082
Validation loss: 2.080083097020785

Epoch: 5| Step: 10
Training loss: 2.0595197677612305
Validation loss: 2.0850621461868286

Epoch: 5| Step: 11
Training loss: 2.739410400390625
Validation loss: 2.095865954955419

Epoch: 142| Step: 0
Training loss: 2.2988367080688477
Validation loss: 2.1037585188945136

Epoch: 5| Step: 1
Training loss: 1.5223242044448853
Validation loss: 2.0834400256474814

Epoch: 5| Step: 2
Training loss: 2.56034517288208
Validation loss: 2.0866489013036094

Epoch: 5| Step: 3
Training loss: 1.7903871536254883
Validation loss: 2.0906231105327606

Epoch: 5| Step: 4
Training loss: 2.1620850563049316
Validation loss: 2.0756005694468818

Epoch: 5| Step: 5
Training loss: 2.320258617401123
Validation loss: 2.070195496082306

Epoch: 5| Step: 6
Training loss: 1.9270778894424438
Validation loss: 2.0618248929580054

Epoch: 5| Step: 7
Training loss: 2.021059513092041
Validation loss: 2.058743432164192

Epoch: 5| Step: 8
Training loss: 2.3394951820373535
Validation loss: 2.0713489055633545

Epoch: 5| Step: 9
Training loss: 2.006221055984497
Validation loss: 2.060822253425916

Epoch: 5| Step: 10
Training loss: 1.5431263446807861
Validation loss: 2.064122716585795

Epoch: 5| Step: 11
Training loss: 1.4935985803604126
Validation loss: 2.0631256798903146

Epoch: 143| Step: 0
Training loss: 2.443143367767334
Validation loss: 2.0717264860868454

Epoch: 5| Step: 1
Training loss: 2.001671552658081
Validation loss: 2.0690097709496817

Epoch: 5| Step: 2
Training loss: 2.1459643840789795
Validation loss: 2.069122369090716

Epoch: 5| Step: 3
Training loss: 2.257275342941284
Validation loss: 2.068565249443054

Epoch: 5| Step: 4
Training loss: 2.163898229598999
Validation loss: 2.0828978220621743

Epoch: 5| Step: 5
Training loss: 2.0908684730529785
Validation loss: 2.096025417248408

Epoch: 5| Step: 6
Training loss: 2.0969796180725098
Validation loss: 2.0978563328584037

Epoch: 5| Step: 7
Training loss: 1.4933867454528809
Validation loss: 2.106392651796341

Epoch: 5| Step: 8
Training loss: 1.9289900064468384
Validation loss: 2.1027313818534217

Epoch: 5| Step: 9
Training loss: 2.3656258583068848
Validation loss: 2.1068152487277985

Epoch: 5| Step: 10
Training loss: 1.606317162513733
Validation loss: 2.094199682275454

Epoch: 5| Step: 11
Training loss: 0.8820765018463135
Validation loss: 2.0804073363542557

Epoch: 144| Step: 0
Training loss: 2.0124237537384033
Validation loss: 2.0979238549868264

Epoch: 5| Step: 1
Training loss: 2.1378467082977295
Validation loss: 2.084218442440033

Epoch: 5| Step: 2
Training loss: 1.533845067024231
Validation loss: 2.0850869913895926

Epoch: 5| Step: 3
Training loss: 2.2672646045684814
Validation loss: 2.0708237836758294

Epoch: 5| Step: 4
Training loss: 2.3286330699920654
Validation loss: 2.0828798611958823

Epoch: 5| Step: 5
Training loss: 1.8393661975860596
Validation loss: 2.072962522506714

Epoch: 5| Step: 6
Training loss: 2.3508687019348145
Validation loss: 2.0710886468489966

Epoch: 5| Step: 7
Training loss: 2.0406835079193115
Validation loss: 2.074810971816381

Epoch: 5| Step: 8
Training loss: 2.134575605392456
Validation loss: 2.0791712204615274

Epoch: 5| Step: 9
Training loss: 1.7529594898223877
Validation loss: 2.071599836150805

Epoch: 5| Step: 10
Training loss: 1.8430713415145874
Validation loss: 2.081209753950437

Epoch: 5| Step: 11
Training loss: 2.1186904907226562
Validation loss: 2.097866172591845

Epoch: 145| Step: 0
Training loss: 1.53928804397583
Validation loss: 2.108231842517853

Epoch: 5| Step: 1
Training loss: 1.677008032798767
Validation loss: 2.084994857509931

Epoch: 5| Step: 2
Training loss: 2.6998884677886963
Validation loss: 2.1066999435424805

Epoch: 5| Step: 3
Training loss: 1.7140334844589233
Validation loss: 2.1141798545916877

Epoch: 5| Step: 4
Training loss: 2.88732647895813
Validation loss: 2.108082408706347

Epoch: 5| Step: 5
Training loss: 2.209886074066162
Validation loss: 2.1119292130072913

Epoch: 5| Step: 6
Training loss: 2.2491354942321777
Validation loss: 2.095898667971293

Epoch: 5| Step: 7
Training loss: 1.8571466207504272
Validation loss: 2.08792474369208

Epoch: 5| Step: 8
Training loss: 2.2230000495910645
Validation loss: 2.0831981201966605

Epoch: 5| Step: 9
Training loss: 1.3312944173812866
Validation loss: 2.0819102178017297

Epoch: 5| Step: 10
Training loss: 2.150998592376709
Validation loss: 2.0647093852361045

Epoch: 5| Step: 11
Training loss: 3.3570666313171387
Validation loss: 2.043602700034777

Epoch: 146| Step: 0
Training loss: 1.8932111263275146
Validation loss: 2.041458939512571

Epoch: 5| Step: 1
Training loss: 2.166710615158081
Validation loss: 2.056629031896591

Epoch: 5| Step: 2
Training loss: 2.4196689128875732
Validation loss: 2.057847335934639

Epoch: 5| Step: 3
Training loss: 2.2854771614074707
Validation loss: 2.0583286732435226

Epoch: 5| Step: 4
Training loss: 1.8720719814300537
Validation loss: 2.056397885084152

Epoch: 5| Step: 5
Training loss: 2.3658766746520996
Validation loss: 2.0534325440724692

Epoch: 5| Step: 6
Training loss: 1.9464361667633057
Validation loss: 2.053427278995514

Epoch: 5| Step: 7
Training loss: 1.83285391330719
Validation loss: 2.0494819283485413

Epoch: 5| Step: 8
Training loss: 2.165367841720581
Validation loss: 2.051601787408193

Epoch: 5| Step: 9
Training loss: 2.4135146141052246
Validation loss: 2.055110439658165

Epoch: 5| Step: 10
Training loss: 1.816070795059204
Validation loss: 2.0591808607180915

Epoch: 5| Step: 11
Training loss: 1.714262843132019
Validation loss: 2.064626842737198

Epoch: 147| Step: 0
Training loss: 2.4439711570739746
Validation loss: 2.070568695664406

Epoch: 5| Step: 1
Training loss: 2.0182125568389893
Validation loss: 2.093917359908422

Epoch: 5| Step: 2
Training loss: 1.5846835374832153
Validation loss: 2.102651591102282

Epoch: 5| Step: 3
Training loss: 2.223069906234741
Validation loss: 2.1146319955587387

Epoch: 5| Step: 4
Training loss: 2.4188132286071777
Validation loss: 2.1046087394158044

Epoch: 5| Step: 5
Training loss: 1.9212653636932373
Validation loss: 2.118414988120397

Epoch: 5| Step: 6
Training loss: 2.0398879051208496
Validation loss: 2.118736286958059

Epoch: 5| Step: 7
Training loss: 1.6767241954803467
Validation loss: 2.1143145859241486

Epoch: 5| Step: 8
Training loss: 1.9157593250274658
Validation loss: 2.111962527036667

Epoch: 5| Step: 9
Training loss: 2.268897533416748
Validation loss: 2.0845322608947754

Epoch: 5| Step: 10
Training loss: 2.1313881874084473
Validation loss: 2.0907995452483497

Epoch: 5| Step: 11
Training loss: 1.5076184272766113
Validation loss: 2.0737436215082803

Epoch: 148| Step: 0
Training loss: 1.7804110050201416
Validation loss: 2.0645023037989936

Epoch: 5| Step: 1
Training loss: 2.8446884155273438
Validation loss: 2.0588572025299072

Epoch: 5| Step: 2
Training loss: 1.9252361059188843
Validation loss: 2.0410600900650024

Epoch: 5| Step: 3
Training loss: 2.2488372325897217
Validation loss: 2.0420158008734384

Epoch: 5| Step: 4
Training loss: 2.137535572052002
Validation loss: 2.041554639736811

Epoch: 5| Step: 5
Training loss: 2.246459484100342
Validation loss: 2.0416871358950934

Epoch: 5| Step: 6
Training loss: 1.892634391784668
Validation loss: 2.049069474140803

Epoch: 5| Step: 7
Training loss: 2.0385565757751465
Validation loss: 2.0421364307403564

Epoch: 5| Step: 8
Training loss: 2.157076835632324
Validation loss: 2.041781177123388

Epoch: 5| Step: 9
Training loss: 1.4890670776367188
Validation loss: 2.0450587272644043

Epoch: 5| Step: 10
Training loss: 2.1096577644348145
Validation loss: 2.0546081761519113

Epoch: 5| Step: 11
Training loss: 1.9143147468566895
Validation loss: 2.0653263131777444

Epoch: 149| Step: 0
Training loss: 1.844604253768921
Validation loss: 2.0741529017686844

Epoch: 5| Step: 1
Training loss: 2.754204750061035
Validation loss: 2.0840140034755072

Epoch: 5| Step: 2
Training loss: 1.7953040599822998
Validation loss: 2.0885895043611526

Epoch: 5| Step: 3
Training loss: 1.4631476402282715
Validation loss: 2.094960033893585

Epoch: 5| Step: 4
Training loss: 1.9583566188812256
Validation loss: 2.1023776829242706

Epoch: 5| Step: 5
Training loss: 1.8860489130020142
Validation loss: 2.108122373620669

Epoch: 5| Step: 6
Training loss: 2.066746234893799
Validation loss: 2.105037828286489

Epoch: 5| Step: 7
Training loss: 2.4566123485565186
Validation loss: 2.1091393182675042

Epoch: 5| Step: 8
Training loss: 1.8322902917861938
Validation loss: 2.1269333958625793

Epoch: 5| Step: 9
Training loss: 1.865920066833496
Validation loss: 2.099108800292015

Epoch: 5| Step: 10
Training loss: 2.271498918533325
Validation loss: 2.095545083284378

Epoch: 5| Step: 11
Training loss: 2.0198802947998047
Validation loss: 2.083769222100576

Epoch: 150| Step: 0
Training loss: 2.181580066680908
Validation loss: 2.086492399374644

Epoch: 5| Step: 1
Training loss: 1.493391752243042
Validation loss: 2.074601396918297

Epoch: 5| Step: 2
Training loss: 2.3259494304656982
Validation loss: 2.052467927336693

Epoch: 5| Step: 3
Training loss: 1.688175916671753
Validation loss: 2.0560678442319236

Epoch: 5| Step: 4
Training loss: 2.317692518234253
Validation loss: 2.0556539992491403

Epoch: 5| Step: 5
Training loss: 1.8957027196884155
Validation loss: 2.0535221695899963

Epoch: 5| Step: 6
Training loss: 2.1251814365386963
Validation loss: 2.056361198425293

Epoch: 5| Step: 7
Training loss: 2.132530689239502
Validation loss: 2.0560611436764398

Epoch: 5| Step: 8
Training loss: 2.2386538982391357
Validation loss: 2.0552760461966195

Epoch: 5| Step: 9
Training loss: 2.0411295890808105
Validation loss: 2.063470015923182

Epoch: 5| Step: 10
Training loss: 2.1627349853515625
Validation loss: 2.075444628794988

Epoch: 5| Step: 11
Training loss: 2.3344714641571045
Validation loss: 2.0746067812045417

Epoch: 151| Step: 0
Training loss: 2.161832809448242
Validation loss: 2.0855555136998496

Epoch: 5| Step: 1
Training loss: 1.6715059280395508
Validation loss: 2.0962064613898597

Epoch: 5| Step: 2
Training loss: 2.166480302810669
Validation loss: 2.1098232517639794

Epoch: 5| Step: 3
Training loss: 1.9035457372665405
Validation loss: 2.1057794988155365

Epoch: 5| Step: 4
Training loss: 1.82016921043396
Validation loss: 2.135661323865255

Epoch: 5| Step: 5
Training loss: 2.3409647941589355
Validation loss: 2.1472694724798203

Epoch: 5| Step: 6
Training loss: 2.244096279144287
Validation loss: 2.1468219657739005

Epoch: 5| Step: 7
Training loss: 1.5044677257537842
Validation loss: 2.1194454034169516

Epoch: 5| Step: 8
Training loss: 2.8990707397460938
Validation loss: 2.115316480398178

Epoch: 5| Step: 9
Training loss: 1.6150434017181396
Validation loss: 2.1049382984638214

Epoch: 5| Step: 10
Training loss: 2.1356143951416016
Validation loss: 2.0725820511579514

Epoch: 5| Step: 11
Training loss: 1.2661097049713135
Validation loss: 2.0792783051729202

Epoch: 152| Step: 0
Training loss: 2.5365796089172363
Validation loss: 2.070851360758146

Epoch: 5| Step: 1
Training loss: 1.5932109355926514
Validation loss: 2.066346382101377

Epoch: 5| Step: 2
Training loss: 2.143690347671509
Validation loss: 2.0723466922839484

Epoch: 5| Step: 3
Training loss: 1.702967643737793
Validation loss: 2.077951118350029

Epoch: 5| Step: 4
Training loss: 1.3957090377807617
Validation loss: 2.0752366880575814

Epoch: 5| Step: 5
Training loss: 2.1348931789398193
Validation loss: 2.086604888240496

Epoch: 5| Step: 6
Training loss: 2.1951663494110107
Validation loss: 2.0989968528350196

Epoch: 5| Step: 7
Training loss: 2.0757248401641846
Validation loss: 2.132642835378647

Epoch: 5| Step: 8
Training loss: 2.154900550842285
Validation loss: 2.105251282453537

Epoch: 5| Step: 9
Training loss: 2.144477367401123
Validation loss: 2.1128657261530557

Epoch: 5| Step: 10
Training loss: 1.994978666305542
Validation loss: 2.0940161844094596

Epoch: 5| Step: 11
Training loss: 2.688460350036621
Validation loss: 2.1052146553993225

Epoch: 153| Step: 0
Training loss: 1.955736756324768
Validation loss: 2.113245869676272

Epoch: 5| Step: 1
Training loss: 2.5906968116760254
Validation loss: 2.11823737124602

Epoch: 5| Step: 2
Training loss: 2.0105745792388916
Validation loss: 2.0929182916879654

Epoch: 5| Step: 3
Training loss: 1.7918405532836914
Validation loss: 2.0713409086068473

Epoch: 5| Step: 4
Training loss: 1.6085288524627686
Validation loss: 2.074347029129664

Epoch: 5| Step: 5
Training loss: 2.2944517135620117
Validation loss: 2.0663378785053887

Epoch: 5| Step: 6
Training loss: 2.095820665359497
Validation loss: 2.0607523918151855

Epoch: 5| Step: 7
Training loss: 2.2780227661132812
Validation loss: 2.0633016477028527

Epoch: 5| Step: 8
Training loss: 1.775708794593811
Validation loss: 2.0772933711608252

Epoch: 5| Step: 9
Training loss: 1.8624061346054077
Validation loss: 2.077297588189443

Epoch: 5| Step: 10
Training loss: 1.9538042545318604
Validation loss: 2.0868523021539054

Epoch: 5| Step: 11
Training loss: 2.4167215824127197
Validation loss: 2.104213615258535

Epoch: 154| Step: 0
Training loss: 2.0394630432128906
Validation loss: 2.103774612148603

Epoch: 5| Step: 1
Training loss: 2.1054248809814453
Validation loss: 2.131958852211634

Epoch: 5| Step: 2
Training loss: 1.7117900848388672
Validation loss: 2.135866572459539

Epoch: 5| Step: 3
Training loss: 2.3114707469940186
Validation loss: 2.123596340417862

Epoch: 5| Step: 4
Training loss: 1.666039228439331
Validation loss: 2.123436003923416

Epoch: 5| Step: 5
Training loss: 2.079326629638672
Validation loss: 2.116320719321569

Epoch: 5| Step: 6
Training loss: 2.1699936389923096
Validation loss: 2.122877443830172

Epoch: 5| Step: 7
Training loss: 2.0378384590148926
Validation loss: 2.12201418975989

Epoch: 5| Step: 8
Training loss: 1.6187855005264282
Validation loss: 2.1241606126228967

Epoch: 5| Step: 9
Training loss: 2.061206579208374
Validation loss: 2.1146952559550605

Epoch: 5| Step: 10
Training loss: 2.1822521686553955
Validation loss: 2.1128903975089393

Epoch: 5| Step: 11
Training loss: 3.0967154502868652
Validation loss: 2.1069914996623993

Epoch: 155| Step: 0
Training loss: 2.001492977142334
Validation loss: 2.1160623182853064

Epoch: 5| Step: 1
Training loss: 1.8396812677383423
Validation loss: 2.1112407594919205

Epoch: 5| Step: 2
Training loss: 1.7210254669189453
Validation loss: 2.1045893877744675

Epoch: 5| Step: 3
Training loss: 2.312476396560669
Validation loss: 2.110206350684166

Epoch: 5| Step: 4
Training loss: 2.163527250289917
Validation loss: 2.1256386637687683

Epoch: 5| Step: 5
Training loss: 2.445387363433838
Validation loss: 2.1307665506998696

Epoch: 5| Step: 6
Training loss: 1.8849990367889404
Validation loss: 2.1283956319093704

Epoch: 5| Step: 7
Training loss: 2.0896291732788086
Validation loss: 2.1223632246255875

Epoch: 5| Step: 8
Training loss: 1.6764577627182007
Validation loss: 2.1255251417557397

Epoch: 5| Step: 9
Training loss: 1.624464750289917
Validation loss: 2.1145388881365457

Epoch: 5| Step: 10
Training loss: 2.1847548484802246
Validation loss: 2.1029089937607446

Epoch: 5| Step: 11
Training loss: 2.812138080596924
Validation loss: 2.0999868909517923

Epoch: 156| Step: 0
Training loss: 1.1949725151062012
Validation loss: 2.0870820532242456

Epoch: 5| Step: 1
Training loss: 2.054586410522461
Validation loss: 2.0950282414754233

Epoch: 5| Step: 2
Training loss: 1.7217248678207397
Validation loss: 2.099238470196724

Epoch: 5| Step: 3
Training loss: 2.1467480659484863
Validation loss: 2.097186028957367

Epoch: 5| Step: 4
Training loss: 1.8777306079864502
Validation loss: 2.1028222143650055

Epoch: 5| Step: 5
Training loss: 1.918940544128418
Validation loss: 2.1149188429117203

Epoch: 5| Step: 6
Training loss: 2.1422958374023438
Validation loss: 2.1235595842202506

Epoch: 5| Step: 7
Training loss: 2.2301955223083496
Validation loss: 2.128828744093577

Epoch: 5| Step: 8
Training loss: 2.4707934856414795
Validation loss: 2.1443757514158883

Epoch: 5| Step: 9
Training loss: 2.4499380588531494
Validation loss: 2.1374549816052117

Epoch: 5| Step: 10
Training loss: 2.0442893505096436
Validation loss: 2.134569267431895

Epoch: 5| Step: 11
Training loss: 1.7093499898910522
Validation loss: 2.121716911594073

Epoch: 157| Step: 0
Training loss: 2.1175906658172607
Validation loss: 2.1179462124904

Epoch: 5| Step: 1
Training loss: 2.435014009475708
Validation loss: 2.1297194411357245

Epoch: 5| Step: 2
Training loss: 1.5174872875213623
Validation loss: 2.1188414792219796

Epoch: 5| Step: 3
Training loss: 1.9419317245483398
Validation loss: 2.1023101011912027

Epoch: 5| Step: 4
Training loss: 1.5509389638900757
Validation loss: 2.1189773877461753

Epoch: 5| Step: 5
Training loss: 2.1788344383239746
Validation loss: 2.1101969132820764

Epoch: 5| Step: 6
Training loss: 2.372066020965576
Validation loss: 2.1139713873465857

Epoch: 5| Step: 7
Training loss: 1.5929298400878906
Validation loss: 2.115301191806793

Epoch: 5| Step: 8
Training loss: 1.9833076000213623
Validation loss: 2.1087479889392853

Epoch: 5| Step: 9
Training loss: 2.356377124786377
Validation loss: 2.0998400847117105

Epoch: 5| Step: 10
Training loss: 1.861505150794983
Validation loss: 2.079313720266024

Epoch: 5| Step: 11
Training loss: 2.6664228439331055
Validation loss: 2.0773990154266357

Epoch: 158| Step: 0
Training loss: 1.5892986059188843
Validation loss: 2.1029542833566666

Epoch: 5| Step: 1
Training loss: 2.4513556957244873
Validation loss: 2.1246619323889413

Epoch: 5| Step: 2
Training loss: 1.7694413661956787
Validation loss: 2.1304453561703363

Epoch: 5| Step: 3
Training loss: 1.906433343887329
Validation loss: 2.1152039070924125

Epoch: 5| Step: 4
Training loss: 2.2265381813049316
Validation loss: 2.1234478453795114

Epoch: 5| Step: 5
Training loss: 1.6094129085540771
Validation loss: 2.1041028002897897

Epoch: 5| Step: 6
Training loss: 2.594752311706543
Validation loss: 2.1025472432374954

Epoch: 5| Step: 7
Training loss: 2.0982754230499268
Validation loss: 2.1190032462279

Epoch: 5| Step: 8
Training loss: 2.3962998390197754
Validation loss: 2.101220096151034

Epoch: 5| Step: 9
Training loss: 1.9650228023529053
Validation loss: 2.1095531284809113

Epoch: 5| Step: 10
Training loss: 1.6933109760284424
Validation loss: 2.090086137255033

Epoch: 5| Step: 11
Training loss: 2.5600554943084717
Validation loss: 2.096933990716934

Epoch: 159| Step: 0
Training loss: 1.949135422706604
Validation loss: 2.093440259496371

Epoch: 5| Step: 1
Training loss: 1.87906813621521
Validation loss: 2.078153242667516

Epoch: 5| Step: 2
Training loss: 1.9120105504989624
Validation loss: 2.073475271463394

Epoch: 5| Step: 3
Training loss: 1.8408340215682983
Validation loss: 2.0773687412341437

Epoch: 5| Step: 4
Training loss: 2.1733622550964355
Validation loss: 2.0771618684132895

Epoch: 5| Step: 5
Training loss: 2.2514266967773438
Validation loss: 2.0777644515037537

Epoch: 5| Step: 6
Training loss: 1.7188142538070679
Validation loss: 2.0772300312916436

Epoch: 5| Step: 7
Training loss: 1.4441356658935547
Validation loss: 2.0842957894007363

Epoch: 5| Step: 8
Training loss: 2.504972457885742
Validation loss: 2.0906593054533005

Epoch: 5| Step: 9
Training loss: 2.396218776702881
Validation loss: 2.088650405406952

Epoch: 5| Step: 10
Training loss: 2.3426356315612793
Validation loss: 2.084064707159996

Epoch: 5| Step: 11
Training loss: 2.2684578895568848
Validation loss: 2.0974072416623435

Epoch: 160| Step: 0
Training loss: 2.0924487113952637
Validation loss: 2.107881729801496

Epoch: 5| Step: 1
Training loss: 1.845388412475586
Validation loss: 2.110600560903549

Epoch: 5| Step: 2
Training loss: 1.9787266254425049
Validation loss: 2.0965596735477448

Epoch: 5| Step: 3
Training loss: 2.160953998565674
Validation loss: 2.1075865427652993

Epoch: 5| Step: 4
Training loss: 2.0144386291503906
Validation loss: 2.1166301469008126

Epoch: 5| Step: 5
Training loss: 2.056069850921631
Validation loss: 2.115535999337832

Epoch: 5| Step: 6
Training loss: 1.7179934978485107
Validation loss: 2.1043039908011756

Epoch: 5| Step: 7
Training loss: 2.238164186477661
Validation loss: 2.102394531170527

Epoch: 5| Step: 8
Training loss: 1.9558693170547485
Validation loss: 2.1104673594236374

Epoch: 5| Step: 9
Training loss: 1.6353199481964111
Validation loss: 2.1162283470233283

Epoch: 5| Step: 10
Training loss: 2.210232734680176
Validation loss: 2.111308748523394

Epoch: 5| Step: 11
Training loss: 1.1350054740905762
Validation loss: 2.124374821782112

Epoch: 161| Step: 0
Training loss: 1.187691330909729
Validation loss: 2.1069731265306473

Epoch: 5| Step: 1
Training loss: 2.2520415782928467
Validation loss: 2.1022547086079917

Epoch: 5| Step: 2
Training loss: 1.6759822368621826
Validation loss: 2.106684366861979

Epoch: 5| Step: 3
Training loss: 1.9436225891113281
Validation loss: 2.1064504037300744

Epoch: 5| Step: 4
Training loss: 2.158292770385742
Validation loss: 2.111717646320661

Epoch: 5| Step: 5
Training loss: 2.23582124710083
Validation loss: 2.125841428836187

Epoch: 5| Step: 6
Training loss: 2.2695746421813965
Validation loss: 2.102885956565539

Epoch: 5| Step: 7
Training loss: 2.3676788806915283
Validation loss: 2.1136654019355774

Epoch: 5| Step: 8
Training loss: 1.7645241022109985
Validation loss: 2.1183522989352546

Epoch: 5| Step: 9
Training loss: 1.8796306848526
Validation loss: 2.1254191299279532

Epoch: 5| Step: 10
Training loss: 1.9794126749038696
Validation loss: 2.125391125679016

Epoch: 5| Step: 11
Training loss: 2.892181873321533
Validation loss: 2.1242236892382302

Epoch: 162| Step: 0
Training loss: 2.0937349796295166
Validation loss: 2.1080554823080697

Epoch: 5| Step: 1
Training loss: 2.597933292388916
Validation loss: 2.119439269105593

Epoch: 5| Step: 2
Training loss: 2.2680764198303223
Validation loss: 2.1264979590972266

Epoch: 5| Step: 3
Training loss: 1.9597247838974
Validation loss: 2.0985273321469626

Epoch: 5| Step: 4
Training loss: 1.5781139135360718
Validation loss: 2.1135325034459433

Epoch: 5| Step: 5
Training loss: 1.9319778680801392
Validation loss: 2.0903464009364447

Epoch: 5| Step: 6
Training loss: 2.2495627403259277
Validation loss: 2.104200631380081

Epoch: 5| Step: 7
Training loss: 1.606100082397461
Validation loss: 2.0982891966899238

Epoch: 5| Step: 8
Training loss: 1.4848921298980713
Validation loss: 2.099042316277822

Epoch: 5| Step: 9
Training loss: 2.007394313812256
Validation loss: 2.0903369088967643

Epoch: 5| Step: 10
Training loss: 2.247663736343384
Validation loss: 2.092108423511187

Epoch: 5| Step: 11
Training loss: 1.5630582571029663
Validation loss: 2.094315990805626

Epoch: 163| Step: 0
Training loss: 2.202871561050415
Validation loss: 2.10055402914683

Epoch: 5| Step: 1
Training loss: 2.6590240001678467
Validation loss: 2.101333826780319

Epoch: 5| Step: 2
Training loss: 2.2891502380371094
Validation loss: 2.114119678735733

Epoch: 5| Step: 3
Training loss: 1.9770523309707642
Validation loss: 2.104083071152369

Epoch: 5| Step: 4
Training loss: 2.1594150066375732
Validation loss: 2.1112010727326074

Epoch: 5| Step: 5
Training loss: 1.6245914697647095
Validation loss: 2.1273715794086456

Epoch: 5| Step: 6
Training loss: 1.819893479347229
Validation loss: 2.1342694809039435

Epoch: 5| Step: 7
Training loss: 2.0307726860046387
Validation loss: 2.1410594383875527

Epoch: 5| Step: 8
Training loss: 1.9516534805297852
Validation loss: 2.1210232228040695

Epoch: 5| Step: 9
Training loss: 1.538779854774475
Validation loss: 2.1253513793150582

Epoch: 5| Step: 10
Training loss: 1.6661043167114258
Validation loss: 2.122086470325788

Epoch: 5| Step: 11
Training loss: 0.44312340021133423
Validation loss: 2.1182991166909537

Epoch: 164| Step: 0
Training loss: 1.752640724182129
Validation loss: 2.1199191908041635

Epoch: 5| Step: 1
Training loss: 1.570547103881836
Validation loss: 2.1336801697810492

Epoch: 5| Step: 2
Training loss: 1.9871265888214111
Validation loss: 2.1206840624411902

Epoch: 5| Step: 3
Training loss: 2.2843520641326904
Validation loss: 2.1018792738517127

Epoch: 5| Step: 4
Training loss: 2.1879897117614746
Validation loss: 2.106566458940506

Epoch: 5| Step: 5
Training loss: 2.39678955078125
Validation loss: 2.0903132607539496

Epoch: 5| Step: 6
Training loss: 2.198519706726074
Validation loss: 2.098970984419187

Epoch: 5| Step: 7
Training loss: 1.8688678741455078
Validation loss: 2.085474371910095

Epoch: 5| Step: 8
Training loss: 1.6547505855560303
Validation loss: 2.0876059532165527

Epoch: 5| Step: 9
Training loss: 1.8884146213531494
Validation loss: 2.088020438949267

Epoch: 5| Step: 10
Training loss: 2.068103551864624
Validation loss: 2.110307916998863

Epoch: 5| Step: 11
Training loss: 1.6723501682281494
Validation loss: 2.105904142061869

Epoch: 165| Step: 0
Training loss: 2.036388397216797
Validation loss: 2.0922342091798782

Epoch: 5| Step: 1
Training loss: 1.8324750661849976
Validation loss: 2.111197700103124

Epoch: 5| Step: 2
Training loss: 1.6254301071166992
Validation loss: 2.1241847773392997

Epoch: 5| Step: 3
Training loss: 2.007476329803467
Validation loss: 2.1201412081718445

Epoch: 5| Step: 4
Training loss: 1.9322589635849
Validation loss: 2.1213393608729043

Epoch: 5| Step: 5
Training loss: 1.6334434747695923
Validation loss: 2.1365229139725366

Epoch: 5| Step: 6
Training loss: 1.991888403892517
Validation loss: 2.107800299922625

Epoch: 5| Step: 7
Training loss: 2.3104453086853027
Validation loss: 2.1107566356658936

Epoch: 5| Step: 8
Training loss: 2.0117344856262207
Validation loss: 2.1269854803880057

Epoch: 5| Step: 9
Training loss: 2.43133544921875
Validation loss: 2.1339306930700936

Epoch: 5| Step: 10
Training loss: 2.2997283935546875
Validation loss: 2.1278423964977264

Epoch: 5| Step: 11
Training loss: 0.432027131319046
Validation loss: 2.122206593553225

Epoch: 166| Step: 0
Training loss: 1.339383840560913
Validation loss: 2.126574923594793

Epoch: 5| Step: 1
Training loss: 1.713640809059143
Validation loss: 2.136964042981466

Epoch: 5| Step: 2
Training loss: 2.082357406616211
Validation loss: 2.139100730419159

Epoch: 5| Step: 3
Training loss: 1.9252727031707764
Validation loss: 2.1355701982975006

Epoch: 5| Step: 4
Training loss: 1.645349144935608
Validation loss: 2.13718647758166

Epoch: 5| Step: 5
Training loss: 2.003960132598877
Validation loss: 2.1257004340489707

Epoch: 5| Step: 6
Training loss: 2.311795949935913
Validation loss: 2.1272858480612435

Epoch: 5| Step: 7
Training loss: 2.176884889602661
Validation loss: 2.1194287141164145

Epoch: 5| Step: 8
Training loss: 1.9714324474334717
Validation loss: 2.1073865592479706

Epoch: 5| Step: 9
Training loss: 2.3499159812927246
Validation loss: 2.1085465252399445

Epoch: 5| Step: 10
Training loss: 2.327354907989502
Validation loss: 2.113804817199707

Epoch: 5| Step: 11
Training loss: 2.036890745162964
Validation loss: 2.1047992209593454

Epoch: 167| Step: 0
Training loss: 1.9747402667999268
Validation loss: 2.0861773441235223

Epoch: 5| Step: 1
Training loss: 1.7449449300765991
Validation loss: 2.0871087412039437

Epoch: 5| Step: 2
Training loss: 2.100980758666992
Validation loss: 2.0808582107226052

Epoch: 5| Step: 3
Training loss: 2.4329605102539062
Validation loss: 2.0756067782640457

Epoch: 5| Step: 4
Training loss: 2.0942389965057373
Validation loss: 2.0714884450038276

Epoch: 5| Step: 5
Training loss: 1.8242275714874268
Validation loss: 2.077960342168808

Epoch: 5| Step: 6
Training loss: 1.8691256046295166
Validation loss: 2.07309656838576

Epoch: 5| Step: 7
Training loss: 2.3020575046539307
Validation loss: 2.0795510609944663

Epoch: 5| Step: 8
Training loss: 2.161219358444214
Validation loss: 2.090294440587362

Epoch: 5| Step: 9
Training loss: 2.00083065032959
Validation loss: 2.070578162868818

Epoch: 5| Step: 10
Training loss: 1.7152111530303955
Validation loss: 2.096838489174843

Epoch: 5| Step: 11
Training loss: 1.7437045574188232
Validation loss: 2.091029385725657

Epoch: 168| Step: 0
Training loss: 1.993021011352539
Validation loss: 2.0970651606718698

Epoch: 5| Step: 1
Training loss: 2.2233946323394775
Validation loss: 2.105259964863459

Epoch: 5| Step: 2
Training loss: 2.4316818714141846
Validation loss: 2.105058973034223

Epoch: 5| Step: 3
Training loss: 1.8770910501480103
Validation loss: 2.1007543802261353

Epoch: 5| Step: 4
Training loss: 1.6510416269302368
Validation loss: 2.1004142413536706

Epoch: 5| Step: 5
Training loss: 2.1887247562408447
Validation loss: 2.0922091007232666

Epoch: 5| Step: 6
Training loss: 1.8431949615478516
Validation loss: 2.0911762068669

Epoch: 5| Step: 7
Training loss: 2.3474698066711426
Validation loss: 2.112543056408564

Epoch: 5| Step: 8
Training loss: 1.525113582611084
Validation loss: 2.098228335380554

Epoch: 5| Step: 9
Training loss: 1.9605319499969482
Validation loss: 2.108878716826439

Epoch: 5| Step: 10
Training loss: 1.797347068786621
Validation loss: 2.101545130213102

Epoch: 5| Step: 11
Training loss: 2.417222499847412
Validation loss: 2.1121106992165246

Epoch: 169| Step: 0
Training loss: 2.3976047039031982
Validation loss: 2.102137103676796

Epoch: 5| Step: 1
Training loss: 2.2329368591308594
Validation loss: 2.1148830453554788

Epoch: 5| Step: 2
Training loss: 2.079787492752075
Validation loss: 2.092895045876503

Epoch: 5| Step: 3
Training loss: 1.5065048933029175
Validation loss: 2.1158633877833686

Epoch: 5| Step: 4
Training loss: 2.529578924179077
Validation loss: 2.1162735571463904

Epoch: 5| Step: 5
Training loss: 1.879115343093872
Validation loss: 2.1161866784095764

Epoch: 5| Step: 6
Training loss: 2.181440830230713
Validation loss: 2.113928680618604

Epoch: 5| Step: 7
Training loss: 1.6270911693572998
Validation loss: 2.1081061214208603

Epoch: 5| Step: 8
Training loss: 1.4696851968765259
Validation loss: 2.1080588599046073

Epoch: 5| Step: 9
Training loss: 1.9359954595565796
Validation loss: 2.0985960364341736

Epoch: 5| Step: 10
Training loss: 2.076059579849243
Validation loss: 2.1067438324292502

Epoch: 5| Step: 11
Training loss: 1.1700226068496704
Validation loss: 2.105971728761991

Epoch: 170| Step: 0
Training loss: 2.580416679382324
Validation loss: 2.1088593204816184

Epoch: 5| Step: 1
Training loss: 2.1419315338134766
Validation loss: 2.1120186696449914

Epoch: 5| Step: 2
Training loss: 1.9153209924697876
Validation loss: 2.1195709109306335

Epoch: 5| Step: 3
Training loss: 2.1047825813293457
Validation loss: 2.1339995563030243

Epoch: 5| Step: 4
Training loss: 1.6579093933105469
Validation loss: 2.13968517879645

Epoch: 5| Step: 5
Training loss: 1.7733447551727295
Validation loss: 2.12832706173261

Epoch: 5| Step: 6
Training loss: 2.0755391120910645
Validation loss: 2.140183304746946

Epoch: 5| Step: 7
Training loss: 1.8483413457870483
Validation loss: 2.1494577725728354

Epoch: 5| Step: 8
Training loss: 1.5824090242385864
Validation loss: 2.1589487294356027

Epoch: 5| Step: 9
Training loss: 1.9102153778076172
Validation loss: 2.149096051851908

Epoch: 5| Step: 10
Training loss: 2.264370918273926
Validation loss: 2.149245793620745

Epoch: 5| Step: 11
Training loss: 1.7696058750152588
Validation loss: 2.1539560854434967

Epoch: 171| Step: 0
Training loss: 2.0556156635284424
Validation loss: 2.1491417487462363

Epoch: 5| Step: 1
Training loss: 1.4102380275726318
Validation loss: 2.152507891257604

Epoch: 5| Step: 2
Training loss: 2.3186521530151367
Validation loss: 2.144989068309466

Epoch: 5| Step: 3
Training loss: 1.6624189615249634
Validation loss: 2.149671976764997

Epoch: 5| Step: 4
Training loss: 2.4436194896698
Validation loss: 2.140779142578443

Epoch: 5| Step: 5
Training loss: 2.409241199493408
Validation loss: 2.1668653736511865

Epoch: 5| Step: 6
Training loss: 1.871750831604004
Validation loss: 2.135179435213407

Epoch: 5| Step: 7
Training loss: 2.214839220046997
Validation loss: 2.128175993760427

Epoch: 5| Step: 8
Training loss: 1.8909657001495361
Validation loss: 2.1225942025581994

Epoch: 5| Step: 9
Training loss: 1.7669404745101929
Validation loss: 2.110827475786209

Epoch: 5| Step: 10
Training loss: 1.779150366783142
Validation loss: 2.1189860800902047

Epoch: 5| Step: 11
Training loss: 2.0582499504089355
Validation loss: 2.123182346423467

Epoch: 172| Step: 0
Training loss: 2.406773090362549
Validation loss: 2.1328589071830115

Epoch: 5| Step: 1
Training loss: 2.1590735912323
Validation loss: 2.1197968870401382

Epoch: 5| Step: 2
Training loss: 2.37969708442688
Validation loss: 2.129598597685496

Epoch: 5| Step: 3
Training loss: 1.6308200359344482
Validation loss: 2.129320666193962

Epoch: 5| Step: 4
Training loss: 2.0078177452087402
Validation loss: 2.125472495953242

Epoch: 5| Step: 5
Training loss: 2.15820574760437
Validation loss: 2.126666486263275

Epoch: 5| Step: 6
Training loss: 1.6644413471221924
Validation loss: 2.12149985631307

Epoch: 5| Step: 7
Training loss: 1.435194730758667
Validation loss: 2.1134310911099115

Epoch: 5| Step: 8
Training loss: 2.2841765880584717
Validation loss: 2.1332423935333886

Epoch: 5| Step: 9
Training loss: 1.8790972232818604
Validation loss: 2.1485363245010376

Epoch: 5| Step: 10
Training loss: 1.7518402338027954
Validation loss: 2.136491278807322

Epoch: 5| Step: 11
Training loss: 2.189310073852539
Validation loss: 2.1297537038723626

Epoch: 173| Step: 0
Training loss: 1.7061951160430908
Validation loss: 2.1366935123999915

Epoch: 5| Step: 1
Training loss: 1.8620178699493408
Validation loss: 2.1419681310653687

Epoch: 5| Step: 2
Training loss: 1.9584541320800781
Validation loss: 2.144452745715777

Epoch: 5| Step: 3
Training loss: 2.0015828609466553
Validation loss: 2.130625898639361

Epoch: 5| Step: 4
Training loss: 2.406249523162842
Validation loss: 2.135414198040962

Epoch: 5| Step: 5
Training loss: 1.790790319442749
Validation loss: 2.139215181271235

Epoch: 5| Step: 6
Training loss: 2.2091403007507324
Validation loss: 2.1258534540732703

Epoch: 5| Step: 7
Training loss: 2.2924249172210693
Validation loss: 2.1252945214509964

Epoch: 5| Step: 8
Training loss: 1.8747373819351196
Validation loss: 2.1290028393268585

Epoch: 5| Step: 9
Training loss: 2.0782508850097656
Validation loss: 2.123703176776568

Epoch: 5| Step: 10
Training loss: 1.7410255670547485
Validation loss: 2.131570597489675

Epoch: 5| Step: 11
Training loss: 1.1822521686553955
Validation loss: 2.12826199332873

Epoch: 174| Step: 0
Training loss: 2.5905816555023193
Validation loss: 2.132518788178762

Epoch: 5| Step: 1
Training loss: 1.5153416395187378
Validation loss: 2.135632445414861

Epoch: 5| Step: 2
Training loss: 1.5895179510116577
Validation loss: 2.1348927120367684

Epoch: 5| Step: 3
Training loss: 1.6080633401870728
Validation loss: 2.14444691936175

Epoch: 5| Step: 4
Training loss: 2.2480969429016113
Validation loss: 2.167482867836952

Epoch: 5| Step: 5
Training loss: 1.9197070598602295
Validation loss: 2.1542030523220697

Epoch: 5| Step: 6
Training loss: 2.032060384750366
Validation loss: 2.149486869573593

Epoch: 5| Step: 7
Training loss: 1.6328665018081665
Validation loss: 2.1569554060697556

Epoch: 5| Step: 8
Training loss: 2.159651517868042
Validation loss: 2.141879215836525

Epoch: 5| Step: 9
Training loss: 2.285336971282959
Validation loss: 2.160954693953196

Epoch: 5| Step: 10
Training loss: 1.8857511281967163
Validation loss: 2.148389865954717

Epoch: 5| Step: 11
Training loss: 2.8263654708862305
Validation loss: 2.1414567679166794

Epoch: 175| Step: 0
Training loss: 2.044934034347534
Validation loss: 2.1389289100964866

Epoch: 5| Step: 1
Training loss: 1.62065851688385
Validation loss: 2.1310684780279794

Epoch: 5| Step: 2
Training loss: 1.5353529453277588
Validation loss: 2.14022026459376

Epoch: 5| Step: 3
Training loss: 2.3169102668762207
Validation loss: 2.1193566719690957

Epoch: 5| Step: 4
Training loss: 1.7249202728271484
Validation loss: 2.1149860322475433

Epoch: 5| Step: 5
Training loss: 1.3986239433288574
Validation loss: 2.126424248019854

Epoch: 5| Step: 6
Training loss: 2.125182867050171
Validation loss: 2.1187791724999747

Epoch: 5| Step: 7
Training loss: 2.2158453464508057
Validation loss: 2.13237955669562

Epoch: 5| Step: 8
Training loss: 2.166506767272949
Validation loss: 2.124840463201205

Epoch: 5| Step: 9
Training loss: 2.2067086696624756
Validation loss: 2.1370408833026886

Epoch: 5| Step: 10
Training loss: 2.7352113723754883
Validation loss: 2.144002228975296

Epoch: 5| Step: 11
Training loss: 0.984045684337616
Validation loss: 2.1283293068408966

Epoch: 176| Step: 0
Training loss: 1.7593570947647095
Validation loss: 2.13311497370402

Epoch: 5| Step: 1
Training loss: 2.297537088394165
Validation loss: 2.120054473479589

Epoch: 5| Step: 2
Training loss: 1.9700336456298828
Validation loss: 2.1283713777860007

Epoch: 5| Step: 3
Training loss: 1.8723064661026
Validation loss: 2.1096306443214417

Epoch: 5| Step: 4
Training loss: 1.709776520729065
Validation loss: 2.122817943493525

Epoch: 5| Step: 5
Training loss: 1.7480230331420898
Validation loss: 2.1152701129515967

Epoch: 5| Step: 6
Training loss: 2.556375741958618
Validation loss: 2.1028598298629126

Epoch: 5| Step: 7
Training loss: 1.9573684930801392
Validation loss: 2.1101705531279245

Epoch: 5| Step: 8
Training loss: 1.8096755743026733
Validation loss: 2.109971130887667

Epoch: 5| Step: 9
Training loss: 1.8933902978897095
Validation loss: 2.112618779142698

Epoch: 5| Step: 10
Training loss: 1.7541935443878174
Validation loss: 2.1172551860411963

Epoch: 5| Step: 11
Training loss: 3.074295997619629
Validation loss: 2.1254113813241324

Epoch: 177| Step: 0
Training loss: 1.3653199672698975
Validation loss: 2.1342056492964425

Epoch: 5| Step: 1
Training loss: 2.0634989738464355
Validation loss: 2.1353959242502847

Epoch: 5| Step: 2
Training loss: 2.267116069793701
Validation loss: 2.157530725002289

Epoch: 5| Step: 3
Training loss: 1.9551401138305664
Validation loss: 2.1442827681700387

Epoch: 5| Step: 4
Training loss: 2.0496063232421875
Validation loss: 2.1540562013785043

Epoch: 5| Step: 5
Training loss: 1.9597949981689453
Validation loss: 2.1531935383876166

Epoch: 5| Step: 6
Training loss: 1.7713515758514404
Validation loss: 2.1430333306392035

Epoch: 5| Step: 7
Training loss: 1.8658450841903687
Validation loss: 2.1508397360642753

Epoch: 5| Step: 8
Training loss: 2.00026273727417
Validation loss: 2.12830513715744

Epoch: 5| Step: 9
Training loss: 2.0827364921569824
Validation loss: 2.116552010178566

Epoch: 5| Step: 10
Training loss: 2.1655893325805664
Validation loss: 2.101800580819448

Epoch: 5| Step: 11
Training loss: 2.373403549194336
Validation loss: 2.093527247508367

Epoch: 178| Step: 0
Training loss: 1.6909822225570679
Validation loss: 2.0946253538131714

Epoch: 5| Step: 1
Training loss: 1.9479986429214478
Validation loss: 2.0862939655780792

Epoch: 5| Step: 2
Training loss: 2.069218635559082
Validation loss: 2.088518261909485

Epoch: 5| Step: 3
Training loss: 2.1162755489349365
Validation loss: 2.0856847763061523

Epoch: 5| Step: 4
Training loss: 2.9204208850860596
Validation loss: 2.0916698475678763

Epoch: 5| Step: 5
Training loss: 2.3647613525390625
Validation loss: 2.09466061492761

Epoch: 5| Step: 6
Training loss: 1.6387208700180054
Validation loss: 2.1014158378044763

Epoch: 5| Step: 7
Training loss: 1.9549564123153687
Validation loss: 2.092137868205706

Epoch: 5| Step: 8
Training loss: 1.827282190322876
Validation loss: 2.103749394416809

Epoch: 5| Step: 9
Training loss: 1.566751480102539
Validation loss: 2.1369802902142205

Epoch: 5| Step: 10
Training loss: 2.1667094230651855
Validation loss: 2.130277300874392

Epoch: 5| Step: 11
Training loss: 1.4917021989822388
Validation loss: 2.1351444820562997

Epoch: 179| Step: 0
Training loss: 1.7336320877075195
Validation loss: 2.1409301261107125

Epoch: 5| Step: 1
Training loss: 1.86161208152771
Validation loss: 2.131155918041865

Epoch: 5| Step: 2
Training loss: 2.409627914428711
Validation loss: 2.130145619312922

Epoch: 5| Step: 3
Training loss: 1.4887382984161377
Validation loss: 2.152897228797277

Epoch: 5| Step: 4
Training loss: 2.252440929412842
Validation loss: 2.1460212667783103

Epoch: 5| Step: 5
Training loss: 1.7542240619659424
Validation loss: 2.1306151896715164

Epoch: 5| Step: 6
Training loss: 2.2308430671691895
Validation loss: 2.1417800933122635

Epoch: 5| Step: 7
Training loss: 1.7075908184051514
Validation loss: 2.13366029659907

Epoch: 5| Step: 8
Training loss: 2.324702501296997
Validation loss: 2.12849752108256

Epoch: 5| Step: 9
Training loss: 2.007453441619873
Validation loss: 2.133175770441691

Epoch: 5| Step: 10
Training loss: 2.142531633377075
Validation loss: 2.1105434050162635

Epoch: 5| Step: 11
Training loss: 1.127664566040039
Validation loss: 2.1189702600240707

Epoch: 180| Step: 0
Training loss: 1.5335016250610352
Validation loss: 2.1178387800852456

Epoch: 5| Step: 1
Training loss: 1.7927913665771484
Validation loss: 2.134948030114174

Epoch: 5| Step: 2
Training loss: 1.4152045249938965
Validation loss: 2.1444072226683297

Epoch: 5| Step: 3
Training loss: 2.583911895751953
Validation loss: 2.154531717300415

Epoch: 5| Step: 4
Training loss: 3.078507900238037
Validation loss: 2.1519667307535806

Epoch: 5| Step: 5
Training loss: 1.8732249736785889
Validation loss: 2.147843067844709

Epoch: 5| Step: 6
Training loss: 2.3989782333374023
Validation loss: 2.17353418469429

Epoch: 5| Step: 7
Training loss: 1.6497398614883423
Validation loss: 2.17144051194191

Epoch: 5| Step: 8
Training loss: 1.8676131963729858
Validation loss: 2.1755333095788956

Epoch: 5| Step: 9
Training loss: 1.720001459121704
Validation loss: 2.175367126862208

Epoch: 5| Step: 10
Training loss: 1.9855051040649414
Validation loss: 2.1722556799650192

Epoch: 5| Step: 11
Training loss: 1.5712682008743286
Validation loss: 2.14510307709376

Epoch: 181| Step: 0
Training loss: 1.8671029806137085
Validation loss: 2.164607435464859

Epoch: 5| Step: 1
Training loss: 1.988168478012085
Validation loss: 2.1402958184480667

Epoch: 5| Step: 2
Training loss: 2.192898750305176
Validation loss: 2.137843002875646

Epoch: 5| Step: 3
Training loss: 2.7756197452545166
Validation loss: 2.1207087288300195

Epoch: 5| Step: 4
Training loss: 1.8692585229873657
Validation loss: 2.112127790848414

Epoch: 5| Step: 5
Training loss: 1.6556755304336548
Validation loss: 2.0916551997264228

Epoch: 5| Step: 6
Training loss: 1.7371721267700195
Validation loss: 2.1041192760070166

Epoch: 5| Step: 7
Training loss: 2.4720981121063232
Validation loss: 2.109808474779129

Epoch: 5| Step: 8
Training loss: 1.2962653636932373
Validation loss: 2.106197029352188

Epoch: 5| Step: 9
Training loss: 2.127272129058838
Validation loss: 2.1103783349196115

Epoch: 5| Step: 10
Training loss: 2.050424098968506
Validation loss: 2.1229654947916665

Epoch: 5| Step: 11
Training loss: 1.1715569496154785
Validation loss: 2.1166610519091287

Epoch: 182| Step: 0
Training loss: 1.930002212524414
Validation loss: 2.1227018187443414

Epoch: 5| Step: 1
Training loss: 1.8966823816299438
Validation loss: 2.127524604399999

Epoch: 5| Step: 2
Training loss: 1.822624921798706
Validation loss: 2.1253907481829324

Epoch: 5| Step: 3
Training loss: 2.0991263389587402
Validation loss: 2.124611104528109

Epoch: 5| Step: 4
Training loss: 1.9652373790740967
Validation loss: 2.1134767830371857

Epoch: 5| Step: 5
Training loss: 2.0313563346862793
Validation loss: 2.1416831016540527

Epoch: 5| Step: 6
Training loss: 1.9181419610977173
Validation loss: 2.134812076886495

Epoch: 5| Step: 7
Training loss: 1.9037755727767944
Validation loss: 2.1261204332113266

Epoch: 5| Step: 8
Training loss: 1.7674732208251953
Validation loss: 2.126019537448883

Epoch: 5| Step: 9
Training loss: 2.096100330352783
Validation loss: 2.128550628821055

Epoch: 5| Step: 10
Training loss: 2.0765697956085205
Validation loss: 2.1115950693686805

Epoch: 5| Step: 11
Training loss: 1.0105490684509277
Validation loss: 2.109675168991089

Epoch: 183| Step: 0
Training loss: 2.3292489051818848
Validation loss: 2.12308798233668

Epoch: 5| Step: 1
Training loss: 1.6137396097183228
Validation loss: 2.1053431630134583

Epoch: 5| Step: 2
Training loss: 1.7402359247207642
Validation loss: 2.0967362970113754

Epoch: 5| Step: 3
Training loss: 1.7964385747909546
Validation loss: 2.0894159575303397

Epoch: 5| Step: 4
Training loss: 2.4896302223205566
Validation loss: 2.097734749317169

Epoch: 5| Step: 5
Training loss: 2.504917621612549
Validation loss: 2.0863727182149887

Epoch: 5| Step: 6
Training loss: 1.9390453100204468
Validation loss: 2.0874793976545334

Epoch: 5| Step: 7
Training loss: 1.549838662147522
Validation loss: 2.0999323228995004

Epoch: 5| Step: 8
Training loss: 2.8049168586730957
Validation loss: 2.093282237648964

Epoch: 5| Step: 9
Training loss: 2.015293598175049
Validation loss: 2.096542626619339

Epoch: 5| Step: 10
Training loss: 1.8516690731048584
Validation loss: 2.0934517284234366

Epoch: 5| Step: 11
Training loss: 1.8687940835952759
Validation loss: 2.1028767923514047

Epoch: 184| Step: 0
Training loss: 1.90765380859375
Validation loss: 2.1127053250869117

Epoch: 5| Step: 1
Training loss: 1.8585422039031982
Validation loss: 2.1133256554603577

Epoch: 5| Step: 2
Training loss: 1.8432105779647827
Validation loss: 2.112387031316757

Epoch: 5| Step: 3
Training loss: 2.520930051803589
Validation loss: 2.1274642447630563

Epoch: 5| Step: 4
Training loss: 1.8672029972076416
Validation loss: 2.135521322488785

Epoch: 5| Step: 5
Training loss: 1.9215924739837646
Validation loss: 2.1369484017292657

Epoch: 5| Step: 6
Training loss: 2.2116172313690186
Validation loss: 2.1283615082502365

Epoch: 5| Step: 7
Training loss: 1.7119449377059937
Validation loss: 2.116698001821836

Epoch: 5| Step: 8
Training loss: 2.2104437351226807
Validation loss: 2.13737723728021

Epoch: 5| Step: 9
Training loss: 1.69147527217865
Validation loss: 2.152594422300657

Epoch: 5| Step: 10
Training loss: 1.666255235671997
Validation loss: 2.124230831861496

Epoch: 5| Step: 11
Training loss: 2.5893189907073975
Validation loss: 2.1087807416915894

Epoch: 185| Step: 0
Training loss: 2.1259400844573975
Validation loss: 2.136311342318853

Epoch: 5| Step: 1
Training loss: 1.5981534719467163
Validation loss: 2.1174727181593576

Epoch: 5| Step: 2
Training loss: 1.934124231338501
Validation loss: 2.1278266410032907

Epoch: 5| Step: 3
Training loss: 2.0961155891418457
Validation loss: 2.128212650616964

Epoch: 5| Step: 4
Training loss: 1.9983323812484741
Validation loss: 2.116972401738167

Epoch: 5| Step: 5
Training loss: 1.7743473052978516
Validation loss: 2.1170953710873923

Epoch: 5| Step: 6
Training loss: 1.499205231666565
Validation loss: 2.121107945839564

Epoch: 5| Step: 7
Training loss: 1.582649827003479
Validation loss: 2.1284442941347756

Epoch: 5| Step: 8
Training loss: 2.219761371612549
Validation loss: 2.1336059967676797

Epoch: 5| Step: 9
Training loss: 2.276273250579834
Validation loss: 2.130663971106211

Epoch: 5| Step: 10
Training loss: 2.1128976345062256
Validation loss: 2.1228919128576913

Epoch: 5| Step: 11
Training loss: 2.117431163787842
Validation loss: 2.131509378552437

Epoch: 186| Step: 0
Training loss: 2.296099901199341
Validation loss: 2.142632325490316

Epoch: 5| Step: 1
Training loss: 1.7247192859649658
Validation loss: 2.1329373766978583

Epoch: 5| Step: 2
Training loss: 1.604856252670288
Validation loss: 2.158407216270765

Epoch: 5| Step: 3
Training loss: 2.3006577491760254
Validation loss: 2.141111820936203

Epoch: 5| Step: 4
Training loss: 2.6844146251678467
Validation loss: 2.1411314755678177

Epoch: 5| Step: 5
Training loss: 1.9899581670761108
Validation loss: 2.1439596811930337

Epoch: 5| Step: 6
Training loss: 1.6642414331436157
Validation loss: 2.1510708232720694

Epoch: 5| Step: 7
Training loss: 1.6808525323867798
Validation loss: 2.1398883859316506

Epoch: 5| Step: 8
Training loss: 1.5708391666412354
Validation loss: 2.1447582443555198

Epoch: 5| Step: 9
Training loss: 2.3412277698516846
Validation loss: 2.1422410110632577

Epoch: 5| Step: 10
Training loss: 1.6129471063613892
Validation loss: 2.1214999755223594

Epoch: 5| Step: 11
Training loss: 3.7570419311523438
Validation loss: 2.132759392261505

Epoch: 187| Step: 0
Training loss: 1.8725872039794922
Validation loss: 2.1419215500354767

Epoch: 5| Step: 1
Training loss: 1.6147480010986328
Validation loss: 2.140394151210785

Epoch: 5| Step: 2
Training loss: 2.3671343326568604
Validation loss: 2.1277874360481897

Epoch: 5| Step: 3
Training loss: 1.9275074005126953
Validation loss: 2.122934321562449

Epoch: 5| Step: 4
Training loss: 2.1649975776672363
Validation loss: 2.1503279407819114

Epoch: 5| Step: 5
Training loss: 1.996744155883789
Validation loss: 2.129168823361397

Epoch: 5| Step: 6
Training loss: 1.8572839498519897
Validation loss: 2.13140403230985

Epoch: 5| Step: 7
Training loss: 1.926690697669983
Validation loss: 2.135228455066681

Epoch: 5| Step: 8
Training loss: 1.5667911767959595
Validation loss: 2.1279901415109634

Epoch: 5| Step: 9
Training loss: 2.2408840656280518
Validation loss: 2.1367821047703424

Epoch: 5| Step: 10
Training loss: 1.993861198425293
Validation loss: 2.13000218073527

Epoch: 5| Step: 11
Training loss: 2.141233444213867
Validation loss: 2.1539174864689508

Epoch: 188| Step: 0
Training loss: 2.25801157951355
Validation loss: 2.1507797141869864

Epoch: 5| Step: 1
Training loss: 1.462775468826294
Validation loss: 2.1245655914147696

Epoch: 5| Step: 2
Training loss: 2.10672664642334
Validation loss: 2.108615239461263

Epoch: 5| Step: 3
Training loss: 2.3767690658569336
Validation loss: 2.1081685026486716

Epoch: 5| Step: 4
Training loss: 1.829220175743103
Validation loss: 2.103119805455208

Epoch: 5| Step: 5
Training loss: 2.5518178939819336
Validation loss: 2.1038022687037787

Epoch: 5| Step: 6
Training loss: 2.248063564300537
Validation loss: 2.0978936503330865

Epoch: 5| Step: 7
Training loss: 1.4528214931488037
Validation loss: 2.096743722756704

Epoch: 5| Step: 8
Training loss: 2.085008144378662
Validation loss: 2.1078201780716577

Epoch: 5| Step: 9
Training loss: 2.183868169784546
Validation loss: 2.101944014430046

Epoch: 5| Step: 10
Training loss: 1.6037366390228271
Validation loss: 2.1173525601625443

Epoch: 5| Step: 11
Training loss: 3.4265594482421875
Validation loss: 2.1100177615880966

Epoch: 189| Step: 0
Training loss: 1.919189453125
Validation loss: 2.116469865043958

Epoch: 5| Step: 1
Training loss: 2.3533172607421875
Validation loss: 2.106536547342936

Epoch: 5| Step: 2
Training loss: 2.116267442703247
Validation loss: 2.1263435979684195

Epoch: 5| Step: 3
Training loss: 2.0218403339385986
Validation loss: 2.1214145521322885

Epoch: 5| Step: 4
Training loss: 2.051668643951416
Validation loss: 2.12907945116361

Epoch: 5| Step: 5
Training loss: 1.7585773468017578
Validation loss: 2.1280454993247986

Epoch: 5| Step: 6
Training loss: 2.4525809288024902
Validation loss: 2.117074112097422

Epoch: 5| Step: 7
Training loss: 1.3842166662216187
Validation loss: 2.1281014482180276

Epoch: 5| Step: 8
Training loss: 2.2952895164489746
Validation loss: 2.129921391606331

Epoch: 5| Step: 9
Training loss: 1.5000526905059814
Validation loss: 2.1270130227009454

Epoch: 5| Step: 10
Training loss: 2.1210668087005615
Validation loss: 2.141313989957174

Epoch: 5| Step: 11
Training loss: 1.103039026260376
Validation loss: 2.134594370921453

Epoch: 190| Step: 0
Training loss: 2.090916872024536
Validation loss: 2.1307910829782486

Epoch: 5| Step: 1
Training loss: 2.697960376739502
Validation loss: 2.144272635380427

Epoch: 5| Step: 2
Training loss: 1.2337013483047485
Validation loss: 2.1564191629489264

Epoch: 5| Step: 3
Training loss: 1.8993761539459229
Validation loss: 2.133377641439438

Epoch: 5| Step: 4
Training loss: 1.4626067876815796
Validation loss: 2.137433076898257

Epoch: 5| Step: 5
Training loss: 2.065117359161377
Validation loss: 2.141454299290975

Epoch: 5| Step: 6
Training loss: 1.4291211366653442
Validation loss: 2.14961513876915

Epoch: 5| Step: 7
Training loss: 2.5343523025512695
Validation loss: 2.1706698487202325

Epoch: 5| Step: 8
Training loss: 2.3938281536102295
Validation loss: 2.1498377124468484

Epoch: 5| Step: 9
Training loss: 1.9351255893707275
Validation loss: 2.1690034568309784

Epoch: 5| Step: 10
Training loss: 1.924975037574768
Validation loss: 2.1588277568419776

Epoch: 5| Step: 11
Training loss: 2.122516393661499
Validation loss: 2.158611014485359

Epoch: 191| Step: 0
Training loss: 1.6426913738250732
Validation loss: 2.148093675573667

Epoch: 5| Step: 1
Training loss: 2.321511745452881
Validation loss: 2.1542453318834305

Epoch: 5| Step: 2
Training loss: 1.8218367099761963
Validation loss: 2.1469678233067193

Epoch: 5| Step: 3
Training loss: 2.113687753677368
Validation loss: 2.1335475842158

Epoch: 5| Step: 4
Training loss: 1.9674571752548218
Validation loss: 2.1327250053485236

Epoch: 5| Step: 5
Training loss: 1.774473786354065
Validation loss: 2.153386582930883

Epoch: 5| Step: 6
Training loss: 1.7965008020401
Validation loss: 2.1434564789136252

Epoch: 5| Step: 7
Training loss: 2.63921856880188
Validation loss: 2.1325933635234833

Epoch: 5| Step: 8
Training loss: 2.3964102268218994
Validation loss: 2.142475406328837

Epoch: 5| Step: 9
Training loss: 1.3964791297912598
Validation loss: 2.145285964012146

Epoch: 5| Step: 10
Training loss: 1.750936508178711
Validation loss: 2.163595716158549

Epoch: 5| Step: 11
Training loss: 1.1602884531021118
Validation loss: 2.1785276979207993

Epoch: 192| Step: 0
Training loss: 1.8851368427276611
Validation loss: 2.1633082727591195

Epoch: 5| Step: 1
Training loss: 2.0389113426208496
Validation loss: 2.1799239615599313

Epoch: 5| Step: 2
Training loss: 2.0106377601623535
Validation loss: 2.1726145644982657

Epoch: 5| Step: 3
Training loss: 1.545035719871521
Validation loss: 2.1931390861670175

Epoch: 5| Step: 4
Training loss: 2.090789794921875
Validation loss: 2.172700136899948

Epoch: 5| Step: 5
Training loss: 2.4712347984313965
Validation loss: 2.157692680756251

Epoch: 5| Step: 6
Training loss: 1.219692349433899
Validation loss: 2.172817960381508

Epoch: 5| Step: 7
Training loss: 2.1531126499176025
Validation loss: 2.1743136843045554

Epoch: 5| Step: 8
Training loss: 2.152801275253296
Validation loss: 2.155249704917272

Epoch: 5| Step: 9
Training loss: 1.465366005897522
Validation loss: 2.1649679243564606

Epoch: 5| Step: 10
Training loss: 2.351560592651367
Validation loss: 2.152720789114634

Epoch: 5| Step: 11
Training loss: 1.7757618427276611
Validation loss: 2.175880571206411

Epoch: 193| Step: 0
Training loss: 2.3202197551727295
Validation loss: 2.1568321585655212

Epoch: 5| Step: 1
Training loss: 1.9208428859710693
Validation loss: 2.1456123292446136

Epoch: 5| Step: 2
Training loss: 2.070887804031372
Validation loss: 2.136400525768598

Epoch: 5| Step: 3
Training loss: 1.542296290397644
Validation loss: 2.1356728772322335

Epoch: 5| Step: 4
Training loss: 1.5786967277526855
Validation loss: 2.1515357891718545

Epoch: 5| Step: 5
Training loss: 2.0957016944885254
Validation loss: 2.143863558769226

Epoch: 5| Step: 6
Training loss: 2.1690468788146973
Validation loss: 2.1393819749355316

Epoch: 5| Step: 7
Training loss: 1.4610354900360107
Validation loss: 2.1452679336071014

Epoch: 5| Step: 8
Training loss: 2.1329736709594727
Validation loss: 2.148236776391665

Epoch: 5| Step: 9
Training loss: 2.165376663208008
Validation loss: 2.1601347674926124

Epoch: 5| Step: 10
Training loss: 1.9681684970855713
Validation loss: 2.153445675969124

Epoch: 5| Step: 11
Training loss: 2.284658432006836
Validation loss: 2.157562792301178

Epoch: 194| Step: 0
Training loss: 2.110044479370117
Validation loss: 2.178918639818827

Epoch: 5| Step: 1
Training loss: 1.7093760967254639
Validation loss: 2.1534672379493713

Epoch: 5| Step: 2
Training loss: 2.6110339164733887
Validation loss: 2.1691187421480813

Epoch: 5| Step: 3
Training loss: 1.407310962677002
Validation loss: 2.1752603302399316

Epoch: 5| Step: 4
Training loss: 1.8040237426757812
Validation loss: 2.1559001753727594

Epoch: 5| Step: 5
Training loss: 2.4383904933929443
Validation loss: 2.1659966657559075

Epoch: 5| Step: 6
Training loss: 2.4059927463531494
Validation loss: 2.1713987439870834

Epoch: 5| Step: 7
Training loss: 1.3987706899642944
Validation loss: 2.1700130303700766

Epoch: 5| Step: 8
Training loss: 1.8691002130508423
Validation loss: 2.1618425647417703

Epoch: 5| Step: 9
Training loss: 1.7367496490478516
Validation loss: 2.1683063556750617

Epoch: 5| Step: 10
Training loss: 1.6701023578643799
Validation loss: 2.1686497032642365

Epoch: 5| Step: 11
Training loss: 1.6560012102127075
Validation loss: 2.1668480734030404

Epoch: 195| Step: 0
Training loss: 1.5890233516693115
Validation loss: 2.1517691612243652

Epoch: 5| Step: 1
Training loss: 2.3030714988708496
Validation loss: 2.1629013816515603

Epoch: 5| Step: 2
Training loss: 2.571089267730713
Validation loss: 2.1567996392647424

Epoch: 5| Step: 3
Training loss: 1.548632025718689
Validation loss: 2.1595790485541024

Epoch: 5| Step: 4
Training loss: 2.135512590408325
Validation loss: 2.184835364421209

Epoch: 5| Step: 5
Training loss: 1.2497001886367798
Validation loss: 2.172043194373449

Epoch: 5| Step: 6
Training loss: 1.7655318975448608
Validation loss: 2.177187919616699

Epoch: 5| Step: 7
Training loss: 2.152395248413086
Validation loss: 2.1768101900815964

Epoch: 5| Step: 8
Training loss: 2.1297707557678223
Validation loss: 2.172263259689013

Epoch: 5| Step: 9
Training loss: 2.413450241088867
Validation loss: 2.18637852370739

Epoch: 5| Step: 10
Training loss: 1.4650323390960693
Validation loss: 2.176368067661921

Epoch: 5| Step: 11
Training loss: 0.9431207180023193
Validation loss: 2.1842953115701675

Epoch: 196| Step: 0
Training loss: 1.978956937789917
Validation loss: 2.163498808940252

Epoch: 5| Step: 1
Training loss: 2.524839162826538
Validation loss: 2.1873256464799247

Epoch: 5| Step: 2
Training loss: 2.156238317489624
Validation loss: 2.1804240196943283

Epoch: 5| Step: 3
Training loss: 1.7512233257293701
Validation loss: 2.164109393954277

Epoch: 5| Step: 4
Training loss: 1.5464085340499878
Validation loss: 2.1599249790112176

Epoch: 5| Step: 5
Training loss: 1.4994404315948486
Validation loss: 2.1739843686421714

Epoch: 5| Step: 6
Training loss: 1.5835548639297485
Validation loss: 2.1702312429745994

Epoch: 5| Step: 7
Training loss: 1.585794448852539
Validation loss: 2.178706740339597

Epoch: 5| Step: 8
Training loss: 2.2812116146087646
Validation loss: 2.1945083091656366

Epoch: 5| Step: 9
Training loss: 2.0466408729553223
Validation loss: 2.187223896384239

Epoch: 5| Step: 10
Training loss: 2.0109503269195557
Validation loss: 2.1903160959482193

Epoch: 5| Step: 11
Training loss: 1.748204231262207
Validation loss: 2.1793314019838967

Epoch: 197| Step: 0
Training loss: 1.7657556533813477
Validation loss: 2.1898314158121743

Epoch: 5| Step: 1
Training loss: 1.846571922302246
Validation loss: 2.1819430142641068

Epoch: 5| Step: 2
Training loss: 1.7405452728271484
Validation loss: 2.1856120228767395

Epoch: 5| Step: 3
Training loss: 1.789843201637268
Validation loss: 2.2202090422312417

Epoch: 5| Step: 4
Training loss: 2.014831304550171
Validation loss: 2.200054869055748

Epoch: 5| Step: 5
Training loss: 2.105966091156006
Validation loss: 2.1930989623069763

Epoch: 5| Step: 6
Training loss: 2.6054489612579346
Validation loss: 2.184739649295807

Epoch: 5| Step: 7
Training loss: 1.6525237560272217
Validation loss: 2.1847758889198303

Epoch: 5| Step: 8
Training loss: 1.9954779148101807
Validation loss: 2.177667294939359

Epoch: 5| Step: 9
Training loss: 1.6197506189346313
Validation loss: 2.177465866009394

Epoch: 5| Step: 10
Training loss: 2.260146379470825
Validation loss: 2.169814715782801

Epoch: 5| Step: 11
Training loss: 2.3182129859924316
Validation loss: 2.1513309379418692

Epoch: 198| Step: 0
Training loss: 1.4587432146072388
Validation loss: 2.1594622184832892

Epoch: 5| Step: 1
Training loss: 2.304551601409912
Validation loss: 2.1600725799798965

Epoch: 5| Step: 2
Training loss: 2.3781063556671143
Validation loss: 2.1619307547807693

Epoch: 5| Step: 3
Training loss: 1.8771934509277344
Validation loss: 2.1651333620150885

Epoch: 5| Step: 4
Training loss: 2.0799450874328613
Validation loss: 2.165542627374331

Epoch: 5| Step: 5
Training loss: 1.2825098037719727
Validation loss: 2.162993679443995

Epoch: 5| Step: 6
Training loss: 2.138805627822876
Validation loss: 2.181632841626803

Epoch: 5| Step: 7
Training loss: 2.0738604068756104
Validation loss: 2.181463489929835

Epoch: 5| Step: 8
Training loss: 2.0648257732391357
Validation loss: 2.1885488828023276

Epoch: 5| Step: 9
Training loss: 1.568840503692627
Validation loss: 2.1917278468608856

Epoch: 5| Step: 10
Training loss: 1.823883056640625
Validation loss: 2.1714640160401664

Epoch: 5| Step: 11
Training loss: 2.9076590538024902
Validation loss: 2.1710377484560013

Epoch: 199| Step: 0
Training loss: 1.9583981037139893
Validation loss: 2.174310793479284

Epoch: 5| Step: 1
Training loss: 2.795714855194092
Validation loss: 2.165557473897934

Epoch: 5| Step: 2
Training loss: 2.3266682624816895
Validation loss: 2.1595814724763236

Epoch: 5| Step: 3
Training loss: 2.0125012397766113
Validation loss: 2.153357674678167

Epoch: 5| Step: 4
Training loss: 1.8423134088516235
Validation loss: 2.1583706935246787

Epoch: 5| Step: 5
Training loss: 1.6877905130386353
Validation loss: 2.132390469312668

Epoch: 5| Step: 6
Training loss: 1.5198702812194824
Validation loss: 2.134979118903478

Epoch: 5| Step: 7
Training loss: 2.3743350505828857
Validation loss: 2.1324660778045654

Epoch: 5| Step: 8
Training loss: 1.6019436120986938
Validation loss: 2.1347665886084237

Epoch: 5| Step: 9
Training loss: 2.043567419052124
Validation loss: 2.1411549945672355

Epoch: 5| Step: 10
Training loss: 1.9459693431854248
Validation loss: 2.1413933684428534

Epoch: 5| Step: 11
Training loss: 1.0422595739364624
Validation loss: 2.1495792865753174

Epoch: 200| Step: 0
Training loss: 1.8838306665420532
Validation loss: 2.1429257641235986

Epoch: 5| Step: 1
Training loss: 1.8095133304595947
Validation loss: 2.148505061864853

Epoch: 5| Step: 2
Training loss: 2.0160770416259766
Validation loss: 2.1577505320310593

Epoch: 5| Step: 3
Training loss: 1.7018051147460938
Validation loss: 2.1688368221124015

Epoch: 5| Step: 4
Training loss: 2.0504488945007324
Validation loss: 2.1591575145721436

Epoch: 5| Step: 5
Training loss: 1.7538583278656006
Validation loss: 2.162136803070704

Epoch: 5| Step: 6
Training loss: 1.8545925617218018
Validation loss: 2.1576919158299765

Epoch: 5| Step: 7
Training loss: 1.4961087703704834
Validation loss: 2.1477015018463135

Epoch: 5| Step: 8
Training loss: 2.3789477348327637
Validation loss: 2.1646034320195517

Epoch: 5| Step: 9
Training loss: 2.670192003250122
Validation loss: 2.1550890505313873

Epoch: 5| Step: 10
Training loss: 1.4169104099273682
Validation loss: 2.160497546195984

Epoch: 5| Step: 11
Training loss: 1.7225747108459473
Validation loss: 2.17605721950531

Epoch: 201| Step: 0
Training loss: 1.5201021432876587
Validation loss: 2.163209949930509

Epoch: 5| Step: 1
Training loss: 2.340054988861084
Validation loss: 2.1661123434702554

Epoch: 5| Step: 2
Training loss: 1.9963934421539307
Validation loss: 2.1820089717706046

Epoch: 5| Step: 3
Training loss: 2.1790225505828857
Validation loss: 2.1984785546859107

Epoch: 5| Step: 4
Training loss: 1.5578181743621826
Validation loss: 2.1818271428346634

Epoch: 5| Step: 5
Training loss: 1.9249778985977173
Validation loss: 2.1895548701286316

Epoch: 5| Step: 6
Training loss: 1.8731114864349365
Validation loss: 2.1849178274472556

Epoch: 5| Step: 7
Training loss: 2.575406551361084
Validation loss: 2.1734582781791687

Epoch: 5| Step: 8
Training loss: 1.3957891464233398
Validation loss: 2.1670939276615777

Epoch: 5| Step: 9
Training loss: 1.6959797143936157
Validation loss: 2.167834679285685

Epoch: 5| Step: 10
Training loss: 2.120131015777588
Validation loss: 2.1707587093114853

Epoch: 5| Step: 11
Training loss: 0.9027955532073975
Validation loss: 2.16582790017128

Epoch: 202| Step: 0
Training loss: 2.472578525543213
Validation loss: 2.1829703946908317

Epoch: 5| Step: 1
Training loss: 2.0616660118103027
Validation loss: 2.1832150916258493

Epoch: 5| Step: 2
Training loss: 2.5304665565490723
Validation loss: 2.191584368546804

Epoch: 5| Step: 3
Training loss: 1.6821072101593018
Validation loss: 2.1976851373910904

Epoch: 5| Step: 4
Training loss: 1.5358526706695557
Validation loss: 2.185921142498652

Epoch: 5| Step: 5
Training loss: 1.8318687677383423
Validation loss: 2.173193782567978

Epoch: 5| Step: 6
Training loss: 2.550666093826294
Validation loss: 2.1952118426561356

Epoch: 5| Step: 7
Training loss: 1.6712806224822998
Validation loss: 2.177459180355072

Epoch: 5| Step: 8
Training loss: 1.1974732875823975
Validation loss: 2.1673045506079993

Epoch: 5| Step: 9
Training loss: 2.0711536407470703
Validation loss: 2.1817541122436523

Epoch: 5| Step: 10
Training loss: 1.5547672510147095
Validation loss: 2.1731080760558448

Epoch: 5| Step: 11
Training loss: 1.8084577322006226
Validation loss: 2.1699070036411285

Epoch: 203| Step: 0
Training loss: 1.8987808227539062
Validation loss: 2.1523529241482415

Epoch: 5| Step: 1
Training loss: 2.636032819747925
Validation loss: 2.1290236165126166

Epoch: 5| Step: 2
Training loss: 1.9039409160614014
Validation loss: 2.1220986942450204

Epoch: 5| Step: 3
Training loss: 1.9483702182769775
Validation loss: 2.121211955944697

Epoch: 5| Step: 4
Training loss: 1.930769681930542
Validation loss: 2.127296502391497

Epoch: 5| Step: 5
Training loss: 1.9571603536605835
Validation loss: 2.1266980469226837

Epoch: 5| Step: 6
Training loss: 1.8141542673110962
Validation loss: 2.12747123837471

Epoch: 5| Step: 7
Training loss: 2.2619996070861816
Validation loss: 2.137691224614779

Epoch: 5| Step: 8
Training loss: 1.9167060852050781
Validation loss: 2.1461248795191445

Epoch: 5| Step: 9
Training loss: 1.5038580894470215
Validation loss: 2.1604868918657303

Epoch: 5| Step: 10
Training loss: 2.209235668182373
Validation loss: 2.1466649075349173

Epoch: 5| Step: 11
Training loss: 2.4622507095336914
Validation loss: 2.17340820034345

Epoch: 204| Step: 0
Training loss: 1.8896844387054443
Validation loss: 2.148067166407903

Epoch: 5| Step: 1
Training loss: 2.079127073287964
Validation loss: 2.1500964363416037

Epoch: 5| Step: 2
Training loss: 1.7901251316070557
Validation loss: 2.1467152138551078

Epoch: 5| Step: 3
Training loss: 1.5583454370498657
Validation loss: 2.1708325843016305

Epoch: 5| Step: 4
Training loss: 2.825706958770752
Validation loss: 2.157065525650978

Epoch: 5| Step: 5
Training loss: 1.6104507446289062
Validation loss: 2.1573267728090286

Epoch: 5| Step: 6
Training loss: 1.8570709228515625
Validation loss: 2.141528755426407

Epoch: 5| Step: 7
Training loss: 1.6689555644989014
Validation loss: 2.1659712294737496

Epoch: 5| Step: 8
Training loss: 2.0155186653137207
Validation loss: 2.1548190663258233

Epoch: 5| Step: 9
Training loss: 1.8163337707519531
Validation loss: 2.173130825161934

Epoch: 5| Step: 10
Training loss: 1.7601686716079712
Validation loss: 2.1699728767077127

Epoch: 5| Step: 11
Training loss: 2.938190460205078
Validation loss: 2.183537075916926

Epoch: 205| Step: 0
Training loss: 1.6652116775512695
Validation loss: 2.1758739054203033

Epoch: 5| Step: 1
Training loss: 1.9566320180892944
Validation loss: 2.1630953500668206

Epoch: 5| Step: 2
Training loss: 1.7835805416107178
Validation loss: 2.1427104274431863

Epoch: 5| Step: 3
Training loss: 1.9713327884674072
Validation loss: 2.138617699344953

Epoch: 5| Step: 4
Training loss: 1.9026386737823486
Validation loss: 2.1365781923135123

Epoch: 5| Step: 5
Training loss: 2.4432859420776367
Validation loss: 2.1218524624904

Epoch: 5| Step: 6
Training loss: 1.7622621059417725
Validation loss: 2.1323993603388467

Epoch: 5| Step: 7
Training loss: 2.1557724475860596
Validation loss: 2.1386696149905524

Epoch: 5| Step: 8
Training loss: 2.162501811981201
Validation loss: 2.143491799632708

Epoch: 5| Step: 9
Training loss: 1.6456623077392578
Validation loss: 2.1347969273726144

Epoch: 5| Step: 10
Training loss: 2.0835893154144287
Validation loss: 2.1307455748319626

Epoch: 5| Step: 11
Training loss: 1.8618499040603638
Validation loss: 2.1309618254502616

Epoch: 206| Step: 0
Training loss: 2.085965394973755
Validation loss: 2.1453807850678763

Epoch: 5| Step: 1
Training loss: 2.2739830017089844
Validation loss: 2.1453518867492676

Epoch: 5| Step: 2
Training loss: 2.663759708404541
Validation loss: 2.1432083447774253

Epoch: 5| Step: 3
Training loss: 2.102539539337158
Validation loss: 2.1488350927829742

Epoch: 5| Step: 4
Training loss: 1.7775192260742188
Validation loss: 2.1536984046300254

Epoch: 5| Step: 5
Training loss: 1.5566178560256958
Validation loss: 2.1625977804263434

Epoch: 5| Step: 6
Training loss: 1.307138204574585
Validation loss: 2.183339148759842

Epoch: 5| Step: 7
Training loss: 1.4425780773162842
Validation loss: 2.186208412051201

Epoch: 5| Step: 8
Training loss: 1.8851391077041626
Validation loss: 2.1680292387803397

Epoch: 5| Step: 9
Training loss: 1.995732069015503
Validation loss: 2.194220463434855

Epoch: 5| Step: 10
Training loss: 2.2300143241882324
Validation loss: 2.182851900657018

Epoch: 5| Step: 11
Training loss: 1.4961788654327393
Validation loss: 2.1991587976614633

Epoch: 207| Step: 0
Training loss: 2.043548583984375
Validation loss: 2.190254434943199

Epoch: 5| Step: 1
Training loss: 1.7227973937988281
Validation loss: 2.184733137488365

Epoch: 5| Step: 2
Training loss: 1.9613056182861328
Validation loss: 2.1569303423166275

Epoch: 5| Step: 3
Training loss: 1.6513904333114624
Validation loss: 2.176800991098086

Epoch: 5| Step: 4
Training loss: 1.9769642353057861
Validation loss: 2.15175029138724

Epoch: 5| Step: 5
Training loss: 2.315822124481201
Validation loss: 2.154328773419062

Epoch: 5| Step: 6
Training loss: 2.6155943870544434
Validation loss: 2.1556993077198663

Epoch: 5| Step: 7
Training loss: 1.2725117206573486
Validation loss: 2.1413683593273163

Epoch: 5| Step: 8
Training loss: 1.9625213146209717
Validation loss: 2.162698765595754

Epoch: 5| Step: 9
Training loss: 1.7820770740509033
Validation loss: 2.1555556058883667

Epoch: 5| Step: 10
Training loss: 2.2418723106384277
Validation loss: 2.1669084280729294

Epoch: 5| Step: 11
Training loss: 1.4188069105148315
Validation loss: 2.16796767214934

Epoch: 208| Step: 0
Training loss: 1.915798544883728
Validation loss: 2.163702686627706

Epoch: 5| Step: 1
Training loss: 1.1663511991500854
Validation loss: 2.1500880817572274

Epoch: 5| Step: 2
Training loss: 2.250471591949463
Validation loss: 2.156610906124115

Epoch: 5| Step: 3
Training loss: 1.9110904932022095
Validation loss: 2.1573896954456964

Epoch: 5| Step: 4
Training loss: 1.8078092336654663
Validation loss: 2.1760013749202094

Epoch: 5| Step: 5
Training loss: 1.4596214294433594
Validation loss: 2.1740580896536508

Epoch: 5| Step: 6
Training loss: 2.5025887489318848
Validation loss: 2.1765955984592438

Epoch: 5| Step: 7
Training loss: 1.9199368953704834
Validation loss: 2.192377587159475

Epoch: 5| Step: 8
Training loss: 2.405517578125
Validation loss: 2.155070722103119

Epoch: 5| Step: 9
Training loss: 2.297508716583252
Validation loss: 2.148612459500631

Epoch: 5| Step: 10
Training loss: 1.8393802642822266
Validation loss: 2.151306410630544

Epoch: 5| Step: 11
Training loss: 2.6078758239746094
Validation loss: 2.1351770559946694

Epoch: 209| Step: 0
Training loss: 2.027268171310425
Validation loss: 2.1220546464125314

Epoch: 5| Step: 1
Training loss: 1.999969482421875
Validation loss: 2.1136768460273743

Epoch: 5| Step: 2
Training loss: 1.9529949426651
Validation loss: 2.1137975255648294

Epoch: 5| Step: 3
Training loss: 1.780700445175171
Validation loss: 2.1282500525315604

Epoch: 5| Step: 4
Training loss: 1.8985626697540283
Validation loss: 2.1342133631308875

Epoch: 5| Step: 5
Training loss: 2.1860241889953613
Validation loss: 2.1289875507354736

Epoch: 5| Step: 6
Training loss: 2.393040180206299
Validation loss: 2.1374133924643197

Epoch: 5| Step: 7
Training loss: 2.40773606300354
Validation loss: 2.132730190952619

Epoch: 5| Step: 8
Training loss: 2.1400558948516846
Validation loss: 2.129810944199562

Epoch: 5| Step: 9
Training loss: 2.0053584575653076
Validation loss: 2.1326232254505157

Epoch: 5| Step: 10
Training loss: 2.0124881267547607
Validation loss: 2.124521921078364

Epoch: 5| Step: 11
Training loss: 1.087369441986084
Validation loss: 2.119653105735779

Epoch: 210| Step: 0
Training loss: 1.6315295696258545
Validation loss: 2.12649874885877

Epoch: 5| Step: 1
Training loss: 1.5088908672332764
Validation loss: 2.125043903787931

Epoch: 5| Step: 2
Training loss: 2.373323917388916
Validation loss: 2.1211181978384652

Epoch: 5| Step: 3
Training loss: 1.9520076513290405
Validation loss: 2.1168735176324844

Epoch: 5| Step: 4
Training loss: 2.4671003818511963
Validation loss: 2.1167257726192474

Epoch: 5| Step: 5
Training loss: 2.3627889156341553
Validation loss: 2.1341662108898163

Epoch: 5| Step: 6
Training loss: 1.9507944583892822
Validation loss: 2.1296032667160034

Epoch: 5| Step: 7
Training loss: 1.3567613363265991
Validation loss: 2.1411273777484894

Epoch: 5| Step: 8
Training loss: 2.3141465187072754
Validation loss: 2.1498774737119675

Epoch: 5| Step: 9
Training loss: 2.0186030864715576
Validation loss: 2.1846115390459695

Epoch: 5| Step: 10
Training loss: 2.1615655422210693
Validation loss: 2.192048047979673

Epoch: 5| Step: 11
Training loss: 1.4911069869995117
Validation loss: 2.1775814294815063

Epoch: 211| Step: 0
Training loss: 2.2003731727600098
Validation loss: 2.2056812047958374

Epoch: 5| Step: 1
Training loss: 2.190326690673828
Validation loss: 2.212348366777102

Epoch: 5| Step: 2
Training loss: 1.3032270669937134
Validation loss: 2.192373221119245

Epoch: 5| Step: 3
Training loss: 1.705592155456543
Validation loss: 2.203615273038546

Epoch: 5| Step: 4
Training loss: 2.2199883460998535
Validation loss: 2.198193992177645

Epoch: 5| Step: 5
Training loss: 2.084188222885132
Validation loss: 2.2081243991851807

Epoch: 5| Step: 6
Training loss: 1.6657164096832275
Validation loss: 2.193853701154391

Epoch: 5| Step: 7
Training loss: 2.1595964431762695
Validation loss: 2.1918058594067893

Epoch: 5| Step: 8
Training loss: 1.8149579763412476
Validation loss: 2.1620240410168967

Epoch: 5| Step: 9
Training loss: 1.6815789937973022
Validation loss: 2.163477490345637

Epoch: 5| Step: 10
Training loss: 2.1014583110809326
Validation loss: 2.163427397608757

Epoch: 5| Step: 11
Training loss: 2.238719940185547
Validation loss: 2.146163046360016

Epoch: 212| Step: 0
Training loss: 1.5127032995224
Validation loss: 2.131486768523852

Epoch: 5| Step: 1
Training loss: 2.3826022148132324
Validation loss: 2.1472101459900537

Epoch: 5| Step: 2
Training loss: 2.438370943069458
Validation loss: 2.1288550794124603

Epoch: 5| Step: 3
Training loss: 1.9661060571670532
Validation loss: 2.1185076286395392

Epoch: 5| Step: 4
Training loss: 1.6171525716781616
Validation loss: 2.1203552981217704

Epoch: 5| Step: 5
Training loss: 1.3889448642730713
Validation loss: 2.117643197377523

Epoch: 5| Step: 6
Training loss: 2.0767722129821777
Validation loss: 2.125832969943682

Epoch: 5| Step: 7
Training loss: 2.329707622528076
Validation loss: 2.1238835801680884

Epoch: 5| Step: 8
Training loss: 1.9109958410263062
Validation loss: 2.1239691277345023

Epoch: 5| Step: 9
Training loss: 1.9731066226959229
Validation loss: 2.1243380308151245

Epoch: 5| Step: 10
Training loss: 2.263188362121582
Validation loss: 2.141716182231903

Epoch: 5| Step: 11
Training loss: 1.3291137218475342
Validation loss: 2.1483840495347977

Epoch: 213| Step: 0
Training loss: 1.638841986656189
Validation loss: 2.170799637834231

Epoch: 5| Step: 1
Training loss: 1.9265167713165283
Validation loss: 2.1870843370755515

Epoch: 5| Step: 2
Training loss: 1.6465955972671509
Validation loss: 2.1741460164388022

Epoch: 5| Step: 3
Training loss: 1.7433345317840576
Validation loss: 2.21702042222023

Epoch: 5| Step: 4
Training loss: 1.8451783657073975
Validation loss: 2.190316687027613

Epoch: 5| Step: 5
Training loss: 1.5974057912826538
Validation loss: 2.200981726249059

Epoch: 5| Step: 6
Training loss: 2.157822370529175
Validation loss: 2.1879135370254517

Epoch: 5| Step: 7
Training loss: 1.943198561668396
Validation loss: 2.1801050355037055

Epoch: 5| Step: 8
Training loss: 2.4583194255828857
Validation loss: 2.1907107134660087

Epoch: 5| Step: 9
Training loss: 2.0176706314086914
Validation loss: 2.1824598213036857

Epoch: 5| Step: 10
Training loss: 1.9787635803222656
Validation loss: 2.1662724912166595

Epoch: 5| Step: 11
Training loss: 2.2066783905029297
Validation loss: 2.170302703976631

Epoch: 214| Step: 0
Training loss: 2.063249111175537
Validation loss: 2.163138379653295

Epoch: 5| Step: 1
Training loss: 1.6649011373519897
Validation loss: 2.1404043436050415

Epoch: 5| Step: 2
Training loss: 1.8056541681289673
Validation loss: 2.1594089716672897

Epoch: 5| Step: 3
Training loss: 1.7252651453018188
Validation loss: 2.14500193297863

Epoch: 5| Step: 4
Training loss: 2.055840253829956
Validation loss: 2.1659279614686966

Epoch: 5| Step: 5
Training loss: 1.6666895151138306
Validation loss: 2.1528382102648416

Epoch: 5| Step: 6
Training loss: 1.5921084880828857
Validation loss: 2.1453659385442734

Epoch: 5| Step: 7
Training loss: 2.083361864089966
Validation loss: 2.153823966781298

Epoch: 5| Step: 8
Training loss: 1.8285611867904663
Validation loss: 2.1496066798766456

Epoch: 5| Step: 9
Training loss: 2.4218859672546387
Validation loss: 2.148778423666954

Epoch: 5| Step: 10
Training loss: 2.058244228363037
Validation loss: 2.1586232284704843

Epoch: 5| Step: 11
Training loss: 3.761570453643799
Validation loss: 2.1494656602541604

Epoch: 215| Step: 0
Training loss: 1.421985387802124
Validation loss: 2.15984013179938

Epoch: 5| Step: 1
Training loss: 2.334902048110962
Validation loss: 2.143579622109731

Epoch: 5| Step: 2
Training loss: 2.241879463195801
Validation loss: 2.153511092066765

Epoch: 5| Step: 3
Training loss: 1.524871587753296
Validation loss: 2.17053060233593

Epoch: 5| Step: 4
Training loss: 1.5128238201141357
Validation loss: 2.160372336705526

Epoch: 5| Step: 5
Training loss: 2.127640724182129
Validation loss: 2.1580549478530884

Epoch: 5| Step: 6
Training loss: 2.223304033279419
Validation loss: 2.1786915411551795

Epoch: 5| Step: 7
Training loss: 1.9712772369384766
Validation loss: 2.1803723822037377

Epoch: 5| Step: 8
Training loss: 2.21158504486084
Validation loss: 2.1760498384634652

Epoch: 5| Step: 9
Training loss: 1.7548065185546875
Validation loss: 2.170777147014936

Epoch: 5| Step: 10
Training loss: 2.123929023742676
Validation loss: 2.1595471650362015

Epoch: 5| Step: 11
Training loss: 1.0030848979949951
Validation loss: 2.1590401083230972

Epoch: 216| Step: 0
Training loss: 1.791285753250122
Validation loss: 2.156291678547859

Epoch: 5| Step: 1
Training loss: 1.9202067852020264
Validation loss: 2.1579344669977822

Epoch: 5| Step: 2
Training loss: 2.4305782318115234
Validation loss: 2.1309892187515893

Epoch: 5| Step: 3
Training loss: 1.8827121257781982
Validation loss: 2.133110279838244

Epoch: 5| Step: 4
Training loss: 2.112048864364624
Validation loss: 2.136737585067749

Epoch: 5| Step: 5
Training loss: 2.1324007511138916
Validation loss: 2.1469250520070395

Epoch: 5| Step: 6
Training loss: 1.4088551998138428
Validation loss: 2.1391918708880744

Epoch: 5| Step: 7
Training loss: 1.622471809387207
Validation loss: 2.158338854710261

Epoch: 5| Step: 8
Training loss: 2.4974918365478516
Validation loss: 2.161218156417211

Epoch: 5| Step: 9
Training loss: 1.7982136011123657
Validation loss: 2.1809141536553702

Epoch: 5| Step: 10
Training loss: 1.7168928384780884
Validation loss: 2.1758040289084115

Epoch: 5| Step: 11
Training loss: 1.421029806137085
Validation loss: 2.1686231046915054

Epoch: 217| Step: 0
Training loss: 1.8831024169921875
Validation loss: 2.185300966103872

Epoch: 5| Step: 1
Training loss: 1.799594521522522
Validation loss: 2.1866001139084497

Epoch: 5| Step: 2
Training loss: 1.8536088466644287
Validation loss: 2.1780312110980353

Epoch: 5| Step: 3
Training loss: 1.7300083637237549
Validation loss: 2.173539231220881

Epoch: 5| Step: 4
Training loss: 2.075883388519287
Validation loss: 2.186525136232376

Epoch: 5| Step: 5
Training loss: 1.5958225727081299
Validation loss: 2.1824036141236625

Epoch: 5| Step: 6
Training loss: 2.0323123931884766
Validation loss: 2.1674316922823587

Epoch: 5| Step: 7
Training loss: 2.005146026611328
Validation loss: 2.1919132272402444

Epoch: 5| Step: 8
Training loss: 1.900846242904663
Validation loss: 2.1985873182614646

Epoch: 5| Step: 9
Training loss: 1.9048271179199219
Validation loss: 2.1939974427223206

Epoch: 5| Step: 10
Training loss: 1.591092824935913
Validation loss: 2.1842053830623627

Epoch: 5| Step: 11
Training loss: 3.037073850631714
Validation loss: 2.180219382047653

Epoch: 218| Step: 0
Training loss: 2.297851085662842
Validation loss: 2.190727790196737

Epoch: 5| Step: 1
Training loss: 2.2002978324890137
Validation loss: 2.1787139028310776

Epoch: 5| Step: 2
Training loss: 1.5648740530014038
Validation loss: 2.174283747871717

Epoch: 5| Step: 3
Training loss: 1.8850101232528687
Validation loss: 2.173778702815374

Epoch: 5| Step: 4
Training loss: 1.954392671585083
Validation loss: 2.1751612474521003

Epoch: 5| Step: 5
Training loss: 1.718590497970581
Validation loss: 2.1805590242147446

Epoch: 5| Step: 6
Training loss: 2.5439839363098145
Validation loss: 2.174351821343104

Epoch: 5| Step: 7
Training loss: 1.9912388324737549
Validation loss: 2.173945516347885

Epoch: 5| Step: 8
Training loss: 1.2661526203155518
Validation loss: 2.1683988024791083

Epoch: 5| Step: 9
Training loss: 1.7045667171478271
Validation loss: 2.178845743338267

Epoch: 5| Step: 10
Training loss: 1.4068180322647095
Validation loss: 2.1619173884391785

Epoch: 5| Step: 11
Training loss: 2.046548843383789
Validation loss: 2.191797931989034

Epoch: 219| Step: 0
Training loss: 1.631453275680542
Validation loss: 2.209584722916285

Epoch: 5| Step: 1
Training loss: 1.7430588006973267
Validation loss: 2.2212051848570504

Epoch: 5| Step: 2
Training loss: 2.1469619274139404
Validation loss: 2.2204531133174896

Epoch: 5| Step: 3
Training loss: 2.000612497329712
Validation loss: 2.2151391406853995

Epoch: 5| Step: 4
Training loss: 1.8738758563995361
Validation loss: 2.2178844114144645

Epoch: 5| Step: 5
Training loss: 2.1057732105255127
Validation loss: 2.2083813548088074

Epoch: 5| Step: 6
Training loss: 1.794338583946228
Validation loss: 2.200017213821411

Epoch: 5| Step: 7
Training loss: 1.8752071857452393
Validation loss: 2.208842545747757

Epoch: 5| Step: 8
Training loss: 1.9605615139007568
Validation loss: 2.1879245142141976

Epoch: 5| Step: 9
Training loss: 1.95327627658844
Validation loss: 2.1987749437491098

Epoch: 5| Step: 10
Training loss: 1.3714821338653564
Validation loss: 2.1996726046005883

Epoch: 5| Step: 11
Training loss: 2.4909400939941406
Validation loss: 2.173586626847585

Epoch: 220| Step: 0
Training loss: 2.358574151992798
Validation loss: 2.2073350846767426

Epoch: 5| Step: 1
Training loss: 1.799634575843811
Validation loss: 2.1937291820844016

Epoch: 5| Step: 2
Training loss: 1.5249910354614258
Validation loss: 2.1963417331377664

Epoch: 5| Step: 3
Training loss: 1.791187047958374
Validation loss: 2.2069179117679596

Epoch: 5| Step: 4
Training loss: 1.9265506267547607
Validation loss: 2.1837224612633386

Epoch: 5| Step: 5
Training loss: 2.375629425048828
Validation loss: 2.2061005383729935

Epoch: 5| Step: 6
Training loss: 1.9373652935028076
Validation loss: 2.2128020574649176

Epoch: 5| Step: 7
Training loss: 1.6454540491104126
Validation loss: 2.2109362930059433

Epoch: 5| Step: 8
Training loss: 2.265346050262451
Validation loss: 2.2017722129821777

Epoch: 5| Step: 9
Training loss: 1.3616533279418945
Validation loss: 2.2149508893489838

Epoch: 5| Step: 10
Training loss: 1.7765216827392578
Validation loss: 2.217027008533478

Epoch: 5| Step: 11
Training loss: 0.9078859686851501
Validation loss: 2.227105751633644

Epoch: 221| Step: 0
Training loss: 1.9442822933197021
Validation loss: 2.2213280498981476

Epoch: 5| Step: 1
Training loss: 1.6284462213516235
Validation loss: 2.219070722659429

Epoch: 5| Step: 2
Training loss: 1.6463207006454468
Validation loss: 2.2082344790299735

Epoch: 5| Step: 3
Training loss: 2.515707492828369
Validation loss: 2.220878392457962

Epoch: 5| Step: 4
Training loss: 1.7660890817642212
Validation loss: 2.210064192612966

Epoch: 5| Step: 5
Training loss: 2.5397746562957764
Validation loss: 2.2069271206855774

Epoch: 5| Step: 6
Training loss: 1.4597885608673096
Validation loss: 2.1813550889492035

Epoch: 5| Step: 7
Training loss: 2.1775970458984375
Validation loss: 2.1896113008260727

Epoch: 5| Step: 8
Training loss: 1.8092056512832642
Validation loss: 2.1651542633771896

Epoch: 5| Step: 9
Training loss: 1.6364517211914062
Validation loss: 2.188021724422773

Epoch: 5| Step: 10
Training loss: 1.3016347885131836
Validation loss: 2.181378329793612

Epoch: 5| Step: 11
Training loss: 3.0019454956054688
Validation loss: 2.1894572377204895

Epoch: 222| Step: 0
Training loss: 2.3696208000183105
Validation loss: 2.1825234989325204

Epoch: 5| Step: 1
Training loss: 1.8718793392181396
Validation loss: 2.215945233901342

Epoch: 5| Step: 2
Training loss: 1.900456190109253
Validation loss: 2.1821796695391336

Epoch: 5| Step: 3
Training loss: 1.4839693307876587
Validation loss: 2.1928883095582328

Epoch: 5| Step: 4
Training loss: 1.314072847366333
Validation loss: 2.221847881873449

Epoch: 5| Step: 5
Training loss: 1.4642921686172485
Validation loss: 2.20039568344752

Epoch: 5| Step: 6
Training loss: 1.4241043329238892
Validation loss: 2.217320442199707

Epoch: 5| Step: 7
Training loss: 2.9461381435394287
Validation loss: 2.213318328062693

Epoch: 5| Step: 8
Training loss: 2.074259042739868
Validation loss: 2.192482282718023

Epoch: 5| Step: 9
Training loss: 1.953762412071228
Validation loss: 2.1926819880803428

Epoch: 5| Step: 10
Training loss: 1.9805580377578735
Validation loss: 2.1827499121427536

Epoch: 5| Step: 11
Training loss: 2.405822277069092
Validation loss: 2.1744344383478165

Epoch: 223| Step: 0
Training loss: 2.550234317779541
Validation loss: 2.1723754604657493

Epoch: 5| Step: 1
Training loss: 1.8580443859100342
Validation loss: 2.174531320730845

Epoch: 5| Step: 2
Training loss: 1.5326398611068726
Validation loss: 2.172529697418213

Epoch: 5| Step: 3
Training loss: 1.6308879852294922
Validation loss: 2.186410109202067

Epoch: 5| Step: 4
Training loss: 1.8186460733413696
Validation loss: 2.187638133764267

Epoch: 5| Step: 5
Training loss: 1.769925832748413
Validation loss: 2.203250522414843

Epoch: 5| Step: 6
Training loss: 1.869127869606018
Validation loss: 2.1934391111135483

Epoch: 5| Step: 7
Training loss: 1.7395318746566772
Validation loss: 2.184757878383001

Epoch: 5| Step: 8
Training loss: 1.8733974695205688
Validation loss: 2.1933323989311853

Epoch: 5| Step: 9
Training loss: 1.8814847469329834
Validation loss: 2.1967389980951944

Epoch: 5| Step: 10
Training loss: 1.8190587759017944
Validation loss: 2.1787573595841727

Epoch: 5| Step: 11
Training loss: 2.1188058853149414
Validation loss: 2.197404553492864

Epoch: 224| Step: 0
Training loss: 2.428525447845459
Validation loss: 2.1953707486391068

Epoch: 5| Step: 1
Training loss: 1.4330869913101196
Validation loss: 2.201017220815023

Epoch: 5| Step: 2
Training loss: 1.5873146057128906
Validation loss: 2.192629704872767

Epoch: 5| Step: 3
Training loss: 2.126185655593872
Validation loss: 2.1810327967007956

Epoch: 5| Step: 4
Training loss: 1.7340099811553955
Validation loss: 2.183091397086779

Epoch: 5| Step: 5
Training loss: 1.7481063604354858
Validation loss: 2.194760243097941

Epoch: 5| Step: 6
Training loss: 1.7125847339630127
Validation loss: 2.1902843912442527

Epoch: 5| Step: 7
Training loss: 2.333317279815674
Validation loss: 2.1840789218743644

Epoch: 5| Step: 8
Training loss: 1.8682187795639038
Validation loss: 2.1773408899704614

Epoch: 5| Step: 9
Training loss: 1.681654930114746
Validation loss: 2.1857444445292153

Epoch: 5| Step: 10
Training loss: 1.436094045639038
Validation loss: 2.1827183167139688

Epoch: 5| Step: 11
Training loss: 2.956151247024536
Validation loss: 2.185382679104805

Epoch: 225| Step: 0
Training loss: 2.374272346496582
Validation loss: 2.184419865409533

Epoch: 5| Step: 1
Training loss: 1.4513700008392334
Validation loss: 2.1875657190879187

Epoch: 5| Step: 2
Training loss: 1.524440884590149
Validation loss: 2.204983731110891

Epoch: 5| Step: 3
Training loss: 2.380531072616577
Validation loss: 2.1762907604376474

Epoch: 5| Step: 4
Training loss: 2.1077003479003906
Validation loss: 2.1575454274813333

Epoch: 5| Step: 5
Training loss: 1.5623395442962646
Validation loss: 2.1692419747511544

Epoch: 5| Step: 6
Training loss: 1.8135769367218018
Validation loss: 2.1989429195721946

Epoch: 5| Step: 7
Training loss: 1.855841040611267
Validation loss: 2.1841649413108826

Epoch: 5| Step: 8
Training loss: 1.8541609048843384
Validation loss: 2.186087409655253

Epoch: 5| Step: 9
Training loss: 1.7619373798370361
Validation loss: 2.1968570351600647

Epoch: 5| Step: 10
Training loss: 1.666213035583496
Validation loss: 2.1930117706457772

Epoch: 5| Step: 11
Training loss: 2.011068105697632
Validation loss: 2.183137387037277

Epoch: 226| Step: 0
Training loss: 2.02260422706604
Validation loss: 2.203480819861094

Epoch: 5| Step: 1
Training loss: 1.6369701623916626
Validation loss: 2.189130042990049

Epoch: 5| Step: 2
Training loss: 1.7800664901733398
Validation loss: 2.176637649536133

Epoch: 5| Step: 3
Training loss: 2.371856212615967
Validation loss: 2.194721261660258

Epoch: 5| Step: 4
Training loss: 2.0182414054870605
Validation loss: 2.201679935057958

Epoch: 5| Step: 5
Training loss: 1.6086781024932861
Validation loss: 2.1920129458109536

Epoch: 5| Step: 6
Training loss: 1.6611459255218506
Validation loss: 2.192620982726415

Epoch: 5| Step: 7
Training loss: 1.8399546146392822
Validation loss: 2.1826714823643365

Epoch: 5| Step: 8
Training loss: 1.7647590637207031
Validation loss: 2.182963490486145

Epoch: 5| Step: 9
Training loss: 1.7832143306732178
Validation loss: 2.184082751472791

Epoch: 5| Step: 10
Training loss: 1.6406959295272827
Validation loss: 2.184961477915446

Epoch: 5| Step: 11
Training loss: 2.631300687789917
Validation loss: 2.186339239279429

Epoch: 227| Step: 0
Training loss: 1.7941749095916748
Validation loss: 2.1844679017861686

Epoch: 5| Step: 1
Training loss: 2.442507266998291
Validation loss: 2.18557608127594

Epoch: 5| Step: 2
Training loss: 2.2248973846435547
Validation loss: 2.1953858137130737

Epoch: 5| Step: 3
Training loss: 1.6119022369384766
Validation loss: 2.2025126218795776

Epoch: 5| Step: 4
Training loss: 1.4998115301132202
Validation loss: 2.2015519539515176

Epoch: 5| Step: 5
Training loss: 1.972945213317871
Validation loss: 2.1936107675234475

Epoch: 5| Step: 6
Training loss: 1.6976665258407593
Validation loss: 2.2017616828282676

Epoch: 5| Step: 7
Training loss: 2.120713949203491
Validation loss: 2.203200494249662

Epoch: 5| Step: 8
Training loss: 2.2338314056396484
Validation loss: 2.1876714328924813

Epoch: 5| Step: 9
Training loss: 1.5632892847061157
Validation loss: 2.1923440198103585

Epoch: 5| Step: 10
Training loss: 1.1442320346832275
Validation loss: 2.1807920038700104

Epoch: 5| Step: 11
Training loss: 1.6552948951721191
Validation loss: 2.1884842912356057

Epoch: 228| Step: 0
Training loss: 1.5850855112075806
Validation loss: 2.1872015794118247

Epoch: 5| Step: 1
Training loss: 1.5577279329299927
Validation loss: 2.206123794118563

Epoch: 5| Step: 2
Training loss: 1.8894582986831665
Validation loss: 2.20435539384683

Epoch: 5| Step: 3
Training loss: 2.161425828933716
Validation loss: 2.1896376659472785

Epoch: 5| Step: 4
Training loss: 1.275526762008667
Validation loss: 2.187897135814031

Epoch: 5| Step: 5
Training loss: 1.7353827953338623
Validation loss: 2.1939634531736374

Epoch: 5| Step: 6
Training loss: 2.076603412628174
Validation loss: 2.204363837838173

Epoch: 5| Step: 7
Training loss: 2.0877397060394287
Validation loss: 2.1830629954735437

Epoch: 5| Step: 8
Training loss: 2.037376642227173
Validation loss: 2.186273122827212

Epoch: 5| Step: 9
Training loss: 2.2620129585266113
Validation loss: 2.1999587267637253

Epoch: 5| Step: 10
Training loss: 1.9406521320343018
Validation loss: 2.1853539645671844

Epoch: 5| Step: 11
Training loss: 1.4264260530471802
Validation loss: 2.1866221725940704

Epoch: 229| Step: 0
Training loss: 2.3424265384674072
Validation loss: 2.186030238866806

Epoch: 5| Step: 1
Training loss: 2.192594528198242
Validation loss: 2.1884269962708154

Epoch: 5| Step: 2
Training loss: 1.590449571609497
Validation loss: 2.190061718225479

Epoch: 5| Step: 3
Training loss: 1.801915168762207
Validation loss: 2.198096921046575

Epoch: 5| Step: 4
Training loss: 1.7444225549697876
Validation loss: 2.1953461468219757

Epoch: 5| Step: 5
Training loss: 1.8029983043670654
Validation loss: 2.1782718896865845

Epoch: 5| Step: 6
Training loss: 1.9869756698608398
Validation loss: 2.1997713843981423

Epoch: 5| Step: 7
Training loss: 1.7438561916351318
Validation loss: 2.1974551578362784

Epoch: 5| Step: 8
Training loss: 1.5541887283325195
Validation loss: 2.1829920510450997

Epoch: 5| Step: 9
Training loss: 2.128603219985962
Validation loss: 2.1821416914463043

Epoch: 5| Step: 10
Training loss: 1.7530205249786377
Validation loss: 2.187536264459292

Epoch: 5| Step: 11
Training loss: 0.9743095636367798
Validation loss: 2.1954346199830375

Epoch: 230| Step: 0
Training loss: 1.9729087352752686
Validation loss: 2.190452128648758

Epoch: 5| Step: 1
Training loss: 1.5871937274932861
Validation loss: 2.176200474301974

Epoch: 5| Step: 2
Training loss: 1.5660966634750366
Validation loss: 2.1874946653842926

Epoch: 5| Step: 3
Training loss: 1.915684700012207
Validation loss: 2.1794757594664893

Epoch: 5| Step: 4
Training loss: 2.0816352367401123
Validation loss: 2.1792567123969397

Epoch: 5| Step: 5
Training loss: 1.8855053186416626
Validation loss: 2.198068787654241

Epoch: 5| Step: 6
Training loss: 1.7926985025405884
Validation loss: 2.1828300257523856

Epoch: 5| Step: 7
Training loss: 1.835119605064392
Validation loss: 2.184072256088257

Epoch: 5| Step: 8
Training loss: 1.8458877801895142
Validation loss: 2.17801142235597

Epoch: 5| Step: 9
Training loss: 1.750463843345642
Validation loss: 2.1792059938112893

Epoch: 5| Step: 10
Training loss: 2.1668994426727295
Validation loss: 2.1952917923529944

Epoch: 5| Step: 11
Training loss: 1.8206825256347656
Validation loss: 2.21286341547966

Epoch: 231| Step: 0
Training loss: 2.5242652893066406
Validation loss: 2.2092623511950173

Epoch: 5| Step: 1
Training loss: 2.36108660697937
Validation loss: 2.2494367510080338

Epoch: 5| Step: 2
Training loss: 1.7801437377929688
Validation loss: 2.2473213970661163

Epoch: 5| Step: 3
Training loss: 1.4818663597106934
Validation loss: 2.2412693897883096

Epoch: 5| Step: 4
Training loss: 1.792301893234253
Validation loss: 2.249182472626368

Epoch: 5| Step: 5
Training loss: 2.2140212059020996
Validation loss: 2.278856784105301

Epoch: 5| Step: 6
Training loss: 1.57368803024292
Validation loss: 2.2660139401753745

Epoch: 5| Step: 7
Training loss: 1.6992976665496826
Validation loss: 2.270291527112325

Epoch: 5| Step: 8
Training loss: 1.2285645008087158
Validation loss: 2.2500879615545273

Epoch: 5| Step: 9
Training loss: 1.8551315069198608
Validation loss: 2.2539394001166024

Epoch: 5| Step: 10
Training loss: 2.1918959617614746
Validation loss: 2.236264631152153

Epoch: 5| Step: 11
Training loss: 2.8053534030914307
Validation loss: 2.2226416965325675

Epoch: 232| Step: 0
Training loss: 2.052150011062622
Validation loss: 2.2291848162810006

Epoch: 5| Step: 1
Training loss: 1.5234206914901733
Validation loss: 2.215764065583547

Epoch: 5| Step: 2
Training loss: 1.9631719589233398
Validation loss: 2.187103802959124

Epoch: 5| Step: 3
Training loss: 1.6302921772003174
Validation loss: 2.1825540562470755

Epoch: 5| Step: 4
Training loss: 1.7684510946273804
Validation loss: 2.1682223975658417

Epoch: 5| Step: 5
Training loss: 2.0403409004211426
Validation loss: 2.1557899117469788

Epoch: 5| Step: 6
Training loss: 1.8410640954971313
Validation loss: 2.1613696167866387

Epoch: 5| Step: 7
Training loss: 1.647660255432129
Validation loss: 2.1654679477214813

Epoch: 5| Step: 8
Training loss: 1.947191834449768
Validation loss: 2.178126702706019

Epoch: 5| Step: 9
Training loss: 2.031747341156006
Validation loss: 2.1819465657075248

Epoch: 5| Step: 10
Training loss: 2.2091641426086426
Validation loss: 2.2046156227588654

Epoch: 5| Step: 11
Training loss: 2.6829135417938232
Validation loss: 2.1937437852223716

Epoch: 233| Step: 0
Training loss: 1.8658373355865479
Validation loss: 2.211176723241806

Epoch: 5| Step: 1
Training loss: 1.536531925201416
Validation loss: 2.2061112572749457

Epoch: 5| Step: 2
Training loss: 1.3996502161026
Validation loss: 2.199120764931043

Epoch: 5| Step: 3
Training loss: 1.8313934803009033
Validation loss: 2.226553683479627

Epoch: 5| Step: 4
Training loss: 1.7178453207015991
Validation loss: 2.1937593867381415

Epoch: 5| Step: 5
Training loss: 1.926429033279419
Validation loss: 2.1948765168587365

Epoch: 5| Step: 6
Training loss: 2.4176440238952637
Validation loss: 2.186211407184601

Epoch: 5| Step: 7
Training loss: 1.5316851139068604
Validation loss: 2.18258069952329

Epoch: 5| Step: 8
Training loss: 1.657436728477478
Validation loss: 2.1783291647831597

Epoch: 5| Step: 9
Training loss: 2.0787758827209473
Validation loss: 2.1705577969551086

Epoch: 5| Step: 10
Training loss: 2.4264378547668457
Validation loss: 2.162042627731959

Epoch: 5| Step: 11
Training loss: 2.5289816856384277
Validation loss: 2.1762778908014297

Epoch: 234| Step: 0
Training loss: 1.4258149862289429
Validation loss: 2.1520620783170066

Epoch: 5| Step: 1
Training loss: 1.8689610958099365
Validation loss: 2.1575272579987845

Epoch: 5| Step: 2
Training loss: 2.961085796356201
Validation loss: 2.1704222708940506

Epoch: 5| Step: 3
Training loss: 2.071430206298828
Validation loss: 2.1622073700030646

Epoch: 5| Step: 4
Training loss: 1.7687221765518188
Validation loss: 2.1655873159567514

Epoch: 5| Step: 5
Training loss: 1.844058632850647
Validation loss: 2.1773924032847085

Epoch: 5| Step: 6
Training loss: 1.293320655822754
Validation loss: 2.1874748865763345

Epoch: 5| Step: 7
Training loss: 2.2127139568328857
Validation loss: 2.173963263630867

Epoch: 5| Step: 8
Training loss: 1.773714303970337
Validation loss: 2.1813678046067557

Epoch: 5| Step: 9
Training loss: 1.47165048122406
Validation loss: 2.2070934921503067

Epoch: 5| Step: 10
Training loss: 1.6453170776367188
Validation loss: 2.2113292713960013

Epoch: 5| Step: 11
Training loss: 1.6188523769378662
Validation loss: 2.1989015489816666

Epoch: 235| Step: 0
Training loss: 2.1824841499328613
Validation loss: 2.227224826812744

Epoch: 5| Step: 1
Training loss: 1.9198567867279053
Validation loss: 2.1938181867202124

Epoch: 5| Step: 2
Training loss: 2.1600730419158936
Validation loss: 2.208645393451055

Epoch: 5| Step: 3
Training loss: 1.4250797033309937
Validation loss: 2.1943766425053277

Epoch: 5| Step: 4
Training loss: 1.3961071968078613
Validation loss: 2.2071592658758163

Epoch: 5| Step: 5
Training loss: 2.191847801208496
Validation loss: 2.1945989231268563

Epoch: 5| Step: 6
Training loss: 1.3015110492706299
Validation loss: 2.2078893184661865

Epoch: 5| Step: 7
Training loss: 2.277024269104004
Validation loss: 2.221208930015564

Epoch: 5| Step: 8
Training loss: 2.222703456878662
Validation loss: 2.2416549026966095

Epoch: 5| Step: 9
Training loss: 1.7124042510986328
Validation loss: 2.219959815343221

Epoch: 5| Step: 10
Training loss: 1.407243013381958
Validation loss: 2.2198769549528756

Epoch: 5| Step: 11
Training loss: 0.6846354603767395
Validation loss: 2.225023627281189

Epoch: 236| Step: 0
Training loss: 1.809239149093628
Validation loss: 2.236670956015587

Epoch: 5| Step: 1
Training loss: 1.8211619853973389
Validation loss: 2.234687864780426

Epoch: 5| Step: 2
Training loss: 2.2658255100250244
Validation loss: 2.2327973941961923

Epoch: 5| Step: 3
Training loss: 2.384009838104248
Validation loss: 2.234043096502622

Epoch: 5| Step: 4
Training loss: 1.5818153619766235
Validation loss: 2.221712271372477

Epoch: 5| Step: 5
Training loss: 1.7768332958221436
Validation loss: 2.2018993397553763

Epoch: 5| Step: 6
Training loss: 1.7350581884384155
Validation loss: 2.194765950242678

Epoch: 5| Step: 7
Training loss: 2.0437448024749756
Validation loss: 2.2081325203180313

Epoch: 5| Step: 8
Training loss: 1.4576281309127808
Validation loss: 2.1998182833194733

Epoch: 5| Step: 9
Training loss: 1.7587049007415771
Validation loss: 2.2052589654922485

Epoch: 5| Step: 10
Training loss: 1.9783557653427124
Validation loss: 2.1972277065118155

Epoch: 5| Step: 11
Training loss: 2.6840662956237793
Validation loss: 2.2005572666724524

Epoch: 237| Step: 0
Training loss: 1.8331714868545532
Validation loss: 2.191651374101639

Epoch: 5| Step: 1
Training loss: 2.109602451324463
Validation loss: 2.1871775686740875

Epoch: 5| Step: 2
Training loss: 1.5625900030136108
Validation loss: 2.2093124190966287

Epoch: 5| Step: 3
Training loss: 1.8171117305755615
Validation loss: 2.18566587070624

Epoch: 5| Step: 4
Training loss: 1.9501550197601318
Validation loss: 2.203058362007141

Epoch: 5| Step: 5
Training loss: 1.8254458904266357
Validation loss: 2.2084570229053497

Epoch: 5| Step: 6
Training loss: 1.9279991388320923
Validation loss: 2.2279458145300546

Epoch: 5| Step: 7
Training loss: 1.855487585067749
Validation loss: 2.230036954085032

Epoch: 5| Step: 8
Training loss: 1.7174726724624634
Validation loss: 2.2226266066233316

Epoch: 5| Step: 9
Training loss: 2.1868526935577393
Validation loss: 2.2222672005494437

Epoch: 5| Step: 10
Training loss: 1.3777239322662354
Validation loss: 2.219068725903829

Epoch: 5| Step: 11
Training loss: 1.0101079940795898
Validation loss: 2.204018692175547

Epoch: 238| Step: 0
Training loss: 1.8796360492706299
Validation loss: 2.202652325232824

Epoch: 5| Step: 1
Training loss: 1.3744828701019287
Validation loss: 2.196587155262629

Epoch: 5| Step: 2
Training loss: 1.550586223602295
Validation loss: 2.1873132487138114

Epoch: 5| Step: 3
Training loss: 2.05318021774292
Validation loss: 2.1865256428718567

Epoch: 5| Step: 4
Training loss: 1.7875173091888428
Validation loss: 2.1873183796803155

Epoch: 5| Step: 5
Training loss: 2.4557137489318848
Validation loss: 2.1969817032416663

Epoch: 5| Step: 6
Training loss: 1.8910976648330688
Validation loss: 2.2005937000115714

Epoch: 5| Step: 7
Training loss: 1.9930732250213623
Validation loss: 2.1978692561388016

Epoch: 5| Step: 8
Training loss: 1.5875276327133179
Validation loss: 2.186203603943189

Epoch: 5| Step: 9
Training loss: 1.7565536499023438
Validation loss: 2.2030443598826728

Epoch: 5| Step: 10
Training loss: 1.825465440750122
Validation loss: 2.195516586303711

Epoch: 5| Step: 11
Training loss: 0.8237754106521606
Validation loss: 2.207411656777064

Epoch: 239| Step: 0
Training loss: 1.9903194904327393
Validation loss: 2.204337924718857

Epoch: 5| Step: 1
Training loss: 2.2239811420440674
Validation loss: 2.215221111973127

Epoch: 5| Step: 2
Training loss: 1.9899513721466064
Validation loss: 2.2363104124863944

Epoch: 5| Step: 3
Training loss: 1.3859033584594727
Validation loss: 2.250795731941859

Epoch: 5| Step: 4
Training loss: 1.9962570667266846
Validation loss: 2.259146069486936

Epoch: 5| Step: 5
Training loss: 2.107844829559326
Validation loss: 2.2419388393561044

Epoch: 5| Step: 6
Training loss: 1.1388437747955322
Validation loss: 2.2276530216137567

Epoch: 5| Step: 7
Training loss: 1.4950752258300781
Validation loss: 2.22464257478714

Epoch: 5| Step: 8
Training loss: 2.1554222106933594
Validation loss: 2.2253063519795737

Epoch: 5| Step: 9
Training loss: 1.8352878093719482
Validation loss: 2.2053268949190774

Epoch: 5| Step: 10
Training loss: 1.909424066543579
Validation loss: 2.1903150975704193

Epoch: 5| Step: 11
Training loss: 2.9024410247802734
Validation loss: 2.1886035104592643

Epoch: 240| Step: 0
Training loss: 1.578759789466858
Validation loss: 2.1942282021045685

Epoch: 5| Step: 1
Training loss: 1.8938661813735962
Validation loss: 2.1992944727341333

Epoch: 5| Step: 2
Training loss: 1.8095080852508545
Validation loss: 2.1762084464232125

Epoch: 5| Step: 3
Training loss: 1.7266998291015625
Validation loss: 2.1949907541275024

Epoch: 5| Step: 4
Training loss: 2.130056619644165
Validation loss: 2.2040835916996

Epoch: 5| Step: 5
Training loss: 2.3469526767730713
Validation loss: 2.225178043047587

Epoch: 5| Step: 6
Training loss: 2.0664358139038086
Validation loss: 2.2146680305401483

Epoch: 5| Step: 7
Training loss: 1.59807288646698
Validation loss: 2.2080125510692596

Epoch: 5| Step: 8
Training loss: 1.4006389379501343
Validation loss: 2.205595870812734

Epoch: 5| Step: 9
Training loss: 1.7632068395614624
Validation loss: 2.2042779127756753

Epoch: 5| Step: 10
Training loss: 2.078155755996704
Validation loss: 2.201737940311432

Epoch: 5| Step: 11
Training loss: 0.694511353969574
Validation loss: 2.2084188560644784

Epoch: 241| Step: 0
Training loss: 1.9383630752563477
Validation loss: 2.200551529725393

Epoch: 5| Step: 1
Training loss: 1.9292571544647217
Validation loss: 2.1906287521123886

Epoch: 5| Step: 2
Training loss: 1.317720890045166
Validation loss: 2.2054369350274405

Epoch: 5| Step: 3
Training loss: 2.05949330329895
Validation loss: 2.2108572920163474

Epoch: 5| Step: 4
Training loss: 1.8142191171646118
Validation loss: 2.1924454470475516

Epoch: 5| Step: 5
Training loss: 1.653001070022583
Validation loss: 2.2066583136717477

Epoch: 5| Step: 6
Training loss: 1.253032922744751
Validation loss: 2.1838917086521783

Epoch: 5| Step: 7
Training loss: 2.2878894805908203
Validation loss: 2.1903070211410522

Epoch: 5| Step: 8
Training loss: 2.2087512016296387
Validation loss: 2.190482646226883

Epoch: 5| Step: 9
Training loss: 2.064436197280884
Validation loss: 2.1745732029279075

Epoch: 5| Step: 10
Training loss: 1.7863914966583252
Validation loss: 2.193679690361023

Epoch: 5| Step: 11
Training loss: 1.2088143825531006
Validation loss: 2.188970704873403

Epoch: 242| Step: 0
Training loss: 1.7176978588104248
Validation loss: 2.184806873401006

Epoch: 5| Step: 1
Training loss: 1.4633082151412964
Validation loss: 2.187603419025739

Epoch: 5| Step: 2
Training loss: 1.5157545804977417
Validation loss: 2.2044216692447662

Epoch: 5| Step: 3
Training loss: 1.9853826761245728
Validation loss: 2.199257309238116

Epoch: 5| Step: 4
Training loss: 1.351178765296936
Validation loss: 2.2105171183745065

Epoch: 5| Step: 5
Training loss: 2.1481499671936035
Validation loss: 2.2087537993987403

Epoch: 5| Step: 6
Training loss: 1.883519172668457
Validation loss: 2.2041475971539817

Epoch: 5| Step: 7
Training loss: 1.518001675605774
Validation loss: 2.207609305779139

Epoch: 5| Step: 8
Training loss: 2.0664474964141846
Validation loss: 2.2101089855035148

Epoch: 5| Step: 9
Training loss: 2.280264377593994
Validation loss: 2.2116136252880096

Epoch: 5| Step: 10
Training loss: 1.9394880533218384
Validation loss: 2.194686104853948

Epoch: 5| Step: 11
Training loss: 2.388333797454834
Validation loss: 2.202562391757965

Epoch: 243| Step: 0
Training loss: 1.4661235809326172
Validation loss: 2.2003464897473655

Epoch: 5| Step: 1
Training loss: 1.690291166305542
Validation loss: 2.2128122548262277

Epoch: 5| Step: 2
Training loss: 1.7542991638183594
Validation loss: 2.2167245596647263

Epoch: 5| Step: 3
Training loss: 1.802579641342163
Validation loss: 2.2093920509020486

Epoch: 5| Step: 4
Training loss: 2.1758999824523926
Validation loss: 2.2275692025820413

Epoch: 5| Step: 5
Training loss: 1.9857232570648193
Validation loss: 2.2350506484508514

Epoch: 5| Step: 6
Training loss: 1.8742567300796509
Validation loss: 2.2236568530400596

Epoch: 5| Step: 7
Training loss: 1.8435184955596924
Validation loss: 2.222853680451711

Epoch: 5| Step: 8
Training loss: 2.004528284072876
Validation loss: 2.2214076966047287

Epoch: 5| Step: 9
Training loss: 1.4398577213287354
Validation loss: 2.207163209716479

Epoch: 5| Step: 10
Training loss: 2.1408634185791016
Validation loss: 2.2151231418053308

Epoch: 5| Step: 11
Training loss: 0.8111470937728882
Validation loss: 2.202304388086001

Epoch: 244| Step: 0
Training loss: 2.4091179370880127
Validation loss: 2.214739849170049

Epoch: 5| Step: 1
Training loss: 1.9231373071670532
Validation loss: 2.2090683728456497

Epoch: 5| Step: 2
Training loss: 1.4224745035171509
Validation loss: 2.2052032202482224

Epoch: 5| Step: 3
Training loss: 1.693239450454712
Validation loss: 2.1816495110591254

Epoch: 5| Step: 4
Training loss: 2.3312828540802
Validation loss: 2.155945767958959

Epoch: 5| Step: 5
Training loss: 1.4758565425872803
Validation loss: 2.1966411471366882

Epoch: 5| Step: 6
Training loss: 1.9145761728286743
Validation loss: 2.204983095328013

Epoch: 5| Step: 7
Training loss: 1.6379003524780273
Validation loss: 2.199594482779503

Epoch: 5| Step: 8
Training loss: 1.4662224054336548
Validation loss: 2.2097399135430655

Epoch: 5| Step: 9
Training loss: 1.7990505695343018
Validation loss: 2.2204560935497284

Epoch: 5| Step: 10
Training loss: 2.1633188724517822
Validation loss: 2.2069882502158484

Epoch: 5| Step: 11
Training loss: 1.2167696952819824
Validation loss: 2.2142749577760696

Epoch: 245| Step: 0
Training loss: 1.8296369314193726
Validation loss: 2.236539269487063

Epoch: 5| Step: 1
Training loss: 2.030388593673706
Validation loss: 2.238038331270218

Epoch: 5| Step: 2
Training loss: 1.547253966331482
Validation loss: 2.2241557091474533

Epoch: 5| Step: 3
Training loss: 1.8692833185195923
Validation loss: 2.236938327550888

Epoch: 5| Step: 4
Training loss: 2.1519036293029785
Validation loss: 2.2501332064469657

Epoch: 5| Step: 5
Training loss: 1.8733068704605103
Validation loss: 2.2304464926322303

Epoch: 5| Step: 6
Training loss: 1.6444981098175049
Validation loss: 2.22044974565506

Epoch: 5| Step: 7
Training loss: 2.1157429218292236
Validation loss: 2.2420281767845154

Epoch: 5| Step: 8
Training loss: 1.0333778858184814
Validation loss: 2.2344924012819924

Epoch: 5| Step: 9
Training loss: 1.6631433963775635
Validation loss: 2.2117522060871124

Epoch: 5| Step: 10
Training loss: 2.0309176445007324
Validation loss: 2.212130298217138

Epoch: 5| Step: 11
Training loss: 2.0317862033843994
Validation loss: 2.2141764611005783

Epoch: 246| Step: 0
Training loss: 2.2932848930358887
Validation loss: 2.2054807245731354

Epoch: 5| Step: 1
Training loss: 1.5886337757110596
Validation loss: 2.2302325069904327

Epoch: 5| Step: 2
Training loss: 1.78756582736969
Validation loss: 2.2261334508657455

Epoch: 5| Step: 3
Training loss: 2.223945379257202
Validation loss: 2.2264280319213867

Epoch: 5| Step: 4
Training loss: 1.9794323444366455
Validation loss: 2.241178164879481

Epoch: 5| Step: 5
Training loss: 1.5343072414398193
Validation loss: 2.26367449760437

Epoch: 5| Step: 6
Training loss: 1.6939901113510132
Validation loss: 2.2629393438498178

Epoch: 5| Step: 7
Training loss: 1.9790585041046143
Validation loss: 2.2645630538463593

Epoch: 5| Step: 8
Training loss: 1.5402357578277588
Validation loss: 2.2641201665004096

Epoch: 5| Step: 9
Training loss: 1.5985651016235352
Validation loss: 2.2686851819356284

Epoch: 5| Step: 10
Training loss: 1.9013135433197021
Validation loss: 2.2632297376791635

Epoch: 5| Step: 11
Training loss: 1.3280819654464722
Validation loss: 2.246694733699163

Epoch: 247| Step: 0
Training loss: 2.018115997314453
Validation loss: 2.2667824774980545

Epoch: 5| Step: 1
Training loss: 1.777684211730957
Validation loss: 2.2515479723612466

Epoch: 5| Step: 2
Training loss: 1.4960861206054688
Validation loss: 2.2637609094381332

Epoch: 5| Step: 3
Training loss: 1.468151330947876
Validation loss: 2.222765768567721

Epoch: 5| Step: 4
Training loss: 1.8893353939056396
Validation loss: 2.207534665862719

Epoch: 5| Step: 5
Training loss: 2.0133769512176514
Validation loss: 2.1946366280317307

Epoch: 5| Step: 6
Training loss: 1.6205953359603882
Validation loss: 2.205041617155075

Epoch: 5| Step: 7
Training loss: 1.8619552850723267
Validation loss: 2.1965669691562653

Epoch: 5| Step: 8
Training loss: 1.6876938343048096
Validation loss: 2.2132985492547355

Epoch: 5| Step: 9
Training loss: 1.9318307638168335
Validation loss: 2.217642361919085

Epoch: 5| Step: 10
Training loss: 2.158590078353882
Validation loss: 2.212936987479528

Epoch: 5| Step: 11
Training loss: 2.1270761489868164
Validation loss: 2.21121713022391

Epoch: 248| Step: 0
Training loss: 1.9286997318267822
Validation loss: 2.2174604336420694

Epoch: 5| Step: 1
Training loss: 0.9997615814208984
Validation loss: 2.2166668275992074

Epoch: 5| Step: 2
Training loss: 2.1951794624328613
Validation loss: 2.2287266304095588

Epoch: 5| Step: 3
Training loss: 2.0258028507232666
Validation loss: 2.215452328324318

Epoch: 5| Step: 4
Training loss: 2.103745937347412
Validation loss: 2.237919489542643

Epoch: 5| Step: 5
Training loss: 1.7812799215316772
Validation loss: 2.2125770996014276

Epoch: 5| Step: 6
Training loss: 1.9179407358169556
Validation loss: 2.2321940759817758

Epoch: 5| Step: 7
Training loss: 1.516299843788147
Validation loss: 2.221064329147339

Epoch: 5| Step: 8
Training loss: 1.8369057178497314
Validation loss: 2.224545588095983

Epoch: 5| Step: 9
Training loss: 2.171619415283203
Validation loss: 2.245079825321833

Epoch: 5| Step: 10
Training loss: 1.6474605798721313
Validation loss: 2.248174265027046

Epoch: 5| Step: 11
Training loss: 0.7190453410148621
Validation loss: 2.229383279879888

Epoch: 249| Step: 0
Training loss: 1.6068000793457031
Validation loss: 2.2022502223650613

Epoch: 5| Step: 1
Training loss: 2.698491096496582
Validation loss: 2.2042726377646127

Epoch: 5| Step: 2
Training loss: 1.3283803462982178
Validation loss: 2.181379849712054

Epoch: 5| Step: 3
Training loss: 1.6311299800872803
Validation loss: 2.1732846945524216

Epoch: 5| Step: 4
Training loss: 1.8881324529647827
Validation loss: 2.1716714004675546

Epoch: 5| Step: 5
Training loss: 1.8626428842544556
Validation loss: 2.1847111582756042

Epoch: 5| Step: 6
Training loss: 1.8540534973144531
Validation loss: 2.1866814295450845

Epoch: 5| Step: 7
Training loss: 1.4036720991134644
Validation loss: 2.184954603513082

Epoch: 5| Step: 8
Training loss: 2.2828493118286133
Validation loss: 2.1990881015857062

Epoch: 5| Step: 9
Training loss: 1.9821441173553467
Validation loss: 2.2335136930147805

Epoch: 5| Step: 10
Training loss: 1.661912202835083
Validation loss: 2.260298565030098

Epoch: 5| Step: 11
Training loss: 2.1404426097869873
Validation loss: 2.2574415107568107

Epoch: 250| Step: 0
Training loss: 1.5202233791351318
Validation loss: 2.3013005753358207

Epoch: 5| Step: 1
Training loss: 2.295475482940674
Validation loss: 2.2887933949629464

Epoch: 5| Step: 2
Training loss: 1.8780529499053955
Validation loss: 2.29077939192454

Epoch: 5| Step: 3
Training loss: 2.4252066612243652
Validation loss: 2.277993068099022

Epoch: 5| Step: 4
Training loss: 2.5098705291748047
Validation loss: 2.25748802224795

Epoch: 5| Step: 5
Training loss: 2.5079808235168457
Validation loss: 2.255011553565661

Epoch: 5| Step: 6
Training loss: 1.5451316833496094
Validation loss: 2.2657614648342133

Epoch: 5| Step: 7
Training loss: 1.5998334884643555
Validation loss: 2.26522887746493

Epoch: 5| Step: 8
Training loss: 1.5947256088256836
Validation loss: 2.245199238260587

Epoch: 5| Step: 9
Training loss: 1.9449594020843506
Validation loss: 2.2499035547176995

Epoch: 5| Step: 10
Training loss: 1.918225884437561
Validation loss: 2.244092643260956

Epoch: 5| Step: 11
Training loss: 1.5700604915618896
Validation loss: 2.2263611803452172

Testing loss: 1.903257735341573
