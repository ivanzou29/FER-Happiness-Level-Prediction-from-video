Epoch: 1| Step: 0
Training loss: 6.53562320881024
Validation loss: 5.840273797266578

Epoch: 6| Step: 1
Training loss: 5.893090498626337
Validation loss: 5.838951983455253

Epoch: 6| Step: 2
Training loss: 5.357305277224178
Validation loss: 5.837673135132674

Epoch: 6| Step: 3
Training loss: 5.432436810971684
Validation loss: 5.836345094935645

Epoch: 6| Step: 4
Training loss: 6.169972882327145
Validation loss: 5.835019667155624

Epoch: 6| Step: 5
Training loss: 5.923182521797166
Validation loss: 5.833692548681592

Epoch: 6| Step: 6
Training loss: 7.047397907081889
Validation loss: 5.832288030791428

Epoch: 6| Step: 7
Training loss: 6.204980068374578
Validation loss: 5.830954920589741

Epoch: 6| Step: 8
Training loss: 4.967039185619978
Validation loss: 5.829545844149764

Epoch: 6| Step: 9
Training loss: 5.647951223881431
Validation loss: 5.828109373015452

Epoch: 6| Step: 10
Training loss: 5.997518026079166
Validation loss: 5.8266243455748015

Epoch: 6| Step: 11
Training loss: 6.556938212359723
Validation loss: 5.825145133506633

Epoch: 6| Step: 12
Training loss: 5.359933006665055
Validation loss: 5.823613906998371

Epoch: 6| Step: 13
Training loss: 5.851872801351985
Validation loss: 5.821979435905256

Epoch: 2| Step: 0
Training loss: 4.667860060188598
Validation loss: 5.820279865898794

Epoch: 6| Step: 1
Training loss: 5.1225352989905595
Validation loss: 5.818600860771376

Epoch: 6| Step: 2
Training loss: 6.423164776482821
Validation loss: 5.816785565593859

Epoch: 6| Step: 3
Training loss: 6.177638354355735
Validation loss: 5.814838253580537

Epoch: 6| Step: 4
Training loss: 5.906613293328405
Validation loss: 5.812846429817167

Epoch: 6| Step: 5
Training loss: 5.551949256676078
Validation loss: 5.81066064204977

Epoch: 6| Step: 6
Training loss: 5.427118322024129
Validation loss: 5.808477589126203

Epoch: 6| Step: 7
Training loss: 6.418229082136384
Validation loss: 5.806114599800142

Epoch: 6| Step: 8
Training loss: 5.534911242482412
Validation loss: 5.803662325528016

Epoch: 6| Step: 9
Training loss: 6.159715325849711
Validation loss: 5.801079006238152

Epoch: 6| Step: 10
Training loss: 6.525305273873118
Validation loss: 5.798416741540528

Epoch: 6| Step: 11
Training loss: 6.15505334677614
Validation loss: 5.795502862711886

Epoch: 6| Step: 12
Training loss: 6.314539211735324
Validation loss: 5.792594295651235

Epoch: 6| Step: 13
Training loss: 6.199045833875426
Validation loss: 5.789327418914848

Epoch: 3| Step: 0
Training loss: 6.092621214564398
Validation loss: 5.785915162704992

Epoch: 6| Step: 1
Training loss: 6.17687322335361
Validation loss: 5.782504246379362

Epoch: 6| Step: 2
Training loss: 5.1471275318592635
Validation loss: 5.778629320719023

Epoch: 6| Step: 3
Training loss: 6.325522106469441
Validation loss: 5.774980874738635

Epoch: 6| Step: 4
Training loss: 6.5727618683382145
Validation loss: 5.77080630446438

Epoch: 6| Step: 5
Training loss: 5.542324208804286
Validation loss: 5.766640922547722

Epoch: 6| Step: 6
Training loss: 5.845544223429193
Validation loss: 5.762260992537053

Epoch: 6| Step: 7
Training loss: 6.397682676401643
Validation loss: 5.7576650309904425

Epoch: 6| Step: 8
Training loss: 5.689084681148396
Validation loss: 5.752899185382133

Epoch: 6| Step: 9
Training loss: 6.303004005795198
Validation loss: 5.747887485932898

Epoch: 6| Step: 10
Training loss: 5.695988953740414
Validation loss: 5.742716308602974

Epoch: 6| Step: 11
Training loss: 5.3189942999743085
Validation loss: 5.737368544635765

Epoch: 6| Step: 12
Training loss: 4.775307346858211
Validation loss: 5.731613589158717

Epoch: 6| Step: 13
Training loss: 6.083734194294338
Validation loss: 5.725998306410958

Epoch: 4| Step: 0
Training loss: 6.169763904178245
Validation loss: 5.720039736425208

Epoch: 6| Step: 1
Training loss: 5.505835991492115
Validation loss: 5.7141692501642884

Epoch: 6| Step: 2
Training loss: 5.720786477286246
Validation loss: 5.707652401743435

Epoch: 6| Step: 3
Training loss: 6.855025804778541
Validation loss: 5.701580378416478

Epoch: 6| Step: 4
Training loss: 6.663079568299938
Validation loss: 5.694511228133604

Epoch: 6| Step: 5
Training loss: 5.6982193424188585
Validation loss: 5.687637830468478

Epoch: 6| Step: 6
Training loss: 6.105012004068806
Validation loss: 5.680464980386018

Epoch: 6| Step: 7
Training loss: 5.640387617278137
Validation loss: 5.673207948705939

Epoch: 6| Step: 8
Training loss: 4.615857134375038
Validation loss: 5.66635737790541

Epoch: 6| Step: 9
Training loss: 6.009965567847206
Validation loss: 5.658816968711032

Epoch: 6| Step: 10
Training loss: 5.742524968824961
Validation loss: 5.651508880380561

Epoch: 6| Step: 11
Training loss: 5.62583459384644
Validation loss: 5.644016813531168

Epoch: 6| Step: 12
Training loss: 5.403500778518696
Validation loss: 5.636593661084595

Epoch: 6| Step: 13
Training loss: 5.003919590999975
Validation loss: 5.629002877578999

Epoch: 5| Step: 0
Training loss: 4.583474636789621
Validation loss: 5.621264708046407

Epoch: 6| Step: 1
Training loss: 5.818149897097673
Validation loss: 5.613359231745642

Epoch: 6| Step: 2
Training loss: 4.944607604593444
Validation loss: 5.605829023065899

Epoch: 6| Step: 3
Training loss: 4.907760096151497
Validation loss: 5.598336554016537

Epoch: 6| Step: 4
Training loss: 6.188573262544357
Validation loss: 5.5898220258211095

Epoch: 6| Step: 5
Training loss: 5.718040880941066
Validation loss: 5.581687551835039

Epoch: 6| Step: 6
Training loss: 6.357812187999194
Validation loss: 5.573180585179523

Epoch: 6| Step: 7
Training loss: 6.361538605667381
Validation loss: 5.564570438089667

Epoch: 6| Step: 8
Training loss: 4.6459244290075175
Validation loss: 5.555931184573662

Epoch: 6| Step: 9
Training loss: 6.124787618886458
Validation loss: 5.54730503761408

Epoch: 6| Step: 10
Training loss: 7.238316560052838
Validation loss: 5.5386505619421635

Epoch: 6| Step: 11
Training loss: 5.444898460989726
Validation loss: 5.529195112870535

Epoch: 6| Step: 12
Training loss: 5.546606266872736
Validation loss: 5.520241394938296

Epoch: 6| Step: 13
Training loss: 5.030566814786117
Validation loss: 5.511028647617654

Epoch: 6| Step: 0
Training loss: 6.014050562532807
Validation loss: 5.502498723789214

Epoch: 6| Step: 1
Training loss: 5.9390883078111
Validation loss: 5.493225057531732

Epoch: 6| Step: 2
Training loss: 5.2868761420550285
Validation loss: 5.484437802671563

Epoch: 6| Step: 3
Training loss: 6.343477290262816
Validation loss: 5.475236254142459

Epoch: 6| Step: 4
Training loss: 6.32815755199961
Validation loss: 5.466343115714181

Epoch: 6| Step: 5
Training loss: 6.468350163141125
Validation loss: 5.457700833469587

Epoch: 6| Step: 6
Training loss: 5.457051522197492
Validation loss: 5.448729484223688

Epoch: 6| Step: 7
Training loss: 4.756909214207981
Validation loss: 5.439597649654668

Epoch: 6| Step: 8
Training loss: 4.241140443627544
Validation loss: 5.430803260238023

Epoch: 6| Step: 9
Training loss: 4.830908112069185
Validation loss: 5.422309029949132

Epoch: 6| Step: 10
Training loss: 4.86612852770501
Validation loss: 5.413550913733529

Epoch: 6| Step: 11
Training loss: 5.55847382298817
Validation loss: 5.405399439353056

Epoch: 6| Step: 12
Training loss: 5.7933753623945
Validation loss: 5.39670839418832

Epoch: 6| Step: 13
Training loss: 5.530999991591251
Validation loss: 5.388559080083843

Epoch: 7| Step: 0
Training loss: 4.990008671204519
Validation loss: 5.379835393436646

Epoch: 6| Step: 1
Training loss: 5.068645561826246
Validation loss: 5.371300895626745

Epoch: 6| Step: 2
Training loss: 6.201353958940923
Validation loss: 5.363172633290705

Epoch: 6| Step: 3
Training loss: 5.219291613221823
Validation loss: 5.3546756645927465

Epoch: 6| Step: 4
Training loss: 5.262953989194928
Validation loss: 5.346784655790385

Epoch: 6| Step: 5
Training loss: 5.058703093654152
Validation loss: 5.338655687060452

Epoch: 6| Step: 6
Training loss: 5.801279374130243
Validation loss: 5.331089213228555

Epoch: 6| Step: 7
Training loss: 5.123699488431567
Validation loss: 5.3234093345387405

Epoch: 6| Step: 8
Training loss: 5.656486717033857
Validation loss: 5.316072676352003

Epoch: 6| Step: 9
Training loss: 6.019976738666191
Validation loss: 5.308983031337204

Epoch: 6| Step: 10
Training loss: 5.109784497757747
Validation loss: 5.302426619992441

Epoch: 6| Step: 11
Training loss: 4.930135522182919
Validation loss: 5.294575870230767

Epoch: 6| Step: 12
Training loss: 6.458319616815912
Validation loss: 5.28756068971162

Epoch: 6| Step: 13
Training loss: 5.098611956927994
Validation loss: 5.280448476548625

Epoch: 8| Step: 0
Training loss: 6.562177668330264
Validation loss: 5.274217064774857

Epoch: 6| Step: 1
Training loss: 5.467916893852818
Validation loss: 5.266773977675263

Epoch: 6| Step: 2
Training loss: 4.859478228781961
Validation loss: 5.259600807097856

Epoch: 6| Step: 3
Training loss: 5.741843367664174
Validation loss: 5.253397583947791

Epoch: 6| Step: 4
Training loss: 4.393157988557521
Validation loss: 5.246250524235299

Epoch: 6| Step: 5
Training loss: 5.747358295806091
Validation loss: 5.240108526867745

Epoch: 6| Step: 6
Training loss: 5.753637075764283
Validation loss: 5.233411892019855

Epoch: 6| Step: 7
Training loss: 5.222731847223065
Validation loss: 5.227172542260305

Epoch: 6| Step: 8
Training loss: 5.392264385001343
Validation loss: 5.220813944608829

Epoch: 6| Step: 9
Training loss: 5.0388480680513945
Validation loss: 5.21463194380062

Epoch: 6| Step: 10
Training loss: 4.850696726041255
Validation loss: 5.208942509947686

Epoch: 6| Step: 11
Training loss: 5.414165545387068
Validation loss: 5.203145345012307

Epoch: 6| Step: 12
Training loss: 5.088331089979307
Validation loss: 5.196952572425408

Epoch: 6| Step: 13
Training loss: 5.113669361046571
Validation loss: 5.19172585189826

Epoch: 9| Step: 0
Training loss: 5.879545036412688
Validation loss: 5.18641786127286

Epoch: 6| Step: 1
Training loss: 4.904582523852195
Validation loss: 5.1805158732340155

Epoch: 6| Step: 2
Training loss: 5.382670053222236
Validation loss: 5.175176790077133

Epoch: 6| Step: 3
Training loss: 4.802022253656201
Validation loss: 5.1692157835315236

Epoch: 6| Step: 4
Training loss: 5.777606537718495
Validation loss: 5.164683833137589

Epoch: 6| Step: 5
Training loss: 2.7882751721299597
Validation loss: 5.159774562090466

Epoch: 6| Step: 6
Training loss: 5.273056626870751
Validation loss: 5.155070530248283

Epoch: 6| Step: 7
Training loss: 4.565169089320451
Validation loss: 5.150373836639937

Epoch: 6| Step: 8
Training loss: 6.173617114691241
Validation loss: 5.144534061540218

Epoch: 6| Step: 9
Training loss: 5.784142013136002
Validation loss: 5.1400271979279095

Epoch: 6| Step: 10
Training loss: 5.428479659946883
Validation loss: 5.134984672075304

Epoch: 6| Step: 11
Training loss: 5.09975411813449
Validation loss: 5.130656276710866

Epoch: 6| Step: 12
Training loss: 5.954994849163554
Validation loss: 5.125750820087223

Epoch: 6| Step: 13
Training loss: 5.176260296227082
Validation loss: 5.121116003807245

Epoch: 10| Step: 0
Training loss: 4.993610686649425
Validation loss: 5.11668530977479

Epoch: 6| Step: 1
Training loss: 5.719569079833233
Validation loss: 5.1105919806973565

Epoch: 6| Step: 2
Training loss: 5.388394366948263
Validation loss: 5.106492157652709

Epoch: 6| Step: 3
Training loss: 5.3263165489610484
Validation loss: 5.101405532236931

Epoch: 6| Step: 4
Training loss: 5.693458537944315
Validation loss: 5.096951903966174

Epoch: 6| Step: 5
Training loss: 5.223264648790887
Validation loss: 5.091405972780317

Epoch: 6| Step: 6
Training loss: 4.712134972962677
Validation loss: 5.0867772031767124

Epoch: 6| Step: 7
Training loss: 4.806327527515974
Validation loss: 5.083593935097135

Epoch: 6| Step: 8
Training loss: 5.611963041655585
Validation loss: 5.077536117447794

Epoch: 6| Step: 9
Training loss: 4.673593262551273
Validation loss: 5.073375809066018

Epoch: 6| Step: 10
Training loss: 5.40855032432146
Validation loss: 5.068997048387228

Epoch: 6| Step: 11
Training loss: 5.488893218216795
Validation loss: 5.064993256153012

Epoch: 6| Step: 12
Training loss: 4.556405163962976
Validation loss: 5.060036864567336

Epoch: 6| Step: 13
Training loss: 5.1563040065826975
Validation loss: 5.054930565643626

Epoch: 11| Step: 0
Training loss: 5.315865920144811
Validation loss: 5.05152979174604

Epoch: 6| Step: 1
Training loss: 5.259888192500618
Validation loss: 5.047613918510908

Epoch: 6| Step: 2
Training loss: 4.722435730738644
Validation loss: 5.041824947846583

Epoch: 6| Step: 3
Training loss: 5.498441475348893
Validation loss: 5.037206815733885

Epoch: 6| Step: 4
Training loss: 4.759395342336902
Validation loss: 5.032826652455636

Epoch: 6| Step: 5
Training loss: 5.062238144872325
Validation loss: 5.028059680452011

Epoch: 6| Step: 6
Training loss: 5.785828133460361
Validation loss: 5.023652210066891

Epoch: 6| Step: 7
Training loss: 5.710432831348066
Validation loss: 5.019450344121398

Epoch: 6| Step: 8
Training loss: 5.449438209626485
Validation loss: 5.014549575816712

Epoch: 6| Step: 9
Training loss: 4.654209585968082
Validation loss: 5.010525084318521

Epoch: 6| Step: 10
Training loss: 5.701548904649453
Validation loss: 5.006342203384149

Epoch: 6| Step: 11
Training loss: 4.049683527885283
Validation loss: 5.001318280955964

Epoch: 6| Step: 12
Training loss: 5.120194205534843
Validation loss: 4.996331888010865

Epoch: 6| Step: 13
Training loss: 4.662077872877441
Validation loss: 4.992105466420374

Epoch: 12| Step: 0
Training loss: 5.372691168705597
Validation loss: 4.987994244274173

Epoch: 6| Step: 1
Training loss: 4.90653514640875
Validation loss: 4.983497502526349

Epoch: 6| Step: 2
Training loss: 5.1038661738582345
Validation loss: 4.978723301427641

Epoch: 6| Step: 3
Training loss: 4.175584151466888
Validation loss: 4.974259143407909

Epoch: 6| Step: 4
Training loss: 4.931877701603541
Validation loss: 4.9705202479968085

Epoch: 6| Step: 5
Training loss: 5.743013532741836
Validation loss: 4.967032241594789

Epoch: 6| Step: 6
Training loss: 5.871148977825739
Validation loss: 4.962317887943519

Epoch: 6| Step: 7
Training loss: 5.138133271255582
Validation loss: 4.958276967388088

Epoch: 6| Step: 8
Training loss: 4.47040127209732
Validation loss: 4.953753667139093

Epoch: 6| Step: 9
Training loss: 5.2607221558754045
Validation loss: 4.950129392326337

Epoch: 6| Step: 10
Training loss: 4.997297319478558
Validation loss: 4.94536225352638

Epoch: 6| Step: 11
Training loss: 4.879539528055837
Validation loss: 4.9415961549476854

Epoch: 6| Step: 12
Training loss: 5.3825678223032485
Validation loss: 4.936919327082257

Epoch: 6| Step: 13
Training loss: 4.718305756328756
Validation loss: 4.932863207058925

Epoch: 13| Step: 0
Training loss: 5.215575571894494
Validation loss: 4.928999170126948

Epoch: 6| Step: 1
Training loss: 4.245307126566575
Validation loss: 4.92491987392354

Epoch: 6| Step: 2
Training loss: 5.762973909895204
Validation loss: 4.921181055628766

Epoch: 6| Step: 3
Training loss: 4.621846128919081
Validation loss: 4.916919647863626

Epoch: 6| Step: 4
Training loss: 5.660216905730899
Validation loss: 4.912368749364845

Epoch: 6| Step: 5
Training loss: 5.672857530472201
Validation loss: 4.908128803872991

Epoch: 6| Step: 6
Training loss: 4.637597737477692
Validation loss: 4.904308250714854

Epoch: 6| Step: 7
Training loss: 4.858302939545102
Validation loss: 4.9002459289182

Epoch: 6| Step: 8
Training loss: 4.451610213854504
Validation loss: 4.896172023448011

Epoch: 6| Step: 9
Training loss: 5.987203303175423
Validation loss: 4.892418090883176

Epoch: 6| Step: 10
Training loss: 4.447343680694014
Validation loss: 4.8877839925459154

Epoch: 6| Step: 11
Training loss: 4.919521386662337
Validation loss: 4.883831436653803

Epoch: 6| Step: 12
Training loss: 3.901254007275695
Validation loss: 4.879244757770372

Epoch: 6| Step: 13
Training loss: 5.484213976112804
Validation loss: 4.875559098224943

Epoch: 14| Step: 0
Training loss: 4.448025108760523
Validation loss: 4.871783997128457

Epoch: 6| Step: 1
Training loss: 5.385018526433247
Validation loss: 4.867550399093537

Epoch: 6| Step: 2
Training loss: 4.140716897196606
Validation loss: 4.863957835246835

Epoch: 6| Step: 3
Training loss: 4.714022459796394
Validation loss: 4.859374116854572

Epoch: 6| Step: 4
Training loss: 4.737718867980822
Validation loss: 4.855926172955308

Epoch: 6| Step: 5
Training loss: 5.647066701855493
Validation loss: 4.852002830814836

Epoch: 6| Step: 6
Training loss: 4.093157310387438
Validation loss: 4.848273251081346

Epoch: 6| Step: 7
Training loss: 5.624734321253972
Validation loss: 4.844355342324584

Epoch: 6| Step: 8
Training loss: 5.918729001806568
Validation loss: 4.839874324953447

Epoch: 6| Step: 9
Training loss: 5.313533906744644
Validation loss: 4.83561088350571

Epoch: 6| Step: 10
Training loss: 4.776612070591959
Validation loss: 4.831932089468383

Epoch: 6| Step: 11
Training loss: 4.723910509881733
Validation loss: 4.82811509083016

Epoch: 6| Step: 12
Training loss: 5.164503116248856
Validation loss: 4.823677491829896

Epoch: 6| Step: 13
Training loss: 4.496268102478458
Validation loss: 4.819582726763341

Epoch: 15| Step: 0
Training loss: 5.020951624488539
Validation loss: 4.815527950087057

Epoch: 6| Step: 1
Training loss: 4.495811632520587
Validation loss: 4.8118614664914325

Epoch: 6| Step: 2
Training loss: 4.213090279083398
Validation loss: 4.807429825880115

Epoch: 6| Step: 3
Training loss: 4.365024638417765
Validation loss: 4.8035367088933665

Epoch: 6| Step: 4
Training loss: 4.8850809183905675
Validation loss: 4.79970765945503

Epoch: 6| Step: 5
Training loss: 4.66493020221138
Validation loss: 4.7958465036873665

Epoch: 6| Step: 6
Training loss: 5.230115928459146
Validation loss: 4.79184022119208

Epoch: 6| Step: 7
Training loss: 4.7979222251118925
Validation loss: 4.7881343703466035

Epoch: 6| Step: 8
Training loss: 5.531149308317254
Validation loss: 4.783960509083015

Epoch: 6| Step: 9
Training loss: 5.319969042924572
Validation loss: 4.78064921807796

Epoch: 6| Step: 10
Training loss: 5.404462044593807
Validation loss: 4.776153491037782

Epoch: 6| Step: 11
Training loss: 4.832990349186726
Validation loss: 4.771972131646152

Epoch: 6| Step: 12
Training loss: 4.6078465918065294
Validation loss: 4.76804411310446

Epoch: 6| Step: 13
Training loss: 5.241638245780969
Validation loss: 4.764223186501739

Epoch: 16| Step: 0
Training loss: 4.917802173074978
Validation loss: 4.759410871544634

Epoch: 6| Step: 1
Training loss: 4.690497902019321
Validation loss: 4.755568569726061

Epoch: 6| Step: 2
Training loss: 5.087133873364473
Validation loss: 4.751683321713673

Epoch: 6| Step: 3
Training loss: 4.8319667111822735
Validation loss: 4.747553781074538

Epoch: 6| Step: 4
Training loss: 4.658622188631648
Validation loss: 4.7431527024326074

Epoch: 6| Step: 5
Training loss: 3.975460356919495
Validation loss: 4.739047322687584

Epoch: 6| Step: 6
Training loss: 5.0481391953201085
Validation loss: 4.735090749287885

Epoch: 6| Step: 7
Training loss: 4.787623526869482
Validation loss: 4.731082321010908

Epoch: 6| Step: 8
Training loss: 5.40706138916611
Validation loss: 4.726745837310337

Epoch: 6| Step: 9
Training loss: 3.9210176176625398
Validation loss: 4.7223745745348

Epoch: 6| Step: 10
Training loss: 4.784117194268052
Validation loss: 4.718432064166534

Epoch: 6| Step: 11
Training loss: 4.975667684405747
Validation loss: 4.714164678662987

Epoch: 6| Step: 12
Training loss: 5.377553643704354
Validation loss: 4.709470403422543

Epoch: 6| Step: 13
Training loss: 5.307548099970088
Validation loss: 4.705519614719817

Epoch: 17| Step: 0
Training loss: 4.261277439054826
Validation loss: 4.701303748307279

Epoch: 6| Step: 1
Training loss: 4.678014491221476
Validation loss: 4.697076331836431

Epoch: 6| Step: 2
Training loss: 5.0092489530110385
Validation loss: 4.6926605301206425

Epoch: 6| Step: 3
Training loss: 3.733900223562033
Validation loss: 4.688075627904966

Epoch: 6| Step: 4
Training loss: 5.611479043175867
Validation loss: 4.684010066941603

Epoch: 6| Step: 5
Training loss: 4.670512022910587
Validation loss: 4.679943521381635

Epoch: 6| Step: 6
Training loss: 3.9355369397362185
Validation loss: 4.675859689120985

Epoch: 6| Step: 7
Training loss: 5.480899241935044
Validation loss: 4.671813249977312

Epoch: 6| Step: 8
Training loss: 4.7473060598027015
Validation loss: 4.667375505064433

Epoch: 6| Step: 9
Training loss: 5.262045529419764
Validation loss: 4.662884860138921

Epoch: 6| Step: 10
Training loss: 5.01543637690493
Validation loss: 4.658554121504946

Epoch: 6| Step: 11
Training loss: 4.789756438368406
Validation loss: 4.654602202980303

Epoch: 6| Step: 12
Training loss: 4.581723410175328
Validation loss: 4.649679032053171

Epoch: 6| Step: 13
Training loss: 5.0429916322220025
Validation loss: 4.645767736043108

Epoch: 18| Step: 0
Training loss: 4.517075883033298
Validation loss: 4.641189626473485

Epoch: 6| Step: 1
Training loss: 5.221553757452639
Validation loss: 4.6370419628226385

Epoch: 6| Step: 2
Training loss: 5.159932988640998
Validation loss: 4.632176579128811

Epoch: 6| Step: 3
Training loss: 3.9962554332134217
Validation loss: 4.627906092502893

Epoch: 6| Step: 4
Training loss: 3.7636403278954846
Validation loss: 4.62347514128717

Epoch: 6| Step: 5
Training loss: 5.018008417468349
Validation loss: 4.619152221235003

Epoch: 6| Step: 6
Training loss: 4.63209237328431
Validation loss: 4.615148964596203

Epoch: 6| Step: 7
Training loss: 4.459548119203361
Validation loss: 4.609998171648061

Epoch: 6| Step: 8
Training loss: 5.140104412398772
Validation loss: 4.605751708367842

Epoch: 6| Step: 9
Training loss: 4.705090691789984
Validation loss: 4.601734168969031

Epoch: 6| Step: 10
Training loss: 4.83749911680386
Validation loss: 4.596685341061028

Epoch: 6| Step: 11
Training loss: 4.34338179749867
Validation loss: 4.592527161893226

Epoch: 6| Step: 12
Training loss: 5.618437605374672
Validation loss: 4.587681072240669

Epoch: 6| Step: 13
Training loss: 4.614328393144055
Validation loss: 4.583436525512544

Epoch: 19| Step: 0
Training loss: 3.865489240034091
Validation loss: 4.578855384657388

Epoch: 6| Step: 1
Training loss: 5.031729918153227
Validation loss: 4.5738394580261605

Epoch: 6| Step: 2
Training loss: 4.952151807611997
Validation loss: 4.569635881293585

Epoch: 6| Step: 3
Training loss: 4.896208966501772
Validation loss: 4.56405501669227

Epoch: 6| Step: 4
Training loss: 4.247688562474807
Validation loss: 4.55931084360919

Epoch: 6| Step: 5
Training loss: 5.433879129030753
Validation loss: 4.554406534191085

Epoch: 6| Step: 6
Training loss: 5.353168419229288
Validation loss: 4.549447571750831

Epoch: 6| Step: 7
Training loss: 3.0095583914298425
Validation loss: 4.544729733910339

Epoch: 6| Step: 8
Training loss: 5.157447259793242
Validation loss: 4.540012525017444

Epoch: 6| Step: 9
Training loss: 4.9222353848715965
Validation loss: 4.534892054530998

Epoch: 6| Step: 10
Training loss: 4.349006820073397
Validation loss: 4.531200049114047

Epoch: 6| Step: 11
Training loss: 4.33038337261363
Validation loss: 4.526268827870984

Epoch: 6| Step: 12
Training loss: 5.227858948536295
Validation loss: 4.521602612041836

Epoch: 6| Step: 13
Training loss: 4.026191317140406
Validation loss: 4.516834523834398

Epoch: 20| Step: 0
Training loss: 4.728085006272422
Validation loss: 4.511789789782754

Epoch: 6| Step: 1
Training loss: 4.807847982380442
Validation loss: 4.507060128666797

Epoch: 6| Step: 2
Training loss: 4.674077054068862
Validation loss: 4.5025413719139005

Epoch: 6| Step: 3
Training loss: 5.233375932232586
Validation loss: 4.498082070123923

Epoch: 6| Step: 4
Training loss: 3.6604037694788856
Validation loss: 4.493616998974172

Epoch: 6| Step: 5
Training loss: 4.468706464221935
Validation loss: 4.488307154895824

Epoch: 6| Step: 6
Training loss: 4.606957373787659
Validation loss: 4.483911895764351

Epoch: 6| Step: 7
Training loss: 4.618539576712023
Validation loss: 4.479211224474807

Epoch: 6| Step: 8
Training loss: 4.893713222867276
Validation loss: 4.474473378115511

Epoch: 6| Step: 9
Training loss: 4.85489440614564
Validation loss: 4.470062721062735

Epoch: 6| Step: 10
Training loss: 4.722263266191817
Validation loss: 4.465527704316614

Epoch: 6| Step: 11
Training loss: 3.9683491662126293
Validation loss: 4.460646406609356

Epoch: 6| Step: 12
Training loss: 3.8197627695927396
Validation loss: 4.456489728460035

Epoch: 6| Step: 13
Training loss: 5.188265456750168
Validation loss: 4.45155961927109

Epoch: 21| Step: 0
Training loss: 4.25155162536509
Validation loss: 4.447007663344768

Epoch: 6| Step: 1
Training loss: 4.206277225400607
Validation loss: 4.442600989824455

Epoch: 6| Step: 2
Training loss: 4.921849229533229
Validation loss: 4.437498567249622

Epoch: 6| Step: 3
Training loss: 4.804860181729204
Validation loss: 4.433060498315362

Epoch: 6| Step: 4
Training loss: 5.196115899171425
Validation loss: 4.428395562261729

Epoch: 6| Step: 5
Training loss: 4.468499876905263
Validation loss: 4.424277130537535

Epoch: 6| Step: 6
Training loss: 5.121311442085984
Validation loss: 4.419209246261558

Epoch: 6| Step: 7
Training loss: 3.4952602991359343
Validation loss: 4.4146134024306045

Epoch: 6| Step: 8
Training loss: 4.9863093816970485
Validation loss: 4.410420349340594

Epoch: 6| Step: 9
Training loss: 4.5029092497435235
Validation loss: 4.404879363591492

Epoch: 6| Step: 10
Training loss: 4.413088422666096
Validation loss: 4.400736143202802

Epoch: 6| Step: 11
Training loss: 4.383369070470679
Validation loss: 4.39555567125111

Epoch: 6| Step: 12
Training loss: 4.679959348192292
Validation loss: 4.391492637983966

Epoch: 6| Step: 13
Training loss: 3.9095992721519472
Validation loss: 4.386504750340982

Epoch: 22| Step: 0
Training loss: 4.125941313643811
Validation loss: 4.381976242205313

Epoch: 6| Step: 1
Training loss: 4.08841643252999
Validation loss: 4.377774112934401

Epoch: 6| Step: 2
Training loss: 4.8055482667097165
Validation loss: 4.37266694486136

Epoch: 6| Step: 3
Training loss: 4.112397797308834
Validation loss: 4.368508181885319

Epoch: 6| Step: 4
Training loss: 5.395952594082254
Validation loss: 4.363984072142479

Epoch: 6| Step: 5
Training loss: 3.7733379216609957
Validation loss: 4.359371536235276

Epoch: 6| Step: 6
Training loss: 4.142003934599566
Validation loss: 4.354935111297113

Epoch: 6| Step: 7
Training loss: 4.458764503996551
Validation loss: 4.350114820141546

Epoch: 6| Step: 8
Training loss: 4.349262499499287
Validation loss: 4.345405793608779

Epoch: 6| Step: 9
Training loss: 4.240978764260233
Validation loss: 4.340959599494771

Epoch: 6| Step: 10
Training loss: 4.5302941728278965
Validation loss: 4.336342934105318

Epoch: 6| Step: 11
Training loss: 4.8505653916982325
Validation loss: 4.331597561306411

Epoch: 6| Step: 12
Training loss: 4.823540248338739
Validation loss: 4.326390824471427

Epoch: 6| Step: 13
Training loss: 4.782783013208986
Validation loss: 4.32203721748555

Epoch: 23| Step: 0
Training loss: 4.296420430500837
Validation loss: 4.317002346483243

Epoch: 6| Step: 1
Training loss: 3.6041629034180738
Validation loss: 4.312443276737177

Epoch: 6| Step: 2
Training loss: 5.056320563390983
Validation loss: 4.30827406443417

Epoch: 6| Step: 3
Training loss: 3.964846275591868
Validation loss: 4.303294266174495

Epoch: 6| Step: 4
Training loss: 4.260741404101177
Validation loss: 4.298123302044278

Epoch: 6| Step: 5
Training loss: 5.102718391735092
Validation loss: 4.2936669228265965

Epoch: 6| Step: 6
Training loss: 4.189601086402331
Validation loss: 4.289243211396105

Epoch: 6| Step: 7
Training loss: 3.961734608757822
Validation loss: 4.284526694088909

Epoch: 6| Step: 8
Training loss: 4.787208783328826
Validation loss: 4.2794326674788365

Epoch: 6| Step: 9
Training loss: 5.684155497368252
Validation loss: 4.274366520724825

Epoch: 6| Step: 10
Training loss: 4.149165260287632
Validation loss: 4.2697859929793065

Epoch: 6| Step: 11
Training loss: 4.573120506569069
Validation loss: 4.265036480633196

Epoch: 6| Step: 12
Training loss: 3.458135499619416
Validation loss: 4.259850791652298

Epoch: 6| Step: 13
Training loss: 4.202277683094024
Validation loss: 4.254335324004476

Epoch: 24| Step: 0
Training loss: 4.809223992131593
Validation loss: 4.249590779218906

Epoch: 6| Step: 1
Training loss: 4.663718359437802
Validation loss: 4.244484801014571

Epoch: 6| Step: 2
Training loss: 4.392596362234262
Validation loss: 4.2392569501434085

Epoch: 6| Step: 3
Training loss: 4.229228929083258
Validation loss: 4.2341839323772295

Epoch: 6| Step: 4
Training loss: 3.4779639687495214
Validation loss: 4.229686510931228

Epoch: 6| Step: 5
Training loss: 4.138730403815734
Validation loss: 4.224092355178484

Epoch: 6| Step: 6
Training loss: 4.378448435172315
Validation loss: 4.21953117767543

Epoch: 6| Step: 7
Training loss: 4.261296238221747
Validation loss: 4.215577013154072

Epoch: 6| Step: 8
Training loss: 4.293843479610381
Validation loss: 4.210630274731544

Epoch: 6| Step: 9
Training loss: 3.9017058529869244
Validation loss: 4.206374952813578

Epoch: 6| Step: 10
Training loss: 4.732448475472084
Validation loss: 4.201221588138574

Epoch: 6| Step: 11
Training loss: 4.66246897505596
Validation loss: 4.196155674108789

Epoch: 6| Step: 12
Training loss: 4.3640536014890925
Validation loss: 4.191316450187457

Epoch: 6| Step: 13
Training loss: 4.397650368761612
Validation loss: 4.18630924660193

Epoch: 25| Step: 0
Training loss: 4.340610604643381
Validation loss: 4.181521555811753

Epoch: 6| Step: 1
Training loss: 4.443942484060267
Validation loss: 4.176022928522093

Epoch: 6| Step: 2
Training loss: 3.8877832536445927
Validation loss: 4.1711521165318395

Epoch: 6| Step: 3
Training loss: 4.747842399057604
Validation loss: 4.166398205055831

Epoch: 6| Step: 4
Training loss: 4.368567178854755
Validation loss: 4.1605800741111105

Epoch: 6| Step: 5
Training loss: 4.176202593993628
Validation loss: 4.155509328216718

Epoch: 6| Step: 6
Training loss: 3.0315979433440527
Validation loss: 4.150275063495347

Epoch: 6| Step: 7
Training loss: 3.4385600449607234
Validation loss: 4.145813288552342

Epoch: 6| Step: 8
Training loss: 4.6311493279638904
Validation loss: 4.1415313880262445

Epoch: 6| Step: 9
Training loss: 4.780102959964495
Validation loss: 4.136754233616652

Epoch: 6| Step: 10
Training loss: 4.732511147205345
Validation loss: 4.131435306642574

Epoch: 6| Step: 11
Training loss: 4.558498561358897
Validation loss: 4.126380188590853

Epoch: 6| Step: 12
Training loss: 4.211776734697538
Validation loss: 4.120976499121914

Epoch: 6| Step: 13
Training loss: 4.191458581773725
Validation loss: 4.1164872734014875

Epoch: 26| Step: 0
Training loss: 4.80896579719322
Validation loss: 4.111406488947848

Epoch: 6| Step: 1
Training loss: 3.5717663632456813
Validation loss: 4.10635640293415

Epoch: 6| Step: 2
Training loss: 4.817014088140266
Validation loss: 4.101616326841742

Epoch: 6| Step: 3
Training loss: 4.16672292035594
Validation loss: 4.096529669699338

Epoch: 6| Step: 4
Training loss: 3.763996452743367
Validation loss: 4.091571296051756

Epoch: 6| Step: 5
Training loss: 3.0237887077487553
Validation loss: 4.086525674745281

Epoch: 6| Step: 6
Training loss: 4.828359653733427
Validation loss: 4.082280736961961

Epoch: 6| Step: 7
Training loss: 4.802935719778094
Validation loss: 4.077510353822113

Epoch: 6| Step: 8
Training loss: 4.448259446145169
Validation loss: 4.072469363158818

Epoch: 6| Step: 9
Training loss: 4.154846413318032
Validation loss: 4.067648339734775

Epoch: 6| Step: 10
Training loss: 4.2409947300909465
Validation loss: 4.062641845574303

Epoch: 6| Step: 11
Training loss: 3.961257951703792
Validation loss: 4.058262243307512

Epoch: 6| Step: 12
Training loss: 3.559539635713148
Validation loss: 4.05305592192032

Epoch: 6| Step: 13
Training loss: 4.351257423103048
Validation loss: 4.047905573467316

Epoch: 27| Step: 0
Training loss: 3.4230829484469467
Validation loss: 4.043108646841134

Epoch: 6| Step: 1
Training loss: 3.5212407675809283
Validation loss: 4.038330523376705

Epoch: 6| Step: 2
Training loss: 5.01568261229324
Validation loss: 4.0342699513448395

Epoch: 6| Step: 3
Training loss: 3.9801920157268373
Validation loss: 4.029159950374356

Epoch: 6| Step: 4
Training loss: 4.675618078815389
Validation loss: 4.024758486876641

Epoch: 6| Step: 5
Training loss: 3.2844988043741252
Validation loss: 4.019837442246008

Epoch: 6| Step: 6
Training loss: 4.703829791720004
Validation loss: 4.015536454507218

Epoch: 6| Step: 7
Training loss: 4.358452593385532
Validation loss: 4.010539970318934

Epoch: 6| Step: 8
Training loss: 4.471505549302316
Validation loss: 4.005417790617938

Epoch: 6| Step: 9
Training loss: 2.478196047597847
Validation loss: 4.001304155575329

Epoch: 6| Step: 10
Training loss: 3.9057445962108273
Validation loss: 3.9968557715730135

Epoch: 6| Step: 11
Training loss: 4.544744562707434
Validation loss: 3.9920093275151065

Epoch: 6| Step: 12
Training loss: 4.675827752744945
Validation loss: 3.986727649505109

Epoch: 6| Step: 13
Training loss: 4.216252470719772
Validation loss: 3.981743036759003

Epoch: 28| Step: 0
Training loss: 3.8463593596791634
Validation loss: 3.9769029352922667

Epoch: 6| Step: 1
Training loss: 3.5630407090346696
Validation loss: 3.971365519856552

Epoch: 6| Step: 2
Training loss: 4.070494781337102
Validation loss: 3.967036360387876

Epoch: 6| Step: 3
Training loss: 4.264831916385969
Validation loss: 3.962357586889736

Epoch: 6| Step: 4
Training loss: 3.726406901887863
Validation loss: 3.9573209505268743

Epoch: 6| Step: 5
Training loss: 4.619761206330434
Validation loss: 3.9529880102895585

Epoch: 6| Step: 6
Training loss: 3.7494875239830954
Validation loss: 3.94742562386408

Epoch: 6| Step: 7
Training loss: 4.715677233508448
Validation loss: 3.942756272918573

Epoch: 6| Step: 8
Training loss: 3.1913751719723034
Validation loss: 3.937876375566944

Epoch: 6| Step: 9
Training loss: 4.007884599360614
Validation loss: 3.933292482185513

Epoch: 6| Step: 10
Training loss: 4.169193620540624
Validation loss: 3.9280632206386477

Epoch: 6| Step: 11
Training loss: 4.657510266868591
Validation loss: 3.9225908211283014

Epoch: 6| Step: 12
Training loss: 4.631605431718258
Validation loss: 3.9180942666158782

Epoch: 6| Step: 13
Training loss: 3.513466676887602
Validation loss: 3.9135325587659704

Epoch: 29| Step: 0
Training loss: 4.241777207009035
Validation loss: 3.9075602864280286

Epoch: 6| Step: 1
Training loss: 4.146098193936638
Validation loss: 3.901769219644529

Epoch: 6| Step: 2
Training loss: 4.273611117502688
Validation loss: 3.897154449746094

Epoch: 6| Step: 3
Training loss: 2.6729559245587624
Validation loss: 3.892589905308368

Epoch: 6| Step: 4
Training loss: 3.8651018780189768
Validation loss: 3.887584023829974

Epoch: 6| Step: 5
Training loss: 3.3473195070205173
Validation loss: 3.8830640213756413

Epoch: 6| Step: 6
Training loss: 4.878630631100985
Validation loss: 3.8788736731937035

Epoch: 6| Step: 7
Training loss: 4.0872910192420315
Validation loss: 3.8745386197639164

Epoch: 6| Step: 8
Training loss: 4.350133363279833
Validation loss: 3.867827124312053

Epoch: 6| Step: 9
Training loss: 4.194811004273287
Validation loss: 3.862657456136074

Epoch: 6| Step: 10
Training loss: 3.740955253433395
Validation loss: 3.858357551504193

Epoch: 6| Step: 11
Training loss: 3.7334721323732962
Validation loss: 3.853824552181348

Epoch: 6| Step: 12
Training loss: 3.8053670977284333
Validation loss: 3.848858919352475

Epoch: 6| Step: 13
Training loss: 4.347201725454764
Validation loss: 3.844445266490792

Epoch: 30| Step: 0
Training loss: 3.5707900648192297
Validation loss: 3.838764606904743

Epoch: 6| Step: 1
Training loss: 3.529865634943749
Validation loss: 3.8344931022862876

Epoch: 6| Step: 2
Training loss: 3.6623762923560332
Validation loss: 3.8296205881831744

Epoch: 6| Step: 3
Training loss: 3.767521677340875
Validation loss: 3.8261284221254295

Epoch: 6| Step: 4
Training loss: 4.652240434935959
Validation loss: 3.821573539483156

Epoch: 6| Step: 5
Training loss: 4.199090205154611
Validation loss: 3.816001930541557

Epoch: 6| Step: 6
Training loss: 3.979541674347212
Validation loss: 3.811191084003829

Epoch: 6| Step: 7
Training loss: 3.8124562245341593
Validation loss: 3.8062092102905227

Epoch: 6| Step: 8
Training loss: 4.255776910915152
Validation loss: 3.8013300249581965

Epoch: 6| Step: 9
Training loss: 3.7061272534891696
Validation loss: 3.796801300798738

Epoch: 6| Step: 10
Training loss: 4.212148743425755
Validation loss: 3.7929900378629355

Epoch: 6| Step: 11
Training loss: 3.413715964740952
Validation loss: 3.787716844853843

Epoch: 6| Step: 12
Training loss: 3.8865109182028
Validation loss: 3.783490738696185

Epoch: 6| Step: 13
Training loss: 4.346425721173964
Validation loss: 3.7782064542148808

Epoch: 31| Step: 0
Training loss: 3.8464282869581004
Validation loss: 3.7733361103555367

Epoch: 6| Step: 1
Training loss: 4.207269716721081
Validation loss: 3.768695407891673

Epoch: 6| Step: 2
Training loss: 4.252204547645215
Validation loss: 3.764517129141069

Epoch: 6| Step: 3
Training loss: 3.387881949312583
Validation loss: 3.7598523731875515

Epoch: 6| Step: 4
Training loss: 3.911507204498011
Validation loss: 3.7550602997036955

Epoch: 6| Step: 5
Training loss: 3.7062920656438414
Validation loss: 3.750044864810016

Epoch: 6| Step: 6
Training loss: 4.219534341874215
Validation loss: 3.7450286125309016

Epoch: 6| Step: 7
Training loss: 3.3083066489218895
Validation loss: 3.740153036403427

Epoch: 6| Step: 8
Training loss: 3.1464607337333454
Validation loss: 3.735594556962162

Epoch: 6| Step: 9
Training loss: 4.196414852409779
Validation loss: 3.7310911927541333

Epoch: 6| Step: 10
Training loss: 3.3277805490399093
Validation loss: 3.7272929096239396

Epoch: 6| Step: 11
Training loss: 4.4569172021314545
Validation loss: 3.723261599508533

Epoch: 6| Step: 12
Training loss: 4.071072732581638
Validation loss: 3.7183746447648547

Epoch: 6| Step: 13
Training loss: 3.989278969305893
Validation loss: 3.714063517680421

Epoch: 32| Step: 0
Training loss: 3.2456708097760205
Validation loss: 3.7096765564333003

Epoch: 6| Step: 1
Training loss: 3.6439887621273948
Validation loss: 3.7052810122733377

Epoch: 6| Step: 2
Training loss: 4.461696366467886
Validation loss: 3.70111430718065

Epoch: 6| Step: 3
Training loss: 3.701667466613692
Validation loss: 3.6964930341604982

Epoch: 6| Step: 4
Training loss: 4.100651172937568
Validation loss: 3.6920255272748417

Epoch: 6| Step: 5
Training loss: 4.207755675500543
Validation loss: 3.6874467447174557

Epoch: 6| Step: 6
Training loss: 3.9905588071347458
Validation loss: 3.683136249177443

Epoch: 6| Step: 7
Training loss: 4.126012042192128
Validation loss: 3.678314017444037

Epoch: 6| Step: 8
Training loss: 4.176085900808045
Validation loss: 3.6738153836321565

Epoch: 6| Step: 9
Training loss: 3.9957109344373287
Validation loss: 3.66919680923001

Epoch: 6| Step: 10
Training loss: 3.31545845210276
Validation loss: 3.6648283309248932

Epoch: 6| Step: 11
Training loss: 3.5585889261424497
Validation loss: 3.6603473408531206

Epoch: 6| Step: 12
Training loss: 2.7357436760131506
Validation loss: 3.6557948815507824

Epoch: 6| Step: 13
Training loss: 3.830142365441627
Validation loss: 3.6518882970672855

Epoch: 33| Step: 0
Training loss: 3.829104924802464
Validation loss: 3.6467671460936972

Epoch: 6| Step: 1
Training loss: 3.8282385984420513
Validation loss: 3.6429930204362493

Epoch: 6| Step: 2
Training loss: 3.7661864309330126
Validation loss: 3.6383129194673978

Epoch: 6| Step: 3
Training loss: 3.4857032878443155
Validation loss: 3.633762610008669

Epoch: 6| Step: 4
Training loss: 4.378886213435426
Validation loss: 3.629159163691009

Epoch: 6| Step: 5
Training loss: 3.6613613819438053
Validation loss: 3.6249725735383196

Epoch: 6| Step: 6
Training loss: 3.7270091686826885
Validation loss: 3.6205031685964784

Epoch: 6| Step: 7
Training loss: 4.005237488295355
Validation loss: 3.615988788860237

Epoch: 6| Step: 8
Training loss: 4.031549250414846
Validation loss: 3.6113752627146036

Epoch: 6| Step: 9
Training loss: 3.982900788087012
Validation loss: 3.60693547760163

Epoch: 6| Step: 10
Training loss: 3.2149718990254703
Validation loss: 3.601776933113347

Epoch: 6| Step: 11
Training loss: 3.1109179784985193
Validation loss: 3.597369066249924

Epoch: 6| Step: 12
Training loss: 3.3737072764769493
Validation loss: 3.5927135576250926

Epoch: 6| Step: 13
Training loss: 3.9959881452550685
Validation loss: 3.588887449453857

Epoch: 34| Step: 0
Training loss: 3.8322818530282716
Validation loss: 3.584597933686762

Epoch: 6| Step: 1
Training loss: 3.887791961794741
Validation loss: 3.580395262899977

Epoch: 6| Step: 2
Training loss: 3.444932012676077
Validation loss: 3.5765385671525634

Epoch: 6| Step: 3
Training loss: 3.7356242241171738
Validation loss: 3.572511292233516

Epoch: 6| Step: 4
Training loss: 4.004461184866638
Validation loss: 3.5681542036721545

Epoch: 6| Step: 5
Training loss: 4.050135179312306
Validation loss: 3.5639045578878177

Epoch: 6| Step: 6
Training loss: 3.6902304416642395
Validation loss: 3.5599459142541128

Epoch: 6| Step: 7
Training loss: 4.155143418390342
Validation loss: 3.555352050368133

Epoch: 6| Step: 8
Training loss: 3.0415173498283123
Validation loss: 3.55085609393527

Epoch: 6| Step: 9
Training loss: 3.1185588831624558
Validation loss: 3.546438473181982

Epoch: 6| Step: 10
Training loss: 3.41324939254524
Validation loss: 3.5425541532474267

Epoch: 6| Step: 11
Training loss: 3.8893273575660254
Validation loss: 3.538271974997992

Epoch: 6| Step: 12
Training loss: 4.0455675995784315
Validation loss: 3.53418394877112

Epoch: 6| Step: 13
Training loss: 3.2022659266243547
Validation loss: 3.530564188119209

Epoch: 35| Step: 0
Training loss: 2.3547019912486444
Validation loss: 3.5263943216439677

Epoch: 6| Step: 1
Training loss: 3.1595979062917734
Validation loss: 3.5224580044721407

Epoch: 6| Step: 2
Training loss: 3.6620742185812483
Validation loss: 3.518886347602714

Epoch: 6| Step: 3
Training loss: 3.975846561518352
Validation loss: 3.5151155908063303

Epoch: 6| Step: 4
Training loss: 4.1452456621690645
Validation loss: 3.511351592007801

Epoch: 6| Step: 5
Training loss: 4.445315503486463
Validation loss: 3.507098198133627

Epoch: 6| Step: 6
Training loss: 3.3984633170714775
Validation loss: 3.503034173410181

Epoch: 6| Step: 7
Training loss: 4.463520965468818
Validation loss: 3.4989025348114438

Epoch: 6| Step: 8
Training loss: 3.214135130125146
Validation loss: 3.4947110587013355

Epoch: 6| Step: 9
Training loss: 3.337241424945031
Validation loss: 3.4902374717273146

Epoch: 6| Step: 10
Training loss: 3.8920033169739123
Validation loss: 3.4861050859443976

Epoch: 6| Step: 11
Training loss: 3.4688203821688433
Validation loss: 3.4819109405121615

Epoch: 6| Step: 12
Training loss: 3.4037523824548246
Validation loss: 3.4775715138778853

Epoch: 6| Step: 13
Training loss: 3.463484057566398
Validation loss: 3.4738169140414814

Epoch: 36| Step: 0
Training loss: 4.164972087862749
Validation loss: 3.4698777298726413

Epoch: 6| Step: 1
Training loss: 4.333979754039334
Validation loss: 3.465757620050882

Epoch: 6| Step: 2
Training loss: 4.117408008207917
Validation loss: 3.46165841131155

Epoch: 6| Step: 3
Training loss: 3.340548970683877
Validation loss: 3.4574014641472455

Epoch: 6| Step: 4
Training loss: 3.576635592119146
Validation loss: 3.453200418560654

Epoch: 6| Step: 5
Training loss: 3.339864309147248
Validation loss: 3.449096285819366

Epoch: 6| Step: 6
Training loss: 3.1476213708432996
Validation loss: 3.4454295627950677

Epoch: 6| Step: 7
Training loss: 3.6759515737056443
Validation loss: 3.441229559886978

Epoch: 6| Step: 8
Training loss: 3.8704736176313452
Validation loss: 3.437268879374438

Epoch: 6| Step: 9
Training loss: 3.9175077035873223
Validation loss: 3.4334190188212252

Epoch: 6| Step: 10
Training loss: 2.9728057462819453
Validation loss: 3.4291367490505484

Epoch: 6| Step: 11
Training loss: 3.208935189871464
Validation loss: 3.42478018285003

Epoch: 6| Step: 12
Training loss: 2.794447372751827
Validation loss: 3.4212838973128146

Epoch: 6| Step: 13
Training loss: 3.3224212053885678
Validation loss: 3.417435993636072

Epoch: 37| Step: 0
Training loss: 3.3810362348129552
Validation loss: 3.4136677272981104

Epoch: 6| Step: 1
Training loss: 3.808510490876801
Validation loss: 3.4102062616398876

Epoch: 6| Step: 2
Training loss: 4.511113113774532
Validation loss: 3.406658556406578

Epoch: 6| Step: 3
Training loss: 3.2152274402241914
Validation loss: 3.402543550764313

Epoch: 6| Step: 4
Training loss: 3.5503141559697364
Validation loss: 3.398581689574649

Epoch: 6| Step: 5
Training loss: 2.962305563167438
Validation loss: 3.3947884447929746

Epoch: 6| Step: 6
Training loss: 3.6159660633486403
Validation loss: 3.3911394001536435

Epoch: 6| Step: 7
Training loss: 3.5633589395067538
Validation loss: 3.3872712596507975

Epoch: 6| Step: 8
Training loss: 3.775625285726561
Validation loss: 3.383547144430649

Epoch: 6| Step: 9
Training loss: 3.461447236904956
Validation loss: 3.3796765105500475

Epoch: 6| Step: 10
Training loss: 3.557226996813719
Validation loss: 3.375916933374113

Epoch: 6| Step: 11
Training loss: 3.584747981493303
Validation loss: 3.3725590768234475

Epoch: 6| Step: 12
Training loss: 2.629643375164795
Validation loss: 3.3684517949593102

Epoch: 6| Step: 13
Training loss: 3.4800659357598858
Validation loss: 3.3651607163674706

Epoch: 38| Step: 0
Training loss: 4.365076855029861
Validation loss: 3.3613785321188954

Epoch: 6| Step: 1
Training loss: 3.694802246996337
Validation loss: 3.357500603155753

Epoch: 6| Step: 2
Training loss: 3.5619586734077155
Validation loss: 3.3536576463341503

Epoch: 6| Step: 3
Training loss: 3.579089571944444
Validation loss: 3.3496839212884324

Epoch: 6| Step: 4
Training loss: 3.1332450434914083
Validation loss: 3.3460451134290916

Epoch: 6| Step: 5
Training loss: 3.1531678815937094
Validation loss: 3.342712669254834

Epoch: 6| Step: 6
Training loss: 2.8386825853184834
Validation loss: 3.338681619282634

Epoch: 6| Step: 7
Training loss: 3.0046792096178856
Validation loss: 3.335494310538387

Epoch: 6| Step: 8
Training loss: 4.125132703091531
Validation loss: 3.3321877338831847

Epoch: 6| Step: 9
Training loss: 3.1579283227305694
Validation loss: 3.3286683022680785

Epoch: 6| Step: 10
Training loss: 3.7276663434926958
Validation loss: 3.3253793390095154

Epoch: 6| Step: 11
Training loss: 3.2043657086429076
Validation loss: 3.3219800643598316

Epoch: 6| Step: 12
Training loss: 3.2004973263520045
Validation loss: 3.3181431523814098

Epoch: 6| Step: 13
Training loss: 3.602507030895819
Validation loss: 3.3148306918360904

Epoch: 39| Step: 0
Training loss: 3.43030321855133
Validation loss: 3.311113223203914

Epoch: 6| Step: 1
Training loss: 2.415479127099249
Validation loss: 3.307739820178914

Epoch: 6| Step: 2
Training loss: 3.2348087038438407
Validation loss: 3.304352030098537

Epoch: 6| Step: 3
Training loss: 3.649247988218477
Validation loss: 3.3011851648591226

Epoch: 6| Step: 4
Training loss: 3.7674408013060026
Validation loss: 3.2975564406093048

Epoch: 6| Step: 5
Training loss: 3.4208773896280125
Validation loss: 3.2941112052429746

Epoch: 6| Step: 6
Training loss: 3.1615163849094285
Validation loss: 3.2905408809255285

Epoch: 6| Step: 7
Training loss: 3.7360093119829925
Validation loss: 3.286945449993862

Epoch: 6| Step: 8
Training loss: 3.905667314939637
Validation loss: 3.283591340347218

Epoch: 6| Step: 9
Training loss: 3.5456277275915498
Validation loss: 3.2797814125402

Epoch: 6| Step: 10
Training loss: 2.7522067839093203
Validation loss: 3.2760143592234106

Epoch: 6| Step: 11
Training loss: 3.0923905902033026
Validation loss: 3.2726961326642865

Epoch: 6| Step: 12
Training loss: 3.7447276881468996
Validation loss: 3.269365155290228

Epoch: 6| Step: 13
Training loss: 3.8021158852773183
Validation loss: 3.265769261728331

Epoch: 40| Step: 0
Training loss: 3.1177179559231374
Validation loss: 3.2623805670965322

Epoch: 6| Step: 1
Training loss: 3.3472779103593546
Validation loss: 3.259119517187615

Epoch: 6| Step: 2
Training loss: 3.0545974288890645
Validation loss: 3.2557737952878685

Epoch: 6| Step: 3
Training loss: 3.482914366158696
Validation loss: 3.2527706122995865

Epoch: 6| Step: 4
Training loss: 3.632319985095076
Validation loss: 3.249350091557836

Epoch: 6| Step: 5
Training loss: 3.7398388845245925
Validation loss: 3.2460143763955767

Epoch: 6| Step: 6
Training loss: 4.327681646121372
Validation loss: 3.242526239677695

Epoch: 6| Step: 7
Training loss: 3.383689995618717
Validation loss: 3.23910074022817

Epoch: 6| Step: 8
Training loss: 3.366437717874073
Validation loss: 3.235379589791131

Epoch: 6| Step: 9
Training loss: 3.0288315396544374
Validation loss: 3.231804654141415

Epoch: 6| Step: 10
Training loss: 2.758251555076651
Validation loss: 3.2283137435857023

Epoch: 6| Step: 11
Training loss: 3.401621342203936
Validation loss: 3.2250537562264183

Epoch: 6| Step: 12
Training loss: 3.1714435152366995
Validation loss: 3.2220846389760625

Epoch: 6| Step: 13
Training loss: 3.2716146779087554
Validation loss: 3.2188416748818414

Epoch: 41| Step: 0
Training loss: 3.503076971917574
Validation loss: 3.215362914798055

Epoch: 6| Step: 1
Training loss: 3.311596585283985
Validation loss: 3.2124461692723214

Epoch: 6| Step: 2
Training loss: 3.2480526004816492
Validation loss: 3.209111693122815

Epoch: 6| Step: 3
Training loss: 3.266491350672546
Validation loss: 3.205748610924331

Epoch: 6| Step: 4
Training loss: 4.050585132291436
Validation loss: 3.2026978991089603

Epoch: 6| Step: 5
Training loss: 3.4690378430508013
Validation loss: 3.199311195686708

Epoch: 6| Step: 6
Training loss: 3.5181756155520767
Validation loss: 3.1957847911492

Epoch: 6| Step: 7
Training loss: 2.9110897333591326
Validation loss: 3.192496628247947

Epoch: 6| Step: 8
Training loss: 2.6318190876663765
Validation loss: 3.1890285791053725

Epoch: 6| Step: 9
Training loss: 3.374699049353298
Validation loss: 3.186039035059101

Epoch: 6| Step: 10
Training loss: 3.8497632139637976
Validation loss: 3.182862504788836

Epoch: 6| Step: 11
Training loss: 3.6191739586717078
Validation loss: 3.179596020931471

Epoch: 6| Step: 12
Training loss: 2.9647675153860016
Validation loss: 3.176425557234622

Epoch: 6| Step: 13
Training loss: 2.68131849294824
Validation loss: 3.1730243874137742

Epoch: 42| Step: 0
Training loss: 3.4380197305518148
Validation loss: 3.1701680744151237

Epoch: 6| Step: 1
Training loss: 3.3629793924408657
Validation loss: 3.1671867110896432

Epoch: 6| Step: 2
Training loss: 3.3119055736460177
Validation loss: 3.1644412218287603

Epoch: 6| Step: 3
Training loss: 3.184257803155707
Validation loss: 3.161240890206228

Epoch: 6| Step: 4
Training loss: 3.7862159340082533
Validation loss: 3.1583205503810645

Epoch: 6| Step: 5
Training loss: 3.9156286338551824
Validation loss: 3.1554655856602807

Epoch: 6| Step: 6
Training loss: 3.2693676104322615
Validation loss: 3.152155079921184

Epoch: 6| Step: 7
Training loss: 2.044697425861336
Validation loss: 3.1489789069729035

Epoch: 6| Step: 8
Training loss: 3.0815652125073627
Validation loss: 3.1463040048184947

Epoch: 6| Step: 9
Training loss: 3.5372731651665417
Validation loss: 3.143358714108093

Epoch: 6| Step: 10
Training loss: 2.8525897122450417
Validation loss: 3.1402132134425056

Epoch: 6| Step: 11
Training loss: 4.0757652266313364
Validation loss: 3.137472363840406

Epoch: 6| Step: 12
Training loss: 3.0515363982178614
Validation loss: 3.1344442707899964

Epoch: 6| Step: 13
Training loss: 2.641227608264007
Validation loss: 3.13129264513165

Epoch: 43| Step: 0
Training loss: 3.06235145675707
Validation loss: 3.1285827063045963

Epoch: 6| Step: 1
Training loss: 3.079938480208674
Validation loss: 3.1256802645001

Epoch: 6| Step: 2
Training loss: 2.9359506619956766
Validation loss: 3.1228945187798467

Epoch: 6| Step: 3
Training loss: 3.463933676809356
Validation loss: 3.1202708254753047

Epoch: 6| Step: 4
Training loss: 3.759711850264789
Validation loss: 3.1176841550518906

Epoch: 6| Step: 5
Training loss: 3.260996774044272
Validation loss: 3.114641199669462

Epoch: 6| Step: 6
Training loss: 2.906477068162401
Validation loss: 3.1117130862756013

Epoch: 6| Step: 7
Training loss: 3.055916541382953
Validation loss: 3.1088406153122743

Epoch: 6| Step: 8
Training loss: 3.6214790345021837
Validation loss: 3.1060891481400597

Epoch: 6| Step: 9
Training loss: 3.08322944122416
Validation loss: 3.1032190519270078

Epoch: 6| Step: 10
Training loss: 2.6108587923177407
Validation loss: 3.1003725986726467

Epoch: 6| Step: 11
Training loss: 3.6155203155423714
Validation loss: 3.0978479314044076

Epoch: 6| Step: 12
Training loss: 3.6282152846452482
Validation loss: 3.0952757338796

Epoch: 6| Step: 13
Training loss: 3.2118379021925962
Validation loss: 3.092364081066194

Epoch: 44| Step: 0
Training loss: 2.826807294697281
Validation loss: 3.0892093101942373

Epoch: 6| Step: 1
Training loss: 3.61991077840036
Validation loss: 3.086421983247116

Epoch: 6| Step: 2
Training loss: 3.1618537634584847
Validation loss: 3.0838821713095648

Epoch: 6| Step: 3
Training loss: 3.3080927481881814
Validation loss: 3.080891845397878

Epoch: 6| Step: 4
Training loss: 3.356598314222599
Validation loss: 3.078154975241699

Epoch: 6| Step: 5
Training loss: 2.495394947694013
Validation loss: 3.075336749031601

Epoch: 6| Step: 6
Training loss: 2.8395418324076798
Validation loss: 3.0727405734712265

Epoch: 6| Step: 7
Training loss: 3.789824796466855
Validation loss: 3.0704211215023447

Epoch: 6| Step: 8
Training loss: 2.7189402897329873
Validation loss: 3.0673222495853465

Epoch: 6| Step: 9
Training loss: 3.5801116891839073
Validation loss: 3.0649483164940885

Epoch: 6| Step: 10
Training loss: 3.3721779221444756
Validation loss: 3.062290314223529

Epoch: 6| Step: 11
Training loss: 3.088732417082441
Validation loss: 3.0594378622400753

Epoch: 6| Step: 12
Training loss: 3.139484710933166
Validation loss: 3.0564542768426035

Epoch: 6| Step: 13
Training loss: 3.407862570288543
Validation loss: 3.053661307401368

Epoch: 45| Step: 0
Training loss: 3.2988970734080114
Validation loss: 3.0510618998198624

Epoch: 6| Step: 1
Training loss: 2.837783254861919
Validation loss: 3.048272097851816

Epoch: 6| Step: 2
Training loss: 3.3953013715285154
Validation loss: 3.0456067437158985

Epoch: 6| Step: 3
Training loss: 3.3751309687316295
Validation loss: 3.042902699685318

Epoch: 6| Step: 4
Training loss: 3.8153918195826857
Validation loss: 3.040194891279049

Epoch: 6| Step: 5
Training loss: 3.1713450322630723
Validation loss: 3.0373658819115255

Epoch: 6| Step: 6
Training loss: 3.670586412650155
Validation loss: 3.034539067095093

Epoch: 6| Step: 7
Training loss: 2.5834078214017406
Validation loss: 3.0319175247400723

Epoch: 6| Step: 8
Training loss: 2.774196295296868
Validation loss: 3.0292196651336742

Epoch: 6| Step: 9
Training loss: 3.01043665966184
Validation loss: 3.0266705033058128

Epoch: 6| Step: 10
Training loss: 3.2102299488452366
Validation loss: 3.024062046993004

Epoch: 6| Step: 11
Training loss: 3.5157451693871864
Validation loss: 3.021627576048779

Epoch: 6| Step: 12
Training loss: 2.623587000973756
Validation loss: 3.018875241626863

Epoch: 6| Step: 13
Training loss: 2.8885470783133886
Validation loss: 3.016574558587116

Epoch: 46| Step: 0
Training loss: 3.5919005569337354
Validation loss: 3.0137868625660085

Epoch: 6| Step: 1
Training loss: 3.15985898198175
Validation loss: 3.0113304141803696

Epoch: 6| Step: 2
Training loss: 3.252034357562748
Validation loss: 3.009083268869115

Epoch: 6| Step: 3
Training loss: 3.0541015999712218
Validation loss: 3.006691873371448

Epoch: 6| Step: 4
Training loss: 3.1718214810370964
Validation loss: 3.0041092174467137

Epoch: 6| Step: 5
Training loss: 3.2039539288031387
Validation loss: 3.001448956893249

Epoch: 6| Step: 6
Training loss: 2.9632655832493513
Validation loss: 2.998861812210041

Epoch: 6| Step: 7
Training loss: 3.391345532059844
Validation loss: 2.9965042834332727

Epoch: 6| Step: 8
Training loss: 2.9896645529388612
Validation loss: 2.993665019974827

Epoch: 6| Step: 9
Training loss: 2.9010049394146677
Validation loss: 2.991033279999882

Epoch: 6| Step: 10
Training loss: 2.822241295310356
Validation loss: 2.988739709861673

Epoch: 6| Step: 11
Training loss: 3.1542353479390197
Validation loss: 2.986445376196541

Epoch: 6| Step: 12
Training loss: 3.4809256274117346
Validation loss: 2.984020032293869

Epoch: 6| Step: 13
Training loss: 2.711515425497329
Validation loss: 2.9816144655142023

Epoch: 47| Step: 0
Training loss: 3.464885036218227
Validation loss: 2.979452497379857

Epoch: 6| Step: 1
Training loss: 3.589677310775386
Validation loss: 2.9771134274676605

Epoch: 6| Step: 2
Training loss: 3.092520729680074
Validation loss: 2.974646137467075

Epoch: 6| Step: 3
Training loss: 3.1911087551155473
Validation loss: 2.9721281273426947

Epoch: 6| Step: 4
Training loss: 3.1133708486263982
Validation loss: 2.9695511523292963

Epoch: 6| Step: 5
Training loss: 2.3264351670958807
Validation loss: 2.9676386308947897

Epoch: 6| Step: 6
Training loss: 2.2256915614333765
Validation loss: 2.9654292624554777

Epoch: 6| Step: 7
Training loss: 3.088783516294832
Validation loss: 2.9633232577023536

Epoch: 6| Step: 8
Training loss: 2.4860584625219793
Validation loss: 2.961350599206259

Epoch: 6| Step: 9
Training loss: 2.825468048212063
Validation loss: 2.9579721060128255

Epoch: 6| Step: 10
Training loss: 3.583596789115713
Validation loss: 2.9570863853834086

Epoch: 6| Step: 11
Training loss: 2.94086620545565
Validation loss: 2.962076858690152

Epoch: 6| Step: 12
Training loss: 3.406205903214063
Validation loss: 2.9530829371125993

Epoch: 6| Step: 13
Training loss: 3.697071132793836
Validation loss: 2.9501153319923055

Epoch: 48| Step: 0
Training loss: 3.505304404194371
Validation loss: 2.9480736536791428

Epoch: 6| Step: 1
Training loss: 3.3537904674521264
Validation loss: 2.946364615380651

Epoch: 6| Step: 2
Training loss: 3.0570839459863737
Validation loss: 2.945094673068488

Epoch: 6| Step: 3
Training loss: 3.3317790858385337
Validation loss: 2.9453956868830313

Epoch: 6| Step: 4
Training loss: 3.2269866147373985
Validation loss: 2.939794334302457

Epoch: 6| Step: 5
Training loss: 2.587184639846321
Validation loss: 2.936551326394732

Epoch: 6| Step: 6
Training loss: 3.4255582591158307
Validation loss: 2.9340794038964497

Epoch: 6| Step: 7
Training loss: 3.368389578879281
Validation loss: 2.9312297372992018

Epoch: 6| Step: 8
Training loss: 2.9533822083860115
Validation loss: 2.928788192050641

Epoch: 6| Step: 9
Training loss: 2.5827367975733706
Validation loss: 2.9262600801042518

Epoch: 6| Step: 10
Training loss: 3.048293346005798
Validation loss: 2.924238585135524

Epoch: 6| Step: 11
Training loss: 2.903014976954287
Validation loss: 2.9223027995603603

Epoch: 6| Step: 12
Training loss: 2.827113861241501
Validation loss: 2.9196724571437436

Epoch: 6| Step: 13
Training loss: 2.7175974540467194
Validation loss: 2.9182142012320935

Epoch: 49| Step: 0
Training loss: 3.2751221612175687
Validation loss: 2.9155138371391702

Epoch: 6| Step: 1
Training loss: 2.9179148228576084
Validation loss: 2.9139474090948134

Epoch: 6| Step: 2
Training loss: 3.879442437214042
Validation loss: 2.9118574866304288

Epoch: 6| Step: 3
Training loss: 3.4179584263236946
Validation loss: 2.91073396482733

Epoch: 6| Step: 4
Training loss: 2.1199723400254884
Validation loss: 2.9068200704212486

Epoch: 6| Step: 5
Training loss: 2.979313097647422
Validation loss: 2.905499501555809

Epoch: 6| Step: 6
Training loss: 2.5116174656690378
Validation loss: 2.9101990971835248

Epoch: 6| Step: 7
Training loss: 2.5480302870071734
Validation loss: 2.905302364942646

Epoch: 6| Step: 8
Training loss: 2.6983158793207895
Validation loss: 2.8981050093268967

Epoch: 6| Step: 9
Training loss: 3.68301338486281
Validation loss: 2.897032857501172

Epoch: 6| Step: 10
Training loss: 3.203690344068651
Validation loss: 2.8951106278843306

Epoch: 6| Step: 11
Training loss: 2.7580341541811775
Validation loss: 2.8936119799178144

Epoch: 6| Step: 12
Training loss: 3.1677438677310783
Validation loss: 2.891343352265782

Epoch: 6| Step: 13
Training loss: 3.0027621586907345
Validation loss: 2.8887342438102364

Epoch: 50| Step: 0
Training loss: 2.7422817463994726
Validation loss: 2.8868446993677757

Epoch: 6| Step: 1
Training loss: 3.072480734383729
Validation loss: 2.8848095380212477

Epoch: 6| Step: 2
Training loss: 3.5219378271989394
Validation loss: 2.881800045598706

Epoch: 6| Step: 3
Training loss: 2.5943356507730586
Validation loss: 2.880661393598718

Epoch: 6| Step: 4
Training loss: 3.416839099037433
Validation loss: 2.8784091749803826

Epoch: 6| Step: 5
Training loss: 3.118814985251842
Validation loss: 2.8763603088278695

Epoch: 6| Step: 6
Training loss: 2.7445242725590924
Validation loss: 2.874490139850385

Epoch: 6| Step: 7
Training loss: 2.607889357817622
Validation loss: 2.872242116172592

Epoch: 6| Step: 8
Training loss: 2.7834586471245957
Validation loss: 2.86976096430496

Epoch: 6| Step: 9
Training loss: 3.217727943295615
Validation loss: 2.8661460197587774

Epoch: 6| Step: 10
Training loss: 2.7820784802861316
Validation loss: 2.864365799475897

Epoch: 6| Step: 11
Training loss: 3.7462575675778456
Validation loss: 2.8648667536313828

Epoch: 6| Step: 12
Training loss: 2.398670297066848
Validation loss: 2.87171992179683

Epoch: 6| Step: 13
Training loss: 3.212747847796417
Validation loss: 2.877718386677517

Epoch: 51| Step: 0
Training loss: 3.0471986256414807
Validation loss: 2.8570401051187355

Epoch: 6| Step: 1
Training loss: 3.5568854275478357
Validation loss: 2.8558460548176163

Epoch: 6| Step: 2
Training loss: 3.253898629755483
Validation loss: 2.8553285855718356

Epoch: 6| Step: 3
Training loss: 2.396538495212043
Validation loss: 2.8555052650994037

Epoch: 6| Step: 4
Training loss: 2.9302515733016703
Validation loss: 2.856120621792902

Epoch: 6| Step: 5
Training loss: 3.1580303949363433
Validation loss: 2.8558274377369273

Epoch: 6| Step: 6
Training loss: 2.900857167338277
Validation loss: 2.8559402097486104

Epoch: 6| Step: 7
Training loss: 2.857209099274167
Validation loss: 2.852694282457204

Epoch: 6| Step: 8
Training loss: 3.3432579748066704
Validation loss: 2.848343140585414

Epoch: 6| Step: 9
Training loss: 3.3326514182350166
Validation loss: 2.8465270571306944

Epoch: 6| Step: 10
Training loss: 2.710305879651445
Validation loss: 2.8428804374606704

Epoch: 6| Step: 11
Training loss: 2.3545373495383535
Validation loss: 2.841112289906692

Epoch: 6| Step: 12
Training loss: 3.163435508865322
Validation loss: 2.8378729542941046

Epoch: 6| Step: 13
Training loss: 2.601048140899052
Validation loss: 2.836094090926157

Epoch: 52| Step: 0
Training loss: 2.656178731523236
Validation loss: 2.8336443356385437

Epoch: 6| Step: 1
Training loss: 3.3037569796618005
Validation loss: 2.8325082942777238

Epoch: 6| Step: 2
Training loss: 3.1687642896582076
Validation loss: 2.8306714812118163

Epoch: 6| Step: 3
Training loss: 3.0306386429441643
Validation loss: 2.8281518643334462

Epoch: 6| Step: 4
Training loss: 2.9980303338305903
Validation loss: 2.826050589453989

Epoch: 6| Step: 5
Training loss: 3.0806032070659093
Validation loss: 2.8243546758771516

Epoch: 6| Step: 6
Training loss: 2.0374713404225377
Validation loss: 2.82179522790592

Epoch: 6| Step: 7
Training loss: 2.980812382918154
Validation loss: 2.8208019645520714

Epoch: 6| Step: 8
Training loss: 2.9510439044061036
Validation loss: 2.8192854514389913

Epoch: 6| Step: 9
Training loss: 2.9504277258668723
Validation loss: 2.8182512325583193

Epoch: 6| Step: 10
Training loss: 3.092633286659114
Validation loss: 2.8160001944393755

Epoch: 6| Step: 11
Training loss: 3.02742455159305
Validation loss: 2.8130690528782964

Epoch: 6| Step: 12
Training loss: 3.0843500231008867
Validation loss: 2.811783536853743

Epoch: 6| Step: 13
Training loss: 2.9396093384051842
Validation loss: 2.8095276561615283

Epoch: 53| Step: 0
Training loss: 3.432958759010142
Validation loss: 2.807479701117406

Epoch: 6| Step: 1
Training loss: 3.45091418441417
Validation loss: 2.8055232227673934

Epoch: 6| Step: 2
Training loss: 2.828883622570718
Validation loss: 2.8035245873538877

Epoch: 6| Step: 3
Training loss: 2.327001108363551
Validation loss: 2.8033742070213874

Epoch: 6| Step: 4
Training loss: 3.187852129465986
Validation loss: 2.799871349217493

Epoch: 6| Step: 5
Training loss: 2.3866962737727997
Validation loss: 2.7993300476575795

Epoch: 6| Step: 6
Training loss: 3.049535597168598
Validation loss: 2.7954460201711413

Epoch: 6| Step: 7
Training loss: 2.9483515190683547
Validation loss: 2.7932768396144048

Epoch: 6| Step: 8
Training loss: 2.6793356795169796
Validation loss: 2.7911564422384925

Epoch: 6| Step: 9
Training loss: 2.7609962478717205
Validation loss: 2.7897386915511735

Epoch: 6| Step: 10
Training loss: 2.7828560810221368
Validation loss: 2.786289835080777

Epoch: 6| Step: 11
Training loss: 2.728740183191819
Validation loss: 2.783782249118856

Epoch: 6| Step: 12
Training loss: 3.528417480887656
Validation loss: 2.782582860171608

Epoch: 6| Step: 13
Training loss: 2.7096568663867995
Validation loss: 2.7815743160821826

Epoch: 54| Step: 0
Training loss: 3.2611663898878542
Validation loss: 2.7773433493941635

Epoch: 6| Step: 1
Training loss: 2.8831909262121695
Validation loss: 2.777075860561229

Epoch: 6| Step: 2
Training loss: 3.335832294886746
Validation loss: 2.773858324101484

Epoch: 6| Step: 3
Training loss: 3.6645909560693366
Validation loss: 2.7752105203453876

Epoch: 6| Step: 4
Training loss: 3.230479082416215
Validation loss: 2.772545154273773

Epoch: 6| Step: 5
Training loss: 2.5750767113082893
Validation loss: 2.7719895859192882

Epoch: 6| Step: 6
Training loss: 2.5042779560293797
Validation loss: 2.7712333696365636

Epoch: 6| Step: 7
Training loss: 2.6118101532483804
Validation loss: 2.771468474557799

Epoch: 6| Step: 8
Training loss: 2.6425461862329884
Validation loss: 2.7696545945119957

Epoch: 6| Step: 9
Training loss: 2.9140814813808746
Validation loss: 2.765672686896688

Epoch: 6| Step: 10
Training loss: 2.643264895543751
Validation loss: 2.7650111176242556

Epoch: 6| Step: 11
Training loss: 2.692948960867057
Validation loss: 2.7627513920708546

Epoch: 6| Step: 12
Training loss: 2.8756175829122856
Validation loss: 2.7613577240284672

Epoch: 6| Step: 13
Training loss: 2.7139719928766577
Validation loss: 2.759727785535441

Epoch: 55| Step: 0
Training loss: 2.3503273796763917
Validation loss: 2.7583053479883053

Epoch: 6| Step: 1
Training loss: 2.8301040721938553
Validation loss: 2.757773553070752

Epoch: 6| Step: 2
Training loss: 2.829876099425228
Validation loss: 2.754936757732052

Epoch: 6| Step: 3
Training loss: 3.5888444674025726
Validation loss: 2.7548698020212243

Epoch: 6| Step: 4
Training loss: 2.444645897434386
Validation loss: 2.7524325564809904

Epoch: 6| Step: 5
Training loss: 3.2123837520480585
Validation loss: 2.749481600248302

Epoch: 6| Step: 6
Training loss: 3.2274965130516025
Validation loss: 2.749413702338935

Epoch: 6| Step: 7
Training loss: 2.7917449617556467
Validation loss: 2.7467284827853162

Epoch: 6| Step: 8
Training loss: 2.575237344710541
Validation loss: 2.7443034964269715

Epoch: 6| Step: 9
Training loss: 2.76713891269412
Validation loss: 2.7471042689270084

Epoch: 6| Step: 10
Training loss: 2.9846028345828857
Validation loss: 2.7598182365440276

Epoch: 6| Step: 11
Training loss: 3.0481908842173873
Validation loss: 2.757559529662297

Epoch: 6| Step: 12
Training loss: 3.11305379575132
Validation loss: 2.7425603078808467

Epoch: 6| Step: 13
Training loss: 2.4935106932275204
Validation loss: 2.738617060626984

Epoch: 56| Step: 0
Training loss: 2.8699106698306163
Validation loss: 2.7342860906769344

Epoch: 6| Step: 1
Training loss: 2.8306883265342972
Validation loss: 2.732664347013947

Epoch: 6| Step: 2
Training loss: 2.845515949950613
Validation loss: 2.730588198165184

Epoch: 6| Step: 3
Training loss: 2.700549535988126
Validation loss: 2.7291010977364434

Epoch: 6| Step: 4
Training loss: 3.095613015003598
Validation loss: 2.7288416797604502

Epoch: 6| Step: 5
Training loss: 2.9941442879034184
Validation loss: 2.729480118744748

Epoch: 6| Step: 6
Training loss: 3.4322025054017335
Validation loss: 2.729389623217423

Epoch: 6| Step: 7
Training loss: 2.6896383959991557
Validation loss: 2.7303489764297946

Epoch: 6| Step: 8
Training loss: 2.391428693923387
Validation loss: 2.7287981255260476

Epoch: 6| Step: 9
Training loss: 2.856957419372217
Validation loss: 2.7306061556855568

Epoch: 6| Step: 10
Training loss: 2.8905943172991515
Validation loss: 2.728182496305775

Epoch: 6| Step: 11
Training loss: 3.034447153885551
Validation loss: 2.724981904625963

Epoch: 6| Step: 12
Training loss: 2.8479027242442485
Validation loss: 2.7229247651761685

Epoch: 6| Step: 13
Training loss: 2.585385358704371
Validation loss: 2.7193517347886735

Epoch: 57| Step: 0
Training loss: 3.164403675664436
Validation loss: 2.7168920314276344

Epoch: 6| Step: 1
Training loss: 3.2095103561250924
Validation loss: 2.714075827908994

Epoch: 6| Step: 2
Training loss: 2.17017237387361
Validation loss: 2.7168174686195288

Epoch: 6| Step: 3
Training loss: 2.879421317454791
Validation loss: 2.715298694574476

Epoch: 6| Step: 4
Training loss: 3.016216477019293
Validation loss: 2.710960629938926

Epoch: 6| Step: 5
Training loss: 3.093821515114085
Validation loss: 2.708102015862828

Epoch: 6| Step: 6
Training loss: 2.535710114105293
Validation loss: 2.7076679781827186

Epoch: 6| Step: 7
Training loss: 2.820852381211341
Validation loss: 2.706351557728254

Epoch: 6| Step: 8
Training loss: 2.5997407050316457
Validation loss: 2.707255887632608

Epoch: 6| Step: 9
Training loss: 3.247748255120414
Validation loss: 2.707156238542008

Epoch: 6| Step: 10
Training loss: 3.0186256146127644
Validation loss: 2.702899445695051

Epoch: 6| Step: 11
Training loss: 2.823319287931357
Validation loss: 2.700012075726855

Epoch: 6| Step: 12
Training loss: 2.468093495055585
Validation loss: 2.6997151412929448

Epoch: 6| Step: 13
Training loss: 2.6191337977924163
Validation loss: 2.698471591589061

Epoch: 58| Step: 0
Training loss: 2.91004777744569
Validation loss: 2.7008374187089794

Epoch: 6| Step: 1
Training loss: 2.988763109638686
Validation loss: 2.6959462770586162

Epoch: 6| Step: 2
Training loss: 2.7175112127302614
Validation loss: 2.7009500415667804

Epoch: 6| Step: 3
Training loss: 2.5263666212673312
Validation loss: 2.7037689823701765

Epoch: 6| Step: 4
Training loss: 2.755604235371228
Validation loss: 2.702048070633873

Epoch: 6| Step: 5
Training loss: 2.8306131956225355
Validation loss: 2.7028940796754917

Epoch: 6| Step: 6
Training loss: 2.9388885462792174
Validation loss: 2.6952720159908745

Epoch: 6| Step: 7
Training loss: 2.7653473967976585
Validation loss: 2.6917936934819213

Epoch: 6| Step: 8
Training loss: 2.593050299336462
Validation loss: 2.6878129643809183

Epoch: 6| Step: 9
Training loss: 2.6430385777706658
Validation loss: 2.6858487194242744

Epoch: 6| Step: 10
Training loss: 2.9308581645464313
Validation loss: 2.686217852376881

Epoch: 6| Step: 11
Training loss: 2.8367735415929376
Validation loss: 2.6861023484483466

Epoch: 6| Step: 12
Training loss: 2.9166364577409256
Validation loss: 2.6826606323886577

Epoch: 6| Step: 13
Training loss: 3.2563818848127024
Validation loss: 2.6846870812343337

Epoch: 59| Step: 0
Training loss: 2.994208467614468
Validation loss: 2.679347232609171

Epoch: 6| Step: 1
Training loss: 2.80135170462151
Validation loss: 2.681796623891774

Epoch: 6| Step: 2
Training loss: 2.521883270363559
Validation loss: 2.6791008250529424

Epoch: 6| Step: 3
Training loss: 2.825910850128421
Validation loss: 2.6817342283875036

Epoch: 6| Step: 4
Training loss: 3.3897352325660206
Validation loss: 2.678293753566716

Epoch: 6| Step: 5
Training loss: 2.8900568223270797
Validation loss: 2.6787395376101113

Epoch: 6| Step: 6
Training loss: 2.548893228335217
Validation loss: 2.677298159953699

Epoch: 6| Step: 7
Training loss: 2.767706739496747
Validation loss: 2.6743939518314597

Epoch: 6| Step: 8
Training loss: 2.963486351922719
Validation loss: 2.6725701957645303

Epoch: 6| Step: 9
Training loss: 2.90087590637206
Validation loss: 2.6703655894630507

Epoch: 6| Step: 10
Training loss: 2.224476690580514
Validation loss: 2.6694718646510083

Epoch: 6| Step: 11
Training loss: 2.810050575914387
Validation loss: 2.667009679270648

Epoch: 6| Step: 12
Training loss: 2.747889055330745
Validation loss: 2.6629661325145912

Epoch: 6| Step: 13
Training loss: 2.8244743600830584
Validation loss: 2.666061725148012

Epoch: 60| Step: 0
Training loss: 2.8469120094414495
Validation loss: 2.662570539325093

Epoch: 6| Step: 1
Training loss: 3.010101477854596
Validation loss: 2.6598998481616114

Epoch: 6| Step: 2
Training loss: 2.793936096410875
Validation loss: 2.659703601299426

Epoch: 6| Step: 3
Training loss: 2.5948212950515828
Validation loss: 2.6621782009886132

Epoch: 6| Step: 4
Training loss: 2.71940552273741
Validation loss: 2.659518426358804

Epoch: 6| Step: 5
Training loss: 2.5718123399371557
Validation loss: 2.6612044858467234

Epoch: 6| Step: 6
Training loss: 2.9804049143823255
Validation loss: 2.662933841395863

Epoch: 6| Step: 7
Training loss: 2.7747105215487893
Validation loss: 2.66862678511405

Epoch: 6| Step: 8
Training loss: 2.830981082229172
Validation loss: 2.692537214989534

Epoch: 6| Step: 9
Training loss: 2.3724698091119527
Validation loss: 2.697693087667578

Epoch: 6| Step: 10
Training loss: 2.9023754585351513
Validation loss: 2.6854170038436624

Epoch: 6| Step: 11
Training loss: 2.6928186350993055
Validation loss: 2.657372525454251

Epoch: 6| Step: 12
Training loss: 3.148219553027543
Validation loss: 2.6532968448241796

Epoch: 6| Step: 13
Training loss: 2.9462681846397336
Validation loss: 2.655994851816887

Epoch: 61| Step: 0
Training loss: 3.014303125216254
Validation loss: 2.6707762602502068

Epoch: 6| Step: 1
Training loss: 3.0516203094022605
Validation loss: 2.686264027410526

Epoch: 6| Step: 2
Training loss: 2.798725049076738
Validation loss: 2.702974436541335

Epoch: 6| Step: 3
Training loss: 2.4645181431751624
Validation loss: 2.6948906314953933

Epoch: 6| Step: 4
Training loss: 2.911459570778099
Validation loss: 2.685201859940047

Epoch: 6| Step: 5
Training loss: 2.3883899887332576
Validation loss: 2.6691249354737985

Epoch: 6| Step: 6
Training loss: 2.7813561237104922
Validation loss: 2.6620300833446944

Epoch: 6| Step: 7
Training loss: 2.5113215629288974
Validation loss: 2.66070897451415

Epoch: 6| Step: 8
Training loss: 2.9069573966868423
Validation loss: 2.657006952476953

Epoch: 6| Step: 9
Training loss: 3.135399565961637
Validation loss: 2.6538377317474273

Epoch: 6| Step: 10
Training loss: 2.7187037847690627
Validation loss: 2.649931674652257

Epoch: 6| Step: 11
Training loss: 3.251393239621628
Validation loss: 2.6478620596076365

Epoch: 6| Step: 12
Training loss: 2.4672586306367763
Validation loss: 2.646208283496941

Epoch: 6| Step: 13
Training loss: 2.6891930148931475
Validation loss: 2.64349741709875

Epoch: 62| Step: 0
Training loss: 2.9067776108779912
Validation loss: 2.6396728394067637

Epoch: 6| Step: 1
Training loss: 2.807449723266551
Validation loss: 2.6395632623894443

Epoch: 6| Step: 2
Training loss: 2.8034475661902745
Validation loss: 2.6359614737671127

Epoch: 6| Step: 3
Training loss: 2.8134406318210696
Validation loss: 2.6330345807236832

Epoch: 6| Step: 4
Training loss: 3.136594092907482
Validation loss: 2.6308669269758287

Epoch: 6| Step: 5
Training loss: 2.794161199224371
Validation loss: 2.6297453570409086

Epoch: 6| Step: 6
Training loss: 2.38880202655438
Validation loss: 2.6293934884950345

Epoch: 6| Step: 7
Training loss: 2.5246988929012693
Validation loss: 2.628157427297052

Epoch: 6| Step: 8
Training loss: 2.9629952318588964
Validation loss: 2.6303649150709023

Epoch: 6| Step: 9
Training loss: 3.0649681266384436
Validation loss: 2.6384275875336836

Epoch: 6| Step: 10
Training loss: 2.5217209401396827
Validation loss: 2.6412009790423627

Epoch: 6| Step: 11
Training loss: 2.5403309631990654
Validation loss: 2.6391252701835883

Epoch: 6| Step: 12
Training loss: 2.677121371185769
Validation loss: 2.626519459756244

Epoch: 6| Step: 13
Training loss: 2.6730528795040245
Validation loss: 2.6295603089182653

Epoch: 63| Step: 0
Training loss: 2.60141164897904
Validation loss: 2.6247771183638866

Epoch: 6| Step: 1
Training loss: 2.842349703261779
Validation loss: 2.622238144336824

Epoch: 6| Step: 2
Training loss: 2.5955353073396497
Validation loss: 2.622280271093271

Epoch: 6| Step: 3
Training loss: 2.9269598304695146
Validation loss: 2.622509895478166

Epoch: 6| Step: 4
Training loss: 2.6209853216674994
Validation loss: 2.623727171981682

Epoch: 6| Step: 5
Training loss: 2.7751432089753973
Validation loss: 2.620384768522725

Epoch: 6| Step: 6
Training loss: 3.008114965514442
Validation loss: 2.62250391040725

Epoch: 6| Step: 7
Training loss: 2.6842281030467197
Validation loss: 2.620419896502351

Epoch: 6| Step: 8
Training loss: 2.605825236809814
Validation loss: 2.618037511851639

Epoch: 6| Step: 9
Training loss: 2.341466172437672
Validation loss: 2.6169006494115874

Epoch: 6| Step: 10
Training loss: 2.7587557036146864
Validation loss: 2.617708251159723

Epoch: 6| Step: 11
Training loss: 3.0378809497704196
Validation loss: 2.615206584635571

Epoch: 6| Step: 12
Training loss: 2.8882971385779848
Validation loss: 2.615285335896081

Epoch: 6| Step: 13
Training loss: 2.858304516468164
Validation loss: 2.6121110714853235

Epoch: 64| Step: 0
Training loss: 2.42682805717626
Validation loss: 2.611838238388881

Epoch: 6| Step: 1
Training loss: 2.738759389536513
Validation loss: 2.612195437990064

Epoch: 6| Step: 2
Training loss: 2.198218326447576
Validation loss: 2.6104082509783244

Epoch: 6| Step: 3
Training loss: 2.8781101156009328
Validation loss: 2.6098057282884772

Epoch: 6| Step: 4
Training loss: 2.8928731887614574
Validation loss: 2.608391178472814

Epoch: 6| Step: 5
Training loss: 2.5829986745171536
Validation loss: 2.6066787403669363

Epoch: 6| Step: 6
Training loss: 2.9594494142612557
Validation loss: 2.6057290438562353

Epoch: 6| Step: 7
Training loss: 2.788381626997696
Validation loss: 2.605626305006174

Epoch: 6| Step: 8
Training loss: 3.1446607480128557
Validation loss: 2.6029357416992736

Epoch: 6| Step: 9
Training loss: 2.8402675223275486
Validation loss: 2.6030359076632945

Epoch: 6| Step: 10
Training loss: 2.666055509946614
Validation loss: 2.6026445187309637

Epoch: 6| Step: 11
Training loss: 3.0815406089680595
Validation loss: 2.603505032730782

Epoch: 6| Step: 12
Training loss: 2.69625351553216
Validation loss: 2.602775497146018

Epoch: 6| Step: 13
Training loss: 2.3120807576974354
Validation loss: 2.6017777331942

Epoch: 65| Step: 0
Training loss: 2.5444054361358175
Validation loss: 2.5974830512337386

Epoch: 6| Step: 1
Training loss: 3.131234473153791
Validation loss: 2.599367898128928

Epoch: 6| Step: 2
Training loss: 2.00200885974246
Validation loss: 2.595269152795851

Epoch: 6| Step: 3
Training loss: 2.281892764320906
Validation loss: 2.5978188982454604

Epoch: 6| Step: 4
Training loss: 2.6398188697927214
Validation loss: 2.5969342827485633

Epoch: 6| Step: 5
Training loss: 3.1793485643604997
Validation loss: 2.597391337795025

Epoch: 6| Step: 6
Training loss: 3.194095146505758
Validation loss: 2.593745266094254

Epoch: 6| Step: 7
Training loss: 2.793757229994053
Validation loss: 2.5926840250100036

Epoch: 6| Step: 8
Training loss: 2.8557340861353553
Validation loss: 2.5953030666644565

Epoch: 6| Step: 9
Training loss: 2.5484618877504626
Validation loss: 2.5941461007879405

Epoch: 6| Step: 10
Training loss: 2.7286297413166474
Validation loss: 2.6032749836529185

Epoch: 6| Step: 11
Training loss: 2.756881599980499
Validation loss: 2.5941965109479566

Epoch: 6| Step: 12
Training loss: 2.4547121781262677
Validation loss: 2.5872635682672027

Epoch: 6| Step: 13
Training loss: 2.7888891342520976
Validation loss: 2.589643452428062

Epoch: 66| Step: 0
Training loss: 2.542320250812322
Validation loss: 2.5870616578406316

Epoch: 6| Step: 1
Training loss: 3.1103054168966997
Validation loss: 2.592241024471106

Epoch: 6| Step: 2
Training loss: 3.118142347442396
Validation loss: 2.587229180407076

Epoch: 6| Step: 3
Training loss: 2.9179051812331873
Validation loss: 2.5880682580791343

Epoch: 6| Step: 4
Training loss: 2.3004141807807583
Validation loss: 2.585654344067166

Epoch: 6| Step: 5
Training loss: 2.964667635425192
Validation loss: 2.5841989041306053

Epoch: 6| Step: 6
Training loss: 2.363945178885681
Validation loss: 2.582885216229533

Epoch: 6| Step: 7
Training loss: 2.772846513563411
Validation loss: 2.5845666269265375

Epoch: 6| Step: 8
Training loss: 2.6708932601069564
Validation loss: 2.5849187098350463

Epoch: 6| Step: 9
Training loss: 2.431030000671785
Validation loss: 2.5820619674602168

Epoch: 6| Step: 10
Training loss: 2.165328884384834
Validation loss: 2.581207959784895

Epoch: 6| Step: 11
Training loss: 3.3843887568341278
Validation loss: 2.578044034669112

Epoch: 6| Step: 12
Training loss: 2.4036208813089583
Validation loss: 2.578388270027306

Epoch: 6| Step: 13
Training loss: 2.5259865561434856
Validation loss: 2.576616666743798

Epoch: 67| Step: 0
Training loss: 2.87517696333558
Validation loss: 2.5788748219110187

Epoch: 6| Step: 1
Training loss: 2.0327559537301907
Validation loss: 2.575932736271869

Epoch: 6| Step: 2
Training loss: 2.7842935775000464
Validation loss: 2.576397928071824

Epoch: 6| Step: 3
Training loss: 3.2195975659915135
Validation loss: 2.575700193716255

Epoch: 6| Step: 4
Training loss: 3.2804435102159983
Validation loss: 2.573604110947973

Epoch: 6| Step: 5
Training loss: 2.375726187261402
Validation loss: 2.57534703567333

Epoch: 6| Step: 6
Training loss: 2.197310329406345
Validation loss: 2.574620232462495

Epoch: 6| Step: 7
Training loss: 3.224554069502255
Validation loss: 2.5699895715811154

Epoch: 6| Step: 8
Training loss: 2.7469731926319954
Validation loss: 2.5696090616870446

Epoch: 6| Step: 9
Training loss: 2.8126228305697576
Validation loss: 2.570311804310435

Epoch: 6| Step: 10
Training loss: 2.656696955158388
Validation loss: 2.570946218175122

Epoch: 6| Step: 11
Training loss: 2.35311888837084
Validation loss: 2.571302739160242

Epoch: 6| Step: 12
Training loss: 2.10680996387357
Validation loss: 2.566848554194004

Epoch: 6| Step: 13
Training loss: 2.8762700136790627
Validation loss: 2.5706105779244344

Epoch: 68| Step: 0
Training loss: 3.21927586676309
Validation loss: 2.5681592894773377

Epoch: 6| Step: 1
Training loss: 2.6114937409499945
Validation loss: 2.5709406308412066

Epoch: 6| Step: 2
Training loss: 2.5065388044591046
Validation loss: 2.570561591140077

Epoch: 6| Step: 3
Training loss: 2.629279417672277
Validation loss: 2.566384232657411

Epoch: 6| Step: 4
Training loss: 2.7339426625287206
Validation loss: 2.566941637527668

Epoch: 6| Step: 5
Training loss: 2.0078293617817016
Validation loss: 2.5651036657858937

Epoch: 6| Step: 6
Training loss: 2.741193020459347
Validation loss: 2.564488608508718

Epoch: 6| Step: 7
Training loss: 2.912406716878926
Validation loss: 2.5664300786832555

Epoch: 6| Step: 8
Training loss: 2.0815826562565034
Validation loss: 2.5672300769001763

Epoch: 6| Step: 9
Training loss: 2.923815078043703
Validation loss: 2.56710115466696

Epoch: 6| Step: 10
Training loss: 2.957014479394319
Validation loss: 2.561535770155334

Epoch: 6| Step: 11
Training loss: 2.879351267069936
Validation loss: 2.5674041402788688

Epoch: 6| Step: 12
Training loss: 2.731291160011476
Validation loss: 2.5636722550553404

Epoch: 6| Step: 13
Training loss: 2.6363510666670154
Validation loss: 2.560195056790735

Epoch: 69| Step: 0
Training loss: 2.94671451782913
Validation loss: 2.560726947984933

Epoch: 6| Step: 1
Training loss: 2.2475119715828984
Validation loss: 2.5610429141227433

Epoch: 6| Step: 2
Training loss: 2.92347094355119
Validation loss: 2.5622229232476497

Epoch: 6| Step: 3
Training loss: 2.5120852189703644
Validation loss: 2.5613852766761434

Epoch: 6| Step: 4
Training loss: 2.937331336840509
Validation loss: 2.561279688610793

Epoch: 6| Step: 5
Training loss: 2.545451509486283
Validation loss: 2.5581739552045866

Epoch: 6| Step: 6
Training loss: 2.3013038754100985
Validation loss: 2.561062836232287

Epoch: 6| Step: 7
Training loss: 2.7031484613888823
Validation loss: 2.5566808485145924

Epoch: 6| Step: 8
Training loss: 2.4107279539982267
Validation loss: 2.559055261508923

Epoch: 6| Step: 9
Training loss: 2.7794397870956535
Validation loss: 2.558225897439457

Epoch: 6| Step: 10
Training loss: 2.665938357396782
Validation loss: 2.5559386554191015

Epoch: 6| Step: 11
Training loss: 2.2422279061853563
Validation loss: 2.554921566256366

Epoch: 6| Step: 12
Training loss: 3.237850367613018
Validation loss: 2.5538483154223206

Epoch: 6| Step: 13
Training loss: 2.95256287406883
Validation loss: 2.5534857082301876

Epoch: 70| Step: 0
Training loss: 2.8799424189533402
Validation loss: 2.5527503770260056

Epoch: 6| Step: 1
Training loss: 2.813844994966973
Validation loss: 2.5532616263181875

Epoch: 6| Step: 2
Training loss: 2.8118764397998386
Validation loss: 2.5531912183014636

Epoch: 6| Step: 3
Training loss: 2.8962953779792397
Validation loss: 2.550169937230751

Epoch: 6| Step: 4
Training loss: 2.002897547813201
Validation loss: 2.552151010874541

Epoch: 6| Step: 5
Training loss: 2.614032358017438
Validation loss: 2.550504021916686

Epoch: 6| Step: 6
Training loss: 2.9885742043901944
Validation loss: 2.5520711210828

Epoch: 6| Step: 7
Training loss: 2.409100021325442
Validation loss: 2.5494814214543835

Epoch: 6| Step: 8
Training loss: 2.2375873868276486
Validation loss: 2.54836349832043

Epoch: 6| Step: 9
Training loss: 2.9073248075543767
Validation loss: 2.546864406197013

Epoch: 6| Step: 10
Training loss: 2.4816202689761604
Validation loss: 2.5450406948251016

Epoch: 6| Step: 11
Training loss: 2.4430164611861427
Validation loss: 2.546814791039862

Epoch: 6| Step: 12
Training loss: 2.9513153505825134
Validation loss: 2.5468716299584684

Epoch: 6| Step: 13
Training loss: 2.832156179895335
Validation loss: 2.547532260080312

Epoch: 71| Step: 0
Training loss: 2.2558483833606675
Validation loss: 2.5391526974038277

Epoch: 6| Step: 1
Training loss: 2.852167269184732
Validation loss: 2.5477988005039416

Epoch: 6| Step: 2
Training loss: 2.622186970024796
Validation loss: 2.544640791724059

Epoch: 6| Step: 3
Training loss: 2.8665424837523736
Validation loss: 2.53880138130477

Epoch: 6| Step: 4
Training loss: 2.7270074606983283
Validation loss: 2.5396045438795025

Epoch: 6| Step: 5
Training loss: 2.9882538039997777
Validation loss: 2.5423616074188184

Epoch: 6| Step: 6
Training loss: 2.4773118482909777
Validation loss: 2.544663028429945

Epoch: 6| Step: 7
Training loss: 2.619505627123138
Validation loss: 2.547081422144117

Epoch: 6| Step: 8
Training loss: 2.7684205145508045
Validation loss: 2.542706688475764

Epoch: 6| Step: 9
Training loss: 2.7000492656592963
Validation loss: 2.548257090008256

Epoch: 6| Step: 10
Training loss: 2.949512350865844
Validation loss: 2.542082804607025

Epoch: 6| Step: 11
Training loss: 2.8611404721956144
Validation loss: 2.543725529583476

Epoch: 6| Step: 12
Training loss: 2.2497637942624924
Validation loss: 2.5404551437923586

Epoch: 6| Step: 13
Training loss: 2.464593696303735
Validation loss: 2.543339809177832

Epoch: 72| Step: 0
Training loss: 2.350446772209849
Validation loss: 2.541546526920086

Epoch: 6| Step: 1
Training loss: 2.2631780630494718
Validation loss: 2.54025689618141

Epoch: 6| Step: 2
Training loss: 2.247520033733286
Validation loss: 2.539716102398668

Epoch: 6| Step: 3
Training loss: 2.882398953019036
Validation loss: 2.539093752937664

Epoch: 6| Step: 4
Training loss: 2.744890668460097
Validation loss: 2.540931991541777

Epoch: 6| Step: 5
Training loss: 3.0304289030173064
Validation loss: 2.5395300801435887

Epoch: 6| Step: 6
Training loss: 2.9225459832847904
Validation loss: 2.536762749318059

Epoch: 6| Step: 7
Training loss: 2.841819694925559
Validation loss: 2.5371432205460343

Epoch: 6| Step: 8
Training loss: 2.6418658168426457
Validation loss: 2.5349634975987967

Epoch: 6| Step: 9
Training loss: 2.9533668701586966
Validation loss: 2.5390213087604283

Epoch: 6| Step: 10
Training loss: 2.949233463073813
Validation loss: 2.5377117770162534

Epoch: 6| Step: 11
Training loss: 2.449575200524553
Validation loss: 2.5360950050478595

Epoch: 6| Step: 12
Training loss: 2.4059779025717534
Validation loss: 2.5368254837751096

Epoch: 6| Step: 13
Training loss: 2.3394328729399754
Validation loss: 2.540141200273493

Epoch: 73| Step: 0
Training loss: 2.838405071553341
Validation loss: 2.5457641581758783

Epoch: 6| Step: 1
Training loss: 2.652751099173279
Validation loss: 2.5444067870212623

Epoch: 6| Step: 2
Training loss: 2.5450738259870027
Validation loss: 2.559129638461965

Epoch: 6| Step: 3
Training loss: 2.596832098761434
Validation loss: 2.5624920914690748

Epoch: 6| Step: 4
Training loss: 2.696966222323114
Validation loss: 2.540525028878518

Epoch: 6| Step: 5
Training loss: 2.89971517282234
Validation loss: 2.5392493233050892

Epoch: 6| Step: 6
Training loss: 3.16538751432502
Validation loss: 2.531801705223526

Epoch: 6| Step: 7
Training loss: 2.453744214867774
Validation loss: 2.5320294282979825

Epoch: 6| Step: 8
Training loss: 2.700706149406917
Validation loss: 2.53639066528879

Epoch: 6| Step: 9
Training loss: 2.2676054618561072
Validation loss: 2.536474197828954

Epoch: 6| Step: 10
Training loss: 2.2977957404635814
Validation loss: 2.5388219709664446

Epoch: 6| Step: 11
Training loss: 2.8514635042747676
Validation loss: 2.53952123948361

Epoch: 6| Step: 12
Training loss: 2.900251206665998
Validation loss: 2.5422356442904483

Epoch: 6| Step: 13
Training loss: 2.3802462407160463
Validation loss: 2.5496569614675364

Epoch: 74| Step: 0
Training loss: 2.773908032543663
Validation loss: 2.546539986698495

Epoch: 6| Step: 1
Training loss: 2.6170494840299776
Validation loss: 2.5507714902760226

Epoch: 6| Step: 2
Training loss: 2.8983927515076675
Validation loss: 2.5459689067281417

Epoch: 6| Step: 3
Training loss: 2.7152325907462487
Validation loss: 2.550695444156423

Epoch: 6| Step: 4
Training loss: 2.5712210026479654
Validation loss: 2.5475203119777814

Epoch: 6| Step: 5
Training loss: 2.842892360263733
Validation loss: 2.5446198040930614

Epoch: 6| Step: 6
Training loss: 2.739274436641846
Validation loss: 2.544094151141189

Epoch: 6| Step: 7
Training loss: 2.354149798667589
Validation loss: 2.5391269616967476

Epoch: 6| Step: 8
Training loss: 2.2045201422570826
Validation loss: 2.5351412027673628

Epoch: 6| Step: 9
Training loss: 2.5580798848841155
Validation loss: 2.5336447796195136

Epoch: 6| Step: 10
Training loss: 2.7666099216969107
Validation loss: 2.531133138839676

Epoch: 6| Step: 11
Training loss: 2.8280896769472696
Validation loss: 2.5305660878015903

Epoch: 6| Step: 12
Training loss: 2.8854389580004427
Validation loss: 2.5266841005950123

Epoch: 6| Step: 13
Training loss: 2.5568832620372084
Validation loss: 2.5261522301666606

Epoch: 75| Step: 0
Training loss: 2.81571336071986
Validation loss: 2.5232870019651137

Epoch: 6| Step: 1
Training loss: 2.663127656839975
Validation loss: 2.5203194107493823

Epoch: 6| Step: 2
Training loss: 2.0720673806932672
Validation loss: 2.5237099625420663

Epoch: 6| Step: 3
Training loss: 2.1573084569179706
Validation loss: 2.520229177877291

Epoch: 6| Step: 4
Training loss: 2.794866426718938
Validation loss: 2.521170196934553

Epoch: 6| Step: 5
Training loss: 2.2440036768415657
Validation loss: 2.516678749354412

Epoch: 6| Step: 6
Training loss: 2.697008478391091
Validation loss: 2.51819698677423

Epoch: 6| Step: 7
Training loss: 2.9421103801131476
Validation loss: 2.514091150449715

Epoch: 6| Step: 8
Training loss: 3.296418795728336
Validation loss: 2.519127186945263

Epoch: 6| Step: 9
Training loss: 2.875567836247195
Validation loss: 2.5171388924102875

Epoch: 6| Step: 10
Training loss: 2.69492423536709
Validation loss: 2.520667351757011

Epoch: 6| Step: 11
Training loss: 2.621768051712428
Validation loss: 2.520039935350613

Epoch: 6| Step: 12
Training loss: 2.272320659850379
Validation loss: 2.5196712326867696

Epoch: 6| Step: 13
Training loss: 2.7271957755069796
Validation loss: 2.517113855138262

Epoch: 76| Step: 0
Training loss: 2.6073446998176117
Validation loss: 2.515493306569047

Epoch: 6| Step: 1
Training loss: 2.289772834838066
Validation loss: 2.517850148430578

Epoch: 6| Step: 2
Training loss: 2.342495391743462
Validation loss: 2.514645087477542

Epoch: 6| Step: 3
Training loss: 2.2828948479329374
Validation loss: 2.513848603583252

Epoch: 6| Step: 4
Training loss: 2.667884568412497
Validation loss: 2.51814369811407

Epoch: 6| Step: 5
Training loss: 2.5421156148002457
Validation loss: 2.5225845485817615

Epoch: 6| Step: 6
Training loss: 2.64428619646788
Validation loss: 2.5201742293159

Epoch: 6| Step: 7
Training loss: 2.679477872517615
Validation loss: 2.527565067433491

Epoch: 6| Step: 8
Training loss: 2.434791331505107
Validation loss: 2.523351677693952

Epoch: 6| Step: 9
Training loss: 2.7431343378484763
Validation loss: 2.522943280996053

Epoch: 6| Step: 10
Training loss: 2.820530595034277
Validation loss: 2.514521457466026

Epoch: 6| Step: 11
Training loss: 2.438942995632248
Validation loss: 2.517419226549267

Epoch: 6| Step: 12
Training loss: 3.057675512458728
Validation loss: 2.517153021151857

Epoch: 6| Step: 13
Training loss: 3.229282811855114
Validation loss: 2.5196038445159914

Epoch: 77| Step: 0
Training loss: 2.7762273806252082
Validation loss: 2.514476980147848

Epoch: 6| Step: 1
Training loss: 3.0242846186881924
Validation loss: 2.5121268202442324

Epoch: 6| Step: 2
Training loss: 2.743846771688672
Validation loss: 2.508568813089546

Epoch: 6| Step: 3
Training loss: 2.3626231893079694
Validation loss: 2.5146007782700486

Epoch: 6| Step: 4
Training loss: 2.7254758926750267
Validation loss: 2.511223743757806

Epoch: 6| Step: 5
Training loss: 2.713514878231694
Validation loss: 2.512718164009195

Epoch: 6| Step: 6
Training loss: 2.6122188946192395
Validation loss: 2.5160683977617486

Epoch: 6| Step: 7
Training loss: 3.3001199816075433
Validation loss: 2.5100275637720366

Epoch: 6| Step: 8
Training loss: 2.4799073552700825
Validation loss: 2.5091542490087377

Epoch: 6| Step: 9
Training loss: 2.4558435428934864
Validation loss: 2.5076813311949446

Epoch: 6| Step: 10
Training loss: 2.040231888251165
Validation loss: 2.508655030246455

Epoch: 6| Step: 11
Training loss: 2.572238189157025
Validation loss: 2.5102724426966274

Epoch: 6| Step: 12
Training loss: 2.9591474532206643
Validation loss: 2.50824469212228

Epoch: 6| Step: 13
Training loss: 1.7159174379792232
Validation loss: 2.50705293142981

Epoch: 78| Step: 0
Training loss: 2.2680553160890056
Validation loss: 2.507384314183664

Epoch: 6| Step: 1
Training loss: 2.588017482887188
Validation loss: 2.5088390336950646

Epoch: 6| Step: 2
Training loss: 2.569070997392313
Validation loss: 2.517696215077346

Epoch: 6| Step: 3
Training loss: 2.545187923785356
Validation loss: 2.530733628840548

Epoch: 6| Step: 4
Training loss: 2.7403957675598805
Validation loss: 2.5348016601609635

Epoch: 6| Step: 5
Training loss: 2.809763785374502
Validation loss: 2.5242426073101405

Epoch: 6| Step: 6
Training loss: 2.646861459816773
Validation loss: 2.5264712935109745

Epoch: 6| Step: 7
Training loss: 2.563010560322415
Validation loss: 2.529402227183711

Epoch: 6| Step: 8
Training loss: 2.3849929588741756
Validation loss: 2.5251353155205862

Epoch: 6| Step: 9
Training loss: 2.723999917835565
Validation loss: 2.5144868254347714

Epoch: 6| Step: 10
Training loss: 2.3809357803765097
Validation loss: 2.5159252453550853

Epoch: 6| Step: 11
Training loss: 3.307371379862857
Validation loss: 2.513621968265702

Epoch: 6| Step: 12
Training loss: 2.890159940682704
Validation loss: 2.505923279531914

Epoch: 6| Step: 13
Training loss: 2.469741429065081
Validation loss: 2.5010083549173876

Epoch: 79| Step: 0
Training loss: 2.2904225758289014
Validation loss: 2.5096717351824354

Epoch: 6| Step: 1
Training loss: 2.5593157266499924
Validation loss: 2.505352481388041

Epoch: 6| Step: 2
Training loss: 2.194843717325096
Validation loss: 2.505611543201378

Epoch: 6| Step: 3
Training loss: 2.913346680785912
Validation loss: 2.5136266633665536

Epoch: 6| Step: 4
Training loss: 2.457236762010864
Validation loss: 2.5060629758236215

Epoch: 6| Step: 5
Training loss: 2.518200521427828
Validation loss: 2.506282620998553

Epoch: 6| Step: 6
Training loss: 3.0667494272038875
Validation loss: 2.5060095084239076

Epoch: 6| Step: 7
Training loss: 2.8323439011147866
Validation loss: 2.5139913210247373

Epoch: 6| Step: 8
Training loss: 2.744835772995414
Validation loss: 2.5176972409625975

Epoch: 6| Step: 9
Training loss: 2.385752580692671
Validation loss: 2.5121643082545155

Epoch: 6| Step: 10
Training loss: 2.522577853858643
Validation loss: 2.509208132404272

Epoch: 6| Step: 11
Training loss: 2.99694939323112
Validation loss: 2.509351406722836

Epoch: 6| Step: 12
Training loss: 2.722604671739524
Validation loss: 2.5081542228886704

Epoch: 6| Step: 13
Training loss: 2.4905143071828006
Validation loss: 2.500182351773435

Epoch: 80| Step: 0
Training loss: 2.0725418467605152
Validation loss: 2.4991741882784275

Epoch: 6| Step: 1
Training loss: 2.6558927407955224
Validation loss: 2.4998755582991334

Epoch: 6| Step: 2
Training loss: 2.6767745575908193
Validation loss: 2.5038331527474593

Epoch: 6| Step: 3
Training loss: 2.658934369996325
Validation loss: 2.5043150696494894

Epoch: 6| Step: 4
Training loss: 2.9395416956132845
Validation loss: 2.5061217616910167

Epoch: 6| Step: 5
Training loss: 2.713591142570687
Validation loss: 2.501177415152042

Epoch: 6| Step: 6
Training loss: 2.517940237728347
Validation loss: 2.4997652261486927

Epoch: 6| Step: 7
Training loss: 2.1656054563314795
Validation loss: 2.5067864415496364

Epoch: 6| Step: 8
Training loss: 2.942015079545223
Validation loss: 2.5051542000000913

Epoch: 6| Step: 9
Training loss: 2.5209057274713973
Validation loss: 2.497673032543352

Epoch: 6| Step: 10
Training loss: 2.5276163652839547
Validation loss: 2.4987580393359248

Epoch: 6| Step: 11
Training loss: 2.8156670434926765
Validation loss: 2.4936559609996363

Epoch: 6| Step: 12
Training loss: 2.767604658151746
Validation loss: 2.5003415828043742

Epoch: 6| Step: 13
Training loss: 2.539350006258426
Validation loss: 2.4965169007676438

Epoch: 81| Step: 0
Training loss: 2.5195977727107115
Validation loss: 2.4998371230155474

Epoch: 6| Step: 1
Training loss: 3.2999564139059774
Validation loss: 2.5030944269911113

Epoch: 6| Step: 2
Training loss: 2.805795604730484
Validation loss: 2.50443172247479

Epoch: 6| Step: 3
Training loss: 2.587058386227493
Validation loss: 2.498814365257046

Epoch: 6| Step: 4
Training loss: 2.36065033050432
Validation loss: 2.5018503970542927

Epoch: 6| Step: 5
Training loss: 2.402182671333781
Validation loss: 2.4986370185930555

Epoch: 6| Step: 6
Training loss: 2.562969071789915
Validation loss: 2.5046291250120127

Epoch: 6| Step: 7
Training loss: 2.160886561744288
Validation loss: 2.500041079183679

Epoch: 6| Step: 8
Training loss: 2.2956460792161555
Validation loss: 2.4988635818138905

Epoch: 6| Step: 9
Training loss: 2.6130117325867923
Validation loss: 2.501394852296888

Epoch: 6| Step: 10
Training loss: 2.5724815793578104
Validation loss: 2.5022198040854358

Epoch: 6| Step: 11
Training loss: 2.746711585486178
Validation loss: 2.501946279777952

Epoch: 6| Step: 12
Training loss: 2.532347076408182
Validation loss: 2.505697227776124

Epoch: 6| Step: 13
Training loss: 2.965272814597374
Validation loss: 2.5131622643606657

Epoch: 82| Step: 0
Training loss: 2.875174143948889
Validation loss: 2.5192289343543695

Epoch: 6| Step: 1
Training loss: 2.5323329539812365
Validation loss: 2.521208275478257

Epoch: 6| Step: 2
Training loss: 2.700425404131958
Validation loss: 2.5203324653164207

Epoch: 6| Step: 3
Training loss: 3.010894860607607
Validation loss: 2.52797345625547

Epoch: 6| Step: 4
Training loss: 2.4438558999455116
Validation loss: 2.5257061345480127

Epoch: 6| Step: 5
Training loss: 2.3660393375986395
Validation loss: 2.522702152279173

Epoch: 6| Step: 6
Training loss: 2.619804144665912
Validation loss: 2.5199595321453696

Epoch: 6| Step: 7
Training loss: 2.5678233236340318
Validation loss: 2.5190500199037533

Epoch: 6| Step: 8
Training loss: 2.2436276373265653
Validation loss: 2.519747954913687

Epoch: 6| Step: 9
Training loss: 2.871668834571072
Validation loss: 2.5104450894299295

Epoch: 6| Step: 10
Training loss: 2.0390519766700437
Validation loss: 2.508469698505913

Epoch: 6| Step: 11
Training loss: 2.4944422934489143
Validation loss: 2.5048272893253456

Epoch: 6| Step: 12
Training loss: 2.74970131032263
Validation loss: 2.5007677329930647

Epoch: 6| Step: 13
Training loss: 3.200580758800427
Validation loss: 2.5015757998594044

Epoch: 83| Step: 0
Training loss: 2.2938573827735853
Validation loss: 2.500691103777787

Epoch: 6| Step: 1
Training loss: 2.266352674764264
Validation loss: 2.4996368303364433

Epoch: 6| Step: 2
Training loss: 2.559779420975861
Validation loss: 2.49587962426598

Epoch: 6| Step: 3
Training loss: 2.7096519390276437
Validation loss: 2.493108565234179

Epoch: 6| Step: 4
Training loss: 2.474463502939652
Validation loss: 2.4906738691270065

Epoch: 6| Step: 5
Training loss: 2.5516105577249553
Validation loss: 2.49309928900549

Epoch: 6| Step: 6
Training loss: 2.8773129323012787
Validation loss: 2.4932514498604514

Epoch: 6| Step: 7
Training loss: 2.9915753328483863
Validation loss: 2.4939380425071307

Epoch: 6| Step: 8
Training loss: 3.279365797835115
Validation loss: 2.48884548175895

Epoch: 6| Step: 9
Training loss: 2.6103763143876524
Validation loss: 2.491159847049163

Epoch: 6| Step: 10
Training loss: 2.6060841532753
Validation loss: 2.493086569996646

Epoch: 6| Step: 11
Training loss: 2.4927034710906946
Validation loss: 2.488392945661665

Epoch: 6| Step: 12
Training loss: 2.493659753528863
Validation loss: 2.4882725466461717

Epoch: 6| Step: 13
Training loss: 2.216341457556108
Validation loss: 2.487488960356632

Epoch: 84| Step: 0
Training loss: 2.5728749775050916
Validation loss: 2.4923537626382832

Epoch: 6| Step: 1
Training loss: 3.0213038286394123
Validation loss: 2.485132305913735

Epoch: 6| Step: 2
Training loss: 2.5103296499617436
Validation loss: 2.4940883518477674

Epoch: 6| Step: 3
Training loss: 2.5562418370944315
Validation loss: 2.4866411282282193

Epoch: 6| Step: 4
Training loss: 2.8466749973160335
Validation loss: 2.4919527076766848

Epoch: 6| Step: 5
Training loss: 2.490784731616554
Validation loss: 2.490354591409951

Epoch: 6| Step: 6
Training loss: 2.8867200714645147
Validation loss: 2.492966214358719

Epoch: 6| Step: 7
Training loss: 2.0051522647565694
Validation loss: 2.4962551520454728

Epoch: 6| Step: 8
Training loss: 2.1464697131835466
Validation loss: 2.4911404027340636

Epoch: 6| Step: 9
Training loss: 2.9400211634490523
Validation loss: 2.4929070305982077

Epoch: 6| Step: 10
Training loss: 3.03219259491844
Validation loss: 2.4863664654584685

Epoch: 6| Step: 11
Training loss: 2.309832710054453
Validation loss: 2.4946784682000662

Epoch: 6| Step: 12
Training loss: 2.430341822597041
Validation loss: 2.4861718483531794

Epoch: 6| Step: 13
Training loss: 2.5087205425332977
Validation loss: 2.4901860570271586

Epoch: 85| Step: 0
Training loss: 2.680819614253951
Validation loss: 2.490804944464217

Epoch: 6| Step: 1
Training loss: 2.420480535891104
Validation loss: 2.4875247270387058

Epoch: 6| Step: 2
Training loss: 2.6048149420963402
Validation loss: 2.488067889285974

Epoch: 6| Step: 3
Training loss: 2.786971219119852
Validation loss: 2.483394533295037

Epoch: 6| Step: 4
Training loss: 2.5864744061203515
Validation loss: 2.489926826584079

Epoch: 6| Step: 5
Training loss: 2.497174573742414
Validation loss: 2.486515075095824

Epoch: 6| Step: 6
Training loss: 2.7479879648147745
Validation loss: 2.4919277203253727

Epoch: 6| Step: 7
Training loss: 2.15780937089631
Validation loss: 2.4891901596930825

Epoch: 6| Step: 8
Training loss: 2.0946309528005584
Validation loss: 2.4908589615773784

Epoch: 6| Step: 9
Training loss: 2.6078110079478205
Validation loss: 2.4920832533443837

Epoch: 6| Step: 10
Training loss: 2.6035000570966473
Validation loss: 2.4913563393679072

Epoch: 6| Step: 11
Training loss: 3.020078384948462
Validation loss: 2.4953725267363085

Epoch: 6| Step: 12
Training loss: 2.5491727047969572
Validation loss: 2.4934833470093087

Epoch: 6| Step: 13
Training loss: 2.89642148711652
Validation loss: 2.4920411819348427

Epoch: 86| Step: 0
Training loss: 2.9702239543593834
Validation loss: 2.4935627235196858

Epoch: 6| Step: 1
Training loss: 2.537922482953327
Validation loss: 2.490575669780108

Epoch: 6| Step: 2
Training loss: 2.516661436399705
Validation loss: 2.493658526534744

Epoch: 6| Step: 3
Training loss: 2.9878318698056896
Validation loss: 2.489815814178026

Epoch: 6| Step: 4
Training loss: 2.133416282511424
Validation loss: 2.492783573820157

Epoch: 6| Step: 5
Training loss: 2.361396277416775
Validation loss: 2.494036061667348

Epoch: 6| Step: 6
Training loss: 2.9277770463659865
Validation loss: 2.4952856754715564

Epoch: 6| Step: 7
Training loss: 2.2888426170589544
Validation loss: 2.491464476105856

Epoch: 6| Step: 8
Training loss: 2.430965369658524
Validation loss: 2.49125713014962

Epoch: 6| Step: 9
Training loss: 2.346557461607062
Validation loss: 2.4863885361253746

Epoch: 6| Step: 10
Training loss: 2.394316771020032
Validation loss: 2.4859091062780445

Epoch: 6| Step: 11
Training loss: 2.9086051340262045
Validation loss: 2.4834446474597045

Epoch: 6| Step: 12
Training loss: 2.556845030980793
Validation loss: 2.4845671989262077

Epoch: 6| Step: 13
Training loss: 2.665359405129898
Validation loss: 2.4879387780044238

Epoch: 87| Step: 0
Training loss: 2.6842601676066913
Validation loss: 2.479566851675284

Epoch: 6| Step: 1
Training loss: 2.8006939096279777
Validation loss: 2.4787390898520374

Epoch: 6| Step: 2
Training loss: 2.681789096797992
Validation loss: 2.4778353110886457

Epoch: 6| Step: 3
Training loss: 3.3367205734801706
Validation loss: 2.4853625783819804

Epoch: 6| Step: 4
Training loss: 2.9653426040920725
Validation loss: 2.4900867373514703

Epoch: 6| Step: 5
Training loss: 1.9226359279880776
Validation loss: 2.483570168443124

Epoch: 6| Step: 6
Training loss: 2.594286392084589
Validation loss: 2.492983604202798

Epoch: 6| Step: 7
Training loss: 2.678794956871368
Validation loss: 2.4885607551959286

Epoch: 6| Step: 8
Training loss: 2.3749972895556595
Validation loss: 2.486779063431459

Epoch: 6| Step: 9
Training loss: 2.2560977958422583
Validation loss: 2.494246665554463

Epoch: 6| Step: 10
Training loss: 2.2112558088555168
Validation loss: 2.493200289658174

Epoch: 6| Step: 11
Training loss: 2.467727159519826
Validation loss: 2.489165384066438

Epoch: 6| Step: 12
Training loss: 2.5723029780590383
Validation loss: 2.49241836419264

Epoch: 6| Step: 13
Training loss: 2.4679620185414888
Validation loss: 2.485214475437104

Epoch: 88| Step: 0
Training loss: 2.7280496733273756
Validation loss: 2.484226246345084

Epoch: 6| Step: 1
Training loss: 2.697142933148159
Validation loss: 2.489102246609107

Epoch: 6| Step: 2
Training loss: 2.3099502734822437
Validation loss: 2.4895950673570324

Epoch: 6| Step: 3
Training loss: 2.7795937567906046
Validation loss: 2.4950437212714554

Epoch: 6| Step: 4
Training loss: 2.754946335063903
Validation loss: 2.486563032929339

Epoch: 6| Step: 5
Training loss: 2.6051577907226635
Validation loss: 2.4883913567743314

Epoch: 6| Step: 6
Training loss: 3.261421235729552
Validation loss: 2.4948572987714783

Epoch: 6| Step: 7
Training loss: 2.372156750174807
Validation loss: 2.4842343400526437

Epoch: 6| Step: 8
Training loss: 2.5066753911143853
Validation loss: 2.4836807880507865

Epoch: 6| Step: 9
Training loss: 2.0676485016155213
Validation loss: 2.4869519030822502

Epoch: 6| Step: 10
Training loss: 2.7685768193835405
Validation loss: 2.483949284896318

Epoch: 6| Step: 11
Training loss: 2.3774778590891197
Validation loss: 2.477928795569677

Epoch: 6| Step: 12
Training loss: 2.522535038715104
Validation loss: 2.487086945173935

Epoch: 6| Step: 13
Training loss: 2.286547845175956
Validation loss: 2.4865137966337563

Epoch: 89| Step: 0
Training loss: 2.7137067650610818
Validation loss: 2.4847431030116307

Epoch: 6| Step: 1
Training loss: 2.3988684847911563
Validation loss: 2.487549630824933

Epoch: 6| Step: 2
Training loss: 2.8890655435037544
Validation loss: 2.48221505436801

Epoch: 6| Step: 3
Training loss: 3.0320380061643677
Validation loss: 2.4844847760848836

Epoch: 6| Step: 4
Training loss: 1.7522886161277245
Validation loss: 2.482611968302803

Epoch: 6| Step: 5
Training loss: 2.8109285838996656
Validation loss: 2.486577670990842

Epoch: 6| Step: 6
Training loss: 2.0138899558345846
Validation loss: 2.4807542771734354

Epoch: 6| Step: 7
Training loss: 2.646876232232502
Validation loss: 2.4877777867825723

Epoch: 6| Step: 8
Training loss: 2.5274788350201094
Validation loss: 2.477254776814054

Epoch: 6| Step: 9
Training loss: 2.88969876682894
Validation loss: 2.481446017090448

Epoch: 6| Step: 10
Training loss: 2.561603389281938
Validation loss: 2.478340753990134

Epoch: 6| Step: 11
Training loss: 2.5149309610708275
Validation loss: 2.4762489128335066

Epoch: 6| Step: 12
Training loss: 2.0869380537197255
Validation loss: 2.4680903877438873

Epoch: 6| Step: 13
Training loss: 3.070594832856246
Validation loss: 2.483894909549679

Epoch: 90| Step: 0
Training loss: 3.092182417330967
Validation loss: 2.481326746294208

Epoch: 6| Step: 1
Training loss: 2.761583726919416
Validation loss: 2.4751185591073357

Epoch: 6| Step: 2
Training loss: 2.7781225043544135
Validation loss: 2.4762848258165158

Epoch: 6| Step: 3
Training loss: 2.1759929451267097
Validation loss: 2.4759400204176205

Epoch: 6| Step: 4
Training loss: 2.867905529450803
Validation loss: 2.4747097333245

Epoch: 6| Step: 5
Training loss: 2.725236280504209
Validation loss: 2.474707678026837

Epoch: 6| Step: 6
Training loss: 1.8032603379998666
Validation loss: 2.4833038228050213

Epoch: 6| Step: 7
Training loss: 2.7603089701438748
Validation loss: 2.482047376139038

Epoch: 6| Step: 8
Training loss: 2.969900450402797
Validation loss: 2.4853354622769683

Epoch: 6| Step: 9
Training loss: 2.607198938561616
Validation loss: 2.484171629125157

Epoch: 6| Step: 10
Training loss: 2.711462052575129
Validation loss: 2.4885516775788665

Epoch: 6| Step: 11
Training loss: 2.126984511074672
Validation loss: 2.491800323992647

Epoch: 6| Step: 12
Training loss: 2.4805154630813027
Validation loss: 2.491785333884471

Epoch: 6| Step: 13
Training loss: 2.24826873294369
Validation loss: 2.492894294668563

Epoch: 91| Step: 0
Training loss: 3.031022840030591
Validation loss: 2.4905344903152313

Epoch: 6| Step: 1
Training loss: 2.737912053837884
Validation loss: 2.48467439970685

Epoch: 6| Step: 2
Training loss: 2.408948301933173
Validation loss: 2.4789084826328223

Epoch: 6| Step: 3
Training loss: 2.580769240565083
Validation loss: 2.4845063436724932

Epoch: 6| Step: 4
Training loss: 1.863398582235061
Validation loss: 2.479417328758084

Epoch: 6| Step: 5
Training loss: 2.776006835566303
Validation loss: 2.487027957031565

Epoch: 6| Step: 6
Training loss: 2.823732706247492
Validation loss: 2.4776385002545314

Epoch: 6| Step: 7
Training loss: 2.3947429221160466
Validation loss: 2.49389809763852

Epoch: 6| Step: 8
Training loss: 2.4325655361650664
Validation loss: 2.4916583130185064

Epoch: 6| Step: 9
Training loss: 2.507848436329845
Validation loss: 2.4823937343199933

Epoch: 6| Step: 10
Training loss: 2.7907744637817893
Validation loss: 2.475272146348019

Epoch: 6| Step: 11
Training loss: 2.4733466319046253
Validation loss: 2.486121789162245

Epoch: 6| Step: 12
Training loss: 2.418397338549493
Validation loss: 2.478114623488597

Epoch: 6| Step: 13
Training loss: 2.9452415882751732
Validation loss: 2.4833743961404093

Epoch: 92| Step: 0
Training loss: 2.8062766840628255
Validation loss: 2.481806116697244

Epoch: 6| Step: 1
Training loss: 2.6805109921859556
Validation loss: 2.4904953364847007

Epoch: 6| Step: 2
Training loss: 2.898759273960006
Validation loss: 2.487061038175905

Epoch: 6| Step: 3
Training loss: 2.723587818122879
Validation loss: 2.4884678777136915

Epoch: 6| Step: 4
Training loss: 2.1530741648216423
Validation loss: 2.488286511921172

Epoch: 6| Step: 5
Training loss: 2.5627057062715544
Validation loss: 2.485146952402534

Epoch: 6| Step: 6
Training loss: 2.325343166170125
Validation loss: 2.47828184628017

Epoch: 6| Step: 7
Training loss: 3.238961179467072
Validation loss: 2.476927817563853

Epoch: 6| Step: 8
Training loss: 2.7536620985522045
Validation loss: 2.4785760822542993

Epoch: 6| Step: 9
Training loss: 2.3960429113745425
Validation loss: 2.4764255762606706

Epoch: 6| Step: 10
Training loss: 2.53046923240193
Validation loss: 2.479465423876251

Epoch: 6| Step: 11
Training loss: 2.064547476150771
Validation loss: 2.474325186316417

Epoch: 6| Step: 12
Training loss: 2.5392230643342026
Validation loss: 2.4828634402101

Epoch: 6| Step: 13
Training loss: 2.225492735748674
Validation loss: 2.481092311547129

Epoch: 93| Step: 0
Training loss: 2.396577094910695
Validation loss: 2.477862525306979

Epoch: 6| Step: 1
Training loss: 2.6006771562989446
Validation loss: 2.4783171606102674

Epoch: 6| Step: 2
Training loss: 2.0627286379693586
Validation loss: 2.4761649373243113

Epoch: 6| Step: 3
Training loss: 2.860946806929496
Validation loss: 2.475390986504292

Epoch: 6| Step: 4
Training loss: 2.6780527539117625
Validation loss: 2.4809318610775657

Epoch: 6| Step: 5
Training loss: 2.1944531696752394
Validation loss: 2.482319331258425

Epoch: 6| Step: 6
Training loss: 2.4551569790190557
Validation loss: 2.481127874153857

Epoch: 6| Step: 7
Training loss: 2.674496351940258
Validation loss: 2.4819262210091777

Epoch: 6| Step: 8
Training loss: 2.6911830062075657
Validation loss: 2.475549035233054

Epoch: 6| Step: 9
Training loss: 1.5316079947379773
Validation loss: 2.4833805965133244

Epoch: 6| Step: 10
Training loss: 2.835182783097806
Validation loss: 2.480148374838631

Epoch: 6| Step: 11
Training loss: 3.0954583585708266
Validation loss: 2.4765871931222874

Epoch: 6| Step: 12
Training loss: 2.8962673895671505
Validation loss: 2.4751248845147784

Epoch: 6| Step: 13
Training loss: 2.6126642567956933
Validation loss: 2.4722532854974206

Epoch: 94| Step: 0
Training loss: 2.7174212837224077
Validation loss: 2.471531295190304

Epoch: 6| Step: 1
Training loss: 2.6439927875691667
Validation loss: 2.4658719440757824

Epoch: 6| Step: 2
Training loss: 2.2729008096852192
Validation loss: 2.4737683407291704

Epoch: 6| Step: 3
Training loss: 2.250902101025742
Validation loss: 2.4719087697265105

Epoch: 6| Step: 4
Training loss: 2.584945534551059
Validation loss: 2.470195508032811

Epoch: 6| Step: 5
Training loss: 2.436215869396344
Validation loss: 2.4663368212908994

Epoch: 6| Step: 6
Training loss: 1.918265014887969
Validation loss: 2.4698409072513066

Epoch: 6| Step: 7
Training loss: 2.615051491049896
Validation loss: 2.4670101747090385

Epoch: 6| Step: 8
Training loss: 2.4624311485928003
Validation loss: 2.466563258280312

Epoch: 6| Step: 9
Training loss: 2.9327272641574798
Validation loss: 2.4650076334579123

Epoch: 6| Step: 10
Training loss: 2.505930542028196
Validation loss: 2.4630706584169055

Epoch: 6| Step: 11
Training loss: 2.6659610728736527
Validation loss: 2.462049800041692

Epoch: 6| Step: 12
Training loss: 2.831818250341344
Validation loss: 2.4742979733409247

Epoch: 6| Step: 13
Training loss: 2.8853606254194126
Validation loss: 2.4623089798552282

Epoch: 95| Step: 0
Training loss: 1.782025887674829
Validation loss: 2.4660211603432978

Epoch: 6| Step: 1
Training loss: 2.3612908675139197
Validation loss: 2.4725086073666143

Epoch: 6| Step: 2
Training loss: 3.0061717128275283
Validation loss: 2.4810929922142804

Epoch: 6| Step: 3
Training loss: 2.6554785112974275
Validation loss: 2.476226535155108

Epoch: 6| Step: 4
Training loss: 2.696555561406431
Validation loss: 2.4734878146142147

Epoch: 6| Step: 5
Training loss: 2.783791570194619
Validation loss: 2.4734155534648985

Epoch: 6| Step: 6
Training loss: 2.568311381888808
Validation loss: 2.46989549547039

Epoch: 6| Step: 7
Training loss: 2.862872543413189
Validation loss: 2.475837978597071

Epoch: 6| Step: 8
Training loss: 2.236047292342295
Validation loss: 2.473246057603697

Epoch: 6| Step: 9
Training loss: 2.7465983072434415
Validation loss: 2.477593914142016

Epoch: 6| Step: 10
Training loss: 2.7048538941360674
Validation loss: 2.471898513727119

Epoch: 6| Step: 11
Training loss: 2.249424542906687
Validation loss: 2.47031767279807

Epoch: 6| Step: 12
Training loss: 2.7280958176283203
Validation loss: 2.4704369040942944

Epoch: 6| Step: 13
Training loss: 2.2122420381499097
Validation loss: 2.470538187866874

Epoch: 96| Step: 0
Training loss: 2.1660574521153078
Validation loss: 2.4637319855569295

Epoch: 6| Step: 1
Training loss: 2.6538133103540194
Validation loss: 2.47674118664925

Epoch: 6| Step: 2
Training loss: 2.1533947159764764
Validation loss: 2.4709191751819772

Epoch: 6| Step: 3
Training loss: 1.5988380892228977
Validation loss: 2.4665629199694736

Epoch: 6| Step: 4
Training loss: 2.7403863713803243
Validation loss: 2.463214285283398

Epoch: 6| Step: 5
Training loss: 2.595345799038994
Validation loss: 2.4686024778689752

Epoch: 6| Step: 6
Training loss: 3.033046858398211
Validation loss: 2.465314800957523

Epoch: 6| Step: 7
Training loss: 2.600137222777003
Validation loss: 2.462475412184702

Epoch: 6| Step: 8
Training loss: 2.406446374583809
Validation loss: 2.4735903871203475

Epoch: 6| Step: 9
Training loss: 2.7327369361057765
Validation loss: 2.4664562933582275

Epoch: 6| Step: 10
Training loss: 3.090030167812004
Validation loss: 2.4679348239577448

Epoch: 6| Step: 11
Training loss: 2.13261373522937
Validation loss: 2.4699921681978796

Epoch: 6| Step: 12
Training loss: 2.2577749070994497
Validation loss: 2.478401536171956

Epoch: 6| Step: 13
Training loss: 3.1836747796915814
Validation loss: 2.4722557928780153

Epoch: 97| Step: 0
Training loss: 2.5273783709411464
Validation loss: 2.482818307743758

Epoch: 6| Step: 1
Training loss: 2.6628279971972413
Validation loss: 2.477610313264093

Epoch: 6| Step: 2
Training loss: 2.125936077610332
Validation loss: 2.47157960807425

Epoch: 6| Step: 3
Training loss: 2.686224523878819
Validation loss: 2.4726937578921095

Epoch: 6| Step: 4
Training loss: 2.399330196692658
Validation loss: 2.474104551043307

Epoch: 6| Step: 5
Training loss: 2.0331799068829204
Validation loss: 2.471685925248121

Epoch: 6| Step: 6
Training loss: 2.503372968756978
Validation loss: 2.4629813290258875

Epoch: 6| Step: 7
Training loss: 2.55599466181811
Validation loss: 2.459140343399695

Epoch: 6| Step: 8
Training loss: 2.7328667540969125
Validation loss: 2.463686639715214

Epoch: 6| Step: 9
Training loss: 2.558570454032781
Validation loss: 2.4689484206670635

Epoch: 6| Step: 10
Training loss: 2.9379554557773395
Validation loss: 2.4678210510644205

Epoch: 6| Step: 11
Training loss: 2.3247425675154885
Validation loss: 2.4690113653583445

Epoch: 6| Step: 12
Training loss: 2.6861556483296387
Validation loss: 2.4651401863446014

Epoch: 6| Step: 13
Training loss: 2.9712690407508395
Validation loss: 2.465439439824936

Epoch: 98| Step: 0
Training loss: 2.0682152832098106
Validation loss: 2.4645467620569748

Epoch: 6| Step: 1
Training loss: 2.3357522438101417
Validation loss: 2.4613618837999987

Epoch: 6| Step: 2
Training loss: 2.4995219727306033
Validation loss: 2.461064443392171

Epoch: 6| Step: 3
Training loss: 2.642811158048973
Validation loss: 2.4590770329275298

Epoch: 6| Step: 4
Training loss: 1.9898754391432807
Validation loss: 2.4613343256965257

Epoch: 6| Step: 5
Training loss: 2.52331353700936
Validation loss: 2.457979764135469

Epoch: 6| Step: 6
Training loss: 2.4651724086922675
Validation loss: 2.4576618171832725

Epoch: 6| Step: 7
Training loss: 3.031670924584445
Validation loss: 2.4651154269158666

Epoch: 6| Step: 8
Training loss: 2.732205822073953
Validation loss: 2.4690840571571737

Epoch: 6| Step: 9
Training loss: 2.975183683222529
Validation loss: 2.471500924311599

Epoch: 6| Step: 10
Training loss: 3.297468231487742
Validation loss: 2.4637675648861013

Epoch: 6| Step: 11
Training loss: 2.2916149711557985
Validation loss: 2.4757651440365485

Epoch: 6| Step: 12
Training loss: 2.3544974530737472
Validation loss: 2.4719580558008407

Epoch: 6| Step: 13
Training loss: 2.124575853092092
Validation loss: 2.4731267448305383

Epoch: 99| Step: 0
Training loss: 2.654445708581343
Validation loss: 2.468341028968651

Epoch: 6| Step: 1
Training loss: 2.3280899762072975
Validation loss: 2.4724140580955236

Epoch: 6| Step: 2
Training loss: 2.7954043139267553
Validation loss: 2.4709553103602926

Epoch: 6| Step: 3
Training loss: 2.8605314323886732
Validation loss: 2.4696467416740178

Epoch: 6| Step: 4
Training loss: 2.7178432662606755
Validation loss: 2.4637699518761944

Epoch: 6| Step: 5
Training loss: 3.041225732345122
Validation loss: 2.460128489733728

Epoch: 6| Step: 6
Training loss: 2.2365279062646386
Validation loss: 2.453320197825235

Epoch: 6| Step: 7
Training loss: 2.8663031022234753
Validation loss: 2.459709660446378

Epoch: 6| Step: 8
Training loss: 2.553064980145762
Validation loss: 2.4652825482341716

Epoch: 6| Step: 9
Training loss: 1.8816194038548644
Validation loss: 2.461799769237075

Epoch: 6| Step: 10
Training loss: 2.384378887688303
Validation loss: 2.466851941337512

Epoch: 6| Step: 11
Training loss: 2.3188473992057395
Validation loss: 2.458392050952434

Epoch: 6| Step: 12
Training loss: 2.5283833978767807
Validation loss: 2.4634337183156987

Epoch: 6| Step: 13
Training loss: 2.371036836798939
Validation loss: 2.4674234488019753

Epoch: 100| Step: 0
Training loss: 2.6236609722152067
Validation loss: 2.4577040486499024

Epoch: 6| Step: 1
Training loss: 2.9004808816449037
Validation loss: 2.462090019526441

Epoch: 6| Step: 2
Training loss: 1.668757089321208
Validation loss: 2.4741476742752244

Epoch: 6| Step: 3
Training loss: 2.0136571933570018
Validation loss: 2.476040597631095

Epoch: 6| Step: 4
Training loss: 2.5317791044352163
Validation loss: 2.477422570905774

Epoch: 6| Step: 5
Training loss: 2.3646100304618707
Validation loss: 2.479757292033146

Epoch: 6| Step: 6
Training loss: 2.6660767935977296
Validation loss: 2.471554141433826

Epoch: 6| Step: 7
Training loss: 2.3195105814181556
Validation loss: 2.4656541140102166

Epoch: 6| Step: 8
Training loss: 2.5777979787860787
Validation loss: 2.471266417692426

Epoch: 6| Step: 9
Training loss: 2.958755856996903
Validation loss: 2.460322356670877

Epoch: 6| Step: 10
Training loss: 2.3184950161391464
Validation loss: 2.461862638451676

Epoch: 6| Step: 11
Training loss: 2.487497730349938
Validation loss: 2.465573419983065

Epoch: 6| Step: 12
Training loss: 2.7461887305209265
Validation loss: 2.462843577626075

Epoch: 6| Step: 13
Training loss: 3.3084954581584776
Validation loss: 2.475514909376144

Epoch: 101| Step: 0
Training loss: 2.6941338214785597
Validation loss: 2.46668441890652

Epoch: 6| Step: 1
Training loss: 2.257329235694322
Validation loss: 2.4683192557380567

Epoch: 6| Step: 2
Training loss: 2.7080457583608553
Validation loss: 2.4709248841571805

Epoch: 6| Step: 3
Training loss: 2.7412770381903875
Validation loss: 2.4649898850476544

Epoch: 6| Step: 4
Training loss: 2.52941074188671
Validation loss: 2.4703312891825275

Epoch: 6| Step: 5
Training loss: 2.763509253580093
Validation loss: 2.4665410263265444

Epoch: 6| Step: 6
Training loss: 2.2056149960229123
Validation loss: 2.461036655911015

Epoch: 6| Step: 7
Training loss: 2.9097265963242056
Validation loss: 2.454211421703112

Epoch: 6| Step: 8
Training loss: 2.7666679183160485
Validation loss: 2.4587364243464074

Epoch: 6| Step: 9
Training loss: 2.430837083285524
Validation loss: 2.465377451593546

Epoch: 6| Step: 10
Training loss: 2.739326223243342
Validation loss: 2.4536169251372195

Epoch: 6| Step: 11
Training loss: 2.4903433263543553
Validation loss: 2.4591824929212756

Epoch: 6| Step: 12
Training loss: 2.3066272912863455
Validation loss: 2.466083067941523

Epoch: 6| Step: 13
Training loss: 1.9700131073142921
Validation loss: 2.455829231324366

Epoch: 102| Step: 0
Training loss: 2.1669158303215754
Validation loss: 2.462967325136066

Epoch: 6| Step: 1
Training loss: 2.2859116047600376
Validation loss: 2.4717432619557766

Epoch: 6| Step: 2
Training loss: 2.6051828665075196
Validation loss: 2.478305720586131

Epoch: 6| Step: 3
Training loss: 2.4450408492157134
Validation loss: 2.478045175171887

Epoch: 6| Step: 4
Training loss: 2.723575300099801
Validation loss: 2.477294637160546

Epoch: 6| Step: 5
Training loss: 3.0082687230097758
Validation loss: 2.477618869633352

Epoch: 6| Step: 6
Training loss: 2.469261792406483
Validation loss: 2.476498961009642

Epoch: 6| Step: 7
Training loss: 2.897366966109697
Validation loss: 2.4720562070713528

Epoch: 6| Step: 8
Training loss: 2.8195301777834185
Validation loss: 2.4825871110213242

Epoch: 6| Step: 9
Training loss: 2.396907852922513
Validation loss: 2.4800434378696057

Epoch: 6| Step: 10
Training loss: 2.945960664133033
Validation loss: 2.47644597851419

Epoch: 6| Step: 11
Training loss: 2.532486601753605
Validation loss: 2.476532784493289

Epoch: 6| Step: 12
Training loss: 2.215988697498294
Validation loss: 2.4730745175723348

Epoch: 6| Step: 13
Training loss: 2.478423276943885
Validation loss: 2.463252195055248

Epoch: 103| Step: 0
Training loss: 2.620906544579085
Validation loss: 2.4558337052155896

Epoch: 6| Step: 1
Training loss: 2.9379320841418837
Validation loss: 2.471537983486132

Epoch: 6| Step: 2
Training loss: 2.6032649704394553
Validation loss: 2.4636075909579938

Epoch: 6| Step: 3
Training loss: 2.9681991869261473
Validation loss: 2.4740476464998173

Epoch: 6| Step: 4
Training loss: 2.711818409030577
Validation loss: 2.4801646449185037

Epoch: 6| Step: 5
Training loss: 2.3656515545784513
Validation loss: 2.461670636161164

Epoch: 6| Step: 6
Training loss: 2.5707360008605717
Validation loss: 2.458397562728875

Epoch: 6| Step: 7
Training loss: 2.6844000569818336
Validation loss: 2.452381272366662

Epoch: 6| Step: 8
Training loss: 1.9695294366182834
Validation loss: 2.467405749978107

Epoch: 6| Step: 9
Training loss: 2.820855846531187
Validation loss: 2.4529097638800654

Epoch: 6| Step: 10
Training loss: 2.284256404193469
Validation loss: 2.4650741122893614

Epoch: 6| Step: 11
Training loss: 2.3835814189060542
Validation loss: 2.464666780384953

Epoch: 6| Step: 12
Training loss: 1.817723672213684
Validation loss: 2.470239568152894

Epoch: 6| Step: 13
Training loss: 2.860935139928539
Validation loss: 2.4667038949098803

Epoch: 104| Step: 0
Training loss: 2.460410603626952
Validation loss: 2.476108593665452

Epoch: 6| Step: 1
Training loss: 2.1971835922186926
Validation loss: 2.468874819533582

Epoch: 6| Step: 2
Training loss: 2.5774841436865934
Validation loss: 2.466538078161105

Epoch: 6| Step: 3
Training loss: 2.67678952120037
Validation loss: 2.466139495637371

Epoch: 6| Step: 4
Training loss: 2.834166086524546
Validation loss: 2.4674136733981187

Epoch: 6| Step: 5
Training loss: 2.4957722201584325
Validation loss: 2.4613405977348934

Epoch: 6| Step: 6
Training loss: 2.0466175645453086
Validation loss: 2.4628237968088604

Epoch: 6| Step: 7
Training loss: 2.546197344722896
Validation loss: 2.465675773790817

Epoch: 6| Step: 8
Training loss: 2.8147561243093793
Validation loss: 2.4538539119411085

Epoch: 6| Step: 9
Training loss: 2.592484682602543
Validation loss: 2.466609090914942

Epoch: 6| Step: 10
Training loss: 2.554694032806536
Validation loss: 2.460129927277026

Epoch: 6| Step: 11
Training loss: 2.6092534750776113
Validation loss: 2.463201186111708

Epoch: 6| Step: 12
Training loss: 2.676523904694734
Validation loss: 2.4642972748447725

Epoch: 6| Step: 13
Training loss: 2.5624531067069825
Validation loss: 2.4612760765046593

Epoch: 105| Step: 0
Training loss: 2.1913192106154913
Validation loss: 2.4617633947490525

Epoch: 6| Step: 1
Training loss: 2.8543226287628003
Validation loss: 2.466728445087087

Epoch: 6| Step: 2
Training loss: 2.4690633647353746
Validation loss: 2.4684942974184136

Epoch: 6| Step: 3
Training loss: 2.819247818862357
Validation loss: 2.471613579263759

Epoch: 6| Step: 4
Training loss: 2.627242084479271
Validation loss: 2.4722736337819025

Epoch: 6| Step: 5
Training loss: 2.3096559923985773
Validation loss: 2.457175051994672

Epoch: 6| Step: 6
Training loss: 2.6917231889425617
Validation loss: 2.465357658871056

Epoch: 6| Step: 7
Training loss: 2.497400076302009
Validation loss: 2.4621180372062077

Epoch: 6| Step: 8
Training loss: 2.231487302155537
Validation loss: 2.4643546786507633

Epoch: 6| Step: 9
Training loss: 2.3612485608752314
Validation loss: 2.4636873090623572

Epoch: 6| Step: 10
Training loss: 2.3425018038584993
Validation loss: 2.4617139933467627

Epoch: 6| Step: 11
Training loss: 3.22419648325695
Validation loss: 2.4688021980272152

Epoch: 6| Step: 12
Training loss: 2.2062234936383565
Validation loss: 2.4687014063949824

Epoch: 6| Step: 13
Training loss: 2.663767510244243
Validation loss: 2.4711248025421484

Epoch: 106| Step: 0
Training loss: 3.2258622192361406
Validation loss: 2.4729069346167054

Epoch: 6| Step: 1
Training loss: 2.0934332992390843
Validation loss: 2.4657511625256556

Epoch: 6| Step: 2
Training loss: 2.7096802712204275
Validation loss: 2.460608211063118

Epoch: 6| Step: 3
Training loss: 2.5983047020170527
Validation loss: 2.4680384644695548

Epoch: 6| Step: 4
Training loss: 2.373387542259109
Validation loss: 2.454432112927263

Epoch: 6| Step: 5
Training loss: 3.167209595432378
Validation loss: 2.456783943284163

Epoch: 6| Step: 6
Training loss: 2.558225462520816
Validation loss: 2.463661268905069

Epoch: 6| Step: 7
Training loss: 2.3860485678092003
Validation loss: 2.4564848809377757

Epoch: 6| Step: 8
Training loss: 2.91155669035398
Validation loss: 2.4639007489467177

Epoch: 6| Step: 9
Training loss: 2.572569438860928
Validation loss: 2.4610108864150906

Epoch: 6| Step: 10
Training loss: 2.007868784549737
Validation loss: 2.4567538753266875

Epoch: 6| Step: 11
Training loss: 2.0330034170727176
Validation loss: 2.4599084064830814

Epoch: 6| Step: 12
Training loss: 2.4656344685535876
Validation loss: 2.4633352718767205

Epoch: 6| Step: 13
Training loss: 2.0850375516514985
Validation loss: 2.460722559670386

Epoch: 107| Step: 0
Training loss: 2.1425313883633232
Validation loss: 2.4607564062264897

Epoch: 6| Step: 1
Training loss: 2.458959553587989
Validation loss: 2.461729925225712

Epoch: 6| Step: 2
Training loss: 2.642075540887755
Validation loss: 2.462189726154128

Epoch: 6| Step: 3
Training loss: 2.8868835980290815
Validation loss: 2.4555308132761495

Epoch: 6| Step: 4
Training loss: 2.651774956413932
Validation loss: 2.4665938993838323

Epoch: 6| Step: 5
Training loss: 2.3565808860710074
Validation loss: 2.470335793108889

Epoch: 6| Step: 6
Training loss: 2.859458546903158
Validation loss: 2.4741046152870423

Epoch: 6| Step: 7
Training loss: 2.499358857911876
Validation loss: 2.466667165842092

Epoch: 6| Step: 8
Training loss: 2.1753721554575414
Validation loss: 2.4691615908396014

Epoch: 6| Step: 9
Training loss: 2.194410254081997
Validation loss: 2.4732206081226282

Epoch: 6| Step: 10
Training loss: 2.3039110847906206
Validation loss: 2.470055279338393

Epoch: 6| Step: 11
Training loss: 2.7891520851771507
Validation loss: 2.4655611875243477

Epoch: 6| Step: 12
Training loss: 2.7077826796010624
Validation loss: 2.4652377789495583

Epoch: 6| Step: 13
Training loss: 2.725055092070943
Validation loss: 2.456832586605044

Epoch: 108| Step: 0
Training loss: 2.2440016581483313
Validation loss: 2.4645923419786673

Epoch: 6| Step: 1
Training loss: 2.399043003652503
Validation loss: 2.4657456349562388

Epoch: 6| Step: 2
Training loss: 2.3662692766165114
Validation loss: 2.4490498510406193

Epoch: 6| Step: 3
Training loss: 2.7538797580175234
Validation loss: 2.456936784392926

Epoch: 6| Step: 4
Training loss: 2.303869483734592
Validation loss: 2.4642354997609015

Epoch: 6| Step: 5
Training loss: 2.7195591215849486
Validation loss: 2.4594840465446244

Epoch: 6| Step: 6
Training loss: 2.6270499626377624
Validation loss: 2.462208414645371

Epoch: 6| Step: 7
Training loss: 2.495870804120641
Validation loss: 2.461469045888282

Epoch: 6| Step: 8
Training loss: 1.9709780967188248
Validation loss: 2.4686478219435477

Epoch: 6| Step: 9
Training loss: 2.7157804560968795
Validation loss: 2.475724761501428

Epoch: 6| Step: 10
Training loss: 2.876295875737181
Validation loss: 2.473597969445312

Epoch: 6| Step: 11
Training loss: 2.5939033187225546
Validation loss: 2.475072980376313

Epoch: 6| Step: 12
Training loss: 2.6703761843726164
Validation loss: 2.4696283347316847

Epoch: 6| Step: 13
Training loss: 2.785577044058159
Validation loss: 2.4765744855813336

Epoch: 109| Step: 0
Training loss: 2.349400841646181
Validation loss: 2.474252676603225

Epoch: 6| Step: 1
Training loss: 3.0184771238720476
Validation loss: 2.4651275971088533

Epoch: 6| Step: 2
Training loss: 2.3689444791729612
Validation loss: 2.462711627212446

Epoch: 6| Step: 3
Training loss: 2.3755161326893743
Validation loss: 2.4596616475349222

Epoch: 6| Step: 4
Training loss: 2.2766788617873783
Validation loss: 2.462135870874335

Epoch: 6| Step: 5
Training loss: 2.5918211601631644
Validation loss: 2.464334273040887

Epoch: 6| Step: 6
Training loss: 2.6510531581986836
Validation loss: 2.4546703484525048

Epoch: 6| Step: 7
Training loss: 2.8589212026234754
Validation loss: 2.4639424380456867

Epoch: 6| Step: 8
Training loss: 2.2001615031523514
Validation loss: 2.4572211971961693

Epoch: 6| Step: 9
Training loss: 3.0775136582592872
Validation loss: 2.4602783935177808

Epoch: 6| Step: 10
Training loss: 2.5294450517648057
Validation loss: 2.4548215486706915

Epoch: 6| Step: 11
Training loss: 2.4423988216688435
Validation loss: 2.452706805501186

Epoch: 6| Step: 12
Training loss: 2.0080809654919163
Validation loss: 2.4648317718617845

Epoch: 6| Step: 13
Training loss: 2.738632462598396
Validation loss: 2.463164808120541

Epoch: 110| Step: 0
Training loss: 2.6501343279207887
Validation loss: 2.469239278990142

Epoch: 6| Step: 1
Training loss: 2.06978845261694
Validation loss: 2.4631506842811777

Epoch: 6| Step: 2
Training loss: 3.024311737704367
Validation loss: 2.4622630106946004

Epoch: 6| Step: 3
Training loss: 2.9717920077154765
Validation loss: 2.4543336777996605

Epoch: 6| Step: 4
Training loss: 1.5662489357813014
Validation loss: 2.4569827319086843

Epoch: 6| Step: 5
Training loss: 2.050540931789843
Validation loss: 2.460845025156754

Epoch: 6| Step: 6
Training loss: 2.8025242530664882
Validation loss: 2.464057002830461

Epoch: 6| Step: 7
Training loss: 2.7503009978206534
Validation loss: 2.4643542916632897

Epoch: 6| Step: 8
Training loss: 2.477605654160253
Validation loss: 2.4569653945450396

Epoch: 6| Step: 9
Training loss: 3.06812532674757
Validation loss: 2.4616748653766916

Epoch: 6| Step: 10
Training loss: 2.444883071194106
Validation loss: 2.458195485813878

Epoch: 6| Step: 11
Training loss: 2.056885446610607
Validation loss: 2.462070168097221

Epoch: 6| Step: 12
Training loss: 2.7178212475863432
Validation loss: 2.462082934359909

Epoch: 6| Step: 13
Training loss: 2.324572419257582
Validation loss: 2.4615046579266653

Epoch: 111| Step: 0
Training loss: 3.305457924933527
Validation loss: 2.4650386968983713

Epoch: 6| Step: 1
Training loss: 2.3870849328466583
Validation loss: 2.459471606078336

Epoch: 6| Step: 2
Training loss: 2.7061231446873673
Validation loss: 2.4620682878519276

Epoch: 6| Step: 3
Training loss: 2.3013835435998486
Validation loss: 2.463906135508278

Epoch: 6| Step: 4
Training loss: 2.593297620182551
Validation loss: 2.459747543458319

Epoch: 6| Step: 5
Training loss: 2.4863983168361865
Validation loss: 2.454373942777197

Epoch: 6| Step: 6
Training loss: 2.3454042827175123
Validation loss: 2.463152305582672

Epoch: 6| Step: 7
Training loss: 2.5476683334723793
Validation loss: 2.4657084242612095

Epoch: 6| Step: 8
Training loss: 2.129629365795076
Validation loss: 2.466057472029036

Epoch: 6| Step: 9
Training loss: 2.53709518510875
Validation loss: 2.464057212473974

Epoch: 6| Step: 10
Training loss: 2.444391924361315
Validation loss: 2.457112693548673

Epoch: 6| Step: 11
Training loss: 2.3804125096557294
Validation loss: 2.4537465954143363

Epoch: 6| Step: 12
Training loss: 2.6731758743236327
Validation loss: 2.453653736192196

Epoch: 6| Step: 13
Training loss: 2.52162053030922
Validation loss: 2.449627888246133

Epoch: 112| Step: 0
Training loss: 2.3975948879013065
Validation loss: 2.4630356336796835

Epoch: 6| Step: 1
Training loss: 2.703948143670597
Validation loss: 2.4521175996843385

Epoch: 6| Step: 2
Training loss: 2.4004659120999423
Validation loss: 2.455014547912214

Epoch: 6| Step: 3
Training loss: 2.433210658112135
Validation loss: 2.459903188857734

Epoch: 6| Step: 4
Training loss: 1.8239536787141077
Validation loss: 2.463489432449856

Epoch: 6| Step: 5
Training loss: 2.3914442466252055
Validation loss: 2.4696416733425695

Epoch: 6| Step: 6
Training loss: 2.2065872150804164
Validation loss: 2.480096023069597

Epoch: 6| Step: 7
Training loss: 2.067483603102254
Validation loss: 2.4751586143967677

Epoch: 6| Step: 8
Training loss: 2.6619761063487184
Validation loss: 2.4740416395650575

Epoch: 6| Step: 9
Training loss: 3.1880883066637953
Validation loss: 2.473408099104385

Epoch: 6| Step: 10
Training loss: 2.7666881694494294
Validation loss: 2.4755755683235336

Epoch: 6| Step: 11
Training loss: 2.7186852809174598
Validation loss: 2.4805586991308592

Epoch: 6| Step: 12
Training loss: 3.119916825286229
Validation loss: 2.476489438043216

Epoch: 6| Step: 13
Training loss: 2.8708766725440364
Validation loss: 2.477448715028161

Epoch: 113| Step: 0
Training loss: 2.8112177999033894
Validation loss: 2.4801911446527005

Epoch: 6| Step: 1
Training loss: 3.0821253154213144
Validation loss: 2.48124297466933

Epoch: 6| Step: 2
Training loss: 2.7362703566406092
Validation loss: 2.4804303664394047

Epoch: 6| Step: 3
Training loss: 2.959149225760645
Validation loss: 2.4777889323684357

Epoch: 6| Step: 4
Training loss: 1.9853031661049745
Validation loss: 2.477171067998676

Epoch: 6| Step: 5
Training loss: 2.413322557544712
Validation loss: 2.4796682913504347

Epoch: 6| Step: 6
Training loss: 2.5657175844239872
Validation loss: 2.473401881764964

Epoch: 6| Step: 7
Training loss: 2.7405835103947314
Validation loss: 2.4713655611558702

Epoch: 6| Step: 8
Training loss: 2.5656296761362114
Validation loss: 2.4639035228661177

Epoch: 6| Step: 9
Training loss: 2.418916531924061
Validation loss: 2.4629317987818595

Epoch: 6| Step: 10
Training loss: 2.7584877808386485
Validation loss: 2.462479381829968

Epoch: 6| Step: 11
Training loss: 1.9733578482385272
Validation loss: 2.4667819262545208

Epoch: 6| Step: 12
Training loss: 2.5399794580725295
Validation loss: 2.470618124644367

Epoch: 6| Step: 13
Training loss: 2.557918080811442
Validation loss: 2.463124081878375

Epoch: 114| Step: 0
Training loss: 2.6800625819400627
Validation loss: 2.47093141327885

Epoch: 6| Step: 1
Training loss: 2.539509989112515
Validation loss: 2.479073231536528

Epoch: 6| Step: 2
Training loss: 1.543185061973465
Validation loss: 2.4674547072881627

Epoch: 6| Step: 3
Training loss: 2.553612159000217
Validation loss: 2.46644592607687

Epoch: 6| Step: 4
Training loss: 2.6755037706833678
Validation loss: 2.4666668275455046

Epoch: 6| Step: 5
Training loss: 2.4488745147843236
Validation loss: 2.4758251388124872

Epoch: 6| Step: 6
Training loss: 2.9292275029498964
Validation loss: 2.469288135578715

Epoch: 6| Step: 7
Training loss: 2.348654333321359
Validation loss: 2.473954665867279

Epoch: 6| Step: 8
Training loss: 2.671102490205794
Validation loss: 2.4702245276379995

Epoch: 6| Step: 9
Training loss: 2.9194229363123965
Validation loss: 2.464967372915649

Epoch: 6| Step: 10
Training loss: 2.1397437070514904
Validation loss: 2.46810138406771

Epoch: 6| Step: 11
Training loss: 2.9898442986305676
Validation loss: 2.463608970018447

Epoch: 6| Step: 12
Training loss: 1.8023420012241935
Validation loss: 2.4608984565665226

Epoch: 6| Step: 13
Training loss: 2.766211496008469
Validation loss: 2.461094733165307

Epoch: 115| Step: 0
Training loss: 2.6468243482623093
Validation loss: 2.4637075990653647

Epoch: 6| Step: 1
Training loss: 2.985996784318341
Validation loss: 2.468331957483348

Epoch: 6| Step: 2
Training loss: 2.5760095413576263
Validation loss: 2.455518959625215

Epoch: 6| Step: 3
Training loss: 2.637328126920852
Validation loss: 2.465339268259291

Epoch: 6| Step: 4
Training loss: 1.7905419907960363
Validation loss: 2.465336254184506

Epoch: 6| Step: 5
Training loss: 1.966635400986934
Validation loss: 2.4649195994431445

Epoch: 6| Step: 6
Training loss: 2.558268985084001
Validation loss: 2.4649229445030003

Epoch: 6| Step: 7
Training loss: 2.7732853377602944
Validation loss: 2.4678448172479603

Epoch: 6| Step: 8
Training loss: 2.9159649322661707
Validation loss: 2.4600004965567153

Epoch: 6| Step: 9
Training loss: 2.867991654302779
Validation loss: 2.464534379392844

Epoch: 6| Step: 10
Training loss: 1.789892678693059
Validation loss: 2.459532886883685

Epoch: 6| Step: 11
Training loss: 2.492682428752767
Validation loss: 2.4694156473647917

Epoch: 6| Step: 12
Training loss: 2.3666752931500312
Validation loss: 2.460853664039917

Epoch: 6| Step: 13
Training loss: 2.558282871142145
Validation loss: 2.462857759696585

Epoch: 116| Step: 0
Training loss: 2.9552535202306163
Validation loss: 2.465175801766398

Epoch: 6| Step: 1
Training loss: 1.8453272522571635
Validation loss: 2.4575339380755685

Epoch: 6| Step: 2
Training loss: 1.9641337695122942
Validation loss: 2.4600451753960164

Epoch: 6| Step: 3
Training loss: 2.615197452800184
Validation loss: 2.4579983714724

Epoch: 6| Step: 4
Training loss: 2.4603040091756787
Validation loss: 2.4605349741331652

Epoch: 6| Step: 5
Training loss: 2.2051463492476735
Validation loss: 2.4706563550621032

Epoch: 6| Step: 6
Training loss: 2.2779775689538697
Validation loss: 2.457938814565129

Epoch: 6| Step: 7
Training loss: 2.375024293474129
Validation loss: 2.457324683169855

Epoch: 6| Step: 8
Training loss: 2.4235970558358906
Validation loss: 2.458661919525443

Epoch: 6| Step: 9
Training loss: 3.1175003086019575
Validation loss: 2.4630652216294577

Epoch: 6| Step: 10
Training loss: 2.824202794706616
Validation loss: 2.471251930129295

Epoch: 6| Step: 11
Training loss: 2.9239784869695504
Validation loss: 2.476824292326362

Epoch: 6| Step: 12
Training loss: 2.472291940665659
Validation loss: 2.4810838632510555

Epoch: 6| Step: 13
Training loss: 2.724844929893768
Validation loss: 2.4761016609478115

Epoch: 117| Step: 0
Training loss: 2.6727168669819488
Validation loss: 2.4813568527826138

Epoch: 6| Step: 1
Training loss: 2.5517428631642085
Validation loss: 2.4794987261138677

Epoch: 6| Step: 2
Training loss: 2.1810746786493156
Validation loss: 2.478377951387337

Epoch: 6| Step: 3
Training loss: 2.6197797548744997
Validation loss: 2.4710868849022285

Epoch: 6| Step: 4
Training loss: 2.7449274964476555
Validation loss: 2.47581541263134

Epoch: 6| Step: 5
Training loss: 3.1618840759955416
Validation loss: 2.471865145265376

Epoch: 6| Step: 6
Training loss: 2.2891829006571607
Validation loss: 2.469628720892723

Epoch: 6| Step: 7
Training loss: 2.0921708030119888
Validation loss: 2.471020961818709

Epoch: 6| Step: 8
Training loss: 2.8049571298189337
Validation loss: 2.4587038752294506

Epoch: 6| Step: 9
Training loss: 1.9285878743373706
Validation loss: 2.4633116234978547

Epoch: 6| Step: 10
Training loss: 2.828245381696382
Validation loss: 2.460185829292472

Epoch: 6| Step: 11
Training loss: 1.8904036084904658
Validation loss: 2.459961817853426

Epoch: 6| Step: 12
Training loss: 2.4772001101530305
Validation loss: 2.472023535958479

Epoch: 6| Step: 13
Training loss: 2.82044251372113
Validation loss: 2.4682519144680404

Epoch: 118| Step: 0
Training loss: 2.677714608618237
Validation loss: 2.45730692778006

Epoch: 6| Step: 1
Training loss: 2.4370909127491314
Validation loss: 2.4665591421619584

Epoch: 6| Step: 2
Training loss: 2.2884079970672317
Validation loss: 2.464494667382307

Epoch: 6| Step: 3
Training loss: 2.206947959746126
Validation loss: 2.4645392647482325

Epoch: 6| Step: 4
Training loss: 3.176343204192184
Validation loss: 2.4646715848658864

Epoch: 6| Step: 5
Training loss: 2.304163986489621
Validation loss: 2.4683553001908263

Epoch: 6| Step: 6
Training loss: 2.471280696139912
Validation loss: 2.474014254824731

Epoch: 6| Step: 7
Training loss: 2.1468195701228825
Validation loss: 2.4672111028533177

Epoch: 6| Step: 8
Training loss: 2.4517868182495666
Validation loss: 2.466369527455383

Epoch: 6| Step: 9
Training loss: 2.2013013068853313
Validation loss: 2.46982709509834

Epoch: 6| Step: 10
Training loss: 2.504958195137637
Validation loss: 2.47185641224299

Epoch: 6| Step: 11
Training loss: 2.74310704651053
Validation loss: 2.4741898010121406

Epoch: 6| Step: 12
Training loss: 2.4657606544453956
Validation loss: 2.4635830338750417

Epoch: 6| Step: 13
Training loss: 2.787092779547211
Validation loss: 2.469014519793105

Epoch: 119| Step: 0
Training loss: 2.3374078008246566
Validation loss: 2.469002473371319

Epoch: 6| Step: 1
Training loss: 3.0296702250184393
Validation loss: 2.467025669710178

Epoch: 6| Step: 2
Training loss: 2.186791441466625
Validation loss: 2.4651270168096246

Epoch: 6| Step: 3
Training loss: 2.4345991038836066
Validation loss: 2.464750462462966

Epoch: 6| Step: 4
Training loss: 2.815159028136551
Validation loss: 2.4662406175412053

Epoch: 6| Step: 5
Training loss: 1.8333898521149987
Validation loss: 2.4642336453556903

Epoch: 6| Step: 6
Training loss: 3.042727890569948
Validation loss: 2.4693698346376767

Epoch: 6| Step: 7
Training loss: 2.7246230258394593
Validation loss: 2.4623869487546712

Epoch: 6| Step: 8
Training loss: 2.7387786282915196
Validation loss: 2.47299402550329

Epoch: 6| Step: 9
Training loss: 2.021555964727212
Validation loss: 2.472917459600804

Epoch: 6| Step: 10
Training loss: 2.3802043711645315
Validation loss: 2.4763694551563167

Epoch: 6| Step: 11
Training loss: 2.693811324764631
Validation loss: 2.4788073084277773

Epoch: 6| Step: 12
Training loss: 2.373229621789269
Validation loss: 2.4766989749565576

Epoch: 6| Step: 13
Training loss: 2.456164378452609
Validation loss: 2.4734874611855404

Epoch: 120| Step: 0
Training loss: 2.8110412205320423
Validation loss: 2.4747310248233

Epoch: 6| Step: 1
Training loss: 2.5693084703729476
Validation loss: 2.4696214320929397

Epoch: 6| Step: 2
Training loss: 2.0995256841968604
Validation loss: 2.4780527117954385

Epoch: 6| Step: 3
Training loss: 2.178345297751615
Validation loss: 2.475494924824782

Epoch: 6| Step: 4
Training loss: 2.878124860831888
Validation loss: 2.467562329433624

Epoch: 6| Step: 5
Training loss: 2.7952918148394885
Validation loss: 2.4660128618355093

Epoch: 6| Step: 6
Training loss: 2.558476895291938
Validation loss: 2.4680490102152226

Epoch: 6| Step: 7
Training loss: 2.4253163160901843
Validation loss: 2.4600593412938587

Epoch: 6| Step: 8
Training loss: 2.3098367355912126
Validation loss: 2.4634863193308365

Epoch: 6| Step: 9
Training loss: 2.9452823870103524
Validation loss: 2.4702580992282104

Epoch: 6| Step: 10
Training loss: 2.0695695803683045
Validation loss: 2.4686583811824967

Epoch: 6| Step: 11
Training loss: 2.5086514504638844
Validation loss: 2.4805405653922694

Epoch: 6| Step: 12
Training loss: 2.8301227742444963
Validation loss: 2.474758144725059

Epoch: 6| Step: 13
Training loss: 1.9722982251681578
Validation loss: 2.4818007849973727

Epoch: 121| Step: 0
Training loss: 2.630098387179673
Validation loss: 2.4721859629849727

Epoch: 6| Step: 1
Training loss: 2.540024888975498
Validation loss: 2.473048479851637

Epoch: 6| Step: 2
Training loss: 2.401555225011346
Validation loss: 2.4663626318075242

Epoch: 6| Step: 3
Training loss: 2.7865245395293785
Validation loss: 2.4693438624507014

Epoch: 6| Step: 4
Training loss: 2.4962671067478337
Validation loss: 2.4722084254571595

Epoch: 6| Step: 5
Training loss: 2.5519320592356753
Validation loss: 2.474195422138961

Epoch: 6| Step: 6
Training loss: 2.988440495654771
Validation loss: 2.4680564807619865

Epoch: 6| Step: 7
Training loss: 1.8845455060906242
Validation loss: 2.468535723823268

Epoch: 6| Step: 8
Training loss: 2.573052705161956
Validation loss: 2.467945281590684

Epoch: 6| Step: 9
Training loss: 2.1458716034177097
Validation loss: 2.472769045152883

Epoch: 6| Step: 10
Training loss: 2.819482654840864
Validation loss: 2.470230262347796

Epoch: 6| Step: 11
Training loss: 2.3125203105962475
Validation loss: 2.4660970380253153

Epoch: 6| Step: 12
Training loss: 2.1434160956762693
Validation loss: 2.468091063946766

Epoch: 6| Step: 13
Training loss: 2.6713134889461374
Validation loss: 2.4669989319133983

Epoch: 122| Step: 0
Training loss: 2.673224571216249
Validation loss: 2.459793390007597

Epoch: 6| Step: 1
Training loss: 2.1705382919677305
Validation loss: 2.459886905918618

Epoch: 6| Step: 2
Training loss: 2.4099687846524627
Validation loss: 2.452334784938681

Epoch: 6| Step: 3
Training loss: 2.6866377400938486
Validation loss: 2.4592261686616523

Epoch: 6| Step: 4
Training loss: 2.405170842722888
Validation loss: 2.4613641601146092

Epoch: 6| Step: 5
Training loss: 2.9089820080119115
Validation loss: 2.4650557034422986

Epoch: 6| Step: 6
Training loss: 2.33643491418343
Validation loss: 2.4690365202540825

Epoch: 6| Step: 7
Training loss: 2.264120720640637
Validation loss: 2.450721794641911

Epoch: 6| Step: 8
Training loss: 2.606610324019803
Validation loss: 2.4522434440548753

Epoch: 6| Step: 9
Training loss: 1.925507748509232
Validation loss: 2.464003785054078

Epoch: 6| Step: 10
Training loss: 2.691054544044211
Validation loss: 2.4652728449334833

Epoch: 6| Step: 11
Training loss: 2.44537519185686
Validation loss: 2.471562662498027

Epoch: 6| Step: 12
Training loss: 2.794700672451756
Validation loss: 2.466525496060248

Epoch: 6| Step: 13
Training loss: 2.8491474951245697
Validation loss: 2.4698036134565786

Epoch: 123| Step: 0
Training loss: 2.5142296184902064
Validation loss: 2.471001825382655

Epoch: 6| Step: 1
Training loss: 2.7008449221414086
Validation loss: 2.472745953018003

Epoch: 6| Step: 2
Training loss: 2.17674751672924
Validation loss: 2.4709587678596674

Epoch: 6| Step: 3
Training loss: 2.966631806272362
Validation loss: 2.4730713201132226

Epoch: 6| Step: 4
Training loss: 2.7983714953742376
Validation loss: 2.4708515188010027

Epoch: 6| Step: 5
Training loss: 2.6610354232465965
Validation loss: 2.470770777403095

Epoch: 6| Step: 6
Training loss: 2.2265751353122845
Validation loss: 2.472698948528164

Epoch: 6| Step: 7
Training loss: 2.395904296708618
Validation loss: 2.4738950272876195

Epoch: 6| Step: 8
Training loss: 2.3790200993898267
Validation loss: 2.468495947405089

Epoch: 6| Step: 9
Training loss: 2.1148152592194527
Validation loss: 2.4580516707708573

Epoch: 6| Step: 10
Training loss: 2.8054589190904404
Validation loss: 2.4559682093943365

Epoch: 6| Step: 11
Training loss: 2.6316473219170393
Validation loss: 2.4500541661561277

Epoch: 6| Step: 12
Training loss: 2.624630856670908
Validation loss: 2.459475160503697

Epoch: 6| Step: 13
Training loss: 2.076311280817757
Validation loss: 2.4850806587632692

Epoch: 124| Step: 0
Training loss: 2.811228401097717
Validation loss: 2.519843850470014

Epoch: 6| Step: 1
Training loss: 2.2301452722829156
Validation loss: 2.5070817938528287

Epoch: 6| Step: 2
Training loss: 2.0374067460700833
Validation loss: 2.475218575712761

Epoch: 6| Step: 3
Training loss: 2.0743096685508897
Validation loss: 2.452482961555943

Epoch: 6| Step: 4
Training loss: 2.353539329820974
Validation loss: 2.4528294767972523

Epoch: 6| Step: 5
Training loss: 2.9377652312315576
Validation loss: 2.4603469220730116

Epoch: 6| Step: 6
Training loss: 2.4971312275640987
Validation loss: 2.4603328224343195

Epoch: 6| Step: 7
Training loss: 2.598074559540421
Validation loss: 2.466064441040027

Epoch: 6| Step: 8
Training loss: 3.2881034848340067
Validation loss: 2.4687692504647334

Epoch: 6| Step: 9
Training loss: 2.272545288776128
Validation loss: 2.4660167452183583

Epoch: 6| Step: 10
Training loss: 2.5475066168252742
Validation loss: 2.466100389544605

Epoch: 6| Step: 11
Training loss: 2.7832668578229196
Validation loss: 2.4665181658694686

Epoch: 6| Step: 12
Training loss: 2.4989357590434227
Validation loss: 2.463191135837926

Epoch: 6| Step: 13
Training loss: 2.1754440512032875
Validation loss: 2.4642992904504997

Epoch: 125| Step: 0
Training loss: 2.3734998482607077
Validation loss: 2.461962241307015

Epoch: 6| Step: 1
Training loss: 2.8266515107318337
Validation loss: 2.463744791594067

Epoch: 6| Step: 2
Training loss: 2.6721093147553754
Validation loss: 2.456695016113365

Epoch: 6| Step: 3
Training loss: 1.9171097768435474
Validation loss: 2.464952622642482

Epoch: 6| Step: 4
Training loss: 2.6429229308375923
Validation loss: 2.4593449036155497

Epoch: 6| Step: 5
Training loss: 2.6325949740327026
Validation loss: 2.459682899664333

Epoch: 6| Step: 6
Training loss: 2.832809025740768
Validation loss: 2.4562798722305432

Epoch: 6| Step: 7
Training loss: 2.3968850743605508
Validation loss: 2.452515706651369

Epoch: 6| Step: 8
Training loss: 3.1011747410909103
Validation loss: 2.447919428938802

Epoch: 6| Step: 9
Training loss: 2.3555118689694514
Validation loss: 2.4528923815283257

Epoch: 6| Step: 10
Training loss: 2.488615914779773
Validation loss: 2.449703446430546

Epoch: 6| Step: 11
Training loss: 2.3544749730421093
Validation loss: 2.4592316704895856

Epoch: 6| Step: 12
Training loss: 1.697315351418423
Validation loss: 2.458370908891827

Epoch: 6| Step: 13
Training loss: 2.6096649008882307
Validation loss: 2.455959715122437

Epoch: 126| Step: 0
Training loss: 2.412808978598557
Validation loss: 2.467079305501093

Epoch: 6| Step: 1
Training loss: 2.6612691693849655
Validation loss: 2.469627031437735

Epoch: 6| Step: 2
Training loss: 2.750744112084222
Validation loss: 2.4682748715597054

Epoch: 6| Step: 3
Training loss: 2.612318833927818
Validation loss: 2.476703515435418

Epoch: 6| Step: 4
Training loss: 2.288895011737292
Validation loss: 2.461220893487562

Epoch: 6| Step: 5
Training loss: 1.8553313836898364
Validation loss: 2.463795692514318

Epoch: 6| Step: 6
Training loss: 2.4457302528854545
Validation loss: 2.468473523589383

Epoch: 6| Step: 7
Training loss: 2.5714003281328974
Validation loss: 2.4544321938755784

Epoch: 6| Step: 8
Training loss: 2.509658846828752
Validation loss: 2.46718873178372

Epoch: 6| Step: 9
Training loss: 2.7834816883623
Validation loss: 2.4721204549819626

Epoch: 6| Step: 10
Training loss: 2.805796029598498
Validation loss: 2.4740468113119003

Epoch: 6| Step: 11
Training loss: 2.69688179660617
Validation loss: 2.4712556605643243

Epoch: 6| Step: 12
Training loss: 2.4864201794624115
Validation loss: 2.4669019163776804

Epoch: 6| Step: 13
Training loss: 2.0433104249417857
Validation loss: 2.4637375015155953

Epoch: 127| Step: 0
Training loss: 2.8156074311685244
Validation loss: 2.4684831821135838

Epoch: 6| Step: 1
Training loss: 2.5073667706497575
Validation loss: 2.4750030934991996

Epoch: 6| Step: 2
Training loss: 2.5268798591063204
Validation loss: 2.4684626898997695

Epoch: 6| Step: 3
Training loss: 2.263177430968551
Validation loss: 2.4693327429240672

Epoch: 6| Step: 4
Training loss: 2.2873874824242124
Validation loss: 2.471925294977703

Epoch: 6| Step: 5
Training loss: 2.059259701454843
Validation loss: 2.478750439706501

Epoch: 6| Step: 6
Training loss: 3.0182654329523246
Validation loss: 2.477691272815959

Epoch: 6| Step: 7
Training loss: 2.3539410598363744
Validation loss: 2.4742888915760926

Epoch: 6| Step: 8
Training loss: 2.1543298547594585
Validation loss: 2.473197632671739

Epoch: 6| Step: 9
Training loss: 2.458285789245515
Validation loss: 2.470839746690975

Epoch: 6| Step: 10
Training loss: 2.6783890762019746
Validation loss: 2.466279922809101

Epoch: 6| Step: 11
Training loss: 2.4063965393627424
Validation loss: 2.4670424853809227

Epoch: 6| Step: 12
Training loss: 2.3644554562937663
Validation loss: 2.4709972663863247

Epoch: 6| Step: 13
Training loss: 2.939632210076216
Validation loss: 2.472429165649947

Epoch: 128| Step: 0
Training loss: 1.6597674464294108
Validation loss: 2.465787276748587

Epoch: 6| Step: 1
Training loss: 2.677523437026996
Validation loss: 2.4772665665607985

Epoch: 6| Step: 2
Training loss: 2.6529250933457056
Validation loss: 2.4627158304374714

Epoch: 6| Step: 3
Training loss: 2.8509226459993053
Validation loss: 2.4645455689383997

Epoch: 6| Step: 4
Training loss: 2.603273029858194
Validation loss: 2.4677694602685682

Epoch: 6| Step: 5
Training loss: 2.5878167368579272
Validation loss: 2.4709821822397444

Epoch: 6| Step: 6
Training loss: 2.482492465404436
Validation loss: 2.4692864378445663

Epoch: 6| Step: 7
Training loss: 2.857856722615231
Validation loss: 2.47028970790308

Epoch: 6| Step: 8
Training loss: 2.2457810159320957
Validation loss: 2.474014624239667

Epoch: 6| Step: 9
Training loss: 2.7152986214030963
Validation loss: 2.474829114287064

Epoch: 6| Step: 10
Training loss: 2.382787285343025
Validation loss: 2.463987109914314

Epoch: 6| Step: 11
Training loss: 2.5709704452709183
Validation loss: 2.4680199650297485

Epoch: 6| Step: 12
Training loss: 2.3674139034161077
Validation loss: 2.4801070943392105

Epoch: 6| Step: 13
Training loss: 2.411814905640274
Validation loss: 2.4639592263772285

Epoch: 129| Step: 0
Training loss: 2.826222322405232
Validation loss: 2.4685945743614384

Epoch: 6| Step: 1
Training loss: 2.9727396608698506
Validation loss: 2.466560181260977

Epoch: 6| Step: 2
Training loss: 2.307140531964756
Validation loss: 2.4664406578379436

Epoch: 6| Step: 3
Training loss: 2.171540817787091
Validation loss: 2.4650723391139286

Epoch: 6| Step: 4
Training loss: 2.9600972213759396
Validation loss: 2.482948789542933

Epoch: 6| Step: 5
Training loss: 2.59160838128036
Validation loss: 2.4756869624665208

Epoch: 6| Step: 6
Training loss: 2.165971815734262
Validation loss: 2.4835001686771467

Epoch: 6| Step: 7
Training loss: 2.2262534479182006
Validation loss: 2.471740167270478

Epoch: 6| Step: 8
Training loss: 2.7375405434867783
Validation loss: 2.483693667219175

Epoch: 6| Step: 9
Training loss: 2.8632952389238766
Validation loss: 2.4818858186410275

Epoch: 6| Step: 10
Training loss: 2.6569878843560324
Validation loss: 2.4674330792278716

Epoch: 6| Step: 11
Training loss: 2.4271418246532694
Validation loss: 2.4688339058182143

Epoch: 6| Step: 12
Training loss: 1.9912375185971034
Validation loss: 2.4680070523707913

Epoch: 6| Step: 13
Training loss: 2.2264410688515532
Validation loss: 2.467606855254087

Epoch: 130| Step: 0
Training loss: 2.660348221494121
Validation loss: 2.4668445074134486

Epoch: 6| Step: 1
Training loss: 2.8408100735141195
Validation loss: 2.4654801519963407

Epoch: 6| Step: 2
Training loss: 2.499781408290213
Validation loss: 2.464646159704385

Epoch: 6| Step: 3
Training loss: 2.5760530411134557
Validation loss: 2.469044808599296

Epoch: 6| Step: 4
Training loss: 2.2091096796978675
Validation loss: 2.4810172848666343

Epoch: 6| Step: 5
Training loss: 2.880496865433542
Validation loss: 2.4750649530384115

Epoch: 6| Step: 6
Training loss: 2.1457340501452262
Validation loss: 2.4680232012341863

Epoch: 6| Step: 7
Training loss: 3.052936491129822
Validation loss: 2.4676671610970033

Epoch: 6| Step: 8
Training loss: 2.6070176857837497
Validation loss: 2.4670779042204893

Epoch: 6| Step: 9
Training loss: 2.8417962038229447
Validation loss: 2.4814856659941977

Epoch: 6| Step: 10
Training loss: 2.17063132705008
Validation loss: 2.476534661779372

Epoch: 6| Step: 11
Training loss: 2.6307257014400114
Validation loss: 2.476120453061042

Epoch: 6| Step: 12
Training loss: 1.9586605515593407
Validation loss: 2.472166039927403

Epoch: 6| Step: 13
Training loss: 1.5307378106934806
Validation loss: 2.4625723358606155

Epoch: 131| Step: 0
Training loss: 2.3381761521548925
Validation loss: 2.457771080720587

Epoch: 6| Step: 1
Training loss: 2.6288580018557295
Validation loss: 2.470763676922894

Epoch: 6| Step: 2
Training loss: 2.3623706923524805
Validation loss: 2.4749372988121445

Epoch: 6| Step: 3
Training loss: 2.897867563152985
Validation loss: 2.4682559875160135

Epoch: 6| Step: 4
Training loss: 2.614258177297322
Validation loss: 2.4617063259923815

Epoch: 6| Step: 5
Training loss: 2.1988605322713988
Validation loss: 2.4611319813251264

Epoch: 6| Step: 6
Training loss: 2.5579987045117782
Validation loss: 2.4707054570404425

Epoch: 6| Step: 7
Training loss: 2.505253612296821
Validation loss: 2.47642014472403

Epoch: 6| Step: 8
Training loss: 3.3781373312246026
Validation loss: 2.4716536592007063

Epoch: 6| Step: 9
Training loss: 1.6071544994961917
Validation loss: 2.4774870806272813

Epoch: 6| Step: 10
Training loss: 2.608734783279939
Validation loss: 2.4719835504295244

Epoch: 6| Step: 11
Training loss: 2.2267070522567227
Validation loss: 2.4700409375014507

Epoch: 6| Step: 12
Training loss: 2.451581530135469
Validation loss: 2.477707262335381

Epoch: 6| Step: 13
Training loss: 2.8032682010131538
Validation loss: 2.468268762031968

Epoch: 132| Step: 0
Training loss: 2.7219964299231107
Validation loss: 2.4663510477201767

Epoch: 6| Step: 1
Training loss: 2.3903243929287457
Validation loss: 2.4700253085848827

Epoch: 6| Step: 2
Training loss: 2.4121831102722924
Validation loss: 2.469072699078947

Epoch: 6| Step: 3
Training loss: 2.917561657147008
Validation loss: 2.4683465265783906

Epoch: 6| Step: 4
Training loss: 3.0176937932928394
Validation loss: 2.469597827818854

Epoch: 6| Step: 5
Training loss: 2.4052010764211746
Validation loss: 2.46247173299557

Epoch: 6| Step: 6
Training loss: 2.3035126358589855
Validation loss: 2.463509353092422

Epoch: 6| Step: 7
Training loss: 2.5917070915119553
Validation loss: 2.4656292146969845

Epoch: 6| Step: 8
Training loss: 2.570550878538068
Validation loss: 2.4628585180074976

Epoch: 6| Step: 9
Training loss: 2.496851559792733
Validation loss: 2.466907852104872

Epoch: 6| Step: 10
Training loss: 2.8038384897840376
Validation loss: 2.4587795585351477

Epoch: 6| Step: 11
Training loss: 1.9077752686912781
Validation loss: 2.469042120925353

Epoch: 6| Step: 12
Training loss: 2.4644851544630177
Validation loss: 2.465131900990535

Epoch: 6| Step: 13
Training loss: 2.2544449240191677
Validation loss: 2.4637388805033322

Epoch: 133| Step: 0
Training loss: 2.691830450769457
Validation loss: 2.4693175359650446

Epoch: 6| Step: 1
Training loss: 2.4961607062921574
Validation loss: 2.469123675237856

Epoch: 6| Step: 2
Training loss: 2.4450995501825146
Validation loss: 2.4629362033031925

Epoch: 6| Step: 3
Training loss: 2.4504304896912195
Validation loss: 2.4843245207258624

Epoch: 6| Step: 4
Training loss: 2.2692355096212955
Validation loss: 2.4750397630830423

Epoch: 6| Step: 5
Training loss: 2.8338881304728942
Validation loss: 2.4811280343085556

Epoch: 6| Step: 6
Training loss: 2.5286276149126192
Validation loss: 2.4680246341790744

Epoch: 6| Step: 7
Training loss: 2.9299330951746505
Validation loss: 2.472311557329625

Epoch: 6| Step: 8
Training loss: 2.258499410605971
Validation loss: 2.470950260794374

Epoch: 6| Step: 9
Training loss: 2.60885660652833
Validation loss: 2.4709368970844587

Epoch: 6| Step: 10
Training loss: 2.300636792141043
Validation loss: 2.4590830440990543

Epoch: 6| Step: 11
Training loss: 3.0094496990055717
Validation loss: 2.474796263018826

Epoch: 6| Step: 12
Training loss: 2.267571185591772
Validation loss: 2.470141730778924

Epoch: 6| Step: 13
Training loss: 2.096191121902642
Validation loss: 2.4680265018363317

Epoch: 134| Step: 0
Training loss: 2.857605934081799
Validation loss: 2.459902736555325

Epoch: 6| Step: 1
Training loss: 3.1836222079824705
Validation loss: 2.47065424814241

Epoch: 6| Step: 2
Training loss: 2.7442492263318843
Validation loss: 2.474628997379697

Epoch: 6| Step: 3
Training loss: 2.117200112393245
Validation loss: 2.467020837599683

Epoch: 6| Step: 4
Training loss: 2.8437912487350117
Validation loss: 2.4637027604470703

Epoch: 6| Step: 5
Training loss: 2.4729593823371734
Validation loss: 2.4716131773357084

Epoch: 6| Step: 6
Training loss: 2.209200442917044
Validation loss: 2.473078189021544

Epoch: 6| Step: 7
Training loss: 2.6224661814179155
Validation loss: 2.4691964321249946

Epoch: 6| Step: 8
Training loss: 2.623177395184406
Validation loss: 2.4711371682624343

Epoch: 6| Step: 9
Training loss: 2.667326775944258
Validation loss: 2.4685807954771963

Epoch: 6| Step: 10
Training loss: 2.586552757068778
Validation loss: 2.480497857671447

Epoch: 6| Step: 11
Training loss: 1.9147497072320483
Validation loss: 2.4718525058833665

Epoch: 6| Step: 12
Training loss: 1.8985773356863578
Validation loss: 2.4703475837058004

Epoch: 6| Step: 13
Training loss: 2.267036156364767
Validation loss: 2.4745797966180687

Epoch: 135| Step: 0
Training loss: 2.55569102324454
Validation loss: 2.4806853032136953

Epoch: 6| Step: 1
Training loss: 2.1888516201304076
Validation loss: 2.480272564676445

Epoch: 6| Step: 2
Training loss: 2.6345891645991304
Validation loss: 2.481044640358447

Epoch: 6| Step: 3
Training loss: 2.327732027414018
Validation loss: 2.4763224713065926

Epoch: 6| Step: 4
Training loss: 2.605137931261924
Validation loss: 2.4748080484213246

Epoch: 6| Step: 5
Training loss: 2.099289923917577
Validation loss: 2.46982243740092

Epoch: 6| Step: 6
Training loss: 2.43577377620644
Validation loss: 2.4699284762736164

Epoch: 6| Step: 7
Training loss: 2.545165254515024
Validation loss: 2.4765244730728506

Epoch: 6| Step: 8
Training loss: 2.2826919179162926
Validation loss: 2.4648793777655733

Epoch: 6| Step: 9
Training loss: 3.0829702283799545
Validation loss: 2.4676281919357437

Epoch: 6| Step: 10
Training loss: 2.3888915515362394
Validation loss: 2.4689296383427206

Epoch: 6| Step: 11
Training loss: 2.574765415061426
Validation loss: 2.4667374177614874

Epoch: 6| Step: 12
Training loss: 2.8992004213033877
Validation loss: 2.465101838139323

Epoch: 6| Step: 13
Training loss: 2.223391124807345
Validation loss: 2.459677091898057

Epoch: 136| Step: 0
Training loss: 2.7792202690327534
Validation loss: 2.4660663343517495

Epoch: 6| Step: 1
Training loss: 1.7918810235658382
Validation loss: 2.4702928446197476

Epoch: 6| Step: 2
Training loss: 2.3945716742484016
Validation loss: 2.4569819879571595

Epoch: 6| Step: 3
Training loss: 1.7192463244894927
Validation loss: 2.4625421530121954

Epoch: 6| Step: 4
Training loss: 2.210100642368069
Validation loss: 2.473944916270498

Epoch: 6| Step: 5
Training loss: 2.607678804347473
Validation loss: 2.470966905025151

Epoch: 6| Step: 6
Training loss: 2.6503051654078624
Validation loss: 2.479203397548211

Epoch: 6| Step: 7
Training loss: 2.4661839343588303
Validation loss: 2.46559238903815

Epoch: 6| Step: 8
Training loss: 2.788835703286505
Validation loss: 2.4814662179337765

Epoch: 6| Step: 9
Training loss: 2.6188016098872864
Validation loss: 2.4738535219711264

Epoch: 6| Step: 10
Training loss: 2.570751396204788
Validation loss: 2.4682819711500157

Epoch: 6| Step: 11
Training loss: 3.200498816236227
Validation loss: 2.4683765418627925

Epoch: 6| Step: 12
Training loss: 2.395507314863126
Validation loss: 2.4836378303416704

Epoch: 6| Step: 13
Training loss: 2.3151549486412915
Validation loss: 2.4786742279634404

Epoch: 137| Step: 0
Training loss: 2.232951317563571
Validation loss: 2.478556651443964

Epoch: 6| Step: 1
Training loss: 2.0675530235198125
Validation loss: 2.4679243743310693

Epoch: 6| Step: 2
Training loss: 2.5495437026825853
Validation loss: 2.4749390087254906

Epoch: 6| Step: 3
Training loss: 2.7462144285250134
Validation loss: 2.468909407350232

Epoch: 6| Step: 4
Training loss: 2.527302147642283
Validation loss: 2.471118933225429

Epoch: 6| Step: 5
Training loss: 2.227283561800506
Validation loss: 2.4779151247168447

Epoch: 6| Step: 6
Training loss: 2.648793514482951
Validation loss: 2.4711031101213154

Epoch: 6| Step: 7
Training loss: 2.8922495632839014
Validation loss: 2.474983851383329

Epoch: 6| Step: 8
Training loss: 2.482164178974279
Validation loss: 2.4700375671979033

Epoch: 6| Step: 9
Training loss: 2.60413313780499
Validation loss: 2.4688088293349497

Epoch: 6| Step: 10
Training loss: 2.760129997674918
Validation loss: 2.471821544147978

Epoch: 6| Step: 11
Training loss: 2.787051376028011
Validation loss: 2.47925757126612

Epoch: 6| Step: 12
Training loss: 2.0789724357359347
Validation loss: 2.4767740522295996

Epoch: 6| Step: 13
Training loss: 2.1056857023833544
Validation loss: 2.4723874910764474

Epoch: 138| Step: 0
Training loss: 2.647989150725206
Validation loss: 2.4722324227064294

Epoch: 6| Step: 1
Training loss: 1.8496537812490454
Validation loss: 2.4777328982753004

Epoch: 6| Step: 2
Training loss: 3.551737942874721
Validation loss: 2.4735970377201917

Epoch: 6| Step: 3
Training loss: 2.4866120445279467
Validation loss: 2.4678886778149947

Epoch: 6| Step: 4
Training loss: 2.5838996717622202
Validation loss: 2.4709738682304643

Epoch: 6| Step: 5
Training loss: 2.359425121052895
Validation loss: 2.472125976334445

Epoch: 6| Step: 6
Training loss: 2.136736826148974
Validation loss: 2.469552163286245

Epoch: 6| Step: 7
Training loss: 2.3617270158780155
Validation loss: 2.470750119210927

Epoch: 6| Step: 8
Training loss: 2.573721251510127
Validation loss: 2.472035567658392

Epoch: 6| Step: 9
Training loss: 2.9412642364870742
Validation loss: 2.478816181273393

Epoch: 6| Step: 10
Training loss: 2.5500878038436268
Validation loss: 2.472592787407806

Epoch: 6| Step: 11
Training loss: 1.6893599820783762
Validation loss: 2.4695419296810903

Epoch: 6| Step: 12
Training loss: 2.5955388897675755
Validation loss: 2.482531905518255

Epoch: 6| Step: 13
Training loss: 2.055596096337823
Validation loss: 2.461662258418877

Epoch: 139| Step: 0
Training loss: 2.6246651935503817
Validation loss: 2.470393828682529

Epoch: 6| Step: 1
Training loss: 2.4458504472054736
Validation loss: 2.4757802632423074

Epoch: 6| Step: 2
Training loss: 2.30823711603288
Validation loss: 2.465085202666767

Epoch: 6| Step: 3
Training loss: 2.677443384877378
Validation loss: 2.4758058308610655

Epoch: 6| Step: 4
Training loss: 2.0038342676749368
Validation loss: 2.473579487487492

Epoch: 6| Step: 5
Training loss: 2.281132838754827
Validation loss: 2.478604675088052

Epoch: 6| Step: 6
Training loss: 2.2948936168473004
Validation loss: 2.4805305693524815

Epoch: 6| Step: 7
Training loss: 2.524963484396196
Validation loss: 2.483858594665825

Epoch: 6| Step: 8
Training loss: 3.026279109671444
Validation loss: 2.479900000540355

Epoch: 6| Step: 9
Training loss: 2.942764434729791
Validation loss: 2.4852224060354295

Epoch: 6| Step: 10
Training loss: 2.2947843210105945
Validation loss: 2.4835765363239295

Epoch: 6| Step: 11
Training loss: 2.213610431874589
Validation loss: 2.4744214450979882

Epoch: 6| Step: 12
Training loss: 2.317226837091823
Validation loss: 2.483222710195807

Epoch: 6| Step: 13
Training loss: 3.1670295273199622
Validation loss: 2.4760985636857407

Epoch: 140| Step: 0
Training loss: 3.1847627143561152
Validation loss: 2.4828829013325073

Epoch: 6| Step: 1
Training loss: 2.297530722926361
Validation loss: 2.4779295252142477

Epoch: 6| Step: 2
Training loss: 2.7202169034529313
Validation loss: 2.4755425584191464

Epoch: 6| Step: 3
Training loss: 2.6950435780698077
Validation loss: 2.4741274859507256

Epoch: 6| Step: 4
Training loss: 2.830288223039497
Validation loss: 2.464054599992001

Epoch: 6| Step: 5
Training loss: 2.1048870804824737
Validation loss: 2.465376919706501

Epoch: 6| Step: 6
Training loss: 2.3347845900379465
Validation loss: 2.465983744326122

Epoch: 6| Step: 7
Training loss: 2.2285783175477247
Validation loss: 2.4711490675967447

Epoch: 6| Step: 8
Training loss: 1.9393054179851827
Validation loss: 2.460025840509842

Epoch: 6| Step: 9
Training loss: 2.8245677178399484
Validation loss: 2.4676867420630884

Epoch: 6| Step: 10
Training loss: 2.3244546722436703
Validation loss: 2.4598648317025655

Epoch: 6| Step: 11
Training loss: 2.3250183268819438
Validation loss: 2.4686597091323685

Epoch: 6| Step: 12
Training loss: 2.408748765993619
Validation loss: 2.4588344569683214

Epoch: 6| Step: 13
Training loss: 2.734192498792446
Validation loss: 2.473340301949417

Epoch: 141| Step: 0
Training loss: 2.1161743217226254
Validation loss: 2.4716207014179696

Epoch: 6| Step: 1
Training loss: 2.094769471624911
Validation loss: 2.469841985191271

Epoch: 6| Step: 2
Training loss: 2.3082241014143
Validation loss: 2.474538527600832

Epoch: 6| Step: 3
Training loss: 3.019684742015648
Validation loss: 2.475308603255503

Epoch: 6| Step: 4
Training loss: 2.3466732868007276
Validation loss: 2.4755820691281003

Epoch: 6| Step: 5
Training loss: 2.411949343913292
Validation loss: 2.4752630280238943

Epoch: 6| Step: 6
Training loss: 2.2098642716651464
Validation loss: 2.478572298709114

Epoch: 6| Step: 7
Training loss: 2.2100989163386378
Validation loss: 2.4809147471364676

Epoch: 6| Step: 8
Training loss: 2.269069394835491
Validation loss: 2.481987499747612

Epoch: 6| Step: 9
Training loss: 2.981027853184603
Validation loss: 2.4813392533425223

Epoch: 6| Step: 10
Training loss: 2.8029688933079164
Validation loss: 2.476513337651168

Epoch: 6| Step: 11
Training loss: 2.421907486236253
Validation loss: 2.477734277492575

Epoch: 6| Step: 12
Training loss: 2.745458667839304
Validation loss: 2.4741859786386082

Epoch: 6| Step: 13
Training loss: 2.6117225183658874
Validation loss: 2.4712738785131156

Epoch: 142| Step: 0
Training loss: 2.0575094244591643
Validation loss: 2.4814764904358975

Epoch: 6| Step: 1
Training loss: 2.167347752065032
Validation loss: 2.4787106107864325

Epoch: 6| Step: 2
Training loss: 2.06213075049006
Validation loss: 2.481362665855056

Epoch: 6| Step: 3
Training loss: 2.802683674955194
Validation loss: 2.4788443946274397

Epoch: 6| Step: 4
Training loss: 1.8009761282838919
Validation loss: 2.484148954908242

Epoch: 6| Step: 5
Training loss: 2.1838645153011225
Validation loss: 2.4820073199536923

Epoch: 6| Step: 6
Training loss: 2.484903147477533
Validation loss: 2.4852064009107915

Epoch: 6| Step: 7
Training loss: 2.51109693076857
Validation loss: 2.4742775854951318

Epoch: 6| Step: 8
Training loss: 2.511158265127774
Validation loss: 2.4813674700368784

Epoch: 6| Step: 9
Training loss: 2.147290176603773
Validation loss: 2.4773942290823

Epoch: 6| Step: 10
Training loss: 3.423834949232004
Validation loss: 2.4882982573833754

Epoch: 6| Step: 11
Training loss: 2.44855759258593
Validation loss: 2.479164337242592

Epoch: 6| Step: 12
Training loss: 2.2462685691138145
Validation loss: 2.4810139534980835

Epoch: 6| Step: 13
Training loss: 3.4072840809579716
Validation loss: 2.486667335227215

Epoch: 143| Step: 0
Training loss: 2.4977180556834786
Validation loss: 2.4838145201618445

Epoch: 6| Step: 1
Training loss: 2.611034664991936
Validation loss: 2.490992627359978

Epoch: 6| Step: 2
Training loss: 2.740166334964709
Validation loss: 2.482515594930284

Epoch: 6| Step: 3
Training loss: 2.1194236742132118
Validation loss: 2.4853532812366153

Epoch: 6| Step: 4
Training loss: 2.807022950021867
Validation loss: 2.4831299290998987

Epoch: 6| Step: 5
Training loss: 2.5520222144041966
Validation loss: 2.481396479090467

Epoch: 6| Step: 6
Training loss: 2.063816459597667
Validation loss: 2.4763828216419452

Epoch: 6| Step: 7
Training loss: 2.7044944160955287
Validation loss: 2.4807008649701445

Epoch: 6| Step: 8
Training loss: 2.8405480436302053
Validation loss: 2.4823881957868124

Epoch: 6| Step: 9
Training loss: 2.2154301265785734
Validation loss: 2.477584371326642

Epoch: 6| Step: 10
Training loss: 2.1164991097199435
Validation loss: 2.483411382135658

Epoch: 6| Step: 11
Training loss: 2.883754834657609
Validation loss: 2.4798701487663486

Epoch: 6| Step: 12
Training loss: 2.0847905466821257
Validation loss: 2.497717785228876

Epoch: 6| Step: 13
Training loss: 2.2292516698109113
Validation loss: 2.4936058926991334

Epoch: 144| Step: 0
Training loss: 2.3785546454807562
Validation loss: 2.5098577064414744

Epoch: 6| Step: 1
Training loss: 1.847392992939328
Validation loss: 2.5001539977644653

Epoch: 6| Step: 2
Training loss: 2.415767228256262
Validation loss: 2.4985880679338552

Epoch: 6| Step: 3
Training loss: 2.4333563577093957
Validation loss: 2.490153887077526

Epoch: 6| Step: 4
Training loss: 2.994674246877224
Validation loss: 2.482566231032664

Epoch: 6| Step: 5
Training loss: 2.548871153252708
Validation loss: 2.4793310404762905

Epoch: 6| Step: 6
Training loss: 2.2484116776118834
Validation loss: 2.477608781614744

Epoch: 6| Step: 7
Training loss: 2.594118574680887
Validation loss: 2.4757946440572245

Epoch: 6| Step: 8
Training loss: 2.249031388222757
Validation loss: 2.476939079462622

Epoch: 6| Step: 9
Training loss: 2.653351312876732
Validation loss: 2.4801044026313193

Epoch: 6| Step: 10
Training loss: 2.399019251547018
Validation loss: 2.4822230585829783

Epoch: 6| Step: 11
Training loss: 3.053952492095221
Validation loss: 2.474149713977447

Epoch: 6| Step: 12
Training loss: 2.58543875226576
Validation loss: 2.4750095155321095

Epoch: 6| Step: 13
Training loss: 2.119444710145564
Validation loss: 2.477983919211061

Epoch: 145| Step: 0
Training loss: 2.2457553243683317
Validation loss: 2.476194304203037

Epoch: 6| Step: 1
Training loss: 2.3789245905427547
Validation loss: 2.478585124262619

Epoch: 6| Step: 2
Training loss: 3.0760168611736525
Validation loss: 2.4776404568928894

Epoch: 6| Step: 3
Training loss: 2.4900024784795844
Validation loss: 2.4665494519384006

Epoch: 6| Step: 4
Training loss: 2.4451719005980177
Validation loss: 2.4779800225110176

Epoch: 6| Step: 5
Training loss: 2.4060060451745553
Validation loss: 2.477471843524841

Epoch: 6| Step: 6
Training loss: 2.5852038676815385
Validation loss: 2.4797924651709473

Epoch: 6| Step: 7
Training loss: 2.055590297073176
Validation loss: 2.4852307203452106

Epoch: 6| Step: 8
Training loss: 2.910004682242176
Validation loss: 2.481476330303689

Epoch: 6| Step: 9
Training loss: 2.6219588328838976
Validation loss: 2.4804967523230745

Epoch: 6| Step: 10
Training loss: 2.541629092663135
Validation loss: 2.475909671520331

Epoch: 6| Step: 11
Training loss: 2.624087038678416
Validation loss: 2.4867417839694097

Epoch: 6| Step: 12
Training loss: 1.5861544906925416
Validation loss: 2.480381985646248

Epoch: 6| Step: 13
Training loss: 2.4587024045292845
Validation loss: 2.488952761695709

Epoch: 146| Step: 0
Training loss: 2.0682633533468624
Validation loss: 2.4777766960675778

Epoch: 6| Step: 1
Training loss: 2.6258207582079627
Validation loss: 2.4784784136364344

Epoch: 6| Step: 2
Training loss: 1.9104904787315038
Validation loss: 2.4814920712503894

Epoch: 6| Step: 3
Training loss: 2.5541384045612214
Validation loss: 2.4652396970741925

Epoch: 6| Step: 4
Training loss: 2.183812985136945
Validation loss: 2.4790925300690256

Epoch: 6| Step: 5
Training loss: 3.2180838775229956
Validation loss: 2.481670931352786

Epoch: 6| Step: 6
Training loss: 2.084691850866124
Validation loss: 2.4675413947738107

Epoch: 6| Step: 7
Training loss: 2.2280792959268725
Validation loss: 2.474627214993203

Epoch: 6| Step: 8
Training loss: 2.3135765250538554
Validation loss: 2.478430507792581

Epoch: 6| Step: 9
Training loss: 1.9237683901735056
Validation loss: 2.4778471221281864

Epoch: 6| Step: 10
Training loss: 2.7736279059584885
Validation loss: 2.47109852719114

Epoch: 6| Step: 11
Training loss: 2.747498328058291
Validation loss: 2.4698694161917443

Epoch: 6| Step: 12
Training loss: 2.617533464481993
Validation loss: 2.473150604632227

Epoch: 6| Step: 13
Training loss: 2.850793186036262
Validation loss: 2.4689091578819076

Epoch: 147| Step: 0
Training loss: 2.415694984123024
Validation loss: 2.485903207928836

Epoch: 6| Step: 1
Training loss: 2.7830843930266465
Validation loss: 2.4766232536236727

Epoch: 6| Step: 2
Training loss: 2.3454280695183702
Validation loss: 2.476629166051774

Epoch: 6| Step: 3
Training loss: 2.6362823351219564
Validation loss: 2.4800027885216243

Epoch: 6| Step: 4
Training loss: 1.996975041660912
Validation loss: 2.4729595671234375

Epoch: 6| Step: 5
Training loss: 1.8541174535613842
Validation loss: 2.4825188122382604

Epoch: 6| Step: 6
Training loss: 2.765510858454101
Validation loss: 2.4863916844956355

Epoch: 6| Step: 7
Training loss: 2.908694316099875
Validation loss: 2.4819521495849153

Epoch: 6| Step: 8
Training loss: 2.49521445963768
Validation loss: 2.4777339166509202

Epoch: 6| Step: 9
Training loss: 3.090919972721875
Validation loss: 2.474900820379337

Epoch: 6| Step: 10
Training loss: 2.4767157570383627
Validation loss: 2.478372548179384

Epoch: 6| Step: 11
Training loss: 2.0061672015350904
Validation loss: 2.4816520051371502

Epoch: 6| Step: 12
Training loss: 2.387064457656329
Validation loss: 2.4795809701472296

Epoch: 6| Step: 13
Training loss: 2.0031907140751195
Validation loss: 2.4823633202570754

Epoch: 148| Step: 0
Training loss: 2.0684212737506704
Validation loss: 2.485992776610626

Epoch: 6| Step: 1
Training loss: 2.4879498942318947
Validation loss: 2.4872636455918586

Epoch: 6| Step: 2
Training loss: 2.555047526057509
Validation loss: 2.496091736189259

Epoch: 6| Step: 3
Training loss: 2.615451886317375
Validation loss: 2.499499207246923

Epoch: 6| Step: 4
Training loss: 2.058271524013521
Validation loss: 2.4900888358078195

Epoch: 6| Step: 5
Training loss: 1.8957261554758313
Validation loss: 2.4969239384100836

Epoch: 6| Step: 6
Training loss: 2.8844637806496864
Validation loss: 2.495424661522164

Epoch: 6| Step: 7
Training loss: 2.895252050519118
Validation loss: 2.503575787729299

Epoch: 6| Step: 8
Training loss: 2.3800360841980863
Validation loss: 2.484290259493505

Epoch: 6| Step: 9
Training loss: 2.7192729578531694
Validation loss: 2.483350306544661

Epoch: 6| Step: 10
Training loss: 2.6799005807399174
Validation loss: 2.471836430264385

Epoch: 6| Step: 11
Training loss: 1.8267962199349717
Validation loss: 2.481334192879863

Epoch: 6| Step: 12
Training loss: 3.075557664375587
Validation loss: 2.4633599362810217

Epoch: 6| Step: 13
Training loss: 2.0772381948313985
Validation loss: 2.4698888751243757

Epoch: 149| Step: 0
Training loss: 2.165420271539125
Validation loss: 2.477059540074205

Epoch: 6| Step: 1
Training loss: 2.556692847060238
Validation loss: 2.492243703369856

Epoch: 6| Step: 2
Training loss: 2.8766272542234614
Validation loss: 2.483602935655632

Epoch: 6| Step: 3
Training loss: 1.8586216530423063
Validation loss: 2.474644532991396

Epoch: 6| Step: 4
Training loss: 2.370133081232762
Validation loss: 2.479359103729547

Epoch: 6| Step: 5
Training loss: 2.7630708613826704
Validation loss: 2.471885251595852

Epoch: 6| Step: 6
Training loss: 2.358683503734355
Validation loss: 2.477320862833479

Epoch: 6| Step: 7
Training loss: 2.7003707525227574
Validation loss: 2.4737956318141126

Epoch: 6| Step: 8
Training loss: 1.9284172046899597
Validation loss: 2.4788311375970946

Epoch: 6| Step: 9
Training loss: 2.2550352762850605
Validation loss: 2.482458194894161

Epoch: 6| Step: 10
Training loss: 2.1130911411933915
Validation loss: 2.4787589520632447

Epoch: 6| Step: 11
Training loss: 2.8146413492641993
Validation loss: 2.4824585310387826

Epoch: 6| Step: 12
Training loss: 3.2089552503623553
Validation loss: 2.482607046484796

Epoch: 6| Step: 13
Training loss: 2.5268702350866854
Validation loss: 2.4873254558213893

Epoch: 150| Step: 0
Training loss: 2.8007759721990895
Validation loss: 2.4824085250243413

Epoch: 6| Step: 1
Training loss: 2.491827768414464
Validation loss: 2.4952705948284257

Epoch: 6| Step: 2
Training loss: 2.492000943558761
Validation loss: 2.4924942513427966

Epoch: 6| Step: 3
Training loss: 2.698525987156124
Validation loss: 2.4824530726847733

Epoch: 6| Step: 4
Training loss: 2.447785123713137
Validation loss: 2.486407713953471

Epoch: 6| Step: 5
Training loss: 2.604522212870611
Validation loss: 2.486293188160783

Epoch: 6| Step: 6
Training loss: 2.267009969500078
Validation loss: 2.4903543839802094

Epoch: 6| Step: 7
Training loss: 2.37560997207252
Validation loss: 2.4915831340281627

Epoch: 6| Step: 8
Training loss: 2.6073784413809915
Validation loss: 2.4915395789338284

Epoch: 6| Step: 9
Training loss: 2.3526202386173805
Validation loss: 2.4793225621379853

Epoch: 6| Step: 10
Training loss: 2.074826253947502
Validation loss: 2.4949361378377675

Epoch: 6| Step: 11
Training loss: 2.4058891124841613
Validation loss: 2.4867148107397017

Epoch: 6| Step: 12
Training loss: 2.760708334046947
Validation loss: 2.4928404173001697

Epoch: 6| Step: 13
Training loss: 2.072792381765249
Validation loss: 2.507957256255073

Testing loss: 2.002938100425307
