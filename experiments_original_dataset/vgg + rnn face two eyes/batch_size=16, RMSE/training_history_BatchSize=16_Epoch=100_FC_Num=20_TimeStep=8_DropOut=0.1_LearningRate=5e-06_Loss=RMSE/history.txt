Epoch: 1| Step: 0
Training loss: 6.892007217695693
Validation loss: 5.8847205726577805

Epoch: 6| Step: 1
Training loss: 5.364473903490487
Validation loss: 5.88291103623313

Epoch: 6| Step: 2
Training loss: 6.235504430511591
Validation loss: 5.8813227725686925

Epoch: 6| Step: 3
Training loss: 7.012982454890191
Validation loss: 5.879740567744629

Epoch: 6| Step: 4
Training loss: 5.91991446459038
Validation loss: 5.8782848076168985

Epoch: 6| Step: 5
Training loss: 6.437568441971577
Validation loss: 5.8768807234846605

Epoch: 6| Step: 6
Training loss: 4.697476768903148
Validation loss: 5.875505899061425

Epoch: 6| Step: 7
Training loss: 5.243017185006217
Validation loss: 5.874231734669242

Epoch: 6| Step: 8
Training loss: 6.328089735144795
Validation loss: 5.872878320556829

Epoch: 6| Step: 9
Training loss: 6.048070981532562
Validation loss: 5.871566932748692

Epoch: 6| Step: 10
Training loss: 6.16617028927818
Validation loss: 5.870245693985173

Epoch: 6| Step: 11
Training loss: 5.158368224650976
Validation loss: 5.868829259584357

Epoch: 6| Step: 12
Training loss: 5.63063546912183
Validation loss: 5.867334112578135

Epoch: 6| Step: 13
Training loss: 6.276716883467429
Validation loss: 5.865815931466804

Epoch: 2| Step: 0
Training loss: 5.127771512063661
Validation loss: 5.864199213036389

Epoch: 6| Step: 1
Training loss: 6.356502849759757
Validation loss: 5.8625951166848385

Epoch: 6| Step: 2
Training loss: 5.547766557420632
Validation loss: 5.86088332365837

Epoch: 6| Step: 3
Training loss: 5.508991521081304
Validation loss: 5.859086798467758

Epoch: 6| Step: 4
Training loss: 6.312794593508804
Validation loss: 5.857250537170484

Epoch: 6| Step: 5
Training loss: 6.200486859310361
Validation loss: 5.855227346026907

Epoch: 6| Step: 6
Training loss: 5.762428121056418
Validation loss: 5.8531670129791955

Epoch: 6| Step: 7
Training loss: 6.127187221579819
Validation loss: 5.851053145292501

Epoch: 6| Step: 8
Training loss: 6.046632431645547
Validation loss: 5.848847802313206

Epoch: 6| Step: 9
Training loss: 5.362022524475118
Validation loss: 5.846449746849425

Epoch: 6| Step: 10
Training loss: 6.838538009824644
Validation loss: 5.844097351521871

Epoch: 6| Step: 11
Training loss: 5.272689472409781
Validation loss: 5.841544348741714

Epoch: 6| Step: 12
Training loss: 6.223738160222658
Validation loss: 5.838942238107938

Epoch: 6| Step: 13
Training loss: 6.568697664032411
Validation loss: 5.836043772651166

Epoch: 3| Step: 0
Training loss: 5.837314591332524
Validation loss: 5.833053672989607

Epoch: 6| Step: 1
Training loss: 7.0952582415413294
Validation loss: 5.829897122792246

Epoch: 6| Step: 2
Training loss: 5.977114583365102
Validation loss: 5.826669356100362

Epoch: 6| Step: 3
Training loss: 5.146605563682241
Validation loss: 5.823312308075711

Epoch: 6| Step: 4
Training loss: 6.718487969545218
Validation loss: 5.8197906874676395

Epoch: 6| Step: 5
Training loss: 5.867650731234756
Validation loss: 5.815997066413108

Epoch: 6| Step: 6
Training loss: 5.523600488224653
Validation loss: 5.812003193067884

Epoch: 6| Step: 7
Training loss: 5.730617861897752
Validation loss: 5.808154050376108

Epoch: 6| Step: 8
Training loss: 5.605545309255053
Validation loss: 5.80405307210419

Epoch: 6| Step: 9
Training loss: 5.603658924949659
Validation loss: 5.799700546207496

Epoch: 6| Step: 10
Training loss: 6.009047997554526
Validation loss: 5.795440688317835

Epoch: 6| Step: 11
Training loss: 5.909722170423225
Validation loss: 5.790822175661541

Epoch: 6| Step: 12
Training loss: 5.275728307407801
Validation loss: 5.7861503384052435

Epoch: 6| Step: 13
Training loss: 6.360600983637228
Validation loss: 5.781375808034275

Epoch: 4| Step: 0
Training loss: 6.277212486959901
Validation loss: 5.776475078900471

Epoch: 6| Step: 1
Training loss: 6.998061592923401
Validation loss: 5.771175011757751

Epoch: 6| Step: 2
Training loss: 5.457237813176236
Validation loss: 5.7661017657564

Epoch: 6| Step: 3
Training loss: 4.633028639693554
Validation loss: 5.760637533174163

Epoch: 6| Step: 4
Training loss: 6.595729440371697
Validation loss: 5.7553698578919485

Epoch: 6| Step: 5
Training loss: 5.091635048492872
Validation loss: 5.749800720078712

Epoch: 6| Step: 6
Training loss: 5.971344868092229
Validation loss: 5.744471725818841

Epoch: 6| Step: 7
Training loss: 6.455951801219396
Validation loss: 5.738979725561441

Epoch: 6| Step: 8
Training loss: 4.761597379118701
Validation loss: 5.73324953653769

Epoch: 6| Step: 9
Training loss: 6.342838616509795
Validation loss: 5.727632361061648

Epoch: 6| Step: 10
Training loss: 6.963824939506014
Validation loss: 5.722165003534712

Epoch: 6| Step: 11
Training loss: 4.847983202486556
Validation loss: 5.7160398527037

Epoch: 6| Step: 12
Training loss: 5.235544922311805
Validation loss: 5.710691767675179

Epoch: 6| Step: 13
Training loss: 5.65727738802583
Validation loss: 5.705003597961593

Epoch: 5| Step: 0
Training loss: 5.651757917118437
Validation loss: 5.69908407225175

Epoch: 6| Step: 1
Training loss: 6.023205704440769
Validation loss: 5.693557922495665

Epoch: 6| Step: 2
Training loss: 5.309656257207442
Validation loss: 5.688146309932315

Epoch: 6| Step: 3
Training loss: 5.7789599032591115
Validation loss: 5.682405334883541

Epoch: 6| Step: 4
Training loss: 5.343773557376803
Validation loss: 5.676867765014433

Epoch: 6| Step: 5
Training loss: 5.690589149693156
Validation loss: 5.671390228992941

Epoch: 6| Step: 6
Training loss: 5.746756924468424
Validation loss: 5.665645320327769

Epoch: 6| Step: 7
Training loss: 6.6594723347532385
Validation loss: 5.66025680898459

Epoch: 6| Step: 8
Training loss: 4.579680403173877
Validation loss: 5.654473406858542

Epoch: 6| Step: 9
Training loss: 5.333902129995736
Validation loss: 5.649034481765169

Epoch: 6| Step: 10
Training loss: 6.052548450274473
Validation loss: 5.643381137559055

Epoch: 6| Step: 11
Training loss: 6.6166870936823905
Validation loss: 5.638041403881955

Epoch: 6| Step: 12
Training loss: 5.579488635678806
Validation loss: 5.632312373278524

Epoch: 6| Step: 13
Training loss: 6.233441199255056
Validation loss: 5.6263267082788415

Epoch: 6| Step: 0
Training loss: 5.645204328381718
Validation loss: 5.620573520334862

Epoch: 6| Step: 1
Training loss: 5.855443993860275
Validation loss: 5.614561695441719

Epoch: 6| Step: 2
Training loss: 6.210628554619656
Validation loss: 5.608286604136323

Epoch: 6| Step: 3
Training loss: 6.623362500773334
Validation loss: 5.602232342780286

Epoch: 6| Step: 4
Training loss: 5.179503746858448
Validation loss: 5.5956693514014955

Epoch: 6| Step: 5
Training loss: 5.819920223253004
Validation loss: 5.589073314661618

Epoch: 6| Step: 6
Training loss: 6.491307241392017
Validation loss: 5.5823925800981575

Epoch: 6| Step: 7
Training loss: 5.673208537060882
Validation loss: 5.575342561834509

Epoch: 6| Step: 8
Training loss: 5.8891308252951395
Validation loss: 5.568239001780811

Epoch: 6| Step: 9
Training loss: 5.288751454976368
Validation loss: 5.560875587586769

Epoch: 6| Step: 10
Training loss: 5.370871266698928
Validation loss: 5.553891610930149

Epoch: 6| Step: 11
Training loss: 5.328340498070568
Validation loss: 5.546169870179044

Epoch: 6| Step: 12
Training loss: 5.3950041301948355
Validation loss: 5.5390864893183505

Epoch: 6| Step: 13
Training loss: 4.714752727347352
Validation loss: 5.531566804768138

Epoch: 7| Step: 0
Training loss: 4.829887389455806
Validation loss: 5.5247734357084575

Epoch: 6| Step: 1
Training loss: 5.495074060303706
Validation loss: 5.517563447735825

Epoch: 6| Step: 2
Training loss: 5.247264149214878
Validation loss: 5.5104387808093405

Epoch: 6| Step: 3
Training loss: 5.433777510540676
Validation loss: 5.503835438944475

Epoch: 6| Step: 4
Training loss: 5.515788910675327
Validation loss: 5.496542913378966

Epoch: 6| Step: 5
Training loss: 6.196637429258509
Validation loss: 5.48969436137524

Epoch: 6| Step: 6
Training loss: 5.529235472990049
Validation loss: 5.4823644417840605

Epoch: 6| Step: 7
Training loss: 5.88293991862756
Validation loss: 5.474913547942307

Epoch: 6| Step: 8
Training loss: 4.516364753082477
Validation loss: 5.467546196096879

Epoch: 6| Step: 9
Training loss: 5.620605277866005
Validation loss: 5.460668176095579

Epoch: 6| Step: 10
Training loss: 5.625653546831647
Validation loss: 5.453280179822524

Epoch: 6| Step: 11
Training loss: 5.600096613186809
Validation loss: 5.445620615199359

Epoch: 6| Step: 12
Training loss: 6.792826391640146
Validation loss: 5.438260547752161

Epoch: 6| Step: 13
Training loss: 5.748506103172622
Validation loss: 5.430933235392575

Epoch: 8| Step: 0
Training loss: 5.807171091330474
Validation loss: 5.423608859956246

Epoch: 6| Step: 1
Training loss: 5.644317010423862
Validation loss: 5.416432106612583

Epoch: 6| Step: 2
Training loss: 5.22449510681116
Validation loss: 5.40938437564066

Epoch: 6| Step: 3
Training loss: 5.922606732496469
Validation loss: 5.402562436495175

Epoch: 6| Step: 4
Training loss: 5.28259874084594
Validation loss: 5.3961131589150275

Epoch: 6| Step: 5
Training loss: 4.7460455244463455
Validation loss: 5.3896566359709945

Epoch: 6| Step: 6
Training loss: 6.068023682177806
Validation loss: 5.383192634909082

Epoch: 6| Step: 7
Training loss: 4.45690821512096
Validation loss: 5.377703644676777

Epoch: 6| Step: 8
Training loss: 4.885834611639543
Validation loss: 5.37178845530963

Epoch: 6| Step: 9
Training loss: 5.948788482676207
Validation loss: 5.3659298388993495

Epoch: 6| Step: 10
Training loss: 5.897711177342246
Validation loss: 5.360662811633399

Epoch: 6| Step: 11
Training loss: 5.393051176451165
Validation loss: 5.354671212060172

Epoch: 6| Step: 12
Training loss: 5.422268987846555
Validation loss: 5.349040544937331

Epoch: 6| Step: 13
Training loss: 6.038935217065025
Validation loss: 5.343058996902115

Epoch: 9| Step: 0
Training loss: 5.185085424089225
Validation loss: 5.337540854328211

Epoch: 6| Step: 1
Training loss: 5.165493903830282
Validation loss: 5.331702857332423

Epoch: 6| Step: 2
Training loss: 5.667847267284438
Validation loss: 5.326207208277252

Epoch: 6| Step: 3
Training loss: 4.782183587175444
Validation loss: 5.320661640707999

Epoch: 6| Step: 4
Training loss: 6.005389018675227
Validation loss: 5.315095155425768

Epoch: 6| Step: 5
Training loss: 5.521210433268913
Validation loss: 5.309521846375804

Epoch: 6| Step: 6
Training loss: 5.576221985600146
Validation loss: 5.304009987474093

Epoch: 6| Step: 7
Training loss: 5.136149861558814
Validation loss: 5.298528962549119

Epoch: 6| Step: 8
Training loss: 5.121745122690765
Validation loss: 5.292961602951048

Epoch: 6| Step: 9
Training loss: 4.771098011565253
Validation loss: 5.287009445052119

Epoch: 6| Step: 10
Training loss: 5.569671465569132
Validation loss: 5.281557815279131

Epoch: 6| Step: 11
Training loss: 5.769633731952047
Validation loss: 5.2754158735936265

Epoch: 6| Step: 12
Training loss: 5.778035027735491
Validation loss: 5.269659894311307

Epoch: 6| Step: 13
Training loss: 5.6926594901076335
Validation loss: 5.263229715794198

Epoch: 10| Step: 0
Training loss: 6.218216302868356
Validation loss: 5.257543775201186

Epoch: 6| Step: 1
Training loss: 5.491132697318518
Validation loss: 5.251550082300152

Epoch: 6| Step: 2
Training loss: 4.590200285354438
Validation loss: 5.245724768975907

Epoch: 6| Step: 3
Training loss: 5.1963844053988035
Validation loss: 5.239601736876953

Epoch: 6| Step: 4
Training loss: 4.874307827839468
Validation loss: 5.2334949873398555

Epoch: 6| Step: 5
Training loss: 5.711928671682676
Validation loss: 5.227753781434642

Epoch: 6| Step: 6
Training loss: 4.403343161707461
Validation loss: 5.221739105215679

Epoch: 6| Step: 7
Training loss: 6.083172033949797
Validation loss: 5.216652576236566

Epoch: 6| Step: 8
Training loss: 5.024013646429201
Validation loss: 5.211024400404915

Epoch: 6| Step: 9
Training loss: 5.679718395290799
Validation loss: 5.205820937410857

Epoch: 6| Step: 10
Training loss: 5.129062624056101
Validation loss: 5.199794371525109

Epoch: 6| Step: 11
Training loss: 5.73190445652494
Validation loss: 5.194256989377007

Epoch: 6| Step: 12
Training loss: 5.242758343197407
Validation loss: 5.189432665050308

Epoch: 6| Step: 13
Training loss: 5.0735278169413185
Validation loss: 5.184005878070356

Epoch: 11| Step: 0
Training loss: 5.353874386578903
Validation loss: 5.17882682972264

Epoch: 6| Step: 1
Training loss: 4.785904357974744
Validation loss: 5.172987373638002

Epoch: 6| Step: 2
Training loss: 5.86289087224748
Validation loss: 5.168796787257776

Epoch: 6| Step: 3
Training loss: 6.258940139116132
Validation loss: 5.163115183189032

Epoch: 6| Step: 4
Training loss: 4.693732022633266
Validation loss: 5.156585805727886

Epoch: 6| Step: 5
Training loss: 5.662214138065824
Validation loss: 5.151752336757099

Epoch: 6| Step: 6
Training loss: 5.072373921880083
Validation loss: 5.146457042295777

Epoch: 6| Step: 7
Training loss: 5.016907905194117
Validation loss: 5.141063482102715

Epoch: 6| Step: 8
Training loss: 5.102212627865598
Validation loss: 5.135553519364427

Epoch: 6| Step: 9
Training loss: 5.761832294961705
Validation loss: 5.130784530684293

Epoch: 6| Step: 10
Training loss: 4.950560859733747
Validation loss: 5.125214766057487

Epoch: 6| Step: 11
Training loss: 5.890765848676685
Validation loss: 5.120337528636713

Epoch: 6| Step: 12
Training loss: 4.796139340728498
Validation loss: 5.114432721791818

Epoch: 6| Step: 13
Training loss: 4.114187924986472
Validation loss: 5.109486647697483

Epoch: 12| Step: 0
Training loss: 6.171625909728238
Validation loss: 5.104728491347763

Epoch: 6| Step: 1
Training loss: 4.473407585638279
Validation loss: 5.099860148288823

Epoch: 6| Step: 2
Training loss: 5.541575304392069
Validation loss: 5.0945690721257275

Epoch: 6| Step: 3
Training loss: 5.004076821534161
Validation loss: 5.089398949940081

Epoch: 6| Step: 4
Training loss: 4.243290260817521
Validation loss: 5.0839935040816355

Epoch: 6| Step: 5
Training loss: 6.188073950455714
Validation loss: 5.0785302259692395

Epoch: 6| Step: 6
Training loss: 5.433977762086228
Validation loss: 5.073654601559922

Epoch: 6| Step: 7
Training loss: 4.848174406357809
Validation loss: 5.0690961024243375

Epoch: 6| Step: 8
Training loss: 5.237983757748352
Validation loss: 5.063841434037153

Epoch: 6| Step: 9
Training loss: 5.4026678488737305
Validation loss: 5.058516076865066

Epoch: 6| Step: 10
Training loss: 4.696126502339621
Validation loss: 5.054233536536049

Epoch: 6| Step: 11
Training loss: 4.544006071785107
Validation loss: 5.049382424440185

Epoch: 6| Step: 12
Training loss: 5.171362353038683
Validation loss: 5.044408866898771

Epoch: 6| Step: 13
Training loss: 5.351796299637393
Validation loss: 5.03934637645156

Epoch: 13| Step: 0
Training loss: 5.551331183448272
Validation loss: 5.035016121306586

Epoch: 6| Step: 1
Training loss: 5.5022857424640925
Validation loss: 5.030158104102339

Epoch: 6| Step: 2
Training loss: 4.565738521472727
Validation loss: 5.024649640421958

Epoch: 6| Step: 3
Training loss: 3.9551211658537686
Validation loss: 5.019533941562589

Epoch: 6| Step: 4
Training loss: 5.505975078599803
Validation loss: 5.014702225804922

Epoch: 6| Step: 5
Training loss: 4.8772131957839315
Validation loss: 5.0102022036561555

Epoch: 6| Step: 6
Training loss: 4.811684081034281
Validation loss: 5.005281392919515

Epoch: 6| Step: 7
Training loss: 5.779595215559035
Validation loss: 5.000520138706884

Epoch: 6| Step: 8
Training loss: 5.47050264883923
Validation loss: 4.995368019983111

Epoch: 6| Step: 9
Training loss: 5.031183467448775
Validation loss: 4.991959050721755

Epoch: 6| Step: 10
Training loss: 4.919438415979336
Validation loss: 4.987029896238253

Epoch: 6| Step: 11
Training loss: 4.829684798734484
Validation loss: 4.982865283296134

Epoch: 6| Step: 12
Training loss: 6.298163118965379
Validation loss: 4.976525482726747

Epoch: 6| Step: 13
Training loss: 4.158952795048344
Validation loss: 4.9725518866188185

Epoch: 14| Step: 0
Training loss: 5.509738969383412
Validation loss: 4.968033904929983

Epoch: 6| Step: 1
Training loss: 5.4263921823527665
Validation loss: 4.96369606677224

Epoch: 6| Step: 2
Training loss: 5.28580075638786
Validation loss: 4.959043446615068

Epoch: 6| Step: 3
Training loss: 5.284914269162505
Validation loss: 4.954629278547669

Epoch: 6| Step: 4
Training loss: 4.330104994701251
Validation loss: 4.949720751145757

Epoch: 6| Step: 5
Training loss: 4.592801573543681
Validation loss: 4.945302439956115

Epoch: 6| Step: 6
Training loss: 4.993505838128151
Validation loss: 4.940879502196818

Epoch: 6| Step: 7
Training loss: 5.220446282379221
Validation loss: 4.9363911023310685

Epoch: 6| Step: 8
Training loss: 4.393243735002272
Validation loss: 4.931501809360255

Epoch: 6| Step: 9
Training loss: 5.611508614505021
Validation loss: 4.926700257241449

Epoch: 6| Step: 10
Training loss: 4.6974710843839205
Validation loss: 4.9225652947332525

Epoch: 6| Step: 11
Training loss: 4.110582761635969
Validation loss: 4.918268115340418

Epoch: 6| Step: 12
Training loss: 6.000888440794198
Validation loss: 4.91388987130332

Epoch: 6| Step: 13
Training loss: 5.045096541691768
Validation loss: 4.909689537897569

Epoch: 15| Step: 0
Training loss: 4.2782689317632006
Validation loss: 4.905958065734455

Epoch: 6| Step: 1
Training loss: 5.667710301654149
Validation loss: 4.901248755895497

Epoch: 6| Step: 2
Training loss: 4.347321942167115
Validation loss: 4.896504143826019

Epoch: 6| Step: 3
Training loss: 4.321992681946355
Validation loss: 4.892743708993154

Epoch: 6| Step: 4
Training loss: 5.495777590075865
Validation loss: 4.888347432588433

Epoch: 6| Step: 5
Training loss: 5.138966579823703
Validation loss: 4.883749470648482

Epoch: 6| Step: 6
Training loss: 5.608383898722014
Validation loss: 4.879927142282057

Epoch: 6| Step: 7
Training loss: 4.960280583659348
Validation loss: 4.875541070108872

Epoch: 6| Step: 8
Training loss: 5.146504202701369
Validation loss: 4.871147312501015

Epoch: 6| Step: 9
Training loss: 5.689345846268028
Validation loss: 4.867027741367171

Epoch: 6| Step: 10
Training loss: 3.88166997974648
Validation loss: 4.862473100262579

Epoch: 6| Step: 11
Training loss: 5.677675922041731
Validation loss: 4.858188234826656

Epoch: 6| Step: 12
Training loss: 4.286846429151493
Validation loss: 4.854099365990279

Epoch: 6| Step: 13
Training loss: 5.011269838441826
Validation loss: 4.850020175249537

Epoch: 16| Step: 0
Training loss: 5.275262813439203
Validation loss: 4.845783618902684

Epoch: 6| Step: 1
Training loss: 5.934026404774299
Validation loss: 4.841294353218571

Epoch: 6| Step: 2
Training loss: 4.981972812108265
Validation loss: 4.836846368414684

Epoch: 6| Step: 3
Training loss: 3.6789447658464414
Validation loss: 4.833183330093627

Epoch: 6| Step: 4
Training loss: 4.5594078977887
Validation loss: 4.828780704815088

Epoch: 6| Step: 5
Training loss: 5.5253151989262435
Validation loss: 4.824519979156116

Epoch: 6| Step: 6
Training loss: 5.177121915104235
Validation loss: 4.820302970460512

Epoch: 6| Step: 7
Training loss: 5.079221636396725
Validation loss: 4.81610875423967

Epoch: 6| Step: 8
Training loss: 4.418839669835279
Validation loss: 4.812381528246593

Epoch: 6| Step: 9
Training loss: 4.9015530985923546
Validation loss: 4.808083791003716

Epoch: 6| Step: 10
Training loss: 5.248703387771843
Validation loss: 4.804443816334835

Epoch: 6| Step: 11
Training loss: 4.0250139129587765
Validation loss: 4.799879891164412

Epoch: 6| Step: 12
Training loss: 4.4426948335479
Validation loss: 4.795577015505167

Epoch: 6| Step: 13
Training loss: 5.478191487180313
Validation loss: 4.791667999046251

Epoch: 17| Step: 0
Training loss: 4.876222506095787
Validation loss: 4.787600702300684

Epoch: 6| Step: 1
Training loss: 4.7448252548664795
Validation loss: 4.783331989106489

Epoch: 6| Step: 2
Training loss: 4.382165327246596
Validation loss: 4.779497078756965

Epoch: 6| Step: 3
Training loss: 4.698641138259292
Validation loss: 4.775630099813015

Epoch: 6| Step: 4
Training loss: 5.565695198554525
Validation loss: 4.771483792047182

Epoch: 6| Step: 5
Training loss: 4.5864282504667715
Validation loss: 4.767031969508857

Epoch: 6| Step: 6
Training loss: 5.709115005027049
Validation loss: 4.763145493811722

Epoch: 6| Step: 7
Training loss: 4.422454688151141
Validation loss: 4.758900551912421

Epoch: 6| Step: 8
Training loss: 5.001601153542842
Validation loss: 4.754845122399957

Epoch: 6| Step: 9
Training loss: 4.503324763932017
Validation loss: 4.7507071052398295

Epoch: 6| Step: 10
Training loss: 4.958178905144501
Validation loss: 4.746592487352073

Epoch: 6| Step: 11
Training loss: 5.413984642184585
Validation loss: 4.743128390456546

Epoch: 6| Step: 12
Training loss: 4.886313588569592
Validation loss: 4.738893004506689

Epoch: 6| Step: 13
Training loss: 4.432353514237205
Validation loss: 4.734485050009282

Epoch: 18| Step: 0
Training loss: 5.467379501821998
Validation loss: 4.730567836589978

Epoch: 6| Step: 1
Training loss: 5.151204733072291
Validation loss: 4.726540069947209

Epoch: 6| Step: 2
Training loss: 4.939233210122751
Validation loss: 4.721964669528034

Epoch: 6| Step: 3
Training loss: 3.464268719458714
Validation loss: 4.717450668273791

Epoch: 6| Step: 4
Training loss: 4.974111291687174
Validation loss: 4.7141088773194975

Epoch: 6| Step: 5
Training loss: 4.7452246101688536
Validation loss: 4.710003778762544

Epoch: 6| Step: 6
Training loss: 4.820837551808579
Validation loss: 4.705572900110852

Epoch: 6| Step: 7
Training loss: 4.596555722349833
Validation loss: 4.701663342492408

Epoch: 6| Step: 8
Training loss: 4.8838698074021485
Validation loss: 4.696989262541053

Epoch: 6| Step: 9
Training loss: 5.270432810084503
Validation loss: 4.693473197539984

Epoch: 6| Step: 10
Training loss: 3.9257252551588095
Validation loss: 4.6888849204670855

Epoch: 6| Step: 11
Training loss: 4.844904608166341
Validation loss: 4.685274553779883

Epoch: 6| Step: 12
Training loss: 5.205063284160363
Validation loss: 4.680767802863601

Epoch: 6| Step: 13
Training loss: 4.964216551343014
Validation loss: 4.67659015505017

Epoch: 19| Step: 0
Training loss: 5.068933237623126
Validation loss: 4.671888506645487

Epoch: 6| Step: 1
Training loss: 5.6296616629103715
Validation loss: 4.668104251187764

Epoch: 6| Step: 2
Training loss: 5.281638949365536
Validation loss: 4.663647231161942

Epoch: 6| Step: 3
Training loss: 5.190445213258765
Validation loss: 4.659363936426685

Epoch: 6| Step: 4
Training loss: 4.12022285117975
Validation loss: 4.655305429525674

Epoch: 6| Step: 5
Training loss: 3.930860461902364
Validation loss: 4.650831000614498

Epoch: 6| Step: 6
Training loss: 5.38952660911072
Validation loss: 4.646687461901361

Epoch: 6| Step: 7
Training loss: 4.728612634860411
Validation loss: 4.6423667781506435

Epoch: 6| Step: 8
Training loss: 5.196147834336912
Validation loss: 4.637747303691431

Epoch: 6| Step: 9
Training loss: 5.550293978216731
Validation loss: 4.633782785328994

Epoch: 6| Step: 10
Training loss: 3.929448205779572
Validation loss: 4.629510690362183

Epoch: 6| Step: 11
Training loss: 4.588645538412971
Validation loss: 4.625429631803721

Epoch: 6| Step: 12
Training loss: 3.808791060594125
Validation loss: 4.621023410273606

Epoch: 6| Step: 13
Training loss: 3.76854114871078
Validation loss: 4.616444105620493

Epoch: 20| Step: 0
Training loss: 3.988435120187713
Validation loss: 4.612565741204034

Epoch: 6| Step: 1
Training loss: 4.7019879053269396
Validation loss: 4.608772488456332

Epoch: 6| Step: 2
Training loss: 5.178688378728209
Validation loss: 4.6049907286333545

Epoch: 6| Step: 3
Training loss: 4.7954811282820184
Validation loss: 4.600548106171401

Epoch: 6| Step: 4
Training loss: 4.961772121598282
Validation loss: 4.5971315355118305

Epoch: 6| Step: 5
Training loss: 4.985344962807826
Validation loss: 4.592767035055163

Epoch: 6| Step: 6
Training loss: 4.243511857330056
Validation loss: 4.5881894597448785

Epoch: 6| Step: 7
Training loss: 5.4291674028670815
Validation loss: 4.584462714488346

Epoch: 6| Step: 8
Training loss: 4.80270856095645
Validation loss: 4.5804589824213435

Epoch: 6| Step: 9
Training loss: 4.126419285604102
Validation loss: 4.576308670202736

Epoch: 6| Step: 10
Training loss: 4.84758621398844
Validation loss: 4.572421534445361

Epoch: 6| Step: 11
Training loss: 4.65290784258635
Validation loss: 4.568376319030765

Epoch: 6| Step: 12
Training loss: 4.402963697891589
Validation loss: 4.564080892001467

Epoch: 6| Step: 13
Training loss: 4.666956937935776
Validation loss: 4.559788913079648

Epoch: 21| Step: 0
Training loss: 4.043924205865892
Validation loss: 4.555775812815254

Epoch: 6| Step: 1
Training loss: 4.888154499690225
Validation loss: 4.551439194602863

Epoch: 6| Step: 2
Training loss: 5.368507900263844
Validation loss: 4.547372482718128

Epoch: 6| Step: 3
Training loss: 4.7126629707630245
Validation loss: 4.543027773009298

Epoch: 6| Step: 4
Training loss: 4.365279598129842
Validation loss: 4.538997892619213

Epoch: 6| Step: 5
Training loss: 5.446651080765636
Validation loss: 4.534756200616696

Epoch: 6| Step: 6
Training loss: 4.429083781335576
Validation loss: 4.530680723713725

Epoch: 6| Step: 7
Training loss: 4.568693790533587
Validation loss: 4.526150449346152

Epoch: 6| Step: 8
Training loss: 3.5583595173666733
Validation loss: 4.522030573701484

Epoch: 6| Step: 9
Training loss: 4.980425474689441
Validation loss: 4.517866834317422

Epoch: 6| Step: 10
Training loss: 4.734290798936677
Validation loss: 4.51395368611052

Epoch: 6| Step: 11
Training loss: 4.222054324799435
Validation loss: 4.50972322532445

Epoch: 6| Step: 12
Training loss: 4.987192153034517
Validation loss: 4.505647047728577

Epoch: 6| Step: 13
Training loss: 4.5365741888669415
Validation loss: 4.501193100332072

Epoch: 22| Step: 0
Training loss: 4.90992841897596
Validation loss: 4.497357192883127

Epoch: 6| Step: 1
Training loss: 4.26608620410494
Validation loss: 4.4928055755447955

Epoch: 6| Step: 2
Training loss: 3.871515737989072
Validation loss: 4.488931642513399

Epoch: 6| Step: 3
Training loss: 4.638171642435452
Validation loss: 4.484674884547229

Epoch: 6| Step: 4
Training loss: 4.1787573804456395
Validation loss: 4.4806339196887786

Epoch: 6| Step: 5
Training loss: 4.888878263596827
Validation loss: 4.476606882528859

Epoch: 6| Step: 6
Training loss: 5.235762591558285
Validation loss: 4.472484886296002

Epoch: 6| Step: 7
Training loss: 4.222284037711957
Validation loss: 4.468425783431489

Epoch: 6| Step: 8
Training loss: 4.798579705235706
Validation loss: 4.464082783764332

Epoch: 6| Step: 9
Training loss: 4.528769188886859
Validation loss: 4.4603324876254264

Epoch: 6| Step: 10
Training loss: 5.127089283906268
Validation loss: 4.4559848815323635

Epoch: 6| Step: 11
Training loss: 4.154069141912664
Validation loss: 4.451915340202434

Epoch: 6| Step: 12
Training loss: 5.494019811816021
Validation loss: 4.447462280553783

Epoch: 6| Step: 13
Training loss: 3.662648788398331
Validation loss: 4.443137854339612

Epoch: 23| Step: 0
Training loss: 5.21998006064162
Validation loss: 4.438831971182501

Epoch: 6| Step: 1
Training loss: 5.328467036480784
Validation loss: 4.434483286257029

Epoch: 6| Step: 2
Training loss: 4.393946141603524
Validation loss: 4.430295692776655

Epoch: 6| Step: 3
Training loss: 4.998136173000634
Validation loss: 4.425853758956175

Epoch: 6| Step: 4
Training loss: 4.989718356392778
Validation loss: 4.421449171215355

Epoch: 6| Step: 5
Training loss: 3.962390279604632
Validation loss: 4.416726987654748

Epoch: 6| Step: 6
Training loss: 4.197157470104907
Validation loss: 4.412043521024329

Epoch: 6| Step: 7
Training loss: 4.345872977719961
Validation loss: 4.408069460398296

Epoch: 6| Step: 8
Training loss: 4.2766493978372235
Validation loss: 4.40349628082496

Epoch: 6| Step: 9
Training loss: 4.45170061855206
Validation loss: 4.399495532276087

Epoch: 6| Step: 10
Training loss: 4.666199569940582
Validation loss: 4.3949418753468175

Epoch: 6| Step: 11
Training loss: 4.2775506513886326
Validation loss: 4.391038144404583

Epoch: 6| Step: 12
Training loss: 4.412867777683287
Validation loss: 4.386694183688448

Epoch: 6| Step: 13
Training loss: 3.7623253765962192
Validation loss: 4.382660072654388

Epoch: 24| Step: 0
Training loss: 4.5647391481442385
Validation loss: 4.378371783173496

Epoch: 6| Step: 1
Training loss: 4.300962633124497
Validation loss: 4.374248022213285

Epoch: 6| Step: 2
Training loss: 4.921778892910888
Validation loss: 4.370161268981585

Epoch: 6| Step: 3
Training loss: 4.73872824979604
Validation loss: 4.3659543939184005

Epoch: 6| Step: 4
Training loss: 3.841312038468091
Validation loss: 4.361848300470052

Epoch: 6| Step: 5
Training loss: 4.628715672171246
Validation loss: 4.357762101024325

Epoch: 6| Step: 6
Training loss: 3.721516197455328
Validation loss: 4.353737196967822

Epoch: 6| Step: 7
Training loss: 4.140966552466641
Validation loss: 4.349535558468457

Epoch: 6| Step: 8
Training loss: 4.596572527863152
Validation loss: 4.345559344824189

Epoch: 6| Step: 9
Training loss: 5.111126427466253
Validation loss: 4.341233400385789

Epoch: 6| Step: 10
Training loss: 4.478770724990424
Validation loss: 4.337145626165476

Epoch: 6| Step: 11
Training loss: 4.112560821361724
Validation loss: 4.332652380821185

Epoch: 6| Step: 12
Training loss: 4.92076209671091
Validation loss: 4.3286351937221506

Epoch: 6| Step: 13
Training loss: 4.417976952772005
Validation loss: 4.3244143300795574

Epoch: 25| Step: 0
Training loss: 3.844230807866561
Validation loss: 4.319861445412602

Epoch: 6| Step: 1
Training loss: 4.6998660941020685
Validation loss: 4.31572661651963

Epoch: 6| Step: 2
Training loss: 4.635632227768188
Validation loss: 4.311663007367241

Epoch: 6| Step: 3
Training loss: 4.972892521880971
Validation loss: 4.307264070372491

Epoch: 6| Step: 4
Training loss: 4.373477125789022
Validation loss: 4.302765109494559

Epoch: 6| Step: 5
Training loss: 4.492264350565462
Validation loss: 4.298260422662997

Epoch: 6| Step: 6
Training loss: 3.814244855985406
Validation loss: 4.294041849774303

Epoch: 6| Step: 7
Training loss: 4.050451870423133
Validation loss: 4.289720791650264

Epoch: 6| Step: 8
Training loss: 4.071988337382045
Validation loss: 4.285552338916074

Epoch: 6| Step: 9
Training loss: 4.5562471366213995
Validation loss: 4.281140068480557

Epoch: 6| Step: 10
Training loss: 5.0648447893769175
Validation loss: 4.277242692424203

Epoch: 6| Step: 11
Training loss: 4.309598527163758
Validation loss: 4.272852995404466

Epoch: 6| Step: 12
Training loss: 5.248721194059905
Validation loss: 4.26855042392713

Epoch: 6| Step: 13
Training loss: 3.367545195165091
Validation loss: 4.264056298072138

Epoch: 26| Step: 0
Training loss: 4.919858876817287
Validation loss: 4.2596497284545265

Epoch: 6| Step: 1
Training loss: 4.227243421495866
Validation loss: 4.255108978842274

Epoch: 6| Step: 2
Training loss: 3.9882889018046086
Validation loss: 4.250717177372937

Epoch: 6| Step: 3
Training loss: 4.457533197113527
Validation loss: 4.246348701223057

Epoch: 6| Step: 4
Training loss: 4.130858913268296
Validation loss: 4.24195189550625

Epoch: 6| Step: 5
Training loss: 3.8209755912985517
Validation loss: 4.237570088574904

Epoch: 6| Step: 6
Training loss: 4.926927474005117
Validation loss: 4.233246881748656

Epoch: 6| Step: 7
Training loss: 4.145813652771414
Validation loss: 4.228865319902023

Epoch: 6| Step: 8
Training loss: 4.7805430569073755
Validation loss: 4.224520168106254

Epoch: 6| Step: 9
Training loss: 4.467755186950429
Validation loss: 4.220313547758754

Epoch: 6| Step: 10
Training loss: 4.263046882874494
Validation loss: 4.215762344962111

Epoch: 6| Step: 11
Training loss: 4.525711779174
Validation loss: 4.211276784426505

Epoch: 6| Step: 12
Training loss: 4.773587338457406
Validation loss: 4.206888662204709

Epoch: 6| Step: 13
Training loss: 3.3482917529635716
Validation loss: 4.202040559585334

Epoch: 27| Step: 0
Training loss: 4.873450399750481
Validation loss: 4.197740284485454

Epoch: 6| Step: 1
Training loss: 3.6452649063947287
Validation loss: 4.193364302536501

Epoch: 6| Step: 2
Training loss: 4.174885438729268
Validation loss: 4.1888235477193625

Epoch: 6| Step: 3
Training loss: 4.41806480782233
Validation loss: 4.184496414440113

Epoch: 6| Step: 4
Training loss: 4.655381089620871
Validation loss: 4.180041869165241

Epoch: 6| Step: 5
Training loss: 4.775381438513659
Validation loss: 4.175539881049889

Epoch: 6| Step: 6
Training loss: 3.6377491868913276
Validation loss: 4.171138817533637

Epoch: 6| Step: 7
Training loss: 3.9438540340672863
Validation loss: 4.166405987532416

Epoch: 6| Step: 8
Training loss: 4.141602598701533
Validation loss: 4.1621792216223055

Epoch: 6| Step: 9
Training loss: 4.322593045664574
Validation loss: 4.157858496689521

Epoch: 6| Step: 10
Training loss: 4.440925243302522
Validation loss: 4.153380050845463

Epoch: 6| Step: 11
Training loss: 3.9428415548912867
Validation loss: 4.149227969811138

Epoch: 6| Step: 12
Training loss: 4.268018561010928
Validation loss: 4.144652378950015

Epoch: 6| Step: 13
Training loss: 4.7318902372397815
Validation loss: 4.1403078161668

Epoch: 28| Step: 0
Training loss: 3.9725777497314176
Validation loss: 4.135853620196693

Epoch: 6| Step: 1
Training loss: 4.634854514792348
Validation loss: 4.1312000996879465

Epoch: 6| Step: 2
Training loss: 3.2437162540863413
Validation loss: 4.126771584986316

Epoch: 6| Step: 3
Training loss: 4.089013540975531
Validation loss: 4.122231334585953

Epoch: 6| Step: 4
Training loss: 5.175590724677255
Validation loss: 4.1178769928314285

Epoch: 6| Step: 5
Training loss: 4.974375485275098
Validation loss: 4.113396363128376

Epoch: 6| Step: 6
Training loss: 4.058838118244824
Validation loss: 4.108657793666707

Epoch: 6| Step: 7
Training loss: 4.11706473295974
Validation loss: 4.104178310836049

Epoch: 6| Step: 8
Training loss: 3.749979654892727
Validation loss: 4.099546798221197

Epoch: 6| Step: 9
Training loss: 3.3175350285673675
Validation loss: 4.095036292437344

Epoch: 6| Step: 10
Training loss: 4.166214091835511
Validation loss: 4.090370511074397

Epoch: 6| Step: 11
Training loss: 4.402989039816158
Validation loss: 4.086024675478674

Epoch: 6| Step: 12
Training loss: 4.728781842722759
Validation loss: 4.081805442879774

Epoch: 6| Step: 13
Training loss: 4.239923986797211
Validation loss: 4.077126450165264

Epoch: 29| Step: 0
Training loss: 3.46147313504647
Validation loss: 4.072647352493688

Epoch: 6| Step: 1
Training loss: 3.8456959334461707
Validation loss: 4.06821229802834

Epoch: 6| Step: 2
Training loss: 4.078898973938875
Validation loss: 4.063981104114737

Epoch: 6| Step: 3
Training loss: 3.3641291135579188
Validation loss: 4.059655489688314

Epoch: 6| Step: 4
Training loss: 4.810124393052194
Validation loss: 4.055345779521087

Epoch: 6| Step: 5
Training loss: 4.2086132195693144
Validation loss: 4.05093769003154

Epoch: 6| Step: 6
Training loss: 4.480436822167191
Validation loss: 4.0469857768996595

Epoch: 6| Step: 7
Training loss: 3.678494075644377
Validation loss: 4.041916882087722

Epoch: 6| Step: 8
Training loss: 4.2671463597373736
Validation loss: 4.037519680483067

Epoch: 6| Step: 9
Training loss: 3.5504357030279325
Validation loss: 4.03326438629448

Epoch: 6| Step: 10
Training loss: 4.273134433523347
Validation loss: 4.028745735900813

Epoch: 6| Step: 11
Training loss: 4.854607405184448
Validation loss: 4.024368761056502

Epoch: 6| Step: 12
Training loss: 4.511115439234904
Validation loss: 4.019697941523322

Epoch: 6| Step: 13
Training loss: 4.679374875435127
Validation loss: 4.015055021017481

Epoch: 30| Step: 0
Training loss: 4.106612869091972
Validation loss: 4.010392397852536

Epoch: 6| Step: 1
Training loss: 4.280590145745048
Validation loss: 4.00525818369201

Epoch: 6| Step: 2
Training loss: 4.2947775420552565
Validation loss: 4.000513977566711

Epoch: 6| Step: 3
Training loss: 4.671691278525954
Validation loss: 3.9954362902051814

Epoch: 6| Step: 4
Training loss: 3.9007494230861
Validation loss: 3.990238876203306

Epoch: 6| Step: 5
Training loss: 4.107983255591806
Validation loss: 3.985101431652994

Epoch: 6| Step: 6
Training loss: 4.100388131727355
Validation loss: 3.9799552588767537

Epoch: 6| Step: 7
Training loss: 4.766122060399724
Validation loss: 3.975075494301245

Epoch: 6| Step: 8
Training loss: 3.102120683153562
Validation loss: 3.9700868412580257

Epoch: 6| Step: 9
Training loss: 4.228556446468662
Validation loss: 3.9653464914675234

Epoch: 6| Step: 10
Training loss: 3.86355870622731
Validation loss: 3.9605535538060224

Epoch: 6| Step: 11
Training loss: 2.9536613502065707
Validation loss: 3.9560099492258125

Epoch: 6| Step: 12
Training loss: 3.8714221310800765
Validation loss: 3.951526866635028

Epoch: 6| Step: 13
Training loss: 4.860434658880025
Validation loss: 3.947104310909809

Epoch: 31| Step: 0
Training loss: 3.765847607122896
Validation loss: 3.9424348616233225

Epoch: 6| Step: 1
Training loss: 3.44040238355792
Validation loss: 3.9377914199767403

Epoch: 6| Step: 2
Training loss: 4.510822210368062
Validation loss: 3.9334415329313206

Epoch: 6| Step: 3
Training loss: 3.936539911355383
Validation loss: 3.9289619074219515

Epoch: 6| Step: 4
Training loss: 3.8628900867993736
Validation loss: 3.924736711454915

Epoch: 6| Step: 5
Training loss: 4.8351699145973495
Validation loss: 3.9201442957614536

Epoch: 6| Step: 6
Training loss: 3.4698536809584266
Validation loss: 3.9155464734816348

Epoch: 6| Step: 7
Training loss: 4.538658452393763
Validation loss: 3.911125151983499

Epoch: 6| Step: 8
Training loss: 3.9489523838367018
Validation loss: 3.9063678571087608

Epoch: 6| Step: 9
Training loss: 3.76479662889264
Validation loss: 3.901776450425609

Epoch: 6| Step: 10
Training loss: 4.564326090711916
Validation loss: 3.897097146300598

Epoch: 6| Step: 11
Training loss: 4.116769613814047
Validation loss: 3.892233928259047

Epoch: 6| Step: 12
Training loss: 3.6973484229536404
Validation loss: 3.8874634915811703

Epoch: 6| Step: 13
Training loss: 3.9005361041816307
Validation loss: 3.8829158203787766

Epoch: 32| Step: 0
Training loss: 3.987831800282729
Validation loss: 3.8780371751044505

Epoch: 6| Step: 1
Training loss: 4.441520910871521
Validation loss: 3.8734516413857407

Epoch: 6| Step: 2
Training loss: 3.9068317437908675
Validation loss: 3.868617554401903

Epoch: 6| Step: 3
Training loss: 3.735833174630124
Validation loss: 3.8638145662374215

Epoch: 6| Step: 4
Training loss: 3.912420053853549
Validation loss: 3.859402119776773

Epoch: 6| Step: 5
Training loss: 3.7489749779119315
Validation loss: 3.854516352006004

Epoch: 6| Step: 6
Training loss: 4.45472319182913
Validation loss: 3.8501928033483366

Epoch: 6| Step: 7
Training loss: 3.07459765647581
Validation loss: 3.8455510042377874

Epoch: 6| Step: 8
Training loss: 3.377367249088746
Validation loss: 3.8410517828682726

Epoch: 6| Step: 9
Training loss: 4.550247881498441
Validation loss: 3.8364929501479383

Epoch: 6| Step: 10
Training loss: 4.001848747266205
Validation loss: 3.832190045959362

Epoch: 6| Step: 11
Training loss: 4.041410195514457
Validation loss: 3.827598255274197

Epoch: 6| Step: 12
Training loss: 3.9395759801663197
Validation loss: 3.8231208324051074

Epoch: 6| Step: 13
Training loss: 4.314086180072414
Validation loss: 3.8186171604824293

Epoch: 33| Step: 0
Training loss: 4.400656538445184
Validation loss: 3.813872397796869

Epoch: 6| Step: 1
Training loss: 3.6424771946891537
Validation loss: 3.809241481378169

Epoch: 6| Step: 2
Training loss: 3.784231728472805
Validation loss: 3.8046373054592904

Epoch: 6| Step: 3
Training loss: 3.1347038667008373
Validation loss: 3.7999455891444787

Epoch: 6| Step: 4
Training loss: 4.654588646173568
Validation loss: 3.795801604913343

Epoch: 6| Step: 5
Training loss: 4.171789961387509
Validation loss: 3.7910522899397434

Epoch: 6| Step: 6
Training loss: 2.9585405375669196
Validation loss: 3.7864417382269737

Epoch: 6| Step: 7
Training loss: 4.586931838938568
Validation loss: 3.7819388316503493

Epoch: 6| Step: 8
Training loss: 3.945189944337207
Validation loss: 3.7771478475260563

Epoch: 6| Step: 9
Training loss: 4.005967457251081
Validation loss: 3.773096673393739

Epoch: 6| Step: 10
Training loss: 4.182014174259927
Validation loss: 3.768171871077493

Epoch: 6| Step: 11
Training loss: 3.5096058498691196
Validation loss: 3.763641827127989

Epoch: 6| Step: 12
Training loss: 4.029310602709286
Validation loss: 3.7588484955883583

Epoch: 6| Step: 13
Training loss: 3.4377283193883725
Validation loss: 3.7543667905406677

Epoch: 34| Step: 0
Training loss: 4.0705692847263775
Validation loss: 3.7496254416009376

Epoch: 6| Step: 1
Training loss: 3.581311268973061
Validation loss: 3.745074322060207

Epoch: 6| Step: 2
Training loss: 3.9756335539321737
Validation loss: 3.7405923245478636

Epoch: 6| Step: 3
Training loss: 3.6805315284824447
Validation loss: 3.7360759144148927

Epoch: 6| Step: 4
Training loss: 3.7837140590547373
Validation loss: 3.732010905744258

Epoch: 6| Step: 5
Training loss: 3.6113035656107844
Validation loss: 3.72735992366299

Epoch: 6| Step: 6
Training loss: 3.0804809229525842
Validation loss: 3.723228258536016

Epoch: 6| Step: 7
Training loss: 4.1177436120069
Validation loss: 3.7192490614142653

Epoch: 6| Step: 8
Training loss: 3.476819112501001
Validation loss: 3.7147273257009163

Epoch: 6| Step: 9
Training loss: 4.075956623149813
Validation loss: 3.7102528365455307

Epoch: 6| Step: 10
Training loss: 4.57723167478854
Validation loss: 3.7055755318886896

Epoch: 6| Step: 11
Training loss: 4.317579733019016
Validation loss: 3.7012149268123316

Epoch: 6| Step: 12
Training loss: 3.4893317440302893
Validation loss: 3.6966431623238485

Epoch: 6| Step: 13
Training loss: 3.890626225605354
Validation loss: 3.6916380256133094

Epoch: 35| Step: 0
Training loss: 3.9371507277816384
Validation loss: 3.686914128028376

Epoch: 6| Step: 1
Training loss: 4.102856938597025
Validation loss: 3.6822733503189182

Epoch: 6| Step: 2
Training loss: 4.437135923252297
Validation loss: 3.67765601924352

Epoch: 6| Step: 3
Training loss: 2.9169913701559786
Validation loss: 3.6729590148273146

Epoch: 6| Step: 4
Training loss: 4.084500412011566
Validation loss: 3.668222891846287

Epoch: 6| Step: 5
Training loss: 4.133822168136099
Validation loss: 3.663939017768404

Epoch: 6| Step: 6
Training loss: 3.7137274925245807
Validation loss: 3.6588802169288757

Epoch: 6| Step: 7
Training loss: 3.690865225729863
Validation loss: 3.6543018987346882

Epoch: 6| Step: 8
Training loss: 3.854308350854191
Validation loss: 3.6495641239092027

Epoch: 6| Step: 9
Training loss: 3.1033635135197906
Validation loss: 3.6449036130296744

Epoch: 6| Step: 10
Training loss: 3.9321382134750307
Validation loss: 3.6404299267636553

Epoch: 6| Step: 11
Training loss: 3.3491073899545594
Validation loss: 3.635727367222346

Epoch: 6| Step: 12
Training loss: 3.6406032577978715
Validation loss: 3.631379619480116

Epoch: 6| Step: 13
Training loss: 3.9378561434065302
Validation loss: 3.62717793250184

Epoch: 36| Step: 0
Training loss: 3.7762136415804006
Validation loss: 3.622694082297731

Epoch: 6| Step: 1
Training loss: 4.020493936132539
Validation loss: 3.618346059651766

Epoch: 6| Step: 2
Training loss: 3.182984987808957
Validation loss: 3.613563078465625

Epoch: 6| Step: 3
Training loss: 2.9377256266199887
Validation loss: 3.6093510878790567

Epoch: 6| Step: 4
Training loss: 3.267715733943038
Validation loss: 3.605088257610898

Epoch: 6| Step: 5
Training loss: 3.4966525009590788
Validation loss: 3.600573245961551

Epoch: 6| Step: 6
Training loss: 3.9974331964823824
Validation loss: 3.5964522664886047

Epoch: 6| Step: 7
Training loss: 3.9608517850069784
Validation loss: 3.592028628532578

Epoch: 6| Step: 8
Training loss: 3.4311517531151656
Validation loss: 3.5876559348780694

Epoch: 6| Step: 9
Training loss: 4.008624316232615
Validation loss: 3.583540559291733

Epoch: 6| Step: 10
Training loss: 3.940851389880621
Validation loss: 3.5790820667244145

Epoch: 6| Step: 11
Training loss: 3.184601906131614
Validation loss: 3.57476148810069

Epoch: 6| Step: 12
Training loss: 4.3334359865989915
Validation loss: 3.5705324379299026

Epoch: 6| Step: 13
Training loss: 4.342186516057823
Validation loss: 3.5664326115637057

Epoch: 37| Step: 0
Training loss: 4.084157172934511
Validation loss: 3.5616729847184514

Epoch: 6| Step: 1
Training loss: 4.561609259622704
Validation loss: 3.5576247603414117

Epoch: 6| Step: 2
Training loss: 2.929421537406872
Validation loss: 3.553033442507266

Epoch: 6| Step: 3
Training loss: 3.7198693650391195
Validation loss: 3.5482990470246283

Epoch: 6| Step: 4
Training loss: 4.054436295505999
Validation loss: 3.5443535803731345

Epoch: 6| Step: 5
Training loss: 3.476997948282518
Validation loss: 3.540318432537869

Epoch: 6| Step: 6
Training loss: 4.032936394025072
Validation loss: 3.5361305875226017

Epoch: 6| Step: 7
Training loss: 3.385490502750505
Validation loss: 3.530237260829219

Epoch: 6| Step: 8
Training loss: 3.795767414568881
Validation loss: 3.5256786225277197

Epoch: 6| Step: 9
Training loss: 3.759945714031113
Validation loss: 3.5209109205616946

Epoch: 6| Step: 10
Training loss: 3.533600151735993
Validation loss: 3.516344643865173

Epoch: 6| Step: 11
Training loss: 3.442051042301322
Validation loss: 3.512352693484893

Epoch: 6| Step: 12
Training loss: 3.6476610815653907
Validation loss: 3.5080570399084827

Epoch: 6| Step: 13
Training loss: 2.566781166131926
Validation loss: 3.5036592882008697

Epoch: 38| Step: 0
Training loss: 3.5986329450050856
Validation loss: 3.4995879884448096

Epoch: 6| Step: 1
Training loss: 3.5607221751707114
Validation loss: 3.4953959018952814

Epoch: 6| Step: 2
Training loss: 4.080767597471132
Validation loss: 3.491200170255832

Epoch: 6| Step: 3
Training loss: 3.8210754256822046
Validation loss: 3.486769601774596

Epoch: 6| Step: 4
Training loss: 4.018951819114685
Validation loss: 3.482871034659981

Epoch: 6| Step: 5
Training loss: 3.464875540431597
Validation loss: 3.4780645775951955

Epoch: 6| Step: 6
Training loss: 2.9337416610306697
Validation loss: 3.4739593932890336

Epoch: 6| Step: 7
Training loss: 3.496487353454351
Validation loss: 3.4698668277188505

Epoch: 6| Step: 8
Training loss: 3.3607753939796834
Validation loss: 3.4659066904725786

Epoch: 6| Step: 9
Training loss: 3.8697619567524706
Validation loss: 3.4617666796906894

Epoch: 6| Step: 10
Training loss: 2.879561578705877
Validation loss: 3.4575373104984966

Epoch: 6| Step: 11
Training loss: 3.7613659591269504
Validation loss: 3.453443509655473

Epoch: 6| Step: 12
Training loss: 3.42616247233026
Validation loss: 3.449558285986537

Epoch: 6| Step: 13
Training loss: 4.028395004042398
Validation loss: 3.4453804084388366

Epoch: 39| Step: 0
Training loss: 3.393143944342233
Validation loss: 3.4413073175869004

Epoch: 6| Step: 1
Training loss: 3.7107001620238527
Validation loss: 3.4371956199209968

Epoch: 6| Step: 2
Training loss: 3.5031805573412833
Validation loss: 3.4328840301242667

Epoch: 6| Step: 3
Training loss: 3.4509262057969954
Validation loss: 3.4290021995202893

Epoch: 6| Step: 4
Training loss: 3.317836134209216
Validation loss: 3.4249103733967967

Epoch: 6| Step: 5
Training loss: 3.0436412376695414
Validation loss: 3.4209734862808374

Epoch: 6| Step: 6
Training loss: 4.500612429164372
Validation loss: 3.4169001421978233

Epoch: 6| Step: 7
Training loss: 3.1233618448015292
Validation loss: 3.412640214957504

Epoch: 6| Step: 8
Training loss: 3.3729942861056794
Validation loss: 3.4089006615545556

Epoch: 6| Step: 9
Training loss: 3.5476744166826624
Validation loss: 3.4043386854010595

Epoch: 6| Step: 10
Training loss: 3.5545587201947444
Validation loss: 3.3999915066781266

Epoch: 6| Step: 11
Training loss: 3.4868582186283983
Validation loss: 3.3961230351417115

Epoch: 6| Step: 12
Training loss: 4.332152327968698
Validation loss: 3.392291911805606

Epoch: 6| Step: 13
Training loss: 3.0777765841736144
Validation loss: 3.388068998064315

Epoch: 40| Step: 0
Training loss: 4.421444282178084
Validation loss: 3.3840490933938647

Epoch: 6| Step: 1
Training loss: 3.6257739063098975
Validation loss: 3.3797794455926295

Epoch: 6| Step: 2
Training loss: 3.2761052079500024
Validation loss: 3.375392278785567

Epoch: 6| Step: 3
Training loss: 2.6326215997417397
Validation loss: 3.371231376870909

Epoch: 6| Step: 4
Training loss: 3.9209913496930437
Validation loss: 3.367485086341464

Epoch: 6| Step: 5
Training loss: 3.123141384543633
Validation loss: 3.3632296426426773

Epoch: 6| Step: 6
Training loss: 3.228443991898525
Validation loss: 3.359312225464994

Epoch: 6| Step: 7
Training loss: 3.656979610320557
Validation loss: 3.355047659158816

Epoch: 6| Step: 8
Training loss: 4.073878156080618
Validation loss: 3.3514339537966995

Epoch: 6| Step: 9
Training loss: 2.9490872991711052
Validation loss: 3.347828288277725

Epoch: 6| Step: 10
Training loss: 3.6584059398864
Validation loss: 3.343333530337276

Epoch: 6| Step: 11
Training loss: 2.9285206009444855
Validation loss: 3.34044393459701

Epoch: 6| Step: 12
Training loss: 3.6270243812837486
Validation loss: 3.335915237102326

Epoch: 6| Step: 13
Training loss: 3.403146992762097
Validation loss: 3.3314871602809797

Epoch: 41| Step: 0
Training loss: 3.431370906402024
Validation loss: 3.327657651847065

Epoch: 6| Step: 1
Training loss: 3.365413614504448
Validation loss: 3.3235828764217827

Epoch: 6| Step: 2
Training loss: 2.7699215375894415
Validation loss: 3.3193146526405806

Epoch: 6| Step: 3
Training loss: 3.6625577850470283
Validation loss: 3.3163784042405533

Epoch: 6| Step: 4
Training loss: 3.4545834598549674
Validation loss: 3.3125314051261

Epoch: 6| Step: 5
Training loss: 3.279721730686508
Validation loss: 3.30870388047382

Epoch: 6| Step: 6
Training loss: 3.242416336991994
Validation loss: 3.304826762073513

Epoch: 6| Step: 7
Training loss: 3.496607362324893
Validation loss: 3.300909096312951

Epoch: 6| Step: 8
Training loss: 3.90009683831127
Validation loss: 3.297105283965815

Epoch: 6| Step: 9
Training loss: 3.455135812919338
Validation loss: 3.2930457851680246

Epoch: 6| Step: 10
Training loss: 2.7073077876653255
Validation loss: 3.288898503193535

Epoch: 6| Step: 11
Training loss: 3.5948986042350963
Validation loss: 3.285296170660277

Epoch: 6| Step: 12
Training loss: 3.609213028613452
Validation loss: 3.2809166390757145

Epoch: 6| Step: 13
Training loss: 3.980734684289947
Validation loss: 3.277188066642729

Epoch: 42| Step: 0
Training loss: 3.827783437010173
Validation loss: 3.2734160866412534

Epoch: 6| Step: 1
Training loss: 2.980769670926575
Validation loss: 3.2692014101703815

Epoch: 6| Step: 2
Training loss: 2.7987773541932066
Validation loss: 3.2662294306048376

Epoch: 6| Step: 3
Training loss: 3.210652953670953
Validation loss: 3.26248030918459

Epoch: 6| Step: 4
Training loss: 3.3169531489212614
Validation loss: 3.2631940782998745

Epoch: 6| Step: 5
Training loss: 4.103350614691589
Validation loss: 3.271757606749156

Epoch: 6| Step: 6
Training loss: 3.5219051979212233
Validation loss: 3.2521572900476388

Epoch: 6| Step: 7
Training loss: 3.9734072055179315
Validation loss: 3.2482564601997876

Epoch: 6| Step: 8
Training loss: 3.0319727399803393
Validation loss: 3.2474866342991433

Epoch: 6| Step: 9
Training loss: 2.862070949333464
Validation loss: 3.2491022361660713

Epoch: 6| Step: 10
Training loss: 3.4709963011901896
Validation loss: 3.2512137518532467

Epoch: 6| Step: 11
Training loss: 3.143167254394701
Validation loss: 3.249806618439161

Epoch: 6| Step: 12
Training loss: 3.418467597525539
Validation loss: 3.2480522701656747

Epoch: 6| Step: 13
Training loss: 3.599983713325111
Validation loss: 3.2361833612529045

Epoch: 43| Step: 0
Training loss: 2.5878004295897723
Validation loss: 3.228029916500985

Epoch: 6| Step: 1
Training loss: 3.619153536893454
Validation loss: 3.2200949368194296

Epoch: 6| Step: 2
Training loss: 3.580857478761634
Validation loss: 3.2158066955580846

Epoch: 6| Step: 3
Training loss: 3.008686206301395
Validation loss: 3.2115484369592475

Epoch: 6| Step: 4
Training loss: 3.3344763385564122
Validation loss: 3.211747487319364

Epoch: 6| Step: 5
Training loss: 3.1636011611490678
Validation loss: 3.211115464772577

Epoch: 6| Step: 6
Training loss: 3.6528895658753435
Validation loss: 3.2040227856883483

Epoch: 6| Step: 7
Training loss: 2.9386771258198636
Validation loss: 3.198075794812824

Epoch: 6| Step: 8
Training loss: 3.60876327549204
Validation loss: 3.1944642623802624

Epoch: 6| Step: 9
Training loss: 3.65246033507944
Validation loss: 3.1917004552767456

Epoch: 6| Step: 10
Training loss: 3.6841077557190847
Validation loss: 3.1886951225580105

Epoch: 6| Step: 11
Training loss: 2.9224676663296356
Validation loss: 3.185033853970777

Epoch: 6| Step: 12
Training loss: 3.4514748613551998
Validation loss: 3.1825926160258904

Epoch: 6| Step: 13
Training loss: 3.3566888049954144
Validation loss: 3.179760568889884

Epoch: 44| Step: 0
Training loss: 2.7064398577829856
Validation loss: 3.1763243638978627

Epoch: 6| Step: 1
Training loss: 2.699896852854243
Validation loss: 3.1730764083743326

Epoch: 6| Step: 2
Training loss: 3.3489583175129196
Validation loss: 3.1693967210670646

Epoch: 6| Step: 3
Training loss: 3.7437888523945198
Validation loss: 3.1661448341531626

Epoch: 6| Step: 4
Training loss: 3.3628225689423443
Validation loss: 3.162016865863654

Epoch: 6| Step: 5
Training loss: 3.302332406422734
Validation loss: 3.158012024196019

Epoch: 6| Step: 6
Training loss: 3.171416451518148
Validation loss: 3.1547341184429207

Epoch: 6| Step: 7
Training loss: 3.922508644498073
Validation loss: 3.151355713046265

Epoch: 6| Step: 8
Training loss: 3.329513618300463
Validation loss: 3.147809946576772

Epoch: 6| Step: 9
Training loss: 3.5247593195569005
Validation loss: 3.144759813930601

Epoch: 6| Step: 10
Training loss: 3.532657174125435
Validation loss: 3.1399241941862557

Epoch: 6| Step: 11
Training loss: 3.033533710806123
Validation loss: 3.1369575735775417

Epoch: 6| Step: 12
Training loss: 3.304922541924043
Validation loss: 3.1329101902419203

Epoch: 6| Step: 13
Training loss: 2.8731220580428873
Validation loss: 3.1295622520124424

Epoch: 45| Step: 0
Training loss: 4.035617325651266
Validation loss: 3.125434718094934

Epoch: 6| Step: 1
Training loss: 3.1796099679103205
Validation loss: 3.122065870568046

Epoch: 6| Step: 2
Training loss: 3.07339485887465
Validation loss: 3.118251469174863

Epoch: 6| Step: 3
Training loss: 3.1012184086720067
Validation loss: 3.11504694614987

Epoch: 6| Step: 4
Training loss: 3.0319427013367934
Validation loss: 3.111844697012904

Epoch: 6| Step: 5
Training loss: 2.686508439360852
Validation loss: 3.1085905047094

Epoch: 6| Step: 6
Training loss: 3.125053863061194
Validation loss: 3.105968558279028

Epoch: 6| Step: 7
Training loss: 3.5397547030188328
Validation loss: 3.1019299703432863

Epoch: 6| Step: 8
Training loss: 3.252480220749197
Validation loss: 3.0987980306928753

Epoch: 6| Step: 9
Training loss: 3.16250715292623
Validation loss: 3.0952635251387437

Epoch: 6| Step: 10
Training loss: 3.212362822338683
Validation loss: 3.092597631210094

Epoch: 6| Step: 11
Training loss: 3.465715335256804
Validation loss: 3.0890291332140154

Epoch: 6| Step: 12
Training loss: 3.3264924106049754
Validation loss: 3.086219948506043

Epoch: 6| Step: 13
Training loss: 3.074788565461053
Validation loss: 3.083509251155453

Epoch: 46| Step: 0
Training loss: 3.1091084581698154
Validation loss: 3.0805362222873374

Epoch: 6| Step: 1
Training loss: 2.95393320155567
Validation loss: 3.077070930333711

Epoch: 6| Step: 2
Training loss: 3.6771856335177873
Validation loss: 3.0742634596718066

Epoch: 6| Step: 3
Training loss: 2.985233842389906
Validation loss: 3.07089533301144

Epoch: 6| Step: 4
Training loss: 3.611765412613609
Validation loss: 3.0674610437656975

Epoch: 6| Step: 5
Training loss: 3.0210849174881393
Validation loss: 3.0645412596911874

Epoch: 6| Step: 6
Training loss: 3.16888497270173
Validation loss: 3.061111122284428

Epoch: 6| Step: 7
Training loss: 2.8413743376808087
Validation loss: 3.0578867231927442

Epoch: 6| Step: 8
Training loss: 3.567433471487076
Validation loss: 3.0545718145944667

Epoch: 6| Step: 9
Training loss: 2.9686892854605715
Validation loss: 3.051205028060307

Epoch: 6| Step: 10
Training loss: 3.2533078599411978
Validation loss: 3.047867833283228

Epoch: 6| Step: 11
Training loss: 2.9807995853818974
Validation loss: 3.044745067579598

Epoch: 6| Step: 12
Training loss: 3.049231297914068
Validation loss: 3.0414322192271244

Epoch: 6| Step: 13
Training loss: 3.5002366394699083
Validation loss: 3.0383844215700124

Epoch: 47| Step: 0
Training loss: 3.1226875904868807
Validation loss: 3.035999169592897

Epoch: 6| Step: 1
Training loss: 3.4467308256374496
Validation loss: 3.0330263943184548

Epoch: 6| Step: 2
Training loss: 2.8665468087386
Validation loss: 3.0300846809413655

Epoch: 6| Step: 3
Training loss: 3.864030508856842
Validation loss: 3.0269696666977546

Epoch: 6| Step: 4
Training loss: 3.6046013248429527
Validation loss: 3.0244216434366096

Epoch: 6| Step: 5
Training loss: 2.8331594600807626
Validation loss: 3.0205731027697755

Epoch: 6| Step: 6
Training loss: 3.2727450637622804
Validation loss: 3.0173857033950053

Epoch: 6| Step: 7
Training loss: 3.7888996521867426
Validation loss: 3.0147291180295817

Epoch: 6| Step: 8
Training loss: 3.4451162407784715
Validation loss: 3.0109640017684156

Epoch: 6| Step: 9
Training loss: 2.5168099781520037
Validation loss: 3.008402937368311

Epoch: 6| Step: 10
Training loss: 2.680060091056692
Validation loss: 3.0048663089610166

Epoch: 6| Step: 11
Training loss: 2.3224264976277604
Validation loss: 3.0023762907894724

Epoch: 6| Step: 12
Training loss: 3.1804594185490105
Validation loss: 2.9989634683522426

Epoch: 6| Step: 13
Training loss: 2.854856996979983
Validation loss: 2.9968806314796677

Epoch: 48| Step: 0
Training loss: 3.6061854946773724
Validation loss: 2.993777125905319

Epoch: 6| Step: 1
Training loss: 2.9719006333714777
Validation loss: 2.991310170290201

Epoch: 6| Step: 2
Training loss: 3.285543339588738
Validation loss: 2.988167515005232

Epoch: 6| Step: 3
Training loss: 3.200673872804174
Validation loss: 2.9844978533584934

Epoch: 6| Step: 4
Training loss: 2.329033181648184
Validation loss: 2.9825830189144096

Epoch: 6| Step: 5
Training loss: 2.8959664147257866
Validation loss: 2.9806753931033683

Epoch: 6| Step: 6
Training loss: 3.0732215514579653
Validation loss: 2.9780725768720053

Epoch: 6| Step: 7
Training loss: 3.4064451389237242
Validation loss: 2.9745873333320345

Epoch: 6| Step: 8
Training loss: 2.571297036697187
Validation loss: 2.972374132815878

Epoch: 6| Step: 9
Training loss: 2.5995293081149864
Validation loss: 2.97056070622156

Epoch: 6| Step: 10
Training loss: 3.394621150995949
Validation loss: 2.968374101364902

Epoch: 6| Step: 11
Training loss: 3.5679215787471903
Validation loss: 2.9646170508119742

Epoch: 6| Step: 12
Training loss: 2.9577529409531143
Validation loss: 2.9625594260563695

Epoch: 6| Step: 13
Training loss: 3.4771958363600137
Validation loss: 2.960084280584052

Epoch: 49| Step: 0
Training loss: 3.330694218805895
Validation loss: 2.95795603929635

Epoch: 6| Step: 1
Training loss: 3.444594950788844
Validation loss: 2.955440051129117

Epoch: 6| Step: 2
Training loss: 2.7771329088834613
Validation loss: 2.9513706331374094

Epoch: 6| Step: 3
Training loss: 2.434636904298858
Validation loss: 2.948356667471743

Epoch: 6| Step: 4
Training loss: 3.230833021519288
Validation loss: 2.9457700729771834

Epoch: 6| Step: 5
Training loss: 3.238492105243219
Validation loss: 2.9460646177483705

Epoch: 6| Step: 6
Training loss: 3.2462001007322607
Validation loss: 2.941621567341698

Epoch: 6| Step: 7
Training loss: 3.3183363834547825
Validation loss: 2.9387559437823496

Epoch: 6| Step: 8
Training loss: 3.272804654295117
Validation loss: 2.935607679409502

Epoch: 6| Step: 9
Training loss: 2.875233184645876
Validation loss: 2.933047416869925

Epoch: 6| Step: 10
Training loss: 3.077439904823139
Validation loss: 2.931518430151888

Epoch: 6| Step: 11
Training loss: 3.504239920184246
Validation loss: 2.928506706488465

Epoch: 6| Step: 12
Training loss: 2.592739965650235
Validation loss: 2.9258617055617013

Epoch: 6| Step: 13
Training loss: 2.605727976381217
Validation loss: 2.9245333215053604

Epoch: 50| Step: 0
Training loss: 2.748776770682986
Validation loss: 2.922984818533869

Epoch: 6| Step: 1
Training loss: 3.0425095805485136
Validation loss: 2.92137744223484

Epoch: 6| Step: 2
Training loss: 3.2341175806189475
Validation loss: 2.9193157064418664

Epoch: 6| Step: 3
Training loss: 2.9071827693942955
Validation loss: 2.9162120101422917

Epoch: 6| Step: 4
Training loss: 3.1526099639760288
Validation loss: 2.915407608393972

Epoch: 6| Step: 5
Training loss: 3.5618766105395196
Validation loss: 2.913144359883037

Epoch: 6| Step: 6
Training loss: 3.5450111903348924
Validation loss: 2.9094352084935444

Epoch: 6| Step: 7
Training loss: 2.8057285597518304
Validation loss: 2.9069243711736474

Epoch: 6| Step: 8
Training loss: 3.0651871705895988
Validation loss: 2.9054704529881303

Epoch: 6| Step: 9
Training loss: 3.046610815870466
Validation loss: 2.9023944205117633

Epoch: 6| Step: 10
Training loss: 3.6314503074459408
Validation loss: 2.900391556625131

Epoch: 6| Step: 11
Training loss: 2.3914175278186782
Validation loss: 2.896967677143138

Epoch: 6| Step: 12
Training loss: 2.8282189116508003
Validation loss: 2.8931340506112595

Epoch: 6| Step: 13
Training loss: 2.4621263327022915
Validation loss: 2.890875686909999

Epoch: 51| Step: 0
Training loss: 3.0217635377763865
Validation loss: 2.889017280044541

Epoch: 6| Step: 1
Training loss: 3.148757047505232
Validation loss: 2.883864985128738

Epoch: 6| Step: 2
Training loss: 2.742603933334896
Validation loss: 2.8813870014710092

Epoch: 6| Step: 3
Training loss: 2.8490366997596133
Validation loss: 2.8802448888922676

Epoch: 6| Step: 4
Training loss: 2.967661447222717
Validation loss: 2.877296138980273

Epoch: 6| Step: 5
Training loss: 2.8769385395081732
Validation loss: 2.87599571234605

Epoch: 6| Step: 6
Training loss: 3.4199464144607883
Validation loss: 2.8758399538022728

Epoch: 6| Step: 7
Training loss: 2.83274623921705
Validation loss: 2.8745296687874697

Epoch: 6| Step: 8
Training loss: 2.608009117947185
Validation loss: 2.8768623373982383

Epoch: 6| Step: 9
Training loss: 3.4110289480590854
Validation loss: 2.881942741873569

Epoch: 6| Step: 10
Training loss: 3.4162296077651444
Validation loss: 2.87464823851432

Epoch: 6| Step: 11
Training loss: 2.6116279424228015
Validation loss: 2.866425152149053

Epoch: 6| Step: 12
Training loss: 3.1540741927492286
Validation loss: 2.8597582228485368

Epoch: 6| Step: 13
Training loss: 3.0127201617188324
Validation loss: 2.8596986681245182

Epoch: 52| Step: 0
Training loss: 3.1088895946002286
Validation loss: 2.859204341055021

Epoch: 6| Step: 1
Training loss: 2.895839297793899
Validation loss: 2.860525097960088

Epoch: 6| Step: 2
Training loss: 2.7926771318475287
Validation loss: 2.8593564753809586

Epoch: 6| Step: 3
Training loss: 2.4963783734683545
Validation loss: 2.860910652961095

Epoch: 6| Step: 4
Training loss: 2.411556387460161
Validation loss: 2.8639053975922515

Epoch: 6| Step: 5
Training loss: 2.9657172523355597
Validation loss: 2.861477716243953

Epoch: 6| Step: 6
Training loss: 3.3988960044508962
Validation loss: 2.8621085325420075

Epoch: 6| Step: 7
Training loss: 3.736104269545356
Validation loss: 2.853932897828151

Epoch: 6| Step: 8
Training loss: 2.7272918512656434
Validation loss: 2.8486237872894753

Epoch: 6| Step: 9
Training loss: 2.992271003852767
Validation loss: 2.8440866655315697

Epoch: 6| Step: 10
Training loss: 3.548733934108785
Validation loss: 2.841401020807757

Epoch: 6| Step: 11
Training loss: 3.259111397051146
Validation loss: 2.837990878269052

Epoch: 6| Step: 12
Training loss: 2.3452304487723845
Validation loss: 2.834352567079956

Epoch: 6| Step: 13
Training loss: 2.8686978470460223
Validation loss: 2.8316953402843663

Epoch: 53| Step: 0
Training loss: 3.1304944373634145
Validation loss: 2.82896896892567

Epoch: 6| Step: 1
Training loss: 2.7386362931270583
Validation loss: 2.826071441489789

Epoch: 6| Step: 2
Training loss: 3.187040108808072
Validation loss: 2.8254147042355466

Epoch: 6| Step: 3
Training loss: 3.0362284569508025
Validation loss: 2.8231613550497827

Epoch: 6| Step: 4
Training loss: 2.460297128829704
Validation loss: 2.8201376173019725

Epoch: 6| Step: 5
Training loss: 3.165994991209366
Validation loss: 2.817970649134108

Epoch: 6| Step: 6
Training loss: 3.1482993727454964
Validation loss: 2.8174489313804227

Epoch: 6| Step: 7
Training loss: 3.292682313962085
Validation loss: 2.8127846044016005

Epoch: 6| Step: 8
Training loss: 2.5145772327600877
Validation loss: 2.8114262544531585

Epoch: 6| Step: 9
Training loss: 2.776104743245685
Validation loss: 2.809512621627927

Epoch: 6| Step: 10
Training loss: 2.578301256108086
Validation loss: 2.8088903646307637

Epoch: 6| Step: 11
Training loss: 3.3090021631228588
Validation loss: 2.8084087567336913

Epoch: 6| Step: 12
Training loss: 3.3461882355910304
Validation loss: 2.805630241214091

Epoch: 6| Step: 13
Training loss: 2.534643371145215
Validation loss: 2.804287229291912

Epoch: 54| Step: 0
Training loss: 3.4159392691312687
Validation loss: 2.8028228568577127

Epoch: 6| Step: 1
Training loss: 2.505062318434071
Validation loss: 2.8007005212588987

Epoch: 6| Step: 2
Training loss: 2.7995323471814073
Validation loss: 2.79951072970791

Epoch: 6| Step: 3
Training loss: 3.6382534177574453
Validation loss: 2.797273845400391

Epoch: 6| Step: 4
Training loss: 2.917666908595661
Validation loss: 2.796277797596617

Epoch: 6| Step: 5
Training loss: 3.0473147343938893
Validation loss: 2.793748027507817

Epoch: 6| Step: 6
Training loss: 2.7467108910744007
Validation loss: 2.7928880230812374

Epoch: 6| Step: 7
Training loss: 2.6539507619894174
Validation loss: 2.7891660897245134

Epoch: 6| Step: 8
Training loss: 3.4092150740697846
Validation loss: 2.7863053229321615

Epoch: 6| Step: 9
Training loss: 2.9955923762575547
Validation loss: 2.78544481805819

Epoch: 6| Step: 10
Training loss: 2.614892847553607
Validation loss: 2.7829300167538196

Epoch: 6| Step: 11
Training loss: 2.36377966803174
Validation loss: 2.782110659701389

Epoch: 6| Step: 12
Training loss: 2.8230389970875622
Validation loss: 2.7810060058322232

Epoch: 6| Step: 13
Training loss: 2.870011687570626
Validation loss: 2.7786538369165696

Epoch: 55| Step: 0
Training loss: 3.251657210166342
Validation loss: 2.776123723194475

Epoch: 6| Step: 1
Training loss: 2.615667921144818
Validation loss: 2.7737248804629098

Epoch: 6| Step: 2
Training loss: 3.0278770321628676
Validation loss: 2.774024650496292

Epoch: 6| Step: 3
Training loss: 3.446359349931441
Validation loss: 2.772456580401942

Epoch: 6| Step: 4
Training loss: 2.685471412292038
Validation loss: 2.768017095347628

Epoch: 6| Step: 5
Training loss: 3.4003882410872603
Validation loss: 2.7669078057309457

Epoch: 6| Step: 6
Training loss: 2.8147240216501155
Validation loss: 2.766153633472035

Epoch: 6| Step: 7
Training loss: 2.689636711774827
Validation loss: 2.7635752810434795

Epoch: 6| Step: 8
Training loss: 2.947387773676129
Validation loss: 2.7608611894563424

Epoch: 6| Step: 9
Training loss: 3.230398045865092
Validation loss: 2.7588981386300113

Epoch: 6| Step: 10
Training loss: 2.4004843858824065
Validation loss: 2.75804442672319

Epoch: 6| Step: 11
Training loss: 2.4083952815482426
Validation loss: 2.7549858988997005

Epoch: 6| Step: 12
Training loss: 2.788334428232559
Validation loss: 2.7551402400255136

Epoch: 6| Step: 13
Training loss: 2.734806397331224
Validation loss: 2.754630741566761

Epoch: 56| Step: 0
Training loss: 2.6061783815053
Validation loss: 2.752371993268722

Epoch: 6| Step: 1
Training loss: 2.1108871126408517
Validation loss: 2.750337767809841

Epoch: 6| Step: 2
Training loss: 3.660297989518109
Validation loss: 2.7486382783208225

Epoch: 6| Step: 3
Training loss: 2.6879045048962222
Validation loss: 2.748770012475485

Epoch: 6| Step: 4
Training loss: 2.7671382234085686
Validation loss: 2.7456042675124452

Epoch: 6| Step: 5
Training loss: 3.038682457860958
Validation loss: 2.7455137968942287

Epoch: 6| Step: 6
Training loss: 2.0009536853560457
Validation loss: 2.7425339671013282

Epoch: 6| Step: 7
Training loss: 2.931492770619907
Validation loss: 2.742015532547214

Epoch: 6| Step: 8
Training loss: 2.947665865488392
Validation loss: 2.740056092600019

Epoch: 6| Step: 9
Training loss: 3.277501171818923
Validation loss: 2.737743693149206

Epoch: 6| Step: 10
Training loss: 3.1534284311462226
Validation loss: 2.737017606156178

Epoch: 6| Step: 11
Training loss: 3.3478667683770977
Validation loss: 2.7356590961565206

Epoch: 6| Step: 12
Training loss: 3.2093974408903847
Validation loss: 2.7362169873514652

Epoch: 6| Step: 13
Training loss: 2.117679665429773
Validation loss: 2.732893129892878

Epoch: 57| Step: 0
Training loss: 2.4294005589456966
Validation loss: 2.7306438529971113

Epoch: 6| Step: 1
Training loss: 2.6308229439640733
Validation loss: 2.7291220644346836

Epoch: 6| Step: 2
Training loss: 2.6785537501160475
Validation loss: 2.7269619682783186

Epoch: 6| Step: 3
Training loss: 2.79670049879535
Validation loss: 2.7266420864669927

Epoch: 6| Step: 4
Training loss: 3.309607916714294
Validation loss: 2.723592968295156

Epoch: 6| Step: 5
Training loss: 2.9525158773668796
Validation loss: 2.7229510913434694

Epoch: 6| Step: 6
Training loss: 2.979650462600011
Validation loss: 2.723950669889933

Epoch: 6| Step: 7
Training loss: 2.3009533647754226
Validation loss: 2.7195715558152727

Epoch: 6| Step: 8
Training loss: 3.04769870676656
Validation loss: 2.721440960292463

Epoch: 6| Step: 9
Training loss: 2.8484210542757555
Validation loss: 2.7176730043379544

Epoch: 6| Step: 10
Training loss: 2.758450442437527
Validation loss: 2.7172499278236386

Epoch: 6| Step: 11
Training loss: 2.8206895063763815
Validation loss: 2.7145670871048413

Epoch: 6| Step: 12
Training loss: 3.3615539581312293
Validation loss: 2.7149361135016057

Epoch: 6| Step: 13
Training loss: 2.98907819106694
Validation loss: 2.7125886841089426

Epoch: 58| Step: 0
Training loss: 2.7933928907899213
Validation loss: 2.7135985082333964

Epoch: 6| Step: 1
Training loss: 3.225749580743368
Validation loss: 2.7192778093274956

Epoch: 6| Step: 2
Training loss: 2.7559354191703136
Validation loss: 2.707292655151077

Epoch: 6| Step: 3
Training loss: 2.9358951161539544
Validation loss: 2.706174449732397

Epoch: 6| Step: 4
Training loss: 2.183708501813448
Validation loss: 2.704554273650709

Epoch: 6| Step: 5
Training loss: 3.24381753781373
Validation loss: 2.704597439617237

Epoch: 6| Step: 6
Training loss: 3.1866971669140707
Validation loss: 2.7023148250511455

Epoch: 6| Step: 7
Training loss: 3.1484599148163026
Validation loss: 2.700985100081868

Epoch: 6| Step: 8
Training loss: 2.381911811073706
Validation loss: 2.6982245742088597

Epoch: 6| Step: 9
Training loss: 2.96937297508638
Validation loss: 2.698288929907521

Epoch: 6| Step: 10
Training loss: 3.1501115082879902
Validation loss: 2.698003927069149

Epoch: 6| Step: 11
Training loss: 2.52939490640139
Validation loss: 2.695055550384331

Epoch: 6| Step: 12
Training loss: 2.452419300987587
Validation loss: 2.6949360607632933

Epoch: 6| Step: 13
Training loss: 2.5884093488087876
Validation loss: 2.699179988128241

Epoch: 59| Step: 0
Training loss: 2.89264999805204
Validation loss: 2.7082472176187884

Epoch: 6| Step: 1
Training loss: 2.8020987717062553
Validation loss: 2.705886987973249

Epoch: 6| Step: 2
Training loss: 3.208937567417676
Validation loss: 2.7351095030515435

Epoch: 6| Step: 3
Training loss: 2.8248855837717333
Validation loss: 2.7172185450384094

Epoch: 6| Step: 4
Training loss: 2.8116440212179743
Validation loss: 2.7035110286193498

Epoch: 6| Step: 5
Training loss: 2.837398100380259
Validation loss: 2.6848133319915877

Epoch: 6| Step: 6
Training loss: 2.8748157276309856
Validation loss: 2.6847029036065693

Epoch: 6| Step: 7
Training loss: 2.6689069000505983
Validation loss: 2.6848785567567988

Epoch: 6| Step: 8
Training loss: 2.9339474237538004
Validation loss: 2.6860193121379865

Epoch: 6| Step: 9
Training loss: 3.0280529348264107
Validation loss: 2.685868588684784

Epoch: 6| Step: 10
Training loss: 3.0675253605746367
Validation loss: 2.687442808503779

Epoch: 6| Step: 11
Training loss: 2.6484189553300777
Validation loss: 2.6900722702415107

Epoch: 6| Step: 12
Training loss: 2.667077112399701
Validation loss: 2.6945244046982664

Epoch: 6| Step: 13
Training loss: 2.54174006204997
Validation loss: 2.6976520943740843

Epoch: 60| Step: 0
Training loss: 2.47111031414876
Validation loss: 2.6897784931777284

Epoch: 6| Step: 1
Training loss: 3.1211716662481783
Validation loss: 2.6872790785482654

Epoch: 6| Step: 2
Training loss: 3.2007024768822263
Validation loss: 2.6832243893307828

Epoch: 6| Step: 3
Training loss: 2.6677632064170718
Validation loss: 2.6803138823815313

Epoch: 6| Step: 4
Training loss: 2.932038119496349
Validation loss: 2.6774684218376783

Epoch: 6| Step: 5
Training loss: 2.219484019758837
Validation loss: 2.6761349038264477

Epoch: 6| Step: 6
Training loss: 3.20255821609888
Validation loss: 2.6772621827306247

Epoch: 6| Step: 7
Training loss: 2.77479025933067
Validation loss: 2.6803470611745728

Epoch: 6| Step: 8
Training loss: 3.044709203705969
Validation loss: 2.675522201881309

Epoch: 6| Step: 9
Training loss: 3.0876331933825045
Validation loss: 2.677281752084577

Epoch: 6| Step: 10
Training loss: 2.810169950212686
Validation loss: 2.6779863984168766

Epoch: 6| Step: 11
Training loss: 2.610208161336527
Validation loss: 2.6689669304260795

Epoch: 6| Step: 12
Training loss: 2.0253196416939954
Validation loss: 2.666706879630472

Epoch: 6| Step: 13
Training loss: 2.9970634711452546
Validation loss: 2.6645696610335348

Epoch: 61| Step: 0
Training loss: 2.972756663567695
Validation loss: 2.661669837823968

Epoch: 6| Step: 1
Training loss: 3.1645249770515798
Validation loss: 2.6644759020549293

Epoch: 6| Step: 2
Training loss: 2.384596860070606
Validation loss: 2.6646934798686432

Epoch: 6| Step: 3
Training loss: 2.8774774906129803
Validation loss: 2.662327623831716

Epoch: 6| Step: 4
Training loss: 3.0261932352596634
Validation loss: 2.6614678986757587

Epoch: 6| Step: 5
Training loss: 3.1281164270182535
Validation loss: 2.661968732194049

Epoch: 6| Step: 6
Training loss: 2.868467123342241
Validation loss: 2.6591720665000507

Epoch: 6| Step: 7
Training loss: 2.590923009649486
Validation loss: 2.6574449282394874

Epoch: 6| Step: 8
Training loss: 2.7565780340642894
Validation loss: 2.655365920201209

Epoch: 6| Step: 9
Training loss: 2.849991206105368
Validation loss: 2.652936491842493

Epoch: 6| Step: 10
Training loss: 2.907224430266685
Validation loss: 2.651847377168423

Epoch: 6| Step: 11
Training loss: 2.613718860063083
Validation loss: 2.650675590336373

Epoch: 6| Step: 12
Training loss: 2.536415668940758
Validation loss: 2.647385109631988

Epoch: 6| Step: 13
Training loss: 2.360001638702858
Validation loss: 2.647990381238741

Epoch: 62| Step: 0
Training loss: 3.0689399116627363
Validation loss: 2.645718449378727

Epoch: 6| Step: 1
Training loss: 2.6580002347832683
Validation loss: 2.643513786639286

Epoch: 6| Step: 2
Training loss: 3.0205108119630273
Validation loss: 2.6441412243208635

Epoch: 6| Step: 3
Training loss: 2.9310348464315625
Validation loss: 2.643440581387302

Epoch: 6| Step: 4
Training loss: 2.5932012689921864
Validation loss: 2.645019741573587

Epoch: 6| Step: 5
Training loss: 3.0504184560914234
Validation loss: 2.6459860319594015

Epoch: 6| Step: 6
Training loss: 2.9497305924842196
Validation loss: 2.647723458957493

Epoch: 6| Step: 7
Training loss: 2.814977783603305
Validation loss: 2.639890203625113

Epoch: 6| Step: 8
Training loss: 2.334087545117776
Validation loss: 2.6411483516892993

Epoch: 6| Step: 9
Training loss: 2.608540475763466
Validation loss: 2.641051910622058

Epoch: 6| Step: 10
Training loss: 2.441471288196203
Validation loss: 2.6339499321072175

Epoch: 6| Step: 11
Training loss: 3.1539598975864447
Validation loss: 2.626414069513327

Epoch: 6| Step: 12
Training loss: 2.5829703373344812
Validation loss: 2.6315250437218474

Epoch: 6| Step: 13
Training loss: 2.6325563934458938
Validation loss: 2.6320272419794155

Epoch: 63| Step: 0
Training loss: 2.501175318055328
Validation loss: 2.633677535759783

Epoch: 6| Step: 1
Training loss: 2.84727979979151
Validation loss: 2.6347777958073464

Epoch: 6| Step: 2
Training loss: 3.112823873927462
Validation loss: 2.6377783485325565

Epoch: 6| Step: 3
Training loss: 2.5491103209742247
Validation loss: 2.6392879976215635

Epoch: 6| Step: 4
Training loss: 2.774802889997526
Validation loss: 2.639036524697323

Epoch: 6| Step: 5
Training loss: 3.2990186330240756
Validation loss: 2.640560126777429

Epoch: 6| Step: 6
Training loss: 2.385458755677117
Validation loss: 2.638039792524007

Epoch: 6| Step: 7
Training loss: 2.6867571846580263
Validation loss: 2.6393874087905025

Epoch: 6| Step: 8
Training loss: 2.2970747049927183
Validation loss: 2.6377943167006834

Epoch: 6| Step: 9
Training loss: 2.5959983181352855
Validation loss: 2.6349759292468242

Epoch: 6| Step: 10
Training loss: 2.7003847907638048
Validation loss: 2.6316866858914576

Epoch: 6| Step: 11
Training loss: 2.476919443298241
Validation loss: 2.6302029197309826

Epoch: 6| Step: 12
Training loss: 3.025648782057852
Validation loss: 2.6295092619951452

Epoch: 6| Step: 13
Training loss: 3.318890291686291
Validation loss: 2.627063326314502

Epoch: 64| Step: 0
Training loss: 2.3467590344016265
Validation loss: 2.6264056120883126

Epoch: 6| Step: 1
Training loss: 3.2747839295839696
Validation loss: 2.622031455814666

Epoch: 6| Step: 2
Training loss: 2.6067737702547817
Validation loss: 2.6197624331310108

Epoch: 6| Step: 3
Training loss: 2.883457845597689
Validation loss: 2.6184574519151984

Epoch: 6| Step: 4
Training loss: 2.6263531421595885
Validation loss: 2.6178677562091313

Epoch: 6| Step: 5
Training loss: 2.7852263582241625
Validation loss: 2.6155930402072474

Epoch: 6| Step: 6
Training loss: 2.3260291990249815
Validation loss: 2.6141016213696497

Epoch: 6| Step: 7
Training loss: 2.5613207080588816
Validation loss: 2.6133846914425183

Epoch: 6| Step: 8
Training loss: 2.861946992054037
Validation loss: 2.6102479095182685

Epoch: 6| Step: 9
Training loss: 3.185731434577371
Validation loss: 2.611178271859299

Epoch: 6| Step: 10
Training loss: 2.801479364322205
Validation loss: 2.609644824485214

Epoch: 6| Step: 11
Training loss: 3.0710401764716346
Validation loss: 2.608902985602244

Epoch: 6| Step: 12
Training loss: 2.1220262701078494
Validation loss: 2.6080305401080706

Epoch: 6| Step: 13
Training loss: 2.8438485935432722
Validation loss: 2.6074726533172

Epoch: 65| Step: 0
Training loss: 2.9441947131346624
Validation loss: 2.6053151357529973

Epoch: 6| Step: 1
Training loss: 2.584162168953024
Validation loss: 2.6061325790824696

Epoch: 6| Step: 2
Training loss: 2.5370468824999444
Validation loss: 2.60002513897798

Epoch: 6| Step: 3
Training loss: 3.0444567351390934
Validation loss: 2.6132817061670472

Epoch: 6| Step: 4
Training loss: 2.720101645337545
Validation loss: 2.614847288954678

Epoch: 6| Step: 5
Training loss: 2.9678605202755164
Validation loss: 2.6047557673120876

Epoch: 6| Step: 6
Training loss: 2.5219897200384733
Validation loss: 2.597812626847591

Epoch: 6| Step: 7
Training loss: 2.743757097587008
Validation loss: 2.596392882175471

Epoch: 6| Step: 8
Training loss: 3.084395629442789
Validation loss: 2.5986766216566273

Epoch: 6| Step: 9
Training loss: 2.732152329757041
Validation loss: 2.601292073931359

Epoch: 6| Step: 10
Training loss: 2.69129409888566
Validation loss: 2.603818402209098

Epoch: 6| Step: 11
Training loss: 2.8106680095724896
Validation loss: 2.6031361842592573

Epoch: 6| Step: 12
Training loss: 2.2576101667828157
Validation loss: 2.603445385545623

Epoch: 6| Step: 13
Training loss: 2.694903887307024
Validation loss: 2.6016625431898905

Epoch: 66| Step: 0
Training loss: 3.075686655680429
Validation loss: 2.6036895060490046

Epoch: 6| Step: 1
Training loss: 2.8229694901107143
Validation loss: 2.6029247577855554

Epoch: 6| Step: 2
Training loss: 2.779526165573665
Validation loss: 2.6022353576605894

Epoch: 6| Step: 3
Training loss: 2.6594564494873705
Validation loss: 2.6029377186461606

Epoch: 6| Step: 4
Training loss: 2.663175642225419
Validation loss: 2.602291978626285

Epoch: 6| Step: 5
Training loss: 3.046491549889775
Validation loss: 2.6002881782945964

Epoch: 6| Step: 6
Training loss: 3.31081952347953
Validation loss: 2.599998064835146

Epoch: 6| Step: 7
Training loss: 2.5968289771747264
Validation loss: 2.597449043442319

Epoch: 6| Step: 8
Training loss: 2.3726177314191554
Validation loss: 2.5948503603755046

Epoch: 6| Step: 9
Training loss: 2.82208804723561
Validation loss: 2.5927902805430247

Epoch: 6| Step: 10
Training loss: 2.161803350526795
Validation loss: 2.5921243835822283

Epoch: 6| Step: 11
Training loss: 2.7070138113277586
Validation loss: 2.5909218440535438

Epoch: 6| Step: 12
Training loss: 2.4877366648283927
Validation loss: 2.5908584256417706

Epoch: 6| Step: 13
Training loss: 2.630866443650025
Validation loss: 2.5934971912153832

Epoch: 67| Step: 0
Training loss: 2.8245496542832664
Validation loss: 2.594597965107535

Epoch: 6| Step: 1
Training loss: 2.569076844001226
Validation loss: 2.595463642432787

Epoch: 6| Step: 2
Training loss: 2.6070372565694404
Validation loss: 2.592047519441534

Epoch: 6| Step: 3
Training loss: 2.793109255370968
Validation loss: 2.5897813638928135

Epoch: 6| Step: 4
Training loss: 2.4123487593132253
Validation loss: 2.584014484886537

Epoch: 6| Step: 5
Training loss: 2.8191666322671103
Validation loss: 2.5851528671486914

Epoch: 6| Step: 6
Training loss: 2.7618537664794984
Validation loss: 2.584130569209171

Epoch: 6| Step: 7
Training loss: 2.2392397121624543
Validation loss: 2.581516170248373

Epoch: 6| Step: 8
Training loss: 2.684518979422367
Validation loss: 2.58092731801913

Epoch: 6| Step: 9
Training loss: 2.8529126459086593
Validation loss: 2.5808556785843786

Epoch: 6| Step: 10
Training loss: 2.5827720606615645
Validation loss: 2.5802688932389635

Epoch: 6| Step: 11
Training loss: 2.6909751602211505
Validation loss: 2.5812392489353333

Epoch: 6| Step: 12
Training loss: 3.1490175077376255
Validation loss: 2.578802971369043

Epoch: 6| Step: 13
Training loss: 3.0257351447034413
Validation loss: 2.5784784248163977

Epoch: 68| Step: 0
Training loss: 3.101919158492096
Validation loss: 2.577452014978396

Epoch: 6| Step: 1
Training loss: 2.7416669128634297
Validation loss: 2.5774928387191847

Epoch: 6| Step: 2
Training loss: 2.84699541961548
Validation loss: 2.5750599375788945

Epoch: 6| Step: 3
Training loss: 2.7670303481036598
Validation loss: 2.575194263228992

Epoch: 6| Step: 4
Training loss: 2.8327366443710056
Validation loss: 2.571919411406732

Epoch: 6| Step: 5
Training loss: 2.57805989501129
Validation loss: 2.5733042488118114

Epoch: 6| Step: 6
Training loss: 3.1139713226154297
Validation loss: 2.574670762553514

Epoch: 6| Step: 7
Training loss: 2.4620759782881945
Validation loss: 2.5707458780046606

Epoch: 6| Step: 8
Training loss: 2.798998490104527
Validation loss: 2.567294388548563

Epoch: 6| Step: 9
Training loss: 2.6066092264167104
Validation loss: 2.5686165761831625

Epoch: 6| Step: 10
Training loss: 2.0011383631661146
Validation loss: 2.566188375281561

Epoch: 6| Step: 11
Training loss: 2.5859889460398953
Validation loss: 2.5669149652327716

Epoch: 6| Step: 12
Training loss: 2.6964485759588532
Validation loss: 2.5646756325750037

Epoch: 6| Step: 13
Training loss: 2.6682144878479357
Validation loss: 2.5641592747884765

Epoch: 69| Step: 0
Training loss: 2.3930089694985655
Validation loss: 2.5656952049571657

Epoch: 6| Step: 1
Training loss: 3.146285540350083
Validation loss: 2.5663993444403066

Epoch: 6| Step: 2
Training loss: 2.695901203824289
Validation loss: 2.563941441602716

Epoch: 6| Step: 3
Training loss: 2.7623556177029025
Validation loss: 2.5621438127783533

Epoch: 6| Step: 4
Training loss: 3.3155296434214323
Validation loss: 2.5659607259114

Epoch: 6| Step: 5
Training loss: 2.409600241655234
Validation loss: 2.5649922354557733

Epoch: 6| Step: 6
Training loss: 2.3979256049508004
Validation loss: 2.5702119631753364

Epoch: 6| Step: 7
Training loss: 2.320555703104262
Validation loss: 2.569369111087985

Epoch: 6| Step: 8
Training loss: 2.74042212889165
Validation loss: 2.569482392955898

Epoch: 6| Step: 9
Training loss: 2.909522234574585
Validation loss: 2.5698472426123193

Epoch: 6| Step: 10
Training loss: 2.335525323232747
Validation loss: 2.571798727790266

Epoch: 6| Step: 11
Training loss: 2.4519723504640476
Validation loss: 2.5698729258043294

Epoch: 6| Step: 12
Training loss: 2.9313201830825424
Validation loss: 2.5688454906476488

Epoch: 6| Step: 13
Training loss: 2.8576269591154437
Validation loss: 2.5671779144040046

Epoch: 70| Step: 0
Training loss: 2.522102309787443
Validation loss: 2.565431019570061

Epoch: 6| Step: 1
Training loss: 2.8240610503386856
Validation loss: 2.564002162758862

Epoch: 6| Step: 2
Training loss: 2.6399143323581433
Validation loss: 2.5624215493947857

Epoch: 6| Step: 3
Training loss: 2.8923895321706836
Validation loss: 2.5580005996818724

Epoch: 6| Step: 4
Training loss: 2.7750738769869887
Validation loss: 2.5597450209336117

Epoch: 6| Step: 5
Training loss: 2.721378239916076
Validation loss: 2.557597502673587

Epoch: 6| Step: 6
Training loss: 2.865097240242453
Validation loss: 2.553407276351137

Epoch: 6| Step: 7
Training loss: 2.4263500584876954
Validation loss: 2.554799022048565

Epoch: 6| Step: 8
Training loss: 3.2460398388366927
Validation loss: 2.554206888484749

Epoch: 6| Step: 9
Training loss: 2.494084798954318
Validation loss: 2.552204118841669

Epoch: 6| Step: 10
Training loss: 3.12936340878433
Validation loss: 2.55372184522547

Epoch: 6| Step: 11
Training loss: 2.489933154269796
Validation loss: 2.5506588963464862

Epoch: 6| Step: 12
Training loss: 1.9452594305559214
Validation loss: 2.5495370164074136

Epoch: 6| Step: 13
Training loss: 2.3780524063559842
Validation loss: 2.553249487143477

Epoch: 71| Step: 0
Training loss: 2.5955023303990568
Validation loss: 2.551581809661303

Epoch: 6| Step: 1
Training loss: 2.6680415801221122
Validation loss: 2.5723324214031873

Epoch: 6| Step: 2
Training loss: 2.784676145287071
Validation loss: 2.556899595537842

Epoch: 6| Step: 3
Training loss: 2.8105394099536025
Validation loss: 2.546810032302607

Epoch: 6| Step: 4
Training loss: 3.0719052131851243
Validation loss: 2.545180226872545

Epoch: 6| Step: 5
Training loss: 2.4781415941180693
Validation loss: 2.5464786306918086

Epoch: 6| Step: 6
Training loss: 2.673882694955378
Validation loss: 2.5469527125447713

Epoch: 6| Step: 7
Training loss: 2.636079204845475
Validation loss: 2.5456569231746045

Epoch: 6| Step: 8
Training loss: 2.4675889000922333
Validation loss: 2.5444804755643853

Epoch: 6| Step: 9
Training loss: 2.5227818065313294
Validation loss: 2.543912385323534

Epoch: 6| Step: 10
Training loss: 2.8274257069346427
Validation loss: 2.545706997955718

Epoch: 6| Step: 11
Training loss: 2.815333824894174
Validation loss: 2.543025963955609

Epoch: 6| Step: 12
Training loss: 2.9673342892946573
Validation loss: 2.543321904331324

Epoch: 6| Step: 13
Training loss: 2.3131416049331386
Validation loss: 2.5457211242354774

Epoch: 72| Step: 0
Training loss: 2.5967074159975887
Validation loss: 2.5440313928724487

Epoch: 6| Step: 1
Training loss: 2.9618205261050883
Validation loss: 2.541232092763464

Epoch: 6| Step: 2
Training loss: 3.1191508675767174
Validation loss: 2.5443488232396687

Epoch: 6| Step: 3
Training loss: 2.345990750150665
Validation loss: 2.542425938580655

Epoch: 6| Step: 4
Training loss: 2.900276854881433
Validation loss: 2.541200913034767

Epoch: 6| Step: 5
Training loss: 2.841398839177853
Validation loss: 2.5420254365532258

Epoch: 6| Step: 6
Training loss: 2.6700584080911804
Validation loss: 2.540519507588698

Epoch: 6| Step: 7
Training loss: 2.3709207939905865
Validation loss: 2.5403293285859716

Epoch: 6| Step: 8
Training loss: 2.450466099991643
Validation loss: 2.539220435292365

Epoch: 6| Step: 9
Training loss: 2.234796871026209
Validation loss: 2.539642565075347

Epoch: 6| Step: 10
Training loss: 2.8089804774387157
Validation loss: 2.537917308286432

Epoch: 6| Step: 11
Training loss: 2.9081475410760205
Validation loss: 2.5414978085901874

Epoch: 6| Step: 12
Training loss: 2.455157755893344
Validation loss: 2.5394860799525216

Epoch: 6| Step: 13
Training loss: 2.5653927919822612
Validation loss: 2.5371097822142508

Epoch: 73| Step: 0
Training loss: 2.249321623367886
Validation loss: 2.537807275617734

Epoch: 6| Step: 1
Training loss: 2.5946870512963676
Validation loss: 2.534069766954157

Epoch: 6| Step: 2
Training loss: 3.1959195108411897
Validation loss: 2.540046430824208

Epoch: 6| Step: 3
Training loss: 3.1386730903855766
Validation loss: 2.540885904389043

Epoch: 6| Step: 4
Training loss: 2.4499463912392634
Validation loss: 2.53561707527139

Epoch: 6| Step: 5
Training loss: 2.5043661138625843
Validation loss: 2.531663256532617

Epoch: 6| Step: 6
Training loss: 2.583068916160536
Validation loss: 2.5351968300603067

Epoch: 6| Step: 7
Training loss: 2.283205631147042
Validation loss: 2.539626801212403

Epoch: 6| Step: 8
Training loss: 2.753327177593502
Validation loss: 2.5381995509963553

Epoch: 6| Step: 9
Training loss: 2.4431934864499465
Validation loss: 2.540441441835642

Epoch: 6| Step: 10
Training loss: 2.697974794760704
Validation loss: 2.5352334283602422

Epoch: 6| Step: 11
Training loss: 2.891334570321148
Validation loss: 2.533264473138179

Epoch: 6| Step: 12
Training loss: 2.619801778502064
Validation loss: 2.5346791308730494

Epoch: 6| Step: 13
Training loss: 2.9023818659172793
Validation loss: 2.5337936901208176

Epoch: 74| Step: 0
Training loss: 2.340863701295313
Validation loss: 2.5330454498607966

Epoch: 6| Step: 1
Training loss: 2.4912934328878245
Validation loss: 2.530056660360716

Epoch: 6| Step: 2
Training loss: 2.8073985139026907
Validation loss: 2.532864107001948

Epoch: 6| Step: 3
Training loss: 2.908914636559995
Validation loss: 2.531160502166318

Epoch: 6| Step: 4
Training loss: 2.547568197638417
Validation loss: 2.5360001627383495

Epoch: 6| Step: 5
Training loss: 3.068915828411956
Validation loss: 2.5238843823309023

Epoch: 6| Step: 6
Training loss: 2.6213445188174385
Validation loss: 2.527333829016181

Epoch: 6| Step: 7
Training loss: 2.380532897145017
Validation loss: 2.525925440260993

Epoch: 6| Step: 8
Training loss: 2.451505964999768
Validation loss: 2.5323441420881765

Epoch: 6| Step: 9
Training loss: 2.2588779351166446
Validation loss: 2.5355463966984684

Epoch: 6| Step: 10
Training loss: 2.784186024359239
Validation loss: 2.5239152406883343

Epoch: 6| Step: 11
Training loss: 2.675528008944767
Validation loss: 2.5268218785508925

Epoch: 6| Step: 12
Training loss: 2.798803250827185
Validation loss: 2.5218409003781077

Epoch: 6| Step: 13
Training loss: 3.0695910200638363
Validation loss: 2.5279289405348315

Epoch: 75| Step: 0
Training loss: 2.6634761578964548
Validation loss: 2.5272450101058945

Epoch: 6| Step: 1
Training loss: 2.8448056787187435
Validation loss: 2.523712521142965

Epoch: 6| Step: 2
Training loss: 3.054625059304282
Validation loss: 2.5261069430277323

Epoch: 6| Step: 3
Training loss: 2.402822555340363
Validation loss: 2.5253412802926003

Epoch: 6| Step: 4
Training loss: 2.867905861984163
Validation loss: 2.5259611818266188

Epoch: 6| Step: 5
Training loss: 2.6579622920557
Validation loss: 2.527496521944545

Epoch: 6| Step: 6
Training loss: 2.8170518280721564
Validation loss: 2.527258437700293

Epoch: 6| Step: 7
Training loss: 2.490779562716783
Validation loss: 2.5258502586181115

Epoch: 6| Step: 8
Training loss: 2.70906507926041
Validation loss: 2.5302678310224698

Epoch: 6| Step: 9
Training loss: 2.4387868760926925
Validation loss: 2.523423185987

Epoch: 6| Step: 10
Training loss: 2.882692246655585
Validation loss: 2.5214495943341366

Epoch: 6| Step: 11
Training loss: 2.340642165565446
Validation loss: 2.522781617518877

Epoch: 6| Step: 12
Training loss: 2.42773211625624
Validation loss: 2.523161330724946

Epoch: 6| Step: 13
Training loss: 2.4938525912566933
Validation loss: 2.5219666846845645

Epoch: 76| Step: 0
Training loss: 2.4422863647989983
Validation loss: 2.519710603387521

Epoch: 6| Step: 1
Training loss: 2.3989916232790875
Validation loss: 2.5231506216080493

Epoch: 6| Step: 2
Training loss: 2.9780144942156994
Validation loss: 2.522145951537406

Epoch: 6| Step: 3
Training loss: 1.9755313882731012
Validation loss: 2.5230532925501468

Epoch: 6| Step: 4
Training loss: 2.7041955492762697
Validation loss: 2.521026041740979

Epoch: 6| Step: 5
Training loss: 2.6964952610397925
Validation loss: 2.5219625565756547

Epoch: 6| Step: 6
Training loss: 2.753314188628183
Validation loss: 2.518365114021182

Epoch: 6| Step: 7
Training loss: 3.217443404689184
Validation loss: 2.5267156167266758

Epoch: 6| Step: 8
Training loss: 2.9803244379585863
Validation loss: 2.5189095136617645

Epoch: 6| Step: 9
Training loss: 2.8888702840287475
Validation loss: 2.5233760231804494

Epoch: 6| Step: 10
Training loss: 2.5253964783260665
Validation loss: 2.5176344086654456

Epoch: 6| Step: 11
Training loss: 2.7269690792511554
Validation loss: 2.518021234069303

Epoch: 6| Step: 12
Training loss: 1.873425076581091
Validation loss: 2.517951852755772

Epoch: 6| Step: 13
Training loss: 2.6076030996829394
Validation loss: 2.5200280303506246

Epoch: 77| Step: 0
Training loss: 3.0748322976135243
Validation loss: 2.5188307939291676

Epoch: 6| Step: 1
Training loss: 2.941670642738429
Validation loss: 2.5217261244056237

Epoch: 6| Step: 2
Training loss: 2.74101053829735
Validation loss: 2.520422631427629

Epoch: 6| Step: 3
Training loss: 2.9365927735932202
Validation loss: 2.522316588257696

Epoch: 6| Step: 4
Training loss: 2.579560683499176
Validation loss: 2.5174935550853434

Epoch: 6| Step: 5
Training loss: 2.193128483645308
Validation loss: 2.517894013807059

Epoch: 6| Step: 6
Training loss: 2.5999316353246322
Validation loss: 2.515095751831193

Epoch: 6| Step: 7
Training loss: 2.472615559561029
Validation loss: 2.51399699541275

Epoch: 6| Step: 8
Training loss: 3.06206400356264
Validation loss: 2.5164723992893485

Epoch: 6| Step: 9
Training loss: 2.2499275195845287
Validation loss: 2.5146968701090344

Epoch: 6| Step: 10
Training loss: 2.5557765680839153
Validation loss: 2.5120265805676647

Epoch: 6| Step: 11
Training loss: 2.37552998301333
Validation loss: 2.511890625004556

Epoch: 6| Step: 12
Training loss: 1.849303207112657
Validation loss: 2.5112811666997437

Epoch: 6| Step: 13
Training loss: 3.08529401419909
Validation loss: 2.5137559411832133

Epoch: 78| Step: 0
Training loss: 2.6478856955056846
Validation loss: 2.514245660122734

Epoch: 6| Step: 1
Training loss: 2.3449612348723803
Validation loss: 2.512093222919164

Epoch: 6| Step: 2
Training loss: 2.873801271728727
Validation loss: 2.5128442942750575

Epoch: 6| Step: 3
Training loss: 2.6592763378162
Validation loss: 2.508513957603655

Epoch: 6| Step: 4
Training loss: 2.439584183360233
Validation loss: 2.5121256813592145

Epoch: 6| Step: 5
Training loss: 2.5686046178659656
Validation loss: 2.514177146622569

Epoch: 6| Step: 6
Training loss: 2.9994089815981417
Validation loss: 2.5128307105899967

Epoch: 6| Step: 7
Training loss: 2.564034723460342
Validation loss: 2.5130404114166462

Epoch: 6| Step: 8
Training loss: 2.2558120260182397
Validation loss: 2.512523484634288

Epoch: 6| Step: 9
Training loss: 3.138790069044787
Validation loss: 2.5166542522385273

Epoch: 6| Step: 10
Training loss: 2.877950729743654
Validation loss: 2.5105156674524562

Epoch: 6| Step: 11
Training loss: 2.396753969083575
Validation loss: 2.5093085084231763

Epoch: 6| Step: 12
Training loss: 2.5157223321317628
Validation loss: 2.507582767853598

Epoch: 6| Step: 13
Training loss: 2.4585369693877275
Validation loss: 2.5126300936242223

Epoch: 79| Step: 0
Training loss: 2.1903330304967015
Validation loss: 2.5073783157985723

Epoch: 6| Step: 1
Training loss: 2.730863659942238
Validation loss: 2.508386120499507

Epoch: 6| Step: 2
Training loss: 2.6414518246897827
Validation loss: 2.5173441065656075

Epoch: 6| Step: 3
Training loss: 2.267777150806268
Validation loss: 2.520457174015892

Epoch: 6| Step: 4
Training loss: 2.5694236261939185
Validation loss: 2.5193877186663545

Epoch: 6| Step: 5
Training loss: 2.3409141168430985
Validation loss: 2.5435879017562524

Epoch: 6| Step: 6
Training loss: 2.6291406762178053
Validation loss: 2.5497718048215616

Epoch: 6| Step: 7
Training loss: 2.0510626899516193
Validation loss: 2.533084565630636

Epoch: 6| Step: 8
Training loss: 2.4980288363976837
Validation loss: 2.52271761236286

Epoch: 6| Step: 9
Training loss: 2.846103239501748
Validation loss: 2.5164934953473757

Epoch: 6| Step: 10
Training loss: 2.856438802075914
Validation loss: 2.5075109979927763

Epoch: 6| Step: 11
Training loss: 2.726605609017418
Validation loss: 2.511030404398392

Epoch: 6| Step: 12
Training loss: 3.015678128579924
Validation loss: 2.5146707339980376

Epoch: 6| Step: 13
Training loss: 3.3894429057988162
Validation loss: 2.524144800854851

Epoch: 80| Step: 0
Training loss: 2.487747877796101
Validation loss: 2.529814780294445

Epoch: 6| Step: 1
Training loss: 2.522685502852321
Validation loss: 2.537151991183054

Epoch: 6| Step: 2
Training loss: 2.6992981563652405
Validation loss: 2.5428877747784298

Epoch: 6| Step: 3
Training loss: 2.653087573467064
Validation loss: 2.5454168221436233

Epoch: 6| Step: 4
Training loss: 2.3000731746809095
Validation loss: 2.540699060665801

Epoch: 6| Step: 5
Training loss: 2.7834589040911237
Validation loss: 2.5449742906841966

Epoch: 6| Step: 6
Training loss: 2.6317506001354833
Validation loss: 2.542974969140421

Epoch: 6| Step: 7
Training loss: 2.7585727411041105
Validation loss: 2.5390469751127935

Epoch: 6| Step: 8
Training loss: 2.7101722538668795
Validation loss: 2.5349523053770655

Epoch: 6| Step: 9
Training loss: 3.129358532776351
Validation loss: 2.536663686806545

Epoch: 6| Step: 10
Training loss: 2.9193195448981957
Validation loss: 2.534282516127891

Epoch: 6| Step: 11
Training loss: 2.542616296769703
Validation loss: 2.535559592271192

Epoch: 6| Step: 12
Training loss: 2.3872387408567177
Validation loss: 2.533849252903177

Epoch: 6| Step: 13
Training loss: 2.7684563405702383
Validation loss: 2.530828511502828

Epoch: 81| Step: 0
Training loss: 2.6302807687787673
Validation loss: 2.532243274732139

Epoch: 6| Step: 1
Training loss: 2.614922206443617
Validation loss: 2.531133201635945

Epoch: 6| Step: 2
Training loss: 2.5485947308431167
Validation loss: 2.5276591257979497

Epoch: 6| Step: 3
Training loss: 2.4901679295669696
Validation loss: 2.522687582067734

Epoch: 6| Step: 4
Training loss: 3.0237839768871377
Validation loss: 2.5224995479072945

Epoch: 6| Step: 5
Training loss: 2.2419165470813467
Validation loss: 2.52209426670382

Epoch: 6| Step: 6
Training loss: 3.092956749530742
Validation loss: 2.519285015523436

Epoch: 6| Step: 7
Training loss: 2.2207733384760884
Validation loss: 2.5167741697815655

Epoch: 6| Step: 8
Training loss: 2.8316064134473686
Validation loss: 2.516130084714493

Epoch: 6| Step: 9
Training loss: 2.263084091748082
Validation loss: 2.514821968880983

Epoch: 6| Step: 10
Training loss: 3.0160854166011903
Validation loss: 2.510968750413226

Epoch: 6| Step: 11
Training loss: 2.174624233013504
Validation loss: 2.510826826554544

Epoch: 6| Step: 12
Training loss: 2.880437767083591
Validation loss: 2.5082795053918496

Epoch: 6| Step: 13
Training loss: 2.7947932333034844
Validation loss: 2.509275205915245

Epoch: 82| Step: 0
Training loss: 2.6813019540728336
Validation loss: 2.5056916773186715

Epoch: 6| Step: 1
Training loss: 2.4773275354986164
Validation loss: 2.503443047760165

Epoch: 6| Step: 2
Training loss: 3.0423128843796463
Validation loss: 2.5021878444327896

Epoch: 6| Step: 3
Training loss: 2.5728148364303545
Validation loss: 2.5005565103375895

Epoch: 6| Step: 4
Training loss: 2.8997730560951607
Validation loss: 2.497605464491771

Epoch: 6| Step: 5
Training loss: 2.848773920110262
Validation loss: 2.5048764353293578

Epoch: 6| Step: 6
Training loss: 2.79826703939547
Validation loss: 2.4921674896999453

Epoch: 6| Step: 7
Training loss: 2.3157142776391093
Validation loss: 2.514979380339169

Epoch: 6| Step: 8
Training loss: 2.9983468269127918
Validation loss: 2.5180030308322174

Epoch: 6| Step: 9
Training loss: 1.9554646631031254
Validation loss: 2.509201061511787

Epoch: 6| Step: 10
Training loss: 2.7014077966895136
Validation loss: 2.499394899889871

Epoch: 6| Step: 11
Training loss: 2.5116347421981073
Validation loss: 2.4933884934666333

Epoch: 6| Step: 12
Training loss: 2.2266575843184184
Validation loss: 2.49465760977158

Epoch: 6| Step: 13
Training loss: 2.575691970883889
Validation loss: 2.496928139742969

Epoch: 83| Step: 0
Training loss: 2.5212406008105006
Validation loss: 2.498882759311558

Epoch: 6| Step: 1
Training loss: 2.988530486440416
Validation loss: 2.4974484297246082

Epoch: 6| Step: 2
Training loss: 2.5146323194264997
Validation loss: 2.497196389761177

Epoch: 6| Step: 3
Training loss: 2.4317204351234882
Validation loss: 2.5012571988438266

Epoch: 6| Step: 4
Training loss: 2.7872007337645868
Validation loss: 2.4969210897750527

Epoch: 6| Step: 5
Training loss: 2.347715050187876
Validation loss: 2.499307091373802

Epoch: 6| Step: 6
Training loss: 3.040343811269156
Validation loss: 2.499959023457723

Epoch: 6| Step: 7
Training loss: 1.9642917471954047
Validation loss: 2.4992934182148425

Epoch: 6| Step: 8
Training loss: 2.1002430230256266
Validation loss: 2.4990496657042236

Epoch: 6| Step: 9
Training loss: 2.475493287529086
Validation loss: 2.499434748961921

Epoch: 6| Step: 10
Training loss: 2.8290454357243147
Validation loss: 2.4963049443565

Epoch: 6| Step: 11
Training loss: 2.479952348435892
Validation loss: 2.502032264571573

Epoch: 6| Step: 12
Training loss: 2.622638639380152
Validation loss: 2.4996276419221957

Epoch: 6| Step: 13
Training loss: 3.365325200321428
Validation loss: 2.492977515380267

Epoch: 84| Step: 0
Training loss: 3.162585707396468
Validation loss: 2.4943747414302284

Epoch: 6| Step: 1
Training loss: 2.8422307577925463
Validation loss: 2.501718280301308

Epoch: 6| Step: 2
Training loss: 2.6107060127209225
Validation loss: 2.4941191964858245

Epoch: 6| Step: 3
Training loss: 2.3391623802494594
Validation loss: 2.5081442893723715

Epoch: 6| Step: 4
Training loss: 2.2209321158115602
Validation loss: 2.502684248887729

Epoch: 6| Step: 5
Training loss: 2.5578791195461057
Validation loss: 2.5265306661468387

Epoch: 6| Step: 6
Training loss: 2.3335497846570887
Validation loss: 2.546778421579595

Epoch: 6| Step: 7
Training loss: 3.037350522982636
Validation loss: 2.5559574746388627

Epoch: 6| Step: 8
Training loss: 2.0979986781506152
Validation loss: 2.517192297058144

Epoch: 6| Step: 9
Training loss: 2.0267901243494357
Validation loss: 2.520209815938414

Epoch: 6| Step: 10
Training loss: 2.9426782297040597
Validation loss: 2.504824164127214

Epoch: 6| Step: 11
Training loss: 2.8743899154193153
Validation loss: 2.49738260583222

Epoch: 6| Step: 12
Training loss: 2.738615921617651
Validation loss: 2.495060762189168

Epoch: 6| Step: 13
Training loss: 2.821062405712399
Validation loss: 2.497614318285667

Epoch: 85| Step: 0
Training loss: 2.239518547599623
Validation loss: 2.5038335177629234

Epoch: 6| Step: 1
Training loss: 3.289114401219806
Validation loss: 2.5105331098425374

Epoch: 6| Step: 2
Training loss: 2.3130064744739154
Validation loss: 2.5156503522081164

Epoch: 6| Step: 3
Training loss: 2.511990023805769
Validation loss: 2.5186654271519395

Epoch: 6| Step: 4
Training loss: 2.7646311035475226
Validation loss: 2.522173688076622

Epoch: 6| Step: 5
Training loss: 2.781012878596647
Validation loss: 2.5233908256253326

Epoch: 6| Step: 6
Training loss: 2.643886921540716
Validation loss: 2.5206718445642062

Epoch: 6| Step: 7
Training loss: 2.468633528267654
Validation loss: 2.5236550504052397

Epoch: 6| Step: 8
Training loss: 3.1037304121513962
Validation loss: 2.5282341687146146

Epoch: 6| Step: 9
Training loss: 2.744333758633974
Validation loss: 2.5276075143960264

Epoch: 6| Step: 10
Training loss: 2.615912101056318
Validation loss: 2.5248543744536787

Epoch: 6| Step: 11
Training loss: 2.7205222481152833
Validation loss: 2.5250032682995687

Epoch: 6| Step: 12
Training loss: 2.1268341899928194
Validation loss: 2.5274551107644467

Epoch: 6| Step: 13
Training loss: 2.5371305187304585
Validation loss: 2.522994011329441

Epoch: 86| Step: 0
Training loss: 2.7016758203871083
Validation loss: 2.5190926734421124

Epoch: 6| Step: 1
Training loss: 3.156540205804738
Validation loss: 2.518976462937341

Epoch: 6| Step: 2
Training loss: 2.787697423264501
Validation loss: 2.518437158357602

Epoch: 6| Step: 3
Training loss: 2.139132905502214
Validation loss: 2.516901880813355

Epoch: 6| Step: 4
Training loss: 2.497030974709699
Validation loss: 2.514849841499674

Epoch: 6| Step: 5
Training loss: 2.9214300949087377
Validation loss: 2.51194282034571

Epoch: 6| Step: 6
Training loss: 2.767213182206309
Validation loss: 2.51146067415242

Epoch: 6| Step: 7
Training loss: 2.2319335403392304
Validation loss: 2.510481890283547

Epoch: 6| Step: 8
Training loss: 2.516198323946689
Validation loss: 2.5092929736420935

Epoch: 6| Step: 9
Training loss: 2.0079346853401483
Validation loss: 2.5041846062583066

Epoch: 6| Step: 10
Training loss: 2.6300970274284072
Validation loss: 2.5052219530609077

Epoch: 6| Step: 11
Training loss: 2.7359626738361236
Validation loss: 2.502364423358566

Epoch: 6| Step: 12
Training loss: 2.39486010037332
Validation loss: 2.5001703522180785

Epoch: 6| Step: 13
Training loss: 3.102732248028196
Validation loss: 2.495047655026344

Epoch: 87| Step: 0
Training loss: 2.4430582301554287
Validation loss: 2.491983483074553

Epoch: 6| Step: 1
Training loss: 2.594841876642315
Validation loss: 2.488282272043223

Epoch: 6| Step: 2
Training loss: 2.8646754764418163
Validation loss: 2.4918440021021744

Epoch: 6| Step: 3
Training loss: 2.5819161947819764
Validation loss: 2.4898288451459734

Epoch: 6| Step: 4
Training loss: 2.904201975479647
Validation loss: 2.4874104763260143

Epoch: 6| Step: 5
Training loss: 2.6397747950877397
Validation loss: 2.491609161461852

Epoch: 6| Step: 6
Training loss: 2.5579357902813253
Validation loss: 2.499872999144355

Epoch: 6| Step: 7
Training loss: 2.432903945174431
Validation loss: 2.4981094603046836

Epoch: 6| Step: 8
Training loss: 2.393066555693349
Validation loss: 2.4944708238899898

Epoch: 6| Step: 9
Training loss: 2.995799302574141
Validation loss: 2.482380128074751

Epoch: 6| Step: 10
Training loss: 2.215313035876381
Validation loss: 2.4885595975421206

Epoch: 6| Step: 11
Training loss: 2.5624585032010647
Validation loss: 2.4855138219841573

Epoch: 6| Step: 12
Training loss: 2.446334284137909
Validation loss: 2.4850890375070604

Epoch: 6| Step: 13
Training loss: 2.9016427878927953
Validation loss: 2.489321329117845

Epoch: 88| Step: 0
Training loss: 2.898112235108005
Validation loss: 2.489324777070828

Epoch: 6| Step: 1
Training loss: 2.5958059963625852
Validation loss: 2.4888947517556814

Epoch: 6| Step: 2
Training loss: 2.6270121174254406
Validation loss: 2.4951020102838712

Epoch: 6| Step: 3
Training loss: 2.2838907503498698
Validation loss: 2.487138390894815

Epoch: 6| Step: 4
Training loss: 2.4357044747150614
Validation loss: 2.4906868716747086

Epoch: 6| Step: 5
Training loss: 2.351954126539969
Validation loss: 2.487923556997451

Epoch: 6| Step: 6
Training loss: 2.6608956495523075
Validation loss: 2.4870028243346027

Epoch: 6| Step: 7
Training loss: 2.6984181079267104
Validation loss: 2.486624756703622

Epoch: 6| Step: 8
Training loss: 2.7618643845032382
Validation loss: 2.486622239841819

Epoch: 6| Step: 9
Training loss: 3.0252033764277733
Validation loss: 2.4891563964553547

Epoch: 6| Step: 10
Training loss: 2.8877955429954754
Validation loss: 2.487275963028174

Epoch: 6| Step: 11
Training loss: 1.746806500615349
Validation loss: 2.4901573657925167

Epoch: 6| Step: 12
Training loss: 2.4472338650797285
Validation loss: 2.482521261231089

Epoch: 6| Step: 13
Training loss: 2.869679046654965
Validation loss: 2.4869221199776126

Epoch: 89| Step: 0
Training loss: 2.5787066179288596
Validation loss: 2.4815298779382653

Epoch: 6| Step: 1
Training loss: 2.510856610973219
Validation loss: 2.489449857913861

Epoch: 6| Step: 2
Training loss: 2.114137937746285
Validation loss: 2.4847680026928916

Epoch: 6| Step: 3
Training loss: 2.6364939501971687
Validation loss: 2.491965591930956

Epoch: 6| Step: 4
Training loss: 3.118147393912933
Validation loss: 2.484468854175017

Epoch: 6| Step: 5
Training loss: 2.7168554084445287
Validation loss: 2.4841193461483297

Epoch: 6| Step: 6
Training loss: 2.31226306423176
Validation loss: 2.48490306752184

Epoch: 6| Step: 7
Training loss: 2.5289041457286774
Validation loss: 2.4904738127842876

Epoch: 6| Step: 8
Training loss: 2.541097066455247
Validation loss: 2.4895568803688004

Epoch: 6| Step: 9
Training loss: 2.801489066221601
Validation loss: 2.491611585571737

Epoch: 6| Step: 10
Training loss: 3.064943389867627
Validation loss: 2.484666611293338

Epoch: 6| Step: 11
Training loss: 2.0090079107209498
Validation loss: 2.4834216065900465

Epoch: 6| Step: 12
Training loss: 2.705587158784447
Validation loss: 2.4857562561907898

Epoch: 6| Step: 13
Training loss: 2.5412434293302675
Validation loss: 2.4855851558887045

Epoch: 90| Step: 0
Training loss: 2.860222029170523
Validation loss: 2.4853956657048943

Epoch: 6| Step: 1
Training loss: 2.720334698336159
Validation loss: 2.478705168225818

Epoch: 6| Step: 2
Training loss: 2.462995365102839
Validation loss: 2.485210590074252

Epoch: 6| Step: 3
Training loss: 2.882358753088579
Validation loss: 2.4878772385649817

Epoch: 6| Step: 4
Training loss: 2.0725795784870065
Validation loss: 2.4763276061969455

Epoch: 6| Step: 5
Training loss: 2.554313235617718
Validation loss: 2.4830753757816026

Epoch: 6| Step: 6
Training loss: 2.1107462629072575
Validation loss: 2.4818903176097487

Epoch: 6| Step: 7
Training loss: 2.734664291337406
Validation loss: 2.480010399309525

Epoch: 6| Step: 8
Training loss: 3.0032988530704854
Validation loss: 2.4863707086033426

Epoch: 6| Step: 9
Training loss: 2.2783978543450933
Validation loss: 2.4828079847771294

Epoch: 6| Step: 10
Training loss: 2.0792971868835477
Validation loss: 2.4848037765573303

Epoch: 6| Step: 11
Training loss: 2.8880603857516634
Validation loss: 2.4851747740976857

Epoch: 6| Step: 12
Training loss: 2.9573034365317765
Validation loss: 2.4855557880544557

Epoch: 6| Step: 13
Training loss: 2.4471195844107196
Validation loss: 2.4833648675371465

Epoch: 91| Step: 0
Training loss: 2.6769747780091557
Validation loss: 2.4887844916239503

Epoch: 6| Step: 1
Training loss: 2.7596244586927288
Validation loss: 2.485531871477993

Epoch: 6| Step: 2
Training loss: 2.2884331055978864
Validation loss: 2.487227683441087

Epoch: 6| Step: 3
Training loss: 2.1433762738962714
Validation loss: 2.4821685173509143

Epoch: 6| Step: 4
Training loss: 3.1516442261341937
Validation loss: 2.480780954812844

Epoch: 6| Step: 5
Training loss: 2.685598365983645
Validation loss: 2.480962588994669

Epoch: 6| Step: 6
Training loss: 2.208773898916692
Validation loss: 2.483875408363075

Epoch: 6| Step: 7
Training loss: 2.570365835639397
Validation loss: 2.483918569930646

Epoch: 6| Step: 8
Training loss: 2.763862694936194
Validation loss: 2.4833848367594373

Epoch: 6| Step: 9
Training loss: 2.8122555944424574
Validation loss: 2.4832670672320565

Epoch: 6| Step: 10
Training loss: 2.6343140437810764
Validation loss: 2.4807175959519414

Epoch: 6| Step: 11
Training loss: 2.6986523267166453
Validation loss: 2.4815473319115586

Epoch: 6| Step: 12
Training loss: 1.9956828849753216
Validation loss: 2.4775018685465673

Epoch: 6| Step: 13
Training loss: 2.691984117367556
Validation loss: 2.482028372745609

Epoch: 92| Step: 0
Training loss: 2.410401169560323
Validation loss: 2.482008440639131

Epoch: 6| Step: 1
Training loss: 2.210818769414415
Validation loss: 2.4870287718827147

Epoch: 6| Step: 2
Training loss: 2.790804022742061
Validation loss: 2.4818249296608337

Epoch: 6| Step: 3
Training loss: 2.4580771641425643
Validation loss: 2.4888358703237947

Epoch: 6| Step: 4
Training loss: 3.050498333852826
Validation loss: 2.487279381864793

Epoch: 6| Step: 5
Training loss: 2.6952458912455692
Validation loss: 2.475494395111587

Epoch: 6| Step: 6
Training loss: 2.474699842188835
Validation loss: 2.48358895204458

Epoch: 6| Step: 7
Training loss: 2.964475425388022
Validation loss: 2.479939858427732

Epoch: 6| Step: 8
Training loss: 2.4266330372223295
Validation loss: 2.4808142874433714

Epoch: 6| Step: 9
Training loss: 2.6988821965359673
Validation loss: 2.4795311304604764

Epoch: 6| Step: 10
Training loss: 1.8751565867842417
Validation loss: 2.4780824732168076

Epoch: 6| Step: 11
Training loss: 2.5114924446066738
Validation loss: 2.4841248968179364

Epoch: 6| Step: 12
Training loss: 2.9535128222733364
Validation loss: 2.480210322336945

Epoch: 6| Step: 13
Training loss: 2.8107801477094085
Validation loss: 2.4841371978254

Epoch: 93| Step: 0
Training loss: 2.307404962403102
Validation loss: 2.482476970902571

Epoch: 6| Step: 1
Training loss: 2.8211950891886595
Validation loss: 2.483939142600696

Epoch: 6| Step: 2
Training loss: 2.189726214430708
Validation loss: 2.485044952845637

Epoch: 6| Step: 3
Training loss: 3.0708181338578924
Validation loss: 2.485586594695837

Epoch: 6| Step: 4
Training loss: 3.018833015516713
Validation loss: 2.4856196150906436

Epoch: 6| Step: 5
Training loss: 2.4582774484607794
Validation loss: 2.4841727248404504

Epoch: 6| Step: 6
Training loss: 2.6532854478754664
Validation loss: 2.4829992327720305

Epoch: 6| Step: 7
Training loss: 2.376684194003512
Validation loss: 2.4860746939233693

Epoch: 6| Step: 8
Training loss: 1.852595946263595
Validation loss: 2.485252481320485

Epoch: 6| Step: 9
Training loss: 3.164974429733855
Validation loss: 2.4821039852170945

Epoch: 6| Step: 10
Training loss: 2.57138363859489
Validation loss: 2.4800371250070774

Epoch: 6| Step: 11
Training loss: 2.5440765171299797
Validation loss: 2.476191038559144

Epoch: 6| Step: 12
Training loss: 2.3135670442547625
Validation loss: 2.4810350627674076

Epoch: 6| Step: 13
Training loss: 2.686575087255685
Validation loss: 2.470976505559455

Epoch: 94| Step: 0
Training loss: 2.0643099155035065
Validation loss: 2.4751037569485708

Epoch: 6| Step: 1
Training loss: 2.612896216613654
Validation loss: 2.476190252236384

Epoch: 6| Step: 2
Training loss: 2.4890617452022847
Validation loss: 2.47294137766146

Epoch: 6| Step: 3
Training loss: 2.781863198564909
Validation loss: 2.474735930191668

Epoch: 6| Step: 4
Training loss: 2.507762112215272
Validation loss: 2.473315094429006

Epoch: 6| Step: 5
Training loss: 2.9338824133944086
Validation loss: 2.4675544386980888

Epoch: 6| Step: 6
Training loss: 2.835129467734396
Validation loss: 2.470917036323082

Epoch: 6| Step: 7
Training loss: 2.8349464723623385
Validation loss: 2.470638422062239

Epoch: 6| Step: 8
Training loss: 2.3727647401727445
Validation loss: 2.4768669831740353

Epoch: 6| Step: 9
Training loss: 2.775641798429415
Validation loss: 2.472081813206332

Epoch: 6| Step: 10
Training loss: 2.335954749002212
Validation loss: 2.4764695335612643

Epoch: 6| Step: 11
Training loss: 2.070173611570647
Validation loss: 2.4726402438882613

Epoch: 6| Step: 12
Training loss: 3.1765017284578954
Validation loss: 2.480875954031763

Epoch: 6| Step: 13
Training loss: 2.278321777552572
Validation loss: 2.476156464192921

Epoch: 95| Step: 0
Training loss: 2.7708107988019623
Validation loss: 2.477219968662956

Epoch: 6| Step: 1
Training loss: 2.2634397293874065
Validation loss: 2.4765515492675503

Epoch: 6| Step: 2
Training loss: 2.882393328371143
Validation loss: 2.479472675724992

Epoch: 6| Step: 3
Training loss: 2.9245329002998965
Validation loss: 2.4815167313323694

Epoch: 6| Step: 4
Training loss: 2.8249978327109875
Validation loss: 2.4800272390961626

Epoch: 6| Step: 5
Training loss: 2.745267263440353
Validation loss: 2.478207784763596

Epoch: 6| Step: 6
Training loss: 2.678969751441435
Validation loss: 2.477286344336467

Epoch: 6| Step: 7
Training loss: 2.632690789100692
Validation loss: 2.4800544132395537

Epoch: 6| Step: 8
Training loss: 2.2435144624900683
Validation loss: 2.4768933256749825

Epoch: 6| Step: 9
Training loss: 1.4807886266247905
Validation loss: 2.4795978609263236

Epoch: 6| Step: 10
Training loss: 2.6414742994413887
Validation loss: 2.4749767308795003

Epoch: 6| Step: 11
Training loss: 3.0234471205131985
Validation loss: 2.4761736029968797

Epoch: 6| Step: 12
Training loss: 2.2106334895131927
Validation loss: 2.4698114326508787

Epoch: 6| Step: 13
Training loss: 2.455277197390924
Validation loss: 2.4740145599935954

Epoch: 96| Step: 0
Training loss: 2.0750804196136037
Validation loss: 2.469632067619192

Epoch: 6| Step: 1
Training loss: 3.0214509179223916
Validation loss: 2.4666629290767226

Epoch: 6| Step: 2
Training loss: 2.9604755937124017
Validation loss: 2.473536217800597

Epoch: 6| Step: 3
Training loss: 2.949396595424157
Validation loss: 2.4726391430625116

Epoch: 6| Step: 4
Training loss: 2.163910677986096
Validation loss: 2.4695240368607503

Epoch: 6| Step: 5
Training loss: 2.420110835224897
Validation loss: 2.471156528771733

Epoch: 6| Step: 6
Training loss: 2.2679492472599496
Validation loss: 2.473896264083967

Epoch: 6| Step: 7
Training loss: 2.5715081584815094
Validation loss: 2.477515036456802

Epoch: 6| Step: 8
Training loss: 2.5092098347998224
Validation loss: 2.4750824124650794

Epoch: 6| Step: 9
Training loss: 2.2224288314564027
Validation loss: 2.4815825197092614

Epoch: 6| Step: 10
Training loss: 2.4524425359093036
Validation loss: 2.4800548458443816

Epoch: 6| Step: 11
Training loss: 2.800458604857778
Validation loss: 2.4815433767558908

Epoch: 6| Step: 12
Training loss: 2.5551231082886674
Validation loss: 2.4950997806745643

Epoch: 6| Step: 13
Training loss: 2.8067743300072063
Validation loss: 2.4954796773492816

Epoch: 97| Step: 0
Training loss: 2.3861289036888875
Validation loss: 2.4983329460019896

Epoch: 6| Step: 1
Training loss: 2.618614422695899
Validation loss: 2.4909778078648364

Epoch: 6| Step: 2
Training loss: 2.6270372568718776
Validation loss: 2.5011787496672175

Epoch: 6| Step: 3
Training loss: 2.3549992487231957
Validation loss: 2.4768253030539205

Epoch: 6| Step: 4
Training loss: 2.412688719330423
Validation loss: 2.469606806158283

Epoch: 6| Step: 5
Training loss: 2.968658767101447
Validation loss: 2.4697264900976785

Epoch: 6| Step: 6
Training loss: 2.208690566432861
Validation loss: 2.4746746485169666

Epoch: 6| Step: 7
Training loss: 2.9388635595424373
Validation loss: 2.4773660393125922

Epoch: 6| Step: 8
Training loss: 3.147729836723603
Validation loss: 2.476720955289201

Epoch: 6| Step: 9
Training loss: 1.8177409201017356
Validation loss: 2.4804108219941883

Epoch: 6| Step: 10
Training loss: 1.9873449972877455
Validation loss: 2.4826381698168682

Epoch: 6| Step: 11
Training loss: 2.7026286468798837
Validation loss: 2.4778907334829943

Epoch: 6| Step: 12
Training loss: 2.5791861459944485
Validation loss: 2.476629823878723

Epoch: 6| Step: 13
Training loss: 3.1651329207870558
Validation loss: 2.4766581904940987

Epoch: 98| Step: 0
Training loss: 2.663672992053219
Validation loss: 2.479991236102093

Epoch: 6| Step: 1
Training loss: 2.2381275383861117
Validation loss: 2.478097033092316

Epoch: 6| Step: 2
Training loss: 2.5855194399251684
Validation loss: 2.477489582710935

Epoch: 6| Step: 3
Training loss: 2.5732962962764656
Validation loss: 2.4786034005616955

Epoch: 6| Step: 4
Training loss: 2.435584562816117
Validation loss: 2.4826184986999267

Epoch: 6| Step: 5
Training loss: 2.6801179145380223
Validation loss: 2.481223500684392

Epoch: 6| Step: 6
Training loss: 2.33646501689561
Validation loss: 2.472802292948836

Epoch: 6| Step: 7
Training loss: 2.7187389505096045
Validation loss: 2.4732091605907347

Epoch: 6| Step: 8
Training loss: 2.8496537182229242
Validation loss: 2.473983255896601

Epoch: 6| Step: 9
Training loss: 2.4560461449901143
Validation loss: 2.467679222088734

Epoch: 6| Step: 10
Training loss: 2.7188709275986533
Validation loss: 2.4715029340424723

Epoch: 6| Step: 11
Training loss: 2.1621003327357218
Validation loss: 2.473171170471863

Epoch: 6| Step: 12
Training loss: 2.6802444101735574
Validation loss: 2.4726170862681047

Epoch: 6| Step: 13
Training loss: 2.8538646863097967
Validation loss: 2.4810165160896736

Epoch: 99| Step: 0
Training loss: 2.6788931244723018
Validation loss: 2.4775355981449962

Epoch: 6| Step: 1
Training loss: 2.653258490377493
Validation loss: 2.480317839589955

Epoch: 6| Step: 2
Training loss: 2.4430474952081416
Validation loss: 2.4806767734395856

Epoch: 6| Step: 3
Training loss: 2.491763661855877
Validation loss: 2.474540687416661

Epoch: 6| Step: 4
Training loss: 2.5835392367434578
Validation loss: 2.485192058568677

Epoch: 6| Step: 5
Training loss: 2.4853632658737217
Validation loss: 2.4708564720764357

Epoch: 6| Step: 6
Training loss: 2.6299230641182554
Validation loss: 2.4794040747911383

Epoch: 6| Step: 7
Training loss: 2.4129262676079843
Validation loss: 2.4771965811604564

Epoch: 6| Step: 8
Training loss: 2.838305616917321
Validation loss: 2.4713231290121733

Epoch: 6| Step: 9
Training loss: 2.6640007481731476
Validation loss: 2.4698613799859146

Epoch: 6| Step: 10
Training loss: 3.081036889558341
Validation loss: 2.4688729444705784

Epoch: 6| Step: 11
Training loss: 2.3188825625959
Validation loss: 2.4690110273829524

Epoch: 6| Step: 12
Training loss: 2.524434651451339
Validation loss: 2.46475462996738

Epoch: 6| Step: 13
Training loss: 2.227801704225403
Validation loss: 2.4688842672542637

Epoch: 100| Step: 0
Training loss: 1.8144910334147168
Validation loss: 2.4591283213220803

Epoch: 6| Step: 1
Training loss: 3.397172223154065
Validation loss: 2.4661471572652216

Epoch: 6| Step: 2
Training loss: 2.643161345615568
Validation loss: 2.4650871370298093

Epoch: 6| Step: 3
Training loss: 2.726396528291507
Validation loss: 2.468506845338162

Epoch: 6| Step: 4
Training loss: 2.557232257181422
Validation loss: 2.472402132705454

Epoch: 6| Step: 5
Training loss: 2.611759489690528
Validation loss: 2.4741198329747913

Epoch: 6| Step: 6
Training loss: 2.8565643337917
Validation loss: 2.4678248349910756

Epoch: 6| Step: 7
Training loss: 2.769445851116361
Validation loss: 2.467184431490078

Epoch: 6| Step: 8
Training loss: 2.297032980124531
Validation loss: 2.470027480390837

Epoch: 6| Step: 9
Training loss: 2.3984380964346776
Validation loss: 2.463853672477879

Epoch: 6| Step: 10
Training loss: 2.327683989467165
Validation loss: 2.4719391034443152

Epoch: 6| Step: 11
Training loss: 2.2449983529677433
Validation loss: 2.4587671145044068

Epoch: 6| Step: 12
Training loss: 2.5819535929072224
Validation loss: 2.4673148865012333

Epoch: 6| Step: 13
Training loss: 2.696173400498232
Validation loss: 2.4662698045216733

Testing loss: 2.0523950695493016
